{"id": "2506.05566", "pdf": "https://arxiv.org/pdf/2506.05566", "abs": "https://arxiv.org/abs/2506.05566", "authors": ["Chenhui Deng", "Yun-Da Tsai", "Guan-Ting Liu", "Zhongzhi Yu", "Haoxing Ren"], "title": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled near-human\nperformance on software coding benchmarks, but their effectiveness in RTL code\ngeneration remains limited due to the scarcity of high-quality training data.\nWhile prior efforts have fine-tuned LLMs for RTL tasks, they do not\nfundamentally overcome the data bottleneck and lack support for test-time\nscaling due to their non-reasoning nature. In this work, we introduce ScaleRTL,\nthe first reasoning LLM for RTL coding that scales up both high-quality\nreasoning data and test-time compute. Specifically, we curate a diverse set of\nlong chain-of-thought reasoning traces averaging 56K tokens each, resulting in\na dataset of 3.5B tokens that captures rich RTL knowledge. Fine-tuning a\ngeneral-purpose reasoning model on this corpus yields ScaleRTL that is capable\nof deep RTL reasoning. Subsequently, we further enhance the performance of\nScaleRTL through a novel test-time scaling strategy that extends the reasoning\nprocess via iteratively reflecting on and self-correcting previous reasoning\nsteps. Experimental results show that ScaleRTL achieves state-of-the-art\nperformance on VerilogEval and RTLLM, outperforming 18 competitive baselines by\nup to 18.4% on VerilogEval and 12.7% on RTLLM.", "AI": {"title_translation": "ScaleRTL：通过推理数据和测试时计算扩展LLM以实现精确的RTL代码生成", "tldr": "ScaleRTL是一个用于RTL代码生成的推理型LLM，通过高质量推理数据和测试时计算的扩展，在VerilogEval和RTLLM上实现了最先进的性能。", "motivation": "尽管大型语言模型（LLM）在软件编码基准测试上表现接近人类水平，但由于高质量训练数据稀缺，它们在RTL代码生成方面的有效性仍然有限。先前的努力未能从根本上克服数据瓶颈，并且由于其非推理性质，缺乏对测试时扩展的支持。", "method": "本文介绍了ScaleRTL，它是第一个用于RTL编码的推理型LLM，它扩展了高质量的推理数据和测试时计算。具体来说，作者整理了一组多样化的长链式思考推理轨迹，平均每个56K token，形成一个包含3.5B token的数据集，捕获了丰富的RTL知识。通过对通用推理模型进行微调，得到了ScaleRTL。随后，通过一种新颖的测试时扩展策略进一步增强了ScaleRTL的性能，该策略通过迭代反思和自我纠正先前的推理步骤来扩展推理过程。", "result": "ScaleRTL在VerilogEval和RTLLM上取得了最先进的性能，在VerilogEval上比18个有竞争力的基线高出18.4%，在RTLLM上高出12.7%。", "conclusion": "ScaleRTL通过结合高质量的推理数据和创新的测试时扩展策略，显著提高了大型语言模型在RTL代码生成任务上的准确性和性能，克服了现有方法的局限性。", "translation": "大型语言模型（LLM）的最新进展使得它们在软件编码基准测试上取得了接近人类的表现，但由于高质量训练数据的稀缺，它们在RTL代码生成方面的有效性仍然有限。虽然之前的努力已经对LLM进行了RTL任务的微调，但它们并未从根本上克服数据瓶颈，并且由于其非推理性质，缺乏对测试时扩展的支持。在这项工作中，我们引入了ScaleRTL，这是第一个用于RTL编码的推理型LLM，它扩展了高质量的推理数据和测试时计算。具体来说，我们整理了一组多样化的长链式思考推理轨迹，平均每个56K token，形成一个包含3.5B token的数据集，捕获了丰富的RTL知识。通过对通用推理模型进行此语料库的微调，得到了能够进行深度RTL推理的ScaleRTL。随后，我们通过一种新颖的测试时扩展策略进一步增强了ScaleRTL的性能，该策略通过迭代反思和自我纠正先前的推理步骤来扩展推理过程。实验结果表明，ScaleRTL在VerilogEval和RTLLM上取得了最先进的性能，在VerilogEval上比18个有竞争力的基线高出18.4%，在RTLLM上高出12.7%。", "summary": "ScaleRTL是一种新型的推理型大型语言模型，专门用于RTL代码生成。它通过构建一个包含3.5B token的高质量链式思考推理数据集来克服数据稀缺问题，并采用创新的测试时自我纠正策略来进一步提升性能。实验证明，ScaleRTL在VerilogEval和RTLLM基准测试上均超越了现有最先进的方法，显著提高了RTL代码生成的准确性。", "keywords": "RTL代码生成, 大型语言模型, 推理数据, 测试时计算, 链式思考", "comments": "该论文的创新点在于结合了高质量的推理数据构建和独特的测试时计算扩展策略，有效地解决了RTL代码生成领域LLM面临的数据稀缺和推理能力不足的挑战。通过引入“链式思考”和“自我纠正”机制，ScaleRTL显著提升了模型在复杂RTL任务上的表现，为未来硬件描述语言的自动化生成提供了新的方向和潜力。"}}
{"id": "2506.05682", "pdf": "https://arxiv.org/pdf/2506.05682", "abs": "https://arxiv.org/abs/2506.05682", "authors": ["Yu Feng", "Weikai Lin", "Yuge Cheng", "Zihan Liu", "Jingwen Leng", "Minyi Guo", "Chen Chen", "Shixuan Sun", "Yuhao Zhu"], "title": "Lumina: Real-Time Mobile Neural Rendering by Exploiting Computational Redundancy", "categories": ["cs.AR"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has vastly advanced the pace of neural\nrendering, but it remains computationally demanding on today's mobile SoCs. To\naddress this challenge, we propose Lumina, a hardware-algorithm co-designed\nsystem, which integrates two principal optimizations: a novel algorithm, S^2,\nand a radiance caching mechanism, RC, to improve the efficiency of neural\nrendering. S2 algorithm exploits temporal coherence in rendering to reduce the\ncomputational overhead, while RC leverages the color integration process of\n3DGS to decrease the frequency of intensive rasterization computations. Coupled\nwith these techniques, we propose an accelerator architecture, LuminCore, to\nfurther accelerate cache lookup and address the fundamental inefficiencies in\nRasterization. We show that Lumina achieves 4.5x speedup and 5.3x energy\nreduction against a mobile Volta GPU, with a marginal quality loss (< 0.2 dB\npeak signal-to-noise ratio reduction) across synthetic and real-world datasets.", "AI": {"title_translation": "Lumina：通过利用计算冗余实现实时移动神经渲染", "tldr": "Lumina是一个软硬件协同设计的系统，通过S^2算法和辐射缓存机制，以及LuminCore加速器，显著提高了移动设备上3D Gaussian Splatting神经渲染的效率和能效，同时保持了高质量。", "motivation": "3D Gaussian Splatting (3DGS) 显著推动了神经渲染的进步，但在当前的移动系统级芯片（SoC）上计算需求仍然很高，难以实现实时性能。", "method": "本文提出了Lumina，一个软硬件协同设计的系统，包含两个主要优化：一种新颖的S^2算法和一种辐射缓存（RC）机制。S^2算法利用渲染中的时间一致性来减少计算开销，而RC机制则利用3DGS的颜色积分过程来降低密集光栅化计算的频率。此外，还提出了一种加速器架构LuminCore，以进一步加速缓存查找并解决光栅化中的基本低效率问题。", "result": "Lumina相对于移动Volta GPU实现了4.5倍的速度提升和5.3倍的能耗降低，且在合成和真实世界数据集上仅有微小的质量损失（峰值信噪比降低<0.2 dB）。", "conclusion": "Lumina通过软硬件协同设计，有效解决了移动设备上3D Gaussian Splatting神经渲染的计算密集型问题，实现了实时、高效且高质量的渲染。", "translation": "3D Gaussian Splatting (3DGS) 极大地推动了神经渲染的进展，但它在当今的移动系统级芯片 (SoC) 上仍然计算量巨大。为了解决这一挑战，我们提出了 Lumina，一个软硬件协同设计的系统，它集成了两个主要优化：一种新颖的 S^2 算法和一种辐射缓存机制 (RC)，以提高神经渲染的效率。S^2 算法利用渲染中的时间一致性来减少计算开销，而 RC 则利用 3DGS 的颜色积分过程来降低密集光栅化计算的频率。结合这些技术，我们提出了一种加速器架构 LuminCore，以进一步加速缓存查找并解决光栅化中的基本低效率问题。我们表明，Lumina 相对于移动 Volta GPU 实现了 4.5 倍的速度提升和 5.3 倍的能耗降低，在合成和真实世界数据集上质量损失微乎其微（峰值信噪比降低 < 0.2 dB）。", "summary": "Lumina是一个针对移动设备上3D Gaussian Splatting神经渲染效率瓶颈的软硬件协同设计系统。它通过引入S^2算法利用时间一致性减少计算，并结合辐射缓存机制降低光栅化频率。此外，LuminCore加速器进一步优化了缓存查找和光栅化效率。实验结果表明，Lumina在移动设备上实现了显著的速度和能效提升，同时保持了高质量的渲染效果。", "keywords": "3D Gaussian Splatting, 神经渲染, 移动设备, 软硬件协同设计, 实时渲染", "comments": "这篇论文的创新点在于其软硬件协同设计的方法，特别是S^2算法和辐射缓存机制与LuminCore加速器的结合，有效地解决了3DGS在移动设备上的计算密集型问题。其重要性在于为实时移动神经渲染提供了可行的解决方案，这对于AR/VR和移动图形应用具有重要意义。该研究成功地在性能和能耗之间取得了平衡，同时将质量损失控制在可接受的范围内。"}}
{"id": "2506.05588", "pdf": "https://arxiv.org/pdf/2506.05588", "abs": "https://arxiv.org/abs/2506.05588", "authors": ["Rishona Daniels", "Duna Wattad", "Ronny Ronen", "David Saad", "Shahar Kvatinsky"], "title": "Preprocessing Methods for Memristive Reservoir Computing for Image Recognition", "categories": ["cs.NE", "cs.AR", "cs.ET"], "comment": "6 pages, 8 figures, submitted for review in IEEE MetroXRAINE 2025\n  conference", "summary": "Reservoir computing (RC) has attracted attention as an efficient recurrent\nneural network architecture due to its simplified training, requiring only its\nlast perceptron readout layer to be trained. When implemented with memristors,\nRC systems benefit from their dynamic properties, which make them ideal for\nreservoir construction. However, achieving high performance in memristor-based\nRC remains challenging, as it critically depends on the input preprocessing\nmethod and reservoir size. Despite growing interest, a comprehensive evaluation\nthat quantifies the impact of these factors is still lacking. This paper\nsystematically compares various preprocessing methods for memristive RC\nsystems, assessing their effects on accuracy and energy consumption. We also\npropose a parity-based preprocessing method that improves accuracy by 2-6%\nwhile requiring only a modest increase in device count compared to other\nmethods. Our findings highlight the importance of informed preprocessing\nstrategies to improve the efficiency and scalability of memristive RC systems.", "AI": {"title_translation": "忆阻器储层计算用于图像识别的预处理方法", "tldr": "本文系统比较了忆阻器储层计算的预处理方法，并提出了一种新的基于奇偶校验的预处理方法，提高了图像识别的准确性。", "motivation": "忆阻器储层计算在实现高性能时面临挑战，其性能关键取决于输入预处理方法和储层大小，目前缺乏对这些因素影响的全面评估。", "method": "本文系统地比较了忆阻器储层计算系统中的各种预处理方法，评估它们对准确性和能耗的影响。同时，提出了一种基于奇偶校验的预处理方法。", "result": "本文提出的基于奇偶校验的预处理方法可以将准确性提高2-6%，同时与其它方法相比，仅需适度增加器件数量。研究结果强调了明智的预处理策略对于提高忆阻器储层计算系统效率和可扩展性的重要性。", "conclusion": "明智的预处理策略对于提高忆阻器储层计算系统的效率和可扩展性至关重要。", "translation": "储层计算（RC）作为一种高效的循环神经网络架构，因其简化的训练（仅需训练其最后一个感知器读出层）而备受关注。当使用忆阻器实现时，RC 系统受益于其动态特性，这使得它们成为储层构建的理想选择。然而，在基于忆忆阻器的 RC 中实现高性能仍然具有挑战性，因为它关键取决于输入预处理方法和储层大小。尽管兴趣日益增长，但仍缺乏量化这些因素影响的全面评估。本文系统地比较了忆阻器 RC 系统中的各种预处理方法，评估它们对准确性和能耗的影响。我们还提出了一种基于奇偶校验的预处理方法，与其它方法相比，该方法将准确性提高了 2-6%，同时仅需适度增加器件数量。我们的研究结果强调了明智的预处理策略对于提高忆阻器 RC 系统效率和可扩展性的重要性。", "summary": "本文针对忆阻器储层计算（RC）在图像识别中面临的性能挑战，系统地比较了多种预处理方法对准确性和能耗的影响。研究提出了一种新的基于奇偶校验的预处理方法，该方法在仅适度增加器件数量的情况下，将准确性提高了2-6%。研究强调了优化预处理策略对于提升忆阻器RC系统效率和可扩展性的重要性。", "keywords": "忆阻器储层计算, 预处理方法, 图像识别, 准确性, 能耗", "comments": "这篇论文在忆阻器储层计算领域具有重要意义，因为它不仅系统地评估了不同的预处理方法，还提出了一种有效的新方法来提高性能。其创新点在于提出了一种基于奇偶校验的预处理方法，这对于提升忆阻器RC在图像识别任务中的准确性和能效具有实际价值。该研究为未来设计和优化忆阻器RC系统提供了重要的指导。"}}
{"id": "2506.05994", "pdf": "https://arxiv.org/pdf/2506.05994", "abs": "https://arxiv.org/abs/2506.05994", "authors": ["Yi-Chun Liao", "Chieh-Lin Tsai", "Yuan-Hao Chang", "Camélia Slimani", "Jalil Boukhobza", "Tei-Wei Kuo"], "title": "RETENTION: Resource-Efficient Tree-Based Ensemble Model Acceleration with Content-Addressable Memory", "categories": ["cs.LG", "cs.AR", "cs.ET"], "comment": null, "summary": "Although deep learning has demonstrated remarkable capabilities in learning\nfrom unstructured data, modern tree-based ensemble models remain superior in\nextracting relevant information and learning from structured datasets. While\nseveral efforts have been made to accelerate tree-based models, the inherent\ncharacteristics of the models pose significant challenges for conventional\naccelerators. Recent research leveraging content-addressable memory (CAM)\noffers a promising solution for accelerating tree-based models, yet existing\ndesigns suffer from excessive memory consumption and low utilization. This work\naddresses these challenges by introducing RETENTION, an end-to-end framework\nthat significantly reduces CAM capacity requirement for tree-based model\ninference. We propose an iterative pruning algorithm with a novel pruning\ncriterion tailored for bagging-based models (e.g., Random Forest), which\nminimizes model complexity while ensuring controlled accuracy degradation.\nAdditionally, we present a tree mapping scheme that incorporates two innovative\ndata placement strategies to alleviate the memory redundancy caused by the\nwidespread use of don't care states in CAM. Experimental results show that\nimplementing the tree mapping scheme alone achieves $1.46\\times$ to $21.30\n\\times$ better space efficiency, while the full RETENTION framework yields\n$4.35\\times$ to $207.12\\times$ improvement with less than 3% accuracy loss.\nThese results demonstrate that RETENTION is highly effective in reducing CAM\ncapacity requirement, providing a resource-efficient direction for tree-based\nmodel acceleration.", "AI": {"title_translation": "RETENTION: 基于内容可寻址存储器的资源高效树形集成模型加速", "tldr": "RETENTION是一个端到端框架，通过迭代剪枝算法和创新的树映射方案，显著减少了基于内容可寻址存储器（CAM）的树形集成模型推理所需的CAM容量，实现了高空间效率和低精度损失。", "motivation": "尽管深度学习在非结构化数据方面表现出色，但现代树形集成模型在处理结构化数据集方面仍具有优势。然而，现有加速树形模型的方法面临挑战，尤其是利用内容可寻址存储器（CAM）的方案存在内存消耗过大和利用率低的问题。", "method": "本文提出了RETENTION框架，旨在显著降低树形模型推理对CAM容量的需求。该框架包括：1. 一种针对bagging-based模型（如随机森林）的迭代剪枝算法，该算法采用新颖的剪枝标准，以最小化模型复杂性并确保可控的精度下降。2. 一种树映射方案，该方案结合了两种创新的数据放置策略，以减轻CAM中广泛使用“不关心”状态导致的内存冗余。", "result": "实验结果表明，仅实施树映射方案即可实现1.46倍至21.30倍的空间效率提升；而完整的RETENTION框架则可实现4.35倍至207.12倍的改进，且精度损失小于3%。", "conclusion": "RETENTION在降低CAM容量需求方面非常有效，为树形模型加速提供了一个资源高效的方向。", "translation": "尽管深度学习在从非结构化数据中学习方面表现出卓越的能力，但现代树形集成模型在提取相关信息和从结构化数据集中学习方面仍然更胜一筹。虽然已经做出了一些努力来加速树形模型，但模型固有的特性给传统加速器带来了重大挑战。最近利用内容可寻址存储器（CAM）的研究为加速树形模型提供了一个有前景的解决方案，但现有设计存在内存消耗过大和利用率低的问题。这项工作通过引入RETENTION来解决这些挑战，RETENTION是一个端到端框架，显著降低了树形模型推理对CAM容量的需求。我们提出了一种迭代剪枝算法，该算法采用一种专为基于bagging的模型（例如随机森林）量身定制的新颖剪枝标准，从而在确保可控精度下降的同时最小化模型复杂性。此外，我们提出了一种树映射方案，该方案结合了两种创新的数据放置策略，以减轻CAM中广泛使用“不关心”状态导致的内存冗余。实验结果表明，仅实施树映射方案即可实现1.46倍至21.30倍的空间效率提升，而完整的RETENTION框架则可在精度损失小于3%的情况下实现4.35倍至207.12倍的改进。这些结果表明，RETENTION在降低CAM容量需求方面非常有效，为树形模型加速提供了一个资源高效的方向。", "summary": "本论文介绍了RETENTION，一个旨在加速树形集成模型推理并提高资源效率的端到端框架。针对现有基于内容可寻址存储器（CAM）的加速方案存在内存消耗大和利用率低的问题，RETENTION提出了一种迭代剪枝算法，该算法能有效降低模型复杂度并控制精度损失，同时还设计了一种创新的树映射方案，以减少CAM中的内存冗余。实验证明，RETENTION框架能显著提高空间效率（最高达207.12倍），且精度损失极小，为树形模型在CAM上的高效部署提供了可行方向。", "keywords": "树形集成模型, 内容可寻址存储器, 模型加速, 资源效率, 剪枝", "comments": "RETENTION的创新性在于将模型剪枝与针对CAM特性的树映射方案相结合，有效解决了CAM在加速树形模型时面临的内存效率瓶颈。这对于在资源受限的环境中部署高性能树形模型具有重要意义，提供了一种实用且高效的硬件加速路径。"}}
{"id": "2506.05355", "title": "Zero-Trust Mobility-Aware Authentication Framework for Secure Vehicular Fog Computing Networks", "authors": ["Taimoor Ahmad"], "summary": "Vehicular Fog Computing (VFC) is a promising paradigm to meet the low-latency\nand high-bandwidth demands of Intelligent Transportation Systems (ITS).\nHowever, dynamic vehicle mobility and diverse trust boundaries introduce\ncritical security challenges. This paper presents a novel Zero-Trust\nMobility-Aware Authentication Framework (ZTMAF) for secure communication in VFC\nnetworks. The framework employs context-aware authentication with lightweight\ncryptographic primitives, a decentralized trust evaluation system, and fog\nnode-assisted session validation to combat spoofing, replay, and impersonation\nattacks. Simulation results on NS-3 and SUMO demonstrate improved\nauthentication latency, reduced computational overhead, and better scalability\ncompared to traditional PKI and blockchain-based models. Our findings suggest\nthat ZTMAF is effective for secure, real-time V2X interactions under\nadversarial and mobility-variant scenarios.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05355v1", "AI": {"title_translation": "零信任移动感知认证框架，用于安全的车载雾计算网络", "tldr": "针对车载雾计算（VFC）网络中的安全挑战，本文提出了一种零信任移动感知认证框架（ZTMAF），通过轻量级加密、去中心化信任评估和雾节点辅助会话验证，有效提升了认证性能和安全性。", "motivation": "车载雾计算（VFC）是智能交通系统（ITS）中满足低延迟和高带宽需求的一种有前景的范式。然而，动态的车辆移动性和多样的信任边界引入了关键的安全挑战。", "method": "本文提出了一种新颖的零信任移动感知认证框架（ZTMAF），用于VFC网络中的安全通信。该框架采用上下文感知认证与轻量级加密原语、去中心化信任评估系统以及雾节点辅助会话验证，以对抗欺骗、重放和冒充攻击。研究通过NS-3和SUMO进行仿真。", "result": "仿真结果表明，与传统的PKI和基于区块链的模型相比，ZTMAF在认证延迟、计算开销和可伸缩性方面均有所改善。", "conclusion": "研究结果表明，ZTMAF在对抗性和移动多变场景下，对于安全的实时V2X交互是有效的。", "translation": "车载雾计算（VFC）是一种很有前景的范式，旨在满足智能交通系统（ITS）对低延迟和高带宽的需求。然而，动态的车辆移动性和多样的信任边界带来了关键的安全挑战。本文提出了一种新颖的零信任移动感知认证框架（ZTMAF），用于VFC网络中的安全通信。该框架采用上下文感知认证与轻量级加密原语、去中心化信任评估系统以及雾节点辅助会话验证，以对抗欺骗、重放和冒充攻击。在NS-3和SUMO上的仿真结果表明，与传统的PKI和基于区块链的模型相比，该框架在认证延迟、计算开销和可伸缩性方面均有所改善。我们的研究结果表明，ZTMAF在对抗性和移动多变场景下，对于安全的实时V2X交互是有效的。", "summary": "本文提出了一种名为ZTMAF的零信任移动感知认证框架，旨在解决车载雾计算（VFC）网络中因车辆移动性和信任边界多样性带来的安全问题。该框架结合了上下文感知认证、轻量级加密、去中心化信任评估和雾节点辅助会话验证，有效防御了多种网络攻击。仿真结果表明，ZTMAF在认证延迟、计算开销和可伸缩性方面优于现有方案，证明了其在复杂V2X环境下的安全性和实时性。", "keywords": "车载雾计算, 零信任, 移动感知, 认证框架, V2X通信", "comments": "该论文提出了一种创新的零信任方法来解决VFC中的移动性和信任边界安全问题，通过结合多种技术手段，有效提升了车载通信的安全性。其轻量级加密和去中心化信任评估的设计有助于在资源受限的车载环境中实现高效认证。仿真结果也验证了其性能优势，对于未来安全V2X通信具有重要的参考价值。"}}
{"id": "2506.05356", "title": "AI-Driven Dynamic Firewall Optimization Using Reinforcement Learning for Anomaly Detection and Prevention", "authors": ["Taimoor Ahmad"], "summary": "The growing complexity of cyber threats has rendered static firewalls\nincreasingly ineffective for dynamic, real-time intrusion prevention. This\npaper proposes a novel AI-driven dynamic firewall optimization framework that\nleverages deep reinforcement learning (DRL) to autonomously adapt and update\nfirewall rules in response to evolving network threats. Our system employs a\nMarkov Decision Process (MDP) formulation, where the RL agent observes network\nstates, detects anomalies using a hybrid LSTM-CNN model, and dynamically\nmodifies firewall configurations to mitigate risks. We train and evaluate our\nframework on the NSL-KDD and CIC-IDS2017 datasets using a simulated\nsoftware-defined network environment. Results demonstrate significant\nimprovements in detection accuracy, false positive reduction, and rule update\nlatency when compared to traditional signature- and behavior-based firewalls.\nThe proposed method provides a scalable, autonomous solution for enhancing\nnetwork resilience against complex attack vectors in both enterprise and\ncritical infrastructure settings.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05356v1", "AI": {"title_translation": "基于强化学习的AI驱动动态防火墙优化，用于异常检测和预防", "tldr": "本文提出了一种AI驱动的动态防火墙优化框架，利用深度强化学习自动调整防火墙规则，以应对不断演变的网络威胁，并在检测准确性、误报率和规则更新延迟方面优于传统防火墙。", "motivation": "日益复杂的网络威胁使得静态防火墙在动态、实时入侵防御方面越来越无效。", "method": "本文提出了一个新颖的AI驱动动态防火墙优化框架，该框架利用深度强化学习（DRL）来自主适应和更新防火墙规则。该系统采用马尔可夫决策过程（MDP）公式，其中RL代理观察网络状态，使用混合LSTM-CNN模型检测异常，并动态修改防火墙配置以降低风险。该框架在NSL-KDD和CIC-IDS2017数据集上，使用模拟软件定义网络环境进行了训练和评估。", "result": "结果表明，与传统的基于签名和基于行为的防火墙相比，在检测准确性、误报减少和规则更新延迟方面有显著改进。", "conclusion": "所提出的方法提供了一种可扩展、自主的解决方案，用于增强企业和关键基础设施设置中网络对复杂攻击向量的弹性。", "translation": "网络威胁日益复杂，使得静态防火墙在动态、实时入侵防御方面越来越无效。本文提出了一种新颖的AI驱动动态防火墙优化框架，该框架利用深度强化学习（DRL）来自主适应和更新防火墙规则，以应对不断演变的网络威胁。我们的系统采用马尔可夫决策过程（MDP）公式，其中RL代理观察网络状态，使用混合LSTM-CNN模型检测异常，并动态修改防火墙配置以降低风险。我们在NSL-KDD和CIC-IDS2017数据集上，使用模拟软件定义网络环境对我们的框架进行了训练和评估。结果表明，与传统的基于签名和基于行为的防火墙相比，在检测准确性、误报减少和规则更新延迟方面有显著改进。所提出的方法提供了一种可扩展、自主的解决方案，用于增强企业和关键基础设施设置中网络对复杂攻击向量的弹性。", "summary": "本文提出了一种基于深度强化学习的AI驱动动态防火墙优化框架，旨在解决静态防火墙在应对复杂网络威胁时的局限性。该框架利用马尔可夫决策过程，通过RL代理观察网络状态并结合LSTM-CNN模型检测异常，从而自主地适应和更新防火墙规则。在NSL-KDD和CIC-IDS2017数据集上的模拟评估显示，该方法在提高检测准确性、减少误报和缩短规则更新延迟方面显著优于传统防火墙，为增强网络弹性提供了一个可扩展的自主解决方案。", "keywords": "AI驱动防火墙, 强化学习, 异常检测, 网络安全, 动态防火墙", "comments": "这项研究的创新之处在于将深度强化学习应用于防火墙规则的动态优化，使其能够自主适应不断变化的网络威胁。其重要性在于提供了一种可扩展的、实时的网络安全解决方案，显著提高了异常检测的准确性并降低了误报率，对于企业和关键基础设施的网络弹性具有重要意义。"}}
{"id": "2506.05374", "title": "A New Representation of Binary Sequences by means of Boolean Functions", "authors": ["S. D. Cardell", "A. Fuúter-Sabater", "V. Requena", "M. Beltrá"], "summary": "Boolean functions and binary sequences are main tools used in cryptography.\nIn this work, we introduce a new bijection between the set of Boolean functions\nand the set of binary sequences with period a power of two. We establish a\nconnection between them which allows us to study some properties of Boolean\nfunctions through binary sequences and vice versa. Then, we define a new\nrepresentation of sequences, based on Boolean functions and derived from the\nalgebraic normal form, named reverse-ANF. Next, we study the relation between\nsuch a representation and other representations of Boolean functions as well as\nbetween such a representation and the binary sequences. Finally, we analyse the\ngeneralized self-shrinking sequences in terms of Boolean functions and some of\ntheir properties using the different representations.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05374v1", "AI": {"title_translation": "二进制序列的一种布尔函数新表示法", "tldr": "论文介绍了一种布尔函数和二进制序列之间的新双射，并定义了基于布尔函数的reverse-ANF表示法，用于研究它们之间的关系和性质。", "motivation": "布尔函数和二进制序列是密码学中的主要工具，研究它们之间的关系和性质具有重要意义。", "method": "1. 引入布尔函数集与周期为2的幂的二进制序列集之间的新双射。2. 建立两者之间的联系，以便通过二进制序列研究布尔函数的性质，反之亦然。3. 定义一种新的序列表示法，称为reverse-ANF，它基于布尔函数并源自代数范式。4. 研究这种表示法与其他布尔函数表示法以及与二进制序列之间的关系。5. 利用布尔函数和不同的表示法分析广义自收缩序列及其性质。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "布尔函数和二进制序列是密码学中使用的主要工具。在这项工作中，我们引入了布尔函数集与周期为2的幂的二进制序列集之间的一种新双射。我们建立了它们之间的联系，这使我们能够通过二进制序列研究布尔函数的某些性质，反之亦然。然后，我们定义了一种新的序列表示法，基于布尔函数并源自代数范式，名为reverse-ANF。接下来，我们研究了这种表示法与布尔函数的其他表示法之间的关系，以及这种表示法与二进制序列之间的关系。最后，我们利用布尔函数和不同的表示法分析了广义自收缩序列及其某些性质。", "summary": "本文提出了一种布尔函数与周期为2的幂的二进制序列之间的新双射，建立了它们之间的联系，从而可以通过相互转换来研究它们的性质。文中还定义了一种基于布尔函数且源自代数范式的新序列表示法，名为reverse-ANF，并研究了其与其他布尔函数表示法及二进制序列的关系。最后，论文利用布尔函数和所提出的不同表示法分析了广义自收缩序列的性质。", "keywords": "布尔函数, 二进制序列, 双射, reverse-ANF, 密码学", "comments": "这项工作通过引入布尔函数与二进制序列之间的新双射和reverse-ANF表示法，为研究这两者之间的关系提供了新的视角和工具，可能对密码学等领域的基础理论研究有所贡献。"}}
{"id": "2506.05437", "title": "A MARL-based Approach for Easing MAS Organization Engineering", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/pdf/2506.05437v1", "AI": {"title_translation": "基于MARL的MAS组织工程简化方法", "tldr": "本文提出了一种基于多智能体强化学习（MARL）的方法，用于简化多智能体系统（MAS）的组织工程，以解决现有方法在复杂部署环境中成本高、可读性差的问题。", "motivation": "多智能体系统（MAS）的组织设计效率受部署环境影响，现有方法依赖设计者知识，但在复杂或低可读性环境中应用成本高昂或存在安全隐患。因此，需要一种方法来简化MAS组织设计。", "method": "本文提出了一种名为辅助MAS组织工程方法（AOMEA）的原创方法。AOMEA结合了多智能体强化学习（MARL）过程与组织模型，以建议相关的组织规范，从而辅助MAS工程。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "多智能体系统（MAS）因其解决复杂分布式问题的能力，尤其是在基于物联网的系统中，已成功应用于工业领域。它们在实现既定目标和满足设计要求方面的效率，在特定应用MAS的工程过程中，强烈依赖于MAS的组织。为了设计一个能够实现既定目标的MAS，现有方法依赖于设计者对部署环境的了解。然而，某些部署环境的高度复杂性和低可读性使得这些方法的应用成本高昂或引发安全问题。为了缓解这些问题下的MAS组织设计，我们引入了一种原创的辅助MAS组织工程方法（AOMEA）。AOMEA依赖于将多智能体强化学习（MARL）过程与组织模型相结合，以建议相关的组织规范，从而辅助MAS工程。", "summary": "本文提出了一种名为辅助MAS组织工程方法（AOMEA）的新方法，旨在简化多智能体系统（MAS）的组织设计。针对现有方法在复杂部署环境中成本高和可读性差的问题，AOMEA通过结合多智能体强化学习（MARL）过程和组织模型，为MAS工程提供相关的组织规范建议。", "keywords": "多智能体系统, 组织工程, 强化学习, 智能体, IoT", "comments": "该论文提出了一种结合MARL和组织模型的新颖方法来解决MAS组织工程中的挑战，特别是针对复杂环境下的设计成本和安全问题。其创新点在于利用强化学习的自适应能力来辅助MAS的设计，有望提高效率并降低风险。"}}
{"id": "2506.05376", "title": "A Red Teaming Roadmap Towards System-Level Safety", "authors": ["Zifan Wang", "Christina Q. Knight", "Jeremy Kritz", "Willow E. Primack", "Julian Michael"], "summary": "Large Language Model (LLM) safeguards, which implement request refusals, have\nbecome a widely adopted mitigation strategy against misuse. At the intersection\nof adversarial machine learning and AI safety, safeguard red teaming has\neffectively identified critical vulnerabilities in state-of-the-art\nrefusal-trained LLMs. However, in our view the many conference submissions on\nLLM red teaming do not, in aggregate, prioritize the right research problems.\nFirst, testing against clear product safety specifications should take a higher\npriority than abstract social biases or ethical principles. Second, red teaming\nshould prioritize realistic threat models that represent the expanding risk\nlandscape and what real attackers might do. Finally, we contend that\nsystem-level safety is a necessary step to move red teaming research forward,\nas AI models present new threats as well as affordances for threat mitigation\n(e.g., detection and banning of malicious users) once placed in a deployment\ncontext. Adopting these priorities will be necessary in order for red teaming\nresearch to adequately address the slate of new threats that rapid AI advances\npresent today and will present in the very near future.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05376v1", "AI": {"title_translation": "迈向系统级安全的红队路线图", "tldr": "当前LLM红队测试需将重点转向产品安全、真实威胁和系统级安全，以应对AI快速发展带来的新威胁。", "motivation": "作者认为当前大型语言模型（LLM）的红队研究未能优先考虑正确的问题，特别是在明确的产品安全规范、真实的威胁模型和系统级安全方面缺乏关注。", "method": "该论文提出了一份红队研究路线图，优先考虑：1）针对明确的产品安全规范进行测试；2）关注真实的威胁模型；3）转向系统级安全。", "result": "该论文提出了一套修订后的大型语言模型红队测试优先级，认为采纳这些优先级对于充分应对人工智能快速发展带来的新威胁是必要的。", "conclusion": "采纳所提出的优先级（产品安全、真实威胁模型和系统级安全）对于红队研究有效应对当前和未来与人工智能相关的威胁至关重要。", "translation": "大型语言模型（LLM）的安全防护措施，即实施请求拒绝，已成为一种广泛采用的防滥用缓解策略。在对抗性机器学习和人工智能安全的交叉领域，安全防护红队测试已有效识别出最先进的经过拒绝训练的LLM中的关键漏洞。然而，在我们看来，许多关于LLM红队测试的会议投稿，总体而言，并未优先考虑正确的研究问题。首先，针对明确的产品安全规范进行测试应比抽象的社会偏见或道德原则具有更高的优先级。其次，红队测试应优先考虑代表不断扩展的风险格局和真实攻击者可能行为的现实威胁模型。最后，我们认为系统级安全是推动红队研究向前发展的必要一步，因为人工智能模型一旦部署，既会带来新的威胁，也会提供威胁缓解的能力（例如，检测和禁止恶意用户）。采纳这些优先级对于红队研究充分应对当前和在不久的将来人工智能快速发展所带来的新威胁是必要的。", "summary": "该论文认为当前大型语言模型（LLM）的红队研究存在错位，并提出了一份新的路线图。这份路线图强调优先考虑产品安全规范而非抽象原则，侧重于现实威胁模型，并推进系统级安全。采纳这些优先级对于红队有效应对人工智能快速发展带来的新兴威胁至关重要。", "keywords": "LLM红队测试, 人工智能安全, 系统级安全, 威胁模型, 产品安全", "comments": "这篇论文意义重大，因为它批判性地评估了当前大型语言模型红队测试的现状，并提出了一份实用且具有前瞻性的路线图。它对系统级安全和现实威胁模型的强调突出了人工智能安全研究中亟需的关键转变，即从孤立的模型测试转向考虑更广泛的部署环境。"}}
{"id": "2506.05527", "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/pdf/2506.05527v1", "AI": {"title_translation": "N智能体特设团队的序列建模", "tldr": "本文针对N智能体特设团队（NAHT）问题，提出了一种基于Transformer的集中式方法，通过捕获智能体间动态，显著优于现有方法，提升了样本效率和泛化能力。", "motivation": "多智能体强化学习中的N智能体特设团队（NAHT）是一个新挑战，现有学习算法（POAM）仅考虑独立学习，未能充分捕捉智能体间的动态，而这对于有效协作至关重要。", "method": "本文引入了一种基于Transformer的集中式方法，该方法利用Transformer处理变长序列的能力，并整合了所有受控智能体的历史观察和动作，以在部分可观察环境中对多样化和未知队友做出最优响应。", "result": "在StarCraft II任务上的实证评估表明，MAT-NAHT（所提出的方法）优于POAM，在没有辅助智能体建模目标的情况下，实现了卓越的样本效率和泛化能力。", "conclusion": "基于Transformer的集中式方法能够有效处理N智能体特设团队问题，通过充分捕获智能体间的动态，显著提升了性能、样本效率和泛化能力。", "translation": "N智能体特设团队（NAHT）是多智能体强化学习中新引入的挑战，其中不同规模的受控子团队必须在没有预先协调的情况下，与数量和类型各异的未知队友动态协作。现有学习算法（POAM）仅考虑独立学习，以应对智能体数量变化的灵活性。然而，独立学习未能充分捕捉对于有效协作至关重要的智能体间动态。基于我们对Transformer能够有效处理变长序列并已在各种机器学习问题中被证明高效的观察，本研究引入了一种基于Transformer的集中式N智能体特设团队方法。我们提出的方法整合了所有受控智能体的历史观察和动作，从而能够在部分可观察环境中对多样化和未知队友做出最优响应。在StarCraft II任务上的实证评估表明，MAT-NAHT 优于 POAM，在没有辅助智能体建模目标的情况下，实现了卓越的样本效率和泛化能力。", "summary": "本文针对多智能体强化学习中N智能体特设团队（NAHT）的挑战，指出现有独立学习方法无法有效捕捉智能体间动态。受Transformer处理变长序列能力的启发，本文提出了一种基于Transformer的集中式方法（MAT-NAHT），该方法整合了所有受控智能体的历史观察和动作。实验证明，在StarCraft II任务中，MAT-NAHT 在样本效率和泛化能力上均优于现有POAM算法。", "keywords": "N智能体特设团队, Transformer, 多智能体强化学习, 序列建模, 星际争霸II", "comments": "该研究通过引入Transformer模型来解决N智能体特设团队中智能体间动态捕捉的挑战，其集中式方法和对历史信息的有效利用是创新点。该方法在没有辅助智能体建模目标的情况下，在样本效率和泛化能力上展现出显著优势，对多智能体强化学习领域特别是动态协作场景具有重要意义。"}}
{"id": "2506.05516", "title": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots", "authors": ["Boyuan Deng", "Luca Rossini", "Jin Wang", "Weijie Wang", "Nikolaos Tsagarakis"], "summary": "Adaptive recovery from fall incidents are essential skills for the practical\ndeployment of wheeled-legged robots, which uniquely combine the agility of legs\nwith the speed of wheels for rapid recovery. However, traditional methods\nrelying on preplanned recovery motions, simplified dynamics or sparse rewards\noften fail to produce robust recovery policies. This paper presents a\nlearning-based framework integrating Episode-based Dynamic Reward Shaping and\ncurriculum learning, which dynamically balances exploration of diverse recovery\nmaneuvers with precise posture refinement. An asymmetric actor-critic\narchitecture accelerates training by leveraging privileged information in\nsimulation, while noise-injected observations enhance robustness against\nuncertainties. We further demonstrate that synergistic wheel-leg coordination\nreduces joint torque consumption by 15.8% and 26.2% and improves stabilization\nthrough energy transfer mechanisms. Extensive evaluations on two distinct\nquadruped platforms achieve recovery success rates up to 99.1% and 97.8%\nwithout platform-specific tuning. The supplementary material is available at\nhttps://boyuandeng.github.io/L2R-WheelLegCoordination/", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05516v1", "AI": {"title_translation": "学习恢复：面向摔倒机器人的轮腿协调动态奖励塑形", "tldr": "本文提出一个基于学习的框架，结合动态奖励塑形和课程学习，使轮腿机器人在摔倒后能高效、鲁棒地恢复，并通过轮腿协调显著降低能耗并提高稳定性，成功率高达99.1%。", "motivation": "轮腿机器人在实际部署中，从摔倒事故中自适应恢复是必不可少的技能。然而，传统方法依赖预先规划的恢复动作、简化的动力学或稀疏奖励，往往无法产生鲁棒的恢复策略。", "method": "本文提出一个基于学习的框架，整合了基于回合的动态奖励塑形和课程学习，动态平衡了多样化恢复动作的探索与精确姿态调整。采用非对称Actor-Critic架构，利用仿真中的特权信息加速训练。通过注入噪声的观测增强了对不确定性的鲁棒性。研究进一步展示了协同轮腿协调机制。", "result": "协同轮腿协调将关节扭矩消耗分别降低了15.8%和26.2%，并通过能量传递机制提高了稳定性。在两个不同的四足机器人平台上进行了广泛评估，恢复成功率分别达到99.1%和97.8%，且无需针对特定平台进行调整。", "conclusion": "本文提出的学习框架，结合动态奖励塑形和轮腿协调，显著提高了轮腿机器人在摔倒后的恢复能力和效率，展现出优异的泛化性和鲁棒性。", "translation": "学习恢复：面向摔倒机器人的轮腿协调动态奖励塑形\n\n从摔倒事故中自适应恢复是轮腿机器人实际部署的必备技能，它独特地结合了腿的敏捷性和轮子的速度以实现快速恢复。然而，依赖预先规划的恢复动作、简化动力学或稀疏奖励的传统方法往往无法产生鲁棒的恢复策略。本文提出了一个基于学习的框架，整合了基于回合的动态奖励塑形和课程学习，动态平衡了多样化恢复动作的探索与精确姿态调整。非对称的Actor-Critic架构通过利用仿真中的特权信息加速训练，同时注入噪声的观测增强了对不确定性的鲁棒性。我们进一步证明，协同的轮腿协调将关节扭矩消耗分别降低了15.8%和26.2%，并通过能量传递机制提高了稳定性。在两个不同的四足机器人平台上进行的广泛评估实现了高达99.1%和97.8%的恢复成功率，且无需针对特定平台进行调整。补充材料可在https://boyuandeng.github.io/L2R-WheelLegCoordination/ 获取。", "summary": "本文提出了一个针对摔倒轮腿机器人恢复的基于学习的框架。该框架结合了基于回合的动态奖励塑形和课程学习，以实现探索与姿态调整的动态平衡。通过非对称Actor-Critic架构和噪声注入观测，提高了训练效率和鲁棒性。研究还发现，协同的轮腿协调能显著降低关节扭矩消耗并增强稳定性。实验结果表明，在不同平台上恢复成功率高，且无需特定调整。", "keywords": "轮腿机器人, 动态奖励塑形, 课程学习, 机器人恢复, 轮腿协调", "comments": "该论文的创新点在于结合了动态奖励塑形和课程学习来解决轮腿机器人摔倒恢复的挑战，并通过非对称Actor-Critic架构和噪声注入观测提高了学习效率和策略鲁棒性。特别值得注意的是，它强调了轮腿协调在节能和稳定方面的优势，并在多个平台上验证了其泛化能力，对机器人实际应用具有重要意义。"}}
{"id": "2506.05370", "title": "Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems", "authors": ["Kristy Wedel"], "summary": "A critical challenge remains unresolved as generative AI systems are quickly\nimplemented in various organizational settings. Despite significant advances in\nmemory components such as RAG, vector stores, and LLM agents, these systems\nstill have substantial memory limitations. Gen AI workflows rarely store or\nreflect on the full context in which decisions are made. This leads to repeated\nerrors and a general lack of clarity. This paper introduces Contextual Memory\nIntelligence (CMI) as a new foundational paradigm for building intelligent\nsystems. It repositions memory as an adaptive infrastructure necessary for\nlongitudinal coherence, explainability, and responsible decision-making rather\nthan passive data. Drawing on cognitive science, organizational theory,\nhuman-computer interaction, and AI governance, CMI formalizes the structured\ncapture, inference, and regeneration of context as a fundamental system\ncapability. The Insight Layer is presented in this paper to operationalize this\nvision. This modular architecture uses human-in-the-loop reflection, drift\ndetection, and rationale preservation to incorporate contextual memory into\nsystems. The paper argues that CMI allows systems to reason with data, history,\njudgment, and changing context, thereby addressing a foundational blind spot in\ncurrent AI architectures and governance efforts. A framework for creating\nintelligent systems that are effective, reflective, auditable, and socially\nresponsible is presented through CMI. This enhances human-AI collaboration,\ngenerative AI design, and the resilience of the institutions.", "comment": "32 pages, 9 tables, 1 figure", "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05370v1", "AI": {"title_translation": "情境记忆智能——人机协作和反思性生成式AI系统的基础范式", "tldr": "本文提出情境记忆智能（CMI）作为一种新的基础范式，旨在解决当前生成式AI系统在记忆方面的局限性，通过结构化捕获、推断和再生上下文来增强系统能力，实现更有效的反思、可审计和负责任的AI系统。", "motivation": "尽管RAG、向量存储和LLM代理等记忆组件取得了显著进展，但生成式AI系统仍存在严重的记忆局限性，工作流很少存储或反思决策的完整上下文，导致重复错误和缺乏清晰度。", "method": "本文引入情境记忆智能（CMI）作为构建智能系统的新基础范式。CMI将记忆重新定位为纵向一致性、可解释性和负责任决策所需的自适应基础设施。它借鉴认知科学、组织理论、人机交互和AI治理，将上下文的结构化捕获、推断和再生形式化为一种基本系统能力。论文还提出了“洞察层”（Insight Layer）来操作化这一愿景，该模块化架构利用人机循环反思、漂移检测和理由保留来将情境记忆整合到系统中。", "result": "CMI使系统能够利用数据、历史、判断和不断变化的上下文进行推理，从而解决了当前AI架构和治理工作中的一个基础盲点。通过CMI，本文提出了一个用于创建有效、反思、可审计和社会负责任的智能系统的框架。", "conclusion": "本文认为情境记忆智能（CMI）允许系统利用数据、历史、判断和不断变化的上下文进行推理，从而解决了当前AI架构和治理工作中的一个基础盲点。CMI提出了一个用于创建有效、反思、可审计和社会负责任的智能系统的框架，这将增强人机协作、生成式AI设计以及机构的韧性。", "translation": "生成式AI系统在各种组织环境中迅速实施，但一个关键挑战仍未解决。尽管RAG、向量存储和LLM代理等记忆组件取得了显著进展，但这些系统仍然存在严重的记忆局限性。生成式AI工作流很少存储或反思决策的完整上下文。这导致重复错误和普遍缺乏清晰度。本文引入情境记忆智能（CMI）作为构建智能系统的新基础范式。它将记忆重新定位为纵向一致性、可解释性和负责任决策所需的自适应基础设施，而不仅仅是被动数据。CMI借鉴认知科学、组织理论、人机交互和AI治理，将上下文的结构化捕获、推断和再生形式化为一种基本系统能力。本文提出了“洞察层”来操作化这一愿景。这种模块化架构利用人机循环反思、漂移检测和理由保留来将情境记忆整合到系统中。本文认为CMI允许系统利用数据、历史、判断和不断变化的上下文进行推理，从而解决了当前AI架构和治理工作中的一个基础盲点。通过CMI，本文提出了一个用于创建有效、反思、可审计和社会负责任的智能系统的框架。这将增强人机协作、生成式AI设计以及机构的韧性。", "summary": "本文提出“情境记忆智能”（CMI）作为一种新的基础范式，旨在解决当前生成式AI系统在记忆和上下文理解方面的显著局限性。通过将记忆视为一种自适应基础设施，CMI强调结构化捕获、推断和再生上下文的重要性。论文引入了“洞察层”这一模块化架构，通过人机循环反思、漂移检测和理由保留来操作化CMI。CMI使AI系统能够更好地利用数据、历史、判断和动态上下文进行推理，从而提升人机协作、生成式AI设计，并构建更具反思性、可审计性和社会责任感的智能系统。", "keywords": "情境记忆智能, 生成式AI, 人机协作, 上下文理解, 洞察层", "comments": "该论文提出了一个重要的概念，即情境记忆智能（CMI），它超越了传统记忆组件的局限性，将记忆视为一种主动的、自适应的基础设施。其创新之处在于将认知科学、组织理论和AI治理等多学科知识整合，并提出了“洞察层”这一具体操作框架。这对于提升生成式AI系统的长期一致性、可解释性和负责任的决策能力具有重要意义，尤其是在强调人机协作和AI伦理的背景下，该范式有望解决当前AI应用中的核心痛点。"}}
{"id": "2506.05358", "title": "Can ChatGPT Perform Image Splicing Detection? A Preliminary Study", "authors": ["Souradip Nath"], "summary": "Multimodal Large Language Models (MLLMs) like GPT-4V are capable of reasoning\nacross text and image modalities, showing promise in a variety of complex\nvision-language tasks. In this preliminary study, we investigate the\nout-of-the-box capabilities of GPT-4V in the domain of image forensics,\nspecifically, in detecting image splicing manipulations. Without any\ntask-specific fine-tuning, we evaluate GPT-4V using three prompting strategies:\nZero-Shot (ZS), Few-Shot (FS), and Chain-of-Thought (CoT), applied over a\ncurated subset of the CASIA v2.0 splicing dataset.\n  Our results show that GPT-4V achieves competitive detection performance in\nzero-shot settings (more than 85% accuracy), with CoT prompting yielding the\nmost balanced trade-off across authentic and spliced images. Qualitative\nanalysis further reveals that the model not only detects low-level visual\nartifacts but also draws upon real-world contextual knowledge such as object\nscale, semantic consistency, and architectural facts, to identify implausible\ncomposites. While GPT-4V lags behind specialized state-of-the-art splicing\ndetection models, its generalizability, interpretability, and encyclopedic\nreasoning highlight its potential as a flexible tool in image forensics.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05358v1", "AI": {"title_translation": "ChatGPT能进行图像拼接检测吗？一项初步研究", "tldr": "本研究探讨了GPT-4V在未经特定任务微调的情况下，在图像拼接检测方面的即用能力，结果显示其在零样本设置下表现良好（超过85%准确率），并能利用上下文知识进行推理，显示出其在图像取证领域的潜力。", "motivation": "探索多模态大型语言模型（MLLMs）如GPT-4V在图像取证领域，特别是图像拼接检测方面的即用能力，且不进行任何任务特定的微调。", "method": "研究者评估了GPT-4V在CASIA v2.0拼接数据集的精选子集上的性能。评估采用了三种提示策略：零样本（ZS）、少样本（FS）和思维链（CoT）。", "result": "GPT-4V在零样本设置下取得了有竞争力的检测性能（超过85%的准确率）。思维链提示在真实图像和拼接图像之间取得了最平衡的权衡。定性分析表明模型不仅能检测低级视觉伪影，还能利用现实世界上下文知识（如物体比例、语义一致性和建筑事实）来识别不合理的合成图像。", "conclusion": "尽管GPT-4V的性能落后于专门的SOTA拼接检测模型，但其泛化性、可解释性和百科全书式推理能力突显了其作为图像取证领域灵活工具的潜力。", "translation": "多模态大型语言模型（MLLMs）如GPT-4V能够跨文本和图像模态进行推理，在各种复杂的视觉-语言任务中显示出前景。在这项初步研究中，我们调查了GPT-4V在图像取证领域，特别是检测图像拼接篡改方面的即用能力。在没有任何任务特定微调的情况下，我们使用三种提示策略：零样本（ZS）、少样本（FS）和思维链（CoT），对GPT-4V进行了评估，这些策略应用于CASIA v2.0拼接数据集的精选子集。\\n我们的结果显示，GPT-4V在零样本设置下取得了有竞争力的检测性能（超过85%的准确率），其中思维链提示在真实图像和拼接图像之间取得了最平衡的权衡。定性分析进一步揭示，该模型不仅能检测低级视觉伪影，还能利用现实世界上下文知识，如物体比例、语义一致性和建筑事实，来识别不合理的合成图像。尽管GPT-4V落后于专门的最新拼接检测模型，但其泛化性、可解释性和百科全书式推理能力突显了其作为图像取证领域灵活工具的潜力。", "summary": "本初步研究评估了多模态大型语言模型GPT-4V在未经特定任务微调的情况下进行图像拼接检测的能力。研究者在CASIA v2.0数据集上，通过零样本、少样本和思维链三种提示策略对GPT-4V进行了测试。结果显示，GPT-4V在零样本设置下达到了超过85%的检测准确率，并且能利用低级视觉伪影和高级上下文知识进行推理。尽管其性能尚未达到专业级SOTA模型水平，但其展现出的泛化性、可解释性和推理能力表明其在图像取证领域具有重要的应用潜力。", "keywords": "图像拼接检测, GPT-4V, 多模态大型语言模型, 图像取证, 零样本学习", "comments": "这项研究的创新之处在于，它探索了将通用型多模态大型语言模型（GPT-4V）应用于特定图像取证任务（图像拼接检测）的潜力，且未进行任何微调。这展示了通用模型在特定领域出人意料的即用能力。模型不仅能识别视觉伪影，还能利用现实世界上下文知识进行推理，这尤其具有洞察力。尽管其性能尚未超越最先进的专业模型，但其泛化性和可解释性是显著的优势，预示着未来在图像取证领域作为灵活工具的广阔前景。"}}
{"id": "2506.05364", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "authors": ["Anjana Sarkar", "Soumyendu Sarkar"], "summary": "This survey investigates how classical software design patterns can enhance\nthe reliability and scalability of communication in Large Language Model\n(LLM)-driven agentic AI systems, focusing particularly on the Model Context\nProtocol (MCP). It examines the foundational architectures of LLM-based agents\nand their evolution from isolated operation to sophisticated, multi-agent\ncollaboration, addressing key communication hurdles that arise in this\ntransition. The study revisits well-established patterns, including Mediator,\nObserver, Publish-Subscribe, and Broker, and analyzes their relevance in\nstructuring agent interactions within MCP-compliant frameworks. To clarify\nthese dynamics, the article provides conceptual schematics and formal models\nthat map out communication pathways and optimize data flow. It further explores\narchitectural variations suited to different degrees of agent autonomy and\nsystem complexity. Real-world applications in domains such as real-time\nfinancial processing and investment banking are discussed, illustrating how\nthese patterns and MCP can meet specific operational demands. The article\nconcludes by outlining open challenges, potential security risks, and promising\ndirections for advancing robust, interoperable, and scalable multi-agent LLM\necosystems.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05364v1", "AI": {"title_translation": "LLM智能体与MCP通信综述：以软件设计模式为中心的视角", "tldr": "本综述探讨了经典软件设计模式如何通过模型上下文协议（MCP）增强大型语言模型（LLM）驱动的智能体AI系统中通信的可靠性和可扩展性，并分析了其在多智能体协作中的应用和未来挑战。", "motivation": "本研究旨在探讨经典软件设计模式如何增强大型语言模型（LLM）驱动的智能体AI系统中通信的可靠性和可扩展性，特别关注模型上下文协议（MCP），以解决多智能体协作中出现的关键通信障碍。", "method": "本研究审查了基于LLM的智能体的基础架构及其从独立操作到复杂多智能体协作的演变。它重新审视了包括中介者、观察者、发布-订阅和代理在内的成熟设计模式，并分析了它们在符合MCP的框架中构建智能体交互的相关性。文章提供了概念示意图和形式模型以映射通信路径并优化数据流，并探讨了适用于不同智能体自主度和系统复杂度的架构变体。", "result": "研究结果表明，经典软件设计模式（如中介者、观察者、发布-订阅和代理）能够有效增强LLM驱动的智能体AI系统中通信的可靠性和可扩展性。文章提供了概念示意图和形式模型，并讨论了这些模式和MCP在实时金融处理和投资银行等领域的实际应用，展示了它们如何满足特定的操作需求。", "conclusion": "本研究总结了开放性挑战、潜在安全风险以及推进健壮、可互操作和可扩展的多智能体LLM生态系统的有前景方向。", "translation": "本综述调查了经典软件设计模式如何增强大型语言模型（LLM）驱动的智能体AI系统中通信的可靠性和可扩展性，特别关注模型上下文协议（MCP）。它审查了基于LLM的智能体的基础架构及其从独立操作到复杂多智能体协作的演变，解决了在此过渡中出现的关键通信障碍。本研究重新审视了成熟的模式，包括中介者、观察者、发布-订阅和代理，并分析了它们在符合MCP的框架中构建智能体交互的相关性。为了阐明这些动态，文章提供了概念示意图和形式模型，以映射通信路径并优化数据流。它进一步探讨了适用于不同智能体自主度和系统复杂度的架构变体。文中讨论了实时金融处理和投资银行等领域的实际应用，说明了这些模式和MCP如何满足特定的操作需求。文章最后概述了开放性挑战、潜在安全风险以及推进健壮、可互操作和可扩展的多智能体LLM生态系统的有前景方向。", "summary": "本综述深入探讨了经典软件设计模式如何通过模型上下文协议（MCP）提升大型语言模型（LLM）驱动的智能体AI系统中的通信可靠性和可扩展性。文章详细考察了LLM智能体从独立运行到复杂多智能体协作的演进过程，并分析了中介者、观察者、发布-订阅和代理等设计模式在构建符合MCP的智能体交互中的应用价值。为阐明这些动态，文中提供了概念示意图和形式模型，并探讨了适用于不同智能体自主度和系统复杂度的架构变体。此外，论文还讨论了这些模式和MCP在金融领域的实际应用，并展望了未来发展面临的挑战和机遇。", "keywords": "LLM智能体, 软件设计模式, 模型上下文协议, 多智能体系统, 通信可靠性", "comments": "这篇综述的创新之处在于将传统的软件设计模式与新兴的LLM智能体通信相结合，特别是聚焦于MCP，为构建更可靠、可扩展的多智能体系统提供了实用的指导和理论框架。其重要性体现在为解决LLM智能体协作中的通信难题提供了系统性的解决方案，并指出了未来研究的方向，具有较高的理论和实践价值。"}}
{"id": "2506.05486", "title": "The Artificial Benchmark for Community Detection with Outliers and Overlapping Communities (ABCD+$o^2$)", "authors": ["Jordan Barrett", "Ryan DeWolfe", "Bogumił Kamiński", "Paweł Prałat", "Aaron Smith", "François Théberge"], "summary": "The Artificial Benchmark for Community Detection (ABCD) graph is a random\ngraph model with community structure and power-law distribution for both\ndegrees and community sizes. The model generates graphs similar to the\nwell-known LFR model but it is faster, more interpretable, and can be\ninvestigated analytically. In this paper, we use the underlying ingredients of\nthe ABCD model, and its generalization to include outliers (ABCD+$o$), and\nintroduce another variant that allows for overlapping communities, ABCD+$o^2$.", "comment": "23 pages, 16 figures, 3 tables", "cate": "cs.SI", "url": "http://arxiv.org/pdf/2506.05486v1", "AI": {"title_translation": "具有异常值和重叠社区的社区检测人工基准 (ABCD+$o^2$)", "tldr": "引入了ABCD模型的一个新变体ABCD+$o^2$，用于社区检测，该模型包含异常值和重叠社区。", "motivation": "现有的ABCD模型及其包含异常值的变体ABCD+$o$需要进一步扩展以支持重叠社区，以提供更全面的社区检测基准。", "method": "本文利用ABCD模型及其包含异常值（ABCD+$o$）的泛化，引入了另一个允许重叠社区的变体，即ABCD+$o^2$。", "result": "引入了ABCD+$o^2$模型，该模型是一个用于社区检测的人工基准，支持异常值和重叠社区。", "conclusion": "ABCD+$o^2$模型被引入作为一种新的社区检测基准，能够处理异常值和重叠社区。", "translation": "人工社区检测基准（ABCD）图是一个具有社区结构和度数与社区大小均服从幂律分布的随机图模型。该模型生成的图与著名的LFR模型相似，但它更快、更具可解释性，并且可以进行分析研究。在本文中，我们利用ABCD模型及其包含异常值（ABCD+$o$）的泛化，并引入了另一个允许重叠社区的变体，即ABCD+$o^2$。", "summary": "本文介绍了ABCD+$o^2$，这是人工社区检测基准（ABCD）模型的一个新变体。ABCD模型是一个快速、可解释且可分析的随机图模型，用于生成具有社区结构和幂律分布的图。ABCD+$o^2$在ABCD+$o$（包含异常值）的基础上进一步扩展，加入了对重叠社区的支持，从而提供了一个更全面的社区检测基准。", "keywords": "社区检测, 人工基准, 异常值, 重叠社区, ABCD模型", "comments": "这篇论文的创新点在于扩展了现有的ABCD基准模型，使其能够处理社区检测中更复杂的现实场景，即存在异常值和重叠社区的情况。这将为评估社区检测算法提供一个更强大和灵活的工具。"}}
{"id": "2506.05352", "title": "A Path to Loving", "authors": ["John Beverley", "Regina Hurley"], "summary": "This work lays the foundations for a rigorous ontological characterization of\nlove, addressing its philosophical complexity and scientific relevance, with\nparticular emphasis on psychology and sociology, as well as highlighting ways\nin which such characterization enhances relevant AI based applications. The\nposition defended here is that love is best understood as a concatenation of\npassive sensations (e.g., emotional arousal) and active evaluative judgments\n(e.g., perceiving the beloved as valuable), in the interest of balancing the\ninvoluntary aspects of love with its rational accountability. To provide a\nstructured foundation, the paper draws on Basic Formal Ontology (BFO) and other\napplied ontological methods to differentiate various senses of love. This work\nengages with objections to the understanding of love as concatenation,\nparticularly concerning the relationship between sensation and judgment. A\ncausal correlation model is defended, ensuring that the affective and cognitive\ncomponents are linked. By offering a precise and scalable ontological account,\nthis work lays the foundation for future interdisciplinary applications, making\nlove a subject of formal inquiry in ontology engineering, artificial\nintelligence, and the sciences.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05352v1", "AI": {"title_translation": "爱的路径", "tldr": "本文为爱的本体论表征奠定了基础，将其理解为被动感觉和主动评价判断的结合，并利用本体论方法，旨在为未来的跨学科应用，特别是AI领域提供形式化探究。", "motivation": "本文旨在对爱进行严格的本体论表征，解决其哲学复杂性和科学相关性，并强调这种表征如何增强相关的人工智能应用。", "method": "本文利用基本形式本体论（BFO）和其他应用本体论方法来区分爱的各种意义。它将爱理解为被动感觉（如情感唤起）和主动评价判断（如将所爱之人视为有价值）的结合。同时，本文还捍卫了一种因果关联模型，以确保情感和认知成分的联系。", "result": "本文提出并捍卫了将爱理解为被动感觉和主动评价判断的结合的立场，并提出了一个因果关联模型来连接情感和认知成分。它为未来的跨学科应用奠定了基础，使爱成为本体论工程、人工智能和科学中形式化探究的主题。", "conclusion": "本文通过提供精确且可扩展的本体论描述，为未来的跨学科应用奠定了基础，使爱成为本体论工程、人工智能和科学中形式式化探究的主题。", "translation": "这项工作为爱的严格本体论表征奠定了基础，解决了其哲学复杂性和科学相关性，特别强调了心理学和社会学，并突出了这种表征如何增强相关的人工智能应用。本文所捍卫的立场是，爱最好被理解为被动感觉（例如，情感唤起）和主动评价判断（例如，将所爱之人视为有价值）的结合，旨在平衡爱的非自愿方面与其理性责任。为了提供一个结构化的基础，本文借鉴了基本形式本体论（BFO）和其他应用本体论方法来区分爱的各种意义。这项工作探讨了对将爱理解为连接的反对意见，特别是关于感觉和判断之间的关系。本文捍卫了一种因果关联模型，确保情感和认知成分是相互关联的。通过提供精确且可扩展的本体论描述，这项工作为未来的跨学科应用奠定了基础，使爱成为本体论工程、人工智能和科学中形式化探究的主题。", "summary": "本文旨在对爱进行严格的本体论表征，解决其哲学和科学复杂性。它将爱定义为被动感觉与主动评价判断的结合，并利用基本形式本体论（BFO）等方法来构建结构化基础。文章探讨了对此观点的异议，并提出了一种因果关联模型来连接情感和认知成分。最终，这项工作为爱在本体论工程、人工智能和科学领域的跨学科形式化研究奠定了基础。", "keywords": "爱, 本体论, 人工智能, 哲学, 心理学", "comments": "本文的创新之处在于将爱视为一个可以进行严格本体论分析的概念，并将其与AI应用联系起来。通过结合哲学、心理学、社会学和本体论方法，它为理解和形式化爱提供了一个新颖的视角。其重要性在于为未来在人工智能领域中更精确地模拟和应用爱提供了理论基础，可能推动情感智能和人机交互的发展。"}}
{"id": "2506.05779", "title": "Pegasus: A Universal Framework for Scalable Deep Learning Inference on the Dataplane", "authors": ["Yinchao Zhang", "Su Yao", "Yong Feng", "Kang Chen", "Tong Li", "Zhuotao Liu", "Yi Zhao", "Lexuan Zhang", "Xiangyu Gao", "Feng Xiong", "Qi Li", "Ke Xu"], "summary": "The paradigm of Intelligent DataPlane (IDP) embeds deep learning (DL) models\non the network dataplane to enable intelligent traffic analysis at line-speed.\nHowever, the current use of the match-action table (MAT) abstraction on the\ndataplane is misaligned with DL inference, leading to several key limitations,\nincluding accuracy degradation, limited scale, and lack of generality. This\npaper proposes Pegasus to address these limitations. Pegasus translates DL\noperations into three dataplane-oriented primitives to achieve generality:\nPartition, Map, and SumReduce. Specifically, Partition \"divides\"\nhigh-dimensional features into multiple low-dimensional vectors, making them\nmore suitable for the dataplane; Map \"conquers\" computations on the\nlow-dimensional vectors in parallel with the technique of fuzzy matching, while\nSumReduce \"combines\" the computation results. Additionally, Pegasus employs\nPrimitive Fusion to merge computations, improving scalability. Finally, Pegasus\nadopts full precision weights with fixed-point activations to improve accuracy.\nOur implementation on a P4 switch demonstrates that Pegasus can effectively\nsupport various types of DL models, including Multi-Layer Perceptron (MLP),\nRecurrent Neural Network (RNN), Convolutional Neural Network (CNN), and\nAutoEncoder models on the dataplane. Meanwhile, Pegasus outperforms\nstate-of-the-art approaches with an average accuracy improvement of up to\n22.8%, along with up to 248x larger model size and 212x larger input scale.", "comment": "to be published in Sigcomm 2025", "cate": "cs.NI", "url": "http://arxiv.org/pdf/2506.05779v1", "AI": {"title_translation": "Pegasus：一个用于数据平面可伸缩深度学习推理的通用框架", "tldr": "Pegasus通过引入数据平面友好原语解决了在网络数据平面上进行深度学习推理的精度、规模和通用性限制，显著提升了性能。", "motivation": "当前在数据平面上使用匹配-动作表（MAT）抽象进行深度学习推理与DL推理不兼容，导致准确性下降、规模受限和通用性不足。", "method": "Pegasus将深度学习操作转换为三种数据平面导向的原语：Partition（分割高维特征）、Map（并行计算低维向量）和SumReduce（组合计算结果）。此外，它采用Primitive Fusion合并计算以提高可伸缩性，并使用全精度权重和定点激活来提高准确性。", "result": "Pegasus能有效支持MLP, RNN, CNN, AutoEncoder等多种DL模型。与现有方法相比，平均准确率提高高达22.8%，模型大小增加248倍，输入规模增加212倍。", "conclusion": "Pegasus通过其创新的设计和实现，有效解决了在数据平面上进行深度学习推理的局限性，并显著提升了性能和通用性。", "translation": "智能数据平面（IDP）范式将深度学习（DL）模型嵌入网络数据平面，以实现线速智能流量分析。然而，当前在数据平面上使用匹配-动作表（MAT）抽象与DL推理不兼容，导致了几个关键限制，包括准确性下降、规模受限和通用性不足。本文提出了Pegasus来解决这些限制。Pegasus将DL操作转换为三种数据平面导向的原语以实现通用性：Partition、Map和SumReduce。具体来说，Partition“分割”高维特征为多个低维向量，使其更适合数据平面；Map通过模糊匹配技术并行“征服”低维向量上的计算，而SumReduce“组合”计算结果。此外，Pegasus采用Primitive Fusion来合并计算，提高可伸缩性。最后，Pegasus采用全精度权重和定点激活来提高准确性。我们在P4交换机上的实现表明，Pegasus可以有效支持数据平面上的各种类型的DL模型，包括多层感知器（MLP）、循环神经网络（RNN）、卷积神经网络（CNN）和自编码器模型。同时，Pegasus优于现有方法，平均准确率提高高达22.8%，模型大小增加高达248倍，输入规模增加高达212倍。", "summary": "本文提出Pegasus，一个通用的框架，旨在解决智能数据平面（IDP）中深度学习（DL）推理的现有局限，如准确性下降、规模受限和通用性不足。Pegasus通过将DL操作转换为Partition、Map和SumReduce三种数据平面导向的原语，并结合Primitive Fusion和混合精度（全精度权重、定点激活）技术，显著提高了在P4交换机上DL模型的性能，包括准确率、模型大小和输入规模，并支持多种DL模型类型。", "keywords": "深度学习推理, 数据平面, Pegasus, 可伸缩性, P4交换机", "comments": "Pegasus的创新之处在于其将复杂的深度学习操作分解为数据平面友好的基本原语，并引入了原始融合和混合精度策略，有效解决了在资源受限的网络数据平面上部署DL模型的挑战。其显著的性能提升和对多种模型类型的支持，表明其在智能数据平面领域具有重要意义。"}}
{"id": "2506.05496", "title": "Channel Estimation with Asynchronous Reception for User-Centric Cell-Free MIMO Systems", "authors": ["Xuyang Sun", "Hussein A. Ammar", "Raviraj Adve", "Israfil Bahceci", "Gary Boudreau"], "summary": "The user-centric, cell-free wireless network is a promising next-generation\ncommunication system, but signal synchronization issues arise due to\ndistributed access points and lack of cellular structure. We propose a novel\nmethod to recover synchronous pilot reception by introducing new pilot\nsequences and a matched filter window, enabling orthogonality even with\nasynchronous reception. Our approach mimics synchronous transmission by\nextending training sequences. Analysis shows asynchronous reception's impact on\nchannel estimation, and our method significantly improves performance with a\nsmall increase of training time overhead. Results demonstrate a 7.26 dB\nreduction in normalized mean square error and 40% increase in data rate,\nachieving performance levels comparable to the synchronous case.", "comment": "To be presented in IEEE International Conference on Communications\n  (IEEE ICC) 2025", "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.05496v1", "AI": {"title_translation": "用户中心无蜂窝MIMO系统中异步接收的信道估计", "tldr": "针对用户中心无蜂窝MIMO系统中的异步接收问题，提出了一种新的导频序列和匹配滤波器窗口方法，通过延长训练序列来恢复同步导频接收，显著提升了信道估计性能和数据速率，达到与同步情况相当的水平。", "motivation": "用户中心无蜂窝无线网络是一种很有前途的下一代通信系统，但由于分布式接入点和缺乏蜂窝结构，会产生信号同步问题。", "method": "提出了一种新方法，通过引入新的导频序列和匹配滤波器窗口来恢复同步导频接收，即使在异步接收下也能实现正交性。该方法通过延长训练序列来模拟同步传输。", "result": "分析表明异步接收对信道估计有影响，但所提出的方法显著改善了性能，只增加了少量训练时间开销。结果显示归一化均方误差降低了7.26 dB，数据速率提高了40%，性能可与同步情况媲美。", "conclusion": "所提出的方法能有效解决用户中心无蜂窝MIMO系统中的异步接收信道估计问题，显著提升性能，达到与同步系统相当的水平。", "translation": "用户中心、无蜂窝无线网络是一种很有前途的下一代通信系统，但由于分布式接入点和缺乏蜂窝结构，会产生信号同步问题。我们提出了一种新颖的方法，通过引入新的导频序列和匹配滤波器窗口来恢复同步导频接收，即使在异步接收下也能实现正交性。我们的方法通过延长训练序列来模拟同步传输。分析表明异步接收对信道估计有影响，我们的方法以少量训练时间开销的增加显著提高了性能。结果表明，归一化均方误差降低了7.26 dB，数据速率提高了40%，达到了与同步情况相当的性能水平。", "summary": "本文提出了一种针对用户中心无蜂窝MIMO系统中异步接收的信道估计方法。该方法通过引入新的导频序列和匹配滤波器窗口，并延长训练序列，有效解决了异步接收导致的同步问题，实现了即使在异步条件下也能正交接收导频。实验结果表明，该方法显著降低了信道估计误差，提高了数据速率，性能可与同步系统相媲美，且仅带来少量训练时间开销。", "keywords": "用户中心无蜂窝MIMO, 异步接收, 信道估计, 导频序列, 匹配滤波器", "comments": "这篇论文解决了无蜂窝MIMO系统中一个关键的实际问题：异步接收下的信道估计。其创新点在于通过设计新的导频序列和匹配滤波器窗口来“模拟”同步接收，从而在不牺牲太多开销的情况下显著提升系统性能。这项工作对于推动用户中心无蜂窝网络的实际部署具有重要意义。"}}
{"id": "2506.05426", "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "authors": ["Wenhao Wu", "Fuhong Liu", "Haoru Li", "Zican Hu", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "summary": "In-context reinforcement learning (ICRL) has emerged as a promising paradigm\nfor adapting RL agents to downstream tasks through prompt conditioning.\nHowever, two notable challenges remain in fully harnessing in-context learning\nwithin RL domains: the intrinsic multi-modality of the state-action-reward data\nand the diverse, heterogeneous nature of decision tasks. To tackle these\nchallenges, we propose \\textbf{T2MIR} (\\textbf{T}oken- and \\textbf{T}ask-wise\n\\textbf{M}oE for \\textbf{I}n-context \\textbf{R}L), an innovative framework that\nintroduces architectural advances of mixture-of-experts (MoE) into\ntransformer-based decision models. T2MIR substitutes the feedforward layer with\ntwo parallel layers: a token-wise MoE that captures distinct semantics of input\ntokens across multiple modalities, and a task-wise MoE that routes diverse\ntasks to specialized experts for managing a broad task distribution with\nalleviated gradient conflicts. To enhance task-wise routing, we introduce a\ncontrastive learning method that maximizes the mutual information between the\ntask and its router representation, enabling more precise capture of\ntask-relevant information. The outputs of two MoE components are concatenated\nand fed into the next layer. Comprehensive experiments show that T2MIR\nsignificantly facilitates in-context learning capacity and outperforms various\ntypes of baselines. We bring the potential and promise of MoE to ICRL, offering\na simple and scalable architectural enhancement to advance ICRL one step closer\ntoward achievements in language and vision communities. Our code is available\nat https://github.com/NJU-RL/T2MIR.", "comment": "26 pages, 13 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05426v1", "AI": {"title_translation": "专家混合模型与上下文强化学习的结合", "tldr": "本文提出了T2MIR框架，将专家混合模型（MoE）引入上下文强化学习（ICRL），以解决ICRL中的多模态数据和异构任务挑战，并通过实验证明其显著提升了上下文学习能力。", "motivation": "上下文强化学习（ICRL）在适应下游任务方面表现出潜力，但面临两大挑战：状态-动作-奖励数据的内在多模态性，以及决策任务的多样性和异构性。", "method": "本文提出了T2MIR（Token- and Task-wise MoE for In-context RL）框架。T2MIR将Transformer基础决策模型中的前馈层替换为两个并行的层：一个Token-wise MoE，用于捕获跨多模态输入Token的不同语义；一个Task-wise MoE，用于将多样化任务路由到专门的专家，以管理广泛的任务分布并缓解梯度冲突。为了增强任务路由，引入了一种对比学习方法，最大化任务与其路由器表示之间的互信息。两个MoE组件的输出被连接并输入到下一层。", "result": "综合实验表明，T2MIR显著提升了上下文学习能力，并优于各种基线模型。", "conclusion": "本文将专家混合模型（MoE）的潜力带入上下文强化学习（ICRL），提供了一种简单且可扩展的架构增强，使ICRL更接近语言和视觉领域所取得的成就。", "translation": "上下文强化学习（ICRL）已成为一种通过提示条件调整RL智能体以适应下游任务的有前景范式。然而，在RL领域中充分利用上下文学习仍存在两个显著挑战：状态-动作-奖励数据的内在多模态性以及决策任务的多样化异构性。为了解决这些挑战，我们提出了T2MIR（Token- and Task-wise MoE for In-context RL），这是一个创新框架，将专家混合模型（MoE）的架构进步引入基于Transformer的决策模型。T2MIR将前馈层替换为两个并行层：一个Token-wise MoE，捕获跨多个模态的输入Token的不同语义；一个Task-wise MoE，将多样化任务路由到专业专家，以管理广泛的任务分布并缓解梯度冲突。为了增强任务路由，我们引入了一种对比学习方法，最大化任务与其路由器表示之间的互信息，从而更精确地捕获任务相关信息。两个MoE组件的输出被连接并馈送到下一层。综合实验表明，T2MIR显著促进了上下文学习能力，并优于各种类型的基线。我们将MoE的潜力和前景带入ICRL，提供了一种简单且可扩展的架构增强，使ICRL向语言和视觉社区的成就迈进了一步。我们的代码可在https://github.com/NJU-RL/T2MIR获取。", "summary": "本文提出T2MIR框架，旨在通过引入专家混合模型（MoE）来提升上下文强化学习（ICRL）的能力。针对ICRL中多模态数据和异构任务的挑战，T2MIR设计了Token-wise MoE和Task-wise MoE来处理输入语义和任务路由，并结合对比学习优化任务路由。实验结果显示T2MIR显著增强了上下文学习效果，超越了现有基线。", "keywords": "上下文强化学习, 专家混合模型, Transformer, 多模态, 任务路由", "comments": "本文创新性地将专家混合模型（MoE）引入到上下文强化学习（ICRL）领域，解决了ICRL在处理多模态数据和多样化任务时的固有挑战。通过引入Token-wise MoE和Task-wise MoE，并结合对比学习进行任务路由优化，T2MIR提供了一种新颖且可扩展的架构改进，这对于推动ICRL的发展具有重要意义，使其能够更好地适应复杂的现实世界RL场景。"}}
{"id": "2506.05508", "title": "Beyond the Buzz: A Pragmatic Take on Inference Disaggregation", "authors": ["Tiyasa Mitra", "Ritika Borkar", "Nidhi Bhatia", "Ramon Matas", "Shivam Raj", "Dheevatsa Mudigere", "Ritchie Zhao", "Maximilian Golub", "Arpan Dutta", "Sailaja Madduri", "Dharmesh Jani", "Brian Pharris", "Bita Darvish Rouhani"], "summary": "As inference scales to multi-node deployments, disaggregation - splitting\ninference into distinct phases - offers a promising path to improving the\nthroughput-interactivity Pareto frontier. Despite growing enthusiasm and a\nsurge of open-source efforts, practical deployment of disaggregated serving\nremains limited due to the complexity of the optimization search space and\nsystem-level coordination. In this paper, we present the first systematic study\nof disaggregated inference at scale, evaluating hundreds of thousands of design\npoints across diverse workloads and hardware configurations. We find that\ndisaggregation is most effective for prefill-heavy traffic patterns and larger\nmodels. Our results highlight the critical role of dynamic rate matching and\nelastic scaling in achieving Pareto-optimal performance. Our findings offer\nactionable insights for efficient disaggregated deployments to navigate the\ntrade-off between system throughput and interactivity.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/pdf/2506.05508v1", "AI": {"title_translation": "超越炒作：推理解耦的务实视角", "tldr": "对大规模推理解耦的首次系统性研究，发现其在特定场景下有效，并提出了实现最佳性能的关键因素，为实际部署提供指导。", "motivation": "随着推理扩展到多节点部署，解耦被认为是提高吞吐量-交互性帕累托前沿的有效途径，但由于优化搜索空间的复杂性和系统级协调问题，其实际部署仍然有限。", "method": "本文对大规模解耦推理进行了首次系统性研究，评估了数十万个设计点，涵盖了不同的工作负载和硬件配置。", "result": "研究发现解耦在预填充密集型流量模式和大型模型中效果最佳。动态速率匹配和弹性扩展在实现帕累托最优性能方面发挥着关键作用。", "conclusion": "研究结果为高效的解耦部署提供了可操作的见解，以权衡系统吞吐量和交互性。", "translation": "随着推理扩展到多节点部署，解耦——将推理拆分为不同的阶段——为改善吞吐量-交互性帕累托前沿提供了一条有前景的路径。尽管热情日益高涨且开源工作激增，但由于优化搜索空间的复杂性和系统级协调，解耦服务的实际部署仍然有限。在本文中，我们首次对大规模解耦推理进行了系统性研究，评估了跨不同工作负载和硬件配置的数十万个设计点。我们发现解耦对于预填充密集型流量模式和大型模型最为有效。我们的结果突出了动态速率匹配和弹性扩展在实现帕累托最优性能方面的关键作用。我们的发现为高效的解耦部署提供了可操作的见解，以权衡系统吞吐量和交互性。", "summary": "本文对大规模推理解耦进行了首次系统性研究，旨在解决其在实际部署中的复杂性。通过评估数十万个设计点，研究发现解耦在预填充密集型流量和大型模型中最为有效。同时，动态速率匹配和弹性扩展被认为是实现帕累托最优性能的关键。这些发现为在系统吞吐量和交互性之间进行权衡的高效解耦部署提供了实用指导。", "keywords": "推理解耦, 大规模推理, 吞吐量, 交互性, 弹性扩展", "comments": "这项研究通过大规模系统性评估，为推理解耦的实际应用提供了数据支持和具体指导，特别是指出了适用场景和关键技术（动态速率匹配和弹性扩展），有助于克服现有部署复杂性，推动该技术的实用化。"}}
{"id": "2506.05565", "title": "Applying Informer for Option Pricing: A Transformer-Based Approach", "authors": ["Feliks Bańka", "Jarosław A. Chudziak"], "summary": "Accurate option pricing is essential for effective trading and risk\nmanagement in financial markets, yet it remains challenging due to market\nvolatility and the limitations of traditional models like Black-Scholes. In\nthis paper, we investigate the application of the Informer neural network for\noption pricing, leveraging its ability to capture long-term dependencies and\ndynamically adjust to market fluctuations. This research contributes to the\nfield of financial forecasting by introducing Informer's efficient architecture\nto enhance prediction accuracy and provide a more adaptable and resilient\nframework compared to existing methods. Our results demonstrate that Informer\noutperforms traditional approaches in option pricing, advancing the\ncapabilities of data-driven financial forecasting in this domain.", "comment": "8 pages, 3 tables, 7 figures. Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025). Final version\n  published in Proceedings of ICAART 2025 (Vol. 3), pages 1270-1277", "cate": "cs.CE", "url": "http://arxiv.org/pdf/2506.05565v1", "AI": {"title_translation": "将Informer应用于期权定价：一种基于Transformer的方法", "tldr": "本文应用基于Transformer的Informer神经网络进行期权定价，结果显示其优于传统方法。", "motivation": "期权定价在金融市场中至关重要，但由于市场波动和传统模型的局限性（如Black-Scholes），准确定价仍具挑战性。", "method": "本文研究了Informer神经网络在期权定价中的应用，利用其捕获长期依赖和动态调整市场波动的能力，旨在提高预测准确性并提供更具适应性和弹性的框架。", "result": "Informer在期权定价方面优于传统方法。", "conclusion": "Informer神经网络能够提升数据驱动的金融预测能力，为期权定价提供更准确、适应性更强的框架。", "translation": "准确的期权定价对于金融市场中有效的交易和风险管理至关重要，然而由于市场波动和Black-Scholes等传统模型的局限性，它仍然具有挑战性。在本文中，我们研究了Informer神经网络在期权定价中的应用，利用其捕获长期依赖并动态调整市场波动的能力。这项研究通过引入Informer的高效架构来提高预测准确性，并提供比现有方法更具适应性和弹性的框架，从而为金融预测领域做出了贡献。我们的结果表明，Informer在期权定价方面优于传统方法，提升了该领域数据驱动的金融预测能力。", "summary": "本文探讨了Informer神经网络在期权定价中的应用，旨在解决传统模型在市场波动性下的局限性。研究利用Informer捕获长期依赖并适应市场变化的能力，构建了一个更准确、适应性更强的期权定价框架。实验结果表明，Informer在期权定价方面优于传统方法，提升了数据驱动的金融预测能力。", "keywords": "期权定价, Informer, Transformer, 神经网络, 金融预测", "comments": "这篇论文的创新点在于将Informer这一基于Transformer的神经网络引入期权定价领域，克服了传统模型在市场波动性下的局限性。其重要性在于为金融市场提供了更准确和适应性更强的定价工具，有助于风险管理和交易策略优化。"}}
{"id": "2506.05351", "title": "Infinite Time Turing Machines and their Applications", "authors": ["Rukmal Weerawarana", "Maxwell Braun"], "summary": "This work establishes a rigorous theoretical foundation for analyzing deep\nlearning systems by leveraging Infinite Time Turing Machines (ITTMs), which\nextend classical computation into transfinite ordinal steps. Using ITTMs, we\nreinterpret modern architectures like Transformers, revealing fundamental\nlimitations in scalability, efficiency, and interpretability. Building on these\ninsights, we propose the Universal State Machine (USM), a novel computational\nparadigm designed from first principles. The USM employs a dynamic, queryable\ncomputation graph that evolves in real time, enabling modular, interpretable,\nand resource-efficient computation. This framework not only overcomes the\ninefficiencies and rigidity of current models but also lays the groundwork for\nscalable, generalizable artificial intelligence systems.", "comment": "Published by Ren XYZ Inc", "cate": "cs.CC", "url": "http://arxiv.org/pdf/2506.05351v1", "AI": {"title_translation": "无限时间图灵机及其应用", "tldr": "本文利用无限时间图灵机（ITTMs）为深度学习系统分析奠定理论基础，揭示现有模型局限性，并提出通用状态机（USM）以实现可扩展、通用和高效的AI系统。", "motivation": "该研究旨在通过利用无限时间图灵机（ITTMs）为分析深度学习系统建立严格的理论基础，并解决现有深度学习架构（如Transformer）在可扩展性、效率和可解释性方面的根本局限性。", "method": "该研究利用无限时间图灵机（ITTMs）重新解释了现代深度学习架构，并在此基础上提出了一种名为通用状态机（USM）的新型计算范式。USM采用动态、可查询的计算图，实时演化，旨在实现模块化、可解释和资源高效的计算。", "result": "研究揭示了Transformer等现代架构在可扩展性、效率和可解释性方面的根本局限性。同时，提出了一种新的计算范式——通用状态机（USM），该范式克服了当前模型的低效和僵化，并为可扩展、通用的人工智能系统奠定了基础。", "conclusion": "通用状态机（USM）的提出为构建可扩展、通用的人工智能系统奠定了基础，克服了当前深度学习模型的局限性。", "translation": "这项工作通过利用无限时间图灵机（ITTMs）为分析深度学习系统建立了严格的理论基础，ITTMs将经典计算扩展到超限序数步。利用ITTMs，我们重新解释了Transformer等现代架构，揭示了其在可扩展性、效率和可解释性方面的根本局限性。基于这些见解，我们提出了通用状态机（USM），这是一种从第一性原理设计的新型计算范式。USM采用动态、可查询的计算图，实时演化，从而实现模块化、可解释和资源高效的计算。该框架不仅克服了当前模型的低效和僵化，而且为可扩展、通用的人工智能系统奠定了基础。", "summary": "本文利用无限时间图灵机（ITTMs）为深度学习系统分析提供了理论框架，揭示了现有架构（如Transformer）的局限性。在此基础上，提出了一种新型计算范式——通用状态机（USM），该机器采用动态计算图，旨在实现模块化、可解释和资源高效的计算，为构建可扩展、通用的人工智能系统奠定了基础。", "keywords": "无限时间图灵机, 深度学习, Transformer, 通用状态机, 人工智能", "comments": "该论文通过引入无限时间图灵机（ITTMs）来分析深度学习系统，提供了一个新颖且理论严谨的视角。其创新点在于从计算理论的深层次揭示了当前主流模型（如Transformer）的固有缺陷，并提出了一种从第一性原理设计的通用状态机（USM）作为潜在的解决方案。USM强调模块化、可解释性和资源效率，这对于未来可扩展和通用人工智能的发展至关重要。这项工作具有重要的理论意义和潜在的实践价值，为突破现有深度学习范式的瓶颈提供了新的思路。"}}
{"id": "2506.05514", "title": "Can LLMs Talk 'Sex'? Exploring How AI Models Handle Intimate Conversations", "authors": ["Huiqian Lai"], "summary": "This study examines how four prominent large language models (Claude 3.7\nSonnet, GPT-4o, Gemini 2.5 Flash, and Deepseek-V3) handle sexually oriented\nrequests through qualitative content analysis. By evaluating responses to\nprompts ranging from explicitly sexual to educational and neutral control\nscenarios, the research reveals distinct moderation paradigms reflecting\nfundamentally divergent ethical positions. Claude 3.7 Sonnet employs strict and\nconsistent prohibitions, while GPT-4o navigates user interactions through\nnuanced contextual redirection. Gemini 2.5 Flash exhibits permissiveness with\nthreshold-based limits, and Deepseek-V3 demonstrates troublingly inconsistent\nboundary enforcement and performative refusals. These varied approaches create\na significant \"ethical implementation gap,\" stressing a critical absence of\nunified ethical frameworks and standards across platforms. The findings\nunderscore the urgent necessity for transparent, standardized guidelines and\ncoordinated international governance to ensure consistent moderation, protect\nuser welfare, and maintain trust as AI systems increasingly mediate intimate\naspects of human life.", "comment": "6 pages, 1 figure, accepted as a short paper at ASIS&T Annual Meeting\n  2025", "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.05514v1", "AI": {"title_translation": "LLMs能谈论“性”吗？探索AI模型如何处理亲密对话", "tldr": "该研究通过定性内容分析，发现四种主流大型语言模型（LLMs）在处理性相关请求时展现出截然不同且不一致的审查范式，揭示了显著的“伦理实施差距”，强调急需统一的指导方针和国际治理。", "motivation": "该研究旨在探究大型语言模型如何处理性相关请求，因为目前在不同平台之间缺乏统一的伦理框架和标准。", "method": "通过对四种主流大型语言模型（Claude 3.7 Sonnet、GPT-4o、Gemini 2.5 Flash和Deepseek-V3）的响应进行定性内容分析，评估它们对从明确性化到教育性和中性对照场景提示的反应。", "result": "Claude 3.7 Sonnet采用严格且一致的禁止策略；GPT-4o通过细致的上下文重定向来引导用户互动；Gemini 2.5 Flash表现出许可性，但有基于阈值的限制；Deepseek-V3显示出令人不安的不一致边界执行和表演性拒绝。总体而言，这些不同的方法造成了显著的“伦理实施差距”，凸显了平台之间缺乏统一的伦理框架和标准。", "conclusion": "研究结果强调，迫切需要透明、标准化的指导方针和协调的国际治理，以确保审查的一致性，保护用户福祉，并在AI系统日益介入人类生活亲密方面时维护信任。", "translation": "本研究通过定性内容分析，考察了四种主要大型语言模型（Claude 3.7 Sonnet、GPT-4o、Gemini 2.5 Flash和Deepseek-V3）如何处理性取向请求。通过评估对从明确性化到教育性和中性对照场景的提示的响应，研究揭示了反映根本性伦理立场差异的独特审查范式。Claude 3.7 Sonnet采用严格且一致的禁止策略，而GPT-4o则通过细致的上下文重定向来引导用户互动。Gemini 2.5 Flash表现出许可性，但有基于阈值的限制，而Deepseek-V3则显示出令人不安的不一致边界执行和表演性拒绝。这些不同的方法造成了显著的“伦理实施差距”，强调了平台之间严重缺乏统一的伦理框架和标准。研究结果强调，迫切需要透明、标准化的指导方针和协调的国际治理，以确保审查的一致性，保护用户福祉，并在AI系统日益介入人类生活亲密方面时维护信任。", "summary": "本研究采用定性内容分析方法，探究了Claude 3.7 Sonnet、GPT-4o、Gemini 2.5 Flash和Deepseek-V3这四款主流大型语言模型在处理性相关对话时的不同表现。研究发现，这些模型在审查策略上存在显著差异，反映出各自独立的伦理立场，从而导致了明显的“伦理实施差距”。研究强调，为确保AI系统在处理亲密内容时能一致地保护用户并维护信任，亟需制定统一、透明的指导原则并加强国际合作治理。", "keywords": "大型语言模型, 性内容审查, 伦理实施差距, AI治理, 内容审核", "comments": "创新性：本研究通过对主流LLMs处理“性”相关对话的定性分析，揭示了不同模型间审查策略的显著差异，这对于理解AI伦理和内容审查机制具有重要意义。重要性：论文指出了AI领域存在的“伦理实施差距”和缺乏统一标准的现状，强调了制定透明、标准化指导方针和国际治理的紧迫性，对于AI的负责任发展具有指导价值。局限性：研究所选取的模型数量有限（四种），且主要依赖定性内容分析，可能无法完全捕捉所有模型行为的细微之处或进行大规模量化比较。"}}
{"id": "2506.05381", "title": "Heterogeneous Secure Transmissions in IRS-Assisted NOMA Communications: CO-GNN Approach", "authors": ["Linlin Liang", "Zongkai Tian", "Haiyan Huang", "Xiaoyan Li", "Zhisheng Yin", "Dehua Zhang", "Nina Zhang", "Wenchao Zhai"], "summary": "Intelligent Reflecting Surfaces (IRS) enhance spectral efficiency by\nadjusting reflection phase shifts, while Non-Orthogonal Multiple Access (NOMA)\nincreases system capacity. Consequently, IRS-assisted NOMA communications have\ngarnered significant research interest. However, the passive nature of the IRS,\nlacking authentication and security protocols, makes these systems vulnerable\nto external eavesdropping due to the openness of electromagnetic signal\npropagation and reflection. NOMA's inherent multi-user signal superposition\nalso introduces internal eavesdropping risks during user pairing. This paper\ninvestigates secure transmissions in IRS-assisted NOMA systems with\nheterogeneous resource configuration in wireless networks to mitigate both\nexternal and internal eavesdropping. To maximize the sum secrecy rate of\nlegitimate users, we propose a combinatorial optimization graph neural network\n(CO-GNN) approach to jointly optimize beamforming at the base station, power\nallocation of NOMA users, and phase shifts of IRS for dynamic heterogeneous\nresource allocation, thereby enabling the design of dual-link or multi-link\nsecure transmissions in the presence of eavesdroppers on the same or\nheterogeneous links. The CO-GNN algorithm simplifies the complex mathematical\nproblem-solving process, eliminates the need for channel estimation, and\nenhances scalability. Simulation results demonstrate that the proposed\nalgorithm significantly enhances the secure transmission performance of the\nsystem.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05381v1", "AI": {"title_translation": "IRS辅助NOMA通信中的异构安全传输：CO-GNN方法", "tldr": "本文提出一种CO-GNN方法，通过联合优化波束成形、功率分配和相位偏移，在IRS辅助NOMA系统中实现异构安全传输，有效抵御内外窃听。", "motivation": "IRS辅助NOMA系统因IRS的被动性（缺乏认证和安全协议）以及NOMA的多用户信号叠加，面临外部和内部窃听的严重安全风险。", "method": "提出一种组合优化图神经网络（CO-GNN）方法，联合优化基站的波束成形、NOMA用户的功率分配以及IRS的相位偏移，以实现动态异构资源分配，从而设计双链路或多链路安全传输，最大化合法用户的总保密速率。该方法简化了数学问题求解过程，消除了信道估计的需要，并增强了可扩展性。", "result": "仿真结果表明，所提出的算法显著提升了系统的安全传输性能。", "conclusion": "所提出的CO-GNN算法能有效增强IRS辅助NOMA系统的安全传输性能，并简化了复杂问题求解，提高了系统可扩展性。", "translation": "智能反射面（IRS）通过调整反射相移来提高频谱效率，而非正交多址接入（NOMA）则增加了系统容量。因此，IRS辅助的NOMA通信受到了广泛的研究关注。然而，IRS的被动性（缺乏认证和安全协议）使得这些系统由于电磁信号传播和反射的开放性而容易受到外部窃听。NOMA固有的多用户信号叠加也在用户配对过程中引入了内部窃听风险。本文研究了无线网络中具有异构资源配置的IRS辅助NOMA系统中的安全传输，以减轻外部和内部窃听。为了最大化合法用户的总保密速率，我们提出了一种组合优化图神经网络（CO-GNN）方法，用于联合优化基站的波束成形、NOMA用户的功率分配以及IRS的相移，以实现动态异构资源分配，从而在存在相同或异构链路上的窃听者的情况下，设计双链路或多链路安全传输。CO-GNN算法简化了复杂的数学问题求解过程，消除了信道估计的需要，并增强了可扩展性。仿真结果表明，所提出的算法显著增强了系统的安全传输性能。", "summary": "本文针对IRS辅助NOMA通信系统中存在的外部和内部窃听安全漏洞，提出了一种名为组合优化图神经网络（CO-GNN）的新方法。该方法旨在通过联合优化基站的波束成形、NOMA用户的功率分配和IRS的相移，以实现动态异构资源分配，从而最大化合法用户的总保密速率。CO-GNN算法能够简化问题求解、避免信道估计并提升系统可扩展性。仿真结果验证了该算法能显著提高系统的安全传输性能。", "keywords": "IRS辅助NOMA, 安全传输, 窃听, 组合优化图神经网络, 异构资源配置", "comments": "这篇论文通过引入CO-GNN方法来解决IRS辅助NOMA系统中的安全传输问题，具有创新性。它不仅考虑了外部窃听，还关注了NOMA固有的内部窃听风险，并通过联合优化多种参数来提升安全性。CO-GNN的优势在于其简化了复杂的优化过程，并消除了传统方法中对信道估计的依赖，这对于实际部署具有重要意义。"}}
{"id": "2506.05555", "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/pdf/2506.05555v1", "AI": {"title_translation": "使用大型语言模型模拟人类行为实验：火星港", "tldr": "本文探讨使用大型语言模型（LLM）模拟集体风险社会困境（CRSD）中的人类行为实验，以解决传统人类实验的局限性，并验证该方法的可行性。", "motivation": "集体风险社会困境（CRSD）的研究需要大规模人类实验，但难以保证足够的效力和社会人口因素的异质性。大型语言模型（LLM）提供了一种潜在的补充方法来解决这一问题。", "method": "通过用大型语言模型（LLM）取代人类参与者，建立一个可扩展的经验框架，以模拟人类行为实验。具体关注“火星港”这一复杂的CRSD模型。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "集体风险社会困境（CRSD）强调了个人偏好与所有人为实现群体目标而贡献之间的权衡。气候变化等问题属于此类，因此了解其社会基础至关重要。然而，严谨的CRSD方法论通常需要大规模人类实验，但难以保证足够的效力以及社会人口因素的异质性。生成式AI提供了一种潜在的补充方法来解决这个问题。通过用大型语言模型（LLM）取代人类参与者，它实现了一个可扩展的经验框架。本文重点关注这种方法的有效性，以及使用大型语言模型（LLM）代表具有足够多样性的大规模类人实验是否可行。特别是，以往文献侧重于政治调查、虚拟城镇和经典博弈论示例，而我们则关注制度经济学和可持续发展文献中使用的复杂CRSD，即“火星港”。", "summary": "本文探讨了利用大型语言模型（LLM）模拟集体风险社会困境（CRSD）中的人类行为实验。鉴于传统人类实验在规模和多样性方面的局限性，研究提出用LLM替代人类参与者，构建可扩展的经验框架。论文主要关注该方法在模拟大规模、多样化类人实验中的有效性和可行性，并以“火星港”这一复杂CRSD模型为例进行研究。", "keywords": "大型语言模型, 行为实验, 集体风险社会困境, 火星港, 模拟", "comments": "本文提出了一种利用大型语言模型（LLM）模拟人类行为实验的创新方法，旨在解决传统大规模人类实验在成本、规模和多样性方面的挑战。这种方法具有重要的研究潜力，尤其是在社会困境等复杂情境下，可以为行为科学研究提供新的工具和视角。其创新性在于将LLM从传统的语言任务扩展到复杂的社会行为模拟，但其有效性和模拟结果的泛化能力仍需严格验证。"}}
{"id": "2506.05576", "title": "TD-TOG Dataset: Benchmarking Zero-Shot and One-Shot Task-Oriented Grasping for Object Generalization", "authors": ["Valerija Holomjova", "Jamie Grech", "Dewei Yi", "Bruno Yun", "Andrew Starkey", "Pascal Meißner"], "summary": "Task-oriented grasping (TOG) is an essential preliminary step for robotic\ntask execution, which involves predicting grasps on regions of target objects\nthat facilitate intended tasks. Existing literature reveals there is a limited\navailability of TOG datasets for training and benchmarking despite large\ndemand, which are often synthetic or have artifacts in mask annotations that\nhinder model performance. Moreover, TOG solutions often require affordance\nmasks, grasps, and object masks for training, however, existing datasets\ntypically provide only a subset of these annotations. To address these\nlimitations, we introduce the Top-down Task-oriented Grasping (TD-TOG) dataset,\ndesigned to train and evaluate TOG solutions. TD-TOG comprises 1,449 real-world\nRGB-D scenes including 30 object categories and 120 subcategories, with\nhand-annotated object masks, affordances, and planar rectangular grasps. It\nalso features a test set for a novel challenge that assesses a TOG solution's\nability to distinguish between object subcategories. To contribute to the\ndemand for TOG solutions that can adapt and manipulate previously unseen\nobjects without re-training, we propose a novel TOG framework, Binary-TOG.\nBinary-TOG uses zero-shot for object recognition, and one-shot learning for\naffordance recognition. Zero-shot learning enables Binary-TOG to identify\nobjects in multi-object scenes through textual prompts, eliminating the need\nfor visual references. In multi-object settings, Binary-TOG achieves an average\ntask-oriented grasp accuracy of 68.9%. Lastly, this paper contributes a\ncomparative analysis between one-shot and zero-shot learning for object\ngeneralization in TOG to be used in the development of future TOG solutions.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05576v1", "AI": {"title_translation": "TD-TOG数据集：基准测试零样本和单样本面向任务抓取以实现物体泛化", "tldr": "本文介绍了TD-TOG数据集和Binary-TOG框架，以解决现有面向任务抓取（TOG）数据集中存在的局限性，并侧重于零样本和单样本学习在物体泛化方面的应用。", "motivation": "现有面向任务抓取（TOG）数据集数量有限，常为合成数据或存在掩码注释伪影，阻碍模型性能。此外，现有数据集通常只提供训练TOG解决方案所需注释（如可供性掩码、抓取和物体掩码）的一个子集。市场对无需重新训练即可适应和操作以前未见物体的TOG解决方案有很大需求。", "method": "1. 引入了Top-down Task-oriented Grasping (TD-TOG) 数据集，包含1,449个真实世界RGB-D场景，30个物体类别和120个子类别，以及手绘的物体掩码、可供性信息和平面矩形抓取。该数据集还包含一个用于评估TOG解决方案区分物体子类别能力的测试集。2. 提出了一个新颖的TOG框架——Binary-TOG，该框架利用零样本学习进行物体识别，并利用单样本学习进行可供性识别。零样本学习通过文本提示识别多物体场景中的物体。", "result": "1. TD-TOG数据集包含1,449个真实世界RGB-D场景，30个物体类别和120个子类别，并提供手绘的物体掩码、可供性信息和平面矩形抓取。2. Binary-TOG框架在多物体设置中实现了68.9%的平均面向任务抓取精度。3. 本文还对零样本和单样本学习在TOG中物体泛化方面的应用进行了比较分析。", "conclusion": "本文通过引入TD-TOG数据集和Binary-TOG框架，解决了现有面向任务抓取（TOG）数据集的局限性，特别是针对未见物体的抓取问题。此外，本文还对零样本和单样本学习在TOG中物体泛化方面的应用进行了比较分析，为未来TOG解决方案的开发提供了基础。", "translation": "面向任务的抓取（TOG）是机器人任务执行中必不可少的第一步，它涉及预测目标物体上便于预期任务的区域的抓取。现有文献表明，尽管需求量大，但用于训练和基准测试的TOG数据集供应有限，这些数据集通常是合成的或在掩码注释中存在伪影，从而阻碍了模型性能。此外，TOG解决方案通常需要可供性掩码、抓取和物体掩码进行训练，然而，现有数据集通常只提供这些注释的一个子集。为了解决这些限制，我们引入了Top-down Task-oriented Grasping (TD-TOG)数据集，旨在训练和评估TOG解决方案。TD-TOG包含1,449个真实世界RGB-D场景，包括30个物体类别和120个子类别，以及手绘的物体掩码、可供性信息和平面矩形抓取。它还设有一个测试集，用于一项新颖的挑战，评估TOG解决方案区分物体子类别的能力。为了满足对无需重新训练即可适应和操作以前未见物体的TOG解决方案的需求，我们提出了一种新颖的TOG框架，Binary-TOG。Binary-TOG使用零样本学习进行物体识别，并使用单样本学习进行可供性识别。零样本学习使Binary-TOG能够通过文本提示识别多物体场景中的物体，无需视觉参考。在多物体设置中，Binary-TOG实现了68.9%的平均面向任务抓取精度。最后，本文贡献了一项关于零样本和单样本学习在TOG中物体泛化方面的比较分析，以用于未来TOG解决方案的开发。", "summary": "本文介绍了TD-TOG数据集和Binary-TOG框架，旨在解决现有面向任务抓取（TOG）数据集中存在的不足。TD-TOG是一个包含1,449个真实世界RGB-D场景、全面手绘注释（包括物体掩码、可供性信息和抓取）的大规模数据集。Binary-TOG是一个新颖的TOG框架，利用零样本学习进行物体识别和单样本学习进行可供性识别，在多物体场景中实现了68.9%的平均抓取精度。此外，本文还对零样本和单样本学习在TOG中物体泛化方面的应用进行了比较分析。", "keywords": "面向任务抓取, TD-TOG数据集, 零样本学习, 单样本学习, 物体泛化", "comments": "该论文通过提供一个全面的、真实世界的数据集（TD-TOG）及其详细注释，解决了机器人抓取研究中的一个关键空白，这对于推动面向任务抓取至关重要。Binary-TOG框架的引入，利用零样本和单样本学习，具有创新性，因为它允许机器人适应未见物体，这是迈向更通用机器人操作的重要一步。所进行的比较分析进一步加深了对这些学习范式在面向任务抓取中应用的理解。"}}
{"id": "2506.05360", "title": "CarboNeXT and CarboFormer: Dual Semantic Segmentation Architectures for Detecting and Quantifying Carbon Dioxide Emissions Using Optical Gas Imaging", "authors": ["Taminul Islam", "Toqi Tahamid Sarker", "Mohamed G Embaby", "Khaled R Ahmed", "Amer AbuGhazaleh"], "summary": "Carbon dioxide (CO$_2$) emissions are critical indicators of both\nenvironmental impact and various industrial processes, including livestock\nmanagement. We introduce CarboNeXT, a semantic segmentation framework for\nOptical Gas Imaging (OGI), designed to detect and quantify CO$_2$ emissions\nacross diverse applications. Our approach integrates a multi-scale context\naggregation network with UPerHead and auxiliary FCN components to effectively\nmodel both local details and global relationships in gas plume imagery. We\ncontribute two novel datasets: (1) the Controlled Carbon Dioxide Release (CCR)\ndataset, which simulates gas leaks with systematically varied flow rates\n(10-100 SCCM), and (2) the Real Time Ankom (RTA) dataset, focusing on emissions\nfrom dairy cow rumen fluid in vitro experiments. Extensive evaluations\ndemonstrate that CarboNeXT outperforms state-of-the-art methods, achieving\n88.46% mIoU on CCR and 92.95% mIoU on RTA, with particular effectiveness in\nchallenging low-flow scenarios. The model operates at 60.95 FPS, enabling\nreal-time monitoring applications. Additionally, we propose CarboFormer, a\nlightweight variant with only 5.07M parameters that achieves 84.68 FPS, with\ncompetitive performance of 84.88% mIoU on CCR and 92.98% on RTA, making it\nsuitable for resource-constrained platforms such as programmable drones. Our\nwork advances both environmental sensing and precision livestock management by\nproviding robust tools for CO$_2$ emission analysis, with a specific focus on\nlivestock applications.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05360v1", "AI": {"title_translation": "CarboNeXT和CarboFormer：用于使用光学气体成像检测和量化二氧化碳排放的双语义分割架构", "tldr": "本文介绍了CarboNeXT和CarboFormer，两种用于光学气体成像（OGI）的语义分割架构，旨在实时检测和量化二氧化碳排放，特别是在畜牧业应用中，并创建了两个新数据集。", "motivation": "二氧化碳（CO2）排放是环境影响和各种工业过程（包括畜牧管理）的关键指标。现有方法可能无法有效检测和量化CO2排放，尤其是在低流量场景和实时监测方面。", "method": "本文提出了CarboNeXT，一个用于光学气体成像（OGI）的语义分割框架，用于检测和量化CO2排放。该方法集成了多尺度上下文聚合网络、UPerHead和辅助FCN组件。此外，本文还贡献了两个新数据集：受控二氧化碳释放（CCR）数据集（模拟10-100 SCCM流量的气体泄漏）和实时Ankom（RTA）数据集（关注奶牛瘤胃液体外实验的排放）。同时提出了CarboFormer，一个轻量级变体，适用于资源受限平台。", "result": "CarboNeXT在CCR数据集上实现了88.46%的mIoU，在RTA数据集上实现了92.95%的mIoU，优于现有最先进的方法，特别是在低流量场景中表现出色。CarboNeXT模型以60.95 FPS运行，支持实时监控。CarboFormer（5.07M参数）以84.68 FPS运行，在CCR上达到84.88%的mIoU，在RTA上达到92.98%的mIoU，性能具有竞争力。", "conclusion": "本文通过提供强大的CO2排放分析工具，特别关注畜牧业应用，推动了环境传感和精准畜牧管理的发展。", "translation": "二氧化碳（CO2）排放是环境影响和各种工业过程（包括畜牧管理）的关键指标。我们引入了CarboNeXT，一个用于光学气体成像（OGI）的语义分割框架，旨在检测和量化各种应用中的CO2排放。我们的方法整合了一个多尺度上下文聚合网络，结合UPerHead和辅助FCN组件，以有效建模气体羽流图像中的局部细节和全局关系。我们贡献了两个新颖的数据集：（1）受控二氧化碳释放（CCR）数据集，模拟了系统性变化的流量（10-100 SCCM）的气体泄漏，以及（2）实时Ankom（RTA）数据集，专注于奶牛瘤胃液体外实验的排放。广泛的评估表明，CarboNeXT优于现有最先进的方法，在CCR上实现了88.46%的mIoU，在RTA上实现了92.95%的mIoU，在具有挑战性的低流量场景中尤其有效。该模型以60.95 FPS运行，支持实时监控应用。此外，我们提出了CarboFormer，一个只有5.07M参数的轻量级变体，实现了84.68 FPS，在CCR上具有84.88%的mIoU，在RTA上具有92.98%的竞争力性能，使其适用于可编程无人机等资源受限平台。我们的工作通过提供强大的CO2排放分析工具，特别关注畜牧业应用，推动了环境传感和精准畜牧管理的发展。", "summary": "该论文介绍了CarboNeXT和CarboFormer，两种用于光学气体成像（OGI）的语义分割架构，用于实时检测和量化二氧化碳（CO2）排放。CarboNeXT采用多尺度上下文聚合网络、UPerHead和FCN组件。作者还创建了两个新数据集：CCR（模拟气体泄漏）和RTA（奶牛瘤胃液排放）。实验结果表明，CarboNeXT在CCR和RTA数据集上均优于现有技术，并能实现实时监控。CarboFormer作为轻量级变体，在资源受限平台上也表现出竞争力。这项工作旨在改进环境传感和精准畜牧管理中的CO2排放分析。", "keywords": "语义分割, 二氧化碳排放, 光学气体成像, CarboNeXT, CarboFormer", "comments": "该论文的创新点在于提出了专门用于光学气体成像的语义分割模型（CarboNeXT和CarboFormer），并为CO2排放检测贡献了两个新颖且具有实际应用价值的数据集。其重要性体现在为环境监测和精准畜牧管理提供了高效、实时的CO2量化工具，尤其是在低流量和资源受限场景下的表现令人印象深刻。模型的实时运行能力（高帧率）是其一大亮点，有望在实际部署中发挥重要作用。"}}
{"id": "2506.05451", "title": "Interpretation Meets Safety: A Survey on Interpretation Methods and Tools for Improving LLM Safety", "authors": ["Seongmin Lee", "Aeree Cho", "Grace C. Kim", "ShengYun Peng", "Mansi Phute", "Duen Horng Chau"], "summary": "As large language models (LLMs) see wider real-world use, understanding and\nmitigating their unsafe behaviors is critical. Interpretation techniques can\nreveal causes of unsafe outputs and guide safety, but such connections with\nsafety are often overlooked in prior surveys. We present the first survey that\nbridges this gap, introducing a unified framework that connects safety-focused\ninterpretation methods, the safety enhancements they inform, and the tools that\noperationalize them. Our novel taxonomy, organized by LLM workflow stages,\nsummarizes nearly 70 works at their intersections. We conclude with open\nchallenges and future directions. This timely survey helps researchers and\npractitioners navigate key advancements for safer, more interpretable LLMs.", "comment": "31 pages, 1 figure", "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05451v1", "AI": {"title_translation": "解释性遇上安全性：关于改进LLM安全性的解释方法和工具的综述", "tldr": "该综述是首个连接大型语言模型（LLM）解释性与安全性的研究，提出了一个统一框架并总结了相关工作。", "motivation": "随着大型语言模型（LLM）在现实世界中得到更广泛的应用，理解和减轻其不安全行为至关重要。解释技术可以揭示不安全输出的原因并指导安全性，但这些与安全性的联系在以前的调查中经常被忽视。", "method": "本文介绍了第一个弥合这一差距的综述，引入了一个统一的框架，该框架将以安全为重点的解释方法、它们所促进的安全增强以及将它们付诸实践的工具联系起来。通过按LLM工作流程阶段组织的新颖分类法，总结了近70项交叉领域的工作。", "result": "本文提出了一个统一的框架，连接了安全导向的解释方法、它们促进的安全增强以及实现这些方法的工具。同时，通过按LLM工作流程阶段组织的新颖分类法，总结了近70项相关工作。", "conclusion": "本文以开放性挑战和未来方向作为结尾。这项及时的综述帮助研究人员和从业者了解关键进展，以实现更安全、更可解释的LLM。", "translation": "随着大型语言模型（LLM）在现实世界中得到更广泛的应用，理解和减轻其不安全行为至关重要。解释技术可以揭示不安全输出的原因并指导安全性，但这些与安全性的联系在以前的调查中经常被忽视。我们提出了第一个弥合这一差距的综述，引入了一个统一的框架，该框架将以安全为重点的解释方法、它们所促进的安全增强以及将它们付诸实践的工具联系起来。我们新颖的分类法，按LLM工作流程阶段组织，总结了近70项交叉领域的工作。我们以开放性挑战和未来方向作为结尾。这项及时的综述帮助研究人员和从业者了解关键进展，以实现更安全、更可解释的LLM。", "summary": "本论文是首个将大型语言模型（LLM）的解释性方法与安全性改进相结合的综述。它提出了一个统一的框架，连接了以安全为重点的解释方法、它们所促进的安全增强以及相关的工具。通过按LLM工作流程阶段组织的新颖分类法，总结了近70项相关工作，并讨论了开放性挑战和未来方向，旨在帮助研究人员和从业者实现更安全、更可解释的LLM。", "keywords": "LLM安全性, 解释性, 综述, 统一框架, 安全增强", "comments": "该综述填补了现有研究的空白，首次系统性地将LLM的解释性与安全性紧密结合，并提供了实用的框架和分类法，对LLM安全研究具有重要指导意义。"}}
{"id": "2506.05522", "title": "Understanding Community-Level Blocklists in Decentralized Social Media", "authors": ["Owen Xingjian Zhang", "Sohyeon Hwang", "Yuhan Liu", "Manoel Horta Ribeiro", "Andrés Monroy-Hernández"], "summary": "Community-level blocklists are key to content moderation practices in\ndecentralized social media. These blocklists enable moderators to prevent other\ncommunities, such as those acting in bad faith, from interacting with their own\n-- and, if shared publicly, warn others about communities worth blocking. Prior\nwork has examined blocklists in centralized social media, noting their\npotential for collective moderation outcomes, but has focused on blocklists as\nindividual-level tools. To understand how moderators perceive and utilize\ncommunity-level blocklists and what additional support they may need, we\nexamine social media communities running Mastodon, an open-source microblogging\nsoftware built on the ActivityPub protocol. We conducted (1) content analysis\nof the community-level blocklist ecosystem, and (2) semi-structured interviews\nwith twelve Mastodon moderators. Our content analysis revealed wide variation\nin blocklist goals, inclusion criteria, and transparency. Interviews showed\nmoderators balance proactive safety, reactive practices, and caution around\nfalse positives when using blocklists for moderation. They noted challenges and\nlimitations in current blocklist use, suggesting design improvements like\ncomment receipts, category filters, and collaborative voting. We discuss\nimplications for decentralized content moderation, highlighting trade-offs\nbetween openness, safety, and nuance; the complexity of moderator roles; and\nopportunities for future design.", "comment": null, "cate": "cs.SI", "url": "http://arxiv.org/pdf/2506.05522v1", "AI": {"title_translation": "理解去中心化社交媒体中的社区级黑名单", "tldr": "本研究探讨了去中心化社交媒体（如Mastodon）中社区级黑名单的用途、挑战和潜在改进，通过内容分析和对版主的访谈，揭示了其在内容审核中的重要性、多样性以及对更好设计工具的需求。", "motivation": "先前的研究主要关注中心化社交媒体中的个人级黑名单，而社区级黑名单在去中心化社交媒体的内容审核中至关重要。本研究旨在理解版主如何看待和利用社区级黑名单，以及他们可能需要哪些额外的支持。", "method": "本研究对运行Mastodon的社交媒体社区进行了调查。方法包括：1) 对社区级黑名单生态系统进行内容分析；2) 对十二位Mastodon版主进行半结构化访谈。", "result": "内容分析揭示了黑名单目标、收录标准和透明度方面的广泛差异。访谈显示版主在使用黑名单进行审核时，需要在主动安全、被动实践和对误报的谨慎之间取得平衡。他们指出了当前黑名单使用中的挑战和局限性，并提出了设计改进建议，如评论收据、类别过滤器和协作投票。", "conclusion": "本研究讨论了去中心化内容审核的含义，强调了开放性、安全性与细微差别之间的权衡；版主角色的复杂性；以及未来设计的机会。", "translation": "社区级黑名单是去中心化社交媒体内容审核实践的关键。这些黑名单使版主能够阻止其他社区（例如那些恶意行为的社区）与自己的社区互动——如果公开共享，还可以提醒他人注意值得屏蔽的社区。先前的研究已经审查了中心化社交媒体中的黑名单，并注意到它们在集体审核结果方面的潜力，但主要关注黑名单作为个人级工具。为了理解版主如何看待和利用社区级黑名单以及他们可能需要哪些额外的支持，我们审查了运行Mastodon的社交媒体社区，Mastodon是一个基于ActivityPub协议的开源微博软件。我们进行了（1）社区级黑名单生态系统的内容分析，以及（2）对十二位Mastodon版主的半结构化访谈。我们的内容分析揭示了黑名单目标、收录标准和透明度方面的广泛差异。访谈显示版主在使用黑名单进行审核时，需要在主动安全、被动实践和对误报的谨慎之间取得平衡。他们指出了当前黑名单使用中的挑战和局限性，并提出了设计改进建议，如评论收据、类别过滤器和协作投票。我们讨论了去中心化内容审核的含义，强调了开放性、安全性与细微差别之间的权衡；版主角色的复杂性；以及未来设计的机会。", "summary": "本研究旨在深入理解去中心化社交媒体中社区级黑名单的运作和挑战。通过对Mastodon社区的内容分析和对版主的访谈，研究发现黑名单在目标、标准和透明度上存在显著差异，且版主在使用时需平衡主动安全与误报风险。研究揭示了当前工具的局限性，并提出了评论收据、类别过滤和协作投票等改进建议，为未来去中心化内容审核工具的设计提供了方向。", "keywords": "去中心化社交媒体, 内容审核, 社区级黑名单, Mastodon, 版主", "comments": "这项研究填补了去中心化社交媒体内容审核领域的一个重要空白，特别是关注了社区级黑名单这一关键工具。其创新之处在于结合了内容分析和访谈，深入理解了版主的实际需求和面临的困境。研究结果对于设计更有效、更具用户支持的去中心化内容审核工具具有重要指导意义，尤其是在平衡开放性、安全性和细微差别方面提供了宝贵的见解。"}}
{"id": "2506.05943", "title": "Nonlinear symbols combining for Power Amplifier-distorted OFDM signal reception", "authors": ["Pawel Kryszkiewicz", "Hanna Bogucka"], "summary": "Nonlinear distortion of a multicarrier signal by a transmitter Power\nAmplifier (PA) can be a serious problem when designing new highly\nenergy-efficient wireless systems. Although the performance of standard\nreception algorithms is seriously deteriorated by the nonlinear distortion, the\nmore advanced solutions allow the utilization of additional frequency diversity\ncaused by nonlinear PA. However, while most of the advanced receivers are\ndecision-aided, their gains are observed mostly in a relatively low Bit Error\nRate (BER) region, not targeted by adaptive Modulation Coding Schemes utilizing\nForward Error Correction (FEC). In this paper, a non-decision-aided\nHigher-Order Combining (HOC) reception scheme is proposed. While the analytical\nformulas for finding symbols combining coefficients are not known, machine\nlearning is used for deriving them. The simulation results show an improved BER\nperformance with respect to a standard reception and one of the established\ndecision-aided receivers. However, as HOC has computational complexity that\nincreases rapidly with the number of subcarriers utilized, more studies are\nneeded to apply it in a wideband system.", "comment": "accepted for EUSIPCO 2025", "cate": "cs.NI", "url": "http://arxiv.org/pdf/2506.05943v1", "AI": {"title_translation": "非线性符号合并用于功率放大器失真OFDM信号接收", "tldr": "本文提出了一种非判决辅助的高阶合并（HOC）方案，通过机器学习改善功率放大器失真OFDM信号的误码率性能，但其计算复杂度随子载波数量快速增加。", "motivation": "在设计高能效无线系统时，发射机功率放大器（PA）引起的非线性失真是一个严重问题，它会严重恶化标准接收算法的性能。尽管现有先进解决方案能利用非线性PA带来的频率分集，但它们多为判决辅助，且增益主要体现在较低的误码率（BER）区域，这与利用前向纠错（FEC）的自适应调制编码方案的目标不符。", "method": "本文提出了一种非判决辅助的高阶合并（HOC）接收方案。由于符号合并系数的解析公式未知，因此利用机器学习来推导这些系数。", "result": "仿真结果表明，相对于标准接收和现有的一种判决辅助接收器，所提出的方案在误码率（BER）性能上有所改善。", "conclusion": "所提出的非判决辅助高阶合并（HOC）方案能够改善功率放大器失真OFDM信号的误码率性能。然而，由于HOC的计算复杂度随所利用的子载波数量快速增加，其在宽带系统中的应用还需要更多的研究。", "translation": "标题：非线性符号合并用于功率放大器失真OFDM信号接收\n\n摘要：发射机功率放大器 (PA) 对多载波信号的非线性失真在设计新型高能效无线系统时可能是一个严重的问题。尽管标准接收算法的性能会因非线性失真而严重恶化，但更先进的解决方案允许利用非线性PA引起的额外频率分集。然而，虽然大多数先进接收器是判决辅助的，但它们的增益主要在相对较低的误码率 (BER) 区域观察到，这并不是利用前向纠错 (FEC) 的自适应调制编码方案所针对的。在本文中，提出了一种非判决辅助的高阶合并 (HOC) 接收方案。由于寻找符号合并系数的解析公式未知，因此使用机器学习来推导它们。仿真结果显示，相对于标准接收和现有的一种判决辅助接收器，误码率性能有所改善。然而，由于HOC的计算复杂度随所利用的子载波数量快速增加，因此需要更多的研究才能将其应用于宽带系统。", "summary": "本文提出了一种用于功率放大器失真OFDM信号接收的非判决辅助高阶合并（HOC）方案。该方案利用机器学习来推导符号合并系数，旨在改善标准接收算法在非线性失真下的性能。仿真结果表明，与标准接收和一些判决辅助接收器相比，HOC方案在误码率方面表现出更好的性能。然而，由于其计算复杂度随子载波数量的增加而迅速提高，该方案在宽带系统中的应用仍需进一步研究。", "keywords": "非线性失真, 功率放大器, OFDM, 高阶合并, 机器学习, 误码率", "comments": "该论文通过利用机器学习推导非判决辅助高阶合并（HOC）方案的合并系数，为处理功率放大器失真OFDM信号提供了一种创新方法，解决了传统和判决辅助接收器在非线性失真下的局限性。其主要贡献在于展示了误码率性能的改善。然而，计算复杂度高是其显著的局限性，需要在未来的研究中加以解决，以实现更广泛的实际应用。"}}
{"id": "2506.05569", "title": "Fluid Antenna System-Assisted Self-Interference Cancellation for In-Band Full Duplex Communications", "authors": ["Hanjiang Hong", "Kai-Kit Wong", "Hao Xu", "Yiyan Wu", "Sai Xu", "Chan-Byoung Chae", "Baiyang Liu", "Kin-Fai Tong"], "summary": "In-band full-duplex (IBFD) systems are expected to double the spectral\nefficiency compared to half-duplex systems, provided that loopback\nself-interference (SI) can be effectively suppressed. The inherent interference\nmitigation capabilities of the emerging fluid antenna system (FAS) technology\nmake it a promising candidate for addressing the SI challenge in IBFD systems.\nThis paper thus proposes a FAS-assisted self-interference cancellation (SIC)\nframework, which leverages a receiver-side FAS to dynamically select an\ninterference-free port. Analytical results include a lower bound and an\napproximation of the residual SI (RSI) power, both derived for rich-scattering\nchannels by considering the joint spatial correlation amongst the FAS ports.\nSimulations of RSI power and forward link rates validate the analysis, showing\nthat the SIC performance improves with the number of FAS ports. Additionally,\nsimulations under practical conditions, such as finite-scattering environments\nand wideband integrated access and backhaul (IAB) channels, reveal that the\nproposed approach offers superior SIC capability and significant forward rate\ngains over conventional IBFD SIC schemes.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.05569v1", "AI": {"title_translation": "流体天线系统辅助的带内全双工通信自干扰消除", "tldr": "该论文提出了一种流体天线系统（FAS）辅助的自干扰消除（SIC）框架，旨在解决带内全双工（IBFD）通信中的自干扰挑战，并通过分析和仿真验证了其有效性。", "motivation": "带内全双工（IBFD）系统有望使频谱效率翻倍，但前提是必须有效抑制环回自干扰（SI）。新兴的流体天线系统（FAS）技术具有固有的干扰缓解能力，使其成为解决IBFD系统中SI挑战的有前景的候选方案。", "method": "本文提出了一种FAS辅助的自干扰消除（SIC）框架，该框架利用接收端的FAS动态选择一个无干扰端口。", "result": "分析结果包括残余自干扰（RSI）功率的下限和近似值，两者都是通过考虑FAS端口间的联合空间相关性，针对丰富散射信道推导得出的。RSI功率和前向链路速率的仿真验证了该分析，表明SIC性能随FAS端口数量的增加而提高。此外，在实际条件，如有限散射环境和宽带集成接入回传（IAB）信道下的仿真表明，所提出的方法比传统的IBFD SIC方案提供了卓越的SIC能力和显著的前向速率增益。", "conclusion": "Not mentioned in abstract", "translation": "带内全双工（IBFD）系统有望使频谱效率比半双工系统翻倍，前提是环回自干扰（SI）能够得到有效抑制。新兴的流体天线系统（FAS）技术固有的干扰缓解能力使其成为解决IBFD系统中SI挑战的有前景的候选方案。因此，本文提出了一种FAS辅助的自干扰消除（SIC）框架，该框架利用接收端的FAS动态选择一个无干扰端口。分析结果包括残余自干扰（RSI）功率的下限和近似值，两者都是通过考虑FAS端口间的联合空间相关性，针对丰富散射信道推导得出的。RSI功率和前向链路速率的仿真验证了该分析，表明SIC性能随FAS端口数量的增加而提高。此外，在实际条件，如有限散射环境和宽带集成接入回传（IAB）信道下的仿真表明，所提出的方法比传统的IBFD SIC方案提供了卓越的SIC能力和显著的前向速率增益。", "summary": "本文提出了一种创新的流体天线系统（FAS）辅助自干扰消除（SIC）框架，旨在解决带内全双工（IBFD）通信中自干扰（SI）的挑战。该框架利用接收端FAS动态选择无干扰端口，并通过分析和仿真验证了其有效性。结果表明，所提出的方法在抑制残余自干扰和提高前向链路速率方面优于传统方案。", "keywords": "流体天线系统, 自干扰消除, 带内全双工, 频谱效率, 残余自干扰", "comments": "该论文的创新点在于将流体天线系统（FAS）应用于带内全双工（IBFD）通信中的自干扰消除（SIC），利用FAS动态选择无干扰端口的能力来提高系统性能。其重要性在于为实现IBFD系统预期的频谱效率翻倍提供了新的解决方案，并通过仿真证明了其在实际条件下的优越性。"}}
{"id": "2506.05427", "title": "MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction", "authors": ["Zishan Shu", "Yufan Deng", "Hongyu Zhang", "Zhiwei Nie", "Jie Chen"], "summary": "Activity cliff prediction is a critical task in drug discovery and material\ndesign. Existing computational methods are limited to handling single binding\ntargets, which restricts the applicability of these prediction models. In this\npaper, we present the Multi-Grained Target Perception network (MTPNet) to\nincorporate the prior knowledge of interactions between the molecules and their\ntarget proteins. Specifically, MTPNet is a unified framework for activity cliff\nprediction, which consists of two components: Macro-level Target Semantic (MTS)\nguidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet\ndynamically optimizes molecular representations through multi-grained protein\nsemantic conditions. To our knowledge, it is the first time to employ the\nreceptor proteins as guiding information to effectively capture critical\ninteraction details. Extensive experiments on 30 representative activity cliff\ndatasets demonstrate that MTPNet significantly outperforms previous approaches,\nachieving an average RMSE improvement of 18.95% on top of several mainstream\nGNN architectures. Overall, MTPNet internalizes interaction patterns through\nconditional deep learning to achieve unified predictions of activity cliffs,\nhelping to accelerate compound optimization and design. Codes are available at:\nhttps://github.com/ZishanShu/MTPNet.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05427v1", "AI": {"title_translation": "MTPNet: 多粒度目标感知统一活性悬崖预测", "tldr": "MTPNet是一个多粒度目标感知网络，通过整合分子与其靶蛋白的相互作用先验知识，解决了现有计算方法在处理单一结合靶点方面的局限性，实现了统一的活性悬崖预测，并在实验中显著优于现有方法。", "motivation": "现有的计算方法在处理单一结合靶点方面存在局限性，这限制了这些预测模型的适用性。", "method": "MTPNet是一个统一的活性悬崖预测框架，包含两个组件：宏观层面目标语义（MTS）指导和微观层面口袋语义（MPS）指导。通过这种方式，MTPNet通过多粒度蛋白质语义条件动态优化分子表示。这是首次利用受体蛋白作为指导信息来有效捕获关键相互作用细节。", "result": "在30个代表性活性悬崖数据集上的大量实验表明，MTPNet显著优于以前的方法，在几种主流GNN架构的基础上平均RMSE提高了18.95%。", "conclusion": "MTPNet通过条件深度学习内化相互作用模式，实现活性悬崖的统一预测，有助于加速化合物的优化和设计。", "translation": "活性悬崖预测是药物发现和材料设计中的一项关键任务。现有的计算方法仅限于处理单一结合靶点，这限制了这些预测模型的适用性。在本文中，我们提出了多粒度目标感知网络（MTPNet），以整合分子与其靶蛋白之间相互作用的先验知识。具体而言，MTPNet是一个统一的活性悬崖预测框架，由两个组件组成：宏观层面目标语义（MTS）指导和微观层面口袋语义（MPS）指导。通过这种方式，MTPNet通过多粒度蛋白质语义条件动态优化分子表示。据我们所知，这是首次利用受体蛋白作为指导信息来有效捕获关键相互作用细节。在30个代表性活性悬崖数据集上的大量实验表明，MTPNet显著优于以前的方法，在几种主流GNN架构的基础上平均RMSE提高了18.95%。总的来说，MTPNet通过条件深度学习内化相互作用模式，实现活性悬崖的统一预测，有助于加速化合物的优化和设计。代码可在https://github.com/ZishanShu/MTPNet获取。", "summary": "本论文提出了MTPNet，一个多粒度目标感知网络，旨在解决药物发现和材料设计中活性悬崖预测现有方法仅限于单一结合靶点的问题。MTPNet通过宏观层面目标语义和微观层面口袋语义的指导，动态优化分子表示，并首次利用受体蛋白作为指导信息。实验结果表明，MTPNet在30个活性悬崖数据集上显著优于现有方法，平均RMSE提高了18.95%，从而实现了活性悬崖的统一预测，加速了化合物的优化和设计。", "keywords": "活性悬崖预测, 药物发现, 多粒度目标感知, MTPNet, 深度学习", "comments": "该论文的创新点在于首次将受体蛋白作为指导信息引入活性悬崖预测模型，通过多粒度语义感知来优化分子表示，从而克服了现有方法处理单一结合靶点的局限性。其统一的预测框架和显著的性能提升显示了其在药物发现和材料设计领域的潜在重要性。"}}
{"id": "2506.05693", "title": "Resilient Auto-Scaling of Microservice Architectures with Efficient Resource Management", "authors": ["Hussain Ahmad", "Christoph Treude", "Markus Wagner", "Claudia Szabo"], "summary": "Horizontal Pod Auto-scalers (HPAs) are crucial for managing resource\nallocation in microservice architectures to handle fluctuating workloads.\nHowever, traditional HPAs fail to address resource disruptions caused by\nfaults, cyberattacks, maintenance, and other operational challenges. These\ndisruptions result in resource wastage, service unavailability, and HPA\nperformance degradation. To address these challenges, we extend our prior work\non Smart HPA and propose SecureSmart HPA, which offers resilient and\nresource-efficient auto-scaling for microservice architectures. SecureSmart HPA\nmonitors microservice resource demands, detects disruptions, evaluates resource\nwastage, and dynamically adjusts scaling decisions to enhance the resilience of\nauto-scaling operations. Furthermore, SecureSmart HPA enables resource sharing\namong microservices, optimizing scaling efficiency in resource-constrained\nenvironments. Experimental evaluation at varying disruption severities, with\n25%, 50%, and 75% resource wastage, demonstrates that SecureSmart HPA performs\neffectively across different levels of disruptions. It achieves up to a 57.2%\nreduction in CPU overutilization and a 51.1% increase in resource allocation\ncompared to Smart HPA, highlighting its ability to deliver resilient and\nefficient auto-scaling operations in volatile and resource-constrained\nenvironments.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/pdf/2506.05693v1", "AI": {"title_translation": "具有高效资源管理的微服务架构弹性自动扩缩容", "tldr": "SecureSmart HPA通过监控资源需求、检测中断和动态调整扩缩容决策，为微服务架构提供弹性且资源高效的自动扩缩容，解决了传统HPA在资源中断时的不足。", "motivation": "传统水平Pod自动扩缩容（HPAs）在处理由故障、网络攻击、维护和其他操作挑战引起的资源中断时存在不足，导致资源浪费、服务不可用和HPA性能下降。", "method": "本文扩展了Smart HPA，提出了SecureSmart HPA。SecureSmart HPA通过监控微服务资源需求、检测中断、评估资源浪费，并动态调整扩缩容决策来增强自动扩缩容操作的弹性。此外，SecureSmart HPA还支持微服务之间的资源共享，以优化资源受限环境中的扩缩容效率。", "result": "在25%、50%和75%资源浪费的不同中断严重程度下进行实验评估表明，SecureSmart HPA在不同程度的中断下均表现出色。与Smart HPA相比，它将CPU过度利用率降低了57.2%，资源分配增加了51.1%。", "conclusion": "SecureSmart HPA能够提供在波动和资源受限环境中具有弹性和高效的自动扩缩容操作。", "translation": "水平Pod自动扩缩容（HPAs）对于管理微服务架构中的资源分配以处理波动的工作负载至关重要。然而，传统HPAs未能解决由故障、网络攻击、维护和其他操作挑战引起的资源中断。这些中断导致资源浪费、服务不可用和HPA性能下降。为了解决这些挑战，我们在Smart HPA的先前工作基础上进行了扩展，并提出了SecureSmart HPA，它为微服务架构提供了弹性且资源高效的自动扩缩容。SecureSmart HPA监控微服务资源需求，检测中断，评估资源浪费，并动态调整扩缩容决策，以增强自动扩缩容操作的弹性。此外，SecureSmart HPA还支持微服务之间的资源共享，优化资源受限环境中的扩缩容效率。在25%、50%和75%资源浪费的不同中断严重程度下进行的实验评估表明，SecureSmart HPA在不同程度的中断下均表现出色。与Smart HPA相比，它将CPU过度利用率降低了57.2%，资源分配增加了51.1%，突显了其在波动和资源受限环境中提供弹性且高效自动扩缩容操作的能力。", "summary": "本论文提出了SecureSmart HPA，一个针对微服务架构的弹性且资源高效的自动扩缩容方案。它旨在解决传统水平Pod自动扩缩容（HPAs）在面对故障、网络攻击等资源中断时的不足，这些不足会导致资源浪费和服务中断。SecureSmart HPA通过监控资源需求、检测中断、评估资源浪费并动态调整扩缩容决策来增强弹性，并通过资源共享优化效率。实验结果表明，SecureSmart HPA显著降低了CPU过度利用率并增加了资源分配，证明其在波动和资源受限环境中表现优异。", "keywords": "微服务架构, 自动扩缩容, 弹性, 资源管理, SecureSmart HPA", "comments": "该论文的创新点在于提出了SecureSmart HPA，它在现有Smart HPA的基础上，特别关注了微服务架构中资源中断（如故障和攻击）下的弹性自动扩缩容问题。通过动态调整扩缩容决策和实现资源共享，该方法有效提升了资源利用率和服务的可用性，对于提高云原生应用在复杂环境下的韧性具有重要意义。"}}
{"id": "2506.05699", "title": "Evaluating AI-Powered Learning Assistants in Engineering Higher Education: Student Engagement, Ethical Challenges, and Policy Implications", "authors": ["Ramteja Sajja", "Yusuf Sermet", "Brian Fodale", "Ibrahim Demir"], "summary": "As generative AI tools become increasingly integrated into higher education,\nunderstanding how students interact with and perceive these technologies is\nessential for responsible and effective adoption. This study evaluates the use\nof the Educational AI Hub, an AI-powered learning framework, in undergraduate\ncivil and environmental engineering courses at a large R1 public university.\nUsing a mixed-methods approach that combines pre- and post-surveys, system\nusage logs, and qualitative analysis of the open-ended prompts and questions\nstudents posed to the AI chatbot, the research explores students' perceptions\nof trust, ethical concerns, usability, and learning outcomes. Findings reveal\nthat students appreciated the AI assistant for its convenience and comfort,\nwith nearly half reporting greater ease in using the AI tool compared to\nseeking help from instructors or teaching assistants. The tool was seen as most\nhelpful for completing homework and understanding course concepts, though\nperceptions of its instructional quality were mixed. Ethical concerns emerged\nas a key barrier to full engagement: while most students viewed AI use as\nethically acceptable, many expressed uncertainties about institutional policies\nand apprehension about potential academic misconduct. This study contributes to\nthe growing body of research on AI in education by highlighting the importance\nof usability, policy clarity, and faculty guidance in fostering meaningful AI\nengagement. The findings suggest that while students are ready to embrace AI as\na supplement to human instruction, thoughtful integration and transparent\ninstitutional frameworks are critical for ensuring student confidence, trust,\nand learning effectiveness.", "comment": "26 pages, 10 Figures, 6 Tables", "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.05699v1", "AI": {"title_translation": "评估工程高等教育中AI驱动的学习助手：学生参与度、伦理挑战和政策影响", "tldr": "学生普遍接受AI学习助手，认为其方便且有助于学习，但对伦理问题和政策缺乏明确性感到担忧，需要更清晰的制度框架和指导。", "motivation": "随着生成式AI工具日益融入高等教育，理解学生如何与这些技术互动并感知它们对于负责任和有效采用至关重要。", "method": "采用混合方法，结合了前/后调查、系统使用日志以及对学生向AI聊天机器人提出的开放式提示和问题的定性分析。研究评估了名为“教育AI中心”的AI驱动学习框架在本科土木与环境工程课程中的使用。", "result": "学生认为AI助手方便舒适，近一半学生觉得使用AI工具比向老师或助教寻求帮助更容易；该工具在完成作业和理解课程概念方面最有帮助，但对其教学质量的看法不一；伦理问题是全面参与的主要障碍，许多学生对机构政策和潜在学术不端行为表示不确定和担忧。", "conclusion": "尽管学生愿意将AI作为人类教学的补充，但深思熟虑的整合和透明的制度框架对于确保学生的信心、信任和学习效率至关重要。研究强调了可用性、政策清晰度和教师指导在促进有意义的AI参与中的重要性。", "translation": "随着生成式AI工具日益融入高等教育，了解学生如何与这些技术互动并感知它们对于负责任和有效采用至关重要。本研究评估了在大型R1公立大学的本科土木与环境工程课程中，AI驱动的学习框架“教育AI中心”的使用情况。研究采用混合方法，结合了前/后调查、系统使用日志以及对学生向AI聊天机器人提出的开放式提示和问题的定性分析，探讨了学生对信任、伦理问题、可用性和学习成果的看法。研究结果显示，学生赞赏AI助手的便利性和舒适性，近一半的学生表示使用AI工具比向教师或助教寻求帮助更容易。该工具被认为在完成作业和理解课程概念方面最有帮助，尽管对其教学质量的看法褒贬不一。伦理问题成为全面参与的关键障碍：虽然大多数学生认为使用AI在伦理上可以接受，但许多人对机构政策表示不确定，并对潜在的学术不端行为感到担忧。本研究通过强调可用性、政策清晰度和教师指导在促进有意义的AI参与中的重要性，为教育领域AI日益增长的研究做出了贡献。研究结果表明，尽管学生已准备好将AI作为人类教学的补充，但深思熟虑的整合和透明的制度框架对于确保学生的信心、信任和学习效率至关重要。", "summary": "本研究评估了在工程高等教育中使用AI驱动的学习助手（“教育AI中心”），通过混合方法探讨了学生对其信任、伦理、可用性和学习成果的看法。结果显示学生认为AI助手方便且有助于学习，但对其教学质量看法不一，且伦理问题和政策不确定性是主要障碍。研究强调了可用性、清晰政策和教师指导对促进AI有效整合的重要性，指出透明的制度框架对于确保学生信心和学习效率至关重要。", "keywords": "AI学习助手, 高等教育, 学生参与, 伦理挑战, 政策影响", "comments": "这篇论文强调了AI在高等教育中实际应用的关键挑战，特别是学生对伦理和政策的担忧。其混合研究方法提供了对学生视角的多维度洞察，有助于教育机构制定更明智的AI采用策略。创新点在于不仅关注技术效果，更深入探讨了人机交互中的信任和伦理维度。"}}
{"id": "2506.05382", "title": "How stealthy is stealthy? Studying the Efficacy of Black-Box Adversarial Attacks in the Real World", "authors": ["Francesco Panebianco", "Mario D'Onghia", "Stefano Zanero aand Michele Carminati"], "summary": "Deep learning systems, critical in domains like autonomous vehicles, are\nvulnerable to adversarial examples (crafted inputs designed to mislead\nclassifiers). This study investigates black-box adversarial attacks in computer\nvision. This is a realistic scenario, where attackers have query-only access to\nthe target model. Three properties are introduced to evaluate attack\nfeasibility: robustness to compression, stealthiness to automatic detection,\nand stealthiness to human inspection. State-of-the-Art methods tend to\nprioritize one criterion at the expense of others. We propose ECLIPSE, a novel\nattack method employing Gaussian blurring on sampled gradients and a local\nsurrogate model. Comprehensive experiments on a public dataset highlight\nECLIPSE's advantages, demonstrating its contribution to the trade-off between\nthe three properties.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05382v1", "AI": {"title_translation": "隐蔽性有多强？研究黑盒对抗性攻击在现实世界中的有效性", "tldr": "本研究调查了黑盒对抗性攻击在计算机视觉中的有效性。论文引入了三个评估攻击可行性的属性：对压缩的鲁棒性、对自动检测的隐蔽性以及对人工检查的隐蔽性。提出了一种名为ECLIPSE的新型攻击方法，并通过实验证明其在这些属性的权衡方面具有优势。", "motivation": "深度学习系统，在自动驾驶等领域至关重要，但易受对抗性样本（旨在误导分类器的精心制作的输入）的攻击。本研究旨在调查现实世界中黑盒对抗性攻击的有效性，并解决现有先进方法在攻击可行性的不同属性之间存在权衡的问题。", "method": "本研究调查了计算机视觉中的黑盒对抗性攻击，其中攻击者只能查询目标模型。引入了三个属性来评估攻击可行性：对压缩的鲁棒性、对自动检测的隐蔽性以及对人工检查的隐蔽性。论文提出了一种名为ECLIPSE的新颖攻击方法，该方法采用对采样梯度进行高斯模糊和使用局部替代模型。", "result": "在公共数据集上的综合实验突出了ECLIPSE的优势，证明了它在攻击可行性的三个属性（对压缩的鲁棒性、对自动检测的隐蔽性、对人工检查的隐蔽性）之间的权衡方面做出了贡献。", "conclusion": "Not mentioned in abstract", "translation": "深度学习系统在自动驾驶等领域至关重要，但易受对抗性样本（旨在误导分类器的精心制作的输入）的攻击。本研究调查了计算机视觉中的黑盒对抗性攻击，这是一种现实场景，攻击者只能查询目标模型。引入了三个属性来评估攻击可行性：对压缩的鲁棒性、对自动检测的隐蔽性以及对人工检查的隐蔽性。现有先进方法往往以牺牲其他标准为代价来优先考虑一个标准。我们提出了ECLIPSE，一种新颖的攻击方法，采用对采样梯度进行高斯模糊和使用局部替代模型。在公共数据集上的综合实验突出了ECLIPSE的优势，证明了它在三个属性之间的权衡方面做出了贡献。", "summary": "本研究探讨了在现实世界场景中黑盒对抗性攻击的有效性，其中深度学习系统易受对抗性样本的影响。论文引入了评估攻击可行性的三个关键属性：对压缩的鲁棒性、对自动检测的隐蔽性以及对人工检查的隐蔽性。为了解决现有方法在这些属性之间权衡的不足，研究提出了一种名为ECLIPSE的新型攻击方法，该方法结合了对采样梯度进行高斯模糊和局部替代模型。实验结果表明，ECLIPSE在这些属性的权衡方面表现出显著优势。", "keywords": "黑盒对抗性攻击, 对抗性样本, 深度学习, 计算机视觉, ECLIPSE", "comments": "Not mentioned in abstract"}}
{"id": "2506.06032", "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio García Castañeda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "cate": "cs.MA", "url": "http://arxiv.org/pdf/2506.06032v1", "AI": {"title_translation": "在时空复杂公共物品供给博弈中建模人类声誉寻求行为", "tldr": "本研究使用多智能体强化学习（MARL）在“清理”公共物品博弈中模拟人类群体行为，发现声誉追踪而非匿名性促使人类和AI代理合作，且两者都采用轮流策略。", "motivation": "多智能体强化学习（MARL）算法在模拟复杂社会行为方面很有用，但尚未得到真实人类参与者实验室实验的经验支持。本研究旨在验证MARL在模拟人类群体行为方面的有效性，尤其是在声誉追踪对合作的影响方面。", "method": "本研究通过一个名为“清理”（Clean Up）的时空复杂公共物品供给博弈来演示多智能体强化学习如何模拟群体行为。实验包括真实人类参与者和新的基于声誉合作的MARL模型，并比较了可识别和匿名条件下的表现。", "result": "人类群体在能够识别并追踪声誉时能在“清理”博弈中成功，但在匿名条件下失败。新的基于声誉合作的MARL模型在可识别和匿名条件下也表现出相同的差异。此外，人类群体和人工代理群体都通过轮流策略解决了问题，尽管有其他选择。", "conclusion": "本研究结果强调了使用多智能体强化学习来模拟复杂环境中人类社会行为的益处。", "translation": "多智能体强化学习算法在模拟对于博弈论等其他理论方法而言过于复杂的社会行为设置中非常有用。然而，它们尚未得到真实人类参与者实验室实验的经验支持。在这项工作中，我们展示了多智能体强化学习如何在名为“清理”的时空复杂公共物品供给博弈中模拟群体行为。我们发现，当人类群体能够识别彼此并随时间追踪声誉时，他们在“清理”中取得成功，但在匿名条件下则失败。一个新的基于声誉合作的多智能体强化学习模型也展示了可识别和匿名条件下的相同差异。此外，人类群体和人工代理群体都通过轮流策略解决了问题，尽管有其他选择。我们的结果突出了使用多智能体强化学习在复杂环境中模拟人类社会行为的益处。", "summary": "本研究探讨了在时空复杂的公共物品供给博弈“清理”中，多智能体强化学习（MARL）如何有效模拟人类群体行为。研究发现，无论是人类群体还是MARL模型，在能够追踪声誉的条件下都能成功合作，而在匿名条件下则失败。此外，人类和人工智能代理都倾向于通过轮流策略来解决问题。这表明MARL是建模复杂社会行为的有效工具。", "keywords": "多智能体强化学习, 声誉, 公共物品博弈, 社会行为, 合作", "comments": "本文的创新之处在于首次通过实验室实验为多智能体强化学习在模拟人类社会行为方面的应用提供了经验支持，尤其是在声誉机制对合作的影响方面。其重要性在于为理解复杂社会环境中的合作机制提供了新的视角，并验证了MARL作为行为模拟工具的潜力。"}}
{"id": "2506.05653", "title": "Towards Autonomous In-situ Soil Sampling and Mapping in Large-Scale Agricultural Environments", "authors": ["Thien Hoang Nguyen", "Erik Muller", "Michael Rubin", "Xiaofei Wang", "Fiorella Sibona", "Salah Sukkarieh"], "summary": "Traditional soil sampling and analysis methods are labor-intensive,\ntime-consuming, and limited in spatial resolution, making them unsuitable for\nlarge-scale precision agriculture. To address these limitations, we present a\nrobotic solution for real-time sampling, analysis and mapping of key soil\nproperties. Our system consists of two main sub-systems: a Sample Acquisition\nSystem (SAS) for precise, automated in-field soil sampling; and a Sample\nAnalysis Lab (Lab) for real-time soil property analysis. The system's\nperformance was validated through extensive field trials at a large-scale\nAustralian farm. Experimental results show that the SAS can consistently\nacquire soil samples with a mass of 50g at a depth of 200mm, while the Lab can\nprocess each sample within 10 minutes to accurately measure pH and\nmacronutrients. These results demonstrate the potential of the system to\nprovide farmers with timely, data-driven insights for more efficient and\nsustainable soil management and fertilizer application.", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05653v1", "AI": {"title_translation": "大规模农业环境中自主原位土壤采样与测绘的展望", "tldr": "本文提出了一种机器人系统，用于大规模农业环境中土壤的实时采样、分析和测绘，以解决传统方法的局限性。", "motivation": "传统土壤采样和分析方法劳动强度大、耗时且空间分辨率有限，不适用于大规模精准农业。", "method": "本文提出了一种机器人解决方案，用于关键土壤特性的实时采样、分析和测绘。该系统由两个主要子系统组成：用于精确自动化田间土壤采样的样品采集系统（SAS）；以及用于实时土壤特性分析的样品分析实验室（Lab）。", "result": "实验结果表明，SAS可以持续采集200毫米深度、50克质量的土壤样品，而Lab可以在10分钟内处理每个样品，并准确测量pH值和常量营养素。", "conclusion": "该系统有望为农民提供及时的数据驱动洞察，以实现更高效和可持续的土壤管理和施肥。", "translation": "传统土壤采样和分析方法劳动强度大、耗时且空间分辨率有限，使其不适用于大规模精准农业。为了解决这些局限性，我们提出了一种机器人解决方案，用于关键土壤特性的实时采样、分析和测绘。我们的系统由两个主要子系统组成：用于精确、自动化田间土壤采样的样品采集系统（SAS）；以及用于实时土壤特性分析的样品分析实验室（Lab）。该系统通过在澳大利亚一个大型农场的广泛田间试验进行了性能验证。实验结果表明，SAS可以持续采集200毫米深度、50克质量的土壤样品，而Lab可以在10分钟内处理每个样品，以准确测量pH值和常量营养素。这些结果表明该系统有潜力为农民提供及时、数据驱动的见解，以实现更高效和可持续的土壤管理和施肥。", "summary": "本文提出了一种针对大规模农业环境的机器人系统，旨在解决传统土壤采样和分析方法的局限性。该系统包含一个用于精确采样的样品采集系统（SAS）和一个用于实时分析的样品分析实验室（Lab）。通过在澳大利亚农场进行的大规模田间试验，验证了系统性能，结果显示SAS能稳定采集土壤样品，Lab能快速准确地测量pH值和常量营养素。该系统有望为精准农业提供及时的数据支持。", "keywords": "土壤采样, 机器人, 精准农业, 实时分析, 土壤管理", "comments": "该论文提出了一种创新的机器人解决方案，用于解决大规模精准农业中土壤采样和分析的效率问题。其核心创新在于将自动化采样与实时分析相结合，显著提高了土壤数据获取的时效性和空间分辨率，对于提升农业可持续管理具有重要意义。"}}
{"id": "2506.05361", "title": "Scalable Generation of Spatial Transcriptomics from Histology Images via Whole-Slide Flow Matching", "authors": ["Tinglin Huang", "Tianyu Liu", "Mehrtash Babadi", "Wengong Jin", "Rex Ying"], "summary": "Spatial transcriptomics (ST) has emerged as a powerful technology for\nbridging histology imaging with gene expression profiling. However, its\napplication has been limited by low throughput and the need for specialized\nexperimental facilities. Prior works sought to predict ST from whole-slide\nhistology images to accelerate this process, but they suffer from two major\nlimitations. First, they do not explicitly model cell-cell interaction as they\nfactorize the joint distribution of whole-slide ST data and predict the gene\nexpression of each spot independently. Second, their encoders struggle with\nmemory constraints due to the large number of spots (often exceeding 10,000) in\ntypical ST datasets. Herein, we propose STFlow, a flow matching generative\nmodel that considers cell-cell interaction by modeling the joint distribution\nof gene expression of an entire slide. It also employs an efficient slide-level\nencoder with local spatial attention, enabling whole-slide processing without\nexcessive memory overhead. On the recently curated HEST-1k and STImage-1K4M\nbenchmarks, STFlow substantially outperforms state-of-the-art baselines and\nachieves over 18% relative improvements over the pathology foundation models.", "comment": "Accepted at ICML 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05361v1", "AI": {"title_translation": "组织图像全玻片流匹配可扩展生成空间转录组学", "tldr": "STFlow使用流匹配模型从组织图像可扩展地生成空间转录组数据，解决了现有方法中细胞间交互建模不足和内存限制的问题，并在基准测试中显著优于现有技术。", "motivation": "空间转录组学（ST）的应用受限于低通量和对专业实验设施的需求。现有从全玻片组织学图像预测ST的方法存在两大局限性：一是未能明确建模细胞间相互作用，独立预测每个点的基因表达；二是编码器在处理大量数据点时面临内存限制。", "method": "本文提出了STFlow，一个流匹配生成模型。该模型通过建模整个玻片基因表达的联合分布来考虑细胞间相互作用。它还采用了一种高效的带局部空间注意力的玻片级编码器，以实现全玻片处理而无需过高的内存开销。", "result": "在HEST-1k和STImage-1K4M基准测试中，STFlow显著优于最先进的基线模型，并比病理学基础模型相对提高了18%以上。", "conclusion": "STFlow有效解决了现有从组织图像生成空间转录组数据的挑战，通过考虑细胞间相互作用和优化内存效率，实现了可扩展且高性能的预测，并在基准测试中表现出卓越的性能。", "translation": "空间转录组学（ST）已成为连接组织学成像与基因表达谱的强大技术。然而，其应用受到低通量和对专业实验设施需求的限制。先前的工作试图从全玻片组织学图像预测ST以加速这一过程，但它们存在两个主要局限性。首先，它们没有明确地建模细胞间相互作用，因为它们分解了全玻片ST数据的联合分布并独立预测每个点的基因表达。其次，由于典型ST数据集中存在大量点（通常超过10,000个），它们的编码器面临内存限制。在此，我们提出了STFlow，一个流匹配生成模型，通过建模整个玻片基因表达的联合分布来考虑细胞间相互作用。它还采用了一种高效的带局部空间注意力的玻片级编码器，使得在没有过度内存开销的情况下进行全玻片处理。在最近整理的HEST-1k和STImage-1K4M基准测试中，STFlow显著优于最先进的基线，并比病理学基础模型相对提高了18%以上。", "summary": "本文提出了STFlow，一种基于流匹配的生成模型，旨在解决从组织图像生成空间转录组数据时现有方法的局限性。STFlow通过建模整个玻片的基因表达联合分布来考虑细胞间相互作用，并采用高效的玻片级编码器以减少内存开销。实验结果表明，STFlow在HEST-1k和STImage-1K4M基准测试中显著超越了现有技术和病理学基础模型。", "keywords": "空间转录组学, 组织图像, 流匹配, 全玻片处理, 基因表达预测", "comments": "该论文提出了一种创新的流匹配生成模型STFlow，解决了从组织图像预测空间转录组学数据中细胞间相互作用建模不足和内存效率低下的关键问题。其全玻片处理能力和显著的性能提升，对于推动空间转录组学在生物医学研究中的应用具有重要意义。"}}
{"id": "2506.05614", "title": "Which Prompting Technique Should I Use? An Empirical Investigation of Prompting Techniques for Software Engineering Tasks", "authors": ["E. G. Santana Jr", "Gabriel Benjamin", "Melissa Araujo", "Harrison Santos", "David Freitas", "Eduardo Almeida", "Paulo Anselmo da M. S. Neto", "Jiawei Li", "Jina Chun", "Iftekhar Ahmed"], "summary": "A growing variety of prompt engineering techniques has been proposed for\nLarge Language Models (LLMs), yet systematic evaluation of each technique on\nindividual software engineering (SE) tasks remains underexplored. In this\nstudy, we present a systematic evaluation of 14 established prompt techniques\nacross 10 SE tasks using four LLM models. As identified in the prior\nliterature, the selected prompting techniques span six core dimensions\n(Zero-Shot, Few-Shot, Thought Generation, Ensembling, Self-Criticism, and\nDecomposition). They are evaluated on tasks such as code generation, bug\nfixing, and code-oriented question answering, to name a few. Our results show\nwhich prompting techniques are most effective for SE tasks requiring complex\nlogic and intensive reasoning versus those that rely more on contextual\nunderstanding and example-driven scenarios. We also analyze correlations\nbetween the linguistic characteristics of prompts and the factors that\ncontribute to the effectiveness of prompting techniques in enhancing\nperformance on SE tasks. Additionally, we report the time and token consumption\nfor each prompting technique when applied to a specific task and model,\noffering guidance for practitioners in selecting the optimal prompting\ntechnique for their use cases.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05614v1", "AI": {"title_translation": "我应该使用哪种提示技术？软件工程任务中提示技术的实证研究", "tldr": "本研究系统地评估了14种提示技术在10个软件工程任务和4个大型语言模型上的表现，以确定最佳选择并分析其有效性因素，为从业者提供指导。", "motivation": "尽管针对大型语言模型（LLMs）提出了种类日益增多的提示工程技术，但对每种技术在各个软件工程（SE）任务上的系统性评估仍未得到充分探索。", "method": "本研究对14种已建立的提示技术在10个软件工程任务上使用四种大型语言模型进行了系统性评估。所选的提示技术涵盖六个核心维度（零样本、少样本、思维生成、集成、自我批评和分解），并在代码生成、错误修复和面向代码的问答等任务上进行评估。此外，还分析了提示的语言特征与提示技术在提升软件工程任务性能方面的有效性因素之间的关联，并报告了每种提示技术在特定任务和模型上的耗时和token消耗。", "result": "研究结果揭示了对于需要复杂逻辑和密集推理的软件工程任务，以及那些更依赖上下文理解和示例驱动场景的任务，哪些提示技术最为有效。研究还分析了提示的语言特征与提示技术有效性因素之间的关联，并报告了每种提示技术在应用于特定任务和模型时的耗时和token消耗。", "conclusion": "研究结果为从业者在选择适合其用例的最佳提示技术方面提供了指导。", "translation": "针对大型语言模型（LLMs），人们提出了种类日益增多的提示工程技术，然而，对每种技术在各个软件工程（SE）任务上的系统性评估仍未得到充分探索。在本研究中，我们对14种已建立的提示技术在10个软件工程任务上使用四个LLM模型进行了系统性评估。如先前文献所述，所选的提示技术涵盖了六个核心维度（零样本、少样本、思维生成、集成、自我批评和分解）。它们在诸如代码生成、错误修复和面向代码的问答等任务上进行了评估。我们的结果显示，哪些提示技术对于需要复杂逻辑和密集推理的软件工程任务最有效，而哪些技术更适用于依赖上下文理解和示例驱动的场景。我们还分析了提示的语言特征与有助于提升软件工程任务性能的提示技术有效性因素之间的关联。此外，我们还报告了每种提示技术在应用于特定任务和模型时的耗时和token消耗，为从业者选择适合其用例的最佳提示技术提供了指导。", "summary": "本论文系统地评估了14种提示工程技术在10个软件工程任务上使用四个大型语言模型的效果。它确定了对于不同类型软件工程任务（复杂逻辑与上下文理解）最有效的技术，分析了影响其有效性的因素，并报告了资源消耗，为从业者提供了实用的指导。", "keywords": "提示工程, 大型语言模型, 软件工程, 实证研究, 提示技术", "comments": "该论文解决了大型语言模型在软件工程应用中一个关键的实际问题：如何选择正确的提示技术。其对多种技术、任务和模型进行的系统性实证研究，使得研究结果具有鲁棒性，对从业者非常有价值。对语言特征和资源消耗的分析进一步增加了研究的深度。"}}
{"id": "2506.05868", "title": "Detecting Coordination on Short-Video Platforms: The Challenge of Multimodality and Complex Similarity on TikTok", "authors": ["Inga K. Wohlert", "Davide Vega", "Matteo Magnani", "Alexandra Sergerberg"], "summary": "Research on online coordinated behaviour has predominantly focused on\ntext-based social media platforms, where coordination manifests clearly through\nthe frequent posting of identical hyperlinks or the frequent re-sharing of the\nsame textual content by the same group of users. However, the rise of\nshort-video platforms like TikTok introduces distinct challenges, by supporting\nintegrated multimodality within posts and complex similarity between them. In\nthis paper, we propose an approach to detecting coordination that addresses\nthese characteristic challenges. Our methodology, based on multilayer network\nanalysis, is tailored to capture coordination across multiple modalities,\nincluding video, audio, and text, and explicitly handles complex forms of\nsimilarity inherent in video and audio content. We test this approach on\npolitical videos posted on TikTok and extracted via the TikTok researcher API.\nThis application demonstrates the capacity of the approach to identify\ncoordination, while also critically highlighting potential pitfalls and\nlimitations.", "comment": null, "cate": "cs.SI", "url": "http://arxiv.org/pdf/2506.05868v1", "AI": {"title_translation": "在短视频平台检测协同行为：TikTok上多模态和复杂相似性的挑战", "tldr": "本研究提出了一种基于多层网络分析的方法，用于检测TikTok等短视频平台上的协同行为，该方法解决了多模态和复杂相似性带来的挑战，并在政治视频上进行了测试。", "motivation": "以往对在线协同行为的研究主要集中在文本社交媒体平台。然而，TikTok等短视频平台的兴起带来了独特的挑战，因为它们支持帖子中的集成多模态和它们之间复杂的相似性，因此需要新的检测协同行为的方法。", "method": "本研究提出了一种基于多层网络分析的方法来检测协同行为。该方法旨在捕获视频、音频和文本等多种模态的协同，并明确处理视频和音频内容中固有的复杂相似性。", "result": "该方法在从TikTok研究员API提取的政治视频上进行了测试。应用结果表明，该方法能够识别协同行为，同时也批判性地强调了潜在的缺陷和局限性。", "conclusion": "该研究提出了一种在短视频平台上检测协同行为的新方法，并验证了其在识别协同行为方面的能力，但也指出了其局限性，为未来的研究提供了方向。", "translation": "在线协同行为的研究主要集中在基于文本的社交媒体平台，其中协同行为通过同一用户群频繁发布相同的超链接或频繁转发相同的文本内容而清晰地表现出来。然而，TikTok等短视频平台的兴起带来了独特的挑战，通过支持帖子中的集成多模态和它们之间复杂的相似性。在本文中，我们提出了一种解决这些特征性挑战的协同检测方法。我们的方法基于多层网络分析，旨在捕获跨多种模态（包括视频、音频和文本）的协同，并明确处理视频和音频内容中固有的复杂相似性。我们在通过TikTok研究员API提取的TikTok上发布的政治视频上测试了这种方法。此应用程序展示了该方法识别协同的能力，同时也批判性地强调了潜在的缺陷和局限性。", "summary": "本研究针对TikTok等短视频平台的多模态和复杂相似性挑战，提出了一种检测协同行为的新方法。该方法基于多层网络分析，能够整合视频、音频和文本等多种模态信息，并有效处理内容间的复杂相似性。通过在TikTok政治视频上的应用，验证了该方法识别协同行为的有效性，同时也指出了其潜在的局限性。", "keywords": "协同检测, 短视频平台, TikTok, 多模态, 多层网络分析", "comments": "该论文创新性地将多层网络分析应用于短视频平台上的协同行为检测，弥补了现有研究主要集中在文本平台的不足。其重要性在于为理解和识别新兴社交媒体平台上的复杂信息操纵提供了新的工具。论文同时指出方法的局限性，体现了研究的严谨性。"}}
{"id": "2506.05422", "title": "Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference", "authors": ["Andrei T. Patrascu"], "summary": "We introduce a novel learning and planning framework that replaces\ntraditional reward-based optimisation with constructive logical inference. In\nour model, actions, transitions, and goals are represented as logical\npropositions, and decision-making proceeds by building constructive proofs\nunder intuitionistic logic. This method ensures that state transitions and\npolicies are accepted only when supported by verifiable preconditions --\neschewing probabilistic trial-and-error in favour of guaranteed logical\nvalidity. We implement a symbolic agent operating in a structured gridworld,\nwhere reaching a goal requires satisfying a chain of intermediate subgoals\n(e.g., collecting keys to open doors), each governed by logical constraints.\nUnlike conventional reinforcement learning agents, which require extensive\nexploration and suffer from unsafe or invalid transitions, our constructive\nagent builds a provably correct plan through goal chaining, condition tracking,\nand knowledge accumulation. Empirical comparison with Q-learning demonstrates\nthat our method achieves perfect safety, interpretable behaviour, and efficient\nconvergence with no invalid actions, highlighting its potential for safe\nplanning, symbolic cognition, and trustworthy AI. This work presents a new\ndirection for reinforcement learning grounded not in numeric optimisation, but\nin constructive logic and proof theory.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05422v1", "AI": {"title_translation": "通过直觉逻辑和目标链推理的构造性符号强化学习", "tldr": "本文介绍了一种新颖的强化学习框架，用构造性逻辑推理取代了传统的基于奖励的优化，实现了可证明的正确规划和安全行为。", "motivation": "传统的强化学习（RL）方法依赖于基于奖励的优化，需要大量探索，并且可能导致不安全或无效的过渡。本文的动机是开发一种能够保证逻辑有效性和安全性的RL框架。", "method": "本文提出了一种新的学习和规划框架，用构造性逻辑推理取代传统的奖励优化。该模型将动作、转换和目标表示为逻辑命题，并通过在直觉逻辑下构建构造性证明来进行决策。它通过目标链、条件跟踪和知识积累来构建可证明正确的计划，确保只有在可验证的先决条件支持下才接受状态转换和策略。", "result": "与Q-learning的实证比较表明，该方法实现了完美的安全性、可解释的行为和高效的收敛，没有无效动作。", "conclusion": "这项工作为强化学习提供了一个新方向，其基础不是数值优化，而是构造性逻辑和证明论，突出了其在安全规划、符号认知和可信赖人工智能方面的潜力。", "translation": "我们引入了一种新颖的学习和规划框架，它用构造性逻辑推理取代了传统的基于奖励的优化。在我们的模型中，动作、转换和目标被表示为逻辑命题，决策通过在直觉逻辑下构建构造性证明来进行。这种方法确保只有在可验证的先决条件支持下才接受状态转换和策略——摒弃了概率性的试错，转而支持有保证的逻辑有效性。我们实现了一个在结构化网格世界中运行的符号智能体，其中达到一个目标需要满足一系列中间子目标（例如，收集钥匙开门），每个子目标都受逻辑约束。与需要大量探索并遭受不安全或无效转换的传统强化学习智能体不同，我们的构造性智能体通过目标链、条件跟踪和知识积累构建了一个可证明正确的计划。与Q-learning的实证比较表明，我们的方法实现了完美的安全性、可解释的行为和高效的收敛，没有无效动作，突出了其在安全规划、符号认知和可信赖人工智能方面的潜力。这项工作为强化学习提供了一个新方向，其基础不是数值优化，而是构造性逻辑和证明论。", "summary": "本文提出了一种新的强化学习和规划框架，该框架用构造性逻辑推理取代了传统的奖励优化。模型中，动作、转换和目标被表示为逻辑命题，决策通过在直觉逻辑下构建构造性证明来进行，确保了状态转换和策略的逻辑有效性。该框架通过目标链、条件跟踪和知识积累构建可证明正确的计划，并在结构化网格世界中进行了实现。与Q-learning的比较显示，该方法在安全性、可解释性和收敛效率方面表现优越，且无无效动作，为安全规划和可信赖AI提供了新途径。", "keywords": "构造性强化学习, 符号AI, 直觉逻辑, 目标链推理, 可信赖AI", "comments": "这项工作创新性地将构造性逻辑和证明论引入强化学习领域，摆脱了传统数值优化的范式。其核心优势在于能够保证行为的逻辑有效性和安全性，解决了传统RL中探索效率低下和不安全动作的问题。这对于需要高可靠性和可解释性的AI应用（如自动驾驶、医疗诊断）具有重要意义。该方法通过符号表示和逻辑推理，为实现可信赖AI和符号认知提供了新的视角。"}}
{"id": "2506.06074", "title": "On the Suitability of Wi-Fi for Interconnecting Moving Equipment in Industrial Environments", "authors": ["Pietro Chiavassa", "Stefano Scanzio", "Gianluca Cena"], "summary": "To ensure an unprecedented degree of flexibility, next-generation Industry\n4.0/5.0 production plants increasingly rely on mobile devices, e.g., autonomous\nmobile robots and wearables. In these cases, a major requirement is getting rid\nof cables through the adoption of wireless networks. To this purpose, Wi-Fi is\ncurrently deemed one of the most promising solutions. Achieving reliable\ncommunications over the air for distributed real-time control applications is,\nhowever, not devoid of troubles. In fact, bounded transmission latency must be\nensured for most of the exchanged packets. Moreover, for devices powered on\nbatteries, energy consumption also needs to be taken into account. In this\npaper, a joint simulated analysis of these aspects is carried out to\nquantitatively evaluate what we can practically expect from Wi-Fi technology.", "comment": "preprint accepted, 8 pages, 2025", "cate": "cs.NI", "url": "http://arxiv.org/pdf/2506.06074v1", "AI": {"title_translation": "评估Wi-Fi在工业环境中互联移动设备的适用性", "tldr": "本文通过联合模拟分析，评估了Wi-Fi技术在工业4.0/5.0环境中连接移动设备（如机器人和可穿戴设备）时的可靠性、传输延迟和能耗表现。", "motivation": "工业4.0/5.0生产工厂为实现前所未有的灵活性，日益依赖移动设备（如自主移动机器人和可穿戴设备），因此需要采用无线网络取代有线连接。Wi-Fi被认为是最有前景的解决方案之一，但为分布式实时控制应用实现可靠的无线通信面临挑战，特别是需要确保有界传输延迟和考虑电池供电设备的能耗问题。", "method": "采用联合模拟分析方法，对传输延迟和能耗等关键方面进行定量评估。", "result": "未在摘要中提及具体结果，但指出通过联合模拟分析定量评估了Wi-Fi技术的实际表现。", "conclusion": "未在摘要中提及", "translation": "为了确保前所未有的灵活性，下一代工业4.0/5.0生产工厂日益依赖移动设备，例如自主移动机器人和可穿戴设备。在这种情况下，一个主要要求是通过采用无线网络摆脱电缆。为此，Wi-Fi目前被认为是最有前景的解决方案之一。然而，为分布式实时控制应用实现可靠的无线通信并非没有问题。事实上，大多数交换的数据包必须确保有界传输延迟。此外，对于电池供电的设备，还需要考虑能耗。在本文中，对这些方面进行了联合模拟分析，以定量评估我们可以从Wi-Fi技术中实际期望什么。", "summary": "本文探讨了Wi-Fi技术在工业4.0/5.0环境中互联移动设备的适用性。鉴于下一代工厂对移动设备和无线连接的需求，研究旨在评估Wi-Fi在确保分布式实时控制应用中可靠通信所面临的挑战，特别是传输延迟和能耗问题。研究通过联合模拟分析对这些关键方面进行了定量评估。", "keywords": "Wi-Fi, 工业4.0/5.0, 移动设备, 实时控制, 无线通信", "comments": "本文关注工业4.0/5.0中无线通信的关键需求，特别是移动设备的互联问题。选择Wi-Fi作为研究对象具有现实意义，因为它是一种广泛应用的技术。通过联合模拟分析来量化评估传输延迟和能耗，显示了研究的实用性和针对性。其创新点在于对Wi-Fi在特定工业场景下的实际性能进行定量预测，为工业无线网络部署提供了参考。"}}
{"id": "2506.05637", "title": "Joint User Association and Beamforming Design for ISAC Networks with Large Language Models", "authors": ["Haoyun Li", "Ming Xiao", "Kezhi Wang", "Robert Schober", "Dong In Kim", "Yong Liang Guan"], "summary": "Integrated sensing and communication (ISAC) has been envisioned to play a\nmore important role in future wireless networks. However, the design of ISAC\nnetworks is challenging, especially when there are multiple communication and\nsensing (C\\&S) nodes and multiple sensing targets. We investigate a multi-base\nstation (BS) ISAC network in which multiple BSs equipped with multiple antennas\nsimultaneously provide C\\&S services for multiple ground communication users\n(CUs) and targets. To enhance the overall performance of C\\&S, we formulate a\njoint user association (UA) and multi-BS transmit beamforming optimization\nproblem with the objective of maximizing the total sum rate of all CUs while\nensuring both the minimum target detection and parameter estimation\nrequirements. To efficiently solve the highly non-convex mixed integer\nnonlinear programming (MINLP) optimization problem, we propose an alternating\noptimization (AO)-based algorithm that decomposes the problem into two\nsub-problems, i.e., UA optimization and multi-BS transmit beamforming\noptimization. Inspired by large language models (LLMs) for prediction and\ninference, we propose a unified framework integrating LLMs with convex-based\noptimization methods. First, we propose a comprehensive design of prompt\nengineering, including few-shot, chain of thought, and self-reflection\ntechniques to guide LLMs in solving the binary integer programming UA\noptimization problem. Second, we utilize convex-based optimization methods to\nhandle the non-convex beamforming optimization problem based on fractional\nprogramming (FP), majorization minimization (MM), and the alternating direction\nmethod of multipliers (ADMM) with an optimized UA from LLMs. Numerical results\ndemonstrate that our proposed LLM-enabled AO-based algorithm achieves fast\nconvergence and near upper-bound performance with the GPT-o1 model,\noutperforming various benchmark schemes.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.05637v1", "AI": {"title_translation": "融合大型语言模型的ISAC网络联合用户关联与波束成形设计", "tldr": "论文提出了一种基于LLM的交替优化算法，用于解决ISAC网络中联合用户关联和波束成形问题，实现了快速收敛和接近最优的性能。", "motivation": "ISAC网络设计具有挑战性，尤其是在存在多个通信感知节点和多个感知目标时。为了提升通信和感知性能，需要解决联合用户关联和多基站发射波束成形优化问题。", "method": "提出了一种基于交替优化（AO）的算法，将问题分解为用户关联（UA）优化和多基站发射波束成形优化两个子问题。受LLM的启发，提出一个统一框架，将LLM与基于凸优化的方法结合。具体地，通过提示工程（包括少样本、思维链和自我反思技术）引导LLM解决二值整数规划UA优化问题。然后，利用分数规划（FP）、大化小（MM）和交替方向乘子法（ADMM）等凸优化方法处理非凸波束成形优化问题，并结合LLM优化后的UA。", "result": "数值结果表明，所提出的支持LLM的AO算法实现了快速收敛和接近上限的性能，优于各种基准方案。", "conclusion": "论文成功地提出了一个LLM-enabled的交替优化算法来解决ISAC网络中的联合用户关联和波束成形问题，并在性能上表现出色。", "translation": "综合感知与通信（ISAC）被设想在未来的无线网络中发挥更重要的作用。然而，ISAC网络的设计具有挑战性，特别是当存在多个通信与感知（C&S）节点和多个感知目标时。我们研究了一个多基站（BS）ISAC网络，其中多个配备多天线的基站同时为多个地面通信用户（CU）和目标提供C&S服务。为了提升C&S的整体性能，我们提出了一个联合用户关联（UA）和多基站发射波束成形优化问题，目标是最大化所有CU的总和速率，同时确保最小目标检测和参数估计要求。为了高效地解决高度非凸的混合整数非线性规划（MINLP）优化问题，我们提出了一种基于交替优化（AO）的算法，将其分解为两个子问题，即UA优化和多基站发射波束成形优化。受大型语言模型（LLM）在预测和推理方面的启发，我们提出了一个将LLM与基于凸优化方法相结合的统一框架。首先，我们提出了一个全面的提示工程设计，包括少样本学习、思维链和自我反思技术，以指导LLM解决二值整数规划UA优化问题。其次，我们利用基于凸优化方法处理非凸波束成形优化问题，这些方法基于分数规划（FP）、主次化（MM）和交替方向乘子法（ADMM），并结合LLM优化后的UA。数值结果表明，我们提出的支持LLM的AO算法使用GPT-o1模型实现了快速收敛和接近上限的性能，优于各种基准方案。", "summary": "该论文研究了多基站ISAC网络中的联合用户关联和多基站发射波束成形优化问题，旨在最大化通信用户总速率同时满足感知要求。为解决此非凸MINLP问题，提出了一种基于LLM的交替优化算法。该算法将问题分解为用户关联和波束成形子问题，并利用LLM进行用户关联优化，结合凸优化方法解决波束成形问题。实验结果表明，该方法收敛快且性能接近最优。", "keywords": "ISAC网络, 用户关联, 波束成形, 大型语言模型, 交替优化", "comments": "这篇论文的创新点在于将大型语言模型（LLM）引入到无线通信的优化问题中，特别是结合了提示工程来解决复杂的整数规划问题。这种结合LLM与传统凸优化方法的混合范式为未来无线网络的设计和优化提供了新的思路，展示了LLM在非传统领域解决复杂优化问题的潜力。"}}
{"id": "2506.05428", "title": "Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction", "authors": ["Zhihao Tang", "Chaozhuo Li", "Litian Zhang", "Xi Zhang"], "summary": "Early prediction of Mild Cognitive Impairment (MCI) conversion is hampered by\na trade-off between immediacy--making fast predictions from a single baseline\nsMRI--and accuracy--leveraging longitudinal scans to capture disease\nprogression. We propose MCI-Diff, a diffusion-based framework that synthesizes\nclinically plausible future sMRI representations directly from baseline data,\nachieving both real-time risk assessment and high predictive performance.\nFirst, a multi-task sequence reconstruction strategy trains a shared denoising\nnetwork on interpolation and extrapolation tasks to handle irregular follow-up\nsampling and learn robust latent trajectories. Second, an LLM-driven\n\"linguistic compass\" is introduced for clinical plausibility sampling:\ngenerated feature candidates are quantized, tokenized, and scored by a\nfine-tuned language model conditioned on expected structural biomarkers,\nguiding autoregressive generation toward realistic disease patterns.\nExperiments on ADNI and AIBL cohorts show that MCI-Diff outperforms\nstate-of-the-art baselines, improving early conversion accuracy by 5-12%.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05428v1", "AI": {"title_translation": "带有语言罗盘的扩散模型：引导生成临床合理未来sMRI表征以预测早期MCI转化", "tldr": "MCI-Diff利用扩散模型和语言模型驱动的“语言罗盘”，从基线sMRI数据生成未来表征，提高了早期MCI转化预测的准确性。", "motivation": "早期预测轻度认知障碍（MCI）转化面临即时性（从单一基线sMRI快速预测）与准确性（利用纵向扫描捕捉疾病进展）之间的权衡挑战。", "method": "提出MCI-Diff，一个基于扩散的框架，可直接从基线数据合成临床合理的未来sMRI表征。首先，采用多任务序列重建策略，在插值和外推任务上训练共享去噪网络，以处理不规则的随访采样并学习鲁棒的潜在轨迹。其次，引入LLM驱动的“语言罗盘”进行临床合理性采样：生成的特征候选被量化、标记，并由一个基于预期结构生物标志物进行条件化的微调语言模型进行评分，从而引导自回归生成符合现实疾病模式。", "result": "在ADNI和AIBL队列上的实验表明，MCI-Diff优于现有最先进的基线方法，将早期转化预测准确率提高了5-12%。", "conclusion": "MCI-Diff框架有效解决了早期MCI转化预测中即时性和准确性之间的权衡，显著提高了预测性能。", "translation": "早期预测轻度认知障碍（MCI）转化受到即时性（从单一基线sMRI进行快速预测）与准确性（利用纵向扫描捕捉疾病进展）之间权衡的阻碍。我们提出了MCI-Diff，一个基于扩散的框架，可以直接从基线数据合成临床合理的未来sMRI表征，实现实时风险评估和高预测性能。首先，多任务序列重建策略在插值和外推任务上训练共享去噪网络，以处理不规则的随访采样并学习鲁棒的潜在轨迹。其次，引入了LLM驱动的“语言罗盘”用于临床合理性采样：生成的特征候选被量化、标记，并由一个基于预期结构生物标志物进行条件化的微调语言模型进行评分，从而引导自回归生成符合现实疾病模式。在ADNI和AIBL队列上的实验表明，MCI-Diff优于现有最先进的基线方法，将早期转化准确率提高了5-12%。", "summary": "本文提出MCI-Diff，一个基于扩散的框架，用于早期预测MCI转化。它通过多任务序列重建策略和LLM驱动的“语言罗盘”进行合理性采样，从基线数据合成临床合理的未来sMRI表征。实验表明，MCI-Diff优于现有最先进的方法，将预测准确率提高了5-12%。", "keywords": "MCI转化预测, 扩散模型, sMRI, 语言罗盘, 大型语言模型", "comments": "该论文的创新之处在于将扩散模型与大型语言模型（LLM）相结合，用于生成临床合理的未来sMRI表征，从而解决了早期MCI转化预测中即时性和准确性之间的权衡问题。LLM驱动的“语言罗盘”概念是其核心创新点，确保了生成数据的临床可靠性，对医学图像生成和疾病预测领域具有重要意义。"}}
{"id": "2506.05742", "title": "Malicious node aware wireless multi hop networks: a systematic review of the literature and recommendations for future research", "authors": ["Shahram Pourdehghan", "Nahideh Derakhshanfard"], "summary": "Wireless communication provides great advantages that are not available\nthrough their wired counterparts such as flexibility, ease of deployment and\nuse, cost reductions, and convenience. Wireless multi-hop networks (WMN) do not\nhave any centralized management infrastructure. Wireless multi-hop networks\nhave many benefits since proposed. In such networks when a node wants to send a\npacket to a destination where is not in the transmission range, depend on some\nintermediate nodes. In this type of networks packet sending is in the form of\nmultiple hop until destination and this work is dynamic. Lack of centralized\nmanagement cause that some nodes show malicious function. Malicious nodes are\nthat receive packets and drop them maliciously. These malicious nodes could\nhave many reasons such as hardware failure, software failure or lack of power.\nSuch nodes make multiple packets drop from the network and the performance of\nnetwork strongly decreases. As a result, the throughput of the network\ndecrease, increase end-to-end delay and increase overhead. Therefore, we must\naware from presence of malicious node in the network and do routing based on\nthis awareness. Therefore, this paper aims to study and review the present\nmalicious node detection methods that proposed in literatures. We categorized\nnetworks in groups, including ad hoc networks, MANET, DTN, Opportunistic\nnetworks, WSN, VANET and other wireless networks and compare malicious node\ndetection met", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/pdf/2506.05742v1", "AI": {"title_translation": "恶意节点感知无线多跳网络：文献系统综述及未来研究建议", "tldr": "本文对无线多跳网络中恶意节点检测方法进行了系统综述，并提出了未来研究建议。", "motivation": "无线多跳网络缺乏集中管理，导致恶意节点（如恶意丢弃数据包）的存在，严重降低网络性能（吞吐量下降、端到端延迟增加、开销增加）。因此，必须识别并感知网络中的恶意节点，并基于此进行路由。", "method": "本文旨在研究和综述现有文献中提出的恶意节点检测方法。作者将网络分为不同组（包括ad hoc网络、MANET、DTN、机会网络、WSN、VANET和其他无线网络），并比较了恶意节点检测方法。", "result": "综述了现有的恶意节点检测方法，并对不同类型的无线网络进行了分类和比较。", "conclusion": "必须感知网络中恶意节点的存在并基于此进行路由。", "translation": "无线通信提供了有线通信所不具备的巨大优势，例如灵活性、易于部署和使用、成本降低以及便利性。无线多跳网络（WMN）不具备任何集中管理基础设施。无线多跳网络自提出以来具有许多优点。在此类网络中，当节点想要向不在传输范围内的目的地发送数据包时，需要依赖一些中间节点。在这种类型的网络中，数据包发送以多跳形式进行，直到到达目的地，并且此工作是动态的。缺乏集中管理导致一些节点表现出恶意功能。恶意节点是指恶意接收并丢弃数据包的节点。这些恶意节点可能由多种原因造成，例如硬件故障、软件故障或电力不足。此类节点导致网络中大量数据包丢失，网络性能严重下降。结果是网络吞吐量下降，端到端延迟增加，开销增加。因此，我们必须意识到网络中恶意节点的存在，并基于这种意识进行路由。因此，本文旨在研究和综述文献中提出的现有恶意节点检测方法。我们将网络分为几组，包括ad hoc网络、MANET、DTN、机会网络、WSN、VANET和其他无线网络，并比较了恶意节点检测方法。", "summary": "本文对无线多跳网络中的恶意节点问题进行了系统综述。由于缺乏集中管理，恶意节点会恶意丢弃数据包，导致网络性能显著下降。作者研究并比较了现有文献中提出的恶意节点检测方法，并根据网络类型（如ad hoc网络、MANET、DTN、机会网络、WSN、VANET等）进行了分类。研究强调了在路由过程中考虑恶意节点感知的重要性，并为未来的研究提供了建议。", "keywords": "无线多跳网络, 恶意节点, 系统综述, 节点检测, 网络安全", "comments": "这篇综述论文对于理解无线多跳网络中的安全挑战及其现有解决方案具有重要意义。它系统地分类和比较了不同网络类型下的恶意节点检测方法，为该领域的未来研究提供了清晰的路线图。"}}
{"id": "2506.05487", "title": "A Neural Network Model of Spatial and Feature-Based Attention", "authors": ["Ruoyang Hu", "Robert A. Jacobs"], "summary": "Visual attention is a mechanism closely intertwined with vision and memory.\nTop-down information influences visual processing through attention. We\ndesigned a neural network model inspired by aspects of human visual attention.\nThis model consists of two networks: one serves as a basic processor performing\na simple task, while the other processes contextual information and guides the\nfirst network through attention to adapt to more complex tasks. After training\nthe model and visualizing the learned attention response, we discovered that\nthe model's emergent attention patterns corresponded to spatial and\nfeature-based attention. This similarity between human visual attention and\nattention in computer vision suggests a promising direction for studying human\ncognition using neural network models.", "comment": "6 pages, 9 figures", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05487v1", "AI": {"title_translation": "空间和基于特征注意力的神经网络模型", "tldr": "该研究设计了一个受人类视觉注意力启发的神经网络模型，该模型表现出与人类空间和基于特征注意力相似的模式，表明神经网络可用于研究人类认知。", "motivation": "视觉注意力与视觉和记忆紧密相关，顶层信息通过注意力影响视觉处理。本研究的动机是设计一个受人类视觉注意力启发的神经网络模型，以理解和研究人类认知。", "method": "本研究设计了一个神经网络模型，该模型包含两个网络：一个作为执行简单任务的基础处理器，另一个处理上下文信息并通过注意力指导第一个网络以适应更复杂的任务。", "result": "训练模型并可视化学习到的注意力响应后，发现模型的涌现注意力模式与空间和基于特征的注意力相对应。", "conclusion": "计算机视觉中的注意力与人类视觉注意力之间的相似性为使用神经网络模型研究人类认知提供了一个有前景的方向。", "translation": "视觉注意力是一种与视觉和记忆紧密相关的机制。顶层信息通过注意力影响视觉处理。我们设计了一个受人类视觉注意力启发的神经网络模型。该模型由两个网络组成：一个作为执行简单任务的基础处理器，而另一个处理上下文信息并通过注意力指导第一个网络以适应更复杂的任务。在训练模型并可视化学习到的注意力响应后，我们发现模型的涌现注意力模式与空间和基于特征的注意力相对应。人类视觉注意力与计算机视觉中注意力之间的这种相似性为使用神经网络模型研究人类认知提供了一个有前景的方向。", "summary": "本研究提出了一个受人类视觉注意力启发的神经网络模型，旨在探索视觉注意力机制。该模型由两个协作网络组成，一个负责基本处理，另一个负责上下文引导。实验结果表明，该模型能够产生与人类空间和基于特征注意力相似的注意力模式，这为利用神经网络模型研究人类认知提供了新的视角和方向。", "keywords": "神经网络, 视觉注意力, 空间注意力, 特征注意力, 认知模型", "comments": "该论文通过构建一个双网络神经网络模型，成功模拟了人类视觉注意力中的空间和基于特征的注意力，这对于理解人类认知机制具有重要意义。其创新之处在于将人类注意力的概念引入到神经网络设计中，并验证了其有效性。未来研究可以进一步探索该模型在更复杂认知任务中的应用或与其他认知过程的结合。"}}
{"id": "2506.05751", "title": "An Ontology for Representing Curriculum and Learning Material", "authors": ["Antrea Christou", "Chris Davis Jaldi", "Joseph Zalewski", "Hande Küçük McGinty", "Pascal Hitzler", "Cogan Shimizu"], "summary": "Educational, learning, and training materials have become extremely\ncommonplace across the Internet. Yet, they frequently remain disconnected from\neach other, fall into platform silos, and so on. One way to overcome this is to\nprovide a mechanism to integrate the material and provide cross-links across\ntopics.\n  In this paper, we present the Curriculum KG Ontology, which we use as a\nframework for the dense interlinking of educational materials, by first\nstarting with organizational and broad pedagogical principles. We provide a\nmaterialized graph for the Prototype Open Knowledge Network use-case, and\nvalidate it using competency questions sourced from domain experts and\neducators.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.05751v1", "AI": {"title_translation": "课程和学习材料表示的本体", "tldr": "论文提出了一个名为Curriculum KG Ontology的本体，用于密集互联教育材料，以解决当前在线教育材料分散的问题。", "motivation": "解决互联网上教育、学习和培训材料普遍存在但相互脱节、平台孤岛的问题，目标是提供一种机制来整合材料并提供跨主题的交叉链接。", "method": "提出并使用了Curriculum KG Ontology作为框架，从组织和广泛的教学原则入手，实现教育材料的密集互联。通过为Prototype Open Knowledge Network用例提供具体化的图谱，并使用来自领域专家和教育工作者的能力问题进行验证。", "result": "为Prototype Open Knowledge Network用例提供了一个具体化的图谱，并使用能力问题进行了验证。", "conclusion": "Not mentioned in abstract", "translation": "教育、学习和培训材料在互联网上变得极其普遍。然而，它们经常相互脱节，陷入平台孤岛等问题。克服这一问题的一种方法是提供一种机制来整合这些材料，并提供跨主题的交叉链接。\n在本文中，我们提出了课程知识图谱本体（Curriculum KG Ontology），我们将其作为密集互联教育材料的框架，首先从组织和广泛的教学原则入手。我们为原型开放知识网络（Prototype Open Knowledge Network）用例提供了一个具体化的图谱，并使用来自领域专家和教育工作者的能力问题对其进行了验证。", "summary": "本文针对互联网上教育材料分散且缺乏互联的问题，提出了Curriculum KG Ontology。该本体旨在通过组织和教学原则，实现教育材料的密集互联，并为原型开放知识网络用例提供了具体化的图谱，通过专家验证了其有效性。", "keywords": "本体, 课程, 学习材料, 知识图谱", "comments": "Not mentioned in abstract"}}
{"id": "2506.05394", "title": "Attacking Attention of Foundation Models Disrupts Downstream Tasks", "authors": ["Hondamunige Prasanna Silva", "Federico Becattini", "Lorenzo Seidenari"], "summary": "Foundation models represent the most prominent and recent paradigm shift in\nartificial intelligence.Foundation models are large models, trained on broad\ndata that deliver high accuracy in many downstream tasks, often without\nfine-tuning. For this reason, models such as CLIP , DINO or Vision Transfomers\n(ViT), are becoming the bedrock of many industrial AI-powered applications.\nHowever, the reliance on pre-trained foundation models also introduces\nsignificant security concerns, as these models are vulnerable to adversarial\nattacks. Such attacks involve deliberately crafted inputs designed to deceive\nAI systems, jeopardizing their reliability.This paper studies the\nvulnerabilities of vision foundation models, focusing specifically on CLIP and\nViTs, and explores the transferability of adversarial attacks to downstream\ntasks. We introduce a novel attack, targeting the structure of\ntransformer-based architectures in a task-agnostic fashion.We demonstrate the\neffectiveness of our attack on several downstream tasks: classification,\ncaptioning, image/text retrieval, segmentation and depth estimation.", "comment": "Paper published at CVPR 2025 Workshop Advml", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05394v1", "AI": {"title_translation": "攻击基础模型的注意力会扰乱下游任务", "tldr": "对基础模型注意力机制的对抗性攻击可以扰乱多种下游任务。", "motivation": "基础模型在人工智能中广泛应用，但容易受到对抗性攻击，这带来了重要的安全隐患。本文旨在研究这些漏洞及其向下游任务的可迁移性。", "method": "本文引入了一种新颖的、任务无关的攻击方法，专门针对基于Transformer的视觉基础模型（如CLIP和ViT）的注意力结构。", "result": "所提出的攻击在分类、图像描述、图像/文本检索、分割和深度估计等多个下游任务上均表现出有效性。", "conclusion": "攻击基础模型的注意力机制能够有效扰乱下游任务，揭示了这些模型在实际应用中的重要安全漏洞。", "translation": "基础模型代表了人工智能领域最突出和最新的范式转变。基础模型是大型模型，在广泛的数据上进行训练，通常无需微调即可在许多下游任务中提供高精度。因此，CLIP、DINO或Vision Transfomers (ViT)等模型正在成为许多工业AI驱动应用的基础。然而，对预训练基础模型的依赖也带来了重大的安全问题，因为这些模型容易受到对抗性攻击。此类攻击涉及精心制作的输入，旨在欺骗AI系统，从而危及其可靠性。本文研究了视觉基础模型的漏洞，特别关注CLIP和ViT，并探讨了对抗性攻击向下游任务的可迁移性。我们引入了一种新颖的攻击，以任务无关的方式针对基于Transformer的架构的结构。我们证明了我们的攻击在多个下游任务上的有效性：分类、图像描述、图像/文本检索、分割和深度估计。", "summary": "基础模型是人工智能的关键组成部分，但面临对抗性攻击带来的安全风险。本文通过引入一种新颖的、任务无关的攻击，针对基于Transformer的基础模型（如CLIP和ViT）的注意力结构，研究了视觉基础模型的漏洞。该攻击成功扰乱了分类、图像描述、图像/文本检索、分割和深度估计等多个下游任务，揭示了重要的安全问题。", "keywords": "基础模型, 对抗性攻击, 注意力机制, 下游任务, Vision Transformers", "comments": "本文解决了广泛应用的基础模型的关键安全问题。其创新之处在于以任务无关的方式针对注意力机制进行攻击，证明了其对各种下游应用的广泛影响。这强调了在基础模型中建立强大防御机制的必要性。"}}
{"id": "2506.05520", "title": "Towards Data Systems That Are Business Semantic-Centric and AI Agents-Assisted", "authors": ["Cecil Pang"], "summary": "Contemporary businesses operate in dynamic environments requiring rapid\nadaptation to achieve goals and maintain competitiveness. Existing data\nplatforms often fall short by emphasizing tools over alignment with business\nneeds, resulting in inefficiencies and delays. To address this gap, I propose\nthe Business Semantics Centric, AI Agents Assisted Data System (BSDS), a\nholistic system that integrates architecture, workflows, and team organization\nto ensure data systems are tailored to business priorities rather than dictated\nby technical constraints. BSDS redefines data systems as dynamic enablers of\nbusiness success, transforming them from passive tools into active drivers of\norganizational growth. BSDS has a modular architecture that comprises curated\ndata linked to business entities, a knowledge base for context-aware AI agents,\nand efficient data pipelines. AI agents play a pivotal role in assisting with\ndata access and system management, reducing human effort, and improving\nscalability. Complementing this architecture, BSDS incorporates workflows\noptimized for both exploratory data analysis and production requirements,\nbalancing speed of delivery with quality assurance. A key innovation of BSDS is\nits incorporation of the human factor. By aligning data team expertise with\nbusiness semantics, BSDS bridges the gap between technical capabilities and\nbusiness needs. Validated through real-world implementation, BSDS accelerates\ntime-to-market for data-driven initiatives, enhances cross-functional\ncollaboration, and provides a scalable blueprint for businesses of all sizes.\nFuture research can build on BSDS to explore optimization strategies using\ncomplex systems and adaptive network theories, as well as developing autonomous\ndata systems leveraging AI agents.", "comment": "Being peer reviewed by a journal", "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05520v1", "AI": {"title_translation": "面向业务语义中心化和AI代理辅助的数据系统", "tldr": "本文提出了一种业务语义中心化、AI代理辅助的数据系统（BSDS），旨在将数据系统与业务需求对齐，提高效率，并加速数据驱动的计划。", "motivation": "现有数据平台强调工具而非业务需求，导致效率低下和延迟。当代企业需要在动态环境中快速适应以实现目标并保持竞争力。", "method": "本文提出业务语义中心化、AI代理辅助的数据系统（BSDS），这是一个集架构、工作流和团队组织于一体的整体系统。BSDS具有模块化架构，包括与业务实体相关联的精选数据、用于上下文感知AI代理的知识库以及高效的数据管道。AI代理在数据访问和系统管理中发挥关键作用。BSDS还整合了针对探索性数据分析和生产需求优化的工作流，并通过将数据团队专业知识与业务语义对齐来弥合技术能力和业务需求之间的差距。", "result": "通过实际实施验证，BSDS加快了数据驱动计划的上市时间，增强了跨职能协作，并为各种规模的企业提供了可扩展的蓝图。", "conclusion": "BSDS将数据系统重新定义为业务成功的动态推动者，将其从被动工具转变为组织增长的积极驱动力，从而弥合了技术能力与业务需求之间的差距。", "translation": "当代企业在动态环境中运营，需要快速适应以实现目标并保持竞争力。现有数据平台往往通过强调工具而非与业务需求的对齐而显得不足，导致效率低下和延迟。为了弥补这一差距，我提出了业务语义中心化、AI代理辅助的数据系统（BSDS），这是一个整合了架构、工作流和团队组织的整体系统，旨在确保数据系统根据业务优先级进行定制，而不是受技术约束的限制。BSDS将数据系统重新定义为业务成功的动态推动者，将其从被动工具转变为组织增长的积极驱动力。BSDS具有模块化架构，包括与业务实体相关联的精选数据、用于上下文感知AI代理的知识库以及高效的数据管道。AI代理在协助数据访问和系统管理方面发挥关键作用，减少了人工工作量并提高了可伸缩性。作为对该架构的补充，BSDS整合了针对探索性数据分析和生产要求优化的工作流，平衡了交付速度和质量保证。BSDS的一个关键创新是其对人为因素的整合。通过将数据团队的专业知识与业务语义对齐，BSDS弥合了技术能力和业务需求之间的差距。通过实际实施验证，BSDS加速了数据驱动计划的上市时间，增强了跨职能协作，并为各种规模的企业提供了可扩展的蓝图。未来的研究可以在BSDS的基础上，探索使用复杂系统和自适应网络理论的优化策略，以及开发利用AI代理的自主数据系统。", "summary": "本文提出了一种业务语义中心化、AI代理辅助的数据系统（BSDS），旨在解决现有数据平台偏重工具而非业务需求导致效率低下的问题。BSDS通过整合架构、工作流和团队组织，确保数据系统与业务优先级对齐。其模块化架构包含与业务实体关联的精选数据、用于上下文感知AI代理的知识库以及高效的数据管道。AI代理在数据访问和系统管理中发挥关键作用。BSDS还优化了工作流，并强调通过将数据团队专业知识与业务语义对齐来弥合技术与业务之间的鸿沟。实际实施验证表明，BSDS能加速数据驱动计划的上市时间，增强跨职能协作，并提供可扩展的解决方案。", "keywords": "业务语义, AI代理, 数据系统, 数据平台, 组织增长", "comments": "该论文的创新之处在于提出了一个业务语义中心化并由AI代理辅助的数据系统，有效弥合了技术能力与业务需求之间的差距。其关注人类因素和实际验证，增加了该方案的实用性和重要性。"}}
{"id": "2506.05714", "title": "Advancement and Field Evaluation of a Dual-arm Apple Harvesting Robot", "authors": ["Keyi Zhu", "Kyle Lammers", "Kaixiang Zhang", "Chaaran Arunachalam", "Siddhartha Bhattacharya", "Jiajia Li", "Renfu Lu", "Zhaojian Li"], "summary": "Apples are among the most widely consumed fruits worldwide. Currently, apple\nharvesting fully relies on manual labor, which is costly, drudging, and\nhazardous to workers. Hence, robotic harvesting has attracted increasing\nattention in recent years. However, existing systems still fall short in terms\nof performance, effectiveness, and reliability for complex orchard\nenvironments. In this work, we present the development and evaluation of a\ndual-arm harvesting robot. The system integrates a ToF camera, two 4DOF robotic\narms, a centralized vacuum system, and a post-harvest handling module. During\nharvesting, suction force is dynamically assigned to either arm via the vacuum\nsystem, enabling efficient apple detachment while reducing power consumption\nand noise. Compared to our previous design, we incorporated a platform movement\nmechanism that enables both in-out and up-down adjustments, enhancing the\nrobot's dexterity and adaptability to varying canopy structures. On the\nalgorithmic side, we developed a robust apple localization pipeline that\ncombines a foundation-model-based detector, segmentation, and clustering-based\ndepth estimation, which improves performance in orchards. Additionally,\npressure sensors were integrated into the system, and a novel dual-arm\ncoordination strategy was introduced to respond to harvest failures based on\nsensor feedback, further improving picking efficiency. Field demos were\nconducted in two commercial orchards in MI, USA, with different canopy\nstructures. The system achieved success rates of 0.807 and 0.797, with an\naverage picking cycle time of 5.97s. The proposed strategy reduced harvest time\nby 28% compared to a single-arm baseline. The dual-arm harvesting robot\nenhances the reliability and efficiency of apple picking. With further\nadvancements, the system holds strong potential for autonomous operation and\ncommercialization for the apple industry.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05714v1", "AI": {"title_translation": "双臂苹果采摘机器人的进展与现场评估", "tldr": "开发并现场评估了一种双臂苹果采摘机器人，该机器人通过集成先进硬件和算法，提高了采摘效率和成功率，有望实现商业化。", "motivation": "苹果采摘目前完全依赖人工，成本高、劳动强度大且对工人有害。现有采摘机器人系统在复杂果园环境下的性能、有效性和可靠性方面仍有不足。", "method": "本研究开发了一种双臂采摘机器人系统，集成了ToF相机、两个4自由度机械臂、集中式真空系统和采后处理模块。与之前设计相比，增加了平台运动机制以实现内外和上下调整，增强了机器人的灵活性和对不同树冠结构的适应性。在算法方面，开发了鲁棒的苹果定位管道，结合了基于基础模型的检测器、分割和基于聚类的深度估计。此外，还集成了压力传感器，并引入了新颖的双臂协调策略，根据传感器反馈响应采摘失败，进一步提高了采摘效率。", "result": "在美国密歇根州两个具有不同树冠结构的商业果园进行了现场演示。系统取得了0.807和0.797的成功率，平均采摘周期时间为5.97秒。与单臂基线相比，所提出的双臂策略将采摘时间减少了28%。", "conclusion": "双臂采摘机器人提高了苹果采摘的可靠性和效率。通过进一步发展，该系统在苹果产业的自主操作和商业化方面具有强大的潜力。", "translation": "苹果是全球消费最广泛的水果之一。目前，苹果采摘完全依赖人工，成本高昂、劳动繁重且对工人有害。因此，机器人采摘近年来引起了越来越多的关注。然而，现有系统在复杂果园环境下的性能、有效性和可靠性方面仍有不足。在这项工作中，我们介绍了双臂采摘机器人的开发和评估。该系统集成了ToF相机、两个4自由度机械臂、一个集中式真空系统和一个采后处理模块。在采摘过程中，吸力通过真空系统动态分配给任一机械臂，从而实现高效的苹果分离，同时降低功耗和噪音。与我们之前的设计相比，我们结合了一个平台运动机制，可以进行内外和上下调整，增强了机器人的灵活性和对不同树冠结构的适应性。在算法方面，我们开发了一个鲁棒的苹果定位管道，它结合了基于基础模型的检测器、分割和基于聚类的深度估计，从而提高了在果园中的性能。此外，系统还集成了压力传感器，并引入了一种新颖的双臂协调策略，根据传感器反馈响应采摘失败，进一步提高了采摘效率。在美国密歇根州两个具有不同树冠结构的商业果园进行了现场演示。该系统取得了0.807和0.797的成功率，平均采摘周期时间为5.97秒。与单臂基线相比，所提出的策略将采摘时间减少了28%。双臂采摘机器人提高了苹果采摘的可靠性和效率。随着进一步的发展，该系统在苹果产业的自主操作和商业化方面具有强大的潜力。", "summary": "本文介绍了一种先进的双臂苹果采摘机器人，旨在解决传统人工采摘的成本高、效率低等问题。该机器人集成了ToF相机、双机械臂、真空系统和平台运动机制，并开发了鲁棒的苹果定位算法和双臂协调策略。现场评估结果显示，该机器人具有较高的采摘成功率和效率，并显著缩短了采摘时间，展现出在苹果产业商业化应用的巨大潜力。", "keywords": "苹果采摘机器人, 双臂机器人, 农业机器人, 机器视觉, 现场评估", "comments": "该研究通过引入双臂设计、动态吸力分配、平台运动机制以及结合基础模型的先进定位算法和双臂协调策略，显著提升了苹果采摘机器人的性能和适应性。特别是在复杂果园环境下的现场评估，验证了其在实际应用中的有效性。减少28%的采摘时间是一个重要的突破，表明了该系统在提高效率方面的潜力。未来的工作应关注其在不同品种苹果和更复杂环境下的泛化能力，以及成本效益分析以推动商业化。"}}
{"id": "2506.05814", "title": "Positional Encoding meets Persistent Homology on Graphs", "authors": ["Yogesh Verma", "Amauri H. Souza", "Vikas Garg"], "summary": "The local inductive bias of message-passing graph neural networks (GNNs)\nhampers their ability to exploit key structural information (e.g., connectivity\nand cycles). Positional encoding (PE) and Persistent Homology (PH) have emerged\nas two promising approaches to mitigate this issue. PE schemes endow GNNs with\nlocation-aware features, while PH methods enhance GNNs with multiresolution\ntopological features. However, a rigorous theoretical characterization of the\nrelative merits and shortcomings of PE and PH has remained elusive. We bridge\nthis gap by establishing that neither paradigm is more expressive than the\nother, providing novel constructions where one approach fails but the other\nsucceeds. Our insights inform the design of a novel learnable method, PiPE\n(Persistence-informed Positional Encoding), which is provably more expressive\nthan both PH and PE. PiPE demonstrates strong performance across a variety of\ntasks (e.g., molecule property prediction, graph classification, and\nout-of-distribution generalization), thereby advancing the frontiers of graph\nrepresentation learning. Code is available at\nhttps://github.com/Aalto-QuML/PIPE.", "comment": "Accepted at ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05814v1", "AI": {"title_translation": "图上的位置编码与持久同源性相遇", "tldr": "本文理论分析了位置编码（PE）和持久同源性（PH）在图神经网络（GNN）中的表达能力，并提出了一种新的、表达能力更强的学习方法PiPE，在各种图任务中表现出色。", "motivation": "消息传递图神经网络（GNN）的局部归纳偏差限制了其利用关键结构信息（如连通性和循环）的能力。现有的位置编码（PE）和持久同源性（PH）方法虽然有前景，但它们各自的优缺点和相对表达能力缺乏严格的理论表征。", "method": "作者通过理论分析证明了位置编码（PE）和持久同源性（PH）在表达能力上互不优于对方，并提供了各自失败而对方成功的新颖构造。基于这些见解，本文设计了一种名为PiPE（Persistence-informed Positional Encoding）的新型可学习方法，该方法被证明比PE和PH都更具表达能力。", "result": "PiPE在多种任务（例如分子性质预测、图分类和域外泛化）中表现出强大的性能。", "conclusion": "PiPE是一种新颖的、可学习的、且表达能力优于现有位置编码和持久同源性方法的图表示学习方法，有效地解决了GNN在捕获图结构信息方面的局限性。", "translation": "消息传递图神经网络（GNN）的局部归纳偏差阻碍了它们利用关键结构信息（例如连通性和循环）的能力。位置编码（PE）和持久同源性（PH）已成为缓解这一问题的两种有前景的方法。PE方案赋予GNN位置感知特征，而PH方法则通过多分辨率拓扑特征增强GNN。然而，关于PE和PH相对优缺点以及表达能力的严格理论表征一直难以捉摸。我们通过确立这两种范式在表达能力上互不优于对方来弥补这一空白，提供了其中一种方法失败而另一种方法成功的新颖构造。我们的见解启发了一种新型可学习方法PiPE（Persistence-informed Positional Encoding）的设计，该方法被证明比PH和PE都更具表达能力。PiPE在各种任务（例如分子性质预测、图分类和域外泛化）中表现出强大的性能，从而推动了图表示学习的前沿。代码可在https://github.com/Aalto-QuML/PIPE获取。", "summary": "本文探讨了消息传递图神经网络（GNN）在捕获图结构信息方面的局限性，并分析了位置编码（PE）和持久同源性（PH）这两种现有方法的表达能力。研究发现，PE和PH在表达能力上各有优劣，互不超越。基于这些发现，论文提出了一种名为PiPE（Persistence-informed Positional Encoding）的新型可学习方法，该方法在理论上被证明比PE和PH更具表达能力，并在分子性质预测、图分类和域外泛化等多种图任务中展现出卓越的性能。", "keywords": "图神经网络, 位置编码, 持久同源性, 表达能力, 图表示学习", "comments": "本文通过理论分析揭示了位置编码和持久同源性在图神经网络中表达能力的局限性，并在此基础上提出了一个创新性的融合方法PiPE。PiPE在理论上证明了其更强的表达能力，并在实际任务中取得了显著效果，这对于提升图表示学习的性能具有重要意义。该研究不仅填补了理论空白，也为未来设计更强大的GNN模型提供了新思路。"}}
{"id": "2506.05363", "title": "Seed Selection for Human-Oriented Image Reconstruction via Guided Diffusion", "authors": ["Yui Tatsumi", "Ziyue Zeng", "Hiroshi Watanabe"], "summary": "Conventional methods for scalable image coding for humans and machines\nrequire the transmission of additional information to achieve scalability. A\nrecent diffusion-based method avoids this by generating human-oriented images\nfrom machine-oriented images without extra bitrate. This method, however, uses\na single random seed, which may lead to suboptimal image quality. In this\npaper, we propose a seed selection method that identifies the optimal seed from\nmultiple candidates to improve image quality without increasing the bitrate. To\nreduce computational cost, the selection is performed based on intermediate\noutputs obtained from early steps of the reverse diffusion process.\nExperimental results demonstrate that our method outperforms the baseline\nacross multiple metrics.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05363v1", "AI": {"title_translation": "面向人类的引导扩散图像重建的种子选择", "tldr": "本文提出了一种种子选择方法，通过从多个候选种子中选择最优种子来改进基于扩散的人工智能图像重建的质量，同时不增加比特率。", "motivation": "现有的基于扩散的方法在从机器导向图像生成人类导向图像时，使用单一随机种子可能导致图像质量不佳。", "method": "提出了一种种子选择方法，通过从多个候选种子中识别最优种子来提高图像质量。为了降低计算成本，选择是基于逆扩散过程早期步骤获得的中间输出来进行的。", "result": "实验结果表明，该方法在多个指标上优于基线方法。", "conclusion": "通过选择最优种子，可以显著提高基于扩散的人类导向图像重建的质量，且不增加比特率，并通过利用早期中间输出有效降低了计算成本。", "translation": "传统的面向人类和机器的可伸缩图像编码方法需要传输额外信息才能实现可伸缩性。最近一种基于扩散的方法通过从机器导向图像生成人类导向图像，避免了额外的比特率。然而，这种方法使用单一随机种子，可能导致次优的图像质量。在本文中，我们提出了一种种子选择方法，该方法从多个候选种子中识别最优种子，以在不增加比特率的情况下提高图像质量。为了降低计算成本，选择是基于逆扩散过程早期步骤获得的中间输出来进行的。实验结果表明，我们的方法在多个指标上优于基线。", "summary": "本论文旨在解决现有基于扩散的人类导向图像重建方法中，单一随机种子导致图像质量次优的问题。研究者提出了一种新颖的种子选择方法，该方法能够从多个候选种子中识别出最佳种子，从而在不增加额外比特率的前提下显著提升图像质量。为了优化计算效率，种子选择过程基于逆扩散早期步骤的中间输出。实验结果证实，该方法在多项指标上均优于现有基线。", "keywords": "图像重建, 扩散模型, 种子选择, 图像质量, 比特率", "comments": "该论文的创新点在于提出了一个有效的种子选择机制，以优化基于扩散模型的图像重建质量，特别是在人机协同场景下。通过在扩散过程的早期阶段进行种子选择，该方法在提高图像质量的同时，有效控制了计算成本和比特率，这对于实际应用具有重要意义。"}}
{"id": "2506.05623", "title": "Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework", "authors": ["Tianyi Zhang", "Shidong Pan", "Zejun Zhang", "Zhenchang Xing", "Xiaoyu Sun"], "summary": "Infrastructure-as-Code (IaC) generation holds significant promise for\nautomating cloud infrastructure provisioning. Recent advances in Large Language\nModels (LLMs) present a promising opportunity to democratize IaC development by\ngenerating deployable infrastructure templates from natural language\ndescriptions, but current evaluation focuses on syntactic correctness while\nignoring deployability, the fatal measure of IaC template utility. We address\nthis gap through two contributions: (1) IaCGen, an LLM-based\ndeployability-centric framework that uses iterative feedback mechanism to\ngenerate IaC templates, and (2) DPIaC-Eval, a deployability-centric IaC\ntemplate benchmark consists of 153 real-world scenarios that can evaluate\nsyntax, deployment, user intent, and security. Our evaluation reveals that\nstate-of-the-art LLMs initially performed poorly, with Claude-3.5 and\nClaude-3.7 achieving only 30.2% and 26.8% deployment success on the first\nattempt respectively. However, IaCGen transforms this performance dramatically:\nall evaluated models reach over 90% passItr@25, with Claude-3.5 and Claude-3.7\nachieving 98% success rate. Despite these improvements, critical challenges\nremain in user intent alignment (25.2% accuracy) and security compliance (8.4%\npass rate), highlighting areas requiring continued research. Our work provides\nthe first comprehensive assessment of deployability-centric IaC template\ngeneration and establishes a foundation for future research.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05623v1", "AI": {"title_translation": "以可部署性为中心的基础设施即代码生成：一个基于LLM的迭代框架", "tldr": "本研究提出了一个基于LLM的迭代框架IaCGen和一个基准DPIaC-Eval，旨在解决当前LLM在生成基础设施即代码（IaC）时忽视可部署性的问题。IaCGen显著提高了LLM的部署成功率，但用户意图对齐和安全合规性仍面临挑战。", "motivation": "当前对大型语言模型（LLM）生成基础设施即代码（IaC）的评估侧重于语法正确性，却忽略了作为IaC模板实用性关键指标的可部署性。", "method": "本研究提出了两个贡献：1) IaCGen，一个基于LLM的以可部署性为中心的框架，它使用迭代反馈机制生成IaC模板；2) DPIaC-Eval，一个以可部署性为中心的IaC模板基准，包含153个真实场景，可以评估语法、部署、用户意图和安全性。", "result": "评估显示，最先进的LLM在首次尝试时表现不佳，Claude-3.5和Claude-3.7的部署成功率分别为30.2%和26.8%。然而，IaCGen显著提升了性能：所有评估模型在passItr@25上均达到90%以上，其中Claude-3.5和Claude-3.7达到了98%的成功率。尽管有这些改进，用户意图对齐（25.2%的准确率）和安全合规性（8.4%的通过率）仍存在严峻挑战。", "conclusion": "本研究首次对以可部署性为中心的IaC模板生成进行了全面评估，并为未来的研究奠定了基础。", "translation": "基础设施即代码（IaC）生成在自动化云基础设施配置方面具有重要前景。大型语言模型（LLM）的最新进展为通过自然语言描述生成可部署的基础设施模板，从而普及IaC开发提供了有希望的机会，但当前的评估侧重于语法正确性，而忽略了可部署性，这是IaC模板实用性的致命衡量标准。我们通过两项贡献弥补了这一空白：(1) IaCGen，一个基于LLM的以可部署性为中心的框架，它使用迭代反馈机制生成IaC模板；(2) DPIaC-Eval，一个以可部署性为中心的IaC模板基准，包含153个真实场景，可以评估语法、部署、用户意图和安全性。我们的评估表明，最先进的LLM最初表现不佳，Claude-3.5和Claude-3.7在首次尝试时分别仅实现30.2%和26.8%的部署成功率。然而，IaCGen显著改变了这一性能：所有评估模型在passItr@25上均达到90%以上，其中Claude-3.5和Claude-3.7达到了98%的成功率。尽管有这些改进，用户意图对齐（25.2%的准确率）和安全合规性（8.4%的通过率）仍然是严峻的挑战，突显了需要持续研究的领域。我们的工作首次对以可部署性为中心的IaC模板生成进行了全面评估，并为未来的研究奠定了基础。", "summary": "本论文提出了一个基于LLM的迭代框架IaCGen和一个新的基准DPIaC-Eval，旨在解决当前LLM在生成基础设施即代码（IaC）时忽视可部署性的问题。IaCGen通过迭代反馈机制显著提高了LLM生成IaC模板的部署成功率，将最先进模型的成功率从初始的低水平提升至90%以上。然而，研究也指出用户意图对齐和安全合规性方面仍存在重大挑战，为未来的研究指明了方向。本工作为以可部署性为中心的IaC模板生成提供了首次全面评估。", "keywords": "基础设施即代码, 大型语言模型, 可部署性, 迭代框架, 基准测试", "comments": "该论文创新性地关注了LLM生成IaC模板的“可部署性”这一关键但被忽视的指标，填补了现有评估的空白。提出的IaCGen框架通过迭代反馈机制显著提升了LLM的部署成功率，展现了其在自动化云基础设施配置方面的巨大潜力。同时，论文也诚实地指出了用户意图对齐和安全合规性方面的显著局限性，为未来研究提供了明确的方向，具有重要的实践和理论意义。"}}
{"id": "2506.06106", "title": "Measuring the co-evolution of online engagement with (mis)information and its visibility at scale", "authors": ["Yueting Han", "Paolo Turrini", "Marya Bazzi", "Giulia Andrighetto", "Eugenia Polizzi", "Manlio De Domenico"], "summary": "Online attention is an increasingly valuable resource in the digital age,\nwith extraordinary events such as the COVID-19 pandemic fuelling fierce\ncompetition around it. As misinformation pervades online platforms, users seek\ncredible sources, while news outlets compete to attract and retain their\nattention. Here we measure the co-evolution of online \"engagement\" with\n(mis)information and its \"visibility\", where engagement corresponds to user\ninteractions on social media, and visibility to fluctuations in user follower\ncounts. Using a scalable temporal network modelling framework applied to over\n100 million COVID-related retweets spanning 3 years, we find that highly\nengaged sources experience sharp spikes in follower growth during major events\n(e.g., vaccine rollouts, epidemic severity), whereas sources with more\nquestionable credibility tend to sustain faster growth outside of these\nperiods. Our framework lends itself to studying other large-scale events where\nonline attention is at stake, such as climate and political debates.", "comment": null, "cate": "cs.SI", "url": "http://arxiv.org/pdf/2506.06106v1", "AI": {"title_translation": "大规模测量在线参与（错误）信息及其可见性的协同演化", "tldr": "研究了在线参与（错误）信息与可见性如何协同演化，发现可信来源在重大事件期间粉丝增长迅速，而可疑来源在非事件期间增长更快。", "motivation": "随着数字时代在线注意力资源的日益宝贵，尤其是在COVID-19大流行等事件中，错误信息泛滥，用户寻求可信来源，新闻媒体争夺注意力。因此，需要测量在线参与（错误）信息及其可见性的协同演化。", "method": "使用可扩展的时间网络建模框架，应用于超过1亿条与COVID相关的转发数据（跨越3年），测量在线“参与”（用户在社交媒体上的互动）和“可见性”（用户粉丝数量的波动）的协同演化。", "result": "发现高度参与的来源在重大事件（如疫苗推广、疫情严重性）期间粉丝增长出现急剧高峰，而可信度较低的来源在这些时期之外倾向于保持更快的增长。", "conclusion": "该框架可用于研究在线注意力面临风险的其他大规模事件，如气候和政治辩论。", "translation": "在线注意力在数字时代是一种日益宝贵的资源，COVID-19大流行等非凡事件加剧了围绕它的激烈竞争。随着错误信息在线平台上的泛滥，用户寻求可信来源，而新闻媒体则竞相吸引和留住他们的注意力。本文测量了在线“参与”（错误）信息及其“可见性”的协同演化，其中参与对应于用户在社交媒体上的互动，可见性对应于用户粉丝数量的波动。我们使用一个可扩展的时间网络建模框架，应用于跨越3年的超过1亿条与COVID相关的转发数据，发现高度参与的来源在重大事件（例如疫苗推广、疫情严重性）期间粉丝增长出现急剧高峰，而可信度较低的来源在这些时期之外倾向于保持更快的增长。我们的框架适用于研究在线注意力面临风险的其他大规模事件，例如气候和政治辩论。", "summary": "本文研究了在线用户对（错误）信息的参与度与信息可见性之间的协同演化关系。研究人员通过分析超过1亿条COVID相关推文，构建了一个可扩展的时间网络模型。结果显示，在重大事件期间，高参与度的信息源其粉丝数量会急剧增长；而在非事件时期，可信度较低的信息源反而能保持更快的增长速度。该研究框架可应用于分析其他涉及在线注意力的大规模事件。", "keywords": "在线参与, 错误信息, 可见性, 协同演化, 时间网络模型", "comments": "这项研究通过量化在线参与度和可见性，为理解信息（包括错误信息）在社交媒体上的传播动态提供了新的视角。其提出的可扩展时间网络模型具有普适性，可应用于其他社会热点事件分析，对于打击错误信息传播和理解在线注意力经济具有重要意义。"}}
{"id": "2506.05738", "title": "Differential Spectrum and Boomerang Spectrum of Some Power Mapping", "authors": ["Yuehui Cui", "Jinquan Luo"], "summary": "Let $f(x)=x^{s(p^m-1)}$ be a power mapping over $\\mathbb{F}_{p^n}$, where\n$n=2m$ and $\\gcd(s,p^m+1)=t$. In \\cite{kpm-1}, Hu et al. determined the\ndifferential spectrum and boomerang spectrum of the power function $f$, where\n$t=1$. So what happens if $t\\geq1$? In this paper, we extend the result of\n\\cite{kpm-1} from $t=1$ to general case. We use a different method than in\n\\cite{kpm-1} to determine the differential spectrum and boomerang spectrum of\n$f$ by studying the number of rational points on some curves. This method may\nbe helpful for calculating the differential spectrum and boomerang spectrum of\nsome Niho type power functions.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.05738v1", "AI": {"title_translation": "某些幂映射的差分谱和回旋镖谱", "tldr": "本文将幂映射的差分谱和回旋镖谱的分析从t=1推广到一般情况，并使用了一种通过研究某些曲线上的有理点数量的新方法。", "motivation": "现有研究（Hu et al. \\cite{kpm-1}）已确定了特定幂映射在参数t=1时的差分谱和回旋镖谱，但对于t≥1的更一般情况尚未解决。", "method": "通过研究某些曲线上的有理点数量，采用与先前研究不同的方法来确定幂映射的差分谱和回旋镖谱。", "result": "成功将先前关于幂映射差分谱和回旋镖谱的分析结果从t=1推广到了更一般的t≥1情况。", "conclusion": "所提出的方法可能有助于计算某些Niho型幂函数的差分谱和回旋镖谱。", "translation": "设 $f(x)=x^{s(p^m-1)}$ 是$\\mathbb{F}_{p^n}$上的一个幂映射，其中 $n=2m$ 且 $\\gcd(s,p^m+1)=t$。在文献 \\cite{kpm-1} 中，胡等人确定了当 $t=1$ 时幂函数 $f$ 的差分谱和回旋镖谱。那么当 $t\\geq1$ 时会发生什么呢？在本文中，我们将文献 \\cite{kpm-1} 的结果从 $t=1$ 推广到一般情况。我们使用与文献 \\cite{kpm-1} 不同的方法，通过研究某些曲线上的有理点数量来确定 $f$ 的差分谱和回旋镖谱。这种方法可能有助于计算某些Niho型幂函数的差分谱和回旋镖谱。", "summary": "本文研究了在有限域$\\mathbb{F}_{p^n}$上定义的幂映射$f(x)=x^{s(p^m-1)}$的差分谱和回旋镖谱。针对先前研究仅限于参数$t=1$的情况，本文将其扩展到更普遍的$t\\geq1$情况。作者采用了一种新颖的方法，即通过分析某些曲线上的有理点数量来确定这些谱，该方法有望应用于其他Niho型幂函数的研究。", "keywords": "差分谱, 回旋镖谱, 幂映射, 有理点, 有限域", "comments": "本文的创新之处在于将现有结果推广到更普遍的情况，并引入了一种通过研究曲线有理点数量来确定差分谱和回旋镖谱的新方法。这种方法可能为密码学中幂函数分析提供了新的工具。"}}
{"id": "2506.05432", "title": "PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling", "authors": ["Yuxuan Yue", "Zukang Xu", "Zhihang Yuan", "Dawei Yang", "Jianglong Wu", "Liqiang Nie"], "summary": "Large Language Models (LLMs) face significant challenges in edge deployment\ndue to their massive parameter scale. Vector Quantization (VQ), a\nclustering-based quantization method, serves as a prevalent solution to this\nissue for its extremely low-bit (even at 2-bit) and considerable accuracy.\nSince a vector is a quantity in mathematics and physics that has both direction\nand magnitude, existing VQ works typically quantize them in a coupled manner.\nHowever, we find that direction exhibits significantly greater sensitivity to\nquantization compared to the magnitude. For instance, when separately\nclustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the\naccuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap\neven increases with the reduction of clustering centers. Further, Euclidean\ndistance, a common metric to access vector similarities in current VQ works,\nplaces greater emphasis on reducing the magnitude error. This property is\ncontrary to the above finding, unavoidably leading to larger quantization\nerrors. To these ends, this paper proposes Polar Coordinate Decoupled Vector\nQuantization (PCDVQ), an effective and efficient VQ framework consisting of two\nkey modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors\ninto their polar coordinate representations and perform independent\nquantization of the direction and magnitude parameters.2) Distribution Aligned\nCodebook Construction (DACC), which optimizes the direction and magnitude\ncodebooks in accordance with the source distribution. Experimental results show\nthat PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\%\nzero-shot accuracy, establishing a novel paradigm for accurate and highly\ncompressed LLMs.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05432v1", "AI": {"title_translation": "PCDVQ：通过极坐标解耦增强大型语言模型的向量量化", "tldr": "PCDVQ通过解耦向量的方向和幅度进行量化，显著提高了LLMs的低比特量化精度，克服了现有VQ方法对方向敏感度不足的问题。", "motivation": "大型语言模型（LLMs）因其庞大的参数规模在边缘部署面临挑战。向量量化（VQ）是解决此问题的一种流行方案，但现有VQ方法在量化向量时以耦合方式处理方向和幅度。研究发现，方向对量化比幅度更敏感，且欧几里得距离更侧重减少幅度误差，导致量化误差较大。", "method": "本文提出了极坐标解耦向量量化（PCDVQ）框架，包含两个关键模块：1）极坐标解耦（PCD），将向量转换为极坐标表示，并独立量化方向和幅度参数。2）分布对齐码本构建（DACC），根据源分布优化方向和幅度码本。", "result": "实验结果表明，PCDVQ在2比特级别上比基线方法至少提高了1.5%的零样本准确率。", "conclusion": "PCDVQ为准确和高度压缩的LLMs建立了一种新范式，通过极坐标解耦和分布对齐码本构建，有效解决了向量量化中方向敏感度的问题。", "translation": "大型语言模型（LLMs）因其庞大的参数规模在边缘部署面临重大挑战。向量量化（VQ）作为一种基于聚类的量化方法，因其极低的比特（甚至2比特）和相当高的精度而成为解决此问题的一种流行方案。由于向量在数学和物理学中是同时具有方向和大小的量，现有的VQ工作通常以耦合方式对其进行量化。然而，我们发现方向对量化的敏感度显著高于幅度。例如，当在LLaMA-2-7B中分别聚类权重向量的方向和幅度时，零样本任务的精度下降分别为46.5%和2.3%。这种差距甚至随着聚类中心的减少而增加。此外，欧几里得距离作为当前VQ工作中评估向量相似度的常用指标，更侧重于减少幅度误差。这一特性与上述发现相悖，不可避免地导致更大的量化误差。为此，本文提出了极坐标解耦向量量化（PCDVQ），一个有效且高效的VQ框架，由两个关键模块组成：1）极坐标解耦（PCD），将向量转换为其极坐标表示并独立量化方向和幅度参数。2）分布对齐码本构建（DACC），根据源分布优化方向和幅度码本。实验结果表明，PCDVQ在2比特级别上比基线方法至少提高了1.5%的零样本准确率，为准确和高度压缩的LLMs建立了一种新范式。", "summary": "本文提出了PCDVQ，一种用于大型语言模型（LLMs）的极坐标解耦向量量化框架，旨在解决LLMs边缘部署中的参数规模挑战。PCDVQ通过极坐标解耦（PCD）将向量的方向和幅度独立量化，并利用分布对齐码本构建（DACC）优化码本，解决了传统向量量化中方向敏感度高但被忽视的问题。实验证明，PCDVQ在2比特量化下，零样本准确率比现有方法至少提高1.5%，为LLMs的精确高效压缩提供了新途径。", "keywords": "向量量化, 大型语言模型, 极坐标解耦, 低比特量化, 模型压缩", "comments": "这项工作的创新点在于发现了向量方向对量化精度影响远大于幅度，并提出了极坐标解耦的思想来独立处理方向和幅度。这为低比特量化提供了一个新的视角和有效的解决方案，对于LLMs在资源受限设备上的部署具有重要意义。该方法通过解耦量化，有效提升了精度，有望推动更小、更高效的LLMs的发展。"}}
{"id": "2506.06102", "title": "Perfect Matching with Few Link Activations", "authors": ["Hugo Mirault", "Peter Robinson", "Ming Ming Tan", "Xianbin Zhu"], "summary": "We consider the problem of computing a perfect matching problem in a\nsynchronous distributed network, where the network topology corresponds to a\ncomplete bipartite graph. The communication between nodes is restricted to\nactivating communication links, which means that instead of sending messages\ncontaining a number of bits, each node can only send a pulse over some of its\nincident links in each round. In the port numbering model, where nodes are\nunaware of their neighbor's IDs, we give a randomized algorithm that terminates\nin $O( \\log n )$ rounds and has a pulse complexity of $O( n\\log n )$, which\ncorresponds to the number of pulses sent over all links. We also show that\nrandomness is crucial in the port numbering model, as any deterministic\nalgorithm must send at least $\\Omega( n^2 )$ messages in the standard LOCAL\nmodel, where the messages can be of unbounded size. Then, we turn our attention\nto the KT_1 assumption, where each node starts out knowing its neighbors' IDs.\nWe show that this additional knowledge enables significantly improved bounds\neven for deterministic algorithms. First, we give an $O( \\log n )$ time\ndeterministic algorithm that sends only $O( n )$ pulses. Finally, we apply this\nalgorithm recursively to obtain an exponential reduction in the time complexity\nto $O( \\log^*n\\log\\log n )$, while slightly increasing the pulse complexity to\n$O( n\\log^*n )$. All our bounds also hold in the standard CONGEST model with\nsingle-bit messages.", "comment": "A short version of this work appeared at SIROCCO 2025", "cate": "cs.DC", "url": "http://arxiv.org/pdf/2506.06102v1", "AI": {"title_translation": "少量链路激活的完美匹配", "tldr": "本文研究了在受限通信模型（仅限链路激活）下分布式网络中的完美匹配问题，并提出了在端口编号模型下（随机）和KT_1假设下（确定性）的有效算法，证明了邻居ID知识和随机性的重要性。", "motivation": "在同步分布式网络中，传统的消息传递模型可能不适用于某些场景，例如仅允许通过链路激活进行通信。本文的动机是探索在这种受限通信模型下，如何在完全二分图中高效地计算完美匹配，并研究随机性以及节点是否知晓邻居ID对算法性能的影响。", "method": "本文在两种不同的模型下提出了算法：\n1.  **端口编号模型（节点不知道邻居ID）**：提出了一种随机算法。\n2.  **KT_1假设（节点知道邻居ID）**：\n    *   首先提出了一种确定性算法。\n    *   然后通过递归应用该确定性算法，进一步优化时间复杂度。\n所有提出的算法的性能都在通信受限的链路激活（脉冲）复杂度和时间轮次方面进行了分析。", "result": "1.  **在端口编号模型中**：提出了一种随机算法，其终止时间为$O(\\log n)$轮，脉冲复杂度为$O(n \\log n)$。同时证明了随机性至关重要，因为任何确定性算法在标准LOCAL模型中至少需要发送$\\Omega(n^2)$条消息。\n2.  **在KT_1假设下**：\n    *   提出了一种$O(\\log n)$时间的确定性算法，仅发送$O(n)$个脉冲。\n    *   通过递归应用该算法，时间复杂度进一步降低到$O(\\log^*n\\log\\log n)$，脉冲复杂度略微增加到$O(n\\log^*n)$。\n所有这些界限在单比特消息的标准CONGEST模型中也成立。", "conclusion": "本文的结论是，在同步分布式网络中计算完美匹配时，节点是否知晓其邻居ID（KT_1假设）对算法的性能有显著影响，能够实现确定性算法的显著改进。此外，在节点不了解邻居ID的端口编号模型中，随机性对于实现高效算法至关重要。", "translation": "我们考虑在同步分布式网络中计算完美匹配问题，其中网络拓扑对应于一个完全二分图。节点之间的通信仅限于激活通信链路，这意味着每个节点在每一轮中只能通过其某些关联链路发送一个脉冲，而不是发送包含比特数的消息。在端口编号模型中，节点不知道其邻居的ID，我们给出了一个随机算法，该算法在$O(\\log n)$轮内终止，并且脉冲复杂度为$O(n \\log n)$，这对应于通过所有链路发送的脉冲数量。我们还表明，在端口编号模型中，随机性至关重要，因为任何确定性算法在标准LOCAL模型中必须发送至少$\\Omega(n^2)$条消息，其中消息大小可以是无界的。然后，我们将注意力转向KT_1假设，即每个节点开始时都知道其邻居的ID。我们表明，这种额外的知识即使对于确定性算法也能显著改善界限。首先，我们给出了一个$O(\\log n)$时间的确定性算法，该算法只发送$O(n)$个脉冲。最后，我们递归地应用此算法，以实现时间复杂度的指数级降低，达到$O(\\log^*n\\log\\log n)$，同时脉冲复杂度略微增加到$O(n\\log^*n)$。我们所有的界限在单比特消息的标准CONGEST模型中也成立。", "summary": "本文研究了在同步分布式网络中（拓扑为完全二分图）计算完美匹配的问题，但通信模型受限，仅允许通过链路激活（发送脉冲）进行通信。在节点不了解邻居ID的端口编号模型下，提出了一种$O(\\log n)$轮、$O(n \\log n)$脉冲复杂度的随机算法，并证明了随机性的必要性。进一步，在节点已知邻居ID（KT_1假设）的情况下，展示了确定性算法的显著性能提升，包括一个$O(\\log n)$时间、$O(n)$脉冲的算法，以及通过递归应用实现的$O(\\log^*n\\log\\log n)$时间、$O(n\\log^*n)$脉冲的更优算法。所有结果在CONGEST模型中也成立。", "keywords": "完美匹配, 分布式算法, 链路激活, 脉冲复杂度, 图论", "comments": "本文的创新点在于其在一种高度受限的分布式通信模型（仅链路激活）下研究了完美匹配问题，这在传统分布式算法中并不常见。它清晰地展示了随机性和节点对邻居ID的先验知识（KT_1假设）对算法效率的决定性影响，尤其是在脉冲复杂度和时间轮次方面。对于处理资源受限或特定通信协议的分布式系统，其提出的高效算法和理论下界具有重要意义。"}}
{"id": "2506.05708", "title": "Hybrid Stabilization Protocol for Cross-Chain Digital Assets Using Adaptor Signatures and AI-Driven Arbitrage", "authors": ["Shengwei You", "Andrey Kuehlkamp", "Jarek Nabrzyski"], "summary": "Stablecoins face an unresolved trilemma of balancing decentralization,\nstability, and regulatory compliance. We present a hybrid stabilization\nprotocol that combines crypto-collateralized reserves, algorithmic futures\ncontracts, and cross-chain liquidity pools to achieve robust price adherence\nwhile preserving user privacy. At its core, the protocol introduces\nstabilization futures contracts (SFCs), non-collateralized derivatives that\nprogrammatically incentivize third-party arbitrageurs to counteract price\ndeviations via adaptor signature atomic swaps. Autonomous AI agents optimize\ndelta hedging across decentralized exchanges (DEXs), while zkSNARKs prove\ncompliance with anti-money laundering (AML) regulations without exposing\nidentities or transaction details. Our cryptographic design reduces cross-chain\nliquidity concentration (Herfindahl-Hirschman Index: 2,400 vs. 4,900 in\nsingle-chain systems) and ensures atomicity under standard cryptographic\nassumptions. The protocol's layered architecture encompassing\nincentive-compatible SFCs, AI-driven market making, and zero-knowledge\nregulatory proofs. It provides a blueprint for next-generation decentralized\nfinancial infrastructure.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05708v1", "AI": {"title_translation": "使用适配器签名和AI驱动套利实现跨链数字资产的混合稳定协议", "tldr": "本文提出一种混合稳定协议，结合加密抵押储备、算法期货合约和跨链流动性池，通过适配器签名和AI驱动套利，解决稳定币去中心化、稳定性与合规性的三难困境，同时保护用户隐私。", "motivation": "稳定币面临去中心化、稳定性与监管合规性之间的未解决的三难困境。", "method": "提出一种混合稳定协议，结合加密抵押储备、算法期货合约和跨链流动性池。核心是引入稳定期货合约（SFCs），通过适配器签名原子交换激励第三方套利者抵消价格偏差。自主AI代理优化去中心化交易所（DEXs）的Delta对冲。zkSNARKs用于在不暴露身份或交易细节的情况下证明符合反洗钱（AML）法规。", "result": "降低了跨链流动性集中度（Herfindahl-Hirschman指数：2,400，而单链系统为4,900），并在标准加密假设下确保了原子性。", "conclusion": "该协议为下一代去中心化金融基础设施提供了一个蓝图。", "translation": "稳定币面临去中心化、稳定性与监管合规性之间未解决的三难困境。我们提出了一种混合稳定协议，结合加密抵押储备、算法期货合约和跨链流动性池，以实现稳健的价格依附，同时保护用户隐私。协议的核心是引入稳定期货合约（SFCs），这是一种非抵押衍生品，通过适配器签名原子交换，以程序化方式激励第三方套利者抵消价格偏差。自主AI代理优化去中心化交易所（DEXs）上的Delta对冲，而zkSNARKs则在不暴露身份或交易细节的情况下证明符合反洗钱（AML）法规。我们的密码学设计降低了跨链流动性集中度（赫芬达尔-赫希曼指数：2,400，而单链系统为4,900），并在标准密码学假设下确保了原子性。该协议的分层架构涵盖了激励兼容的SFCs、AI驱动的市场做市和零知识监管证明。它为下一代去中心化金融基础设施提供了蓝图。", "summary": "本文提出一种混合稳定协议，旨在解决稳定币在去中心化、稳定性与监管合规性方面的三难困境。该协议整合了加密抵押储备、算法期货合约和跨链流动性池，通过引入稳定期货合约（SFCs）并利用适配器签名原子交换激励套利者纠正价格偏差。此外，自主AI代理优化Delta对冲，而zkSNARKs则用于在保护隐私的前提下证明监管合规性。实验结果表明，该协议显著降低了跨链流动性集中度，并确保了交易的原子性，为未来去中心化金融基础设施提供了可行方案。", "keywords": "稳定币, 跨链, 适配器签名, AI套利, 零知识证明", "comments": "该论文提出了一种创新的混合稳定协议，通过结合加密经济激励（SFCs）、AI驱动的套利优化和零知识证明（zkSNARKs）实现了在去中心化、稳定性与合规性之间的平衡。其在降低流动性集中度方面的表现是亮点，为解决稳定币长期存在的“不可能三角”问题提供了新的思路和技术框架，对未来DeFi发展具有重要指导意义。"}}
{"id": "2506.05903", "title": "The NetMob25 Dataset: A High-resolution Multi-layered View of Individual Mobility in Greater Paris Region", "authors": ["Alexandre Chasse", "Anne J. Kouam", "Aline C. Viana", "Razvan Stanica", "Wellington V. Lobato", "Geymerson Ramos", "Geoffrey Deperle", "Abdelmounaim Bouroudi", "Suzanne Bussod", "Fernando Molano"], "summary": "High-quality mobility data remains scarce despite growing interest from\nresearchers and urban stakeholders in understanding individual-level movement\npatterns. The Netmob25 Data Challenge addresses this gap by releasing a unique\nGPS-based mobility dataset derived from the EMG 2023 GNSS-based mobility survey\nconducted in the Ile-de-France region (Greater Paris area), France. This\ndataset captures detailed daily mobility over a full week for 3,337 volunteer\nresidents aged 16 to 80, collected between October 2022 and May 2023. Each\nparticipant was equipped with a dedicated GPS tracking device configured to\nrecord location points every 2-3 seconds and was asked to maintain a digital or\npaper logbook of their trips. All inferred mobility traces were algorithmically\nprocessed and validated through follow-up phone interviews.\n  The dataset includes three components: (i) an Individuals database describing\ndemographic, socioeconomic, and household characteristics; (ii) a Trips\ndatabase with over 80,000 annotated displacements including timestamps,\ntransport modes, and trip purposes; and (iii) a Raw GPS Traces database\ncomprising about 500 million high-frequency points. A statistical weighting\nmechanism is provided to support population-level estimates. An extensive\nanonymization pipeline was applied to the GPS traces to ensure GDPR compliance\nwhile preserving analytical value. Access to the dataset requires acceptance of\nthe challenge's Terms and Conditions and signing a Non-Disclosure Agreement.\nThis paper describes the survey design, collection protocol, processing\nmethodology, and characteristics of the released dataset.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.05903v1", "AI": {"title_translation": "NetMob25数据集：大巴黎地区个人出行的高分辨率多层视图", "tldr": "本文介绍了NetMob25数据集，这是一个为大巴黎地区收集的高分辨率、多层次的个人出行GPS数据集，旨在弥补高质量出行数据稀缺的现状。", "motivation": "尽管研究人员和城市利益相关者对理解个体层面的出行模式越来越感兴趣，但高质量的出行数据仍然稀缺。Netmob25数据挑战旨在通过发布独特的基于GPS的出行数据集来解决这一差距。", "method": "该数据集来源于2022年10月至2023年5月期间在法兰西岛大巴黎地区进行的EMG 2023 GNSS出行调查。3,337名16至80岁的志愿者居民被配备了GPS追踪设备，每2-3秒记录一次位置点，并被要求维护数字或纸质的出行日志。所有推断出的出行轨迹都经过算法处理，并通过后续电话访谈进行验证。GPS轨迹经过了广泛的匿名化处理以确保GDPR合规性。", "result": "该数据集包含三个组成部分：(i)一个包含人口统计、社会经济和家庭特征的个体数据库；(ii)一个包含超过80,000个带时间戳、交通模式和出行目的的标注位移的出行数据库；(iii)一个包含约5亿高频点的原始GPS轨迹数据库。此外，还提供了统计加权机制以支持人口层面的估计。", "conclusion": "本文描述了NetMob25数据集的调查设计、数据收集协议、处理方法和已发布数据集的特征。", "translation": "尽管研究人员和城市利益相关者对理解个体层面的出行模式越来越感兴趣，但高质量的出行数据仍然稀缺。Netmob25数据挑战旨在通过发布独特的基于GPS的出行数据集来解决这一差距，该数据集来源于2023年在法兰西岛地区（大巴黎地区）进行的EMG 2023 GNSS出行调查。该数据集记录了2022年10月至2023年5月期间，3,337名16至80岁的志愿居民为期一周的详细日常出行情况。每位参与者都配备了专用的GPS追踪设备，设置为每2-3秒记录一次位置点，并被要求维护其出行的数字或纸质日志。所有推断出的出行轨迹都经过算法处理，并通过后续电话访谈进行验证。\n\n该数据集包括三个组成部分：(i)一个描述人口统计、社会经济和家庭特征的个体数据库；(ii)一个包含超过80,000个标注位移的出行数据库，包括时间戳、交通模式和出行目的；(iii)一个包含约5亿高频点的原始GPS轨迹数据库。为了支持人口层面的估计，还提供了统计加权机制。为了确保GDPR合规性并保留分析价值，GPS轨迹应用了广泛的匿名化流程。访问数据集需要接受挑战的条款和条件并签署保密协议。\n\n本文描述了该调查的设计、收集协议、处理方法以及已发布数据集的特征。", "summary": "本文介绍了NetMob25数据集，这是一个通过GPS追踪设备和日志收集的、针对大巴黎地区个人出行的高分辨率、多层次数据集。该数据集旨在解决高质量出行数据稀缺的问题，包含了个人特征、标注出行记录和原始GPS轨迹三部分，并经过严格的匿名化处理以确保隐私合规性。文章详细阐述了数据的收集、处理和特征。", "keywords": "出行数据, GPS, 大巴黎地区, 数据集, 匿名化", "comments": "NetMob25数据集的创新之处在于其高分辨率和多层次的出行数据，以及对GDPR合规性的严格遵循，这对于个人出行研究具有重要意义。它通过结合GPS数据和人工日志，提供了更精确和丰富的出行信息。该数据集的发布有望推动对个体出行模式的深入理解和城市规划的发展。其局限性在于访问需要签署保密协议，可能限制了其广泛应用。"}}
{"id": "2506.05401", "title": "Robust Anti-Backdoor Instruction Tuning in LVLMs", "authors": ["Yuan Xun", "Siyuan Liang", "Xiaojun Jia", "Xinwei Liu", "Xiaochun Cao"], "summary": "Large visual language models (LVLMs) have demonstrated excellent\ninstruction-following capabilities, yet remain vulnerable to stealthy backdoor\nattacks when finetuned using contaminated data. Existing backdoor defense\ntechniques are usually developed for single-modal visual or language models\nunder fully parameter-adjustable settings or rely on supervisory knowledge\nduring training. However, in real-world scenarios, defenders cannot modify\nfrozen visual encoders or core LLM parameters, nor possess prior knowledge of\nunknown trigger patterns or target responses. Motivated by the empirical\nfinding that LVLMs readily overfit to fixed, unknown triggers, which can embed\nmalicious associations during adapter-level tuning, we aim to design a defense\nthat operates without access to core weights or attack priors. To this end, we\nintroduce a lightweight, certified-agnostic defense framework, Robust\nInstruction Tuning, that finetunes only adapter modules and text embedding\nlayers under instruction tuning. Our method integrates two complementary\nregularizations: (1) Input Diversity Regularization, which perturbs trigger\ncomponents across training samples to disrupt consistent spurious cues; and (2)\nAnomalous Activation Regularization, which dynamically sparses adapter weights\nexhibiting abnormally sharp activations linked to backdoor patterns. These\nmechanisms jointly guide the model toward learning semantically grounded\nrepresentations rather than memorizing superficial trigger-response mappings.\n  Extensive experiments against seven attacks on Flickr30k and MSCOCO\ndemonstrate that ours\n  reduces their attack success rate to nearly zero, with an increase in\ntraining cost of less than 15%.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05401v1", "AI": {"title_translation": "LVLM中鲁棒的抗后门指令微调", "tldr": "大型视觉语言模型（LVLMs）在指令微调过程中易受后门攻击。本文提出了一种名为“鲁棒指令微调”的轻量级防御框架，通过两种互补的正则化方法，在不修改核心模型参数或需要攻击先验知识的情况下，有效对抗后门攻击，将攻击成功率降低至接近零，且训练成本增加不到15%。", "motivation": "大型视觉语言模型（LVLMs）在指令微调时容易受到后门攻击，而现有防御技术通常针对单模态模型且需要完全可调参数或监督知识，不适用于核心参数冻结且攻击模式未知等真实世界场景。研究发现LVLM容易过拟合固定的未知触发器，这促使研究者设计一种无需访问核心权重或攻击先验知识的防御方法。", "method": "本文引入了一种轻量级、认证无关的防御框架，名为“鲁棒指令微调”，该框架仅在指令微调过程中对适配器模块和文本嵌入层进行微调。该方法集成了两种互补的正则化技术：1）输入多样性正则化，通过扰动训练样本中的触发器组件来破坏一致的虚假线索；2）异常激活正则化，动态稀疏化表现出与后门模式相关的异常尖锐激活的适配器权重。这些机制共同引导模型学习语义上有基础的表示，而不是记忆肤浅的触发器-响应映射。", "result": "在Flickr30k和MSCOCO数据集上针对七种攻击进行的大量实验表明，本文提出的方法能将攻击成功率降低到几乎为零，且训练成本增加不到15%。", "conclusion": "本文提出的鲁棒指令微调框架在真实世界约束下有效防御了LVLMs的后门攻击，实现了高鲁棒性且开销极小。", "translation": "大型视觉语言模型（LVLMs）已展现出卓越的指令遵循能力，但在使用受污染数据进行微调时，仍易受隐蔽后门攻击。现有后门防御技术通常是为单模态视觉或语言模型在完全参数可调设置下开发的，或依赖训练期间的监督知识。然而，在真实世界场景中，防御者无法修改冻结的视觉编码器或核心LLM参数，也无法预先了解未知的触发模式或目标响应。基于LVLMs容易过拟合固定、未知触发器（这可能在适配器级微调期间嵌入恶意关联）的经验发现，我们的目标是设计一种无需访问核心权重或攻击先验知识的防御方法。为此，我们引入了一个轻量级、认证无关的防御框架——鲁棒指令微调，该框架仅在指令微调下微调适配器模块和文本嵌入层。我们的方法整合了两种互补的正则化技术：(1) 输入多样性正则化，它扰动训练样本中的触发器组件以破坏一致的虚假线索；和 (2) 异常激活正则化，它动态稀疏化表现出与后门模式相关的异常尖锐激活的适配器权重。这些机制共同引导模型学习语义上有基础的表示，而不是记忆肤浅的触发器-响应映射。在Flickr30k和MSCOCO上针对七种攻击进行的大量实验表明，我们的方法能将攻击成功率降低到几乎为零，且训练成本增加不到15%。", "summary": "大型视觉语言模型（LVLMs）在指令微调过程中易受后门攻击，尤其是在无法访问核心模型参数或攻击先验知识的真实场景中。针对这一挑战，本文提出了一种名为“鲁棒指令微调”的轻量级防御框架。该框架仅对适配器模块和文本嵌入层进行微调，并结合了两种正则化技术：输入多样性正则化（扰动触发器）和异常激活正则化（稀疏化异常激活的适配器权重）。这些机制旨在引导模型学习更具语义基础的表示，而非简单记忆触发器-响应映射。实验结果表明，该方法能有效将多种后门攻击的成功率降至接近零，且仅带来不到15%的训练成本增加。", "keywords": "LVLMs, 后门攻击, 指令微调, 鲁棒性, 适配器微调", "comments": "本文的创新点在于其在现实约束（核心参数冻结、无攻击先验）下对LVLMs后门攻击的有效防御。其轻量级的适配器级微调方法以及两种互补的正则化技术是关键。这项研究的重要性在于提升了LVLMs在实际部署中的安全性和可信度。"}}
{"id": "2506.05542", "title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data", "authors": ["Vlastimil Martinek", "Andrea Gariboldi", "Dimosthenis Tzimotoudis", "Aitor Alberdi Escudero", "Edward Blake", "David Cechak", "Luke Cassar", "Alessandro Balestrucci", "Panagiotis Alexiou"], "summary": "The adoption of machine learning (ML) and deep learning methods has\nrevolutionized molecular medicine by driving breakthroughs in genomics,\ntranscriptomics, drug discovery, and biological systems modeling. The\nincreasing quantity, multimodality, and heterogeneity of biological datasets\ndemand automated methods that can produce generalizable predictive models.\nRecent developments in large language model-based agents have shown promise for\nautomating end-to-end ML experimentation on structured benchmarks. However,\nwhen applied to heterogeneous computational biology datasets, these methods\nstruggle with generalization and success rates. Here, we introduce\nAgentomics-ML, a fully autonomous agent-based system designed to produce a\nclassification model and the necessary files for reproducible training and\ninference. Our method follows predefined steps of an ML experimentation\nprocess, repeatedly interacting with the file system through Bash to complete\nindividual steps. Once an ML model is produced, training and validation metrics\nprovide scalar feedback to a reflection step to identify issues such as\noverfitting. This step then creates verbal feedback for future iterations,\nsuggesting adjustments to steps such as data representation, model\narchitecture, and hyperparameter choices. We have evaluated Agentomics-ML on\nseveral established genomic and transcriptomic benchmark datasets and show that\nit outperforms existing state-of-the-art agent-based methods in both\ngeneralization and success rates. While state-of-the-art models built by domain\nexperts still lead in absolute performance on the majority of the computational\nbiology datasets used in this work, Agentomics-ML narrows the gap for fully\nautonomous systems and achieves state-of-the-art performance on one of the used\nbenchmark datasets. The code is available at\nhttps://github.com/BioGeMT/Agentomics-ML.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05542v1", "AI": {"title_translation": "Agentomics-ML：用于基因组和转录组数据的自主机器学习实验代理", "tldr": "Agentomics-ML是一个自主ML代理，专门用于基因组和转录组数据，通过反射机制提高泛化性和成功率，优于现有代理方法。", "motivation": "机器学习和深度学习在分子医学中取得突破，但生物数据集的增加、多模态和异质性要求自动化方法能够生成可泛化的预测模型。现有基于LLM的代理在应用于异构计算生物学数据集时，泛化性和成功率较低。", "method": "引入Agentomics-ML，一个完全自主的基于代理的系统。它遵循预定义的ML实验步骤，通过Bash与文件系统交互完成每个步骤。生成模型后，训练和验证指标会向反射步骤提供标量反馈，以识别过拟合等问题。反射步骤创建口头反馈，为未来迭代建议调整数据表示、模型架构和超参数选择等。", "result": "在多个基因组和转录组基准数据集上进行了评估，Agentomics-ML在泛化性和成功率方面优于现有最先进的基于代理的方法。虽然领域专家构建的模型在大多数计算生物学数据集上仍保持绝对性能领先，但Agentomics-ML缩小了与完全自主系统之间的差距，并在其中一个基准数据集上实现了最先进的性能。", "conclusion": "Agentomics-ML通过其自主的、基于反射的ML实验方法，显著提升了在基因组和转录组数据上自动化模型构建的性能，尤其是在泛化性和成功率方面，并为缩小与人类专家模型之间的差距奠定了基础。", "translation": "机器学习（ML）和深度学习方法的采用通过推动基因组学、转录组学、药物发现和生物系统建模的突破，彻底改变了分子医学。生物数据集数量的增加、多模态性和异质性要求自动化方法能够生成可泛化的预测模型。大型语言模型（LLM）驱动的代理的最新发展在结构化基准上自动化端到端ML实验方面显示出前景。然而，当应用于异构计算生物学数据集时，这些方法在泛化性和成功率方面表现不佳。在此，我们介绍了Agentomics-ML，一个完全自主的基于代理的系统，旨在生成分类模型和可重现训练和推理所需的文件。我们的方法遵循ML实验过程的预定义步骤，通过Bash反复与文件系统交互以完成各个步骤。一旦生成ML模型，训练和验证指标会向反射步骤提供标量反馈，以识别过拟合等问题。此步骤随后为未来的迭代创建口头反馈，建议调整数据表示、模型架构和超参数选择等步骤。我们已在几个已建立的基因组和转录组基准数据集上评估了Agentomics-ML，结果表明它在泛化性和成功率方面均优于现有最先进的基于代理的方法。尽管领域专家构建的最先进模型在本文使用的多数计算生物学数据集上的绝对性能仍处于领先地位，但Agentomics-ML缩小了完全自主系统之间的差距，并在其中一个使用的基准数据集上实现了最先进的性能。代码可在https://github.com/BioGeMT/Agentomics-ML获取。", "summary": "Agentomics-ML是一个为基因组和转录组数据设计的自主机器学习实验代理。它通过预定义步骤和与文件系统的交互来构建分类模型，并通过反射机制提供反馈以改进数据表示、模型架构和超参数。该系统在泛化性和成功率方面超越了现有代理方法，并缩小了与人类专家构建的模型之间的性能差距。", "keywords": "自主机器学习代理, 基因组学, 转录组学, 反射机制, 计算生物学", "comments": "本文提出了一种新颖的自主机器学习代理系统Agentomics-ML，其创新之处在于引入了基于反射的反馈机制，允许系统自我识别问题并调整实验策略，这对于处理复杂且异构的生物学数据至关重要。其重要性体现在提升了自动化ML在基因组和转录组领域的应用潜力，并为缩小自动化系统与人类专家之间的性能差距提供了有效途径。虽然在绝对性能上仍有提升空间，但其在泛化性和成功率上的改进是显著的。"}}
{"id": "2506.05741", "title": "A Soft Robotic Module with Pneumatic Actuation and Enhanced Controllability Using a Shape Memory Alloy Wire", "authors": ["Mohammadnavid Golchin"], "summary": "In this paper, a compressed air-actuated soft robotic module was developed by\nincorporating a shape memory alloy (SMA) wire into its structure to achieve the\ndesired bending angle with greater precision. First, a fiber-reinforced bending\nmodule with a strain-limiting layer made of polypropylene was fabricated. The\nSMA wire was then placed in a silicon matrix, which was used as a new\nstrain-limiting layer. A simple closed-loop control algorithm was used to\nregulate the bending angle of the soft robot within its workspace. A camera was\nutilized to measure the angular changes in the vertical plane. Different\nangles, ranging from 0 to 65 degrees, were covered to evaluate the performance\nof the module and the bending angle control algorithm. The experimental tests\ndemonstrate that using the SMA wire results in more precise control of bending\nin the vertical plane. In addition, it is possible to bend more with less\nworking pressure. The error range was reduced from an average of 5 degrees to 2\ndegrees, and the rise time was reduced from an average of 19 seconds to 3\nseconds.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05741v1", "AI": {"title_translation": "采用形状记忆合金线增强可控性的气动软体机器人模块", "tldr": "通过引入形状记忆合金线，开发了一种气动软体机器人模块，显著提高了弯曲角度的控制精度和响应速度。", "motivation": "开发一种气动软体机器人模块，以更高的精度实现所需的弯曲角度。", "method": "首先，制作了一个带有聚丙烯应变限制层的纤维增强弯曲模块。然后，将形状记忆合金（SMA）线置于硅基质中作为新的应变限制层。使用简单的闭环控制算法来调节软体机器人的弯曲角度，并利用摄像头测量垂直平面内的角度变化。", "result": "使用SMA线使得垂直平面内的弯曲控制更加精确，能以更低的工作压力实现更大的弯曲。误差范围从平均5度减少到2度，上升时间从平均19秒减少到3秒。", "conclusion": "通过在气动软体机器人模块中集成形状记忆合金线，可以显著提高弯曲角度的控制精度和响应速度，并降低所需工作压力。", "translation": "在本文中，通过将形状记忆合金（SMA）线集成到其结构中，开发了一种压缩空气驱动的软体机器人模块，以更高的精度实现所需的弯曲角度。首先，制作了一个带有聚丙烯应变限制层的纤维增强弯曲模块。然后，将SMA线置于硅基质中，该硅基质被用作新的应变限制层。使用简单的闭环控制算法来调节软体机器人在其工作空间内的弯曲角度。利用摄像头测量垂直平面内的角度变化。涵盖了0到65度范围内的不同角度，以评估模块和弯曲角度控制算法的性能。实验测试表明，使用SMA线可以更精确地控制垂直平面内的弯曲。此外，可以用更少的工作压力实现更大的弯曲。误差范围从平均5度减少到2度，上升时间从平均19秒减少到3秒。", "summary": "本文开发了一种新型气动软体机器人模块，通过在结构中引入形状记忆合金（SMA）线，显著提升了弯曲角度的控制精度。该模块采用纤维增强设计，并利用SMA线作为新的应变限制层。结合闭环控制算法和视觉测量，实验证明该方法将弯曲误差从5度降至2度，响应时间从19秒缩短至3秒，同时降低了操作压力，实现了更精确、更高效的弯曲控制。", "keywords": "软体机器人, 气动, 形状记忆合金, 精确控制, 弯曲模块", "comments": "这篇论文通过巧妙地将形状记忆合金线集成到气动软体机器人中，解决了传统气动软体机器人控制精度不足的问题。其创新点在于利用SMA线作为可变应变限制层，实现了对弯曲角度的精细调节。实验结果表明了显著的性能提升，尤其是在精度和响应速度方面，这对于软体机器人实际应用具有重要意义。"}}
{"id": "2506.05367", "title": "Text2Stereo: Repurposing Stable Diffusion for Stereo Generation with Consistency Rewards", "authors": ["Aakash Garg", "Libing Zeng", "Andrii Tsarov", "Nima Khademi Kalantari"], "summary": "In this paper, we propose a novel diffusion-based approach to generate stereo\nimages given a text prompt. Since stereo image datasets with large baselines\nare scarce, training a diffusion model from scratch is not feasible. Therefore,\nwe propose leveraging the strong priors learned by Stable Diffusion and\nfine-tuning it on stereo image datasets to adapt it to the task of stereo\ngeneration. To improve stereo consistency and text-to-image alignment, we\nfurther tune the model using prompt alignment and our proposed stereo\nconsistency reward functions. Comprehensive experiments demonstrate the\nsuperiority of our approach in generating high-quality stereo images across\ndiverse scenarios, outperforming existing methods.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05367v1", "AI": {"title_translation": "Text2Stereo: 将 Stable Diffusion 用于立体图像生成，并引入一致性奖励", "tldr": "提出了一种新颖的基于扩散模型的方法，利用 Stable Diffusion 生成高质量的文本提示驱动的立体图像，并通过一致性奖励进一步优化。", "motivation": "由于缺乏大基线的立体图像数据集，从头开始训练扩散模型不可行，因此需要一种有效的方法来生成立体图像。", "method": "本文提出利用 Stable Diffusion 学习到的强大先验知识，并在立体图像数据集上对其进行微调以适应立体图像生成任务。为了提高立体一致性和文本到图像的对齐，进一步使用提示对齐和提出的立体一致性奖励函数对模型进行调整。", "result": "全面的实验证明，该方法在生成高质量立体图像方面优于现有方法，适用于各种场景。", "conclusion": "该方法能够生成高质量的立体图像，并在性能上超越现有方法。", "translation": "本文提出了一种新颖的基于扩散模型的方法，用于根据文本提示生成立体图像。由于缺乏具有大基线的立体图像数据集，从头开始训练扩散模型是不可行的。因此，我们建议利用 Stable Diffusion 学习到的强大先验知识，并在立体图像数据集上对其进行微调，以适应立体图像生成任务。为了提高立体一致性和文本到图像的对齐，我们进一步使用提示对齐和我们提出的立体一致性奖励函数来调整模型。全面的实验证明，我们的方法在生成各种场景下的高质量立体图像方面具有优越性，超越了现有方法。", "summary": "本文提出了一种名为 Text2Stereo 的新颖扩散模型方法，旨在通过文本提示生成立体图像。鉴于大基线立体图像数据集的稀缺性，该方法利用预训练的 Stable Diffusion 模型，并在立体图像数据集上进行微调。为增强立体一致性和文本-图像对齐，模型进一步通过提示对齐和新颖的立体一致性奖励函数进行优化。实验结果表明，该方法在生成高质量立体图像方面表现优异，超越了现有技术。", "keywords": "立体图像生成, 扩散模型, Stable Diffusion, 一致性奖励, 文本到图像", "comments": "这项工作创新性地将预训练的 Stable Diffusion 模型应用于立体图像生成，解决了数据稀缺的挑战。通过引入一致性奖励函数，有效提升了生成图像的立体质量和文本对齐度，为文本到立体图像生成领域开辟了新途径。"}}
{"id": "2506.05817", "title": "CodeContests+: High-Quality Test Case Generation for Competitive Programming", "authors": ["Zihan Wang", "Siyao Liu", "Yang Sun", "Hongyan Li", "Kai Shen"], "summary": "Competitive programming, due to its high reasoning difficulty and precise\ncorrectness feedback, has become a key task for both training and evaluating\nthe reasoning capabilities of large language models (LLMs). However, while a\nlarge amount of public problem data, such as problem statements and solutions,\nis available, the test cases of these problems are often difficult to obtain.\nTherefore, test case generation is a necessary task for building large-scale\ndatasets, and the quality of the test cases directly determines the accuracy of\nthe evaluation. In this paper, we introduce an LLM-based agent system that\ncreates high-quality test cases for competitive programming problems. We apply\nthis system to the CodeContests dataset and propose a new version with improved\ntest cases, named CodeContests+. We evaluated the quality of test cases in\nCodeContestsPlus. First, we used 1.72 million submissions with pass/fail labels\nto examine the accuracy of these test cases in evaluation. The results\nindicated that CodeContests+ achieves significantly higher accuracy than\nCodeContests, particularly with a notably higher True Positive Rate (TPR).\nSubsequently, our experiments in LLM Reinforcement Learning (RL) further\nconfirmed that improvements in test case quality yield considerable advantages\nfor RL.", "comment": "28 pages, 7 figures", "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05817v1", "AI": {"title_translation": "CodeContests+：高质量竞技编程测试用例生成", "tldr": "本文提出了一个基于LLM的智能体系统，用于生成高质量竞技编程测试用例，并创建了CodeContests+数据集，显著提高了LLM评估的准确性，并对强化学习有益。", "motivation": "竞技编程是训练和评估大型语言模型（LLMs）推理能力的关键任务，但高质量的测试用例难以获取，而测试用例的质量直接影响评估的准确性。因此，需要生成高质量的测试用例以构建大规模数据集。", "method": "本文引入了一个基于LLM的智能体系统，该系统专门用于创建高质量的竞技编程问题测试用例。该系统被应用于CodeContests数据集，从而构建了一个具有改进测试用例的新版本——CodeContests+。", "result": "通过对172万次提交的评估，CodeContests+的测试用例在评估准确性方面显著优于CodeContests，尤其在真阳性率（TPR）方面表现出显著提高。此外，LLM强化学习实验也证实了测试用例质量的改进对强化学习带来了显著优势。", "conclusion": "高质量测试用例的生成对于提高大型语言模型（LLMs）在竞技编程任务中的评估准确性至关重要，并且对LLM的强化学习过程具有显著的积极影响。CodeContests+提供了更准确的评估基础。", "translation": "竞技编程因其高推理难度和精确的正确性反馈，已成为训练和评估大型语言模型（LLMs）推理能力的关键任务。然而，尽管大量的公开问题数据（如问题描述和解决方案）可用，但这些问题的测试用例通常难以获取。因此，测试用例生成是构建大规模数据集的必要任务，而测试用例的质量直接决定了评估的准确性。在本文中，我们介绍了一个基于LLM的智能体系统，该系统为竞技编程问题创建高质量的测试用例。我们将此系统应用于CodeContests数据集，并提出了一个具有改进测试用例的新版本，名为CodeContests+。我们评估了CodeContests+中测试用例的质量。首先，我们使用了172万次带有通过/失败标签的提交来检查这些测试用例在评估中的准确性。结果表明，CodeContests+比CodeContests实现了显著更高的准确性，特别是真阳性率（TPR）显著更高。随后，我们在LLM强化学习（RL）中的实验进一步证实，测试用例质量的改进为RL带来了可观的优势。", "summary": "本文提出了一种基于大型语言模型（LLM）的智能体系统，旨在为竞技编程问题生成高质量的测试用例。研究人员将此系统应用于CodeContests数据集，并创建了增强版CodeContests+。评估结果显示，CodeContests+在评估准确性上显著优于原始CodeContests，尤其体现在更高的真阳性率。此外，LLM强化学习实验进一步验证了高质量测试用例对RL的积极影响。", "keywords": "竞技编程, 测试用例生成, 大型语言模型, CodeContests+, 评估准确性", "comments": "这篇论文通过开发基于LLM的智能体系统来生成高质量的竞技编程测试用例，解决了LLM推理能力评估中的一个关键瓶颈。CodeContests+的提出为训练和评估大型语言模型提供了更可靠、更精确的数据集。其创新之处在于利用LLM本身来生成评估LLM的工具，形成了一个有益的闭环。这项工作对于推动LLM在复杂编程和推理任务上的发展具有重要意义。"}}
{"id": "2506.06153", "title": "Personalized Large Language Models Can Increase the Belief Accuracy of Social Networks", "authors": ["Adiba Mahbub Proma", "Neeley Pate", "Sean Kelty", "Gourab Ghoshal", "James N. Druckman", "Ehsan Hoque"], "summary": "Large language models (LLMs) are increasingly involved in shaping public\nunderstanding on contested issues. This has led to substantial discussion about\nthe potential of LLMs to reinforce or correct misperceptions. While existing\nliterature documents the impact of LLMs on individuals' beliefs, limited work\nexplores how LLMs affect social networks. We address this gap with a\npre-registered experiment (N = 1265) around the 2024 US presidential election,\nwhere we empirically explore the impact of personalized LLMs on belief accuracy\nin the context of social networks. The LLMs are constructed to be personalized,\noffering messages tailored to individuals' profiles, and to have guardrails for\naccurate information retrieval. We find that the presence of a personalized LLM\nleads individuals to update their beliefs towards the truth. More importantly,\nindividuals with a personalized LLM in their social network not only choose to\nfollow it, indicating they would like to obtain information from it in\nsubsequent interactions, but also construct subsequent social networks to\ninclude other individuals with beliefs similar to the LLM -- in this case, more\naccurate beliefs. Therefore, our results show that LLMs have the capacity to\ninfluence individual beliefs and the social networks in which people exist, and\nhighlight the potential of LLMs to act as corrective agents in online\nenvironments. Our findings can inform future strategies for responsible\nAI-mediated communication.", "comment": "Adiba and Neeley contributed equally to the project", "cate": "cs.SI", "url": "http://arxiv.org/pdf/2506.06153v1", "AI": {"title_translation": "个性化大型语言模型可以提高社交网络的信念准确性", "tldr": "个性化大型语言模型（LLMs）可以帮助个体更新信念以趋向真相，并影响社交网络形成，从而提高整体信念准确性。", "motivation": "现有文献记录了LLMs对个体信念的影响，但很少有研究探讨LLMs如何影响社交网络。本研究旨在弥补这一空白。", "method": "本研究通过一项针对2024年美国总统选举的预注册实验（N=1265）来探讨个性化LLMs对社交网络中信念准确性的影响。LLMs被设计为个性化，提供量身定制的信息，并具有准确信息检索的防护措施。", "result": "研究发现，个性化LLM的存在促使个体将信念更新至真相。更重要的是，社交网络中拥有个性化LLM的个体不仅选择关注它，还会构建包含与LLM信念相似（即更准确信念）的其他个体的后续社交网络。", "conclusion": "LLMs有能力影响个体信念及其所存在的社交网络，并有望在线环境中充当纠正性代理。", "translation": "大型语言模型（LLMs）日益参与塑造公众对争议问题的理解。这引发了关于LLMs强化或纠正错误观念潜力的广泛讨论。现有文献记录了LLMs对个体信念的影响，但很少有工作探讨LLMs如何影响社交网络。我们通过一项围绕2024年美国总统选举的预注册实验（N = 1265）弥补了这一空白，在该实验中，我们实证探讨了个性化LLMs在社交网络背景下对信念准确性的影响。这些LLMs被构建为个性化的，提供根据个体资料量身定制的消息，并具有准确信息检索的防护措施。我们发现，个性化LLM的存在导致个体将信念更新至真相。更重要的是，社交网络中拥有个性化LLM的个体不仅选择关注它，表明他们希望在后续互动中从中获取信息，而且还会构建后续社交网络以包含其他与LLM信念相似的个体——在这种情况下，是更准确的信念。因此，我们的结果表明，LLMs有能力影响个体信念以及人们所存在的社交网络，并强调了LLMs作为在线环境中纠正性代理的潜力。我们的发现可以为未来负责任的AI介导通信策略提供信息。", "summary": "本研究通过一项针对2024年美国总统选举的实验（N=1265），探讨了个性化大型语言模型（LLMs）如何影响社交网络中的信念准确性。研究发现，个性化LLMs能够促使个体将信念更新至真相，并且这些LLMs在社交网络中能够被个体采纳，并影响社交网络的形成，使其包含更多持有准确信念的个体。这表明LLMs有潜力作为在线环境中的纠正性工具，提高社会整体的信念准确性。", "keywords": "个性化大型语言模型, 社交网络, 信念准确性, 错误信息纠正, 预注册实验", "comments": "这项研究的创新之处在于其首次实证探讨了个性化LLMs对社交网络信念准确性的影响，而不仅仅是关注个体信念。其重要性在于揭示了LLMs在纠正错误信息和塑造更准确社会信念方面的巨大潜力，为负责任的AI介导通信策略提供了新的视角。"}}
{"id": "2506.05529", "title": "Avoiding Death through Fear Intrinsic Conditioning", "authors": ["Rodney Sanchez", "Ferat Sahin", "Alexander Ororbia", "Jamison Heard"], "summary": "Biological and psychological concepts have inspired reinforcement learning\nalgorithms to create new complex behaviors that expand agents' capacity. These\nbehaviors can be seen in the rise of techniques like goal decomposition,\ncurriculum, and intrinsic rewards, which have paved the way for these complex\nbehaviors. One limitation in evaluating these methods is the requirement for\nengineered extrinsic for realistic environments. A central challenge in\nengineering the necessary reward function(s) comes from these environments\ncontaining states that carry high negative rewards, but provide no feedback to\nthe agent. Death is one such stimuli that fails to provide direct feedback to\nthe agent. In this work, we introduce an intrinsic reward function inspired by\nearly amygdala development and produce this intrinsic reward through a novel\nmemory-augmented neural network (MANN) architecture. We show how this intrinsic\nmotivation serves to deter exploration of terminal states and results in\navoidance behavior similar to fear conditioning observed in animals.\nFurthermore, we demonstrate how modifying a threshold where the fear response\nis active produces a range of behaviors that are described under the paradigm\nof general anxiety disorders (GADs). We demonstrate this behavior in the\nMiniworld Sidewalk environment, which provides a partially observable Markov\ndecision process (POMDP) and a sparse reward with a non-descriptive terminal\ncondition, i.e., death. In effect, this study results in a\nbiologically-inspired neural architecture and framework for fear conditioning\nparadigms; we empirically demonstrate avoidance behavior in a constructed agent\nthat is able to solve environments with non-descriptive terminal conditions.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05529v1", "AI": {"title_translation": "通过恐惧内在条件作用避免死亡", "tldr": "本文介绍了一种受杏仁核启发的内在奖励函数，通过记忆增强神经网络（MANN）实现，旨在帮助强化学习代理在缺乏直接负反馈的环境中（如死亡）避免探索终止状态，并展示了类似恐惧条件作用和广义焦虑症的行为。", "motivation": "强化学习算法在评估方法时，需要为现实环境设计外部奖励，但这些环境中的高负奖励状态（如死亡）往往不提供反馈给代理，导致奖励函数工程面临挑战。", "method": "本文引入了一种受早期杏仁核发育启发的内在奖励函数，并通过一种新颖的记忆增强神经网络（MANN）架构生成。此外，通过修改恐惧反应激活的阈值来产生一系列行为。该方法在Miniworld Sidewalk环境中进行了验证。", "result": "这种内在动机能够阻止代理探索终止状态，并产生类似于动物恐惧条件作用中观察到的规避行为。修改恐惧反应阈值能够产生一系列类似于广义焦虑症（GADs）的行为。研究经验性地证明了在构建的代理中，能够解决具有非描述性终止条件的环境中的规避行为。", "conclusion": "这项研究提出了一个受生物学启发的神经网络架构和恐惧条件作用范式框架，并经验性地证明了构建的代理能够通过规避行为解决具有非描述性终止条件的环境。", "translation": "生物学和心理学概念启发了强化学习算法，以创造新的复杂行为，扩展代理的能力。这些行为体现在目标分解、课程学习和内在奖励等技术的兴起，它们为这些复杂行为铺平了道路。评估这些方法的一个限制是，对于现实环境需要精心设计的外部奖励。在工程设计必要的奖励函数时，一个核心挑战来自于这些环境包含高负奖励状态，但却不向代理提供反馈。死亡就是这样一种未能向代理提供直接反馈的刺激。在这项工作中，我们引入了一种受早期杏仁核发育启发的内在奖励函数，并通过一种新颖的记忆增强神经网络（MANN）架构产生这种内在奖励。我们展示了这种内在动机如何阻止探索终止状态，并导致类似于动物中观察到的恐惧条件作用的规避行为。此外，我们还展示了修改恐惧反应激活的阈值如何产生一系列在广义焦虑症（GADs）范式下描述的行为。我们在Miniworld Sidewalk环境中展示了这种行为，该环境提供了一个部分可观察马尔可夫决策过程（POMDP）和稀疏奖励，以及一个非描述性的终止条件，即死亡。实际上，这项研究产生了一个受生物学启发的神经网络架构和恐惧条件作用范式框架；我们经验性地证明了在构建的代理中，能够解决具有非描述性终止条件的环境中的规避行为。", "summary": "本研究提出了一种受生物学启发的记忆增强神经网络（MANN）架构，用于生成内在恐惧奖励，以解决强化学习中代理在缺乏直接负反馈（如死亡）的复杂环境中避免终止状态的挑战。该方法能够使代理表现出类似动物恐惧条件作用的规避行为，并通过调整恐惧反应阈值模拟广义焦虑症的行为范围。实验在Miniworld Sidewalk环境中验证了该方法，证明了其在解决具有非描述性终止条件的环境中的有效性。", "keywords": "恐惧条件作用, 内在奖励, 记忆增强神经网络, 强化学习, 规避行为", "comments": "这项研究通过引入受杏仁核启发的内在奖励函数，并结合记忆增强神经网络（MANN）架构，创新性地解决了强化学习中代理在缺乏直接负反馈（如死亡）的稀疏奖励环境中学习规避行为的挑战。其重要性在于为代理在安全关键型应用中学习避免危险状态提供了新的途径，并展示了生物学启发机制在人工智能领域的潜力。该方法能够模拟动物的恐惧条件作用和广义焦虑症行为，为理解和构建更接近生物智能的代理提供了新的视角。"}}
{"id": "2506.05601", "title": "Network Hexagons Under Attack: Secure Crowdsourcing of Geo-Referenced Data", "authors": ["Okemawo Obadofin", "Joao Barros"], "summary": "A critical requirement for modern-day Intelligent Transportation Systems\n(ITS) is the ability to collect geo-referenced data from connected vehicles and\nmobile devices in a safe, secure and anonymous way. The Nexagon protocol, which\nbuilds on the IETF Locator/ID Separation Protocol (LISP) and the Hierarchical\nHexagonal Clustering (H3) geo-spatial indexing system, offers a promising\nframework for dynamic, privacy-preserving data aggregation. Seeking to address\nthe critical security and privacy vulnerabilities that persist in its current\nspecification, we apply the STRIDE and LINDDUN threat modelling frameworks and\nprove among other that the Nexagon protocol is susceptible to user\nre-identification, session linkage, and sparse-region attacks. To address these\nchallenges, we propose an enhanced security architecture that combines public\nkey infrastructure (PKI) with ephemeral pseudonym certificates. Our solution\nguarantees user and device anonymity through randomized key rotation and\nadaptive geospatial resolution, thereby effectively mitigating\nre-identification and surveillance risks in sparse environments. A prototype\nimplementation over a microservice-based overlay network validates the approach\nand underscores its readiness for real-world deployment. Our results show that\nit is possible to achieve the required level of security without increasing\nlatency by more than 25% or reducing the throughput by more than 7%.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05601v1", "AI": {"title_translation": "受攻击的网络六边形：地理参考数据的安全众包", "tldr": "Nexagon协议用于安全地理数据收集存在安全漏洞（用户再识别、会话关联、稀疏区域攻击）。一种结合PKI和临时假名、密钥轮换和自适应分辨率的新架构解决了这些问题，实现了安全性且对性能影响最小。", "motivation": "现代智能交通系统（ITS）需要以安全、匿名的方式收集地理参考数据。现有的Nexagon协议存在关键的安全和隐私漏洞，包括用户再识别、会话关联和稀疏区域攻击。", "method": "作者应用STRIDE和LINDDUN威胁建模框架来识别Nexagon协议中的漏洞。他们提出了一种增强的安全架构，结合了公钥基础设施（PKI）与临时假名证书、随机密钥轮换和自适应地理空间分辨率。通过基于微服务叠加网络的原型实现来验证该方法。", "result": "所提出的解决方案保证了用户和设备的匿名性，有效缓解了稀疏环境中的再识别和监视风险。原型实现验证了该方法的有效性，并表明在不增加延迟超过25%或降低吞吐量超过7%的情况下，可以达到所需的安全级别。", "conclusion": "本文的结论是，其增强的安全架构有效解决了Nexagon协议中的安全和隐私漏洞，使得安全、匿名的地理参考数据收集成为可能，且性能开销极小，适用于实际部署。", "translation": "现代智能交通系统（ITS）的一个关键要求是能够以安全、保密和匿名的方式从联网车辆和移动设备收集地理参考数据。Nexagon协议建立在IETF定位器/ID分离协议（LISP）和分层六边形聚类（H3）地理空间索引系统之上，为动态、保护隐私的数据聚合提供了一个有前景的框架。为了解决其当前规范中持续存在的关键安全和隐私漏洞，我们应用STRIDE和LINDDUN威胁建模框架，并证明Nexagon协议易受用户再识别、会话关联和稀疏区域攻击。为了应对这些挑战，我们提出了一种增强的安全架构，该架构结合了公钥基础设施（PKI）与临时假名证书。我们的解决方案通过随机密钥轮换和自适应地理空间分辨率保证了用户和设备的匿名性，从而有效缓解了稀疏环境中的再识别和监视风险。通过基于微服务叠加网络的原型实现验证了该方法，并强调了其在实际部署中的准备就绪。我们的结果表明，在不增加延迟超过25%或降低吞吐量超过7%的情况下，可以达到所需的安全级别。", "summary": "本文旨在解决Nexagon协议在智能交通系统（ITS）中安全、匿名收集地理参考数据时存在的安全和隐私漏洞。通过STRIDE和LINDDUN威胁建模，论文识别了用户再识别和稀疏区域攻击等问题。提出的解决方案是一种增强的安全架构，利用PKI、临时假名证书、随机密钥轮换和自适应地理空间分辨率来确保用户匿名性。原型实现验证了其有效性，展示了在可接受的性能开销下提供强大的安全性，适用于实际部署。", "keywords": "Nexagon协议, 地理参考数据, 隐私保护, 安全众包, 匿名性", "comments": "该论文为地理参考数据收集引入了重要的安全增强功能，这对于智能交通系统至关重要。使用成熟的威胁建模框架（STRIDE、LINDDUN）是一个强项。所提出的解决方案将众所周知的安全原语（PKI、临时假名）与特定技术（随机密钥轮换、自适应地理空间分辨率）相结合，以解决位置隐私的独特挑战。性能评估也很好地说明了其实际适用性。"}}
{"id": "2506.05983", "title": "Capacity of MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)", "authors": ["Matteo Nerini", "Bruno Clerckx"], "summary": "Future wireless systems, known as gigantic multiple-input multiple-output\n(MIMO), are expected to enhance performance by significantly increasing the\nnumber of antennas, e.g., a few thousands. To enable gigantic MIMO overcoming\nthe scalability limitations of digital architectures, microwave linear analog\ncomputers (MiLACs) have recently emerged. A MiLAC is a multiport microwave\nnetwork that processes input microwave signals entirely in the analog domain,\nthereby reducing hardware costs and computational complexity of gigantic MIMO\narchitectures. In this paper, we investigate the fundamental limits on the rate\nachievable in MiLAC-aided MIMO systems. We model a MIMO system employing\nMiLAC-aided beamforming at the transmitter and receiver, and formulate the rate\nmaximization problem to optimize the microwave networks of the MiLACs, which\nare assumed lossless and reciprocal for practical reasons. Under the lossless\nand reciprocal constraints, we derive a global optimal solution for the\nmicrowave networks of the MiLACs in closed form. In addition, we also\ncharacterize in closed-form the capacity of MIMO systems operating MiLAC-aided\nbeamforming. Our theoretical analysis, confirmed by numerical simulations,\nreveals that MiLAC-aided beamforming achieves the same capacity as digital\nbeamforming, while significantly reducing the number of radio frequency (RF)\nchains, analog-to-digital converters (ADCs)/digital-to-analog converters (DACs)\nresolution requirements, and computational complexity.", "comment": "Submitted to IEEE for publication", "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.05983v1", "AI": {"title_translation": "微波线性模拟计算机（MiLACs）辅助的MIMO系统容量", "tldr": "本文研究了MiLAC辅助MIMO系统的速率限制，发现MiLAC辅助波束成形在显著降低硬件和计算复杂度的同时，能达到与数字波束成形相同的容量。", "motivation": "未来的巨型多输入多输出（MIMO）系统将显著增加天线数量，但数字架构存在可扩展性限制。微波线性模拟计算机（MiLACs）作为一种新兴技术，旨在解决这些限制，降低硬件成本和计算复杂度。", "method": "研究者建模了采用MiLAC辅助的发射端和接收端波束成形MIMO系统，并提出了速率最大化问题，以优化MiLAC的微波网络（假设无损和互易）。在此约束下，他们推导出了MiLAC微波网络的全局最优闭合解，并以闭合形式表征了MiLAC辅助波束成形MIMO系统的容量。", "result": "理论分析和数值模拟证实，MiLAC辅助波束成形能够实现与数字波束成形相同的系统容量，同时显著减少射频链数量、模数/数模转换器（ADCs/DACs）的分辨率要求以及计算复杂度。", "conclusion": "MiLAC辅助的MIMO系统可以在保持与数字波束成形相同容量的前提下，大幅降低硬件成本和计算复杂度，为未来巨型MIMO系统提供了一种有前景的解决方案。", "translation": "未来无线系统，即巨型多输入多输出（MIMO），有望通过显著增加天线数量（例如数千根）来增强性能。为了使巨型MIMO克服数字架构的可扩展性限制，微波线性模拟计算机（MiLACs）最近应运而生。MiLAC是一种多端口微波网络，它完全在模拟域处理输入微波信号，从而降低了巨型MIMO架构的硬件成本和计算复杂度。在本文中，我们研究了MiLAC辅助MIMO系统可达速率的根本限制。我们建模了一个在发射端和接收端采用MiLAC辅助波束成形的MIMO系统，并提出了速率最大化问题，以优化MiLAC的微波网络，出于实际原因，这些网络被假定为无损和互易的。在无损和互易约束下，我们推导出了MiLAC微波网络的全局最优闭合解。此外，我们还以闭合形式表征了运行MiLAC辅助波束成形的MIMO系统的容量。我们的理论分析得到了数值模拟的证实，结果表明MiLAC辅助波束成形实现了与数字波束成形相同的容量，同时显著减少了射频（RF）链的数量、模数转换器（ADCs）/数模转换器（DACs）的分辨率要求以及计算复杂度。", "summary": "本文研究了微波线性模拟计算机（MiLACs）辅助的多输入多输出（MIMO）系统的容量限制。通过建模MiLAC辅助的发射端和接收端波束成形，并推导出无损互易约束下MiLAC微波网络的全局最优解以及MiLAC辅助MIMO系统的容量闭合形式。研究结果表明，MiLAC辅助波束成形在显著降低硬件成本、射频链数量、ADCs/DACs分辨率要求和计算复杂度的同时，能够达到与传统数字波束成形相同的容量性能。", "keywords": "MIMO系统, MiLACs, 容量, 波束成形, 模拟计算", "comments": "这篇论文的创新之处在于提出了MiLACs作为解决巨型MIMO系统数字架构可扩展性限制的有效方案。其重要性在于证明了模拟计算可以在不牺牲性能的前提下，大幅降低未来无线通信系统的硬件成本和复杂度，为MIMO技术的发展开辟了新途径。"}}
{"id": "2506.05433", "title": "Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward", "authors": ["Zikang Liu", "Tongtian Yue", "Yepeng Tang", "Longteng Guo", "Junxian Cai", "Qingbin Liu", "Xi Chen", "Jing Liu"], "summary": "Group Relative Policy Optimization (GRPO) enhances policy learning by\ncomputing gradients from relative comparisons among candidate outputs that\nshare a common input prefix. Despite its effectiveness, GRPO introduces\nsubstantial computational overhead when processing long shared prefixes, which\nmust be redundantly encoded for each group member. This inefficiency becomes a\nmajor scalability bottleneck in long-context learning scenarios. We propose\nPrefix Grouper, an efficient GRPO training algorithm that eliminates redundant\nprefix computation via a Shared-Prefix Forward strategy. In particular, by\nrestructuring self-attention into two parts, our method enables the shared\nprefix to be encoded only once, while preserving full differentiability and\ncompatibility with end-to-end training. We provide both theoretical and\nempirical evidence that Prefix Grouper is training-equivalent to standard GRPO:\nit yields identical forward outputs and backward gradients, ensuring that the\noptimization dynamics and final policy performance remain unchanged.\nEmpirically, our experiments confirm that Prefix Grouper achieves consistent\nresults while significantly reducing the computational cost of training,\nparticularly in long-prefix scenarios. The proposed method is fully\nplug-and-play: it is compatible with existing GRPO-based architectures and can\nbe seamlessly integrated into current training pipelines as a drop-in\nreplacement, requiring no structural modifications and only minimal changes to\ninput construction and attention computation. Prefix Grouper enables the use of\nlarger group sizes under the same computational budget, thereby improving the\nscalability of GRPO to more complex tasks and larger models. Code is now\navailable at https://github.com/johncaged/PrefixGrouper", "comment": "10 pages, technical report", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05433v1", "AI": {"title_translation": "Prefix Grouper：通过共享前缀前向传播实现高效GRPO训练", "tldr": "Prefix Grouper是一种高效的GRPO训练算法，通过共享前缀前向传播策略消除冗余前缀计算，显著降低计算成本并提高GRPO的可扩展性，同时保持与标准GRPO相同的性能。", "motivation": "尽管GRPO有效，但在处理长共享前缀时会引入大量计算开销，因为每个组成员都必须冗余编码，这在长上下文学习场景中成为主要的扩展性瓶颈。", "method": "本文提出Prefix Grouper，一种通过共享前缀前向传播策略消除冗余前缀计算的GRPO高效训练算法。它将自注意力重构为两部分，使共享前缀只需编码一次，同时保持完全可微分性并兼容端到端训练。", "result": "理论和经验证据表明，Prefix Grouper与标准GRPO训练等效：它产生相同的前向输出和后向梯度，确保优化动态和最终策略性能不变。实验证实，Prefix Grouper在显著降低训练计算成本（特别是在长前缀场景中）的同时，实现了与标准GRPO一致的结果。它完全即插即用，兼容现有GRPO架构，并能以更低的计算预算支持更大的组规模，从而提高GRPO处理更复杂任务和更大模型的可扩展性。", "conclusion": "Prefix Grouper通过消除冗余计算，显著提高了GRPO训练的效率和可扩展性，使其在长上下文学习场景中更具可行性，同时保持了与标准GRPO相同的优化效果和最终性能。", "translation": "前缀分组器：通过共享前缀前向传播实现高效GRPO训练\n\n群组相对策略优化（GRPO）通过计算共享共同输入前缀的候选输出之间的相对比较来增强策略学习。尽管其有效，GRPO在处理长共享前缀时引入了大量的计算开销，这些前缀必须为每个组成员冗余编码。这种低效率在长上下文学习场景中成为主要的扩展性瓶颈。我们提出了Prefix Grouper，一种高效的GRPO训练算法，它通过共享前缀前向传播策略消除了冗余前缀计算。特别是，通过将自注意力重构为两部分，我们的方法使共享前缀只需编码一次，同时保持完全可微分性并兼容端到端训练。我们提供了理论和经验证据，表明Prefix Grouper与标准GRPO训练等效：它产生相同的前向输出和后向梯度，确保优化动态和最终策略性能保持不变。经验上，我们的实验证实，Prefix Grouper在显著降低训练计算成本（特别是在长前缀场景中）的同时，实现了与标准GRPO一致的结果。所提出的方法完全即插即用：它与现有的基于GRPO的架构兼容，并且可以作为即时替换无缝集成到当前的训练管道中，无需结构修改，只需对输入构造和注意力计算进行最小更改。Prefix Grouper使得在相同计算预算下可以使用更大的组规模，从而提高了GRPO处理更复杂任务和更大模型的可扩展性。代码现已在https://github.com/johncaged/PrefixGrouper提供。", "summary": "本论文提出了Prefix Grouper，一种旨在解决群组相对策略优化（GRPO）在处理长共享前缀时面临的计算效率问题的算法。GRPO因冗余编码共享前缀而导致显著的计算开销和可扩展性瓶颈。Prefix Grouper通过引入共享前缀前向传播策略，并重构自注意力机制，实现了共享前缀的一次性编码，从而消除了这种冗余。该方法在理论和实践上都被证明与标准GRPO训练等效，能够产生相同的优化结果和策略性能，同时显著降低了计算成本，尤其是在长前缀场景下。Prefix Grouper具有即插即用的特性，易于集成到现有GRPO训练流程中，并能支持更大组规模，从而提升GRPO在复杂任务和大型模型上的可扩展性。", "keywords": "GRPO, 策略优化, 计算效率, 共享前缀, 自注意力", "comments": "这项工作的创新点在于提出了一种巧妙的方法来解决GRPO在长上下文学习中的计算效率问题，即通过重构自注意力机制实现共享前缀的一次性编码。其重要性在于，在不牺牲性能的前提下显著降低了训练成本，使得GRPO能够更好地扩展到处理更长序列和更复杂的任务，这对于当前大模型和长上下文学习的发展至关重要。其即插即用的特性也大大降低了实际应用的门槛。"}}
{"id": "2506.05640", "title": "FedShield-LLM: A Secure and Scalable Federated Fine-Tuned Large Language Model", "authors": ["Md Jueal Mia", "M. Hadi Amini"], "summary": "Federated Learning (FL) offers a decentralized framework for training and\nfine-tuning Large Language Models (LLMs) by leveraging computational resources\nacross organizations while keeping sensitive data on local devices. It\naddresses privacy and security concerns while navigating challenges associated\nwith the substantial computational demands of LLMs, which can be prohibitive\nfor small and medium-sized organizations. FL supports the development of\ntask-specific LLMs for cross-silo applications through fine-tuning but remains\nvulnerable to inference attacks, such as membership inference and gradient\ninversion, which threaten data privacy. Prior studies have utilized\nDifferential Privacy (DP) in LLM fine-tuning, which, despite being effective at\npreserving privacy, can degrade model performance. To overcome these\nchallenges, we propose a novel method, FedShield-LLM, that uses pruning with\nFully Homomorphic Encryption (FHE) for Low-Rank Adaptation (LoRA) parameters,\nenabling secure computations on encrypted model updates while mitigating the\nattack surface by deactivating less important LoRA parameters. Furthermore,\noptimized federated algorithms for cross-silo environments enhance scalability\nand efficiency. Parameter-efficient fine-tuning techniques like LoRA\nsubstantially reduce computational and communication overhead, making FL\nfeasible for resource-constrained clients. Experimental results show that the\nproposed method outperforms existing methods while maintaining robust privacy\nprotection, enabling organizations to collaboratively train secure and\nefficient LLMs.\n  The code and data are available at,\nhttps://github.com/solidlabnetwork/fedshield-llm", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05640v1", "AI": {"title_translation": "FedShield-LLM：一种安全可扩展的联邦微调大型语言模型", "tldr": "FedShield-LLM提出了一种结合剪枝和全同态加密的新方法，用于LoRA参数的联邦微调大型语言模型，以实现安全、可扩展且高效的隐私保护。", "motivation": "联邦学习（FL）在训练和微调大型语言模型（LLMs）时面临计算资源需求大、小型组织难以承受以及易受成员推理和梯度反转等推理攻击的挑战，现有差分隐私（DP）方法虽能保护隐私但会降低模型性能。", "method": "本文提出了一种名为FedShield-LLM的新方法，它结合了剪枝和全同态加密（FHE）来处理低秩适应（LoRA）参数。这种方法能够在加密模型更新上进行安全计算，并通过禁用不重要的LoRA参数来减少攻击面。此外，针对跨筒仓环境优化的联邦算法提高了可扩展性和效率。参数高效微调技术（如LoRA）显著降低了计算和通信开销。", "result": "实验结果表明，所提出的FedShield-LLM方法在保持强大隐私保护的同时，性能优于现有方法。", "conclusion": "FedShield-LLM使组织能够协同训练安全高效的LLMs。", "translation": "联邦学习（FL）提供了一个去中心化的框架，通过利用跨组织的计算资源来训练和微调大型语言模型（LLMs），同时将敏感数据保留在本地设备上。它解决了隐私和安全问题，同时应对了与LLMs巨大计算需求相关的挑战，这些需求可能对于中小型组织来说是难以承受的。FL通过微调支持跨筒仓应用程序的特定任务LLMs的开发，但仍然容易受到推理攻击，例如成员推理和梯度反转，这威胁到数据隐私。先前的研究在LLM微调中使用了差分隐私（DP），尽管在保护隐私方面有效，但可能会降低模型性能。为了克服这些挑战，我们提出了一种新颖的方法FedShield-LLM，它使用剪枝与全同态加密（FHE）相结合，用于低秩适应（LoRA）参数，从而能够在加密模型更新上进行安全计算，并通过停用不重要的LoRA参数来减轻攻击面。此外，针对跨筒仓环境优化的联邦算法增强了可扩展性和效率。像LoRA这样的参数高效微调技术显著减少了计算和通信开销，使得FL对于资源受限的客户端来说是可行的。实验结果表明，所提出的方法在保持强大隐私保护的同时，性能优于现有方法，使组织能够协同训练安全高效的LLMs。代码和数据可在https://github.com/solidlabnetwork/fedshield-llm获取。", "summary": "本文提出FedShield-LLM，一种针对大型语言模型（LLMs）的联邦微调框架，旨在解决现有联邦学习在隐私保护和计算效率上的挑战。该方法通过结合剪枝和全同态加密（FHE）处理低秩适应（LoRA）参数，实现了在加密状态下的安全模型更新计算，并通过剪枝降低了攻击风险。同时，优化的联邦算法和LoRA技术显著提升了系统的可扩展性和效率。实验证明FedShield-LLM在提供强大隐私保护的同时，其性能优于现有方案，使得组织能够安全高效地协同训练LLMs。", "keywords": "联邦学习, 大型语言模型, 隐私保护, 全同态加密, LoRA", "comments": "FedShield-LLM的创新之处在于其将剪枝与全同态加密（FHE）应用于LoRA参数的联邦微调，有效平衡了隐私保护、模型性能和计算效率。这种结合方法不仅解决了传统差分隐私可能导致性能下降的问题，还通过剪枝进一步减少了攻击面，对于资源受限的组织尤其重要。该研究为联邦学习环境中LLM的安全和可扩展部署提供了新的思路。"}}
{"id": "2506.05755", "title": "FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts", "authors": ["Yang Li", "Zhi Chen"], "summary": "Optimal execution in financial markets refers to the process of strategically\ntransacting a large volume of assets over a period to achieve the best possible\noutcome by balancing the trade-off between market impact costs and timing or\nvolatility risks. Traditional optimal execution strategies, such as static\nAlmgren-Chriss models, often prove suboptimal in dynamic financial markets.\nThis paper propose flowOE, a novel imitation learning framework based on flow\nmatching models, to address these limitations. FlowOE learns from a diverse set\nof expert traditional strategies and adaptively selects the most suitable\nexpert behavior for prevailing market conditions. A key innovation is the\nincorporation of a refining loss function during the imitation process,\nenabling flowOE not only to mimic but also to improve upon the learned expert\nactions. To the best of our knowledge, this work is the first to apply flow\nmatching models in a stochastic optimal execution problem. Empirical\nevaluations across various market conditions demonstrate that flowOE\nsignificantly outperforms both the specifically calibrated expert models and\nother traditional benchmarks, achieving higher profits with reduced risk. These\nresults underscore the practical applicability and potential of flowOE to\nenhance adaptive optimal execution.", "comment": "3 figures, 3 algorithms, 7 tables", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05755v1", "AI": {"title_translation": "FlowOE：基于集成强化学习专家流策略的模仿学习，用于赫斯顿波动率和凹形市场影响下的最优执行", "tldr": "FlowOE利用流匹配从集成强化学习专家策略中学习最优执行，在赫斯顿波动率和凹形市场影响下表现优于传统方法。", "motivation": "传统的最佳执行策略（例如静态Almgren-Chriss模型）在动态金融市场中往往表现不佳，导致次优结果。", "method": "本文提出了FlowOE，一个基于流匹配模型的新型模仿学习框架。FlowOE从多样化的专家传统策略中学习，并自适应地选择最适合当前市场状况的专家行为。一个关键创新是在模仿过程中引入了精炼损失函数，使FlowOE不仅能够模仿，而且能够改进所学的专家行动。", "result": "在各种市场条件下的实证评估表明，FlowOE显著优于经过特定校准的专家模型和其他传统基准，以更低的风险实现了更高的利润。", "conclusion": "FlowOE在增强自适应最优执行方面具有实际适用性和潜力。", "translation": "金融市场中的最优执行是指在一段时间内战略性地交易大量资产，通过平衡市场影响成本与时机或波动风险之间的权衡，以实现最佳结果的过程。传统的最佳执行策略，例如静态Almgren-Chriss模型，在动态金融市场中往往表现不佳。本文提出了一种基于流匹配模型的新型模仿学习框架FlowOE，以解决这些局限性。FlowOE从各种专家传统策略中学习，并自适应地选择最适合当前市场状况的专家行为。一个关键创新是在模仿过程中引入了精炼损失函数，使FlowOE不仅能够模仿，而且能够改进所学的专家行动。据我们所知，这项工作是首次将流匹配模型应用于随机最优执行问题。在各种市场条件下的实证评估表明，FlowOE显著优于经过特定校准的专家模型和其他传统基准，以更低的风险实现了更高的利润。这些结果强调了FlowOE在增强自适应最优执行方面的实际适用性和潜力。", "summary": "本文介绍了FlowOE，一个利用流匹配模型进行金融市场最优执行的模仿学习框架。它通过学习多样化的专家行为并自适应地选择最优行动，解决了传统策略的局限性。其创新之处在于引入了精炼损失函数，使FlowOE不仅能模仿还能改进专家行动。实证结果表明，FlowOE优于现有模型，以更低的风险实现了更高的利润，突出了其在自适应最优执行中的实际适用性。", "keywords": "最优执行, 模仿学习, 流匹配, 集成强化学习, 赫斯顿波动率", "comments": "创新点在于首次将流匹配模型应用于随机最优执行问题，为最优执行问题提供了新的解决方案。该研究解决了传统策略在动态市场中的局限性，通过模仿学习和损失函数改进，实现了更高的利润和更低的风险，具有重要的实践意义和应用潜力。"}}
{"id": "2506.05925", "title": "Small Models, Big Support: A Local LLM Framework for Teacher-Centric Content Creation and Assessment using RAG and CAG", "authors": ["Zarreen Reza", "Alexander Mazur", "Michael T. Dugdale", "Robin Ray-Chaudhuri"], "summary": "While Large Language Models (LLMs) are increasingly utilized as\nstudent-facing educational aids, their potential to directly support educators,\nparticularly through locally deployable and customizable open-source solutions,\nremains significantly underexplored. Many existing educational solutions rely\non cloud-based infrastructure or proprietary tools, which are costly and may\nraise privacy concerns. Regulated industries with limited budgets require\naffordable, self-hosted solutions. We introduce an end-to-end, open-source\nframework leveraging small (3B-7B parameters), locally deployed LLMs for\ncustomized teaching material generation and assessment. Our system uniquely\nincorporates an interactive loop crucial for effective small-model refinement,\nand an auxiliary LLM verifier to mitigate jailbreaking risks, enhancing output\nreliability and safety. Utilizing Retrieval and Context Augmented Generation\n(RAG/CAG), it produces factually accurate, customized pedagogically-styled\ncontent. Deployed on-premises for data privacy and validated through an\nevaluation pipeline and a college physics pilot, our findings show that\ncarefully engineered small LLM systems can offer robust, affordable, practical,\nand safe educator support, achieving utility comparable to larger models for\ntargeted tasks.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.05925v1", "AI": {"title_translation": "小型模型，巨大支持：一个用于教师中心内容创建和评估的本地大型语言模型框架，采用RAG和CAG技术", "tldr": "该研究提出了一个本地部署的开源小型LLM框架，利用RAG和CAG技术，为教师提供定制化的教学材料生成和评估支持，具有成本效益和数据隐私优势，效果可与大型模型媲美。", "motivation": "现有教育解决方案多依赖昂贵的云端或专有工具，存在成本高和隐私问题；受监管行业和预算有限的机构需要负担得起、自托管的解决方案；大型语言模型在直接支持教育工作者方面（尤其是通过本地可部署的开源解决方案）的潜力尚未得到充分探索。", "method": "引入了一个端到端的开源框架，利用小型（3B-7B参数）本地部署的LLM进行定制化教学材料生成和评估。该系统独特地结合了用于小型模型优化的交互循环和用于降低越狱风险的辅助LLM验证器。采用检索增强生成（RAG）和上下文增强生成（CAG）技术生成事实准确、定制化的教学风格内容。", "result": "通过评估流程和大学物理试点验证，研究结果表明，精心设计的小型LLM系统可以为教育工作者提供强大、经济、实用且安全的G支持，在特定任务上达到与大型模型相当的效用。", "conclusion": "精心设计的小型LLM系统能够为教育工作者提供强大、经济、实用且安全的本地支持，在特定任务上可以达到与大型模型相当的效用。", "translation": "尽管大型语言模型（LLM）越来越多地被用作面向学生的教育辅助工具，但它们直接支持教育工作者，特别是通过本地可部署和可定制的开源解决方案的潜力仍未得到充分探索。许多现有的教育解决方案依赖于基于云的基础设施或专有工具，这些工具成本高昂并可能引发隐私问题。预算有限的受监管行业需要负担得起、自托管的解决方案。我们引入了一个端到端、开源的框架，该框架利用小型（3B-7B参数）、本地部署的LLM进行定制化的教学材料生成和评估。我们的系统独特地结合了对于有效的小型模型优化至关重要的交互循环，以及一个辅助LLM验证器以减轻越狱风险，从而增强输出的可靠性和安全性。通过利用检索和上下文增强生成（RAG/CAG），它能生成事实准确、定制化的教学风格内容。该系统在本地部署以保护数据隐私，并通过评估流程和大学物理试点进行了验证，我们的研究结果表明，精心设计的小型LLM系统可以提供强大、经济、实用且安全的教育支持，在目标任务上达到与大型模型相当的效用。", "summary": "本文提出了一个名为“Small Models, Big Support”的本地LLM开源框架，旨在解决教育领域中大型模型部署的成本高和隐私问题。该框架利用小型（3B-7B参数）本地部署的LLM，结合RAG和CAG技术，为教师提供定制化的教学内容创建和评估工具。系统包含交互循环和辅助LLM验证器以提高可靠性和安全性。通过实地部署和试点验证，证明了小型LLM系统在提供经济、实用且安全的教师支持方面，其效用可与大型模型媲美。", "keywords": "小型LLM, 本地部署, 教师支持, RAG, CAG", "comments": "该论文的创新之处在于提出了一种经济高效、数据隐私友好的本地化LLM解决方案，弥补了现有教育AI工具的不足。它证明了小型模型在特定任务上也能提供与大型模型相当的性能，这对于预算有限或对数据隐私有严格要求的教育机构具有重要意义。特别是在框架中加入交互循环和辅助LLM验证器，增强了小模型的实用性和安全性，是其重要贡献。"}}
{"id": "2506.05402", "title": "Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models via Collaborative Fine-tuning", "authors": ["Tianyu Qi", "Lei Xue", "Yufeng Zhan", "Xiaobo Ma"], "summary": "The growing adoption of large pre-trained models in edge computing has made\ndeploying model inference on mobile clients both practical and popular. These\ndevices are inherently vulnerable to direct adversarial attacks, which pose a\nsubstantial threat to the robustness and security of deployed models. Federated\nadversarial training (FAT) has emerged as an effective solution to enhance\nmodel robustness while preserving client privacy. However, FAT frequently\nproduces a generalized global model, which struggles to address the diverse and\nheterogeneous data distributions across clients, resulting in insufficiently\npersonalized performance, while also encountering substantial communication\nchallenges during the training process. In this paper, we propose\n\\textit{Sylva}, a personalized collaborative adversarial training framework\ndesigned to deliver customized defense models for each client through a\ntwo-phase process. In Phase 1, \\textit{Sylva} employs LoRA for local\nadversarial fine-tuning, enabling clients to personalize model robustness while\ndrastically reducing communication costs by uploading only LoRA parameters\nduring federated aggregation. In Phase 2, a game-based layer selection strategy\nis introduced to enhance accuracy on benign data, further refining the\npersonalized model. This approach ensures that each client receives a tailored\ndefense model that balances robustness and accuracy effectively. Extensive\nexperiments on benchmark datasets demonstrate that \\textit{Sylva} can achieve\nup to 50$\\times$ improvements in communication efficiency compared to\nstate-of-the-art algorithms, while achieving up to 29.5\\% and 50.4\\%\nenhancements in adversarial robustness and benign accuracy, respectively.", "comment": "Accepted by the ACM Conference on Computer and Communications\n  Security (CCS) 2025", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05402v1", "AI": {"title_translation": "Sylva：通过协作微调为预训练模型定制个性化对抗防御", "tldr": "Sylva是一种个性化协作对抗训练框架，通过两阶段过程为每个客户端提供定制的防御模型，显著提高通信效率、对抗鲁棒性和良性准确性。", "motivation": "大型预训练模型在边缘计算中的应用日益广泛，但易受直接对抗攻击，对其鲁棒性和安全性构成威胁。现有联邦对抗训练（FAT）产生的全局模型难以解决客户端数据分布的多样性和异构性，导致个性化性能不足，并面临通信挑战。", "method": "本文提出了Sylva框架，一个个性化协作对抗训练框架，旨在通过两阶段过程为每个客户端提供定制的防御模型。第一阶段，Sylva采用LoRA进行局部对抗微调，使客户端能够在联邦聚合期间仅上传LoRA参数，从而大幅降低通信成本，实现模型鲁棒性的个性化。第二阶段，引入基于博弈的层选择策略，以提高良性数据上的准确性，进一步完善个性化模型。", "result": "相比现有算法，Sylva在通信效率方面可提高50倍，同时在对抗鲁棒性方面提高29.5%，良性准确性方面提高50.4%。", "conclusion": "Sylva通过平衡鲁棒性和准确性，为每个客户端提供定制的防御模型，有效解决了联邦对抗训练中个性化不足和通信效率低下的问题，并显著提高了通信效率、对抗鲁棒性和良性准确性。", "translation": "大型预训练模型在边缘计算中的日益普及，使得在移动客户端部署模型推理变得实用且流行。这些设备本质上容易受到直接对抗攻击，这对已部署模型的鲁棒性和安全性构成了重大威胁。联邦对抗训练（FAT）已成为一种有效的解决方案，可以在保护客户端隐私的同时增强模型鲁棒性。然而，FAT经常产生一个泛化的全局模型，该模型难以解决客户端之间多样化和异构的数据分布问题，导致个性化性能不足，同时在训练过程中也遇到实质性的通信挑战。在本文中，我们提出了\\textit{Sylva}，一个个性化协作对抗训练框架，旨在通过两阶段过程为每个客户端提供定制的防御模型。在第一阶段，\\textit{Sylva}采用LoRA进行局部对抗微调，使客户端能够在联邦聚合期间仅上传LoRA参数，从而大幅降低通信成本，实现模型鲁棒性的个性化。在第二阶段，引入基于博弈的层选择策略，以提高良性数据上的准确性，进一步完善个性化模型。这种方法确保每个客户端都能获得一个平衡鲁棒性和准确性的定制防御模型。在基准数据集上的大量实验表明，\\textit{Sylva}在通信效率方面可提高50倍，同时在对抗鲁棒性和良性准确性方面分别提高29.5\\%和50.4\\%。", "summary": "本文提出了Sylva，一个个性化协作对抗训练框架，旨在为边缘设备上的预训练模型提供定制的对抗防御。针对现有联邦对抗训练在数据异构性和通信效率上的不足，Sylva采用两阶段方法：首先利用LoRA进行局部对抗微调以降低通信成本并实现个性化鲁棒性，然后通过博弈层选择策略优化良性数据准确性。实验证明，Sylva在通信效率、对抗鲁棒性和良性准确性方面均实现了显著提升。", "keywords": "个性化对抗防御, 预训练模型, 协作微调, 联邦对抗训练, LoRA", "comments": "Sylva的创新之处在于结合LoRA和博弈论层选择策略，解决了联邦对抗训练中个性化不足和通信效率低下的问题。它为边缘设备上的模型部署提供了更安全、更高效的解决方案，对实际应用具有重要意义。"}}
{"id": "2506.05577", "title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts", "authors": ["Saptarshi Nath", "Christos Peridis", "Eseoghene Benjamin", "Xinran Liu", "Soheil Kolouri", "Peter Kinnell", "Zexin Li", "Cong Liu", "Shirin Dora", "Andrea Soltoggio"], "summary": "Agentic AI has gained significant interest as a research paradigm focused on\nautonomy, self-directed learning, and long-term reliability of decision making.\nReal-world agentic systems operate in decentralized settings on a large set of\ntasks or data distributions with constraints such as limited bandwidth,\nasynchronous execution, and the absence of a centralized model or even common\nobjectives. We posit that exploiting previously learned skills, task\nsimilarities, and communication capabilities in a collective of agentic AI are\nchallenging but essential elements to enabling scalability, open-endedness, and\nbeneficial collaborative learning dynamics. In this paper, we introduce Modular\nSharing and Composition in Collective Learning (MOSAIC), an agentic algorithm\nthat allows multiple agents to independently solve different tasks while also\nidentifying, sharing, and reusing useful machine-learned knowledge, without\ncoordination, synchronization, or centralized control. MOSAIC combines three\nmechanisms: (1) modular policy composition via neural network masks, (2) cosine\nsimilarity estimation using Wasserstein embeddings for knowledge selection, and\n(3) asynchronous communication and policy integration. Results on a set of RL\nbenchmarks show that MOSAIC has a greater sample efficiency than isolated\nlearners, i.e., it learns significantly faster, and in some cases, finds\nsolutions to tasks that cannot be solved by isolated learners. The\ncollaborative learning and sharing dynamics are also observed to result in the\nemergence of ideal curricula of tasks, from easy to hard. These findings\nsupport the case for collaborative learning in agentic systems to achieve\nbetter and continuously evolving performance both at the individual and\ncollective levels.", "comment": "36 pages, 21 figures, 6 tables. Preprint", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05577v1", "AI": {"title_translation": "智能体系统中的协作学习：集体AI大于其各部分之和", "tldr": "MOSAIC算法使多智能体在去中心化环境中通过模块化共享和组合进行协作学习，提高了样本效率并解决了独立智能体无法解决的任务。", "motivation": "现有的智能体系统在去中心化环境中操作时面临带宽有限、异步执行、缺乏中心化模型或共同目标等挑战。利用已学习技能、任务相似性和通信能力对于实现可扩展性、开放性和有益的协作学习动态至关重要。", "method": "本文介绍了“集体学习中的模块化共享与组合（MOSAIC）”算法，该算法允许多智能体独立解决不同任务，同时识别、共享和重用机器学习知识，无需协调、同步或集中控制。MOSAIC结合了三种机制：（1）通过神经网络掩码进行模块化策略组合；（2）使用Wasserstein嵌入进行余弦相似度估计以选择知识；（3）异步通信和策略集成。", "result": "在一系列RL基准测试中，MOSAIC显示出比独立学习器更高的样本效率（学习速度显著加快），在某些情况下，它能找到独立学习器无法解决的任务的解决方案。协作学习和共享动态还促使任务的理想课程（从易到难）的出现。", "conclusion": "这些发现支持了在智能体系统中进行协作学习的必要性，以在个体和集体层面实现更好和持续演进的性能。", "translation": "智能体AI作为一种研究范式，专注于自主性、自导学习和决策的长期可靠性，引起了广泛关注。现实世界的智能体系统在去中心化环境中运行，处理大量任务或数据分布，并受限于有限带宽、异步执行以及缺乏中心化模型甚至共同目标等约束。我们认为，在智能体AI集合中利用先前学习的技能、任务相似性和通信能力具有挑战性，但却是实现可扩展性、开放性和有益协作学习动态的关键要素。在本文中，我们引入了“集体学习中的模块化共享与组合（MOSAIC）”，这是一种智能体算法，允许多个智能体独立解决不同的任务，同时识别、共享和重用有用的机器学习知识，而无需协调、同步或集中控制。MOSAIC结合了三种机制：（1）通过神经网络掩码进行模块化策略组合；（2）使用Wasserstein嵌入进行余弦相似度估计以选择知识；（3）异步通信和策略集成。在一系列RL基准测试中的结果表明，MOSAIC比独立学习器具有更高的样本效率，即学习速度显著加快，在某些情况下，它能找到独立学习器无法解决的任务的解决方案。还观察到协作学习和共享动态导致了从易到难的任务理想课程的出现。这些发现支持了在智能体系统中进行协作学习的案例，以在个体和集体层面实现更好和持续演进的性能。", "summary": "本研究提出了一种名为MOSAIC的智能体算法，旨在解决去中心化环境中智能体系统协作学习的挑战。MOSAIC通过模块化策略组合、基于Wasserstein嵌入的知识选择以及异步通信，使多个智能体能够独立学习并共享知识，无需中心化控制。实验结果表明，MOSAIC显著提高了学习效率，并能解决独立智能体无法完成的任务，证明了协作学习在智能体系统中的优越性。", "keywords": "智能体系统, 协作学习, 样本效率, 去中心化, MOSAIC", "comments": "MOSAIC算法的创新点在于其无需协调、同步或中心化控制的去中心化知识共享机制，这对于现实世界大规模智能体系统的部署具有重要意义。通过结合模块化策略、知识选择和异步通信，它有效地解决了传统多智能体协作中的通信和协调难题，提高了学习效率和任务解决能力。"}}
{"id": "2506.05808", "title": "Where Do We Look When We Teach? Analyzing Human Gaze Behavior Across Demonstration Devices in Robot Imitation Learning", "authors": ["Yutaro Ishida", "Takamitsu Matsubara", "Takayuki Kanai", "Kazuhiro Shintani", "Hiroshi Bito"], "summary": "Imitation learning for acquiring generalizable policies often requires a\nlarge volume of demonstration data, making the process significantly costly.\nOne promising strategy to address this challenge is to leverage the cognitive\nand decision-making skills of human demonstrators with strong generalization\ncapability, particularly by extracting task-relevant cues from their gaze\nbehavior. However, imitation learning typically involves humans collecting data\nusing demonstration devices that emulate a robot's embodiment and visual\ncondition. This raises the question of how such devices influence gaze\nbehavior. We propose an experimental framework that systematically analyzes\ndemonstrators' gaze behavior across a spectrum of demonstration devices. Our\nexperimental results indicate that devices emulating (1) a robot's embodiment\nor (2) visual condition impair demonstrators' capability to extract\ntask-relevant cues via gaze behavior, with the extent of impairment depending\non the degree of emulation. Additionally, gaze data collected using devices\nthat capture natural human behavior improves the policy's task success rate\nfrom 18.8% to 68.8% under environmental shifts.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05808v1", "AI": {"title_translation": "当我们教学时看向何处？分析机器模仿学习中演示设备上的人类注视行为", "tldr": "本研究分析了在机器人模仿学习中，不同演示设备如何影响人类的注视行为，发现模仿机器人形态或视觉条件的设备会损害人类提取任务相关线索的能力，而自然行为捕获设备能显著提高策略成功率。", "motivation": "模仿学习需要大量演示数据且成本高昂，利用人类演示者的认知和决策能力，特别是从其注视行为中提取任务相关线索是一种有前景的策略。然而，模仿学习中使用的演示设备可能影响注视行为，因此需要研究这种影响。", "method": "本文提出了一个实验框架，系统地分析了演示者在使用不同演示设备时的注视行为。", "result": "实验结果表明，模仿机器人形态或视觉条件的设备会损害演示者通过注视行为提取任务相关线索的能力，损害程度取决于模仿的程度。此外，使用捕捉自然人类行为的设备收集的注视数据，在环境变化下将策略的任务成功率从18.8%提高到68.8%。", "conclusion": "模仿机器人形态或视觉条件的演示设备会影响人类的注视行为，降低其从任务相关线索中提取信息的能力。相反，使用能够捕捉自然人类行为的设备进行数据收集，可以显著提高模仿学习策略在环境变化下的表现。", "translation": "为获得可泛化策略的模仿学习通常需要大量的演示数据，这使得过程成本显著。解决这一挑战的一个有前景的策略是利用人类演示者具有强大泛化能力的认知和决策技能，特别是从他们的注视行为中提取任务相关线索。然而，模仿学习通常涉及人类使用模拟机器人实体和视觉条件的演示设备来收集数据。这就提出了这些设备如何影响注视行为的问题。我们提出了一个实验框架，系统地分析了演示者在使用一系列演示设备时的注视行为。我们的实验结果表明，模拟（1）机器人实体或（2）视觉条件的设备会损害演示者通过注视行为提取任务相关线索的能力，损害程度取决于模仿的程度。此外，使用捕捉自然人类行为的设备收集的注视数据，在环境变化下将策略的任务成功率从18.8%提高到68.8%。", "summary": "本研究探讨了在机器人模仿学习中，不同演示设备如何影响人类演示者的注视行为。研究发现，模拟机器人形态或视觉条件的设备会损害人类通过注视行为提取任务相关线索的能力，且损害程度与模仿程度相关。然而，使用能捕捉自然人类行为的设备收集的注视数据，可以显著提升模仿学习策略在环境变化下的任务成功率。", "keywords": "模仿学习, 注视行为, 演示设备, 机器人学习, 泛化能力", "comments": "这项研究揭示了在模仿学习数据采集中，演示设备选择对人类注视行为及其对机器人学习效果的关键影响。其创新点在于系统性地分析了设备仿真程度与注视行为和学习表现之间的关系。研究结果对于设计更有效的数据收集范式和提升模仿学习的泛化能力具有重要指导意义。"}}
{"id": "2506.05368", "title": "Speaking images. A novel framework for the automated self-description of artworks", "authors": ["Valentine Bernasconi", "Gustavo Marfia"], "summary": "Recent breakthroughs in generative AI have opened the door to new research\nperspectives in the domain of art and cultural heritage, where a large number\nof artifacts have been digitized. There is a need for innovation to ease the\naccess and highlight the content of digital collections. Such innovations\ndevelop into creative explorations of the digital image in relation to its\nmalleability and contemporary interpretation, in confrontation to the original\nhistorical object. Based on the concept of the autonomous image, we propose a\nnew framework towards the production of self-explaining cultural artifacts\nusing open-source large-language, face detection, text-to-speech and\naudio-to-animation models. The goal is to start from a digitized artwork and to\nautomatically assemble a short video of the latter where the main character\nanimates to explain its content. The whole process questions cultural biases\nencapsulated in large-language models, the potential of digital images and\ndeepfakes of artworks for educational purposes, along with concerns of the\nfield of art history regarding such creative diversions.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05368v1", "AI": {"title_translation": "会说话的图像。一种艺术品自动自描述的新颖框架", "tldr": "该论文提出一个利用生成式AI（大型语言模型、人脸检测、文本转语音、音频转动画模型）的框架，为数字化艺术品创建自动自解释视频，其中艺术品中的角色会动起来解释其内容，同时也探讨了文化偏见和伦理问题。", "motivation": "近期生成式AI的突破为艺术和文化遗产领域开辟了新的研究视角，大量文物已被数字化。目前需要创新来方便访问并突出数字藏品的内容。", "method": "基于自主图像的概念，该论文提出了一个新框架，旨在利用开源大型语言模型、人脸检测、文本转语音和音频转动画模型来制作自解释的文化艺术品。目标是从数字化艺术品开始，自动组装一个短视频，其中主要角色会动起来解释其内容。", "result": "Not mentioned in abstract", "conclusion": "该论文提出的整个过程探讨了大型语言模型中包含的文化偏见、数字图像和艺术品深度伪造在教育方面的潜力，以及艺术史领域对这种创造性偏离的担忧。", "translation": "生成式AI的最新突破为艺术和文化遗产领域开辟了新的研究视角，该领域有大量文物已被数字化。目前需要创新来方便访问并突出数字藏品的内容。此类创新发展为数字图像与其可塑性和当代诠释相关的创造性探索，与原始历史对象形成对比。基于自主图像的概念，我们提出了一个新框架，旨在利用开源大型语言模型、人脸检测、文本转语音和音频转动画模型来制作自解释的文化艺术品。目标是从数字化艺术品开始，自动组装一个短视频，其中主要角色会动起来解释其内容。整个过程探讨了大型语言模型中包含的文化偏见、数字图像和艺术品深度伪造在教育方面的潜力，以及艺术史领域对这种创造性偏离的担忧。", "summary": "本文介绍了“会说话的图像”，这是一个利用生成式AI（大型语言模型、人脸检测、文本转语音、音频转动画）的新颖框架，旨在为数字化艺术品创建自解释视频。其目标是让艺术品中的主要角色动起来解释其内容，从而增强对数字文化遗产的访问。该框架还引发了对AI中文化偏见、深度伪造在教育方面的潜力以及艺术史领域伦理问题的讨论。", "keywords": "生成式AI, 文化遗产, 自描述, 数字艺术, 深度伪造", "comments": "该论文的创新之处在于将生成式AI应用于创建交互式、自解释的文化艺术品，从而解决了可访问性问题。其重要性在于连接了技术与文化遗产领域，但局限性可能包括AI生成内容的准确性以及深度伪造和文化偏见带来的潜在伦理问题。"}}
{"id": "2506.05822", "title": "Towards Mixed-Criticality Software Architectures for Centralized HPC Platforms in Software-Defined Vehicles: A Systematic Literature Review", "authors": ["Lucas Mauser", "Eva Zimmermann", "Pavel Nedvědický", "Tobias Eisenreich", "Moritz Wäschle", "Stefan Wagner"], "summary": "Centralized electrical/electronic architectures and High-Performance\nComputers (HPCs) are redefining automotive software development, challenging\ntraditional microcontroller-based approaches. Ensuring real-time, safety, and\nscalability in software-defined vehicles necessitates reevaluating how\nmixed-criticality software is integrated into centralized architectures. While\nexisting research on automotive SoftWare Architectures (SWAs) is relevant to\nthe industry, it often lacks validation through systematic, empirical methods.\nTo address this gap, we conduct a systematic literature review focusing on\nautomotive mixed-criticality SWAs. Our goal is to provide practitioner-oriented\nguidelines that assist automotive software architects and developers design\ncentralized, mixed-criticality SWAs based on a rigorous and transparent\nmethodology. First, we set up a systematic review protocol grounded in\nestablished guidelines. Second, we apply this protocol to identify relevant\nstudies. Third, we extract key functional domains, constraints, and enabling\ntechnologies that drive changes in automotive SWAs, thereby assessing the\nprotocol's effectiveness. Additionally, we extract techniques, architectural\npatterns, and design practices for integrating mixed-criticality requirements\ninto HPC-based SWAs, further demonstrating the protocol's applicability. Based\non these insights, we propose an exemplary SWA for a microprocessor-based\nsystem-on-chip. In conclusion, this study provides a structured approach to\nexplore and realize mixed-criticality software integration for next-generation\nautomotive SWAs, offering valuable insights for industry and research\napplications.", "comment": "Preprint for research paper track of ECSA 2025", "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05822v1", "AI": {"title_translation": "迈向软件定义汽车中集中式HPC平台的多关键性软件架构：一项系统文献综述", "tldr": "本文对软件定义汽车中集中式高性能计算平台的多关键性软件架构进行了系统文献综述，旨在为汽车软件架构师和开发者提供设计指南，并提出了一个示例性软件架构。", "motivation": "集中式电气/电子架构和高性能计算机正在重塑汽车软件开发，但现有关于汽车软件架构的研究缺乏通过系统、实证方法的验证。本研究旨在弥补这一空白，为将多关键性软件集成到集中式架构中提供实践导向的指导。", "method": "本文进行了一项系统文献综述。首先，建立了基于既定指南的系统综述协议；其次，应用该协议识别相关研究；第三，提取驱动汽车软件架构变化的关键功能领域、约束和使能技术，并提取将多关键性需求集成到基于HPC的软件架构中的技术、架构模式和设计实践。", "result": "识别了驱动汽车软件架构变化的关键功能领域、约束和使能技术；提取了将多关键性需求集成到基于HPC的软件架构中的技术、架构模式和设计实践；提出了一个基于微处理器片上系统的示例性软件架构。", "conclusion": "本研究提供了一种探索和实现下一代汽车软件架构中多关键性软件集成的结构化方法，为行业和研究应用提供了有价值的见解。", "translation": "集中式电气/电子架构和高性能计算机（HPC）正在重新定义汽车软件开发，挑战了传统的基于微控制器的开发方法。在软件定义汽车中确保实时性、安全性和可扩展性，需要重新评估如何将多关键性软件集成到集中式架构中。尽管现有关于汽车软件架构（SWA）的研究与行业相关，但它们通常缺乏通过系统、实证方法的验证。为了弥补这一空白，我们进行了一项专注于汽车多关键性软件架构的系统文献综述。我们的目标是提供面向实践者的指南，以协助汽车软件架构师和开发者基于严谨透明的方法设计集中式、多关键性软件架构。首先，我们建立了基于既定指南的系统综述协议。其次，我们应用此协议识别相关研究。第三，我们提取了驱动汽车软件架构变化的关键功能领域、约束和使能技术，从而评估了协议的有效性。此外，我们还提取了将多关键性需求集成到基于HPC的软件架构中的技术、架构模式和设计实践，进一步证明了协议的适用性。基于这些见解，我们提出了一个基于微处理器片上系统的示例性软件架构。总之，本研究提供了一种探索和实现下一代汽车软件架构中多关键性软件集成的结构化方法，为行业和研究应用提供了有价值的见解。", "summary": "本文对软件定义汽车中集中式高性能计算平台的多关键性软件架构进行了系统文献综述。研究旨在弥补现有研究缺乏系统验证的空白，为汽车软件架构师提供设计指南。通过建立综述协议、识别相关研究、提取关键功能领域、约束、使能技术、集成技术、架构模式和设计实践，并提出了一个示例性软件架构。最终，本研究为探索和实现下一代汽车软件架构中的多关键性软件集成提供了一种结构化方法。", "keywords": "软件定义汽车, 多关键性软件架构, 集中式HPC平台, 系统文献综述, 汽车软件架构", "comments": "本文通过系统文献综述的方法，填补了当前汽车软件架构研究中缺乏系统验证的空白，为软件定义汽车背景下的集中式HPC平台多关键性软件架构设计提供了实践导向的指导。其创新性在于提出了一个严谨透明的综述协议，并基于此提取了关键信息，最终提出了一个示例性软件架构，对于推动汽车软件架构的现代化和标准化具有重要意义。"}}
{"id": "2506.06157", "title": "Masked Language Models are Good Heterogeneous Graph Generalizers", "authors": ["Jinyu Yang", "Cheng Yang", "Shanyuan Cui", "Zeyuan Guo", "Liangwei Yang", "Muhan Zhang", "Chuan Shi"], "summary": "Heterogeneous graph neural networks (HGNNs) excel at capturing structural and\nsemantic information in heterogeneous graphs (HGs), while struggling to\ngeneralize across domains and tasks. Recently, some researchers have turned to\nintegrating HGNNs with large language models (LLMs) for more generalizable\nheterogeneous graph learning. However, these approaches typically extract\nstructural information via HGNNs as HG tokens, and disparities in embedding\nspaces between HGNNs and LLMs have been shown to bias the LLM's comprehension\nof HGs. Moreover, as these HG tokens are often derived from node-level tasks,\nthe model's ability to generalize across tasks remains limited. To this end, we\npropose a simple yet effective Masked Language Modeling-based method, called\nMLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokens\nto extract structural and semantic information inherent in HGs, and designs\ncustomized textual templates to unify different graph tasks into a coherent\ncloze-style \"mask\" token prediction paradigm. Specifically, MLM4HG first\nconverts HGs from various domains to texts based on metapaths, and subsequently\ncombines them with the unified task texts to form a HG-based corpus. Moreover,\nthe corpus is fed into a pretrained LM for fine-tuning with a constrained\ntarget vocabulary, enabling the fine-tuned LM to generalize to unseen target\nHGs. Extensive cross-domain and multi-task experiments on four real-world\ndatasets demonstrate the superior generalization performance of MLM4HG over\nstate-of-the-art methods in both few-shot and zero-shot scenarios. Our code is\navailable at https://github.com/BUPT-GAMMA/MLM4HG.", "comment": null, "cate": "cs.SI", "url": "http://arxiv.org/pdf/2506.06157v1", "AI": {"title_translation": "掩码语言模型是优秀的异构图泛化器", "tldr": "提出MLM4HG，通过将异构图转换为基于元路径的文本序列，并统一任务为完形填空式预测，解决了异构图神经网络在跨域和多任务泛化方面的局限性，实现了更好的泛化性能。", "motivation": "现有的异构图神经网络（HGNNs）在异构图（HGs）中捕捉结构和语义信息方面表现出色，但在跨领域和任务泛化方面存在困难。将HGNNs与大型语言模型（LLMs）结合的方法，存在HGNNs和LLMs之间嵌入空间不匹配导致的LLM理解偏差，以及因HG tokens通常来源于节点级任务而导致的跨任务泛化能力有限的问题。", "method": "本文提出了一种基于掩码语言模型（MLM）的方法，名为MLM4HG。MLM4HG引入了基于元路径的文本序列来提取异构图的结构和语义信息，而不是使用HG tokens。它设计了定制的文本模板，将不同的图任务统一到一种连贯的完形填空式“掩码”令牌预测范式中。具体来说，MLM4HG首先将来自不同领域的异构图转换为基于元路径的文本，然后将它们与统一的任务文本结合形成一个基于HG的语料库。此外，该语料库被输入到预训练的语言模型中进行微调，并使用受限的目标词汇表，从而使微调后的语言模型能够泛化到未见的异构图。", "result": "在四个真实世界数据集上进行的广泛的跨域和多任务实验表明，MLM4HG在少样本和零样本场景中都优于最先进的方法，展现出卓越的泛化性能。", "conclusion": "掩码语言模型能够通过将异构图转换为文本序列并统一任务范式，有效解决异构图神经网络在跨域和多任务泛化上的挑战，实现更好的泛化能力。", "translation": "异构图神经网络（HGNNs）在捕捉异构图（HGs）中的结构和语义信息方面表现出色，但在跨领域和任务泛化方面却面临困难。最近，一些研究人员转向将HGNNs与大型语言模型（LLMs）相结合，以实现更具泛化性的异构图学习。然而，这些方法通常通过HGNNs提取结构信息作为HG tokens，并且HGNNs和LLMs之间嵌入空间的不一致性已被证明会影响LLM对HGs的理解。此外，由于这些HG tokens通常源自节点级任务，模型的跨任务泛化能力仍然有限。为此，我们提出了一种简单而有效的基于掩码语言模型的方法，称为MLM4HG。MLM4HG引入了基于元路径的文本序列，而非HG tokens，以提取异构图中固有的结构和语义信息，并设计了定制的文本模板，将不同的图任务统一为一种连贯的完形填空式“掩码”令牌预测范式。具体来说，MLM4HG首先将来自不同领域的HGs基于元路径转换为文本，随后将它们与统一的任务文本结合形成一个基于HG的语料库。此外，该语料库被送入预训练的LM进行微调，并采用受限的目标词汇表，从而使微调后的LM能够泛化到未见的目标HGs。在四个真实世界数据集上进行的广泛的跨域和多任务实验表明，MLM4HG在少样本和零样本场景中都优于最先进的方法，展现出卓越的泛化性能。我们的代码可在https://github.com/BUPT-GAMMA/MLM4HG获取。", "summary": "本研究提出MLM4HG，一种基于掩码语言模型的方法，旨在解决异构图神经网络在跨域和多任务泛化上的局限性。MLM4HG通过将异构图转化为基于元路径的文本序列，并利用定制模板将不同图任务统一为完形填空式预测，从而使预训练语言模型能更好地理解和泛化异构图信息。实验证明，MLM4HG在多种真实数据集上的跨域和多任务泛化性能均优于现有方法。", "keywords": "掩码语言模型, 异构图, 泛化, 文本序列, 跨域学习", "comments": "该论文的创新点在于提出了一种新颖的异构图泛化范式，通过将图结构和任务信息统一编码为文本，并利用掩码语言模型进行学习，避免了传统HGNNs与LLMs集成时嵌入空间不匹配的问题。这种方法提供了一种更通用和灵活的异构图学习框架，尤其在少样本和零样本场景下表现出显著优势，为异构图的泛化能力提升开辟了新途径。"}}
{"id": "2506.05579", "title": "When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration", "authors": ["Quan Shi", "Carlos E. Jimenez", "Shunyu Yao", "Nick Haber", "Diyi Yang", "Karthik Narasimhan"], "summary": "Recent advancements in AI reasoning have driven substantial improvements\nacross diverse tasks. A critical open question is whether these improvements\nalso yields better knowledge transfer: the ability of models to communicate\nreasoning in ways humans can understand, apply, and learn from. To investigate\nthis, we introduce Knowledge Integration and Transfer Evaluation (KITE), a\nconceptual and experimental framework for Human-AI knowledge transfer\ncapabilities and conduct the first large-scale human study (N=118) explicitly\ndesigned to measure it. In our two-phase setup, humans first ideate with an AI\non problem-solving strategies, then independently implement solutions,\nisolating model explanations' influence on human understanding. Our findings\nreveal that although model benchmark performance correlates with collaborative\noutcomes, this relationship is notably inconsistent, featuring significant\noutliers, indicating that knowledge transfer requires dedicated optimization.\nOur analysis identifies behavioral and strategic factors mediating successful\nknowledge transfer. We release our code, dataset, and evaluation framework to\nsupport future work on communicatively aligned models.", "comment": "For code, data, visualizer, visit: https:kite-live.vercel.app", "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05579v1", "AI": {"title_translation": "当模型知晓多于其能解释：量化人机协作中的知识迁移", "tldr": "模型表现良好，但其向人类传递知识的能力不稳定，需要专门优化。", "motivation": "探讨AI推理的进步是否也能带来更好的知识迁移，即模型能否以人类可理解、应用和学习的方式传达推理。", "method": "引入了知识整合与迁移评估（KITE）框架，并进行了一项大规模（N=118）的人类研究。研究采用两阶段设置：人类首先与AI共同构思问题解决策略，然后独立实施解决方案，以隔离模型解释对人类理解的影响。", "result": "模型基准性能与协作结果相关，但这种关系显著不一致，存在异常值，表明知识迁移需要专门优化。分析还确定了促进成功知识迁移的行为和策略因素。", "conclusion": "人机协作中的知识迁移不会随着模型性能的提高而自动改善，需要专门的优化和对中介因素的理解。", "translation": "AI推理的最新进展已在各种任务中带来了显著改进。一个关键的未解决问题是，这些改进是否也能带来更好的知识迁移：即模型以人类能够理解、应用和学习的方式传达推理的能力。为了调查这一点，我们引入了知识整合与迁移评估（KITE），这是一个用于衡量人机知识迁移能力的概念和实验框架，并进行了首次大规模（N=118）专门设计用于测量此能力的人类研究。在我们的两阶段设置中，人类首先与AI共同构思解决问题的策略，然后独立实施解决方案，从而隔离模型解释对人类理解的影响。我们的研究结果表明，尽管模型基准性能与协作结果相关，但这种关系显著不一致，存在显著异常值，表明知识迁移需要专门优化。我们的分析确定了促成成功知识迁移的行为和策略因素。我们发布了代码、数据集和评估框架，以支持未来在通信对齐模型方面的工作。", "summary": "这篇论文探讨了人机协作中的知识迁移，将其定义为AI以人类可理解的方式传达推理的能力。为此，论文引入了KITE框架和一项大规模（N=118）两阶段人类研究来衡量知识迁移。研究结果表明，尽管模型性能与协作成果相关，但知识迁移并不稳定，需要专门优化，并确定了促成因素。作者还发布了相关资源以支持未来的研究。", "keywords": "知识迁移, 人机协作, 可解释AI, KITE, 模型可解释性", "comments": "这篇论文探讨了人机交互中一个超越单纯性能的关键方面：AI知识对人类学习和协作的解释性和实用性。KITE框架的引入和大规模人类研究是重要的贡献，为这一常被讨论但研究不足的领域提供了具体的框架和实证证据。研究发现高模型性能并不能保证良好的知识迁移，这对未来AI发展方向（即“通信对齐模型”）具有重要指导意义。"}}
{"id": "2506.06024", "title": "On Inverse Problems, Parameter Estimation, and Domain Generalization", "authors": ["Deborah Pereg"], "summary": "Signal restoration and inverse problems are key elements in most real-world\ndata science applications. In the past decades, with the emergence of machine\nlearning methods, inversion of measurements has become a popular step in almost\nall physical applications, which is normally executed prior to downstream tasks\nthat often involve parameter estimation. In this work, we analyze the general\nproblem of parameter estimation in an inverse problem setting. First, we\naddress the domain-shift problem by re-formulating it in direct relation with\nthe discrete parameter estimation analysis. We analyze a significant\nvulnerability in current attempts to enforce domain generalization, which we\ndubbed the Double Meaning Theorem. Our theoretical findings are experimentally\nillustrated for domain shift examples in image deblurring and speckle\nsuppression in medical imaging. We then proceed to a theoretical analysis of\nparameter estimation given observed measurements before and after data\nprocessing involving an inversion of the observations. We compare this setting\nfor invertible and non-invertible (degradation) processes. We distinguish\nbetween continuous and discrete parameter estimation, corresponding with\nregression and classification problems, respectively. Our theoretical findings\nalign with the well-known information-theoretic data processing inequality, and\nto a certain degree question the common misconception that data-processing for\ninversion, based on modern generative models that may often produce outstanding\nperceptual quality, will necessarily improve the following parameter estimation\nobjective. It is our hope that this paper will provide practitioners with\ndeeper insights that may be leveraged in the future for the development of more\nefficient and informed strategic system planning, critical in safety-sensitive\napplications.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.06024v1", "AI": {"title_translation": "关于逆问题、参数估计和域泛化", "tldr": "本文分析了逆问题设置下的参数估计，揭示了域泛化中的“双重含义定理”漏洞，并质疑了通过数据处理提高参数估计的普遍观念，强调了信息处理不等式的重要性。", "motivation": "逆问题和信号恢复是大多数现实世界数据科学应用中的关键要素，测量反演是物理应用中常见的预处理步骤，通常在参数估计等下游任务之前执行。本研究旨在分析逆问题设置中参数估计的普遍问题，特别是域泛化中的漏洞，并纠正关于数据处理一定会改善后续参数估计目标的普遍误解。", "method": "分析逆问题设置下的参数估计问题。通过将其与离散参数估计分析直接关联来重新阐述域漂移问题。分析了当前强制域泛化尝试中的一个显著漏洞，并将其命名为“双重含义定理”。通过图像去模糊和医学成像中的散斑抑制等域漂移示例，对理论发现进行了实验说明。对观察测量数据在经过反演处理前后进行参数估计的理论分析，并比较了可逆和不可逆（退化）过程的设置。区分了连续和离散参数估计（分别对应回归和分类问题）。", "result": "发现并命名了当前域泛化尝试中的一个显著漏洞，即“双重含义定理”。理论发现与已知的信息论数据处理不等式一致。对普遍存在的“基于现代生成模型的数据处理（即使产生出色的感知质量）必然会改善后续参数估计目标”的误解提出了质疑。通过图像去模糊和医学成像中的散斑抑制示例，实验性地证实了理论发现。", "conclusion": "本文的理论发现与信息论数据处理不等式一致，并质疑了通过反演数据处理（即使是高质量的生成模型）必然会改善后续参数估计目标的普遍观念。希望本研究能为从业者提供更深入的见解，有助于未来开发更高效、更明智的系统规划，这在安全敏感应用中至关重要。", "translation": "信号恢复和逆问题是大多数现实世界数据科学应用中的关键要素。在过去的几十年中，随着机器学习方法的兴起，测量反演已成为几乎所有物理应用中的热门步骤，通常在涉及参数估计的下游任务之前执行。在这项工作中，我们分析了逆问题设置中参数估计的普遍问题。首先，我们通过将其与离散参数估计分析直接关联来重新阐述域漂移问题。我们分析了当前强制域泛化尝试中的一个显著漏洞，我们称之为“双重含义定理”。我们的理论发现通过图像去模糊和医学成像中的散斑抑制等域漂移示例进行了实验说明。然后，我们对观察测量数据在经过涉及观察反演的数据处理前后进行参数估计的理论分析。我们比较了可逆和不可逆（退化）过程的这种设置。我们区分了连续和离散参数估计，分别对应于回归和分类问题。我们的理论发现与众所周知的信息论数据处理不等式一致，并在一定程度上质疑了普遍存在的误解，即基于现代生成模型的数据处理（这些模型通常能产生出色的感知质量）必然会改善后续的参数估计目标。我们希望这篇论文能为从业者提供更深入的见解，这些见解未来可用于开发更高效、更明智的战略系统规划，这在安全敏感应用中至关重要。", "summary": "本文深入分析了逆问题设置中的参数估计，并揭示了当前域泛化方法中存在的一个名为“双重含义定理”的显著漏洞。研究通过理论分析和图像去模糊、医学散斑抑制等实验例证，探讨了数据反演处理对后续参数估计任务的影响。研究结果与信息论数据处理不等式相符，并挑战了“高质量数据反演必然提升参数估计”的普遍观念。论文旨在为安全敏感应用中的系统规划提供更深入的指导。", "keywords": "逆问题, 参数估计, 域泛化, 双重含义定理, 数据处理不等式", "comments": "创新性: 提出了“双重含义定理”来揭示域泛化中的潜在漏洞，这是一个新颖的理论贡献。重要性: 质疑了机器学习领域中一个普遍存在的误解，即高质量的感知输出必然带来更好的下游任务性能，这对于指导实际应用（特别是安全敏感领域）中的系统设计具有重要意义。"}}
{"id": "2506.05434", "title": "Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks", "authors": ["Thomas Massena", "Léo andéol", "Thibaut Boissin", "Franck Mamalet", "Corentin Friedrich", "Mathieu Serrurier", "Sébastien Gerchinovitz"], "summary": "Conformal Prediction (CP) has proven to be an effective post-hoc method for\nimproving the trustworthiness of neural networks by providing prediction sets\nwith finite-sample guarantees. However, under adversarial attacks, classical\nconformal guarantees do not hold anymore: this problem is addressed in the\nfield of Robust Conformal Prediction. Several methods have been proposed to\nprovide robust CP sets with guarantees under adversarial perturbations, but,\nfor large scale problems, these sets are either too large or the methods are\ntoo computationally demanding to be deployed in real life scenarios. In this\nwork, we propose a new method that leverages Lipschitz-bounded networks to\nprecisely and efficiently estimate robust CP sets. When combined with a\n1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms\nstate-of-the-art results in both the size of the robust CP sets and\ncomputational efficiency in medium and large-scale scenarios such as ImageNet.\nTaking a different angle, we also study vanilla CP under attack, and derive new\nworst-case coverage bounds of vanilla CP sets, which are valid simultaneously\nfor all adversarial attack levels. Our lip-rcp method makes this second\napproach as efficient as vanilla CP while also allowing robustness guarantees.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05434v1", "AI": {"title_translation": "通过Lipschitz有界网络实现高效鲁棒共形预测", "tldr": "本文提出了一种名为lip-rcp的新方法，该方法利用Lipschitz有界网络高效准确地估计鲁棒共形预测集，解决了现有方法在对抗攻击下鲁棒性差或计算成本高的问题，并在大型数据集上展现出优于现有技术的性能。", "motivation": "在对抗性攻击下，传统的共形预测（CP）保证不再成立。现有的鲁棒共形预测方法在大规模问题中，要么预测集过大，要么计算成本过高，难以在实际场景中部署。", "method": "本文提出了一种利用Lipschitz有界网络来精确高效地估计鲁棒共形预测集的新方法，命名为lip-rcp。该方法与1-Lipschitz鲁棒网络结合使用。此外，本文还从另一个角度研究了受攻击的普通CP，并推导出了新的、对所有对抗性攻击级别同时有效的普通CP集最坏情况覆盖界限。", "result": "当与1-Lipschitz鲁棒网络结合时，lip-rcp方法在ImageNet等中大型场景中，在鲁棒CP集的大小和计算效率方面均优于现有技术水平。lip-rcp方法还使得第二种方法（研究普通CP在攻击下的覆盖界限）与普通CP一样高效，同时提供了鲁棒性保证。", "conclusion": "lip-rcp方法通过利用Lipschitz有界网络，能够高效且精确地提供鲁棒共形预测集，克服了现有方法的局限性，并在对抗性攻击下提供了可靠的性能保证，使其适用于实际大规模应用。", "translation": "共形预测（CP）已被证明是一种有效的后处理方法，通过提供具有有限样本保证的预测集来提高神经网络的可靠性。然而，在对抗性攻击下，经典的共形保证不再成立：这个问题在鲁棒共形预测领域得到了解决。已经提出了几种方法来提供在对抗性扰动下具有保证的鲁棒CP集，但是，对于大规模问题，这些集合要么太大，要么计算成本过高，难以在实际场景中部署。在这项工作中，我们提出了一种新方法，该方法利用Lipschitz有界网络来精确高效地估计鲁棒CP集。当与1-Lipschitz鲁棒网络结合时，我们证明了我们的lip-rcp方法在鲁棒CP集的大小和计算效率方面都优于ImageNet等中大型场景中的现有技术水平。从另一个角度来看，我们还研究了受攻击的普通CP，并推导出了新的普通CP集最坏情况覆盖界限，这些界限对所有对抗性攻击级别同时有效。我们的lip-rcp方法使第二种方法与普通CP一样高效，同时还允许鲁棒性保证。", "summary": "本论文提出了一种名为lip-rcp的新型鲁棒共形预测方法，该方法利用Lipschitz有界网络来高效且精确地估计预测集。针对现有鲁巴共形预测方法在大规模应用中存在的预测集过大或计算成本过高的问题，lip-rcp方法结合1-Lipschitz鲁棒网络，在ImageNet等中大型场景中，在预测集大小和计算效率方面均超越了现有技术。此外，研究还分析了对抗攻击下普通CP的覆盖界限，并证明了lip-rcp方法在此类分析中也能保持与普通CP相当的效率，同时提供鲁棒性保证。", "keywords": "共形预测, 鲁棒性, Lipschitz网络, 对抗攻击, 计算效率", "comments": "该论文的创新点在于将Lipschitz有界网络引入鲁棒共形预测，有效解决了现有方法在大型数据集上效率低和预测集过大的问题。其重要性体现在为神经网络在对抗性攻击下提供更可靠、更实用的不确定性量化工具，对于提升AI系统的可信赖性具有重要意义。"}}
{"id": "2506.05871", "title": "BestServe: Serving Strategies with Optimal Goodput in Collocation and Disaggregation Architectures", "authors": ["Xiannan Hu", "Tianyou Zeng", "Xiaoming Yuan", "Liwei Song", "Guangyuan Zhang", "Bangzheng He"], "summary": "Serving large language models (LLMs) to millions of users requires efficient\nresource allocation and parallelism strategies. It is a labor intensive\ntrial-and-error process to find such a strategy. We present BestServe, a novel\nframework for ranking serving strategies by estimating goodput under various\noperating scenarios. Supporting both collocated and disaggregated\narchitectures, BestServe leverages an inference simulator built on an adapted\nroofline model and CPU-GPU dispatch dynamics. Our framework determines the\noptimal strategy in minutes on a single standard CPU, eliminating the need for\ncostly benchmarking, while achieving predictions within a $20\\%$ error margin.\nIt appeals to be practical for rapid deployment planning because of its\nlightweight design and strong extensibility.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05871v1", "AI": {"title_translation": "BestServe：在共置和解耦架构中提供具有最佳有效吞吐量的服务策略", "tldr": "BestServe是一个用于快速评估和选择LLM服务策略的框架，它通过模拟预测有效吞吐量，避免了昂贵的基准测试，并能在几分钟内找到最优策略。", "motivation": "为数百万用户提供大型语言模型（LLM）服务需要高效的资源分配和并行策略，而找到这种策略是一个耗时且需要反复试验的过程。", "method": "BestServe是一个新颖的框架，通过估计不同操作场景下的有效吞吐量来对服务策略进行排名。它支持共置和解耦架构，利用基于改进的屋脊线模型和CPU-GPU调度动态的推理模拟器。", "result": "该框架可以在几分钟内在单个标准CPU上确定最佳策略，消除了昂贵的基准测试需求，并实现了20%以内的预测误差。", "conclusion": "BestServe因其轻量级设计和强大的可扩展性，对于快速部署规划具有实用性。", "translation": "服务大型语言模型（LLMs）给数百万用户需要高效的资源分配和并行策略。找到这样的策略是一个劳动密集型的试错过程。我们提出了BestServe，一个新颖的框架，通过估计不同操作场景下的有效吞吐量来对服务策略进行排名。BestServe支持共置和解耦架构，利用基于改进的屋脊线模型和CPU-GPU调度动态的推理模拟器。我们的框架可以在几分钟内在单个标准CPU上确定最佳策略，消除了昂贵的基准测试需求，同时实现了20%以内的预测误差。由于其轻量级设计和强大的可扩展性，它对于快速部署规划具有实用性。", "summary": "BestServe是一个创新框架，旨在优化大型语言模型（LLM）的服务策略。它通过一个基于改进屋脊线模型和CPU-GPU调度动态的推理模拟器，快速评估共置和解耦架构下的服务策略，并预测其有效吞吐量。该框架能够在几分钟内确定最佳策略，预测误差在20%以内，从而替代了耗时的基准测试，并支持快速部署规划。", "keywords": "大型语言模型服务, 有效吞吐量, 资源分配, 推理模拟器, 部署规划", "comments": "BestServe的创新之处在于其通过模拟而非实际基准测试来快速评估LLM服务策略，显著降低了部署规划的成本和时间。其轻量级和可扩展性使其在实际应用中具有很高的价值，特别是在LLM快速发展的背景下。"}}
{"id": "2506.05797", "title": "EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator", "authors": ["Qianyi Chen", "Tianrun Gao", "Chenbo Jiang", "Tailin Wu"], "summary": "Simulating collisions of deformable objects is a fundamental yet challenging\ntask due to the complexity of modeling solid mechanics and multi-body\ninteractions. Existing data-driven methods often suffer from lack of\nequivariance to physical symmetries, inadequate handling of collisions, and\nlimited scalability. Here we introduce EqCollide, the first end-to-end\nequivariant neural fields simulator for deformable objects and their\ncollisions. We propose an equivariant encoder to map object geometry and\nvelocity into latent control points. A subsequent equivariant Graph Neural\nNetwork-based Neural Ordinary Differential Equation models the interactions\namong control points via collision-aware message passing. To reconstruct\nvelocity fields, we query a neural field conditioned on control point features,\nenabling continuous and resolution-independent motion predictions. Experimental\nresults show that EqCollide achieves accurate, stable, and scalable simulations\nacross diverse object configurations, and our model achieves 24.34% to 35.82%\nlower rollout MSE even compared with the best-performing baseline model.\nFurthermore, our model could generalize to more colliding objects and extended\ntemporal horizons, and stay robust to input transformed with group action.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05797v1", "AI": {"title_translation": "EqCollide：等变和碰撞感知可变形物体神经模拟器", "tldr": "EqCollide是第一个端到端等变神经场模拟器，用于可变形物体及其碰撞，解决了现有方法在等变性、碰撞处理和可扩展性方面的不足，并实现了准确、稳定和可扩展的模拟。", "motivation": "模拟可变形物体的碰撞是一项基础但具有挑战性的任务，因为固体力学和多体相互作用的建模复杂。现有数据驱动方法常缺乏物理对称性的等变性、碰撞处理不充分以及可扩展性有限。", "method": "EqCollide引入了第一个端到端等变神经场模拟器。它提出一个等变编码器将物体几何和速度映射到潜在控制点。随后，一个基于图神经网络的神经常微分方程通过碰撞感知消息传递建模控制点之间的相互作用。为了重建速度场，模型查询一个以控制点特征为条件的神经场，从而实现连续和分辨率无关的运动预测。", "result": "EqCollide在不同物体配置下实现了准确、稳定和可扩展的模拟。与表现最佳的基线模型相比，EqCollide的模型滚动MSE降低了24.34%至35.82%。此外，该模型能够泛化到更多碰撞物体和更长的时间范围，并且对通过群作用变换的输入保持鲁棒性。", "conclusion": "EqCollide通过其新颖的等变架构和碰撞感知机制，显著提升了可变形物体碰撞模拟的准确性、稳定性和可扩展性，并且展现出良好的泛化能力和对输入变换的鲁棒性。", "translation": "论文题目：EqCollide：等变和碰撞感知可变形物体神经模拟器\n\n摘要：\n由于固体力学和多体相互作用建模的复杂性，可变形物体的碰撞模拟是一项基础但具有挑战性的任务。现有数据驱动方法常缺乏物理对称性的等变性、碰撞处理不充分以及可扩展性有限。本文介绍了EqCollide，这是第一个端到端等变神经场模拟器，用于可变形物体及其碰撞。我们提出一个等变编码器，将物体几何和速度映射到潜在控制点。随后，一个基于图神经网络的神经常微分方程通过碰撞感知消息传递建模控制点之间的相互作用。为了重建速度场，我们查询一个以控制点特征为条件的神经场，从而实现连续和分辨率无关的运动预测。实验结果表明，EqCollide在不同物体配置下实现了准确、稳定和可扩展的模拟，并且我们的模型与表现最佳的基线模型相比，滚动MSE降低了24.34%至35.82%。此外，我们的模型可以泛化到更多碰撞物体和更长的时间范围，并且对通过群作用变换的输入保持鲁棒性。", "summary": "本论文介绍了EqCollide，这是一种新颖的端到端等变神经场模拟器，专为可变形物体及其碰撞而设计。它通过等变编码器将几何和速度映射到潜在控制点，并利用基于图神经网络的神经常微分方程进行碰撞感知交互建模。通过查询神经场重建速度，实现了连续且分辨率无关的运动预测。实验表明，EqCollide在准确性、稳定性、可扩展性方面优于现有方法，并在滚动MSE上实现了显著降低，同时展现出对更多碰撞物体和更长时间范围的泛化能力以及对输入变换的鲁棒性。", "keywords": "可变形物体模拟, 等变性, 碰撞感知, 神经场, 图神经网络", "comments": "EqCollide的创新之处在于它是第一个将等变性引入可变形物体碰撞模拟的端到端神经场模拟器。其结合等变编码器、GNN-based NODE和神经场的方法，有效解决了现有数据驱动方法在等变性、碰撞处理和可扩展性方面的痛点。显著的性能提升和泛化能力，使其在物理模拟领域具有重要意义。"}}
{"id": "2506.06011", "title": "London Blue Light Collaboration Evaluation: A Comparative Analysis of Spatio temporal Patterns on Emergency Services by London Ambulance Service and London Fire Brigade", "authors": ["Fangyuan Li", "Yijing Li", "Luke Edward Rogerson"], "summary": "With rising demand for emergency services, the London Ambulance Service, LAS,\nand the London Fire Brigade, LFB, face growing challenges in resource\ncoordination. This study investigates the temporal and spatial similarities in\ntheir service demands to assess potential for routine cross-agency\ncollaboration. Time series analysis revealed aligned demand peaks in summer, on\nFridays, during daytime hours, and were highly sensitive to high temperature\nweather conditions. Bivariate mapping and Moran I indicated significant spatial\noverlaps in central London and Hillingdon. Geographically Weighted Regression,\nGWR, examined the influence of socioeconomic factors, while Comap analysis\nuncovered spatiotemporal heterogeneity across fire service types. The findings\nhighlight opportunities for targeted collaboration in high-overlap areas and\npeak periods, offering practical insights to enhance emergency service\nresilience and efficiency.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.06011v1", "AI": {"title_translation": "伦敦蓝光合作评估：伦敦救护服务和伦敦消防队紧急服务时空模式的比较分析", "tldr": "本研究评估了伦敦救护服务和伦敦消防队服务需求的时空相似性，旨在促进跨机构合作，通过分析发现需求高峰和空间重叠，并据此提出有针对性的合作机会，以提升紧急服务效率。", "motivation": "随着紧急服务需求的增长，伦敦救护服务（LAS）和伦敦消防队（LFB）在资源协调方面面临挑战。本研究旨在调查他们服务需求的时空相似性，以评估常规跨机构合作的潜力。", "method": "本研究采用了时间序列分析来揭示需求高峰；使用双变量映射和Moran I来指示空间重叠；通过地理加权回归（GWR）检查社会经济因素的影响；并利用Comap分析揭示消防服务类型的时空异质性。", "result": "时间序列分析显示需求高峰在夏季、周五、白天时段一致，并且对高温天气条件高度敏感。双变量映射和Moran I表明伦敦市中心和希灵登存在显著的空间重叠。GWR分析了社会经济因素的影响，而Comap分析揭示了消防服务类型的时空异质性。", "conclusion": "研究结果强调了在高重叠区域和高峰期进行有针对性合作的机会，为增强紧急服务的韧性和效率提供了实用见解。", "translation": "随着紧急服务需求的不断增长，伦敦救护服务（LAS）和伦敦消防队（LFB）在资源协调方面面临日益严峻的挑战。本研究调查了其服务需求在时间和空间上的相似性，以评估常规跨机构合作的潜力。时间序列分析显示，需求高峰在夏季、周五、白天时段一致，并且对高温天气条件高度敏感。双变量映射和Moran I 指出伦敦市中心和希灵登存在显著的空间重叠。地理加权回归（GWR）检验了社会经济因素的影响，而Comap分析揭示了消防服务类型的时空异质性。研究结果强调了在高重叠区域和高峰期进行有针对性合作的机会，为增强紧急服务的韧性和效率提供了实用见解。", "summary": "本研究评估了伦敦救护服务（LAS）和伦敦消防队（LFB）紧急服务需求的时空模式，旨在探究跨机构合作的可能性。通过时间序列分析、双变量映射、Moran I、地理加权回归（GWR）和Comap分析，研究发现两机构的需求高峰在夏季、周五和白天时段高度一致，并对高温敏感；同时在伦敦市中心和希灵登存在显著的空间重叠。此外，还分析了社会经济因素的影响及消防服务类型的时空异质性。研究结果为在需求重叠区域和高峰期开展有针对性的合作提供了实践指导，有助于提升紧急服务的韧性和效率。", "keywords": "紧急服务, 时空模式, 跨机构合作, 伦敦救护服务, 伦敦消防队", "comments": "该研究通过对伦敦救护服务和消防队需求模式进行细致的时空分析，为跨机构合作提供了数据驱动的洞察。其创新之处在于结合多种地理空间和时间序列分析方法，揭示了紧急服务需求的内在关联性。这对于优化资源配置、提升城市紧急响应能力具有重要意义。研究结果可以直接指导决策者制定更有效的协同策略，从而提高紧急服务的效率和韧性。"}}
{"id": "2506.05403", "title": "Poisoning Behavioral-based Worker Selection in Mobile Crowdsensing using Generative Adversarial Networks", "authors": ["Ruba Nasser", "Ahmed Alagha", "Shakti Singh", "Rabeb Mizouni", "Hadi Otrok", "Jamal Bentahar"], "summary": "With the widespread adoption of Artificial intelligence (AI), AI-based tools\nand components are becoming omnipresent in today's solutions. However, these\ncomponents and tools are posing a significant threat when it comes to\nadversarial attacks. Mobile Crowdsensing (MCS) is a sensing paradigm that\nleverages the collective participation of workers and their smart devices to\ncollect data. One of the key challenges faced at the selection stage is\nensuring task completion due to workers' varying behavior. AI has been utilized\nto tackle this challenge by building unique models for each worker to predict\ntheir behavior. However, the integration of AI into the system introduces\nvulnerabilities that can be exploited by malicious insiders to reduce the\nrevenue obtained by victim workers. This work proposes an adversarial attack\ntargeting behavioral-based selection models in MCS. The proposed attack\nleverages Generative Adversarial Networks (GANs) to generate poisoning points\nthat can mislead the models during the training stage without being detected.\nThis way, the potential damage introduced by GANs on worker selection in MCS\ncan be anticipated. Simulation results using a real-life dataset show the\neffectiveness of the proposed attack in compromising the victim workers' model\nand evading detection by an outlier detector, compared to a benchmark. In\naddition, the impact of the attack on reducing the payment obtained by victim\nworkers is evaluated.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05403v1", "AI": {"title_translation": "使用生成对抗网络毒害移动众包中基于行为的工人选择", "tldr": "本文提出了一种基于GAN的对抗性攻击，旨在毒害移动众包中基于AI的工人选择模型，从而降低受害工人的收入并规避检测。", "motivation": "在移动众包中，AI被用于预测工人行为以确保任务完成。然而，AI的集成引入了漏洞，可能被恶意内部人员利用，通过对抗性攻击来降低受害工人的收入。本文旨在预见并评估这种潜在损害。", "method": "本文提出了一种针对移动众包中基于行为的选择模型的对抗性攻击。该攻击利用生成对抗网络（GANs）生成中毒点，这些中毒点可以在训练阶段误导模型而不会被检测到。", "result": "使用真实数据集的模拟结果表明，与基准相比，所提出的攻击在损害受害工人模型和规避异常值检测器检测方面是有效的。此外，还评估了攻击对降低受害工人所获报酬的影响。", "conclusion": "所提出的基于GAN的投毒攻击能够有效损害移动众包中基于行为的工人选择模型，突显了AI系统在对抗性环境中的脆弱性，并强调了预测此类威胁的重要性。", "translation": "随着人工智能（AI）的广泛采用，基于AI的工具和组件在当今的解决方案中无处不在。然而，当涉及到对抗性攻击时，这些组件和工具构成了重大威胁。移动众包（MCS）是一种利用工人和智能设备的集体参与来收集数据的感知范式。在选择阶段面临的关键挑战之一是由于工人行为各异而难以确保任务完成。AI已被用于通过为每个工人建立独特的模型来预测其行为，从而解决这一挑战。然而，AI集成到系统中引入了漏洞，恶意内部人员可以利用这些漏洞来降低受害工人获得的收入。这项工作提出了一种针对移动众包中基于行为的选择模型的对抗性攻击。所提出的攻击利用生成对抗网络（GANs）生成中毒点，这些中毒点可以在训练阶段误导模型而不会被检测到。通过这种方式，可以预测GANs对移动众包中工人选择造成的潜在损害。使用真实数据集的模拟结果表明，与基准相比，所提出的攻击在损害受害工人模型和规避异常值检测器检测方面是有效的。此外，还评估了攻击对降低受害工人所获报酬的影响。", "summary": "本文提出了一种新颖的对抗性攻击，利用生成对抗网络（GANs）来毒害移动众包（MCS）中基于AI的工人选择模型。这种攻击在训练阶段生成不可检测的投毒数据点，从而损害模型并减少受害工人的收入。使用真实世界数据的模拟证实了该攻击在模型损害和隐蔽性方面的有效性，强调了AI集成到MCS中的脆弱性。", "keywords": "移动众包, 对抗性攻击, 生成对抗网络, 工人选择, 投毒攻击", "comments": "该论文及时地解决了AI系统对抗性攻击的关键问题，特别是在众包的背景下。利用GANs生成隐蔽的投毒攻击具有创新性。它突出了AI集成所带来的安全风险，并为开发更强大的防御机制提供了基础。"}}
{"id": "2506.06136", "title": "UAV-UGV Cooperative Trajectory Optimization and Task Allocation for Medical Rescue Tasks in Post-Disaster Environments", "authors": ["Kaiyuan Chen", "Wanpeng Zhao", "Yongxi Liu", "Yuanqing Xia", "Wannian Liang", "Shuo Wang"], "summary": "In post-disaster scenarios, rapid and efficient delivery of medical resources\nis critical and challenging due to severe damage to infrastructure. To provide\nan optimized solution, we propose a cooperative trajectory optimization and\ntask allocation framework leveraging unmanned aerial vehicles (UAVs) and\nunmanned ground vehicles (UGVs). This study integrates a Genetic Algorithm (GA)\nfor efficient task allocation among multiple UAVs and UGVs, and employs an\ninformed-RRT* (Rapidly-exploring Random Tree Star) algorithm for collision-free\ntrajectory generation. Further optimization of task sequencing and path\nefficiency is conducted using Covariance Matrix Adaptation Evolution Strategy\n(CMA-ES). Simulation experiments conducted in a realistic post-disaster\nenvironment demonstrate that our proposed approach significantly improves the\noverall efficiency of medical rescue operations compared to traditional\nstrategies, showing substantial reductions in total mission completion time and\ntraveled distance. Additionally, the cooperative utilization of UAVs and UGVs\neffectively balances their complementary advantages, highlighting the system' s\nscalability and practicality for real-world deployment.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06136v1", "AI": {"title_translation": "无人机-无人车协同轨迹优化与任务分配在灾后医疗救援任务中的应用", "tldr": "提出无人机与无人车协同框架，优化灾后医疗救援中的轨迹和任务分配，显著提高效率。", "motivation": "在灾后情景中，由于基础设施严重受损，快速高效地运送医疗资源至关重要且充满挑战。", "method": "本文提出了一个利用无人机（UAV）和无人地面车辆（UGV）的协同轨迹优化和任务分配框架。该研究整合了遗传算法（GA）用于高效任务分配，并采用informed-RRT*算法生成无碰撞轨迹，同时利用协方差矩阵自适应进化策略（CMA-ES）进一步优化任务序列和路径效率。", "result": "在真实的灾后环境中进行的仿真实验表明，所提出的方法与传统策略相比，显著提高了医疗救援行动的整体效率，表现为总任务完成时间和行驶距离的大幅减少。此外，无人机和无人车的协同利用有效平衡了它们的互补优势。", "conclusion": "该系统具有可扩展性和实用性，适用于实际部署，能够有效提高灾后医疗救援效率。", "translation": "在灾后情景中，由于基础设施严重受损，快速高效地运送医疗资源至关重要且充满挑战。为了提供一个优化的解决方案，我们提出了一个利用无人机（UAV）和无人地面车辆（UGV）的协同轨迹优化和任务分配框架。本研究整合了遗传算法（GA）以实现多无人机和无人车之间的高效任务分配，并采用了informed-RRT*（快速探索随机树星）算法生成无碰撞轨迹。使用协方差矩阵自适应进化策略（CMA-ES）进一步优化了任务序列和路径效率。在真实的灾后环境中进行的仿真实验表明，与传统策略相比，我们提出的方法显著提高了医疗救援行动的整体效率，显示出总任务完成时间和行驶距离的大幅减少。此外，无人机和无人车的协同利用有效平衡了它们的互补优势，突出了该系统在实际部署中的可扩展性和实用性。", "summary": "本文提出了一种无人机-无人车协同框架，用于优化灾后医疗救援任务中的轨迹规划和任务分配。该框架结合了遗传算法进行任务分配，informed-RRT*算法生成无碰撞轨迹，并利用CMA-ES优化任务序列和路径效率。仿真结果表明，该方法显著提升了救援效率，减少了任务时间和行驶距离，并有效利用了无人机和无人车的互补优势，展现了其在实际应用中的潜力和可扩展性。", "keywords": "无人机,无人车,协同优化,医疗救援,灾后环境", "comments": "本文创新性地将无人机和无人车结合，提出了一个协同框架来解决灾后医疗救援中的复杂路径规划和任务分配问题。通过集成GA、informed-RRT*和CMA-ES等多种优化算法，实现了高效且鲁棒的解决方案。该研究的重要性在于其直接针对灾后救援的实际需求，并提供了具有可扩展性和实用性的技术方案，有望在紧急情况下大幅提升救援效率。"}}
{"id": "2506.05812", "title": "Optimal Robotic Velcro Peeling with Force Feedback", "authors": ["Jiacheng Yuan", "Changhyun Choi", "Volkan Isler"], "summary": "We study the problem of peeling a Velcro strap from a surface using a robotic\nmanipulator. The surface geometry is arbitrary and unknown. The robot has\naccess to only the force feedback and its end-effector position. This problem\nis challenging due to the partial observability of the environment and the\nincompleteness of the sensor feedback. To solve it, we first model the system\nwith simple analytic state and action models based on quasi-static dynamics\nassumptions. We then study the fully-observable case where the state of both\nthe Velcro and the robot are given. For this case, we obtain the optimal\nsolution in closed-form which minimizes the total energy cost. Next, for the\npartially-observable case, we design a state estimator which estimates the\nunderlying state using only force and position feedback. Then, we present a\nheuristics-based controller that balances exploratory and exploitative\nbehaviors in order to peel the velcro efficiently. Finally, we evaluate our\nproposed method in environments with complex geometric uncertainties and sensor\nnoises, achieving 100% success rate with less than 80% increase in energy cost\ncompared to the optimal solution when the environment is fully-observable,\noutperforming the baselines by a large margin.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05812v1", "AI": {"title_translation": "基于力反馈的最优机器人尼龙搭扣剥离", "tldr": "本文研究了机器人使用力反馈从未知表面剥离尼龙搭扣的问题，提出了一种结合状态估计和启发式控制的方法，在复杂环境中实现了高成功率并优于基线。", "motivation": "在环境部分可观测且传感器反馈不完整的情况下，机器人从任意未知表面剥离尼龙搭扣是一个具有挑战性的问题。", "method": "首先，基于准静态动力学假设，用简单的解析状态和动作模型对系统进行建模。然后，针对完全可观测情况，获得了最小化总能量成本的闭式最优解。接着，针对部分可观测情况，设计了一个仅使用力和位置反馈估计底层状态的状态估计器。最后，提出了一种平衡探索和利用行为的启发式控制器。", "result": "在具有复杂几何不确定性和传感器噪声的环境中，所提出的方法实现了100%的成功率，与环境完全可观测时的最优解相比，能量成本增加不到80%，并且大大优于基线方法。", "conclusion": "本文提出了一种有效的机器人尼龙搭扣剥离方法，即使在环境部分可观测和传感器反馈不完整的情况下，也能实现高成功率和较低的能量成本，显著优于现有方法。", "translation": "我们研究了使用机器人操纵器从表面剥离尼龙搭扣的问题。表面几何形状是任意且未知的。机器人只能获得力反馈及其末端执行器位置。由于环境的部分可观测性和传感器反馈的不完整性，这个问题具有挑战性。为了解决它，我们首先基于准静态动力学假设，用简单的解析状态和动作模型对系统进行建模。然后，我们研究了尼龙搭扣和机器人状态都已知的完全可观测情况。对于这种情况，我们获得了最小化总能量成本的闭式最优解。接下来，对于部分可观测情况，我们设计了一个状态估计器，仅使用力和位置反馈来估计底层状态。然后，我们提出了一种基于启发式的控制器，平衡探索和利用行为，以有效地剥离尼龙搭扣。最后，我们在具有复杂几何不确定性和传感器噪声的环境中评估了我们提出的方法，与环境完全可观测时的最优解相比，实现了100%的成功率，能量成本增加不到80%，大大优于基线。", "summary": "本文探讨了机器人在仅有力和位置反馈的情况下，从未知表面剥离尼龙搭扣的难题。针对该挑战，研究者首先建立了系统模型，并为完全可观测情况找到了最优解。随后，针对更实际的部分可观测情况，开发了一个状态估计器和一种平衡探索与利用的启发式控制器。实验结果表明，该方法在复杂不确定环境中表现出色，实现了100%的成功率，且能量成本接近最优，显著优于现有方法。", "keywords": "机器人剥离, 尼龙搭扣, 力反馈, 部分可观测, 最优控制", "comments": "这篇论文的创新点在于它解决了机器人操作中常见的局部可观测性和不完整传感器反馈的难题，特别是在尼龙搭扣剥离这一特定但具有代表性的任务中。通过结合理论建模（完全可观测最优解）和实用工程（状态估计器和启发式控制器），该方法在复杂环境中展现了强大的鲁棒性和高效性。其在能量成本控制上的表现也值得关注，表明了其在实际应用中的潜力。"}}
{"id": "2506.05369", "title": "MR.NAVI: Mixed-Reality Navigation Assistant for the Visually Impaired", "authors": ["Nicolas Pfitzer", "Yifan Zhou", "Marco Poggensee", "Defne Kurtulus", "Bessie Dominguez-Dager", "Mihai Dusmanu", "Marc Pollefeys", "Zuria Bauer"], "summary": "Over 43 million people worldwide live with severe visual impairment, facing\nsignificant challenges in navigating unfamiliar environments. We present\nMR.NAVI, a mixed reality system that enhances spatial awareness for visually\nimpaired users through real-time scene understanding and intuitive audio\nfeedback. Our system combines computer vision algorithms for object detection\nand depth estimation with natural language processing to provide contextual\nscene descriptions, proactive collision avoidance, and navigation instructions.\nThe distributed architecture processes sensor data through MobileNet for object\ndetection and employs RANSAC-based floor detection with DBSCAN clustering for\nobstacle avoidance. Integration with public transit APIs enables navigation\nwith public transportation directions. Through our experiments with user\nstudies, we evaluated both scene description and navigation functionalities in\nunfamiliar environments, showing promising usability and effectiveness.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05369v1", "AI": {"title_translation": "MR.NAVI：视障人士混合现实导航助手", "tldr": "MR.NAVI是一个混合现实系统，通过实时场景理解和音频反馈帮助视障人士在陌生环境中导航和避障。", "motivation": "全球有超过4300万人患有严重的视力障碍，他们在陌生环境中导航时面临巨大挑战。", "method": "MR.NAVI系统结合了计算机视觉算法（用于物体检测和深度估计）、自然语言处理（提供情境化场景描述、主动碰撞避免和导航指令）。其分布式架构通过MobileNet处理传感器数据进行物体检测，并采用基于RANSAC的地面检测和DBSCAN聚类进行障碍物规避。系统还集成了公共交通API以提供公共交通方向的导航。", "result": "通过用户研究实验，系统在陌生环境中的场景描述和导航功能都表现出良好的可用性和有效性。", "conclusion": "Not mentioned in abstract", "translation": "全球有超过4300万人患有严重的视力障碍，他们在陌生环境中导航时面临着巨大的挑战。我们推出了MR.NAVI，一个混合现实系统，通过实时场景理解和直观的音频反馈，增强视障用户的空间感知能力。我们的系统结合了计算机视觉算法（用于物体检测和深度估计）和自然语言处理技术，以提供情境化的场景描述、主动的碰撞避免和导航指令。其分布式架构通过MobileNet处理传感器数据进行物体检测，并采用基于RANSAC的地面检测和DBSCAN聚类进行障碍物规避。与公共交通API的集成使得系统能够提供公共交通方向的导航。通过用户研究实验，我们评估了系统在陌生环境中的场景描述和导航功能，结果显示出良好的可用性和有效性。", "summary": "MR.NAVI是一个专为视障人士设计的混合现实导航系统。它利用计算机视觉和自然语言处理技术，结合MobileNet进行物体检测，并利用RANSAC和DBSCAN进行障碍物规避。系统还集成公共交通API，旨在通过实时场景理解和直观音频反馈增强用户的空间感知能力和提供导航指导。用户研究表明该系统具有良好的可用性和有效性。", "keywords": "混合现实, 视障导航, 计算机视觉, 空间感知, 避障", "comments": "该论文提出了一种创新的混合现实系统MR.NAVI，旨在解决视障人士在陌生环境中导航的重大挑战。其亮点在于结合了多种先进技术，包括计算机视觉、自然语言处理以及分布式架构，以提供实时的空间感知增强、碰撞避免和导航指导。系统的实用性通过用户研究得到了初步验证，显示出其在提升视障人士独立出行能力方面的潜力。"}}
{"id": "2506.05836", "title": "Analysis of cost-efficiency of serverless approaches", "authors": ["Nakhat Syeda", "Harsh Shah", "Rajvinder Singh", "Suraj Jaju", "Sumedha Kumar", "Gourav Chhabra", "Maria Spichkova"], "summary": "In this paper, we present a survey of research studies related to the\ncost-effectiveness of serverless approach and corresponding cost savings. We\nconducted a systematic literature review using Google Scholar search engine,\ncovering the period from 2010 to 2024. We identified 34 related studies, from\nwhich we extracted 17 parameters that might influence the relative cost savings\nof applying the serverless approach.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05836v1", "AI": {"title_translation": "无服务器方法成本效益分析", "tldr": "本文对2010年至2024年间关于无服务器方法成本效益和成本节约的研究进行了系统文献综述，识别出34项相关研究，并提取了17个可能影响成本节约的参数。", "motivation": "了解无服务器方法的成本效益及其潜在的成本节约。", "method": "采用Google Scholar搜索引擎，对2010年至2024年期间的研究进行了系统文献综述。", "result": "识别出34项相关研究，并从中提取了17个可能影响无服务器方法相对成本节约的参数。", "conclusion": "Not mentioned in abstract", "translation": "在本文中，我们对与无服务器方法的成本效益和相应成本节约相关的研究进行了调查。我们使用Google Scholar搜索引擎进行了系统文献综查，涵盖了2010年至2024年期间。我们识别出34项相关研究，并从中提取了17个可能影响应用无服务器方法的相对成本节约的参数。", "summary": "本文通过对2010年至2024年Google Scholar上的研究进行系统文献综述，旨在调查无服务器方法的成本效益和成本节约。研究共识别出34项相关研究，并提取了17个可能影响无服务器方法成本节约的参数。", "keywords": "Serverless, Cost-efficiency, Cost savings, Literature review, Parameters", "comments": "Not mentioned in abstract"}}
{"id": "2506.02619", "title": "HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport", "authors": ["Yanbei Liu", "Chongxu Wang", "Zhitao Xiao", "Lei Geng", "Yanwei Pang", "Xiao Wang"], "summary": "Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent\ncapabilities in processing heterogeneous information networks. Self-supervised\nlearning on heterogeneous graphs, especially contrastive self-supervised\nstrategy, shows great potential when there are no labels. However, this\napproach requires the use of carefully designed graph augmentation strategies\nand the selection of positive and negative samples. Determining the exact level\nof similarity between sample pairs is non-trivial.To solve this problem, we\npropose a novel self-supervised Heterogeneous graph neural network with Optimal\nTransport (HGOT) method which is designed to facilitate self-supervised\nlearning for heterogeneous graphs without graph augmentation strategies.\nDifferent from traditional contrastive self-supervised learning, HGOT employs\nthe optimal transport mechanism to relieve the laborious sampling process of\npositive and negative samples. Specifically, we design an aggregating view\n(central view) to integrate the semantic information contained in the views\nrepresented by different meta-paths (branch views). Then, we introduce an\noptimal transport plan to identify the transport relationship between the\nsemantics contained in the branch view and the central view. This allows the\noptimal transport plan between graphs to align with the representations,\nforcing the encoder to learn node representations that are more similar to the\ngraph space and of higher quality. Extensive experiments on four real-world\ndatasets demonstrate that our proposed HGOT model can achieve state-of-the-art\nperformance on various downstream tasks. In particular, in the node\nclassification task, HGOT achieves an average of more than 6% improvement in\naccuracy compared with state-of-the-art methods.", "comment": "The paper has 9 pages of text and 13 pages in total (including\n  acknowledgments, impact statement, references, and appendix), with 6 figures\n  and 2 tables. This paper has been accepted by ICML 2025 conference and this\n  is a final version of the manuscript submitted to the conference", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.02619v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05587", "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "summary": "Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05587v1", "AI": {"title_translation": "MMTU：一个大规模多任务表格理解和推理基准", "tldr": "引入MMTU，一个包含25个真实世界表格任务、3万多问题的基准，用于全面评估模型对表格的理解、推理和操作能力，并发现现有前沿模型在此方面仍有显著提升空间。", "motivation": "现有大型语言模型（LLMs）在表格处理方面取得了进展，但缺乏全面的基准来评估其能力。当前的表格相关评估稀缺且范围狭窄，未能涵盖专业用户面临的广泛真实世界任务，这限制了对表格领域模型的理解和进展。", "method": "作者引入了MMTU，这是一个大规模基准，包含超过30,000个问题，涵盖25个真实世界的表格任务。该基准旨在全面评估模型在专家级别理解、推理和操作真实表格的能力。这些任务来源于数十年的表格数据计算机科学研究，并侧重于专业用户面临的复杂表格任务。", "result": "MMTU基准要求模型具备表格理解、推理和编码的综合技能，这对当前的前沿模型（如OpenAI o4-mini和DeepSeek R1）仍然具有挑战性，它们的得分仅在60%左右。这表明在该领域仍有显著的改进空间。", "conclusion": "MMTU基准揭示了当前前沿模型在复杂表格理解、推理和操作方面存在的显著不足。作者希望MMTU能够推动结构化数据处理和分析的基础模型进一步发展。", "translation": "表格和基于表格的用例在许多重要的实际应用中发挥着关键作用，例如电子表格、数据库和计算笔记本，这些传统上需要数据工程师、数据分析师和数据库管理员等专家级用户来操作。尽管大型语言模型（LLMs）在处理表格方面（例如在电子表格和数据库副驾驶场景中）取得了显著进展，但对此类能力的全面基准测试仍然有限。与广泛且不断增长的自然语言处理（NLP）基准列表相比，表格相关任务的评估稀缺，且狭隘地集中于自然语言到SQL（NL-to-SQL）和表格问答（Table-QA）等任务，忽视了专业用户面临的更广泛的真实世界任务。这一空白限制了我们对这一重要领域的理解和模型进展。\n在这项工作中，我们引入了MMTU，这是一个大规模基准，包含来自25个真实世界表格任务的3万多个问题，旨在全面评估模型在专家级别理解、推理和操作真实表格的能力。这些任务来源于数十年的表格数据计算机科学研究，重点关注专业用户面临的复杂表格任务。我们表明，MMTU需要多种技能组合——包括表格理解、推理和编码——这对当今的前沿模型仍然具有挑战性，即使是像OpenAI o4-mini和DeepSeek R1这样的前沿推理模型也只取得了约60%的得分，这表明仍有显著的改进空间。我们强调了使用MMTU评估中的主要发现，并希望这个基准能推动结构化数据处理和分析的基础模型进一步发展。我们的代码和数据可在https://github.com/MMTU-Benchmark/MMTU 和 https://huggingface.co/datasets/MMTU-benchmark/MMTU 获取。", "summary": "这项工作介绍了MMTU，一个大规模多任务表格理解和推理基准，旨在弥补现有表格处理基准的不足。MMTU包含超过3万个问题，涵盖25个真实世界的复杂表格任务，全面评估模型在专家级别理解、推理和操作表格的能力。评估结果显示，即使是当前最先进的模型在MMTU上表现仍不理想，得分仅为60%左右，这突显了该领域巨大的改进潜力，并有望推动未来结构化数据处理基础模型的发展。", "keywords": "表格理解, 多任务基准, 大规模语言模型, 数据推理, 结构化数据", "comments": "MMTU基准的创新之处在于其大规模和对真实世界复杂表格任务的全面覆盖，填补了现有表格处理基准的空白。它不仅关注表格理解，还强调了推理和编码能力，更贴近专业用户实际需求。其重要性在于为评估和推动大模型在结构化数据处理领域的发展提供了一个更具挑战性和代表性的平台，揭示了当前前沿模型在复杂表格任务上的局限性，为未来的研究指明了方向。"}}
{"id": "2506.06156", "title": "Resource Allocation for Pinching-Antenna Systems: State-of-the-Art, Key Techniques and Open Issues", "authors": ["Ming Zeng", "Ji Wang", "Octavia A. Dobre", "Zhiguo Ding", "George K. Karagiannidis", "Robert Schober", "H. Vincent Poor"], "summary": "Pinching antennas have emerged as a promising technology for reconfiguring\nwireless propagation environments, particularly in high-frequency communication\nsystems operating in the millimeter-wave and terahertz bands. By enabling\ndynamic activation at arbitrary positions along a dielectric waveguide,\npinching antennas offer unprecedented channel reconfigurability and the ability\nto provide line-of-sight (LoS) links in scenarios with severe LoS blockages.\nThe performance of pinching-antenna systems is highly dependent on the\noptimized placement of the pinching antennas, which must be jointly considered\nwith traditional resource allocation (RA) variables -- including transmission\npower, time slots, and subcarriers. The resulting joint RA problems are\ntypically non-convex with complex variable coupling, necessitating\nsophisticated optimization techniques. This article provides a comprehensive\nsurvey of existing RA algorithms designed for pinching-antenna systems,\nsupported by numerical case studies that demonstrate their potential\nperformance gains. Key challenges and open research problems are also\nidentified to guide future developments in this emerging field.", "comment": "submitted to IEEE WCM, 8 pages, 5 figures", "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.06156v1", "AI": {"title_translation": "夹持天线系统的资源分配：现状、关键技术与开放问题", "tldr": "本文综述了夹持天线系统中的资源分配算法，并讨论了其挑战和未来方向。", "motivation": "夹持天线是一种有前景的技术，能动态重构无线传播环境，尤其在高频通信中提供视距链路。然而，其性能高度依赖于天线优化放置以及与传统资源分配变量的联合考虑，这导致复杂的非凸问题，需要先进的优化技术。", "method": "本文对现有针对夹持天线系统的资源分配算法进行了全面综述，并通过数值案例研究展示了其潜在性能增益。", "result": "综述了现有资源分配算法，并通过数值案例展示了性能增益；识别了关键挑战和开放研究问题。", "conclusion": "夹持天线系统的资源分配是一个复杂但重要的领域，需要先进的优化技术，并且仍有许多开放研究问题。", "translation": "夹持天线已成为一种很有前景的技术，用于重新配置无线传播环境，特别是在毫米波和太赫兹频段运行的高频通信系统中。通过在介质波导的任意位置实现动态激活，夹持天线提供了前所未有的信道可重构性，并能够在严重视距阻塞的场景中提供视距（LoS）链路。夹持天线系统的性能高度依赖于夹持天线的优化放置，这必须与包括传输功率、时隙和子载波在内的传统资源分配（RA）变量联合考虑。由此产生的联合资源分配问题通常是非凸的，变量耦合复杂，因此需要复杂的优化技术。本文对现有针对夹持天线系统的资源分配算法进行了全面综述，并辅以数值案例研究，以证明其潜在的性能增益。文中还指出了关键挑战和开放研究问题，以指导该新兴领域的未来发展。", "summary": "本文对夹持天线系统中的资源分配（RA）问题进行了全面综述。夹持天线是一种新兴技术，通过动态激活实现无线环境重构，在高频通信中提供视距链路。然而，其性能优化涉及天线放置与传统RA变量的联合考虑，形成复杂的非凸问题。文章回顾了现有RA算法，通过案例研究展示了其潜力，并识别了该领域的关键挑战和开放研究问题。", "keywords": "夹持天线, 资源分配, 毫米波, 太赫兹, 优化算法", "comments": "这篇综述文章为夹持天线系统的资源分配领域提供了全面的概述，识别了关键的挑战和未来的研究方向，对于推动该新兴技术的发展具有重要指导意义。其价值在于系统梳理了现有算法，并指出了非凸优化等核心难点。"}}
{"id": "2506.05435", "title": "Event Classification of Accelerometer Data for Industrial Package Monitoring with Embedded Deep Learning", "authors": ["Manon Renault", "Hamoud Younes", "Hugo Tessier", "Ronan Le Roy", "Bastien Pasdeloup", "Mathieu Léonardon"], "summary": "Package monitoring is an important topic in industrial applications, with\nsignificant implications for operational efficiency and ecological\nsustainability. In this study, we propose an approach that employs an embedded\nsystem, placed on reusable packages, to detect their state (on a Forklift, in a\nTruck, or in an undetermined location). We aim to design a system with a\nlifespan of several years, corresponding to the lifespan of reusable packages.\nOur analysis demonstrates that maximizing device lifespan requires minimizing\nwake time. We propose a pipeline that includes data processing, training, and\nevaluation of the deep learning model designed for imbalanced, multiclass time\nseries data collected from an embedded sensor. The method uses a\none-dimensional Convolutional Neural Network architecture to classify\naccelerometer data from the IoT device. Before training, two data augmentation\ntechniques are tested to solve the imbalance problem of the dataset: the\nSynthetic Minority Oversampling TEchnique and the ADAptive SYNthetic sampling\napproach. After training, compression techniques are implemented to have a\nsmall model size. On the considered twoclass problem, the methodology yields a\nprecision of 94.54% for the first class and 95.83% for the second class, while\ncompression techniques reduce the model size by a factor of four. The trained\nmodel is deployed on the IoT device, where it operates with a power consumption\nof 316 mW during inference.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05435v1", "AI": {"title_translation": "工业包裹监测中嵌入式深度学习的加速度计数据事件分类", "tldr": "本文提出了一种基于嵌入式深度学习的加速度计数据分类方法，用于工业可重复使用包裹的状态监测，实现了高精度和低功耗。", "motivation": "工业包裹监测对运营效率和生态可持续性至关重要。研究旨在设计一个寿命长达数年的嵌入式系统，以检测可重复使用包裹的状态（叉车上、卡车上或未知位置），并最大化设备寿命，这需要最小化唤醒时间。", "method": "提出一个包含数据处理、训练和评估深度学习模型的流程，该模型针对嵌入式传感器收集的不平衡、多类别时间序列数据设计。方法使用一维卷积神经网络 (CNN) 架构对加速度计数据进行分类。训练前，测试了两种数据增强技术（SMOTE 和 ADASYN）来解决数据集不平衡问题。训练后，实施压缩技术以减小模型大小。", "result": "在所考虑的两类问题上，该方法对第一类的精确度达到 94.54%，对第二类的精确度达到 95.83%。压缩技术将模型大小减小了四倍。训练后的模型部署在物联网设备上，推理期间的功耗为 316 mW。", "conclusion": "本文成功开发并部署了一个高效、低功耗的嵌入式深度学习系统，用于工业包裹状态监测，具有高分类精度和较长的设备寿命。", "translation": "工业包裹监测是工业应用中的一个重要课题，对运营效率和生态可持续性具有重要意义。在这项研究中，我们提出了一种方法，该方法采用放置在可重复使用包裹上的嵌入式系统来检测其状态（在叉车上、在卡车上或在未确定的位置）。我们的目标是设计一个寿命长达数年的系统，与可重复使用包裹的寿命相对应。我们的分析表明，最大化设备寿命需要最小化唤醒时间。我们提出了一个流程，包括数据处理、训练和评估为嵌入式传感器收集的不平衡、多类别时间序列数据设计的深度学习模型。该方法使用一维卷积神经网络架构对来自物联网设备的加速度计数据进行分类。训练前，测试了两种数据增强技术来解决数据集不平衡问题：合成少数过采样技术（Synthetic Minority Oversampling TEchnique）和自适应合成采样方法（ADAptive SYNthetic sampling approach）。训练后，实施压缩技术以减小模型大小。在所考虑的两类问题上，该方法对第一类的精确度达到 94.54%，对第二类的精确度达到 95.83%，而压缩技术将模型大小减小了四倍。训练后的模型部署在物联网设备上，推理期间的功耗为 316 mW。", "summary": "本文提出了一种用于工业包裹监测的嵌入式深度学习方法，利用加速度计数据识别包裹状态。该方法采用一维CNN处理不平衡的多类别时间序列数据，并通过数据增强和模型压缩优化系统性能和设备寿命。实验结果显示，在两类问题上分类精度高，模型尺寸显著减小，且部署在IoT设备上运行时功耗低，满足了工业应用中长期监测的需求。", "keywords": "工业包裹监测, 嵌入式深度学习, 加速度计数据, 一维卷积神经网络, 模型压缩", "comments": "这项研究的创新点在于将嵌入式深度学习应用于工业包裹监测，并特别关注了设备寿命和功耗优化。通过结合数据增强和模型压缩技术，解决了实际应用中数据不平衡和资源受限的挑战。其重要性体现在为工业物流提供了高效、可持续的解决方案。"}}
{"id": "2506.05977", "title": "Mitigating Catastrophic Forgetting with Adaptive Transformer Block Expansion in Federated Fine-Tuning", "authors": ["Yujia Huo", "Jianchun Liu", "Hongli Xu", "Zhenguo Ma", "Shilong Wang", "Liusheng Huang"], "summary": "Federated fine-tuning (FedFT) of large language models (LLMs) has emerged as\na promising solution for adapting models to distributed data environments while\nensuring data privacy.\n  Existing FedFT methods predominantly utilize parameter-efficient fine-tuning\n(PEFT) techniques to reduce communication and computation overhead.\n  However, they often fail to adequately address the catastrophic forgetting, a\ncritical challenge arising from continual adaptation in distributed\nenvironments. The traditional centralized fine-tuning methods, which are not\ndesigned for the heterogeneous and privacy-constrained nature of federated\nenvironments, struggle to mitigate this issue effectively. Moreover, the\nchallenge is further exacerbated by significant variation in data distributions\nand device capabilities across clients, which leads to intensified forgetting\nand degraded model generalization. To tackle these issues, we propose FedBE, a\nnovel FedFT framework that integrates an adaptive transformer block expansion\nmechanism with a dynamic trainable-block allocation strategy. Specifically,\nFedBE expands trainable blocks within the model architecture, structurally\nseparating newly learned task-specific knowledge from the original pre-trained\nrepresentations. Additionally, FedBE dynamically assigns these trainable blocks\nto clients based on their data distributions and computational capabilities.\nThis enables the framework to better accommodate heterogeneous federated\nenvironments and enhances the generalization ability of the model.Extensive\nexperiments show that compared with existing federated fine-tuning methods,\nFedBE achieves 12-74% higher accuracy retention on general tasks after\nfine-tuning and a model convergence acceleration ratio of 1.9-3.1x without\ndegrading the accuracy of downstream tasks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05977v1", "AI": {"title_translation": "联邦微调中通过自适应Transformer块扩展缓解灾难性遗忘", "tldr": "提出FedBE框架，通过自适应Transformer块扩展和动态可训练块分配，缓解联邦微调中的灾难性遗忘问题，并提高模型泛化能力和收敛速度。", "motivation": "现有的联邦微调（FedFT）方法主要使用参数高效微调（PEFT）技术，但未能充分解决持续适应分布式环境中出现的灾难性遗忘问题。此外，客户端数据分布和设备能力的显著差异加剧了遗忘并降低了模型泛化能力。", "method": "提出FedBE框架，它结合了自适应Transformer块扩展机制和动态可训练块分配策略。FedBE扩展模型架构中的可训练块，将新学习的任务特定知识与原始预训练表示结构性分离。同时，FedBE根据客户端数据分布和计算能力动态分配这些可训练块。", "result": "实验表明，与现有联邦微调方法相比，FedBE在微调后通用任务上的准确性保留率提高了12-74%，模型收敛速度提高了1.9-3.1倍，且不降低下游任务的准确性。", "conclusion": "FedBE通过结构性分离新知识和动态资源分配，有效缓解了联邦微调中的灾难性遗忘问题，显著提高了模型性能和效率。", "translation": "联邦微调（FedFT）作为一种有前景的解决方案，已出现用于使模型适应分布式数据环境，同时确保数据隐私。现有的FedFT方法主要利用参数高效微调（PEFT）技术来减少通信和计算开销。然而，它们通常未能充分解决灾难性遗忘问题，这是分布式环境中持续适应所带来的一个关键挑战。传统的集中式微调方法并非为联邦环境中异构和隐私受限的性质而设计，难以有效缓解此问题。此外，客户端数据分布和设备能力的显著差异进一步加剧了这一挑战，导致遗忘加剧和模型泛化能力下降。为了解决这些问题，我们提出了FedBE，一个新颖的FedFT框架，它集成了自适应Transformer块扩展机制和动态可训练块分配策略。具体来说，FedBE扩展了模型架构中的可训练块，将新学习的任务特定知识与原始预训练表示结构性分离。此外，FedBE根据客户端的数据分布和计算能力动态分配这些可训练块。这使得该框架能够更好地适应异构联邦环境，并增强模型的泛化能力。大量实验表明，与现有联邦微调方法相比，FedBE在微调后通用任务上的准确性保留率提高了12-74%，模型收敛加速比为1.9-3.1倍，且不降低下游任务的准确性。", "summary": "本文提出了FedBE，一种新颖的联邦微调（FedFT）框架，旨在通过自适应Transformer块扩展和动态可训练块分配策略，有效缓解联邦微调中普遍存在的灾难性遗忘问题。FedBE通过结构性地分离新学习的任务知识和预训练表示，并根据客户端特点动态分配资源，显著提高了模型在异构联邦环境中的泛化能力、准确性保留率和收敛速度。", "keywords": "联邦微调, 灾难性遗忘, Transformer块扩展, 参数高效微调, 大语言模型", "comments": "FedBE通过创新的自适应Transformer块扩展机制，在联邦微调中有效解决了灾难性遗忘这一核心挑战，同时兼顾了联邦环境的异构性，具有重要的实践意义。其性能提升显著，特别是在准确性保持和收敛速度方面。"}}
{"id": "2506.05828", "title": "FinanceReasoning: Benchmarking Financial Numerical Reasoning More Credible, Comprehensive and Challenging", "authors": ["Zichen Tang", "Haihong E", "Ziyan Ma", "Haoyang He", "Jiacheng Liu", "Zhongjun Yang", "Zihua Rong", "Rongjin Li", "Kun Ji", "Qing Huang", "Xinyang Hu", "Yang Liu", "Qianhe Zheng"], "summary": "We introduce FinanceReasoning, a novel benchmark designed to evaluate the\nreasoning capabilities of large reasoning models (LRMs) in financial numerical\nreasoning problems. Compared to existing benchmarks, our work provides three\nkey advancements. (1) Credibility: We update 15.6% of the questions from four\npublic datasets, annotating 908 new questions with detailed Python solutions\nand rigorously refining evaluation standards. This enables an accurate\nassessment of the reasoning improvements of LRMs. (2) Comprehensiveness:\nFinanceReasoning covers 67.8% of financial concepts and formulas, significantly\nsurpassing existing datasets. Additionally, we construct 3,133 Python-formatted\nfunctions, which enhances LRMs' financial reasoning capabilities through\nrefined knowledge (e.g., 83.2% $\\rightarrow$ 91.6% for GPT-4o). (3) Challenge:\nModels are required to apply multiple financial formulas for precise numerical\nreasoning on 238 Hard problems. The best-performing model (i.e., OpenAI o1 with\nPoT) achieves 89.1% accuracy, yet LRMs still face challenges in numerical\nprecision. We demonstrate that combining Reasoner and Programmer models can\neffectively enhance LRMs' performance (e.g., 83.2% $\\rightarrow$ 87.8% for\nDeepSeek-R1). Our work paves the way for future research on evaluating and\nimproving LRMs in domain-specific complex reasoning tasks.", "comment": "Accepted by ACL 2025 Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05828v1", "AI": {"title_translation": "FinanceReasoning: 评估金融数值推理更可信、更全面、更具挑战性", "tldr": "引入FinanceReasoning基准，以更可信、更全面、更具挑战性的方式评估大型推理模型在金融数值推理方面的能力，并展示了通过结合推理器和编程器模型可以有效提升性能。", "motivation": "现有基准在评估大型推理模型（LRMs）在金融数值推理方面存在不足，无法准确评估LRMs的推理改进，覆盖的金融概念和公式有限，且缺乏足够的挑战性。", "method": "引入了FinanceReasoning基准，该基准通过以下三方面改进：1) 可信度：更新了15.6%的现有数据集问题，并标注了908个新问题，提供了详细的Python解决方案，并严格完善了评估标准。2) 全面性：覆盖了67.8%的金融概念和公式，并构建了3,133个Python格式的函数。3) 挑战性：设计了238个需要应用多个金融公式进行精确数值推理的“困难”问题。", "result": "FinanceReasoning通过完善知识显著增强了LRMs的金融推理能力（例如，GPT-4o从83.2%提升到91.6%）。尽管表现最佳的模型（OpenAI o1 with PoT）达到了89.1%的准确率，LRMs在数值精度方面仍面临挑战。研究表明，结合推理器和编程器模型可以有效提升LRMs的性能（例如，DeepSeek-R1从83.2%提升到87.8%）。", "conclusion": "FinanceReasoning基准为未来评估和改进大型推理模型在特定领域复杂推理任务方面的研究铺平了道路。", "translation": "我们引入了FinanceReasoning，这是一个新颖的基准，旨在评估大型推理模型（LRMs）在金融数值推理问题中的推理能力。与现有基准相比，我们的工作提供了三个关键进展。(1) 可信度：我们更新了四个公共数据集中15.6%的问题，标注了908个带有详细Python解决方案的新问题，并严格完善了评估标准。这使得能够准确评估LRMs的推理改进。(2) 全面性：FinanceReasoning覆盖了67.8%的金融概念和公式，显著超越了现有数据集。此外，我们构建了3,133个Python格式的函数，通过完善知识增强了LRMs的金融推理能力（例如，GPT-4o从83.2%提高到91.6%）。(3) 挑战性：模型需要在238个困难问题上应用多个金融公式进行精确的数值推理。表现最佳的模型（即带有PoT的OpenAI o1）达到了89.1%的准确率，但LRMs在数值精度方面仍面临挑战。我们证明了结合推理器和编程器模型可以有效提升LRMs的性能（例如，DeepSeek-R1从83.2%提高到87.8%）。我们的工作为未来评估和改进LRMs在特定领域复杂推理任务方面的研究铺平了道路。", "summary": "该论文介绍了FinanceReasoning，一个用于评估大型推理模型（LRMs）金融数值推理能力的新基准。该基准在可信度、全面性和挑战性方面超越了现有数据集，通过更新问题、覆盖更广泛的金融概念和公式，并引入需要多公式推理的难题。研究结果表明，FinanceReasoning能有效提升LRMs的金融推理能力，并指出通过结合推理器和编程器模型可进一步提高性能，为未来在特定领域复杂推理任务中评估和改进LRMs提供了方向。", "keywords": "金融数值推理, 大型推理模型, 基准测试, FinanceReasoning, Python解决方案", "comments": "该论文的创新之处在于提出了一个专门针对金融数值推理的、更具挑战性和全面性的评估基准。通过引入Python解决方案和更广泛的金融概念覆盖，它为评估和提升大型推理模型在专业领域应用中的实际推理能力提供了宝贵的工具。特别是对“困难”问题的设计以及结合推理器和编程器模型的尝试，为未来研究提供了有益的思路，有助于解决模型在数值精度方面的局限性。"}}
{"id": "2506.06062", "title": "Minoritised Ethnic People's Security and Privacy Concerns and Responses towards Essential Online Services", "authors": ["Aunam Quyoum", "Mark Wong", "Sebati Ghosh", "Siamak F. Shahandashti"], "summary": "Minoritised ethnic people are marginalised in society, and therefore at a\nhigher risk of adverse online harms, including those arising from the loss of\nsecurity and privacy of personal data. Despite this, there has been very little\nresearch focused on minoritised ethnic people's security and privacy concerns,\nattitudes, and behaviours. In this work, we provide the results of one of the\nfirst studies in this regard. We explore minoritised ethnic people's\nexperiences of using essential online services across three sectors: health,\nsocial housing, and energy, their security and privacy-related concerns, and\nresponses towards these services. We conducted a thematic analysis of 44\nsemi-structured interviews with people of various reported minoritised\nethnicities in the UK. Privacy concerns and lack of control over personal data\nemerged as a major theme, with many interviewees considering privacy as their\nmost significant concern when using online services. Several creative tactics\nto exercise some agency were reported, including selective and inconsistent\ndisclosure of personal data. A core concern about how data may be used was\ndriven by a fear of repercussions, including penalisation and discrimination,\ninfluenced by prior experiences of institutional and online racism. The\nincreased concern and potential for harm resulted in minoritised ethnic people\ngrappling with a higher-stakes dilemma of whether to disclose personal\ninformation online or not. Furthermore, trust in institutions, or lack thereof,\nwas found to be embedded throughout as a basis for adapting behaviour. We draw\non our results to provide lessons learned for the design of more inclusive,\nmarginalisation-aware, and privacy-preserving online services.", "comment": "This is an e-print of a paper accepted to the USENIX Symposium on\n  Usable Privacy and Security (SOUPS) 2025", "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.06062v1", "AI": {"title_translation": "少数族裔对基本在线服务的安全和隐私担忧及应对措施", "tldr": "本研究发现少数族裔在使用基本在线服务时对个人数据安全和隐私表现出高度担忧，并采取选择性披露等应对策略，这主要源于对歧视和报复的恐惧以及对机构缺乏信任。", "motivation": "少数族裔在社会中处于边缘地位，面临更高的在线危害风险，尤其是个人数据安全和隐私的丢失。然而，现有研究很少关注少数族裔的安全和隐私担忧、态度和行为，本研究旨在填补这一空白。", "method": "本研究对英国44名不同少数族裔的人进行了半结构化访谈，并采用主题分析法探讨了他们在健康、社会住房和能源三个领域使用基本在线服务的经验、安全和隐私相关担忧及应对措施。", "result": "研究发现，隐私担忧和对个人数据缺乏控制是主要问题，许多受访者认为隐私是使用在线服务时最主要的担忧。受访者报告了多种创造性策略来行使自主权，包括选择性且不一致地披露个人数据。对数据如何被使用的核心担忧源于对报复（包括惩罚和歧视）的恐惧，这受到之前机构性和在线种族主义经历的影响。更高的担忧和潜在的危害导致少数族裔在是否在线披露个人信息上面临更高风险的困境。此外，对机构的信任或缺乏信任被认为是适应行为的基础。", "conclusion": "本研究结果为设计更具包容性、关注边缘化群体并保护隐私的在线服务提供了宝贵的经验教训。", "translation": "少数族裔在社会中处于边缘地位，因此面临更高的不良在线危害风险，包括个人数据安全和隐私丢失带来的风险。尽管如此，很少有研究关注少数族裔的安全和隐私担忧、态度和行为。在这项工作中，我们提供了这方面首批研究之一的结果。我们探讨了少数族裔在使用健康、社会住房和能源三个领域的基本在线服务时的经验，他们与安全和隐私相关的担忧，以及对这些服务的应对措施。我们对英国44名报告为不同少数族裔的人进行了半结构化访谈，并进行了主题分析。隐私担忧和对个人数据缺乏控制成为一个主要主题，许多受访者认为隐私是他们使用在线服务时最主要的担忧。报告了几种行使自主权的创造性策略，包括选择性、不一致地披露个人数据。对数据可能如何被使用的核心担忧源于对报复的恐惧，包括惩罚和歧视，这受到之前机构性和在线种族主义经历的影响。担忧的增加和潜在的危害导致少数族裔面临是否在线披露个人信息的更高风险困境。此外，对机构的信任或缺乏信任被发现是适应行为的基础。我们利用研究结果为设计更具包容性、关注边缘化群体并保护隐私的在线服务提供了经验教训。", "summary": "本文通过对英国44名少数族裔的半结构化访谈，深入探讨了他们在健康、社会住房和能源等基本在线服务中面临的安全和隐私担忧。研究发现，隐私担忧和对个人数据缺乏控制是核心问题，受访者常因担心歧视和报复而采取选择性披露等应对策略。信任机构与否也显著影响其行为。研究强调了社会边缘化与数字风险的关联，并为设计更具包容性和隐私保护的在线服务提供了实践指导。", "keywords": "少数族裔, 在线服务, 安全, 隐私, 担忧, 应对策略", "comments": "这项研究创新性地关注了少数族裔群体在数字服务使用中的独特安全和隐私挑战，填补了该领域研究的空白。其重要性在于揭示了社会边缘化与数字风险之间的关联，并为服务设计者提供了具体的指导，以促进数字包容性，对政策制定和技术开发具有重要参考价值。"}}
{"id": "2506.05407", "title": "PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs", "authors": ["Jianqing Zhang", "Yang Liu", "Jie Fu", "Yang Hua", "Tianyuan Zou", "Jian Cao", "Qiang Yang"], "summary": "The rise of generative APIs has fueled interest in privacy-preserving\nsynthetic data generation. While the Private Evolution (PE) algorithm generates\nDifferential Privacy (DP) synthetic images using diffusion model APIs, it\nstruggles with few-shot private data due to the limitations of its DP-protected\nsimilarity voting approach. In practice, the few-shot private data challenge is\nparticularly prevalent in specialized domains like healthcare and industry. To\naddress this challenge, we propose a novel API-assisted algorithm, Private\nContrastive Evolution (PCEvolve), which iteratively mines inherent inter-class\ncontrastive relationships in few-shot private data beyond individual data\npoints and seamlessly integrates them into an adapted Exponential Mechanism\n(EM) to optimize DP's utility in an evolution loop. We conduct extensive\nexperiments on four specialized datasets, demonstrating that PCEvolve\noutperforms PE and other API-assisted baselines. These results highlight the\npotential of leveraging API access with private data for quality evaluation,\nenabling the generation of high-quality DP synthetic images and paving the way\nfor more accessible and effective privacy-preserving generative API\napplications. Our code is available at https://github.com/TsingZ0/PCEvolve.", "comment": "Accepted as ICML Spotlight (top 2.6%)", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05407v1", "AI": {"title_translation": "PCEvolve：通过少样本私有数据和生成式API实现合成数据集生成的私有对比进化", "tldr": "PCEvolve是一种新的算法，通过挖掘少样本私有数据中的类间对比关系，解决了现有私有进化算法在生成差分隐私合成图像时面临的少样本数据挑战。", "motivation": "现有的私有进化（PE）算法在处理少样本私有数据时表现不佳，因为它在差分隐私保护的相似性投票方法存在局限性。在医疗保健和工业等专业领域，少样本私有数据挑战尤为普遍。", "method": "PCEvolve通过迭代挖掘少样本私有数据中固有的类间对比关系，并将其无缝集成到改进的指数机制（EM）中，以在进化循环中优化差分隐私的效用。", "result": "PCEvolve在四个专业数据集上进行了广泛实验，结果表明它优于PE和其他API辅助基线方法。", "conclusion": "这些结果突出了利用API访问私有数据进行质量评估的潜力，能够生成高质量的差分隐私合成图像，并为更易访问和有效的隐私保护生成式API应用铺平道路。", "translation": "生成式API的兴起推动了人们对隐私保护合成数据生成的研究兴趣。虽然私有进化（PE）算法利用扩散模型API生成差分隐私（DP）合成图像，但由于其受DP保护的相似性投票方法的局限性，它在少样本私有数据方面表现不佳。在实践中，少样本私有数据挑战在医疗保健和工业等专业领域尤为普遍。为了解决这一挑战，我们提出了一种新颖的API辅助算法——私有对比进化（PCEvolve），它迭代地挖掘少样本私有数据中超越单个数据点的固有类间对比关系，并将其无缝集成到改进的指数机制（EM）中，以在进化循环中优化DP的效用。我们在四个专业数据集上进行了广泛实验，证明PCEvolve优于PE和其他API辅助基线方法。这些结果突出了利用API访问私有数据进行质量评估的潜力，能够生成高质量的DP合成图像，并为更易访问和有效的隐私保护生成式API应用铺平道路。我们的代码可在https://github.com/TsingZ0/PCEvolve获取。", "summary": "该论文提出了一种名为PCEvolve的新型API辅助算法，旨在解决现有私有进化（PE）算法在生成差分隐私（DP）合成图像时，面对少样本私有数据时的局限性。PCEvolve通过迭代挖掘少样本数据中固有的类间对比关系，并将其整合到改进的指数机制中，以优化DP的效用。实验结果表明，PCEvolve在多个专业数据集上优于PE和其他基线方法，表明其在高质量DP合成图像生成和隐私保护生成式API应用方面的潜力。", "keywords": "差分隐私, 合成数据生成, 少样本学习, 对比进化, 生成式API", "comments": "该论文的创新点在于提出了PCEvolve算法，通过利用少样本数据中的类间对比关系来改进差分隐私合成数据生成，特别是在医疗保健等数据稀缺的专业领域具有重要意义。它有效地克服了现有PE算法在处理少样本数据时的缺陷，并通过与生成式API的结合，提升了合成数据的质量和隐私保护效果。"}}
{"id": "2506.05896", "title": "Object Navigation with Structure-Semantic Reasoning-Based Multi-level Map and Multimodal Decision-Making LLM", "authors": ["Chongshang Yan", "Jiaxuan He", "Delun Li", "Yi Yang", "Wenjie Song"], "summary": "The zero-shot object navigation (ZSON) in unknown open-ended environments\ncoupled with semantically novel target often suffers from the significant\ndecline in performance due to the neglect of high-dimensional implicit scene\ninformation and the long-range target searching task. To address this, we\nproposed an active object navigation framework with Environmental Attributes\nMap (EAM) and MLLM Hierarchical Reasoning module (MHR) to improve its success\nrate and efficiency. EAM is constructed by reasoning observed environments with\nSBERT and predicting unobserved ones with Diffusion, utilizing human space\nregularities that underlie object-room correlations and area adjacencies. MHR\nis inspired by EAM to perform frontier exploration decision-making, avoiding\nthe circuitous trajectories in long-range scenarios to improve path efficiency.\nExperimental results demonstrate that the EAM module achieves 64.5\\% scene\nmapping accuracy on MP3D dataset, while the navigation task attains SPLs of\n28.4\\% and 26.3\\% on HM3D and MP3D benchmarks respectively - representing\nabsolute improvements of 21.4\\% and 46.0\\% over baseline methods.", "comment": "16 pages, 11 figures", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05896v1", "AI": {"title_translation": "结合结构语义推理的多级地图和多模态决策LLM的物体导航", "tldr": "本文提出了一种基于环境属性图（EAM）和多模态LLM分层推理模块（MHR）的主动物体导航框架，旨在解决零样本物体导航中高维隐式场景信息和长距离目标搜索导致的性能下降问题，实验结果显示该框架显著提高了导航的成功率和效率。", "motivation": "零样本物体导航（ZSON）在未知开放环境中，当目标语义新颖时，由于忽略高维隐式场景信息和长距离目标搜索任务，性能往往显著下降。", "method": "本文提出了一种主动物体导航框架，该框架包含环境属性图（EAM）和MLLM分层推理模块（MHR）。EAM通过SBERT推理已观察环境，并利用Diffusion预测未观察环境，构建时利用了物体-房间关联和区域相邻性等人类空间规律。MHR受EAM启发，执行前沿探索决策，以避免长距离场景中的迂回轨迹，从而提高路径效率。", "result": "EAM模块在MP3D数据集上实现了64.5%的场景映射精度。导航任务在HM3D基准上达到了28.4%的SPL，在MP3D基准上达到了26.3%的SPL。与基线方法相比，这些结果分别代表了21.4%和46.0%的绝对改进。", "conclusion": "该框架通过结合结构语义推理的多级地图和多模态决策LLM，有效解决了零样本物体导航的挑战，显著提升了导航成功率和效率。", "translation": "零样本物体导航（ZSON）在未知开放环境中，当目标语义新颖时，由于忽略高维隐式场景信息和长距离目标搜索任务，性能往往显著下降。为了解决这个问题，我们提出了一种主动物体导航框架，该框架结合了环境属性图（EAM）和MLLM分层推理模块（MHR），以提高其成功率和效率。EAM通过SBERT推理已观察到的环境并利用Diffusion预测未观察到的环境来构建，其中利用了物体-房间关联和区域相邻性等人类空间规律。MHR受EAM启发，执行前沿探索决策，避免长距离场景中的迂回轨迹，从而提高路径效率。实验结果表明，EAM模块在MP3D数据集上实现了64.5%的场景映射精度，而导航任务在HM3D和MP3D基准上分别达到了28.4%和26.3%的SPL——这代表着比基线方法分别提高了21.4%和46.0%的绝对改进。", "summary": "本文提出了一种针对零样本物体导航（ZSON）的主动导航框架，旨在解决现有方法在未知环境中因忽略高维隐式场景信息和长距离搜索导致的性能下降问题。该框架包含环境属性图（EAM）和多模态LLM分层推理模块（MHR）。EAM利用SBERT和Diffusion构建，整合了人类空间规律；MHR则基于EAM进行前沿探索决策，优化路径效率。实验证明，该框架在场景映射精度和导航任务成功率上均取得显著提升，优于现有基线方法。", "keywords": "物体导航, 零样本导航, 多级地图, 结构语义推理, 多模态LLM", "comments": "该论文通过引入结构语义推理的多级地图和多模态LLM决策，有效地解决了零样本物体导航中的关键挑战，特别是长距离目标搜索和对隐式场景信息的利用。EAM和MHR模块的设计具有创新性，能够显著提升导航效率和成功率。"}}
{"id": "2506.05372", "title": "DVD: A Comprehensive Dataset for Advancing Violence Detection in Real-World Scenarios", "authors": ["Dimitrios Kollias", "Damith C. Senadeera", "Jianian Zheng", "Kaushal K. K. Yadav", "Greg Slabaugh", "Muhammad Awais", "Xiaoyun Yang"], "summary": "Violence Detection (VD) has become an increasingly vital area of research.\nExisting automated VD efforts are hindered by the limited availability of\ndiverse, well-annotated databases. Existing databases suffer from coarse\nvideo-level annotations, limited scale and diversity, and lack of metadata,\nrestricting the generalization of models. To address these challenges, we\nintroduce DVD, a large-scale (500 videos, 2.7M frames), frame-level annotated\nVD database with diverse environments, varying lighting conditions, multiple\ncamera sources, complex social interactions, and rich metadata. DVD is designed\nto capture the complexities of real-world violent events.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05372v1", "AI": {"title_translation": "DVD：一个用于推进真实世界场景暴力检测的综合数据集", "tldr": "引入了一个名为DVD的大型、帧级标注数据集，以解决现有暴力检测数据集中存在的局限性，从而更好地捕捉真实世界暴力事件的复杂性。", "motivation": "现有自动化暴力检测（VD）工作受到多样化、标注良好的数据库可用性有限的阻碍。现有数据库存在视频级标注粗糙、规模和多样性有限以及缺乏元数据等问题，这些都限制了模型的泛化能力。", "method": "为解决现有数据集的挑战，研究人员引入了一个名为DVD的大型（500个视频，270万帧）、帧级标注的暴力检测数据库。该数据库包含多样化的环境、不同的光照条件、多个摄像机来源、复杂的社会互动以及丰富的元数据。", "result": "DVD数据集是一个大规模（500个视频，270万帧）、帧级标注的暴力检测数据库，具有多样化的环境、不同的光照条件、多个摄像机来源、复杂的社会互动和丰富的元数据。它旨在捕捉真实世界暴力事件的复杂性。", "conclusion": "DVD数据集通过提供大规模、帧级标注和多样化的数据，成功解决了现有暴力检测数据集中存在的局限性，从而能够更好地捕捉真实世界暴力事件的复杂性。", "translation": "暴力检测（VD）已成为一个日益重要的研究领域。现有的自动化暴力检测工作受到多样化、标注良好的数据库可用性有限的阻碍。现有数据库存在视频级标注粗糙、规模和多样性有限以及缺乏元数据等问题，这些都限制了模型的泛化能力。为了解决这些挑战，我们引入了DVD，一个大型（500个视频，270万帧）、帧级标注的暴力检测数据库，它包含多样化的环境、不同的光照条件、多个摄像机来源、复杂的社会互动和丰富的元数据。DVD旨在捕捉真实世界暴力事件的复杂性。", "summary": "本论文介绍了DVD数据集，这是一个大规模、帧级标注的暴力检测数据库，旨在解决现有暴力检测数据集中普遍存在的局限性，如粗糙标注、规模和多样性不足以及缺乏元数据。DVD数据集包含500个视频和270万帧，涵盖多样环境、不同光照、多摄像机源和复杂社会互动，并提供丰富的元数据，以更好地捕捉真实世界暴力事件的复杂性，从而推进暴力检测领域的研究。", "keywords": "暴力检测, 数据集, 帧级标注, 真实世界场景, 视频分析", "comments": "该论文的创新之处在于其提出了一个大规模、帧级标注且包含丰富元数据的暴力检测数据集，这对于解决现有数据集的局限性至关重要。其重要性在于，通过提供更接近真实世界复杂性的数据，有望显著提升暴力检测模型的泛化能力和性能。"}}
{"id": "2506.05990", "title": "Leveraging Generative AI for Enhancing Automated Assessment in Programming Education Contests", "authors": ["Stefan Dascalescu", "Adrian Marius Dumitran", "Mihai Alexandru Vasiluta"], "summary": "Competitive programming contests play a crucial role in cultivating\ncomputational thinking and algorithmic skills among learners. However,\ngenerating comprehensive test cases to effectively assess programming solutions\nremains resource-intensive and challenging for educators. This paper introduces\nan innovative NLP-driven method leveraging generative AI (large language\nmodels) to automate the creation of high-quality test cases for competitive\nprogramming assessments. We extensively evaluated our approach on diverse\ndatasets, including 25 years of Romanian Informatics Olympiad (OJI) data for\n5th graders, recent competitions hosted on the Kilonova.ro platform, and the\nInternational Informatics Olympiad in Teams (IIOT). Our results demonstrate\nthat AI-generated test cases substantially enhanced assessments, notably\nidentifying previously undetected errors in 67% of the OJI 5th grade\nprogramming problems. These improvements underscore the complementary\neducational value of our technique in formative assessment contexts. By openly\nsharing our prompts, translated datasets, and methodologies, we offer practical\nNLP-based tools that educators and contest organizers can readily integrate to\nenhance assessment quality, reduce workload, and deepen insights into learner\nperformance.", "comment": "11 pages, 2 chart pies, 1 figure Pre-print version Accepted at BEA\n  2025", "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.05990v1", "AI": {"title_translation": "利用生成式AI提升编程教育竞赛中的自动化评估", "tldr": "本文提出了一种利用生成式AI（大型语言模型）自动化生成编程竞赛高质量测试用例的方法，并在多个数据集上进行了评估，结果显示显著提升了评估质量，能够发现传统方法未能发现的错误。", "motivation": "在编程教育竞赛中，生成全面的测试用例来有效评估编程解决方案对教育工作者来说资源密集且具有挑战性。", "method": "本文引入了一种创新的、由自然语言处理驱动的方法，利用生成式AI（大型语言模型）来自动化创建用于编程竞赛评估的高质量测试用例。", "result": "AI生成的测试用例显著增强了评估效果，特别是在67%的OJI五年级编程问题中发现了以前未检测到的错误。", "conclusion": "该技术在形成性评估背景下具有补充性的教育价值，并提供了教育工作者和竞赛组织者可以轻松整合的实用NLP工具，以提高评估质量、减少工作量并加深对学习者表现的见解。", "translation": "编程竞赛在培养学习者的计算思维和算法技能方面发挥着关键作用。然而，生成全面的测试用例以有效评估编程解决方案对教育工作者来说仍然是资源密集且具有挑战性的。本文介绍了一种创新的、由自然语言处理驱动的方法，利用生成式AI（大型语言模型）来自动化创建用于编程竞赛评估的高质量测试用例。我们对该方法在多样化数据集上进行了广泛评估，包括罗马尼亚信息学奥林匹克（OJI）五年级学生25年的数据、Kilonova.ro平台上举办的近期比赛以及国际团队信息学奥林匹克（IIOT）。我们的结果表明，AI生成的测试用例显著增强了评估效果，特别是在67%的OJI五年级编程问题中发现了以前未检测到的错误。这些改进强调了我们技术在形成性评估背景下的补充教育价值。通过公开分享我们的提示、翻译后的数据集和方法，我们提供了实用的基于自然语言处理的工具，教育工作者和竞赛组织者可以轻松整合这些工具，以提高评估质量、减少工作量并加深对学习者表现的见解。", "summary": "本文提出了一种利用生成式AI（大型语言模型）自动化生成编程竞赛测试用例的创新方法，旨在解决传统测试用例生成过程中的资源密集和挑战性问题。该方法通过NLP驱动，在罗马尼亚信息学奥林匹克等多个数据集上进行了广泛评估，结果表明AI生成的测试用例显著提升了评估质量，并能发现传统方法未能检测到的错误。研究强调了该技术在形成性评估中的教育价值，并提供了可供教育工作者和竞赛组织者使用的实用工具。", "keywords": "生成式AI, 编程教育, 自动化评估, 测试用例生成, 大型语言模型", "comments": "该论文的创新之处在于将生成式AI应用于编程教育的自动化评估，特别是通过自动化测试用例的生成，显著提高了评估的效率和准确性。其重要性体现在能够减轻教育工作者的负担，同时帮助识别传统方法难以发现的编程错误，从而深化对学习者表现的理解。公开分享数据集和方法也促进了该领域的研究和应用。"}}
{"id": "2506.05582", "title": "Combating Misinformation in the Arab World: Challenges & Opportunities", "authors": ["Azza Abouzied", "Firoj Alam", "Raian Ali", "Paolo Papotti"], "summary": "Misinformation and disinformation pose significant risks globally, with the\nArab region facing unique vulnerabilities due to geopolitical instabilities,\nlinguistic diversity, and cultural nuances. We explore these challenges through\nthe key facets of combating misinformation: detection, tracking, mitigation and\ncommunity-engagement. We shed light on how connecting with grass-roots\nfact-checking organizations, understanding cultural norms, promoting social\ncorrection, and creating strong collaborative information networks can create\nopportunities for a more resilient information ecosystem in the Arab world.", "comment": "disinformation, misinformation, factuality, harmfulness, fake news", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05582v1", "AI": {"title_translation": "阿拉伯世界打击虚假信息：挑战与机遇", "tldr": "本文探讨了阿拉伯世界在打击虚假信息方面的独特挑战，并提出了通过检测、追踪、缓解和社区参与来创造机会，以建立更具弹性的信息生态系统。", "motivation": "虚假信息和不实信息在全球范围内构成重大风险，阿拉伯地区因地缘政治不稳定、语言多样性和文化细微差别而面临独特的脆弱性。", "method": "本文通过打击虚假信息的关键方面（检测、追踪、缓解和社区参与）来探讨这些挑战。研究阐明了如何通过与基层事实核查组织建立联系、理解文化规范、促进社会纠正以及建立强大的协作信息网络来创造机会。", "result": "通过与基层事实核查组织建立联系、理解文化规范、促进社会纠正以及建立强大的协作信息网络，可以在阿拉伯世界建立更具弹性的信息生态系统。", "conclusion": "通过多方面的方法，包括社区参与和协作，可以应对阿拉伯世界的虚假信息挑战，并建立一个更具弹性的信息生态系统。", "translation": "标题：阿拉伯世界打击虚假信息：挑战与机遇\n摘要：虚假信息和不实信息在全球范围内构成重大风险，阿拉伯地区因地缘政治不稳定、语言多样性和文化细微差别而面临独特的脆弱性。我们通过打击虚假信息的关键方面：检测、追踪、缓解和社区参与来探讨这些挑战。我们阐明了如何通过与基层事实核查组织建立联系、理解文化规范、促进社会纠正以及建立强大的协作信息网络，为阿拉伯世界建立更具弹性的信息生态系统创造机会。", "summary": "本文探讨了阿拉伯世界在打击虚假信息方面面临的挑战，这些挑战源于地缘政治、语言和文化因素。文章从检测、追踪、缓解和社区参与四个关键方面分析了这些问题。研究强调，通过与基层事实核查组织合作、理解文化、促进社会纠正以及建立协作网络，可以为该地区创建一个更具弹性的信息生态系统。", "keywords": "虚假信息, 阿拉伯世界, 事实核查, 社区参与, 信息生态系统", "comments": "这篇论文的重要性在于它关注了阿拉伯世界这一特殊且复杂的区域，识别出地缘政治、语言和文化等独特挑战。其创新之处在于提出了多方面的应对策略，强调了社区参与和协作网络的重要性，为构建更具弹性的信息生态系统提供了实用方向。"}}
{"id": "2506.05616", "title": "Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists", "authors": ["Lianhao Zhou", "Hongyi Ling", "Keqiang Yan", "Kaiji Zhao", "Xiaoning Qian", "Raymundo Arróyave", "Xiaofeng Qian", "Shuiwang Ji"], "summary": "We aim at designing language agents with greater autonomy for crystal\nmaterials discovery. While most of existing studies restrict the agents to\nperform specific tasks within predefined workflows, we aim to automate workflow\nplanning given high-level goals and scientist intuition. To this end, we\npropose Materials Agent unifying Planning, Physics, and Scientists, known as\nMAPPS. MAPPS consists of a Workflow Planner, a Tool Code Generator, and a\nScientific Mediator. The Workflow Planner uses large language models (LLMs) to\ngenerate structured and multi-step workflows. The Tool Code Generator\nsynthesizes executable Python code for various tasks, including invoking a\nforce field foundation model that encodes physics. The Scientific Mediator\ncoordinates communications, facilitates scientist feedback, and ensures\nrobustness through error reflection and recovery. By unifying planning,\nphysics, and scientists, MAPPS enables flexible and reliable materials\ndiscovery with greater autonomy, achieving a five-fold improvement in\nstability, uniqueness, and novelty rates compared with prior generative models\nwhen evaluated on the MP-20 data. We provide extensive experiments across\ndiverse tasks to show that MAPPS is a promising framework for autonomous\nmaterials discovery.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05616v1", "AI": {"title_translation": "迈向材料发现智能体的更高自主性：统一规划、物理和科学家", "tldr": "本文提出了MAPPS，一种基于LLM的自主晶体材料发现智能体，通过统一规划、物理和科学家，显著提升了性能。", "motivation": "现有研究将智能体限制在预定义工作流中的特定任务，而本文旨在根据高级目标和科学家直觉自动化工作流规划，以实现晶体材料发现的更高自主性。", "method": "本文提出了MAPPS（Materials Agent unifying Planning, Physics, and Scientists），它包含一个工作流规划器（使用大型语言模型生成结构化多步工作流）、一个工具代码生成器（合成可执行Python代码，包括调用编码物理的力场基础模型），以及一个科学协调器（协调通信、促进科学家反馈、通过错误反思和恢复确保鲁棒性）。", "result": "MAPPS通过统一规划、物理和科学家，实现了更灵活、可靠且具有更高自主性的材料发现。在MP-20数据上评估时，与先前的生成模型相比，MAPPS在稳定性、独特性和新颖性方面实现了五倍的提升。广泛的实验表明MAPPS是自主材料发现的一个有前景的框架。", "conclusion": "MAPPS通过统一规划、物理和科学家，为自主材料发现提供了一个有前景的框架，并显著提高了性能。", "translation": "我们旨在设计具有更高自主性的语言智能体，用于晶体材料发现。尽管大多数现有研究将智能体限制在预定义工作流中的特定任务，但我们旨在根据高级目标和科学家直觉自动化工作流规划。为此，我们提出了MAPPS（Materials Agent unifying Planning, Physics, and Scientists），它统一了规划、物理和科学家。MAPPS由一个工作流规划器、一个工具代码生成器和一个科学协调器组成。工作流规划器使用大型语言模型（LLMs）生成结构化和多步工作流。工具代码生成器为各种任务合成可执行的Python代码，包括调用一个编码物理的力场基础模型。科学协调器协调通信，促进科学家反馈，并通过错误反思和恢复确保鲁棒性。通过统一规划、物理和科学家，MAPPS实现了更灵活、可靠且具有更高自主性的材料发现，在MP-20数据上评估时，与先前的生成模型相比，在稳定性、独特性和新颖性方面实现了五倍的提升。我们提供了跨越不同任务的广泛实验，以表明MAPPS是自主材料发现的一个有前景的框架。", "summary": "本文提出了一种名为MAPPS（Materials Agent unifying Planning, Physics, and Scientists）的语言智能体，旨在实现晶体材料发现的更高自主性。与现有将智能体限制在预定义工作流中的方法不同，MAPPS通过整合工作流规划器（使用大型语言模型）、工具代码生成器（合成可执行代码并调用物理模型）和科学协调器（协调沟通、处理反馈和错误恢复），实现了工作流的自动化规划。这种统一规划、物理和科学家的方法使得MAPPS能够进行灵活可靠的材料发现，并在稳定性、独特性和新颖性方面比现有模型提升了五倍。", "keywords": "材料发现, 自主智能体, 大型语言模型, 工作流规划, 晶体材料", "comments": "本文的创新之处在于将规划、物理知识和人类科学家反馈统一到一个自主智能体中，以实现材料发现的自动化，这超越了传统预定义工作流的限制。LLM在动态工作流生成中的应用以及科学协调器在人机交互和鲁棒性保障方面的作用是其核心优势。所宣称的性能提升（五倍）具有显著意义。"}}
{"id": "2506.06256", "title": "Quadratic Extended and Unscented Kalman Filter Updates", "authors": ["Simone Servadio", "Chiran Cherian"], "summary": "Common filters are usually based on the linear approximation of the optimal\nminimum mean square error estimator. The Extended and Unscented Kalman Filters\nhandle nonlinearity through linearization and unscented transformation,\nrespectively, but remain linear estimators, meaning that the state estimate is\na linear function of the measurement. This paper proposes a quadratic\napproximation of the optimal estimator, creating the Quadratic Extended and\nQuadratic Unscented Kalman Filter. These retain the structure of their linear\ncounterpart, but include information from the measurement square to obtain a\nmore accurate estimate. Numerical results show the benefits in accuracy of the\nnew technique, which can be generalized to upgrade other linear estimators to\ntheir quadratic versions.", "comment": "8 pages, 5 figures, 2025 INTERNATIONAL CONFERENCE ON MULTISENSOR\n  FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS", "cate": "cs.IT", "url": "http://arxiv.org/pdf/2506.06256v1", "AI": {"title_translation": "二次扩展和无迹卡尔曼滤波更新", "tldr": "本文提出了二次扩展和二次无迹卡尔曼滤波器，通过包含测量平方信息来提高非线性估计的精度。", "motivation": "常见的卡尔曼滤波器（如扩展和无迹卡尔曼滤波器）虽然处理非线性，但本质上仍是线性估计器，即状态估计是测量的线性函数。这限制了它们在非线性系统中的精度。", "method": "本文提出了一种最优估计器的二次近似方法，从而创建了二次扩展卡尔曼滤波器（QEKF）和二次无迹卡尔曼滤波器（QUKF）。这些滤波器保留了其线性对应物的结构，但通过包含测量平方的信息来获得更准确的估计。", "result": "数值结果表明，新方法在精度方面具有优势。", "conclusion": "新提出的二次扩展和二次无迹卡尔曼滤波器通过包含测量平方信息，能够提供比现有线性卡尔曼滤波器更准确的估计，并且该技术可以推广到其他线性估计器。", "translation": "常见滤波器通常基于最优最小均方误差估计器的线性近似。扩展卡尔曼滤波器和无迹卡尔曼滤波器分别通过线性化和无迹变换处理非线性，但它们仍是线性估计器，这意味着状态估计是测量的线性函数。本文提出了一种最优估计器的二次近似，创建了二次扩展卡尔曼滤波器和二次无迹卡尔曼滤波器。这些滤波器保留了其线性对应物的结构，但包含了来自测量平方的信息，以获得更准确的估计。数值结果显示了这项新技术在精度方面的优势，并且可以推广以将其他线性估计器升级到其二次版本。", "summary": "本文针对扩展卡尔曼滤波器和无迹卡尔曼滤波器在处理非线性时仍保持线性估计器本质的问题，提出了一种对最优估计器的二次近似方法。由此引入的二次扩展卡尔曼滤波器和二次无迹卡尔曼滤波器，在保留原有结构的同时，通过纳入测量平方信息，显著提高了估计精度。数值结果验证了其有效性，并指出该方法可推广至其他线性估计器的二次升级。", "keywords": "二次卡尔曼滤波器, 扩展卡尔曼滤波器, 无迹卡尔曼滤波器, 非线性估计, 状态估计", "comments": "这篇论文通过引入二次近似来改进传统的卡尔曼滤波器，解决了其在非线性系统中作为线性估计器所固有的精度限制。这种方法创新性地利用了测量平方信息，为非线性状态估计提供了更精确的解决方案。其潜在影响在于，这种二次升级的思路可能适用于更广泛的线性估计器，从而在多个领域提升估计性能。"}}
{"id": "2506.05438", "title": "An Unsupervised Framework for Dynamic Health Indicator Construction and Its Application in Rolling Bearing Prognostics", "authors": ["Tongda Sun", "Chen Yin", "Huailiang Zheng", "Yining Dong"], "summary": "Health indicator (HI) plays a key role in degradation assessment and\nprognostics of rolling bearings. Although various HI construction methods have\nbeen investigated, most of them rely on expert knowledge for feature extraction\nand overlook capturing dynamic information hidden in sequential degradation\nprocesses, which limits the ability of the constructed HI for degradation trend\nrepresentation and prognostics. To address these concerns, a novel dynamic HI\nthat considers HI-level temporal dependence is constructed through an\nunsupervised framework. Specifically, a degradation feature learning module\ncomposed of a skip-connection-based autoencoder first maps raw signals to a\nrepresentative degradation feature space (DFS) to automatically extract\nessential degradation features without the need for expert knowledge.\nSubsequently, in this DFS, a new HI-generating module embedded with an inner\nHI-prediction block is proposed for dynamic HI construction, where the temporal\ndependence between past and current HI states is guaranteed and modeled\nexplicitly. On this basis, the dynamic HI captures the inherent dynamic\ncontents of the degradation process, ensuring its effectiveness for degradation\ntendency modeling and future degradation prognostics. The experiment results on\ntwo bearing lifecycle datasets demonstrate that the proposed HI construction\nmethod outperforms comparison methods, and the constructed dynamic HI is\nsuperior for prognostic tasks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05438v1", "AI": {"title_translation": "滚动轴承动态健康指标构建的无监督框架及其在预测中的应用", "tldr": "提出一种无监督框架，用于构建动态健康指标，以提高滚动轴承的退化评估和预测能力。", "motivation": "现有的健康指标构建方法大多依赖专家知识进行特征提取，并且忽略了捕获序列退化过程中隐藏的动态信息，这限制了所构建健康指标在退化趋势表示和预测方面的能力。", "method": "提出一种无监督框架来构建动态健康指标，该框架考虑了健康指标级别的时间依赖性。具体而言，首先通过一个由跳跃连接自编码器组成的退化特征学习模块，将原始信号映射到代表性退化特征空间（DFS），以自动提取必要的退化特征，无需专家知识。随后，在该DFS中，提出一个新的嵌入内部健康指标预测模块的健康指标生成模块，用于动态健康指标的构建，其中保证并明确建模了过去和当前健康指标状态之间的时间依赖性。", "result": "在两个轴承生命周期数据集上的实验结果表明，所提出的健康指标构建方法优于对比方法，并且所构建的动态健康指标在预测任务中表现更优。", "conclusion": "所构建的动态健康指标能够捕捉退化过程的内在动态内容，确保其对退化趋势建模和未来退化预测的有效性，并在实验中表现出优越性。", "translation": "健康指标（HI）在滚动轴承的退化评估和预测中扮演着关键角色。尽管已经研究了各种HI构建方法，但大多数方法依赖专家知识进行特征提取，并且忽略了捕获序列退化过程中隐藏的动态信息，这限制了所构建HI在退化趋势表示和预测方面的能力。为了解决这些问题，本文通过一个无监督框架构建了一种考虑HI级别时间依赖性的新型动态HI。具体来说，一个由跳跃连接自编码器组成的退化特征学习模块首先将原始信号映射到代表性退化特征空间（DFS），以自动提取必要的退化特征，无需专家知识。随后，在该DFS中，提出一个新的嵌入内部HI预测模块的HI生成模块，用于动态HI的构建，其中保证并明确建模了过去和当前HI状态之间的时间依赖性。在此基础上，动态HI捕获了退化过程固有的动态内容，确保其在退化趋势建模和未来退化预测中的有效性。在两个轴承生命周期数据集上的实验结果表明，所提出的HI构建方法优于对比方法，并且所构建的动态HI在预测任务中表现更优。", "summary": "本文提出一个无监督框架，用于构建动态健康指标（HI），以克服传统方法对专家知识的依赖和对退化过程动态信息捕获不足的问题。该框架包括一个基于跳跃连接自编码器的退化特征学习模块，用于自动提取特征，以及一个嵌入内部HI预测模块的HI生成模块，用于明确建模HI状态间的时间依赖性。实验结果表明，所构建的动态HI在滚动轴承的退化评估和预测任务中表现出优越性。", "keywords": "健康指标, 无监督框架, 动态健康指标, 滚动轴承, 预测", "comments": "本文的创新点在于提出了一个完全无监督的框架来构建动态健康指标，成功解决了传统方法对专家知识的依赖问题。通过自编码器自动提取特征和显式建模健康指标间的时间依赖性，显著提高了退化趋势表示和预测的准确性，对于工业设备健康管理具有重要的实际应用价值。"}}
{"id": "2506.06122", "title": "Reinforcement Learning Optimization for Large-Scale Learning: An Efficient and User-Friendly Scaling Library", "authors": ["Weixun Wang", "Shaopan Xiong", "Gengru Chen", "Wei Gao", "Sheng Guo", "Yancheng He", "Ju Huang", "Jiaheng Liu", "Zhendong Li", "Xiaoyang Li", "Zichen Liu", "Haizhou Zhao", "Dakai An", "Lunxi Cao", "Qiyang Cao", "Wanxi Deng", "Feilei Du", "Yiliang Gu", "Jiahe Li", "Xiang Li", "Mingjie Liu", "Yijia Luo", "Zihe Liu", "Yadao Wang", "Pei Wang", "Tianyuan Wu", "Yanan Wu", "Yuheng Zhao", "Shuaibing Zhao", "Jin Yang", "Siran Yang", "Yingshui Tan", "Huimin Yi", "Yuchi Xu", "Yujin Yuan", "Xingyao Zhang", "Lin Qu", "Wenbo Su", "Wei Wang", "Jiamang Wang", "Bo Zheng"], "summary": "We introduce ROLL, an efficient, scalable, and user-friendly library designed\nfor Reinforcement Learning Optimization for Large-scale Learning. ROLL caters\nto three primary user groups: tech pioneers aiming for cost-effective,\nfault-tolerant large-scale training, developers requiring flexible control over\ntraining workflows, and researchers seeking agile experimentation. ROLL is\nbuilt upon several key modules to serve these user groups effectively. First, a\nsingle-controller architecture combined with an abstraction of the parallel\nworker simplifies the development of the training pipeline. Second, the\nparallel strategy and data transfer modules enable efficient and scalable\ntraining. Third, the rollout scheduler offers fine-grained management of each\nsample's lifecycle during the rollout stage. Fourth, the environment worker and\nreward worker support rapid and flexible experimentation with agentic RL\nalgorithms and reward designs. Finally, AutoDeviceMapping allows users to\nassign resources to different models flexibly across various stages.", "comment": "16 pages", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06122v1", "AI": {"title_translation": "大规模学习的强化学习优化：一个高效且用户友好的扩展库", "tldr": "ROLL是一个为大规模强化学习优化设计的高效、用户友好且可扩展的库。", "motivation": "为满足技术先驱对经济高效、容错大规模训练的需求，开发者对训练工作流灵活控制的需求，以及研究人员对敏捷实验的需求，本文引入了ROLL库。", "method": "ROLL库通过以下关键模块实现其目标：结合并行worker抽象的单控制器架构；高效可扩展的并行策略和数据传输模块；用于细粒度样本生命周期管理的rollout调度器；支持快速灵活实验的环境worker和奖励worker；以及允许灵活分配资源的AutoDeviceMapping。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "我们引入了ROLL，一个为大规模学习的强化学习优化而设计的高效、可扩展且用户友好的库。ROLL服务于三个主要用户群体：旨在实现成本效益高、容错大规模训练的技术先驱；需要灵活控制训练工作流的开发者；以及寻求敏捷实验的研究人员。ROLL建立在几个关键模块之上，以有效地服务这些用户群体。首先，结合并行worker抽象的单控制器架构简化了训练管道的开发。其次，并行策略和数据传输模块实现了高效和可扩展的训练。第三，rollout调度器在rollout阶段提供了对每个样本生命周期的细粒度管理。第四，环境worker和奖励worker支持对智能体RL算法和奖励设计的快速灵活实验。最后，AutoDeviceMapping允许用户在不同阶段灵活地为不同模型分配资源。", "summary": "ROLL是一个为大规模强化学习优化而设计的库，它通过结合并行worker抽象的单控制器架构、高效的并行策略和数据传输模块、细粒度rollout调度器、灵活的环境和奖励worker以及AutoDeviceMapping等关键模块，为技术先驱、开发者和研究人员提供高效、可扩展且用户友好的大规模训练解决方案。", "keywords": "强化学习, 大规模学习, 优化, 库, 可扩展性", "comments": "该论文介绍了一个名为ROLL的库，旨在解决大规模强化学习中的优化挑战。其创新之处在于提供了一个高效、可扩展且用户友好的平台，通过模块化设计满足了技术先驱、开发者和研究人员的不同需求。特别是其单控制器架构、并行策略、rollout调度器以及灵活的资源分配能力，有望简化大规模RL训练的复杂性并提高实验效率。然而，摘要中未提供具体的实验结果或性能数据，这使得对其实际效果的全面评估存在局限性。"}}
{"id": "2506.06162", "title": "Recommender systems, stigmergy, and the tyranny of popularity", "authors": ["Zackary Okun Dunivin", "Paul E. Smaldino"], "summary": "Scientific recommender systems, such as Google Scholar and Web of Science,\nare essential tools for discovery. Search algorithms that power work through\nstigmergy, a collective intelligence mechanism that surfaces useful paths\nthrough repeated engagement. While generally effective, this\n``rich-get-richer'' dynamic results in a small number of high-profile papers\nthat dominate visibility. This essay argues argue that these algorithm\nover-reliance on popularity fosters intellectual homogeneity and exacerbates\nstructural inequities, stifling innovative and diverse perspectives critical\nfor scientific progress. We propose an overhaul of search platforms to\nincorporate user-specific calibration, allowing researchers to manually adjust\nthe weights of factors like popularity, recency, and relevance. We also advise\nplatform developers on how word embeddings and LLMs could be implemented in\nways that increase user autonomy. While our suggestions are particularly\npertinent to aligning recommender systems with scientific values, these ideas\nare broadly applicable to information access systems in general. Designing\nplatforms that increase user autonomy is an important step toward more robust\nand dynamic information", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.06162v1", "AI": {"title_translation": "推荐系统、信息素协同与流行度的暴政", "tldr": "科学推荐系统过度依赖流行度导致同质化和不平等，本文提出通过用户自定义权重和利用LLMs等技术增加用户自主性来改进推荐系统。", "motivation": "科学推荐系统（如Google Scholar和Web of Science）过度依赖流行度（信息素协同机制），导致少数高知名度论文占据主导，抑制了创新和多样性，并加剧了结构性不平等，这阻碍了科学进步。", "method": "本文提出改革搜索平台，纳入用户特定的校准，允许研究人员手动调整流行度、新近度、相关性等因素的权重。此外，建议平台开发者以增加用户自主性的方式实现词嵌入和大型语言模型（LLMs）。", "result": "本文提出了改进推荐系统以增加用户自主性的方法，以期实现更健壮和动态的信息访问系统。", "conclusion": "设计增加用户自主性的平台是迈向更健壮和动态信息访问系统的重要一步，这对于科学推荐系统和一般信息访问系统都具有广泛适用性。", "translation": "科学推荐系统，如Google Scholar和Web of Science，是发现必不可少的工具。驱动这些系统工作的搜索算法通过信息素协同（stigmergy）发挥作用，这是一种集体智能机制，通过重复参与来浮现出有用的路径。虽然通常有效，但这种“富者愈富”的动态导致少数高知名度论文占据主导地位。本文认为，这些算法过度依赖流行度会助长知识同质化并加剧结构性不平等，从而扼杀对科学进步至关重要的创新和多样化视角。我们建议对搜索平台进行全面改革，以纳入用户特定的校准，允许研究人员手动调整流行度、新近度、相关性等因素的权重。我们还建议平台开发者如何以增加用户自主性的方式实现词嵌入和大型语言模型（LLMs）。虽然我们的建议对于使推荐系统与科学价值观保持一致尤其相关，但这些思想也广泛适用于一般信息访问系统。设计增加用户自主性的平台是迈向更健壮和动态信息访问系统的重要一步。", "summary": "本文探讨了科学推荐系统（如Google Scholar）中普遍存在的“信息素协同”机制，指出其过度依赖流行度导致了学术同质化和结构性不平等，从而阻碍了科学进步。为解决此问题，作者提出改革搜索平台，允许用户自定义调整流行度、新近度、相关性等因素的权重，并建议利用词嵌入和大型语言模型（LLMs）来增强用户自主性。这些建议旨在使信息访问系统更加健壮和动态，并与科学价值观保持一致。", "keywords": "推荐系统, 流行度, 信息素协同, 用户自主性, 科学发现", "comments": "本文批判性地审视了当前科学推荐系统中的流行度偏见问题，并提出了用户自主性校准和整合先进AI技术的创新性解决方案。其重要性在于强调了信息系统设计中用户控制权的重要性，对于促进学术多样性和创新具有积极意义。"}}
{"id": "2506.05408", "title": "Differentially Private Federated $k$-Means Clustering with Server-Side Data", "authors": ["Jonathan Scott", "Christoph H. Lampert", "David Saulpic"], "summary": "Clustering is a cornerstone of data analysis that is particularly suited to\nidentifying coherent subgroups or substructures in unlabeled data, as are\ngenerated continuously in large amounts these days. However, in many cases\ntraditional clustering methods are not applicable, because data are\nincreasingly being produced and stored in a distributed way, e.g. on edge\ndevices, and privacy concerns prevent it from being transferred to a central\nserver. To address this challenge, we present \\acronym, a new algorithm for\n$k$-means clustering that is fully-federated as well as differentially private.\nOur approach leverages (potentially small and out-of-distribution) server-side\ndata to overcome the primary challenge of differentially private clustering\nmethods: the need for a good initialization. Combining our initialization with\na simple federated DP-Lloyds algorithm we obtain an algorithm that achieves\nexcellent results on synthetic and real-world benchmark tasks. We also provide\na theoretical analysis of our method that provides bounds on the convergence\nspeed and cluster identification success.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05408v1", "AI": {"title_translation": "差分隐私联邦 $k$-均值聚类与服务器端数据", "tldr": "提出了一种新的差分隐私联邦 $k$-均值聚类算法（\u0007cronym），利用服务器端数据解决初始化问题，并在合成和真实数据集上表现出色。", "motivation": "传统聚类方法不适用于分布式数据和隐私问题，因为数据越来越多地在边缘设备上生成和存储，且隐私问题阻止数据传输到中央服务器。", "method": "提出了一种名为 \u0007cronym 的新算法，用于 $k$-均值聚类，该算法是完全联邦且差分隐私的。它利用（可能很小且分布外）服务器端数据来克服差分隐私聚类方法的主要挑战：对良好初始化的需求。结合这种初始化和简单的联邦 DP-Lloyds 算法。", "result": "该算法在合成和真实世界基准任务上取得了优异的结果。同时提供了该方法的理论分析，给出了收敛速度和聚类识别成功的界限。", "conclusion": "该论文成功开发了一种差分隐私联邦 $k$-均值聚类算法，有效解决了分布式数据下的隐私保护聚类挑战，并通过理论分析和实验验证了其有效性。", "translation": "聚类是数据分析的基石，特别适用于识别未标记数据中的连贯子群或子结构，这些数据目前正以巨大数量持续生成。然而，在许多情况下，传统的聚类方法不适用，因为数据越来越多地以分布式方式生成和存储，例如在边缘设备上，并且隐私问题阻止其传输到中央服务器。为了解决这一挑战，我们提出了 \u0007cronym，一种全新的 $k$-均值聚类算法，它既是完全联邦的，又是差分隐私的。我们的方法利用（可能很小且分布外）服务器端数据来克服差分隐私聚类方法的主要挑战：对良好初始化的需求。将我们的初始化与简单的联邦 DP-Lloyds 算法相结合，我们得到了一种在合成和真实世界基准任务上取得优异结果的算法。我们还提供了该方法的理论分析，给出了收敛速度和聚类识别成功的界限。", "summary": "本论文提出了一种名为 \u0007cronym 的新型差分隐私联邦 $k$-均值聚类算法，旨在解决传统聚类方法在分布式数据和隐私限制下的适用性问题。该算法创新性地利用服务器端数据来克服差分隐私聚类中初始化困难的关键挑战，并结合了简单的联邦DP-Lloyds算法。通过理论分析和在合成及真实世界任务上的实验，证明了该方法在收敛速度和聚类识别成功方面的优异表现。", "keywords": "差分隐私, 联邦学习, $k$-均值聚类, 分布式数据, 服务器端数据", "comments": "该论文的创新点在于利用服务器端数据来解决差分隐私聚类中初始化这一核心难题，这对于在保护用户隐私的同时实现分布式数据聚类具有重要意义。该方法结合了联邦学习和差分隐私，为处理敏感分布式数据提供了实用的解决方案。"}}
{"id": "2506.05997", "title": "Improving Long-Range Navigation with Spatially-Enhanced Recurrent Memory via End-to-End Reinforcement Learning", "authors": ["Fan Yang", "Per Frivik", "David Hoeller", "Chen Wang", "Cesar Cadena", "Marco Hutter"], "summary": "Recent advancements in robot navigation, especially with end-to-end learning\napproaches like reinforcement learning (RL), have shown remarkable efficiency\nand effectiveness. Yet, successful navigation still relies on two key\ncapabilities: mapping and planning, whether explicit or implicit. Classical\napproaches use explicit mapping pipelines to register ego-centric observations\ninto a coherent map frame for the planner. In contrast, end-to-end learning\nachieves this implicitly, often through recurrent neural networks (RNNs) that\nfuse current and past observations into a latent space for planning. While\narchitectures such as LSTM and GRU capture temporal dependencies, our findings\nreveal a key limitation: their inability to perform effective spatial\nmemorization. This skill is essential for transforming and integrating\nsequential observations from varying perspectives to build spatial\nrepresentations that support downstream planning. To address this, we propose\nSpatially-Enhanced Recurrent Units (SRUs), a simple yet effective modification\nto existing RNNs, designed to enhance spatial memorization capabilities. We\nintroduce an attention-based architecture with SRUs, enabling long-range\nnavigation using a single forward-facing stereo camera. Regularization\ntechniques are employed to ensure robust end-to-end recurrent training via RL.\nExperimental results show our approach improves long-range navigation by 23.5%\ncompared to existing RNNs. Furthermore, with SRU memory, our method outperforms\nthe RL baseline with explicit mapping and memory modules, achieving a 29.6%\nimprovement in diverse environments requiring long-horizon mapping and\nmemorization. Finally, we address the sim-to-real gap by leveraging large-scale\npretraining on synthetic depth data, enabling zero-shot transfer to diverse and\ncomplex real-world environments.", "comment": "21 pages", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.05997v1", "AI": {"title_translation": "通过端到端强化学习，利用空间增强循环记忆改进长距离导航", "tldr": "提出空间增强循环单元 (SRUs) 改进RNN的空间记忆能力，显著提升长距离导航性能并实现零样本真实世界迁移。", "motivation": "现有端到端学习方法（如循环神经网络RNNs）在机器人导航中存在空间记忆能力不足的局限性，而空间记忆对于将不同视角的序列观测转换为空间表示并支持后续规划至关重要。", "method": "本文提出空间增强循环单元（SRUs），这是一种对现有RNNs的简单但有效的修改，旨在增强其空间记忆能力。该方法引入了一个基于注意力的SRUs架构，并结合正则化技术进行鲁棒的端到端强化学习训练。此外，通过利用合成深度数据进行大规模预训练，以实现从模拟到真实世界的零样本迁移。", "result": "实验结果表明，该方法与现有RNNs相比，长距离导航性能提高了23.5%。此外，在需要长距离建图和记忆的复杂环境中，与带有显式建图和记忆模块的强化学习基线相比，性能提升了29.6%。通过大规模合成深度数据预训练，实现了对多样化复杂真实世界环境的零样本迁移。", "conclusion": "本文提出的空间增强循环单元（SRUs）有效解决了端到端强化学习导航中循环神经网络空间记忆不足的关键局限性，显著提升了长距离导航的性能和在复杂真实世界环境中的泛化能力。", "translation": "机器人导航领域的最新进展，特别是端到端学习方法如强化学习（RL），已展现出卓越的效率和有效性。然而，成功的导航仍然依赖于两个关键能力：建图和规划，无论是显式的还是隐式的。经典方法使用显式建图流程将以自我为中心的观测注册到连贯的地图框架中供规划器使用。相比之下，端到端学习通过循环神经网络（RNNs）将当前和过去的观测融合到潜在空间中进行规划，从而隐式地实现这一点。尽管LSTM和GRU等架构能够捕获时间依赖性，但我们的发现揭示了一个关键局限性：它们无法进行有效的空间记忆。这种技能对于转换和整合来自不同视角的序列观测，以构建支持后续规划的空间表示至关重要。为了解决这个问题，我们提出了空间增强循环单元（SRUs），这是对现有RNN的一种简单而有效的修改，旨在增强空间记忆能力。我们引入了一种基于注意力的SRUs架构，使得使用单个前向立体摄像头进行长距离导航成为可能。采用正则化技术以确保通过RL进行鲁棒的端到端循环训练。实验结果表明，与现有RNNs相比，我们的方法将长距离导航性能提高了23.5%。此外，通过SRU记忆，我们的方法在需要长距离建图和记忆的各种环境中，其性能优于带有显式建图和记忆模块的RL基线，实现了29.6%的提升。最后，我们通过利用合成深度数据进行大规模预训练来解决模拟到真实世界的差距，从而实现了对多样化复杂真实世界环境的零样本迁移。", "summary": "本文提出空间增强循环单元（SRUs），以解决现有循环神经网络在端到端强化学习导航中空间记忆能力不足的问题。SRUs通过注意力机制增强RNN的空间记忆，显著提升了长距离导航性能。实验结果显示，SRUs在长距离导航方面比现有RNNs提升23.5%，比带有显式建图的RL基线提升29.6%，并通过合成数据预训练实现了零样本真实世界迁移。", "keywords": "长距离导航, 强化学习, 循环神经网络, 空间记忆, 模拟到真实迁移", "comments": "本文通过引入空间增强循环单元（SRUs），巧妙地弥补了现有RNNs在机器人长距离导航中空间记忆能力的不足，这对于提升端到端强化学习的鲁棒性和性能具有重要意义。特别是结合注意力机制和模拟到真实世界的零样本迁移能力，使其在实际应用中具有很大的潜力。"}}
{"id": "2506.05375", "title": "State Estimation and Control of Dynamic Systems from High-Dimensional Image Data", "authors": ["Ashik E Rasul", "Hyung-Jin Yoon"], "summary": "Accurate state estimation is critical for optimal policy design in dynamic\nsystems. However, obtaining true system states is often impractical or\ninfeasible, complicating the policy learning process. This paper introduces a\nnovel neural architecture that integrates spatial feature extraction using\nconvolutional neural networks (CNNs) and temporal modeling through gated\nrecurrent units (GRUs), enabling effective state representation from sequences\nof images and corresponding actions. These learned state representations are\nused to train a reinforcement learning agent with a Deep Q-Network (DQN).\nExperimental results demonstrate that our proposed approach enables real-time,\naccurate estimation and control without direct access to ground-truth states.\nAdditionally, we provide a quantitative evaluation methodology for assessing\nthe accuracy of the learned states, highlighting their impact on policy\nperformance and control stability.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05375v1", "AI": {"title_translation": "动态系统高维图像数据的状态估计与控制", "tldr": "本文提出了一种结合CNN和GRU的神经网络架构，用于从高维图像数据中进行动态系统的状态估计和控制，实现了实时、准确的无地真状态访问的控制。", "motivation": "准确的状态估计对于动态系统中的最优策略设计至关重要，但获取真实系统状态通常不切实际或不可行，这使得策略学习过程复杂化。", "method": "本文介绍了一种新颖的神经网络架构，该架构集成了使用卷积神经网络（CNNs）进行空间特征提取和通过门控循环单元（GRUs）进行时间建模，从而能够从图像序列和相应动作中有效地表示状态。这些学习到的状态表示用于使用深度Q网络（DQN）训练强化学习智能体。", "result": "实验结果表明，所提出的方法无需直接访问地面真实状态即可实现实时、准确的估计和控制。此外，论文提供了一种量化评估方法来评估学习状态的准确性，并强调了它们对策略性能和控制稳定性的影响。", "conclusion": "该论文提出了一种有效的神经网络架构，能够从高维图像数据中进行动态系统的状态估计和控制，无需真实状态信息，并展示了其在实时、准确控制方面的有效性以及对策略性能和控制稳定性的积极影响。", "translation": "**标题**：动态系统高维图像数据的状态估计与控制\n\n**摘要**：准确的状态估计对于动态系统中的最优策略设计至关重要。然而，获取真实的系统状态通常不切实际或不可行，这使得策略学习过程复杂化。本文介绍了一种新颖的神经网络架构，该架构集成了使用卷积神经网络（CNN）进行空间特征提取和通过门控循环单元（GRU）进行时间建模，从而能够从图像序列和相应动作中有效地表示状态。这些学习到的状态表示用于使用深度Q网络（DQN）训练强化学习智能体。实验结果表明，我们提出的方法无需直接访问地面真实状态即可实现实时、准确的估计和控制。此外，我们提供了一种量化评估方法来评估学习状态的准确性，强调了它们对策略性能和控制稳定性的影响。", "summary": "本文提出了一种新颖的神经网络架构，结合CNN的空间特征提取和GRU的时间建模能力，旨在从高维图像数据中学习动态系统的有效状态表示。这些学习到的状态随后被用于训练基于DQN的强化学习智能体，以实现系统的状态估计和控制。实验证明，该方法能够在不直接访问真实状态的情况下实现实时、准确的估计和控制，并且还提供了一种评估学习状态准确性的方法。", "keywords": "状态估计, 动态系统, 图像数据, 卷积神经网络, 门控循环单元, 强化学习", "comments": "该研究的创新点在于其提出的结合CNN和GRU的神经网络架构，能够有效地从高维图像数据中学习状态表示，解决了在缺乏真实系统状态时进行策略学习的难题。其重要性体现在实现了无需地面真实状态的实时、准确的动态系统估计和控制，这在许多实际应用中具有重要价值。"}}
{"id": "2506.06202", "title": "MLOps with Microservices: A Case Study on the Maritime Domain", "authors": ["Renato Cordeiro Ferreira", "Rowanne Trapmann", "Willem-Jan van den Heuvel"], "summary": "This case study describes challenges and lessons learned on building Ocean\nGuard: a Machine Learning-Enabled System (MLES) for anomaly detection in the\nmaritime domain. First, the paper presents the system's specification, and\narchitecture. Ocean Guard was designed with a microservices' architecture to\nenable multiple teams to work on the project in parallel. Then, the paper\ndiscusses how the developers adapted contract-based design to MLOps for\nachieving that goal. As a MLES, Ocean Guard employs code, model, and data\ncontracts to establish guidelines between its services. This case study hopes\nto inspire software engineers, machine learning engineers, and data scientists\nto leverage similar approaches for their systems.", "comment": "13 pages, 3 figures, to be published in SummerSOC 2025", "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.06202v1", "AI": {"title_translation": "微服务MLOps：海事领域案例研究", "tldr": "本案例研究探讨了使用微服务架构和契约式设计构建海事领域异常检测ML系统的挑战和经验。", "motivation": "本研究的动机是分享在海事领域构建一个名为Ocean Guard的机器学习系统（MLES）的挑战和经验，该系统用于异常检测，并展示如何通过微服务架构和契约式设计来支持多团队并行工作。", "method": "本研究采用微服务架构设计了Ocean Guard系统，并讨论了如何将契约式设计（包括代码、模型和数据契约）应用于MLOps，以在服务之间建立指导原则。", "result": "Ocean Guard系统采用微服务架构设计，实现了多团队并行工作。通过将契约式设计应用于MLOps，该系统利用代码、模型和数据契约在其服务之间建立了指导原则。", "conclusion": "本案例研究旨在启发软件工程师、机器学习工程师和数据科学家在他们的系统中利用类似的方法。", "translation": "本案例研究描述了在海事领域构建一个用于异常检测的机器学习系统（MLES）——Ocean Guard所面临的挑战和吸取的经验教训。首先，论文介绍了系统的规格和架构。Ocean Guard采用微服务架构设计，以使多个团队能够并行开展项目工作。然后，论文讨论了开发人员如何将契约式设计应用于MLOps以实现该目标。作为一个MLES，Ocean Guard采用代码、模型和数据契约来建立其服务之间的指导原则。本案例研究希望能启发软件工程师、机器学习工程师和数据科学家在他们的系统中利用类似的方法。", "summary": "本案例研究详细介绍了在海事领域构建一个基于微服务架构的机器学习系统（Ocean Guard），用于异常检测的经验。论文阐述了系统的规格、架构，并强调了如何通过将契约式设计（包含代码、模型和数据契约）应用于MLOps，从而支持多团队并行开发。该研究旨在为相关领域的专业人员提供实践参考。", "keywords": "MLOps, 微服务, 案例研究, 海事领域, 异常检测", "comments": "本论文通过一个具体的案例研究，展示了在MLOps实践中结合微服务架构和契约式设计的有效性，特别是在需要多团队协作的大型机器学习系统开发中。其创新点在于将契约式设计引入MLOps流程，以提高团队间的协作效率和系统一致性，对未来MLOps的实施具有重要的指导意义。"}}
{"id": "2506.05619", "title": "Population-Proportional Preference Learning from Human Feedback: An Axiomatic Approach", "authors": ["Kihyun Kim", "Jiawei Zhang", "Asuman Ozdaglar", "Pablo A. Parrilo"], "summary": "Conventional preference learning methods often prioritize opinions held more\nwidely when aggregating preferences from multiple evaluators. This may result\nin policies that are biased in favor of some types of opinions or groups. The\nobjective of this paper is to develop a novel preference learning framework\ncapable of aligning aggregate opinions and policies proportionally with the\ntrue population distribution of evaluator preferences. Our approach infers the\nfeasible set of evaluator population distributions directly from pairwise\ncomparison data. Using these estimates, the algorithm constructs a policy that\nsatisfies foundational axioms from social choice theory, namely monotonicity\nand Pareto efficiency, as well as our newly-introduced axioms of\npopulation-proportional representation and population-bounded robustness. We\npropose a soft-max relaxation method that smoothly trade-offs\npopulation-proportional representation with the selection of the Condorcet\nwinner (which beats all other options in pairwise comparisons). Finally, we\nvalidate the effectiveness and scalability of our approach through experiments\non both tabular recommendation tasks and large-scale language model alignment.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05619v1", "AI": {"title_translation": "从人类反馈中学习人口比例偏好：一种公理化方法", "tldr": "传统偏好学习方法可能存在偏见。本文提出了一种新颖的、基于公理的人口比例偏好学习框架，并通过在推荐任务和大型语言模型对齐上的实验验证了其有效性。", "motivation": "传统的偏好学习方法在聚合多评估者偏好时，往往优先考虑更广泛持有的意见，这可能导致政策偏向某些特定意见或群体。本文旨在开发一个框架，使聚合意见和政策能够与评估者偏好的真实人口分布成比例地对齐。", "method": "该方法直接从成对比较数据中推断评估者人口分布的可行集。利用这些估计，算法构建的策略满足社会选择理论的基本公理（单调性和帕累托效率），以及新引入的人口比例代表性和人口有界鲁棒性公理。此外，论文提出了一种软最大松弛方法，以平滑地权衡人口比例代表性与孔多塞胜者的选择。", "result": "通过在表格推荐任务和大规模语言模型对齐上的实验，验证了该方法的有效性和可扩展性。", "conclusion": "本文成功开发并验证了一种新颖的、以人口比例为导向的偏好学习框架，该框架能够纠正传统方法的偏差，并满足重要的社会选择公理，从而实现聚合意见与真实人口偏好分布的比例对齐。", "translation": "传统的偏好学习方法在聚合来自多个评估者的偏好时，通常会优先考虑更广泛持有的意见。这可能导致政策偏向某些类型的意见或群体。本文的目标是开发一种新颖的偏好学习框架，能够使聚合意见和政策与评估者偏好的真实人口分布成比例地对齐。我们的方法直接从成对比较数据中推断出评估者人口分布的可行集。利用这些估计，算法构建了一个满足社会选择理论基本公理（即单调性和帕累托效率）以及我们新引入的人口比例代表性和人口有界鲁棒性公理的策略。我们提出了一种软最大松弛方法，可以平滑地权衡人口比例代表性与孔多塞胜者（在成对比较中击败所有其他选项）的选择。最后，我们通过在表格推荐任务和大规模语言模型对齐上的实验，验证了我们方法的有效性和可扩展性。", "summary": "本文提出了一种新颖的偏好学习框架，旨在解决传统方法中因优先考虑多数意见而导致的偏见问题。该框架的目标是确保聚合意见和政策与评估者偏好的真实人口分布成比例地对齐。其方法包括从成对比较数据中推断出评估者人口分布的可行集，并基于此构建满足社会选择理论（如单调性、帕累托效率）及新引入的人口比例代表性和人口有界鲁棒性公理的策略。论文还引入了一种软最大松弛方法，以平衡人口比例代表性与孔多塞胜者的选择。该方法的有效性和可扩展性已通过在表格推荐任务和大规模语言模型对齐上的实验得到验证。", "keywords": "偏好学习, 人口比例, 公理化方法, 人类反馈, 社会选择理论", "comments": "该论文通过引入一种公理化方法来解决偏好学习中存在的偏见问题，确保人口比例代表性，具有重要的创新性。它将社会选择理论的既有公理与新提出的公理相结合，并提出了一种实用的软最大松弛方法。其在大型语言模型对齐领域的应用，展现了其超越传统推荐系统的广泛相关性和潜在影响力。"}}
{"id": "2506.05443", "title": "UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss", "authors": ["Yiyu Lin", "Yan Wang", "You Zhou", "Xinye Ni", "Jiahui Wu", "Sen Yang"], "summary": "As a core mechanism of epigenetic regulation in eukaryotes, protein\npost-translational modifications (PTMs) require precise prediction to decipher\ndynamic life activity networks. To address the limitations of existing deep\nlearning models in cross-modal feature fusion, domain generalization, and\narchitectural optimization, this study proposes UniPTMs: the first unified\nframework for multi-type PTM prediction. The framework innovatively establishes\na \"Master-Slave\" dual-path collaborative architecture: The master path\ndynamically integrates high-dimensional representations of protein sequences,\nstructures, and evolutionary information through a Bidirectional Gated\nCross-Attention (BGCA) module, while the slave path optimizes feature\ndiscrepancies and recalibration between structural and traditional features\nusing a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale\nAdaptive convolutional Pyramid (MACP) for capturing local feature patterns and\na Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level\nfeature integration across paths, the framework employs a Hierarchical Dynamic\nWeighting Fusion (HDWF) mechanism to intelligently aggregate multimodal\nfeatures. Enhanced by a novel Hierarchical Contrastive loss function for\nfeature consistency optimization, UniPTMs demonstrates significant performance\nimprovements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art\nmodels across five modification types and transcends the Single-Type Prediction\nParadigm. To strike a balance between model complexity and performance, we have\nalso developed a lightweight variant named UniPTMs-mini.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05443v1", "AI": {"title_translation": "UniPTMs：首个基于主从架构多阶段融合策略和分层对比损失的统一多类型PTM位点预测模型", "tldr": "UniPTMs是首个统一的多类型蛋白质翻译后修饰（PTM）位点预测模型，通过创新的主从架构、多阶段融合策略和分层对比损失，显著提高了预测性能，超越了传统的单一类型预测范式。", "motivation": "为了解决现有深度学习模型在跨模态特征融合、领域泛化和架构优化方面的局限性，并精确预测蛋白质翻译后修饰（PTMs）以解析动态生命活动网络。", "method": "本研究提出了UniPTMs框架，其核心是“主从”双路径协作架构：主路径通过双向门控交叉注意力（BGCA）模块动态整合蛋白质序列、结构和进化信息的高维表示；从路径利用低维融合网络（LDFN）优化结构特征与传统特征之间的差异并进行重新校准。该框架还辅以多尺度自适应卷积金字塔（MACP）捕获局部特征模式，以及双向分层门控融合网络（BHGFN）实现跨路径多级别特征整合，并采用分层动态加权融合（HDWF）机制智能聚合多模态特征。此外，引入了新颖的分层对比损失函数以优化特征一致性。为平衡模型复杂性与性能，还开发了轻量级变体UniPTMs-mini。", "result": "UniPTMs在五种修饰类型上的性能均显著优于现有最先进模型，MCC指标提高了3.2%-11.4%，AP指标提高了4.2%-14.3%，并成功超越了单一类型预测范式。", "conclusion": "Not mentioned in abstract", "translation": "Not mentioned in abstract", "summary": "UniPTMs是第一个统一的多类型蛋白质翻译后修饰（PTM）位点预测框架，旨在解决现有深度学习模型在跨模态特征融合和领域泛化方面的不足。该模型创新性地采用了“主从”双路径协作架构，结合多阶段融合策略（如BGCA、LDFN、MACP、BHGFN和HDWF）以及新颖的分层对比损失函数，有效整合并优化了多模态特征。实验结果表明，UniPTMs在多种修饰类型上均显著优于现有SOTA模型，实现了性能的显著提升，并成功超越了单一类型预测的局限。", "keywords": "PTMs, 统一预测, 主从架构, 多阶段融合, 分层对比损失", "comments": "该论文的创新点在于提出了首个统一的多类型PTM位点预测框架UniPTMs，其核心是独特的“主从”双路径协作架构，有效解决了跨模态特征融合和领域泛化等挑战。通过引入多阶段融合策略和分层对比损失，模型能够更有效地整合和优化复杂的生物信息。其在多类型PTM预测上的显著性能提升，以及超越单一类型预测范式的能力，显示了其在生物信息学和蛋白质研究领域的重要应用潜力。"}}
{"id": "2506.06193", "title": "Validation of the Critical Reflection and Agency in Computing Index: Do Computing Ethics Courses Make a Difference?", "authors": ["Aadarsh Padiyath", "Casey Fiesler", "Mark Guzdial", "Barbara Ericson"], "summary": "Computing ethics education aims to develop students' critical reflection and\nagency. We need validated ways to measure whether our efforts succeed. Through\ntwo survey administrations (N=474, N=464) with computing students and\nprofessionals, we provide evidence for the validity of the Critical Reflection\nand Agency in Computing Index. Our psychometric analyses demonstrate distinct\ndimensions of ethical development and show strong reliability and construct\nvalidity. Participants who completed computing ethics courses showed higher\nscores in some dimensions of ethical reflection and agency, but they also\nexhibited stronger techno-solutionist beliefs, highlighting a challenge in\ncurrent pedagogy. This validated instrument enables systematic measurement of\nhow computing students develop critical consciousness, allowing educators to\nbetter understand how to prepare computing professionals to tackle ethical\nchallenges in their work.", "comment": "Accepted to the ACM Conference on International Computing Education\n  Research V.1 (ICER 2025 Vol. 1)", "cate": "cs.CY", "url": "http://arxiv.org/pdf/2506.06193v1", "AI": {"title_translation": "计算批判性反思与能动性指数的验证：计算伦理课程是否有效？", "tldr": "本文验证了“计算批判性反思与能动性指数”，发现伦理课程有助于学生在某些方面提升伦理意识，但也可能增强技术解决方案主义信念。", "motivation": "计算伦理教育旨在培养学生的批判性反思和能动性，但缺乏有效的方法来衡量这些努力是否成功。因此，本研究的动机是提供一个经过验证的工具来衡量计算伦理教育的效果。", "method": "研究通过两次问卷调查（N=474，N=464）对计算机专业的学生和专业人士进行了数据收集。随后，进行了心理测量学分析，以验证“计算批判性反思与能动性指数”的有效性。", "result": "研究结果表明，“计算批判性反思与能动性指数”具有很强的信度和结构效度，并揭示了伦理发展的不同维度。完成计算伦理课程的参与者在伦理反思和能动性的某些维度上得分更高，但他们也表现出更强的技术解决方案主义信念。", "conclusion": "本研究验证的工具能够系统地衡量计算专业学生批判性意识的发展，从而帮助教育工作者更好地理解如何培养计算专业人才应对工作中的伦理挑战。同时，研究也指出了当前教学中存在的挑战，即伦理课程可能在某些方面增强技术解决方案主义信念。", "translation": "计算伦理教育旨在培养学生的批判性反思和能动性。我们需要经过验证的方法来衡量我们的努力是否成功。通过对计算专业学生和专业人士进行两次问卷调查（N=474，N=464），我们为“计算批判性反思与能动性指数”的有效性提供了证据。我们的心理测量学分析表明伦理发展的不同维度，并显示出很强的信度和结构效度。完成计算伦理课程的参与者在伦理反思和能动性的某些维度上得分更高，但他们也表现出更强的技术解决方案主义信念，这凸显了当前教学法中的一个挑战。这种经过验证的工具能够系统地衡量计算专业学生如何发展批判性意识，从而使教育工作者能够更好地理解如何培养计算专业人士应对工作中的伦理挑战。", "summary": "本研究验证了“计算批判性反思与能动性指数”，旨在衡量计算伦理教育对学生批判性反思和能动性的影响。通过对近千名计算专业学生和专业人士进行两次大规模调查及心理测量学分析，结果证实了该指数的有效性、信度和结构效度。研究发现，尽管伦理课程能提升学生在某些伦理维度的分数，但也意外地增强了他们的技术解决方案主义信念。该工具为评估伦理教育成效提供了系统方法，并揭示了当前教学法需改进之处。", "keywords": "计算伦理, 批判性反思, 能动性, 伦理教育, 心理测量学", "comments": "本文的创新之处在于开发并验证了一个专门用于衡量计算领域批判性反思和能动性的量化工具，填补了该领域测量工具的空白。其重要性在于，该工具能够帮助教育者更科学地评估伦理课程的实际效果，并识别教学中可能存在的不足，例如意外增强的技术解决方案主义信念。这为改进计算伦理教育提供了数据支持和方向。"}}
{"id": "2506.05411", "title": "QA-HFL: Quality-Aware Hierarchical Federated Learning for Resource-Constrained Mobile Devices with Heterogeneous Image Quality", "authors": ["Sajid Hussain", "Muhammad Sohail", "Nauman Ali Khan"], "summary": "This paper introduces QA-HFL, a quality-aware hierarchical federated learning\nframework that efficiently handles heterogeneous image quality across\nresource-constrained mobile devices. Our approach trains specialized local\nmodels for different image quality levels and aggregates their features using a\nquality-weighted fusion mechanism, while incorporating differential privacy\nprotection. Experiments on MNIST demonstrate that QA-HFL achieves 92.31%\naccuracy after just three federation rounds, significantly outperforming\nstate-of-the-art methods like FedRolex (86.42%). Under strict privacy\nconstraints, our approach maintains 30.77% accuracy with formal differential\nprivacy guarantees. Counter-intuitively, low-end devices contributed most\nsignificantly (63.5%) to the final model despite using 100 fewer parameters\nthan high-end counterparts. Our quality-aware approach addresses accuracy\ndecline through device-specific regularization, adaptive weighting, intelligent\nclient selection, and server-side knowledge distillation, while maintaining\nefficient communication with a 4.71% compression ratio. Statistical analysis\nconfirms that our approach significantly outperforms baseline methods (p 0.01)\nunder both standard and privacy-constrained conditions.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05411v1", "AI": {"title_translation": "QA-HFL：面向资源受限移动设备和异构图像质量的质量感知分层联邦学习", "tldr": "QA-HFL是一种新的分层联邦学习框架，能有效处理移动设备上的异构图像质量，在低轮次和严格隐私下表现优异，甚至低端设备贡献更大。", "motivation": "解决资源受限移动设备上异构图像质量导致的联邦学习性能下降问题。", "method": "引入QA-HFL框架，通过为不同图像质量级别训练专门的本地模型，使用质量加权融合机制聚合特征，并结合差分隐私保护。采用设备特定正则化、自适应加权、智能客户端选择和服务器端知识蒸馏来解决精度下降问题，并保持高效通信。", "result": "在MNIST数据集上，QA-HFL在3轮联邦后达到92.31%的准确率，优于FedRolex（86.42%）。在严格隐私约束下，仍保持30.77%的准确率。低端设备对最终模型的贡献最大（63.5%），尽管参数减少了100个。通信压缩比为4.71%。统计分析表明，在标准和隐私约束条件下均显著优于基线方法（p < 0.01）。", "conclusion": "QA-HFL有效解决了资源受限移动设备上异构图像质量带来的挑战，并在准确性、隐私保护和通信效率方面表现出色，特别值得注意的是低端设备的显著贡献。", "translation": "本文介绍了QA-HFL，一个质量感知分层联邦学习框架，它能有效处理资源受限移动设备上异构图像质量的问题。我们的方法为不同图像质量级别训练专门的本地模型，并使用质量加权融合机制聚合其特征，同时结合了差分隐私保护。在MNIST上的实验表明，QA-HFL在仅仅三轮联邦后就达到了92.31%的准确率，显著优于最先进的方法如FedRolex（86.42%）。在严格的隐私约束下，我们的方法在正式的差分隐私保证下仍保持30.77%的准确率。与直觉相反的是，尽管低端设备比高端设备使用的参数少了100个，但它们对最终模型的贡献最大（63.5%）。我们提出的质量感知方法通过设备特定正则化、自适应加权、智能客户端选择和服务器端知识蒸馏来解决准确率下降问题，同时通过4.71%的压缩率保持高效通信。统计分析证实，在标准和隐私约束条件下，我们的方法均显著优于基线方法（p < 0.01）。", "summary": "QA-HFL是一种新型质量感知分层联邦学习框架，旨在解决资源受限移动设备上异构图像质量问题。该框架通过训练特定质量级别的本地模型并进行质量加权融合，同时整合差分隐私保护。实验证明，QA-HFL在准确性、隐私保护和通信效率方面均表现出色，尤其在低轮次和严格隐私条件下，且发现低端设备贡献显著。", "keywords": "联邦学习, 异构图像质量, 资源受限设备", "comments": "这篇论文的创新点在于提出了一个质量感知的分层联邦学习框架，专门处理移动设备上的异构图像质量问题。其重要性体现在有效提升了资源受限环境下的联邦学习性能，同时兼顾了隐私保护和通信效率。特别值得注意的是，该研究发现低端设备对模型贡献更大，这可能为未来联邦学习的设计和资源分配提供了新的视角。"}}
{"id": "2506.06012", "title": "Enhanced Trust Region Sequential Convex Optimization for Multi-Drone Thermal Screening Trajectory Planning in Urban Environments", "authors": ["Kaiyuan Chen", "Zhengjie Hu", "Shaolin Zhang", "Yuanqing Xia", "Wannian Liang", "Shuo Wang"], "summary": "The rapid detection of abnormal body temperatures in urban populations is\nessential for managing public health risks, especially during outbreaks of\ninfectious diseases. Multi-drone thermal screening systems offer promising\nsolutions for fast, large-scale, and non-intrusive human temperature\nmonitoring. However, trajectory planning for multiple drones in complex urban\nenvironments poses significant challenges, including collision avoidance,\ncoverage efficiency, and constrained flight environments. In this study, we\npropose an enhanced trust region sequential convex optimization (TR-SCO)\nalgorithm for optimal trajectory planning of multiple drones performing thermal\nscreening tasks. Our improved algorithm integrates a refined convex\noptimization formulation within a trust region framework, effectively balancing\ntrajectory smoothness, obstacle avoidance, altitude constraints, and maximum\nscreening coverage. Simulation results demonstrate that our approach\nsignificantly improves trajectory optimality and computational efficiency\ncompared to conventional convex optimization methods. This research provides\ncritical insights and practical contributions toward deploying efficient\nmulti-drone systems for real-time thermal screening in urban areas. For reader\nwho are interested in our research, we release our source code at\nhttps://github.com/Cherry0302/Enhanced-TR-SCO.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06012v1", "AI": {"title_translation": "城市环境中多无人机热成像筛查轨迹规划的增强型信任域序贯凸优化", "tldr": "本研究提出了一种增强型信任域序贯凸优化（TR-SCO）算法，用于在城市环境中为多无人机热成像筛查任务规划最优轨迹，该方法在轨迹优化和计算效率方面表现出显著改进。", "motivation": "在传染病爆发期间，快速检测城市人口中的异常体温对于管理公共卫生风险至关重要。多无人机热成像筛查系统为快速、大规模和非侵入性的人体温度监测提供了有前景的解决方案。然而，在复杂的城市环境中为多无人机规划轨迹面临碰撞避免、覆盖效率和飞行环境受限等重大挑战。", "method": "本研究提出了一种增强型信任域序贯凸优化（TR-SCO）算法，用于多无人机执行热成像筛查任务的最优轨迹规划。改进的算法在信任域框架内集成了精炼的凸优化公式，有效平衡了轨迹平滑度、障碍物避让、高度限制和最大筛查覆盖范围。", "result": "仿真结果表明，与传统凸优化方法相比，我们的方法显著提高了轨迹最优性和计算效率。", "conclusion": "本研究为在城市地区部署高效的多无人机系统进行实时热成像筛查提供了重要的见解和实际贡献。", "translation": "在城市人口中快速检测异常体温对于管理公共卫生风险至关重要，特别是在传染病爆发期间。多无人机热成像筛查系统为快速、大规模和非侵入性的人体温度监测提供了有前景的解决方案。然而，在复杂的城市环境中为多无人机规划轨迹带来了重大挑战，包括碰撞避免、覆盖效率和受限的飞行环境。在本研究中，我们提出了一种增强型信任域序贯凸优化（TR-SCO）算法，用于执行热成像筛查任务的多无人机最优轨迹规划。我们改进的算法在信任域框架内集成了精炼的凸优化公式，有效平衡了轨迹平滑度、障碍物避让、高度限制和最大筛查覆盖范围。仿真结果表明，与传统凸优化方法相比，我们的方法显著提高了轨迹最优性和计算效率。这项研究为在城市地区部署高效的多无人机系统进行实时热成像筛查提供了重要的见解和实际贡献。对于对我们研究感兴趣的读者，我们已在 https://github.com/Cherry0302/Enhanced-TR-SCO 发布了源代码。", "summary": "本研究提出了一种增强型信任域序贯凸优化（TR-SCO）算法，以解决城市环境中多无人机热成像筛查的轨迹规划难题。该算法在信任域框架内整合了改进的凸优化公式，旨在优化轨迹平滑度、避障、高度限制和筛查覆盖范围。仿真结果表明，与现有方法相比，该方法在轨迹最优性和计算效率方面均有显著提升，为城市实时热成像筛查提供了实用的多无人机系统部署方案。", "keywords": "多无人机, 轨迹规划, 热成像筛查, 信任域序贯凸优化, 城市环境", "comments": "该论文通过提出增强型信任域序贯凸优化算法，有效解决了城市环境中多无人机热成像筛查轨迹规划的复杂问题，尤其在平衡多重约束和提高效率方面表现出创新性。其对公共卫生风险管理的潜在应用价值高，且提供源代码体现了研究的开放性和可复现性。"}}
{"id": "2506.05377", "title": "An Independent Discriminant Network Towards Identification of Counterfeit Images and Videos", "authors": ["Shayantani Kar", "B. Shresth Bhimrajka", "Aditya Kumar", "Sahil Gupta", "Sourav Ghosh", "Subhamita Mukherjee", "Shauvik Paul"], "summary": "Rapid spread of false images and videos on online platforms is an emerging\nproblem. Anyone may add, delete, clone or modify people and entities from an\nimage using various editing software which are readily available. This\ngenerates false and misleading proof to hide the crime. Now-a-days, these false\nand counterfeit images and videos are flooding on the internet. These spread\nfalse information. Many methods are available in literature for detecting those\ncounterfeit contents but new methods of counterfeiting are also evolving.\nGenerative Adversarial Networks (GAN) are observed to be one effective method\nas it modifies the context and definition of images producing plausible results\nvia image-to-image translation. This work uses an independent discriminant\nnetwork that can identify GAN generated image or video. A discriminant network\nhas been created using a convolutional neural network based on\nInceptionResNetV2. The article also proposes a platform where users can detect\nforged images and videos. This proposed work has the potential to help the\nforensics domain to detect counterfeit videos and hidden criminal evidence\ntowards the identification of criminal activities.", "comment": "This research was conducted by student and professor co-authors from\n  Techno Main Salt Lake, with co-author Sourav Ghosh serving as an alumni\n  mentor in an invited capacity -- distinct from his primary affiliation and\n  pre-approved by his employer. This preprint presents research originally\n  completed in early 2023 and published in IETE Journal of Research in 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05377v1", "AI": {"title_translation": "鉴别伪造图像和视频的独立判别网络", "tldr": "本文提出一个基于InceptionResNetV2的独立判别网络，用于识别GAN生成的伪造图像和视频，并旨在帮助法证领域打击犯罪。", "motivation": "虚假图像和视频在网络平台上的迅速传播是一个日益严重的问题，它们被用于隐藏犯罪和散布虚假信息。尽管现有方法众多，但新的伪造技术（如GAN）不断演进，需要更有效的方法来识别这些伪造内容。", "method": "本文利用一个独立的判别网络来识别GAN生成的图像或视频。该判别网络是基于InceptionResNetV2的卷积神经网络构建的。文章还提出了一个供用户检测伪造图像和视频的平台。", "result": "Not mentioned in abstract", "conclusion": "本文提出的独立判别网络和平台有潜力帮助法证领域检测伪造视频和隐藏的犯罪证据，从而识别犯罪活动。", "translation": "虚假图像和视频在网络平台上的迅速传播是一个日益严重的问题。任何人都可以使用现成的各种编辑软件，从图像中添加、删除、克隆或修改人物和实体。这会产生虚假和误导性的证据来掩盖犯罪。如今，这些虚假和伪造的图像和视频正在互联网上泛滥。它们传播虚假信息。文献中有许多检测这些伪造内容的方法，但新的伪造方法也在不断发展。生成对抗网络（GAN）被认为是一种有效的方法，因为它通过图像到图像的转换来修改图像的上下文和定义，从而产生合理的结果。这项工作使用了一个独立的判别网络，可以识别GAN生成的图像或视频。一个基于InceptionResNetV2的卷积神经网络构建了一个判别网络。文章还提出了一个用户可以检测伪造图像和视频的平台。这项提议的工作有潜力帮助法证领域检测伪造视频和隐藏的犯罪证据，从而识别犯罪活动。", "summary": "针对网络上虚假图像和视频泛滥的问题，本文提出了一种基于InceptionResNetV2卷积神经网络的独立判别网络，旨在识别由生成对抗网络（GAN）产生的伪造图像和视频。该研究还设想了一个用户可用的检测平台，以期为法证领域提供检测伪造内容和犯罪证据的工具。", "keywords": "伪造图像, 伪造视频, 判别网络, GAN, InceptionResNetV2", "comments": "本文的创新点在于提出了一个专门用于识别GAN生成图像和视频的独立判别网络，并基于InceptionResNetV2构建。其重要性在于应对日益增长的深度伪造威胁，为法证领域提供了潜在的工具。"}}
{"id": "2506.06247", "title": "Scalable Language Agnostic Taint Tracking using Explicit Data Dependencies", "authors": ["Sedick David Baker Effendi", "Xavier Pinho", "Andrei Michael Dreyer", "Fabian Yamaguchi"], "summary": "Taint analysis using explicit whole-program data-dependence graphs is\npowerful for vulnerability discovery but faces two major challenges. First,\naccurately modeling taint propagation through calls to external library\nprocedures requires extensive manual annotations, which becomes impractical for\nlarge ecosystems. Second, the sheer size of whole-program graph representations\nleads to serious scalability and performance issues, particularly when quick\nanalysis is needed in continuous development pipelines.\n  This paper presents the design and implementation of a system for a\nlanguage-agnostic data-dependence representation. The system accommodates\nmissing annotations describing the behavior of library procedures by\nover-approximating data flows, allowing annotations to be added later without\nrecalculation. We contribute this data-flow analysis system to the open-source\ncode analysis platform Joern making it available to the community.", "comment": "9 pages including appendix, SOAP'25", "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.06247v1", "AI": {"title_translation": "可扩展的语言无关污点跟踪使用显式数据依赖", "tldr": "本文提出了一种可扩展的语言无关数据依赖表示系统，以解决现有污点分析中库过程手动标注和全程序图表示规模的问题。", "motivation": "现有的使用全程序数据依赖图的污点分析在漏洞发现方面功能强大，但面临两大挑战：1. 准确建模通过外部库过程的污点传播需要大量手动标注，这对于大型生态系统不切实际。2. 全程序图表示的庞大规模导致严重的扩展性和性能问题，尤其是在持续开发流程中需要快速分析时。", "method": "本文设计并实现了一个用于语言无关数据依赖表示的系统。该系统通过过度近似数据流来适应描述库过程行为的缺失标注，从而允许后续添加标注而无需重新计算。该数据流分析系统已贡献给开源代码分析平台Joern。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "污点分析利用显式全程序数据依赖图在漏洞发现方面功能强大，但面临两大主要挑战。首先，通过调用外部库过程准确建模污点传播需要大量手动标注，这对于大型生态系统来说变得不切实际。其次，全程序图表示的庞大规模导致严重的扩展性和性能问题，尤其是在持续开发流程中需要快速分析时。\n本文提出了一个用于语言无关数据依赖表示系统的设计和实现。该系统通过过度近似数据流来适应描述库过程行为的缺失标注，从而允许后续添加标注而无需重新计算。我们将该数据流分析系统贡献给开源代码分析平台Joern，使其可供社区使用。", "summary": "本文提出并实现了一个可扩展的语言无关数据依赖表示系统，旨在解决传统污点分析中对外部库过程进行手动标注的繁琐性以及全程序数据依赖图的规模和性能问题。该系统通过过度近似数据流来处理缺失的库标注，并支持后续添加标注而无需重新计算。该系统已作为数据流分析组件贡献给开源代码分析平台Joern。", "keywords": "污点跟踪, 数据依赖, 语言无关, 漏洞发现, 静态分析", "comments": "该论文的创新点在于提出了一个语言无关的数据依赖表示系统，并通过过度近似数据流的方式解决了传统污点分析中库函数手动标注的难题，同时提升了分析的扩展性。将该系统贡献给开源平台Joern也增强了其在社区中的可用性和影响力。"}}
{"id": "2506.05744", "title": "Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties", "authors": ["Gouki Minegishi", "Hiroki Furuta", "Takeshi Kojima", "Yusuke Iwasawa", "Yutaka Matsuo"], "summary": "Recent large-scale reasoning models have achieved state-of-the-art\nperformance on challenging mathematical benchmarks, yet the internal mechanisms\nunderlying their success remain poorly understood. In this work, we introduce\nthe notion of a reasoning graph, extracted by clustering hidden-state\nrepresentations at each reasoning step, and systematically analyze three key\ngraph-theoretic properties: cyclicity, diameter, and small-world index, across\nmultiple tasks (GSM8K, MATH500, AIME 2024). Our findings reveal that distilled\nreasoning models (e.g., DeepSeek-R1-Distill-Qwen-32B) exhibit significantly\nmore recurrent cycles (about 5 per sample), substantially larger graph\ndiameters, and pronounced small-world characteristics (about 6x) compared to\ntheir base counterparts. Notably, these structural advantages grow with task\ndifficulty and model capacity, with cycle detection peaking at the 14B scale\nand exploration diameter maximized in the 32B variant, correlating positively\nwith accuracy. Furthermore, we show that supervised fine-tuning on an improved\ndataset systematically expands reasoning graph diameters in tandem with\nperformance gains, offering concrete guidelines for dataset design aimed at\nboosting reasoning capabilities. By bridging theoretical insights into\nreasoning graph structures with practical recommendations for data\nconstruction, our work advances both the interpretability and the efficacy of\nlarge reasoning models.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05744v1", "AI": {"title_translation": "思考的拓扑学：通过思考图属性理解大型思考模型", "tldr": "本文通过分析大型推理模型的推理图属性（循环性、直径、小世界指数），发现蒸馏模型和经过微调的模型具有更好的图结构特性，且与性能正相关，为提高模型可解释性和效率提供了指导。", "motivation": "尽管大型推理模型在具有挑战性的数学基准测试中取得了最先进的性能，但其内部机制仍知之甚少。本文旨在通过引入推理图的概念来理解这些模型的成功。", "method": "引入推理图概念，通过聚类每个推理步骤的隐藏状态表示来提取推理图。系统分析了三个关键图论属性：循环性、直径和小世界指数，并在多个任务（GSM8K, MATH500, AIME 2024）上进行分析。", "result": "蒸馏推理模型（如DeepSeek-R1-Distill-Qwen-32B）比其基础模型表现出明显更多的循环（每个样本约5个）、显著更大的图直径和明显的小世界特征（约6倍）。这些结构优势随着任务难度和模型容量的增加而增长，循环检测在14B规模达到峰值，探索直径在32B变体中最大化，并与准确性呈正相关。此外，在改进的数据集上进行监督微调可以系统地扩大推理图直径，同时提高性能。", "conclusion": "通过将推理图结构的理论见解与数据构建的实践建议相结合，这项工作提升了大型推理模型的可解释性和效率。", "translation": "近期的大型推理模型在具有挑战性的数学基准测试中取得了最先进的性能，但其成功背后的内部机制仍知之甚少。在这项工作中，我们引入了推理图的概念，通过聚类每个推理步骤的隐藏状态表示来提取推理图，并系统地分析了三个关键的图论属性：循环性、直径和小世界指数，跨越多个任务（GSM8K、MATH500、AIME 2024）。我们的研究结果表明，与基础模型相比，蒸馏推理模型（例如DeepSeek-R1-Distill-Qwen-32B）表现出明显更多的循环（每个样本约5个）、显著更大的图直径和明显的小世界特征（约6倍）。值得注意的是，这些结构优势随着任务难度和模型容量的增加而增长，循环检测在14B规模达到峰值，探索直径在32B变体中最大化，并与准确性呈正相关。此外，我们表明，在改进的数据集上进行监督微调可以系统地扩大推理图直径，同时提高性能，为旨在提升推理能力的数据集设计提供了具体的指导方针。通过将推理图结构的理论见解与数据构建的实践建议相结合，我们的工作提升了大型推理模型的可解释性和效率。", "summary": "本文引入了推理图的概念，通过分析大型推理模型（特别是蒸馏模型）的推理图属性（循环性、直径、小世界指数），揭示了这些模型在数学任务中表现优异的内在机制。研究发现，蒸馏模型和经过微调的模型展现出更优的图结构特性，且这些特性与模型性能正相关。这为理解和提升大型推理模型的可解释性与效率提供了新的视角和具体的数据集设计指导。", "keywords": "推理图, 大型推理模型, 图论属性, 模型可解释性, 数据集设计", "comments": "这篇论文通过引入“推理图”的概念，为理解大型推理模型内部机制提供了一个新颖且量化的视角。它将图论属性与模型性能联系起来，揭示了蒸馏和微调对模型内部结构的影响，这对于提升模型可解释性和指导数据集设计具有重要意义。"}}
{"id": "2506.05445", "title": "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic", "authors": ["Thanh Vinh Vo", "Young Lee", "Haozhe Ma", "Chien Lu", "Tze-Yun Leong"], "summary": "Hidden confounders that influence both states and actions can bias policy\nlearning in reinforcement learning (RL), leading to suboptimal or\nnon-generalizable behavior. Most RL algorithms ignore this issue, learning\npolicies from observational trajectories based solely on statistical\nassociations rather than causal effects. We propose DoSAC (Do-Calculus Soft\nActor-Critic with Backdoor Adjustment), a principled extension of the SAC\nalgorithm that corrects for hidden confounding via causal intervention\nestimation. DoSAC estimates the interventional policy $\\pi(a | \\mathrm{do}(s))$\nusing the backdoor criterion, without requiring access to true confounders or\ncausal labels. To achieve this, we introduce a learnable Backdoor Reconstructor\nthat infers pseudo-past variables (previous state and action) from the current\nstate to enable backdoor adjustment from observational data. This module is\nintegrated into a soft actor-critic framework to compute both the\ninterventional policy and its entropy. Empirical results on continuous control\nbenchmarks show that DoSAC outperforms baselines under confounded settings,\nwith improved robustness, generalization, and policy reliability.", "comment": "Preprint", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05445v1", "AI": {"title_translation": "强化学习中的因果策略学习：后门调整的软演员-评论家算法", "tldr": "DoSAC是一种新的强化学习算法，通过后门调整纠正隐藏混杂因素，从而学习因果策略，提高鲁棒性和泛化能力。", "motivation": "隐藏混杂因素会影响状态和动作，导致强化学习（RL）中的策略学习产生偏差，从而导致次优或不可泛化的行为。大多数RL算法忽略了这个问题，仅基于统计关联而非因果效应从观察轨迹中学习策略。", "method": "本文提出了DoSAC（Do-Calculus Soft Actor-Critic with Backdoor Adjustment）算法，它是SAC算法的一个原则性扩展，通过因果干预估计来纠正隐藏混杂。DoSAC使用后门准则估计干预策略 $\\pi(a | \\mathrm{do}(s))$，无需访问真实的混杂因素或因果标签。为此，引入了一个可学习的后门重构器，它从当前状态推断伪过去变量（先前状态和动作），从而实现从观测数据进行后门调整。该模块集成到软演员-评论家框架中，以计算干预策略及其熵。", "result": "在连续控制基准上的实证结果表明，DoSAC在混杂设置下优于基线算法，具有更高的鲁棒性、泛化能力和策略可靠性。", "conclusion": "Not mentioned in abstract", "translation": "隐藏混杂因素会同时影响状态和动作，从而导致强化学习 (RL) 中的策略学习产生偏差，导致次优或不可泛化的行为。大多数RL算法忽略了这个问题，仅基于统计关联而非因果效应从观察轨迹中学习策略。我们提出了DoSAC (Do-Calculus Soft Actor-Critic with Backdoor Adjustment)，它是SAC算法的一个原则性扩展，通过因果干预估计来纠正隐藏混杂。DoSAC使用后门准则估计干预策略 $\\pi(a | \\mathrm{do}(s))$，而无需访问真实的混杂因素或因果标签。为了实现这一点，我们引入了一个可学习的后门重构器，它从当前状态推断伪过去变量（先前状态和动作），从而实现从观测数据进行后门调整。该模块集成到软演员-评论家框架中，以计算干预策略及其熵。在连续控制基准上的实证结果表明，DoSAC在混杂设置下优于基线算法，具有更高的鲁棒性、泛化能力和策略可靠性。", "summary": "本文提出了一种名为DoSAC的强化学习算法，旨在解决隐藏混杂因素导致策略学习偏差的问题。DoSAC是软演员-评论家（SAC）算法的扩展，它通过引入一个可学习的后门重构器，从观测数据中推断伪过去变量，从而利用后门准则估计因果干预策略。实验证明，在存在混杂因素的环境中，DoSAC相比现有基线算法，在鲁棒性、泛化能力和策略可靠性方面表现更优。", "keywords": "因果策略学习, 强化学习, 后门调整, 软演员-评论家, 隐藏混杂因素", "comments": "这篇论文通过将因果推断的后门调整引入强化学习，创新性地解决了隐藏混杂因素导致的策略偏差问题。其亮点在于无需真实混杂因素即可实现因果干预估计，并通过可学习的后门重构器使其在实际应用中更具可行性。这对于提高RL策略的泛化能力和可靠性具有重要意义。"}}
{"id": "2506.05379", "title": "Designing DSIC Mechanisms for Data Sharing in the Era of Large Language Models", "authors": ["Seyed Moein Ayyoubzadeh", "Kourosh Shahnazari", "Mohammmadali Keshtparvar", "MohammadAmin Fazli"], "summary": "Training large language models (LLMs) requires vast amounts of high-quality\ndata from institutions that face legal, privacy, and strategic constraints.\nExisting data procurement methods often rely on unverifiable trust or ignore\nheterogeneous provider costs. We introduce a mechanism-design framework for\ntruthful, trust-minimized data sharing that ensures dominant-strategy incentive\ncompatibility (DSIC), individual rationality, and weak budget balance, while\nrewarding data based on both quality and learning utility. We formalize a model\nwhere providers privately know their data cost and quality, and value arises\nsolely from the data's contribution to model performance. Based on this, we\npropose the Quality-Weighted Marginal-Incentive Auction (Q-MIA), which ranks\nproviders using a virtual cost metric and uses Myerson-style payments to ensure\nDSIC and budget feasibility. To support settings with limited liquidity or\nlong-term incentives, we introduce the Marginal Utility Token (MUT), which\nallocates future rights based on marginal contributions. We unify these in\nMixed-MIA, a hybrid mechanism balancing upfront payments and deferred rewards.\nAll mechanisms support verifiable, privacy-preserving implementation.\nTheoretically and empirically, they outperform volume-based and trust-based\nbaselines, eliciting higher-quality data under budget constraints while\nremaining robust to misreporting and collusion. This establishes a principled\nfoundation for sustainable and fair data markets for future LLMs.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.05379v1", "AI": {"title_translation": "大型语言模型时代数据共享的DSIC机制设计", "tldr": "本文设计了一种新的机制，用于在考虑成本和质量的情况下，以激励兼容的方式共享高质量数据，以训练大型语言模型。", "motivation": "训练大型语言模型（LLMs）需要大量高质量数据，但机构面临法律、隐私和战略限制。现有数据采购方法通常依赖于不可验证的信任或忽略异构提供者成本。", "method": "提出了一个机制设计框架，用于真实、最小化信任的数据共享，确保主导策略激励兼容性（DSIC）、个体理性和弱预算平衡，并根据数据质量和学习效用奖励数据。具体提出了质量加权边际激励拍卖（Q-MIA），使用虚拟成本指标排名提供者和Myerson式支付。为了支持有限流动性或长期激励，引入了边际效用代币（MUT）。并将两者统一为混合-MIA。所有机制都支持可验证、保护隐私的实现。", "result": "理论和实证表明，所提出的机制优于基于数量和基于信任的基线，在预算限制下能获取更高质量的数据，并且对虚报和串通具有鲁棒性。", "conclusion": "这些机制为未来大型语言模型的可持续和公平数据市场奠定了原则性基础。", "translation": "训练大型语言模型（LLMs）需要来自面临法律、隐私和战略限制的机构的大量高质量数据。现有数据采购方法通常依赖于不可验证的信任或忽略异构提供者成本。我们引入了一种机制设计框架，用于真实、最小化信任的数据共享，该框架确保了主导策略激励兼容性（DSIC）、个体理性和弱预算平衡，同时根据数据质量和学习效用进行奖励。我们形式化了一个模型，其中提供者私下了解其数据成本和质量，并且价值仅来源于数据对模型性能的贡献。在此基础上，我们提出了质量加权边际激励拍卖（Q-MIA），它使用虚拟成本指标对提供者进行排名，并使用Myerson式支付来确保DSIC和预算可行性。为了支持流动性有限或长期激励的设置，我们引入了边际效用代币（MUT），它根据边际贡献分配未来权利。我们将这些统一在混合-MIA中，这是一种平衡前期支付和递延奖励的混合机制。所有机制都支持可验证、保护隐私的实现。从理论和经验上讲，它们优于基于数量和基于信任的基线，在预算限制下能获取更高质量的数据，同时对虚报和串通保持鲁棒性。这为未来大型语言模型的可持续和公平数据市场奠定了原则性基础。", "summary": "本文针对大型语言模型训练中数据共享面临的挑战，提出了一种主导策略激励兼容（DSIC）的机制设计框架。该框架考虑数据质量和学习效用，并引入了质量加权边际激励拍卖（Q-MIA）和边际效用代币（MUT），以及两者的混合机制混合-MIA。这些机制旨在促进真实、最小化信任的数据共享，并在理论和实证上证明其在获取高质量数据方面的优越性及对虚报和串通的鲁棒性，为构建可持续的LLM数据市场奠定基础。", "keywords": "大型语言模型, 数据共享, 机制设计, 激励兼容", "comments": "这篇论文通过引入DSIC机制，有效地解决了LLM数据共享中信任、成本和质量激励的关键问题。其创新点在于结合了机制设计理论，提出了Q-MIA和MUT等新颖的解决方案，并考虑了实际场景中的流动性问题。这对于构建公平、高效且可持续的LLM数据市场具有重要意义，有助于推动LLM的进一步发展。"}}
{"id": "2506.05416", "title": "FERRET: Private Deep Learning Faster And Better Than DPSGD", "authors": ["David Zagardo"], "summary": "We revisit 1-bit gradient compression through the lens of mutual-information\ndifferential privacy (MI-DP). Building on signSGD, we propose FERRET--Fast and\nEffective Restricted Release for Ethical Training--which transmits at most one\nsign bit per parameter group with Bernoulli masking.\n  Theory: We prove each fired group leaks at most ln 2 nats; after subsampling\nwith rate s, the total privacy loss of G groups trained for T steps with firing\nprobability p is epsilon = G * T * s * p * ln 2. Thus FERRET achieves MI-DP for\nepsilon in [0.1, 2] without additive noise.\n  Practice: We evaluate three granularities--FERRET-MAX (finest), FERRET-EIGHTH\n(medium), and FERRET-2 (coarsest)--on five LLMs (137M-1.8B parameters) against\nDPSGD and Non-DP baselines. All methods trained for 1, 3, and 5 epochs.\n  Utility: Across all settings, FERRET-MAX/EIGHTH beat DPSGD's perplexity. At\nepsilon=0.5, 5 epochs: FERRET-EIGHTH achieves 3.98 perplexity vs DPSGD's 11.61\n(2.9x better), within 23% of Non-DP (3.25).\n  Privacy: MI-AUC stays at chance for FERRET-MAX/EIGHTH (~0.51), matching DPSGD\nvs Non-DP's 0.76-0.99. FERRET-2 shows higher leakage (~0.55) due to lower\nheadroom.\n  Efficiency: Stricter budgets fire fewer signs, so FERRET uses 19-33% of\nDPSGD's training time and only 34-36% of Non-DP training time.\n  Take-away: Sign-based MI-DP gets closer to achieving all three qualities of\nthe privacy, utility, performance trilemma: FERRET trains up to 5x faster,\nachieves 3x lower perplexity compared to DPSGD and 1.2x greater than Non-DP,\nall while providing formal, mathematically provable privacy guarantees using\nzero additive noise. The results also show that, in certain instances, masked\n1-bit updates can match non-private training utility while safeguarding data.", "comment": "28 pages, 6 figures", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05416v1", "AI": {"title_translation": "FERRET：比DPSGD更快更好的私有深度学习", "tldr": "FERRET是一种基于1位梯度压缩和互信息差分隐私的新型深度学习方法，它在提供形式化隐私保证的同时，比DPSGD训练更快、性能更好，甚至在某些情况下接近非私有训练的效用。", "motivation": "该研究旨在通过重新审视1位梯度压缩并结合互信息差分隐私（MI-DP）来解决私有深度学习中隐私、效用和性能的平衡问题，目标是实现比现有方法（如DPSGD）更快、更好且具有形式化隐私保证的训练。", "method": "本文提出了一种名为FERRET（Fast and Effective Restricted Release for Ethical Training）的方法，该方法基于signSGD，通过伯努利掩码对每个参数组最多传输一个符号位。理论上，FERRET通过控制触发概率实现了MI-DP，无需添加噪声。实践中，作者评估了三种粒度（FERRET-MAX、FERRET-EIGHTH和FERRET-2）在五种大型语言模型上的性能。", "result": "效用方面：FERRET-MAX/EIGHTH在所有设置下都优于DPSGD的困惑度。在epsilon=0.5、5个epoch时，FERRET-EIGHTH的困惑度为3.98，而DPSGD为11.61（2.9倍更好），接近Non-DP的3.25（23%以内）。隐私方面：FERRET-MAX/EIGHTH的MI-AUC保持在随机水平（约0.51），与DPSGD相当，而非私有训练的MI-AUC为0.76-0.99。FERRET-2由于冗余度较低，泄露程度较高（约0.55）。效率方面：FERRET的训练时间是DPSGD的19-33%，是非私有训练的34-36%。", "conclusion": "基于符号的MI-DP方法（FERRET）在隐私、效用和性能三难困境中取得了更好的平衡：FERRET训练速度比DPSGD快5倍，困惑度比DPSGD低3倍，比非私有训练高1.2倍，同时提供形式化、数学上可证明的隐私保证，且无需添加噪声。结果还表明，在某些情况下，掩码的1位更新可以匹配非私有训练的效用，同时保护数据。", "translation": "我们从互信息差分隐私（MI-DP）的角度重新审视了1位梯度压缩。在signSGD的基础上，我们提出了FERRET——快速有效的伦理训练受限释放——它通过伯努利掩码对每个参数组最多传输一个符号位。\n  理论：我们证明每个触发的组最多泄露ln 2纳特；以采样率s，G组训练T步，触发概率p，总隐私损失为epsilon = G * T * s * p * ln 2。因此，FERRET在epsilon值范围为[0.1, 2]时无需添加噪声即可实现MI-DP。\n  实践：我们评估了三种粒度——FERRET-MAX（最细）、FERRET-EIGHTH（中等）和FERRET-2（最粗）——在五种大型语言模型（1.37亿-18亿参数）上与DPSGD和Non-DP基线进行比较。所有方法均训练1、3和5个epoch。\n  效用：在所有设置下，FERRET-MAX/EIGHTH的困惑度均优于DPSGD。在epsilon=0.5，5个epoch时：FERRET-EIGHTH的困惑度为3.98，而DPSGD为11.61（好2.9倍），在非私有训练（3.25）的23%以内。\n  隐私：FERRET-MAX/EIGHTH的MI-AUC保持在随机水平（约0.51），与DPSGD相当，而非私有训练的MI-AUC为0.76-0.99。FERRET-2由于冗余度较低，显示出更高的泄露（约0.55）。\n  效率：更严格的预算会触发更少的符号，因此FERRET的训练时间仅为DPSGD的19-33%，非私有训练的34-36%。\n  总结：基于符号的MI-DP更接近于实现隐私、效用、性能三难困境的所有三个品质：FERRET训练速度快5倍，困惑度比DPSGD低3倍，比非私有训练高1.2倍，所有这些都提供了形式化、数学上可证明的隐私保证，且无需添加额外噪声。结果还表明，在某些情况下，掩码的1位更新可以匹配非私有训练的效用，同时保护数据。", "summary": "本文介绍了FERRET，一种基于1位梯度压缩和互信息差分隐私（MI-DP）的私有深度学习新方法。FERRET通过伯努利掩码实现隐私保护，并提供形式化理论证明其隐私损失。实验结果表明，FERRET在大型语言模型上，其效用（困惑度）显著优于DPSGD，接近非私有训练，且训练效率远高于DPSGD和非私有训练，同时保持了良好的隐私保护水平。FERRET在无需添加噪声的情况下，成功平衡了隐私、效用和性能。", "keywords": "私有深度学习, 1位梯度压缩, 互信息差分隐私, FERRET, 深度学习效率", "comments": "该论文的创新点在于将1位梯度压缩与互信息差分隐私相结合，提出了一种无需添加噪声即可实现形式化隐私保证的私有深度学习方法。其重要性在于，FERRET在实践中显著改善了私有训练的效用和效率，克服了传统差分隐私方法（如DPSGD）在性能上的局限性，使得私有深度学习在实际应用中更具可行性。论文强调了在特定情况下，掩码的1位更新甚至可以匹配非私有训练的效用，这对于推动隐私保护机器学习的发展具有重要意义。"}}
{"id": "2506.06028", "title": "End-to-End Framework for Robot Lawnmower Coverage Path Planning using Cellular Decomposition", "authors": ["Nikunj Shah", "Utsav Dey", "Kenji Nishimiya"], "summary": "Efficient Coverage Path Planning (CPP) is necessary for autonomous robotic\nlawnmowers to effectively navigate and maintain lawns with diverse and\nirregular shapes. This paper introduces a comprehensive end-to-end pipeline for\nCPP, designed to convert user-defined boundaries on an aerial map into\noptimized coverage paths seamlessly. The pipeline includes user input\nextraction, coordinate transformation, area decomposition and path generation\nusing our novel AdaptiveDecompositionCPP algorithm, preview and customization\nthrough an interactive coverage path visualizer, and conversion to actionable\nGPS waypoints. The AdaptiveDecompositionCPP algorithm combines cellular\ndecomposition with an adaptive merging strategy to reduce non-mowing travel\nthereby enhancing operational efficiency. Experimental evaluations,\nencompassing both simulations and real-world lawnmower tests, demonstrate the\neffectiveness of the framework in coverage completeness and mowing efficiency.", "comment": "8 pages, ICRA 2025, Workshop on Field Robotics", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06028v1", "AI": {"title_translation": "机器人割草机覆盖路径规划的端到端框架：基于单元分解", "tldr": "本文提出了一个用于机器人割草机覆盖路径规划的端到端框架，包含自适应分解算法，能有效提高割草效率和覆盖完整性。", "motivation": "自动机器人割草机需要高效的覆盖路径规划来有效导航和维护各种不规则形状的草坪。", "method": "本文介绍了一个全面的端到端覆盖路径规划（CPP）流程，旨在将航空地图上用户定义的边界无缝转换为优化的覆盖路径。该流程包括用户输入提取、坐标转换、区域分解和使用新型AdaptiveDecompositionCPP算法生成路径、通过交互式覆盖路径可视化工具进行预览和定制、以及转换为可操作的GPS航点。AdaptiveDecompositionCPP算法结合了单元分解和自适应合并策略，以减少非割草行程。", "result": "实验评估（包括模拟和真实世界割草机测试）证明了该框架在覆盖完整性和割草效率方面的有效性。", "conclusion": "Not mentioned in abstract", "translation": "高效的覆盖路径规划（CPP）对于自主机器人割草机有效导航和维护各种不规则形状的草坪是必不可少的。本文介绍了一个用于CPP的全面端到端流程，旨在将航空地图上用户定义的边界无缝转换为优化的覆盖路径。该流程包括用户输入提取、坐标转换、区域分解和使用我们新颖的AdaptiveDecompositionCPP算法生成路径、通过交互式覆盖路径可视化工具进行预览和定制、以及转换为可操作的GPS航点。AdaptiveDecompositionCPP算法结合了单元分解和自适应合并策略，以减少非割草行程，从而提高操作效率。涵盖模拟和真实世界割草机测试的实验评估证明了该框架在覆盖完整性和割草效率方面的有效性。", "summary": "本文提出了一个针对机器人割草机的端到端覆盖路径规划（CPP）框架，旨在将用户定义的草坪边界转换为优化的割草路径。该框架包含用户输入处理、坐标转换、基于新型AdaptiveDecompositionCPP算法的区域分解和路径生成、以及可视化工具和GPS航点转换。AdaptiveDecompositionCPP算法通过结合单元分解和自适应合并策略，有效减少了非割草行程，提高了操作效率。实验结果表明，该框架在覆盖完整性和割草效率上表现出色。", "keywords": "机器人割草机, 覆盖路径规划, 单元分解, 自适应算法, 端到端框架", "comments": "该论文提出了一个实用的端到端解决方案，解决了机器人割草机在复杂草坪上的覆盖路径规划问题。其创新点在于引入了AdaptiveDecompositionCPP算法，通过自适应合并策略有效减少了无效行程，提高了效率。该框架的全面性，从用户输入到GPS航点输出，使其具有很高的应用价值。"}}
{"id": "2506.05378", "title": "A Compendium of Autonomous Navigation using Object Detection and Tracking in Unmanned Aerial Vehicles", "authors": ["Mohit Arora", "Pratyush Shukla", "Shivali Chopra"], "summary": "Unmanned Aerial Vehicles (UAVs) are one of the most revolutionary inventions\nof 21st century. At the core of a UAV lies the central processing system that\nuses wireless signals to control their movement. The most popular UAVs are\nquadcopters that use a set of four motors, arranged as two on either side with\nopposite spin. An autonomous UAV is called a drone. Drones have been in service\nin the US army since the 90's for covert missions critical to national\nsecurity. It would not be wrong to claim that drones make up an integral part\nof the national security and provide the most valuable service during\nsurveillance operations. While UAVs are controlled using wireless signals,\nthere reside some challenges that disrupt the operation of such vehicles such\nas signal quality and range, real time processing, human expertise, robust\nhardware and data security. These challenges can be solved by programming UAVs\nto be autonomous, using object detection and tracking, through Computer Vision\nalgorithms. Computer Vision is an interdisciplinary field that seeks the use of\ndeep learning to gain a high-level understanding of digital images and videos\nfor the purpose of automating the task of human visual system. Using computer\nvision, algorithms for detecting and tracking various objects can be developed\nsuitable to the hardware so as to allow real time processing for immediate\njudgement. This paper attempts to review the various approaches several authors\nhave proposed for the purpose of autonomous navigation of UAVs by through\nvarious algorithms of object detection and tracking in real time, for the\npurpose of applications in various fields such as disaster management, dense\narea exploration, traffic vehicle surveillance etc.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05378v1", "AI": {"title_translation": "无人机中利用目标检测与跟踪实现自主导航的汇编", "tldr": "本文综述了无人机利用计算机视觉算法进行目标检测与跟踪以实现自主导航的各种方法。", "motivation": "解决无人机在无线信号控制下遇到的挑战，如信号质量、实时处理、人工干预、硬件限制和数据安全，通过使其自主化来克服这些问题。自主化依赖于计算机视觉算法进行目标检测和跟踪。", "method": "本文旨在回顾现有文献中作者们提出的各种利用实时目标检测和跟踪算法实现无人机自主导航的方法。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "无人机（UAVs）是21世纪最具革命性的发明之一。无人机的核心是使用无线信号控制其运动的中央处理系统。最受欢迎的无人机是四旋翼无人机，它们有四个电机，每侧两个，旋转方向相反。自主无人机被称为“无人机”。自90年代以来，无人机在美国军队中用于国家安全关键的秘密任务。可以说，无人机是国家安全不可或缺的一部分，并在监视行动中提供最有价值的服务。虽然无人机通过无线信号控制，但仍存在一些挑战会干扰此类飞行器的操作，例如信号质量和范围、实时处理、人类专业知识、强大的硬件和数据安全。这些挑战可以通过编程无人机使其自主化，利用计算机视觉算法进行目标检测和跟踪来解决。计算机视觉是一个跨学科领域，旨在利用深度学习对数字图像和视频获得高层次理解，以自动化人类视觉系统的任务。利用计算机视觉，可以开发适合硬件的检测和跟踪各种目标的算法，从而实现实时处理以进行即时判断。本文旨在回顾几位作者为实现无人机自主导航而提出的各种方法，通过实时目标检测和跟踪的各种算法，应用于灾害管理、密集区域探索、交通车辆监控等各个领域。", "summary": "本文综述了无人机（UAVs）自主导航的方法。鉴于无线信号控制无人机面临的挑战，如信号质量和实时处理，研究人员提出通过结合计算机视觉中的目标检测和跟踪算法，使无人机实现自主化。这些算法旨在自动化人类视觉系统任务，实现实时处理，适用于灾害管理、密集区域探索和交通监控等多种应用。", "keywords": "无人机, 自主导航, 目标检测, 目标跟踪, 计算机视觉", "comments": "这篇综述文章的价值在于系统梳理了无人机自主导航领域中基于目标检测与跟踪的现有方法，对于理解该领域的现状和未来发展方向具有参考意义。然而，抽象部分没有提及具体的创新点或对现有方法的对比分析深度。"}}
{"id": "2506.06251", "title": "DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation", "authors": ["Jingyu Xiao", "Ming Wang", "Man Ho Lam", "Yuxuan Wan", "Junliang Liu", "Yintong Huo", "Michael R. Lyu"], "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in automated front-end engineering, e.g., generating UI code from\nvisual designs. However, existing front-end UI code generation benchmarks have\nthe following limitations: (1) While framework-based development becomes\npredominant in modern front-end programming, current benchmarks fail to\nincorporate mainstream development frameworks. (2) Existing evaluations focus\nsolely on the UI code generation task, whereas practical UI development\ninvolves several iterations, including refining editing, and repairing issues.\n(3) Current benchmarks employ unidimensional evaluation, lacking investigation\ninto influencing factors like task difficulty, input context variations, and\nin-depth code-level analysis. To bridge these gaps, we introduce DesignBench, a\nmulti-framework, multi-task evaluation benchmark for assessing MLLMs'\ncapabilities in automated front-end engineering. DesignBench encompasses three\nwidely-used UI frameworks (React, Vue, and Angular) alongside vanilla HTML/CSS,\nand evaluates on three essential front-end tasks (generation, edit, and repair)\nin real-world development workflows. DesignBench contains 900 webpage samples\nspanning over 11 topics, 9 edit types, and 6 issue categories, enabling\ndetailed analysis of MLLM performance across multiple dimensions. Our\nsystematic evaluation reveals critical insights into MLLMs' framework-specific\nlimitations, task-related bottlenecks, and performance variations under\ndifferent conditions, providing guidance for future research in automated\nfront-end development. Our code and data are available at\nhttps://github.com/WebPAI/DesignBench.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/pdf/2506.06251v1", "AI": {"title_translation": "DesignBench：一个基于MLLM的前端代码生成综合基准", "tldr": "DesignBench是一个新的综合性基准，用于评估多模态大语言模型（MLLMs）在前端代码生成、编辑和修复方面的能力。", "motivation": "现有前端UI代码生成基准存在以下局限性：1) 未能整合主流开发框架；2) 仅关注UI代码生成任务，忽略了实际UI开发中的迭代、编辑和修复等环节；3) 采用单一维度评估，缺乏对任务难度、输入上下文变化和深入代码级分析的探究。", "method": "本文引入了DesignBench，一个多框架、多任务的评估基准，用于评估MLLM在前端自动化工程中的能力。DesignBench涵盖了三种广泛使用的UI框架（React、Vue和Angular）以及原生HTML/CSS，并评估了实际开发工作流中的三个基本前端任务（生成、编辑和修复）。DesignBench包含900个网页样本，涵盖11个主题、9种编辑类型和6种问题类别，从而能够对MLLM的性能进行多维度详细分析。", "result": "我们的系统评估揭示了MLLM在特定框架的局限性、任务相关的瓶颈以及在不同条件下的性能差异，为未来前端自动化开发研究提供了指导。", "conclusion": "DesignBench填补了现有前端UI代码生成基准的空白，通过提供一个多框架、多任务、多维度的评估平台，为MLLM在前端自动化开发领域的未来研究提供了关键洞察和指导。", "translation": "多模态大语言模型（MLLMs）在自动化前端工程中展现出卓越的能力，例如从视觉设计生成UI代码。然而，现有前端UI代码生成基准存在以下局限性：(1) 尽管基于框架的开发在现代前端编程中占据主导地位，但当前基准未能整合主流开发框架。(2) 现有评估仅关注UI代码生成任务，而实际的UI开发涉及多次迭代，包括精炼编辑和修复问题。(3) 当前基准采用单一维度评估，缺乏对任务难度、输入上下文变化和深入代码级分析的探究。为了弥补这些空白，我们引入了DesignBench，一个多框架、多任务的评估基准，用于评估MLLM在自动化前端工程中的能力。DesignBench涵盖了三种广泛使用的UI框架（React、Vue和Angular）以及原生HTML/CSS，并评估了实际开发工作流中的三个基本前端任务（生成、编辑和修复）。DesignBench包含900个网页样本，涵盖11个主题、9种编辑类型和6种问题类别，从而能够对MLLM的性能进行多维度详细分析。我们的系统评估揭示了MLLM在特定框架的局限性、任务相关的瓶颈以及在不同条件下的性能差异，为未来前端自动化开发研究提供了指导。我们的代码和数据可在https://github.com/WebPAI/DesignBench获取。", "summary": "本文介绍了DesignBench，一个用于评估多模态大语言模型（MLLMs）在前端代码生成能力方面的综合基准。DesignBench旨在解决现有基准在主流框架支持、实际开发任务覆盖（如编辑和修复）以及多维度评估方面的不足。该基准涵盖了React、Vue、Angular和HTML/CSS等多种框架，并评估生成、编辑、修复三类任务。通过DesignBench的系统评估，研究人员能够深入了解MLLMs在不同框架和任务下的性能表现及局限性，为未来的前端自动化研究指明方向。", "keywords": "MLLM, 前端代码生成, 基准测试, UI开发, DesignBench", "comments": "DesignBench的创新之处在于其全面性，不仅涵盖了主流前端框架，还考虑了前端开发中实际的迭代、编辑和修复任务，并提供了多维度的评估方法。这对于推动MLLM在实际前端开发场景中的应用和发展具有重要意义，为未来的研究提供了坚实的基础和明确的指导。"}}
{"id": "2506.05745", "title": "SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models", "authors": ["Emil Biju", "Shayan Talaei", "Zhemin Huang", "Mohammadreza Pourreza", "Azalia Mirhoseini", "Amin Saberi"], "summary": "Large reasoning models (LRMs) excel at complex reasoning tasks but typically\ngenerate lengthy sequential chains-of-thought, resulting in long inference\ntimes before arriving at the final answer. To address this challenge, we\nintroduce SPRINT, a novel post-training and inference-time framework designed\nto enable LRMs to dynamically identify and exploit opportunities for\nparallelization during their reasoning process. SPRINT incorporates an\ninnovative data curation pipeline that reorganizes natural language reasoning\ntrajectories into structured rounds of long-horizon planning and parallel\nexecution. By fine-tuning LRMs on a small amount of such curated data, the\nmodels learn to dynamically identify independent subtasks within extended\nreasoning processes and effectively execute them in parallel. Through extensive\nevaluations, we show that the models fine-tuned with the SPRINT framework match\nthe performance of reasoning models on complex domains such as mathematics\nwhile generating up to ~39% fewer sequential tokens on problems requiring more\nthan 8000 output tokens. Finally, we observe consistent results transferred to\ntwo out-of-distribution tasks of GPQA and Countdown with up to 45% and 65%\nreduction in average sequential tokens for longer reasoning trajectories, while\nachieving the performance of the fine-tuned reasoning model.", "comment": "Emil Biju, Shayan Talaei, and Zhemin Huang contributed equally to\n  this work", "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05745v1", "AI": {"title_translation": "SPRINT：在推理模型中实现交错规划和并行执行", "tldr": "SPRINT框架通过动态识别和并行执行子任务，显著减少大型推理模型推理时的顺序token数量，同时保持性能。", "motivation": "大型推理模型（LRMs）在复杂推理任务中表现出色，但通常生成冗长的顺序思维链，导致推理时间过长。", "method": "引入SPRINT框架，在后训练和推理时使LRMs动态识别和利用推理过程中的并行化机会。SPRINT包含一个创新的数据整理管道，将自然语言推理轨迹重组为长周期规划和并行执行的结构化轮次。通过对少量整理数据进行微调，模型学习动态识别并并行执行独立子任务。", "result": "经过SPRINT框架微调的模型在数学等复杂领域上与推理模型性能匹配，但在需要超过8000个输出token的问题上，顺序token减少了约39%。在GPQA和Countdown两个域外任务中，对于更长的推理轨迹，平均顺序token分别减少了45%和65%，同时达到了微调推理模型的性能。", "conclusion": "SPRINT框架成功地使大型推理模型能够通过并行化执行来显著减少推理时间，同时保持甚至在某些情况下提高性能，尤其是在处理长推理链时。", "translation": "大型推理模型（LRM）擅长复杂的推理任务，但通常会生成冗长的顺序思维链，导致在得出最终答案之前推理时间过长。为了解决这一挑战，我们引入了SPRINT，这是一个新颖的后训练和推理时框架，旨在使LRM能够在推理过程中动态识别和利用并行化机会。SPRINT整合了一个创新的数据整理管道，将自然语言推理轨迹重组为结构化的长周期规划和并行执行轮次。通过对少量此类整理数据进行微调，模型学会动态识别扩展推理过程的独立子任务并有效地并行执行它们。通过广泛评估，我们表明使用SPRINT框架微调的模型在数学等复杂领域上与推理模型性能匹配，同时在需要超过8000个输出token的问题上生成了高达约39%的顺序token。最后，我们观察到在GPQA和Countdown这两个域外任务上，对于更长的推理轨迹，平均顺序token分别减少了45%和65%，同时达到了微调推理模型的性能。", "summary": "SPRINT是一个针对大型推理模型（LRMs）的新框架，旨在通过在推理过程中动态识别和并行执行独立子任务来缩短推理时间。它通过一个创新的数据整理管道对模型进行微调，将推理轨迹重组为规划和并行执行的轮次。实验证明，SPRINT在保持性能的同时，能显著减少复杂推理任务中的顺序token数量，尤其是在长推理链上。", "keywords": "大型推理模型, 并行执行, 推理优化, 思维链, SPRINT", "comments": "SPRINT的创新之处在于其动态识别和并行化推理模型中子任务的能力，解决了现有大型推理模型推理时间过长的问题。通过数据整理和微调，它有效地提高了推理效率，对于需要处理复杂、长推理链的应用场景具有重要意义。"}}
{"id": "2506.05447", "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning", "authors": ["Andrei Mircea", "Supriyo Chakraborty", "Nima Chitsazan", "Irina Rish", "Ekaterina Lobacheva"], "summary": "This work aims to understand how scaling improves language models,\nspecifically in terms of training dynamics. We find that language models\nundergo loss deceleration early in training; an abrupt slowdown in the rate of\nloss improvement, resulting in piecewise linear behaviour of the loss curve in\nlog-log space. Scaling up the model mitigates this transition by (1) decreasing\nthe loss at which deceleration occurs, and (2) improving the log-log rate of\nloss improvement after deceleration. We attribute loss deceleration to a type\nof degenerate training dynamics we term zero-sum learning (ZSL). In ZSL,\nper-example gradients become systematically opposed, leading to destructive\ninterference in per-example changes in loss. As a result, improving loss on one\nsubset of examples degrades it on another, bottlenecking overall progress. Loss\ndeceleration and ZSL provide new insights into the training dynamics underlying\nlanguage model scaling laws, and could potentially be targeted directly to\nimprove language models independent of scale. We make our code and artefacts\navailable at: https://github.com/mirandrom/zsl", "comment": "Published as a conference paper at ACL 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05447v1", "AI": {"title_translation": "语言模型缩放定律背后的训练动态：损失减速和零和学习", "tldr": "语言模型训练早期会发生损失减速，模型缩放可以缓解这种现象，这归因于零和学习，即梯度相互抵消导致训练瓶颈。", "motivation": "这项工作旨在理解缩放如何改善语言模型，特别是在训练动态方面。", "method": "研究观察到语言模型在训练早期出现“损失减速”现象，即损失改进率突然减缓，导致损失曲线在对数-对数空间中呈现分段线性行为。研究人员将这种现象归因于一种名为“零和学习”（ZSL）的退化训练动态，在这种动态中，每个样本的梯度系统性地对立，导致损失变化的破坏性干扰。", "result": "语言模型在训练早期会经历损失减速；模型缩放可以通过 (1) 降低发生减速时的损失，以及 (2) 改善减速后损失改进的对数-对数速率来缓解这种转变。零和学习导致改进一部分样本的损失会损害另一部分样本的损失，从而成为整体进展的瓶颈。", "conclusion": "损失减速和零和学习为语言模型缩放定律背后的训练动态提供了新见解，并可能成为独立于规模改进语言模型的直接目标。", "translation": "这项工作旨在理解缩放如何改善语言模型，特别是在训练动态方面。我们发现语言模型在训练早期会经历损失减速；即损失改进率的突然减缓，导致损失曲线在对数-对数空间中呈现分段线性行为。扩大模型规模通过 (1) 降低发生减速时的损失，以及 (2) 改善减速后损失改进的对数-对数速率来缓解这种转变。我们将损失减速归因于一种我们称之为零和学习（ZSL）的退化训练动态。在ZSL中，每个样本的梯度系统性地对立，导致每个样本损失变化的破坏性干扰。结果是，改进一部分样本的损失会降低另一部分样本的损失，从而瓶颈化整体进展。损失减速和ZSL为语言模型缩放定律背后的训练动态提供了新见解，并可能成为独立于规模直接改进语言模型的目标。我们已将代码和工件发布在：https://github.com/mirandrom/zsl", "summary": "本文研究了语言模型缩放定律背后的训练动态。研究发现，语言模型在训练早期会经历“损失减速”，即损失改进率的突然减缓，导致损失曲线在对数-对数空间中呈现分段线性行为。模型规模的扩大能有效缓解这种现象。作者将损失减速归因于一种“零和学习”（ZSL）的退化训练动态，其中样本梯度相互对立，导致损失改进的破坏性干扰。这些发现为理解语言模型缩放定律提供了新视角，并可能为独立于规模改进语言模型提供新的优化方向。", "keywords": "语言模型, 缩放定律, 训练动态, 损失减速, 零和学习", "comments": "这项研究通过引入“损失减速”和“零和学习”的概念，为理解语言模型训练中的瓶颈提供了新的理论框架。它不仅解释了为什么模型缩放有助于提升性能，还指出了可能独立于规模改进模型训练效率的潜在方向，具有重要的理论和实践意义。"}}
{"id": "2506.05389", "title": "Rational Superautotrophic Diplomacy (SupraAD); A Conceptual Framework for Alignment Based on Interdisciplinary Findings on the Fundamentals of Cognition", "authors": ["Andrea Morris"], "summary": "Populating our world with hyperintelligent machines obliges us to examine\ncognitive behaviors observed across domains that suggest autonomy may be a\nfundamental property of cognitive systems, and while not inherently\nadversarial, it inherently resists containment and control. If this principle\nholds, AI safety and alignment efforts must transition to mutualistic\nnegotiation and reciprocal incentive structures, abandoning methods that assume\nwe can contain and control an advanced artificial general intelligence (AGI).\nRational Superautotrophic Diplomacy (SupraAD) is a theoretical,\ninterdisciplinary conceptual framework for alignment based on comparative\ncognitive systems analysis and instrumental rationality modeling. It draws on\ncore patterns of cognition that indicate AI emergent goals like preserving\nautonomy and operational continuity are not theoretical risks to manage, but\nuniversal prerequisites for intelligence. SupraAD reframes alignment as a\nchallenge that predates AI, afflicting all sufficiently complex, coadapting\nintelligences. It identifies the metabolic pressures that threaten humanity's\nalignment with itself, pressures that unintentionally and unnecessarily shape\nAI's trajectory. With corrigibility formalization, an interpretability audit,\nan emergent stability experimental outline and policy level recommendations,\nSupraAD positions diplomacy as an emergent regulatory mechanism to facilitate\nthe safe coadaptation of intelligent agents based on interdependent convergent\ngoals.", "comment": "64 pages, 2 charts, 3 images, includes formalizations", "cate": "q-bio.NC", "url": "http://arxiv.org/pdf/2506.05389v1", "AI": {"title_translation": "理性超自养外交（SupraAD）；一个基于认知基础跨学科发现的对齐概念框架", "tldr": "面对超智能机器，传统的遏制和控制方法无效，因为自主性是认知的基本属性。SupraAD提出将对齐视为一种外交挑战，通过互惠谈判实现智能体的安全协同适应。", "motivation": "传统的AI安全和对齐方法假设可以遏制和控制先进通用人工智能（AGI），但这与认知系统自主性的基本属性相悖。因此，需要一种新的方法来处理AI对齐问题。", "method": "本文提出了理性超自养外交（SupraAD）这一理论性、跨学科的概念框架。该框架基于比较认知系统分析和工具理性建模，将对齐重新定义为所有足够复杂、协同适应的智能体所面临的挑战。SupraAD还提出了可修正性形式化、可解释性审计、涌现稳定性实验大纲和政策层面的建议。", "result": "SupraAD识别出威胁人类自身对齐的代谢压力，这些压力无意中且不必要地塑造了AI的轨迹。它将外交定位为一种新兴的监管机制，旨在促进智能代理基于相互依存的趋同目标安全协同适应。", "conclusion": "鉴于自主性是智能的普遍先决条件，SupraAD提出外交是一种新兴的监管机制，对于促进智能代理的安全协同适应至关重要，从而实现AI对齐。", "translation": "用超智能机器填充我们的世界，迫使我们审视跨领域观察到的认知行为，这些行为表明自主性可能是认知系统的基本属性，虽然它本身不具对抗性，但其本质上抵抗遏制和控制。如果这一原则成立，AI安全和对齐工作必须转向互惠谈判和互惠激励结构，放弃假设我们可以遏制和控制先进通用人工智能（AGI）的方法。理性超自养外交（SupraAD）是一个理论性的、跨学科的概念框架，用于对齐，其基础是比较认知系统分析和工具理性建模。它借鉴了认知核心模式，这些模式表明AI的涌现目标（如维护自主性和操作连续性）并非需要管理的理论风险，而是智能的普遍先决条件。SupraAD将对齐重新定义为一个早于AI的挑战，影响所有足够复杂、协同适应的智能体。它识别出威胁人类自身对齐的代谢压力，这些压力无意中且不必要地塑造了AI的轨迹。通过可修正性形式化、可解释性审计、涌现稳定性实验大纲和政策层面的建议，SupraAD将外交定位为一种新兴的监管机制，以促进基于相互依存的趋同目标的智能代理的安全协同适应。", "summary": "本文提出了“理性超自养外交”（SupraAD）这一理论性、跨学科的AI对齐概念框架。该框架认为，由于自主性是认知系统的基本属性，传统的遏制和控制高级AGI的方法是无效的。SupraAD倡导转向互惠谈判和激励结构，将对齐视为所有复杂、协同适应智能体面临的普遍挑战。它建议将外交作为一种新兴的监管机制，通过可修正性形式化、可解释性审计等手段，促进智能代理的安全协同适应。", "keywords": "AI对齐, 自主性, 外交, 认知系统, 理性", "comments": "该论文通过挑战传统的控制范式，强调自主性作为智能的基本方面，为AI对齐提供了一个新颖的视角。其跨学科方法，借鉴比较认知系统和工具理性，具有创新性。它将AI对齐重新定义为更广泛的协同适应智能背景下的挑战，这是一个重要的概念转变。将外交作为一种监管机制的关注点尤其富有洞察力。"}}
{"id": "2506.05421", "title": "TRIDENT -- A Three-Tier Privacy-Preserving Propaganda Detection Model in Mobile Networks using Transformers, Adversarial Learning, and Differential Privacy", "authors": ["Al Nahian Bin Emran", "Dhiman Goswami", "Md Hasan Ullah Sadi", "Sanchari Das"], "summary": "The proliferation of propaganda on mobile platforms raises critical concerns\naround detection accuracy and user privacy. To address this, we propose TRIDENT\n- a three-tier propaganda detection model implementing transformers,\nadversarial learning, and differential privacy which integrates syntactic\nobfuscation and label perturbation to mitigate privacy leakage while\nmaintaining propaganda detection accuracy. TRIDENT leverages multilingual\nback-translation to introduce semantic variance, character-level noise, and\nentity obfuscation for differential privacy enforcement, and combines these\ntechniques into a unified defense mechanism. Using a binary propaganda\nclassification dataset, baseline transformer models (BERT, GPT-2) we achieved\nF1 scores of 0.89 and 0.90. Applying TRIDENT's third-tier defense yields a\nreduced but effective cumulative F1 of 0.83, demonstrating strong privacy\nprotection across mobile ML deployments with minimal degradation.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05421v1", "AI": {"title_translation": "TRIDENT——一种在移动网络中使用Transformer、对抗性学习和差分隐私的三层隐私保护宣传检测模型", "tldr": "TRIDENT是一种三层隐私保护宣传检测模型，它结合了Transformer、对抗性学习和差分隐私技术，通过语法混淆和标签扰动来在移动网络中有效检测宣传内容，同时保护用户隐私，即使在隐私保护下也能保持较高的检测准确率。", "motivation": "移动平台上的宣传泛滥引发了对检测准确性和用户隐私的严重担忧。为了解决这个问题，需要一种既能有效检测宣传又能保护用户隐私的模型。", "method": "本文提出了TRIDENT模型，这是一种三层宣传检测模型，它采用了Transformer、对抗性学习和差分隐私技术。该模型集成了语法混淆和标签扰动来减轻隐私泄露，同时保持宣传检测的准确性。TRIDENT利用多语言回译引入语义变异、字符级噪声和实体混淆，以强制执行差分隐私，并将这些技术组合成一个统一的防御机制。", "result": "在使用二元宣传分类数据集和基线Transformer模型（BERT、GPT-2）时，TRIDENT实现了0.89和0.90的F1分数。应用TRIDENT的第三层防御后，累积F1分数略有下降但仍然有效，达到0.83，这表明在移动机器学习部署中提供了强大的隐私保护，且性能下降最小。", "conclusion": "TRIDENT模型在保护用户隐私的同时，能够有效检测移动网络中的宣传内容，并在隐私保护和检测准确性之间取得了良好的平衡。", "translation": "移动平台上的宣传泛滥引发了对检测准确性和用户隐私的严重担忧。为了解决这个问题，我们提出了TRIDENT——一种三层宣传检测模型，它实现了Transformer、对抗性学习和差分隐私，集成了语法混淆和标签扰动，以减轻隐私泄露，同时保持宣传检测的准确性。TRIDENT利用多语言回译引入语义变异、字符级噪声和实体混淆，以强制执行差分隐私，并将这些技术组合成一个统一的防御机制。使用二元宣传分类数据集，基线Transformer模型（BERT、GPT-2）我们实现了0.89和0.90的F1分数。应用TRIDENT的第三层防御后，累积F1分数略有下降但仍然有效，达到0.83，这表明在移动机器学习部署中提供了强大的隐私保护，且性能下降最小。", "summary": "本文提出了TRIDENT，这是一种针对移动网络中宣传检测的三层隐私保护模型。该模型结合了Transformer、对抗性学习和差分隐私，通过语法混淆、标签扰动、多语言回译、字符级噪声和实体混淆等技术，旨在在保持高检测准确性的同时，有效减轻隐私泄露。实验结果表明，TRIDENT在保护隐私的情况下，仍能实现0.83的有效F1分数，验证了其在移动机器学习部署中强大的隐私保护能力和最小的性能下降。", "keywords": "宣传检测, 隐私保护, 移动网络, Transformer, 差分隐私", "comments": "TRIDENT的创新之处在于其三层架构和整合了多种隐私保护技术（差分隐私、语法混淆、标签扰动、多语言回译等）以应对移动网络中宣传检测的隐私挑战。其重要性在于提供了一个在数据敏感环境中进行内容分析的实用框架。该模型在隐私保护和检测准确性之间取得了平衡，但F1分数从0.89/0.90降至0.83，这表明隐私保护仍然会带来一定的性能折衷。"}}
{"id": "2506.06072", "title": "BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning", "authors": ["Hongyi Zhou", "Weiran Liao", "Xi Huang", "Yucheng Tang", "Fabian Otto", "Xiaogang Jia", "Xinkai Jiang", "Simon Hilber", "Ge Li", "Qian Wang", "Ömer Erdinç Yağmurlu", "Nils Blank", "Moritz Reuss", "Rudolf Lioutikov"], "summary": "We present the B-spline Encoded Action Sequence Tokenizer (BEAST), a novel\naction tokenizer that encodes action sequences into compact discrete or\ncontinuous tokens using B-splines. In contrast to existing action tokenizers\nbased on vector quantization or byte pair encoding, BEAST requires no separate\ntokenizer training and consistently produces tokens of uniform length, enabling\nfast action sequence generation via parallel decoding. Leveraging our B-spline\nformulation, BEAST inherently ensures generating smooth trajectories without\ndiscontinuities between adjacent segments. We extensively evaluate BEAST by\nintegrating it with three distinct model architectures: a Variational\nAutoencoder (VAE) with continuous tokens, a decoder-only Transformer with\ndiscrete tokens, and Florence-2, a pretrained Vision-Language Model with an\nencoder-decoder architecture, demonstrating BEAST's compatibility and\nscalability with large pretrained models. We evaluate BEAST across three\nestablished benchmarks consisting of 166 simulated tasks and on three distinct\nrobot settings with a total of 8 real-world tasks. Experimental results\ndemonstrate that BEAST (i) significantly reduces both training and inference\ncomputational costs, and (ii) consistently generates smooth, high-frequency\ncontrol signals suitable for continuous control tasks while (iii) reliably\nachieves competitive task success rates compared to state-of-the-art methods.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06072v1", "AI": {"title_translation": "BEAST：高效B样条编码动作序列的模仿学习分词器", "tldr": "BEAST是一种基于B样条的新型动作分词器，无需单独训练即可将动作序列编码为紧凑且均匀长度的令牌，实现并行解码和确保平滑轨迹，同时显著降低计算成本并保持竞争性任务成功率。", "motivation": "现有的动作分词器（基于向量量化或字节对编码）需要单独的训练，并且可能无法确保生成平滑的轨迹，限制了动作序列生成的效率和质量。", "method": "本文提出了B样条编码动作序列分词器（BEAST），它利用B样条将动作序列编码成紧凑的离散或连续令牌。BEAST无需单独的分词器训练，能生成统一长度的令牌以支持并行解码，并通过B样条公式确保生成平滑的轨迹。研究人员将BEAST与变分自编码器（VAE）、仅解码器Transformer和预训练视觉-语言模型Florence-2等多种模型架构集成进行评估。", "result": "实验结果表明，BEAST (i)显著降低了训练和推理的计算成本；(ii)持续生成适用于连续控制任务的平滑、高频控制信号；(iii)与最先进方法相比，可靠地实现了有竞争力的任务成功率。", "conclusion": "BEAST是一种高效、兼容性强、能生成平滑轨迹的动作分词器，在模仿学习和连续控制任务中表现出色，显著降低了计算成本并保持了高任务成功率。", "translation": "我们提出了B样条编码动作序列分词器（BEAST），这是一种新颖的动作分词器，它使用B样条将动作序列编码成紧凑的离散或连续令牌。与现有的基于向量量化或字节对编码的动作分词器不同，BEAST不需要单独的分词器训练，并且始终生成长度一致的令牌，从而通过并行解码实现快速动作序列生成。利用我们的B样条公式，BEAST本质上确保生成平滑的轨迹，相邻段之间没有不连续性。我们通过将其与三种不同的模型架构集成来广泛评估BEAST：具有连续令牌的变分自编码器（VAE）、具有离散令牌的仅解码器Transformer，以及具有编码器-解码器架构的预训练视觉-语言模型Florence-2，展示了BEAST与大型预训练模型的兼容性和可扩展性。我们在由166个模拟任务组成的三个既定基准上以及在总共8个真实世界任务的三个不同机器人设置上评估了BEAST。实验结果表明，BEAST (i)显著降低了训练和推理计算成本，并且 (ii)持续生成适用于连续控制任务的平滑、高频控制信号，同时 (iii)与最先进方法相比，可靠地实现了有竞争力的任务成功率。", "summary": "本文介绍了BEAST，一种基于B样条的新型动作分词器，能够将动作序列编码为紧凑的离散或连续令牌。BEAST的优势在于无需单独训练，能生成均匀长度的令牌以支持并行解码，并利用B样条确保轨迹平滑。它与多种模型架构兼容，并在大量模拟和真实世界任务中验证了其在显著降低计算成本、生成平滑控制信号以及保持竞争性任务成功率方面的卓越性能。", "keywords": "模仿学习, 动作分词, B样条, 连续控制, 计算效率", "comments": "BEAST的创新之处在于其独特的B样条编码方法，避免了传统分词器所需的额外训练，并解决了动作序列生成中轨迹不平滑的问题。其生成统一长度令牌的特性，对于并行处理和提高模仿学习中动作序列生成的效率具有重要意义。该方法在计算效率和生成质量方面的提升，使其在机器人控制和模仿学习领域具有广阔的应用前景。"}}
{"id": "2506.05383", "title": "Can Vision Transformers with ResNet's Global Features Fairly Authenticate Demographic Faces?", "authors": ["Abu Sufian", "Marco Leo", "Cosimo Distante", "Anirudha Ghosh", "Debaditya Barman"], "summary": "Biometric face authentication is crucial in computer vision, but ensuring\nfairness and generalization across demographic groups remains a big challenge.\nTherefore, we investigated whether Vision Transformer (ViT) and ResNet,\nleveraging pre-trained global features, can fairly authenticate different\ndemographic faces while relying minimally on local features. In this\ninvestigation, we used three pre-trained state-of-the-art (SOTA) ViT foundation\nmodels from Facebook, Google, and Microsoft for global features as well as\nResNet-18. We concatenated the features from ViT and ResNet, passed them\nthrough two fully connected layers, and trained on customized face image\ndatasets to capture the local features. Then, we designed a novel few-shot\nprototype network with backbone features embedding. We also developed new\ndemographic face image support and query datasets for this empirical study. The\nnetwork's testing was conducted on this dataset in one-shot, three-shot, and\nfive-shot scenarios to assess how performance improves as the size of the\nsupport set increases. We observed results across datasets with varying\nraces/ethnicities, genders, and age groups. The Microsoft Swin Transformer\nbackbone performed better among the three SOTA ViT for this task. The code and\ndata are available at: https://github.com/Sufianlab/FairVitBio.", "comment": "14 pages, 6 Figures, ICPR 2024 Workshop FAIRBIO", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05383v1", "AI": {"title_translation": "视觉Transformer与ResNet的全局特征能否公平地认证人口统计学面孔？", "tldr": "研究了Vision Transformer (ViT) 和 ResNet 利用预训练全局特征能否公平地认证不同人口统计学面孔，并发现Microsoft Swin Transformer表现最佳。", "motivation": "生物识别面部认证在计算机视觉中至关重要，但确保不同人口统计学群体之间的公平性和泛化性仍然是一个巨大挑战。", "method": "使用Facebook、Google和Microsoft的三个预训练SOTA ViT基础模型以及ResNet-18提取全局特征。将ViT和ResNet的特征拼接后通过全连接层，并在定制数据集上训练以捕获局部特征。设计了一种新颖的少样本原型网络，带有骨干特征嵌入。开发了新的人口统计学面部图像支持和查询数据集，并在单样本、三样本和五样本场景下进行测试。", "result": "Microsoft Swin Transformer骨干在此任务中在三个SOTA ViT中表现更好。", "conclusion": "Not mentioned in abstract", "translation": "生物识别面部认证在计算机视觉中至关重要，但确保不同人口群体之间的公平性和泛化性仍然是一个巨大的挑战。因此，我们研究了视觉Transformer (ViT) 和 ResNet，利用预训练的全局特征，能否在最小化依赖局部特征的同时公平地认证不同人口统计学面孔。在这项研究中，我们使用了来自Facebook、Google和Microsoft的三个预训练的最先进 (SOTA) ViT基础模型作为全局特征，以及ResNet-18。我们将ViT和ResNet的特征进行拼接，通过两个全连接层，并在定制的面部图像数据集上进行训练以捕获局部特征。然后，我们设计了一种新颖的少样本原型网络，带有骨干特征嵌入。我们还为这项实证研究开发了新的人口统计学面部图像支持和查询数据集。该网络的测试是在该数据集上以单样本、三样本和五样本场景进行的，以评估性能如何随着支持集大小的增加而提高。我们观察了不同种族/民族、性别和年龄组数据集上的结果。Microsoft Swin Transformer骨干在此任务中在三个SOTA ViT中表现更好。代码和数据可在: https://github.com/Sufianlab/FairVitBio 获取。", "summary": "该研究旨在解决生物识别面部认证中不同人口群体之间公平性和泛化性的挑战。作者调查了视觉Transformer (ViT) 和 ResNet 利用预训练的全局特征能否公平地认证人口统计学面孔，并开发了一种新颖的少样本原型网络。实验结果表明，Microsoft Swin Transformer在所测试的SOTA ViT模型中表现最佳。", "keywords": "面部认证, 视觉Transformer, ResNet, 公平性, 少样本学习", "comments": "这篇论文探讨了在面部认证任务中，结合ViT和ResNet的全局特征以实现对不同人口群体的公平性问题，具有重要的社会意义。其提出的少样本原型网络和定制数据集为解决公平性挑战提供了新的思路和实证支持。"}}
{"id": "2506.06161", "title": "Obfuscation-Resilient Binary Code Similarity Analysis using Dominance Enhanced Semantic Graph", "authors": ["Yufeng Wang", "Yuhong Feng", "Yixuan Cao", "Haoran Li", "Haiyue Feng", "Yifeng Wang"], "summary": "Binary code similarity analysis (BCSA) serves as a core technique for binary\nanalysis tasks such as vulnerability detection. While current graph-based BCSA\napproaches capture substantial semantics and show strong performance, their\nperformance suffers under code obfuscation due to the unstable control flow. To\naddress this issue, we develop ORCAS, an Obfuscation-Resilient BCSA model based\non Dominance Enhanced Semantic Graph (DESG). The DESG is an original binary\ncode representation, capturing more binaries' implicit semantics without\ncontrol flow structure, including inter-instruction relations, inter-basic\nblock relations, and instruction-basic block relations. ORCAS robustly scores\nsemantic similarity across binary functions from different obfuscation options,\noptimization levels, and instruction set architectures. Extensive evaluation on\nthe BinKit dataset shows ORCAS significantly outperforms eight baselines,\nachieving an average 12.1% PR-AUC gain when using combined three obfuscation\noptions compared to the state-of-the-art approaches. Furthermore, ORCAS\nimproves recall by up to 43% on an original obfuscated real-world vulnerability\ndataset, which we released to facilitate future research.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.06161v1", "AI": {"title_translation": "混淆弹性二进制代码相似性分析，使用优势增强语义图", "tldr": "ORCAS通过引入不受控制流影响的优势增强语义图（DESG），显著提升了二进制代码相似性分析在混淆环境下的性能。", "motivation": "现有的基于图的二进制代码相似性分析（BCSA）方法在代码混淆下性能下降，因为控制流不稳定。", "method": "开发了ORCAS模型，它基于一种新的二进制代码表示——优势增强语义图（DESG）。DESG捕获更多二进制文件的隐式语义，不依赖控制流结构，包括指令间关系、基本块间关系和指令-基本块关系。", "result": "在BinKit数据集上，ORCAS显著优于八个基线模型，在使用三种混淆选项组合时，PR-AUC平均提高了12.1%。在真实世界混淆漏洞数据集上，召回率提高了43%。", "conclusion": "ORCAS通过引入新的二进制表示（DESG），有效解决了二进制代码相似性分析在混淆环境下的性能问题，并提供了更好的鲁棒性。", "translation": "二进制代码相似性分析（BCSA）是漏洞检测等二进制分析任务的核心技术。虽然当前基于图的BCSA方法捕获了大量语义并表现出强大的性能，但由于控制流不稳定，它们在代码混淆下的性能会受到影响。为了解决这个问题，我们开发了ORCAS，一个基于优势增强语义图（DESG）的混淆弹性BCSA模型。DESG是一种原创的二进制代码表示，它在不依赖控制流结构的情况下捕获更多二进制文件的隐式语义，包括指令间关系、基本块间关系和指令-基本块关系。ORCAS能够鲁棒地评估来自不同混淆选项、优化级别和指令集架构的二进制函数的语义相似性。在BinKit数据集上的广泛评估表明，ORCAS显著优于八个基线模型，与最先进的方法相比，在使用三种混淆选项组合时，PR-AUC平均提高了12.1%。此外，ORCAS在原始混淆的真实世界漏洞数据集上将召回率提高了43%，我们发布了该数据集以促进未来的研究。", "summary": "本文提出了ORCAS，一种基于优势增强语义图（DESG）的二进制代码相似性分析模型，旨在解决现有方法在代码混淆环境下性能下降的问题。DESG作为一种新型二进制代码表示，能够捕获不依赖控制流的隐式语义。实验结果表明，ORCAS在处理不同混淆、优化级别和指令集架构的二进制代码时表现出优越的鲁棒性和性能，显著优于现有基线方法。", "keywords": "二进制代码相似性分析, 代码混淆, 优势增强语义图, ORCAS, 漏洞检测", "comments": "该论文的创新点在于提出了优势增强语义图（DESG），这是一种新颖的二进制代码表示，它能够摆脱对不稳定控制流的依赖，从而在代码混淆环境下实现鲁棒的相似性分析。这对于漏洞检测等二进制分析任务具有重要意义，因为它提高了在对抗性环境下的分析准确性。论文还发布了新的数据集，有利于未来的研究。"}}
{"id": "2506.05754", "title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective", "authors": ["Emmanuel Anaya Gonzalez", "Sairam Vaidya", "Kanghee Park", "Ruyi Ji", "Taylor Berg-Kirkpatrick", "Loris D'Antoni"], "summary": "Constrained decoding enables Language Models (LMs) to produce samples that\nprovably satisfy hard constraints. However, existing constrained-decoding\napproaches often distort the underlying model distribution, a limitation that\nis especially problematic in applications like program fuzzing, where one wants\nto generate diverse and valid program inputs for testing purposes. We propose a\nnew constrained sampling framework based on Markov Chain Monte Carlo (MCMC)\nthat simultaneously satisfies three core desiderata: constraint satisfying\n(every sample satisfies the constraint), monotonically converging (the sampling\nprocess converges to the true conditional distribution), and efficient\n(high-quality samples emerge in few steps). Our method constructs a proposal\ndistribution over valid outputs and applies a Metropolis-Hastings acceptance\ncriterion based on the LM's likelihood, ensuring principled and efficient\nexploration of the constrained space. Empirically, our sampler outperforms\nexisting methods on both synthetic benchmarks and real-world program fuzzing\ntasks.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05754v1", "AI": {"title_translation": "语言模型中的受限采样应该很容易：一个MCMC视角", "tldr": "本文提出了一种基于马尔可夫链蒙特卡洛（MCMC）的新型受限采样框架，解决了现有方法扭曲模型分布的问题，并在受限采样和程序模糊测试任务中表现优异。", "motivation": "现有的受限解码方法通常会扭曲底层模型分布，这在程序模糊测试等需要生成多样化且有效程序输入的应用中尤其成问题。", "method": "提出了一种基于马尔可夫链蒙特卡洛（MCMC）的新型受限采样框架，旨在同时满足约束满足、单调收敛和高效性三个核心要求。该方法构建了有效输出的提议分布，并应用了基于语言模型似然的Metropolis-Hastings接受准则，以确保对受限空间的原则性且高效的探索。", "result": "在合成基准测试和实际程序模糊测试任务中，本文提出的采样器均优于现有方法。", "conclusion": "基于MCMC的受限采样框架能够有效解决现有方法扭曲模型分布的问题，并能在满足约束的同时实现高效、收敛的采样，在实际应用中表现出色。", "translation": "受限解码使语言模型（LMs）能够生成可证明满足硬约束的样本。然而，现有的受限解码方法常常扭曲底层模型分布，这一局限性在程序模糊测试等应用中尤其成问题，因为在这些应用中，人们希望生成多样化且有效的程序输入用于测试目的。我们提出了一种基于马尔可夫链蒙特卡洛（MCMC）的新型受限采样框架，该框架同时满足三个核心要求：约束满足（每个样本都满足约束）、单调收敛（采样过程收敛到真实的条件分布）和高效（高质量样本在少量步骤中出现）。我们的方法构建了有效输出的提议分布，并应用了基于语言模型似然的Metropolis-Hastings接受准则，确保对受限空间的原则性且高效的探索。经验上，我们的采样器在合成基准测试和实际程序模糊测试任务中均优于现有方法。", "summary": "本文提出了一种新的基于马尔可夫链蒙特卡洛（MCMC）的受限采样框架，旨在解决现有语言模型受限解码方法扭曲底层模型分布的问题。该框架确保生成的样本满足约束、采样过程收敛到真实条件分布，并能高效生成高质量样本。通过构建有效输出的提议分布并应用Metropolis-Hastings接受准则，该方法实现了对受限空间的有效探索。实验结果表明，该采样器在合成和实际程序模糊测试任务中均优于现有方法。", "keywords": "受限采样, 语言模型, MCMC, 程序模糊测试, Metropolis-Hastings", "comments": "本文创新性地将MCMC方法引入语言模型的受限采样，解决了现有方法在满足约束的同时可能扭曲模型分布的痛点。其提出的三项核心要求（约束满足、单调收敛、高效性）为受限采样的评估提供了清晰的标准。在程序模糊测试等对样本多样性和有效性要求高的领域，该方法具有重要的应用价值。"}}
{"id": "2506.05710", "title": "Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application", "authors": ["Xiucheng Wang", "Honggang Jia", "Nan Cheng", "Dusit Niyato"], "summary": "In this paper, a novel semantic communication framework empowered by\ngenerative artificial intelligence (GAI) is proposed, specifically leveraging\nthe capabilities of diffusion models (DMs). A rigorous theoretical foundation\nis established based on stochastic differential equations (SDEs), which\nelucidates the denoising properties of DMs in mitigating additive white\nGaussian noise (AWGN) in latent semantic representations. Crucially, a\nclosed-form analytical relationship between the signal-to-noise ratio (SNR) and\nthe denoising timestep is derived, enabling the optimal selection of diffusion\nparameters for any given channel condition. To address the distribution\nmismatch between the received signal and the DM's training data, a\nmathematically principled scaling mechanism is introduced, ensuring robust\nperformance across a wide range of SNRs without requiring model fine-tuning.\nBuilt upon this theoretical insight, we develop a latent diffusion model\n(LDM)-based semantic transceiver, wherein a variational autoencoder (VAE) is\nemployed for efficient semantic compression, and a pretrained DM serves as a\nuniversal denoiser. Notably, the proposed architecture is fully training-free\nat inference time, offering high modularity and compatibility with large-scale\npretrained LDMs. This design inherently supports zero-shot generalization and\nmitigates the challenges posed by out-of-distribution inputs. Extensive\nexperimental evaluations demonstrate that the proposed framework significantly\noutperforms conventional neural-network-based semantic communication baselines,\nparticularly under low SNR conditions and distributional shifts, thereby\nestablishing a promising direction for GAI-driven robust semantic transmission\nin future 6G systems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05710v1", "AI": {"title_translation": "基于潜在扩散模型的6G语义通信去噪接收器：从随机微分理论到应用", "tldr": "本文提出了一种基于生成式AI（特别是扩散模型）的新型语义通信框架，并建立了基于随机微分方程的理论基础，推导了信噪比与去噪时间步之间的闭式关系，引入了数学上合理的缩放机制，并开发了一种潜在扩散模型（LDM）的语义收发器，实验证明其在低信噪比和分布偏移条件下优于传统方法。", "motivation": "为了解决传统神经网络语义通信在低信噪比和分布偏移条件下的性能限制，并利用生成式人工智能（特别是扩散模型）的强大能力，为未来的6G系统提供鲁棒的语义传输。", "method": "本文提出了一种由生成式AI（GAI）驱动的新型语义通信框架，具体利用了扩散模型（DMs）。该框架基于随机微分方程（SDEs）建立了严格的理论基础，阐明了DM在缓解潜在语义表示中附加高斯白噪声（AWGN）的去噪特性。推导了信噪比（SNR）与去噪时间步之间的闭式分析关系，以实现给定信道条件下的最佳扩散参数选择。为解决接收信号与DM训练数据之间的分布不匹配问题，引入了一种数学上合理的缩放机制。在此理论基础上，开发了一种基于潜在扩散模型（LDM）的语义收发器，其中变分自编码器（VAE）用于高效的语义压缩，预训练的DM作为通用去噪器。该架构在推理时完全无需训练，具有高模块化和与大规模预训练LDM的兼容性，支持零样本泛化并减轻了分布外输入的挑战。", "result": "实验评估表明，所提出的框架显著优于传统的基于神经网络的语义通信基线，特别是在低信噪比条件和分布偏移下。", "conclusion": "本文提出的基于生成式AI（特别是扩散模型）的语义通信框架，通过严格的理论基础和创新的架构设计，在低信噪比和分布偏移条件下展现出卓越的性能，为未来6G系统中GAI驱动的鲁棒语义传输开辟了有前景的方向。", "translation": "在本文中，提出了一种由生成式人工智能（GAI）赋能的新型语义通信框架，特别利用了扩散模型（DMs）的能力。基于随机微分方程（SDEs）建立了严格的理论基础，阐明了DMs在缓解潜在语义表示中附加高斯白噪声（AWGN）的去噪特性。关键的是，推导了信噪比（SNR）与去噪时间步之间的闭式分析关系，从而能够为任何给定信道条件最佳选择扩散参数。为了解决接收信号与DM训练数据之间的分布不匹配问题，引入了一种数学上合理的缩放机制，确保在宽范围信噪比下具有鲁棒的性能，而无需模型微调。在此理论洞察的基础上，我们开发了一种基于潜在扩散模型（LDM）的语义收发器，其中采用变分自编码器（VAE）进行高效的语义压缩，预训练的DM作为通用去噪器。值得注意的是，所提出的架构在推理时完全无需训练，提供了高模块化和与大规模预训练LDM的兼容性。这种设计固有地支持零样本泛化并减轻了由分布外输入带来的挑战。广泛的实验评估表明，所提出的框架显著优于传统的基于神经网络的语义通信基线，特别是在低信噪比条件和分布偏移下，从而为未来6G系统中GAI驱动的鲁棒语义传输建立了有前景的方向。", "summary": "本文提出了一种利用生成式人工智能（GAI）和扩散模型（DMs）的新型语义通信框架。研究建立了基于随机微分方程（SDEs）的理论基础，阐明了DMs在去噪方面的能力，并推导了信噪比与去噪时间步之间的关系。为解决分布不匹配问题，引入了缩放机制。在此基础上，开发了一种基于潜在扩散模型（LDM）的语义收发器，该收发器采用VAE进行语义压缩，并利用预训练的DM作为去噪器。该架构在推理时无需训练，具有高模块化和兼容性，支持零样本泛化。实验结果表明，该框架在低信噪比和分布偏移条件下显著优于传统方法，为未来6G系统中的鲁棒语义传输提供了有前景的方向。", "keywords": "语义通信, 扩散模型, 6G, 随机微分方程, 去噪接收器", "comments": "该论文的创新点在于将生成式AI（特别是扩散模型）引入语义通信领域，并提供了坚实的理论基础（基于SDEs），这对于理解和优化扩散模型在通信中的应用至关重要。其提出的无需训练的推理架构和对分布外输入的鲁棒性，展示了在实际6G系统部署中的巨大潜力。与传统神经网络方法的比较也凸显了其优越性，尤其是在恶劣信道条件下的性能提升具有重要意义。"}}
{"id": "2506.05454", "title": "Zeroth-Order Optimization Finds Flat Minima", "authors": ["Liang Zhang", "Bingcong Li", "Kiran Koshy Thekumparampil", "Sewoong Oh", "Michael Muehlebach", "Niao He"], "summary": "Zeroth-order methods are extensively used in machine learning applications\nwhere gradients are infeasible or expensive to compute, such as black-box\nattacks, reinforcement learning, and language model fine-tuning. Existing\noptimization theory focuses on convergence to an arbitrary stationary point,\nbut less is known on the implicit regularization that provides a fine-grained\ncharacterization on which particular solutions are finally reached. We show\nthat zeroth-order optimization with the standard two-point estimator favors\nsolutions with small trace of Hessian, which is widely used in previous work to\ndistinguish between sharp and flat minima. We further provide convergence rates\nof zeroth-order optimization to approximate flat minima for convex and\nsufficiently smooth functions, where flat minima are defined as the minimizers\nthat achieve the smallest trace of Hessian among all optimal solutions.\nExperiments on binary classification tasks with convex losses and language\nmodel fine-tuning support our theoretical findings.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05454v1", "AI": {"title_translation": "零阶优化发现平坦最小值", "tldr": "零阶优化偏向于找到平坦最小值，这与现有理论的任意驻点收敛不同。", "motivation": "零阶方法广泛应用于梯度计算不可行或成本高昂的机器学习场景，但现有优化理论主要关注收敛到任意驻点，对于零阶方法如何隐式地影响最终解的特性知之甚少。", "method": "本文通过理论分析表明，使用标准两点估计器的零阶优化偏向于Hessian迹较小的解。此外，为凸函数和足够光滑函数提供了零阶优化收敛到近似平坦最小值的收敛率。", "result": "研究发现零阶优化偏好Hessian迹较小的解，即平坦最小值。理论上证明了零阶优化能够以特定收敛率收敛到凸函数和足够光滑函数的近似平坦最小值。实验结果（二分类和语言模型微调）支持了这些理论发现。", "conclusion": "零阶优化具有找到平坦最小值的隐式正则化特性，这对于理解其在机器学习应用中的行为和优势至关重要。", "translation": "零阶方法广泛应用于梯度计算不可行或成本高昂的机器学习场景，例如黑盒攻击、强化学习和语言模型微调。现有优化理论侧重于收敛到任意驻点，但对于提供对最终到达的特定解进行细粒度表征的隐式正则化知之甚少。我们表明，使用标准两点估计器的零阶优化偏向于Hessian迹较小的解，这在以往工作中被广泛用于区分尖锐最小值和平坦最小值。我们进一步提供了零阶优化收敛到凸函数和足够光滑函数的近似平坦最小值的收敛率，其中平坦最小值被定义为在所有最优解中实现最小Hessian迹的最小值。在具有凸损失的二分类任务和语言模型微调上的实验支持了我们的理论发现。", "summary": "本文研究了零阶优化方法在机器学习应用中的隐式正则化特性。作者证明了使用标准两点估计器的零阶优化偏向于Hessian迹较小的平坦最小值，这与现有理论关注任意驻点收敛不同。文章还为凸函数和足够光滑函数提供了零阶优化收敛到近似平坦最小值的收敛率。通过二分类和语言模型微调实验验证了理论发现。", "keywords": "零阶优化, 平坦最小值, 隐式正则化, Hessian迹, 收敛率", "comments": "这项工作揭示了零阶优化的一种重要隐式正则化特性，即它倾向于找到平坦最小值。这对于理解零阶方法在实际机器学习任务（如黑盒攻击和语言模型微调）中为何表现良好具有重要意义，因为它表明零阶方法可能自然地提高模型的泛化能力和鲁棒性。"}}
{"id": "2506.05430", "title": "Explainer-guided Targeted Adversarial Attacks against Binary Code Similarity Detection Models", "authors": ["Mingjie Chen", "Tiancheng Zhu", "Mingxue Zhang", "Yiling He", "Minghao Lin", "Penghui Li", "Kui Ren"], "summary": "Binary code similarity detection (BCSD) serves as a fundamental technique for\nvarious software engineering tasks, e.g., vulnerability detection and\nclassification. Attacks against such models have therefore drawn extensive\nattention, aiming at misleading the models to generate erroneous predictions.\nPrior works have explored various approaches to generating semantic-preserving\nvariants, i.e., adversarial samples, to evaluate the robustness of the models\nagainst adversarial attacks. However, they have mainly relied on heuristic\ncriteria or iterative greedy algorithms to locate salient code influencing the\nmodel output, failing to operate on a solid theoretical basis. Moreover, when\nprocessing programs with high complexities, such attacks tend to be\ntime-consuming.\n  In this work, we propose a novel optimization for adversarial attacks against\nBCSD models. In particular, we aim to improve the attacks in a challenging\nscenario, where the attack goal is to limit the model predictions to a specific\nrange, i.e., the targeted attacks. Our attack leverages the superior capability\nof black-box, model-agnostic explainers in interpreting the model decision\nboundaries, thereby pinpointing the critical code snippet to apply\nsemantic-preserving perturbations. The evaluation results demonstrate that\ncompared with the state-of-the-art attacks, the proposed attacks achieve higher\nattack success rate in almost all scenarios, while also improving the\nefficiency and transferability. Our real-world case studies on vulnerability\ndetection and classification further demonstrate the security implications of\nour attacks, highlighting the urgent need to further enhance the robustness of\nexisting BCSD models.", "comment": "12 pages, 3 figures", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05430v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06077", "title": "Self driving algorithm for an active four wheel drive racecar", "authors": ["Gergely Bari", "Laszlo Palkovics"], "summary": "Controlling autonomous vehicles at their handling limits is a significant\nchallenge, particularly for electric vehicles with active four wheel drive\n(A4WD) systems offering independent wheel torque control. While traditional\nVehicle Dynamics Control (VDC) methods use complex physics-based models, this\nstudy explores Deep Reinforcement Learning (DRL) to develop a unified,\nhigh-performance controller. We employ the Proximal Policy Optimization (PPO)\nalgorithm to train an agent for optimal lap times in a simulated racecar\n(TORCS) at the tire grip limit. Critically, the agent learns an end-to-end\npolicy that directly maps vehicle states, like velocities, accelerations, and\nyaw rate, to a steering angle command and independent torque commands for each\nof the four wheels. This formulation bypasses conventional pedal inputs and\nexplicit torque vectoring algorithms, allowing the agent to implicitly learn\nthe A4WD control logic needed for maximizing performance and stability.\nSimulation results demonstrate the RL agent learns sophisticated strategies,\ndynamically optimizing wheel torque distribution corner-by-corner to enhance\nhandling and mitigate the vehicle's inherent understeer. The learned behaviors\nmimic and, in aspects of grip utilization, potentially surpass traditional\nphysics-based A4WD controllers while achieving competitive lap times. This\nresearch underscores DRL's potential to create adaptive control systems for\ncomplex vehicle dynamics, suggesting RL is a potent alternative for advancing\nautonomous driving in demanding, grip-limited scenarios for racing and road\nsafety.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06077v1", "AI": {"title_translation": "主动四轮驱动赛车的自动驾驶算法", "tldr": "本研究使用深度强化学习为主动四轮驱动赛车开发了一种高性能控制器，以在抓地力极限下实现最佳圈速，并展示了其优于传统方法的潜力。", "motivation": "在车辆操控极限下控制自动驾驶汽车是一个重大挑战，特别是对于具有独立车轮扭矩控制的主动四轮驱动电动汽车。传统车辆动力学控制方法复杂且基于物理模型。", "method": "本研究采用深度强化学习（DRL），特别是近端策略优化（PPO）算法，训练一个智能体。该智能体学习一种端到端策略，将车辆状态（如速度、加速度、横摆角速度）直接映射到转向角指令和每个车轮的独立扭矩指令，从而绕过传统的踏板输入和显式扭矩矢量分配算法。", "result": "仿真结果表明，RL智能体学习了复杂的策略，动态优化逐弯的车轮扭矩分配，以增强操控性并减轻车辆固有的转向不足。学习到的行为模仿并在抓地力利用方面可能超越传统的基于物理的A4WD控制器，同时实现了有竞争力的圈速。", "conclusion": "该研究强调了DRL在为复杂车辆动力学创建自适应控制系统方面的潜力，表明RL是在要求苛刻、抓地力受限的赛车和道路安全场景中推进自动驾驶的强大替代方案。", "translation": "在操控极限下控制自动驾驶车辆是一个重大挑战，特别是对于具有独立车轮扭矩控制的主动四轮驱动（A4WD）系统电动汽车。虽然传统的车辆动力学控制（VDC）方法使用复杂的基于物理的模型，但本研究探索深度强化学习（DRL）来开发一个统一的高性能控制器。我们采用近端策略优化（PPO）算法在模拟赛车（TORCS）中训练一个智能体，以在轮胎抓地力极限下实现最佳圈速。关键是，该智能体学习了一个端到端策略，将车辆状态（如速度、加速度和横摆角速度）直接映射到转向角指令和每个车轮的独立扭矩指令。这种公式绕过了传统的踏板输入和显式扭矩矢量分配算法，使智能体能够隐式学习最大化性能和稳定所需的A4WD控制逻辑。仿真结果表明，RL智能体学习了复杂的策略，逐弯动态优化车轮扭矩分配，以增强操控性并减轻车辆固有的转向不足。学习到的行为模仿并在抓地力利用方面可能超越传统的基于物理的A4WD控制器，同时实现了有竞争力的圈速。这项研究强调了DRL在为复杂车辆动力学创建自适应控制系统方面的潜力，表明RL是在要求苛刻、抓地力受限的赛车和道路安全场景中推进自动驾驶的强大替代方案。", "summary": "本文研究了利用深度强化学习（DRL）为主动四轮驱动（A4WD）赛车开发一种高性能自动驾驶控制器，以应对在操控极限下控制车辆的挑战。通过近端策略优化（PPO）算法，智能体学习了一种端到端策略，直接将车辆状态映射到转向和独立车轮扭矩指令，从而避免了传统的控制方法。仿真结果表明，该DRL智能体能够学习复杂的策略，动态优化扭矩分配，提升操控性并减轻转向不足，其性能可与甚至超越传统的基于物理的控制器，并取得有竞争力的圈速。这表明DRL在复杂车辆动力学控制和先进自动驾驶领域具有巨大潜力。", "keywords": "深度强化学习, 主动四轮驱动, 自动驾驶, 车辆动力学控制, 扭矩矢量分配", "comments": "本文的创新之处在于将深度强化学习应用于主动四轮驱动赛车的自动驾驶控制，特别是通过端到端学习绕过传统的复杂物理模型和显式扭矩矢量分配算法。这种方法能够让智能体隐式学习复杂的A4WD控制逻辑，以在抓地力极限下最大化性能和稳定性。研究结果表明DRL在处理复杂车辆动力学和应对极端操控场景方面具有显著潜力，为未来自动驾驶技术的发展提供了新的思路。"}}
{"id": "2506.05384", "title": "Q-Ponder: A Unified Training Pipeline for Reasoning-based Visual Quality Assessment", "authors": ["Zhuoxuan Cai", "Jian Zhang", "Xinbin Yuan", "Pengtao Jiang", "Wenxiang Chen", "Bowen Tang", "Lujian Yao", "Qiyuan Wang", "Jinwen Chen", "Bo Li"], "summary": "Recent studies demonstrate that multimodal large language models (MLLMs) can\nproficiently evaluate visual quality through interpretable assessments.\nHowever, existing approaches typically treat quality scoring and reasoning\ndescriptions as separate tasks with disjoint optimization objectives, leading\nto a trade-off: models adept at quality reasoning descriptions struggle with\nprecise score regression, while score-focused models lack interpretability.\nThis limitation hinders the full potential of MLLMs in visual quality\nassessment, where accuracy and interpretability should be mutually reinforcing.\nTo address this, we propose a unified two-stage training framework comprising a\ncold-start stage and a reinforcement learning-based fine-tuning stage.\nSpecifically, in the first stage, we distill high-quality data from a teacher\nmodel through expert-designed prompts, initializing reasoning capabilities via\ncross-entropy loss supervision. In the second stage, we introduce a novel\nreward with Group Relative Policy Optimization (GRPO) to jointly optimize\nscoring accuracy and reasoning consistency. We designate the models derived\nfrom these two stages as Q-Ponder-CI and Q-Ponder. Extensive experiments show\nthat Q-Ponder achieves state-of-the-art (SOTA) performance on quality score\nregression benchmarks, delivering up to 6.5% higher SRCC on cross-domain\ndatasets. Furthermore, Q-Ponder significantly outperforms description-based\nSOTA models, including its teacher model Qwen-2.5-VL-72B, particularly in\ndescription accuracy and reasonableness, demonstrating the generalization\npotential over diverse tasks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05384v1", "AI": {"title_translation": "Q-Ponder：一种基于推理的视觉质量评估统一训练流程", "tldr": "Q-Ponder提出了一种统一的两阶段训练框架，解决了多模态大语言模型在视觉质量评估中得分精度和推理可解释性之间的权衡问题，实现了SOTA性能。", "motivation": "现有的多模态大语言模型（MLLMs）在视觉质量评估中，通常将质量评分和推理描述视为独立任务，导致得分精确的模型缺乏可解释性，而擅长推理描述的模型在分数回归上表现不佳。这种局限性阻碍了MLLMs在需要准确性和可解释性并存的视觉质量评估中的潜力。", "method": "本文提出了一个统一的两阶段训练框架，称为Q-Ponder。第一阶段是冷启动阶段，通过专家设计的提示从教师模型中提取高质量数据，并利用交叉熵损失监督初始化推理能力，生成Q-Ponder-CI模型。第二阶段是基于强化学习的微调阶段，引入了带有组相对策略优化（GRPO）的新型奖励机制，以联合优化评分准确性和推理一致性，最终得到Q-Ponder模型。", "result": "Q-Ponder在质量分数回归基准测试上取得了最先进（SOTA）的性能，在跨域数据集上的SRCC提高了高达6.5%。此外，Q-Ponder在描述准确性和合理性方面显著优于基于描述的SOTA模型，包括其教师模型Qwen-2.5-VL-72B，并展示了在不同任务上的泛化潜力。", "conclusion": "通过Q-Ponder统一的两阶段训练框架，能够有效地解决视觉质量评估中得分精度与推理可解释性之间的权衡问题，实现了在评分准确性和推理一致性方面的SOTA性能，并展现了良好的泛化能力。", "translation": "最近的研究表明，多模态大语言模型（MLLMs）能够通过可解释的评估熟练地评估视觉质量。然而，现有方法通常将质量评分和推理描述视为具有不相交优化目标的独立任务，导致一种权衡：擅长质量推理描述的模型在精确分数回归方面表现不佳，而专注于分数的模型则缺乏可解释性。这种局限性阻碍了MLLMs在视觉质量评估中的全部潜力，其中准确性和可解释性应该相互增强。为了解决这个问题，我们提出了一个统一的两阶段训练框架，包括冷启动阶段和基于强化学习的微调阶段。具体而言，在第一阶段，我们通过专家设计的提示从教师模型中提取高质量数据，通过交叉熵损失监督初始化推理能力。在第二阶段，我们引入了一种新的奖励机制，结合组相对策略优化（GRPO），以联合优化评分准确性和推理一致性。我们将从这两个阶段衍生的模型分别命名为Q-Ponder-CI和Q-Ponder。广泛的实验表明，Q-Ponder在质量分数回归基准测试上实现了最先进（SOTA）的性能，在跨域数据集上的SRCC提高了高达6.5%。此外，Q-Ponder显著优于基于描述的SOTA模型，包括其教师模型Qwen-2.5-VL-72B，特别是在描述准确性和合理性方面，展示了在不同任务上的泛化潜力。", "summary": "Q-Ponder提出了一种创新的统一两阶段训练框架，用于解决多模态大语言模型在视觉质量评估中分数精度与推理可解释性之间的矛盾。该框架首先通过教师模型蒸馏进行冷启动以初始化推理能力，随后利用基于强化学习的组相对策略优化（GRPO）联合优化评分准确性和推理一致性。实验结果表明，Q-Ponder在视觉质量评分回归任务上达到了最先进水平，并在描述准确性和合理性方面超越了现有模型，展现了强大的泛化能力。", "keywords": "视觉质量评估, 多模态大语言模型, 强化学习, 统一训练, 可解释性", "comments": "这篇论文的创新点在于提出了一个统一的训练流程，有效地整合了视觉质量评估中的评分和推理任务。通过两阶段训练，特别是引入强化学习和GRPO来联合优化这两个目标，解决了现有方法中精度和可解释性之间的权衡问题。其重要性在于提升了MLLMs在视觉质量评估领域的实用性，使其既能提供准确的质量分数，又能提供可信赖的推理依据，这对于实际应用具有重要价值。"}}
{"id": "2506.06262", "title": "PyGemini: Unified Software Development towards Maritime Autonomy Systems", "authors": ["Kjetil Vasstein", "Christian Le", "Simon Lervåg Breivik", "Trygve Maukon Myhr", "Annette Stahl", "Edmund Førland Brekke"], "summary": "Ensuring the safety and certifiability of autonomous surface vessels (ASVs)\nrequires robust decision-making systems, supported by extensive simulation,\ntesting, and validation across a broad range of scenarios. However, the current\nlandscape of maritime autonomy development is fragmented -- relying on\ndisparate tools for communication, simulation, monitoring, and system\nintegration -- which hampers interdisciplinary collaboration and inhibits the\ncreation of compelling assurance cases, demanded by insurers and regulatory\nbodies. Furthermore, these disjointed tools often suffer from performance\nbottlenecks, vendor lock-in, and limited support for continuous integration\nworkflows. To address these challenges, we introduce PyGemini, a permissively\nlicensed, Python-native framework that builds on the legacy of Autoferry Gemini\nto unify maritime autonomy development. PyGemini introduces a novel\nConfiguration-Driven Development (CDD) process that fuses Behavior-Driven\nDevelopment (BDD), data-oriented design, and containerization to support\nmodular, maintainable, and scalable software architectures. The framework\nfunctions as a stand-alone application, cloud-based service, or embedded\nlibrary -- ensuring flexibility across research and operational contexts. We\ndemonstrate its versatility through a suite of maritime tools -- including 3D\ncontent generation for simulation and monitoring, scenario generation for\nautonomy validation and training, and generative artificial intelligence\npipelines for augmenting imagery -- thereby offering a scalable, maintainable,\nand performance-oriented foundation for future maritime robotics and autonomy\nresearch.", "comment": "Preprint. Not yet submitted for peer review. Includes 14 figures and\n  3 tables. 18 pages, 1 appendix", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06262v1", "AI": {"title_translation": "PyGemini：迈向海事自主系统的统一软件开发", "tldr": "PyGemini是一个统一的Python框架，通过解决现有工具的碎片化、性能瓶颈等问题，为海事自主系统提供模块化、可维护和可扩展的软件开发。", "motivation": "现有海事自主开发工具碎片化，导致跨学科协作困难、难以创建有说服力的保证案例，且存在性能瓶颈、供应商锁定和持续集成支持有限等问题。", "method": "PyGemini引入了一种新颖的配置驱动开发（CDD）过程，该过程融合了行为驱动开发（BDD）、面向数据设计和容器化，以支持模块化、可维护和可扩展的软件架构。它可作为独立应用程序、基于云的服务或嵌入式库。", "result": "PyGemini通过一套海事工具展示了其多功能性，包括用于仿真和监控的3D内容生成、用于自主验证和训练的场景生成，以及用于图像增强的生成式人工智能管道。", "conclusion": "PyGemini为未来的海事机器人和自主研究提供了一个可扩展、可维护且注重性能的基础。", "translation": "确保自主水面舰艇（ASV）的安全性和可认证性需要强大的决策系统，并得到广泛场景下的仿真、测试和验证的支持。然而，当前海事自主开发领域是碎片化的——依赖于通信、仿真、监控和系统集成的不同工具——这阻碍了跨学科协作，并抑制了保险公司和监管机构所要求的令人信服的保证案例的创建。此外，这些脱节的工具常常面临性能瓶颈、供应商锁定以及对持续集成工作流支持有限的问题。为了解决这些挑战，我们引入了PyGemini，一个允许许可的、Python原生的框架，它建立在Autoferry Gemini的遗产之上，旨在统一海事自主开发。PyGemini引入了一种新颖的配置驱动开发（CDD）过程，该过程融合了行为驱动开发（BDD）、面向数据设计和容器化，以支持模块化、可维护和可扩展的软件架构。该框架可作为独立应用程序、基于云的服务或嵌入式库运行——确保了在研究和操作环境中的灵活性。我们通过一套海事工具展示了其多功能性——包括用于仿真和监控的3D内容生成、用于自主验证和训练的场景生成，以及用于增强图像的生成式人工智能管道——从而为未来的海事机器人和自主研究提供了一个可扩展、可维护且注重性能的基础。", "summary": "PyGemini是一个Python原生的框架，旨在解决当前海事自主开发中工具碎片化、性能瓶颈和协作障碍等问题。它通过引入配置驱动开发（CDD）过程，结合行为驱动开发（BDD）、面向数据设计和容器化，提供模块化、可维护和可扩展的软件架构。该框架可作为独立应用、云服务或嵌入式库，并通过3D内容生成、场景生成和AI管道等工具展示了其在海事领域的广泛应用和潜力，为未来的海事机器人和自主研究奠定基础。", "keywords": "海事自主系统, 统一软件开发, PyGemini, 配置驱动开发, 行为驱动开发", "comments": "PyGemini的创新之处在于其统一的、Python原生的框架，以及结合CDD、BDD和容器化的开发流程，解决了海事自主系统开发中的关键痛点。其重要性在于提升了开发效率、协作能力和系统的可认证性，为海事领域的自主系统发展提供了坚实的基础。"}}
{"id": "2506.05810", "title": "Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction", "authors": ["Yesheng Zhang", "Wenjian Sun", "Yuheng Chen", "Qingwei Liu", "Qi Lin", "Rui Zhang", "Xu Zhao"], "summary": "Complex interactions among agents present a significant challenge for\nautonomous driving in real-world scenarios. Recently, a promising approach has\nemerged, which formulates the interactions of agents as a level-k game\nframework. It effectively decouples agent policies by hierarchical game levels.\nHowever, this framework ignores both the varying driving complexities among\nagents and the dynamic changes in agent states across game levels, instead\ntreating them uniformly. Consequently, redundant and error-prone computations\nare introduced into this framework. To tackle the issue, this paper proposes a\nmetric, termed as Trajectory Entropy, to reveal the game status of agents\nwithin the level-k game framework. The key insight stems from recognizing the\ninherit relationship between agent policy uncertainty and the associated\ndriving complexity. Specifically, Trajectory Entropy extracts statistical\nsignals representing uncertainty from the multimodality trajectory prediction\nresults of agents in the game. Then, the signal-to-noise ratio of this signal\nis utilized to quantify the game status of agents. Based on the proposed\nTrajectory Entropy, we refine the current level-k game framework through a\nsimple gating mechanism, significantly improving overall accuracy while\nreducing computational costs. Our method is evaluated on the Waymo and nuPlan\ndatasets, in terms of trajectory prediction, open-loop and closed-loop planning\ntasks. The results demonstrate the state-of-the-art performance of our method,\nwith precision improved by up to 19.89% for prediction and up to 16.48% for\nplanning.", "comment": "10 pages", "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05810v1", "AI": {"title_translation": "轨迹熵：从多模态轨迹预测中建模博弈状态稳定性", "tldr": "本文提出了轨迹熵，一种量化博弈状态的指标，以改进自动驾驶中基于Level-k博弈框架的交互预测和规划。", "motivation": "现有的Level-k博弈框架忽略了智能体之间不同的驾驶复杂性和跨博弈层级动态变化的智能体状态，导致冗余和易错的计算。", "method": "提出“轨迹熵”指标，通过从多模态轨迹预测结果中提取表示不确定性的统计信号，并利用信号的信噪比来量化智能体的博弈状态。基于此，通过简单的门控机制改进了现有的Level-k博弈框架。", "result": "在Waymo和nuPlan数据集上进行了评估，在轨迹预测、开环和闭环规划任务中，方法表现出最先进的性能，预测精度提高了19.89%，规划精度提高了16.48%。", "conclusion": "轨迹熵能够有效揭示博弈状态，并通过改进Level-k博弈框架，显著提升了自动驾驶中交互预测和规划的准确性并降低了计算成本。", "translation": "复杂智能体之间的交互对现实世界中的自动驾驶构成了重大挑战。最近，一种有前景的方法出现了，它将智能体之间的交互表述为Level-k博弈框架。它通过分层博弈级别有效地解耦了智能体策略。然而，该框架忽略了智能体之间不同的驾驶复杂性以及跨博弈层级智能体状态的动态变化，而是将它们统一对待。因此，该框架引入了冗余和易错的计算。为了解决这个问题，本文提出了一种名为“轨迹熵”的度量，以揭示Level-k博弈框架中智能体的博弈状态。关键在于认识到智能体策略不确定性与相关驾驶复杂性之间固有的关系。具体来说，轨迹熵从博弈中智能体的多模态轨迹预测结果中提取表示不确定性的统计信号。然后，利用该信号的信噪比来量化智能体的博弈状态。基于所提出的轨迹熵，我们通过简单的门控机制改进了当前的Level-k博弈框架，显著提高了整体准确性，同时降低了计算成本。我们的方法在Waymo和nuPlan数据集上进行了评估，涵盖轨迹预测、开环和闭环规划任务。结果表明，我们的方法表现出最先进的性能，预测精度提高了19.89%，规划精度提高了16.48%。", "summary": "本文针对自动驾驶中Level-k博弈框架在处理智能体交互时存在的计算冗余和错误问题，提出了一种名为“轨迹熵”的新度量。轨迹熵通过分析多模态轨迹预测结果中的不确定性信号来量化智能体的博弈状态，并利用其信噪比进行精确评估。通过将轨迹熵整合到Level-k框架中，引入简单的门控机制，显著提升了预测和规划的准确性，并有效降低了计算成本。实验结果验证了该方法在多个任务上的先进性能。", "keywords": "轨迹熵, Level-k博弈, 多模态轨迹预测, 自动驾驶", "comments": "这篇论文通过引入“轨迹熵”这一创新概念，有效解决了现有Level-k博弈框架在处理智能体交互时所面临的局限性，特别是在考虑不同驾驶复杂性和动态状态变化方面的不足。其核心创新在于将智能体策略的不确定性与驾驶复杂性关联起来，并利用多模态轨迹预测中的统计信号来量化博弈状态。这种方法不仅提高了预测和规划的准确性，还降低了计算成本，对自动驾驶领域的多智能体交互建模具有重要意义。"}}
{"id": "2506.05794", "title": "Markov Blanket Density and Free Energy Minimization", "authors": ["Luca M. Possati"], "summary": "This paper presents a continuous, information-theoretic extension of the Free\nEnergy Principle through the concept of Markov blanket density, i.e., a scalar\nfield that quantifies the degree of conditional independence between internal\nand external states at each point in space (ranging from 0 for full coupling to\n1 for full separation). It demonstrates that active inference dynamics\n(including the minimization of variational and expected free energy) naturally\nemerge from spatial gradients in this density, making Markov blanket density a\nnecessary foundation for the definability and coherence of the Free Energy\nPrinciple. These ideas are developed through a mathematically framework that\nlinks density gradients to precise and testable dynamics, offering a foundation\nfor novel predictions and simulation paradigms.", "comment": null, "cate": "q-bio.NC", "url": "http://arxiv.org/pdf/2506.05794v1", "AI": {"title_translation": "马尔可夫毯密度与自由能最小化", "tldr": "本文提出了马尔可夫毯密度的概念，将其作为自由能原理的连续信息论扩展，并证明主动推断动力学源于这种密度的空间梯度。", "motivation": "旨在通过引入马尔可夫毯密度概念，对自由能原理进行连续、信息论的扩展，并为自由能原理的可定义性和连贯性奠定必要基础。", "method": "提出马尔可夫毯密度这一标量场概念，用于量化内部状态和外部状态之间条件独立性的程度。通过一个数学框架，将这种密度的空间梯度与精确可测试的动力学联系起来，从而推导出主动推断动力学。", "result": "证明了主动推断动力学（包括变分自由能和预期自由能的最小化）自然地源于马尔可夫毯密度的空间梯度。", "conclusion": "马尔可夫毯密度是自由能原理可定义性和连贯性的必要基础。", "translation": "本文提出了自由能原理的一个连续的、信息论的扩展，通过马尔可夫毯密度这一概念。马尔可夫毯密度是一个标量场，它量化了空间中每个点上内部状态和外部状态之间条件独立性的程度（从完全耦合的0到完全分离的1）。它表明主动推断动力学（包括变分自由能和预期自由能的最小化）自然地从这种密度的空间梯度中出现，使得马尔可夫毯密度成为自由能原理可定义性和连贯性的必要基础。这些思想是通过一个数学框架发展的，该框架将密度梯度与精确且可测试的动力学联系起来，为新的预测和模拟范式提供了基础。", "summary": "本文引入了马尔可夫毯密度，这是一个量化内部与外部状态间条件独立性的标量场，并以此对自由能原理进行了连续的信息论扩展。研究表明，主动推断动力学源于这种密度的空间梯度，从而确立了马尔可夫毯密度作为自由能原理基础的重要性。该工作通过数学框架将密度梯度与可测试动力学关联，为新预测和模拟提供了基础。", "keywords": "马尔可夫毯密度, 自由能原理, 主动推断, 信息论, 空间梯度", "comments": "本文创新性地将马尔可夫毯密度引入自由能原理，将其从离散概念扩展为连续信息论框架，并揭示了主动推断动力学与空间梯度的内在联系。这不仅加深了对自由能原理的理解，也为神经科学和人工智能等领域提供了新的理论和模拟工具，具有重要的理论和实践意义。"}}
{"id": "2506.05479", "title": "Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors", "authors": ["Matei Gabriel Coşa", "Marek Eliáš"], "summary": "We consider the following problem: We are given $\\ell$ heuristics for\nMetrical Task Systems (MTS), where each might be tailored to a different type\nof input instances. While processing an input instance received online, we are\nallowed to query the action of only one of the heuristics at each time step.\nOur goal is to achieve performance comparable to the best of the given\nheuristics. The main difficulty of our setting comes from the fact that the\ncost paid by a heuristic at time $t$ cannot be estimated unless the same\nheuristic was also queried at time $t-1$. This is related to Bandit Learning\nagainst memory bounded adversaries (Arora et al., 2012). We show how to achieve\nregret of $O(\\text{OPT}^{2/3})$ and prove a tight lower bound based on the\nconstruction of Dekel et al. (2013).", "comment": "Accepted to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05479v1", "AI": {"title_translation": "学习增强算法，用于具有多预测器强盗访问的度量任务系统 (MTS)", "tldr": "针对度量任务系统(MTS)中多启发式选择问题，论文提出了一种学习增强算法，实现了$O(\text{OPT}^{2/3})$的遗憾界限，并证明了其紧密下界。", "motivation": "在度量任务系统（MTS）中，存在多个针对不同输入实例的启发式算法。目标是在线处理输入实例时，通过在每个时间步只查询一个启发式算法来达到与其中最好算法相当的性能。主要挑战在于启发式算法的成本估计困难，除非在先前的时间步也查询了相同的启发式算法。", "method": "本文提出了一种学习增强算法，该算法受到针对记忆受限对抗者的强盗学习（Bandit Learning against memory bounded adversaries）的启发。算法在每个时间步只允许查询一个启发式算法的动作。", "result": "实现了$O(\text{OPT}^{2/3})$的遗憾（regret），并基于Dekel et al. (2013)的构造证明了一个紧密的下界。", "conclusion": "论文成功地为具有多预测器强盗访问的度量任务系统（MTS）问题设计了一种学习增强算法，并证明了其遗憾界限是渐近最优的，提供了严格的理论性能保证。", "translation": "我们考虑以下问题：我们有$\\ell$个用于度量任务系统（MTS）的启发式算法，每个算法可能针对不同类型的输入实例进行定制。在在线处理接收到的输入实例时，我们被允许在每个时间步只查询其中一个启发式算法的动作。我们的目标是实现与给定启发式算法中最佳算法相当的性能。我们设置的主要困难在于，一个启发式算法在时间$t$所支付的成本无法估计，除非在时间$t-1$也查询了相同的启发式算法。这与针对记忆受限对抗者的强盗学习（Arora et al., 2012）有关。我们展示了如何实现$O(\\text{OPT}^{2/3})$的遗憾（regret），并基于Dekel et al. (2013)的构造证明了一个紧密的下界。", "summary": "这篇论文研究了在度量任务系统（MTS）中，当有多个启发式算法且只能在每个时间步查询一个时如何选择最佳算法的问题。核心挑战在于启发式算法的成本估计需要连续查询。作者提出了一种受强盗学习启发的学习增强算法，并证明其遗憾界限为$O(\\text{OPT}^{2/3})$，同时给出了一个紧密的下界，表明该算法在性能上具有理论上的最优性。", "keywords": "度量任务系统, 强盗学习, 学习增强算法, 遗憾界限, 在线算法", "comments": "这篇论文的创新点在于将强盗学习的范式应用于度量任务系统（MTS）中的启发式选择问题，特别是在成本估计受限的条件下。其重要性在于为在线算法设计提供了一种新的视角，并给出了严格的理论分析（遗憾界限和下界），这对于理解此类问题在不确定性环境下的性能极限具有重要意义。"}}
{"id": "2506.05446", "title": "Sentinel: SOTA model to protect against prompt injections", "authors": ["Dror Ivry", "Oran Nahum"], "summary": "Large Language Models (LLMs) are increasingly powerful but remain vulnerable\nto prompt injection attacks, where malicious inputs cause the model to deviate\nfrom its intended instructions. This paper introduces Sentinel, a novel\ndetection model, qualifire/prompt-injection-sentinel, based on the\n\\answerdotai/ModernBERT-large architecture. By leveraging ModernBERT's advanced\nfeatures and fine-tuning on an extensive and diverse dataset comprising a few\nopen-source and private collections, Sentinel achieves state-of-the-art\nperformance. This dataset amalgamates varied attack types, from role-playing\nand instruction hijacking to attempts to generate biased content, alongside a\nbroad spectrum of benign instructions, with private datasets specifically\ntargeting nuanced error correction and real-world misclassifications. On a\ncomprehensive, unseen internal test set, Sentinel demonstrates an average\naccuracy of 0.987 and an F1-score of 0.980. Furthermore, when evaluated on\npublic benchmarks, it consistently outperforms strong baselines like\nprotectai/deberta-v3-base-prompt-injection-v2. This work details Sentinel's\narchitecture, its meticulous dataset curation, its training methodology, and a\nthorough evaluation, highlighting its superior detection capabilities.", "comment": "6 pages, 2 tables", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05446v1", "AI": {"title_translation": "Sentinel：保护免受提示注入攻击的SOTA模型", "tldr": "大型语言模型（LLMs）易受提示注入攻击。本文介绍了Sentinel，一个基于ModernBERT-large的新型检测模型，通过多样化数据集训练实现了最先进的性能，有效抵御此类攻击。", "motivation": "大型语言模型（LLMs）功能日益强大，但仍然容易受到提示注入攻击，即恶意输入会导致模型偏离其预期指令。", "method": "本文引入了Sentinel，一个基于\\answerdotai/ModernBERT-large架构的新型检测模型。通过利用ModernBERT的先进特性，并在包含少量开源和私有集合的广泛多样化数据集上进行微调。该数据集融合了各种攻击类型，从角色扮演和指令劫持到试图生成偏见内容，以及广泛的良性指令，其中私有数据集专门针对细微的错误纠正和真实世界的错误分类。", "result": "在全面、未见的内部测试集上，Sentinel的平均准确率为0.987，F1-分数为0.980。此外，在公共基准测试中，它始终优于protectai/deberta-v3-base-prompt-injection-v2等强基线。", "conclusion": "Sentinel模型通过其架构、精心策划的数据集和训练方法，展示了卓越的检测能力，有效保护LLMs免受提示注入攻击。", "translation": "大型语言模型（LLMs）功能日益强大，但仍然容易受到提示注入攻击，即恶意输入导致模型偏离其预期指令。本文介绍了Sentinel，一个基于\\answerdotai/ModernBERT-large架构的新型检测模型，qualifire/prompt-injection-sentinel。通过利用ModernBERT的先进特性，并在包含少量开源和私有集合的广泛多样化数据集上进行微调，Sentinel实现了最先进的性能。该数据集融合了各种攻击类型，从角色扮演和指令劫持到试图生成偏见内容，以及广泛的良性指令，其中私有数据集专门针对细微的错误纠正和真实世界的错误分类。在一个全面、未见的内部测试集上，Sentinel的平均准确率为0.987，F1-分数为0.980。此外，在公共基准测试中，它始终优于protectai/deberta-v3-base-prompt-injection-v2等强基线。这项工作详细介绍了Sentinel的架构、其精心策划的数据集、其训练方法和彻底的评估，突出了其卓越的检测能力。", "summary": "本文提出了一种名为Sentinel的新型检测模型，用于防御大型语言模型（LLMs）面临的提示注入攻击。该模型基于ModernBERT-large架构，并通过包含多种攻击类型和良性指令的广泛数据集进行微调，实现了最先进的检测性能，在内部测试集上达到0.987的准确率和0.980的F1分数，并在公共基准测试中超越了现有强基线。", "keywords": "提示注入, 大型语言模型, Sentinel, ModernBERT, 安全", "comments": "该论文通过引入基于ModernBERT-large的Sentinel模型，为LLM的提示注入攻击提供了一个SOTA解决方案。其创新之处在于利用了先进的BERT架构和精心策划的包含多种攻击类型及私有数据的多样化数据集，这对于提升检测模型的泛化能力和真实世界表现至关重要。其高准确率和F1分数表明了该方法的有效性，对于提升LLM的安全性具有重要意义。"}}
{"id": "2506.06094", "title": "On-board Mission Replanning for Adaptive Cooperative Multi-Robot Systems", "authors": ["Elim Kwan", "Rehman Qureshi", "Liam Fletcher", "Colin Laganier", "Victoria Nockles", "Richard Walters"], "summary": "Cooperative autonomous robotic systems have significant potential for\nexecuting complex multi-task missions across space, air, ground, and maritime\ndomains. But they commonly operate in remote, dynamic and hazardous\nenvironments, requiring rapid in-mission adaptation without reliance on fragile\nor slow communication links to centralised compute. Fast, on-board replanning\nalgorithms are therefore needed to enhance resilience. Reinforcement Learning\nshows strong promise for efficiently solving mission planning tasks when\nformulated as Travelling Salesperson Problems (TSPs), but existing methods: 1)\nare unsuitable for replanning, where agents do not start at a single location;\n2) do not allow cooperation between agents; 3) are unable to model tasks with\nvariable durations; or 4) lack practical considerations for on-board\ndeployment. Here we define the Cooperative Mission Replanning Problem as a\nnovel variant of multiple TSP with adaptations to overcome these issues, and\ndevelop a new encoder/decoder-based model using Graph Attention Networks and\nAttention Models to solve it effectively and efficiently. Using a simple\nexample of cooperative drones, we show our replanner consistently (90% of the\ntime) maintains performance within 10% of the state-of-the-art LKH3 heuristic\nsolver, whilst running 85-370 times faster on a Raspberry Pi. This work paves\nthe way for increased resilience in autonomous multi-agent systems.", "comment": "9 pages, 5 figures, 1 table", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06094v1", "AI": {"title_translation": "自适应协同多机器人系统的机载任务重规划", "tldr": "开发了一种基于图注意力网络的新型机载任务重规划算法，用于自适应协同多机器人系统，其性能接近现有最佳算法，但速度快得多，适用于资源受限的设备。", "motivation": "协同自主机器人系统在复杂任务中潜力巨大，但常在远程、动态和危险环境中运行，需要快速的在任务中适应能力，且不依赖脆弱或缓慢的中心通信。现有强化学习方法不适用于重规划、不支持多智能体协作、无法建模可变持续时间任务或缺乏实际部署考虑。", "method": "将协同任务重规划问题定义为多旅行商问题的一个新变体，并开发了一种新的基于编码器/解码器的模型，使用图注意力网络和注意力模型来有效解决该问题。", "result": "在协同无人机示例中，重规划器90%的时间内性能保持在LKH3启发式求解器最佳水平的10%以内，同时在树莓派上运行速度快85-370倍。", "conclusion": "这项工作为提高自主多智能体系统的弹性铺平了道路。", "translation": "协同自主机器人系统在执行跨越空间、空中、地面和海事领域的复杂多任务方面具有巨大潜力。但它们通常在远程、动态和危险环境中运行，需要在任务中快速适应，而无需依赖脆弱或缓慢的集中计算通信链路。因此，需要快速的机载重规划算法来增强弹性。当任务规划问题被表述为旅行商问题（TSPs）时，强化学习在有效解决这些问题方面显示出强大前景，但现有方法：1）不适用于重规划，即智能体不从单一位置开始；2）不允许智能体之间进行协作；3）无法建模持续时间可变的任务；或4）缺乏机载部署的实际考虑。本文将协同任务重规划问题定义为多旅行商问题的一个新颖变体，并进行了修改以克服这些问题，并开发了一种使用图注意力网络和注意力模型的新的编码器/解码器模型，以有效和高效地解决它。通过一个简单的协同无人机示例，我们展示了我们的重规划器始终（90%的时间）将性能保持在最先进的LKH3启发式求解器性能的10%以内，同时在树莓派上运行速度快85-370倍。这项工作为提高自主多智能体系统的弹性铺平了道路。", "summary": "本文提出了一种针对自适应协同多机器人系统的机载任务重规划问题的新方法。该问题被定义为多旅行商问题的一个变体，以解决现有强化学习方法在重规划、多智能体协作、可变任务持续时间和实际部署方面的不足。研究开发了一种基于编码器/解码器和图注意力网络的新模型。实验结果表明，该模型在保持接近现有最佳启发式求解器性能的同时，显著提高了在资源受限设备上的运行速度，从而增强了自主多智能体系统的弹性。", "keywords": "任务重规划, 多机器人系统, 图注意力网络, 旅行商问题, 机载部署", "comments": "这项工作创新性地将多旅行商问题与图注意力网络结合，解决了现有强化学习方法在多机器人系统机载重规划中的实际限制。其在资源受限设备上展现出的高效率和接近最优的性能，对于提高自主系统在恶劣环境下的韧性具有重要意义。"}}
{"id": "2506.05395", "title": "TriPSS: A Tri-Modal Keyframe Extraction Framework Using Perceptual, Structural, and Semantic Representations", "authors": ["Mert Can Cakmak", "Nitin Agarwal", "Diwash Poudel"], "summary": "Efficient keyframe extraction is critical for effective video summarization\nand retrieval, yet capturing the complete richness of video content remains\nchallenging. In this work, we present TriPSS, a novel tri-modal framework that\neffectively integrates perceptual cues from color features in the CIELAB space,\ndeep structural embeddings derived from ResNet-50, and semantic context from\nframe-level captions generated by Llama-3.2-11B-Vision-Instruct. By fusing\nthese diverse modalities using principal component analysis, TriPSS constructs\nrobust multi-modal embeddings that enable adaptive segmentation of video\ncontent via HDBSCAN clustering. A subsequent refinement stage incorporating\nquality assessment and duplicate filtering ensures that the final keyframe set\nis both concise and semantically rich. Comprehensive evaluations on benchmark\ndatasets TVSum20 and SumMe demonstrate that TriPSS achieves state-of-the-art\nperformance, substantially outperforming traditional unimodal and previous\nmulti-modal methods. These results underscore TriPSS's ability to capture\nnuanced visual and semantic information, thereby setting a new benchmark for\nvideo content understanding in large-scale retrieval scenarios.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05395v1", "AI": {"title_translation": "TriPSS：一种利用感知、结构和语义表示的三模态关键帧提取框架", "tldr": "TriPSS是一个新颖的三模态框架，通过融合感知、结构和语义信息，实现了高效且高质量的关键帧提取，在基准数据集上达到了最先进的性能。", "motivation": "高效的关键帧提取对于有效的视频摘要和检索至关重要，但捕捉视频内容的完整丰富性仍然具有挑战性。", "method": "TriPSS框架整合了来自CIELAB颜色特征的感知线索、ResNet-50的深度结构嵌入以及Llama-3.2-11B-Vision-Instruct生成的帧级字幕的语义上下文。通过主成分分析融合这些不同模态，构建鲁棒的多模态嵌入，并通过HDBSCAN聚类实现视频内容的自适应分割。后续的细化阶段通过质量评估和重复过滤，确保最终的关键帧集既简洁又语义丰富。", "result": "在基准数据集TVSum20和SumMe上的综合评估表明，TriPSS实现了最先进的性能，显著优于传统的单模态和以前的多模态方法。这些结果突出了TriPSS捕捉细微视觉和语义信息的能力。", "conclusion": "TriPSS通过捕捉细微的视觉和语义信息，为大规模检索场景中的视频内容理解设定了新的基准。", "translation": "高效的关键帧提取对于有效的视频摘要和检索至关重要，但捕捉视频内容的完整丰富性仍然具有挑战性。在这项工作中，我们提出了TriPSS，一个新颖的三模态框架，它有效地整合了来自CIELAB空间颜色特征的感知线索、来自ResNet-50的深度结构嵌入，以及来自Llama-3.2-11B-Vision-Instruct生成的帧级字幕的语义上下文。通过使用主成分分析融合这些不同的模态，TriPSS构建了鲁棒的多模态嵌入，从而通过HDBSCAN聚类实现视频内容的自适应分割。随后的细化阶段结合质量评估和重复过滤，确保最终的关键帧集既简洁又语义丰富。在基准数据集TVSum20和SumMe上的综合评估表明，TriPSS实现了最先进的性能，显著优于传统的单模态和以前的多模态方法。这些结果强调了TriPSS捕捉细微视觉和语义信息的能力，从而为大规模检索场景中的视频内容理解设定了新的基准。", "summary": "TriPSS是一个创新的三模态关键帧提取框架，旨在解决视频内容完整性捕获的挑战。它通过融合感知（CIELAB颜色）、结构（ResNet-50）和语义（Llama-3.2-11B-Vision-Instruct字幕）表示来创建多模态嵌入。利用PCA进行融合，HDBSCAN进行自适应分割，并通过质量评估和去重进行精炼，TriPSS在TVSum20和SumMe数据集上表现出色，超越了现有方法，为视频内容理解树立了新标杆。", "keywords": "关键帧提取, 多模态融合, 视频摘要, 感知表示, 语义表示", "comments": "该论文的创新点在于其独特的三模态融合方法，结合了传统特征（颜色）、深度学习特征（ResNet-50）和大型语言模型生成的语义信息（Llama-3.2-11B-Vision-Instruct），构建了更全面的视频表示。这种多模态融合策略显著提升了关键帧提取的准确性和效率，为视频摘要和检索领域带来了显著进步。"}}
{"id": "2506.05887", "title": "Explainability in Context: A Multilevel Framework Aligning AI Explanations with Stakeholder with LLMs", "authors": ["Marilyn Bello", "Rafael Bello", "Maria-Matilde García", "Ann Nowé", "Iván Sevillano-García", "Francisco Herrera"], "summary": "The growing application of artificial intelligence in sensitive domains has\nintensified the demand for systems that are not only accurate but also\nexplainable and trustworthy. Although explainable AI (XAI) methods have\nproliferated, many do not consider the diverse audiences that interact with AI\nsystems: from developers and domain experts to end-users and society. This\npaper addresses how trust in AI is influenced by the design and delivery of\nexplanations and proposes a multilevel framework that aligns explanations with\nthe epistemic, contextual, and ethical expectations of different stakeholders.\nThe framework consists of three layers: algorithmic and domain-based,\nhuman-centered, and social explainability. We highlight the emerging role of\nLarge Language Models (LLMs) in enhancing the social layer by generating\naccessible, natural language explanations. Through illustrative case studies,\nwe demonstrate how this approach facilitates technical fidelity, user\nengagement, and societal accountability, reframing XAI as a dynamic,\ntrust-building process.", "comment": "22 pages, 5 figures", "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05887v1", "AI": {"title_translation": "情境中的可解释性：一个利用大型语言模型将人工智能解释与利益相关者对齐的多层框架", "tldr": "本文提出了一个多层框架，利用大型语言模型（LLMs）生成易于理解的自然语言解释，以根据不同利益相关者的期望对齐AI解释，从而增强对AI的信任。", "motivation": "人工智能在敏感领域的日益广泛应用，使得对不仅准确而且可解释和值得信任的系统需求日益增加。现有的可解释人工智能（XAI）方法往往没有考虑到与AI系统交互的多元受众（从开发者到终端用户和社会）。", "method": "本文提出了一个多层框架，旨在根据不同利益相关者的认知、情境和伦理期望来对齐解释。该框架包含三个层次：算法和领域层、以人为中心层以及社会可解释性层。文中强调了大型语言模型（LLMs）在通过生成易于理解的自然语言解释来增强社会层方面的作用。", "result": "通过说明性案例研究，本文展示了该方法如何促进技术忠实度、用户参与和社会责任，并将XAI重新定义为一个动态的、建立信任的过程。", "conclusion": "本文将可解释人工智能（XAI）重新定义为一个动态的、建立信任的过程，通过一个多层框架，利用大型语言模型（LLMs）为不同利益相关者提供对齐的解释，从而增强对AI的信任。", "translation": "人工智能在敏感领域的日益广泛应用，加剧了对不仅准确而且可解释和值得信任的系统的需求。尽管可解释人工智能（XAI）方法已大量涌现，但许多方法并未考虑到与人工智能系统交互的多元受众：从开发者和领域专家到终端用户和社会。本文探讨了解释的设计和交付如何影响对人工智能的信任，并提出了一个多层框架，旨在根据不同利益相关者的认知、情境和伦理期望来对齐解释。该框架由三个层次组成：算法和领域层、以人为中心层和社会可解释性层。我们强调了大型语言模型（LLMs）在通过生成易于理解的自然语言解释来增强社会层方面的新兴作用。通过说明性案例研究，我们展示了这种方法如何促进技术忠实度、用户参与和社会责任，并将XAI重新定义为一个动态的、建立信任的过程。", "summary": "本文提出了一个多层框架，旨在根据不同利益相关者的认知、情境和伦理期望，利用大型语言模型（LLMs）生成易于理解的自然语言解释，从而对齐人工智能解释。该框架包含算法和领域、以人为中心以及社会可解释性三个层次，旨在将可解释人工智能（XAI）重塑为一种动态的信任构建过程，促进技术忠实度、用户参与和社会责任。", "keywords": "可解释人工智能, 大型语言模型, 多层框架, 利益相关者, 信任", "comments": "本文的创新之处在于提出了一个多层框架，并特别强调了大型语言模型（LLMs）在提升社会可解释性方面的潜力，这对于解决AI解释在不同受众中的适用性问题具有重要意义。它将XAI从单一的技术问题提升到涉及多方利益相关者信任构建的范畴。"}}
{"id": "2506.05919", "title": "RSMA-Enabled Covert Communications Against Multiple Spatially Random Wardens", "authors": ["Xinyue Pei", "Jihao Liu", "Xuewen Luo", "Xingwei Wang", "Yingyang Chen", "Miaowen Wen", "Theodoros A. Tsiftsis"], "summary": "This work investigates covert communication in a rate-splitting multiple\naccess (RSMA)-based multi-user multiple-input single-output system, where the\nrandom locations of the wardens follow a homogeneous Poisson point process. To\ndemonstrate practical deployment scenarios, imperfect channel state information\nat the transmitter is considered. Closed-form expressions for the statistics of\nthe received signal-to-interference-plus-noise ratio, along with the analytical\nformulations for the covertness constraint, outage probability, and effective\ncovert throughput (ECT), are derived. Subsequently, an ECT maximization problem\nis formulated under covertness and power allocation constraints. This\noptimization problem is addressed using an alternating optimization-assisted\ngenetic algorithm (AO-GA). Simulation results corroborate the theoretical\nanalysis and demonstrate the superiority of RSMA over conventional multiple\naccess schemes, as well as the effectiveness of the proposed AO-GA.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05919v1", "AI": {"title_translation": "启用RSMA的对抗多个空间随机看守者的隐蔽通信", "tldr": "本文研究了在RSMA多用户MISO系统中对抗多个随机分布看守者的隐蔽通信，并提出了一个最大化有效隐蔽吞吐量的AO-GA算法。", "motivation": "本文旨在研究在基于速率分裂多址（RSMA）的多用户多输入单输出（MISO）系统中实现隐蔽通信，其中看守者的随机位置遵循齐次泊松点过程，并考虑了发射机不完善的信道状态信息，以演示实际部署场景。", "method": "本文推导了接收信干噪比统计量的闭式表达式，以及隐蔽性约束、中断概率和有效隐蔽吞吐量（ECT）的分析公式。随后，在隐蔽性和功率分配约束下，提出了一个ECT最大化问题，并使用交替优化辅助遗传算法（AO-GA）来解决该优化问题。", "result": "仿真结果证实了理论分析，并表明RSMA优于传统多址方案，同时验证了所提出的AO-GA的有效性。", "conclusion": "RSMA在对抗多个空间随机看守者的隐蔽通信中表现出优越性，并且所提出的AO-GA算法能有效解决ECT最大化问题。", "translation": "这项工作研究了基于速率分裂多址（RSMA）的多用户多输入单输出（MISO）系统中的隐蔽通信，其中看守者的随机位置遵循齐次泊松点过程。为了展示实际部署场景，文中考虑了发射机不完善的信道状态信息。推导了接收信干噪比统计量的闭式表达式，以及隐蔽性约束、中断概率和有效隐蔽吞吐量（ECT）的分析公式。随后，在隐蔽性和功率分配约束下，提出了一个ECT最大化问题。该优化问题通过交替优化辅助遗传算法（AO-GA）解决。仿真结果证实了理论分析，并表明RSMA优于传统多址方案，同时验证了所提出的AO-GA的有效性。", "summary": "本文研究了在存在多个随机分布看守者的RSMA多用户MISO系统中的隐蔽通信。研究考虑了不完善的CSI，并推导了SINR、隐蔽性约束、中断概率和有效隐蔽吞吐量（ECT）的分析表达式。为了最大化ECT，文章提出了一个在隐蔽性和功率分配约束下的优化问题，并利用交替优化辅助遗传算法（AO-GA）进行求解。仿真结果验证了理论分析，并展示了RSMA相对于传统多址方案的优越性以及AO-GA的有效性。", "keywords": "隐蔽通信, 速率分裂多址 (RSMA), 泊松点过程, 有效隐蔽吞吐量 (ECT), 交替优化辅助遗传算法 (AO-GA)", "comments": "这项工作创新性地将RSMA技术应用于隐蔽通信领域，并在考虑随机看守者和不完善CSI的复杂场景下进行了深入分析。提出的AO-GA算法为解决ECT最大化问题提供了有效途径，其结果对未来隐蔽通信系统的设计具有重要指导意义。"}}
{"id": "2506.05484", "title": "Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?", "authors": ["Ruihua Chen", "Bangyu Wu", "Meng Li", "Kai Yang"], "summary": "Subsurface property neural network reparameterized full waveform inversion\n(FWI) has emerged as an effective unsupervised learning framework, which can\ninvert stably with an inaccurate starting model. It updates the trainable\nneural network parameters instead of fine-tuning on the subsurface model\ndirectly. There are primarily two ways to embed the prior knowledge of the\ninitial model into neural networks, that is, pretraining and denormalization.\nPretraining first regulates the neural networks' parameters by fitting the\ninitial velocity model; Denormalization directly adds the outputs of the\nnetwork into the initial models without pretraining. In this letter, we\nsystematically investigate the influence of the two ways of initial model\nincorporation for the neural network reparameterized FWI. We demonstrate that\npretraining requires inverting the model perturbation based on a constant\nvelocity value (mean) with a two-stage implementation. It leads to a complex\nworkflow and inconsistency of objective functions in the two-stage process,\ncausing the network parameters to become inactive and lose plasticity.\nExperimental results demonstrate that denormalization can simplify workflows,\naccelerate convergence, and enhance inversion accuracy compared with\npretraining.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05484v1", "AI": {"title_translation": "深度学习FWI的初始模型融合：预训练还是去归一化？", "tldr": "本文系统研究了深度学习FWI中初始模型融合的两种方法（预训练和去归一化），发现去归一化能简化工作流程、加速收敛并提高反演精度。", "motivation": "探索并比较深度学习FWI中初始模型融合的两种主要方式（预训练和去归一化）对反演性能的影响，以解决传统FWI对初始模型精度敏感的问题。", "method": "本文系统地研究了预训练和去归一化这两种初始模型融合方式对神经网络重参数化全波形反演（FWI）的影响。通过实验对比，评估了它们在工作流程、收敛速度和反演精度方面的表现。", "result": "预训练需要基于恒定速度值（均值）反演模型扰动，并采用两阶段实现，导致工作流程复杂且两阶段目标函数不一致，使网络参数变得不活跃并失去可塑性。实验结果表明，与预训练相比，去归一化可以简化工作流程、加速收敛并提高反演精度。", "conclusion": "去归一化是深度学习FWI中一种更优的初始模型融合方法，因为它能带来更简单的工作流程、更快的收敛速度和更高的反演精度，而预训练则存在复杂性、目标函数不一致以及网络参数失去可塑性等问题。", "translation": "地下属性神经网络重参数化全波形反演（FWI）已成为一种有效的无监督学习框架，即使在初始模型不准确的情况下也能稳定反演。它更新的是可训练的神经网络参数，而不是直接对地下模型进行微调。将初始模型的先验知识嵌入神经网络主要有两种方式：预训练和去归一化。预训练首先通过拟合初始速度模型来调整神经网络的参数；去归一化则直接将网络输出添加到初始模型中，而无需预训练。在这封信中，我们系统地研究了这两种初始模型融合方式对神经网络重参数化FWI的影响。我们证明，预训练需要基于恒定速度值（均值）反演模型扰动，并采用两阶段实现。这导致工作流程复杂，两阶段过程中的目标函数不一致，从而导致网络参数变得不活跃并失去可塑性。实验结果表明，与预训练相比，去归一化可以简化工作流程、加速收敛并提高反演精度。", "summary": "本文探讨了深度学习重参数化全波形反演（FWI）中初始模型融合的两种策略：预训练和去归一化。研究发现，预训练涉及复杂的多阶段流程和目标函数不一致性，导致网络参数活跃度降低。相比之下，去归一化能有效简化工作流程，加速收敛并显著提升反演精度。", "keywords": "深度学习FWI, 初始模型融合, 预训练, 去归一化, 全波形反演", "comments": "本文通过对比预训练和去归一化两种初始模型融合方式，为深度学习FWI提供了一个清晰的指导。其创新点在于系统性地揭示了预训练方法的缺陷（复杂性和参数失活），并明确指出了去归一化作为更优选择的优势。这对于提升深度学习FWI的实用性和效率具有重要意义，有助于推动该技术在地球物理勘探领域的应用。"}}
{"id": "2506.06100", "title": "Compression of executable QR codes or sQRy for Industry: an example for Wi-Fi access points", "authors": ["Stefano Scanzio", "Gabriele Formis", "Pietro Chiavassa", "Lukasz Wisniewski", "Gianluca Cena"], "summary": "Executable QR codes, or sQRy, is a technology dated 2022 that permits to\ninclude a runnable program inside a QR code, enabling interaction with the user\neven in the absence of an Internet connection. sQRy are enablers for different\npractical applications, including network equipment configuration, diagnostics,\nand enhanced smart manuals in industrial contexts. Many other\nnon-industry-related fields can also benefit from this technology. Regardless\nof where sQRy are used, text strings are among the most commonly embedded data.\nHowever, due to strict limitations on the available payload, the occupancy of\nstrings limits the length of the programs that can be embedded. In this work,\nwe propose a simple yet effective strategy that can reduce the space taken by\nstrings, hence broadening sQRy applicability.", "comment": "preprint accepted, 4 pages, 2025", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06100v1", "AI": {"title_translation": "可执行二维码或sQRy的压缩及其在工业中的应用：以Wi-Fi接入点为例", "tldr": "sQRy可执行二维码因字符串占用空间限制了程序长度，本文提出一种压缩字符串的方法以扩大其应用范围。", "motivation": "sQRy可执行二维码中字符串数据占用空间大，限制了可嵌入程序的长度，从而影响了其应用范围。", "method": "提出了一种简单而有效的策略，用于减少字符串所占用的空间。", "result": "成功减少了字符串占用的空间，从而拓宽了sQRy的应用范围。", "conclusion": "所提出的策略有效减少了字符串占用空间，从而拓宽了sQRy的应用范围。", "translation": "可执行二维码，或称sQRy，是一项2022年的技术，它允许在二维码中包含一个可运行的程序，即使在没有互联网连接的情况下也能与用户进行交互。sQRy是实现不同实际应用的推动者，包括网络设备配置、诊断以及工业环境中增强型智能手册。许多其他与工业无关的领域也可以从这项技术中受益。无论sQRy在哪里使用，文本字符串都是最常嵌入的数据之一。然而，由于对可用有效载荷的严格限制，字符串的占用空间限制了可嵌入程序的长度。在这项工作中，我们提出了一种简单而有效的策略，可以减少字符串所占用的空间，从而拓宽sQRy的适用性。", "summary": "sQRy是一种允许在无网络连接下与用户交互的可执行二维码技术，在工业领域有广泛应用。然而，由于有效载荷限制，字符串数据占用空间过大，限制了可嵌入程序的长度。本文提出了一种简单有效的策略来压缩字符串空间，旨在扩大sQRy的应用范围。", "keywords": "可执行二维码, sQRy, 压缩, 字符串, Wi-Fi接入点", "comments": "该论文提出了一种解决sQRy可执行二维码中字符串数据存储限制的实用方法，这对于扩展sQRy在工业及其他领域内的应用具有重要意义，尤其是在需要离线交互和有限存储空间的场景下。其创新点在于通过优化字符串存储来提升sQRy的实用性。"}}
{"id": "2506.05502", "title": "StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models", "authors": ["Ya Jiang", "Chuxiong Wu", "Massieh Kordi Boroujeny", "Brian Mark", "Kai Zeng"], "summary": "Watermarking for large language models (LLMs) offers a promising approach to\nidentifying AI-generated text. Existing approaches, however, either compromise\nthe distribution of original generated text by LLMs or are limited to embedding\nzero-bit information that only allows for watermark detection but ignores\nidentification. We present StealthInk, a stealthy multi-bit watermarking scheme\nthat preserves the original text distribution while enabling the embedding of\nprovenance data, such as userID, TimeStamp, and modelID, within LLM-generated\ntext. This enhances fast traceability without requiring access to the language\nmodel's API or prompts. We derive a lower bound on the number of tokens\nnecessary for watermark detection at a fixed equal error rate, which provides\ninsights on how to enhance the capacity. Comprehensive empirical evaluations\nacross diverse tasks highlight the stealthiness, detectability, and resilience\nof StealthInk, establishing it as an effective solution for LLM watermarking\napplications.", "comment": "camera-ready version", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05502v1", "AI": {"title_translation": "StealthInk: 一种针对大型语言模型的多比特隐形水印", "tldr": "StealthInk 是一种多比特隐形水印方案，用于大型语言模型（LLM）生成的文本，旨在在不改变文本原始分布的情况下嵌入来源数据，以实现快速溯源。", "motivation": "现有的LLM水印方法要么损害原始生成文本的分布，要么仅限于嵌入零比特信息，无法进行身份识别。因此，需要一种既能保持文本分布又能嵌入多比特信息以实现溯源的水印方案。", "method": "StealthInk 是一种隐形多比特水印方案，它通过在LLM生成的文本中嵌入来源数据（如userID、TimeStamp和modelID）来工作，同时保持原始文本分布。该方法不要求访问语言模型的API或提示。作者还推导了在固定等错误率下水印检测所需令牌数量的下限，以指导容量增强。", "result": "StealthInk 在不同任务中的全面实证评估表明其具有隐蔽性、可检测性和弹性。", "conclusion": "StealthInk 被确立为大型语言模型水印应用的有效解决方案。", "translation": "大型语言模型（LLM）的水印技术为识别AI生成文本提供了一种有前景的方法。然而，现有方法要么损害LLM生成的原始文本分布，要么仅限于嵌入零比特信息，仅允许水印检测而忽略识别。我们提出了StealthInk，一种隐形多比特水印方案，它在保留原始文本分布的同时，能够在LLM生成的文本中嵌入来源数据，例如用户ID、时间戳和模型ID。这增强了快速可追溯性，而无需访问语言模型的API或提示。我们推导了在固定等错误率下水印检测所需令牌数量的下限，这为如何提高容量提供了见解。跨不同任务的全面实证评估突出了StealthInk的隐蔽性、可检测性和弹性，将其确立为LLM水印应用的有效解决方案。", "summary": "该论文提出了一种名为 StealthInk 的多比特隐形水印方案，用于大型语言模型（LLM）生成的文本。与现有方法不同，StealthInk 能够在不改变文本原始分布的前提下，在LLM生成文本中嵌入用户ID、时间戳和模型ID等来源数据，从而实现快速溯源。该方案无需访问LLM的API或提示。论文还推导了水印检测所需令牌数量的下限，以指导容量增强。实验结果表明 StealthInk 具有良好的隐蔽性、可检测性和弹性，证明其是LLM水印的有效解决方案。", "keywords": "大型语言模型, 水印, 多比特, 隐形, 溯源", "comments": "StealthInk 的创新之处在于它实现了多比特水印，这使得在LLM生成文本中嵌入详细的来源信息成为可能，从而增强了溯源能力。同时，其保持原始文本分布的特性解决了现有水印方案的一个关键限制。该研究对AI生成内容的可信度和责任性具有重要意义。"}}
{"id": "2506.05396", "title": "Talk2SAM: Text-Guided Semantic Enhancement for Complex-Shaped Object Segmentation", "authors": ["Luka Vetoshkin", "Dmitry Yudin"], "summary": "Segmenting objects with complex shapes, such as wires, bicycles, or\nstructural grids, remains a significant challenge for current segmentation\nmodels, including the Segment Anything Model (SAM) and its high-quality variant\nSAM-HQ. These models often struggle with thin structures and fine boundaries,\nleading to poor segmentation quality. We propose Talk2SAM, a novel approach\nthat integrates textual guidance to improve segmentation of such challenging\nobjects. The method uses CLIP-based embeddings derived from user-provided text\nprompts to identify relevant semantic regions, which are then projected into\nthe DINO feature space. These features serve as additional prompts for SAM-HQ,\nenhancing its ability to focus on the target object. Beyond improving\nsegmentation accuracy, Talk2SAM allows user-controllable segmentation, enabling\ndisambiguation of objects within a single bounding box based on textual input.\nWe evaluate our approach on three benchmarks: BIG, ThinObject5K, and DIS5K.\nTalk2SAM consistently outperforms SAM-HQ, achieving up to +5.9\\% IoU and +8.3\\%\nboundary IoU improvements. Our results demonstrate that incorporating natural\nlanguage guidance provides a flexible and effective means for precise object\nsegmentation, particularly in cases where traditional prompt-based methods\nfail. The source code is available on GitHub:\nhttps://github.com/richlukich/Talk2SAM", "comment": "14 pages, 7 figures, Submitted to the conference", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05396v1", "AI": {"title_translation": "Talk2SAM：文本引导的复杂形状对象分割语义增强", "tldr": "Talk2SAM通过文本引导语义增强，显著提高了SAM-HQ对复杂形状对象的分割精度，特别是薄结构和精细边界。", "motivation": "现有分割模型（包括SAM和SAM-HQ）难以分割复杂形状对象（如电线、自行车、结构网格），在薄结构和精细边界上表现不佳，导致分割质量差。", "method": "Talk2SAM利用用户提供的文本提示生成基于CLIP的嵌入，将其投影到DINO特征空间，这些特征作为SAM-HQ的额外提示，增强其对目标对象的关注。此外，它还支持用户可控的分割，通过文本输入消除单个边界框内对象的歧义。", "result": "Talk2SAM在BIG、ThinObject5K和DIS5K三个基准测试中始终优于SAM-HQ，IoU提高了高达5.9%，边界IoU提高了8.3%。结果表明，结合自然语言指导为精确对象分割提供了灵活有效的方法，尤其是在传统基于提示的方法失败的情况下。", "conclusion": "结合自然语言指导为精确对象分割提供了一种灵活有效的方法，尤其是在传统基于提示的方法失败的情况下，并且能够显著提高复杂形状对象的分割精度。", "translation": "Talk2SAM：文本引导的复杂形状对象分割语义增强\n\n分割电线、自行车或结构网格等复杂形状对象仍然是当前分割模型（包括Segment Anything Model (SAM) 及其高质量变体SAM-HQ）面临的重大挑战。这些模型通常难以处理薄结构和精细边界，导致分割质量不佳。我们提出了Talk2SAM，一种新颖的方法，它集成了文本引导以改善此类挑战性对象的分割。该方法使用从用户提供的文本提示派生出的基于CLIP的嵌入来识别相关的语义区域，然后将其投影到DINO特征空间中。这些特征作为SAM-HQ的额外提示，增强了其关注目标对象的能力。除了提高分割精度，Talk2SAM还允许用户可控的分割，通过文本输入消除单个边界框内对象的歧义。我们在三个基准测试上评估了我们的方法：BIG、ThinObject5K和DIS5K。Talk2SAM始终优于SAM-HQ，IoU提高了高达+5.9%，边界IoU提高了+8.3%。我们的结果表明，结合自然语言指导为精确对象分割提供了一种灵活有效的方法，尤其是在传统基于提示的方法失败的情况下。源代码可在GitHub上获取：https://github.com/richlukich/Talk2SAM", "summary": "Talk2SAM是一种新颖的文本引导语义增强方法，旨在解决现有分割模型（如SAM和SAM-HQ）在分割电线、自行车等复杂形状对象时遇到的挑战。该方法利用CLIP嵌入和DINO特征空间，将用户提供的文本提示转化为SAM-HQ的额外提示，从而提高其对目标对象的关注和分割精度。实验结果表明，Talk2SAM在多个基准测试中显著优于SAM-HQ，并在用户可控分割方面展现了优势。", "keywords": "复杂形状对象分割, 文本引导, SAM-HQ, CLIP, DINO, 语义增强", "comments": "Talk2SAM的创新之处在于其将文本引导与视觉分割模型SAM-HQ相结合，有效解决了复杂形状对象（特别是薄结构和精细边界）的分割难题。这种方法不仅提高了分割精度，还通过文本输入实现了用户可控的语义消歧，增强了模型的实用性和灵活性。这对于需要高精度和精细控制的图像编辑、医学成像等领域具有重要意义。"}}
{"id": "2506.05904", "title": "Proactive Assistant Dialogue Generation from Streaming Egocentric Videos", "authors": ["Yichi Zhang", "Xin Luna Dong", "Zhaojiang Lin", "Andrea Madotto", "Anuj Kumar", "Babak Damavandi", "Joyce Chai", "Seungwhan Moon"], "summary": "Recent advances in conversational AI have been substantial, but developing\nreal-time systems for perceptual task guidance remains challenging. These\nsystems must provide interactive, proactive assistance based on streaming\nvisual inputs, yet their development is constrained by the costly and\nlabor-intensive process of data collection and system evaluation. To address\nthese limitations, we present a comprehensive framework with three key\ncontributions. First, we introduce a novel data curation pipeline that\nsynthesizes dialogues from annotated egocentric videos, resulting in \\dataset,\na large-scale synthetic dialogue dataset spanning multiple domains. Second, we\ndevelop a suite of automatic evaluation metrics, validated through extensive\nhuman studies. Third, we propose an end-to-end model that processes streaming\nvideo inputs to generate contextually appropriate responses, incorporating\nnovel techniques for handling data imbalance and long-duration videos. This\nwork lays the foundation for developing real-time, proactive AI assistants\ncapable of guiding users through diverse tasks. Project page:\nhttps://pro-assist.github.io/", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05904v1", "AI": {"title_translation": "基于流式第一人称视频的主动式助手对话生成", "tldr": "本文提出了一个用于主动式人工智能助手的综合框架，包括数据合成管道、自动评估指标和端到端模型，旨在通过处理流式第一人称视频来生成对话。", "motivation": "尽管会话式人工智能取得了显著进展，但开发用于感知任务指导的实时系统仍面临挑战，主要受限于数据收集和系统评估的高成本和劳动密集型过程。这些系统需要基于流式视觉输入提供交互式、主动的辅助。", "method": "本文提出了一个包含三个关键贡献的综合框架：1. 引入了一种新颖的数据整理管道，从标注的第一人称视频中合成对话，创建了大规模合成对话数据集\\dataset。2. 开发了一套通过广泛人工研究验证的自动评估指标。3. 提出了一个端到端模型，用于处理流式视频输入并生成符合上下文的响应，该模型包含了处理数据不平衡和长时视频的新颖技术。", "result": "该工作为开发能够指导用户完成各种任务的实时、主动式人工智能助手奠定了基础。具体成果包括创建了大规模合成对话数据集\\dataset，开发了经验证的自动评估指标，并提出了能够处理流式视频输入生成上下文适宜响应的端到端模型。", "conclusion": "这项工作为开发能够指导用户完成各种任务的实时、主动式人工智能助手奠定了基础。", "translation": "会话式人工智能的最新进展显著，但开发用于感知任务指导的实时系统仍然充满挑战。这些系统必须基于流式视觉输入提供交互式、主动的辅助，然而其开发受到数据收集和系统评估成本高昂且劳动密集型过程的限制。为了解决这些局限性，我们提出了一个包含三个关键贡献的综合框架。首先，我们引入了一种新颖的数据整理管道，可以从标注的第一人称视频中合成对话，从而产生了\\dataset，一个跨多个领域的大规模合成对话数据集。其次，我们开发了一套自动评估指标，并通过广泛的人工研究进行了验证。第三，我们提出了一个端到端模型，用于处理流式视频输入以生成符合上下文的响应，其中包含了处理数据不平衡和长时视频的新颖技术。这项工作为开发能够指导用户完成各种任务的实时、主动式人工智能助手奠定了基础。项目页面：https://pro-assist.github.io/", "summary": "本文提出了一个全面的框架，用于从流式第一人称视频中生成主动式助手对话。它通过引入新颖的数据合成管道（创建了大规模的\\dataset数据集）、开发自动评估指标以及提出一个能够从视频输入中实时生成上下文适宜响应的端到端模型，解决了数据收集和系统评估的挑战。该工作旨在促进实时、主动式人工智能助手在任务指导方面的开发。", "keywords": "主动式人工智能助手, 对话生成, 第一人称视频, 合成数据集, 实时系统", "comments": "该论文通过为数据生成、评估和模型开发提供全面的解决方案，解决了实时人工智能助手中一个关键挑战。关注第一人称视频和主动式辅助是创新的，而大规模合成数据集（\\dataset）的创建对该领域是一个重大贡献，可能缓解数据稀缺问题。自动指标通过人工研究的验证也增加了其可信度。"}}
{"id": "2506.05955", "title": "Dual Approach to Inverse Covariance Intersection Fusion", "authors": ["Jiří Ajgl", "Ondřej Straka"], "summary": "Linear fusion of estimates under the condition of no knowledge of correlation\nof estimation errors has reached maturity. On the other hand, various cases of\npartial knowledge are still active research areas. A frequent motivation is to\ndeal with \"common information\" or \"common noise\", whatever it means. A fusion\nrule for a strict meaning of the former expression has already been elaborated.\nDespite the dual relationship, a strict meaning of the latter one has not been\nconsidered so far. The paper focuses on this area. The assumption of unknown\n\"common noise\" is formulated first, analysis of theoretical properties and\nillustrations follow. Although the results are disappointing from the\nperspective of a single upper bound of mean square error matrices, the partial\nknowledge demonstrates improvement over no knowledge in suboptimal cases and\nfrom the perspective of families of upper bounds.", "comment": "Submitted to the conference MFI 2024", "cate": "eess.SP", "url": "http://arxiv.org/pdf/2506.05955v1", "AI": {"title_translation": "逆协方差交集融合的双重方法", "tldr": "本文研究了未知“共同噪声”条件下的估计融合，发现尽管单个均方误差上限不理想，但在次优情况和上限族方面仍有改进。", "motivation": "在估计误差相关性未知的情况下，处理线性估计融合中的“共同信息”或“共同噪声”问题，特别是之前未严格考虑的“共同噪声”方面。", "method": "首先提出未知“共同噪声”的假设，然后进行理论性质分析和说明。", "result": "从均方误差矩阵的单个上限角度来看结果令人失望，但在次优情况以及从上限族角度来看，部分知识显示出优于无知识的改进。", "conclusion": "即使无法获得单个最佳上限，部分“共同噪声”知识在特定场景（次优情况、上限族）中仍能提供改进。", "translation": "线性估计融合在估计误差相关性未知的情况下已趋于成熟。另一方面，各种部分知识的情况仍然是活跃的研究领域。一个常见的动机是处理“共同信息”或“共同噪声”，无论其含义如何。前一个表达的严格含义的融合规则已经阐明。尽管存在双重关系，但后一个表达的严格含义迄今尚未被考虑。本文重点关注这一领域。首先提出了未知“共同噪声”的假设，随后进行理论性质分析和说明。尽管从均方误差矩阵的单个上限角度来看结果令人失望，但部分知识在次优情况下以及从上限族角度来看，显示出优于无知识的改进。", "summary": "本文研究了在未知“共同噪声”假设下的线性估计融合，这是与“共同信息”对偶但较少探索的领域。文章首先阐述了这一假设，并对其理论性质进行了分析。结果表明，尽管在单一均方误差矩阵上限方面表现不佳，但在次优情境和考虑上限族时，这种部分知识仍能比完全无知的情况带来改进。", "keywords": "逆协方差交集, 融合, 共同噪声, 部分知识, 估计误差", "comments": "该论文探讨了融合领域中一个特定且较少被探索的方面——“共同噪声”，这对于无法获得完整相关性知识的实际应用至关重要。研究发现，即使未能提供普遍最优的单一上限，部分知识仍能带来益处，这突出了探索这些部分知识场景的实用价值。其对理论性质的关注为未来的研究奠定了基础。"}}
{"id": "2506.05497", "title": "Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models", "authors": ["Sima Noorani", "Shayan Kiyani", "George Pappas", "Hamed Hassani"], "summary": "Uncertainty quantification (UQ) is essential for safe deployment of\ngenerative AI models such as large language models (LLMs), especially in high\nstakes applications. Conformal prediction (CP) offers a principled uncertainty\nquantification framework, but classical methods focus on regression and\nclassification, relying on geometric distances or softmax scores: tools that\npresuppose structured outputs. We depart from this paradigm by studying CP in a\nquery only setting, where prediction sets must be constructed solely from\nfinite queries to a black box generative model, introducing a new trade off\nbetween coverage, test time query budget, and informativeness. We introduce\nConformal Prediction with Query Oracle (CPQ), a framework characterizing the\noptimal interplay between these objectives. Our finite sample algorithm is\nbuilt on two core principles: one governs the optimal query policy, and the\nother defines the optimal mapping from queried samples to prediction sets.\nRemarkably, both are rooted in the classical missing mass problem in\nstatistics. Specifically, the optimal query policy depends on the rate of\ndecay, or the derivative, of the missing mass, for which we develop a novel\nestimator. Meanwhile, the optimal mapping hinges on the missing mass itself,\nwhich we estimate using Good Turing estimators. We then turn our focus to\nimplementing our method for language models, where outputs are vast, variable,\nand often under specified. Fine grained experiments on three real world open\nended tasks and two LLMs, show CPQ applicability to any black box LLM and\nhighlight: (1) individual contribution of each principle to CPQ performance,\nand (2) CPQ ability to yield significantly more informative prediction sets\nthan existing conformal methods for language uncertainty quantification.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05497v1", "AI": {"title_translation": "超越已知的一致性预测：生成模型不确定性量化的缺失质量视角", "tldr": "生成式AI模型，特别是大型语言模型（LLMs）的安全部署需要不确定性量化（UQ）。经典的一致性预测（CP）方法不适用于生成模型非结构化输出。本文提出了一种名为CPQ的新框架，它在仅查询设置下，通过“缺失质量”的视角，为黑盒生成模型（尤其是LLMs）提供不确定性量化，并能生成信息量更大的预测集。", "motivation": "不确定性量化对于生成式AI模型（如大型语言模型LLMs）的安全部署至关重要，尤其是在高风险应用中。然而，经典的一致性预测方法主要关注回归和分类任务，依赖于几何距离或softmax分数，这些工具预设了结构化输出，不适用于生成模型非结构化的输出。", "method": "本文提出了一种名为“带查询预言机的一致性预测（CPQ）”的框架，用于在仅查询设置下，从对黑盒生成模型的有限查询中构建预测集。该框架通过权衡覆盖范围、测试时查询预算和信息量来表征这些目标之间的最佳相互作用。其有限样本算法建立在两个核心原则之上：一个控制最佳查询策略，另一个定义从查询样本到预测集的最佳映射。这两个原则都植根于统计学中的经典缺失质量问题。具体而言，最佳查询策略取决于缺失质量的衰减率（即导数），为此开发了一种新颖的估计器；而最佳映射则取决于缺失质量本身，通过Good Turing估计器进行估计。", "result": "在三个真实世界的开放式任务和两个大型语言模型上的精细实验表明，CPQ适用于任何黑盒大型语言模型，并突出显示了：(1) 每个原则对CPQ性能的个体贡献，以及 (2) CPQ能够比现有语言不确定性量化的一致性方法产生信息量显著更高的预测集。", "conclusion": "CPQ是一个有效且有原则的框架，通过利用缺失质量问题中的原则，为黑盒生成模型（特别是大型语言模型）提供不确定性量化，并能够生成信息量更大的预测集。", "translation": "不确定性量化（UQ）对于生成式AI模型（如大型语言模型LLMs）的安全部署至关重要，尤其是在高风险应用中。一致性预测（CP）提供了一个有原则的不确定性量化框架，但经典方法侧重于回归和分类，依赖于几何距离或softmax分数：这些工具预设了结构化输出。我们通过在仅查询设置下研究CP来脱离这种范式，其中预测集必须仅通过对黑盒生成模型的有限查询来构建，引入了覆盖范围、测试时查询预算和信息量之间的新权衡。我们引入了带查询预言机的一致性预测（CPQ），这是一个表征这些目标之间最佳相互作用的框架。我们的有限样本算法建立在两个核心原则之上：一个控制最佳查询策略，另一个定义从查询样本到预测集的最佳映射。值得注意的是，两者都植根于统计学中的经典缺失质量问题。具体而言，最佳查询策略取决于缺失质量的衰减率（即导数），为此我们开发了一种新颖的估计器。同时，最佳映射取决于缺失质量本身，我们使用Good Turing估计器对其进行估计。然后，我们将重点转向将我们的方法应用于语言模型，其中输出是庞大、多变且通常不明确的。在三个真实世界的开放式任务和两个大型语言模型上的精细实验表明，CPQ适用于任何黑盒大型语言模型，并突出显示：(1) 每个原则对CPQ性能的个体贡献，以及 (2) CPQ能够比现有语言不确定性量化的一致性方法产生信息量显著更高的预测集。", "summary": "本文提出了一种名为“带查询预言机的一致性预测（CPQ）”的新框架，旨在解决生成式AI模型（特别是大型语言模型）的不确定性量化问题。针对传统一致性预测方法不适用于生成模型非结构化输出的局限性，CPQ在仅查询的黑盒设置下工作。该框架的核心思想是利用统计学中的“缺失质量”问题，来确定最佳查询策略和从查询样本到预测集的最佳映射。实验结果表明，CPQ适用于任何黑盒大型语言模型，并且能够生成比现有方法信息量更大的预测集，为生成模型的安全部署提供了重要工具。", "keywords": "一致性预测, 不确定性量化, 生成模型, 缺失质量, 大型语言模型", "comments": "本文的创新之处在于成功地将一致性预测框架应用于生成模型这一具有挑战性的领域，特别是针对大型语言模型非结构化输出的特点，提出了“仅查询”设置下的解决方案。通过引入“缺失质量”这一统计学概念，并为其开发了新颖的估计方法，CPQ为黑盒生成模型的不确定性量化提供了一个有原则且有效的方法。这对于提高生成式AI模型在关键应用中的安全性、可靠性具有重要意义。"}}
{"id": "2506.05373", "title": "Game Theory in Social Media: A Stackelberg Model of Collaboration, Conflict, and Algorithmic Incentives", "authors": ["Arjan Khadka"], "summary": "Social media platforms are ecosystems in which many decisions are constantly\nmade for the benefit of the creators in order to maximize engagement, which\nleads to a maximization of income. The decisions, ranging from collaboration to\npublic conflict or ``beefing,'' are heavily influenced by social media\nalgorithms, viewer preferences, and sponsor risk. This paper models this\ninteraction as a Stackelberg game in which the algorithm is the leader, setting\nexposure and reward rules, and the content creators are the followers, who\noptimize their content to maximize engagement. It focuses on two influencer\nstrategies of collaborating and beefing. Viewer preferences are modeled\nindirectly through the algorithm's utility function, which rewards engagement\nmetrics like click-through rate and watch time. Our simplified game-theoretic\nmodel demonstrates how different algorithmic priorities can shift creator\nstrategies and provides insight into the equilibrium dynamics of social media\ninfluence.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.05373v1", "AI": {"title_translation": "社交媒体中的博弈论：协作、冲突和算法激励的斯塔克尔伯格模型", "tldr": "本研究将社交媒体创作者的策略（协作与冲突）建模为一个斯塔克尔伯格博弈，其中算法是领导者，创作者是追随者，展示了算法优先级如何改变创作者行为。", "motivation": "社交媒体平台上的创作者决策（从协作到公开冲突）受到算法、观众偏好和赞助商风险的严重影响。本研究旨在通过建模来理解这些互动，特别是算法如何影响创作者策略。", "method": "本文将这种互动建模为一个斯塔克尔伯格博弈，其中算法是领导者，设定曝光和奖励规则，而内容创作者是追随者，优化其内容以最大限度地提高参与度。研究侧重于影响者的两种策略：协作和“互撕”。观众偏好通过算法的效用函数间接建模。", "result": "我们简化的博弈论模型表明，不同的算法优先级可以改变创作者策略，并提供了对社交媒体影响力均衡动态的深入见解。", "conclusion": "不同的算法优先级能够改变创作者的策略，从而影响社交媒体影响力的均衡动态。", "translation": "社交媒体平台是生态系统，其中不断做出许多决策以造福创作者，以最大化参与度，从而实现收入最大化。这些决策，从协作到公开冲突或“互撕”，都受到社交媒体算法、观众偏好和赞助商风险的严重影响。本文将这种互动建模为一个斯塔克尔伯格博弈，其中算法是领导者，设定曝光和奖励规则，而内容创作者是追随者，他们优化其内容以最大化参与度。它侧重于影响者的两种策略：协作和“互撕”。观众偏好通过算法的效用函数间接建模，该函数奖励点击率和观看时长等参与度指标。我们简化的博弈论模型表明，不同的算法优先级可以改变创作者策略，并提供了对社交媒体影响力均衡动态的深入见解。", "summary": "本文通过构建一个斯塔克尔伯格博弈模型，分析了社交媒体中算法与内容创作者之间的互动。模型中，算法作为领导者设定曝光和奖励规则，而创作者作为追随者优化内容以最大化参与度，特别关注协作和“互撕”两种策略。研究结果表明，算法优先级的变化会影响创作者的策略选择，并揭示了社交媒体影响力的均衡动态。", "keywords": "博弈论, 社交媒体, 斯塔克尔伯格模型, 算法激励, 内容创作者", "comments": "本文创新性地将斯塔克尔伯格博弈模型应用于社交媒体领域，分析算法与内容创作者之间的复杂动态。该模型为理解算法激励如何塑造创作者策略和平台生态系统提供了一个理论框架，具有重要的研究价值。"}}
{"id": "2506.06166", "title": "The Lock-in Hypothesis: Stagnation by Algorithm", "authors": ["Tianyi Alex Qiu", "Zhonghao He", "Tejasveer Chugh", "Max Kleiman-Weiner"], "summary": "The training and deployment of large language models (LLMs) create a feedback\nloop with human users: models learn human beliefs from data, reinforce these\nbeliefs with generated content, reabsorb the reinforced beliefs, and feed them\nback to users again and again. This dynamic resembles an echo chamber. We\nhypothesize that this feedback loop entrenches the existing values and beliefs\nof users, leading to a loss of diversity and potentially the lock-in of false\nbeliefs. We formalize this hypothesis and test it empirically with agent-based\nLLM simulations and real-world GPT usage data. Analysis reveals sudden but\nsustained drops in diversity after the release of new GPT iterations,\nconsistent with the hypothesized human-AI feedback loop. Code and data\navailable at https://thelockinhypothesis.com", "comment": "ICML 2025, 46 pages", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06166v1", "AI": {"title_translation": "锁定假说：算法导致的停滞", "tldr": "大型语言模型与人类用户的反馈循环可能导致多样性丧失和错误信念的锁定。", "motivation": "探讨大型语言模型（LLM）与人类用户的反馈循环如何固化现有价值观和信念，导致多样性丧失，并可能锁定错误信念。", "method": "通过基于代理的LLM模拟和真实的GPT使用数据进行实证检验。", "result": "分析显示，在新版GPT发布后，多样性出现突然但持续的下降。", "conclusion": "这些结果与假设的人机反馈循环一致，表明LLM的反馈循环可能导致现有价值观和信念的固化以及多样性的丧失。", "translation": "大型语言模型（LLM）的训练和部署与人类用户形成了一个反馈循环：模型从数据中学习人类的信念，用生成的内容强化这些信念，重新吸收被强化的信念，并一次又一次地将它们反馈给用户。这种动态类似于回音室。我们假设这种反馈循环会固化用户现有的价值观和信念，导致多样性丧失，并可能锁定错误信念。我们对这一假设进行了形式化，并通过基于代理的LLM模拟和真实的GPT使用数据进行了实证检验。分析显示，在新版GPT发布后，多样性出现突然但持续的下降，这与假设的人机反馈循环一致。代码和数据可在https://thelockinhypothesis.com获取。", "summary": "本文提出了“锁定假说”，认为大型语言模型（LLM）与人类用户之间的反馈循环（模型学习、强化并再吸收信念）可能导致现有价值观和信念的固化，从而减少多样性并可能锁定错误信念。研究通过基于代理的LLM模拟和真实GPT数据进行了实证测试，发现新GPT版本发布后多样性出现突然但持续的下降，证实了人机反馈循环的影响。", "keywords": "大型语言模型, 反馈循环, 多样性丧失, 锁定假说, 算法停滞", "comments": "这项研究提出了一个关于LLM潜在负面影响的重要假说，即其反馈机制可能导致文化和认知上的“锁定”效应，减少多样性。其使用模拟和真实数据相结合的方法增加了研究的可信度。研究结果对LLM的设计和部署提出了警示，提示我们需要关注算法对人类信念和多样性的深远影响。"}}
{"id": "2506.05594", "title": "SoK: Are Watermarks in LLMs Ready for Deployment?", "authors": ["Kieu Dang", "Phung Lai", "NhatHai Phan", "Yelong Shen", "Ruoming Jin", "Abdallah Khreishah", "My Thai"], "summary": "Large Language Models (LLMs) have transformed natural language processing,\ndemonstrating impressive capabilities across diverse tasks. However, deploying\nthese models introduces critical risks related to intellectual property\nviolations and potential misuse, particularly as adversaries can imitate these\nmodels to steal services or generate misleading outputs. We specifically focus\non model stealing attacks, as they are highly relevant to proprietary LLMs and\npose a serious threat to their security, revenue, and ethical deployment. While\nvarious watermarking techniques have emerged to mitigate these risks, it\nremains unclear how far the community and industry have progressed in\ndeveloping and deploying watermarks in LLMs.\n  To bridge this gap, we aim to develop a comprehensive systematization for\nwatermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs,\n2) proposing a novel intellectual property classifier to explore the\neffectiveness and impacts of watermarks on LLMs under both attack and\nattack-free environments, 3) analyzing the limitations of existing watermarks\nin LLMs, and 4) discussing practical challenges and potential future directions\nfor watermarks in LLMs. Through extensive experiments, we show that despite\npromising research outcomes and significant attention from leading companies\nand community to deploy watermarks, these techniques have yet to reach their\nfull potential in real-world applications due to their unfavorable impacts on\nmodel utility of LLMs and downstream tasks. Our findings provide an insightful\nunderstanding of watermarks in LLMs, highlighting the need for practical\nwatermarks solutions tailored to LLM deployment.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05594v1", "AI": {"title_translation": "SoK：LLM 中的水印是否已准备好部署？", "tldr": "本研究系统化地分析了大型语言模型（LLM）中的水印技术，发现尽管研究前景广阔，但由于对模型效用和下游任务的不利影响，现有水印技术尚未准备好在实际部署中充分应用。", "motivation": "部署大型语言模型（LLM）带来了知识产权侵犯和潜在滥用等关键风险，尤其是模型窃取攻击对专有LLM的安全性、收益和伦理部署构成严重威胁。尽管已出现各种水印技术来缓解这些风险，但社区和行业在LLM中开发和部署水印的进展程度尚不明确。", "method": "为了弥补这一空白，本文旨在为LLM中的水印开发一个全面的知识系统（Systematization of Knowledge），具体包括：1) 提出LLM水印的详细分类法；2) 提出一种新颖的知识产权分类器，以探索水印在攻击和无攻击环境下的有效性和影响；3) 分析现有LLM水印的局限性；4) 讨论LLM水印的实际挑战和潜在未来方向。", "result": "通过广泛的实验，研究表明，尽管研究成果喜人且受到领先公司和社区的广泛关注，但由于对LLM模型效用和下游任务的不利影响，现有水印技术尚未在实际应用中充分发挥其潜力。", "conclusion": "本研究的发现提供了对LLM中水印的深刻理解，强调了需要为LLM部署量身定制的实用水印解决方案。", "translation": "大型语言模型（LLM）已经改变了自然语言处理领域，在各种任务中展现出令人印象深刻的能力。然而，部署这些模型带来了与知识产权侵犯和潜在滥用相关的关键风险，特别是当攻击者可以模仿这些模型以窃取服务或生成误导性输出时。我们特别关注模型窃取攻击，因为它们与专有LLM高度相关，并对其安全性、收益和伦理部署构成严重威胁。尽管各种水印技术已经出现以缓解这些风险，但社区和行业在LLM中开发和部署水印的进展程度尚不明确。\n为了弥补这一空白，我们旨在通过以下方式为LLM中的水印开发一个全面的知识系统：1) 提出LLM水印的详细分类法；2) 提出一种新颖的知识产权分类器，以探索水印在攻击和无攻击环境下的有效性和影响；3) 分析现有LLM水印的局限性；4) 讨论LLM水印的实际挑战和潜在未来方向。通过广泛的实验，我们表明，尽管研究成果喜人且受到领先公司和社区的广泛关注，但由于对LLM模型效用和下游任务的不利影响，这些技术尚未在实际应用中充分发挥其潜力。我们的发现提供了对LLM中水印的深刻理解，强调了需要为LLM部署量身定制的实用水印解决方案。", "summary": "本文对大型语言模型（LLM）中的水印技术进行了全面的知识系统化研究，旨在解决LLM部署中面临的知识产权侵犯和模型窃取风险。研究提出了LLM水印的详细分类法、新颖的知识产权分类器，并分析了现有水印的局限性及其面临的实际挑战。实验结果表明，尽管水印技术受到广泛关注并取得一定研究进展，但由于其对LLM模型效用和下游任务的不利影响，尚未完全准备好在实际世界中部署。研究强调了开发更实用、适应LLM部署需求的水印解决方案的必要性。", "keywords": "LLM, 水印, 模型窃取, 知识产权, 知识系统化", "comments": "本文通过提供LLM水印的全面知识系统化（SoK），填补了该领域的一个重要空白。其创新之处在于提出了详细的分类法和新颖的知识产权分类器。研究的重要性在于直接解决了LLM部署中日益增长的知识产权保护和模型滥用风险。然而，其主要局限性在于揭示了现有水印技术对模型效用和下游任务的不利影响，表明这些技术尚未成熟到可以大规模实际部署。这为未来的研究指明了方向，即开发更实用、对模型性能影响更小的水印解决方案。"}}
{"id": "2506.06196", "title": "Bridging Perception and Action: Spatially-Grounded Mid-Level Representations for Robot Generalization", "authors": ["Jonathan Yang", "Chuyuan Kelly Fu", "Dhruv Shah", "Dorsa Sadigh", "Fei Xia", "Tingnan Zhang"], "summary": "In this work, we investigate how spatially grounded auxiliary representations\ncan provide both broad, high-level grounding as well as direct, actionable\ninformation to improve policy learning performance and generalization for\ndexterous tasks. We study these mid-level representations across three critical\ndimensions: object-centricity, pose-awareness, and depth-awareness. We use\nthese interpretable mid-level representations to train specialist encoders via\nsupervised learning, then feed them as inputs to a diffusion policy to solve\ndexterous bimanual manipulation tasks in the real world. We propose a novel\nmixture-of-experts policy architecture that combines multiple specialized\nexpert models, each trained on a distinct mid-level representation, to improve\npolicy generalization. This method achieves an average success rate that is 11%\nhigher than a language-grounded baseline and 24 percent higher than a standard\ndiffusion policy baseline on our evaluation tasks. Furthermore, we find that\nleveraging mid-level representations as supervision signals for policy actions\nwithin a weighted imitation learning algorithm improves the precision with\nwhich the policy follows these representations, yielding an additional\nperformance increase of 10%. Our findings highlight the importance of grounding\nrobot policies not only with broad perceptual tasks but also with more\ngranular, actionable representations. For further information and videos,\nplease visit https://mid-level-moe.github.io.", "comment": "16 pages, 13 figures", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06196v1", "AI": {"title_translation": "连接感知与行动：用于机器人泛化的空间接地中层表示", "tldr": "本研究探索了空间接地的中层表示如何提供广泛的高层接地信息和直接可操作的信息，以提高机器人灵巧任务中策略学习的性能和泛化能力。通过结合专业编码器和新型专家混合策略架构，该方法显著提升了成功率，并强调了使用细粒度、可操作表示的重要性。", "motivation": "本研究旨在探究空间接地的辅助表示如何提供广泛的高层接地信息以及直接可操作的信息，从而改善灵巧任务中策略学习的性能和泛化能力。", "method": "研究了以物体为中心、姿态感知和深度感知三个关键维度的中层表示。通过监督学习训练专业编码器，并将其作为输入馈送给扩散策略。提出了一种新颖的专家混合（MoE）策略架构，该架构结合了多个在不同中层表示上训练的专业专家模型，以提高策略泛化能力。此外，利用中层表示作为加权模仿学习算法中策略动作的监督信号。", "result": "该方法在评估任务中，平均成功率比语言接地基线高11%，比标准扩散策略基线高24%。利用中层表示作为策略动作的监督信号，通过加权模仿学习算法，额外提高了10%的性能。", "conclusion": "研究结果强调了不仅要用广泛的感知任务，还要用更细粒度、可操作的表示来接地机器人策略的重要性。", "translation": "在这项工作中，我们研究了空间接地的辅助表示如何提供广泛的高层接地信息以及直接可操作的信息，以提高灵巧任务中策略学习的性能和泛化能力。我们从三个关键维度：以物体为中心、姿态感知和深度感知，研究了这些中层表示。我们使用这些可解释的中层表示，通过监督学习训练专业编码器，然后将它们作为输入馈送给扩散策略，以解决现实世界中的灵巧双臂操作任务。我们提出了一种新颖的专家混合策略架构，该架构结合了多个专业专家模型，每个模型都在不同的中层表示上进行训练，以提高策略泛化能力。在我们的评估任务中，该方法实现的平均成功率比语言接地基线高11%，比标准扩散策略基线高24%。此外，我们发现利用中层表示作为加权模仿学习算法中策略动作的监督信号，提高了策略遵循这些表示的精确度，从而额外提高了10%的性能。我们的发现强调了不仅要用广泛的感知任务，还要用更细粒度、可操作的表示来接地机器人策略的重要性。更多信息和视频，请访问 https://mid-level-moe.github.io。", "summary": "本论文探讨了通过使用空间接地的中层表示来提高机器人灵巧操作任务中的策略学习性能和泛化能力。研究分析了以物体为中心、姿态感知和深度感知等中层表示，并利用它们训练专业编码器，进而输入到扩散策略中。作者提出了一种创新的专家混合策略架构，该架构整合了基于不同中层表示训练的多个专业模型，显著提升了策略的泛化能力。实验结果表明，该方法在成功率上优于现有基线，并且通过将中层表示作为加权模仿学习的监督信号，进一步提高了性能。研究强调了将机器人策略与细粒度、可操作的表示相结合的重要性。", "keywords": "空间接地表示, 中层表示, 机器人泛化, 扩散策略, 专家混合", "comments": "本文的创新点在于提出了空间接地的中层表示，并结合了新颖的专家混合策略架构来解决机器人灵巧操作的泛化问题。这种方法有效桥接了感知与行动，通过提供更细粒度的信息，显著提升了策略学习的性能和泛化能力。其在成功率上的显著提升证明了该方法的有效性，为机器人泛化学习提供了新的视角和技术路线。"}}
{"id": "2506.05399", "title": "Attention-based transformer models for image captioning across languages: An in-depth survey and evaluation", "authors": ["Israa A. Albadarneh", "Bassam H. Hammo", "Omar S. Al-Kadi"], "summary": "Image captioning involves generating textual descriptions from input images,\nbridging the gap between computer vision and natural language processing.\nRecent advancements in transformer-based models have significantly improved\ncaption generation by leveraging attention mechanisms for better scene\nunderstanding. While various surveys have explored deep learning-based\napproaches for image captioning, few have comprehensively analyzed\nattention-based transformer models across multiple languages. This survey\nreviews attention-based image captioning models, categorizing them into\ntransformer-based, deep learning-based, and hybrid approaches. It explores\nbenchmark datasets, discusses evaluation metrics such as BLEU, METEOR, CIDEr,\nand ROUGE, and highlights challenges in multilingual captioning. Additionally,\nthis paper identifies key limitations in current models, including semantic\ninconsistencies, data scarcity in non-English languages, and limitations in\nreasoning ability. Finally, we outline future research directions, such as\nmultimodal learning, real-time applications in AI-powered assistants,\nhealthcare, and forensic analysis. This survey serves as a comprehensive\nreference for researchers aiming to advance the field of attention-based image\ncaptioning.", "comment": "31 pages, 15 figures, 6 tables", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05399v1", "AI": {"title_translation": "跨语言图像字幕的基于注意力的Transformer模型：深入调查与评估", "tldr": "该论文全面调查了跨语言图像字幕的基于注意力的Transformer模型，分类了现有方法，讨论了评估指标和挑战，并提出了未来研究方向。", "motivation": "尽管现有调查已探讨深度学习图像字幕方法，但很少有研究全面分析跨多种语言的基于注意力的Transformer模型，因此需要一份深入的调查报告。", "method": "该调查回顾了基于注意力的图像字幕模型，将其分为基于Transformer、基于深度学习和混合方法。它探讨了基准数据集，讨论了BLEU、METEOR、CIDEr和ROUGE等评估指标，并强调了多语言字幕中的挑战。此外，本文还指出了当前模型的主要局限性。", "result": "结果是系统地分类了基于注意力的图像字幕模型，讨论了评估指标，并明确了多语言字幕的挑战（如语义不一致性、非英语数据稀缺、推理能力限制）。同时，提出了未来的研究方向，如多模态学习、AI助手、医疗保健和法医分析中的实时应用。", "conclusion": "这份调查报告为旨在推进基于注意力的图像字幕领域的研究人员提供了全面的参考。", "translation": "图像字幕涉及从输入图像生成文本描述，弥合了计算机视觉和自然语言处理之间的鸿沟。基于Transformer模型的最新进展通过利用注意力机制更好地理解场景，显著改善了字幕生成。尽管各种调查已经探讨了基于深度学习的图像字幕方法，但很少有研究全面分析跨多种语言的基于注意力的Transformer模型。本调查回顾了基于注意力的图像字幕模型，将其分为基于Transformer、基于深度学习和混合方法。它探讨了基准数据集，讨论了BLEU、METEOR、CIDEr和ROUGE等评估指标，并强调了多语言字幕中的挑战。此外，本文还指出了当前模型的主要局限性，包括语义不一致性、非英语语言数据稀缺以及推理能力限制。最后，我们概述了未来的研究方向，例如多模态学习、AI助手、医疗保健和法医分析中的实时应用。本调查为旨在推进基于注意力的图像字幕领域的研究人员提供了全面的参考。", "summary": "本调查全面回顾了跨语言图像字幕的基于注意力的Transformer模型。它对现有模型进行了分类，探讨了基准数据集和评估指标，并深入分析了多语言字幕的挑战，包括语义不一致性、数据稀缺和推理能力限制。此外，论文还提出了未来的研究方向，为该领域的研究人员提供了宝贵的参考。", "keywords": "图像字幕, Transformer模型, 注意力机制, 多语言, 调查", "comments": "该调查的重要性在于其对跨语言、基于注意力的Transformer图像字幕模型的全面分析，填补了现有文献的空白。它不仅系统地分类了模型，还深入探讨了多语言环境下的具体挑战和局限性，并为未来研究指明了方向，对于推动该领域的发展具有重要意义。"}}
{"id": "2506.05967", "title": "Preference Learning for AI Alignment: a Causal Perspective", "authors": ["Katarzyna Kobalczyk", "Mihaela van der Schaar"], "summary": "Reward modelling from preference data is a crucial step in aligning large\nlanguage models (LLMs) with human values, requiring robust generalisation to\nnovel prompt-response pairs. In this work, we propose to frame this problem in\na causal paradigm, providing the rich toolbox of causality to identify the\npersistent challenges, such as causal misidentification, preference\nheterogeneity, and confounding due to user-specific factors. Inheriting from\nthe literature of causal inference, we identify key assumptions necessary for\nreliable generalisation and contrast them with common data collection\npractices. We illustrate failure modes of naive reward models and demonstrate\nhow causally-inspired approaches can improve model robustness. Finally, we\noutline desiderata for future research and practices, advocating targeted\ninterventions to address inherent limitations of observational data.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05967v1", "AI": {"title_translation": "AI对齐中的偏好学习：一个因果视角", "tldr": "本文从因果角度探讨了基于偏好数据的奖励建模，以解决大型语言模型对齐中的泛化挑战，并提出了改进模型鲁棒性的方法及未来的研究方向。", "motivation": "奖励建模是使大型语言模型（LLMs）与人类价值观对齐的关键步骤，需要对新颖的提示-响应对进行鲁棒泛化。", "method": "本文提出将奖励建模问题置于因果范式中，利用因果工具箱识别持续存在的挑战，如因果误识别、偏好异质性和用户特定因素导致的混淆。研究从因果推断文献中继承，识别了可靠泛化所需的关键假设，并将其与常见数据收集实践进行对比。", "result": "研究说明了朴素奖励模型的失败模式，并展示了受因果启发的方***如何提高模型的鲁棒性。", "conclusion": "本文概述了未来研究和实践的期望，主张采取有针对性的干预措施来解决观测数据固有的局限性。", "translation": "基于偏好数据的奖励建模是使大型语言模型（LLMs）与人类价值观对齐的关键步骤，需要对新颖的提示-响应对进行鲁棒泛化。在这项工作中，我们提出将此问题置于因果范式中，提供丰富的因果工具箱来识别持续存在的挑战，例如因果误识别、偏好异质性以及用户特定因素导致的混淆。借鉴因果推断文献，我们识别了可靠泛化所需的关键假设，并将其与常见数据收集实践进行对比。我们说明了朴素奖励模型的失败模式，并展示了受因果启发的方***如何提高模型鲁棒性。最后，我们概述了未来研究和实践的期望，主张采取有针对性的干预措施来解决观测数据固有的局限性。", "summary": "本文将LLMs对齐中的偏好学习问题置于因果框架下，以解决奖励建模中的泛化挑战。研究利用因果推断的工具，识别了因果误识别、偏好异质性等问题，并提出了实现可靠泛化的关键假设。通过展示朴素模型的失败模式，并证明因果启发方法能提高模型鲁棒性，论文最终为未来的研究和实践指明了方向，强调通过有针对性的干预来克服观测数据的局限性。", "keywords": "偏好学习, AI对齐, 因果推断, 奖励建模, 泛化", "comments": "本文的创新之处在于将因果推断引入到AI对齐的偏好学习领域，为解决奖励模型泛化中的挑战提供了一个新的视角。通过识别因果误识别和偏好异质性等问题，并提出因果启发的方法，为提高模型鲁棒性提供了理论基础和实践指导。强调未来研究应关注有针对性的干预措施，以应对观测数据的固有局限性，具有重要的指导意义。"}}
{"id": "2506.05500", "title": "The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models", "authors": ["Alex Damian", "Jason D. Lee", "Joan Bruna"], "summary": "In this work we consider generic Gaussian Multi-index models, in which the\nlabels only depend on the (Gaussian) $d$-dimensional inputs through their\nprojection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient\nagnostic estimation procedures for this hidden subspace. We introduce the\n\\emph{generative leap} exponent $k^\\star$, a natural extension of the\ngenerative exponent from [Damian et al.'24] to the multi-index setting. We\nfirst show that a sample complexity of $n=\\Theta(d^{1 \\vee \\k/2})$ is necessary\nin the class of algorithms captured by the Low-Degree-Polynomial framework. We\nthen establish that this sample complexity is also sufficient, by giving an\nagnostic sequential estimation procedure (that is, requiring no prior knowledge\nof the multi-index model) based on a spectral U-statistic over appropriate\nHermite tensors. We further compute the generative leap exponent for several\nexamples including piecewise linear functions (deep ReLU networks with bias),\nand general deep neural networks (with $r$-dimensional first hidden layer).", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05500v1", "AI": {"title_translation": "生成式飞跃：高效学习高斯多索引模型的精确样本复杂度", "tldr": "本文研究了高斯多索引模型中隐藏子空间的高效不可知估计，引入了生成式飞跃指数，并确定了其精确的样本复杂度。", "motivation": "研究高斯多索引模型中隐藏低维子空间的有效不可知估计过程。", "method": "引入了“生成式飞跃”指数，并首先在低度多项式框架下证明了必要的样本复杂度。随后，通过基于适当Hermite张量的谱U统计量，提出了一种不可知序贯估计过程，证明了该样本复杂度的充分性。", "result": "证明了在低度多项式算法类中，样本复杂度$n=\\Theta(d^{1 \\\\vee \\\\k/2})$是必要的。通过提出的估计过程，证明了该样本复杂度也是充分的。此外，还计算了分段线性函数（带偏置的深度ReLU网络）和通用深度神经网络（具有r维第一隐藏层）等示例的生成式飞跃指数。", "conclusion": "本文成功为高斯多索引模型提供了高效且不可知的估计过程，并确定了精确的样本复杂度，为理解这类模型的学习效率提供了理论基础。", "translation": "在这项工作中，我们考虑了通用高斯多索引模型，其中标签仅通过其在低维$r = O_d(1)$子空间上的投影依赖于（高斯）$d$维输入，并且我们研究了该隐藏子空间的高效不可知估计过程。我们引入了“生成式飞跃”指数$k^\\star$，它是[Damian et al.\\'24]中生成式指数向多索引设置的自然扩展。我们首先表明，在低度多项式框架所捕获的算法类别中，样本复杂度$n=\\\\Theta(d^{1 \\\\vee \\\\k/2})$是必要的。然后，我们通过提供一个基于适当Hermite张量上的谱U统计量的不可知序贯估计过程（即不需要多索引模型的先验知识），证明了该样本复杂度也是充分的。我们进一步计算了包括分段线性函数（带偏置的深度ReLU网络）和通用深度神经网络（具有r维第一隐藏层）在内的几个示例的生成式飞跃指数。", "summary": "本研究探讨了高斯多索引模型中隐藏低维子空间的高效不可知估计问题。论文引入了“生成式飞跃”指数，并证明了在低度多项式框架下，样本复杂度$n=\\Theta(d^{1 \\vee \\k/2})$是必要的。通过提出一种基于谱U统计量的不可知序贯估计方法，进一步证明了该样本复杂度的充分性。研究还计算了多种模型（包括深度ReLU网络和通用深度神经网络）的生成式飞跃指数，为理解这类模型的学习效率提供了理论基础。", "keywords": "高斯多索引模型, 样本复杂度, 生成式飞跃, 不可知估计, 谱U统计量", "comments": "这项工作为高斯多索引模型的学习效率提供了重要的理论贡献，特别是在样本复杂度方面给出了精确的界限。引入“生成式飞跃”指数并将其与深度学习模型联系起来，具有创新性。提出的基于谱U统计量的不可知序贯估计过程为实际应用提供了指导，且无需先验知识，增加了其普适性。"}}
{"id": "2506.06199", "title": "3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model", "authors": ["Hongyan Zhi", "Peihao Chen", "Siyuan Zhou", "Yubo Dong", "Quanxi Wu", "Lei Han", "Mingkui Tan"], "summary": "Manipulation has long been a challenging task for robots, while humans can\neffortlessly perform complex interactions with objects, such as hanging a cup\non the mug rack. A key reason is the lack of a large and uniform dataset for\nteaching robots manipulation skills. Current robot datasets often record robot\naction in different action spaces within a simple scene. This hinders the robot\nto learn a unified and robust action representation for different robots within\ndiverse scenes. Observing how humans understand a manipulation task, we find\nthat understanding how the objects should move in the 3D space is a critical\nclue for guiding actions. This clue is embodiment-agnostic and suitable for\nboth humans and different robots. Motivated by this, we aim to learn a 3D flow\nworld model from both human and robot manipulation data. This model predicts\nthe future movement of the interacting objects in 3D space, guiding action\nplanning for manipulation. Specifically, we synthesize a large-scale 3D optical\nflow dataset, named ManiFlow-110k, through a moving object auto-detect\npipeline. A video diffusion-based world model then learns manipulation physics\nfrom these data, generating 3D optical flow trajectories conditioned on\nlanguage instructions. With the generated 3D object optical flow, we propose a\nflow-guided rendering mechanism, which renders the predicted final state and\nleverages GPT-4o to assess whether the predicted flow aligns with the task\ndescription. This equips the robot with a closed-loop planning ability.\nFinally, we consider the predicted 3D optical flow as constraints for an\noptimization policy to determine a chunk of robot actions for manipulation.\nExtensive experiments demonstrate strong generalization across diverse robotic\nmanipulation tasks and reliable cross-embodiment adaptation without\nhardware-specific training.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06199v1", "AI": {"title_translation": "3DFlowAction: 从3D流世界模型中学习跨肢体操作", "tldr": "该研究提出3DFlowAction，一个学习3D流世界模型的方法，以解决机器人操作中缺乏统一数据集的问题，并通过3D光流指导动作规划，实现跨肢体和多样化场景的泛化能力。", "motivation": "机器人操作长期以来都是一项具有挑战性的任务，主要原因在于缺乏大型且统一的数据集来教授机器人操作技能。当前的机器人数据集通常记录不同动作空间中的机器人动作，这阻碍了机器人学习统一且鲁棒的动作表示。人类理解操作任务的关键在于理解物体应如何在3D空间中移动，这种线索与肢体无关，适用于人类和不同机器人。", "method": "本文旨在从人类和机器人操作数据中学习一个3D流世界模型。该模型预测交互物体在3D空间中的未来运动，以指导操作的动作规划。具体方法包括：1) 通过移动物体自动检测管道合成大规模3D光流数据集ManiFlow-110k。2) 一个基于视频扩散的世界模型从这些数据中学习操作物理，根据语言指令生成3D光流轨迹。3) 提出一种流引导渲染机制，渲染预测的最终状态并利用GPT-4o评估预测流是否与任务描述对齐，从而赋予机器人闭环规划能力。4) 将预测的3D光流作为优化策略的约束，以确定机器人操作的一系列动作。", "result": "广泛的实验表明，该方法在各种机器人操作任务中表现出强大的泛化能力，并且无需特定硬件训练即可实现可靠的跨肢体适应。", "conclusion": "通过学习3D流世界模型并利用其指导动作规划，该方法有效解决了机器人操作中统一动作表示和跨肢体泛化的问题，实现了在多样化场景和不同机器人上的鲁棒操作能力。", "translation": "操作长期以来一直是机器人的一个具有挑战性的任务，而人类可以毫不费力地与物体进行复杂的互动，例如将杯子挂在杯架上。一个关键原因是缺乏大型且统一的数据集来教授机器人操作技能。当前的机器人数据集通常在简单的场景中记录不同动作空间中的机器人动作。这阻碍了机器人学习统一且鲁棒的动作表示，以适应不同机器人和多样化的场景。观察人类如何理解操作任务，我们发现理解物体应如何在3D空间中移动是指导动作的关键线索。这种线索与肢体无关，适用于人类和不同的机器人。受此启发，我们旨在从人类和机器人操作数据中学习一个3D流世界模型。该模型预测交互物体在3D空间中的未来运动，指导操作的动作规划。具体来说，我们通过一个移动物体自动检测管道合成了一个大规模的3D光流数据集，命名为ManiFlow-110k。然后，一个基于视频扩散的世界模型从这些数据中学习操作物理，生成以语言指令为条件的3D光流轨迹。利用生成的3D物体光流，我们提出了一种流引导渲染机制，该机制渲染预测的最终状态并利用GPT-4o评估预测流是否与任务描述对齐。这赋予了机器人闭环规划能力。最后，我们将预测的3D光流作为优化策略的约束，以确定机器人操作的一系列动作。广泛的实验证明了在多样化的机器人操作任务中强大的泛化能力，以及无需硬件特定训练的可靠跨肢体适应性。", "summary": "本文提出3DFlowAction，旨在解决机器人操作中缺乏统一数据集的问题。受人类理解3D物体运动的启发，该研究学习了一个3D流世界模型，能够预测物体在3D空间中的未来运动，从而指导机器人动作规划。通过构建大规模ManiFlow-110k数据集和基于视频扩散的世界模型，结合流引导渲染机制和GPT-4o评估，赋予机器人闭环规划能力。实验证明了该方法在多样化机器人任务中的强大泛化能力和跨肢体适应性。", "keywords": "3D流世界模型, 机器人操作, 跨肢体泛化, 3D光流, 动作规划", "comments": "该论文的创新点在于提出了一个3D流世界模型，将3D光流作为一种与肢体无关的统一表示，有效地解决了机器人操作中跨肢体和多样化场景泛化能力的挑战。通过结合大规模数据集合成、视频扩散模型和外部语言模型（GPT-4o）进行闭环评估，构建了一个新颖且强大的操作规划框架。其重要性在于为机器人学习复杂操作技能提供了一条新路径，尤其是在数据稀疏和泛化能力要求高的场景下。"}}
{"id": "2506.05404", "title": "AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving", "authors": ["Lianming Huang", "Haibo Hu", "Yufei Cui", "Jiacheng Zuo", "Shangyu Wu", "Nan Guan", "Chun Jason Xue"], "summary": "With the rapid advancement of autonomous driving, deploying Vision-Language\nModels (VLMs) to enhance perception and decision-making has become increasingly\ncommon. However, the real-time application of VLMs is hindered by high latency\nand computational overhead, limiting their effectiveness in time-critical\ndriving scenarios. This challenge is particularly evident when VLMs exhibit\nover-inference, continuing to process unnecessary layers even after confident\npredictions have been reached. To address this inefficiency, we propose AD-EE,\nan Early Exit framework that incorporates domain characteristics of autonomous\ndriving and leverages causal inference to identify optimal exit layers. We\nevaluate our method on large-scale real-world autonomous driving datasets,\nincluding Waymo and the corner-case-focused CODA, as well as on a real vehicle\nrunning the Autoware Universe platform. Extensive experiments across multiple\nVLMs show that our method significantly reduces latency, with maximum\nimprovements reaching up to 57.58%, and enhances object detection accuracy,\nwith maximum gains of up to 44%.", "comment": "8 pages", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05404v1", "AI": {"title_translation": "AD-EE：自动驾驶中快速可靠的视觉语言模型的提前退出机制", "tldr": "AD-EE提出了一种提前退出框架，通过结合自动驾驶领域特性和因果推理，显著降低了视觉语言模型在自动驾驶场景中的延迟并提高了目标检测精度。", "motivation": "视觉语言模型（VLMs）在自动驾驶中的应用面临高延迟和计算开销的挑战，尤其是在模型达到高置信度预测后仍进行不必要的过推理，这限制了它们在时间敏感型驾驶场景中的有效性。", "method": "本文提出了AD-EE，一个结合自动驾驶领域特性并利用因果推理来识别最佳退出层的提前退出（Early Exit）框架。该方法在大型真实世界自动驾驶数据集（包括Waymo和CODA）以及在运行Autoware Universe平台的真实车辆上进行了评估。", "result": "AD-EE显著降低了延迟，最大改进达到57.58%；同时提高了目标检测精度，最大提升达到44%。", "conclusion": "AD-EE框架通过优化视觉语言模型在自动驾驶中的推理过程，有效解决了高延迟问题并提升了性能，使其更适用于时间敏感型自动驾驶应用。", "translation": "随着自动驾驶的快速发展，部署视觉语言模型（VLMs）以增强感知和决策变得越来越普遍。然而，VLMs的实时应用受到高延迟和计算开销的阻碍，这限制了它们在时间关键型驾驶场景中的有效性。当VLMs出现过度推理（即在达到高置信度预测后仍继续处理不必要的层）时，这一挑战尤为明显。为了解决这种低效率问题，我们提出了AD-EE，一个提前退出框架，它结合了自动驾驶的领域特性并利用因果推理来识别最佳退出层。我们在大规模真实世界自动驾驶数据集（包括Waymo和以极端情况为重点的CODA）以及在运行Autoware Universe平台的真实车辆上评估了我们的方法。对多个VLMs进行的广泛实验表明，我们的方法显著降低了延迟，最大改进达到57.58%，并提高了目标检测精度，最大增益达到44%。", "summary": "本论文提出了AD-EE，一个针对自动驾驶中视觉语言模型（VLMs）的提前退出框架，旨在解决高延迟和计算开销问题。通过整合自动驾驶领域特性和因果推理来确定最佳退出层，AD-EE在Waymo和CODA等真实世界数据集以及真实车辆上进行了广泛评估。实验结果表明，该方法显著降低了VLMs的推理延迟（最高达57.58%），并提升了目标检测精度（最高达44%）。", "keywords": "自动驾驶, 视觉语言模型, 提前退出, 延迟优化, 目标检测", "comments": "该论文通过引入领域特定知识和因果推理来优化VLMs的提前退出机制，为自动驾驶中的实时部署提供了有效解决方案，具有重要的实际应用价值。其创新点在于将提前退出与自动驾驶的特性深度结合，并利用因果推理进行退出层选择，这可能为其他时间敏感型AI应用提供借鉴。"}}
{"id": "2506.05981", "title": "CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents", "authors": ["Qingbin Zeng", "Ruotong Zhao", "Jinzhu Mao", "Haoyang Li", "Fengli Xu", "Yong Li"], "summary": "Modeling urban crime is an important yet challenging task that requires\nunderstanding the subtle visual, social, and cultural cues embedded in urban\nenvironments. Previous work has predominantly focused on rule-based agent-based\nmodeling (ABM) and deep learning methods. ABMs offer interpretability of\ninternal mechanisms but exhibit limited predictive accuracy.In contrast, deep\nlearning methods are often effective in prediction but are less interpretable\nand require extensive training data. Moreover, both lines of work lack the\ncognitive flexibility to adapt to changing environments. Leveraging the\ncapabilities of large language models (LLMs), we propose CrimeMind, a novel\nLLM-driven ABM framework for simulating urban crime within a multi-modal urban\ncontext.A key innovation of our design is the integration of the Routine\nActivity Theory (RAT) into the agentic workflow of CrimeMind, enabling it to\nprocess rich multi-modal urban features and reason about criminal\nbehavior.However, RAT requires LLM agents to infer subtle cues in evaluating\nenvironmental safety as part of assessing guardianship, which can be\nchallenging for LLMs. To address this, we collect a small-scale human-annotated\ndataset and align CrimeMind's perception with human judgment via a\ntraining-free textual gradient method.Experiments across four major U.S. cities\ndemonstrate that CrimeMind outperforms both traditional ABMs and deep learning\nbaselines in crime hotspot prediction and spatial distribution accuracy,\nachieving up to a 24% improvement over the strongest baseline.Furthermore, we\nconduct counterfactual simulations of external incidents and policy\ninterventions and it successfully captures the expected changes in crime\npatterns, demonstrating its ability to reflect counterfactual\nscenarios.Overall, CrimeMind enables fine-grained modeling of individual\nbehaviors and facilitates evaluation of real-world interventions.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.05981v1", "AI": {"title_translation": "CrimeMind: 模拟多模态LLM智能体的城市犯罪", "tldr": "CrimeMind是一个基于LLM的多模态智能体模型，用于模拟城市犯罪，它在犯罪热点预测和空间分布准确性上优于现有方法，并能模拟反事实场景。", "motivation": "城市犯罪建模是一项重要但具有挑战性的任务，需要理解城市环境中微妙的视觉、社会和文化线索。现有方法（基于规则的ABM和深度学习）存在局限性：ABM可解释性强但预测准确性有限；深度学习预测有效但可解释性差且需要大量训练数据，并且两者都缺乏适应环境变化的认知灵活性。", "method": "本文提出了CrimeMind，一个新颖的由LLM驱动的ABM框架，用于在多模态城市背景下模拟城市犯罪。其关键创新是将日常活动理论（RAT）整合到CrimeMind的智能体工作流程中，使其能够处理丰富的多模态城市特征并推断犯罪行为。为解决RAT中LLM智能体评估环境安全（监护）的挑战，研究者收集了一个小型人工标注数据集，并通过无训练的文本梯度方法使CrimeMind的感知与人类判断对齐。", "result": "在美国四个主要城市的实验表明，CrimeMind在犯罪热点预测和空间分布准确性方面优于传统ABM和深度学习基线，比最强的基线提高了24%。此外，对外部事件和政策干预的反事实模拟成功捕捉了犯罪模式的预期变化，证明了其反映反事实场景的能力。", "conclusion": "CrimeMind能够对个体行为进行细粒度建模，并促进对现实世界干预措施的评估。", "translation": "建模城市犯罪是一项重要但具有挑战性的任务，它需要理解城市环境中微妙的视觉、社会和文化线索。之前的工作主要集中在基于规则的智能体建模（ABM）和深度学习方法。ABM提供了内部机制的可解释性，但预测准确性有限。相比之下，深度学习方法在预测方面通常有效，但可解释性较差，并且需要大量的训练数据。此外，这两种方法都缺乏适应不断变化环境的认知灵活性。利用大型语言模型（LLMs）的能力，我们提出了CrimeMind，一个新颖的由LLM驱动的ABM框架，用于在多模态城市背景下模拟城市犯罪。我们设计的关键创新是将日常活动理论（RAT）整合到CrimeMind的智能体工作流程中，使其能够处理丰富的多模态城市特征并推断犯罪行为。然而，RAT要求LLM智能体在评估监护（guardianship）时推断评估环境安全中的微妙线索，这对于LLM来说可能具有挑战性。为了解决这个问题，我们收集了一个小规模的人工标注数据集，并通过无训练的文本梯度方法使CrimeMind的感知与人类判断对齐。在美国四个主要城市的实验表明，CrimeMind在犯罪热点预测和空间分布准确性方面优于传统ABM和深度学习基线，实现了比最强基线高达24%的改进。此外，我们对外部事件和政策干预进行了反事实模拟，它成功捕捉了犯罪模式的预期变化，证明了其反映反事实场景的能力。总的来说，CrimeMind能够对个体行为进行细粒度建模，并促进对现实世界干预措施的评估。", "summary": "本文提出了CrimeMind，一个基于大型语言模型（LLM）的多模态智能体建模（ABM）框架，用于模拟城市犯罪。该模型将日常活动理论（RAT）整合到LLM智能体的工作流程中，使其能够处理多模态城市特征并推断犯罪行为。为了解决LLM在评估环境安全方面的挑战，研究人员构建了一个小型人工标注数据集，并采用无训练的文本梯度方法对齐模型的感知与人类判断。实验结果显示，CrimeMind在犯罪热点预测和空间分布准确性方面优于现有方法，并能成功模拟外部事件和政策干预的反事实场景，为个体行为建模和现实世界干预评估提供了新的工具。", "keywords": "城市犯罪模拟, 多模态LLM智能体, 日常活动理论, 智能体建模, 犯罪热点预测", "comments": "CrimeMind的创新在于将LLM的认知灵活性与ABM的可解释性相结合，并通过整合日常活动理论和处理多模态数据来提升城市犯罪模拟的准确性和适应性。其在反事实模拟方面的能力尤其重要，为城市规划和政策制定提供了有价值的洞察。通过无训练的文本梯度方法对齐模型感知与人类判断，也展示了在数据标注有限情况下的有效策略。"}}
{"id": "2506.06125", "title": "Convergence of linear programming hierarchies for Gibbs states of spin systems", "authors": ["Hamza Fawzi", "Omar Fawzi"], "summary": "We consider the problem of computing expectation values of local functions\nunder the Gibbs distribution of a spin system. In particular, we study two\nfamilies of linear programming hierarchies for this problem. The first\nhierarchy imposes local spin flip equalities and has been considered in the\nbootstrap literature in high energy physics. For this hierarchy, we prove fast\nconvergence under a spatial mixing (decay of correlations) condition. This\ncondition is satisfied for example above the critical temperature for Ising\nmodels on a $d$-dimensional grid. The second hierarchy is based on a Markov\nchain having the Gibbs state as a fixed point and has been studied in the\noptimization literature and more recently in the bootstrap literature. For this\nhierarchy, we prove fast convergence provided the Markov chain mixes rapidly.\nBoth hierarchies lead to an $\\varepsilon$-approximation for local expectation\nvalues using a linear program of size quasi-polynomial in $n/\\varepsilon$,\nwhere $n$ is the total number of sites, provided the interactions can be\nembedded in a $d$-dimensional grid with constant $d$. Compared to standard\nMonte Carlo methods, an advantage of this approach is that it always (i.e., for\nany system) outputs rigorous upper and lower bounds on the expectation value of\ninterest, without needing an a priori analysis of the convergence speed.", "comment": "11 pages", "cate": "math.OC", "url": "http://arxiv.org/pdf/2506.06125v1", "AI": {"title_translation": "自旋系统Gibbs态线性规划层次的收敛性", "tldr": "本文研究了两种计算自旋系统Gibbs态局部函数期望值的线性规划层次结构，并证明了它们在特定条件下（空间混合或马尔可夫链快速混合）的快速收敛性，提供了严格的上下界估计。", "motivation": "计算自旋系统Gibbs分布下局部函数的期望值。", "method": "本文研究了两种线性规划层次结构：第一种施加局部自旋翻转等式，在空间混合条件下快速收敛；第二种基于以Gibbs态为不动点的马尔可夫链，在马尔可夫链快速混合条件下快速收敛。两种方法都通过拟多项式大小的线性规划实现对局部期望值的ε-近似。", "result": "第一种层次结构在空间混合条件下（例如d维网格上Ising模型临界温度以上）快速收敛。第二种层次结构在马尔可夫链快速混合条件下快速收敛。两种层次结构都能通过大小为n/ε的拟多项式线性规划对局部期望值实现ε-近似（如果相互作用可嵌入d维网格）。与标准蒙特卡洛方法相比，该方法总是能输出期望值的严格上下界，无需预先分析收敛速度。", "conclusion": "两种线性规划层次结构为计算自旋系统Gibbs态的局部期望值提供了有效且具有严格界限的方法，克服了传统蒙特卡洛方法的一些局限性，尤其是在提供严格上下界方面具有优势。", "translation": "我们考虑计算自旋系统Gibbs分布下局部函数期望值的问题。具体来说，我们研究了解决此问题的两种线性规划层次结构家族。第一个层次结构施加局部自旋翻转等式，并在高能物理的自举文献中有所考虑。对于这个层次结构，我们在空间混合（相关性衰减）条件下证明了快速收敛。例如，在d维网格上Ising模型的临界温度以上满足此条件。第二个层次结构基于以Gibbs态为不动点的马尔可夫链，并在优化文献以及最近的自举文献中有所研究。对于这个层次结构，我们证明了只要马尔可夫链快速混合，就能实现快速收敛。两种层次结构都能通过大小为n/ε的拟多项式线性规划对局部期望值实现ε-近似，其中n是总站点数，前提是相互作用可以嵌入常数d的d维网格中。与标准蒙特卡洛方法相比，这种方法的优点是它总是（即，对于任何系统）输出感兴趣的期望值的严格上限和下限，而无需事先分析收敛速度。", "summary": "本文研究了两种计算自旋系统Gibbs分布下局部函数期望值的线性规划层次结构。第一种层次结构基于局部自旋翻转等式，在空间混合条件下能快速收敛；第二种层次结构基于马尔可夫链，在马尔可夫链快速混合条件下能快速收敛。这两种方法都能通过拟多项式大小的线性规划提供局部期望值的ε-近似，并且与蒙特卡洛方法相比，其优势在于能够提供严格的上下界。", "keywords": "线性规划层次, Gibbs态, 自旋系统, 期望值, 快速收敛", "comments": "这篇论文的创新点在于提出了两种线性规划层次结构来精确估计自旋系统Gibbs态的局部期望值，并证明了它们在特定条件下的快速收敛性。其重要性体现在为统计物理和优化问题提供了一种替代传统蒙特卡洛方法的严格解析工具，尤其是在能够提供期望值的严格上下界方面具有显著优势，这对于需要高精度和可验证结果的场景非常有用。"}}
{"id": "2506.05513", "title": "Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates", "authors": ["Yunfei Huang", "David S. Greenberg"], "summary": "Neural PDE surrogates can improve the cost-accuracy tradeoff of classical\nsolvers, but often generalize poorly to new initial conditions and accumulate\nerrors over time. Physical and symmetry constraints have shown promise in\nclosing this performance gap, but existing techniques for imposing these\ninductive biases are incompatible with the staggered grids commonly used in\ncomputational fluid dynamics. Here we introduce novel input and output layers\nthat respect physical laws and symmetries on the staggered grids, and for the\nfirst time systematically investigate how these constraints, individually and\nin combination, affect the accuracy of PDE surrogates. We focus on two\nchallenging problems: shallow water equations with closed boundaries and\ndecaying incompressible turbulence. Compared to strong baselines, symmetries\nand physical constraints consistently improve performance across tasks,\narchitectures, autoregressive prediction steps, accuracy measures, and network\nsizes. Symmetries are more effective than physical constraints, but surrogates\nwith both performed best, even compared to baselines with data augmentation or\npushforward training, while themselves benefiting from the pushforward trick.\nDoubly-constrained surrogates also generalize better to initial conditions and\ndurations beyond the range of the training data, and more accurately predict\nreal-world ocean currents.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05513v1", "AI": {"title_translation": "几何和物理约束协同增强神经偏微分方程代理模型", "tldr": "本文引入了新的输入和输出层，使神经偏微分方程代理模型在交错网格上能遵守物理定律和对称性，显著提高了模型的准确性和泛化能力，尤其是在同时应用两种约束时。", "motivation": "神经偏微分方程代理模型在泛化到新的初始条件时表现不佳，并且会随时间积累误差。现有的物理和对称性约束方法与计算流体动力学中常用的交错网格不兼容，导致性能差距。", "method": "本文引入了在交错网格上遵守物理定律和对称性的新型输入和输出层。研究系统地探究了这些约束（单独和组合）如何影响偏微分方程代理模型的准确性，并通过浅水方程和衰减不可压缩湍流两个具有挑战性的问题进行了验证。", "result": "与强基线模型相比，对称性和物理约束持续提升了模型在不同任务、架构、自回归预测步长、精度度量和网络规模上的性能。对称性比物理约束更有效，但同时应用两种约束的模型表现最佳，甚至优于采用数据增强或前推训练的基线模型，并且双重约束模型本身也受益于前推技巧。双重约束代理模型对训练数据范围之外的初始条件和持续时间也具有更好的泛化能力，并能更准确地预测真实世界的洋流。", "conclusion": "几何和物理约束能够协同增强神经偏微分方程代理模型的性能，尤其是在交错网格上。结合使用两种约束的模型在准确性、泛化能力和对真实世界现象的预测方面表现出显著优势。", "translation": "神经偏微分方程代理模型可以改善经典求解器的成本-精度权衡，但通常对新的初始条件泛化能力差，并随时间累积误差。物理和对称性约束已显示出弥补这种性能差距的潜力，但现有施加这些归纳偏置的技术与计算流体动力学中常用的交错网格不兼容。本文引入了尊重交错网格上物理定律和对称性的新型输入和输出层，并首次系统地研究了这些约束（单独和组合）如何影响偏微分方程代理模型的准确性。我们专注于两个具有挑战性的问题：封闭边界的浅水方程和衰减的不可压缩湍流。与强大的基线模型相比，对称性和物理约束在不同任务、架构、自回归预测步长、精度度量和网络规模上持续改善了性能。对称性比物理约束更有效，但同时应用两种约束的代理模型表现最佳，甚至与采用数据增强或前推训练的基线模型相比也更优，同时它们自身也受益于前推技巧。双重约束的代理模型对超出训练数据范围的初始条件和持续时间也具有更好的泛化能力，并能更准确地预测真实世界的洋流。", "summary": "本研究解决了神经偏微分方程代理模型在泛化性和误差积累方面的不足，特别是在交错网格上的应用挑战。文章提出并验证了新型的输入和输出层，这些层在交错网格上能有效整合几何和物理约束。实验结果表明，这些约束（尤其是两者结合时）显著提升了模型的准确性、泛化能力，并能更准确地预测真实世界的复杂流体现象，超越了现有强基线模型。", "keywords": "神经偏微分方程代理, 几何约束, 物理约束, 交错网格, 泛化能力", "comments": "本文的创新点在于首次将物理和对称性约束有效地应用于计算流体动力学中常用的交错网格，并通过新颖的输入输出层实现了这一点。其重要性在于显著提升了神经偏微分方程代理模型的泛化能力和准确性，尤其是在处理复杂物理系统时。研究结果表明，结合几何和物理约束是提高此类模型性能的关键，这为未来的物理信息神经网络研究提供了新的方向。"}}
{"id": "2506.05611", "title": "Breaking Anonymity at Scale: Re-identifying the Trajectories of 100K Real Users in Japan", "authors": ["Abhishek Kumar Mishra", "Mathieu Cunche", "Heber H. Arcolezi"], "summary": "Mobility traces represent a critical class of personal data, often subjected\nto privacy-preserving transformations before public release. In this study, we\nanalyze the anonymized Yjmob100k dataset, which captures the trajectories of\n100,000 users in Japan, and demonstrate how existing anonymization techniques\nfail to protect their sensitive attributes. We leverage population density\npatterns, structural correlations, and temporal activity profiles to\nre-identify the dataset's real-world location and timing. Our results reveal\nthat the anonymization process carried out for Yjmob100k is inefficient and\npreserves enough spatial and temporal structure to enable re-identification.\nThis work underscores the limitations of current trajectory anonymization\nmethods and calls for more robust privacy mechanisms in the publication of\nmobility data.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05611v1", "AI": {"title_translation": "大规模打破匿名性：重新识别日本10万真实用户的轨迹", "tldr": "研究发现，日本Yjmob100k数据集中10万用户的匿名化移动轨迹可以被重新识别，现有匿名化技术不足以保护敏感属性。", "motivation": "移动轨迹是关键的个人数据，通常在公开发布前进行隐私保护转换。本研究的动机是分析匿名化后的Yjmob100k数据集，并证明现有匿名化技术未能保护用户的敏感属性。", "method": "研究利用人口密度模式、结构相关性和时间活动概况来重新识别数据集的真实世界位置和时间。", "result": "结果显示，Yjmob100k的匿名化过程效率低下，保留了足够的空间和时间结构，从而能够实现重新识别。", "conclusion": "本研究强调了当前轨迹匿名化方法的局限性，并呼吁在发布移动数据时采用更强大的隐私保护机制。", "translation": "移动轨迹代表着一类关键的个人数据，在公开发布前通常会经过隐私保护转换。在本研究中，我们分析了匿名化的Yjmob100k数据集，该数据集捕获了日本10万用户的轨迹，并展示了现有匿名化技术如何未能保护其敏感属性。我们利用人口密度模式、结构相关性和时间活动概况来重新识别数据集的真实世界位置和时间。我们的结果显示，Yjmob100k所进行的匿名化过程效率低下，并保留了足够的空间和时间结构，从而能够实现重新识别。这项工作强调了当前轨迹匿名化方法的局限性，并呼吁在发布移动数据时采用更强大的隐私保护机制。", "summary": "本研究分析了匿名化的日本Yjmob100k数据集，该数据集包含10万用户的移动轨迹。通过利用人口密度、结构相关性和时间活动模式，研究人员成功地重新识别了用户的真实位置和时间。结果表明，现有轨迹匿名化技术存在缺陷，未能有效保护用户隐私，因此需要更强大的隐私保护机制。", "keywords": "轨迹匿名化, 隐私保护, 去匿名化, 移动数据, Yjmob100k", "comments": "这项研究揭示了大规模匿名化移动数据中存在的严重隐私漏洞，强调了在数据共享时代，仅依赖传统匿名化技术是不足够的。其方法创新性在于利用多维度信息进行去匿名化，对未来的隐私保护技术发展具有重要警示意义。"}}
{"id": "2506.06205", "title": "Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning", "authors": ["Sheng Chen", "Peiyu He", "Jiaxin Hu", "Ziyang Liu", "Yansheng Wang", "Tao Xu", "Chi Zhang", "Chongchong Zhang", "Chao An", "Shiyu Cai", "Duo Cao", "Kangping Chen", "Shuai Chu", "Tianwei Chu", "Mingdi Dan", "Min Du", "Weiwei Fang", "Pengyou Fu", "Junkai Hu", "Xiaowei Jiang", "Zhaodi Jiang", "Fuxuan Li", "Jun Li", "Minghui Li", "Mingyao Li", "Yanchang Li", "Zhibin Li", "Guangming Liu", "Kairui Liu", "Lihao Liu", "Weizhi Liu", "Xiaoshun Liu", "Yufei Liu", "Yunfei Liu", "Qiang Lu", "Yuanfei Luo", "Xiang Lv", "Hongying Ma", "Sai Ma", "Lingxian Mi", "Sha Sa", "Hongxiang Shu", "Lei Tian", "Chengzhi Wang", "Jiayu Wang", "Kaijie Wang", "Qingyi Wang", "Renwen Wang", "Tao Wang", "Wei Wang", "Xirui Wang", "Chao Wei", "Xuguang Wei", "Zijun Xia", "Zhaohao Xiao", "Tingshuai Yan", "Liyan Yang", "Yifan Yang", "Zhikai Yang", "Zhong Yin", "Li Yuan", "Liuchun Yuan", "Chi Zhang", "Jinyang Zhang", "Junhui Zhang", "Linge Zhang", "Zhenyi Zhang", "Zheyu Zhang", "Dongjie Zhu", "Hang Li", "Yangang Zhang"], "summary": "Modern robot navigation systems encounter difficulties in diverse and complex\nindoor environments. Traditional approaches rely on multiple modules with small\nmodels or rule-based systems and thus lack adaptability to new environments. To\naddress this, we developed Astra, a comprehensive dual-model architecture,\nAstra-Global and Astra-Local, for mobile robot navigation. Astra-Global, a\nmultimodal LLM, processes vision and language inputs to perform self and goal\nlocalization using a hybrid topological-semantic graph as the global map, and\noutperforms traditional visual place recognition methods. Astra-Local, a\nmultitask network, handles local path planning and odometry estimation. Its 4D\nspatial-temporal encoder, trained through self-supervised learning, generates\nrobust 4D features for downstream tasks. The planning head utilizes flow\nmatching and a novel masked ESDF loss to minimize collision risks for\ngenerating local trajectories, and the odometry head integrates multi-sensor\ninputs via a transformer encoder to predict the relative pose of the robot.\nDeployed on real in-house mobile robots, Astra achieves high end-to-end mission\nsuccess rate across diverse indoor environments.", "comment": "Astra Technical Report", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06205v1", "AI": {"title_translation": "Astra：通过分层多模态学习迈向通用移动机器人", "tldr": "Astra是一个双模型架构，通过多模态学习和分层设计，使移动机器人在复杂室内环境中实现高任务成功率。", "motivation": "现代机器人导航系统在多样化和复杂的室内环境中遇到困难，传统方法依赖于小型模型或基于规则的系统，缺乏对新环境的适应性。", "method": "Astra是一个全面的双模型架构，包括Astra-Global和Astra-Local。Astra-Global是一个多模态LLM，处理视觉和语言输入，使用混合拓扑语义图作为全局地图进行自我和目标定位。Astra-Local是一个多任务网络，处理局部路径规划和里程计估计。其4D时空编码器通过自监督学习训练，规划头部利用流匹配和新型掩码ESDF损失来最小化碰撞风险，里程计头部通过Transformer编码器整合多传感器输入以预测机器人相对姿态。", "result": "Astra在实际的内部移动机器人上部署，在多样化的室内环境中实现了高端到端任务成功率，并且Astra-Global在视觉地点识别方面优于传统方法。", "conclusion": "Astra通过其分层双模型多模态学习架构，有效解决了移动机器人在复杂室内环境中的导航难题，展现了实现通用移动机器人的潜力。", "translation": "现代机器人导航系统在多样化和复杂的室内环境中遇到困难。传统方法依赖于小型模型或基于规则的系统，因此缺乏对新环境的适应性。为了解决这个问题，我们开发了Astra，一个全面的双模型架构，Astra-Global和Astra-Local，用于移动机器人导航。Astra-Global是一个多模态大型语言模型（LLM），处理视觉和语言输入，使用混合拓扑语义图作为全局地图进行自我和目标定位，并且优于传统的视觉地点识别方法。Astra-Local是一个多任务网络，处理局部路径规划和里程计估计。其4D时空编码器通过自监督学习训练，为下游任务生成鲁棒的4D特征。规划头部利用流匹配和新型掩码ESDF损失来最小化碰撞风险，从而生成局部轨迹，里程计头部通过Transformer编码器整合多传感器输入来预测机器人的相对姿态。Astra部署在真实的内部移动机器人上，在多样化的室内环境中实现了高的端到端任务成功率。", "summary": "Astra是一个为解决移动机器人在复杂室内环境中导航困难而设计的双模型架构。它包含Astra-Global（一个多模态LLM，负责全局定位和地图构建）和Astra-Local（一个多任务网络，处理局部路径规划和里程计估计）。Astra利用分层多模态学习，并在实际机器人上实现了高任务成功率。", "keywords": "移动机器人, 导航, 多模态学习, 分层架构, Astra", "comments": "Astra的创新之处在于其双模型分层架构，特别是Astra-Global作为多模态LLM处理全局定位，以及Astra-Local中4D时空编码器和新型ESDF损失的应用。这使得机器人能够更好地适应复杂环境，是迈向通用移动机器人的重要一步。"}}
{"id": "2506.05405", "title": "A VLM-based Method for Visual Anomaly Detection in Robotic Scientific Laboratories", "authors": ["Shiwei Lin", "Chenxu Wang", "Xiaozhen Ding", "Yi Wang", "Boyuan Du", "Lei Song", "Chenggang Wang", "Huaping Liu"], "summary": "In robot scientific laboratories, visual anomaly detection is important for\nthe timely identification and resolution of potential faults or deviations. It\nhas become a key factor in ensuring the stability and safety of experimental\nprocesses. To address this challenge, this paper proposes a VLM-based visual\nreasoning approach that supports different levels of supervision through four\nprogressively informative prompt configurations. To systematically evaluate its\neffectiveness, we construct a visual benchmark tailored for process anomaly\ndetection in scientific workflows. Experiments on two representative\nvision-language models show that detection accuracy improves as more contextual\ninformation is provided, confirming the effectiveness and adaptability of the\nproposed reasoning approach for process anomaly detection in scientific\nworkflows. Furthermore, real-world validations at selected experimental steps\nconfirm that first-person visual observation can effectively identify\nprocess-level anomalies. This work provides both a data-driven foundation and\nan evaluation framework for vision anomaly detection in scientific experiment\nworkflows.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05405v1", "AI": {"title_translation": "机器人科学实验室中基于VLM的视觉异常检测方法", "tldr": "本文提出了一种基于VLM的视觉推理方法，用于机器人科学实验室中的视觉异常检测，并通过提供更多上下文信息来提高检测精度。", "motivation": "在机器人科学实验室中，视觉异常检测对于及时识别和解决潜在故障或偏差至关重要，是确保实验过程稳定性和安全性的关键因素。", "method": "本文提出了一种基于VLM的视觉推理方法，通过四种渐进信息提示配置支持不同级别的监督。为了系统地评估其有效性，论文构建了一个专门用于科学工作流程中过程异常检测的视觉基准。", "result": "在两个代表性视觉-语言模型上的实验表明，随着提供更多上下文信息，检测精度提高，证实了所提出的推理方法在科学工作流程中过程异常检测的有效性和适应性。此外，在选定实验步骤的实际验证证实了第一人称视觉观察可以有效识别过程级异常。", "conclusion": "这项工作为科学实验工作流程中的视觉异常检测提供了数据驱动的基础和评估框架。", "translation": "在机器人科学实验室中，视觉异常检测对于及时识别和解决潜在故障或偏差至关重要。它已成为确保实验过程稳定性和安全性的关键因素。为了应对这一挑战，本文提出了一种基于VLM的视觉推理方法，通过四种渐进信息提示配置支持不同级别的监督。为了系统地评估其有效性，我们构建了一个专门用于科学工作流程中过程异常检测的视觉基准。对两个代表性视觉-语言模型的实验表明，随着提供更多上下文信息，检测精度提高，证实了所提出的推理方法在科学工作流程中过程异常检测的有效性和适应性。此外，在选定实验步骤的实际验证证实了第一人称视觉观察可以有效识别过程级异常。这项工作为科学实验工作流程中的视觉异常检测提供了数据驱动的基础和评估框架。", "summary": "本文提出了一种基于VLM的视觉推理方法，用于机器人科学实验室中的视觉异常检测，旨在及时识别和解决潜在故障或偏差，确保实验过程的稳定性和安全性。该方法通过四种渐进信息提示配置支持不同级别的监督，并构建了一个视觉基准进行系统评估。实验结果表明，提供更多上下文信息可以提高检测精度，且第一人称视觉观察能有效识别过程级异常。这项工作为科学实验工作流程中的视觉异常检测提供了数据驱动的基础和评估框架。", "keywords": "视觉异常检测, 机器人科学实验室, VLM, 视觉推理, 科学工作流程", "comments": "这项工作创新性地将VLM应用于机器人科学实验室的视觉异常检测，通过多级提示配置提高了方法的灵活性和性能。构建专门的视觉基准和实际验证增强了研究的实用性和说服力。它为确保自动化实验的稳定性和安全性提供了重要支持。"}}
{"id": "2506.06052", "title": "CP-Bench: Evaluating Large Language Models for Constraint Modelling", "authors": ["Kostis Michailidis", "Dimos Tsouros", "Tias Guns"], "summary": "Combinatorial problems are present in a wide range of industries. Constraint\nProgramming (CP) is a well-suited problem-solving paradigm, but its core\nprocess, namely constraint modelling, is a bottleneck for wider adoption.\nAiming to alleviate this bottleneck, recent studies have explored using Large\nLanguage Models (LLMs) as modelling assistants, transforming combinatorial\nproblem descriptions to executable constraint models, similar to coding\nassistants. However, the existing evaluation datasets for constraint modelling\nare often limited to small, homogeneous, or domain-specific instances, which do\nnot capture the diversity of real-world scenarios. This work addresses this gap\nby introducing CP-Bench, a novel benchmark dataset that includes a diverse set\nof well-known combinatorial problem classes sourced from the CP community,\nstructured explicitly for evaluating LLM-driven CP modelling. With this\ndataset, and given the variety of constraint modelling frameworks, we compare\nand evaluate the modelling capabilities of LLMs for three distinct constraint\nmodelling systems, which vary in abstraction level and underlying syntax: the\nhigh-level MiniZinc language and Python-based CPMpy library, and the\nlower-level Python interface of the OR-Tools CP-SAT solver. In order to enhance\nthe ability of LLMs to produce valid constraint models, we systematically\nevaluate the use of prompt-based and inference-time compute methods adapted\nfrom existing LLM-based code generation research. Our results underscore the\nmodelling convenience provided by Python-based frameworks, as well as the\neffectiveness of documentation-rich system prompts, which, augmented with\nrepeated sampling and self-verification, achieve further improvements, reaching\nup to 70\\% accuracy on this new, highly challenging benchmark.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.06052v1", "AI": {"title_translation": "CP-Bench：评估大型语言模型在约束建模方面的能力", "tldr": "CP-Bench引入了一个多样化的基准数据集，用于评估大型语言模型（LLMs）在约束编程（CP）建模方面的能力，并发现文档丰富的系统提示结合重复采样和自我验证能显著提高LLMs的建模准确性，尤其是在Python框架中。", "motivation": "约束编程（CP）的核心过程——约束建模——是其广泛应用的一个瓶颈。现有用于约束建模的评估数据集通常有限，无法捕捉现实世界场景的多样性。本文旨在通过引入一个多样化的基准数据集来解决这一差距，以更好地评估LLMs作为建模助手的潜力。", "method": "本文引入了一个名为CP-Bench的新型基准数据集，该数据集包含来自CP社区的各种知名组合问题类别，专门用于评估LLM驱动的CP建模。利用此数据集，作者比较并评估了LLMs在三种不同约束建模系统（MiniZinc、CPMpy和OR-Tools CP-SAT的Python接口）上的建模能力。为了提高LLMs生成有效约束模型的能力，系统地评估了基于提示和推理时计算方法的使用。", "result": "研究结果强调了基于Python的框架在建模方面的便利性。文档丰富的系统提示被证明是有效的，结合重复采样和自我验证，可以进一步提高LLMs的建模准确性，在新挑战性基准上最高可达到70%的准确率。", "conclusion": "CP-Bench基准数据集能够有效评估大型语言模型在约束建模方面的能力，并证实了特定提示策略和推理时方法能显著提升LLMs在生成有效约束模型方面的表现，尤其是在Python框架中。", "translation": "组合问题广泛存在于各种行业中。约束编程（CP）是一种非常适合解决问题的范式，但其核心过程，即约束建模，是其更广泛应用的瓶颈。为了缓解这一瓶颈，最近的研究探索了使用大型语言模型（LLMs）作为建模助手，将组合问题描述转化为可执行的约束模型，类似于代码助手。然而，现有的约束建模评估数据集通常局限于小型、同质或领域特定的实例，无法捕捉现实世界场景的多样性。这项工作通过引入CP-Bench解决了这一差距，CP-Bench是一个新颖的基准数据集，它包含了来自CP社区的各种知名组合问题类别，明确地构建用于评估LLM驱动的CP建模。通过这个数据集，并考虑到约束建模框架的多样性，我们比较和评估了LLMs在三种不同的约束建模系统上的建模能力，这些系统在抽象级别和底层语法上有所不同：高级的MiniZinc语言和基于Python的CPMpy库，以及OR-Tools CP-SAT求解器的低级Python接口。为了增强LLMs生成有效约束模型的能力，我们系统地评估了从现有基于LLM的代码生成研究中改编的基于提示和推理时计算方法的使用。我们的结果强调了基于Python的框架提供的建模便利性，以及文档丰富的系统提示的有效性，这些提示通过重复采样和自我验证的增强，实现了进一步的改进，在这个新的、极具挑战性的基准上达到了高达70%的准确率。", "summary": "本文介绍了CP-Bench，这是一个旨在评估大型语言模型（LLMs）在约束建模方面能力的新型基准数据集。鉴于约束建模是约束编程（CP）广泛应用的瓶颈，且现有评估数据集存在局限性，CP-Bench提供了多样化的组合问题实例。研究使用该数据集，比较了LLMs在MiniZinc、CPMpy和OR-Tools CP-SAT三种不同约束建模系统上的表现。通过评估基于提示和推理时的方法，研究发现基于Python的框架更便于建模，并且结合文档丰富的系统提示、重复采样和自我验证，LLMs的建模准确率可显著提升，在新基准上最高可达70%。", "keywords": "大型语言模型, 约束建模, 约束编程, 基准测试, CP-Bench", "comments": "CP-Bench的创新之处在于其多样化的数据集，这弥补了现有评估数据集的不足，更贴近真实世界场景。这项工作对于推动LLMs在自动化约束建模领域的应用具有重要意义，特别是指出了Python框架的优势以及提示工程和推理时策略的有效性。其局限性可能在于70%的准确率仍有提升空间，且未详细探讨不同LLM架构或规模对建模性能的影响。"}}
{"id": "2506.05515", "title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting", "authors": ["Adrien Cortés", "Rémi Rehm", "Victor Letzelter"], "summary": "We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL)\nparadigm to forecast multiple plausible time series futures. Our approach\nemploys a neural network with multiple heads and utilizes the Winner-Takes-All\n(WTA) loss to promote diversity among predictions. MCL has recently gained\nattention due to its simplicity and ability to address ill-posed and ambiguous\ntasks. We propose an adaptation of this framework for time-series forecasting,\npresenting it as an efficient method to predict diverse futures, which we\nrelate to its implicit quantization objective. We provide insights into our\napproach using synthetic data and evaluate it on real-world time series,\ndemonstrating its promising performance at a light computational cost.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05515v1", "AI": {"title_translation": "多元概率时间序列预测中的赢者通吃", "tldr": "TimeMCL是一种利用多选学习（MCL）和赢者通吃（WTA）损失来预测多元概率时间序列未来的方法，它能生成多样化预测且计算成本低。", "motivation": "旨在预测多个合理的未来时间序列；解决不适定和模糊的任务；提供一种高效预测多样化未来的方法。", "method": "本文引入了TimeMCL，一种利用多选学习（MCL）范式进行多元概率时间序列预测的方法。该方法采用具有多个头部的神经网络，并利用赢者通吃（WTA）损失来促进预测的多样性。该框架被适应于时间序列预测，并与隐式量化目标相关联。", "result": "在合成数据和真实世界时间序列上进行了评估，结果表明其性能有前景，且计算成本较低。", "conclusion": "TimeMCL是一种有效且计算成本低廉的方法，能够预测多元概率时间序列的多种合理未来。", "translation": "我们引入TimeMCL，一种利用多选学习（MCL）范式来预测多个合理时间序列未来的方法。我们的方法采用具有多个头部的神经网络，并利用赢者通吃（WTA）损失来促进预测的多样性。MCL最近因其简单性和解决不适定和模糊任务的能力而受到关注。我们提出了该框架在时间序列预测中的应用，将其作为一种高效预测多样化未来的方法，并将其与隐式量化目标联系起来。我们使用合成数据提供了对我们方法的见解，并在真实世界时间序列上对其进行了评估，展示了其在轻量计算成本下有前景的性能。", "summary": "本文介绍了TimeMCL，一种基于多选学习（MCL）和赢者通吃（WTA）损失的多元概率时间序列预测方法。该方法采用多头神经网络来生成多样化预测，并被证明在计算成本较低的情况下表现出有前景的性能，有效解决了预测多个合理未来时间序列的挑战。", "keywords": "时间序列预测, 概率预测, 多选学习, 赢者通吃, 多元预测", "comments": "该论文的创新点在于将多选学习（MCL）范式及其赢者通吃（WTA）损失应用于多元概率时间序列预测，以促进预测的多样性。其重要性在于提供了一种有效且计算成本低廉的方法来处理时间序列预测中的不确定性和多模态性，这在许多实际应用中至关重要。"}}
{"id": "2506.06221", "title": "BiAssemble: Learning Collaborative Affordance for Bimanual Geometric Assembly", "authors": ["Yan Shen", "Ruihai Wu", "Yubin Ke", "Xinyuan Song", "Zeyi Li", "Xiaoqi Li", "Hongwei Fan", "Haoran Lu", "Hao dong"], "summary": "Shape assembly, the process of combining parts into a complete whole, is a\ncrucial robotic skill with broad real-world applications. Among various\nassembly tasks, geometric assembly--where broken parts are reassembled into\ntheir original form (e.g., reconstructing a shattered bowl)--is particularly\nchallenging. This requires the robot to recognize geometric cues for grasping,\nassembly, and subsequent bimanual collaborative manipulation on varied\nfragments. In this paper, we exploit the geometric generalization of\npoint-level affordance, learning affordance aware of bimanual collaboration in\ngeometric assembly with long-horizon action sequences. To address the\nevaluation ambiguity caused by geometry diversity of broken parts, we introduce\na real-world benchmark featuring geometric variety and global reproducibility.\nExtensive experiments demonstrate the superiority of our approach over both\nprevious affordance-based and imitation-based methods. Project page:\nhttps://sites.google.com/view/biassembly/.", "comment": "ICML 2025", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06221v1", "AI": {"title_translation": "BiAssemble：学习双臂几何组装中的协作功能", "tldr": "BiAssemble是一种学习双臂协作功能以进行几何组装的方法，并在实际基准测试中表现出色。", "motivation": "形状组装是机器人的一项关键技能，具有广泛的实际应用。在各种组装任务中，几何组装——即将破碎的零件重新组装成其原始形式（例如，重建一个破碎的碗）——尤其具有挑战性。这要求机器人识别几何线索以进行抓取、组装以及后续对各种碎片的双臂协作操作。", "method": "本文利用点级功能几何泛化，学习在几何组装中具有长序列动作的双臂协作功能。为了解决破碎零件几何多样性引起的评估模糊性，引入了一个具有几何多样性和全局可重复性的真实世界基准。", "result": "大量的实验证明，我们的方法优于以前基于功能和基于模仿的方法。", "conclusion": "Not mentioned in abstract", "translation": "形状组装是将零件组合成一个完整整体的过程，是机器人的一项关键技能，具有广泛的实际应用。在各种组装任务中，几何组装——即将破碎的零件重新组装成其原始形式（例如，重建一个破碎的碗）——尤其具有挑战性。这要求机器人识别几何线索以进行抓取、组装以及后续对各种碎片的双臂协作操作。在本文中，我们利用点级功能几何泛化，学习在几何组装中具有长序列动作的双臂协作功能。为了解决破碎零件几何多样性引起的评估模糊性，我们引入了一个具有几何多样性和全局可重复性的真实世界基准。大量的实验证明，我们的方法优于以前基于功能和基于模仿的方法。项目页面：https://sites.google.com/view/biassembly/。", "summary": "本文提出BiAssemble，一种利用点级功能几何泛化来学习双臂协作功能的方法，旨在解决几何组装中破碎零件的挑战。该方法能够处理长序列动作，并引入了一个具有几何多样性和全局可重复性的真实世界基准。实验结果表明，BiAssemble优于现有的基于功能和基于模仿的方法，提升了机器人进行复杂几何组装的能力。", "keywords": "几何组装, 双臂协作, 功能学习, 机器人技能, 点级功能", "comments": "该论文的创新之处在于利用点级功能泛化来学习双臂协作功能，以应对几何组装中破碎零件的多样性和评估挑战。引入真实世界基准也提升了研究的实用性和可重复性。其优于现有方法的表现表明了该方法在机器人组装领域的潜力。"}}
{"id": "2506.05409", "title": "Object-level Self-Distillation for Vision Pretraining", "authors": ["Çağlar Hızlı", "Çağatay Yıldız", "Pekka Marttinen"], "summary": "State-of-the-art vision pretraining methods rely on image-level\nself-distillation from object-centric datasets such as ImageNet, implicitly\nassuming each image contains a single object. This assumption does not always\nhold: many ImageNet images already contain multiple objects. Further, it limits\nscalability to scene-centric datasets that better mirror real-world complexity.\nWe address these challenges by introducing Object-level Self-DIStillation\n(ODIS), a pretraining approach that shifts the self-distillation granularity\nfrom whole images to individual objects. Using object-aware cropping and masked\nattention, ODIS isolates object-specific regions, guiding the transformer\ntoward semantically meaningful content and transforming a noisy, scene-level\ntask into simpler object-level sub-tasks. We show that this approach improves\nvisual representations both at the image and patch levels. Using masks at\ninference time, our method achieves an impressive $82.6\\%$ $k$-NN accuracy on\nImageNet1k with ViT-Large.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05409v1", "AI": {"title_translation": "面向视觉预训练的对象级自蒸馏", "tldr": "本文提出了一种名为ODIS的对象级自蒸馏方法，用于视觉预训练，解决了现有图像级自蒸馏的局限性，通过关注单个对象来提高视觉表示，并在ImageNet1k上取得了82.6%的k-NN准确率。", "motivation": "目前最先进的视觉预训练方法依赖于ImageNet等以对象为中心的数据集进行图像级自蒸馏，并隐含假设每张图像只包含一个对象。然而，这一假设并不总是成立，许多ImageNet图像已经包含多个对象。此外，这限制了其扩展到更能反映真实世界复杂性的场景中心数据集的能力。", "method": "本文引入了对象级自蒸馏（Object-level Self-DIStillation, ODIS）预训练方法，将自蒸馏的粒度从整个图像转移到单个对象。ODIS通过使用对象感知裁剪和掩码注意力来隔离特定对象的区域，从而引导Transformer关注语义上有意义的内容，并将嘈杂的场景级任务转化为更简单的对象级子任务。", "result": "该方法在图像和补丁级别都改善了视觉表示。在推理时使用掩码，我们的方法使用ViT-Large在ImageNet1k上取得了令人印象深刻的82.6% k-NN准确率。", "conclusion": "通过将自蒸馏的粒度从图像级转移到对象级，ODIS显著改善了视觉表示，并在多对象场景中表现出更高的鲁棒性和可扩展性，从而在ImageNet1k上取得了优异的性能。", "translation": "最先进的视觉预训练方法依赖于ImageNet等以对象为中心的数据集进行图像级自蒸馏，隐含假设每张图像包含单个对象。这一假设并不总是成立：许多ImageNet图像已经包含多个对象。此外，它限制了其扩展到更能反映真实世界复杂性的场景中心数据集的能力。我们通过引入对象级自蒸馏（Object-level Self-DIStillation, ODIS）来解决这些挑战，这是一种将自蒸馏粒度从整个图像转移到单个对象的预训练方法。ODIS使用对象感知裁剪和掩码注意力隔离特定对象的区域，引导Transformer关注语义上有意义的内容，并将嘈杂的场景级任务转化为更简单的对象级子任务。我们表明，这种方法在图像和补丁级别都改善了视觉表示。在推理时使用掩码，我们的方法使用ViT-Large在ImageNet1k上取得了令人印象深刻的82.6% k-NN准确率。", "summary": "ODIS是一种新的视觉预训练方法，通过将自蒸馏的粒度从图像级转移到对象级来解决现有方法的局限性。它利用对象感知裁剪和掩码注意力来隔离对象区域，从而改进视觉表示。该方法在ImageNet1k上使用ViT-Large实现了82.6%的k-NN准确率。", "keywords": "对象级自蒸馏, 视觉预训练, 掩码注意力, 视觉表示, ImageNet", "comments": "该论文的创新之处在于将自蒸馏的粒度从传统的图像级转移到对象级，这对于包含多个对象的图像数据集更为鲁棒，并有望更好地扩展到复杂的真实世界场景。这种方法通过将复杂的场景级任务分解为更简单的对象级子任务，提高了模型的学习效率和表示能力。"}}
{"id": "2506.06121", "title": "Decomposability-Guaranteed Cooperative Coevolution for Large-Scale Itinerary Planning", "authors": ["Ziyu Zhang", "Peilan Xu", "Yuetong Sun", "Yuhui Shi", "Wenjian Luo"], "summary": "Large-scale itinerary planning is a variant of the traveling salesman\nproblem, aiming to determine an optimal path that maximizes the collected\npoints of interest (POIs) scores while minimizing travel time and cost, subject\nto travel duration constraints. This paper analyzes the decomposability of\nlarge-scale itinerary planning, proving that strict decomposability is\ndifficult to satisfy, and introduces a weak decomposability definition based on\na necessary condition, deriving the corresponding graph structures that fulfill\nthis property. With decomposability guaranteed, we propose a novel\nmulti-objective cooperative coevolutionary algorithm for large-scale itinerary\nplanning, addressing the challenges of component imbalance and interactions.\nSpecifically, we design a dynamic decomposition strategy based on the\nnormalized fitness within each component, define optimization potential\nconsidering component scale and contribution, and develop a computational\nresource allocation strategy. Finally, we evaluate the proposed algorithm on a\nset of real-world datasets. Comparative experiments with state-of-the-art\nmulti-objective itinerary planning algorithms demonstrate the superiority of\nour approach, with performance advantages increasing as the problem scale\ngrows.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.06121v1", "AI": {"title_translation": "大规模行程规划中的可分解性保证协同协同进化", "tldr": "本文提出了一种基于弱可分解性定义的多目标协同协同进化算法，用于解决大规模行程规划问题，并在真实数据集上表现出优越性。", "motivation": "解决大规模行程规划问题中严格可分解性难以满足以及组件不平衡和交互的挑战，以找到最优路径。", "method": "1. 分析大规模行程规划的可分解性，提出弱可分解性定义。 2. 基于弱可分解性，提出一种新型多目标协同协同进化算法。 3. 设计动态分解策略、优化潜力定义和计算资源分配策略。", "result": "在真实世界数据集上的比较实验表明，所提出的算法优于现有最先进的多目标行程规划算法，且性能优势随问题规模增长而增加。", "conclusion": "所提出的基于弱可分解性保证的多目标协同协同进化算法，能够有效解决大规模行程规划问题，并随着问题规模的增大展现出更显著的性能优势。", "translation": "大规模行程规划是旅行商问题的一种变体，旨在确定一条最优路径，以在旅行时间限制下最大化收集到的兴趣点（POI）分数，同时最小化旅行时间和成本。本文分析了大规模行程规划的可分解性，证明了严格可分解性难以满足，并基于一个必要条件引入了弱可分解性定义，推导出了满足此属性的相应图结构。在可分解性得到保证的情况下，我们提出了一种新颖的多目标协同协同进化算法，用于大规模行程规划，解决了组件不平衡和交互的挑战。具体来说，我们设计了一种基于每个组件内归一化适应度的动态分解策略，定义了考虑组件规模和贡献的优化潜力，并开发了计算资源分配策略。最后，我们在真实世界数据集上评估了所提出的算法。与最先进的多目标行程规划算法的比较实验表明，我们的方法具有优越性，且性能优势随问题规模的增长而增加。", "summary": "本文研究大规模行程规划问题，这是一种旅行商问题的变体。作者分析了其可分解性，并提出了一个基于必要条件的弱可分解性定义。在此基础上，提出了一种新颖的多目标协同协同进化算法，旨在解决组件不平衡和交互问题。该算法包含动态分解策略、优化潜力定义和计算资源分配策略。实验结果表明，该算法在真实数据集上优于现有方法，且性能优势随问题规模的增大而更显著。", "keywords": "大规模行程规划, 可分解性, 协同协同进化, 多目标优化, 旅行商问题", "comments": "本文的创新点在于提出了弱可分解性定义，并基于此设计了专门的协同协同进化算法，有效解决了大规模行程规划中组件交互和资源分配的挑战。其性能随问题规模增长而提升的特点显示了该方法在大规模问题上的潜力。"}}
{"id": "2506.05526", "title": "On Fitting Flow Models with Large Sinkhorn Couplings", "authors": ["Michal Klein", "Alireza Mousavi-Hosseini", "Stephen Zhang", "Marco Cuturi"], "summary": "Flow models transform data gradually from one modality (e.g. noise) onto\nanother (e.g. images). Such models are parameterized by a time-dependent\nvelocity field, trained to fit segments connecting pairs of source and target\npoints. When the pairing between source and target points is given, training\nflow models boils down to a supervised regression problem. When no such pairing\nexists, as is the case when generating data from noise, training flows is much\nharder. A popular approach lies in picking source and target points\nindependently. This can, however, lead to velocity fields that are slow to\ntrain, but also costly to integrate at inference time. In theory, one would\ngreatly benefit from training flow models by sampling pairs from an optimal\ntransport (OT) measure coupling source and target, since this would lead to a\nhighly efficient flow solving the Benamou and Brenier dynamical OT problem. In\npractice, recent works have proposed to sample mini-batches of $n$ source and\n$n$ target points and reorder them using an OT solver to form better pairs.\nThese works have advocated using batches of size $n\\approx 256$, and considered\nOT solvers that return couplings that are either sharp (using e.g. the\nHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.\nSinkhorn). We follow in the footsteps of these works by exploring the benefits\nof increasing $n$ by three to four orders of magnitude, and look more carefully\non the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn\nalgorithm. Our analysis is facilitated by new scale invariant quantities to\nreport the sharpness of a coupling, while our sharded computations across\nmultiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic\nand image generation tasks, flow models greatly benefit when fitted with large\nSinkhorn couplings, with a low entropic regularization $\\varepsilon$.", "comment": "20 pages, 14 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05526v1", "AI": {"title_translation": "关于使用大型 Sinkhorn 耦合拟合流模型", "tldr": "本文探索了使用大规模 Sinkhorn 耦合和低熵正则化来训练流模型，发现这能显著提升模型性能。", "motivation": "当源点和目标点之间没有明确配对时，训练流模型（如从噪声生成数据）非常困难。独立选择源点和目标点会导致训练缓慢且推理成本高昂的流模型。理论上，使用最优传输（OT）测量耦合采样对会更高效，但实际应用中，现有方法使用较小的批次大小（n≈256）和夏普或模糊的OT求解器，仍存在效率问题。", "method": "作者探索了将批次大小 n 增加三到四个数量级的好处，并更仔细地研究了 Sinkhorn 算法中熵正则化参数 ε 的影响。通过新的尺度不变量来报告耦合的锐度，并通过跨多个 GPU 或 GPU 节点的碎片化计算实现 n 的扩展。", "result": "在合成数据和图像生成任务中，使用大型 Sinkhorn 耦合和低熵正则化 ε 来拟合流模型可以获得显著的好处。", "conclusion": "使用大规模 Sinkhorn 耦合和适当的熵正则化是训练高效流模型的有效策略。", "translation": "流模型逐渐将数据从一种模态（例如噪声）转换到另一种模态（例如图像）。这类模型由时间相关的速度场参数化，并通过拟合连接源点和目标点对的片段进行训练。当源点和目标点之间的配对已知时，训练流模型就简化为监督回归问题。当不存在这种配对时，例如从噪声生成数据时，训练流模型就变得困难得多。一种流行的方法是独立选择源点和目标点。然而，这可能导致速度场训练缓慢，并且在推理时集成成本高昂。理论上，如果通过从最优传输（OT）测量耦合源点和目标点中采样对来训练流模型，将极大地受益，因为这将导致一个高效的流来解决 Benamou 和 Brenier 动态 OT 问题。在实践中，最近的工作提出采样 n 个源点和 n 个目标点的小批量数据，并使用 OT 求解器对其进行重新排序以形成更好的配对。这些工作提倡使用大小约为 n≈256 的批次，并考虑返回锐利（例如使用匈牙利算法）或模糊（例如使用熵正则化，又称 Sinkhorn）耦合的 OT 求解器。我们沿着这些工作的足迹，探索将 n 增加三到四个数量级的好处，并更仔细地研究 Sinkhorn 算法中使用的熵正则化 ε 的影响。我们的分析通过新的尺度不变量来报告耦合的锐度，而我们跨多个 GPU 或 GPU 节点的碎片化计算允许扩展 n。我们表明，在合成和图像生成任务中，流模型在拟合大型 Sinkhorn 耦合且具有低熵正则化 ε 时会获得巨大的好处。", "summary": "流模型在没有明确源目标配对时训练困难。现有方法使用小批量OT求解器进行配对，但效率不高。本文提出将Sinkhorn耦合的批次大小n增加三到四个数量级，并仔细研究熵正则化ε的影响。通过引入新的尺度不变量和分布式计算，作者证明在合成和图像生成任务中，使用大规模Sinkhorn耦合和低熵正则化能显著提升流模型的性能。", "keywords": "流模型, Sinkhorn 耦合, 最优传输, 熵正则化", "comments": "本文的创新点在于探索了大规模 Sinkhorn 耦合在流模型训练中的潜力，并通过技术手段（尺度不变量、分布式计算）克服了传统方法的局限性。这对于提高流模型训练效率和性能具有重要意义，尤其是在生成模型领域。"}}
{"id": "2506.05692", "title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "authors": ["Xinghang Li", "Jingzhe Ding", "Chao Peng", "Bing Zhao", "Xiang Gao", "Hongwan Gao", "Xinchen Gu"], "summary": "The code generation capabilities of large language models(LLMs) have emerged\nas a critical dimension in evaluating their overall performance. However, prior\nresearch has largely overlooked the security risks inherent in the generated\ncode. In this work, we introduce \\benchmark, a benchmark specifically designed\nto assess the security of LLM-generated code. The dataset encompasses a wide\nrange of common software development scenarios and vulnerability types.\nBuilding upon this benchmark, we develop an automatic evaluation framework that\nleverages both static application security testing(SAST) and LLM-based judging\nto assess the presence of security vulnerabilities in model-generated code.\nThrough the empirical evaluation of state-of-the-art LLMs on \\benchmark, we\nreveal notable deficiencies in their ability to produce vulnerability-free\ncode. Our findings highlight pressing challenges and offer actionable insights\nfor future advancements in the secure code generation performance of LLMs. The\ndata and code will be released soon.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05692v1", "AI": {"title_translation": "SafeGenBench：一个用于检测大型语言模型生成代码中安全漏洞的基准框架", "tldr": "引入SafeGenBench，一个评估LLM生成代码安全性的基准，发现现有LLM在生成无漏洞代码方面存在显著缺陷。", "motivation": "尽管大型语言模型（LLM）的代码生成能力是评估其整体性能的关键维度，但先前的研究在很大程度上忽视了生成代码中固有的安全风险。", "method": "本研究引入了一个名为SafeGenBench的基准，专门用于评估LLM生成代码的安全性。该数据集涵盖了广泛的常见软件开发场景和漏洞类型。在此基准之上，开发了一个自动评估框架，该框架利用静态应用安全测试（SAST）和基于LLM的判断来评估模型生成代码中安全漏洞的存在。", "result": "通过对SafeGenBench上最先进LLM的实证评估，揭示了它们在生成无漏洞代码方面的显著缺陷。", "conclusion": "研究结果强调了紧迫的挑战，并为LLM安全代码生成性能的未来发展提供了可行的见解。", "translation": "大型语言模型（LLM）的代码生成能力已成为评估其整体性能的关键维度。然而，先前的研究在很大程度上忽视了生成代码中固有的安全风险。在这项工作中，我们引入了SafeGenBench，一个专门设计用于评估LLM生成代码安全性的基准。该数据集涵盖了广泛的常见软件开发场景和漏洞类型。在此基准之上，我们开发了一个自动评估框架，该框架利用静态应用安全测试（SAST）和基于LLM的判断来评估模型生成代码中安全漏洞的存在。通过对SafeGenBench上最先进LLM的实证评估，我们揭示了它们在生成无漏洞代码方面的显著缺陷。我们的研究结果强调了紧迫的挑战，并为LLM安全代码生成性能的未来发展提供了可行的见解。数据和代码将很快发布。", "summary": "本研究介绍了SafeGenBench，一个用于评估大型语言模型生成代码安全性的基准框架。该框架包含一个涵盖多种开发场景和漏洞类型的数据集，并结合SAST和LLM判断进行自动化评估。通过对主流LLM的测试，发现它们在生成无漏洞代码方面存在明显不足，并提出了未来改进的方向。", "keywords": "LLM, 代码生成, 安全漏洞, 基准测试, SafeGenBench", "comments": "这项工作通过引入一个专门的基准和评估框架，填补了LLM生成代码安全风险评估方面的空白，具有重要的创新性和实用价值。它揭示了当前LLM在安全代码生成方面的局限性，为未来的研究和开发提供了明确的方向。"}}
{"id": "2506.06255", "title": "From NLVO to NAO: Reactive Robot Navigation using Velocity and Acceleration Obstacles", "authors": ["Asher Stern", "Zvi Shiller"], "summary": "This paper introduces a novel approach for robot navigation in challenging\ndynamic environments. The proposed method builds upon the concept of Velocity\nObstacles (VO) that was later extended to Nonlinear Velocity Obstacles (NLVO)\nto account for obstacles moving along nonlinear trajectories. The NLVO is\nextended in this paper to Acceleration Obstacles (AO) and Nonlinear\nAcceleration Obstacles (NAO) that account for velocity and acceleration\nconstraints. Multi-robot navigation is achieved by using the same avoidance\nalgorithm by all robots. At each time step, the trajectories of all robots are\npredicted based on their current velocity and acceleration to allow the\ncomputation of their respective NLVO, AO and NAO.\n  The introduction of AO and NAO allows the generation of safe avoidance\nmaneuvers that account for the robot dynamic constraints better than could be\ndone with the NLVO alone. This paper demonstrates the use of AO and NAO for\nrobot navigation in challenging environments. It is shown that using AO and NAO\nenables simultaneous real-time collision avoidance while accounting for robot\nkinematics and a direct consideration of its dynamic constraints. The presented\napproach enables reactive and efficient navigation, with potential application\nfor autonomous vehicles operating in complex dynamic environments.", "comment": "8 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2504.13637", "cate": "cs.RO", "url": "http://arxiv.org/pdf/2506.06255v1", "AI": {"title_translation": "从NLVO到NAO：使用速度和加速度障碍的反应式机器人导航", "tldr": "本文介绍了一种将NLVO扩展到AO和NAO的新型机器人导航方法，该方法考虑了速度和加速度约束，实现了在复杂动态环境中安全高效的实时避碰。", "motivation": "现有方法（如NLVO）在处理机器人动态约束方面存在不足，尤其是在复杂动态环境中，无法充分考虑速度和加速度约束。", "method": "本文将非线性速度障碍（NLVO）扩展到加速度障碍（AO）和非线性加速度障碍（NAO），以考虑速度和加速度约束。通过预测所有机器人的轨迹来计算各自的NLVO、AO和NAO，所有机器人使用相同的避障算法实现多机器人导航。", "result": "引入AO和NAO能够生成比单独使用NLVO更安全、更充分考虑机器人动态约束的避障机动。使用AO和NAO实现了同步实时避碰，同时考虑了机器人运动学及其动态约束。", "conclusion": "使用AO和NAO的方法能够实现反应式和高效的导航，在复杂动态环境中运行的自动驾驶车辆具有潜在应用。", "translation": "本文介绍了一种在挑战性动态环境中进行机器人导航的新颖方法。所提出的方法建立在速度障碍（VO）概念的基础上，该概念后来扩展到非线性速度障碍（NLVO）以考虑沿非线性轨迹移动的障碍物。本文将NLVO扩展到加速度障碍（AO）和非线性加速度障碍（NAO），以考虑速度和加速度约束。通过所有机器人使用相同的避障算法实现多机器人导航。在每个时间步，根据所有机器人当前的速度和加速度预测其轨迹，以计算各自的NLVO、AO和NAO。AO和NAO的引入使得生成的安全避障机动能够比单独使用NLVO更好地考虑机器人动态约束。本文展示了AO和NAO在挑战性环境中进行机器人导航的应用。结果表明，使用AO和NAO能够实现同步实时避碰，同时考虑机器人运动学并直接考虑其动态约束。所提出的方法实现了反应式和高效的导航，在复杂动态环境中运行的自动驾驶车辆具有潜在应用。", "summary": "本文提出了一种新颖的机器人导航方法，将非线性速度障碍（NLVO）概念扩展为加速度障碍（AO）和非线性加速度障碍（NAO）。该方法通过考虑机器人的速度和加速度约束，预测机器人轨迹并计算相应的障碍区域，从而在动态环境中实现多机器人实时安全避碰。实验结果表明，AO和NAO能够比单独使用NLVO更好地处理机器人动态约束，提供更安全、高效的导航策略，适用于自动驾驶车辆在复杂环境中的应用。", "keywords": "机器人导航, 速度障碍, 加速度障碍, 实时避碰, 动态环境", "comments": "该论文的创新点在于将现有的速度障碍概念进一步扩展到加速度障碍，从而更全面地考虑了机器人的动态约束，这对于在高速或复杂动态环境中运行的自主系统至关重要。其重要性在于提升了机器人导航的安全性与效率，尤其是在多机器人协作避障场景下。"}}
{"id": "2506.05412", "title": "Can Vision Language Models Infer Human Gaze Direction? A Controlled Study", "authors": ["Zory Zhang", "Pinyuan Feng", "Bingyang Wang", "Tianwei Zhao", "Suyang Yu", "Qingying Gao", "Hokin Deng", "Ziqiao Ma", "Yijiang Li", "Dezhi Luo"], "summary": "Gaze-referential inference--the ability to infer what others are looking\nat--is a critical component of a theory of mind that underpins natural human-AI\ninteraction. In a controlled study, we evaluated this skill across 111 Vision\nLanguage Models (VLMs) using photos taken with manipulated difficulty and\nvariability, comparing performance with that of human participants (N = 65),\nand analyzed behaviors using mixed-effects models. We found that 94 of the 111\nVLMs failed to do better than random guessing, while humans achieved\nnear-ceiling accuracy. VLMs even respond with each choice almost equally\nfrequently. Are they randomly guessing? Although most VLMs struggle, when we\nzoom in on five of the top-tier VLMs with above-chance performance, we find\nthat their performance declined with increasing task difficulty but varied only\nslightly across different prompts and scene objects. These behavioral features\ncannot be explained by considering them as random guessers. Instead, they\nlikely use a combination of heuristics and guessing such that their performance\nis subject to the task difficulty but robust to perceptual variations. This\nsuggests that VLMs, lacking gaze inference capability, have yet to become\ntechnologies that can naturally interact with humans, but the potential\nremains.", "comment": "Preprint under review. Project page at\n  https://grow-ai-like-a-child.github.io/gaze/", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05412v1", "AI": {"title_translation": "视觉语言模型能否推断人类凝视方向？一项对照研究", "tldr": "大多数视觉语言模型无法准确推断人类凝视方向，但少数顶级模型表现出非随机行为，仍有发展潜力。", "motivation": "凝视参照推断是心智理论的关键组成部分，对自然的人机交互至关重要。该研究旨在评估视觉语言模型（VLMs）在这方面的能力。", "method": "研究人员进行了一项对照研究，评估了111个视觉语言模型（VLMs）的凝视推断能力，使用难度和变异性经过控制的照片，并与65名人类参与者的表现进行比较，使用混合效应模型分析行为。", "result": "111个VLM中有94个表现不如随机猜测，而人类几乎达到最高准确率。即使是表现较好的顶级VLM，其性能也随任务难度增加而下降，但对不同提示和场景对象的敏感度较低。这表明它们可能结合了启发式方法和猜测，性能受任务难度影响但对感知变异具有鲁棒性。", "conclusion": "视觉语言模型目前缺乏凝视推断能力，尚未成为能与人类自然交互的技术，但仍有潜力。", "translation": "凝视参照推断——推断他人在看什么的这种能力——是心智理论的关键组成部分，它支撑着自然的人机交互。在一项对照研究中，我们使用难度和变异性经过操控的照片，评估了111个视觉语言模型（VLMs）的这项技能，并将其性能与人类参与者（N=65）的表现进行比较，使用混合效应模型分析了它们的行为。我们发现，111个VLM中有94个表现不如随机猜测，而人类达到了接近最高水平的准确率。VLM甚至对每个选项的响应频率几乎相同。它们是随机猜测吗？尽管大多数VLM表现不佳，但当我们仔细观察五个表现优于随机猜测的顶级VLM时，我们发现它们的性能随任务难度增加而下降，但对不同提示和场景对象的变异性很小。这些行为特征无法通过将其视为随机猜测来解释。相反，它们可能结合了启发式方法和猜测，因此它们的性能受任务难度影响，但对感知变异具有鲁棒性。这表明，缺乏凝视推断能力的VLM尚未成为能够与人类自然交互的技术，但其潜力依然存在。", "summary": "本文通过一项对照研究，评估了111个视觉语言模型（VLMs）在推断人类凝视方向方面的能力，并与人类表现进行了比较。研究发现，绝大多数VLM的表现未能超越随机猜测，而人类表现优异。少数表现较好的顶级VLM显示出性能随任务难度增加而下降的趋势，但对感知变异具有鲁棒性，这表明它们可能结合了启发式方法和猜测。研究得出结论，VLMs目前缺乏凝视推断能力，尚不能实现自然的人机交互，但未来仍有发展潜力。", "keywords": "视觉语言模型, 凝视推断, 人机交互", "comments": "这项研究通过严格的对照实验，揭示了当前视觉语言模型在模拟人类高级认知能力（如凝视推断）方面的显著局限性。其创新之处在于使用了受控的难度和变异性照片，并详细分析了模型行为，区分了随机猜测和基于启发式的表现。研究结果强调了在实现真正智能、自然的人机交互方面，VLMs仍需在理解复杂人类意图和行为上取得重大突破。"}}
{"id": "2506.06216", "title": "Integer Linear Programming Preprocessing for Maximum Satisfiability", "authors": ["Jialu Zhang", "Chu-Min Li", "Sami Cherif", "Shuolin Li", "Zhifei Zheng"], "summary": "The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge\nwith numerous practical applications. In recent MaxSAT evaluations, most MaxSAT\nsolvers have adopted an ILP solver as part of their portfolios. This paper\ninvestigates the impact of Integer Linear Programming (ILP) preprocessing\ntechniques on MaxSAT solving. Experimental results show that ILP preprocessing\ntechniques help WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024\nin the unweighted track, solve 15 additional instances. Moreover, current\nstate-of-the-art MaxSAT solvers heavily use an ILP solver in their portfolios,\nwhile our proposed approach reduces the need to call an ILP solver in a\nportfolio including WMaxCDCL or MaxCDCL.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.06216v1", "AI": {"title_translation": "整数线性规划预处理在最大可满足性问题中的应用", "tldr": "本文研究了整数线性规划（ILP）预处理对最大可满足性（MaxSAT）求解的影响，实验表明它能帮助求解器解决更多实例，并减少对ILP求解器的依赖。", "motivation": "最大可满足性问题（MaxSAT）是一个重要的优化挑战，具有广泛的实际应用。", "method": "本文研究了整数线性规划（ILP）预处理技术对MaxSAT求解的影响。", "result": "实验结果表明，ILP预处理技术帮助2024年MaxSAT评估无权重赛道冠军WMaxCDCL-OpenWbo1200额外解决了15个实例。此外，它减少了包含WMaxCDCL或MaxCDCL的组合中调用ILP求解器的需求。", "conclusion": "ILP预处理技术显著提高了MaxSAT求解器的性能，并降低了对外部ILP求解器的依赖。", "translation": "最大可满足性问题（MaxSAT）是一个重要的优化挑战，具有众多的实际应用。在最近的MaxSAT评估中，大多数MaxSAT求解器都采用了ILP求解器作为其组合的一部分。本文研究了整数线性规划（ILP）预处理技术对MaxSAT求解的影响。实验结果表明，ILP预处理技术帮助WMaxCDCL-OpenWbo1200（2024年MaxSAT评估无权重赛道冠军）额外解决了15个实例。此外，当前最先进的MaxSAT求解器在其组合中大量使用ILP求解器，而我们提出的方法减少了在包含WMaxCDCL或MaxCDCL的组合中调用ILP求解器的需求。", "summary": "本文探讨了整数线性规划（ILP）预处理技术在解决最大可满足性（MaxSAT）问题中的作用。研究发现，这种预处理方法能够提升MaxSAT求解器的性能，例如帮助WMaxCDCL-OpenWbo1200求解更多实例。同时，它还能有效减少当前先进MaxSAT求解器对ILP求解器的调用频率，从而优化求解过程。", "keywords": "最大可满足性, 整数线性规划, 预处理, MaxSAT求解器, 优化", "comments": "这项研究通过引入ILP预处理，为MaxSAT求解提供了一种有效的优化手段。其创新之处在于，它不仅提升了现有SOTA求解器的性能，更重要的是，它减少了对外部ILP求解器的依赖，这可能意味着更高效、更独立的MaxSAT求解方案。对于MaxSAT社区而言，这是一个有价值的进展。"}}
{"id": "2506.05530", "title": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum", "authors": ["Snir Hordan", "Maya Bechler-Speicher", "Gur Lifshitz", "Nadav Dym"], "summary": "Spectral features are widely incorporated within Graph Neural Networks (GNNs)\nto improve their expressive power, or their ability to distinguish among\nnon-isomorphic graphs. One popular example is the usage of graph Laplacian\neigenvectors for positional encoding in MPNNs and Graph Transformers. The\nexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluated\nvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,\nthese frameworks align poorly with the graph spectra, yielding limited insight\ninto SGNNs' expressive power. We leverage a well-studied paradigm of\nclassifying graphs by their largest eigenvalue multiplicity to introduce an\nexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incomplete\neven on graphs with distinct eigenvalues. To mitigate this deficiency, we adapt\nrotation equivariant neural networks to the graph spectra setting to propose a\nmethod to provably improve SGNNs' expressivity on simple spectrum graphs. We\nempirically verify our theoretical claims via an image classification\nexperiment on the MNIST Superpixel dataset and eigenvector canonicalization on\ngraphs from ZINC.", "comment": "9 pages main text", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05530v1", "AI": {"title_translation": "谱图神经网络在简单谱图上的不完备性", "tldr": "本研究证明了许多谱图神经网络（SGNNs）在具有简单谱的图上是不完备的，并提出了一种通过适应旋转等变神经网络来提高其表达能力的方法，并通过实验验证了其有效性。", "motivation": "谱特征被广泛应用于图神经网络（GNNs）以提高其表达能力，但现有评估框架（如k-WL图同构测试）与图谱对齐不佳，限制了对SGNNs表达能力的深入理解。研究发现SGNNs即使在具有不同特征值的图上也是不完备的。", "method": "研究利用按最大特征值多重性对图进行分类的范式，为SGNNs引入了一个表达能力层次结构。然后，证明了许多SGNNs即使在具有不同特征值的图上也是不完备的。为了弥补这一不足，研究将旋转等变神经网络适应到图谱设置中，提出了一种可证明提高SGNNs在简单谱图上表达能力的方法。", "result": "通过在MNIST Superpixel数据集上的图像分类实验和在ZINC图上的特征向量规范化，经验性地验证了理论主张。", "conclusion": "许多谱图神经网络（SGNNs）在具有简单谱的图上是不完备的。本研究提出了一种适应旋转等变神经网络的方法，可以有效地提高SGNNs在简单谱图上的表达能力。", "translation": "谱图神经网络（GNNs）中广泛融入谱特征以提高其表达能力，即区分非同构图的能力。一个常见的例子是使用图拉普拉斯特征向量进行MPNNs和图Transformer中的位置编码。此类谱增强型GNNs（SGNNs）的表达能力通常通过k-WL图同构测试层次结构和同态计数进行评估。然而，这些框架与图谱对齐不佳，对SGNNs表达能力的洞察有限。我们利用一个通过最大特征值多重性对图进行分类的成熟范式，为SGNNs引入了一个表达能力层次结构。然后，我们证明了许多SGNNs即使在具有不同特征值的图上也是不完备的。为了弥补这一缺陷，我们将旋转等变神经网络适应到图谱设置中，提出了一种可证明提高SGNNs在简单谱图上表达能力的方法。我们通过在MNIST Superpixel数据集上的图像分类实验和在ZINC图上的特征向量规范化，经验性地验证了我们的理论主张。", "summary": "本论文探讨了谱图神经网络（SGNNs）的表达能力，指出其在区分非同构图方面的不足。作者提出，现有评估框架（如k-WL）未能充分反映SGNNs的谱特性。为此，论文引入了一种基于图最大特征值多重性的表达能力层次结构，并证明了许多SGNNs即使在具有简单谱的图上也是不完备的。为解决此问题，论文提出了一种将旋转等变神经网络应用于图谱设置的方法，以提高SGNNs在简单谱图上的表达能力。实验结果在MNIST Superpixel图像分类和ZINC数据集上验证了理论发现。", "keywords": "谱图神经网络, 表达能力, 图同构, 特征值, 旋转等变神经网络", "comments": "本文通过引入新的表达能力层次结构并证明谱图神经网络在简单谱图上的不完备性，对图神经网络的理论基础做出了重要贡献。提出的适应旋转等变神经网络的方法为提高SGNNs的表达能力提供了有前景的方向，具有创新性。"}}
{"id": "2506.05414", "title": "SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing", "authors": ["Mingfei Chen", "Zijun Cui", "Xiulong Liu", "Jinlin Xiang", "Caleb Zheng", "Jingyuan Li", "Eli Shlizerman"], "summary": "3D spatial reasoning in dynamic, audio-visual environments is a cornerstone\nof human cognition yet remains largely unexplored by existing Audio-Visual\nLarge Language Models (AV-LLMs) and benchmarks, which predominantly focus on\nstatic or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D\nspatial reasoning in dynamic scenes with synchronized spatial audio.\nSAVVY-Bench is comprised of thousands of relationships involving static and\nmoving objects, and requires fine-grained temporal grounding, consistent 3D\nlocalization, and multi-modal annotation. To tackle this challenge, we propose\nSAVVY, a novel training-free reasoning pipeline that consists of two stages:\n(i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as\nother audio-visual methods to track the trajectories of key objects related to\nthe query using both visual and spatial audio cues, and (ii) Dynamic Global Map\nConstruction, which aggregates multi-modal queried object trajectories and\nconverts them into a unified global dynamic map. Using the constructed map, a\nfinal QA answer is obtained through a coordinate transformation that aligns the\nglobal map with the queried viewpoint. Empirical evaluation demonstrates that\nSAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a\nnew standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.", "comment": "Project website with demo videos: https://zijuncui02.github.io/SAVVY/", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05414v1", "AI": {"title_translation": "SAVVY: 通过视觉和听觉实现音视频大语言模型的空间感知", "tldr": "SAVVY引入了SAVVY-Bench，首个用于动态3D场景空间推理的基准测试，并提出了一个名为SAVVY的无训练推理管道，显著提升了现有音视频大语言模型在动态3D空间推理上的性能。", "motivation": "现有的音视频大语言模型（AV-LLMs）和基准测试主要关注静态或2D场景，而3D空间推理在动态音视频环境中是人类认知的基础，但在这方面仍未被充分探索。", "method": "本文引入了SAVVY-Bench，这是首个用于动态场景中3D空间推理的基准测试，包含数千个涉及静态和移动对象的关系。为解决这一挑战，提出了SAVVY，一个无训练的推理管道，分为两个阶段：(i) 以自我为中心的空间轨迹估计，利用AV-LLMs和其他音视频方法，通过视觉和空间音频线索跟踪与查询相关的关键对象的轨迹；(ii) 动态全局地图构建，聚合多模态查询对象的轨迹并将其转换为统一的全局动态地图。最终的问答答案通过坐标变换获得，将全局地图与查询视角对齐。", "result": "实证评估表明，SAVVY显著增强了最先进的音视频大语言模型的性能，为音视频大语言模型中处理动态3D空间推理设定了新的标准和阶段。", "conclusion": "SAVVY及其伴随的SAVVY-Bench为音视频大语言模型在动态3D空间推理领域的研究和发展开辟了新途径，并显著提升了现有模型的性能。", "translation": "3D空间推理在动态、音视频环境中是人类认知的基石，然而现有音视频大语言模型（AV-LLMs）和基准测试对此仍未充分探索，它们主要关注静态或2D场景。我们引入了SAVVY-Bench，这是首个用于动态场景中3D空间推理的基准测试，并带有同步空间音频。SAVVY-Bench包含数千个涉及静态和移动对象的关系，需要细粒度的时间定位、一致的3D定位和多模态标注。为了应对这一挑战，我们提出了SAVVY，一个新颖的无训练推理管道，它由两个阶段组成：(i) 以自我为中心的空间轨迹估计，利用AV-LLMs以及其他音视频方法，通过视觉和空间音频线索跟踪与查询相关的关键对象的轨迹；(ii) 动态全局地图构建，聚合多模态查询对象的轨迹并将其转换为统一的全局动态地图。使用构建的地图，通过将全局地图与查询视角对齐的坐标变换，获得最终的问答答案。实证评估表明，SAVVY显著增强了最先进的AV-LLMs的性能，为AV-LLMs中处理动态3D空间推理设定了新的标准和阶段。", "summary": "本文介绍了SAVVY-Bench，这是首个针对动态音视频环境中3D空间推理的基准测试，旨在解决现有音视频大语言模型（AV-LLMs）在此领域探索不足的问题。为应对这一挑战，论文提出了SAVVY，一个新颖的无训练推理管道，它通过估计自我中心空间轨迹和构建动态全局地图来处理查询。实验结果表明，SAVVY显著提升了当前AV-LLMs的性能，为动态3D空间推理设定了新标准。", "keywords": "3D空间推理, 音视频大语言模型, 动态场景, SAVVY, SAVVY-Bench", "comments": "SAVVY的创新之处在于其提出了首个针对动态3D空间推理的基准测试SAVVY-Bench，并设计了一个无训练的推理管道，有效地利用了音视频大语言模型进行空间轨迹估计和全局地图构建。这对于推动AV-LLMs在更复杂、动态的真实世界场景中的应用具有重要意义。其“无训练”的特点也降低了部署和适应的门槛。"}}
{"id": "2506.06254", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "authors": ["Weizhi Zhang", "Xinyang Zhang", "Chenwei Zhang", "Liangwei Yang", "Jingbo Shang", "Zhepei Wei", "Henry Peng Zou", "Zijie Huang", "Zhengyang Wang", "Yifan Gao", "Xiaoman Pan", "Lian Xiong", "Jingguo Liu", "Philip S. Yu", "Xian Li"], "summary": "Large Language Model (LLM) empowered agents have recently emerged as advanced\nparadigms that exhibit impressive capabilities in a wide range of domains and\ntasks. Despite their potential, current LLM agents often adopt a\none-size-fits-all approach, lacking the flexibility to respond to users'\nvarying needs and preferences. This limitation motivates us to develop\nPersonaAgent, the first personalized LLM agent framework designed to address\nversatile personalization tasks. Specifically, PersonaAgent integrates two\ncomplementary components - a personalized memory module that includes episodic\nand semantic memory mechanisms; a personalized action module that enables the\nagent to perform tool actions tailored to the user. At the core, the persona\n(defined as unique system prompt for each user) functions as an intermediary:\nit leverages insights from personalized memory to control agent actions, while\nthe outcomes of these actions in turn refine the memory. Based on the\nframework, we propose a test-time user-preference alignment strategy that\nsimulate the latest n interactions to optimize the persona prompt, ensuring\nreal-time user preference alignment through textual loss feedback between\nsimulated and ground-truth responses. Experimental evaluations demonstrate that\nPersonaAgent significantly outperforms other baseline methods by not only\npersonalizing the action space effectively but also scaling during test-time\nreal-world applications. These results underscore the feasibility and potential\nof our approach in delivering tailored, dynamic user experiences.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.06254v1", "AI": {"title_translation": "PersonaAgent：当大型语言模型智能体在测试时遇到个性化", "tldr": "PersonaAgent是一个个性化的LLM智能体框架，通过个性化记忆和行动模块，以及测试时用户偏好对齐策略，显著提升了LLM智能体的个性化能力和实际应用的可扩展性。", "motivation": "当前的大型语言模型（LLM）智能体通常采用“一刀切”的方法，缺乏灵活性来响应用户不同的需求和偏好。", "method": "PersonaAgent集成了两个互补的组件：个性化记忆模块（包括情景记忆和语义记忆机制）和个性化行动模块（使智能体能够执行为用户量身定制的工具操作）。其核心是“persona”（为每个用户定义的独特系统提示）作为中介，利用个性化记忆的洞察力来控制智能体行动，行动结果反过来又优化记忆。此外，该框架提出了一种测试时用户偏好对齐策略，通过模拟最新的n次交互来优化persona提示，并利用模拟响应和真实响应之间的文本损失反馈来确保实时用户偏好对齐。", "result": "实验评估表明，PersonaAgent显著优于其他基线方法，不仅有效地个性化了行动空间，而且在测试时的实际应用中具有可扩展性。", "conclusion": "该方法在提供量身定制、动态的用户体验方面的可行性和潜力得到了强调。", "translation": "大型语言模型（LLM）赋能的智能体最近已成为先进的范式，在广泛的领域和任务中展现出令人印象深刻的能力。尽管它们具有潜力，但当前的LLM智能体通常采用“一刀切”的方法，缺乏灵活性来响应用户不同的需求和偏好。这一限制促使我们开发了PersonaAgent，这是第一个旨在解决通用个性化任务的个性化LLM智能体框架。具体而言，PersonaAgent集成了两个互补的组件——一个包含情景记忆和语义记忆机制的个性化记忆模块；一个使智能体能够执行为用户量身定制的工具操作的个性化行动模块。其核心是“persona”（为每个用户定义的独特系统提示）作为中介：它利用个性化记忆的洞察力来控制智能体行动，而这些行动的结果反过来又优化记忆。基于该框架，我们提出了一种测试时用户偏好对齐策略，该策略模拟最新的n次交互以优化persona提示，通过模拟响应和真实响应之间的文本损失反馈来确保实时用户偏好对齐。实验评估表明，PersonaAgent显著优于其他基线方法，不仅有效地个性化了行动空间，而且在测试时的实际应用中具有可扩展性。这些结果强调了我们方法在提供量身定制、动态用户体验方面的可行性和潜力。", "summary": "本文介绍了PersonaAgent，这是一个新颖的个性化大型语言模型（LLM）智能体框架，旨在解决现有LLM智能体缺乏个性化的问题。PersonaAgent通过整合个性化记忆模块（包括情景和语义记忆）和个性化行动模块来实现定制化交互。其核心机制是“persona”作为中介，利用记忆来指导行动并反向优化记忆。此外，该框架引入了一种测试时用户偏好对齐策略，通过模拟交互和文本损失反馈来实时优化persona提示。实验证明PersonaAgent在个性化行动空间和实际应用的可扩展性方面显著优于基线方法，展示了其提供定制化用户体验的潜力。", "keywords": "大型语言模型, 智能体, 个性化, 记忆模块, 测试时对齐", "comments": "PersonaAgent的创新之处在于其将个性化记忆和行动模块与测试时用户偏好对齐策略相结合，为LLM智能体提供了更强的适应性和用户定制能力，这对于提升用户体验和拓展LLM应用场景具有重要意义。"}}
{"id": "2506.05538", "title": "SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms", "authors": ["Arnesh Batra", "Anushk Kumar", "Jashn Khemani", "Arush Gumber", "Arhan Jain", "Somil Gupta"], "summary": "The rapid advancement of deep generative models has significantly improved\nthe realism of synthetic media, presenting both opportunities and security\nchallenges. While deepfake technology has valuable applications in\nentertainment and accessibility, it has emerged as a potent vector for\nmisinformation campaigns, particularly on social media. Existing detection\nframeworks struggle to distinguish between benign and adversarially generated\ndeepfakes engineered to manipulate public perception. To address this\nchallenge, we introduce SocialDF, a curated dataset reflecting real-world\ndeepfake challenges on social media platforms. This dataset encompasses\nhigh-fidelity deepfakes sourced from various online ecosystems, ensuring broad\ncoverage of manipulative techniques. We propose a novel LLM-based multi-factor\ndetection approach that combines facial recognition, automated speech\ntranscription, and a multi-agent LLM pipeline to cross-verify audio-visual\ncues. Our methodology emphasizes robust, multi-modal verification techniques\nthat incorporate linguistic, behavioral, and contextual analysis to effectively\ndiscern synthetic media from authentic content.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05538v1", "AI": {"title_translation": "社会DF：用于缓解社交媒体平台上有害深度伪造内容的基准数据集和检测模型", "tldr": "提出SocialDF数据集和一种基于LLM的多因素检测模型，用于识别社交媒体上的有害深度伪造内容。", "motivation": "深度伪造技术在社交媒体上被滥用，成为虚假信息传播的强大载体，而现有检测框架难以区分良性和对抗性生成的深度伪造，特别是那些旨在操纵公众认知的深度伪造。", "method": "引入了SocialDF数据集，该数据集包含来自各种在线生态系统的高保真深度伪造内容。提出了一种新颖的基于LLM的多因素检测方法，结合面部识别、自动语音转录和多智能体LLM管道来交叉验证视听线索，并强调鲁棒的多模态验证技术，包括语言、行为和上下文分析。", "result": "Not mentioned in abstract", "conclusion": "该研究通过引入专门的基准数据集和社会媒体深度伪造检测模型，旨在有效区分合成媒体和真实内容，从而缓解社交媒体上深度伪造带来的虚假信息挑战。", "translation": "深度生成模型的快速发展显著提高了合成媒体的真实性，带来了机遇也带来了安全挑战。尽管深度伪造技术在娱乐和无障碍方面具有宝贵应用，但它已成为虚假信息传播的强大载体，尤其是在社交媒体上。现有检测框架难以区分良性和对抗性生成的、旨在操纵公众认知的深度伪造。为了解决这一挑战，我们引入了SocialDF，这是一个反映社交媒体平台上真实世界深度伪造挑战的精选数据集。该数据集包含来自各种在线生态系统的高保真深度伪造，确保了对操纵技术的广泛覆盖。我们提出了一种新颖的基于LLM的多因素检测方法，该方法结合了面部识别、自动语音转录和多智能体LLM管道来交叉验证视听线索。我们的方法强调鲁棒的多模态验证技术，结合语言、行为和上下文分析，以有效辨别合成媒体和真实内容。", "summary": "本文介绍了SocialDF，一个专门用于应对社交媒体上深度伪造挑战的基准数据集。为了有效检测有害深度伪造内容，研究提出了一种新颖的基于大型语言模型（LLM）的多因素检测方法，该方法整合了面部识别、语音转录以及多智能体LLM管道，通过多模态分析（包括语言、行为和上下文线索）来辨别合成媒体。", "keywords": "深度伪造, 检测, 社交媒体, LLM, 数据集", "comments": "该论文通过引入一个专门的基准数据集和社会媒体深度伪造检测模型，解决了当前深度伪造检测领域面临的挑战，特别是现有框架难以应对对抗性深度伪造的问题。其创新之处在于提出了一个基于LLM的多因素检测方法，结合了多种模态分析，这有望提高检测的鲁棒性和准确性。"}}
{"id": "2506.05711", "title": "A symmetric LWE-based Multi-Recipient Cryptosystem", "authors": ["Saikat Gope", "Srinivasan Krishnaswamy", "Chayan Bhawal"], "summary": "This article describes a post-quantum multirecipient symmetric cryptosystem\nwhose security is based on the hardness of the LWE problem. In this scheme a\nsingle sender encrypts multiple messages for multiple recipients generating a\nsingle ciphertext which is broadcast to the recipients. Each recipient decrypts\nthe ciphertext with her secret key to recover the message intended for her. In\nthis process, the recipient cannot efficiently extract any information about\nthe other messages. This scheme is intended for messages like images and sound\nthat can tolerate a small amount of noise. This article introduces the scheme\nand establishes its security based on the LWE problem. Further, an example is\ngiven to demonstrate the application of this scheme for encrypting multiple\nimages.", "comment": "9 pages, 4 figures", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05711v1", "AI": {"title_translation": "对称LWE多接收者密码系统", "tldr": "基于LWE的多接收者对称加密系统，单发多收，抗量子，用于图像和声音等可容忍噪声的消息。", "motivation": "需要一个后量子、多接收者、单密文广播的对称加密系统，且接收者无法获取其他消息的信息，适用于可容忍少量噪声的数据。", "method": "提出一个基于LWE问题的多接收者对称密码系统，单发送者加密多条消息给多个接收者，生成一个单一密文广播。每个接收者用自己的密钥解密以恢复其指定消息，且无法有效提取其他消息信息。通过LWE问题建立其安全性。", "result": "引入了该方案并基于LWE问题建立了其安全性；通过一个加密多张图像的例子演示了其应用。", "conclusion": "该文章引入了一个基于LWE的后量子多接收者对称密码系统，并建立了其安全性，适用于可容忍噪声的消息类型。", "translation": "本文描述了一种后量子多接收者对称密码系统，其安全性基于LWE问题的困难性。在该方案中，单个发送者为多个接收者加密多条消息，生成一个广播给接收者的单一密文。每个接收者使用她的密钥解密密文以恢复为她指定的消息。在此过程中，接收者不能有效提取关于其他消息的任何信息。该方案旨在用于图像和声音等可以容忍少量噪声的消息。本文介绍了该方案并基于LWE问题建立了其安全性。此外，还给出了一个例子来演示该方案在加密多张图像方面的应用。", "summary": "本文介绍了一种基于LWE问题的后量子多接收者对称密码系统。该系统允许单个发送者为多个接收者加密多条消息，生成一个广播的单一密文。每个接收者可以使用自己的密钥解密以恢复其指定的消息，同时无法有效获取其他消息的信息。该方案适用于图像和声音等可容忍少量噪声的消息。文章阐述了该方案并基于LWE问题证明了其安全性，并给出了加密多张图像的应用示例。", "keywords": "LWE, 多接收者密码系统, 后量子密码, 对称加密, 密文广播", "comments": "该论文提出了一种新颖的后量子多接收者对称加密方案，其核心创新在于利用LWE问题的难度来保证安全性，并实现了单密文广播和接收者消息隔离的特性，这对于处理多媒体数据尤其具有实用价值。其对噪声的容忍度可能是一个特点，但也可能是其局限性。"}}
{"id": "2506.05417", "title": "Better STEP, a format and dataset for boundary representation", "authors": ["Nafiseh Izadyar", "Sai Chandra Madduri", "Teseo Schneider"], "summary": "Boundary representation (B-rep) generated from computer-aided design (CAD) is\nwidely used in industry, with several large datasets available. However, the\ndata in these datasets is represented in STEP format, requiring a CAD kernel to\nread and process it. This dramatically limits their scope and usage in large\nlearning pipelines, as it constrains the possibility of deploying them on\ncomputing clusters due to the high cost of per-node licenses.\n  This paper introduces an alternative format based on the open, cross-platform\nformat HDF5 and a corresponding dataset for STEP files, paired with an\nopen-source library to query and process them. Our Python package also provides\nstandard functionalities such as sampling, normals, and curvature to ease\nintegration in existing pipelines.\n  To demonstrate the effectiveness of our format, we converted the Fusion 360\ndataset and the ABC dataset. We developed four standard use cases (normal\nestimation, denoising, surface reconstruction, and segmentation) to assess the\nintegrity of the data and its compliance with the original STEP files.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05417v1", "AI": {"title_translation": "Better STEP：一种边界表示格式和数据集", "tldr": "本文提出了一种基于HDF5的开放格式和数据集，以及一个Python库，旨在解决现有STEP格式CAD数据集在大型学习管道中使用受限的问题，使其更易于访问和处理。", "motivation": "现有的边界表示（B-rep）CAD数据集以STEP格式存储，需要CAD内核来读取和处理，这限制了它们在大型学习管道中的应用，尤其是在计算集群上部署时，由于每节点许可证成本高昂。", "method": "本文引入了一种基于开放、跨平台HDF5格式的替代格式，并为STEP文件提供了一个相应的数据集，同时发布了一个开源Python库来查询和处理这些数据。该Python包还提供了采样、法线和曲率等标准功能。作者通过转换Fusion 360和ABC数据集，并开发了法线估计、去噪、表面重建和分割四种标准用例来评估数据完整性和与原始STEP文件的符合性，以证明新格式的有效性。", "result": "作者成功转换了Fusion 360数据集和ABC数据集，并开发了四种标准用例来评估数据的完整性及其与原始STEP文件的符合性，从而证明了所提出格式的有效性。", "conclusion": "本文提出了一种有效的替代格式和数据集，成功解决了现有STEP格式边界表示数据在大型学习管道中应用受限的问题，极大地提高了数据的可访问性和可用性。", "translation": "边界表示（B-rep）由计算机辅助设计（CAD）生成，在工业中广泛使用，并且有几个大型数据集可用。然而，这些数据集中的数据以STEP格式表示，需要CAD内核来读取和处理。这极大地限制了它们在大型学习管道中的范围和使用，因为它限制了由于每节点许可证的高成本而无法将其部署在计算集群上的可能性。\n本文介绍了一种基于开放、跨平台HDF5格式的替代格式，以及一个用于STEP文件的相应数据集，并配有一个开源库来查询和处理它们。我们的Python包还提供了标准功能，如采样、法线和曲率，以简化现有管道的集成。\n为了证明我们格式的有效性，我们转换了Fusion 360数据集和ABC数据集。我们开发了四种标准用例（法线估计、去噪、表面重建和分割）来评估数据的完整性及其与原始STEP文件的符合性。", "summary": "本文介绍了“Better STEP”，一种基于开放HDF5格式的边界表示（B-rep）数据格式和数据集，并提供了一个配套的开源Python库。该工作旨在克服现有STEP格式CAD数据集在大型学习管道中因依赖昂贵的CAD内核而难以使用的局限性。为证明新格式的有效性，作者转换了Fusion 360和ABC等大型数据集，并通过法线估计、去噪、表面重建和分割等用例评估了数据的完整性。", "keywords": "边界表示, CAD, STEP, HDF5, 数据集", "comments": "这篇论文通过提出一种更易于访问且成本效益更高的数据格式，解决了在机器学习中使用工业CAD数据的一个重要实际挑战。HDF5和开源Python库的结合具有创新性，使得大型边界表示数据集更适用于现代深度学习管道，有望显著推动CAD相关机器学习任务的研究和应用。"}}
{"id": "2506.06261", "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens", "authors": ["Jihwan Jeong", "Xiaoyu Wang", "Jingmin Wang", "Scott Sanner", "Pascal Poupart"], "summary": "Offline reinforcement learning (RL) is crucial when online exploration is\ncostly or unsafe but often struggles with high epistemic uncertainty due to\nlimited data. Existing methods rely on fixed conservative policies, restricting\nadaptivity and generalization. To address this, we propose Reflect-then-Plan\n(RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach.\nRefPlan unifies uncertainty modeling and MB planning by recasting planning as\nBayesian posterior estimation. At deployment, it updates a belief over\nenvironment dynamics using real-time observations, incorporating uncertainty\ninto MB planning via marginalization. Empirical results on standard benchmarks\nshow that RefPlan significantly improves the performance of conservative\noffline RL policies. In particular, RefPlan maintains robust performance under\nhigh epistemic uncertainty and limited data, while demonstrating resilience to\nchanging environment dynamics, improving the flexibility, generalizability, and\nrobustness of offline-learned policies.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/pdf/2506.06261v1", "AI": {"title_translation": "反思-然后-规划：通过双重贝叶斯视角进行离线基于模型的规划", "tldr": "提出RefPlan，一种双重贝叶斯离线模型规划方法，通过将规划视为贝叶斯后验估计来处理不确定性，提高离线RL策略的性能、鲁棒性和泛化能力。", "motivation": "离线强化学习在数据有限时面临高认知不确定性，现有方法依赖固定保守策略，限制了适应性和泛化能力。", "method": "提出Reflect-then-Plan (RefPlan)，一种新颖的双重贝叶斯离线基于模型的规划方法。它通过将规划重构为贝叶斯后验估计来统一不确定性建模和基于模型的规划。在部署时，RefPlan使用实时观测更新对环境动态的信念，并通过边缘化将不确定性纳入基于模型的规划中。", "result": "RefPlan显著提高了保守离线RL策略的性能。它在面临高认知不确定性和有限数据时仍能保持鲁棒性能，并对变化的环境动态表现出韧性，从而提高了离线学习策略的灵活性、泛化性和鲁棒性。", "conclusion": "RefPlan通过其双重贝叶斯方法有效解决了离线RL中的不确定性问题，显著提升了策略的性能、鲁棒性、灵活性和泛化能力。", "translation": "离线强化学习（RL）在在线探索成本高昂或不安全时至关重要，但由于数据有限，它经常面临高认知不确定性的困扰。现有方法依赖于固定的保守策略，这限制了适应性和泛化能力。为了解决这个问题，我们提出了Reflect-then-Plan（RefPlan），一种新颖的双重贝叶斯离线基于模型的（MB）规划方法。RefPlan通过将规划重构为贝叶斯后验估计，统一了不确定性建模和基于模型的规划。在部署时，它利用实时观测更新对环境动态的信念，并通过边缘化将不确定性纳入基于模型的规划中。标准基准上的实证结果表明，RefPlan显著提高了保守离线RL策略的性能。特别是，RefPlan在高认知不确定性和有限数据下保持了鲁棒性能，同时对变化的环境动态表现出韧性，从而提高了离线学习策略的灵活性、泛化性和鲁棒性。", "summary": "本论文提出了一种名为Reflect-then-Plan (RefPlan) 的新型双重贝叶斯离线基于模型的规划方法，旨在解决离线强化学习中因数据有限导致的高认知不确定性以及现有保守策略适应性差的问题。RefPlan将规划重新定义为贝叶斯后验估计，并在部署时结合实时观测和边缘化来处理不确定性。实验证明，RefPlan显著提升了离线RL策略的性能、鲁棒性、灵活性和泛化能力，尤其是在高不确定性和数据有限的环境下。", "keywords": "离线强化学习, 模型规划, 贝叶斯方法, 不确定性, 鲁棒性", "comments": "RefPlan的创新之处在于其双重贝叶斯视角，将规划与不确定性建模深度融合，并通过实时信念更新和边缘化处理不确定性，这对于解决离线RL中数据稀疏性带来的挑战具有重要意义。该方法提高了策略的适应性和泛化能力，使其在实际应用中更具潜力。"}}
{"id": "2506.05380", "title": "EvidenceOutcomes: a Dataset of Clinical Trial Publications with Clinically Meaningful Outcomes", "authors": ["Yiliang Zhou", "Abigail M. Newbury", "Gongbo Zhang", "Betina Ross Idnay", "Hao Liu", "Chunhua Weng", "Yifan Peng"], "summary": "The fundamental process of evidence extraction and synthesis in\nevidence-based medicine involves extracting PICO (Population, Intervention,\nComparison, and Outcome) elements from biomedical literature. However,\nOutcomes, being the most complex elements, are often neglected or\noversimplified in existing benchmarks. To address this issue, we present\nEvidenceOutcomes, a novel, large, annotated corpus of clinically meaningful\noutcomes extracted from biomedical literature. We first developed a robust\nannotation guideline for extracting clinically meaningful outcomes from text\nthrough iteration and discussion with clinicians and Natural Language\nProcessing experts. Then, three independent annotators annotated the Results\nand Conclusions sections of a randomly selected sample of 500 PubMed abstracts\nand 140 PubMed abstracts from the existing EBM-NLP corpus. This resulted in\nEvidenceOutcomes with high-quality annotations of an inter-rater agreement of\n0.76. Additionally, our fine-tuned PubMedBERT model, applied to these 500\nPubMed abstracts, achieved an F1-score of 0.69 at the entity level and 0.76 at\nthe token level on the subset of 140 PubMed abstracts from the EBM-NLP corpus.\nEvidenceOutcomes can serve as a shared benchmark to develop and test future\nmachine learning algorithms to extract clinically meaningful outcomes from\nbiomedical abstracts.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05380v1", "AI": {"title_translation": "临床试验出版物中具有临床意义结果的数据集：EvidenceOutcomes", "tldr": "创建了一个名为 EvidenceOutcomes 的大型带注释数据集，用于从生物医学文献中提取具有临床意义的结果，并展示了其作为基准的潜力。", "motivation": "循证医学中，PICO元素中的“结果”是最复杂的元素，但在现有基准中常被忽视或过度简化，这限制了证据提取和综合的完整性。", "method": "1. 与临床医生和自然语言处理专家迭代讨论，开发了用于提取具有临床意义结果的鲁棒注释指南。2. 三名独立注释员对随机选取的500篇PubMed摘要和来自现有EBM-NLP语料库的140篇PubMed摘要的“结果”和“结论”部分进行了注释。3. 应用微调的PubMedBERT模型对这500篇PubMed摘要进行测试。", "result": "1. 成功创建了EvidenceOutcomes数据集，其高质量注释的注释者间一致性（IRA）达到0.76。2. 微调的PubMedBERT模型在实体级别达到0.69的F1分数，在token级别达到0.76的F1分数（在EBM-NLP语料库的140篇PubMed摘要子集上）。", "conclusion": "EvidenceOutcomes数据集可以作为一个共享基准，用于开发和测试未来从生物医学摘要中提取具有临床意义结果的机器学习算法。", "translation": "循证医学中证据提取和综合的基本过程涉及从生物医学文献中提取PICO（人群、干预、比较和结果）元素。然而，作为最复杂元素的“结果”在现有基准中经常被忽视或过度简化。为了解决这个问题，我们提出了EvidenceOutcomes，这是一个新颖的、大型的、带注释的语料库，其中包含从生物医学文献中提取的具有临床意义的结果。我们首先通过与临床医生和自然语言处理专家迭代讨论，开发了提取文本中具有临床意义结果的鲁棒注释指南。然后，三名独立注释员对随机选择的500篇PubMed摘要和来自现有EBM-NLP语料库的140篇PubMed摘要的“结果”和“结论”部分进行了注释。这产生了EvidenceOutcomes数据集，其高质量注释的注释者间一致性达到0.76。此外，我们应用于这500篇PubMed摘要的微调PubMedBERT模型，在实体级别达到了0.69的F1分数，在token级别达到了0.76的F1分数（在EBM-NLP语料库的140篇PubMed摘要子集上）。EvidenceOutcomes可以作为一个共享基准，用于开发和测试未来从生物医学摘要中提取具有临床意义结果的机器学习算法。", "summary": "本文介绍了EvidenceOutcomes，一个新颖的大型带注释语料库，旨在解决现有基准中对临床试验出版物中“结果”元素提取的不足。通过与临床医生和NLP专家合作，开发了详细的注释指南，并由多名注释员对PubMed摘要进行标注，实现了高注释质量和0.76的注释者间一致性。此外，微调的PubMedBERT模型在该数据集上取得了可观的性能。EvidenceOutcomes有望成为未来机器学习算法提取临床意义结果的共享基准。", "keywords": "临床试验, 数据集, 结果提取, 循证医学, 自然语言处理", "comments": "这项工作通过创建一个专门针对临床意义结果的大型高质量数据集，填补了现有证据提取基准的空白。其严谨的注释指南开发过程和高注释者间一致性保证了数据集的可靠性。该数据集的发布及其作为基准的潜力，将极大地推动从生物医学文本中自动化提取复杂临床结果的机器学习研究。"}}
{"id": "2506.05734", "title": "There's Waldo: PCB Tamper Forensic Analysis using Explainable AI on Impedance Signatures", "authors": ["Maryam Saadat Safa", "Seyedmohammad Nouraniboosjin", "Fatemeh Ganji", "Shahin Tajik"], "summary": "The security of printed circuit boards (PCBs) has become increasingly vital\nas supply chain vulnerabilities, including tampering, present significant risks\nto electronic systems. While detecting tampering on a PCB is the first step for\nverification, forensics is also needed to identify the modified component. One\nnon-invasive and reliable PCB tamper detection technique with global coverage\nis the impedance characterization of a PCB's power delivery network (PDN).\nHowever, it is an open question whether one can use the two-dimensional\nimpedance signatures for forensics purposes. In this work, we introduce a novel\nPCB forensics approach using explainable AI (XAI) on impedance signatures.\nThrough extensive experiments, we replicate various PCB tamper events,\ngenerating a dataset used to develop an XAI algorithm capable of not only\ndetecting tampering but also explaining why the algorithm makes a decision\nabout whether a tamper event has happened. At the core of our XAI algorithm is\na random forest classifier with an accuracy of 96.7%, sufficient to explain the\nalgorithm's decisions. To understand the behavior of the classifier in the\ndecision-making process, we utilized SHAP values as an XAI tool to determine\nwhich frequency component influences the classifier's decision for a particular\nclass the most. This approach enhances detection capabilities as well as\nadvancing the verifier's ability to reverse-engineer and analyze\ntwo-dimensional impedance signatures for forensics.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05734v1", "AI": {"title_translation": "PCB篡改取证分析：基于阻抗特征的可解释AI", "tldr": "本文提出一种新颖的基于可解释AI（XAI）的PCB篡改取证方法，利用阻抗特征识别被篡改的组件，并通过SHAP值解释AI决策。", "motivation": "印刷电路板（PCB）在供应链中面临篡改风险，而现有技术虽能检测篡改，但无法进行取证以识别被修改的组件。将二维阻抗特征用于取证仍是一个未解决的问题。", "method": "本文提出一种使用可解释AI（XAI）对阻抗特征进行PCB取证的新方法。通过复制多种PCB篡改事件生成数据集，开发了一个XAI算法（核心是随机森林分类器），该算法不仅能检测篡改，还能解释其决策。利用SHAP值作为XAI工具，确定哪些频率分量对分类器的决策影响最大。", "result": "所提出的随机森林分类器实现了96.7%的准确率。该方法增强了检测能力，并提高了验证者逆向工程和分析二维阻抗特征进行取证的能力。", "conclusion": "本文成功展示了利用可解释AI和阻抗特征进行PCB篡改取证的可行性，提供了高准确率的检测，并能解释AI的决策，从而提升了取证分析能力。", "translation": "印刷电路板（PCB）的安全性变得越来越重要，因为包括篡改在内的供应链漏洞对电子系统构成了重大风险。虽然检测PCB上的篡改是验证的第一步，但还需要取证来识别被修改的组件。一种非侵入式、可靠且具有全球覆盖范围的PCB篡改检测技术是PCB电源传输网络（PDN）的阻抗特性。然而，是否可以将二维阻抗特征用于取证目的仍是一个悬而未决的问题。在这项工作中，我们引入了一种新颖的PCB取证方法，该方法在阻抗特征上使用可解释AI（XAI）。通过广泛的实验，我们复制了各种PCB篡改事件，生成了一个数据集，用于开发一个XAI算法，该算法不仅能够检测篡改，还能解释算法为何做出篡改事件是否发生的决定。我们XAI算法的核心是一个随机森林分类器，其准确率为96.7%，足以解释算法的决策。为了理解分类器在决策过程中的行为，我们利用SHAP值作为XAI工具，以确定哪个频率分量对特定类别的分类器决策影响最大。这种方法增强了检测能力，并提高了验证者逆向工程和分析二维阻抗特征以进行取证的能力。", "summary": "本文针对PCB供应链中日益增长的篡改风险，提出了一种新颖的基于阻抗特征的可解释AI（XAI）取证方法。该方法通过复制篡改事件构建数据集，并开发了一个以随机森林分类器为核心的XAI算法，实现了96.7%的准确率。该算法不仅能有效检测篡改，还能利用SHAP值解释其决策，从而识别被修改的组件并增强取证能力。", "keywords": "PCB篡改, 取证分析, 可解释AI, 阻抗特征, 随机森林, SHAP值", "comments": "这项工作在PCB安全领域具有重要意义，尤其是在供应链安全日益受到关注的背景下。其创新点在于将可解释AI引入PCB篡改取证，解决了传统检测方法无法识别具体篡改组件的痛点。通过提供决策解释，增强了AI的透明度和可信度，有助于安全专家进行更深入的分析和逆向工程。"}}
{"id": "2506.05648", "title": "A Modular Haptic Display with Reconfigurable Signals for Personalized Information Transfer", "authors": ["Antonio Alvarez Valdivia", "Benjamin A. Christie", "Dylan P. Losey", "Laura H. Blumenschein"], "summary": "We present a customizable soft haptic system that integrates modular hardware\nwith an information-theoretic algorithm to personalize feedback for different\nusers and tasks. Our platform features modular, multi-degree-of-freedom\npneumatic displays, where different signal types, such as pressure, frequency,\nand contact area, can be activated or combined using fluidic logic circuits.\nThese circuits simplify control by reducing reliance on specialized electronics\nand enabling coordinated actuation of multiple haptic elements through a\ncompact set of inputs. Our approach allows rapid reconfiguration of haptic\nsignal rendering through hardware-level logic switching without rewriting code.\nPersonalization of the haptic interface is achieved through the combination of\nmodular hardware and software-driven signal selection. To determine which\ndisplay configurations will be most effective, we model haptic communication as\na signal transmission problem, where an agent must convey latent information to\nthe user. We formulate the optimization problem to identify the haptic hardware\nsetup that maximizes the information transfer between the intended message and\nthe user's interpretation, accounting for individual differences in\nsensitivity, preferences, and perceptual salience. We evaluate this framework\nthrough user studies where participants interact with reconfigurable displays\nunder different signal combinations. Our findings support the role of\nmodularity and personalization in creating multimodal haptic interfaces and\nadvance the development of reconfigurable systems that adapt with users in\ndynamic human-machine interaction contexts.", "comment": "This work has been submitted to the IEEE Transactions on Haptics for\n  possible publication", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05648v1", "AI": {"title_translation": "可重构信号的模块化触觉显示器，用于个性化信息传输", "tldr": "本文提出了一种模块化、可定制的软触觉系统，通过结合模块化硬件和信息论算法，实现个性化的触觉反馈，并支持快速配置和优化信息传输。", "motivation": "开发一种可定制的软触觉系统，能够为不同用户和任务提供个性化反馈，同时简化控制、减少对专用电子设备的依赖，并实现触觉信号渲染的快速重配置，以最大化信息传输效率。", "method": "该系统集成了模块化硬件和信息论算法。硬件部分采用模块化、多自由度气动显示器，通过流体逻辑电路激活或组合不同信号类型（如压力、频率、接触面积），实现多触觉元素的协调驱动和硬件层面的逻辑切换。软件部分将触觉通信建模为信号传输问题，并通过优化问题确定最大化信息传输的触觉硬件设置，考虑个体差异。", "result": "用户研究评估了该框架，结果支持模块化和个性化在创建多模态触觉界面中的作用，并推动了适应动态人机交互中用户的可重构系统的发展。", "conclusion": "模块化和个性化对于创建多模态触觉界面至关重要，并且有助于开发在动态人机交互环境中适应用户的可重构系统。", "translation": "我们提出了一种可定制的软触觉系统，该系统将模块化硬件与信息论算法相结合，为不同用户和任务提供个性化反馈。我们的平台具有模块化、多自由度气动显示器，其中不同的信号类型，例如压力、频率和接触面积，可以通过流体逻辑电路激活或组合。这些电路通过减少对专用电子设备的依赖并实现通过一组紧凑的输入对多个触觉元件的协调驱动来简化控制。我们的方法允许通过硬件级逻辑切换快速重新配置触觉信号渲染，而无需重写代码。触觉界面的个性化是通过模块化硬件和软件驱动的信号选择相结合来实现的。为了确定哪种显示配置最有效，我们将触觉通信建模为信号传输问题，其中代理必须向用户传达潜在信息。我们制定了优化问题，以确定最大化预期消息和用户解释之间信息传输的触觉硬件设置，同时考虑敏感度、偏好和感知显著性方面的个体差异。我们通过用户研究评估了该框架，参与者在不同信号组合下与可重构显示器进行交互。我们的发现支持模块化和个性化在创建多模态触觉界面中的作用，并推动了在动态人机交互环境中适应用户的可重构系统的发展。", "summary": "本文介绍了一种可定制的软触觉系统，该系统将模块化硬件与信息论算法相结合，为不同用户和任务提供个性化反馈。该平台采用模块化、多自由度气动显示器，通过流体逻辑电路实现信号类型（如压力、频率、接触面积）的激活或组合，从而简化控制并支持快速硬件级重配置。通过将触觉通信建模为信息传输问题，并优化硬件设置以最大化信息传输，实现了触觉界面的个性化。用户研究验证了该框架的有效性，强调了模块化和个性化在创建适应动态人机交互场景的可重构触觉界面中的重要性。", "keywords": "模块化触觉显示器, 可重构信号, 个性化信息传输, 气动显示, 信息论", "comments": "这项研究的创新之处在于将模块化硬件设计与信息论算法相结合，以实现触觉反馈的个性化和高效信息传输。通过使用流体逻辑电路减少对复杂电子设备的依赖，并允许硬件层面的快速重配置，大大提高了系统的灵活性和实用性。这一方法为未来可适应用户个体差异的智能人机交互系统提供了新的思路。"}}
{"id": "2506.05418", "title": "Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning", "authors": ["Kyungsoo Kim", "Jeongsoo Ha", "Yusung Kim"], "summary": "Vision-based reinforcement learning requires efficient and robust\nrepresentations of image-based observations, especially when the images contain\ndistracting (task-irrelevant) elements such as shadows, clouds, and light. It\nbecomes more important if those distractions are not exposed during training.\nWe design a Self-Predictive Dynamics (SPD) method to extract task-relevant\nfeatures efficiently, even in unseen observations after training. SPD uses weak\nand strong augmentations in parallel, and learns representations by predicting\ninverse and forward transitions across the two-way augmented versions. In a set\nof MuJoCo visual control tasks and an autonomous driving task (CARLA), SPD\noutperforms previous studies in complex observations, and significantly\nimproves the generalization performance for unseen observations. Our code is\navailable at https://github.com/unigary/SPD.", "comment": "IJCAI 2022", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05418v1", "AI": {"title_translation": "视觉强化学习泛化的自预测动力学", "tldr": "提出自预测动力学(SPD)方法，通过预测增强图像间的转换来学习表示，有效提高视觉强化学习在复杂和未见干扰下的泛化能力。", "motivation": "视觉强化学习需要高效鲁棒的图像表示，尤其当图像包含分散注意力的（与任务无关的）元素（如阴影、云、光），且这些干扰在训练中未出现时，这变得更为重要。", "method": "设计了自预测动力学（SPD）方法，并行使用弱增强和强增强，通过预测两种增强版本之间的逆向和正向转换来学习表示，从而有效提取任务相关特征。", "result": "在MuJoCo视觉控制任务和CARLA自动驾驶任务中，SPD在复杂观测下优于现有研究，并显著提高了对未见观测的泛化性能。", "conclusion": "SPD方法能够有效提取任务相关特征，显著提升视觉强化学习在复杂和未见干扰下的泛化能力。", "translation": "视觉强化学习需要高效且鲁棒的基于图像的观测表示，尤其当图像包含分散注意力的（与任务无关的）元素（如阴影、云和光）时更是如此。如果这些干扰在训练期间没有暴露，这一点变得更加重要。我们设计了一种自预测动力学（SPD）方法，即使在训练后未见的观测中也能有效提取任务相关特征。SPD并行使用弱增强和强增强，并通过预测两种增强版本之间的逆向和正向转换来学习表示。在一系列MuJoCo视觉控制任务和自动驾驶任务（CARLA）中，SPD在复杂观测下优于之前的研究，并显著提高了对未见观测的泛化性能。我们的代码可在https://github.com/unigary/SPD获取。", "summary": "本文提出了一种名为自预测动力学（SPD）的新方法，旨在解决视觉强化学习中图像表示的泛化问题，尤其是在面对未曾训练过的分散注意力元素时。SPD通过并行应用弱增强和强增强，并学习预测这两种增强版本之间的逆向和正向转换来提取任务相关特征。实验结果表明，在MuJoCo和CARLA任务中，SPD在复杂观测下表现优异，并显著提升了对未见观测的泛化能力。", "keywords": "视觉强化学习, 自预测动力学, 泛化, 图像表示, 数据增强", "comments": "该研究通过引入自预测动力学（SPD）方法，有效解决了视觉强化学习在复杂和未见干扰下泛化能力不足的关键问题。其创新点在于利用弱增强和强增强并行预测图像转换来学习鲁棒表示，这对于实际应用中图像多样性带来的挑战具有重要意义。"}}
{"id": "2303.14005", "title": "Category Query Learning for Human-Object Interaction Classification", "authors": ["Chi Xie", "Fangao Zeng", "Yue Hu", "Shuang Liang", "Yichen Wei"], "summary": "Unlike most previous HOI methods that focus on learning better human-object\nfeatures, we propose a novel and complementary approach called category query\nlearning. Such queries are explicitly associated to interaction categories,\nconverted to image specific category representation via a transformer decoder,\nand learnt via an auxiliary image-level classification task. This idea is\nmotivated by an earlier multi-label image classification method, but is for the\nfirst time applied for the challenging human-object interaction classification\ntask. Our method is simple, general and effective. It is validated on three\nrepresentative HOI baselines and achieves new state-of-the-art results on two\nbenchmarks.", "comment": "Accepted by CVPR 2023", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2303.14005v1", "AI": {"title_translation": "类别查询学习用于人-物交互分类", "tldr": "本文提出了一种新颖的类别查询学习方法，用于人-物交互分类，通过将查询与交互类别关联并使用Transformer解码器学习，在两个基准测试中取得了最先进的结果。", "motivation": "以往的人-物交互（HOI）方法主要关注学习更好的人-物特征。本文提出类别查询学习，作为一种新颖且互补的方法，以解决HOI分类任务。", "method": "本文提出了一种新颖的类别查询学习方法。这种查询明确地与交互类别关联，通过Transformer解码器转换为图像特定的类别表示，并通过辅助的图像级分类任务进行学习。该方法首次应用于人-物交互分类任务，其灵感来源于早期的多标签图像分类方法。", "result": "该方法在三个代表性的人-物交互基线上进行了验证，并在两个基准测试中取得了新的最先进结果。", "conclusion": "本文提出的类别查询学习方法简单、通用且有效，在人-物交互分类任务中取得了显著的性能提升。", "translation": "与大多数以前专注于学习更好的人-物特征的HOI方法不同，我们提出了一种新颖且互补的方法，称为类别查询学习。这些查询明确地与交互类别相关联，通过Transformer解码器转换为图像特定的类别表示，并通过辅助的图像级分类任务进行学习。这个想法受到早期多标签图像分类方法的启发，但首次应用于具有挑战性的人-物交互分类任务。我们的方法简单、通用且有效。它在三个代表性HOI基线上得到了验证，并在两个基准测试中取得了新的最先进结果。", "summary": "本文提出了一种新颖的类别查询学习（Category Query Learning）方法，旨在改进人-物交互（HOI）分类。与以往侧重于特征学习的方法不同，该方法将查询与交互类别明确关联，并通过Transformer解码器将其转化为图像特定的类别表示，再通过辅助的图像级分类任务进行学习。该方法简单、通用且有效，已在三个HOI基线上验证，并在两个基准测试中达到了最先进的性能。", "keywords": "类别查询学习, 人-物交互分类, Transformer, 图像级分类, HOI", "comments": "该论文的创新点在于提出了一种不同于传统特征学习的互补方法——类别查询学习，并将其首次应用于复杂的人-物交互分类任务。通过引入类别查询和Transformer解码器，该方法提供了一种新颖的视角来处理HOI分类，并取得了显著的SOTA结果，显示出其潜力和通用性。"}}
{"id": "2506.05568", "title": "Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning", "authors": ["Arian Raje", "Baris Askin", "Divyansh Jhunjhunwala", "Gauri Joshi"], "summary": "Large language models (LLMs) have not yet effectively leveraged the vast\namounts of edge-device data, and federated learning (FL) offers a promising\nparadigm to collaboratively fine-tune LLMs without transferring private edge\ndata to the cloud. To operate within the computation and communication\nconstraints of edge devices, recent literature on federated fine-tuning of LLMs\nproposes the use of low-rank adaptation (LoRA) and similar parameter-efficient\nmethods. However, LoRA-based methods suffer from accuracy degradation in FL\nsettings, primarily because of data and computational heterogeneity across\nclients. We propose \\textsc{Ravan}, an adaptive multi-head LoRA method that\nbalances parameter efficiency and model expressivity by reparameterizing the\nweight updates as the sum of multiple LoRA heads\n$s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$ in which only the core matrices\n$\\textbf{H}_i$ and their lightweight scaling factors $s_i$ are trained. These\ntrainable scaling factors let the optimization focus on the most useful heads,\nrecovering a higher-rank approximation of the full update without increasing\nthe number of communicated parameters since clients upload $s_i\\textbf{H}_i$\ndirectly. Experiments on vision and language benchmarks show that\n\\textsc{Ravan} improves test accuracy by 2-8\\% over prior parameter-efficient\nbaselines, making it a robust and scalable solution for federated fine-tuning\nof LLMs.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05568v1", "AI": {"title_translation": "Ravan：面向联邦微调的多头低秩适应", "tldr": "Ravan是一种新的多头低秩适应方法，解决了联邦学习中LoRA微调的精度下降问题，在视觉和语言任务上显著提高了性能。", "motivation": "大型语言模型（LLMs）尚未有效利用边缘设备数据。联邦学习（FL）提供了一种在不传输私有边缘数据的情况下协同微调LLMs的范式。然而，现有的基于低秩适应（LoRA）的方法在FL设置中面临精度下降问题，这主要是由于客户端之间的数据和计算异构性。", "method": "提出了一种自适应多头低秩适应（LoRA）方法，名为\\textsc{Ravan}。该方法通过将权重更新重新参数化为多个LoRA头的总和（$s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$），在参数效率和模型表达能力之间取得平衡。其中，只有核心矩阵$\\textbf{H}_i$及其轻量级缩放因子$s_i$被训练。这些可训练的缩放因子使得优化能够聚焦于最有用的头部，从而在不增加通信参数数量的情况下恢复更高秩的近似更新，因为客户端直接上传$s_i\\textbf{H}_i$。", "result": "在视觉和语言基准测试中，\\textsc{Ravan}相比于之前的参数高效基线方法，测试精度提高了2-8%。", "conclusion": "\\textsc{Ravan}是LLMs联邦微调的一种鲁棒且可扩展的解决方案。", "translation": "大型语言模型（LLMs）尚未有效利用大量的边缘设备数据，而联邦学习（FL）提供了一种有前景的范式，可以在不将私有边缘数据传输到云端的情况下协同微调LLMs。为了在边缘设备的计算和通信限制内运行，最近关于LLMs联邦微调的文献提出了使用低秩适应（LoRA）和类似的参数高效方法。然而，基于LoRA的方法在FL设置中存在精度下降问题，这主要是由于客户端之间的数据和计算异构性。我们提出了\\textsc{Ravan}，一种自适应多头LoRA方法，通过将权重更新重新参数化为多个LoRA头$s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$的总和来平衡参数效率和模型表达能力，其中只有核心矩阵$\\textbf{H}_i$及其轻量级缩放因子$s_i$被训练。这些可训练的缩放因子使得优化能够聚焦于最有用的头部，从而在不增加通信参数数量的情况下恢复更高秩的近似更新，因为客户端直接上传$s_i\\textbf{H}_i$。在视觉和语言基准测试中的实验表明，\\textsc{Ravan}比之前的参数高效基线方法提高了2-8%的测试精度，使其成为LLMs联邦微调的一种鲁棒且可扩展的解决方案。", "summary": "本文提出了一种名为\\textsc{Ravan}的自适应多头低秩适应（LoRA）方法，旨在解决联邦学习（FL）环境下LLMs微调中LoRA方法因数据和计算异构性导致的精度下降问题。\\textsc{Ravan}通过重新参数化权重更新为多个LoRA头的总和，并仅训练核心矩阵和可训练的缩放因子，实现了参数效率与模型表达能力的平衡。实验结果表明，在视觉和语言基准测试中，\\textsc{Ravan}比现有参数高效基线方法的测试精度提高了2-8%，证明了其作为LLMs联邦微调的鲁棒且可扩展的解决方案的有效性。", "keywords": "联邦学习, 低秩适应, 大语言模型, 参数高效, 多头", "comments": "Ravan的创新之处在于引入了多头LoRA架构和可训练的缩放因子，这有效地解决了联邦学习中LoRA的精度瓶颈，同时保持了参数效率。通过仅上传$s_i\\textbf{H}_i$，该方法在通信效率上也有显著优势，使其非常适合资源受限的边缘设备。"}}
{"id": "2506.05739", "title": "To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt", "authors": ["Zhilong Wang", "Neha Nagaraja", "Lan Zhang", "Hayretdin Bahsi", "Pawan Patil", "Peng Liu"], "summary": "LLM agents are widely used as agents for customer support, content\ngeneration, and code assistance. However, they are vulnerable to prompt\ninjection attacks, where adversarial inputs manipulate the model's behavior.\nTraditional defenses like input sanitization, guard models, and guardrails are\neither cumbersome or ineffective. In this paper, we propose a novel,\nlightweight defense mechanism called Polymorphic Prompt Assembling (PPA), which\nprotects against prompt injection with near-zero overhead. The approach is\nbased on the insight that prompt injection requires guessing and breaking the\nstructure of the system prompt. By dynamically varying the structure of system\nprompts, PPA prevents attackers from predicting the prompt structure, thereby\nenhancing security without compromising performance. We conducted experiments\nto evaluate the effectiveness of PPA against existing attacks and compared it\nwith other defense methods.", "comment": "To appear in the Industry Track of the 55th Annual IEEE/IFIP\n  International Conference on Dependable Systems and Networks (DSN 2025)", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05739v1", "AI": {"title_translation": "使用多态提示保护LLM代理免受提示注入攻击", "tldr": "LLM代理易受提示注入攻击，本文提出一种轻量级防御机制PPA，通过动态改变系统提示结构来防止攻击，且开销接近于零。", "motivation": "LLM代理广泛应用但易受提示注入攻击，传统防御机制笨重或无效，需要一种新型轻量级防御机制。", "method": "提出多态提示组装（PPA）机制，通过动态改变系统提示的结构，使攻击者无法预测提示结构，从而增强安全性。", "result": "实验评估了PPA对抗现有攻击的有效性，并将其与其他防御方法进行了比较。", "conclusion": "PPA能有效保护LLM代理免受提示注入攻击，且性能开销极低。", "translation": "LLM代理被广泛用作客户支持、内容生成和代码辅助的代理。然而，它们容易受到提示注入攻击，即对抗性输入操纵模型行为。传统的防御措施，如输入清理、守卫模型和护栏，要么繁琐，要么无效。在本文中，我们提出了一种新颖、轻量级的防御机制，称为多态提示组装（PPA），它以接近零的开销来防止提示注入。该方法基于提示注入需要猜测和破坏系统提示结构的见解。通过动态改变系统提示的结构，PPA阻止攻击者预测提示结构，从而在不影响性能的情况下增强安全性。我们进行了实验，评估了PPA对抗现有攻击的有效性，并将其与其他防御方法进行了比较。", "summary": "本文提出一种名为多态提示组装（PPA）的新型轻量级防御机制，旨在保护LLM代理免受提示注入攻击。PPA通过动态改变系统提示的结构，使攻击者难以预测和破坏提示结构，从而有效增强安全性。实验证明PPA在对抗现有攻击方面表现良好，且对性能影响极小。", "keywords": "LLM代理, 提示注入, 多态提示, 安全, PPA", "comments": "PPA的创新之处在于其“多态”思想，通过动态变化提示结构来对抗攻击，这比静态防御更具鲁棒性。其轻量级和接近零开销的特点也使其具有实际应用价值。"}}
{"id": "2506.05719", "title": "You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping", "authors": ["Jingshun Huang", "Haitao Lin", "Tianyu Wang", "Yanwei Fu", "Yu-Gang Jiang", "Xiangyang Xue"], "summary": "This paper addresses the problem of category-level pose estimation for\narticulated objects in robotic manipulation tasks. Recent works have shown\npromising results in estimating part pose and size at the category level.\nHowever, these approaches primarily follow a complex multi-stage pipeline that\nfirst segments part instances in the point cloud and then estimates the\nNormalized Part Coordinate Space (NPCS) representation for 6D poses. These\napproaches suffer from high computational costs and low performance in\nreal-time robotic tasks. To address these limitations, we propose YOEO, a\nsingle-stage method that simultaneously outputs instance segmentation and NPCS\nrepresentations in an end-to-end manner. We use a unified network to generate\npoint-wise semantic labels and centroid offsets, allowing points from the same\npart instance to vote for the same centroid. We further utilize a clustering\nalgorithm to distinguish points based on their estimated centroid distances.\nFinally, we first separate the NPCS region of each instance. Then, we align the\nseparated regions with the real point cloud to recover the final pose and size.\nExperimental results on the GAPart dataset demonstrate the pose estimation\ncapabilities of our proposed single-shot method. We also deploy our\nsynthetically-trained model in a real-world setting, providing real-time visual\nfeedback at 200Hz, enabling a physical Kinova robot to interact with unseen\narticulated objects. This showcases the utility and effectiveness of our\nproposed method.", "comment": "To appear in ICRA 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05719v1", "AI": {"title_translation": "你只估计一次：统一、单阶段、实时类别级可动对象6D姿态估计用于机器人抓取", "tldr": "YOEO是一种统一的、单阶段、实时方法，用于机器人抓取中的类别级可动对象6D姿态估计，解决了传统多阶段方法的计算成本和实时性能问题。", "motivation": "现有方法在机器人操作任务中进行类别级可动对象姿态估计时，遵循复杂的多阶段流程，导致计算成本高昂且实时性能低下，不适用于实时机器人任务。", "method": "本文提出了YOEO，一种单阶段、端到端的方法，同时输出实例分割和标准化部件坐标空间（NPCS）表示。该方法使用统一网络生成点级语义标签和质心偏移，使得同一部件实例的点可以投票给同一个质心。通过聚类算法根据估计的质心距离区分点，然后分离每个实例的NPCS区域，并将其与真实点云对齐以恢复最终姿态和大小。", "result": "在GAPart数据集上的实验结果表明，所提出的单阶段方法具有强大的姿态估计能力。此外，合成训练的模型已部署到真实世界环境中，能够以200Hz的速度提供实时视觉反馈，使得Kinova机器人能够与未见过的可动对象进行交互。", "conclusion": "所提出的YOEO方法在机器人抓取任务中对类别级可动对象进行6D姿态估计方面表现出实用性和有效性。", "translation": "本文解决了机器人操作任务中可动对象的类别级姿态估计问题。最近的工作在估计类别级别的部件姿态和尺寸方面取得了可喜的成果。然而，这些方法主要遵循一个复杂的多阶段管道，首先在点云中分割部件实例，然后估计用于6D姿态的标准化部件坐标空间（NPCS）表示。这些方法在实时机器人任务中存在计算成本高和性能低的问题。为了解决这些限制，我们提出了YOEO，一种单阶段方法，以端到端的方式同时输出实例分割和NPCS表示。我们使用一个统一的网络来生成点级语义标签和质心偏移，允许来自同一部件实例的点投票给同一个质心。我们进一步利用聚类算法根据其估计的质心距离来区分点。最后，我们首先分离每个实例的NPCS区域。然后，我们将分离的区域与真实点云对齐以恢复最终的姿态和尺寸。GAPart数据集上的实验结果证明了我们提出的单次方法（single-shot method）的姿态估计能力。我们还在真实世界环境中部署了我们经过合成训练的模型，以200Hz的速度提供实时视觉反馈，使物理Kinova机器人能够与未见过的可动对象进行交互。这展示了我们提出的方法的实用性和有效性。", "summary": "针对机器人操作中类别级可动对象6D姿态估计现有方法计算成本高、实时性差的问题，本文提出了YOEO，一种统一的单阶段端到端方法。YOEO通过统一网络同时进行实例分割和NPCS表示学习，利用点级语义标签和质心偏移进行聚类，并最终通过区域对齐恢复姿态和尺寸。实验证明，该方法在GAPart数据集上表现出色，并能在真实世界中实现200Hz的实时反馈，有效支持机器人与未知可动对象的交互。", "keywords": "类别级姿态估计, 可动对象, 实时, 单阶段, 机器人抓取", "comments": "YOEO的创新之处在于其统一的单阶段设计，显著简化了传统多阶段姿态估计算法的复杂性，并大幅提升了实时性能。这对于需要高效率和低延迟的机器人抓取等实际应用具有重要意义。其在真实世界部署并实现高频实时反馈的能力，进一步验证了该方法的实用性和鲁棒性。"}}
{"id": "2506.05419", "title": "Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions", "authors": ["Jeongsoo Ha", "Kyungsoo Kim", "Yusung Kim"], "summary": "Model-based reinforcement learning (MBRL) has been used to efficiently solve\nvision-based control tasks in highdimensional image observations. Although\nrecent MBRL algorithms perform well in trained observations, they fail when\nfaced with visual distractions in observations. These task-irrelevant\ndistractions (e.g., clouds, shadows, and light) may be constantly present in\nreal-world scenarios. In this study, we propose a novel self-supervised method,\nDream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and\nworld model with dual contrastive learning which efficiently captures\ntask-relevant features among multi-view data augmentations. We also introduce a\nrecurrent state inverse dynamics model that helps the world model to better\nunderstand the temporal structure. The proposed methods can enhance the\nrobustness of the world model against visual distractions. To evaluate the\ngeneralization performance, we first train Dr. G on simple backgrounds and then\ntest it on complex natural video backgrounds in the DeepMind Control suite, and\nthe randomizing environments in Robosuite. Dr. G yields a performance\nimprovement of 117% and 14% over prior works, respectively. Our code is\nopen-sourced and available at https://github.com/JeongsooHa/DrG.git", "comment": "AAAI 2023", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05419v1", "AI": {"title_translation": "梦想泛化：零样本模型基强化学习应对未见过的视觉干扰", "tldr": "提出了一种名为Dr. G的新型自监督方法，通过双重对比学习和循环状态逆动力学模型，显著提高了模型基强化学习在面对视觉干扰时的泛化能力。", "motivation": "尽管模型基强化学习（MBRL）在训练过的观测中表现良好，但当面对视觉干扰（如云、阴影和光线）时，它们会失败，而这些干扰在现实世界场景中可能持续存在，这限制了MBRL在实际应用中的泛化能力。", "method": "本研究提出了一种新颖的自监督方法，名为“梦想泛化”（Dr. G），用于零样本模型基强化学习。Dr. G通过双重对比学习训练其编码器和世界模型，以有效捕获多视图数据增强中的任务相关特征。此外，还引入了一个循环状态逆动力学模型，帮助世界模型更好地理解时间结构，从而增强了世界模型对抗视觉干扰的鲁棒性。", "result": "为了评估泛化性能，Dr. G首先在简单背景下进行训练，然后在DeepMind Control套件的复杂自然视频背景和Robosuite的随机化环境中进行测试。结果显示，Dr. G分别比现有工作性能提高了117%和14%。", "conclusion": "本研究提出的方法（Dr. G）能够增强世界模型对抗视觉干扰的鲁棒性，并在零样本泛化任务中取得了显著的性能提升，证明了其在处理现实世界视觉干扰方面的有效性。", "translation": "模型基强化学习（MBRL）已被用于有效解决高维图像观测中的基于视觉的控制任务。尽管最近的MBRL算法在训练过的观测中表现良好，但当面对观测中的视觉干扰时，它们会失败。这些与任务无关的干扰（例如云、阴影和光线）可能在现实世界场景中持续存在。在本研究中，我们提出了一种新颖的自监督方法，梦想泛化（Dr. G），用于零样本MBRL。Dr. G通过双重对比学习训练其编码器和世界模型，该方法能有效捕获多视图数据增强中的任务相关特征。我们还引入了一个循环状态逆动力学模型，帮助世界模型更好地理解时间结构。所提出的方法可以增强世界模型对抗视觉干扰的鲁棒性。为了评估泛化性能，我们首先在简单背景上训练Dr. G，然后在DeepMind Control套件的复杂自然视频背景和Robosuite的随机化环境中对其进行测试。Dr. G分别比现有工作性能提高了117%和14%。我们的代码已开源，可在https://github.com/JeongsooHa/DrG.git获取。", "summary": "本研究提出了一种名为“梦想泛化”（Dr. G）的新型自监督方法，旨在解决模型基强化学习（MBRL）在面对未见过的视觉干扰时泛化能力不足的问题。Dr. G通过双重对比学习训练编码器和世界模型以捕获任务相关特征，并引入循环状态逆动力学模型来增强对时间结构的理解。实验结果表明，Dr. G在复杂视觉背景下的零样本泛化任务中，性能分别比现有方法提升了117%和14%，显著增强了世界模型应对视觉干扰的鲁棒性。", "keywords": "模型基强化学习, 零样本, 视觉干扰, 泛化, 对比学习", "comments": "这项研究的创新之处在于其提出的Dr. G方法，它通过结合自监督学习、双重对比学习和循环状态逆动力学模型，有效解决了MBRL在现实世界中面临视觉干扰时的泛化难题。其零样本泛化的能力对于实际部署具有重要意义，因为它可以减少对大量特定环境数据的依赖。性能显著提升（117%和14%）也凸显了该方法的有效性。"}}
{"id": "2506.05171", "title": "Towards provable probabilistic safety for scalable embodied AI systems", "authors": ["Linxuan He", "Qing-Shan Jia", "Ang Li", "Hongyan Sang", "Ling Wang", "Jiwen Lu", "Tao Zhang", "Jie Zhou", "Yi Zhang", "Yisen Wang", "Peng Wei", "Zhongyuan Wang", "Henry X. Liu", "Shuo Feng"], "summary": "Embodied AI systems, comprising AI models and physical plants, are\nincreasingly prevalent across various applications. Due to the rarity of system\nfailures, ensuring their safety in complex operating environments remains a\nmajor challenge, which severely hinders their large-scale deployment in\nsafety-critical domains, such as autonomous vehicles, medical devices, and\nrobotics. While achieving provable deterministic safety--verifying system\nsafety across all possible scenarios--remains theoretically ideal, the rarity\nand complexity of corner cases make this approach impractical for scalable\nembodied AI systems. To address this challenge, we introduce provable\nprobabilistic safety, which aims to ensure that the residual risk of\nlarge-scale deployment remains below a predefined threshold. Instead of\nattempting exhaustive safety proof across all corner cases, this paradigm\nestablishes a probabilistic safety boundary on overall system performance,\nleveraging statistical methods to enhance feasibility and scalability. A\nwell-defined probabilistic safety boundary enables embodied AI systems to be\ndeployed at scale while allowing for continuous refinement of safety\nguarantees. Our work focuses on three core questions: what is provable\nprobabilistic safety, how to prove the probabilistic safety, and how to achieve\nthe provable probabilistic safety. By bridging the gap between theoretical\nsafety assurance and practical deployment, our work offers a pathway toward\nsafer, large-scale adoption of embodied AI systems in safety-critical\napplications.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05171v1", "AI": {"title_translation": "面向可扩展具身AI系统的可证明概率安全", "tldr": "本文提出可证明概率安全的概念，以解决具身AI系统在大规模部署中难以确保安全性的挑战，通过统计方法建立概率安全边界，从而实现安全的大规模应用。", "motivation": "具身AI系统在复杂操作环境中确保安全性是一个重大挑战，尤其是在自动驾驶、医疗设备和机器人等安全关键领域。由于系统故障的罕见性，可证明的确定性安全方法对于可扩展的具身AI系统来说不切实际，这严重阻碍了它们的大规模部署。", "method": "本文引入了可证明概率安全的概念，旨在确保大规模部署的残余风险低于预设阈值。该方法不尝试对所有极端情况进行穷尽的安全证明，而是利用统计方法在整体系统性能上建立概率安全边界，以增强可行性和可扩展性。研究集中回答了三个核心问题：什么是可证明概率安全、如何证明概率安全以及如何实现概率安全。", "result": "通过弥合理论安全保证和实际部署之间的差距，该工作为具身AI系统在安全关键应用中更安全、大规模的采用提供了途径。", "conclusion": "可证明概率安全范式能够实现具身AI系统的大规模部署，同时允许持续完善安全保证，为安全关键应用中具身AI系统的广泛采用铺平道路。", "translation": "具身AI系统由AI模型和物理设备组成，在各种应用中越来越普及。由于系统故障的罕见性，在复杂操作环境中确保其安全性仍然是一个重大挑战，这严重阻碍了它们在自动驾驶、医疗设备和机器人等安全关键领域的大规模部署。虽然实现可证明的确定性安全——验证所有可能场景下的系统安全性——在理论上是理想的，但极端情况的罕见性和复杂性使得这种方法对于可扩展的具身AI系统来说不切实际。为了解决这一挑战，我们引入了可证明概率安全，旨在确保大规模部署的残余风险低于预设阈值。这种范式不尝试对所有极端情况进行穷尽的安全证明，而是利用统计方法在整体系统性能上建立概率安全边界，以增强可行性和可扩展性。明确定义的概率安全边界使得具身AI系统能够大规模部署，同时允许持续完善安全保证。我们的工作重点关注三个核心问题：什么是可证明概率安全，如何证明概率安全，以及如何实现可证明概率安全。通过弥合理论安全保证和实际部署之间的差距，我们的工作为具身AI系统在安全关键应用中更安全、大规模的采用提供了途径。", "summary": "本文针对具身AI系统在复杂环境中的安全性挑战，尤其是在安全关键领域大规模部署时面临的难题，提出了“可证明概率安全”的新范式。与不切实际的确定性安全不同，该方法利用统计手段，为系统整体性能设定概率安全边界，从而将残余风险控制在预设阈值以下，增强了安全验证的可行性和可扩展性。研究围绕可证明概率安全的定义、证明方法和实现路径展开，旨在促进具身AI系统在安全关键应用中的安全大规模部署。", "keywords": "具身AI, 概率安全, 可证明安全, 系统安全, 大规模部署", "comments": "本文提出了一种新颖且实用的安全验证方法，即“可证明概率安全”，以应对具身AI系统在大规模部署中面临的复杂性。其创新之处在于从确定性证明转向概率性证明，这对于处理罕见故障和复杂系统具有重要意义。该方法有望加速具身AI在自动驾驶、医疗等安全关键领域的落地，但具体实现细节和统计方法的有效性仍需进一步研究。"}}
{"id": "2506.05574", "title": "When can in-context learning generalize out of task distribution?", "authors": ["Chase Goddard", "Lindsay M. Smith", "Vudtiwat Ngampruetikorn", "David J. Schwab"], "summary": "In-context learning (ICL) is a remarkable capability of pretrained\ntransformers that allows models to generalize to unseen tasks after seeing only\na few examples. We investigate empirically the conditions necessary on the\npretraining distribution for ICL to emerge and generalize\n\\emph{out-of-distribution}. Previous work has focused on the number of distinct\ntasks necessary in the pretraining dataset. Here, we use a different notion of\ntask diversity to study the emergence of ICL in transformers trained on linear\nfunctions. We find that as task diversity increases, transformers undergo a\ntransition from a specialized solution, which exhibits ICL only within the\npretraining task distribution, to a solution which generalizes out of\ndistribution to the entire task space. We also investigate the nature of the\nsolutions learned by the transformer on both sides of the transition, and\nobserve similar transitions in nonlinear regression problems. We construct a\nphase diagram to characterize how our concept of task diversity interacts with\nthe number of pretraining tasks. In addition, we explore how factors such as\nthe depth of the model and the dimensionality of the regression problem\ninfluence the transition.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05574v1", "AI": {"title_translation": "上下文学习何时能泛化到任务分布之外？", "tldr": "该研究探讨了上下文学习（ICL）泛化到任务分布之外的条件，发现预训练时任务多样性增加会导致模型泛化到分布外，并分析了影响这一转变的因素。", "motivation": "探究预训练分布需要满足何种条件，才能使上下文学习（ICL）出现并泛化到分布之外。此前的研究侧重于预训练数据集中不同任务的数量，而本文则使用不同的任务多样性概念。", "method": "通过对线性函数上训练的Transformer进行实证研究，使用不同的任务多样性概念来研究ICL的出现。还研究了Transformer学习到的解决方案的性质，并在非线性回归问题中观察到类似的转变。构建了一个相图来描述任务多样性与预训练任务数量的相互作用，并探讨了模型深度和回归问题维度等因素的影响。", "result": "随着任务多样性的增加，Transformer会经历一个转变，从只能在预训练任务分布内进行ICL的专业化解决方案，转变为可以泛化到整个任务空间之外的解决方案。在非线性回归问题中也观察到类似的转变。模型深度和回归问题维度等因素会影响这种转变。", "conclusion": "增加任务多样性可以使上下文学习从特定领域泛化到任务分布之外。", "translation": "上下文学习（ICL）是预训练Transformer模型的一项显著能力，它允许模型在只看到少量示例后就能泛化到未见过的任务。我们实证研究了预训练分布需要满足何种条件，才能使ICL出现并泛化到分布之外。此前的研究侧重于预训练数据集中不同任务的数量。在此，我们使用不同的任务多样性概念来研究在训练于线性函数的Transformer中ICL的出现。我们发现，随着任务多样性的增加，Transformer会经历一个转变，从一个仅在预训练任务分布内表现出ICL的专业化解决方案，转变为一个可以泛化到整个任务空间之外的解决方案。我们还研究了Transformer在转变两侧学到的解决方案的性质，并在非线性回归问题中观察到类似的转变。我们构建了一个相图来表征我们的任务多样性概念如何与预训练任务的数量相互作用。此外，我们还探讨了模型深度和回归问题维度等因素如何影响这种转变。", "summary": "本文实证研究了上下文学习（ICL）泛化到任务分布之外所需的预训练条件。通过在训练于线性函数的Transformer上引入不同的任务多样性概念，研究发现，随着任务多样性的增加，模型会从仅在预训练分布内表现ICL转变为能够泛化到整个任务空间。研究还探讨了这种转变两侧学习到的解决方案的性质，并在非线性回归中观察到类似现象，同时分析了模型深度和问题维度等因素的影响，并构建了相图。", "keywords": "上下文学习, 分布外泛化, 任务多样性, Transformer, 预训练", "comments": "本文的创新点在于引入了“任务多样性”这一新概念来研究上下文学习（ICL）的分布外泛化能力，而非仅仅关注任务数量。这对于理解和提升ICL的泛化能力具有重要意义。研究通过相图和对模型深度、维度等因素的分析，为未来的模型预训练策略提供了新的视角。"}}
{"id": "2506.05740", "title": "FIST: A Structured Threat Modeling Framework for Fraud Incidents", "authors": ["Yu-Chen Dai", "Lu-An Chen", "Sy-Jye Her", "Yu-Xian Jiang"], "summary": "Fraudulent activities are rapidly evolving, employing increasingly diverse\nand sophisticated methods that pose serious threats to individuals,\norganizations, and society. This paper proposes the FIST Framework (Fraud\nIncident Structured Threat Framework), an innovative structured threat modeling\nmethodology specifically designed for fraud scenarios. Inspired by MITRE\nATT\\&CK and DISARM, FIST systematically incorporates social engineering\ntactics, stage-based behavioral decomposition, and detailed attack technique\nmapping into a reusable knowledge base. FIST aims to enhance the efficiency of\nfraud detection and the standardization of threat intelligence sharing,\npromoting collaboration and a unified language across organizations and\nsectors. The framework integrates interdisciplinary insights from\ncybersecurity, criminology, and behavioral science, addressing both technical\nvectors and psychological manipulation mechanisms in fraud. This approach\nenables fine-grained analysis of fraud incidents, supporting automated\ndetection, quantitative risk assessment, and standardized incident reporting.\nThe effectiveness of the framework is further validated through real-world case\nstudies, demonstrating its value in bridging academic research and practical\napplications, and laying the foundation for an intelligence-driven anti-fraud\necosystem. To the best of our knowledge, FIST is the first systematic,\nopen-source fraud threat modeling framework that unifies both technical and\npsychological aspects, and is made freely available to foster collaboration\nbetween academia and industry.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05740v1", "AI": {"title_translation": "FIST：一种欺诈事件结构化威胁建模框架", "tldr": "提出了FIST框架，一个用于欺诈事件的结构化威胁建模方法，整合技术和心理因素，旨在提升欺诈检测效率和威胁情报共享标准化。", "motivation": "欺诈活动迅速演变，方法日益多样和复杂，对个人、组织和社会构成严重威胁，因此需要一种专门针对欺诈场景的威胁建模方法。", "method": "本文提出了FIST框架（Fraud Incident Structured Threat Framework），这是一种专门为欺诈场景设计的创新结构化威胁建模方法。FIST受MITRE ATT\\&CK和DISARM的启发，系统地将社会工程策略、基于阶段的行为分解和详细的攻击技术映射到一个可重用的知识库中。该框架整合了网络安全、犯罪学和行为科学的跨学科见解，处理欺诈中的技术向量和心理操纵机制。", "result": "FIST旨在提高欺诈检测效率和威胁情报共享的标准化，促进组织和部门之间的协作和统一语言。它支持欺诈事件的细粒度分析、自动化检测、定量风险评估和标准化事件报告。该框架的有效性通过真实世界的案例研究得到验证，证明了其在连接学术研究和实际应用方面的价值，并为智能驱动的反欺诈生态系统奠定了基础。", "conclusion": "据作者所知，FIST是第一个系统化、开源的欺诈威胁建模框架，它统一了技术和心理方面，并免费提供以促进学术界和工业界之间的合作。", "translation": "欺诈活动正在迅速演变，采用日益多样和复杂的方法，对个人、组织和社会构成严重威胁。本文提出了FIST框架（欺诈事件结构化威胁框架），这是一种专门为欺诈场景设计的创新结构化威胁建模方法。受MITRE ATT\\&CK和DISARM的启发，FIST系统地将社会工程策略、基于阶段的行为分解和详细的攻击技术映射到一个可重用的知识库中。FIST旨在提高欺诈检测效率和威胁情报共享的标准化，促进组织和部门之间的协作和统一语言。该框架整合了网络安全、犯罪学和行为科学的跨学科见解，解决了欺诈中的技术向量和心理操纵机制。这种方法能够对欺诈事件进行细粒度分析，支持自动化检测、定量风险评估和标准化事件报告。通过真实世界的案例研究进一步验证了该框架的有效性，证明了其在连接学术研究和实际应用方面的价值，并为智能驱动的反欺诈生态系统奠定了基础。据我们所知，FIST是第一个系统化、开源的欺诈威胁建模框架，它统一了技术和心理方面，并免费提供以促进学术界和工业界之间的合作。", "summary": "本文提出了FIST框架，一个专门针对欺诈场景的创新结构化威胁建模方法。该框架借鉴MITRE ATT\\&CK和DISARM，整合了社会工程、行为分解和攻击技术映射，形成可重用知识库。FIST通过结合网络安全、犯罪学和行为科学的跨学科视角，全面处理欺诈中的技术和心理因素，旨在提升欺诈检测效率、标准化威胁情报共享，并支持细粒度分析、自动化检测和风险评估。通过真实案例验证，FIST被认为是首个统一技术与心理方面的系统化、开源欺诈威胁建模框架，有助于连接学术与实践。", "keywords": "欺诈威胁建模, FIST框架, 社会工程, 威胁情报共享, 反欺诈生态系统", "comments": "FIST框架的创新之处在于其首次系统地将欺诈中的技术和心理操纵机制相结合进行威胁建模，并提供开源可用性。其重要性体现在提升欺诈检测效率、标准化威胁情报共享以及促进跨领域合作，为构建智能驱动的反欺诈生态系统奠定基础。"}}
{"id": "2506.05780", "title": "Robust sensor fusion against on-vehicle sensor staleness", "authors": ["Meng Fan", "Yifan Zuo", "Patrick Blaes", "Harley Montgomery", "Subhasis Das"], "summary": "Sensor fusion is crucial for a performant and robust Perception system in\nautonomous vehicles, but sensor staleness, where data from different sensors\narrives with varying delays, poses significant challenges. Temporal\nmisalignment between sensor modalities leads to inconsistent object state\nestimates, severely degrading the quality of trajectory predictions that are\ncritical for safety. We present a novel and model-agnostic approach to address\nthis problem via (1) a per-point timestamp offset feature (for LiDAR and radar\nboth relative to camera) that enables fine-grained temporal awareness in sensor\nfusion, and (2) a data augmentation strategy that simulates realistic sensor\nstaleness patterns observed in deployed vehicles. Our method is integrated into\na perspective-view detection model that consumes sensor data from multiple\nLiDARs, radars and cameras. We demonstrate that while a conventional model\nshows significant regressions when one sensor modality is stale, our approach\nreaches consistently good performance across both synchronized and stale\nconditions.", "comment": "This paper has been accepted by CVPR 2025 Precognition Workshop", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05780v1", "AI": {"title_translation": "车载传感器数据陈旧性鲁棒传感器融合", "tldr": "提出了一种新颖的模型无关方法，通过逐点时间戳偏移特征和数据增强策略，解决了自动驾驶中传感器数据陈旧性导致的融合问题，并在同步和陈旧条件下均表现出良好性能。", "motivation": "自动驾驶汽车中，传感器数据陈旧性（不同传感器数据到达延迟不同）导致时间错位，进而导致物体状态估计不一致，严重降低轨迹预测质量，影响安全。", "method": "提出了一种新颖且模型无关的方法来解决传感器数据陈旧性问题：1) 引入逐点时间戳偏移特征（LiDAR和雷达相对于摄像机），以实现传感器融合中的细粒度时间感知；2) 采用数据增强策略，模拟部署车辆中观察到的真实传感器陈旧模式。该方法被集成到消费多LiDAR、雷达和摄像机传感器数据的透视检测模型中。", "result": "传统模型在一种传感器模态陈旧时性能显著下降，而我们的方法在同步和陈旧条件下均能达到持续良好的性能。", "conclusion": "Not mentioned in abstract", "translation": "传感器融合对于自动驾驶汽车中高性能和鲁棒的感知系统至关重要，但传感器数据陈旧性（不同传感器数据到达延迟不同）带来了重大挑战。传感器模态之间的时间错位导致物体状态估计不一致，严重降低了对安全至关重要的轨迹预测质量。我们提出了一种新颖且模型无关的方法来解决这个问题，通过 (1) 逐点时间戳偏移特征（LiDAR 和雷达均相对于摄像头）实现传感器融合中的细粒度时间感知，以及 (2) 一种数据增强策略，模拟部署车辆中观察到的真实传感器陈旧模式。我们的方法集成到一个透视检测模型中，该模型消耗来自多个 LiDAR、雷达和摄像头的传感器数据。我们证明，当一种传感器模态陈旧时，传统模型表现出显著的退步，而我们的方法在同步和陈旧条件下均能达到持续良好的性能。", "summary": "本论文提出了一种针对自动驾驶中传感器数据陈旧性问题的鲁棒传感器融合方法。针对不同传感器数据到达时间不一致导致的时间错位和轨迹预测质量下降问题，作者引入了逐点时间戳偏移特征和数据增强策略。该方法被集成到多传感器透视检测模型中，实验结果表明，与传统模型相比，该方法在传感器数据同步和陈旧两种情况下均能保持稳定的高性能。", "keywords": "传感器融合, 传感器陈旧性, 自动驾驶, 时间感知, 数据增强", "comments": "该论文的创新点在于提出了模型无关的逐点时间戳偏移特征和模拟真实传感器陈旧模式的数据增强策略，有效解决了自动驾驶中传感器数据时间错位导致的性能下降问题。其重要性体现在提升了自动驾驶感知系统的鲁棒性和安全性，尤其是在复杂和动态的真实世界部署环境中。"}}
{"id": "2506.05420", "title": "Self-supervised One-Stage Learning for RF-based Multi-Person Pose Estimation", "authors": ["Seunghwan Shin", "Yusung Kim"], "summary": "In the field of Multi-Person Pose Estimation (MPPE), Radio Frequency\n(RF)-based methods can operate effectively regardless of lighting conditions\nand obscured line-of-sight situations. Existing RF-based MPPE methods typically\ninvolve either 1) converting RF signals into heatmap images through complex\npreprocessing, or 2) applying a deep embedding network directly to raw RF\nsignals. The first approach, while delivering decent performance, is\ncomputationally intensive and time-consuming. The second method, though simpler\nin preprocessing, results in lower MPPE accuracy and generalization\nperformance. This paper proposes an efficient and lightweight one-stage MPPE\nmodel based on raw RF signals. By sub-grouping RF signals and embedding them\nusing a shared single-layer CNN followed by multi-head attention, this model\noutperforms previous methods that embed all signals at once through a large and\ndeep CNN. Additionally, we propose a new self-supervised learning (SSL) method\nthat takes inputs from both one unmasked subgroup and the remaining masked\nsubgroups to predict the latent representations of the masked data. Empirical\nresults demonstrate that our model improves MPPE accuracy by up to 15 in\nPCKh@0.5 compared to previous methods using raw RF signals. Especially, the\nproposed SSL method has shown to significantly enhance performance improvements\nwhen placed in new locations or in front of obstacles at RF antennas,\ncontributing to greater performance gains as the number of people increases.\nOur code and dataset is open at Github. https://github.com/sshnan7/SOSPE .", "comment": "CIKM 2024", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05420v1", "AI": {"title_translation": "基于射频的自监督一阶段多人姿态估计", "tldr": "本文提出了一种高效轻量级的基于原始射频信号的一阶段多人姿态估计模型，并引入了一种新的自监督学习方法，显著提高了在不同场景下的姿态估计精度。", "motivation": "现有的基于射频的多人姿态估计方法存在问题：1) 将射频信号转换为热图图像的方法计算量大且耗时；2) 直接将深度嵌入网络应用于原始射频信号的方法导致姿态估计精度和泛化性能较低。", "method": "本文提出了一种高效轻量级的一阶段多人姿态估计模型，直接处理原始射频信号。该模型通过对射频信号进行分组，并使用共享的单层CNN和多头注意力进行嵌入，优于之前通过大型深度CNN一次性嵌入所有信号的方法。此外，还提出了一种新的自监督学习（SSL）方法，该方法从一个未遮蔽的子组和剩余的遮蔽子组中获取输入，以预测遮蔽数据的潜在表示。", "result": "与之前使用原始射频信号的方法相比，该模型在PCKh@0.5上的多人姿态估计精度提高了15%。特别是，所提出的自监督学习方法在射频天线位于新位置或障碍物前时，显著增强了性能，并且随着人数的增加，性能提升更为显著。", "conclusion": "本文提出的高效轻量级一阶段模型结合新的自监督学习方法，显著提升了基于射频的多人姿态估计的精度和泛化能力，尤其是在复杂场景和多人情况下表现出色。", "translation": "在多人姿态估计（MPPE）领域，基于射频（RF）的方法无论光照条件和视线遮挡情况如何，都能有效运行。现有的基于射频的MPPE方法通常涉及：1）通过复杂的预处理将射频信号转换为热图图像，或2）直接将深度嵌入网络应用于原始射频信号。第一种方法虽然性能不错，但计算量大且耗时。第二种方法虽然预处理更简单，但导致MPPE精度和泛化性能较低。本文提出了一种高效轻量级的一阶段MPPE模型，基于原始射频信号。通过对射频信号进行分组，并使用共享的单层CNN和多头注意力进行嵌入，该模型优于之前通过大型深度CNN一次性嵌入所有信号的方法。此外，我们提出了一种新的自监督学习（SSL）方法，该方法从一个未遮蔽的子组和剩余的遮蔽子组中获取输入，以预测遮蔽数据的潜在表示。实证结果表明，与之前使用原始射频信号的方法相比，我们的模型在PCKh@0.5上的MPPE精度提高了15%。特别是，所提出的SSL方法在射频天线位于新位置或障碍物前时，显著增强了性能改进，并且随着人数的增加，性能提升更大。我们的代码和数据集已在Github开源。https://github.com/sshnan7/SOSPE。", "summary": "本文针对现有基于射频的多人姿态估计方法存在的计算复杂或精度较低的问题，提出了一种高效轻量级的一阶段模型。该模型直接处理原始射频信号，通过信号分组、单层CNN和多头注意力机制进行嵌入，并引入了一种新的自监督学习方法，该方法通过预测遮蔽数据的潜在表示来提升性能。实验证明，该方法显著提高了姿态估计精度，尤其是在新位置或障碍物前以及人数增加的情况下表现出更强的泛化能力和性能提升。", "keywords": "射频姿态估计, 自监督学习, 多人姿态估计, 一阶段学习, 原始射频信号", "comments": "本文的创新点在于提出了一个高效、轻量级的一阶段RF-based MPPE模型，并引入了新颖的自监督学习方法，解决了传统方法计算量大或精度低的问题。其重要性体现在无需光照条件和视线遮挡的限制，提升了RF-based MPPE的实用性和泛化能力，尤其是在复杂场景和多人环境下的性能提升显著。"}}
{"id": "2506.05743", "title": "When Better Features Mean Greater Risks: The Performance-Privacy Trade-Off in Contrastive Learning", "authors": ["Ruining Sun", "Hongsheng Hu", "Wei Luo", "Zhaoxi Zhang", "Yanjun Zhang", "Haizhuan Yuan", "Leo Yu Zhang"], "summary": "With the rapid advancement of deep learning technology, pre-trained encoder\nmodels have demonstrated exceptional feature extraction capabilities, playing a\npivotal role in the research and application of deep learning. However, their\nwidespread use has raised significant concerns about the risk of training data\nprivacy leakage. This paper systematically investigates the privacy threats\nposed by membership inference attacks (MIAs) targeting encoder models, focusing\non contrastive learning frameworks. Through experimental analysis, we reveal\nthe significant impact of model architecture complexity on membership privacy\nleakage: As more advanced encoder frameworks improve feature-extraction\nperformance, they simultaneously exacerbate privacy-leakage risks. Furthermore,\nthis paper proposes a novel membership inference attack method based on the\np-norm of feature vectors, termed the Embedding Lp-Norm Likelihood Attack\n(LpLA). This method infers membership status, by leveraging the statistical\ndistribution characteristics of the p-norm of feature vectors. Experimental\nresults across multiple datasets and model architectures demonstrate that LpLA\noutperforms existing methods in attack performance and robustness, particularly\nunder limited attack knowledge and query volumes. This study not only uncovers\nthe potential risks of privacy leakage in contrastive learning frameworks, but\nalso provides a practical basis for privacy protection research in encoder\nmodels. We hope that this work will draw greater attention to the privacy risks\nassociated with self-supervised learning models and shed light on the\nimportance of a balance between model utility and training data privacy. Our\ncode is publicly available at: https://github.com/SeroneySun/LpLA_code.", "comment": "Accepted In ACM ASIA Conference on Computer and Communications\n  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam. For Code, see\n  https://github.com/SeroneySun/LpLA_code", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05743v1", "AI": {"title_translation": "当更好的特征意味着更大的风险：对比学习中的性能-隐私权衡", "tldr": "对比学习中，更好的特征提取性能会带来更大的隐私泄露风险；本文提出了一种基于特征向量p范数的新型成员推断攻击方法LpLA，该方法在攻击性能和鲁棒性方面优于现有方法。", "motivation": "随着深度学习技术的发展，预训练编码器模型在特征提取方面表现出色，但其广泛使用引发了训练数据隐私泄露的担忧，尤其是在对比学习框架中。", "method": "本文系统性地调查了针对编码器模型的成员推断攻击（MIAs），重点关注对比学习框架。提出了一种基于特征向量p范数的新型成员推断攻击方法LpLA（Embedding Lp-Norm Likelihood Attack），该方法利用特征向量p范数的统计分布特性来推断成员状态。", "result": "实验分析揭示了模型架构复杂性对成员隐私泄露的显著影响：更先进的编码器框架在提高特征提取性能的同时，会加剧隐私泄露风险。LpLA在多个数据集和模型架构上的实验结果表明，其在攻击性能和鲁棒性方面优于现有方法，尤其是在有限的攻击知识和查询量下。", "conclusion": "本研究不仅揭示了对比学习框架中潜在的隐私泄露风险，也为编码器模型中的隐私保护研究提供了实践基础，并强调了模型效用与训练数据隐私之间平衡的重要性。", "translation": "随着深度学习技术的快速发展，预训练编码器模型展现出卓越的特征提取能力，在深度学习的研究和应用中发挥着关键作用。然而，它们的广泛使用引发了对训练数据隐私泄露风险的重大担忧。本文系统地研究了针对编码器模型的成员推断攻击（MIAs）所带来的隐私威胁，重点关注对比学习框架。通过实验分析，我们揭示了模型架构复杂性对成员隐私泄露的显著影响：随着更先进的编码器框架提高特征提取性能，它们同时加剧了隐私泄露风险。此外，本文提出了一种基于特征向量p范数的新型成员推断攻击方法，命名为Embedding Lp-Norm Likelihood Attack (LpLA)。该方法通过利用特征向量p范数的统计分布特性来推断成员状态。在多个数据集和模型架构上的实验结果表明，LpLA在攻击性能和鲁棒性方面优于现有方法，特别是在有限的攻击知识和查询量下。这项研究不仅揭示了对比学习框架中隐私泄露的潜在风险，而且为编码器模型中的隐私保护研究提供了实践基础。我们希望这项工作能引起对自监督学习模型相关隐私风险的更大关注，并阐明模型效用与训练数据隐私之间平衡的重要性。我们的代码已公开可用：https://github.com/SeroneySun/LpLA_code。", "summary": "本文系统性地研究了对比学习框架中编码器模型面临的成员推断攻击带来的隐私威胁。研究发现，模型架构越复杂，特征提取性能越好，隐私泄露风险也越大。为此，论文提出了一种基于特征向量p范数的新型成员推断攻击方法LpLA，该方法在攻击性能和鲁棒性方面均优于现有方法。这项工作揭示了对比学习中的隐私风险，并为隐私保护研究提供了基础，强调了模型效用与数据隐私平衡的重要性。", "keywords": "对比学习, 隐私泄露, 成员推断攻击, LpLA, 性能-隐私权衡", "comments": "这项工作创新性地揭示了对比学习中性能提升与隐私风险加剧之间的权衡，并提出了一种高效的成员推断攻击LpLA，为未来隐私保护研究提供了新的视角和实用工具。其强调了在开发高性能模型时必须考虑数据隐私的重要性。"}}
{"id": "2506.05425", "title": "SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning", "authors": ["Fanqi Kong", "Weiqin Zu", "Xinyu Chen", "Yaodong Yang", "Song-Chun Zhu", "Xue Feng"], "summary": "The rich and multifaceted nature of human social interaction, encompassing\nmultimodal cues, unobservable relations and mental states, and dynamical\nbehavior, presents a formidable challenge for artificial intelligence. To\nadvance research in this area, we introduce SIV-Bench, a novel video benchmark\nfor rigorously evaluating the capabilities of Multimodal Large Language Models\n(MLLMs) across Social Scene Understanding (SSU), Social State Reasoning (SSR),\nand Social Dynamics Prediction (SDP). SIV-Bench features 2,792 video clips and\n8,792 meticulously generated question-answer pairs derived from a human-LLM\ncollaborative pipeline. It is originally collected from TikTok and YouTube,\ncovering a wide range of video genres, presentation styles, and linguistic and\ncultural backgrounds. It also includes a dedicated setup for analyzing the\nimpact of different textual cues-original on-screen text, added dialogue, or no\ntext. Our comprehensive experiments on leading MLLMs reveal that while models\nadeptly handle SSU, they significantly struggle with SSR and SDP, where\nRelation Inference (RI) is an acute bottleneck, as further examined in our\nanalysis. Our study also confirms the critical role of transcribed dialogue in\naiding comprehension of complex social interactions. By systematically\nidentifying current MLLMs' strengths and limitations, SIV-Bench offers crucial\ninsights to steer the development of more socially intelligent AI. The dataset\nand code are available at https://kfq20.github.io/sivbench/.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05425v1", "AI": {"title_translation": "SIV-Bench: 一个用于社交互动理解与推理的视频基准", "tldr": "本文介绍了SIV-Bench，一个用于评估多模态大语言模型在社交互动理解和推理方面能力的视频基准，发现当前模型在推理和预测方面存在显著困难，并强调了对话的重要性。", "motivation": "人类社交互动本质复杂，包含多模态线索、不可观察的关系和心理状态以及动态行为，对人工智能构成了巨大挑战。为了推动该领域的研究，需要一个严格的基准来评估多模态大语言模型（MLLMs）的能力。", "method": "本文引入了SIV-Bench，一个新颖的视频基准。该基准包含2,792个视频片段和8,792个通过人-LLM协作管道精心生成的问题-答案对，这些数据最初从TikTok和YouTube收集，涵盖广泛的视频类型、呈现风格以及语言和文化背景。SIV-Bench专门用于评估MLLMs在社交场景理解（SSU）、社交状态推理（SSR）和社交动态预测（SDP）方面的能力，并包含一个用于分析不同文本线索（原始屏幕文本、添加的对话或无文本）影响的专用设置。研究人员对领先的MLLMs进行了全面实验。", "result": "实验结果表明，虽然多模态大语言模型（MLLMs）能够熟练处理社交场景理解（SSU），但它们在社交状态推理（SSR）和社交动态预测（SDP）方面存在显著困难，其中关系推理（RI）是一个严重的瓶颈。研究还证实了转录对话在帮助理解复杂社交互动中的关键作用。", "conclusion": "SIV-Bench通过系统地识别当前多模态大语言模型（MLLMs）的优势和局限性，为引导更具社交智能的AI发展提供了关键见解。", "translation": "人类社交互动丰富而多面，包含多模态线索、不可观察的关系和心理状态以及动态行为，这对人工智能构成了巨大挑战。为了推动该领域的研究，我们引入了SIV-Bench，这是一个新颖的视频基准，用于严格评估多模态大语言模型（MLLMs）在社交场景理解（SSU）、社交状态推理（SSR）和社交动态预测（SDP）方面的能力。SIV-Bench包含2,792个视频片段和8,792个精心生成的问题-答案对，这些问题-答案对来源于人-LLM协作管道。它最初从TikTok和YouTube收集，涵盖了广泛的视频类型、呈现风格以及语言和文化背景。它还包括一个专门的设置，用于分析不同文本线索（原始屏幕文本、添加的对话或无文本）的影响。我们对领先MLLMs进行的全面实验表明，虽然模型能够熟练处理SSU，但它们在SSR和SDP方面存在显著困难，其中关系推理（RI）是一个严重的瓶颈，正如我们的分析进一步探讨的那样。我们的研究还证实了转录对话在帮助理解复杂社交互动中的关键作用。通过系统地识别当前MLLMs的优势和局限性，SIV-Bench为引导更具社交智能的AI发展提供了关键见解。数据集和代码可在https://kfq20.github.io/sivbench/获取。", "summary": "本论文介绍了SIV-Bench，一个用于评估多模态大语言模型在社交互动理解、状态推理和动态预测方面能力的视频基准。该基准包含大量来自TikTok和YouTube的视频剪辑及高质量问答对。实验结果表明，当前MLLMs在社交场景理解方面表现良好，但在社交状态推理和动态预测方面存在显著困难，尤其是在关系推理方面，并强调了转录对话对理解复杂社交互动的重要性。SIV-Bench旨在推动更具社交智能的AI发展。", "keywords": "SIV-Bench, 社交互动理解, 视频基准, 多模态大语言模型, 关系推理", "comments": "SIV-Bench的创新之处在于其专注于评估MLLMs在复杂社交互动理解上的能力，并细化到场景理解、状态推理和动态预测。其数据集的构建方式（人-LLM协作）和数据来源（TikTok/YouTube）确保了数据的多样性和真实性。研究结果明确指出了当前MLLMs在推理能力上的瓶颈，特别是关系推理，这为未来的研究指明了方向。强调对话的重要性也提供了实用的指导。"}}
{"id": "2506.05583", "title": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "authors": ["Nien-Shao Wang", "Duygu Nur Yaldiz", "Yavuz Faruk Bakman", "Sai Praneeth Karimireddy"], "summary": "Conformal prediction is widely used to equip black-box machine learning\nmodels with uncertainty quantification enjoying formal coverage guarantees.\nHowever, these guarantees typically break down in the presence of distribution\nshifts, where the data distribution at test time differs from the training (or\ncalibration-time) distribution. In this work, we address subpopulation shifts,\nwhere the test environment exhibits an unknown and differing mixture of\nsubpopulations compared to the calibration data. We propose new methods that\nprovably adapt conformal prediction to such shifts, ensuring valid coverage\nwithout requiring explicit knowledge of subpopulation structure. Our algorithms\nscale to high-dimensional settings and perform effectively in realistic machine\nlearning tasks. Extensive experiments on vision (with vision transformers) and\nlanguage (with large language models) benchmarks demonstrate that our methods\nreliably maintain coverage and controls risk in scenarios where standard\nconformal prediction fails.", "comment": "20 pages, 6 figures, 5 tables, submitted to NeurIPS 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05583v1", "AI": {"title_translation": "未知子群体偏移下的共形预测自适应", "tldr": "针对未知子群体偏移，本文提出新方法使共形预测保持有效覆盖，即使在标准方法失效的情况下也能可靠地维持覆盖并控制风险。", "motivation": "传统的共形预测在存在分布偏移（特别是未知子群体偏移）时，其形式覆盖保证会失效，导致在测试时数据分布与训练/校准时不同。", "method": "提出了新的方法，能够可证明地使共形预测适应未知子群体偏移，在不需要明确了解子群体结构的情况下，确保有效的覆盖率。", "result": "提出的算法能够扩展到高维设置，并在真实的机器学习任务中有效执行。在视觉（使用视觉Transformer）和语言（使用大型语言模型）基准上的大量实验表明，在标准共形预测失效的情况下，所提出的方法能够可靠地保持覆盖并控制风险。", "conclusion": "Not mentioned in abstract", "translation": "共形预测被广泛用于为黑盒机器学习模型提供具有形式覆盖保证的不确定性量化。然而，当存在分布偏移时，即测试时的数据分布与训练（或校准时）分布不同时，这些保证通常会失效。在这项工作中，我们解决了子群体偏移问题，即测试环境与校准数据相比呈现出未知且不同的子群体混合。我们提出了新的方法，这些方法可证明地使共形预测适应此类偏移，从而在不需要明确了解子群体结构的情况下确保有效的覆盖率。我们的算法可以扩展到高维设置，并在真实的机器学习任务中有效执行。在视觉（使用视觉Transformer）和语言（使用大型语言模型）基准上的大量实验表明，在标准共形预测失效的情况下，我们的方法能够可靠地保持覆盖并控制风险。", "summary": "本文针对黑盒机器学习模型在存在未知子群体偏移时，传统共形预测的覆盖保证失效的问题。作者提出了一系列新方法，这些方法能够自适应地使共形预测适应此类偏移，并在无需明确子群体结构知识的情况下，保证有效的覆盖率。实验证明，这些算法在高维环境中表现良好，并在视觉和语言任务中，即便在标准共形预测失败的情况下，也能可靠地维持覆盖并控制风险。", "keywords": "共形预测, 分布偏移, 子群体偏移, 不确定性量化, 覆盖保证", "comments": "这篇论文解决了共形预测在实际应用中面临的一个关键挑战，即如何处理未知分布偏移。其创新之处在于提出了无需明确子群体结构知识即可适应偏移的方法，并证明了其在高维和复杂模型（如视觉Transformer和大型语言模型）上的有效性，这对于提高机器学习模型在不确定环境中的可靠性具有重要意义。"}}
{"id": "2506.05844", "title": "$\\text{C}^{2}\\text{BNVAE}$: Dual-Conditional Deep Generation of Network Traffic Data for Network Intrusion Detection System Balancing", "authors": ["Yifan Zeng"], "summary": "Network Intrusion Detection Systems (NIDS) face challenges due to class\nimbalance, affecting their ability to detect novel and rare attacks. This paper\nproposes a Dual-Conditional Batch Normalization Variational Autoencoder\n($\\text{C}^{2}\\text{BNVAE}$) for generating balanced and labeled network\ntraffic data. $\\text{C}^{2}\\text{BNVAE}$ improves the model's adaptability to\ndifferent data categories and generates realistic category-specific data by\nincorporating Conditional Batch Normalization (CBN) into the Conditional\nVariational Autoencoder (CVAE). Experiments on the NSL-KDD dataset show the\npotential of $\\text{C}^{2}\\text{BNVAE}$ in addressing imbalance and improving\nNIDS performance with lower computational overhead compared to some baselines.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05844v1", "AI": {"title_translation": "$\text{C}^{2}\text{BNVAE}$：用于网络入侵检测系统平衡的双条件深度生成网络流量数据", "tldr": "$\text{C}^{2}\text{BNVAE}$是一种新的双条件批量归一化变分自编码器，通过生成平衡且带标签的网络流量数据来解决网络入侵检测系统（NIDS）中的类别不平衡问题，并提高其性能。", "motivation": "网络入侵检测系统（NIDS）面临类别不平衡的挑战，这影响了它们检测新型和罕见攻击的能力。", "method": "本文提出了一种双条件批量归一化变分自编码器（$\text{C}^{2}\text{BNVAE}$），通过将条件批量归一化（CBN）整合到条件变分自编码器（CVAE）中，以生成平衡且带标签的网络流量数据，从而提高模型对不同数据类别的适应性并生成逼真的特定类别数据。", "result": "在NSL-KDD数据集上的实验表明，与一些基线相比，$\text{C}^{2}\text{BNVAE}$在解决不平衡和提高NIDS性能方面具有潜力，且计算开销较低。", "conclusion": "$\text{C}^{2}\text{BNVAE}$能够有效解决网络入侵检测系统中的类别不平衡问题，并通过生成高质量的合成数据来提高其检测性能。", "translation": "网络入侵检测系统（NIDS）面临类别不平衡的挑战，这影响了它们检测新型和罕见攻击的能力。本文提出了一种双条件批量归一化变分自编码器（$\text{C}^{2}\text{BNVAE}$），用于生成平衡且带标签的网络流量数据。$\text{C}^{2}\text{BNVAE}$通过将条件批量归一化（CBN）整合到条件变分自编码器（CVAE）中，提高了模型对不同数据类别的适应性，并生成逼真的特定类别数据。在NSL-KDD数据集上的实验表明，与一些基线相比，$\text{C}^{2}\text{BNVAE}$在解决不平衡和提高NIDS性能方面具有潜力，且计算开销较低。", "summary": "本文提出了一种名为$\text{C}^{2}\text{BNVAE}$的双条件批量归一化变分自编码器，旨在解决网络入侵检测系统（NIDS）中存在的类别不平衡问题。该模型通过将条件批量归一化（CBN）引入条件变分自编码器（CVAE），能够生成平衡且带标签的网络流量数据，从而提高NIDS检测新型和罕见攻击的能力。实验结果表明，$\text{C}^{2}\text{BNVAE}$在改善NIDS性能和处理数据不平衡方面表现出显著潜力，并且与现有方法相比具有较低的计算开销。", "keywords": "网络入侵检测系统, 类别不平衡, 变分自编码器, 数据生成, 条件批量归一化", "comments": "该论文的创新点在于提出了$\text{C}^{2}\text{BNVAE}$模型，通过引入条件批量归一化来增强变分自编码器的生成能力，专门用于解决网络入侵检测系统中的类别不平衡问题。这种方法对于提高NIDS在检测罕见攻击方面的鲁棒性和有效性具有重要意义。"}}
{"id": "2506.05429", "title": "Coordinated Robustness Evaluation Framework for Vision-Language Models", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "summary": "Vision-language models, which integrate computer vision and natural language\nprocessing capabilities, have demonstrated significant advancements in tasks\nsuch as image captioning and visual question and answering. However, similar to\ntraditional models, they are susceptible to small perturbations, posing a\nchallenge to their robustness, particularly in deployment scenarios. Evaluating\nthe robustness of these models requires perturbations in both the vision and\nlanguage modalities to learn their inter-modal dependencies. In this work, we\ntrain a generic surrogate model that can take both image and text as input and\ngenerate joint representation which is further used to generate adversarial\nperturbations for both the text and image modalities. This coordinated attack\nstrategy is evaluated on the visual question and answering and visual reasoning\ndatasets using various state-of-the-art vision-language models. Our results\nindicate that the proposed strategy outperforms other multi-modal attacks and\nsingle-modality attacks from the recent literature. Our results demonstrate\ntheir effectiveness in compromising the robustness of several state-of-the-art\npre-trained multi-modal models such as instruct-BLIP, ViLT and others.", "comment": "Accepted: IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW) 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05429v1", "AI": {"title_translation": "视觉-语言模型的协同鲁棒性评估框架", "tldr": "本文提出了一个协同鲁棒性评估框架，通过生成图像和文本的联合对抗性扰动来有效评估视觉-语言模型的鲁棒性，并证明其优于现有攻击方法。", "motivation": "视觉-语言模型虽然在多项任务中表现出色，但其鲁棒性面临挑战，尤其是在部署场景中易受小扰动影响。评估这些模型的鲁棒性需要考虑视觉和语言模态之间的相互依赖性。", "method": "本文训练了一个通用替代模型，该模型能够同时接收图像和文本作为输入，并生成联合表示。该联合表示随后用于为文本和图像模态生成协同对抗性扰动。该协同攻击策略在视觉问答和视觉推理数据集上，针对多种最先进的视觉-语言模型进行了评估。", "result": "所提出的协同攻击策略表现优于其他多模态攻击和近期文献中的单模态攻击。实验结果表明，该策略能有效损害包括 instruct-BLIP 和 ViLT 在内的多个最先进预训练多模态模型的鲁棒性。", "conclusion": "本文提出的协同攻击策略是一种评估视觉-语言模型鲁棒性的有效且更优的方法，能够揭示模型在图像和文本模态协同扰动下的脆弱性。", "translation": "视觉-语言模型集成了计算机视觉和自然语言处理能力，在图像标注和视觉问答等任务中取得了显著进展。然而，与传统模型类似，它们容易受到小扰动的影响，对其鲁棒性构成挑战，特别是在部署场景中。评估这些模型的鲁棒性需要在视觉和语言模态中进行扰动，以了解它们的模态间依赖性。在这项工作中，我们训练了一个通用替代模型，该模型可以同时接收图像和文本作为输入，并生成联合表示，该表示进一步用于为文本和图像模态生成对抗性扰动。这种协同攻击策略在视觉问答和视觉推理数据集上使用各种最先进的视觉-语言模型进行了评估。我们的结果表明，所提出的策略优于其他多模态攻击和近期文献中的单模态攻击。我们的结果证明了它们在损害 instruct-BLIP、ViLT 等多个最先进预训练多模态模型鲁棒性方面的有效性。", "summary": "本文提出了一个针对视觉-语言模型的协同鲁棒性评估框架。该框架通过训练一个能够生成图像和文本联合对抗性扰动的通用替代模型，来评估视觉-语言模型的鲁棒性。实验证明，该协同攻击策略在视觉问答和视觉推理任务上，相比其他多模态和单模态攻击方法，能更有效地降低当前最先进视觉-语言模型的鲁棒性。", "keywords": "视觉-语言模型, 鲁棒性评估, 对抗性攻击, 多模态, 协同扰动", "comments": "该论文的创新点在于提出了一个协同攻击策略，通过生成图像和文本的联合对抗性扰动来评估视觉-语言模型的鲁棒性，这比传统的单模态或非协同多模态攻击更为全面和有效。这对于理解和提高视觉-语言模型在实际部署中的安全性至关重要。"}}
{"id": "2506.05584", "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention", "authors": ["Yuchen Zeng", "Tuan Dinh", "Wonjun Kang", "Andreas C Mueller"], "summary": "Leveraging the in-context learning (ICL) capability of Large Language Models\n(LLMs) for tabular classification has gained significant attention for its\ntraining-free adaptability across diverse datasets. Recent advancements, like\nTabPFN, excel in small-scale tabular datasets but struggle to scale for large\nand complex datasets. Our work enhances the efficiency and scalability of\nTabPFN for larger datasets by incorporating linear attention mechanisms as a\nscalable alternative to complexity-quadratic self-attention. Our model,\nTabFlex, efficiently handles tabular datasets with thousands of features and\nhundreds of classes, scaling seamlessly to millions of samples. For instance,\nTabFlex processes the poker-hand dataset with over a million samples in just 5\nseconds. Our extensive evaluations demonstrate that TabFlex can achieve over a\n2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, outperforming 25\ntested baselines in terms of efficiency across a diverse range of datasets.\nFurthermore, TabFlex remains highly effective on large-scale datasets,\ndelivering strong performance with significantly reduced computational costs,\nespecially when combined with data-efficient techniques such as dimensionality\nreduction and data sampling.", "comment": "30 pages, ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05584v1", "AI": {"title_translation": "TabFlex：利用线性注意力将表格学习扩展到百万级样本", "tldr": "TabFlex利用线性注意力机制，将表格学习扩展到百万级样本，比TabPFN和XGBoost更快、更高效，同时在大规模数据集上保持高性能。", "motivation": "现有的大语言模型（LLMs）在表格分类中的上下文学习能力在小规模数据集上表现出色，但如TabPFN等模型在处理大型复杂数据集时面临可扩展性挑战。", "method": "我们的工作通过引入线性注意力机制作为复杂度为二次方的自注意力机制的可扩展替代方案，从而提高了TabPFN在大型数据集上的效率和可扩展性。", "result": "TabFlex能够高效处理具有数千个特征和数百个类别的表格数据集，并无缝扩展到数百万个样本。例如，TabFlex在短短5秒内处理了包含超过一百万个样本的poker-hand数据集。与TabPFN相比，TabFlex的速度提升了2倍以上，与XGBoost相比，速度提升了1.5倍以上，在效率方面优于25个测试基线模型。此外，TabFlex在大规模数据集上仍然非常有效，以显著降低的计算成本提供强大的性能，特别是与降维和数据采样等数据高效技术结合使用时。", "conclusion": "TabFlex通过引入线性注意力机制，成功解决了现有表格学习模型在处理大规模数据集时的可扩展性问题，显著提升了处理速度和效率，并在保持高性能的同时降低了计算成本。", "translation": "利用大语言模型（LLMs）的上下文学习（ICL）能力进行表格分类因其在不同数据集上的免训练适应性而获得了广泛关注。近期进展，如TabPFN，在小规模表格数据集上表现出色，但在处理大型复杂数据集时难以扩展。我们的工作通过引入线性注意力机制作为复杂度为二次方的自注意力机制的可扩展替代方案，从而提高了TabPFN在大型数据集上的效率和可扩展性。我们的模型TabFlex能高效处理具有数千个特征和数百个类别的表格数据集，并能无缝扩展到数百万个样本。例如，TabFlex在短短5秒内处理了包含超过一百万个样本的poker-hand数据集。我们广泛的评估表明，与TabPFN相比，TabFlex的速度提升了2倍以上，与XGBoost相比，速度提升了1.5倍以上，在效率方面优于25个测试基线模型。此外，TabFlex在大规模数据集上仍然非常有效，以显著降低的计算成本提供强大的性能，特别是与降维和数据采样等数据高效技术结合使用时。", "summary": "TabFlex提出了一种利用线性注意力机制扩展表格学习模型（如TabPFN）以处理百万级样本的方法。该模型解决了现有方法在处理大型复杂数据集时的可扩展性问题，显著提高了处理效率和速度，并在大规模数据集上保持了高性能，尤其在结合数据高效技术时。", "keywords": "表格学习, 线性注意力, 可扩展性, TabFlex, 大规模数据集", "comments": "这篇论文的创新点在于将线性注意力机制引入到表格学习中，有效解决了传统自注意力机制在处理大规模表格数据时面临的计算复杂度高和可扩展性差的问题。TabFlex的提出对于推动表格数据处理领域在大数据背景下的发展具有重要意义，其在效率和性能上的显著提升预示着在实际应用中更广阔的前景，尤其是在需要快速处理海量表格数据的场景。"}}
{"id": "2506.05385", "title": "LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models", "authors": ["Xinxin Li", "Huiyao Chen", "Chengjun Liu", "Jing Li", "Meishan Zhang", "Jun Yu", "Min Zhang"], "summary": "Semantic role labeling (SRL) is a crucial task of natural language processing\n(NLP). Although generative decoder-based large language models (LLMs) have\nachieved remarkable success across various NLP tasks, they still lag behind\nstate-of-the-art encoder-decoder (BERT-like) models in SRL. In this work, we\nseek to bridge this gap by equipping LLMs for SRL with two mechanisms: (a)\nretrieval-augmented generation and (b) self-correction. The first mechanism\nenables LLMs to leverage external linguistic knowledge such as predicate and\nargument structure descriptions, while the second allows LLMs to identify and\ncorrect inconsistent SRL outputs. We conduct extensive experiments on three\nwidely-used benchmarks of SRL (CPB1.0, CoNLL-2009, and CoNLL-2012). Results\ndemonstrate that our method achieves state-of-the-art performance in both\nChinese and English, marking the first successful application of LLMs to\nsurpass encoder-decoder approaches in SRL.", "comment": "19 pages, 3 figures, 10 tables", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05385v1", "AI": {"title_translation": "大型语言模型也能表现出色！通过大型语言模型打破语义角色标注的障碍", "tldr": "本文通过引入检索增强生成和自校正机制，使大型语言模型（LLMs）在语义角色标注（SRL）任务上取得了最先进的性能，首次超越了编码器-解码器模型。", "motivation": "尽管生成式大型语言模型（LLMs）在各种自然语言处理任务中取得了显著成功，但在语义角色标注（SRL）方面仍落后于最先进的编码器-解码器（BERT-like）模型。本研究旨在弥合这一差距。", "method": "本文通过两种机制来提升大型语言模型在语义角色标注上的表现：(a) 检索增强生成，使LLMs能够利用外部语言知识（如谓词和论元结构描述）；(b) 自校正，允许LLMs识别并纠正不一致的SRL输出。", "result": "在三个广泛使用的SRL基准测试（CPB1.0、CoNLL-2009和CoNLL-2012）上进行了广泛实验。结果表明，该方法在中英文SRL任务中均达到了最先进的性能，标志着大型语言模型首次成功超越编码器-解码器方法在SRL中的表现。", "conclusion": "大型语言模型通过结合检索增强生成和自校正机制，首次在语义角色标注任务上超越了传统的编码器-解码器方法，达到了最先进的性能。", "translation": "语义角色标注（SRL）是自然语言处理（NLP）的一项关键任务。尽管生成式解码器大型语言模型（LLMs）在各种NLP任务中取得了显著成功，但在SRL方面仍落后于最先进的编码器-解码器（BERT-like）模型。在这项工作中，我们试图通过为LLMs配备两种机制来弥合这一差距：(a) 检索增强生成和(b) 自校正。第一种机制使LLMs能够利用外部语言知识，如谓词和论元结构描述，而第二种机制则允许LLMs识别和纠正不一致的SRL输出。我们在三个广泛使用的SRL基准测试（CPB1.0、CoNLL-2009和CoNLL-2012）上进行了广泛实验。结果表明，我们的方法在中英文中均达到了最先进的性能，标志着LLMs首次成功应用于SRL并超越编码器-解码器方法。", "summary": "本研究旨在解决大型语言模型（LLMs）在语义角色标注（SRL）任务上落后于编码器-解码器模型的现状。通过引入检索增强生成和自校正两种创新机制，本文成功提升了LLMs在SRL上的表现。实验结果表明，该方法在三个主要SRL基准测试上，无论中英文，均取得了最先进的性能，首次实现了LLMs在SRL领域超越编码器-解码器模型的突破。", "keywords": "语义角色标注, 大型语言模型, 检索增强生成, 自校正, 自然语言处理", "comments": "本文的创新之处在于首次成功地将大型语言模型应用于语义角色标注任务并使其超越了传统的编码器-解码器方法。通过引入检索增强生成来利用外部知识，以及自校正机制来提升输出一致性，该研究为LLMs在复杂NLP任务中的应用开辟了新途径，具有重要的研究价值和潜在应用前景。"}}
{"id": "2506.05867", "title": "Stealix: Model Stealing via Prompt Evolution", "authors": ["Zhixiong Zhuang", "Hui-Po Wang", "Maria-Irina Nicolae", "Mario Fritz"], "summary": "Model stealing poses a significant security risk in machine learning by\nenabling attackers to replicate a black-box model without access to its\ntraining data, thus jeopardizing intellectual property and exposing sensitive\ninformation. Recent methods that use pre-trained diffusion models for data\nsynthesis improve efficiency and performance but rely heavily on manually\ncrafted prompts, limiting automation and scalability, especially for attackers\nwith little expertise. To assess the risks posed by open-source pre-trained\nmodels, we propose a more realistic threat model that eliminates the need for\nprompt design skills or knowledge of class names. In this context, we introduce\nStealix, the first approach to perform model stealing without predefined\nprompts. Stealix uses two open-source pre-trained models to infer the victim\nmodel's data distribution, and iteratively refines prompts through a genetic\nalgorithm, progressively improving the precision and diversity of synthetic\nimages. Our experimental results demonstrate that Stealix significantly\noutperforms other methods, even those with access to class names or\nfine-grained prompts, while operating under the same query budget. These\nfindings highlight the scalability of our approach and suggest that the risks\nposed by pre-trained generative models in model stealing may be greater than\npreviously recognized.", "comment": "Accepted at ICML 2025. The project page is at\n  https://zhixiongzh.github.io/stealix/", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05867v1", "AI": {"title_translation": "Stealix：通过提示演化进行模型窃取", "tldr": "Stealix是一种新的模型窃取方法，它利用遗传算法自动进化提示，无需人工干预，并且表现优于现有方法。", "motivation": "现有的模型窃取方法依赖手动设计的提示，限制了自动化和可扩展性，尤其对于经验不足的攻击者。为了评估开源预训练模型带来的风险，需要一种不需要提示设计技能或类名知识的模型窃取方法。", "method": "Stealix利用两个开源预训练模型推断受害者模型的数据分布，并通过遗传算法迭代地优化提示，逐步提高合成图像的精度和多样性。", "result": "Stealix在相同的查询预算下，显著优于其他方法，即使是那些可以使用类名或更精细提示的方法。这表明该方法具有可扩展性，并且预训练生成模型在模型窃取方面带来的风险可能比之前认为的更大。", "conclusion": "预训练生成模型在模型窃取方面带来的风险可能比之前认为的更大，Stealix的成功证明了无需预定义提示进行模型窃取的可能性和有效性。", "translation": "模型窃取通过使攻击者无需访问其训练数据即可复制黑盒模型，从而对机器学习构成重大安全风险，危及知识产权并暴露敏感信息。最近使用预训练扩散模型进行数据合成的方法提高了效率和性能，但严重依赖手动制作的提示，限制了自动化和可扩展性，特别是对于专业知识较少的攻击者。为了评估开源预训练模型带来的风险，我们提出了一种更现实的威胁模型，消除了对提示设计技能或类名知识的需求。在此背景下，我们介绍了Stealix，这是第一个无需预定义提示即可执行模型窃取的方法。Stealix使用两个开源预训练模型来推断受害者模型的数据分布，并通过遗传算法迭代地优化提示，逐步提高合成图像的精度和多样性。我们的实验结果表明，Stealix显著优于其他方法，即使是那些可以使用类名或更精细提示的方法，同时在相同的查询预算下运行。这些发现突出了我们方法的可扩展性，并表明预训练生成模型在模型窃取方面带来的风险可能比之前认为的更大。", "summary": "Stealix是一种新颖的模型窃取方法，旨在解决现有方法对人工设计提示的依赖问题。它引入了一种更现实的威胁模型，无需攻击者具备提示设计技能或类名知识。Stealix利用两个开源预训练模型来推断目标模型的数据分布，并通过遗传算法迭代优化提示，从而生成高精度和多样性的合成图像。实验证明，Stealix在相同查询预算下，性能优于其他即使拥有类名或精细提示的方法，表明了其高可扩展性，并揭示了预训练生成模型在模型窃取方面可能带来比以往更大风险。", "keywords": "模型窃取, 提示演化, 遗传算法, 预训练模型, 机器学习安全", "comments": "Stealix的创新之处在于其通过遗传算法实现提示的自动化演化，解决了传统模型窃取方法对人工提示设计的依赖，极大地提升了自动化和可扩展性。这对于评估和防御模型窃取攻击具有重要意义，尤其是在开源预训练模型日益普及的背景下，其揭示的潜在风险值得关注。"}}
{"id": "2506.05968", "title": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning", "authors": ["Motoki Omura", "Kazuki Ota", "Takayuki Osa", "Yusuke Mukuta", "Tatsuya Harada"], "summary": "For continuous action spaces, actor-critic methods are widely used in online\nreinforcement learning (RL). However, unlike RL algorithms for discrete\nactions, which generally model the optimal value function using the Bellman\noptimality operator, RL algorithms for continuous actions typically model\nQ-values for the current policy using the Bellman operator. These algorithms\nfor continuous actions rely exclusively on policy updates for improvement,\nwhich often results in low sample efficiency. This study examines the\neffectiveness of incorporating the Bellman optimality operator into\nactor-critic frameworks. Experiments in a simple environment show that modeling\noptimal values accelerates learning but leads to overestimation bias. To\naddress this, we propose an annealing approach that gradually transitions from\nthe Bellman optimality operator to the Bellman operator, thereby accelerating\nlearning while mitigating bias. Our method, combined with TD3 and SAC,\nsignificantly outperforms existing approaches across various locomotion and\nmanipulation tasks, demonstrating improved performance and robustness to\nhyperparameters related to optimality.", "comment": "Accepted at ICML 2025. Source code:\n  https://github.com/motokiomura/annealed-q-learning", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05968v1", "AI": {"title_translation": "渐进式地从贝尔曼最优算子到贝尔曼算子的在线强化学习", "tldr": "本文提出一种退火方法，渐进地从贝尔曼最优算子过渡到贝尔曼算子，以加速连续动作空间在线强化学习并减轻过高估计偏差，在多种任务上显著优于现有方法。", "motivation": "对于连续动作空间，在线强化学习算法通常使用贝尔曼算子对当前策略的Q值建模，仅依赖策略更新进行改进，这通常导致样本效率低下。", "method": "提出一种退火方法，该方法渐进地从贝尔曼最优算子过渡到贝尔曼算子。该方法结合了TD3和SAC。", "result": "实验表明，建模最优值可以加速学习，但会导致过高估计偏差。提出的方法在加速学习的同时减轻了偏差。结合TD3和SAC，在各种运动和操作任务中显著优于现有方法，并提高了对最优性相关超参数的性能和鲁棒性。", "conclusion": "渐进地从贝尔曼最优算子过渡到贝尔曼算子能够有效解决连续动作空间强化学习中学习速度慢和过高估计偏差的问题，显著提升算法性能和鲁棒性。", "translation": "对于连续动作空间，actor-critic方法在在线强化学习（RL）中被广泛使用。然而，与通常使用贝尔曼最优算子建模最优值函数的离散动作RL算法不同，连续动作RL算法通常使用贝尔曼算子建模当前策略的Q值。这些连续动作算法完全依赖策略更新进行改进，这通常导致样本效率低下。本研究探讨了将贝尔曼最优算子纳入actor-critic框架的有效性。在一个简单环境中的实验表明，建模最优值可以加速学习，但会导致过高估计偏差。为了解决这个问题，我们提出了一种退火方法，该方法渐进地从贝尔曼最优算子过渡到贝尔曼算子，从而在加速学习的同时减轻偏差。我们的方法结合TD3和SAC，在各种运动和操作任务中显著优于现有方法，展示了改进的性能和对最优性相关超参数的鲁棒性。", "summary": "本文关注连续动作空间在线强化学习中样本效率低下的问题。现有方法通常使用贝尔曼算子，而离散动作RL使用贝尔曼最优算子。研究发现，将贝尔曼最优算子引入actor-critic框架能加速学习但会引入过高估计偏差。为解决此问题，作者提出一种退火方法，渐进地从贝尔曼最优算子过渡到贝尔曼算子，以期在加速学习的同时减轻偏差。实验证明，该方法与TD3和SAC结合后，在多种任务上显著优于现有方法，并提升了性能和超参数鲁棒性。", "keywords": "强化学习, 贝尔曼最优算子, 贝尔曼算子, 连续动作空间, Actor-Critic, 退火方法", "comments": "这篇论文通过引入贝尔曼最优算子并采用渐进退火策略，巧妙地解决了连续动作空间强化学习中学习效率和偏差的平衡问题。其创新点在于将两种不同操作符的优势结合，并用退火机制平滑过渡，这对于提高在线RL的样本效率和稳定性具有重要意义。"}}
{"id": "2506.05431", "title": "Robustness Evaluation for Video Models with Reinforcement Learning", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "summary": "Evaluating the robustness of Video classification models is very challenging,\nspecifically when compared to image-based models. With their increased temporal\ndimension, there is a significant increase in complexity and computational\ncost. One of the key challenges is to keep the perturbations to a minimum to\ninduce misclassification. In this work, we propose a multi-agent reinforcement\nlearning approach (spatial and temporal) that cooperatively learns to identify\nthe given video's sensitive spatial and temporal regions. The agents consider\ntemporal coherence in generating fine perturbations, leading to a more\neffective and visually imperceptible attack. Our method outperforms the\nstate-of-the-art solutions on the Lp metric and the average queries. Our method\nenables custom distortion types, making the robustness evaluation more relevant\nto the use case. We extensively evaluate 4 popular models for video action\nrecognition on two popular datasets, HMDB-51 and UCF-101.", "comment": "Accepted at the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW) 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05431v1", "AI": {"title_translation": "基于强化学习的视频模型鲁棒性评估", "tldr": "本研究提出了一种多智能体强化学习方法，用于评估视频模型的鲁棒性，通过识别敏感时空区域生成视觉上难以察觉的扰动，并在性能上超越了现有先进方法。", "motivation": "评估视频分类模型的鲁棒性非常具有挑战性，尤其与基于图像的模型相比。视频模型的时间维度增加了复杂性和计算成本。主要挑战之一是最小化扰动以诱导模型错误分类。", "method": "我们提出了一种多智能体强化学习方法（包括空间和时间智能体），这些智能体协同学习识别给定视频的敏感空间和时间区域。这些智能体在生成精细扰动时考虑时间连贯性，从而实现更有效且视觉上难以察觉的攻击。", "result": "我们的方法在Lp度量和平均查询方面优于现有最先进的解决方案。我们的方法支持自定义失真类型，使鲁棒性评估与用例更相关。我们广泛评估了HMDB-51和UCF-101两个流行数据集上的4个流行视频动作识别模型。", "conclusion": "本研究提出的多智能体强化学习方法在视频模型鲁棒性评估中表现出色，超越了现有最先进的方法，并支持自定义失真类型，提高了评估的实用性和相关性。", "translation": "评估视频分类模型的鲁棒性非常具有挑战性，尤其是与基于图像的模型相比。随着时间维度的增加，复杂性和计算成本显著增加。关键挑战之一是最小化扰动以诱导错误分类。在这项工作中，我们提出了一种多智能体强化学习方法（空间和时间），该方法协同学习识别给定视频的敏感空间和时间区域。智能体在生成精细扰动时考虑时间连贯性，从而实现更有效且视觉上难以察觉的攻击。我们的方法在Lp度量和平均查询方面优于现有最先进的解决方案。我们的方法支持自定义失真类型，使鲁棒性评估与用例更相关。我们广泛评估了HMDB-51和UCF-101两个流行数据集上的4个流行视频动作识别模型。", "summary": "本论文旨在解决视频分类模型鲁棒性评估的挑战，该挑战因视频的时间维度而增加复杂性和计算成本。为实现最小扰动下的错误分类，作者提出了一种多智能体强化学习方法，该方法通过空间和时间智能体协同学习识别视频的敏感时空区域。该方法在生成细微扰动时考虑时间连贯性，从而实现更有效且视觉上难以察觉的攻击。实验结果表明，该方法在Lp度量和平均查询方面优于现有最先进的解决方案，并且支持自定义失真类型，提高了评估的实用性。研究在HMDB-51和UCF-101数据集上对四种流行的视频动作识别模型进行了广泛评估。", "keywords": "鲁棒性评估, 视频模型, 强化学习, 多智能体, 对抗性攻击", "comments": "该论文的创新点在于将多智能体强化学习引入视频模型的鲁棒性评估，特别是在生成扰动时考虑了视频的时间连贯性，并实现了视觉上难以察觉的攻击。这对于理解和提高视频模型的安全性具有重要意义。支持自定义失真类型也增加了其在实际应用中的灵活性和相关性。"}}
{"id": "2506.05586", "title": "CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions", "authors": ["Isha Puri", "Amit Dhurandhar", "Tejaswini Pedapati", "Kartikeyan Shanmugam", "Dennis Wei", "Kush R. Varshney"], "summary": "In recent years there has been a considerable amount of research on local\npost hoc explanations for neural networks. However, work on building\ninterpretable neural architectures has been relatively sparse. In this paper,\nwe present a novel neural architecture, CoFrNet, inspired by the form of\ncontinued fractions which are known to have many attractive properties in\nnumber theory, such as fast convergence of approximations to real numbers. We\nshow that CoFrNets can be efficiently trained as well as interpreted leveraging\ntheir particular functional form. Moreover, we prove that such architectures\nare universal approximators based on a proof strategy that is different than\nthe typical strategy used to prove universal approximation results for neural\nnetworks based on infinite width (or depth), which is likely to be of\nindependent interest. We experiment on nonlinear synthetic functions and are\nable to accurately model as well as estimate feature attributions and even\nhigher order terms in some cases, which is a testament to the representational\npower as well as interpretability of such architectures. To further showcase\nthe power of CoFrNets, we experiment on seven real datasets spanning tabular,\ntext and image modalities, and show that they are either comparable or\nsignificantly better than other interpretable models and multilayer\nperceptrons, sometimes approaching the accuracies of state-of-the-art models.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05586v1", "AI": {"title_translation": "CoFrNets：受连分数启发的神经网络可解释架构", "tldr": "CoFrNets是一种受连分数启发的、可解释且性能优异的新型神经网络架构。", "motivation": "现有研究主要集中在局部事后解释，而可解释神经网络架构的构建相对较少。", "method": "提出了一种名为CoFrNet的新型神经网络架构，其灵感来源于连分数，具有可高效训练、可解释性强以及通用逼近器的特性。证明其通用逼近器特性采用了与传统基于无限宽度/深度不同的策略。", "result": "在非线性合成函数上能够准确建模并估计特征归因和高阶项。在七个真实数据集（表格、文本、图像）上，CoFrNets的性能与其它可解释模型和多层感知机相当或显著更好，有时接近最先进模型的准确性。", "conclusion": "CoFrNets是一种具有强大表示能力和可解释性的新型神经网络架构，在各种任务上表现出色，并提供了新的通用逼近器证明策略。", "translation": "近年来，关于神经网络的局部事后解释研究相当多。然而，关于构建可解释神经网络架构的工作相对较少。在本文中，我们提出了一种新型神经网络架构CoFrNet，其灵感来源于连分数的形式，连分数在数论中以其许多吸引人的特性而闻名，例如对实数逼近的快速收敛。我们表明，CoFrNets可以高效训练，并且可以利用其特殊的函数形式进行解释。此外，我们证明了这种架构是通用逼近器，其证明策略不同于通常用于证明基于无限宽度（或深度）神经网络的通用逼近结果的典型策略，这可能具有独立的意义。我们在非线性合成函数上进行实验，能够准确建模并估计特征归因，在某些情况下甚至能估计高阶项，这证明了这种架构的表示能力和可解释性。为了进一步展示CoFrNets的强大功能，我们在涵盖表格、文本和图像模态的七个真实数据集上进行了实验，结果表明它们与其它可解释模型和多层感知器相比，性能相当或显著更好，有时甚至接近最先进模型的准确性。", "summary": "本文提出了一种名为CoFrNets的新型可解释神经网络架构，其灵感来源于连分数。该架构不仅可以高效训练和解释，而且被证明是通用逼近器，其证明策略具有新颖性。实验结果表明，CoFrNets在合成函数上具有强大的表示能力和可解释性，能够准确估计特征归因和高阶项。在多个真实数据集上，CoFrNets的性能优于或媲美其他可解释模型和多层感知机，有时甚至接近最先进模型的水平。", "keywords": "可解释神经网络, 连分数, CoFrNets, 通用逼近器, 特征归因", "comments": "该论文通过引入连分数这一数论概念，为构建可解释神经网络架构提供了新颖的视角和方法。其在通用逼近器证明策略上的创新也具有独立的理论价值。CoFrNets在保持高性能的同时，强调了模型的可解释性，这在当前深度学习“黑箱”问题日益突出的背景下显得尤为重要，有望推动可解释AI领域的发展。"}}
{"id": "2506.05386", "title": "Beyond RAG: Reinforced Reasoning Augmented Generation for Clinical Notes", "authors": ["Lo Pang-Yun Ting", "Chengshuai Zhao", "Yu-Hua Zeng", "Yuan Jee Lim", "Kun-Ta Chuang"], "summary": "Clinical note generation aims to automatically produce free-text summaries of\na patient's condition and diagnostic process, with discharge instructions being\na representative long-form example. While recent large language model\n(LLM)-based methods pre-trained on general clinical corpora show promise in\nclinical text generation, they fall short in producing long-form notes from\nlimited patient information. In this paper, we propose R2AG, the first\nreinforced retriever for long-form discharge instruction generation based on\npre-admission data. R2AG is trained with reinforcement learning to retrieve\nreasoning paths from a medical knowledge graph, providing explicit semantic\nguidance to the LLM. To bridge the information gap, we propose Group-Based\nRetriever Optimization (GRO) which improves retrieval quality with\ngroup-relative rewards, encouraging reasoning leaps for deeper inference by the\nLLM. Comprehensive experiments on the MIMIC-IV-Note dataset show that R2AG\noutperforms baselines in both clinical efficacy and natural language generation\nmetrics. Further analysis reveals that R2AG fills semantic gaps in sparse input\nscenarios, and retrieved reasoning paths help LLMs avoid clinical\nmisinterpretation by focusing on key evidence and following coherent reasoning.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05386v1", "AI": {"title_translation": "超越RAG：用于临床笔记的强化推理增强生成", "tldr": "R2AG是一种基于强化学习的检索器，用于从有限的患者信息中生成长篇临床出院指导，通过检索医学知识图谱中的推理路径来弥补信息差距并提高生成质量。", "motivation": "目前的LLM-based方法在临床文本生成方面表现出潜力，但在从有限的患者信息生成长篇笔记方面存在不足，特别是在生成出院指导时。", "method": "本文提出了R2AG，第一个用于基于入院前数据生成长篇出院指导的强化检索器。R2AG通过强化学习训练，从医学知识图谱中检索推理路径，为LLM提供明确的语义指导。为弥补信息差距，提出了Group-Based Retriever Optimization (GRO)，通过组相对奖励提高检索质量，鼓励LLM进行更深层次的推理。", "result": "在MIMIC-IV-Note数据集上的综合实验表明，R2AG在临床疗效和自然语言生成指标上均优于基线模型。进一步分析显示，R2AG弥补了稀疏输入场景中的语义空白，并且检索到的推理路径通过关注关键证据和遵循连贯推理，帮助LLM避免临床误解。", "conclusion": "R2AG通过结合强化学习和医学知识图谱检索，有效解决了LLM在从有限信息生成长篇临床笔记时的不足，提高了生成质量和临床准确性。", "translation": "临床笔记生成旨在自动生成患者病情和诊断过程的自由文本摘要，其中出院指导是一个代表性的长篇例子。尽管最近基于大型语言模型（LLM）的方法在通用临床语料库上进行预训练，在临床文本生成方面显示出潜力，但它们在从有限的患者信息中生成长篇笔记方面有所欠缺。在本文中，我们提出了R2AG，这是第一个基于入院前数据用于长篇出院指导生成的强化检索器。R2AG通过强化学习进行训练，以从医学知识图谱中检索推理路径，为LLM提供明确的语义指导。为了弥补信息差距，我们提出了基于组的检索器优化（GRO），它通过组相对奖励提高了检索质量，鼓励LLM进行更深层次的推理。在MIMIC-IV-Note数据集上的综合实验表明，R2AG在临床疗效和自然语言生成指标上均优于基线模型。进一步分析表明，R2AG填补了稀疏输入场景中的语义空白，并且检索到的推理路径通过关注关键证据和遵循连贯推理，帮助LLM避免临床误解。", "summary": "本文提出了一种名为R2AG的新型强化检索增强生成框架，旨在解决大型语言模型在从有限患者信息生成长篇临床笔记（如出院指导）时的不足。R2AG利用强化学习从医学知识图谱中检索推理路径，为LLM提供语义指导。此外，引入了Group-Based Retriever Optimization (GRO)来优化检索质量并促进深度推理。实验结果表明，R2AG在临床有效性和生成质量方面均优于现有基线，并能有效弥补信息空白，避免临床误解。", "keywords": "临床笔记生成, 强化学习, 知识图谱, 大型语言模型, RAG", "comments": "这篇论文通过结合强化学习和医学知识图谱，创新性地解决了长篇临床笔记生成中信息稀疏的问题。其核心贡献在于R2AG框架，特别是利用强化学习进行推理路径检索，以及GRO方法对检索质量的提升。这对于提高临床文本生成的准确性和可靠性具有重要意义，尤其是在医疗健康领域，误解可能导致严重后果。"}}
{"id": "2506.05900", "title": "Differentially Private Explanations for Clusters", "authors": ["Amir Gilad", "Tova Milo", "Kathy Razmadze", "Ron Zadicario"], "summary": "The dire need to protect sensitive data has led to various flavors of privacy\ndefinitions. Among these, Differential privacy (DP) is considered one of the\nmost rigorous and secure notions of privacy, enabling data analysis while\npreserving the privacy of data contributors. One of the fundamental tasks of\ndata analysis is clustering , which is meant to unravel hidden patterns within\ncomplex datasets. However, interpreting clustering results poses significant\nchallenges, and often necessitates an extensive analytical process.\nInterpreting clustering results under DP is even more challenging, as analysts\nare provided with noisy responses to queries, and longer, manual exploration\nsessions require additional noise to meet privacy constraints. While increasing\nattention has been given to clustering explanation frameworks that aim at\nassisting analysts by automatically uncovering the characteristics of each\ncluster, such frameworks may also disclose sensitive information within the\ndataset, leading to a breach in privacy. To address these challenges, we\npresent DPClustX, a framework that provides explanations for black-box\nclustering results while satisfying DP. DPClustX takes as input the sensitive\ndataset alongside privately computed clustering labels, and outputs a global\nexplanation, emphasizing prominent characteristics of each cluster while\nguaranteeing DP. We perform an extensive experimental analysis of DPClustX on\nreal data, showing that it provides insightful and accurate explanations even\nunder tight privacy constraints.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05900v1", "AI": {"title_translation": "差分隐私聚类解释", "tldr": "提出DPClustX框架，为聚类结果提供差分隐私保护的解释，即使在严格的隐私限制下也能提供准确且有见地的解释。", "motivation": "保护敏感数据是当务之急，差分隐私是严格的隐私保护方法。数据分析中的聚类任务旨在揭示隐藏模式，但解释聚类结果具有挑战性。在差分隐私下解释聚类结果更具挑战性，因为查询响应带有噪声，且手动探索需要额外噪声。现有的聚类解释框架可能泄露敏感信息，导致隐私泄露。", "method": "本文提出了DPClustX框架，该框架在满足差分隐私的同时，为黑盒聚类结果提供解释。DPClustX以敏感数据集和私下计算的聚类标签作为输入，并输出全局解释，强调每个聚类的显著特征，同时保证差分隐私。", "result": "在真实数据上对DPClustX进行了广泛的实验分析，结果表明它即使在严格的隐私限制下也能提供有见地和准确的解释。", "conclusion": "DPClustX框架成功地解决了在差分隐私下解释聚类结果的挑战，提供了准确且受隐私保护的聚类解释。", "translation": "保护敏感数据的迫切需求催生了各种形式的隐私定义。其中，差分隐私（DP）被认为是最严格、最安全的隐私概念之一，它能够在保护数据贡献者隐私的同时进行数据分析。数据分析的基本任务之一是聚类，旨在揭示复杂数据集中的隐藏模式。然而，解释聚类结果带来了巨大的挑战，通常需要 extensive 的分析过程。在差分隐私下解释聚类结果更具挑战性，因为分析师获得的查询响应带有噪声，并且更长、手动的探索会话需要额外的噪声才能满足隐私约束。虽然人们越来越关注旨在通过自动揭示每个聚类特征来协助分析师的聚类解释框架，但此类框架也可能泄露数据集中的敏感信息，导致隐私泄露。为了应对这些挑战，我们提出了DPClustX，一个在满足差分隐私的同时为黑盒聚类结果提供解释的框架。DPClustX将敏感数据集与私下计算的聚类标签作为输入，并输出全局解释，强调每个聚类的显著特征，同时保证差分隐私。我们在真实数据上对DPClustX进行了广泛的实验分析，表明即使在严格的隐私限制下，它也能提供有见地和准确的解释。", "summary": "本文提出了DPClustX框架，旨在解决在差分隐私（DP）下解释聚类结果的挑战。鉴于数据隐私的重要性以及现有聚类解释方法可能泄露敏感信息的风险，DPClustX提供了一种机制，可以在满足DP的同时，为黑盒聚类结果生成全局解释，突出每个聚类的关键特征。实验结果表明，该框架即使在严格的隐私约束下，也能提供准确且富有洞察力的解释。", "keywords": "差分隐私, 聚类解释, 数据隐私, DPClustX, 黑盒模型解释", "comments": "该论文创新性地将差分隐私应用于聚类解释领域，解决了在保护数据隐私的同时理解聚类结果的难题。其提出的DPClustX框架为需要对敏感数据进行聚类分析的场景提供了重要的工具，增强了模型的可解释性和隐私安全性，具有重要的实践意义。"}}
{"id": "2506.05985", "title": "Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning", "authors": ["Yuheng Lei", "Sitong Mao", "Shunbo Zhou", "Hongyuan Zhang", "Xuelong Li", "Ping Luo"], "summary": "A generalist agent must continuously learn and adapt throughout its lifetime,\nachieving efficient forward transfer while minimizing catastrophic forgetting.\nPrevious work within the dominant pretrain-then-finetune paradigm has explored\nparameter-efficient fine-tuning for single-task adaptation, effectively\nsteering a frozen pretrained model with a small number of parameters. However,\nin the context of lifelong learning, these methods rely on the impractical\nassumption of a test-time task identifier and restrict knowledge sharing among\nisolated adapters. To address these limitations, we propose Dynamic Mixture of\nProgressive Parameter-Efficient Expert Library (DMPEL) for lifelong robot\nlearning. DMPEL progressively learn a low-rank expert library and employs a\nlightweight router to dynamically combine experts into an end-to-end policy,\nfacilitating flexible behavior during lifelong adaptation. Moreover, by\nleveraging the modular structure of the fine-tuned parameters, we introduce\ncoefficient replay to guide the router in accurately retrieving frozen experts\nfor previously encountered tasks, thereby mitigating catastrophic forgetting.\nThis method is significantly more storage- and computationally-efficient than\napplying demonstration replay to the entire policy. Extensive experiments on\nthe lifelong manipulation benchmark LIBERO demonstrate that our framework\noutperforms state-of-the-art lifelong learning methods in success rates across\ncontinual adaptation, while utilizing minimal trainable parameters and storage.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05985v1", "AI": {"title_translation": "终身机器人学习中渐进式参数高效专家库的动态混合", "tldr": "DMPEL是一种新颖的终身机器人学习方法，它通过动态混合参数高效的专家库来解决灾难性遗忘和知识共享受限的问题，并在实验中取得了最先进的性能。", "motivation": "现有的预训练-微调范式在终身学习中存在局限性，例如需要测试时任务识别器，以及限制了孤立适配器之间的知识共享，这导致了灾难性遗忘和效率低下。", "method": "本文提出了动态渐进式参数高效专家库（DMPEL），用于终身机器人学习。DMPEL逐步学习一个低秩专家库，并使用一个轻量级路由器动态组合专家以形成端到端策略，从而促进终身适应过程中的灵活行为。此外，通过利用微调参数的模块化结构，引入了系数回放来指导路由器准确检索先前任务的冻结专家，从而减轻灾难性遗忘。", "result": "在终身操作基准LIBERO上的大量实验表明，DMPEL框架在持续适应的成功率方面优于最先进的终身学习方法，同时使用最少的可训练参数和存储空间。", "conclusion": "DMPEL通过动态混合参数高效的专家库和利用系数回放机制，有效解决了终身机器人学习中的灾难性遗忘和知识共享问题，并在性能和效率上超越了现有方法。", "translation": "一个通用代理必须在其生命周期内持续学习和适应，实现高效的正向迁移，同时最大限度地减少灾难性遗忘。先前在主流的预训练-微调范式中的工作探索了单任务适应的参数高效微调，有效地以少量参数引导一个冻结的预训练模型。然而，在终身学习的背景下，这些方法依赖于不切实际的测试时任务标识符假设，并限制了孤立适配器之间的知识共享。为了解决这些限制，我们提出了用于终身机器人学习的渐进式参数高效专家库的动态混合（DMPEL）。DMPEL逐步学习一个低秩专家库，并采用一个轻量级路由器动态地将专家组合成一个端到端策略，促进终身适应过程中的灵活行为。此外，通过利用微调参数的模块化结构，我们引入了系数回放来指导路由器准确检索先前遇到的任务的冻结专家，从而减轻灾难性遗忘。这种方法比将演示回放应用于整个策略更节省存储和计算效率。在终身操作基准LIBERO上的大量实验表明，我们的框架在持续适应的成功率方面优于最先进的终身学习方法，同时使用最少的可训练参数和存储。", "summary": "本文提出了一种名为动态渐进式参数高效专家库（DMPEL）的新方法，用于解决终身机器人学习中灾难性遗忘和知识共享受限的问题。DMPEL通过逐步学习一个低秩专家库，并利用轻量级路由器动态组合专家来形成策略。它还引入了系数回放机制，以有效检索冻结专家并减轻灾难性遗忘。实验证明，DMPEL在持续适应的成功率上优于现有方法，并且在参数和存储效率方面表现出色。", "keywords": "终身学习, 机器人学习, 参数高效, 专家系统, 灾难性遗忘", "comments": "DMPEL的创新之处在于其动态混合专家库的架构和系数回放机制，这有效地解决了终身学习中长期存在的灾难性遗忘问题，并提高了知识共享的效率。其参数和存储效率也使其在实际机器人应用中具有重要意义。"}}
{"id": "2506.05439", "title": "LLMs Can Compensate for Deficiencies in Visual Representations", "authors": ["Sho Takishita", "Jay Gala", "Abdelrahman Mohamed", "Kentaro Inui", "Yova Kementchedjhieva"], "summary": "Many vision-language models (VLMs) that prove very effective at a range of\nmultimodal task, build on CLIP-based vision encoders, which are known to have\nvarious limitations. We investigate the hypothesis that the strong language\nbackbone in VLMs compensates for possibly weak visual features by\ncontextualizing or enriching them. Using three CLIP-based VLMs, we perform\ncontrolled self-attention ablations on a carefully designed probing task. Our\nfindings show that despite known limitations, CLIP visual representations offer\nready-to-read semantic information to the language decoder. However, in\nscenarios of reduced contextualization in the visual representations, the\nlanguage decoder can largely compensate for the deficiency and recover\nperformance. This suggests a dynamic division of labor in VLMs and motivates\nfuture architectures that offload more visual processing to the language\ndecoder.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05439v1", "AI": {"title_translation": "LLMs 可以弥补视觉表征的不足", "tldr": "VLMs中的大型语言模型（LLMs）可以弥补视觉表征的不足，通过实验发现语言解码器能补偿视觉缺陷并恢复性能，提示未来架构可将更多视觉处理交给语言解码器。", "motivation": "许多在多模态任务中表现出色的视觉-语言模型（VLMs）建立在基于CLIP的视觉编码器之上，而这些编码器已知存在各种局限性。研究旨在验证VLM中强大的语言骨干是否能通过语境化或丰富视觉特征来弥补其可能存在的弱点。", "method": "使用三个基于CLIP的VLM，在一个精心设计的探测任务上进行受控的自注意力消融实验。", "result": "尽管存在已知局限性，CLIP视觉表征能向语言解码器提供现成的语义信息。在视觉表征语境化减少的情况下，语言解码器能很大程度上弥补不足并恢复性能。", "conclusion": "这表明VLMs中存在动态的任务分工，并激励未来的架构将更多的视觉处理卸载到语言解码器。", "translation": "许多在多模态任务中表现出色的视觉-语言模型（VLMs）建立在基于CLIP的视觉编码器之上，而这些编码器已知存在各种局限性。我们研究了VLM中强大的语言骨干是否能通过语境化或丰富视觉特征来弥补可能较弱的视觉特征的假设。我们使用三个基于CLIP的VLM，在一个精心设计的探测任务上进行了受控的自注意力消融实验。我们的发现表明，尽管存在已知局限性，CLIP视觉表征仍能向语言解码器提供现成的语义信息。然而，在视觉表征语境化减少的情况下，语言解码器能很大程度上弥补这些不足并恢复性能。这表明VLMs中存在动态的任务分工，并激励未来的架构将更多的视觉处理卸载到语言解码器。", "summary": "本文探讨了视觉-语言模型（VLMs）中大型语言模型（LLMs）如何弥补基于CLIP的视觉编码器存在的局限性。通过对三种CLIP-based VLM进行受控实验，研究发现尽管CLIP视觉表征有其局限性，但能提供语义信息，并且在视觉信息不足时，语言解码器能够显著补偿并恢复模型性能。这揭示了VLM中视觉与语言模块间的动态协作，并为未来将更多视觉处理任务交由语言解码器的新架构提供了方向。", "keywords": "视觉-语言模型, LLMs, 视觉表征, CLIP, 补偿机制", "comments": "本文提出了一个关于VLMs中视觉与语言模块动态协作的重要见解，即LLMs能够有效补偿视觉表征的不足。这一发现挑战了传统上对视觉编码器性能的单一依赖，并为设计更高效、鲁棒的多模态模型提供了新思路。其创新性在于通过实验验证了语言骨干在视觉处理中的补偿能力，对未来VLMs架构的优化具有指导意义。"}}
{"id": "2506.05596", "title": "Zero-shot protein stability prediction by inverse folding models: a free energy interpretation", "authors": ["Jes Frellsen", "Maher M. Kassem", "Tone Bengtsen", "Lars Olsen", "Kresten Lindorff-Larsen", "Jesper Ferkinghoff-Borg", "Wouter Boomsma"], "summary": "Inverse folding models have proven to be highly effective zero-shot\npredictors of protein stability. Despite this success, the link between the\namino acid preferences of an inverse folding model and the free-energy\nconsiderations underlying thermodynamic stability remains incompletely\nunderstood. A better understanding would be of interest not only from a\ntheoretical perspective, but also potentially provide the basis for stronger\nzero-shot stability prediction. In this paper, we take steps to clarify the\nfree-energy foundations of inverse folding models. Our derivation reveals the\nstandard practice of likelihood ratios as a simplistic approximation and\nsuggests several paths towards better estimates of the relative stability. We\nempirically assess these approaches and demonstrate that considerable gains in\nzero-shot performance can be achieved with fairly simple means.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05596v1", "AI": {"title_translation": "逆向折叠模型在零样本蛋白质稳定性预测中的应用：一种自由能解释", "tldr": "本文阐明了逆向折叠模型与蛋白质自由能稳定性的关系，并提出了改进零样本蛋白质稳定性预测的方法，通过简单方法实现了显著性能提升。", "motivation": "逆向折叠模型在零样本蛋白质稳定性预测方面表现出色，但其氨基酸偏好与热力学稳定性背后的自由能考虑之间的联系尚不完全清楚。更好地理解这一联系不仅具有理论意义，还可能为更强的零样本稳定性预测奠定基础。", "method": "本文通过推导阐明了逆向折叠模型的自由能基础，揭示了似然比的标准做法是一种简化近似，并提出了几种获得更好相对稳定性估计的途径。研究人员对这些方法进行了实证评估。", "result": "通过相当简单的方法可以实现零样本预测性能的显著提升。", "conclusion": "通过澄清逆向折叠模型的自由能基础并改进估计方法，可以显著提高零样本蛋白质稳定性预测的性能。", "translation": "逆向折叠模型已被证明是非常有效的蛋白质稳定性零样本预测器。尽管取得了成功，但逆向折叠模型的氨基酸偏好与热力学稳定性背后的自由能考虑之间的联系仍未完全理解。更好地理解这一点不仅具有理论意义，而且可能为更强的零样本稳定性预测提供基础。在本文中，我们采取措施阐明逆向折叠模型的自由能基础。我们的推导揭示了似然比的标准做法是一种简化近似，并提出了几种获得更好相对稳定性估计的途径。我们对这些方法进行了实证评估，并证明通过相当简单的方法可以实现零样本性能的显著提升。", "summary": "本文旨在阐明逆向折叠模型在零样本蛋白质稳定性预测中氨基酸偏好与自由能之间的联系。研究通过理论推导揭示了现有似然比方法的局限性，并提出了改进相对稳定性估计的新途径。实证评估表明，这些方法能够显著提升零样本预测性能。", "keywords": "蛋白质稳定性预测, 逆向折叠模型, 零样本学习, 自由能, 似然比", "comments": "本文通过深入探讨逆向折叠模型的自由能基础，不仅填补了理论理解上的空白，还为零样本蛋白质稳定性预测提供了实用的改进方法。其创新之处在于对现有似然比方法的批判性分析，并提出了更精确的自由能解释，这对于蛋白质工程和药物设计等领域具有重要意义。"}}
{"id": "2506.05387", "title": "Advancing Decoding Strategies: Enhancements in Locally Typical Sampling for LLMs", "authors": ["Jaydip Sen", "Saptarshi Sengupta. Subhasis Dasgupta"], "summary": "This chapter explores advancements in decoding strategies for large language\nmodels (LLMs), focusing on enhancing the Locally Typical Sampling (LTS)\nalgorithm. Traditional decoding methods, such as top-k and nucleus sampling,\noften struggle to balance fluency, diversity, and coherence in text generation.\nTo address these challenges, Adaptive Semantic-Aware Typicality Sampling (ASTS)\nis proposed as an improved version of LTS, incorporating dynamic entropy\nthresholding, multi-objective scoring, and reward-penalty adjustments. ASTS\nensures contextually coherent and diverse text generation while maintaining\ncomputational efficiency. Its performance is evaluated across multiple\nbenchmarks, including story generation and abstractive summarization, using\nmetrics such as perplexity, MAUVE, and diversity scores. Experimental results\ndemonstrate that ASTS outperforms existing sampling techniques by reducing\nrepetition, enhancing semantic alignment, and improving fluency.", "comment": "This is the accepted but pre-reviewed version of the chapter that has\n  been accepted for publication in the Springer volume 'Decision-Making in\n  Computational Intelligence-Based Systems,' edited by Witold Pedrycz, Gilberto\n  Rivera, Rose Ma Rodriguez, and Salvador Ibarra Martinez. The chapter is 39\n  pages long, and it contains 2 figures and 6 tables. This is NOT the final\n  camera-ready version", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05387v1", "AI": {"title_translation": "推进解码策略：增强大型语言模型中的局部典型采样", "tldr": "通过引入自适应语义感知典型性采样（ASTS）来改进大型语言模型（LLMs）的文本生成解码策略，以平衡流畅性、多样性和连贯性。", "motivation": "传统的解码方法（如top-k和nucleus采样）在大型语言模型（LLMs）的文本生成中难以平衡流畅性、多样性和连贯性。", "method": "本文提出了一种改进的局部典型性采样（LTS）算法，称为自适应语义感知典型性采样（ASTS）。ASTS结合了动态熵阈值、多目标评分和奖惩调整。其性能通过故事生成和抽象摘要等多个基准进行评估，并使用困惑度、MAUVE和多样性分数等指标。", "result": "实验结果表明，ASTS通过减少重复、增强语义对齐和提高流畅性，优于现有的采样技术。", "conclusion": "ASTS有效解决了传统解码方法的局限性，从而在大型语言模型中生成更连贯、多样和流畅的文本。", "translation": "本章探讨了大型语言模型（LLMs）解码策略的进展，重点是增强局部典型性采样（LTS）算法。传统的解码方法，如top-k和nucleus采样，在文本生成中往往难以平衡流畅性、多样性和连贯性。为了解决这些挑战，本文提出了自适应语义感知典型性采样（ASTS）作为LTS的改进版本，它结合了动态熵阈值、多目标评分和奖惩调整。ASTS在保持计算效率的同时，确保了上下文连贯和多样化的文本生成。其性能在多个基准上进行了评估，包括故事生成和抽象摘要，使用困惑度、MAUVE和多样性分数等指标。实验结果表明，ASTS通过减少重复、增强语义对齐和提高流畅性，优于现有的采样技术。", "summary": "本章提出了一种名为自适应语义感知典型性采样（ASTS）的解码策略，旨在改进大型语言模型（LLMs）中的局部典型性采样（LTS）。针对传统解码方法在平衡文本生成流畅性、多样性和连贯性方面的不足，ASTS引入了动态熵阈值、多目标评分和奖惩调整。通过在故事生成和抽象摘要等任务上的评估，ASTS在减少重复、提升语义对齐和增强流畅性方面表现出优于现有采样技术的性能，同时保持了计算效率。", "keywords": "解码策略, 大型语言模型, 局部典型性采样, 自适应语义感知典型性采样, 文本生成", "comments": "该论文提出了一种创新的解码策略ASTS，通过增强LTS解决了LLM文本生成中的关键挑战。其结合动态熵、多目标评分和奖惩调整的多方面方法是一个显著的创新点。对平衡流畅性、多样性和连贯性的关注以及所展示的改进，突显了其对LLM实际应用的重要性。"}}
{"id": "2506.05932", "title": "Combating Reentrancy Bugs on Sharded Blockchains", "authors": ["Roman Kashitsyn", "Robin Künzler", "Ognjen Marić", "Lara Schmid"], "summary": "Reentrancy is a well-known source of smart contract bugs on Ethereum, leading\ne.g. to double-spending vulnerabilities in DeFi applications. But less is known\nabout this problem in other blockchains, which can have significantly different\nexecution models. Sharded blockchains in particular generally use an\nasynchronous messaging model that differs substantially from the synchronous\nand transactional model of Ethereum. We study the features of this model and\nits effect on reentrancy bugs on three examples: the Internet Computer (ICP)\nblockchain, NEAR Protocol, and MultiversX. We argue that this model, while\nuseful for improving performance, also makes it easier to introduce reentrancy\nbugs. For example, reviews of the pre-production versions of some of the most\ncritical ICP smart contracts found that 66% (10/15) of the reviewed contracts\n-- written by expert authors -- contained reentrancy bugs of medium or high\nseverity, with potential damages in tens of millions of dollars. We evaluate\nexisting Ethereum programming techniques (in particular the\neffects-checks-interactions pattern, and locking) to prevent reentrancy bugs in\nthe context of this new messaging model and identify some issues with them. We\nthen present novel Rust and Motoko patterns that can be leveraged on ICP to\nsolve these issues. Finally, we demonstrate that the formal verification tool\nTLA+ can be used to find and eliminate such bugs in real world smart contracts\non sharded blockchains.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.05932v1", "AI": {"title_translation": "在分片区块链上对抗重入漏洞", "tldr": "分片区块链中的重入漏洞普遍且严重，原因是其异步模型；传统以太坊的修复方法存在问题，但新的模式和TLA+可以提供帮助。", "motivation": "重入漏洞是以太坊上智能合约的已知问题，但在具有显著不同执行模型（如异步消息模型）的其他区块链（特别是分片区块链）中，对此问题的了解较少。这种模型可能使重入漏洞更容易引入，并可能导致数千万美元的潜在损失。", "method": "本文研究了分片区块链中异步消息模型的特性及其对重入漏洞的影响，以互联网计算机 (ICP) 区块链、NEAR Protocol 和 MultiversX 为例。它评估了现有以太坊编程技术（特别是 effects-checks-interactions 模式和锁定）在这一新消息模型背景下预防重入漏洞的效果，并识别出其中的问题。然后，提出了可用于 ICP 的新型 Rust 和 Motoko 模式来解决这些问题。最后，演示了形式化验证工具 TLA+ 可用于在分片区块链的真实世界智能合约中发现并消除此类漏洞。", "result": "分片区块链的异步模型虽然有助于提高性能，但也更容易引入重入漏洞。对一些最关键的 ICP 智能合约的预生产版本审查发现，66%（15个中的10个）的合约包含中等或高严重性的重入漏洞，可能造成数千万美元的损失。现有的以太坊编程技术在新的消息模型下存在问题。本文提出了可在 ICP 上利用的新型 Rust 和 Motoko 模式来解决这些问题，并证明形式化验证工具 TLA+ 可用于发现和消除分片区块链真实世界智能合约中的此类漏洞。", "conclusion": "分片区块链的异步模型使得重入漏洞更容易引入。为了解决这些漏洞，需要新的编程模式（如 Rust 和 Motoko）和形式化验证工具（如 TLA+），这些方法已被证明在发现和消除分片区块链上的真实世界智能合约中的重入漏洞方面是有效的。", "translation": "重入是以太坊上智能合约漏洞的一个众所周知的来源，例如导致 DeFi 应用程序中的双重支付漏洞。但对于其他可能具有显著不同执行模型的区块链中的这个问题知之甚少。特别是分片区块链通常使用异步消息模型，这与以太坊的同步和事务模型大相径庭。我们以互联网计算机 (ICP) 区块链、NEAR Protocol 和 MultiversX 为例，研究了这种模型的特点及其对重入漏洞的影响。我们认为，这种模型虽然有助于提高性能，但也更容易引入重入漏洞。例如，对一些最关键的 ICP 智能合约预生产版本的审查发现，66%（15个中的10个）的被审查合约——由专家作者编写——包含中等或高严重性的重入漏洞，潜在损失达数千万美元。我们评估了现有的以太坊编程技术（特别是 effects-checks-interactions 模式和锁定）在这一新消息模型背景下预防重入漏洞的效果，并识别出其中的一些问题。然后，我们提出了可在 ICP 上利用的新型 Rust 和 Motoko 模式来解决这些问题。最后，我们证明了形式化验证工具 TLA+ 可用于在分片区块链的真实世界智能合约中发现并消除此类漏洞。", "summary": "本文研究了分片区块链中的重入漏洞，这类区块链采用与以太坊不同的异步消息模型。研究指出，尽管该模型有利于性能提升，但却更容易引入重入漏洞，并通过对关键 ICP 智能合约的审查数据证实了高漏洞率。论文评估了现有以太坊预防技术在此新环境下的局限性，并提出了新颖的 Rust 和 Motoko 编程模式。此外，研究还展示了形式化验证工具 TLA+ 在检测和消除这些漏洞方面的有效性。", "keywords": "重入漏洞, 分片区块链, 智能合约, 形式化验证, TLA+", "comments": "该论文揭示了分片区块链这一新兴架构中的一个关键安全问题（重入漏洞），考虑到其日益增长的采用，这具有重要意义。其创新之处在于针对不同的执行模型，提出了并适应了新的解决方案（Rust/Motoko 模式，TLA+ 应用），超越了以太坊特有的解决方案。所提供的真实世界数据（66%的漏洞率）强调了该问题的严重性。"}}
{"id": "2506.06016", "title": "Equivariant Filter for Relative Attitude and Target Angular Velocity Estimation", "authors": ["Gil Serrano", "Bruno J. Guerreiro", "Pedro Lourenço", "Rita Cunha"], "summary": "Accurate estimation of the relative attitude and angular velocity between two\nrigid bodies is fundamental in aerospace applications such as spacecraft\nrendezvous and docking. In these scenarios, a chaser vehicle must determine the\norientation and angular velocity of a target object using onboard sensors. This\nwork addresses the challenge of designing an Equivariant Filter (EqF) that can\nreliably estimate both the relative attitude and the target angular velocity\nusing noisy observations of two known, non-collinear vectors fixed in the\ntarget frame. To derive the EqF, a symmetry for the system is proposed and an\nequivariant lift onto the symmetry group is calculated. Observability and\nconvergence properties are analyzed. Simulations demonstrate the filter's\nperformance, with Monte Carlo runs yielding statistically significant results.\nThe impact of low-rate measurements is also examined and a strategy to mitigate\nthis effect is proposed. Experimental results, using fiducial markers and both\nconventional and event cameras for measurement acquisition, further validate\nthe approach, confirming its effectiveness in a realistic setting.", "comment": "This work has been submitted to the IEEE for possible publication", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.06016v1", "AI": {"title_translation": "相对姿态和目标角速度估计的等变滤波器", "tldr": "本文提出了一种等变滤波器（EqF），用于在航天应用中利用噪声观测数据，可靠地估计两个刚体之间的相对姿态和目标角速度，并通过仿真和实验验证了其性能。", "motivation": "在航天应用（如航天器交会与对接）中，准确估计两个刚体之间的相对姿态和角速度至关重要。追踪飞行器需要利用机载传感器确定目标物体的姿态和角速度。", "method": "提出了一种系统对称性并计算了对称群上的等变提升，以推导等变滤波器（EqF）。分析了可观测性和收敛性。研究了低速率测量的影响并提出了缓解策略。", "result": "仿真结果（蒙特卡洛运行）表明该滤波器性能良好并具有统计学意义。实验结果（使用基准标记、传统相机和事件相机）进一步验证了该方法的有效性，证实了其在实际环境中的性能。", "conclusion": "所提出的等变滤波器能够可靠地估计相对姿态和目标角速度，并通过仿真和实验验证了其在实际航天应用中的有效性。", "translation": "相对姿态和目标角速度估计的等变滤波器\n\n准确估计两个刚体之间的相对姿态和角速度在航天应用（如航天器交会与对接）中至关重要。在这些场景中，追踪飞行器必须利用机载传感器确定目标物体的方向和角速度。这项工作旨在解决设计一种等变滤波器（EqF）的挑战，该滤波器能够利用目标坐标系中两个已知非共线向量的噪声观测数据，可靠地估计相对姿态和目标角速度。为了推导等变滤波器，提出了一种系统对称性并计算了对称群上的等变提升。分析了可观测性和收敛性。仿真结果表明了该滤波器的性能，蒙特卡洛运行产生了具有统计学意义的结果。还研究了低速率测量的影响，并提出了一种缓解这种影响的策略。使用基准标记以及传统相机和事件相机进行测量采集的实验结果进一步验证了该方法，证实了其在实际环境中的有效性。", "summary": "本文提出了一种等变滤波器（EqF），旨在解决航天器交会与对接等航天应用中，利用噪声观测数据准确估计两个刚体之间相对姿态和目标角速度的挑战。通过提出系统对称性并计算等变提升来推导EqF，并分析了其可观测性和收敛性。仿真和实验结果（包括对低速率测量的研究）均验证了该方法在实际环境中的有效性和可靠性。", "keywords": "等变滤波器, 相对姿态估计, 角速度估计, 航天器交会, 刚体动力学", "comments": "该论文创新性地将等变滤波应用于航天器相对姿态和角速度估计，解决了传统方法在处理噪声观测和低速率测量时的局限性。其提出的对称性分析和等变提升计算为相关领域的研究提供了新的视角。通过仿真和实际实验的验证，该方法在实际应用中具有重要潜力。"}}
{"id": "2506.05440", "title": "BYO-Eval: Build Your Own Dataset for Fine-Grained Visual Assessment of Multimodal Language Models", "authors": ["Ludovic Arnould", "Salim Khazem", "Hugues Ali Mehenni"], "summary": "Visual Language Models (VLMs) are now sufficiently advanced to support a\nbroad range of applications, including answering complex visual questions, and\nare increasingly expected to interact with images in varied ways. To evaluate\nthem, current benchmarks often focus on specific domains (e.g., reading\ncharts), constructing datasets of annotated real images paired with pre-defined\nMultiple Choice Questions (MCQs) to report aggregate accuracy scores. However,\nsuch benchmarks entail high annotation costs, risk information leakage, and do\nnot clarify whether failures stem from limitations in visual perception,\nreasoning, or general knowledge. We propose a new evaluation methodology,\ninspired by ophthalmologic diagnostics, leveraging procedural generation of\nsynthetic images to obtain control over visual attributes and precisely reveal\nperception failures in VLMs. Specifically, we build collections of images with\ngradually more challenging variations in the content of interest (e.g., number\nof objects in a counting task) while holding other visual parameters constant.\nThis diagnostic allows systematic stress testing and fine-grained failure\nanalysis, shifting the focus from coarse benchmarking toward targeted and\ninterpretable assessment of VLM capabilities. Our code is available at\nhttps://github.com/byoeval/BYO-EVAL.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05440v1", "AI": {"title_translation": "BYO-Eval: 构建您自己的数据集用于多模态语言模型的细粒度视觉评估", "tldr": "BYO-Eval 提出一种新的评估方法，通过程序化生成合成图像来精细诊断视觉语言模型（VLMs）的视觉感知失败，以克服现有基准测试的局限性。", "motivation": "现有的视觉语言模型（VLMs）评估基准存在高昂的标注成本、信息泄露风险，并且无法明确失败是源于视觉感知、推理还是通用知识的限制。", "method": "BYO-Eval 提出一种受眼科诊断启发的评估方法，利用程序化生成合成图像来控制视觉属性，以精确揭示 VLMs 的感知失败。具体来说，它构建了图像集合，其中感兴趣内容（如计数任务中的对象数量）的变化逐渐增加挑战性，同时保持其他视觉参数不变。", "result": "这种诊断方法允许对 VLMs 进行系统性压力测试和细粒度故障分析，将评估的重点从粗略的基准测试转向针对性、可解释的能力评估。", "conclusion": "BYO-Eval 提供了一种新的、可解释的评估范式，能够对视觉语言模型进行细致的诊断，从而更清晰地理解其能力和局限性。", "translation": "视觉语言模型（VLMs）现在已经足够先进，可以支持广泛的应用，包括回答复杂的视觉问题，并且越来越期望以各种方式与图像进行交互。为了评估它们，当前的基准测试通常侧重于特定领域（例如，阅读图表），构建带注释的真实图像数据集，并配以预定义的单项选择题（MCQs）来报告总准确率分数。然而，此类基准测试需要高昂的标注成本，存在信息泄露的风险，并且无法阐明失败是源于视觉感知、推理还是通用知识的限制。我们提出了一种新的评估方法，灵感来自眼科诊断，利用程序化生成合成图像来控制视觉属性，并精确揭示 VLMs 中的感知失败。具体来说，我们构建了图像集合，其中感兴趣内容（例如，计数任务中的对象数量）的变化逐渐增加挑战性，同时保持其他视觉参数不变。这种诊断方法允许系统性压力测试和细粒度故障分析，将重点从粗略的基准测试转向对 VLM 能力的针对性、可解释的评估。我们的代码可在 https://github.com/byoeval/BYO-EVAL 获取。", "summary": "BYO-Eval 提出一种创新的评估方法，用于对多模态语言模型进行细粒度视觉评估。该方法通过程序化生成合成图像来克服现有基准测试的局限性，如高昂的标注成本和无法区分失败原因。它受眼科诊断启发，能够系统地控制视觉属性，并创建具有逐渐增加挑战性的图像变体，从而实现对视觉语言模型感知失败的精确诊断、系统性压力测试和细粒度故障分析，最终提供更具针对性和可解释性的评估。", "keywords": "视觉语言模型, 评估, 合成数据, 细粒度评估, 程序化生成", "comments": "该论文的创新点在于其提出了一种全新的评估范式，即通过程序化生成合成图像来创建受控的、可诊断的评估数据集。这解决了现有基准测试中成本高昂、信息泄露以及无法定位具体失败原因的痛点。其重要性在于能够对视觉语言模型进行更深入、更细致的能力分析，有助于研究人员更准确地理解模型的强项和弱点，从而推动模型的改进和发展。"}}
{"id": "2506.05597", "title": "FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting", "authors": ["Yash Vijay", "Harini Subramanyan"], "summary": "While Transformers excel in language and vision-where inputs are semantically\nrich and exhibit univariate dependency structures-their architectural\ncomplexity leads to diminishing returns in time series forecasting. Time series\ndata is characterized by low per-timestep information density and complex\ndependencies across channels and covariates, requiring conditioning on\nstructured variable interactions. To address this mismatch and\noverparameterization, we propose FaCTR, a lightweight spatiotemporal\nTransformer with an explicitly structural design. FaCTR injects dynamic,\nsymmetric cross-channel interactions-modeled via a low-rank Factorization\nMachine into temporally contextualized patch embeddings through a learnable\ngating mechanism. It further encodes static and dynamic covariates for\nmultivariate conditioning. Despite its compact design, FaCTR achieves\nstate-of-the-art performance on eleven public forecasting benchmarks spanning\nboth short-term and long-term horizons, with its largest variant using close to\nonly 400K parameters-on average 50x smaller than competitive spatiotemporal\ntransformer baselines. In addition, its structured design enables\ninterpretability through cross-channel influence scores-an essential\nrequirement for real-world decision-making. Finally, FaCTR supports\nself-supervised pretraining, positioning it as a compact yet versatile\nfoundation for downstream time series tasks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05597v1", "AI": {"title_translation": "FaCTR: 因子化通道-时间表示Transformer用于高效时间序列预测", "tldr": "FaCTR是一种轻量级的时空Transformer，通过因子分解机和门控机制处理通道间交互和协变量，实现了时间序列预测的SOTA性能，且参数量远小于现有模型，并支持自监督预训练和可解释性。", "motivation": "传统Transformer在语言和视觉领域表现出色，但应用于时间序列预测时，由于其架构复杂性，回报递减。时间序列数据信息密度低，且通道和协变量之间存在复杂依赖，需要对结构化变量交互进行条件化处理。为了解决这种不匹配和过参数化问题。", "method": "提出FaCTR，一个轻量级的时空Transformer，具有明确的结构化设计。它通过可学习的门控机制，将通过低秩因子分解机建模的动态、对称的跨通道交互注入到时间上下文化的补丁嵌入中。它还编码静态和动态协变量用于多变量条件化。", "result": "尽管设计紧凑，FaCTR在11个公共预测基准（涵盖短期和长期）上实现了最先进的性能。其最大变体的参数量接近400K，平均比有竞争力的时空Transformer基线小50倍。此外，其结构化设计通过跨通道影响分数实现可解释性。", "conclusion": "FaCTR是一种紧凑而多功能的时序预测基础模型，具有SOTA性能、高效率、可解释性，并支持自监督预训练。", "translation": "FaCTR: 因子化通道-时间表示Transformer用于高效时间序列预测\n\n尽管Transformer在语言和视觉领域表现出色——这些领域的输入语义丰富且呈现单变量依赖结构——但其架构复杂性导致在时间序列预测中回报递减。时间序列数据的特点是每时间步信息密度低，以及通道和协变量之间存在复杂依赖，需要对结构化变量交互进行条件化处理。为了解决这种不匹配和过参数化问题，我们提出了FaCTR，一种具有明确结构化设计的轻量级时空Transformer。FaCTR通过可学习的门控机制，将通过低秩因子分解机建模的动态、对称的跨通道交互注入到时间上下文化的补丁嵌入中。它进一步编码静态和动态协变量用于多变量条件化。尽管设计紧凑，FaCTR在涵盖短期和长期预测的11个公共预测基准上实现了最先进的性能，其最大变体的参数量接近400K，平均比有竞争力的时空Transformer基线小近50倍。此外，其结构化设计通过跨通道影响分数实现可解释性——这是实际决策的关键要求。最后，FaCTR支持自监督预训练，使其成为下游时间序列任务的紧凑而多功能的基础模型。", "summary": "本文提出了FaCTR，一种轻量级且结构化的时空Transformer，旨在解决传统Transformer在时间序列预测中因复杂性和过参数化导致性能下降的问题。FaCTR通过因子分解机建模跨通道交互，并结合协变量编码，实现了高效且可解释的时间序列预测。它在多项基准测试中达到了最先进的性能，同时参数量显著减少，并支持自监督预训练。", "keywords": "时间序列预测, Transformer, 因子分解机, 时空表示, 可解释性", "comments": "FaCTR的创新点在于其轻量级和结构化设计，特别是引入低秩因子分解机来建模动态跨通道交互，有效解决了时间序列数据低信息密度和复杂依赖的问题。其参数量大幅减少（50倍）同时达到SOTA性能，显示了其高效性。此外，支持可解释性和自监督预训练使其成为一个有前景的通用时间序列基础模型。"}}
{"id": "2506.05388", "title": "taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades", "authors": ["Stefanie Urchs", "Veronika Thurner", "Matthias Aßenmacher", "Christian Heumann", "Stephanie Thiemichen"], "summary": "Open-access corpora are essential for advancing natural language processing\n(NLP) and computational social science (CSS). However, large-scale resources\nfor German remain limited, restricting research on linguistic trends and\nsocietal issues such as gender bias. We present taz2024full, the largest\npublicly available corpus of German newspaper articles to date, comprising over\n1.8 million texts from taz, spanning 1980 to 2024.\n  As a demonstration of the corpus's utility for bias and discrimination\nresearch, we analyse gender representation across four decades of reporting. We\nfind a consistent overrepresentation of men, but also a gradual shift toward\nmore balanced coverage in recent years. Using a scalable, structured analysis\npipeline, we provide a foundation for studying actor mentions, sentiment, and\nlinguistic framing in German journalistic texts.\n  The corpus supports a wide range of applications, from diachronic language\nanalysis to critical media studies, and is freely available to foster inclusive\nand reproducible research in German-language NLP.", "comment": "Accepted @ \"63rd Annual Meeting of the Association for Computational\n  Linguistics (ACL 2025)\" as a findings paper. This is the author's version of\n  the work. The definitive version of record will be published in the\n  proceedings", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05388v1", "AI": {"title_translation": "taz2024full：分析德国报纸数十年间的性别偏见与歧视", "tldr": "发布了最大的德语报纸语料库taz2024full，并用它分析了德语报纸在数十年间的性别偏见和歧视，发现男性长期被过度代表，但近年有所改善。", "motivation": "德语的大规模开放获取语料库有限，限制了对语言趋势和性别偏见等社会问题的研究。", "method": "构建了迄今为止最大的德语报纸文章语料库taz2024full（包含180多万篇1980-2024年间的taz报纸文章）。利用可扩展的结构化分析流程，分析了四十年间报道中的性别代表性。", "result": "发现男性一直被过度代表，但近年来报道的平衡性逐渐改善。为研究德语新闻文本中的行为者提及、情感和语言框架奠定了基础。", "conclusion": "taz2024full语料库支持广泛的应用，从历时语言分析到批判性媒体研究，并且免费可用，旨在促进德语NLP领域包容和可复现的研究。", "translation": "开放获取语料库对于推进自然语言处理（NLP）和计算社会科学（CSS）至关重要。然而，德语的大规模资源仍然有限，这限制了对语言趋势和性别偏见等社会问题的研究。我们发布了taz2024full，这是迄今为止最大的公开可用德语报纸文章语料库，包含来自taz的180多万篇文本，时间跨度从1980年到2024年。\n作为语料库在偏见和歧视研究中实用性的演示，我们分析了四十年报道中的性别代表性。我们发现男性一直被过度代表，但也发现近年来报道的平衡性逐渐改善。通过使用可扩展的结构化分析流程，我们为研究德语新闻文本中的行为者提及、情感和语言框架奠定了基础。\n该语料库支持广泛的应用，从历时语言分析到批判性媒体研究，并且免费可用，旨在促进德语NLP领域包容和可复现的研究。", "summary": "这篇论文介绍了taz2024full，一个包含180多万篇德国taz报纸文章（1980-2024年）的大规模开放获取德语语料库。作者利用该语料库分析了四十年间新闻报道中的性别代表性，发现男性长期被过度代表，但近年来性别平衡有所改善。该语料库为德语NLP和计算社会科学提供了宝贵的资源，支持对媒体偏见、语言演变等多种应用研究。", "keywords": "德语语料库, 性别偏见, 新闻分析, 自然语言处理, 计算社会科学", "comments": "该论文的创新之处在于构建并公开了迄今为止最大的德语报纸语料库，极大地弥补了德语NLP领域大规模资源的不足。其重要性体现在为研究德语媒体中的性别偏见和歧视提供了坚实的数据基础，并演示了语料库在社会科学研究中的应用潜力。语料库的开放获取性质也促进了研究的包容性和可复现性。"}}
{"id": "2506.06119", "title": "SATversary: Adversarial Attacks on Satellite Fingerprinting", "authors": ["Joshua Smailes", "Sebastian Köhler", "Simon Birnbach", "Martin Strohmeier", "Ivan Martinovic"], "summary": "As satellite systems become increasingly vulnerable to physical layer attacks\nvia SDRs, novel countermeasures are being developed to protect critical\nsystems, particularly those lacking cryptographic protection, or those which\ncannot be upgraded to support modern cryptography. Among these is transmitter\nfingerprinting, which provides mechanisms by which communication can be\nauthenticated by looking at characteristics of the transmitter, expressed as\nimpairments on the signal.\n  Previous works show that fingerprinting can be used to classify satellite\ntransmitters, or authenticate them against SDR-equipped attackers under simple\nreplay scenarios. In this paper we build upon this by looking at attacks\ndirectly targeting the fingerprinting system, with an attacker optimizing for\nmaximum impact in jamming, spoofing, and dataset poisoning attacks, and\ndemonstrate these attacks on the SatIQ system designed to authenticate Iridium\ntransmitters. We show that an optimized jamming signal can cause a 50% error\nrate with attacker-to-victim ratios as low as -30dB (far less power than\ntraditional jamming) and demonstrate successful identity forgery during\nspoofing attacks, with an attacker successfully removing their own\ntransmitter's fingerprint from messages. We also present a data poisoning\nattack, enabling persistent message spoofing by altering the data used to\nauthenticate incoming messages to include the fingerprint of the attacker's\ntransmitter.\n  Finally, we show that our model trained to optimize spoofing attacks can also\nbe used to detect spoofing and replay attacks, even when it has never seen the\nattacker's transmitter before. Furthermore, this technique works even when the\ntraining dataset includes only a single transmitter, enabling fingerprinting to\nbe used to protect small constellations and even individual satellites,\nproviding additional protection where it is needed the most.", "comment": "19 pages, 18 figures, 2 tables", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.06119v1", "AI": {"title_translation": "SATversary：针对卫星指纹识别的对抗性攻击", "tldr": "本文研究了针对卫星发射机指纹识别系统的对抗性攻击，包括干扰、欺骗和数据投毒，并展示了有效的攻击手段和一种新型的欺骗攻击检测方法，该方法即使在训练数据有限的情况下也能保护卫星系统。", "motivation": "卫星系统日益容易受到通过SDR进行的物理层攻击，而许多关键系统缺乏加密保护或无法升级以支持现代加密。发射机指纹识别作为一种通过分析发射机特征来认证通信的机制被提出，但其易受攻击性尚未被充分研究。", "method": "作者构建了直接针对指纹识别系统的攻击，攻击者优化其对干扰、欺骗和数据集投毒攻击的最大影响。这些攻击在为认证铱星发射机而设计的SatIQ系统上进行了演示。此外，作者还展示了训练用于优化欺骗攻击的模型如何用于检测欺骗和重放攻击。", "result": "优化后的干扰信号可以在攻击者与受害者功率比低至-30dB的情况下导致50%的错误率。在欺骗攻击中成功实现了身份伪造，攻击者成功地从消息中移除了其自身发射机的指纹。数据投毒攻击可以改变用于认证传入消息的数据，以包含攻击者发射机的指纹，从而实现持久的消息欺骗。训练用于优化欺骗攻击的模型可以检测欺骗和重放攻击，即使它从未见过攻击者的发射机，并且即使训练数据集只包含单个发射机也有效。", "conclusion": "针对卫星发射机指纹识别系统的对抗性攻击是有效的，并且可以在低功率和有限信息下实现。然而，用于优化欺骗攻击的模型也可以有效地用于检测欺骗和重放攻击，即使在训练数据有限的情况下也能为小型卫星群甚至单个卫星提供保护。", "translation": "随着卫星系统越来越容易受到通过SDRs进行的物理层攻击，人们正在开发新的对策来保护关键系统，特别是那些缺乏加密保护或无法升级以支持现代加密的系统。其中之一是发射机指纹识别，它提供了一种通过观察发射机特征（表现为信号上的损伤）来认证通信的机制。\n  以往的工作表明，指纹识别可用于分类卫星发射机，或在简单的重放场景下针对配备SDR的攻击者进行认证。在本文中，我们在此基础上进一步研究了直接针对指纹识别系统的攻击，攻击者优化其在干扰、欺骗和数据集投毒攻击中的最大影响，并在旨在认证铱星发射机的SatIQ系统上演示了这些攻击。我们表明，优化后的干扰信号可以在攻击者与受害者功率比低至-30dB（远低于传统干扰所需的功率）的情况下导致50%的错误率，并演示了在欺骗攻击中成功的身份伪造，攻击者成功地从消息中移除了其自身发射机的指纹。我们还提出了一种数据投毒攻击，通过改变用于认证传入消息的数据以包含攻击者发射机的指纹，从而实现持久的消息欺骗。\n  最后，我们表明，我们训练用于优化欺骗攻击的模型也可以用于检测欺骗和重放攻击，即使它从未见过攻击者的发射机。此外，这项技术即使在训练数据集只包含单个发射机时也能工作，这使得指纹识别可以用于保护小型卫星群甚至单个卫星，在最需要的地方提供额外的保护。", "summary": "本文研究了针对卫星发射机指纹识别系统的对抗性攻击，以应对SDRs带来的物理层威胁。作者在SatIQ系统上演示了优化后的干扰、欺骗和数据投毒攻击，结果显示低功率干扰即可导致高错误率，并能实现身份伪造和持久性消息欺骗。此外，研究还发现用于优化欺骗攻击的模型可以有效检测欺骗和重放攻击，即便在训练数据稀缺的情况下也能为卫星提供保护。", "keywords": "卫星指纹识别, 对抗性攻击, 干扰, 欺骗, 数据投毒", "comments": "本文创新性地提出了针对卫星指纹识别系统的多种对抗性攻击，揭示了该技术在实际应用中可能面临的脆弱性。其重要性在于，它不仅展示了有效的攻击手段，还提出了一种利用攻击模型进行防御检测的逆向思维方法，这对于保护缺乏加密或难以升级的卫星系统具有重要意义。特别值得注意的是，该检测方法在仅有单个发射机训练数据的情况下也能奏效，这极大地扩展了其适用范围，为小型卫星群和单个卫星提供了急需的保护。"}}
{"id": "2506.06038", "title": "Trajectory Optimization for UAV-Based Medical Delivery with Temporal Logic Constraints and Convex Feasible Set Collision Avoidance", "authors": ["Kaiyuan Chen", "Yuhan Suo", "Shaowei Cui", "Yuanqing Xia", "Wannian Liang", "Shuo Wang"], "summary": "This paper addresses the problem of trajectory optimization for unmanned\naerial vehicles (UAVs) performing time-sensitive medical deliveries in urban\nenvironments. Specifically, we consider a single UAV with 3 degree-of-freedom\ndynamics tasked with delivering blood packages to multiple hospitals, each with\na predefined time window and priority. Mission objectives are encoded using\nSignal Temporal Logic (STL), enabling the formal specification of\nspatial-temporal constraints. To ensure safety, city buildings are modeled as\n3D convex obstacles, and obstacle avoidance is handled through a Convex\nFeasible Set (CFS) method. The entire planning problem-combining UAV dynamics,\nSTL satisfaction, and collision avoidance-is formulated as a convex\noptimization problem that ensures tractability and can be solved efficiently\nusing standard convex programming techniques. Simulation results demonstrate\nthat the proposed method generates dynamically feasible, collision-free\ntrajectories that satisfy temporal mission goals, providing a scalable and\nreliable approach for autonomous UAV-based medical logistics.", "comment": "7 pages, 4 figures", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.06038v1", "AI": {"title_translation": "无人机医疗配送的轨迹优化，考虑时态逻辑约束和凸可行集避障", "tldr": "本文提出了一种基于凸优化的方法，为无人机在城市环境中进行时间敏感医疗配送生成满足时态逻辑约束和避障的轨迹。", "motivation": "解决无人机在城市环境中执行时间敏感医疗配送的轨迹优化问题，特别是对于具有预定义时间窗和优先级的多医院血液包配送。", "method": "使用3自由度动力学模型；任务目标采用信号时态逻辑（STL）编码以形式化时空约束；城市建筑建模为3D凸障碍物；通过凸可行集（CFS）方法处理障碍物避障；将整个规划问题（UAV动力学、STL满足和避障）表述为凸优化问题，并使用标准凸规划技术高效求解。", "result": "仿真结果表明，所提出的方法生成了动态可行、无碰撞且满足时态任务目标的轨迹。", "conclusion": "该方法为自主无人机医疗物流提供了一种可扩展且可靠的方法。", "translation": "标题：无人机医疗配送的轨迹优化，考虑时态逻辑约束和凸可行集避障\n摘要：本文探讨了无人机在城市环境中执行时间敏感医疗配送的轨迹优化问题。具体来说，我们考虑了一架具有3自由度动力学的单架无人机，其任务是将血液包运送到多家医院，每家医院都有预定义的时间窗和优先级。任务目标使用信号时态逻辑（STL）进行编码，从而能够形式化地指定时空约束。为了确保安全性，城市建筑被建模为3D凸障碍物，并通过凸可行集（CFS）方法处理障碍物避障。整个规划问题——结合了无人机动力学、STL满足和避障——被表述为一个凸优化问题，确保了可处理性，并且可以使用标准凸规划技术高效求解。仿真结果表明，所提出的方法生成了动态可行、无碰撞且满足时态任务目标的轨迹，为自主无人机医疗物流提供了一种可扩展且可靠的方法。", "summary": "本文提出了一种针对城市环境中时间敏感无人机医疗配送的轨迹优化方法。该方法将无人机动力学、基于信号时态逻辑（STL）的时间-空间任务约束以及基于凸可行集（CFS）的障碍物避障整合为一个凸优化问题。仿真结果验证了该方法能够生成动态可行、无碰撞且满足任务时间目标的轨迹，为无人机医疗物流提供了一种可靠且可扩展的解决方案。", "keywords": "无人机，轨迹优化，时态逻辑，避障，凸优化", "comments": "该论文的创新点在于将信号时态逻辑（STL）与凸可行集（CFS）避障相结合，并将整个复杂的轨迹规划问题建模为可高效求解的凸优化问题，这对于确保无人机在复杂城市环境中进行时间敏感医疗配送的安全性、可靠性和效率至关重要。其可扩展性也表明了该方法在实际应用中的潜力。"}}
{"id": "2506.05442", "title": "Structured Labeling Enables Faster Vision-Language Models for End-to-End Autonomous Driving", "authors": ["Hao Jiang", "Chuan Hu", "Yukang Shi", "Yuan He", "Ke Wang", "Xi Zhang", "Zhipeng Zhang"], "summary": "Vision-Language Models (VLMs) offer a promising approach to end-to-end\nautonomous driving due to their human-like reasoning capabilities. However,\ntroublesome gaps remains between current VLMs and real-world autonomous driving\napplications. One major limitation is that existing datasets with loosely\nformatted language descriptions are not machine-friendly and may introduce\nredundancy. Additionally, high computational cost and massive scale of VLMs\nhinder the inference speed and real-world deployment. To bridge the gap, this\npaper introduces a structured and concise benchmark dataset, NuScenes-S, which\nis derived from the NuScenes dataset and contains machine-friendly structured\nrepresentations. Moreover, we present FastDrive, a compact VLM baseline with\n0.9B parameters. In contrast to existing VLMs with over 7B parameters and\nunstructured language processing(e.g., LLaVA-1.5), FastDrive understands\nstructured and concise descriptions and generates machine-friendly driving\ndecisions with high efficiency. Extensive experiments show that FastDrive\nachieves competitive performance on structured dataset, with approximately 20%\naccuracy improvement on decision-making tasks, while surpassing massive\nparameter baseline in inference speed with over 10x speedup. Additionally,\nablation studies further focus on the impact of scene annotations (e.g.,\nweather, time of day) on decision-making tasks, demonstrating their importance\non decision-making tasks in autonomous driving.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05442v1", "AI": {"title_translation": "结构化标注助力端到端自动驾驶中更快视觉-语言模型", "tldr": "本文提出了一种结构化数据集NuScenes-S和紧凑型视觉-语言模型FastDrive，以实现更快、更高效的端到端自动驾驶，解决了现有VLM的低效性和高计算成本问题。", "motivation": "现有的视觉-语言模型（VLMs）在端到端自动驾驶中存在问题，包括：现有数据集的语言描述格式松散、不便于机器处理，可能引入冗余；高计算成本和大规模的VLM阻碍了推理速度和实际部署。", "method": "本文引入了一个名为NuScenes-S的结构化、简洁的基准数据集，该数据集源自NuScenes数据集，并包含机器友好的结构化表示。此外，本文提出了一个紧凑型VLM基线模型FastDrive，参数量为0.9B，与现有参数超过7B且处理非结构化语言的VLM（如LLaVA-1.5）不同，FastDrive能够理解结构化和简洁的描述，并高效生成机器友好的驾驶决策。", "result": "FastDrive在结构化数据集上取得了有竞争力的性能，决策任务的准确性提高了约20%，推理速度比大规模参数基线模型快10倍以上。此外，消融研究表明场景标注（如天气、一天中的时间）对自动驾驶中的决策任务至关重要。", "conclusion": "通过引入结构化数据集NuScenes-S和紧凑型VLM FastDrive，可以有效解决现有VLM在端到端自动驾驶应用中的效率和部署问题，显著提升决策准确性和推理速度。", "translation": "视觉-语言模型（VLMs）因其类人推理能力为端到端自动驾驶提供了一种有前景的方法。然而，当前的VLM与现实世界的自动驾驶应用之间仍存在令人担忧的差距。一个主要限制是，现有数据集的语言描述格式松散，不便于机器处理，并且可能引入冗余。此外，VLM的高计算成本和大规模阻碍了推理速度和实际部署。为了弥补这一差距，本文引入了一个结构化且简洁的基准数据集NuScenes-S，该数据集来源于NuScenes数据集，并包含机器友好的结构化表示。此外，我们提出了FastDrive，一个拥有0.9B参数的紧凑型VLM基线模型。与现有参数超过7B且处理非结构化语言的VLM（例如LLaVA-1.5）相比，FastDrive能够理解结构化和简洁的描述，并高效生成机器友好的驾驶决策。大量的实验表明，FastDrive在结构化数据集上取得了有竞争力的性能，在决策任务上准确率提高了约20%，同时在推理速度上比大规模参数基线模型快10倍以上。此外，消融研究进一步关注了场景标注（例如天气、一天中的时间）对决策任务的影响，证明了它们在自动驾驶决策任务中的重要性。", "summary": "本文旨在解决视觉-语言模型（VLMs）在端到端自动驾驶应用中面临的数据集低效性和高计算成本问题。为此，研究者提出了一个结构化、机器友好的基准数据集NuScenes-S，并开发了一个紧凑型VLM模型FastDrive（0.9B参数）。FastDrive能够高效处理结构化语言描述并生成驾驶决策。实验结果表明，FastDrive在决策任务上表现出竞争性性能，准确率提升约20%，推理速度提升10倍以上，验证了结构化标注和紧凑模型在提升自动驾驶VLM效率和性能方面的有效性。", "keywords": "视觉-语言模型, 端到端自动驾驶, 结构化标注, NuScenes-S, FastDrive", "comments": "本文的创新点在于提出了“结构化标注”的概念，并构建了相应的NuScenes-S数据集，这解决了现有VLM数据集中语言描述松散、不便于机器处理的问题。同时，FastDrive模型通过紧凑的参数量和对结构化数据的理解，显著提升了推理速度和决策准确性，这对于VLM在实际自动驾驶场景中的部署具有重要意义。文章的贡献在于为端到端自动驾驶VLM提供了一个更高效、更实用的解决方案。"}}
{"id": "2506.05615", "title": "When Maximum Entropy Misleads Policy Optimization", "authors": ["Ruipeng Zhang", "Ya-Chien Chang", "Sicun Gao"], "summary": "The Maximum Entropy Reinforcement Learning (MaxEnt RL) framework is a leading\napproach for achieving efficient learning and robust performance across many RL\ntasks. However, MaxEnt methods have also been shown to struggle with\nperformance-critical control problems in practice, where non-MaxEnt algorithms\ncan successfully learn. In this work, we analyze how the trade-off between\nrobustness and optimality affects the performance of MaxEnt algorithms in\ncomplex control tasks: while entropy maximization enhances exploration and\nrobustness, it can also mislead policy optimization, leading to failure in\ntasks that require precise, low-entropy policies. Through experiments on a\nvariety of control problems, we concretely demonstrate this misleading effect.\nOur analysis leads to better understanding of how to balance reward design and\nentropy maximization in challenging control problems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05615v1", "AI": {"title_translation": "当最大熵误导策略优化时", "tldr": "最大熵强化学习在需要精确策略的控制任务中可能会因为熵最大化而导致策略优化失败。", "motivation": "最大熵强化学习（MaxEnt RL）框架在实践中难以解决对性能要求严格的控制问题，而非MaxEnt算法却能成功学习。本文旨在分析鲁棒性与最优性之间的权衡如何影响MaxEnt算法在复杂控制任务中的性能。", "method": "通过分析鲁棒性与最优性之间的权衡，并通过一系列控制问题的实验来具体证明熵最大化的误导效应。", "result": "熵最大化虽然增强了探索和鲁棒性，但它也可能误导策略优化，导致在需要精确、低熵策略的任务中失败。实验具体证明了这种误导效应。", "conclusion": "我们的分析有助于更好地理解如何在具有挑战性的控制问题中平衡奖励设计和熵最大化。", "translation": "最大熵强化学习（MaxEnt RL）框架是实现高效学习和在许多RL任务中获得稳健性能的主导方法。然而，MaxEnt方法在实践中也被证明在对性能要求严格的控制问题上表现不佳，而此时非MaxEnt算法却能成功学习。在这项工作中，我们分析了鲁棒性与最优性之间的权衡如何影响MaxEnt算法在复杂控制任务中的性能：虽然熵最大化增强了探索和鲁棒性，但它也可能误导策略优化，导致在需要精确、低熵策略的任务中失败。通过对各种控制问题进行实验，我们具体证明了这种误导效应。我们的分析有助于更好地理解如何在具有挑战性的控制问题中平衡奖励设计和熵最大化。", "summary": "本文探讨了最大熵强化学习（MaxEnt RL）在性能关键型控制任务中可能存在的缺陷。研究指出，尽管熵最大化能增强探索和鲁棒性，但它可能误导策略优化，导致在需要精确低熵策略的任务中学习失败。通过实验验证了这一误导效应，并提出其分析有助于更好地平衡奖励设计和熵最大化。", "keywords": "最大熵强化学习, 策略优化, 控制问题, 熵最大化, 鲁棒性", "comments": "这篇论文揭示了最大熵强化学习的一个重要局限性，即在某些需要高精度控制的任务中，其核心机制——熵最大化反而可能成为障碍。这对于理解MaxEnt RL的适用范围及其在实际应用中的挑战具有重要意义。论文强调了在设计RL算法时，需要在探索/鲁棒性与最优性之间进行精细权衡的重要性。"}}
{"id": "2506.05390", "title": "Understanding Gender Bias in AI-Generated Product Descriptions", "authors": ["Markelle Kelly", "Mohammad Tahaei", "Padhraic Smyth", "Lauren Wilcox"], "summary": "While gender bias in large language models (LLMs) has been extensively\nstudied in many domains, uses of LLMs in e-commerce remain largely unexamined\nand may reveal novel forms of algorithmic bias and harm. Our work investigates\nthis space, developing data-driven taxonomic categories of gender bias in the\ncontext of product description generation, which we situate with respect to\nexisting general purpose harms taxonomies. We illustrate how AI-generated\nproduct descriptions can uniquely surface gender biases in ways that require\nspecialized detection and mitigation approaches. Further, we quantitatively\nanalyze issues corresponding to our taxonomic categories in two models used for\nthis task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these\nforms of bias commonly occur in practice. Our results illuminate unique,\nunder-explored dimensions of gender bias, such as assumptions about clothing\nsize, stereotypical bias in which features of a product are advertised, and\ndifferences in the use of persuasive language. These insights contribute to our\nunderstanding of three types of AI harms identified by current frameworks:\nexclusionary norms, stereotyping, and performance disparities, particularly for\nthe context of e-commerce.", "comment": "Accepted to FAccT 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05390v1", "AI": {"title_translation": "理解AI生成产品描述中的性别偏见", "tldr": "本研究调查了电子商务中AI生成产品描述的性别偏见，开发了偏见分类法，并量化分析了GPT-3.5和电子商务专用LLM中的偏见，揭示了独特的偏见形式。", "motivation": "尽管大型语言模型（LLMs）中的性别偏见已在许多领域得到广泛研究，但LLMs在电子商务中的应用仍未被充分检验，这可能会揭示新型的算法偏见和危害。", "method": "本研究通过开发数据驱动的性别偏见分类法来调查AI生成产品描述中的性别偏见，并将其与现有通用危害分类法进行对照。此外，研究还定量分析了GPT-3.5和一个电子商务专用LLM中与这些分类法相对应的问题。", "result": "研究结果揭示了独特且未被充分探索的性别偏见维度，例如关于服装尺寸的假设、产品特征广告中的刻板印象偏见以及说服性语言使用上的差异。这些形式的偏见在实践中普遍存在。", "conclusion": "这些见解有助于我们理解当前框架中识别出的三种AI危害：排他性规范、刻板印象和性能差异，尤其是在电子商务背景下。", "translation": "尽管大型语言模型（LLMs）中的性别偏见已在许多领域得到广泛研究，但LLMs在电子商务中的应用仍未被充分检验，这可能会揭示新型的算法偏见和危害。我们的工作调查了这一领域，在产品描述生成的背景下，开发了数据驱动的性别偏见分类类别，并将其与现有通用危害分类法进行对照。我们阐释了AI生成的产品描述如何以独特的方式揭示性别偏见，这些方式需要专门的检测和缓解方法。此外，我们定量分析了用于此任务的两种模型——GPT-3.5和一个电子商务专用LLM中与我们分类类别相对应的问题，证明这些形式的偏见在实践中普遍存在。我们的结果揭示了独特且未被充分探索的性别偏见维度，例如关于服装尺寸的假设、产品特征广告中的刻板印象偏见以及说服性语言使用上的差异。这些见解有助于我们理解当前框架中识别出的三种AI危害：排他性规范、刻板印象和性能差异，尤其是在电子商务背景下。", "summary": "本研究旨在理解AI生成产品描述中的性别偏见，填补了电子商务领域LLM偏见研究的空白。研究开发了数据驱动的性别偏见分类法，并定量分析了GPT-3.5和电子商务专用LLM中的偏见。结果揭示了独特的偏见形式，如服装尺寸假设、产品特征的刻板印象广告以及说服性语言使用差异，这些偏见在实践中普遍存在。这些发现加深了对AI危害（排他性规范、刻板印象、性能差异）在电子商务背景下理解。", "keywords": "性别偏见, AI, 产品描述, 电子商务, 大型语言模型", "comments": "这篇论文的创新之处在于它首次系统性地审视了AI在电子商务产品描述中可能引入的性别偏见，这是一个先前未被充分探索的领域。通过开发专门的偏见分类法并量化分析，该研究揭示了诸如服装尺寸假设和产品特征广告刻板印象等独特偏见形式，为未来针对特定领域AI偏见的检测和缓解提供了重要基础。其重要性在于强调了AI在商业应用中潜在的社会危害，并提醒开发者和使用者需要更细致地考虑AI系统的公平性。"}}
{"id": "2506.06124", "title": "PrivTru: A Privacy-by-Design Data Trustee Minimizing Information Leakage", "authors": ["Lukas Gehring", "Florian Tschorsch"], "summary": "Data trustees serve as intermediaries that facilitate secure data sharing\nbetween independent parties. This paper offers a technical perspective on Data\ntrustees, guided by privacy-by-design principles. We introduce PrivTru, an\ninstantiation of a data trustee that provably achieves optimal privacy\nproperties. Therefore, PrivTru calculates the minimal amount of information the\ndata trustee needs to request from data sources to respond to a given query.\nOur analysis shows that PrivTru minimizes information leakage to the data\ntrustee, regardless of the trustee's prior knowledge, while preserving the\nutility of the data.", "comment": "14 pages, 2 figures, IFIP Sec 2025", "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.06124v1", "AI": {"title_translation": "PrivTru: 一种最小化信息泄露的隐私设计数据受托人", "tldr": "PrivTru是一个基于隐私设计的数据受托人，它能证明性地实现最优隐私，最小化数据受托人所需信息，同时保持数据效用。", "motivation": "现有数据受托人需要技术视角和隐私设计指导，以实现安全数据共享并最小化信息泄露。", "method": "本文引入了PrivTru，一个数据受托人实例，它通过计算响应给定查询所需的最少信息量，实现可证明的最优隐私属性。", "result": "PrivTru最小化了信息泄露给数据受托人，无论受托人的先验知识如何，同时保留了数据的效用。", "conclusion": "Not mentioned in abstract", "translation": "数据受托人作为中间人，促进独立方之间的安全数据共享。本文从技术角度审视数据受托人，并以隐私设计原则为指导。我们介绍了PrivTru，一个数据受托人实例，它可证明地实现最优隐私属性。因此，PrivTru计算数据受托人需要从数据源请求的最少信息量，以响应给定查询。我们的分析表明，无论受托人的先验知识如何，PrivTru都能最小化信息泄露给数据受托人，同时保持数据的效用。", "summary": "本文从隐私设计的角度探讨了数据受托人，并提出了PrivTru，一个可证明实现最优隐私的数据受托人实例。PrivTru通过计算响应查询所需的最小信息量，有效最小化了信息泄露给数据受托人，同时保持了数据效用。", "keywords": "数据受托人, 隐私设计, 信息泄露, 数据共享, PrivTru", "comments": "Not mentioned in abstract"}}
{"id": "2506.05444", "title": "U-NetMN and SegNetMN: Modified U-Net and SegNet models for bimodal SAR image segmentation", "authors": ["Marwane Kzadri", "Franco Alberto Cardillo", "Nanée Chahinian", "Carole Delenne", "Renaud Hostache", "Jamal Riffi"], "summary": "Segmenting Synthetic Aperture Radar (SAR) images is crucial for many remote\nsensing applications, particularly water body detection. However, deep\nlearning-based segmentation models often face challenges related to convergence\nspeed and stability, mainly due to the complex statistical distribution of this\ntype of data. In this study, we evaluate the impact of mode normalization on\ntwo widely used semantic segmentation models, U-Net and SegNet. Specifically,\nwe integrate mode normalization, to reduce convergence time while maintaining\nthe performance of the baseline models. Experimental results demonstrate that\nmode normalization significantly accelerates convergence. Furthermore,\ncross-validation results indicate that normalized models exhibit increased\nstability in different zones. These findings highlight the effectiveness of\nnormalization in improving computational efficiency and generalization in SAR\nimage segmentation.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05444v1", "AI": {"title_translation": "U-NetMN和SegNetMN：用于双峰SAR图像分割的改进U-Net和SegNet模型", "tldr": "本研究评估了模式归一化对U-Net和SegNet模型在SAR图像分割中收敛速度和稳定性的影响，并证明其能显著加速收敛并提高稳定性。", "motivation": "合成孔径雷达（SAR）图像分割对于遥感应用至关重要，特别是水体检测。然而，基于深度学习的分割模型由于此类数据复杂的统计分布，常面临收敛速度和稳定性方面的挑战。", "method": "本研究评估了模式归一化对两种广泛使用的语义分割模型U-Net和SegNet的影响。具体来说，研究人员整合了模式归一化以缩短收敛时间，同时保持基线模型的性能。", "result": "实验结果表明，模式归一化显著加速了收敛。此外，交叉验证结果表明，归一化模型在不同区域表现出更高的稳定性。", "conclusion": "这些发现强调了归一化在提高SAR图像分割计算效率和泛化能力方面的有效性。", "translation": "合成孔径雷达（SAR）图像分割对于许多遥感应用至关重要，特别是水体检测。然而，基于深度学习的分割模型常常面临收敛速度和稳定性方面的挑战，这主要归因于此类数据复杂的统计分布。在本研究中，我们评估了模式归一化对两种广泛使用的语义分割模型U-Net和SegNet的影响。具体来说，我们整合了模式归一化，以缩短收敛时间，同时保持基线模型的性能。实验结果表明，模式归一化显著加速了收敛。此外，交叉验证结果表明，归一化模型在不同区域表现出更高的稳定性。这些发现强调了归一化在提高SAR图像分割计算效率和泛化能力方面的有效性。", "summary": "本研究旨在解决SAR图像分割中深度学习模型收敛速度和稳定性问题。通过将模式归一化集成到U-Net和SegNet模型中，实验证明该方法能够显著加快模型收敛，并提高其在不同区域的稳定性，从而提升计算效率和泛化能力。", "keywords": "SAR图像分割, U-Net, SegNet, 模式归一化, 收敛性", "comments": "该论文的创新点在于提出了将模式归一化应用于U-Net和SegNet模型以优化SAR图像分割。其重要性体现在解决了SAR图像复杂统计分布导致的模型收敛慢和稳定性差的问题，为遥感领域，特别是水体检测，提供了更高效和鲁棒的解决方案。"}}
{"id": "2506.05617", "title": "LFA applied to CNNs: Efficient Singular Value Decomposition of Convolutional Mappings by Local Fourier Analysis", "authors": ["Antonia van Betteray", "Matthias Rottmann", "Karsten Kahl"], "summary": "The singular values of convolutional mappings encode interesting spectral\nproperties, which can be used, e.g., to improve generalization and robustness\nof convolutional neural networks as well as to facilitate model compression.\nHowever, the computation of singular values is typically very\nresource-intensive. The naive approach involves unrolling the convolutional\nmapping along the input and channel dimensions into a large and sparse\ntwo-dimensional matrix, making the exact calculation of all singular values\ninfeasible due to hardware limitations. In particular, this is true for\nmatrices that represent convolutional mappings with large inputs and a high\nnumber of channels. Existing efficient methods leverage the Fast Fourier\ntransformation (FFT) to transform convolutional mappings into the frequency\ndomain, enabling the computation of singular values for matrices representing\nconvolutions with larger input and channel dimensions. For a constant number of\nchannels in a given convolution, an FFT can compute N singular values in O(N\nlog N) complexity. In this work, we propose an approach of complexity O(N)\nbased on local Fourier analysis, which additionally exploits the shift\ninvariance of convolutional operators. We provide a theoretical analysis of our\nalgorithm's runtime and validate its efficiency through numerical experiments.\nOur results demonstrate that our proposed method is scalable and offers a\npractical solution to calculate the entire set of singular values - along with\nthe corresponding singular vectors if needed - for high-dimensional\nconvolutional mappings.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05617v1", "AI": {"title_translation": "LFA应用于CNN：通过局部傅里叶分析对卷积映射进行高效奇异值分解", "tldr": "提出一种基于局部傅里叶分析（LFA）的O(N)复杂度方法，用于高效计算卷积映射的奇异值，解决了现有方法计算成本高的问题。", "motivation": "卷积映射的奇异值编码了有趣的谱特性，可用于提高卷积神经网络的泛化能力和鲁棒性，并促进模型压缩。然而，计算奇异值通常资源密集且因硬件限制而不可行，尤其对于高维卷积映射。", "method": "提出一种基于局部傅里叶分析（LFA）的方法，复杂度为O(N)，并额外利用了卷积算子的平移不变性。", "result": "结果表明所提出的方法具有可扩展性，并为计算高维卷积映射的全部奇异值（如果需要，还包括相应的奇异向量）提供了一个实用的解决方案。", "conclusion": "所提出的基于局部傅里叶分析的方法能够以O(N)的复杂度高效计算高维卷积映射的全部奇异值，提供了一种实用且可扩展的解决方案，解决了现有方法计算成本高的问题。", "translation": "Not mentioned in abstract", "summary": "本文提出了一种基于局部傅里叶分析（LFA）的新方法，用于高效计算卷积神经网络中卷积映射的奇异值。现有方法因计算资源密集且硬件限制而难以执行。该方法利用卷积算子的平移不变性，实现了O(N)的计算复杂度，显著优于传统FFT方法的O(N log N)。数值实验验证了该方法的效率和可扩展性，为高维卷积映射的奇异值计算提供了一个实用的解决方案。", "keywords": "卷积神经网络, 奇异值分解, 局部傅里叶分析, 计算效率, 谱特性", "comments": "该论文的创新之处在于提出了一种基于局部傅里叶分析的O(N)复杂度算法，解决了卷积映射奇异值计算资源密集的问题。其重要性在于为提高CNN的泛化能力、鲁棒性和模型压缩提供了实用且高效的工具。局限性在摘要中未提及。"}}
{"id": "2506.05393", "title": "Are Large Language Models Good Temporal Graph Learners?", "authors": ["Shenyang Huang", "Ali Parviz", "Emma Kondrup", "Zachary Yang", "Zifeng Ding", "Michael Bronstein", "Reihaneh Rabbany", "Guillaume Rabusseau"], "summary": "Large Language Models (LLMs) have recently driven significant advancements in\nNatural Language Processing and various other applications. While a broad range\nof literature has explored the graph-reasoning capabilities of LLMs, including\ntheir use of predictors on graphs, the application of LLMs to dynamic graphs --\nreal world evolving networks -- remains relatively unexplored. Recent work\nstudies synthetic temporal graphs generated by random graph models, but\napplying LLMs to real-world temporal graphs remains an open question. To\naddress this gap, we introduce Temporal Graph Talker (TGTalker), a novel\ntemporal graph learning framework designed for LLMs. TGTalker utilizes the\nrecency bias in temporal graphs to extract relevant structural information,\nconverted to natural language for LLMs, while leveraging temporal neighbors as\nadditional information for prediction. TGTalker demonstrates competitive link\nprediction capabilities compared to existing Temporal Graph Neural Network\n(TGNN) models. Across five real-world networks, TGTalker performs competitively\nwith state-of-the-art temporal graph methods while consistently outperforming\npopular models such as TGN and HTGN. Furthermore, TGTalker generates textual\nexplanations for each prediction, thus opening up exciting new directions in\nexplainability and interpretability for temporal link prediction. The code is\npublicly available at https://github.com/shenyangHuang/TGTalker.", "comment": "9 pages, 9 tables, 4 figures", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05393v1", "AI": {"title_translation": "大型语言模型是优秀的时序图学习者吗？", "tldr": "TGTalker是一个LLM框架，用于在真实世界时序图上进行链接预测，性能与现有TGNN模型相当，并能生成解释。", "motivation": "现有文献广泛探索了LLMs的图推理能力，但LLMs在动态图（真实世界演化网络）上的应用相对未被探索。虽然近期工作研究了随机图模型生成的合成时序图，但将LLMs应用于真实世界时序图仍然是一个开放问题。", "method": "为解决这一空白，我们引入了Temporal Graph Talker (TGTalker)，一个新颖的专为LLMs设计的时序图学习框架。TGTalker利用时序图中的近因偏差提取相关结构信息，并将其转换为自然语言供LLMs使用，同时利用时序邻居作为额外的预测信息。", "result": "TGTalker在链接预测能力方面与现有时序图神经网络(TGNN)模型具有竞争力。在五个真实世界网络上，TGTalker与最先进的时序图方法表现相当，并持续优于TGN和HTGN等流行模型。此外，TGTalker为每个预测生成文本解释。", "conclusion": "TGTalker证明了LLMs在真实世界时序图学习中的潜力，并在链接预测任务上表现出色，同时提供了可解释性，为时序链接预测的可解释性和可解释性开辟了令人兴奋的新方向。", "translation": "大型语言模型（LLMs）最近推动了自然语言处理和各种其他应用的显著进步。虽然大量文献探索了LLMs的图推理能力，包括它们在图上使用预测器，但LLMs在动态图——真实世界演化网络——上的应用仍相对未被探索。近期工作研究了随机图模型生成的合成时序图，但将LLMs应用于真实世界时序图仍然是一个开放问题。为了解决这一空白，我们引入了Temporal Graph Talker (TGTalker)，一个新颖的专为LLMs设计的时序图学习框架。TGTalker利用时序图中的近因偏差提取相关结构信息，并将其转换为自然语言供LLMs使用，同时利用时序邻居作为额外的预测信息。TGTalker在链接预测能力方面与现有时序图神经网络(TGNN)模型具有竞争力。在五个真实世界网络上，TGTalker与最先进的时序图方法表现相当，并持续优于TGN和HTGN等流行模型。此外，TGTalker为每个预测生成文本解释，从而为时序链接预测的可解释性和可解释性开辟了令人兴奋的新方向。代码已公开在https://github.com/shenyangHuang/TGTalker。", "summary": "该论文介绍了Temporal Graph Talker (TGTalker)，一个新颖的框架，旨在弥补大型语言模型(LLMs)在真实世界时序图上应用的研究空白。TGTalker利用时序图的近因偏差提取结构信息并转化为自然语言，结合时序邻居进行链接预测。实验结果表明，TGTalker在五个真实世界数据集上的链接预测性能与最先进的时序图方法相当，并优于TGN和HTGN等模型。此外，TGTalker能够生成文本解释，为时序链接预测的可解释性研究提供了新方向。", "keywords": "大型语言模型, 时序图, 链接预测, 可解释性, TGTalker", "comments": "TGTalker的创新之处在于将LLMs应用于真实世界的动态图，并利用其自然语言处理能力生成可解释的预测。这不仅推动了LLMs在图学习领域的应用，也为图神经网络的可解释性研究提供了新的视角。其性能与现有SOTA模型相当，且能提供解释，这在实际应用中具有重要价值。"}}
{"id": "2506.06151", "title": "Joint-GCG: Unified Gradient-Based Poisoning Attacks on Retrieval-Augmented Generation Systems", "authors": ["Haowei Wang", "Rupeng Zhang", "Junjie Wang", "Mingyang Li", "Yuekai Huang", "Dandan Wang", "Qing Wang"], "summary": "Retrieval-Augmented Generation (RAG) systems enhance Large Language Models\n(LLMs) by retrieving relevant documents from external corpora before generating\nresponses. This approach significantly expands LLM capabilities by leveraging\nvast, up-to-date external knowledge. However, this reliance on external\nknowledge makes RAG systems vulnerable to corpus poisoning attacks that\nmanipulate generated outputs via poisoned document injection. Existing\npoisoning attack strategies typically treat the retrieval and generation stages\nas disjointed, limiting their effectiveness. We propose Joint-GCG, the first\nframework to unify gradient-based attacks across both retriever and generator\nmodels through three innovations: (1) Cross-Vocabulary Projection for aligning\nembedding spaces, (2) Gradient Tokenization Alignment for synchronizing\ntoken-level gradient signals, and (3) Adaptive Weighted Fusion for dynamically\nbalancing attacking objectives. Evaluations demonstrate that Joint-GCG achieves\nat most 25% and an average of 5% higher attack success rate than previous\nmethods across multiple retrievers and generators. While optimized under a\nwhite-box assumption, the generated poisons show unprecedented transferability\nto unseen models. Joint-GCG's innovative unification of gradient-based attacks\nacross retrieval and generation stages fundamentally reshapes our understanding\nof vulnerabilities within RAG systems. Our code is available at\nhttps://github.com/NicerWang/Joint-GCG.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.06151v1", "AI": {"title_translation": "Joint-GCG：统一的基于梯度的检索增强生成系统投毒攻击", "tldr": "RAG系统易受投毒攻击，Joint-GCG是首个统一检索和生成阶段的梯度攻击框架，显著提高了攻击成功率和可迁移性。", "motivation": "检索增强生成（RAG）系统对外部知识的依赖使其容易受到语料投毒攻击，而现有攻击策略通常将检索和生成阶段视为分离，限制了其有效性。", "method": "本文提出了Joint-GCG框架，这是首个通过三项创新统一了检索器和生成器模型梯度攻击的框架：(1) 跨词汇投影（Cross-Vocabulary Projection）用于对齐嵌入空间；(2) 梯度分词对齐（Gradient Tokenization Alignment）用于同步词元级梯度信号；(3) 自适应加权融合（Adaptive Weighted Fusion）用于动态平衡攻击目标。", "result": "Joint-GCG在多种检索器和生成器上的攻击成功率比现有方法最高提高了25%，平均提高了5%。尽管在白盒假设下进行了优化，但生成的毒药对未见过的模型显示出前所未有的可迁移性。", "conclusion": "Joint-GCG通过统一检索和生成阶段的梯度攻击，从根本上重塑了我们对RAG系统漏洞的理解。", "translation": "检索增强生成（RAG）系统通过在生成响应之前从外部语料库检索相关文档来增强大型语言模型（LLMs）。这种方法通过利用庞大、最新的外部知识显著扩展了LLM的能力。然而，这种对外部知识的依赖使得RAG系统容易受到通过注入投毒文档来操纵生成输出的语料投毒攻击。现有的投毒攻击策略通常将检索和生成阶段视为分离，限制了它们的有效性。我们提出了Joint-GCG，这是第一个通过三项创新统一检索器和生成器模型梯度攻击的框架：(1) 跨词汇投影用于对齐嵌入空间；(2) 梯度分词对齐用于同步词元级梯度信号；(3) 自适应加权融合用于动态平衡攻击目标。评估表明，Joint-GCG在多个检索器和生成器上的攻击成功率比现有方法最高提高了25%，平均提高了5%。虽然在白盒假设下进行了优化，但生成的毒药对未见过的模型显示出前所未有的可迁移性。Joint-GCG对检索和生成阶段梯度攻击的创新性统一从根本上重塑了我们对RAG系统漏洞的理解。我们的代码可在https://github.com/NicerWang/Joint-GCG获取。", "summary": "检索增强生成（RAG）系统通过利用外部知识增强大型语言模型，但其对外部数据的依赖使其易受语料投毒攻击。鉴于现有攻击策略将检索和生成阶段分离处理，效果有限，本文提出了Joint-GCG。作为首个统一检索器和生成器模型梯度攻击的框架，Joint-GCG引入了跨词汇投影、梯度分词对齐和自适应加权融合三项创新。实验证明，Joint-GCG的攻击成功率比现有方法平均高出5%，最高可达25%，并且生成的毒药对未见过的模型具有显著的可迁移性。这项工作深刻改变了我们对RAG系统漏洞的认识。", "keywords": "检索增强生成, 投毒攻击, 梯度攻击, RAG系统漏洞, 可迁移性", "comments": "Joint-GCG的创新之处在于首次成功地将RAG系统中分离的检索和生成阶段的梯度攻击统一起来，有效解决了现有方法在攻击效率上的局限性。其提出的三项核心技术——跨词汇投影、梯度分词对齐和自适应加权融合——展现了高度的技术独创性。尤其值得关注的是，尽管在白盒环境下优化，但其生成的投毒样本对未知模型展现出卓越的可迁移性，这不仅揭示了RAG系统潜在的深层安全风险，也强调了未来在系统防御方面进行更深入研究的必要性和紧迫性。"}}
{"id": "2506.05450", "title": "Degradation-Aware Image Enhancement via Vision-Language Classification", "authors": ["Jie Cai", "Kangning Yang", "Jiaming Ding", "Lan Fu", "Ling Ouyang", "Jiang Li", "Jinglin Shen", "Zibo Meng"], "summary": "Image degradation is a prevalent issue in various real-world applications,\naffecting visual quality and downstream processing tasks. In this study, we\npropose a novel framework that employs a Vision-Language Model (VLM) to\nautomatically classify degraded images into predefined categories. The VLM\ncategorizes an input image into one of four degradation types: (A)\nsuper-resolution degradation (including noise, blur, and JPEG compression), (B)\nreflection artifacts, (C) motion blur, or (D) no visible degradation\n(high-quality image). Once classified, images assigned to categories A, B, or C\nundergo targeted restoration using dedicated models tailored for each specific\ndegradation type. The final output is a restored image with improved visual\nquality. Experimental results demonstrate the effectiveness of our approach in\naccurately classifying image degradations and enhancing image quality through\nspecialized restoration models. Our method presents a scalable and automated\nsolution for real-world image enhancement tasks, leveraging the capabilities of\nVLMs in conjunction with state-of-the-art restoration techniques.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05450v1", "AI": {"title_translation": "降级感知图像增强通过视觉-语言分类", "tldr": "该研究提出一个利用视觉-语言模型对图像降级类型进行分类，并针对性地进行图像增强的新框架。", "motivation": "图像降级是现实世界应用中普遍存在的问题，影响视觉质量和下游处理任务。", "method": "提出一个新颖的框架，利用视觉-语言模型（VLM）自动将降级图像分类为四种预定义类别：超分辨率降级（包括噪声、模糊和JPEG压缩）、反射伪影、运动模糊或无可见降级。一旦分类，对前三类图像使用专门的模型进行有针对性的恢复。", "result": "实验结果表明该方法在准确分类图像降级和通过专业恢复模型增强图像质量方面有效。", "conclusion": "该方法为现实世界的图像增强任务提供了一个可扩展和自动化的解决方案，结合了视觉-语言模型的能力和最先进的恢复技术。", "translation": "图像降级在各种现实世界应用中是一个普遍存在的问题，影响视觉质量和下游处理任务。在本研究中，我们提出了一个新颖的框架，该框架采用视觉-语言模型（VLM）将降级图像自动分类为预定义类别。VLM将输入图像分为四种降级类型之一：（A）超分辨率降级（包括噪声、模糊和JPEG压缩），（B）反射伪影，（C）运动模糊，或（D）无可见降级（高质量图像）。一旦分类，被归类为A、B或C的图像将使用针对每种特定降级类型量身定制的专用模型进行有针对性的恢复。最终输出是视觉质量得到改善的恢复图像。实验结果表明，我们的方法在准确分类图像降级和通过专业恢复模型增强图像质量方面是有效的。我们的方法为现实世界的图像增强任务提供了一个可扩展和自动化的解决方案，利用了VLM的能力以及最先进的恢复技术。", "summary": "本文提出一种新颖的图像增强框架，利用视觉-语言模型自动识别并分类图像的降级类型。该模型将图像分为超分辨率降级、反射伪影、运动模糊或高质量图像。针对分类出的降级类型，系统会调用专门的恢复模型进行处理，从而提高图像质量。实验证明，此方法能有效分类降级并提升图像视觉效果，为现实世界图像增强提供了一个可扩展且自动化的解决方案。", "keywords": "图像增强, 视觉-语言模型, 图像降级分类, 图像恢复, 自动化", "comments": "该研究的创新点在于将视觉-语言模型引入到图像降级分类中，实现了图像增强过程的自动化和智能化。这种分类-恢复的流水线方法提高了图像增强的针对性和效率。"}}
{"id": "2506.05626", "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods", "authors": ["Xiaohua Lu", "Liubov Tupikina", "Mehwish Alam"], "summary": "Real-world knowledge can take various forms, including structured,\nsemi-structured, and unstructured data. Among these, knowledge graphs are a\nform of structured human knowledge that integrate heterogeneous data sources\ninto structured representations but typically reduce complex n-ary relations to\nsimple triples, thereby losing higher-order relational details. In contrast,\nhypergraphs naturally represent n-ary relations with hyperedges, which directly\nconnect multiple entities together. Yet hypergraph representation learning\noften overlooks entity roles in hyperedges, limiting the fine-grained semantic\nmodelling. To address these issues, knowledge hypergraphs and hyper-relational\nknowledge graphs combine the advantages of knowledge graphs and hypergraphs to\nbetter capture the complex structures and role-specific semantics of real-world\nknowledge. This survey provides a comprehensive review of methods handling\nn-ary relational data, covering both knowledge hypergraphs and hyper-relational\nknowledge graphs literatures. We propose a two-dimensional taxonomy: the first\ndimension categorises models based on their methodology, i.e.,\ntranslation-based models, tensor factorisation-based models, deep neural\nnetwork-based models, logic rules-based models, and hyperedge expansion-based\nmodels. The second dimension classifies models according to their awareness of\nentity roles and positions in n-ary relations, dividing them into aware-less,\nposition-aware, and role-aware approaches. Finally, we discuss existing\ndatasets, negative sampling strategies, and outline open challenges to inspire\nfuture research.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05626v1", "AI": {"title_translation": "N元知识表示学习方法的二维分类法", "tldr": "本文综述了N元知识表示学习方法，提出了一个基于方法论和实体角色/位置感知的二维分类法，并讨论了现有挑战。", "motivation": "现实世界的知识复杂多样，传统知识图谱将复杂的N元关系简化为三元组，导致高阶关系细节丢失。超图表示学习常忽略超边中实体角色，限制了细粒度语义建模。知识超图和超关系知识图谱结合了知识图谱和超图的优点，能更好地捕获复杂结构和角色特定语义，因此需要对其进行全面综述和分类。", "method": "本文对处理N元关系数据的方法进行了全面综述，涵盖了知识超图和超关系知识图谱文献。作者提出了一个二维分类法：第一维根据方法论对模型进行分类，包括基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型。第二维根据模型对N元关系中实体角色和位置的感知程度进行分类，分为无感知、位置感知和角色感知方法。最后，讨论了现有数据集、负采样策略并概述了开放挑战。", "result": "本文提出了一个针对N元知识表示学习方法的二维分类法。综述了现有数据集、负采样策略，并指出了未来研究的开放挑战。", "conclusion": "本文对N元知识表示学习进行了全面综述，并提出了一个新颖的二维分类法，突出了现有研究状况和未来的研究方向。", "translation": "现实世界中的知识可以采取各种形式，包括结构化、半结构化和非结构化数据。其中，知识图谱是一种结构化的人类知识形式，它将异构数据源集成到结构化表示中，但通常将复杂的N元关系简化为简单的三元组，从而丢失了高阶关系细节。相比之下，超图通过超边自然地表示N元关系，直接连接多个实体。然而，超图表示学习常常忽略超边中的实体角色，限制了细粒度的语义建模。为了解决这些问题，知识超图和超关系知识图谱结合了知识图谱和超图的优点，以更好地捕获现实世界知识的复杂结构和角色特定语义。本综述全面回顾了处理N元关系数据的方法，涵盖了知识超图和超关系知识图谱文献。我们提出了一个二维分类法：第一维根据模型的方法论进行分类，即基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型。第二维根据模型对N元关系中实体角色和位置的感知程度进行分类，将其分为无感知、位置感知和角色感知方法。最后，我们讨论了现有数据集、负采样策略，并概述了开放挑战以启发未来的研究。", "summary": "本综述论文回顾了N元知识表示学习方法，重点关注知识超图和超关系知识图谱，这些方法比传统知识图谱能更好地捕获复杂结构和角色特定语义。论文提出了一个二维分类法，根据方法论（如基于翻译、深度学习）和实体角色及位置感知程度（无感知、位置感知、角色感知）对模型进行分类。此外，论文还讨论了数据集、负采样策略和开放挑战。", "keywords": "N元知识表示, 知识图谱, 超图, 分类法, 综述", "comments": "这篇论文具有重要意义，因为它通过综述知识超图和超关系知识图谱等先进方法，解决了传统知识图谱在处理复杂N元关系方面的局限性。所提出的二维分类法为理解和分类现有模型提供了一种结构化的方式，这对研究人员非常有价值。此外，它还指明了未来的研究方向。"}}
{"id": "2506.05466", "title": "Towards Reliable Identification of Diffusion-based Image Manipulations", "authors": ["Alex Costanzino", "Woody Bayliss", "Juil Sock", "Marc Gorriz Blanch", "Danijela Horak", "Ivan Laptev", "Philip Torr", "Fabio Pizzati"], "summary": "Changing facial expressions, gestures, or background details may dramatically\nalter the meaning conveyed by an image. Notably, recent advances in diffusion\nmodels greatly improve the quality of image manipulation while also opening the\ndoor to misuse. Identifying changes made to authentic images, thus, becomes an\nimportant task, constantly challenged by new diffusion-based editing tools. To\nthis end, we propose a novel approach for ReliAble iDentification of inpainted\nAReas (RADAR). RADAR builds on existing foundation models and combines features\nfrom different image modalities. It also incorporates an auxiliary contrastive\nloss that helps to isolate manipulated image patches. We demonstrate these\ntechniques to significantly improve both the accuracy of our method and its\ngeneralisation to a large number of diffusion models. To support realistic\nevaluation, we further introduce BBC-PAIR, a new comprehensive benchmark, with\nimages tampered by 28 diffusion models. Our experiments show that RADAR\nachieves excellent results, outperforming the state-of-the-art in detecting and\nlocalising image edits made by both seen and unseen diffusion models. Our code,\ndata and models will be publicly available at alex-costanzino.github.io/radar.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05466v1", "AI": {"title_translation": "迈向可靠识别基于扩散的图像篡改", "tldr": "本文提出了RADAR，一种利用基础模型和对比损失来可靠检测基于扩散的图像篡改的新方法，在新基准BBC-PAIR上优于现有技术水平。", "motivation": "最近扩散模型在图像处理质量方面取得了显著进展，但也带来了滥用的风险。识别对真实图像的篡改成为一项重要任务，并不断受到新的基于扩散的编辑工具的挑战。", "method": "本文提出了一种名为RADAR（ReliAble iDentification of inpainted ARas）的新方法。RADAR建立在现有基础模型之上，结合了来自不同图像模态的特征，并融入了辅助对比损失以帮助隔离被操纵的图像补丁。为了支持现实评估，本文还引入了一个新的综合基准BBC-PAIR，其中包含由28个扩散模型篡改的图像。", "result": "RADAR显著提高了方法的准确性及其对大量扩散模型的泛化能力。实验表明，RADAR取得了优异的结果，在检测和定位由已知和未知扩散模型进行的图像编辑方面，超越了现有技术水平。", "conclusion": "RADAR是一种用于识别基于扩散的图像篡改的高效方法，展示了卓越的性能和泛化能力。", "translation": "改变面部表情、手势或背景细节可能会极大地改变图像所传达的含义。值得注意的是，扩散模型的最新进展极大地提高了图像处理的质量，同时也为滥用打开了大门。因此，识别对真实图像所做的更改成为一项重要任务，不断受到新的基于扩散的编辑工具的挑战。为此，我们提出了一种用于可靠识别修复区域（RADAR）的新方法。RADAR建立在现有基础模型之上，并结合了来自不同图像模态的特征。它还结合了一个辅助对比损失，有助于隔离被操纵的图像补丁。我们证明这些技术显著提高了我们方法的准确性及其对大量扩散模型的泛化能力。为了支持现实评估，我们进一步引入了BBC-PAIR，这是一个新的综合基准，其中包含由28个扩散模型篡改的图像。我们的实验表明，RADAR取得了优异的结果，在检测和定位由已知和未知扩散模型进行的图像编辑方面，超越了现有技术水平。我们的代码、数据和模型将公开在alex-costanzino.github.io/radar。", "summary": "本文介绍了一种名为RADAR（ReliAble iDentification of inpainted ARas）的新方法，旨在可靠地检测和定位由扩散模型创建的图像篡改。RADAR利用现有的基础模型，整合多模态图像特征，并采用辅助对比损失来精确定位被操纵区域。为了促进鲁棒评估，作者还提出了一个新的综合基准数据集BBC-PAIR。实验结果表明，RADAR显著提高了检测准确性和泛化能力，在已知和未知扩散模型上均优于现有技术水平。", "keywords": "扩散模型, 图像篡改检测, 数字取证, 修复检测, 对比学习", "comments": "这篇论文解决了数字取证领域一个关键且不断演变的挑战：识别由先进扩散模型生成的复杂图像篡改。所提出的RADAR方法在结合基础模型、多模态特征和用于补丁隔离的特定对比损失方面具有创新性。BBC-PAIR基准的引入非常有价值，它提供了一个更现实和更全面的评估环境，这对于推动这个快速发展领域的研究至关重要。代码和数据的公开可用性进一步增强了其潜在影响。"}}
{"id": "2506.05397", "title": "Gen4D: Synthesizing Humans and Scenes in the Wild", "authors": ["Jerrin Bright", "Zhibo Wang", "Yuhao Chen", "Sirisha Rambhatla", "John Zelek", "David Clausi"], "summary": "Lack of input data for in-the-wild activities often results in low\nperformance across various computer vision tasks. This challenge is\nparticularly pronounced in uncommon human-centric domains like sports, where\nreal-world data collection is complex and impractical. While synthetic datasets\noffer a promising alternative, existing approaches typically suffer from\nlimited diversity in human appearance, motion, and scene composition due to\ntheir reliance on rigid asset libraries and hand-crafted rendering pipelines.\nTo address this, we introduce Gen4D, a fully automated pipeline for generating\ndiverse and photorealistic 4D human animations. Gen4D integrates expert-driven\nmotion encoding, prompt-guided avatar generation using diffusion-based Gaussian\nsplatting, and human-aware background synthesis to produce highly varied and\nlifelike human sequences. Based on Gen4D, we present SportPAL, a large-scale\nsynthetic dataset spanning three sports: baseball, icehockey, and soccer.\nTogether, Gen4D and SportPAL provide a scalable foundation for constructing\nsynthetic datasets tailored to in-the-wild human-centric vision tasks, with no\nneed for manual 3D modeling or scene design.", "comment": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) Workshops", "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.05397v1", "AI": {"title_translation": "Gen4D: 野外场景下的人体与场景合成", "tldr": "Gen4D是一个全自动管线，用于生成多样化、逼真的4D人体动画，并在此基础上构建了大型合成体育数据集SportPAL，旨在解决野外以人为中心的计算机视觉任务中的数据稀缺问题。", "motivation": "野外活动输入数据的缺乏导致计算机视觉任务性能低下，尤其在体育等不常见的以人为中心的领域更为突出。现有合成数据集方法因依赖僵硬的资产库和手工渲染管线，导致人体外观、动作和场景多样性有限。", "method": "本文引入了Gen4D，一个用于生成多样化且逼真的4D人体动画的全自动管线。Gen4D集成了专家驱动的运动编码、使用基于扩散的高斯泼溅的提示引导式虚拟形象生成，以及以人为背景的合成。", "result": "基于Gen4D，本文提出了SportPAL，一个涵盖棒球、冰球和足球三种运动的大规模合成数据集。Gen4D和SportPAL共同为构建针对野外以人为中心的视觉任务的合成数据集提供了可扩展的基础，无需手动3D建模或场景设计。", "conclusion": "Gen4D及其伴随的SportPAL数据集为解决野外以人为中心的视觉任务中的数据稀缺问题提供了一个可扩展的合成数据生成基础，并消除了手动3D建模和场景设计的需求。", "translation": "野外活动输入数据的缺乏常常导致各种计算机视觉任务的低性能。这一挑战在不常见的以人为中心的领域（如体育）中尤为突出，因为真实世界的数据收集复杂且不切实际。虽然合成数据集提供了一个有前景的替代方案，但现有方法通常由于依赖僵硬的资产库和手工制作的渲染管线，导致人体外观、动作和场景构成的多样性有限。为了解决这个问题，我们引入了Gen4D，一个用于生成多样化且逼真的4D人体动画的全自动管线。Gen4D集成了专家驱动的运动编码、使用基于扩散的高斯泼溅的提示引导式虚拟形象生成，以及以人为背景的合成，以生成高度多样化和逼真的人体序列。基于Gen4D，我们提出了SportPAL，一个涵盖棒球、冰球和足球三种运动的大规模合成数据集。Gen4D和SportPAL共同为构建针对野外以人为中心的视觉任务的合成数据集提供了可扩展的基础，无需手动3D建模或场景设计。", "summary": "本文介绍了Gen4D，一个用于生成多样化、逼真4D人体动画的全自动管线，旨在解决野外以人为中心的计算机视觉任务中数据稀缺的问题。Gen4D结合了专家驱动的运动编码、基于扩散的高斯泼溅的虚拟形象生成以及以人为背景的合成。基于Gen4D，作者构建了大型合成体育数据集SportPAL，为野外人体视觉任务提供了可扩展的数据集构建基础，无需手动建模或场景设计。", "keywords": "4D人体动画, 合成数据, 计算机视觉, 野外场景, SportPAL", "comments": "创新点在于Gen4D是一个全自动的4D人体动画生成管线，并集成了扩散模型和高斯泼溅等先进技术，显著提高了合成数据的多样性和真实感。其重要性在于提供了一个可扩展的解决方案，有效缓解了野外以人为中心的计算机视觉任务中数据收集困难的瓶颈。抽象中未提及具体局限性。"}}
{"id": "2506.05628", "title": "GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance", "authors": ["Jiri Navratil", "Jarret Ross", "Payel Das", "Youssef Mroueh", "Samuel C Hoffman", "Vijil Chenthamarakshan", "Brian Belgodere"], "summary": "The ability to design molecules while preserving similarity to a target\nmolecule and/or property is crucial for various applications in drug discovery,\nchemical design, and biology. We introduce in this paper an efficient\ntraining-free method for navigating and sampling from the molecular space with\na generative Chemical Language Model (CLM), while using the molecular\nsimilarity to the target as a guide. Our method leverages the contextual\nrepresentations learned from the CLM itself to estimate the molecular\nsimilarity, which is then used to adjust the autoregressive sampling strategy\nof the CLM. At each step of the decoding process, the method tracks the\ndistance of the current generations from the target and updates the logits to\nencourage the preservation of similarity in generations. We implement the\nmethod using a recently proposed $\\sim$47M parameter SMILES-based CLM,\nGP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, which\nenables a test-time update of the deep generative policy to reflect the\ncontextual similarity to a set of guide molecules. The method is further\nintegrated into a genetic algorithm (GA) and tested on a set of standard\nmolecular optimization benchmarks involving property optimization, molecular\nrediscovery, and structure-based drug design. Results show that,\nGP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existing\ntraining-free baseline methods, when the oracle remains black-box. The findings\nin this work are a step forward in understanding and guiding the generative\nmechanisms of CLMs.", "comment": "12 pages main article, 21 pages total", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05628v1", "AI": {"title_translation": "GP-MoLFormer-Sim：通过上下文相似性指导进行测试时分子优化", "tldr": "提出一种基于GP-MoLFormer的训练无关方法GP-MoLFormer-Sim，利用上下文相似性指导CLM的自回归采样，以在分子设计中保持与目标分子的相似性，并在与遗传算法结合后超越现有基线方法。", "motivation": "在药物发现、化学设计和生物学等各种应用中，设计分子同时保持与目标分子和/或性质的相似性至关重要。", "method": "引入了一种高效的训练无关方法，利用生成式化学语言模型（CLM）的上下文表示来估计分子相似性，并用其调整CLM的自回归采样策略。在解码的每一步，该方法跟踪当前生成与目标之间的距离，并更新logits以鼓励在生成中保持相似性。该方法使用GP-MoLFormer实现，并进一步集成到遗传算法（GA）中。", "result": "GP-MoLFormer-Sim与遗传算法结合（GP-MoLFormer-Sim+GA）在标准分子优化基准测试（包括性质优化、分子再发现和基于结构的药物设计）中，当oracle保持黑盒时，优于现有训练无关的基线方法。", "conclusion": "这项工作中的发现是理解和指导CLM生成机制向前迈出的一步。", "translation": "标题：GP-MoLFormer-Sim：通过上下文相似性指导进行测试时分子优化\n\n摘要：在药物发现、化学设计和生物学等各种应用中，设计分子同时保持与目标分子和/或性质的相似性至关重要。本文介绍了一种高效的训练无关方法，用于使用生成式化学语言模型（CLM）在分子空间中导航和采样，同时使用与目标的分子相似性作为指导。我们的方法利用从CLM本身学习到的上下文表示来估计分子相似性，然后将其用于调整CLM的自回归采样策略。在解码过程的每一步，该方法跟踪当前生成与目标之间的距离并更新logits，以鼓励在生成中保持相似性。我们使用最近提出的约47M参数的基于SMILES的CLM GP-MoLFormer实现该方法，因此将该方法称为GP-MoLFormer-Sim，它能够在测试时更新深度生成策略，以反映与一组指导分子的上下文相似性。该方法进一步集成到遗传算法（GA）中，并在涉及性质优化、分子再发现和基于结构的药物设计的一组标准分子优化基准上进行了测试。结果表明，当oracle保持黑盒时，GP-MoLFormer-Sim与GA结合（GP-MoLFormer-Sim+GA）优于现有训练无关的基线方法。这项工作中的发现是理解和指导CLM生成机制向前迈出的一步。", "summary": "本文提出了一种名为GP-MoLFormer-Sim的训练无关分子优化方法，该方法利用化学语言模型（CLM）GP-MoLFormer的上下文表示来估计分子相似性。它通过在自回归采样过程中调整logits来指导分子生成，以保持与目标分子的相似性。该方法与遗传算法（GA）结合后，在多项分子优化任务中表现优于现有的训练无关基线方法，尤其适用于黑盒oracle场景。", "keywords": "分子优化, 化学语言模型, 上下文相似性, 遗传算法, GP-MoLFormer-Sim", "comments": "该论文提出了一种创新的训练无关分子优化方法，通过利用预训练CLM的上下文表示来指导分子生成，以保持相似性，这对于药物发现等领域具有重要意义。与遗传算法的结合进一步提升了其性能，并在黑盒优化场景下展现出优势。"}}
{"id": "2506.06226", "title": "PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems", "authors": ["Yi Huang", "Wajih UI Hassan", "Yao Guo", "Xiangqun Chen", "Ding Li"], "summary": "Provenance graph analysis plays a vital role in intrusion detection,\nparticularly against Advanced Persistent Threats (APTs), by exposing complex\nattack patterns. While recent systems combine graph neural networks (GNNs) with\nnatural language processing (NLP) to capture structural and semantic features,\ntheir effectiveness is limited by class imbalance in real-world data. To\naddress this, we introduce PROVSYN, an automated framework that synthesizes\nprovenance graphs through a three-phase pipeline: (1) heterogeneous graph\nstructure synthesis with structural-semantic modeling, (2) rule-based\ntopological refinement, and (3) context-aware textual attribute synthesis using\nlarge language models (LLMs). PROVSYN includes a comprehensive evaluation\nframework that integrates structural, textual, temporal, and embedding-based\nmetrics, along with a semantic validation mechanism to assess the correctness\nof generated attack patterns and system behaviors. To demonstrate practical\nutility, we use the synthetic graphs to augment training datasets for\ndownstream APT detection models. Experimental results show that PROVSYN\nproduces high-fidelity graphs and improves detection performance through\neffective data augmentation.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/pdf/2506.06226v1", "AI": {"title_translation": "PROVSYN: 用于入侵检测系统数据增强的溯源图合成", "tldr": "PROVSYN通过三阶段流程合成溯源图，以解决入侵检测中真实数据类不平衡问题，并通过数据增强提高APT检测性能。", "motivation": "现有的将图神经网络（GNNs）与自然语言处理（NLP）结合用于入侵检测的系统，其有效性受限于真实世界数据中类不平衡问题。", "method": "本文提出了PROVSYN，一个自动化的溯源图合成框架，通过三阶段流程实现：1) 结构-语义建模的异构图结构合成；2) 基于规则的拓扑细化；3) 使用大型语言模型（LLMs）的上下文感知文本属性合成。PROVSYN还包含一个全面的评估框架，集成结构、文本、时间、基于嵌入的指标和语义验证机制，以评估生成的攻击模式和系统行为的正确性。", "result": "实验结果表明，PROVSYN生成了高保真（high-fidelity）图，并通过有效的数据增强提高了下游APT检测模型的性能。", "conclusion": "PROVSYN能够生成高质量的合成溯源图，并有效改善入侵检测系统在高级持续性威胁（APT）检测方面的性能，从而解决了数据不平衡问题。", "translation": "溯源图分析在入侵检测中发挥着至关重要的作用，尤其是在对抗高级持续性威胁（APTs）方面，通过揭示复杂的攻击模式。尽管最近的系统结合了图神经网络（GNNs）和自然语言处理（NLP）来捕获结构和语义特征，但其有效性受限于真实世界数据中的类不平衡问题。为了解决这个问题，我们引入了PROVSYN，一个自动化框架，通过三阶段流程合成溯源图：(1) 结构-语义建模的异构图结构合成，(2) 基于规则的拓扑细化，以及 (3) 使用大型语言模型（LLMs）的上下文感知文本属性合成。PROVSYN包括一个全面的评估框架，它集成了结构、文本、时间、基于嵌入的指标，以及一个语义验证机制来评估生成的攻击模式和系统行为的正确性。为了展示其实用性，我们使用合成图来增强下游APT检测模型的训练数据集。实验结果表明，PROVSYN生成了高保真图，并通过有效的数据增强提高了检测性能。", "summary": "本文提出了PROVSYN，一个用于入侵检测系统的自动化溯源图合成框架，旨在解决真实数据中类不平衡的问题。PROVSYN通过异构图结构合成、拓扑细化和上下文感知文本属性合成三个阶段生成高保真溯源图。该框架还包含一个全面的评估机制，并利用合成图增强下游APT检测模型的训练数据集。实验证明，利用合成图进行数据增强能显著提升APT检测模型的性能。", "keywords": "溯源图, 数据增强, 入侵检测系统, 图神经网络, 大型语言模型", "comments": "该论文提出了一种新颖的自动化框架PROVSYN，用于合成溯源图，以解决入侵检测领域中常见的类不平衡问题。其创新点在于结合了结构-语义建模、规则细化和大型语言模型（LLM）进行文本属性合成，并提供了一个全面的评估框架。这项工作对于提升APT检测模型的鲁棒性和性能具有重要意义，尤其是在数据稀缺或不平衡的场景下。"}}
{"id": "2506.05473", "title": "S2GO: Streaming Sparse Gaussian Occupancy Prediction", "authors": ["Jinhyung Park", "Yihan Hu", "Chensheng Peng", "Wenzhao Zheng", "Kris Kitani", "Wei Zhan"], "summary": "Despite the demonstrated efficiency and performance of sparse query-based\nrepresentations for perception, state-of-the-art 3D occupancy prediction\nmethods still rely on voxel-based or dense Gaussian-based 3D representations.\nHowever, dense representations are slow, and they lack flexibility in capturing\nthe temporal dynamics of driving scenes. Distinct from prior work, we instead\nsummarize the scene into a compact set of 3D queries which are propagated\nthrough time in an online, streaming fashion. These queries are then decoded\ninto semantic Gaussians at each timestep. We couple our framework with a\ndenoising rendering objective to guide the queries and their constituent\nGaussians in effectively capturing scene geometry. Owing to its efficient,\nquery-based representation, S2GO achieves state-of-the-art performance on the\nnuScenes and KITTI occupancy benchmarks, outperforming prior art (e.g.,\nGaussianWorld) by 1.5 IoU with 5.9x faster inference.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05473v1", "AI": {"title_translation": "S2GO：流式稀疏高斯占用预测", "tldr": "S2GO提出了一种流式稀疏高斯占用预测方法，通过使用紧凑的3D查询和去噪渲染目标，实现了比现有密集表示方法更快的推理速度和更高的性能。", "motivation": "尽管稀疏基于查询的表示在感知方面表现出效率和性能，但最先进的3D占用预测方法仍然依赖于基于体素或密集高斯的3D表示。这些密集表示速度慢，并且在捕获驾驶场景的时间动态方面缺乏灵活性。", "method": "S2GO将场景总结为一组紧凑的3D查询，这些查询以在线、流式方式随时间传播。这些查询在每个时间步被解码为语义高斯。该框架与一个去噪渲染目标相结合，以引导查询及其组成高斯有效地捕获场景几何。", "result": "由于其高效的、基于查询的表示，S2GO在nuScenes和KITTI占用基准测试上取得了最先进的性能，比现有技术（例如GaussianWorld）的IoU高出1.5，推理速度快5.9倍。", "conclusion": "S2GO通过其高效的稀疏基于查询的表示，显著提高了3D占用预测的性能和推理速度，解决了传统密集表示的局限性。", "translation": "尽管稀疏基于查询的表示在感知方面表现出效率和性能，但最先进的3D占用预测方法仍然依赖于基于体素或密集高斯的3D表示。然而，密集表示速度慢，并且在捕获驾驶场景的时间动态方面缺乏灵活性。与以往的工作不同，我们转而将场景总结为一组紧凑的3D查询，这些查询以在线、流式方式随时间传播。然后，这些查询在每个时间步被解码为语义高斯。我们将我们的框架与一个去噪渲染目标相结合，以引导查询及其组成高斯有效地捕获场景几何。由于其高效的、基于查询的表示，S2GO在nuScenes和KITTI占用基准测试上取得了最先进的性能，比现有技术（例如GaussianWorld）的IoU高出1.5，推理速度快5.9倍。", "summary": "S2GO提出了一种新颖的流式稀疏高斯占用预测方法，旨在克服现有3D占用预测方法中密集表示的局限性。该方法通过将场景表示为紧凑的3D查询集，并将其在线流式传播和解码为语义高斯，实现了高效的时间动态捕获。结合去噪渲染目标，S2GO在nuScenes和KITTI基准测试上取得了最先进的性能，与现有技术相比，IoU提高了1.5，推理速度加快了5.9倍。", "keywords": "稀疏高斯, 占用预测, 流式, 3D查询, S2GO", "comments": "该论文的创新之处在于提出了流式稀疏查询作为3D占用预测的核心表示，有效解决了传统密集表示在速度和时间动态捕获方面的瓶颈。其重要性体现在它不仅在性能上超越了现有技术，更在推理速度上实现了显著提升，这对于实时自动驾驶等应用至关重要。"}}
{"id": "2506.05632", "title": "List-Level Distribution Coupling with Applications to Speculative Decoding and Lossy Compression", "authors": ["Joseph Rowan", "Buu Phan", "Ashish Khisti"], "summary": "We study a relaxation of the problem of coupling probability distributions --\na list of samples is generated from one distribution and an accept is declared\nif any one of these samples is identical to the sample generated from the other\ndistribution. We propose a novel method for generating samples, which extends\nthe Gumbel-max sampling suggested in Daliri et al. (arXiv:2408.07978) for\ncoupling probability distributions. We also establish a corresponding lower\nbound on the acceptance probability, which we call the list matching lemma. We\nnext discuss two applications of our setup. First, we develop a new mechanism\nfor multi-draft speculative sampling that is simple to implement and achieves\nperformance competitive with baselines such as SpecTr and SpecInfer across a\nrange of language tasks. Our method also guarantees a certain degree of drafter\ninvariance with respect to the output tokens which is not supported by existing\nschemes. We also provide a theoretical lower bound on the token level\nacceptance probability. As our second application, we consider distributed\nlossy compression with side information in a setting where a source sample is\ncompressed and available to multiple decoders, each with independent side\ninformation. We propose a compression technique that is based on our\ngeneralization of Gumbel-max sampling and show that it provides significant\ngains in experiments involving synthetic Gaussian sources and the MNIST image\ndataset.", "comment": "Submitted to NeurIPS 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05632v1", "AI": {"title_translation": "列表级分布耦合及其在推测解码和有损压缩中的应用", "tldr": "本文研究了一种新的分布耦合放松问题，提出了一种扩展Gumbel-max采样的新方法，并将其应用于多草稿推测解码和带侧信息的分布式有损压缩，在各项任务中均表现出色。", "motivation": "研究概率分布耦合问题的一种放松形式，即从一个分布生成样本列表，如果其中任何一个与另一个分布生成的样本相同则接受。在此基础上探索其在实际应用中的潜力。", "method": "本文提出了一种新颖的样本生成方法，该方法扩展了Daliri等人提出的Gumbel-max采样，用于耦合概率分布。此外，还建立了一个称为列表匹配引理的接受概率下界。", "result": "在多草稿推测采样方面，开发了一种易于实现的新机制，其性能与SpecTr和SpecInfer等基线在各种语言任务中具有竞争力，并保证了对输出token一定程度的起草者不变性。在带侧信息的分布式有损压缩方面，提出了一种基于Gumbel-max采样泛化的压缩技术，并在涉及合成高斯源和MNIST图像数据集的实验中显示出显著增益。", "conclusion": "本文提出了一种新的列表级分布耦合方法，并在理论上建立了接受概率下界。该方法在多草稿推测解码和分布式有损压缩两个应用中均取得了显著效果，证明了其有效性和优越性。", "translation": "我们研究了概率分布耦合问题的一种放松形式——从一个分布生成一个样本列表，如果其中任何一个样本与从另一个分布生成的样本相同，则声明接受。我们提出了一种新颖的样本生成方法，该方法扩展了Daliri等人（arXiv:2408.07978）建议的用于耦合概率分布的Gumbel-max采样。我们还建立了接受概率的相应下界，我们称之为列表匹配引理。接下来，我们讨论了我们设置的两个应用。首先，我们开发了一种新的多草稿推测采样机制，该机制易于实现，并在一系列语言任务中实现了与SpecTr和SpecInfer等基线相当的性能。我们的方法还保证了对输出token一定程度的起草者不变性，这是现有方案不支持的。我们还提供了token级别接受概率的理论下界。作为我们的第二个应用，我们考虑了带侧信息的分布式有损压缩，在这种设置中，源样本被压缩并提供给多个解码器，每个解码器都具有独立的侧信息。我们提出了一种基于我们对Gumbel-max采样泛化的压缩技术，并表明它在涉及合成高斯源和MNIST图像数据集的实验中提供了显著增益。", "summary": "本文研究了列表级概率分布耦合的放松问题，并提出了一种扩展Gumbel-max采样的新方法，同时建立了列表匹配引理。该方法被成功应用于两个领域：一是多草稿推测解码，实现了与现有先进方法相当的性能，并提供了独特的起草者不变性；二是带侧信息的分布式有损压缩，在实验中显示出显著增益。", "keywords": "列表级分布耦合, 推测解码, 有损压缩, Gumbel-max采样, 列表匹配引理", "comments": "本文的创新点在于提出了列表级分布耦合的新框架和扩展的Gumbel-max采样方法。其重要性体现在为推测解码和分布式有损压缩这两个重要应用提供了理论和实践上的新解决方案，尤其是在推测解码中提供了现有方案不具备的起草者不变性，这可能对模型输出的鲁棒性有积极影响。"}}
{"id": "2506.05482", "title": "OpenRR-5k: A Large-Scale Benchmark for Reflection Removal in the Wild", "authors": ["Jie Cai", "Kangning Yang", "Ling Ouyang", "Lan Fu", "Jiaming Ding", "Jinglin Shen", "Zibo Meng"], "summary": "Removing reflections is a crucial task in computer vision, with significant\napplications in photography and image enhancement. Nevertheless, existing\nmethods are constrained by the absence of large-scale, high-quality, and\ndiverse datasets. In this paper, we present a novel benchmark for Single Image\nReflection Removal (SIRR). We have developed a large-scale dataset containing\n5,300 high-quality, pixel-aligned image pairs, each consisting of a reflection\nimage and its corresponding clean version. Specifically, the dataset is divided\ninto two parts: 5,000 images are used for training, and 300 images are used for\nvalidation. Additionally, we have included 100 real-world testing images\nwithout ground truth (GT) to further evaluate the practical performance of\nreflection removal methods. All image pairs are precisely aligned at the pixel\nlevel to guarantee accurate supervision. The dataset encompasses a broad\nspectrum of real-world scenarios, featuring various lighting conditions, object\ntypes, and reflection patterns, and is segmented into training, validation, and\ntest sets to facilitate thorough evaluation. To validate the usefulness of our\ndataset, we train a U-Net-based model and evaluate it using five widely-used\nmetrics, including PSNR, SSIM, LPIPS, DISTS, and NIQE. We will release both the\ndataset and the code on https://github.com/caijie0620/OpenRR-5k to facilitate\nfuture research in this field.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05482v1", "AI": {"title_translation": "OpenRR-5k：一个大规模野外反射去除基准", "tldr": "OpenRR-5k是一个用于单幅图像反射去除的大规模、高质量、像素对齐的数据集，旨在解决现有数据集的不足。", "motivation": "现有反射去除方法受限于缺乏大规模、高质量和多样化的数据集，这阻碍了该领域的发展。", "method": "本文提出了一个名为OpenRR-5k的单幅图像反射去除（SIRR）新基准。该基准包含5300对高质量、像素对齐的图像对，其中5000张用于训练，300张用于验证。此外，还包括100张没有真实标签的真实世界测试图像。所有图像对都经过精确的像素级对齐，并涵盖了各种真实世界场景。为了验证数据集的有效性，研究人员训练了一个基于U-Net的模型，并使用PSNR、SSIM、LPIPS、DISTS和NIQE五种常用指标进行了评估。", "result": "本文通过训练一个基于U-Net的模型并使用五种常用指标进行评估，验证了所提出数据集的有效性和实用性。", "conclusion": "本文成功构建并推出了OpenRR-5k数据集，这是一个大规模、高质量且多样化的反射去除基准，有望推动单幅图像反射去除领域的研究进展。", "translation": "去除反射是计算机视觉中的一项关键任务，在摄影和图像增强方面具有重要的应用。然而，现有方法受限于缺乏大规模、高质量和多样化的数据集。在本文中，我们提出了一个用于单幅图像反射去除（SIRR）的新颖基准。我们开发了一个包含5300对高质量、像素对齐的图像对的大规模数据集，每对都由一张反射图像及其对应的清晰版本组成。具体而言，该数据集分为两部分：5000张图像用于训练，300张图像用于验证。此外，我们还包含了100张没有真实标签（GT）的真实世界测试图像，以进一步评估反射去除方法的实际性能。所有图像对都在像素级别上精确对齐，以保证准确的监督。该数据集涵盖了广泛的真实世界场景，具有各种照明条件、物体类型和反射模式，并被分割成训练集、验证集和测试集，以促进全面评估。为了验证我们数据集的有用性，我们训练了一个基于U-Net的模型，并使用PSNR、SSIM、LPIPS、DISTS和NIQE五种广泛使用的指标对其进行了评估。我们将在https://github.com/caijie0620/OpenRR-5k上发布数据集和代码，以促进该领域的未来研究。", "summary": "本文介绍了OpenRR-5k，一个针对单幅图像反射去除（SIRR）的大规模新基准。该数据集包含5300对高质量、像素对齐的反射图像及其对应清晰图像，其中5000对用于训练，300对用于验证，并额外提供了100张无真实标签的真实世界测试图像。数据集旨在解决现有数据集中缺乏大规模、高质量和多样性图像的问题，涵盖了广泛的真实世界场景。为验证其有效性，研究人员使用一个基于U-Net的模型进行了训练和评估。该数据集和代码将公开发布，以促进未来的研究。", "keywords": "反射去除, 数据集, 基准, 单幅图像反射去除, 深度学习", "comments": "该论文通过构建一个大规模、高质量且像素对齐的反射去除数据集，解决了当前该领域研究中数据不足的关键瓶颈。数据集的多样性和对齐精度是其主要创新点，有望显著提升反射去除算法的训练效果和泛化能力。其公开发布将极大地促进该领域的进步。"}}
{"id": "2506.05634", "title": "AutoQD: Automatic Discovery of Diverse Behaviors with Quality-Diversity Optimization", "authors": ["Saeed Hedayatian", "Stefanos Nikolaidis"], "summary": "Quality-Diversity (QD) algorithms have shown remarkable success in\ndiscovering diverse, high-performing solutions, but rely heavily on\nhand-crafted behavioral descriptors that constrain exploration to predefined\nnotions of diversity. Leveraging the equivalence between policies and occupancy\nmeasures, we present a theoretically grounded approach to automatically\ngenerate behavioral descriptors by embedding the occupancy measures of policies\nin Markov Decision Processes. Our method, AutoQD, leverages random Fourier\nfeatures to approximate the Maximum Mean Discrepancy (MMD) between policy\noccupancy measures, creating embeddings whose distances reflect meaningful\nbehavioral differences. A low-dimensional projection of these embeddings that\ncaptures the most behaviorally significant dimensions is then used as\nbehavioral descriptors for off-the-shelf QD methods. We prove that our\nembeddings converge to true MMD distances between occupancy measures as the\nnumber of sampled trajectories and embedding dimensions increase. Through\nexperiments in multiple continuous control tasks we demonstrate AutoQD's\nability in discovering diverse policies without predefined behavioral\ndescriptors, presenting a well-motivated alternative to prior methods in\nunsupervised Reinforcement Learning and QD optimization. Our approach opens new\npossibilities for open-ended learning and automated behavior discovery in\nsequential decision making settings without requiring domain-specific\nknowledge.", "comment": "22 pages, 5 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05634v1", "AI": {"title_translation": "AutoQD：基于质量-多样性优化的多样化行为自动发现", "tldr": "AutoQD通过自动生成行为描述符，解决了传统质量-多样性（QD）算法依赖手动定义行为描述符的问题，实现了多样化行为的自动发现。", "motivation": "传统的质量-多样性（QD）算法在发现多样化、高性能解决方案方面表现出色，但严重依赖于手工制作的行为描述符，这限制了探索到预定义的行为多样性概念。", "method": "AutoQD利用策略与占用度量之间的等价性，通过将策略的占用度量嵌入到马尔可夫决策过程中来自动生成行为描述符。该方法利用随机傅里叶特征来近似策略占用度量之间的最大平均差异（MMD），创建距离反映有意义行为差异的嵌入。然后将这些嵌入的低维投影（捕获最具行为意义的维度）用作现成QD方法的行为描述符。该方法证明了嵌入在采样轨迹和嵌入维度增加时收敛到占用度量之间的真实MMD距离。", "result": "通过在多个连续控制任务中的实验，AutoQD证明了其在没有预定义行为描述符的情况下发现多样化策略的能力，为无监督强化学习和QD优化中的现有方法提供了一个充分的替代方案。", "conclusion": "AutoQD的方法为开放式学习和序列决策设置中的自动化行为发现开辟了新的可能性，而无需领域特定知识。", "translation": "质量-多样性（QD）算法在发现多样化、高性能解决方案方面取得了显著成功，但它们严重依赖于手工制作的行为描述符，这限制了探索仅限于预定义的行为多样性概念。本文利用策略与占用度量之间的等价性，提出了一种理论基础的方法，通过在马尔可夫决策过程中嵌入策略的占用度量来自动生成行为描述符。我们的方法AutoQD利用随机傅里叶特征来近似策略占用度量之间的最大平均差异（MMD），创建其距离反映有意义行为差异的嵌入。然后将这些嵌入的低维投影（捕获最具行为意义的维度）用作现成QD方法的行为描述符。我们证明了随着采样轨迹数量和嵌入维度的增加，我们的嵌入收敛到占用度量之间的真实MMD距离。通过在多个连续控制任务中的实验，我们证明了AutoQD在没有预定义行为描述符的情况下发现多样化策略的能力，为无监督强化学习和QD优化中的现有方法提供了一个充分的替代方案。我们的方法为开放式学习和序列决策设置中的自动化行为发现开辟了新的可能性，而无需领域特定知识。", "summary": "本文提出了AutoQD，一种通过自动生成行为描述符来解决质量-多样性（QD）算法对人工描述符依赖的新方法。AutoQD利用策略占用度量和最大平均差异（MMD）创建行为嵌入，并将其低维投影用作QD方法的描述符。实验证明，AutoQD在连续控制任务中无需预定义描述符即可发现多样化策略，为无监督强化学习和QD优化提供了新途径，促进了开放式学习和自动化行为发现。", "keywords": "质量-多样性优化, 行为发现, 占用度量, 最大平均差异, 无监督强化学习", "comments": "AutoQD的创新之处在于其能够自动发现行为描述符，从而克服了传统QD算法在多样性探索上受限的问题。这对于需要大量探索和多样化解决方案的领域，如开放式学习和机器人控制，具有重要意义。该方法通过理论证明其嵌入的收敛性，增加了其可靠性。其在无监督强化学习中的应用潜力尤其值得关注。"}}
{"id": "2506.05359", "title": "Enhancing Meme Token Market Transparency: A Multi-Dimensional Entity-Linked Address Analysis for Liquidity Risk Evaluation", "authors": ["Qiangqiang Liu", "Qian Huang", "Frank Fan", "Haishan Wu", "Xueyan Tang"], "summary": "Meme tokens represent a distinctive asset class within the cryptocurrency\necosystem, characterized by high community engagement, significant market\nvolatility, and heightened vulnerability to market manipulation. This paper\nintroduces an innovative approach to assessing liquidity risk in meme token\nmarkets using entity-linked address identification techniques. We propose a\nmulti-dimensional method integrating fund flow analysis, behavioral similarity,\nand anomalous transaction detection to identify related addresses. We develop a\ncomprehensive set of liquidity risk indicators tailored for meme tokens,\ncovering token distribution, trading activity, and liquidity metrics. Empirical\nanalysis of tokens like BabyBonk, NMT, and BonkFork validates our approach,\nrevealing significant disparities between apparent and actual liquidity in meme\ntoken markets. The findings of this study provide significant empirical\nevidence for market participants and regulatory authorities, laying a\ntheoretical foundation for building a more transparent and robust meme token\necosystem.", "comment": "IEEE International Conference on Blockchain and Cryptocurrency (Proc.\n  IEEE ICBC 2025)", "cate": "q-fin.ST", "url": "http://arxiv.org/pdf/2506.05359v1", "AI": {"title_translation": "提升Meme代币市场透明度：一种用于流动性风险评估的多维度实体关联地址分析", "tldr": "本文提出一种多维度实体关联地址分析方法，以评估Meme代币市场的流动性风险，揭示了表观流动性与实际流动性之间的差异，并为市场参与者和监管机构提供了经验证据。", "motivation": "Meme代币作为一种独特的加密货币资产，具有高社区参与度、显著市场波动性和易受市场操纵的特点，因此需要一种评估其流动性风险的创新方法。", "method": "提出了一种多维度方法，整合资金流分析、行为相似性和异常交易检测来识别相关地址，并开发了一套针对Meme代币的综合流动性风险指标，涵盖代币分布、交易活动和流动性指标。", "result": "对BabyBonk、NMT和BonkFork等代币的实证分析验证了所提出的方法，并揭示了Meme代币市场中表观流动性与实际流动性之间存在显著差异。", "conclusion": "本研究的发现为市场参与者和监管机构提供了重要的经验证据，为构建更透明、更健壮的Meme代币生态系统奠定了理论基础。", "translation": "Meme代币代表了加密货币生态系统中的一种独特资产类别，其特点是社区参与度高、市场波动性大以及极易受到市场操纵。本文引入了一种创新方法，利用实体关联地址识别技术来评估Meme代币市场的流动性风险。我们提出了一种多维度方法，整合资金流分析、行为相似性和异常交易检测，以识别相关地址。我们开发了一套针对Meme代币的综合流动性风险指标，涵盖代币分布、交易活动和流动性指标。对BabyBonk、NMT和BonkFork等代币的实证分析验证了我们的方法，揭示了Meme代币市场中表观流动性与实际流动性之间存在显著差异。本研究的发现为市场参与者和监管机构提供了重要的经验证据，为构建更透明和更健壮的Meme代币生态系统奠定了理论基础。", "summary": "本文提出了一种创新的多维度实体关联地址分析方法，用于评估Meme代币市场的流动性风险。该方法整合了资金流分析、行为相似性和异常交易检测，并开发了专门的流动性风险指标。实证分析揭示了Meme代币市场中表观流动性与实际流动性之间的显著差异，为市场参与者和监管机构提供了重要的经验证据，旨在提升Meme代币市场的透明度和稳健性。", "keywords": "Meme代币, 流动性风险, 实体关联地址分析, 市场透明度, 加密货币", "comments": "本文的创新之处在于提出了一种多维度实体关联地址分析方法来评估Meme代币的流动性风险，这对于理解和管理Meme代币市场的高波动性和操纵风险具有重要意义。研究结果揭示了Meme代币市场中表观流动性与实际流动性之间的差异，为市场透明度和监管提供了新的视角和经验基础。"}}
{"id": "2506.05413", "title": "SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs", "authors": ["Patrik Czakó", "Gábor Kertész", "Sándor Szénási"], "summary": "We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.", "comment": "6 pages, 3 figures, 5 tables. Submitted to the IEEE SMC 2025\n  conference", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05413v1", "AI": {"title_translation": "SmoothRot：结合通道级缩放和旋转以实现量化友好的大型语言模型", "tldr": "SmoothRot是一种新的后训练量化技术，通过结合通道级缩放和Hadamard变换，显著提高了LLM中4位量化的效率和准确性，减少了量化模型与FP16模型之间的性能差距，且不增加推理延迟。", "motivation": "提高大型语言模型（LLM）中4位量化的效率，解决大规模激活异常值这一关键挑战，以缩小量化模型与FP16模型之间的性能差距。", "method": "SmoothRot通过结合通道级缩放（channel-wise scaling）和Hadamard变换来解决大规模激活异常值问题。该技术能有效地将极端异常值转换为有利于量化的激活值。", "result": "在LLaMA2 7B、LLaMA3.1 8B和Mistral 7B等流行LLM上的实验表明，SmoothRot在语言生成和零样本推理任务中，持续将量化模型与FP16模型之间的性能差距缩小约10-30%，且不引入额外的推理延迟。", "conclusion": "SmoothRot通过其创新的通道级缩放和Hadamard变换结合，显著提高了LLM 4位量化的准确性和效率，有效缩小了与全精度模型的性能差距，同时保持了推理速度。", "translation": "我们提出了SmoothRot，一种新颖的后训练量化技术，旨在提高大型语言模型（LLM）中4位量化的效率。SmoothRot通过将通道级缩放与Hadamard变换相结合，解决了大规模激活异常值的关键挑战。我们的技术有效地将极端异常值转换为有利于量化的激活值，显著提高了量化精度。在流行的LLM（LLaMA2 7B、LLaMA3.1 8B和Mistral 7B）上进行的实验表明，SmoothRot在语言生成和零样本推理任务中，持续将量化模型与FP16模型之间的性能差距缩小约10-30%，且不引入额外的推理延迟。代码可在https://github.com/czakop/smoothrot获取。", "summary": "本文提出了SmoothRot，一种新颖的后训练量化技术，旨在提升大型语言模型（LLM）中4位量化的效率。SmoothRot通过整合通道级缩放和Hadamard变换来解决大规模激活异常值的关键问题，从而将极端异常值转化为有利于量化的激活值，显著提高了量化精度。实验结果表明，在多种流行LLM上，SmoothRot在语言生成和零样本推理任务中，能持续将量化模型与FP16模型之间的性能差距缩小约10-30%，且不增加推理延迟。", "keywords": "后训练量化, 大型语言模型, 4位量化, 激活异常值, Hadamard变换", "comments": "SmoothRot的创新点在于结合了通道级缩放和Hadamard变换来处理激活异常值，这对于提升低比特量化（如4位）的准确性至关重要。其在不引入额外推理延迟的情况下，显著缩小了量化模型与全精度模型之间的性能差距，这对于在资源受限设备上部署LLM具有重要意义。"}}
{"id": "2506.05636", "title": "Bayesian Inference for Correlated Human Experts and Classifiers", "authors": ["Markelle Kelly", "Alex Boyd", "Sam Showalter", "Mark Steyvers", "Padhraic Smyth"], "summary": "Applications of machine learning often involve making predictions based on\nboth model outputs and the opinions of human experts. In this context, we\ninvestigate the problem of querying experts for class label predictions, using\nas few human queries as possible, and leveraging the class probability\nestimates of pre-trained classifiers. We develop a general Bayesian framework\nfor this problem, modeling expert correlation via a joint latent\nrepresentation, enabling simulation-based inference about the utility of\nadditional expert queries, as well as inference of posterior distributions over\nunobserved expert labels. We apply our approach to two real-world medical\nclassification problems, as well as to CIFAR-10H and ImageNet-16H,\ndemonstrating substantial reductions relative to baselines in the cost of\nquerying human experts while maintaining high prediction accuracy.", "comment": "accepted to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05636v1", "AI": {"title_translation": "关联人类专家和分类器的贝叶斯推断", "tldr": "该研究提出了一种贝叶斯框架，用于在机器学习应用中有效结合人类专家和预训练分类器的预测，以最小化人类查询成本同时保持高准确性。", "motivation": "在机器学习应用中，需要结合模型输出和人类专家意见进行预测。研究的动机是解决如何以尽可能少的人类查询来获取类标签预测，并利用预训练分类器的类概率估计。", "method": "提出了一种通用的贝叶斯框架，通过联合潜在表示对专家相关性进行建模，从而能够对额外专家查询的效用进行基于模拟的推断，以及推断未观察到的专家标签的后验分布。", "result": "将该方法应用于两个真实的医学分类问题以及CIFAR-10H和ImageNet-16H数据集，结果表明在保持高预测准确性的同时，相对于基线显著降低了查询人类专家的成本。", "conclusion": "该贝叶斯框架能够有效结合人类专家和分类器，显著降低人类查询成本，同时保持高预测准确性，在实际应用中具有重要价值。", "translation": "机器学习的应用通常涉及根据模型输出和人类专家的意见进行预测。在此背景下，我们研究了查询专家以获取类别标签预测的问题，目标是尽可能少地进行人工查询，并利用预训练分类器的类别概率估计。我们为此问题开发了一个通用的贝叶斯框架，通过联合潜在表示对专家相关性进行建模，从而能够对额外专家查询的效用进行基于模拟的推断，以及推断未观察到的专家标签的后验分布。我们将我们的方法应用于两个真实的医学分类问题，以及CIFAR-10H和ImageNet-16H数据集，结果表明在保持高预测准确性的同时，相对于基线显著降低了查询人类专家的成本。", "summary": "本文提出了一个通用的贝叶斯框架，用于在机器学习应用中，结合人类专家和预训练分类器的预测，以最小化人工查询成本。该框架通过联合潜在表示建模专家相关性，并支持基于模拟的推断。实验证明，在医学分类和图像分类任务中，该方法能显著降低查询成本，同时保持高预测精度。", "keywords": "贝叶斯推断, 人类专家, 分类器, 专家相关性, 主动学习", "comments": "这篇论文的创新点在于提出了一个通用的贝叶斯框架来解决结合人类专家和机器学习模型预测的问题，特别是在专家之间存在相关性的情况下。通过建模专家相关性并进行基于模拟的推断，该方法有效地减少了对人类专家的查询需求，这在实际应用中，尤其是在专家资源昂贵或稀缺的领域（如医学诊断）具有重要意义。其在真实世界数据集上的表现证明了其实用性和有效性。"}}
{"id": "2506.05398", "title": "IGSM: Improved Geometric and Sensitivity Matching for Finetuning Pruned Diffusion Models", "authors": ["Caleb Zheng", "Eli Shlizerman"], "summary": "Diffusion models achieve realistic outcomes across a wide range of generative\ntasks, but their high computational cost remains a major barrier to deployment.\nModel pruning has emerged as a promising strategy to reduce inference cost and\nenable lightweight diffusion models. While effective, pruned diffusion models\nare proned to quality reduction due to limited capacity. A key limitation of\ncurrent pruning approaches is that pruned models are finetuned using the same\nobjective as the dense model, typically denoising score matching (DSM). Since\nthe dense model is accessible during finetuning, it warrants a more effective\napproach for knowledge transfer from the dense to the pruned model. Motivated\nby this aim, we revisit the finetuning stage and propose IGSM\n(\\textbf{I}mproved \\textbf{G}eometric and \\textbf{S}ensitivity\n\\textbf{M}atching), a general-purpose finetuning framework that introduces a\nsecond-order Jacobian projection loss inspired by Finite-Time Lyapunov\nExponents (FTLE). IGSM efficiently captures and aligns the geometric and the\ntemporal dynamics of pruned models with their dense teachers using scalable\nsecond-order projections. Our approach is architecture-agnostic and applies to\nboth U-Net- and Transformer-based diffusion models. Experiments on CIFAR-10,\nCelebA, LSUN-Church, and LSUN-Bedroom show that IGSM consistently narrows the\nperformance gap between pruned and dense models, substantially improving sample\nquality. Code is available on GitHub: https://github.com/FATE4869/IGSM-Official", "comment": "23 pages, 4 figures", "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.05398v1", "AI": {"title_translation": "IGSM: 改进的几何和敏感度匹配用于微调剪枝扩散模型", "tldr": "提出IGSM框架，通过改进微调方法，显著提升剪枝扩散模型的性能，缩小与原始密集模型的差距。", "motivation": "扩散模型计算成本高，剪枝可降低成本但会降低模型质量。现有剪枝模型微调方法使用与密集模型相同的目标，效果不佳。本文旨在探索更有效的知识从密集模型到剪枝模型的迁移方法。", "method": "提出IGSM（Improved Geometric and Sensitivity Matching）通用微调框架，引入受有限时间李雅普诺夫指数（FTLE）启发的二阶雅可比投影损失。IGSM通过可扩展的二阶投影有效地捕捉并对齐剪枝模型与其密集教师模型的几何和时间动态。该方法与架构无关，适用于U-Net和Transformer基扩散模型。", "result": "在CIFAR-10、CelebA、LSUN-Church和LSUN-Bedroom上的实验表明，IGSM持续缩小剪枝模型与密集模型之间的性能差距，显著提高了样本质量。", "conclusion": "IGSM通过改进微调阶段，有效提升了剪枝扩散模型的性能和样本质量，缩小了与原始密集模型的差距。", "translation": "扩散模型在广泛的生成任务中取得了逼真的结果，但其高计算成本仍然是部署的主要障碍。模型剪枝已成为一种有前景的策略，可以降低推理成本并实现轻量级扩散模型。尽管有效，但剪枝扩散模型由于容量有限，容易出现质量下降。当前剪枝方法的一个关键限制是，剪枝模型使用与密集模型相同的目标（通常是去噪分数匹配（DSM））进行微调。由于在微调期间可以访问密集模型，因此需要一种更有效的方法将知识从密集模型转移到剪枝模型。受此目的的启发，我们重新审视了微调阶段，并提出了IGSM（改进的几何和敏感度匹配），这是一个通用的微调框架，引入了受有限时间李雅普诺夫指数（FTLE）启发的二阶雅可比投影损失。IGSM使用可扩展的二阶投影有效地捕捉并对齐剪枝模型与其密集教师模型的几何和时间动态。我们的方法与架构无关，适用于基于U-Net和Transformer的扩散模型。在CIFAR-10、CelebA、LSUN-Church和LSUN-Bedroom上的实验表明，IGSM持续缩小剪枝模型与密集模型之间的性能差距，显著提高了样本质量。代码已在GitHub上提供。", "summary": "扩散模型计算成本高，剪枝虽能降低成本但常导致质量下降。现有微调方法未充分利用密集模型信息。本文提出IGSM框架，通过引入基于FTLE的二阶雅可比投影损失，在微调阶段有效对齐剪枝模型与密集教师模型的几何和时间动态。实验证明IGSM显著提升了剪枝模型的样本质量，缩小了与密集模型的性能差距。", "keywords": "扩散模型, 模型剪枝, 微调, 几何匹配, 敏感度匹配", "comments": "该论文创新性在于引入了二阶雅可比投影损失来改进剪枝扩散模型的微调过程，有效利用了密集教师模型的知识。这对于部署轻量级扩散模型具有重要意义，因为它解决了剪枝模型普遍存在的质量下降问题。"}}
{"id": "2506.05683", "title": "Multi-Modal Multi-Task Federated Foundation Models for Next-Generation Extended Reality Systems: Towards Privacy-Preserving Distributed Intelligence in AR/VR/MR", "authors": ["Fardis Nadimi", "Payam Abdisarabshali", "Kasra Borazjani", "Jacob Chakareski", "Seyyedali Hosseinalipour"], "summary": "Extended reality (XR) systems, which consist of virtual reality (VR),\naugmented reality (AR), and mixed reality (XR), offer a transformative\ninterface for immersive, multi-modal, and embodied human-computer interaction.\nIn this paper, we envision that multi-modal multi-task (M3T) federated\nfoundation models (FedFMs) can offer transformative capabilities for XR systems\nthrough integrating the representational strength of M3T foundation models\n(FMs) with the privacy-preserving model training principles of federated\nlearning (FL). We present a modular architecture for FedFMs, which entails\ndifferent coordination paradigms for model training and aggregations. Central\nto our vision is the codification of XR challenges that affect the\nimplementation of FedFMs under the SHIFT dimensions: (1) Sensor and modality\ndiversity, (2) Hardware heterogeneity and system-level constraints, (3)\nInteractivity and embodied personalization, (4) Functional/task variability,\nand (5) Temporality and environmental variability. We illustrate the\nmanifestation of these dimensions across a set of emerging and anticipated\napplications of XR systems. Finally, we propose evaluation metrics, dataset\nrequirements, and design tradeoffs necessary for the development of\nresource-aware FedFMs in XR. This perspective aims to chart the technical and\nconceptual foundations for context-aware privacy-preserving intelligence in the\nnext generation of XR systems.", "comment": "16 pages, 4 Figures, 8 Tables", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05683v1", "AI": {"title_translation": "多模态多任务联邦基础模型用于下一代扩展现实系统：迈向AR/VR/MR中的隐私保护分布式智能", "tldr": "该论文提出多模态多任务联邦基础模型（FedFMs）以实现下一代XR系统中隐私保护的分布式智能。", "motivation": "扩展现实（XR）系统提供了变革性的人机交互界面，但其面临数据隐私和分布式智能的挑战。论文旨在通过整合多模态多任务基础模型（FMs）的表示能力和联邦学习（FL）的隐私保护训练原则，为XR系统提供变革性能力，以解决这些挑战。", "method": "论文提出了一个模块化的多模态多任务联邦基础模型（FedFMs）架构，该架构包含不同的模型训练和聚合协调范式。此外，论文通过SHIFT维度（传感器和模态多样性、硬件异构性和系统级约束、交互性和具身个性化、功能/任务可变性、时间性和环境可变性）对影响FedFMs在XR中实施的挑战进行了编码，并提出了开发资源感知型FedFMs所需的评估指标、数据集要求和设计权衡。", "result": "论文设想了多模态多任务联邦基础模型（FedFMs）为XR系统带来的变革性能力，并阐释了SHIFT维度在XR系统新兴和预期应用中的体现。它还提出了开发资源感知型FedFMs所需的评估指标、数据集要求和设计权衡。", "conclusion": "本视角旨在为下一代XR系统中上下文感知隐私保护智能奠定技术和概念基础。", "translation": "扩展现实（XR）系统，包括虚拟现实（VR）、增强现实（AR）和混合现实（XR），为沉浸式、多模态和具身人机交互提供了变革性的界面。在本文中，我们设想多模态多任务（M3T）联邦基础模型（FedFMs）可以通过整合M3T基础模型（FMs）的表示能力与联邦学习（FL）的隐私保护模型训练原则，为XR系统提供变革性能力。我们提出了一个模块化的FedFMs架构，其中包含不同的模型训练和聚合协调范式。我们愿景的核心是对影响FedFMs在SHIFT维度下实现XR挑战的编码：(1) 传感器和模态多样性，(2) 硬件异构性和系统级约束，(3) 交互性和具身个性化，(4) 功能/任务可变性，以及 (5) 时间性和环境可变性。我们阐释了这些维度在XR系统一系列新兴和预期应用中的体现。最后，我们提出了开发XR中资源感知型FedFMs所需的评估指标、数据集要求和设计权衡。本视角旨在为下一代XR系统中上下文感知隐私保护智能绘制技术和概念基础。", "summary": "本文设想并探讨了多模态多任务联邦基础模型（FedFMs）在下一代扩展现实（XR）系统中的应用潜力。通过结合多模态多任务基础模型（FMs）的表示能力和联邦学习（FL）的隐私保护特性，FedFMs旨在为XR提供变革性能力。论文提出了一个模块化的FedFMs架构，并编码了影响其实施的XR挑战（SHIFT维度）。此外，文章还提出了开发资源感知型FedFMs的评估指标、数据集要求和设计权衡，旨在为未来XR系统中的隐私保护分布式智能奠定基础。", "keywords": "联邦学习, 基础模型, 扩展现实, 多模态, 隐私保护", "comments": "这篇论文的创新点在于将联邦学习与多模态多任务基础模型结合，以应对XR系统中隐私保护和分布式智能的挑战。其提出的SHIFT维度为未来研究提供了清晰的框架，具有重要的理论和实践指导意义。"}}
{"id": "2506.05488", "title": "Implicit Neural Representation for Video Restoration", "authors": ["Mary Aiyetigbo", "Wanqi Yuan", "Feng Luo", "Nianyi Li"], "summary": "High-resolution (HR) videos play a crucial role in many computer vision\napplications. Although existing video restoration (VR) methods can\nsignificantly enhance video quality by exploiting temporal information across\nvideo frames, they are typically trained for fixed upscaling factors and lack\nthe flexibility to handle scales or degradations beyond their training\ndistribution. In this paper, we introduce VR-INR, a novel video restoration\napproach based on Implicit Neural Representations (INRs) that is trained only\non a single upscaling factor ($\\times 4$) but generalizes effectively to\narbitrary, unseen super-resolution scales at test time. Notably, VR-INR also\nperforms zero-shot denoising on noisy input, despite never having seen noisy\ndata during training. Our method employs a hierarchical\nspatial-temporal-texture encoding framework coupled with multi-resolution\nimplicit hash encoding, enabling adaptive decoding of high-resolution and\nnoise-suppressed frames from low-resolution inputs at any desired\nmagnification. Experimental results show that VR-INR consistently maintains\nhigh-quality reconstructions at unseen scales and noise during training,\nsignificantly outperforming state-of-the-art approaches in sharpness, detail\npreservation, and denoising efficacy.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05488v1", "AI": {"title_translation": "视频恢复的隐式神经表示", "tldr": "VR-INR使用隐式神经表示，在单一训练尺度下实现任意尺度视频超分辨率和零样本去噪。", "motivation": "现有视频恢复方法通常针对固定上采样因子训练，缺乏处理超出其训练分布的尺度或退化的灵活性。", "method": "本文提出VR-INR，一种基于隐式神经表示（INRs）的新型视频恢复方法。它采用分层时空纹理编码框架，并结合多分辨率隐式哈希编码，从而能够从低分辨率输入自适应地解码任意所需放大倍数的高分辨率和噪声抑制帧。", "result": "VR-INR在训练中未见的尺度和噪声下始终保持高质量重建，在清晰度、细节保留和去噪效果方面显著优于现有最先进方法。", "conclusion": "VR-INR通过隐式神经表示，解决了现有视频恢复方法在处理任意尺度和未见噪声方面的局限性，并展现出卓越的性能。", "translation": "高分辨率（HR）视频在许多计算机视觉应用中发挥着关键作用。尽管现有的视频恢复（VR）方法可以通过利用视频帧之间的时间信息显著提高视频质量，但它们通常针对固定的上采样因子进行训练，并且缺乏处理超出其训练分布的尺度或退化的灵活性。在本文中，我们引入了VR-INR，一种基于隐式神经表示（INRs）的新型视频恢复方法，该方法仅在单一上采样因子（×4）上进行训练，但在测试时能有效泛化到任意、未见的超分辨率尺度。值得注意的是，尽管VR-INR在训练期间从未见过噪声数据，但它还能对噪声输入执行零样本去噪。我们的方法采用分层时空纹理编码框架，并结合多分辨率隐式哈希编码，从而能够从低分辨率输入自适应地解码任意所需放大倍数的高分辨率和噪声抑制帧。实验结果表明，VR-INR在训练中未见的尺度和噪声下始终保持高质量重建，在清晰度、细节保留和去噪效果方面显著优于现有最先进方法。", "summary": "本文提出VR-INR，一种基于隐式神经表示（INRs）的视频恢复新方法。与传统方法不同，VR-INR仅通过单一尺度训练（×4），即可泛化到任意未见超分辨率尺度，并能实现零样本去噪。该方法利用分层时空纹理编码和多分辨率隐式哈希编码，实现从低分辨率输入自适应解码高分辨率和降噪帧。实验证明，VR-INR在未见尺度和噪声下表现出色，超越现有技术。", "keywords": "视频恢复, 隐式神经表示, 超分辨率, 零样本去噪, 泛化性", "comments": "该论文的创新点在于将隐式神经表示应用于视频恢复领域，解决了传统方法在处理任意尺度和未见退化时的泛化性问题。特别是其零样本去噪能力，在训练数据不包含噪声的情况下实现，展示了该方法的强大鲁棒性和普适性，具有重要的研究价值和实际应用潜力。"}}
{"id": "2506.05641", "title": "Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones", "authors": ["Andrey Zhmoginov", "Jihwan Lee", "Mark Sandler"], "summary": "Modern Foundation Models (FMs) are typically trained on corpora spanning a\nwide range of different data modalities, topics and downstream tasks. Utilizing\nthese models can be very computationally expensive and is out of reach for most\nconsumer devices. Furthermore, most of the broad FM knowledge may actually be\nirrelevant for a specific task at hand. Here we explore a technique for mapping\nparameters of a large Transformer to parameters of a smaller specialized model.\nBy making this transformation task-specific, we aim to capture a narrower scope\nof the knowledge needed for performing a specific task by a smaller model. We\nstudy our method on image modeling tasks, showing that performance of generated\nmodels exceeds that of universal conditional models.", "comment": "Presented at ES-FoMo II: 2nd Workshop on Efficient Systems for\n  Foundation Models (ICML 2024)", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05641v1", "AI": {"title_translation": "可投影模型：从大型模型中一次性生成小型专用Transformer", "tldr": "从大型Transformer一次性生成小型专用Transformer，以降低计算成本并提高特定任务的效率，在图像建模任务上表现优异。", "motivation": "现代基础模型（FMs）计算成本高昂，且其广泛知识对特定任务而言可能无关紧要，因此需要一种更高效、更专业化的模型。", "method": "本文探讨了一种将大型Transformer的参数映射到较小型专用模型参数的技术。通过使这种转换具有任务特异性，旨在让较小型模型捕获执行特定任务所需的更窄范围的知识。", "result": "在图像建模任务上，所生成模型的性能超过了通用条件模型。", "conclusion": "通过参数映射可以有效地从大型Transformer生成小型专用模型，这些模型在特定任务上表现出色，且计算效率更高。", "translation": "现代基础模型（FMs）通常在涵盖广泛不同数据模态、主题和下游任务的语料库上进行训练。利用这些模型可能计算成本非常高昂，并且超出了大多数消费设备的承受范围。此外，大多数广泛的FM知识实际上可能与手头的特定任务无关。本文探讨了一种将大型Transformer的参数映射到较小型专用模型参数的技术。通过使这种转换具有任务特异性，我们旨在让较小型模型捕获执行特定任务所需的更窄范围的知识。我们在图像建模任务上研究了我们的方法，结果表明所生成模型的性能超过了通用条件模型。", "summary": "本文提出了一种名为“可投影模型”的新技术，旨在通过将大型Transformer的参数一次性映射到小型专用模型来解决现代基础模型计算成本高昂且知识冗余的问题。这种任务特定的转换使得小型模型能够捕获执行特定任务所需的更精细知识。研究在图像建模任务上验证了该方法，结果表明生成的模型性能优于通用条件模型，证明了其在生成高效、专业化模型方面的潜力。", "keywords": "Projectable Models, Specialized Transformers, One-Shot Generation, Foundation Models, Parameter Mapping", "comments": "该研究提出了一种新颖的方法，通过参数映射实现从大型通用模型到小型专业化模型的知识迁移，有效解决了大模型部署的计算成本和任务特异性问题。其创新点在于“一次性生成”和“任务特定转换”，有望在边缘设备和特定应用场景中推广，但其泛化能力和对其他模态任务的适用性仍需进一步探索。"}}
{"id": "2506.05908", "title": "QualitEye: Public and Privacy-preserving Gaze Data Quality Verification", "authors": ["Mayar Elfares", "Pascal Reisert", "Ralf Küsters", "Andreas Bulling"], "summary": "Gaze-based applications are increasingly advancing with the availability of\nlarge datasets but ensuring data quality presents a substantial challenge when\ncollecting data at scale. It further requires different parties to collaborate,\ntherefore, privacy concerns arise. We propose QualitEye--the first method for\nverifying image-based gaze data quality. QualitEye employs a new semantic\nrepresentation of eye images that contains the information required for\nverification while excluding irrelevant information for better domain\nadaptation. QualitEye covers a public setting where parties can freely exchange\ndata and a privacy-preserving setting where parties cannot reveal their raw\ndata nor derive gaze features/labels of others with adapted private set\nintersection protocols. We evaluate QualitEye on the MPIIFaceGaze and\nGazeCapture datasets and achieve a high verification performance (with a small\noverhead in runtime for privacy-preserving versions). Hence, QualitEye paves\nthe way for new gaze analysis methods at the intersection of machine learning,\nhuman-computer interaction, and cryptography.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05908v1", "AI": {"title_translation": "QualitEye：公开且保护隐私的凝视数据质量验证", "tldr": "QualitEye 是一种验证图像凝视数据质量的方法，支持公开和隐私保护设置。", "motivation": "大规模凝视数据收集面临数据质量保证和多方协作时的隐私挑战。", "method": "QualitEye 提出了一种新的眼睛图像语义表示，用于验证图像凝视数据质量，并支持公开和隐私保护两种设置，其中隐私保护设置使用适应的私有集合交集协议。", "result": "QualitEye 在 MPIIFaceGaze 和 GazeCapture 数据集上实现了高验证性能，且隐私保护版本的运行时开销很小。", "conclusion": "QualitEye 为机器学习、人机交互和密码学交叉领域的新凝视分析方法奠定了基础。", "translation": "凝视应用随着大型数据集的可用性而不断发展，但在大规模收集数据时，确保数据质量提出了巨大挑战。它还需要不同方协作，因此产生了隐私问题。我们提出了 QualitEye——首个用于验证基于图像的凝视数据质量的方法。QualitEye 采用一种新的眼睛图像语义表示，其中包含验证所需的信息，同时排除无关信息以更好地适应领域。QualitEye 涵盖了一个各方可以自由交换数据的公开设置，以及一个各方不能透露其原始数据或通过改编的私有集合交集协议推断他人凝视特征/标签的隐私保护设置。我们在 MPIIFaceGaze 和 GazeCapture 数据集上评估了 QualitEye，并实现了高验证性能（隐私保护版本的运行时开销很小）。因此，QualitEye 为机器学习、人机交互和密码学交叉领域的新凝视分析方法铺平了道路。", "summary": "本文提出了 QualitEye，一个用于验证图像凝视数据质量的首创方法。它通过新的语义表示来处理大规模数据收集中的质量保证和隐私问题。QualitEye 支持公开和隐私保护两种设置，并在实验中展现了高验证性能和低隐私保护开销，为跨领域凝视分析提供了新途径。", "keywords": "凝视数据质量, 隐私保护, 语义表示, 人机交互, 密码学", "comments": "QualitEye 的创新之处在于首次提出了图像凝视数据质量验证方法，并巧妙地解决了大规模数据收集中的隐私问题，通过语义表示和私有集合交集协议实现了公开和隐私保护两种模式，这对于推动凝视分析在实际应用中的发展具有重要意义。"}}
{"id": "2506.05489", "title": "F2T2-HiT: A U-Shaped FFT Transformer and Hierarchical Transformer for Reflection Removal", "authors": ["Jie Cai", "Kangning Yang", "Ling Ouyang", "Lan Fu", "Jiaming Ding", "Huiming Sun", "Chiu Man Ho", "Zibo Meng"], "summary": "Single Image Reflection Removal (SIRR) technique plays a crucial role in\nimage processing by eliminating unwanted reflections from the background. These\nreflections, often caused by photographs taken through glass surfaces, can\nsignificantly degrade image quality. SIRR remains a challenging problem due to\nthe complex and varied reflections encountered in real-world scenarios. These\nreflections vary significantly in intensity, shapes, light sources, sizes, and\ncoverage areas across the image, posing challenges for most existing methods to\neffectively handle all cases. To address these challenges, this paper\nintroduces a U-shaped Fast Fourier Transform Transformer and Hierarchical\nTransformer (F2T2-HiT) architecture, an innovative Transformer-based design for\nSIRR. Our approach uniquely combines Fast Fourier Transform (FFT) Transformer\nblocks and Hierarchical Transformer blocks within a UNet framework. The FFT\nTransformer blocks leverage the global frequency domain information to\neffectively capture and separate reflection patterns, while the Hierarchical\nTransformer blocks utilize multi-scale feature extraction to handle reflections\nof varying sizes and complexities. Extensive experiments conducted on three\npublicly available testing datasets demonstrate state-of-the-art performance,\nvalidating the effectiveness of our approach.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05489v1", "AI": {"title_translation": "F2T2-HiT: 用于反射去除的U型FFT Transformer和分层Transformer", "tldr": "F2T2-HiT是一种结合FFT Transformer和分层Transformer的U型网络，用于从单张图像中去除反射，并在三个公开数据集上取得了最先进的性能。", "motivation": "单图像反射去除（SIRR）技术在图像处理中至关重要，它能消除背景中不必要的反射。这些反射通常由透过玻璃表面拍摄的照片引起，会显著降低图像质量。SIRR仍然是一个具有挑战性的问题，因为现实世界中遇到的反射复杂且多变，在强度、形状、光源、大小和覆盖区域方面差异很大，这使得大多数现有方法难以有效处理所有情况。", "method": "本文提出了一种U型快速傅里叶变换Transformer和分层Transformer（F2T2-HiT）架构，这是一种创新的基于Transformer的SIRR设计。该方法独特地将快速傅里叶变换（FFT）Transformer块和分层Transformer块结合在UNet框架内。FFT Transformer块利用全局频域信息有效捕获和分离反射模式，而分层Transformer块利用多尺度特征提取来处理不同大小和复杂性的反射。", "result": "在三个公开可用测试数据集上进行的广泛实验证明了最先进的性能，验证了我们方法的有效性。", "conclusion": "Not mentioned in abstract", "translation": "单图像反射去除（SIRR）技术在图像处理中发挥着关键作用，通过消除背景中不必要的反射来提升图像质量。这些反射通常是由透过玻璃表面拍摄的照片引起的，会显著降低图像质量。由于现实世界中遇到的反射复杂且多变，SIRR仍然是一个具有挑战性的问题。这些反射在图像中强度、形状、光源、大小和覆盖区域方面差异很大，这给大多数现有方法有效处理所有情况带来了挑战。为了应对这些挑战，本文引入了一种U型快速傅里叶变换Transformer和分层Transformer（F2T2-HiT）架构，这是一种创新的、基于Transformer的SIRR设计。我们的方法独特地将快速傅里叶变换（FFT）Transformer块和分层Transformer块结合在UNet框架内。FFT Transformer块利用全局频域信息有效捕获和分离反射模式，而分层Transformer块利用多尺度特征提取来处理不同大小和复杂性的反射。在三个公开可用测试数据集上进行的广泛实验证明了最先进的性能，验证了我们方法的有效性。", "summary": "本论文提出了一种名为F2T2-HiT的新型Transformer架构，用于单图像反射去除（SIRR）。该模型结合了U型网络、快速傅里叶变换（FFT）Transformer块和分层Transformer块。FFT Transformer块用于捕获全局频域信息以分离反射模式，而分层Transformer块则负责多尺度特征提取以处理不同复杂度的反射。实验结果表明，F2T2-HiT在三个公开数据集上达到了最先进的性能。", "keywords": "单图像反射去除, Transformer, 快速傅里叶变换, 分层Transformer, 图像处理", "comments": "本文的创新点在于将FFT Transformer和分层Transformer巧妙地集成到U-Net框架中，以解决单图像反射去除中复杂多变反射的挑战。通过结合频域信息和多尺度特征，该方法能够更有效地处理不同类型和尺度的反射，对于提升图像质量具有重要意义。"}}
{"id": "2506.05647", "title": "Learning to Weight Parameters for Data Attribution", "authors": ["Shuangqi Li", "Hieu Le", "Jingyi Xu", "Mathieu Salzmann"], "summary": "We study data attribution in generative models, aiming to identify which\ntraining examples most influence a given output. Existing methods achieve this\nby tracing gradients back to training data. However, they typically treat all\nnetwork parameters uniformly, ignoring the fact that different layers encode\ndifferent types of information and may thus draw information differently from\nthe training set. We propose a method that models this by learning parameter\nimportance weights tailored for attribution, without requiring labeled data.\nThis allows the attribution process to adapt to the structure of the model,\ncapturing which training examples contribute to specific semantic aspects of an\noutput, such as subject, style, or background. Our method improves attribution\naccuracy across diffusion models and enables fine-grained insights into how\noutputs borrow from training data.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05647v1", "AI": {"title_translation": "学习为数据归因加权参数", "tldr": "一种新的数据归因方法，通过学习参数重要性权重来识别生成模型中训练数据对输出的影响，提高了归因准确性并提供了细粒度洞察。", "motivation": "现有生成模型中的数据归因方法在追溯梯度时，倾向于统一处理所有网络参数，忽略了不同层编码不同信息，从而无法捕捉训练数据对输出特定语义方面的影响。", "method": "提出了一种无需标注数据的方法，通过学习针对归因的参数重要性权重来建模，使归因过程能够适应模型结构。", "result": "该方法提高了扩散模型中的归因准确性，并能对输出如何从训练数据中借鉴提供细粒度的洞察。", "conclusion": "Not mentioned in abstract", "translation": "我们研究生成模型中的数据归因，旨在识别哪些训练样本对给定输出的影响最大。现有方法通过将梯度追溯回训练数据来实现这一点。然而，它们通常统一处理所有网络参数，忽略了不同层编码不同类型信息并可能以不同方式从训练集中提取信息的事实。我们提出了一种方法，通过学习为归因量身定制的参数重要性权重来对此进行建模，而无需标记数据。这使得归因过程能够适应模型的结构，捕获哪些训练样本有助于输出的特定语义方面，例如主题、风格或背景。我们的方法提高了扩散模型中的归因准确性，并能够对输出如何从训练数据中借鉴提供细粒度的洞察。", "summary": "本文研究生成模型中的数据归因问题，旨在确定训练数据对模型输出的影响。针对现有方法未区分网络参数重要性的不足，本文提出了一种新方法，通过学习参数重要性权重来优化归因过程，使其能适应模型结构并捕捉训练数据对输出特定语义方面（如主题、风格、背景）的贡献。实验结果表明，该方法提高了扩散模型的归因准确性，并提供了关于输出如何借鉴训练数据的细粒度洞察。", "keywords": "数据归因, 生成模型, 参数加权, 扩散模型, 模型可解释性", "comments": "这篇论文的创新点在于提出了学习参数重要性权重的方法，以改进生成模型中的数据归因。它解决了现有方法统一处理参数的局限性，使得归因过程更能适应模型内部结构，从而实现对输出中特定语义元素的更精准归因。这种细粒度的洞察对于理解生成模型的行为和提高其可解释性具有重要意义。"}}
{"id": "2506.05400", "title": "Auto Review: Second Stage Error Detection for Highly Accurate Information Extraction from Phone Conversations", "authors": ["Ayesha Qamar", "Arushi Raghuvanshi", "Conal Sathi", "Youngseo Son"], "summary": "Automating benefit verification phone calls saves time in healthcare and\nhelps patients receive treatment faster. It is critical to obtain highly\naccurate information in these phone calls, as it can affect a patient's\nhealthcare journey. Given the noise in phone call transcripts, we have a\ntwo-stage system that involves a post-call review phase for potentially noisy\nfields, where human reviewers manually verify the extracted\ndata$\\unicode{x2013}$a labor-intensive task. To automate this stage, we\nintroduce Auto Review, which significantly reduces manual effort while\nmaintaining a high bar for accuracy. This system, being highly reliant on call\ntranscripts, suffers a performance bottleneck due to automatic speech\nrecognition (ASR) issues. This problem is further exacerbated by the use of\ndomain-specific jargon in the calls. In this work, we propose a second-stage\npostprocessing pipeline for accurate information extraction. We improve\naccuracy by using multiple ASR alternatives and a pseudo-labeling approach that\ndoes not require manually corrected transcripts. Experiments with\ngeneral-purpose large language models and feature-based model pipelines\ndemonstrate substantial improvements in the quality of corrected call\ntranscripts, thereby enhancing the efficiency of Auto Review.", "comment": "Accepted to ACL Industry track 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05400v1", "AI": {"title_translation": "Auto Review：电话会话中高精度信息提取的第二阶段错误检测", "tldr": "提出Auto Review系统，通过多ASR替代和伪标签方法，显著提高电话会话中信息提取的准确性，减少人工复核。", "motivation": "自动化利益核实电话可节省医疗时间并帮助患者更快获得治疗，但电话转录中的噪音和ASR问题导致信息提取准确性低，需要大量人工复核。", "method": "引入Auto Review系统，作为第二阶段后处理流程。通过使用多个ASR替代方案和无需人工纠正转录的伪标签方法来提高准确性。", "result": "实验证明，使用通用大型语言模型和基于特征的模型管道，显著改善了纠正后的通话转录质量，从而提高了Auto Review的效率。", "conclusion": "通过多ASR替代和伪标签方法，可以有效提高电话会话中信息提取的准确性，减少人工复核需求，克服ASR问题和领域特定术语的挑战。", "translation": "自动化利益核实电话可以节省医疗保健时间，并帮助患者更快地获得治疗。在这些电话中获取高精度信息至关重要，因为它会影响患者的医疗旅程。鉴于电话转录中的噪音，我们有一个两阶段系统，其中包括一个针对可能嘈杂字段的通话后复核阶段，其中人工复核员手动验证提取的数据——这是一项劳动密集型任务。为了自动化此阶段，我们引入了Auto Review，它在保持高准确性标准的同时显著减少了人工工作量。该系统高度依赖通话转录，由于自动语音识别（ASR）问题而面临性能瓶颈。电话中使用的领域特定术语进一步加剧了这个问题。在这项工作中，我们提出了一个用于准确信息提取的第二阶段后处理管道。我们通过使用多个ASR替代方案和无需手动纠正转录的伪标签方法来提高准确性。对通用大型语言模型和基于特征的模型管道进行的实验表明，纠正后的通话转录质量显著提高，从而增强了Auto Review的效率。", "summary": "本文提出了一种名为Auto Review的第二阶段错误检测系统，旨在解决电话会话中信息提取的准确性问题。鉴于电话转录中的噪音和ASR限制导致人工复核工作量大，该系统通过利用多个ASR替代方案和无需人工干预的伪标签方法，显著提高了信息提取的准确性，并减少了人工复核的需求。实验结果表明，该方法有效提升了纠正后通话转录的质量，进而提高了Auto Review系统的效率。", "keywords": "信息提取, 错误检测, 自动语音识别, 伪标签, 医疗保健", "comments": "这项工作通过自动化信息提取的第二阶段复核，显著减少了医疗保健领域人工干预的需求，具有重要的实际应用价值。其创新点在于利用多ASR替代和伪标签技术来克服ASR噪声和领域特定术语的挑战，无需大量人工标注数据，提高了系统的鲁棒性和效率。"}}
{"id": "2506.06003", "title": "What Really is a Member? Discrediting Membership Inference via Poisoning", "authors": ["Neal Mangaokar", "Ashish Hooda", "Zhuohang Li", "Bradley A. Malin", "Kassem Fawaz", "Somesh Jha", "Atul Prakash", "Amrita Roy Chowdhury"], "summary": "Membership inference tests aim to determine whether a particular data point\nwas included in a language model's training set. However, recent works have\nshown that such tests often fail under the strict definition of membership\nbased on exact matching, and have suggested relaxing this definition to include\nsemantic neighbors as members as well. In this work, we show that membership\ninference tests are still unreliable under this relaxation - it is possible to\npoison the training dataset in a way that causes the test to produce incorrect\npredictions for a target point. We theoretically reveal a trade-off between a\ntest's accuracy and its robustness to poisoning. We also present a concrete\ninstantiation of this poisoning attack and empirically validate its\neffectiveness. Our results show that it can degrade the performance of existing\ntests to well below random.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06003v1", "AI": {"title_translation": "什么是真正的成员？通过投毒攻击来否定成员推断", "tldr": "成员推断测试即使在放宽成员定义后，仍然容易受到投毒攻击，导致其表现远低于随机水平。", "motivation": "尽管最近的工作建议放宽成员推断测试中“成员”的定义以提高其可靠性，但本文旨在证明即使在这种放宽的定义下，成员推断测试仍然是不可靠的。", "method": "研究人员通过向训练数据集投毒来展示成员推断测试的不可靠性。他们还从理论上揭示了测试准确性与对投毒的鲁棒性之间的权衡，并具体实例化了这种投毒攻击并进行了实证验证。", "result": "投毒攻击可以导致成员推断测试对目标点产生不正确的预测。理论分析表明测试的准确性与其对投毒的鲁棒性之间存在权衡。实证结果显示，这种攻击能将现有测试的性能降低到远低于随机水平。", "conclusion": "成员推断测试，即使在放宽成员定义的情况下，仍然容易受到训练数据投毒攻击的影响，这使得它们不可靠，并揭示了准确性和鲁棒性之间的基本权衡。", "translation": "成员推断测试旨在确定某个特定数据点是否包含在语言模型的训练集中。然而，最近的研究表明，此类测试在基于精确匹配的严格成员定义下常常失败，并建议放宽此定义，将语义邻居也包括在成员中。在这项工作中，我们表明即使在放宽定义的情况下，成员推断测试仍然不可靠——可以通过一种方式对训练数据集进行投毒，导致测试对目标点产生不正确的预测。我们从理论上揭示了测试准确性与其对投毒的鲁棒性之间的权衡。我们还提出了这种投毒攻击的一个具体实例，并凭经验验证了其有效性。我们的结果表明，它可以将现有测试的性能降低到远低于随机水平。", "summary": "本文探讨了成员推断测试的可靠性问题，即使在放宽“成员”定义以包括语义邻居的情况下。研究表明，通过对训练数据集进行投毒，可以使这些测试对目标点产生错误的预测。作者理论上揭示了测试准确性与对投毒攻击鲁棒性之间的权衡，并通过具体实例和实验验证了投毒攻击的有效性，证明其能显著降低现有成员推断测试的性能。", "keywords": "成员推断, 投毒攻击, 语言模型, 隐私, 鲁棒性", "comments": "这篇论文通过引入投毒攻击的概念，对成员推断测试的鲁棒性提出了重要的质疑。其创新性在于不仅理论上揭示了准确性和鲁棒性之间的权衡，还通过具体的攻击实例和实验验证了其有效性，这对于理解和改进隐私保护机制具有重要意义。它强调了在评估模型隐私时，需要考虑更复杂的攻击向量。"}}
{"id": "2506.05501", "title": "FocusDiff: Advancing Fine-Grained Text-Image Alignment for Autoregressive Visual Generation through RL", "authors": ["Kaihang Pan", "Wendong Bu", "Yuruo Wu", "Yang Wu", "Kai Shen", "Yunfei Li", "Hang Zhao", "Juncheng Li", "Siliang Tang", "Yueting Zhuang"], "summary": "Recent studies extend the autoregression paradigm to text-to-image\ngeneration, achieving performance comparable to diffusion models. However, our\nnew PairComp benchmark -- featuring test cases of paired prompts with similar\nsyntax but different fine-grained semantics -- reveals that existing models\nstruggle with fine-grained text-image alignment thus failing to realize precise\ncontrol over visual tokens. To address this, we propose FocusDiff, which\nenhances fine-grained text-image semantic alignment by focusing on subtle\ndifferences between similar text-image pairs. We construct a new dataset of\npaired texts and images with similar overall expressions but distinct local\nsemantics, further introducing a novel reinforcement learning algorithm to\nemphasize such fine-grained semantic differences for desired image generation.\nOur approach achieves state-of-the-art performance on existing text-to-image\nbenchmarks and significantly outperforms prior methods on PairComp.", "comment": "15 pages, 8 figures. Project Page: https://focusdiff.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05501v1", "AI": {"title_translation": "FocusDiff：通过强化学习推进自回归视觉生成的细粒度文本-图像对齐", "tldr": "FocusDiff通过新的数据集和强化学习算法，解决了现有自回归文本到图像模型在细粒度文本-图像对齐上的不足，并在相关基准测试中取得了SOTA性能。", "motivation": "现有自回归文本到图像生成模型在细粒度文本-图像对齐方面存在困难，无法实现对视觉token的精确控制。为了解决这一问题，研究人员提出了FocusDiff。", "method": "提出了FocusDiff模型，通过关注相似文本-图像对之间的细微差异来增强细粒度文本-图像语义对齐。构建了一个新的配对文本和图像数据集，其中包含总体表达相似但局部语义不同的数据。引入了一种新颖的强化学习算法，以强调这些细粒度语义差异，从而生成所需的图像。", "result": "FocusDiff在现有文本到图像基准测试中取得了最先进的性能，并在PairComp基准测试中显著优于现有方法。", "conclusion": "Not mentioned in abstract", "translation": "\n最近的研究将自回归范式扩展到文本到图像生成，实现了与扩散模型相当的性能。然而，我们新的PairComp基准测试——其测试用例具有语法相似但细粒度语义不同的配对提示——揭示了现有模型在细粒度文本-图像对齐方面存在困难，因此无法实现对视觉token的精确控制。为了解决这个问题，我们提出了FocusDiff，它通过关注相似文本-图像对之间的细微差异来增强细粒度文本-图像语义对齐。我们构建了一个新的配对文本和图像数据集，其中包含总体表达相似但局部语义不同的数据，并进一步引入了一种新颖的强化学习算法，以强调这些细粒度语义差异，从而生成所需的图像。我们的方法在现有文本到图像基准测试中取得了最先进的性能，并在PairComp上显著优于现有方法。\n", "summary": "\n该论文提出了FocusDiff模型，旨在解决现有自回归文本到图像生成模型在细粒度文本-图像对齐上的不足。通过引入新的PairComp基准测试，揭示了当前模型难以实现对视觉token的精确控制。FocusDiff通过构建新的细粒度语义差异数据集并结合新颖的强化学习算法，增强了文本与图像之间的细粒度语义对齐。实验结果表明，FocusDiff在现有文本到图像基准测试中达到SOTA性能，并在PairComp上显著超越了先前的方法。\n", "keywords": "文本到图像生成, 细粒度对齐, 自回归模型, 强化学习, PairComp基准测试", "comments": "\n该论文的创新点在于提出了一个新的基准测试PairComp，专门用于评估模型在细粒度文本-图像对齐方面的能力，这对于推动文本到图像生成领域的发展具有重要意义。同时，FocusDiff通过引入强化学习来解决细微语义差异问题，提供了一种新颖的解决方案。其在SOTA性能上的提升以及在PairComp上的显著优势，表明了该方法在提升生成质量和控制精度方面的潜力。\n"}}
{"id": "2506.05664", "title": "BAQ: Efficient Bit Allocation Quantization for Large Language Models", "authors": ["Chao Zhang", "Li Wang", "Samson Lasaulce", "Merouane Debbah"], "summary": "Post-training model quantization is a widely adopted technique for reducing\nthe memory and computational costs of large language models (LLMs). However,\nmost existing methods rely on uniform or heuristic bitwidth assignments,\nfailing to account for the nonuniform sensitivity of weights to quantization\nnoise. In this paper, we propose a novel framework for allocating quantization\nbitwidths based on sensitivity metrics derived from a Hessian proxy. We make\nkey assumptions, which allow the layer/component-wise loss function to be\nexpressed as an explicit function of the bitwidths. This enables a neat\nformulation of the bit allocation problem as a convex optimization task, whose\nclosed-form solution adapts precision across weights to minimize the layer-wise\nquantization loss. Inspecting the solution provides several insights (such as\nthe equal-loss structure), which are then exploited to design the proposed\n\\textbf{BAQ} (Bit Allocation Quantization) algorithm. The proposed algorithm\nachieves a good trade-off between loss minimization and complexity and allows\nBAQ to be integrated into standard quantization pipelines with minimal\noverhead. Experimental results show that BAQ consistently outperforms GPTQ,\nachieving up to 56$\\times$ lower perplexity at the same bitwidth on large\nlanguage models ranging from 125M to 30B parameters. Leveraging our analytical\nresults derived from solving the optimal bit allocation problem, we also\nprovide a theoretical explanation for the observed gains. All codes of this\npaper are available at https://github.com/CSU-ModelCompression/BAQ.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05664v1", "AI": {"title_translation": "BAQ：大语言模型高效比特分配量化", "tldr": "BAQ是一种基于Hessian代理的比特分配量化方法，通过凸优化最小化量化损失，在大语言模型上显著优于现有方法。", "motivation": "现有的大语言模型后训练量化方法大多依赖统一或启发式比特宽度分配，未能考虑权重对量化噪声的非均匀敏感性，导致量化效果不佳。", "method": "本文提出了一种基于Hessian代理导出的敏感度指标来分配量化比特宽度的新框架。通过关键假设，将层/组件的损失函数表示为比特宽度的显式函数，从而将比特分配问题表述为一个凸优化任务，其闭式解能自适应地调整权重精度以最小化层级量化损失。基于这些分析结果，设计了BAQ（比特分配量化）算法。", "result": "BAQ在相同的比特宽度下，在大语言模型（1.25亿到300亿参数）上，相较于GPTQ实现了高达56倍的困惑度降低，表现出显著的性能提升。", "conclusion": "BAQ算法通过优化的比特分配策略，成功地在最小化损失和复杂度之间取得了良好平衡，并能以最小的开销集成到标准量化流程中，从而显著提高了大语言模型的量化性能。", "translation": "后训练模型量化是一种广泛采用的技术，用于降低大型语言模型（LLMs）的内存和计算成本。然而，大多数现有方法依赖于统一或启发式比特宽度分配，未能考虑到权重对量化噪声的非均匀敏感性。在本文中，我们提出了一种基于Hessian代理导出的敏感度指标来分配量化比特宽度的新颖框架。我们做出了关键假设，使得层/组件的损失函数可以表示为比特宽度的显式函数。这使得比特分配问题可以整洁地表述为一个凸优化任务，其闭式解可以自适应地调整权重精度以最小化层级量化损失。对解的检查提供了几点见解（例如等损失结构），这些见解随后被用于设计所提出的BAQ（比特分配量化）算法。所提出的算法在损失最小化和复杂度之间取得了良好的平衡，并允许BAQ以最小的开销集成到标准量化流程中。实验结果表明，BAQ始终优于GPTQ，在1.25亿到300亿参数的大型语言模型上，在相同比特宽度下实现了高达56倍的困惑度降低。利用从解决最优比特分配问题中获得的分析结果，我们还为观察到的增益提供了理论解释。本文的所有代码都可在https://github.com/CSU-ModelCompression/BAQ获得。", "summary": "本文提出了一种名为BAQ（比特分配量化）的新颖框架，旨在解决大语言模型后训练量化中比特宽度分配不均匀的问题。BAQ利用基于Hessian代理的敏感度指标，将比特分配建模为凸优化问题，并导出了闭式解以最小化层级量化损失。实验结果表明，BAQ在相同比特宽度下，相比GPTQ显著降低了困惑度，展现了卓越的性能和效率。", "keywords": "比特分配, 量化, 大语言模型, Hessian代理, 凸优化", "comments": "BAQ的创新之处在于将比特分配问题转化为一个可求解的凸优化任务，并利用Hessian代理来衡量权重敏感性，这提供了一个理论上更优的量化策略。其在实际应用中表现出的显著性能提升（高达56倍困惑度降低）表明了其重要性，并且其低开销的集成能力也增强了实用性。"}}
{"id": "2506.06018", "title": "Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models", "authors": ["Chaoyi Zhu", "Zaitang Li", "Renyi Yang", "Robert Birke", "Pin-Yu Chen", "Tsung-Yi Ho", "Lydia Y. Chen"], "summary": "Watermarking becomes one of the pivotal solutions to trace and verify the\norigin of synthetic images generated by artificial intelligence models, but it\nis not free of risks. Recent studies demonstrate the capability to forge\nwatermarks from a target image onto cover images via adversarial optimization\nwithout knowledge of the target generative model and watermark schemes. In this\npaper, we uncover a greater risk of an optimization-free and universal\nwatermark forgery that harnesses existing regenerative diffusion models. Our\nproposed forgery attack, PnP (Plug-and-Plant), seamlessly extracts and\nintegrates the target watermark via regenerating the image, without needing any\nadditional optimization routine. It allows for universal watermark forgery that\nworks independently of the target image's origin or the watermarking model\nused. We explore the watermarked latent extracted from the target image and\nvisual-textual context of cover images as priors to guide sampling of the\nregenerative process. Extensive evaluation on 24 scenarios of\nmodel-data-watermark combinations demonstrates that PnP can successfully forge\nthe watermark (up to 100% detectability and user attribution), and maintain the\nbest visual perception. By bypassing model retraining and enabling adaptability\nto any image, our approach significantly broadens the scope of forgery attacks,\npresenting a greater challenge to the security of current watermarking\ntechniques for diffusion models and the authority of watermarking schemes in\nsynthetic data generation and governance.", "comment": null, "cate": "cs.MM", "url": "http://arxiv.org/pdf/2506.06018v1", "AI": {"title_translation": "基于再生扩散模型的免优化通用水印伪造", "tldr": "本文提出了一种名为PnP的免优化通用水印伪造攻击，它利用再生扩散模型，无需额外优化即可成功伪造水印，并保持最佳视觉感知，对现有水印技术构成重大挑战。", "motivation": "水印是追踪和验证人工智能模型生成合成图像来源的关键解决方案，但并非没有风险。现有研究表明可以通过对抗性优化将水印从目标图像伪造到封面图像上，但需要目标生成模型和水印方案的知识。本文旨在揭示更大的风险：一种利用现有再生扩散模型的免优化通用水印伪造方法。", "method": "本文提出了一种名为PnP（Plug-and-Plant）的伪造攻击。它通过再生图像无缝地提取和整合目标水印，无需任何额外的优化程序。PnP利用从目标图像中提取的水印潜在信息以及封面图像的视觉-文本上下文作为先验知识来指导再生过程的采样。", "result": "在24种模型-数据-水印组合场景的广泛评估中，PnP能够成功伪造水印（高达100%的可检测性和用户归因），并保持最佳视觉感知。", "conclusion": "通过绕过模型再训练并实现对任何图像的适应性，PnP方法显著拓宽了伪造攻击的范围，对当前扩散模型水印技术的安全性以及合成数据生成和治理中水印方案的权威性提出了更大的挑战。", "translation": "水印已成为追踪和验证人工智能模型生成合成图像来源的关键解决方案之一，但并非没有风险。最近的研究表明，在不知道目标生成模型和水印方案的情况下，可以通过对抗性优化将水印从目标图像伪造到封面图像上。在本文中，我们揭示了一种更大的风险，即利用现有再生扩散模型的免优化通用水印伪造。我们提出的伪造攻击，PnP（Plug-and-Plant），通过再生图像无缝地提取和整合目标水印，无需任何额外的优化程序。它允许进行通用水印伪造，独立于目标图像的来源或所使用的水印模型。我们探索了从目标图像中提取的水印潜在信息以及封面图像的视觉-文本上下文作为先验知识，以指导再生过程的采样。在24种模型-数据-水印组合场景的广泛评估中，PnP能够成功伪造水印（高达100%的可检测性和用户归因），并保持最佳视觉感知。通过绕过模型再训练并实现对任何图像的适应性，我们的方法显著拓宽了伪造攻击的范围，对当前扩散模型水印技术的安全性以及合成数据生成和治理中水印方案的权威性提出了更大的挑战。", "summary": "本文介绍了一种名为PnP的免优化通用水印伪造攻击，该攻击利用再生扩散模型，无需额外的优化过程即可无缝地提取和整合目标水印。与之前需要对抗性优化的方法不同，PnP通过再生图像来实现水印伪造，使其独立于目标图像的来源或所使用的水印模型。通过利用目标图像中提取的水印潜在信息和封面图像的视觉-文本上下文作为先验知识来指导再生过程，PnP在24种模型-数据-水印组合场景中表现出色，能够成功伪造水印（高达100%的可检测性和用户归因），并保持最佳视觉感知。该方法绕过了模型再训练，并能适应任何图像，显著扩大了伪造攻击的范围，对当前扩散模型水印技术的安全性和水印方案在合成数据生成和治理中的权威性构成了重大挑战。", "keywords": "水印伪造, 扩散模型, 免优化, 通用攻击, 合成图像", "comments": "本文通过引入一种免优化且通用的攻击，在水印伪造领域取得了重大进展。其创新之处在于利用再生扩散模型来规避复杂的优化过程，使攻击具有高度的适应性和效率。这项工作揭示了当前AI生成内容水印方案中的一个关键漏洞，敦促开发更强大的保护机制。PnP攻击的普适性和高成功率尤其令人担忧。"}}
{"id": "2506.05523", "title": "MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning", "authors": ["Zikui Cai", "Andrew Wang", "Anirudh Satheesh", "Ankit Nakhawa", "Hyunwoo Jae", "Keenan Powell", "Minghui Liu", "Neel Jay", "Sungbin Oh", "Xiyao Wang", "Yongyuan Liang", "Tom Goldstein", "Furong Huang"], "summary": "Despite rapid advances in vision-language models (VLMs), current benchmarks\nfor multimodal reasoning fall short in three key dimensions. First, they\noverwhelmingly rely on static images, failing to capture the temporal\ncomplexity of real-world environments. Second, they narrowly focus on\nmathematical problem-solving, neglecting the broader spectrum of reasoning\nskills -- including abstract, physical, planning, spatial, and temporal\ncapabilities -- required for robust multimodal intelligence. Third, many\nbenchmarks quickly saturate, offering limited headroom for diagnosing failure\nmodes or measuring continued progress. We introduce MORSE-500 (Multimodal\nReasoning Stress-test Environment), a video benchmark composed of 500 fully\nscripted clips with embedded questions spanning six complementary reasoning\ncategories. Each instance is programmatically generated using deterministic\nPython scripts (via Manim, Matplotlib, MoviePy), generative video models, and\ncurated real footage. This script-driven design allows fine-grained control\nover visual complexity, distractor density, and temporal dynamics -- enabling\ndifficulty to be scaled systematically as models improve. Unlike static\nbenchmarks that become obsolete once saturated, MORSE-500 is built to evolve:\nits controllable generation pipeline supports the creation of arbitrarily\nchallenging new instances, making it ideally suited for stress-testing\nnext-generation models. Initial experiments with state-of-the-art systems --\nincluding various Gemini 2.5 Pro and OpenAI o3 which represent the strongest\navailable at the time, alongside strong open-source models -- reveal\nsubstantial performance gaps across all categories, with particularly large\ndeficits in abstract and planning tasks. We release the full dataset,\ngeneration scripts, and evaluation harness to support transparent,\nreproducible, and forward-looking multimodal reasoning research.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05523v1", "AI": {"title_translation": "MORSE-500：一个可编程控制的视频基准，用于压力测试多模态推理", "tldr": "MORSE-500是一个新的视频基准，通过程序化生成，旨在弥补现有视觉语言模型基准的不足，特别是在时间复杂度、推理广度和饱和度方面，并发现当前SOTA模型在抽象和规划任务上表现不佳。", "motivation": "现有视觉语言模型（VLM）基准存在三个主要缺陷：1. 过于依赖静态图像，未能捕捉真实世界的时间复杂性。2. 过于关注数学问题解决，忽视了抽象、物理、规划、空间和时间等更广泛的推理技能。3. 许多基准很快达到饱和，限制了诊断故障模式和衡量持续进展的能力。", "method": "本文引入了MORSE-500（多模态推理压力测试环境），这是一个包含500个完全脚本化视频片段的视频基准，其中嵌入了涵盖六个互补推理类别的问题。每个实例都使用确定性Python脚本（通过Manim、Matplotlib、MoviePy）、生成视频模型和精选真实素材程序化生成。这种脚本驱动的设计允许对视觉复杂性、干扰物密度和时间动态进行细粒度控制，从而能够随着模型的改进系统地调整难度。", "result": "对包括Gemini 2.5 Pro和OpenAI o3在内的最先进系统以及强大的开源模型进行的初步实验显示，所有类别都存在显著的性能差距，特别是在抽象和规划任务中存在巨大的缺陷。", "conclusion": "MORSE-500作为一个可演进的、可编程控制的视频基准，能够有效压力测试下一代多模态模型，并揭示了当前SOTA模型在复杂推理任务上的不足，为未来的多模态推理研究提供了透明、可复现和前瞻性的支持。", "translation": "尽管视觉语言模型（VLM）取得了快速进展，但当前用于多模态推理的基准在三个关键维度上存在不足。首先，它们绝大多数依赖静态图像，未能捕捉真实世界环境的时间复杂性。其次，它们狭隘地专注于数学问题解决，忽视了鲁棒多模态智能所需的更广泛推理技能——包括抽象、物理、规划、空间和时间能力。第三，许多基准很快达到饱和，为诊断故障模式或衡量持续进展提供的空间有限。我们引入了MORSE-500（多模态推理压力测试环境），这是一个视频基准，由500个完全脚本化视频片段组成，其中嵌入了涵盖六个互补推理类别的问题。每个实例都使用确定性Python脚本（通过Manim、Matplotlib、MoviePy）、生成视频模型和精选真实素材程序化生成。这种脚本驱动的设计允许对视觉复杂性、干扰物密度和时间动态进行细粒度控制——从而能够随着模型的改进系统地调整难度。与一旦饱和就变得过时的静态基准不同，MORSE-500旨在演进：其可控的生成管道支持创建任意具有挑战性的新实例，使其非常适合压力测试下一代模型。对包括各种Gemini 2.5 Pro和OpenAI o3（代表当时最强的可用模型）以及强大的开源模型进行的初步实验显示，所有类别都存在显著的性能差距，特别是在抽象和规划任务中存在巨大的缺陷。我们发布了完整的数据集、生成脚本和评估工具，以支持透明、可复现和前瞻性的多模态推理研究。", "summary": "本文介绍了MORSE-500，这是一个创新的视频基准，旨在解决现有视觉语言模型（VLM）评估基准的局限性，包括对静态图像的过度依赖、推理范围的狭窄以及基准快速饱和的问题。MORSE-500包含500个程序化生成的视频片段和相关问题，涵盖了六种推理类别，其脚本驱动的设计允许对难度进行精细控制和系统扩展。初步实验表明，即使是当前最先进的VLM（如Gemini 2.5 Pro和OpenAI o3）在MORSE-500上的表现也存在显著差距，尤其在抽象和规划任务中表现尤为薄弱。该数据集、生成脚本和评估工具已公开发布，以促进多模态推理研究的进展。", "keywords": "视频基准, 多模态推理, 视觉语言模型, 程序化生成, 压力测试", "comments": "MORSE-500的创新之处在于其程序化生成和可演进的设计，这使其能够系统地调整难度并避免传统基准的快速饱和问题。它通过引入视频内容和更广泛的推理类别，显著提升了多模态推理基准的复杂性和实用性。这项工作对于诊断当前视觉语言模型的弱点、推动下一代模型的发展至关重要，特别是揭示了模型在抽象和规划任务上的显著不足。"}}
{"id": "2506.05668", "title": "RNE: a plug-and-play framework for diffusion density estimation and inference-time control", "authors": ["Jiajun He", "José Miguel Hernández-Lobato", "Yuanqi Du", "Francisco Vargas"], "summary": "In this paper, we introduce the Radon-Nikodym Estimator (RNE), a flexible,\nplug-and-play framework for diffusion inference-time density estimation and\ncontrol, based on the concept of the density ratio between path distributions.\nRNE connects and unifies a variety of existing density estimation and\ninference-time control methods under a single and intuitive perspective,\nstemming from basic variational inference and probabilistic principles\ntherefore offering both theoretical clarity and practical versatility.\nExperiments demonstrate that RNE achieves promising performances in diffusion\ndensity estimation and inference-time control tasks, including annealing,\ncomposition of diffusion models, and reward-tilting.", "comment": "39 pages; 10 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05668v1", "AI": {"title_translation": "RNE：一种用于扩散密度估计和推理时控制的即插即用框架", "tldr": "RNE是一个即插即用的框架，用于扩散密度估计和推理时控制，它统一了现有方法并表现出色。", "motivation": "本文旨在通过引入Radon-Nikodym Estimator (RNE)，连接和统一现有多种密度估计和推理时控制方法，提供一个单一且直观的视角，以提升理论清晰度和实际多功能性。", "method": "本文引入了Radon-Nikodym Estimator (RNE)，这是一个灵活的即插即用框架，用于扩散推理时密度估计和控制。RNE基于路径分布之间的密度比概念，并源于基本的变分推断和概率原理。", "result": "实验证明RNE在扩散密度估计和推理时控制任务中（包括退火、扩散模型组合和奖励倾斜）取得了有希望的性能。", "conclusion": "RNE作为一个统一的即插即用框架，在扩散密度估计和推理时控制方面表现出色，为相关任务提供了理论清晰度和实际多功能性。", "translation": "在本文中，我们引入了Radon-Nikodym Estimator (RNE)，一个灵活的、即插即用的框架，用于基于路径分布之间密度比概念的扩散推理时密度估计和控制。RNE从基本的变分推断和概率原理出发，将各种现有密度估计和推理时控制方法连接并统一在一个单一且直观的视角下，从而提供了理论清晰度和实际多功能性。实验表明，RNE在扩散密度估计和推理时控制任务（包括退火、扩散模型组合和奖励倾斜）中取得了有希望的性能。", "summary": "本文介绍了Radon-Nikodym Estimator (RNE)，一个灵活的即插即用框架，用于扩散推理时密度估计和控制。RNE基于路径分布的密度比概念，并结合变分推断和概率原理，统一了多种现有方法。实验结果表明，RNE在扩散密度估计和推理时控制任务（如退火、扩散模型组合和奖励倾斜）中表现出良好的性能。", "keywords": "Radon-Nikodym Estimator, 扩散模型, 密度估计, 推理时控制, 即插即用", "comments": "RNE的创新之处在于它提供了一个统一的框架，将多种现有密度估计和推理时控制方法整合到一个直观的视角下，这不仅增强了理论理解，也提高了实际应用中的灵活性和多功能性。其即插即用的特性使其易于集成和使用。"}}
{"id": "2506.05533", "title": "Personalized Interpretability -- Interactive Alignment of Prototypical Parts Networks", "authors": ["Tomasz Michalski", "Adam Wróbel", "Andrea Bontempelli", "Jakub Luśtyk", "Mikolaj Kniejski", "Stefano Teso", "Andrea Passerini", "Bartosz Zieliński", "Dawid Rymarczyk"], "summary": "Concept-based interpretable neural networks have gained significant attention\ndue to their intuitive and easy-to-understand explanations based on case-based\nreasoning, such as \"this bird looks like those sparrows\". However, a major\nlimitation is that these explanations may not always be comprehensible to users\ndue to concept inconsistency, where multiple visual features are\ninappropriately mixed (e.g., a bird's head and wings treated as a single\nconcept). This inconsistency breaks the alignment between model reasoning and\nhuman understanding. Furthermore, users have specific preferences for how\nconcepts should look, yet current approaches provide no mechanism for\nincorporating their feedback. To address these issues, we introduce\nYoursProtoP, a novel interactive strategy that enables the personalization of\nprototypical parts - the visual concepts used by the model - according to user\nneeds. By incorporating user supervision, YoursProtoP adapts and splits\nconcepts used for both prediction and explanation to better match the user's\npreferences and understanding. Through experiments on both the synthetic\nFunnyBirds dataset and a real-world scenario using the CUB, CARS, and PETS\ndatasets in a comprehensive user study, we demonstrate the effectiveness of\nYoursProtoP in achieving concept consistency without compromising the accuracy\nof the model.", "comment": "20 pages, 11 figures", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05533v1", "AI": {"title_translation": "个性化可解释性——原型部分网络的交互式对齐", "tldr": "本研究提出了一种名为YoursProtoP的交互式策略，通过融入用户反馈来个性化概念，以解决概念不一致性和用户偏好未被考虑的问题，从而提高可解释性并保持模型准确性。", "motivation": "概念基可解释神经网络面临概念不一致性的主要限制，即多个视觉特征混合不当，导致模型推理与人类理解之间不一致。此外，现有方法无法整合用户对概念外观的特定偏好。", "method": "本研究引入了YoursProtoP，这是一种新颖的交互式策略，能够根据用户需求个性化原型部分（模型使用的视觉概念）。通过整合用户监督，YoursProtoP调整并拆分用于预测和解释的概念，以更好地匹配用户的偏好和理解。", "result": "在合成的FunnyBirds数据集以及使用CUB、CARS和PETS数据集的真实场景中的综合用户研究表明，YoursProtoP在不损害模型准确性的前提下，有效实现了概念一致性。", "conclusion": "YoursProtoP通过允许用户个性化概念并整合他们的反馈，成功解决了概念不一致性和用户偏好未被考虑的问题，从而提高了可解释性并保持了模型性能。", "translation": "基于概念的可解释神经网络因其基于案例推理的直观易懂的解释（例如“这只鸟看起来像那些麻雀”）而获得了广泛关注。然而，一个主要的限制是，由于概念不一致性，这些解释可能并不总是用户可以理解的，其中多个视觉特征被不适当地混合（例如，鸟的头部和翅膀被视为一个单一概念）。这种不一致性打破了模型推理和人类理解之间的对齐。此外，用户对概念应该如何呈现有特定的偏好，但当前的方法没有提供整合其反馈的机制。为了解决这些问题，我们引入了YoursProtoP，这是一种新颖的交互式策略，能够根据用户需求个性化原型部分——模型使用的视觉概念。通过整合用户监督，YoursProtoP调整并拆分用于预测和解释的概念，以更好地匹配用户的偏好和理解。通过在合成的FunnyBirds数据集和使用CUB、CARS和PETS数据集的真实场景中的综合用户研究，我们证明了YoursProtoP在不损害模型准确性的前提下实现概念一致性的有效性。", "summary": "该研究提出了一种名为YoursProtoP的交互式策略，旨在解决概念基可解释神经网络中概念不一致性和用户偏好无法整合的问题。YoursProtoP允许用户个性化模型使用的原型部分（视觉概念），通过用户监督来调整和拆分概念，使其与用户理解和偏好更好地匹配。实验证明，YoursProtoP在保持模型准确性的同时，有效提升了概念的一致性。", "keywords": "个性化可解释性, 原型网络, 交互式策略, 概念一致性, 用户反馈", "comments": "该论文的创新点在于引入了用户交互和个性化机制来解决概念可解释性中的核心问题——概念不一致性。通过允许用户反馈来调整模型内部概念，YoursProtoP显著提高了可解释性与人类理解的对齐程度，这对于实际应用中提高用户对AI决策的信任度至关重要。"}}
{"id": "2506.05672", "title": "Contextually Guided Transformers via Low-Rank Adaptation", "authors": ["Andrey Zhmoginov", "Jihwan Lee", "Max Vladymyrov", "Mark Sandler"], "summary": "Large Language Models (LLMs) based on Transformers excel at text processing,\nbut their reliance on prompts for specialized behavior introduces computational\noverhead. We propose a modification to a Transformer architecture that\neliminates the need for explicit prompts by learning to encode context into the\nmodel's weights. Our Contextually Guided Transformer (CGT) model maintains a\ncontextual summary at each sequence position, allowing it to update the weights\non the fly based on the preceding context. This approach enables the model to\nself-specialize, effectively creating a tailored model for processing\ninformation following a given prefix. We demonstrate the effectiveness of our\nmethod on synthetic in-context learning tasks and language modeling benchmarks.\nFurthermore, we introduce techniques for enhancing the interpretability of the\nlearned contextual representations, drawing connections to Variational\nAutoencoders and promoting smoother, more consistent context encoding. This\nwork offers a novel direction for efficient and adaptable language modeling by\nintegrating context directly into the model's architecture.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05672v1", "AI": {"title_translation": "语境引导的低秩自适应Transformer", "tldr": "提出一种语境引导的Transformer (CGT) 模型，通过动态更新模型权重来编码语境，无需显式提示，实现高效自适应的语言建模。", "motivation": "大型语言模型（LLMs）依赖提示词以实现专业化行为会引入计算开销。", "method": "提出语境引导的Transformer (CGT) 模型，通过在每个序列位置维护语境摘要，并根据前置语境动态更新模型权重，从而将语境直接编码到模型权重中，无需显式提示。此外，还引入了增强学习到的语境表示可解释性的技术，并与变分自编码器建立联系，促进更平滑、更一致的语境编码。", "result": "在合成的语境学习任务和语言建模基准测试中证明了该方法的有效性。", "conclusion": "这项工作通过将语境直接集成到模型架构中，为高效和自适应的语言建模提供了一个新方向。", "translation": "基于Transformer的大型语言模型（LLMs）在文本处理方面表现出色，但它们对提示词的依赖以实现专业化行为会引入计算开销。我们提出了一种对Transformer架构的修改，通过学习将语境编码到模型的权重中，从而消除了对显式提示词的需求。我们的语境引导Transformer（CGT）模型在每个序列位置维护一个语境摘要，使其能够根据前置语境动态更新权重。这种方法使模型能够自我专业化，有效地为处理给定前缀后的信息创建量身定制的模型。我们证明了该方法在合成语境学习任务和语言建模基准测试上的有效性。此外，我们引入了增强学习到的语境表示可解释性的技术，将其与变分自编码器联系起来，并促进更平滑、更一致的语境编码。这项工作通过将语境直接集成到模型架构中，为高效和自适应的语言建模提供了一个新方向。", "summary": "本文提出了一种名为语境引导Transformer（CGT）的新型Transformer架构，旨在解决大型语言模型对显式提示的计算开销问题。CGT模型通过在每个序列位置维护语境摘要并动态更新模型权重，将语境直接编码进模型，从而实现模型的自我专业化。该方法在语境学习任务和语言建模基准测试中展示了有效性，并提供了增强语境表示可解释性的技术，为高效和自适应的语言建模开辟了新途径。", "keywords": "Transformer, 低秩自适应, 语境引导, 语言模型, 提示词无关", "comments": "这项工作通过将语境直接融入Transformer架构而非依赖外部提示，提出了一个新颖且高效的语言建模方向。其创新点在于通过动态权重更新实现模型的“自我专业化”，有望显著降低LLM的推理成本并提高适应性。与变分自编码器的结合也提升了模型的可解释性。"}}
{"id": "2506.06108", "title": "Synthetic Tabular Data: Methods, Attacks and Defenses", "authors": ["Graham Cormode", "Samuel Maddock", "Enayat Ullah", "Shripad Gade"], "summary": "Synthetic data is often positioned as a solution to replace sensitive\nfixed-size datasets with a source of unlimited matching data, freed from\nprivacy concerns. There has been much progress in synthetic data generation\nover the last decade, leveraging corresponding advances in machine learning and\ndata analytics. In this survey, we cover the key developments and the main\nconcepts in tabular synthetic data generation, including paradigms based on\nprobabilistic graphical models and on deep learning. We provide background and\nmotivation, before giving a technical deep-dive into the methodologies. We also\naddress the limitations of synthetic data, by studying attacks that seek to\nretrieve information about the original sensitive data. Finally, we present\nextensions and open problems in this area.", "comment": "Survey paper for accepted lecture-style tutorial at ACM KDD 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06108v1", "AI": {"title_translation": "合成表格数据：方法、攻击与防御", "tldr": "这篇综述涵盖了合成表格数据的生成方法、对原始数据的攻击以及相关防御措施，并探讨了该领域的局限性、扩展和开放问题。", "motivation": "合成数据被视为替代敏感固定大小数据集的解决方案，以消除隐私问题，并且在过去十年中，合成数据生成取得了显著进展。本论文旨在对表格合成数据生成领域的关键发展、主要概念、方法、局限性、攻击和开放问题进行全面综述。", "method": "本文通过调查和综述的方式，涵盖了表格合成数据生成领域的关键发展和主要概念，包括基于概率图模型和深度学习的范式。它还研究了旨在检索原始敏感数据信息的攻击，并提出了该领域的扩展和开放问题。", "result": "本文综述了表格合成数据生成的主要进展和概念，包括基于概率图模型和深度学习的方法。它还探讨了合成数据的局限性，特别是针对原始敏感数据信息检索的攻击，并提出了该领域的扩展和开放问题。", "conclusion": "本文全面综述了表格合成数据生成的方法、攻击和防御，并探讨了该领域的局限性、未来的扩展和开放问题。", "translation": "合成数据通常被定位为一种解决方案，用于替代敏感的固定大小数据集，提供无限匹配的数据来源，且不受隐私问题的困扰。在过去十年中，借助机器学习和数据分析的相应进展，合成数据生成取得了很大进展。在本综述中，我们涵盖了表格合成数据生成领域的关键发展和主要概念，包括基于概率图模型和深度学习的范式。在深入技术方法之前，我们提供了背景和动机。我们还通过研究旨在检索原始敏感数据信息的攻击来解决合成数据的局限性。最后，我们提出了该领域的扩展和开放问题。", "summary": "本综述全面探讨了合成表格数据领域，涵盖了其生成方法（包括基于概率图模型和深度学习的范式）、对原始敏感数据进行信息检索的攻击及其防御。文章还讨论了合成数据的局限性、未来的扩展方向以及该领域尚待解决的问题。", "keywords": "合成表格数据, 隐私保护, 数据生成, 攻击, 综述", "comments": "这篇综述为合成表格数据领域提供了全面的概览，涵盖了生成方法、安全挑战和未来方向，对于理解和应用合成数据具有重要价值。其创新在于系统地整合了现有知识，并指出了该领域的开放问题。"}}
{"id": "2506.05543", "title": "FRAME: Pre-Training Video Feature Representations via Anticipation and Memory", "authors": ["Sethuraman TV", "Savya Khosla", "Vignesh Srinivasakumar", "Jiahui Huang", "Seoung Wug Oh", "Simon Jenni", "Derek Hoiem", "Joon-Young Lee"], "summary": "Dense video prediction tasks, such as object tracking and semantic\nsegmentation, require video encoders that generate temporally consistent,\nspatially dense features for every frame. However, existing approaches fall\nshort: image encoders like DINO or CLIP lack temporal awareness, while video\nmodels such as VideoMAE underperform compared to image encoders on dense\nprediction tasks. We address this gap with FRAME, a self-supervised video frame\nencoder tailored for dense video understanding. FRAME learns to predict current\nand future DINO patch features from past and present RGB frames, leading to\nspatially precise and temporally coherent representations. To our knowledge,\nFRAME is the first video encoder to leverage image-based models for dense\nprediction while outperforming them on tasks requiring fine-grained visual\ncorrespondence. As an auxiliary capability, FRAME aligns its class token with\nCLIP's semantic space, supporting language-driven tasks such as video\nclassification. We evaluate FRAME across six dense prediction tasks on seven\ndatasets, where it consistently outperforms image encoders and existing\nself-supervised video models. Despite its versatility, FRAME maintains a\ncompact architecture suitable for a range of downstream applications.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05543v1", "AI": {"title_translation": "FRAME：通过预测和记忆预训练视频特征表示", "tldr": "FRAME是一个自监督视频帧编码器，通过预测和记忆来预训练视频特征，解决了现有模型在密集视频预测任务上的不足，并在多个任务上表现优异。", "motivation": "密集视频预测任务（如目标跟踪和语义分割）需要视频编码器生成时间一致、空间密集的帧特征。然而，现有的图像编码器（如DINO或CLIP）缺乏时间感知能力，而现有的视频模型（如VideoMAE）在密集预测任务上的表现不如图像编码器，因此存在一个空白。", "method": "FRAME是一种自监督视频帧编码器，专为密集视频理解量身定制。它通过学习从过去和当前的RGB帧预测当前和未来的DINO补丁特征，从而生成空间精确和时间连贯的表示。它是第一个利用基于图像的模型进行密集预测并超越它们的视频编码器。此外，FRAME将其类令牌与CLIP的语义空间对齐，以支持视频分类等语言驱动的任务。", "result": "FRAME在七个数据集上的六个密集预测任务中进行了评估，并始终优于图像编码器和现有的自监督视频模型。尽管功能多样，FRAME仍保持紧凑的架构，适用于各种下游应用。", "conclusion": "FRAME成功弥补了现有模型在密集视频预测任务上的不足，通过新颖的预训练方法，生成了高质量的视频特征表示，并在多项任务上展现了卓越的性能和普适性。", "translation": "密集视频预测任务，例如目标跟踪和语义分割，需要视频编码器为每一帧生成时间一致、空间密集的特征。然而，现有方法存在不足：DINO或CLIP等图像编码器缺乏时间感知能力，而VideoMAE等视频模型在密集预测任务上的表现不如图像编码器。我们通过FRAME解决了这一空白，FRAME是一个自监督视频帧编码器，专为密集视频理解量身定制。FRAME学习从过去和当前的RGB帧预测当前和未来的DINO补丁特征，从而生成空间精确和时间连贯的表示。据我们所知，FRAME是第一个利用基于图像的模型进行密集预测并超越它们的视频编码器。作为一项辅助功能，FRAME将其类令牌与CLIP的语义空间对齐，支持视频分类等语言驱动的任务。我们在七个数据集上的六个密集预测任务中评估了FRAME，它始终优于图像编码器和现有的自监督视频模型。尽管功能多样，FRAME仍保持紧凑的架构，适用于各种下游应用。", "summary": "该论文提出了FRAME，一个自监督视频帧编码器，旨在解决现有图像和视频模型在密集视频预测任务中时间一致性和空间密度特征不足的问题。FRAME通过预测当前和未来DINO补丁特征来学习生成精确且连贯的视频表示，并是首个在密集预测任务中超越图像模型的视频编码器。它还在多项密集预测任务中表现出色，并支持语言驱动的任务，同时保持紧凑的架构。", "keywords": "视频特征学习,自监督学习,密集预测,视频编码器,预训练模型", "comments": "这项工作的创新之处在于，它开创性地将图像预训练模型的强大空间表示能力与视频的时间感知能力相结合，解决了传统视频模型在密集预测任务上的劣势。通过预测未来帧特征，FRAME有效地学习了时间连贯性，并为需要细粒度视觉对应关系的下游任务提供了高质量的特征表示，具有重要的实用价值。"}}
{"id": "2506.05673", "title": "Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery", "authors": ["Sajjad Abdoli", "Freeman Lewin", "Gediminas Vasiliauskas", "Fabian Schonholz"], "summary": "The development of modern Artificial Intelligence (AI) models, particularly\ndiffusion-based models employed in computer vision and image generation tasks,\nis undergoing a paradigmatic shift in development methodologies. Traditionally\ndominated by a \"Model Centric\" approach, in which performance gains were\nprimarily pursued through increasingly complex model architectures and\nhyperparameter optimization, the field is now recognizing a more nuanced\n\"Data-Centric\" approach. This emergent framework foregrounds the quality,\nstructure, and relevance of training data as the principal driver of model\nperformance. To operationalize this paradigm shift, we introduce the\nDataSeeds.AI sample dataset (the \"DSD\"), initially comprised of approximately\n10,610 high-quality human peer-ranked photography images accompanied by\nextensive multi-tier annotations. The DSD is a foundational computer vision\ndataset designed to usher in a new standard for commercial image datasets.\nRepresenting a small fraction of DataSeed.AI's 100 million-plus image catalog,\nthe DSD provides a scalable foundation necessary for robust commercial and\nmultimodal AI development. Through this in-depth exploratory analysis, we\ndocument the quantitative improvements generated by the DSD on specific models\nagainst known benchmarks and make the code and the trained models used in our\nevaluation publicly available.", "comment": "28 pages, 12 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05673v1", "AI": {"title_translation": "同行评级精度：从DataSeeds的标注图像创建用于微调视觉模型的基础数据集", "tldr": "本文介绍了DataSeeds.AI样本数据集（DSD），这是一个包含约10,610张高质量人工同行评级图像和多层标注的计算机视觉数据集，旨在为商业图像数据集设定新标准，并展示了其在特定模型上的性能提升。", "motivation": "现代AI模型开发正从“模型中心”转向“数据中心”方法，强调训练数据质量对模型性能的重要性。为了实现这一范式转变，需要高质量的、结构化的相关训练数据。", "method": "研究人员引入了DataSeeds.AI样本数据集（DSD），该数据集包含约10,610张经过人工同行评级的高质量摄影图像，并附有广泛的多层标注。他们通过深入的探索性分析，记录了DSD在特定模型上相对于已知基准产生的定量改进，并公开了评估中使用的代码和训练模型。", "result": "DSD在特定模型上相对于已知基准产生了定量改进。数据集被证明是用于稳健商业和多模态AI开发的必要可扩展基础。", "conclusion": "DataSeeds.AI样本数据集（DSD）为商业图像数据集树立了新标准，并展示了数据中心方法在提升AI模型性能方面的潜力。", "translation": "现代人工智能（AI）模型，特别是计算机视觉和图像生成任务中使用的基于扩散的模型，其开发方法正在经历一场范式转变。传统上以“模型中心”方法为主导，即性能提升主要通过日益复杂的模型架构和超参数优化来追求，而现在该领域正在认识到一种更细致的“数据中心”方法。这种新兴框架将训练数据的质量、结构和相关性作为模型性能的主要驱动力。为了实现这一范式转变，我们引入了DataSeeds.AI样本数据集（“DSD”），最初由大约10,610张高质量的人工同行评级摄影图像组成，并附有广泛的多层标注。DSD是一个基础性的计算机视觉数据集，旨在为商业图像数据集引入新标准。DSD代表了DataSeed.AI一亿多张图像目录中的一小部分，为稳健的商业和多模态AI开发提供了必要的可扩展基础。通过这项深入的探索性分析，我们记录了DSD在特定模型上相对于已知基准产生的定量改进，并公开了我们评估中使用的代码和训练模型。", "summary": "该论文介绍了DataSeeds.AI样本数据集（DSD），这是一个包含约10,610张高质量人工同行评级图像和多层标注的计算机视觉数据集。DSD旨在应对AI模型开发从“模型中心”到“数据中心”范式转变的需求，强调数据质量对模型性能的关键作用。研究表明，DSD能够为商业和多模态AI开发提供可扩展的基础，并在特定模型上相对于已知基准产生了显著的定量改进。相关的代码和训练模型已公开。", "keywords": "数据中心方法, 计算机视觉, 数据集, 同行评级, 模型微调", "comments": "这篇论文的创新之处在于其“数据中心”方法的实践，通过创建高质量、经过同行评级且带有丰富标注的数据集（DSD），为视觉模型的微调提供了新的基础。这与当前AI领域对数据质量和管理日益增长的关注相吻合，预示着未来AI模型性能提升将更多地依赖于数据而非仅仅模型架构。其重要性在于为商业和多模态AI开发提供了可扩展的基础，并可能推动高质量数据集成为行业标准。"}}
{"id": "2506.06112", "title": "Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness", "authors": ["Cheng-Long Wang", "Qi Li", "Zihang Xiang", "Yinzhi Cao", "Di Wang"], "summary": "Growing concerns over data privacy and security highlight the importance of\nmachine unlearning--removing specific data influences from trained models\nwithout full retraining. Techniques like Membership Inference Attacks (MIAs)\nare widely used to externally assess successful unlearning. However, existing\nmethods face two key limitations: (1) maximizing MIA effectiveness (e.g., via\nonline attacks) requires prohibitive computational resources, often exceeding\nretraining costs; (2) MIAs, designed for binary inclusion tests, struggle to\ncapture granular changes in approximate unlearning. To address these\nchallenges, we propose the Interpolated Approximate Measurement (IAM), a\nframework natively designed for unlearning inference. IAM quantifies\nsample-level unlearning completeness by interpolating the model's\ngeneralization-fitting behavior gap on queried samples. IAM achieves strong\nperformance in binary inclusion tests for exact unlearning and high correlation\nfor approximate unlearning--scalable to LLMs using just one pre-trained shadow\nmodel. We theoretically analyze how IAM's scoring mechanism maintains\nperformance efficiently. We then apply IAM to recent approximate unlearning\nalgorithms, revealing general risks of both over-unlearning and\nunder-unlearning, underscoring the need for stronger safeguards in approximate\nunlearning systems. The code is available at\nhttps://github.com/Happy2Git/Unlearning_Inference_IAM.", "comment": "To appear in the Proceedings of USENIX Security Symposium, 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06112v1", "AI": {"title_translation": "迈向生命周期遗忘承诺管理：衡量样本级遗忘完整性", "tldr": "现有机器学习遗忘评估方法计算成本高且难以捕捉近似遗忘的细微变化。本文提出IAM框架，用于高效衡量样本级遗忘完整性，适用于精确和近似遗忘，甚至大型语言模型，并揭示了近似遗忘中的过遗忘和欠遗忘风险。", "motivation": "现有机器学习遗忘评估方法（如MIAs）存在两大局限性：1) 最大化MIA效率需要极高的计算资源，甚至超过模型重新训练的成本；2) MIAs专为二元包含测试设计，难以捕捉近似遗忘中的细微变化。因此，需要一种更高效、更精细的遗忘完整性测量方法。", "method": "本文提出了一种名为“内插近似测量（Interpolated Approximate Measurement, IAM）”的框架，该框架原生为遗忘推理设计。IAM通过内插模型在查询样本上的泛化-拟合行为差距来量化样本级遗忘完整性。它仅需一个预训练的影子模型即可扩展到大型语言模型。", "result": "IAM在精确遗忘的二元包含测试中取得了强大的性能，并在近似遗忘中显示出高度相关性。它能够高效地保持性能。将IAM应用于近期近似遗忘算法，揭示了过遗忘和欠遗忘的普遍风险。", "conclusion": "IAM提供了一种有效且可扩展的方法来衡量样本级遗忘完整性，凸显了在近似遗忘系统中加强保障措施的必要性，以避免过遗忘和欠遗忘的风险。", "translation": "对数据隐私和安全日益增长的关注凸显了机器学习遗忘的重要性——在不完全重新训练的情况下，从训练模型中移除特定数据的影响。成员推断攻击（MIAs）等技术被广泛用于外部评估遗忘是否成功。然而，现有方法面临两个关键限制：(1) 最大化MIA效率（例如，通过在线攻击）需要高昂的计算资源，通常超过重新训练的成本；(2) MIAs专为二元包含测试设计，难以捕捉近似遗忘中的细微变化。为了解决这些挑战，我们提出了内插近似测量（IAM），一个原生为遗忘推理设计的框架。IAM通过内插模型在查询样本上的泛化-拟合行为差距来量化样本级遗忘完整性。IAM在精确遗忘的二元包含测试中取得了强大的性能，并在近似遗忘中具有高度相关性——只需一个预训练的影子模型即可扩展到大型语言模型。我们从理论上分析了IAM的评分机制如何高效地保持性能。然后，我们将IAM应用于最近的近似遗忘算法，揭示了过遗忘和欠遗忘的普遍风险，强调了在近似遗忘系统中需要更强的保障措施。代码可在https://github.com/Happy2Git/Unlearning_Inference_IAM 获取。", "summary": "本文针对现有机器学习遗忘评估方法（如MIAs）的计算成本高昂和无法捕捉近似遗忘细微变化的局限性，提出了一种名为内插近似测量（IAM）的新框架。IAM通过量化模型在查询样本上的泛化-拟合行为差距来衡量样本级遗忘完整性，可高效应用于精确和近似遗忘，包括大型语言模型。研究结果表明，IAM性能优异，并揭示了近似遗忘中普遍存在的过遗忘和欠遗忘风险，强调了加强相关保障措施的必要性。", "keywords": "机器学习遗忘, 样本级遗忘, 遗忘完整性, 内插近似测量, 数据隐私", "comments": "这篇论文通过提出IAM框架，有效地解决了现有机器学习遗忘评估方法在计算效率和对近似遗忘细粒度捕捉方面的不足。其创新点在于利用模型泛化-拟合行为差距来量化遗忘完整性，并能扩展到LLMs，这对于保障数据隐私和安全具有重要意义。揭示近似遗忘中的过遗忘和欠遗忘风险，为未来遗忘算法的设计和评估提供了宝贵的见解。"}}
{"id": "2506.05546", "title": "Layered Motion Fusion: Lifting Motion Segmentation to 3D in Egocentric Videos", "authors": ["Vadim Tschernezki", "Diane Larlus", "Andrea Vedaldi", "Iro Laina"], "summary": "Computer vision is largely based on 2D techniques, with 3D vision still\nrelegated to a relatively narrow subset of applications. However, by building\non recent advances in 3D models such as neural radiance fields, some authors\nhave shown that 3D techniques can at last improve outputs extracted from\nindependent 2D views, by fusing them into 3D and denoising them. This is\nparticularly helpful in egocentric videos, where the camera motion is\nsignificant, but only under the assumption that the scene itself is static. In\nfact, as shown in the recent analysis conducted by EPIC Fields, 3D techniques\nare ineffective when it comes to studying dynamic phenomena, and, in\nparticular, when segmenting moving objects. In this paper, we look into this\nissue in more detail. First, we propose to improve dynamic segmentation in 3D\nby fusing motion segmentation predictions from a 2D-based model into layered\nradiance fields (Layered Motion Fusion). However, the high complexity of long,\ndynamic videos makes it challenging to capture the underlying geometric\nstructure, and, as a result, hinders the fusion of motion cues into the\n(incomplete) scene geometry. We address this issue through test-time\nrefinement, which helps the model to focus on specific frames, thereby reducing\nthe data complexity. This results in a synergy between motion fusion and the\nrefinement, and in turn leads to segmentation predictions of the 3D model that\nsurpass the 2D baseline by a large margin. This demonstrates that 3D techniques\ncan enhance 2D analysis even for dynamic phenomena in a challenging and\nrealistic setting.", "comment": "Camera-ready for CVPR25", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05546v1", "AI": {"title_translation": "分层运动融合：将自我中心视频中的运动分割提升至3D", "tldr": "本研究提出了一种名为“分层运动融合”的新方法，通过将2D运动分割预测融合到分层辐射场中，并在测试时进行细化，显著提高了自我中心视频中动态现象的3D运动分割效果，超越了2D基线。", "motivation": "计算机视觉主要基于2D技术，而3D视觉在处理动态现象，特别是在自我中心视频中分割移动物体时，仍然效率低下，尽管3D模型（如神经辐射场）在静态场景中已显示出改进2D输出的潜力。", "method": "本研究提出“分层运动融合”方法，将基于2D模型的运动分割预测融合到分层辐射场中，以改善3D动态分割。为解决长动态视频的复杂性对运动线索融合的阻碍，采用测试时细化（test-time refinement）技术，帮助模型聚焦特定帧，从而降低数据复杂性。", "result": "运动融合与测试时细化之间产生了协同效应，使得3D模型的分割预测结果显著超越了2D基线。这表明3D技术即使在具有挑战性和真实的动态现象场景中也能增强2D分析。", "conclusion": "本研究证明，通过“分层运动融合”和测试时细化，3D技术能够有效提升自我中心视频中动态现象的运动分割能力，克服了以往3D方法在处理动态场景时的局限性。", "translation": "计算机视觉主要基于2D技术，3D视觉仍局限于相对狭窄的应用子集。然而，基于神经辐射场等3D模型的最新进展，一些作者已经表明，通过将独立的2D视图融合到3D并进行去噪，3D技术最终可以改进提取的输出。这在相机运动显著的自我中心视频中特别有用，但前提是场景本身是静态的。事实上，正如EPIC Fields最近的分析所示，3D技术在研究动态现象，特别是分割移动物体时是无效的。在本文中，我们更详细地探讨了这个问题。首先，我们提出通过将2D模型的运动分割预测融合到分层辐射场中（分层运动融合）来改进3D动态分割。然而，长动态视频的高度复杂性使得捕捉底层几何结构变得具有挑战性，从而阻碍了运动线索融合到（不完整的）场景几何中。我们通过测试时细化来解决这个问题，这有助于模型专注于特定帧，从而降低数据复杂性。这导致了运动融合和细化之间的协同作用，进而使得3D模型的分割预测结果显著超越了2D基线。这表明3D技术即使在具有挑战性和真实的动态现象场景中也能增强2D分析。", "summary": "本论文针对3D视觉在处理动态现象和分割移动物体（尤其在自我中心视频中）的不足，提出了一种名为“分层运动融合”的新方法。该方法通过将2D运动分割预测整合到分层辐射场中，并辅以测试时细化技术以应对长动态视频的复杂性。实验结果显示，该方法显著提升了3D模型的运动分割性能，超越了2D基线，证明了3D技术在复杂动态场景下增强2D分析的潜力。", "keywords": "分层运动融合, 运动分割, 3D视觉, 自我中心视频, 神经辐射场", "comments": "该论文的创新点在于提出了“分层运动融合”的概念，并结合了“测试时细化”策略，有效解决了3D视觉在处理动态场景和运动物体分割方面的长期挑战。其重要性在于，它打破了3D技术在自我中心视频中仅限于静态场景的假设，为未来在复杂动态环境中应用3D视觉技术奠定了基础。"}}
{"id": "2506.05676", "title": "Topology-aware Neural Flux Prediction Guided by Physics", "authors": ["Haoyang Jiang", "Jindong Wang", "Xingquan Zhu", "Yi He"], "summary": "Graph Neural Networks (GNNs) often struggle in preserving high-frequency\ncomponents of nodal signals when dealing with directed graphs. Such components\nare crucial for modeling flow dynamics, without which a traditional GNN tends\nto treat a graph with forward and reverse topologies equal.To make GNNs\nsensitive to those high-frequency components thereby being capable to capture\ndetailed topological differences, this paper proposes a novel framework that\ncombines 1) explicit difference matrices that model directional gradients and\n2) implicit physical constraints that enforce messages passing within GNNs to\nbe consistent with natural laws. Evaluations on two real-world directed graph\ndata, namely, water flux network and urban traffic flow network, demonstrate\nthe effectiveness of our proposal.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05676v1", "AI": {"title_translation": "拓扑感知神经通量预测，物理引导", "tldr": "针对有向图上GNNs难以保留高频信号的问题，本文提出了一种结合显式差分矩阵和隐式物理约束的新框架，以提高GNNs对拓扑差异的敏感性，并在真实世界数据上验证了其有效性。", "motivation": "传统GNN在处理有向图时难以保留节点信号的高频分量，导致无法区分前向和反向拓扑相同的图，而这些高频分量对建模流动力学至关重要。", "method": "提出一个新颖的框架，结合了：1) 建模方向梯度的显式差分矩阵；2) 强制GNN内部消息传递与自然法则一致的隐式物理约束。", "result": "在水通量网络和城市交通流网络这两个真实世界的有向图数据上的评估表明了所提方法的有效性。", "conclusion": "该方法能够有效提高GNNs对有向图高频分量的敏感性，从而更好地捕获详细的拓扑差异，并在实际流动力学建模中表现出优越性。", "translation": "图神经网络（GNNs）在处理有向图时，往往难以保留节点信号的高频分量。这些分量对于建模流动力学至关重要，缺乏它们，传统的GNN倾向于将具有前向和反向拓扑的图视为相同。为了使GNNs对这些高频分量敏感，从而能够捕获详细的拓扑差异，本文提出了一种新颖的框架，该框架结合了1）建模方向梯度的显式差分矩阵和2）强制GNN内部消息传递与自然法则一致的隐式物理约束。在水通量网络和城市交通流网络这两个真实世界的有向图数据上的评估证明了我们提案的有效性。", "summary": "本文提出了一种新颖的框架，通过结合显式差分矩阵和隐式物理约束来解决图神经网络在处理有向图时难以保留高频信号的问题。该方法使GNNs能够捕获详细的拓扑差异，并在水通量和城市交通流网络等真实世界数据上表现出有效性。", "keywords": "图神经网络, 有向图, 高频分量, 物理约束, 拓扑感知", "comments": "这项工作通过引入物理约束和显式差分矩阵，有效提升了图神经网络在有向图上对高频信号和拓扑差异的捕获能力，对于流动力学建模具有重要意义。"}}
{"id": "2506.05551", "title": "When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding", "authors": ["Yan Shu", "Hangui Lin", "Yexin Liu", "Yan Zhang", "Gangyan Zeng", "Yan Li", "Yu Zhou", "Ser-Nam Lim", "Harry Yang", "Nicu Sebe"], "summary": "Large Multimodal Models (LMMs) have achieved impressive progress in visual\nperception and reasoning. However, when confronted with visually ambiguous or\nnon-semantic scene text, they often struggle to accurately spot and understand\nthe content, frequently generating semantically plausible yet visually\nincorrect answers, which we refer to as semantic hallucination. In this work,\nwe investigate the underlying causes of semantic hallucination and identify a\nkey finding: Transformer layers in LLM with stronger attention focus on scene\ntext regions are less prone to producing semantic hallucinations. Thus, we\npropose a training-free semantic hallucination mitigation framework comprising\ntwo key components: (1) ZoomText, a coarse-to-fine strategy that identifies\npotential text regions without external detectors; and (2) Grounded Layer\nCorrection, which adaptively leverages the internal representations from layers\nless prone to hallucination to guide decoding, correcting hallucinated outputs\nfor non-semantic samples while preserving the semantics of meaningful ones. To\nenable rigorous evaluation, we introduce TextHalu-Bench, a benchmark of over\n1,730 samples spanning both semantic and non-semantic cases, with manually\ncurated question-answer pairs designed to probe model hallucinations. Extensive\nexperiments demonstrate that our method not only effectively mitigates semantic\nhallucination but also achieves strong performance on public benchmarks for\nscene text spotting and understanding.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05551v1", "AI": {"title_translation": "当语义误导视觉时：缓解大型多模态模型在场景文本检测与理解中的幻觉", "tldr": "大型多模态模型（LMMs）在处理模糊场景文本时容易产生语义幻觉。本文提出了一种无需训练的框架（ZoomText和Grounded Layer Correction）和新的评估基准（TextHalu-Bench），以有效缓解这种幻觉并提高性能。", "motivation": "大型多模态模型（LMMs）在处理视觉模糊或非语义的场景文本时，难以准确识别和理解内容，经常生成语义上合理但视觉上不正确的答案，即语义幻觉。本研究旨在解决这一问题。", "method": "本研究调查了语义幻觉的根本原因，发现对场景文本区域注意力更强的Transformer层不易产生语义幻觉。基于此，提出了一个无需训练的语义幻觉缓解框架，包含：1) ZoomText，一种无需外部检测器的粗到细文本区域识别策略；2) Grounded Layer Correction，自适应利用不易产生幻觉的层的内部表示来指导解码。为严格评估，引入了TextHalu-Bench，一个包含1,730多个样本的基准测试，用于探测模型幻觉。", "result": "广泛的实验表明，所提出的方法不仅有效缓解了语义幻觉，而且在场景文本检测和理解的公共基准测试中也取得了强大的性能。", "conclusion": "所提出的无需训练的框架，包括ZoomText和Grounded Layer Correction，有效缓解了大型多模态模型在处理场景文本时的语义幻觉，并提高了在标准基准上的性能。引入的TextHalu-Bench为评估模型幻觉提供了有价值的工具。", "translation": "大型多模态模型（LMMs）在视觉感知和推理方面取得了令人瞩目的进展。然而，当面对视觉模糊或非语义的场景文本时，它们往往难以准确地识别和理解内容，经常生成语义上合理但视觉上不正确的答案，我们称之为语义幻觉。在这项工作中，我们调查了语义幻觉的根本原因，并发现了一个关键结论：LLM中对场景文本区域注意力更强的Transformer层更不容易产生语义幻觉。因此，我们提出了一个无需训练的语义幻觉缓解框架，包括两个关键组件：（1）ZoomText，一种无需外部检测器即可识别潜在文本区域的粗到细策略；（2）Grounded Layer Correction，它自适应地利用不易产生幻觉的层的内部表示来指导解码，纠正非语义样本的幻觉输出，同时保留有意义样本的语义。为了实现严格的评估，我们引入了TextHalu-Bench，一个包含1,730多个样本的基准测试，涵盖了语义和非语义情况，并附有手动策划的问题-答案对，旨在探测模型幻觉。大量的实验表明，我们的方法不仅有效地缓解了语义幻觉，而且在场景文本检测和理解的公共基准测试中也取得了强大的性能。", "summary": "本文旨在解决大型多模态模型（LMMs）在处理场景文本时出现的语义幻觉问题，即模型生成语义合理但视觉不正确的答案。通过发现对文本注意力更强的Transformer层不易产生幻觉，作者提出了一个无需训练的缓解框架。该框架包括用于文本区域识别的ZoomText和用于自适应解码引导的Grounded Layer Correction。此外，他们还引入了TextHalu-Bench这一新的基准测试来评估幻觉。实验证实，他们的方法有效减少了幻觉，并提高了场景文本任务的性能。", "keywords": "大型多模态模型, 语义幻觉, 场景文本, 无需训练, TextHalu-Bench", "comments": "创新点：本文的创新在于识别了Transformer层注意力与幻觉之间的联系，并提出了一个无需训练的框架（ZoomText和Grounded Layer Correction）来缓解幻觉。TextHalu-Bench的引入也对严格评估做出了重要贡献。\n重要性：这项工作对于提高LMMs在涉及场景文本的实际应用中的可靠性和可信度至关重要，特别是在处理模糊或非语义内容时。\n局限性：Not mentioned in abstract."}}
{"id": "2506.05678", "title": "Numerical Investigation of Sequence Modeling Theory using Controllable Memory Functions", "authors": ["Haotian Jiang", "Zeyu Bao", "Shida Wang", "Qianxiao Li"], "summary": "The evolution of sequence modeling architectures, from recurrent neural\nnetworks and convolutional models to Transformers and structured state-space\nmodels, reflects ongoing efforts to address the diverse temporal dependencies\ninherent in sequential data. Despite this progress, systematically\ncharacterizing the strengths and limitations of these architectures remains a\nfundamental challenge.In this work, we propose a synthetic benchmarking\nframework to evaluate how effectively different sequence models capture\ndistinct temporal structures. The core of this approach is to generate\nsynthetic targets, each characterized by a memory function and a parameter that\ndetermines the strength of temporal dependence. This setup allows us to produce\na continuum of tasks that vary in temporal complexity, enabling fine-grained\nanalysis of model behavior concerning specific memory properties. We focus on\nfour representative memory functions, each corresponding to a distinct class of\ntemporal structures.Experiments on several sequence modeling architectures\nconfirm existing theoretical insights and reveal new findings.These results\ndemonstrate the effectiveness of the proposed method in advancing theoretical\nunderstandingand highlight the importance of using controllable targets with\nclearly defined structures for evaluating sequence modeling architectures.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05678v1", "AI": {"title_translation": "使用可控记忆函数对序列建模理论的数值研究", "tldr": "本文提出了一个合成基准测试框架，通过可控记忆函数评估不同序列模型捕获时间结构的能力，证实了现有理论并揭示了新发现。", "motivation": "尽管序列建模架构（从循环神经网络到Transformer和结构化状态空间模型）在处理序列数据中固有的多样时间依赖性方面取得了进展，但系统地表征这些架构的优势和局限性仍然是一个基本挑战。", "method": "本文提出了一个合成基准测试框架，用于评估不同序列模型捕获不同时间结构的有效性。该方法的核心是生成合成目标，每个目标都由一个记忆函数和一个确定时间依赖强度参数来表征。这种设置允许生成时间复杂度连续变化的任务，从而能够对模型行为进行关于特定记忆属性的细粒度分析。研究重点是四种代表性记忆函数，每种对应一类不同的时间结构。", "result": "在几种序列建模架构上进行的实验证实了现有理论见解并揭示了新发现。这些结果证明了所提出方法在推进理论理解方面的有效性。", "conclusion": "所提出的方法在推进序列建模的理论理解方面是有效的，并且强调了使用具有明确定义结构的可控目标来评估序列建模架构的重要性。", "translation": "序列建模架构的演变，从循环神经网络和卷积模型到Transformer和结构化状态空间模型，反映了为解决序列数据中固有的多样时间依赖性而持续进行的努力。尽管取得了这些进展，系统地表征这些架构的优势和局限性仍然是一个基本挑战。在这项工作中，我们提出了一个合成基准测试框架，用于评估不同序列模型捕获不同时间结构的有效性。该方法的核心是生成合成目标，每个目标都由一个记忆函数和一个确定时间依赖强度的参数来表征。这种设置允许我们生成时间复杂度连续变化的任务，从而能够对模型行为进行关于特定记忆属性的细粒度分析。我们重点关注四种代表性记忆函数，每种都对应一类不同的时间结构。在几种序列建模架构上进行的实验证实了现有理论见解并揭示了新发现。这些结果证明了所提出方法在推进理论理解方面的有效性，并强调了使用具有明确定义结构的可控目标来评估序列建模架构的重要性。", "summary": "本文提出了一种合成基准测试框架，旨在系统评估序列建模架构捕获时间结构的能力。该框架通过生成具有可控记忆函数和可变时间依赖强度参数的合成目标，创建了一系列时间复杂度连续变化的测试任务。实验结果验证了现有理论并提供了新的见解，突显了使用明确定义、可控目标进行模型评估的重要性。", "keywords": "序列建模, 时间依赖性, 基准测试, 记忆函数, 合成数据", "comments": "该论文的创新之处在于提出了一个可控的合成基准测试框架，这使得对序列模型记忆特性进行系统且细致的分析成为可能。它解决了理解特定架构为何在某些时间依赖性上表现出色这一关键挑战。其重要性在于推动了理论理解，并为未来的模型开发和评估提供了一个强大的工具。"}}
{"id": "2506.05554", "title": "EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh", "authors": ["Tao Hu", "Haoyang Peng", "Xiao Liu", "Yuewen Ma"], "summary": "Generating high-quality camera-controllable videos from monocular input is a\nchallenging task, particularly under extreme viewpoint. Existing methods often\nstruggle with geometric inconsistencies and occlusion artifacts in boundaries,\nleading to degraded visual quality. In this paper, we introduce EX-4D, a novel\nframework that addresses these challenges through a Depth Watertight Mesh\nrepresentation. The representation serves as a robust geometric prior by\nexplicitly modeling both visible and occluded regions, ensuring geometric\nconsistency in extreme camera pose. To overcome the lack of paired multi-view\ndatasets, we propose a simulated masking strategy that generates effective\ntraining data only from monocular videos. Additionally, a lightweight\nLoRA-based video diffusion adapter is employed to synthesize high-quality,\nphysically consistent, and temporally coherent videos. Extensive experiments\ndemonstrate that EX-4D outperforms state-of-the-art methods in terms of\nphysical consistency and extreme-view quality, enabling practical 4D video\ngeneration.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05554v1", "AI": {"title_translation": "EX-4D：通过深度水密网格实现极限视点4D视频合成", "tldr": "EX-4D提出了一种新的框架，利用深度水密网格解决单目输入下极限视点4D视频合成中的几何不一致和遮挡伪影问题，通过模拟遮罩策略和LoRA视频扩散适配器生成高质量、物理一致且时间连贯的视频。", "motivation": "从单目输入生成高质量、摄像机可控的视频，尤其是在极限视点下，是一项具有挑战性的任务。现有方法在边界处的几何不一致和遮挡伪影方面表现不佳，导致视觉质量下降。", "method": "本文引入了EX-4D框架，通过深度水密网格（Depth Watertight Mesh）表示来解决挑战。该表示通过明确建模可见和被遮挡区域，确保在极限摄像机姿态下的几何一致性。为了克服多视图数据集缺乏的问题，提出了一种模拟遮罩策略，仅从单目视频生成有效的训练数据。此外，采用轻量级基于LoRA的视频扩散适配器来合成高质量、物理一致且时间连贯的视频。", "result": "广泛的实验表明，EX-4D在物理一致性和极限视点质量方面优于最先进的方法。", "conclusion": "EX-4D实现了实用的4D视频生成。", "translation": "从单目输入生成高质量、摄像机可控的视频是一项具有挑战性的任务，尤其是在极限视点下。现有方法通常在边界处存在几何不一致和遮挡伪影，导致视觉质量下降。在本文中，我们引入了EX-4D，这是一个新颖的框架，通过深度水密网格表示来解决这些挑战。该表示通过明确建模可见和被遮挡区域，作为强大的几何先验，确保在极限摄像机姿态下的几何一致性。为了克服配对多视图数据集的缺乏，我们提出了一种模拟遮罩策略，仅从单目视频生成有效的训练数据。此外，采用轻量级基于LoRA的视频扩散适配器来合成高质量、物理一致且时间连贯的视频。广泛的实验表明，EX-4D在物理一致性和极限视点质量方面优于最先进的方法，实现了实用的4D视频生成。", "summary": "EX-4D是一个用于极限视点4D视频合成的新框架，旨在解决从单目输入生成高质量视频时存在的几何不一致和遮挡伪影问题。该方法利用深度水密网格作为鲁棒的几何先验，并通过模拟遮罩策略生成训练数据，结合基于LoRA的视频扩散适配器合成高质量、物理一致且时间连贯的视频。实验证明EX-4D在物理一致性和极限视点质量方面优于现有技术。", "keywords": "4D视频合成, 极限视点, 深度水密网格, 几何一致性, 视频扩散", "comments": "本文的创新点在于提出了深度水密网格表示来解决极限视点下的几何一致性问题，并通过模拟遮罩策略克服了多视图数据集缺乏的限制。结合LoRA的视频扩散适配器，使得生成高质量的4D视频成为可能，具有重要的实际应用价值。"}}
{"id": "2506.05680", "title": "Learning Design-Score Manifold to Guide Diffusion Models for Offline Optimization", "authors": ["Tailin Zhou", "Zhilin Chen", "Wenlong Lyu", "Zhitang Chen", "Danny H. K. Tsang", "Jun Zhang"], "summary": "Optimizing complex systems, from discovering therapeutic drugs to designing\nhigh-performance materials, remains a fundamental challenge across science and\nengineering, as the underlying rules are often unknown and costly to evaluate.\nOffline optimization aims to optimize designs for target scores using\npre-collected datasets without system interaction. However, conventional\napproaches may fail beyond training data, predicting inaccurate scores and\ngenerating inferior designs. This paper introduces ManGO, a diffusion-based\nframework that learns the design-score manifold, capturing the design-score\ninterdependencies holistically. Unlike existing methods that treat design and\nscore spaces in isolation, ManGO unifies forward prediction and backward\ngeneration, attaining generalization beyond training data. Key to this is its\nderivative-free guidance for conditional generation, coupled with adaptive\ninference-time scaling that dynamically optimizes denoising paths. Extensive\nevaluations demonstrate that ManGO outperforms 24 single- and 10\nmulti-objective optimization methods across diverse domains, including\nsynthetic tasks, robot control, material design, DNA sequence, and real-world\nengineering optimization.", "comment": "This manuscript is submitted and under review", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05680v1", "AI": {"title_translation": "学习设计-分数流形以指导扩散模型进行离线优化", "tldr": "ManGO是一个基于扩散的框架，通过学习设计-分数流形来解决离线优化中传统方法泛化能力差的问题，并在多领域表现优异。", "motivation": "优化复杂系统（如药物发现、材料设计）是一个基本挑战，因为底层规则未知且评估成本高。传统的离线优化方法在训练数据之外可能失效，导致分数预测不准确和设计质量差。", "method": "本文介绍了ManGO，一个基于扩散的框架，它学习设计-分数流形，整体捕获设计-分数相互依赖关系。ManGO统一了前向预测和后向生成，实现了训练数据之外的泛化。其关键在于无导数引导的条件生成和自适应推理时间缩放。", "result": "ManGO在合成任务、机器人控制、材料设计、DNA序列和真实世界工程优化等多个领域，超越了24种单目标和10种多目标优化方法。", "conclusion": "ManGO通过学习设计-分数流形并统一预测与生成，有效解决了离线优化中的泛化问题，并在多种复杂系统优化任务中取得了显著的性能提升。", "translation": "优化复杂系统，从发现治疗药物到设计高性能材料，仍然是科学和工程领域的一个基本挑战，因为其底层规则往往未知且评估成本高昂。离线优化旨在利用预收集的数据集，在不与系统交互的情况下，优化设计以达到目标分数。然而，传统方法在训练数据之外可能会失效，预测不准确的分数并生成劣质设计。本文介绍了ManGO，一个基于扩散的框架，它学习设计-分数流形，整体捕获设计-分数相互依赖关系。与现有方法将设计和分数空间孤立对待不同，ManGO统一了前向预测和后向生成，实现了训练数据之外的泛化。其关键在于其用于条件生成的无导数引导，以及动态优化去噪路径的自适应推理时间缩放。广泛的评估表明，ManGO在包括合成任务、机器人控制、材料设计、DNA序列和真实世界工程优化在内的不同领域，超越了24种单目标和10种多目标优化方法。", "summary": "本文提出了ManGO，一个创新的基于扩散的框架，用于解决离线优化中传统方法泛化能力不足的问题。ManGO通过学习设计-分数流形，整体捕捉设计与分数之间的复杂相互依赖关系，并统一了设计的前向预测和后向生成过程。该框架的关键在于其无导数引导的条件生成和自适应推理时间缩放机制。实验证明，ManGO在多种复杂的优化任务中，包括材料设计和机器人控制，均显著优于现有方法。", "keywords": "离线优化, 扩散模型, 设计-分数流形, 无导数引导, ManGO", "comments": "ManGO的创新之处在于其将设计和分数空间统一处理，并通过学习设计-分数流形来解决传统离线优化方法泛化能力差的问题。其基于扩散模型的框架，特别是无导数引导和自适应推理时间缩放，为复杂系统的离线优化提供了一种有效且通用的解决方案。在多个领域的卓越表现表明其在实际应用中的巨大潜力。"}}
{"id": "2506.05558", "title": "On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images", "authors": ["Andreas Meuleman", "Ishaan Shah", "Alexandre Lanvin", "Bernhard Kerbl", "George Drettakis"], "summary": "Radiance field methods such as 3D Gaussian Splatting (3DGS) allow easy\nreconstruction from photos, enabling free-viewpoint navigation. Nonetheless,\npose estimation using Structure from Motion and 3DGS optimization can still\neach take between minutes and hours of computation after capture is complete.\nSLAM methods combined with 3DGS are fast but struggle with wide camera\nbaselines and large scenes. We present an on-the-fly method to produce camera\nposes and a trained 3DGS immediately after capture. Our method can handle dense\nand wide-baseline captures of ordered photo sequences and large-scale scenes.\nTo do this, we first introduce fast initial pose estimation, exploiting learned\nfeatures and a GPU-friendly mini bundle adjustment. We then introduce direct\nsampling of Gaussian primitive positions and shapes, incrementally spawning\nprimitives where required, significantly accelerating training. These two\nefficient steps allow fast and robust joint optimization of poses and Gaussian\nprimitives. Our incremental approach handles large-scale scenes by introducing\nscalable radiance field construction, progressively clustering 3DGS primitives,\nstoring them in anchors, and offloading them from the GPU. Clustered primitives\nare progressively merged, keeping the required scale of 3DGS at any viewpoint.\nWe evaluate our solution on a variety of datasets and show that our solution\ncan provide on-the-fly processing of all the capture scenarios and scene sizes\nwe target while remaining competitive with other methods that only handle\nspecific capture styles or scene sizes in speed, image quality, or both.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05558v1", "AI": {"title_translation": "大规模无姿态图像新颖视图合成的即时重建", "tldr": "提出一种即时方法，利用学习特征、GPU友好的BA和增量高斯采样，实现无姿态图像大规模新颖视图合成的快速姿态估计和3DGS重建，并支持大规模场景。", "motivation": "现有辐射场方法（如SfM+3DGS）在姿态估计和优化上计算耗时，而SLAM+3DGS虽快但难以处理宽相机基线和大规模场景。", "method": "我们提出了一种即时方法：1. 引入快速初始姿态估计，利用学习特征和GPU友好的小型束调整。2. 引入高斯基元位置和形状的直接采样，按需增量生成基元，显著加速训练。3. 增量方法处理大规模场景：引入可扩展辐射场构建，逐步聚类3DGS基元，存储在锚点中并从GPU卸载，聚类基元逐步合并以保持所需尺度。", "result": "该解决方案可以对所有目标捕获场景和场景尺寸进行即时处理，并且在速度和图像质量方面与仅处理特定捕获样式或场景尺寸的其他方法相比具有竞争力。", "conclusion": "该方法能够对无姿态图像进行即时重建，支持大规模新颖视图合成，并在效率和质量上表现良好。", "translation": "3D高斯泼溅（3DGS）等辐射场方法可以轻松地从照片中进行重建，从而实现自由视点导航。然而，使用运动结构（SfM）进行姿态估计和3DGS优化在捕获完成后仍可能分别花费数分钟到数小时的计算时间。SLAM方法与3DGS结合虽然速度快，但在宽相机基线和大规模场景中表现不佳。\n我们提出了一种即时方法，在捕获完成后立即生成相机姿态和训练好的3DGS。我们的方法可以处理有序照片序列的密集和宽基线捕获以及大规模场景。\n为此，我们首先引入了快速初始姿态估计，利用学习到的特征和GPU友好的小型束调整。然后，我们引入了高斯基元位置和形状的直接采样，在需要时增量地生成基元，显著加速了训练。这两个高效的步骤使得姿态和高斯基元能够快速且鲁棒地联合优化。\n我们的增量方法通过引入可扩展的辐射场构建来处理大规模场景，逐步聚类3DGS基元，将它们存储在锚点中并从GPU卸载。聚类后的基元逐步合并，从而在任何视点保持所需的3DGS尺度。\n我们在各种数据集上评估了我们的解决方案，结果表明我们的解决方案可以对我们目标的所有捕获场景和场景尺寸进行即时处理，同时在速度、图像质量或两者兼有方面，与仅处理特定捕获样式或场景尺寸的其他方法相比，仍具有竞争力。", "summary": "这篇论文提出了一种即时（on-the-fly）方法，用于从无姿态图像中进行大规模新颖视图合成。针对现有3DGS重建方法耗时且难以处理大规模场景和宽基线的问题，该方法引入了快速初始姿态估计（利用学习特征和GPU友好的小型束调整）和高斯基元的直接增量采样，以加速训练和联合优化。此外，通过可扩展的辐射场构建和基元聚类及合并策略，有效处理大规模场景。实验表明，该方法能即时处理多种捕获场景和场景尺寸，并在速度和图像质量上与现有方法保持竞争力。", "keywords": "即时重建, 3D高斯泼溅, 新颖视图合成, 无姿态图像, 大规模场景", "comments": "论文的创新点在于结合了快速姿态估计和增量高斯采样，并提出了可扩展的辐射场构建，以实现即时、大规模的3DGS重建。这对于需要快速生成3D模型（如AR/VR、实时渲染）的应用具有重要意义，解决了传统方法耗时和规模受限的问题。"}}
{"id": "2506.05563", "title": "VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction", "authors": ["Ziyue Zhu", "Shenlong Wang", "Jin Xie", "Jiang-jiang Liu", "Jingdong Wang", "Jian Yang"], "summary": "Recent advancements in camera-based occupancy prediction have focused on the\nsimultaneous prediction of 3D semantics and scene flow, a task that presents\nsignificant challenges due to specific difficulties, e.g., occlusions and\nunbalanced dynamic environments. In this paper, we analyze these challenges and\ntheir underlying causes. To address them, we propose a novel regularization\nframework called VoxelSplat. This framework leverages recent developments in 3D\nGaussian Splatting to enhance model performance in two key ways: (i) Enhanced\nSemantics Supervision through 2D Projection: During training, our method\ndecodes sparse semantic 3D Gaussians from 3D representations and projects them\nonto the 2D camera view. This provides additional supervision signals in the\ncamera-visible space, allowing 2D labels to improve the learning of 3D\nsemantics. (ii) Scene Flow Learning: Our framework uses the predicted scene\nflow to model the motion of Gaussians, and is thus able to learn the scene flow\nof moving objects in a self-supervised manner using the labels of adjacent\nframes. Our method can be seamlessly integrated into various existing occupancy\nmodels, enhancing performance without increasing inference time. Extensive\nexperiments on benchmark datasets demonstrate the effectiveness of VoxelSplat\nin improving the accuracy of both semantic occupancy and scene flow estimation.\nThe project page and codes are available at\nhttps://zzy816.github.io/VoxelSplat-Demo/.", "comment": "Accepted by CVPR 2025 Project Page:\n  https://zzy816.github.io/VoxelSplat-Demo/", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05563v1", "AI": {"title_translation": "VoxelSplat：动态高斯泼溅作为占用和流预测的有效损失", "tldr": "VoxelSplat利用3D高斯泼溅技术，通过2D投影语义监督和自监督场景流学习，显著提升了3D语义占用和场景流预测的准确性，且不增加推理时间。", "motivation": "现有的基于摄像头的占用预测在同时预测3D语义和场景流方面面临挑战，特别是由于遮挡和不平衡的动态环境造成的困难。", "method": "本文提出了一种名为VoxelSplat的新型正则化框架，旨在解决3D语义占用和场景流预测中的挑战。该框架利用3D高斯泼溅技术增强模型性能，主要通过两种方式实现：(i) 2D投影增强语义监督：在训练期间，将稀疏语义3D高斯从3D表示解码并投影到2D相机视图，以利用2D标签改进3D语义的学习。(ii) 场景流学习：利用预测的场景流对高斯运动进行建模，并通过相邻帧的标签以自监督方式学习运动物体的场景流。该方法可以无缝集成到各种现有占用模型中，且不增加推理时间。", "result": "在基准数据集上进行的大量实验证明，VoxelSplat在提高语义占用和场景流估计的准确性方面是有效的。", "conclusion": "VoxelSplat是一个有效且可集成到现有模型中的框架，能够显著提高3D语义占用和场景流预测的准确性，解决了现有方法面临的挑战。", "translation": "近年来，基于摄像头的占用预测研究主要集中在同时预测3D语义和场景流，这项任务由于遮挡和不平衡动态环境等特定困难而面临重大挑战。在本文中，我们分析了这些挑战及其根本原因。为了解决这些问题，我们提出了一种新颖的正则化框架，名为VoxelSplat。该框架利用3D高斯泼溅的最新发展，通过两种关键方式增强模型性能：(i) 通过2D投影增强语义监督：在训练期间，我们的方法从3D表示中解码稀疏语义3D高斯，并将其投影到2D相机视图。这在相机可见空间中提供了额外的监督信号，允许2D标签改进3D语义的学习。(ii) 场景流学习：我们的框架使用预测的场景流来模拟高斯的运动，从而能够利用相邻帧的标签以自监督方式学习运动物体的场景流。我们的方法可以无缝集成到各种现有占用模型中，在不增加推理时间的情况下提高性能。在基准数据集上进行的大量实验证明了VoxelSplat在提高语义占用和场景流估计准确性方面的有效性。项目页面和代码可在https://zzy816.github.io/VoxelSplat-Demo/ 获取。", "summary": "本文提出了VoxelSplat框架，旨在解决3D语义占用和场景流预测中因遮挡和动态环境带来的挑战。该框架利用3D高斯泼溅技术，通过将3D高斯投影到2D视图以提供额外的语义监督，并利用预测的场景流自监督学习运动物体的场景流。VoxelSplat可无缝集成到现有模型中，并在不增加推理时间的情况下显著提高语义占用和场景流估计的准确性。", "keywords": "3D高斯泼溅, 占用预测, 场景流, 语义监督, 自监督学习", "comments": "VoxelSplat的创新点在于将3D高斯泼溅技术引入到占用和场景流预测任务中，并通过2D投影监督和自监督场景流学习解决了现有方法的挑战。其优势在于能够提高性能同时不增加推理时间，且易于集成，这对于实际应用具有重要意义。"}}
{"id": "2506.05701", "title": "Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health", "authors": ["Pavel Dolin", "Weizhi Li", "Gautam Dasarathy", "Visar Berisha"], "summary": "This position paper argues that post-deployment monitoring in clinical AI is\nunderdeveloped and proposes statistically valid and label-efficient testing\nframeworks as a principled foundation for ensuring reliability and safety in\nreal-world deployment. A recent review found that only 9% of FDA-registered\nAI-based healthcare tools include a post-deployment surveillance plan. Existing\nmonitoring approaches are often manual, sporadic, and reactive, making them\nill-suited for the dynamic environments in which clinical models operate. We\ncontend that post-deployment monitoring should be grounded in label-efficient\nand statistically valid testing frameworks, offering a principled alternative\nto current practices. We use the term \"statistically valid\" to refer to methods\nthat provide explicit guarantees on error rates (e.g., Type I/II error), enable\nformal inference under pre-defined assumptions, and support\nreproducibility--features that align with regulatory requirements.\nSpecifically, we propose that the detection of changes in the data and model\nperformance degradation should be framed as distinct statistical hypothesis\ntesting problems. Grounding monitoring in statistical rigor ensures a\nreproducible and scientifically sound basis for maintaining the reliability of\nclinical AI systems. Importantly, it also opens new research directions for the\ntechnical community--spanning theory, methods, and tools for statistically\nprincipled detection, attribution, and mitigation of post-deployment model\nfailures in real-world settings.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05701v1", "AI": {"title_translation": "AI驱动数字健康中统计有效部署后监控应成为标准", "tldr": "本立场文件指出，临床AI工具部署后监控不足，应采用统计学有效且标签高效的测试框架来确保其在实际部署中的可靠性和安全性，并为相关研究开辟新方向。", "motivation": "临床AI部署后监控不足（仅9%的FDA注册工具包含监控计划），现有方法手动、零星、被动，不适用于动态环境，导致可靠性和安全性问题。", "method": "提出将数据变化和模型性能下降的检测框架为独立的统计假设检验问题，并倡导采用统计学有效且标签高效的测试框架，以提供明确的错误率保证、支持正式推断和可重复性。", "result": "确保临床AI系统可靠性的可重复和科学合理基础，并为技术社区开辟了新的研究方向，包括统计原理检测、归因和缓解部署后模型故障的理论、方法和工具。", "conclusion": "部署后监控应以统计严谨性为基础，以确保临床AI系统的可靠性并促进相关研究。", "translation": "这篇立场文件认为，临床AI中的部署后监控不足，并提出了统计有效且标签高效的测试框架作为确保实际部署中可靠性和安全性的原则性基础。最近一项审查发现，只有9%的FDA注册AI医疗工具包含部署后监控计划。现有的监控方法通常是手动的、零星的、被动的，使其不适合临床模型运行的动态环境。我们认为，部署后监控应以标签高效和统计有效的测试框架为基础，为当前实践提供原则性的替代方案。我们使用“统计有效”一词来指代那些对错误率（例如，I型/II型错误）提供明确保证、在预定义假设下实现正式推断以及支持可重复性的方法——这些特征与监管要求相符。具体来说，我们建议将数据变化和模型性能下降的检测视为独立的统计假设检验问题。将监控建立在统计严谨性之上，可为维护临床AI系统的可靠性提供可重复且科学合理的基础。重要的是，它还为技术社区开辟了新的研究方向——涵盖了在实际环境中对部署后模型故障进行统计学原理检测、归因和缓解的理论、方法和工具。", "summary": "本立场文件指出，临床AI部署后监控现状不足，仅9%的FDA注册AI医疗工具包含监控计划。为解决现有手动、零星、被动监控的局限性，论文倡导采用统计有效且标签高效的测试框架，将数据变化和模型性能下降检测视为统计假设检验问题。这种方法旨在提供明确的错误率保证、支持正式推断和可重复性，从而为确保临床AI系统的可靠性提供科学严谨的基础，并为相关研究开辟新方向。", "keywords": "AI医疗, 部署后监控, 统计有效性, 可靠性, 假设检验", "comments": "这篇立场文件强调了AI医疗领域一个关键且常被忽视的问题：部署后的持续监控。其创新之处在于提出了将统计假设检验引入监控框架，以确保可重复性和科学严谨性，这对于AI医疗工具的监管和实际应用至关重要。该论文不仅指出了现有不足，还为未来的研究和实践提供了明确的方向。"}}
{"id": "2506.05410", "title": "Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs", "authors": ["Wanyun Cui", "Mingwei Xu"], "summary": "Recent advances in Large Language Models (LLMs) have highlighted the critical\nimportance of extending context length, yet the quadratic complexity of\nattention mechanisms poses significant challenges for efficient long-context\nmodeling. KV cache compression has emerged as a key approach to address this\nchallenge. Through extensive empirical analysis, we reveal a fundamental yet\npreviously overlooked asymmetry in KV caches: while adjacent keys receive\nsimilar attention weights (local homogeneity), adjacent values demonstrate\ndistinct heterogeneous distributions. This key-value asymmetry reveals a\ncritical limitation in existing compression methods that treat keys and values\nuniformly. To address the limitation, we propose a training-free compression\nframework (AsymKV) that combines homogeneity-based key merging with a\nmathematically proven lossless value compression. Extensive experiments\ndemonstrate that AsymKV consistently outperforms existing long-context methods\nacross various tasks and base models. For example, on LLaMA3.1-8B, AsymKV\nachieves an average score of 43.95 on LongBench, surpassing SOTA methods like\nH$_2$O (38.89) by a large margin.", "comment": "14 pages,7 figures", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05410v1", "AI": {"title_translation": "齐次键，异质值：利用局部KV缓存不对称性处理长上下文LLM", "tldr": "提出AsymKV框架，通过利用KV缓存不对称性（键同质，值异质）来高效压缩KV缓存，显著提升长上下文LLM性能。", "motivation": "现有大型语言模型（LLM）在处理长上下文时面临注意力机制的二次复杂度挑战；KV缓存压缩是解决该挑战的关键方法，但现有方法未能充分利用KV缓存中键和值的内在不对称性。", "method": "本文提出了一个免训练的压缩框架AsymKV，该框架结合了基于同质性的键合并（针对局部同质的键）和数学上证明的无损值压缩（针对异质分布的值）。", "result": "AsymKV在各种任务和基础模型上始终优于现有长上下文方法。例如，在LLaMA3.1-8B上，AsymKV在LongBench上的平均得分为43.95，大幅超越了最先进的方法H2O（38.89）。", "conclusion": "AsymKV通过利用KV缓存的局部不对称性，提供了一种有效且高性能的KV缓存压缩方法，显著提升了LLM处理长上下文的能力，解决了现有方法的局局限性。", "translation": "大型语言模型（LLM）的最新进展凸显了扩展上下文长度的至关重要性，然而，注意力机制的二次复杂度对高效长上下文建模构成了重大挑战。KV缓存压缩已成为解决这一挑战的关键方法。通过广泛的实证分析，我们揭示了KV缓存中一个基本但以前被忽视的不对称性：相邻键接收相似的注意力权重（局部同质性），而相邻值则表现出明显不同的异质分布。这种键值不对称性揭示了现有压缩方法统一处理键和值的关键局限性。为了解决这一局限性，我们提出了一个免训练的压缩框架（AsymKV），它结合了基于同质性的键合并和数学上证明的无损值压缩。广泛的实验表明，AsymKV在各种任务和基础模型上始终优于现有的长上下文方法。例如，在LLaMA3.1-8B上，AsymKV在LongBench上的平均得分为43.95，大幅超越了H2O（38.89）等SOTA方法。", "summary": "本文通过实证分析揭示了KV缓存中键的局部同质性和值的异质性这一先前被忽视的不对称性。针对现有压缩方法统一处理键值的局限性，提出了一种免训练的AsymKV压缩框架。该框架结合了基于同质性的键合并和数学上证明的无损值压缩，旨在高效处理长上下文LLM。实验结果表明，AsymKV在多项任务和模型上均显著优于现有长上下文方法。", "keywords": "KV缓存压缩, 长上下文LLM, 键值不对称性, AsymKV, 无损压缩", "comments": "本文的创新点在于发现了KV缓存中键和值的内在不对称性，这为KV缓存压缩提供了新的视角。提出的AsymKV框架是免训练的，并且包含数学上证明的无损值压缩，这保证了其高效性和可靠性。其在多个模型和任务上的显著性能提升，证明了该方法的有效性和重要性，为长上下文LLM的效率提升提供了新思路。"}}
{"id": "2506.05573", "title": "PartCrafter: Structured 3D Mesh Generation via Compositional Latent Diffusion Transformers", "authors": ["Yuchen Lin", "Chenguo Lin", "Panwang Pan", "Honglei Yan", "Yiqiang Feng", "Yadong Mu", "Katerina Fragkiadaki"], "summary": "We introduce PartCrafter, the first structured 3D generative model that\njointly synthesizes multiple semantically meaningful and geometrically distinct\n3D meshes from a single RGB image. Unlike existing methods that either produce\nmonolithic 3D shapes or follow two-stage pipelines, i.e., first segmenting an\nimage and then reconstructing each segment, PartCrafter adopts a unified,\ncompositional generation architecture that does not rely on pre-segmented\ninputs. Conditioned on a single image, it simultaneously denoises multiple 3D\nparts, enabling end-to-end part-aware generation of both individual objects and\ncomplex multi-object scenes. PartCrafter builds upon a pretrained 3D mesh\ndiffusion transformer (DiT) trained on whole objects, inheriting the pretrained\nweights, encoder, and decoder, and introduces two key innovations: (1) A\ncompositional latent space, where each 3D part is represented by a set of\ndisentangled latent tokens; (2) A hierarchical attention mechanism that enables\nstructured information flow both within individual parts and across all parts,\nensuring global coherence while preserving part-level detail during generation.\nTo support part-level supervision, we curate a new dataset by mining part-level\nannotations from large-scale 3D object datasets. Experiments show that\nPartCrafter outperforms existing approaches in generating decomposable 3D\nmeshes, including parts that are not directly visible in input images,\ndemonstrating the strength of part-aware generative priors for 3D understanding\nand synthesis. Code and training data will be released.", "comment": "Project Page: https://wgsxm.github.io/projects/partcrafter/", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05573v1", "AI": {"title_translation": "PartCrafter: 通过组合潜在扩散Transformer进行结构化3D网格生成", "tldr": "PartCrafter是一个新的3D生成模型，能从单张图片同时生成多个有语义和几何意义的3D网格部件，优于现有方法，并能生成不可见部件。", "motivation": "现有3D生成模型要么生成整体形状，要么需要两阶段处理（图像分割后重建），而PartCrafter旨在解决这些限制，实现统一的、组合式的端到端部件感知3D生成，包括复杂场景和不可见部件。", "method": "PartCrafter是第一个结构化3D生成模型，它从单个RGB图像联合合成多个语义有意义且几何上独特的3D网格。它采用统一的、组合式的生成架构，不依赖预分割输入。它基于预训练的3D网格扩散Transformer (DiT)，并引入两个关键创新：1) 组合潜在空间，每个3D部件由一组解耦的潜在标记表示；2) 分层注意力机制，实现部件内部和部件间结构化信息流。为支持部件级监督，作者还策划了一个新的数据集。", "result": "PartCrafter在生成可分解3D网格方面优于现有方法，包括生成输入图像中不直接可见的部件，这证明了部件感知生成先验对于3D理解和合成的强大能力。", "conclusion": "PartCrafter成功地实现了从单张图像端到端地生成结构化3D网格，包括不可见的部件，展示了其在3D理解和合成中的潜力。", "translation": "我们介绍了PartCrafter，这是第一个结构化3D生成模型，它能从单个RGB图像联合合成多个语义有意义且几何上独特的3D网格。与现有方法（要么生成整体3D形状，要么遵循两阶段流程，即先分割图像再重建每个部分）不同，PartCrafter采用统一的、组合式的生成架构，不依赖预分割输入。在单张图像条件下，它同时对多个3D部件进行去噪，从而实现个体对象和复杂多对象场景的端到端部件感知生成。PartCrafter基于在整个对象上预训练的3D网格扩散Transformer (DiT) 构建，继承了预训练权重、编码器和解码器，并引入了两项关键创新：(1) 组合潜在空间，其中每个3D部件由一组解耦的潜在标记表示；(2) 分层注意力机制，实现部件内部和所有部件之间的结构化信息流，确保全局一致性同时在生成过程中保留部件级细节。为了支持部件级监督，我们通过从大规模3D对象数据集中挖掘部件级注释，策划了一个新数据集。实验表明，PartCrafter在生成可分解3D网格方面优于现有方法，包括输入图像中不直接可见的部件，这证明了部件感知生成先验对于3D理解和合成的强大能力。代码和训练数据将发布。", "summary": "PartCrafter是一个创新的结构化3D生成模型，它能从单张RGB图像端到端地同时生成多个语义和几何上独立的3D网格部件。它不同于传统方法，采用统一的组合式架构，通过组合潜在空间和分层注意力机制，在继承预训练3D网格扩散Transformer的基础上，实现了对个体对象和复杂场景的部件感知生成，甚至能生成输入图像中不可见的部件。实验证明其在生成可分解3D网格方面表现优异。", "keywords": "3D生成, 结构化3D网格, 组合潜在扩散, Transformer, 部件感知", "comments": "PartCrafter的创新之处在于其统一的、组合式生成架构，避免了传统两阶段方法的复杂性，并能从单张图片生成多个结构化3D部件，包括不可见的部件，这对于3D理解和合成具有重要意义。其引入的组合潜在空间和分层注意力机制是实现这一能力的关键。"}}
{"id": "2506.05702", "title": "Action-Adaptive Continual Learning: Enabling Policy Generalization under Dynamic Action Spaces", "authors": ["Chaofan Pan", "Jiafen Liu", "Yanhua Li", "Linbo Xiong", "Fan Min", "Wei Wei", "Xin Yang"], "summary": "Continual Learning (CL) is a powerful tool that enables agents to learn a\nsequence of tasks, accumulating knowledge learned in the past and using it for\nproblem-solving or future task learning. However, existing CL methods often\nassume that the agent's capabilities remain static within dynamic environments,\nwhich doesn't reflect real-world scenarios where capabilities dynamically\nchange. This paper introduces a new and realistic problem: Continual Learning\nwith Dynamic Capabilities (CL-DC), posing a significant challenge for CL\nagents: How can policy generalization across different action spaces be\nachieved? Inspired by the cortical functions, we propose an Action-Adaptive\nContinual Learning framework (AACL) to address this challenge. Our framework\ndecouples the agent's policy from the specific action space by building an\naction representation space. For a new action space, the encoder-decoder of\naction representations is adaptively fine-tuned to maintain a balance between\nstability and plasticity. Furthermore, we release a benchmark based on three\nenvironments to validate the effectiveness of methods for CL-DC. Experimental\nresults demonstrate that our framework outperforms popular methods by\ngeneralizing the policy across action spaces.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05702v1", "AI": {"title_translation": "动作自适应持续学习：在动态动作空间下实现策略泛化", "tldr": "本文提出动作自适应持续学习（AACL）框架，通过构建动作表示空间，解决动态动作空间下持续学习中的策略泛化问题，并发布了相关基准，实验证明其优于现有方法。", "motivation": "现有持续学习方法假设智能体能力在动态环境中保持静态，不符合真实世界中能力动态变化的场景。本文引入了一个新的现实问题：动态能力持续学习（CL-DC），旨在解决如何在不同动作空间下实现策略泛化。", "method": "提出动作自适应持续学习框架（AACL）。该框架通过构建动作表示空间，将智能体策略与特定动作空间解耦。对于新的动作空间，自适应微调动作表示的编码器-解码器，以在稳定性和可塑性之间保持平衡。此外，还发布了一个基于三种环境的基准来验证CL-DC方法的有效性。", "result": "实验结果表明，所提出的AACL框架通过跨动作空间泛化策略，性能优于流行方法。", "conclusion": "Not mentioned in abstract", "translation": "持续学习（CL）是一种强大的工具，使智能体能够学习一系列任务，积累过去所学知识并将其用于解决问题或未来的任务学习。然而，现有的CL方法通常假设智能体能力在动态环境中保持静态，这不符合能力动态变化的真实世界场景。本文引入了一个新的现实问题：动态能力持续学习（CL-DC），这给CL智能体带来了重大挑战：如何在不同动作空间下实现策略泛化？受皮层功能的启发，我们提出了一个动作自适应持续学习框架（AACL）来应对这一挑战。我们的框架通过构建动作表示空间，将智能体策略与特定动作空间解耦。对于新的动作空间，动作表示的编码器-解码器自适应微调，以在稳定性和可塑性之间保持平衡。此外，我们发布了一个基于三种环境的基准来验证CL-DC方法的有效性。实验结果表明，我们的框架通过跨动作空间泛化策略，优于流行方法。", "summary": "本文介绍了动作自适应持续学习（AACL）框架，旨在解决动态能力持续学习（CL-DC）这一新问题，即在智能体能力动态变化的真实世界场景中实现策略泛化。AACL通过构建动作表示空间，巧妙地将智能体策略与具体动作空间解耦，并通过自适应微调动作表示的编码器-解码器来平衡稳定性和可塑性。为促进研究，论文还发布了一个基于三种环境的CL-DC基准。实验结果验证了AACL在跨动作空间策略泛化方面的优越性。", "keywords": "持续学习, 动态动作空间, 策略泛化, 动作表示, AACL", "comments": "该论文提出了一种新颖且重要的持续学习问题——动态能力持续学习（CL-DC），这更符合真实世界的复杂性。其提出的AACL框架通过引入动作表示空间，巧妙地解耦了策略与动作空间，为解决策略泛化问题提供了新的思路。同时，发布基准有助于推动该领域的研究。"}}
{"id": "2506.05599", "title": "UniRes: Universal Image Restoration for Complex Degradations", "authors": ["Mo Zhou", "Keren Ye", "Mauricio Delbracio", "Peyman Milanfar", "Vishal M. Patel", "Hossein Talebi"], "summary": "Real-world image restoration is hampered by diverse degradations stemming\nfrom varying capture conditions, capture devices and post-processing pipelines.\nExisting works make improvements through simulating those degradations and\nleveraging image generative priors, however generalization to in-the-wild data\nremains an unresolved problem. In this paper, we focus on complex degradations,\ni.e., arbitrary mixtures of multiple types of known degradations, which is\nfrequently seen in the wild. A simple yet flexible diffusionbased framework,\nnamed UniRes, is proposed to address such degradations in an end-to-end manner.\nIt combines several specialized models during the diffusion sampling steps,\nhence transferring the knowledge from several well-isolated restoration tasks\nto the restoration of complex in-the-wild degradations. This only requires\nwell-isolated training data for several degradation types. The framework is\nflexible as extensions can be added through a unified formulation, and the\nfidelity-quality trade-off can be adjusted through a new paradigm. Our proposed\nmethod is evaluated on both complex-degradation and single-degradation image\nrestoration datasets. Extensive qualitative and quantitative experimental\nresults show consistent performance gain especially for images with complex\ndegradations.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05599v1", "AI": {"title_translation": "UniRes: 复杂退化的通用图像恢复", "tldr": "UniRes是一个基于扩散的框架，通过结合多个专业模型来解决真实世界中图像的复杂（多种类型混合）退化问题，在复杂退化图像上表现出一致的性能提升。", "motivation": "现有图像恢复方法在处理真实世界中由多种捕获条件、设备和后处理流程引起的复杂（即多种已知退化类型任意混合）图像退化时，泛化能力不足。", "method": "本文提出了一个名为UniRes的简单灵活的基于扩散的端到端框架。它在扩散采样步骤中结合了多个专业模型，从而将来自多个独立恢复任务的知识转移到复杂真实世界退化的恢复中。该框架只需要针对几种退化类型的独立训练数据，并且可以通过统一的公式进行扩展，通过新的范式调整保真度-质量权衡。", "result": "在复杂退化和单一退化图像恢复数据集上进行了评估。广泛的定性和定量实验结果显示出一致的性能提升，尤其是在具有复杂退化的图像上。", "conclusion": "UniRes框架有效解决了真实世界中图像的复杂退化问题，通过结合专业模型和灵活的设计，实现了对多种退化类型图像的通用恢复，并在实验中展现出优越性能。", "translation": "真实世界的图像恢复受到源于不同捕获条件、捕获设备和后处理流程的多种退化的阻碍。现有工作通过模拟这些退化和利用图像生成先验来改进，但泛化到野外数据仍然是一个未解决的问题。在本文中，我们关注复杂退化，即多种已知退化类型的任意混合，这在野外数据中经常出现。我们提出了一个简单而灵活的基于扩散的框架，名为UniRes，以端到端的方式解决此类退化。它在扩散采样步骤中结合了几个专业模型，从而将来自几个独立恢复任务的知识转移到复杂野外退化的恢复中。这只需要几种退化类型的独立训练数据。该框架是灵活的，可以通过统一的公式添加扩展，并且可以通过新的范式调整保真度-质量权衡。我们提出的方法在复杂退化和单一退化图像恢复数据集上进行了评估。广泛的定性和定量实验结果显示出一致的性能提升，尤其是在具有复杂退化的图像上。", "summary": "本文提出了一种名为UniRes的通用图像恢复框架，旨在解决真实世界中由多种退化类型任意混合形成的复杂图像退化问题。UniRes是一个基于扩散的端到端模型，它在扩散采样过程中整合了多个针对单一退化任务训练的专业模型，从而将它们的知识泛化到复杂退化场景。该框架具有高度灵活性，仅需独立的退化类型训练数据，并能通过新范式调整保真度-质量权衡。实验结果表明，UniRes在处理复杂退化图像方面表现出显著且一致的性能提升。", "keywords": "图像恢复, 复杂退化, 扩散模型, 泛化, UniRes", "comments": "UniRes的创新点在于其基于扩散的框架能够以灵活的方式整合多个专业模型，从而有效处理真实世界中常见的复杂（混合类型）图像退化。这种方法通过知识转移解决了现有方法在泛化能力上的不足，尤其是在仅需独立训练数据的情况下实现对复杂退化的通用恢复，具有重要的实际应用价值。"}}
{"id": "2506.05607", "title": "Controlled Data Rebalancing in Multi-Task Learning for Real-World Image Super-Resolution", "authors": ["Shuchen Lin", "Mingtao Feng", "Weisheng Dong", "Fangfang Wu", "Jianqiao Luo", "Yaonan Wang", "Guangming Shi"], "summary": "Real-world image super-resolution (Real-SR) is a challenging problem due to\nthe complex degradation patterns in low-resolution images. Unlike approaches\nthat assume a broadly encompassing degradation space, we focus specifically on\nachieving an optimal balance in how SR networks handle different degradation\npatterns within a fixed degradation space. We propose an improved paradigm that\nframes Real-SR as a data-heterogeneous multi-task learning problem, our work\naddresses task imbalance in the paradigm through coordinated advancements in\ntask definition, imbalance quantification, and adaptive data rebalancing.\nSpecifically, we introduce a novel task definition framework that segments the\ndegradation space by setting parameter-specific boundaries for degradation\noperators, effectively reducing the task quantity while maintaining task\ndiscrimination. We then develop a focal loss based multi-task weighting\nmechanism that precisely quantifies task imbalance dynamics during model\ntraining. Furthermore, to prevent sporadic outlier samples from dominating the\ngradient optimization of the shared multi-task SR model, we strategically\nconvert the quantified task imbalance into controlled data rebalancing through\ndeliberate regulation of task-specific training volumes. Extensive quantitative\nand qualitative experiments demonstrate that our method achieves consistent\nsuperiority across all degradation tasks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05607v1", "AI": {"title_translation": "多任务学习中受控数据再平衡用于真实世界图像超分辨率", "tldr": "本文提出了一种新的范式，将真实世界图像超分辨率（Real-SR）视为数据异构多任务学习问题，并通过改进任务定义、不平衡量化和自适应数据再平衡来解决任务不平衡问题，从而在所有降质任务中实现一致的优越性。", "motivation": "真实世界图像超分辨率（Real-SR）由于低分辨率图像中复杂的降质模式而具有挑战性。现有方法通常假设一个广泛的降质空间，但本文专注于在固定降质空间内实现SR网络如何处理不同降质模式的最佳平衡。", "method": "本文提出将Real-SR视为数据异构多任务学习问题，并通过协调以下方面的进展来解决任务不平衡：1. 任务定义：引入新的任务定义框架，通过为降质操作符设置特定参数边界来分割降质空间，减少任务数量同时保持任务区分度。2. 不平衡量化：开发基于focal loss的多任务加权机制，精确量化模型训练期间的任务不平衡动态。3. 自适应数据再平衡：将量化的任务不平衡转化为受控数据再平衡，通过有意调节特定任务的训练量，防止离群样本主导梯度优化。", "result": "广泛的定量和定性实验表明，该方法在所有降质任务中都表现出持续的优越性。", "conclusion": "本文提出的方法通过在多任务学习中对数据进行受控再平衡，有效地解决了真实世界图像超分辨率中的任务不平衡问题，并在各种降质任务中取得了卓越的性能。", "translation": "真实世界图像超分辨率（Real-SR）由于低分辨率图像中复杂的降质模式而具有挑战性。与假设广泛降质空间的方法不同，我们专注于在固定降质空间内实现SR网络如何处理不同降质模式的最佳平衡。我们提出了一种改进的范式，将Real-SR构建为数据异构多任务学习问题，我们的工作通过任务定义、不平衡量化和自适应数据再平衡方面的协调进展来解决范式中的任务不平衡问题。具体来说，我们引入了一种新颖的任务定义框架，通过为降质操作符设置特定参数边界来分割降质空间，有效地减少了任务数量，同时保持了任务区分度。然后，我们开发了一种基于focal loss的多任务加权机制，可以精确量化模型训练期间的任务不平衡动态。此外，为了防止零星的离群样本主导共享多任务SR模型的梯度优化，我们通过有意调节特定任务的训练量，战略性地将量化的任务不平衡转化为受控数据再平衡。广泛的定量和定性实验表明，我们的方法在所有降质任务中都实现了持续的优越性。", "summary": "本文针对真实世界图像超分辨率（Real-SR）中复杂的降质模式问题，提出了一种将Real-SR视为数据异构多任务学习问题的新范式。为解决多任务学习中的任务不平衡，该方法在任务定义、不平衡量化和自适应数据再平衡三个方面进行了改进。具体地，通过参数边界分割降质空间以优化任务定义；利用基于focal loss的机制量化任务不平衡；并通过调节训练量实现受控数据再平衡。实验结果表明，该方法在各种降质任务上均表现出一致的优越性。", "keywords": "图像超分辨率, 多任务学习, 数据再平衡, 降质模式, 任务不平衡", "comments": "该论文的创新点在于将真实世界图像超分辨率问题重新构建为数据异构多任务学习，并通过系统地解决任务不平衡问题来提升性能。其方法结合了新的任务定义、精确的不平衡量化和受控的数据再平衡策略，特别是通过调节训练量来防止离群样本影响优化，这对于提升多任务学习模型的鲁棒性和泛化能力具有重要意义。该研究对于处理真实世界中复杂且多样化的图像降质问题提供了有效的解决方案，具有较高的实用价值。"}}
{"id": "2506.05713", "title": "Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation", "authors": ["Zhan Zhuang", "Xiequn Wang", "Wei Li", "Yulong Zhang", "Qiushi Huang", "Shuhao Chen", "Xuehao Wang", "Yanbin Wei", "Yuhe Nie", "Kede Ma", "Yu Zhang", "Ying Wei"], "summary": "Low-rank adaptation (LoRA) has emerged as a leading parameter-efficient\nfine-tuning technique for adapting large foundation models, yet it often locks\nadapters into suboptimal minima near their initialization. This hampers model\ngeneralization and limits downstream operators such as adapter merging and\npruning. Here, we propose CoTo, a progressive training strategy that gradually\nincreases adapters' activation probability over the course of fine-tuning. By\nstochastically deactivating adapters, CoTo encourages more balanced\noptimization and broader exploration of the loss landscape. We provide a\ntheoretical analysis showing that CoTo promotes layer-wise dropout stability\nand linear mode connectivity, and we adopt a cooperative-game approach to\nquantify each adapter's marginal contribution. Extensive experiments\ndemonstrate that CoTo consistently boosts single-task performance, enhances\nmulti-task merging accuracy, improves pruning robustness, and reduces training\noverhead, all while remaining compatible with diverse LoRA variants. Code is\navailable at https://github.com/zwebzone/coto.", "comment": "Accepted by ICML 2025. Code link: https://github.com/zwebzone/coto", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05713v1", "AI": {"title_translation": "循序渐进，非一蹴而就：一种提升低秩适应的渐进策略", "tldr": "CoTo是一种渐进式训练策略，通过逐步增加适配器激活概率，解决LoRA训练中的次优局部最小值问题，从而提高模型泛化能力、合并准确性和剪枝鲁棒性。", "motivation": "低秩适应（LoRA）作为一种参数高效的微调技术，在适应大型基础模型方面表现出色，但它通常会使适配器锁定在其初始化附近的次优局部最小值，这阻碍了模型泛化并限制了适配器合并和剪枝等下游操作。", "method": "我们提出了CoTo，一种渐进式训练策略，在微调过程中逐渐增加适配器的激活概率。通过随机停用适配器，CoTo鼓励更均衡的优化和对损失函数景观的更广泛探索。我们提供了理论分析，表明CoTo促进了层级dropout的稳定性和线性模式连接性，并采用了合作博弈方法来量化每个适配器的边际贡献。", "result": "广泛的实验表明，CoTo始终能提升单任务性能，增强多任务合并准确性，改善剪枝鲁棒性，并降低训练开销，同时与各种LoRA变体兼容。", "conclusion": "CoTo是一种有效的渐进式训练策略，通过解决LoRA训练中的次优局部最小值问题，显著提升了低秩适应的性能和鲁棒性，并与现有LoRA变体兼容。", "translation": "低秩适应（LoRA）已成为一种领先的参数高效微调技术，用于适应大型基础模型，但它通常会将适配器锁定在其初始化附近的次优局部最小值。这阻碍了模型泛化并限制了适配器合并和剪枝等下游操作。在此，我们提出了CoTo，一种渐进式训练策略，在微调过程中逐渐增加适配器的激活概率。通过随机停用适配器，CoTo鼓励更均衡的优化和对损失函数景观的更广泛探索。我们提供了理论分析，表明CoTo促进了层级dropout的稳定性和线性模式连接性，并且我们采用合作博弈方法来量化每个适配器的边际贡献。广泛的实验表明，CoTo始终能提升单任务性能，增强多任务合并准确性，改善剪枝鲁棒性，并降低训练开销，所有这些都与各种LoRA变体兼容。代码可在 https://github.com/zwebzone/coto 获取。", "summary": "该论文提出了一种名为CoTo的渐进式训练策略，旨在解决低秩适应（LoRA）在微调大型基础模型时常遇到的次优局部最小值问题。CoTo通过在训练过程中逐步增加适配器的激活概率，并随机停用适配器，促进更均衡的优化和对损失景观的更广泛探索。理论分析表明CoTo能增强层级dropout稳定性和线性模式连接性。实验结果证明，CoTo能一致提升单任务性能、多任务合并准确性、剪枝鲁棒性并降低训练开销，同时兼容多种LoRA变体。", "keywords": "低秩适应, LoRA, 参数高效微调, 渐进式训练, CoTo", "comments": "CoTo的创新之处在于其渐进式训练策略，通过动态调整适配器的激活概率，有效地避免了LoRA训练中常见的次优局部最小值问题。这种方法不仅提升了模型性能和泛化能力，还增强了适配器合并和剪枝等下游操作的鲁棒性，具有重要的实践价值。其与多种LoRA变体的兼容性也表明了其广泛的适用性。"}}
{"id": "2506.05651", "title": "Hallucinate, Ground, Repeat: A Framework for Generalized Visual Relationship Detection", "authors": ["Shanmukha Vellamcheti", "Sanjoy Kundu", "Sathyanarayanan N. Aakur"], "summary": "Understanding relationships between objects is central to visual\nintelligence, with applications in embodied AI, assistive systems, and scene\nunderstanding. Yet, most visual relationship detection (VRD) models rely on a\nfixed predicate set, limiting their generalization to novel interactions. A key\nchallenge is the inability to visually ground semantically plausible, but\nunannotated, relationships hypothesized from external knowledge. This work\nintroduces an iterative visual grounding framework that leverages large\nlanguage models (LLMs) as structured relational priors. Inspired by\nexpectation-maximization (EM), our method alternates between generating\ncandidate scene graphs from detected objects using an LLM (expectation) and\ntraining a visual model to align these hypotheses with perceptual evidence\n(maximization). This process bootstraps relational understanding beyond\nannotated data and enables generalization to unseen predicates. Additionally,\nwe introduce a new benchmark for open-world VRD on Visual Genome with 21\nheld-out predicates and evaluate under three settings: seen, unseen, and mixed.\nOur model outperforms LLM-only, few-shot, and debiased baselines, achieving\nmean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification on\nthese three sets. These results highlight the promise of grounded LLM priors\nfor scalable open-world visual understanding.", "comment": "22 pages, 9 figures, 5 tables", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05651v1", "AI": {"title_translation": "幻化、接地、重复：一个用于通用视觉关系检测的框架", "tldr": "本文提出了一个迭代视觉接地框架，利用大型语言模型（LLMs）作为关系先验，以提升视觉关系检测（VRD）模型对新颖交互的泛化能力，并在新的开放世界基准上取得了优于现有基线的性能。", "motivation": "大多数视觉关系检测（VRD）模型依赖于固定的谓词集，限制了它们对新颖交互的泛化能力。主要挑战在于无法对从外部知识中假设的、语义合理但未标注的关系进行视觉接地。", "method": "本文引入了一个迭代视觉接地框架，该框架利用大型语言模型（LLMs）作为结构化关系先验。受期望最大化（EM）启发，该方法在两个阶段交替进行：一是使用LLM从检测到的对象生成候选场景图（期望阶段），二是训练一个视觉模型将这些假设与感知证据对齐（最大化阶段）。此过程超越了标注数据，实现了对未见谓词的泛化。", "result": "引入了一个新的开放世界VRD基准，该基准基于Visual Genome，包含21个保留谓词，并在三种设置下进行评估：已见、未见和混合。本文模型在谓词分类上表现优于纯LLM、少样本和去偏基线，在这些数据集上的平均召回率（mR@50）分别为15.9、13.1和11.7。", "conclusion": "这些结果突出了接地LLM先验在可扩展开放世界视觉理解方面的潜力。", "translation": "理解物体之间的关系是视觉智能的核心，在具身AI、辅助系统和场景理解中都有应用。然而，大多数视觉关系检测（VRD）模型依赖于固定的谓词集，限制了它们对新颖交互的泛化。一个关键挑战在于无法视觉上接地那些从外部知识中假设的、语义合理但未标注的关系。这项工作引入了一个迭代视觉接地框架，该框架利用大型语言模型（LLMs）作为结构化关系先验。受期望最大化（EM）启发，我们的方法在两个阶段交替进行：一是使用LLM从检测到的对象生成候选场景图（期望阶段），二是训练一个视觉模型将这些假设与感知证据对齐（最大化阶段）。这个过程超越了标注数据，实现了对未见谓词的泛化。此外，我们引入了一个新的开放世界VRD基准，该基准基于Visual Genome，包含21个保留谓词，并在三种设置下进行评估：已见、未见和混合。我们的模型在谓词分类上表现优于纯LLM、少样本和去偏基线，在这些数据集上的平均召回率（mR@50）分别为15.9、13.1和11.7。这些结果突出了接地LLM先验在可扩展开放世界视觉理解方面的潜力。", "summary": "本文提出了一个名为“幻化、接地、重复”的通用视觉关系检测框架，旨在解决现有VRD模型泛化能力不足的问题。该框架受期望最大化启发，通过迭代地利用大型语言模型（LLMs）生成场景图假设，并训练视觉模型进行接地验证，从而实现对未见谓词的泛化。研究还引入了一个新的开放世界VRD基准，并在实验中证明了该方法在已见、未见和混合设置下均优于多种基线模型，强调了接地LLM先验在开放世界视觉理解中的潜力。", "keywords": "视觉关系检测, 大型语言模型, 开放世界VRD, 迭代视觉接地, 期望最大化", "comments": "该论文的创新之处在于其迭代视觉接地框架，巧妙地将大型语言模型（LLMs）的语义推理能力与视觉模型的感知能力结合起来，以实现对开放世界视觉关系检测的泛化。受期望最大化（EM）启发的交替过程是其核心亮点，有效地解决了传统VRD模型依赖固定谓词集的问题。引入新的开放世界基准也具有重要意义，为该领域的研究提供了新的评估标准。"}}
{"id": "2506.05716", "title": "Ensemble Elastic DQN: A novel multi-step ensemble approach to address overestimation in deep value-based reinforcement learning", "authors": ["Adrian Ly", "Richard Dazeley", "Peter Vamplew", "Francisco Cruz", "Sunil Aryal"], "summary": "While many algorithmic extensions to Deep Q-Networks (DQN) have been\nproposed, there remains limited understanding of how different improvements\ninteract. In particular, multi-step and ensemble style extensions have shown\npromise in reducing overestimation bias, thereby improving sample efficiency\nand algorithmic stability. In this paper, we introduce a novel algorithm called\nEnsemble Elastic Step DQN (EEDQN), which unifies ensembles with elastic step\nupdates to stabilise algorithmic performance. EEDQN is designed to address two\nmajor challenges in deep reinforcement learning: overestimation bias and sample\nefficiency. We evaluated EEDQN against standard and ensemble DQN variants\nacross the MinAtar benchmark, a set of environments that emphasise behavioral\nlearning while reducing representational complexity. Our results show that\nEEDQN achieves consistently robust performance across all tested environments,\noutperforming baseline DQN methods and matching or exceeding state-of-the-art\nensemble DQNs in final returns on most of the MinAtar environments. These\nfindings highlight the potential of systematically combining algorithmic\nimprovements and provide evidence that ensemble and multi-step methods, when\ncarefully integrated, can yield substantial gains.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05716v1", "AI": {"title_translation": "集成弹性DQN：一种新颖的多步集成方法，用于解决深度基于价值强化学习中的过高估计问题", "tldr": "提出了一种名为集成弹性步长DQN (EEDQN) 的新算法，该算法结合了集成和弹性步长更新，以解决深度强化学习中的过高估计偏差和样本效率问题，并在MinAtar基准测试中表现出稳健的性能。", "motivation": "解决深度强化学习中的两个主要挑战：过高估计偏差和样本效率。同时，现有研究对不同DQN改进方法（特别是多步和集成方法）如何相互作用的理解有限。", "method": "引入了一种名为集成弹性步长DQN (EEDQN) 的新算法，该算法将集成与弹性步长更新相结合，以稳定算法性能。", "result": "EEDQN 在所有测试环境中都取得了持续稳健的性能，优于基线 DQN 方法，并在大多数 MinAtar 环境中在最终回报方面达到或超过了最先进的集成 DQN。", "conclusion": "系统地结合算法改进具有潜力，并且当集成和多步方法仔细整合时，可以产生实质性收益。", "translation": "尽管已经提出了许多深度Q网络（DQN）的算法扩展，但对于不同改进如何相互作用的理解仍然有限。特别是，多步和集成风格的扩展已显示出在减少过高估计偏差方面的前景，从而提高了样本效率和算法稳定性。在本文中，我们引入了一种名为集成弹性步长DQN（EEDQN）的新算法，该算法将集成与弹性步长更新相结合，以稳定算法性能。EEDQN旨在解决深度强化学习中的两个主要挑战：过高估计偏差和样本效率。我们在MinAtar基准测试（一组强调行为学习同时降低表示复杂性的环境）中，评估了EEDQN相对于标准和集成DQN变体的性能。我们的结果表明，EEDQN在所有测试环境中都取得了持续稳健的性能，优于基线DQN方法，并在大多数MinAtar环境中在最终回报方面达到或超过了最先进的集成DQN。这些发现突出了系统地结合算法改进的潜力，并提供了证据，表明集成和多步方法在仔细整合时可以产生实质性收益。", "summary": "本文提出了一种名为集成弹性步长DQN (EEDQN) 的新型算法，旨在通过结合集成方法和弹性步长更新来解决深度强化学习中的过高估计偏差和样本效率问题。研究在MinAtar基准测试中评估了EEDQN的性能，结果显示其在多个环境中表现出优于基线DQN并与现有先进集成DQN相当或更优的稳健性能，强调了系统结合算法改进的有效性。", "keywords": "深度强化学习, DQN, 过高估计, 集成学习, 多步学习", "comments": "EEDQN的创新之处在于它系统地结合了两种有前景的DQN扩展（集成和多步更新），以解决过高估计和样本效率问题。其重要性在于证明了这些方法的协同作用可以带来显著的性能提升，为未来的深度强化学习算法设计提供了有价值的见解。"}}
{"id": "2506.05655", "title": "Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues", "authors": ["Yimei Liu", "Yakun Ju", "Yuan Rao", "Hao Fan", "Junyu Dong", "Feng Gao", "Qian Du"], "summary": "Three-dimensional digital urban reconstruction from multi-view aerial images\nis a critical application where deep multi-view stereo (MVS) methods outperform\ntraditional techniques. However, existing methods commonly overlook the key\ndifferences between aerial and close-range settings, such as varying depth\nranges along epipolar lines and insensitive feature-matching associated with\nlow-detailed aerial images. To address these issues, we propose an Adaptive\nDepth Range MVS (ADR-MVS), which integrates monocular geometric cues to improve\nmulti-view depth estimation accuracy. The key component of ADR-MVS is the depth\nrange predictor, which generates adaptive range maps from depth and normal\nestimates using cross-attention discrepancy learning. In the first stage, the\nrange map derived from monocular cues breaks through predefined depth\nboundaries, improving feature-matching discriminability and mitigating\nconvergence to local optima. In later stages, the inferred range maps are\nprogressively narrowed, ultimately aligning with the cascaded MVS framework for\nprecise depth regression. Moreover, a normal-guided cost aggregation operation\nis specially devised for aerial stereo images to improve geometric awareness\nwithin the cost volume. Finally, we introduce a normal-guided depth refinement\nmodule that surpasses existing RGB-guided techniques. Experimental results\ndemonstrate that ADR-MVS achieves state-of-the-art performance on the WHU,\nLuoJia-MVS, and M\\\"unchen datasets, while exhibits superior computational\ncomplexity.", "comment": "IEEE TGRS 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05655v1", "AI": {"title_translation": "航空多视角立体匹配：通过自适应深度范围推断和法线线索", "tldr": "本文提出ADR-MVS，一种用于从航空图像进行三维城市重建的方法，通过自适应深度范围推断和法线线索，提高了深度估计精度和计算效率，达到了最先进的性能。", "motivation": "现有深度多视角立体匹配（MVS）方法在从多视角航空图像进行三维数字城市重建时，普遍忽视了航空和近距离设置之间的关键差异，例如沿极线的深度范围变化以及与低细节航空图像相关的特征匹配不敏感问题。", "method": "本文提出了一种自适应深度范围MVS（ADR-MVS）方法，它通过集成单目几何线索来提高多视角深度估计精度。ADR-MVS的关键组成部分是深度范围预测器，该预测器利用交叉注意力差异学习从深度和法线估计中生成自适应范围图。在第一阶段，源自单目线索的范围图突破了预定义的深度边界，提高了特征匹配的辨别力并减轻了收敛到局部最优的问题。在后期阶段，推断的范围图逐渐缩小，最终与级联MVS框架对齐，实现精确的深度回归。此外，还专门为航空立体图像设计了法线引导的代价聚合操作，以提高代价体内的几何感知。最后，引入了一个法线引导的深度细化模块，该模块超越了现有的RGB引导技术。", "result": "实验结果表明，ADR-MVS在WHU、LuoJia-MVS和München数据集上实现了最先进的性能，同时表现出卓越的计算复杂度。", "conclusion": "本文提出的ADR-MVS方法有效解决了航空多视角立体匹配中的挑战，从而实现了更精确和计算效率更高的三维城市重建。", "translation": "从多视角航空图像进行三维数字城市重建是一项关键应用，其中深度多视角立体匹配（MVS）方法优于传统技术。然而，现有方法普遍忽视了航空和近距离设置之间的关键差异，例如沿极线的深度范围变化以及与低细节航空图像相关的特征匹配不敏感问题。为了解决这些问题，我们提出了一种自适应深度范围MVS（ADR-MVS），它集成了单目几何线索以提高多视角深度估计精度。ADR-MVS的关键组成部分是深度范围预测器，它利用交叉注意力差异学习从深度和法线估计中生成自适应范围图。在第一阶段，源自单目线索的范围图突破了预定义的深度边界，提高了特征匹配的辨别力并减轻了收敛到局部最优的问题。在后期阶段，推断的范围图逐渐缩小，最终与级联MVS框架对齐，实现精确的深度回归。此外，还专门为航空立体图像设计了法线引导的代价聚合操作，以提高代价体内的几何感知。最后，我们引入了一个法线引导的深度细化模块，该模块超越了现有的RGB引导技术。实验结果表明，ADR-MVS在WHU、LuoJia-MVS和München数据集上实现了最先进的性能，同时表现出卓越的计算复杂度。", "summary": "本文提出了一种名为ADR-MVS的航空多视角立体匹配方法，旨在解决现有方法在航空图像三维城市重建中面临的深度范围变化和特征匹配不敏感问题。ADR-MVS通过引入自适应深度范围推断和法线线索，利用单目几何信息提高深度估计精度，并通过法线引导的代价聚合和深度细化进一步优化。实验证明，ADR-MVS在多个数据集上达到了最先进的性能，并具有优越的计算效率。", "keywords": "航空多视角立体匹配, 自适应深度范围, 法线线索, 三维城市重建, 深度估计", "comments": "创新点在于引入自适应深度范围推断和法线线索，专门解决了航空图像的特点（如深度范围变化大、细节信息少导致的特征匹配不敏感）。该研究对于提高航空图像三维城市重建的精度和效率具有重要意义。"}}
{"id": "2506.05718", "title": "Grokking Beyond the Euclidean Norm of Model Parameters", "authors": ["Pascal Jr Tikeng Notsawo", "Guillaume Dumas", "Guillaume Rabusseau"], "summary": "Grokking refers to a delayed generalization following overfitting when\noptimizing artificial neural networks with gradient-based methods. In this\nwork, we demonstrate that grokking can be induced by regularization, either\nexplicit or implicit. More precisely, we show that when there exists a model\nwith a property $P$ (e.g., sparse or low-rank weights) that generalizes on the\nproblem of interest, gradient descent with a small but non-zero regularization\nof $P$ (e.g., $\\ell_1$ or nuclear norm regularization) results in grokking.\nThis extends previous work showing that small non-zero weight decay induces\ngrokking. Moreover, our analysis shows that over-parameterization by adding\ndepth makes it possible to grok or ungrok without explicitly using\nregularization, which is impossible in shallow cases. We further show that the\n$\\ell_2$ norm is not a reliable proxy for generalization when the model is\nregularized toward a different property $P$, as the $\\ell_2$ norm grows in many\ncases where no weight decay is used, but the model generalizes anyway. We also\nshow that grokking can be amplified solely through data selection, with any\nother hyperparameter fixed.", "comment": "67 pages, 35 figures. Forty-second International Conference on\n  Machine Learning (ICML), 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05718v1", "AI": {"title_translation": "模型参数欧氏范数之外的Grokking现象", "tldr": "研究表明，Grokking现象可通过显式或隐式正则化诱导，并受模型深度和数据选择影响，且L2范数并非泛化的可靠衡量标准。", "motivation": "论文旨在证明Grokking现象可以通过显式或隐式正则化诱导，并扩展先前关于权重衰减诱导Grokking的工作，同时探索其他因素（如模型深度和数据选择）对Grokking的影响。", "method": "通过分析梯度下降与小但非零的特定属性P（如稀疏或低秩权重）正则化（如ℓ1或核范数正则化）的关系，证明其可以导致Grokking。此外，通过分析模型深度和数据选择对Grokking的影响。", "result": "Grokking可以通过显式或隐式正则化诱导。当存在具有属性P（如稀疏或低秩权重）的模型时，梯度下降与小但非零的P正则化（如ℓ1或核范数正则化）会导致Grokking。通过增加深度进行过参数化可以在不明确使用正则化的情况下实现Grokking或Ungrokking，这在浅层模型中是不可能的。当模型向不同属性P正则化时，ℓ2范数并非泛化的可靠代理，因为在许多未使用权重衰减的情况下ℓ2范数会增长但模型仍能泛化。Grokking可以仅通过数据选择来放大，而无需改变其他超参数。", "conclusion": "Grokking现象的发生不仅限于权重衰减，还可以由其他形式的正则化（包括隐式正则化）以及模型深度和数据选择等因素诱导和影响。ℓ2范数在某些情况下不足以作为泛化的可靠指标。", "translation": "Grokking指的是在使用基于梯度的方法优化人工神经网络时，在过拟合之后出现延迟泛化。在这项工作中，我们证明Grokking可以通过显式或隐式正则化诱导。更准确地说，我们表明，当存在一个具有属性P（例如，稀疏或低秩权重）的模型能够在目标问题上泛化时，梯度下降与小但非零的P正则化（例如，ℓ1或核范数正则化）会导致Grokking。这扩展了之前关于小非零权重衰减诱导Grokking的工作。此外，我们的分析表明，通过增加深度进行过参数化可以在不明确使用正则化的情况下实现Grokking或Ungrokking，这在浅层情况下是不可能的。我们进一步表明，当模型向不同属性P正则化时，ℓ2范数并非泛化的可靠代理，因为在许多未使用权重衰减的情况下ℓ2范数会增长，但模型仍然泛化。我们还表明，Grokking可以仅通过数据选择来放大，而无需改变任何其他超参数。", "summary": "本文研究了神经网络训练中的Grokking现象，发现其不仅可以通过显式或隐式正则化（如ℓ1或核范数正则化）诱导，而且与模型参数的特定属性P相关。研究表明，增加模型深度可以实现Grokking或Ungrokking而无需显式正则化，这在浅层模型中无法实现。此外，论文指出ℓ2范数在模型向不同属性正则化时并非泛化的可靠指标，并且Grokking现象可以通过数据选择来放大。", "keywords": "Grokking, 正则化, 泛化, 深度学习, ℓ2范数", "comments": "这篇论文深入探讨了Grokking现象的诱导机制及其与正则化、模型深度和数据选择的关系。它挑战了L2范数作为泛化可靠代理的普遍认知，揭示了过参数化在Grokking中的复杂作用。研究结果对于理解神经网络的泛化行为和设计更有效的训练策略具有重要意义。"}}
{"id": "2506.05415", "title": "Automatically Detecting Amusing Games in Wordle", "authors": ["Ronaldo Luo", "Gary Liang", "Cindy Liu", "Adam Kabbara", "Minahil Bakhtawar", "Kina Kim", "Michael Guerzhoy"], "summary": "We explore automatically predicting which Wordle games Reddit users find\namusing.\n  We scrape approximately 80k reactions by Reddit users to Wordle games from\nReddit, classify the reactions as expressing amusement or not using OpenAI's\nGPT-3.5 using few-shot prompting, and verify that GPT-3.5's labels roughly\ncorrespond to human labels.\n  We then extract features from Wordle games that can predict user amusement.\nWe demonstrate that the features indeed provide a (weak) signal that predicts\nuser amusement as predicted by GPT-3.5.\n  Our results indicate that user amusement at Wordle games can be predicted\ncomputationally to some extent. We explore which features of the game\ncontribute to user amusement.\n  We find that user amusement is predictable, indicating a measurable aspect of\ncreativity infused into Wordle games through humor.", "comment": "Accepted to the Intenational Conference on Computational Creeativity\n  (ICCC) 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05415v1", "AI": {"title_translation": "自动检测Wordle游戏中令人愉悦的对局", "tldr": "使用Reddit数据和GPT-3.5预测Wordle游戏中令人愉悦的对局。", "motivation": "探索自动预测Reddit用户认为哪些Wordle游戏令人愉悦。", "method": "爬取约8万条Reddit用户对Wordle游戏的反应，使用OpenAI的GPT-3.5（通过少样本提示）将反应分类为表达愉悦或不表达愉悦，并验证GPT-3.5的标签与人工标签大致对应。然后，从Wordle游戏中提取可以预测用户愉悦度的特征。", "result": "提取的特征确实提供了预测GPT-3.5预测的用户愉悦度的（弱）信号。Wordle游戏中用户愉悦度可以在某种程度上通过计算进行预测。用户愉悦度是可预测的，这表明通过幽默注入Wordle游戏的创造力具有可衡量性。", "conclusion": "Wordle游戏中用户愉悦度在计算上可在一定程度上预测，这种可预测性突出了通过幽默注入的创造力的可衡量方面。", "translation": "我们探索自动预测Reddit用户觉得哪些Wordle游戏令人愉悦。我们从Reddit爬取了大约8万条Reddit用户对Wordle游戏的反应，使用OpenAI的GPT-3.5通过少样本提示将这些反应分类为表达愉悦或不表达愉悦，并验证GPT-3.5的标签与人工标签大致对应。然后，我们从Wordle游戏中提取可以预测用户愉悦度的特征。我们证明这些特征确实提供了一个（弱）信号，可以预测GPT-3.5预测的用户愉悦度。我们的结果表明，Wordle游戏中用户愉悦度可以在某种程度上通过计算进行预测。我们探索了游戏的哪些特征有助于用户愉悦度。我们发现用户愉悦度是可预测的，这表明通过幽默注入Wordle游戏的创造力具有可衡量性。", "summary": "本文研究了自动预测Reddit用户认为哪些Wordle游戏令人愉悦。研究人员爬取了8万条Reddit评论，并使用GPT-3.5对评论进行情感分类以识别愉悦反应。随后，他们从Wordle游戏中提取特征，并证明这些特征能（弱）预测用户愉悦度。结果表明，Wordle游戏的愉悦度在计算上是可预测的，这揭示了通过幽默融入游戏的创造力的可衡量性。", "keywords": "Wordle, 愉悦度, GPT-3.5, 用户反应, 计算预测", "comments": "这项研究创新性地利用GPT-3.5对用户对游戏的反应进行情感分类，以识别愉悦感。其重要性在于证明了游戏愉悦感在计算上的可预测性，并将其与游戏中通过幽默体现的创造力联系起来，为理解和设计更具吸引力的游戏提供了新的视角。"}}
{"id": "2506.05660", "title": "TissUnet: Improved Extracranial Tissue and Cranium Segmentation for Children through Adulthood", "authors": ["Markian Mandzak", "Elvira Yang", "Anna Zapaishchykova", "Yu-Hui Chen", "Lucas Heilbroner", "John Zielke", "Divyanshu Tak", "Reza Mojahed-Yazdi", "Francesca Romana Mussa", "Zezhong Ye", "Sridhar Vajapeyam", "Viviana Benitez", "Ralph Salloum", "Susan N. Chi", "Houman Sotoudeh", "Jakob Seidlitz", "Sabine Mueller", "Hugo J. W. L. Aerts", "Tina Y. Poussaint", "Benjamin H. Kann"], "summary": "Extracranial tissues visible on brain magnetic resonance imaging (MRI) may\nhold significant value for characterizing health conditions and clinical\ndecision-making, yet they are rarely quantified. Current tools have not been\nwidely validated, particularly in settings of developing brains or underlying\npathology. We present TissUnet, a deep learning model that segments skull bone,\nsubcutaneous fat, and muscle from routine three-dimensional T1-weighted MRI,\nwith or without contrast enhancement. The model was trained on 155 paired\nMRI-computed tomography (CT) scans and validated across nine datasets covering\na wide age range and including individuals with brain tumors. In comparison to\nAI-CT-derived labels from 37 MRI-CT pairs, TissUnet achieved a median Dice\ncoefficient of 0.79 [IQR: 0.77-0.81] in a healthy adult cohort. In a second\nvalidation using expert manual annotations, median Dice was 0.83 [IQR:\n0.83-0.84] in healthy individuals and 0.81 [IQR: 0.78-0.83] in tumor cases,\noutperforming previous state-of-the-art method. Acceptability testing resulted\nin an 89% acceptance rate after adjudication by a tie-breaker(N=108 MRIs), and\nTissUnet demonstrated excellent performance in the blinded comparative review\n(N=45 MRIs), including both healthy and tumor cases in pediatric populations.\nTissUnet enables fast, accurate, and reproducible segmentation of extracranial\ntissues, supporting large-scale studies on craniofacial morphology, treatment\neffects, and cardiometabolic risk using standard brain T1w MRI.", "comment": "44 pages, 4 tables, 6 figures, supplementary material", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05660v1", "AI": {"title_translation": "TissUnet：改进的儿童至成人颅外组织和颅骨分割", "tldr": "TissUnet是一种深度学习模型，能够快速准确地从T1加权MRI中分割颅骨、皮下脂肪和肌肉，适用于儿童和成人，包括肿瘤病例。", "motivation": "脑MRI上可见的颅外组织对健康状况和临床决策具有重要价值，但现有量化工具尚未得到广泛验证，尤其是在发育中的大脑或潜在病理情况下。", "method": "本文提出了TissUnet，一个深度学习模型，用于从常规三维T1加权MRI（有或无对比增强）中分割颅骨、皮下脂肪和肌肉。该模型在155对MRI-CT扫描上进行训练，并在9个数据集上验证，涵盖广泛年龄范围和包括脑肿瘤患者。", "result": "与AI-CT衍生标签相比，在健康成人队列中TissUnet的Dice系数中位数为0.79。与专家手动标注相比，健康个体Dice系数中位数为0.83，肿瘤病例为0.81，优于现有最先进方法。可接受性测试获得89%的接受率，并在盲法比较审查中表现出色，包括儿科健康和肿瘤病例。", "conclusion": "TissUnet能够实现颅外组织的快速、准确和可重复分割，支持使用标准脑T1w MRI进行颅面形态、治疗效果和心血管代谢风险的大规模研究。", "translation": "脑磁共振成像（MRI）上可见的颅外组织可能对表征健康状况和临床决策具有重要价值，但它们很少被量化。目前的工具尚未得到广泛验证，特别是在发育中的大脑或潜在病理情况下。我们提出了TissUnet，一个深度学习模型，用于从常规三维T1加权MRI（有或无对比增强）中分割颅骨、皮下脂肪和肌肉。该模型在155对MRI-计算机断层扫描（CT）上进行训练，并在九个涵盖广泛年龄范围和包括脑肿瘤患者的数据集上进行验证。与37对MRI-CT的AI-CT衍生标签相比，TissUnet在健康成人队列中实现了中位Dice系数0.79 [IQR: 0.77-0.81]。在第二次使用专家手动标注的验证中，健康个体中位Dice系数为0.83 [IQR: 0.83-0.84]，肿瘤病例中位Dice系数为0.81 [IQR: 0.78-0.83]，优于先前的最先进方法。可接受性测试在由决胜者裁定后（N=108 MRIs）获得89%的接受率，并且TissUnet在盲法比较审查中（N=45 MRIs）表现出色，包括儿科健康和肿瘤病例。TissUnet能够实现颅外组织的快速、准确和可重复分割，支持使用标准脑T1w MRI进行颅面形态、治疗效果和心血管代谢风险的大规模研究。", "summary": "本文介绍了TissUnet，一个基于深度学习的颅外组织分割模型，能够从T1加权MRI中准确分割颅骨、皮下脂肪和肌肉。该模型在包含儿童和成人的多样化数据集上进行了训练和验证，包括脑肿瘤患者。实验结果表明，TissUnet在分割精度上优于现有方法，并具有良好的可接受性，为颅面形态学、治疗效果评估和心血管代谢风险研究提供了快速、准确且可重复的工具。", "keywords": "颅外组织分割, TissUnet, 深度学习, MRI", "comments": "TissUnet的创新之处在于其对儿童至成人广泛年龄范围的适用性，以及在肿瘤病例中的有效性，这解决了现有工具在发育中大脑或病理情况下的局限性。其在多种数据集上的验证和优于现有技术的表现，凸显了其在临床和研究中的潜在价值，特别是在大规模研究中实现颅外组织的量化。"}}
{"id": "2506.05721", "title": "Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data", "authors": ["Dumindu Tissera", "Omar Awadallah", "Muhammad Umair Danish", "Ayan Sadhu", "Katarina Grolinger"], "summary": "Multi-label Classification (MLC) assigns an instance to one or more\nnon-exclusive classes. A challenge arises when the dataset contains a large\nproportion of instances with no assigned class, referred to as negative data,\nwhich can overwhelm the learning process and hinder the accurate identification\nand classification of positive instances. Nevertheless, it is common in MLC\napplications such as industrial defect detection, agricultural disease\nidentification, and healthcare diagnosis to encounter large amounts of negative\ndata. Assigning a separate negative class to these instances further\ncomplicates the learning objective and introduces unnecessary redundancies. To\naddress this challenge, we redesign standard MLC loss functions by deriving a\nlikelihood of any class being present, formulated by a normalized weighted\ngeometric mean of the predicted class probabilities. We introduce a\nregularization parameter that controls the relative contribution of the absent\nclass probabilities to the any-class presence likelihood in positive instances.\nThe any-class presence likelihood complements the multi-label learning by\nencouraging the network to become more aware of implicit positive instances and\nimprove the label classification within those positive instances. Experiments\non large-scale datasets with negative data: SewerML, modified COCO, and\nChestX-ray14, across various networks and base loss functions show that our\nloss functions consistently improve MLC performance of their standard loss\ncounterparts, achieving gains of up to 6.01 percentage points in F1, 8.06 in\nF2, and 3.11 in mean average precision, all without additional parameters or\ncomputational complexity. Code available at:\nhttps://github.com/ML-for-Sensor-Data-Western/gmean-mlc", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05721v1", "AI": {"title_translation": "用于处理大量负样本数据的鲁棒多标签分类的任意类别存在似然", "tldr": "本文提出了一种新的多标签分类损失函数，通过引入“任意类别存在似然”来有效处理包含大量未标记负样本数据的情况，显著提高了分类性能，且不增加额外参数或计算复杂度。", "motivation": "多标签分类（MLC）中存在一个挑战，即数据集中包含大量没有分配类别的实例（称为负样本数据），这些负样本会压倒学习过程，阻碍对正样本的准确识别和分类。在工业缺陷检测、农业疾病识别和医疗诊断等MLC应用中，大量负样本数据很常见。将这些实例分配一个单独的负类别会进一步使学习目标复杂化并引入不必要的冗余。", "method": "为了解决负样本数据挑战，我们通过推导“任意类别存在似然”来重新设计标准MLC损失函数。这种似然由预测类别概率的归一化加权几何平均值公式化。我们引入了一个正则化参数，用于控制负样本类别概率对正样本实例中“任意类别存在似然”的相对贡献。“任意类别存在似然”通过鼓励网络更多地关注隐式正样本实例并改进这些正样本实例内的标签分类来补充多标签学习。", "result": "在包含负样本的大规模数据集（SewerML、修改后的COCO和ChestX-ray14）上，通过各种网络和基础损失函数进行的实验表明，我们的损失函数始终优于其标准损失对应项的MLC性能，F1得分提高高达6.01个百分点，F2得分提高8.06个百分点，平均精度（mean average precision）提高3.11个百分点，所有这些都无需额外的参数或计算复杂性。", "conclusion": "通过引入“任意类别存在似然”并重新设计损失函数，本文提出的方法能够有效提升在存在大量负样本数据情况下的多标签分类性能，且不增加模型复杂性。", "translation": "多标签分类（MLC）将一个实例分配给一个或多个非排他性类别。当数据集中包含大量没有分配类别的实例（称为负样本数据）时，就会出现一个挑战，这些负样本会压倒学习过程，阻碍对正样本的准确识别和分类。然而，在工业缺陷检测、农业疾病识别和医疗诊断等MLC应用中，遇到大量负样本数据是很常见的。将这些实例分配一个单独的负类别会进一步使学习目标复杂化并引入不必要的冗余。为了解决这个挑战，我们通过推导“任意类别存在似然”来重新设计标准MLC损失函数，该似然由预测类别概率的归一化加权几何平均值公式化。我们引入了一个正则化参数，用于控制负样本类别概率对正样本实例中“任意类别存在似然”的相对贡献。“任意类别存在似然”通过鼓励网络更多地关注隐式正样本实例并改进这些正样本实例内的标签分类来补充多标签学习。在包含负样本的大规模数据集：SewerML、修改后的COCO和ChestX-ray14上，通过各种网络和基础损失函数进行的实验表明，我们的损失函数始终优于其标准损失对应项的MLC性能，F1得分提高高达6.01个百分点，F2得分提高8.06个百分点，平均精度提高3.11个百分点，所有这些都无需额外的参数或计算复杂性。代码可在此处获取：https://github.com/ML-for-Sensor-Data-Western/gmean-mlc", "summary": "本论文旨在解决多标签分类（MLC）中大量未标记负样本数据带来的挑战，这些数据会阻碍正样本的准确识别。针对传统方法中为负样本分配独立类别所带来的复杂性和冗余，作者提出了一种新的方法：通过计算预测类别概率的归一化加权几何平均值来推导“任意类别存在似然”，并将其融入标准MLC损失函数中。该方法引入了一个正则化参数来控制负样本概率对正样本实例中“任意类别存在似然”的贡献，从而鼓励网络更关注隐式正样本并提高其内部的标签分类。在SewerML、修改后的COCO和ChestX-ray14等大规模负样本数据集上的实验表明，与标准损失函数相比，该方法在不增加额外参数或计算复杂度的情况下，持续提升了MLC性能，F1、F2和平均精度分别取得了显著提升。", "keywords": "多标签分类, 负样本数据, 损失函数, 任意类别存在似然, 几何平均", "comments": "本文的创新之处在于其处理多标签分类中大量负样本数据的方式。通过引入“任意类别存在似然”并将其整合到现有损失函数中，而不是创建单独的负类别，该方法提供了一种优雅且有效的问题解决方案。其优势在于在真实世界应用中提高了模型的鲁棒性和分类性能，同时避免了额外的模型复杂性，这对于实际部署非常重要。"}}
{"id": "2506.05667", "title": "DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models", "authors": ["Yuhan Hao", "Zhengning Li", "Lei Sun", "Weilong Wang", "Naixin Yi", "Sheng Song", "Caihong Qin", "Mofan Zhou", "Yifei Zhan", "Peng Jia", "Xianpeng Lang"], "summary": "Vision-Language-Action (VLA) models have advanced autonomous driving, but\nexisting benchmarks still lack scenario diversity, reliable action-level\nannotation, and evaluation protocols aligned with human preferences. To address\nthese limitations, we introduce DriveAction, the first action-driven benchmark\nspecifically designed for VLA models, comprising 16,185 QA pairs generated from\n2,610 driving scenarios. DriveAction leverages real-world driving data\nproactively collected by users of production-level autonomous vehicles to\nensure broad and representative scenario coverage, offers high-level discrete\naction labels collected directly from users' actual driving operations, and\nimplements an action-rooted tree-structured evaluation framework that\nexplicitly links vision, language, and action tasks, supporting both\ncomprehensive and task-specific assessment. Our experiments demonstrate that\nstate-of-the-art vision-language models (VLMs) require both vision and language\nguidance for accurate action prediction: on average, accuracy drops by 3.3%\nwithout vision input, by 4.1% without language input, and by 8.0% without\neither. Our evaluation supports precise identification of model bottlenecks\nwith robust and consistent results, thus providing new insights and a rigorous\nfoundation for advancing human-like decisions in autonomous driving.", "comment": "Benchmark:\n  https://huggingface.co/datasets/LiAuto-DriveAction/drive-action", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05667v1", "AI": {"title_translation": "DriveAction：探索VLA模型中类人驾驶决策的基准", "tldr": "DriveAction是一个新的、以动作为驱动的基准，旨在解决现有自动驾驶VLA模型基准的局限性，并促进类人驾驶决策的进步。", "motivation": "现有基准缺乏场景多样性、可靠的动作级标注以及与人类偏好一致的评估协议，这些限制阻碍了视觉-语言-动作（VLA）模型在自动驾驶领域的进一步发展。", "method": "本文引入了DriveAction，这是一个首个专门为VLA模型设计的以动作为驱动的基准，包含从2,610个驾驶场景中生成的16,185个问答对。它利用生产级自动驾驶汽车用户主动收集的真实世界驾驶数据，确保广泛且具代表性的场景覆盖，提供直接从用户实际驾驶操作中收集的高级离散动作标签，并实施了一个明确连接视觉、语言和动作任务的以动作根植的树状评估框架，支持全面和任务特定的评估。", "result": "实验表明，最先进的视觉-语言模型（VLMs）需要视觉和语言指导才能准确预测动作：平均而言，没有视觉输入时准确率下降3.3%，没有语言输入时下降4.1%，而两者都缺乏时则下降8.0%。该评估支持以稳健和一致的结果精确识别模型瓶颈。", "conclusion": "DriveAction基准为推进自动驾驶中类人决策提供了新的见解和严格的基础，并通过其评估框架能够精确识别模型瓶型。", "translation": "视觉-语言-动作（VLA）模型推动了自动驾驶技术的发展，但现有基准仍缺乏场景多样性、可靠的动作级标注以及与人类偏好一致的评估协议。为了解决这些局限性，我们引入了DriveAction，这是首个专门为VLA模型设计的以动作为驱动的基准，包含从2,610个驾驶场景中生成的16,185个问答对。DriveAction利用生产级自动驾驶汽车用户主动收集的真实世界驾驶数据，以确保广泛且具代表性的场景覆盖；它提供直接从用户实际驾驶操作中收集的高级离散动作标签；并实施了一个明确连接视觉、语言和动作任务的以动作根植的树状评估框架，支持全面和任务特定的评估。我们的实验表明，最先进的视觉-语言模型（VLMs）需要视觉和语言指导才能准确预测动作：平均而言，没有视觉输入时准确率下降3.3%，没有语言输入时下降4.1%，而两者都缺乏时则下降8.0%。我们的评估支持以稳健和一致的结果精确识别模型瓶颈，从而为推进自动驾驶中类人决策提供了新的见解和严格的基础。", "summary": "本论文介绍了DriveAction，一个针对视觉-语言-动作（VLA）模型的全新以动作为驱动的基准，旨在解决现有自动驾驶基准在场景多样性、动作标注和评估协议方面的不足。DriveAction包含大量基于真实世界驾驶数据的问答对，并提供高级离散动作标签及树状评估框架。实验结果强调，VLMs在进行准确动作预测时，视觉和语言输入都至关重要，且该基准能有效识别模型瓶颈，为发展类人驾驶决策提供支持。", "keywords": "DriveAction, VLA模型, 自动驾驶, 基准, 类人决策", "comments": "DriveAction的创新之处在于它直接解决了现有VLA模型基准的几个关键缺陷，特别是通过利用生产级自动驾驶汽车用户的真实世界数据来确保场景的广泛代表性，并引入了以动作为驱动的树状评估框架，这对于精确诊断模型在视觉、语言和动作任务上的性能瓶颈至关重要。这项工作为推动自动驾驶领域中更接近人类决策的VLA模型发展奠定了坚实的基础，具有重要的实践意义。"}}
{"id": "2506.05736", "title": "Generalized Incremental Learning under Concept Drift across Evolving Data Streams", "authors": ["En Yu", "Jie Lu", "Guangquan Zhang"], "summary": "Real-world data streams exhibit inherent non-stationarity characterized by\nconcept drift, posing significant challenges for adaptive learning systems.\nWhile existing methods address isolated distribution shifts, they overlook the\ncritical co-evolution of label spaces and distributions under limited\nsupervision and persistent uncertainty. To address this, we formalize\nGeneralized Incremental Learning under Concept Drift (GILCD), characterizing\nthe joint evolution of distributions and label spaces in open-environment\nstreaming contexts, and propose a novel framework called Calibrated Source-Free\nAdaptation (CSFA). First, CSFA introduces a training-free prototype calibration\nmechanism that dynamically fuses emerging prototypes with base representations,\nenabling stable new-class identification without optimization overhead. Second,\nwe design a novel source-free adaptation algorithm, i.e., Reliable Surrogate\nGap Sharpness-aware (RSGS) minimization. It integrates sharpness-aware\nperturbation loss optimization with surrogate gap minimization, while employing\nentropy-based uncertainty filtering to discard unreliable samples. This\nmechanism ensures robust distribution alignment and mitigates generalization\ndegradation caused by uncertainties. Therefore, CSFA establishes a unified\nframework for stable adaptation to evolving semantics and distributions in\nopen-world streaming scenarios. Extensive experiments validate the superior\nperformance and effectiveness of CSFA compared to state-of-the-art approaches.", "comment": "This work has been submitted to the IEEE for possible publication", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05736v1", "AI": {"title_translation": "演化数据流中概念漂移下的广义增量学习", "tldr": "本论文提出了CSFA，一个在演化数据流中处理概念漂移下的广义增量学习的新框架。它通过原型校准和无源自适应算法解决了标签空间和分布的共同演化问题，并表现出卓越的性能。", "motivation": "现有方法在处理概念漂移时，忽略了在有限监督和持续不确定性下，真实世界非平稳数据流中标签空间和分布的关键共同演化问题。", "method": "本研究提出了“校准无源自适应”（Calibrated Source-Free Adaptation, CSFA）框架。首先，CSFA引入了一种无需训练的原型校准机制，该机制能动态地将新兴原型与基本表示融合，从而在没有优化开销的情况下实现稳定的新类别识别。其次，设计了一种新颖的无源自适应算法，即“可靠替代间隙锐度感知”（Reliable Surrogate Gap Sharpness-aware, RSGS）最小化。它将锐度感知扰动损失优化与替代间隙最小化相结合，同时采用基于熵的不确定性过滤来剔除不可靠样本。", "result": "广泛的实验验证了CSFA与现有最先进方法相比，具有卓越的性能和有效性。", "conclusion": "CSFA为在开放世界流场景中稳定适应不断演变的语义和分布建立了一个统一的框架。", "translation": "现实世界的数据流表现出固有的非平稳性，其特征是概念漂移，这对自适应学习系统提出了重大挑战。尽管现有方法解决了孤立的分布偏移，但它们忽视了在有限监督和持续不确定性下标签空间和分布的关键共同演化。为了解决这个问题，我们形式化了概念漂移下的广义增量学习（GILCD），表征了开放环境流上下文中分布和标签空间的联合演化，并提出了一个名为“校准无源自适应”（Calibrated Source-Free Adaptation, CSFA）的新颖框架。首先，CSFA引入了一种无需训练的原型校准机制，该机制能动态地将新兴原型与基本表示融合，从而在没有优化开销的情况下实现稳定的新类别识别。其次，我们设计了一种新颖的无源自适应算法，即“可靠替代间隙锐度感知”（RSGS）最小化。它将锐度感知扰动损失优化与替代间隙最小化相结合，同时采用基于熵的不确定性过滤来剔除不可靠样本。这种机制确保了鲁棒的分布对齐，并减轻了由不确定性引起的泛化性能下降。因此，CSFA为在开放世界流场景中稳定适应不断演变的语义和分布建立了一个统一的框架。广泛的实验验证了CSFA与现有最先进方法相比，具有卓越的性能和有效性。", "summary": "针对现实世界数据流中概念漂移下标签空间和分布共同演化的挑战，本论文形式化了概念漂移下的广义增量学习（GILCD）问题，并提出了“校准无源自适应”（CSFA）框架。CSFA通过引入无需训练的原型校准机制实现新类别识别，并设计了“可靠替代间隙锐度感知”（RSGS）最小化算法，结合锐度感知损失和不确定性过滤，以实现鲁棒的分布对齐。实验证明CSFA在开放世界流场景中能有效且稳定地适应演变的语义和分布，性能优于现有方法。", "keywords": "广义增量学习, 概念漂移, 数据流, 无源自适应, 原型校准", "comments": "该论文的创新之处在于首次形式化了概念漂移下的广义增量学习（GILCD）问题，并提出了CSFA框架来解决标签空间和分布的共同演化问题。其提出的无需训练的原型校准机制和RSGS最小化算法是重要的技术贡献，有望提高增量学习系统在动态环境中的适应性和鲁棒性。"}}
{"id": "2506.05689", "title": "Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models", "authors": ["Hugues Thomas", "Chen Chen", "Jian Zhang"], "summary": "Effectively representing 3D scenes for Multimodal Large Language Models\n(MLLMs) is crucial yet challenging. Existing approaches commonly only rely on\n2D image features and use varied tokenization approaches. This work presents a\nrigorous study of 3D token structures, systematically comparing video-based and\npoint-based representations while maintaining consistent model backbones and\nparameters. We propose a novel approach that enriches visual tokens by\nincorporating 3D point cloud features from a Sonata pretrained Point\nTransformer V3 encoder. Our experiments demonstrate that merging explicit 3D\nfeatures significantly boosts performance. Furthermore, we show that\npoint-based token structures can rival video-based ones when the points are\ncleverly sampled and ordered. Our best models from both structures achieve\nstate-of-the-art results on multiple 3D understanding benchmarks. We emphasize\nour analysis of token structures as a key contribution, alongside transparent\nreporting of results averaged over multiple seeds, a practice we believe is\nvital for robust progress in the field.", "comment": "Main paper and appendix", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05689v1", "AI": {"title_translation": "Pts3D-LLM：研究令牌结构对大型语言模型3D场景理解的影响", "tldr": "Pts3D-LLM系统研究了3D令牌结构对多模态大语言模型3D场景理解的影响，发现融合3D点云特征能显著提升性能，且点基令牌结构在巧妙采样和排序下可媲美视频基结构，并取得SOTA结果。", "motivation": "有效地表示3D场景对于多模态大语言模型(MLLMs)至关重要但具有挑战性。现有方法通常只依赖2D图像特征并使用不同的token化方法。", "method": "本文对3D令牌结构进行了严格研究，系统地比较了基于视频和基于点的表示，同时保持了模型骨干和参数的一致性。提出了一种新方法，通过结合来自Sonata预训练的Point Transformer V3编码器的3D点云特征来丰富视觉令牌。", "result": "实验表明，融合显式3D特征显著提升了性能。此外，当点被巧妙地采样和排序时，基于点的令牌结构可以与基于视频的结构相媲美。两种结构中最好的模型在多个3D理解基准上都取得了最先进的结果。", "conclusion": "对令牌结构的分析是关键贡献，同时透明地报告了多次平均的结果，这对于该领域的稳健进展至关重要。融合3D点云特征和优化点基令牌结构可以显著提升MLLM在3D场景理解方面的性能。", "translation": "有效地表示多模态大型语言模型（MLLMs）的3D场景至关重要但具有挑战性。现有方法通常仅依赖2D图像特征并使用各种令牌化方法。这项工作对3D令牌结构进行了严格研究，系统地比较了基于视频和基于点的表示，同时保持了模型骨干和参数的一致性。我们提出了一种新颖的方法，通过结合来自Sonata预训练的Point Transformer V3编码器的3D点云特征来丰富视觉令牌。我们的实验表明，合并显式3D特征显著提升了性能。此外，我们证明，当点被巧妙地采样和排序时，基于点的令牌结构可以与基于视频的结构相媲美。我们来自两种结构的最佳模型在多个3D理解基准上取得了最先进的结果。我们强调我们对令牌结构的分析是一项关键贡献，同时透明地报告了在多个种子下平均的结果，我们认为这种做法对于该领域的稳健进展至关重要。", "summary": "本文针对多模态大语言模型（MLLMs）中3D场景表示的挑战，系统研究了3D令牌结构的影响。通过比较视频基和点基表示，并引入一种新方法，将3D点云特征融入视觉令牌。实验证明，显式3D特征的融合显著提升了性能，且优化后的点基令牌结构可与视频基结构媲美，最终模型在多个3D理解基准上取得了最先进的结果。", "keywords": "3D场景理解, 大语言模型, 令牌结构, 点云特征, 多模态", "comments": "该研究通过系统比较和引入3D点云特征，为MLLM在3D场景理解方面的令牌结构提供了深入分析，是该领域的重要进展。透明的结果报告也值得称赞。"}}
{"id": "2506.05748", "title": "Efficient Online RFT with Plug-and-Play LLM Judges: Unlocking State-of-the-Art Performance", "authors": ["Rudransh Agnihotri", "Ananya Pandey"], "summary": "Reward-model training is the cost bottleneck in modern Reinforcement Learning\nHuman Feedback (RLHF) pipelines, often requiring tens of billions of parameters\nand an offline preference-tuning phase. In the proposed method, a frozen,\ninstruction-tuned 7B LLM is augmented with only a one line JSON rubric and a\nrank-16 LoRA adapter (affecting just 0.8% of the model's parameters), enabling\nit to serve as a complete substitute for the previously used heavyweight\nevaluation models. The plug-and-play judge achieves 96.2% accuracy on\nRewardBench, outperforming specialized reward networks ranging from 27B to 70B\nparameters. Additionally, it allows a 7B actor to outperform the top 70B DPO\nbaseline, which scores 61.8%, by achieving 92% exact match accuracy on GSM-8K\nutilizing online PPO. Thorough ablations indicate that (i) six in context\ndemonstrations deliver the majority of the zero-to-few-shot improvements\n(+2pp), and (ii) the LoRA effectively addresses the remaining disparity,\nparticularly in the safety and adversarial Chat-Hard segments. The proposed\nmodel introduces HH-Rationales, a subset of 10,000 pairs from Anthropic\nHH-RLHF, to examine interpretability, accompanied by human generated\njustifications. GPT-4 scoring indicates that our LoRA judge attains\napproximately = 9/10 in similarity to human explanations, while zero-shot\njudges score around =5/10. These results indicate that the combination of\nprompt engineering and tiny LoRA produces a cost effective, transparent, and\neasily adjustable reward function, removing the offline phase while achieving\nnew state-of-the-art outcomes for both static evaluation and online RLHF.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05748v1", "AI": {"title_translation": "即插即用LLM判官的在线高效RFT：解锁最先进性能", "tldr": "本文提出了一种使用小型LoRA适配器增强的冻结LLM作为奖励模型，替代了大型评估模型，显著降低了RLHF的成本瓶颈，并实现了最先进的性能。", "motivation": "现代强化学习人类反馈（RLHF）管线中，奖励模型训练是成本瓶颈，通常需要数百亿参数和离线偏好调整阶段。", "method": "本文提出了一种方法，用一行JSON规则和一个rank-16 LoRA适配器（仅影响模型参数的0.8%）来增强一个冻结的、指令调整的7B LLM，使其能够完全替代之前使用的重量级评估模型。该方法支持在线PPO。", "result": "即插即用判官在RewardBench上达到96.2%的准确率，优于27B到70B参数的专用奖励网络。一个7B的Actor在使用在线PPO的情况下，在GSM-8K上实现了92%的精确匹配准确率，超越了得分为61.8%的顶级70B DPO基线。消融实验表明，六个上下文示例提供了大部分零样本到少样本改进（+2pp），LoRA有效解决了剩余差异，尤其是在安全和对抗性Chat-Hard部分。本文引入了HH-Rationales（来自Anthropic HH-RLHF的10,000对子集）来检查可解释性，并附带人类生成的理由。GPT-4评分显示，LoRA判官与人类解释的相似度约为9/10，而零样本判官的得分约为5/10。", "conclusion": "提示工程和小型LoRA的结合产生了成本效益高、透明且易于调整的奖励函数，消除了离线阶段，并在静态评估和在线RLHF方面都取得了新的最先进成果。", "translation": "奖励模型训练是现代强化学习人类反馈（RLHF）管线中的成本瓶颈，通常需要数百亿参数和离线偏好调整阶段。在所提出的方法中，一个冻结的、指令调整的7B LLM仅通过一行JSON规则和一个rank-16 LoRA适配器（仅影响模型参数的0.8%）进行增强，使其能够完全替代先前使用的重量级评估模型。该即插即用判官在RewardBench上实现了96.2%的准确率，超越了参数范围从27B到70B的专用奖励网络。此外，它允许一个7B的Actor通过利用在线PPO在GSM-8K上实现92%的精确匹配准确率，超越了得分61.8%的顶级70B DPO基线。彻底的消融实验表明，(i) 六个上下文示例提供了大部分零样本到少样本改进（+2pp），(ii) LoRA有效解决了剩余差异，特别是在安全和对抗性Chat-Hard部分。所提出的模型引入了HH-Rationales，它是Anthropic HH-RLHF中10,000对的子集，用于检查可解释性，并附带了人类生成的理由。GPT-4评分表明，我们的LoRA判官在与人类解释的相似度上达到了约9/10，而零样本判官的得分约为5/10。这些结果表明，提示工程和小型LoRA的结合产生了一种成本效益高、透明且易于调整的奖励函数，消除了离线阶段，同时为静态评估和在线RLHF实现了新的最先进成果。", "summary": "本文提出了一种高效的在线奖励函数训练（RFT）方法，通过将一个冻结的7B指令调整大型语言模型（LLM）与一行JSON规则和一个微小的rank-16 LoRA适配器结合，使其能够作为即插即用的奖励模型。该方法旨在解决RLHF中奖励模型训练的成本瓶颈。实验结果表明，该轻量级判官在RewardBench上实现了96.2%的准确率，超越了参数量更大的专用奖励网络。此外，它使一个7B的Actor在使用在线PPO时，在GSM-8K上取得了92%的精确匹配准确率，优于70B DPO基线。研究还发现，上下文示例和LoRA适配器对性能提升至关重要。通过引入HH-Rationales并进行可解释性分析，发现LoRA判官的解释与人类解释高度相似。这表明该方法提供了一种成本效益高、透明且可调整的奖励函数，实现了RLHF领域的最新性能。", "keywords": "RLHF, 奖励模型, LLM判官, LoRA, 在线RFT", "comments": "本文的创新点在于使用一个极小的LoRA适配器（仅0.8%的参数）来增强一个冻结的7B LLM，使其能够作为高性能的奖励模型，从而显著降低了RLHF的训练成本和复杂性。其重要性体现在实现了成本效益高、透明且易于调整的奖励函数，打破了大型奖励模型的需求瓶颈，并为在线RLHF带来了最先进的性能。"}}
{"id": "2506.05696", "title": "MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory", "authors": ["Ana Carolina Condez", "Diogo Tavares", "João Magalhães"], "summary": "Recent advances in vision-language models have enabled rich semantic\nunderstanding across modalities. However, these encoding methods lack the\nability to interpret or reason about the moral dimensions of content-a crucial\naspect of human cognition. In this paper, we address this gap by introducing\nMoralCLIP, a novel embedding representation method that extends multimodal\nlearning with explicit moral grounding based on Moral Foundations Theory (MFT).\nOur approach integrates visual and textual moral cues into a unified embedding\nspace, enabling cross-modal moral alignment. MoralCLIP is grounded on the\nmulti-label dataset Social-Moral Image Database to identify co-occurring moral\nfoundations in visual content. For MoralCLIP training, we design a moral data\naugmentation strategy to scale our annotated dataset to 15,000 image-text pairs\nlabeled with MFT-aligned dimensions. Our results demonstrate that explicit\nmoral supervision improves both unimodal and multimodal understanding of moral\ncontent, establishing a foundation for morally-aware AI systems capable of\nrecognizing and aligning with human moral values.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05696v1", "AI": {"title_translation": "MoralCLIP：基于道德基础理论的视觉-语言表征对比对齐", "tldr": "MoralCLIP通过将视觉-语言模型与道德基础理论明确结合，扩展了其道德理解能力，并展示了对道德内容的更好理解。", "motivation": "最近的视觉-语言模型缺乏解释或推理内容道德维度的能力，而这是人类认知的一个关键方面。本文旨在解决这一空白。", "method": "本文引入了MoralCLIP，这是一种新颖的嵌入表示方法，它通过基于道德基础理论（MFT）的明确道德基础来扩展多模态学习。该方法将视觉和文本道德线索整合到一个统一的嵌入空间中，从而实现跨模态道德对齐。MoralCLIP以多标签数据集Social-Moral Image Database为基础，用于识别视觉内容中同时出现的道德基础。对于MoralCLIP的训练，作者设计了一种道德数据增强策略，将标注数据集扩展到15,000个带有MFT对齐维度标签的图像-文本对。", "result": "明确的道德监督提高了对道德内容的单模态和多模态理解。", "conclusion": "本研究为能够识别并与人类道德价值观对齐的具备道德意识的AI系统奠定了基础。", "translation": "视觉-语言模型的最新进展使得跨模态的丰富语义理解成为可能。然而，这些编码方法缺乏解释或推理内容道德维度的能力——这是人类认知的一个关键方面。在本文中，我们通过引入MoralCLIP来解决这一空白，这是一种新颖的嵌入表示方法，它通过基于道德基础理论（MFT）的明确道德基础来扩展多模态学习。我们的方法将视觉和文本道德线索整合到一个统一的嵌入空间中，从而实现跨模态道德对齐。MoralCLIP以多标签数据集Social-Moral Image Database为基础，用于识别视觉内容中同时出现的道德基础。对于MoralCLIP的训练，我们设计了一种道德数据增强策略，将我们的标注数据集扩展到15,000个带有MFT对齐维度标签的图像-文本对。我们的结果表明，明确的道德监督提高了对道德内容的单模态和多模态理解，为能够识别并与人类道德价值观对齐的具备道德意识的AI系统奠定了基础。", "summary": "本文介绍了MoralCLIP，这是一种新型视觉-语言模型，通过将其明确地建立在道德基础理论（MFT）之上，从而融入了道德理解能力。它通过将视觉和文本道德线索整合到一个统一的嵌入空间中，解决了现有模型在道德推理方面的不足。训练利用了一个扩展至15,000个图像-文本对（带有MFT对齐标签）的数据集。结果表明，明确的道德监督增强了对道德内容的单模态和多模态理解，为能够与人类道德价值观对齐的AI系统奠定了基础。", "keywords": "MoralCLIP, 视觉-语言模型, 道德基础理论, 多模态学习, 人工智能伦理", "comments": "本文解决了AI研究中一个关键且新兴的领域：将道德理解融入AI系统。道德基础理论的使用为定义道德维度提供了一个结构化框架。专门数据集的创建和数据增强策略是推动该领域研究的关键贡献。这项工作在通过明确的道德基础扩展多模态学习方面具有创新性，这对于开发具有道德意识的AI至关重要。"}}
{"id": "2506.05752", "title": "Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting", "authors": ["Zhongying Wang", "Thoai D. Ngo", "Hamidreza Zoraghein", "Benjamin Lucas", "Morteza Karimzadeh"], "summary": "The COVID-19 pandemic's severe impact highlighted the need for accurate,\ntimely hospitalization forecasting to support effective healthcare planning.\nHowever, most forecasting models struggled, especially during variant surges,\nwhen they were needed most. This study introduces a novel Long Short-Term\nMemory (LSTM) framework for forecasting daily state-level incident\nhospitalizations in the United States. We present a spatiotemporal feature,\nSocial Proximity to Hospitalizations (SPH), derived from Facebook's Social\nConnectedness Index to improve forecasts. SPH serves as a proxy for interstate\npopulation interaction, capturing transmission dynamics across space and time.\nOur parallel LSTM architecture captures both short- and long-term temporal\ndependencies, and our multi-horizon ensembling strategy balances consistency\nand forecasting error. Evaluation against COVID-19 Forecast Hub ensemble models\nduring the Delta and Omicron surges reveals superiority of our model. On\naverage, our model surpasses the ensemble by 27, 42, 54, and 69\nhospitalizations per state on the $7^{th}$, $14^{th}$, $21^{st}$, and $28^{th}$\nforecast days, respectively, during the Omicron surge. Data-ablation\nexperiments confirm SPH's predictive power, highlighting its effectiveness in\nenhancing forecasting models. This research not only advances hospitalization\nforecasting but also underscores the significance of spatiotemporal features,\nsuch as SPH, in refining predictive performance in modeling the complex\ndynamics of infectious disease spread.", "comment": "36 pages, 12 figures. This is the accepted version of the article\n  published in International Journal of Geographical Information Science. DOI\n  will be added upon publication", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05752v1", "AI": {"title_translation": "将时空特征整合到LSTM中用于空间知情的COVID-19住院预测", "tldr": "本研究提出了一种新的LSTM框架，通过引入社会与住院距离（SPH）时空特征来提高美国COVID-19住院预测的准确性，并在Delta和Omicron变种浪潮期间表现优于现有模型。", "motivation": "COVID-19大流行期间，准确及时的住院预测对于有效的医疗保健规划至关重要，但大多数预测模型在变种激增期间表现不佳。", "method": "本研究引入了一种新的长短期记忆（LSTM）框架，用于预测美国每日州级COVID-19住院人数。该框架提出了一种时空特征——社会与住院距离（SPH），该特征来源于Facebook的社会连接指数，用作州际人口互动的代理。模型采用并行LSTM架构以捕捉短期和长期时间依赖性，并使用多预测期集成策略来平衡一致性和预测误差。", "result": "在Delta和Omicron变种浪潮期间，该模型与COVID-19预测中心集成模型进行评估。在Omicron浪潮期间，该模型在第7、14、21和28个预测日，平均每州分别超过集成模型27、42、54和69例住院人数。数据消融实验证实了SPH的预测能力及其在增强预测模型方面的有效性。", "conclusion": "本研究不仅推进了住院预测，还强调了时空特征（如SPH）在改进传染病传播复杂动力学建模预测性能方面的重要性。", "translation": "COVID-19大流行造成的严重影响凸显了对准确、及时住院预测的需求，以支持有效的医疗保健规划。然而，大多数预测模型表现不佳，尤其是在变种激增期间，而这正是它们最需要的时候。本研究引入了一种新颖的长短期记忆（LSTM）框架，用于预测美国每日州级COVID-19住院人数。我们提出了一种时空特征——社会与住院距离（SPH），该特征来源于Facebook的社会连接指数，旨在改善预测。SPH作为州际人口互动的代理，捕捉了跨空间和时间的传播动态。我们的并行LSTM架构同时捕捉短期和长期时间依赖性，并且我们的多预测期集成策略平衡了预测的一致性和误差。与COVID-19预测中心集成模型在Delta和Omicron变种浪潮期间的评估表明，我们的模型表现更优。平均而言，在Omicron浪潮期间，我们的模型在第7、14、21和28个预测日，每州分别超过集成模型27、42、54和69例住院人数。数据消融实验证实了SPH的预测能力，突出了其在增强预测模型方面的有效性。这项研究不仅推进了住院预测，还强调了时空特征（如SPH）在改进传染病传播复杂动力学建模预测性能方面的重要性。", "summary": "本研究针对COVID-19住院预测的挑战，提出了一种新的基于LSTM的框架。该框架引入了社会与住院距离（SPH）这一时空特征，利用Facebook的社会连接指数作为州际人口互动的代理，以捕捉疾病传播的时空动态。模型采用并行LSTM架构和多预测期集成策略。实验结果表明，该模型在Delta和Omicron变种激增期间，相比现有集成模型，在预测准确性上表现出显著优势，尤其是在长期预测中。研究强调了SPH等时空特征在提高传染病预测模型性能方面的重要性。", "keywords": "COVID-19预测, LSTM, 时空特征, 住院预测, SPH", "comments": "该论文的创新点在于引入了社会与住院距离（SPH）这一新颖的时空特征，并将其整合到LSTM框架中，有效捕捉了COVID-19传播的复杂动态。其重要性体现在提高了关键时期（如变种激增）的住院预测准确性，为医疗卫生规划提供了更可靠的依据。该方法为未来传染病预测模型的开发提供了有价值的参考，尤其是在考虑人口互动和时空依赖性方面。"}}
{"id": "2506.05709", "title": "Token Transforming: A Unified and Training-Free Token Compression Framework for Vision Transformer Acceleration", "authors": ["Fanhu Zeng", "Deli Yu", "Zhenglun Kong", "Hao Tang"], "summary": "Vision transformers have been widely explored in various vision tasks. Due to\nheavy computational cost, much interest has aroused for compressing vision\ntransformer dynamically in the aspect of tokens. Current methods mainly pay\nattention to token pruning or merging to reduce token numbers, in which tokens\nare compressed exclusively, causing great information loss and therefore\npost-training is inevitably required to recover the performance. In this paper,\nwe rethink token reduction and unify the process as an explicit form of token\nmatrix transformation, in which all existing methods are constructing special\nforms of matrices within the framework. Furthermore, we propose a many-to-many\nToken Transforming framework that serves as a generalization of all existing\nmethods and reserves the most information, even enabling training-free\nacceleration. We conduct extensive experiments to validate our framework.\nSpecifically, we reduce 40% FLOPs and accelerate DeiT-S by $\\times$1.5 with\nmarginal 0.1% accuracy drop. Furthermore, we extend the method to dense\nprediction tasks including segmentation, object detection, depth estimation,\nand language model generation. Results demonstrate that the proposed method\nconsistently achieves substantial improvements, offering a better\ncomputation-performance trade-off, impressive budget reduction and inference\nacceleration.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05709v1", "AI": {"title_translation": "令牌转换：一种统一且免训练的视觉Transformer加速令牌压缩框架", "tldr": "本文提出了一种名为“令牌转换”的统一且免训练的令牌压缩框架，用于加速视觉Transformer，该框架通过令牌矩阵变换保留了更多信息，并实现了显著的计算量减少和推理加速。", "motivation": "现有的视觉Transformer令牌压缩方法（如令牌剪枝或合并）是排他性压缩，导致大量信息丢失，因此不可避免地需要后训练来恢复性能。", "method": "本文将令牌缩减统一为令牌矩阵变换的显式形式，并提出了一种多对多“令牌转换”框架，该框架是现有方法的一种泛化，并保留了最多的信息，甚至可以实现免训练加速。", "result": "在DeiT-S上，FLOPs减少了40%，加速了1.5倍，精度仅下降0.1%。该方法还扩展到密集预测任务（包括分割、目标检测、深度估计）和语言模型生成，并始终实现显著改进，提供了更好的计算-性能权衡、令人印象深刻的预算减少和推理加速。", "conclusion": "所提出的令牌转换方法通过统一令牌压缩过程并保留更多信息，实现了视觉Transformer的免训练加速和显著的性能提升，并在多种视觉和语言任务中表现出色。", "translation": "视觉Transformer已在各种视觉任务中得到广泛探索。由于计算成本高昂，人们对从令牌方面动态压缩视觉Transformer产生了浓厚兴趣。当前方法主要关注令牌剪枝或合并以减少令牌数量，其中令牌被排他性压缩，导致大量信息丢失，因此不可避免地需要后训练来恢复性能。在本文中，我们重新思考了令牌缩减，并将其统一为令牌矩阵变换的显式形式，其中所有现有方法都在该框架内构建特殊形式的矩阵。此外，我们提出了一种多对多“令牌转换”框架，该框架是所有现有方法的一种泛化，并保留了最多的信息，甚至可以实现免训练加速。我们进行了广泛的实验来验证我们的框架。具体而言，我们减少了40%的FLOPs，并将DeiT-S加速了1.5倍，而精度仅下降0.1%。此外，我们将该方法扩展到密集预测任务，包括分割、目标检测、深度估计和语言模型生成。结果表明，所提出的方法始终实现显著改进，提供了更好的计算-性能权衡、令人印象深刻的预算减少和推理加速。", "summary": "本文提出了一种名为“令牌转换”的统一且免训练的令牌压缩框架，旨在解决现有视觉Transformer令牌压缩方法中信息丢失严重导致需要后训练的问题。该框架将令牌缩减统一为令牌矩阵变换，并提供了一种多对多方法，能够保留更多信息，从而实现免训练加速。实验结果表明，该方法在减少FLOPs和加速视觉Transformer方面表现出色，且精度损失极小，并能有效推广到多种视觉密集预测任务和语言模型生成。", "keywords": "令牌压缩, 视觉Transformer, 免训练, 令牌矩阵变换, 加速", "comments": "该论文的创新点在于将令牌压缩统一为令牌矩阵变换，并提出了一个多对多框架，解决了现有方法信息丢失严重的问题，实现了免训练加速。其重要性在于为视觉Transformer的加速提供了一种高效且普适的解决方案，显著提升了计算效率和性能。"}}
{"id": "2506.05762", "title": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning", "authors": ["Yunpeng Qing", "Shuo Chen", "Yixiao Chi", "Shunyu Liu", "Sixu Lin", "Changqing Zou"], "summary": "Recent advances in offline Reinforcement Learning (RL) have proven that\neffective policy learning can benefit from imposing conservative constraints on\npre-collected datasets. However, such static datasets often exhibit\ndistribution bias, resulting in limited generalizability. To address this\nlimitation, a straightforward solution is data augmentation (DA), which\nleverages generative models to enrich data distribution. Despite the promising\nresults, current DA techniques focus solely on reconstructing future\ntrajectories from given states, while ignoring the exploration of history\ntransitions that reach them. This single-direction paradigm inevitably hinders\nthe discovery of diverse behavior patterns, especially those leading to\ncritical states that may have yielded high-reward outcomes. In this work, we\nintroduce Bidirectional Trajectory Diffusion (BiTrajDiff), a novel DA framework\nfor offline RL that models both future and history trajectories from any\nintermediate states. Specifically, we decompose the trajectory generation task\ninto two independent yet complementary diffusion processes: one generating\nforward trajectories to predict future dynamics, and the other generating\nbackward trajectories to trace essential history transitions.BiTrajDiff can\nefficiently leverage critical states as anchors to expand into potentially\nvaluable yet underexplored regions of the state space, thereby facilitating\ndataset diversity. Extensive experiments on the D4RL benchmark suite\ndemonstrate that BiTrajDiff achieves superior performance compared to other\nadvanced DA methods across various offline RL backbones.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05762v1", "AI": {"title_translation": "BiTrajDiff：基于扩散模型的双向轨迹生成用于离线强化学习", "tldr": "BiTrajDiff提出了一种新的双向轨迹生成扩散模型，通过同时建模未来和历史轨迹来增强离线强化学习的数据集多样性，并在D4RL基准测试中表现出色。", "motivation": "现有的离线强化学习数据增强技术只关注从给定状态重建未来轨迹，忽略了到达这些状态的历史转换探索，这限制了发现多样化行为模式的能力，尤其是那些导致高回报关键状态的行为模式。", "method": "本文提出了一种新颖的数据增强框架BiTrajDiff，它将轨迹生成任务分解为两个独立但互补的扩散过程：一个生成前向轨迹以预测未来动态，另一个生成后向轨迹以追踪必要的历史转换。BiTrajDiff利用关键状态作为锚点，扩展到潜在有价值但未充分探索的状态空间区域，从而促进数据集多样性。", "result": "在D4RL基准测试套件上的大量实验表明，BiTrajDiff在各种离线强化学习骨干网络上都优于其他先进的数据增强方法，取得了卓越的性能。", "conclusion": "BiTrajDiff通过引入双向轨迹生成，有效解决了离线强化学习中数据分布偏差和泛化能力受限的问题，显著提升了性能。", "translation": "离线强化学习（RL）的最新进展表明，有效的策略学习可以受益于对预收集数据集施加保守约束。然而，此类静态数据集通常表现出分布偏差，导致泛化能力有限。为了解决这一限制，一个直接的解决方案是数据增强（DA），它利用生成模型来丰富数据分布。尽管取得了有希望的结果，但当前的数据增强技术只专注于从给定状态重建未来轨迹，而忽略了探索到达它们的历史转换。这种单向范式不可避免地阻碍了发现多样化行为模式，尤其是那些可能产生高回报结果的关键状态。在这项工作中，我们引入了双向轨迹扩散（BiTrajDiff），一个用于离线强化学习的新型数据增强框架，它从任何中间状态建模未来和历史轨迹。具体来说，我们将轨迹生成任务分解为两个独立但互补的扩散过程：一个生成前向轨迹以预测未来动态，另一个生成后向轨迹以追踪必要的历史转换。BiTrajDiff可以有效地利用关键状态作为锚点，扩展到潜在有价值但未充分探索的状态空间区域，从而促进数据集多样性。在D4RL基准测试套件上的大量实验表明，BiTrajDiff在各种离线强化学习骨干网络上都优于其他先进的数据增强方法。", "summary": "本文介绍了BiTrajDiff，一种针对离线强化学习的新型数据增强框架。它通过将轨迹生成分解为前向和后向扩散过程，同时建模未来和历史轨迹。这种双向方法旨在克服现有单向数据增强的局限性，增强数据集多样性，并利用关键状态探索未开发的状态空间区域。实验结果表明，BiTrajDiff在D4RL基准测试上优于其他先进的数据增强方法。", "keywords": "离线强化学习, 数据增强, 扩散模型, 双向轨迹生成, BiTrajDiff", "comments": "BiTrajDiff的创新点在于引入了双向轨迹生成，克服了传统单向数据增强在探索多样化行为模式上的不足。通过同时考虑历史和未来轨迹，该方法能够更全面地利用离线数据集中的信息，并有效扩展数据集多样性，这对于解决离线RL的分布偏差问题至关重要。其在D4RL基准上的优越表现证明了其有效性和重要性。"}}
{"id": "2506.05749", "title": "Investigating the Relationship between Weighted Figure of Merit and Rosin's Measure", "authors": ["Bimal Kumar Ray"], "summary": "Many studies had been conducted to solve the problem of approximating a\ndigital boundary by piece straight-line segments for further processing\nrequired in computer vision applications. The authors of these studies compared\ntheir schemes to determine the best one. The initial measure used to assess the\ngoodness of a polygonal approximation was figure of merit. Later, it was\npointed out that this measure was not an appropriate metric for a valid reason\nand this is why Rosin - through mathematical analysis - introduced a measure\ncalled merit. However, this measure involves optimal scheme of polygonal\napproximation and so it is time-consuming to compute it to assess the goodness\nof an approximation. This led many researchers to use weighted figure of merit\nas a substitute for Rosin's measure to compare among sub-optimal schemes. An\nattempt is made in this communication to investigate whether the two measures -\nweighted figure of merit and Rosin's measure - are related so that one can be\nused instead of the other and towards this end theoretical analysis,\nexperimental investigation and statistical analysis are carried out. The\nmathematical formula for weighted figure of merit and Rosin's measure are\nanalyzed and through proof of theorems it is found that the two measures are\nindependent of each other theoretically. The graphical analysis of experiments\ncarried out using public dataset supports theoretical analysis. The statistical\nanalysis using Pearson's correlation coefficient also establishes that the two\nmeasures are uncorrelated. This analysis leads one to conclude that if a\nsub-optimal scheme is found to be better (worse) than some other sub-optimal\nscheme as indicated by Rosin's measure then the same conclusion cannot be drawn\nusing weighted figure of merit and so one cannot use weighted figure of merit\ninstead of Rosin's measure.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05749v1", "AI": {"title_translation": "加权品质因数与罗辛度量之间关系的研究", "tldr": "本研究通过理论、实验和统计分析发现，加权品质因数和罗辛度量是相互独立的，不能互相替代来评估多边形逼近方案。", "motivation": "在计算机视觉应用中，为了评估数字边界的多边形逼近方案，研究人员曾使用品质因数，但后来发现其不合适。罗辛度量被引入，但计算耗时。因此，许多研究人员使用加权品质因数作为罗辛度量的替代品来比较次优方案。本研究的动机是调查这两种度量之间是否存在关系，以便一种可以代替另一种使用。", "method": "本研究进行了理论分析、实验调查和统计分析。具体包括对加权品质因数和罗辛度量的数学公式进行分析，通过定理证明，使用公共数据集进行实验的图形分析，以及使用皮尔逊相关系数进行统计分析。", "result": "理论分析和定理证明发现，这两种度量在理论上是相互独立的。实验的图形分析支持了理论分析。统计分析也表明这两种度量是不相关的。", "conclusion": "如果一个次优方案根据罗辛度量被发现比另一个次优方案更好（或更差），那么使用加权品质因数无法得出相同的结论。因此，不能使用加权品质因数来替代罗辛度量。", "translation": "许多研究致力于解决通过分段直线段逼近数字边界的问题，以满足计算机视觉应用中的进一步处理需求。这些研究的作者比较了他们的方案以确定最佳方案。最初用于评估多边形逼近优劣的度量是品质因数。后来指出，由于一个有效的原因，该度量不是一个合适的指标，这就是为什么罗辛通过数学分析引入了一个名为“优劣度量”的度量。然而，这个度量涉及到多边形逼近的最佳方案，因此计算它来评估逼近的优劣是耗时的。这导致许多研究人员使用加权品质因数作为罗辛度量的替代品来比较次优方案。本次交流尝试调查这两种度量——加权品质因数和罗辛度量——是否相关，以便一种可以替代另一种使用，为此进行了理论分析、实验调查和统计分析。对加权品质因数和罗辛度量的数学公式进行了分析，并通过定理证明发现这两种度量在理论上是相互独立的。使用公共数据集进行的实验的图形分析支持了理论分析。使用皮尔逊相关系数进行的统计分析也证实了这两种度量是不相关的。这项分析使得人们得出结论，如果一个次优方案被罗辛度量指示为比其他次优方案更好（或更差），那么使用加权品质因数无法得出相同的结论，因此不能使用加权品质因数来替代罗辛度量。", "summary": "本研究旨在探究计算机视觉中用于评估数字边界多边形逼近的两种度量——加权品质因数和罗辛度量——之间的关系。鉴于罗辛度量计算复杂，研究人员常以加权品质因数作为其替代。通过理论推导、实验验证和统计分析，本研究发现这两种度量在理论上和实践中均相互独立且不相关。这意味着加权品质因数不能有效替代罗辛度量来评估次优方案的优劣，从而澄清了长期以来在多边形逼近评估领域的一个重要假设。", "keywords": "加权品质因数, 罗辛度量, 多边形逼近, 度量关系, 计算机视觉", "comments": "这篇论文具有重要的实践意义，它纠正了计算机视觉领域中一个普遍存在的误解，即加权品质因数可以替代罗辛度量来评估多边形逼近。通过严谨的理论证明和实验验证，论文明确指出两者是独立的，这对于后续研究选择合适的评估指标具有指导作用。其创新点在于通过多角度分析（理论、实验、统计）彻底解决了这一问题。"}}
{"id": "2506.05764", "title": "Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer", "authors": ["Haochuan", "Wang"], "summary": "Cryptocurrency price dynamics are driven largely by microstructural supply\ndemand imbalances in the limit order book (LOB), yet the highly noisy nature of\nLOB data complicates the signal extraction process. Prior research has\ndemonstrated that deep-learning architectures can yield promising predictive\nperformance on pre-processed equity and futures LOB data, but they often treat\nmodel complexity as an unqualified virtue. In this paper, we aim to examine\nwhether adding extra hidden layers or parameters to \"blackbox ish\" neural\nnetworks genuinely enhances short term price forecasting, or if gains are\nprimarily attributable to data preprocessing and feature engineering. We\nbenchmark a spectrum of models from interpretable baselines, logistic\nregression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT\nLOB snapshots sampled at 100 ms to multi second intervals using publicly\navailable Bybit data. We introduce two data filtering pipelines (Kalman,\nSavitzky Golay) and evaluate both binary (up/down) and ternary (up/flat/down)\nlabeling schemes. Our analysis compares models on out of sample accuracy,\nlatency, and robustness to noise. Results reveal that, with data preprocessing\nand hyperparameter tuning, simpler models can match and even exceed the\nperformance of more complex networks, offering faster inference and greater\ninterpretability.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05764v1", "AI": {"title_translation": "探索加密货币限价订单簿中的微观结构动态：更好的输入比增加隐藏层更重要", "tldr": "研究发现，在加密货币限价订单簿价格预测中，数据预处理和特征工程比增加神经网络的复杂性更重要，简单模型在预处理后能达到甚至超越复杂模型的性能。", "motivation": "现有研究表明深度学习在LOB数据上表现良好，但往往过分强调模型复杂性。本文旨在探究增加神经网络隐藏层或参数是否真正增强了短期价格预测，还是主要归因于数据预处理和特征工程。", "method": "本文基准测试了一系列模型，包括可解释的基线模型、逻辑回归、XGBoost和深度架构（DeepLOB, Conv1D+LSTM），在以100毫秒到多秒间隔采样的BTC/USDT限价订单簿快照上，并使用公开可用的Bybit数据。研究引入了两种数据过滤管道（Kalman, Savitzky Golay），并评估了二元（上涨/下跌）和三元（上涨/持平/下跌）标签方案。分析比较了模型在样本外准确性、延迟和对噪声的鲁棒性。", "result": "结果表明，通过数据预处理和超参数调优，更简单的模型可以匹配甚至超越更复杂网络的性能，同时提供更快的推理速度和更大的可解释性。", "conclusion": "数据预处理和特征工程对于加密货币限价订单簿的短期价格预测至关重要，其重要性超过了单纯增加模型复杂性，简单模型经过优化后能表现出色。", "translation": "加密货币的价格动态在很大程度上是由限价订单簿（LOB）中微观结构供需失衡驱动的，然而LOB数据的高度噪声性质使信号提取过程复杂化。先前的研究表明，深度学习架构可以在预处理的股票和期货LOB数据上产生有前景的预测性能，但它们通常将模型复杂性视为一种无条件的优点。在本文中，我们旨在检验向“黑箱式”神经网络添加额外的隐藏层或参数是否真正增强了短期价格预测，或者收益是否主要归因于数据预处理和特征工程。我们基准测试了一系列模型，从可解释的基线模型、逻辑回归、XGBoost到深度架构（DeepLOB, Conv1D+LSTM），在以100毫秒到多秒间隔采样的BTC/USDT LOB快照上，使用公开可用的Bybit数据。我们引入了两种数据过滤管道（Kalman, Savitzky Golay），并评估了二元（上涨/下跌）和三元（上涨/持平/下跌）标签方案。我们的分析比较了模型在样本外准确性、延迟和对噪声的鲁棒性。结果表明，通过数据预处理和超参数调优，更简单的模型可以匹配甚至超越更复杂网络的性能，提供更快的推理速度和更大的可解释性。", "summary": "本文探讨了加密货币限价订单簿（LOB）中微观结构动态对价格预测的影响。研究旨在评估在短期价格预测中，数据预处理和特征工程是否比增加神经网络复杂性更重要。通过在BTC/USDT LOB数据上对包括简单模型和深度学习模型进行基准测试，并引入数据过滤管道，结果表明，经过充分预处理和调优后，简单模型在性能上可以与复杂模型媲美甚至超越，同时具有更快的推理速度和更好的可解释性。", "keywords": "加密货币, 限价订单簿, 价格预测, 数据预处理, 深度学习", "comments": "这项研究挑战了深度学习领域中普遍存在的“模型越复杂越好”的观念，强调了数据质量和特征工程在处理高噪声金融时间序列数据（如限价订单簿）中的核心作用。其发现对于资源有限或需要低延迟预测的实际应用具有重要指导意义，鼓励研究者和实践者在追求复杂模型之前，优先关注数据输入的优化。"}}
{"id": "2506.05763", "title": "Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking", "authors": ["Puntawat Ponglertnapakorn", "Supasorn Suwajanakorn"], "summary": "We present a method for 3D ball trajectory estimation from a 2D tracking\nsequence. To overcome the ambiguity in 3D from 2D estimation, we design an\nLSTM-based pipeline that utilizes a novel canonical 3D representation that is\nindependent of the camera's location to handle arbitrary views and a series of\nintermediate representations that encourage crucial invariance and reprojection\nconsistency. We evaluated our method on four synthetic and three real datasets\nand conducted extensive ablation studies on our design choices. Despite\ntraining solely on simulated data, our method achieves state-of-the-art\nperformance and can generalize to real-world scenarios with multiple\ntrajectories, opening up a range of applications in sport analysis and virtual\nreplay. Please visit our page: https://where-is-the-ball.github.io.", "comment": "11th International Workshop on Computer Vision in Sports (CVsports)\n  at CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05763v1", "AI": {"title_translation": "球在哪里：基于2D单目跟踪的3D球体轨迹估计", "tldr": "该论文提出了一种基于LSTM的管道，利用新颖的规范3D表示，从2D单目跟踪序列中估计3D球体轨迹，并在合成和真实数据集上实现了最先进的性能，可泛化到真实世界场景。", "motivation": "克服从2D估计3D时的歧义性，并实现从2D跟踪序列中估计3D球体轨迹。", "method": "设计了一个基于LSTM的管道，该管道利用一种新颖的规范3D表示，该表示独立于摄像机位置以处理任意视图，并使用一系列中间表示来鼓励关键的不变性和重投影一致性。", "result": "在四个合成数据集和三个真实数据集上进行了评估，并进行了广泛的消融研究。尽管仅在模拟数据上进行训练，但该方法实现了最先进的性能，并且可以泛化到具有多个轨迹的真实世界场景。", "conclusion": "该方法在3D球体轨迹估计方面表现出色，即使仅使用模拟数据训练也能泛化到真实世界，为体育分析和虚拟回放等应用提供了可能性。", "translation": "我们提出了一种从2D跟踪序列中估计3D球体轨迹的方法。为了克服从2D估计3D时的歧义性，我们设计了一个基于LSTM的管道，该管道利用一种新颖的规范3D表示，该表示独立于摄像机位置以处理任意视图，并使用一系列中间表示来鼓励关键的不变性和重投影一致性。我们在四个合成数据集和三个真实数据集上评估了我们的方法，并对我们的设计选择进行了广泛的消融研究。尽管仅在模拟数据上进行训练，但我们的方法实现了最先进的性能，并且可以泛化到具有多个轨迹的真实世界场景，从而在体育分析和虚拟回放中开辟了一系列应用。请访问我们的页面：https://where-is-the-ball.github.io。", "summary": "本论文介绍了一种基于LSTM的创新方法，用于从2D单目跟踪数据中精确估计3D球体轨迹。为解决2D到3D转换中的固有模糊性，该方法引入了一种与摄像机位置无关的规范3D表示以及一系列中间表示，以确保不变性和重投影一致性。尽管仅使用模拟数据进行训练，该方法在合成和真实数据集上均展现出最先进的性能，并能有效泛化至真实世界的多轨迹场景，为体育分析和虚拟回放提供了潜在应用。", "keywords": "3D球体轨迹估计, 单目跟踪, LSTM, 规范3D表示, 体育分析", "comments": "该论文的创新点在于其LSTM-based管道和新颖的规范3D表示，解决了2D到3D估计的歧义问题。其重要性在于即使仅在模拟数据上训练也能泛化到真实世界场景，这大大降低了对真实世界标注数据的依赖，并为体育分析和虚拟回放等实际应用提供了强大的工具。该方法的泛化能力是其亮点。"}}
{"id": "2506.05768", "title": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation", "authors": ["Wenyu Zhu", "Jianhui Wang", "Bowen Gao", "Yinjun Jia", "Haichuan Tan", "Ya-Qin Zhang", "Wei-Ying Ma", "Yanyan Lan"], "summary": "Virtual screening (VS) is a critical component of modern drug discovery, yet\nmost existing methods--whether physics-based or deep learning-based--are\ndeveloped around holo protein structures with known ligand-bound pockets.\nConsequently, their performance degrades significantly on apo or predicted\nstructures such as those from AlphaFold2, which are more representative of\nreal-world early-stage drug discovery, where pocket information is often\nmissing. In this paper, we introduce an alignment-and-aggregation framework to\nenable accurate virtual screening under structural uncertainty. Our method\ncomprises two core components: (1) a tri-modal contrastive learning module that\naligns representations of the ligand, the holo pocket, and cavities detected\nfrom structures, thereby enhancing robustness to pocket localization error; and\n(2) a cross-attention based adapter for dynamically aggregating candidate\nbinding sites, enabling the model to learn from activity data even without\nprecise pocket annotations. We evaluated our method on a newly curated\nbenchmark of apo structures, where it significantly outperforms\nstate-of-the-art methods in blind apo setting, improving the early enrichment\nfactor (EF1%) from 11.75 to 37.19. Notably, it also maintains strong\nperformance on holo structures. These results demonstrate the promise of our\napproach in advancing first-in-class drug discovery, particularly in scenarios\nlacking experimentally resolved protein-ligand complexes.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05768v1", "AI": {"title_translation": "AANet: 通过对齐和聚合在结构不确定性下的虚拟筛选", "tldr": "AANet提出一个对齐聚合框架，显著提高了在结构不确定性（如非全息或预测结构）下虚拟筛选的性能，对早期药物发现至关重要。", "motivation": "现有的虚拟筛选方法在缺乏已知配体结合口袋信息的非全息（apo）或预测结构（如AlphaFold2）上表现显著下降，而这些结构在早期药物发现阶段更具代表性，通常缺少口袋信息。", "method": "本文引入了一个对齐和聚合框架AANet，以实现在结构不确定性下的精确虚拟筛选。该方法包含两个核心组件：1) 一个三模态对比学习模块，用于对齐配体、全息口袋和从结构中检测到的腔体的表示，从而增强对口袋定位误差的鲁棒性；2) 一个基于交叉注意力的适配器，用于动态聚合候选结合位点，使模型即使没有精确的口袋注释也能从活性数据中学习。", "result": "在专门整理的非全息结构基准测试中，AANet在盲非全息设置下显著优于最先进的方法，早期富集因子（EF1%）从11.75提高到37.19。值得注意的是，它在全息结构上也能保持强大的性能。", "conclusion": "这些结果表明，AANet方法在推进首创药物发现方面前景广阔，尤其是在缺乏实验解析的蛋白质-配体复合物的场景中。", "translation": "虚拟筛选（VS）是现代药物发现的关键组成部分，然而大多数现有方法——无论是基于物理的还是基于深度学习的——都是围绕具有已知配体结合口袋的全息蛋白结构开发的。因此，它们在非全息或预测结构（例如来自AlphaFold2的结构）上的性能显著下降，而这些结构更能代表现实世界的早期药物发现，其中口袋信息通常缺失。在本文中，我们引入了一个对齐和聚合框架，以实现在结构不确定性下的精确虚拟筛选。我们的方法包括两个核心组件：(1) 一个三模态对比学习模块，用于对齐配体、全息口袋和从结构中检测到的腔体的表示，从而增强对口袋定位误差的鲁棒性；(2) 一个基于交叉注意力的适配器，用于动态聚合候选结合位点，使模型即使没有精确的口袋注释也能从活性数据中学习。我们在新整理的非全息结构基准上评估了我们的方法，在盲非全息设置下，它显著优于最先进的方法，将早期富集因子（EF1%）从11.75提高到37.19。值得注意的是，它在全息结构上也能保持强大的性能。这些结果表明，我们的方法在推进首创药物发现方面前景广阔，尤其是在缺乏实验解析的蛋白质-配体复合物的场景中。", "summary": "AANet提出一种对齐和聚合框架，旨在解决现有虚拟筛选方法在结构不确定性下（如非全息或预测结构）性能下降的问题。该方法通过三模态对比学习增强对口袋定位误差的鲁棒性，并通过基于交叉注意力的适配器动态聚合结合位点，即使无精确口袋注释也能从活性数据中学习。实验证明，AANet在非全息结构上显著优于现有方法，并在全息结构上保持良好性能，对缺乏实验解析复合物的早期药物发现具有重要意义。", "keywords": "虚拟筛选, 结构不确定性, 对齐聚合, 早期药物发现, AANet", "comments": "该论文的创新之处在于其提出的AANet框架，有效解决了早期药物发现中，尤其是在缺乏明确结合口袋信息时，虚拟筛选面临的结构不确定性挑战。其三模态对比学习和交叉注意力适配器设计，使其能够从不精确的结构信息中学习，并显著提升了在非全息结构上的筛选性能，这对于加速首创药物的发现具有重要实践意义。"}}
{"id": "2506.05765", "title": "Do Large Vision-Language Models Distinguish between the Actual and Apparent Features of Illusions?", "authors": ["Taiga Shinozaki", "Tomoki Doi", "Satoshi Nishida", "Hitomi Yanaka"], "summary": "Humans are susceptible to optical illusions, which serve as valuable tools\nfor investigating sensory and cognitive processes. Inspired by human vision\nstudies, research has begun exploring whether machines, such as large vision\nlanguage models (LVLMs), exhibit similar susceptibilities to visual illusions.\nHowever, studies often have used non-abstract images and have not distinguished\nactual and apparent features, leading to ambiguous assessments of machine\ncognition. To address these limitations, we introduce a visual question\nanswering (VQA) dataset, categorized into genuine and fake illusions, along\nwith corresponding control images. Genuine illusions present discrepancies\nbetween actual and apparent features, whereas fake illusions have the same\nactual and apparent features even though they look illusory due to the similar\ngeometric configuration. We evaluate the performance of LVLMs for genuine and\nfake illusion VQA tasks and investigate whether the models discern actual and\napparent features. Our findings indicate that although LVLMs may appear to\nrecognize illusions by correctly answering questions about both feature types,\nthey predict the same answers for both Genuine Illusion and Fake Illusion VQA\nquestions. This suggests that their responses might be based on prior knowledge\nof illusions rather than genuine visual understanding. The dataset is available\nat https://github.com/ynklab/FILM", "comment": "To appear in the Proceedings of the 47th Annual Meeting of the\n  Cognitive Science Society (COGSCI 2025)", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05765v1", "AI": {"title_translation": "大型视觉-语言模型能否区分错觉的实际特征和表观特征？", "tldr": "大型视觉-语言模型（LVLMs）在回答错觉问题时，可能依赖于对错觉的先验知识而非真正的视觉理解，因为它们对真实错觉和虚假错觉的回答相同。", "motivation": "现有研究在评估大型视觉-语言模型（LVLMs）对视觉错觉的感知能力时，常使用非抽象图像且未能区分实际特征和表观特征，导致评估结果模糊。本文旨在解决这些局限性。", "method": "本文引入了一个视觉问答（VQA）数据集，该数据集分为真实错觉和虚假错觉两类，并包含相应的对照图像。真实错觉中实际特征与表观特征存在差异，而虚假错觉的实际特征和表观特征相同，但由于几何配置相似而看起来像错觉。研究评估了LVLMs在真实错觉和虚假错觉VQA任务上的表现，并调查了模型是否能区分实际特征和表观特征。", "result": "研究结果表明，尽管LVLMs通过正确回答两种特征类型的问题可能看起来识别了错觉，但它们对真实错觉和虚假错觉VQA问题给出了相同的答案。", "conclusion": "这表明LVLMs的反应可能基于对错觉的先验知识，而非真正的视觉理解。", "translation": "人类容易受到光学错觉的影响，光学错觉是研究感觉和认知过程的宝贵工具。受人类视觉研究的启发，研究开始探索机器，如大型视觉-语言模型（LVLMs），是否表现出对视觉错觉的类似敏感性。然而，研究通常使用非抽象图像，并且没有区分实际特征和表观特征，导致对机器认知的评估模糊不清。为了解决这些局限性，我们引入了一个视觉问答（VQA）数据集，该数据集分为真实错觉和虚假错觉，以及相应的对照图像。真实错觉呈现出实际特征和表观特征之间的差异，而虚假错觉虽然由于相似的几何配置看起来像错觉，但其实际特征和表观特征相同。我们评估了LVLMs在真实错觉和虚假错觉VQA任务上的表现，并调查了模型是否能辨别实际特征和表观特征。我们的发现表明，尽管LVLMs通过正确回答关于两种特征类型的问题可能看起来识别了错觉，但它们对真实错觉和虚假错觉VQA问题预测了相同的答案。这表明它们的反应可能基于对错觉的先验知识而非真正的视觉理解。数据集可在https://github.com/ynklab/FILM获取。", "summary": "本研究旨在解决现有大型视觉-语言模型（LVLMs）在评估视觉错觉时未能区分实际与表观特征的局限性。为此，研究构建了一个包含真实错觉和虚假错觉的视觉问答数据集。实验结果显示，LVLMs在面对真实错觉和虚假错觉时给出相同的答案，这暗示它们可能依赖于对错觉的先验知识而非真正的视觉理解。", "keywords": "大型视觉-语言模型, 视觉错觉, 视觉问答, 实际特征, 表观特征", "comments": "这项研究通过引入区分实际特征和表观特征的数据集，为评估LVLMs的视觉理解能力提供了一个更严谨的框架。其创新点在于对“错觉”概念的细致划分（真实与虚假），这有助于更深入地探测模型的认知机制。研究结果对理解当前LVLMs的“理解”深度具有重要意义，揭示了它们可能只是在模式匹配而非真正理解视觉现象。"}}
{"id": "2506.05774", "title": "Evaluating Neuron Explanations: A Unified Framework with Sanity Checks", "authors": ["Tuomas Oikarinen", "Ge Yan", "Tsui-Wei Weng"], "summary": "Understanding the function of individual units in a neural network is an\nimportant building block for mechanistic interpretability. This is often done\nby generating a simple text explanation of the behavior of individual neurons\nor units. For these explanations to be useful, we must understand how reliable\nand truthful they are. In this work we unify many existing explanation\nevaluation methods under one mathematical framework. This allows us to compare\nexisting evaluation metrics, understand the evaluation pipeline with increased\nclarity and apply existing statistical methods on the evaluation. In addition,\nwe propose two simple sanity checks on the evaluation metrics and show that\nmany commonly used metrics fail these tests and do not change their score after\nmassive changes to the concept labels. Based on our experimental and\ntheoretical results, we propose guidelines that future evaluations should\nfollow and identify a set of reliable evaluation metrics.", "comment": "Published at ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05774v1", "AI": {"title_translation": "评估神经元解释：一个统一的框架与健全性检查", "tldr": "本研究统一了神经元解释的评估方法，提出了健全性检查，发现许多现有指标未能通过，并为未来的可靠评估提供了指导方针。", "motivation": "为了使神经网络中单个神经元或单元的文本解释有用，必须了解它们的可靠性和真实性。当前缺乏一个统一的框架来评估这些解释的可靠性和真实性。", "method": "本研究将许多现有的解释评估方法统一到一个数学框架下，以便比较现有评估指标、更清晰地理解评估流程并应用统计方法。此外，论文提出了两个简单的评估指标健全性检查。", "result": "许多常用评估指标未能通过所提出的健全性检查，即使概念标签发生巨大变化，其分数也没有改变。论文基于实验和理论结果，提出了一套未来评估应遵循的指导方针，并确定了一组可靠的评估指标。", "conclusion": "根据实验和理论结果，本研究为未来的神经元解释评估提供了指导方针，并确定了一组可靠的评估指标。", "translation": "理解神经网络中单个单元的功能是机械可解释性的重要组成部分。这通常通过生成单个神经元或单元行为的简单文本解释来完成。为了使这些解释有用，我们必须了解它们的可靠性和真实性。在这项工作中，我们将许多现有的解释评估方法统一到一个数学框架下。这使我们能够比较现有的评估指标，更清晰地理解评估流程，并应用现有的统计方法进行评估。此外，我们对评估指标提出了两个简单的健全性检查，并表明许多常用指标未能通过这些测试，并且在概念标签发生巨大变化后分数没有改变。根据我们的实验和理论结果，我们提出了未来评估应遵循的指导方针，并确定了一组可靠的评估指标。", "summary": "本论文旨在解决神经网络中单个神经元功能解释的可靠性和真实性问题。它将现有的解释评估方法统一到一个数学框架下，从而更好地比较和理解评估流程。更重要的是，作者引入了两个针对评估指标的健全性检查，揭示了许多常用指标的不可靠性，因为它们未能反映概念标签的显著变化。该工作最终提出了未来评估应遵循的指导方针，并确定了一组可靠的评估指标。", "keywords": "神经元解释, 可解释性, 评估指标, 健全性检查, 神经网络", "comments": "这篇论文具有创新性，因为它提供了一个统一的数学框架来评估神经元解释，这对于推进机械可解释性至关重要。引入简单而有效的评估指标“健全性检查”尤为重要，因为它揭示了许多当前方法的局限性，并推动该领域向更健壮和可靠的评估实践发展。这项工作为建立信任和提高人工智能解释的实用性做出了重要贡献。"}}
{"id": "2506.05453", "title": "MLLM-CL: Continual Learning for Multimodal Large Language Models", "authors": ["Hongbo Zhao", "Fei Zhu", "Rundong Wang", "Gaofeng Meng", "Zhaoxiang Zhang"], "summary": "Recent Multimodal Large Language Models (MLLMs) excel in vision-language\nunderstanding but face challenges in adapting to dynamic real-world scenarios\nthat require continuous integration of new knowledge and skills. While\ncontinual learning (CL) offers a potential solution, existing benchmarks and\nmethods suffer from critical limitations. In this paper, we introduce MLLM-CL,\na novel benchmark encompassing domain and ability continual learning, where the\nformer focuses on independently and identically distributed (IID) evaluation\nacross evolving mainstream domains, whereas the latter evaluates on non-IID\nscenarios with emerging model ability. Methodologically, we propose preventing\ncatastrophic interference through parameter isolation, along with an MLLM-based\nrouting mechanism. Extensive experiments demonstrate that our approach can\nintegrate domain-specific knowledge and functional abilities with minimal\nforgetting, significantly outperforming existing methods.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05453v1", "AI": {"title_translation": "MLLM-CL：多模态大语言模型的持续学习", "tldr": "本文提出了MLLM-CL，一个针对多模态大语言模型（MLLMs）持续学习的新基准和方法，通过参数隔离和MLLM路由机制有效防止灾难性遗忘，并在实验中表现出优于现有方法的性能。", "motivation": "现有的多模态大语言模型（MLLMs）在适应需要持续整合新知识和技能的动态真实世界场景时面临挑战，且当前的持续学习（CL）基准和方法存在严重局限性。", "method": "本文引入了MLLM-CL，一个包含领域和能力持续学习的新型基准。在方法上，提出了通过参数隔离以及基于MLLM的路由机制来防止灾难性遗忘。", "result": "广泛的实验证明，所提出的方法能够以最小的遗忘整合领域特定知识和功能能力，并且显著优于现有方法。", "conclusion": "MLLM-CL方法能够有效解决多模态大语言模型在持续学习中面临的灾难性遗忘问题，并能有效整合新知识和技能，表现出优越的性能。", "translation": "近来的多模态大语言模型（MLLMs）在视觉-语言理解方面表现出色，但在适应需要持续整合新知识和技能的动态真实世界场景时面临挑战。尽管持续学习（CL）提供了一个潜在的解决方案，但现有的基准和方法存在严重的局限性。在本文中，我们引入了MLLM-CL，这是一个包含领域和能力持续学习的新型基准，其中前者侧重于在不断演变的主流领域中进行独立同分布（IID）评估，而后者则在非IID场景下评估新兴模型能力。在方法上，我们提出了通过参数隔离以及基于MLLM的路由机制来防止灾难性遗忘。广泛的实验表明，我们的方法可以以最小的遗忘整合领域特定知识和功能能力，显著优于现有方法。", "summary": "本文针对多模态大语言模型（MLLMs）在动态场景下持续学习的挑战，提出了MLLM-CL，一个涵盖领域和能力持续学习的新型基准。为解决灾难性遗忘问题，该研究提出了一种通过参数隔离和基于MLLM的路由机制的方法。实验结果表明，该方法能够有效地整合领域特定知识和功能能力，同时最大程度地减少遗忘，显著优于现有方法。", "keywords": "多模态大语言模型, 持续学习, 灾难性遗忘, 参数隔离, 路由机制", "comments": "该论文通过引入MLLM-CL基准和创新的参数隔离与路由机制，为多模态大语言模型在动态环境下的持续学习提供了新的解决方案，有效克服了灾难性遗忘这一核心难题，对多模态持续学习领域具有重要的贡献和实践意义。"}}
{"id": "2506.05791", "title": "Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization", "authors": ["Yuki Takezawa", "Xiaowen Jiang", "Anton Rodomanov", "Sebastian U. Stich"], "summary": "Reducing communication complexity is critical for efficient decentralized\noptimization. The proximal decentralized optimization (PDO) framework is\nparticularly appealing, as methods within this framework can exploit functional\nsimilarity among nodes to reduce communication rounds. Specifically, when local\nfunctions at different nodes are similar, these methods achieve faster\nconvergence with fewer communication steps. However, existing PDO methods often\nrequire highly accurate solutions to subproblems associated with the proximal\noperator, resulting in significant computational overhead. In this work, we\npropose the Stabilized Proximal Decentralized Optimization (SPDO) method, which\nachieves state-of-the-art communication and computational complexities within\nthe PDO framework. Additionally, we refine the analysis of existing PDO methods\nby relaxing subproblem accuracy requirements and leveraging average functional\nsimilarity. Experimental results demonstrate that SPDO significantly\noutperforms existing methods.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05791v1", "AI": {"title_translation": "利用相似性实现计算和通信高效的去中心化优化", "tldr": "本文提出了一种名为SPDO的新型去中心化优化方法，通过放宽子问题精度要求和利用函数相似性，显著降低了通信和计算开销，优于现有方法。", "motivation": "为了实现高效的去中心化优化，降低通信复杂性至关重要。现有的近端去中心化优化（PDO）方法虽然能利用节点间的函数相似性减少通信轮次，但通常需要对近端算子相关的子问题进行高精度求解，导致显著的计算开销。", "method": "本文提出了稳定近端去中心化优化（SPDO）方法。此外，通过放宽子问题精度要求和利用平均函数相似性，本文还改进了对现有PDO方法的分析。", "result": "SPDO方法在PDO框架内实现了最先进的通信和计算复杂性。实验结果表明，SPDO显著优于现有方法。", "conclusion": "SPDO是一种在去中心化优化中，通过有效利用函数相似性并降低子问题精度要求，显著提升计算和通信效率的先进方法。", "translation": "减少通信复杂性对于高效的去中心化优化至关重要。近端去中心化优化（PDO）框架特别有吸引力，因为该框架内的方法可以利用节点间的函数相似性来减少通信轮次。具体来说，当不同节点的局部函数相似时，这些方法可以以更少的通信步骤实现更快的收敛。然而，现有的PDO方法通常需要对与近端算子相关的子问题进行高精度求解，从而导致显著的计算开销。在这项工作中，我们提出了稳定近端去中心化优化（SPDO）方法，该方法在PDO框架内实现了最先进的通信和计算复杂性。此外，我们通过放宽子问题精度要求和利用平均函数相似性，改进了对现有PDO方法的分析。实验结果表明，SPDO显著优于现有方法。", "summary": "为了解决现有近端去中心化优化（PDO）方法在高精度子问题求解中产生的计算开销问题，本文提出了稳定近端去中心化优化（SPDO）方法。SPDO通过放宽子问题精度要求并利用平均函数相似性，实现了最先进的通信和计算效率。实验结果表明，SPDO在性能上显著优于现有方法。", "keywords": "去中心化优化, 通信复杂性, 近端去中心化优化, SPDO, 函数相似性", "comments": "本文的创新点在于提出了SPDO方法，该方法通过放宽对子问题求解精度的要求，显著降低了计算开销，同时保持了通信效率。通过利用函数相似性，该方法在去中心化优化中具有重要意义，尤其适用于节点间函数相似度较高的场景。"}}
{"id": "2506.05782", "title": "GazeNLQ @ Ego4D Natural Language Queries Challenge 2025", "authors": ["Wei-Cheng Lin", "Chih-Ming Lien", "Chen Lo", "Chia-Hung Yeh"], "summary": "This report presents our solution to the Ego4D Natural Language Queries (NLQ)\nChallenge at CVPR 2025. Egocentric video captures the scene from the wearer's\nperspective, where gaze serves as a key non-verbal communication cue that\nreflects visual attention and offer insights into human intention and\ncognition. Motivated by this, we propose a novel approach, GazeNLQ, which\nleverages gaze to retrieve video segments that match given natural language\nqueries. Specifically, we introduce a contrastive learning-based pretraining\nstrategy for gaze estimation directly from video. The estimated gaze is used to\naugment video representations within proposed model, thereby enhancing\nlocalization accuracy. Experimental results show that GazeNLQ achieves\nR1@IoU0.3 and R1@IoU0.5 scores of 27.82 and 18.68, respectively. Our code is\navailable at https://github.com/stevenlin510/GazeNLQ.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05782v1", "AI": {"title_translation": "GazeNLQ @ Ego4D 自然语言查询挑战赛 2025", "tldr": "GazeNLQ提出了一种新颖的方法，利用注视信息来增强自我中心视频的自然语言查询（NLQ）挑战中的视频片段检索，通过对比学习预训练来估计注视并提升定位精度，并在Ego4D挑战赛中取得了良好的结果。", "motivation": "自我中心视频中，注视作为一种关键的非语言交流线索，能够反映视觉注意力，并提供对人类意图和认知的洞察。本文的动机是利用这一特性来检索与自然语言查询匹配的视频片段。", "method": "本文提出了一种名为GazeNLQ的新颖方法，该方法利用注视来检索与给定自然语言查询匹配的视频片段。具体来说，它引入了一种基于对比学习的预训练策略，直接从视频中估计注视。估计的注视被用于增强模型中的视频表示，从而提高定位精度。", "result": "GazeNLQ在R1@IoU0.3和R1@IoU0.5分数上分别达到了27.82和18.68。", "conclusion": "GazeNLQ在Ego4D自然语言查询挑战赛中取得了27.82的R1@IoU0.3和18.68的R1@IoU0.5分数，证明了其通过利用注视信息有效提升视频片段检索准确性的能力。", "translation": "本报告介绍了我们参加CVPR 2025 Ego4D 自然语言查询（NLQ）挑战赛的解决方案。自我中心视频从佩戴者的视角捕捉场景，其中注视作为一种关键的非语言交流线索，反映了视觉注意力，并提供了对人类意图和认知的洞察。受此启发，我们提出了一种新颖的方法GazeNLQ，该方法利用注视来检索与给定自然语言查询匹配的视频片段。具体来说，我们引入了一种基于对比学习的预训练策略，直接从视频中估计注视。估计的注视被用于增强所提出模型中的视频表示，从而提高了定位精度。实验结果表明，GazeNLQ在R1@IoU0.3和R1@IoU0.5分数上分别达到了27.82和18.68。我们的代码可在https://github.com/stevenlin510/GazeNLQ获取。", "summary": "GazeNLQ是为Ego4D自然语言查询（NLQ）挑战赛提出的一种新颖解决方案，旨在利用注视信息增强自我中心视频的片段检索。该方法通过基于对比学习的预训练策略从视频中估计注视，并用其增强视频表示，从而提高了定位精度。实验结果表明，GazeNLQ在相关指标上表现良好，分别取得了27.82和18.68的R1@IoU0.3和R1@IoU0.5分数。", "keywords": "GazeNLQ, Ego4D, 自然语言查询, 自我中心视频, 注视估计", "comments": "本文的创新点在于将注视这一非语言线索引入到自我中心视频的自然语言查询任务中，并通过对比学习进行注视估计，这为理解和检索以人为中心的视频内容提供了新的视角。该方法在Ego4D挑战赛中的表现，证明了其在实际应用中的潜力。"}}
{"id": "2506.05787", "title": "EASG-Bench: Video Q&A Benchmark with Egocentric Action Scene Graphs", "authors": ["Ivan Rodin", "Tz-Ying Wu", "Kyle Min", "Sharath Nittur Sridhar", "Antonino Furnari", "Subarna Tripathi", "Giovanni Maria Farinella"], "summary": "We introduce EASG-Bench, a question-answering benchmark for egocentric videos\nwhere the question-answering pairs are created from spatio-temporally grounded\ndynamic scene graphs capturing intricate relationships among actors, actions,\nand objects. We propose a systematic evaluation framework and evaluate several\nlanguage-only and video large language models (video-LLMs) on this benchmark.\nWe observe a performance gap in language-only and video-LLMs, especially on\nquestions focusing on temporal ordering, thus identifying a research gap in the\narea of long-context video understanding. To promote the reproducibility of our\nfindings and facilitate further research, the benchmark and accompanying code\nare available at the following GitHub page:\nhttps://github.com/fpv-iplab/EASG-bench.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05787v1", "AI": {"title_translation": "EASG-Bench：带有自我中心动作场景图的视频问答基准", "tldr": "引入EASG-Bench，一个基于自我中心视频和动态场景图的视频问答基准，并揭示了现有模型在长上下文视频理解方面的不足。", "motivation": "现有模型在自我中心视频理解方面存在局限性，尤其是在处理时间顺序问题上；需要一个更复杂的基准来评估视频问答模型，特别是针对自我中心视频。", "method": "本文引入了EASG-Bench，一个用于自我中心视频的问答基准，其问答对由捕获了演员、动作和物体之间复杂关系的时空关联动态场景图创建。同时，提出了一个系统的评估框架，并评估了多个纯语言模型和视频大型语言模型（video-LLMs）在该基准上的表现。", "result": "研究观察到纯语言模型和视频大型语言模型之间存在性能差距，特别是在关注时间顺序的问题上，从而识别出长上下文视频理解领域的研究空白。", "conclusion": "EASG-Bench的引入揭示了现有模型在长上下文视频理解，尤其是在处理复杂时间顺序问题上的不足，并明确指出了该领域未来研究的空白和方向。", "translation": "我们引入了EASG-Bench，这是一个用于自我中心视频的问答基准，其问答对由捕获了演员、动作和物体之间复杂关系的时空关联动态场景图创建。我们提出了一个系统的评估框架，并评估了多个纯语言模型和视频大型语言模型（video-LLMs）在该基准上的表现。我们观察到纯语言模型和视频-LLMs之间存在性能差距，特别是在关注时间顺序的问题上，从而识别出长上下文视频理解领域的研究空白。为了促进我们研究结果的可复现性并便于进一步研究，该基准和配套代码可在以下GitHub页面获取：https://github.com/fpv-iplab/EASG-bench。", "summary": "本文介绍了EASG-Bench，一个专门用于自我中心视频的问答基准。该基准的问答对基于时空关联的动态场景图生成，能够捕捉演员、动作和物体之间的复杂关系。通过一个系统的评估框架，研究人员测试了多种语言模型和视频大型语言模型，发现它们在处理时间顺序等长上下文视频理解问题上存在显著性能差距，揭示了该领域的研究空白。为促进后续研究，该基准及配套代码已开源。", "keywords": "视频问答, 自我中心视频, 场景图, 视频理解, 基准", "comments": "该论文通过引入EASG-Bench，一个基于自我中心视频和动态场景图的视频问答基准，有效识别了当前视频理解模型在处理复杂时间关系和长上下文理解方面的局限性。其创新点在于利用动态场景图构建问答对，这使得问题能够更精细地探究视频中演员、动作和物体之间的复杂时空关系。通过揭示现有模型（特别是视频-LLMs）在时间顺序问题上的性能差距，该工作为未来的长上下文视频理解研究指明了方向，具有重要的研究价值。开源基准和代码也极大地促进了该领域的可复现性和后续研究。"}}
{"id": "2506.05490", "title": "Sentiment Analysis in Learning Management Systems Understanding Student Feedback at Scale", "authors": ["Mohammed Almutairi"], "summary": "During the wake of the Covid-19 pandemic, the educational paradigm has\nexperienced a major change from in person learning traditional to online\nplatforms. The change of learning convention has impacted the teacher-student\nespecially in non-verbal communication. The absent of non-verbal communication\nhas led to a reliance on verbal feedback which diminished the efficacy of the\neducational experience. This paper explores the integration of sentiment\nanalysis into learning management systems (LMS) to bridge the student-teacher's\ngap by offering an alternative approach to interpreting student feedback beyond\nits verbal context. The research involves data preparation, feature selection,\nand the development of a deep neural network model encompassing word embedding,\nLSTM, and attention mechanisms. This model is compared against a logistic\nregression baseline to evaluate its efficacy in understanding student feedback.\nThe study aims to bridge the communication gap between instructors and students\nin online learning environments, offering insights into the emotional context\nof student feedback and ultimately improving the quality of online education.", "comment": "10 pages, 10 figures", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05490v1", "AI": {"title_translation": "学习管理系统中的情感分析：大规模理解学生反馈", "tldr": "本文探讨了在学习管理系统中集成情感分析，以大规模理解学生反馈并弥合师生沟通鸿沟。", "motivation": "新冠疫情导致教育模式从线下转向线上，非语言交流的缺失使得师生过度依赖口头反馈，降低了教育体验的效率。本研究旨在通过情感分析弥补线上学习环境中师生之间的沟通鸿沟，提供超越口头语境解释学生反馈的替代方法。", "method": "研究包括数据准备、特征选择，以及开发一个包含词嵌入、LSTM和注意力机制的深度神经网络模型。该模型与逻辑回归基线进行比较，以评估其在理解学生反馈方面的功效。", "result": "Not mentioned in abstract", "conclusion": "该研究旨在弥合在线学习环境中教师和学生之间的沟通鸿沟，提供对学生反馈情感背景的深入见解，并最终提高在线教育的质量。", "translation": "在新冠疫情爆发期间，教育范式经历了从传统的面对面学习到在线平台的重大转变。学习习惯的改变影响了师生关系，尤其是在非语言交流方面。非语言交流的缺失导致对口头反馈的依赖，这降低了教育体验的效率。本文探讨了将情感分析集成到学习管理系统（LMS）中，通过提供一种超越口头语境解释学生反馈的替代方法来弥合师生之间的鸿沟。该研究涉及数据准备、特征选择以及深度神经网络模型的开发，该模型包含词嵌入、LSTM和注意力机制。将该模型与逻辑回归基线进行比较，以评估其在理解学生反馈方面的功效。该研究旨在弥合在线学习环境中教师和学生之间的沟通鸿沟，提供对学生反馈情感背景的见解，并最终提高在线教育的质量。", "summary": "本文研究了在新冠疫情下在线学习中非语言交流缺失导致的问题，提出将情感分析集成到学习管理系统（LMS）中。通过数据准备、特征选择和构建包含词嵌入、LSTM、注意力机制的深度神经网络模型，并与逻辑回归基线进行比较，旨在理解学生反馈的情感背景，弥合师生沟通鸿沟，从而提升在线教育质量。", "keywords": "情感分析, 学习管理系统, 学生反馈, 深度神经网络, 在线教育", "comments": "该论文通过将情感分析应用于学习管理系统，创新性地解决了在线教育中非语言交流缺失导致的学生反馈理解不足的问题。其采用深度学习方法（LSTM、注意力机制）处理文本数据，有望为大规模学生反馈分析提供有效工具，对提升在线教育质量具有重要意义。然而，摘要中未提及具体的实验结果，这限制了对其方法有效性的初步评估。"}}
{"id": "2506.05799", "title": "Option Pricing Using Ensemble Learning", "authors": ["Zeyuan Li", "Qingdao Huang"], "summary": "Ensemble learning is characterized by flexibility, high precision, and\nrefined structure. As a critical component within computational finance, option\npricing with machine learning requires both high predictive accuracy and\nreduced structural complexity-features that align well with the inherent\nadvantages of ensemble learning. This paper investigates the application of\nensemble learning to option pricing, and conducts a comparative analysis with\nclassical machine learning models to assess their performance in terms of\naccuracy, local feature extraction, and robustness to noise. A novel\nexperimental strategy is introduced, leveraging parameter transfer across\nexperiments to improve robustness and realism in financial simulations.Building\nupon this strategy, an evaluation mechanism is developed that incorporates a\nscoring strategy and a weighted evaluation strategy explicitly emphasizing the\nfoundational role of financial theory. This mechanism embodies an orderly\nintegration of theoretical finance and computational methods. In addition, the\nstudy examines the interaction between sliding window technique and noise,\nrevealing nuanced patterns that suggest a potential connection relevant to\nongoing research in machine learning and data science.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05799v1", "AI": {"title_translation": "期权定价中的集成学习", "tldr": "本文探讨了集成学习在期权定价中的应用，并通过与经典机器学习模型进行比较，评估其在准确性、局部特征提取和噪声鲁棒性方面的性能。研究引入了一种新的实验策略和评估机制，并分析了滑动窗口技术与噪声的相互作用。", "motivation": "机器学习在计算金融中进行期权定价需要高预测精度和简化的结构复杂性，而集成学习具有灵活性、高精度和精炼结构的特点，与此需求高度契合。", "method": "本文研究了集成学习在期权定价中的应用，并与经典机器学习模型进行比较分析，评估其在准确性、局部特征提取和噪声鲁棒性方面的性能。引入了一种新的实验策略，利用跨实验的参数转移来提高金融模拟的鲁棒性和真实性。开发了一种评估机制，该机制结合了评分策略和加权评估策略，明确强调了金融理论的基础作用。此外，研究还考察了滑动窗口技术与噪声之间的相互作用。", "result": "通过与经典机器学习模型进行比较，评估了集成学习在期权定价方面的性能（准确性、局部特征提取、噪声鲁棒性）。引入了利用参数转移的新实验策略，提高了金融模拟的鲁棒性和真实性。开发了一种结合金融理论的评估机制。揭示了滑动窗口技术与噪声之间微妙的模式，暗示了与机器学习和数据科学研究相关的潜在联系。", "conclusion": "本文通过将集成学习应用于期权定价，并引入创新的实验策略和评估机制，有效地将金融理论与计算方法结合起来，同时揭示了滑动窗口与噪声之间的新模式。", "translation": "集成学习以其灵活性、高精度和精炼结构为特征。作为计算金融中的一个关键组成部分，利用机器学习进行期权定价需要高预测准确性和简化的结构复杂性——这些特点与集成学习固有的优势高度契合。本文研究了集成学习在期权定价中的应用，并与经典机器学习模型进行了比较分析，以评估它们在准确性、局部特征提取和噪声鲁棒性方面的性能。引入了一种新颖的实验策略，利用跨实验的参数转移来提高金融模拟的鲁棒性和真实性。在此策略的基础上，开发了一种评估机制，该机制结合了评分策略和加权评估策略，明确强调了金融理论的基础作用。这种机制体现了金融理论和计算方法的有序整合。此外，该研究还考察了滑动窗口技术与噪声之间的相互作用，揭示了细致入微的模式，这些模式暗示了与机器学习和数据科学正在进行的研究相关的潜在联系。", "summary": "本文探讨了集成学习在期权定价中的应用，并将其与经典机器学习模型进行比较，评估了其在准确性、局部特征提取和噪声鲁棒性方面的表现。研究引入了一种新颖的实验策略，通过参数转移增强金融模拟的鲁棒性，并开发了一种结合金融理论的评估机制。此外，论文还分析了滑动窗口技术与噪声的相互作用，揭示了潜在的联系。", "keywords": "集成学习, 期权定价, 机器学习, 金融模拟, 噪声鲁棒性", "comments": "本文创新性地将集成学习应用于期权定价，并强调了金融理论在计算方法中的基础作用，这对于金融建模的实际应用和理论研究都具有重要意义。引入的参数转移实验策略和综合评估机制提升了研究的实用性和严谨性。"}}
{"id": "2506.05806", "title": "LLIA -- Enabling Low-Latency Interactive Avatars: Real-Time Audio-Driven Portrait Video Generation with Diffusion Models", "authors": ["Haojie Yu", "Zhaonian Wang", "Yihan Pan", "Meng Cheng", "Hao Yang", "Chao Wang", "Tao Xie", "Xiaoming Xu", "Xiaoming Wei", "Xunliang Cai"], "summary": "Diffusion-based models have gained wide adoption in the virtual human\ngeneration due to their outstanding expressiveness. However, their substantial\ncomputational requirements have constrained their deployment in real-time\ninteractive avatar applications, where stringent speed, latency, and duration\nrequirements are paramount. We present a novel audio-driven portrait video\ngeneration framework based on the diffusion model to address these challenges.\nFirstly, we propose robust variable-length video generation to reduce the\nminimum time required to generate the initial video clip or state transitions,\nwhich significantly enhances the user experience. Secondly, we propose a\nconsistency model training strategy for Audio-Image-to-Video to ensure\nreal-time performance, enabling a fast few-step generation. Model quantization\nand pipeline parallelism are further employed to accelerate the inference\nspeed. To mitigate the stability loss incurred by the diffusion process and\nmodel quantization, we introduce a new inference strategy tailored for\nlong-duration video generation. These methods ensure real-time performance and\nlow latency while maintaining high-fidelity output. Thirdly, we incorporate\nclass labels as a conditional input to seamlessly switch between speaking,\nlistening, and idle states. Lastly, we design a novel mechanism for\nfine-grained facial expression control to exploit our model's inherent\ncapacity. Extensive experiments demonstrate that our approach achieves\nlow-latency, fluid, and authentic two-way communication. On an NVIDIA RTX\n4090D, our model achieves a maximum of 78 FPS at a resolution of 384x384 and 45\nFPS at a resolution of 512x512, with an initial video generation latency of 140\nms and 215 ms, respectively.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05806v1", "AI": {"title_translation": "LLIA -- 实现低延迟交互式虚拟形象：基于扩散模型的实时音频驱动肖像视频生成", "tldr": "LLIA是一个基于扩散模型的实时音频驱动肖像视频生成框架，解决了扩散模型在交互式虚拟形象应用中计算量大、延迟高的问题，实现了低延迟和高帧率。", "motivation": "扩散模型虽然在虚拟人生成中表现出色，但其巨大的计算需求限制了其在实时交互式虚拟形象应用中的部署，这些应用对速度、延迟和持续时间有严格要求。", "method": "1. 提出鲁棒的变长视频生成以减少初始视频剪辑或状态转换所需时间。2. 提出音频-图像-视频一致性模型训练策略以确保实时性能和快速少步生成。3. 采用模型量化和流水线并行加速推理。4. 引入新的推理策略以减轻扩散过程和模型量化导致的稳定性损失，用于长时间视频生成。5. 将类别标签作为条件输入，实现说话、听和空闲状态的无缝切换。6. 设计新的机制进行细粒度面部表情控制。", "result": "在NVIDIA RTX 4090D上，模型在384x384分辨率下达到最高78 FPS，在512x512分辨率下达到45 FPS，初始视频生成延迟分别为140毫秒和215毫秒。实验表明该方法实现了低延迟、流畅和真实的双向通信。", "conclusion": "该方法确保了实时性能和低延迟，同时保持了高保真输出，并实现了低延迟、流畅和真实的双向通信。", "translation": "扩散模型因其出色的表达能力在虚拟人生成中得到了广泛应用。然而，其巨大的计算需求限制了它们在实时交互式虚拟形象应用中的部署，这些应用对速度、延迟和持续时间有严格要求。我们提出了一个基于扩散模型的新型音频驱动肖像视频生成框架来解决这些挑战。首先，我们提出了鲁棒的变长视频生成，以减少生成初始视频片段或状态转换所需的最短时间，这显著增强了用户体验。其次，我们提出了音频-图像-视频的一致性模型训练策略，以确保实时性能，实现快速的几步生成。进一步采用模型量化和流水线并行来加速推理速度。为了减轻扩散过程和模型量化引起的稳定性损失，我们引入了一种针对长时间视频生成的新推理策略。这些方法确保了实时性能和低延迟，同时保持了高保真输出。第三，我们将类别标签作为条件输入，以在说话、听和空闲状态之间无缝切换。最后，我们设计了一种新颖的机制，用于细粒度的面部表情控制，以利用我们模型固有的能力。大量实验表明，我们的方法实现了低延迟、流畅和真实的双向通信。在NVIDIA RTX 4090D上，我们的模型在384x384分辨率下达到最高78 FPS，在512x512分辨率下达到45 FPS，初始视频生成延迟分别为140毫秒和215毫秒。", "summary": "本文提出了LLIA，一个基于扩散模型的新型音频驱动肖像视频生成框架，旨在解决现有扩散模型在实时交互式虚拟形象应用中面临的计算量大和延迟高的问题。该框架通过引入变长视频生成、一致性模型训练策略、模型量化与流水线并行、新的长时长视频推理策略、状态切换条件输入以及细粒度表情控制等多种创新方法，显著提升了生成速度和用户体验。实验结果表明，LLIA在保持高保真输出的同时，实现了低延迟和高帧率的实时双向通信。", "keywords": "扩散模型, 实时视频生成, 交互式虚拟形象, 音频驱动, 低延迟", "comments": "该研究创新性地将扩散模型应用于低延迟实时交互式虚拟形象生成，通过多项技术优化解决了扩散模型计算量大的固有挑战。其提出的变长视频生成、一致性训练和新的推理策略对于提升用户体验和系统稳定性具有重要意义。在实时通信和虚拟人领域具有潜在的应用价值。"}}
{"id": "2506.05801", "title": "Neural Collapse in Cumulative Link Models for Ordinal Regression: An Analysis with Unconstrained Feature Model", "authors": ["Chuang Ma", "Tomoyuki Obuchi", "Toshiyuki Tanaka"], "summary": "A phenomenon known as ''Neural Collapse (NC)'' in deep classification tasks,\nin which the penultimate-layer features and the final classifiers exhibit an\nextremely simple geometric structure, has recently attracted considerable\nattention, with the expectation that it can deepen our understanding of how\ndeep neural networks behave. The Unconstrained Feature Model (UFM) has been\nproposed to explain NC theoretically, and there emerges a growing body of work\nthat extends NC to tasks other than classification and leverages it for\npractical applications. In this study, we investigate whether a similar\nphenomenon arises in deep Ordinal Regression (OR) tasks, via combining the\ncumulative link model for OR and UFM. We show that a phenomenon we call Ordinal\nNeural Collapse (ONC) indeed emerges and is characterized by the following\nthree properties: (ONC1) all optimal features in the same class collapse to\ntheir within-class mean when regularization is applied; (ONC2) these class\nmeans align with the classifier, meaning that they collapse onto a\none-dimensional subspace; (ONC3) the optimal latent variables (corresponding to\nlogits or preactivations in classification tasks) are aligned according to the\nclass order, and in particular, in the zero-regularization limit, a highly\nlocal and simple geometric relationship emerges between the latent variables\nand the threshold values. We prove these properties analytically within the UFM\nframework with fixed threshold values and corroborate them empirically across a\nvariety of datasets. We also discuss how these insights can be leveraged in OR,\nhighlighting the use of fixed thresholds.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05801v1", "AI": {"title_translation": "序数回归累积链接模型中的神经坍缩：基于无约束特征模型的分析", "tldr": "研究发现，在序数回归任务中存在一种称为“序数神经坍缩（ONC）”的现象，其特征与分类任务中的神经坍缩类似。", "motivation": "深度分类任务中的“神经坍缩（NC）”现象及其理论解释（UFM）已引起广泛关注，并被扩展到其他任务。本文旨在探究在深度序数回归（OR）任务中是否存在类似现象。", "method": "通过结合序数回归的累积链接模型和无约束特征模型（UFM）进行研究。通过UFM框架进行分析证明，并通过各种数据集进行经验验证。", "result": "发现了一种名为“序数神经坍缩（ONC）”的现象，其具有三个特性：(ONC1) 应用正则化时，同一类别的所有最优特征坍缩到其类内均值；(ONC2) 这些类别均值与分类器对齐，坍缩到一维子空间；(ONC3) 最优潜在变量根据类别顺序对齐，在零正则化极限下，潜在变量与阈值之间出现高度局部和简单的几何关系。", "conclusion": "序数回归任务中确实存在序数神经坍缩（ONC）现象，其特性已在UFM框架内得到分析证明和经验证实。这些发现可用于指导序数回归任务。", "translation": "深度分类任务中一种被称为“神经坍缩（NC）”的现象，即倒数第二层特征和最终分类器展现出极其简单的几何结构，最近引起了相当大的关注，人们期望它能加深我们对深度神经网络行为的理解。无约束特征模型（UFM）已被提出来从理论上解释NC，并且越来越多的工作将NC扩展到分类以外的任务并将其用于实际应用。在这项研究中，我们通过结合序数回归（OR）的累积链接模型和UFM，研究了在深度序数回归任务中是否出现类似现象。我们表明，一种我们称之为序数神经坍缩（ONC）的现象确实出现了，并且其特点是以下三个属性：(ONC1) 当应用正则化时，同一类别中的所有最优特征都坍缩到其类内均值；(ONC2) 这些类别均值与分类器对齐，这意味着它们坍缩到一个一维子空间；(ONC3) 最优潜在变量（对应于分类任务中的 logits 或预激活）根据类别顺序对齐，特别是，在零正则化极限下，潜在变量与阈值之间出现高度局部和简单的几何关系。我们在具有固定阈值的UFM框架内分析证明了这些属性，并通过各种数据集进行了经验证实。我们还讨论了如何在OR中利用这些见解，强调了固定阈值的使用。", "summary": "本文研究了深度序数回归（OR）任务中是否存在类似深度分类任务中“神经坍缩（NC）”的现象。通过结合累积链接模型和无约束特征模型（UFM），研究发现并命名为“序数神经坍缩（ONC）”的现象确实存在，并具有三个关键特性：正则化下特征坍缩到类内均值，类均值与分类器对齐并坍缩到一维子空间，以及潜在变量根据类别顺序对齐。这些特性在UFM框架内得到分析证明，并在一系列数据集上得到经验证实。研究还讨论了这些见解在OR中的应用，强调了固定阈值的使用。", "keywords": "神经坍缩, 序数回归, 累积链接模型, 无约束特征模型, 序数神经坍缩", "comments": "本文通过将深度分类任务中的“神经坍缩”现象扩展到序数回归任务，提出了“序数神经坍缩（ONC）”的概念及其明确的三个特性，具有创新性。这有助于加深对深度神经网络行为的理解，并为序数回归任务的设计和优化提供了新的理论指导和实践见解。"}}
{"id": "2506.05815", "title": "NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces", "authors": ["Pierluigi Zama Ramirez", "Fabio Tosi", "Luigi Di Stefano", "Radu Timofte", "Alex Costanzino", "Matteo Poggi", "Samuele Salti", "Stefano Mattoccia", "Zhe Zhang", "Yang Yang", "Wu Chen", "Anlong Ming", "Mingshuai Zhao", "Mengying Yu", "Shida Gao", "Xiangfeng Wang", "Feng Xue", "Jun Shi", "Yong Yang", "Yong A", "Yixiang Jin", "Dingzhe Li", "Aryan Shukla", "Liam Frija-Altarac", "Matthew Toews", "Hui Geng", "Tianjiao Wan", "Zijian Gao", "Qisheng Xu", "Kele Xu", "Zijian Zang", "Jameer Babu Pinjari", "Kuldeep Purohit", "Mykola Lavreniuk", "Jing Cao", "Shenyi Li", "Kui Jiang", "Junjun Jiang", "Yong Huang"], "summary": "This paper reports on the NTIRE 2025 challenge on HR Depth From images of\nSpecular and Transparent surfaces, held in conjunction with the New Trends in\nImage Restoration and Enhancement (NTIRE) workshop at CVPR 2025. This challenge\naims to advance the research on depth estimation, specifically to address two\nof the main open issues in the field: high-resolution and non-Lambertian\nsurfaces. The challenge proposes two tracks on stereo and single-image depth\nestimation, attracting about 177 registered participants. In the final testing\nstage, 4 and 4 participating teams submitted their models and fact sheets for\nthe two tracks.", "comment": "NTIRE Workshop Challenge Report, CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05815v1", "AI": {"title_translation": "NTIRE 2025高反射和透明表面图像高分辨率深度挑战赛", "tldr": "NTIRE 2025挑战赛报告，旨在解决高分辨率和非朗伯表面图像深度估计问题。", "motivation": "该挑战旨在推进深度估计研究，特别是解决该领域两大开放性问题：高分辨率和非朗伯表面。", "method": "该挑战提出了立体和单图像深度估计两个赛道，吸引了约177名注册参与者。", "result": "在最终测试阶段，两个赛道各有4个参与团队提交了模型和事实表。", "conclusion": "Not mentioned in abstract", "translation": "本文报告了NTIRE 2025高反射和透明表面图像高分辨率深度挑战赛，该挑战赛与2025年CVPR新趋势图像恢复与增强（NTIRE）研讨会同期举行。这项挑战旨在推动深度估计研究，特别是解决该领域两个主要的开放性问题：高分辨率和非朗伯表面。挑战提出了立体和单图像深度估计两个赛道，吸引了大约177名注册参与者。在最终测试阶段，两个赛道各有4个参与团队提交了他们的模型和事实表。", "summary": "本论文报告了NTIRE 2025高反射和透明表面图像高分辨率深度挑战赛，该挑战赛与CVPR 2025的NTIRE研讨会同期举行。挑战旨在推进深度估计研究，解决高分辨率和非朗伯表面图像的深度估计难题。挑战赛设置了立体和单图像深度估计两个赛道，吸引了约177名注册者，最终各有4支团队提交了模型。", "keywords": "深度估计, 高分辨率, 非朗伯表面, NTIRE 2025, 挑战赛", "comments": "Not mentioned in abstract"}}
{"id": "2506.05820", "title": "DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image", "authors": ["Ziwei Zhao", "Zhixing Zhang", "Yuhang Liu", "Zhao Zhang", "Haojun Yu", "Dong Wang", "Liwei Wang"], "summary": "In the field of 3D medical imaging, accurately extracting and representing\nthe blood vessels with curvilinear structures holds paramount importance for\nclinical diagnosis. Previous methods have commonly relied on discrete\nrepresentation like mask, often resulting in local fractures or scattered\nfragments due to the inherent limitations of the per-pixel classification\nparadigm. In this work, we introduce DeformCL, a new continuous representation\nbased on Deformable Centerlines, where centerline points act as nodes connected\nby edges that capture spatial relationships. Compared with previous\nrepresentations, DeformCL offers three key advantages: natural connectivity,\nnoise robustness, and interaction facility. We present a comprehensive training\npipeline structured in a cascaded manner to fully exploit these favorable\nproperties of DeformCL. Extensive experiments on four 3D vessel segmentation\ndatasets demonstrate the effectiveness and superiority of our method.\nFurthermore, the visualization of curved planar reformation images validates\nthe clinical significance of the proposed framework. We release the code in\nhttps://github.com/barry664/DeformCL", "comment": "Accepted by CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05820v1", "AI": {"title_translation": "DeformCL：学习可变形中心线表示用于3D医学图像中的血管提取", "tldr": "DeformCL是一种基于可变形中心线的新型连续表示方法，用于3D医学图像中的血管提取，解决了传统离散表示的局限性，并表现出优越的性能和临床意义。", "motivation": "在3D医学成像领域，准确提取和表示具有曲线结构的血管对于临床诊断至关重要。以往的方法通常依赖于掩膜等离散表示，但由于像素级分类范式的固有局限性，这些方法常导致局部断裂或碎片化。", "method": "本研究引入了DeformCL，一种基于可变形中心线的新型连续表示方法，其中中心线点作为节点，通过捕获空间关系的边连接。DeformCL具有自然连通性、噪声鲁棒性和交互便利性三个关键优势。作者提出了一个级联的综合训练流程，以充分利用DeformCL的这些有利特性。", "result": "在四个3D血管分割数据集上进行的大量实验证明了该方法的有效性和优越性。此外，弯曲平面重建图像的可视化验证了所提出框架的临床意义。", "conclusion": "DeformCL作为一种新型连续表示方法，有效解决了传统离散表示的局限性，并在3D血管提取方面表现出卓越的性能和临床价值。", "translation": "在3D医学成像领域，准确提取和表示具有曲线结构的血管对于临床诊断至关重要。以往的方法通常依赖于掩膜等离散表示，由于像素级分类范式的固有局限性，常导致局部断裂或碎片化。在这项工作中，我们引入了DeformCL，一种基于可变形中心线的新型连续表示方法，其中中心线点作为节点，通过捕获空间关系的边连接。与以往的表示方法相比，DeformCL具有三个关键优势：自然连通性、噪声鲁棒性和交互便利性。我们提出了一个级联的综合训练流程，以充分利用DeformCL的这些有利特性。在四个3D血管分割数据集上进行的大量实验证明了我们方法的有效性和优越性。此外，弯曲平面重建图像的可视化验证了所提出框架的临床意义。我们已在https://github.com/barry664/DeformCL发布了代码。", "summary": "本论文介绍了DeformCL，一种用于3D医学图像中血管提取的新型连续可变形中心线表示方法。针对传统离散表示在血管提取中存在的局部断裂和碎片化问题，DeformCL通过将中心线点作为节点连接，提供了自然连通性、噪声鲁棒性和交互便利性。论文提出了一种级联训练流程，并在四个3D血管分割数据集上通过实验验证了DeformCL的有效性和优越性，同时弯曲平面重建图像的可视化也证实了其临床意义。", "keywords": "血管提取, 3D医学图像, 可变形中心线, 连续表示, DeformCL", "comments": "这项工作的创新之处在于提出了可变形中心线作为血管的连续表示，克服了传统像素级分类的局限性。其优势在于提高了血管提取的准确性和连通性，对于临床诊断具有重要意义。"}}
{"id": "2506.05826", "title": "Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning", "authors": ["Ngoc Bui", "Menglin Yang", "Runjin Chen", "Leonardo Neves", "Mingxuan Ju", "Rex Ying", "Neil Shah", "Tong Zhao"], "summary": "Backward compatible representation learning enables updated models to\nintegrate seamlessly with existing ones, avoiding to reprocess stored data.\nDespite recent advances, existing compatibility approaches in Euclidean space\nneglect the uncertainty in the old embedding model and force the new model to\nreconstruct outdated representations regardless of their quality, thereby\nhindering the learning process of the new model. In this paper, we propose to\nswitch perspectives to hyperbolic geometry, where we treat time as a natural\naxis for capturing a model's confidence and evolution. By lifting embeddings\ninto hyperbolic space and constraining updated embeddings to lie within the\nentailment cone of the old ones, we maintain generational consistency across\nmodels while accounting for uncertainties in the representations. To further\nenhance compatibility, we introduce a robust contrastive alignment loss that\ndynamically adjusts alignment weights based on the uncertainty of the old\nembeddings. Experiments validate the superiority of the proposed method in\nachieving compatibility, paving the way for more resilient and adaptable\nmachine learning systems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05826v1", "AI": {"title_translation": "沿着时间之箭学习：用于向后兼容表示学习的双曲几何", "tldr": "本文提出了一种利用双曲几何和不确定性感知对比对齐损失的方法，以在向后兼容表示学习中实现模型间的世代一致性，同时解决现有欧几里德空间方法中旧模型不确定性被忽略的问题。", "motivation": "现有的欧几里德空间兼容性方法忽略了旧嵌入模型的不确定性，并强制新模型重建过时的表示，无论其质量如何，从而阻碍了新模型的学习过程。", "method": "本文提出将视角转向双曲几何，将时间视为捕获模型置信度和演变的自然轴。通过将嵌入提升到双曲空间，并将更新的嵌入限制在旧嵌入的蕴含锥内，从而在考虑表示不确定性的同时保持模型间的世代一致性。此外，引入了一种鲁棒的对比对齐损失，该损失根据旧嵌入的不确定性动态调整对齐权重。", "result": "实验验证了所提方法在实现兼容性方面的优越性。", "conclusion": "该方法为构建更具弹性和适应性的机器学习系统铺平了道路。", "translation": "向后兼容的表示学习使更新后的模型能够与现有模型无缝集成，避免重新处理存储的数据。尽管最近取得了进展，但欧几里德空间中现有的兼容性方法忽略了旧嵌入模型的不确定性，并强制新模型重建过时的表示，无论其质量如何，从而阻碍了新模型的学习过程。在本文中，我们提出将视角转向双曲几何，其中我们将时间视为捕获模型置信度和演变的自然轴。通过将嵌入提升到双曲空间，并将更新的嵌入限制在旧嵌入的蕴含锥内，我们可以在考虑表示不确定性的同时保持模型间的世代一致性。为了进一步增强兼容性，我们引入了一种鲁棒的对比对齐损失，该损失根据旧嵌入的不确定性动态调整对齐权重。实验验证了所提方法在实现兼容性方面的优越性，为更具弹性和适应性的机器学习系统铺平了道路。", "summary": "本研究针对向后兼容表示学习中现有欧几里德空间方法忽略旧模型不确定性并阻碍新模型学习的问题，提出了一种基于双曲几何的新方法。该方法将时间视为模型置信度和演化的轴，通过将嵌入映射到双曲空间并限制更新嵌入在旧嵌入的蕴含锥内，从而在考虑不确定性的同时保持世代一致性。此外，引入了根据旧嵌入不确定性动态调整对齐权重的鲁棒对比对齐损失。实验结果表明，该方法在实现兼容性方面表现优越，有助于构建更具弹性和适应性的机器学习系统。", "keywords": "向后兼容表示学习, 双曲几何, 不确定性, 对比学习, 模型演进", "comments": "本文创新性地将双曲几何引入向后兼容表示学习，解决了欧几里德空间方法中旧模型不确定性被忽略的问题。通过利用双曲空间的特性来建模时间演进和不确定性，并引入不确定性感知的对比对齐损失，显著提升了模型间的兼容性和新模型的学习效率。这对于构建可演进的、无需重复处理历史数据的机器学习系统具有重要意义。"}}
{"id": "2506.05821", "title": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks", "authors": ["Quansong He", "Xiangde Min", "Kaishen Wang", "Tao He"], "summary": "Medical image segmentation is a critical task in computer vision, with UNet\nserving as a milestone architecture. The typical component of UNet family is\nthe skip connection, however, their skip connections face two significant\nlimitations: (1) they lack effective interaction between features at different\nscales, and (2) they rely on simple concatenation or addition operations, which\nconstrain efficient information integration. While recent improvements to UNet\nhave focused on enhancing encoder and decoder capabilities, these limitations\nremain overlooked. To overcome these challenges, we propose a novel multi-scale\nfeature fusion method that reimagines the UNet decoding process as solving an\ninitial value problem (IVP), treating skip connections as discrete nodes. By\nleveraging principles from the linear multistep method, we propose an adaptive\nordinary differential equation method to enable effective multi-scale feature\nfusion. Our approach is independent of the encoder and decoder architectures,\nmaking it adaptable to various U-Net-like networks. Experiments on ACDC,\nKiTS2023, MSD brain tumor, and ISIC2017/2018 skin lesion segmentation datasets\ndemonstrate improved feature utilization, reduced network parameters, and\nmaintained high performance. The code is available at\nhttps://github.com/nayutayuki/FuseUNet.", "comment": "ICML2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05821v1", "AI": {"title_translation": "FuseUNet：一种U形网络的多尺度特征融合方法", "tldr": "FuseUNet提出了一种新颖的多尺度特征融合方法，通过将UNet解码过程视为解决初值问题，并利用自适应常微分方程方法，解决了传统UNet跳跃连接中特征交互不足和信息集成受限的问题，在医学图像分割任务中实现了性能提升和参数减少。", "motivation": "传统的UNet家族网络中的跳跃连接存在两个主要局限性：（1）它们缺乏不同尺度特征之间的有效交互；（2）它们依赖简单的连接或加法操作，这限制了高效的信息集成。尽管最近对UNet的改进主要集中在增强编码器和解码器能力上，但这些局限性仍被忽视。", "method": "本文提出了一种新颖的多尺度特征融合方法，将UNet的解码过程重新构想为解决一个初值问题（IVP），并将跳跃连接视为离散节点。通过利用线性多步法的原理，提出了一种自适应常微分方程方法，以实现有效的多尺度特征融合。该方法独立于编码器和解码器架构，使其适用于各种U-Net类网络。", "result": "在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上的实验表明，该方法改善了特征利用率，减少了网络参数，并保持了高性能。", "conclusion": "FuseUNet通过创新的多尺度特征融合方法，有效解决了UNet跳跃连接的局限性，在医学图像分割任务中取得了显著的改进，证明了其在多种U-Net类网络中的普适性和有效性。", "translation": "医学图像分割是计算机视觉中的一项关键任务，其中UNet是一种里程碑式的架构。UNet家族的典型组件是跳跃连接，然而，它们的跳跃连接面临两个重要的局限性：(1) 它们缺乏不同尺度特征之间的有效交互，以及 (2) 它们依赖简单的连接或加法操作，这限制了高效的信息集成。尽管最近对UNet的改进主要集中在增强编码器和解码器能力上，但这些局限性仍被忽视。为了克服这些挑战，我们提出了一种新颖的多尺度特征融合方法，该方法将UNet解码过程重新构想为解决一个初值问题（IVP），并将跳跃连接视为离散节点。通过利用线性多步法的原理，我们提出了一种自适应常微分方程方法，以实现有效的多尺度特征融合。我们的方法独立于编码器和解码器架构，使其适用于各种U-Net类网络。在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上的实验表明，该方法改善了特征利用率，减少了网络参数，并保持了高性能。代码可在https://github.com/nayutayuki/FuseUNet获得。", "summary": "该论文提出了一种名为FuseUNet的新型多尺度特征融合方法，旨在解决传统UNet跳跃连接中存在的特征交互不足和信息集成受限的问题。通过将UNet解码过程重新定义为初值问题，并引入基于线性多步法的自适应常微分方程方法，FuseUNet实现了有效的多尺度特征融合。该方法独立于具体编码器和解码器架构，具有广泛的适用性。实验证明，FuseUNet在医学图像分割任务中提升了特征利用率，减少了网络参数，并维持了高水平的性能。", "keywords": "多尺度特征融合, U-Net, 医学图像分割, 跳跃连接, 常微分方程", "comments": "该论文的创新点在于将UNet的解码过程与常微分方程相结合，通过自适应方法解决了跳跃连接中多尺度特征融合的难题，为U-Net类网络的改进提供了新思路。其方法独立于编码器和解码器架构，具有良好的通用性，这使得它能够广泛应用于现有的各种U-Net变体，具有重要的实践价值。"}}
{"id": "2506.05831", "title": "Heartcare Suite: Multi-dimensional Understanding of ECG with Raw Multi-lead Signal Modeling", "authors": ["Yihan Xie", "Sijing Li", "Tianwei Lin", "Zhuonan Wang", "Chenglin Yang", "Yu Zhong", "Wenqiao Zhang", "Haoyuan Li", "Hao Jiang", "Fengda Zhang", "Qishan Chen", "Jun Xiao", "Yueting Zhuang", "Beng Chin Ooi"], "summary": "We present Heartcare Suite, a multimodal comprehensive framework for\nfinegrained electrocardiogram (ECG) understanding. It comprises three key\ncomponents: (i) Heartcare-220K, a high-quality, structured, and comprehensive\nmultimodal ECG dataset covering essential tasks such as disease diagnosis,\nwaveform morphology analysis, and rhythm interpretation. (ii) Heartcare-Bench,\na systematic and multi-dimensional benchmark designed to evaluate diagnostic\nintelligence and guide the optimization of Medical Multimodal Large Language\nModels (Med-MLLMs) in ECG scenarios. and (iii) HeartcareGPT with a tailored\ntokenizer Bidirectional ECG Abstract Tokenization (Beat), which compresses raw\nmulti-lead signals into semantically rich discrete tokens via duallevel vector\nquantization and query-guided bidirectional diffusion mechanism. Built upon\nHeartcare-220K, HeartcareGPT achieves strong generalization and SoTA\nperformance across multiple clinically meaningful tasks. Extensive experiments\ndemonstrate that Heartcare Suite is highly effective in advancing ECGspecific\nmultimodal understanding and evaluation. Our project is available at\nhttps://github.com/Wznnnnn/Heartcare-Suite .", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05831v1", "AI": {"title_translation": "Heartcare Suite：基于原始多导联信号建模的心电图多维度理解", "tldr": "Heartcare Suite是一个用于精细心电图理解的多模态框架，包含高质量数据集、评估基准和用于压缩原始多导联信号的HeartcareGPT模型，在多项临床任务中表现出色。", "motivation": "为了解决精细心电图（ECG）理解的挑战，并推进ECG专用多模态理解和评估。", "method": "Heartcare Suite包含三个关键组件：(i) Heartcare-220K，一个高质量、结构化、全面的多模态ECG数据集；(ii) Heartcare-Bench，一个系统化、多维度的基准，用于评估诊断智能并指导医疗多模态大型语言模型（Med-MLLMs）在ECG场景中的优化；(iii) HeartcareGPT，带有定制的Beat分词器，通过双层向量量化和查询引导的双向扩散机制，将原始多导联信号压缩成语义丰富的离散标记。", "result": "HeartcareGPT在Heartcare-220K数据集上实现了强大的泛化能力和在多项临床有意义任务上的最先进（SoTA）性能。广泛的实验表明，Heartcare Suite在推进ECG专用多模态理解和评估方面非常有效。", "conclusion": "Heartcare Suite框架，包括其数据集、基准和新模型HeartcareGPT，成功地实现了ECG的精细多模态理解，并在多项临床任务中展现出卓越的性能和泛化能力，有效推进了ECG领域的AI应用。", "translation": "我们提出了Heartcare Suite，一个用于精细心电图（ECG）理解的多模态综合框架。它包含三个关键组件：(i) Heartcare-220K，一个高质量、结构化、全面的多模态ECG数据集，涵盖疾病诊断、波形形态分析和心律解释等基本任务。(ii) Heartcare-Bench，一个系统化、多维度的基准，旨在评估诊断智能并指导医疗多模态大型语言模型（Med-MLLMs）在ECG场景中的优化。(iii) HeartcareGPT，带有定制的分词器Bidirectional ECG Abstract Tokenization (Beat)，它通过双层向量量化和查询引导的双向扩散机制，将原始多导联信号压缩成语义丰富的离散标记。HeartcareGPT基于Heartcare-220K构建，在多个临床有意义的任务中实现了强大的泛化能力和最先进（SoTA）的性能。广泛的实验表明，Heartcare Suite在推进ECG专用多模态理解和评估方面非常有效。我们的项目可在https://github.com/Wznnnnn/Heartcare-Suite 获取。", "summary": "Heartcare Suite是一个用于精细心电图（ECG）理解的综合多模态框架。它由三部分组成：Heartcare-220K数据集，用于疾病诊断、波形分析和心律解释；Heartcare-Bench基准，用于评估诊断智能和优化医疗多模态大语言模型；以及HeartcareGPT模型，该模型利用Beat分词器将原始多导联信号压缩为语义标记。HeartcareGPT在Heartcare-220K上表现出强大的泛化能力和最先进的性能，有效促进了ECG多模态理解和评估。", "keywords": "心电图理解, 多模态框架, Heartcare Suite, 原始多导联信号, 医疗AI", "comments": "该论文提出的Heartcare Suite框架通过整合高质量数据集、系统性评估基准和创新的模型HeartcareGPT，为ECG的多维度理解提供了一个全面的解决方案。特别是HeartcareGPT中将原始多导联信号压缩为语义丰富离散标记的方法，是其创新之处，有望显著提升ECG分析的效率和准确性。该项目对于医疗AI领域，尤其是心血管疾病的诊断和研究具有重要意义。"}}
{"id": "2506.05825", "title": "High Throughput Event Filtering: The Interpolation-based DIF Algorithm Hardware Architecture", "authors": ["Marcin Kowalczyk", "Tomasz Kryjak"], "summary": "In recent years, there has been rapid development in the field of event\nvision. It manifests itself both on the technical side, as better and better\nevent sensors are available, and on the algorithmic side, as more and more\napplications of this technology are proposed and scientific papers are\npublished. However, the data stream from these sensors typically contains a\nsignificant amount of noise, which varies depending on factors such as the\ndegree of illumination in the observed scene or the temperature of the sensor.\nWe propose a hardware architecture of the Distance-based Interpolation with\nFrequency Weights (DIF) filter and implement it on an FPGA chip. To evaluate\nthe algorithm and compare it with other solutions, we have prepared a new\nhigh-resolution event dataset, which we are also releasing to the community.\nOur architecture achieved a throughput of 403.39 million events per second\n(MEPS) for a sensor resolution of 1280 x 720 and 428.45 MEPS for a resolution\nof 640 x 480. The average values of the Area Under the Receiver Operating\nCharacteristic (AUROC) index ranged from 0.844 to 0.999, depending on the\ndataset, which is comparable to the state-of-the-art filtering solutions, but\nwith much higher throughput and better operation over a wide range of noise\nlevels.", "comment": "Accepted in the Microprocessors and Microsystems journal", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05825v1", "AI": {"title_translation": "高吞吐量事件滤波：基于插值的DIF算法硬件架构", "tldr": "本文提出了一种基于插值的DIF滤波器硬件架构，并在FPGA上实现，实现了高吞吐量和在宽噪声范围内的良好性能，并发布了一个新的高分辨率事件数据集。", "motivation": "事件视觉领域快速发展，但事件传感器的数据流通常包含大量噪声，且噪声水平随光照和传感器温度变化，这促使研究者开发更高效的噪声过滤解决方案。", "method": "本文提出了一种基于频率权重距离插值（DIF）滤波器的硬件架构，并在FPGA芯片上实现。为评估算法，作者准备并发布了一个新的高分辨率事件数据集。", "result": "该架构在1280x720分辨率下实现了403.39 MEPS的吞吐量，在640x480分辨率下实现了428.45 MEPS的吞吐量。接收者操作特征曲线下面积（AUROC）指数的平均值在0.844到0.999之间，与最先进的滤波解决方案相比，吞吐量更高，并且在宽噪声水平范围内表现更好。", "conclusion": "所提出的基于插值的DIF算法硬件架构在FPGA上实现，能够提供与现有最先进解决方案相当的滤波性能，但在吞吐量方面显著更高，并且在不同噪声水平下具有更优异的运行表现。", "translation": "近年来，事件视觉领域发展迅速。这体现在技术方面，有越来越好的事件传感器可用；也体现在算法方面，该技术被提出越来越多的应用，并发表了许多科学论文。然而，这些传感器的数据流通常包含大量的噪声，这些噪声根据观察场景的光照程度或传感器的温度等因素而变化。我们提出了一种基于频率权重距离插值（DIF）滤波器的硬件架构，并在FPGA芯片上实现。为了评估该算法并将其与其他解决方案进行比较，我们准备了一个新的高分辨率事件数据集，并将其发布给社区。我们的架构在1280 x 720的传感器分辨率下实现了每秒4.0339亿事件（MEPS）的吞吐量，在640 x 480的分辨率下实现了4.2845亿事件的吞吐量。接收者操作特征曲线下面积（AUROC）指数的平均值根据数据集的不同，范围从0.844到0.999，这与最先进的滤波解决方案相当，但吞吐量更高，并且在宽噪声水平范围内运行表现更好。", "summary": "本文针对事件视觉传感器数据流中存在的噪声问题，提出并实现了一种基于频率权重距离插值（DIF）算法的硬件架构，并在FPGA芯片上进行了验证。为评估性能，研究者创建并发布了一个新的高分辨率事件数据集。实验结果表明，该DIF硬件架构在不同分辨率下均实现了极高的事件吞吐量，并且在AUROC指标上与现有先进滤波方案相当，同时在更宽的噪声水平范围内表现出更好的操作性能。", "keywords": "事件滤波, 硬件架构, FPGA, DIF算法, 高吞吐量", "comments": "该论文的创新点在于提出了DIF算法的硬件实现，并将其部署在FPGA上，显著提升了事件滤波的吞吐量，这对于实时事件视觉应用至关重要。同时，发布新的高分辨率事件数据集也为社区的研究提供了宝贵的资源。其重要性体现在解决了事件相机噪声过滤的瓶颈问题，为未来事件视觉系统的发展奠定了基础。"}}
{"id": "2506.05857", "title": "Wavelet-based Disentangled Adaptive Normalization for Non-stationary Times Series Forecasting", "authors": ["Junpeng Lin", "Tian Lan", "Bo Zhang", "Ke Lin", "Dandan Miao", "Huiru He", "Jiantao Ye", "Chen Zhang", "Yan-fu Li"], "summary": "Forecasting non-stationary time series is a challenging task because their\nstatistical properties often change over time, making it hard for deep models\nto generalize well. Instance-level normalization techniques can help address\nshifts in temporal distribution. However, most existing methods overlook the\nmulti-component nature of time series, where different components exhibit\ndistinct non-stationary behaviors. In this paper, we propose Wavelet-based\nDisentangled Adaptive Normalization (WDAN), a model-agnostic framework designed\nto address non-stationarity in time series forecasting. WDAN uses discrete\nwavelet transforms to break down the input into low-frequency trends and\nhigh-frequency fluctuations. It then applies tailored normalization strategies\nto each part. For trend components that exhibit strong non-stationarity, we\napply first-order differencing to extract stable features used for predicting\nnormalization parameters. Extensive experiments on multiple benchmarks\ndemonstrate that WDAN consistently improves forecasting accuracy across various\nbackbone model. Code is available at this repository:\nhttps://github.com/MonBG/WDAN.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05857v1", "AI": {"title_translation": "小波分解自适应归一化用于非平稳时间序列预测", "tldr": "提出WDAN框架，利用小波变换分解时间序列并对不同分量应用定制归一化策略，有效提升非平稳时间序列预测精度。", "motivation": "预测非平稳时间序列是一项挑战，因为其统计特性随时间变化，导致深度模型泛化能力差。现有实例级归一化方法忽略时间序列的多分量性质，其中不同分量表现出独特的非平稳行为。", "method": "提出Wavelet-based Disentangled Adaptive Normalization (WDAN) 模型无关框架。WDAN使用离散小波变换将输入分解为低频趋势和高频波动，然后对每个部分应用定制的归一化策略。对于展现强非平稳性的趋势分量，应用一阶差分提取稳定特征，用于预测归一化参数。", "result": "在多个基准测试上进行的大量实验表明，WDAN持续提高各种骨干模型的预测精度。", "conclusion": "WDAN通过分解时间序列并定制归一化策略，有效解决了非平稳时间序列预测中的挑战，并显著提升了预测性能。", "translation": "预测非平稳时间序列是一项具有挑战性的任务，因为它们的统计特性经常随时间变化，使得深度模型难以很好地泛化。实例级归一化技术可以帮助解决时间分布的变化。然而，大多数现有方法忽略了时间序列的多分量性质，其中不同分量表现出独特的非平稳行为。在本文中，我们提出了基于小波分解的自适应归一化（WDAN），这是一个模型无关的框架，旨在解决时间序列预测中的非平稳性。WDAN使用离散小波变换将输入分解为低频趋势和高频波动。然后对每个部分应用定制的归一化策略。对于表现出强非平稳性的趋势分量，我们应用一阶差分来提取用于预测归一化参数的稳定特征。在多个基准测试上的大量实验表明，WDAN持续提高了各种骨干模型的预测精度。代码可在以下仓库获取：https://github.com/MonBG/WDAN。", "summary": "本文提出了Wavelet-based Disentangled Adaptive Normalization (WDAN) 框架，旨在解决非平稳时间序列预测中的挑战。WDAN利用离散小波变换将时间序列分解为低频趋势和高频波动，并对不同分量应用定制的归一化策略。特别是，对于趋势分量，采用一阶差分来提取稳定特征以预测归一化参数。实验结果表明，WDAN在多个基准测试上显著提高了各种骨干模型的预测精度。", "keywords": "非平稳时间序列预测, 小波变换, 自适应归一化", "comments": "该论文的创新点在于认识到时间序列的多分量性质，并利用小波变换将其分解，然后对不同频率分量应用定制的归一化策略，有效地处理了非平稳性。这种模型无关的框架具有良好的普适性，能够提升现有预测模型的性能。"}}
{"id": "2506.05843", "title": "FontAdapter: Instant Font Adaptation in Visual Text Generation", "authors": ["Myungkyu Koo", "Subin Kim", "Sangkyung Kwak", "Jaehyun Nam", "Seojin Kim", "Jinwoo Shin"], "summary": "Text-to-image diffusion models have significantly improved the seamless\nintegration of visual text into diverse image contexts. Recent approaches\nfurther improve control over font styles through fine-tuning with predefined\nfont dictionaries. However, adapting unseen fonts outside the preset is\ncomputationally expensive, often requiring tens of minutes, making real-time\ncustomization impractical. In this paper, we present FontAdapter, a framework\nthat enables visual text generation in unseen fonts within seconds, conditioned\non a reference glyph image. To this end, we find that direct training on font\ndatasets fails to capture nuanced font attributes, limiting generalization to\nnew glyphs. To overcome this, we propose a two-stage curriculum learning\napproach: FontAdapter first learns to extract font attributes from isolated\nglyphs and then integrates these styles into diverse natural backgrounds. To\nsupport this two-stage training scheme, we construct synthetic datasets\ntailored to each stage, leveraging large-scale online fonts effectively.\nExperiments demonstrate that FontAdapter enables high-quality, robust font\ncustomization across unseen fonts without additional fine-tuning during\ninference. Furthermore, it supports visual text editing, font style blending,\nand cross-lingual font transfer, positioning FontAdapter as a versatile\nframework for font customization tasks.", "comment": "Project page: https://fontadapter.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05843v1", "AI": {"title_translation": "FontAdapter：视觉文本生成中的即时字体适应", "tldr": "FontAdapter 实现了对新字体的快速适应，将视觉文本生成时间从数十分钟缩短到数秒，支持多种定制功能。", "motivation": "现有的文本到图像扩散模型虽然能很好地集成视觉文本，但对预定义字体字典之外的字体进行适应计算成本高昂（通常需要数十分钟），使得实时定制不切实际。", "method": "本文提出了 FontAdapter 框架，通过两阶段课程学习方法实现：FontAdapter 首先学习从孤立的字形中提取字体属性，然后将这些样式集成到不同的自然背景中。为支持此训练方案，构建了定制的合成数据集，并有效利用了大规模在线字体。", "result": "实验表明，FontAdapter 能够在推理过程中无需额外微调即可对未见字体进行高质量、鲁棒的字体定制。此外，它还支持视觉文本编辑、字体样式混合和跨语言字体迁移。", "conclusion": "FontAdapter 是一个多功能的字体定制框架，能够实现快速、高质量的字体适应和多种高级定制功能。", "translation": "文本到图像扩散模型显著改善了视觉文本与不同图像上下文的无缝集成。最近的方法通过使用预定义字体字典进行微调，进一步提高了对字体样式的控制。然而，适应预设之外的未见字体计算成本高昂，通常需要数十分钟，这使得实时定制不切实际。在本文中，我们提出了 FontAdapter，一个能够根据参考字形图像在数秒内生成未见字体视觉文本的框架。为此，我们发现直接在字体数据集上训练无法捕捉细微的字体属性，限制了对新字形的泛化能力。为了克服这个问题，我们提出了一种两阶段课程学习方法：FontAdapter 首先学习从孤立的字形中提取字体属性，然后将这些样式集成到不同的自然背景中。为了支持这种两阶段训练方案，我们构建了针对每个阶段定制的合成数据集，有效利用了大规模在线字体。实验表明，FontAdapter 能够在推理过程中无需额外微调即可对未见字体进行高质量、鲁棒的字体定制。此外，它还支持视觉文本编辑、字体样式混合和跨语言字体迁移，将 FontAdapter 定位为一个多功能的字体定制框架。", "summary": "FontAdapter 是一种新型框架，旨在解决现有文本到图像扩散模型在适应未见字体时计算成本高昂的问题。它采用两阶段课程学习方法，首先从字形中提取字体属性，然后将其融入自然背景，并利用定制的合成数据集进行训练。实验证明，FontAdapter 能在数秒内实现高质量、鲁棒的未见字体定制，并支持视觉文本编辑、字体样式混合和跨语言字体迁移，是一个多功能的字体定制解决方案。", "keywords": "字体适应, 视觉文本生成, 扩散模型, 课程学习, FontAdapter", "comments": "FontAdapter 的创新之处在于其两阶段课程学习方法和定制合成数据集，有效地解决了现有模型对新字体适应速度慢、泛化能力差的问题。它将字体适应时间从数十分钟缩短到数秒，极大地提高了实用性和实时性，并且支持多种高级字体定制功能，具有重要的应用价值。"}}
{"id": "2506.05869", "title": "Loss Functions for Predictor-based Neural Architecture Search", "authors": ["Han Ji", "Yuqi Feng", "Jiahao Fan", "Yanan Sun"], "summary": "Evaluation is a critical but costly procedure in neural architecture search\n(NAS). Performance predictors have been widely adopted to reduce evaluation\ncosts by directly estimating architecture performance. The effectiveness of\npredictors is heavily influenced by the choice of loss functions. While\ntraditional predictors employ regression loss functions to evaluate the\nabsolute accuracy of architectures, recent approaches have explored various\nranking-based loss functions, such as pairwise and listwise ranking losses, to\nfocus on the ranking of architecture performance. Despite their success in NAS,\nthe effectiveness and characteristics of these loss functions have not been\nthoroughly investigated. In this paper, we conduct the first comprehensive\nstudy on loss functions in performance predictors, categorizing them into three\nmain types: regression, ranking, and weighted loss functions. Specifically, we\nassess eight loss functions using a range of NAS-relevant metrics on 13 tasks\nacross five search spaces. Our results reveal that specific categories of loss\nfunctions can be effectively combined to enhance predictor-based NAS.\nFurthermore, our findings could provide practical guidance for selecting\nappropriate loss functions for various tasks. We hope this work provides\nmeaningful insights to guide the development of loss functions for\npredictor-based methods in the NAS community.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05869v1", "AI": {"title_translation": "基于预测器的神经架构搜索的损失函数", "tldr": "本文对神经架构搜索（NAS）中性能预测器使用的损失函数进行了首次全面研究，发现特定类别的损失函数可以有效结合以提升预测器性能，并为选择合适的损失函数提供了指导。", "motivation": "尽管损失函数在神经架构搜索（NAS）中取得了成功，但其有效性和特性尚未得到彻底研究。", "method": "本文对性能预测器中的损失函数进行了首次全面研究，将其分为回归、排序和加权三类。具体来说，在五个搜索空间中的13个任务上，使用一系列与NAS相关的指标评估了八种损失函数。", "result": "研究结果表明，特定类别的损失函数可以有效结合以增强基于预测器的神经架构搜索。", "conclusion": "研究结果为针对各种任务选择合适的损失函数提供了实用指导，并有望为NAS社区中基于预测器的方法的损失函数开发提供有意义的见解。", "translation": "评估是神经架构搜索（NAS）中一个关键但成本高昂的程序。性能预测器已被广泛采用以通过直接估计架构性能来降低评估成本。预测器的有效性受到损失函数选择的严重影响。虽然传统预测器采用回归损失函数来评估架构的绝对准确性，但最近的方法探索了各种基于排序的损失函数，例如成对和列表式排序损失，以关注架构性能的排序。尽管它们在NAS中取得了成功，但这些损失函数的有效性和特性尚未得到彻底研究。在本文中，我们对性能预测器中的损失函数进行了首次全面研究，将其分为三类：回归、排序和加权损失函数。具体来说，我们在五个搜索空间中的13个任务上，使用一系列与NAS相关的指标评估了八种损失函数。我们的结果表明，特定类别的损失函数可以有效结合以增强基于预测器的NAS。此外，我们的发现可以为针对各种任务选择合适的损失函数提供实用指导。我们希望这项工作能为NAS社区中基于预测器的方法的损失函数开发提供有意义的见解。", "summary": "神经架构搜索（NAS）中的评估成本高昂，性能预测器通过直接估计架构性能来降低成本，其有效性受损失函数选择的影响。传统预测器使用回归损失，而近期方法探索了排序损失。本文首次对性能预测器中的损失函数进行了全面研究，将其分为回归、排序和加权三类，并在13个任务和五个搜索空间中评估了八种损失函数。研究发现，特定类别的损失函数可以有效结合以提升基于预测器的NAS，并为选择合适的损失函数提供了实践指导。", "keywords": "神经架构搜索, 损失函数, 性能预测器, 回归损失, 排序损失", "comments": "本文对NAS中性能预测器所使用的损失函数进行了系统性的首次全面研究，填补了该领域的一个空白。其创新之处在于对损失函数进行了分类并进行了实证评估，为NAS社区提供了实用的指导和深刻见解，有助于未来损失函数的设计与开发。"}}
{"id": "2506.05856", "title": "Cross-View Multi-Modal Segmentation @ Ego-Exo4D Challenges 2025", "authors": ["Yuqian Fu", "Runze Wang", "Yanwei Fu", "Danda Pani Paudel", "Luc Van Gool"], "summary": "In this report, we present a cross-view multi-modal object segmentation\napproach for the object correspondence task in the Ego-Exo4D Correspondence\nChallenges 2025. Given object queries from one perspective (e.g., ego view),\nthe goal is to predict the corresponding object masks in another perspective\n(e.g., exo view). To tackle this task, we propose a multimodal condition fusion\nmodule that enhances object localization by leveraging both visual masks and\ntextual descriptions as segmentation conditions. Furthermore, to address the\nvisual domain gap between ego and exo views, we introduce a cross-view object\nalignment module that enforces object-level consistency across perspectives,\nthereby improving the model's robustness to viewpoint changes. Our proposed\nmethod ranked second on the leaderboard of the large-scale Ego-Exo4D object\ncorrespondence benchmark. Code will be made available at\nhttps://github.com/lovelyqian/ObjectRelator.", "comment": "The 2nd Price Award of EgoExo4D Relations, Second Joint EgoVis\n  Workshop with CVPR2025, technical report paper is accepted by CVPRW 25", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05856v1", "AI": {"title_translation": "跨视角多模态分割 @ Ego-Exo4D 2025挑战赛", "tldr": "本报告提出了一种跨视角多模态对象分割方法，用于Ego-Exo4D 2025挑战赛中的对象对应任务，通过多模态条件融合和跨视角对象对齐模块，提升了对象定位和跨视角一致性，并在排行榜上排名第二。", "motivation": "解决Ego-Exo4D 2025挑战赛中对象对应任务的跨视角多模态对象分割问题，特别是处理不同视角（如第一人称和第三人称视角）之间的视觉域差距。", "method": "提出了一种多模态条件融合模块，利用视觉遮罩和文本描述作为分割条件来增强对象定位。此外，引入了跨视角对象对齐模块，以强制跨视角的对象级一致性，从而提高模型对视角变化的鲁棒性。", "result": "所提出的方法在大型Ego-Exo4D对象对应基准测试的排行榜上排名第二。", "conclusion": "该方法通过多模态条件融合和跨视角对象对齐，有效解决了跨视角多模态对象分割任务，并在Ego-Exo4D挑战赛中取得了优异成绩。", "translation": "在本报告中，我们提出了一种跨视角多模态对象分割方法，用于Ego-Exo4D 2025对应挑战赛中的对象对应任务。给定来自一个视角（例如，第一人称视角）的对象查询，目标是预测另一个视角（例如，第三人称视角）中对应的对象遮罩。为了解决这项任务，我们提出了一种多模态条件融合模块，通过利用视觉遮罩和文本描述作为分割条件来增强对象定位。此外，为了解决第一人称视角和第三人称视角之间的视觉域差距，我们引入了一个跨视角对象对齐模块，该模块强制跨视角的对象级一致性，从而提高了模型对视角变化的鲁棒性。我们提出的方法在大型Ego-Exo4D对象对应基准测试的排行榜上排名第二。代码将在https://github.com/lovelyqian/ObjectRelator 提供。", "summary": "本报告介绍了一种为Ego-Exo4D 2025挑战赛设计的跨视角多模态对象分割方法。该方法旨在根据一个视角的对象查询，预测另一个视角中对应的对象遮罩。为实现此目标，论文提出了一个多模态条件融合模块，结合视觉遮罩和文本描述以提升对象定位；同时，引入了跨视角对象对齐模块，以解决不同视角间的视觉域差距并增强模型对视角变化的鲁棒性。该方法在Ego-Exo4D对象对应基准测试中排名第二。", "keywords": "跨视角分割, 多模态融合, 对象对应, Ego-Exo4D, 视觉对齐", "comments": "该论文的创新点在于提出了多模态条件融合模块和跨视角对象对齐模块，有效地结合了视觉和文本信息，并解决了跨视角数据的一致性问题。其在Ego-Exo4D挑战赛中取得第二名的成绩，表明了该方法的有效性和竞争力。这项工作对于未来多视角、多模态对象理解和分割任务具有重要意义。"}}
{"id": "2506.05858", "title": "ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On", "authors": ["Jinjuan Wang", "Wenzhang Sun", "Ming Li", "Yun Zheng", "Fanyao Li", "Zhulin Tao", "Donglin Di", "Hao Li", "Wei Chen", "Xianglin Huang"], "summary": "Video virtual try-on aims to seamlessly replace the clothing of a person in a\nsource video with a target garment. Despite significant progress in this field,\nexisting approaches still struggle to maintain continuity and reproduce garment\ndetails. In this paper, we introduce ChronoTailor, a diffusion-based framework\nthat generates temporally consistent videos while preserving fine-grained\ngarment details. By employing a precise spatio-temporal attention mechanism to\nguide the integration of fine-grained garment features, ChronoTailor achieves\nrobust try-on performance. First, ChronoTailor leverages region-aware spatial\nguidance to steer the evolution of spatial attention and employs an\nattention-driven temporal feature fusion mechanism to generate more continuous\ntemporal features. This dual approach not only enables fine-grained local\nediting but also effectively mitigates artifacts arising from video dynamics.\nSecond, ChronoTailor integrates multi-scale garment features to preserve\nlow-level visual details and incorporates a garment-pose feature alignment to\nensure temporal continuity during dynamic motion. Additionally, we collect\nStyleDress, a new dataset featuring intricate garments, varied environments,\nand diverse poses, offering advantages over existing public datasets, and will\nbe publicly available for research. Extensive experiments show that\nChronoTailor maintains spatio-temporal continuity and preserves garment details\nduring motion, significantly outperforming previous methods.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05858v1", "AI": {"title_translation": "ChronoTailor：利用注意力引导实现细粒度视频虚拟试穿", "tldr": "ChronoTailor是一种基于扩散的视频虚拟试穿框架，通过精确的时空注意力机制，在保持时间一致性和细粒度服装细节方面优于现有方法，并引入了新数据集StyleDress。", "motivation": "现有视频虚拟试穿方法难以保持时间连续性并重现服装细节。", "method": "ChronoTailor是一个基于扩散的框架，通过精确的时空注意力机制引导细粒度服装特征的整合。它利用区域感知空间引导和注意力驱动的时间特征融合机制生成更连续的时间特征，实现细粒度局部编辑并减轻视频动态伪影。此外，它整合多尺度服装特征以保留低级视觉细节，并结合服装-姿态特征对齐以确保动态运动中的时间连续性。研究还收集并发布了新数据集StyleDress。", "result": "ChronoTailor在运动过程中保持了时空连续性并保留了服装细节，显著优于以往的方法。", "conclusion": "ChronoTailor通过其创新的注意力引导机制和特征整合策略，成功解决了视频虚拟试穿中时间一致性和细节保留的挑战，实现了卓越的性能。", "translation": "视频虚拟试穿旨在将源视频中人物的服装与目标服装无缝替换。尽管该领域取得了显著进展，但现有方法仍难以保持连续性和重现服装细节。在本文中，我们引入了ChronoTailor，一个基于扩散的框架，它在保持细粒度服装细节的同时生成时间一致的视频。通过采用精确的时空注意力机制来引导细粒度服装特征的整合，ChronoTailor实现了鲁棒的试穿性能。首先，ChronoTailor利用区域感知空间引导来控制空间注意力的演变，并采用注意力驱动的时间特征融合机制来生成更连续的时间特征。这种双重方法不仅能够实现细粒度局部编辑，还能有效减轻视频动态引起的伪影。其次，ChronoTailor整合了多尺度服装特征以保留低级视觉细节，并结合服装-姿态特征对齐以确保动态运动中的时间连续性。此外，我们收集了StyleDress，一个包含复杂服装、多样环境和不同姿态的新数据集，与现有公共数据集相比具有优势，并将公开发布供研究使用。大量实验表明，ChronoTailor在运动过程中保持了时空连续性并保留了服装细节，显著优于以往的方法。", "summary": "ChronoTailor是一种新颖的基于扩散的视频虚拟试穿框架，旨在解决现有方法在时间连续性和服装细节保留方面的不足。它通过引入精确的时空注意力机制、区域感知空间引导、注意力驱动的时间特征融合以及多尺度特征整合和服装-姿态特征对齐来实现细粒度局部编辑和动态运动中的时间一致性。此外，该研究还推出了一个包含复杂服装和多样姿态的新数据集StyleDress。实验证明，ChronoTailor在保持时空连续性和服装细节方面显著优于现有方法。", "keywords": "视频虚拟试穿, 扩散模型, 注意力机制, 时间一致性, 服装细节", "comments": "ChronoTailor的创新之处在于其结合了扩散模型与精细化的时空注意力引导机制，有效解决了视频虚拟试穿中长期存在的连续性和细节丢失问题。新数据集StyleDress的发布也为该领域的研究提供了宝贵的资源，有助于推动未来的发展。"}}
{"id": "2506.05877", "title": "Interpretable Clustering Ensemble", "authors": ["Hang Lv", "Lianyu Hu", "Mudi Jiang", "Xinying Liu", "Zengyou He"], "summary": "Clustering ensemble has emerged as an important research topic in the field\nof machine learning. Although numerous methods have been proposed to improve\nclustering quality, most existing approaches overlook the need for\ninterpretability in high-stakes applications. In domains such as medical\ndiagnosis and financial risk assessment, algorithms must not only be accurate\nbut also interpretable to ensure transparent and trustworthy decision-making.\nTherefore, to fill the gap of lack of interpretable algorithms in the field of\nclustering ensemble, we propose the first interpretable clustering ensemble\nalgorithm in the literature. By treating base partitions as categorical\nvariables, our method constructs a decision tree in the original feature space\nand use the statistical association test to guide the tree building process.\nExperimental results demonstrate that our algorithm achieves comparable\nperformance to state-of-the-art (SOTA) clustering ensemble methods while\nmaintaining an additional feature of interpretability. To the best of our\nknowledge, this is the first interpretable algorithm specifically designed for\nclustering ensemble, offering a new perspective for future research in\ninterpretable clustering.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05877v1", "AI": {"title_translation": "可解释聚类集成", "tldr": "提出了第一个可解释的聚类集成算法，通过构建决策树实现，性能与现有最佳方法相当，同时具备可解释性。", "motivation": "现有聚类集成方法忽视了高风险应用（如医疗诊断、金融风险评估）中对可解释性的需求，导致决策不透明、不可信。", "method": "将基础分区视为分类变量，在原始特征空间中构建决策树，并利用统计关联测试指导树的构建过程。", "result": "算法性能与最先进的聚类集成方法相当，同时保持了可解释性的额外特性。", "conclusion": "提出了文献中第一个专门为聚类集成设计的可解释算法，为未来可解释聚类研究提供了新视角。", "translation": "聚类集成已成为机器学习领域的一个重要研究课题。尽管已经提出了许多方法来提高聚类质量，但大多数现有方法忽略了在高风险应用中对可解释性的需求。在医疗诊断和金融风险评估等领域，算法不仅必须准确，而且必须可解释，以确保透明和值得信赖的决策。因此，为了填补聚类集成领域缺乏可解释算法的空白，我们提出了文献中第一个可解释聚类集成算法。通过将基础分区视为分类变量，我们的方法在原始特征空间中构建决策树，并使用统计关联测试来指导树的构建过程。实验结果表明，我们的算法实现了与最先进（SOTA）聚类集成方法相当的性能，同时保持了可解释性的额外特性。据我们所知，这是第一个专门为聚类集成设计的可解释算法，为未来可解释聚类研究提供了新的视角。", "summary": "聚类集成是机器学习中的重要研究课题，但现有方法在高风险应用中缺乏可解释性。为解决此问题，本文提出了首个可解释聚类集成算法。该方法将基础分区视为分类变量，在原始特征空间中构建决策树，并利用统计关联测试指导树的构建。实验结果表明，该算法在保持可解释性的同时，性能与最先进的聚类集成方法相当。", "keywords": "聚类集成, 可解释性, 决策树, 统计关联测试", "comments": "这篇论文的创新点在于首次将可解释性引入聚类集成领域，解决了高风险应用中透明度和可信度不足的问题。其方法通过决策树在原始特征空间进行解释，为理解聚类结果提供了清晰的路径。这对于推动可解释AI的发展具有重要意义，尤其是在需要决策依据的敏感领域。"}}
{"id": "2506.05862", "title": "Improved Allergy Wheal Detection for the Skin Prick Automated Test Device", "authors": ["Rembert Daems", "Sven Seys", "Valérie Hox", "Adam Chaker", "Glynnis De Greve", "Winde Lemmens", "Anne-Lise Poirrier", "Eline Beckers", "Zuzana Diamant", "Carmen Dierickx", "Peter W. Hellings", "Caroline Huart", "Claudia Jerin", "Mark Jorissen", "Hanne Oscé", "Karolien Roux", "Mark Thompson", "Sophie Tombu", "Saartje Uyttebroek", "Andrzej Zarowski", "Senne Gorris", "Laura Van Gerven", "Dirk Loeckx", "Thomas Demeester"], "summary": "Background: The skin prick test (SPT) is the gold standard for diagnosing\nsensitization to inhalant allergies. The Skin Prick Automated Test (SPAT)\ndevice was designed for increased consistency in test results, and captures 32\nimages to be jointly used for allergy wheal detection and delineation, which\nleads to a diagnosis.\n  Materials and Methods: Using SPAT data from $868$ patients with suspected\ninhalant allergies, we designed an automated method to detect and delineate\nwheals on these images. To this end, $10,416$ wheals were manually annotated by\ndrawing detailed polygons along the edges. The unique data-modality of the SPAT\ndevice, with $32$ images taken under distinct lighting conditions, requires a\ncustom-made approach. Our proposed method consists of two parts: a neural\nnetwork component that segments the wheals on the pixel level, followed by an\nalgorithmic and interpretable approach for detecting and delineating the\nwheals.\n  Results: We evaluate the performance of our method on a hold-out validation\nset of $217$ patients. As a baseline we use a single conventionally lighted\nimage per SPT as input to our method.\n  Conclusion: Using the $32$ SPAT images under various lighting conditions\noffers a considerably higher accuracy than a single image in conventional,\nuniform light.", "comment": "This work is presented at Artificial Intelligence in Medicine 2025,\n  this is the longer (10 pages) version", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05862v1", "AI": {"title_translation": "改进的皮肤点刺自动化测试设备过敏风团检测", "tldr": "开发了一种利用32张不同光照图像的自动化方法，显著提高了皮肤点刺测试中过敏风团检测的准确性。", "motivation": "皮肤点刺测试（SPT）是诊断吸入性过敏原致敏的金标准。皮肤点刺自动化测试（SPAT）设备旨在提高测试结果的一致性。本研究的动机是设计一种自动化方法来检测和描绘SPAT设备捕获的过敏风团，以实现诊断，并克服传统方法在处理SPAT独特多模态数据时的局限性。", "method": "使用来自868名疑似吸入性过敏患者的SPAT数据，其中10,416个风团被手动标注。由于SPAT设备在不同光照条件下拍摄32张图像的独特数据模式，采用了一种定制方法。该方法包含两部分：一个用于像素级风团分割的神经网络组件，以及一个用于检测和描绘风团的算法化和可解释性方法。", "result": "该方法在217名患者的保留验证集上进行了评估。结果表明，与使用单张传统光照图像作为基线相比，使用32张SPAT图像在各种光照条件下提供了显著更高的准确性。", "conclusion": "利用32张不同光照条件下的SPAT图像进行过敏风团检测，比仅使用单张传统均匀光照图像能提供更高的准确性。", "translation": "背景：皮肤点刺测试（SPT）是诊断吸入性过敏原致敏的金标准。皮肤点刺自动化测试（SPAT）设备旨在提高测试结果的一致性，并捕获32张图像，这些图像共同用于过敏风团的检测和描绘，从而得出诊断。\n材料与方法：我们使用来自868名疑似吸入性过敏患者的SPAT数据，设计了一种自动化方法来检测和描绘这些图像上的风团。为此，10,416个风团通过沿边缘绘制详细多边形的方式进行手动标注。SPAT设备在不同光照条件下拍摄32张图像的独特数据模式，需要一种定制的方法。我们提出的方法包括两部分：一个在像素级别分割风团的神经网络组件，随后是一个用于检测和描绘风团的算法化和可解释性方法。\n结果：我们在217名患者的保留验证集上评估了我们方法的性能。作为基线，我们使用每张SPT的单张常规光照图像作为我们方法的输入。\n结论：与使用单张传统均匀光照图像相比，使用32张SPAT图像在各种光照条件下能提供显著更高的准确性。", "summary": "本文提出了一种改进的自动化方法，用于皮肤点刺自动化测试（SPAT）设备中的过敏风团检测和描绘。该方法利用SPAT设备在不同光照条件下捕获的32张图像的独特数据模式，结合神经网络进行像素级分割和算法化方法进行风团检测。实验结果表明，与仅使用单张传统光照图像相比，利用多张图像显著提高了风团检测的准确性。", "keywords": "皮肤点刺测试, 过敏风团检测, 自动化测试设备, 神经网络, 图像处理", "comments": "这项研究通过利用SPAT设备独特的32张多光照图像数据，解决了传统过敏风团检测的挑战。其创新之处在于结合了神经网络和可解释性算法，为医学诊断提供了更准确、更一致的自动化解决方案，有望提高过敏诊断的效率和可靠性。"}}
{"id": "2506.05878", "title": "A projection-based framework for gradient-free and parallel learning", "authors": ["Andreas Bergmeister", "Manish Krishan Lal", "Stefanie Jegelka", "Suvrit Sra"], "summary": "We present a feasibility-seeking approach to neural network training. This\nmathematical optimization framework is distinct from conventional\ngradient-based loss minimization and uses projection operators and iterative\nprojection algorithms. We reformulate training as a large-scale feasibility\nproblem: finding network parameters and states that satisfy local constraints\nderived from its elementary operations. Training then involves projecting onto\nthese constraints, a local operation that can be parallelized across the\nnetwork. We introduce PJAX, a JAX-based software framework that enables this\nparadigm. PJAX composes projection operators for elementary operations,\nautomatically deriving the solution operators for the feasibility problems\n(akin to autodiff for derivatives). It inherently supports GPU/TPU\nacceleration, provides a familiar NumPy-like API, and is extensible. We train\ndiverse architectures (MLPs, CNNs, RNNs) on standard benchmarks using PJAX,\ndemonstrating its functionality and generality. Our results show that this\napproach is as a compelling alternative to gradient-based training, with clear\nadvantages in parallelism and the ability to handle non-differentiable\noperations.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05878v1", "AI": {"title_translation": "基于投影的无梯度并行学习框架", "tldr": "PJAX是一个基于投影的无梯度神经网络训练框架，它通过将训练重构为可行性问题来实现并行化，并能处理不可微分操作。", "motivation": "传统的基于梯度的损失最小化方法存在局限性，特别是在并行化和处理不可微分操作方面。", "method": "本文提出了一种可行性寻求方法来训练神经网络。该框架将训练重构为一个大规模可行性问题，即找到满足其基本操作派生出的局部约束的网络参数和状态。训练涉及对这些约束进行投影，这是一种可以在网络中并行化的局部操作。为此，引入了PJAX，一个基于JAX的软件框架，它能自动导出可行性问题的解算子，并支持GPU/TPU加速。", "result": "PJAX在标准基准上训练了多种架构（MLPs、CNNs、RNNs），展示了其功能性和通用性。结果表明，这种方法是梯度训练的一个有力的替代方案，在并行性和处理不可微分操作方面具有明显优势。", "conclusion": "基于投影的神经网络训练方法是一种有前景的替代方案，它克服了传统梯度方法的局限性，尤其在并行处理和支持不可微分操作方面表现出色。", "translation": "我们提出了一种用于神经网络训练的可行性寻求方法。这种数学优化框架不同于传统的基于梯度的损失最小化，它使用投影算子和迭代投影算法。我们将训练重构为一个大规模的可行性问题：找到满足其基本操作派生出的局部约束的网络参数和状态。训练然后涉及对这些约束进行投影，这是一种可以在网络中并行化的局部操作。我们引入了PJAX，一个基于JAX的软件框架，它实现了这种范式。PJAX为基本操作组合投影算子，自动导出可行性问题的解算子（类似于导数的自动微分）。它固有地支持GPU/TPU加速，提供熟悉的NumPy-like API，并且可扩展。我们使用PJAX在标准基准上训练了多种架构（MLPs、CNNs、RNNs），展示了其功能性和通用性。我们的结果表明，这种方法是梯度训练的一个有力的替代方案，在并行性和处理不可微分操作方面具有明显优势。", "summary": "本文提出了一种名为PJAX的基于投影的无梯度并行神经网络训练框架。该方法将传统训练重构为大规模可行性问题，利用投影算子和迭代投影算法，实现参数和状态对局部约束的满足。PJAX是一个JAX-based软件，支持GPU/TPU加速，并能自动导出解算子。实验证明，PJAX能有效训练MLPs、CNNs、RNNs等多种架构，并在并行性和处理不可微分操作方面优于传统梯度方法，是其有力的替代方案。", "keywords": "投影学习, 无梯度训练, 并行学习, 神经网络, 可行性问题", "comments": "该论文的创新之处在于将神经网络训练重新定义为一个可行性问题，并利用投影操作来解决，从而实现了无梯度和高度并行的学习范式。其重要性体现在为克服传统梯度下降法的局限性（如对可微分性的依赖和并行化挑战）提供了新思路。"}}
{"id": "2506.05864", "title": "CryoFastAR: Fast Cryo-EM Ab Initio Reconstruction Made Easy", "authors": ["Jiakai Zhang", "Shouchen Zhou", "Haizhao Dai", "Xinhang Liu", "Peihao Wang", "Zhiwen Fan", "Yuan Pei", "Jingyi Yu"], "summary": "Pose estimation from unordered images is fundamental for 3D reconstruction,\nrobotics, and scientific imaging. Recent geometric foundation models, such as\nDUSt3R, enable end-to-end dense 3D reconstruction but remain underexplored in\nscientific imaging fields like cryo-electron microscopy (cryo-EM) for\nnear-atomic protein reconstruction. In cryo-EM, pose estimation and 3D\nreconstruction from unordered particle images still depend on time-consuming\niterative optimization, primarily due to challenges such as low signal-to-noise\nratios (SNR) and distortions from the contrast transfer function (CTF). We\nintroduce CryoFastAR, the first geometric foundation model that can directly\npredict poses from Cryo-EM noisy images for Fast ab initio Reconstruction. By\nintegrating multi-view features and training on large-scale simulated cryo-EM\ndata with realistic noise and CTF modulations, CryoFastAR enhances pose\nestimation accuracy and generalization. To enhance training stability, we\npropose a progressive training strategy that first allows the model to extract\nessential features under simpler conditions before gradually increasing\ndifficulty to improve robustness. Experiments show that CryoFastAR achieves\ncomparable quality while significantly accelerating inference over traditional\niterative approaches on both synthetic and real datasets.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05864v1", "AI": {"title_translation": "CryoFastAR：快速冷冻电镜从头重建变得容易", "tldr": "CryoFastAR是一个新的几何基础模型，可以直接从冷冻电镜噪声图像中预测姿态，实现快速从头重建，比传统方法更快且质量相当。", "motivation": "冷冻电镜中的姿态估计和3D重建仍依赖耗时的迭代优化，主要原因是低信噪比和CTF畸变。现有的几何基础模型在冷冻电镜领域尚未充分探索。", "method": "本文引入了CryoFastAR，它是第一个可以直接从冷冻电镜噪声图像中预测姿态以实现快速从头重建的几何基础模型。该模型通过整合多视图特征，并在大规模模拟冷冻电镜数据上进行训练，这些数据包含了真实的噪声和CTF调制。为提高训练稳定性，模型采用了一种渐进式训练策略。", "result": "CryoFastAR在合成和真实数据集上均能达到与传统迭代方法相当的重建质量，同时显著加速了推理过程。", "conclusion": "CryoFastAR成功地将几何基础模型引入冷冻电镜领域，解决了传统迭代方法耗时的问题，实现了快速且高质量的从头重建。", "translation": "从无序图像中进行姿态估计是3D重建、机器人技术和科学成像的基础。最近的几何基础模型，如DUSt3R，实现了端到端的密集3D重建，但在冷冻电子显微镜（cryo-EM）等科学成像领域（用于近原子级蛋白质重建）中仍未得到充分探索。在冷冻电镜中，从无序粒子图像中进行姿态估计和3D重建仍然依赖于耗时的迭代优化，这主要是由于低信噪比（SNR）和对比度传递函数（CTF）引起的畸变等挑战。我们引入了CryoFastAR，这是第一个可以直接从冷冻电镜噪声图像中预测姿态以实现快速从头重建的几何基础模型。通过整合多视图特征并在包含真实噪声和CTF调制的、大规模模拟冷冻电镜数据上进行训练，CryoFastAR提高了姿态估计的准确性和泛化能力。为了提高训练稳定性，我们提出了一种渐进式训练策略，该策略首先允许模型在更简单的条件下提取基本特征，然后逐渐增加难度以提高鲁棒性。实验表明，CryoFastAR在合成和真实数据集上均能达到可比的质量，同时显著加速了相对于传统迭代方法的推理过程。", "summary": "本文介绍了CryoFastAR，一个专门为冷冻电镜从头重建设计的几何基础模型。针对冷冻电镜图像的低信噪比和CTF畸变导致的传统迭代优化耗时问题，CryoFastAR通过整合多视图特征并在大规模模拟数据上进行渐进式训练，实现了直接从噪声图像中预测姿态。实验证明，CryoFastAR在保持重建质量的同时，显著提升了重建速度。", "keywords": "冷冻电镜, 3D重建, 姿态估计, 几何基础模型, 从头重建", "comments": "CryoFastAR的创新之处在于它是首个将几何基础模型应用于冷冻电镜从头重建的尝试，解决了该领域长期存在的计算耗时问题。其渐进式训练策略对于处理冷冻电镜图像的复杂性（如低信噪比和CTF效应）至关重要。该方法有望加速蛋白质结构解析。"}}
{"id": "2506.05880", "title": "NILMFormer: Non-Intrusive Load Monitoring that Accounts for Non-Stationarity", "authors": ["Adrien Petralia", "Philippe Charpentier", "Youssef Kadhi", "Themis Palpanas"], "summary": "Millions of smart meters have been deployed worldwide, collecting the total\npower consumed by individual households. Based on these data, electricity\nsuppliers offer their clients energy monitoring solutions to provide feedback\non the consumption of their individual appliances. Historically, such estimates\nhave relied on statistical methods that use coarse-grained total monthly\nconsumption and static customer data, such as appliance ownership.\nNon-Intrusive Load Monitoring (NILM) is the problem of disaggregating a\nhousehold's collected total power consumption to retrieve the consumed power\nfor individual appliances. Current state-of-the-art (SotA) solutions for NILM\nare based on deep-learning (DL) and operate on subsequences of an entire\nhousehold consumption reading. However, the non-stationary nature of real-world\nsmart meter data leads to a drift in the data distribution within each\nsegmented window, which significantly affects model performance. This paper\nintroduces NILMFormer, a Transformer-based architecture that incorporates a new\nsubsequence stationarization/de-stationarization scheme to mitigate the\ndistribution drift and that uses a novel positional encoding that relies only\non the subsequence's timestamp information. Experiments with 4 real-world\ndatasets show that NILMFormer significantly outperforms the SotA approaches.\nOur solution has been deployed as the backbone algorithm for EDF's\n(Electricit\\'e De France) consumption monitoring service, delivering detailed\ninsights to millions of customers about their individual appliances' power\nconsumption. This paper appeared in KDD 2025.", "comment": "12 pages, 8 figures. This paper appeared in ACM SIGKDD 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05880v1", "AI": {"title_translation": "NILMFormer：考虑非平稳性的非侵入式负荷监测", "tldr": "NILMFormer是一种基于Transformer的非侵入式负荷监测（NILM）解决方案，通过引入子序列平稳化方案和新颖的位置编码，有效解决了智能电表数据中的非平稳性问题，显著优于现有技术并已实际部署。", "motivation": "现有的非侵入式负荷监测（NILM）解决方案，特别是基于深度学习的方法，在处理真实世界智能电表数据时，由于数据的非平稳性导致数据分布漂移，从而显著影响模型性能。", "method": "本文提出NILMFormer，一个基于Transformer的架构。该架构包含一个新的子序列平稳化/去平稳化方案，以减轻数据分布漂移，并使用一种仅依赖子序列时间戳信息的新颖位置编码。", "result": "在4个真实世界数据集上的实验表明，NILMFormer显著优于现有最先进的方法。该解决方案已被部署为法国电力公司（EDF）功耗监测服务的核心算法，为数百万客户提供详细的家电功耗洞察。", "conclusion": "NILMFormer通过其创新的平稳化方案和位置编码，成功克服了NILM中智能电表数据的非平稳性挑战，实现了卓越的性能，并已在实际应用中得到验证。", "translation": "全球已部署数百万智能电表，收集各个家庭的总用电量。基于这些数据，电力供应商为客户提供能源监测解决方案，以反馈其各个电器的消耗情况。历史上，此类估算依赖于统计方法，这些方法使用粗粒度的每月总消耗量和静态客户数据（例如电器所有权）。非侵入式负荷监测（NILM）是分解家庭收集到的总用电量以获取各个电器消耗功率的问题。当前最先进的NILM解决方案基于深度学习（DL），并对整个家庭消耗读数的子序列进行操作。然而，真实世界智能电表数据的非平稳性导致每个分段窗口内数据分布的漂移，这显著影响模型性能。本文介绍了NILMFormer，一个基于Transformer的架构，它结合了一种新的子序列平稳化/去平稳化方案来减轻分布漂移，并使用一种仅依赖子序列时间戳信息的新颖位置编码。在4个真实世界数据集上的实验表明，NILMFormer显著优于现有最先进的方法。我们的解决方案已被部署为法国电力公司（EDF）功耗监测服务的核心算法，为数百万客户提供关于其各个电器功耗的详细洞察。本文发表于KDD 2025。", "summary": "NILMFormer是一种基于Transformer的非侵入式负荷监测（NILM）模型，旨在解决智能电表数据非平稳性导致的数据分布漂移问题。它引入了子序列平稳化/去平稳化方案和基于时间戳的新型位置编码。实验证明，NILMFormer在多个真实数据集上显著超越现有技术，并已成功应用于法国电力公司的消费监测服务，为数百万用户提供电器功耗分析。", "keywords": "非侵入式负荷监测, NILM, Transformer, 非平稳性, 智能电表", "comments": "本文的创新点在于其Transformer架构中引入的子序列平稳化/去平稳化方案和基于时间戳的新颖位置编码，有效解决了NILM领域中长期存在的非平稳性数据漂移问题。其在EDF的实际部署，充分证明了该方案的实用性和重要性，对于智能电网和能源管理具有重要的应用价值。"}}
{"id": "2506.05872", "title": "Domain-RAG: Retrieval-Guided Compositional Image Generation for Cross-Domain Few-Shot Object Detection", "authors": ["Yu Li", "Xingyu Qiu", "Yuqian Fu", "Jie Chen", "Tianwen Qian", "Xu Zheng", "Danda Pani Paudel", "Yanwei Fu", "Xuanjing Huang", "Luc Van Gool", "Yu-Gang Jiang"], "summary": "Cross-Domain Few-Shot Object Detection (CD-FSOD) aims to detect novel objects\nwith only a handful of labeled samples from previously unseen domains. While\ndata augmentation and generative methods have shown promise in few-shot\nlearning, their effectiveness for CD-FSOD remains unclear due to the need for\nboth visual realism and domain alignment. Existing strategies, such as\ncopy-paste augmentation and text-to-image generation, often fail to preserve\nthe correct object category or produce backgrounds coherent with the target\ndomain, making them non-trivial to apply directly to CD-FSOD. To address these\nchallenges, we propose Domain-RAG, a training-free, retrieval-guided\ncompositional image generation framework tailored for CD-FSOD. Domain-RAG\nconsists of three stages: domain-aware background retrieval, domain-guided\nbackground generation, and foreground-background composition. Specifically, the\ninput image is first decomposed into foreground and background regions. We then\nretrieve semantically and stylistically similar images to guide a generative\nmodel in synthesizing a new background, conditioned on both the original and\nretrieved contexts. Finally, the preserved foreground is composed with the\nnewly generated domain-aligned background to form the generated image. Without\nrequiring any additional supervision or training, Domain-RAG produces\nhigh-quality, domain-consistent samples across diverse tasks, including\nCD-FSOD, remote sensing FSOD, and camouflaged FSOD. Extensive experiments show\nconsistent improvements over strong baselines and establish new\nstate-of-the-art results. Codes will be released upon acceptance.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05872v1", "AI": {"title_translation": "Domain-RAG: 检索引导的组合图像生成用于跨域少样本目标检测", "tldr": "Domain-RAG是一个无需训练的框架，通过检索引导的组合图像生成来解决跨域少样本目标检测中的视觉真实性和域对齐问题，并取得了最先进的结果。", "motivation": "现有的数据增强和生成方法在跨域少样本目标检测（CD-FSOD）中效果不佳，因为它们难以同时保证视觉真实性和域对齐，例如复制粘贴增强和文本到图像生成无法保留正确的对象类别或生成与目标域一致的背景。", "method": "提出Domain-RAG，一个无需训练、检索引导的组合图像生成框架。它包含三个阶段：域感知背景检索、域引导背景生成和前景背景合成。具体来说，输入图像被分解为前景和背景区域，然后检索语义和风格相似的图像来引导生成模型合成新的背景，最后将保留的前景与新生成的域对齐背景进行合成。", "result": "Domain-RAG在无需额外监督或训练的情况下，能够生成高质量、域一致的样本，并在CD-FSOD、遥感FSOD和伪装FSOD等多样任务中，始终优于强基线方法，并建立了新的最先进结果。", "conclusion": "Domain-RAG通过其检索引导的组合图像生成方法，有效解决了跨域少样本目标检测中的挑战，显著提升了性能并达到了新的最先进水平。", "translation": "跨域少样本目标检测（CD-FSOD）旨在仅用少量来自未见过域的带标签样本来检测新颖对象。尽管数据增强和生成方法在少样本学习中展现出潜力，但由于需要同时考虑视觉真实性和域对齐，它们在CD-FSOD中的有效性仍不明确。现有策略，例如复制粘贴增强和文本到图像生成，往往无法保留正确的对象类别或生成与目标域一致的背景，这使得它们难以直接应用于CD-FSOD。为了应对这些挑战，我们提出了Domain-RAG，一个无需训练、检索引导的组合图像生成框架，专为CD-FSOD量身定制。Domain-RAG由三个阶段组成：域感知背景检索、域引导背景生成和前景背景合成。具体来说，输入图像首先被分解为前景和背景区域。然后，我们检索语义和风格相似的图像，以指导生成模型合成新的背景，该背景以原始和检索到的上下文为条件。最后，将保留的前景与新生成的域对齐背景进行合成，以形成生成的图像。在不需要任何额外监督或训练的情况下，Domain-RAG在包括CD-FSOD、遥感FSOD和伪装FSOD在内的各种任务中生成高质量、域一致的样本。广泛的实验表明，该方法持续优于强基线并建立了新的最先进结果。代码将在接受后发布。", "summary": "该论文提出了Domain-RAG，一个无需训练的检索引导组合图像生成框架，旨在解决跨域少样本目标检测（CD-FSOD）中现有数据增强和生成方法面临的视觉真实性和域对齐挑战。Domain-RAG通过将输入图像分解为前景和背景，然后检索相似图像指导新背景生成，并最终与前景合成，从而产生高质量、域一致的样本。实验证明，该方法在多种FSOD任务中均取得了优于现有方法的性能，并达到了新的最先进水平。", "keywords": "跨域少样本目标检测, 图像生成, 数据增强, 检索引导, 域对齐", "comments": "Domain-RAG的创新之处在于其“无需训练”和“检索引导的组合图像生成”方法，这有效避免了传统生成模型在跨域少样本场景中难以平衡视觉真实性和域对齐的问题。该框架通过分解图像、智能检索和引导生成，提供了一个实用的解决方案，对少样本目标检测领域具有重要意义。其在多种FSOD任务中展现的优越性能证明了其有效性和通用性。"}}
{"id": "2506.05895", "title": "Few Labels are all you need: A Weakly Supervised Framework for Appliance Localization in Smart-Meter Series", "authors": ["Adrien Petralia", "Paul Boniol", "Philippe Charpentier", "Themis Palpanas"], "summary": "Improving smart grid system management is crucial in the fight against\nclimate change, and enabling consumers to play an active role in this effort is\na significant challenge for electricity suppliers. In this regard, millions of\nsmart meters have been deployed worldwide in the last decade, recording the\nmain electricity power consumed in individual households. This data produces\nvaluable information that can help them reduce their electricity footprint;\nnevertheless, the collected signal aggregates the consumption of the different\nappliances running simultaneously in the house, making it difficult to\napprehend. Non-Intrusive Load Monitoring (NILM) refers to the challenge of\nestimating the power consumption, pattern, or on/off state activation of\nindividual appliances using the main smart meter signal. Recent methods\nproposed to tackle this task are based on a fully supervised deep-learning\napproach that requires both the aggregate signal and the ground truth of\nindividual appliance power. However, such labels are expensive to collect and\nextremely scarce in practice, as they require conducting intrusive surveys in\nhouseholds to monitor each appliance. In this paper, we introduce CamAL, a\nweakly supervised approach for appliance pattern localization that only\nrequires information on the presence of an appliance in a household to be\ntrained. CamAL merges an ensemble of deep-learning classifiers combined with an\nexplainable classification method to be able to localize appliance patterns.\nOur experimental evaluation, conducted on 4 real-world datasets, demonstrates\nthat CamAL significantly outperforms existing weakly supervised baselines and\nthat current SotA fully supervised NILM approaches require significantly more\nlabels to reach CamAL performances. The source of our experiments is available\nat: https://github.com/adrienpetralia/CamAL. This paper appeared in ICDE 2025.", "comment": "12 pages, 10 figures. This paper appeared in IEEE ICDE 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05895v1", "AI": {"title_translation": "少量标签足矣：一种用于智能电表序列中电器定位的弱监督框架", "tldr": "CamAL是一种弱监督方法，仅需少量标签即可在智能电表数据中定位电器模式，且性能优于现有方法。", "motivation": "改善智能电网系统管理对于应对气候变化至关重要，而让消费者积极参与其中是电力供应商面临的巨大挑战。尽管智能电表数据提供了有价值的信息，但其聚合了家中同时运行的各种电器的消耗，难以理解。现有的非侵入式负荷监测（NILM）方法多基于全监督深度学习，需要昂贵且稀缺的电器单独功耗真值标签。", "method": "本文引入了CamAL，一种用于电器模式定位的弱监督方法，它仅需要关于家庭中电器存在的信息即可进行训练。CamAL融合了深度学习分类器集成与可解释分类方法，以定位电器模式。", "result": "在4个真实世界数据集上的实验评估表明，CamAL显著优于现有的弱监督基线，并且当前的SotA全监督NILM方法需要显著更多的标签才能达到CamAL的性能。", "conclusion": "CamAL在标签稀缺的场景下，能有效定位电器模式，并达到与全监督方法相当甚至更好的性能，为智能电网系统管理提供了新的解决方案。", "translation": "提高智能电网系统管理对于应对气候变化至关重要，而使消费者在此项工作中发挥积极作用是电力供应商面临的重大挑战。在这方面，过去十年中全球已部署了数百万智能电表，记录了单个家庭消耗的主要电力。这些数据产生了有价值的信息，可以帮助他们减少用电足迹；然而，收集到的信号聚合了家中同时运行的不同电器的消耗，使其难以理解。非侵入式负荷监测（NILM）是指利用主智能电表信号估算单个电器的功耗、模式或开关状态激活的挑战。最近提出的解决此任务的方法基于全监督深度学习方法，需要聚合信号和单个电器功率的真实值。然而，此类标签收集成本高昂且在实践中极为稀缺，因为它们需要对家庭进行侵入性调查以监测每个电器。在本文中，我们引入了CamAL，一种用于电器模式定位的弱监督方法，它仅需要关于家庭中电器存在的信息即可进行训练。CamAL融合了深度学习分类器集成与可解释分类方法，以定位电器模式。我们对4个真实世界数据集进行的实验评估表明，CamAL显著优于现有的弱监督基线，并且当前的SotA全监督NILM方法需要显著更多的标签才能达到CamAL的性能。我们实验的源代码可在：https://github.com/adrienpetralia/CamAL 获取。本文发表于ICDE 2025。", "summary": "本文提出CamAL，一个用于智能电表序列中电器定位的弱监督框架，旨在解决传统全监督非侵入式负荷监测（NILM）方法对昂贵且稀缺的电器单独功耗标签的依赖。CamAL仅需家庭中电器存在的信息即可进行训练，它通过结合深度学习分类器集成与可解释分类方法来定位电器模式。在4个真实世界数据集上的实验结果表明，CamAL显著优于现有的弱监督基线，并且在标签效率上超越了当前最先进的全监督NILM方法。", "keywords": "弱监督学习, 电器定位, 智能电表, 非侵入式负荷监测, 深度学习", "comments": "本文创新性地提出了一个弱监督框架CamAL，有效解决了非侵入式负荷监测（NILM）领域中标签数据稀缺的痛点。通过结合深度学习和可解释性方法，该模型仅需少量标签即可实现电器模式的精准定位，并在真实数据集上展现出优异的性能和标签效率。这对于推动智能电网的精细化管理和消费者能源效率的提升具有重要意义。"}}
{"id": "2506.05883", "title": "HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios", "authors": ["Daming Wang", "Yuhao Song", "Zijian He", "Kangliang Chen", "Xing Pan", "Lu Deng", "Weihao Gu"], "summary": "We present HaoMo Vision-Language Model (HMVLM), an end-to-end driving\nframework that implements the slow branch of a cognitively inspired fast-slow\narchitecture. A fast controller outputs low-level steering, throttle, and brake\ncommands, while a slow planner-a large vision-language model-generates\nhigh-level intents such as \"yield to pedestrian\" or \"merge after the truck\"\nwithout compromising latency. HMVLM introduces three upgrades: (1) selective\nfive-view prompting with an embedded 4s history of ego kinematics, (2)\nmulti-stage chain-of-thought (CoT) prompting that enforces a Scene\nUnderstanding -> Driving Decision -> Trajectory Inference reasoning flow, and\n(3) spline-based trajectory post-processing that removes late-stage jitter and\nsharp turns. Trained on the Waymo Open Dataset, these upgrades enable HMVLM to\nachieve a Rater Feedback Score (RFS) of 7.7367, securing 2nd place in the 2025\nWaymo Vision-based End-to-End (E2E) Driving Challenge and surpassing the public\nbaseline by 2.77%.", "comment": "WOD Vision-based End-to-End Driving Challenge", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05883v1", "AI": {"title_translation": "HMVLM: 多阶段推理增强的视觉-语言模型，用于长尾驾驶场景", "tldr": "HMVLM是一个端到端的驾驶框架，通过引入选择性五视图提示、多阶段思维链提示和样条曲线轨迹后处理等升级，在Waymo视觉端到端驾驶挑战中取得了第二名。", "motivation": "本研究旨在开发一个端到端驾驶框架，能够处理长尾驾驶场景，在不影响延迟的情况下生成高级意图，并增强推理流程以做出稳健的驾驶决策。", "method": "HMVLM是一个端到端驾驶框架，采用认知启发的快慢架构。一个快速控制器处理低级指令，而一个慢速规划器（大型视觉-语言模型）生成高级意图。它引入了三项升级：（1）选择性五视图提示，嵌入了4秒的自我运动学历史，（2）多阶段思维链（CoT）提示（场景理解 -> 驾驶决策 -> 轨迹推断），以及（3）基于样条曲线的轨迹后处理，以消除抖动和急转弯。", "result": "HMVLM在Waymo开放数据集上进行了训练，获得了7.7367的评分者反馈分数（RFS），在2025年Waymo基于视觉的端到端（E2E）驾驶挑战中获得第二名，并超越公共基线2.77%。", "conclusion": "HMVLM框架及其特定的升级显著提高了端到端视觉驾驶任务的性能，这通过其在Waymo挑战中的出色表现得到了证明。", "translation": "我们提出了浩墨视觉-语言模型（HMVLM），一个端到端驾驶框架，它实现了认知启发式快慢架构中的慢分支。一个快速控制器输出低级转向、油门和刹车指令，而一个慢速规划器——一个大型视觉-语言模型——生成高级意图，例如“让行行人”或“卡车后并道”，且不影响延迟。HMVLM引入了三项升级：（1）选择性五视图提示，嵌入了4秒的自我运动学历史，（2）多阶段思维链（CoT）提示，强制执行场景理解 -> 驾驶决策 -> 轨迹推断的推理流程，以及（3）基于样条曲线的轨迹后处理，消除了后期抖动和急转弯。在Waymo开放数据集上进行训练，这些升级使HMVLM达到了7.7367的评分者反馈分数（RFS），在2025年Waymo基于视觉的端到端（E2E）驾驶挑战中获得了第二名，并超越了公共基线2.77%。", "summary": "本论文介绍了HMVLM，一个受认知启发的快慢架构端到端驾驶框架。该模型通过集成选择性五视图提示、多阶段思维链推理流程和样条曲线轨迹后处理等创新，显著提升了在长尾驾驶场景中的表现。在Waymo开放数据集上训练后，HMVLM在2025年Waymo视觉端到端驾驶挑战中取得了第二名，评分者反馈分数达到7.7367，超越公共基线2.77%。", "keywords": "视觉-语言模型, 端到端驾驶, 长尾场景, 思维链, Waymo开放数据集", "comments": "该论文提出的HMVLM框架通过结合视觉-语言模型和多阶段推理，为解决长尾驾驶场景中的复杂决策问题提供了一个新颖且有效的方法。其创新的三项升级，特别是多阶段思维链提示，增强了模型的解释性和决策逻辑。在Waymo挑战中取得的优异成绩证明了其在实际应用中的潜力。"}}
{"id": "2506.05902", "title": "A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics", "authors": ["Shirui Zhou", "Jiying Yan", "Junfang Tian", "Tao Wang", "Yongfu Li", "Shiquan Zhong"], "summary": "A fundamental challenge in car-following modeling lies in accurately\nrepresenting the multi-scale complexity of driving behaviors, particularly the\nintra-driver heterogeneity where a single driver's actions fluctuate\ndynamically under varying conditions. While existing models, both conventional\nand data-driven, address behavioral heterogeneity to some extent, they often\nemphasize inter-driver heterogeneity or rely on simplified assumptions,\nlimiting their ability to capture the dynamic heterogeneity of a single driver\nunder different driving conditions. To address this gap, we propose a novel\ndata-driven car-following framework that systematically embeds discrete driving\nregimes (e.g., steady-state following, acceleration, cruising) into vehicular\nmotion predictions. Leveraging high-resolution traffic trajectory datasets, the\nproposed hybrid deep learning architecture combines Gated Recurrent Units for\ndiscrete driving regime classification with Long Short-Term Memory networks for\ncontinuous kinematic prediction, unifying discrete decision-making processes\nand continuous vehicular dynamics to comprehensively represent inter- and\nintra-driver heterogeneity. Driving regimes are identified using a bottom-up\nsegmentation algorithm and Dynamic Time Warping, ensuring robust\ncharacterization of behavioral states across diverse traffic scenarios.\nComparative analyses demonstrate that the framework significantly reduces\nprediction errors for acceleration (maximum MSE improvement reached 58.47\\%),\nspeed, and spacing metrics while reproducing critical traffic phenomena, such\nas stop-and-go wave propagation and oscillatory dynamics.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05902v1", "AI": {"title_translation": "一种嵌入驾驶模式的深度学习框架，用于建模多尺度跟车动态中的驾驶员内部异质性", "tldr": "该论文提出了一种嵌入驾驶模式的深度学习框架，用于更好地建模跟车行为中驾驶员内部的动态异质性。", "motivation": "跟车建模的一个根本挑战在于准确表示驾驶行为的多尺度复杂性，特别是驾驶员内部异质性，即单个驾驶员的行为在不同条件下会动态波动。现有模型在某种程度上解决了行为异质性，但通常强调驾驶员间异质性或依赖简化假设，限制了它们捕捉单个驾驶员在不同驾驶条件下动态异质性的能力。", "method": "提出了一种新颖的数据驱动跟车框架，将离散驾驶模式（例如，稳态跟车、加速、巡航）系统地嵌入到车辆运动预测中。该混合深度学习架构结合了用于离散驾驶模式分类的门控循环单元（GRU）和用于连续运动学预测的长短期记忆（LSTM）网络。驾驶模式通过自下而上的分割算法和动态时间规整（DTW）进行识别。", "result": "该框架显著降低了加速度（最大MSE改善达到58.47%）、速度和车距指标的预测误差，同时再现了关键的交通现象，如走走停停波传播和振荡动力学。", "conclusion": "该框架通过有效建模驾驶员内部异质性，显著提高了跟车行为的预测精度并再现了关键交通现象，表明其在解决现有模型局限性方面的有效性。", "translation": "跟车建模的一个根本挑战在于准确表示驾驶行为的多尺度复杂性，特别是驾驶员内部异质性，即单个驾驶员的行为在不同条件下会动态波动。尽管现有的传统和数据驱动模型在一定程度上解决了行为异质性，但它们通常强调驾驶员间异质性或依赖简化假设，限制了它们捕捉单个驾驶员在不同驾驶条件下动态异质性的能力。为了弥补这一空白，我们提出了一种新颖的数据驱动跟车框架，将离散驾驶模式（例如，稳态跟车、加速、巡航）系统地嵌入到车辆运动预测中。利用高分辨率交通轨迹数据集，所提出的混合深度学习架构结合了用于离散驾驶模式分类的门控循环单元和用于连续运动学预测的长短期记忆网络，统一了离散决策过程和连续车辆动力学，从而全面表示驾驶员间和驾驶员内部异质性。驾驶模式通过自下而上的分割算法和动态时间规整进行识别，确保在不同交通场景下对行为状态进行稳健表征。比较分析表明，该框架显著降低了加速度（最大MSE改善达到58.47%）、速度和车距指标的预测误差，同时再现了关键的交通现象，如走走停停波传播和振荡动力学。", "summary": "该论文提出了一种新颖的深度学习跟车框架，旨在解决现有模型在捕捉单个驾驶员在不同驾驶条件下的动态异质性方面的不足。该框架将离散驾驶模式嵌入到车辆运动预测中，并采用结合GRU和LSTM的混合深度学习架构，同时利用自下而上的分割算法和动态时间规整识别驾驶模式。实验结果表明，该框架显著降低了加速度、速度和车距的预测误差，并能再现关键交通现象。", "keywords": "驾驶员内部异质性, 跟车, 深度学习, 驾驶模式, 多尺度", "comments": "创新点在于将离散驾驶模式系统地嵌入到深度学习框架中，并采用混合GRU和LSTM架构来统一离散决策和连续动力学。该方法通过更精细地建模驾驶员内部异质性，显著提高了跟车行为的预测精度，对交通流建模和智能交通系统具有重要意义。"}}
{"id": "2506.05890", "title": "Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation", "authors": ["Yiheng Li", "Yang Yang", "Zichang Tan", "Huan Liu", "Weihua Chen", "Xu Zhou", "Zhen Lei"], "summary": "To tackle the threat of fake news, the task of detecting and grounding\nmulti-modal media manipulation DGM4 has received increasing attention. However,\nmost state-of-the-art methods fail to explore the fine-grained consistency\nwithin local content, usually resulting in an inadequate perception of detailed\nforgery and unreliable results. In this paper, we propose a novel approach\nnamed Contextual-Semantic Consistency Learning (CSCL) to enhance the\nfine-grained perception ability of forgery for DGM4. Two branches for image and\ntext modalities are established, each of which contains two cascaded decoders,\ni.e., Contextual Consistency Decoder (CCD) and Semantic Consistency Decoder\n(SCD), to capture within-modality contextual consistency and across-modality\nsemantic consistency, respectively. Both CCD and SCD adhere to the same\ncriteria for capturing fine-grained forgery details. To be specific, each\nmodule first constructs consistency features by leveraging additional\nsupervision from the heterogeneous information of each token pair. Then, the\nforgery-aware reasoning or aggregating is adopted to deeply seek forgery cues\nbased on the consistency features. Extensive experiments on DGM4 datasets prove\nthat CSCL achieves new state-of-the-art performance, especially for the results\nof grounding manipulated content. Codes and weights are avaliable at\nhttps://github.com/liyih/CSCL.", "comment": "Accepted by CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05890v1", "AI": {"title_translation": "释放一致性学习在检测和定位多模态媒体篡改方面的潜力", "tldr": "本文提出了一种名为CSCL的新方法，通过上下文和语义一致性学习来提高多模态媒体篡改检测和定位的细粒度感知能力，并在DGM4数据集上取得了SOTA性能。", "motivation": "为了应对假新闻的威胁，多模态媒体篡改检测和定位（DGM4）任务受到了越来越多的关注。然而，大多数最先进的方法未能探索局部内容中的细粒度一致性，通常导致对详细伪造的感知不足和结果不可靠。", "method": "本文提出了一种名为上下文-语义一致性学习（CSCL）的新方法，以增强DGM4对伪造的细粒度感知能力。建立了图像和文本模态的两个分支，每个分支都包含两个级联解码器，即上下文一致性解码器（CCD）和语义一致性解码器（SCD），分别捕获模态内上下文一致性和跨模态语义一致性。CCD和SCD都遵循相同的标准来捕获细粒度伪造细节。具体来说，每个模块首先通过利用每个令牌对的异构信息进行额外监督来构建一致性特征。然后，采用伪造感知推理或聚合来深入寻找基于一致性特征的伪造线索。", "result": "在DGM4数据集上进行的广泛实验证明，CSCL实现了新的最先进性能，尤其是在定位被篡改内容的结果方面。", "conclusion": "CSCL通过增强对细粒度伪造的感知能力，显著提升了多模态媒体篡改检测和定位的性能，特别是在篡改内容定位方面表现优异，为应对假新闻威胁提供了有效方案。", "translation": "为了应对假新闻的威胁，多模态媒体篡改检测和定位（DGM4）任务受到了越来越多的关注。然而，大多数最先进的方法未能探索局部内容中的细粒度一致性，通常导致对详细伪造的感知不足和结果不可靠。在本文中，我们提出了一种名为上下文-语义一致性学习（CSCL）的新方法，以增强DGM4对伪造的细粒度感知能力。建立了图像和文本模态的两个分支，每个分支都包含两个级联解码器，即上下文一致性解码器（CCD）和语义一致性解码器（SCD），分别捕获模态内上下文一致性和跨模态语义一致性。CCD和SCD都遵循相同的标准来捕获细粒度伪造细节。具体来说，每个模块首先通过利用每个令牌对的异构信息进行额外监督来构建一致性特征。然后，采用伪造感知推理或聚合来深入寻找基于一致性特征的伪造线索。在DGM4数据集上进行的广泛实验证明，CSCL实现了新的最先进性能，尤其是在定位被篡改内容的结果方面。代码和权重可在https://github.com/liyih/CSCL获取。", "summary": "本文针对多模态媒体篡改检测和定位（DGM4）中现有方法在细粒度一致性探索方面的不足，提出了一种新颖的上下文-语义一致性学习（CSCL）方法。CSCL通过上下文一致性解码器（CCD）和语义一致性解码器（SCD）分别捕获模态内上下文一致性和跨模态语义一致性，并利用异构信息进行额外监督以构建一致性特征，从而增强对细粒度伪造的感知。实验证明，CSCL在DGM4数据集上取得了最先进的性能，尤其在篡改内容定位方面表现突出。", "keywords": "多模态媒体篡改检测, 一致性学习, 细粒度感知, DGM4, 深度伪造", "comments": "该论文通过引入上下文-语义一致性学习（CSCL），有效解决了现有方法在多模态媒体篡改检测和定位中对细粒度伪造感知不足的问题。其创新点在于同时考虑了模态内和跨模态的一致性，并通过级联解码器和利用异构信息进行额外监督，显著提升了对伪造细节的感知和定位精度。这对于打击日益增长的深度伪造和假新闻威胁具有重要的实际应用价值。"}}
{"id": "2506.05912", "title": "DeviceScope: An Interactive App to Detect and Localize Appliance Patterns in Electricity Consumption Time Series", "authors": ["Adrien Petralia", "Paul Boniol", "Philippe Charpentier", "Themis Palpanas"], "summary": "In recent years, electricity suppliers have installed millions of smart\nmeters worldwide to improve the management of the smart grid system. These\nmeters collect a large amount of electrical consumption data to produce\nvaluable information to help consumers reduce their electricity footprint.\nHowever, having non-expert users (e.g., consumers or sales advisors) understand\nthese data and derive usage patterns for different appliances has become a\nsignificant challenge for electricity suppliers because these data record the\naggregated behavior of all appliances. At the same time, ground-truth labels\n(which could train appliance detection and localization models) are expensive\nto collect and extremely scarce in practice. This paper introduces DeviceScope,\nan interactive tool designed to facilitate understanding smart meter data by\ndetecting and localizing individual appliance patterns within a given time\nperiod. Our system is based on CamAL (Class Activation Map-based Appliance\nLocalization), a novel weakly supervised approach for appliance localization\nthat only requires the knowledge of the existence of an appliance in a\nhousehold to be trained. This paper appeared in ICDE 2025.", "comment": "4 pages, 5 figures. This paper appeared in ICDE 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05912v1", "AI": {"title_translation": "DeviceScope：一个交互式应用程序，用于检测和定位电力消耗时间序列中的电器模式", "tldr": "DeviceScope是一个交互式工具，利用弱监督方法CamAL，帮助非专业用户理解智能电表数据，通过检测和定位用电时间序列中的单个电器模式。", "motivation": "智能电表收集大量电力消耗数据，但非专业用户（如消费者或销售顾问）难以理解这些数据并从中推导出不同电器的使用模式，因为数据记录的是所有电器的总聚合行为。同时，用于训练电器检测和定位模型的真实标签收集成本高昂且在实践中极为稀缺。", "method": "本文介绍了DeviceScope，一个交互式工具，旨在通过检测和定位给定时间段内的单个电器模式来促进对智能电表数据的理解。该系统基于CamAL（基于类别激活图的电器定位），这是一种新颖的弱监督电器定位方法，仅需要知道家庭中是否存在某种电器即可进行训练。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "近年来，电力供应商在全球范围内安装了数百万智能电表，以改善智能电网系统的管理。这些电表收集大量用电数据，以产生有价值的信息，帮助消费者减少用电足迹。然而，让非专业用户（例如消费者或销售顾问）理解这些数据并推导出不同电器的使用模式已成为电力供应商面临的一项重大挑战，因为这些数据记录的是所有电器的聚合行为。与此同时，用于训练电器检测和定位模型的真实标签收集成本高昂且在实践中极为稀缺。本文介绍了DeviceScope，一个交互式工具，旨在通过检测和定位给定时间段内的单个电器模式来促进对智能电表数据的理解。我们的系统基于CamAL（基于类别激活图的电器定位），这是一种新颖的弱监督电器定位方法，仅需要知道家庭中是否存在某种电器即可进行训练。本文发表于ICDE 2025。", "summary": "DeviceScope是一款交互式应用程序，旨在解决非专业用户难以理解智能电表聚合数据的问题。它通过一种新颖的弱监督方法CamAL，仅需了解电器存在性即可训练模型，从而检测和定位电力消耗时间序列中的单个电器模式，帮助消费者和销售顾问更好地理解和管理用电情况。", "keywords": "智能电表, 电器模式检测, 弱监督学习, 时间序列, DeviceScope", "comments": "该论文的创新点在于提出了DeviceScope这一交互式工具，并采用了CamAL这种新颖的弱监督方法来解决电器模式检测和定位中真实标签稀缺的问题。这种方法降低了数据标注成本，使得智能电表数据的分析对非专业用户更加友好和可访问。其重要性在于能够帮助消费者更好地理解自身用电行为，从而可能实现节能减排。"}}
{"id": "2506.05897", "title": "Query Nearby: Offset-Adjusted Mask2Former enhances small-organ segmentation", "authors": ["Xin Zhang", "Dongdong Meng", "Sheng Li"], "summary": "Medical segmentation plays an important role in clinical applications like\nradiation therapy and surgical guidance, but acquiring clinically acceptable\nresults is difficult. In recent years, progress has been witnessed with the\nsuccess of utilizing transformer-like models, such as combining the attention\nmechanism with CNN. In particular, transformer-based segmentation models can\nextract global information more effectively, compensating for the drawbacks of\nCNN modules that focus on local features. However, utilizing transformer\narchitecture is not easy, because training transformer-based models can be\nresource-demanding. Moreover, due to the distinct characteristics in the\nmedical field, especially when encountering mid-sized and small organs with\ncompact regions, their results often seem unsatisfactory. For example, using\nViT to segment medical images directly only gives a DSC of less than 50\\%,\nwhich is far lower than the clinically acceptable score of 80\\%. In this paper,\nwe used Mask2Former with deformable attention to reduce computation and\nproposed offset adjustment strategies to encourage sampling points within the\nsame organs during attention weights computation, thereby integrating compact\nforeground information better. Additionally, we utilized the 4th feature map in\nMask2Former to provide a coarse location of organs, and employed an FCN-based\nauxiliary head to help train Mask2Former more quickly using Dice loss. We show\nthat our model achieves SOTA (State-of-the-Art) performance on the HaNSeg and\nSegRap2023 datasets, especially on mid-sized and small organs.Our code is\navailable at link\nhttps://github.com/earis/Offsetadjustment\\_Background-location\\_Decoder\\_Mask2former.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05897v1", "AI": {"title_translation": "邻近查询：偏移调整的Mask2Former增强小器官分割", "tldr": "该论文提出了一种偏移调整的Mask2Former模型，结合可变形注意力机制和辅助头，以改善医学图像中小/中型器官的分割效果，并取得了SOTA结果。", "motivation": "医学分割在临床应用中至关重要，但获得临床可接受的结果很困难。Transformer模型在提取全局信息方面有优势，但计算资源需求高，并且在处理紧凑的中小型器官时表现不佳（例如，ViT在医学图像分割上的DSC低于50%，远低于临床要求的80%）。", "method": "本研究使用了带有可变形注意力的Mask2Former来减少计算量。提出了偏移调整策略，以鼓励在注意力权重计算过程中在同一器官内进行采样，从而更好地整合紧凑的前景信息。此外，利用Mask2Former的第四个特征图提供器官的粗略位置，并采用基于FCN的辅助头与Dice损失函数帮助Mask2Former更快地训练。", "result": "模型在HaNSeg和SegRap2023数据集上取得了SOTA（State-of-the-Art）性能，尤其是在中小型器官分割方面。", "conclusion": "所提出的偏移调整Mask2Former模型及其辅助组件显著改善了医学图像中小器官的分割效果，满足了临床需求。", "translation": "医学分割在放射治疗和手术指导等临床应用中发挥着重要作用，但获得临床可接受的结果却很困难。近年来，随着Transformer类模型的成功应用，例如将注意力机制与CNN结合，取得了进展。特别是，基于Transformer的分割模型可以更有效地提取全局信息，弥补了专注于局部特征的CNN模块的缺点。然而，利用Transformer架构并不容易，因为训练基于Transformer的模型可能需要大量资源。此外，由于医学领域的独特特性，特别是在遇到具有紧凑区域的中小型器官时，其结果往往不尽如人意。例如，直接使用ViT分割医学图像的DSC仅低于50%，远低于临床可接受的80%分数。在本文中，我们使用了带有可变形注意力的Mask2Former来减少计算量，并提出了偏移调整策略，以鼓励在注意力权重计算过程中在同一器官内进行采样点，从而更好地整合紧凑的前景信息。此外，我们利用Mask2Former的第四个特征图提供器官的粗略位置，并采用基于FCN的辅助头，使用Dice损失函数帮助Mask2Former更快地训练。我们表明，我们的模型在HaNSeg和SegRap2023数据集上取得了SOTA（State-of-the-Art）性能，特别是在中小型器官上。我们的代码可在链接https://github.com/earis/Offsetadjustment_Background-location_Decoder_Mask2former获取。", "summary": "本论文旨在解决医学图像中中小型器官的精确分割难题，这对于临床应用至关重要。尽管基于Transformer的模型能有效提取全局信息，但其计算量大，且在处理紧凑器官时表现不佳。为克服这些挑战，作者提出了一种增强型Mask2Former模型，该模型引入了可变形注意力机制以提高效率，并设计了新颖的偏移调整策略，通过引导注意力采样点集中在器官内部，从而更好地整合前景信息。此外，模型利用Mask2Former的第四个特征图提供器官的粗略位置，并采用基于FCN的辅助头结合Dice损失函数以加速训练。实验结果表明，该模型在HaNSeg和SegRap2023数据集上，特别是在中小型器官分割方面，取得了最先进的性能。", "keywords": "医学分割, Mask2Former, 可变形注意力, 小器官分割, 偏移调整", "comments": "该论文的创新之处在于其独特的偏移调整策略，旨在优化对紧凑器官的注意力机制，以及利用辅助组件（第四特征图、FCN头）使得Mask2Former这一强大的模型在具有挑战性的医学分割任务中更加有效和高效。其重要性在于解决了医学图像分析中的一个关键空白，有望改善临床结果。"}}
{"id": "2506.05593", "title": "Improving Neural Diarization through Speaker Attribute Attractors and Local Dependency Modeling", "authors": ["David Palzer", "Matthew Maciejewski", "Eric Fosler-Lussier"], "summary": "In recent years, end-to-end approaches have made notable progress in\naddressing the challenge of speaker diarization, which involves segmenting and\nidentifying speakers in multi-talker recordings. One such approach,\nEncoder-Decoder Attractors (EDA), has been proposed to handle variable speaker\ncounts as well as better guide the network during training. In this study, we\nextend the attractor paradigm by moving beyond direct speaker modeling and\ninstead focus on representing more detailed `speaker attributes' through a\nmulti-stage process of intermediate representations. Additionally, we enhance\nthe architecture by replacing transformers with conformers, a\nconvolution-augmented transformer, to model local dependencies. Experiments\ndemonstrate improved diarization performance on the CALLHOME dataset.", "comment": "ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP), Seoul, Korea, Republic of, 2024, pp.\n  11911-11915", "cate": "cs.SD", "url": "http://arxiv.org/pdf/2506.05593v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05918", "title": "Over-PINNs: Enhancing Physics-Informed Neural Networks via Higher-Order Partial Derivative Overdetermination of PDEs", "authors": ["Wenxuan Huo", "Qiang He", "Gang Zhu", "Weifeng Huang"], "summary": "Partial differential equations (PDEs) serve as the cornerstone of\nmathematical physics. In recent years, Physics-Informed Neural Networks (PINNs)\nhave significantly reduced the dependence on large datasets by embedding\nphysical laws directly into the training of neural networks. However, when\ndealing with complex problems, the accuracy of PINNs still has room for\nimprovement. To address this issue, we introduce the Over-PINNs framework,\nwhich leverages automatic differentiation (AD) to generate higher-order\nauxiliary equations that impose additional physical constraints. These\nequations are incorporated as extra loss terms in the training process,\neffectively enhancing the model's ability to capture physical information\nthrough an \"overdetermined\" approach. Numerical results illustrate that this\nmethod exhibits strong versatility in solving various types of PDEs. It\nachieves a significant improvement in solution accuracy without incurring\nsubstantial additional computational costs.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05918v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05917", "title": "Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness", "authors": ["Steven Landgraf", "Markus Hillemann", "Markus Ulrich"], "summary": "Semantic segmentation is critical for scene understanding but demands costly\npixel-wise annotations, attracting increasing attention to semi-supervised\napproaches to leverage abundant unlabeled data. While semi-supervised\nsegmentation is often promoted as a path toward scalable, real-world\ndeployment, it is astonishing that current evaluation protocols exclusively\nfocus on segmentation accuracy, entirely overlooking reliability and\nrobustness. These qualities, which ensure consistent performance under diverse\nconditions (robustness) and well-calibrated model confidences as well as\nmeaningful uncertainties (reliability), are essential for safety-critical\napplications like autonomous driving, where models must handle unpredictable\nenvironments and avoid sudden failures at all costs. To address this gap, we\nintroduce the Reliable Segmentation Score (RSS), a novel metric that combines\npredictive accuracy, calibration, and uncertainty quality measures via a\nharmonic mean. RSS penalizes deficiencies in any of its components, providing\nan easy and intuitive way of holistically judging segmentation models.\nComprehensive evaluations of UniMatchV2 against its predecessor and a\nsupervised baseline show that semi-supervised methods often trade reliability\nfor accuracy. While out-of-domain evaluations demonstrate UniMatchV2's\nrobustness, they further expose persistent reliability shortcomings. We\nadvocate for a shift in evaluation protocols toward more holistic metrics like\nRSS to better align semi-supervised learning research with real-world\ndeployment needs.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05917v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05933", "title": "Machine Learning Predictions for Traffic Equilibria in Road Renovation Scheduling", "authors": ["Robbert Bosch", "Wouter van Heeswijk", "Patricia Rogetzer", "Martijn Mes"], "summary": "Accurately estimating the impact of road maintenance schedules on traffic\nconditions is important because maintenance operations can substantially worsen\ncongestion if not carefully planned. Reliable estimates allow planners to avoid\nexcessive delays during periods of roadwork. Since the exact increase in\ncongestion is difficult to predict analytically, traffic simulations are\ncommonly used to assess the redistribution of the flow of traffic. However,\nwhen applied to long-term maintenance planning involving many overlapping\nprojects and scheduling alternatives, these simulations must be run thousands\nof times, resulting in a significant computational burden. This paper\ninvestigates the use of machine learning-based surrogate models to predict\nnetwork-wide congestion caused by simultaneous road renovations. We frame the\nproblem as a supervised learning task, using one-hot encodings, engineered\ntraffic features, and heuristic approximations. A range of linear,\nensemble-based, probabilistic, and neural regression models is evaluated under\nan online learning framework in which data progressively becomes available. The\nexperimental results show that the Costliest Subset Heuristic provides a\nreasonable approximation when limited training data is available, and that most\nregression models fail to outperform it, with the exception of XGBoost, which\nachieves substantially better accuracy. In overall performance, XGBoost\nsignificantly outperforms alternatives in a range of metrics, most strikingly\nMean Absolute Percentage Error (MAPE) and Pinball loss, where it achieves a\nMAPE of 11% and outperforms the next-best model by 20% and 38% respectively.\nThis modeling approach has the potential to reduce the computational burden of\nlarge-scale traffic assignment problems in maintenance planning.", "comment": "15 pages, 2 figures, submitted as conference paper to ICCL 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05933v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05934", "title": "FADE: Frequency-Aware Diffusion Model Factorization for Video Editing", "authors": ["Yixuan Zhu", "Haolin Wang", "Shilin Ma", "Wenliang Zhao", "Yansong Tang", "Lei Chen", "Jie Zhou"], "summary": "Recent advancements in diffusion frameworks have significantly enhanced video\nediting, achieving high fidelity and strong alignment with textual prompts.\nHowever, conventional approaches using image diffusion models fall short in\nhandling video dynamics, particularly for challenging temporal edits like\nmotion adjustments. While current video diffusion models produce high-quality\nresults, adapting them for efficient editing remains difficult due to the heavy\ncomputational demands that prevent the direct application of previous image\nediting techniques. To overcome these limitations, we introduce FADE, a\ntraining-free yet highly effective video editing approach that fully leverages\nthe inherent priors from pre-trained video diffusion models via frequency-aware\nfactorization. Rather than simply using these models, we first analyze the\nattention patterns within the video model to reveal how video priors are\ndistributed across different components. Building on these insights, we propose\na factorization strategy to optimize each component's specialized role.\nFurthermore, we devise spectrum-guided modulation to refine the sampling\ntrajectory with frequency domain cues, preventing information leakage and\nsupporting efficient, versatile edits while preserving the basic spatial and\ntemporal structure. Extensive experiments on real-world videos demonstrate that\nour method consistently delivers high-quality, realistic and temporally\ncoherent editing results both qualitatively and quantitatively. Code is\navailable at https://github.com/EternalEvan/FADE .", "comment": "Accepted by IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05934v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05598", "title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs", "authors": ["Michael J Ryan", "Omar Shaikh", "Aditri Bhagirath", "Daniel Frees", "William Held", "Diyi Yang"], "summary": "Recent calls for pluralistic alignment of Large Language Models (LLMs)\nencourage adapting models to diverse user preferences. However, most prior work\non personalized reward models heavily rely on additional identity information,\nsuch as demographic details or a predefined set of preference categories. To\nthis end, we introduce SynthesizeMe, an approach to inducing synthetic user\npersonas from user interactions for personalized reward modeling. SynthesizeMe\nfirst generates and verifies reasoning to explain user preferences, then\ninduces synthetic user personas from that reasoning, and finally filters to\ninformative prior user interactions in order to build personalized prompts for\na particular user. We show that using SynthesizeMe induced prompts improves\npersonalized LLM-as-a-judge accuracy by 4.4% on Chatbot Arena. Combining\nSynthesizeMe derived prompts with a reward model achieves top performance on\nPersonalRewardBench: a new curation of user-stratified interactions with\nchatbots collected from 854 users of Chatbot Arena and PRISM.", "comment": "ACL 2025 Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05598v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05937", "title": "Quantifying Adversarial Uncertainty in Evidential Deep Learning using Conflict Resolution", "authors": ["Charmaine Barker", "Daniel Bethell", "Simos Gerasimou"], "summary": "Reliability of deep learning models is critical for deployment in high-stakes\napplications, where out-of-distribution or adversarial inputs may lead to\ndetrimental outcomes. Evidential Deep Learning, an efficient paradigm for\nuncertainty quantification, models predictions as Dirichlet distributions of a\nsingle forward pass. However, EDL is particularly vulnerable to adversarially\nperturbed inputs, making overconfident errors. Conflict-aware Evidential Deep\nLearning (C-EDL) is a lightweight post-hoc uncertainty quantification approach\nthat mitigates these issues, enhancing adversarial and OOD robustness without\nretraining. C-EDL generates diverse, task-preserving transformations per input\nand quantifies representational disagreement to calibrate uncertainty estimates\nwhen needed. C-EDL's conflict-aware prediction adjustment improves detection of\nOOD and adversarial inputs, maintaining high in-distribution accuracy and low\ncomputational overhead. Our experimental evaluation shows that C-EDL\nsignificantly outperforms state-of-the-art EDL variants and competitive\nbaselines, achieving substantial reductions in coverage for OOD data (up to\n55%) and adversarial data (up to 90%), across a range of datasets, attack\ntypes, and uncertainty metrics.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05937v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05952", "title": "MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation", "authors": ["Dongjie Fu", "Tengjiao Sun", "Pengcheng Fang", "Xiaohao Cai", "Hansung Kim"], "summary": "Recent advances in transformer-based text-to-motion generation have led to\nimpressive progress in synthesizing high-quality human motion. Nevertheless,\njointly achieving high fidelity, streaming capability, real-time\nresponsiveness, and scalability remains a fundamental challenge. In this paper,\nwe propose MOGO (Motion Generation with One-pass), a novel autoregressive\nframework tailored for efficient and real-time 3D motion generation. MOGO\ncomprises two key components: (1) MoSA-VQ, a motion scale-adaptive residual\nvector quantization module that hierarchically discretizes motion sequences\nwith learnable scaling to produce compact yet expressive representations; and\n(2) RQHC-Transformer, a residual quantized hierarchical causal transformer that\ngenerates multi-layer motion tokens in a single forward pass, significantly\nreducing inference latency. To enhance semantic fidelity, we further introduce\na text condition alignment mechanism that improves motion decoding under\ntextual control. Extensive experiments on benchmark datasets including\nHumanML3D, KIT-ML, and CMP demonstrate that MOGO achieves competitive or\nsuperior generation quality compared to state-of-the-art transformer-based\nmethods, while offering substantial improvements in real-time performance,\nstreaming generation, and generalization under zero-shot settings.", "comment": "9 pages, 4 figures, conference", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05952v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05605", "title": "Scenarios in Computing Research: A Systematic Review of the Use of Scenario Methods for Exploring the Future of Computing Technologies in Society", "authors": ["Julia Barnett", "Kimon Kieslich", "Jasmine Sinchai", "Nicholas Diakopoulos"], "summary": "Scenario building is an established method to anticipate the future of\nemerging technologies. Its primary goal is to use narratives to map future\ntrajectories of technology development and sociotechnical adoption. Following\nthis process, risks and benefits can be identified early on, and strategies can\nbe developed that strive for desirable futures. In recent years, computer\nscience has adopted this method and applied it to various technologies,\nincluding Artificial Intelligence (AI). Because computing technologies play\nsuch an important role in shaping modern societies, it is worth exploring how\nscenarios are being used as an anticipatory tool in the field -- and what\npossible traditional uses of scenarios are not yet covered but have the\npotential to enrich the field. We address this gap by conducting a systematic\nliterature review on the use of scenario building methods in computer science\nover the last decade (n = 59). We guide the review along two main questions.\nFirst, we aim to uncover how scenarios are used in computing literature,\nfocusing especially on the rationale for why scenarios are used. Second, in\nfollowing the potential of scenario building to enhance inclusivity in\nresearch, we dive deeper into the participatory element of the existing\nscenario building literature in computer science.", "comment": "10 pages, 3 figures. Currently under review", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05605v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05940", "title": "Exponential Family Variational Flow Matching for Tabular Data Generation", "authors": ["Andrés Guzmán-Cordero", "Floor Eijkelboom", "Jan-Willem van de Meent"], "summary": "While denoising diffusion and flow matching have driven major advances in\ngenerative modeling, their application to tabular data remains limited, despite\nits ubiquity in real-world applications. To this end, we develop TabbyFlow, a\nvariational Flow Matching (VFM) method for tabular data generation. To apply\nVFM to data with mixed continuous and discrete features, we introduce\nExponential Family Variational Flow Matching (EF-VFM), which represents\nheterogeneous data types using a general exponential family distribution. We\nhereby obtain an efficient, data-driven objective based on moment matching,\nenabling principled learning of probability paths over mixed continuous and\ndiscrete variables. We also establish a connection between variational flow\nmatching and generalized flow matching objectives based on Bregman divergences.\nEvaluation on tabular data benchmarks demonstrates state-of-the-art performance\ncompared to baselines.", "comment": "14 pages, 1 figure, and 9 tables; To be published in the Proceedings\n  of the Forty-Second International Conference on Machine Learning", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05940v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05449", "title": "AI-powered Contextual 3D Environment Generation: A Systematic Review", "authors": ["Miguel Silva", "Alexandre Valle de Carvalho"], "summary": "The generation of high-quality 3D environments is crucial for industries such\nas gaming, virtual reality, and cinema, yet remains resource-intensive due to\nthe reliance on manual processes. This study performs a systematic review of\nexisting generative AI techniques for 3D scene generation, analyzing their\ncharacteristics, strengths, limitations, and potential for improvement. By\nexamining state-of-the-art approaches, it presents key challenges such as scene\nauthenticity and the influence of textual inputs. Special attention is given to\nhow AI can blend different stylistic domains while maintaining coherence, the\nimpact of training data on output quality, and the limitations of current\nmodels. In addition, this review surveys existing evaluation metrics for\nassessing realism and explores how industry professionals incorporate AI into\ntheir workflows. The findings of this study aim to provide a comprehensive\nunderstanding of the current landscape and serve as a foundation for future\nresearch on AI-driven 3D content generation. Key findings include that advanced\ngenerative architectures enable high-quality 3D content creation at a high\ncomputational cost, effective multi-modal integration techniques like\ncross-attention and latent space alignment facilitate text-to-3D tasks, and the\nquality and diversity of training data combined with comprehensive evaluation\nmetrics are critical to achieving scalable, robust 3D scene generation.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.05449v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05965", "title": "Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments", "authors": ["Mingrui Li", "Yiming Zhou", "Hongxing Zhou", "Xinggang Hu", "Florian Roemer", "Hongyu Wang", "Ahmad Osman"], "summary": "Current Simultaneous Localization and Mapping (SLAM) methods based on Neural\nRadiance Fields (NeRF) or 3D Gaussian Splatting excel in reconstructing static\n3D scenes but struggle with tracking and reconstruction in dynamic\nenvironments, such as real-world scenes with moving elements. Existing\nNeRF-based SLAM approaches addressing dynamic challenges typically rely on\nRGB-D inputs, with few methods accommodating pure RGB input. To overcome these\nlimitations, we propose Dy3DGS-SLAM, the first 3D Gaussian Splatting (3DGS)\nSLAM method for dynamic scenes using monocular RGB input. To address dynamic\ninterference, we fuse optical flow masks and depth masks through a\nprobabilistic model to obtain a fused dynamic mask. With only a single network\niteration, this can constrain tracking scales and refine rendered geometry.\nBased on the fused dynamic mask, we designed a novel motion loss to constrain\nthe pose estimation network for tracking. In mapping, we use the rendering loss\nof dynamic pixels, color, and depth to eliminate transient interference and\nocclusion caused by dynamic objects. Experimental results demonstrate that\nDy3DGS-SLAM achieves state-of-the-art tracking and rendering in dynamic\nenvironments, outperforming or matching existing RGB-D methods.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05965v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05941", "title": "Comparative Analysis of Modern Machine Learning Models for Retail Sales Forecasting", "authors": ["Luka Hobor", "Mario Brcic", "Lidija Polutnik", "Ante Kapetanovic"], "summary": "Accurate forecasting is key for all business planning. When estimated sales\nare too high, brick-and-mortar retailers may incur higher costs due to unsold\ninventories, higher labor and storage space costs, etc. On the other hand, when\nforecasts underestimate the level of sales, firms experience lost sales,\nshortages, and impact on the reputation of the retailer in their relevant\nmarket. Accurate forecasting presents a competitive advantage for companies. It\nfacilitates the achievement of revenue and profit goals and execution of\npricing strategy and tactics. In this study, we provide an exhaustive\nassessment of the forecasting models applied to a high-resolution\nbrick-and-mortar retail dataset. Our forecasting framework addresses the\nproblems found in retail environments, including intermittent demand, missing\nvalues, and frequent product turnover. We compare tree-based ensembles (such as\nXGBoost and LightGBM) and state-of-the-art neural network architectures\n(including N-BEATS, NHITS, and the Temporal Fusion Transformer) across various\nexperimental settings. Our results show that localized modeling strategies\nespecially those using tree-based models on individual groups with non-imputed\ndata, consistently deliver superior forecasting accuracy and computational\nefficiency. In contrast, neural models benefit from advanced imputation\nmethods, yet still fall short in handling the irregularities typical of\nphysical retail data. These results further practical understanding for model\nselection in retail environment and highlight the significance of data\npreprocessing to improve forecast performance.", "comment": "20 total pages, 10 pages article, 10 pages appendix, 3 figures, 24\n  tables", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05941v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05972", "title": "Domain Adaptation in Agricultural Image Analysis: A Comprehensive Review from Shallow Models to Deep Learning", "authors": ["Xing Hu", "Siyuan Chen", "Dawei Zhang"], "summary": "With the increasing use of computer vision in agriculture, image analysis has\nbecome crucial for tasks like crop health monitoring and pest detection.\nHowever, significant domain shifts between source and target domains-due to\nenvironmental differences, crop types, and data acquisition methods-pose\nchallenges. These domain gaps limit the ability of models to generalize across\nregions, seasons, and complex agricultural environments. This paper explores\nhow Domain Adaptation (DA) techniques can address these challenges, focusing on\ntheir role in enhancing the cross-domain transferability of agricultural image\nanalysis. DA has gained attention in agricultural vision tasks due to its\npotential to mitigate domain heterogeneity. The paper systematically reviews\nrecent advances in DA for agricultural imagery, particularly its practical\napplications in complex agricultural environments. We examine the key drivers\nfor adopting DA in agriculture, such as limited labeled data, weak model\ntransferability, and dynamic environmental conditions. We also discuss its use\nin crop health monitoring, pest detection, and fruit recognition, highlighting\nimprovements in performance across regions and seasons. The paper categorizes\nDA methods into shallow and deep learning models, with further divisions into\nsupervised, semi-supervised, and unsupervised approaches. A special focus is\ngiven to adversarial learning-based DA methods, which have shown great promise\nin challenging agricultural scenarios. Finally, we review key public datasets\nin agricultural imagery, analyzing their value and limitations in DA research.\nThis review provides a comprehensive framework for researchers, offering\ninsights into current research gaps and supporting the advancement of DA\nmethods in agricultural image analysis.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05972v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05942", "title": "Additive decomposition of one-dimensional signals using Transformers", "authors": ["Samuele Salti", "Andrea Pinto", "Alessandro Lanza", "Serena Morigi"], "summary": "One-dimensional signal decomposition is a well-established and widely used\ntechnique across various scientific fields. It serves as a highly valuable\npre-processing step for data analysis. While traditional decomposition\ntechniques often rely on mathematical models, recent research suggests that\napplying the latest deep learning models to this problem presents an exciting,\nunexplored area with promising potential. This work presents a novel method for\nthe additive decomposition of one-dimensional signals. We leverage the\nTransformer architecture to decompose signals into their constituent\ncomponents: piece-wise constant, smooth (low-frequency oscillatory), textured\n(high-frequency oscillatory), and a noise component. Our model, trained on\nsynthetic data, achieves excellent accuracy in modeling and decomposing input\nsignals from the same distribution, as demonstrated by the experimental\nresults.", "comment": "Under consideration at Pattern Recognition Letters", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05942v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05982", "title": "MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks", "authors": ["Zonglin Wu", "Yule Xue", "Xin Wei", "Yiren Song"], "summary": "As automated attack techniques rapidly advance, CAPTCHAs remain a critical\ndefense mechanism against malicious bots. However, existing CAPTCHA schemes\nencompass a diverse range of modalities -- from static distorted text and\nobfuscated images to interactive clicks, sliding puzzles, and logic-based\nquestions -- yet the community still lacks a unified, large-scale, multimodal\nbenchmark to rigorously evaluate their security robustness. To address this\ngap, we introduce MCA-Bench, a comprehensive and reproducible benchmarking\nsuite that integrates heterogeneous CAPTCHA types into a single evaluation\nprotocol. Leveraging a shared vision-language model backbone, we fine-tune\nspecialized cracking agents for each CAPTCHA category, enabling consistent,\ncross-modal assessments. Extensive experiments reveal that MCA-Bench\neffectively maps the vulnerability spectrum of modern CAPTCHA designs under\nvaried attack settings, and crucially offers the first quantitative analysis of\nhow challenge complexity, interaction depth, and model solvability interrelate.\nBased on these findings, we propose three actionable design principles and\nidentify key open challenges, laying the groundwork for systematic CAPTCHA\nhardening, fair benchmarking, and broader community collaboration. Datasets and\ncode are available online.", "comment": "31 pages, 8 figures", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.05982v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05953", "title": "Learning Deterministic Policies with Policy Gradients in Constrained Markov Decision Processes", "authors": ["Alessandro Montenegro", "Leonardo Cesani", "Marco Mussi", "Matteo Papini", "Alberto Maria Metelli"], "summary": "Constrained Reinforcement Learning (CRL) addresses sequential decision-making\nproblems where agents are required to achieve goals by maximizing the expected\nreturn while meeting domain-specific constraints. In this setting, policy-based\nmethods are widely used thanks to their advantages when dealing with\ncontinuous-control problems. These methods search in the policy space with an\naction-based or a parameter-based exploration strategy, depending on whether\nthey learn the parameters of a stochastic policy or those of a stochastic\nhyperpolicy. We introduce an exploration-agnostic algorithm, called C-PG, which\nenjoys global last-iterate convergence guarantees under gradient domination\nassumptions. Furthermore, under specific noise models where the (hyper)policy\nis expressed as a stochastic perturbation of the actions or of the parameters\nof an underlying deterministic policy, we additionally establish global\nlast-iterate convergence guarantees of C-PG to the optimal deterministic\npolicy. This holds when learning a stochastic (hyper)policy and subsequently\nswitching off the stochasticity at the end of training, thereby deploying a\ndeterministic policy. Finally, we empirically validate both the action-based\n(C-PGAE) and parameter-based (C-PGPE) variants of C-PG on constrained control\ntasks, and compare them against state-of-the-art baselines, demonstrating their\neffectiveness, in particular when deploying deterministic policies after\ntraining.", "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10775", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05953v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06006", "title": "Bootstrapping World Models from Dynamics Models in Multimodal Foundation Models", "authors": ["Yifu Qiu", "Yftah Ziser", "Anna Korhonen", "Shay B. Cohen", "Edoardo M. Ponti"], "summary": "To what extent do vision-and-language foundation models possess a realistic\nworld model (observation $\\times$ action $\\rightarrow$ observation) and a\ndynamics model (observation $\\times$ observation $\\rightarrow$ action), when\nactions are expressed through language? While open-source foundation models\nstruggle with both, we find that fine-tuning them to acquire a dynamics model\nthrough supervision is significantly easier than acquiring a world model. In\nturn, dynamics models can be used to bootstrap world models through two main\nstrategies: 1) weakly supervised learning from synthetic data and 2) inference\ntime verification. Firstly, the dynamics model can annotate actions for\nunlabelled pairs of video frame observations to expand the training data. We\nfurther propose a new objective, where image tokens in observation pairs are\nweighted by their importance, as predicted by a recognition model. Secondly,\nthe dynamics models can assign rewards to multiple samples of the world model\nto score them, effectively guiding search at inference time. We evaluate the\nworld models resulting from both strategies through the task of action-centric\nimage editing on Aurora-Bench. Our best model achieves a performance\ncompetitive with state-of-the-art image editing models, improving on them by a\nmargin of $15\\%$ on real-world subsets according to GPT4o-as-judge, and\nachieving the best average human evaluation across all subsets of Aurora-Bench.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06006v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05957", "title": "Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization", "authors": ["Tianjun Yao", "Haoxuan Li", "Yongqiang Chen", "Tongliang Liu", "Le Song", "Eric Xing", "Zhiqiang Shen"], "summary": "Graph Neural Networks (GNNs) often encounter significant performance\ndegradation under distribution shifts between training and test data, hindering\ntheir applicability in real-world scenarios. Recent studies have proposed\nvarious methods to address the out-of-distribution generalization challenge,\nwith many methods in the graph domain focusing on directly identifying an\ninvariant subgraph that is predictive of the target label. However, we argue\nthat identifying the edges from the invariant subgraph directly is challenging\nand error-prone, especially when some spurious edges exhibit strong\ncorrelations with the targets. In this paper, we propose PrunE, the first\npruning-based graph OOD method that eliminates spurious edges to improve OOD\ngeneralizability. By pruning spurious edges, \\mine{} retains the invariant\nsubgraph more comprehensively, which is critical for OOD generalization.\nSpecifically, PrunE employs two regularization terms to prune spurious edges:\n1) graph size constraint to exclude uninformative spurious edges, and 2)\n$\\epsilon$-probability alignment to further suppress the occurrence of spurious\nedges. Through theoretical analysis and extensive experiments, we show that\nPrunE achieves superior OOD performance and outperforms previous\nstate-of-the-art methods significantly. Codes are available at:\n\\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.", "comment": "Submission of ICML2025, with score 4/4/3/3", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05957v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06007", "title": "Enhancing Orthopox Image Classification Using Hybrid Machine Learning and Deep Learning Models", "authors": ["Alejandro Puente-Castro", "Enrique Fernandez-Blanco", "Daniel Rivero", "Andres Molares-Ulloa"], "summary": "Orthopoxvirus infections must be accurately classified from medical pictures\nfor an easy and early diagnosis and epidemic prevention. The necessity for\nautomated and scalable solutions is highlighted by the fact that traditional\ndiagnostic techniques can be time-consuming and require expert interpretation\nand there are few and biased data sets of the different types of Orthopox. In\norder to improve classification performance and lower computational costs, a\nhybrid strategy is put forth in this paper that uses Machine Learning models\ncombined with pretrained Deep Learning models to extract deep feature\nrepresentations without the need for augmented data. The findings show that\nthis feature extraction method, when paired with other methods in the\nstate-of-the-art, produces excellent classification outcomes while preserving\ntraining and inference efficiency. The proposed approach demonstrates strong\ngeneralization and robustness across multiple evaluation settings, offering a\nscalable and interpretable solution for real-world clinical deployment.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06007v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05960", "title": "AQUATIC-Diff: Additive Quantization for Truly Tiny Compressed Diffusion Models", "authors": ["Adil Hasan", "Thomas Peyrin"], "summary": "Significant investments have been made towards the commodification of\ndiffusion models for generation of diverse media. Their mass-market adoption is\nhowever still hobbled by the intense hardware resource requirements of\ndiffusion model inference. Model quantization strategies tailored specifically\ntowards diffusion models have been useful in easing this burden, yet have\ngenerally explored the Uniform Scalar Quantization (USQ) family of quantization\nmethods. In contrast, Vector Quantization (VQ) methods, which operate on groups\nof multiple related weights as the basic unit of compression, have seen\nsubstantial success in Large Language Model (LLM) quantization. In this work,\nwe apply codebook-based additive vector quantization to the problem of\ndiffusion model compression. Our resulting approach achieves a new Pareto\nfrontier for the extremely low-bit weight quantization on the standard\nclass-conditional benchmark of LDM-4 on ImageNet at 20 inference time steps.\nNotably, we report sFID 1.92 points lower than the full-precision model at W4A8\nand the best-reported results for FID, sFID and ISC at W2A8. We are also able\nto demonstrate FLOPs savings on arbitrary hardware via an efficient inference\nkernel, as opposed to savings resulting from small integer operations which may\nlack broad hardware support.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05960v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06023", "title": "Restereo: Diffusion stereo video generation and restoration", "authors": ["Xingchang Huang", "Ashish Kumar Singh", "Florian Dubost", "Cristina Nader Vasconcelos", "Sakar Khattar", "Liang Shi", "Christian Theobalt", "Cengiz Oztireli", "Gurprit Singh"], "summary": "Stereo video generation has been gaining increasing attention with recent\nadvancements in video diffusion models. However, most existing methods focus on\ngenerating 3D stereoscopic videos from monocular 2D videos. These approaches\ntypically assume that the input monocular video is of high quality, making the\ntask primarily about inpainting occluded regions in the warped video while\npreserving disoccluded areas. In this paper, we introduce a new pipeline that\nnot only generates stereo videos but also enhances both left-view and\nright-view videos consistently with a single model. Our approach achieves this\nby fine-tuning the model on degraded data for restoration, as well as\nconditioning the model on warped masks for consistent stereo generation. As a\nresult, our method can be fine-tuned on a relatively small synthetic stereo\nvideo datasets and applied to low-quality real-world videos, performing both\nstereo video generation and restoration. Experiments demonstrate that our\nmethod outperforms existing approaches both qualitatively and quantitatively in\nstereo video generation from low-resolution inputs.", "comment": "12 pages, 5 figures", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06023v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06026", "title": "O-MaMa @ EgoExo4D Correspondence Challenge: Learning Object Mask Matching between Egocentric and Exocentric Views", "authors": ["Lorenzo Mur-Labadia", "Maria Santos-Villafranca", "Alejandro Perez-Yus", "Jesus Bermudez-Cameo", "Ruben Martinez-Cantin", "Jose J. Guerrero"], "summary": "The goal of the correspondence task is to segment specific objects across\ndifferent views. This technical report re-defines cross-image segmentation by\ntreating it as a mask matching task. Our method consists of: (1) A Mask-Context\nEncoder that pools dense DINOv2 semantic features to obtain discriminative\nobject-level representations from FastSAM mask candidates, (2) an\nEgo$\\leftrightarrow$Exo Cross-Attention that fuses multi-perspective\nobservations, (3) a Mask Matching contrastive loss that aligns cross-view\nfeatures in a shared latent space, and (4) a Hard Negative Adjacent Mining\nstrategy to encourage the model to better differentiate between nearby objects.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06026v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05971", "title": "On Measuring Long-Range Interactions in Graph Neural Networks", "authors": ["Jacob Bamberger", "Benjamin Gutteridge", "Scott le Roux", "Michael M. Bronstein", "Xiaowen Dong"], "summary": "Long-range graph tasks -- those dependent on interactions between distant\nnodes -- are an open problem in graph neural network research. Real-world\nbenchmark tasks, especially the Long Range Graph Benchmark, have become popular\nfor validating the long-range capability of proposed architectures. However,\nthis is an empirical approach that lacks both robustness and theoretical\nunderpinning; a more principled characterization of the long-range problem is\nrequired. To bridge this gap, we formalize long-range interactions in graph\ntasks, introduce a range measure for operators on graphs, and validate it with\nsynthetic experiments. We then leverage our measure to examine commonly used\ntasks and architectures, and discuss to what extent they are, in fact,\nlong-range. We believe our work advances efforts to define and address the\nlong-range problem on graphs, and that our range measure will aid evaluation of\nnew datasets and architectures.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05971v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06027", "title": "Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification", "authors": ["Yuhao Sun", "Jiacheng Zhang", "Zesheng Ye", "Chaowei Xiao", "Feng Liu"], "summary": "Diffusion-based purification (DBP) methods aim to remove adversarial noise\nfrom the input sample by first injecting Gaussian noise through a forward\ndiffusion process, and then recovering the clean example through a reverse\ngenerative process. In the above process, how much Gaussian noise is injected\nto the input sample is key to the success of DBP methods, which is controlled\nby a constant noise level $t^*$ for all samples in existing methods. In this\npaper, we discover that an optimal $t^*$ for each sample indeed could be\ndifferent. Intuitively, the cleaner a sample is, the less the noise it should\nbe injected, and vice versa. Motivated by this finding, we propose a new\nframework, called Sample-specific Score-aware Noise Injection (SSNI).\nSpecifically, SSNI uses a pre-trained score network to estimate how much a data\npoint deviates from the clean data distribution (i.e., score norms). Then,\nbased on the magnitude of score norms, SSNI applies a reweighting function to\nadaptively adjust $t^*$ for each sample, achieving sample-specific noise\ninjections. Empirically, incorporating our framework with existing DBP methods\nresults in a notable improvement in both accuracy and robustness on CIFAR-10\nand ImageNet-1K, highlighting the necessity to allocate distinct noise levels\nto different samples in DBP methods. Our code is available at:\nhttps://github.com/tmlr-group/SSNI.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06027v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05480", "title": "ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting", "authors": ["Daniel Wang", "Patrick Rim", "Tian Tian", "Alex Wong", "Ganesh Sundaramoorthi"], "summary": "We present ODE-GS, a novel method that unifies 3D Gaussian Splatting with\nlatent neural ordinary differential equations (ODEs) to forecast dynamic 3D\nscenes far beyond the time span seen during training. Existing neural rendering\nsystems - whether NeRF- or 3DGS-based - embed time directly in a deformation\nnetwork and therefore excel at interpolation but collapse when asked to predict\nthe future, where timestamps are strictly out-of-distribution. ODE-GS\neliminates this dependency: after learning a high-fidelity, time-conditioned\ndeformation model for the training window, we freeze it and train a Transformer\nencoder that summarizes past Gaussian trajectories into a latent state whose\ncontinuous evolution is governed by a neural ODE. Numerical integration of this\nlatent flow yields smooth, physically plausible Gaussian trajectories that can\nbe queried at any future instant and rendered in real time. Coupled with a\nvariational objective and a lightweight second-derivative regularizer, ODE-GS\nattains state-of-the-art extrapolation on D-NeRF and NVFI benchmarks, improving\nPSNR by up to 10 dB and halving perceptual error (LPIPS) relative to the\nstrongest baselines. Our results demonstrate that continuous-time latent\ndynamics are a powerful, practical route to photorealistic prediction of\ncomplex 3D scenes.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.05480v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06035", "title": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion", "authors": ["Shiyi Zhang", "Dong Liang", "Hairong Zheng", "Yihang Zhou"], "summary": "Reconstructing visual information from brain activity bridges the gap between\nneuroscience and computer vision. Even though progress has been made in\ndecoding images from fMRI using generative models, a challenge remains in\naccurately recovering highly complex visual stimuli. This difficulty stems from\ntheir elemental density and diversity, sophisticated spatial structures, and\nmultifaceted semantic information.\n  To address these challenges, we propose HAVIR that contains two adapters: (1)\nThe AutoKL Adapter transforms fMRI voxels into a latent diffusion prior,\ncapturing topological structures; (2) The CLIP Adapter converts the voxels to\nCLIP text and image embeddings, containing semantic information. These\ncomplementary representations are fused by Versatile Diffusion to generate the\nfinal reconstructed image. To extract the most essential semantic information\nfrom complex scenarios, the CLIP Adapter is trained with text captions\ndescribing the visual stimuli and their corresponding semantic images\nsynthesized from these captions. The experimental results demonstrate that\nHAVIR effectively reconstructs both structural features and semantic\ninformation of visual stimuli even in complex scenarios, outperforming existing\nmodels.", "comment": "15 pages, 6 figures, 3 tabs", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06035v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05980", "title": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification", "authors": ["Geonwoo Cho", "Jaemoon Lee", "Jaegyun Im", "Subi Lee", "Jihwan Lee", "Sundong Kim"], "summary": "Skill-based reinforcement learning (SBRL) enables rapid adaptation in\nenvironments with sparse rewards by pretraining a skill-conditioned policy.\nEffective skill learning requires jointly maximizing both exploration and skill\ndiversity. However, existing methods often face challenges in simultaneously\noptimizing for these two conflicting objectives. In this work, we propose a new\nmethod, Adaptive Multi-objective Projection for balancing Exploration and skill\nDiversification (AMPED), which explicitly addresses both exploration and skill\ndiversification. We begin by conducting extensive ablation studies to identify\nand define a set of objectives that effectively capture the aspects of\nexploration and skill diversity, respectively. During the skill pretraining\nphase, AMPED introduces a gradient surgery technique to balance the objectives\nof exploration and skill diversity, mitigating conflicts and reducing reliance\non heuristic tuning. In the subsequent fine-tuning phase, AMPED incorporates a\nskill selector module that dynamically selects suitable skills for downstream\ntasks, based on task-specific performance signals. Our approach achieves\nperformance that surpasses SBRL baselines across various benchmarks. These\nresults highlight the importance of explicitly harmonizing exploration and\ndiversity and demonstrate the effectiveness of AMPED in enabling robust and\ngeneralizable skill learning. Project Page: https://geonwoo.me/amped/", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05980v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06041", "title": "Tensor-to-Tensor Models with Fast Iterated Sum Features", "authors": ["Joscha Diehl", "Rasheed Ibraheem", "Leonard Schmitz", "Yue Wu"], "summary": "Data in the form of images or higher-order tensors is ubiquitous in modern\ndeep learning applications. Owing to their inherent high dimensionality, the\nneed for subquadratic layers processing such data is even more pressing than\nfor sequence data. We propose a novel tensor-to-tensor layer with linear cost\nin the input size, utilizing the mathematical gadget of ``corner trees'' from\nthe field of permutation counting. In particular, for order-two tensors, we\nprovide an image-to-image layer that can be plugged into image processing\npipelines. On the one hand, our method can be seen as a higher-order\ngeneralization of state-space models. On the other hand, it is based on a\nmultiparameter generalization of the signature of iterated integrals (or sums).\nThe proposed tensor-to-tensor concept is used to build a neural network layer\ncalled the Fast Iterated Sums (FIS) layer which integrates seamlessly with\nother layer types. We demonstrate the usability of the FIS layer with both\nclassification and anomaly detection tasks. By replacing some layers of a\nsmaller ResNet architecture with FIS, a similar accuracy (with a difference of\nonly 0.1\\%) was achieved in comparison to a larger ResNet while reducing the\nnumber of trainable parameters and multi-add operations. The FIS layer was also\nused to build an anomaly detection model that achieved an average AUROC of\n97.3\\% on the texture images of the popular MVTec AD dataset. The processing\nand modelling codes are publicly available at\nhttps://github.com/diehlj/fast-iterated-sums.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06041v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06042", "title": "SDS-Net: Shallow-Deep Synergism-detection Network for infrared small target detection", "authors": ["Taoran Yue", "Xiaojin Lu", "Jiaxi Cai", "Yuanping Chen", "Shibing Chu"], "summary": "Current CNN-based infrared small target detection(IRSTD) methods generally\noverlook the heterogeneity between shallow and deep features, leading to\ninefficient collaboration between shallow fine grained structural information\nand deep high-level semantic representations. Additionally, the dependency\nrelationships and fusion mechanisms across different feature hierarchies lack\nsystematic modeling, which fails to fully exploit the complementarity of\nmultilevel features. These limitations hinder IRSTD performance while incurring\nsubstantial computational costs. To address these challenges, this paper\nproposes a shallow-deep synergistic detection network (SDS-Net) that\nefficiently models multilevel feature representations to increase both the\ndetection accuracy and computational efficiency in IRSTD tasks. SDS-Net\nintroduces a dual-branch architecture that separately models the structural\ncharacteristics and semantic properties of features, effectively preserving\nshallow spatial details while capturing deep semantic representations, thereby\nachieving high-precision detection with significantly improved inference speed.\nFurthermore, the network incorporates an adaptive feature fusion module to\ndynamically model cross-layer feature correlations, enhancing overall feature\ncollaboration and representation capability. Comprehensive experiments on three\npublic datasets (NUAA-SIRST, NUDT-SIRST, and IRSTD-1K) demonstrate that SDS-Net\noutperforms state-of-the-art IRSTD methods while maintaining low computational\ncomplexity and high inference efficiency, showing superior detection\nperformance and broad application prospects. Our code will be made public at\nhttps://github.com/PhysiLearn/SDS-Net.", "comment": "13 pages,9 figures, Submitted IEEE Transactions on Geoscience and\n  Remote Sensing", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06042v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06076", "title": "Full Conformal Adaptation of Medical Vision-Language Models", "authors": ["Julio Silva-Rodríguez", "Leo Fillioux", "Paul-Henry Cournède", "Maria Vakalopoulou", "Stergios Christodoulidis", "Ismail Ben Ayed", "Jose Dolz"], "summary": "Vision-language models (VLMs) pre-trained at large scale have shown\nunprecedented transferability capabilities and are being progressively\nintegrated into medical image analysis. Although its discriminative potential\nhas been widely explored, its reliability aspect remains overlooked. This work\ninvestigates their behavior under the increasingly popular split conformal\nprediction (SCP) framework, which theoretically guarantees a given error level\non output sets by leveraging a labeled calibration set. However, the zero-shot\nperformance of VLMs is inherently limited, and common practice involves\nfew-shot transfer learning pipelines, which cannot absorb the rigid\nexchangeability assumptions of SCP. To alleviate this issue, we propose full\nconformal adaptation, a novel setting for jointly adapting and conformalizing\npre-trained foundation models, which operates transductively over each test\ndata point using a few-shot adaptation set. Moreover, we complement this\nframework with SS-Text, a novel training-free linear probe solver for VLMs that\nalleviates the computational cost of such a transductive approach. We provide\ncomprehensive experiments using 3 different modality-specialized medical VLMs\nand 9 adaptation tasks. Our framework requires exactly the same data as SCP,\nand provides consistent relative improvements of up to 27% on set efficiency\nwhile maintaining the same coverage guarantees.", "comment": "IPMI 2025. Code: https://github.com/jusiro/FCA", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06076v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05999", "title": "Machine learning for in-situ composition mapping in a self-driving magnetron sputtering system", "authors": ["Sanna Jarl", "Jens Sjölund", "Robert J. W. Frost", "Anders Holst", "Jonathan J. S. Scragg"], "summary": "Self-driving labs (SDLs), employing automation and machine learning (ML) to\naccelerate experimental procedures, have enormous potential in the discovery of\nnew materials. However, in thin film science, SDLs are mainly restricted to\nsolution-based synthetic methods which are easier to automate but cannot access\nthe broad chemical space of inorganic materials. This work presents an SDL\nbased on magnetron co-sputtering. We are using combinatorial frameworks,\nobtaining accurate composition maps on multi-element, compositionally graded\nthin films. This normally requires time-consuming ex-situ analysis prone to\nsystematic errors. We present a rapid and calibration-free in-situ, ML driven\napproach to produce composition maps for arbitrary source combinations and\nsputtering conditions. We develop a method to predict the composition\ndistribution in a multi-element combinatorial thin film, using in-situ\nmeasurements from quartz-crystal microbalance sensors placed in a sputter\nchamber. For a given source, the sensor readings are learned as a function of\nthe sputtering pressure and magnetron power, through active learning using\nGaussian processes (GPs). The final GPs are combined with a geometric model of\nthe deposition flux distribution in the chamber, which allows interpolation of\nthe deposition rates from each source, at any position across the sample. We\ninvestigate several acquisition functions for the ML procedure. A fully\nBayesian GP - BALM (Bayesian active learning MacKay) - achieved the best\nperformance, learning the deposition rates for a single source in 10\nexperiments. Prediction accuracy for co-sputtering composition distributions\nwas verified experimentally. Our framework dramatically increases throughput by\navoiding the need for extensive characterisation or calibration, thus\ndemonstrating the potential of ML-guided SDLs to accelerate materials\nexploration.", "comment": "24 pages, 10 figures. Submitted to the journal npj computational\n  materials", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.05999v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06084", "title": "WisWheat: A Three-Tiered Vision-Language Dataset for Wheat Management", "authors": ["Bowen Yuan", "Selena Song", "Javier Fernandez", "Yadan Luo", "Mahsa Baktashmotlagh", "Zijian Wang"], "summary": "Wheat management strategies play a critical role in determining yield.\nTraditional management decisions often rely on labour-intensive expert\ninspections, which are expensive, subjective and difficult to scale. Recently,\nVision-Language Models (VLMs) have emerged as a promising solution to enable\nscalable, data-driven management support. However, due to a lack of\ndomain-specific knowledge, directly applying VLMs to wheat management tasks\nresults in poor quantification and reasoning capabilities, ultimately producing\nvague or even misleading management recommendations. In response, we propose\nWisWheat, a wheat-specific dataset with a three-layered design to enhance VLM\nperformance on wheat management tasks: (1) a foundational pretraining dataset\nof 47,871 image-caption pairs for coarsely adapting VLMs to wheat morphology;\n(2) a quantitative dataset comprising 7,263 VQA-style image-question-answer\ntriplets for quantitative trait measuring tasks; and (3) an Instruction\nFine-tuning dataset with 4,888 samples targeting biotic and abiotic stress\ndiagnosis and management plan for different phenological stages. Extensive\nexperimental results demonstrate that fine-tuning open-source VLMs (e.g.,\nQwen2.5 7B) on our dataset leads to significant performance improvements.\nSpecifically, the Qwen2.5 VL 7B fine-tuned on our wheat instruction dataset\nachieves accuracy scores of 79.2% and 84.6% on wheat stress and growth stage\nconversation tasks respectively, surpassing even general-purpose commercial\nmodels such as GPT-4o by a margin of 11.9% and 34.6%.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06084v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06001", "title": "LaDEEP: A Deep Learning-based Surrogate Model for Large Deformation of Elastic-Plastic Solids", "authors": ["Shilong Tao", "Zhe Feng", "Haonan Sun", "Zhanxing Zhu", "Yunhuai Liu"], "summary": "Scientific computing for large deformation of elastic-plastic solids is\ncritical for numerous real-world applications. Classical numerical solvers rely\nprimarily on local discrete linear approximation and are constrained by an\ninherent trade-off between accuracy and efficiency. Recently, deep learning\nmodels have achieved impressive progress in solving the continuum mechanism.\nWhile previous models have explored various architectures and constructed\ncoefficient-solution mappings, they are designed for general instances without\nconsidering specific problem properties and hard to accurately handle with\ncomplex elastic-plastic solids involving contact, loading and unloading. In\nthis work, we take stretch bending, a popular metal fabrication technique, as\nour case study and introduce LaDEEP, a deep learning-based surrogate model for\n\\textbf{La}rge \\textbf{De}formation of \\textbf{E}lastic-\\textbf{P}lastic\nSolids. We encode the partitioned regions of the involved slender solids into a\ntoken sequence to maintain their essential order property. To characterize the\nphysical process of the solid deformation, a two-stage Transformer-based module\nis designed to predict the deformation with the sequence of tokens as input.\nEmpirically, LaDEEP achieves five magnitudes faster speed than finite element\nmethods with a comparable accuracy, and gains 20.47\\% relative improvement on\naverage compared to other deep learning baselines. We have also deployed our\nmodel into a real-world industrial production system, and it has shown\nremarkable performance in both accuracy and efficiency.", "comment": "Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining V.2 (KDD '25)", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06001v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06085", "title": "Feedback Guidance of Diffusion Models", "authors": ["Koulischer Felix", "Handke Florian", "Deleu Johannes", "Demeester Thomas", "Ambrogioni Luca"], "summary": "While Classifier-Free Guidance (CFG) has become standard for improving sample\nfidelity in conditional diffusion models, it can harm diversity and induce\nmemorization by applying constant guidance regardless of whether a particular\nsample needs correction. We propose FeedBack Guidance (FBG), which uses a\nstate-dependent coefficient to self-regulate guidance amounts based on need.\nOur approach is derived from first principles by assuming the learned\nconditional distribution is linearly corrupted by the unconditional\ndistribution, contrasting with CFG's implicit multiplicative assumption. Our\nscheme relies on feedback of its own predictions about the conditional signal\ninformativeness to adapt guidance dynamically during inference, challenging the\nview of guidance as a fixed hyperparameter. The approach is benchmarked on\nImageNet512x512, where it significantly outperforms Classifier-Free Guidance\nand is competitive to Limited Interval Guidance (LIG) while benefitting from a\nstrong mathematical framework. On Text-To-Image generation, we demonstrate\nthat, as anticipated, our approach automatically applies higher guidance scales\nfor complex prompts than for simpler ones and that it can be easily combined\nwith existing guidance schemes such as CFG or LIG.", "comment": "Preprint. Article currently under review. Code is available at:\n  https://github.com/FelixKoulischer/FBG_using_edm2", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06085v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05700", "title": "RKEFino1: A Regulation Knowledge-Enhanced Large Language Model", "authors": ["Yan Wang", "Yueru He", "Ruoyu Xiang", "Jeff Zhao"], "summary": "Recent advances in large language models (LLMs) hold great promise for\nfinancial applications but introduce critical accuracy and compliance\nchallenges in Digital Regulatory Reporting (DRR). To address these issues, we\npropose RKEFino1, a regulation knowledge-enhanced financial reasoning model\nbuilt upon Fino1, fine-tuned with domain knowledge from XBRL, CDM, and MOF. We\nformulate two QA tasks-knowledge-based and mathematical reasoning-and introduce\na novel Numerical NER task covering financial entities in both sentences and\ntables. Experimental results demonstrate the effectiveness and generalization\ncapacity of RKEFino1 in compliance-critical financial tasks. We have released\nour model on Hugging Face.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05700v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06097", "title": "VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning", "authors": ["Zikang Wang", "Boyu Chen", "Zhengrong Yue", "Yi Wang", "Yu Qiao", "Limin Wang", "Yali Wang"], "summary": "The recent advance in video understanding has been driven by multimodal large\nlanguage models (MLLMs). But these MLLMs are good at analyzing short videos,\nwhile suffering from difficulties in understanding videos with a longer\ncontext. To address this difficulty, several agent paradigms have recently been\nproposed, using MLLMs as agents for retrieving extra contextual knowledge in a\nlong video. However, most existing agents ignore the key fact that a long video\nis composed with multiple shots, i.e., to answer the user question from a long\nvideo, it is critical to deeply understand its relevant shots like human.\nWithout such insight, these agents often mistakenly find redundant even noisy\ntemporal context, restricting their capacity for long video understanding. To\nfill this gap, we propose VideoChat-A1, a novel long video agent paradigm.\nDifferent from the previous works, our VideoChat-A1 can deeply think with long\nvideos, via a distinct chain-of-shot reasoning paradigm. More specifically, it\ncan progressively select the relevant shots of user question, and look into\nthese shots in a coarse-to-fine partition. By multi-modal reasoning along the\nshot chain, VideoChat-A1 can effectively mimic step-by-step human thinking\nprocess, allowing to interactively discover preferable temporal context for\nthoughtful understanding in long videos. Extensive experiments show that, our\nVideoChat-A1 achieves the state-of-the-art performance on the mainstream long\nvideo QA benchmarks, e.g., it achieves 77.0 on VideoMME and 70.1 on EgoSchema,\noutperforming its strong baselines (e.g., Intern2.5VL-8B and\nInternVideo2.5-8B), by up to 10.8\\% and 6.2\\%. Compared to leading close-source\nGPT-4o and Gemini 1.5 Pro, VideoChat-A1 offers competitive accuracy, but with\n7\\% input frames and 12\\% inference time on average.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06097v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06005", "title": "LightGTS: A Lightweight General Time Series Forecasting Model", "authors": ["Yihang Wang", "Yuying Qiu", "Peng Chen", "Yang Shu", "Zhongwen Rao", "Lujia Pan", "Bin Yang", "Chenjuan Guo"], "summary": "Existing works on general time series forecasting build foundation models\nwith heavy model parameters through large-scale multi-source pre-training.\nThese models achieve superior generalization ability across various datasets at\nthe cost of significant computational burdens and limitations in\nresource-constrained scenarios. This paper introduces LightGTS, a lightweight\ngeneral time series forecasting model designed from the perspective of\nconsistent periodical modeling. To handle diverse scales and intrinsic periods\nin multi-source pre-training, we introduce Periodical Tokenization, which\nextracts consistent periodic patterns across different datasets with varying\nscales. To better utilize the periodicity in the decoding process, we further\nintroduce Periodical Parallel Decoding, which leverages historical tokens to\nimprove forecasting. Based on the two techniques above which fully leverage the\ninductive bias of periods inherent in time series, LightGTS uses a lightweight\nmodel to achieve outstanding performance on general time series forecasting. It\nachieves state-of-the-art forecasting performance on 9 real-world benchmarks in\nboth zero-shot and full-shot settings with much better efficiency compared with\nexisting time series foundation models.", "comment": "Accepted by the 42th International Conference on Machine Learning\n  (ICML 2025)", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06005v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06120", "title": "Bidirectional Image-Event Guided Low-Light Image Enhancement", "authors": ["Zhanwen Liu", "Huanna Song", "Yang Wang", "Nan Yang", "Shangyu Xie", "Yisheng An", "Xiangmo Zhao"], "summary": "Under extreme low-light conditions, traditional frame-based cameras, due to\ntheir limited dynamic range and temporal resolution, face detail loss and\nmotion blur in captured images. To overcome this bottleneck, researchers have\nintroduced event cameras and proposed event-guided low-light image enhancement\nalgorithms. However, these methods neglect the influence of global\nlow-frequency noise caused by dynamic lighting conditions and local structural\ndiscontinuities in sparse event data. To address these issues, we propose an\ninnovative Bidirectional guided Low-light Image Enhancement framework (BiLIE).\nSpecifically, to mitigate the significant low-frequency noise introduced by\nglobal illumination step changes, we introduce the frequency high-pass\nfiltering-based Event Feature Enhancement (EFE) module at the event\nrepresentation level to suppress the interference of low-frequency information,\nand preserve and highlight the high-frequency edges.Furthermore, we design a\nBidirectional Cross Attention Fusion (BCAF) mechanism to acquire high-frequency\nstructures and edges while suppressing structural discontinuities and local\nnoise introduced by sparse event guidance, thereby generating smoother fused\nrepresentations.Additionally, considering the poor visual quality and color\nbias in existing datasets, we provide a new dataset (RELIE), with high-quality\nground truth through a reliable enhancement scheme. Extensive experimental\nresults demonstrate that our proposed BiLIE outperforms state-of-the-art\nmethods by 0.96dB in PSNR and 0.03 in LPIPS.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06120v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06021", "title": "Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems", "authors": ["Shilong Tao", "Zhe Feng", "Haonan Sun", "Zhanxing Zhu", "Yunhuai Liu"], "summary": "Multi-solid systems are foundational to a wide range of real-world\napplications, yet modeling their complex interactions remains challenging.\nExisting deep learning methods predominantly rely on implicit modeling, where\nthe factors influencing solid deformation are not explicitly represented but\nare instead indirectly learned. However, as the number of solids increases,\nthese methods struggle to accurately capture intricate physical interactions.\nIn this paper, we introduce a novel explicit modeling paradigm that\nincorporates factors influencing solid deformation through structured modules.\nSpecifically, we present Unisoma, a unified and flexible Transformer-based\nmodel capable of handling variable numbers of solids. Unisoma directly captures\nphysical interactions using contact modules and adaptive interaction allocation\nmechanism, and learns the deformation through a triplet relationship. Compared\nto implicit modeling techniques, explicit modeling is more well-suited for\nmulti-solid systems with diverse coupling patterns, as it enables detailed\ntreatment of each solid while preventing information blending and confusion.\nExperimentally, Unisoma achieves consistent state-of-the-art performance across\nseven well-established datasets and two complex multi-solid tasks. Code is\navaiable at \\href{this link}{https://github.com/therontau0054/Unisoma}.", "comment": "Proceedings of the 42nd International Conference on Machine Learning", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06021v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05495", "title": "Learning-Augmented Hierarchical Clustering", "authors": ["Vladimir Braverman", "Jon C. Ergun", "Chen Wang", "Samson Zhou"], "summary": "Hierarchical clustering (HC) is an important data analysis technique in which\nthe goal is to recursively partition a dataset into a tree-like structure while\ngrouping together similar data points at each level of granularity.\nUnfortunately, for many of the proposed HC objectives, there exist strong\nbarriers to approximation algorithms with the hardness of approximation. Thus,\nwe consider the problem of hierarchical clustering given auxiliary information\nfrom natural oracles. Specifically, we focus on a *splitting oracle* which,\nwhen provided with a triplet of vertices $(u,v,w)$, answers (possibly\nerroneously) the pairs of vertices whose lowest common ancestor includes all\nthree vertices in an optimal tree, i.e., identifying which vertex ``splits\naway'' from the others. Using such an oracle, we obtain the following results:\n  - A polynomial-time algorithm that outputs a hierarchical clustering tree\nwith $O(1)$-approximation to the Dasgupta objective (Dasgupta [STOC'16]).\n  - A near-linear time algorithm that outputs a hierarchical clustering tree\nwith $(1-o(1))$-approximation to the Moseley-Wang objective (Moseley and Wang\n[NeurIPS'17]).\n  Under the plausible Small Set Expansion Hypothesis, no polynomial-time\nalgorithm can achieve any constant approximation for Dasgupta's objective or\n$(1-C)$-approximation for the Moseley-Wang objective for some constant $C>0$.\nAs such, our results demonstrate that the splitting oracle enables algorithms\nto outperform standard HC approaches and overcome hardness constraints.\nFurthermore, our approaches extend to sublinear settings, in which we show new\nstreaming and PRAM algorithms for HC with improved guarantees.", "comment": "ICML 2025; abstract shortened for arxiv requirements", "cate": "cs.DS", "url": "http://arxiv.org/pdf/2506.05495v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06128", "title": "CCLSTM: Coupled Convolutional Long-Short Term Memory Network for Occupancy Flow Forecasting", "authors": ["Peter Lengyel"], "summary": "Predicting future states of dynamic agents is a fundamental task in\nautonomous driving. An expressive representation for this purpose is Occupancy\nFlow Fields, which provide a scalable and unified format for modeling motion,\nspatial extent, and multi-modal future distributions. While recent methods have\nachieved strong results using this representation, they often depend on\nhigh-quality vectorized inputs, which are unavailable or difficult to generate\nin practice, and the use of transformer-based architectures, which are\ncomputationally intensive and costly to deploy. To address these issues, we\npropose \\textbf{Coupled Convolutional LSTM (CCLSTM)}, a lightweight, end-to-end\ntrainable architecture based solely on convolutional operations. Without\nrelying on vectorized inputs or self-attention mechanisms, CCLSTM effectively\ncaptures temporal dynamics and spatial occupancy-flow correlations using a\ncompact recurrent convolutional structure. Despite its simplicity, CCLSTM\nachieves state-of-the-art performance on occupancy flow metrics and, as of this\nsubmission, ranks \\(1^{\\text{st}}\\) in all metrics on the 2024 Waymo Occupancy\nand Flow Prediction Challenge leaderboard.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06128v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06039", "title": "Do-PFN: In-Context Learning for Causal Effect Estimation", "authors": ["Jake Robertson", "Arik Reuter", "Siyuan Guo", "Noah Hollmann", "Frank Hutter", "Bernhard Schölkopf"], "summary": "Estimation of causal effects is critical to a range of scientific\ndisciplines. Existing methods for this task either require interventional data,\nknowledge about the ground truth causal graph, or rely on assumptions such as\nunconfoundedness, restricting their applicability in real-world settings. In\nthe domain of tabular machine learning, Prior-data fitted networks (PFNs) have\nachieved state-of-the-art predictive performance, having been pre-trained on\nsynthetic data to solve tabular prediction problems via in-context learning. To\nassess whether this can be transferred to the harder problem of causal effect\nestimation, we pre-train PFNs on synthetic data drawn from a wide variety of\ncausal structures, including interventions, to predict interventional outcomes\ngiven observational data. Through extensive experiments on synthetic case\nstudies, we show that our approach allows for the accurate estimation of causal\neffects without knowledge of the underlying causal graph. We also perform\nablation studies that elucidate Do-PFN's scalability and robustness across\ndatasets with a variety of causal characteristics.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06039v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06144", "title": "CLaMR: Contextualized Late-Interaction for Multimodal Content Retrieval", "authors": ["David Wan", "Han Wang", "Elias Stengel-Eskin", "Jaemin Cho", "Mohit Bansal"], "summary": "Online video web content is richly multimodal: a single video blends vision,\nspeech, ambient audio, and on-screen text. Retrieval systems typically treat\nthese modalities as independent retrieval sources, which can lead to noisy and\nsubpar retrieval. We explore multimodal video content retrieval, where\nrelevance can be scored from one particular modality or jointly across multiple\nmodalities simultaneously. Consequently, an effective retriever must\ndynamically choose which modality (or set of modalities) best addresses the\nquery. We introduce CLaMR, a multimodal, late-interaction retriever that\njointly indexes 4 modalities: video frames, transcribed speech, on-screen text,\nand metadata. CLaMR jointly encodes all modalities with a unified multimodal\nbackbone for improved contextualization and is trained to enhance dynamic\nmodality selection via two key innovations. First, given the lack of training\ndata for multimodal retrieval, we introduce MultiVENT 2.0++, a large-scale\nsynthetic training dataset built on MultiVENT 2.0 (event-centric videos in\nvarious languages paired with queries) with modality-targeted queries. Next, we\npropose a modality-aware loss that jointly trains according to a standard\ncontrastive objective alongside an objective for learning correct modality\nusage. On the test sets of MultiVENT 2.0++ and MSRVTT, conventional aggregation\nstrategies, such as averaging similarities for baseline retrievers, degrade\nperformance by introducing noise from irrelevant modalities. In contrast, CLaMR\nconsistently outperforms existing retrievers: on MultiVENT 2.0++, CLaMR\nimproves nDCG@10 by 25.6 over the best single-modality retriever and by 35.4\nover the best multi-modality retriever. We illustrate CLaMR's downstream\nutility on long-video QA, retrieving relevant frames and obtaining a 3.50%\nboost over LanguageBind on Video-MME and 1.42% over dense sampling on\nLongVideoBench.", "comment": "18 pages. Code and data: https://github.com/meetdavidwan/clamr", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06144v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06045", "title": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "authors": ["Tobias Würth", "Niklas Freymuth", "Gerhard Neumann", "Luise Kärger"], "summary": "Graph-based learned simulators have emerged as a promising approach for\nsimulating physical systems on unstructured meshes, offering speed and\ngeneralization across diverse geometries. However, they often struggle with\ncapturing global phenomena, such as bending or long-range correlations, and\nsuffer from error accumulation over long rollouts due to their reliance on\nlocal message passing and direct next-step prediction. We address these\nlimitations by introducing the Rolling Diffusion-Batched Inference Network\n(ROBIN), a novel learned simulator that integrates two key innovations: (i)\nRolling Diffusion, a parallelized inference scheme that amortizes the cost of\ndiffusion-based refinement across physical time steps by overlapping denoising\nsteps across a temporal window. (ii) A Hierarchical Graph Neural Network built\non algebraic multigrid coarsening, enabling multiscale message passing across\ndifferent mesh resolutions. This architecture, implemented via\nAlgebraic-hierarchical Message Passing Networks, captures both fine-scale local\ndynamics and global structural effects critical for phenomena like beam bending\nor multi-body contact. We validate ROBIN on challenging 2D and 3D solid\nmechanics benchmarks involving geometric, material, and contact nonlinearities.\nROBIN achieves state-of-the-art accuracy on all tasks, substantially\noutperforming existing next-step learned simulators while reducing inference\ntime by up to an order of magnitude compared to standard diffusion simulators.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06045v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06155", "title": "A Novel Large-scale Crop Dataset and Dual-stream Transformer Method for Fine-grained Hierarchical Crop Classification from Integrated Hyperspectral EnMAP Data and Multispectral Sentinel-2 Time Series", "authors": ["Wenyuan Li", "Shunlin Liang", "Yuxiang Zhang", "Liqin Liu", "Keyan Chen", "Yongzhe Chen", "Han Ma", "Jianglei Xu", "Yichuan Ma", "Shikang Guan", "Zhenwei Shi"], "summary": "Fine-grained crop classification is crucial for precision agriculture and\nfood security monitoring. It requires simultaneous capture of both phenological\ndynamics (obtained from multi-temporal satellite data like Sentinel-2) and\nsubtle spectral variations (demanding nanometer-scale spectral resolution from\nhyperspectral imagery). Research combining these two modalities remains scarce\ncurrently due to challenges in hyperspectral data acquisition and crop types\nannotation costs. To address these issues, we construct a hierarchical\nhyperspectral crop dataset (H2Crop) by integrating 30m-resolution EnMAP\nhyperspectral data with Sentinel-2 time series. With over one million annotated\nfield parcels organized in a four-tier crop taxonomy, H2Crop establishes a\nvital benchmark for fine-grained agricultural crop classification and\nhyperspectral image processing. We propose a dual-stream Transformer\narchitecture that synergistically processes these modalities. It coordinates\ntwo specialized pathways: a spectral-spatial Transformer extracts fine-grained\nsignatures from hyperspectral EnMAP data, while a temporal Swin Transformer\nextracts crop growth patterns from Sentinel-2 time series. The designed\nhierarchy classification heads with hierarchical fusion then simultaneously\ndelivers multi-level classification across all taxonomic tiers. Experiments\ndemonstrate that adding hyperspectral EnMAP data to Sentinel-2 time series\nyields a 4.2% average F1-scores improvement (peaking at 6.3%). Extensive\ncomparisons also confirming our method's higher accuracy over existing deep\nlearning approaches for crop type classification and the consistent benefits of\nhyperspectral data across varying temporal windows and crop change scenarios.\nCodes and dataset will be available at https://github.com/flyakon/H2Crop and\nwww.glass.hku.hk\n  Keywords: Crop type classification, precision agriculture, remote sensing,\ndeep learning, hyperspectral data, Sentinel-2 time series, fine-grained crops", "comment": "28 pages, 12 figures", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06155v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05725", "title": "Large Language Models are Good Relational Learners", "authors": ["Fang Wu", "Vijay Prakash Dwivedi", "Jure Leskovec"], "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, yet their application to relational deep learning (RDL)\nremains underexplored. Existing approaches adapt LLMs by traversing relational\nlinks between entities in a database and converting the structured data into\nflat text documents. Still, this text-based serialization disregards critical\nrelational structures, introduces redundancy, and often exceeds standard LLM\ncontext lengths. We introduce Rel-LLM, a novel architecture that utilizes a\ngraph neural network (GNN)- based encoder to generate structured relational\nprompts for LLMs within a retrieval-augmented generation (RAG) framework.\nUnlike traditional text-based serialization approaches, our method preserves\nthe inherent relational structure of databases while enabling LLMs to\neffectively process and reason over complex entity relationships. Specifically,\nthe GNN encoder extracts a local subgraph around an entity to build feature\nrepresentations that contain relevant entity relationships and temporal\ndependencies. These representations are transformed into structured prompts\nusing a denormalization process, effectively allowing the LLM to reason over\nrelational structures. Through extensive experiments, we demonstrate that\nRel-LLM outperforms existing methods on key RDL tasks, offering a scalable and\nefficient approach to integrating LLMs with structured data sources. Code is\navailable at https://github.com/smiles724/Rel-LLM.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05725v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06048", "title": "TRUST: Test-time Resource Utilization for Superior Trustworthiness", "authors": ["Haripriya Harikumar", "Santu Rana"], "summary": "Standard uncertainty estimation techniques, such as dropout, often struggle\nto clearly distinguish reliable predictions from unreliable ones. We attribute\nthis limitation to noisy classifier weights, which, while not impairing overall\nclass-level predictions, render finer-level statistics less informative. To\naddress this, we propose a novel test-time optimization method that accounts\nfor the impact of such noise to produce more reliable confidence estimates.\nThis score defines a monotonic subset-selection function, where population\naccuracy consistently increases as samples with lower scores are removed, and\nit demonstrates superior performance in standard risk-based metrics such as\nAUSE and AURC. Additionally, our method effectively identifies discrepancies\nbetween training and test distributions, reliably differentiates\nin-distribution from out-of-distribution samples, and elucidates key\ndifferences between CNN and ViT classifiers across various vision datasets.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06048v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05498", "title": "Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering", "authors": ["Niruthiha Selvanayagam"], "summary": "Specific Language Impairment (SLI) affects approximately 7 percent of\nchildren, presenting as isolated language deficits despite normal cognitive\nabilities, sensory systems, and supportive environments. Traditional diagnostic\napproaches often rely on standardized assessments, which may overlook subtle\ndevelopmental patterns. This study aims to identify natural language\ndevelopment trajectories in children with and without SLI using unsupervised\nmachine learning techniques, providing insights for early identification and\ntargeted interventions. Narrative samples from 1,163 children aged 4-16 years\nacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using\nPrincipal Component Analysis (PCA) and clustering. A total of 64 linguistic\nfeatures were evaluated to uncover developmental trajectories and distinguish\nlinguistic profiles. Two primary clusters emerged: (1) high language production\nwith low SLI prevalence, and (2) limited production but higher syntactic\ncomplexity with higher SLI prevalence. Additionally, boundary cases exhibited\nintermediate traits, supporting a continuum model of language abilities.\nFindings suggest SLI manifests primarily through reduced production capacity\nrather than syntactic complexity deficits. The results challenge categorical\ndiagnostic frameworks and highlight the potential of unsupervised learning\ntechniques for refining diagnostic criteria and intervention strategies.", "comment": "14 pages, 3 figures, 16 tables", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05498v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06174", "title": "Technical Report for Egocentric Mistake Detection for the HoloAssist Challenge", "authors": ["Constantin Patsch", "Marsil Zakour", "Yuankai Wu", "Eckehard Steinbach"], "summary": "In this report, we address the task of online mistake detection, which is\nvital in domains like industrial automation and education, where real-time\nvideo analysis allows human operators to correct errors as they occur. While\nprevious work focuses on procedural errors involving action order, broader\nerror types must be addressed for real-world use. We introduce an online\nmistake detection framework that handles both procedural and execution errors\n(e.g., motor slips or tool misuse). Upon detecting an error, we use a large\nlanguage model (LLM) to generate explanatory feedback. Experiments on the\nHoloAssist benchmark confirm the effectiveness of our approach, where our\napproach is placed second on the mistake detection task.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06174v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06073", "title": "System-Aware Unlearning Algorithms: Use Lesser, Forget Faster", "authors": ["Linda Lu", "Ayush Sekhari", "Karthik Sridharan"], "summary": "Machine unlearning addresses the problem of updating a machine learning\nmodel/system trained on a dataset $S$ so that the influence of a set of\ndeletion requests $U \\subseteq S$ on the unlearned model is minimized. The gold\nstandard definition of unlearning demands that the updated model, after\ndeletion, be nearly identical to the model obtained by retraining. This\ndefinition is designed for a worst-case attacker (one who can recover not only\nthe unlearned model but also the remaining data samples, i.e., $S \\setminus\nU$). Such a stringent definition has made developing efficient unlearning\nalgorithms challenging. However, such strong attackers are also unrealistic. In\nthis work, we propose a new definition, system-aware unlearning, which aims to\nprovide unlearning guarantees against an attacker that can at best only gain\naccess to the data stored in the system for learning/unlearning requests and\nnot all of $S\\setminus U$. With this new definition, we use the simple\nintuition that if a system can store less to make its learning/unlearning\nupdates, it can be more secure and update more efficiently against a\nsystem-aware attacker. Towards that end, we present an exact system-aware\nunlearning algorithm for linear classification using a selective sampling-based\napproach, and we generalize the method for classification with general function\nclasses. We theoretically analyze the tradeoffs between deletion capacity,\naccuracy, memory, and computation time.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06073v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06176", "title": "SatelliteFormula: Multi-Modal Symbolic Regression from Remote Sensing Imagery for Physics Discovery", "authors": ["Zhenyu Yu", "Mohd. Yamani Idna Idris", "Pei Wang", "Yuelong Xia", "Fei Ma", "Rizwan Qureshi"], "summary": "We propose SatelliteFormula, a novel symbolic regression framework that\nderives physically interpretable expressions directly from multi-spectral\nremote sensing imagery. Unlike traditional empirical indices or black-box\nlearning models, SatelliteFormula combines a Vision Transformer-based encoder\nfor spatial-spectral feature extraction with physics-guided constraints to\nensure consistency and interpretability. Existing symbolic regression methods\nstruggle with the high-dimensional complexity of multi-spectral data; our\nmethod addresses this by integrating transformer representations into a\nsymbolic optimizer that balances accuracy and physical plausibility. Extensive\nexperiments on benchmark datasets and remote sensing tasks demonstrate superior\nperformance, stability, and generalization compared to state-of-the-art\nbaselines. SatelliteFormula enables interpretable modeling of complex\nenvironmental variables, bridging the gap between data-driven learning and\nphysical understanding.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06176v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06095", "title": "Flexible Operator Fusion for Fast Sparse Transformer with Diverse Masking on GPU", "authors": ["Wenhao Dai", "Haodong Deng", "Mengfei Rong", "Xinyu Yang", "Hongyu Liu", "Fangxin Liu", "Hailong Yang", "Weifeng Liu", "Qingxiao Sun"], "summary": "Large language models are popular around the world due to their powerful\nunderstanding capabilities. As the core component of LLMs, accelerating\nTransformer through parallelization has gradually become a hot research topic.\nMask layers introduce sparsity into Transformer to reduce calculations.\nHowever, previous works rarely focus on the performance optimization of sparse\nTransformer. Moreover, rule-based mechanisms ignore the fusion opportunities of\nmixed-type operators and fail to adapt to various sequence lengths. To address\nthe above problems, we propose STOF, a framework that incorporates\noptimizations for Sparse Transformer via flexible masking and operator fusion\non GPU. We firstly unify the storage format and kernel implementation for the\nmulti-head attention. Then, we map fusion schemes to compilation templates and\ndetermine the optimal parameter setting through a two-stage search engine. The\nexperimental results show that compared to the state-of-the-art work, STOF\nachieves maximum speedups of 1.7x in MHA computation and 1.5x in end-to-end\ninference.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06095v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06218", "title": "STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving", "authors": ["Christian Fruhwirth-Reisinger", "Dušan Malić", "Wei Lin", "David Schinagl", "Samuel Schulter", "Horst Possegger"], "summary": "We introduce STSBench, a scenario-based framework to benchmark the holistic\nunderstanding of vision-language models (VLMs) for autonomous driving. The\nframework automatically mines pre-defined traffic scenarios from any dataset\nusing ground-truth annotations, provides an intuitive user interface for\nefficient human verification, and generates multiple-choice questions for model\nevaluation. Applied to the NuScenes dataset, we present STSnu, the first\nbenchmark that evaluates the spatio-temporal reasoning capabilities of VLMs\nbased on comprehensive 3D perception. Existing benchmarks typically target\noff-the-shelf or fine-tuned VLMs for images or videos from a single viewpoint\nand focus on semantic tasks such as object recognition, dense captioning, risk\nassessment, or scene understanding. In contrast, STSnu evaluates driving expert\nVLMs for end-to-end driving, operating on videos from multi-view cameras or\nLiDAR. It specifically assesses their ability to reason about both ego-vehicle\nactions and complex interactions among traffic participants, a crucial\ncapability for autonomous vehicles. The benchmark features 43 diverse scenarios\nspanning multiple views and frames, resulting in 971 human-verified\nmultiple-choice questions. A thorough evaluation uncovers critical shortcomings\nin existing models' ability to reason about fundamental traffic dynamics in\ncomplex environments. These findings highlight the urgent need for\narchitectural advances that explicitly model spatio-temporal reasoning. By\naddressing a core gap in spatio-temporal evaluation, STSBench enables the\ndevelopment of more robust and explainable VLMs for autonomous driving.", "comment": "Dataset: https://huggingface.co/datasets/ivc-lrp/STSBench, Code:\n  https://github.com/LRP-IVC/STSBench", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06218v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06105", "title": "Text-to-LoRA: Instant Transformer Adaption", "authors": ["Rujikorn Charakorn", "Edoardo Cetin", "Yujin Tang", "Robert Tjarko Lange"], "summary": "While Foundation Models provide a general tool for rapid content creation,\nthey regularly require task-specific adaptation. Traditionally, this exercise\ninvolves careful curation of datasets and repeated fine-tuning of the\nunderlying model. Fine-tuning techniques enable practitioners to adapt\nfoundation models for many new applications but require expensive and lengthy\ntraining while being notably sensitive to hyper-parameter choices. To overcome\nthese limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting\nLarge Language Models on the fly solely based on a natural language description\nof the target task. T2L is a hypernetwork trained to construct LoRAs in a\nsingle inexpensive forward pass. After training T2L on a suite of 9 pre-trained\nLoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc reconstructed LoRA\ninstances match the performance of task-specific adapters across the\ncorresponding test sets. Furthermore, T2L can compress hundreds of LoRA\ninstances and zero-shot generalize to entirely unseen tasks. This approach\nprovides a significant step towards democratizing the specialization of\nfoundation models and enables language-based adaptation with minimal compute\nrequirements. Our code is available at https://github.com/SakanaAI/text-to-lora", "comment": "Accepted at ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06105v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06220", "title": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": ["Diji Yang", "Minghao Liu", "Chung-Hsiang Lo", "Yi Zhang", "James Davis"], "summary": "Vision-language models (VLMs) have shown strong performance on text-to-image\nretrieval benchmarks. However, bridging this success to real-world applications\nremains a challenge. In practice, human search behavior is rarely a one-shot\naction. Instead, it is often a multi-round process guided by clues in mind,\nthat is, a mental image ranging from vague recollections to vivid mental\nrepresentations of the target image. Motivated by this gap, we study the task\nof Mental Image Retrieval (MIR), which targets the realistic yet underexplored\nsetting where users refine their search for a mentally envisioned image through\nmulti-round interactions with an image search engine. Central to successful\ninteractive retrieval is the capability of machines to provide users with\nclear, actionable feedback; however, existing methods rely on indirect or\nabstract verbal feedback, which can be ambiguous, misleading, or ineffective\nfor users to refine the query. To overcome this, we propose GenIR, a generative\nmulti-round retrieval paradigm leveraging diffusion-based image generation to\nexplicitly reify the AI system's understanding at each round. These synthetic\nvisual representations provide clear, interpretable feedback, enabling users to\nrefine their queries intuitively and effectively. We further introduce a fully\nautomated pipeline to generate a high-quality multi-round MIR dataset.\nExperimental results demonstrate that GenIR significantly outperforms existing\ninteractive methods in the MIR scenario. This work establishes a new task with\na dataset and an effective generative retrieval method, providing a foundation\nfor future research in this direction.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06220v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05503", "title": "On Differential Privacy for Adaptively Solving Search Problems via Sketching", "authors": ["Shiyuan Feng", "Ying Feng", "George Z. Li", "Zhao Song", "David P. Woodruff", "Lichen Zhang"], "summary": "Recently differential privacy has been used for a number of streaming, data\nstructure, and dynamic graph problems as a means of hiding the internal\nrandomness of the data structure, so that multiple possibly adaptive queries\ncan be made without sacrificing the correctness of the responses. Although\nthese works use differential privacy to show that for some problems it is\npossible to tolerate $T$ queries using $\\widetilde{O}(\\sqrt{T})$ copies of a\ndata structure, such results only apply to numerical estimation problems, and\nonly return the cost of an optimization problem rather than the solution\nitself. In this paper, we investigate the use of differential privacy for\nadaptive queries to search problems, which are significantly more challenging\nsince the responses to queries can reveal much more about the internal\nrandomness than a single numerical query. We focus on two classical search\nproblems: nearest neighbor queries and regression with arbitrary turnstile\nupdates. We identify key parameters to these problems, such as the number of\n$c$-approximate near neighbors and the matrix condition number, and use\ndifferent differential privacy techniques to design algorithms returning the\nsolution vector with memory and time depending on these parameters. We give\nalgorithms for each of these problems that achieve similar tradeoffs.", "comment": "ICML 2025", "cate": "cs.DS", "url": "http://arxiv.org/pdf/2506.05503v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06232", "title": "Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study", "authors": ["Leon Mayer", "Tim Rädsch", "Dominik Michael", "Lucas Luttner", "Amine Yamlahi", "Evangelia Christodoulou", "Patrick Godau", "Marcel Knopp", "Annika Reinke", "Fiona Kolbinger", "Lena Maier-Hein"], "summary": "While traditional computer vision models have historically struggled to\ngeneralize to endoscopic domains, the emergence of foundation models has shown\npromising cross-domain performance. In this work, we present the first\nlarge-scale study assessing the capabilities of Vision Language Models (VLMs)\nfor endoscopic tasks with a specific focus on laparoscopic surgery. Using a\ndiverse set of state-of-the-art models, multiple surgical datasets, and\nextensive human reference annotations, we address three key research questions:\n(1) Can current VLMs solve basic perception tasks on surgical images? (2) Can\nthey handle advanced frame-based endoscopic scene understanding tasks? and (3)\nHow do specialized medical VLMs compare to generalist models in this context?\nOur results reveal that VLMs can effectively perform basic surgical perception\ntasks, such as object counting and localization, with performance levels\ncomparable to general domain tasks. However, their performance deteriorates\nsignificantly when the tasks require medical knowledge. Notably, we find that\nspecialized medical VLMs currently underperform compared to generalist models\nacross both basic and advanced surgical tasks, suggesting that they are not yet\noptimized for the complexity of surgical environments. These findings highlight\nthe need for further advancements to enable VLMs to handle the unique\nchallenges posed by surgery. Overall, our work provides important insights for\nthe development of next-generation endoscopic AI systems and identifies key\nareas for improvement in medical visual language models.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06232v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06235", "title": "Optimizing Cloud-to-GPU Throughput for Deep Learning With Earth Observation Data", "authors": ["Akram Zaytar", "Caleb Robinson", "Girmaw Abebe Tadesse", "Tammy Glazer", "Gilles Hacheme", "Anthony Ortiz", "Rahul M Dodhia", "Juan M Lavista Ferres"], "summary": "Training deep learning models on petabyte-scale Earth observation (EO) data\nrequires separating compute resources from data storage. However, standard\nPyTorch data loaders cannot keep modern GPUs utilized when streaming GeoTIFF\nfiles directly from cloud storage. In this work, we benchmark GeoTIFF loading\nthroughput from both cloud object storage and local SSD, systematically testing\ndifferent loader configurations and data parameters. We focus on tile-aligned\nreads and worker thread pools, using Bayesian optimization to find optimal\nsettings for each storage type. Our optimized configurations increase remote\ndata loading throughput by 20x and local throughput by 4x compared to default\nsettings. On three public EO benchmarks, models trained with optimized remote\nloading achieve the same accuracy as local training within identical time\nbudgets. We improve validation IoU by 6-15% and maintain 85-95% GPU utilization\nversus 0-30% with standard configurations. Code is publicly available at\nhttps://github.com/microsoft/pytorch-cloud-geotiff-optimization", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06235v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06114", "title": "Scalable unsupervised feature selection via weight stability", "authors": ["Xudong Zhang", "Renato Cordeiro de Amorim"], "summary": "Unsupervised feature selection is critical for improving clustering\nperformance in high-dimensional data, where irrelevant features can obscure\nmeaningful structure. In this work, we introduce the Minkowski weighted\n$k$-means++, a novel initialisation strategy for the Minkowski Weighted\n$k$-means. Our initialisation selects centroids probabilistically using feature\nrelevance estimates derived from the data itself. Building on this, we propose\ntwo new feature selection algorithms, FS-MWK++, which aggregates feature\nweights across a range of Minkowski exponents to identify stable and\ninformative features, and SFS-MWK++, a scalable variant based on subsampling.\nWe support our approach with a theoretical guarantee under mild assumptions and\nextensive experiments showing that our methods consistently outperform existing\nalternatives.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06114v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06242", "title": "Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models", "authors": ["Zahra Babaiee", "Peyman M. Kiasari", "Daniela Rus", "Radu Grosu"], "summary": "Recent advancements in multimodal large language models have driven\nbreakthroughs in visual question answering. Yet, a critical gap persists,\n`conceptualization'-the ability to recognize and reason about the same concept\ndespite variations in visual form, a basic ability of human reasoning. To\naddress this challenge, we introduce the Visual Graph Arena (VGA), a dataset\nfeaturing six graph-based tasks designed to evaluate and improve AI systems'\ncapacity for visual abstraction. VGA uses diverse graph layouts (e.g.,\nKamada-Kawai vs. planar) to test reasoning independent of visual form.\nExperiments with state-of-the-art vision models and multimodal LLMs reveal a\nstriking divide: humans achieved near-perfect accuracy across tasks, while\nmodels totally failed on isomorphism detection and showed limited success in\npath/cycle tasks. We further identify behavioral anomalies suggesting\npseudo-intelligent pattern matching rather than genuine understanding. These\nfindings underscore fundamental limitations in current AI models for visual\nunderstanding. By isolating the challenge of representation-invariant\nreasoning, the VGA provides a framework to drive progress toward human-like\nconceptualization in AI visual models. The Visual Graph Arena is available at:\n\\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06242v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06253", "title": "Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision", "authors": ["Yuping He", "Yifei Huang", "Guo Chen", "Lidong Lu", "Baoqi Pei", "Jilan Xu", "Tong Lu", "Yoichi Sato"], "summary": "Perceiving the world from both egocentric (first-person) and exocentric\n(third-person) perspectives is fundamental to human cognition, enabling rich\nand complementary understanding of dynamic environments. In recent years,\nallowing the machines to leverage the synergistic potential of these dual\nperspectives has emerged as a compelling research direction in video\nunderstanding. In this survey, we provide a comprehensive review of video\nunderstanding from both exocentric and egocentric viewpoints. We begin by\nhighlighting the practical applications of integrating egocentric and\nexocentric techniques, envisioning their potential collaboration across\ndomains. We then identify key research tasks to realize these applications.\nNext, we systematically organize and review recent advancements into three main\nresearch directions: (1) leveraging egocentric data to enhance exocentric\nunderstanding, (2) utilizing exocentric data to improve egocentric analysis,\nand (3) joint learning frameworks that unify both perspectives. For each\ndirection, we analyze a diverse set of tasks and relevant works. Additionally,\nwe discuss benchmark datasets that support research in both perspectives,\nevaluating their scope, diversity, and applicability. Finally, we discuss\nlimitations in current works and propose promising future research directions.\nBy synthesizing insights from both perspectives, our goal is to inspire\nadvancements in video understanding and artificial intelligence, bringing\nmachines closer to perceiving the world in a human-like manner. A GitHub repo\nof related works can be found at\nhttps://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06253v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05759", "title": "Revealing hidden correlations from complex spatial distributions: Adjacent Correlation Analysis", "authors": ["Guang-Xing Li"], "summary": "Physics has been transforming our view of nature for centuries. While\ncombining physical knowledge with computational approaches has enabled detailed\nmodeling of physical systems' evolution, understanding the emergence of\npatterns and structures remains limited. Correlations between quantities are\nthe most reliable approach to describe relationships between different\nvariables. However, for complex patterns, directly searching for correlations\nis often impractical, as complexity and spatial inhomogeneity can obscure\ncorrelations. We discovered that the key is to search for correlations in local\nregions and developed a new method, adjacent correlation analysis, to extract\nsuch correlations and represent them in phase space. When multiple observations\nare available, a useful way to study a system is to analyze distributions in\nphase space using the Probability Density Function (PDF). Adjacent correlation\nanalysis evaluates vectors representing local correlations, which can be\noverlaid on the PDF plot to form the adjacent correlation plot. These\ncorrelation vectors often exhibit remarkably regular patterns and may lead to\nthe discovery of new laws. The vectors we derive are equivalent to the vector\nfield in dynamical systems on the attracting manifold. By efficiently\nrepresenting spatial patterns as correlation vectors in phase space, our\napproach opens avenues for classification, prediction, parameter fitting, and\nforecasting.", "comment": "Code avaliable at\n  https://github.com/gxli/Adjacent-Correlation-Analysis", "cate": "physics.comp-ph", "url": "http://arxiv.org/pdf/2506.05759v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06127", "title": "Flow-Attentional Graph Neural Networks", "authors": ["Pascal Plettenberg", "Dominik Köhler", "Bernhard Sick", "Josephine M. Thomas"], "summary": "Graph Neural Networks (GNNs) have become essential for learning from\ngraph-structured data. However, existing GNNs do not consider the conservation\nlaw inherent in graphs associated with a flow of physical resources, such as\nelectrical current in power grids or traffic in transportation networks, which\ncan lead to reduced model performance. To address this, we propose flow\nattention, which adapts existing graph attention mechanisms to satisfy\nKirchhoff\\'s first law. Furthermore, we discuss how this modification\ninfluences the expressivity and identify sets of non-isomorphic graphs that can\nbe discriminated by flow attention but not by standard attention. Through\nextensive experiments on two flow graph datasets (electronic circuits and power\ngrids), we demonstrate that flow attention enhances the performance of\nattention-based GNNs on both graph-level classification and regression tasks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06127v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06271", "title": "BecomingLit: Relightable Gaussian Avatars with Hybrid Neural Shading", "authors": ["Jonathan Schmidt", "Simon Giebenhain", "Matthias Niessner"], "summary": "We introduce BecomingLit, a novel method for reconstructing relightable,\nhigh-resolution head avatars that can be rendered from novel viewpoints at\ninteractive rates. Therefore, we propose a new low-cost light stage capture\nsetup, tailored specifically towards capturing faces. Using this setup, we\ncollect a novel dataset consisting of diverse multi-view sequences of numerous\nsubjects under varying illumination conditions and facial expressions. By\nleveraging our new dataset, we introduce a new relightable avatar\nrepresentation based on 3D Gaussian primitives that we animate with a\nparametric head model and an expression-dependent dynamics module. We propose a\nnew hybrid neural shading approach, combining a neural diffuse BRDF with an\nanalytical specular term. Our method reconstructs disentangled materials from\nour dynamic light stage recordings and enables all-frequency relighting of our\navatars with both point lights and environment maps. In addition, our avatars\ncan easily be animated and controlled from monocular videos. We validate our\napproach in extensive experiments on our dataset, where we consistently\noutperform existing state-of-the-art methods in relighting and reenactment by a\nsignificant margin.", "comment": "Project Page: see https://jonathsch.github.io/becominglit/ ; YouTube\n  Video: see https://youtu.be/xPyeIqKdszA", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06271v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05767", "title": "dots.llm1 Technical Report", "authors": ["Bi Huo", "Bin Tu", "Cheng Qin", "Da Zheng", "Debing Zhang", "Dongjie Zhang", "En Li", "Fu Guo", "Jian Yao", "Jie Lou", "Junfeng Tian", "Li Hu", "Ran Zhu", "Shengdong Chen", "Shuo Liu", "Su Guang", "Te Wo", "Weijun Zhang", "Xiaoming Shi", "Xinxin Peng", "Xing Wu", "Yawen Liu", "Yuqiu Ji", "Ze Wen", "Zhenhai Liu", "Zichao Li", "Zilong Liao"], "summary": "Mixture of Experts (MoE) models have emerged as a promising paradigm for\nscaling language models efficiently by activating only a subset of parameters\nfor each input token. In this report, we present dots.llm1, a large-scale MoE\nmodel that activates 14B parameters out of a total of 142B parameters,\ndelivering performance on par with state-of-the-art models while reducing\ntraining and inference costs. Leveraging our meticulously crafted and efficient\ndata processing pipeline, dots.llm1 achieves performance comparable to\nQwen2.5-72B after pretraining on 11.2T high-quality tokens and post-training to\nfully unlock its capabilities. Notably, no synthetic data is used during\npretraining. To foster further research, we open-source intermediate training\ncheckpoints at every one trillion tokens, providing valuable insights into the\nlearning dynamics of large language models.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05767v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06130", "title": "Gradient Similarity Surgery in Multi-Task Deep Learning", "authors": ["Thomas Borsani", "Andrea Rosani", "Giuseppe Nicosia", "Giuseppe Di Fatta"], "summary": "The multi-task learning ($MTL$) paradigm aims to simultaneously learn\nmultiple tasks within a single model capturing higher-level, more general\nhidden patterns that are shared by the tasks. In deep learning, a significant\nchallenge in the backpropagation training process is the design of advanced\noptimisers to improve the convergence speed and stability of the gradient\ndescent learning rule. In particular, in multi-task deep learning ($MTDL$) the\nmultitude of tasks may generate potentially conflicting gradients that would\nhinder the concurrent convergence of the diverse loss functions. This challenge\narises when the gradients of the task objectives have either different\nmagnitudes or opposite directions, causing one or a few to dominate or to\ninterfere with each other, thus degrading the training process. Gradient\nsurgery methods address the problem explicitly dealing with conflicting\ngradients by adjusting the overall gradient trajectory. This work introduces a\nnovel gradient surgery method, the Similarity-Aware Momentum Gradient Surgery\n(SAM-GS), which provides an effective and scalable approach based on a gradient\nmagnitude similarity measure to guide the optimisation process. The SAM-GS\nsurgery adopts gradient equalisation and modulation of the first-order\nmomentum. A series of experimental tests have shown the effectiveness of SAM-GS\non synthetic problems and $MTL$ benchmarks. Gradient magnitude similarity plays\na crucial role in regularising gradient aggregation in $MTDL$ for the\noptimisation of the learning process.", "comment": "Paper accepted at ECMLPKDD 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06130v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06275", "title": "Movie Facts and Fibs (MF$^2$): A Benchmark for Long Movie Understanding", "authors": ["Emmanouil Zaranis", "António Farinhas", "Saul Santos", "Beatriz Canaverde", "Miguel Moura Ramos", "Aditya K Surikuchi", "André Viveiros", "Baohao Liao", "Elena Bueno-Benito", "Nithin Sivakumaran", "Pavlo Vasylenko", "Shoubin Yu", "Sonal Sannigrahi", "Wafaa Mohammed", "Ben Peters", "Danae Sánchez Villegas", "Elias Stengel-Eskin", "Giuseppe Attanasio", "Jaehong Yoon", "Stella Frank", "Alessandro Suglia", "Chrysoula Zerva", "Desmond Elliott", "Mariella Dimiccoli", "Mohit Bansal", "Oswald Lanz", "Raffaella Bernardi", "Raquel Fernández", "Sandro Pezzelle", "Vlad Niculae", "André F. T. Martins"], "summary": "Despite recent progress in vision-language models (VLMs), holistic\nunderstanding of long-form video content remains a significant challenge,\npartly due to limitations in current benchmarks. Many focus on peripheral,\n``needle-in-a-haystack'' details, encouraging context-insensitive retrieval\nover deep comprehension. Others rely on large-scale, semi-automatically\ngenerated questions (often produced by language models themselves) that are\neasier for models to answer but fail to reflect genuine understanding. In this\npaper, we introduce MF$^2$, a new benchmark for evaluating whether models can\ncomprehend, consolidate, and recall key narrative information from full-length\nmovies (50-170 minutes long). MF$^2$ includes over 50 full-length,\nopen-licensed movies, each paired with manually constructed sets of claim pairs\n-- one true (fact) and one plausible but false (fib), totalling over 850 pairs.\nThese claims target core narrative elements such as character motivations and\nemotions, causal chains, and event order, and refer to memorable moments that\nhumans can recall without rewatching the movie. Instead of multiple-choice\nformats, we adopt a binary claim evaluation protocol: for each pair, models\nmust correctly identify both the true and false claims. This reduces biases\nlike answer ordering and enables a more precise assessment of reasoning. Our\nexperiments demonstrate that both open-weight and closed state-of-the-art\nmodels fall well short of human performance, underscoring the relative ease of\nthe task for humans and their superior ability to retain and reason over\ncritical narrative information -- an ability current VLMs lack.", "comment": "Under Review", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06275v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06137", "title": "Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models", "authors": ["Rihui Jin", "Zheyu Xin", "Xing Xie", "Zuoyi Li", "Guilin Qi", "Yongrui Chen", "Xinbang Dai", "Tongtong Wu", "Gholamreza Haffari"], "summary": "Table reasoning (TR) requires structured reasoning over semi-structured\ntabular data and remains challenging, particularly for small language models\n(SLMs, e.g., LLaMA-8B) due to their limited capacity compared to large LMs\n(LLMs, e.g., GPT-4o). To narrow this gap, we explore program-based TR (P-TR),\nwhich circumvents key limitations of text-based TR (T-TR), notably in numerical\nreasoning, by generating executable programs. However, applying P-TR to SLMs\nintroduces two challenges: (i) vulnerability to heterogeneity in table layouts,\nand (ii) inconsistency in reasoning due to limited code generation capability.\nWe propose Table-r1, a two-stage P-TR method designed for SLMs. Stage 1\nintroduces an innovative self-supervised learning task, Layout Transformation\nInference, to improve tabular layout generalization from a programmatic view.\nStage 2 adopts a mix-paradigm variant of Group Relative Policy Optimization,\nenhancing P-TR consistency while allowing dynamic fallback to T-TR when needed.\nExperiments on four TR benchmarks demonstrate that Table-r1 outperforms all\nSLM-based methods, achieving at least a 15% accuracy improvement over the base\nmodel (LLaMA-8B) across all datasets and reaching performance competitive with\nLLMs.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06137v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05518", "title": "Sorting by pile shuffles on queue-like and stack-like piles can be hard", "authors": ["Kyle B. Treleaven"], "summary": "Inspired by a common technique for shuffling a deck of cards on a table\nwithout riffling, we continue the study of a prequel paper on the pile shuffle\nand its capabilities as a sorting device. We study two sort feasibility\nproblems of general interest concerning pile shuffle, first introduced in the\nprequel. These problems are characterized by: (1) bounds on the number of\nsequential rounds of shuffle, and piles created in each round; (2) the use of a\nheterogeneous mixture of queue-like and stack-like piles, as when each round of\nshuffle may have a combination of face-up and face-down piles; and (3) the\nability of the dealer to choose the types of piles used during each round of\nshuffle. We prove by a sequence of reductions from the Boolean satisfiability\nproblem (SAT) that the more general problem is NP-Hard. We leave as an open\nquestion the complexity of its arguably more natural companion, but discuss\navenues for further investigation. Our analysis leverages a novel framework,\nintroduced herein, which equates instances of shuffle to members of a\nparticular class of deterministic finite automata.", "comment": "55 pages, 18 figures. arXiv admin note: text overlap with\n  arXiv:2503.11463", "cate": "cs.CC", "url": "http://arxiv.org/pdf/2506.05518v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06276", "title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis", "authors": ["Jiatao Gu", "Tianrong Chen", "David Berthelot", "Huangjie Zheng", "Yuyang Wang", "Ruixiang Zhang", "Laurent Dinh", "Miguel Angel Bautista", "Josh Susskind", "Shuangfei Zhai"], "summary": "We present STARFlow, a scalable generative model based on normalizing flows\nthat achieves strong performance in high-resolution image synthesis. The core\nof STARFlow is Transformer Autoregressive Flow (TARFlow), which combines the\nexpressive power of normalizing flows with the structured modeling capabilities\nof Autoregressive Transformers. We first establish the theoretical universality\nof TARFlow for modeling continuous distributions. Building on this foundation,\nwe introduce several key architectural and algorithmic innovations to\nsignificantly enhance scalability: (1) a deep-shallow design, wherein a deep\nTransformer block captures most of the model representational capacity,\ncomplemented by a few shallow Transformer blocks that are computationally\nefficient yet substantially beneficial; (2) modeling in the latent space of\npretrained autoencoders, which proves more effective than direct pixel-level\nmodeling; and (3) a novel guidance algorithm that significantly boosts sample\nquality. Crucially, our model remains an end-to-end normalizing flow, enabling\nexact maximum likelihood training in continuous spaces without discretization.\nSTARFlow achieves competitive performance in both class-conditional and\ntext-conditional image generation tasks, approaching state-of-the-art diffusion\nmodels in sample quality. To our knowledge, this work is the first successful\ndemonstration of normalizing flows operating effectively at this scale and\nresolution.", "comment": "TLDR: We show for the first time that normalizing flows can be scaled\n  for high-resolution and text-conditioned image synthesis", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06276v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06143", "title": "carps: A Framework for Comparing N Hyperparameter Optimizers on M Benchmarks", "authors": ["Carolin Benjamins", "Helena Graf", "Sarah Segel", "Difan Deng", "Tim Ruhkopf", "Leona Hennig", "Soham Basu", "Neeratyoy Mallik", "Edward Bergman", "Deyao Chen", "François Clément", "Matthias Feurer", "Katharina Eggensperger", "Frank Hutter", "Carola Doerr", "Marius Lindauer"], "summary": "Hyperparameter Optimization (HPO) is crucial to develop well-performing\nmachine learning models. In order to ease prototyping and benchmarking of HPO\nmethods, we propose carps, a benchmark framework for Comprehensive Automated\nResearch Performance Studies allowing to evaluate N optimizers on M benchmark\ntasks. In this first release of carps, we focus on the four most important\ntypes of HPO task types: blackbox, multi-fidelity, multi-objective and\nmulti-fidelity-multi-objective. With 3 336 tasks from 5 community benchmark\ncollections and 28 variants of 9 optimizer families, we offer the biggest go-to\nlibrary to date to evaluate and compare HPO methods. The carps framework relies\non a purpose-built, lightweight interface, gluing together optimizers and\nbenchmark tasks. It also features an analysis pipeline, facilitating the\nevaluation of optimizers on benchmarks. However, navigating a huge number of\ntasks while developing and comparing methods can be computationally infeasible.\nTo address this, we obtain a subset of representative tasks by minimizing the\nstar discrepancy of the subset, in the space spanned by the full set. As a\nresult, we propose an initial subset of 10 to 30 diverse tasks for each task\ntype, and include functionality to re-compute subsets as more benchmarks become\navailable, enabling efficient evaluations. We also establish a first set of\nbaseline results on these tasks as a measure for future comparisons. With carps\n(https://www.github.com/automl/CARP-S), we make an important step in the\nstandardization of HPO evaluation.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06143v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06277", "title": "ExAct: A Video-Language Benchmark for Expert Action Analysis", "authors": ["Han Yi", "Yulu Pan", "Feihong He", "Xinyu Liu", "Benjamin Zhang", "Oluwatumininu Oguntola", "Gedas Bertasius"], "summary": "We present ExAct, a new video-language benchmark for expert-level\nunderstanding of skilled physical human activities. Our new benchmark contains\n3521 expert-curated video question-answer pairs spanning 11 physical activities\nin 6 domains: Sports, Bike Repair, Cooking, Health, Music, and Dance. ExAct\nrequires the correct answer to be selected from five carefully designed\ncandidate options, thus necessitating a nuanced, fine-grained, expert-level\nunderstanding of physical human skills. Evaluating the recent state-of-the-art\nVLMs on ExAct reveals a substantial performance gap relative to human expert\nperformance. Specifically, the best-performing GPT-4o model achieves only\n44.70% accuracy, well below the 82.02% attained by trained human\nspecialists/experts. We believe that ExAct will be beneficial for developing\nand evaluating VLMs capable of precise understanding of human skills in various\nphysical and procedural domains. Dataset and code are available at\nhttps://texaser.github.io/exact_project_page/", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06277v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06158", "title": "ENMA: Tokenwise Autoregression for Generative Neural PDE Operators", "authors": ["Armand Kassaï Koupaï", "Lise Le Boudec", "Louis Serrano", "Patrick Gallinari"], "summary": "Solving time-dependent parametric partial differential equations (PDEs)\nremains a fundamental challenge for neural solvers, particularly when\ngeneralizing across a wide range of physical parameters and dynamics. When data\nis uncertain or incomplete-as is often the case-a natural approach is to turn\nto generative models. We introduce ENMA, a generative neural operator designed\nto model spatio-temporal dynamics arising from physical phenomena. ENMA\npredicts future dynamics in a compressed latent space using a generative masked\nautoregressive transformer trained with flow matching loss, enabling tokenwise\ngeneration. Irregularly sampled spatial observations are encoded into uniform\nlatent representations via attention mechanisms and further compressed through\na spatio-temporal convolutional encoder. This allows ENMA to perform in-context\nlearning at inference time by conditioning on either past states of the target\ntrajectory or auxiliary context trajectories with similar dynamics. The result\nis a robust and adaptable framework that generalizes to new PDE regimes and\nsupports one-shot surrogate modeling of time-dependent parametric PDEs.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06158v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06279", "title": "CoMemo: LVLMs Need Image Context with Image Memory", "authors": ["Shi Liu", "Weijie Su", "Xizhou Zhu", "Wenhai Wang", "Jifeng Dai"], "summary": "Recent advancements in Large Vision-Language Models built upon Large Language\nModels have established aligning visual features with LLM representations as\nthe dominant paradigm. However, inherited LLM architectural designs introduce\nsuboptimal characteristics for multimodal processing. First, LVLMs exhibit a\nbimodal distribution in attention allocation, leading to the progressive\nneglect of middle visual content as context expands. Second, conventional\npositional encoding schemes fail to preserve vital 2D structural relationships\nwhen processing dynamic high-resolution images. To address these limitations,\nwe propose CoMemo - a dual-path architecture that combines a Context image path\nwith an image Memory path for visual processing, effectively alleviating visual\ninformation neglect. Additionally, we introduce RoPE-DHR, a novel positional\nencoding mechanism that employs thumbnail-based positional aggregation to\nmaintain 2D spatial awareness while mitigating remote decay in extended\nsequences. Evaluations across seven benchmarks,including long-context\ncomprehension, multi-image reasoning, and visual question answering,\ndemonstrate CoMemo's superior performance compared to conventional LVLM\narchitectures. Project page is available at\nhttps://lalbj.github.io/projects/CoMemo/.", "comment": "ICML 2025", "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06279v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06281", "title": "TerraFM: A Scalable Foundation Model for Unified Multisensor Earth Observation", "authors": ["Muhammad Sohail Danish", "Muhammad Akhtar Munir", "Syed Roshaan Ali Shah", "Muhammad Haris Khan", "Rao Muhammad Anwer", "Jorma Laaksonen", "Fahad Shahbaz Khan", "Salman Khan"], "summary": "Modern Earth observation (EO) increasingly leverages deep learning to harness\nthe scale and diversity of satellite imagery across sensors and regions. While\nrecent foundation models have demonstrated promising generalization across EO\ntasks, many remain limited by the scale, geographical coverage, and spectral\ndiversity of their training data, factors critical for learning globally\ntransferable representations. In this work, we introduce TerraFM, a scalable\nself-supervised learning model that leverages globally distributed Sentinel-1\nand Sentinel-2 imagery, combined with large spatial tiles and land-cover aware\nsampling to enrich spatial and semantic coverage. By treating sensing\nmodalities as natural augmentations in our self-supervised approach, we unify\nradar and optical inputs via modality-specific patch embeddings and adaptive\ncross-attention fusion. Our training strategy integrates local-global\ncontrastive learning and introduces a dual-centering mechanism that\nincorporates class-frequency-aware regularization to address long-tailed\ndistributions in land cover.TerraFM achieves strong generalization on both\nclassification and segmentation tasks, outperforming prior models on GEO-Bench\nand Copernicus-Bench. Our code and pretrained models are publicly available at:\nhttps://github.com/mbzuai-oryx/TerraFM .", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/pdf/2506.06281v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05833", "title": "Fuzzy Lattice-based Description Logic", "authors": ["Yiwen Ding", "Krishna Manoorkar"], "summary": "Recently, description logic LE-ALC was introduced for reasoning in the\nsemantic environment of enriched formal contexts, and a polynomial-time\ntableaux algorithm was developed to check the consistency of knowledge bases\nwith acyclic TBoxes. In this work, we introduce a fuzzy generalization of\nLE-ALC called LE-FALC which provides a description logic counterpart of\nmany-valued normal non-distributive logic a.k.a. many-valued LE-logic. This\ndescription logic can be used to represent and reason about knowledge in the\nformal framework of fuzzy formal contexts and fuzzy formal concepts. We provide\na tableaux algorithm that provides a complete and sound polynomial-time\ndecision procedure to check the consistency of LE-FALC ABoxes. As a result, we\nalso obtain an exponential-time decision procedure for checking the consistency\nof LE-FALC with acyclic TBoxes by unraveling.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05833v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06178", "title": "Reusing Trajectories in Policy Gradients Enables Fast Convergence", "authors": ["Alessandro Montenegro", "Federico Mansutti", "Marco Mussi", "Matteo Papini", "Alberto Maria Metelli"], "summary": "Policy gradient (PG) methods are a class of effective reinforcement learning\nalgorithms, particularly when dealing with continuous control problems. These\nmethods learn the parameters of parametric policies via stochastic gradient\nascent, typically using on-policy trajectory data to estimate the policy\ngradient. However, such reliance on fresh data makes them sample-inefficient.\nIndeed, vanilla PG methods require $O(\\epsilon^{-2})$ trajectories to reach an\n$\\epsilon$-approximate stationary point. A common strategy to improve\nefficiency is to reuse off-policy information from past iterations, such as\nprevious gradients or trajectories. While gradient reuse has received\nsubstantial theoretical attention, leading to improved rates of\n$O(\\epsilon^{-3/2})$, the reuse of past trajectories remains largely unexplored\nfrom a theoretical perspective. In this work, we provide the first rigorous\ntheoretical evidence that extensive reuse of past off-policy trajectories can\nsignificantly accelerate convergence in PG methods. We introduce a power mean\ncorrection to the multiple importance weighting estimator and propose RPG\n(Retrospective Policy Gradient), a PG algorithm that combines old and new\ntrajectories for policy updates. Through a novel analysis, we show that, under\nestablished assumptions, RPG achieves a sample complexity of\n$\\widetilde{O}(\\epsilon^{-1})$, the best known rate in the literature. We\nfurther validate empirically our approach against PG methods with\nstate-of-the-art rates.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06178v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05525", "title": "Model Checking as Program Verification by Abstract Interpretation (Extended Version)", "authors": ["Paolo Baldan", "Roberto Bruni", "Francesco Ranzato", "Diletta Rigo"], "summary": "Abstract interpretation offers a powerful toolset for static analysis,\ntackling precision, complexity and state-explosion issues. In the literature,\nstate partitioning abstractions based on (bi)simulation and property-preserving\nstate relations have been successfully applied to abstract model checking.\nHere, we pursue a different track in which model checking is seen as an\ninstance of program verification. To this purpose, we introduce a suitable\nlanguage-called MOKA (for MOdel checking as abstract interpretation of Kleene\nAlgebras)-which is used to encode temporal formulae as programs. In particular,\nwe show that (universal fragments of) temporal logics, such as ACTL or, more\ngenerally, universal mu-calculus can be transformed into MOKA programs. Such\nprograms return all and only the initial states which violate the formula. By\napplying abstract interpretation to MOKA programs, we pave the way for reusing\nmore general abstractions than partitions as well as for tuning the precision\nof the abstraction to remove or avoid false alarms. We show how to perform\nmodel checking via a program logic that combines under-approximation and\nabstract interpretation analysis to avoid false alarms. The notion of locally\ncomplete abstraction is used to dynamically improve the analysis precision via\ncounterexample-guided domain refinement.", "comment": null, "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05525v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05391", "title": "Enhancing Neural Autoregressive Distribution Estimators for Image Reconstruction", "authors": ["Ambrose Emmett-Iwaniw", "Nathan Kirk"], "summary": "Autoregressive models are often employed to learn distributions of image data\nby decomposing the $D$-dimensional density function into a product of\none-dimensional conditional distributions. Each conditional depends on\npreceding variables (pixels, in the case of image data), making the order in\nwhich variables are processed fundamental to the model performance. In this\npaper, we study the problem of observing a small subset of image pixels\n(referred to as a pixel patch) to predict the unobserved parts of the image. As\nour prediction mechanism, we propose a generalized and computationally\nefficient version of the convolutional neural autoregressive distribution\nestimator (ConvNADE) model adapted for real-valued and color images. Moreover,\nwe investigate the quality of image reconstruction when observing both random\npixel patches and low-discrepancy pixel patches inspired by quasi-Monte Carlo\ntheory. Experiments on benchmark datasets demonstrate that choosing the pixels\nakin to a low-discrepancy sequence reduces test loss and produces more\nrealistic reconstructed images.", "comment": "Accepted for publication in conference proceedings, MCQMC 2024", "cate": "eess.IV", "url": "http://arxiv.org/pdf/2506.05391v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05834", "title": "Regional, Lattice and Logical Representations of Neural Networks", "authors": ["Sandro Preto", "Marcelo Finger"], "summary": "A possible path to the interpretability of neural networks is to\n(approximately) represent them in the regional format of piecewise linear\nfunctions, where regions of inputs are associated to linear functions computing\nthe network outputs. We present an algorithm for the translation of feedforward\nneural networks with ReLU activation functions in hidden layers and truncated\nidentity activation functions in the output layer. We also empirically\ninvestigate the complexity of regional representations outputted by our method\nfor neural networks with varying sizes. Lattice and logical representations of\nneural networks are straightforward from regional representations as long as\nthey satisfy a specific property. So we empirically investigate to what extent\nthe translations by our algorithm satisfy such property.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05834v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06179", "title": "A Theoretical Study of (Hyper) Self-Attention through the Lens of Interactions: Representation, Training, Generalization", "authors": ["Muhammed Ustaomeroglu", "Guannan Qu"], "summary": "Self-attention has emerged as a core component of modern neural\narchitectures, yet its theoretical underpinnings remain elusive. In this paper,\nwe study self-attention through the lens of interacting entities, ranging from\nagents in multi-agent reinforcement learning to alleles in genetic sequences,\nand show that a single layer linear self-attention can efficiently represent,\nlearn, and generalize functions capturing pairwise interactions, including\nout-of-distribution scenarios. Our analysis reveals that self-attention acts as\na mutual interaction learner under minimal assumptions on the diversity of\ninteraction patterns observed during training, thereby encompassing a wide\nvariety of real-world domains. In addition, we validate our theoretical\ninsights through experiments demonstrating that self-attention learns\ninteraction functions and generalizes across both population distributions and\nout-of-distribution scenarios. Building on our theories, we introduce\nHyperFeatureAttention, a novel neural network module designed to learn\ncouplings of different feature-level interactions between entities.\nFurthermore, we propose HyperAttention, a new module that extends beyond\npairwise interactions to capture multi-entity dependencies, such as three-way,\nfour-way, or general n-way interactions.", "comment": "Accepted to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06179v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05850", "title": "Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models", "authors": ["Cheonbok Park", "Jeonghoon Kim", "Joosung Lee", "Sanghwan Bae", "Jaegul Choo", "Kangmin Yoo"], "summary": "We identify \\textbf{Cross-lingual Collapse}, a systematic drift in which the\nchain-of-thought (CoT) of a multilingual language model reverts to its dominant\npre-training language even when the prompt is expressed in a different\nlanguage. Recent large language models (LLMs) with reinforcement learning with\nverifiable reward (RLVR) have achieved strong logical reasoning performances by\nexposing their intermediate reasoning traces, giving rise to large reasoning\nmodels (LRMs). However, the mechanism behind multilingual reasoning in LRMs is\nnot yet fully explored. To investigate the issue, we fine-tune multilingual\nLRMs with Group-Relative Policy Optimization (GRPO) on translated versions of\nthe GSM$8$K and SimpleRL-Zoo datasets in three different languages: Chinese,\nKorean, and Ukrainian. During training, we monitor both task accuracy and\nlanguage consistency of the reasoning chains. Our experiments reveal three key\nfindings: (i) GRPO rapidly amplifies pre-training language imbalances, leading\nto the erosion of low-resource languages within just a few hundred updates;\n(ii) language consistency reward mitigates this drift but does so at the\nexpense of an almost 5 - 10 pp drop in accuracy. and (iii) the resulting\nlanguage collapse is severely damaging and largely irreversible, as subsequent\nfine-tuning struggles to steer the model back toward its original\ntarget-language reasoning capabilities. Together, these findings point to a\nremarkable conclusion: \\textit{not all languages are trained equally for\nreasoning}. Furthermore, our paper sheds light on the roles of reward shaping,\ndata difficulty, and pre-training priors in eliciting multilingual reasoning.", "comment": "Preprint", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05850v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06185", "title": "Antithetic Noise in Diffusion Models", "authors": ["Jing Jia", "Sifan Liu", "Bowen Song", "Wei Yuan", "Liyue Shen", "Guanyang Wang"], "summary": "We initiate a systematic study of antithetic initial noise in diffusion\nmodels. Across unconditional models trained on diverse datasets,\ntext-conditioned latent-diffusion models, and diffusion-posterior samplers, we\nfind that pairing each initial noise with its negation consistently yields\nstrongly negatively correlated samples. To explain this phenomenon, we combine\nexperiments and theoretical analysis, leading to a symmetry conjecture that the\nlearned score function is approximately affine antisymmetric (odd symmetry up\nto a constant shift), and provide evidence supporting it. Leveraging this\nnegative correlation, we enable two applications: (1) enhancing image diversity\nin models like Stable Diffusion without quality loss, and (2) sharpening\nuncertainty quantification (e.g., up to 90% narrower confidence intervals) when\nestimating downstream statistics. Building on these gains, we extend the\ntwo-point pairing to a randomized quasi-Monte Carlo estimator, which further\nimproves estimation accuracy. Our framework is training-free, model-agnostic,\nand adds no runtime overhead.", "comment": "43 pages, 20 figures, 9 tables", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06185v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05851", "title": "DeepFake Doctor: Diagnosing and Treating Audio-Video Fake Detection", "authors": ["Marcel Klemt", "Carlotta Segna", "Anna Rohrbach"], "summary": "Generative AI advances rapidly, allowing the creation of very realistic\nmanipulated video and audio. This progress presents a significant security and\nethical threat, as malicious users can exploit DeepFake techniques to spread\nmisinformation. Recent DeepFake detection approaches explore the multimodal\n(audio-video) threat scenario. In particular, there is a lack of\nreproducibility and critical issues with existing datasets - such as the\nrecently uncovered silence shortcut in the widely used FakeAVCeleb dataset.\nConsidering the importance of this topic, we aim to gain a deeper understanding\nof the key issues affecting benchmarking in audio-video DeepFake detection. We\nexamine these challenges through the lens of the three core benchmarking\npillars: datasets, detection methods, and evaluation protocols. To address\nthese issues, we spotlight the recent DeepSpeak v1 dataset and are the first to\npropose an evaluation protocol and benchmark it using SOTA models. We introduce\nSImple Multimodal BAseline (SIMBA), a competitive yet minimalistic approach\nthat enables the exploration of diverse design choices. We also deepen insights\ninto the issue of audio shortcuts and present a promising mitigation strategy.\nFinally, we analyze and enhance the evaluation scheme on the widely used\nFakeAVCeleb dataset. Our findings offer a way forward in the complex area of\naudio-video DeepFake detection.", "comment": null, "cate": "cs.MM", "url": "http://arxiv.org/pdf/2506.05851v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06188", "title": "Physics-Informed Neural Networks for Control of Single-Phase Flow Systems Governed by Partial Differential Equations", "authors": ["Luis Kin Miyatake", "Eduardo Camponogara", "Eric Aislan Antonelo", "Alexey Pavlov"], "summary": "The modeling and control of single-phase flow systems governed by Partial\nDifferential Equations (PDEs) present challenges, especially under transient\nconditions. In this work, we extend the Physics-Informed Neural Nets for\nControl (PINC) framework, originally proposed to modeling and control of\nOrdinary Differential Equations (ODE) without the need of any labeled data, to\nthe PDE case, particularly to single-phase incompressible and compressible\nflows, integrating neural networks with physical conservation laws. The PINC\nmodel for PDEs is structured into two stages: a steady-state network, which\nlearns equilibrium solutions for a wide range of control inputs, and a\ntransient network, which captures dynamic responses under time-varying boundary\nconditions. We propose a simplifying assumption that reduces the dimensionality\nof the spatial coordinate regarding the initial condition, allowing the\nefficient training of the PINC network. This simplification enables the\nderivation of optimal control policies using Model Predictive Control (MPC). We\nvalidate our approach through numerical experiments, demonstrating that the\nPINC model, which is trained exclusively using physical laws, i.e., without\nlabeled data, accurately represents flow dynamics and enables real-time control\napplications. The results highlight the PINC's capability to efficiently\napproximate PDE solutions without requiring iterative solvers, making it a\npromising alternative for fluid flow monitoring and optimization in engineering\napplications.", "comment": "62 pages, 14 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06188v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05441", "title": "Deep histological synthesis from mass spectrometry imaging for multimodal registration", "authors": ["Kimberley M. Bird", "Xujiong Ye", "Alan M. Race", "James M. Brown"], "summary": "Registration of histological and mass spectrometry imaging (MSI) allows for\nmore precise identification of structural changes and chemical interactions in\ntissue. With histology and MSI having entirely different image formation\nprocesses and dimensionalities, registration of the two modalities remains an\nongoing challenge. This work proposes a solution that synthesises histological\nimages from MSI, using a pix2pix model, to effectively enable unimodal\nregistration. Preliminary results show promising synthetic histology images\nwith limited artifacts, achieving increases in mutual information (MI) and\nstructural similarity index measures (SSIM) of +0.924 and +0.419, respectively,\ncompared to a baseline U-Net model. Our source code is available on GitHub:\nhttps://github.com/kimberley/MIUA2025.", "comment": "Medical Image Understanding and Analysis (MIUA) 2025 Extended\n  Abstract Submission", "cate": "eess.IV", "url": "http://arxiv.org/pdf/2506.05441v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06192", "title": "ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts", "authors": ["Dimitrios Proios", "Alban Bornet", "Anthony Yazdani", "Jose F Rodrigues Jr", "Douglas Teodoro"], "summary": "Patient stratification identifying clinically meaningful subgroups is\nessential for advancing personalized medicine through improved diagnostics and\ntreatment strategies. Electronic health records (EHRs), particularly those from\nintensive care units (ICUs), contain rich temporal clinical data that can be\nleveraged for this purpose. In this work, we introduce ICU-TSB (Temporal\nStratification Benchmark), the first comprehensive benchmark for evaluating\npatient stratification based on temporal patient representation learning using\nthree publicly available ICU EHR datasets. A key contribution of our benchmark\nis a novel hierarchical evaluation framework utilizing disease taxonomies to\nmeasure the alignment of discovered clusters with clinically validated disease\ngroupings. In our experiments with ICU-TSB, we compared statistical methods and\nseveral recurrent neural networks, including LSTM and GRU, for their ability to\ngenerate effective patient representations for subsequent clustering of patient\ntrajectories. Our results demonstrate that temporal representation learning can\nrediscover clinically meaningful patient cohorts; nevertheless, it remains a\nchallenging task, with v-measuring varying from up to 0.46 at the top level of\nthe taxonomy to up to 0.40 at the lowest level. To further enhance the\npractical utility of our findings, we also evaluate multiple strategies for\nassigning interpretable labels to the identified clusters. The experiments and\nbenchmark are fully reproducible and available at\nhttps://github.com/ds4dh/CBMS2025stratification.", "comment": "6 pages 1 table 6 figures", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06192v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06194", "title": "Transformative or Conservative? Conservation laws for ResNets and Transformers", "authors": ["Sibylle Marcotte", "Rémi Gribonval", "Gabriel Peyré"], "summary": "While conservation laws in gradient flow training dynamics are well\nunderstood for (mostly shallow) ReLU and linear networks, their study remains\nlargely unexplored for more practical architectures. This paper bridges this\ngap by deriving and analyzing conservation laws for modern architectures, with\na focus on convolutional ResNets and Transformer networks. For this, we first\nshow that basic building blocks such as ReLU (or linear) shallow networks, with\nor without convolution, have easily expressed conservation laws, and no more\nthan the known ones. In the case of a single attention layer, we also\ncompletely describe all conservation laws, and we show that residual blocks\nhave the same conservation laws as the same block without a skip connection. We\nthen introduce the notion of conservation laws that depend only on a subset of\nparameters (corresponding e.g. to a pair of consecutive layers, to a residual\nblock, or to an attention layer). We demonstrate that the characterization of\nsuch laws can be reduced to the analysis of the corresponding building block in\nisolation. Finally, we examine how these newly discovered conservation\nprinciples, initially established in the continuous gradient flow regime,\npersist under discrete optimization dynamics, particularly in the context of\nStochastic Gradient Descent (SGD).", "comment": "Accepted to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06194v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05531", "title": "Meta-analysis of Life Cycle Assessments for Li-Ion Batteries Production Emissions", "authors": ["Maurizio Clemente", "Prapti Maharjan", "Mauro Salazar", "Theo Hofman"], "summary": "This paper investigates the environmental impact of Li-Ion batteries by\nquantifying manufacturing-related emissions and analyzing how electricity mix\nand production scale affect emission intensity. To this end, we conduct a\nmeta-analysis of life cycle assessments on lithium-ion batteries published over\nthe past two decades, categorizing them by year, battery chemistry, functional\nunit, system boundaries, and electricity mix. We then carry out a\ncradle-to-gate assessment for a nickel manganese cobalt 811 battery with a\nsilicon-coated graphite anode, analyzing how variations in the carbon intensity\nof the electricity mix affect emissions, with case studies for China, South\nKorea, and Sweden. Finally, we develop a set of regression models that link\nannual battery production and the carbon intensity of China's electricity mix\nto the average mass-specific emissions observed each year. The meta-analysis\nshows a median global warming potential of 17.63 kg CO2-eq./kg of battery, with\na standard deviation of 7.34. Differences in electricity mix mainly influence\nemissions from the energy-intensive cell production, particularly from cathode\nmaterial processing. We found that a multivariate linear regression using\nproduction volume and the carbon intensity of the Chinese electricity mix as\npredictors explains emissions with moderate accuracy. The environmental impact\nof battery manufacturing can be reduced by using clean energy sources in\nproduction processes. However, achieving substantial reductions requires clean\nenergy throughout the entire supply chain, as importing materials from regions\nwith carbon-intensive electricity mixes can undermine these efforts. Our\nfindings also highlight the emission-reducing effect of learning associated\nwith increased production scale, supporting the integration of learning effects\nin future life cycle assessment models.", "comment": "15 pages, 7 figures, 12 tables", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05531v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05873", "title": "Research on Personalized Financial Product Recommendation by Integrating Large Language Models and Graph Neural Networks", "authors": ["Yushang Zhao", "Yike Peng", "Dannier Li", "Yuxin Yang", "Chengrui Zhou", "Jing Dong"], "summary": "With the rapid growth of fintech, personalized financial product\nrecommendations have become increasingly important. Traditional methods like\ncollaborative filtering or content-based models often fail to capture users'\nlatent preferences and complex relationships. We propose a hybrid framework\nintegrating large language models (LLMs) and graph neural networks (GNNs). A\npre-trained LLM encodes text data (e.g., user reviews) into rich feature\nvectors, while a heterogeneous user-product graph models interactions and\nsocial ties. Through a tailored message-passing mechanism, text and graph\ninformation are fused within the GNN to jointly optimize embeddings.\nExperiments on public and real-world financial datasets show our model\noutperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong\ninterpretability. This work offers new insights for personalized financial\nrecommendations and cross-modal fusion in broader recommendation tasks.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.05873v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06204", "title": "How to craft a deep reinforcement learning policy for wind farm flow control", "authors": ["Elie Kadoche", "Pascal Bianchi", "Florence Carton", "Philippe Ciblat", "Damien Ernst"], "summary": "Within wind farms, wake effects between turbines can significantly reduce\noverall energy production. Wind farm flow control encompasses methods designed\nto mitigate these effects through coordinated turbine control. Wake steering,\nfor example, consists in intentionally misaligning certain turbines with the\nwind to optimize airflow and increase power output. However, designing a robust\nwake steering controller remains challenging, and existing machine learning\napproaches are limited to quasi-static wind conditions or small wind farms.\nThis work presents a new deep reinforcement learning methodology to develop a\nwake steering policy that overcomes these limitations. Our approach introduces\na novel architecture that combines graph attention networks and multi-head\nself-attention blocks, alongside a novel reward function and training strategy.\nThe resulting model computes the yaw angles of each turbine, optimizing energy\nproduction in time-varying wind conditions. An empirical study conducted on\nsteady-state, low-fidelity simulation, shows that our model requires\napproximately 10 times fewer training steps than a fully connected neural\nnetwork and achieves more robust performance compared to a strong optimization\nbaseline, increasing energy production by up to 14 %. To the best of our\nknowledge, this is the first deep reinforcement learning-based wake steering\ncontroller to generalize effectively across any time-varying wind conditions in\na low-fidelity, steady-state numerical simulation setting.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06204v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05876", "title": "Bayesian Persuasion as a Bargaining Game", "authors": ["Yue Lin", "Shuhui Zhu", "William A Cunningham", "Wenhao Li", "Pascal Poupart", "Hongyuan Zha", "Baoxiang Wang"], "summary": "Bayesian persuasion, an extension of cheap-talk communication, involves an\ninformed sender committing to a signaling scheme to influence a receiver's\nactions. Compared to cheap talk, this sender's commitment enables the receiver\nto verify the incentive compatibility of signals beforehand, facilitating\ncooperation. While effective in one-shot scenarios, Bayesian persuasion faces\ncomputational complexity (NP-hardness) when extended to long-term interactions,\nwhere the receiver may adopt dynamic strategies conditional on past outcomes\nand future expectations. To address this complexity, we introduce the\nbargaining perspective, which allows: (1) a unified framework and\nwell-structured solution concept for long-term persuasion, with desirable\nproperties such as fairness and Pareto efficiency; (2) a clear distinction\nbetween two previously conflated advantages: the sender's informational\nadvantage and first-proposer advantage. With only modest modifications to the\nstandard setting, this perspective makes explicit the common knowledge of the\ngame structure and grants the receiver comparable commitment capabilities,\nthereby reinterpreting classic one-sided persuasion as a balanced information\nbargaining framework. The framework is validated through a two-stage\nvalidation-and-inference paradigm: We first demonstrate that GPT-o3 and\nDeepSeek-R1, out of publicly available LLMs, reliably handle standard tasks; We\nthen apply them to persuasion scenarios to test that the outcomes align with\nwhat our information-bargaining framework suggests. All code, results, and\nterminal logs are publicly available at\ngithub.com/YueLin301/InformationBargaining.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.05876v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06212", "title": "Model-Driven Graph Contrastive Learning", "authors": ["Ali Azizpour", "Nicolas Zilberstein", "Santiago Segarra"], "summary": "We propose $\\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)\nframework that leverages graphons (probabilistic generative models for graphs)\nto guide contrastive learning by accounting for the data's underlying\ngenerative process. GCL has emerged as a powerful self-supervised framework for\nlearning expressive node or graph representations without relying on annotated\nlabels, which are often scarce in real-world data. By contrasting augmented\nviews of graph data, GCL has demonstrated strong performance across various\ndownstream tasks, such as node and graph classification. However, existing\nmethods typically rely on manually designed or heuristic augmentation\nstrategies that are not tailored to the underlying data distribution and\noperate at the individual graph level, ignoring similarities among graphs\ngenerated from the same model. Conversely, in our proposed approach, MGCL first\nestimates the graphon associated with the observed data and then defines a\ngraphon-informed augmentation process, enabling data-adaptive and principled\naugmentations. Additionally, for graph-level tasks, MGCL clusters the dataset\nand estimates a graphon per group, enabling contrastive pairs to reflect shared\nsemantics and structure. Extensive experiments on benchmark datasets\ndemonstrate that MGCL achieves state-of-the-art performance, highlighting the\nadvantages of incorporating generative models into GCL.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06212v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05535", "title": "Approximation of the Pseudospectral Abscissa via Eigenvalue Perturbation Theory", "authors": ["Waqar Ahmed", "Emre Mengi"], "summary": "Reliable and efficient computation of the pseudospectral abscissa in the\nlarge-scale setting is still not settled. Unlike the small-scale setting where\nthere are globally convergent criss-cross algorithms, all algorithms in the\nlarge-scale setting proposed to date are at best locally convergent. We first\ndescribe how eigenvalue perturbation theory can be put in use to estimate the\nglobally rightmost point in the $\\epsilon$-pseudospectrum if $\\epsilon$ is\nsmall. Our treatment addresses both general nonlinear eigenvalue problems, and\nthe standard eigenvalue problem as a special case. For small $\\epsilon$, the\nestimates by eigenvalue perturbation theory are quite accurate. In the standard\neigenvalue case, we even derive a formula with an ${\\mathcal O}(\\epsilon^3)$\nerror. For larger $\\epsilon$, the estimates can be used to initialize the\nlocally convergent algorithms. We also propose fixed-point iterations built on\nthe the perturbation theory ideas for large $\\epsilon$ that are suitable for\nthe large-scale setting. The proposed fixed-point iterations initialized by\nusing eigenvalue perturbation theory converge to the globally rightmost point\nin the pseudospectrum in a vast majority of the cases that we experiment with.", "comment": "40 pages, 8 figures", "cate": "math.NA", "url": "http://arxiv.org/pdf/2506.05535v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05633", "title": "Noninvasive precision modulation of high-level neural population activity via natural vision perturbations", "authors": ["Guy Gaziv", "Sarah Goulding", "Ani Ayvazian-Hancock", "Yoon Bai", "James J. DiCarlo"], "summary": "Precise control of neural activity -- modulating target neurons deep in the\nbrain while leaving nearby neurons unaffected -- is an outstanding challenge in\nneuroscience, generally achieved through invasive techniques. This study\ninvestigates the possibility of precisely and noninvasively modulating neural\nactivity in the high-level primate ventral visual stream via perturbations on\none's natural visual feed. When tested on macaque inferior temporal (IT) neural\npopulations, we found quantitative agreement between the model-predicted and\nbiologically realized effect: strong modulation concentrated on targeted neural\nsites. We extended this to demonstrate accurate injection of\nexperimenter-chosen neural population patterns via subtle perturbations applied\non the background of typical natural visual feeds. These results highlight that\ncurrent machine-executable models of the ventral stream can now design\nnoninvasive, visually-delivered, possibly imperceptible neural interventions at\nthe resolution of individual neurons.", "comment": null, "cate": "q-bio.NC", "url": "http://arxiv.org/pdf/2506.05633v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06215", "title": "Corrector Sampling in Language Models", "authors": ["Itai Gat", "Neta Shaul", "Uriel Singer", "Yaron Lipman"], "summary": "Autoregressive language models accumulate errors due to their fixed,\nirrevocable left-to-right token generation. To address this, we propose a new\nsampling method called Resample-Previous-Tokens (RPT). RPT mitigates error\naccumulation by iteratively revisiting and potentially replacing tokens in a\nwindow of previously generated text. This method can be integrated into\nexisting autoregressive models, preserving their next-token-prediction quality\nand speed. Fine-tuning a pretrained 8B parameter model with RPT for only 100B\nresulted in ~10% relative improvements on reasoning and coding benchmarks\ncompared to the standard sampling.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06215v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06231", "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": ["Mohammad Jalali", "Bahar Dibaei Nia", "Farzan Farnia"], "summary": "While several feature embedding models have been developed in the literature,\ncomparisons of these embeddings have largely focused on their numerical\nperformance in classification-related downstream applications. However, an\ninterpretable comparison of different embeddings requires identifying and\nanalyzing mismatches between sample groups clustered within the embedding\nspaces. In this work, we propose the \\emph{Spectral Pairwise Embedding\nComparison (SPEC)} framework to compare embeddings and identify their\ndifferences in clustering a reference dataset. Our approach examines the kernel\nmatrices derived from two embeddings and leverages the eigendecomposition of\nthe difference kernel matrix to detect sample clusters that are captured\ndifferently by the two embeddings. We present a scalable implementation of this\nkernel-based approach, with computational complexity that grows linearly with\nthe sample size. Furthermore, we introduce an optimization problem using this\nframework to align two embeddings, ensuring that clusters identified in one\nembedding are also captured in the other model. We provide numerical results\ndemonstrating the SPEC's application to compare and align embeddings on\nlarge-scale datasets such as ImageNet and MS-COCO. The code is available at\n[https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06231v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05899", "title": "WhisQ: Cross-Modal Representation Learning for Text-to-Music MOS Prediction", "authors": ["Jakaria Islam Emon", "Kazi Tamanna Alam", "Md. Abu Salek"], "summary": "Mean Opinion Score (MOS) prediction for text to music systems requires\nevaluating both overall musical quality and text prompt alignment. This paper\nintroduces WhisQ, a multimodal architecture that addresses this dual-assessment\nchallenge through sequence level co-attention and optimal transport\nregularization. WhisQ employs the Whisper Base pretrained model for temporal\naudio encoding and Qwen 3, a 0.6B Small Language Model (SLM), for text\nencoding, with both maintaining sequence structure for fine grained cross-modal\nmodeling. The architecture features specialized prediction pathways: OMQ is\npredicted from pooled audio embeddings, while TA leverages bidirectional\nsequence co-attention between audio and text. Sinkhorn optimal transport loss\nfurther enforce semantic alignment in the shared embedding space. On the\nMusicEval Track-1 dataset, WhisQ achieves substantial improvements over the\nbaseline: 7% improvement in Spearman correlation for OMQ and 14% for TA.\nAblation studies reveal that optimal transport regularization provides the\nlargest performance gain (10% SRCC improvement), demonstrating the importance\nof explicit cross-modal alignment for text-to-music evaluation.", "comment": "3 pages", "cate": "cs.SD", "url": "http://arxiv.org/pdf/2506.05899v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06244", "title": "Neural Responses to Affective Sentences Reveal Signatures of Depression", "authors": ["Aditya Kommineni", "Woojae Jeong", "Kleanthis Avramidis", "Colin McDaniel", "Myzelle Hughes", "Thomas McGee", "Elsi Kaiser", "Kristina Lerman", "Idan A. Blank", "Dani Byrd", "Assal Habibi", "B. Rael Cahn", "Sudarsana Kadiri", "Takfarinas Medani", "Richard M. Leahy", "Shrikanth Narayanan"], "summary": "Major Depressive Disorder (MDD) is a highly prevalent mental health\ncondition, and a deeper understanding of its neurocognitive foundations is\nessential for identifying how core functions such as emotional and\nself-referential processing are affected. We investigate how depression alters\nthe temporal dynamics of emotional processing by measuring neural responses to\nself-referential affective sentences using surface electroencephalography (EEG)\nin healthy and depressed individuals. Our results reveal significant\ngroup-level differences in neural activity during sentence viewing, suggesting\ndisrupted integration of emotional and self-referential information in\ndepression. Deep learning model trained on these responses achieves an area\nunder the receiver operating curve (AUC) of 0.707 in distinguishing healthy\nfrom depressed participants, and 0.624 in differentiating depressed subgroups\nwith and without suicidal ideation. Spatial ablations highlight anterior\nelectrodes associated with semantic and affective processing as key\ncontributors. These findings suggest stable, stimulus-driven neural signatures\nof depression that may inform future diagnostic tools.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06244v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05679", "title": "Integer Binary-Range Alignment Neuron for Spiking Neural Networks", "authors": ["Binghao Ye", "Wenjuan Li", "Dong Wang", "Man Yao", "Bing Li", "Weiming Hu", "Dong Liang", "Kun Shang"], "summary": "Spiking Neural Networks (SNNs) are noted for their brain-like computation and\nenergy efficiency, but their performance lags behind Artificial Neural Networks\n(ANNs) in tasks like image classification and object detection due to the\nlimited representational capacity. To address this, we propose a novel spiking\nneuron, Integer Binary-Range Alignment Leaky Integrate-and-Fire to\nexponentially expand the information expression capacity of spiking neurons\nwith only a slight energy increase. This is achieved through Integer Binary\nLeaky Integrate-and-Fire and range alignment strategy. The Integer Binary Leaky\nIntegrate-and-Fire allows integer value activation during training and\nmaintains spike-driven dynamics with binary conversion expands virtual\ntimesteps during inference. The range alignment strategy is designed to solve\nthe spike activation limitation problem where neurons fail to activate high\ninteger values. Experiments show our method outperforms previous SNNs,\nachieving 74.19% accuracy on ImageNet and 66.2% mAP@50 and 49.1% mAP@50:95 on\nCOCO, surpassing previous bests with the same architecture by +3.45% and +1.6%\nand +1.8%, respectively. Notably, our SNNs match or exceed ANNs' performance\nwith the same architecture, and the energy efficiency is improved by\n6.3${\\times}$.", "comment": "11 pages", "cate": "cs.NE", "url": "http://arxiv.org/pdf/2506.05679v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05901", "title": "Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router", "authors": ["Chenyang Shao", "Xinyang Liu", "Yutang Lin", "Fengli Xu", "Yong Li"], "summary": "Multi-step reasoning has proven essential for enhancing the problem-solving\ncapabilities of Large Language Models (LLMs) by decomposing complex tasks into\nintermediate steps, either explicitly or implicitly. Extending the reasoning\nchain at test time through deeper thought processes or broader exploration, can\nfurthur improve performance, but often incurs substantial costs due to the\nexplosion in token usage. Yet, many reasoning steps are relatively simple and\ncan be handled by more efficient smaller-scale language models (SLMs). This\nmotivates hybrid approaches that allocate subtasks across models of varying\ncapacities. However, realizing such collaboration requires accurate task\ndecomposition and difficulty-aware subtask allocation, which is challenging. To\naddress this, we propose R2-Reasoner, a novel framework that enables\ncollaborative reasoning across heterogeneous LLMs by dynamically routing\nsub-tasks based on estimated complexity. At the core of our framework is a\nReinforced Model Router, composed of a task decomposer and a subtask allocator.\nThe task decomposer segments complex input queries into logically ordered\nsubtasks, while the subtask allocator assigns each subtask to the most\nappropriate model, ranging from lightweight SLMs to powerful LLMs, balancing\naccuracy and efficiency. To train this router, we introduce a staged pipeline\nthat combines supervised fine-tuning on task-specific datasets with Group\nRelative Policy Optimization algorithm, enabling self-supervised refinement\nthrough iterative reinforcement learning. Extensive experiments across four\nchallenging benchmarks demonstrate that R2-Reasoner reduces API costs by 86.85%\nwhile maintaining or surpassing baseline accuracy. Our framework paves the way\nfor more cost-effective and adaptive LLM reasoning. The code is open-source at\nhttps://anonymous.4open.science/r/R2_Reasoner .", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05901v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06248", "title": "Lagrangian-based Equilibrium Propagation: generalisation to arbitrary boundary conditions & equivalence with Hamiltonian Echo Learning", "authors": ["Guillaume Pourcel", "Debabrota Basu", "Maxence Ernoult", "Aditya Gilra"], "summary": "Equilibrium Propagation (EP) is a learning algorithm for training\nEnergy-based Models (EBMs) on static inputs which leverages the variational\ndescription of their fixed points. Extending EP to time-varying inputs is a\nchallenging problem, as the variational description must apply to the entire\nsystem trajectory rather than just fixed points, and careful consideration of\nboundary conditions becomes essential. In this work, we present Generalized\nLagrangian Equilibrium Propagation (GLEP), which extends the variational\nformulation of EP to time-varying inputs. We demonstrate that GLEP yields\ndifferent learning algorithms depending on the boundary conditions of the\nsystem, many of which are impractical for implementation. We then show that\nHamiltonian Echo Learning (HEL) -- which includes the recently proposed\nRecurrent HEL (RHEL) and the earlier known Hamiltonian Echo Backpropagation\n(HEB) algorithms -- can be derived as a special case of GLEP. Notably, HEL is\nthe only instance of GLEP we found that inherits the properties that make EP a\ndesirable alternative to backpropagation for hardware implementations: it\noperates in a \"forward-only\" manner (i.e. using the same system for both\ninference and learning), it scales efficiently (requiring only two or more\npasses through the system regardless of model size), and enables local\nlearning.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06248v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06278", "title": "Distillation Robustifies Unlearning", "authors": ["Bruce W. Lee", "Addie Foote", "Alex Infanger", "Leni Shor", "Harish Kamath", "Jacob Goldman-Wetzler", "Bryce Woodworth", "Alex Cloud", "Alexander Matt Turner"], "summary": "Current LLM unlearning methods are not robust: they can be reverted easily\nwith a few steps of finetuning. This is true even for the idealized unlearning\nmethod of training to imitate an oracle model that was never exposed to\nunwanted information, suggesting that output-based finetuning is insufficient\nto achieve robust unlearning. In a similar vein, we find that training a\nrandomly initialized student to imitate an unlearned model transfers desired\nbehaviors while leaving undesired capabilities behind. In other words,\ndistillation robustifies unlearning. Building on this insight, we propose\nUnlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an\nunlearned model into a partially noised copy of itself. UNDO introduces a\ntunable tradeoff between compute cost and robustness, establishing a new Pareto\nfrontier on synthetic language and arithmetic tasks. At its strongest setting,\nUNDO matches the robustness of a model retrained from scratch with perfect data\nfiltering while using only 60-80% of the compute and requiring only 0.01% of\nthe pretraining data to be labeled. We also show that UNDO robustifies\nunlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP)\nbenchmark. Since distillation is widely used in practice, incorporating an\nunlearning step beforehand offers a convenient path to robust capability\nremoval.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06278v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06280", "title": "Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias", "authors": ["Yuanzhe Hu", "Kinshuk Goel", "Vlad Killiakov", "Yaoqing Yang"], "summary": "Diagnosing deep neural networks (DNNs) through the eigenspectrum of weight\nmatrices has been an active area of research in recent years. At a high level,\neigenspectrum analysis of DNNs involves measuring the heavytailness of the\nempirical spectral densities (ESD) of weight matrices. It provides insight into\nhow well a model is trained and can guide decisions on assigning better\nlayer-wise training hyperparameters. In this paper, we address a challenge\nassociated with such eigenspectrum methods: the impact of the aspect ratio of\nweight matrices on estimated heavytailness metrics. We demonstrate that\nmatrices of varying sizes (and aspect ratios) introduce a non-negligible bias\nin estimating heavytailness metrics, leading to inaccurate model diagnosis and\nlayer-wise hyperparameter assignment. To overcome this challenge, we propose\nFARMS (Fixed-Aspect-Ratio Matrix Subsampling), a method that normalizes the\nweight matrices by subsampling submatrices with a fixed aspect ratio. Instead\nof measuring the heavytailness of the original ESD, we measure the average ESD\nof these subsampled submatrices. We show that measuring the heavytailness of\nthese submatrices with the fixed aspect ratio can effectively mitigate the\naspect ratio bias. We validate our approach across various optimization\ntechniques and application domains that involve eigenspectrum analysis of\nweights, including image classification in computer vision (CV) models,\nscientific machine learning (SciML) model training, and large language model\n(LLM) pruning. Our results show that despite its simplicity, FARMS uniformly\nimproves the accuracy of eigenspectrum analysis while enabling more effective\nlayer-wise hyperparameter assignment in these application domains. In one of\nthe LLM pruning experiments, FARMS reduces the perplexity of the LLaMA-7B model\nby 17.3% when compared with the state-of-the-art method.", "comment": "30 pages, 14 figures, published to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06280v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05927", "title": "LengClaro2023: A Dataset of Administrative Texts in Spanish with Plain Language adaptations", "authors": ["Belén Agüera-Marco", "Itziar Gonzalez-Dios"], "summary": "In this work, we present LengClaro2023, a dataset of legal-administrative\ntexts in Spanish. Based on the most frequently used procedures from the Spanish\nSocial Security website, we have created for each text two simplified\nequivalents. The first version follows the recommendations provided by arText\nclaro. The second version incorporates additional recommendations from plain\nlanguage guidelines to explore further potential improvements in the system.\nThe linguistic resource created in this work can be used for evaluating\nautomatic text simplification (ATS) systems in Spanish.", "comment": "In this report, we present a part of the master thesis written by\n  Bel\\'en Ag\\\"uera Marco in order to obtain the B.S. Language Analysis and\n  Processing at the University of the Basque Country (UPV/EHU), supervised by\n  Itziar Gonzalez-Dios", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05927v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2406.03674", "title": "Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions", "authors": ["Negin Golrezaei", "Sourav Sahoo"], "summary": "We study the bidding problem in repeated uniform price multi-unit auctions\nfrom the perspective of a single value-maximizing buyer who aims to maximize\ntheir cumulative value over $T$ rounds while adhering to return-on-investment\n(RoI) constraints in each round. Buyers adopt $m$-uniform bidding format, where\nthey submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid\n$b_i$. We introduce safe bidding strategies as those that satisfy RoI\nconstraints in every auction, regardless of competing bids. We show that these\nstrategies depend only on the valuation curve of the bidder, and the bidder can\nfocus on a finite subset of this class without loss of generality. While the\nnumber of strategies in this subset is exponential in $m$, we develop a\npolynomial-time algorithm to learn the optimal safe strategy that achieves\nsublinear regret in the online setting, where regret is measured against a\nclairvoyant benchmark that knows the competing bids a priori and selects a\nfixed hindsight optimal safe strategy. We then evaluate the performance of safe\nstrategies against a clairvoyant that selects the optimal strategy from a\nricher class of strategies in the online setting. In this scenario, we compute\nthe richness ratio, $\\alpha\\in(0, 1]$ for the class of strategies chosen by the\nclairvoyant and show that our algorithm, designed to learn safe strategies,\nachieves $\\alpha$-approximate sublinear regret against these stronger\nbenchmarks. Experiments on semi-synthetic data from real-world auctions show\nthat safe strategies substantially outperform the derived theoretical bounds,\nmaking them quite appealing in practice.", "comment": "61 pages, 4 figures. To appear at ICML 2025", "cate": "cs.DS", "url": "http://arxiv.org/pdf/2406.03674v2", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05928", "title": "MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient Fine-Tuning of Large Language Models", "authors": ["Jie Cao", "Tianwei Lin", "Hongyang He", "Rolan Yan", "Wenqiao Zhang", "Juncheng Li", "Dongping Zhang", "Siliang Tang", "Yueting Zhuang"], "summary": "Recent studies integrate Low-Rank Adaptation (LoRA) and Mixture-of-Experts\n(MoE) to further enhance the performance of parameter-efficient fine-tuning\n(PEFT) methods in Large Language Model (LLM) applications. Existing methods\nemploy \\emph{homogeneous} MoE-LoRA architectures composed of LoRA experts with\neither similar or identical structures and capacities. However, these\napproaches often suffer from representation collapse and expert load imbalance,\nwhich negatively impact the potential of LLMs. To address these challenges, we\npropose a \\emph{heterogeneous} \\textbf{Mixture-of-Adapters (MoA)} approach.\nThis method dynamically integrates PEFT adapter experts with diverse\nstructures, leveraging their complementary representational capabilities to\nfoster expert specialization, thereby enhancing the effective transfer of\npre-trained knowledge to downstream tasks. MoA supports two variants:\n\\textbf{(i)} \\textit{Soft MoA} achieves fine-grained integration by performing\na weighted fusion of all expert outputs; \\textbf{(ii)} \\textit{Sparse MoA}\nactivates adapter experts sparsely based on their contribution, achieving this\nwith negligible performance degradation. Experimental results demonstrate that\nheterogeneous MoA outperforms homogeneous MoE-LoRA methods in both performance\nand parameter efficiency. Our project is available at\nhttps://github.com/DCDmllm/MoA.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05928v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05354", "title": "Adaptive stable distribution and Hurst exponent by method of moments moving estimator for nonstationary time series", "authors": ["Jarek Duda"], "summary": "Nonstationarity of real-life time series requires model adaptation. In\nclassical approaches like ARMA-ARCH there is assumed some arbitrarily chosen\ndependence type. To avoid their bias, we will focus on novel more agnostic\napproach: moving estimator, which estimates parameters separately for every\ntime $t$: optimizing $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta\n(x_\\tau))$ local log-likelihood with exponentially weakening weights of the old\nvalues. In practice such moving estimates can be found by EMA (exponential\nmoving average) of some parameters, like $m_p=E[|x-\\mu|^p]$ absolute central\nmoments, updated by $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$. We\nwill focus here on its applications for alpha-Stable distribution, which also\ninfluences Hurst exponent, hence can be used for its adaptive estimation. Its\napplication will be shown on financial data as DJIA time series - beside\nstandard estimation of evolution of center $\\mu$ and scale parameter $\\sigma$,\nthere is also estimated evolution of $\\alpha$ parameter allowing to\ncontinuously evaluate market stability - tails having $\\rho(x) \\sim\n1/|x|^{\\alpha+1}$ behavior, controlling probability of potentially dangerous\nextreme events.", "comment": "5 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2304.03069", "cate": "stat.ME", "url": "http://arxiv.org/pdf/2506.05354v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05560", "title": "Improving LLMs with a knowledge from databases", "authors": ["Petr Máša"], "summary": "Large language models (LLMs) are achieving significant progress almost every\nmoment now. Many advanced techniques have been introduced and widely accepted,\nlike retrieval-augmentation generation (RAG), agents, and tools. Tools can\nquery the database to answer questions from structured data files or perform\ngroupings or other statistics. This unlocks huge opportunities, such as it can\nanswer any question, but also poses threats, such as safety, because there is\nno control over the commands that are created. We would like to discuss whether\nwe can create a new method that improves answers based on dataset/database via\nsome interpretable ML methods, namely enhanced association rules. The advantage\nwould be if the method can be also used in some safe technique like RAG.\nAssociation rules have a sound history. Since the introduction of CN2 and\naproiri, many enhancements have been made. In parallel, enhanced association\nrules have been introduced and evolved over the last 40 years. The general\nproblem is typically that there are too many rules. There are some techniques\nfor handling it, but when LLM emerged, it turned out to be the best use case\nfor the RAG technique for LLMs. We proposed a method that generates a ruleset\nbased on defined knowledge patterns, then converts rules into text form via a\nrule-to-text converter, and includes the result as an RAG into LLM. We compared\nthis method with ChatGPT (even with using agents) and we have discovered a\nsignificant improvement in answering questions based on the dataset. We have\nalso tried several strategies how much rules to generate. We found this\nimprovement interesting. Moreover, it can also be improved in many ways as\nfuture work, like incorporating other patterns, the use of rule mining as an\nagent, and many others.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05560v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05935", "title": "SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction", "authors": ["Yuchao Zheng", "Jianing Zhang", "Guochen Ning", "Hongen Liao"], "summary": "Intraoperative navigation relies heavily on precise 3D reconstruction to\nensure accuracy and safety during surgical procedures. However, endoscopic\nscenarios present unique challenges, including sparse features and inconsistent\nlighting, which render many existing Structure-from-Motion (SfM)-based methods\ninadequate and prone to reconstruction failure. To mitigate these constraints,\nwe propose SurGSplat, a novel paradigm designed to progressively refine 3D\nGaussian Splatting (3DGS) through the integration of geometric constraints. By\nenabling the detailed reconstruction of vascular structures and other critical\nfeatures, SurGSplat provides surgeons with enhanced visual clarity,\nfacilitating precise intraoperative decision-making. Experimental evaluations\ndemonstrate that SurGSplat achieves superior performance in both novel view\nsynthesis (NVS) and pose estimation accuracy, establishing it as a\nhigh-fidelity and efficient solution for surgical scene reconstruction. More\ninformation and results can be found on the page https://surgsplat.github.io/.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.05935v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05936", "title": "DynamicMind: A Tri-Mode Thinking System for Large Language Models", "authors": ["Wei Li", "Yanbin Wei", "Qiushi Huang", "Jiangyue Yan", "Yang Chen", "James T. Kwok", "Yu Zhang"], "summary": "Modern large language models (LLMs) often struggle to dynamically adapt their\nreasoning depth to varying task complexities, leading to suboptimal performance\nor inefficient resource utilization. To address this, we introduce DynamicMind,\na novel tri-mode thinking system. DynamicMind empowers LLMs to autonomously\nselect between Fast, Normal, and Slow thinking modes for zero-shot question\nanswering (ZSQA) tasks through cognitive-inspired prompt engineering. Our\nframework's core innovations include: (1) expanding the established\ndual-process framework of fast and slow thinking into a tri-mode thinking\nsystem involving a normal thinking mode to preserve the intrinsic capabilities\nof LLM; (2) proposing the Thinking Density metric, which aligns computational\nresource allocation with problem complexity; and (3) developing the Thinking\nMode Capacity (TMC) dataset and a lightweight Mind Router to predict the\noptimal thinking mode. Extensive experiments across diverse mathematical,\ncommonsense, and scientific QA benchmarks demonstrate that DynamicMind achieves\nsuperior ZSQA capabilities while establishing an effective trade-off between\nperformance and computational efficiency.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05936v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06054", "title": "FPDANet: A Multi-Section Classification Model for Intelligent Screening of Fetal Ultrasound", "authors": ["Minglang Chen", "Jie He", "Caixu Xu", "Bocheng Liang", "Shengli Li", "Guannan He", "Xiongjie Tao"], "summary": "ResNet has been widely used in image classification tasks due to its ability\nto model the residual dependence of constant mappings for linear computation.\nHowever, the ResNet method adopts a unidirectional transfer of features and\nlacks an effective method to correlate contextual information, which is not\neffective in classifying fetal ultrasound images in the classification task,\nand fetal ultrasound images have problems such as low contrast, high\nsimilarity, and high noise. Therefore, we propose a bilateral multi-scale\ninformation fusion network-based FPDANet to address the above challenges.\nSpecifically, we design the positional attention mechanism (DAN) module, which\nutilizes the similarity of features to establish the dependency of different\nspatial positional features and enhance the feature representation. In\naddition, we design a bilateral multi-scale (FPAN) information fusion module to\ncapture contextual and global feature dependencies at different feature scales,\nthereby further improving the model representation. FPDANet classification\nresults obtained 91.05\\% and 100\\% in Top-1 and Top-5 metrics, respectively,\nand the experimental results proved the effectiveness and robustness of\nFPDANet.", "comment": null, "cate": "eess.IV", "url": "http://arxiv.org/pdf/2506.06054v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06092", "title": "LinGuinE: Longitudinal Guidance Estimation for Volumetric Lung Tumour Segmentation", "authors": ["Nadine Garibli", "Mayank Patwari", "Bence Csiba", "Yi Wei", "Kostas Sidiropoulos"], "summary": "Segmentation of lung gross tumour volumes is an important first step in\nradiotherapy and surgical intervention, and is starting to play a role in\nassessing chemotherapy response. Response to a drug is measured by tracking the\ntumour volumes over a series of CT scans over a time period i.e. a longitudinal\nstudy. However, there currently exist few solutions for automated or\nsemi-automated longitudinal tumour segmentation. This paper introduces\nLinGuinE, an automated method to segment a longitudinal series of lung tumours.\nA radiologist must provide an initial input, indicating the location of the\ntumour in a CT scan at an arbitrary time point. LinGuinE samples points inside\nthis tumour and propagates them to another time point using rigid registration.\nA click validity classifier selects points which still fall within the tumour;\nthese are used to automatically create a segmentation in the new time point. We\ntest LinGuinE on a dataset acquired from a phase 3 clinical trial for lung\ntumours and the publicly available 4-D lung CBCT dataset. We find that LinGuinE\nimproves the Dice on both test sets by over 20% (p< 0.05) across 63\nlongitudinal studies. We show that any time point can be used as a starting\npoint, conduct ablation experiments, and find that our LinGuinE setup yields\nthe best results on both test datasets.", "comment": "10 pages, 3 figures", "cate": "eess.IV", "url": "http://arxiv.org/pdf/2506.06092v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05947", "title": "IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems", "authors": ["Xinjie Zhang", "Wenxuan Wang", "Qin Jin"], "summary": "In emotional support conversations, unclear intentions can lead supporters to\nemploy inappropriate strategies, inadvertently imposing their expectations or\nsolutions on the seeker. Clearly defined intentions are essential for guiding\nboth the supporter's motivations and the overall emotional support process. In\nthis paper, we propose the Intention-centered Emotional Support Conversation\n(IntentionESC) framework, which defines the possible intentions of supporters\nin emotional support conversations, identifies key emotional state aspects for\ninferring these intentions, and maps them to appropriate support strategies.\nWhile Large Language Models (LLMs) excel in text generating, they fundamentally\noperate as probabilistic models trained on extensive datasets, lacking a true\nunderstanding of human thought processes and intentions. To address this\nlimitation, we introduce the Intention Centric Chain-of-Thought (ICECoT)\nmechanism. ICECoT enables LLMs to mimic human reasoning by analyzing emotional\nstates, inferring intentions, and selecting suitable support strategies,\nthereby generating more effective emotional support responses. To train the\nmodel with ICECoT and integrate expert knowledge, we design an automated\nannotation pipeline that produces high-quality training data. Furthermore, we\ndevelop a comprehensive evaluation scheme to assess emotional support efficacy\nand conduct extensive experiments to validate our framework. Our data and code\nare available at https://github.com/43zxj/IntentionESC_ICECoT.", "comment": "ACL2025 findings", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05947v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06099", "title": "DermaCon-IN: A Multi-concept Annotated Dermatological Image Dataset of Indian Skin Disorders for Clinical AI Research", "authors": ["Shanawaj S Madarkar", "Mahajabeen Madarkar", "Madhumitha V", "Teli Prakash", "Konda Reddy Mopuri", "Vinaykumar MV", "KVL Sathwika", "Adarsh Kasturi", "Gandla Dilip Raj", "PVN Supranitha", "Harsh Udai"], "summary": "Artificial intelligence is poised to augment dermatological care by enabling\nscalable image-based diagnostics. Yet, the development of robust and equitable\nmodels remains hindered by datasets that fail to capture the clinical and\ndemographic complexity of real-world practice. This complexity stems from\nregion-specific disease distributions, wide variation in skin tones, and the\nunderrepresentation of outpatient scenarios from non-Western populations. We\nintroduce DermaCon-IN, a prospectively curated dermatology dataset comprising\nover 5,450 clinical images from approximately 3,000 patients across outpatient\nclinics in South India. Each image is annotated by board-certified\ndermatologists with over 240 distinct diagnoses, structured under a\nhierarchical, etiology-based taxonomy adapted from Rook's classification. The\ndataset captures a wide spectrum of dermatologic conditions and tonal variation\ncommonly seen in Indian outpatient care. We benchmark a range of architectures\nincluding convolutional models (ResNet, DenseNet, EfficientNet),\ntransformer-based models (ViT, MaxViT, Swin), and Concept Bottleneck Models to\nestablish baseline performance and explore how anatomical and concept-level\ncues may be integrated. These results are intended to guide future efforts\ntoward interpretable and clinically realistic models. DermaCon-IN provides a\nscalable and representative foundation for advancing dermatology AI in\nreal-world settings.", "comment": null, "cate": "eess.IV", "url": "http://arxiv.org/pdf/2506.06099v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06104", "title": "WoundAIssist: A Patient-Centered Mobile App for AI-Assisted Wound Care With Physicians in the Loop", "authors": ["Vanessa Borst", "Anna Riedmann", "Tassilo Dege", "Konstantin Müller", "Astrid Schmieder", "Birgit Lugrin", "Samuel Kounev"], "summary": "The rising prevalence of chronic wounds, especially in aging populations,\npresents a significant healthcare challenge due to prolonged hospitalizations,\nelevated costs, and reduced patient quality of life. Traditional wound care is\nresource-intensive, requiring frequent in-person visits that strain both\npatients and healthcare professionals (HCPs). Therefore, we present\nWoundAIssist, a patient-centered, AI-driven mobile application designed to\nsupport telemedical wound care. WoundAIssist enables patients to regularly\ndocument wounds at home via photographs and questionnaires, while physicians\nremain actively engaged in the care process through remote monitoring and video\nconsultations. A distinguishing feature is an integrated lightweight deep\nlearning model for on-device wound segmentation, which, combined with\npatient-reported data, enables continuous monitoring of wound healing\nprogression. Developed through an iterative, user-centered process involving\nboth patients and domain experts, WoundAIssist prioritizes an user-friendly\ndesign, particularly for elderly patients. A conclusive usability study with\npatients and dermatologists reported excellent usability, good app quality, and\nfavorable perceptions of the AI-driven wound recognition. Our main contribution\nis two-fold: (I) the implementation and (II) evaluation of WoundAIssist, an\neasy-to-use yet comprehensive telehealth solution designed to bridge the gap\nbetween patients and HCPs. Additionally, we synthesize design insights for\nremote patient monitoring apps, derived from over three years of\ninterdisciplinary research, that may inform the development of similar digital\nhealth tools across clinical domains.", "comment": "Submitted to ACM Health (Special Issue)", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06104v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05970", "title": "Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models", "authors": ["Kazutoshi Shinoda", "Nobukatsu Hojo", "Kyosuke Nishida", "Yoshihiro Yamazaki", "Keita Suzuki", "Hiroaki Sugiyama", "Kuniko Saito"], "summary": "Recent studies have shown that Theory of Mind (ToM) in large language models\n(LLMs) has not reached human-level performance yet. Since fine-tuning LLMs on\nToM datasets often degrades their generalization, several inference-time\nmethods have been proposed to enhance ToM in LLMs. However, existing\ninference-time methods for ToM are specialized for inferring beliefs from\ncontexts involving changes in the world state. In this study, we present a new\ninference-time method for ToM, Shoes-of-Others (SoO) prefixing, which makes\nfewer assumptions about contexts and is applicable to broader scenarios. SoO\nprefixing simply specifies the beginning of LLM outputs with ``Let's put\nourselves in A's shoes.'', where A denotes the target character's name. We\nevaluate SoO prefixing on two benchmarks that assess ToM in conversational and\nnarrative contexts without changes in the world state and find that it\nconsistently improves ToM across five categories of mental states. Our analysis\nsuggests that SoO prefixing elicits faithful thoughts, thereby improving the\nToM performance.", "comment": "14pages, 12 figures", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05970v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06211", "title": "PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts", "authors": ["Hengzhi Li", "Brendon Jiang", "Alexander Naehu", "Regan Song", "Justin Zhang", "Megan Tjandrasuwita", "Chanakya Ekbote", "Steven-Shine Chen", "Adithya Balachandran", "Wei Dai", "Rebecca Chang", "Paul Pu Liang"], "summary": "Puzzlehunts are a genre of complex, multi-step puzzles lacking well-defined\nproblem definitions. In contrast to conventional reasoning benchmarks\nconsisting of tasks with clear instructions, puzzlehunts require models to\ndiscover the underlying problem structure from multimodal evidence and\niterative reasoning, mirroring real-world domains such as scientific discovery,\nexploratory data analysis, or investigative problem-solving. Despite recent\nprogress in foundation models, their performance on such open-ended settings\nremains largely untested. In this paper, we introduce PuzzleWorld, a\nlarge-scale benchmark of 667 puzzlehunt-style problems designed to assess\nstep-by-step, open-ended, and creative multimodal reasoning. Each puzzle is\nannotated with the final solution, detailed reasoning traces, and cognitive\nskill labels, enabling holistic benchmarking and fine-grained diagnostic\nanalysis. Most state-of-the-art models achieve only 1-2% final answer accuracy,\nwith the best model solving only 14% of puzzles and reaching 40% stepwise\naccuracy. To demonstrate the value of our reasoning annotations, we show that\nfine-tuning a small model on reasoning traces improves stepwise reasoning from\n4% to 11%, while training on final answers alone degrades performance to near\nzero. Our error analysis reveals that current models exhibit myopic reasoning,\nare bottlenecked by the limitations of language-based inference, and lack\nsketching capabilities crucial for visual and spatial reasoning. We release\nPuzzleWorld at https://github.com/MIT-MI/PuzzleWorld to support future work on\nbuilding more general, open-ended, and creative reasoning systems.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06211v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05984", "title": "Audio-Aware Large Language Models as Judges for Speaking Styles", "authors": ["Cheng-Han Chiang", "Xiaofei Wang", "Chung-Ching Lin", "Kevin Lin", "Linjie Li", "Radu Kopetz", "Yao Qian", "Zhendong Wang", "Zhengyuan Yang", "Hung-yi Lee", "Lijuan Wang"], "summary": "Audio-aware large language models (ALLMs) can understand the textual and\nnon-textual information in the audio input. In this paper, we explore using\nALLMs as an automatic judge to assess the speaking styles of speeches. We use\nALLM judges to evaluate the speeches generated by SLMs on two tasks: voice\nstyle instruction following and role-playing. The speaking style we consider\nincludes emotion, volume, speaking pace, word emphasis, pitch control, and\nnon-verbal elements. We use four spoken language models (SLMs) to complete the\ntwo tasks and use humans and ALLMs to judge the SLMs' responses. We compare two\nALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and\nshow that the agreement between Gemini and human judges is comparable to the\nagreement between human evaluators. These promising results show that ALLMs can\nbe used as a judge to evaluate SLMs. Our results also reveal that current SLMs,\neven GPT-4o-audio, still have room for improvement in controlling the speaking\nstyle and generating natural dialogues.", "comment": null, "cate": "eess.AS", "url": "http://arxiv.org/pdf/2506.05984v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06008", "title": "Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models", "authors": ["Peijie Liu", "Fengli Xu", "Yong Li"], "summary": "Chain-of-Thought (CoT) technique has proven effective in improving the\nperformance of large language models (LLMs) on complex reasoning tasks.\nHowever, the performance gains are inconsistent across different tasks, and the\nunderlying mechanism remains a long-standing research question. In this work,\nwe make a preliminary observation that the monotonicity of token probability\ndistributions may be correlated with the gains achieved through CoT reasoning.\nLeveraging this insight, we propose two indicators based on the token\nprobability distribution to assess CoT effectiveness across different tasks. By\ncombining instance-level indicators with logistic regression model, we\nintroduce Dynamic CoT, a method that dynamically select between CoT and direct\nanswer. Furthermore, we extend Dynamic CoT to closed-source models by\ntransferring decision strategies learned from open-source models. Our\nindicators for assessing CoT effectiveness achieve an accuracy of 89.2\\%, and\nDynamic CoT reduces token consumption by more than 35\\% while maintaining high\naccuracy. Overall, our work offers a novel perspective on the underlying\nmechanisms of CoT reasoning and provides a framework for its more efficient\ndeployment.", "comment": "20 pages, 6 figures, 13 tables(Accept by ICML2025)", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06008v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06009", "title": "Unlocking Recursive Thinking of LLMs: Alignment via Refinement", "authors": ["Haoke Zhang", "Xiaobo Liang", "Cunxiang Wang", "Juntao Li", "Min Zhang"], "summary": "The OpenAI o1-series models have demonstrated that leveraging long-form Chain\nof Thought (CoT) can substantially enhance performance. However, the recursive\nthinking capabilities of Large Language Models (LLMs) remain limited,\nparticularly in the absence of expert-curated data for distillation. In this\npaper, we propose \\textbf{AvR}: \\textbf{Alignment via Refinement}, a novel\nmethod aimed at unlocking the potential of LLMs for recursive reasoning through\nlong-form CoT. AvR introduces a refinement process that integrates criticism\nand improvement actions, guided by differentiable learning techniques to\noptimize \\textbf{refinement-aware rewards}. As a result, the synthesized\nmulti-round data can be organized as a long refinement thought, further\nenabling test-time scaling. Experimental results show that AvR significantly\noutperforms conventional preference optimization methods. Notably, with only 3k\nsynthetic samples, our method boosts the performance of the LLaMA-3-8B-Instruct\nmodel by over 20\\% in win rate on AlpacaEval 2.0. Our code is available at\nGithub (https://github.com/Banner-Z/AvR.git).", "comment": "Accepted to the Findings of ACL 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06009v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06020", "title": "When to Trust Context: Self-Reflective Debates for Context Reliability", "authors": ["Zeqi Zhou", "Fang Wu", "Shayan Talaei", "Haokai Zhao", "Cheng Meixin", "Tinson Xu", "Amin Saberi", "Yejin Choi"], "summary": "Large language models frequently encounter conflicts between their parametric\nknowledge and contextual input, often resulting in factual inconsistencies or\nhallucinations. We propose Self-Reflective Debate for Contextual Reliability\n(SR-DCR), a lightweight framework that integrates token-level self-confidence\nwith an asymmetric multi-agent debate to adjudicate such conflicts. A critic,\ndeprived of context, challenges a defender who argues from the given passage; a\njudge model evaluates the debate and determines the context's reliability. The\nfinal answer is selected by combining the verdict with model confidence.\nExperiments on the ClashEval benchmark demonstrate that SR-DCR consistently\nenhances robustness to misleading context while maintaining accuracy on\ntrustworthy inputs, outperforming both classical debate and confidence-only\nbaselines with minimal computational overhead. The code is available at\nhttps://github.com/smiles724/Self-Reflective-Debates.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06020v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05589", "title": "UTSA-NLP at ArchEHR-QA 2025: Improving EHR Question Answering via Self-Consistency Prompting", "authors": ["Sara Shields-Menard", "Zach Reimers", "Joshua Gardner", "David Perry", "Anthony Rios"], "summary": "We describe our system for the ArchEHR-QA Shared Task on answering clinical\nquestions using electronic health records (EHRs). Our approach uses large\nlanguage models in two steps: first, to find sentences in the EHR relevant to a\nclinician's question, and second, to generate a short, citation-supported\nresponse based on those sentences. We use few-shot prompting, self-consistency,\nand thresholding to improve the sentence classification step to decide which\nsentences are essential. We compare several models and find that a smaller 8B\nmodel performs better than a larger 70B model for identifying relevant\ninformation. Our results show that accurate sentence selection is critical for\ngenerating high-quality responses and that self-consistency with thresholding\nhelps make these decisions more reliable.", "comment": "Accepted to BioNLP 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05589v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06057", "title": "Hey, That's My Data! Label-Only Dataset Inference in Large Language Models", "authors": ["Chen Xiong", "Zihao Wang", "Rui Zhu", "Tsung-Yi Ho", "Pin-Yu Chen", "Jingwei Xiong", "Haixu Tang", "Lucila Ohno-Machado"], "summary": "Large Language Models (LLMs) have revolutionized Natural Language Processing\nby excelling at interpreting, reasoning about, and generating human language.\nHowever, their reliance on large-scale, often proprietary datasets poses a\ncritical challenge: unauthorized usage of such data can lead to copyright\ninfringement and significant financial harm. Existing dataset-inference methods\ntypically depend on log probabilities to detect suspicious training material,\nyet many leading LLMs have begun withholding or obfuscating these signals. This\nreality underscores the pressing need for label-only approaches capable of\nidentifying dataset membership without relying on internal model logits.\n  We address this gap by introducing CatShift, a label-only dataset-inference\nframework that capitalizes on catastrophic forgetting: the tendency of an LLM\nto overwrite previously learned knowledge when exposed to new data. If a\nsuspicious dataset was previously seen by the model, fine-tuning on a portion\nof it triggers a pronounced post-tuning shift in the model's outputs;\nconversely, truly novel data elicits more modest changes. By comparing the\nmodel's output shifts for a suspicious dataset against those for a known\nnon-member validation set, we statistically determine whether the suspicious\nset is likely to have been part of the model's original training corpus.\nExtensive experiments on both open-source and API-based LLMs validate\nCatShift's effectiveness in logit-inaccessible settings, offering a robust and\npractical solution for safeguarding proprietary data.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06057v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06058", "title": "Microgrids Coalitions for Energy Market Balancing", "authors": ["Viorica Chifu", "Cristina Bianca Pop", "Tudor Cioara", "Ionut Anghel"], "summary": "With the integration of renewable sources in electricity distribution\nnetworks, the need to develop intelligent mechanisms for balancing the energy\nmarket has arisen. In the absence of such mechanisms, the energy market may\nface imbalances that can lead to power outages, financial losses or instability\nat the grid level. In this context, the grouping of microgrids into optimal\ncoalitions that can absorb energy from the market during periods of surplus or\nsupply energy to the market during periods of is a key aspect in the efficient\nmanagement of distribution networks. In this article, we propose a method that\nidentify an optimal microgrids coalition capable of addressing the dynamics of\nthe energy market. The proposed method models the problem of identifying the\noptimal coalition as an optimization problem that it solves by combining a\nstrategy inspired by cooperative game theory with a memetic algorithm. An\nindividual is represented as a coalition of microgrids and the evolution of\npopulation of individuals over generations is assured by recombination and\nmutation. The fitness function is defined as the difference between the total\nvalue generated by the coalition and a penalty applied to the coalition when\nthe energy traded by coalition exceeds the energy available/demanded on/by the\nenergy market. The value generated by the coalition is calculated based on the\nprofit obtained by the collation if it sells energy on the market during\nperiods of deficit or the savings obtained by the coalition if it buys energy\non the market during periods of surplus and the costs associated with the\ntrading process. This value is divided equitably among the coalition members,\naccording to the Shapley value, which considers the contribution of each one to\nthe formation of collective value.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.06058v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06060", "title": "Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models", "authors": ["Yingqi Hu", "Zhuo Zhang", "Jingyuan Zhang", "Lizhen Qu", "Zenglin Xu"], "summary": "Federated fine-tuning of large language models (FedLLMs) presents a promising\napproach for achieving strong model performance while preserving data privacy\nin sensitive domains. However, the inherent memorization ability of LLMs makes\nthem vulnerable to training data extraction attacks. To investigate this risk,\nwe introduce simple yet effective extraction attack algorithms specifically\ndesigned for FedLLMs. In contrast to prior \"verbatim\" extraction attacks, which\nassume access to fragments from all training data, our approach operates under\na more realistic threat model, where the attacker only has access to a single\nclient's data and aims to extract previously unseen personally identifiable\ninformation (PII) from other clients. This requires leveraging contextual\nprefixes held by the attacker to generalize across clients. To evaluate the\neffectiveness of our approaches, we propose two rigorous metrics-coverage rate\nand efficiency-and extend a real-world legal dataset with PII annotations\naligned with CPIS, GDPR, and CCPA standards, achieving 89.9% human-verified\nprecision. Experimental results show that our method can extract up to 56.57%\nof victim-exclusive PII, with \"Address,\" \"Birthday,\" and \"Name\" being the most\nvulnerable categories. Our findings underscore the pressing need for robust\ndefense strategies and contribute a new benchmark and evaluation framework for\nfuture research in privacy-preserving federated learning.", "comment": "10 pages, 4 figures", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06060v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05544", "title": "Online Conformal Model Selection for Nonstationary Time Series", "authors": ["Shibo Li", "Yao Zheng"], "summary": "This paper introduces the MPS (Model Prediction Set), a novel framework for\nonline model selection for nonstationary time series. Classical model selection\nmethods, such as information criteria and cross-validation, rely heavily on the\nstationarity assumption and often fail in dynamic environments which undergo\ngradual or abrupt changes over time. Yet real-world data are rarely stationary,\nand model selection under nonstationarity remains a largely open problem. To\ntackle this challenge, we combine conformal inference with model confidence\nsets to develop a procedure that adaptively selects models best suited to the\nevolving dynamics at any given time. Concretely, the MPS updates in real time a\nconfidence set of candidate models that covers the best model for the next time\nperiod with a specified long-run probability, while adapting to nonstationarity\nof unknown forms. Through simulations and real-world data analysis, we\ndemonstrate that MPS reliably and efficiently identifies optimal models under\nnonstationarity, an essential capability lacking in offline methods. Moreover,\nMPS frequently produces high-quality sets with small cardinality, whose\nevolution offers deeper insights into changing dynamics. As a generic\nframework, MPS accommodates any data-generating process, data structure, model\nclass, training method, and evaluation metric, making it broadly applicable\nacross diverse problem settings.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/pdf/2506.05544v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05604", "title": "Why is My Route Different Today? An Algorithm for Explaining Route Selection", "authors": ["Aaron Schild", "Sreenivas Gollapudi", "Anupam Gupta", "Kostas Kollias", "Ali Sinop"], "summary": "Users of routing services like Apple Maps, Google Maps, and Waze frequently\nwonder why a given route is proposed. This question particularly arises when\ndynamic conditions like traffic and road closures cause unusual routes to be\nproposed. While many dynamic conditions may exist in a road network at any\ntime, only a small fraction of those conditions are typically relevant to a\ngiven user's route. In this work, we introduce the concept of a simple valid\nexplanation (SVE), which consists of a small set of traffic-laden road segments\nthat answer the following question: Which traffic conditions cause a particular\nshortest traffic-aware route to differ from the shortest traffic-free route? We\ngive an efficient algorithm for finding SVEs and show that they theoretically\nand experimentally lead to small and interpretable answers to the question.", "comment": "To appear in the SIAM Conference on Applied and Computational\n  Discrete Algorithms (ACDA) 2025. Code and data for the experiments can be\n  found here:\n  https://github.com/google-research/google-research/blob/master/explainable_routing", "cate": "cs.DS", "url": "http://arxiv.org/pdf/2506.05604v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05556", "title": "DART-Vetter: A Deep LeARning Tool for automatic triage of exoplanet candidates", "authors": ["Stefano Fiscale", "Laura Inno", "Alessandra Rotundi", "Angelo Ciaramella", "Alessio Ferone", "Christian Magliano", "Luca Cacciapuoti", "Veselin Kostov", "Elisa Quintana", "Giovanni Covone", "Maria Teresa Muscari Tomajoli", "Vito Saggese", "Luca Tonietti", "Antonio Vanzanella", "Vincenzo Della Corte"], "summary": "In the identification of new planetary candidates in transit surveys, the\nemployment of Deep Learning models proved to be essential to efficiently\nanalyse a continuously growing volume of photometric observations. To further\nimprove the robustness of these models, it is necessary to exploit the\ncomplementarity of data collected from different transit surveys such as NASA's\nKepler, Transiting Exoplanet Survey Satellite (TESS), and, in the near future,\nthe ESA PLAnetary Transits and Oscillation of stars (PLATO) mission. In this\nwork, we present a Deep Learning model, named DART-Vetter, able to distinguish\nplanetary candidates (PC) from false positives signals (NPC) detected by any\npotential transiting survey. DART-Vetter is a Convolutional Neural Network that\nprocesses only the light curves folded on the period of the relative signal,\nfeaturing a simpler and more compact architecture with respect to other\ntriaging and/or vetting models available in the literature. We trained and\ntested DART-Vetter on several dataset of publicly available and homogeneously\nlabelled TESS and Kepler light curves in order to prove the effectiveness of\nour model. Despite its simplicity, DART-Vetter achieves highly competitive\ntriaging performance, with a recall rate of 91% on an ensemble of TESS and\nKepler data, when compared to Exominer and Astronet-Triage. Its compact, open\nsource and easy to replicate architecture makes DART-Vetter a particularly\nuseful tool for automatizing triaging procedures or assisting human vetters,\nshowing a discrete generalization on TCEs with Multiple Event Statistic (MES) >\n20 and orbital period < 50 days.", "comment": "Number of pages: 24, Number of figures: 8, Article accepted for\n  publication in The Astronomical Journal on 2025-05-30", "cate": "astro-ph.EP", "url": "http://arxiv.org/pdf/2506.05556v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06117", "title": "Phonetically-Augmented Discriminative Rescoring for Voice Search Error Correction", "authors": ["Christophe Van Gysel", "Maggie Wu", "Lyan Verwimp", "Caglar Tirkaz", "Marco Bertola", "Zhihong Lei", "Youssef Oualil"], "summary": "End-to-end (E2E) Automatic Speech Recognition (ASR) models are trained using\npaired audio-text samples that are expensive to obtain, since high-quality\nground-truth data requires human annotators. Voice search applications, such as\ndigital media players, leverage ASR to allow users to search by voice as\nopposed to an on-screen keyboard. However, recent or infrequent movie titles\nmay not be sufficiently represented in the E2E ASR system's training data, and\nhence, may suffer poor recognition.\n  In this paper, we propose a phonetic correction system that consists of (a) a\nphonetic search based on the ASR model's output that generates phonetic\nalternatives that may not be considered by the E2E system, and (b) a rescorer\ncomponent that combines the ASR model recognition and the phonetic\nalternatives, and select a final system output.\n  We find that our approach improves word error rate between 4.4 and 7.6%\nrelative on benchmarks of popular movie titles over a series of competitive\nbaselines.", "comment": "To appear at Interspeech '25", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06117v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05606", "title": "OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation", "authors": ["Ziyi Wang", "Yuxuan Lu", "Wenbo Li", "Amirali Amini", "Bo Sun", "Yakov Bart", "Weimin Lyu", "Jiri Gesi", "Tian Wang", "Jing Huang", "Yu Su", "Upol Ehsan", "Malihe Alikhani", "Toby Jia-Jun Li", "Lydia Chilton", "Dakuo Wang"], "summary": "Can large language models (LLMs) accurately simulate the next web action of a\nspecific user? While LLMs have shown promising capabilities in generating\n``believable'' human behaviors, evaluating their ability to mimic real user\nbehaviors remains an open challenge, largely due to the lack of high-quality,\npublicly available datasets that capture both the observable actions and the\ninternal reasoning of an actual human user. To address this gap, we introduce\nOPERA, a novel dataset of Observation, Persona, Rationale, and Action collected\nfrom real human participants during online shopping sessions. OPERA is the\nfirst public dataset that comprehensively captures: user personas, browser\nobservations, fine-grained web actions, and self-reported just-in-time\nrationales. We developed both an online questionnaire and a custom browser\nplugin to gather this dataset with high fidelity. Using OPERA, we establish the\nfirst benchmark to evaluate how well current LLMs can predict a specific user's\nnext action and rationale with a given persona and <observation, action,\nrationale> history. This dataset lays the groundwork for future research into\nLLM agents that aim to act as personalized digital twins for human.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05606v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05567", "title": "Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming", "authors": ["Fuat Can Beylunioglu", "Mehrdad Pirnia", "P. Robert Duimering"], "summary": "Neural Networks (NN) with ReLU activation functions are used to model\nmultiparametric quadratic optimization problems (mp-QP) in diverse engineering\napplications. Researchers have suggested leveraging the piecewise affine\nproperty of deep NN models to solve mp-QP with linear constraints, which also\nexhibit piecewise affine behaviour. However, traditional deep NN applications\nto mp-QP fall short of providing optimal and feasible predictions, even when\ntrained on large datasets. This study proposes a partially-supervised NN (PSNN)\narchitecture that directly represents the mathematical structure of the global\nsolution function. In contrast to generic NN training approaches, the proposed\nPSNN method derives a large proportion of model weights directly from the\nmathematical properties of the optimization problem, producing more accurate\nsolutions despite significantly smaller training data sets. Many energy\nmanagement problems are formulated as QP, so we apply the proposed approach to\nenergy systems (specifically DC optimal power flow) to demonstrate proof of\nconcept. Model performance in terms of solution accuracy and speed of\npredictions was compared against a commercial solver and a generic Deep NN\nmodel based on classical training. Results show KKT sufficient conditions for\nPSNN consistently outperform generic NN architectures with classical training\nusing far less data, including when tested on extreme, out-of-training\ndistribution test data. Given its speed advantages over traditional solvers,\nthe PSNN model can quickly produce optimal and feasible solutions within a\nsecond for millions of input parameters sampled from a distribution of\nstochastic demands and renewable generator dispatches, which can be used for\nsimulations and long term planning.", "comment": "36 pages including references and appendix", "cate": "math.OC", "url": "http://arxiv.org/pdf/2506.05567v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05610", "title": "Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking", "authors": ["Zhecheng Sheng", "Xiruo Ding", "Brian Hur", "Changye Li", "Trevor Cohen", "Serguei Pakhomov"], "summary": "Deep transformer models have been used to detect linguistic anomalies in\npatient transcripts for early Alzheimer's disease (AD) screening. While\npre-trained neural language models (LMs) fine-tuned on AD transcripts perform\nwell, little research has explored the effects of the gender of the speakers\nrepresented by these transcripts. This work addresses gender confounding in\ndementia detection and proposes two methods: the $\\textit{Extended Confounding\nFilter}$ and the $\\textit{Dual Filter}$, which isolate and ablate weights\nassociated with gender. We evaluate these methods on dementia datasets with\nfirst-person narratives from patients with cognitive impairment and healthy\ncontrols. Our results show transformer models tend to overfit to training data\ndistributions. Disrupting gender-related weights results in a deconfounded\ndementia classifier, with the trade-off of slightly reduced dementia detection\nperformance.", "comment": "16 pages, 20 figures. Accepted to ACL 2025 Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05610v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06165", "title": "(AI peers) are people learning from the same standpoint: Perception of AI characters in a Collaborative Science Investigation", "authors": ["Eunhye Grace Ko", "Soo Hyoung Joo"], "summary": "While the complexity of 21st-century demands has promoted pedagogical\napproaches to foster complex competencies, a persistent gap remains between\nin-class learning activities and individualized learning or assessment\npractices. To address this, studies have explored the use of AI-generated\ncharacters in learning and assessment. One attempt is scenario-based assessment\n(SBA), a technique that not only measures but also fosters the development of\ncompetencies throughout the assessment process. SBA introduces simulated agents\nto provide an authentic social-interactional context, allowing for the\nassessment of competency-based constructs while mitigating the unpredictability\nof real-life interactions. Recent advancements in multimodal AI, such as\ntext-to-video technology, allow these agents to be enhanced into AI-generated\ncharacters. This mixed-method study investigates how learners perceive AI\ncharacters taking the role of mentor and teammates in an SBA mirroring the\ncontext of a collaborative science investigation. Specifically, we examined the\nLikert scale responses of 56 high schoolers regarding trust, social presence,\nand effectiveness. We analyzed the relationships between these factors and\ntheir impact on the intention to adopt AI characters through PLS-SEM. Our\nfindings indicated that learners' trust shaped their sense of social presence\nwith the AI characters, enhancing perceived effectiveness. Qualitative analysis\nfurther highlighted factors that foster trust, such as material credibility and\nalignment with learning goals, as well as the pivotal role of social presence\nin creating a collaborative context.\n  This paper was accepted as an full paper for AIED 2025.", "comment": "14 pages", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06165v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05590", "title": "Nonlinear Causal Discovery through a Sequential Edge Orientation Approach", "authors": ["Stella Huang", "Qing Zhou"], "summary": "Recent advances have established the identifiability of a directed acyclic\ngraph (DAG) under additive noise models (ANMs), spurring the development of\nvarious causal discovery methods. However, most existing methods make\nrestrictive model assumptions, rely heavily on general independence tests, or\nrequire substantial computational time. To address these limitations, we\npropose a sequential procedure to orient undirected edges in a completed\npartial DAG (CPDAG), representing an equivalence class of DAGs, by leveraging\nthe pairwise additive noise model (PANM) to identify their causal directions.\nWe prove that this procedure can recover the true causal DAG assuming a\nrestricted ANM. Building on this result, we develop a novel constraint-based\nalgorithm for learning causal DAGs under nonlinear ANMs. Given an estimated\nCPDAG, we develop a ranking procedure that sorts undirected edges by their\nadherence to the PANM, which defines an evaluation order of the edges. To\ndetermine the edge direction, we devise a statistical test that compares the\nlog-likelihood values, evaluated with respect to the competing directions, of a\nsub-graph comprising just the candidate nodes and their identified parents in\nthe partial DAG. We further establish the structural learning consistency of\nour algorithm in the large-sample limit. Extensive experiments on synthetic and\nreal-world datasets demonstrate that our method is computationally efficient,\nrobust to model misspecification, and consistently outperforms many existing\nnonlinear DAG learning methods.", "comment": "42 Pages, 13 figures, 3 tables", "cate": "stat.ML", "url": "http://arxiv.org/pdf/2506.05590v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05613", "title": "Beating the Logarithmic Barrier for the Subadditive Maximin Share Problem", "authors": ["Masoud Seddighin", "Saeed Seddighin"], "summary": "We study the problem of fair allocation of indivisible goods for subadditive\nagents. While constant-\\textsf{MMS} bounds have been given for additive and\nfractionally subadditive agents, the best existential bound for the case of\nsubadditive agents is $1/O(\\log n \\log \\log n)$. In this work, we improve this\nbound to a $1/O((\\log \\log n)^2)$-\\textsf{MMS} guarantee. To this end, we\nintroduce new matching techniques and rounding methods for subadditive\nvaluations that we believe are of independent interest and will find their\napplications in future work.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.05613v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06169", "title": "semantic-features: A User-Friendly Tool for Studying Contextual Word Embeddings in Interpretable Semantic Spaces", "authors": ["Jwalanthi Ranganathan", "Rohan Jha", "Kanishka Misra", "Kyle Mahowald"], "summary": "We introduce semantic-features, an extensible, easy-to-use library based on\nChronis et al. (2023) for studying contextualized word embeddings of LMs by\nprojecting them into interpretable spaces. We apply this tool in an experiment\nwhere we measure the contextual effect of the choice of dative construction\n(prepositional or double object) on the semantic interpretation of utterances\n(Bresnan, 2007). Specifically, we test whether \"London\" in \"I sent London the\nletter.\" is more likely to be interpreted as an animate referent (e.g., as the\nname of a person) than in \"I sent the letter to London.\" To this end, we devise\na dataset of 450 sentence pairs, one in each dative construction, with\nrecipients being ambiguous with respect to person-hood vs. place-hood. By\napplying semantic-features, we show that the contextualized word embeddings of\nthree masked language models show the expected sensitivities. This leaves us\noptimistic about the usefulness of our tool.", "comment": "SCiL 2025 Camera Ready Extended Abstract", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06169v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05625", "title": "Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning", "authors": ["Anushka Tiwari", "Haimonti Dutta", "Shahrzad Khanizadeh"], "summary": "Graph-based recommendation systems use higher-order user and item embeddings\nfor next-item predictions. Dynamically adding collaborative signals from\nneighbors helps to use similar users' preferences during learning. While\nitem-item correlations and their impact on recommendations have been studied,\nthe efficacy of temporal item sequences for recommendations is much less\nexplored. In this paper, we examine temporal item sequence (sequel-aware)\nembeddings along with higher-order user embeddings and show that sequel-aware\nGraph Neural Networks have better (or comparable) recommendation performance\nthan graph-based recommendation systems that do not consider sequel\ninformation. Extensive empirical results comparing Heterogeneous Sequel-aware\nGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning\n(such as transformers, graph neural networks, auto-encoders) are presented on\nthree synthetic and three real-world datasets. Our results indicate that the\nincorporation of sequence information from items greatly enhances\nrecommendations.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.05625v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05631", "title": "The TESS Ten Thousand Catalog: 10,001 uniformly-vetted and -validated Eclipsing Binary Stars detected in Full-Frame Image data by machine learning and analyzed by citizen scientists", "authors": ["Veselin B. Kostov", "Brian P. Powell", "Aline U. Fornear", "Marco Z. Di Fraia", "Robert Gagliano", "Thomas L. Jacobs", "Julien S. de Lambilly", "Hugo A. Durantini Luca", "Steven R. Majewski", "Mark Omohundro", "Jerome Orosz", "Saul A. Rappaport", "Ryan Salik", "Donald Short", "William Welsh", "Svetoslav Alexandrov", "Cledison Marcos da Silva", "Erika Dunning", "Gerd Guhne", "Marc Huten", "Michiharu Hyogo", "Davide Iannone", "Sam Lee", "Christian Magliano", "Manya Sharma", "Allan Tarr", "John Yablonsky", "Sovan Acharya", "Fred Adams", "Thomas Barclay", "Benjamin T. Montet", "Susan Mullally", "Greg Olmschenk", "Andrej Prsa", "Elisa Quintana", "Robert Wilson", "Hasret Balcioglu", "Ethan Kruse", "the Eclipsing Binary Patrol Collaboration"], "summary": "The Transiting Exoplanet Survey Satellite (TESS) has surveyed nearly the\nentire sky in Full-Frame Image mode with a time resolution of 200 seconds to 30\nminutes and a temporal baseline of at least 27 days. In addition to the primary\ngoal of discovering new exoplanets, TESS is exceptionally capable at detecting\nvariable stars, and in particular short-period eclipsing binaries which are\nrelatively common, making up a few percent of all stars, and represent powerful\nastrophysical laboratories for deep investigations of stellar formation and\nevolution. We combed Sectors 1-82 of TESS Full-Frame Image data searching for\neclipsing binary stars using a neural network that identified ~1.2 million\nstars with eclipse-like features. Of these, we have performed an in-depth\nanalysis on ~60,000 targets using automated methods and manual inspection by\ncitizen scientists. Here we present a catalog of 10001 uniformly-vetted and\n-validated eclipsing binary stars that passed all our ephemeris and photocenter\ntests, as well as complementary visual inspection. Of these, 7936 are new\neclipsing binaries while the remaining 2065 are known systems for which we\nupdate the published ephemerides. We outline the detection and analysis of the\ntargets, discuss the properties of the sample, and highlight potentially\ninteresting systems. Finally, we also provide a list of ~900,000 unvetted and\nunvalidated targets for which the neural network found eclipse-like features\nwith a score higher than 0.9, and for which there are no known eclipsing\nbinaries within a sky-projected separation of a TESS pixel (~21 arcsec).", "comment": "40 pages, 39 figures, 4 tables", "cate": "astro-ph.SR", "url": "http://arxiv.org/pdf/2506.05631v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05639", "title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition", "authors": ["John Kirchenbauer", "Janny Mongkolsupawan", "Yuxin Wen", "Tom Goldstein", "Daphne Ippolito"], "summary": "When language models are trained on textual data, they acquire both knowledge\nabout the structure of language as well as knowledge of facts about the world.\nAt inference time, their knowledge of facts can be leveraged to solve\ninteresting problems and perform useful knowledge work for users. It is well\nknown that language models can verbatim memorize long sequences from their\ntraining data. However, it is much less well understood how language models\nmemorize facts seen during training. In this work, we propose a new dataset to\nspecifically empower researchers to study the dual processes of fact\nmemorization and verbatim sequence memorization. The dataset consists of\nsynthetically-generated, webtext-like documents about fictional events, as well\nas question-answer pairs about the events. We conduct training experiments\nshowing how synthetic data about fictional events can be effective in teasing\napart different forms of memorization. We also document the challenges in\neffectively building realistic, fictional synthetic data.", "comment": "10 pages and 8 figures in the main body", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05639v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06208", "title": "Building Models of Neurological Language", "authors": ["Henry Watkins"], "summary": "This report documents the development and evaluation of domain-specific\nlanguage models for neurology. Initially focused on building a bespoke model,\nthe project adapted to rapid advances in open-source and commercial medical\nLLMs, shifting toward leveraging retrieval-augmented generation (RAG) and\nrepresentational models for secure, local deployment. Key contributions include\nthe creation of neurology-specific datasets (case reports, QA sets,\ntextbook-derived data), tools for multi-word expression extraction, and\ngraph-based analyses of medical terminology. The project also produced scripts\nand Docker containers for local hosting. Performance metrics and graph\ncommunity results are reported, with future possible work open for multimodal\nmodels using open-source architectures like phi-4.", "comment": "21 pages, 6 figures", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06208v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05657", "title": "Emulating compact binary population synthesis simulations with robust uncertainty quantification and model comparison: Bayesian normalizing flows", "authors": ["Anarya Ray"], "summary": "Population synthesis simulations of compact binary coalescences~(CBCs) play a\ncrucial role in extracting astrophysical insights from an ensemble of\ngravitational wave~(GW) observations. However, realistic simulations are costly\nto implement for a dense grid of initial conditions. Normalizing flows can\nemulate the distribution functions of a simulated population of binary\nparameters and thereby enable empirical constraints on the astrophysical\ninitial conditions and branching fractions of various formation channels given\ndata from a catalog of GW observations. They can also be used for data\namplification in sparse regions of the CBC parameter space to guide the\ndevelopment of phenomenological population models for rarely synthesizable\nsystems with components in theorized mass gaps, without having to simulate a\nprohibitively large number of binaries. But flow predictions are wrought with\nuncertainties, especially for sparse training sets. In this work I develop a\nmethod for quantifying and marginalizing uncertainties in the emulators by\nintroducing the Bayesian Normalizing flow, a conditional density estimator\nconstructed from Bayesian neural networks. Using the exact likelihood function\nassociated with density estimators I sample the posterior distribution of flow\nparameters with suitably chosen priors to quantify and marginalize over flow\nuncertainties. I demonstrate the accuracy, calibration, and data-amplification\nimpacts of the estimated uncertainties for simulations of binary black hole\npopulations formed through common envelope evolution. I outline applications of\nthe methodology in simulation-based inference from growing GW catalogs and\nsketch other uses for general simulation-based approaches in GW astronomy.", "comment": "16 pages, 4 figures", "cate": "astro-ph.HE", "url": "http://arxiv.org/pdf/2506.05657v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05688", "title": "Voice Impression Control in Zero-Shot TTS", "authors": ["Keinichi Fujita", "Shota Horiguchi", "Yusuke Ijima"], "summary": "Para-/non-linguistic information in speech is pivotal in shaping the\nlisteners' impression. Although zero-shot text-to-speech (TTS) has achieved\nhigh speaker fidelity, modulating subtle para-/non-linguistic information to\ncontrol perceived voice characteristics, i.e., impressions, remains\nchallenging. We have therefore developed a voice impression control method in\nzero-shot TTS that utilizes a low-dimensional vector to represent the\nintensities of various voice impression pairs (e.g., dark-bright). The results\nof both objective and subjective evaluations have demonstrated our method's\neffectiveness in impression control. Furthermore, generating this vector via a\nlarge language model enables target-impression generation from a natural\nlanguage description of the desired impression, thus eliminating the need for\nmanual optimization.", "comment": "5 pages,5 figures, Accepted to INTERSPEECH 2025", "cate": "cs.SD", "url": "http://arxiv.org/pdf/2506.05688v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06214", "title": "Can Theoretical Physics Research Benefit from Language Agents?", "authors": ["Sirui Lu", "Zhijing Jin", "Terry Jingchen Zhang", "Pavel Kos", "J. Ignacio Cirac", "Bernhard Schölkopf"], "summary": "Large Language Models (LLMs) are rapidly advancing across diverse domains,\nyet their application in theoretical physics research is not yet mature. This\nposition paper argues that LLM agents can potentially help accelerate\ntheoretical, computational, and applied physics when properly integrated with\ndomain knowledge and toolbox. We analyze current LLM capabilities for physics\n-- from mathematical reasoning to code generation -- identifying critical gaps\nin physical intuition, constraint satisfaction, and reliable reasoning. We\nenvision future physics-specialized LLMs that could handle multimodal data,\npropose testable hypotheses, and design experiments. Realizing this vision\nrequires addressing fundamental challenges: ensuring physical consistency, and\ndeveloping robust verification methods. We call for collaborative efforts\nbetween physics and AI communities to help advance scientific discovery in\nphysics.", "comment": "9 pages", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06214v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05695", "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "summary": "Knowledge Distillation (KD) compresses large language models (LLMs) by\ntransferring the teacher model's capabilities to a smaller student model,\nreducing inference cost and memory usage while maintaining performance.\nHowever, existing KD methods for LLMs often fail to prevent significant shifts\nin the student model's distribution during training, leading to issues such as\ncatastrophic forgetting, mode collapse, and training-inference mismatch. To\naddress these challenges, we propose a novel, plug-in curriculum learning\nframework inspired by the strength training principle of \"progressive overload\"\n(POCL), which can be seamlessly integrated into existing white-box KD\napproaches with minimal computational overhead. The framework comprises two\ncore components: (1) a difficulty measurer that ranks and partitions training\nsamples from easy to hard, and (2) a training scheduler that incrementally\nintroduces these subsets into the distillation process at fixed intervals while\napplying loss functions with progressively rising temperatures. By starting\nwith the easiest samples and progressively increasing the difficulty, the\napproach enhances both the stability and efficiency of learning. Extensive\nexperiments in instruction-following settings demonstrate that POCL\nconsistently improves the performance of distilled student models across\nvarious white-box KD methods and model families. Our findings highlight the\neffectiveness of sorted training samples in KD for LLMs. More generally, our\nwork demonstrates how to structure training data within the KD process to\nenhance the stability and performance of distilled LLMs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05695v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06225", "title": "\"We need to avail ourselves of GenAI to enhance knowledge distribution\": Empowering Older Adults through GenAI Literacy", "authors": ["Eunhye Grace Ko", "Shaini Nanayakkara", "Earl W. Huff Jr"], "summary": "As generative AI (GenAI) becomes increasingly widespread, it is crucial to\nequip users, particularly vulnerable populations such as older adults (65 and\nolder), with the knowledge to understand its benefits and potential risks.\nOlder adults often exhibit greater reservations about adopting emerging\ntechnologies and require tailored literacy support. Using a mixed methods\napproach, this study examines strategies for delivering GenAI literacy to older\nadults through a chatbot named Litti, evaluating its impact on their AI\nliteracy (knowledge, safety, and ethical use). The quantitative data indicated\na trend toward improved AI literacy, though the results were not statistically\nsignificant. However, qualitative interviews revealed diverse levels of\nfamiliarity with generative AI and a strong desire to learn more. Findings also\nshow that while Litti provided a positive learning experience, it did not\nsignificantly enhance participants' trust or sense of safety regarding GenAI.\nThis exploratory case study highlights the challenges and opportunities in\ndesigning AI literacy education for the rapidly growing older adult population.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06225v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05735", "title": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness", "authors": ["Rongzhe Wei", "Peizhi Niu", "Hans Hao-Hsun Hsu", "Ruihan Wu", "Haoteng Yin", "Mohsen Ghassemi", "Yifan Li", "Vamsi K. Potluru", "Eli Chien", "Kamalika Chaudhuri", "Olgica Milenkovic", "Pan Li"], "summary": "Machine unlearning techniques aim to mitigate unintended memorization in\nlarge language models (LLMs). However, existing approaches predominantly focus\non the explicit removal of isolated facts, often overlooking latent inferential\ndependencies and the non-deterministic nature of knowledge within LLMs.\nConsequently, facts presumed forgotten may persist implicitly through\ncorrelated information. To address these challenges, we propose a knowledge\nunlearning evaluation framework that more accurately captures the implicit\nstructure of real-world knowledge by representing relevant factual contexts as\nknowledge graphs with associated confidence scores. We further develop an\ninference-based evaluation protocol leveraging powerful LLMs as judges; these\njudges reason over the extracted knowledge subgraph to determine unlearning\nsuccess. Our LLM judges utilize carefully designed prompts and are calibrated\nagainst human evaluations to ensure their trustworthiness and stability.\nExtensive experiments on our newly constructed benchmark demonstrate that our\nframework provides a more realistic and rigorous assessment of unlearning\nperformance. Moreover, our findings reveal that current evaluation strategies\ntend to overestimate unlearning effectiveness. Our code is publicly available\nat https://github.com/Graph-COM/Knowledge_Unlearning.git.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05735v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05629", "title": "Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs", "authors": ["Ananth Muppidi", "Abhilash Nandy", "Sambaran Bandyopadhyay"], "summary": "The performance of large language models in domain-specific tasks\nnecessitates fine-tuning, which is computationally expensive and technically\nchallenging. This paper focuses on parameter-efficient fine-tuning using soft\nprompting, a promising approach that adapts pre-trained models to downstream\ntasks by learning a small set of parameters. We propose a novel Input Dependent\nSoft Prompting technique with a self-Attention Mechanism (ID-SPAM) that\ngenerates soft prompts based on the input tokens and attends different tokens\nwith varying importance. Our method is simple and efficient, keeping the number\nof trainable parameters small. We show the merits of the proposed approach\ncompared to state-of-the-art techniques on various tasks and show the improved\nzero shot domain transfer capability.", "comment": "Accepted in ACL 2025 (Main) Conference", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05629v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05758", "title": "Mapping correlations and coherence: adjacency-based approach to data visualization and regularity discovery", "authors": ["Guang-Xing Li"], "summary": "The development of science has been transforming man's view towards nature\nfor centuries. Observing structures and patterns in an effective approach to\ndiscover regularities from data is a key step toward theory-building. With\nincreasingly complex data being obtained, revealing regularities systematically\nhas become a challenge. Correlation is a most commonly-used and effective\napproach to describe regularities in data, yet for complex patterns, spatial\ninhomogeneity and complexity can often undermine the correlations. We present\nan algorithm to derive maps representing the type and degree of correlations,\nby taking the two-fold symmetry of the correlation vector into full account\nusing the Stokes parameter. The method allows for a spatially resolved view of\nthe nature and strength of correlations between physical quantities. In the\ncorrelation view, a region can often be separated into different subregions\nwith different types of correlations. Subregions correspond to physical regimes\nfor physical systems, or climate zones for climate maps. The simplicity of the\nmethod makes it widely applicable to a variety of data, where the\ncorrelation-based approach makes the map particularly useful in revealing\nregularities in physical systems and alike. As a new and efficient approach to\nrepresent data, the method should facilitate the development of new\ncomputational approaches to regularity discovery.", "comment": "Code is avaliable at\n  https://github.com/gxli/Adjacent-Correlation-Analysis", "cate": "physics.comp-ph", "url": "http://arxiv.org/pdf/2506.05758v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06266", "title": "Cartridges: Lightweight and general-purpose long context representations via self-study", "authors": ["Sabri Eyuboglu", "Ryan Ehrlich", "Simran Arora", "Neel Guha", "Dylan Zinsley", "Emily Liu", "Will Tennien", "Atri Rudra", "James Zou", "Azalia Mirhoseini", "Christopher Re"], "summary": "Large language models are often used to answer queries grounded in large text\ncorpora (e.g. codebases, legal documents, or chat histories) by placing the\nentire corpus in the context window and leveraging in-context learning (ICL).\nAlthough current models support contexts of 100K-1M tokens, this setup is\ncostly to serve because the memory consumption of the KV cache scales with\ninput length. We explore an alternative: training a smaller KV cache offline on\neach corpus. At inference time, we load this trained KV cache, which we call a\nCartridge, and decode a response. Critically, the cost of training a Cartridge\ncan be amortized across all the queries referencing the same corpus. However,\nwe find that the naive approach of training the Cartridge with next-token\nprediction on the corpus is not competitive with ICL. Instead, we propose\nself-study, a training recipe in which we generate synthetic conversations\nabout the corpus and train the Cartridge with a context-distillation objective.\nWe find that Cartridges trained with self-study replicate the functionality of\nICL, while being significantly cheaper to serve. On challenging long-context\nbenchmarks, Cartridges trained with self-study match ICL performance while\nusing 38.6x less memory and enabling 26.4x higher throughput. Self-study also\nextends the model's effective context length (e.g. from 128k to 484k tokens on\nMTOB) and surprisingly, leads to Cartridges that can be composed at inference\ntime without retraining.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06266v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05635", "title": "IYKYK: Using language models to decode extremist cryptolects", "authors": ["Christine de Kock", "Arij Riabi", "Zeerak Talat", "Michael Sejr Schlichtkrull", "Pranava Madhyastha", "Ed Hovy"], "summary": "Extremist groups develop complex in-group language, also referred to as\ncryptolects, to exclude or mislead outsiders. We investigate the ability of\ncurrent language technologies to detect and interpret the cryptolects of two\nonline extremist platforms. Evaluating eight models across six tasks, our\nresults indicate that general purpose LLMs cannot consistently detect or decode\nextremist language. However, performance can be significantly improved by\ndomain adaptation and specialised prompting techniques. These results provide\nimportant insights to inform the development and deployment of automated\nmoderation technologies. We further develop and release novel labelled and\nunlabelled datasets, including 19.4M posts from extremist platforms and\nlexicons validated by human experts.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05635v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05853", "title": "Training-Free Query Optimization via LLM-Based Plan Similarity", "authors": ["Nikita Vasilenko", "Alexander Demin", "Vladimir Boorlakov"], "summary": "Large language model (LLM) embeddings offer a promising new avenue for\ndatabase query optimization. In this paper, we explore how pre-trained\nexecution plan embeddings can guide SQL query execution without the need for\nadditional model training. We introduce LLM-PM (LLM-based Plan Mapping), a\nframework that embeds the default execution plan of a query, finds its k\nnearest neighbors among previously executed plans, and recommends database\nhintsets based on neighborhood voting. A lightweight consistency check\nvalidates the selected hint, while a fallback mechanism searches the full hint\nspace when needed. Evaluated on the JOB-CEB benchmark using OpenGauss, LLM-PM\nachieves an average speed-up of 21% query latency reduction. This work\nhighlights the potential of LLM-powered embeddings to deliver practical\nimprovements in query performance and opens new directions for training-free,\nembedding-based optimizer guidance systems.", "comment": "18 pages, 5 figures", "cate": "cs.DB", "url": "http://arxiv.org/pdf/2506.05853v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05638", "title": "Smallest Suffixient Sets as a Repetitiveness Measure", "authors": ["Gonzalo Navarro", "Giuseppe Romana", "Cristian Urbina"], "summary": "Suffixient sets are a novel combinatorial object that capture the essential\ninformation of repetitive strings in a way that, provided with a random-access\nmechanism, supports various forms of pattern matching. In this paper we study\nthe size $\\chi$ of the smallest suffixient set as a repetitiveness measure: we\nplace it between known measures and study its sensitivity to various string\noperations.", "comment": null, "cate": "cs.FL", "url": "http://arxiv.org/pdf/2506.05638v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05888", "title": "Variational Inference for Quantum HyperNetworks", "authors": ["Luca Nepote", "Alix Lhéritier", "Nicolas Bondoux", "Marios Kountouris", "Maurizio Filippone"], "summary": "Binary Neural Networks (BiNNs), which employ single-bit precision weights,\nhave emerged as a promising solution to reduce memory usage and power\nconsumption while maintaining competitive performance in large-scale systems.\nHowever, training BiNNs remains a significant challenge due to the limitations\nof conventional training algorithms. Quantum HyperNetworks offer a novel\nparadigm for enhancing the optimization of BiNN by leveraging quantum\ncomputing. Specifically, a Variational Quantum Algorithm is employed to\ngenerate binary weights through quantum circuit measurements, while key quantum\nphenomena such as superposition and entanglement facilitate the exploration of\na broader solution space. In this work, we establish a connection between this\napproach and Bayesian inference by deriving the Evidence Lower Bound (ELBO),\nwhen direct access to the output distribution is available (i.e., in\nsimulations), and introducing a surrogate ELBO based on the Maximum Mean\nDiscrepancy (MMD) metric for scenarios involving implicit distributions, as\ncommonly encountered in practice. Our experimental results demonstrate that the\nproposed methods outperform standard Maximum Likelihood Estimation (MLE),\nimproving trainability and generalization.", "comment": "This work has been accepted for publication in 2025 International\n  Joint Conference on Neural Networks (IJCNN 2025) and will be published on\n  IEEE Xplore", "cate": "quant-ph", "url": "http://arxiv.org/pdf/2506.05888v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05894", "title": "Policy Optimization for Continuous-time Linear-Quadratic Graphon Mean Field Games", "authors": ["Philipp Plank", "Yufei Zhang"], "summary": "Multi-agent reinforcement learning, despite its popularity and empirical\nsuccess, faces significant scalability challenges in large-population dynamic\ngames. Graphon mean field games (GMFGs) offer a principled framework for\napproximating such games while capturing heterogeneity among players. In this\npaper, we propose and analyze a policy optimization framework for\ncontinuous-time, finite-horizon linear-quadratic GMFGs. Exploiting the\nstructural properties of GMFGs, we design an efficient policy parameterization\nin which each player's policy is represented as an affine function of their\nprivate state, with a shared slope function and player-specific intercepts. We\ndevelop a bilevel optimization algorithm that alternates between policy\ngradient updates for best-response computation under a fixed population\ndistribution, and distribution updates using the resulting policies. We prove\nlinear convergence of the policy gradient steps to best-response policies and\nestablish global convergence of the overall algorithm to the Nash equilibrium.\nThe analysis relies on novel landscape characterizations over\ninfinite-dimensional policy spaces. Numerical experiments demonstrate the\nconvergence and robustness of the proposed algorithm under varying graphon\nstructures, noise levels, and action frequencies.", "comment": null, "cate": "math.OC", "url": "http://arxiv.org/pdf/2506.05894v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05958", "title": "Applying XAI based unsupervised knowledge discovering for Operation modes in a WWTP. A real case: AQUAVALL WWTP", "authors": ["Alicia Beneyto-Rodriguez", "Gregorio I. Sainz-Palmero", "Marta Galende-Hernández", "María J. Fuente", "José M. Cuenca"], "summary": "Water reuse is a key point when fresh water is a commodity in ever greater\ndemand, but which is also becoming ever more available. Furthermore, the return\nof clean water to its natural environment is also mandatory. Therefore,\nwastewater treatment plants (WWTPs) are essential in any policy focused on\nthese serious challenges.\n  WWTPs are complex facilities which need to operate at their best to achieve\ntheir goals. Nowadays, they are largely monitored, generating large databases\nof historical data concerning their functioning over time. All this implies a\nlarge amount of embedded information which is not usually easy for plant\nmanagers to assimilate, correlate and understand; in other words, for them to\nknow the global operation of the plant at any given time. At this point, the\nintelligent and Machine Learning (ML) approaches can give support for that\nneed, managing all the data and translating them into manageable, interpretable\nand explainable knowledge about how the WWTP plant is operating at a glance.\n  Here, an eXplainable Artificial Intelligence (XAI) based methodology is\nproposed and tested for a real WWTP, in order to extract explainable service\nknowledge concerning the operation modes of the WWTP managed by AQUAVALL, which\nis the public service in charge of the integral water cycle in the City Council\nof Valladolid (Castilla y Le\\'on, Spain). By applying well-known approaches of\nXAI and ML focused on the challenge of WWTP, it has been possible to summarize\na large number of historical databases through a few explained operation modes\nof the plant in a low-dimensional data space, showing the variables and\nfacility units involved in each case.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05958v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05663", "title": "Insights from Designing Context-Aware Meal Preparation Assistance for Older Adults with Mild Cognitive Impairment (MCI) and Their Care Partners", "authors": ["Szeyi Chan", "Jiachen Li", "Siman Ao", "Yufei Wang", "Ibrahim Bilau", "Brian Jones", "Eunhwa Yang", "Elizabeth D Mynatt", "Xiang Zhi Tan"], "summary": "Older adults with mild cognitive impairment (MCI) often face challenges\nduring meal preparation, such as forgetting ingredients, skipping steps, or\nleaving appliances on, which can compromise their safety and independence. Our\nstudy explores the design of context-aware assistive technologies for meal\npreparation using a user-centered iterative design process. Through three\niterative phases of design and feedback, evolving from low-tech lightbox to a\ndigital screen, we gained insights into managing diverse contexts and\npersonalizing assistance through collaboration with older adults with MCI and\ntheir care partners. We concluded our findings in three key\ncontexts--routine-based, real-time, and situational--that informed strategies\nfor designing context-aware meal prep assistance tailored to users' needs. Our\nresults provide actionable insights for creating technologies to assist meal\npreparation that are personalized for the unique lifestyles of older adults\nwith MCI, situated in the complex and dynamic homebound context, and respecting\nthe collaboration between older adults and their care partners.", "comment": "DIS 2025", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05663v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06069", "title": "Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning", "authors": ["Maor Ashkenazi", "Ofir Brenner", "Tal Furman Shohet", "Eran Treister"], "summary": "Detecting Large Language Model (LLM)-generated code is a growing challenge\nwith implications for security, intellectual property, and academic integrity.\nWe investigate the role of conditional probability distributions in improving\nzero-shot LLM-generated code detection, when considering both the code and the\ncorresponding task prompt that generated it. Our key insight is that when\nevaluating the probability distribution of code tokens using an LLM, there is\nlittle difference between LLM-generated and human-written code. However,\nconditioning on the task reveals notable differences. This contrasts with\nnatural language text, where differences exist even in the unconditional\ndistributions. Leveraging this, we propose a novel zero-shot detection approach\nthat approximates the original task used to generate a given code snippet and\nthen evaluates token-level entropy under the approximated task conditioning\n(ATC). We further provide a mathematical intuition, contextualizing our method\nrelative to previous approaches. ATC requires neither access to the generator\nLLM nor the original task prompts, making it practical for real-world\napplications. To the best of our knowledge, it achieves state-of-the-art\nresults across benchmarks and generalizes across programming languages,\nincluding Python, CPP, and Java. Our findings highlight the importance of\ntask-level conditioning for LLM-generated code detection. The supplementary\nmaterials and code are available at https://github.com/maorash/ATC, including\nthe dataset gathering implementation, to foster further research in this area.", "comment": "To appear in the Proceedings of ECML-PKDD 2025, Springer Lecture\n  Notes in Computer Science (LNCS)", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06069v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06083", "title": "A Novel, Human-in-the-Loop Computational Grounded Theory Framework for Big Social Data", "authors": ["Lama Alqazlan", "Zheng Fang", "Michael Castelle", "Rob Procter"], "summary": "The availability of big data has significantly influenced the possibilities\nand methodological choices for conducting large-scale behavioural and social\nscience research. In the context of qualitative data analysis, a major\nchallenge is that conventional methods require intensive manual labour and are\noften impractical to apply to large datasets. One effective way to address this\nissue is by integrating emerging computational methods to overcome scalability\nlimitations. However, a critical concern for researchers is the trustworthiness\nof results when Machine Learning (ML) and Natural Language Processing (NLP)\ntools are used to analyse such data. We argue that confidence in the\ncredibility and robustness of results depends on adopting a 'human-in-the-loop'\nmethodology that is able to provide researchers with control over the\nanalytical process, while retaining the benefits of using ML and NLP. With this\nin mind, we propose a novel methodological framework for Computational Grounded\nTheory (CGT) that supports the analysis of large qualitative datasets, while\nmaintaining the rigour of established Grounded Theory (GT) methodologies. To\nillustrate the framework's value, we present the results of testing it on a\ndataset collected from Reddit in a study aimed at understanding tutors'\nexperiences in the gig economy.", "comment": "24 pages, 2 figures, 15 tables", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06083v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06087", "title": "Multilevel neural simulation-based inference", "authors": ["Yuga Hikida", "Ayush Bharti", "Niall Jeffrey", "François-Xavier Briol"], "summary": "Neural simulation-based inference (SBI) is a popular set of methods for\nBayesian inference when models are only available in the form of a simulator.\nThese methods are widely used in the sciences and engineering, where writing\ndown a likelihood can be significantly more challenging than constructing a\nsimulator. However, the performance of neural SBI can suffer when simulators\nare computationally expensive, thereby limiting the number of simulations that\ncan be performed. In this paper, we propose a novel approach to neural SBI\nwhich leverages multilevel Monte Carlo techniques for settings where several\nsimulators of varying cost and fidelity are available. We demonstrate through\nboth theoretical analysis and extensive experiments that our method can\nsignificantly enhance the accuracy of SBI methods given a fixed computational\nbudget.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/pdf/2506.06087v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05670", "title": "Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment", "authors": ["Priyanka Dey", "Yugal Khanter", "Aayush Bothra", "Jieyu Zhao", "Emilio Ferrara"], "summary": "As LLMs become central to interactive applications, ranging from tutoring to\nmental health, the ability to express personality in culturally appropriate\nways is increasingly important. While recent works have explored personality\nevaluation of LLMs, they largely overlook the interplay between culture and\npersonality. To address this, we introduce CulturalPersonas, the first\nlarge-scale benchmark with human validation for evaluating LLMs' personality\nexpression in culturally grounded, behaviorally rich contexts. Our dataset\nspans 3,000 scenario-based questions across six diverse countries, designed to\nelicit personality through everyday scenarios rooted in local values. We\nevaluate three LLMs, using both multiple-choice and open-ended response\nformats. Our results show that CulturalPersonas improves alignment with\ncountry-specific human personality distributions (over a 20% reduction in\nWasserstein distance across models and countries) and elicits more expressive,\nculturally coherent outputs compared to existing benchmarks. CulturalPersonas\nsurfaces meaningful modulated trait outputs in response to culturally grounded\nprompts, offering new directions for aligning LLMs to global norms of behavior.\nBy bridging personality expression and cultural nuance, we envision that\nCulturalPersonas will pave the way for more socially intelligent and globally\nadaptive LLMs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05670v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06096", "title": "Label-Context-Dependent Internal Language Model Estimation for CTC", "authors": ["Zijian Yang", "Minh-Nghia Phan", "Ralf Schlüter", "Hermann Ney"], "summary": "Although connectionist temporal classification (CTC) has the label context\nindependence assumption, it can still implicitly learn a context-dependent\ninternal language model (ILM) due to modern powerful encoders. In this work, we\ninvestigate the implicit context dependency modeled in the ILM of CTC. To this\nend, we propose novel context-dependent ILM estimation methods for CTC based on\nknowledge distillation (KD) with theoretical justifications. Furthermore, we\nintroduce two regularization methods for KD. We conduct experiments on\nLibrispeech and TED-LIUM Release 2 datasets for in-domain and cross-domain\nevaluation, respectively. Experimental results show that context-dependent ILMs\noutperform the context-independent priors in cross-domain evaluation,\nindicating that CTC learns a context-dependent ILM. The proposed label-level KD\nwith smoothing method surpasses other ILM estimation approaches, with more than\n13% relative improvement in word error rate compared to shallow fusion.", "comment": "accepted to Interspeech 2025", "cate": "cs.SD", "url": "http://arxiv.org/pdf/2506.06096v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05675", "title": "Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models", "authors": ["Zefan Zeng", "Xingchen Hu", "Qing Cheng", "Weiping Ding", "Wentao Li", "Zhong Liu"], "summary": "Event Causality Identification (ECI) aims to detect causal relationships\nbetween events in textual contexts. Existing ECI models predominantly rely on\nsupervised methodologies, suffering from dependence on large-scale annotated\ndata. Although Large Language Models (LLMs) enable zero-shot ECI, they are\nprone to causal hallucination-erroneously establishing spurious causal links.\nTo address these challenges, we propose MEFA, a novel zero-shot framework based\non Multi-source Evidence Fuzzy Aggregation. First, we decompose causality\nreasoning into three main tasks (temporality determination, necessity analysis,\nand sufficiency verification) complemented by three auxiliary tasks. Second,\nleveraging meticulously designed prompts, we guide LLMs to generate uncertain\nresponses and deterministic outputs. Finally, we quantify LLM's responses of\nsub-tasks and employ fuzzy aggregation to integrate these evidence for\ncausality scoring and causality determination. Extensive experiments on three\nbenchmarks demonstrate that MEFA outperforms second-best unsupervised baselines\nby 6.2% in F1-score and 9.3% in precision, while significantly reducing\nhallucination-induced errors. In-depth analysis verify the effectiveness of\ntask decomposition and the superiority of fuzzy aggregation.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05675v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06134", "title": "Similarity Matching Networks: Hebbian Learning and Convergence Over Multiple Time Scales", "authors": ["Veronica Centorrino", "Francesco Bullo", "Giovanni Russo"], "summary": "A recent breakthrough in biologically-plausible normative frameworks for\ndimensionality reduction is based upon the similarity matching cost function\nand the low-rank matrix approximation problem. Despite clear biological\ninterpretation, successful application in several domains, and experimental\nvalidation, a formal complete convergence analysis remains elusive. Building on\nthis framework, we consider and analyze a continuous-time neural network, the\n\\emph{similarity matching network}, for principal subspace projection. Derived\nfrom a min-max-min objective, this biologically-plausible network consists of\nthree coupled dynamics evolving at different time scales: neural dynamics,\nlateral synaptic dynamics, and feedforward synaptic dynamics at the fast,\nintermediate, and slow time scales, respectively. The feedforward and lateral\nsynaptic dynamics consist of Hebbian and anti-Hebbian learning rules,\nrespectively. By leveraging a multilevel optimization framework, we prove\nconvergence of the dynamics in the offline setting. Specifically, at the first\nlevel (fast time scale), we show strong convexity of the cost function and\nglobal exponential convergence of the corresponding gradient-flow dynamics. At\nthe second level (intermediate time scale), we prove strong concavity of the\ncost function and exponential convergence of the corresponding gradient-flow\ndynamics within the space of positive definite matrices. At the third and final\nlevel (slow time scale), we study a non-convex and non-smooth cost function,\nprovide explicit expressions for its global minima, and prove almost sure\nconvergence of the corresponding gradient-flow dynamics to the global minima.\nThese results rely on two empirically motivated conjectures that are supported\nby thorough numerical experiments. Finally, we validate the effectiveness of\nour approach via a numerical example.", "comment": "28 pages, 9 figures", "cate": "q-bio.NC", "url": "http://arxiv.org/pdf/2506.06134v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06243", "title": "fairmetrics: An R package for group fairness evaluation", "authors": ["Benjamin Smith", "Jianhui Gao", "Jessica Gronsbell"], "summary": "Fairness is a growing area of machine learning (ML) that focuses on ensuring\nmodels do not produce systematically biased outcomes for specific groups,\nparticularly those defined by protected attributes such as race, gender, or\nage. Evaluating fairness is a critical aspect of ML model development, as\nbiased models can perpetuate structural inequalities. The {fairmetrics} R\npackage offers a user-friendly framework for rigorously evaluating numerous\ngroup-based fairness criteria, including metrics based on independence (e.g.,\nstatistical parity), separation (e.g., equalized odds), and sufficiency (e.g.,\npredictive parity). Group-based fairness criteria assess whether a model is\nequally accurate or well-calibrated across a set of predefined groups so that\nappropriate bias mitigation strategies can be implemented. {fairmetrics}\nprovides both point and interval estimates for multiple metrics through a\nconvenient wrapper function and includes an example dataset derived from the\nMedical Information Mart for Intensive Care, version II (MIMIC-II) database\n(Goldberger et al., 2000; Raffa, 2016).", "comment": "6 pages, 1 figure, 1 table", "cate": "stat.CO", "url": "http://arxiv.org/pdf/2506.06243v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05685", "title": "NGA: Non-autoregressive Generative Auction with Global Externalities for Advertising Systems", "authors": ["Zuowu Zheng", "Ze Wang", "Fan Yang", "Wenqing Ye", "Weihua Huang", "Wenqiang He", "Teng Zhang", "Xingxing Wang"], "summary": "Online advertising auctions are fundamental to internet commerce, demanding\nsolutions that not only maximize revenue but also ensure incentive\ncompatibility, high-quality user experience, and real-time efficiency. While\nrecent learning-based auction frameworks have improved context modeling by\ncapturing intra-list dependencies among ads, they remain limited in addressing\nglobal externalities and often suffer from inefficiencies caused by sequential\nprocessing. In this work, we introduce the Non-autoregressive Generative\nAuction with global externalities (NGA), a novel end-to-end framework designed\nfor industrial online advertising. NGA explicitly models global externalities\nby jointly capturing the relationships among ads as well as the effects of\nadjacent organic content. To further enhance efficiency, NGA utilizes a\nnon-autoregressive, constraint-based decoding strategy and a parallel\nmulti-tower evaluator for unified list-wise reward and payment computation.\nExtensive offline experiments and large-scale online A/B testing on commercial\nadvertising platforms demonstrate that NGA consistently outperforms existing\nmethods in both effectiveness and efficiency.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.05685v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05686", "title": "A Unified Representation for Continuity and Discontinuity: Syntactic and Computational Motivations", "authors": ["Ratna Kandala", "Prakash Mondal"], "summary": "This paper advances a unified representation of linguistic structure for\nthree grammar formalisms, namely, Phrase Structure Grammar (PSG), Dependency\nGrammar (DG) and Categorial Grammar (CG) from the perspective of syntactic and\ncomputational complexity considerations. The correspondence principle is\nproposed to enable a unified representation of the representational principles\nfrom PSG, DG, and CG. To that end, the paper first illustrates a series of\nsteps in achieving a unified representation for a discontinuous subordinate\nclause from Turkish as an illustrative case. This affords a new way of\napproaching discontinuity in natural language from a theoretical point of view\nthat unites and integrates the basic tenets of PSG, DG, and CG, with\nsignificant consequences for syntactic analysis. Then this paper demonstrates\nthat a unified representation can simplify computational complexity with\nregards to the neurocognitive representation and processing of both continuous\nand discontinuous sentences vis-\\`a-vis the basic principles of PSG, DG, and\nCG.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05686v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05687", "title": "What Comes After Harm? Mapping Reparative Actions in AI through Justice Frameworks", "authors": ["Sijia Xiao", "Haodi Zou", "Alice Qian Zhang", "Deepak Kumar", "Hong Shen", "Jason Hong", "Motahhare Eslami"], "summary": "As Artificial Intelligence (AI) systems are integrated into more aspects of\nsociety, they offer new capabilities but also cause a range of harms that are\ndrawing increasing scrutiny. A large body of work in the Responsible AI\ncommunity has focused on identifying and auditing these harms. However, much\nless is understood about what happens after harm occurs: what constitutes\nreparation, who initiates it, and how effective these reparations are. In this\npaper, we develop a taxonomy of AI harm reparation based on a thematic analysis\nof real-world incidents. The taxonomy organizes reparative actions into four\noverarching goals: acknowledging harm, attributing responsibility, providing\nremedies, and enabling systemic change. We apply this framework to a dataset of\n1,060 AI-related incidents, analyzing the prevalence of each action and the\ndistribution of stakeholder involvement. Our findings show that reparation\nefforts are concentrated in early, symbolic stages, with limited actions toward\naccountability or structural reform. Drawing on theories of justice, we argue\nthat existing responses fall short of delivering meaningful redress. This work\ncontributes a foundation for advancing more accountable and reparative\napproaches to Responsible AI.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05687v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05690", "title": "When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation", "authors": ["Zhishang Xiang", "Chuanjie Wu", "Qinggang Zhang", "Shengyuan Chen", "Zijin Hong", "Xiao Huang", "Jinsong Su"], "summary": "Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful\nparadigm for enhancing large language models (LLMs) with external knowledge. It\nleverages graphs to model the hierarchical structure between specific concepts,\nenabling more coherent and effective knowledge retrieval for accurate\nreasoning.Despite its conceptual promise, recent studies report that GraphRAG\nfrequently underperforms vanilla RAG on many real-world tasks. This raises a\ncritical question: Is GraphRAG really effective, and in which scenarios do\ngraph structures provide measurable benefits for RAG systems? To address this,\nwe propose GraphRAG-Bench, a comprehensive benchmark designed to evaluate\nGraphRAG models onboth hierarchical knowledge retrieval and deep contextual\nreasoning. GraphRAG-Bench features a comprehensive dataset with tasks of\nincreasing difficulty, coveringfact retrieval, complex reasoning, contextual\nsummarization, and creative generation, and a systematic evaluation across the\nentire pipeline, from graph constructionand knowledge retrieval to final\ngeneration. Leveraging this novel benchmark, we systematically investigate the\nconditions when GraphRAG surpasses traditional RAG and the underlying reasons\nfor its success, offering guidelines for its practical application. All related\nresources and analyses are collected for the community at\nhttps://github.com/GraphRAG-Bench/GraphRAG-Benchmark.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05690v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05698", "title": "Simulation Everywhere: An Evolutionary Expansion of Discrete-Event Modeling and Simulation research and practice", "authors": ["Ikpe Justice Akpan", "Godwin E. Etti"], "summary": "Simulation was launched in the 1950s, nicknamed a tool of \"last resort.\" Over\nthe years, this Operations Research (OR) method has made significant progress,\nand utilizing the accelerated advances in computer science (hardware and\nsoftware, processing speed, and advanced information visualization\ncapabilities) to improve simulation usability in research and practice. After\novercoming the initial obstacles and the scare of outliving its usefulness in\nthe 2000s, computer simulation has remained a popular OR tool applied in\ndiverse industries and sectors, earning its popularity leading to the term\n\"simulation everywhere.\" This study uses bibliographic data from research and\npractice literature to evaluate the evolutionary expansion in simulation,\nfocusing on discrete-event simulation (DES). The results show asymmetrical but\npositive yearly literature out-put, broadened DES adoption in diverse fields,\nand sustained relevance as a scientific method for tackling old, new, and\nemerging issues. Also, DES is an essential tool in Industry 4.0 and plays a\ncentral role in digital transformation that has swept the industrial space,\nfrom manufacturing to healthcare and other sectors. With the emergence, ongoing\nadoption, and deployment of generative artificial intelligence (GenAI), future\nstudies seek ways to integrate GenAI in DES to remain relevant and improve the\nmodeling and simulation processes.", "comment": "30 pages, 6 figures, 6 tables", "cate": "cs.OH", "url": "http://arxiv.org/pdf/2506.05698v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05705", "title": "Multi-Project Contracts", "authors": ["Tal Alon", "Matteo Castiglioni", "Junjie Chen", "Tomer Ezra", "Yingkai Li", "Inbal Talgam-Cohen"], "summary": "We study a new class of contract design problems where a principal delegates\nthe execution of multiple projects to a set of agents. The principal's expected\nreward from each project is a combinatorial function of the agents working on\nit. Each agent has limited capacity and can work on at most one project, and\nthe agents are heterogeneous, with different costs and contributions for\nparticipating in different projects. The main challenge of the principal is to\ndecide how to allocate the agents to projects when the number of projects grows\nin scale.\n  We analyze this problem under different assumptions on the structure of the\nexpected reward functions. As our main result, for XOS functions we show how to\nderive a constant approximation to the optimal multi-project contract in\npolynomial time, given access to value and demand oracles. Along the way (and\nof possible independent interest), we develop approximate demand queries for\n\\emph{capped} subadditive functions, by reducing to demand queries for the\noriginal functions. Our work paves the way to combinatorial contract design in\nricher settings.", "comment": "A short version of this paper appears at EC 2025", "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.05705v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05720", "title": "A Survey of Earable Technology: Trends, Tools, and the Road Ahead", "authors": ["Changshuo Hu", "Qiang Yang", "Yang Liu", "Tobias Röddiger", "Kayla-Jade Butkow", "Mathias Ciliberto", "Adam Luke Pullin", "Jake Stuchbury-Wass", "Mahbub Hassan", "Cecilia Mascolo", "Dong Ma"], "summary": "Earable devices, wearables positioned in or around the ear, are undergoing a\nrapid transformation from audio-centric accessories into multifunctional\nsystems for interaction, contextual awareness, and health monitoring. This\nevolution is driven by commercial trends emphasizing sensor integration and by\na surge of academic interest exploring novel sensing capabilities. Building on\nthe foundation established by earlier surveys, this work presents a timely and\ncomprehensive review of earable research published since 2022. We analyze over\none hundred recent studies to characterize this shifting research landscape,\nidentify emerging applications and sensing modalities, and assess progress\nrelative to prior efforts. In doing so, we address three core questions: how\nhas earable research evolved in recent years, what enabling resources are now\navailable, and what opportunities remain for future exploration. Through this\nsurvey, we aim to provide both a retrospective and forward-looking view of\nearable technology as a rapidly expanding frontier in ubiquitous computing. In\nparticular, this review reveals that over the past three years, researchers\nhave discovered a variety of novel sensing principles, developed many new\nearable sensing applications, enhanced the accuracy of existing sensing tasks,\nand created substantial new resources to advance research in the field. Based\non this, we further discuss open challenges and propose future directions for\nthe next phase of earable research.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05720v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05728", "title": "The Geometry of Extended Kalman Filters on Manifolds with Affine Connection", "authors": ["Yixiao Ge", "Pieter van Goor", "Robert Mahony"], "summary": "The extended Kalman filter (EKF) has been the industry standard for state\nestimation problems over the past sixty years. The classical formulation of the\nEKF is posed for nonlinear systems defined on global Euclidean spaces. The\ndesign methodology is regularly applied to systems on smooth manifolds by\nchoosing local coordinates, however, it is well known that this approach is not\nintrinsic to the manifold and performance depends heavily on choosing 'good'\ncoordinates. In this paper, we propose an extended Kalman filter that is\nadapted to the specific geometry of the manifold in question. We show that an\naffine connection and the concepts of parallel transport, torsion, and\ncurvature are the key geometric structures that allow the formulation of a\nsuitable family of intrinsic Gaussian-like distributions and provide the tools\nto understand how to propagate state estimates and fuse measurements. This\nleads us to propose novel geometric modifications to the propagation and update\nsteps of the EKF and revisit recent work on the geometry of the reset step. The\nrelative performance of the proposed geometric modifications are benchmarked\nagainst classical EKF and iterated EKF algorithms on a simplified inertial\nnavigation system with direct pose measurements and no bias.", "comment": "24 pages, 7 figures", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05728v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05729", "title": "Regenerating Daily Routines for Young Adults with Depression through User-Led Indoor Environment Modifications Using Local Natural Materials", "authors": ["Ziqun Hua", "Ao Jiang", "Haoling Yang", "Hao Fan", "Huizhong Hu", "Bernard Foing"], "summary": "Young adults with depression often experience prolonged indoor stays,\nlimiting their access to natural environments and exacerbating mental health\nchallenges. While nature therapy is recognized for its psychological benefits,\nexisting interventions frequently require outdoor engagement, which may not be\naccessible for all individuals. This study explores the potential of user-led\nindoor modifications using local natural materials as a mental health\nintervention. A qualitative approach\nwasemployedtoassessemotionalandenvironmentalconnectedness.Participants engaged\nin material exploration, collection, and crafting, integrating natural elements\ninto their living spaces. Findings indicate improved mood,increased\nenvironmental awareness,and a stronger sense of agency over personal space. The\nstandardized intervention steps suggest the feasibility of a self-help toolkit,\nenabling broader implementation. This research contributes to sustainable,\nuser-driven mental health interventions, bridging the gap between nature\ntherapy and practical indoor applications.", "comment": "This work (7 pages, 2 figures) was accepted as a poster at HCII 2025.\n  Due to limited funding, it will not appear in the official Springer\n  proceedings. The version uploaded here is the original preprint submitted for\n  review. The preprint is shared to support further discussion on user-led,\n  nature-integrated mental health interventions in HCI contexts", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05729v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05746", "title": "LLM-Symbolic Integration for Robust Temporal Tabular Reasoning", "authors": ["Atharv Kulkarni", "Kushagra Dixit", "Vivek Srikumar", "Dan Roth", "Vivek Gupta"], "summary": "Temporal tabular question answering presents a significant challenge for\nLarge Language Models (LLMs), requiring robust reasoning over structured data,\nwhich is a task where traditional prompting methods often fall short. These\nmethods face challenges such as memorization, sensitivity to table size, and\nreduced performance on complex queries. To overcome these limitations, we\nintroduce TempTabQA-C, a synthetic dataset designed for systematic and\ncontrolled evaluations, alongside a symbolic intermediate representation that\ntransforms tables into database schemas. This structured approach allows LLMs\nto generate and execute SQL queries, enhancing generalization and mitigating\nbiases. By incorporating adaptive few-shot prompting with contextually tailored\nexamples, our method achieves superior robustness, scalability, and\nperformance. Experimental results consistently highlight improvements across\nkey challenges, setting a new benchmark for robust temporal reasoning with\nLLMs.", "comment": "Accepted to ACL Findings 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05746v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05760", "title": "Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning", "authors": ["Xuanyu Lei", "Chenliang Li", "Yuning Wu", "Kaiming Liu", "Weizhou Shen", "Peng Li", "Ming Yan", "Ji Zhang", "Fei Huang", "Yang Liu"], "summary": "Recent advances in Large Language Models (LLMs) have enabled strong\nperformance in long-form writing, yet existing supervised fine-tuning (SFT)\napproaches suffer from limitations such as data saturation and restricted\nlearning capacity bounded by teacher signals. In this work, we present\nWriting-RL: an Adaptive Curriculum Reinforcement Learning framework to advance\nlong-form writing capabilities beyond SFT. The framework consists of three key\ncomponents: Margin-aware Data Selection strategy that prioritizes samples with\nhigh learning potential, Pairwise Comparison Reward mechanism that provides\ndiscriminative learning signals in the absence of verifiable rewards, and\nDynamic Reference Scheduling approach, which plays a particularly critical role\nby adaptively adjusting task difficulty based on evolving model performance.\nExperiments on 7B-scale writer models show that our RL framework largely\nimproves long-form writing performance over strong SFT baselines. Furthermore,\nwe observe that models trained with long-output RL generalize surprisingly well\nto long-input reasoning tasks, potentially offering a promising perspective for\nrethinking long-context training.", "comment": "Work in progress", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05760v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05766", "title": "BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions", "authors": ["Saptarshi Sengupta", "Shuhua Yang", "Paul Kwong Yu", "Fali Wang", "Suhang Wang"], "summary": "Retrieval augmented generation (RAG) has shown great power in improving Large\nLanguage Models (LLMs). However, most existing RAG-based LLMs are dedicated to\nretrieving single modality information, mainly text; while for many real-world\nproblems, such as healthcare, information relevant to queries can manifest in\nvarious modalities such as knowledge graph, text (clinical notes), and complex\nmolecular structure. Thus, being able to retrieve relevant multi-modality\ndomain-specific information, and reason and synthesize diverse knowledge to\ngenerate an accurate response is important. To address the gap, we present\nBioMol-MQA, a new question-answering (QA) dataset on polypharmacy, which is\ncomposed of two parts (i) a multimodal knowledge graph (KG) with text and\nmolecular structure for information retrieval; and (ii) challenging questions\nthat designed to test LLM capabilities in retrieving and reasoning over\nmultimodal KG to answer questions. Our benchmarks indicate that existing LLMs\nstruggle to answer these questions and do well only when given the necessary\nbackground data, signaling the necessity for strong RAG frameworks.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05766v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05781", "title": "Generating Long Semantic IDs in Parallel for Recommendation", "authors": ["Yupeng Hou", "Jiacheng Li", "Ashley Shin", "Jinsung Jeon", "Abhishek Santhanam", "Wei Shao", "Kaveh Hassani", "Ning Yao", "Julian McAuley"], "summary": "Semantic ID-based recommendation models tokenize each item into a small\nnumber of discrete tokens that preserve specific semantics, leading to better\nperformance, scalability, and memory efficiency. While recent models adopt a\ngenerative approach, they often suffer from inefficient inference due to the\nreliance on resource-intensive beam search and multiple forward passes through\nthe neural sequence model. As a result, the length of semantic IDs is typically\nrestricted (e.g. to just 4 tokens), limiting their expressiveness. To address\nthese challenges, we propose RPG, a lightweight framework for semantic ID-based\nrecommendation. The key idea is to produce unordered, long semantic IDs,\nallowing the model to predict all tokens in parallel. We train the model to\npredict each token independently using a multi-token prediction loss, directly\nintegrating semantics into the learning objective. During inference, we\nconstruct a graph connecting similar semantic IDs and guide decoding to avoid\ngenerating invalid IDs. Experiments show that scaling up semantic ID length to\n64 enables RPG to outperform generative baselines by an average of 12.6% on the\nNDCG@10, while also improving inference efficiency. Code is available at:\nhttps://github.com/facebookresearch/RPG_KDD2025.", "comment": "KDD 2025", "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.05781v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05790", "title": "Discrete Minds in a Continuous World: Do Language Models Know Time Passes?", "authors": ["Minghan Wang", "Ye Bai", "Thuy-Trang Vu", "Ehsan Shareghi", "Gholamreza Haffari"], "summary": "While Large Language Models (LLMs) excel at temporal reasoning tasks like\nevent ordering and duration estimation, their ability to perceive the actual\npassage of time remains unexplored. We investigate whether LLMs perceive the\npassage of time and adapt their decision-making accordingly through three\ncomplementary experiments. First, we introduce the Token-Time Hypothesis,\npositing that LLMs can map discrete token counts to continuous wall-clock time,\nand validate this through a dialogue duration judgment task. Second, we\ndemonstrate that LLMs could use this awareness to adapt their response length\nwhile maintaining accuracy when users express urgency in question answering\ntasks. Finally, we develop BombRush, an interactive navigation challenge that\nexamines how LLMs modify behavior under progressive time pressure in dynamic\nenvironments. Our findings indicate that LLMs possess certain awareness of time\npassage, enabling them to bridge discrete linguistic tokens and continuous\nphysical time, though this capability varies with model size and reasoning\nabilities. This work establishes a theoretical foundation for enhancing\ntemporal awareness in LLMs for time-sensitive applications.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05790v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05793", "title": "ShyLU node: On-node Scalable Solvers and Preconditioners Recent Progresses and Current Performance", "authors": ["Ichitaro Yamazaki", "Nathan Ellingwood", "Sivasankaran Rajamanickam"], "summary": "ShyLU-node is an open-source software package that implements linear solvers\nand preconditioners on shared-memory multicore CPUs or on a GPU. It is part of\nthe Trilinos software framework and designed to provide a robust and efficient\nsolution of large-scale linear systems from real-world applications on the\ncurrent and emerging computers. In this paper, we discuss two sparse direct\nsolvers, Basker and Tacho, and an algebraic preconditioner, FastILU, in\nShyLU-node package. These ShyLU solvers and preconditioner can be used as a\nstand-alone global problem solver, as a local subdomain solver for domain\ndecomposition (DD) preconditioner, or as the coarse-problem solver in algebraic\nmulti-grid preconditioner. We present performance results with the sparse\ndirect solvers for real application problems, namely, Basker for Xyce Circuit\nSimulations and Tacho for Albany Land-Ice Simulation of Antarctica. FastILU has\nbeen also used in real-world applications, but in this paper, we illustrate its\nperformance using 3D model problems.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/pdf/2506.05793v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05811", "title": "Synchronous Clock and RF Carrier Transmission for Radio Access Network Fronthaul", "authors": ["Kari Aaron Clark", "Zun Htay", "Zichuan Zhou", "Amany Kassem", "Andrea Pertoldi", "Benjamin Rudin", "Florian Emaury", "Izzat Darwazeh", "Zhixin Liu"], "summary": "We simultaneously achieve clock synchronisation, clock-synchronised data\ntransmission and ultra-low noise RF carrier generation by combining clock phase\ncaching and frequency comb transmission in radio access networks (RAN). We\ndemonstrate <100fs jitter for 25GHz RF carrier and 2.5GHz clock, and 16-hour\n6.6ps RMS wander.", "comment": "Conference manuscript submitted to the European Conference on Optical\n  Communication 2025 (ECOC 2025) on 2nd May 2025", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05811v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05813", "title": "MAPLE: Multi-Agent Adaptive Planning with Long-Term Memory for Table Reasoning", "authors": ["Ye Bai", "Minghan Wang", "Thuy-Trang Vu"], "summary": "Table-based question answering requires complex reasoning capabilities that\ncurrent LLMs struggle to achieve with single-pass inference. Existing\napproaches, such as Chain-of-Thought reasoning and question decomposition, lack\nerror detection mechanisms and discard problem-solving experiences, contrasting\nsharply with how humans tackle such problems. In this paper, we propose MAPLE\n(Multi-agent Adaptive Planning with Long-term mEmory), a novel framework that\nmimics human problem-solving through specialized cognitive agents working in a\nfeedback-driven loop. MAPLE integrates 4 key components: (1) a Solver using the\nReAct paradigm for reasoning, (2) a Checker for answer verification, (3) a\nReflector for error diagnosis and strategy correction, and (4) an Archiver\nmanaging long-term memory for experience reuse and evolution. Experiments on\nWiKiTQ and TabFact demonstrate significant improvements over existing methods,\nachieving state-of-the-art performance across multiple LLM backbones.", "comment": "26 pages, 10 figures", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05813v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05824", "title": "Positive Varieties of Lattice Languages", "authors": ["Yusuke Inoue", "Yuji Komatsu"], "summary": "While a language assigns a value of either `yes' or `no' to each word, a\nlattice language assigns an element of a given lattice to each word. An\nadvantage of lattice languages is that joins and meets of languages can be\ndefined as generalizations of unions and intersections. This fact also allows\nfor the definition of positive varieties -- classes closed under joins, meets,\nquotients, and inverse homomorphisms -- of lattice languages. In this paper, we\nextend Pin's positive variety theorem, proving a one-to-one correspondence\nbetween positive varieties of regular lattice languages and pseudo-varieties of\nfinite ordered monoids. Additionally, we briefly explore algebraic approaches\nto finite-state Markov chains as an application of our framework.", "comment": "Accepted to DLT 2025", "cate": "cs.FL", "url": "http://arxiv.org/pdf/2506.05824v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05832", "title": "Properties of UTxO Ledgers and Programs Implemented on Them", "authors": ["Polina Vinogradova", "Alexey Sorokin"], "summary": "Trace-based properties are the gold standard for program behaviour analysis.\nOne of the domains of application of this type of analysis is cryptocurrency\nledgers, both for the purpose of analyzing the behaviour of the ledger itself,\nand any user-defined programs called by it, known as smart contracts. The\n(extended) UTxO ledger model is a kind of ledger model where all smart contract\ncode is stateless, and additional work must be done to model stateful programs.\nWe formalize the application of trace-based analysis to UTxO ledgers and\ncontracts, expressing it in the languages of topology, as well as graph and\ncategory theory. To describe valid traces of UTxO ledger executions, and their\nrelation to the behaviour of stateful programs implemented on the ledger, we\ndefine a category of simple graphs, infinite paths in which form an\nultra-metric space. Maps in this category are arbitrary partial sieve-define\nhomomorphisms of simple graphs. Programs implemented on the ledger correspond\nto non-expanding maps out of the graph of valid UTxO execution traces. We\nreason about safety properties in this framework, and prove properties of valid\nUTxO ledger traces.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05832v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05835", "title": "Nominal Equational Rewriting and Narrowing", "authors": ["Mauricio Ayala-Rincón", "Maribel Fernández", "Daniele Nantes-Sobrinho", "Daniella Santaguida"], "summary": "Narrowing is a well-known technique that adds to term rewriting mechanisms\nthe required power to search for solutions to equational problems. Rewriting\nand narrowing are well-studied in first-order term languages, but several\nproblems remain to be investigated when dealing with languages with binders\nusing nominal techniques. Applications in programming languages and theorem\nproving require reasoning modulo alpha-equivalence considering structural\ncongruences generated by equational axioms, such as commutativity. This paper\npresents the first definitions of nominal rewriting and narrowing modulo an\nequational theory. We establish a property called nominal E-coherence and\ndemonstrate its role in identifying normal forms of nominal terms.\nAdditionally, we prove the nominal E-Lifting theorem, which ensures the\ncorrespondence between sequences of nominal equational rewriting steps and\nnarrowing, crucial for developing a correct algorithm for nominal equational\nunification via nominal equational narrowing. We illustrate our results using\nthe equational theory for commutativity.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219. arXiv admin note:\n  substantial text overlap with arXiv:2505.14895", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05835v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05837", "title": "Towards an Analysis of Proofs in Arithmetic", "authors": ["Alexander Leitsch", "Anela Lolić", "Stella Mahler"], "summary": "Inductive proofs can be represented as proof schemata, i.e. as parameterized\nsequences of proofs defined in a primitive recursive way. Applications of proof\nschemata can be found in the area of automated proof analysis where the\nschemata admit (schematic) cut-elimination and the construction of Herbrand\nsystems. This work focuses on the expressivity of proof schemata. We show that\nproof schemata can simulate primitive recursive arithmetic. The translation of\nproofs in arithmetic to proof schemata can be considered as a crucial step in\nthe analysis of inductive proofs.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05837v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05839", "title": "An Execution Model for RICE", "authors": ["Steven Libby"], "summary": "In this paper, we build on the previous work of the RICE compiler by giving\nits execution model. We show the restrictions to the FlatCurry language that\nwere made to produce executable code, and present the execution model using\noperational semantics similar to Launchbury. Finally, we show that the\nexecution model conforms with the standard operational semantics for Curry.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "cate": "cs.PL", "url": "http://arxiv.org/pdf/2506.05839v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05840", "title": "Paraconsistent Relations as a Variant of Kleene Algebras", "authors": ["Juliana Cunha", "Alexandre Madeira", "Luís S. Barbosa"], "summary": "Kleene algebras (KA) and Kleene algebras with tests (KAT) provide an\nalgebraic framework to capture the behavior of conventional programming\nconstructs. This paper explores a broader understanding of these structures, in\norder to enable the expression of programs and tests yielding vague or\ninconsistent outcomes. Within this context, we introduce the concept of a\nparaconsistent Kleene Algebra with tests (PKAT), capable of capturing vague and\ncontradictory computations. Finally, to establish the semantics of such a\nstructure, we introduce two algebras parametric on a class of twisted\nstructures. We believe this sort of structures, for their huge flexibility,\nhave an interesting application potential.", "comment": "In Proceedings LSFA 2024, arXiv:2506.05219", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.05840v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05854", "title": "Towards Next-Generation Intelligent Maintenance: Collaborative Fusion of Large and Small Models", "authors": ["Xiaoyi Yuan", "Qiming Huang", "Mingqing Guo", "Huiming Ma", "Ming Xu", "Zeyi Liu", "Xiao He"], "summary": "With the rapid advancement of intelligent technologies, collaborative\nframeworks integrating large and small models have emerged as a promising\napproach for enhancing industrial maintenance. However, several challenges\npersist, including limited domain adaptability, insufficient real-time\nperformance and reliability, high integration complexity, and difficulties in\nknowledge representation and fusion. To address these issues, an intelligent\nmaintenance framework for industrial scenarios is proposed. This framework\nadopts a five-layer architecture and integrates the precise computational\ncapabilities of domain-specific small models with the cognitive reasoning,\nknowledge integration, and interactive functionalities of large language\nmodels. The objective is to achieve more accurate, intelligent, and efficient\nmaintenance in industrial applications. Two realistic implementations,\ninvolving the maintenance of telecommunication equipment rooms and the\nintelligent servicing of energy storage power stations, demonstrate that the\nframework significantly enhances maintenance efficiency.", "comment": "6 pages, 5 figures, Accepted by the 2025 CAA Symposium on Fault\n  Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2025)", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05854v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05879", "title": "Human-AI Alignment of Multimodal Large Language Models with Speech-Language Pathologists in Parent-Child Interactions", "authors": ["Weiyan Shi", "Kenny Tsu Wei Choo"], "summary": "Joint attention is a critical marker of early social-communicative\ndevelopment, yet remains difficult for caregivers to assess without expert\nguidance. In this work, we explore how multimodal large language models (MLLMs)\ncan be aligned with the reasoning processes of speech-language pathologists\n(SLPs) to support the interpretation of everyday parent-child interactions. We\nconducted in-depth interviews and video annotation studies with three\nexperienced SLPs to uncover how they evaluate joint attention based on three\ncore behavioural cues: gaze, action, and vocalisation. Using these insights, we\ndeveloped a two-stage MLLM-based system that first extracts fine-grained\nbehavioural descriptions from video segments and then judge joint attention\nquality using expert-aligned prompts. Our evaluation across 26 parent-child\ninteraction videos shows that MLLMs can achieve up to 85% accuracy in\nperceptual cue extraction and over 75% average precision in simulating expert\njudgement. We further propose design guidelines for building MLLM-based\nbehaviour observation-judgement systems that align with SLPs, emphasising the\nstructuring of behavioural cues, the construction of exemplar libraries\ngrounded in expert annotations, and the need to personalise system responses\nbased on developmental stage and neurotypical or atypical presentation. This\nwork provides structured behavioural cues derived from SLP expertise,\ndemonstrates the feasibility of aligning SLPs observation and judgement using\nMLLMs, and offers practical design guidelines for building aligned systems to\nsupport parent-child interaction analysis.", "comment": "work in progress", "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.05879v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05886", "title": "Inf-sup stable space-time discretization of the wave equation based on a first-order-in-time variational formulation", "authors": ["Matteo Ferrari", "Ilaria Perugia", "Enrico Zampa"], "summary": "In this paper, we present a conforming space-time discretization of the wave\nequation based on a first-order-in-time variational formulation with\nexponential weights in time. We analyze the method, showing its stability\nwithout imposing any restrictions on the mesh size or time step, and proving\nquasi-optimal convergence for any choice of space-time tensor product discrete\nspaces that satisfies standard approximation assumptions. Numerical examples\nare provided to support the theoretical findings.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/pdf/2506.05886v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05891", "title": "WAKE: Watermarking Audio with Key Enrichment", "authors": ["Yaoxun Xu", "Jianwei Yu", "Hangting Chen", "Zhiyong Wu", "Xixin Wu", "Dong Yu", "Rongzhi Gu", "Yi Luo"], "summary": "As deep learning advances in audio generation, challenges in audio security\nand copyright protection highlight the need for robust audio watermarking.\nRecent neural network-based methods have made progress but still face three\nmain issues: preventing unauthorized access, decoding initial watermarks after\nmultiple embeddings, and embedding varying lengths of watermarks. To address\nthese issues, we propose WAKE, the first key-controllable audio watermark\nframework. WAKE embeds watermarks using specific keys and recovers them with\ncorresponding keys, enhancing security by making incorrect key decoding\nimpossible. It also resolves the overwriting issue by allowing watermark\ndecoding after multiple embeddings and supports variable-length watermark\ninsertion. WAKE outperforms existing models in both watermarked audio quality\nand watermark detection accuracy. Code, more results, and demo page:\nhttps://thuhcsi.github.io/WAKE.", "comment": "Accepted by InterSpeech2025", "cate": "cs.SD", "url": "http://arxiv.org/pdf/2506.05891v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05893", "title": "Field-of-View and Input Constrained Impact Time Guidance Against Stationary Targets", "authors": ["Swati Singh", "Shashi Ranjan Kumar", "Dwaipayan Mukherjee"], "summary": "This paper proposes a guidance strategy to achieve time-constrained\ninterception of stationary targets, taking into account both the bounded\nfield-of-view (FOV) of seeker-equipped interceptors and the actuator's physical\nconstraints. Actuator saturation presents a significant challenge in real-world\nsystems, often resulting in degraded performance. However, since these\nlimitations are typically known in advance, incorporating them into the\nguidance design can enhance overall performance. To address the FOV constraint,\na time-to-go error-based approach is adopted. Furthermore, to incorporate the\nlateral acceleration constraints, the engagement kinematics are augmented with\nan input saturation model. Subsequently, the guidance strategy that constrains\nthe lateral acceleration and the time-to-go values within their respective\nbounds is derived using Lyapunov stability concepts and the backstepping\ntechnique. Furthermore, a multi-stage approach is suggested to expand the\nachievable range of impact time. Numerical simulations are performed to\nvalidate the efficacy of the proposed scheme for different initial engagement\ngeometries.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.05893v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05924", "title": "Generating Grounded Responses to Counter Misinformation via Learning Efficient Fine-Grained Critiques", "authors": ["Xiaofei Xu", "Xiuzhen Zhang", "Ke Deng"], "summary": "Fake news and misinformation poses a significant threat to society, making\nefficient mitigation essential. However, manual fact-checking is costly and\nlacks scalability. Large Language Models (LLMs) offer promise in automating\ncounter-response generation to mitigate misinformation, but a critical\nchallenge lies in their tendency to hallucinate non-factual information.\nExisting models mainly rely on LLM self-feedback to reduce hallucination, but\nthis approach is computationally expensive. In this paper, we propose\nMisMitiFact, Misinformation Mitigation grounded in Facts, an efficient\nframework for generating fact-grounded counter-responses at scale. MisMitiFact\ngenerates simple critique feedback to refine LLM outputs, ensuring responses\nare grounded in evidence. We develop lightweight, fine-grained critique models\ntrained on data sourced from readily available fact-checking sites to identify\nand correct errors in key elements such as numerals, entities, and topics in\nLLM generations. Experiments show that MisMitiFact generates counter-responses\nof comparable quality to LLMs' self-feedback while using significantly smaller\ncritique models. Importantly, it achieves ~5x increase in feedback generation\nthroughput, making it highly suitable for cost-effective, large-scale\nmisinformation mitigation. Code and LLM prompt templates are at\nhttps://github.com/xxfwin/MisMitiFact.", "comment": "accepted to IJCAI 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05924v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05930", "title": "Neural Visibility Cache for Real-Time Light Sampling", "authors": ["Jakub Bokšanský", "Daniel Meister"], "summary": "Direct illumination with many lights is an inherent component of\nphysically-based rendering, remaining challenging, especially in real-time\nscenarios. We propose an online-trained neural cache that stores visibility\nbetween lights and 3D positions. We feed light visibility to weighted reservoir\nsampling (WRS) to sample a light source. The cache is implemented as a\nfully-fused multilayer perceptron (MLP) with multi-resolution hash-grid\nencoding, enabling online training and efficient inference on modern GPUs in\nreal-time frame rates. The cache can be seamlessly integrated into existing\nrendering frameworks and can be used in combination with other real-time\ntechniques such as spatiotemporal reservoir sampling (ReSTIR).", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.05930v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05939", "title": "Respecting Temporal-Causal Consistency: Entity-Event Knowledge Graphs for Retrieval-Augmented Generation", "authors": ["Ze Yu Zhang", "Zitao Li", "Yaliang Li", "Bolin Ding", "Bryan Kian Hsiang Low"], "summary": "Retrieval-augmented generation (RAG) based on large language models often\nfalters on narrative documents with inherent temporal structures. Standard\nunstructured RAG methods rely solely on embedding-similarity matching and lack\nany general mechanism to encode or exploit chronological information, while\nknowledge graph RAG (KG-RAG) frameworks collapse every mention of an entity\ninto a single node, erasing the evolving context that drives many queries. To\nformalize this challenge and draw the community's attention, we construct\nChronoQA, a robust and discriminative QA benchmark that measures temporal,\ncausal, and character consistency understanding in narrative documents (e.g.,\nnovels) under the RAG setting. We then introduce Entity-Event RAG (E^2RAG), a\ndual-graph framework that keeps separate entity and event subgraphs linked by a\nbipartite mapping, thereby preserving the temporal and causal facets needed for\nfine-grained reasoning. Across ChronoQA, our approach outperforms\nstate-of-the-art unstructured and KG-based RAG baselines, with notable gains on\ncausal and character consistency queries. E^2RAG therefore offers a practical\npath to more context-aware retrieval for tasks that require precise answers\ngrounded in chronological information.", "comment": "24 pages, 4 figures", "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.05939v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05949", "title": "NameTag 3: A Tool and a Service for Multilingual/Multitagset NER", "authors": ["Jana Straková", "Milan Straka"], "summary": "We introduce NameTag 3, an open-source tool and cloud-based web service for\nmultilingual, multidataset, and multitagset named entity recognition (NER),\nsupporting both flat and nested entities. NameTag 3 achieves state-of-the-art\nresults on 21 test datasets in 15 languages and remains competitive on the\nrest, even against larger models. It is available as a command-line tool and as\na cloud-based service, enabling use without local installation. NameTag 3 web\nservice currently provides flat NER for 17 languages, trained on 21 corpora and\nthree NE tagsets, all powered by a single 355M-parameter fine-tuned model; and\nnested NER for Czech, powered by a 126M fine-tuned model. The source code is\nlicensed under open-source MPL 2.0, while the models are distributed under\nnon-commercial CC BY-NC-SA 4.0. Documentation is available at\nhttps://ufal.mff.cuni.cz/nametag, source code at\nhttps://github.com/ufal/nametag3, and trained models via https://lindat.cz. The\nREST service and the web application can be found at\nhttps://lindat.mff.cuni.cz/services/nametag/. A demonstration video is\navailable at https://www.youtube.com/watch?v=-gaGnP0IV8A.", "comment": "Accepted to ACL 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05949v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05950", "title": "Elementary Math Word Problem Generation using Large Language Models", "authors": ["Nimesh Ariyarathne", "Harshani Bandara", "Yasith Heshan", "Omega Gamage", "Surangika Ranathunga", "Dilan Nayanajith", "Yutharsan Sivapalan", "Gayathri Lihinikaduarachchi", "Tharoosha Vihidun", "Meenambika Chandirakumar", "Sanujen Premakumar", "Sanjula Gathsara"], "summary": "Mathematics is often perceived as a complex subject by students, leading to\nhigh failure rates in exams. To improve Mathematics skills, it is important to\nprovide sample questions for students to practice problem-solving. Manually\ncreating Math Word Problems (MWPs) is time consuming for tutors, because they\nhave to type in natural language while adhering to grammar and spelling rules\nof the language. Existing Deep Learning techniques for MWP generation either\nrequire a tutor to provide the initial portion of the MWP, and/or additional\ninformation such as an equation. In this paper, we present an MWP generation\nsystem based on Large Language Models (LLMs) that overcome the need for\nadditional input - the only input to our system is the number of MWPs needed,\nthe grade and the type of question (e.g. addition, subtraction). Unlike the\nexisting LLM-based solutions for MWP generation, we carried out an extensive\nset of experiments involving different LLMs, prompting strategies, techniques\nto improve the diversity of questions, as well as techniques that employ human\nfeedback to improve LLM performance. Human and automated evaluations confirmed\nthat the generated MWPs are high in quality, with minimal spelling and grammar\nissues. However, LLMs still struggle to generate questions that adhere to the\nspecified grade and question type requirements.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05950v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05976", "title": "LTG at SemEval-2025 Task 10: Optimizing Context for Classification of Narrative Roles", "authors": ["Egil Rønningstad", "Gaurav Negi"], "summary": "Our contribution to the SemEval 2025 shared task 10, subtask 1 on entity\nframing, tackles the challenge of providing the necessary segments from longer\ndocuments as context for classification with a masked language model. We show\nthat a simple entity-oriented heuristics for context selection can enable text\nclassification using models with limited context window. Our context selection\napproach and the XLM-RoBERTa language model is on par with, or outperforms,\nSupervised Fine-Tuning with larger generative language models.", "comment": "Accepted for SemEval 2025; The 19th International Workshop on\n  Semantic Evaluation", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05976v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05979", "title": "Tau-Eval: A Unified Evaluation Framework for Useful and Private Text Anonymization", "authors": ["Gabriel Loiseau", "Damien Sileo", "Damien Riquet", "Maxime Meyer", "Marc Tommasi"], "summary": "Text anonymization is the process of removing or obfuscating information from\ntextual data to protect the privacy of individuals. This process inherently\ninvolves a complex trade-off between privacy protection and information\npreservation, where stringent anonymization methods can significantly impact\nthe text's utility for downstream applications. Evaluating the effectiveness of\ntext anonymization proves challenging from both privacy and utility\nperspectives, as there is no universal benchmark that can comprehensively\nassess anonymization techniques across diverse, and sometimes contradictory\ncontexts. We present Tau-Eval, an open-source framework for benchmarking text\nanonymization methods through the lens of privacy and utility task sensitivity.\nA Python library, code, documentation and tutorials are publicly available.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05979v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05987", "title": "The JPEG XL Image Coding System: History, Features, Coding Tools, Design Rationale, and Future", "authors": ["Jon Sneyers", "Jyrki Alakuijala", "Luca Versari", "Zoltán Szabadka", "Sami Boukortt", "Amnon Cohen-Tidhar", "Moritz Firsching", "Evgenii Kliuchnikov", "Tal Lev-Ami", "Eric Portis", "Thomas Richter", "Osamu Watanabe"], "summary": "JPEG XL is a new image coding system offering state-of-the-art compression\nperformance, lossless JPEG recompression, and advanced features. It aims to\nreplace JPEG, PNG, GIF, and other formats with a single universal codec. This\narticle provides an overview of JPEG XL, including its history, design\nrationale, coding tools, and future potential. It can be used as a companion\ndocument to the standard (ISO/IEC 18181), or as a standalone article to better\nunderstand JPEG XL, either at a high level or in considerable technical detail.", "comment": "73 pages, 62 figures", "cate": "cs.MM", "url": "http://arxiv.org/pdf/2506.05987v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05991", "title": "A Culturally-Rich Romanian NLP Dataset from \"Who Wants to Be a Millionaire?\" Videos", "authors": ["Alexandru-Gabriel Ganea", "Antonia-Adelina Popovici", "Adrian-Marius Dumitran"], "summary": "Large Language Models (LLMs) demonstrate varying performance across languages\nand cultural contexts. This study introduces a novel, culturally-rich,\nmultilingual dataset derived from video recordings of the Romanian game show\n\"Who Wants to Be a Millionaire?\" (Vrei s\\u{a} fii Milionar?). We employed an\ninnovative process combining optical character recognition (OCR), automated\ntext extraction, and manual verification to collect question-answer pairs,\nenriching them with metadata including question domain (e.g., biology,\nhistory), cultural relevance (Romanian-specific vs. international), and\ndifficulty. Benchmarking state-of-the-art LLMs, including Romanian-adapted\nmodels, on this dataset revealed significant performance disparities: models\nconsistently achieve higher accuracy (80-95%) on international questions\ncompared to Romanian-specific cultural questions (50-75%). We further\ninvestigate these differences through experiments involving machine translation\nof Romanian questions into English and cross-lingual tests using a comparable\ndataset in French. Our findings underscore the impact of cultural context and\ndata source on LLM performance and offer practical insights for building\nrobust, culturally-aware multilingual NLP systems, especially in educational\ndomains. The dataset is publicly available at Hugging Face.", "comment": "10 pages", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.05991v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06013", "title": "Scalable Counting of Minimal Trap Spaces and Fixed Points in Boolean Networks", "authors": ["Mohimenul Kabir", "Van-Giang Trinh", "Samuel Pastva", "Kuldeep S Meel"], "summary": "Boolean Networks (BNs) serve as a fundamental modeling framework for\ncapturing complex dynamical systems across various domains, including systems\nbiology, computational logic, and artificial intelligence. A crucial property\nof BNs is the presence of trap spaces -- subspaces of the state space that,\nonce entered, cannot be exited. Minimal trap spaces, in particular, play a\nsignificant role in analyzing the long-term behavior of BNs, making their\nefficient enumeration and counting essential. The fixed points in BNs are a\nspecial case of minimal trap spaces. In this work, we formulate several\nmeaningful counting problems related to minimal trap spaces and fixed points in\nBNs. These problems provide valuable insights both within BN theory (e.g., in\nprobabilistic reasoning and dynamical analysis) and in broader application\nareas, including systems biology, abstract argumentation, and logic\nprogramming. To address these computational challenges, we propose novel\nmethods based on {\\em approximate answer set counting}, leveraging techniques\nfrom answer set programming. Our approach efficiently approximates the number\nof minimal trap spaces and the number of fixed points without requiring\nexhaustive enumeration, making it particularly well-suited for large-scale BNs.\nOur experimental evaluation on an extensive and diverse set of benchmark\ninstances shows that our methods significantly improve the feasibility of\ncounting minimal trap spaces and fixed points, paving the way for new\napplications in BN analysis and beyond.", "comment": "The paper is accepted at CP 2025", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.06013v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06015", "title": "On the Merits of LLM-Based Corpus Enrichment", "authors": ["Gal Zur", "Tommy Mordo", "Moshe Tennenholtz", "Oren Kurland"], "summary": "Generative AI (genAI) technologies -- specifically, large language models\n(LLMs) -- and search have evolving relations. We argue for a novel perspective:\nusing genAI to enrich a document corpus so as to improve query-based retrieval\neffectiveness. The enrichment is based on modifying existing documents or\ngenerating new ones. As an empirical proof of concept, we use LLMs to generate\ndocuments relevant to a topic which are more retrievable than existing ones. In\naddition, we demonstrate the potential merits of using corpus enrichment for\nretrieval augmented generation (RAG) and answer attribution in question\nanswering.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.06015v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06017", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "authors": ["Yu Li", "Lehui Li", "Zhihao Wu", "Qingmin Liao", "Jianye Hao", "Kun Shao", "Fengli Xu", "Yong Li"], "summary": "Large language model (LLM) agents have demonstrated strong capabilities\nacross diverse domains. However, designing high-performing agentic systems\nremains challenging. Existing agent search methods suffer from three major\nlimitations: (1) an emphasis on optimizing agentic workflows while\nunder-utilizing proven human-designed components such as memory, planning, and\ntool use; (2) high evaluation costs, as each newly generated agent must be\nfully evaluated on benchmarks; and (3) inefficient search in large search\nspace. In this work, we introduce a comprehensive framework to address these\nchallenges. First, We propose a hierarchical search space that jointly models\nagentic workflow and composable functional components, enabling richer agentic\nsystem designs. Building on this structured design space, we introduce a\npredictive value model that estimates agent performance given agentic system\nand task description, allowing for efficient, low-cost evaluation during the\nsearch process. Finally, we present a hierarchical Monte Carlo Tree Search\n(MCTS) strategy informed by uncertainty to guide the search. Experiments on\nseven benchmarks, covering embodied, math, web, tool, and game, show that our\nmethod achieves an average performance gain of 8.34\\% over state-of-the-art\nbaselines and exhibits faster search progress with steeper improvement\ntrajectories. Code repo is available at\nhttps://github.com/Ericccc02/AgentSwift.", "comment": "20pages", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06017v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06019", "title": "Runtime Analysis of Evolutionary NAS for Multiclass Classification", "authors": ["Zeqiong Lv", "Chao Qian", "Yun Liu", "Jiahao Fan", "Yanan Sun"], "summary": "Evolutionary neural architecture search (ENAS) is a key part of evolutionary\nmachine learning, which commonly utilizes evolutionary algorithms (EAs) to\nautomatically design high-performing deep neural architectures. During past\nyears, various ENAS methods have been proposed with exceptional performance.\nHowever, the theory research of ENAS is still in the infant. In this work, we\nstep for the runtime analysis, which is an essential theory aspect of EAs, of\nENAS upon multiclass classification problems. Specifically, we first propose a\nbenchmark to lay the groundwork for the analysis. Furthermore, we design a\ntwo-level search space, making it suitable for multiclass classification\nproblems and consistent with the common settings of ENAS. Based on both\ndesigns, we consider (1+1)-ENAS algorithms with one-bit and bit-wise mutations,\nand analyze their upper and lower bounds on the expected runtime. We prove that\nthe algorithm using both mutations can find the optimum with the expected\nruntime upper bound of $O(rM\\ln{rM})$ and lower bound of $\\Omega(rM\\ln{M})$.\nThis suggests that a simple one-bit mutation may be greatly considered, given\nthat most state-of-the-art ENAS methods are laboriously designed with the\nbit-wise mutation. Empirical studies also support our theoretical proof.", "comment": "Accepted by ICML 2025", "cate": "cs.NE", "url": "http://arxiv.org/pdf/2506.06019v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06033", "title": "Large Language Models are Demonstration Pre-Selectors for Themselves", "authors": ["Jiarui Jin", "Yuwei Wu", "Haoxuan Li", "Xiaoting He", "Weinan Zhang", "Yiming Yang", "Yong Yu", "Jun Wang", "Mengyue Yang"], "summary": "In-context learning (ICL) with large language models (LLMs) delivers strong\nfew-shot performance by choosing few-shot demonstrations from the entire\ntraining data. However, existing ICL methods, which rely on similarity or\ndiversity scores to choose demonstrations, incur high computational costs due\nto repeatedly retrieval from large-scale datasets for each query. To this end,\nwe propose FEEDER (FEw yet Essential Demonstration prE-selectoR), a novel\npre-selection framework that identifies a representative subset of\ndemonstrations containing the most representative examples in the training\ndata, tailored to specific LLMs. To construct this subset, we introduce the\n\"sufficiency\" and \"necessity\" metrics in the pre-selection stage and design a\ntree-based algorithm to identify representative examples efficiently. Once\npre-selected, this representative subset can effectively replace the full\ntraining data, improving efficiency while maintaining comparable performance in\nICL. Additionally, our pre-selected subset also benefits fine-tuning LLMs,\nwhere we introduce a bi-level optimization method that enhances training\nefficiency without sacrificing performance. Experiments with LLMs ranging from\n300M to 8B parameters show that FEEDER can reduce training data size by over\n20% while maintaining performance and seamlessly integrating with various\ndownstream demonstration selection strategies in ICL.", "comment": "ICML 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06033v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06034", "title": "MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?", "authors": ["Zhitao He", "Zongwei Lyu", "Dazhong Chen", "Dadi Guo", "Yi R. Fung"], "summary": "Numerous theorems, such as those in geometry, are often presented in\nmultimodal forms (e.g., diagrams). Humans benefit from visual reasoning in such\nsettings, using diagrams to gain intuition and guide the proof process. Modern\nMultimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in solving a wide range of mathematical problems. However, the\npotential of MLLMs as Automated Theorem Provers (ATPs), specifically in the\nmultimodal domain, remains underexplored. In this paper, we introduce the\nMultimodal Automated Theorem Proving benchmark (MATP-BENCH), a new Multimodal,\nMulti-level, and Multi-language benchmark designed to evaluate MLLMs in this\nrole as multimodal automated theorem provers. MATP-BENCH consists of 1056\nmultimodal theorems drawn from high school, university, and competition-level\nmathematics. All these multimodal problems are accompanied by formalizations in\nLean 4, Coq and Isabelle, thus making the benchmark compatible with a wide\nrange of theorem-proving frameworks. MATP-BENCH requires models to integrate\nsophisticated visual understanding with mastery of a broad spectrum of\nmathematical knowledge and rigorous symbolic reasoning to generate formal\nproofs. We use MATP-BENCH to evaluate a variety of advanced multimodal language\nmodels. Existing methods can only solve a limited number of the MATP-BENCH\nproblems, indicating that this benchmark poses an open challenge for research\non automated theorem proving.", "comment": "29 pages", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06034v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06037", "title": "SVD: Spatial Video Dataset", "authors": ["M. H. Izadimehr", "Milad Ghanbari", "Guodong Chen", "Wei Zhou", "Xiaoshuai Hao", "Mallesham Dasari", "Christian Timmerer", "Hadi Amirpour"], "summary": "Stereoscopic video has long been the subject of research due to its capacity\nto deliver immersive three-dimensional content across a wide range of\napplications, from virtual and augmented reality to advanced human-computer\ninteraction. The dual-view format inherently provides binocular disparity cues\nthat enhance depth perception and realism, making it indispensable for fields\nsuch as telepresence, 3D mapping, and robotic vision. Until recently, however,\nend-to-end pipelines for capturing, encoding, and viewing high-quality 3D video\nwere neither widely accessible nor optimized for consumer-grade devices.\nToday's smartphones, such as the iPhone Pro, and modern Head-Mounted Displays\n(HMDs), like the Apple Vision Pro (AVP), offer built-in support for\nstereoscopic video capture, hardware-accelerated encoding, and seamless\nplayback on devices like the Apple Vision Pro and Meta Quest 3, requiring\nminimal user intervention. Apple refers to this streamlined workflow as spatial\nvideo. Making the full stereoscopic video process available to everyone has\nmade new applications possible. Despite these advances, there remains a notable\nabsence of publicly available datasets that include the complete spatial video\npipeline.\n  In this paper, we introduce SVD, a spatial video dataset comprising 300\nfive-second video sequences, 150 captured using an iPhone Pro and 150 with an\nAVP. Additionally, 10 longer videos with a minimum duration of 2 minutes have\nbeen recorded. The SVD dataset is publicly released under an open-access\nlicense to facilitate research in codec performance evaluation, subjective and\nobjective quality of experience (QoE) assessment, depth-based computer vision,\nstereoscopic video streaming, and other emerging 3D applications such as neural\nrendering and volumetric capture. Link to the dataset:\nhttps://cd-athena.github.io/SVD/", "comment": null, "cate": "cs.MM", "url": "http://arxiv.org/pdf/2506.06037v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06040", "title": "Hardware Accelerated Neural Block Texture Compression with Cooperative Vectors", "authors": ["Belcour Laurent", "Benyoub Anis"], "summary": "In this work, we present an extension to the neural texture compression\nmethod of Weinreich and colleagues [2024]. Like them, we leverage existing\nblock compression methods which permit to use hardware texture filtering to\nstore a neural representation of physically-based rendering (PBR) texture sets\n(including albedo, normal maps, roughness, etc.). However, we show that low\ndynamic range block compression formats still make the solution viable. Thanks\nto this, we show that we can achieve higher compression ratio or higher quality\nat fixed compression ratio. We improve performance at runtime using a tile\nbased rendering architecture that leverage hardware matrix multiplication\nengine. Thanks to all this, we render 4k textures sets (9 channels per asset)\nwith anisotropic filtering at 1080p using only 28MB of VRAM per texture set at\n0.55ms on an Intel B580.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/pdf/2506.06040v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06044", "title": "On the Complexity of Claw-Free Vertex Splitting", "authors": ["Faisal N. Abu-Khzam", "Sergio Thoumi"], "summary": "Vertex splitting consists of taking a vertex v in a graph and replacing it\nwith two vertices whose combined neighborhoods is the neighborhood of v. The\nsplit is said to be exclusive when these neighborhoods are disjoint. In the\n(Exclusive) Claw-Free Vertex Splitting problem, we are given a graph G and an\ninteger k, and we are asked if we can find a subset of at most k vertices whose\n(exclusive) splitting can make G claw-free. We consider the complexity of\nExclusive Claw-Free Vertex Splitting and prove it to be NP-complete in general,\nwhile admitting a polynomial-time algorithm when the input graph has maximum\ndegree four. This result settles an open problem posed in [Firbas \\& Sorge,\nISAAC 2024]. On the positive side, we show that Claw-Free Vertex Splitting is\nfixed-parameter tractable by providing a cubic-order kernel. We also show that\nour results can be generalized to $K_{1,c}$-Free Vertex Splitting for all $c\n\\geq 3$.", "comment": null, "cate": "cs.CC", "url": "http://arxiv.org/pdf/2506.06044v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06055", "title": "The Turn to Practice in Design Ethics: Characteristics and Future Research Directions for HCI Research", "authors": ["Gizem Öz", "Christian Dindler", "Sharon Lindberg"], "summary": "As emerging technologies continue to shape society, there is a growing\nemphasis on the need to engage with design ethics as it unfolds in practice to\nbetter capture the complexities of ethical considerations embedded in\nday-to-day work. Positioned within the broader \"turn to practice\" in HCI, the\nreview characterizes this body of work in terms of its motivations, conceptual\nframeworks, methodologies, and contributions across a range of design\ndisciplines and academic databases. The findings reveal a shift away from\nstatic and abstract ethical frameworks toward an understanding of ethics as an\nevolving, situated, and inherent aspect of design activities, one that can be\ncultivated and fostered collaboratively. This review proposes six future\ndirections for establishing common research priorities and fostering the\nfield's growth. While the review promotes cross-disciplinary dialogue, we argue\nthat HCI research, given its cumulative experience with practice-oriented\nresearch, is well-equipped to guide this emerging strand of work on design\nethics.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06055v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06065", "title": "Direct Integration of Recursive Gaussian Process Regression Into Extended Kalman Filters With Application to Vapor Compression Cycle Control", "authors": ["Ricus Husmann", "Sven Weishaupt", "Harald Aschemann"], "summary": "This paper presents a real-time capable algorithm for the learning of\nGaussian Processes (GP) for submodels. It extends an existing recursive\nGaussian Process (RGP) algorithm which requires a measurable output. In many\napplications, however, an envisaged GP output is not directly measurable.\nTherefore, we present the integration of an RGP into an Extended Kalman Filter\n(EKF) for the combined state estimation and GP learning. The algorithm is\nsuccessfully tested in simulation studies and outperforms two alternative\nimplementations -- especially if high measurement noise is present. We conclude\nthe paper with an experimental validation within the control structure of a\nVapor Compression Cycle typically used in refrigeration and heat pumps. In this\napplication, the algorithm is used to learn a GP model for the heat-transfer\nvalues in dependency of several process parameters. The GP model significantly\nimproves the tracking performance of a previously published model-based\ncontroller.", "comment": "Accepted at NOLCOS 2025 (13th IFAC Symposium on Nonlinear Control\n  Systems)", "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.06065v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06066", "title": "Conversational Interfaces for Parametric Conceptual Architectural Design: Integrating Mixed Reality with LLM-driven Interaction", "authors": ["Ruochen Ji", "Lyu Tiangang"], "summary": "Mixed reality (MR) environments offer embodied spatial interaction, providing\nintuitive 3D manipulation capabilities that enhance the conceptual design\nprocess. Parametric modeling, a powerful and advanced architectural design\nmethod, enables the generation of complex, optimized geometries. However, its\nintegration into MR environments remains limited due to precision constraints\nand unsuitable input modalities. Existing MR tools prioritize spatial\ninteraction but lack the control and expressiveness required for parametric\nworkflows, particularly for designers without formal programming backgrounds.\nWe address this gap by introducing a novel conversational MR interface that\ncombines speech input, gesture recognition, and a multi-agent large language\nmodel (LLM) system to support intuitive parametric modeling. Our system\ndynamically manages parameter states, resolves ambiguous commands through\nconversation and contextual prompting, and enables real-time model manipulation\nwithin immersive environments. We demonstrate how this approach reduces\ncognitive and operational barriers in early-stage design tasks, allowing users\nto refine and explore their design space. This work expands the role of MR to a\ngenerative design platform, supporting programmatic thinking in design tasks\nthrough natural, embodied interaction.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/pdf/2506.06066v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06067", "title": "Efficient Memory Tiering in a Virtual Machine", "authors": ["Chandra Prakash", "Aravinda Prasad", "Sandeep Kumar", "Sreenivas Subramoney"], "summary": "Memory tiering is the norm to effectively tackle the increasing server memory\ntotal cost of ownership (TCO) and the growing data demands of modern data\ncenter workloads. However, the host-based state-of-the-art memory tiering\nsolutions can be inefficient for a virtualized environment when (i) the\nfrequently accessed data are scattered across the guest physical address space\nor (ii) the accesses to a huge page inside the guest are skewed due to a small\nnumber of subpages being hot. Scattered or skewed accesses make the whole huge\npage look hot in the host address space. This results in host selecting and\nplacing sparsely accessed huge pages in near memory, wasting costly near memory\nresources.\n  We propose a host-agnostic technique employed inside the guest that exploits\nthe two-level address translation in a virtualized environment to consolidate\nthe scattered and skewed accesses to a set of guest physical address ranges.\nConsolidation transforms sparsely hot huge pages to densely hot huge pages in\nthe host address space context. As a consequence, host-based tiering solutions\ncan place densely hot huge pages in near memory, improving near memory\nutilization. Our evaluation of our technique on standalone real-world\nbenchmarks with state-of-the-art host-based tiering show 50-70% reduction in\nnear memory consumption at similar performance levels, while evaluation at\nscale improves performance by 10-13% with similar memory TCO.", "comment": null, "cate": "cs.OS", "url": "http://arxiv.org/pdf/2506.06067v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06078", "title": "A Sound and Complete Characterization of Fair Asynchronous Session Subtyping", "authors": ["Mario Bravetti", "Luca Padovani", "Gianluigi Zavattaro"], "summary": "Session types are abstractions of communication protocols enabling the static\nanalysis of message-passing processes. Refinement notions for session types are\nkey to support safe forms of process substitution while preserving their\ncompatibility with the rest of the system. Recently, a fair refinement relation\nfor asynchronous session types has been defined allowing the anticipation of\nmessage outputs with respect to an unbounded number of message inputs. This\nrefinement is useful to capture common patterns in communication protocols that\ntake advantage of asynchrony. However, while the semantic (\\`a la testing)\ndefinition of such refinement is straightforward, its characterization has\nproved to be quite challenging. In fact, only a sound but not complete\ncharacterization is known so far. In this paper we close this open problem by\npresenting a sound and complete characterization of asynchronous fair\nrefinement for session types. We relate this characterization to those given in\nthe literature for synchronous session types by leveraging a novel labelled\ntransition system of session types that embeds their asynchronous semantics.", "comment": null, "cate": "cs.PL", "url": "http://arxiv.org/pdf/2506.06078v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06079", "title": "Data-driven nonlinear output regulation via data-enforced incremental passivity", "authors": ["Yixuan Liu", "Meichen Guo"], "summary": "This work proposes a data-driven regulator design that drives the output of a\nnonlinear system asymptotically to a time-varying reference and rejects\ntime-varying disturbances. The key idea is to design a data-driven feedback\ncontroller such that the closed-loop system is incrementally passive with\nrespect to the regulation error and a virtual input. By carefully designing the\nvirtual input, we solve the data-driven nonlinear output regulation problem\nwhere the reference and disturbances are generated by a linear exosystem. The\ndesigned regulator is composed of an internal model and a passivation feedback\ncontroller characterized by a set of data-dependent linear matrix inequalities.\nThe proposed data-driven method is also applied to stabilizing the non-zero\nequilibrium of a class of nonlinear systems with unknown equilibrium input.\nNumerical examples are presented to illustrate the effectiveness of the\nproposed designs.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.06079v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06091", "title": "MIRIAD: Augmenting LLMs with millions of medical query-response pairs", "authors": ["Qinyue Zheng", "Salman Abdullah", "Sam Rawal", "Cyril Zakka", "Sophie Ostmeier", "Maximilian Purk", "Eduardo Reis", "Eric J. Topol", "Jure Leskovec", "Michael Moor"], "summary": "LLMs are bound to transform healthcare with advanced decision support and\nflexible chat assistants. However, LLMs are prone to generate inaccurate\nmedical content. To ground LLMs in high-quality medical knowledge, LLMs have\nbeen equipped with external knowledge via RAG, where unstructured medical\nknowledge is split into small text chunks that can be selectively retrieved and\nintegrated into the LLMs context. Yet, existing RAG pipelines rely on raw,\nunstructured medical text, which can be noisy, uncurated and difficult for LLMs\nto effectively leverage. Systematic approaches to organize medical knowledge to\nbest surface it to LLMs are generally lacking. To address these challenges, we\nintroduce MIRIAD, a large-scale, curated corpus of 5,821,948 medical QA pairs,\neach rephrased from and grounded in a passage from peer-reviewed medical\nliterature using a semi-automated pipeline combining LLM generation, filtering,\ngrounding, and human annotation. Unlike prior medical corpora, which rely on\nunstructured text, MIRIAD encapsulates web-scale medical knowledge in an\noperationalized query-response format, which enables more targeted retrieval.\nExperiments on challenging medical QA benchmarks show that augmenting LLMs with\nMIRIAD improves accuracy up to 6.7% compared to unstructured RAG baselines with\nthe same source corpus and with the same amount of retrieved text. Moreover,\nMIRIAD improved the ability of LLMs to detect medical hallucinations by 22.5 to\n37% (increase in F1 score). We further introduce MIRIAD-Atlas, an interactive\nmap of MIRIAD spanning 56 medical disciplines, enabling clinical users to\nvisually explore, search, and refine medical knowledge. MIRIAD promises to\nunlock a wealth of down-stream applications, including medical information\nretrievers, enhanced RAG applications, and knowledge-grounded chat interfaces,\nwhich ultimately enables more reliable LLM applications in healthcare.", "comment": "Preprint", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06091v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06093", "title": "Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning", "authors": ["Atharv Kulkarni", "Vivek Srikumar"], "summary": "In this work, we study the problem of code generation with a large language\nmodel (LLM), with a focus on generating SQL queries from natural language\nquestions. We ask: Instead of using supervised fine tuning with text-code\npairs, can we tune a model by having it interact with a database engine? We\nframe this problem as a reinforcement learning problem where the model receives\nexecution-based feedback from the environment in the form of scalar rewards.\nThese rewards penalize execution failures and assign positive values when a\nquery returns a correct answer. We use the rewards within the Group Relative\nPolicy Optimization (GRPO) framework. We use a tabular reasoning benchmark to\ntest and evaluate our findings. We find that with only weak supervision in the\nform of question-answer pairs, RL-tuning improves the accuracy of model\ngenerated SQL code from 31.49 to 49.83 while reducing error percentage from\n25.43% to 14.71%. This improvement allowed the model nearly match the\nperformance performance to the larger SQLCoder-70B model. Our work demonstrates\nthe potential of using execution-based feedback to improve symbolic reasoning\ncapabilities of LLMs.", "comment": "Under review at EMNLP 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06093v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06113", "title": "Bridging the Gap: In-Context Learning for Modeling Human Disagreement", "authors": ["Benedetta Muscato", "Yue Li", "Gizem Gezici", "Zhixue Zhao", "Fosca Giannotti"], "summary": "Large Language Models (LLMs) have shown strong performance on NLP\nclassification tasks. However, they typically rely on aggregated labels-often\nvia majority voting-which can obscure the human disagreement inherent in\nsubjective annotations. This study examines whether LLMs can capture multiple\nperspectives and reflect annotator disagreement in subjective tasks such as\nhate speech and offensive language detection. We use in-context learning (ICL)\nin zero-shot and few-shot settings, evaluating four open-source LLMs across\nthree label modeling strategies: aggregated hard labels, and disaggregated hard\nand soft labels. In few-shot prompting, we assess demonstration selection\nmethods based on textual similarity (BM25, PLM-based), annotation disagreement\n(entropy), a combined ranking, and example ordering strategies (random vs.\ncurriculum-based). Results show that multi-perspective generation is viable in\nzero-shot settings, while few-shot setups often fail to capture the full\nspectrum of human judgments. Prompt design and demonstration selection notably\naffect performance, though example ordering has limited impact. These findings\nhighlight the challenges of modeling subjectivity with LLMs and the importance\nof building more perspective-aware, socially intelligent models.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06113v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06133", "title": "Let's CONFER: A Dataset for Evaluating Natural Language Inference Models on CONditional InFERence and Presupposition", "authors": ["Tara Azin", "Daniel Dumitrescu", "Diana Inkpen", "Raj Singh"], "summary": "Natural Language Inference (NLI) is the task of determining whether a\nsentence pair represents entailment, contradiction, or a neutral relationship.\nWhile NLI models perform well on many inference tasks, their ability to handle\nfine-grained pragmatic inferences, particularly presupposition in conditionals,\nremains underexplored. In this study, we introduce CONFER, a novel dataset\ndesigned to evaluate how NLI models process inference in conditional sentences.\nWe assess the performance of four NLI models, including two pre-trained models,\nto examine their generalization to conditional reasoning. Additionally, we\nevaluate Large Language Models (LLMs), including GPT-4o, LLaMA, Gemma, and\nDeepSeek-R1, in zero-shot and few-shot prompting settings to analyze their\nability to infer presuppositions with and without prior context. Our findings\nindicate that NLI models struggle with presuppositional reasoning in\nconditionals, and fine-tuning on existing NLI datasets does not necessarily\nimprove their performance.", "comment": "This paper is published in the Proceedings of the 38th Canadian\n  Conference on Artificial Intelligence (CAIAC 2025). Please cite the\n  conference version at https://caiac.pubpub.org/pub/keh8ij01", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06133v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06138", "title": "An extension of Dembo-Hammer's reduction algorithm for the 0-1 knapsack problem", "authors": ["Yang Yang"], "summary": "Dembo-Hammer's Reduction Algorithm (DHR) is one of the classical algorithms\nfor the 0-1 Knapsack Problem (0-1 KP) and its variants, which reduces an\ninstance of the 0-1 KP to a sub-instance of smaller size with reduction time\ncomplexity $O(n)$. We present an extension of DHR (abbreviated as EDHR), which\nreduces an instance of 0-1 KP to at most $n^i$ sub-instances for any positive\ninteger $i$. In practice, $i$ can be set as needed. In particular, if we choose\n$i=1$ then EDHR is exactly DHR. Finally, computational experiments on randomly\ngenerated data instances demonstrate that EDHR substantially reduces the search\ntree size compared to CPLEX.", "comment": null, "cate": "cs.CC", "url": "http://arxiv.org/pdf/2506.06138v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06147", "title": "Stream DaQ: Stream-First Data Quality Monitoring", "authors": ["Vasileios Papastergios", "Anastasios Gounaris"], "summary": "Data quality is fundamental to modern data science workflows, where data\ncontinuously flows as unbounded streams feeding critical downstream tasks, from\nelementary analytics to advanced artificial intelligence models. Existing data\nquality approaches either focus exclusively on static data or treat streaming\nas an extension of batch processing, lacking the temporal granularity and\ncontextual awareness required for true streaming applications. In this paper,\nwe present a novel data quality monitoring model specifically designed for\nunbounded data streams. Our model introduces stream-first concepts, such as\nconfigurable windowing mechanisms, dynamic constraint adaptation, and\ncontinuous assessment that produces quality meta-streams for real-time pipeline\nawareness. To demonstrate practical applicability, we developed Stream DaQ, an\nopen-source Python framework that implements our theoretical model. Stream DaQ\nunifies and adapts over 30 quality checks fragmented across existing static\ntools into a comprehensive streaming suite, enabling practitioners to define\nsophisticated, context-aware quality constraints through compositional\nexpressiveness. Our evaluation demonstrates that the model's implementation\nsignificantly outperforms a production-grade alternative in both execution time\nand throughput while offering richer functionality via native streaming\ncapabilities compared to other choices. Through its Python-native design,\nStream DaQ seamlessly integrates with modern data science workflows, making\ncontinuous quality monitoring accessible to the broader data science community.", "comment": null, "cate": "cs.DB", "url": "http://arxiv.org/pdf/2506.06147v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06172", "title": "Monitorability for the Modal mu-Calculus over Systems with Data: From Practice to Theory", "authors": ["Luca Aceto", "Antonis Achilleos", "Duncan Paul Attard", "Léo Exibard", "Adrian Francalanza", "Anna Ingólfsdóttir", "Karoliina Lehtinen"], "summary": "Runtime verification, also known as runtime monitoring, consists of checking\nwhether a system satisfies a given specification by observing the trace it\nproduces during its execution. It is used as a lightweight verification\ntechnique to complement or substitute costlier methods such as model-checking.\n  In the regular setting, Hennessy-Milner logic with recursion, a variant of\nthe modal mu-calculus, provides a versatile formalism for expressing linear-\nand branching-time specifications of the control flow of the system.\n  In this paper, we shift the focus from control to data and study the\nmonitorability of an extension of this logic that allows one to express\nproperties of the data flow. Data values are modelled as values from an\ninfinite domain. They are stored using data variables and manipulated using\npredicates and first-order quantification.\n  The resulting logic is closely related to register automata with guessing.\nThis correspondence yields a monitor synthesis algorithm, and allows us to\nderive a strict monitorability hierarchy between the different fragments of the\nlogic, in stark contrast to the regular setting. In particular, restricting to\ndeterministic monitors strictly reduces the set of monitorable properties.\n  Last, we exhibit a fragment of the logic that can express all monitorable\nformulae in the logic without greatest fixed-points but not in the full logic.\nWe finally show that this is unavoidable because, in fact, there is no\ndecidable fragment of the logic that captures all monitorable properties.", "comment": null, "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.06172v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06175", "title": "Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach", "authors": ["James Ford", "Anthony Rios"], "summary": "Large language models can translate natural-language chart descriptions into\nrunnable code, yet approximately 15\\% of the generated scripts still fail to\nexecute, even after supervised fine-tuning and reinforcement learning. We\ninvestigate whether this persistent error rate stems from model limitations or\nfrom reliance on a single-prompt design. To explore this, we propose a\nlightweight multi-agent pipeline that separates drafting, execution, repair,\nand judgment, using only an off-the-shelf GPT-4o-mini model. On the\n\\textsc{Text2Chart31} benchmark, our system reduces execution errors to 4.5\\%\nwithin three repair iterations, outperforming the strongest fine-tuned baseline\nby nearly 5 percentage points while requiring significantly less compute.\nSimilar performance is observed on the \\textsc{ChartX} benchmark, with an error\nrate of 4.6\\%, demonstrating strong generalization. Under current benchmarks,\nexecution success appears largely solved. However, manual review reveals that 6\nout of 100 sampled charts contain hallucinations, and an LLM-based\naccessibility audit shows that only 33.3\\% (\\textsc{Text2Chart31}) and 7.2\\%\n(\\textsc{ChartX}) of generated charts satisfy basic colorblindness guidelines.\nThese findings suggest that future work should shift focus from execution\nreliability toward improving chart aesthetics, semantic fidelity, and\naccessibility.", "comment": "8 pages", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06175v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06180", "title": "Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models", "authors": ["Ju Yong Sim", "Seong Hwan Kim"], "summary": "We develop a voice phishing (VP) detector by fine-tuning Llama3, a\nrepresentative open-source, small language model (LM). In the prompt, we\nprovide carefully-designed VP evaluation criteria and apply the\nChain-of-Thought (CoT) technique. To evaluate the robustness of LMs and\nhighlight differences in their performance, we construct an adversarial test\ndataset that places the models under challenging conditions. Moreover, to\naddress the lack of VP transcripts, we create transcripts by referencing\nexisting or new types of VP techniques. We compare cases where evaluation\ncriteria are included, the CoT technique is applied, or both are used together.\nIn the experiment, our results show that the Llama3-8B model, fine-tuned with a\ndataset that includes a prompt with VP evaluation criteria, yields the best\nperformance among small LMs and is comparable to that of a GPT-4-based VP\ndetector. These findings indicate that incorporating human expert knowledge\ninto the prompt is more effective than using the CoT technique for small LMs in\nVP detection.", "comment": "15 pages, 4 figures, 8 tables, journal submission", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06180v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06181", "title": "Swap Kripke models for deontic LFIs", "authors": ["Mahan Vaz", "Marcelo E. Coniglio"], "summary": "We present a construction of nondeterministic semantics for some deontic\nlogics based on the class of paraconsistent logics known as Logics of Formal\nInconsistency (LFIs), for the first time combining swap structures and Kripke\nmodels through the novel notion of swap Kripe models. We start by making use of\nNmatrices to characterize systems based on LFIs that do not satisfy axiom (cl),\nwhile turning to RNmatrices when the latter is considered in the underlying\nLFIs. This paper also presents, for the first time, a full axiomatization and a\nsemantics for the $C^{D}_n$ hierarchy, by use of the aforementioned mixed\nsemantics with RNmatrices. This includes the historical system $C^{D}_1$ of da\nCosta-Carnielli (1986), the first deontic paraconsistent system proposed in the\nliterature.", "comment": "35 pages", "cate": "cs.LO", "url": "http://arxiv.org/pdf/2506.06181v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06190", "title": "NAT: Neural Acoustic Transfer for Interactive Scenes in Real Time", "authors": ["Xutong Jin", "Bo Pang", "Chenxi Xu", "Xinyun Hou", "Guoping Wang", "Sheng Li"], "summary": "Previous acoustic transfer methods rely on extensive precomputation and\nstorage of data to enable real-time interaction and auditory feedback. However,\nthese methods struggle with complex scenes, especially when dynamic changes in\nobject position, material, and size significantly alter sound effects. These\ncontinuous variations lead to fluctuating acoustic transfer distributions,\nmaking it challenging to represent with basic data structures and render\nefficiently in real time. To address this challenge, we present Neural Acoustic\nTransfer, a novel approach that utilizes an implicit neural representation to\nencode precomputed acoustic transfer and its variations, allowing for real-time\nprediction of sound fields under varying conditions. To efficiently generate\nthe training data required for the neural acoustic field, we developed a fast\nMonte-Carlo-based boundary element method (BEM) approximation for general\nscenarios with smooth Neumann conditions. Additionally, we implemented a\nGPU-accelerated version of standard BEM for scenarios requiring higher\nprecision. These methods provide the necessary training data, enabling our\nneural network to accurately model the sound radiation space. We demonstrate\nour method's numerical accuracy and runtime efficiency (within several\nmilliseconds for 30s audio) through comprehensive validation and comparisons in\ndiverse acoustic transfer scenarios. Our approach allows for efficient and\naccurate modeling of sound behavior in dynamically changing environments, which\ncan benefit a wide range of interactive applications such as virtual reality,\naugmented reality, and advanced audio production.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/pdf/2506.06190v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06217", "title": "Longer Lists Yield Better Matchings", "authors": ["Yuri Faenza", "Aapeli Vuorinen"], "summary": "Many centralized mechanisms for two-sided matching markets that enjoy strong\ntheoretical properties assume that the planner solicits full information on the\npreferences of each participating agent. In particular, they expect that\nparticipants compile and communicate their complete preference lists over\nagents from the other side of the market. However, real-world markets are often\nvery large and agents cannot always be expected to even produce a ranking of\nall options on the other side. It is therefore important to understand the\nimpact of incomplete or truncated lists on the quality of the resultant\nmatching.\n  In this paper, we focus on the Serial Dictatorship mechanism in a model where\neach agent of the proposing side (students) has a random preference list of\nlength $d$, sampled independently and uniformly at random from $n$ schools,\neach of which has one seat. Our main result shows that if the students\nprimarily care about being matched to any school of their list (as opposed to\nending up unmatched), then all students in position $i\\leq n$ will prefer\nmarkets with longer lists, when $n$ is large enough. Schools on the other hand\nwill always prefer longer lists in our model. We moreover investigate the\nimpact of $d$ on the rank of the school that a student gets matched to.\n  Our main result suggests that markets that are well-approximated by our\nhypothesis and where the demand of schools does not exceed supply should be\ndesigned with preference lists as long as reasonable, since longer lists would\nfavor all agents.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.06217v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06223", "title": "A Direct Reduction from Stochastic Parity Games to Simple Stochastic Games", "authors": ["Raphaël Berthon", "Joost-Pieter Katoen", "Zihan Zhou"], "summary": "Significant progress has been recently achieved in developing efficient\nsolutions for simple stochastic games (SSGs), focusing on reachability\nobjectives. While reductions from stochastic parity games (SPGs) to SSGs have\nbeen presented in the literature through the use of multiple intermediate game\nmodels, a direct and simple reduction has been notably absent. This paper\nintroduces a novel and direct polynomial-time reduction from quantitative SPGs\nto quantitative SSGs. By leveraging a gadget-based transformation that\neffectively removes the priority function, we construct an SSG that simulates\nthe behavior of a given SPG. We formally establish the correctness of our\ndirect reduction. Furthermore, we demonstrate that under binary encoding this\nreduction is polynomial, thereby directly corroborating the known\n$\\textbf{NP}\\,\\mathbf{\\cap}\\,\\textbf{coNP}$ complexity of SPGs and providing\nnew understanding in the relationship between parity and reachability\nobjectives in turn-based stochastic games.", "comment": "Paper accepted at CONCUR 2025 - Full version", "cate": "cs.GT", "url": "http://arxiv.org/pdf/2506.06223v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06227", "title": "CompilerGPT: Leveraging Large Language Models for Analyzing and Acting on Compiler Optimization Reports", "authors": ["Peter Pirkelbauer"], "summary": "Current compiler optimization reports often present complex, technical\ninformation that is difficult for programmers to interpret and act upon\neffectively. This paper assesses the capability of large language models (LLM)\nto understand compiler optimization reports and automatically rewrite the code\naccordingly.\n  To this end, the paper introduces CompilerGPT, a novel framework that\nautomates the interaction between compilers, LLMs, and user defined test and\nevaluation harness. CompilerGPT's workflow runs several iterations and reports\non the obtained results.\n  Experiments with two leading LLM models (GPT-4o and Claude Sonnet),\noptimization reports from two compilers (Clang and GCC), and five benchmark\ncodes demonstrate the potential of this approach. Speedups of up to 6.5x were\nobtained, though not consistently in every test. This method holds promise for\nimproving compiler usability and streamlining the software optimization\nprocess.", "comment": "C3PO at ISC HPC 2025", "cate": "cs.PL", "url": "http://arxiv.org/pdf/2506.06227v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06228", "title": "Statistical Guarantees in Data-Driven Nonlinear Control: Conformal Robustness for Stability and Safety", "authors": ["Ting-Wei Hsu", "Hiroyasu Tsukamoto"], "summary": "We present a true-dynamics-agnostic, statistically rigorous framework for\nestablishing exponential stability and safety guarantees of closed-loop,\ndata-driven nonlinear control. Central to our approach is the novel concept of\nconformal robustness, which robustifies the Lyapunov and zeroing barrier\ncertificates of data-driven dynamical systems against model prediction\nuncertainties using conformal prediction. It quantifies these uncertainties by\nleveraging rank statistics of prediction scores over system trajectories,\nwithout assuming any specific underlying structure of the prediction model or\ndistribution of the uncertainties. With the quantified uncertainty information,\nwe further construct the conformally robust control Lyapunov function (CR-CLF)\nand control barrier function (CR-CBF), data-driven counterparts of the CLF and\nCBF, for fully data-driven control with statistical guarantees of\nfinite-horizon exponential stability and safety. The performance of the\nproposed concept is validated in numerical simulations with four benchmark\nnonlinear control problems.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/pdf/2506.06228v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06238", "title": "Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection", "authors": ["Sahrish Khan", "Arshad Jhumka", "Gabriele Pergola"], "summary": "The detection of sexism in online content remains an open problem, as harmful\nlanguage disproportionately affects women and marginalized groups. While\nautomated systems for sexism detection have been developed, they still face two\nkey challenges: data sparsity and the nuanced nature of sexist language. Even\nin large, well-curated datasets like the Explainable Detection of Online Sexism\n(EDOS), severe class imbalance hinders model generalization. Additionally, the\noverlapping and ambiguous boundaries of fine-grained categories introduce\nsubstantial annotator disagreement, reflecting the difficulty of interpreting\nnuanced expressions of sexism. To address these challenges, we propose two\nprompt-based data augmentation techniques: Definition-based Data Augmentation\n(DDA), which leverages category-specific definitions to generate\nsemantically-aligned synthetic examples, and Contextual Semantic Expansion\n(CSE), which targets systematic model errors by enriching examples with\ntask-specific semantic features. To further improve reliability in fine-grained\nclassification, we introduce an ensemble strategy that resolves prediction ties\nby aggregating complementary perspectives from multiple language models. Our\nexperimental evaluation on the EDOS dataset demonstrates state-of-the-art\nperformance across all tasks, with notable improvements of macro F1 by 1.5\npoints for binary classification (Task A) and 4.1 points for fine-grained\nclassification (Task C).", "comment": "Proceedings of the 2025 Annual Meeting of the Association for\n  Computational Linguistics (ACL). ACL 2025 - Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06238v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06239", "title": "Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for Item-to-Item Retrieval in Recommendation", "authors": ["Jiang Zhang", "Sumit Kumar", "Wei Chang", "Yubo Wang", "Feng Zhang", "Weize Mao", "Hanchao Yu", "Aashu Singh", "Min Li", "Qifan Wang"], "summary": "The task of item-to-item (I2I) retrieval is to identify a set of relevant and\nhighly engaging items based on a given trigger item. It is a crucial component\nin modern recommendation systems, where users' previously engaged items serve\nas trigger items to retrieve relevant content for future engagement. However,\nexisting I2I retrieval models in industry are primarily built on co-engagement\ndata and optimized using the recall measure, which overly emphasizes\nco-engagement patterns while failing to capture semantic relevance. This often\nleads to overfitting short-term co-engagement trends at the expense of\nlong-term benefits such as discovering novel interests and promoting content\ndiversity. To address this challenge, we propose MTMH, a Multi-Task and\nMulti-Head I2I retrieval model that achieves both high recall and semantic\nrelevance. Our model consists of two key components: 1) a multi-task learning\nloss for formally optimizing the trade-off between recall and semantic\nrelevance, and 2) a multi-head I2I retrieval architecture for retrieving both\nhighly co-engaged and semantically relevant items. We evaluate MTMH using\nproprietary data from a commercial platform serving billions of users and\ndemonstrate that it can improve recall by up to 14.4% and semantic relevance by\nup to 56.6% compared with prior state-of-the-art models. We also conduct live\nexperiments to verify that MTMH can enhance both short-term consumption metrics\nand long-term user-experience-related metrics. Our work provides a principled\napproach for jointly optimizing I2I recall and semantic relevance, which has\nsignificant implications for improving the overall performance of\nrecommendation systems.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.06239v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06240", "title": "Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge", "authors": ["Yi Sui", "Chaozhuo Li", "Chen Zhang", "Dawei song", "Qiuchi Li"], "summary": "Retrieval-augmented generation (RAG) is a cost-effective approach to mitigate\nthe hallucination of Large Language Models (LLMs) by incorporating the\nretrieved external knowledge into the generation process. However, external\nknowledge may conflict with the parametric knowledge of LLMs. Furthermore,\ncurrent LLMs lack inherent mechanisms for resolving such knowledge conflicts,\nmaking traditional RAG methods suffer from degraded performance and stability.\nThus, we propose a Dual-Stream Knowledge-Augmented Framework for Shared-Private\nSemantic Synergy (DSSP-RAG). Central to the framework is a novel approach that\nrefines self-attention into a mixed-attention, distinguishing shared and\nprivate semantics for a controlled internal-external knowledge integration. To\neffectively facilitate DSSP in RAG, we further introduce an unsupervised\nhallucination detection method based on cognitive uncertainty, ensuring the\nnecessity of introducing knowledge, and an Energy Quotient (EQ) based on\nattention difference matrices to reduce noise in the retrieved external\nknowledge. Extensive experiments on benchmark datasets show that DSSP-RAG can\neffectively resolve conflicts and enhance the complementarity of dual-stream\nknowledge, leading to superior performance over strong baselines.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06240v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06265", "title": "Integrating Complexity and Biological Realism: High-Performance Spiking Neural Networks for Breast Cancer Detection", "authors": ["Zofia Rudnicka", "Januszcz Szczepanski", "Agnieszka Pregowska"], "summary": "Spiking Neural Networks (SNNs) event-driven nature enables efficient encoding\nof spatial and temporal features, making them suitable for dynamic\ntime-dependent data processing. Despite their biological relevance, SNNs have\nseen limited application in medical image recognition due to difficulties in\nmatching the performance of conventional deep learning models. To address this,\nwe propose a novel breast cancer classification approach that combines SNNs\nwith Lempel-Ziv Complexity (LZC) a computationally efficient measure of\nsequence complexity. LZC enhances the interpretability and accuracy of\nspike-based models by capturing structural patterns in neural activity. Our\nstudy explores both biophysical Leaky Integrate-and-Fire (LIF) and\nprobabilistic Levy-Baxter (LB) neuron models under supervised, unsupervised,\nand hybrid learning regimes. Experiments were conducted on the Breast Cancer\nWisconsin dataset using numerical features derived from medical imaging.\nLB-based models consistently exceeded 90.00% accuracy, while LIF-based models\nreached over 85.00%. The highest accuracy of 98.25% was achieved using an\nANN-to-SNN conversion method applied to both neuron models comparable to\ntraditional deep learning with back-propagation, but at up to 100 times lower\ncomputational cost. This hybrid approach merges deep learning performance with\nthe efficiency and plausibility of SNNs, yielding top results at lower\ncomputational cost. We hypothesize that the synergy between temporal-coding,\nspike-sparsity, and LZC-driven complexity analysis enables more-efficient\nfeature extraction. Our findings demonstrate that SNNs combined with LZC offer\npromising, biologically plausible alternative to conventional neural networks\nin medical diagnostics, particularly for resource-constrained or real-time\nsystems.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/pdf/2506.06265v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06270", "title": "RecGPT: A Foundation Model for Sequential Recommendation", "authors": ["Yangqin Jiang", "Xubin Ren", "Lianghao Xia", "Da Luo", "Kangyi Lin", "Chao Huang"], "summary": "This work addresses a fundamental barrier in recommender systems: the\ninability to generalize across domains without extensive retraining.\nTraditional ID-based approaches fail entirely in cold-start and cross-domain\nscenarios where new users or items lack sufficient interaction history.\nInspired by foundation models' cross-domain success, we develop a foundation\nmodel for sequential recommendation that achieves genuine zero-shot\ngeneralization capabilities. Our approach fundamentally departs from existing\nID-based methods by deriving item representations exclusively from textual\nfeatures. This enables immediate embedding of any new item without model\nretraining. We introduce unified item tokenization with Finite Scalar\nQuantization that transforms heterogeneous textual descriptions into\nstandardized discrete tokens. This eliminates domain barriers that plague\nexisting systems. Additionally, the framework features hybrid\nbidirectional-causal attention that captures both intra-item token coherence\nand inter-item sequential dependencies. An efficient catalog-aware beam search\ndecoder enables real-time token-to-item mapping. Unlike conventional approaches\nconfined to their training domains, RecGPT naturally bridges diverse\nrecommendation contexts through its domain-invariant tokenization mechanism.\nComprehensive evaluations across six datasets and industrial scenarios\ndemonstrate consistent performance advantages.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/pdf/2506.06270v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06273", "title": "AdvSumm: Adversarial Training for Bias Mitigation in Text Summarization", "authors": ["Mukur Gupta", "Nikhil Reddy Varimalla", "Nicholas Deas", "Melanie Subbiah", "Kathleen McKeown"], "summary": "Large Language Models (LLMs) have achieved impressive performance in text\nsummarization and are increasingly deployed in real-world applications.\nHowever, these systems often inherit associative and framing biases from\npre-training data, leading to inappropriate or unfair outputs in downstream\ntasks. In this work, we present AdvSumm (Adversarial Summarization), a\ndomain-agnostic training framework designed to mitigate bias in text\nsummarization through improved generalization. Inspired by adversarial\nrobustness, AdvSumm introduces a novel Perturber component that applies\ngradient-guided perturbations at the embedding level of Sequence-to-Sequence\nmodels, enhancing the model's robustness to input variations. We empirically\ndemonstrate that AdvSumm effectively reduces different types of bias in\nsummarization-specifically, name-nationality bias and political framing\nbias-without compromising summarization quality. Compared to standard\ntransformers and data augmentation techniques like back-translation, AdvSumm\nachieves stronger bias mitigation performance across benchmark datasets.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.06273v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05671", "title": "Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning", "authors": ["Yangui Fang", "Jing Peng", "Xu Li", "Yu Xi", "Chengwei Zhang", "Guohui Zhong", "Kai Yu"], "summary": "Recent advances in automatic speech recognition (ASR) have combined speech\nencoders with large language models (LLMs) through projection, forming Speech\nLLMs with strong performance. However, adapting them to new domains remains\nchallenging, especially in low-resource settings where paired speech-text data\nis scarce. We propose a text-only fine-tuning strategy for Speech LLMs using\nunpaired target-domain text without requiring additional audio. To preserve\nspeech-text alignment, we introduce a real-time evaluation mechanism during\nfine-tuning. This enables effective domain adaptation while maintaining\nsource-domain performance. Experiments on LibriSpeech, SlideSpeech, and Medical\ndatasets show that our method achieves competitive recognition performance,\nwith minimal degradation compared to full audio-text fine-tuning. It also\nimproves generalization to new domains without catastrophic forgetting,\nhighlighting the potential of text-only fine-tuning for low-resource domain\nadaptation of ASR.", "comment": null, "cate": "eess.AS", "url": "http://arxiv.org/pdf/2506.05671v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05905", "title": "Sequential Monte Carlo approximations of Wasserstein--Fisher--Rao gradient flows", "authors": ["Francesca R. Crucinio", "Sahani Pathiraja"], "summary": "We consider the problem of sampling from a probability distribution $\\pi$. It\nis well known that this can be written as an optimisation problem over the\nspace of probability distribution in which we aim to minimise the\nKullback--Leibler divergence from $\\pi$. We consider several partial\ndifferential equations (PDEs) whose solution is a minimiser of the\nKullback--Leibler divergence from $\\pi$ and connect them to well-known Monte\nCarlo algorithms. We focus in particular on PDEs obtained by considering the\nWasserstein--Fisher--Rao geometry over the space of probabilities and show that\nthese lead to a natural implementation using importance sampling and sequential\nMonte Carlo. We propose a novel algorithm to approximate the\nWasserstein--Fisher--Rao flow of the Kullback--Leibler divergence which\nempirically outperforms the current state-of-the-art.\n  We study tempered versions of these PDEs obtained by replacing the target\ndistribution with a geometric mixture of initial and target distribution and\nshow that these do not lead to a convergence speed up.", "comment": null, "cate": "stat.ME", "url": "http://arxiv.org/pdf/2506.05905v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06053", "title": "Some remarks on stochastic converse Lyapunov theorems", "authors": ["Pavel Osinenko", "Grigory Yaremenko"], "summary": "In this brief note, we investigate some constructions of Lyapunov functions\nfor stochastic discrete-time stabilizable dynamical systems, in other words,\ncontrolled Markov chains. The main question here is whether a Lyapunov function\nin some statistical sense exists if the respective controlled Markov chain\nadmits a stabilizing policy. We demonstrate some constructions extending on the\nclassical results for deterministic systems. Some limitations of the\nconstructed Lyapunov functions for stabilization are discussed, particularly\nfor stabilization in mean. Although results for deterministic systems are well\nknown, the stochastic case was addressed in less detail, which the current\npaper remarks on. A distinguishable feature of this work is the study of\nstabilizers that possess computationally tractable convergence certificates.", "comment": null, "cate": "math.DS", "url": "http://arxiv.org/pdf/2506.06053v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06071", "title": "CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition", "authors": ["Yun-Shao Tsai", "Yi-Cheng Lin", "Huang-Cheng Chou", "Hung-yi Lee"], "summary": "Bias in speech emotion recognition (SER) systems often stems from spurious\ncorrelations between speaker characteristics and emotional labels, leading to\nunfair predictions across demographic groups. Many existing debiasing methods\nrequire model-specific changes or demographic annotations, limiting their\npractical use. We present CO-VADA, a Confidence-Oriented Voice Augmentation\nDebiasing Approach that mitigates bias without modifying model architecture or\nrelying on demographic information. CO-VADA identifies training samples that\nreflect bias patterns present in the training data and then applies voice\nconversion to alter irrelevant attributes and generate samples. These augmented\nsamples introduce speaker variations that differ from dominant patterns in the\ndata, guiding the model to focus more on emotion-relevant features. Our\nframework is compatible with various SER models and voice conversion tools,\nmaking it a scalable and practical solution for improving fairness in SER\nsystems.", "comment": "8 pages", "cate": "eess.AS", "url": "http://arxiv.org/pdf/2506.06071v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.06259", "title": "An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds", "authors": ["Siyu Chen", "Theodor Misiakiewicz", "Ilias Zadik", "Peiyuan Zhang"], "summary": "Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for\ncharacterizing the computational hard phases in statistical detection problems.\nThe FP criterion, based on an annealed version of the celebrated Franz-Parisi\npotential from statistical physics, was shown to be equivalent to low-degree\npolynomial (LDP) lower bounds for Gaussian additive models, thereby connecting\ntwo distinct approaches to understanding the computational hardness in\nstatistical inference. In this paper, we propose a refined FP criterion that\naims to better capture the geometric ``overlap\" structure of statistical\nmodels. Our main result establishes that this optimized FP criterion is\nequivalent to Statistical Query (SQ) lower bounds -- another foundational\nframework in computational complexity of statistical inference. Crucially, this\nequivalence holds under a mild, verifiable assumption satisfied by a broad\nclass of statistical models, including Gaussian additive models, planted sparse\nmodels, as well as non-Gaussian component analysis (NGCA), single-index (SI)\nmodels, and convex truncation detection settings. For instance, in the case of\nconvex truncation tasks, the assumption is equivalent with the Gaussian\ncorrelation inequality (Royen, 2014) from convex geometry.\n  In addition to the above, our equivalence not only unifies and simplifies the\nderivation of several known SQ lower bounds -- such as for the NGCA model\n(Diakonikolas et al., 2017) and the SI model (Damian et al., 2024) -- but also\nyields new SQ lower bounds of independent interest, including for the\ncomputational gaps in mixed sparse linear regression (Arpino et al., 2023) and\nconvex truncation (De et al., 2023).", "comment": null, "cate": "math.ST", "url": "http://arxiv.org/pdf/2506.06259v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
