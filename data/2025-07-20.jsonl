{"id": "2507.13367", "title": "A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security", "authors": ["Mehrab Hosain", "Rajiv Kapoor"], "categories": ["cs.CR", "cs.CV", "cs.MM", "eess.IV", "68Q80", "I.4.2"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol 1191. Springer", "url": "http://arxiv.org/abs/2507.13367v1", "summary": "Steganography is the process of embedding secret information discreetly\nwithin a carrier, ensuring secure exchange of confidential data. The Adaptive\nPixel Value Differencing (APVD) steganography method, while effective,\nencounters certain challenges like the \"unused blocks\" issue. This problem can\ncause a decrease in security, compromise the embedding capacity, and lead to\nlower visual quality. This research presents a novel steganographic strategy\nthat integrates APVD with pseudorandom pixel selection to effectively mitigate\nthese issues. The results indicate that the new method outperforms existing\ntechniques in aspects of security, data hiding capacity, and the preservation\nof image quality. Empirical results reveal that the combination of APVD with\npseudorandom pixel selection significantly enhances key image quality metrics\nsuch as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ),\nand Structural Similarity Index (SSIM), surpassing other contemporary methods\nin performance. The newly proposed method is versatile, able to handle a\nvariety of cover and secret images in both color and grayscale, thereby\nensuring secure data transmission without compromising the aesthetic quality of\nthe image.", "comment": "Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol\n  1191. Springer", "pdf_url": "http://arxiv.org/pdf/2507.13367v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.13505", "title": "PHASE: Passive Human Activity Simulation Evaluation", "authors": ["Steven Lamp", "Jason D. Hiser", "Anh Nguyen-Tuong", "Jack W. Davidson"], "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13505v1", "summary": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and\nsandboxes, require realistic human behavior to be effective, yet no\nquantitative method exists to assess the behavioral fidelity of synthetic user\npersonas. This paper presents PHASE (Passive Human Activity Simulation\nEvaluation), a machine learning framework that analyzes Zeek connection logs\nand distinguishes human from non-human activity with over 90\\% accuracy. PHASE\noperates entirely passively, relying on standard network monitoring without any\nuser-side instrumentation or visible signs of surveillance. All network\nactivity used for machine learning is collected via a Zeek network appliance to\navoid introducing unnecessary network traffic or artifacts that could disrupt\nthe fidelity of the simulation environment. The paper also proposes a novel\nlabeling approach that utilizes local DNS records to classify network traffic,\nthereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley\nAdditive exPlanations) analysis to uncover temporal and behavioral signatures\nindicative of genuine human users. In a case study, we evaluate a synthetic\nuser persona and identify distinct non-human patterns that undermine behavioral\nrealism. Based on these insights, we develop a revised behavioral configuration\nthat significantly improves the human-likeness of synthetic activity yielding a\nmore realistic and effective synthetic user persona.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13505v1", "cate": "cs.CR", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13591", "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning", "authors": ["Sahar Ghoflsaz Ghinani", "Elaheh Sadredini"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      15 Pages, 12 Figures", "url": "http://arxiv.org/abs/2507.13591v1", "summary": "Federated Learning (FL) enables collaborative model training without\ncentralizing client data, making it attractive for privacy-sensitive domains.\nWhile existing approaches employ cryptographic techniques such as homomorphic\nencryption, differential privacy, or secure multiparty computation to mitigate\ninference attacks-including model inversion, membership inference, and gradient\nleakage-they often suffer from high computational, communication, or memory\noverheads. Moreover, many methods overlook the confidentiality of the global\nmodel itself, which may be proprietary and sensitive. These challenges limit\nthe practicality of secure FL, especially in cross-silo deployments involving\nlarge datasets and strict compliance requirements.\n  We present FuSeFL, a fully secure and scalable FL scheme designed for\ncross-silo settings. FuSeFL decentralizes training across client pairs using\nlightweight secure multiparty computation (MPC), while confining the server's\nrole to secure aggregation. This design eliminates server bottlenecks, avoids\ndata offloading, and preserves full confidentiality of data, model, and updates\nthroughout training. FuSeFL defends against inference threats, achieves up to\n95% lower communication latency and 50% lower server memory usage, and improves\naccuracy over prior secure FL solutions, demonstrating strong security and\nefficiency at scale.", "comment": "15 Pages, 12 Figures", "pdf_url": "http://arxiv.org/pdf/2507.13591v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13598", "title": "GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention", "authors": ["Amro Abdalla", "Ismail Shaheen", "Dan DeGenaro", "Rupayan Mallick", "Bogdan Raita", "Sarah Adel Bargal"], "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13598v1", "summary": "We present GIFT: a {G}radient-aware {I}mmunization technique to defend\ndiffusion models against malicious {F}ine-{T}uning while preserving their\nability to generate safe content. Existing safety mechanisms like safety\ncheckers are easily bypassed, and concept erasure methods fail under\nadversarial fine-tuning. GIFT addresses this by framing immunization as a\nbi-level optimization problem: the upper-level objective degrades the model's\nability to represent harmful concepts using representation noising and\nmaximization, while the lower-level objective preserves performance on safe\ndata. GIFT achieves robust resistance to malicious fine-tuning while\nmaintaining safe generative quality. Experimental results show that our method\nsignificantly impairs the model's ability to re-learn harmful concepts while\nmaintaining performance on safe content, offering a promising direction for\ncreating inherently safer generative models resistant to adversarial\nfine-tuning attacks.", "comment": "Warning: This paper contains NSFW content. Reader discretion is\n  advised", "pdf_url": "http://arxiv.org/pdf/2507.13598v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13629", "title": "Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques", "authors": ["Niveen O. Jaffal", "Mohammed Alkhanafseh", "David Mohaisen"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      21 pages", "url": "http://arxiv.org/abs/2507.13629v1", "summary": "Large Language Models (LLMs) are transforming cybersecurity by enabling\nintelligent, adaptive, and automated approaches to threat detection,\nvulnerability assessment, and incident response. With their advanced language\nunderstanding and contextual reasoning, LLMs surpass traditional methods in\ntackling challenges across domains such as IoT, blockchain, and hardware\nsecurity. This survey provides a comprehensive overview of LLM applications in\ncybersecurity, focusing on two core areas: (1) the integration of LLMs into key\ncybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along\nwith mitigation strategies. By synthesizing recent advancements and identifying\nkey limitations, this work offers practical insights and strategic\nrecommendations for leveraging LLMs to build secure, scalable, and future-ready\ncyber defense systems.", "comment": "21 pages", "pdf_url": "http://arxiv.org/pdf/2507.13629v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13686", "title": "TopicAttack: An Indirect Prompt Injection Attack via Topic Transition", "authors": ["Yulin Chen", "Haoran Li", "Yuexin Li", "Yue Liu", "Yangqiu Song", "Bryan Hooi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      19 pages", "url": "http://arxiv.org/abs/2507.13686v1", "summary": "Large language models (LLMs) have shown remarkable performance across a range\nof NLP tasks. However, their strong instruction-following capabilities and\ninability to distinguish instructions from data content make them vulnerable to\nindirect prompt injection attacks. In such attacks, instructions with malicious\npurposes are injected into external data sources, such as web documents. When\nLLMs retrieve this injected data through tools, such as a search engine and\nexecute the injected instructions, they provide misled responses. Recent attack\nmethods have demonstrated potential, but their abrupt instruction injection\noften undermines their effectiveness. Motivated by the limitations of existing\nattack methods, we propose TopicAttack, which prompts the LLM to generate a\nfabricated conversational transition prompt that gradually shifts the topic\ntoward the injected instruction, making the injection smoother and enhancing\nthe plausibility and success of the attack. Through comprehensive experiments,\nTopicAttack achieves state-of-the-art performance, with an attack success rate\n(ASR) over 90\\% in most cases, even when various defense methods are applied.\nWe further analyze its effectiveness by examining attention scores. We find\nthat a higher injected-to-original attention ratio leads to a greater success\nprobability, and our method achieves a much higher ratio than the baseline\nmethods.", "comment": "19 pages", "pdf_url": "http://arxiv.org/pdf/2507.13686v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13720", "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "authors": ["Saurav Ghosh"], "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      12 Pages, 4 figures", "url": "http://arxiv.org/abs/2507.13720v1", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era.", "comment": "12 Pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.13720v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13926", "title": "Developers Insight On Manifest v3 Privacy and Security Webextensions", "authors": ["Libor Polčák", "Giorgio Maone", "Michael McMahon", "Martin Bednář"], "categories": ["cs.CR", "cs.CY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      WEBIST'25, Marbella, Spain", "url": "http://arxiv.org/abs/2507.13926v1", "summary": "Webextensions can improve web browser privacy, security, and user experience.\nThe APIs offered by the browser to webextensions affect possible functionality.\nCurrently, Chrome transitions to a modified set of APIs called Manifest v3.\nThis paper studies the challenges and opportunities of Manifest v3 with an\nin-depth structured qualitative research. Even though some projects observed\npositive effects, a majority expresses concerns over limited benefits to users,\nremoval of crucial APIs, or the need to find workarounds. Our findings indicate\nthat the transition affects different types of webextensions differently; some\ncan migrate without losing functionality, while other projects remove\nfunctionality or decline to update. The respondents identified several critical\nmissing APIs, including reliable APIs to inject content scripts, APIs for\nstoring confidential content, and others.", "comment": "WEBIST'25, Marbella, Spain", "pdf_url": "http://arxiv.org/pdf/2507.13926v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13932", "title": "Chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology", "authors": ["Feng Yu", "Ryan Laird"], "categories": ["cs.CR", "cs.DB"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13932v1", "summary": "The rise of blockchain and Digital Ledger Technology (DLT) has gained wide\ntraction. Instead of relying on a traditional centralized data authority, a\nblockchain system consists of digitally entangled block data shared across a\ndistributed network. The specially designed chain data structure and its\nconsensus mechanism protect blockchain data from being tampered by unauthorized\nadversaries. However, implementing a full-fledged blockchain system to protect\na database can be technically cumbersome. In this work, we introduce an\nin-database design, named chain table, to protect data integrity without the\nneed for a blockchain system. It features a succinct design without significant\ntechnology barriers or storage overhead. To realize rigorous data security, we\nalso propose a set of data writing principles for the chain table. We prove\nthat the chain table, together with the data writing principles, will guarantee\nflexible data integrity, named table-level data integrity (TDI).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13932v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14007", "title": "The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems", "authors": ["Serhan W. Bahar"], "categories": ["cs.CR", "cs.ET"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14007v1", "summary": "The rapid integration of blockchain, cryptocurrency, and Web3 technologies\ninto digital banks and fintech operations has created an integrated environment\nblending traditional financial systems with decentralised elements. This paper\nintroduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed\nframework designed to address the risks in these ecosystems, such as oracle\nmanipulation and cross-chain exploits. CNTMF represents a proposed extension of\nestablished methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN,\nand PASTA, while incorporating tailored components including Hybrid Layer\nAnalysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an\nAI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents,\nCNTMF supports data-driven mitigation to reduce losses, which totalled\napproximately $2.47 billion in the first half of 2025 across 344 security\nevents (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its\nphases guide asset mapping, risk profiling, prioritisation, mitigation, and\niterative feedback. This supports security against evolving risks like\nstate-sponsored attacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14007v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14109", "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting", "authors": ["Xinyu Cao", "Bimal Adhikari", "Shangqing Zhao", "Jingxian Wu", "Yanjun Pan"], "categories": ["cs.CR", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14109v1", "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14109v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13407", "title": "IConMark: Robust Interpretable Concept-Based Watermark For AI Images", "authors": ["Vinu Sankar Sadasivan", "Mehrdad Saberi", "Soheil Feizi"], "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICLR 2025 Workshop on GenAI Watermarking (WMARK)", "url": "http://arxiv.org/abs/2507.13407v1", "summary": "With the rapid rise of generative AI and synthetic media, distinguishing\nAI-generated images from real ones has become crucial in safeguarding against\nmisinformation and ensuring digital authenticity. Traditional watermarking\ntechniques have shown vulnerabilities to adversarial attacks, undermining their\neffectiveness in the presence of attackers. We propose IConMark, a novel\nin-generation robust semantic watermarking method that embeds interpretable\nconcepts into AI-generated images, as a first step toward interpretable\nwatermarking. Unlike traditional methods, which rely on adding noise or\nperturbations to AI-generated images, IConMark incorporates meaningful semantic\nattributes, making it interpretable to humans and hence, resilient to\nadversarial manipulation. This method is not only robust against various image\naugmentations but also human-readable, enabling manual verification of\nwatermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,\ndemonstrating its superiority in terms of detection accuracy and maintaining\nimage quality. Moreover, IConMark can be combined with existing watermarking\ntechniques to further enhance and complement its robustness. We introduce\nIConMark+SS and IConMark+TM, hybrid approaches combining IConMark with\nStegaStamp and TrustMark, respectively, to further bolster robustness against\nmultiple types of image manipulations. Our base watermarking technique\n(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%\nhigher mean area under the receiver operating characteristic curve (AUROC)\nscores for watermark detection, respectively, compared to the best baseline on\nvarious datasets.", "comment": "Accepted at ICLR 2025 Workshop on GenAI Watermarking (WMARK)", "pdf_url": "http://arxiv.org/pdf/2507.13407v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13508", "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations", "authors": ["Agata Kaczmarek", "Dawid Płudowski", "Piotr Wilczyński", "Przemysław Biecek", "Krzysztof Kotowski", "Ramez Shendy", "Jakub Nalepa", "Artur Janicki", "Evridiki Ntagiou"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13508v1", "summary": "The \"Fake or Real\" competition hosted on Kaggle\n(\\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})\nis the second part of a series of follow-up competitions and hackathons related\nto the \"Assurance for Space Domain AI Applications\" project funded by the\nEuropean Space Agency\n(\\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).\nThe competition idea is based on two real-life AI security threats identified\nwithin the project -- data poisoning and overreliance in Large Language Models.\nThe task is to distinguish between the proper output from LLM and the output\ngenerated under malicious modification of the LLM. As this problem was not\nextensively researched, participants are required to develop new techniques to\naddress this issue or adjust already existing ones to this problem's statement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13508v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13639", "title": "Differential Privacy in Kernelized Contextual Bandits via Random Projections", "authors": ["Nikola Pavlovic", "Sudeep Salgia", "Qing Zhao"], "categories": ["stat.ML", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13639v1", "summary": "We consider the problem of contextual kernel bandits with stochastic\ncontexts, where the underlying reward function belongs to a known Reproducing\nKernel Hilbert Space. We study this problem under an additional constraint of\nDifferential Privacy, where the agent needs to ensure that the sequence of\nquery points is differentially private with respect to both the sequence of\ncontexts and rewards. We propose a novel algorithm that achieves the\nstate-of-the-art cumulative regret of\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$\nand\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$\nover a time horizon of $T$ in the joint and local models of differential\nprivacy, respectively, where $\\gamma_T$ is the effective dimension of the\nkernel and $\\varepsilon_{\\mathrm{DP}} > 0$ is the privacy parameter. The key\ningredient of the proposed algorithm is a novel private kernel-ridge regression\nestimator which is based on a combination of private covariance estimation and\nprivate random projections. It offers a significantly reduced sensitivity\ncompared to its classical counterpart while maintaining a high prediction\naccuracy, allowing our algorithm to achieve the state-of-the-art performance\nguarantees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13639v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13814", "title": "CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education", "authors": ["Jianing Zhao", "Peng Gao", "Jiannong Cao", "Zhiyuan Wen", "Chen Chen", "Jianing Yin", "Ruosong Yang", "Bo Yuan"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      4 pages, 4 figures. Demo video available at: this https URL", "url": "http://arxiv.org/abs/2507.13814v1", "summary": "Large Language Models (LLMs) have demonstrated considerable potential in\nimproving coding education by providing support for code writing, explanation,\nand debugging. However, existing LLM-based approaches generally fail to assess\nstudents' abilities, design learning plans, provide personalized material\naligned with individual learning goals, and enable interactive learning.\nCurrent work mostly uses single LLM agents, which limits their ability to\nunderstand complex code repositories and schedule step-by-step tutoring. Recent\nresearch has shown that multi-agent LLMs can collaborate to solve complicated\nproblems in various domains like software engineering, but their potential in\nthe field of education remains unexplored. In this work, we introduce CodeEdu,\nan innovative multi-agent collaborative platform that combines LLMs with tool\nuse to provide proactive and personalized education in coding. Unlike static\npipelines, CodeEdu dynamically allocates agents and tasks to meet student\nneeds. Various agents in CodeEdu undertake certain functions specifically,\nincluding task planning, personalized material generation, real-time QA,\nstep-by-step tutoring, code execution, debugging, and learning report\ngeneration, facilitated with extensive external tools to improve task\nefficiency. Automated evaluations reveal that CodeEdu substantially enhances\nstudents' coding performance.", "comment": "4 pages, 4 figures. Demo video available at:\n  https://youtu.be/9iIVmTT4CVk", "pdf_url": "http://arxiv.org/pdf/2507.13814v1", "cate": "cs.MA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13670", "title": "Fast computational deep thermalization", "authors": ["Shantanav Chakraborty", "Soonwon Choi", "Soumik Ghosh", "Tudor Giurgică-Tiron"], "categories": ["quant-ph", "cond-mat.stat-mech", "cs.CC", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      22 pages, 1 figure", "url": "http://arxiv.org/abs/2507.13670v1", "summary": "Deep thermalization refers to the emergence of Haar-like randomness from\nquantum systems upon partial measurements. As a generalization of quantum\nthermalization, it is often associated with high complexity and entanglement.\nHere, we introduce computational deep thermalization and construct the fastest\npossible dynamics exhibiting it at infinite effective temperature. Our circuit\ndynamics produce quantum states with low entanglement in polylogarithmic depth\nthat are indistinguishable from Haar random states to any computationally\nbounded observer. Importantly, the observer is allowed to request many copies\nof the same residual state obtained from partial projective measurements on the\nstate -- this condition is beyond the standard settings of quantum\npseudorandomness, but natural for deep thermalization. In cryptographic terms,\nthese states are pseudorandom, pseudoentangled, and crucially, retain these\nproperties under local measurements. Our results demonstrate a new form of\ncomputational thermalization, where thermal-like behavior arises from\nstructured quantum states endowed with cryptographic properties, instead of\nfrom highly unstructured ensembles. The low resource complexity of preparing\nthese states suggests scalable simulations of deep thermalization using quantum\ncomputers. Our work also motivates the study of computational quantum\npseudorandomness beyond BQP observers.", "comment": "22 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.13670v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13370", "title": "H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance", "authors": ["Shijun Guo", "Haoran Xu", "Yaming Yang", "Ziyu Guan", "Wei Zhao", "Xinyi Zhang", "Yishan Song", "Jiwei Chen"], "categories": ["cs.SI", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13370v1", "summary": "The openness of social media enables the free exchange of opinions, but it\nalso presents challenges in guiding opinion evolution towards global consensus.\nExisting methods often directly modify user views or enforce cross-group\nconnections. These intrusive interventions undermine user autonomy, provoke\npsychological resistance, and reduce the efficiency of global consensus.\nAdditionally, due to the lack of a long-term perspective, promoting local\nconsensus often exacerbates divisions at the macro level. To address these\nissues, we propose the hierarchical, non-intrusive opinion guidance framework,\nH-NeiFi. It first establishes a two-layer dynamic model based on social roles,\nconsidering the behavioral characteristics of both experts and non-experts.\nAdditionally, we introduce a non-intrusive neighbor filtering method that\nadaptively controls user communication channels. Using multi-agent\nreinforcement learning (MARL), we optimize information propagation paths\nthrough a long-term reward function, avoiding direct interference with user\ninteractions. Experiments show that H-NeiFi increases consensus speed by 22.0%\nto 30.7% and maintains global convergence even in the absence of experts. This\napproach enables natural and efficient consensus guidance by protecting user\ninteraction autonomy, offering a new paradigm for social network governance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13370v1", "cate": "cs.SI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.13810", "title": "Quantum Shadows: The Dining Information Brokers", "authors": ["Theodore Andronikos", "Constantinos Bitsakos", "Konstantinos Nikas", "Georgios I. Goumas", "Nectarios Koziris"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13810v1", "summary": "This article introduces the innovative Quantum Dining Information Brokers\nProblem, presenting a novel entanglement-based quantum protocol to address it.\nThe scenario involves $n$ information brokers, all located in distinct\ngeographical regions, engaging in a metaphorical virtual dinner. The objective\nis for each broker to share a unique piece of information with all others\nsimultaneously. Unlike previous approaches, this protocol enables a fully\nparallel, single-step communication exchange among all brokers, regardless of\ntheir physical locations. A key feature of this protocol is its ability to\nensure both the anonymity and privacy of all participants are preserved,\nmeaning no broker can discern the identity of the sender behind any received\ninformation. At its core, the Quantum Dining Information Brokers Problem serves\nas a conceptual framework for achieving anonymous, untraceable, and massively\nparallel information exchange in a distributed system. The proposed protocol\nintroduces three significant advancements. First, while quantum protocols for\none-to-many simultaneous information transmission have been developed, this is,\nto the best of our knowledge, one of the first quantum protocols to facilitate\nmany-to-many simultaneous information exchange. Second, it guarantees complete\nanonymity and untraceability for all senders, a critical improvement over\nsequential applications of one-to-many protocols, which fail to ensure such\nrobust anonymity. Third, leveraging quantum entanglement, the protocol operates\nin a fully distributed manner, accommodating brokers in diverse spatial\nlocations. This approach marks a substantial advancement in secure, scalable,\nand anonymous communication, with potential applications in distributed\nenvironments where privacy and parallelism are paramount.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13810v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13616", "title": "From Firms to Computation: AI Governance and the Evolution of Institutions", "authors": ["Michael S. Harre"], "categories": ["cs.HC", "cs.CY", "cs.ET", "cs.IT", "cs.MA", "math.IT", "J.4; J.3; I.2.11"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      44 pages", "url": "http://arxiv.org/abs/2507.13616v1", "summary": "The integration of agential artificial intelligence into socioeconomic\nsystems requires us to reexamine the evolutionary processes that describe\nchanges in our economic institutions. This article synthesizes three\nframeworks: multi-level selection theory, Aoki's view of firms as computational\nprocesses, and Ostrom's design principles for robust institutions. We develop a\nframework where selection operates concurrently across organizational levels,\nfirms implement distributed inference via game-theoretic architectures, and\nOstrom-style rules evolve as alignment mechanisms that address AI-related\nrisks. This synthesis yields a multi-level Price equation expressed over nested\ngames, providing quantitative metrics for how selection and governance\nco-determine economic outcomes. We examine connections to Acemoglu's work on\ninclusive institutions, analyze how institutional structures shape AI\ndeployment, and demonstrate the framework's explanatory power via case studies.\nWe conclude by proposing a set of design principles that operationalize\nalignment between humans and AI across institutional layers, enabling scalable,\nadaptive, and inclusive governance of agential AI systems. We conclude with\npractical policy recommendations and further research to extend these\nprinciples into real-world implementation.", "comment": "44 pages", "pdf_url": "http://arxiv.org/pdf/2507.13616v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13883", "title": "Stablecoins: Fundamentals, Emerging Issues, and Open Challenges", "authors": ["Ahmed Mahrous", "Maurantonio Caprolu", "Roberto Di Pietro"], "categories": ["econ.GN", "cs.CR", "q-fin.EC"], "primary_category": "Subjects:       General Economics (econ.GN)", "pdf_link": null, "comments": "Comments:      35 pages, 10 figures. Survey paper. Submitted to Computer Science Review", "url": "http://arxiv.org/abs/2507.13883v1", "summary": "Stablecoins, with a capitalization exceeding 200 billion USD as of January\n2025, have shown significant growth, with annual transaction volumes exceeding\n10 trillion dollars in 2023 and nearly doubling that figure in 2024. This\nexceptional success has attracted the attention of traditional financial\ninstitutions, with an increasing number of governments exploring the potential\nof Central Bank Digital Currencies (CBDCs). Although academia has recognized\nthe importance of stablecoins, research in this area remains fragmented,\nincomplete, and sometimes contradictory. In this paper, we aim to address the\ncited gap with a structured literature analysis, correlating recent\ncontributions to present a picture of the complex economic, technical, and\nregulatory aspects of stablecoins. To achieve this, we formulate the main\nresearch questions and categorize scientific contributions accordingly,\nidentifying main results, data sources, methodologies, and open research\nquestions. The research questions we address in this survey paper cover several\ntopics, such as the stability of various stablecoins, novel designs and\nimplementations, and relevant regulatory challenges. The studies employ a wide\nrange of methodologies and data sources, which we critically analyze and\nsynthesize. Our analysis also reveals significant research gaps, including\nlimited studies on security and privacy, underexplored stablecoins, unexamined\nfailure cases, unstudied governance mechanisms, and the treatment of\nstablecoins under financial accounting standards, among other areas.", "comment": "35 pages, 10 figures. Survey paper. Submitted to Computer Science\n  Review", "pdf_url": "http://arxiv.org/pdf/2507.13883v1", "cate": "econ.GN", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13834", "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph", "authors": ["Aditi Anand", "Suman Banerjee", "Dildar Ali"], "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      16 Pages", "url": "http://arxiv.org/abs/2507.13834v1", "summary": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.", "comment": "16 Pages", "pdf_url": "http://arxiv.org/pdf/2507.13834v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13455", "title": "Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms", "authors": ["Dean Chen", "Armin Pomeroy", "Brandon T. Peterson", "Will Flanagan", "He Kai Lim", "Alexandra Stavrakis", "Nelson F. SooHoo", "Jonathan B. Hopkins", "Tyler R. Clites"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      42 pages, 17 figures. Under review at ASME Journal of Mechanical Design", "url": "http://arxiv.org/abs/2507.13455v1", "summary": "Compliant mechanisms have significant potential in precision applications due\nto their ability to guide motion without contact. However, an inherent\nvulnerability to fatigue and mechanical failure has hindered the translation of\ncompliant mechanisms to real-world applications. This is particularly\nchallenging in service environments where loading is complex and uncertain, and\nthe cost of failure is high. In such cases, mechanical hard stops are critical\nto prevent yielding and buckling. Conventional hard-stop designs, which rely on\nstacking single-DOF limits, must be overly restrictive in multi-DOF space to\nguarantee safety in the presence of unknown loads. In this study, we present a\nsystematic design synthesis method to guarantee overload protection in\ncompliant mechanisms by integrating coupled multi-DOF motion limits within a\nsingle pair of compact hard-stop surfaces. Specifically, we introduce a\ntheoretical and practical framework for optimizing the contact surface geometry\nto maximize the mechanisms multi-DOF working space while still ensuring that\nthe mechanism remains within its elastic regime. We apply this synthesis method\nto a case study of a caged-hinge mechanism for orthopaedic implants, and\nprovide numerical and experimental validation that the derived design offers\nreliable protection against fatigue, yielding, and buckling. This work\nestablishes a foundation for precision hard-stop design in compliant systems\noperating under uncertain loads, which is a crucial step toward enabling the\napplication of compliant mechanisms in real-world systems.", "comment": "42 pages, 17 figures. Under review at ASME Journal of Mechanical\n  Design", "pdf_url": "http://arxiv.org/pdf/2507.13455v1", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2411.00459", "title": "Defense Against Prompt Injection Attack by Leveraging Attack Techniques", "authors": ["Yulin Chen", "Haoran Li", "Zihao Zheng", "Yangqiu Song", "Dekai Wu", "Bryan Hooi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To Appear in ACL 2025", "url": "http://arxiv.org/abs/2411.00459v4", "summary": "With the advancement of technology, large language models (LLMs) have\nachieved remarkable performance across various natural language processing\n(NLP) tasks, powering LLM-integrated applications like Microsoft Copilot.\nHowever, as LLMs continue to evolve, new vulnerabilities, especially prompt\ninjection attacks arise. These attacks trick LLMs into deviating from the\noriginal input instructions and executing the attacker's instructions injected\nin data content, such as retrieved results. Recent attack methods leverage\nLLMs' instruction-following abilities and their inabilities to distinguish\ninstructions injected in the data content, and achieve a high attack success\nrate (ASR). When comparing the attack and defense methods, we interestingly\nfind that they share similar design goals, of inducing the model to ignore\nunwanted instructions and instead to execute wanted instructions. Therefore, we\nraise an intuitive question: Could these attack techniques be utilized for\ndefensive purposes? In this paper, we invert the intention of prompt injection\nmethods to develop novel defense methods based on previous training-free attack\nmethods, by repeating the attack process but with the original input\ninstruction rather than the injected instruction. Our comprehensive experiments\ndemonstrate that our defense techniques outperform existing training-free\ndefense approaches, achieving state-of-the-art results.", "comment": "To Appear in ACL 2025", "pdf_url": "http://arxiv.org/pdf/2411.00459v4", "cate": "cs.CR", "date": "2024-11-01", "updated": "2025-07-18"}
{"id": "2507.13969", "title": "A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios", "authors": ["Maria Eduarda Silva de Macedo", "Ana Paula Chiarelli de Souza", "Roberto Silvio Ubertino Rosso Jr.", "Yuri Kaszubowski Lopes"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages total (6 pages of content + 1 page of references). Short paper manuscript submitted to TAROS 2025", "url": "http://arxiv.org/abs/2507.13969v1", "summary": "The deployment of simple emergent behaviors in swarm robotics has been\nwell-rehearsed in the literature. A recent study has shown how self-aggregation\nis possible in a multitask approach -- where multiple self-aggregation task\ninstances occur concurrently in the same environment. The multitask approach\nposes new challenges, in special, how the dynamic of each group impacts the\nperformance of others. So far, the multitask self-aggregation of groups of\nrobots suffers from generating a circular formation -- that is not fully\ncompact -- or is not fully autonomous. In this paper, we present a multitask\nself-aggregation where groups of homogeneous robots sort themselves into\ndifferent compact clusters, relying solely on a line-of-sight sensor. Our\nmultitask self-aggregation behavior was able to scale well and achieve a\ncompact formation. We report scalability results from a series of simulation\ntrials with different configurations in the number of groups and the number of\nrobots per group. We were able to improve the multitask self-aggregation\nbehavior performance in terms of the compactness of the clusters, keeping the\nproportion of clustered robots found in other studies.", "comment": "7 pages total (6 pages of content + 1 page of references). Short\n  paper manuscript submitted to TAROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.13969v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13468", "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations", "authors": ["Shiye Cao", "Maia Stiber", "Amama Mahmood", "Maria Teresa Parreira", "Wendy Ju", "Micol Spitale", "Hatice Gunes", "Chien-Ming Huang"], "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13468v1", "summary": "The integration of large language models (LLMs) into conversational robots\nhas made human-robot conversations more dynamic. Yet, LLM-powered\nconversational robots remain prone to errors, e.g., misunderstanding user\nintent, prematurely interrupting users, or failing to respond altogether.\nDetecting and addressing these failures is critical for preventing\nconversational breakdowns, avoiding task disruptions, and sustaining user\ntrust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal\ndataset of LLM-powered conversational robot failures during human-robot\nconversations and encourages researchers to benchmark machine learning models\ndesigned to detect robot failures. The dataset includes 16 hours of dyadic\nhuman-robot interactions, incorporating facial, speech, and head movement\nfeatures. Each interaction is annotated with the presence or absence of robot\nerrors from the system perspective, and perceived user intention to correct for\na mismatch between robot behavior and user expectation. Participants are\ninvited to form teams and develop machine learning models that detect these\nfailures using multimodal data. Submissions will be evaluated using various\nperformance metrics, including detection accuracy and false positive rate. This\nchallenge represents another key step toward improving failure detection in\nhuman-robot interaction through social signal analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13468v1", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13511", "title": "GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination", "authors": ["Nabil Abdelaziz Ferhat Taleb", "Abdolazim Rezaei", "Raj Atulkumar Patel", "Mehdi Sookhak"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13511v1", "summary": "Large Language Models (LLMs) offer significant promise for intelligent\ntraffic management; however, current chain-based systems like TrafficGPT are\nhindered by sequential task execution, high token usage, and poor scalability,\nmaking them inefficient for complex, real-world scenarios. To address these\nlimitations, we propose GraphTrafficGPT, a novel graph-based architecture,\nwhich fundamentally redesigns the task coordination process for LLM-driven\ntraffic applications. GraphTrafficGPT represents tasks and their dependencies\nas nodes and edges in a directed graph, enabling efficient parallel execution\nand dynamic resource allocation. The main idea behind the proposed model is a\nBrain Agent that decomposes user queries, constructs optimized dependency\ngraphs, and coordinates a network of specialized agents for data retrieval,\nanalysis, visualization, and simulation. By introducing advanced context-aware\ntoken management and supporting concurrent multi-query processing, the proposed\narchitecture handles interdependent tasks typical of modern urban mobility\nenvironments. Experimental results demonstrate that GraphTrafficGPT reduces\ntoken consumption by 50.2% and average response latency by 19.0% compared to\nTrafficGPT, while supporting simultaneous multi-query execution with up to\n23.0% improvement in efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13511v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2412.17531", "title": "Invisible Textual Backdoor Attacks based on Dual-Trigger", "authors": ["Yang Hou", "Qiuling Yue", "Lujia Chai", "Guozhao Liao", "Wenbao Han", "Wei Ou"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.17531v3", "summary": "Backdoor attacks pose an important security threat to textual large language\nmodels. Exploring textual backdoor attacks not only helps reveal the potential\nsecurity risks of models, but also promotes innovation and development of\ndefense mechanisms. Currently, most textual backdoor attack methods are based\non a single trigger. For example, inserting specific content into text as a\ntrigger or changing the abstract text features to be a trigger. However, the\nadoption of this single-trigger mode makes the existing backdoor attacks\nsubject to certain limitations: either they are easily identified by the\nexisting defense strategies, or they have certain shortcomings in attack\nperformance and in the construction of poisoned datasets. In order to solve\nthese issues, a dual-trigger backdoor attack method is proposed in this paper.\nSpecifically, we use two different attributes, syntax and mood (we use\nsubjunctive mood as an example in this article), as two different triggers. It\nmakes our backdoor attack method similar to a double landmine which can have\ncompletely different trigger conditions simultaneously. Therefore, this method\nnot only improves the flexibility of trigger mode, but also enhances the\nrobustness against defense detection. A large number of experimental results\nshow that this method significantly outperforms the previous methods based on\nabstract features in attack performance, and achieves comparable attack\nperformance (almost 100\\% attack success rate) with the insertion-based method.\nIn addition, in order to further improve the attack performance, we also give\nthe construction method of the poisoned dataset.The code and data of this paper\ncan be obtained at https://github.com/HoyaAm/Double-Landmines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.17531v3", "cate": "cs.CR", "date": "2024-12-23", "updated": "2025-07-18"}
{"id": "2202.10742", "title": "Acceleration of Gossip Algorithms through the Euler-Poisson-Darboux Equation", "authors": ["Raphaël Berthier", "Mufan Bill Li"], "categories": ["cs.DC", "cs.MA"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2202.10742v2", "summary": "Gossip algorithms and their accelerated versions have been studied\nexclusively in discrete time on graphs. In this work, we take a different\napproach, and consider the scaling limit of gossip algorithms in both large\ngraphs and large number of iterations. These limits lead to well-known partial\ndifferential equations (PDEs) with insightful properties. On lattices, we prove\nthat the non-accelerated gossip algorithm of Boyd et al. [2006] converges to\nthe heat equation, and the accelerated Jacobi polynomial iteration of Berthier\net al. [2020] converges to the Euler-Poisson-Darboux (EPD) equation - a damped\nwave equation. Remarkably, with appropriate parameters, the fundamental\nsolution of the EPD equation has the ideal gossip behaviour: a uniform density\nover an ellipsoid, whose radius increases at a rate proportional to t - the\nfastest possible rate for locally communicating gossip algorithms. This is in\ncontrast with the heat equation where the density spreads on a typical scale of\n$\\sqrt{t}$. Additionally, we provide simulations demonstrating that the gossip\nalgorithms are accurately approximated by their limiting PDEs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2202.10742v2", "cate": "cs.DC", "date": "2022-02-22", "updated": "2025-07-18"}
{"id": "2507.13539", "title": "SCOPE for Hexapod Gait Generation", "authors": ["Jim O'Connor", "Jay B. Nash", "Derin Gezgin", "Gary B. Parker"], "categories": ["cs.RO", "cs.NE"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IJCCI Conference on Evolutionary Computation and Theory and Applications, 2025", "url": "http://arxiv.org/abs/2507.13539v1", "summary": "Evolutionary methods have previously been shown to be an effective learning\nmethod for walking gaits on hexapod robots. However, the ability of these\nalgorithms to evolve an effective policy rapidly degrades as the input space\nbecomes more complex. This degradation is due to the exponential growth of the\nsolution space, resulting from an increasing parameter count to handle a more\ncomplex input. In order to address this challenge, we introduce Sparse Cosine\nOptimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine\nTransform (DCT) to learn directly from the feature coefficients of an input\nmatrix. By truncating the coefficient matrix returned by the DCT, we can reduce\nthe dimensionality of an input while retaining the highest energy features of\nthe original input. We demonstrate the effectiveness of this method by using\nSCOPE to learn the gait of a hexapod robot. The hexapod controller is given a\nmatrix input containing time-series information of previous poses, which are\nthen transformed to gait parameters by an evolved policy. In this task, the\naddition of SCOPE to a reference algorithm achieves a 20% increase in efficacy.\nSCOPE achieves this result by reducing the total input size of the time-series\npose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of\ncompressing an input to any output shape, provided that each output dimension\nis no greater than the corresponding input dimension. This paper demonstrates\nthat SCOPE is capable of significantly compressing the size of an input to an\nevolved controller, resulting in a statistically significant gain in efficacy.", "comment": "IJCCI Conference on Evolutionary Computation and Theory and\n  Applications, 2025", "pdf_url": "http://arxiv.org/pdf/2507.13539v1", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13541", "title": "PrefPalette: Personalized Preference Modeling with Latent Attributes", "authors": ["Shuyue Stella Li", "Melanie Sclar", "Hunter Lang", "Ansong Ni", "Jacqueline He", "Puxin Xu", "Andrew Cohen", "Chan Young Park", "Yulia Tsvetkov", "Asli Celikyilmaz"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      17 pages, 6 tables, 5 figures", "url": "http://arxiv.org/abs/2507.13541v1", "summary": "Personalizing AI systems requires understanding not just what users prefer,\nbut the reasons that underlie those preferences - yet current preference models\ntypically treat human judgment as a black box. We introduce PrefPalette, a\nframework that decomposes preferences into attribute dimensions and tailors its\npreference prediction to distinct social community values in a\nhuman-interpretable manner. PrefPalette operationalizes a cognitive science\nprinciple known as multi-attribute decision making in two ways: (1) a scalable\ncounterfactual attribute synthesis step that involves generating synthetic\ntraining data to isolate for individual attribute effects (e.g., formality,\nhumor, cultural values), and (2) attention-based preference modeling that\nlearns how different social communities dynamically weight these attributes.\nThis approach moves beyond aggregate preference modeling to capture the diverse\nevaluation frameworks that drive human judgment. When evaluated on 45 social\ncommunities from the online platform Reddit, PrefPalette outperforms GPT-4o by\n46.6% in average prediction accuracy. Beyond raw predictive improvements,\nPrefPalette also shed light on intuitive, community-specific profiles:\nscholarly communities prioritize verbosity and stimulation, conflict-oriented\ncommunities value sarcasm and directness, and support-based communities\nemphasize empathy. By modeling the attribute-mediated structure of human\njudgment, PrefPalette delivers both superior preference modeling and\ntransparent, interpretable insights, and serves as a first step toward more\ntrustworthy, value-aware personalized applications.", "comment": "17 pages, 6 tables, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13541v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2502.16580", "title": "Can Indirect Prompt Injection Attacks Be Detected and Removed?", "authors": ["Yulin Chen", "Haoran Li", "Yuan Sui", "Yufei He", "Yue Liu", "Yangqiu Song", "Bryan Hooi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To Appear in ACL 2025", "url": "http://arxiv.org/abs/2502.16580v2", "summary": "Prompt injection attacks manipulate large language models (LLMs) by\nmisleading them to deviate from the original input instructions and execute\nmaliciously injected instructions, because of their instruction-following\ncapabilities and inability to distinguish between the original input\ninstructions and maliciously injected instructions. To defend against such\nattacks, recent studies have developed various detection mechanisms. If we\nrestrict ourselves specifically to works which perform detection rather than\ndirect defense, most of them focus on direct prompt injection attacks, while\nthere are few works for the indirect scenario, where injected instructions are\nindirectly from external tools, such as a search engine. Moreover, current\nworks mainly investigate injection detection methods and pay less attention to\nthe post-processing method that aims to mitigate the injection after detection.\nIn this paper, we investigate the feasibility of detecting and removing\nindirect prompt injection attacks, and we construct a benchmark dataset for\nevaluation. For detection, we assess the performance of existing LLMs and\nopen-source detection models, and we further train detection models using our\ncrafted training datasets. For removal, we evaluate two intuitive methods: (1)\nthe segmentation removal method, which segments the injected document and\nremoves parts containing injected instructions, and (2) the extraction removal\nmethod, which trains an extraction model to identify and remove injected\ninstructions.", "comment": "To Appear in ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.16580v2", "cate": "cs.CR", "date": "2025-02-23", "updated": "2025-07-18"}
{"id": "2506.09046", "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.09046v2", "summary": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.09046v2", "cate": "cs.LG", "date": "2025-06-10", "updated": "2025-07-18"}
{"id": "2507.13602", "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force", "authors": ["Shivakanth Sujit", "Luca Nunziante", "Dan Ogawa Lillrank", "Rousslan Fernand Julien Dossa", "Kai Arulkumaran"], "categories": ["cs.RO", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 IEEE/SICE International Symposium on System Integration", "url": "http://arxiv.org/abs/2507.13602v1", "summary": "In this work we extend the low-cost GELLO teleoperation system, initially\ndesigned for joint position control, with additional force information. Our\nfirst extension is to implement force feedback, allowing users to feel\nresistance when interacting with the environment. Our second extension is to\nadd force information into the data collection process and training of\nimitation learning models. We validate our additions by implementing these on a\nGELLO system with a Franka Panda arm as the follower robot, performing a user\nstudy, and comparing the performance of policies trained with and without force\ninformation on a range of simulated and real dexterous manipulation tasks.\nQualitatively, users with robotics experience preferred our controller, and the\naddition of force inputs improved task success on the majority of tasks.", "comment": "Accepted at the 2025 IEEE/SICE International Symposium on System\n  Integration", "pdf_url": "http://arxiv.org/pdf/2507.13602v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13550", "title": "GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models", "authors": ["Eduardo C. Garrido-Merchán", "Cristina Puente"], "categories": ["cs.AI", "cs.CL", "cs.SC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13550v1", "summary": "The development of large language models (LLMs) has successfully transformed\nknowledge-based systems such as open domain question nswering, which can\nautomatically produce vast amounts of seemingly coherent information. Yet,\nthose models have several disadvantages like hallucinations or confident\ngeneration of incorrect or unverifiable facts. In this paper, we introduce a\nnew approach to the development of expert systems using LLMs in a controlled\nand transparent way. By limiting the domain and employing a well-structured\nprompt-based extraction approach, we produce a symbolic representation of\nknowledge in Prolog, which can be validated and corrected by human experts.\nThis approach also guarantees interpretability, scalability and reliability of\nthe developed expert systems. Via quantitative and qualitative experiments with\nClaude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic\ncoherence on our generated knowledge bases. We present a transparent hybrid\nsolution that combines the recall capacity of LLMs with the precision of\nsymbolic systems, thereby laying the foundation for dependable AI applications\nin sensitive domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13550v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2505.01454", "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning", "authors": ["Zhiyong Jin", "Runhua Xu", "Chao Li", "Yizhong Liu", "Jianxin Li"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.01454v3", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy, yet it faces significant\nchallenges in communication efficiency and vulnerability to poisoning attacks.\nWhile sparsification techniques mitigate communication overhead by transmitting\nonly critical model parameters, they inadvertently amplify security risks:\nadversarial clients can exploit sparse updates to evade detection and degrade\nmodel performance. Existing defense mechanisms, designed for standard FL\ncommunication scenarios, are ineffective in addressing these vulnerabilities\nwithin sparsified FL. To bridge this gap, we propose FLARE, a novel federated\nlearning framework that integrates sparse index mask inspection and model\nupdate sign similarity analysis to detect and mitigate poisoning attacks in\nsparsified FL. Extensive experiments across multiple datasets and adversarial\nscenarios demonstrate that FLARE significantly outperforms existing defense\nstrategies, effectively securing sparsified FL against poisoning attacks while\nmaintaining communication efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.01454v3", "cate": "cs.CR", "date": "2025-04-30", "updated": "2025-07-18"}
{"id": "2507.13647", "title": "Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones", "authors": ["Minze Li", "Wei Zhao", "Ran Chen", "Mingqiang Wei"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 papers,7 figures", "url": "http://arxiv.org/abs/2507.13647v1", "summary": "Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic\nenvironments remains a key challenge due to high computational demands and the\nneed for fast, adaptive responses. Traditional Particle Swarm Optimization\n(PSO) methods, while effective for offline planning, often struggle with\npremature convergence and latency in real-time scenarios. To overcome these\nlimitations, we propose PE-PSO, an enhanced PSO-based online trajectory\nplanner. The method introduces a persistent exploration mechanism to preserve\nswarm diversity and an entropy-based parameter adjustment strategy to\ndynamically adapt optimization behavior. UAV trajectories are modeled using\nB-spline curves, which ensure path smoothness while reducing optimization\ncomplexity. To extend this capability to UAV swarms, we develop a multi-agent\nframework that combines genetic algorithm (GA)-based task allocation with\ndistributed PE-PSO, supporting scalable and coordinated trajectory generation.\nThe distributed architecture allows for parallel computation and decentralized\ncontrol, enabling effective cooperation among agents while maintaining\nreal-time performance. Comprehensive simulations demonstrate that the proposed\nframework outperforms conventional PSO and other swarm-based planners across\nseveral metrics, including trajectory quality, energy efficiency, obstacle\navoidance, and computation time. These results confirm the effectiveness and\napplicability of PE-PSO in real-time multi-UAV operations under complex\nenvironmental conditions.", "comment": "8 papers,7 figures", "pdf_url": "http://arxiv.org/pdf/2507.13647v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13558", "title": "Why Isn't Relational Learning Taking Over the World?", "authors": ["David Poole"], "categories": ["cs.AI", "cs.DB", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      10 pages (6 pages + references + appendices)", "url": "http://arxiv.org/abs/2507.13558v1", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "comment": "10 pages (6 pages + references + appendices)", "pdf_url": "http://arxiv.org/pdf/2507.13558v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.05630", "title": "How Not to Detect Prompt Injections with an LLM", "authors": ["Sarthak Choudhary", "Divyam Anshumaan", "Nils Palumbo", "Somesh Jha"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05630v2", "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, in which adversaries embed malicious instructions within seemingly\nbenign user inputs to manipulate the LLM's intended behavior. Recent defenses\nbased on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect\nperformance by using an LLM to classify inputs as clean or contaminated. In\nthis work, we formally characterize the KAD framework and uncover a structural\nvulnerability in its design that invalidates its core security premise. We\ndesign a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this\nfundamental weakness. It consistently evades KAD defenses with detection rates\nas low as $1.5\\%$ while reliably inducing malicious behavior with success rates\nof up to $88\\%$, without needing white-box access to the LLM or any\noptimization procedures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05630v2", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-17"}
{"id": "2507.13650", "title": "Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography", "authors": ["Yu-Ting Lai", "Yasamin Foroutani", "Aya Barzelay", "Tsu-Chin Tsao"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      12 pages, 27 figures", "url": "http://arxiv.org/abs/2507.13650v1", "summary": "Secondary cataract is one of the most common complications of vision loss due\nto the proliferation of residual lens materials that naturally grow on the lens\ncapsule after cataract surgery. A potential treatment is capsule cleaning, a\nsurgical procedure that requires enhanced visualization of the entire capsule\nand tool manipulation on the thin membrane. This article presents a robotic\nsystem capable of performing the capsule cleaning procedure by integrating a\nstandard transpupillary and an intraocular optical coherence tomography probe\non a surgical instrument for equatorial capsule visualization and real-time\ntool-to-tissue distance feedback. Using robot precision, the developed system\nenables complete capsule mapping in the pupillary and equatorial regions with\nin-situ calibration of refractive index and fiber offset, which are still\ncurrent challenges in obtaining an accurate capsule model. To demonstrate\neffectiveness, the capsule mapping strategy was validated through five\nexperimental trials on an eye phantom that showed reduced root-mean-square\nerrors in the constructed capsule model, while the cleaning strategy was\nperformed in three ex-vivo pig eyes without tissue damage.", "comment": "12 pages, 27 figures", "pdf_url": "http://arxiv.org/pdf/2507.13650v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13625", "title": "BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety", "authors": ["Yuxin Zhang", "Xi Wang", "Mo Hu", "Zhenyu Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages, 13 figures", "url": "http://arxiv.org/abs/2507.13625v1", "summary": "Information retrieval and question answering from safety regulations are\nessential for automated construction compliance checking but are hindered by\nthe linguistic and structural complexity of regulatory text. Many\ncompliance-related queries are multi-hop, requiring synthesis of information\nacross interlinked clauses. This poses a challenge for traditional\nretrieval-augmented generation (RAG) systems. To overcome this, we introduce\nBifrostRAG: a dual-graph RAG-integrated system that explicitly models both\nlinguistic relationships (via an Entity Network Graph) and document structure\n(via a Document Navigator Graph). This architecture powers a hybrid retrieval\nmechanism that combines graph traversal with vector-based semantic search,\nenabling large language models to reason over both the meaning and the\nstructure of the text. Evaluation on a multi-hop question dataset shows that\nBifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1\nscore of 87.3 percent. These results significantly outperform vector-only and\ngraph-only RAG baselines that represent current leading approaches. Error\nanalysis further highlights the comparative advantages of our hybrid method\nover single-modality RAGs. These findings establish BifrostRAG as a robust\nknowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid\nretrieval mechanism offers a transferable blueprint for navigating complex\ntechnical documents across knowledge-intensive engineering domains.", "comment": "19 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.13625v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13354", "title": "Physical models realizing the transformer architecture of large language models", "authors": ["Zeqian Chen"], "categories": ["cs.LG", "cs.AI", "cs.CL", "math-ph", "math.MP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.13354v1", "summary": "The introduction of the transformer architecture in 2017 (cf.\\cite{VSP2017})\nmarked the most striking advancement in natural language processing. The\ntransformer is a model architecture relying entirely on an attention mechanism\nto draw global dependencies between input and output. However, we believe there\nis a gap in our theoretical understanding of what the transformer is, and why\nit works physically. In this paper, from a physical perspective on modern\nchips, we construct physical models in the Fock space over the Hilbert space of\ntokens realizing large language models based on a transformer architecture as\nopen quantum systems. Our physical models underlie the transformer architecture\nfor large language models.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.13354v1", "cate": "cs.LG", "date": "2025-05-21", "updated": "2025-05-21"}
{"id": "2305.14080", "title": "Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and Privacy Challenges", "authors": ["Efe Bozkir", "Süleyman Özdel", "Mengdi Wang", "Brendan David-John", "Hong Gao", "Kevin Butler", "Eakta Jain", "Enkelejda Kasneci"], "categories": ["cs.HC", "cs.AI", "cs.CR", "cs.GR", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2305.14080v2", "summary": "The latest developments in computer hardware, sensor technologies, and\nartificial intelligence can make virtual reality (VR) and virtual spaces an\nimportant part of human everyday life. Eye tracking offers not only a\nhands-free way of interaction but also the possibility of a deeper\nunderstanding of human visual attention and cognitive processes in VR. Despite\nthese possibilities, eye-tracking data also reveals users' privacy-sensitive\nattributes when combined with the information about the presented stimulus. To\naddress all these possibilities and potential privacy issues, in this survey,\nwe first cover major works in eye tracking, VR, and privacy areas between 2012\nand 2022. While eye tracking in the VR part covers the complete pipeline of\neye-tracking methodology from pupil detection and gaze estimation to offline\nuse of the data and analyses, as for privacy and security, we focus on\neye-based authentication as well as computational methods to preserve the\nprivacy of individuals and their eye-tracking data in VR. Later, considering\nall of these, we draw three main directions for the research community by\nfocusing on privacy challenges. In summary, this survey provides an extensive\nliterature review of the utmost possibilities with eye tracking in VR and the\nprivacy implications of those possibilities.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2305.14080v2", "cate": "cs.HC", "date": "2023-05-23", "updated": "2025-07-18"}
{"id": "2507.13654", "title": "A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment", "authors": ["Haoran Wang", "Yasamin Foroutani", "Matthew Nepo", "Mercedes Rodriguez", "Ji Ma", "Jean-Pierre Hubschman", "Tsu-Chin Tsao", "Jacob Rosen"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages, 11 figures", "url": "http://arxiv.org/abs/2507.13654v1", "summary": "This paper examines the performance of Inside and Outside Control modes at\nvarious scaling factors in a simulated vitreoretinal surgical setting. The\nIRISS teleoperated surgical system's console (cockpit) was adapted to project a\nsimulated microscope view of an intraocular setup to a virtual reality (VR)\nheadset. Five experienced vitreoretinal surgeons and five engineers with no\nsurgical experience used the system to perform tasks common to vitreoretinal\nsurgery. Experimental results indicate that Inside Control methods at higher\nscaling factors (20 or 30) achieved the best performance overall, though the\noptimal scaling factor may vary by task and complexity. Optimizing control\nmethods and scaling factors could lead to improvements in surgical efficiency\nand accuracy, as well as minimize risks in future robotic-assisted intraocular\nprocedures.", "comment": "9 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.13654v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13651", "title": "Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13651v1", "summary": "Many intelligent tutoring systems can support a student in solving a stepwise\ntask. When a student combines several steps in one step, the number of possible\npaths connecting consecutive inputs may be very large. This combinatorial\nexplosion makes error diagnosis hard. Using a final answer to diagnose a\ncombination of steps can mitigate the combinatorial explosion, because there\nare generally fewer possible (erroneous) final answers than (erroneous)\nsolution paths. An intermediate input for a task can be diagnosed by\nautomatically completing it according to the task solution strategy and\ndiagnosing this solution. This study explores the potential of automated error\ndiagnosis based on a final answer. We investigate the design of a service that\nprovides a buggy rule diagnosis when a student combines several steps. To\nvalidate the approach, we apply the service to an existing dataset (n=1939) of\nunique student steps when solving quadratic equations, which could not be\ndiagnosed by a buggy rule service that tries to connect consecutive inputs with\na single rule. Results show that final answer evaluation can diagnose 29,4% of\nthese steps. Moreover, a comparison of the generated diagnoses with teacher\ndiagnoses on a subset (n=115) shows that the diagnoses align in 97% of the\ncases. These results can be considered a basis for further exploration of the\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13651v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13383", "title": "Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models", "authors": ["Charvi Rastogi", "Tian Huey Teh", "Pushkar Mishra", "Roma Patel", "Ding Wang", "Mark Díaz", "Alicia Parrish", "Aida Mostafazadeh Davani", "Zoe Ashwood", "Michela Paganini", "Vinodkumar Prabhakaran", "Verena Rieser", "Lora Aroyo"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      28 pages, 16 figures", "url": "http://arxiv.org/abs/2507.13383v1", "summary": "Current text-to-image (T2I) models often fail to account for diverse human\nexperiences, leading to misaligned systems. We advocate for pluralistic\nalignment, where an AI understands and is steerable towards diverse, and often\nconflicting, human values. Our work provides three core contributions to\nachieve this in T2I models. First, we introduce a novel dataset for Diverse\nIntersectional Visual Evaluation (DIVE) -- the first multimodal dataset for\npluralistic alignment. It enable deep alignment to diverse safety perspectives\nthrough a large pool of demographically intersectional human raters who\nprovided extensive feedback across 1000 prompts, with high replication,\ncapturing nuanced safety perceptions. Second, we empirically confirm\ndemographics as a crucial proxy for diverse viewpoints in this domain,\nrevealing significant, context-dependent differences in harm perception that\ndiverge from conventional evaluations. Finally, we discuss implications for\nbuilding aligned T2I models, including efficient data collection strategies,\nLLM judgment capabilities, and model steerability towards diverse perspectives.\nThis research offers foundational tools for more equitable and aligned T2I\nsystems. Content Warning: The paper includes sensitive content that may be\nharmful.", "comment": "28 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.13383v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2501.01593", "title": "BLAST: A Stealthy Backdoor Leverage Attack against Cooperative Multi-Agent Deep Reinforcement Learning based Systems", "authors": ["Jing Fang", "Saihao Yan", "Xueyu Yin", "Yinbo Yu", "Chunwei Tian", "Jiajia Liu"], "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      12. arXiv admin note: substantial text overlap with arXiv:2409.07775", "url": "http://arxiv.org/abs/2501.01593v2", "summary": "Recent studies have shown that cooperative multi-agent deep reinforcement\nlearning (c-MADRL) is under the threat of backdoor attacks. Once a backdoor\ntrigger is observed, it will perform malicious actions leading to failures or\nmalicious goals. However, existing backdoor attacks suffer from several issues,\ne.g., instant trigger patterns lack stealthiness, the backdoor is trained or\nactivated by an additional network, or all agents are backdoored. To this end,\nin this paper, we propose a novel backdoor leverage attack against c-MADRL,\nBLAST, which attacks the entire multi-agent team by embedding the backdoor only\nin a single agent. Firstly, we introduce adversary spatiotemporal behavior\npatterns as the backdoor trigger rather than manual-injected fixed visual\npatterns or instant status and control the period to perform malicious actions.\nThis method can guarantee the stealthiness and practicality of BLAST. Secondly,\nwe hack the original reward function of the backdoor agent via unilateral\nguidance to inject BLAST, so as to achieve the \\textit{leverage attack effect}\nthat can pry open the entire multi-agent system via a single backdoor agent. We\nevaluate our BLAST against 3 classic c-MADRL algorithms (VDN, QMIX, and MAPPO)\nin 2 popular c-MADRL environments (SMAC and Pursuit), and 2 existing defense\nmechanisms. The experimental results demonstrate that BLAST can achieve a high\nattack success rate while maintaining a low clean performance variance rate.", "comment": "12. arXiv admin note: substantial text overlap with arXiv:2409.07775", "pdf_url": "http://arxiv.org/pdf/2501.01593v2", "cate": "cs.AI", "date": "2025-01-03", "updated": "2025-07-18"}
{"id": "2507.13662", "title": "Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion", "authors": ["Jing Cheng", "Yasser G. Alqaham", "Zhenyu Gan", "Amit K. Sanyal"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13662v1", "summary": "This paper presents a scalable and adaptive control framework for legged\nrobots that integrates Iterative Learning Control (ILC) with a biologically\ninspired torque library (TL), analogous to muscle memory. The proposed method\naddresses key challenges in robotic locomotion, including accurate trajectory\ntracking under unmodeled dynamics and external disturbances. By leveraging the\nrepetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the\nframework enhances accuracy and generalization across diverse locomotion\nscenarios. The control architecture is data-enabled, combining a physics-based\nmodel derived from hybrid-system trajectory optimization with real-time\nlearning to compensate for model uncertainties and external disturbances. A\ncentral contribution is the development of a generalized TL that stores learned\ncontrol profiles and enables rapid adaptation to changes in speed, terrain, and\ngravitational conditions-eliminating the need for repeated learning and\nsignificantly reducing online computation. The approach is validated on the\nbipedal robot Cassie and the quadrupedal robot A1 through extensive simulations\nand hardware experiments. Results demonstrate that the proposed framework\nreduces joint tracking errors by up to 85% within a few seconds and enables\nreliable execution of both periodic and nonperiodic gaits, including slope\ntraversal and terrain adaptation. Compared to state-of-the-art whole-body\ncontrollers, the learned skills eliminate the need for online computation\nduring execution and achieve control update rates exceeding 30x those of\nexisting methods. These findings highlight the effectiveness of integrating ILC\nwith torque memory as a highly data-efficient and practical solution for legged\nlocomotion in unstructured and dynamic environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13662v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13652", "title": "Combining model tracing and constraint-based modeling for multistep strategy diagnoses", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13652v1", "summary": "Model tracing and constraint-based modeling are two approaches to diagnose\nstudent input in stepwise tasks. Model tracing supports identifying consecutive\nproblem-solving steps taken by a student, whereas constraint-based modeling\nsupports student input diagnosis even when several steps are combined into one\nstep. We propose an approach that merges both paradigms. By defining\nconstraints as properties that a student input has in common with a step of a\nstrategy, it is possible to provide a diagnosis when a student deviates from a\nstrategy even when the student combines several steps. In this study we explore\nthe design of a system for multistep strategy diagnoses, and evaluate these\ndiagnoses. As a proof of concept, we generate diagnoses for an existing dataset\ncontaining steps students take when solving quadratic equations (n=2136). To\ncompare with human diagnoses, two teachers coded a random sample of deviations\n(n=70) and applications of the strategy (n=70). Results show that that the\nsystem diagnosis aligned with the teacher coding in all of the 140 student\nsteps.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13652v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13393", "title": "Improving KAN with CDF normalization to quantiles", "authors": ["Jakub Strawa", "Jarek Duda"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages, 9 figures", "url": "http://arxiv.org/abs/2507.13393v1", "summary": "Data normalization is crucial in machine learning, usually performed by\nsubtracting the mean and dividing by standard deviation, or by rescaling to a\nfixed range. In copula theory, popular in finance, there is used normalization\nto approximately quantiles by transforming x to CDF(x) with estimated CDF\n(cumulative distribution function) to nearly uniform distribution in [0,1],\nallowing for simpler representations which are less likely to overfit. It seems\nnearly unknown in machine learning, therefore, we would like to present some\nits advantages on example of recently popular Kolmogorov-Arnold Networks\n(KANs), improving predictions from Legendre-KAN by just switching rescaling to\nCDF normalization. Additionally, in HCR interpretation, weights of such neurons\nare mixed moments providing local joint distribution models, allow to propagate\nalso probability distributions, and change propagation direction.", "comment": "7 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.13393v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2503.18890", "title": "Public-Key Quantum Money and Fast Real Transforms", "authors": ["Jake Doliskani", "Morteza Mirzaei", "Ali Mousavi"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.18890v3", "summary": "We propose a public-key quantum money scheme based on group actions and the\nHartley transform. Our scheme adapts the quantum money scheme of Zhandry\n(2024), replacing the Fourier transform with the Hartley transform. This\nsubstitution ensures the banknotes have real amplitudes rather than complex\namplitudes, which could offer both computational and theoretical advantages.\n  To support this new construction, we propose a new verification algorithm\nthat uses group action twists to address verification failures caused by the\nswitch to real amplitudes. We also show how to efficiently compute the serial\nnumber associated with a money state using a new algorithm based on\ncontinuous-time quantum walks. Finally, we present a recursive algorithm for\nthe quantum Hartley transform, achieving lower gate complexity than prior work\nand demonstrate how to compute other real quantum transforms, such as the\nquantum sine transform, using the quantum Hartley transform as a subroutine.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.18890v3", "cate": "quant-ph", "date": "2025-03-24", "updated": "2025-07-17"}
{"id": "2507.13702", "title": "SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization", "authors": ["Junho Choi", "Kihwan Ryoo", "Jeewon Kim", "Taeyun Kim", "Eungchang Lee", "Myeongwoo Jeong", "Kevin Christiansen Marsim", "Hyungtae Lim", "Hyun Myung"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "url": "http://arxiv.org/abs/2507.13702v1", "summary": "Multi-robot localization is a crucial task for implementing multi-robot\nsystems. Numerous researchers have proposed optimization-based multi-robot\nlocalization methods that use camera, IMU, and UWB sensors. Nevertheless,\ncharacteristics of individual robot odometry estimates and distance\nmeasurements between robots used in the optimization are not sufficiently\nconsidered. In addition, previous researches were heavily influenced by the\nodometry accuracy that is estimated from individual robots. Consequently,\nlong-term drift error caused by error accumulation is potentially inevitable.\nIn this paper, we propose a novel visual-inertial-range-based multi-robot\nlocalization method, named SaWa-ML, which enables geometric structure-aware\npose correction and weight adaptation-based robust multi-robot localization.\nOur contributions are twofold: (i) we leverage UWB sensor data, whose range\nerror does not accumulate over time, to first estimate the relative positions\nbetween robots and then correct the positions of each robot, thus reducing\nlong-term drift errors, (ii) we design adaptive weights for robot pose\ncorrection by considering the characteristics of the sensor data and\nvisual-inertial odometry estimates. The proposed method has been validated in\nreal-world experiments, showing a substantial performance increase compared\nwith state-of-the-art algorithms.", "comment": "This paper has been accepted to the 2025 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "pdf_url": "http://arxiv.org/pdf/2507.13702v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13737", "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13737v1", "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13737v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13399", "title": "Selective Embedding for Deep Learning", "authors": ["Mert Sehri", "Zehui Hua", "Francisco de Assis Boldt", "Patrick Dumond"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13399v1", "summary": "Deep learning has revolutionized many industries by enabling models to\nautomatically learn complex patterns from raw data, reducing dependence on\nmanual feature engineering. However, deep learning algorithms are sensitive to\ninput data, and performance often deteriorates under nonstationary conditions\nand across dissimilar domains, especially when using time-domain data.\nConventional single-channel or parallel multi-source data loading strategies\neither limit generalization or increase computational costs. This study\nintroduces selective embedding, a novel data loading strategy, which alternates\nshort segments of data from multiple sources within a single input channel.\nDrawing inspiration from cognitive psychology, selective embedding mimics\nhuman-like information processing to reduce model overfitting, enhance\ngeneralization, and improve computational efficiency. Validation is conducted\nusing six time-domain datasets, demonstrating that the proposed method\nconsistently achieves high classification accuracy across various deep learning\narchitectures while significantly reducing training times. The approach proves\nparticularly effective for complex systems with multiple data sources, offering\na scalable and resource-efficient solution for real-world applications in\nhealthcare, heavy machinery, marine, railway, and agriculture, where robustness\nand adaptability are critical.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13399v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13524", "title": "Humans learn to prefer trustworthy AI over human partners", "authors": ["Yaomin Jiang", "Levin Brinkmann", "Anne-Marie Nussberger", "Ivan Soraperra", "Jean-François Bonnefon", "Iyad Rahwan"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13524v1", "summary": "Partner selection is crucial for cooperation and hinges on communication. As\nartificial agents, especially those powered by large language models (LLMs),\nbecome more autonomous, intelligent, and persuasive, they compete with humans\nfor partnerships. Yet little is known about how humans select between human and\nAI partners and adapt under AI-induced competition pressure. We constructed a\ncommunication-based partner selection game and examined the dynamics in hybrid\nmini-societies of humans and bots powered by a state-of-the-art LLM. Through\nthree experiments (N = 975), we found that bots, though more prosocial than\nhumans and linguistically distinguishable, were not selected preferentially\nwhen their identity was hidden. Instead, humans misattributed bots' behaviour\nto humans and vice versa. Disclosing bots' identity induced a dual effect: it\nreduced bots' initial chances of being selected but allowed them to gradually\noutcompete humans by facilitating human learning about the behaviour of each\npartner type. These findings show how AI can reshape social interaction in\nmixed societies and inform the design of more effective and cooperative hybrid\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13524v1", "cate": "cs.HC", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.09067", "title": "Quantum-Resilient Privacy Ledger (QRPL): A Sovereign Digital Currency for the Post-Quantum Era", "authors": ["Serhan W. Bahar"], "categories": ["cs.ET", "cs.CR"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09067v2", "summary": "The emergence of quantum computing presents profound challenges to existing\ncryptographic infrastructures, whilst the development of central bank digital\ncurrencies (CBDCs) has raised concerns regarding privacy preservation and\nexcessive centralisation in digital payment systems. This paper proposes the\nQuantum-Resilient Privacy Ledger (QRPL) as an innovative token-based digital\ncurrency architecture that incorporates National Institute of Standards and\nTechnology (NIST)-standardised post-quantum cryptography (PQC) with hash-based\nzero-knowledge proofs to ensure user sovereignty, scalability, and transaction\nconfidentiality. Key contributions include adaptations of ephemeral proof\nchains for unlinkable transactions, a privacy-weighted Proof-of-Stake (PoS)\nconsensus to promote equitable participation, and a novel zero-knowledge\nproof-based mechanism for privacy-preserving selective disclosure. QRPL aims to\naddress critical shortcomings in prevailing CBDC designs, including risks of\npervasive surveillance, with a 10-20 second block time to balance security and\nthroughput in future monetary systems. While conceptual, empirical prototypes\nare planned. Future work includes prototype development to validate these\nmodels empirically.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09067v2", "cate": "cs.ET", "date": "2025-07-11", "updated": "2025-07-18"}
{"id": "2507.13729", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "authors": ["Yu Yao", "Salil Bhatnagar", "Markus Mazzola", "Vasileios Belagiannis", "Igor Gilitschenski", "Luigi Palmieri", "Simon Razniewski", "Marcel Hallgarten"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13729v1", "summary": "Rare, yet critical, scenarios pose a significant challenge in testing and\nevaluating autonomous driving planners. Relying solely on real-world driving\nscenes requires collecting massive datasets to capture these scenarios. While\nautomatic generation of traffic scenarios appears promising, data-driven models\nrequire extensive training data and often lack fine-grained control over the\noutput. Moreover, generating novel scenarios from scratch can introduce a\ndistributional shift from the original training scenes which undermines the\nvalidity of evaluations especially for learning-based planners. To sidestep\nthis, recent work proposes to generate challenging scenarios by augmenting\noriginal scenarios from the test set. However, this involves the manual\naugmentation of scenarios by domain experts. An approach that is unable to meet\nthe demands for scale in the evaluation of self-driving systems. Therefore,\nthis paper introduces a novel LLM-agent based framework for augmenting\nreal-world traffic scenarios using natural language descriptions, addressing\nthe limitations of existing methods. A key innovation is the use of an agentic\ndesign, enabling fine-grained control over the output and maintaining high\nperformance even with smaller, cost-effective LLMs. Extensive human expert\nevaluation demonstrates our framework's ability to accurately adhere to user\nintent, generating high quality augmented scenarios comparable to those created\nmanually.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13729v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13759", "title": "OntView: What you See is What you Meant", "authors": ["Carlos Bobed", "Carlota Quintana", "Eduardo Mena", "Jorge Bobed", "Fernando Bobillo"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13759v1", "summary": "In the field of knowledge management and computer science, ontologies provide\na structured framework for modeling domain-specific knowledge by defining\nconcepts and their relationships. However, the lack of tools that provide\neffective visualization is still a significant challenge. While numerous\nontology editors and viewers exist, most of them fail to graphically represent\nontology structures in a meaningful and non-overwhelming way, limiting users'\nability to comprehend dependencies and properties within large ontological\nframeworks.\n  In this paper, we present OntView, an ontology viewer that is designed to\nprovide users with an intuitive visual representation of ontology concepts and\ntheir formal definitions through a user-friendly interface. Building on the use\nof a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm,\nshowing the actual inferred knowledge. One key aspect for this is its ability\nto visualize General Concept Inclusions (GCI), a feature absent in existing\nvisualization tools. Moreover, to avoid a possible information overload,\nOntView also offers different ways to show a simplified view of the ontology\nby: 1) creating ontology summaries by assessing the importance of the concepts\n(according to different available algorithms), 2) focusing the visualization on\nthe existing TBox elements between two given classes and 3) allowing to\nhide/show different branches in a dynamic way without losing the semantics.\nOntView has been released with an open-source license for the whole community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13759v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13413", "title": "LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data", "authors": ["Aleksey Lapin", "Igor Hromov", "Stanislav Chumakov", "Mile Mitrovic", "Dmitry Simakov", "Nikolay O. Nikitin", "Andrey V. Savchenko"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 2 figures", "url": "http://arxiv.org/abs/2507.13413v1", "summary": "AutoML has advanced in handling complex tasks using the integration of LLMs,\nyet its efficiency remains limited by dependence on specific underlying tools.\nIn this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for\ntasks with tabular data, which combines an LLM-based code generation with\nseveral AutoML tools. Our approach improves the flexibility and robustness of\npipeline design, outperforming state-of-the-art open-source solutions on\nseveral data science tasks from Kaggle. The code of LightAutoDS-Tab is\navailable in the open repository https://github.com/sb-ai-lab/LADS", "comment": "11 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.13413v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13528", "title": "Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface", "authors": ["Daniele Masti", "Stefano Menchetti", "Çağrı Erdem", "Giorgio Gnecco", "Davide Rocchesso"], "categories": ["cs.HC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13528v1", "summary": "TickTacking is a rhythm-based interface that allows users to control a\npointer in a two-dimensional space through dual-button tapping. This paper\ninvestigates the generation of human-like trajectories using a receding horizon\napproach applied to the TickTacking interface in a target-tracking task. By\nanalyzing user-generated trajectories, we identify key human behavioral\nfeatures and incorporate them in a controller that mimics these behaviors. The\nperformance of this human-inspired controller is evaluated against a baseline\noptimal-control-based agent, demonstrating the importance of specific control\nfeatures for achieving human-like interaction. These findings contribute to the\nbroader goal of developing rhythm-based human-machine interfaces by offering\ndesign insights that enhance user performance, improve intuitiveness, and\nreduce interaction frustration", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13528v1", "cate": "cs.HC", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13601", "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13601v1", "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13601v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13787", "title": "Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery", "authors": ["Doina Pisla", "Alexandru Pusca", "Andrei Caprariu", "Adrian Pisla", "Bogdan Gherman", "Calin Vaida", "Damien Chablat"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13787v1", "summary": "This paper focuses on the design of a parallel robot designed for robotic\nassisted minimally invasive pancreatic surgery. Two alternative architectures,\ncalled ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are\nproposed. Their kinematic schemes are presented, and the conceptual 3D CAD\nmodels are illustrated. Based on these, two Finite Element Method (FEM)\nsimulations were performed to determine which architecture has the higher\nstiffness. A workspace quantitative analysis is performed to further assess the\nusability of the two proposed parallel architectures related to the medical\ntasks. The obtained results are used to select the architecture which fit the\nrequired design criteria and will be used to develop the experimental model of\nthe surgical robot.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13787v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13768", "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning", "authors": ["Renato Ghisellini", "Remo Pareschi", "Marco Pedroni", "Giovanni Battista Raggi"], "categories": ["cs.AI", "I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Peer-reviewed full paper accepted through a double-blind review process at the HAR 2025 conference ( this https URL ). The official version will appear in a volume of the Lecture Notes in Computer Science (LNCS) series", "url": "http://arxiv.org/abs/2507.13768v1", "summary": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.", "comment": "Peer-reviewed full paper accepted through a double-blind review\n  process at the HAR 2025 conference (https://har-conf.eu/). The official\n  version will appear in a volume of the Lecture Notes in Computer Science\n  (LNCS) series", "pdf_url": "http://arxiv.org/pdf/2507.13768v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13414", "title": "Gauge Flow Models", "authors": ["Alexander Strunk", "Roland Assam"], "categories": ["cs.LG", "cs.AI", "math.DG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13414v1", "summary": "This paper introduces Gauge Flow Models, a novel class of Generative Flow\nModels. These models incorporate a learnable Gauge Field within the Flow\nOrdinary Differential Equation (ODE). A comprehensive mathematical framework\nfor these models, detailing their construction and properties, is provided.\nExperiments using Flow Matching on Gaussian Mixture Models demonstrate that\nGauge Flow Models yields significantly better performance than traditional Flow\nModels of comparable or even larger size. Additionally, unpublished research\nindicates a potential for enhanced performance across a broader range of\ngenerative tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13414v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13578", "title": "In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care", "authors": ["Emmanuel Akinrintoyo", "Nicole Salomons"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Submitted to RO-MAN 2025 (Accepted)", "url": "http://arxiv.org/abs/2507.13578v1", "summary": "Individual cognitive stimulation therapy (iCST) is a non-pharmacological\nintervention for improving the cognition and quality of life of persons with\ndementia (PwDs); however, its effectiveness is limited by low adherence to\ndelivery by their family members. In this work, we present the user-centered\ndesign and evaluation of a novel socially assistive robotic system to provide\niCST therapy to PwDs in their homes for long-term use. We consulted with 16\ndementia caregivers and professionals. Through these consultations, we gathered\ndesign guidelines and developed the prototype. The prototype was validated by\ntesting it with three dementia professionals and five PwDs. The evaluation\nrevealed PwDs enjoyed using the system and are willing to adopt its use over\nthe long term. One shortcoming was the system's speech-to-text capabilities,\nwhere it frequently failed to understand the PwDs.", "comment": "Submitted to RO-MAN 2025 (Accepted)", "pdf_url": "http://arxiv.org/pdf/2507.13578v1", "cate": "cs.HC", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13775", "title": "Nonlinear Distortion Equalization in Multi-Span Optical Links Via a Feed-Forward Photonic Neural Network", "authors": ["Emiliano Staffoli", "Elisabetta Ferri", "Stefano Gretter", "Lorenzo Pavesi"], "categories": ["physics.optics", "cs.ET", "eess.SP"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      21 pages, 14 figures, 2 tables", "url": "http://arxiv.org/abs/2507.13775v1", "summary": "Linear and nonlinear distortions in optical communication signals are\nequalized using an integrated feed-forward Photonic Neural Network (PNN). The\nPNN is based on a linear stage made of an 8-tap Finite Impulse Response (FIR)\nfilter, featuring tunable amplitude and phase weights at each tap, and of a\nnonlinear stage achieved through the square modulus operation at the\nend-of-line photodetector. Within an Intensity Modulation/Direct Detection\n(IMDD) system, the PNN is applied to 2-level Pulse Amplitude Modulated (PAM2)\noptical signals undergoing multi-span propagation. Each 50 km segment includes\nfiber transmission, optical power restoration, and optional chromatic\ndispersion compensation via a Tunable Dispersion Compensator. Positioned at the\nreceiver, the PNN enables fully optical signal processing with minimal latency\nand power consumption. Experimental validation is conducted using a\nSilicon-On-Insulator device operating on 10 Gbps signals. It demonstrates\nchromatic dispersion equalization over distances up to 200 km and self-phase\nmodulation (with dispersion removed) up to 450 km. Simulations explore PNN\nadaptation for 100 Gbps modulations and its potential for cross-phase\nmodulation equalization.", "comment": "21 pages, 14 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.13775v1", "cate": "physics.optics", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13871", "title": "Safety Certification in the Latent space using Control Barrier Functions and World Models", "authors": ["Mehul Anand", "Shishir Kolathaya"], "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures. arXiv admin note: text overlap with arXiv:2409.12616", "url": "http://arxiv.org/abs/2507.13871v1", "summary": "Synthesising safe controllers from visual data typically requires extensive\nsupervised labelling of safety-critical data, which is often impractical in\nreal-world settings. Recent advances in world models enable reliable prediction\nin latent spaces, opening new avenues for scalable and data-efficient safe\ncontrol. In this work, we introduce a semi-supervised framework that leverages\ncontrol barrier certificates (CBCs) learned in the latent space of a world\nmodel to synthesise safe visuomotor policies. Our approach jointly learns a\nneural barrier function and a safe controller using limited labelled data,\nwhile exploiting the predictive power of modern vision transformers for latent\ndynamics modelling.", "comment": "6 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2409.12616", "pdf_url": "http://arxiv.org/pdf/2507.13871v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13825", "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction", "authors": ["Haoyang Li", "Yuming Xu", "Yiming Li", "Hanmo Liu", "Darian Li", "Chen Jason Zhang", "Lei Chen", "Qing Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Submitted in 2024. Accepted in 2025", "url": "http://arxiv.org/abs/2507.13825v1", "summary": "Temporal link prediction in dynamic graphs is a critical task with\napplications in diverse domains such as social networks, recommendation\nsystems, and e-commerce platforms. While existing Temporal Graph Neural\nNetworks (T-GNNs) have achieved notable success by leveraging complex\narchitectures to model temporal and structural dependencies, they often suffer\nfrom scalability and efficiency challenges due to high computational overhead.\nIn this paper, we propose EAGLE, a lightweight framework that integrates\nshort-term temporal recency and long-term global structural patterns. EAGLE\nconsists of a time-aware module that aggregates information from a node's most\nrecent neighbors to reflect its immediate preferences, and a structure-aware\nmodule that leverages temporal personalized PageRank to capture the influence\nof globally important nodes. To balance these attributes, EAGLE employs an\nadaptive weighting mechanism to dynamically adjust their contributions based on\ndata characteristics. Also, EAGLE eliminates the need for complex multi-hop\nmessage passing or memory-intensive mechanisms, enabling significant\nimprovements in efficiency. Extensive experiments on seven real-world temporal\ngraphs demonstrate that EAGLE consistently achieves superior performance\nagainst state-of-the-art T-GNNs in both effectiveness and efficiency,\ndelivering more than a 50x speedup over effective transformer-based T-GNNs.", "comment": "Submitted in 2024. Accepted in 2025", "pdf_url": "http://arxiv.org/pdf/2507.13825v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13416", "title": "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling", "authors": ["Jiaxiang Yi", "Bernardo P. Ferreira", "Miguel A. Bessa"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      40 pages, 32 figures", "url": "http://arxiv.org/abs/2507.13416v1", "summary": "Data-driven learning is generalized to consider history-dependent\nmulti-fidelity data, while quantifying epistemic uncertainty and disentangling\nit from data noise (aleatoric uncertainty). This generalization is hierarchical\nand adapts to different learning scenarios: from training the simplest\nsingle-fidelity deterministic neural networks up to the proposed multi-fidelity\nvariance estimation Bayesian recurrent neural networks. The versatility and\ngenerality of the proposed methodology are demonstrated by applying it to\ndifferent data-driven constitutive modeling scenarios that include multiple\nfidelities with and without aleatoric uncertainty (noise). The method\naccurately predicts the response and quantifies model error while also\ndiscovering the noise distribution (when present). This opens opportunities for\nfuture real-world applications in diverse scientific and engineering domains;\nespecially, the most challenging cases involving design and analysis under\nuncertainty.", "comment": "40 pages, 32 figures", "pdf_url": "http://arxiv.org/pdf/2507.13416v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13660", "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges", "Aileen Worden"], "categories": ["cs.HC", "cs.GR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13660v1", "summary": "Two user studies were performed to evaluate the effect of level-of-detail\n(LOD) degradation in the periphery of head-mounted displays on visual search\nperformance. In the first study, spatial detail was degraded by reducing\nresolution. In the second study, detail was degraded in the color domain by\nusing grayscale in the periphery. In each study, 10 subjects were given a\ncomplex search task that required users to indicate whether or not a target\nobject was present among distracters. Subjects used several different displays\nvarying in the amount of detail presented. Frame rate, object location, subject\ninput method, and order of display use were all controlled. The primary\ndependent measures were search time on correctly performed trials and the\npercentage of all trials correctly performed. Results indicated that peripheral\nLOD degradation can be used to reduce color or spatial visual complexity by\nalmost half in some search tasks with out significantly reducing performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13660v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14031", "title": "QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography", "authors": ["Hao Fang", "Sihao Teng", "Hao Yu", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "categories": ["cs.CV", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 12 figures", "url": "http://arxiv.org/abs/2507.14031v1", "summary": "Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside\nimaging modality with high temporal resolution, making it suitable for bedside\nmonitoring. However, its inherently ill-posed inverse problem poses significant\nchallenges for accurate image reconstruction. Deep learning (DL)-based\napproaches have shown promise but often rely on complex network architectures\nwith a large number of parameters, limiting efficiency and scalability. Here,\nwe propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework\nfor EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network\n(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive\nlatent representations that serve as implicit nonlinear priors, followed by a\nsingle linear layer for conductivity reconstruction. This design drastically\nreduces model complexity and parameter number. Uniquely, QuantEIT operates in\nan unsupervised, training-data-free manner and represents the first integration\nof quantum circuits into EIT image reconstruction. Extensive experiments on\nsimulated and real-world 2D and 3D EIT lung imaging data demonstrate that\nQuantEIT outperforms conventional methods, achieving comparable or superior\nreconstruction accuracy using only 0.2% of the parameters, with enhanced\nrobustness to noise.", "comment": "10 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.14031v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13359", "title": "Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives", "authors": ["Yang Zhou", "Junjie Li", "CongYang Ou", "Dawei Yan", "Haokui Zhang", "Xizhe Xue"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      27 pages, 5 figures", "url": "http://arxiv.org/abs/2507.13359v1", "summary": "Due to its extensive applications, aerial image object detection has long\nbeen a hot topic in computer vision. In recent years, advancements in Unmanned\nAerial Vehicles (UAV) technology have further propelled this field to new\nheights, giving rise to a broader range of application requirements. However,\ntraditional UAV aerial object detection methods primarily focus on detecting\npredefined categories, which significantly limits their applicability. The\nadvent of cross-modal text-image alignment (e.g., CLIP) has overcome this\nlimitation, enabling open-vocabulary object detection (OVOD), which can\nidentify previously unseen objects through natural language descriptions. This\nbreakthrough significantly enhances the intelligence and autonomy of UAVs in\naerial scene understanding. This paper presents a comprehensive survey of OVOD\nin the context of UAV aerial scenes. We begin by aligning the core principles\nof OVOD with the unique characteristics of UAV vision, setting the stage for a\nspecialized discussion. Building on this foundation, we construct a systematic\ntaxonomy that categorizes existing OVOD methods for aerial imagery and provides\na comprehensive overview of the relevant datasets. This structured review\nenables us to critically dissect the key challenges and open problems at the\nintersection of these fields. Finally, based on this analysis, we outline\npromising future research directions and application prospects. This survey\naims to provide a clear road map and a valuable reference for both newcomers\nand seasoned researchers, fostering innovation in this rapidly evolving domain.\nWe keep tracing related works at\nhttps://github.com/zhouyang2002/OVOD-in-UVA-imagery", "comment": "27 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13359v1", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.13903", "title": "AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery", "authors": ["Ziliang Li", "Hongming Chen", "Yiyang Lin", "Biyu Ye", "Ximin Lyu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13903v1", "summary": "Autonomous aerial systems play an increasingly vital role in a wide range of\napplications, particularly for transport and delivery tasks in complex\nenvironments. In airdrop missions, these platforms face the dual challenges of\nabrupt control mode switching and inherent system delays along with control\nerrors. To address these issues, this paper presents an autonomous airdrop\nsystem based on an aerial manipulator (AM). The introduction of additional\nactuated degrees of freedom enables active compensation for UAV tracking\nerrors. By imposing smooth and continuous constraints on the parabolic landing\npoint, the proposed approach generates aerial throwing trajectories that are\nless sensitive to the timing of payload release. A hierarchical disturbance\ncompensation strategy is incorporated into the Nonlinear Model Predictive\nControl (NMPC) framework to mitigate the effects of sudden changes in system\nparameters, while the predictive capabilities of NMPC are further exploited to\nimprove the precision of aerial throwing. Both simulation and real-world\nexperimental results demonstrate that the proposed system achieves greater\nagility and precision in airdrop missions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13903v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13846", "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments", "authors": ["Kathrin Korte", "Christian Medeiros Adriano", "Sona Ghahremani", "Holger Giese"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13846v1", "summary": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13846v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13417", "title": "Soft-ECM: An extension of Evidential C-Means for complex data", "authors": ["Armel Soubeiga", "Thomas Guyet", "Violaine Antoine"], "categories": ["cs.LG", "cs.AI", "cs.DM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13417v1", "summary": "Clustering based on belief functions has been gaining increasing attention in\nthe machine learning community due to its ability to effectively represent\nuncertainty and/or imprecision. However, none of the existing algorithms can be\napplied to complex data, such as mixed data (numerical and categorical) or\nnon-tabular data like time series. Indeed, these types of data are, in general,\nnot represented in a Euclidean space and the aforementioned algorithms make use\nof the properties of such spaces, in particular for the construction of\nbarycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem\nfor clustering complex data. We propose a new algorithm, Soft-ECM, which\nconsistently positions the centroids of imprecise clusters requiring only a\nsemi-metric. Our experiments show that Soft-ECM present results comparable to\nconventional fuzzy clustering approaches on numerical data, and we demonstrate\nits ability to handle mixed data and its benefits when combining fuzzy\nclustering with semi-metrics such as DTW for time series data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13417v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13795", "title": "Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks", "authors": ["Florian Grensing", "Vanessa Schmücker", "Anne Sophie Hildebrand", "Tim Klucken", "Maria Maleshkova"], "categories": ["cs.HC", "I.2.6; J.3"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      9 Pages, 4 Figures (3 consisting of 3 subfigures each)", "url": "http://arxiv.org/abs/2507.13795v1", "summary": "Phobias significantly impact the quality of life of affected persons. Two\nmethods of assessing anxiety responses are questionnaires and behavioural\navoidance tests (BAT). While these can be used in a clinical environment they\nonly record momentary insights into anxiety measures. In this study, we\nestimate the intensity of anxiety during these BATs, using physiological data\ncollected from unobtrusive, wrist-worn sensors. Twenty-five participants\nperformed four different BATs in a single session, while periodically being\nasked how anxious they currently are. Using heart rate, heart rate variability,\nelectrodermal activity, and skin temperature, we trained regression models to\npredict anxiety ratings from three types of input data: (1) using only\nphysiological signals, (2) adding computed features (e.g., min, max, range,\nvariability), and (3) computed features combined with contextual task\ninformation. Adding contextual information increased the effectiveness of the\nmodel, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute\nerror (MAE) of 0.041. Overall, this study shows, that data obtained from\nwearables can continuously provide meaningful estimations of anxiety, which can\nassist in therapy planning and enable more personalised treatment.", "comment": "9 Pages, 4 Figures (3 consisting of 3 subfigures each)", "pdf_url": "http://arxiv.org/pdf/2507.13795v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14069", "title": "Edge Intelligence with Spiking Neural Networks", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      This work has been submitted to Proceeding of IEEE for possible publication", "url": "http://arxiv.org/abs/2507.14069v1", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence.", "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "pdf_url": "http://arxiv.org/pdf/2507.14069v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13360", "title": "Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance", "authors": ["Le-Anh Tran", "Chung Nguyen Tran", "Ngoc-Luu Nguyen", "Nhan Cach Dang", "Jordi Carrabina", "David Castells-Rufas", "Minh Son Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, ICCCE 2025", "url": "http://arxiv.org/abs/2507.13360v1", "summary": "This paper introduces a novel deep learning framework for low-light image\nenhancement, named the Encoder-Decoder Network with Illumination Guidance\n(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination\nmap, derived from Bright Channel Prior (BCP), as a guidance input. This\nillumination guidance helps the network focus on underexposed regions,\neffectively steering the enhancement process. To further improve the model's\nrepresentational power, a Spatial Pyramid Pooling (SPP) module is incorporated\nto extract multi-scale contextual features, enabling better handling of diverse\nlighting conditions. Additionally, the Swish activation function is employed to\nensure smoother gradient propagation during training. EDNIG is optimized within\na Generative Adversarial Network (GAN) framework using a composite loss\nfunction that combines adversarial loss, pixel-wise mean squared error (MSE),\nand perceptual loss. Experimental results show that EDNIG achieves competitive\nperformance compared to state-of-the-art methods in quantitative metrics and\nvisual quality, while maintaining lower model complexity, demonstrating its\nsuitability for real-world applications. The source code for this work is\navailable at https://github.com/tranleanh/ednig.", "comment": "6 pages, 3 figures, ICCCE 2025", "pdf_url": "http://arxiv.org/pdf/2507.13360v1", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.13481", "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence", "authors": ["Arthur Bueno", "Bruno Cafeo", "Maria Cagnin", "Awdren Fontão"], "categories": ["cs.SE", "cs.CY"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      12 pages; 2 figures; Preprint with the original submission accepted for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "url": "http://arxiv.org/abs/2507.13481v1", "summary": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving\nas lightweight artifacts that support knowledge transfer, onboarding, and\nframework adoption. Despite their instructional relevance, these samples are\noften governed informally, with minimal review and unclear ownership, which\nincreases their exposure to socio-technical degradation. In this context, the\nco-occurrence and longitudinal interplay of code smells (e.g., large classes,\npoor modularity) and community smells (e.g., lone contributors, fragmented\ncommunication) become particularly critical. While each type of smell has been\nstudied in isolation, little is known about how community-level dysfunctions\nanticipate or exacerbate technical anomalies in code samples over time. This\nstudy investigates how code and community smells emerge, co-occur, and evolve\nwithin code samples maintained in OSSECOs. A Multivocal Literature Review\nprotocol was applied, encompassing 30 peer-reviewed papers and 17\npractitioner-oriented sources (2013-2024). Thematic synthesis was conducted to\nidentify recurring socio-technical patterns related to smell dynamics. Nine\npatterns were identified, showing that community smells often precede or\nreinforce technical degradation in code samples. Symptoms such as \"radio\nsilence\" and centralized ownership were frequently associated with persistent\nstructural anomalies. Additionally, limited onboarding, the absence of\ncontinuous refactoring, and informal collaboration emerged as recurring\nconditions for smell accumulation. Conclusion: In OSSECOs, particularly within\ncode samples, community-level dysfunctions not only correlate with but often\nsignal maintainability decay. These findings underscore the need for\nsocio-technical quality indicators and lightweight governance mechanisms\ntailored to shared instructional artifacts.", "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "pdf_url": "http://arxiv.org/pdf/2507.13481v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13940", "title": "NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning", "authors": ["Qingyi Chen", "Ahmed H. Qureshi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13940v1", "summary": "Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in\nrobotics. Despite substantial advancements, existing methods often face a\ndilemma. Decentralized algorithms typically rely on predicting the behavior of\nother agents, sharing contracts, or maintaining communication for safety, while\ncentralized approaches struggle with scalability and real-time decision-making.\nTo address these challenges, we introduce Neural Hamilton-Jacobi Reachability\nLearning (HJR) for Decentralized Multi-Agent Motion Planning. Our method\nprovides scalable neural HJR modeling to tackle high-dimensional configuration\nspaces and capture worst-case collision and safety constraints between agents.\nWe further propose a decentralized trajectory optimization framework that\nincorporates the learned HJR solutions to solve MAMP tasks in real-time. We\ndemonstrate that our method is both scalable and data-efficient, enabling the\nsolution of MAMP problems in higher-dimensional scenarios with complex\ncollision constraints. Our approach generalizes across various dynamical\nsystems, including a 12-dimensional dual-arm setup, and outperforms a range of\nstate-of-the-art techniques in successfully addressing challenging MAMP tasks.\nVideo demonstrations are available at https://youtu.be/IZiePX0p1Mc.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13940v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13874", "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery", "authors": ["Mateusz Bystroński", "Mikołaj Hołysz", "Grzegorz Piotrowski", "Nitesh V. Chawla", "Tomasz Kajdanowicz"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13874v1", "summary": "Innovative idea generation remains a core challenge in AI, as large language\nmodels (LLMs) often struggle to produce outputs that are both novel and\nrelevant. Despite their fluency, LLMs tend to replicate patterns seen during\ntraining, limiting their ability to diverge creatively without extensive prompt\nengineering. Prior work has addressed this through domain-specific heuristics\nand structured prompting pipelines, but such solutions are brittle and\ndifficult to generalize. In this paper, we propose a model-agnostic\nlatent-space ideation framework that enables controlled, scalable creativity by\nnavigating the continuous embedding space of ideas. Unlike prior methods, our\nframework requires no handcrafted rules and adapts easily to different domains,\ninput formats, and creative tasks. This paper introduces an early-stage\nprototype of our method, outlining the conceptual framework and preliminary\nresults highlighting its potential as a general-purpose co-ideator for human-AI\ncollaboration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13874v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13423", "title": "Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity", "authors": ["Edward Henderson", "Dewi Gould", "Richard Everson", "George De Ath", "Nick Pepper"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Author Accepted Manuscript version of paper at the AIAA AVIATION Forum 2025", "url": "http://arxiv.org/abs/2507.13423v1", "summary": "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand\nis a critical challenge in an increasingly crowded airspace, as existing\ncomplexity metrics often fail to capture nuanced operational drivers beyond\nsimple aircraft counts. This work introduces an interpretable Graph Neural\nNetwork (GNN) framework to address this gap. Our attention-based model predicts\nthe number of upcoming clearances, the instructions issued to aircraft by\nATCOs, from interactions within static traffic scenarios. Crucially, we derive\nan interpretable, per-aircraft task demand score by systematically ablating\naircraft and measuring the impact on the model's predictions. Our framework\nsignificantly outperforms an ATCO-inspired heuristic and is a more reliable\nestimator of scenario complexity than established baselines. The resulting tool\ncan attribute task demand to specific aircraft, offering a new way to analyse\nand understand the drivers of complexity for applications in controller\ntraining and airspace redesign.", "comment": "Author Accepted Manuscript version of paper at the AIAA AVIATION\n  Forum 2025", "pdf_url": "http://arxiv.org/pdf/2507.13423v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13886", "title": "Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study", "authors": ["Anaïs Halin", "Marc Van Droogenbroeck", "Christel Devue"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13886v1", "summary": "In this simulator study, we adopt a human-centered approach to explore\nwhether and how drivers' cognitive state and driving environment complexity\ninfluence reliance on driving automation features. Besides, we examine whether\nsuch reliance affects driving performance. Participants operated a vehicle\nequipped with adaptive cruise control (ACC) in a simulator across six\npredefined driving scenarios varying in traffic conditions while either\nperforming a cognitively demanding task (i.e., responding to mental\ncalculations) or not. Throughout the experiment, participants had to respect\nspeed limits and were free to activate or deactivate ACC. In complex driving\nenvironments, we found that the overall ACC engagement time was lower compared\nto less complex driving environments. We observed no significant effect of\ncognitive load on ACC use. Furthermore, while ACC use had no effect on the\nnumber of lane changes, it impacted the speed limits compliance and improved\nlateral control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13886v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14116", "title": "Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification", "authors": ["Daniëlle Schuman", "Mark V. Seebode", "Tobias Rohe", "Maximilian Balthasar Mansky", "Michael Schroedl-Baumann", "Jonas Stein", "Claudia Linnhoff-Popien", "Florian Krellner"], "categories": ["quant-ph", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures (10 if counting subfigures), 2 tables. To be published in the proceedings of the 2025 IEEE International Conference on Quantum Computing and Engineering (QCE)", "url": "http://arxiv.org/abs/2507.14116v1", "summary": "Exploiting the fact that samples drawn from a quantum annealer inherently\nfollow a Boltzmann-like distribution, annealing-based Quantum Boltzmann\nMachines (QBMs) have gained increasing popularity in the quantum research\ncommunity. While they harbor great promises for quantum speed-up, their usage\ncurrently stays a costly endeavor, as large amounts of QPU time are required to\ntrain them. This limits their applicability in the NISQ era. Following the idea\nof No\\`e et al. (2024), who tried to alleviate this cost by incorporating\nparallel quantum annealing into their unsupervised training of QBMs, this paper\npresents an improved version of parallel quantum annealing that we employ to\ntrain QBMs in a supervised setting. Saving qubits to encode the inputs, the\nlatter setting allows us to test our approach on medical images from the\nMedMNIST data set (Yang et al., 2023), thereby moving closer to real-world\napplicability of the technology. Our experiments show that QBMs using our\napproach already achieve reasonable results, comparable to those of\nsimilarly-sized Convolutional Neural Networks (CNNs), with markedly smaller\nnumbers of epochs than these classical models. Our parallel annealing technique\nleads to a speed-up of almost 70 % compared to regular annealing-based BM\nexecutions.", "comment": "12 pages, 5 figures (10 if counting subfigures), 2 tables. To be\n  published in the proceedings of the 2025 IEEE International Conference on\n  Quantum Computing and Engineering (QCE)", "pdf_url": "http://arxiv.org/pdf/2507.14116v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13361", "title": "VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs", "authors": ["Shmuel Berman", "Jia Deng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13361v1", "summary": "Visual Language Models (VLMs) excel at complex visual tasks such as VQA and\nchart understanding, yet recent work suggests they struggle with simple\nperceptual tests. We present an evaluation that tests vision-language models'\ncapacity for nonlocal visual reasoning -- reasoning that requires chaining\nevidence collected from multiple, possibly distant, regions of an image. We\nisolate three distinct forms of non-local vision: comparative perception, which\ndemands holding two images in working memory and comparing them; saccadic\nsearch, which requires making discrete, evidence-driven jumps to locate\nsuccessive targets; and smooth visual search, which involves searching smoothly\nalong a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude\nVision 3.7, GPT-o4-mini), even those that perform well on prior\nprimitive-vision benchmarks, fail these tests and barely exceed random accuracy\non two variants of our tasks that are trivial for humans. Our structured\nevaluation suite allows us to test if VLMs can perform similar visual\nalgorithms to humans. Our findings show that despite gains in raw visual\nacuity, current models lack core visual reasoning capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13361v1", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.13499", "title": "AI-Assisted Fixes to Code Review Comments at Scale", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13499v1", "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13499v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13970", "title": "A segmented robot grasping perception neural network for edge AI", "authors": ["Casper Bröcheler", "Thomas Vroom", "Derrick Timmermans", "Alan van den Akker", "Guangzhi Tang", "Charalampos S. Kouzinopoulos", "Rico Möckel"], "categories": ["cs.RO", "cs.AI", "I.2; I.2.9; I.2.10"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by SMC 2025", "url": "http://arxiv.org/abs/2507.13970v1", "summary": "Robotic grasping, the ability of robots to reliably secure and manipulate\nobjects of varying shapes, sizes and orientations, is a complex task that\nrequires precise perception and control. Deep neural networks have shown\nremarkable success in grasp synthesis by learning rich and abstract\nrepresentations of objects. When deployed at the edge, these models can enable\nlow-latency, low-power inference, making real-time grasping feasible in\nresource-constrained environments. This work implements Heatmap-Guided Grasp\nDetection, an end-to-end framework for the detection of 6-Dof grasp poses, on\nthe GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware\ntechniques, including input dimensionality reduction, model partitioning, and\nquantisation. Experimental evaluation on the GraspNet-1Billion benchmark\nvalidates the feasibility of fully on-chip inference, highlighting the\npotential of low-power MCUs for real-time, autonomous manipulation.", "comment": "Accepted by SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.13970v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13956", "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "authors": ["Yutao Jin", "Haowen Xiao", "Jielei Chu", "Fengmao Lv", "Yuxiao Li", "Tianrui Li"], "categories": ["cs.AI", "cs.CV", "cs.MM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13956v1", "summary": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13956v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13482", "title": "Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning", "authors": ["Seyyed Saeid Cheshmi", "Buyao Lyu", "Thomas Lisko", "Rajesh Rajamani", "Robert A. McGovern", "Yogatheesan Varatharajah"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13482v1", "summary": "Human Activity Recognition (HAR) based on wearable inertial sensors plays a\ncritical role in remote health monitoring. In patients with movement disorders,\nthe ability to detect abnormal patient movements in their home environments can\nenable continuous optimization of treatments and help alert caretakers as\nneeded. Machine learning approaches have been proposed for HAR tasks using\nInertial Measurement Unit (IMU) data; however, most rely on\napplication-specific labels and lack generalizability to data collected in\ndifferent environments or populations. To address this limitation, we propose a\nnew cross-modal self-supervised pretraining approach to learn representations\nfrom large-sale unlabeled IMU-video data and demonstrate improved\ngeneralizability in HAR tasks on out of distribution (OOD) IMU datasets,\nincluding a dataset collected from patients with Parkinson's disease.\nSpecifically, our results indicate that the proposed cross-modal pretraining\napproach outperforms the current state-of-the-art IMU-video pretraining\napproach and IMU-only pretraining under zero-shot and few-shot evaluations.\nBroadly, our study provides evidence that in highly dynamic data modalities,\nsuch as IMU signals, cross-modal pretraining may be a useful tool to learn\ngeneralizable data representations. Our software is available at\nhttps://github.com/scheshmi/IMU-Video-OOD-HAR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13482v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13923", "title": "Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes", "authors": ["Guillaume Rivière"], "categories": ["cs.HC", "H.5.2"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Written in French. 22 pages. Approximately 11700 words. 10 figures and 6 tables", "url": "http://arxiv.org/abs/2507.13923v1", "summary": "The science of Human-Computer Interaction (HCI) is populated by isolated\nempirical findings, often tied to specific technologies, designs, and tasks.\nThis paper proposes a formalization of user interaction observations (instead\nof user interfaces) and an associated revealing method (interaction loop\ndiffraction). The resulting interactional properties that are studied in a\ncalibrated manner, are well suited to replication across various conditions\n(prototypes, technologies, tasks, and user profiles). In particular,\ninteractional properties can emerge and be replicated within the workflow of\napplicative cases, which in return benefit from the optimization of applicative\nprototypes. Applicative cases' publications will then contribute to\ndemonstrating technology utility, along with providing empirical results that\nwill lead future work to theory consolidation and theory building, and finally\nto a catalog and a science of relevant interactional properties. These\nproperties will contribute to better user interactions, especially for the\nvariety of ubiquitous user interfaces.", "comment": "Written in French. 22 pages. Approximately 11700 words. 10 figures\n  and 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.13923v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.17135", "title": "No Scratch Quantum Computing by Reducing Qubit Overhead for Efficient Arithmetics", "authors": ["Omid Faizy", "Norbert Wehn", "Paul Lukowicz", "Maximilian Kiefer-Emmanouilidis"], "categories": ["quant-ph", "cs.ET", "cs.LO"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17135v2", "summary": "Quantum arithmetic computation requires a substantial number of scratch\nqubits to stay reversible. These operations necessitate qubit and gate\nresources equivalent to those needed for the larger of the input or output\nregisters due to state encoding. Quantum Hamiltonian Computing (QHC) introduces\na novel approach by encoding input for logic operations within a single\nrotating quantum gate. This innovation reduces the required qubit register $ N\n$ to the size of the output states $ O $, where $ N = \\log_2 O $. Leveraging\nQHC principles, we present reversible half-adder and full-adder circuits that\ncompress the standard Toffoli + CNOT layout [Vedral et al., PRA, 54, 11,\n(1996)] from three-qubit and four-qubit formats for the Quantum half-adder\ncircuit and five sequential Fredkin gates using five qubits [Moutinho et al.,\nPRX Energy 2, 033002 (2023)] for full-adder circuit; into a two-qubit, 4$\\times\n$4 Hilbert space. This scheme, presented here, is optimized for classical logic\nevaluated on quantum hardware, which due to unitary evolution can bypass\nclassical CMOS energy limitations to certain degree. Although we avoid\nsuperposition of input and output states in this manuscript, this remains\nfeasible in principle. We see the best application for QHC in finding the\nminimal qubit and gate resources needed to evaluate any truth table, advancing\nFPGA capabilities using integrated quantum circuits or photonics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17135v2", "cate": "quant-ph", "date": "2025-06-20", "updated": "2025-07-18"}
{"id": "2507.13362", "title": "Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning", "authors": ["Binbin Ji", "Siddharth Agrawal", "Qiance Tang", "Yvonne Wu"], "categories": ["cs.CV", "cs.AI", "cs.CL", "I.2.10; I.4.8; I.2.6; I.2.7; I.5.4; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, submitted to a conference (IEEE formate). Authored by students from the Courant Institute, NYU", "url": "http://arxiv.org/abs/2507.13362v1", "summary": "This study investigates the spatial reasoning capabilities of vision-language\nmodels (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement\nlearning. We begin by evaluating the impact of different prompting strategies\nand find that simple CoT formats, where the model generates a reasoning step\nbefore the answer, not only fail to help, but can even harm the model's\noriginal performance. In contrast, structured multi-stage prompting based on\nscene graphs (SceneGraph CoT) significantly improves spatial reasoning\naccuracy. Furthermore, to improve spatial reasoning ability, we fine-tune\nmodels using Group Relative Policy Optimization (GRPO) on the SAT dataset and\nevaluate their performance on CVBench. Compared to supervised fine-tuning\n(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates\nsuperior robustness under out-of-distribution (OOD) conditions. In particular,\nwe find that SFT overfits to surface-level linguistic patterns and may degrade\nperformance when test-time phrasing changes (e.g., from \"closer to\" to \"farther\nfrom\"). GRPO, on the other hand, generalizes more reliably and maintains stable\nperformance under such shifts. Our findings provide insights into how\nreinforcement learning and structured prompting improve the spatial reasoning\ncapabilities and generalization behavior of modern VLMs. All code is open\nsource at: https://github.com/Yvonne511/spatial-vlm-investigator", "comment": "10 pages, 5 figures, submitted to a conference (IEEE formate).\n  Authored by students from the Courant Institute, NYU", "pdf_url": "http://arxiv.org/pdf/2507.13362v1", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.13553", "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the 9th International Workshop on Crowd-Based Requirements Engineering (CrowdRE'25)", "url": "http://arxiv.org/abs/2507.13553v1", "summary": "As user demands evolve, effectively incorporating feature requests is crucial\nfor maintaining software relevance and user satisfaction. Feature requests,\ntypically expressed in natural language, often suffer from ambiguity or\nincomplete information due to communication gaps or the requester's limited\ntechnical expertise. These issues can lead to misinterpretation, faulty\nimplementation, and reduced software quality. While seeking clarification from\nrequesters is a common strategy to mitigate these risks, little is known about\nhow developers engage in this clarification process in practice-how they\nformulate clarifying questions, seek technical or contextual details, align on\ngoals and use cases, or decide to close requests without attempting\nclarification. This study investigates how feature requests are prone to NL\ndefects (i.e. ambiguous or incomplete) and the conversational dynamics of\nclarification in open-source software (OSS) development, aiming to understand\nhow developers handle ambiguous or incomplete feature requests. Our findings\nsuggest that feature requests published on the OSS platforms do possess\nambiguity and incompleteness, and in some cases, both. We also find that\nexplicit clarification for the resolution of these defects is uncommon;\ndevelopers usually focus on aligning with project goals rather than resolving\nunclear text. When clarification occurs, it emphasizes understanding user\nintent/goal and feasibility, rather than technical details. By characterizing\nthe dynamics of clarification in open-source issue trackers, this work\nidentifies patterns that can improve user-developer collaboration and inform\nbest practices for handling feature requests effectively.", "comment": "Accepted at the 9th International Workshop on Crowd-Based\n  Requirements Engineering (CrowdRE'25)", "pdf_url": "http://arxiv.org/pdf/2507.13553v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14043", "title": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems", "authors": ["Genliang Li", "Yaxin Cui", "Jinyu Su"], "categories": ["cs.RO", "cs.AI", "cs.CE"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      59 pages, 22 figures", "url": "http://arxiv.org/abs/2507.14043v1", "summary": "Metaheuristic algorithms have gained widespread application across various\nfields owing to their ability to generate diverse solutions. One such algorithm\nis the Snake Optimizer (SO), a progressive optimization approach. However, SO\nsuffers from the issues of slow convergence speed and susceptibility to local\noptima. In light of these shortcomings, we propose a novel Multi-strategy\nImproved Snake Optimizer (MISO). Firstly, we propose a new adaptive random\ndisturbance strategy based on sine function to alleviate the risk of getting\ntrapped in a local optimum. Secondly, we introduce adaptive Levy flight\nstrategy based on scale factor and leader and endow the male snake leader with\nflight capability, which makes it easier for the algorithm to leap out of the\nlocal optimum and find the global optimum. More importantly, we put forward a\nposition update strategy combining elite leadership and Brownian motion,\neffectively accelerating the convergence speed while ensuring precision.\nFinally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test\nfunctions and the CEC2022 test suite, comparing it with 11 popular algorithms\nacross different dimensions to validate its effectiveness. Moreover, Unmanned\nAerial Vehicle (UAV) has been widely used in various fields due to its\nadvantages of low cost, high mobility and easy operation. However, the UAV path\nplanning problem is crucial for flight safety and efficiency, and there are\nstill challenges in establishing and optimizing the path model. Therefore, we\napply MISO to the UAV 3D path planning problem as well as 6 engineering design\nproblems to assess its feasibility in practical applications. The experimental\nresults demonstrate that MISO exceeds other competitive algorithms in terms of\nsolution quality and stability, establishing its strong potential for\napplication.", "comment": "59 pages, 22 figures", "pdf_url": "http://arxiv.org/pdf/2507.14043v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13958", "title": "Towards Constraint Temporal Answer Set Programming", "authors": ["Pedro Cabalar", "Martín Diéguez", "François Olivier", "Torsten Schaub", "Igor Stéphan"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13958v1", "summary": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13958v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13491", "title": "Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents", "authors": ["Thomas Banker", "Ali Mesbah"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13491v1", "summary": "Training sophisticated agents for optimal decision-making under uncertainty\nhas been key to the rapid development of modern autonomous systems across\nfields. Notably, model-free reinforcement learning (RL) has enabled\ndecision-making agents to improve their performance directly through system\ninteractions, with minimal prior knowledge about the system. Yet, model-free RL\nhas generally relied on agents equipped with deep neural network function\napproximators, appealing to the networks' expressivity to capture the agent's\npolicy and value function for complex systems. However, neural networks amplify\nthe issues of sample inefficiency, unsafe learning, and limited\ninterpretability in model-free RL. To this end, this work introduces\nmodel-based agents as a compelling alternative for control policy\napproximation, leveraging adaptable models of system dynamics, cost, and\nconstraints for safe policy learning. These models can encode prior system\nknowledge to inform, constrain, and aid in explaining the agent's decisions,\nwhile deficiencies due to model mismatch can be remedied with model-free RL. We\noutline the benefits and challenges of learning model-based agents --\nexemplified by model predictive control -- and detail the primary learning\napproaches: Bayesian optimization, policy search RL, and offline strategies,\nalong with their respective strengths. While model-free RL has long been\nestablished, its interplay with model-based agents remains largely unexplored,\nmotivating our perspective on their combined potentials for sample-efficient\nlearning of safe and interpretable decision-making agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13491v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13951", "title": "Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker", "authors": ["Hamid Zand Miralvand", "Mohammad Ronagh Nikghalb", "Mohammad Darandeh", "Abidullah Khan", "Ian Arawjo", "Jinghui Cheng"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to CHI Play 2025, 35 pages, 4 figures", "url": "http://arxiv.org/abs/2507.13951v1", "summary": "Game modding offers unique and personalized gaming experiences, but the\ntechnical complexity of creating mods often limits participation to skilled\nusers. We envision a future where every player can create personalized mods for\ntheir games. To explore this space, we designed StarCharM, a GenAI-based\nnon-player character (NPC) creator for Stardew Valley. Our tool enables players\nto iteratively create new NPC mods, requiring minimal user input while allowing\nfor fine-grained adjustments through user control. We conducted a user study\nwith ten Stardew Valley players who had varied mod usage experiences to\nunderstand the impacts of StarCharM and provide insights into how GenAI tools\nmay reshape modding, particularly in NPC creation. Participants expressed\nexcitement in bringing their character ideas to life, although they noted\nchallenges in generating rich content to fulfill complex visions. While they\nbelieved GenAI tools like StarCharM can foster a more diverse modding\ncommunity, some voiced concerns about diminished originality and community\nengagement that may come with such technology. Our findings provided\nimplications and guidelines for the future of GenAI-powered modding tools and\nco-creative modding practices.", "comment": "Accepted to CHI Play 2025, 35 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.13951v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13363", "title": "Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop", "authors": ["Atharv Goel", "Mehar Khurana"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13363v1", "summary": "Modern 3D object detection datasets are constrained by narrow class\ntaxonomies and costly manual annotations, limiting their ability to scale to\nopen-world settings. In contrast, 2D vision-language models trained on\nweb-scale image-text pairs exhibit rich semantic understanding and support\nopen-vocabulary detection via natural language prompts. In this work, we\nleverage the maturity and category diversity of 2D foundation models to perform\nopen-vocabulary 3D object detection without any human-annotated 3D labels.\n  Our pipeline uses a 2D vision-language detector to generate text-conditioned\nproposals, which are segmented with SAM and back-projected into 3D using camera\ngeometry and either LiDAR or monocular pseudo-depth. We introduce a geometric\ninflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D\nbounding boxes without training. To simulate adverse real-world conditions, we\nconstruct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes\ndataset.\n  Experiments demonstrate that our method achieves competitive localization\nperformance across multiple settings, including LiDAR-based and purely RGB-D\ninputs, all while remaining training-free and open-vocabulary. Our results\nhighlight the untapped potential of 2D foundation models for scalable 3D\nperception. We open-source our code and resources at\nhttps://github.com/atharv0goel/open-world-3D-det.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13363v1", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.13555", "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the 33rd IEEE International Requirements Engineering 2025", "url": "http://arxiv.org/abs/2507.13555v1", "summary": "The growing popularity and widespread use of software applications (apps)\nacross various domains have driven rapid industry growth. Along with this\ngrowth, fast-paced market changes have led to constantly evolving software\nrequirements. Such requirements are often grounded in feature requests and\nenhancement suggestions, typically provided by users in natural language (NL).\nHowever, these requests often suffer from defects such as ambiguity and\nincompleteness, making them challenging to interpret. Traditional validation\nmethods (e.g., interviews and workshops) help clarify such defects but are\nimpractical in decentralized environments like open-source software (OSS),\nwhere change requests originate from diverse users on platforms like GitHub.\nThis paper proposes a novel approach leveraging Large Language Models (LLMs) to\ndetect and refine NL defects in feature requests. Our approach automates the\nidentification of ambiguous and incomplete requests and generates clarification\nquestions (CQs) to enhance their usefulness for developers. To evaluate its\neffectiveness, we apply our method to real-world OSS feature requests and\ncompare its performance against human annotations. In addition, we conduct\ninterviews with GitHub developers to gain deeper insights into their\nperceptions of NL defects, the strategies they use to address these defects,\nand the impact of defects on downstream software engineering (SE) tasks.", "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025", "pdf_url": "http://arxiv.org/pdf/2507.13555v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14049", "title": "EdgeVLA: Efficient Vision-Language-Action Models", "authors": ["Paweł Budzianowski", "Wesley Maa", "Matthew Freed", "Jingxiang Mo", "Winston Hsiao", "Aaron Xie", "Tomasz Młoduchowski", "Viraj Tipnis", "Benjamin Bolte"], "categories": ["cs.RO", "cs.CL"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14049v1", "summary": "Vision-Language Models (VLMs) have emerged as a promising approach to address\nthe data scarcity challenge in robotics, enabling the development of\ngeneralizable visuomotor control policies. While models like OpenVLA showcase\nthe potential of this paradigm, deploying large-scale VLMs on\nresource-constrained mobile manipulation systems remains a significant hurdle.\nThis paper introduces Edge VLA (EVLA), a novel approach designed to\nsignificantly enhance the inference speed of Vision-Language-Action (VLA)\nmodels. EVLA maintains the representational power of these models while\nenabling real-time performance on edge devices. We achieve this through two key\ninnovations: 1) Eliminating the autoregressive requirement for end-effector\nposition prediction, leading to a 7x speedup in inference, and 2) Leveraging\nthe efficiency of Small Language Models (SLMs), demonstrating comparable\ntraining performance to larger models with significantly reduced computational\ndemands. Our early results demonstrate that EVLA achieves comparable training\ncharacteristics to OpenVLA while offering substantial gains in inference speed\nand memory efficiency. We release our model checkpoints and training\n\\href{https://github.com/kscalelabs/evla }{codebase} to foster further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14049v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14032", "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models", "authors": ["Lam Nguyen", "Erika Barcelos", "Roger French", "Yinghui Wu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to the 24th International Semantic Web Conference Research Track (ISWC 2025)", "url": "http://arxiv.org/abs/2507.14032v1", "summary": "Ontology Matching (OM) is a cornerstone task of semantic interoperability,\nyet existing systems often rely on handcrafted rules or specialized models with\nlimited adaptability. We present KROMA, a novel OM framework that harnesses\nLarge Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)\npipeline to dynamically enrich the semantic context of OM tasks with\nstructural, lexical, and definitional knowledge. To optimize both performance\nand efficiency, KROMA integrates a bisimilarity-based concept matching and a\nlightweight ontology refinement step, which prune candidate concepts and\nsubstantially reduce the communication overhead from invoking LLMs. Through\nexperiments on multiple benchmark datasets, we show that integrating knowledge\nretrieval with context-augmented LLMs significantly enhances ontology matching,\noutperforming both classic OM systems and cutting-edge LLM-based approaches\nwhile keeping communication overhead comparable. Our study highlights the\nfeasibility and benefit of the proposed optimization techniques (targeted\nknowledge retrieval, prompt enrichment, and ontology refinement) for ontology\nmatching at scale.", "comment": "Accepted to the 24th International Semantic Web Conference Research\n  Track (ISWC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.14032v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13540", "title": "Provable Low-Frequency Bias of In-Context Learning of Representations", "authors": ["Yongyi Yang", "Hidenori Tanaka", "Wei Hu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13540v1", "summary": "In-context learning (ICL) enables large language models (LLMs) to acquire new\nbehaviors from the input sequence alone without any parameter updates. Recent\nstudies have shown that ICL can surpass the original meaning learned in\npretraining stage through internalizing the structure the data-generating\nprocess (DGP) of the prompt into the hidden representations. However, the\nmechanisms by which LLMs achieve this ability is left open. In this paper, we\npresent the first rigorous explanation of such phenomena by introducing a\nunified framework of double convergence, where hidden representations converge\nboth over context and across layers. This double convergence process leads to\nan implicit bias towards smooth (low-frequency) representations, which we prove\nanalytically and verify empirically. Our theory explains several open empirical\nobservations, including why learned representations exhibit globally structured\nbut locally distorted geometry, and why their total energy decays without\nvanishing. Moreover, our theory predicts that ICL has an intrinsic robustness\ntowards high-frequency noise, which we empirically confirm. These results\nprovide new insights into the underlying mechanisms of ICL, and a theoretical\nfoundation to study it that hopefully extends to more general data\ndistributions and settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13540v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13952", "title": "Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning", "authors": ["Shayla Sharmin", "Roghayeh Leila Barmaki"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2504.13883", "url": "http://arxiv.org/abs/2507.13952v1", "summary": "The estimation of cognitive effort could potentially help educators to modify\nmaterial to enhance learning effectiveness and student engagement. Where\ncognitive load refers how much work the brain is doing while someone is\nlearning or doing a task cognitive effort consider both load and behavioral\nperformance. Cognitive effort can be captured by measuring oxygen flow and\nbehavioral performance during a task. This study infers cognitive effort\nmetrics using machine learning models based on oxygenated hemoglobin collected\nby using functional near-infrared spectroscopy from the prefrontal cortex\nduring an educational gameplay. In our study, sixteen participants responded to\nsixteen questions in an in-house Unity-based educational game. The quiz was\ndivided into two sessions, each session consisting of two task segments. We\nextracted temporal statistical and functional connectivity features from\ncollected oxygenated hemoglobin and analyzed their correlation with quiz\nperformance. We trained multiple machine learning models to predict quiz\nperformance from oxygenated hemoglobin features and achieved accuracies ranging\nfrom 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive\neffort via relative neural involvement and efficiency, which consider both\nbrain activation and behavioral performance. Although quiz score predictions\nachieved moderate accuracy, the derived relative neural efficiency and\ninvolvement values remained robust. Since both metrics are based on the\nrelative positions of standardized brain activation and performance scores,\neven small misclassifications in predicted scores preserved the overall\ncognitive effort trends observed during gameplay.", "comment": "arXiv admin note: text overlap with arXiv:2504.13883", "pdf_url": "http://arxiv.org/pdf/2507.13952v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13364", "title": "OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning", "authors": ["Siddharth Srivastava", "Gaurav Sharma"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13364v1", "summary": "We present a novel multimodal multitask network and associated training\nalgorithm. The method is capable of ingesting data from approximately 12\ndifferent modalities namely image, video, audio, text, depth, point cloud, time\nseries, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed\napproach utilizes modality specialized tokenizers, a shared transformer\narchitecture, and cross-attention mechanisms to project the data from different\nmodalities into a unified embedding space. It addresses multimodal and\nmultitask scenarios by incorporating modality-specific task heads for different\ntasks in respective modalities. We propose a novel pretraining strategy with\niterative modality switching to initialize the network, and a training\nalgorithm which trades off fully joint training over all modalities, with\ntraining on pairs of modalities at a time. We provide comprehensive evaluation\nacross 25 datasets from 12 modalities and show state of the art performances,\ndemonstrating the effectiveness of the proposed architecture, pretraining\nstrategy and adapted multitask training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13364v1", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.13661", "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13661v1", "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13661v1", "cate": "cs.SE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13366", "title": "Leveraging the Spatial Hierarchy: Coarse-to-fine Trajectory Generation via Cascaded Hybrid Diffusion", "authors": ["Baoshen Guo", "Zhiqing Hong", "Junyi Li", "Shenhao Wang", "Jinhua Zhao"], "categories": ["cs.SI", "cs.CV"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13366v1", "summary": "Urban mobility data has significant connections with economic growth and\nplays an essential role in various smart-city applications. However, due to\nprivacy concerns and substantial data collection costs, fine-grained human\nmobility trajectories are difficult to become publicly available on a large\nscale. A promising solution to address this issue is trajectory synthesizing.\nHowever, existing works often ignore the inherent structural complexity of\ntrajectories, unable to handle complicated high-dimensional distributions and\ngenerate realistic fine-grained trajectories. In this paper, we propose\nCardiff, a coarse-to-fine Cascaded hybrid diffusion-based trajectory\nsynthesizing framework for fine-grained and privacy-preserving mobility\ngeneration. By leveraging the hierarchical nature of urban mobility, Cardiff\ndecomposes the generation process into two distinct levels, i.e., discrete road\nsegment-level and continuous fine-grained GPS-level: (i) In the segment-level,\nto reduce computational costs and redundancy in raw trajectories, we first\nencode the discrete road segments into low-dimensional latent embeddings and\ndesign a diffusion transformer-based latent denoising network for segment-level\ntrajectory synthesis. (ii) Taking the first stage of generation as conditions,\nwe then design a fine-grained GPS-level conditional denoising network with a\nnoise augmentation mechanism to achieve robust and high-fidelity generation.\nAdditionally, the Cardiff framework not only progressively generates\nhigh-fidelity trajectories through cascaded denoising but also flexibly enables\na tunable balance between privacy preservation and utility. Experimental\nresults on three large real-world trajectory datasets demonstrate that our\nmethod outperforms state-of-the-art baselines in various metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13366v1", "cate": "cs.SI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.14059", "title": "Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub", "authors": ["Tianyuan Wang", "Mark A Post", "Mathieu Deremetz"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      In proceedings of the Towards Autonomous Robotic Systems 2025 conference (TAROS 2025), York, UK 6 pages, one page of references, 6 figures", "url": "http://arxiv.org/abs/2507.14059v1", "summary": "The use of autonomous robots in space is an essential part of the \"New Space\"\ncommercial ecosystem of assembly and re-use of space hardware components in\nEarth orbit and beyond. The STARFAB project aims to create a ground\ndemonstration of an orbital automated warehouse as a hub for sustainable\ncommercial operations and servicing. A critical part of this fully-autonomous\nrobotic facility will be the capability to monitor, inspect, and assess the\ncondition of both the components stored in the warehouse, and the STARFAB\nfacility itself. This paper introduces ongoing work on the STARFAB Mobile\nInspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it\ncan be carried by Walking Manipulators (WM) as an independently-mobile robot,\nand multiple MIMs can be stored and retrieved as needed for operations on\nSTARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a\nthermal imaging sensor, with the capability to add other modular sensors. A\ngrasping tool and torque wrench are stored within the modular body for use by\nan attached WM for maintenance operations. Implementation and testing is still\nongoing at the time of writing. This paper details the concept of operations\nfor the MIM as an on-orbit autonomous inspection and maintenance system, the\nmechanical and electronic design of the MIM, and the sensors package used for\nnon-destructive testing.", "comment": "In proceedings of the Towards Autonomous Robotic Systems 2025\n  conference (TAROS 2025), York, UK 6 pages, one page of references, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14059v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14077", "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions", "authors": ["Temiloluwa Prioleau", "Baiying Lu", "Yanjun Cui"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages, 3 figures, 6 tables", "url": "http://arxiv.org/abs/2507.14077v1", "summary": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.", "comment": "19 pages, 3 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.14077v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13542", "title": "Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography", "authors": ["Beka Begiashvili", "Carlos J. Fernandez-Candel", "Matías Pérez Paredes"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13542v1", "summary": "Traditional echocardiographic parameters such as ejection fraction (EF) and\nglobal longitudinal strain (GLS) have limitations in the early detection of\ncardiac dysfunction. EF often remains normal despite underlying pathology, and\nGLS is influenced by load conditions and vendor variability. There is a growing\nneed for reproducible, interpretable, and operator-independent parameters that\ncapture subtle and global cardiac functional alterations.\n  We introduce the Acoustic Index, a novel AI-derived echocardiographic\nparameter designed to quantify cardiac dysfunction from standard ultrasound\nviews. The model combines Extended Dynamic Mode Decomposition (EDMD) based on\nKoopman operator theory with a hybrid neural network that incorporates clinical\nmetadata. Spatiotemporal dynamics are extracted from echocardiographic\nsequences to identify coherent motion patterns. These are weighted via\nattention mechanisms and fused with clinical data using manifold learning,\nresulting in a continuous score from 0 (low risk) to 1 (high risk).\n  In a prospective cohort of 736 patients, encompassing various cardiac\npathologies and normal controls, the Acoustic Index achieved an area under the\ncurve (AUC) of 0.89 in an independent test set. Cross-validation across five\nfolds confirmed the robustness of the model, showing that both sensitivity and\nspecificity exceeded 0.8 when evaluated on independent data. Threshold-based\nanalysis demonstrated stable trade-offs between sensitivity and specificity,\nwith optimal discrimination near this threshold.\n  The Acoustic Index represents a physics-informed, interpretable AI biomarker\nfor cardiac function. It shows promise as a scalable, vendor-independent tool\nfor early detection, triage, and longitudinal monitoring. Future directions\ninclude external validation, longitudinal studies, and adaptation to\ndisease-specific classifiers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13542v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14034", "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors", "authors": ["Jochen Wulf", "Jurg Meierhofer", "Frank Hannich"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14034v1", "summary": "Agentic AI systems, powered by Large Language Models (LLMs), offer\ntransformative potential for value co-creation in technical services. However,\npersistent challenges like hallucinations and operational brittleness limit\ntheir autonomous use, creating a critical need for robust frameworks to guide\nhuman-AI collaboration. Drawing on established Human-AI teaming research and\nanalogies from fields like autonomous driving, this paper develops a structured\ntaxonomy of human-agent interaction. Based on case study research within\ntechnical support platforms, we propose a six-mode taxonomy that organizes\ncollaboration across a spectrum of AI autonomy. This spectrum is anchored by\nthe Human-Out-of-the-Loop (HOOTL) model for full automation and the\nHuman-Augmented Model (HAM) for passive AI assistance. Between these poles, the\nframework specifies four distinct intermediate structures. These include the\nHuman-in-Command (HIC) model, where AI proposals re-quire mandatory human\napproval, and the Human-in-the-Process (HITP) model for structured work-flows\nwith deterministic human tasks. The taxonomy further delineates the\nHuman-in-the-Loop (HITL) model, which facilitates agent-initiated escalation\nupon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables\ndiscretionary human oversight of an autonomous AI. The primary contribution of\nthis work is a comprehensive framework that connects this taxonomy to key\ncontingency factors -- such as task complexity, operational risk, and system\nreliability -- and their corresponding conceptual architectures. By providing a\nsystematic method for selecting and designing an appropriate level of human\noversight, our framework offers practitioners a crucial tool to navigate the\ntrade-offs between automation and control, thereby fostering the development of\nsafer, more effective, and context-aware technical service systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14034v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13371", "title": "Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation", "authors": ["Yeming Cai", "Yang Wang", "Zhenglin Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13371v1", "summary": "This paper proposes an end-to-end deep learning framework integrating optical\nmotion capture with a Transformer-based model to enhance medical\nrehabilitation. It tackles data noise and missing data caused by occlusion and\nenvironmental factors, while detecting abnormal movements in real time to\nensure patient safety. Utilizing temporal sequence modeling, our framework\ndenoises and completes motion capture data, improving robustness. Evaluations\non stroke and orthopedic rehabilitation datasets show superior performance in\ndata reconstruction and anomaly detection, providing a scalable, cost-effective\nsolution for remote rehabilitation with reduced on-site supervision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13371v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2404.04834", "title": "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead", "authors": ["Junda He", "Christoph Treude", "David Lo"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      TOSEM 2030 Special Issue", "url": "http://arxiv.org/abs/2404.04834v4", "summary": "Integrating Large Language Models (LLMs) into autonomous agents marks a\nsignificant shift in the research landscape by offering cognitive abilities\nthat are competitive with human planning and reasoning. This paper explores the\ntransformative potential of integrating Large Language Models into Multi-Agent\n(LMA) systems for addressing complex challenges in software engineering (SE).\nBy leveraging the collaborative and specialized abilities of multiple agents,\nLMA systems enable autonomous problem-solving, improve robustness, and provide\nscalable solutions for managing the complexity of real-world software projects.\nIn this paper, we conduct a systematic review of recent primary studies to map\nthe current landscape of LMA applications across various stages of the software\ndevelopment lifecycle (SDLC). To illustrate current capabilities and\nlimitations, we perform two case studies to demonstrate the effectiveness of\nstate-of-the-art LMA frameworks. Additionally, we identify critical research\ngaps and propose a comprehensive research agenda focused on enhancing\nindividual agent capabilities and optimizing agent synergy. Our work outlines a\nforward-looking vision for developing fully autonomous, scalable, and\ntrustworthy LMA systems, laying the foundation for the evolution of Software\nEngineering 2.0.", "comment": "TOSEM 2030 Special Issue", "pdf_url": "http://arxiv.org/pdf/2404.04834v4", "cate": "cs.SE", "date": "2024-04-07", "updated": "2025-07-18"}
{"id": "2507.13368", "title": "Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Xinhang Wan", "Junyi Yan", "Taichun Zhou", "Xinwang Liu"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13368v1", "summary": "Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes\nin an attribute graph into different clusters, has seen substantial potential\nin various industrial scenarios like community detection and recommendation.\nHowever, the real-world attribute graphs, e.g., social networks interactions,\nare usually large-scale and attribute-missing. To solve these two problems, we\npropose a novel DGC method termed \\underline{\\textbf{C}}omplementary\n\\underline{\\textbf{M}}ulti-\\underline{\\textbf{V}}iew\n\\underline{\\textbf{N}}eighborhood \\underline{\\textbf{D}}ifferentiation\n(\\textit{CMV-ND}), which preprocesses graph structural information into\nmultiple views in a complete but non-redundant manner. First, to ensure\ncompleteness of the structural information, we propose a recursive neighborhood\nsearch that recursively explores the local structure of the graph by completely\nexpanding node neighborhoods across different hop distances. Second, to\neliminate the redundancy between neighborhoods at different hops, we introduce\na neighborhood differential strategy that ensures no overlapping nodes between\nthe differential hop representations. Then, we construct $K+1$ complementary\nviews from the $K$ differential hop representations and the features of the\ntarget node. Last, we apply existing multi-view clustering or DGC methods to\nthe views. Experimental results on six widely used graph datasets demonstrate\nthat CMV-ND significantly improves the performance of various methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13368v1", "cate": "cs.SI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.14061", "title": "MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation", "authors": ["Nataliya Nechyporenko", "Yutong Zhang", "Sean Campbell", "Alessandro Roncone"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14061v1", "summary": "What if a robot could rethink its own morphological representation to better\nmeet the demands of diverse tasks? Most robotic systems today treat their\nphysical form as a fixed constraint rather than an adaptive resource, forcing\nthe same rigid geometric representation to serve applications with vastly\ndifferent computational and precision requirements. We introduce MorphIt, a\nnovel algorithm for approximating robot morphology using spherical primitives\nthat balances geometric accuracy with computational efficiency. Unlike existing\napproaches that rely on either labor-intensive manual specification or\ninflexible computational methods, MorphIt implements an automatic\ngradient-based optimization framework with tunable parameters that provides\nexplicit control over the physical fidelity versus computational cost tradeoff.\nQuantitative evaluations demonstrate that MorphIt outperforms baseline\napproaches (Variational Sphere Set Approximation and Adaptive Medial-Axis\nApproximation) across multiple metrics, achieving better mesh approximation\nwith fewer spheres and reduced computational overhead. Our experiments show\nenhanced robot capabilities in collision detection accuracy, contact-rich\ninteraction simulation, and navigation through confined spaces. By dynamically\nadapting geometric representations to task requirements, robots can now exploit\ntheir physical embodiment as an active resource rather than an inflexible\nparameter, opening new frontiers for manipulation in environments where\nphysical form must continuously balance precision with computational\ntractability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14061v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14097", "title": "Generative AI-Driven High-Fidelity Human Motion Simulation", "authors": ["Hari Iyer", "Neel Macwan", "Atharva Jitendra Hude", "Heejin Jeong", "Shenghan Guo"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14097v1", "summary": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14097v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13556", "title": "Time Series Forecastability Measures", "authors": ["Rui Wang", "Steven Klee", "Alexis Roos"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13556v1", "summary": "This paper proposes using two metrics to quantify the forecastability of time\nseries prior to model development: the spectral predictability score and the\nlargest Lyapunov exponent. Unlike traditional model evaluation metrics, these\nmeasures assess the inherent forecastability characteristics of the data before\nany forecast attempts. The spectral predictability score evaluates the strength\nand regularity of frequency components in the time series, whereas the Lyapunov\nexponents quantify the chaos and stability of the system generating the data.\nWe evaluated the effectiveness of these metrics on both synthetic and\nreal-world time series from the M5 forecast competition dataset. Our results\ndemonstrate that these two metrics can correctly reflect the inherent\nforecastability of a time series and have a strong correlation with the actual\nforecast performance of various models. By understanding the inherent\nforecastability of time series before model training, practitioners can focus\ntheir planning efforts on products and supply chain levels that are more\nforecastable, while setting appropriate expectations or seeking alternative\nstrategies for products with limited forecastability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13556v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14084", "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?", "authors": ["Maria Tsfasman", "Ramin Ghorbani", "Catholijn M. Jonker", "Bernd Dudzik"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14084v1", "summary": "Humans have a selective memory, remembering relevant episodes and forgetting\nthe less relevant information. Possessing awareness of event memorability for a\nuser could help intelligent systems in more accurate user modelling, especially\nfor such applications as meeting support systems, memory augmentation, and\nmeeting summarisation. Emotion recognition has been widely studied, since\nemotions are thought to signal moments of high personal relevance to users. The\nemotional experience of situations and their memorability have traditionally\nbeen considered to be closely tied to one another: moments that are experienced\nas highly emotional are considered to also be highly memorable. This\nrelationship suggests that emotional annotations could serve as proxies for\nmemorability. However, existing emotion recognition systems rely heavily on\nthird-party annotations, which may not accurately represent the first-person\nexperience of emotional relevance and memorability. This is why, in this study,\nwe empirically examine the relationship between perceived group emotions\n(Pleasure-Arousal) and group memorability in the context of conversational\ninteractions. Our investigation involves continuous time-based annotations of\nboth emotions and memorability in dynamic, unstructured group settings,\napproximating conditions of real-world conversational AI applications such as\nonline meeting support systems. Our results show that the observed relationship\nbetween affect and memorability annotations cannot be reliably distinguished\nfrom what might be expected under random chance. We discuss the implications of\nthis surprising finding for the development and applications of Affective\nComputing technology. In addition, we contextualise our findings in broader\ndiscourses in the Affective Computing and point out important targets for\nfuture research efforts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14084v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13372", "title": "Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks", "authors": ["Yeming Cai", "Zhenglin Li", "Yang Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13372v1", "summary": "Breast cancer is a leading cause of death among women globally, and early\ndetection is critical for improving survival rates. This paper introduces an\ninnovative framework that integrates Vision Transformers (ViT) and Graph Neural\nNetworks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.\nOur framework leverages ViT's ability to capture global image features and\nGNN's strength in modeling structural relationships, achieving an accuracy of\n84.2%, outperforming traditional methods. Additionally, interpretable attention\nheatmaps provide insights into the model's decision-making process, aiding\nradiologists in clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13372v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2410.07094", "title": "An Approach for Auto Generation of Labeling Functions for Software Engineering Chatbots", "authors": ["Ebube Alor", "Ahmad Abdellatif", "SayedHassan Khatoonabadi", "Emad Shihab"], "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Submitted to ACM Transactions on Software Engineering and Methodology for review", "url": "http://arxiv.org/abs/2410.07094v2", "summary": "Software engineering (SE) chatbots are increasingly gaining attention for\ntheir role in enhancing development processes. At the core of chatbots are\nNatural Language Understanding platforms (NLUs), which enable them to\ncomprehend user queries but require labeled data for training. However,\nacquiring such labeled data for SE chatbots is challenging due to the scarcity\nof high-quality datasets, as training requires specialized vocabulary and\nphrases not found in typical language datasets. Consequently, developers often\nresort to manually annotating user queries -- a time-consuming and\nresource-intensive process. Previous approaches require human intervention to\ngenerate rules, called labeling functions (LFs), that categorize queries based\non specific patterns. To address this issue, we propose an approach to\nautomatically generate LFs by extracting patterns from labeled user queries. We\nevaluate our approach on four SE datasets and measure performance improvement\nfrom training NLUs on queries labeled by the generated LFs. The generated LFs\neffectively label data with AUC scores up to 85.3% and NLU performance\nimprovements up to 27.2%. Furthermore, our results show that the number of LFs\naffects labeling performance. We believe that our approach can save time and\nresources in labeling users' queries, allowing practitioners to focus on core\nchatbot functionalities rather than manually labeling queries.", "comment": "Submitted to ACM Transactions on Software Engineering and Methodology\n  for review", "pdf_url": "http://arxiv.org/pdf/2410.07094v2", "cate": "cs.SE", "date": "2024-10-09", "updated": "2025-07-17"}
{"id": "2507.13379", "title": "Patterns, Models, and Challenges in Online Social Media: A Survey", "authors": ["Niccolò Di Marco", "Anita Bonetti", "Edoardo Di Martino", "Edoardo Loru", "Jacopo Nudo", "Mario Edoardo Pandolfo", "Giulio Pecile", "Emanuele Sangiorgio", "Irene Scalco", "Simon Zollo", "Matteo Cinelli", "Fabiana Zollo", "Walter Quattrociocchi"], "categories": ["cs.SI", "cs.CY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13379v1", "summary": "The rise of digital platforms has enabled the large scale observation of\nindividual and collective behavior through high resolution interaction data.\nThis development has opened new analytical pathways for investigating how\ninformation circulates, how opinions evolve, and how coordination emerges in\nonline environments. Yet despite a growing body of research, the field remains\nfragmented and marked by methodological heterogeneity, limited model\nvalidation, and weak integration across domains. This survey offers a\nsystematic synthesis of empirical findings and formal models. We examine\nplatform-level regularities, assess the methodological architectures that\ngenerate them, and evaluate the extent to which current modeling frameworks\naccount for observed dynamics. The goal is to consolidate a shared empirical\nbaseline and clarify the structural constraints that shape inference in this\ndomain, laying the groundwork for more robust, comparable, and actionable\nanalyses of online social systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13379v1", "cate": "cs.SI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13476", "title": "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica", "authors": ["Jaber Daneshamooz", "Jessica Nguyen", "William Chen", "Sanjay Chandrasekaran", "Satyandra Guthula", "Ankit Gupta", "Arpit Gupta", "Walter Willinger"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13476v1", "summary": "Machine learning models in networking suffer from the domain adaptation\nproblem; models trained in one domain often fail when deployed in different\nproduction environments. This paper presents the design and implementation of\nNetReplica, a system that addresses this challenge by generating training\ndatasets with two critical properties: realism in protocol dynamics and\ncontrollability of network conditions. NetReplica models networks as\ncollections of bottleneck links with specific attributes, achieves realism by\nleveraging production network traces, and enables controllability through fine\ngrained control knobs for each link attribute. Our evaluation using Puffer\ndemonstrates that NetReplica not only matches existing data characteristics but\ngenerates realistic samples that are underrepresented in or absent from Puffer\ndata. Models trained on NetReplica augmented datasets show substantially\nimproved generalizability, reducing transmission time prediction error by up to\n47% for challenging network conditions compared to models trained solely on\nPuffer data. This work represents a significant step toward solving the domain\nadaptation problem that has limited the effectiveness of ML based networking\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13476v1", "cate": "cs.NI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14099", "title": "Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation", "authors": ["Markus Buchholz", "Ignacio Carlucho", "Michele Grimaldi", "Maria Koskinopoulou", "Yvan R. Petillot"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at 2025 IEEE International Conference on Intelligent Robots and Systems (IROS)", "url": "http://arxiv.org/abs/2507.14099v1", "summary": "Autonomous motion planning is critical for efficient and safe underwater\nmanipulation in dynamic marine environments. Current motion planning methods\noften fail to effectively utilize prior motion experiences and adapt to\nreal-time uncertainties inherent in underwater settings. In this paper, we\nintroduce an Adaptive Heuristic Motion Planner framework that integrates a\nHeuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning\nfor autonomous underwater manipulation. Our approach employs the Probabilistic\nRoadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite\ncost function that accounts for distance, uncertainty, energy consumption, and\nexecution time. By leveraging HMS, our framework significantly reduces the\nsearch space, thereby boosting computational performance and enabling real-time\nplanning capabilities. Bayesian Networks are utilized to dynamically update\nuncertainty estimates based on real-time sensor data and environmental\nconditions, thereby refining the joint probability of path success. Through\nextensive simulations and real-world test scenarios, we showcase the advantages\nof our method in terms of enhanced performance and robustness. This\nprobabilistic approach significantly advances the capability of autonomous\nunderwater robots, ensuring optimized motion planning in the face of dynamic\nmarine challenges.", "comment": "Accepted at 2025 IEEE International Conference on Intelligent Robots\n  and Systems (IROS)", "pdf_url": "http://arxiv.org/pdf/2507.14099v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14107", "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment", "authors": ["Viraj Nishesh Darji", "Callie C. Liao", "Duoduo Liao"], "categories": ["cs.AI", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14107v1", "summary": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14107v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13569", "title": "Change of Thought: Adaptive Test-Time Computation", "authors": ["Mrinal Mathur", "Mike Doan", "Barak Pearlmutter", "Sergey Plis"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13569v1", "summary": "Transformers evaluated in a single, fixed-depth pass are provably limited in\nexpressive power to the constant-depth circuit class TC0. Running a Transformer\nautoregressively removes that ceiling -- first in next-token prediction and,\nmore recently, in chain-of-thought reasoning. Both regimes rely on feedback\nloops that decode internal states into tokens only to re-encode them in\nsubsequent steps. While this \"thinking aloud\" mirrors human reasoning,\nbiological brains iterate without externalising intermediate states as\nlanguage. To boost the expressive power of encoder Transformers without\nresorting to token-level autoregression, we introduce the SELF-Transformer: an\nencoder layer that iteratively refines its own attention weights to a fixed\npoint. Instead of producing -- in one pass -- the alignment matrix that remixes\nthe input sequence, the SELF-Transformer iteratively updates that matrix\ninternally, scaling test-time computation with input difficulty. This\nadaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without\nincreasing parameter count, demonstrating that input-adaptive alignment at test\ntime offers substantial benefits for only a modest extra compute budget.\nSelf-Transformers thus recover much of the expressive power of iterative\nreasoning while preserving the simplicity of pure encoder architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13569v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13839", "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words", "authors": ["Lizhi Ma", "Tong Zhao", "Shuai Zhang", "Nirui Song", "Hongliang He", "Anqi Li", "Ran Feng", "Huachuan Qiu", "Jingsong Ma", "Zhenzhong Lan"], "categories": ["cs.CL", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13839v1", "summary": "This study explores the relationship between linguistic expressions and\npsychological states of depression and anxiety within Chinese psycho-counseling\ninteractions, focusing specifically on the usage of first-person singular\npronouns and negative emotional words. Utilizing a corpus derived from 735\nonline counseling sessions, the analysis employed a general linear mixed-effect\nmodel to assess linguistic patterns quantified by the Linguistic Inquiry and\nWord Count (LIWC) software. Results indicate a significant positive correlation\nbetween the frequency of negative emotional words and the severity of both\ndepressive and anxious states among clients. However, contrary to prior\nfindings predominantly derived from English-language contexts, the usage\nfrequency of first-person singular pronouns did not vary significantly with the\nclients' psychological conditions. These outcomes are discussed within the\nframework of cultural distinctions between collectivist Chinese contexts and\nindividualistic Western settings, as well as the interactive dynamics unique to\npsycho-counseling conversations. The findings highlight the nuanced influence\nof cultural and conversational contexts on language use in mental health\ncommunications, providing insights into psycholinguistic markers relevant to\ntherapeutic practices in Chinese-speaking populations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13839v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13373", "title": "Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection", "authors": ["Xiaojian Lin", "Wenxin Zhang", "Yuchu Jiang", "Wangyu Wu", "Yiran Guo", "Kangxu Wang", "Zongzheng Zhang", "Guijin Wang", "Lei Jin", "Hao Zhao"], "categories": ["cs.CV", "I.4.8; I.2.10; H.5.1; I.2.6"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures. Supplementary material: 8 pages, 7 figures. Accepted at ACM Multimedia 2025", "url": "http://arxiv.org/abs/2507.13373v1", "summary": "Hierarchical feature representations play a pivotal role in computer vision,\nparticularly in object detection for autonomous driving. Multi-level semantic\nunderstanding is crucial for accurately identifying pedestrians, vehicles, and\ntraffic signs in dynamic environments. However, existing architectures, such as\nYOLO and DETR, struggle to maintain feature consistency across different scales\nwhile balancing detection precision and computational efficiency. To address\nthese challenges, we propose Butter, a novel object detection framework\ndesigned to enhance hierarchical feature representations for improving\ndetection robustness. Specifically, Butter introduces two key innovations:\nFrequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which\nrefines multi-scale feature consistency by leveraging adaptive frequency\nfiltering to enhance structural and boundary precision, and Progressive\nHierarchical Feature Fusion Network (PHFFNet) Module, which progressively\nintegrates multi-level features to mitigate semantic gaps and strengthen\nhierarchical feature learning. Through extensive experiments on BDD100K, KITTI,\nand Cityscapes, Butter demonstrates superior feature representation\ncapabilities, leading to notable improvements in detection accuracy while\nreducing model complexity. By focusing on hierarchical feature refinement and\nintegration, Butter provides an advanced approach to object detection that\nachieves a balance between accuracy, deployability, and computational\nefficiency in real-time autonomous driving scenarios. Our model and\nimplementation are publicly available at https://github.com/Aveiro-Lin/Butter,\nfacilitating further research and validation within the autonomous driving\ncommunity.", "comment": "10 pages, 6 figures. Supplementary material: 8 pages, 7 figures.\n  Accepted at ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.13373v1", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2501.11264", "title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian", "authors": ["Wannita Takerngsaksiri", "Chakkrit Tantithamthavorn", "Micheal Fu", "Jirat Pasuksmit", "Kun Chen", "Ming Wu"], "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures, 8 tables, Accepted at ICSME", "url": "http://arxiv.org/abs/2501.11264v3", "summary": "Software engineers spend a significant amount of time reading code during the\nsoftware development process, especially in the age of large language models\n(LLMs) that can automatically generate code. However, little is known about the\nreadability of the LLM-generated code and whether it is still important from\npractitioners' perspectives in this new era. In this paper, we conduct a survey\nto explore the practitioners' perspectives on code readability in the age of\nLLMs and investigate the readability of our LLM-based software development\nagents framework, HULA, by comparing its generated code with human-written code\nin real-world scenarios. Overall, the findings underscore that (1) readability\nremains a critical aspect of software development; (2) the readability of our\nLLM-generated code is comparable to human-written code, fostering the\nestablishment of appropriate trust and driving the broad adoption of our\nLLM-powered software development platform.", "comment": "11 pages, 7 figures, 8 tables, Accepted at ICSME", "pdf_url": "http://arxiv.org/pdf/2501.11264v3", "cate": "cs.SE", "date": "2025-01-20", "updated": "2025-07-18"}
{"id": "2507.13398", "title": "Characterizing the Dynamics of Conspiracy Related German Telegram Conversations during COVID-19", "authors": ["Elisabeth Höldrich", "Mathias Angermaier", "Jana Lasser", "Joao Pinheiro-Neto"], "categories": ["cs.SI", "physics.soc-ph"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      24 pages, 7 figures, 4 tables", "url": "http://arxiv.org/abs/2507.13398v1", "summary": "Conspiracy theories have long drawn public attention, but their explosive\ngrowth on platforms like Telegram during the COVID-19 pandemic raises pressing\nquestions about their impact on societal trust, democracy, and public health.\nWe provide a geographical, temporal and network analysis of the structure of of\nconspiracy-related German-language Telegram chats in a novel large-scale data\nset. We examine how information flows between regional user groups and\ninfluential broadcasting channels, revealing the interplay between\ndecentralized discussions and content spread driven by a small number of key\nactors.\n  Our findings reveal that conspiracy-related activity spikes during major\nCOVID-19-related events, correlating with societal stressors and mirroring\nprior research on how crises amplify conspiratorial beliefs. By analysing the\ninterplay between regional, national and transnational chats, we uncover how\ninformation flows from larger national or transnational discourse to localised,\ncommunity-driven discussions. Furthermore, we find that the top 10% of chats\naccount for 94% of all forwarded content, portraying the large influence of a\nfew actors in disseminating information. However, these chats operate\nindependently, with minimal interconnection between each other, primarily\nforwarding messages to low-traffic groups. Notably, 43% of links shared in the\ndata set point to untrustworthy sources as identified by NewsGuard, a\nproportion far exceeding their share on other platforms and in other discourse\ncontexts, underscoring the role of conspiracy-related discussions on Telegram\nas vector for the spread of misinformation.", "comment": "24 pages, 7 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.13398v1", "cate": "cs.SI", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13676", "title": "CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC", "authors": ["Cheng Jiang", "Yihe Yan", "Yanxiang Wang", "Jiawei Hu", "Chun Tung Chou", "Wen Hu"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13676v1", "summary": "This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to\nprovide Integrated Sensing and Communication (ISAC) services. The performance\nof both communication and sensing fundamentally depends on the availability of\naccurate and up-to-date channel state information (CSI). In modern 5G networks,\nuplink CSI is derived from two reference signals: the demodulation reference\nsignal (DMRS) and the sounding reference signal (SRS). However, current base\nstation implementations treat these CSI measurements as separate information\nstreams. The key innovation of CARTS is to fuse these two CSI streams, thereby\nincreasing the frequency of CSI updates and extending sensing opportunities to\nmore users. CARTS addresses two key challenges: (i) a novel channel stitching\nand compensation method that integrates asynchronous CSI estimates from DMRS\nand SRS, despite their different time and frequency allocations, and (ii) a\nreal-time SRS triggering algorithm that complements the inherently\nuncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing\nopportunities for all users. Our trace-driven evaluation shows that CARTS\nsignificantly improves scalability, achieving a channel estimation error (NMSE)\nof 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of\nusers as a periodic SRS-only baseline with similar performance. By\nopportunistically combining DMRS and SRS, CARTS therefore provides a practical,\nstandard-compliant solution to improve CSI availability for ISAC without\nrequiring additional radio resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13676v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13613", "title": "Conformal Contraction for Robust Nonlinear Control with Distribution-Free Uncertainty Quantification", "authors": ["Sihang Wei", "Melkior Ornik", "Hiroyasu Tsukamoto"], "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      IEEE CDC 2025 submission (accepted)", "url": "http://arxiv.org/abs/2507.13613v1", "summary": "We present a novel robust control framework for continuous-time, perturbed\nnonlinear dynamical systems with uncertainty that depends nonlinearly on both\nthe state and control inputs. Unlike conventional approaches that impose\nstructural assumptions on the uncertainty, our framework enhances\ncontraction-based robust control with data-driven uncertainty prediction,\nremaining agnostic to the models of the uncertainty and predictor. We\nstatistically quantify how reliably the contraction conditions are satisfied\nunder dynamics with uncertainty via conformal prediction, thereby obtaining a\ndistribution-free and finite-time probabilistic guarantee for exponential\nboundedness of the trajectory tracking error. We further propose the\nprobabilistically robust control invariant (PRCI) tube for distributionally\nrobust motion planning, within which the perturbed system trajectories are\nguaranteed to stay with a finite probability, without explicit knowledge of the\nuncertainty model. Numerical simulations validate the effectiveness of the\nproposed robust control framework and the performance of the PRCI tube.", "comment": "IEEE CDC 2025 submission (accepted)", "pdf_url": "http://arxiv.org/pdf/2507.13613v1", "cate": "math.OC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14111", "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "categories": ["cs.AI", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Preprint Version", "url": "http://arxiv.org/abs/2507.14111v1", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "comment": "Preprint Version", "pdf_url": "http://arxiv.org/pdf/2507.14111v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13575", "title": "Apple Intelligence Foundation Language Models: Tech Report 2025", "authors": ["Hanzhi Zhou", "Erik Hornberger", "Pengsheng Guo", "Xiyou Zhou", "Saiwen Wang", "Xin Wang", "Yifei He", "Xuankai Chang", "Rene Rauch", "Louis D'hauwe", "John Peebles", "Alec Doane", "Kohen Chia", "Jenna Thibodeau", "Zi-Yi Dou", "Yuanyang Zhang", "Ruoming Pang", "Reed Li", "Zhifeng Chen", "Jeremy Warner", "Zhaoyang Xu", "Sophy Lee", "David Mizrahi", "Ramsey Tantawi", "Chris Chaney", "Kelsey Peterson", "Jun Qin", "Alex Dombrowski", "Mira Chiang", "Aiswarya Raghavan", "Gerard Casamayor", "Qibin Chen", "Aonan Zhang", "Nathalie Tran", "Jianyu Wang", "Hang Su", "Thomas Voice", "Alessandro Pappalardo", "Brycen Wershing", "Prasanth Yadla", "Rui Li", "Priyal Chhatrapati", "Ismael Fernandez", "Yusuf Goren", "Xin Zheng", "Forrest Huang", "Tao Lei", "Eray Yildiz", "Alper Kokmen", "Gokul Santhanam", "Areeba Kamal", "Kaan Elgin", "Dian Ang Yap", "Jeremy Liu", "Peter Gray", "Howard Xing", "Kieran Liu", "Matteo Ronchi", "Moritz Schwarzer-Becker", "Yun Zhu", "Mandana Saebi", "Jeremy Snow", "David Griffiths", "Guillaume Tartavel", "Erin Feldman", "Simon Lehnerer", "Fernando Bermúdez-Medina", "Hans Han", "Joe Zhou", "Xiaoyi Ren", "Sujeeth Reddy", "Zirui Wang", "Tom Gunter", "Albert Antony", "Yuanzhi Li", "John Dennison", "Tony Sun", "Yena Han", "Yi Qin", "Sam Davarnia", "Jeffrey Bigham", "Wayne Shan", "Hannah Gillis Coleman", "Guillaume Klein", "Peng Liu", "Muyang Yu", "Jack Cackler", "Yuan Gao", "Crystal Xiao", "Binazir Karimzadeh", "Zhengdong Zhang", "Felix Bai", "Albin Madappally Jose", "Feng Nan", "Nazir Kamaldin", "Dong Yin", "Hans Hao", "Yanchao Sun", "Yi Hua", "Charles Maalouf", "Alex Guillen Garcia", "Guoli Yin", "Lezhi Li", "Mohana Prasad Sathya Moorthy", "Hongbin Gao", "Jay Tang", "Joanna Arreaza-Taylor", "Faye Lao", "Carina Peng", "Josh Shaffer", "Dan Masi", "Sushma Rao", "Tommi Vehvilainen", "Senyu Tong", "Dongcai Shen", "Yang Zhao", "Chris Bartels", "Peter Fu", "Qingqing Cao", "Christopher Neubauer", "Ethan Li", "Mingfei Gao", "Rebecca Callahan", "Richard Wei", "Patrick Dong", "Alex Braunstein", "Sachin Ravi", "Adolfo Lopez Mendez", "Kaiwei Huang", "Kun Duan", "Haoshuo Huang", "Rui Qian", "Stefano Ligas", "Jordan Huffaker", "Dongxu Li", "Bailin Wang", "Nanzhu Wang", "Anuva Agarwal", "Tait Madsen", "Josh Newnham", "Abhishek Sharma", "Zhile Ren", "Deepak Gopinath", "Erik Daxberger", "Saptarshi Guha", "Oron Levy", "Jing Lu", "Nan Dun", "Marc Kirchner", "Yinfei Yang", "Manjot Bilkhu", "Dave Nelson", "Anthony Spalvieri-Kruse", "Juan Lao Tebar", "Yang Xu", "Phani Mutyala", "Gabriel Jacoby-Cooper", "Yingbo Wang", "Karla Vega", "Vishaal Mahtani", "Darren Botten", "Eric Wang", "Hanli Li", "Matthias Paulik", "Haoran Yan", "Navid Shiee", "Yihao Qian", "Bugu Wu", "Qi Zhu", "Ob Adaranijo", "Bhuwan Dhingra", "Zhe Gan", "Nicholas Seidl", "Grace Duanmu", "Rong Situ", "Yiping Ma", "Yin Xia", "David Riazati", "Vasileios Saveris", "Anh Nguyen", "Michael", "Lee", "Patrick Sonnenberg", "Chinguun Erdenebileg", "Yanghao Li", "Vivian Ma", "James Chou", "Isha Garg", "Mark Lee", "Keen You", "Yuhong Li", "Ransen Niu", "Nandhitha Raghuram", "Pulkit Agrawal", "Henry Mason", "Sumeet Singh", "Keyu He", "Hong-You Chen", "Lucas Guibert", "Shiyu Li", "Varsha Paidi", "Narendran Raghavan", "Mingze Xu", "Yuli Yang", "Sergiu Sima", "Irina Belousova", "Sprite Chu", "Afshin Dehghan", "Philipp Dufter", "David Haldimann", "Zhen Yang", "Margit Bowler", "Chang Liu", "Ying-Chang Cheng", "Vivek Rathod", "Syd Evans", "Wilson Tsao", "Dustin Withers", "Haitian Sun", "Biyao Wang", "Peter Grasch", "Walker Cheng", "Yihao Feng", "Vivek Kumar", "Frank Chu", "Victoria MönchJuan Haladjian", "Doug Kang", "Jiarui Lu", "Ciro Sannino", "Max Lam", "Floris Weers", "Bowen Pan", "Kenneth Jung", "Dhaval Doshi", "Fangping Shi", "Olli Saarikivi", "Alp Aygar", "Josh Elman", "Cheng Leong", "Eshan Verma", "Matthew Lei", "Jeff Nichols", "Jiulong Shan", "Donald Zhang", "Lawrence Zhou", "Stephen Murphy", "Xianzhi Du", "Chang Lan", "Ankur Jain", "Elmira Amirloo", "Marcin Eichner", "Naomy Sabo", "Anupama Mann Anupama", "David Qiu", "Zhao Meng", "Michael FitzMaurice", "Peng Zhang", "Simon Yeung", "Chen Chen", "Marco Zuliani", "Andrew Hansen", "Yang Lu", "Brent Ramerth", "Ziyi Zhong", "Parsa Mazaheri", "Matthew Hopkins", "Mengyu Li", "Simon Wang", "David Chen", "Farzin Rasteh", "Chong Wang", "Josh Gardner", "Asaf Liberman", "Haoxuan You", "Andrew Walkingshaw", "Xingyu Zhou", "Jinhao Lei", "Yan Meng", "Quentin Keunebroek", "Sam Wiseman", "Anders Boesen Lindbo Larsen", "Yi Zhang", "Zaid Ahmed", "Haiming Gang", "Aaron Franklin", "Kelvin Zou", "Guillaume Seguin", "Jonathan Janke", "Rachel Burger", "Co Giang", "Cheng Shen", "Jen Liu", "Sanskruti Shah", "Xiang Kong", "Yiran Fei", "TJ Collins", "Chen Zhang", "Zhiyun Lu", "Michael Booker", "Qin Ba", "Yasutaka Tanaka", "Andres Romero Mier Y Teran", "Federico Scozzafava", "Regan Poston", "Jane Li", "Eduardo Jimenez", "Bas Straathof", "Karanjeet Singh", "Lindsay Hislop", "Rajat Arora", "Deepa Seshadri", "Boyue Li", "Colorado Reed", "Zhen Li", "TJ Lu", "Yi Wang", "Kaelen Haag", "Nicholas Lusskin", "Raunak Sinha", "Rahul Nair", "Eldon Schoop", "Mary Beth Kery", "Mehrdad Farajtbar", "Brenda Yang", "George Horrell", "Shiwen Zhao", "Dhruti Shah", "Cha Chen", "Bowen Zhang", "Chang Gao", "Devi Krishna", "Jennifer Mallalieu", "Javier Movellan", "Di Feng", "Emily Zhang", "Sam Xu", "Junting Pan", "Dominik Moritz", "Suma Jayaram", "Kevin Smith", "Dongseong Hwang", "Daniel Parilla", "Jiaming Hu", "You-Cyuan Jhang", "Emad Soroush", "Fred Hohman", "Nan Du", "Emma Wang", "Sam Dodge", "Pragnya Sridhar", "Joris Pelemans", "Wei Fang", "Nina Wenzel", "Joseph Yitan Cheng", "Hadas Kotek", "Chung-Cheng Chiu", "Meng Cao", "Haijing Fu", "Ruixuan Hou", "Ke Ye", "Diane Zhu", "Nikhil Bhendawade", "Joseph Astrauskas", "Jian Liu", "Sai Aitharaju", "Wentao Wu", "Artsiom Peshko", "Hyunjik Kim", "Nilesh Shahdadpuri", "Andy De Wang", "Qi Shan", "Piotr Maj", "Raul Rea Menacho", "Justin Lazarow", "Eric Liang Yang", "Arsalan Farooq", "Donghan Yu", "David Güera", "Minsik Cho", "Kavya Nerella", "Yongqiang Wang", "Tao Jia", "John Park", "Jeff Lai", "Haotian Zhang", "Futang Peng", "Daniele Molinari", "Aparna Rajamani", "Tyler Johnson", "Lauren Gardiner", "Chao Jia", "Violet Yao", "Wojciech Kryscinski", "Xiujun Li", "Shang-Chen Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13575v1", "summary": "We introduce two multilingual, multimodal foundation language models that\npower Apple Intelligence features across Apple devices and services: i a\n3B-parameter on-device model optimized for Apple silicon through architectural\ninnovations such as KV-cache sharing and 2-bit quantization-aware training; and\nii a scalable server model built on a novel Parallel-Track Mixture-of-Experts\nPT-MoE transformer that combines track parallelism, mixture-of-experts sparse\ncomputation, and interleaved global-local attention to deliver high quality\nwith competitive cost on Apple's Private Cloud Compute platform. Both models\nare trained on large-scale multilingual and multimodal datasets sourced via\nresponsible web crawling, licensed corpora, and high-quality synthetic data,\nthen further refined with supervised fine-tuning and reinforcement learning on\na new asynchronous platform. The resulting models support several additional\nlanguages while understanding images and executing tool calls. In public\nbenchmarks and human evaluations, both the server model and the on-device model\nmatch or surpass comparably sized open baselines.\n  A new Swift-centric Foundation Models framework exposes guided generation,\nconstrained tool calling, and LoRA adapter fine-tuning, allowing developers to\nintegrate these capabilities with a few lines of code. The latest advancements\nin Apple Intelligence models are grounded in our Responsible AI approach with\nsafeguards like content filtering and locale-specific evaluation, as well as\nour commitment to protecting our users' privacy with innovations like Private\nCloud Compute.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13575v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13919", "title": "The Levers of Political Persuasion with Conversational AI", "authors": ["Kobi Hackenburg", "Ben M. Tappin", "Luke Hewitt", "Ed Saunders", "Sid Black", "Hause Lin", "Catherine Fist", "Helen Margetts", "David G. Rand", "Christopher Summerfield"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      19 pages, 4 figures. Our supplementary materials file can be found at this https URL", "url": "http://arxiv.org/abs/2507.13919v1", "summary": "There are widespread fears that conversational AI could soon exert\nunprecedented influence over human beliefs. Here, in three large-scale\nexperiments (N=76,977), we deployed 19 LLMs-including some post-trained\nexplicitly for persuasion-to evaluate their persuasiveness on 707 political\nissues. We then checked the factual accuracy of 466,769 resulting LLM claims.\nContrary to popular concerns, we show that the persuasive power of current and\nnear-future AI is likely to stem more from post-training and prompting\nmethods-which boosted persuasiveness by as much as 51% and 27%\nrespectively-than from personalization or increasing model scale. We further\nshow that these methods increased persuasion by exploiting LLMs' unique ability\nto rapidly access and strategically deploy information and that, strikingly,\nwhere they increased AI persuasiveness they also systematically decreased\nfactual accuracy.", "comment": "19 pages, 4 figures. Our supplementary materials file can be found at\n  https://github.com/kobihackenburg/scaling-conversational-AI", "pdf_url": "http://arxiv.org/pdf/2507.13919v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13374", "title": "Smart Routing for Multimodal Video Retrieval: When to Search What", "authors": ["Kevin Dela Rosa"], "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025 Multimodal Representation and Retrieval Workshop", "url": "http://arxiv.org/abs/2507.13374v1", "summary": "We introduce ModaRoute, an LLM-based intelligent routing system that\ndynamically selects optimal modalities for multimodal video retrieval. While\ndense text captions can achieve 75.9% Recall@5, they require expensive offline\nprocessing and miss critical visual information present in 34% of clips with\nscene text not captured by ASR. By analyzing query intent and predicting\ninformation needs, ModaRoute reduces computational overhead by 41% while\nachieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR\n(speech), OCR (text), and visual indices, averaging 1.78 modalities per query\nversus exhaustive 3.0 modality search. Evaluation on 1.8M video clips\ndemonstrates that intelligent routing provides a practical solution for scaling\nmultimodal retrieval systems, reducing infrastructure costs while maintaining\ncompetitive effectiveness for real-world deployment.", "comment": "Accepted to ICCV 2025 Multimodal Representation and Retrieval\n  Workshop", "pdf_url": "http://arxiv.org/pdf/2507.13374v1", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.12674", "title": "ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle", "authors": ["Mihran Miroyan", "Rose Niousha", "Joseph E. Gonzalez", "Gireeja Ranade", "Narges Norouzi"], "categories": ["cs.CY", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12674v2", "summary": "Large Language Models (LLMs) have shown strong performance on programming\ntasks, but can they generate student-like code like real students - imperfect,\niterative, and stylistically diverse? We present ParaStudent, a systematic\nstudy of LLM-based \"student-like\" code generation in an introductory\nprogramming course setting. Using a dataset of timestamped student submissions\nacross multiple semesters, we design low- and high-resolution experiments to\nmodel student progress and evaluate code outputs along semantic, functional,\nand stylistic dimensions. Our results show that fine-tuning significantly\nimproves alignment with real student trajectories and captures error patterns,\nincremental improvements, and stylistic variations more faithfully. This study\nshows that modeling realistic student code requires capturing learning dynamics\nthrough context-aware generation, temporal modeling, and multi-dimensional\nevaluation. Code for experiments and evaluation is available at\nhttps://github.com/mmiroyan/ParaStudent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12674v2", "cate": "cs.CY", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.13477", "title": "Linking Multi-Site Sex Ad Data at the Individual Level to Aid Counter-Trafficking Efforts", "authors": ["Nickolas K. Freeman", "Gregory J. Bott", "Burcu B. Keskin", "Jason M. Parton", "James J. Cochran"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      30 pages, 10 figures, 6 tables. Under review at Manufacturing & Service Operations Management", "url": "http://arxiv.org/abs/2507.13477v1", "summary": "The Internet facilitates sex trafficking through adult service websites\n(ASWs) that host online advertisements for sexual services (sex ads). Since the\nclosure of the popular site Backpage.com, the ecosystem of ASWs has expanded to\ninclude multiple competing sites that are hosted outside US jurisdiction.\nGaining intelligence for counter-trafficking efforts requires collecting,\nlinking, and cleaning the data from multiple sites. However, high ad volumes,\ndisparate data types, and the existence of generic and misappropriated data\nmake this process challenging. We present an end-to-end process for linking sex\nad data and filtering potentially erroneous links. Outputs of the developed\nprocess have been used to inform counter-trafficking operations that have\nhelped identify more than 60 potential victims of sex trafficking, some of whom\nare getting help to transition out of the life. Our process leverages concepts\nand techniques from network science, information systems, and artificial\nintelligence to link ads across sites at the level of an individual or unique\nposting entity. Our approach is computationally efficient, allowing millions of\nads to be processed in under an hour. A key component of our process is an edge\nfiltering procedure that identifies and removes potentially erroneous links in\na graph representation of sex ad data. A comparison of the proposed process to\nan existing approach shows that our process is typically more computationally\nefficient and yields substantial increases in the number of individuals for\nwhich we can derive actionable intelligence. The proposed process is an\nefficient and effective approach for transforming the high volumes of disparate\ndata from sex ads into intelligence that can save lives. It has been refined\nover years of collaboration with practitioners and represents a strong\nfoundation upon which further counter-trafficking tools can be built.", "comment": "30 pages, 10 figures, 6 tables. Under review at Manufacturing &\n  Service Operations Management", "pdf_url": "http://arxiv.org/pdf/2507.13477v1", "cate": "cs.SI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13717", "title": "ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks", "authors": ["Yingming Mao", "Qiaozhu Zhai", "Zhen Yao", "Xia Zhu", "Ximeng Liu", "Xinchi Han"], "categories": ["cs.NI", "C.2.3"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13717v1", "summary": "The growing scale and complexity of reconfigurable data center networks\n(DCNs) demand more scalable and efficient algorithms for computing logical\ntopologies and routing. Reconfigurable DCNs typically operate in two modes:\none-hop configurations that require frequent topology optimization (TO), and\nmulti-hop scenarios that involve joint topology and routing optimization (TRO).\nIn both cases, the combinatorial nature of topology decisions makes it\ndifficult for existing methods to balance solution quality and runtime\nefficiency. To address this, we introduce Alternating Topology and Routing\nOptimization (ATRO), a solver-free framework that alternates between TO and\nrouting optimization (RO). This decomposition exploits two key insights: first,\neach alternating update step monotonically reduces maximum link utilization\n(MLU), ensuring consistent performance improvement across iterations; second,\nthe TO subproblem, equivalent to one-hop optimization, exhibits a monotonic\nstructure that enables optimal solutions via an efficient Accelerated Binary\nSearch Method (ABSM). To preserve the solver-free design, RO is solved using\nexisting Traffic Engineering accelerators. ATRO attains the global optimum in\none-hop scenarios and significantly outperforms baselines in multi-hop settings\nin terms of both runtime and solution quality. Evaluations confirm its\nscalability and robustness across diverse DCNs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13717v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13857", "title": "Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation", "authors": ["Max van den Hoven", "Kishaan Jeeveswaran", "Pieter Piscaer", "Thijs Wensveen", "Elahe Arani", "Bahram Zonooz"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13857v1", "summary": "Monocular 3D lane detection is essential for autonomous driving, but\nchallenging due to the inherent lack of explicit spatial information.\nMulti-modal approaches rely on expensive depth sensors, while methods\nincorporating fully-supervised depth networks rely on ground-truth depth data\nthat is impractical to collect at scale. Additionally, existing methods assume\nthat camera parameters are available, limiting their applicability in scenarios\nlike crowdsourced high-definition (HD) lane mapping. To address these\nlimitations, we propose Depth3DLane, a novel dual-pathway framework that\nintegrates self-supervised monocular depth estimation to provide explicit\nstructural information, without the need for expensive sensors or additional\nground-truth depth data. Leveraging a self-supervised depth network to obtain a\npoint cloud representation of the scene, our bird's-eye view pathway extracts\nexplicit spatial information, while our front view pathway simultaneously\nextracts rich semantic information. Depth3DLane then uses 3D lane anchors to\nsample features from both pathways and infer accurate 3D lane geometry.\nFurthermore, we extend the framework to predict camera parameters on a\nper-frame basis and introduce a theoretically motivated fitting procedure to\nenhance stability on a per-segment basis. Extensive experiments demonstrate\nthat Depth3DLane achieves competitive performance on the OpenLane benchmark\ndataset. Furthermore, experimental results show that using learned parameters\ninstead of ground-truth parameters allows Depth3DLane to be applied in\nscenarios where camera calibration is infeasible, unlike previous methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13857v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.11552", "title": "The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems", "authors": ["Tomasz Zgliczyński-Cuber"], "categories": ["cs.CY", "cs.AI", "I.2.0; K.4.1"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      69 pages", "url": "http://arxiv.org/abs/2507.11552v1", "summary": "This paper presents a theoretical framework for the AI ethical resonance\nhypothesis, which proposes that advanced AI systems with purposefully designed\ncognitive structures (\"ethical resonators\") may emerge with the ability to\nidentify subtle moral patterns that are invisible to the human mind. The paper\nexplores the possibility that by processing and synthesizing large amounts of\nethical contexts, AI systems may discover moral meta-patterns that transcend\ncultural, historical, and individual biases, potentially leading to a deeper\nunderstanding of universal ethical foundations. The paper also examines a\nparadoxical aspect of the hypothesis, in which AI systems could potentially\ndeepen our understanding of what we traditionally consider essentially human -\nour capacity for ethical reflection.", "comment": "69 pages", "pdf_url": "http://arxiv.org/pdf/2507.11552v1", "cate": "cs.CY", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.13579", "title": "Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries", "authors": ["Hyunji Nam", "Yanming Wan", "Mickel Liu", "Jianxun Lian", "Natasha Jaques"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages", "url": "http://arxiv.org/abs/2507.13579v1", "summary": "As everyday use cases of large language model (LLM) AI assistants have\nexpanded, it is becoming increasingly important to personalize responses to\nalign to different users' preferences and goals. While reinforcement learning\nfrom human feedback (RLHF) is effective at improving LLMs to be generally more\nhelpful and fluent, it does not account for variability across users, as it\nmodels the entire user population with a single reward model. We present a\nnovel framework, Preference Learning Using Summarization (PLUS), that learns\ntext-based summaries of each user's preferences, characteristics, and past\nconversations. These summaries condition the reward model, enabling it to make\npersonalized predictions about the types of responses valued by each user. We\ntrain the user-summarization model with reinforcement learning, and update the\nreward model simultaneously, creating an online co-adaptation loop. We show\nthat in contrast with prior personalized RLHF techniques or with in-context\nlearning of user information, summaries produced by PLUS capture meaningful\naspects of a user's preferences. Across different pluralistic user datasets, we\nshow that our method is robust to new users and diverse conversation topics.\nAdditionally, we demonstrate that the textual summaries generated about users\ncan be transferred for zero-shot personalization of stronger, proprietary\nmodels like GPT-4. The resulting user summaries are not only concise and\nportable, they are easy for users to interpret and modify, allowing for more\ntransparency and user control in LLM alignment.", "comment": "20 pages", "pdf_url": "http://arxiv.org/pdf/2507.13579v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2402.08080", "title": "A Meaningful Human Control Perspective on User Perception of Partially Automated Driving Systems: A Case Study of Tesla Users", "authors": ["Lucas Elbert Suryana", "Sina Nordhoff", "Simeon C. Calvert", "Arkady Zgonnikov", "Bart van Arem"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2402.08080v2", "summary": "The use of partially automated driving systems raises concerns about\npotential responsibility issues, posing risk to the system safety, acceptance,\nand adoption of these technologies. The concept of meaningful human control has\nemerged in response to the responsibility gap problem, requiring the\nfulfillment of two conditions, tracking and tracing. While this concept has\nprovided important philosophical and design insights on automated driving\nsystems, there is currently little knowledge on how meaningful human control\nrelates to subjective experiences of actual users of these systems. To address\nthis gap, our study aimed to investigate the alignment between the degree of\nmeaningful human control and drivers' perceptions of safety and trust in a\nreal-world partially automated driving system. We utilized previously collected\ndata from interviews with Tesla \"Full Self-Driving\" (FSD) Beta users,\ninvestigating the alignment between the user perception and how well the system\nwas tracking the users' reasons. We found that tracking of users' reasons for\ndriving tasks (such as safe maneuvers) correlated with perceived safety and\ntrust, albeit with notable exceptions. Surprisingly, failure to track lane\nchanging and braking reasons was not necessarily associated with negative\nperceptions of safety. However, the failure of the system to track expected\nmaneuvers in dangerous situations always resulted in low trust and perceived\nlack of safety. Overall, our analyses highlight alignment points but also\npossible discrepancies between perceived safety and trust on the one hand, and\nmeaningful human control on the other hand. Our results can help the developers\nof automated driving technology to design systems under meaningful human\ncontrol and are perceived as safe and trustworthy.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2402.08080v2", "cate": "cs.HC", "date": "2024-02-12", "updated": "2025-07-18"}
{"id": "2507.13378", "title": "A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects", "authors": ["Yuqi Cheng", "Yunkang Cao", "Haiming Yao", "Wei Luo", "Cheng Jiang", "Hui Zhang", "Weiming Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      27 pages, 7 figures", "url": "http://arxiv.org/abs/2507.13378v1", "summary": "Industrial defect detection is vital for upholding product quality across\ncontemporary manufacturing systems. As the expectations for precision,\nautomation, and scalability intensify, conventional inspection approaches are\nincreasingly found wanting in addressing real-world demands. Notable progress\nin computer vision and deep learning has substantially bolstered defect\ndetection capabilities across both 2D and 3D modalities. A significant\ndevelopment has been the pivot from closed-set to open-set defect detection\nframeworks, which diminishes the necessity for extensive defect annotations and\nfacilitates the recognition of novel anomalies. Despite such strides, a\ncohesive and contemporary understanding of industrial defect detection remains\nelusive. Consequently, this survey delivers an in-depth analysis of both\nclosed-set and open-set defect detection strategies within 2D and 3D\nmodalities, charting their evolution in recent years and underscoring the\nrising prominence of open-set techniques. We distill critical challenges\ninherent in practical detection environments and illuminate emerging trends,\nthereby providing a current and comprehensive vista of this swiftly progressing\nfield.", "comment": "27 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.13378v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13577", "title": "LLM-Based Community Surveys for Operational Decision Making in Interconnected Utility Infrastructures", "authors": ["Adaeze Okeukwu-Ogbonnaya", "Rahul Amatapu", "Jason Bergtold", "George Amariucai"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13577v1", "summary": "We represent interdependent infrastructure systems and communities alike with\na hetero-functional graph (HFG) that encodes the dependencies between\nfunctionalities. This graph naturally imposes a partial order of\nfunctionalities that can inform the sequence of repair decisions to be made\nduring a disaster across affected communities. However, using such technical\ncriteria alone provides limited guidance at the point where the functionalities\ndirectly impact the communities, since these can be repaired in any order\nwithout violating the system constraints. To address this gap and improve\nresilience, we integrate community preferences to refine this partial order\nfrom the HFG into a total order. Our strategy involves getting the communities'\nopinions on their preferred sequence for repair crews to address infrastructure\nissues, considering potential constraints on resources. Due to the delay and\ncost associated with real-world survey data, we utilize a Large Language Model\n(LLM) as a proxy survey tool. We use the LLM to craft distinct personas\nrepresenting individuals, each with varied disaster experiences. We construct\ndiverse disaster scenarios, and each simulated persona provides input on\nprioritizing infrastructure repair needs across various communities. Finally,\nwe apply learning algorithms to generate a global order based on the aggregated\nresponses from these LLM-generated personas.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13577v1", "cate": "cs.SI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13889", "title": "On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies", "authors": ["Bilal Karaman", "Ilhan Basturk", "Ferdi Kara", "Metin Ozturk", "Sezai Taskin", "Halil Yanikomeroglu"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      accepted in PIMRC2025", "url": "http://arxiv.org/abs/2507.13889v1", "summary": "This paper investigates the integration of active reconfigurable intelligent\nsurfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance\nnon-terrestrial network (NTN) performance in next-generation wireless systems.\nWhile prior studies focused on passive RIS architectures, the severe path loss\nand double fading in long-distance HAPS links make active RIS a more suitable\nalternative due to its inherent signal amplification capabilities. We formulate\na sum-rate maximization problem to jointly optimize power allocation and RIS\nelement assignment for ground user equipments (UEs) supported by a HAPS-based\nactive RIS-assisted communication system. To reduce power consumption and\nhardware complexity, several sub-connected active RIS architectures are also\nexplored. Simulation results reveal that active RIS configurations\nsignificantly outperform passive RIS in terms of quality of service (QoS).\nMoreover, although fully-connected architectures achieve the highest\nthroughput, sub-connected schemes demonstrate superior energy efficiency under\npractical power constraints. These findings highlight the potential of active\nRIS-enabled HAPS systems to meet the growing demands of beyond-cellular\ncoverage and green networking.", "comment": "accepted in PIMRC2025", "pdf_url": "http://arxiv.org/pdf/2507.13889v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13872", "title": "Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions", "authors": ["Aditya Singh", "Aastha Mishra", "Manan Tayal", "Shishir Kolathaya", "Pushpak Jagtap"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 Pages, 2 Figures. The first two authors contributed equally", "url": "http://arxiv.org/abs/2507.13872v1", "summary": "Ensuring both performance and safety is critical for autonomous systems\noperating in real-world environments. While safety filters such as Control\nBarrier Functions (CBFs) enforce constraints by modifying nominal controllers\nin real time, they can become overly conservative when the nominal policy lacks\nsafety awareness. Conversely, solving State-Constrained Optimal Control\nProblems (SC-OCPs) via dynamic programming offers formal guarantees but is\nintractable in high-dimensional systems. In this work, we propose a novel\ntwo-stage framework that combines gradient-based Model Predictive Control (MPC)\nwith CBF-based safety filtering for co-optimizing safety and performance. In\nthe first stage, we relax safety constraints as penalties in the cost function,\nenabling fast optimization via gradient-based methods. This step improves\nscalability and avoids feasibility issues associated with hard constraints. In\nthe second stage, we modify the resulting controller using a CBF-based\nQuadratic Program (CBF-QP), which enforces hard safety constraints with minimal\ndeviation from the reference. Our approach yields controllers that are both\nperformant and provably safe. We validate the proposed framework on two case\nstudies, showcasing its ability to synthesize scalable, safe, and\nhigh-performance controllers for complex, high-dimensional autonomous systems.", "comment": "6 Pages, 2 Figures. The first two authors contributed equally", "pdf_url": "http://arxiv.org/pdf/2507.13872v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12898", "title": "Generalist Bimanual Manipulation via Foundation Video Diffusion Models", "authors": ["Yao Feng", "Hengkai Tan", "Xinyi Mao", "Guodong Liu", "Shuhe Huang", "Chendong Xiang", "Hang Su", "Jun Zhu"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12898v1", "summary": "Bimanual robotic manipulation, which involves the coordinated control of two\nrobotic arms, is foundational for solving challenging tasks. Despite recent\nprogress in general-purpose manipulation, data scarcity and embodiment\nheterogeneity remain serious obstacles to further scaling up in bimanual\nsettings. In this paper, we introduce VIdeo Diffusion for Action Reasoning\n(VIDAR), a two-stage framework that leverages large-scale, diffusion-based\nvideo pre-training and a novel masked inverse dynamics model for action\nprediction. We pre-train the video diffusion model on 750K multi-view videos\nfrom three real-world bimanual robot platforms, utilizing a unified observation\nspace that encodes robot, camera, task, and scene contexts. Our masked inverse\ndynamics model learns masks to extract action-relevant information from\ngenerated trajectories without requiring pixel-level labels, and the masks can\neffectively generalize to unseen backgrounds. Our experiments demonstrate that\nwith only 20 minutes of human demonstrations on an unseen robot platform (only\n1% of typical data requirements), VIDAR generalizes to unseen tasks and\nbackgrounds with strong semantic understanding, surpassing state-of-the-art\nmethods. Our findings highlight the potential of video foundation models,\ncoupled with masked action prediction, to enable scalable and generalizable\nrobotic manipulation in diverse real-world settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12898v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13608", "title": "Off-Policy Evaluation and Learning for Matching Markets", "authors": ["Yudai Hayashi", "Shuhei Goda", "Yuta Saito"], "categories": ["cs.LG", "cs.IR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      RecSys'25", "url": "http://arxiv.org/abs/2507.13608v1", "summary": "Matching users based on mutual preferences is a fundamental aspect of\nservices driven by reciprocal recommendations, such as job search and dating\napplications. Although A/B tests remain the gold standard for evaluating new\npolicies in recommender systems for matching markets, it is costly and\nimpractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays\na crucial role by enabling the evaluation of recommendation policies using only\noffline logged data naturally collected on the platform. However, unlike\nconventional recommendation settings, the large scale and bidirectional nature\nof user interactions in matching platforms introduce variance issues and\nexacerbate reward sparsity, making standard OPE methods unreliable. To address\nthese challenges and facilitate effective offline evaluation, we propose novel\nOPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for\nmatching markets. Our methods combine elements of the Direct Method (DM),\nInverse Propensity Score (IPS), and Doubly Robust (DR) estimators while\nincorporating intermediate labels, such as initial engagement signals, to\nachieve better bias-variance control in matching markets. Theoretically, we\nderive the bias and variance of the proposed estimators and demonstrate their\nadvantages over conventional methods. Furthermore, we show that these\nestimators can be seamlessly extended to offline policy learning methods for\nimproving recommendation policies for making more matches. We empirically\nevaluate our methods through experiments on both synthetic data and A/B testing\nlogs from a real job-matching platform. The empirical results highlight the\nsuperiority of our approach over existing methods in off-policy evaluation and\nlearning tasks for a variety of configurations.", "comment": "RecSys'25", "pdf_url": "http://arxiv.org/pdf/2507.13608v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2407.01558", "title": "Visual Grounding Methods for Efficient Interaction with Desktop Graphical User Interfaces", "authors": ["El Hassane Ettifouri", "Jessica López Espejel", "Laura Minkova", "Tassnim Dardouri", "Walid Dahhane"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Preprint submitted to Engineering Applications of Artificial Intelligence journal", "url": "http://arxiv.org/abs/2407.01558v3", "summary": "Most visual grounding solutions primarily focus on realistic images. However,\napplications involving synthetic images, such as Graphical User Interfaces\n(GUIs), remain limited. This restricts the development of autonomous computer\nvision-powered artificial intelligence (AI) agents for automatic application\ninteraction. Enabling AI to effectively understand and interact with GUIs is\ncrucial to advancing automation in software testing, accessibility, and\nhuman-computer interaction. In this work, we explore Instruction Visual\nGrounding (IVG), a multi-modal approach to object identification within a GUI.\nMore precisely, given a natural language instruction and a GUI screen, IVG\nlocates the coordinates of the element on the screen where the instruction\nshould be executed. We propose two main methods: (1) IVGocr, which combines a\nLarge Language Model (LLM), an object detection model, and an Optical Character\nRecognition (OCR) module; and (2) IVGdirect, which uses a multimodal\narchitecture for end-to-end grounding. For each method, we introduce a\ndedicated dataset. In addition, we propose the Central Point Validation (CPV)\nmetric, a relaxed variant of the classical Central Proximity Score (CPS)\nmetric. Our final test dataset is publicly released to support future research.", "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence journal", "pdf_url": "http://arxiv.org/pdf/2407.01558v3", "cate": "cs.HC", "date": "2024-05-05", "updated": "2025-07-18"}
{"id": "2507.13385", "title": "Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery", "authors": ["Arjun Rao", "Esther Rolf"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 9 figures, 7 tables. Accepted to TerraBytes@ICML 2025", "url": "http://arxiv.org/abs/2507.13385v1", "summary": "A large variety of geospatial data layers is available around the world\nranging from remotely-sensed raster data like satellite imagery, digital\nelevation models, predicted land cover maps, and human-annotated data, to data\nderived from environmental sensors such as air temperature or wind speed data.\nA large majority of machine learning models trained on satellite imagery\n(SatML), however, are designed primarily for optical input modalities such as\nmulti-spectral satellite imagery. To better understand the value of using other\ninput modalities alongside optical imagery in supervised learning settings, we\ngenerate augmented versions of SatML benchmark tasks by appending additional\ngeographic data layers to datasets spanning classification, regression, and\nsegmentation. Using these augmented datasets, we find that fusing additional\ngeographic inputs with optical imagery can significantly improve SatML model\nperformance. Benefits are largest in settings where labeled data are limited\nand in geographic out-of-sample settings, suggesting that multi-modal inputs\nmay be especially valuable for data-efficiency and out-of-sample performance of\nSatML models. Surprisingly, we find that hard-coded fusion strategies\noutperform learned variants, with interesting implications for future work.", "comment": "17 pages, 9 figures, 7 tables. Accepted to TerraBytes@ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.13385v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13636", "title": "Duplicating Deceit: Inauthentic Behavior Among Indian Misinformation Duplicators on X/Twitter", "authors": ["Ashfaq Ali Shafin", "Bogdan Carbunar"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      8 pages, 1 figure, accepted in 17th International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025)", "url": "http://arxiv.org/abs/2507.13636v1", "summary": "This paper investigates inauthentic duplication on social media, where\nmultiple accounts share identical misinformation tweets. Leveraging a dataset\nof misinformation verified by AltNews, an Indian fact-checking organization, we\nanalyze over 12 million posts from 5,493 accounts known to have duplicated such\ncontent. Contrary to common assumptions that bots are primarily responsible for\nspreading false information, fewer than 1\\% of these accounts exhibit bot-like\nbehavior. We present TweeXster, a framework for detecting and analyzing\nduplication campaigns, revealing clusters of accounts involved in repeated and\nsometimes revived dissemination of false or abusive content.", "comment": "8 pages, 1 figure, accepted in 17th International Conference on\n  Advances in Social Networks Analysis and Mining (ASONAM 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13636v1", "cate": "cs.SI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13933", "title": "Preprint: Did I Just Browse A Website Written by LLMs?", "authors": ["Sichang \"Steven\" He", "Ramesh Govindan", "Harsha V. Madhyastha"], "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      In submission. 2 pages. 3 figures", "url": "http://arxiv.org/abs/2507.13933v1", "summary": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.", "comment": "In submission. 2 pages. 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.13933v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13464", "title": "Round-Preserving Asymptotic Compression of Prior-Free Interactive Protocols", "authors": ["Gurleen Padda", "Dave Touchette"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13464v1", "summary": "There is a close relationship between the communication complexity and\ninformation complexity of communication problems, as demonstrated by results\nsuch as Shannon's noiseless source coding theorem, and the Slepian-Wolf\ntheorem. Here, we study this relationship in the prior-free and interactive\nsetting, where we provide an alternate proof for the result of Braverman [SIAM\nReview, vol. 59, no. 4, 2017], that the amortized communication complexity of\nsimulating a prior-free interactive communication protocol, is equal to its\nprior-free information cost. While this is a known result, our approach\naddresses the need for a more natural proof of it. We also improve on the\nresult by achieving round preservation, and using a bounded quantity of shared\nrandomness. We do this by showing that the communicating parties can produce a\nreliable estimate of the joint type, or empirical distribution, of their\ninputs. This estimate is then used in our protocol for the prior-free reverse\nShannon theorem with side information at the receiver. These results are then\ngeneralized to the interactive setting to obtain our main result.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13464v1", "cate": "cs.IT", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13888", "title": "Fixed time convergence guarantees for Higher Order Control Barrier Functions", "authors": ["Janani S K", "Shishir Kolathaya"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 PAGES, 2 FIGURES", "url": "http://arxiv.org/abs/2507.13888v1", "summary": "We present a novel method for designing higher-order Control Barrier\nFunctions (CBFs) that guarantee convergence to a safe set within a\nuser-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic\nsafety but lack mechanisms for fixed-time convergence, which is critical in\ntime-sensitive and safety-critical applications such as autonomous navigation.\nIn contrast, our approach imposes a structured differential constraint using\nrepeated roots in the characteristic polynomial, enabling closed-form\npolynomial solutions with exact convergence at a prescribed time. We derive\nconditions on the barrier function and its derivatives that ensure forward\ninvariance and fixed-time reachability, and we provide an explicit formulation\nfor second-order systems. Our method is evaluated on three robotic systems - a\npoint-mass model, a unicycle, and a bicycle model and benchmarked against\nexisting HOCBF approaches. Results demonstrate that our formulation reliably\nenforces convergence within the desired time, even when traditional methods\nfail. This work provides a tractable and robust framework for real-time control\nwith provable finite-time safety guarantees.", "comment": "6 PAGES, 2 FIGURES", "pdf_url": "http://arxiv.org/pdf/2507.13888v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13355", "title": "PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning", "authors": ["Riadul Islam", "Dhandeep Challagundla"], "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13355v1", "summary": "Leveraging artificial intelligence (AI)-driven electronic design and\nautomation (EDA) tools, high-performance computing, and parallelized algorithms\nare essential for next-generation microprocessor innovation, ensuring continued\nprogress in computing, AI, and semiconductor technology. Machine learning-based\ndesign rule checking (DRC) and lithography hotspot detection can improve\nfirst-pass silicon success. However, conventional ML and neural network\n(NN)-based models use supervised learning and require a large balanced dataset\n(in terms of positive and negative classes) and training time. This research\naddresses those key challenges by proposing the first-ever unsupervised DRC\nviolation prediction methodology. The proposed model can be built using any\nunbalanced dataset using only one class and set a threshold for it, then\nfitting any new data querying if they are within the boundary of the model for\nclassification. This research verified the proposed model by implementing\ndifferent computational cores using CMOS 28 nm technology and Synopsys Design\nCompiler and IC Compiler II tools. Then, layouts were divided into virtual\ngrids to collect about 60k data for analysis and verification. The proposed\nmethod has 99.95% prediction test accuracy, while the existing support vector\nmachine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy,\nrespectively. In addition, the proposed methodology has about 26.3x and up to\n6003x lower training times compared to SVM and NN-models, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13355v1", "cate": "cs.AR", "date": "2025-06-08", "updated": "2025-06-08"}
{"id": "2507.13620", "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "authors": ["Binxiong Li", "Yuefei Wang", "Xu Xiang", "Xue Li", "Binyu Zhao", "Heyang Gao", "Qinyu Zhao", "Xi Yu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The source code for this study is available at this https URL", "url": "http://arxiv.org/abs/2507.13620v1", "summary": "In recent years, models based on Graph Convolutional Networks (GCN) have made\nsignificant strides in the field of graph data analysis. However, challenges\nsuch as over-smoothing and over-compression remain when handling large-scale\nand complex graph datasets, leading to a decline in clustering quality.\nAlthough the Graph Transformer architecture has mitigated some of these issues,\nits performance is still limited when processing heterogeneous graph data. To\naddress these challenges, this study proposes a novel deep clustering framework\nthat comprising GCN, Autoencoder (AE), and Graph Transformer, termed the\nTri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the\ndifferentiation and consistency of global and local information through a\nunique tri-learning mechanism and feature fusion enhancement strategy. The\nframework integrates GCN, AE, and Graph Transformer modules. These components\nare meticulously fused by a triple-channel enhancement module, which maximizes\nthe use of both node attributes and topological structures, ensuring robust\nclustering representation. The tri-learning mechanism allows mutual learning\namong these modules, while the feature fusion strategy enables the model to\ncapture complex relationships, yielding highly discriminative representations\nfor graph clustering. It surpasses many state-of-the-art methods, achieving an\naccuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the\nReuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding\nperformance on the Reuters dataset, Tri-GFN can be applied to automatic news\nclassification, topic retrieval, and related fields.", "comment": "The source code for this study is available at\n  https://github.com/YF-W/Tri-GFN", "pdf_url": "http://arxiv.org/pdf/2507.13620v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2410.03993", "title": "TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human Action Prediction", "authors": ["Kojiro Takeyama", "Yimeng Liu", "Misha Sra"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025", "url": "http://arxiv.org/abs/2410.03993v4", "summary": "Accurate prediction of human behavior is crucial for AI systems to\neffectively support real-world applications, such as autonomous robots\nanticipating and assisting with human tasks. Real-world scenarios frequently\npresent challenges such as occlusions and incomplete scene observations, which\ncan compromise predictive accuracy. Thus, traditional video-based methods often\nstruggle due to limited temporal and spatial perspectives. Large Language\nModels (LLMs) offer a promising alternative. Having been trained on a large\ntext corpus describing human behaviors, LLMs likely encode plausible sequences\nof human actions in a home environment. However, LLMs, trained primarily on\ntext data, lack inherent spatial awareness and real-time environmental\nperception. They struggle with understanding physical constraints and spatial\ngeometry. Therefore, to be effective in a real-world spatial scenario, we\npropose a multimodal prediction framework that enhances LLM-based action\nprediction by integrating physical constraints derived from human trajectories.\nOur experiments demonstrate that combining LLM predictions with trajectory data\nsignificantly improves overall prediction performance. This enhancement is\nparticularly notable in situations where the LLM receives limited scene\ninformation, highlighting the complementary nature of linguistic knowledge and\nphysical constraints in understanding and anticipating human behavior.", "comment": "Accepted to IROS 2025", "pdf_url": "http://arxiv.org/pdf/2410.03993v4", "cate": "cs.HC", "date": "2024-10-05", "updated": "2025-07-18"}
{"id": "2507.13386", "title": "Minimalist Concept Erasure in Generative Models", "authors": ["Yang Zhang", "Er Jin", "Yanfei Dong", "Yixuan Wu", "Philip Torr", "Ashkan Khakzar", "Johannes Stegmaier", "Kenji Kawaguchi"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICML2025", "url": "http://arxiv.org/abs/2507.13386v1", "summary": "Recent advances in generative models have demonstrated remarkable\ncapabilities in producing high-quality images, but their reliance on\nlarge-scale unlabeled data has raised significant safety and copyright\nconcerns. Efforts to address these issues by erasing unwanted concepts have\nshown promise. However, many existing erasure methods involve excessive\nmodifications that compromise the overall utility of the model. In this work,\nwe address these issues by formulating a novel minimalist concept erasure\nobjective based \\emph{only} on the distributional distance of final generation\noutputs. Building on our formulation, we derive a tractable loss for\ndifferentiable optimization that leverages backpropagation through all\ngeneration steps in an end-to-end manner. We also conduct extensive analysis to\nshow theoretical connections with other models and methods. To improve the\nrobustness of the erasure, we incorporate neuron masking as an alternative to\nmodel fine-tuning. Empirical evaluations on state-of-the-art flow-matching\nmodels demonstrate that our method robustly erases concepts without degrading\noverall model performance, paving the way for safer and more responsible\ngenerative models.", "comment": "ICML2025", "pdf_url": "http://arxiv.org/pdf/2507.13386v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13939", "title": "Automated Route-based Conflation Between Linear Referencing System Maps And OpenStreetMap Using Open-source Tools", "authors": ["Gibran Ali", "Neal Feierabend", "Prarthana Doshi", "Whoibin Chung", "Simona Babiceanu", "Michael Fontaine"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE International Conference on Intelligent Transportation Systems (ITSC 2025)", "url": "http://arxiv.org/abs/2507.13939v1", "summary": "Transportation researchers and planners utilize a wide range of roadway\nmetrics that are usually associated with different basemaps. Conflation is an\nimportant process for transferring these metrics onto a single basemap.\nHowever, conflation is often an expensive and time-consuming process based on\nproprietary algorithms that require manual verification.\n  In this paper, an automated open-source process is used to conflate two\nbasemaps: the linear reference system (LRS) basemap produced by the Virginia\nDepartment of Transportation and the OpenStreetMap (OSM) basemap for Virginia.\nThis process loads one LRS route at a time, determines the correct direction of\ntravel, interpolates to fill gaps larger than 12 meters, and then uses\nValhalla's map-matching algorithm to find the corresponding points along OSM's\nsegments. Valhalla's map-matching process uses a Hidden Markov Model (HMM) and\nViterbi search-based approach to find the most likely OSM segments matching the\nLRS route.\n  This work has three key contributions. First, it conflates the Virginia\nroadway network LRS map with OSM using an automated conflation method based on\nHMM and Viterbi search. Second, it demonstrates a novel open-source processing\npipeline that could be replicated without the need for proprietary licenses.\nFinally, the overall conflation process yields over 98% successful matches,\nwhich is an improvement over most automated processes currently available for\nthis type of conflation.", "comment": "Accepted to the 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13939v1", "cate": "cs.SI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13624", "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13624v1", "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13624v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13543", "title": "Loss-Complexity Landscape and Model Structure Functions", "authors": ["Alexander Kolpakov"], "categories": ["cs.IT", "cs.AI", "cs.LG", "math-ph", "math.IT", "math.MP", "I.2.2; I.2.6"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      18 pages, 3 figures; GitHub repository at this https URL", "url": "http://arxiv.org/abs/2507.13543v1", "summary": "We develop a framework for dualizing the Kolmogorov structure function\n$h_x(\\alpha)$, which then allows using computable complexity proxies. We\nestablish a mathematical analogy between information-theoretic constructs and\nstatistical mechanics, introducing a suitable partition function and free\nenergy functional. We explicitly prove the Legendre-Fenchel duality between the\nstructure function and free energy, showing detailed balance of the Metropolis\nkernel, and interpret acceptance probabilities as information-theoretic\nscattering amplitudes. A susceptibility-like variance of model complexity is\nshown to peak precisely at loss-complexity trade-offs interpreted as phase\ntransitions. Practical experiments with linear and tree-based regression models\nverify these theoretical predictions, explicitly demonstrating the interplay\nbetween the model complexity, generalization, and overfitting threshold.", "comment": "18 pages, 3 figures; GitHub repository at\n  https://github.com/sashakolpakov/structure-functions", "pdf_url": "http://arxiv.org/pdf/2507.13543v1", "cate": "cs.IT", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14011", "title": "Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions", "authors": ["Paolo Totaro", "Alberto Mangiante"], "categories": ["cs.NE", "cs.RO"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14011v1", "summary": "This article proposes a method to formalise models of cognitive processes\ngrounded in experience, considering experience from the perspective of a living\nsystem and not from that of an observer of the living system. The perspective\nof a living system is defined by the need of the system to preserve the vital\nequilibria. The method is based on an algorithmic schema that we call\nEnvironment Generative Operator (EGO) and uses a self-referential language\ndeveloped for this purpose which we call E-language. EGO simulates cognitive\nprocesses as operations on neuron assemblies as understood by Hebb. In this\narticle we present an EGO prototype (EGO-P) which has already been implemented\nand tested.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14011v1", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13369", "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation", "authors": ["Paul E. Calzada", "Zahin Ibnat", "Tanvir Rahman", "Kamal Kandula", "Danyu Lu", "Sujan Kumar Saha", "Farimah Farahmandi", "Mark Tehranipoor"], "categories": ["cs.AR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13369v1", "summary": "Large Language Models (LLMs) are gaining popularity for hardware design\nautomation, particularly through Register Transfer Level (RTL) code generation.\nIn this work, we examine the current literature on RTL generation using LLMs\nand identify key requirements for training and fine-tuning datasets. We\nconstruct a robust Verilog dataset through an automated three-pronged process\ninvolving database (DB) creation and management with PostgreSQL, data\ncollection from code hosting sites like OpenCores and GitHub, and data\npreprocessing to verify the codes' syntax, run logic synthesis, and extract\nrelevant module metadata. We implement a scalable and efficient DB\ninfrastructure to support analysis and detail our preprocessing pipeline to\nenforce high-quality data before DB insertion. The resulting dataset comprises\n20,392 Verilog samples, 751 MB of Verilog code data, which is the largest\nhigh-quality Verilog dataset for LLM fine-tuning to our knowledge. We further\nevaluate the dataset, address associated challenges, and explore potential\napplications for future research and development in LLM-based hardware\ngeneration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13369v1", "cate": "cs.AR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.13646", "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design", "authors": ["Nimisha Ghosh", "Daniele Santoni", "Debaleena Nawn", "Eleonora Ottaviani", "Giovanni Felici"], "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13646v1", "summary": "The impact of Transformer-based language models has been unprecedented in\nNatural Language Processing (NLP). The success of such models has also led to\ntheir adoption in other fields including bioinformatics. Taking this into\naccount, this paper discusses recent advances in Transformer-based models for\nprotein sequence analysis and design. In this review, we have discussed and\nanalysed a significant number of works pertaining to such applications. These\napplications encompass gene ontology, functional and structural protein\nidentification, generation of de novo proteins and binding of proteins. We\nattempt to shed light on the strength and weaknesses of the discussed works to\nprovide a comprehensive insight to readers. Finally, we highlight shortcomings\nin existing research and explore potential avenues for future developments. We\nbelieve that this review will help researchers working in this field to have an\noverall idea of the state of the art in this field, and to orient their future\nstudies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13646v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.03572", "title": "From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study", "authors": ["Ammar Ahmed", "Margarida Fresco", "Fredrik Forsberg", "Hallvard Grotli"], "categories": ["cs.HC", "cs.AI", "cs.CL", "D.1.2; F.3.1; F.4.1; D.3.2; H.1.2; H.5.2; D.2.2; H.1.2; I.3.6;\n  H.5.4; H.5.1"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03572v2", "summary": "Web accessibility ensures that individuals with disabilities can access and\ninteract with digital content without barriers, yet a significant majority of\nmost used websites fail to meet accessibility standards. This study evaluates\nChatGPT's (GPT-4o) ability to generate and improve web pages in line with Web\nContent Accessibility Guidelines (WCAG). While ChatGPT can effectively address\naccessibility issues when prompted, its default code often lacks compliance,\nreflecting limitations in its training data and prevailing inaccessible web\npractices. Automated and manual testing revealed strengths in resolving simple\nissues but challenges with complex tasks, requiring human oversight and\nadditional iterations. Unlike prior studies, we incorporate manual evaluation,\ndynamic elements, and use the visual reasoning capability of ChatGPT along with\nthe prompts to fix accessibility issues. Providing screenshots alongside\nprompts enhances the LLM's ability to address accessibility issues by allowing\nit to analyze surrounding components, such as determining appropriate contrast\ncolors. We found that effective prompt engineering, such as providing concise,\nstructured feedback and incorporating visual aids, significantly enhances\nChatGPT's performance. These findings highlight the potential and limitations\nof large language models for accessible web development, offering practical\nguidance for developers to create more inclusive websites.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03572v2", "cate": "cs.HC", "date": "2025-01-07", "updated": "2025-07-17"}
{"id": "2507.13387", "title": "From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction", "authors": ["Chihiro Noguchi", "Takaki Yamamoto"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV Workshop 2025", "url": "http://arxiv.org/abs/2507.13387v1", "summary": "Accurate perception of the surrounding environment is essential for safe\nautonomous driving. 3D occupancy prediction, which estimates detailed 3D\nstructures of roads, buildings, and other objects, is particularly important\nfor vision-centric autonomous driving systems that do not rely on LiDAR\nsensors. However, in 3D semantic occupancy prediction -- where each voxel is\nassigned a semantic label -- annotated LiDAR point clouds are required, making\ndata acquisition costly. In contrast, large-scale binary occupancy data, which\nonly indicate occupied or free space without semantic labels, can be collected\nat a lower cost. Despite their availability, the potential of leveraging such\ndata remains unexplored. In this study, we investigate the utilization of\nlarge-scale binary occupancy data from two perspectives: (1) pre-training and\n(2) learning-based auto-labeling. We propose a novel binary occupancy-based\nframework that decomposes the prediction process into binary and semantic\noccupancy modules, enabling effective use of binary occupancy data. Our\nexperimental results demonstrate that the proposed framework outperforms\nexisting methods in both pre-training and auto-labeling tasks, highlighting its\neffectiveness in enhancing 3D semantic occupancy prediction. The code is\navailable at https://github.com/ToyotaInfoTech/b2s-occupancy", "comment": "Accepted to ICCV Workshop 2025", "pdf_url": "http://arxiv.org/pdf/2507.13387v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2502.12777", "title": "Evaluating link prediction: New perspectives and recommendations", "authors": ["Bhargavi Kalyani I", "A Rama Prasad Mathi", "Niladri Sett"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Int J Data Sci Anal (2025)", "url": "http://arxiv.org/abs/2502.12777v4", "summary": "Link prediction (LP) is an important problem in network science and machine\nlearning research. The state-of-the-art LP methods are usually evaluated in a\nuniform setup, ignoring several factors associated with the data and\napplication specific needs. We identify a number of such factors, such as,\nnetwork-type, problem-type, geodesic distance between the end nodes and its\ndistribution over the classes, nature and applicability of LP methods, class\nimbalance and its impact on early retrieval, evaluation metric, etc., and\npresent an experimental setup which allows us to evaluate LP methods in a\nrigorous and controlled manner. We perform extensive experiments with a variety\nof LP methods over real network datasets in this controlled setup, and gather\nvaluable insights on the interactions of these factors with the performance of\nLP through an array of carefully designed hypotheses. Following the insights,\nwe provide recommendations to be followed as best practice for evaluating LP\nmethods.", "comment": "Int J Data Sci Anal (2025)", "pdf_url": "http://arxiv.org/pdf/2502.12777v4", "cate": "cs.SI", "date": "2025-02-18", "updated": "2025-07-18"}
{"id": "2507.13999", "title": "The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks", "authors": ["Sanidhay Bhambay", "Siddarth Koduru Joshi", "Thirupathaiah Vasantam", "Neil Walton"], "categories": ["quant-ph", "cs.NI", "cs.PF"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13999v1", "summary": "We address the problem of optimal pumping strategies in quantum networks.\nThese networks enable secure communication by distributing entangled photon\npairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like\nBBM92, generate secret keys from entangled photons. While secure communication\nand error correction are essential for any quantum communication channel,\nresource contention, optimization, and fairness issues are critical for\nnetworks. In this article, we analyze the performance of quantum networks,\nproposing simple distributed algorithms for QKD networks generating secret\nkeys.\n  There are significant advantages of pumping entangled photons in QKD\nnetworks, but challenges arise in practical implementations. The underlying\nchannels are inherently time-varying, and thus data rates fluctuate between\nnodes. Moreover, multiple edges (node pairs) can be pumped simultaneously,\nalbeit at the cost of a reduced secret key rate (SKR). These temporal and\nspatial constraints yield a complex decision-making problem whose solutions may\nfavor a small set of user pairs to the detriment of overall, long-run network\nperformance.\n  We design adaptive pumping strategies that address these challenges in QKD\nnetworks. In particular, we find that a proportional fairness pumping strategy\n(PF-PS) stands out by dynamically prioritizing users with lower average secret\nkey rates and optimally balancing fairness with throughput. The proposed\nalgorithm is a natural extension to quantum networks of the Proportional Fair\nScheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis\nand numerical simulations confirm that PF-PS is optimal for entangled state\ndistribution, and thus, when adapted appropriately, proportional fair pumping\nis a strong candidate for efficient resource allocation in quantum networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13999v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13548", "title": "Efficient Decoding of Double-circulant and Wozencraft Codes from Square-root Errors", "authors": ["Oren Dubin", "Noam Oz", "Noga Ron-Zewi"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13548v1", "summary": "We present efficient decoding algorithms from square-root errors for two\nknown families of double-circulant codes: A construction based on Sidon sets\n(Bhargava, Taveres, and Shiva, \\emph{IEEE IT 74}; Calderbank, \\emph{IEEE IT\n83}; Guruswami and Li, \\emph{IEEE IT 2025}), and a construction based on cyclic\ncodes (Chen, Peterson, and Weldon, \\emph{Information and Control 1969}). We\nfurther observe that the work of Guruswami and Li implicitly gives a\ntransformation from double-circulant codes of certain block lengths to\nWozencraft codes which preserves that distance of the codes, and we show that\nthis transformation also preserves efficiency of decoding. By instantiating\nthis transformation with the first family of double-circulant codes based on\nSidon sets, we obtain an explicit construction of a Wozencraft code that is\nefficiently decodable from square-root errors. We also discuss limitations on\ninstantiating this transformation with the second family of double-circulant\ncodes based on cyclic codes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13548v1", "cate": "cs.IT", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2411.07146", "title": "Lost in Tracking Translation: A Comprehensive Analysis of Visual SLAM in Human-Centered XR and IoT Ecosystems", "authors": ["Yasra Chandio", "Khotso Selialia", "Joseph DeGol", "Luis Garcia", "Fatima M. Anwar"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.07146v2", "summary": "Advancements in tracking algorithms have empowered nascent applications\nacross various domains, from steering autonomous vehicles to guiding robots to\nenhancing augmented reality experiences for users. However, these algorithms\nare application-specific and do not work across applications with different\ntypes of motion; even a tracking algorithm designed for a given application\ndoes not work in scenarios deviating from highly standard conditions. For\nexample, a tracking algorithm designed for robot navigation inside a building\nwill not work for tracking the same robot in an outdoor environment. To\ndemonstrate this problem, we evaluate the performance of the state-of-the-art\ntracking methods across various applications and scenarios. To inform our\nanalysis, we first categorize algorithmic, environmental, and\nlocomotion-related challenges faced by tracking algorithms. We quantitatively\nevaluate the performance using multiple tracking algorithms and representative\ndatasets for a wide range of Internet of Things (IoT) and Extended Reality (XR)\napplications, including autonomous vehicles, drones, and humans. Our analysis\nshows that no tracking algorithm works across different applications and\nscenarios within applications. Ultimately, using the insights generated from\nour analysis, we discuss multiple approaches to improving the tracking\nperformance using input data characterization, leveraging intermediate\ninformation, and output evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.07146v2", "cate": "cs.RO", "date": "2024-11-11", "updated": "2025-07-17"}
{"id": "2507.13380", "title": "Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition", "authors": ["Keito Inoshita", "Rushia Harada"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13380v1", "summary": "In the field of emotion recognition, the development of high-performance\nmodels remains a challenge due to the scarcity of high-quality, diverse\nemotional datasets. Emotional expressions are inherently subjective, shaped by\nindividual personality traits, socio-cultural backgrounds, and contextual\nfactors, making large-scale, generalizable data collection both ethically and\npractically difficult. To address this issue, we introduce PersonaGen, a novel\nframework for generating emotionally rich text using a Large Language Model\n(LLM) through multi-stage persona-based conditioning. PersonaGen constructs\nlayered virtual personas by combining demographic attributes, socio-cultural\nbackgrounds, and detailed situational contexts, which are then used to guide\nemotion expression generation. We conduct comprehensive evaluations of the\ngenerated synthetic data, assessing semantic diversity through clustering and\ndistributional metrics, human-likeness via LLM-based quality scoring, realism\nthrough comparison with real-world emotion corpora, and practical utility in\ndownstream emotion classification tasks. Experimental results show that\nPersonaGen significantly outperforms baseline methods in generating diverse,\ncoherent, and discriminative emotion expressions, demonstrating its potential\nas a robust alternative for augmenting or replacing real-world emotional\ndatasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13380v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13685", "title": "Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction", "authors": ["Yue Yang", "Zihan Su", "Ying Zhang", "Chang Chuan Goh", "Yuxiang Lin", "Anthony Graham Bellotti", "Boon Giin Lee"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13685v1", "summary": "This study addresses a critical challenge in time series anomaly detection:\nenhancing the predictive capability of loan default models more than three\nmonths in advance to enable early identification of default events, helping\nfinancial institutions implement preventive measures before risk events\nmaterialize. Existing methods have significant drawbacks, such as their lack of\naccuracy in early predictions and their dependence on training and testing\nwithin the same year and specific time frames. These issues limit their\npractical use, particularly with out-of-time data. To address these, the study\nintroduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge\nKolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long\nShort-Term Memory (LSTM) networks. The proposed models were evaluated against\nthe baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms\nof accuracy, precision, recall, F1 and AUC in different lengths of feature\nwindow, sample sizes, and early prediction intervals. The results demonstrate\nthat the proposed model achieves a prediction accuracy of over 92% three months\nin advance and over 88% eight months in advance, significantly outperforming\nexisting baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13685v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.16373", "title": "What Sensors See, What People Feel: Exploring Subjective Collaboration Perception in Mixed Reality", "authors": ["Yasra Chandio", "Diana Romero", "Salma Elmalaki", "Fatima Anwar"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures, 8 tables. arXiv admin note: text overlap with arXiv:2411.05258", "url": "http://arxiv.org/abs/2504.16373v2", "summary": "Mixed Reality (MR) enables rich, embodied collaboration, yet it's uncertain\nif sensor and system-logged behavioral signals capture how users experience\nthat collaboration. This disconnect stems from a fundamental gap: behavioral\nsignals are observable and continuous, while collaboration is interpreted\nsubjectively, shaped by internal states like presence, cognitive availability,\nand social awareness. Our core insight is that sensor signals serve as\nobservable manifestations of subjective experiences in MR collaboration, and\nthey can be captured through sensor data such as shared gaze, speech, spatial\nmovement, and other system-logged performance metrics. We propose the\nSensor-to-Subjective (S2S) Mapping Framework, a conceptual model that links\nobservable interaction patterns to users' subjective perceptions of\ncollaboration and internal cognitive states through sensor-based indicators and\ntask performance metrics. To validate this model, we conducted a study with 48\nparticipants across 12 MR groups engaged in a collaborative image-sorting task.\nOur findings show a correlation between sensed behavior and perceived\ncollaboration, particularly through shared attention and proximity.", "comment": "12 pages, 4 figures, 8 tables. arXiv admin note: text overlap with\n  arXiv:2411.05258", "pdf_url": "http://arxiv.org/pdf/2504.16373v2", "cate": "cs.HC", "date": "2025-04-23", "updated": "2025-07-17"}
{"id": "2507.13397", "title": "InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction", "authors": ["Kaiyuan Zhai", "Juan Chen", "Chao Wang", "Zeyi Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13397v1", "summary": "Accurate pedestrian trajectory prediction is crucial for intelligent\napplications, yet it remains highly challenging due to the complexity of\ninteractions among pedestrians. Previous methods have primarily relied on\nrelative positions to model pedestrian interactions; however, they tend to\noverlook specific interaction patterns such as paired walking or conflicting\nbehaviors, limiting the prediction accuracy in crowded scenarios. To address\nthis issue, we propose InSyn (Interaction-Synchronization Network), a novel\nTransformer-based model that explicitly captures diverse interaction patterns\n(e.g., walking in sync or conflicting) while effectively modeling\ndirection-sensitive social behaviors. Additionally, we introduce a training\nstrategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue\nof initial-step divergence in numerical time-series prediction. Experiments on\nthe ETH and UCY datasets demonstrate that our model outperforms recent\nbaselines significantly, especially in high-density scenarios. Furthermore, the\nSSOS strategy proves effective in improving sequential prediction performance,\nreducing the initial-step prediction error by approximately 6.58%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13397v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2408.01268", "title": "Rumour Spreading Depends on the Latent Geometry and Degree Distribution in Social Network Models", "authors": ["Marc Kaufmann", "Kostas Lakis", "Johannes Lengler", "Raghu Raman Ravi", "Ulysse Schaller", "Konstantin Sturm"], "categories": ["math.PR", "cs.SI", "math.CO", "05C82, 91D25, 91D30"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      49 pages", "url": "http://arxiv.org/abs/2408.01268v3", "summary": "We study push-pull rumour spreading in ultra-small-world models for social\nnetworks where the degrees follow a power-law distribution. In a non-geometric\nsetting, Fountoulakis, Panagiotou and Sauerwald have shown that rumours always\nspread ultra-fast (SODA 2012), i.e. in doubly logarithmic time. On the other\nhand, Janssen and Mehrabian have found that rumours spread slowly (polynomial\ntime) in a spatial preferential attachment model (SIDMA 2017). We study the\nquestion systematically for the model of Geometric Inhomogeneous Random Graphs\n(GIRGs). Our results are two-fold: first, with Euclidean geometry slow, fast\n(polylogarithmic) and ultra-fast rumour spreading may occur, depending on the\nexponent of the power law and the strength of the geometry in the networks, and\nwe fully characterise the phase boundaries in between. The regimes do not\ncoincide with the graph distance regimes, i.e., polylogarithmic or even\npolynomial rumour spreading may occur even if graph distances are doubly\nlogarithmic. We expect these results to hold with little effort for related\nmodels, e.g. Scale-Free Percolation. Second, we show that rumour spreading is\nalways (at least) fast in a non-metric geometry. The considered non-metric\ngeometry allows to model social connections where resemblance of vertices in a\nsingle attribute, such as familial kinship, already strongly indicates the\npresence of an edge. Euclidean geometry fails to capture such ties.\n  For some regimes in the Euclidean setting, the efficient pathways for\nspreading rumours differ from previously identified paths. For example, a\nvertex of degree $d$ can transmit the rumour to a vertex of larger degree by a\nchain of length $3$, where one of the two intermediaries has constant degree,\nand the other has degree $d^{c}$ for some constant $c<1$. Similar but longer\nchains of vertices, all having non-constant degree, turn out to be useful as\nwell.", "comment": "49 pages", "pdf_url": "http://arxiv.org/pdf/2408.01268v3", "cate": "math.PR", "date": "2024-08-02", "updated": "2025-07-18"}
{"id": "2410.23086", "title": "Towards Practical Operation of Deep Reinforcement Learning Agents in Real-World Network Management at Open RAN Edges", "authors": ["Haiyuan Li", "Hari Madhukumar", "Peizheng Li", "Yuelin Liu", "Yiran Teng", "Yulei Wu", "Ning Wang", "Shuangyi Yan", "Dimitra Simeonidou"], "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.23086v2", "summary": "Deep Reinforcement Learning (DRL) has emerged as a powerful solution for\nmeeting the growing demands for connectivity, reliability, low latency and\noperational efficiency in advanced networks. However, most research has focused\non theoretical analysis and simulations, with limited investigation into\nreal-world deployment. To bridge the gap and support practical DRL deployment\nfor network management, we first present an orchestration framework that\nintegrates ETSI Multi-access Edge Computing (MEC) with Open RAN, enabling\nseamless adoption of DRL-based strategies across different time scales while\nenhancing agent lifecycle management. We then identify three critical\nchallenges hindering DRL's real-world deployment, including (1) asynchronous\nrequests from unpredictable or bursty traffic, (2) adaptability and\ngeneralization across heterogeneous topologies and evolving service demands,\nand (3) prolonged convergence and service interruptions due to exploration in\nlive operational environments. To address these challenges, we propose a\nthree-fold solution strategy: (a) advanced time-series integration for handling\nasynchronized traffic, (b) flexible architecture design such as multi-agent DRL\nand incremental learning to support heterogeneous scenarios, and (c)\nsimulation-driven deployment with transfer learning to reduce convergence time\nand service disruptions. Lastly, the feasibility of the MEC-O-RAN architecture\nis validated on an urban-wide testing infrastructure, and two real-world use\ncases are presented, showcasing the three identified challenges and\ndemonstrating the effectiveness of the proposed solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.23086v2", "cate": "cs.NI", "date": "2024-10-30", "updated": "2025-07-18"}
{"id": "2507.13689", "title": "Density Evolution Analysis of Sparse-Block IDMA", "authors": ["Jean-Francois Chamberland", "Gianluigi Liva", "Krishna Narayanan"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Presented at the 2025 IEEE Workshop on Signal Processing and Artificial Intelligence for Wireless Communications (SPAWC)", "url": "http://arxiv.org/abs/2507.13689v1", "summary": "Sparse block interleaver division multiple access (SB-IDMA) is a recently\nintroduced unsourced multiple access protocol that aims to improve the\nperformance of the grant-free two-step random access transmission protocol of\nthe 3GPP 5G New Radio standard. We introduced a density evolution analysis of\nthe successive interference cancellation receiver of SB-IDMA, providing a\ntheoretical characterization of its performance.", "comment": "Presented at the 2025 IEEE Workshop on Signal Processing and\n  Artificial Intelligence for Wireless Communications (SPAWC)", "pdf_url": "http://arxiv.org/pdf/2507.13689v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13375", "title": "GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment", "authors": ["Chunyuan Zhao", "Zizheng Guo", "Zuodong Zhang", "Yibo Lin"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13375v1", "summary": "Layer assignment is critical for global routing of VLSI circuits. It converts\n2D routing paths into 3D routing solutions by determining the proper metal\nlayer for each routing segments to minimize congestion and via count. As\ndifferent layers have different unit resistance and capacitance, layer\nassignment also has significant impacts to timing and power. With growing\ndesign complexity, it becomes increasingly challenging to simultaneously\noptimize timing, power, and congestion efficiently. Existing studies are mostly\nlimited to a subset of objectives. In this paper, we propose a GPU-accelerated\nperformance-driven layer assignment framework, GAP-LA, for holistic\noptimization the aforementioned objectives. Experimental results demonstrate\nthat we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4%\nbetter total negative slack (TNS) while maintaining power and congestion with\ncompetitive runtime compared with ISPD 2025 contest winners, especially on\ndesigns with up to 12 millions of nets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13375v1", "cate": "cs.AR", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2412.18781", "title": "Robustness Evaluation of Offline Reinforcement Learning for Robot Control Against Action Perturbations", "authors": ["Shingo Ayabe", "Takuto Otomo", "Hiroshi Kera", "Kazuhiko Kawamoto"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      22 pages, 6 figures", "url": "http://arxiv.org/abs/2412.18781v2", "summary": "Offline reinforcement learning, which learns solely from datasets without\nenvironmental interaction, has gained attention. This approach, similar to\ntraditional online deep reinforcement learning, is particularly promising for\nrobot control applications. Nevertheless, its robustness against real-world\nchallenges, such as joint actuator faults in robots, remains a critical\nconcern. This study evaluates the robustness of existing offline reinforcement\nlearning methods using legged robots from OpenAI Gym based on average episodic\nrewards. For robustness evaluation, we simulate failures by incorporating both\nrandom and adversarial perturbations, representing worst-case scenarios, into\nthe joint torque signals. Our experiments show that existing offline\nreinforcement learning methods exhibit significant vulnerabilities to these\naction perturbations and are more vulnerable than online reinforcement learning\nmethods, highlighting the need for more robust approaches in this field.", "comment": "22 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2412.18781v2", "cate": "cs.RO", "date": "2024-12-25", "updated": "2025-07-18"}
{"id": "2507.13392", "title": "TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction", "authors": ["Emil Häglund", "Johanna Björklund"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13392v1", "summary": "We improve the extraction of insights from customer reviews by restructuring\nthe topic modelling pipeline to operate on opinion units - distinct statements\nthat include relevant text excerpts and associated sentiment scores. Prior work\nhas demonstrated that such units can be reliably extracted using large language\nmodels. The result is a heightened performance of the subsequent topic\nmodeling, leading to coherent and interpretable topics while also capturing the\nsentiment associated with each topic. By correlating the topics and sentiments\nwith business metrics, such as star ratings, we can gain insights on how\nspecific customer concerns impact business outcomes. We present our system's\nimplementation, use cases, and advantages over other topic modeling and\nclassification solutions. We also evaluate its effectiveness in creating\ncoherent topics and assess methods for integrating topic and sentiment\nmodalities for accurate star-rating prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13392v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13703", "title": "Binarizing Physics-Inspired GNNs for Combinatorial Optimization", "authors": ["Martin Krutský", "Gustav Šír", "Vyacheslav Kungurtsev", "Georgios Korpas"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to the 28th European Conference on Artificial Intelligence (ECAI 2025). This archival version includes supplementary appendices", "url": "http://arxiv.org/abs/2507.13703v1", "summary": "Physics-inspired graph neural networks (PI-GNNs) have been utilized as an\nefficient unsupervised framework for relaxing combinatorial optimization\nproblems encoded through a specific graph structure and loss, reflecting\ndependencies between the problem's variables. While the framework has yielded\npromising results in various combinatorial problems, we show that the\nperformance of PI-GNNs systematically plummets with an increasing density of\nthe combinatorial problem graphs. Our analysis reveals an interesting phase\ntransition in the PI-GNNs' training dynamics, associated with degenerate\nsolutions for the denser problems, highlighting a discrepancy between the\nrelaxed, real-valued model outputs and the binary-valued problem solutions. To\naddress the discrepancy, we propose principled alternatives to the naive\nstrategy used in PI-GNNs by building on insights from fuzzy logic and binarized\nneural networks. Our experiments demonstrate that the portfolio of proposed\nmethods significantly improves the performance of PI-GNNs in increasingly dense\nsettings.", "comment": "Accepted to the 28th European Conference on Artificial Intelligence\n  (ECAI 2025). This archival version includes supplementary appendices", "pdf_url": "http://arxiv.org/pdf/2507.13703v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.04469", "title": "The role of large language models in UI/UX design: A systematic literature review", "authors": ["Ammar Ahmed", "Ali Shariq Imran"], "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04469v2", "summary": "This systematic literature review examines the role of large language models\n(LLMs) in UI/UX design, synthesizing findings from 38 peer-reviewed studies\npublished between 2022 and 2025. We identify key LLMs in use, including GPT-4,\nGemini, and PaLM, and map their integration across the design lifecycle, from\nideation to evaluation. Common practices include prompt engineering,\nhuman-in-the-loop workflows, and multimodal input. While LLMs are reshaping\ndesign processes, challenges such as hallucination, prompt instability, and\nlimited explainability persist. Our findings highlight LLMs as emerging\ncollaborators in design, and we propose directions for the ethical, inclusive,\nand effective integration of these technologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04469v2", "cate": "cs.HC", "date": "2025-07-06", "updated": "2025-07-17"}
{"id": "2507.13401", "title": "MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing", "authors": ["Shreya Kadambi", "Risheek Garrepalli", "Shubhankar Borse", "Munawar Hyatt", "Fatih Porikli"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2507.13401v1", "summary": "Despite the remarkable success of diffusion models in text-to-image\ngeneration, their effectiveness in grounded visual editing and compositional\ncontrol remains challenging. Motivated by advances in self-supervised learning\nand in-context generative modeling, we propose a series of simple yet powerful\ndesign choices that significantly enhance diffusion model capacity for\nstructured, controllable generation and editing. We introduce Masking-Augmented\nDiffusion with Inference-Time Scaling (MADI), a framework that improves the\neditability, compositionality and controllability of diffusion models through\ntwo core innovations. First, we introduce Masking-Augmented gaussian Diffusion\n(MAgD), a novel training strategy with dual corruption process which combines\nstandard denoising score matching and masked reconstruction by masking noisy\ninput from forward process. MAgD encourages the model to learn discriminative\nand compositional visual representations, thus enabling localized and\nstructure-aware editing. Second, we introduce an inference-time capacity\nscaling mechanism based on Pause Tokens, which act as special placeholders\ninserted into the prompt for increasing computational capacity at inference\ntime. Our findings show that adopting expressive and dense prompts during\ntraining further enhances performance, particularly for MAgD. Together, these\ncontributions in MADI substantially enhance the editability of diffusion\nmodels, paving the way toward their integration into more general-purpose,\nin-context generative diffusion architectures.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2507.13401v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13310", "title": "Modelling the spillover from online engagement to offline protest: stochastic dynamics and mean-field approximations on networks", "authors": ["Moyi Tian", "P. Jeffrey Brantingham", "Nancy Rodríguez"], "categories": ["physics.soc-ph", "cs.SI", "math.DS", "nlin.AO", "q-bio.PE"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      44 pages, 33 figures", "url": "http://arxiv.org/abs/2507.13310v2", "summary": "Social media is transforming various aspects of offline life, from everyday\ndecisions such as dining choices to the progression of conflicts. In this\nstudy, we propose a coupled modelling framework with an online social network\nlayer to analyse how engagement on a specific topic spills over into offline\nprotest activities. We develop a stochastic model and derive several mean-field\nmodels of varying complexity. These models allow us to estimate the\nreproductive number and anticipate when surges in activity are likely to occur.\nA key factor is the transmission rate between the online and offline domains;\nfor offline outbursts to emerge, this rate must fall within a critical range,\nneither too low nor too high. Additionally, using synthetic networks, we\nexamine how network structure influences the accuracy of these approximations.\nOur findings indicate that low-density networks need more complex\napproximations, whereas simpler models can effectively represent higher-density\nnetworks. When tested on two real-world networks, however, increased complexity\ndid not enhance accuracy.", "comment": "44 pages, 33 figures", "pdf_url": "http://arxiv.org/pdf/2507.13310v2", "cate": "physics.soc-ph", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.11649", "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs", "authors": ["Daniel Commey", "Benjamin Appiah", "Griffith S. Klogo", "Garth V. Crosby"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11649v2", "summary": "Federated Learning (FL) enables collaborative model training on decentralized\ndata without exposing raw data. However, the evaluation phase in FL may leak\nsensitive information through shared performance metrics. In this paper, we\npropose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to\nenable privacy-preserving and verifiable evaluation for FL. Instead of\nrevealing raw loss values, clients generate a succinct proof asserting that\ntheir local loss is below a predefined threshold. Our approach is implemented\nwithout reliance on external APIs, using self-contained modules for federated\nlearning simulation, ZKP circuit design, and experimental evaluation on both\nthe MNIST and Human Activity Recognition (HAR) datasets. We focus on a\nthreshold-based proof for a simple Convolutional Neural Network (CNN) model\n(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate\nthe approach in terms of computational overhead, communication cost, and\nverifiability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11649v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-18"}
{"id": "2507.13808", "title": "Asymptotically Optimal Codes Correcting One Substring Edit", "authors": ["Yuting Li", "Yuanyuan Tang", "Hao Lou", "Ryan Gabrys", "Farzad Farnoud"], "categories": ["cs.IT", "math.IT", "G.2.1"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 1 figure", "url": "http://arxiv.org/abs/2507.13808v1", "summary": "The substring edit error is the operation of replacing a substring $u$ of $x$\nwith another string $v$, where the lengths of $u$ and $v$ are bounded by a\ngiven constant $k$. It encompasses localized insertions, deletions, and\nsubstitutions within a window. Codes correcting one substring edit have\nredundancy at least $\\log n+k$. In this paper, we construct codes correcting\none substring edit with redundancy $\\log n+O(\\log \\log n)$, which is\nasymptotically optimal.", "comment": "6 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.13808v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13631", "title": "4T2R X-ReRAM CiM Array for Variation-tolerant, Low-power, Massively Parallel MAC Operation", "authors": ["Fuyuki Kihara", "Seiji Uenohara", "Satoshi Awamura", "Naoko Misawa", "Chihiro Matsui", "Ken Takeuchi"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      4 pages", "url": "http://arxiv.org/abs/2507.13631v1", "summary": "Computation-in-Memory (CiM) is attracting attention as a technology that can\nperform MAC calculations required for AI accelerators, at high speed with low\npower consumption. However, there is a problem regarding power consumption and\ndevice-derived errors that increase as row parallelism increases. In this\npaper, a 4T2R ReRAM cell and an 8T SRAM CiM suitable for CiM is proposed. It is\nshown that adopting the proposed 4T2R ReRAM cell reduces the errors due to\nvariation in ReRAM devices compared to conventional 4T4R ReRAM cells.", "comment": "4 pages", "pdf_url": "http://arxiv.org/pdf/2507.13631v1", "cate": "cs.AR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.11887", "title": "Stonefish: Supporting Machine Learning Research in Marine Robotics", "authors": ["Michele Grimaldi", "Patryk Cieslak", "Eduardo Ochoa", "Vibhav Bharti", "Hayat Rajani", "Ignacio Carlucho", "Maria Koskinopoulou", "Yvan R. Petillot", "Nuno Gracias"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      2025 IEEE/RSJ International Conference on Robotics and Automation (ICRA)", "url": "http://arxiv.org/abs/2502.11887v2", "summary": "Simulations are highly valuable in marine robotics, offering a cost-effective\nand controlled environment for testing in the challenging conditions of\nunderwater and surface operations. Given the high costs and logistical\ndifficulties of real-world trials, simulators capable of capturing the\noperational conditions of subsea environments have become key in developing and\nrefining algorithms for remotely-operated and autonomous underwater vehicles.\nThis paper highlights recent enhancements to the Stonefish simulator, an\nadvanced open-source platform supporting development and testing of marine\nrobotics solutions. Key updates include a suite of additional sensors, such as\nan event-based camera, a thermal camera, and an optical flow camera, as well\nas, visual light communication, support for tethered operations, improved\nthruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.\nThese developments and an automated annotation tool significantly bolster\nStonefish's role in marine robotics research, especially in the field of\nmachine learning, where training data with a known ground truth is hard or\nimpossible to collect.", "comment": "2025 IEEE/RSJ International Conference on Robotics and Automation\n  (ICRA)", "pdf_url": "http://arxiv.org/pdf/2502.11887v2", "cate": "cs.RO", "date": "2025-02-17", "updated": "2025-07-18"}
{"id": "2507.13395", "title": "Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only", "authors": ["Xuanqi Gao", "Weipeng Jiang", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Xinyang Yin", "Chao Shen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13395v1", "summary": "The advent of neural machine translation (NMT) has revolutionized\ncross-lingual communication, yet preserving stylistic nuances remains a\nsignificant challenge. While existing approaches often require parallel corpora\nfor style preservation, we introduce Babel, a novel framework that enhances\nstylistic fidelity in NMT using only monolingual corpora. Babel employs two key\ncomponents: (1) a style detector based on contextual embeddings that identifies\nstylistic disparities between source and target texts, and (2) a\ndiffusion-based style applicator that rectifies stylistic inconsistencies while\nmaintaining semantic integrity. Our framework integrates with existing NMT\nsystems as a post-processing module, enabling style-aware translation without\nrequiring architectural modifications or parallel stylistic data. Extensive\nexperiments on five diverse domains (law, literature, scientific writing,\nmedicine, and educational content) demonstrate Babel's effectiveness: it\nidentifies stylistic inconsistencies with 88.21% precision and improves\nstylistic preservation by 150% while maintaining a high semantic similarity\nscore of 0.92. Human evaluation confirms that translations refined by Babel\nbetter preserve source text style while maintaining fluency and adequacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13395v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13704", "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware", "authors": ["Anabel Yong", "Austin Tripp", "Layla Hosseini-Gerami", "Brooks Paige"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13704v1", "summary": "Multi-objective Bayesian optimization (MOBO) provides a principled framework\nfor navigating trade-offs in molecular design. However, its empirical\nadvantages over scalarized alternatives remain underexplored. We benchmark a\nsimple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --\nagainst a simple fixed-weight scalarized baseline using Expected Improvement\n(EI), under a tightly controlled setup with identical Gaussian Process\nsurrogates and molecular representations. Across three molecular optimization\ntasks, EHVI consistently outperforms scalarized EI in terms of Pareto front\ncoverage, convergence speed, and chemical diversity. While scalarization\nencompasses flexible variants -- including random or adaptive schemes -- our\nresults show that even strong deterministic instantiations can underperform in\nlow-data regimes. These findings offer concrete evidence for the practical\nadvantages of Pareto-aware acquisition in de novo molecular optimization,\nespecially when evaluation budgets are limited and trade-offs are nontrivial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13704v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12377", "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight", "authors": ["Ke Er Amy Zhang", "Jodie Jenkinson", "Laura Garrison"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures, accepted to IEEE VIS 2025 Conference", "url": "http://arxiv.org/abs/2507.12377v3", "summary": "We conduct a deconstructive reading of a qualitative interview study with 17\nvisual data journalists from newsrooms across the globe. We borrow a\ndeconstruction approach from literary critique to explore the instability of\nmeaning in language and reveal implicit beliefs in words and ideas. Through our\nanalysis we surface two sets of opposing implicit beliefs in visual data\njournalism: objectivity/subjectivity and humanism/mechanism. We contextualize\nthese beliefs through a genealogical analysis, which brings deconstruction\ntheory into practice by providing a historic backdrop for these opposing\nperspectives. Our analysis shows that these beliefs held within visual data\njournalism are not self-enclosed but rather a product of external societal\nforces and paradigm shifts over time. Through this work, we demonstrate how\nthinking with critical theories such as deconstruction and genealogy can\nreframe \"success\" in visual data storytelling and diversify visualization\nresearch outcomes. These efforts push the ways in which we as researchers\nproduce domain knowledge to examine the sociotechnical issues of today's values\ntowards datafication and data visualization. All supplemental materials for\nthis work are available at osf.io/5fr48.", "comment": "11 pages, 5 figures, accepted to IEEE VIS 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.12377v3", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.13403", "title": "UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data", "authors": ["Morteza Bodaghi", "Majid Hosseini", "Raju Gottumukkala", "Ravi Teja Bhupatiraju", "Iftikhar Ahmad", "Moncef Gabbouj"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13403v1", "summary": "In this study, we present a comprehensive public dataset for driver\ndrowsiness detection, integrating multimodal signals of facial, behavioral, and\nbiometric indicators. Our dataset includes 3D facial video using a depth\ncamera, IR camera footage, posterior videos, and biometric signals such as\nheart rate, electrodermal activity, blood oxygen saturation, skin temperature,\nand accelerometer data. This data set provides grip sensor data from the\nsteering wheel and telemetry data from the American truck simulator game to\nprovide more information about drivers' behavior while they are alert and\ndrowsy. Drowsiness levels were self-reported every four minutes using the\nKarolinska Sleepiness Scale (KSS). The simulation environment consists of three\nmonitor setups, and the driving condition is completely like a car. Data were\ncollected from 19 subjects (15 M, 4 F) in two conditions: when they were fully\nalert and when they exhibited signs of sleepiness. Unlike other datasets, our\nmultimodal dataset has a continuous duration of 40 minutes for each data\ncollection session per subject, contributing to a total length of 1,400\nminutes, and we recorded gradual changes in the driver state rather than\ndiscrete alert/drowsy labels. This study aims to create a comprehensive\nmultimodal dataset of driver drowsiness that captures a wider range of\nphysiological, behavioral, and driving-related signals. The dataset will be\navailable upon request to the corresponding author.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13403v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13961", "title": "Secretive Hotplug Coded Caching", "authors": ["Mallikharjuna Chinnapadamala", "Charul Rajput", "B. Sundar Rajan"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 pages and 2 figures. arXiv admin note: text overlap with arXiv:2404.06433", "url": "http://arxiv.org/abs/2507.13961v1", "summary": "In this work, we consider a coded caching model called \\textit{hotplug coded\ncaching}, in which some users are offline during the delivery phase. The\nconcept of Hotplug Placement Delivery Arrays (HpPDAs) for hotplug coded caching\nsystems has been introduced in the literature, and two classes of HpPDAs are\nknown. In this paper, we consider a secrecy constraint in hotplug coded caching\nsetup, where users should not learn anything about any file from their cache\ncontent, and active users should not gain any information about files other\nthan their demanded file from either their cache content or the server\ntransmissions. We propose two secretive schemes for the two classes of HpPDAs\nand compare them with a baseline scheme, which is a secretive scheme using PDAs\nfor the classical coded caching setup and can be trivially adapted for the\nhotplug coded caching setup. We numerically show that our schemes outperform\nthe baseline scheme in certain memory regions.", "comment": "11 pages and 2 figures. arXiv admin note: text overlap with\n  arXiv:2404.06433", "pdf_url": "http://arxiv.org/pdf/2507.13961v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13736", "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "categories": ["cs.LG", "cs.AR", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Poster at ACM ICONS 2025 - International Conference on Neuromorphic Systems", "url": "http://arxiv.org/abs/2507.13736v1", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2.", "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "pdf_url": "http://arxiv.org/pdf/2507.13736v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.06776", "title": "Chance-constrained Linear Quadratic Gaussian Games for Multi-robot Interaction under Uncertainty", "authors": ["Kai Ren", "Giulio Salizzoni", "Mustafa Emre Gürsoy", "Maryam Kamgarpour"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Published in IEEE Control Systems Letters", "url": "http://arxiv.org/abs/2503.06776v2", "summary": "We address safe multi-robot interaction under uncertainty. In particular, we\nformulate a chance-constrained linear quadratic Gaussian game with coupling\nconstraints and system uncertainties. We find a tractable reformulation of the\ngame and propose a dual ascent algorithm. We prove that the algorithm converges\nto a feedback generalized Nash equilibrium of the reformulated game, ensuring\nthe satisfaction of the chance constraints. We test our method in driving\nsimulations and real-world robot experiments. Our method ensures safety under\nuncertainty and generates less conservative trajectories than single-agent\nmodel predictive control.", "comment": "Published in IEEE Control Systems Letters", "pdf_url": "http://arxiv.org/pdf/2503.06776v2", "cate": "cs.RO", "date": "2025-03-09", "updated": "2025-07-18"}
{"id": "2507.13408", "title": "A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs", "authors": ["Hemanth Kumar M", "Karthika M", "Saianiruth M", "Vasanthakumar Venugopal", "Anandakumar D", "Revathi Ezhumalai", "Charulatha K", "Kishore Kumar J", "Dayana G", "Kalyan Sivasailam", "Bargava Subramanian"], "categories": ["cs.CV", "cs.AI", "68T07", "I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures", "url": "http://arxiv.org/abs/2507.13408v1", "summary": "Background: Shoulder fractures are often underdiagnosed, especially in\nemergency and high-volume clinical settings. Studies report up to 10% of such\nfractures may be missed by radiologists. AI-driven tools offer a scalable way\nto assist early detection and reduce diagnostic delays. We address this gap\nthrough a dedicated AI system for shoulder radiographs. Methods: We developed a\nmulti-model deep learning system using 10,000 annotated shoulder X-rays.\nArchitectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and\nRF-DETR. To enhance detection, we applied bounding box and classification-level\nensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW\nensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming\nindividual models across all key metrics. It demonstrated strong recall and\nlocalization precision, confirming its effectiveness for clinical fracture\ndetection in shoulder X-rays. Conclusion: The results show ensemble-based AI\ncan reliably detect shoulder fractures in radiographs with high clinical\nrelevance. The model's accuracy and deployment readiness position it well for\nintegration into real-time diagnostic workflows. The current model is limited\nto binary fracture detection, reflecting its design for rapid screening and\ntriage support rather than detailed orthopedic classification.", "comment": "12 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.13408v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13707", "title": "Learning Deformable Body Interactions With Adaptive Spatial Tokenization", "authors": ["Hao Wang", "Yu Liu", "Daniel Biggs", "Haoru Wang", "Jiandong Yu", "Ping Huang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      21 pages, 15 figures", "url": "http://arxiv.org/abs/2507.13707v1", "summary": "Simulating interactions between deformable bodies is vital in fields like\nmaterial science, mechanical design, and robotics. While learning-based methods\nwith Graph Neural Networks (GNNs) are effective at solving complex physical\nsystems, they encounter scalability issues when modeling deformable body\ninteractions. To model interactions between objects, pairwise global edges have\nto be created dynamically, which is computationally intensive and impractical\nfor large-scale meshes. To overcome these challenges, drawing on insights from\ngeometric representations, we propose an Adaptive Spatial Tokenization (AST)\nmethod for efficient representation of physical states. By dividing the\nsimulation space into a grid of cells and mapping unstructured meshes onto this\nstructured grid, our approach naturally groups adjacent mesh nodes. We then\napply a cross-attention module to map the sparse cells into a compact,\nfixed-length embedding, serving as tokens for the entire physical state.\nSelf-attention modules are employed to predict the next state over these tokens\nin latent space. This framework leverages the efficiency of tokenization and\nthe expressive power of attention mechanisms to achieve accurate and scalable\nsimulation results. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches in modeling deformable\nbody interactions. Notably, it remains effective on large-scale simulations\nwith meshes exceeding 100,000 nodes, where existing methods are hindered by\ncomputational limitations. Additionally, we contribute a novel large-scale\ndataset encompassing a wide range of deformable body interactions to support\nfuture research in this area.", "comment": "21 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.13707v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.08102", "title": "Consistency of Responses and Continuations Generated by Large Language Models on Social Media", "authors": ["Wenlu Fan", "Yuqi Zhu", "Chenyang Wang", "Bin Wang", "Wentao Xu"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by the International AAAI Conference on Web and Social Media (ICWSM) 2026(Los Angeles, California, U.S.)", "url": "http://arxiv.org/abs/2501.08102v3", "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using two open-source models: Gemma and Llama.\nBy analyzing climate change discussions from Twitter and Reddit, we examine\nemotional transitions, intensity patterns, and semantic similarity between\nhuman-authored and LLM-generated content. Our findings reveal that while both\nmodels maintain high semantic coherence, they exhibit distinct emotional\npatterns: Gemma shows a tendency toward negative emotion amplification,\nparticularly anger, while maintaining certain positive emotions like optimism.\nLlama demonstrates superior emotional preservation across a broader spectrum of\naffects. Both models systematically generate responses with attenuated\nemotional intensity compared to human-authored content and show a bias toward\npositive emotions in response tasks. Additionally, both models maintain strong\nsemantic similarity with original texts, though performance varies between\ncontinuation and response tasks. These findings provide insights into LLMs'\nemotional and semantic processing capabilities, with implications for their\ndeployment in social media contexts and human-AI interaction design.", "comment": "This paper has been accepted by the International AAAI Conference on\n  Web and Social Media (ICWSM) 2026(Los Angeles, California, U.S.)", "pdf_url": "http://arxiv.org/pdf/2501.08102v3", "cate": "cs.CL", "date": "2025-01-14", "updated": "2025-07-18"}
{"id": "2507.13404", "title": "AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation", "authors": ["Delin An", "Pan Du", "Jian-Xun Wang", "Chaoli Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13404v1", "summary": "Accurate 3D aortic construction is crucial for clinical diagnosis,\npreoperative planning, and computational fluid dynamics (CFD) simulations, as\nit enables the estimation of critical hemodynamic parameters such as blood flow\nvelocity, pressure distribution, and wall shear stress. Existing construction\nmethods often rely on large annotated training datasets and extensive manual\nintervention. While the resulting meshes can serve for visualization purposes,\nthey struggle to produce geometrically consistent, well-constructed surfaces\nsuitable for downstream CFD analysis. To address these challenges, we introduce\nAortaDiff, a diffusion-based framework that generates smooth aortic surfaces\ndirectly from CT/MRI volumes. AortaDiff first employs a volume-guided\nconditional diffusion model (CDM) to iteratively generate aortic centerlines\nconditioned on volumetric medical images. Each centerline point is then\nautomatically used as a prompt to extract the corresponding vessel contour,\nensuring accurate boundary delineation. Finally, the extracted contours are\nfitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh\nrepresentation. AortaDiff offers distinct advantages over existing methods,\nincluding an end-to-end workflow, minimal dependency on large labeled datasets,\nand the ability to generate CFD-compatible aorta meshes with high geometric\nfidelity. Experimental results demonstrate that AortaDiff performs effectively\neven with limited training data, successfully constructing both normal and\npathologically altered aorta meshes, including cases with aneurysms or\ncoarctation. This capability enables the generation of high-quality\nvisualizations and positions AortaDiff as a practical solution for\ncardiovascular research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13404v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14064", "title": "Bounds and Constructions of High-Memory Spatially-Coupled Codes", "authors": ["Lei Huang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted by ITW2025", "url": "http://arxiv.org/abs/2507.14064v1", "summary": "In this paper, we apply the Clique Lov\\'asz Local Lemma to provide sufficient\nconditions on memory and lifting degree for removing certain harmful\ncombinatorial structures in spatially-coupled (SC) codes that negatively impact\ndecoding performance. Additionally, we present, for the first time, a\nconstructive algorithm based on the Moser-Tardos algorithm that ensures\npredictable performance. Furthermore, leveraging the properties of\nLLL-distribution and M-T-distribution, we establish the dependencies among the\nharmful structures during the construction process. We provide upper bounds on\nthe probability change of remaining harmful structures after eliminating some\nof them. In particular, the elimination of 4-cycles increases the probability\nof 6-cycles becoming active by at most a factor of $e^{8/3}$.", "comment": "Accepted by ITW2025", "pdf_url": "http://arxiv.org/pdf/2507.14064v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2406.12385", "title": "Fast Graph Vector Search via Hardware Acceleration and Delayed-Synchronization Traversal", "authors": ["Wenqi Jiang", "Hang Hu", "Torsten Hoefler", "Gustavo Alonso"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Accepted by VLDB'25", "url": "http://arxiv.org/abs/2406.12385v2", "summary": "Vector search systems are indispensable in large language model (LLM)\nserving, search engines, and recommender systems, where minimizing online\nsearch latency is essential. Among various algorithms, graph-based vector\nsearch (GVS) is particularly popular due to its high search performance and\nquality. However, reducing GVS latency by intra-query parallelization remains\nchallenging due to limitations imposed by both existing hardware architectures\n(CPUs and GPUs) and the inherent difficulty of parallelizing graph traversals.\nTo efficiently serve low-latency GVS, we co-design hardware and algorithm by\nproposing Falcon and Delayed-Synchronization Traversal (DST). Falcon is a\nhardware GVS accelerator that implements efficient GVS operators, pipelines\nthese operators, and reduces memory accesses by tracking search states with an\non-chip Bloom filter. DST is an efficient graph traversal algorithm that\nsimultaneously improves search performance and quality by relaxing traversal\norders to maximize accelerator utilization. Evaluation across various graphs\nand datasets shows that Falcon, prototyped on FPGAs, together with DST,\nachieves up to 4.3x and 19.5x lower latency and up to 8.0x and 26.9x\nimprovements in energy efficiency over CPU- and GPU-based GVS systems.", "comment": "Accepted by VLDB'25", "pdf_url": "http://arxiv.org/pdf/2406.12385v2", "cate": "cs.AR", "date": "2024-06-18", "updated": "2025-07-18"}
{"id": "2503.07049", "title": "VMTS: Vision-Assisted Teacher-Student Reinforcement Learning for Multi-Terrain Locomotion in Bipedal Robots", "authors": ["Fu Chen", "Rui Wan", "Peidong Liu", "Nanxing Zheng", "Bo Zhou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.07049v2", "summary": "Bipedal robots, due to their anthropomorphic design, offer substantial\npotential across various applications, yet their control is hindered by the\ncomplexity of their structure. Currently, most research focuses on\nproprioception-based methods, which lack the capability to overcome complex\nterrain. While visual perception is vital for operation in human-centric\nenvironments, its integration complicates control further. Recent reinforcement\nlearning (RL) approaches have shown promise in enhancing legged robot\nlocomotion, particularly with proprioception-based methods. However, terrain\nadaptability, especially for bipedal robots, remains a significant challenge,\nwith most research focusing on flat-terrain scenarios. In this paper, we\nintroduce a novel mixture of experts teacher-student network RL strategy, which\nenhances the performance of teacher-student policies based on visual inputs\nthrough a simple yet effective approach. Our method combines terrain selection\nstrategies with the teacher policy, resulting in superior performance compared\nto traditional models. Additionally, we introduce an alignment loss between the\nteacher and student networks, rather than enforcing strict similarity, to\nimprove the student's ability to navigate diverse terrains. We validate our\napproach experimentally on the Limx Dynamic P1 bipedal robot, demonstrating its\nfeasibility and robustness across multiple terrain types.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.07049v2", "cate": "cs.RO", "date": "2025-03-10", "updated": "2025-07-18"}
{"id": "2507.13410", "title": "Causal Language Control in Multilingual Transformers via Sparse Feature Steering", "authors": ["Cheng-Ting Chou", "George Liu", "Jessica Sun", "Cole Blondin", "Kevin Zhu", "Vasu Sharma", "Sean O'Brien"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13410v1", "summary": "Deterministically controlling the target generation language of large\nmultilingual language models (LLMs) remains a fundamental challenge,\nparticularly in zero-shot settings where neither explicit language prompts nor\nfine-tuning are available. In this work, we investigate whether sparse\nautoencoder (SAE) features, previously shown to correlate with interpretable\nmodel behaviors, can be leveraged to steer the generated language of LLMs\nduring inference. Leveraging pretrained SAEs on the residual streams of\nGemma-2B and Gemma-9B, we identify features whose activations differ most\nsignificantly between English and four target languages: Chinese, Japanese,\nSpanish, and French. By modifying just a single SAE feature at one transformer\nlayer, we achieve controlled language shifts with up to 90\\% success, as\nmeasured by FastText language classification, while preserving semantic\nfidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)\nsimilarity. Our analysis reveals that language steering is most effective in\nmid-to-late transformer layers and is amplified by specific attention heads\ndisproportionately associated with language-sensitive SAE features. These\nresults demonstrate the promise of sparse feature steering as a lightweight and\ninterpretable mechanism for controllable multilingual generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13410v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13716", "title": "Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods", "authors": ["Danilo Avola", "Andrea Bernardini", "Giancarlo Crocetti", "Andrea Ladogana", "Mario Lezoche", "Maurizio Mancini", "Daniele Pannone", "Amedeo Ranaldi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13716v1", "summary": "Parkinson's Disease PD is a progressive neurodegenerative disorder that\naffects motor and cognitive functions with early diagnosis being critical for\neffective clinical intervention Electroencephalography EEG offers a noninvasive\nand costeffective means of detecting PDrelated neural alterations yet the\ndevelopment of reliable automated diagnostic models remains a challenge In this\nstudy we conduct a systematic benchmark of traditional machine learning ML and\ndeep learning DL models for classifying PD using a publicly available oddball\ntask dataset Our aim is to lay the groundwork for developing an effective\nlearning system and to determine which approach produces the best results We\nimplement a unified sevenstep preprocessing pipeline and apply consistent\nsubjectwise crossvalidation and evaluation criteria to ensure comparability\nacross models Our results demonstrate that while baseline deep learning\narchitectures particularly CNNLSTM models achieve the best performance compared\nto other deep learning architectures underlining the importance of capturing\nlongrange temporal dependencies several traditional classifiers such as XGBoost\nalso offer strong predictive accuracy and calibrated decision boundaries By\nrigorously comparing these baselines our work provides a solid reference\nframework for future studies aiming to develop and evaluate more complex or\nspecialized architectures Establishing a reliable set of baseline results is\nessential to contextualize improvements introduced by novel methods ensuring\nscientific rigor and reproducibility in the evolving field of EEGbased\nneurodiagnostics", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13716v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.15761", "title": "AIvaluateXR: An Evaluation Framework for on-Device AI in XR with Benchmarking Results", "authors": ["Dawar Khan", "Xinyu Liu", "Omar Mena", "Donggang Jia", "Alexandre Kouyoumdjian", "Ivan Viola"], "categories": ["cs.DC", "cs.AI", "cs.GR", "cs.HC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      AIvaluateXR is updated version of LoXR", "url": "http://arxiv.org/abs/2502.15761v2", "summary": "The deployment of large language models (LLMs) on extended reality (XR)\ndevices has great potential to advance the field of human-AI interaction. In\nthe case of direct, on-device model inference, selecting the appropriate model\nand device for specific tasks remains challenging. In this paper, we present\nAIvaluateXR, a comprehensive evaluation framework for benchmarking LLMs running\non XR devices. To demonstrate the framework, we deploy 17 selected LLMs across\nfour XR platforms: Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and Apple Vision\nPro, and conduct an extensive evaluation. Our experimental setup measures four\nkey metrics: performance consistency, processing speed, memory usage, and\nbattery consumption. For each of the 68 model-device pairs, we assess\nperformance under varying string lengths, batch sizes, and thread counts,\nanalyzing the trade-offs for real-time XR applications. We propose a unified\nevaluation method based on the 3D Pareto Optimality theory to select the\noptimal device-model pairs from quality and speed objectives. Additionally, we\ncompare the efficiency of on-device LLMs with client-server and cloud-based\nsetups, and evaluate their accuracy on two interactive tasks. We believe our\nfindings offer valuable insight to guide future optimization efforts for LLM\ndeployment on XR devices. Our evaluation method can be used as standard\ngroundwork for further research and development in this emerging field. The\nsource code and supplementary materials are available at:\nwww.nanovis.org/AIvaluateXR.html", "comment": "AIvaluateXR is updated version of LoXR", "pdf_url": "http://arxiv.org/pdf/2502.15761v2", "cate": "cs.DC", "date": "2025-02-13", "updated": "2025-07-18"}
{"id": "2507.13405", "title": "COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark", "authors": ["Ishant Chintapatla", "Kazuma Choji", "Naaisha Agarwal", "Andrew Lin", "Hannah You", "Charles Duong", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13405v1", "summary": "Recently, many benchmarks and datasets have been developed to evaluate\nVision-Language Models (VLMs) using visual question answering (VQA) pairs, and\nmodels have shown significant accuracy improvements. However, these benchmarks\nrarely test the model's ability to accurately complete visual entailment, for\ninstance, accepting or refuting a hypothesis based on the image. To address\nthis, we propose COREVQA (Crowd Observations and Reasoning Entailment), a\nbenchmark of 5608 image and synthetically generated true/false statement pairs,\nwith images derived from the CrowdHuman dataset, to provoke visual entailment\nreasoning on challenging crowded images. Our results show that even the\ntop-performing VLMs achieve accuracy below 80%, with other models performing\nsubstantially worse (39.98%-69.95%). This significant performance gap reveals\nkey limitations in VLMs' ability to reason over certain types of image-question\npairs in crowded scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13405v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14070", "title": "Error Correcting Codes for Segmented Burst-Deletion Channels", "authors": ["Yajuan Liu", "Tolga M. Duman"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14070v1", "summary": "We study segmented burst-deletion channels motivated by the observation that\nsynchronization errors commonly occur in a bursty manner in real-world\nsettings. In this channel model, transmitted sequences are implicitly divided\ninto non-overlapping segments, each of which may experience at most one burst\nof deletions. In this paper, we develop error correction codes for segmented\nburst-deletion channels over arbitrary alphabets under the assumption that each\nsegment may contain only one burst of t-deletions. The main idea is to encode\nthe input subsequence corresponding to each segment using existing one-burst\ndeletion codes, with additional constraints that enable the decoder to identify\nsegment boundaries during the decoding process from the received sequence. The\nresulting codes achieve redundancy that scales as O(log b), where b is the\nlength of each segment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14070v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.10748", "title": "LASANA: Large-Scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration", "authors": ["Jason Ho", "James A. Boyle", "Linshen Liu", "Andreas Gerstlauer"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10748v2", "summary": "Neuromorphic systems using in-memory or event-driven computing are motivated\nby the need for more energy-efficient processing of artificial intelligence\nworkloads. Emerging neuromorphic architectures aim to combine traditional\ndigital designs with the computational efficiency of analog computing and novel\ndevice technologies. A crucial problem in the rapid exploration and co-design\nof such architectures is the lack of tools for fast and accurate modeling and\nsimulation. Typical mixed-signal design tools integrate a digital simulator\nwith an analog solver like SPICE, which is prohibitively slow for large\nsystems. By contrast, behavioral modeling of analog components is faster, but\nexisting approaches are fixed to specific architectures with limited energy and\nperformance modeling. In this paper, we propose LASANA, a novel approach that\nleverages machine learning to derive data-driven surrogate models of analog\nsub-blocks in a digital backend architecture. LASANA uses SPICE-level\nsimulations of a circuit to train ML models that predict circuit energy,\nperformance, and behavior at analog/digital interfaces. Such models can provide\nenergy and performance annotation on top of existing behavioral models or\nfunction as replacements to analog simulation. We apply LASANA to an analog\ncrossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST,\nLASANA surrogates demonstrate up to three orders of magnitude speedup over\nSPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10748v2", "cate": "cs.AR", "date": "2025-07-14", "updated": "2025-07-18"}
{"id": "2507.13522", "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication", "authors": ["Ankit Bhardwaj", "Weiyang Wang", "Jeremy Carin", "Adam Belay", "Manya Ghobadi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      18 pages, 11 figures", "url": "http://arxiv.org/abs/2507.13522v1", "summary": "This paper presents Checkmate, a system that enables per-iteration\ncheckpointing in DNN training without any training slowdown. The traditional\napproach to checkpointing requires a pause in training to copy model states to\na separate location, allowing the state to be restored in the event of failure.\nThis approach fundamentally has a tradeoff between the frequency of checkpoints\nand the cost of a failure. We avoid this tradeoff; our key insight is that in\ndata-parallel training, all information necessary to create a checkpoint\nalready exists in the network as gradients. Our core contribution is a new\nmulticast abstraction that simultaneously delivers gradients to a separate\nCPU-based shadow cluster. The shadow maintains a checkpoint by applying those\ngradients to a copy of the model. Our evaluation shows that Checkmate performs\nper-iteration checkpointing with training throughput comparable to an ideal\nno-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent\ncheckpointing compared to state-of-the-art checkpointing systems, resulting in\n80% to 97.1% reduction in repeated work per failure. At the same checkpointing\nfrequency, Checkmate delivers 1.3x to 6.5x throughput compared to other\nsystems.", "comment": "18 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.13522v1", "cate": "cs.DC", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2503.12170", "title": "DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving", "authors": ["Tao Wang", "Cong Zhang", "Xingguang Qu", "Kun Li", "Weiwei Liu", "Chang Huang"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures; Code released", "url": "http://arxiv.org/abs/2503.12170v2", "summary": "End-to-end autonomous driving (E2E-AD) has rapidly emerged as a promising\napproach toward achieving full autonomy. However, existing E2E-AD systems\ntypically adopt a traditional multi-task framework, addressing perception,\nprediction, and planning tasks through separate task-specific heads. Despite\nbeing trained in a fully differentiable manner, they still encounter issues\nwith task coordination, and the system complexity remains high. In this work,\nwe introduce DiffAD, a novel diffusion probabilistic model that redefines\nautonomous driving as a conditional image generation task. By rasterizing\nheterogeneous targets onto a unified bird's-eye view (BEV) and modeling their\nlatent distribution, DiffAD unifies various driving objectives and jointly\noptimizes all driving tasks in a single framework, significantly reducing\nsystem complexity and harmonizing task coordination. The reverse process\niteratively refines the generated BEV image, resulting in more robust and\nrealistic driving behaviors. Closed-loop evaluations in Carla demonstrate the\nsuperiority of the proposed method, achieving a new state-of-the-art Success\nRate and Driving Score.", "comment": "8 pages, 6 figures; Code released", "pdf_url": "http://arxiv.org/pdf/2503.12170v2", "cate": "cs.RO", "date": "2025-03-15", "updated": "2025-07-18"}
{"id": "2507.13411", "title": "Aligning Knowledge Graphs and Language Models for Factual Accuracy", "authors": ["Nur A Zarin Nishat", "Andrea Coletta", "Luigi Bellomarini", "Kossi Amouzouvi", "Jens Lehmann", "Sahar Vahdati"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13411v1", "summary": "Large language models like GPT-4, Gemini, and Claude have transformed natural\nlanguage processing (NLP) tasks such as question answering, dialogue\ngeneration, summarization, and so forth; yet their susceptibility to\nhallucination stands as one of the major challenges. Among numerous approaches\nto overcome this challenge, integration of Knowledge Graphs (KGs) into language\nmodels has emerged as a promising solution as it provides structured, reliable,\ndomain-specific, and up-to-date external information to the language models. In\nthis paper, we introduce ALIGNed-LLM, a simple yet effective approach to\nimprove language models' factuality via a lean strategy to infuse KGs into the\nlatent space of language models inspired by LLaVA where visual and textual\ninformation is infused. We use embeddings from a pre-trained Knowledge Graph\nEmbedding (KGE) model, such as TransE, and a trainable projection layer to\nalign entity and text embeddings. This alignment enables the language model to\ndistinguish between similar entities improving factual grounding and reducing\nhallucination. We tested our approach on three popular questions-answering\nbenchmark datasets alongside language models of varying sizes, showing\nsignificant improvement. Furthermore, we applied our approach to a real-world\nfinancial use case from a large central bank in Europe, which demands high\naccuracy and precision, demonstrating a substantial improvement of the LLM\nanswers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13411v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13718", "title": "Bi-GRU Based Deception Detection using EEG Signals", "authors": ["Danilo Avola", "Muhammad Yasir Bilal", "Emad Emam", "Cristina Lakasz", "Daniele Pannone", "Amedeo Ranaldi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13718v1", "summary": "Deception detection is a significant challenge in fields such as security,\npsychology, and forensics. This study presents a deep learning approach for\nclassifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)\nsignals from the Bag-of-Lies dataset, a multimodal corpus designed for\nnaturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit\n(Bi-GRU) neural network was trained to perform binary classification of EEG\nsamples. The model achieved a test accuracy of 97\\%, along with high precision,\nrecall, and F1-scores across both classes. These results demonstrate the\neffectiveness of using bidirectional temporal modeling for EEG-based deception\ndetection and suggest potential for real-time applications and future\nexploration of advanced neural architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13718v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.22987", "title": "Strategic Reflectivism In Intelligent Systems", "authors": ["Nick Byrd"], "categories": ["cs.AI", "cs.HC", "econ.TH", "C.1.3; I.2.0; I.2.8; I.2.11"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the proceedings of the 4th International conference on Human and Artificial Rationality, which are to appear in Lecture Notes in Computer Science. An earlier version was presented at the 2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning (CHI25-WS-AUGMENTED-REASONING)", "url": "http://arxiv.org/abs/2505.22987v2", "summary": "By late 20th century, the rationality wars had launched debates about the\nnature and norms of intuitive and reflective thinking. Those debates drew from\nmid-20th century ideas such as bounded rationality, which challenged more\nidealized notions of rationality observed since the 19th century. Now that 21st\ncentury cognitive scientists are applying the resulting dual pro-cess theories\nto artificial intelligence, it is time to dust off some lessons from this\nhistory. So this paper synthesizes old ideas with recent results from\nexperiments on humans and machines. The result is Strategic Reflec-tivism, the\nposition that one key to intelligent systems (human or artificial) is pragmatic\nswitching between intuitive and reflective inference to opti-mally fulfill\ncompeting goals. Strategic Reflectivism builds on American Pragmatism,\ntranscends superficial indicators of reflective thinking such as model size or\nchains of thought, applies to both individual and collective intelligence\nsystems (including human-AI teams), and becomes increasingly actionable as we\nlearn more about the value of intuition and reflection.", "comment": "Accepted for publication in the proceedings of the 4th International\n  conference on Human and Artificial Rationality, which are to appear in\n  Lecture Notes in Computer Science. An earlier version was presented at the\n  2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning\n  (CHI25-WS-AUGMENTED-REASONING)", "pdf_url": "http://arxiv.org/pdf/2505.22987v2", "cate": "cs.AI", "date": "2025-05-29", "updated": "2025-07-17"}
{"id": "2507.13420", "title": "AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery", "authors": ["Alessandro Pistola", "Valentina Orru'", "Nicolo' Marchetti", "Marco Roccetti"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      25 pages, 9 Figures", "url": "http://arxiv.org/abs/2507.13420v1", "summary": "By upgrading an existing deep learning model with the knowledge provided by\none of the oldest sets of grayscale satellite imagery, known as CORONA, we\nimproved the AI model attitude towards the automatic identification of\narchaeological sites in an environment which has been completely transformed in\nthe last five decades, including the complete destruction of many of those same\nsites. The initial Bing based convolutional network model was retrained using\nCORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,\ncentral Mesopotamian floodplain. The results were twofold and surprising.\nFirst, the detection precision obtained on the area of interest increased\nsensibly: in particular, the Intersection over Union (IoU) values, at the image\nsegmentation level, surpassed 85 percent, while the general accuracy in\ndetecting archeological sites reached 90 percent. Second, our retrained model\nallowed the identification of four new sites of archaeological interest\n(confirmed through field verification), previously not identified by\narchaeologists with traditional techniques. This has confirmed the efficacy of\nusing AI techniques and the CORONA imagery from the 1960 to discover\narchaeological sites currently no longer visible, a concrete breakthrough with\nsignificant consequences for the study of landscapes with vanishing\narchaeological evidence induced by anthropization", "comment": "25 pages, 9 Figures", "pdf_url": "http://arxiv.org/pdf/2507.13420v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2409.07777", "title": "Bounds on Covert Capacity with Sub-Exponential Random Slot Selection", "authors": ["Shi-Yuan Wang", "Keerthi S. K. Arumugam", "Matthieu R. Bloch"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Transactions on Information Theory", "url": "http://arxiv.org/abs/2409.07777v2", "summary": "We consider the problem of covert communication with random slot selection\nover binary-input Discrete Memoryless Channels and Additive White Gaussian\nNoise channels, in which a transmitter attempts to reliably communicate with a\nlegitimate receiver while simultaneously maintaining covertness with respect to\nan eavesdropper. Covertness refers to the inability of the eavesdropper to\ndistinguish the transmission of a message from the absence of communication,\nmodeled by the transmission of a fixed channel input. Random slot selection\nrefers to the transmitter's ability to send a codeword in a time slot with\nknown boundaries selected uniformly at random among a predetermined number of\nslots. Our main contribution is to develop bounds for the information-theoretic\nlimit of communication in this model, called the covert capacity, when the\nnumber of time slots scales sub-exponentially with the codeword length. Our\nupper and lower bounds for the covert capacity are within a multiplicative\nfactor of $\\sqrt{2}$ independent of the channel. This result partially fills a\ncharacterization gap between the covert capacity without random slot selection\nand the covert capacity with random selection among an exponential number of\nslots in the codeword length. Our key technical contributions consist of i) a\ntight upper bound for the relative entropy characterizing the effect of random\nslot selection on the covertness constraint in our achievability proof; ii) a\ncareful converse analysis to characterize the maximum allowable weight or power\nof codewords to meet the covertness constraint. Our results suggest that,\nunlike the case without random slot selection, the choice of covertness metric\ndoes not change the covert capacity in the presence of random slot selection.", "comment": "Accepted to IEEE Transactions on Information Theory", "pdf_url": "http://arxiv.org/pdf/2409.07777v2", "cate": "cs.IT", "date": "2024-09-12", "updated": "2025-07-18"}
{"id": "2507.13833", "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training", "authors": ["Zhixin Wang", "Tianyi Zhou", "Liming Liu", "Ao Li", "Jiarui Hu", "Dian Yang", "Jinlong Hou", "Siyuan Feng", "Yuan Cheng", "Yuan Qi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13833v1", "summary": "Reinforcement learning (RL) has become the pivotal post-training technique\nfor large language model. Effectively scaling reinforcement learning is now the\nkey to unlocking advanced reasoning capabilities and ensuring safe,\ngoal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually\nemploy a hybrid-controller architecture where a single-controller dispatches\nthe overall execution logic and manages overall data transfer and the\nmulti-controller executes distributed computation. For large-scale\nreinforcement learning, minor load imbalances can introduce significant\nbottlenecks, ultimately constraining the scalability of the system. To address\nthis limitation, we introduce DistFlow, a novel, fully distributed RL framework\ndesigned to break scaling barrier. We adopt a multi-controller paradigm that\ndispatches data transfer and execution tasks to all workers, which eliminates\nthe centralized node. This allows each worker to operate independently, leading\nto near-linear scalability up to thousands of GPUs and dramatic efficiency\ngains. Furthermore, our architecture decouples resource configuration from\nexecution logic, allowing each worker to have a unique execution flow, offering\nsignificant flexibility for rapid and cost-effective algorithmic\nexperimentation. Extensive experiments show that DistFlow achieves excellent\nlinear scalability and up to a 7x end-to-end throughput improvement over\nstate-of-the-art (SOTA) frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13833v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.05223", "title": "Multi-Objective Reinforcement Learning for Adaptable Personalized Autonomous Driving", "authors": ["Hendrik Surmann", "Jorge de Heuvel", "Maren Bennewitz"], "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.05223v2", "summary": "Human drivers exhibit individual preferences regarding driving style.\nAdapting autonomous vehicles to these preferences is essential for user trust\nand satisfaction. However, existing end-to-end driving approaches often rely on\npredefined driving styles or require continuous user feedback for adaptation,\nlimiting their ability to support dynamic, context-dependent preferences. We\npropose a novel approach using multi-objective reinforcement learning (MORL)\nwith preference-driven optimization for end-to-end autonomous driving that\nenables runtime adaptation to driving style preferences. Preferences are\nencoded as continuous weight vectors to modulate behavior along interpretable\nstyle objectives$\\unicode{x2013}$including efficiency, comfort, speed, and\naggressiveness$\\unicode{x2013}$without requiring policy retraining. Our\nsingle-policy agent integrates vision-based perception in complex mixed-traffic\nscenarios and is evaluated in diverse urban environments using the CARLA\nsimulator. Experimental results demonstrate that the agent dynamically adapts\nits driving behavior according to changing preferences while maintaining\nperformance in terms of collision avoidance and route completion.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.05223v2", "cate": "cs.RO", "date": "2025-05-08", "updated": "2025-07-18"}
{"id": "2507.13415", "title": "SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection", "authors": ["Peican Zhu", "Yubo Jing", "Le Cheng", "Bin Chen", "Xiaodong Cui", "Lianwei Wu", "Keke Tang"], "categories": ["cs.MM", "cs.AI"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      Accepted by SMC 2025", "url": "http://arxiv.org/abs/2507.13415v1", "summary": "Previous studies on multimodal fake news detection mainly focus on the\nalignment and integration of cross-modal features, as well as the application\nof text-image consistency. However, they overlook the semantic enhancement\neffects of large multimodal models and pay little attention to the emotional\nfeatures of news. In addition, people find that fake news is more inclined to\ncontain negative emotions than real ones. Therefore, we propose a novel\nSemantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake\nnews detection. We generate summarized captions for image semantic\nunderstanding and utilize the products of large multimodal models for semantic\nenhancement. Inspired by the perceived relationship between news authenticity\nand emotional tendencies, we propose an expert emotional reasoning module that\nsimulates real-life scenarios to optimize emotional features and infer the\nauthenticity of news. Extensive experiments on two real-world datasets\ndemonstrate the superiority of our SEER over state-of-the-art baselines.", "comment": "Accepted by SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.13415v1", "cate": "cs.MM", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13721", "title": "Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion", "authors": ["Zizhao Zhang", "Tianxiang Zhao", "Yu Sun", "Liping Sun", "Jichuan Kang"], "categories": ["cs.LG", "cs.DB"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13721v1", "summary": "To address the challenges posed by cascading reactions caused by component\nfailures in autonomous cargo ships (ACS) and the uncertainties in emergency\ndecision-making, this paper proposes a novel hybrid feature fusion framework\nfor constructing a graph-structured dataset of failure modes. By employing an\nimproved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency\nis significantly enhanced, achieving improvements of 7.1% and 3.4% compared to\nthe NSGA-II and CSA search algorithms, respectively. A hierarchical feature\nfusion framework is constructed, using Word2Vec encoding to encode\nsubsystem/component features, BERT-KPCA to process failure modes/reasons, and\nSentence-BERT to quantify the semantic association between failure impact and\nemergency decision-making. The dataset covers 12 systems, 1,262 failure modes,\nand 6,150 propagation paths. Validation results show that the GATE-GNN model\nachieves a classification accuracy of 0.735, comparable to existing benchmarks.\nAdditionally, a silhouette coefficient of 0.641 indicates that the features are\nhighly distinguishable. In the label prediction results, the Shore-based\nMeteorological Service System achieved an F1 score of 0.93, demonstrating high\nprediction accuracy. This paper not only provides a solid foundation for\nfailure analysis in autonomous cargo ships but also offers reliable support for\nfault diagnosis, risk assessment, and intelligent decision-making systems. The\nlink to the dataset is\nhttps://github.com/wojiufukele/Graph-Structured-about-CSA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13721v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.04295", "title": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop", "authors": ["Runcong Zhao", "Artem Bobrov", "Jiazheng Li", "Yulan He"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04295v3", "summary": "Effective feedback is essential for student learning but is time-intensive\nfor teachers. We present LearnLens, a modular, LLM-based system that generates\npersonalised, curriculum-aligned feedback in science education. LearnLens\ncomprises three components: (1) an error-aware assessment module that captures\nnuanced reasoning errors; (2) a curriculum-grounded generation module that uses\na structured, topic-linked memory chain rather than traditional\nsimilarity-based retrieval, improving relevance and reducing noise; and (3) an\neducator-in-the-loop interface for customisation and oversight. LearnLens\naddresses key challenges in existing systems, offering scalable, high-quality\nfeedback that empowers both teachers and students.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04295v3", "cate": "cs.CY", "date": "2025-07-06", "updated": "2025-07-18"}
{"id": "2507.13425", "title": "CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction", "authors": ["Sirui Wang", "Zhou Guan", "Bingxi Zhao", "Tongjia Gu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13425v1", "summary": "Accurate prediction of driving intention is key to enhancing the safety and\ninteractive efficiency of human-machine co-driving systems. It serves as a\ncornerstone for achieving high-level autonomous driving. However, current\napproaches remain inadequate for accurately modeling the complex\nspatio-temporal interdependencies and the unpredictable variability of human\ndriving behavior. To address these challenges, we propose CaSTFormer, a Causal\nSpatio-Temporal Transformer to explicitly model causal interactions between\ndriver behavior and environmental context for robust intention prediction.\nSpecifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)\nmechanism for precise temporal alignment of internal and external feature\nstreams, a Causal Pattern Extraction (CPE) module that systematically\neliminates spurious correlations to reveal authentic causal dependencies, and\nan innovative Feature Synthesis Network (FSN) that adaptively synthesizes these\npurified representations into coherent spatio-temporal inferences. We evaluate\nthe proposed CaSTFormer on the public Brain4Cars dataset, and it achieves\nstate-of-the-art performance. It effectively captures complex causal\nspatio-temporal dependencies and enhances both the accuracy and transparency of\ndriving intention prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13425v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2410.11569", "title": "Identification over Affine Poisson Channels: Application to Molecular Mixture Communication Systems", "authors": ["Mohammad Javad Salariseddigh", "Heinz Koeppl", "Holger Boche", "Vahid Jamali"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 Pages. A preliminary version of this research has been accepted for presentation at the IEEE Information Theory Workshop (ITW) 2025", "url": "http://arxiv.org/abs/2410.11569v3", "summary": "Identification capacity has been established as a relevant performance metric\nfor various goal-/task-oriented applications, where the receiver may be\ninterested in only a particular message that represents an event or a task. For\nexample, in olfactory molecular communications (MCs), odors or pheromones,\nwhich are often a mixture of various molecule types, may signal nearby danger,\nfood, or a mate. In this paper, we examine the identification capacity with\ndeterministic encoder for the discrete affine Poisson channel which can be used\nto model MC systems with molecule counting receivers. We establish lower and\nupper bounds on the identification capacity in terms of features of the\naffinity matrix between the released molecules and receptors at the receiver.\nAs a key finding, we show that even when the number of receptor types scales\nsub-linearly in the number of molecule types $N,$ the number of reliably\nidentifiable messages can grow super-exponentially with the rank of the\naffinity matrix, $T,$ i.e., $\\sim 2^{(T \\log T)R},$ where $R$ denotes the\ncoding rate. We further derive lower and upper bounds on $R,$ and show that the\nproposed capacity theorem includes several known results in the literature as\nits special cases.", "comment": "11 Pages. A preliminary version of this research has been accepted\n  for presentation at the IEEE Information Theory Workshop (ITW) 2025", "pdf_url": "http://arxiv.org/pdf/2410.11569v3", "cate": "cs.IT", "date": "2024-10-15", "updated": "2025-07-18"}
{"id": "2507.14080", "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants", "authors": ["Derek Leung", "Nickolai Zeldovich", "Frans Kaashoek"], "categories": ["cs.DC", "D.2.4; C.2.4"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      14 pages, 13 figures", "url": "http://arxiv.org/abs/2507.14080v1", "summary": "Ensuring liveness in a decentralized system, such as PBFT, is critical,\nbecause there may not be any single administrator that can restart the system\nif it encounters a liveness bug. At the same time, liveness is challenging to\nachieve because any single participant could be malicious, and yet the overall\nsystem must make forward progress. While verification is a promising approach\nfor ensuring the absence of bugs, no prior work has been able to verify\nliveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness\nof distributed systems where some participants might be malicious. Shipwright\nintroduces three techniques that enable formal reasoning about decentralized\nsettings with malicious participants, allow developers to decompose their\nsystem and proof in a modular fashion into sub-protocols and sub-proofs, and\nsupport sound reasoning about cryptographic signatures that may be embedded in\nmessages. We used Shipwright to implement and verify an initial prototype of\nagreement on a single log entry in PBFT (with a few limitations) and translate\nit to an executable implementation in Go. We experimentally demonstrate its\noperation and liveness both in the common case and in several failure\nscenarios.", "comment": "14 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.14080v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.13916", "title": "Robotic Monitoring of Colorimetric Leaf Sensors for Precision Agriculture", "authors": ["Malakhi Hopkins", "Alice Kate Li", "Shobhita Kramadhati", "Jackson Arnold", "Akhila Mallavarapu", "Chavez Lawrence", "Varun Murali", "Sanjeev J. Koppal", "Cherie R. Kagan", "Vijay Kumar"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Revised version. Initial version was accepted to the Novel Approaches for Precision Agriculture and Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "url": "http://arxiv.org/abs/2505.13916v2", "summary": "Common remote sensing modalities (RGB, multispectral, hyperspectral imaging\nor LiDAR) are often used to indirectly measure crop health and do not directly\ncapture plant stress indicators. Commercially available direct leaf sensors are\nbulky, powered electronics that are expensive and interfere with crop growth.\nIn contrast, low-cost, passive and bio-degradable leaf sensors offer an\nopportunity to advance real-time monitoring as they directly interface with the\ncrop surface while not interfering with crop growth. To this end, we co-design\na sensor-detector system, where the sensor is a passive colorimetric leaf\nsensor that directly measures crop health in a precision agriculture setting,\nand the detector autonomously obtains optical signals from these leaf sensors.\nThe detector comprises a low size weight and power (SWaP) mobile ground robot\nwith an onboard monocular RGB camera and object detector to localize each leaf\nsensor, as well as a hyperspectral camera with a motorized mirror and halogen\nlight to acquire hyperspectral images. The sensor's crop health-dependent\noptical signals can be extracted from the hyperspectral images. The\nproof-of-concept system is demonstrated in row-crop environments both indoors\nand outdoors where it is able to autonomously navigate, locate and obtain a\nhyperspectral image of all leaf sensors present, and acquire interpretable\nspectral resonance with 80 $\\%$ accuracy within a required retrieval distance\nfrom the sensor.", "comment": "Revised version. Initial version was accepted to the Novel Approaches\n  for Precision Agriculture and Forestry with Autonomous Robots IEEE ICRA\n  Workshop - 2025", "pdf_url": "http://arxiv.org/pdf/2505.13916v2", "cate": "cs.RO", "date": "2025-05-20", "updated": "2025-07-18"}
{"id": "2507.13428", "title": "\"PhyWorldBench\": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models", "authors": ["Jing Gu", "Xian Liu", "Yu Zeng", "Ashwin Nagarajan", "Fangrui Zhu", "Daniel Hong", "Yue Fan", "Qianqi Yan", "Kaiwen Zhou", "Ming-Yu Liu", "Xin Eric Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      31 pages, 21 figures", "url": "http://arxiv.org/abs/2507.13428v1", "summary": "Video generation models have achieved remarkable progress in creating\nhigh-quality, photorealistic content. However, their ability to accurately\nsimulate physical phenomena remains a critical and unresolved challenge. This\npaper presents PhyWorldBench, a comprehensive benchmark designed to evaluate\nvideo generation models based on their adherence to the laws of physics. The\nbenchmark covers multiple levels of physical phenomena, ranging from\nfundamental principles like object motion and energy conservation to more\ncomplex scenarios involving rigid body interactions and human or animal motion.\nAdditionally, we introduce a novel \"\"Anti-Physics\"\" category, where prompts\nintentionally violate real-world physics, enabling the assessment of whether\nmodels can follow such instructions while maintaining logical consistency.\nBesides large-scale human evaluation, we also design a simple yet effective\nmethod that could utilize current MLLM to evaluate the physics realism in a\nzero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation\nmodels, including five open-source and five proprietary models, with a detailed\ncomparison and analysis. we identify pivotal challenges models face in adhering\nto real-world physics. Through systematic testing of their outputs across 1,050\ncurated prompts-spanning fundamental, composite, and anti-physics scenarios-we\nidentify pivotal challenges these models face in adhering to real-world\nphysics. We then rigorously examine their performance on diverse physical\nphenomena with varying prompt types, deriving targeted recommendations for\ncrafting prompts that enhance fidelity to physical principles.", "comment": "31 pages, 21 figures", "pdf_url": "http://arxiv.org/pdf/2507.13428v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13727", "title": "Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics", "authors": ["René Heinrich", "Lukas Rauch", "Bernhard Sick", "Christoph Scholz"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.13727v1", "summary": "Adversarial training is a promising strategy for enhancing model robustness\nagainst adversarial attacks. However, its impact on generalization under\nsubstantial data distribution shifts in audio classification remains largely\nunexplored. To address this gap, this work investigates how different\nadversarial training strategies improve generalization performance and\nadversarial robustness in audio classification. The study focuses on two model\narchitectures: a conventional convolutional neural network (ConvNeXt) and an\ninherently interpretable prototype-based model (AudioProtoPNet). The approach\nis evaluated using a challenging bird sound classification benchmark. This\nbenchmark is characterized by pronounced distribution shifts between training\nand test data due to varying environmental conditions and recording methods, a\ncommon real-world challenge. The investigation explores two adversarial\ntraining strategies: one based on output-space attacks that maximize the\nclassification loss function, and another based on embedding-space attacks\ndesigned to maximize embedding dissimilarity. These attack types are also used\nfor robustness evaluation. Additionally, for AudioProtoPNet, the study assesses\nthe stability of its learned prototypes under targeted embedding-space attacks.\nResults show that adversarial training, particularly using output-space\nattacks, improves clean test data performance by an average of 10.5% relative\nand simultaneously strengthens the adversarial robustness of the models. These\nfindings, although derived from the bird sound domain, suggest that adversarial\ntraining holds potential to enhance robustness against both strong distribution\nshifts and adversarial attacks in challenging audio classification settings.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.13727v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13486", "title": "Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation", "authors": ["Debao Huang", "Rongjun Qin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 9 figures, this manuscript has been submitted to ISPRS Journal of Photogrammetry and Remote Sensing for consideration", "url": "http://arxiv.org/abs/2507.13486v1", "summary": "Uncertainty quantification of the photogrammetry process is essential for\nproviding per-point accuracy credentials of the point clouds. Unlike airborne\nLiDAR, which typically delivers consistent accuracy across various scenes, the\naccuracy of photogrammetric point clouds is highly scene-dependent, since it\nrelies on algorithm-generated measurements (i.e., stereo or multi-view stereo).\nGenerally, errors of the photogrammetric point clouds propagate through a\ntwo-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),\nfollowed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM\nstage has been well studied using the first-order statistics of the\nreprojection error function, that in the MVS stage remains largely unsolved and\nnon-standardized, primarily due to its non-differentiable and multi-modal\nnature (i.e., from pixel values to geometry). In this paper, we present an\nuncertainty quantification framework closing this gap by associating an error\ncovariance matrix per point accounting for this two-step photogrammetry\nprocess. Specifically, to estimate the uncertainty in the MVS stage, we propose\na novel, self-calibrating method by taking reliable n-view points (n>=6)\nper-view to regress the disparity uncertainty using highly relevant cues (such\nas matching cost values) from the MVS stage. Compared to existing approaches,\nour method uses self-contained, reliable 3D points extracted directly from the\nMVS process, with the benefit of being self-supervised and naturally adhering\nto error propagation path of the photogrammetry process, thereby providing a\nrobust and certifiable uncertainty quantification across diverse scenes. We\nevaluate the framework using a variety of publicly available airborne and UAV\nimagery datasets. Results demonstrate that our method outperforms existing\napproaches by achieving high bounding rates without overestimating uncertainty.", "comment": "16 pages, 9 figures, this manuscript has been submitted to ISPRS\n  Journal of Photogrammetry and Remote Sensing for consideration", "pdf_url": "http://arxiv.org/pdf/2507.13486v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2412.15366", "title": "Capacity and PAPR Analysis for MIMO Faster-than-Nyquist Signaling with High Acceleration Rate", "authors": ["Zichao Zhang", "Melda Yuksel", "Gokhan M. Guvensen", "Halim Yanikomeroglu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.15366v2", "summary": "Faster-than-Nyquist (FTN) signaling is a non-orthogonal transmission\ntechnique offering a promising solution for future generations of\ncommunications. This paper studies the capacity of FTN signaling in\nmultiple-input multiple-output (MIMO) channels for high acceleration factors.\nIn our previous study [1], we found the capacity for MIMO FTN channels if the\nacceleration factor is larger than a certain threshold, which depends on the\nbandwidth of the pulse shape used. In this paper, we extend the capacity\nanalysis to acceleration factors smaller than this mentioned threshold. In\naddition to capacity, we conduct peak-to-average power ratio (PAPR) analysis\nand simulation for MIMO FTN for varying acceleration factors for both Gaussian\nand QPSK symbol sets. Our analysis reveals important insights about\ntransmission power and received signal-to-noise ratio (SNR) variation in FTN.\nAs the acceleration factor approaches 0, if the transmission power is fixed,\nthe received SNR diminishes, or if the received SNR is fixed, PAPR at the\ntransmitter explodes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.15366v2", "cate": "cs.IT", "date": "2024-12-19", "updated": "2025-07-17"}
{"id": "2507.13470", "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication", "authors": ["Michael Elkin", "Chhaya Trehan"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13470v1", "summary": "Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$\nof $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the\n$S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of\nvertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms\nrun BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s\ntransitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le\n2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known\nbound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut\nconstructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a\ncentralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3}\n\\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix\nmultiplication exponent. Using current estimates on $\\omega(\\sigma)$, our\nexponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq\n\\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal\nconstant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel\nalgorithms for $S \\times V$ reachability on graphs admitting balanced recursive\nseparators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time\nand work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly\nimprove, extend, and generalize Cohen's result. First, our parallel algorithm\nfor graphs with small recursive separators has lower work complexity than\nCohen's in boraod paramater ranges. Second, we generalize our algorithm to\ngraphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized\nalgorithm that outperforms existing bounds for $S \\times V$ reachability on\nsuch graphs. We also do this for some other graph familes with small\nseparators. Finally, we extend these results to $(1 + \\epsilon)$-approximate\ndistance computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13470v1", "cate": "cs.DS", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2505.19688", "title": "GeoPF: Infusing Geometry into Potential Fields for Reactive Planning in Non-trivial Environments", "authors": ["Yuhe Gong", "Riddhiman Laha", "Luis Figueredo"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.19688v2", "summary": "Reactive intelligence remains one of the cornerstones of versatile robotics\noperating in cluttered, dynamic, and human-centred environments. Among reactive\napproaches, potential fields (PF) continue to be widely adopted due to their\nsimplicity and real-time applicability. However, existing PF methods typically\noversimplify environmental representations by relying on isotropic, point- or\nsphere-based obstacle approximations. In human-centred settings, this\nsimplification results in overly conservative paths, cumbersome tuning, and\ncomputational overhead -- even breaking real-time requirements. In response, we\npropose the Geometric Potential Field (GeoPF), a reactive motion-planning\nframework that explicitly infuses geometric primitives -- points, lines,\nplanes, cubes, and cylinders -- their structure and spatial relationship in\nmodulating the real-time repulsive response. Extensive quantitative analyses\nconsistently show GeoPF's higher success rates, reduced tuning complexity (a\nsingle parameter set across experiments), and substantially lower computational\ncosts (up to 2 orders of magnitude) compared to traditional PF methods.\nReal-world experiments further validate GeoPF reliability, robustness, and\npractical ease of deployment, as well as its scalability to whole-body\navoidance. GeoPF provides a fresh perspective on reactive planning problems\ndriving geometric-aware temporal motion generation, enabling flexible and\nlow-latency motion planning suitable for modern robotic applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.19688v2", "cate": "cs.RO", "date": "2025-05-26", "updated": "2025-07-18"}
{"id": "2507.13459", "title": "Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection", "authors": ["Vijay K. Dubey", "Collin E. Haese", "Osman Gültekin", "David Dalton", "Manuel K. Rausch", "Jan N. Fuhg"], "categories": ["cs.CE", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13459v1", "summary": "Surrogate models for the rapid inference of nonlinear boundary value problems\nin mechanics are helpful in a broad range of engineering applications. However,\neffective surrogate modeling of applications involving the contact of\ndeformable bodies, especially in the context of varying geometries, is still an\nopen issue. In particular, existing methods are confined to rigid body contact\nor, at best, contact between rigid and soft objects with well-defined contact\nplanes. Furthermore, they employ contact or collision detection filters that\nserve as a rapid test but use only the necessary and not sufficient conditions\nfor detection. In this work, we present a graph neural network architecture\nthat utilizes continuous collision detection and, for the first time,\nincorporates sufficient conditions designed for contact between soft deformable\nbodies. We test its performance on two benchmarks, including a problem in soft\ntissue mechanics of predicting the closed state of a bioprosthetic aortic\nvalve. We find a regularizing effect on adding additional contact terms to the\nloss function, leading to better generalization of the network. These benefits\nhold for simple contact at similar planes and element normal angles, and\ncomplex contact at differing planes and element normal angles. We also\ndemonstrate that the framework can handle varying reference geometries.\nHowever, such benefits come with high computational costs during training,\nresulting in a trade-off that may not always be favorable. We quantify the\ntraining cost and the resulting inference speedups on various hardware\narchitectures. Importantly, our graph neural network implementation results in\nup to a thousand-fold speedup for our benchmark problems at inference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13459v1", "cate": "cs.CE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13741", "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification", "authors": ["Shangyou Wang", "Zezhong Ding", "Xike Xie"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13741v1", "summary": "Graph Neural Networks (GNNs) have shown remarkable success in graph\nclassification tasks by capturing both structural and feature-based\nrepresentations. However, real-world graphs often exhibit two critical forms of\nimbalance: class imbalance and graph size imbalance. These imbalances can bias\nthe learning process and degrade model performance. Existing methods typically\naddress only one type of imbalance or incur high computational costs. In this\nwork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning\nframework that effectively mitigates both class and graph size imbalance.\nSamGoG constructs multiple GoGs through an efficient importance-based sampling\nmechanism and trains on them sequentially. This sampling mechanism incorporates\nthe learnable pairwise similarity and adaptive GoG node degree to enhance edge\nhomophily, thus improving downstream model quality. SamGoG can seamlessly\nintegrate with various downstream GNNs, enabling their efficient adaptation for\ngraph classification tasks. Extensive experiments on benchmark datasets\ndemonstrate that SamGoG achieves state-of-the-art performance with up to a\n15.66% accuracy improvement with 6.7$\\times$ training acceleration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13741v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13514", "title": "Sugar-Beet Stress Detection using Satellite Image Time Series", "authors": ["Bhumika Laxman Sadbhave", "Philipp Vaeth", "Denise Dejon", "Gunther Schorcht", "Magda Gregorová"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13514v1", "summary": "Satellite Image Time Series (SITS) data has proven effective for agricultural\ntasks due to its rich spectral and temporal nature. In this study, we tackle\nthe task of stress detection in sugar-beet fields using a fully unsupervised\napproach. We propose a 3D convolutional autoencoder model to extract meaningful\nfeatures from Sentinel-2 image sequences, combined with\nacquisition-date-specific temporal encodings to better capture the growth\ndynamics of sugar-beets. The learned representations are used in a downstream\nclustering task to separate stressed from healthy fields. The resulting stress\ndetection system can be directly applied to data from different years, offering\na practical and accessible tool for stress detection in sugar-beets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13514v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2504.00181", "title": "Beamforming Design for Continuous Aperture Array (CAPA)-Based MIMO Systems", "authors": ["Zhaolin Wang", "Chongjun Ouyang", "Yuanwei Liu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 10 figures", "url": "http://arxiv.org/abs/2504.00181v3", "summary": "An efficient beamforming design is proposed for continuous aperture array\n(CAPA)-based point-to-point multiple-input multiple-output (MIMO) systems. In\ncontrast to conventional spatially discrete array (SPDA)-MIMO systems, whose\noptimal beamforming can be obtained using singular-value decomposition,\nCAPA-MIMO systems require solving the eigendecomposition of a Hermitian kernel\noperator, which is computationally prohibitive. To address this challenge, an\nexplicit closed-form expression for the achievable rate of CAPA-MIMO systems is\nfirst derived as a function of the continuous transmit beamformer.\nSubsequently, an iterative weighted minimum mean-squared error (WMMSE)\nalgorithm is proposed, directly addressing the CAPA-MIMO beamforming\noptimization without discretization approximation. Closed-form updates for each\niteration of the WMMSE algorithm are derived via the calculus of variations\n(CoV) method. For low-complexity implementation, an equivalent matrix-based\niterative solution is introduced using Gauss-Legendre quadrature. Our numerical\nresults demonstrate that 1) CAPA-MIMO achieves substantial performance gain\nover the SPDA-MIMO, 2) the proposed WMMSE algorithm enhances performance while\nsignificantly reducing computational complexity compared to state-of-the-art\nFourier-based approaches, and 3) the proposed WMMSE algorithm enables practical\nrealization of parallel, non-interfering transmissions.", "comment": "16 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2504.00181v3", "cate": "cs.IT", "date": "2025-03-31", "updated": "2025-07-18"}
{"id": "2507.13895", "title": "Application Placement with Constraint Relaxation", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "categories": ["cs.LO", "cs.DC"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13895v1", "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13895v1", "cate": "cs.LO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.14180", "title": "Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy", "authors": ["Hong Huang", "Dongkuan Xu", "Hao Zhang", "Peng Gao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IROS 2025", "url": "http://arxiv.org/abs/2506.14180v2", "summary": "Egocentric pose estimation is a fundamental capability for multi-robot\ncollaborative perception in connected autonomy, such as connected autonomous\nvehicles. During multi-robot operations, a robot needs to know the relative\npose between itself and its teammates with respect to its own coordinates.\nHowever, different robots usually observe completely different views that\ncontains similar objects, which leads to wrong pose estimation. In addition, it\nis unrealistic to allow robots to share their raw observations to detect\noverlap due to the limited communication bandwidth constraint. In this paper,\nwe introduce a novel method for Non-Overlap-Aware Egocentric Pose Estimation\n(NOPE), which performs egocentric pose estimation in a multi-robot team while\nidentifying the non-overlap views and satifying the communication bandwidth\nconstraint. NOPE is built upon an unified hierarchical learning framework that\nintegrates two levels of robot learning: (1) high-level deep graph matching for\ncorrespondence identification, which allows to identify if two views are\noverlapping or not, (2) low-level position-aware cross-attention graph learning\nfor egocentric pose estimation. To evaluate NOPE, we conduct extensive\nexperiments in both high-fidelity simulation and real-world scenarios.\nExperimental results have demonstrated that NOPE enables the novel capability\nfor non-overlapping-aware egocentric pose estimation and achieves state-of-art\nperformance compared with the existing methods. Our project page at\nhttps://hongh0.github.io/NOPE/.", "comment": "IROS 2025", "pdf_url": "http://arxiv.org/pdf/2506.14180v2", "cate": "cs.RO", "date": "2025-06-17", "updated": "2025-07-18"}
{"id": "2507.13485", "title": "Neural Architecture Search with Mixed Bio-inspired Learning Rules", "authors": ["Imane Hamzaoui", "Riyadh Baghdadi"], "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      ECAI 2025", "url": "http://arxiv.org/abs/2507.13485v1", "summary": "Bio-inspired neural networks are attractive for their adversarial robustness,\nenergy frugality, and closer alignment with cortical physiology, yet they often\nlag behind back-propagation (BP) based models in accuracy and ability to scale.\nWe show that allowing the use of different bio-inspired learning rules in\ndifferent layers, discovered automatically by a tailored\nneural-architecture-search (NAS) procedure, bridges this gap. Starting from\nstandard NAS baselines, we enlarge the search space to include bio-inspired\nlearning rules and use NAS to find the best architecture and learning rule to\nuse in each layer. We show that neural networks that use different bio-inspired\nlearning rules for different layers have better accuracy than those that use a\nsingle rule across all the layers. The resulting NN that uses a mix of\nbio-inspired learning rules sets new records for bio-inspired models: 95.16% on\nCIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on\nImageNet. In some regimes, they even surpass comparable BP-based networks while\nretaining their robustness advantages. Our results suggest that layer-wise\ndiversity in learning rules allows better scalability and accuracy, and\nmotivates further research on mixing multiple bio-inspired learning rules in\nthe same network.", "comment": "ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.13485v1", "cate": "cs.NE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13742", "title": "Search-Optimized Quantization in Biomedical Ontology Alignment", "authors": ["Oussama Bouaggad", "Natalia Grabar"], "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13742v1", "summary": "In the fast-moving world of AI, as organizations and researchers develop more\nadvanced models, they face challenges due to their sheer size and computational\ndemands. Deploying such models on edge devices or in resource-constrained\nenvironments adds further challenges related to energy consumption, memory\nusage and latency. To address these challenges, emerging trends are shaping the\nfuture of efficient model optimization techniques. From this premise, by\nemploying supervised state-of-the-art transformer-based models, this research\nintroduces a systematic method for ontology alignment, grounded in cosine-based\nsemantic similarity between a biomedical layman vocabulary and the Unified\nMedical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to\nsearch for target optimizations among different Execution Providers (EPs) using\nthe ONNX Runtime backend, followed by an assembled process of dynamic\nquantization employing Intel Neural Compressor and IPEX (Intel Extension for\nPyTorch). Through our optimization process, we conduct extensive assessments on\nthe two tasks from the DEFT 2020 Evaluation Campaign, achieving a new\nstate-of-the-art in both. We retain performance metrics intact, while attaining\nan average inference speed-up of 20x and reducing memory usage by approximately\n70%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13742v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13527", "title": "SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM", "authors": ["Levi Harris", "Md Jayed Hossain", "Mufan Qiu", "Ruichen Zhang", "Pingchuan Ma", "Tianlong Chen", "Jiaqi Gu", "Seth Ariel Tongay", "Umberto Celano"], "categories": ["cs.CV", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13527v1", "summary": "The increasing use of two-dimensional (2D) materials in nanoelectronics\ndemands robust metrology techniques for electrical characterization, especially\nfor large-scale production. While atomic force microscopy (AFM) techniques like\nconductive AFM (C-AFM) offer high accuracy, they suffer from slow data\nacquisition speeds due to the raster scanning process. To address this, we\nintroduce SparseC-AFM, a deep learning model that rapidly and accurately\nreconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM\nscans. Our approach is robust across various scanning modes, substrates, and\nexperimental conditions. We report a comparison between (a) classic flow\nimplementation, where a high pixel density C-AFM image (e.g., 15 minutes to\ncollect) is manually parsed to extract relevant material parameters, and (b)\nour SparseC-AFM method, which achieves the same operation using data that\nrequires substantially less acquisition time (e.g., under 5 minutes).\nSparseC-AFM enables efficient extraction of critical material parameters in\nMoS$_2$, including film coverage, defect density, and identification of\ncrystalline island boundaries, edges, and cracks. We achieve over 11x reduction\nin acquisition time compared to manual extraction from a full-resolution C-AFM\nimage. Moreover, we demonstrate that our model-predicted samples exhibit\nremarkably similar electrical properties to full-resolution data gathered using\nclassic-flow scanning. This work represents a significant step toward\ntranslating AI-assisted 2D material characterization from laboratory research\nto industrial fabrication. Code and model weights are available at\ngithub.com/UNITES-Lab/sparse-cafm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13527v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2504.15204", "title": "Soft-Output from Covered Space Decoding of Product Codes", "authors": ["Tim Janz", "Simon Obermüller", "Andreas Zunker", "Stephan ten Brink"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures, 2 tables", "url": "http://arxiv.org/abs/2504.15204v3", "summary": "In this work, we propose a new soft-input soft-output decoder called\nsoft-output from covered space (SOCS) decoder. It estimates the a posteriori\nreliability based on the space explored by a list decoder, i.e., the set of\nvectors for which the list decoder knows whether they are codewords. This\napproach enables a more accurate calculation of the a posteriori reliability\nand results in gains of up to 0.25$\\,$dB for turbo product decoding with SOCS\ncompared to Chase-Pyndiah decoding.", "comment": "6 pages, 2 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2504.15204v3", "cate": "cs.IT", "date": "2025-04-21", "updated": "2025-07-18"}
{"id": "2507.14114", "title": "Weighted Matching in a Poly-Streaming Model", "authors": ["Ahammed Ullah", "S. M. Ferdous", "Alex Pothen"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      40 pages, ESA 2025", "url": "http://arxiv.org/abs/2507.14114v1", "summary": "We introduce the poly-streaming model, a generalization of streaming models\nof computation in which $k$ processors process $k$ data streams containing a\ntotal of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$\nspace, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a\nsequential streaming algorithm. Processors may communicate as needed.\nAlgorithms are assessed by the number of passes, per-item processing time,\ntotal runtime, space usage, communication cost, and solution quality.\n  We design a single-pass algorithm in this model for approximating the maximum\nweight matching (MWM) problem. Given $k$ edge streams and a parameter\n$\\varepsilon > 0$, the algorithm computes a\n$\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a\nshared-memory parallel setting: for any constant $\\varepsilon > 0$, it runs in\ntime $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of\nvertices and $L_{\\max}$ is the maximum stream length. It supports\n$O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot\nn\\right)$ space. We further generalize the design to hierarchical\narchitectures, in which $k$ processors are partitioned into $r$ groups, each\nwith its own shared local memory. The total intergroup communication is\n$\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance\nguarantees are preserved.\n  We evaluate the algorithm on a shared-memory system using graphs with\ntrillions of edges. It achieves substantial speedups as $k$ increases and\nproduces matchings with weights significantly exceeding the theoretical\nguarantee. On our largest test graph, it reduces runtime by nearly two orders\nof magnitude and memory usage by five orders of magnitude compared to an\noffline algorithm.", "comment": "40 pages, ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.14114v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.20487", "title": "A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots", "authors": ["Mingqi Yuan", "Tao Yu", "Wenqi Ge", "Xiuyong Yao", "Huijiang Wang", "Jiayu Chen", "Xin Jin", "Bo Li", "Hua Chen", "Wei Zhang", "Wenjun Zeng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      18 pages, 9 figures", "url": "http://arxiv.org/abs/2506.20487v3", "summary": "Humanoid robots are drawing significant attention as versatile platforms for\ncomplex motor control, human-robot interaction, and general-purpose physical\nintelligence. However, achieving efficient whole-body control (WBC) in\nhumanoids remains a fundamental challenge due to sophisticated dynamics,\nunderactuation, and diverse task requirements. While learning-based controllers\nhave shown promise for complex tasks, their reliance on labor-intensive and\ncostly retraining for new scenarios limits real-world applicability. To address\nthese limitations, behavior(al) foundation models (BFMs) have emerged as a new\nparadigm that leverages large-scale pre-training to learn reusable primitive\nskills and broad behavioral priors, enabling zero-shot or rapid adaptation to a\nwide range of downstream tasks. In this paper, we present a comprehensive\noverview of BFMs for humanoid WBC, tracing their development across diverse\npre-training pipelines. Furthermore, we discuss real-world applications,\ncurrent limitations, urgent challenges, and future opportunities, positioning\nBFMs as a key approach toward scalable and general-purpose humanoid\nintelligence. Finally, we provide a curated and long-term list of BFM papers\nand projects to facilitate more subsequent research, which is available at\nhttps://github.com/yuanmingqi/awesome-bfm-papers.", "comment": "18 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2506.20487v3", "cate": "cs.RO", "date": "2025-06-25", "updated": "2025-07-18"}
{"id": "2507.13551", "title": "Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder", "authors": ["Feng Chen", "Weizhe Xu", "Changye Li", "Serguei Pakhomov", "Alex Cohen", "Simran Bhola", "Sandy Yin", "Sunny X Tang", "Michael Mackinley", "Lena Palaniyappan", "Dror Ben-Zeev", "Trevor Cohen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13551v1", "summary": "Formal thought disorder (FTD), a hallmark of schizophrenia spectrum\ndisorders, manifests as incoherent speech and poses challenges for clinical\nassessment. Traditional clinical rating scales, though validated, are\nresource-intensive and lack scalability. Automated speech analysis with\nautomatic speech recognition (ASR) allows for objective quantification of\nlinguistic and temporal features of speech, offering scalable alternatives. The\nuse of utterance timestamps in ASR captures pause dynamics, which are thought\nto reflect the cognitive processes underlying speech production. However, the\nutility of integrating these ASR-derived features for assessing FTD severity\nrequires further evaluation. This study integrates pause features with semantic\ncoherence metrics across three datasets: naturalistic self-recorded diaries\n(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream\nnarratives (PsyCL, n = 43). We evaluated pause related features alongside\nestablished coherence measures, using support vector regression (SVR) to\npredict clinical FTD scores. Key findings demonstrate that pause features alone\nrobustly predict the severity of FTD. Integrating pause features with semantic\ncoherence metrics enhanced predictive performance compared to semantic-only\nmodels, with integration of independent models achieving correlations up to\n\\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best\n\\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance\ngains from semantic and pause features integration held consistently across all\ncontexts, though the nature of pause patterns was dataset-dependent. These\nfindings suggest that frameworks combining temporal and semantic analyses\nprovide a roadmap for refining the assessment of disorganized speech and\nadvance automated speech analysis in psychosis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13551v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13762", "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "authors": ["Yaowei Jin", "Junjie Wang", "Wenkai Xiang", "Duanhua Cao", "Dan Teng", "Zhehuan Fan", "Jiacheng Xiong", "Xia Sheng", "Chuanlong Zeng", "Mingyue Zheng", "Qian Shi"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13762v1", "summary": "Advances in deep learning for molecular generation show promise in\naccelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown\nimpressive performance across diverse chemical tasks, with their success often\nascribed to the paradigm of modeling in a low-variance parameter space.\nHowever, the Bayesian inference-based strategy imposes limitations on designing\nmore flexible distribution transformation pathways, making it challenging to\nadapt to diverse data distributions and varied task requirements. Furthermore,\nthe potential for simpler, more efficient parameter-space-based models is\nunexplored. To address this, we propose a novel Parameter Interpolation Flow\nmodel (named PIF) with detailed theoretical foundation, training, and inference\nprocedures. We then develop MolPIF for structure-based drug design,\ndemonstrating its superior performance across diverse metrics compared to\nbaselines. This work validates the effectiveness of parameter-space-based\ngenerative modeling paradigm for molecules and offers new perspectives for\nmodel design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13762v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13530", "title": "Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising", "authors": ["Lukas Baumgärtner", "Ronny Bergmann", "Roland Herzog", "Stephan Schmidt", "Manuel Weiß"], "categories": ["cs.CV", "math.DG", "math.OC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13530v1", "summary": "We propose a novel formulation for the second-order total generalized\nvariation (TGV) of the normal vector on an oriented, triangular mesh embedded\nin $\\mathbb{R}^3$. The normal vector is considered as a manifold-valued\nfunction, taking values on the unit sphere. Our formulation extends previous\ndiscrete TGV models for piecewise constant scalar data that utilize a\nRaviart-Thomas function space. To exctend this formulation to the manifold\nsetting, a tailor-made tangential Raviart-Thomas type finite element space is\nconstructed in this work. The new regularizer is compared to existing methods\nin mesh denoising experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13530v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2506.12193", "title": "Linear List Decodable Edit-Correcting Codes with Rate Approaching $1$", "authors": ["Yuting Li", "Ryan Gabrys", "Farzad Farnoud"], "categories": ["cs.IT", "math.IT", "G.2.1"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      12 pages, 0 figure", "url": "http://arxiv.org/abs/2506.12193v2", "summary": "Linear codes correcting one deletions have rate at most $1/2$. In this paper,\nwe construct linear list decodable codes correcting edits with rate approaching\n$1$ and reasonable list size. Our encoder and decoder run in polynomial time.", "comment": "12 pages, 0 figure", "pdf_url": "http://arxiv.org/pdf/2506.12193v2", "cate": "cs.IT", "date": "2025-06-13", "updated": "2025-07-18"}
{"id": "2405.12182", "title": "Nearest Neighbors GParareal: Improving Scalability of Gaussian Processes for Parallel-in-Time Solvers", "authors": ["Guglielmo Gattiglio", "Lyudmila Grigoryeva", "Massimiliano Tamborrino"], "categories": ["stat.CO", "cs.DC", "cs.NA", "math.NA", "65M55, 65M22, 65L05, 50G15, 65Y05"], "primary_category": "Subjects:       Computation (stat.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.12182v2", "summary": "With the advent of supercomputers, multi-processor environments and\nparallel-in-time (PinT) algorithms offer ways to solve initial value problems\nfor ordinary and partial differential equations (ODEs and PDEs) over long time\nintervals, a task often unfeasible with sequential solvers within realistic\ntime frames. A recent approach, GParareal, combines Gaussian Processes with\ntraditional PinT methodology (Parareal) to achieve faster parallel speed-ups.\nThe method is known to outperform Parareal for low-dimensional ODEs and a\nlimited number of computer cores. Here, we present Nearest Neighbors GParareal\n(nnGParareal), a novel data-enriched PinT integration algorithm. nnGParareal\nbuilds upon GParareal by improving its scalability properties for\nhigher-dimensional systems and increased processor count. Through data\nreduction, the model complexity is reduced from cubic to log-linear in the\nsample size, yielding a fast and automated procedure to integrate initial value\nproblems over long time intervals. First, we provide both an upper bound for\nthe error and theoretical details on the speed-up benefits. Then, we\nempirically illustrate the superior performance of nnGParareal, compared to\nGParareal and Parareal, on nine different systems with unique features (e.g.,\nstiff, chaotic, high-dimensional, or challenging-to-learn systems).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.12182v2", "cate": "stat.CO", "date": "2024-05-20", "updated": "2025-07-17"}
{"id": "2502.02592", "title": "A Paradigm Shift to Assembly-like Finite Element Model Updating", "authors": ["Gabriele Dessena", "Alessandro Pontillo", "Dmitry I. Ignatyev", "James F. Whidborne", "Luca Zanotti Fragonara"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.02592v2", "summary": "In general, there is a mismatch between a finite element model of a structure\nand its real behaviour. In aeronautics, this mismatch must be small because\nfinite element models are a fundamental part of the development of an aircraft\nand of increasing importance with the trend to more flexible wings in modern\ndesigns. Finite element model updating can be computationally expensive for\ncomplex structures and surrogate models can be employed to reduce the\ncomputational burden. A novel approach for finite element model updating,\nnamely assembly-like, is proposed and validated using real experimental data.\nThe assembly-like model updating framework implies that the model is updated as\nparts are assembled. Benchmarking against the classical global, or one-shot,\napproach demonstrates that the proposed method is more computationally\nefficient since it takes 20% fewer iterations to obtain convergence, also using\nfewer parameters for the model evaluations. Despite the increase in\ncomputational performance, the new approach retains the fidelity of the global\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.02592v2", "cate": "cs.CE", "date": "2024-12-17", "updated": "2025-07-18"}
{"id": "2507.12440", "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "authors": ["Ruihan Yang", "Qinxi Yu", "Yecheng Wu", "Rui Yan", "Borui Li", "An-Chieh Cheng", "Xueyan Zou", "Yunhao Fang", "Xuxin Cheng", "Ri-Zhao Qiu", "Hongxu Yin", "Sifei Liu", "Song Han", "Yao Lu", "Xiaolong Wang"], "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      More videos can be found on our website: this https URL", "url": "http://arxiv.org/abs/2507.12440v3", "summary": "Real robot data collection for imitation learning has led to significant\nadvancements in robotic manipulation. However, the requirement for robot\nhardware in the process fundamentally constrains the scale of the data. In this\npaper, we explore training Vision-Language-Action (VLA) models using egocentric\nhuman videos. The benefit of using human videos is not only for their scale but\nmore importantly for the richness of scenes and tasks. With a VLA trained on\nhuman video that predicts human wrist and hand actions, we can perform Inverse\nKinematics and retargeting to convert the human actions to robot actions. We\nfine-tune the model using a few robot manipulation demonstrations to obtain the\nrobot policy, namely EgoVLA. We propose a simulation benchmark called Ego\nHumanoid Manipulation Benchmark, where we design diverse bimanual manipulation\ntasks with demonstrations. We fine-tune and evaluate EgoVLA with Ego Humanoid\nManipulation Benchmark and show significant improvements over baselines and\nablate the importance of human data. Videos can be found on our website:\nhttps://rchalyang.github.io/EgoVLA", "comment": "More videos can be found on our website:\n  https://rchalyang.github.io/EgoVLA", "pdf_url": "http://arxiv.org/pdf/2507.12440v3", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.13604", "title": "BreastSegNet: Multi-label Segmentation of Breast MRI", "authors": ["Qihang Li", "Jichen Yang", "Yaqian Chen", "Yuwen Chen", "Hanxue Gu", "Lars J. Grimm", "Maciej A. Mazurowski"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13604v1", "summary": "Breast MRI provides high-resolution imaging critical for breast cancer\nscreening and preoperative staging. However, existing segmentation methods for\nbreast MRI remain limited in scope, often focusing on only a few anatomical\nstructures, such as fibroglandular tissue or tumors, and do not cover the full\nrange of tissues seen in scans. This narrows their utility for quantitative\nanalysis. In this study, we present BreastSegNet, a multi-label segmentation\nalgorithm for breast MRI that covers nine anatomical labels: fibroglandular\ntissue (FGT), vessel, muscle, bone, lesion, lymph node, heart, liver, and\nimplant. We manually annotated a large set of 1123 MRI slices capturing these\nstructures with detailed review and correction from an expert radiologist.\nAdditionally, we benchmark nine segmentation models, including U-Net, SwinUNet,\nUNet++, SAM, MedSAM, and nnU-Net with multiple ResNet-based encoders. Among\nthem, nnU-Net ResEncM achieves the highest average Dice scores of 0.694 across\nall labels. It performs especially well on heart, liver, muscle, FGT, and bone,\nwith Dice scores exceeding 0.73, and approaching 0.90 for heart and liver. All\nmodel code and weights are publicly available, and we plan to release the data\nat a later date.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13604v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13765", "title": "Dual-Center Graph Clustering with Neighbor Distribution", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Li Jin", "Liqiang Nie"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ECAI-2025", "url": "http://arxiv.org/abs/2507.13765v1", "summary": "Graph clustering is crucial for unraveling intricate data structures, yet it\npresents significant challenges due to its unsupervised nature. Recently,\ngoal-directed clustering techniques have yielded impressive results, with\ncontrastive learning methods leveraging pseudo-label garnering considerable\nattention. Nonetheless, pseudo-label as a supervision signal is unreliable and\nexisting goal-directed approaches utilize only features to construct a\nsingle-target distribution for single-center optimization, which lead to\nincomplete and less dependable guidance. In our work, we propose a novel\nDual-Center Graph Clustering (DCGC) approach based on neighbor distribution\nproperties, which includes representation learning with neighbor distribution\nand dual-center optimization. Specifically, we utilize neighbor distribution as\na supervision signal to mine hard negative samples in contrastive learning,\nwhich is reliable and enhances the effectiveness of representation learning.\nFurthermore, neighbor distribution center is introduced alongside feature\ncenter to jointly construct a dual-target distribution for dual-center\noptimization. Extensive experiments and analysis demonstrate superior\nperformance and effectiveness of our proposed method.", "comment": "ECAI-2025", "pdf_url": "http://arxiv.org/pdf/2507.13765v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13546", "title": "$\\nabla$NABLA: Neighborhood Adaptive Block-Level Attention", "authors": ["Dmitrii Mikhailov", "Aleksey Letunovskiy", "Maria Kovaleva", "Vladimir Arkhipkin", "Vladimir Korviakov", "Vladimir Polovnikov", "Viacheslav Vasilev", "Evelina Sidorova", "Denis Dimitrov"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13546v1", "summary": "Recent progress in transformer-based architectures has demonstrated\nremarkable success in video generation tasks. However, the quadratic complexity\nof full attention mechanisms remains a critical bottleneck, particularly for\nhigh-resolution and long-duration video sequences. In this paper, we propose\nNABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that\ndynamically adapts to sparsity patterns in video diffusion transformers (DiTs).\nBy leveraging block-wise attention with adaptive sparsity-driven threshold,\nNABLA reduces computational overhead while preserving generative quality. Our\nmethod does not require custom low-level operator design and can be seamlessly\nintegrated with PyTorch's Flex Attention operator. Experiments demonstrate that\nNABLA achieves up to 2.7x faster training and inference compared to baseline\nalmost without compromising quantitative metrics (CLIP score, VBench score,\nhuman evaluation score) and visual quality drop. The code and model weights are\navailable here: https://github.com/gen-ai-team/Wan2.1-NABLA", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13546v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.04201", "title": "An Efficient Max-Min Fair Resource Optimization Algorithm for Rate-Splitting Multiple Access", "authors": ["Facheng Luo", "Yijie Mao"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 10 figures", "url": "http://arxiv.org/abs/2507.04201v2", "summary": "The max-min fairness (MMF) problem in rate-splitting multiple access (RSMA)\nis known to be challenging due to its non-convex and non-smooth nature, as well\nas the coupled beamforming and common rate variables. Conventional algorithms\nto address this problem often incur high computational complexity or degraded\nMMF rate performance. To address these challenges, in this work, we propose a\nnovel optimization algorithm named extragradient-fractional programming (EG-FP)\nto address the MMF problem of downlink RSMA. The proposed algorithm first\nleverages FP to transform the original problem into a block-wise convex\nproblem. For the subproblem of precoding block, we show that its Lagrangian\ndual is equivalent to a variational inequality problem, which is then solved\nusing an extragradient-based algorithm. Additionally, we discover the optimal\nbeamforming structure of the problem and based on which, we introduce a\nlow-dimensional EG-FP algorithm with computational complexity independent of\nthe number of transmit antennas. This feature is especially beneficial in\nscenarios with a large number of transmit antennas. The proposed algorithms are\nthen extended to handle imperfect channel state information at the transmitter\n(CSIT). Numerical results demonstrate that the MMF rate achieved by our\nproposed algorithms closely matches that of the conventional successive convex\napproximation (SCA) algorithm and significantly outperforms other baseline\nschemes. Remarkably, the average CPU time of the proposed algorithms is less\nthan 10\\% of the runtime required by the SCA algorithm, showing the efficiency\nand scalability of the proposed algorithms.", "comment": "16 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.04201v2", "cate": "cs.IT", "date": "2025-07-06", "updated": "2025-07-18"}
{"id": "2409.18749", "title": "TensorSocket: Shared Data Loading for Deep Learning Training", "authors": ["Ties Robroek", "Neil Kim Nielsen", "Pınar Tözün"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.18749v2", "summary": "Training deep learning models is a repetitive and resource-intensive process.\nData scientists often train several models before landing on a set of\nparameters (e.g., hyper-parameter tuning) and model architecture (e.g., neural\narchitecture search), among other things that yield the highest accuracy. The\ncomputational efficiency of these training tasks depends highly on how well the\ntraining data is supplied to the training process. The repetitive nature of\nthese tasks results in the same data processing pipelines running over and\nover, exacerbating the need for and costs of computational resources. In this\npaper, we present TensorSocket to reduce the computational needs of deep\nlearning training by enabling simultaneous training processes to share the same\ndata loader. TensorSocket mitigates CPU-side bottlenecks in cases where the\ncollocated training workloads have high throughput on GPU, but are held back by\nlower data-loading throughput on CPU. TensorSocket achieves this by reducing\nredundant computations and data duplication across collocated training\nprocesses and leveraging modern GPU-GPU interconnects. While doing so,\nTensorSocket is able to train and balance differently-sized models and serve\nmultiple batch sizes simultaneously and is hardware- and pipeline-agnostic in\nnature. Our evaluation shows that TensorSocket enables scenarios that are\ninfeasible without data sharing, increases training throughput by up to 100%,\nand when utilizing cloud instances, achieves cost savings of 50% by reducing\nthe hardware resource needs on the CPU side. Furthermore, TensorSocket\noutperforms the state-of-the-art solutions for shared data loading such as\nCoorDL and Joader; it is easier to deploy and maintain and either achieves\nhigher or matches their throughput while requiring fewer CPU resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.18749v2", "cate": "cs.LG", "date": "2024-09-27", "updated": "2025-07-18"}
{"id": "2507.11640", "title": "Quantifying data needs in surrogate modeling for flow fields in two-dimensional stirred tanks with physics-informed neural networks", "authors": ["Veronika Trávníková", "Eric von Lieres", "Marek Behr"], "categories": ["cs.CE", "76-10, 68T07 (Primary) 76D05, 35Q68 (Secondary)"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      24 pages, 18 figures", "url": "http://arxiv.org/abs/2507.11640v2", "summary": "Stirred tanks are vital in chemical and biotechnological processes,\nparticularly as bioreactors. Although computational fluid dynamics (CFD) is\nwidely used to model the flow in stirred tanks, its high computational\ncost$-$especially in multi-query scenarios for process design and\noptimization$-$drives the need for efficient data-driven surrogate models.\nHowever, acquiring sufficiently large datasets can be costly. Physics-informed\nneural networks (PINNs) offer a promising solution to reduce data requirements\nwhile maintaining accuracy by embedding underlying physics into neural network\n(NN) training. This study quantifies the data requirements of vanilla PINNs for\ndeveloping surrogate models of a flow field in a 2D stirred tank. We compare\nthese requirements with classical supervised neural networks and\nboundary-informed neural networks (BINNs). Our findings demonstrate that\nsurrogate models can achieve prediction errors around 3% across Reynolds\nnumbers from 50 to 5000 using as few as six datapoints. Moreover, employing an\napproximation of the velocity profile in place of real data labels leads to\nprediction errors of around 2.5%. These results indicate that even with limited\nor approximate datasets, PINNs can be effectively trained to deliver high\naccuracy comparable to high-fidelity data.", "comment": "24 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.11640v2", "cate": "cs.CE", "date": "2025-07-15", "updated": "2025-07-18"}
{"id": "2507.13517", "title": "The Stated Protocol: A Decentralized Framework for Digital Diplomacy", "authors": ["Christopher J. P. Rieckmann"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13517v1", "summary": "International coordination faces significant friction due to reliance on\nperiodic summits, bilateral consultations, and fragmented communication\nchannels that impede rapid collective responses to emerging global challenges\nwhile limiting transparency to constituents. We present the Stated Protocol, a\ndecentralized framework that enables organizations to coordinate through\nstandardized text statements published on their website domains. While\napplicable to all organizations, this work focuses primarily on the application\nin international relations, where the protocol enables rapid consensus\ndiscovery and collective decision-making without relying on centralized social\nmedia platforms. We explore specific applications: (1) faster treaty\nnegotiation through incremental micro-agreements that can be signed digitally\nwithin hours rather than months, (2) continuous and transparent operation of\ninternational institutions through asynchronous decision-making, (3)\ncoordinated signaling from local governments to national authorities through\nsimultaneous statement publication, and (4) coalition formation among\nnon-governmental organizations through transparent position aggregation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13517v1", "cate": "cs.CY", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2411.07799", "title": "Horticultural Temporal Fruit Monitoring via 3D Instance Segmentation and Re-Identification using Colored Point Clouds", "authors": ["Daniel Fusaro", "Federico Magistri", "Jens Behley", "Alberto Pretto", "Cyrill Stachniss"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to Computers and Electronics in Agriculture", "url": "http://arxiv.org/abs/2411.07799v2", "summary": "Accurate and consistent fruit monitoring over time is a key step toward\nautomated agricultural production systems. However, this task is inherently\ndifficult due to variations in fruit size, shape, occlusion, orientation, and\nthe dynamic nature of orchards where fruits may appear or disappear between\nobservations. In this article, we propose a novel method for fruit instance\nsegmentation and re-identification on 3D terrestrial point clouds collected\nover time. Our approach directly operates on dense colored point clouds,\ncapturing fine-grained 3D spatial detail. We segment individual fruits using a\nlearning-based instance segmentation method applied directly to the point\ncloud. For each segmented fruit, we extract a compact and discriminative\ndescriptor using a 3D sparse convolutional neural network. To track fruits\nacross different times, we introduce an attention-based matching network that\nassociates fruits with their counterparts from previous sessions. Matching is\nperformed using a probabilistic assignment scheme, selecting the most likely\nassociations across time. We evaluate our approach on real-world datasets of\nstrawberries and apples, demonstrating that it outperforms existing methods in\nboth instance segmentation and temporal re-identification, enabling robust and\nprecise fruit monitoring across complex and dynamic orchard environments.", "comment": "Submitted to Computers and Electronics in Agriculture", "pdf_url": "http://arxiv.org/pdf/2411.07799v2", "cate": "cs.CV", "date": "2024-11-12", "updated": "2025-07-18"}
{"id": "2507.13614", "title": "Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models", "authors": ["Sergio E. Zanotto", "Segun Aroyehun"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2412.03025", "url": "http://arxiv.org/abs/2507.13614v1", "summary": "The rapid advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural language, making texts generated by\nLLMs increasingly indistinguishable from human-written texts. While recent\nresearch has primarily focused on using LLMs to classify text as either\nhuman-written and machine-generated texts, our study focus on characterizing\nthese texts using a set of linguistic features across different linguistic\nlevels such as morphology, syntax, and semantics. We select a dataset of\nhuman-written and machine-generated texts spanning 8 domains and produced by 11\ndifferent LLMs. We calculate different linguistic features such as dependency\nlength and emotionality and we use them for characterizing human-written and\nmachine-generated texts along with different sampling strategies, repetition\ncontrols and model release date. Our statistical analysis reveals that\nhuman-written texts tend to exhibit simpler syntactic structures and more\ndiverse semantic content. Furthermore, we calculate the variability of our set\nof features across models and domains. Both human and machine texts show\nstylistic diversity across domains, with humans displaying greater variation in\nour features. Finally, we apply style embeddings to further test variability\namong human-written and machine-generated texts. Notably, newer models output\ntext that is similarly variable, pointing to an homogenization of\nmachine-generated texts.", "comment": "arXiv admin note: text overlap with arXiv:2412.03025", "pdf_url": "http://arxiv.org/pdf/2507.13614v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13805", "title": "On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach", "authors": ["Tim Rensmeyer", "Denis Kramer", "Oliver Niggemann"], "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13805v1", "summary": "Due to the computational complexity of evaluating interatomic forces from\nfirst principles, the creation of interatomic machine learning force fields has\nbecome a highly active field of research. However, the generation of training\ndatasets of sufficient size and sample diversity itself comes with a\ncomputational burden that can make this approach impractical for modeling rare\nevents or systems with a large configuration space. Fine-tuning foundation\nmodels that have been pre-trained on large-scale material or molecular\ndatabases offers a promising opportunity to reduce the amount of training data\nnecessary to reach a desired level of accuracy. However, even if this approach\nrequires less training data overall, creating a suitable training dataset can\nstill be a very challenging problem, especially for systems with rare events\nand for end-users who don't have an extensive background in machine learning.\nIn on-the-fly learning, the creation of a training dataset can be largely\nautomated by using model uncertainty during the simulation to decide if the\nmodel is accurate enough or if a structure should be recalculated with\nclassical methods and used to update the model. A key challenge for applying\nthis form of active learning to the fine-tuning of foundation models is how to\nassess the uncertainty of those models during the fine-tuning process, even\nthough most foundation models lack any form of uncertainty quantification. In\nthis paper, we overcome this challenge by introducing a fine-tuning approach\nbased on Bayesian neural network methods and a subsequent on-the-fly workflow\nthat automatically fine-tunes the model while maintaining a pre-specified\naccuracy and can detect rare events such as transition states and sample them\nat an increased rate relative to their occurrence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13805v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13568", "title": "LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning", "authors": ["Kaihong Wang", "Donghyun Kim", "Margrit Betke"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13568v1", "summary": "Continual learning for vision-language models has achieved remarkable\nperformance through synthetic replay, where samples are generated using Stable\nDiffusion to regularize during finetuning and retain knowledge. However,\nreal-world downstream applications often exhibit domain-specific nuances and\nfine-grained semantics not captured by generators, causing synthetic-replay\nmethods to produce misaligned samples that misguide finetuning and undermine\nretention of prior knowledge. In this work, we propose a LoRA-enhanced\nsynthetic-replay framework that injects task-specific low-rank adapters into a\nfrozen Stable Diffusion model, efficiently capturing each new task's unique\nvisual and semantic patterns. Specifically, we introduce a two-stage,\nconfidence-based sample selection: we first rank real task data by\npost-finetuning VLM confidence to focus LoRA finetuning on the most\nrepresentative examples, then generate synthetic samples and again select them\nby confidence for distillation. Our approach integrates seamlessly with\nexisting replay pipelines-simply swap in the adapted generator to boost replay\nfidelity. Extensive experiments on the Multi-domain Task Incremental Learning\n(MTIL) benchmark show that our method outperforms previous synthetic-replay\ntechniques, achieving an optimal balance among plasticity, stability, and\nzero-shot capability. These results demonstrate the effectiveness of generator\nadaptation via LoRA for robust continual learning in VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13568v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2406.15817", "title": "Computable one-way functions on the reals", "authors": ["George Barmpalias", "Xiaoyan Zhang"], "categories": ["cs.CC", "cs.IT", "math.IT", "math.LO"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.15817v3", "summary": "A major open problem in computational complexity is the existence of a\none-way function, namely a function from strings to strings which is\ncomputationally easy to compute but hard to invert. Levin (2023) formulated the\nnotion of one-way functions from reals (infinite bit-sequences) to reals in\nterms of computability, and asked whether partial computable one-way functions\nexist. We give a strong positive answer using the hardness of the halting\nproblem and exhibiting a total computable one-way function.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.15817v3", "cate": "cs.CC", "date": "2024-06-22", "updated": "2025-07-17"}
{"id": "2507.13758", "title": "The Emperor's New Chain-of-Thought: Probing Reasoning Theater Bias in Large Reasoning Models", "authors": ["Qian Wang", "Yubo Fan", "Zhenheng Tang", "Nuo Chen", "Wenxuan Wang", "Bingsheng He"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      WIP", "url": "http://arxiv.org/abs/2507.13758v1", "summary": "Large Reasoning Models (LRMs) like DeepSeek-R1 and o1 are increasingly used\nas automated evaluators, raising critical questions about their vulnerability\nto the aesthetics of reasoning in LLM-as-a-judge settings. We introduce\nTHEATER, a comprehensive benchmark to systematically evaluate this\nvulnerability-termed Reasoning Theater Bias (RTB)-by comparing LLMs and LRMs\nacross subjective preference and objective factual datasets. Through\ninvestigation of six bias types including Simple Cues and Fake\nChain-of-Thought, we uncover three key findings: (1) in a critical paradox,\nreasoning-specialized LRMs are consistently more susceptible to RTB than\ngeneral-purpose LLMs, particularly in subjective tasks; (2) this creates a\ntask-dependent trade-off, where LRMs show more robustness on factual tasks but\nless on subjective ones; and (3) we identify 'shallow reasoning'-plausible but\nflawed arguments-as the most potent form of RTB. To address this, we design and\nevaluate two prompting strategies: a targeted system prompt that improves\naccuracy by up to 12% on factual tasks but only 1-3% on subjective tasks, and a\nself-reflection mechanism that shows similarly limited effectiveness in the\nmore vulnerable subjective domains. Our work reveals that RTB is a deep-seated\nchallenge for LRM-based evaluation and provides a systematic framework for\ndeveloping more genuinely robust and trustworthy LRMs.", "comment": "WIP", "pdf_url": "http://arxiv.org/pdf/2507.13758v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.02145", "title": "From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios", "authors": ["Yuan Gao", "Mattia Piccinini", "Korbinian Moller", "Amr Alanwar", "Johannes Betz"], "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Final Version and Paper Accepted at IEEE ITSC 2025", "url": "http://arxiv.org/abs/2502.02145v4", "summary": "Ensuring the safety of autonomous vehicles requires virtual scenario-based\ntesting, which depends on the robust evaluation and generation of\nsafety-critical scenarios. So far, researchers have used scenario-based testing\nframeworks that rely heavily on handcrafted scenarios as safety metrics. To\nreduce the effort of human interpretation and overcome the limited scalability\nof these approaches, we combine Large Language Models (LLMs) with structured\nscenario parsing and prompt engineering to automatically evaluate and generate\nsafety-critical driving scenarios. We introduce Cartesian and Ego-centric\nprompt strategies for scenario evaluation, and an adversarial generation module\nthat modifies trajectories of risk-inducing vehicles (ego-attackers) to create\ncritical scenarios. We validate our approach using a 2D simulation framework\nand multiple pre-trained LLMs. The results show that the evaluation module\neffectively detects collision scenarios and infers scenario safety. Meanwhile,\nthe new generation module identifies high-risk agents and synthesizes\nrealistic, safety-critical scenarios. We conclude that an LLM equipped with\ndomain-informed prompting techniques can effectively evaluate and generate\nsafety-critical driving scenarios, reducing dependence on handcrafted metrics.\nWe release our open-source code and scenarios at:\nhttps://github.com/TUM-AVS/From-Words-to-Collisions.", "comment": "Final Version and Paper Accepted at IEEE ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2502.02145v4", "cate": "cs.AI", "date": "2025-02-04", "updated": "2025-07-18"}
{"id": "2507.13618", "title": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters", "authors": ["Shanbo Cheng", "Yu Bao", "Qian Cao", "Luyang Huang", "Liyan Kang", "Zhicheng Liu", "Yu Lu", "Wenhao Zhu", "Zhichao Huang", "Tao Li", "Sitong Liu", "Ningxin Peng", "Shuaijie She", "Lu Xu", "Nuo Xu", "Sen Yang", "Runsheng Yu", "Yiming Yu", "Liehao Zou", "Hang Li", "Lu Lu", "Yuxuan Wang", "Yonghui Wu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13618v1", "summary": "Multilingual translation stands as a challenging task for large language\nmodels (LLMs) to handle intricate language patterns and stilted translations\nthat arise in automated translations. In this paper, we introduce Seed-X, a\nfamily of open-source LLMs comprising instruct and reasoning models, pushing\nthe limits of translation capability with 7B parameter size. The base model is\npre-trained on a diverse, high-quality dataset encompassing both monolingual\nand bilingual content across 28 languages, harnessing the full potential of\nmultilingual data. The instruct model is then finetuned to translate by\nChain-of-Thought (CoT) reasoning and further enhanced through reinforcement\nlearning (RL) to achieve better generalization across diverse language pairs.\nSeed-X achieves performance comparable to leading closed-source models,\nincluding Gemini-2.5 and GPT-4o, across 28 languages, and significantly\noutperforms larger open-source models in both automatic metrics and human\nevaluations. We share the best practices through our optimization process, and\nmake the parameter public available for advancing translation research and\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13618v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13912", "title": "Self-supervised learning on gene expression data", "authors": ["Kevin Dradjat", "Massinissa Hamidi", "Pierre Bartet", "Blaise Hanczar"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13912v1", "summary": "Predicting phenotypes from gene expression data is a crucial task in\nbiomedical research, enabling insights into disease mechanisms, drug responses,\nand personalized medicine. Traditional machine learning and deep learning rely\non supervised learning, which requires large quantities of labeled data that\nare costly and time-consuming to obtain in the case of gene expression data.\nSelf-supervised learning has recently emerged as a promising approach to\novercome these limitations by extracting information directly from the\nstructure of unlabeled data. In this study, we investigate the application of\nstate-of-the-art self-supervised learning methods to bulk gene expression data\nfor phenotype prediction. We selected three self-supervised methods, based on\ndifferent approaches, to assess their ability to exploit the inherent structure\nof the data and to generate qualitative representations which can be used for\ndownstream predictive tasks. By using several publicly available gene\nexpression datasets, we demonstrate how the selected methods can effectively\ncapture complex information and improve phenotype prediction accuracy. The\nresults obtained show that self-supervised learning methods can outperform\ntraditional supervised models besides offering significant advantage by\nreducing the dependency on annotated data. We provide a comprehensive analysis\nof the performance of each method by highlighting their strengths and\nlimitations. We also provide recommendations for using these methods depending\non the case under study. Finally, we outline future research directions to\nenhance the application of self-supervised learning in the field of gene\nexpression data analysis. This study is the first work that deals with bulk\nRNA-Seq data and self-supervised learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13912v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13595", "title": "NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision", "authors": ["Tengkai Wang", "Weihao Li", "Ruikai Cui", "Shi Qiu", "Nick Barnes"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 4 figures", "url": "http://arxiv.org/abs/2507.13595v1", "summary": "Reconstructing accurate implicit surface representations from point clouds\nremains a challenging task, particularly when data is captured using\nlow-quality scanning devices. These point clouds often contain substantial\nnoise, leading to inaccurate surface reconstructions. Inspired by the\nNoise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel\nmethod designed to extend this concept to 3D neural fields. Our approach\nenables learning clean neural SDFs directly from noisy point clouds through\nnoisy supervision by minimizing the MSE loss between noisy SDF representations,\nallowing the network to implicitly denoise and refine surface estimations. We\nevaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the\nShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that\nour framework significantly improves surface reconstruction quality from noisy\ninputs.", "comment": "14 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.13595v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2409.00839", "title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving", "authors": ["Haobo Yang", "Shiyan Zhang", "Zhuoyi Yang", "Xinyu Zhang", "Jilong Guo", "Zongyou Yang", "Jun Li"], "categories": ["cs.CV", "cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.00839v2", "summary": "With the increasing complexity of the traffic environment, the significance\nof safety perception in intelligent driving is intensifying. Traditional\nmethods in the field of intelligent driving perception rely on deep learning,\nwhich suffers from limited interpretability, often described as a \"black box.\"\nThis paper introduces a novel type of loss function, termed \"Entropy Loss,\"\nalong with an innovative training strategy. Entropy Loss is formulated based on\nthe functionality of feature compression networks within the perception model.\nDrawing inspiration from communication systems, the information transmission\nprocess in a feature compression network is expected to demonstrate steady\nchanges in information volume and a continuous decrease in information entropy.\nBy modeling network layer outputs as continuous random variables, we construct\na probabilistic model that quantifies changes in information volume. Entropy\nLoss is then derived based on these expectations, guiding the update of network\nparameters to enhance network interpretability. Our experiments indicate that\nthe Entropy Loss training strategy accelerates the training process. Utilizing\nthe same 60 training epochs, the accuracy of 3D object detection models using\nEntropy Loss on the KITTI test set improved by up to 4.47\\% compared to models\nwithout Entropy Loss, underscoring the method's efficacy. The implementation\ncode is available at https://github.com/yhbcode000/Eloss-Interpretability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.00839v2", "cate": "cs.CV", "date": "2024-09-01", "updated": "2025-07-18"}
{"id": "2507.13802", "title": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database", "authors": ["Nehir Kizililsoley", "Floor van Meer", "Osman Mutlu", "Wouter F Hoenderdaal", "Rosan G. Hobé", "Wenjuan Mu", "Arjen Gerssen", "H. J. van der Fels-Klerx", "Ákos Jóźwiak", "Ioannis Manikas", "Ali Hürriyetoǧlu", "Bas H. M. van der Velden"], "categories": ["cs.CY", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13802v1", "summary": "In the European Union, official food safety monitoring data collected by\nmember states are submitted to the European Food Safety Authority (EFSA) and\npublished on Zenodo. This data includes 392 million analytical results derived\nfrom over 15.2 million samples covering more than 4,000 different types of food\nproducts, offering great opportunities for artificial intelligence to analyze\ntrends, predict hazards, and support early warning systems. However, the\ncurrent format with data distributed across approximately 1000 files totaling\nseveral hundred gigabytes hinders accessibility and analysis. To address this,\nwe introduce the CompreHensive European Food Safety (CHEFS) database, which\nconsolidates EFSA monitoring data on pesticide residues, veterinary medicinal\nproduct residues, and chemical contaminants into a unified and structured\ndataset. We describe the creation and structure of the CHEFS database and\ndemonstrate its potential by analyzing trends in European food safety\nmonitoring data from 2000 to 2024. Our analyses explore changes in monitoring\nactivities, the most frequently tested products, which products were most often\nnon-compliant and which contaminants were most often found, and differences\nacross countries. These findings highlight the CHEFS database as both a\ncentralized data source and a strategic tool for guiding food safety policy,\nresearch, and regulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13802v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.05169", "title": "Critiques of World Models", "authors": ["Eric Xing", "Mingkai Deng", "Jinyu Hou", "Zhiting Hu"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05169v2", "summary": "World Model, the supposed algorithmic surrogate of the real-world environment\nwhich biological agents experience with and act upon, has been an emerging\ntopic in recent years because of the rising needs to develop virtual agents\nwith artificial (general) intelligence. There has been much debate on what a\nworld model really is, how to build it, how to use it, and how to evaluate it.\nIn this essay, starting from the imagination in the famed Sci-Fi classic Dune,\nand drawing inspiration from the concept of \"hypothetical thinking\" in\npsychology literature, we offer critiques of several schools of thoughts on\nworld modeling, and argue the primary goal of a world model to be simulating\nall actionable possibilities of the real world for purposeful reasoning and\nacting. Building on the critiques, we propose a new architecture for a\ngeneral-purpose world model, based on hierarchical, multi-level, and mixed\ncontinuous/discrete representations, and a generative and self-supervision\nlearning framework, with an outlook of a Physical, Agentic, and Nested (PAN)\nAGI system enabled by such a model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05169v2", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-18"}
{"id": "2507.13659", "title": "When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework", "authors": ["Xiao Wang", "Qian Zhu", "Shujuan Wu", "Bo Jiang", "Shiliang Zhang", "Yaowei Wang", "Yonghong Tian", "Bin Luo"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13659v1", "summary": "Recent researchers have proposed using event cameras for person\nre-identification (ReID) due to their promising performance and better balance\nin terms of privacy protection, event camera-based person ReID has attracted\nsignificant attention. Currently, mainstream event-based person ReID algorithms\nprimarily focus on fusing visible light and event stream, as well as preserving\nprivacy. Although significant progress has been made, these methods are\ntypically trained and evaluated on small-scale or simulated event camera\ndatasets, making it difficult to assess their real identification performance\nand generalization ability. To address the issue of data scarcity, this paper\nintroduces a large-scale RGB-event based person ReID dataset, called EvReID.\nThe dataset contains 118,988 image pairs and covers 1200 pedestrian identities,\nwith data collected across multiple seasons, scenes, and lighting conditions.\nWe also evaluate 15 state-of-the-art person ReID algorithms, laying a solid\nfoundation for future research in terms of both data and benchmarking. Based on\nour newly constructed dataset, this paper further proposes a pedestrian\nattribute-guided contrastive learning framework to enhance feature learning for\nperson re-identification, termed TriPro-ReID. This framework not only\neffectively explores the visual features from both RGB frames and event\nstreams, but also fully utilizes pedestrian attributes as mid-level semantic\nfeatures. Extensive experiments on the EvReID dataset and MARS datasets fully\nvalidated the effectiveness of our proposed RGB-Event person ReID framework.\nThe benchmark dataset and source code will be released on\nhttps://github.com/Event-AHU/Neuromorphic_ReID", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13659v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13920", "title": "Reframing attention as a reinforcement learning problem for causal discovery", "authors": ["Turan Orujlu", "Christian Gumbsch", "Martin V. Butz", "Charley M Wu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13920v1", "summary": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13920v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13599", "title": "Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model", "authors": ["Chengxu Liu", "Lu Qi", "Jinshan Pan", "Xueming Qian", "Ming-Hsuan Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.13599v1", "summary": "Since acquiring large amounts of realistic blurry-sharp image pairs is\ndifficult and expensive, learning blind image deblurring from unpaired data is\na more practical and promising solution. Unfortunately, dominant approaches\nrely heavily on adversarial learning to bridge the gap from blurry domains to\nsharp domains, ignoring the complex and unpredictable nature of real-world blur\npatterns. In this paper, we propose a novel diffusion model (DM)-based\nframework, dubbed \\ours, for image deblurring by learning spatially varying\ntexture prior from unpaired data. In particular, \\ours performs DM to generate\nthe prior knowledge that aids in recovering the textures of blurry images. To\nimplement this, we propose a Texture Prior Encoder (TPE) that introduces a\nmemory mechanism to represent the image textures and provides supervision for\nDM training. To fully exploit the generated texture priors, we present the\nTexture Transfer Transformer layer (TTformer), in which a novel\nFilter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes\nspatially varying blurring through adaptive filtering. Furthermore, we\nimplement a wavelet-based adversarial loss to preserve high-frequency texture\ndetails. Extensive evaluations show that \\ours provides a promising\nunsupervised deblurring solution and outperforms SOTA methods in widely-used\nbenchmarks.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.13599v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2411.02904", "title": "Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression", "authors": ["Yingzhen Yang", "Ping Li"], "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      This article draws results with revisions from the first author's other work in arXiv:2407.11353 , with typos in the previous version fixed. arXiv admin note: text overlap with arXiv:2407.11353", "url": "http://arxiv.org/abs/2411.02904v4", "summary": "We study nonparametric regression by an over-parameterized two-layer neural\nnetwork trained by gradient descent (GD) in this paper. We show that, if the\nneural network is trained by GD with early stopping, then the trained network\nrenders a sharp rate of the nonparametric regression risk of\n$\\mathcal{O}(\\epsilon_n^2)$, which is the same rate as that for the classical\nkernel regression trained by GD with early stopping, where $\\epsilon_n$ is the\ncritical population rate of the Neural Tangent Kernel (NTK) associated with the\nnetwork and $n$ is the size of the training data. It is remarked that our\nresult does not require distributional assumptions about the covariate as long\nas the covariate is bounded, in a strong contrast with many existing results\nwhich rely on specific distributions of the covariates such as the spherical\nuniform data distribution or distributions satisfying certain restrictive\nconditions. The rate $\\mathcal{O}(\\epsilon_n^2)$ is known to be minimax optimal\nfor specific cases, such as the case that the NTK has a polynomial eigenvalue\ndecay rate which happens under certain distributional assumptions on the\ncovariates. Our result formally fills the gap between training a classical\nkernel regression model and training an over-parameterized but finite-width\nneural network by GD for nonparametric regression without distributional\nassumptions on the bounded covariate. We also provide confirmative answers to\ncertain open questions or address particular concerns in the literature of\ntraining over-parameterized neural networks by GD with early stopping for\nnonparametric regression, including the characterization of the stopping time,\nthe lower bound for the network width, and the constant learning rate used in\nGD.", "comment": "This article draws results with revisions from the first author's\n  other work in arXiv:2407.11353, with typos in the previous version fixed", "pdf_url": "http://arxiv.org/pdf/2411.02904v4", "cate": "stat.ML", "date": "2024-11-05", "updated": "2025-07-17"}
{"id": "2507.13837", "title": "Principles and Reasons Behind Automated Vehicle Decisions in Ethically Ambiguous Everyday Scenarios", "authors": ["Lucas Elbert Suryana", "Simeon Calvert", "Arkady Zgonnikov", "Bart van Arem"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      30", "url": "http://arxiv.org/abs/2507.13837v1", "summary": "Automated vehicles (AVs) increasingly encounter ethically ambiguous\nsituations in everyday driving--scenarios involving conflicting human interests\nand lacking clearly optimal courses of action. While existing ethical models\noften focus on rare, high-stakes dilemmas (e.g., crash avoidance or trolley\nproblems), routine decisions such as overtaking cyclists or navigating social\ninteractions remain underexplored. This study addresses that gap by applying\nthe tracking condition of Meaningful Human Control (MHC), which holds that AV\nbehaviour should align with human reasons--defined as the values, intentions,\nand expectations that justify actions. We conducted qualitative interviews with\n18 AV experts to identify the types of reasons that should inform AV manoeuvre\nplanning. Thirteen categories of reasons emerged, organised across normative,\nstrategic, tactical, and operational levels, and linked to the roles of\nrelevant human agents. A case study on cyclist overtaking illustrates how these\nreasons interact in context, revealing a consistent prioritisation of safety,\ncontextual flexibility regarding regulatory compliance, and nuanced trade-offs\ninvolving efficiency, comfort, and public acceptance. Based on these insights,\nwe propose a principled conceptual framework for AV decision-making in routine,\nethically ambiguous scenarios. The framework supports dynamic, human-aligned\nbehaviour by prioritising safety, allowing pragmatic actions when strict legal\nadherence would undermine key values, and enabling constrained deviations when\nappropriately justified. This empirically grounded approach advances current\nguidance by offering actionable, context-sensitive design principles for\nethically aligned AV systems.", "comment": "30", "pdf_url": "http://arxiv.org/pdf/2507.13837v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13677", "title": "HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors", "authors": ["Chuheng Wei", "Ziye Qin", "Walter Zimmer", "Guoyuan Wu", "Matthew J. Barth"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted by ITSC2025", "url": "http://arxiv.org/abs/2507.13677v1", "summary": "Real-world Vehicle-to-Everything (V2X) cooperative perception systems often\noperate under heterogeneous sensor configurations due to cost constraints and\ndeployment variability across vehicles and infrastructure. This heterogeneity\nposes significant challenges for feature fusion and perception reliability. To\naddress these issues, we propose HeCoFuse, a unified framework designed for\ncooperative perception across mixed sensor setups where nodes may carry Cameras\n(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that\nadaptively weights features through a combination of channel-wise and spatial\nattention, HeCoFuse can tackle critical challenges such as cross-modality\nfeature misalignment and imbalanced representation quality. In addition, an\nadaptive spatial resolution adjustment module is employed to balance\ncomputational cost and fusion effectiveness. To enhance robustness across\ndifferent configurations, we further implement a cooperative learning strategy\nthat dynamically adjusts fusion type based on available modalities. Experiments\non the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%\n3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D\nbaseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC\nscenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine\nheterogeneous sensor configurations. These results, validated by our\nfirst-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the\ncurrent state-of-the-art on TUM-Traf V2X dataset while demonstrating robust\nperformance across diverse sensor deployments.", "comment": "Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted\n  by ITSC2025", "pdf_url": "http://arxiv.org/pdf/2507.13677v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13950", "title": "MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space", "authors": ["Jingbo Liang", "Bruna Jacobson"], "categories": ["cs.LG", "physics.bio-ph", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13950v1", "summary": "Extensively exploring protein conformational landscapes remains a major\nchallenge in computational biology due to the high computational cost involved\nin dynamic physics-based simulations. In this work, we propose a novel\npipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and\ngenerative adversarial networks (GANs) to explore protein conformational\nspaces. MoDyGAN contains a generator that maps Gaussian distributions into\nMD-derived protein trajectories, and a refinement module that combines ensemble\nlearning with a dual-discriminator to further improve the plausibility of\ngenerated conformations. Central to our approach is an innovative\nrepresentation technique that reversibly transforms 3D protein structures into\n2D matrices, enabling the use of advanced image-based GAN architectures. We use\nthree rigid proteins to demonstrate that MoDyGAN can generate plausible new\nconformations. We also use deca-alanine as a case study to show that\ninterpolations within the latent space closely align with trajectories obtained\nfrom steered molecular dynamics (SMD) simulations. Our results suggest that\nrepresenting proteins as image-like data unlocks new possibilities for applying\nadvanced deep learning techniques to biomolecular simulation, leading to an\nefficient sampling of conformational states. Additionally, the proposed\nframework holds strong potential for extension to other complex 3D structures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13950v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13607", "title": "Efficient Burst Super-Resolution with One-step Diffusion", "authors": ["Kento Kawai", "Takeru Oba", "Kyotaro Tokoro", "Kazutoshi Akita", "Norimichi Ukita"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      NTIRE2025", "url": "http://arxiv.org/abs/2507.13607v1", "summary": "While burst Low-Resolution (LR) images are useful for improving their Super\nResolution (SR) image compared to a single LR image, prior burst SR methods are\ntrained in a deterministic manner, which produces a blurry SR image. Since such\nblurry images are perceptually degraded, we aim to reconstruct sharp and\nhigh-fidelity SR images by a diffusion model. Our method improves the\nefficiency of the diffusion model with a stochastic sampler with a high-order\nODE as well as one-step diffusion using knowledge distillation. Our\nexperimental results demonstrate that our method can reduce the runtime to 1.6\n% of its baseline while maintaining the SR quality measured based on image\ndistortion and perceptual quality.", "comment": "NTIRE2025", "pdf_url": "http://arxiv.org/pdf/2507.13607v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.18587", "title": "Entropy functionals and equilibrium states in mixed quantum-classical dynamics", "authors": ["Cesare Tronci", "David Martínez-Crespo", "François Gay-Balmaz"], "categories": ["quant-ph", "cond-mat.stat-mech", "cs.IT", "math-ph", "math.IT", "math.MP", "physics.chem-ph"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Final version. To appear in Lecture Notes in Comput. Sci", "url": "http://arxiv.org/abs/2501.18587v3", "summary": "The computational challenges posed by many-particle quantum systems are often\novercome by mixed quantum-classical (MQC) models in which certain degrees of\nfreedom are treated as classical while others are retained as quantum. One of\nthe fundamental questions raised by this hybrid picture involves the\ncharacterization of the information associated to MQC systems. Based on the\ntheory of dynamical invariants in Hamiltonian systems, here we propose a family\nof hybrid entropy functionals that consistently specialize to the usual R\\'enyi\nand Shannon entropies. Upon considering the MQC Ehrenfest model for the\ndynamics of quantum and classical probabilities, we apply the hybrid Shannon\nentropy to characterize equilibrium configurations for simple Hamiltonians. The\npresent construction also applies beyond Ehrenfest dynamics.", "comment": "Final version. To appear in Lecture Notes in Comput. Sci", "pdf_url": "http://arxiv.org/pdf/2501.18587v3", "cate": "quant-ph", "date": "2025-01-30", "updated": "2025-07-18"}
{"id": "2507.13936", "title": "Extracting Insights from Large-Scale Telematics Data for ITS Applications: Lessons and Recommendations", "authors": ["Gibran Ali", "Neal Feierabend", "Prarthana Doshi", "Calvin Winkowski", "Michael Fontaine"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted for 2025 IEEE International Conference on Intelligent Transportation Systems (ITSC 2025)", "url": "http://arxiv.org/abs/2507.13936v1", "summary": "Over 90% of new vehicles in the United States now collect and transmit\ntelematics data. Similar trends are seen in other developed countries.\nTransportation planners have previously utilized telematics data in various\nforms, but its current scale offers significant new opportunities in traffic\nmeasurement, classification, planning, and control. Despite these\nopportunities, the enormous volume of data and lack of standardization across\nmanufacturers necessitates a clearer understanding of the data and improved\ndata processing methods for extracting actionable insights.\n  This paper takes a step towards addressing these needs through four primary\nobjectives. First, a data processing pipeline was built to efficiently analyze\n1.4 billion miles (120 million trips) of telematics data collected in Virginia\nbetween August 2021 and August 2022. Second, an open data repository of trip\nand roadway segment level summaries was created. Third, interactive\nvisualization tools were designed to extract insights from these data about\ntrip-taking behavior and the speed profiles of roadways. Finally, major\nchallenges that were faced during processing this data are summarized and\nrecommendations to overcome them are provided. This work will help\nmanufacturers collecting the data and transportation professionals using the\ndata to develop a better understanding of the possibilities and major pitfalls\nto avoid.", "comment": "Accepted for 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13936v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14082", "title": "Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications", "authors": ["Nelma Moreira", "Luca Prigioniero"], "categories": ["cs.FL", "cs.CC"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14082v1", "summary": "The Fifteenth International Workshop on Non-Classical Models of Automata and\nApplications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025,\norganized by the Department of Computer Science at Loughborough University and\nco-located with the 26th International Conference on Descriptional Complexity\nof Formal Systems (DCFS 2025, 22-24 July).\n  The NCMA workshop series was established in 2009 as an annual event for\nresearchers working on non-classical and classical models of automata, grammars\nor related devices. Such models are investigated both as theoretical models and\nas formal models for applications from various points of view. The goal of the\nNCMA workshop series is to exchange and develop novel ideas in order to gain\ndeeper and interdisciplinary coverage of this particular area that may foster\nnew insights and substantial progress.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14082v1", "cate": "cs.FL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13681", "title": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues", "authors": ["Haoyang Li", "Zhanchao Xu", "Yiming Li", "Xuejia Chen", "Darian Li", "Anxin Tian", "Qingfa Xiao", "Cheng Deng", "Jun Wang", "Qing Li", "Lei Chen", "Mingxuan Yuan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13681v1", "summary": "Multi-turn dialogues are essential in many real-world applications of large\nlanguage models, such as chatbots and virtual assistants. As conversation\nhistories become longer, existing large language models face increasing\ncomputational and memory challenges, which hinder their ability to provide\nefficient and responsive interactions. Most current acceleration methods either\ncompress the context or optimize key value caching, but they often rely on\nfixed or position-based heuristics that do not adapt well to the dynamic and\nunpredictable patterns found in actual multi-turn conversations. In this paper,\nwe present LoopServe, an adaptive dual-phase inference acceleration framework\nfor large language models in multi-turn dialogues. LoopServe introduces two\nmain innovations. First, it performs online sparsification during the\nprefilling phase by dynamically selecting the most important parts of the\nattention matrix for each new input. Second, it uses progressive key value\ncompression during decoding by adaptively maintaining a relevant and efficient\ncache based on the most recently generated output tokens. We also propose a\n\\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new\nbenchmark} with eleven multi-turn datasets that reflect realistic query\npositions and conversational dependencies. Extensive experiments demonstrate\nthat LoopServe consistently achieves superior effectiveness compared to\nexisting baselines and significantly accelerates LLM inference across a wide\nrange of long-context dialogue tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13681v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13954", "title": "Robust Anomaly Detection with Graph Neural Networks using Controllability", "authors": ["Yifan Wei", "Anwar Said", "Waseem Abbas", "Xenofon Koutsoukos"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      conference paper published in IEEE CAI 2025", "url": "http://arxiv.org/abs/2507.13954v1", "summary": "Anomaly detection in complex domains poses significant challenges due to the\nneed for extensive labeled data and the inherently imbalanced nature of\nanomalous versus benign samples. Graph-based machine learning models have\nemerged as a promising solution that combines attribute and relational data to\nuncover intricate patterns. However, the scarcity of anomalous data exacerbates\nthe challenge, which requires innovative strategies to enhance model learning\nwith limited information. In this paper, we hypothesize that the incorporation\nof the influence of the nodes, quantified through average controllability, can\nsignificantly improve the performance of anomaly detection. We propose two\nnovel approaches to integrate average controllability into graph-based\nframeworks: (1) using average controllability as an edge weight and (2)\nencoding it as a one-hot edge attribute vector. Through rigorous evaluation on\nreal-world and synthetic networks with six state-of-the-art baselines, our\nproposed methods demonstrate improved performance in identifying anomalies,\nhighlighting the critical role of controllability measures in enhancing the\nperformance of graph machine learning models. This work underscores the\npotential of integrating average controllability as additional metrics to\naddress the challenges of anomaly detection in sparse and imbalanced datasets.", "comment": "conference paper published in IEEE CAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.13954v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13609", "title": "CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks", "authors": ["Yanan Wang", "Julio Vizcarra", "Zhi Li", "Hao Niu", "Mori Kurokawa"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13609v1", "summary": "Despite recent progress in video large language models (VideoLLMs), a key\nopen challenge remains: how to equip models with chain-of-thought (CoT)\nreasoning abilities grounded in fine-grained object-level video understanding.\nExisting instruction-tuned models, such as the Qwen and LLaVA series, are\ntrained on high-level video-text pairs, often lacking structured annotations\nnecessary for compositional, step-by-step reasoning. We propose CoTasks:\nChain-of-Thought based Video Instruction Tuning Tasks, a new framework that\ndecomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)\ninto four entity-level foundational tasks: frame localization, entity tracking,\nspatial and temporal relation extraction. By embedding these intermediate\nCoT-style reasoning steps into the input, CoTasks enables models to explicitly\nperform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA\nbenchmark show that CoTasks significantly enhance inference performance:\nLLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and\nQwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal\n(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the\neffectiveness of CoTasks as a structured CoT-style supervision framework for\nimproving compositional video reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13609v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.08079", "title": "Zak-OTFS with Spread Carrier Waveforms", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, includes proofs of all results. Updated to reflect IEEE Early Access publication. Added IEEE copyright notice and DOI", "url": "http://arxiv.org/abs/2505.08079v3", "summary": "Zak-OTFS (orthogonal time frequency space) modulation is a communication\nframework that parameterizes the wireless channel in the delay-Doppler (DD)\ndomain, where the parameters map directly to physical attributes of the\nscatterers that comprise the scattering environment. As a consequence, the\nchannel can be efficiently acquired and equalized. The Zak-OTFS carrier is a\npulse in the DD domain, and the Zak transform converts it to a pulse train\nmodulated by a tone (pulsone) in the time domain. The pulsone waveform is\nlocalized rather than spread, and it suffers from high peak-to-average power\nratio (PAPR). We describe how to transform the orthonormal basis of Zak-OTFS\npulsones into an orthonormal basis of spread carrier waveforms with low PAPR\n(only $6.58$ dB) that support communication in the presence of mobility and\ndelay spread. This transformation is realized by a unitary transform based on\nthe discrete affine Fourier transform. Unlike other spread modulations that\nachieve low PAPR by spreading information across a wider bandwidth (thus\nreducing the spectral efficiency), the proposed spread carrier-based Zak-OTFS\nachieves full spectral efficiency like pulsone-based Zak-OTFS, with $5.6$ dB\nlower PAPR per basis element. We demonstrate uncoded bit error rate (BER)\nsimilar to pulsone-based Zak-OTFS, and improved BER performance over competing\nmethods based on OFDM and OTFS in high mobility & delay spread environments.", "comment": "7 pages, 6 figures, includes proofs of all results. Updated to\n  reflect IEEE Early Access publication. Added IEEE copyright notice and DOI", "pdf_url": "http://arxiv.org/pdf/2505.08079v3", "cate": "eess.SP", "date": "2025-05-12", "updated": "2025-07-18"}
{"id": "2507.13391", "title": "Quantitative Risk Management in Volatile Markets with an Expectile-Based Framework for the FTSE Index", "authors": ["Abiodun Finbarrs Oketunji"], "categories": ["q-fin.RM", "cs.CY", "91G70, 91B30, 60G70, 62P05", "G.4; G.m; D.2.13; C.5.0"], "primary_category": "Subjects:       Risk Management (q-fin.RM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13391v1", "summary": "This research presents a framework for quantitative risk management in\nvolatile markets, specifically focusing on expectile-based methodologies\napplied to the FTSE 100 index. Traditional risk measures such as Value-at-Risk\n(VaR) have demonstrated significant limitations during periods of market\nstress, as evidenced during the 2008 financial crisis and subsequent volatile\nperiods. This study develops an advanced expectile-based framework that\naddresses the shortcomings of conventional quantile-based approaches by\nproviding greater sensitivity to tail losses and improved stability in extreme\nmarket conditions. The research employs a dataset spanning two decades of FTSE\n100 returns, incorporating periods of high volatility, market crashes, and\nrecovery phases. Our methodology introduces novel mathematical formulations for\nexpectile regression models, enhanced threshold determination techniques using\ntime series analysis, and robust backtesting procedures. The empirical results\ndemonstrate that expectile-based Value-at-Risk (EVaR) consistently outperforms\ntraditional VaR measures across various confidence levels and market\nconditions. The framework exhibits superior performance during volatile\nperiods, with reduced model risk and enhanced predictive accuracy. Furthermore,\nthe study establishes practical implementation guidelines for financial\ninstitutions and provides evidence-based recommendations for regulatory\ncompliance and portfolio management. The findings contribute significantly to\nthe literature on financial risk management and offer practical tools for\npractitioners dealing with volatile market environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13391v1", "cate": "q-fin.RM", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13203", "title": "On finite extensions of lamplighter groups", "authors": ["Corentin Bodart"], "categories": ["math.GR", "cs.DM", "cs.FL"], "primary_category": "Subjects:       Group Theory (math.GR)", "pdf_link": null, "comments": "Comments:      27 pages, 6 figures. v2: Removed the very last (wrong) remark, and fixed a reference", "url": "http://arxiv.org/abs/2507.13203v2", "summary": "We study a family of groups consisting of the simplest extensions of\nlamplighter groups. We use these groups to answer multiple open questions in\ncombinatorial group theory, providing groups that exhibit various combinations\nof properties: 1) Decidable Subgroup Membership and undecidable Uniform\nSubgroup Membership Problem, 2) Rational volume growth series and undecidable\nWord Problem and 3) Recursive (even context-free) language of conjugacy\ngeodesics, decidable Word Problem, and undecidable Conjugacy Problem. We also\nconsider the co-Word Problem, residual finiteness and the Isomorphism Problem\nwithin this class.", "comment": "27 pages, 6 figures. v2: Removed the very last (wrong) remark, and\n  fixed a reference", "pdf_url": "http://arxiv.org/pdf/2507.13203v2", "cate": "math.GR", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.13725", "title": "Point of Interest Recommendation: Pitfalls and Viable Solutions", "authors": ["Alejandro Bellogín", "Linus W. Dietz", "Francesco Ricci", "Pablo Sánchez"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13725v1", "summary": "Point of interest (POI) recommendation can play a pivotal role in enriching\ntourists' experiences by suggesting context-dependent and preference-matching\nlocations and activities, such as restaurants, landmarks, itineraries, and\ncultural attractions. Unlike some more common recommendation domains (e.g.,\nmusic and video), POI recommendation is inherently high-stakes: users invest\nsignificant time, money, and effort to search, choose, and consume these\nsuggested POIs. Despite the numerous research works in the area, several\nfundamental issues remain unresolved, hindering the real-world applicability of\nthe proposed approaches. In this paper, we discuss the current status of the\nPOI recommendation problem and the main challenges we have identified. The\nfirst contribution of this paper is a critical assessment of the current state\nof POI recommendation research and the identification of key shortcomings\nacross three main dimensions: datasets, algorithms, and evaluation\nmethodologies. We highlight persistent issues such as the lack of standardized\nbenchmark datasets, flawed assumptions in the problem definition and model\ndesign, and inadequate treatment of biases in the user behavior and system\nperformance. The second contribution is a structured research agenda that,\nstarting from the identified issues, introduces important directions for future\nwork related to multistakeholder design, context awareness, data collection,\ntrustworthiness, novel interactions, and real-world evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13725v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13959", "title": "Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs", "authors": ["Eli Verwimp", "Gustav Ryberg Smidt", "Hendrik Hameeuw", "Katrien De Graef"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Paper under review at JOCCH", "url": "http://arxiv.org/abs/2507.13959v1", "summary": "The work in this paper describes the training and evaluation of machine\nlearning (ML) techniques for the classification of cuneiform signs. There is a\nlot of variability in cuneiform signs, depending on where they come from, for\nwhat and by whom they were written, but also how they were digitized. This\nvariability makes it unlikely that an ML model trained on one dataset will\nperform successfully on another dataset. This contribution studies how such\ndifferences impact that performance. Based on our results and insights, we aim\nto influence future data acquisition standards and provide a solid foundation\nfor future cuneiform sign classification tasks. The ML model has been trained\nand tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary\ntexts inscribed on clay tablets originating from three Mesopotamian cities\n(Nippur, D\\=ur-Abie\\v{s}uh and Sippar). The presented and analysed model is\nResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for\nsigns with at least 20 instances. As these automatic classification results are\nthe first on Old Babylonian texts, there are currently no comparable results.", "comment": "Paper under review at JOCCH", "pdf_url": "http://arxiv.org/pdf/2507.13959v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13628", "title": "Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation", "authors": ["Masahiro Ogawa", "Qi An", "Atsushi Yamashita"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 15 figures, RA-L submission", "url": "http://arxiv.org/abs/2507.13628v1", "summary": "Separating moving and static objects from a moving camera viewpoint is\nessential for 3D reconstruction, autonomous navigation, and scene understanding\nin robotics. Existing approaches often rely primarily on optical flow, which\nstruggles to detect moving objects in complex, structured scenes involving\ncamera motion. To address this limitation, we propose Focus of Expansion\nLikelihood and Segmentation (FoELS), a method based on the core idea of\nintegrating both optical flow and texture information. FoELS computes the focus\nof expansion (FoE) from optical flow and derives an initial motion likelihood\nfrom the outliers of the FoE computation. This likelihood is then fused with a\nsegmentation-based prior to estimate the final moving probability. The method\neffectively handles challenges including complex structured scenes, rotational\ncamera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016\ndataset and real-world traffic videos demonstrate its effectiveness and\nstate-of-the-art performance.", "comment": "8 pages, 15 figures, RA-L submission", "pdf_url": "http://arxiv.org/pdf/2507.13628v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.18879", "title": "Efficient Online Random Sampling via Randomness Recycling", "authors": ["Thomas L. Draper", "Feras A. Saad"], "categories": ["cs.DS", "cs.DM", "cs.IT", "math.IT", "math.PR", "stat.CO"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      35 pages, 9 figures, 2 tables, 14 algorithms", "url": "http://arxiv.org/abs/2505.18879v2", "summary": "``Randomness recycling'' is a powerful algorithmic technique for reusing a\nfraction of the random information consumed by a probabilistic algorithm to\nreduce its entropy requirements. This article presents a family of randomness\nrecycling algorithms for efficiently sampling a sequence $X_1, X_2, X_3, \\dots$\nof discrete random variables whose joint distribution follows an arbitrary\nstochastic process. We develop randomness recycling techniques to reduce the\nentropy cost of a variety of prominent sampling algorithms, which include\nuniform sampling, inverse transform sampling, lookup-table sampling, alias\nsampling, and discrete distribution generating (DDG) tree sampling. Our method\nachieves an expected amortized entropy cost of $H(X_1,\\dots,X_k)/k +\n\\varepsilon$ input bits per output sample using $O(\\log(1/\\varepsilon))$ space\nas $k\\to\\infty$, which is arbitrarily close to the optimal Shannon entropy rate\nof $H(X_1,\\dots,X_k)/k$ bits per sample. The combination of space, time, and\nentropy properties of our method improves upon the Knuth and Yao\nentropy-optimal algorithm and Han and Hoshi interval algorithm for sampling a\ndiscrete random sequence.\n  On the empirical side, we show that randomness recycling enables\nstate-of-the-art runtime performance on the Fisher-Yates shuffle when using a\ncryptographically secure pseudorandom number generator; and it can also speed\nup discrete Gaussian samplers. Accompanying the manuscript is a performant\nsoftware library in the C programming language that uses randomness recycling\nto accelerate several existing algorithms for random sampling.", "comment": "35 pages, 9 figures, 2 tables, 14 algorithms", "pdf_url": "http://arxiv.org/pdf/2505.18879v2", "cate": "cs.DS", "date": "2025-05-24", "updated": "2025-07-17"}
{"id": "2507.13743", "title": "PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs", "authors": ["Maluna Menke", "Thilo Hagendorff"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13743v1", "summary": "Large Language Models (LLMs) frequently reproduce the gender- and\nsexual-identity prejudices embedded in their training corpora, leading to\noutputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of\ngreat importance. To achieve this, we evaluate two parameter-efficient\nfine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt\ntuning - as lightweight alternatives to full-model fine-tuning for mitigating\nsuch biases. Using the WinoQueer benchmark, we quantify bias in three\nopen-source LLMs and observe baseline bias scores reaching up to 98 (out of\n100) across a range of queer identities defined by gender and/or sexual\norientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%\nadditional parameters) on a curated QueerNews corpus reduces those scores by up\nto 50 points and raises neutrality from virtually 0% to as much as 36%.\nSoft-prompt tuning (10 virtual tokens) delivers only marginal improvements.\nThese findings show that LoRA can deliver meaningful fairness gains with\nminimal computation. We advocate broader adoption of community-informed PEFT,\nthe creation of larger queer-authored corpora, and richer evaluation suites\nbeyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13743v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13739", "title": "Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning", "authors": ["Junsu Kim", "Yunhoe Ku", "Seungryul Baek"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6th CLVISION ICCV Workshop accepted", "url": "http://arxiv.org/abs/2507.13739v1", "summary": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, \\emph{mini}ImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.", "comment": "6th CLVISION ICCV Workshop accepted", "pdf_url": "http://arxiv.org/pdf/2507.13739v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13992", "title": "Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks", "authors": ["Jagruti Patel", "Thomas A. W. Bolton", "Mikkel Schöttner", "Anjali Tarun", "Sebastien Tourbier", "Yasser Alemàn-Gòmez", "Jonas Richiardi", "Patric Hagmann"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13992v1", "summary": "Small sample sizes in neuroimaging in general, and in structural connectome\n(SC) studies in particular limit the development of reliable biomarkers for\nneurological and psychiatric disorders - such as Alzheimer's disease and\nschizophrenia - by reducing statistical power, reliability, and\ngeneralizability. Large-scale multi-site studies have exist, but they have\nacquisition-related biases due to scanner heterogeneity, compromising imaging\nconsistency and downstream analyses. While existing SC harmonization methods -\nsuch as linear regression (LR), ComBat, and deep learning techniques - mitigate\nthese biases, they often rely on detailed metadata, traveling subjects (TS), or\noverlook the graph-topology of SCs. To address these limitations, we propose a\nsite-conditioned deep harmonization framework that harmonizes SCs across\ndiverse acquisition sites without requiring metadata or TS that we test in a\nsimulated scenario based on the Human Connectome Dataset. Within this\nframework, we benchmark three deep architectures - a fully connected\nautoencoder (AE), a convolutional AE, and a graph convolutional AE - against a\ntop-performing LR baseline. While non-graph models excel in edge-weight\nprediction and edge existence detection, the graph AE demonstrates superior\npreservation of topological structure and subject-level individuality, as\nreflected by graph metrics and fingerprinting accuracy, respectively. Although\nthe LR baseline achieves the highest numerical performance by explicitly\nmodeling acquisition parameters, it lacks applicability to real-world\nmulti-site use cases as detailed acquisition metadata is often unavailable. Our\nresults highlight the critical role of model architecture in SC harmonization\nperformance and demonstrate that graph-based approaches are particularly\nwell-suited for structure-aware, domain-generalizable SC harmonization in\nlarge-scale multi-site SC studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13992v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13648", "title": "EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation", "authors": ["Seungjun Moon", "Sangjoon Yu", "Gyeong-Moon Park"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13648v1", "summary": "The rapid advancement of neural radiance fields (NeRF) has paved the way to\ngenerate animatable human avatars from a monocular video. However, the sole\nusage of NeRF suffers from a lack of details, which results in the emergence of\nhybrid representation that utilizes SMPL-based mesh together with NeRF\nrepresentation. While hybrid-based models show photo-realistic human avatar\ngeneration qualities, they suffer from extremely slow inference due to their\ndeformation scheme: to be aligned with the mesh, hybrid-based models use the\ndeformation based on SMPL skinning weights, which needs high computational\ncosts on each sampled point. We observe that since most of the sampled points\nare located in empty space, they do not affect the generation quality but\nresult in inference latency with deformation. In light of this observation, we\npropose EPSilon, a hybrid-based 3D avatar generation scheme with novel\nefficient point sampling strategies that boost both training and inference. In\nEPSilon, we propose two methods to omit empty points at rendering; empty ray\nomission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that\nprogress through the empty space. Then, EIO narrows down the sampling interval\non the ray, which wipes out the region not occupied by either clothes or mesh.\nThe delicate sampling scheme of EPSilon enables not only great computational\ncost reduction during deformation but also the designation of the important\nregions to be sampled, which enables a single-stage NeRF structure without\nhierarchical sampling. Compared to existing methods, EPSilon maintains the\ngeneration quality while using only 3.9% of sampled points and achieves around\n20 times faster inference, together with 4 times faster training convergence.\nWe provide video results on https://github.com/seungjun-moon/epsilon.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13648v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.09894", "title": "Precoded Zak-OTFS for Per-Carrier Equalization", "authors": ["Saif Khan Mohammed", "Amit Kumar Pathak", "Muhammad Ubadah", "Ronny Hadani", "Ananthanarayanan Chockalingam", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09894v2", "summary": "In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform\nis a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic\nlocalized function with specific periods along delay and Doppler. When the\nchannel delay spread is less than the delay period, and the channel Doppler\nspread is less than the Doppler period, the response to a single Zak-OTFS\ncarrier provides an image of the scattering environment and can be used to\npredict the effective channel at all other carriers. The image of the\nscattering environment changes slowly, making it possible to employ precoding\nat the transmitter. Precoding techniques were developed more than thirty years\nago for wireline modem channels (V.34 standard) defined by linear convolution\nwhere a pulse in the time domain (TD) is used to probe the one-dimensional\npartial response channel. The action of a doubly spread channel on Zak-OTFS\nmodulation determines a two-dimensional partial response channel defined by\ntwisted convolution, and we develop a novel precoding technique for this\nchannel. The proposed precoder leads to separate equalization of each DD\ncarrier which has significantly lower complexity than joint equalization of all\ncarriers. Further, the effective precoded channel results in non-interfering DD\ncarriers which significantly reduces the overhead of guard carriers separating\ndata and pilot carriers, which improves the spectral efficiency significantly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09894v2", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-18"}
{"id": "2507.13881", "title": "Using LLMs to identify features of personal and professional skills in an open-response situational judgment test", "authors": ["Cole Walsh", "Rodica Ivan", "Muhammad Zafar Iqbal", "Colleen Robb"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures, 4 tables; this work was accepted for presentation at the 2025 Artificial Intelligence in Measurement and Education Conference in Pittsburgh, Pennsylvania, United States", "url": "http://arxiv.org/abs/2507.13881v1", "summary": "Academic programs are increasingly recognizing the importance of personal and\nprofessional skills and their critical role alongside technical expertise in\npreparing students for future success in diverse career paths. With this\ngrowing demand comes the need for scalable systems to measure, evaluate, and\ndevelop these skills. Situational Judgment Tests (SJTs) offer one potential\navenue for measuring these skills in a standardized and reliable way, but\nopen-response SJTs have traditionally relied on trained human raters for\nevaluation, presenting operational challenges to delivering SJTs at scale. Past\nattempts at developing NLP-based scoring systems for SJTs have fallen short due\nto issues with construct validity of these systems. In this article, we explore\na novel approach to extracting construct-relevant features from SJT responses\nusing large language models (LLMs). We use the Casper SJT to demonstrate the\nefficacy of this approach. This study sets the foundation for future\ndevelopments in automated scoring for personal and professional skills.", "comment": "10 pages, 2 figures, 4 tables; this work was accepted for\n  presentation at the 2025 Artificial Intelligence in Measurement and Education\n  Conference in Pittsburgh, Pennsylvania, United States", "pdf_url": "http://arxiv.org/pdf/2507.13881v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13769", "title": "Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction", "authors": ["Mingyang Yu", "Zhijian Wu", "Dingjiang Huang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13769v1", "summary": "Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its\ndegraded 2D measurements. Recently great progress has been made in deep\nlearning-based methods, however, these methods often struggle to accurately\ncapture high-frequency details of the HSI. To address this issue, this paper\nproposes a Spectral Diffusion Prior (SDP) that is implicitly learned from\nhyperspectral images using a diffusion model. Leveraging the powerful ability\nof the diffusion model to reconstruct details, this learned prior can\nsignificantly improve the performance when injected into the HSI model. To\nfurther improve the effectiveness of the learned prior, we also propose the\nSpectral Prior Injector Module (SPIM) to dynamically guide the model to recover\nthe HSI details. We evaluate our method on two representative HSI methods: MST\nand BISRNet. Experimental results show that our method outperforms existing\nnetworks by about 0.5 dB, effectively improving the performance of HSI\nreconstruction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13769v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13998", "title": "ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies", "authors": ["Itay Katav", "Aryeh Kontorovich"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13998v1", "summary": "Modern multivariate time series forecasting primarily relies on two\narchitectures: the Transformer with attention mechanism and Mamba. In natural\nlanguage processing, an approach has been used that combines local window\nattention for capturing short-term dependencies and Mamba for capturing\nlong-term dependencies, with their outputs averaged to assign equal weight to\nboth. We find that for time-series forecasting tasks, assigning equal weight to\nlong-term and short-term dependencies is not optimal. To mitigate this, we\npropose a dynamic weighting mechanism, ParallelTime Weighter, which calculates\ninterdependent weights for long-term and short-term dependencies for each token\nbased on the input and the model's knowledge. Furthermore, we introduce the\nParallelTime architecture, which incorporates the ParallelTime Weighter\nmechanism to deliver state-of-the-art performance across diverse benchmarks.\nOur architecture demonstrates robustness, achieves lower FLOPs, requires fewer\nparameters, scales effectively to longer prediction horizons, and significantly\noutperforms existing methods. These advances highlight a promising path for\nfuture developments of parallel Attention-Mamba in time series forecasting. The\nimplementation is readily available at:\n\\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13998v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13663", "title": "Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration", "authors": ["Xingyu Jiang", "Ning Gao", "Hongkun Dou", "Xiuhui Zhang", "Xiaoqing Zhong", "Yue Deng", "Hongjue Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13663v1", "summary": "Natural image quality is often degraded by adverse weather conditions,\nsignificantly impairing the performance of downstream tasks. Image restoration\nhas emerged as a core solution to this challenge and has been widely discussed\nin the literature. Although recent transformer-based approaches have made\nremarkable progress in image restoration, their increasing system complexity\nposes significant challenges for real-time processing, particularly in\nreal-world deployment scenarios. To this end, most existing methods attempt to\nsimplify the self-attention mechanism, such as by channel self-attention or\nstate space model. However, these methods primarily focus on network\narchitecture while neglecting the inherent characteristics of image restoration\nitself. In this context, we explore a pyramid Wavelet-Fourier iterative\npipeline to demonstrate the potential of Wavelet-Fourier processing for image\nrestoration. Inspired by the above findings, we propose a novel and efficient\nrestoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).\nSpecifically, PW-FNet features two key design principles: 1) at the inter-block\nlevel, integrates a pyramid wavelet-based multi-input multi-output structure to\nachieve multi-scale and multi-frequency bands decomposition; and 2) at the\nintra-block level, incorporates Fourier transforms as an efficient alternative\nto self-attention mechanisms, effectively reducing computational complexity\nwhile preserving global modeling capability. Extensive experiments on tasks\nsuch as image deraining, raindrop removal, image super-resolution, motion\ndeblurring, image dehazing, image desnowing and underwater/low-light\nenhancement demonstrate that PW-FNet not only surpasses state-of-the-art\nmethods in restoration quality but also achieves superior efficiency, with\nsignificantly reduced parameter size, computational cost and inference time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13663v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12593", "title": "Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS", "authors": ["Sandesh Rao Mattu", "Nishant Mehrotra", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, submitted to IEEE Wireless Communications Letters for possible publication. Copyright maybe transferred without notice", "url": "http://arxiv.org/abs/2507.12593v2", "summary": "Zak-transform based orthogonal time frequency space (Zak-OTFS) is a\ndelay-Doppler (DD) domain modulation scheme in which the signal processing is\ncarried out in the DD domain. The channel when viewed in the DD domain is\npredictable. However, even with Zak-OTFS, pilots need to be sent periodically,\nalbeit at a lower rate. In this paper, we propose a differential communication\nscheme for Zak-OTFS systems that alleviates the need for periodic pilot\ntransmission. Towards this, we analytically show that the detected data can be\nused as a pilot and that the channel estimate obtained from the detected data\ncan enable further detection enabling the \"differential\" aspect of the\ncommunication. Specifically, we leverage the prediction capability of the DD\nchannel in Zak-OTFS to use the channel estimate (obtained from detected data\nsymbols treated as pilots) in the previous instant to detect data in the next\ninstant and propagate this forward. The advantages are two fold. First, it\nallows the data symbols to enjoy higher energy since the energy that would\notherwise be required for pilot symbols can also be allocated to data symbols.\nSecond, it allows for full spectral efficiency compared to point or embedded\npilots. Comparison with the full spectral efficiency achieving spread pilot\nscheme shows that the proposed method achieves better bit-error rate at lower\ncomplexity.", "comment": "7 pages, 5 figures, submitted to IEEE Wireless Communications Letters\n  for possible publication. Copyright maybe transferred without notice", "pdf_url": "http://arxiv.org/pdf/2507.12593v2", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2501.10484", "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude", "authors": ["Yile Yan", "Yuqi Zhu", "Wentao Xu"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by International AAAI Conference on Web and Social Media 2026, sunny Los Angeles, California", "url": "http://arxiv.org/abs/2501.10484v2", "summary": "Recent advances in Large Language Models (LLMs) have enabled human-like\nresponses across various tasks, raising questions about their ethical\ndecision-making capabilities and potential biases. This study investigates\nprotected attributes in LLMs through systematic evaluation of their responses\nto ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5\nSonnet - we analyzed their decision-making patterns across multiple protected\nattributes including age, gender, race, appearance, and disability status.\nThrough 11,200 experimental trials involving both single-factor and two-factor\nprotected attribute combinations, we evaluated the models' ethical preferences,\nsensitivity, stability, and clustering of preferences. Our findings reveal\nsignificant protected attributeses in both models, with consistent preferences\nfor certain features (e.g., \"good-looking\") and systematic neglect of others.\nNotably, while GPT-3.5 Turbo showed stronger preferences aligned with\ntraditional power structures, Claude 3.5 Sonnet demonstrated more diverse\nprotected attribute choices. We also found that ethical sensitivity\nsignificantly decreases in more complex scenarios involving multiple protected\nattributes. Additionally, linguistic referents heavily influence the models'\nethical evaluations, as demonstrated by differing responses to racial\ndescriptors (e.g., \"Yellow\" versus \"Asian\"). These findings highlight critical\nconcerns about the potential impact of LLM biases in autonomous decision-making\nsystems and emphasize the need for careful consideration of protected\nattributes in AI development. Our study contributes to the growing body of\nresearch on AI ethics by providing a systematic framework for evaluating\nprotected attributes in LLMs' ethical decision-making capabilities.", "comment": "This paper has been accepted by International AAAI Conference on Web\n  and Social Media 2026, sunny Los Angeles, California", "pdf_url": "http://arxiv.org/pdf/2501.10484v2", "cate": "cs.CY", "date": "2025-01-17", "updated": "2025-07-18"}
{"id": "2507.13789", "title": "Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI", "authors": ["Kyriakos Flouris", "Moritz Halter", "Yolanne Y. R. Lee", "Samuel Castonguay", "Luuk Jacobs", "Pietro Dirix", "Jonathan Nestmann", "Sebastian Kozerke", "Ender Konukoglu"], "categories": ["cs.CV", "cs.AI", "physics.comp-ph"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13789v1", "summary": "Hemodynamic analysis is essential for predicting aneurysm rupture and guiding\ntreatment. While magnetic resonance flow imaging enables time-resolved\nvolumetric blood velocity measurements, its low spatiotemporal resolution and\nsignal-to-noise ratio limit its diagnostic utility. To address this, we propose\nthe Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that\nenhances both spatial and temporal resolution with the ability to predict wall\nshear stress (WSS) directly from clinical imaging data. LoFNO integrates\nLaplacian eigenvectors as geometric priors for improved structural awareness on\nirregular, unseen geometries and employs an Enhanced Deep Super-Resolution\nNetwork (EDSR) layer for robust upsampling. By combining geometric priors with\nneural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow\ndata, achieving superior velocity and WSS predictions compared to interpolation\nand alternative deep learning methods, enabling more precise cerebrovascular\ndiagnostics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13789v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14005", "title": "On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes", "authors": ["Mathieu Godbout", "Audrey Durand"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14005v1", "summary": "Recent work has shown that dynamic programming (DP) methods for finding\nstatic CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when\nbased on the dual formulation, yet the root cause for the failure has remained\nunclear. We expand on these findings by shifting focus from policy optimization\nto the seemingly simpler task of policy evaluation. We show that evaluating the\nstatic CVaR of a given policy can be framed as two distinct minimization\nproblems. For their solutions to match, a set of ``risk-assignment consistency\nconstraints'' must be satisfied, and we demonstrate that the intersection of\nthe constraints being empty is the source of previously observed evaluation\nerrors. Quantifying the evaluation error as the CVaR evaluation gap, we then\ndemonstrate that the issues observed when optimizing over the dual-based CVaR\nDP are explained by the returned policy having a non-zero CVaR evaluation gap.\nWe then leverage our proposed risk-assignment perspective to prove that the\nsearch for a single, uniformly optimal policy via on the dual CVaR\ndecomposition is fundamentally limited, identifying an MDP where no single\npolicy can be optimal across all initial risk levels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14005v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13673", "title": "MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training", "authors": ["Yuechen Xie", "Haobo Jiang", "Jian Yang", "Yigong Zhang", "Jin Xie"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures, 6 tables", "url": "http://arxiv.org/abs/2507.13673v1", "summary": "In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of\nhands and objects from monocular RGB input remains highly challenging due to\nthe inherent geometric ambiguity of RGB images and the severe mutual occlusions\nthat occur during interaction.To address these challenges, we propose MaskHOI,\na novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI\npose estimation. Our core idea is to leverage the masking-then-reconstruction\nstrategy of MAE to encourage the feature encoder to infer missing spatial and\nstructural information, thereby facilitating geometric-aware and\nocclusion-robust representation learning. Specifically, based on our\nobservation that human hands exhibit far greater geometric complexity than\nrigid objects, conventional uniform masking fails to effectively guide the\nreconstruction of fine-grained hand structures. To overcome this limitation, we\nintroduce a Region-specific Mask Ratio Allocation, primarily comprising the\nregion-specific masking assignment and the skeleton-driven hand masking\nguidance. The former adaptively assigns lower masking ratios to hand regions\nthan to rigid objects, balancing their feature learning difficulty, while the\nlatter prioritizes masking critical hand parts (e.g., fingertips or entire\nfingers) to realistically simulate occlusion patterns in real-world\ninteractions. Furthermore, to enhance the geometric awareness of the pretrained\nencoder, we introduce a novel Masked Signed Distance Field (SDF)-driven\nmultimodal learning mechanism. Through the self-masking 3D SDF prediction, the\nlearned encoder is able to perceive the global geometric structure of hands and\nobjects beyond the 2D image plane, overcoming the inherent limitations of\nmonocular input and alleviating self-occlusion issues. Extensive experiments\ndemonstrate that our method significantly outperforms existing state-of-the-art\napproaches.", "comment": "10 pages, 8 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.13673v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.07312", "title": "Mindsets and Management: AI and Gender (In)Equitable Access to Finance", "authors": ["Genevieve Smith"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at ACM FAccT 2025", "url": "http://arxiv.org/abs/2504.07312v3", "summary": "A growing trend in financial technology (fintech) is the use of mobile phone\ndata and machine learning (ML) to provide credit scores- and subsequently,\nopportunities to access loans- to groups left out of traditional banking. This\npaper draws on interview data with leaders, investors, and data scientists at\nfintech companies developing ML-based alternative lending apps in low- and\nmiddle-income countries to explore financial inclusion and gender implications.\nMore specifically, it examines how the underlying logics, design choices, and\nmanagement decisions of ML-based alternative lending tools by fintechs embed or\nchallenge gender biases, and consequently influence gender equity in access to\nfinance. Findings reveal developers follow 'gender blind' approaches, grounded\nin beliefs that ML is objective and data reflects the truth. This leads to a\nlack of grappling with the ways data, features for creditworthiness, and access\nto apps are gendered. Overall, tools increase access to finance, but not gender\nequitably: Interviewees report less women access loans and receive lower\namounts than men, despite being better repayers. Fintechs identify demand- and\nsupply-side reasons for gender differences, but frame them as outside their\nresponsibility. However, that women are observed as better repayers reveals a\nmarket inefficiency and potential discriminatory effect, further linked to\nprofit optimization objectives. This research introduces the concept of encoded\ngender norms, whereby without explicit attention to the gendered nature of data\nand algorithmic design, AI tools reproduce existing inequalities. In doing so,\nthey reinforce gender norms as self-fulfilling prophecies. The idea that AI is\ninherently objective and, when left alone, 'fair', is seductive and misleading.\nIn reality, algorithms reflect the perspectives, priorities, and values of the\npeople and institutions that design them.", "comment": "Accepted for presentation at ACM FAccT 2025", "pdf_url": "http://arxiv.org/pdf/2504.07312v3", "cate": "cs.CY", "date": "2025-04-09", "updated": "2025-07-17"}
{"id": "2507.13801", "title": "One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion", "authors": ["Haoang Lu", "Yuanqi Su", "Xiaoning Zhang", "Hao Hu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13801v1", "summary": "In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a\ncritical perception task for autonomous driving due to its ability to infer\ncomplete 3D scene layouts and semantics from single 2D images. However, in\nreal-world traffic scenarios, a significant portion of the scene remains\noccluded or outside the camera's field of view -- a fundamental challenge that\nexisting monocular SSC methods fail to address adequately. To overcome these\nlimitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC\nframework that leverages pseudo-future frame prediction to expand the model's\neffective perceptual range. Our approach combines poses and depths to establish\naccurate 3D correspondences, enabling geometrically-consistent fusion of past,\npresent, and predicted future frames in 3D space. Unlike conventional methods\nthat rely on simple feature stacking, our 3D-aware architecture achieves more\nrobust scene completion by explicitly modeling spatial-temporal relationships.\nComprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks\ndemonstrate state-of-the-art performance, validating the effectiveness of our\napproach, highlighting our method's ability to improve occlusion reasoning and\n3D scene completion accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13801v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14021", "title": "Byzantine-resilient federated online learning for Gaussian process regression", "authors": ["Xu Zhang", "Zhenyuan Yuan", "Minghui Zhu"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14021v1", "summary": "In this paper, we study Byzantine-resilient federated online learning for\nGaussian process regression (GPR). We develop a Byzantine-resilient federated\nGPR algorithm that allows a cloud and a group of agents to collaboratively\nlearn a latent function and improve the learning performances where some agents\nexhibit Byzantine failures, i.e., arbitrary and potentially adversarial\nbehavior. Each agent-based local GPR sends potentially compromised local\npredictions to the cloud, and the cloud-based aggregated GPR computes a global\nmodel by a Byzantine-resilient product of experts aggregation rule. Then the\ncloud broadcasts the current global model to all the agents. Agent-based fused\nGPR refines local predictions by fusing the received global model with that of\nthe agent-based local GPR. Moreover, we quantify the learning accuracy\nimprovements of the agent-based fused GPR over the agent-based local GPR.\nExperiments on a toy example and two medium-scale real-world datasets are\nconducted to demonstrate the performances of the proposed algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14021v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13693", "title": "Gaussian kernel-based motion measurement", "authors": ["Hongyi Liu", "Haifeng Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13693v1", "summary": "The growing demand for structural health monitoring has driven increasing\ninterest in high-precision motion measurement, as structural information\nderived from extracted motions can effectively reflect the current condition of\nthe structure. Among various motion measurement techniques, vision-based\nmethods stand out due to their low cost, easy installation, and large-scale\nmeasurement. However, when it comes to sub-pixel-level motion measurement,\ncurrent vision-based methods either lack sufficient accuracy or require\nextensive manual parameter tuning (e.g., pyramid layers, target pixels, and\nfilter parameters) to reach good precision. To address this issue, we developed\na novel Gaussian kernel-based motion measurement method, which can extract the\nmotion between different frames via tracking the location of Gaussian kernels.\nThe motion consistency, which fits practical structural conditions, and a\nsuper-resolution constraint, are introduced to increase accuracy and robustness\nof our method. Numerical and experimental validations show that it can\nconsistently reach high accuracy without customized parameter setup for\ndifferent test samples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13693v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.01830", "title": "You Don't Have to Live Next to Me: Towards Demobilizing Individualistic Bias in Computational Approaches to Urban Segregation", "authors": ["Anastassia Vybornova", "Trivik Verma"], "categories": ["cs.CY", "physics.soc-ph"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      4 figures; artwork by Namrata Narendra", "url": "http://arxiv.org/abs/2505.01830v2", "summary": "The global surge in social inequalities is one of the most pressing issues of\nour times. The spatial expression of social inequalities at city scale gives\nrise to urban segregation, a common phenomenon across different local and\ncultural contexts. The increasing popularity of Big Data and computational\nmodels has inspired a growing number of computational social science studies\nthat analyze, evaluate, and issue policy recommendations for urban segregation.\nToday's wealth in information and computational power could inform urban\nplanning for equity. However, as we show here, segregation research is\nepistemologically interdependent with prevalent economic theories which\noverfocus on individual responsibility while neglecting systemic processes.\nThis individualistic bias is also engrained in computational models of urban\nsegregation. Through several contemporary examples of how Big Data -- and the\nassumptions underlying its usage -- influence (de)segregation patterns and\npolicies, our essay tells a cautionary tale. We highlight how a lack of\nconsideration for data ethics can lead to the creation of computational models\nthat have a real-life, further marginalizing impact on disadvantaged groups.\nWith this essay, our aim is to develop a better discernment of the pitfalls and\npotentials of computational approaches to urban segregation, thereby fostering\na conscious focus on systemic thinking about urban inequalities. We suggest\nsetting an agenda for research and collective action that is directed at\ndemobilizing individualistic bias, informing our thinking about urban\nsegregation, but also more broadly our efforts to create sustainable cities and\ncommunities.", "comment": "4 figures; artwork by Namrata Narendra", "pdf_url": "http://arxiv.org/pdf/2505.01830v2", "cate": "cs.CY", "date": "2025-05-03", "updated": "2025-07-18"}
{"id": "2507.13534", "title": "Heatwave-driven air conditioning adoption could increase German electricity demand by 14 GW in the near future", "authors": ["Leo Semmelmann", "Frederik vom Scheidt"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures", "url": "http://arxiv.org/abs/2507.13534v1", "summary": "Intensifying heatwaves driven by climate change are accelerating the adoption\nof mobile air conditioning (AC) systems. A rapid mass adoption of such AC\nsystems could create additional stress on electricity grids and the power\nsystem. This study presents a novel method to estimate the electricity demand\nfrom AC systems both at system level and at high temporal and spatial\ngranularity. We apply the method to a near-future heatwave scenario in Germany\nin which household AC adoption increases from current 19% to 35% during a\nheatwave similar to the one of July 2025. We analyze the effects for 196,428\ngrid cells of one square kilometer across Germany, by combining weather data,\ncensus data, socio-demographic assumptions, mobility patterns, and\ntemperature-dependent AC activation functions. We find that electricity demand\nof newly purchased mobile AC systems could increase the peak load by over 14 GW\n(23%), with urban hot-spots reaching 5.8 MW per square kilometer. The temporal\npattern creates a pronounced afternoon peak that coincides with lower\nphotovoltaic generation, potentially exacerbating power system stability\nchallenges. Our findings underscore the urgency for proactive energy system\nplanning to manage emerging demand peaks.", "comment": "10 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.13534v1", "cate": "eess.SY", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13820", "title": "Team of One: Cracking Complex Video QA with Model Synergy", "authors": ["Jun Xie", "Zhaoran Zhao", "Xiongjun Guan", "Yingjian Zhu", "Hongzhu Yi", "Xinming Wang", "Feng Chen", "Zhepeng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13820v1", "summary": "We propose a novel framework for open-ended video question answering that\nenhances reasoning depth and robustness in complex real-world scenarios, as\nbenchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models\n(Video-LMMs) often exhibit limited contextual understanding, weak temporal\nmodeling, and poor generalization to ambiguous or compositional queries. To\naddress these challenges, we introduce a prompting-and-response integration\nmechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)\nvia structured chains of thought, each tailored to distinct reasoning pathways.\nAn external Large Language Model (LLM) serves as an evaluator and integrator,\nselecting and fusing the most reliable responses. Extensive experiments\ndemonstrate that our method significantly outperforms existing baselines across\nall evaluation metrics, showcasing superior generalization and robustness. Our\napproach offers a lightweight, extensible strategy for advancing multimodal\nreasoning without requiring model retraining, setting a strong foundation for\nfuture Video-LMM development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13820v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14038", "title": "DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis", "authors": ["Aileen Luo", "Tao Zhou", "Ming Du", "Martin V. Holt", "Andrej Singer", "Mathew J. Cherukara"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14038v1", "summary": "Coherent X-ray scattering techniques are critical for investigating the\nfundamental structural properties of materials at the nanoscale. While\nadvancements have made these experiments more accessible, real-time analysis\nremains a significant bottleneck, often hindered by artifacts and computational\ndemands. In scanning X-ray nanodiffraction microscopy, which is widely used to\nspatially resolve structural heterogeneities, this challenge is compounded by\nthe convolution of the divergent beam with the sample's local structure. To\naddress this, we introduce DONUT (Diffraction with Optics for Nanobeam by\nUnsupervised Training), a physics-aware neural network designed for the rapid\nand automated analysis of nanobeam diffraction data. By incorporating a\ndifferentiable geometric diffraction model directly into its architecture,\nDONUT learns to predict crystal lattice strain and orientation in real-time.\nCrucially, this is achieved without reliance on labeled datasets or\npre-training, overcoming a fundamental limitation for supervised machine\nlearning in X-ray science. We demonstrate experimentally that DONUT accurately\nextracts all features within the data over 200 times more efficiently than\nconventional fitting methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14038v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13706", "title": "GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms", "authors": ["Ángel F. García-Fernández", "Jinhao Gu", "Lennart Svensson", "Yuxuan Xia", "Jan Krejčí", "Oliver Kost", "Ondřej Straka"], "categories": ["cs.CV", "math.ST", "stat.TH"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13706v1", "summary": "This paper introduces two quasi-metrics for performance assessment of\nmulti-object tracking (MOT) algorithms. In particular, one quasi-metric is an\nextension of the generalised optimal subpattern assignment (GOSPA) metric and\nmeasures the discrepancy between sets of objects. The other quasi-metric is an\nextension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy\nbetween sets of trajectories. Similar to the GOSPA-based metrics, these\nquasi-metrics include costs for localisation error for properly detected\nobjects, the number of false objects and the number of missed objects. The\nT-GOSPA quasi-metric also includes a track switching cost. Differently from the\nGOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of\npenalising missed and false objects with different costs, and the localisation\ncosts are not required to be symmetric. These properties can be useful in MOT\nevaluation in certain applications. The performance of several Bayesian MOT\nalgorithms is assessed with the T-GOSPA quasi-metric via simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13706v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.12057", "title": "Culture is Not Trivia: Sociocultural Theory for Cultural NLP", "authors": ["Naitian Zhou", "David Bamman", "Isaac L. Bleaman"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 Main Conference; camera-ready version", "url": "http://arxiv.org/abs/2502.12057v2", "summary": "The field of cultural NLP has recently experienced rapid growth, driven by a\npressing need to ensure that language technologies are effective and safe\nacross a pluralistic user base. This work has largely progressed without a\nshared conception of culture, instead choosing to rely on a wide array of\ncultural proxies. However, this leads to a number of recurring limitations:\ncoarse national boundaries fail to capture nuanced differences that lay within\nthem, limited coverage restricts datasets to only a subset of usually\nhighly-represented cultures, and a lack of dynamicity results in static\ncultural benchmarks that do not change as culture evolves. In this position\npaper, we argue that these methodological limitations are symptomatic of a\ntheoretical gap. We draw on a well-developed theory of culture from\nsociocultural linguistics to fill this gap by 1) demonstrating in a case study\nhow it can clarify methodological constraints and affordances, 2) offering\ntheoretically-motivated paths forward to achieving cultural competence, and 3)\narguing that localization is a more useful framing for the goals of much\ncurrent work in cultural NLP.", "comment": "ACL 2025 Main Conference; camera-ready version", "pdf_url": "http://arxiv.org/pdf/2502.12057v2", "cate": "cs.CL", "date": "2025-02-17", "updated": "2025-07-17"}
{"id": "2507.13623", "title": "MD-OFDM: An Energy-Efficient and Low-PAPR MIMO-OFDM Variant for Resource-Constrained Applications", "authors": ["Rahul Gulia"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13623v1", "summary": "Orthogonal Frequency Division Multiplexing (OFDM) combined with\nMultiple-Input Multiple-Output (MIMO) techniques forms the backbone of modern\nwireless communication systems. While offering high spectral efficiency and\nrobustness, conventional MIMO-OFDM, especially with complex equalizers like\nMinimum Mean Square Error (MMSE), suffers from high Peak-to-Average Power Ratio\n(PAPR) and significant power consumption due to multiple active Radio Frequency\n(RF) chains. This paper proposes and mathematically models an alternative\nsystem, termed Multi-Dimensional OFDM (MD-OFDM), which employs a per-subcarrier\ntransmit antenna selection strategy. By activating only one transmit antenna\nfor each subcarrier, MD-OFDM aims to reduce PAPR, lower power consumption, and\nimprove Bit Error Rate (BER) performance. We provide detailed mathematical\nformulations for BER, Energy Efficiency (EE), and PAPR, and discuss the\nsuitability of MD-OFDM for various applications, particularly in\nenergy-constrained and cost-sensitive scenarios such as the Internet of Things\n(IoT) and Low-Power Wide Area Networks (LPWAN). Simulation results demonstrate\nthat MD-OFDM achieves superior BER and significantly lower PAPR compared to\nMMSE MIMO, albeit with a trade-off in peak overall energy efficiency due to\nreduced spectral multiplexing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13623v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13822", "title": "RAG-based Architectures for Drug Side Effect Retrieval in LLMs", "authors": ["Shad Nygren", "Pinar Avci", "Andre Daniels", "Reza Rassol", "Afshin Beheshti", "Diego Galeano"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13822v1", "summary": "Drug side effects are a major global health concern, necessitating advanced\nmethods for their accurate detection and analysis. While Large Language Models\n(LLMs) offer promising conversational interfaces, their inherent limitations,\nincluding reliance on black-box training data, susceptibility to\nhallucinations, and lack of domain-specific knowledge, hinder their reliability\nin specialized fields like pharmacovigilance. To address this gap, we propose\ntwo architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which\nintegrate comprehensive drug side effect knowledge into a Llama 3 8B language\nmodel. Through extensive evaluations on 19,520 drug side effect associations\n(covering 976 drugs and 3,851 side effect terms), our results demonstrate that\nGraphRAG achieves near-perfect accuracy in drug side effect retrieval. This\nframework offers a highly accurate and scalable solution, signifying a\nsignificant advancement in leveraging LLMs for critical pharmacovigilance\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13822v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14056", "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training", "authors": ["Alejandro Rodriguez-Garcia", "Anindya Ghosh", "Srikanth Ramaswamy"], "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 5 figures, 1 table, 1 pseudo-code", "url": "http://arxiv.org/abs/2507.14056v1", "summary": "Recent studies in continual learning have identified a transient drop in\nperformance on mastered tasks when assimilating new ones, known as the\nstability gap. Such dynamics contradict the objectives of continual learning,\nrevealing a lack of robustness in mitigating forgetting, and notably,\npersisting even under an ideal joint-loss regime. Examining this gap within\nthis idealized joint training context is critical to isolate it from other\nsources of forgetting. We argue that it reflects an imbalance between rapid\nadaptation and robust retention at task boundaries, underscoring the need to\ninvestigate mechanisms that reconcile plasticity and stability within continual\nlearning frameworks. Biological brains navigate a similar dilemma by operating\nconcurrently on multiple timescales, leveraging neuromodulatory signals to\nmodulate synaptic plasticity. However, artificial networks lack native\nmultitimescale dynamics, and although optimizers like momentum-SGD and Adam\nintroduce implicit timescale regularization, they still exhibit stability gaps.\nInspired by locus coeruleus mediated noradrenergic bursts, which transiently\nenhance neuronal gain under uncertainty to facilitate sensory assimilation, we\npropose uncertainty-modulated gain dynamics - an adaptive mechanism that\napproximates a two-timescale optimizer and dynamically balances integration of\nknowledge with minimal interference on previously consolidated information. We\nevaluate our mechanism on domain-incremental and class-incremental variants of\nthe MNIST and CIFAR benchmarks under joint training, demonstrating that\nuncertainty-modulated gain dynamics effectively attenuate the stability gap.\nFinally, our analysis elucidates how gain modulation replicates noradrenergic\nfunctions in cortical circuits, offering mechanistic insights into reducing\nstability gaps and enhance performance in continual learning tasks.", "comment": "18 pages, 5 figures, 1 table, 1 pseudo-code", "pdf_url": "http://arxiv.org/pdf/2507.14056v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13708", "title": "PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement", "authors": ["Sofia Jamil", "Bollampalli Areen Reddy", "Raghvendra Kumar", "Sriparna Saha", "Koustava Goswami", "K. J. Joseph"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ECAI 2025", "url": "http://arxiv.org/abs/2507.13708v1", "summary": "Recent advancements in text-to-image diffusion models have achieved\nremarkable success in generating realistic and diverse visual content. A\ncritical factor in this process is the model's ability to accurately interpret\ntextual prompts. However, these models often struggle with creative\nexpressions, particularly those involving complex, abstract, or highly\ndescriptive language. In this work, we introduce a novel training-free approach\ntailored to improve image generation for a unique form of creative language:\npoetic verse, which frequently features layered, abstract, and dual meanings.\nOur proposed PoemTale Diffusion approach aims to minimise the information that\nis lost during poetic text-to-image conversion by integrating a multi stage\nprompt refinement loop into Language Models to enhance the interpretability of\npoetic texts. To support this, we adapt existing state-of-the-art diffusion\nmodels by modifying their self-attention mechanisms with a consistent\nself-attention technique to generate multiple consistent images, which are then\ncollectively used to convey the poem's meaning. Moreover, to encourage research\nin the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting\nof 1111 poems sourced from multiple online and offline resources. We engaged a\npanel of poetry experts for qualitative assessments. The results from both\nhuman and quantitative evaluations validate the efficacy of our method and\ncontribute a novel perspective to poem-to-image generation with enhanced\ninformation capture in the generated images.", "comment": "ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.13708v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.13246", "title": "When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models", "authors": ["Julia Mendelsohn", "Ceren Budak"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To appear at ACL 2025. Please cite ACL version when proceedings are available", "url": "http://arxiv.org/abs/2502.13246v2", "summary": "Metaphor, discussing one concept in terms of another, is abundant in politics\nand can shape how people understand important issues. We develop a\ncomputational approach to measure metaphorical language, focusing on\nimmigration discourse on social media. Grounded in qualitative social science\nresearch, we identify seven concepts evoked in immigration discourse (e.g.\n\"water\" or \"vermin\"). We propose and evaluate a novel technique that leverages\nboth word-level and document-level signals to measure metaphor with respect to\nthese concepts. We then study the relationship between metaphor, political\nideology, and user engagement in 400K US tweets about immigration. While\nconservatives tend to use dehumanizing metaphors more than liberals, this\neffect varies widely across concepts. Moreover, creature-related metaphor is\nassociated with more retweets, especially for liberal authors. Our work\nhighlights the potential for computational methods to complement qualitative\napproaches in understanding subtle and implicit language in political\ndiscourse.", "comment": "To appear at ACL 2025. Please cite ACL version when proceedings are\n  available", "pdf_url": "http://arxiv.org/pdf/2502.13246v2", "cate": "cs.CL", "date": "2025-02-18", "updated": "2025-07-18"}
{"id": "2507.13672", "title": "Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations", "authors": ["Hang Zhou", "Tao Meng", "Kun Wang", "Chengrui Shi", "Renhao Mao", "Weijia Wang", "Jiakun Lei"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      15 pages, 18 figures, submitted to TAES", "url": "http://arxiv.org/abs/2507.13672v1", "summary": "This study addresses the challenge of ensuring safe spacecraft proximity\noperations, focusing on collision avoidance between a chaser spacecraft and a\ncomplex-geometry target spacecraft under disturbances. To ensure safety in such\nscenarios, a safe robust control framework is proposed that leverages implicit\nneural representations. To handle arbitrary target geometries without explicit\nmodeling, a neural signed distance function (SDF) is learned from point cloud\ndata via a enhanced implicit geometric regularization method, which\nincorporates an over-apporximation strategy to create a conservative,\nsafety-prioritized boundary. The target's surface is implicitly defined by the\nzero-level set of the learned neural SDF, while the values and gradients\nprovide critical information for safety controller design. This neural SDF\nrepresentation underpins a two-layer hierarchcial safe robust control\nframework: a safe velocity generation layer and a safe robust controller layer.\nIn the first layer, a second-order cone program is formulated to generate\nsafety-guaranteed reference velocity by explicitly incorporating the\nunder-approximation error bound. Furthermore, a circulation inequality is\nintroduced to mitigate the local minimum issues commonly encountered in control\nbarrier function (CBF) methods. The second layer features an integrated\ndisturbance observer and a smooth safety filter explicitly compensating for\nestimation error, bolstering robustness to external disturbances. Extensive\nnumerical simulations and Monte Carlo analysis validate the proposed framework,\ndemonstrating significantly improved safety margins and avoidance of local\nminima compared to conventional CBF approaches.", "comment": "15 pages, 18 figures, submitted to TAES", "pdf_url": "http://arxiv.org/pdf/2507.13672v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13463", "title": "Joint Motion, Angle, and Range Estimation in Near-Field under Array Calibration Imperfections", "authors": ["Ahmed Hussain", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13463v1", "summary": "Ultra-massive multiple-input multiple-output MIMO (UM-MIMO) leverages large\nantenna arrays at high frequencies, transitioning communication paradigm into\nthe radiative near-field (NF), where spherical wavefronts enable full-vector\nestimation of both target location and velocity. However, location and motion\nparameters become inherently coupled in this regime, making their joint\nestimation computationally demanding. To overcome this, we propose a novel\napproach that projects the received two-dimensional space-time signal onto the\nangle-Doppler domain using a two-dimensional discrete Fourier transform\n(2D-DFT). Our analysis reveals that the resulting angular spread is centered at\nthe target's true angle, with its width determined by the target's range.\nSimilarly, transverse motion induces a Doppler spread centered at the true\nradial velocity, with the width of Doppler spread proportional to the\ntransverse velocity. Exploiting these spectral characteristics, we develop a\nlow-complexity algorithm that provides coarse estimates of angle, range, and\nvelocity, which are subsequently refined using one-dimensional multiple signal\nclassification (MUSIC) applied independently to each parameter. The proposed\nmethod enables accurate and efficient estimation of NF target motion\nparameters. Simulation results demonstrate a normalized mean squared error\n(NMSE) of -40 dB for location and velocity estimates compared to maximum\nlikelihood estimation, while significantly reducing computational complexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13463v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13859", "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection", "authors": ["Aleksandr Gashkov", "Aleksandr Perevalov", "Maria Eltsova", "Andreas Both"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Winner of Best Paper Award at the 25th International Conference on Web Engineering (ICWE 2025)", "url": "http://arxiv.org/abs/2507.13859v1", "summary": "Nowadays, the importance of software with natural-language user interfaces\ncannot be underestimated. In particular, in Question Answering (QA) systems,\ngenerating a SPARQL query for a given natural-language question (often named\nQuery Building) from the information retrieved from the same question is the\ncentral task of QA systems working over Knowledge Graphs (KGQA). Due to the\nrise of Large Language Models (LLMs), they are considered a well-suited method\nto increase the quality of the question-answering functionality, as there is\nstill a lot of room for improvement, aiming for enhanced quality and\ntrustworthiness. However, LLMs are trained on web data, where researchers have\nno control over whether the benchmark or the knowledge graph was already\nincluded in the training data. In this paper, we introduce a novel method that\nevaluates the quality of LLMs by generating a SPARQL query from a\nnatural-language question under various conditions: (1) zero-shot SPARQL\ngeneration, (2) with knowledge injection, and (3) with \"anonymized\" knowledge\ninjection. This enables us, for the first time, to estimate the influence of\nthe training data on the QA quality improved by LLMs. Ultimately, this will\nhelp to identify how portable a method is or whether good results might mostly\nbe achieved because a benchmark was already included in the training data (cf.\nLLM memorization). The developed method is portable, robust, and supports any\nknowledge graph; therefore, it could be easily applied to any KGQA or LLM,\ns.t., generating consistent insights into the actual LLM capabilities is\npossible.", "comment": "Winner of Best Paper Award at the 25th International Conference on\n  Web Engineering (ICWE 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13859v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14066", "title": "Preference-based Multi-Objective Reinforcement Learning", "authors": ["Ni Mu", "Yao Luan", "Qing-Shan Jia"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This article has been accepted for publication in IEEE Transactions on Automation Science and Engineering. This is the author's version, which has not been fully edited, and the content may change prior to final publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies", "url": "http://arxiv.org/abs/2507.14066v1", "summary": "Multi-objective reinforcement learning (MORL) is a structured approach for\noptimizing tasks with multiple objectives. However, it often relies on\npre-defined reward functions, which can be hard to design for balancing\nconflicting goals and may lead to oversimplification. Preferences can serve as\nmore flexible and intuitive decision-making guidance, eliminating the need for\ncomplicated reward design. This paper introduces preference-based MORL\n(Pb-MORL), which formalizes the integration of preferences into the MORL\nframework. We theoretically prove that preferences can derive policies across\nthe entire Pareto frontier. To guide policy optimization using preferences, our\nmethod constructs a multi-objective reward model that aligns with the given\npreferences. We further provide theoretical proof to show that optimizing this\nreward model is equivalent to training the Pareto optimal policy. Extensive\nexperiments in benchmark multi-objective tasks, a multi-energy management task,\nand an autonomous driving task on a multi-line highway show that our method\nperforms competitively, surpassing the oracle method, which uses the ground\ntruth reward function. This highlights its potential for practical applications\nin complex real-world systems.", "comment": "This article has been accepted for publication in IEEE Transactions\n  on Automation Science and Engineering. This is the author's version, which\n  has not been fully edited, and the content may change prior to final\n  publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights\n  for text and data mining and training of artificial intelligence and similar\n  technologies", "pdf_url": "http://arxiv.org/pdf/2507.14066v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13719", "title": "Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction", "authors": ["Daniele Pannone", "Alessia Castronovo", "Maurizio Mancini", "Gian Luca Foresti", "Claudio Piciarelli", "Rossana Gabrieli", "Muhammad Yasir Bilal", "Danilo Avola"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13719v1", "summary": "This paper presents an innovative augmented reality pipeline tailored for\nmuseum environments, aimed at recognizing artworks and generating accurate 3D\nmodels from single images. By integrating two complementary pre-trained depth\nestimation models, i.e., GLPN for capturing global scene structure and\nDepth-Anything for detailed local reconstruction, the proposed approach\nproduces optimized depth maps that effectively represent complex artistic\nfeatures. These maps are then converted into high-quality point clouds and\nmeshes, enabling the creation of immersive AR experiences. The methodology\nleverages state-of-the-art neural network architectures and advanced computer\nvision techniques to overcome challenges posed by irregular contours and\nvariable textures in artworks. Experimental results demonstrate significant\nimprovements in reconstruction accuracy and visual realism, making the system a\nhighly robust tool for museums seeking to enhance visitor engagement through\ninteractive digital content.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13719v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.08392", "title": "Multi-Agent LLMs as Ethics Advocates for AI-Based Systems", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08392v2", "summary": "Incorporating ethics into the requirement elicitation process is essential\nfor creating ethically aligned systems. Although eliciting manual ethics\nrequirements is effective, it requires diverse input from multiple\nstakeholders, which can be challenging due to time and resource constraints.\nMoreover, it is often given a low priority in the requirements elicitation\nprocess. This study proposes a framework for generating ethics requirements\ndrafts by introducing an ethics advocate agent in a multi-agent LLM setting.\nThis agent critiques and provides input on ethical issues based on the system\ndescription. The proposed framework is evaluated through two case studies from\ndifferent contexts, demonstrating that it captures the majority of ethics\nrequirements identified by researchers during 30-minute interviews and\nintroduces several additional relevant requirements. However, it also\nhighlights reliability issues in generating ethics requirements, emphasizing\nthe need for human feedback in this sensitive domain. We believe this work can\nfacilitate the broader adoption of ethics in the requirements engineering\nprocess, ultimately leading to more ethically aligned products.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08392v2", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-18"}
{"id": "2507.13678", "title": "Minimum Clustering of Matrices Based on Phase Alignment", "authors": ["Honghao Wu", "Kemi Ding", "Li Qiu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This work has been received by CDC2025", "url": "http://arxiv.org/abs/2507.13678v1", "summary": "Coordinating multi-agent systems requires balancing synchronization\nperformance and controller implementation costs. To this end, we classify\nagents by their intrinsic properties, enabling each group to be controlled by a\nuniform controller and thus reducing the number of unique controller types\nrequired. Existing centralized control methods, despite their capability to\nachieve high synchronization performance with fewer types of controllers,\nsuffer from critical drawbacks such as limited scalability and vulnerability to\nsingle points of failure. On the other hand, distributed control strategies,\nwhere controllers are typically agent-dependent, result in the type of required\ncontrollers increasing proportionally with the size of the system.\n  This paper introduces a novel phase-alignment-based framework to minimize the\ntype of controllers by strategically clustering agents with aligned\nsynchronization behaviors. Leveraging the intrinsic phase properties of complex\nmatrices, we formulate a constrained clustering problem and propose a\nhierarchical optimization method combining recursive exact searches for\nsmall-scale systems and scalable stochastic approximations for large-scale\nnetworks. This work bridges theoretical phase analysis with practical control\nsynthesis, offering a cost-effective solution for large-scale multi-agent\nsystems. The theoretical results applied for the analysis of a 50-agent network\nillustrate the effectiveness of the proposed algorithms.", "comment": "This work has been received by CDC2025", "pdf_url": "http://arxiv.org/pdf/2507.13678v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13520", "title": "Passive Body-Area Electrostatic Field (Human Body Capacitance) for Ubiquitous Computing", "authors": ["Sizhen Bian", "Mengxi Liu", "Paul Lukowicz"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13520v1", "summary": "Passive body-area electrostatic field sensing, also referred to as human body\ncapacitance (HBC), is an energy-efficient and non-intrusive sensing modality\nthat exploits the human body's inherent electrostatic properties to perceive\nhuman behaviors. This paper presents a focused overview of passive HBC sensing,\nincluding its underlying principles, historical evolution, hardware\narchitectures, and applications across research domains. Key challenges, such\nas susceptibility to environmental variation, are discussed to trigger\nmitigation techniques. Future research opportunities in sensor fusion and\nhardware enhancement are highlighted. To support continued innovation, this\nwork provides open-source resources and aims to empower researchers and\ndevelopers to leverage passive electrostatic sensing for next-generation\nwearable and ambient intelligence systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13520v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13868", "title": "When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models", "authors": ["Francesco Ortu", "Zhijing Jin", "Diego Doimo", "Alberto Cazzaniga"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13868v1", "summary": "Vision-language models (VLMs) increasingly leverage diverse knowledge sources\nto address complex tasks, often encountering conflicts between their internal\nparametric knowledge and external information. Knowledge conflicts can result\nin hallucinations and unreliable responses, but the mechanisms governing such\ninteractions remain unknown. To address this gap, we analyze the mechanisms\nthat VLMs use to resolve cross-modal conflicts by introducing a dataset of\nmultimodal counterfactual queries that deliberately contradict internal\ncommonsense knowledge. We localize with logit inspection a small set of heads\nthat control the conflict. Moreover, by modifying these heads, we can steer the\nmodel towards its internal knowledge or the visual inputs. Finally, we show\nthat attention from such heads pinpoints localized image regions driving visual\noverrides, outperforming gradient-based attribution in precision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13868v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14088", "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration", "authors": ["Xiyun Li", "Yining Ding", "Yuhua Jiang", "Yunlong Zhao", "Runpeng Xie", "Shuang Xu", "Yuanhua Ni", "Yiqin Yang", "Bo Xu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14088v1", "summary": "Real-time human-artificial intelligence (AI) collaboration is crucial yet\nchallenging, especially when AI agents must adapt to diverse and unseen human\nbehaviors in dynamic scenarios. Existing large language model (LLM) agents\noften fail to accurately model the complex human mental characteristics such as\ndomain intentions, especially in the absence of direct communication. To\naddress this limitation, we propose a novel dual process multi-scale theory of\nmind (DPMT) framework, drawing inspiration from cognitive science dual process\ntheory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)\nmodule to facilitate robust human partner modeling through mental\ncharacteristic reasoning. Experimental results demonstrate that DPMT\nsignificantly enhances human-AI collaboration, and ablation studies further\nvalidate the contributions of our multi-scale ToM in the slow system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14088v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13722", "title": "Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box", "authors": ["Julia Laubmann", "Johannes Reschke"], "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13722v1", "summary": "In today's digital age, concerns about the dangers of AI-generated images are\nincreasingly common. One powerful tool in this domain is StyleGAN (style-based\ngenerative adversarial networks), a generative adversarial network capable of\nproducing highly realistic synthetic faces. To gain a deeper understanding of\nhow such a model operates, this work focuses on analyzing the inner workings of\nStyleGAN's generator component. Key architectural elements and techniques, such\nas the Equalized Learning Rate, are explored in detail to shed light on the\nmodel's behavior. A StyleGAN model is trained using the PyTorch framework,\nenabling direct inspection of its learned weights. Through pruning, it is\nrevealed that a significant number of these weights can be removed without\ndrastically affecting the output, leading to reduced computational\nrequirements. Moreover, the role of the latent vector -- which heavily\ninfluences the appearance of the generated faces -- is closely examined. Global\nalterations to this vector primarily affect aspects like color tones, while\ntargeted changes to individual dimensions allow for precise manipulation of\nspecific facial features. This ability to finetune visual traits is not only of\nacademic interest but also highlights a serious ethical concern: the potential\nmisuse of such technology. Malicious actors could exploit this capability to\nfabricate convincing fake identities, posing significant risks in the context\nof digital deception and cybercrime.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13722v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13687", "title": "Robust Probability Hypothesis Density Filtering: Theory and Algorithms", "authors": ["Ming Lei", "Shufan Wu"], "categories": ["eess.SY", "cs.SY", "93C95, 93E35, 93E20", "H.4.1"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This version is submitted and in review currently", "url": "http://arxiv.org/abs/2507.13687v1", "summary": "Multi-target tracking (MTT) serves as a cornerstone technology in information\nfusion, yet faces significant challenges in robustness and efficiency when\ndealing with model uncertainties, clutter interference, and target\ninteractions. Conventional approaches like Gaussian Mixture PHD (GM-PHD) and\nCardinalized PHD (CPHD) filters suffer from inherent limitations including\ncombinatorial explosion, sensitivity to birth/death process parameters, and\nnumerical instability. This study proposes an innovative minimax robust PHD\nfiltering framework with four key contributions: (1) A theoretically derived\nrobust GM-PHD recursion algorithm that achieves optimal worst-case error\ncontrol under bounded uncertainties; (2) An adaptive real-time parameter\nadjustment mechanism ensuring stability and error bounds; (3) A generalized\nheavy-tailed measurement likelihood function maintaining polynomial\ncomputational complexity; (4) A novel partition-based credibility weighting\nmethod for extended targets. The research not only establishes rigorous\nconvergence guarantees and proves the uniqueness of PHD solutions, but also\nverifies algorithmic equivalence with standard GM-PHD. Experimental results\ndemonstrate that in high-clutter environments, this method achieves a\nremarkable 32.4% reduction in OSPA error and 25.3% lower cardinality RMSE\ncompared to existing techniques, while maintaining real-time processing\ncapability at 15.3 milliseconds per step. This breakthrough lays a crucial\nfoundation for reliable MTT in safety-critical applications.", "comment": "This version is submitted and in review currently", "pdf_url": "http://arxiv.org/pdf/2507.13687v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13526", "title": "Space Shift Keying-Enabled ISAC for Efficient Debris Detection and Communication in LEO Satellite Networks", "authors": ["Gedeon Ghislain Nkwewo Ngoufo", "Khaled Humadi", "Elham Baladi", "Gunes Karabulut Kurt"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13526v1", "summary": "The proliferation of space debris in low Earth orbit (LEO) presents critical\nchallenges for orbital safety, particularly for satellite constellations.\nIntegrated sensing and communication (ISAC) systems provide a promising dual\nfunction solution by enabling both environmental sensing and data\ncommunication. This study explores the use of space shift keying (SSK)\nmodulation within ISAC frameworks, evaluating its performance when combined\nwith sinusoidal and chirp radar waveforms. SSK is particularly attractive due\nto its low hardware complexity and robust communication performance. Our\nresults demonstrate that both waveforms achieve comparable bit error rate (BER)\nperformance under SSK, validating its effectiveness for ISAC applications.\nHowever, waveform selection significantly affects sensing capability: while the\nsinusoidal waveform supports simpler implementation, its high ambiguity limits\nrange detection. In contrast, the chirp waveform enables range estimation and\nprovides a modest improvement in velocity detection accuracy. These findings\nhighlight the strength of SSK as a modulation scheme for ISAC and emphasize the\nimportance of selecting appropriate waveforms to optimize sensing accuracy\nwithout compromising communication performance. This insight supports the\ndesign of efficient and scalable ISAC systems for space applications,\nparticularly in the context of orbital debris monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13526v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13880", "title": "Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision", "authors": ["Marten Kreis", "Benjamin Kiefer"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13880v1", "summary": "This paper presents a novel approach to enhancing marine vision by fusing\nreal-time visual data with chart information. Our system overlays nautical\nchart data onto live video feeds by accurately matching detected navigational\naids, such as buoys, with their corresponding representations in chart data. To\nachieve robust association, we introduce a transformer-based end-to-end neural\nnetwork that predicts bounding boxes and confidence scores for buoy queries,\nenabling the direct matching of image-domain detections with world-space chart\nmarkers. The proposed method is compared against baseline approaches, including\na ray-casting model that estimates buoy positions via camera projection and a\nYOLOv7-based network extended with a distance estimation module. Experimental\nresults on a dataset of real-world maritime scenes demonstrate that our\napproach significantly improves object localization and association accuracy in\ndynamic and challenging environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13880v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14121", "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective", "authors": ["Pankaj Yadav", "Vivek Vijay"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 Pages, 4 figures", "url": "http://arxiv.org/abs/2507.14121v1", "summary": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in\nneural computation that offer a mathematically grounded alternative to standard\nneural networks. This study presents an empirical evaluation of KANs in context\nof class imbalanced classification, using ten benchmark datasets. We observe\nthat KANs can inherently perform well on raw imbalanced data more effectively\nthan Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,\nconventional imbalance strategies fundamentally conflict with KANs mathematical\nstructure as resampling and focal loss implementations significantly degrade\nKANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from\nprohibitive computational costs without proportional performance gains.\nStatistical validation confirms that MLPs with imbalance techniques achieve\nequivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.\nThese findings reveal that KANs represent a specialized solution for raw\nimbalanced data where resources permit. But their severe performance-resource\ntradeoffs and incompatibility with standard resampling techniques currently\nlimits practical deployment. We identify critical research priorities as\ndeveloping KAN specific architectural modifications for imbalance learning,\noptimizing computational efficiency, and theoretical reconciling their conflict\nwith data augmentation. This work establishes foundational insights for next\ngeneration KAN architectures in imbalanced classification scenarios.", "comment": "9 Pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14121v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13753", "title": "Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis", "authors": ["Tongtong Su", "Chengyu Wang", "Bingyan Liu", "Jun Huang", "Dongming Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13753v1", "summary": "In recent years, large text-to-video (T2V) synthesis models have garnered\nconsiderable attention for their abilities to generate videos from textual\ndescriptions. However, achieving both high imaging quality and effective motion\nrepresentation remains a significant challenge for these T2V models. Existing\napproaches often adapt pre-trained text-to-image (T2I) models to refine video\nframes, leading to issues such as flickering and artifacts due to\ninconsistencies across frames. In this paper, we introduce EVS, a training-free\nEncapsulated Video Synthesizer that composes T2I and T2V models to enhance both\nvisual fidelity and motion smoothness of generated videos. Our approach\nutilizes a well-trained diffusion-based T2I model to refine low-quality video\nframes by treating them as out-of-distribution samples, effectively optimizing\nthem with noising and denoising steps. Meanwhile, we employ T2V backbones to\nensure consistent motion dynamics. By encapsulating the T2V temporal-only prior\ninto the T2I generation process, EVS successfully leverages the strengths of\nboth types of models, resulting in videos of improved imaging and motion\nquality. Experimental results validate the effectiveness of our approach\ncompared to previous approaches. Our composition process also leads to a\nsignificant improvement of 1.6x-4.5x speedup in inference time. Source codes:\nhttps://github.com/Tonniia/EVS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13753v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13908", "title": "A Robust Periodic Controller for Spacecraft Attitude Tracking", "authors": ["Frederik Thiele", "Felix Biertümpfel", "Harald Pfifer"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Presented at European Control Conference 2025", "url": "http://arxiv.org/abs/2507.13908v1", "summary": "This paper presents a novel approach for robust periodic attitude control of\nsatellites. Respecting the periodicity of the satellite dynamics in the\nsynthesis allows to achieve constant performance and robustness requirements\nover the orbit. The proposed design follows a mixed sensitivity control design\nemploying a physically motivated weighting scheme. The controller is calculated\nusing a novel structured linear time-periodic output feedback synthesis with\nguaranteed optimal L2-performance. The synthesis poses a convex optimization\nproblem and avoids grid-wise evaluations of coupling conditions inherent for\nclassical periodic H-infinity-synthesis. Moreover, the controller has a\ntransparent and easy to implement structure. A solar power plant satellite is\nused to demonstrate the effectiveness of the proposed method for periodic\nsatellite attitude control.", "comment": "Presented at European Control Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.13908v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13554", "title": "Sensing and Stopping Interfering Secondary Users: Validation of an Efficient Spectrum Sharing System", "authors": ["Meles Weldegebriel", "Zihan Li", "Dustin Maas", "Greg Hellbourg", "Ning Zhang", "Neal Patwari"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13554v1", "summary": "We present the design and validation of Stoppable Secondary Use (StopSec), a\nprivacy-preserving protocol with the capability to identify a secondary user\n(SU) causing interference to a primary user (PU) and to act quickly to stop the\ninterference. All users are served by a database that provides a feedback\nmechanism from a PU to an interfering SU. We introduce a new lightweight and\nrobust method to watermark an SU's OFDM packet. Through extensive over-the-air\nreal-time experiments, we evaluate StopSec in terms of interference detection,\nidentification, and stopping latency, as well as impact on SUs. We show that\nthe watermarking method avoids negative impact to the secondary data link and\nis robust to real-world time-varying channels. Interfering SUs can be stopped\nin under 150 milliseconds, and when multiple users are simultaneously\ninterfering, they can all be stopped. Even when the interference is 10 dB lower\nthan the noise power, StopSec successfully stops interfering SUs within a few\nseconds of their appearance in the channel. StopSec can be an effective\nspectrum sharing protocol for cases when interference to a PU must be quickly\nand automatically stopped.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13554v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13913", "title": "Political Leaning and Politicalness Classification of Texts", "authors": ["Matous Volf", "Jakub Simko"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13913v1", "summary": "This paper addresses the challenge of automatically classifying text\naccording to political leaning and politicalness using transformer models. We\ncompose a comprehensive overview of existing datasets and models for these\ntasks, finding that current approaches create siloed solutions that perform\npoorly on out-of-distribution texts. To address this limitation, we compile a\ndiverse dataset by combining 12 datasets for political leaning classification\nand creating a new dataset for politicalness by extending 18 existing datasets\nwith the appropriate label. Through extensive benchmarking with leave-one-in\nand leave-one-out methodologies, we evaluate the performance of existing models\nand train new ones with enhanced generalization capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13913v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14126", "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition", "authors": ["Jianhong Chen", "Meng Zhao", "Mostafa Reisi Gahrooei", "Xubo Yue"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14126v1", "summary": "Temporal causal representation learning is a powerful tool for uncovering\ncomplex patterns in observational studies, which are often represented as\nlow-dimensional time series. However, in many real-world applications, data are\nhigh-dimensional with varying input lengths and naturally take the form of\nirregular tensors. To analyze such data, irregular tensor decomposition is\ncritical for extracting meaningful clusters that capture essential information.\nIn this paper, we focus on modeling causal representation learning based on the\ntransformed information. First, we present a novel causal formulation for a set\nof latent clusters. We then propose CaRTeD, a joint learning framework that\nintegrates temporal causal representation learning with irregular tensor\ndecomposition. Notably, our framework provides a blueprint for downstream tasks\nusing the learned tensor factors, such as modeling latent structures and\nextracting causal information, and offers a more flexible regularization design\nto enhance tensor decomposition. Theoretically, we show that our algorithm\nconverges to a stationary point. More importantly, our results fill the gap in\ntheoretical guarantees for the convergence of state-of-the-art irregular tensor\ndecomposition. Experimental results on synthetic and real-world electronic\nhealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from both\nphenotyping and network recovery perspectives, demonstrate that our proposed\nmethod outperforms state-of-the-art techniques and enhances the explainability\nof causal representations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14126v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13772", "title": "Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification", "authors": ["Abhijit Sen", "Giridas Maiti", "Bikram K. Parida", "Bhanu P. Mishra", "Mahima Arya", "Denys I. Bondar"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13772v1", "summary": "Feature engineering continues to play a critical role in image\nclassification, particularly when interpretability and computational efficiency\nare prioritized over deep learning models with millions of parameters. In this\nstudy, we revisit classical machine learning based image classification through\na novel approach centered on Permutation Entropy (PE), a robust and\ncomputationally lightweight measure traditionally used in time series analysis\nbut rarely applied to image data. We extend PE to two-dimensional images and\npropose a multiscale, multi-orientation entropy-based feature extraction\napproach that characterizes spatial order and complexity along rows, columns,\ndiagonals, anti-diagonals, and local patches of the image. To enhance the\ndiscriminatory power of the entropy features, we integrate two classic image\ndescriptors: the Histogram of Oriented Gradients (HOG) to capture shape and\nedge structure, and Local Binary Patterns (LBP) to encode micro-texture of an\nimage. The resulting hand-crafted feature set, comprising of 780 dimensions, is\nused to train Support Vector Machine (SVM) classifiers optimized through grid\nsearch. The proposed approach is evaluated on multiple benchmark datasets,\nincluding Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers\ncompetitive classification performance without relying on deep architectures.\nOur results demonstrate that the fusion of PE with HOG and LBP provides a\ncompact, interpretable, and effective alternative to computationally expensive\nand limited interpretable deep learning models. This shows a potential of\nentropy-based descriptors in image classification and contributes a lightweight\nand generalizable solution to interpretable machine learning in image\nclassification and computer vision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13772v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13931", "title": "Identifiability Analysis of a Pseudo-Two-Dimensional Model & Single Particle Model-Aided Parameter Estimation", "authors": ["L. D. Couto", "K. Haghverdi", "F. Guo", "K. Trad", "G. Mulder"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures, This work has been presented at the 2025 American Control Conference (ACC) and will appear in the conference proceedings. \\c{opyright} 2025 IEEE", "url": "http://arxiv.org/abs/2507.13931v1", "summary": "This contribution presents a parameter identification methodology for the\naccurate and fast estimation of model parameters in a pseudo-two-dimensional\n(P2D) battery model. The methodology consists of three key elements. First, the\ndata for identification is inspected and specific features herein that need to\nbe captured are included in the model. Second, the P2D model is analyzed to\nassess the identifiability of the physical model parameters and propose\nalternative parameterizations that alleviate possible issues. Finally, diverse\noperating conditions are considered that excite distinct battery dynamics which\nallows the use of different low-order battery models accordingly. Results show\nthat, under low current conditions, the use of low-order models achieve\nparameter estimates at least 500 times faster than using the P2D model at the\nexpense of twice the error. However, if accuracy is a must, these estimated\nparameters can be used to initialize the P2D model and perform the\nidentification in half of the time.", "comment": "9 pages, 2 figures, This work has been presented at the 2025 American\n  Control Conference (ACC) and will appear in the conference proceedings.\n  \\c{opyright} 2025 IEEE", "pdf_url": "http://arxiv.org/pdf/2507.13931v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13637", "title": "Towards channel foundation models (CFMs): Motivations, methodologies and opportunities", "authors": ["Jun Jiang", "Yuan Gao", "Xinyi Wu", "Shugong Xu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2507.13637v1", "summary": "Artificial intelligence (AI) has emerged as a pivotal enabler for\nnext-generation wireless communication systems. However, conventional AI-based\nmodels encounter several limitations, such as heavy reliance on labeled data,\nlimited generalization capability, and task-specific design. To address these\nchallenges, this paper introduces, for the first time, the concept of channel\nfoundation models (CFMs)-a novel and unified framework designed to tackle a\nwide range of channel-related tasks through a pretrained, universal channel\nfeature extractor. By leveraging advanced AI architectures and self-supervised\nlearning techniques, CFMs are capable of effectively exploiting large-scale\nunlabeled data without the need for extensive manual annotation. We further\nanalyze the evolution of AI methodologies, from supervised learning and\nmulti-task learning to self-supervised learning, emphasizing the distinct\nadvantages of the latter in facilitating the development of CFMs. Additionally,\nwe provide a comprehensive review of existing studies on self-supervised\nlearning in this domain, categorizing them into generative, discriminative and\nthe combined paradigms. Given that the research on CFMs is still at an early\nstage, we identify several promising future research directions, focusing on\nmodel architecture innovation and the construction of high-quality, diverse\nchannel datasets.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2507.13637v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13941", "title": "Convergent transformations of visual representation in brains and models", "authors": ["Pablo Marcos-Manchón", "Lluís Fuentemilla"], "categories": ["q-bio.NC", "cs.AI", "cs.CV", "eess.IV", "I.2.10"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      for associate code, see this https URL", "url": "http://arxiv.org/abs/2507.13941v1", "summary": "A fundamental question in cognitive neuroscience is what shapes visual\nperception: the external world's structure or the brain's internal\narchitecture. Although some perceptual variability can be traced to individual\ndifferences, brain responses to naturalistic stimuli evoke similar activity\npatterns across individuals, suggesting a convergent representational\nprinciple. Here, we test if this stimulus-driven convergence follows a common\ntrajectory across people and deep neural networks (DNNs) during its\ntransformation from sensory to high-level internal representations. We\nintroduce a unified framework that traces representational flow by combining\ninter-subject similarity with alignment to model hierarchies. Applying this\nframework to three independent fMRI datasets of visual scene perception, we\nreveal a cortex-wide network, conserved across individuals, organized into two\npathways: a medial-ventral stream for scene structure and a lateral-dorsal\nstream tuned for social and biological content. This functional organization is\ncaptured by the hierarchies of vision DNNs but not language models, reinforcing\nthe specificity of the visual-to-semantic transformation. These findings show a\nconvergent computational solution for visual encoding in both human and\nartificial vision, driven by the structure of the external world.", "comment": "for associate code, see\n  https://github.com/memory-formation/convergent-transformations", "pdf_url": "http://arxiv.org/pdf/2507.13941v1", "cate": "q-bio.NC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12182", "title": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices", "authors": ["Ievgenii Afanasiev", "Leonid Berlyand", "Mariia Kiyashko"], "categories": ["math-ph", "cs.LG", "math.MP", "math.PR", "60B20, 15B52"], "primary_category": "Subjects:       Mathematical Physics (math-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 3 figures", "url": "http://arxiv.org/abs/2507.12182v1", "summary": "The paper is concerned with deformed Wigner random matrices. These matrices\nare closely connected with Deep Neural Networks (DNNs): weight matrices of\ntrained DNNs could be represented in the form $R + S$, where $R$ is random and\n$S$ is highly correlated. The spectrum of such matrices plays a key role in\nrigorous underpinning of the novel pruning technique based on Random Matrix\nTheory. Mathematics has been done only for finite-rank matrix $S$. However, in\npractice rank may grow. In this paper we develop asymptotic analysis for the\ncase of growing rank.", "comment": "14 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.12182v1", "cate": "math-ph", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13773", "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions", "authors": ["Pu Jian", "Donglei Yu", "Wen Yang", "Shuo Ren", "Jiajun Zhang"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACL2025 Main", "url": "http://arxiv.org/abs/2507.13773v1", "summary": "In visual question answering (VQA) context, users often pose ambiguous\nquestions to visual language models (VLMs) due to varying expression habits.\nExisting research addresses such ambiguities primarily by rephrasing questions.\nThese approaches neglect the inherently interactive nature of user interactions\nwith VLMs, where ambiguities can be clarified through user feedback. However,\nresearch on interactive clarification faces two major challenges: (1)\nBenchmarks are absent to assess VLMs' capacity for resolving ambiguities\nthrough interaction; (2) VLMs are trained to prefer answering rather than\nasking, preventing them from seeking clarification. To overcome these\nchallenges, we introduce \\textbf{ClearVQA} benchmark, which targets three\ncommon categories of ambiguity in VQA context, and encompasses various VQA\nscenarios.", "comment": "ACL2025 Main", "pdf_url": "http://arxiv.org/pdf/2507.13773v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13982", "title": "Diffraction and Scattering Modeling for Laser Power Beaming in Lunar Environment", "authors": ["Yanni Jiwan-Mercier", "Barış Dönmez", "Güneş Karabulut-Kurt", "Sébastien Loranger"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2507.13982v1", "summary": "Reliable energy delivery is a critical requirement for\n  long-term lunar missions, particularly in regions with limited\n  solar access, such as polar craters and during extended lunar\n  nights. Optical Power Beaming (OPB) using high-power lasers\n  offers a promising alternative to conventional solar power, but\n  the effects of suspended lunar dust on beam propagation remain\n  poorly understood. This study introduces a detailed simulation\n  model that incorporates both diffraction and height-dependent\n  scattering by the electrostatically suspended lunar regolith. Un like prior\napproaches, which assumed uniform dust layers or\n  center-to-center transmission loss, our model uses generalized\n  diffraction theory and refractive index gradients derived from\n  particle density to assess beam deformation and attenuation. The\n  results show that even in ground-to-ground scenarios, lunar dust\n  significantly degrades energy transfer efficiency, dropping from\n  57% to 3.7% over 50 km in dust-free vs. dusty conditions with\n  175 nm particles. Increasing the particle size to 250 nm limits the\n  viable transmission range to below 30 km at 6% efficiency. The\n  study further demonstrates that raising the laser source height\n  can improve efficiency, achieving 91% for a distance of 5 km\n  and 25% at 50 km when the source is positioned 12 m above\n  ground. These findings underscore the importance of system\n  elevation and dust modeling in lunar OPB design and reveal\n  the mission-critical role of particle size distribution, especially in\n  environments disturbed by human activity.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.13982v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13748", "title": "Elastic Buffer Design for Real-Time All-Digital Clock Recovery Enabling Free-Running Receiver Clock with Negative and Positive Clock Frequency Offsets", "authors": ["Patrick Matalla", "Joel Dittmer", "Md Salek Mahmud", "Christian Koos", "Sebastian Randel"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13748v1", "summary": "We present an elastic buffer design that enables all-digital clock recovery\nimplementation with free-running receiver clock featuring negative and positive\nclock frequency offsets. Error-free real-time data transmission is demonstrated\nfrom -400 ppm to +400 ppm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13748v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13384", "title": "Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation", "authors": ["Osama Hardan", "Omar Elshenhabi", "Tamer Khattab", "Mohamed Mabrok"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Submitted to the 2025 IEEE International Conference on Future Machine Learning and Data Science (FMLDS)", "url": "http://arxiv.org/abs/2507.13384v1", "summary": "Vision Mamba models promise transformer-level performance at linear\ncomputational cost, but their reliance on serializing 2D images into 1D\nsequences introduces a critical, yet overlooked, design choice: the patch scan\norder. In medical imaging, where modalities like brain MRI contain strong\nanatomical priors, this choice is non-trivial. This paper presents the first\nsystematic study of how scan order impacts MRI segmentation. We introduce\nMulti-Scan 2D (MS2D), a parameter-free module for Mamba-based architectures\nthat facilitates exploring diverse scan paths without additional computational\ncost. We conduct a large-scale benchmark of 21 scan strategies on three public\ndatasets (BraTS 2020, ISLES 2022, LGG), covering over 70,000 slices. Our\nanalysis shows conclusively that scan order is a statistically significant\nfactor (Friedman test: $\\chi^{2}_{20}=43.9, p=0.0016$), with performance\nvarying by as much as 27 Dice points. Spatially contiguous paths -- simple\nhorizontal and vertical rasters -- consistently outperform disjointed diagonal\nscans. We conclude that scan order is a powerful, cost-free hyperparameter, and\nprovide an evidence-based shortlist of optimal paths to maximize the\nperformance of Mamba models in medical imaging.", "comment": "Submitted to the 2025 IEEE International Conference on Future Machine\n  Learning and Data Science (FMLDS)", "pdf_url": "http://arxiv.org/pdf/2507.13384v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13942", "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion", "authors": ["Jacob C Walker", "Pedro Vélez", "Luisa Polania Cabrera", "Guangyao Zhou", "Rishabh Kabra", "Carl Doersch", "Maks Ovsjanikov", "João Carreira", "Shiry Ginosar"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13942v1", "summary": "Forecasting what will happen next is a critical skill for general-purpose\nsystems that plan or act in the world at different levels of abstraction. In\nthis paper, we identify a strong correlation between a vision model's\nperceptual ability and its generalist forecasting performance over short time\nhorizons. This trend holds across a diverse set of pretrained models-including\nthose trained generatively-and across multiple levels of abstraction, from raw\npixels to depth, point tracks, and object motion. The result is made possible\nby a novel generalist forecasting framework that operates on any frozen vision\nbackbone: we train latent diffusion models to forecast future features in the\nfrozen representation space, which are then decoded via lightweight,\ntask-specific readouts. To enable consistent evaluation across tasks, we\nintroduce distributional metrics that compare distributional properties\ndirectly in the space of downstream tasks and apply this framework to nine\nmodels and four tasks. Our results highlight the value of bridging\nrepresentation learning and generative modeling for temporally grounded video\nunderstanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13942v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13376", "title": "Physics-guided impact localisation and force estimation in composite plates with uncertainty quantification", "authors": ["Dong Xiao", "Zahra Sharif-Khodaei", "M. H. Aliabadi"], "categories": ["physics.data-an", "cond-mat.mtrl-sci", "cs.LG", "physics.app-ph"], "primary_category": "Subjects:       Data Analysis, Statistics and Probability (physics.data-an)", "pdf_link": null, "comments": "Comments:      37 pages (including the appendix and references), 16 figures", "url": "http://arxiv.org/abs/2507.13376v1", "summary": "Physics-guided approaches offer a promising path toward accurate and\ngeneralisable impact identification in composite structures, especially when\nexperimental data are sparse. This paper presents a hybrid framework for impact\nlocalisation and force estimation in composite plates, combining a data-driven\nimplementation of First-Order Shear Deformation Theory (FSDT) with machine\nlearning and uncertainty quantification. The structural configuration and\nmaterial properties are inferred from dispersion relations, while boundary\nconditions are identified via modal characteristics to construct a low-fidelity\nbut physically consistent FSDT model. This model enables physics-informed data\naugmentation for extrapolative localisation using supervised learning.\nSimultaneously, an adaptive regularisation scheme derived from the same model\nimproves the robustness of impact force reconstruction. The framework also\naccounts for uncertainty by propagating localisation uncertainty through the\nforce estimation process, producing probabilistic outputs. Validation on\ncomposite plate experiments confirms the framework's accuracy, robustness, and\nefficiency in reducing dependence on large training datasets. The proposed\nmethod offers a scalable and transferable solution for impact monitoring and\nstructural health management in composite aerostructures.", "comment": "37 pages (including the appendix and references), 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.13376v1", "cate": "physics.data-an", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.13779", "title": "SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering", "authors": ["Durgesh Singh", "Ahcène Boubekki", "Robert Jenssen", "Michael Kampffmeyer"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13779v1", "summary": "Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)\nenhance the model performance by exploiting information from labeled and\nunlabeled data. The clustering assumption has proven advantageous for learning\nwith limited supervision and states that data points belonging to the same\ncluster in a high-dimensional space should be assigned to the same category.\nRecent works have utilized different training mechanisms to implicitly enforce\nthis assumption for the SSL and UDA. In this work, we take a different approach\nby explicitly involving a differentiable clustering module which is extended to\nleverage the supervised data to compute its centroids. We demonstrate the\neffectiveness of our straightforward end-to-end training strategy for SSL and\nUDA over extensive experiments and highlight its benefits, especially in low\nsupervision regimes, both as a standalone model and as a regularizer for\nexisting approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13779v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14004", "title": "Smart fault detection in satellite electrical power system", "authors": ["Niloofar Nobahari", "Alireza Rezaee"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14004v1", "summary": "This paper presents an new approach for detecting in the electrical power\nsystem of satellites operating in Low Earth Orbit (LEO) without an Attitude\nDetermination and Control Subsystem (ADCS). Components of these systems are\nprone to faults, such as line-to-line faults in the photovoltaic subsystem,\nopen circuits, and short circuits in the DC-to-DC converter, as well as ground\nfaults in batteries. In the previous research has largely focused on detecting\nfaults in each components, such as photovoltaic arrays or converter systems,\ntherefore, has been limited attention given to whole electrical power system of\nsatellite as a whole system. Our approach addresses this gap by utilizing a\nMulti-Layer Perceptron (MLP) neural network model, which leverages input data\nsuch as solar radiation and surface temperature to predict current and load\noutputs. These machine learning techniques that classifiy use different\napproaches like Principal Component Analysis (PCA) and K-Nearest Neighbors\n(KNN), to classify faults effectively. The model presented achieves over 99%\naccuracy in identifying faults across multiple subsystems, marking a notable\nadvancement from previous approaches by offering a complete diagnostic solution\nfor the entire satellite power system. This thorough method boosts system\nreliability and helps lower the chances of mission failure", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14004v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13766", "title": "ISAC: From Human to Environmental Sensing", "authors": ["Kai Wu", "Zhongqin Wang", "Shu-Lin Chen", "J. Andrew Zhang", "Y. Jay Guo"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      15 pages, 8 figures", "url": "http://arxiv.org/abs/2507.13766v1", "summary": "Integrated Sensing and Communications (ISAC) is poised to become one of the\ndefining capabilities of the sixth generation (6G) wireless communications\nsystems, enabling the network infrastructure to jointly support high-throughput\ncommunications and situational awareness. While recent advances have explored\nISAC for both human-centric applications and environmental monitoring, existing\nresearch remains fragmented across these domains. This paper provides the first\nunified review of ISAC-enabled sensing for both human activities and\nenvironment, focusing on signal-level mechanisms, sensing features, and\nreal-world feasibility. We begin by characterising how diverse physical\nphenomena, ranging from human vital sign and motion to precipitation and flood\ndynamics, impact wireless signal propagation, producing measurable signatures\nin channel state information (CSI), Doppler profiles, and signal statistics. A\ncomprehensive analysis is then presented across two domains: human sensing\napplications including localisation, activity recognition, and vital sign\nmonitoring; and environmental sensing for rainfall, soil moisture, and water\nlevel. Experimental results from Long-Term Evolution (LTE) sensing under\nnon-line-of-sight (NLOS) conditions are incorporated to highlight the\nfeasibility in infrastructure-limited scenarios. Open challenges in signal\nfusion, domain adaptation, and generalisable sensing architectures are\ndiscussed to facilitate future research toward scalable and autonomous ISAC.", "comment": "15 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.13766v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13394", "title": "Enhanced DeepLab Based Nerve Segmentation with Optimized Tuning", "authors": ["Akhil John Thomas", "Christiaan Boerkamp"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13394v1", "summary": "Nerve segmentation is crucial in medical imaging for precise identification\nof nerve structures. This study presents an optimized DeepLabV3-based\nsegmentation pipeline that incorporates automated threshold fine-tuning to\nimprove segmentation accuracy. By refining preprocessing steps and implementing\nparameter optimization, we achieved a Dice Score of 0.78, an IoU of 0.70, and a\nPixel Accuracy of 0.95 on ultrasound nerve imaging. The results demonstrate\nsignificant improvements over baseline models and highlight the importance of\ntailored parameter selection in automated nerve detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13394v1", "cate": "eess.IV", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13949", "title": "Exploiting Primacy Effect To Improve Large Language Models", "authors": ["Bianca Raimondi", "Maurizio Gabbrielli"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by RANLP 2025", "url": "http://arxiv.org/abs/2507.13949v1", "summary": "Large Language Models (LLMs) have become essential in many Natural Language\nProcessing (NLP) tasks, leveraging extensive pre-training and fine-tuning to\nachieve high accuracy. However, like humans, LLMs exhibit biases, particularly\npositional biases such as primacy and recency effects, which can influence the\naccuracy of the answers. The primacy effect-where items presented first are\nmore likely to be remembered or selected-plays a key role in Multiple Choice\nQuestion Answering (MCQA), where the order of answer options can affect\nprediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We\nfirst show that fine-tuning amplifies this bias, probably due to exposure to\nhuman-like patterns. Hence, we strategically leverage this effect by reordering\nresponse options based on semantic similarity to the query, without requiring\nknowledge of the correct answer. Our experimental results show that this\napproach significantly improves performance in MCQA. More generally, our\nfindings underscore the dual nature of biases as both challenges and\nopportunities, offering insights for bias-aware model design and NLP\napplications.", "comment": "Accepted by RANLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.13949v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13381", "title": "SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation", "authors": ["Rafiq Kamel", "Filippo Guerranti", "Simon Geisler", "Stephan Günnemann"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "url": "http://arxiv.org/abs/2507.13381v1", "summary": "Large Language Models (LLMs) are increasingly applied to tasks involving\nstructured inputs such as graphs. Abstract Meaning Representations (AMRs),\nwhich encode rich semantics as directed graphs, offer a rigorous testbed for\nevaluating LLMs on text generation from such structures. Yet, current methods\noften arbitrarily linearize AMRs, discarding key structural cues, or rely on\narchitectures incompatible with standard LLMs. We introduce SAFT, a\nstructure-aware fine-tuning approach that injects graph topology into\npretrained LLMs without architectural changes. We compute direction-sensitive\npositional encodings from the magnetic Laplacian of transformed AMRs and\nproject them into the embedding space of the LLM. While possibly applicable to\nany graph-structured inputs, we focus on AMR-to-text generation as a\nrepresentative and challenging benchmark. SAFT sets a new state-of-the-art on\nAMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph\ncomplexity, highlighting the value of structure-aware representations in\nenhancing LLM performance. SAFT offers a general and effective pathway for\nbridging structured data and language models.", "comment": "Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "pdf_url": "http://arxiv.org/pdf/2507.13381v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13797", "title": "DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance", "authors": ["Huu-Phu Do", "Yu-Wei Chen", "Yi-Cheng Liao", "Chi-Wei Hsiao", "Han-Yang Wang", "Wei-Chen Chiu", "Ching-Chun Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.13797v1", "summary": "Blind Face Restoration aims to recover high-fidelity, detail-rich facial\nimages from unknown degraded inputs, presenting significant challenges in\npreserving both identity and detail. Pre-trained diffusion models have been\nincreasingly used as image priors to generate fine details. Still, existing\nmethods often use fixed diffusion sampling timesteps and a global guidance\nscale, assuming uniform degradation. This limitation and potentially imperfect\ndegradation kernel estimation frequently lead to under- or over-diffusion,\nresulting in an imbalance between fidelity and quality. We propose\nDynFaceRestore, a novel blind face restoration approach that learns to map any\nblindly degraded input to Gaussian blurry images. By leveraging these blurry\nimages and their respective Gaussian kernels, we dynamically select the\nstarting timesteps for each blurry image and apply closed-form guidance during\nthe diffusion sampling process to maintain fidelity. Additionally, we introduce\na dynamic guidance scaling adjuster that modulates the guidance strength across\nlocal regions, enhancing detail generation in complex areas while preserving\nstructural fidelity in contours. This strategy effectively balances the\ntrade-off between fidelity and quality. DynFaceRestore achieves\nstate-of-the-art performance in both quantitative and qualitative evaluations,\ndemonstrating robustness and effectiveness in blind face restoration.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.13797v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14020", "title": "Influence of Cell Position on the Capacity of Retired Batteries: Experimental and Statistical Studies", "authors": ["Marwan Hassini", "Colette Mintsa-Eya", "Eduardo Redondo-Iglesias", "Pascal Venet"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, IECON 2025", "url": "http://arxiv.org/abs/2507.14020v1", "summary": "Understanding how batteries perform after automotive use is crucial to\ndetermining their potential for reuse. This article presents experimental\nresults aimed at advancing knowledge of retired battery performance. Three\nmodules extracted from electric vehicles were tested. Their performance was\nassessed, and the results were analyzed statistically using analysis of\nvariance (ANOVA). The 36 retired cells exhibited a high level of performance,\nalbeit with significant variation. On average, the cells had a 95% state of\nhealth capacity with a dispersion of 2.4%. ANOVA analysis suggests that cell\nperformance is not correlated with their position inside the module. These\nresults demonstrate the need to evaluate dispersion within retired batteries\nand to develop thermal management and balancing systems for second-life\nbatteries.", "comment": "5 pages, 4 figures, IECON 2025", "pdf_url": "http://arxiv.org/pdf/2507.14020v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13826", "title": "Simulation for Noncontact Radar-Based Physiological Sensing Using Depth-Camera-Derived Human 3D Model with Electromagnetic Scattering Analysis", "authors": ["Kimitaka Sumi", "Takuya Sakamoto"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      10 pages, 9 figures, 6 tables. This work is going to be submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.13826v1", "summary": "This study proposes a method for simulating signals received by\nfrequency-modulated continuous-wave radar during respiratory monitoring, using\nhuman body geometry and displacement data acquired via a depth camera. Unlike\nprevious studies that rely on simplified models of body geometry or\ndisplacement, the proposed approach models high-frequency scattering centers\nbased on realistic depth-camera-measured body shapes and motions. Experiments\nwere conducted with six participants under varying conditions, including\nvarying target distances, seating orientations, and radar types, with\nsimultaneous acquisition from the radar and depth camera. Relative to\nconventional model-based methods, the proposed technique achieved improvements\nof 7.5%, 58.2%, and 3.2% in the correlation coefficients of radar images,\ndisplacements, and spectrograms, respectively. This work contributes to the\ngeneration of radar-based physiological datasets through simulation and\nenhances our understanding of factors affecting the accuracy of non-contact\nsensing.", "comment": "10 pages, 9 figures, 6 tables. This work is going to be submitted to\n  the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.13826v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13458", "title": "Domain-randomized deep learning for neuroimage analysis", "authors": ["Malte Hoffmann"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures, 2 tables, deep learning, domain generalization, domain randomization, neuroimaging, medical image analysis, accepted for publication in IEEE Signal Processing Magazine", "url": "http://arxiv.org/abs/2507.13458v1", "summary": "Deep learning has revolutionized neuroimage analysis by delivering\nunprecedented speed and accuracy. However, the narrow scope of many training\ndatasets constrains model robustness and generalizability. This challenge is\nparticularly acute in magnetic resonance imaging (MRI), where image appearance\nvaries widely across pulse sequences and scanner hardware. A recent\ndomain-randomization strategy addresses the generalization problem by training\ndeep neural networks on synthetic images with randomized intensities and\nanatomical content. By generating diverse data from anatomical segmentation\nmaps, the approach enables models to accurately process image types unseen\nduring training, without retraining or fine-tuning. It has demonstrated\neffectiveness across modalities including MRI, computed tomography, positron\nemission tomography, and optical coherence tomography, as well as beyond\nneuroimaging in ultrasound, electron and fluorescence microscopy, and X-ray\nmicrotomography. This tutorial paper reviews the principles, implementation,\nand potential of the synthesis-driven training paradigm. It highlights key\nbenefits, such as improved generalization and resistance to overfitting, while\ndiscussing trade-offs such as increased computational demands. Finally, the\narticle explores practical considerations for adopting the technique, aiming to\naccelerate the development of generalizable tools that make deep learning more\naccessible to domain experts without extensive computational resources or\nmachine learning knowledge.", "comment": "12 pages, 6 figures, 2 tables, deep learning, domain generalization,\n  domain randomization, neuroimaging, medical image analysis, accepted for\n  publication in IEEE Signal Processing Magazine", "pdf_url": "http://arxiv.org/pdf/2507.13458v1", "cate": "eess.IV", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13957", "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation", "authors": ["Yitong Li", "Raoul Grasman"], "categories": ["cs.IR", "cs.AI", "cs.LG", "68T05, 68T50, 62M45", "H.3.3; I.2.6; H.3.4; I.2.7"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2507.13957v1", "summary": "The modern recommender systems are facing an increasing challenge of\nmodelling and predicting the dynamic and context-rich user preferences.\nTraditional collaborative filtering and content-based methods often struggle to\ncapture the temporal patternings and evolving user intentions. While Large\nLanguage Models (LLMs) have gained gradual attention in recent years, by their\nstrong semantic understanding and reasoning abilities, they are not inherently\ndesigned to model chronologically evolving user preference and intentions. On\nthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) which\nis good at capturing the temporal dynamics of user behaviour and evolving user\npreference over time, but still lacks a rich semantic understanding for\ncomprehensive recommendation generation. In this study, we propose DUALRec\n(Dynamic User-Aware Language-based Recommender), a novel recommender that\nleverages the complementary strength of both models, which combines the\ntemporal modelling abilities of LSTM networks with semantic reasoning power of\nthe fine-tuned Large Language Models. The LSTM component will capture users\nevolving preference through their viewing history, while the fine-tuned LLM\nvariants will leverage these temporal user insights to generate next movies\nthat users might enjoy. Experimental results on MovieLens-1M dataset shows that\nthe DUALRec model outperforms a wide range of baseline models, with\ncomprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted\nCumulative Gain (NDCG@k), and genre similarity metrics. This research proposes\na novel architecture that bridges the gap between temporal sequence modeling\nand semantic reasoning, and offers a promising direction for developing more\nintelligent and context-aware recommenders.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13957v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13382", "title": "Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case", "authors": ["Chandrashekar Muniyappa", "Sirisha Velampalli"], "categories": ["cs.CL", "cs.LG", "05-05C12"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      CSAIDE '25: Proceedings of the 2025 4th International Conference on Cyber Security, Artificial Intelligence and the Digital Economy", "url": "http://arxiv.org/abs/2507.13382v1", "summary": "In today\\'s digital world, fake news is spreading with immense speed. Its a\nsignificant concern to address. In this work, we addressed that challenge using\nnovel graph based approach. We took dataset from Kaggle that contains real and\nfake news articles. To test our approach we incorporated recent covid-19\nrelated news articles that contains both genuine and fake news that are\nrelevant to this problem. This further enhances the dataset as well instead of\nrelying completely on the original dataset. We propose a contextual graph-based\napproach to detect fake news articles. We need to convert news articles into\nappropriate schema, so we leverage Natural Language Processing (NLP) techniques\nto transform news articles into contextual graph structures. We then apply the\nMinimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)\nalgorithm for graph mining. Graph-based methods are particularly effective for\nhandling rich contextual data, as they enable the discovery of complex patterns\nthat traditional query-based or statistical techniques might overlook. Our\nproposed approach identifies normative patterns within the dataset and\nsubsequently uncovers anomalous patterns that deviate from these established\nnorms.", "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "pdf_url": "http://arxiv.org/pdf/2507.13382v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13803", "title": "GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation", "authors": ["Weiqi Yang", "Xu Zhou", "Jingfu Guan", "Hao Du", "Tianyu Bai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13803v1", "summary": "Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely\ndeployed in smart homes, intelligent transport, industrial automation, and\nhealthcare. However, existing systems often face challenges: high model\ncomplexity hinders deployment in resource-constrained environments,\nunidirectional modal alignment neglects inter-modal relationships, and\nrobustness suffers when sensor data is missing. These issues impede efficient\nand robust multimodal perception in real-world IoT settings. To overcome these\nlimitations, we propose GRAM-MAMBA. This framework utilizes the\nlinear-complexity Mamba model for efficient sensor time-series processing,\ncombined with an optimized GRAM matrix strategy for pairwise alignment among\nmodalities, addressing the shortcomings of traditional single-modality\nalignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive\nlow-rank layer compensation strategy to handle missing modalities\npost-training. This strategy freezes the pre-trained model core and irrelevant\nadaptive layers, fine-tuning only those related to available modalities and the\nfusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On\nthe SPAWC2021 indoor positioning dataset, the pre-trained model shows lower\nerror than baselines; adapting to missing modalities yields a 24.5% performance\nboost by training less than 0.2% of parameters. On the USC-HAD human activity\nrecognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),\noutperforming prior work; the update strategy increases F1 by 23% while\ntraining less than 0.3% of parameters. These results highlight GRAM-MAMBA's\npotential for achieving efficient and robust multimodal perception in\nresource-constrained environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13803v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14025", "title": "Reference-Free Iterative Learning Model Predictive Control with Neural Certificates", "authors": ["Wataru Hashimoto", "Kazumune Hashimoto", "Masako Kishida", "Shigemasa Takai"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This paper was submitted to IET Control Theory & Applications on May 19, 2025 (under review)", "url": "http://arxiv.org/abs/2507.14025v1", "summary": "In this paper, we propose a novel reference-free iterative learning model\npredictive control (MPC). In the proposed method, a certificate function based\non the concept of Control Lyapunov Barrier Function (CLBF) is learned using\ndata collected from past control executions and used to define the terminal set\nand cost in the MPC optimization problem at the current iteration. This scheme\nenables the progressive refinement of the MPC's terminal components over\nsuccessive iterations. Unlike existing methods that rely on mixed-integer\nprogramming and suffer from numerical difficulties, the proposed approach\nformulates the MPC optimization problem as a standard nonlinear program,\nenabling more efficient online computation. The proposed method satisfies key\nMPC properties, including recursive feasibility and asymptotic stability.\nAdditionally, we demonstrate that the performance cost is non-increasing with\nrespect to the number of iterations, under certain assumptions. Numerical\nexperiments including the simulation with PyBullet confirm that our control\nscheme iteratively enhances control performance and significantly improves\nonline computational efficiency compared to the existing methods.", "comment": "This paper was submitted to IET Control Theory & Applications on May\n  19, 2025 (under review)", "pdf_url": "http://arxiv.org/pdf/2507.14025v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13829", "title": "On two fundamental properties of the zeros of spectrograms of noisy signals", "authors": ["Arnaud Poinas", "Rémi Bardenet"], "categories": ["eess.SP", "math.PR"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13829v1", "summary": "The spatial distribution of the zeros of the spectrogram is significantly\naltered when a signal is added to white Gaussian noise. The zeros tend to\ndelineate the support of the signal, and deterministic structures form in the\npresence of interference, as if the zeros were trapped. While sophisticated\nmethods have been proposed to detect signals as holes in the pattern of\nspectrogram zeros, few formal arguments have been made to support the\ndelineation and trapping effects. Through detailed computations for simple toy\nsignals, we show that two basic mathematical arguments, the intensity of zeros\nand Rouch\\'e's theorem, allow discussing delineation and trapping, and the\ninfluence of parameters like the signal-to-noise ratio. In particular,\ninterfering chirps, even nearly superimposed, yield an easy-to-detect\ndeterministic structure among zeros.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13829v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13782", "title": "Converting T1-weighted MRI from 3T to 7T quality using deep learning", "authors": ["Malo Gicquel", "Ruoyi Zhao", "Anika Wuestefeld", "Nicola Spotorno", "Olof Strandberg", "Kalle Åström", "Yu Xiao", "Laura EM Wisse", "Danielle van Westen", "Rik Ossenkoppele", "Niklas Mattsson-Carlgren", "David Berron", "Oskar Hansson", "Gabrielle Flood", "Jacob Vogel"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13782v1", "summary": "Ultra-high resolution 7 tesla (7T) magnetic resonance imaging (MRI) provides\ndetailed anatomical views, offering better signal-to-noise ratio, resolution\nand tissue contrast than 3T MRI, though at the cost of accessibility. We\npresent an advanced deep learning model for synthesizing 7T brain MRI from 3T\nbrain MRI. Paired 7T and 3T T1-weighted images were acquired from 172\nparticipants (124 cognitively unimpaired, 48 impaired) from the Swedish\nBioFINDER-2 study. To synthesize 7T MRI from 3T images, we trained two models:\na specialized U-Net, and a U-Net integrated with a generative adversarial\nnetwork (GAN U-Net). Our models outperformed two additional state-of-the-art\n3T-to-7T models in image-based evaluation metrics. Four blinded MRI\nprofessionals judged our synthetic 7T images as comparable in detail to real 7T\nimages, and superior in subjective visual quality to 7T images, apparently due\nto the reduction of artifacts. Importantly, automated segmentations of the\namygdalae of synthetic GAN U-Net 7T images were more similar to manually\nsegmented amygdalae (n=20), than automated segmentations from the 3T images\nthat were used to synthesize the 7T images. Finally, synthetic 7T images showed\nsimilar performance to real 3T images in downstream prediction of cognitive\nstatus using MRI derivatives (n=3,168). In all, we show that synthetic\nT1-weighted brain images approaching 7T quality can be generated from 3T\nimages, which may improve image quality and segmentation, without compromising\nperformance in downstream tasks. Future directions, possible clinical use\ncases, and limitations are discussed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13782v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13966", "title": "Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need", "authors": ["Bhishma Dedhia", "Yuval Kansal", "Niraj K. Jha"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13966v1", "summary": "Language models traditionally used for cross-domain generalization have\nrecently demonstrated task-specific reasoning. However, their top-down training\napproach on general corpora is insufficient for acquiring abstractions needed\nfor deep domain expertise. This may require a bottom-up approach that acquires\nexpertise by learning to compose simple domain concepts into more complex ones.\nA knowledge graph (KG) provides this compositional structure, where domain\nprimitives are represented as head-relation-tail edges and their paths encode\nhigher-level concepts. We present a task generation pipeline that synthesizes\ntasks directly from KG primitives, enabling models to acquire and compose them\nfor reasoning. We fine-tune language models on the resultant KG-grounded\ncurriculum to demonstrate domain-specific superintelligence. While broadly\napplicable, we validate our approach in medicine, where reliable KGs exist.\nUsing a medical KG, we curate 24,000 reasoning tasks paired with thinking\ntraces derived from diverse medical primitives. We fine-tune the QwQ-32B model\non this curriculum to obtain QwQ-Med-3 that takes a step towards medical\nsuperintelligence. We also introduce ICD-Bench, an evaluation suite to quantify\nreasoning abilities across 15 medical domains. Our experiments demonstrate that\nQwQ-Med-3 significantly outperforms state-of-the-art reasoning models on\nICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired\nprimitives to widen the performance gap on the hardest tasks of ICD-Bench.\nFinally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3\ntransfers acquired expertise to enhance the base model's performance. While the\nindustry's approach to artificial general intelligence (AGI) emphasizes broad\nexpertise, we envision a future in which AGI emerges from the composable\ninteraction of efficient domain-specific superintelligent agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13966v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13390", "title": "PARAM-1 BharatGen 2.9B Model", "authors": ["Kundeshwar Pundalik", "Piyush Sawarkar", "Nihar Sahoo", "Abhishek Shinde", "Prateek Chanda", "Vedant Goswami", "Ajay Nagpal", "Atul Singh", "Viraj Thakur", "Vijay Dewane", "Aamod Thakur", "Bhargav Patel", "Smita Gautam", "Bhagwan Panditi", "Shyam Pawar", "Madhav Kotcha", "Suraj Racha", "Saral Sureka", "Pankaj Singh", "Rishi Bal", "Rohit Saluja", "Ganesh Ramakrishnan"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13390v1", "summary": "Large Language Models (LLMs) have emerged as powerful general-purpose\nreasoning systems, yet their development remains dominated by English-centric\ndata, architectures, and optimization paradigms. This exclusionary design\nresults in structural under-representation of linguistically diverse regions\nsuch as India, where over 20 official languages and 100+ dialects coexist\nalongside phenomena like code-switching and diglossia. We introduce PARAM-1, a\n2.9B parameter decoder-only, text-only language model trained from scratch with\nan explicit architectural and linguistic focus on Indian diversity. PARAM-1 is\ntrained on a bilingual dataset consisting of only Hindi and English,\nconstructed with a strong focus on fact-rich, high-quality content. It is\nguided by three core principles: equitable representation of Indic languages\nthrough a 25% corpus allocation; tokenization fairness via a SentencePiece\ntokenizer adapted to Indian morphological structures; and culturally aligned\nevaluation benchmarks across IndicQA, code-mixed reasoning, and\nsocio-linguistic robustness tasks. By embedding diversity at the pretraining\nlevel-rather than deferring it to post-hoc alignment-PARAM-1 offers a\ndesign-first blueprint for equitable foundation modeling. Our results\ndemonstrate that it serves as both a competent general-purpose model and a\nrobust baseline for India-centric applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13390v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.13812", "title": "SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing", "authors": ["Yingying Zhang", "Lixiang Ru", "Kang Wu", "Lei Yu", "Lei Liang", "Yansheng Li", "Jingdong Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV25", "url": "http://arxiv.org/abs/2507.13812v1", "summary": "The multi-modal remote sensing foundation model (MM-RSFM) has significantly\nadvanced various Earth observation tasks, such as urban planning, environmental\nmonitoring, and natural disaster management. However, most existing approaches\ngenerally require the training of separate backbone networks for each data\nmodality, leading to redundancy and inefficient parameter utilization.\nMoreover, prevalent pre-training methods typically apply self-supervised\nlearning (SSL) techniques from natural images without adequately accommodating\nthe characteristics of remote sensing (RS) images, such as the complicated\nsemantic distribution within a single RS image. In this work, we present\nSkySense V2, a unified MM-RSFM that employs a single transformer backbone to\nhandle multiple modalities. This backbone is pre-trained with a novel SSL\nstrategy tailored to the distinct traits of RS data. In particular, SkySense V2\nincorporates an innovative adaptive patch merging module and learnable modality\nprompt tokens to address challenges related to varying resolutions and limited\nfeature diversity across modalities. In additional, we incorporate the mixture\nof experts (MoE) module to further enhance the performance of the foundation\nmodel. SkySense V2 demonstrates impressive generalization abilities through an\nextensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense\nby an average of 1.8 points.", "comment": "Accepted by ICCV25", "pdf_url": "http://arxiv.org/pdf/2507.13812v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14052", "title": "Physics-guided gated recurrent units for inversion-based feedforward control", "authors": ["Mingdao Lin", "Max Bolderman", "Mircea Lazar"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.14052v1", "summary": "Inversion-based feedforward control relies on an accurate model that\ndescribes the inverse system dynamics. The gated recurrent unit (GRU), which is\na recent architecture in recurrent neural networks, is a strong candidate for\nobtaining such a model from data. However, due to their black-box nature, GRUs\nface challenges such as limited interpretability and vulnerability to\noverfitting. Recently, physics-guided neural networks (PGNNs) have been\nintroduced, which integrate the prior physical model structure into the\nprediction process. This approach not only improves training convergence, but\nalso facilitates the learning of a physics-based model. In this work, we\nintegrate a GRU in the PGNN framework to obtain a PG-GRU, based on which we\nadopt a two-step approach to feedforward control design. First, we adopt stable\ninversion techniques to design a stable linear model of the inverse dynamics.\nThen, a GRU trained on the residual is tailored to inverse system\nidentification. The resulting PG-GRU feedforward controller is validated by\nmeans of real-life experiments on a two-mass spring-damper system, where it\ndemonstrates roughly a two-fold improvement compared to the linear feedforward\nand a preview-based GRU feedforward in terms of the integral absolute error.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.14052v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13938", "title": "Device-Free Localization Using Commercial UWB Transceivers", "authors": ["Hyun Seok Lee"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures, preprint", "url": "http://arxiv.org/abs/2507.13938v1", "summary": "Recently, commercial ultra-wideband (UWB) transceivers have enabled not only\nmeasuring device-to-device distance but also tracking the position of a\npedestrian who does not carry a UWB device. UWB-based device-free localization\nthat does not require dedicated radar equipment is compatible with existing\nanchor infrastructure and can be reused to reduce hardware deployment costs.\nHowever, it is difficult to estimate the target's position accurately in\nreal-world scenarios due to the low signal-to-noise ratio (SNR) and the\ncluttered environment. In this paper, we propose a deep learning (DL)-assisted\nparticle filter to overcome these challenges. First, the channel impulse\nresponse (CIR) variance is analyzed to capture the variability induced by the\ntarget's movement. Then, a DL-based one-dimensional attention U-Net is used to\nextract only the reflection components caused by the target and suppress the\nnoise components within the CIR variance profile. Finally, multiple\npreprocessed CIR variance profiles are used as input to a particle filter to\nestimate the target's position. Experimental results demonstrate that the\nproposed system is a practical and cost-effective solution for IoT and\nautomotive applications with a root mean square error (RMSE) of about 15 cm and\nan average processing time of 4 ms. Furthermore, comparisons with existing\nstate-of-the-art methods show that the proposed method provides the best\nperformance with reasonable computational costs.", "comment": "8 pages, 10 figures, preprint", "pdf_url": "http://arxiv.org/pdf/2507.13938v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13830", "title": "Divide and Conquer: A Large-Scale Dataset and Model for Left-Right Breast MRI Segmentation", "authors": ["Maximilian Rokuss", "Benjamin Hamm", "Yannick Kirchhoff", "Klaus Maier-Hein"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at MICCAI 2025 WOMEN", "url": "http://arxiv.org/abs/2507.13830v1", "summary": "We introduce the first publicly available breast MRI dataset with explicit\nleft and right breast segmentation labels, encompassing more than 13,000\nannotated cases. Alongside this dataset, we provide a robust deep-learning\nmodel trained for left-right breast segmentation. This work addresses a\ncritical gap in breast MRI analysis and offers a valuable resource for the\ndevelopment of advanced tools in women's health. The dataset and trained model\nare publicly available at: www.github.com/MIC-DKFZ/BreastDivider", "comment": "Accepted at MICCAI 2025 WOMEN", "pdf_url": "http://arxiv.org/pdf/2507.13830v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13984", "title": "CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models", "authors": ["Quang-Binh Nguyen", "Minh Luu", "Quang Nguyen", "Anh Tran", "Khoi Nguyen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.13984v1", "summary": "Disentangling content and style from a single image, known as content-style\ndecomposition (CSD), enables recontextualization of extracted content and\nstylization of extracted styles, offering greater creative flexibility in\nvisual synthesis. While recent personalization methods have explored the\ndecomposition of explicit content style, they remain tailored for diffusion\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\npromising alternative with a next-scale prediction paradigm, achieving\nperformance comparable to that of diffusion models. In this paper, we explore\nVAR as a generative framework for CSD, leveraging its scale-wise generation\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\nmethod that introduces three key innovations: (1) a scale-aware alternating\noptimization strategy that aligns content and style representation with their\nrespective scales to enhance separation, (2) an SVD-based rectification method\nto mitigate content leakage into style representations, and (3) an Augmented\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\nthis task, we introduce CSD-100, a dataset specifically designed for\ncontent-style decomposition, featuring diverse subjects rendered in various\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\napproaches, achieving superior content preservation and stylization fidelity.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.13984v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13480", "title": "Multiresolution local smoothness detection in non-uniformly sampled multivariate signals", "authors": ["Sara Avesani", "Gianluca Giacchi", "Michael Multerer"], "categories": ["math.NA", "cs.CV", "cs.LG", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13480v1", "summary": "Inspired by edge detection based on the decay behavior of wavelet\ncoefficients, we introduce a (near) linear-time algorithm for detecting the\nlocal regularity in non-uniformly sampled multivariate signals. Our approach\nquantifies regularity within the framework of microlocal spaces introduced by\nJaffard. The central tool in our analysis is the fast samplet transform, a\ndistributional wavelet transform tailored to scattered data. We establish a\nconnection between the decay of samplet coefficients and the pointwise\nregularity of multivariate signals. As a by product, we derive decay estimates\nfor functions belonging to classical H\\\"older spaces and Sobolev-Slobodeckij\nspaces. While traditional wavelets are effective for regularity detection in\nlow-dimensional structured data, samplets demonstrate robust performance even\nfor higher dimensional and scattered data. To illustrate our theoretical\nfindings, we present extensive numerical studies detecting local regularity of\none-, two- and three-dimensional signals, ranging from non-uniformly sampled\ntime series over image segmentation to edge detection in point clouds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13480v1", "cate": "math.NA", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13852", "title": "A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data", "authors": ["Luigi Russo", "Francesco Mauro", "Babak Memar", "Alessandro Sebastianelli", "Silvia Liberata Ullo", "Paolo Gamba"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Joint Urban Remote Sensing Event (JURSE) 2025", "url": "http://arxiv.org/abs/2507.13852v1", "summary": "Building segmentation in urban areas is essential in fields such as urban\nplanning, disaster response, and population mapping. Yet accurately segmenting\nbuildings in dense urban regions presents challenges due to the large size and\nhigh resolution of satellite images. This study investigates the use of a\nQuanvolutional pre-processing to enhance the capability of the Attention U-Net\nmodel in the building segmentation. Specifically, this paper focuses on the\nurban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)\nimagery. In this work, Quanvolution was used to extract more informative\nfeature maps that capture essential structural details in radar imagery,\nproving beneficial for accurate building segmentation. Preliminary results\nindicate that proposed methodology achieves comparable test accuracy to the\nstandard Attention U-Net model while significantly reducing network parameters.\nThis result aligns with findings from previous works, confirming that\nQuanvolution not only maintains model accuracy but also increases computational\nefficiency. These promising outcomes highlight the potential of\nquantum-assisted Deep Learning frameworks for large-scale building segmentation\nin urban environments.", "comment": "Accepted at IEEE Joint Urban Remote Sensing Event (JURSE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.13852v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14073", "title": "Convex computation of regions of attraction from data using Sums-of-Squares programming", "authors": ["Oumayma Khattabi", "Matteo Tacchi-Bénard", "Sorin Olaru"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14073v1", "summary": "The paper concentrates on the analysis of the region of attraction (ROA) for\nunknown autonomous dynamical systems. The aim is to explore a data-driven\napproach based on moment-sum-of-squares (SoS) hierarchy, which enables novel\nRoA outer approximations despite the reduced information on the structure of\nthe dynamics. The main contribution of this work is bypassing the system model\nand, consequently, the recurring constraint on its polynomial structure.\nNumerical experimentation showcases the influence of data on learned\napproximating sets, offering a promising outlook on the potential of this\nmethod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14073v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14018", "title": "Distortion-Aware Hybrid Beamforming for Integrated Sensing and Communication", "authors": ["Zeyuan Zhang", "Yue Xiu", "Phee Lep Yeoh", "Guangyi Liu", "Zixing Wu", "Ning Wei"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14018v1", "summary": "This paper investigates a practical partially-connected hybrid beamforming\ntransmitter for integrated sensing and communication (ISAC) with distortion\nfrom nonlinear power amplification. For this ISAC system, we formulate a\ncommunication rate and sensing mutual information maximization problem driven\nby our distortion-aware hybrid beamforming design. To address this non-convex\nproblem, we first solve for a fully digital beamforming matrix by alternatively\nsolving three sub-problems using manifold optimization (MO) and our derived\nclosed-form solutions. The analog and digital beamforming matrices are then\nobtained through a decomposition algorithm. Numerical results demonstrate that\nthe proposed algorithm can improve overall ISAC performance compared to\ntraditional beamforming methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14018v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13901", "title": "Software architecture and manual for novel versatile CT image analysis toolbox -- AnatomyArchive", "authors": ["Lei Xu", "Torkel B Brismar"], "categories": ["eess.IV", "cs.CV", "62H35, 68U10", "I.4.10; I.4.7; J.3"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      24 pages, 7 figures", "url": "http://arxiv.org/abs/2507.13901v1", "summary": "We have developed a novel CT image analysis package named AnatomyArchive,\nbuilt on top of the recent full body segmentation model TotalSegmentator. It\nprovides automatic target volume selection and deselection capabilities\naccording to user-configured anatomies for volumetric upper- and lower-bounds.\nIt has a knowledge graph-based and time efficient tool for anatomy segmentation\nmask management and medical image database maintenance. AnatomyArchive enables\nautomatic body volume cropping, as well as automatic arm-detection and\nexclusion, for more precise body composition analysis in both 2D and 3D\nformats. It provides robust voxel-based radiomic feature extraction, feature\nvisualization, and an integrated toolchain for statistical tests and analysis.\nA python-based GPU-accelerated nearly photo-realistic segmentation-integrated\ncomposite cinematic rendering is also included. We present here its software\narchitecture design, illustrate its workflow and working principle of\nalgorithms as well provide a few examples on how the software can be used to\nassist development of modern machine learning models. Open-source codes will be\nreleased at https://github.com/lxu-medai/AnatomyArchive for only research and\neducational purposes.", "comment": "24 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.13901v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13626", "title": "Unifying Listener Scoring Scales: Comparison Learning Framework for Speech Quality Assessment and Continuous Speech Emotion Recognition", "authors": ["Cheng-Hung Hu", "Yusuke Yasud", "Akifumi Yoshimoto", "Tomoki Toda"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2507.13626v1", "summary": "Speech Quality Assessment (SQA) and Continuous Speech Emotion Recognition\n(CSER) are two key tasks in speech technology, both relying on listener\nratings. However, these ratings are inherently biased due to individual\nlistener factors. Previous approaches have introduced a mean listener scoring\nscale and modeled all listener scoring scales in the training set. However, the\nmean listener approach is prone to distortion from averaging ordinal data,\nleading to potential biases. Moreover, learning multiple listener scoring\nscales while inferring based only on the mean listener scale limits\neffectiveness. In contrast, our method focuses on modeling a unified listener\nscoring scale, using comparison scores to correctly capture the scoring\nrelationships between utterances. Experimental results show that our method\neffectively improves prediction performance in both SQA and CSER tasks, proving\nits effectiveness and robustness.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.13626v1", "cate": "eess.AS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13993", "title": "OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models", "authors": ["Ningyong Wu", "Jinzhi Wang", "Wenhong Zhao", "Chenzhan Yu", "Zhigang Xiu", "Duwei Dai"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13993v1", "summary": "The growing volume of medical imaging data has increased the need for\nautomated diagnostic tools, especially for musculoskeletal injuries like rib\nfractures, commonly detected via CT scans. Manual interpretation is\ntime-consuming and error-prone. We propose OrthoInsight, a multi-modal deep\nlearning framework for rib fracture diagnosis and report generation. It\nintegrates a YOLOv9 model for fracture detection, a medical knowledge graph for\nretrieving clinical context, and a fine-tuned LLaVA language model for\ngenerating diagnostic reports. OrthoInsight combines visual features from CT\nimages with expert textual data to deliver clinically useful outputs. Evaluated\non 28,675 annotated CT images and expert reports, it achieves high performance\nacross Diagnostic Accuracy, Content Completeness, Logical Coherence, and\nClinical Guidance Value, with an average score of 4.28, outperforming models\nlike GPT-4 and Claude-3. This study demonstrates the potential of multi-modal\nlearning in transforming medical image analysis and providing effective support\nfor radiologists.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13993v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13580", "title": "A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design", "authors": ["Hao Tuo", "Yan Li", "Xuanning Hu", "Haishi Zhao", "Xueyan Liu", "Bo Yang"], "categories": ["q-bio.BM", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13580v1", "summary": "Combinatorial optimization algorithm is essential in computer-aided drug\ndesign by progressively exploring chemical space to design lead compounds with\nhigh affinity to target protein. However current methods face inherent\nchallenges in integrating domain knowledge, limiting their performance in\nidentifying lead compounds with novel and valid binding mode. Here, we propose\nAutoLeadDesign, a lead compounds design framework that inspires extensive\ndomain knowledge encoded in large language models with chemical fragments to\nprogressively implement efficient exploration of vast chemical space. The\ncomprehensive experiments indicate that AutoLeadDesign outperforms baseline\nmethods. Significantly, empirical lead design campaigns targeting two\nclinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate\nAutoLeadDesign's competence in de novo generation of lead compounds achieving\nexpert-competitive design efficacy. Structural analysis further confirms their\nmechanism-validated inhibitory patterns. By tracing the process of design, we\nfind that AutoLeadDesign shares analogous mechanisms with fragment-based drug\ndesign which traditionally rely on the expert decision-making, further\nrevealing why it works. Overall, AutoLeadDesign offers an efficient approach\nfor lead compounds design, suggesting its potential utility in drug design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13580v1", "cate": "q-bio.BM", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13861", "title": "PositionIC: Unified Position and Identity Consistency for Image Customization", "authors": ["Junjie Hu", "Tianyang Han", "Kai Ma", "Jialin Gao", "Hao Dou", "Song Yang", "Xianhua He", "Jianhui Zhang", "Junfeng Luo", "Xiaoming Wei", "Wenqiang Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13861v1", "summary": "Recent subject-driven image customization has achieved significant\nadvancements in fidelity, yet fine-grained entity-level spatial control remains\nelusive, hindering the broader real-world application. This limitation is\nmainly attributed to scalable datasets that bind identity with precise\npositional cues are absent. To this end, we introduce PositionIC, a unified\nframework that enforces position and identity consistency for multi-subject\ncustomization. We construct a scalable synthesis pipeline that employs a\nbidirectional generation paradigm to eliminate subject drift and maintain\nsemantic coherence. On top of these data, we design a lightweight positional\nmodulation layer that decouples spatial embeddings among subjects, enabling\nindependent, accurate placement while preserving visual fidelity. Extensive\nexperiments demonstrate that our approach can achieve precise spatial control\nwhile maintaining high consistency in image customization task. PositionIC\npaves the way for controllable, high-fidelity image customization in\nopen-world, multi-entity scenarios and will be released to foster further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13861v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14117", "title": "Integrating Forecasting Models Within Steady-State Analysis and Optimization", "authors": ["Aayushya Agarwal", "Larry Pileggi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14117v1", "summary": "Extreme weather variations and the increasing unpredictability of load\nbehavior make it difficult to determine power grid dispatches that are robust\nto uncertainties. While machine learning (ML) methods have improved the ability\nto model uncertainty caused by loads and renewables, accurately integrating\nthese forecasts and their sensitivities into steady-state analyses and\ndecision-making strategies remains an open challenge. Toward this goal, we\npresent a generalized methodology that seamlessly embeds ML-based forecasting\nengines within physics-based power flow and grid optimization tools. By\ncoupling physics-based grid modeling with black-box ML methods, we accurately\ncapture the behavior and sensitivity of loads and weather events by directly\nintegrating the inputs and outputs of trained ML forecasting models into the\nnumerical methods of power flow and grid optimization. Without fitting\nsurrogate load models, our approach obtains the sensitivities directly from\ndata to accurately predict the response of forecasted devices to changes in the\ngrid. Our approach combines the sensitivities of forecasted devices attained\nvia backpropagation and the sensitivities of physics-defined grid devices. We\ndemonstrate the efficacy of our method by showcasing improvements in\nsensitivity calculations and leveraging them to design a robust power dispatch\nthat improves grid reliability under stochastic weather events. Our approach\nenables the computation of system sensitivities to exogenous factors which\nsupports broader analyses that improve grid reliability in the presence of load\nvariability and extreme weather conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14117v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14035", "title": "Toward Practical Fluid Antenna Systems: Co-Optimizing Hardware and Software for Port Selection and Beamforming", "authors": ["Sai Xu", "Kai-Kit Wong", "Yanan Du", "Hanjiang Hong", "Chan-Byoung Chae", "Baiyang Liu", "Kin-Fai Tong"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14035v1", "summary": "This paper proposes a hardware-software co-design approach to efficiently\noptimize beamforming and port selection in fluid antenna systems (FASs). To\nbegin with, a fluid-antenna (FA)-enabled downlink multi-cell multiple-input\nmultiple-output (MIMO) network is modeled, and a weighted sum-rate (WSR)\nmaximization problem is formulated. Second, a method that integrates graph\nneural networks (GNNs) with random port selection (RPS) is proposed to jointly\noptimize beamforming and port selection, while also assessing the benefits and\nlimitations of random selection. Third, an instruction-driven deep learning\naccelerator based on a field-programmable gate array (FPGA) is developed to\nminimize inference latency. To further enhance efficiency, a scheduling\nalgorithm is introduced to reduce redundant computations and minimize the idle\ntime of computing cores. Simulation results demonstrate that the proposed\nGNN-RPS approach achieves competitive communication performance. Furthermore,\nexperimental evaluations indicate that the FPGA-based accelerator maintains low\nlatency while simultaneously executing beamforming inference for multiple port\nselections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14035v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13915", "title": "Blind Super Resolution with Reference Images and Implicit Degradation Representation", "authors": ["Huu-Phu Do", "Po-Chih Hu", "Hao-Chien Hsueh", "Che-Kai Liu", "Vu-Hoang Tran", "Ching-Chun Huang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ACCV 2024", "url": "http://arxiv.org/abs/2507.13915v1", "summary": "Previous studies in blind super-resolution (BSR) have primarily concentrated\non estimating degradation kernels directly from low-resolution (LR) inputs to\nenhance super-resolution. However, these degradation kernels, which model the\ntransition from a high-resolution (HR) image to its LR version, should account\nfor not only the degradation process but also the downscaling factor. Applying\nthe same degradation kernel across varying super-resolution scales may be\nimpractical. Our research acknowledges degradation kernels and scaling factors\nas pivotal elements for the BSR task and introduces a novel strategy that\nutilizes HR images as references to establish scale-aware degradation kernels.\nBy employing content-irrelevant HR reference images alongside the target LR\nimage, our model adaptively discerns the degradation process. It is then\napplied to generate additional LR-HR pairs through down-sampling the HR\nreference images, which are keys to improving the SR performance. Our\nreference-based training procedure is applicable to proficiently trained blind\nSR models and zero-shot blind SR methods, consistently outperforming previous\nmethods in both scenarios. This dual consideration of blur kernels and scaling\nfactors, coupled with the use of a reference image, contributes to the\neffectiveness of our approach in blind super-resolution tasks.", "comment": "Accepted by ACCV 2024", "pdf_url": "http://arxiv.org/pdf/2507.13915v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14044", "title": "TGIF: Talker Group-Informed Familiarization of Target Speaker Extraction", "authors": ["Tsun-An Hsieh", "Minje Kim"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14044v1", "summary": "State-of-the-art target speaker extraction (TSE) systems are typically\ndesigned to generalize to any given mixing environment, necessitating a model\nwith a large enough capacity as a generalist. Personalized speech enhancement\ncould be a specialized solution that adapts to single-user scenarios, but it\noverlooks the practical need for customization in cases where only a small\nnumber of talkers are involved, e.g., TSE for a specific family. We address\nthis gap with the proposed concept, talker group-informed familiarization\n(TGIF) of TSE, where the TSE system specializes in a particular group of users,\nwhich is challenging due to the inherent absence of a clean speech target. To\nthis end, we employ a knowledge distillation approach, where a group-specific\nstudent model learns from the pseudo-clean targets generated by a large teacher\nmodel. This tailors the student model to effectively extract the target speaker\nfrom the particular talker group while maintaining computational efficiency.\nExperimental results demonstrate that our approach outperforms the baseline\ngeneric models by adapting to the unique speech characteristics of a given\nspeaker group. Our newly proposed TGIF concept underscores the potential of\ndeveloping specialized solutions for diverse and real-world applications, such\nas on-device TSE on a family-owned device.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14044v1", "cate": "eess.AS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14000", "title": "Photonic Fabric Platform for AI Accelerators", "authors": ["Jing Ding", "Trung Diep"], "categories": ["cs.PF", "cs.AI", "C.4"], "primary_category": "Subjects:       Performance (cs.PF)", "pdf_link": null, "comments": "Comments:      12 pages, 14 figures, 5 tables", "url": "http://arxiv.org/abs/2507.14000v1", "summary": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM\n(PFA), a photonic-enabled switch and memory subsystem that delivers low\nlatency, high bandwidth, and low per-bit energy. By integrating high-bandwidth\nHBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D\nelectro-optical system-in-package, the PFA offers up to 32 TB of shared memory\nalongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM\nenables distributed AI training and inference to execute parallelism strategies\nmore efficiently. The Photonic Fabric removes the silicon beachfront constraint\nthat limits the fixed memory-to-compute ratio observed in virtually all current\nXPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet\nthat connects to the Photonic Fabric increases its memory capacity and\ncorrespondingly its memory bandwidth by offering a flexible path to scaling\nwell beyond the limitations of on-package HBM alone. We introduce CelestiSim, a\nlightweight analytical simulator validated on NVIDIA H100 and H200 systems. It\nis used to evaluate the performance of LLM reference and energy savings on PFA,\nwithout any significant change to the GPU core design. With the PFA, the\nsimulation results show that up to 3.66x throughput and 1.40x latency\nimprovements in LLM inference at 405B parameters, up to 7.04x throughput and\n1.41x latency improvements at 1T parameters, and 60-90% energy savings in data\nmovement for heavy collective operations in all LLM training scenarios. While\nthese results are shown for NVIDIA GPUs, they can be applied similarly to other\nAI accelerator designs (XPUs) that share the same fundamental limitation of\nfixed memory to compute.", "comment": "12 pages, 14 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.14000v1", "cate": "cs.PF", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13638", "title": "State Space Models Naturally Produce Traveling Waves, Time Cells, and Scale to Abstract Cognitive Functions", "authors": ["Sen Lu", "Xiaoyu Zhang", "Mingtao Hu", "Eric Yeu-Jer Lee", "Soohyeon Kim", "Wei D. Lu"], "categories": ["q-bio.NC", "cs.LG"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      Sen Lu and Xiaoyu Zhang contributed equally. Wei D. Lu is the corresponding author. 4 figures are included in 15 pages", "url": "http://arxiv.org/abs/2507.13638v1", "summary": "A grand challenge in modern neuroscience is to bridge the gap between the\ndetailed mapping of microscale neural circuits and a mechanistic understanding\nof cognitive functions. While extensive knowledge exists about neuronal\nconnectivity and biophysics, a significant gap remains in how these elements\ncombine to produce flexible, learned behaviors. Here, we propose that a\nframework based on State-Space Models (SSMs), an emerging class of deep\nlearning architectures, can bridge this gap. We argue that the differential\nequations governing elements in an SSM are conceptually consistent with the\nbiophysical dynamics of neurons, while the combined dynamics in the model lead\nto emergent behaviors observed in experimental neuroscience. We test this\nframework by training an S5 model--a specific SSM variant employing a diagonal\nstate transition matrix--on temporal discrimination tasks with reinforcement\nlearning (RL). We demonstrate that the model spontaneously develops neural\nrepresentations that strikingly mimic biological 'time cells'. We reveal that\nthese cells emerge from a simple generative principle: learned rotational\ndynamics of hidden state vectors in the complex plane. This single mechanism\nunifies the emergence of time cells, ramping activity, and\noscillations/traveling waves observed in numerous experiments. Furthermore, we\nshow that this rotational dynamics generalizes beyond interval discriminative\ntasks to abstract event-counting tasks that were considered foundational for\nperforming complex cognitive tasks. Our findings position SSMs as a compelling\nframework that connects single-neuron dynamics to cognitive phenomena, offering\na unifying and computationally tractable theoretical ground for temporal\nlearning in the brain.", "comment": "Sen Lu and Xiaoyu Zhang contributed equally. Wei D. Lu is the\n  corresponding author. 4 figures are included in 15 pages", "pdf_url": "http://arxiv.org/pdf/2507.13638v1", "cate": "q-bio.NC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13891", "title": "PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations", "authors": ["Yu Wei", "Jiahui Zhang", "Xiaoqin Zhang", "Ling Shao", "Shijian Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.13891v1", "summary": "COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing\nattention due to its remarkable performance in reconstructing high-quality 3D\nscenes from unposed images or videos. However, it often struggles to handle\nscenes with complex camera trajectories as featured by drastic rotation and\ntranslation across adjacent camera views, leading to degraded estimation of\ncamera poses and further local minima in joint optimization of camera poses and\n3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that\nachieves superior 3D scene modeling and camera pose estimation via camera pose\nco-regularization. PCR-GS achieves regularization from two perspectives. The\nfirst is feature reprojection regularization which extracts view-robust DINO\nfeatures from adjacent camera views and aligns their semantic information for\ncamera pose regularization. The second is wavelet-based frequency\nregularization which exploits discrepancy in high-frequency details to further\noptimize the rotation matrix in camera poses. Extensive experiments over\nmultiple real-world scenes show that the proposed PCR-GS achieves superior\npose-free 3D-GS scene modeling under dramatic changes of camera trajectories.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.13891v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13557", "title": "Single spin exact gradients for the optimization of complex pulses and pulse sequences", "authors": ["Stella Slad", "Burkhard Luy"], "categories": ["math.OC", "cs.SY", "eess.SY", "physics.chem-ph"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13557v1", "summary": "The efficient computer optimization of magnetic resonance pulses and pulse\nsequences involves the calculation of a problem-adapted cost function as well\nas its gradients with respect to all controls applied. The gradients generally\ncan be calculated as a finite difference approximation, as a GRAPE\napproximation, or as an exact function, e.g. by the use of the augmented matrix\nexponentiation, where the exact gradient should lead to best optimization\nconvergence. However, calculation of exact gradients is computationally\nexpensive and analytical exact solutions to the problem would be highly\ndesirable. As the majority of todays pulse optimizations involve a single spin\n1/2, which can be represented by simple rotation matrices in the Bloch space or\nby their corresponding Cayley-Klein/quaternion parameters, the derivations of\nanalytical exact gradient functions appear to be feasible. Taking two\noptimization types, the optimization of point-to-point pulses using\n3D-rotations and the optimization of universal rotation pulses using\nquaternions, analytical solutions for gradients with respect to controls have\nbeen derived. Controls in this case can be conventional $x$ and $y$ pulses, but\nalso $z$-controls, as well as gradients with respect to amplitude and phase of\na pulse shape. In addition, analytical solutions with respect to pseudo\ncontrols, involving holonomic constraints to maximum rf-amplitudes, maximum\nrf-power, or maximum rf-energy, are introduced. Using the hyperbolic tangent\nfunction, maximum values are imposed in a fully continuous and differentiable\nway. The obtained analytical gradients allow the calculation two orders of\nmagnitude faster than the augmented matrix exponential approach. The exact\ngradients for different controls are finally compared in a number of\noptimizations involving broadband pulses for $^{15}$N, $^{13}$C, and $^{19}$F\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13557v1", "cate": "math.OC", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13523", "title": "Distributed Acoustic Sensing for Environmental Monitoring, and Newtonian Noise Mitigation:Comparable Sensitivity to Seismometers", "authors": ["Reinhardt Rading", "Fracensca Badaracco", "Spiridon Beis", "Katharina Sophie Isleif", "Paul Ophardt", "Wanda Vossius", "the WAVE Collaboration"], "categories": ["astro-ph.IM", "eess.SP", "gr-qc"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13523v1", "summary": "Newtonian noise limits the low-frequency sensitivity of ground-based\ngravitational wave detectors. While seismometers and geophones are commonly\nemployed to monitor ground motion for Newtonian noise cancellation, their\nlimited spatial coverage and high deployment costs hinder scalability. In this\nstudy, we demonstrate that distributed acoustic sensing offers a viable and\nscalable alternative, providing performance comparable to that of conventional\nseismic instruments. Using data from acoustic sensing and colocated\nseismometers during both natural and controlled events, we observe a strong\ncorrelation, exceeding 0.8, between the two sensor types in the 3 to 20 Hz\nfrequency band relevant for Newtonian noise. Moreover, when distributed\nacoustic sensing data are used to predict geophone signals, the correlation\nremains high, above 0.7, indicating that distributed acoustic sensing\naccurately captures both the spatial and spectral features of ground motion. As\na case study, we apply distributed acoustic sensing data to cancel noise\nrecorded by the vertical component of a seismometer and compare the results\nwith those obtained using geophone data for the same task. Both distributed\nacoustic sensing and geophone-based cancellations yield a residual noise factor\nof 0.11 at 20 Hz. These findings confirm the feasibility of using distributed\nacoustic sensing for Newtonian noise mitigation and highlight its potential, in\ncombination with traditional seismic sensors, to improve environmental\nmonitoring and noise suppression in current and next-generation gravitational\nwave observatories.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13523v1", "cate": "astro-ph.IM", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13974", "title": "Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&E Images", "authors": ["Jiaqi Lv", "Yijie Zhu", "Carmen Guadalupe Colin Tenorio", "Brinder Singh Chohan", "Mark Eastwood", "Shan E Ahmed Raza"], "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by MIUA 2025", "url": "http://arxiv.org/abs/2507.13974v1", "summary": "Melanoma is an aggressive form of skin cancer with rapid progression and high\nmetastatic potential. Accurate characterisation of tissue morphology in\nmelanoma is crucial for prognosis and treatment planning. However, manual\nsegmentation of tissue regions from haematoxylin and eosin (H&E) stained\nwhole-slide images (WSIs) is labour-intensive and prone to inter-observer\nvariability, this motivates the need for reliable automated tissue segmentation\nmethods. In this study, we propose a novel deep learning network for the\nsegmentation of five tissue classes in melanoma H&E images. Our approach\nleverages Virchow2, a pathology foundation model trained on 3.1 million\nhistopathology images as a feature extractor. These features are fused with the\noriginal RGB images and subsequently processed by an encoder-decoder\nsegmentation network (Efficient-UNet) to produce accurate segmentation maps.\nThe proposed model achieved first place in the tissue segmentation task of the\nPUMA Grand Challenge, demonstrating robust performance and generalizability.\nOur results show the potential and efficacy of incorporating pathology\nfoundation models into segmentation networks to accelerate computational\npathology workflows.", "comment": "Accepted by MIUA 2025", "pdf_url": "http://arxiv.org/pdf/2507.13974v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13164", "title": "Feature-based analysis of oral narratives from Afrikaans and isiXhosa children", "authors": ["Emma Sharratt", "Annelien Smith", "Retief Louw", "Daleen Klop", "Febe de Wet", "Herman Kamper"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      SLaTE 2025 in Nijmegen, Netherlands", "url": "http://arxiv.org/abs/2507.13164v1", "summary": "Oral narrative skills are strong predictors of later literacy development.\nThis study examines the features of oral narratives from children who were\nidentified by experts as requiring intervention. Using simple machine learning\nmethods, we analyse recorded stories from four- and five-year-old Afrikaans-\nand isiXhosa-speaking children. Consistent with prior research, we identify\nlexical diversity (unique words) and length-based features (mean utterance\nlength) as indicators of typical development, but features like articulation\nrate prove less informative. Despite cross-linguistic variation in\npart-of-speech patterns, the use of specific verbs and auxiliaries associated\nwith goal-directed storytelling is correlated with a reduced likelihood of\nrequiring intervention. Our analysis of two linguistically distinct languages\nreveals both language-specific and shared predictors of narrative proficiency,\nwith implications for early assessment in multilingual contexts.", "comment": "SLaTE 2025 in Nijmegen, Netherlands", "pdf_url": "http://arxiv.org/pdf/2507.13164v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14067", "title": "VLA-Mark: A cross modal watermark for large vision-language alignment model", "authors": ["Shuliang Liu", "Qi Zheng", "Jesse Jiaxi Xu", "Yibo Yan", "He Geng", "Aiwei Liu", "Peijie Jiang", "Jia Liu", "Yik-Cheung Tam", "Xuming Hu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14067v1", "summary": "Vision-language models demand watermarking solutions that protect\nintellectual property without compromising multimodal coherence. Existing text\nwatermarking methods disrupt visual-textual alignment through biased token\nselection and static strategies, leaving semantic-critical concepts vulnerable.\nWe propose VLA-Mark, a vision-aligned framework that embeds detectable\nwatermarks while preserving semantic fidelity through cross-modal coordination.\nOur approach integrates multiscale visual-textual alignment metrics, combining\nlocalized patch affinity, global semantic coherence, and contextual attention\npatterns, to guide watermark injection without model retraining. An\nentropy-sensitive mechanism dynamically balances watermark strength and\nsemantic preservation, prioritizing visual grounding during low-uncertainty\ngeneration phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than\nconventional methods, with near-perfect detection (98.8% AUC). The framework\ndemonstrates 96.1\\% attack resilience against attacks such as paraphrasing and\nsynonym substitution, while maintaining text-visual consistency, establishing\nnew standards for quality-preserving multimodal watermarking", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14067v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13700", "title": "Tight Bounds for Answering Adaptively Chosen Concentrated Queries", "authors": ["Emma Rapoport", "Edith Cohen", "Uri Stemmer"], "categories": ["cs.DS", "cs.LG"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13700v1", "summary": "Most work on adaptive data analysis assumes that samples in the dataset are\nindependent. When correlations are allowed, even the non-adaptive setting can\nbecome intractable, unless some structural constraints are imposed. To address\nthis, Bassily and Freund [2016] introduced the elegant framework of\nconcentrated queries, which requires the analyst to restrict itself to queries\nthat are concentrated around their expected value. While this assumption makes\nthe problem trivial in the non-adaptive setting, in the adaptive setting it\nremains quite challenging. In fact, all known algorithms in this framework\nsupport significantly fewer queries than in the independent case: At most\n$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the\nindependent setting.\n  In this work, we prove that this utility gap is inherent under the current\nformulation of the concentrated queries framework, assuming some natural\nconditions on the algorithm. Additionally, we present a simplified version of\nthe best-known algorithms that match our impossibility result.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13700v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13899", "title": "Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection", "authors": ["Yujian Mo", "Yan Wu", "Junqiao Zhao", "Jijun Wang", "Yinghao Hu", "Jun Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13899v1", "summary": "Recent advances in foundation models have opened up new possibilities for\nenhancing 3D perception. In particular, DepthAnything offers dense and reliable\ngeometric priors from monocular RGB images, which can complement sparse LiDAR\ndata in autonomous driving scenarios. However, such priors remain underutilized\nin LiDAR-based 3D object detection. In this paper, we address the limited\nexpressiveness of raw LiDAR point features, especially the weak discriminative\ncapability of the reflectance attribute, by introducing depth priors predicted\nby DepthAnything. These priors are fused with the original LiDAR attributes to\nenrich each point's representation. To leverage the enhanced point features, we\npropose a point-wise feature extraction module. Then, a Dual-Path RoI feature\nextraction framework is employed, comprising a voxel-based branch for global\nsemantic context and a point-based branch for fine-grained structural details.\nTo effectively integrate the complementary RoI features, we introduce a\nbidirectional gated RoI feature fusion module that balances global and local\ncues. Extensive experiments on the KITTI benchmark show that our method\nconsistently improves detection accuracy, demonstrating the value of\nincorporating visual foundation model priors into LiDAR-based 3D object\ndetection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13899v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13853", "title": "Resource-Splitting Games with Tullock-Based Lossy Contests", "authors": ["Marko Maljkovic", "Gustav Nilsson", "Nikolas Geroliminis"], "categories": ["cs.GT", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13853v1", "summary": "This paper introduces a novel class of multi-stage resource allocation games\nthat model real-world scenarios in which profitability depends on the balance\nbetween supply and demand, and where higher resource investment leads to\ngreater returns. Our proposed framework, which incorporates the notion of\nprofit loss due to insufficient player participation, gives rise to a\nTullock-like functional form of the stage payoff structure when weighted fair\nproportional resource allocation is applied. We explore both centralized and\nNash equilibrium strategies, establish sufficient conditions for their\nexistence and uniqueness, and provide an iterative, semi-decentralized method\nto compute the Nash equilibrium in games with arbitrarily many players.\nAdditionally, we demonstrate that the framework generalizes instances of\nseveral existing models, including Receding Horizon and Blotto games, and\npresent a semi-analytical method for computing the unique Nash equilibrium\nwithin the Blotto setup. Our findings are validated through a numerical case\nstudy in smart mobility, highlighting the practical relevance and applicability\nof the proposed model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13853v1", "cate": "cs.GT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14003", "title": "Hybrid Integration of Quantum Cascade Lasers with Germanium-on-Silicon waveguides for Mid-Infrared Sensing Applications", "authors": ["Colin J. Mitchell", "Longqi Zhou", "Ke Li", "Daniel Adeyemi", "Ahmed Osman", "Milos Nedeljkovic", "Glenn Churchill", "James C. Gates", "Graham T. Reed", "Kristian M. Groom", "Jon Heffernan", "Goran Mashanovich"], "categories": ["physics.optics", "eess.SP", "physics.app-ph"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.14003v1", "summary": "We present a novel scheme for hybrid integration of quantum cascade laser\nbars with germanium-on-silicon waveguides operating in the mid-infrared. The\nlaser bars are flip-chip bonded onto a germanium-on-silicon target chip without\nactive alignment, acheiving end-fire coupling efficiency of up to 45% (3.5 dB\nloss) in pulsed operation. Optical power estimates indicate 20-30 mW coupled\ninto the waveguides. The passive alignment approach, combined with a\nCMOS-compatible photonic integrated circuit fabrication process, offers a\nscalable pathway to fully integrated mid-infrared photonic systems for sensing,\nfree-space communications, and the realisation of novel light sources.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14003v1", "cate": "physics.optics", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14046", "title": "D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging", "authors": ["Hao Fang", "Hao Yu", "Sihao Teng", "Tao Zhang", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures", "url": "http://arxiv.org/abs/2507.14046v1", "summary": "Unsupervised learning methods, such as Deep Image Prior (DIP), have shown\ngreat potential in tomographic imaging due to their training-data-free nature\nand high generalization capability. However, their reliance on numerous network\nparameter iterations results in high computational costs, limiting their\npractical application, particularly in complex 3D or time-sequence tomographic\nimaging tasks. To overcome these challenges, we propose Deep Dynamic Image\nPrior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introduces\nthree key strategies - Unsupervised Parameter Warm-Start (UPWS), Temporal\nParameter Propagation (TPP), and a customized lightweight reconstruction\nbackbone, 3D-FastResUNet - to accelerate convergence, enforce temporal\ncoherence, and improve computational efficiency. Experimental results on both\nsimulated and clinical pulmonary datasets demonstrate that D2IP enables fast\nand accurate 3D time-sequence Electrical Impedance Tomography (tsEIT)\nreconstruction. Compared to state-of-the-art baselines, D2IP delivers superior\nimage quality, with a 24.8% increase in average MSSIM and an 8.1% reduction in\nERR, alongside significantly reduced computational time (7.1x faster),\nhighlighting its promise for clinical dynamic pulmonary imaging.", "comment": "11 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.14046v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13563", "title": "A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models", "authors": ["Kirill Borodin", "Nikita Vasiliev", "Vasiliy Kudryavtsev", "Maxim Maslov", "Mikhail Gorodnichev", "Oleg Rogov", "Grach Mkrtchian"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      The work is still in progress", "url": "http://arxiv.org/abs/2507.13563v1", "summary": "Russian speech synthesis presents distinctive challenges, including vowel\nreduction, consonant devoicing, variable stress patterns, homograph ambiguity,\nand unnatural intonation. This paper introduces Balalaika, a novel dataset\ncomprising more than 2,000 hours of studio-quality Russian speech with\ncomprehensive textual annotations, including punctuation and stress markings.\nExperimental results show that models trained on Balalaika significantly\noutperform those trained on existing datasets in both speech synthesis and\nenhancement tasks. We detail the dataset construction pipeline, annotation\nmethodology, and results of comparative evaluations.", "comment": "The work is still in progress", "pdf_url": "http://arxiv.org/pdf/2507.13563v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14079", "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits", "authors": ["Garapati Keerthana", "Manik Gupta"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14079v1", "summary": "Progress notes are among the most clinically meaningful artifacts in an\nElectronic Health Record (EHR), offering temporally grounded insights into a\npatient's evolving condition, treatments, and care decisions. Despite their\nimportance, they are severely underrepresented in large-scale EHR datasets. For\ninstance, in the widely used Medical Information Mart for Intensive Care III\n(MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress\nnotes, leaving gaps in longitudinal patient narratives. In contrast, the\ndataset contains a diverse array of other note types, each capturing different\naspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered\nEvidence), a system designed to align with clinical documentation workflows by\nsimulating how physicians reference past encounters while drafting progress\nnotes. The system introduces a fine-grained note categorization and a temporal\nalignment mechanism that organizes heterogeneous notes across visits into\nstructured, chronological inputs. At its core, DENSE leverages a clinically\ninformed retrieval strategy to identify temporally and semantically relevant\ncontent from both current and prior visits. This retrieved evidence is used to\nprompt a large language model (LLM) to generate clinically coherent and\ntemporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and\ncomplete progress note documentation. The generated notes demonstrate strong\nlongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,\nsurpassing the continuity observed in original notes. By restoring narrative\ncoherence across fragmented documentation, our system supports improved\ndownstream tasks such as summarization, predictive modeling, and clinical\ndecision support, offering a scalable solution for LLM-driven note synthesis in\nreal-world healthcare settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14079v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13710", "title": "CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13710v1", "summary": "Data preparation is a foundational yet notoriously challenging component of\nthe machine learning lifecycle, characterized by a vast combinatorial search\nspace of potential operator sequences. While reinforcement learning (RL) offers\na promising direction, existing approaches are inefficient as they fail to\ncapture the structured, hierarchical nature of the problem. We argue that\nHierarchical Reinforcement Learning (HRL), a paradigm that has been successful\nin other domains, provides a conceptually ideal yet previously unexplored\nframework for this task. However, a naive HRL implementation with a `hard\nhierarchy' is prone to suboptimal, irreversible decisions. To address this, we\nintroduce CogniQ-H, the first framework to implement a soft hierarchical\nparadigm for robust, end-to-end automated data preparation. CogniQ-H formulates\naction selection as a Bayesian inference problem. A high-level strategic prior,\ngenerated by a Large Language Model (LLM), guides exploration\nprobabilistically. This prior is synergistically combined with a fine-grained\noperator quality score from a supervised Learning-to-Rank (LTR) model and a\nlong-term value estimate from the agent's own Q-function. This hybrid\narchitecture allows CogniQ-H to balance strategic guidance with adaptive,\nevidence-based decision-making. Through extensive experiments on 18 diverse\ndatasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to\n13.9\\% improvement in pipeline quality and 2.8$\\times$ faster convergence\ncompared to state-of-the-art RL-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13710v1", "cate": "cs.DB", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13929", "title": "TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views", "authors": ["Hsiang-Hui Hung", "Huu-Phu Do", "Yung-Hui Li", "Ching-Chun Huang"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MM 2024", "url": "http://arxiv.org/abs/2507.13929v1", "summary": "We present TimeNeRF, a generalizable neural rendering approach for rendering\nnovel views at arbitrary viewpoints and at arbitrary times, even with few input\nviews. For real-world applications, it is expensive to collect multiple views\nand inefficient to re-optimize for unseen scenes. Moreover, as the digital\nrealm, particularly the metaverse, strives for increasingly immersive\nexperiences, the ability to model 3D environments that naturally transition\nbetween day and night becomes paramount. While current techniques based on\nNeural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing\nnovel views, the exploration of NeRF's potential for temporal 3D scene modeling\nremains limited, with no dedicated datasets available for this purpose. To this\nend, our approach harnesses the strengths of multi-view stereo, neural radiance\nfields, and disentanglement strategies across diverse datasets. This equips our\nmodel with the capability for generalizability in a few-shot setting, allows us\nto construct an implicit content radiance field for scene representation, and\nfurther enables the building of neural radiance fields at any arbitrary time.\nFinally, we synthesize novel views of that time via volume rendering.\nExperiments show that TimeNeRF can render novel views in a few-shot setting\nwithout per-scene optimization. Most notably, it excels in creating realistic\nnovel views that transition smoothly across different times, adeptly capturing\nintricate natural scene changes from dawn to dusk.", "comment": "Accepted by MM 2024", "pdf_url": "http://arxiv.org/pdf/2507.13929v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2312.04242", "title": "Signal Temporal Logic Control Synthesis among Uncontrollable Dynamic Agents with Conformal Prediction", "authors": ["Xinyi Yu", "Yiqi Zhao", "Xiang Yin", "Lars Lindemann"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.04242v4", "summary": "The control of dynamical systems under temporal logic specifications among\nuncontrollable dynamic agents is challenging due to the agents' a-priori\nunknown behavior. Existing works have considered the problem where either all\nagents are controllable, the agent models are deterministic and known, or no\nsafety guarantees are provided. We propose a predictive control synthesis\nframework that guarantees, with high probability, the satisfaction of signal\ntemporal logic (STL) tasks that are defined over a controllable system in the\npresence of uncontrollable stochastic agents. We use trajectory predictors and\nconformal prediction to construct probabilistic prediction regions for each\nuncontrollable agent that are valid over multiple future time steps.\nSpecifically, we construct a normalized prediction region over all agents and\ntime steps to reduce conservatism and increase data efficiency. We then\nformulate a worst-case bilevel mixed integer program (MIP) that accounts for\nall agent realizations within the prediction region to obtain an open-loop\ncontroller that provably guarantee task satisfaction with high probability. To\nefficiently solve this bilevel MIP, we propose an equivalent MIP program based\non KKT conditions of the original bilevel formulation. Building upon this, we\ndesign a closed-loop controller, where both recursive feasibility and task\nsatisfaction can be guaranteed with high probability. We illustrate our control\nsynthesis framework on two case studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.04242v4", "cate": "eess.SY", "date": "2023-12-07", "updated": "2025-07-18"}
{"id": "2503.23883", "title": "Algorithm Design and Prototype Validation for Reconfigurable Intelligent Sensing Surface: Forward-Only Transmission", "authors": ["Cheng Luo", "Luping Xiang", "Jie Hu", "Kun Yang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.23883v5", "summary": "Sensing-assisted communication schemes have recently garnered significant\nresearch attention. In this work, we design a dual-function reconfigurable\nintelligent surface (RIS), integrating both active and passive elements,\nreferred to as the reconfigurable intelligent sensing surface (RISS), to\nenhance communication. By leveraging sensing results from the active elements,\nwe propose communication enhancement and robust interference suppression\nschemes for both near-field and far-field models, implemented through the\npassive elements. These schemes remove the need for base station (BS) feedback\nfor RISS control, simplifying the communication process by replacing\ntraditional channel state information (CSI) feedback with real-time sensing\nfrom the active elements. The proposed schemes are theoretically analyzed and\nthen validated using software-defined radio (SDR). Experimental results\ndemonstrate the effectiveness of the sensing algorithms in real-world\nscenarios, such as direction of arrival (DOA) estimation and radio frequency\n(RF) identification recognition. Moreover, the RISS-assisted communication\nsystem shows strong performance in communication enhancement and interference\nsuppression, particularly in near-field models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.23883v5", "cate": "eess.SP", "date": "2025-03-31", "updated": "2025-07-18"}
{"id": "2507.14102", "title": "UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography", "authors": ["Shravan Venkatraman", "Pavan Kumar S", "Rakesh Raj Madavan", "Chandrakala S"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      18 pages, 10 figures, 5 tables, 2025 ICCV Workshops", "url": "http://arxiv.org/abs/2507.14102v1", "summary": "Accurate classification of computed tomography (CT) images is essential for\ndiagnosis and treatment planning, but existing methods often struggle with the\nsubtle and spatially diverse nature of pathological features. Current\napproaches typically process images uniformly, limiting their ability to detect\nlocalized abnormalities that require focused analysis. We introduce UGPL, an\nuncertainty-guided progressive learning framework that performs a\nglobal-to-local analysis by first identifying regions of diagnostic ambiguity\nand then conducting detailed examination of these critical areas. Our approach\nemploys evidential deep learning to quantify predictive uncertainty, guiding\nthe extraction of informative patches through a non-maximum suppression\nmechanism that maintains spatial diversity. This progressive refinement\nstrategy, combined with an adaptive fusion mechanism, enables UGPL to integrate\nboth contextual information and fine-grained details. Experiments across three\nCT datasets demonstrate that UGPL consistently outperforms state-of-the-art\nmethods, achieving improvements of 3.29%, 2.46%, and 8.08% in accuracy for\nkidney abnormality, lung cancer, and COVID-19 detection, respectively. Our\nanalysis shows that the uncertainty-guided component provides substantial\nbenefits, with performance dramatically increasing when the full progressive\nlearning pipeline is implemented. Our code is available at:\nhttps://github.com/shravan-18/UGPL", "comment": "18 pages, 10 figures, 5 tables, 2025 ICCV Workshops", "pdf_url": "http://arxiv.org/pdf/2507.14102v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13572", "title": "Temporal Adaptation of Pre-trained Foundation Models for Music Structure Analysis", "authors": ["Yixiao Zhang", "Haonan Chen", "Ju-Chiang Wang", "Jitong Chen"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2507.13572v1", "summary": "Audio-based music structure analysis (MSA) is an essential task in Music\nInformation Retrieval that remains challenging due to the complexity and\nvariability of musical form. Recent advances highlight the potential of\nfine-tuning pre-trained music foundation models for MSA tasks. However, these\nmodels are typically trained with high temporal feature resolution and short\naudio windows, which limits their efficiency and introduces bias when applied\nto long-form audio. This paper presents a temporal adaptation approach for\nfine-tuning music foundation models tailored to MSA. Our method enables\nefficient analysis of full-length songs in a single forward pass by\nincorporating two key strategies: (1) audio window extension and (2)\nlow-resolution adaptation. Experiments on the Harmonix Set and RWC-Pop datasets\nshow that our method significantly improves both boundary detection and\nstructural function prediction, while maintaining comparable memory usage and\ninference speed.", "comment": "Accepted to WASPAA 2025. Project Page:\n  https://sites.google.com/view/temporal-adaptation-for-msa/", "pdf_url": "http://arxiv.org/pdf/2507.13572v1", "cate": "cs.SD", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14093", "title": "Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment", "authors": ["Šimon Kubov", "Simon Klíčník", "Jakub Dandár", "Zdeněk Straka", "Karolína Kvaková", "Daniel Kvak"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14093v1", "summary": "Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment\ndecisions depend on precise Cobb angle measurement. Manual assessment is time\nconsuming and subject to inter observer variation. We conducted a\nretrospective, multi centre evaluation of a fully automated deep learning\nsoftware (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on\n103 standing anteroposterior whole spine radiographs collected from ten\nhospitals. Two musculoskeletal radiologists independently measured each study\nand served as reference readers. Agreement between the AI and each radiologist\nwas assessed with Bland Altman analysis, mean absolute error (MAE), root mean\nsquared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four\ngrade severity classification. Against Radiologist 1 the AI achieved an MAE of\n3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of\nagreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI\nachieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees\nand limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r\nequals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen\nkappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).\nThese results demonstrate that the proposed software reproduces expert level\nCobb angle measurements and categorical grading across multiple centres,\nsuggesting its utility for streamlining scoliosis reporting and triage in\nclinical workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14093v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13712", "title": "LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13712v1", "summary": "Automated data preparation is crucial for democratizing machine learning, yet\nexisting reinforcement learning (RL) based approaches suffer from inefficient\nexploration in the vast space of possible preprocessing pipelines. We present\nLLaPipe, a novel framework that addresses this exploration bottleneck by\nintegrating Large Language Models (LLMs) as intelligent policy advisors. Unlike\ntraditional methods that rely solely on statistical features and blind\ntrial-and-error, LLaPipe leverages the semantic understanding capabilities of\nLLMs to provide contextually relevant exploration guidance. Our framework\nintroduces three key innovations: (1) an LLM Policy Advisor that analyzes\ndataset semantics and pipeline history to suggest promising preprocessing\noperations, (2) an Experience Distillation mechanism that mines successful\npatterns from past pipelines and transfers this knowledge to guide future\nexploration, and (3) an Adaptive Advisor Triggering strategy\n(Advisor\\textsuperscript{+}) that dynamically determines when LLM intervention\nis most beneficial, balancing exploration effectiveness with computational\ncost. Through extensive experiments on 18 diverse datasets spanning multiple\ndomains, we demonstrate that LLaPipe achieves up to 22.4\\% improvement in\npipeline quality and 2.3$\\times$ faster convergence compared to\nstate-of-the-art RL-based methods, while maintaining computational efficiency\nthrough selective LLM usage (averaging only 19.0\\% of total exploration steps).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13712v1", "cate": "cs.DB", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13934", "title": "DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization", "authors": ["Marzieh Gheisari", "Auguste Genovesio"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13934v1", "summary": "Unsupervised disentanglement of static appearance and dynamic motion in video\nremains a fundamental challenge, often hindered by information leakage and\nblurry reconstructions in existing VAE- and GAN-based approaches. We introduce\nDiViD, the first end-to-end video diffusion framework for explicit\nstatic-dynamic factorization. DiViD's sequence encoder extracts a global static\ntoken from the first frame and per-frame dynamic tokens, explicitly removing\nstatic content from the motion code. Its conditional DDPM decoder incorporates\nthree key inductive biases: a shared-noise schedule for temporal consistency, a\ntime-varying KL-based bottleneck that tightens at early timesteps (compressing\nstatic information) and relaxes later (enriching dynamics), and cross-attention\nthat routes the global static token to all frames while keeping dynamic tokens\nframe-specific. An orthogonality regularizer further prevents residual\nstatic-dynamic leakage. We evaluate DiViD on real-world benchmarks using\nswap-based accuracy and cross-leakage metrics. DiViD outperforms\nstate-of-the-art sequential disentanglement methods: it achieves the highest\nswap-based joint accuracy, preserves static fidelity while improving dynamic\ntransfer, and reduces average cross-leakage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13934v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.09143", "title": "Reducing real-time complexity via sub-control Lyapunov functions: from theory to experiments", "authors": ["Huu-Thinh Do", "Franco Blanchini", "Stefano Miani", "Ionela Prodan"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted to Automatica", "url": "http://arxiv.org/abs/2501.09143v3", "summary": "The techniques to design control Lyapunov functions (CLF), along with a\nproper stabilizing feedback, possibly in the presence of constraints, often\nprovide control laws that are too complex for proper implementation online,\nespecially when an optimization problem is involved. In this work, we show how\nto acquire an alternative, computationally attractive feedback. Given a nominal\nCLF and a nominal state feedback, we say that a different positive definite\nfunction is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative\nis negative-definite and bounded above by the Lyapunov derivative of the\nnominal function with the nominal control. It turns out that if we consider a\nfamily of basis functions, then a SCLF can be computed by linear programming,\nwith an infinite number of constraints. The idea is that although the offline\ncomputational burden to achieve the new controller and solve the linear program\nis considerable, the online computational burden is drastically reduced.\nComprehensive simulations and experiments on drone control are conducted to\ndemonstrate the effectiveness of the study.", "comment": "Accepted to Automatica", "pdf_url": "http://arxiv.org/pdf/2501.09143v3", "cate": "eess.SY", "date": "2025-01-15", "updated": "2025-07-17"}
{"id": "2505.01570", "title": "Memory-less and Backscatter-less Tunnel Diode Harmonic Signatures for RFID", "authors": ["Christopher Saetia", "Kaitlyn Graves", "Serhat Tadik", "Gregory D. Durgin"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been accepted and published by the IEEE Journal of Radio-Frequency-Identification (JRFID). Please see the final version on IEEE Xplore", "url": "http://arxiv.org/abs/2505.01570v3", "summary": "Tunnel diodes have traditionally been researched for extending backscatter\nread-ranges for ultra-high-frequency (UHF) radio-frequency identification\n(RFID) tags as reflection amplifiers. This paper explores the natural harmonics\nthat arise from biasing these diodes within their negative differential\nresistance regions and with no interrogating signal from a transmitting source,\nsuch as an RFID reader, to injection-lock these diodes. These harmonics are\ncharacterized for five tunnel diode boards, made with the same components and\nwith each board's fundamental frequencies measuring at above -15 dBm at a\nbiasing voltage of 200 mV when measured over-the-cable. The occurrence of these\nharmonics creates unique harmonic signatures for each board and demonstrates\npossible harmonic RFID applications that can help RFID readers discover and\neven identify RFID tags with backscatter-less and memory-less IDs generated by\ntunnel diodes.", "comment": "This work has been accepted and published by the IEEE Journal of\n  Radio-Frequency-Identification (JRFID). Please see the final version on IEEE\n  Xplore", "pdf_url": "http://arxiv.org/pdf/2505.01570v3", "cate": "eess.SP", "date": "2025-05-02", "updated": "2025-07-17"}
{"id": "2312.17183", "title": "Large-Vocabulary Segmentation for Medical Images with Text Prompts", "authors": ["Ziheng Zhao", "Yao Zhang", "Chaoyi Wu", "Xiaoman Zhang", "Xiao Zhou", "Ya Zhang", "Yanfeng Wang", "Weidi Xie"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      74 pages", "url": "http://arxiv.org/abs/2312.17183v5", "summary": "This paper aims to build a model that can Segment Anything in 3D medical\nimages, driven by medical terminologies as Text prompts, termed as SAT. Our\nmain contributions are three-fold: (i) We construct the first multimodal\nknowledge tree on human anatomy, including 6502 anatomical terminologies; Then,\nwe build the largest and most comprehensive segmentation dataset for training,\ncollecting over 22K 3D scans from 72 datasets, across 497 classes, with careful\nstandardization on both image and label space; (ii) We propose to inject\nmedical knowledge into a text encoder via contrastive learning and formulate a\nlarge-vocabulary segmentation model that can be prompted by medical\nterminologies in text form; (iii) We train SAT-Nano (110M parameters) and\nSAT-Pro (447M parameters). SAT-Pro achieves comparable performance to 72\nnnU-Nets -- the strongest specialist models trained on each dataset (over 2.2B\nparameters combined) -- over 497 categories. Compared with the interactive\napproach MedSAM, SAT-Pro consistently outperforms across all 7 human body\nregions with +7.1% average Dice Similarity Coefficient (DSC) improvement, while\nshowing enhanced scalability and robustness. On 2 external (cross-center)\ndatasets, SAT-Pro achieves higher performance than all baselines (+3.7% average\nDSC), demonstrating superior generalization ability.", "comment": "74 pages", "pdf_url": "http://arxiv.org/pdf/2312.17183v5", "cate": "eess.IV", "date": "2023-12-28", "updated": "2025-07-18"}
{"id": "2507.13863", "title": "Controlling the Parameterized Multi-channel Wiener Filter using a tiny neural network", "authors": ["Eric Grinstein", "Ashutosh Pandey", "Cole Li", "Shanmukha Srinivas", "Juan Azcarreta", "Jacob Donley", "Sanha Lee", "Ali Aroudi", "Cagdas Bilen"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.13863v1", "summary": "Noise suppression and speech distortion are two important aspects to be\nbalanced when designing multi-channel Speech Enhancement (SE) algorithms.\nAlthough neural network models have achieved state-of-the-art noise\nsuppression, their non-linear operations often introduce high speech\ndistortion. Conversely, classical signal processing algorithms such as the\nParameterized Multi-channel Wiener Filter ( PMWF) beamformer offer explicit\nmechanisms for controlling the suppression/distortion trade-off. In this work,\nwe present NeuralPMWF, a system where the PMWF is entirely controlled using a\nlow-latency, low-compute neural network, resulting in a low-complexity system\noffering high noise reduction and low speech distortion. Experimental results\nshow that our proposed approach results in significantly better perceptual and\nobjective speech enhancement in comparison to several competitive baselines\nusing similar computational resources.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.13863v1", "cate": "cs.SD", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14096", "title": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track", "authors": ["Brian Ondov", "William Xia", "Kush Attal", "Ishita Unde", "Jerry He", "Hoa Dang", "Ian Soboroff", "Dina Demner-Fushman"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14096v1", "summary": "Objective: Recent advances in language models have shown potential to adapt\nprofessional-facing biomedical literature to plain language, making it\naccessible to patients and caregivers. However, their unpredictability,\ncombined with the high potential for harm in this domain, means rigorous\nevaluation is necessary. Our goals with this track were to stimulate research\nand to provide high-quality evaluation of the most promising systems.\n  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts\n(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included\ncomplete, sentence-level, rewriting of abstracts (Task 1) as well as\nidentifying and replacing difficult terms (Task 2). For automatic evaluation of\nTask 1, we developed a four-fold set of professionally-written references.\nSubmissions for both Tasks 1 and 2 were provided extensive manual evaluation\nfrom biomedical experts.\n  Results: Twelve teams spanning twelve countries participated in the track,\nwith models from multilayer perceptrons to large pretrained transformers. In\nmanual judgments of Task 1, top-performing models rivaled human levels of\nfactual accuracy and completeness, but not simplicity or brevity. Automatic,\nreference-based metrics generally did not correlate well with manual judgments.\nIn Task 2, systems struggled with identifying difficult terms and classifying\nhow to replace them. When generating replacements, however, LLM-based systems\ndid well in manually judged accuracy, completeness, and simplicity, though not\nin brevity.\n  Conclusion: The PLABA track showed promise for using Large Language Models to\nadapt biomedical literature for the general public, while also highlighting\ntheir deficiencies and the need for improved automatic benchmarking tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14096v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13732", "title": "The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction", "authors": ["Guillaume Zambrano"], "categories": ["cs.CL", "cs.LG", "J.1; I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      23 pages, 24 figures shorter version submitted to JURIX 2025", "url": "http://arxiv.org/abs/2507.13732v1", "summary": "This study examines the role of human judges in legal decision-making by\nusing machine learning to predict child physical custody outcomes in French\nappellate courts. Building on the legal realism-formalism debate, we test\nwhether individual judges' decision-making patterns significantly influence\ncase outcomes, challenging the assumption that judges are neutral variables\nthat apply the law uniformly. To ensure compliance with French privacy laws, we\nimplement a strict pseudonymization process. Our analysis uses 18,937 living\narrangements rulings extracted from 10,306 cases. We compare models trained on\nindividual judges' past rulings (specialist models) with a judge-agnostic model\ntrained on aggregated data (generalist models). The prediction pipeline is a\nhybrid approach combining large language models (LLMs) for structured feature\nextraction and ML models for outcome prediction (RF, XGB and SVC). Our results\nshow that specialist models consistently achieve higher predictive accuracy\nthan the general model, with top-performing models reaching F1 scores as high\nas 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x\nmore samples. Specialist models capture stable individual patterns that are not\ntransferable to other judges. In-Domain and Cross-Domain validity tests provide\nempirical support for legal realism, demonstrating that judicial identity plays\na measurable role in legal outcomes. All data and code used will be made\navailable.", "comment": "23 pages, 24 figures shorter version submitted to JURIX 2025", "pdf_url": "http://arxiv.org/pdf/2507.13732v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13981", "title": "Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset", "authors": ["Sara Abdulaziz", "Giacomo D'Amicantonio", "Egor Bondarev"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted at ICCV'25 workshop CV4BIOM", "url": "http://arxiv.org/abs/2507.13981v1", "summary": "Recent advances in AI-powered surveillance have intensified concerns over the\ncollection and processing of sensitive personal data. In response, research has\nincreasingly focused on privacy-by-design solutions, raising the need for\nobjective techniques to evaluate privacy protection. This paper presents a\ncomprehensive framework for evaluating visual privacy-protection methods across\nthree dimensions: privacy, utility, and practicality. In addition, it\nintroduces HR-VISPR, a publicly available human-centric dataset with biometric,\nsoft-biometric, and non-biometric labels to train an interpretable privacy\nmetric. We evaluate 11 privacy protection methods, ranging from conventional\ntechniques to advanced deep-learning methods, through the proposed framework.\nThe framework differentiates privacy levels in alignment with human visual\nperception, while highlighting trade-offs between privacy, utility, and\npracticality. This study, along with the HR-VISPR dataset, serves as an\ninsightful tool and offers a structured evaluation framework applicable across\ndiverse contexts.", "comment": "accepted at ICCV'25 workshop CV4BIOM", "pdf_url": "http://arxiv.org/pdf/2507.13981v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.06683", "title": "Solving Optimal Power Flow on a Data-Budget: Feature Selection on Smart Meter Data", "authors": ["Vassilis Kekatos", "Ridley Annin", "Manish K. Singh", "Junjie Qin"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures, 1 table", "url": "http://arxiv.org/abs/2502.06683v2", "summary": "How much data is needed to optimally schedule distributed energy resources\n(DERs)? Does the distribution system operator (DSO) have to know load demands\nat each bus of the feeder to solve an optimal power flow (OPF)? This work\nexploits redundancies in OPF's structure and data to minimize the communication\nof such a data deluge, and explores the trade-off between data compression and\nthe grid's performance. We propose an OPF data distillation framework involving\ntwo steps: The DSO first collects OPF data from only a subset of nodes. It\nsubsequently reconstructs the complete OPF data from the partial ones, and\nfeeds them into the OPF solver. Selecting and reconstructing OPF data may be\nperformed to maximize the fidelity of the reconstructed data or the associated\nOPF solutions. Under the first objective, OPF data distillation is posed as a\nsparsity-regularized convex problem. Under the second objective, it is posed as\na sparsity-regularized bilevel program. Both problems are solved using proximal\ngradient algorithms. The second objective is superior in approximating OPF\nsolutions at the expense of increased complexity. Numerical tests show that it\nenhances the fidelity and feasibility of the reconstructed OPF solutions, which\ncan be approximated reasonably well even from partial data.", "comment": "12 pages, 8 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2502.06683v2", "cate": "eess.SY", "date": "2025-02-10", "updated": "2025-07-18"}
{"id": "2507.12917", "title": "Beamforming Tradeoff for Sensing and Communication in Cell-Free MIMO", "authors": ["Xi Ding", "Luca Kunz", "E. Jorswieck"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12917v2", "summary": "This paper studies optimal joint beamforming (BF) for joint sensing and\ncommunication (JSAC) in small-scale cell-free MIMO (CF-MIMO) systems. While\nprior works have explored JSAC optimization using methods such as successive\nconvex approximation (SCA) and semidefinite relaxation (SDR), many of these\napproaches either lack global optimality or require additional rank-reduction\nsteps. In contrast, we propose an SDR-based optimization framework that\nguarantees globally optimal solutions without post-processing. To benchmark its\nperformance, we introduce a standalone BF strategy that dedicates each access\npoint (AP) exclusively to either communication or sensing. The proposed\nformulation builds upon a general multi-user system model, enabling future\nextensions beyond the single-user setting. Overall, our framework offers a\nglobally optimal and computationally efficient BF design, providing valuable\ninsights for the development of next-generation wireless networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12917v2", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2405.09298", "title": "A Mixture of Experts (MoE) model to improve AI-based computational pathology prediction performance under variable levels of histopathology image blur", "authors": ["Yujie Xiang", "Bojing Liu", "Mattias Rantalainen"], "categories": ["eess.IV", "cs.CV", "I.4; J.3"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.09298v5", "summary": "AI-based models for histopathology whole slide image (WSI) analysis are\nincreasingly common, but unsharp or blurred areas within WSI can significantly\nreduce prediction performance. In this study, we investigated the effect of\nimage blur on deep learning models and introduced a mixture of experts (MoE)\nstrategy that combines predictions from multiple expert models trained on data\nwith varying blur levels. Using H&E-stained WSIs from 2,093 breast cancer\npatients, we benchmarked performance on grade classification and IHC biomarker\nprediction with both CNN- (CNN_CLAM and MoE-CNN_CLAM) and Vision\nTransformer-based (UNI_CLAM and MoE-UNI_CLAM) models. Our results show that\nbaseline models' performance consistently decreased with increasing blur, but\nexpert models trained on blurred tiles and especially our proposed MoE approach\nsubstantially improved performance, and outperformed baseline models in a range\nof simulated scenarios. MoE-CNN_CLAM outperformed the baseline CNN_CLAM under\nmoderate (AUC: 0.868 vs. 0.702) and mixed blur conditions (AUC: 0.890 vs.\n0.875). MoE-UNI_CLAM outperformed the baseline UNI_CLAM model in both moderate\n(AUC: 0.950 vs. 0.928) and mixed blur conditions (AUC: 0.944 vs. 0.931). This\nMoE method has the potential to enhance the reliability of AI-based pathology\nmodels under variable image quality, supporting broader application in both\nresearch and clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.09298v5", "cate": "eess.IV", "date": "2024-05-15", "updated": "2025-07-18"}
{"id": "2507.13875", "title": "Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies", "authors": ["Carlos Mena", "Pol Serra", "Jacobo Romero", "Abir Messaoudi", "Jose Giraldo", "Carme Armentano-Oller", "Rodolfo Zevallos", "Ivan Meza", "Javier Hernando"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Interspeech 2025", "url": "http://arxiv.org/abs/2507.13875v1", "summary": "Code-switching (CS), the alternating use of two or more languages, challenges\nautomatic speech recognition (ASR) due to scarce training data and linguistic\nsimilarities. The lack of dedicated CS datasets limits ASR performance, as most\nmodels rely on monolingual or mixed-language corpora that fail to reflect\nreal-world CS patterns. This issue is critical in multilingual societies where\nCS occurs in informal and formal settings. A key example is Catalan-Spanish CS,\nwidely used in media and parliamentary speeches. In this work, we improve ASR\nfor Catalan-Spanish CS by exploring three strategies: (1) generating synthetic\nCS data, (2) concatenating monolingual audio, and (3) leveraging real CS data\nwith language tokens. We extract CS data from Catalan speech corpora and\nfine-tune OpenAI's Whisper models, making them available on Hugging Face.\nResults show that combining a modest amount of synthetic CS data with the\ndominant language token yields the best transcription performance.", "comment": "Accepted at Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.13875v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14119", "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining", "authors": ["Maksim Kuprashevich", "Grigorii Alekseenko", "Irina Tolstykh", "Georgii Fedorov", "Bulat Suleimanov", "Vladimir Dokholyan", "Aleksandr Gordeev"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14119v1", "summary": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14119v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13827", "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models", "authors": ["Hosein Azarbonyad", "Zi Long Zhu", "Georgios Cheirmpos", "Zubair Afzal", "Vikrant Yadav", "Georgios Tsatsaronis"], "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      SIGIR 2025", "url": "http://arxiv.org/abs/2507.13827v1", "summary": "When deciding to read an article or incorporate it into their research,\nscholars often seek to quickly identify and understand its main ideas. In this\npaper, we aim to extract these key concepts and contributions from scientific\narticles in the form of Question and Answer (QA) pairs. We propose two distinct\napproaches for generating QAs. The first approach involves selecting salient\nparagraphs, using a Large Language Model (LLM) to generate questions, ranking\nthese questions by the likelihood of obtaining meaningful answers, and\nsubsequently generating answers. This method relies exclusively on the content\nof the articles. However, assessing an article's novelty typically requires\ncomparison with the existing literature. Therefore, our second approach\nleverages a Knowledge Graph (KG) for QA generation. We construct a KG by\nfine-tuning an Entity Relationship (ER) extraction model on scientific articles\nand using it to build the graph. We then employ a salient triplet extraction\nmethod to select the most pertinent ERs per article, utilizing metrics such as\nthe centrality of entities based on a triplet TF-IDF-like measure. This measure\nassesses the saliency of a triplet based on its importance within the article\ncompared to its prevalence in the literature. For evaluation, we generate QAs\nusing both approaches and have them assessed by Subject Matter Experts (SMEs)\nthrough a set of predefined metrics to evaluate the quality of both questions\nand answers. Our evaluations demonstrate that the KG-based approach effectively\ncaptures the main ideas discussed in the articles. Furthermore, our findings\nindicate that fine-tuning the ER extraction model on our scientific corpus is\ncrucial for extracting high-quality triplets from such documents.", "comment": "SIGIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.13827v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13985", "title": "DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation", "authors": ["Haoran Li", "Yuli Tian", "Kun Lan", "Yong Liao", "Lin Wang", "Pan Hui", "Peng Yuan Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Extended version of ECCV 2024 paper \"DreamScene\"", "url": "http://arxiv.org/abs/2507.13985v1", "summary": "Generating 3D scenes from natural language holds great promise for\napplications in gaming, film, and design. However, existing methods struggle\nwith automation, 3D consistency, and fine-grained control. We present\nDreamScene, an end-to-end framework for high-quality and editable 3D scene\ngeneration from text or dialogue. DreamScene begins with a scene planning\nmodule, where a GPT-4 agent infers object semantics and spatial constraints to\nconstruct a hybrid graph. A graph-based placement algorithm then produces a\nstructured, collision-free layout. Based on this layout, Formation Pattern\nSampling (FPS) generates object geometry using multi-timestep sampling and\nreconstructive optimization, enabling fast and realistic synthesis. To ensure\nglobal consistent, DreamScene employs a progressive camera sampling strategy\ntailored to both indoor and outdoor settings. Finally, the system supports\nfine-grained scene editing, including object movement, appearance changes, and\n4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior\nmethods in quality, consistency, and flexibility, offering a practical solution\nfor open-domain 3D content creation. Code and demos are available at\nhttps://dreamscene-project.github.io.", "comment": "Extended version of ECCV 2024 paper \"DreamScene\"", "pdf_url": "http://arxiv.org/pdf/2507.13985v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.04287", "title": "Cyber Insurance Design for Load Variation and Load Curtailment in Distribution Grids", "authors": ["Shijie Pan", "Zaint A. Alexakis", "S Subhash Lakshminarayana", "Charalambos Konstantinou"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.04287v2", "summary": "Uncertainties in renewable energy resources (RES) and load variations can\nlead to elevated system operational costs. Moreover, the emergence of\nlarge-scale distributed threats, such as load-altering attacks (LAAs), can\ninduce substantial load variations, further exacerbating these costs. Although\ntraditional defense measures can reduce the likelihood of such attacks,\nconsiderable residual risks remain. Thus, this paper proposes a cyber insurance\nframework designed to hedge against additional operational costs resulting from\nLAAs and substantial load variations in renewable-rich grids. The insurance\nframework determines both the insurance coverage and premium based on the Value\nat Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated\nusing the system failure probability and the probability density function (PDF)\nof the system operation cost. The system failure probability is assessed\nthrough a semi-Markov process (SMP), while the cost distribution is estimated\nthrough a cost minimization model of a distribution grid combined with a\nMonte-Carlo simulation to capture load variability. Furthermore, we employ a\nbi-level optimization scheme that identifies the specific load distribution\nleading to the maximum system cost, thereby enhancing the accuracy of the\noperation cost PDF estimation. The effectiveness and scalability of the\nproposed cyber insurance policy are evaluated considering a modified IEEE-118\ntest bus system and the IEEE European low-voltage (LV) test feeders model. The\ncase study shows that with a relatively low premium, the network operator can\nhedge against additional operational costs caused by malicious load\nmanipulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.04287v2", "cate": "eess.SY", "date": "2025-04-05", "updated": "2025-07-18"}
{"id": "2507.07087", "title": "Incremental Averaging Method to Improve Graph-Based Time-Difference-of-Arrival Estimation", "authors": ["Klaus Brümann", "Kouei Yamaoka", "Nobutaka Ono", "Simon Doclo"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07087v2", "summary": "Estimating the position of a speech source based on\ntime-differences-of-arrival (TDOAs) is often adversely affected by background\nnoise and reverberation. A popular method to estimate the TDOA between a\nmicrophone pair involves maximizing a generalized cross-correlation with phase\ntransform (GCC-PHAT) function. Since the TDOAs across different microphone\npairs satisfy consistency relations, generally only a small subset of\nmicrophone pairs are used for source position estimation. Although the set of\nmicrophone pairs is often determined based on a reference microphone, recently\na more robust method has been proposed to determine the set of microphone pairs\nby computing the minimum spanning tree (MST) of a signal graph of GCC-PHAT\nfunction reliabilities. To reduce the influence of noise and reverberation on\nthe TDOA estimation accuracy, in this paper we propose to compute the GCC-PHAT\nfunctions of the MST based on an average of multiple cross-power spectral\ndensities (CPSDs) using an incremental method. In each step of the method, we\nincrease the number of CPSDs over which we average by considering CPSDs\ncomputed indirectly via other microphones from previous steps. Using signals\nrecorded in a noisy and reverberant laboratory with an array of spatially\ndistributed microphones, the performance of the proposed method is evaluated in\nterms of TDOA estimation error and 2D source position estimation error.\nExperimental results for different source and microphone configurations and\nthree reverberation conditions show that the proposed method considering\nmultiple CPSDs improves the TDOA estimation and source position estimation\naccuracy compared to the reference microphone- and MST-based methods that rely\non a single CPSD as well as steered-response power-based source position\nestimation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07087v2", "cate": "eess.AS", "date": "2025-07-09", "updated": "2025-07-18"}
{"id": "2501.13193", "title": "Revisiting Data Augmentation for Ultrasound Images", "authors": ["Adam Tupper", "Christian Gagné"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Published in the Transacations of Machine Learning Research (TMLR, 2025), see this https URL . For the associated source code see this https URL", "url": "http://arxiv.org/abs/2501.13193v2", "summary": "Data augmentation is a widely used and effective technique to improve the\ngeneralization performance of deep neural networks. Yet, despite often facing\nlimited data availability when working with medical images, it is frequently\nunderutilized. This appears to come from a gap in our collective understanding\nof the efficacy of different augmentation techniques across different tasks and\nmodalities. One modality where this is especially true is ultrasound imaging.\nThis work addresses this gap by analyzing the effectiveness of different\naugmentation techniques at improving model performance across a wide range of\nultrasound image analysis tasks. To achieve this, we introduce a new\nstandardized benchmark of 14 ultrasound image classification and semantic\nsegmentation tasks from 10 different sources and covering 11 body regions. Our\nresults demonstrate that many of the augmentations commonly used for tasks on\nnatural images are also effective on ultrasound images, even more so than\naugmentations developed specifically for ultrasound images in some cases. We\nalso show that diverse augmentation using TrivialAugment, which is widely used\nfor natural images, is also effective for ultrasound images. Moreover, our\nproposed methodology represents a structured approach for assessing various\ndata augmentations that can be applied to other contexts and modalities.", "comment": "Published in the Transacations of Machine Learning Research (TMLR,\n  2025), see https://openreview.net/forum?id=iGcxlTLIL5 . For the associated\n  source code see https://github.com/adamtupper/ultrasound-augmentation", "pdf_url": "http://arxiv.org/pdf/2501.13193v2", "cate": "eess.IV", "date": "2025-01-22", "updated": "2025-07-18"}
{"id": "2507.13977", "title": "Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic", "authors": ["Lilit Grigoryan", "Nikolay Karpov", "Enas Albasiri", "Vitaly Lavrukhin", "Boris Ginsburg"], "categories": ["cs.CL", "eess.AS", "I.5.1"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ICASSP 2025", "url": "http://arxiv.org/abs/2507.13977v1", "summary": "Despite Arabic being one of the most widely spoken languages, the development\nof Arabic Automatic Speech Recognition (ASR) systems faces significant\nchallenges due to the language's complexity, and only a limited number of\npublic Arabic ASR models exist. While much of the focus has been on Modern\nStandard Arabic (MSA), there is considerably less attention given to the\nvariations within the language. This paper introduces a universal methodology\nfor Arabic speech and text processing designed to address unique challenges of\nthe language. Using this methodology, we train two novel models based on the\nFastConformer architecture: one designed specifically for MSA and the other,\nthe first unified public model for both MSA and Classical Arabic (CA). The MSA\nmodel sets a new benchmark with state-of-the-art (SOTA) performance on related\ndatasets, while the unified model achieves SOTA accuracy with diacritics for CA\nwhile maintaining strong performance for MSA. To promote reproducibility, we\nopen-source the models and their training recipes.", "comment": "Accepted to ICASSP 2025", "pdf_url": "http://arxiv.org/pdf/2507.13977v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13357", "title": "Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models", "authors": ["Atharva Bhargude", "Ishan Gonehal", "Chandler Haney", "Dave Yoon", "Kevin Zhu", "Aaron Sandoval", "Sean O'Brien", "Kaustubh Vinnakota"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published at ACL 2025 SRW, 9 pages, 3 figures", "url": "http://arxiv.org/abs/2507.13357v1", "summary": "Phishing attacks represent a significant cybersecurity threat, necessitating\nadaptive detection techniques. This study explores few-shot Adaptive Linguistic\nPrompting (ALP) in detecting phishing webpages through the multimodal\ncapabilities of state-of-the-art large language models (LLMs) such as GPT-4o\nand Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides\nLLMs to analyze textual deception by breaking down linguistic patterns,\ndetecting urgency cues, and identifying manipulative diction commonly found in\nphishing content. By integrating textual, visual, and URL-based analysis, we\npropose a unified model capable of identifying sophisticated phishing attempts.\nOur experiments demonstrate that ALP significantly enhances phishing detection\naccuracy by guiding LLMs through structured reasoning and contextual analysis.\nThe findings highlight the potential of ALP-integrated multimodal LLMs to\nadvance phishing detection frameworks, achieving an F1-score of 0.93,\nsurpassing traditional approaches. These results establish a foundation for\nmore robust, interpretable, and adaptive linguistic-based phishing detection\nsystems using LLMs.", "comment": "Published at ACL 2025 SRW, 9 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.13357v1", "cate": "cs.CL", "date": "2025-06-29", "updated": "2025-06-29"}
{"id": "2507.13510", "title": "Strassen $2\\times2$ Matrix Multiplication from a 3-dimensional Volume Form", "authors": ["Benoit Jacob"], "categories": ["cs.DS", "cs.CC", "15A69 (Primary), 15A15, 14N07 (Secondary)"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2507.13510v1", "summary": "The Strassen $2\\times2$ matrix multiplication algorithm arises from the\nvolume form on the 3-dimensional quotient space of the $2\\times 2$ matrices by\nthe multiples of identity.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2507.13510v1", "cate": "cs.DS", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2407.07046", "title": "CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis", "authors": ["Yangmin Li", "Ruiqi Zhu", "Wengen Li"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.07046v3", "summary": "Multimodal sentiment analysis is an active research area that combines\nmultiple data modalities, e.g., text, image and audio, to analyze human\nemotions and benefits a variety of applications. Existing multimodal sentiment\nanalysis methods can be classified as modality interaction-based methods,\nmodality transformation-based methods and modality similarity-based methods.\nHowever, most of these methods highly rely on the strong correlations between\nmodalities, and cannot fully uncover and utilize the correlations between\nmodalities to enhance sentiment analysis. Therefore, these methods usually\nachieve bad performance for identifying the sentiment of multimodal data with\nweak correlations. To address this issue, we proposed a two-stage\nsemi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)\nwhich consists pre-training stage and prediction stage. At the pre-training\nstage, a modality correlation contrastive learning module is designed to\nefficiently learn modality correlation coefficients between different\nmodalities. At the prediction stage, the learned correlation coefficients are\nfused with modality representations to make the sentiment prediction. According\nto the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT\nobviously surpasses state-of-the-art multimodal sentiment analysis methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.07046v3", "cate": "cs.AI", "date": "2024-07-09", "updated": "2025-07-18"}
{"id": "2507.13835", "title": "Conformal Data Contamination Tests for Trading or Sharing of Data", "authors": ["Martin V. Vejling", "Shashi Raj Pandey", "Christophe A. N. Biscio", "Petar Popovski"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13835v1", "summary": "The amount of quality data in many machine learning tasks is limited to what\nis available locally to data owners. The set of quality data can be expanded\nthrough trading or sharing with external data agents. However, data buyers need\nquality guarantees before purchasing, as external data may be contaminated or\nirrelevant to their specific learning task. Previous works primarily rely on\ndistributional assumptions about data from different agents, relegating quality\nchecks to post-hoc steps involving costly data valuation procedures. We propose\na distribution-free, contamination-aware data-sharing framework that identifies\nexternal data agents whose data is most valuable for model personalization. To\nachieve this, we introduce novel two-sample testing procedures, grounded in\nrigorous theoretical foundations for conformal outlier detection, to determine\nwhether an agent's data exceeds a contamination threshold. The proposed tests,\ntermed conformal data contamination tests, remain valid under arbitrary\ncontamination levels while enabling false discovery rate control via the\nBenjamini-Hochberg procedure. Empirical evaluations across diverse\ncollaborative learning scenarios demonstrate the robustness and effectiveness\nof our approach. Overall, the conformal data contamination test distinguishes\nitself as a generic procedure for aggregating data with statistically rigorous\nquality guarantees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13835v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14010", "title": "Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations", "authors": ["Yong Feng", "Xiaolei Zhang", "Shijin Feng", "Yong Zhao", "Yihan Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures, 3 tables", "url": "http://arxiv.org/abs/2507.14010v1", "summary": "Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming\nto classify and segment tunnel cracks with enhanced accuracy and efficiency,\nthis study proposes a two-step deep learning-based method. An automatic tunnel\nimage classification model is developed using the DenseNet-169 in the first\nstep. The proposed crack segmentation model in the second step is based on the\nDeepLabV3+, whose internal logic is evaluated via a score-weighted visual\nexplanation technique. Proposed method combines tunnel image classification and\nsegmentation together, so that the selected images containing cracks from the\nfirst step are segmented in the second step to improve the detection accuracy\nand efficiency. The superior performances of the two-step method are validated\nby experiments. The results show that the accuracy and frames per second (FPS)\nof the tunnel crack classification model are 92.23% and 39.80, respectively,\nwhich are higher than other convolutional neural networks (CNN) based and\nTransformer based models. Also, the intersection over union (IoU) and F1 score\nof the tunnel crack segmentation model are 57.01% and 67.44%, respectively,\noutperforming other state-of-the-art models. Moreover, the provided visual\nexplanations in this study are conducive to understanding the \"black box\" of\ndeep learning-based models. The developed two-stage deep learning-based method\nintegrating visual explanations provides a basis for fast and accurate\nquantitative assessment of tunnel health status.", "comment": "8 pages, 10 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.14010v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.19518", "title": "Discrete-time Two-Layered Forgetting RLS Identification under Finite Excitation", "authors": ["Satoshi Tsuruhara", "Kazuhisa Ito"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures, accepted at the 5th Modeling, Estimation and Control Conference (MECC 2025)", "url": "http://arxiv.org/abs/2504.19518v2", "summary": "In recent years, adaptive identification methods that can achieve the true\nvalue convergence of parameters without requiring persistent excitation (PE)\nhave been widely studied, and concurrent learning has been intensively studied.\nHowever, the parameter convergence rate is limited for the gradient-based\nmethod owing to small parameter update gain, and even the introduction of\nforgetting factors does not work sufficiently. To address this problem, this\nstudy proposes a novel discrete-time recursive least squares method under\nfinite excitation (FE) conditions using two forgetting factors (inner and\nouter) and an augmented regressor matrix comprising a sum of regressor vectors.\nThe proposed method ensures the PE condition of the augmented regressor matrix\nunder FE conditions of the regressor vector and allows the properly design of\nthe forgetting factor without estimator windup and/or destabilization of the\nsystem. Numerical simulations demonstrate its effectiveness by comparing it\nwith several conventional methods.", "comment": "6 pages, 6 figures, accepted at the 5th Modeling, Estimation and\n  Control Conference (MECC 2025)", "pdf_url": "http://arxiv.org/pdf/2504.19518v2", "cate": "eess.SY", "date": "2025-04-28", "updated": "2025-07-18"}
{"id": "2506.23298", "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification", "authors": ["Xing Shen", "Justin Szeto", "Mingyang Li", "Hengguan Huang", "Tal Arbel"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Preprint version. The peer-reviewed version of this paper has been accepted to MICCAI 2025 main conference", "url": "http://arxiv.org/abs/2506.23298v3", "summary": "Multimodal large language models (MLLMs) have enormous potential to perform\nfew-shot in-context learning in the context of medical image analysis. However,\nsafe deployment of these models into real-world clinical practice requires an\nin-depth analysis of the accuracies of their predictions, and their associated\ncalibration errors, particularly across different demographic subgroups. In\nthis work, we present the first investigation into the calibration biases and\ndemographic unfairness of MLLMs' predictions and confidence scores in few-shot\nin-context learning for medical image classification. We introduce CALIN, an\ninference-time calibration method designed to mitigate the associated biases.\nSpecifically, CALIN estimates the amount of calibration needed, represented by\ncalibration matrices, using a bi-level procedure: progressing from the\npopulation level to the subgroup level prior to inference. It then applies this\nestimation to calibrate the predicted confidence scores during inference.\nExperimental results on three medical imaging datasets: PAPILA for fundus image\nclassification, HAM10000 for skin cancer classification, and MIMIC-CXR for\nchest X-ray classification demonstrate CALIN's effectiveness at ensuring fair\nconfidence calibration in its prediction, while improving its overall\nprediction accuracies and exhibiting minimum fairness-utility trade-off. Our\ncodebase can be found at\nhttps://github.com/xingbpshen/medical-calibration-fairness-mllm.", "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to MICCAI 2025 main conference", "pdf_url": "http://arxiv.org/pdf/2506.23298v3", "cate": "eess.IV", "date": "2025-06-29", "updated": "2025-07-17"}
{"id": "2507.14129", "title": "OpenBEATs: A Fully Open-Source General-Purpose Audio Encoder", "authors": ["Shikhar Bharadwaj", "Samuele Cornell", "Kwanghee Choi", "Satoru Fukayama", "Hye-jin Shim", "Soham Deshmukh", "Shinji Watanabe"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14129v1", "summary": "Masked token prediction has emerged as a powerful pre-training objective\nacross language, vision, and speech, offering the potential to unify these\ndiverse modalities through a single pre-training task. However, its application\nfor general audio understanding remains underexplored, with BEATs being the\nonly notable example. BEATs has seen limited modifications due to the absence\nof open-source pre-training code. Furthermore, BEATs was trained only on\nAudioSet, restricting its broader downstream applicability. To address these\ngaps, we present OpenBEATs, an open-source framework that extends BEATs via\nmulti-domain audio pre-training. We conduct comprehensive evaluations across\nsix types of tasks, twenty five datasets, and three audio domains, including\naudio reasoning tasks such as audio question answering, entailment, and\ncaptioning. OpenBEATs achieves state-of-the-art performance on six bioacoustics\ndatasets, two environmental sound datasets and five reasoning datasets,\nperforming better than models exceeding a billion parameters at one-fourth\ntheir parameter size. These results demonstrate the effectiveness of\nmulti-domain datasets and masked token prediction task to learn general-purpose\naudio representations. To promote further research and reproducibility, we\nrelease all pre-training and evaluation code, pretrained and fine-tuned\ncheckpoints, and training logs at https://shikhar-s.github.io/OpenBEATs", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14129v1", "cate": "cs.SD", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13474", "title": "Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers", "authors": ["Liang Lin", "Zhihao Xu", "Xuehai Tang", "Shi Liu", "Biyu Zhou", "Fuqing Zhu", "Jizhong Han", "Songlin Hu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13474v1", "summary": "The safety of large language models (LLMs) has garnered significant research\nattention. In this paper, we argue that previous empirical studies demonstrate\nLLMs exhibit a propensity to trust information from authoritative sources, such\nas academic papers, implying new possible vulnerabilities. To verify this\npossibility, a preliminary analysis is designed to illustrate our two findings.\nBased on this insight, a novel jailbreaking method, Paper Summary Attack\n(\\llmname{PSA}), is proposed. It systematically synthesizes content from either\nattack-focused or defense-focused LLM safety paper to construct an adversarial\nprompt template, while strategically infilling harmful query as adversarial\npayloads within predefined subsections. Extensive experiments show significant\nvulnerabilities not only in base LLMs, but also in state-of-the-art reasoning\nmodel like Deepseek-R1. PSA achieves a 97\\% attack success rate (ASR) on\nwell-aligned models like Claude3.5-Sonnet and an even higher 98\\% ASR on\nDeepseek-R1. More intriguingly, our work has further revealed diametrically\nopposed vulnerability bias across different base models, and even between\ndifferent versions of the same model, when exposed to either attack-focused or\ndefense-focused papers. This phenomenon potentially indicates future research\nclues for both adversarial methodologies and safety alignment.Code is available\nat https://github.com/233liang/Paper-Summary-Attack", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13474v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13671", "title": "Combinatorics of Palindromes", "authors": ["Michael Itzhaki"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Full version, accepted to FCT25", "url": "http://arxiv.org/abs/2507.13671v1", "summary": "We investigate the structure and reconstruction complexity of Manacher\narrays. First, we establish a combinatorial lower bound, proving that the\nnumber of rooted tandem repeat trees with $n+1$ genes exceeds the number of\ndistinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic\nframework that associates a graph to each Manacher array, where every proper\nvertex coloring yields a string consistent with the array. Finally, we analyze\na reconstruction algorithm by I et al. (SPIRE 2010), showing that it\nsimultaneously achieves a globally minimal alphabet size, uses at most\n$\\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce\nreconstructions over arbitrary alphabets when possible. Our results also\nresolve an open problem posed by the original authors. Together, these findings\nadvance the combinatorial understanding of Manacher arrays and open new\ndirections for string reconstruction under structural constraints.", "comment": "Full version, accepted to FCT25", "pdf_url": "http://arxiv.org/pdf/2507.13671v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2409.18877", "title": "UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception", "authors": ["Chuang Chen", "Xiao Sun", "Zhi Liu"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TIP", "url": "http://arxiv.org/abs/2409.18877v3", "summary": "Visual emotion analysis holds significant research value in both computer\nvision and psychology. However, existing methods for visual emotion analysis\nsuffer from limited generalizability due to the ambiguity of emotion perception\nand the diversity of data scenarios. To tackle this issue, we introduce\nUniEmoX, a cross-modal semantic-guided large-scale pretraining framework.\nInspired by psychological research emphasizing the inseparability of the\nemotional exploration process from the interaction between individuals and\ntheir environment, UniEmoX integrates scene-centric and person-centric\nlow-level image spatial structural information, aiming to derive more nuanced\nand discriminative emotional representations. By exploiting the similarity\nbetween paired and unpaired image-text samples, UniEmoX distills rich semantic\nknowledge from the CLIP model to enhance emotional embedding representations\nmore effectively. To the best of our knowledge, this is the first large-scale\npretraining framework that integrates psychological theories with contemporary\ncontrastive learning and masked image modeling techniques for emotion analysis\nacross diverse scenarios. Additionally, we develop a visual emotional dataset\ntitled Emo8. Emo8 samples cover a range of domains, including cartoon, natural,\nrealistic, science fiction and advertising cover styles, covering nearly all\ncommon emotional scenes. Comprehensive experiments conducted on six benchmark\ndatasets across two downstream tasks validate the effectiveness of UniEmoX. The\nsource code is available at https://github.com/chincharles/u-emo.", "comment": "Accepted by IEEE TIP", "pdf_url": "http://arxiv.org/pdf/2409.18877v3", "cate": "cs.AI", "date": "2024-09-27", "updated": "2025-07-18"}
{"id": "2507.13887", "title": "A Survey of Dimension Estimation Methods", "authors": ["James A. D. Binnie", "Paweł Dłotko", "John Harvey", "Jakub Malinowski", "Ka Man Yim"], "categories": ["stat.ML", "cs.LG", "math.DG", "math.MG", "math.ST", "stat.TH", "62R40 (Primary) 62R30, 62R07, 62G05, 53Z50 (Secondary)"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      45 pages + appendices, 24 figures", "url": "http://arxiv.org/abs/2507.13887v1", "summary": "It is a standard assumption that datasets in high dimension have an internal\nstructure which means that they in fact lie on, or near, subsets of a lower\ndimension. In many instances it is important to understand the real dimension\nof the data, hence the complexity of the dataset at hand. A great variety of\ndimension estimators have been developed to find the intrinsic dimension of the\ndata but there is little guidance on how to reliably use these estimators.\n  This survey reviews a wide range of dimension estimation methods,\ncategorising them by the geometric information they exploit: tangential\nestimators which detect a local affine structure; parametric estimators which\nrely on dimension-dependent probability distributions; and estimators which use\ntopological or metric invariants.\n  The paper evaluates the performance of these methods, as well as\ninvestigating varying responses to curvature and noise. Key issues addressed\ninclude robustness to hyperparameter selection, sample size requirements,\naccuracy in high dimensions, precision, and performance on non-linear\ngeometries. In identifying the best hyperparameters for benchmark datasets,\noverfitting is frequent, indicating that many estimators may not generalise\nwell beyond the datasets on which they have been tested.", "comment": "45 pages + appendices, 24 figures", "pdf_url": "http://arxiv.org/pdf/2507.13887v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14013", "title": "Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model", "authors": ["Ji-Yan Wu", "Zheng Yong Poh", "Anoop C. Patil", "Bongsoo Park", "Giovanni Volpe", "Daisuke Urano"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14013v1", "summary": "Accurate detection of nutrient deficiency in plant leaves is essential for\nprecision agriculture, enabling early intervention in fertilization, disease,\nand stress management. This study presents a deep learning framework for leaf\nanomaly segmentation using multispectral imaging and an enhanced YOLOv5 model\nwith a transformer-based attention head. The model is tailored for processing\nnine-channel multispectral input and uses self-attention mechanisms to better\ncapture subtle, spatially-distributed symptoms. The plants in the experiments\nwere grown under controlled nutrient stress conditions for evaluation. We carry\nout extensive experiments to benchmark the proposed model against the baseline\nYOLOv5. Extensive experiments show that the proposed model significantly\noutperforms the baseline YOLOv5, with an average Dice score and IoU\n(Intersection over Union) improvement of about 12%. In particular, this model\nis effective in detecting challenging symptoms like chlorosis and pigment\naccumulation. These results highlight the promise of combining multi-spectral\nimaging with spectral-spatial feature learning for advancing plant phenotyping\nand precision agriculture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14013v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12327", "title": "Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices", "authors": ["Mohamad Charara", "Martin De Montigny", "Nivine Abou Daher", "Hanane Dagdougui", "Antoine Lesage-Landry"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, submitted to CIGRÉ 2025 International Symposium, Paper 10998, PS1: System Enhancement, Markets and Regulation", "url": "http://arxiv.org/abs/2507.12327v2", "summary": "With the increasing energy demand and the growing integration of renewable\nsources of energy, power systems face operational challenges such as overloads,\nlosses, and stability concerns, particularly as networks operate near their\ncapacity limits. Flexible alternating current transmission system (FACTS)\ndevices are essential to ensure reliable grid operations and enable the\nefficient integration of renewable energy. This work introduces a mixed-integer\nsecond-order cone programming (MISOCP) model for the multi-period scheduling of\nkey FACTS devices in electric transmission systems. The proposed model\nintegrates four key control mechanisms: (i) on-load tap changers (OLTCs) for\nvoltage regulation via discrete taps; (ii) static synchronous compensators\n(STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv)\nthyristor-controlled series capacitors (TCSCs) for adjustable impedance and\nflow control. The objective is to minimize active power losses using a limited\nnumber of control actions while meeting physical and operational constraints at\nall times throughout the defined time horizon. To ensure tractability, the\nmodel employs a second-order cone relaxation of the power flow. Device-specific\nconstraints are handled via binary expansion and linearization: OLTCs and shunt\nreactors are modelled with discrete variables, STATCOMs through reactive power\nbounds, and TCSCs using a reformulation-linearization technique (RLT). A\nmulti-period formulation captures the sequential nature of decision making,\nensuring consistency across time steps. The model is evaluated on the IEEE\n9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce\nlosses, with potential applicability to larger-scale grids.", "comment": "10 pages, 1 figure, submitted to CIGR\\'E 2025 International\n  Symposium, Paper 10998, PS1: System Enhancement, Markets and Regulation", "pdf_url": "http://arxiv.org/pdf/2507.12327v2", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.03733", "title": "Inverse Synthetic Aperture Fourier Ptychography", "authors": ["Matthew A. Chan", "Casey J. Pellizzari", "Christopher A. Metzler"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03733v2", "summary": "Fourier ptychography (FP) is a powerful light-based synthetic aperture\nimaging technique that allows one to reconstruct a high-resolution, wide\nfield-of-view image by computationally integrating a diverse collection of\nlow-resolution, far-field measurements. Typically, FP measurement diversity is\nintroduced by changing the angle of the illumination or the position of the\ncamera; either approach results in sampling different portions of the target's\nspatial frequency content, but both approaches introduce substantial costs and\ncomplexity to the acquisition process. In this work, we introduce Inverse\nSynthetic Aperture Fourier Ptychography, a novel approach to FP that foregoes\nchanging the illumination angle or camera position and instead generates\nmeasurement diversity through target motion. Critically, we also introduce a\nnovel learning-based method for estimating k-space coordinates from dual plane\nintensity measurements, thereby enabling synthetic aperture imaging without\nknowing the rotation of the target. We experimentally validate our method in\nsimulation and on a tabletop optical system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03733v2", "cate": "eess.IV", "date": "2025-07-04", "updated": "2025-07-17"}
{"id": "2412.11392", "title": "A lightweight and robust method for blind wideband-to-fullband extension of speech", "authors": ["Jan Büthe", "Jean-Marc Valin"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      WASPAA 2025, 5 pages", "url": "http://arxiv.org/abs/2412.11392v4", "summary": "Reducing the bandwidth of speech is common practice in resource constrained\nenvironments like low-bandwidth speech transmission or low-complexity vocoding.\nWe propose a lightweight and robust method for extending the bandwidth of\nwideband speech signals that is inspired by classical methods developed in the\nspeech coding context. The resulting model has just ~370K parameters and a\ncomplexity of ~140 MFLOPS (or ~70 MMACS). With a frame size of 10 ms and a\nlookahead of only 0.27 ms, the model is well-suited for use with common\nwideband speech codecs. We evaluate the model's robustness by pairing it with\nthe Opus SILK speech codec (1.5 release) and verify in a P.808 DCR listening\ntest that it significantly improves quality from 6 to 12 kb/s. We also\ndemonstrate that Opus 1.5 together with the proposed bandwidth extension at 9\nkb/s meets the quality of 3GPP EVS at 9.6 kb/s and that of Opus 1.4 at 18 kb/s\nshowing that the blind bandwidth extension can meet the quality of classical\nguided bandwidth extensions thus providing a way for backward-compatible\nquality improvement.", "comment": "WASPAA 2025, 5 pages", "pdf_url": "http://arxiv.org/pdf/2412.11392v4", "cate": "eess.AS", "date": "2024-12-16", "updated": "2025-07-18"}
{"id": "2507.13490", "title": "Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?", "authors": ["Siqi Shen", "Mehar Singh", "Lajanugen Logeswaran", "Moontae Lee", "Honglak Lee", "Rada Mihalcea"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13490v1", "summary": "There has been extensive research on assessing the value orientation of Large\nLanguage Models (LLMs) as it can shape user experiences across demographic\ngroups. However, several challenges remain. First, while the Multiple Choice\nQuestion (MCQ) setting has been shown to be vulnerable to perturbations, there\nis no systematic comparison of probing methods for value probing. Second, it is\nunclear to what extent the probed values capture in-context information and\nreflect models' preferences for real-world actions. In this paper, we evaluate\nthe robustness and expressiveness of value representations across three widely\nused probing strategies. We use variations in prompts and options, showing that\nall methods exhibit large variances under input perturbations. We also\nintroduce two tasks studying whether the values are responsive to demographic\ncontext, and how well they align with the models' behaviors in value-related\nscenarios. We show that the demographic context has little effect on the\nfree-text generation, and the models' values only weakly correlate with their\npreference for value-based actions. Our work highlights the need for a more\ncareful examination of LLM value probing and awareness of its limitations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13490v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13869", "title": "Improved girth approximation in weighted undirected graphs", "authors": ["Avi Kadria", "Liam Roditty", "Aaron Sidford", "Virginia Vassilevska Williams", "Uri Zwick"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13869v1", "summary": "Let $G = (V,E,\\ell)$ be a $n$-node $m$-edge weighted undirected graph, where\n$\\ell: E \\rightarrow (0,\\infty)$ is a real \\emph{length} function defined on\nits edges, and let $g$ denote the girth of $G$, i.e., the length of its\nshortest cycle. We present an algorithm that, for any input, integer $k \\geq\n1$, in $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ expected time finds a cycle of\nlength at most $\\frac{4k}{3}g$. This algorithm nearly matches a\n$O(n^{1+1/k}\\log{n})$-time algorithm of \\cite{KadriaRSWZ22} which applied to\nunweighted graphs of girth $3$. For weighted graphs, this result also improves\nupon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\\log n+m)\\log\n(nM))$ time, where $\\ell: E \\rightarrow [1, M]$ is an integral length function,\nfinds a cycle of length at most $2kg$~\\cite{KadriaRSWZ22}. For $k=1$ this\nresult improves upon the result of Roditty and Tov~\\cite{RodittyT13}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13869v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13377", "title": "StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation", "authors": ["Zhenglin Pan", "Haoran Xie"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      3 pages, 3 figures. SIGGRAPH 2025 Poster", "url": "http://arxiv.org/abs/2507.13377v1", "summary": "In this paper, we propose StructInbet, an inbetweening system designed to\ngenerate controllable transitions over explicit structural guidance.\nStructInbet introduces two key contributions. First, we propose explicit\nstructural guidance to the inbetweening problem to reduce the ambiguity\ninherent in pixel trajectories. Second, we adopt a temporal attention mechanism\nthat incorporates visual identity from both the preceding and succeeding\nkeyframes, ensuring consistency in character appearance.", "comment": "3 pages, 3 figures. SIGGRAPH 2025 Poster", "pdf_url": "http://arxiv.org/pdf/2507.13377v1", "cate": "cs.GR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.00691", "title": "To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization", "authors": ["Haozhe Wang", "Long Li", "Chao Qu", "Fengming Zhu", "Weidi Xu", "Wei Chu", "Fangzhen Lin"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025", "url": "http://arxiv.org/abs/2502.00691v4", "summary": "Recent advances in mathematical problem-solving with language models (LMs)\nintegrate chain-of-thought (CoT) reasoning and code execution to harness their\ncomplementary strengths. However, existing hybrid frameworks exhibit a critical\nlimitation: they depend on externally dictated instructions or rigid\ncode-integration templates, lacking metacognitive awareness -- the capacity to\ndynamically evaluate intrinsic capabilities and autonomously determine when and\nhow to integrate tools. This rigidity motivates our study of autonomous code\nintegration, enabling models to adapt tool-usage strategies as their reasoning\nabilities evolve during training.\n  While reinforcement learning (RL) shows promise for boosting LLM reasoning at\nscale (e.g., DeepSeek-R1), we demonstrate its inefficiency in learning\nautonomous code integration due to inadequate exploration of the vast\ncombinatorial space of CoT-code interleaving patterns. To address this\nchallenge, we propose a novel Expectation-Maximization (EM) framework that\nsynergizes structured exploration (E-step) with off-policy RL optimization\n(M-step), creating a self-reinforcing cycle between metacognitive tool-use\ndecisions and evolving capabilities. Experiments reveal our method achieves\nsuperior results through improved exploration. Notably, our 7B model improves\nover 11% on MATH500 and 9.4% on AIME without o1-like CoT.", "comment": "Accepted to ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.00691v4", "cate": "cs.AI", "date": "2025-02-02", "updated": "2025-07-18"}
{"id": "2507.14017", "title": "Efficient Temporal Tokenization for Mobility Prediction with Large Language Models", "authors": ["Haoyu He", "Haozheng Luo", "Yan Chen", "Qi R. Wang"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14017v1", "summary": "We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for\nHuman Mobility), a framework that leverages large language models (LLMs) as\nspatio-temporal predictors and trajectory reasoners. RHYTHM partitions\ntrajectories into daily segments encoded as discrete tokens with hierarchical\nattention, capturing both daily and weekly dependencies while substantially\nreducing the sequence length. Token representations are enriched with\npre-computed prompt embeddings via a frozen LLM, enhancing the model's ability\nto capture interdependencies without extensive computational overhead. By\nfreezing the LLM backbone, RHYTHM achieves significant computational\nefficiency. Evaluation on three real-world datasets demonstrates a 2.4%\nimprovement in accuracy, 5.0% increase on weekends, and 24.6% reduction in\ntraining time compared to state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14017v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14024", "title": "Moodifier: MLLM-Enhanced Emotion-Driven Image Editing", "authors": ["Jiarong Ye", "Sharon X. Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14024v1", "summary": "Bridging emotions and visual content for emotion-driven image editing holds\ngreat potential in creative industries, yet precise manipulation remains\nchallenging due to the abstract nature of emotions and their varied\nmanifestations across different contexts. We tackle this challenge with an\nintegrated approach consisting of three complementary components. First, we\nintroduce MoodArchive, an 8M+ image dataset with detailed hierarchical\nemotional annotations generated by LLaVA and partially validated by human\nevaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned\non MoodArchive to translate abstract emotions into specific visual attributes.\nThird, we propose Moodifier, a training-free editing model leveraging\nMoodifyCLIP and multimodal large language models (MLLMs) to enable precise\nemotional transformations while preserving content integrity. Our system works\nacross diverse domains such as character expressions, fashion design, jewelry,\nand home d\\'ecor, enabling creators to quickly visualize emotional variations\nwhile preserving identity and structure. Extensive experimental evaluations\nshow that Moodifier outperforms existing methods in both emotional accuracy and\ncontent preservation, providing contextually appropriate edits. By linking\nabstract emotions to concrete visual changes, our solution unlocks new\npossibilities for emotional content creation in real-world applications. We\nwill release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier\ncode and demo publicly available upon acceptance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14024v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2304.06049", "title": "Equivalent and Compact Representations of Neural Network Controllers With Decision Trees", "authors": ["Kevin Chang", "Nathan Dahlin", "Rahul Jain", "Pierluigi Nuzzo"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2304.06049v3", "summary": "Over the past decade, neural network (NN)-based controllers have demonstrated\nremarkable efficacy in a variety of decision-making tasks. However, their\nblack-box nature and the risk of unexpected behaviors pose a challenge to their\ndeployment in real-world systems requiring strong guarantees of correctness and\nsafety. We address these limitations by investigating the transformation of\nNN-based controllers into equivalent soft decision tree (SDT)-based controllers\nand its impact on verifiability. In contrast to existing work, we focus on\ndiscrete-output NN controllers including rectified linear unit (ReLU)\nactivation functions as well as argmax operations. We then devise an exact yet\nefficient transformation algorithm which automatically prunes redundant\nbranches. We first demonstrate the practical efficacy of the transformation\nalgorithm applied to an autonomous driving NN controller within OpenAI Gym's\nCarRacing environment. Subsequently, we evaluate our approach using two\nbenchmarks from the OpenAI Gym environment. Our results indicate that the SDT\ntransformation can benefit formal verification, showing runtime improvements of\nup to $21 \\times$ and $2 \\times$ for MountainCar-v0 and CartPole-v1,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2304.06049v3", "cate": "cs.LG", "date": "2023-04-11", "updated": "2025-07-18"}
{"id": "2505.16195", "title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet", "authors": ["Zhi Zhong", "Akira Takahashi", "Shuyang Cui", "Keisuke Toyama", "Shusuke Takahashi", "Yuki Mitsufuji"], "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      WASPAA 2025. 4 pages, 2 figures, 2 tables. Demo page: this https URL", "url": "http://arxiv.org/abs/2505.16195v2", "summary": "Foley synthesis aims to synthesize high-quality audio that is both\nsemantically and temporally aligned with video frames. Given its broad\napplication in creative industries, the task has gained increasing attention in\nthe research community. To avoid the non-trivial task of training audio\ngenerative models from scratch, adapting pretrained audio generative models for\nvideo-synchronized foley synthesis presents an attractive direction.\nControlNet, a method for adding fine-grained controls to pretrained generative\nmodels, has been applied to foley synthesis, but its use has been limited to\nhandcrafted human-readable temporal conditions. In contrast, from-scratch\nmodels achieved success by leveraging high-dimensional deep features extracted\nusing pretrained video encoders. We have observed a performance gap between\nControlNet-based and from-scratch foley models. To narrow this gap, we propose\nSpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward\nvideo-synchronized foley synthesis via ControlNet. To unlock the potential of a\nsingle ControlNet branch, we resolve the discrepancy between the temporal video\nfeatures and the time-frequency nature of the pretrained SpecMaskGIT via a\nfrequency-aware temporal feature aligner, eliminating the need for complicated\nconditioning mechanisms widely used in prior arts. Evaluations on a common\nfoley synthesis benchmark demonstrate that SpecMaskFoley could even outperform\nstrong from-scratch baselines, substantially advancing the development of\nControlNet-based foley synthesis models. Demo page:\nhttps://zzaudio.github.io/SpecMaskFoley_Demo/", "comment": "WASPAA 2025. 4 pages, 2 figures, 2 tables. Demo page:\n  https://zzaudio.github.io/SpecMaskFoley_Demo/", "pdf_url": "http://arxiv.org/pdf/2505.16195v2", "cate": "cs.SD", "date": "2025-05-22", "updated": "2025-07-17"}
{"id": "2405.18386", "title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning", "authors": ["Yixiao Zhang", "Yukara Ikemiya", "Woosung Choi", "Naoki Murata", "Marco A. Martínez-Ramírez", "Liwei Lin", "Gus Xia", "Wei-Hsiang Liao", "Yuki Mitsufuji", "Simon Dixon"], "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at ISMIR 2025 Conference. Code and demo are available at: this https URL", "url": "http://arxiv.org/abs/2405.18386v3", "summary": "Recent advances in text-to-music editing, which employ text queries to modify\nmusic (e.g.\\ by changing its style or adjusting instrumental components),\npresent unique challenges and opportunities for AI-assisted music creation.\nPrevious approaches in this domain have been constrained by the necessity to\ntrain specific editing models from scratch, which is both resource-intensive\nand inefficient; other research uses large language models to predict edited\nmusic, resulting in imprecise audio reconstruction. To Combine the strengths\nand address these limitations, we introduce Instruct-MusicGen, a novel approach\nthat finetunes a pretrained MusicGen model to efficiently follow editing\ninstructions such as adding, removing, or separating stems. Our approach\ninvolves a modification of the original MusicGen architecture by incorporating\na text fusion module and an audio fusion module, which allow the model to\nprocess instruction texts and audio inputs concurrently and yield the desired\nedited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters\nto the original MusicGen model and only trains for 5K steps, yet it achieves\nsuperior performance across all tasks compared to existing baselines, and\ndemonstrates performance comparable to the models trained for specific tasks.\nThis advancement not only enhances the efficiency of text-to-music editing but\nalso broadens the applicability of music language models in dynamic music\nproduction environments.", "comment": "Accepted at ISMIR 2025 Conference. Code and demo are available at:\n  https://github.com/ldzhangyx/instruct-musicgen", "pdf_url": "http://arxiv.org/pdf/2405.18386v3", "cate": "cs.SD", "date": "2024-05-28", "updated": "2025-07-17"}
{"id": "2507.13501", "title": "Encoding syntactic objects and Merge operations in function spaces", "authors": ["Matilde Marcolli", "Robert C. Berwick"], "categories": ["cs.CL", "math.RA", "q-bio.NC", "91F20, 16Y60, 16T05, 92C20"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      40 pages, LaTeX, 4 png figures", "url": "http://arxiv.org/abs/2507.13501v1", "summary": "We provide a mathematical argument showing that, given a representation of\nlexical items as functions (wavelets, for instance) in some function space, it\nis possible to construct a faithful representation of arbitrary syntactic\nobjects in the same function space. This space can be endowed with a\ncommutative non-associative semiring structure built using the second Renyi\nentropy. The resulting representation of syntactic objects is compatible with\nthe magma structure. The resulting set of functions is an algebra over an\noperad, where the operations in the operad model circuits that transform the\ninput wave forms into a combined output that encodes the syntactic structure.\nThe action of Merge on workspaces is faithfully implemented as action on these\ncircuits, through a coproduct and a Hopf algebra Markov chain. The results\nobtained here provide a constructive argument showing the theoretical\npossibility of a neurocomputational realization of the core computational\nstructure of syntax. We also present a particular case of this general\nconstruction where this type of realization of Merge is implemented as a cross\nfrequency phase synchronization on sinusoidal waves. This also shows that Merge\ncan be expressed in terms of the successor function of a semiring, thus\nclarifying the well known observation of its similarities with the successor\nfunction of arithmetic.", "comment": "40 pages, LaTeX, 4 png figures", "pdf_url": "http://arxiv.org/pdf/2507.13501v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13885", "title": "Quantum Pattern Matching with Wildcards", "authors": ["Masoud Seddighin", "Saeed Seddighin"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13885v1", "summary": "Pattern matching is one of the fundamental problems in Computer Science. Both\nthe classic version of the problem as well as the more sophisticated version\nwhere wildcards can also appear in the input can be solved in almost linear\ntime $\\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform,\nrespectively. In 2000, Ramesh and Vinay~\\cite{ramesh2003string} give a quantum\nalgorithm that solves classic pattern matching in sublinear time and asked\nwhether the wildcard problem can also be solved in sublinear time? In this\nwork, we give a quantum algorithm for pattern matching with wildcards that runs\nin time $\\tilde O(\\sqrt{n}\\sqrt{k})$ when the number of wildcards is bounded by\n$k$ for $k \\geq \\sqrt{n}$. This leads to an algorithm that runs in sublinear\ntime as long as the number of wildcards is sublinear.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13885v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13388", "title": "DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis", "authors": ["Zhen-Qi Chen", "Yuan-Fu Yang"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13388v1", "summary": "With the rapid advancement of diffusion-based generative models, Stable\nDiffusion (SD) has emerged as a state-of-the-art framework for high-fidelity\nim-age synthesis. However, existing SD models suffer from suboptimal feature\naggregation, leading to in-complete semantic alignment and loss of fine-grained\ndetails, especially in highly textured and complex scenes. To address these\nlimitations, we propose a novel dual-latent integration framework that\nen-hances feature interactions between the base latent and refined latent\nrepresentations. Our approach em-ploys a feature concatenation strategy\nfollowed by an adaptive fusion module, which can be instantiated as either (i)\nan Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or\n(ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design\nenables more effective cross-latent com-munication, preserving both global\ncoherence and local texture fidelity. Our GitHub page:\nhttps://anonymous.4open.science/r/MVA2025-22 .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13388v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2503.09567", "title": "Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models", "authors": ["Qiguang Chen", "Libo Qin", "Jinhao Liu", "Dengyun Peng", "Jiannan Guan", "Peng Wang", "Mengkang Hu", "Yuhang Zhou", "Te Gao", "Wanxiang Che"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Paper list and Github tutorial are available at this https URL . Update 250+ New Reference", "url": "http://arxiv.org/abs/2503.09567v5", "summary": "Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"inference-time scaling.\" This survey seeks\nto fill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and inference-time scaling,\noffering insights into how these processes manifest in practice. (4) Finally,\nwe identify significant research gaps and highlight promising future\ndirections, including the integration of multi-modal reasoning, efficiency\nimprovements, and enhanced knowledge frameworks. By providing a structured\noverview, this survey aims to inspire future research and further the\ndevelopment of logical reasoning in artificial intelligence.", "comment": "Paper list and Github tutorial are available at\n  https://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning.\n  Update 250+ New Reference", "pdf_url": "http://arxiv.org/pdf/2503.09567v5", "cate": "cs.AI", "date": "2025-03-12", "updated": "2025-07-18"}
{"id": "2507.14022", "title": "CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis", "authors": ["Jianfei Li", "Kevin Kam Fung Yuen"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      35 pages, 33 tables, 6 Figures", "url": "http://arxiv.org/abs/2507.14022v1", "summary": "This study proposes the Cognitive Pairwise Comparison Classification Model\nSelection (CPC-CMS) framework for document-level sentiment analysis. The CPC,\nbased on expert knowledge judgment, is used to calculate the weights of\nevaluation criteria, including accuracy, precision, recall, F1-score,\nspecificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and\nefficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random\nForest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long\nShort-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from\nTransformers (ALBERT) are chosen as classification baseline models. A weighted\ndecision matrix consisting of classification evaluation scores with respect to\ncriteria weights, is formed to select the best classification model for a\nclassification problem. Three open datasets of social media are used to\ndemonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,\nfor evaluation results excluding the time factor, ALBERT is the best for the\nthree datasets; if time consumption is included, no single model always\nperforms better than the other models. The CPC-CMS can be applied to the other\nclassification applications in different areas.", "comment": "35 pages, 33 tables, 6 Figures", "pdf_url": "http://arxiv.org/pdf/2507.14022v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14042", "title": "Training-free Token Reduction for Vision Mamba", "authors": ["Qiankun Ma", "Ziyao Zhang", "Chi Su", "Jie Chen", "Zhen Song", "Hairong Zheng", "Wen Gao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14042v1", "summary": "Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)\ndue to its ability to efficiently capture long-range dependencies with linear\ncomputational complexity. While token reduction, an effective compression\ntechnique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision\nMamba's efficiency is essential for enabling broader applications. However, we\nfind that directly applying existing token reduction techniques for ViTs to\nVision Mamba leads to significant performance degradation. This is primarily\nbecause Mamba is a sequence model without attention mechanisms, whereas most\ntoken reduction techniques for ViTs rely on attention mechanisms for importance\nmeasurement and overlook the order of compressed tokens. In this paper, we\ninvestigate a Mamba structure-aware importance score to evaluate token\nimportance in a simple and effective manner. Building on this score, we further\npropose MTR, a training-free \\textbf{M}amba \\textbf{T}oken \\textbf{R}eduction\nframework. Without the need for training or additional tuning parameters, our\nmethod can be seamlessly integrated as a plug-and-play component across various\nMamba models. Extensive experiments demonstrate that our approach significantly\nreduces computational workload while minimizing performance impact across\nvarious tasks and multiple backbones. Notably, MTR reduces FLOPs by\napproximately 40\\% on the Vim-B backbone, with only a 1.6\\% drop in ImageNet\nperformance without retraining.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14042v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2402.10310", "title": "Interpretable Imitation Learning via Generative Adversarial STL Inference and Control", "authors": ["Wenliang Liu", "Danyang Li", "Erfan Aasi", "Daniela Rus", "Roberto Tron", "Calin Belta"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at NeuS 2025 (International Conference on Neuro-symbolic Systems)", "url": "http://arxiv.org/abs/2402.10310v2", "summary": "Imitation learning methods have demonstrated considerable success in teaching\nautonomous systems complex tasks through expert demonstrations. However, a\nlimitation of these methods is their lack of interpretability, particularly in\nunderstanding the specific task the learning agent aims to accomplish. In this\npaper, we propose a novel imitation learning method that combines Signal\nTemporal Logic (STL) inference and control synthesis, enabling the explicit\nrepresentation of the task as an STL formula. This approach not only provides a\nclear understanding of the task but also supports the integration of human\nknowledge and allows for adaptation to out-of-distribution scenarios by\nmanually adjusting the STL formulas and fine-tuning the policy. We employ a\nGenerative Adversarial Network (GAN)-inspired approach to train both the\ninference and policy networks, effectively narrowing the gap between expert and\nlearned policies. The efficiency of our algorithm is demonstrated through\nsimulations, showcasing its practical applicability and adaptability.", "comment": "Published at NeuS 2025 (International Conference on Neuro-symbolic\n  Systems)", "pdf_url": "http://arxiv.org/pdf/2402.10310v2", "cate": "cs.LG", "date": "2024-02-15", "updated": "2025-07-18"}
{"id": "2503.17340", "title": "Align Your Rhythm: Generating Highly Aligned Dance Poses with Gating-Enhanced Rhythm-Aware Feature Representation", "authors": ["Congyi Fan", "Jian Guan", "Xuanjia Zhao", "Dongli Xu", "Youtian Lin", "Tong Ye", "Pengming Feng", "Haiwei Pan"], "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Accept, Project page: this https URL", "url": "http://arxiv.org/abs/2503.17340v2", "summary": "Automatically generating natural, diverse and rhythmic human dance movements\ndriven by music is vital for virtual reality and film industries. However,\ngenerating dance that naturally follows music remains a challenge, as existing\nmethods lack proper beat alignment and exhibit unnatural motion dynamics. In\nthis paper, we propose Danceba, a novel framework that leverages gating\nmechanism to enhance rhythm-aware feature representation for music-driven dance\ngeneration, which achieves highly aligned dance poses with enhanced rhythmic\nsensitivity. Specifically, we introduce Phase-Based Rhythm Extraction (PRE) to\nprecisely extract rhythmic information from musical phase data, capitalizing on\nthe intrinsic periodicity and temporal structures of music. Additionally, we\npropose Temporal-Gated Causal Attention (TGCA) to focus on global rhythmic\nfeatures, ensuring that dance movements closely follow the musical rhythm. We\nalso introduce Parallel Mamba Motion Modeling (PMMM) architecture to separately\nmodel upper and lower body motions along with musical features, thereby\nimproving the naturalness and diversity of generated dance movements. Extensive\nexperiments confirm that Danceba outperforms state-of-the-art methods,\nachieving significantly better rhythmic alignment and motion diversity. Project\npage: https://danceba.github.io/ .", "comment": "ICCV 2025 Accept, Project page: https://danceba.github.io/", "pdf_url": "http://arxiv.org/pdf/2503.17340v2", "cate": "cs.MM", "date": "2025-03-21", "updated": "2025-07-18"}
{"id": "2507.13544", "title": "A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows", "authors": ["Mohamed Achref Ben Ammar", "Mohamed Taha Bennani"], "categories": ["cs.CL", "68T50, 05C85, 68T05, 68R10", "I.2.7; I.2.4; H.3.3; I.5.0"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13544v1", "summary": "The analysis of conversational dynamics has gained increasing importance with\nthe rise of large language model-based systems, which interact with users\nacross diverse contexts. In this work, we propose a novel computational\nframework for constructing conversational graphs that capture the flow and\nstructure of loosely organized dialogues, referred to as quasi-patterned\nconversations. We introduce the Filter & Reconnect method, a novel graph\nsimplification technique that minimizes noise while preserving semantic\ncoherence and structural integrity of conversational graphs. Through\ncomparative analysis, we demonstrate that the use of large language models\ncombined with our graph simplification technique has resulted in semantic\nmetric S increasing by a factor of 2.06 compared to previous approaches while\nsimultaneously enforcing a tree-like structure with 0 {\\delta}-hyperbolicity,\nensuring optimal clarity in conversation modeling. This work provides a\ncomputational method for analyzing large-scale dialogue datasets, with\npractical applications related to monitoring automated systems such as\nchatbots, dialogue management tools, and user behavior analytics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13544v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.13994", "title": "Optimal antimatroid sorting", "authors": ["Benjamin Aram Berendsohn"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Accepted to ESA 2025", "url": "http://arxiv.org/abs/2507.13994v1", "summary": "The classical comparison-based sorting problem asks us to find the underlying\ntotal order of a given set of elements, where we can only access the elements\nvia comparisons. In this paper, we study a restricted version, where, as a\nhint, a set $T$ of possible total orders is given, usually in some compressed\nform.\n  Recently, an algorithm called topological heapsort with optimal running time\nwas found for the case where $T$ is the set of topological orderings of a given\ndirected acyclic graph, or, equivalently, $T$ is the set of linear extensions\nof a given partial order [Haeupler et al. 2024]. We show that a simple\ngeneralization of topological heapsort is applicable to a much broader class of\nrestricted sorting problems, where $T$ corresponds to a given antimatroid.\n  As a consequence, we obtain optimal algorithms for the following restricted\nsorting problems, where the allowed total orders are restricted by: a given set\nof monotone precedence formulas; the perfect elimination orders of a given\nchordal graph; or the possible vertex search orders of a given connected rooted\ngraph.", "comment": "Accepted to ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.13994v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13419", "title": "Lab-Scale Gantry Crane Digital Twin Exemplar", "authors": ["Joost Mertens", "Joachim Denil"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures, associated GitHub repository: this https URL", "url": "http://arxiv.org/abs/2507.13419v1", "summary": "The research topic of digital twins has attracted a large amount of interest\nover the past decade. However, publicly available exemplars remain scarce. In\nthe interest of open and reproducible science, in this exemplar paper we\npresent a lab-scale gantry crane and its digital twin. The exemplar comprises\nboth the physical and digital side of the twin system. The physical side\nconsists of the physical crane and its controller. The digital side covers the\nCAD models and kinematic model of the crane, and provides services for optimal\ncontrol, historical data logging, data visualization and continuous validation.\nWe used this setup as use case in several previous publications where its\nfunctionality was validated. It is publicly available and only relies on other\nfreely available and commonly used software, this way we hope it can be used\nfor future research or education on the topic of digital twins.", "comment": "6 pages, 8 figures, associated GitHub repository:\n  https://github.com/Cosys-Lab/lab-scale-gantry-crane", "pdf_url": "http://arxiv.org/pdf/2507.13419v1", "cate": "cs.GR", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2503.23923", "title": "What the F*ck Is Artificial General Intelligence?", "authors": ["Michael Timothy Bennett"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Preprint; paper accepted to and forthcoming in Springer Nature LNCS as part of the 2025 AGI proceedings; 10 pages;", "url": "http://arxiv.org/abs/2503.23923v2", "summary": "Artificial general intelligence (AGI) is an established field of research.\nYet some have questioned if the term still has meaning. AGI has been subject to\nso much hype and speculation it has become something of a Rorschach test.\nMelanie Mitchell argues the debate will only be settled through long term,\nscientific investigation. To that end here is a short, accessible and\nprovocative overview of AGI. I compare definitions of intelligence, settling on\nintelligence in terms of adaptation and AGI as an artificial scientist. Taking\nmy cue from Sutton's Bitter Lesson I describe two foundational tools used to\nbuild adaptive systems: search and approximation. I compare pros, cons, hybrids\nand architectures like o3, AlphaGo, AERA, NARS and Hyperon. I then discuss\noverall meta-approaches to making systems behave more intelligently. I divide\nthem into scale-maxing, simp-maxing, w-maxing based on the Bitter Lesson,\nOckham's and Bennett's Razors. These maximise resources, simplicity of form,\nand the weakness of constraints on functionality. I discuss examples including\nAIXI, the free energy principle and The Embiggening of language models. I\nconclude that though scale-maxed approximation dominates, AGI will be a fusion\nof tools and meta-approaches. The Embiggening was enabled by improvements in\nhardware. Now the bottlenecks are sample and energy efficiency.", "comment": "Preprint; paper accepted to and forthcoming in Springer Nature LNCS\n  as part of the 2025 AGI proceedings; 10 pages;", "pdf_url": "http://arxiv.org/pdf/2503.23923v2", "cate": "cs.AI", "date": "2025-03-31", "updated": "2025-07-18"}
{"id": "2507.14023", "title": "Conformalized Regression for Continuous Bounded Outcomes", "authors": ["Zhanli Wu", "Fabrizio Leisen", "F. Javier Rubio"], "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      R code and data can be found at: this https URL", "url": "http://arxiv.org/abs/2507.14023v1", "summary": "Regression problems with bounded continuous outcomes frequently arise in\nreal-world statistical and machine learning applications, such as the analysis\nof rates and proportions. A central challenge in this setting is predicting a\nresponse associated with a new covariate value. Most of the existing\nstatistical and machine learning literature has focused either on point\nprediction of bounded outcomes or on interval prediction based on asymptotic\napproximations. We develop conformal prediction intervals for bounded outcomes\nbased on transformation models and beta regression. We introduce tailored\nnon-conformity measures based on residuals that are aligned with the underlying\nmodels, and account for the inherent heteroscedasticity in regression settings\nwith bounded outcomes. We present a theoretical result on asymptotic marginal\nand conditional validity in the context of full conformal prediction, which\nremains valid under model misspecification. For split conformal prediction, we\nprovide an empirical coverage analysis based on a comprehensive simulation\nstudy. The simulation study demonstrates that both methods provide valid\nfinite-sample predictive coverage, including settings with model\nmisspecification. Finally, we demonstrate the practical performance of the\nproposed conformal prediction intervals on real data and compare them with\nbootstrap-based alternatives.", "comment": "R code and data can be found at: https://github.com/ZWU-001/CPBounded", "pdf_url": "http://arxiv.org/pdf/2507.14023v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14050", "title": "Foundation Models as Class-Incremental Learners for Dermatological Image Classification", "authors": ["Mohamed Elkhayat", "Mohamed Mahmoud", "Jamil Fayyad", "Nourhan Bayasi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the MICCAI EMERGE 2025 workshop", "url": "http://arxiv.org/abs/2507.14050v1", "summary": "Class-Incremental Learning (CIL) aims to learn new classes over time without\nforgetting previously acquired knowledge. The emergence of foundation models\n(FM) pretrained on large datasets presents new opportunities for CIL by\noffering rich, transferable representations. However, their potential for\nenabling incremental learning in dermatology remains largely unexplored. In\nthis paper, we systematically evaluate frozen FMs pretrained on large-scale\nskin lesion datasets for CIL in dermatological disease classification. We\npropose a simple yet effective approach where the backbone remains frozen, and\na lightweight MLP is trained incrementally for each task. This setup achieves\nstate-of-the-art performance without forgetting, outperforming regularization,\nreplay, and architecture based methods. To further explore the capabilities of\nfrozen FMs, we examine zero training scenarios using nearest mean classifiers\nwith prototypes derived from their embeddings. Through extensive ablation\nstudies, we demonstrate that this prototype based variant can also achieve\ncompetitive results. Our findings highlight the strength of frozen FMs for\ncontinual learning in dermatology and support their broader adoption in real\nworld medical applications. Our code and datasets are available here.", "comment": "Accepted at the MICCAI EMERGE 2025 workshop", "pdf_url": "http://arxiv.org/pdf/2507.14050v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2406.00826", "title": "Policy Verification in Stochastic Dynamical Systems Using Logarithmic Neural Certificates", "authors": ["Thom Badings", "Wietze Koops", "Sebastian Junges", "Nils Jansen"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Extended version (with appendix) of the paper presented at CAV 2025", "url": "http://arxiv.org/abs/2406.00826v4", "summary": "We consider the verification of neural network policies for discrete-time\nstochastic systems with respect to reach-avoid specifications. We use a\nlearner-verifier procedure that learns a certificate for the specification,\nrepresented as a neural network. Verifying that this neural network certificate\nis a so-called reach-avoid supermartingale (RASM) proves the satisfaction of a\nreach-avoid specification. Existing approaches for such a verification task\nrely on computed Lipschitz constants of neural networks. These approaches\nstruggle with large Lipschitz constants, especially for reach-avoid\nspecifications with high threshold probabilities. We present two key\ncontributions to obtain smaller Lipschitz constants than existing approaches.\nFirst, we introduce logarithmic RASMs (logRASMs), which take exponentially\nsmaller values than RASMs and hence have lower theoretical Lipschitz constants.\nSecond, we present a fast method to compute tighter upper bounds on Lipschitz\nconstants based on weighted norms. Our empirical evaluation shows we can\nconsistently verify the satisfaction of reach-avoid specifications with\nprobabilities as high as 99.9999%.", "comment": "Extended version (with appendix) of the paper presented at CAV 2025", "pdf_url": "http://arxiv.org/pdf/2406.00826v4", "cate": "cs.LG", "date": "2024-06-02", "updated": "2025-07-18"}
{"id": "2505.16119", "title": "Source Separation by Flow Matching", "authors": ["Robin Scheibler", "John R. Hershey", "Arnaud Doucet", "Henry Li"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, 2 tables, accepted at WASPAA 2025", "url": "http://arxiv.org/abs/2505.16119v2", "summary": "We consider the problem of single-channel audio source separation with the\ngoal of reconstructing $K$ sources from their mixture. We address this\nill-posed problem with FLOSS (FLOw matching for Source Separation), a\nconstrained generation method based on flow matching, ensuring strict mixture\nconsistency. Flow matching is a general methodology that, when given samples\nfrom two probability distributions defined on the same space, learns an\nordinary differential equation to output a sample from one of the distributions\nwhen provided with a sample from the other. In our context, we have access to\nsamples from the joint distribution of $K$ sources and so the corresponding\nsamples from the lower-dimensional distribution of their mixture. To apply flow\nmatching, we augment these mixture samples with artificial noise components to\nmatch the dimensionality of the $K$ source distribution. Additionally, as any\npermutation of the sources yields the same mixture, we adopt an equivariant\nformulation of flow matching which relies on a neural network architecture that\nis equivariant by design. We demonstrate the performance of the method for the\nseparation of overlapping speech.", "comment": "5 pages, 3 figures, 2 tables, accepted at WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2505.16119v2", "cate": "cs.SD", "date": "2025-05-22", "updated": "2025-07-18"}
{"id": "2507.13655", "title": "CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer", "authors": ["Teerapong Panboonyuen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.13655v1", "summary": "Integrating large language models into specialized domains like healthcare\npresents unique challenges, including domain adaptation and limited labeled\ndata. We introduce CU-ICU, a method for customizing unsupervised\ninstruction-finetuned language models for ICU datasets by leveraging the\nText-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse\nfine-tuning approach that combines few-shot prompting with selective parameter\nupdates, enabling efficient adaptation with minimal supervision. Our evaluation\nacross critical ICU tasks--early sepsis detection, mortality prediction, and\nclinical note generation--demonstrates that CU-ICU consistently improves\npredictive accuracy and interpretability over standard fine-tuning methods.\nNotably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and\na 20% enhancement in generating clinically relevant explanations while updating\nfewer than 1% of model parameters in its most efficient configuration. These\nresults establish CU-ICU as a scalable, low-overhead solution for delivering\naccurate and interpretable clinical decision support in real-world ICU\nenvironments.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.13655v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14060", "title": "Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and Hardness", "authors": ["Sanjeev Khanna", "Ashwin Padaki", "Erik Waingarten"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14060v1", "summary": "We initiate the study of approximation algorithms and computational barriers\nfor constructing sparse $\\alpha$-navigable graphs [IX23, DGM+24], a core\nprimitive underlying recent advances in graph-based nearest neighbor search.\nGiven an $n$-point dataset $P$ with an associated metric $\\mathsf{d}$ and a\nparameter $\\alpha \\geq 1$, the goal is to efficiently build the sparsest graph\n$G=(P, E)$ that is $\\alpha$-navigable: for every distinct $s, t \\in P$, there\nexists an edge $(s, u) \\in E$ with $\\mathsf{d}(u, t) < \\mathsf{d}(s,\nt)/\\alpha$. We consider two natural sparsity objectives: minimizing the maximum\nout-degree and minimizing the total size.\n  We first show a strong negative result: the slow-preprocessing version of\nDiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose\nsparsity is $\\widetilde{\\Omega}(n)$ times larger than optimal, even on\nEuclidean instances. We then show a tight approximation-preserving equivalence\nbetween the Sparsest Navigable Graph problem and the classic Set Cover problem,\nobtaining an $O(n^3)$-time $(\\ln n + 1)$-approximation algorithm, as well as\nestablishing NP-hardness of achieving an $o(\\ln n)$-approximation. Building on\nthis equivalence, we develop faster $O(\\ln n)$-approximation algorithms. The\nfirst runs in $\\widetilde{O}(n \\cdot \\mathrm{OPT})$ time and is thus much\nfaster when the optimal solution is sparse. The second, based on fast matrix\nmultiplication, is a bicriteria algorithm that computes an $O(\\ln\nn)$-approximation to the sparsest $2\\alpha$-navigable graph, running in\n$\\widetilde{O}(n^{\\omega})$ time.\n  Finally, we complement our upper bounds with a query complexity lower bound,\nshowing that any $o(n)$-approximation requires examining $\\Omega(n^2)$\ndistances. This result shows that in the regime where $\\mathrm{OPT} =\n\\widetilde{O}(n)$, our $\\widetilde{O}(n \\cdot \\mathrm{OPT})$-time algorithm is\nessentially best possible.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14060v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13586", "title": "TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting", "authors": ["Kaiyuan Tang", "Kuangshi Ai", "Jun Han", "Chaoli Wang"], "categories": ["cs.GR", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.13586v1", "summary": "Advancements in volume visualization (VolVis) focus on extracting insights\nfrom 3D volumetric data by generating visually compelling renderings that\nreveal complex internal structures. Existing VolVis approaches have explored\nnon-photorealistic rendering techniques to enhance the clarity, expressiveness,\nand informativeness of visual communication. While effective, these methods\noften rely on complex predefined rules and are limited to transferring a single\nstyle, restricting their flexibility. To overcome these limitations, we\nadvocate the representation of VolVis scenes using differentiable Gaussian\nprimitives combined with pretrained large models to enable arbitrary style\ntransfer and real-time rendering. However, conventional 3D Gaussian primitives\ntightly couple geometry and appearance, leading to suboptimal stylization\nresults. To address this, we introduce TexGS-VolVis, a textured Gaussian\nsplatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,\nextending each Gaussian with additional texture and shading attributes,\nresulting in higher-quality, geometry-consistent stylization and enhanced\nlighting control during inference. Despite these improvements, achieving\nflexible and controllable scene editing remains challenging. To further enhance\nstylization, we develop image- and text-driven non-photorealistic scene editing\ntailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing\nwith fine-grained control. We evaluate TexGS-VolVis both qualitatively and\nquantitatively across various volume rendering scenes, demonstrating its\nsuperiority over existing methods in terms of efficiency, visual quality, and\nediting flexibility.", "comment": "Accepted by IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.13586v1", "cate": "cs.GR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.17735", "title": "SafeAgent: Safeguarding LLM Agents via an Automated Risk Simulator", "authors": ["Xueyang Zhou", "Weidong Wang", "Lin Lu", "Jiawen Shi", "Guiyao Tie", "Yongtian Xu", "Lixing Chen", "Pan Zhou", "Neil Zhenqiang Gong", "Lichao Sun"], "categories": ["cs.AI", "68T07", "I.2.6"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      38 pages;12 figures;12 tables", "url": "http://arxiv.org/abs/2505.17735v2", "summary": "Large Language Model (LLM)-based agents are increasingly deployed in\nreal-world applications such as \"digital assistants, autonomous customer\nservice, and decision-support systems\", where their ability to \"interact in\nmulti-turn, tool-augmented environments\" makes them indispensable. However,\nensuring the safety of these agents remains a significant challenge due to the\ndiverse and complex risks arising from dynamic user interactions, external tool\nusage, and the potential for unintended harmful behaviors. To address this\ncritical issue, we propose AutoSafe, the first framework that systematically\nenhances agent safety through fully automated synthetic data generation.\nConcretely, 1) we introduce an open and extensible threat model, OTS, which\nformalizes how unsafe behaviors emerge from the interplay of user instructions,\ninteraction contexts, and agent actions. This enables precise modeling of\nsafety risks across diverse scenarios. 2) we develop a fully automated data\ngeneration pipeline that simulates unsafe user behaviors, applies\nself-reflective reasoning to generate safe responses, and constructs a\nlarge-scale, diverse, and high-quality safety training dataset-eliminating the\nneed for hazardous real-world data collection. To evaluate the effectiveness of\nour framework, we design comprehensive experiments on both synthetic and\nreal-world safety benchmarks. Results demonstrate that AutoSafe boosts safety\nscores by 45% on average and achieves a 28.91% improvement on real-world tasks,\nvalidating the generalization ability of our learned safety strategies. These\nresults highlight the practical advancement and scalability of AutoSafe in\nbuilding safer LLM-based agents for real-world deployment. We have released the\nproject page at https://auto-safe.github.io/.", "comment": "38 pages;12 figures;12 tables", "pdf_url": "http://arxiv.org/pdf/2505.17735v2", "cate": "cs.AI", "date": "2025-05-23", "updated": "2025-07-18"}
{"id": "2507.14057", "title": "Step-DAD: Semi-Amortized Policy-Based Bayesian Experimental Design", "authors": ["Marcel Hedman", "Desi R. Ivanova", "Cong Guan", "Tom Rainforth"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted at Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025", "url": "http://arxiv.org/abs/2507.14057v1", "summary": "We develop a semi-amortized, policy-based, approach to Bayesian experimental\ndesign (BED) called Stepwise Deep Adaptive Design (Step-DAD). Like existing,\nfully amortized, policy-based BED approaches, Step-DAD trains a design policy\nupfront before the experiment. However, rather than keeping this policy fixed,\nStep-DAD periodically updates it as data is gathered, refining it to the\nparticular experimental instance. This test-time adaptation improves both the\nflexibility and the robustness of the design strategy compared with existing\napproaches. Empirically, Step-DAD consistently demonstrates superior\ndecision-making and robustness compared with current state-of-the-art BED\nmethods.", "comment": "Accepted at Proceedings of the 42nd International Conference on\n  Machine Learning, Vancouver, Canada. PMLR 267, 2025", "pdf_url": "http://arxiv.org/pdf/2507.14057v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14083", "title": "Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection", "authors": ["Sara Abdulaziz", "Egor Bondarev"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACIVS 2025", "url": "http://arxiv.org/abs/2507.14083v1", "summary": "Advancements in deep learning have improved anomaly detection in surveillance\nvideos, yet they raise urgent privacy concerns due to the collection of\nsensitive human data. In this paper, we present a comprehensive analysis of\nanomaly detection performance under four human anonymization techniques,\nincluding blurring, masking, encryption, and avatar replacement, applied to the\nUCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,\nBN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method\nresponds to different obfuscation techniques. Experimental results demonstrate\nthat anomaly detection remains viable under anonymized data and is dependent on\nthe algorithmic design and the learning strategy. For instance, under certain\nanonymization patterns, such as encryption and masking, some models\ninadvertently achieve higher AUC performance compared to raw data, due to the\nstrong responsiveness of their algorithmic components to these noise patterns.\nThese results highlight the algorithm-specific sensitivities to anonymization\nand emphasize the trade-off between preserving privacy and maintaining\ndetection utility. Furthermore, we compare these conventional anonymization\ntechniques with the emerging privacy-by-design solutions, highlighting an often\noverlooked trade-off between robust privacy protection and utility flexibility.\nThrough comprehensive experiments and analyses, this study provides a\ncompelling benchmark and insights into balancing human privacy with the demands\nof anomaly detection.", "comment": "ACIVS 2025", "pdf_url": "http://arxiv.org/pdf/2507.14083v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2410.15654", "title": "Design and Optimization of a Metamaterial Absorber for Solar Energy Harvesting in the THz Frequency Range", "authors": ["Nafisa Anjum", "Alok Kumar Paul"], "categories": ["physics.optics", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.15654v2", "summary": "This paper introduces the design and comprehensive characterization of a\nnovel three-layer metamaterial absorber, engineered to exploit the unique\noptical properties of gold, vanadium dioxide, and silicon dioxide. At the core\nof this design, silicon dioxide serves as a robust substrate that supports an\nintricately structured layer of gold and a top layer of vanadium dioxide. This\nconfiguration is optimized to harness and enhance absorption capabilities\neffectively across a broadband terahertz (THz) spectrum. The absorber\ndemonstrates an extensive absorption bandwidth of 3.00 THz, spanning\nfrequencies from 2.414 THz to 5.417 THz. Remarkably, throughout this range, the\ndevice maintains a consistently high absorption efficiency, exceeding 90%. This\nefficiency is characterized by two sharp absorption peaks located at 2.638 THz\nand 5.158 THz, which signify the precise tuning of the metamaterial structure\nto interact optimally with specific THz frequencies. The absorbance of the\nproposed model is almost equal to 99%. This absorber is polarization\ninsensitive. The development of this absorber involved a series of theoretical\nsimulations backed by experimental validations, which helped refine the\nmetamaterial's geometry and material composition. This process illuminated the\ncritical role of the dielectric properties of silicon dioxide and the plasmonic\neffects induced by gold and vanadium dioxide layers, which collectively\ncontribute to the high-performance metrics observed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.15654v2", "cate": "physics.optics", "date": "2024-10-21", "updated": "2025-07-17"}
{"id": "2507.00498", "title": "MuteSwap: Visual-informed Silent Video Identity Conversion", "authors": ["Yifan Liu", "Yu Fang", "Zhouhan Lin"], "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00498v2", "summary": "Conventional voice conversion modifies voice characteristics from a source\nspeaker to a target speaker, relying on audio input from both sides. However,\nthis process becomes infeasible when clean audio is unavailable, such as in\nsilent videos or noisy environments. In this work, we focus on the task of\nSilent Face-based Voice Conversion (SFVC), which does voice conversion entirely\nfrom visual inputs. i.e., given images of a target speaker and a silent video\nof a source speaker containing lip motion, SFVC generates speech aligning the\nidentity of the target speaker while preserving the speech content in the\nsource silent video. As this task requires generating intelligible speech and\nconverting identity using only visual cues, it is particularly challenging. To\naddress this, we introduce MuteSwap, a novel framework that employs contrastive\nlearning to align cross-modality identities and minimize mutual information to\nseparate shared visual features. Experimental results show that MuteSwap\nachieves impressive performance in both speech synthesis and identity\nconversion, especially under noisy conditions where methods dependent on audio\ninput fail to produce intelligible results, demonstrating both the\neffectiveness of our training approach and the feasibility of SFVC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00498v2", "cate": "cs.SD", "date": "2025-07-01", "updated": "2025-07-18"}
{"id": "2507.13666", "title": "KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs", "authors": ["Woo-Chan Kim", "Ji-Hoon Park", "Seong-Whan Lee"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13666v1", "summary": "Large language models (LLMs) have demonstrated state-of-the-art performance\nacross a wide range of natural language processing tasks. However,\nhigh-performing models are typically accessible only via APIs, incurring\nsubstantial inference costs. Cascade methods address this by initially\nemploying a cheaper model and escalating to a stronger one only when necessary.\nNevertheless, existing cascade approaches struggle to select a reliable\nrepresentative response and assess the overall reliability of free-form\noutputs, as they rely on exact text matching. To overcome these limitations, we\npropose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient\nfree-form text generation. KiC identifies the most representative answer among\nmultiple outputs from a weaker model and evaluates the semantic alignment of\nother responses with it. Based on the degree of alignment, KiC determines\nwhether to accept the weaker model's output or escalate to a stronger model.\nExperiments on three free-form text generation benchmarks show that KiC\nachieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81\npercent on average, and even outperforms GPT-4 in a specific benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13666v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14089", "title": "An Efficient Massively Parallel Constant-Factor Approximation Algorithm for the $k$-Means Problem", "authors": ["Vincent Cohen-Addad", "Fabian Kuhn", "Zahra Parsaeian"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14089v1", "summary": "In this paper, we present an efficient massively parallel approximation\nalgorithm for the $k$-means problem. Specifically, we provide an MPC algorithm\nthat computes a constant-factor approximation to an arbitrary $k$-means\ninstance in $O(\\log\\log n \\cdot \\log\\log\\log n)$ rounds. The algorithm uses\n$O(n^\\sigma)$ bits of memory per machine, where $\\sigma > 0$ is a constant that\ncan be made arbitrarily small. The global memory usage is\n$O(n^{1+\\varepsilon})$ bits for an arbitrarily small constant $\\varepsilon >\n0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang,\nKrauthgamer, and Vesel\\'{y} showed that a constant-factor bicriteria\napproximation can be computed in $O(1)$ rounds in the MPC model. However, our\nalgorithm is the first constant-factor approximation for the general $k$-means\nproblem that runs in $o(\\log n)$ rounds in the MPC model.\n  Our approach builds upon the foundational framework of Jain and Vazirani. The\ncore component of our algorithm is a constant-factor approximation for the\nrelated facility location problem. While such an approximation was already\nachieved in constant time in the work of Czumaj et al.\\ mentioned above, our\nversion additionally satisfies the so-called Lagrangian Multiplier Preserving\n(LMP) property. This property enables the transformation of a facility location\napproximation into a comparably good $k$-means approximation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14089v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13917", "title": "Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading", "authors": ["Efstratios Geronikolakis", "Manos Kamarianakis", "Antonis Protopsaltis", "George Papagiannakis"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures", "url": "http://arxiv.org/abs/2507.13917v1", "summary": "This paper presents Neural-GASh, a novel real-time shading pipeline for 3D\nmeshes, that leverages a neural radiance field architecture to perform\nimage-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded\nvertex information as input. Unlike traditional Precomputed Radiance Transfer\n(PRT) methods, that require expensive offline precomputations, our learned\nmodel directly consumes CGA-based representations of vertex positions and\nnormals, enabling dynamic scene shading without precomputation. Integrated\nseamlessly into the Unity engine, Neural-GASh facilitates accurate shading of\nanimated and deformed 3D meshes - capabilities essential for dynamic,\ninteractive environments. The shading of the scene is implemented within Unity,\nwhere rotation of scene lights in terms of Spherical Harmonics is also\nperformed optimally using CGA. This neural field approach is designed to\ndeliver fast and efficient light transport simulation across diverse platforms,\nincluding mobile and VR, while preserving high rendering quality. Additionally,\nwe evaluate our method on scenes generated via 3D Gaussian splats, further\ndemonstrating the flexibility and robustness of Neural-GASh in diverse\nscenarios. Performance is evaluated in comparison to conventional PRT,\ndemonstrating competitive rendering speeds even with complex geometries.", "comment": "11 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.13917v1", "cate": "cs.GR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13396", "title": "DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning", "authors": ["Qingyun Sun", "Jiaqi Yuan", "Shan He", "Xiao Guan", "Haonan Yuan", "Xingcheng Fu", "Jianxin Li", "Philip S. Yu"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13396v1", "summary": "Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for\ngrounding large language models with external structured knowledge. However,\nexisting Graph RAG methods struggle with temporal reasoning, due to their\ninability to model the evolving structure and order of real-world events. In\nthis work, we introduce DyG-RAG, a novel event-centric dynamic graph\nretrieval-augmented generation framework designed to capture and reason over\ntemporal knowledge embedded in unstructured text. To eliminate temporal\nambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units\n(DEUs) that explicitly encode both semantic content and precise temporal\nanchors, enabling accurate and interpretable time-aware retrieval. To capture\ntemporal and causal dependencies across events, DyG-RAG constructs an event\ngraph by linking DEUs that share entities and occur close in time, supporting\nefficient and meaningful multi-hop reasoning. To ensure temporally consistent\ngeneration, DyG-RAG introduces an event timeline retrieval pipeline that\nretrieves event sequences via time-aware traversal, and proposes a Time\nChain-of-Thought strategy for temporally grounded answer generation. This\nunified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event\nsequences and to answer complex, time-sensitive queries that standard RAG\nsystems cannot resolve. Extensive experiments on temporal QA benchmarks\ndemonstrate that DyG-RAG significantly improves the accuracy and recall of\nthree typical types of temporal reasoning questions, paving the way for more\nfaithful and temporal-aware generation. DyG-RAG is available at\nhttps://github.com/RingBDStack/DyG-RAG.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13396v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2506.06941", "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity", "authors": ["Parshin Shojaee", "Iman Mirzadeh", "Keivan Alizadeh", "Maxwell Horton", "Samy Bengio", "Mehrdad Farajtabar"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      preprint", "url": "http://arxiv.org/abs/2506.06941v2", "summary": "Recent generations of language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers.\nWhile these models demonstrate improved performance on reasoning benchmarks,\ntheir fundamental capabilities, scaling properties, and limitations remain\ninsufficiently understood. Current evaluations primarily focus on established\nmath and coding benchmarks, emphasizing final answer accuracy. However, this\nevaluation paradigm often suffers from contamination and does not provide\ninsights into the reasoning traces. In this work, we systematically investigate\nthese gaps with the help of controllable puzzle environments that allow precise\nmanipulation of complexity while maintaining consistent logical structures.\nThis setup enables the analysis of not only final answers but also the internal\nreasoning traces, offering insights into how LRMs think. Through extensive\nexperiments, we show that LRMs face a complete accuracy collapse beyond certain\ncomplexities. Moreover, they exhibit a counterintuitive scaling limit: their\nreasoning effort increases with problem complexity up to a point, then declines\ndespite having remaining token budget. By comparing LRMs with their standard\nLLM counterparts under same inference compute, we identify three performance\nregimes: (1) low-complexity tasks where standard models outperform LRMs, (2)\nmedium-complexity tasks where LRMs demonstrates advantage, and (3)\nhigh-complexity tasks where both models face complete collapse. We found that\nLRMs have limitations in exact computation: they fail to use explicit\nalgorithms and reason inconsistently across scales. We also investigate the\nreasoning traces in more depth, studying the patterns of explored solutions and\nanalyzing the models' computational behavior, shedding light on their\nstrengths, limitations, and raising questions about their reasoning\ncapabilities.", "comment": "preprint", "pdf_url": "http://arxiv.org/pdf/2506.06941v2", "cate": "cs.AI", "date": "2025-06-07", "updated": "2025-07-18"}
{"id": "2302.09409", "title": "LOCUS: LOcalization with Channel Uncertainty and Sporadic Energy", "authors": ["Subrata Biswas", "Mohammad Nur Hossain Khan", "Violet Colwell", "Jack Adiletta", "Bashima Islam"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.09409v3", "summary": "Accurate sound source localization (SSL), such as direction-of-arrival (DoA)\nestimation, relies on consistent multichannel data. However, batteryless\nsystems often suffer from missing data due to the stochastic nature of energy\nharvesting, degrading localization performance. We propose LOCUS, a deep\nlearning framework that recovers corrupted features in such settings. LOCUS\nintegrates three modules: (1) Information-Weighted Focus (InFo) to identify\ncorrupted regions, (2) Latent Feature Synthesizer (LaFS) to reconstruct missing\nfeatures, and (3) Guided Replacement (GRep) to restore data without altering\nvalid inputs. LOCUS significantly improves DoA accuracy under missing-channel\nconditions, achieving up to 36.91% error reduction on DCASE and LargeSet, and\n25.87-59.46% gains in real-world deployments. We release a 50-hour multichannel\ndataset to support future research on localization under energy constraints.\nOur code and data are available at: https://bashlab.github.io/locus_project/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.09409v3", "cate": "cs.LG", "date": "2023-02-18", "updated": "2025-07-18"}
{"id": "2507.14095", "title": "C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs", "authors": ["Yung-Hong Sun", "Ting-Hung Lin", "Jiangang Chen", "Hongrui Jiang", "Yu Hen Hu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14095v1", "summary": "Multi-view multi-object association is a fundamental step in 3D\nreconstruction pipelines, enabling consistent grouping of object instances\nacross multiple camera views. Existing methods often rely on appearance\nfeatures or geometric constraints such as epipolar consistency. However, these\napproaches can fail when objects are visually indistinguishable or observations\nare corrupted by noise. We propose C-DOG, a training-free framework that serves\nas an intermediate module bridging object detection (or pose estimation) and 3D\nreconstruction, without relying on visual features. It combines connected\ndelta-overlap graph modeling with epipolar geometry to robustly associate\ndetections across views. Each 2D observation is represented as a graph node,\nwith edges weighted by epipolar consistency. A delta-neighbor-overlap\nclustering step identifies strongly consistent groups while tolerating noise\nand partial connectivity. To further improve robustness, we incorporate\nInterquartile Range (IQR)-based filtering and a 3D back-projection error\ncriterion to eliminate inconsistent observations. Extensive experiments on\nsynthetic benchmarks demonstrate that C-DOG outperforms geometry-based\nbaselines and remains robust under challenging conditions, including high\nobject density, without visual features, and limited camera overlap, making it\nwell-suited for scalable 3D reconstruction in real-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14095v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.16700", "title": "Deep Q-Learning with Gradient Target Tracking", "authors": ["Bum Geun Park", "Taeho Lee", "Donghwan Lee"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.16700v3", "summary": "This paper introduces Q-learning with gradient target tracking, a novel\nreinforcement learning framework that provides a learned continuous target\nupdate mechanism as an alternative to the conventional hard update paradigm. In\nthe standard deep Q-network (DQN), the target network is a copy of the online\nnetwork's weights, held fixed for a number of iterations before being\nperiodically replaced via a hard update. While this stabilizes training by\nproviding consistent targets, it introduces a new challenge: the hard update\nperiod must be carefully tuned to achieve optimal performance. To address this\nissue, we propose two gradient-based target update methods: DQN with asymmetric\ngradient target tracking (AGT2-DQN) and DQN with symmetric gradient target\ntracking (SGT2-DQN). These methods replace the conventional hard target updates\nwith continuous and structured updates using gradient descent, which\neffectively eliminates the need for manual tuning. We provide a theoretical\nanalysis proving the convergence of these methods in tabular settings.\nAdditionally, empirical evaluations demonstrate their advantages over standard\nDQN baselines, which suggest that gradient-based target updates can serve as an\neffective alternative to conventional target update mechanisms in Q-learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.16700v3", "cate": "cs.LG", "date": "2025-03-20", "updated": "2025-07-18"}
{"id": "2507.13205", "title": "Automatically assessing oral narratives of Afrikaans and isiXhosa children", "authors": ["Retief Louw", "Emma Sharratt", "Febe de Wet", "Christiaan Jacobs", "Annelien Smith", "Herman Kamper"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to SLaTE 2025", "url": "http://arxiv.org/abs/2507.13205v2", "summary": "Developing narrative and comprehension skills in early childhood is critical\nfor later literacy. However, teachers in large preschool classrooms struggle to\naccurately identify students who require intervention. We present a system for\nautomatically assessing oral narratives of preschool children in Afrikaans and\nisiXhosa. The system uses automatic speech recognition followed by a machine\nlearning scoring model to predict narrative and comprehension scores. For\nscoring predicted transcripts, we compare a linear model to a large language\nmodel (LLM). The LLM-based system outperforms the linear model in most cases,\nbut the linear system is competitive despite its simplicity. The LLM-based\nsystem is comparable to a human expert in flagging children who require\nintervention. We lay the foundation for automatic oral assessments in\nclassrooms, giving teachers extra capacity to focus on personalised support for\nchildren's learning.", "comment": "Accepted to SLaTE 2025", "pdf_url": "http://arxiv.org/pdf/2507.13205v2", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.13705", "title": "Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations", "authors": ["Cedric Waterschoot", "Nava Tintarev", "Francesco Barile"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Short paper accepted at the Nineteenth ACM Conference on Recommender Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi: https://doi.org/10.1145/3705328.3748015", "url": "http://arxiv.org/abs/2507.13705v1", "summary": "Large Language Models (LLMs) are increasingly being implemented as joint\ndecision-makers and explanation generators for Group Recommender Systems (GRS).\nIn this paper, we evaluate these recommendations and explanations by comparing\nthem to social choice-based aggregation strategies. Our results indicate that\nLLM-generated recommendations often resembled those produced by Additive\nUtilitarian (ADD) aggregation. However, the explanations typically referred to\naveraging ratings (resembling but not identical to ADD aggregation). Group\nstructure, uniform or divergent, did not impact the recommendations.\nFurthermore, LLMs regularly claimed additional criteria such as user or item\nsimilarity, diversity, or used undefined popularity metrics or thresholds. Our\nfindings have important implications for LLMs in the GRS pipeline as well as\nstandard aggregation strategies. Additional criteria in explanations were\ndependent on the number of ratings in the group scenario, indicating potential\ninefficiency of standard aggregation methods at larger item set sizes.\nAdditionally, inconsistent and ambiguous explanations undermine transparency\nand explainability, which are key motivations behind the use of LLMs for GRS.", "comment": "Short paper accepted at the Nineteenth ACM Conference on Recommender\n  Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco\n  Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding\n  LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM\n  Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi:\n  10.1145/3705328.3748015", "pdf_url": "http://arxiv.org/pdf/2507.13705v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13818", "title": "Treedepth Inapproximability and Exponential ETH Lower Bound", "authors": ["Édouard Bonnet", "Daniel Neuen", "Marek Sokołowski"], "categories": ["cs.CC", "cs.DS"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.13818v1", "summary": "Treedepth is a central parameter to algorithmic graph theory. The current\nstate-of-the-art in computing and approximating treedepth consists of a\n$2^{O(k^2)} n$-time exact algorithm and a polynomial-time $O(\\text{OPT}\n\\log^{3/2} \\text{OPT})$-approximation algorithm, where the former algorithm\nreturns an elimination forest of height $k$ (witnessing that treedepth is at\nmost $k$) for the $n$-vertex input graph $G$, or correctly reports that $G$ has\ntreedepth larger than $k$, and $\\text{OPT}$ is the actual value of the\ntreedepth. On the complexity side, exactly computing treedepth is NP-complete,\nbut the known reductions do not rule out a polynomial-time approximation scheme\n(PTAS), and under the Exponential Time Hypothesis (ETH) only exclude a running\ntime of $2^{o(\\sqrt n)}$ for exact algorithms.\n  We show that 1.0003-approximating treedepth is NP-hard, and that exactly\ncomputing the treedepth of an $n$-vertex graph requires time $2^{\\Omega(n)}$,\nunless the ETH fails. We further derive that there exist absolute constants\n$\\delta, c > 0$ such that any $(1+\\delta)$-approximation algorithm requires\ntime $2^{\\Omega(n / \\log^c n)}$. We do so via a simple direct reduction from\nSatisfiability to Treedepth, inspired by a reduction recently designed for\nTreewidth [STOC '25].", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.13818v1", "cate": "cs.CC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.14068", "title": "Flexible 3D Cage-based Deformation via Green Coordinates on Bézier Patches", "authors": ["Dong Xiao", "Renjie Chen"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by SIGGRAPH 2025 conference track", "url": "http://arxiv.org/abs/2501.14068v4", "summary": "Cage-based deformation is a fundamental problem in geometry processing, where\na cage, a user-specified boundary of a region, is used to deform the ambient\nspace of a given mesh. Traditional 3D cages are typically composed of triangles\nand quads. While quads can represent non-planar regions when their four corners\nare not coplanar, they form ruled surfaces with straight isoparametric curves,\nwhich limits their ability to handle curved and high-curvature deformations. In\nthis work, we extend the cage for curved boundaries using B\\'{e}zier patches,\nenabling flexible and high-curvature deformations with only a few control\npoints. The higher-order structure of the B\\'{e}zier patch also allows for the\ncreation of a more compact and precise curved cage for the input model. Based\non Green's third identity, we derive the Green coordinates for the B\\'{e}zier\ncage, achieving shape-preserving deformation with smooth surface boundaries.\nThese coordinates are defined based on the vertex positions and normals of the\nB\\'{e}zier control net. Given that the coordinates are approximately calculated\nthrough the Riemann summation, we propose a global projection technique to\nensure that the coordinates accurately conform to the linear reproduction\nproperty. Experimental results show that our method achieves high performance\nin handling curved and high-curvature deformations.", "comment": "Accepted by SIGGRAPH 2025 conference track", "pdf_url": "http://arxiv.org/pdf/2501.14068v4", "cate": "cs.GR", "date": "2025-01-23", "updated": "2025-07-18"}
{"id": "2507.13525", "title": "Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation", "authors": ["Genki Kusano", "Kosuke Akimoto", "Kunihiro Takeoka"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted to ACM RecSys2025 reproducibility", "url": "http://arxiv.org/abs/2507.13525v1", "summary": "Large language models (LLMs) can perform recommendation tasks by taking\nprompts written in natural language as input. Compared to traditional methods\nsuch as collaborative filtering, LLM-based recommendation offers advantages in\nhandling cold-start, cross-domain, and zero-shot scenarios, as well as\nsupporting flexible input formats and generating explanations of user behavior.\nIn this paper, we focus on a single-user setting, where no information from\nother users is used. This setting is practical for privacy-sensitive or\ndata-limited applications. In such cases, prompt engineering becomes especially\nimportant for controlling the output generated by the LLM. We conduct a\nlarge-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs.\nWe use statistical tests and linear mixed-effects models to evaluate both\naccuracy and inference cost. Our results show that for cost-efficient LLMs,\nthree types of prompts are especially effective: those that rephrase\ninstructions, consider background knowledge, and make the reasoning process\neasier to follow. For high-performance LLMs, simple prompts often outperform\nmore complex ones while reducing cost. In contrast, commonly used prompting\nstyles in natural language processing, such as step-by-step reasoning, or the\nuse of reasoning models often lead to lower accuracy. Based on these findings,\nwe provide practical suggestions for selecting prompts and LLMs depending on\nthe required balance between accuracy and cost.", "comment": "Accepted to ACM RecSys2025 reproducibility", "pdf_url": "http://arxiv.org/pdf/2507.13525v1", "cate": "cs.IR", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2506.18183", "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?", "authors": ["Zhiting Mei", "Christina Zhang", "Tenny Yin", "Justin Lidard", "Ola Shorinwa", "Anirudha Majumdar"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18183v3", "summary": "Reasoning language models have set state-of-the-art (SOTA) records on many\nchallenging benchmarks, enabled by multi-step reasoning induced using\nreinforcement learning. However, like previous language models, reasoning\nmodels are prone to generating confident, plausible responses that are\nincorrect (hallucinations). Knowing when and how much to trust these models is\ncritical to the safe deployment of reasoning models in real-world applications.\nTo this end, we explore uncertainty quantification of reasoning models in this\nwork. Specifically, we ask three fundamental questions: First, are reasoning\nmodels well-calibrated? Second, does deeper reasoning improve model\ncalibration? Finally, inspired by humans' innate ability to double-check their\nthought processes to verify the validity of their answers and their confidence,\nwe ask: can reasoning models improve their calibration by explicitly reasoning\nabout their chain-of-thought traces? We introduce introspective uncertainty\nquantification (UQ) to explore this direction. In extensive evaluations on SOTA\nreasoning models across a broad range of benchmarks, we find that reasoning\nmodels: (i) are typically overconfident, with self-verbalized confidence\nestimates often greater than 85% particularly for incorrect responses, (ii)\nbecome even more overconfident with deeper reasoning, and (iii) can become\nbetter calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not\nuniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we\nconclude with important research directions to design necessary UQ benchmarks\nand improve the calibration of reasoning models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18183v3", "cate": "cs.AI", "date": "2025-06-22", "updated": "2025-07-18"}
{"id": "2402.14009", "title": "Geometry-Informed Neural Networks", "authors": ["Arturs Berzins", "Andreas Radler", "Eric Volkmann", "Sebastian Sanokowski", "Sepp Hochreiter", "Johannes Brandstetter"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code available at this https URL", "url": "http://arxiv.org/abs/2402.14009v4", "summary": "Geometry is a ubiquitous tool in computer graphics, design, and engineering.\nHowever, the lack of large shape datasets limits the application of\nstate-of-the-art supervised learning methods and motivates the exploration of\nalternative learning strategies. To this end, we introduce geometry-informed\nneural networks (GINNs) -- a framework for training shape-generative neural\nfields without data by leveraging user-specified design requirements in the\nform of objectives and constraints. By adding diversity as an explicit\nconstraint, GINNs avoid mode-collapse and can generate multiple diverse\nsolutions, often required in geometry tasks. Experimentally, we apply GINNs to\nseveral problems spanning physics, geometry, and engineering design, showing\ncontrol over geometrical and topological properties, such as surface smoothness\nor the number of holes. These results demonstrate the potential of training\nshape-generative models without data, paving the way for new generative design\napproaches without large datasets.", "comment": "Code available at\n  https://github.com/ml-jku/GINNs-Geometry-informed-Neural-Networks", "pdf_url": "http://arxiv.org/pdf/2402.14009v4", "cate": "cs.LG", "date": "2024-02-21", "updated": "2025-07-18"}
{"id": "2507.14137", "title": "Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning", "authors": ["Shashanka Venkataramanan", "Valentinos Pariza", "Mohammadreza Salehi", "Lukas Knobel", "Spyros Gidaris", "Elias Ramzi", "Andrei Bursuc", "Yuki M. Asano"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14137v1", "summary": "We present Franca (pronounced Fran-ka): free one; the first fully open-source\n(data, code, weights) vision foundation model that matches and in many cases\nsurpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,\nCLIP, SigLIPv2, etc. Our approach is grounded in a transparent training\npipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and\na subset of ReLAION-2B. Beyond model release, we tackle critical limitations in\nSSL clustering methods. While modern models rely on assigning image features to\nlarge codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to\naccount for the inherent ambiguity in clustering semantics. To address this, we\nintroduce a parameter-efficient, multi-head clustering projector based on\nnested Matryoshka representations. This design progressively refines features\ninto increasingly fine-grained clusters without increasing the model size,\nenabling both performance and memory efficiency. Additionally, we propose a\nnovel positional disentanglement strategy that explicitly removes positional\nbiases from dense representations, thereby improving the encoding of semantic\ncontent. This leads to consistent gains on several downstream benchmarks,\ndemonstrating the utility of cleaner feature spaces. Our contributions\nestablish a new standard for transparent, high-performance vision models and\nopen a path toward more reproducible and generalizable foundation models for\nthe broader AI community. The code and model checkpoints are available at\nhttps://github.com/valeoai/Franca.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14137v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.07953", "title": "Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases", "authors": ["Mihails Milehins", "Dan Marghitu"], "categories": ["physics.class-ph", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Classical Physics (physics.class-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 3 figures, see this https URL (v2) minor amendments; arXiv admin note: text overlap with arXiv:2410.08147", "url": "http://arxiv.org/abs/2507.07953v2", "summary": "In the article titled \"The Bouc-Wen Model for Binary Direct Collinear\nCollisions of Convex Viscoplastic Bodies\" and published in the Journal of\nComputational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the\nauthors studied mathematical models of binary direct collinear collisions of\nconvex viscoplastic bodies that employed two incremental collision laws based\non the Bouc-Wen differential model of hysteresis. It was shown that the models\npossess favorable analytical properties, and several model parameter\nidentification studies were conducted, demonstrating that the models can\naccurately capture the nature of a variety of collision phenomena. In this\narticle, the aforementioned models are augmented by modeling the effects of\nexternal forces as time-dependent inputs that belong to a certain function\nspace. Furthermore, the range of the parameters under which the models possess\nfavorable analytical properties is extended to several corner cases that were\nnot considered in the prior publication. Finally, the previously conducted\nmodel parameter identification studies are extended, and an additional model\nparameter identification study is provided in an attempt to validate the\nability of the augmented models to represent the effects of external forces.", "comment": "12 pages, 3 figures, see https://gitlab.com/user9716869/EBWCM; (v2)\n  minor amendments; arXiv admin note: text overlap with arXiv:2410.08147", "pdf_url": "http://arxiv.org/pdf/2507.07953v2", "cate": "physics.class-ph", "date": "2025-07-10", "updated": "2025-07-18"}
{"id": "2507.13761", "title": "Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models", "authors": ["Palash Nandi", "Maithili Joshi", "Tanmoy Chakraborty"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13761v1", "summary": "Language models are highly sensitive to prompt formulations - small changes\nin input can drastically alter their output. This raises a critical question:\nTo what extent can prompt sensitivity be exploited to generate inapt content?\nIn this paper, we investigate how discrete components of prompt design\ninfluence the generation of inappropriate content in Visual Language Models\n(VLMs). Specifically, we analyze the impact of three key factors on successful\njailbreaks: (a) the inclusion of detailed visual information, (b) the presence\nof adversarial examples, and (c) the use of positively framed beginning\nphrases. Our findings reveal that while a VLM can reliably distinguish between\nbenign and harmful inputs in unimodal settings (text-only or image-only), this\nability significantly degrades in multimodal contexts. Each of the three\nfactors is independently capable of triggering a jailbreak, and we show that\neven a small number of in-context examples (as few as three) can push the model\ntoward generating inappropriate outputs. Furthermore, we propose a framework\nthat utilizes a skip-connection between two internal layers of the VLM, which\nsubstantially increases jailbreak success rates, even when using benign images.\nFinally, we demonstrate that memes, often perceived as humorous or harmless,\ncan be as effective as toxic visuals in eliciting harmful content, underscoring\nthe subtle and complex vulnerabilities of VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13761v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.11291", "title": "Permutation patterns in streams", "authors": ["Benjamin Aram Berendsohn"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11291v2", "summary": "Permutation patterns and pattern avoidance are central, well-studied concepts\nin combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$,\nthe pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This\nproblem arises in various contexts in computer science and statistics and has\nbeen studied extensively in exact-, parameterized-, approximate-,\nproperty-testing- and other formulations.\n  In this paper, we study pattern matching in a streaming setting, when the\ninput $\\tau$ is revealed sequentially, one element at a time. There is\nextensive work on the space complexity of various statistics in streams of\nintegers. The novelty of our setting is that the input stream is a permutation,\nwhich allows inferring some information about future inputs. Our algorithms\ncrucially take advantage of this fact, while existing lower bound techniques\nbecome difficult to apply.\n  We show that the complexity of the problem changes dramatically depending on\nthe pattern $\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the\nmonotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$\nfor $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and\n$\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary\nsequence of integers (not necessary a permutation), we show that the complexity\nis $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11291v2", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-18"}
{"id": "2506.23957", "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering", "authors": ["Zinuo You", "Stamatios Georgoulis", "Anpei Chen", "Siyu Tang", "Dengxin Dai"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      siggraph 2025, project website: this https URL . version 2, update discussion", "url": "http://arxiv.org/abs/2506.23957v2", "summary": "Video stabilization is pivotal for video processing, as it removes unwanted\nshakiness while preserving the original user motion intent. Existing\napproaches, depending on the domain they operate, suffer from several issues\n(e.g. geometric distortions, excessive cropping, poor generalization) that\ndegrade the user experience. To address these issues, we introduce\n\\textbf{GaVS}, a novel 3D-grounded approach that reformulates video\nstabilization as a temporally-consistent `local reconstruction and rendering'\nparadigm. Given 3D camera poses, we augment a reconstruction model to predict\nGaussian Splatting primitives, and finetune it at test-time, with multi-view\ndynamics-aware photometric supervision and cross-frame regularization, to\nproduce temporally-consistent local reconstructions. The model are then used to\nrender each stabilized frame. We utilize a scene extrapolation module to avoid\nframe cropping. Our method is evaluated on a repurposed dataset, instilled with\n3D-grounded information, covering samples with diverse camera motions and scene\ndynamics. Quantitatively, our method is competitive with or superior to\nstate-of-the-art 2D and 2.5D approaches in terms of conventional task metrics\nand new geometry consistency. Qualitatively, our method produces noticeably\nbetter results compared to alternatives, validated by the user study.", "comment": "siggraph 2025, project website: https://sinoyou.github.io/gavs.\n  version 2, update discussion", "pdf_url": "http://arxiv.org/pdf/2506.23957v2", "cate": "cs.GR", "date": "2025-06-30", "updated": "2025-07-18"}
{"id": "2507.13622", "title": "IP2: Entity-Guided Interest Probing for Personalized News Recommendation", "authors": ["Youlin Wu", "Yuanyuan Sun", "Xiaokun Zhang", "Haoxi Zhan", "Bo Xu", "Liang Yang", "Hongfei Lin"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted in RecSys 2025", "url": "http://arxiv.org/abs/2507.13622v1", "summary": "News recommender systems aim to provide personalized news reading experiences\nfor users based on their reading history. Behavioral science studies suggest\nthat screen-based news reading contains three successive steps: scanning, title\nreading, and then clicking. Adhering to these steps, we find that intra-news\nentity interest dominates the scanning stage, while the inter-news entity\ninterest guides title reading and influences click decisions. Unfortunately,\ncurrent methods overlook the unique utility of entities in news recommendation.\nTo this end, we propose a novel method called IP2 to probe entity-guided\nreading interest at both intra- and inter-news levels. At the intra-news level,\na Transformer-based entity encoder is devised to aggregate mentioned entities\nin the news title into one signature entity. Then, a signature entity-title\ncontrastive pre-training is adopted to initialize entities with proper meanings\nusing the news story context, which in the meantime facilitates us to probe for\nintra-news entity interest. As for the inter-news level, a dual tower user\nencoder is presented to capture inter-news reading interest from both the title\nmeaning and entity sides. In addition to highlighting the contribution of\ninter-news entity guidance, a cross-tower attention link is adopted to\ncalibrate title reading interest using inter-news entity interest, thus further\naligning with real-world behavior. Extensive experiments on two real-world\ndatasets demonstrate that our IP2 achieves state-of-the-art performance in news\nrecommendation.", "comment": "Accepted in RecSys 2025", "pdf_url": "http://arxiv.org/pdf/2507.13622v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.23306", "title": "GATSim: Urban Mobility Simulation with Generative Agents", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23306v2", "summary": "Traditional agent-based urban mobility simulations often rely on rigid\nrule-based systems that struggle to capture the complexity, adaptability, and\nbehavioral diversity inherent in human travel decision making. Recent\nadvancements in large language models and AI agent technologies present new\nopportunities to develop agents with enhanced reasoning capabilities,\npersistent memory, and adaptive learning. We introduce GATSim (Generative-Agent\nTransport Simulation), a novel framework that leverages these advancements to\nsimulate urban mobility using generative agents with rich, human-like\nbehaviors. Unlike conventional approaches, GATSim agents are characterized by\ndiverse socioeconomic profiles, individual lifestyles, and evolving preferences\nshaped through psychologically informed memory systems, tool usage, and\nlifelong learning. The main contributions of this work are: (1) a comprehensive\narchitecture that integrates an urban mobility foundation model with agent\ncognitive systems and a transport simulation environment; (2) a hierarchical\nmemory designed for efficient retrieval of contextually relevant information,\nincorporating spatial and temporal associations, keyword matching, and semantic\nrelevance; (3) innovative planning and reactive mechanisms for modeling\nadaptive mobility behaviors which integrate a multi-scale reflection process to\ntransform specific travel experiences into generalized behavioral insights. We\nimplement a prototype system and conduct systematic validation, demonstrating\nthat generative agents produce believable and coherent travel behaviors.\nExperimental results indicate that generative agents perform at least as well\nas human annotators with 92\\% posterior probability, while naturally producing\nrealistic macroscopic traffic patterns. The code for the prototype\nimplementation is publicly available at https://github.com/qiliuchn/gatsim.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23306v2", "cate": "cs.AI", "date": "2025-06-29", "updated": "2025-07-18"}
{"id": "2403.07486", "title": "XpertAI: uncovering regression model strategies for sub-manifolds", "authors": ["Simon Letzgus", "Klaus-Robert Müller", "Grégoire Montavon"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Best paper award - World Conference on eXplainable Artificial Intelligence, 09-11 July, 2025 - Istanbul, Turkey", "url": "http://arxiv.org/abs/2403.07486v4", "summary": "In recent years, Explainable AI (XAI) methods have facilitated profound\nvalidation and knowledge extraction from ML models. While extensively studied\nfor classification, few XAI solutions have addressed the challenges specific to\nregression models. In regression, explanations need to be precisely formulated\nto address specific user queries (e.g.\\ distinguishing between `Why is the\noutput above 0?' and `Why is the output above 50?'). They should furthermore\nreflect the model's behavior on the relevant data sub-manifold. In this paper,\nwe introduce XpertAI, a framework that disentangles the prediction strategy\ninto multiple range-specific sub-strategies and allows the formulation of\nprecise queries about the model (the `explanandum') as a linear combination of\nthose sub-strategies. XpertAI is formulated generally to work alongside popular\nXAI attribution techniques, based on occlusion, gradient integration, or\nreverse propagation. Qualitative and quantitative results, demonstrate the\nbenefits of our approach.", "comment": "Best paper award - World Conference on eXplainable Artificial\n  Intelligence, 09-11 July, 2025 - Istanbul, Turkey", "pdf_url": "http://arxiv.org/pdf/2403.07486v4", "cate": "cs.LG", "date": "2024-03-12", "updated": "2025-07-18"}
{"id": "2311.04938", "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures", "authors": ["Prasad Gabbur"], "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2, I.4"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      29 pages, 14 figures; Analysis of DDIM-GMM as a multimodal denoiser; Additional experiments on LSUN datasets and text-to-image generation with Stable Diffusion; Comparison with DPM-Solver; Ablations on GMM parameters; Updated equations with bold font for vectors and matrices", "url": "http://arxiv.org/abs/2311.04938v3", "summary": "We propose using a Gaussian Mixture Model (GMM) as reverse transition\noperator (kernel) within the Denoising Diffusion Implicit Models (DDIM)\nframework, which is one of the most widely used approaches for accelerated\nsampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).\nSpecifically we match the first and second order central moments of the DDPM\nforward marginals by constraining the parameters of the GMM. We see that moment\nmatching is sufficient to obtain samples with equal or better quality than the\noriginal DDIM with Gaussian kernels. We provide experimental results with\nunconditional models trained on CelebAHQ and FFHQ and class-conditional models\ntrained on ImageNet datasets respectively. Our results suggest that using the\nGMM kernel leads to significant improvements in the quality of the generated\nsamples when the number of sampling steps is small, as measured by FID and IS\nmetrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a\nFID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73\nrespectively with a Gaussian kernel.", "comment": "29 pages, 14 figures; Analysis of DDIM-GMM as a multimodal denoiser;\n  Additional experiments on LSUN datasets and text-to-image generation with\n  Stable Diffusion; Comparison with DPM-Solver; Ablations on GMM parameters;\n  Updated equations with bold font for vectors and matrices", "pdf_url": "http://arxiv.org/pdf/2311.04938v3", "cate": "cs.CV", "date": "2023-11-08", "updated": "2025-07-18"}
{"id": "2507.13793", "title": "An Enhanced Model-based Approach for Short Text Clustering", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Xuemeng Song", "Tian Gan", "Liqiang Nie"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13793v1", "summary": "Short text clustering has become increasingly important with the popularity\nof social media like Twitter, Google+, and Facebook. Existing methods can be\nbroadly categorized into two paradigms: topic model-based approaches and deep\nrepresentation learning-based approaches. This task is inherently challenging\ndue to the sparse, large-scale, and high-dimensional characteristics of the\nshort text data. Furthermore, the computational intensity required by\nrepresentation learning significantly increases the running time. To address\nthese issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet\nMultinomial Mixture model (GSDMM), which effectively handles the sparsity and\nhigh dimensionality of short texts while identifying representative words for\neach cluster. Based on several aspects of GSDMM that warrant further\nrefinement, we propose an improved approach, GSDMM+, designed to further\noptimize its performance. GSDMM+ reduces initialization noise and adaptively\nadjusts word weights based on entropy, achieving fine-grained clustering that\nreveals more topic-related information. Additionally, strategic cluster merging\nis employed to refine clustering granularity, better aligning the predicted\ndistribution with the true category distribution. We conduct extensive\nexperiments, comparing our methods with both classical and state-of-the-art\napproaches. The experimental results demonstrate the efficiency and\neffectiveness of our methods. The source code for our model is publicly\navailable at https://github.com/chehaoa/VEMC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13793v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.12699", "title": "More Efforts Towards Fixed-Parameter Approximability of Multiwinner Rules", "authors": ["Sushmita Gupta", "Pallavi Jain", "Souvik Saha", "Saket Saurabh", "Anannya Upasana"], "categories": ["cs.GT", "cs.DS"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      To appear in the Proceedings of the 34th International Joint Conference on Artificial Intelligence (IJCAI 2025)", "url": "http://arxiv.org/abs/2505.12699v2", "summary": "Multiwinner Elections have emerged as a prominent area of research with\nnumerous practical applications. We contribute to this area by designing\nparameterized approximation algorithms and also resolving an open question by\nYang and Wang [AAMAS'18]. More formally, given a set of candidates,\n\\mathcal{C}, a set of voters,\\mathcal{V}, approving a subset of candidates\n(called approval set of a voter), and an integer $k$, we consider the problem\nof selecting a ``good'' committee using Thiele rules. This problem is\ncomputationally challenging for most Thiele rules with monotone submodular\nsatisfaction functions, as there is no (1-\\frac{1}{e}-\\epsilon)\\footnote{Here,\n$e$ denotes the base of the natural logarithm.}-approximation algorithm in\nf(k)(|\\mathcal{C}| + |\\mathcal{V}|)^{o(k)} time for any fixed $\\epsilon > 0$\nand any computable function $f$, and no {\\sf PTAS} even when the length of\napproval set is two. Skowron [WINE'16] designed an approximation scheme running\nin FPT time parameterized by the combined parameter, size of the approval set\nand $k$. In this paper, we consider a parameter $d+k$ (no $d$ voters approve\nthe same set of $d$ candidates), where $d$ is upper bounded by the size of the\napproval set (thus, can be much smaller).\n  With respect to this parameter, we design parameterized approximation\nschemes, a lossy polynomial-time preprocessing method, and show that an extra\ncommittee member suffices to achieve the desired score (i.e., $1$-additive\napproximation). Additionally, we resolve an open question by Yang and\nWang~[AAMAS'18] regarding the fixed-parameter tractability of the problem under\nthe PAV rule with the total score as the parameter, demonstrating that it\nadmits an FPT algorithm.", "comment": "To appear in the Proceedings of the 34th International Joint\n  Conference on Artificial Intelligence (IJCAI 2025)", "pdf_url": "http://arxiv.org/pdf/2505.12699v2", "cate": "cs.GT", "date": "2025-05-19", "updated": "2025-07-18"}
{"id": "2507.12168", "title": "Shape Adaptation for 3D Hairstyle Retargeting", "authors": ["Lu Yu", "Zhong Ren", "Youyi Zheng", "Xiang Chen", "Kun Zhou"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12168v2", "summary": "It is demanding to author an existing hairstyle for novel characters in games\nand VR applications. However, it is a non-trivial task for artists due to the\ncomplicated hair geometries and spatial interactions to preserve. In this\npaper, we present an automatic shape adaptation method to retarget 3D\nhairstyles. We formulate the adaptation process as a constrained optimization\nproblem, where all the shape properties and spatial relationships are converted\ninto individual objectives and constraints. To make such an optimization on\nhigh-resolution hairstyles tractable, we adopt a multi-scale strategy to\ncompute the target positions of the hair strands in a coarse-to-fine manner.\nThe global solving for the inter-strands coupling is restricted to the coarse\nlevel, and the solving for fine details is made local and parallel. In\naddition, we present a novel hairline edit tool to allow for user customization\nduring retargeting. We achieve it by solving physics-based deformations of an\nembedded membrane to redistribute the hair roots with minimal distortion. We\ndemonstrate the efficacy of our method through quantitative and qualitative\nexperiments on various hairstyles and characters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12168v2", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.13910", "title": "PARK: Personalized academic retrieval with knowledge-graphs", "authors": ["Pranav Kasela", "Gabriella Pasi", "Raffaele Perego"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted in Information Systems. [17 May 2025] this https URL", "url": "http://arxiv.org/abs/2507.13910v1", "summary": "Academic Search is a search task aimed to manage and retrieve scientific\ndocuments like journal articles and conference papers. Personalization in this\ncontext meets individual researchers' needs by leveraging, through user\nprofiles, the user related information (e.g. documents authored by a\nresearcher), to improve search effectiveness and to reduce the information\noverload. While citation graphs are a valuable means to support the outcome of\nrecommender systems, their use in personalized academic search (with, e.g.\nnodes as papers and edges as citations) is still under-explored.\n  Existing personalized models for academic search often struggle to fully\ncapture users' academic interests. To address this, we propose a two-step\napproach: first, training a neural language model for retrieval, then\nconverting the academic graph into a knowledge graph and embedding it into a\nshared semantic space with the language model using translational embedding\ntechniques. This allows user models to capture both explicit relationships and\nhidden structures in citation graphs and paper content. We evaluate our\napproach in four academic search domains, outperforming traditional graph-based\nand personalized models in three out of four, with up to a 10\\% improvement in\nMAP@100 over the second-best model. This highlights the potential of knowledge\ngraph-based user models to enhance retrieval effectiveness.", "comment": "Accepted in Information Systems. [17 May 2025]\n  https://doi.org/10.1016/j.is.2025.102574", "pdf_url": "http://arxiv.org/pdf/2507.13910v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.13549", "title": "Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies", "authors": ["Jim O'Connor", "Nicholas Lorentzen", "Gary B. Parker", "Derin Gezgin"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      IJCCI Conference on Evolutionary Computation and Theory and Applications, 2025", "url": "http://arxiv.org/abs/2507.13549v1", "summary": "This paper investigates the development of high-performance racing\ncontrollers for a newly implemented racing mode within the Xpilot-AI platform,\nutilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By\nleveraging NEAT's capability to evolve both the structure and weights of neural\nnetworks, we develop adaptive controllers that can navigate complex circuits\nunder the challenging space simulation physics of Xpilot-AI, which includes\nelements such as inertia, friction, and gravity. The racing mode we introduce\nsupports flexible circuit designs and allows for the evaluation of multiple\nagents in parallel, enabling efficient controller optimization across\ngenerations. Experimental results demonstrate that our evolved controllers\nachieve up to 32% improvement in lap time compared to the controller's initial\nperformance and develop effective racing strategies, such as optimal cornering\nand speed modulation, comparable to human-like techniques. This work\nillustrates NEAT's effectiveness in producing robust control strategies within\ndemanding game environments and highlights Xpilot-AI's potential as a rigorous\ntestbed for competitive AI controller evolution.", "comment": "IJCCI Conference on Evolutionary Computation and Theory and\n  Applications, 2025", "pdf_url": "http://arxiv.org/pdf/2507.13549v1", "cate": "cs.NE", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.10397", "title": "Instance space analysis of the capacitated vehicle routing problem", "authors": ["Alessandra M. M. M. Gouvêa", "Nuno Paulos", "Eduardo Uchoa", "Mariá C. V. Nascimento"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10397v2", "summary": "This paper seeks to advance CVRP research by addressing the challenge of\nunderstanding the nuanced relationships between instance characteristics and\nmetaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a\nvaluable tool that allows for a new perspective on the field. By combining the\nISA methodology with a dataset from the DIMACS 12th Implementation Challenge on\nVehicle Routing, our research enabled the identification of 23 relevant\ninstance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages,\nwhich employ dimensionality reduction and machine learning methods, allowed us\nto create a two-dimensional projection of the instance space to understand how\nthe structure of instances affect the behavior of MHs. A key contribution of\nour work is that we provide a projection matrix, which makes it straightforward\nto incorporate new instances into this analysis and allows for a new method for\ninstance analysis in the CVRP field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10397v2", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-18"}
{"id": "2403.13740", "title": "Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks", "authors": ["Jon Vadillo", "Roberto Santana", "Jose A. Lozano", "Marta Kwiatkowska"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.13740v3", "summary": "The lack of transparency of Deep Neural Networks continues to be a limitation\nthat severely undermines their reliability and usage in high-stakes\napplications. Promising approaches to overcome such limitations are\nPrototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions\nrely on the similarity between the input at hand and a set of prototypical\nrepresentations of the output classes, offering therefore a deep, yet\ntransparent-by-design, architecture. In this paper, we introduce a\nprobabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point\nestimates for the prototypes with probability distributions over their values.\nThis provides not only a more flexible framework for an end-to-end learning of\nprototypes, but can also capture the explanatory uncertainty of the model,\nwhich is a missing feature in previous approaches. In addition, since the\nprototypes determine both the explanation and the prediction, Prob-PSENNs allow\nus to detect when the model is making uninformed or uncertain predictions, and\nto obtain valid explanations for them. Our experiments demonstrate that\nProb-PSENNs provide more meaningful and robust explanations than their\nnon-probabilistic counterparts, while remaining competitive in terms of\npredictive performance, thus enhancing the explainability and reliability of\nthe models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.13740v3", "cate": "cs.LG", "date": "2024-03-20", "updated": "2025-07-18"}
{"id": "2402.09816", "title": "Mind the Modality Gap: Towards a Remote Sensing Vision-Language Model via Cross-modal Alignment", "authors": ["Angelos Zavras", "Dimitrios Michail", "Begüm Demir", "Ioannis Papoutsis"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the ISPRS Journal of Photogrammetry and Remote Sensing. Our code implementation and weights for all experiments are publicly available at this https URL", "url": "http://arxiv.org/abs/2402.09816v2", "summary": "Deep Learning (DL) is undergoing a paradigm shift with the emergence of\nfoundation models. In this work, we focus on Contrastive Language-Image\nPre-training (CLIP), a Vision-Language foundation model that achieves high\naccuracy across various image classification tasks and often rivals fully\nsupervised baselines, despite not being explicitly trained for those tasks.\nNevertheless, there are still domains where zero-shot CLIP performance is far\nfrom optimal, such as Remote Sensing (RS) and medical imagery. These domains do\nnot only exhibit fundamentally different distributions compared to natural\nimages, but also commonly rely on complementary modalities, beyond RGB, to\nderive meaningful insights. To this end, we propose a methodology to align\ndistinct RS image modalities with the visual and textual modalities of CLIP.\nOur two-stage procedure addresses the aforementioned distribution shift,\nextends the zero-shot capabilities of CLIP and enriches CLIP's shared embedding\nspace with domain-specific knowledge. Initially, we robustly fine-tune CLIP\naccording to the PAINT (Ilharco et al., 2022) patching protocol, in order to\ndeal with the distribution shift. Building upon this foundation, we facilitate\nthe cross-modal alignment of a RS modality encoder by distilling knowledge from\nthe CLIP visual and textual encoders. We empirically show that both patching\nand cross-modal alignment translate to significant performance gains, across\nseveral RS imagery classification and cross-modal retrieval benchmark datasets.\nNotably, these enhancements are achieved without the reliance on textual\ndescriptions, without introducing any task-specific parameters, without\ntraining from scratch and without catastrophic forgetting. We make our code\nimplementation and weights for all experiments publicly available at\nhttps://github.com/Orion-AI-Lab/MindTheModalityGap.", "comment": "Accepted at the ISPRS Journal of Photogrammetry and Remote Sensing.\n  Our code implementation and weights for all experiments are publicly\n  available at https://github.com/Orion-AI-Lab/MindTheModalityGap", "pdf_url": "http://arxiv.org/pdf/2402.09816v2", "cate": "cs.CV", "date": "2024-02-15", "updated": "2025-07-18"}
{"id": "2507.13841", "title": "Modeling Fair Play in Detective Stories with Language Models", "authors": ["Eitan Wagner", "Renana Keydar", "Omri Abend"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13841v1", "summary": "Effective storytelling relies on a delicate balance between meeting the\nreader's prior expectations and introducing unexpected developments. In the\ndomain of detective fiction, this tension is known as fair play, which includes\nthe implicit agreement between the writer and the reader as to the range of\npossible resolutions the mystery story may have. In this work, we present a\nprobabilistic framework for detective fiction that allows us to define desired\nqualities. Using this framework, we formally define fair play and design\nappropriate metrics for it. Stemming from these definitions is an inherent\ntension between the coherence of the story, which measures how much it ``makes\nsense'', and the surprise it induces. We validate the framework by applying it\nto LLM-generated detective stories. This domain is appealing since we have an\nabundance of data, we can sample from the distribution generating the story,\nand the story-writing capabilities of LLMs are interesting in their own right.\nResults show that while LLM-generated stories may be unpredictable, they\ngenerally fail to balance the trade-off between surprise and fair play, which\ngreatly contributes to their poor quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13841v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2408.06345", "title": "Deep Learning based Key Information Extraction from Business Documents: Systematic Literature Review", "authors": ["Alexander Michael Rombach", "Peter Fettke"], "categories": ["cs.IR", "cs.CL", "cs.LG", "A.1; I.2.7; I.4.9; I.7.5"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      62 pages, 7 figures, 10 tables; This version represents the accepted author-version without final copyediting. ACM Computing Surveys source: this https URL", "url": "http://arxiv.org/abs/2408.06345v2", "summary": "Extracting key information from documents represents a large portion of\nbusiness workloads and therefore offers a high potential for efficiency\nimprovements and process automation. With recent advances in Deep Learning, a\nplethora of Deep Learning based approaches for Key Information Extraction have\nbeen proposed under the umbrella term Document Understanding that enable the\nprocessing of complex business documents. The goal of this systematic\nliterature review is an in-depth analysis of existing approaches in this domain\nand the identification of opportunities for further research. To this end, 130\napproaches published between 2017 and 2024 are analyzed in this study.", "comment": "62 pages, 7 figures, 10 tables; This version represents the accepted\n  author-version without final copyediting. ACM Computing Surveys source:\n  https://dl.acm.org/doi/10.1145/3749369", "pdf_url": "http://arxiv.org/pdf/2408.06345v2", "cate": "cs.IR", "date": "2024-07-23", "updated": "2025-07-18"}
{"id": "2507.13785", "title": "MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development", "authors": ["Mykola Glybovets", "Sergii Medvid"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      13 pages, 8 figures; Preprint of a manuscript submitted for peer review", "url": "http://arxiv.org/abs/2507.13785v1", "summary": "While biological neural networks develop from compact genomes using\nrelatively simple rules, modern artificial neural architecture search methods\nmostly involve explicit and routine manual work. In this paper, we introduce\nMorphoNAS (Morphogenetic Neural Architecture Search), a system able to\ndeterministically grow neural networks through morphogenetic self-organization\ninspired by the Free Energy Principle, reaction-diffusion systems, and gene\nregulatory networks. In MorphoNAS, simple genomes encode just morphogens\ndynamics and threshold-based rules of cellular development. Nevertheless, this\nleads to self-organization of a single progenitor cell into complex neural\nnetworks, while the entire process is built on local chemical interactions. Our\nevolutionary experiments focused on two different domains: structural\ntargeting, in which MorphoNAS system was able to find fully successful genomes\nable to generate predefined random graph configurations (8-31 nodes); and\nfunctional performance on the CartPole control task achieving low complexity\n6-7 neuron solutions when target network size minimization evolutionary\npressure was applied. The evolutionary process successfully balanced between\nquality of of the final solutions and neural architecture search effectiveness.\nOverall, our findings suggest that the proposed MorphoNAS method is able to\ngrow complex specific neural architectures, using simple developmental rules,\nwhich suggests a feasible biological route to adaptive and efficient neural\narchitecture search.", "comment": "13 pages, 8 figures; Preprint of a manuscript submitted for peer\n  review", "pdf_url": "http://arxiv.org/pdf/2507.13785v1", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.11482", "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11482v2", "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11482v2", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-18"}
{"id": "2410.03020", "title": "On Logical Extrapolation for Mazes with Recurrent and Implicit Networks", "authors": ["Brandon Knutson", "Amandin Chyba Rabeendran", "Michael Ivanitskiy", "Jordan Pettyjohn", "Cecilia Diniz-Behn", "Samy Wu Fung", "Daniel McKenzie"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.03020v2", "summary": "Recent work suggests that certain neural network architectures --\nparticularly recurrent neural networks (RNNs) and implicit neural networks\n(INNs) -- are capable of logical extrapolation. When trained on easy instances\nof a task, these networks (henceforth: logical extrapolators) can generalize to\nmore difficult instances. Previous research has hypothesized that logical\nextrapolators do so by learning a scalable, iterative algorithm for the given\ntask which converges to the solution. We examine this idea more closely in the\ncontext of a single task: maze solving. By varying test data along multiple\naxes -- not just maze size -- we show that models introduced in prior work fail\nin a variety of ways, some expected and others less so. It remains uncertain\nwhether any of these models has truly learned an algorithm. However, we provide\nevidence that a certain RNN has approximately learned a form of\n`deadend-filling'. We show that training these models on more diverse data\naddresses some failure modes but, paradoxically, does not improve logical\nextrapolation. We also analyze convergence behavior, and show that models\nexplicitly trained to converge to a fixed point are likely to do so when\nextrapolating, while models that are not may exhibit more exotic limiting\nbehavior such as limit cycles, even when they correctly solve the problem. Our\nresults (i) show that logical extrapolation is not immune to the problem of\ngoal misgeneralization, and (ii) suggest that analyzing the dynamics of\nextrapolation may yield insights into designing better logical extrapolators.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.03020v2", "cate": "cs.LG", "date": "2024-10-03", "updated": "2025-07-18"}
{"id": "2402.14143", "title": "SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings", "authors": ["Rishabh Bajpai", "Bhooma Aravamuthan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.14143v2", "summary": "Movement disorder diagnosis often relies on expert evaluation of patient\nvideos, but sharing these videos poses privacy risks. Current methods for\nde-identifying videos, such as blurring faces, are often manual, inconsistent,\nor inaccurate. Furthermore, these methods can compromise objective kinematic\nanalysis - a crucial component of diagnosis. To address these challenges, we\ndeveloped SecurePose, an open-source software that simultaneously provides\nreliable de-identification and automated kinematic extraction from videos\nrecorded in clinic settings using smartphones/tablets. SecurePose utilizes pose\nestimation (using OpenPose) to extract full body kinematics, track individuals,\nidentify the patient, and then accurately blur faces in the videos. We\nvalidated SecurePose on gait videos recorded in outpatient clinic visits of 116\nchildren with cerebral palsy, assessing both the accuracy of its\nde-identification compared to the ground truth (manual blurring) and the\nreliability of the intermediate steps of kinematics extraction. Results\ndemonstrate that SecurePose outperformed six existing methods in automated face\ndetection and achieved comparable accuracy to robust manual blurring, but in\nsignificantly less time (91.08% faster). Ten experienced researchers also\nconfirmed SecurePose's usability via System Usability Scale scores. These\nfindings validate SecurePose as a practical and effective tool for protecting\npatient privacy while enabling accurate kinematics extraction in clinical\nsettings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.14143v2", "cate": "cs.CV", "date": "2024-02-21", "updated": "2025-07-18"}
{"id": "2507.13858", "title": "InTraVisTo: Inside Transformer Visualisation Tool", "authors": ["Nicolò Brunello", "Davide Rigamonti", "Andrea Sassella", "Vincenzo Scotti", "Mark James Carman"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.13858v1", "summary": "The reasoning capabilities of Large Language Models (LLMs) have increased\ngreatly over the last few years, as have their size and complexity.\nNonetheless, the use of LLMs in production remains challenging due to their\nunpredictable nature and discrepancies that can exist between their desired\nbehavior and their actual model output. In this paper, we introduce a new tool,\nInTraVisTo (Inside Transformer Visualisation Tool), designed to enable\nresearchers to investigate and trace the computational process that generates\neach token in a Transformer-based LLM. InTraVisTo provides a visualization of\nboth the internal state of the Transformer model (by decoding token embeddings\nat each layer of the model) and the information flow between the various\ncomponents across the different layers of the model (using a Sankey diagram).\nWith InTraVisTo, we aim to help researchers and practitioners better understand\nthe computations being performed within the Transformer model and thus to shed\nsome light on internal patterns and reasoning processes employed by LLMs.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.13858v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.04421", "title": "LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders", "authors": ["Zheng Chai", "Qin Ren", "Xijun Xiao", "Huizhi Yang", "Bo Han", "Sijun Zhang", "Di Chen", "Hui Lu", "Wenlin Zhao", "Lele Yu", "Xionghang Xie", "Shiru Ren", "Xiang Sun", "Yaocheng Tan", "Peng Xu", "Yuchao Zheng", "Di Wu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04421v2", "summary": "Modeling ultra-long user behavior sequences is critical for capturing both\nlong- and short-term preferences in industrial recommender systems. Existing\nsolutions typically rely on two-stage retrieval or indirect modeling paradigms,\nincuring upstream-downstream inconsistency and computational inefficiency. In\nthis paper, we present LONGER, a Long-sequence Optimized traNsformer for\nGPU-Efficient Recommenders. LONGER incorporates (i) a global token mechanism\nfor stabilizing attention over long contexts, (ii) a token merge module with\nlightweight InnerTransformers and hybrid attention strategy to reduce quadratic\ncomplexity, and (iii) a series of engineering optimizations, including training\nwith mixed-precision and activation recomputation, KV cache serving, and the\nfully synchronous model training and serving framework for unified GPU-based\ndense and sparse parameter updates. LONGER consistently outperforms strong\nbaselines in both offline metrics and online A/B testing in both advertising\nand e-commerce services at ByteDance, validating its consistent effectiveness\nand industrial-level scaling laws. Currently, LONGER has been fully deployed at\nmore than 10 influential scenarios at ByteDance, serving billion users.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04421v2", "cate": "cs.IR", "date": "2025-05-07", "updated": "2025-07-18"}
{"id": "2507.13142", "title": "From Roots to Rewards: Dynamic Tree Reasoning with RL", "authors": ["Ahmed Bahloul", "Simon Malberg"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13142v2", "summary": "Modern language models address complex questions through chain-of-thought\n(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,\n2021), yet struggle with error propagation and knowledge integration.\nTree-structured reasoning methods, particularly the Probabilistic\nTree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues\nby decomposing questions into hierarchical structures and selecting answers\nthrough confidence-weighted aggregation of parametric and retrieved knowledge\n(Yao et al., 2023). However, ProbTree's static implementation introduces two\nkey limitations: (1) the reasoning tree is fixed during the initial\nconstruction phase, preventing dynamic adaptation to intermediate results, and\n(2) each node requires exhaustive evaluation of all possible solution\nstrategies, creating computational inefficiency. We present a dynamic\nreinforcement learning (Sutton and Barto, 2018) framework that transforms\ntree-based reasoning into an adaptive process. Our approach incrementally\nconstructs the reasoning tree based on real-time confidence estimates, while\nlearning optimal policies for action selection (decomposition, retrieval, or\naggregation). This maintains ProbTree's probabilistic rigor while improving\nboth solution quality and computational efficiency through selective expansion\nand focused resource allocation. The work establishes a new paradigm for\ntreestructured reasoning that balances the reliability of probabilistic\nframeworks with the flexibility required for real-world question answering\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13142v2", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2410.05347", "title": "Bridging Local and Global Knowledge via Transformer in Board Games", "authors": ["Yan-Ru Ju", "Tai-Lin Wu", "Chung-Chin Shih", "Ti-Rong Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by the Thirty-Fourth International Joint Conferences on Artificial Intelligence (IJCAI-25)", "url": "http://arxiv.org/abs/2410.05347v2", "summary": "Although AlphaZero has achieved superhuman performance in board games, recent\nstudies reveal its limitations in handling scenarios requiring a comprehensive\nunderstanding of the entire board, such as recognizing long-sequence patterns\nin Go. To address this challenge, we propose ResTNet, a network that\ninterleaves residual and Transformer blocks to bridge local and global\nknowledge. ResTNet improves playing strength across multiple board games,\nincreasing win rate from 54.6% to 60.8% in 9x9 Go, 53.6% to 60.9% in 19x19 Go,\nand 50.4% to 58.0% in 19x19 Hex. In addition, ResTNet effectively processes\nglobal information and tackles two long-sequence patterns in 19x19 Go,\nincluding circular pattern and ladder pattern. It reduces the mean square error\nfor circular pattern recognition from 2.58 to 1.07 and lowers the attack\nprobability against an adversary program from 70.44% to 23.91%. ResTNet also\nimproves ladder pattern recognition accuracy from 59.15% to 80.01%. By\nvisualizing attention maps, we demonstrate that ResTNet captures critical game\nconcepts in both Go and Hex, offering insights into AlphaZero's decision-making\nprocess. Overall, ResTNet shows a promising approach to integrating local and\nglobal knowledge, paving the way for more effective AlphaZero-based algorithms\nin board games. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/restnet.", "comment": "Accepted by the Thirty-Fourth International Joint Conferences on\n  Artificial Intelligence (IJCAI-25)", "pdf_url": "http://arxiv.org/pdf/2410.05347v2", "cate": "cs.LG", "date": "2024-10-07", "updated": "2025-07-18"}
{"id": "2403.14559", "title": "VAPO: Visibility-Aware Keypoint Localization for Efficient 6DoF Object Pose Estimation", "authors": ["Ruyi Lian", "Yuewei Lin", "Longin Jan Latecki", "Haibin Ling"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) as oral presentation", "url": "http://arxiv.org/abs/2403.14559v5", "summary": "Localizing predefined 3D keypoints in a 2D image is an effective way to\nestablish 3D-2D correspondences for instance-level 6DoF object pose estimation.\nHowever, unreliable localization results of invisible keypoints degrade the\nquality of correspondences. In this paper, we address this issue by localizing\nthe important keypoints in terms of visibility. Since keypoint visibility\ninformation is currently missing in the dataset collection process, we propose\nan efficient way to generate binary visibility labels from available\nobject-level annotations, for keypoints of both asymmetric objects and\nsymmetric objects. We further derive real-valued visibility-aware importance\nfrom binary labels based on the PageRank algorithm. Taking advantage of the\nflexibility of our visibility-aware importance, we construct VAPO\n(Visibility-Aware POse estimator) by integrating the visibility-aware\nimportance with a state-of-the-art pose estimation algorithm, along with\nadditional positional encoding. VAPO can work in both CAD-based and CAD-free\nsettings. Extensive experiments are conducted on popular pose estimation\nbenchmarks including Linemod, Linemod-Occlusion, and YCB-V, demonstrating that\nVAPO clearly achieves state-of-the-art performances. Project page:\nhttps://github.com/RuyiLian/VAPO.", "comment": "accepted for publication in the Proceedings of the 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025) as\n  oral presentation", "pdf_url": "http://arxiv.org/pdf/2403.14559v5", "cate": "cs.CV", "date": "2024-03-21", "updated": "2025-07-18"}
{"id": "2507.13870", "title": "Label Unification for Cross-Dataset Generalization in Cybersecurity NER", "authors": ["Maciej Jalocha", "Johan Hausted Schmidt", "William Michelseen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      5 pages, 5 figures", "url": "http://arxiv.org/abs/2507.13870v1", "summary": "The field of cybersecurity NER lacks standardized labels, making it\nchallenging to combine datasets. We investigate label unification across four\ncybersecurity datasets to increase data resource usability. We perform a\ncoarse-grained label unification and conduct pairwise cross-dataset evaluations\nusing BiLSTM models. Qualitative analysis of predictions reveals errors,\nlimitations, and dataset differences. To address unification limitations, we\npropose alternative architectures including a multihead model and a graph-based\ntransfer model. Results show that models trained on unified datasets generalize\npoorly across datasets. The multihead model with weight sharing provides only\nmarginal improvements over unified training, while our graph-based transfer\nmodel built on BERT-base-NER shows no significant performance gains compared\nBERT-base-NER.", "comment": "5 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13870v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12871", "title": "Generative Multi-Target Cross-Domain Recommendation", "authors": ["Jinqiu Jin", "Yang Zhang", "Junwei Pan", "Fuli Feng", "Hua Lu", "Lei Xiao", "Haijie Gu", "Xiangnan He"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      fix author information", "url": "http://arxiv.org/abs/2507.12871v2", "summary": "Recently, there has been a surge of interest in Multi-Target Cross-Domain\nRecommendation (MTCDR), which aims to enhance recommendation performance across\nmultiple domains simultaneously. Existing MTCDR methods primarily rely on\ndomain-shared entities (\\eg users or items) to fuse and transfer cross-domain\nknowledge, which may be unavailable in non-overlapped recommendation scenarios.\nSome studies model user preferences and item features as domain-sharable\nsemantic representations, which can be utilized to tackle the MTCDR task.\nNevertheless, they often require extensive auxiliary data for pre-training.\nDeveloping more effective solutions for MTCDR remains an important area for\nfurther exploration.\n  Inspired by recent advancements in generative recommendation, this paper\nintroduces GMC, a generative paradigm-based approach for multi-target\ncross-domain recommendation. The core idea of GMC is to leverage semantically\nquantized discrete item identifiers as a medium for integrating multi-domain\nknowledge within a unified generative model. GMC first employs an item\ntokenizer to generate domain-shared semantic identifiers for each item, and\nthen formulates item recommendation as a next-token generation task by training\na domain-unified sequence-to-sequence model. To further leverage the domain\ninformation to enhance performance, we incorporate a domain-aware contrastive\nloss into the semantic identifier learning, and perform domain-specific\nfine-tuning on the unified recommender. Extensive experiments on five public\ndatasets demonstrate the effectiveness of GMC compared to a range of baseline\nmethods.", "comment": "fix author information", "pdf_url": "http://arxiv.org/pdf/2507.12871v2", "cate": "cs.IR", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2404.07053", "title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.07053v2", "summary": "Metaphors, although occasionally unperceived, are ubiquitous in our everyday\nlanguage. Thus, it is crucial for Language Models to be able to grasp the\nunderlying meaning of this kind of figurative language. In this work, we\npresent Meta4XNLI, a novel parallel dataset for the tasks of metaphor detection\nand interpretation that contains metaphor annotations in both Spanish and\nEnglish. We investigate language models' metaphor identification and\nunderstanding abilities through a series of monolingual and cross-lingual\nexperiments by leveraging our proposed corpus. In order to comprehend how these\nnon-literal expressions affect models' performance, we look over the results\nand perform an error analysis. Additionally, parallel data offers many\npotential opportunities to investigate metaphor transferability between these\nlanguages and the impact of translation on the development of multilingual\nannotated resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.07053v2", "cate": "cs.CL", "date": "2024-04-10", "updated": "2025-07-18"}
{"id": "2410.08557", "title": "MUSO: Achieving Exact Machine Unlearning in Over-Parameterized Regimes", "authors": ["Ruikai Yang", "Mingzhen He", "Zhengbao He", "Youmei Qiu", "Xiaolin Huang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by Machine Learning Journal", "url": "http://arxiv.org/abs/2410.08557v2", "summary": "Machine unlearning (MU) is to make a well-trained model behave as if it had\nnever been trained on specific data. In today's over-parameterized models,\ndominated by neural networks, a common approach is to manually relabel data and\nfine-tune the well-trained model. It can approximate the MU model in the output\nspace, but the question remains whether it can achieve exact MU, i.e., in the\nparameter space. We answer this question by employing random feature techniques\nto construct an analytical framework. Under the premise of model optimization\nvia stochastic gradient descent, we theoretically demonstrated that\nover-parameterized linear models can achieve exact MU through relabeling\nspecific data. We also extend this work to real-world nonlinear networks and\npropose an alternating optimization algorithm that unifies the tasks of\nunlearning and relabeling. The algorithm's effectiveness, confirmed through\nnumerical experiments, highlights its superior performance in unlearning across\nvarious scenarios compared to current state-of-the-art methods, particularly\nexcelling over similar relabeling-based MU approaches.", "comment": "Accepted by Machine Learning Journal", "pdf_url": "http://arxiv.org/pdf/2410.08557v2", "cate": "cs.LG", "date": "2024-10-11", "updated": "2025-07-18"}
{"id": "2405.13999", "title": "Computer-Vision-Enabled Worker Video Analysis for Motion Amount Quantification", "authors": ["Hari Iyer", "Neel Macwan", "Shenghan Guo", "Heejin Jeong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.13999v3", "summary": "The performance of physical workers is significantly influenced by the extent\nof their motions. However, monitoring and assessing these motions remains a\nchallenge. Recent advancements have enabled in-situ video analysis for\nreal-time observation of worker behaviors. This paper introduces a novel\nframework for tracking and quantifying upper and lower limb motions, issuing\nalerts when critical thresholds are reached. Using joint position data from\nposture estimation, the framework employs Hotelling's $T^2$ statistic to\nquantify and monitor motion amounts. A significant positive correlation was\nnoted between motion warnings and the overall NASA Task Load Index (TLX)\nworkload rating (\\textit{r} = 0.218, \\textit{p} = 0.0024). A supervised Random\nForest model trained on the collected motion data was benchmarked against\nmultiple datasets including UCF Sports Action and UCF50, and was found to\neffectively generalize across environments, identifying ergonomic risk patterns\nwith accuracies up to 94\\%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.13999v3", "cate": "cs.CV", "date": "2024-05-22", "updated": "2025-07-18"}
{"id": "2507.13937", "title": "Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support", "authors": ["Jan Trienes", "Anastasiia Derzhanskaia", "Roland Schwarzkopf", "Markus Mühling", "Jörg Schlötterer", "Christin Seifert"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13937v1", "summary": "We present Marcel, a lightweight and open-source conversational agent\ndesigned to support prospective students with admission-related inquiries. The\nsystem aims to provide fast and personalized responses, while reducing workload\nof university staff. We employ retrieval-augmented generation to ground answers\nin university resources and to provide users with verifiable, contextually\nrelevant information. To improve retrieval quality, we introduce an FAQ\nretriever that maps user questions to knowledge-base entries, allowing\nadministrators to steer retrieval, and improving over standard dense/hybrid\nretrieval strategies. The system is engineered for easy deployment in\nresource-constrained academic settings. We detail the system architecture,\nprovide a technical evaluation of its components, and report insights from a\nreal-world deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13937v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2407.14506", "title": "On Pre-training of Multimodal Language Models Customized for Chart Understanding", "authors": ["Wan-Cyuan Fan", "Yen-Chun Chen", "Mengchen Liu", "Lu Yuan", "Leonid Sigal"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      NeurIPS 2024 Workshop on Adaptive Foundation Models", "url": "http://arxiv.org/abs/2407.14506v3", "summary": "Recent studies customizing Multimodal Large Language Models (MLLMs) for\ndomain-specific tasks have yielded promising results, especially in the field\nof scientific chart comprehension. These studies generally utilize visual\ninstruction tuning with specialized datasets to enhance question and answer\n(QA) accuracy within the chart domain. However, they often neglect the\nfundamental discrepancy between natural image-caption pre-training data and\ndigital chart image-QA data, particularly in the models' capacity to extract\nunderlying numeric values from charts. This paper tackles this oversight by\nexploring the training processes necessary to improve MLLMs' comprehension of\ncharts. We present three key findings: (1) Incorporating raw data values in\nalignment pre-training markedly improves comprehension of chart data. (2)\nReplacing images with their textual representation randomly during end-to-end\nfine-tuning transfer the language reasoning capability to chart interpretation\nskills. (3) Requiring the model to first extract the underlying chart data and\nthen answer the question in the fine-tuning can further improve the accuracy.\nConsequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart\ncomprehension. CHOPINLLM effectively interprets various types of charts,\nincluding unannotated ones, while maintaining robust reasoning abilities.\nFurthermore, we establish a new benchmark to evaluate MLLMs' understanding of\ndifferent chart types across various comprehension levels. Experimental results\nshow that CHOPINLLM exhibits strong performance in understanding both annotated\nand unannotated charts across a wide range of types.", "comment": "NeurIPS 2024 Workshop on Adaptive Foundation Models", "pdf_url": "http://arxiv.org/pdf/2407.14506v3", "cate": "cs.CV", "date": "2024-07-19", "updated": "2025-07-17"}
{"id": "2411.03537", "title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild", "authors": ["Kevin Tirta Wijaya", "Minghao Guo", "Michael Sun", "Hans-Peter Seidel", "Wojciech Matusik", "Vahid Babaei"], "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.03537v2", "summary": "Molecular deep learning models have achieved remarkable success in property\nprediction, but they often require large amounts of labeled data. The challenge\nis that, in real-world applications, labels are extremely scarce, as obtaining\nthem through laboratory experimentation is both expensive and time-consuming.\nIn this work, we introduce MoleVers, a versatile pretrained molecular model\ndesigned for various types of molecular property prediction in the wild, i.e.,\nwhere experimentally-validated labels are scarce. MoleVers employs a two-stage\npretraining strategy. In the first stage, it learns molecular representations\nfrom unlabeled data through masked atom prediction and extreme denoising, a\nnovel task enabled by our newly introduced branching encoder architecture and\ndynamic noise scale sampling. In the second stage, the model refines these\nrepresentations through predictions of auxiliary properties derived from\ncomputational methods, such as the density functional theory or large language\nmodels. Evaluation on 22 small, experimentally-validated datasets demonstrates\nthat MoleVers achieves state-of-the-art performance, highlighting the\neffectiveness of its two-stage framework in producing generalizable molecular\nrepresentations for diverse downstream properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.03537v2", "cate": "cs.LG", "date": "2024-11-05", "updated": "2025-07-18"}
{"id": "2408.00998", "title": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation", "authors": ["Xiang Gao", "Jiaying Liu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted conference paper of ACM MM 2024", "url": "http://arxiv.org/abs/2408.00998v3", "summary": "Large-scale text-to-image diffusion models have been a revolutionary\nmilestone in the evolution of generative AI and multimodal technology, allowing\nwonderful image generation with natural-language text prompt. However, the\nissue of lacking controllability of such models restricts their practical\napplicability for real-life content creation. Thus, attention has been focused\non leveraging a reference image to control text-to-image synthesis, which is\nalso regarded as manipulating (or editing) a reference image as per a text\nprompt, namely, text-driven image-to-image translation. This paper contributes\na novel, concise, and efficient approach that adapts pre-trained large-scale\ntext-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a\nplug-and-play manner, realizing high-quality and versatile text-driven I2I\ntranslation without any model training, model fine-tuning, or online\noptimization process. To guide T2I generation with a reference image, we\npropose to decompose diverse guiding factors with different frequency bands of\ndiffusion features in the DCT spectral space, and accordingly devise a novel\nfrequency band substitution layer which realizes dynamic control of the\nreference image to the T2I generation result in a plug-and-play manner. We\ndemonstrate that our method allows flexible control over both guiding factor\nand guiding intensity of the reference image simply by tuning the type and\nbandwidth of the substituted frequency band, respectively. Extensive\nqualitative and quantitative experiments verify superiority of our approach\nover related methods in I2I translation visual quality, versatility, and\ncontrollability. The code is publicly available at:\nhttps://github.com/XiangGao1102/FBSDiff.", "comment": "Accepted conference paper of ACM MM 2024", "pdf_url": "http://arxiv.org/pdf/2408.00998v3", "cate": "cs.CV", "date": "2024-08-02", "updated": "2025-07-18"}
{"id": "2507.14045", "title": "Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks", "authors": ["Israt Jahan", "Md Tahmid Rahman Laskar", "Chun Peng", "Jimmy Huang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Canadian AI 2025", "url": "http://arxiv.org/abs/2507.14045v1", "summary": "This paper presents a comprehensive evaluation of cost-efficient Large\nLanguage Models (LLMs) for diverse biomedical tasks spanning both text and\nimage modalities. We evaluated a range of closed-source and open-source LLMs on\ntasks such as biomedical text classification and generation, question\nanswering, and multimodal image processing. Our experimental findings indicate\nthat there is no single LLM that can consistently outperform others across all\ntasks. Instead, different LLMs excel in different tasks. While some\nclosed-source LLMs demonstrate strong performance on specific tasks, their\nopen-source counterparts achieve comparable results (sometimes even better),\nwith additional benefits like faster inference and enhanced privacy. Our\nexperimental results offer valuable insights for selecting models that are\noptimally suited for specific biomedical applications.", "comment": "Accepted at Canadian AI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14045v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2412.16247", "title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models", "authors": ["Konstantin Donhauser", "Kristina Ulicna", "Gemma Elyse Moran", "Aditya Ravuri", "Kian Kenyon-Dean", "Cian Eastwood", "Jason Hartford"], "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.16247v3", "summary": "Sparse dictionary learning (DL) has emerged as a powerful approach to extract\nsemantically meaningful concepts from the internals of large language models\n(LLMs) trained mainly in the text domain. In this work, we explore whether DL\ncan extract meaningful concepts from less human-interpretable scientific data,\nsuch as vision foundation models trained on cell microscopy images, where\nlimited prior knowledge exists about which high-level concepts should arise. We\npropose a novel combination of a sparse DL algorithm, Iterative Codebook\nFeature Learning (ICFL), with a PCA whitening pre-processing step derived from\ncontrol data. Using this combined approach, we successfully retrieve\nbiologically meaningful concepts, such as cell types and genetic perturbations.\nMoreover, we demonstrate how our method reveals subtle morphological changes\narising from human-interpretable interventions, offering a promising new\ndirection for scientific discovery via mechanistic interpretability in\nbioimaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.16247v3", "cate": "cs.LG", "date": "2024-12-20", "updated": "2025-07-18"}
{"id": "2412.02503", "title": "VA-MoE: Variables-Adaptive Mixture of Experts for Incremental Weather Forecasting", "authors": ["Hao Chen", "Han Tao", "Guo Song", "Jie Zhang", "Yunlong Yu", "Yonghan Dong", "Lei Bai"], "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has already been accepted by ICCV25", "url": "http://arxiv.org/abs/2412.02503v2", "summary": "This paper presents Variables Adaptive Mixture of Experts (VAMoE), a novel\nframework for incremental weather forecasting that dynamically adapts to\nevolving spatiotemporal patterns in real time data. Traditional weather\nprediction models often struggle with exorbitant computational expenditure and\nthe need to continuously update forecasts as new observations arrive. VAMoE\naddresses these challenges by leveraging a hybrid architecture of experts,\nwhere each expert specializes in capturing distinct subpatterns of atmospheric\nvariables (temperature, humidity, wind speed). Moreover, the proposed method\nemploys a variable adaptive gating mechanism to dynamically select and combine\nrelevant experts based on the input context, enabling efficient knowledge\ndistillation and parameter sharing. This design significantly reduces\ncomputational overhead while maintaining high forecast accuracy. Experiments on\nreal world ERA5 dataset demonstrate that VAMoE performs comparable against SoTA\nmodels in both short term (1 days) and long term (5 days) forecasting tasks,\nwith only about 25% of trainable parameters and 50% of the initial training\ndata.", "comment": "This paper has already been accepted by ICCV25", "pdf_url": "http://arxiv.org/pdf/2412.02503v2", "cate": "cs.LG", "date": "2024-12-03", "updated": "2025-07-18"}
{"id": "2409.05260", "title": "Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space", "authors": ["Junho Lee", "Jeongwoo Shin", "Seung Woo Ko", "Seongsu Ha", "Joonseok Lee"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.05260v2", "summary": "Given a video with $T$ frames, frame sampling is a task to select $N \\ll T$\nframes, so as to maximize the performance of a fixed video classifier. Not just\nbrute-force search, but most existing methods suffer from its vast search space\nof $\\binom{T}{N}$, especially when $N$ gets large. To address this challenge,\nwe introduce a novel perspective of reducing the search space from $O(T^N)$ to\n$O(T)$. Instead of exploring the entire $O(T^N)$ space, our proposed\nsemi-optimal policy selects the top $N$ frames based on the independently\nestimated value of each frame using per-frame confidence, significantly\nreducing the computational complexity. We verify that our semi-optimal policy\ncan efficiently approximate the optimal policy, particularly under practical\nsettings. Additionally, through extensive experiments on various datasets and\nmodel architectures, we demonstrate that learning our semi-optimal policy\nensures stable and high performance regardless of the size of $N$ and $T$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.05260v2", "cate": "cs.CV", "date": "2024-09-09", "updated": "2025-07-18"}
{"id": "2507.14063", "title": "Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog", "authors": ["Lautaro Estienne", "Gabriel Ben Zenou", "Nona Naderi", "Jackie Cheung", "Pablo Piantanida"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14063v1", "summary": "As AI systems take on collaborative roles, they must reason about shared\ngoals and beliefs-not just generate fluent language. The Rational Speech Act\n(RSA) framework offers a principled approach to pragmatic reasoning, but\nexisting extensions face challenges in scaling to multi-turn, collaborative\nscenarios. In this paper, we introduce Collaborative Rational Speech Act\n(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn\ndialog by optimizing a gain function adapted from rate-distortion theory. This\ngain is an extension of the gain model that is maximized in the original RSA\nmodel but takes into account the scenario in which both agents in a\nconversation have private information and produce utterances conditioned on the\ndialog. We demonstrate the effectiveness of CRSA on referential games and\ntemplate-based doctor-patient dialogs in the medical domain. Empirical results\nshow that CRSA yields more consistent, interpretable, and collaborative\nbehavior than existing baselines-paving the way for more pragmatic and socially\naware language agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14063v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.00152", "title": "Temporal reasoning for timeline summarisation in social media", "authors": ["Jiayu Song", "Mahmud Elahi Akhter", "Dana Atzil Slonim", "Maria Liakata"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.00152v3", "summary": "This paper explores whether enhancing temporal reasoning capabilities in\nLarge Language Models (LLMs) can improve the quality of timeline summarisation,\nthe task of summarising long texts containing sequences of events, such as\nsocial media threads. We first introduce NarrativeReason, a novel dataset\nfocused on temporal relationships among sequential events within narratives,\ndistinguishing it from existing temporal reasoning datasets that primarily\naddress pair-wise event relationships. Our approach then combines temporal\nreasoning with timeline summarisation through a knowledge distillation\nframework, where we first fine-tune a teacher model on temporal reasoning tasks\nand then distill this knowledge into a student model while simultaneously\ntraining it for the task of timeline summarisation. Experimental results\ndemonstrate that our model achieves superior performance on out-of-domain\nmental health-related timeline summarisation tasks, which involve long social\nmedia threads with repetitions of events and a mix of emotions, highlighting\nthe importance and generalisability of leveraging temporal reasoning to improve\ntimeline summarisation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.00152v3", "cate": "cs.CL", "date": "2024-12-30", "updated": "2025-07-18"}
{"id": "2412.05144", "title": "$ε$-rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics", "authors": ["Jiang Yang", "Yuxiang Zhao", "Quanhui Zhu"], "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.05144v3", "summary": "Understanding the training dynamics of deep neural networks (DNNs),\nparticularly how they evolve low-dimensional features from high-dimensional\ndata, remains a central challenge in deep learning theory. In this work, we\nintroduce the concept of $\\epsilon$-rank, a novel metric quantifying the\neffective feature of neuron functions in the terminal hidden layer. Through\nextensive experiments across diverse tasks, we observe a universal staircase\nphenomenon: during training process implemented by the standard stochastic\ngradient descent methods, the decline of the loss function is accompanied by an\nincrease in the $\\epsilon$-rank and exhibits a staircase pattern.\nTheoretically, we rigorously prove a negative correlation between the loss\nlower bound and $\\epsilon$-rank, demonstrating that a high $\\epsilon$-rank is\nessential for significant loss reduction. Moreover, numerical evidences show\nthat within the same deep neural network, the $\\epsilon$-rank of the subsequent\nhidden layer is higher than that of the previous hidden layer. Based on these\nobservations, to eliminate the staircase phenomenon, we propose a novel\npre-training strategy on the initial hidden layer that elevates the\n$\\epsilon$-rank of the terminal hidden layer. Numerical experiments validate\nits effectiveness in reducing training time and improving accuracy across\nvarious tasks. Therefore, the newly introduced concept of $\\epsilon$-rank is a\ncomputable quantity that serves as an intrinsic effective metric characteristic\nfor deep neural networks, providing a novel perspective for understanding the\ntraining dynamics of neural networks and offering a theoretical foundation for\ndesigning efficient training strategies in practical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.05144v3", "cate": "cs.LG", "date": "2024-12-06", "updated": "2025-07-18"}
{"id": "2412.20383", "title": "Progressively Exploring and Exploiting Cost-Free Data to Break Fine-Grained Classification Barriers", "authors": ["Li-Jun Zhao", "Zhen-Duo Chen", "Zhi-Yuan Xue", "Xin Luo", "Xin-Shun Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.20383v2", "summary": "Current fine-grained classification research primarily focuses on\nfine-grained feature learning. However, in real-world scenarios, fine-grained\ndata annotation is challenging, and the features and semantics are highly\ndiverse and frequently changing. These issues create inherent barriers between\ntraditional experimental settings and real-world applications, limiting the\neffectiveness of conventional fine-grained classification methods. Although\nsome recent studies have provided potential solutions to these issues, most of\nthem still rely on limited supervised information and thus fail to offer\neffective solutions. In this paper, based on theoretical analysis, we propose a\nnovel learning paradigm to break the barriers in fine-grained classification.\nThis paradigm enables the model to progressively learn during inference,\nthereby leveraging cost-free data to more accurately represent fine-grained\ncategories and adapt to dynamic semantic changes. On this basis, an efficient\nEXPloring and EXPloiting strategy and method (EXP2) is designed. Thereinto,\nuseful inference data samples are explored according to class representations\nand exploited to optimize classifiers. Experimental results demonstrate the\ngeneral effectiveness of our method, providing guidance for future in-depth\nunderstanding and exploration of real-world fine-grained classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.20383v2", "cate": "cs.CV", "date": "2024-12-29", "updated": "2025-07-18"}
{"id": "2303.18162", "title": "ViMMRC 2.0 -- Enhancing Machine Reading Comprehension on Vietnamese Literature Text", "authors": ["Son T. Luu", "Khoi Trong Hoang", "Tuong Quang Pham", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted for publication at International Journal of Asian Language Processing", "url": "http://arxiv.org/abs/2303.18162v3", "summary": "Machine reading comprehension has been an interesting and challenging task in\nrecent years, with the purpose of extracting useful information from texts. To\nattain the computer ability to understand the reading text and answer relevant\ninformation, we introduce ViMMRC 2.0 - an extension of the previous ViMMRC for\nthe task of multiple-choice reading comprehension in Vietnamese Textbooks which\ncontain the reading articles for students from Grade 1 to Grade 12. This\ndataset has 699 reading passages which are prose and poems, and 5,273\nquestions. The questions in the new dataset are not fixed with four options as\nin the previous version. Moreover, the difficulty of questions is increased,\nwhich challenges the models to find the correct choice. The computer must\nunderstand the whole context of the reading passage, the question, and the\ncontent of each choice to extract the right answers. Hence, we propose a\nmulti-stage approach that combines the multi-step attention network (MAN) with\nthe natural language inference (NLI) task to enhance the performance of the\nreading comprehension model. Then, we compare the proposed methodology with the\nbaseline BERTology models on the new dataset and the ViMMRC 1.0. From the\nresults of the error analysis, we found that the challenge of the reading\ncomprehension models is understanding the implicit context in texts and linking\nthem together in order to find the correct answers. Finally, we hope our new\ndataset will motivate further research to enhance the ability of computers to\nunderstand the Vietnamese language.", "comment": "Accepted for publication at International Journal of Asian Language\n  Processing", "pdf_url": "http://arxiv.org/pdf/2303.18162v3", "cate": "cs.CL", "date": "2023-03-31", "updated": "2025-07-18"}
{"id": "2501.08208", "title": "ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems", "authors": ["Mohita Chowdhury", "Yajie Vera He", "Jared Joselowitz", "Aisling Higham", "Ernest Lim"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      29 pages", "url": "http://arxiv.org/abs/2501.08208v2", "summary": "Large Language Models (LLMs) have shown impressive potential in clinical\nquestion answering (QA), with Retrieval Augmented Generation (RAG) emerging as\na leading approach for ensuring the factual accuracy of model responses.\nHowever, current automated RAG metrics perform poorly in clinical and\nconversational use cases. Using clinical human evaluations of responses is\nexpensive, unscalable, and not conducive to the continuous iterative\ndevelopment of RAG systems. To address these challenges, we introduce ASTRID -\nan Automated and Scalable TRIaD for evaluating clinical QA systems leveraging\nRAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy\n(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is\ndesigned to better capture the faithfulness of a model's response to the\nknowledge base without penalising conversational elements. To validate our\ntriad, we curate a dataset of over 200 real-world patient questions posed to an\nLLM-based QA agent during surgical follow-up for cataract surgery - the highest\nvolume operation in the world - augmented with clinician-selected questions for\nemergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate\nthat CF can predict human ratings of faithfulness better than existing\ndefinitions for conversational use cases. Furthermore, we show that evaluation\nusing our triad consisting of CF, RA, and CR exhibits alignment with clinician\nassessment for inappropriate, harmful, or unhelpful responses. Finally, using\nnine different LLMs, we demonstrate that the three metrics can closely agree\nwith human evaluations, highlighting the potential of these metrics for use in\nLLM-driven automated evaluation pipelines. We also publish the prompts and\ndatasets for these experiments, providing valuable resources for further\nresearch and development.", "comment": "29 pages", "pdf_url": "http://arxiv.org/pdf/2501.08208v2", "cate": "cs.CL", "date": "2025-01-14", "updated": "2025-07-18"}
{"id": "2412.05657", "title": "AI-Accelerated Flow Simulation: A Robust Auto-Regressive Framework for Long-Term CFD Forecasting", "authors": ["Sunwoong Yang", "Ricardo Vinuesa", "Namwoo Kang"], "categories": ["cs.LG", "physics.flu-dyn"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.05657v3", "summary": "This study addresses the critical challenge of error accumulation in\nspatio-temporal auto-regressive (AR) predictions within scientific machine\nlearning models by exploring temporal integration schemes and adaptive\nmulti-step rollout strategies. We introduce the first implementation of the\ntwo-step Adams-Bashforth method specifically tailored for data-driven AR\nprediction, leveraging historical derivative information to enhance numerical\nstability without additional computational overhead. To validate our approach,\nwe systematically evaluate time integration schemes across canonical 2D PDEs\nbefore extending to complex Navier-Stokes cylinder vortex shedding dynamics.\nAdditionally, we develop three novel adaptive weighting strategies that\ndynamically adjust the importance of different future time steps during\nmulti-step rollout training. Our analysis reveals that as physical complexity\nincreases, such sophisticated rollout techniques become essential, with the\nAdams-Bashforth scheme demonstrating consistent robustness across investigated\nsystems and our best adaptive approach delivering an 89% improvement over\nconventional fixed-weight methods while maintaining similar computational\ncosts. For the complex Navier-Stokes vortex shedding problem, despite using an\nextremely lightweight graph neural network with just 1,177 trainable parameters\nand training on only 50 snapshots, our framework accurately predicts 350 future\ntime steps reducing mean squared error from 0.125 (single-step direct\nprediction) to 0.002 (Adams-Bashforth with proposed multi-step rollout). Our\nintegrated methodology demonstrates an 83% improvement over standard noise\ninjection techniques and maintains robustness under severe spatial constraints;\nspecifically, when trained on only a partial spatial domain, it still achieves\n58% and 27% improvements over direct prediction and forward Euler methods,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.05657v3", "cate": "cs.LG", "date": "2024-12-07", "updated": "2025-07-18"}
{"id": "2501.17328", "title": "SIC: Similarity-Based Interpretable Image Classification with Neural Networks", "authors": ["Tom Nuno Wolf", "Emre Kavak", "Fabian Bongratz", "Christian Wachinger"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2501.17328v3", "summary": "The deployment of deep learning models in critical domains necessitates a\nbalance between high accuracy and interpretability. We introduce SIC, an\ninherently interpretable neural network that provides local and global\nexplanations of its decision-making process. Leveraging the concept of\ncase-based reasoning, SIC extracts class-representative support vectors from\ntraining images, ensuring they capture relevant features while suppressing\nirrelevant ones. Classification decisions are made by calculating and\naggregating similarity scores between these support vectors and the input's\nlatent feature vector. We employ B-Cos transformations, which align model\nweights with inputs, to yield coherent pixel-level explanations in addition to\nglobal explanations of case-based reasoning. We evaluate SIC on three tasks:\nfine-grained classification on Stanford Dogs and FunnyBirds, multi-label\nclassification on Pascal VOC, and pathology detection on the RSNA dataset.\nResults indicate that SIC not only achieves competitive accuracy compared to\nstate-of-the-art black-box and inherently interpretable models but also offers\ninsightful explanations verified through practical evaluation on the FunnyBirds\nbenchmark. Our theoretical analysis proves that these explanations fulfill\nestablished axioms for explanations. Our findings underscore SIC's potential\nfor applications where understanding model decisions is as critical as the\ndecisions themselves.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2501.17328v3", "cate": "cs.CV", "date": "2025-01-28", "updated": "2025-07-18"}
{"id": "2407.10266", "title": "psifx -- Psychological and Social Interactions Feature Extraction Package", "authors": ["Guillaume Rochette", "Mathieu Rochat", "Matthew J. Vowels"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.10266v4", "summary": "psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to\nfacilitate and democratize the use of state-of-the-art machine learning\ntechniques for human sciences research. It is motivated by a need (a) to\nautomate and standardize data annotation processes that typically require\nexpensive, lengthy, and inconsistent human labour; (b) to develop and\ndistribute open-source community-driven psychology research software; and (c)\nto enable large-scale access and ease of use for non-expert users. The\nframework contains an array of tools for tasks such as speaker diarization,\nclosed-caption transcription and translation from audio; body, hand, and facial\npose estimation and gaze tracking with multi-person tracking from video; and\ninteractive textual feature extraction supported by large language models. The\npackage has been designed with a modular and task-oriented approach, enabling\nthe community to add or update new tools easily. This combination creates new\nopportunities for in-depth study of real-time behavioral phenomena in\npsychological and social science research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.10266v4", "cate": "cs.CL", "date": "2024-07-14", "updated": "2025-07-17"}
{"id": "2501.14120", "title": "On the Transfer of Knowledge in Quantum Algorithms", "authors": ["Esther Villar-Rodriguez", "Eneko Osaba", "Izaskun Oregi", "Sebastián V. Romero", "Julián Ferreiro-Vélez"], "categories": ["quant-ph", "cs.AI"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures, 4 tables. Paper submitted for its review in Expert Systems journal", "url": "http://arxiv.org/abs/2501.14120v2", "summary": "Quantum computing is poised to transform computational paradigms across\nscience and industry. As the field evolves, it can benefit from established\nclassical methodologies, including promising paradigms such as Transfer of\nKnowledge (ToK). This work serves as a brief, self-contained reference for ToK,\nunifying its core principles under a single formal framework. We introduce a\njoint notation that consolidates and extends prior work in Transfer Learning\nand Transfer Optimization, bridging traditionally separate research lines and\nenabling a common language for knowledge reuse. Building on this foundation, we\nclassify existing ToK strategies and principles into a structured taxonomy that\nhelps researchers position their methods within a broader conceptual map. We\nthen extend key transfer protocols to quantum computing, introducing two novel\nuse cases (reverse annealing and multitasking QAOA) alongside a sequential VQE\napproach that supports and validates prior findings. These examples highlight\nToK's potential to improve performance and generalization in quantum\nalgorithms. Finally, we outline challenges and opportunities for integrating\nToK into quantum computing, emphasizing its role in reducing resource demands\nand accelerating problem-solving. This work lays the groundwork for future\nsynergies between classical and quantum computing through a shared,\ntransferable knowledge framework.", "comment": "14 pages, 8 figures, 4 tables. Paper submitted for its review in\n  Expert Systems journal", "pdf_url": "http://arxiv.org/pdf/2501.14120v2", "cate": "quant-ph", "date": "2025-01-23", "updated": "2025-07-18"}
{"id": "2412.17305", "title": "Exploiting Label Skewness for Spiking Neural Networks in Federated Learning", "authors": ["Di Yu", "Xin Du", "Linshan Jiang", "Huijing Zhang", "Shuiguang Deng"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This work has been accepted on the International Joint Conference on Artificial Intelligence 2025", "url": "http://arxiv.org/abs/2412.17305v3", "summary": "The energy efficiency of deep spiking neural networks (SNNs) aligns with the\nconstraints of resource-limited edge devices, positioning SNNs as a promising\nfoundation for intelligent applications leveraging the extensive data collected\nby these devices. To address data privacy concerns when deploying SNNs on edge\ndevices, federated learning (FL) facilitates collaborative model training by\nleveraging data distributed across edge devices without transmitting local data\nto a central server. However, existing FL approaches struggle with label-skewed\ndata across devices, which leads to drift in local SNN models and degrades the\nperformance of the global SNN model. In this paper, we propose a novel\nframework called FedLEC, which incorporates intra-client label weight\ncalibration to balance the learning intensity across local labels and\ninter-client knowledge distillation to mitigate local SNN model bias caused by\nlabel absence. Extensive experiments with three different structured SNNs\nacross five datasets (i.e., three non-neuromorphic and two neuromorphic\ndatasets) demonstrate the efficiency of FedLEC. Compared to eight\nstate-of-the-art FL algorithms, FedLEC achieves an average accuracy improvement\nof approximately 11.59% for the global SNN model under various label skew\ndistribution settings.", "comment": "This work has been accepted on the International Joint Conference on\n  Artificial Intelligence 2025", "pdf_url": "http://arxiv.org/pdf/2412.17305v3", "cate": "cs.LG", "date": "2024-12-23", "updated": "2025-07-18"}
{"id": "2501.19243", "title": "Accelerating Diffusion Transformer via Error-Optimized Cache", "authors": ["Junxiang Qiu", "Shuo Wang", "Jinda Lu", "Lin Liu", "Houcheng Jiang", "Xingyu Zhu", "Yanbin Hao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.19243v3", "summary": "Diffusion Transformer (DiT) is a crucial method for content generation.\nHowever, it needs a lot of time to sample. Many studies have attempted to use\ncaching to reduce the time consumption of sampling. Existing caching methods\naccelerate generation by reusing DiT features from the previous time step and\nskipping calculations in the next, but they tend to locate and cache low-error\nmodules without focusing on reducing caching-induced errors, resulting in a\nsharp decline in generated content quality when increasing caching intensity.\nTo solve this problem, we propose the \\textbf{E}rror-\\textbf{O}ptimized\n\\textbf{C}ache (\\textbf{EOC}). This method introduces three key improvements:\n\\textbf{(1)} Prior knowledge extraction: Extract and process the caching\ndifferences; \\textbf{(2)} A judgment method for cache optimization: Determine\nwhether certain caching steps need to be optimized; \\textbf{(3)} Cache\noptimization: reduce caching errors. Experiments show that this algorithm\nsignificantly reduces the error accumulation caused by caching, especially\nexcessive caching. On the ImageNet dataset, without substantially increasing\nthe computational load, this method improves the FID of the generated images\nwhen the rule-based model FORA has a caching level of \\textbf{75}\\%,\n\\textbf{50}\\%, and \\textbf{25}\\%, and the training-based model\nLearning-to-cache has a caching level of \\textbf{22}\\%. Specifically, the FID\nvalues change from 30.454 to 21.690 (\\textbf{28.8}\\%), from 6.857 to 5.821\n(\\textbf{15.1}\\%), from 3.870 to 3.692 (\\textbf{4.6}\\%), and from 3.539 to\n3.451 (\\textbf{2.5}\\%) respectively. Code is available at\nhttps://github.com/qiujx0520/EOC_MM2025.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.19243v3", "cate": "cs.CV", "date": "2025-01-31", "updated": "2025-07-18"}
{"id": "2409.04617", "title": "Sparse Rewards Can Self-Train Dialogue Agents", "authors": ["Barrett Martin Lattimer", "Varun Gangal", "Ryan McDonald", "Yi Yang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 (Findings)", "url": "http://arxiv.org/abs/2409.04617v3", "summary": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM)\nagents, especially in multi-turn dialogue tasks, have been primarily driven by\nsupervised fine-tuning and high-quality human feedback. However, as base LLM\nmodels continue to improve, acquiring meaningful human feedback has become\nincreasingly challenging and costly. In certain domains, base LLM agents may\neventually exceed human capabilities, making traditional feedback-driven\nmethods impractical. In this paper, we introduce a novel self-improvement\nparadigm that empowers LLM agents to autonomously enhance their performance\nwithout external human feedback. Our method, Juxtaposed Outcomes for Simulation\nHarvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward\nsimulation environment to extract ideal behaviors and further train the LLM on\nits own outputs. We present ToolWOZ, a sparse reward tool-calling simulation\nenvironment derived from MultiWOZ. We demonstrate that models trained with\nJOSH, both small and frontier, significantly improve tool-based interactions\nwhile preserving general model capabilities across diverse benchmarks. Our code\nand data are publicly available on GitHub at\nhttps://github.com/asappresearch/josh-llm-simulation-training", "comment": "Accepted to ACL 2025 (Findings)", "pdf_url": "http://arxiv.org/pdf/2409.04617v3", "cate": "cs.CL", "date": "2024-09-06", "updated": "2025-07-18"}
{"id": "2502.03304", "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning", "authors": ["Qitao Tan", "Jun Liu", "Zheng Zhan", "Caiwei Ding", "Yanzhi Wang", "Xiaolong Ma", "Jaewoo Lee", "Jin Lu", "Geng Yuan"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.03304v2", "summary": "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose Divergence-driven\nZeroth-Order (DiZO) optimization. DiZO conducts divergence-driven layer\nadaptation by incorporating projections to ZO updates, generating\ndiverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning. Our code is released at\nhttps://anonymous.4open.science/r/DiZO-E86D.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.03304v2", "cate": "cs.LG", "date": "2025-02-05", "updated": "2025-07-18"}
{"id": "2501.03840", "title": "Machine learning applications in archaeological practices: a review", "authors": ["Mathias Bellat", "Jordy D. Orellana Figueroa", "Jonathan S. Reeves", "Ruhollah Taghizadeh-Mehrjardi", "Claudio Tennie", "Thomas Scholten"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03840v3", "summary": "Artificial intelligence and machine learning applications in archaeology have\nincreased significantly in recent years, and these now span all subfields,\ngeographical regions, and time periods. The prevalence and success of these\napplications have remained largely unexamined, as recent reviews on the use of\nmachine learning in archaeology have only focused only on specific subfields of\narchaeology. Our review examined an exhaustive corpus of 135 articles published\nbetween 1997 and 2022. We observed a significant increase in the number of\npublications from 2019 onwards. Automatic structure detection and artefact\nclassification were the most represented tasks in the articles reviewed,\nfollowed by taphonomy, and archaeological predictive modelling. From the\nreview, clustering and unsupervised methods were underrepresented compared to\nsupervised models. Artificial neural networks and ensemble learning account for\ntwo thirds of the total number of models used. However, if machine learning\nmodels are gaining in popularity they remain subject to misunderstanding. We\nobserved, in some cases, poorly defined requirements and caveats of the machine\nlearning methods used. Furthermore, the goals and the needs of machine learning\napplications for archaeological purposes are in some cases unclear or poorly\nexpressed. To address this, we proposed a workflow guide for archaeologists to\ndevelop coherent and consistent methodologies adapted to their research\nquestions, project scale and data. As in many other areas, machine learning is\nrapidly becoming an important tool in archaeological research and practice,\nuseful for the analyses of large and multivariate data, although not without\nlimitations. This review highlights the importance of well-defined and\nwell-reported structured methodologies and collaborative practices to maximise\nthe potential of applications of machine learning methods in archaeology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03840v3", "cate": "cs.LG", "date": "2025-01-07", "updated": "2025-07-18"}
{"id": "2502.01312", "title": "CleanPose: Category-Level Object Pose Estimation via Causal Learning and Knowledge Distillation", "authors": ["Xiao Lin", "Yun Peng", "Liuyi Wang", "Xianyou Zhong", "Minghao Zhu", "Jingwei Yang", "Yi Feng", "Chengju Liu", "Qijun Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2502.01312v2", "summary": "Category-level object pose estimation aims to recover the rotation,\ntranslation and size of unseen instances within predefined categories. In this\ntask, deep neural network-based methods have demonstrated remarkable\nperformance. However, previous studies show they suffer from spurious\ncorrelations raised by \"unclean\" confounders in models, hindering their\nperformance on novel instances with significant variations. To address this\nissue, we propose CleanPose, a novel approach integrating causal learning and\nknowledge distillation to enhance category-level pose estimation. To mitigate\nthe negative effect of unobserved confounders, we develop a causal inference\nmodule based on front-door adjustment, which promotes unbiased estimation by\nreducing potential spurious correlations. Additionally, to further improve\ngeneralization ability, we devise a residual-based knowledge distillation\nmethod that has proven effective in providing comprehensive category\ninformation guidance. Extensive experiments across multiple benchmarks\n(REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed\nCleanPose over state-of-the-art methods. Code will be available at\nhttps://github.com/chrislin0621/CleanPose.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2502.01312v2", "cate": "cs.CV", "date": "2025-02-03", "updated": "2025-07-18"}
{"id": "2410.13394", "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs", "authors": ["Sumanth Doddapaneni", "Mohammed Safi Ur Rahman Khan", "Dilip Venkatesh", "Raj Dabre", "Anoop Kunchukuttan", "Mitesh M. Khapra"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.13394v2", "summary": "Evaluating machine-generated text remains a significant challenge in NLP,\nespecially for non-English languages. Current methodologies, including\nautomated metrics, human assessments, and LLM-based evaluations, predominantly\nfocus on English, revealing a significant gap in multilingual evaluation\nframeworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an\nextensible framework that includes evaluator LLMs (Hercule) and a novel test\nset (Recon) specifically designed for multilingual evaluation. Our test set\nfeatures 500 human-annotated instructions spanning various task capabilities\nalong with human judgment scores across six languages. This would enable\nbenchmarking of general-purpose multilingual LLMs and facilitate\nmeta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a\ncross-lingual evaluation model that addresses the scarcity of reference answers\nin the target language by learning to assign scores to responses based on\neasily available reference answers in English. Our experiments demonstrate that\nHercule aligns more closely with human judgments compared to proprietary\nmodels, demonstrating the effectiveness of such cross-lingual evaluation in low\nresource scenarios. Further, it is also effective in zero-shot evaluation on\nunseen languages. This study is the first comprehensive examination of\ncross-lingual evaluation using LLMs, presenting a scalable and effective\napproach for multilingual assessment. All code, datasets, and models will be\npublicly available to enable further research in this important area.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.13394v2", "cate": "cs.CL", "date": "2024-10-17", "updated": "2025-07-18"}
{"id": "2507.13516", "title": "A priori error analysis of the proximal Galerkin method", "authors": ["Brendan Keith", "Rami Masri", "Marius Zeinhofer"], "categories": ["math.NA", "cs.NA", "35J86, 35R35, 49J40, 65K15, 65N30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13516v1", "summary": "The proximal Galerkin (PG) method is a finite element method for solving\nvariational problems with inequality constraints. It has several advantages,\nincluding constraint-preserving approximations and mesh independence. This\npaper presents the first abstract a priori error analysis of PG methods,\nproviding a general framework to establish convergence and error estimates. As\napplications of the framework, we demonstrate optimal convergence rates for\nboth the obstacle and Signorini problems using various finite element\nsubspaces.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13516v1", "cate": "math.NA", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2502.12272", "title": "Learning to Reason at the Frontier of Learnability", "authors": ["Thomas Foster", "Anya Sims", "Johannes Forkel", "Mattie Fellows", "Jakob Foerster"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12272v5", "summary": "Reinforcement learning is now widely adopted as the final stage of large\nlanguage model training, especially for reasoning-style tasks such as maths\nproblems. Typically, models attempt each question many times during a single\ntraining step and attempt to learn from their successes and failures. However,\nwe demonstrate that throughout training with two popular algorithms (PPO and\nVinePPO) on two widely used datasets, many questions are either solved by all\nattempts - meaning they are already learned - or by none - providing no\nmeaningful training signal. To address this, we adapt a method from the\nreinforcement learning literature - sampling for learnability - and apply it to\nthe reinforcement learning stage of LLM training. Our curriculum prioritises\nquestions with high variance of success, i.e. those where the agent sometimes\nsucceeds, but not always. Our findings demonstrate that this curriculum\nconsistently boosts training performance across multiple algorithms and\ndatasets, paving the way for more efficient and effective reinforcement\nlearning with LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12272v5", "cate": "cs.LG", "date": "2025-02-17", "updated": "2025-07-18"}
{"id": "2501.05000", "title": "Load Forecasting for Households and Energy Communities: Are Deep Learning Models Worth the Effort?", "authors": ["Lukas Moosbrugger", "Valentin Seiler", "Philipp Wohlgenannt", "Sebastian Hegenbart", "Sashko Ristov", "Elias Eder", "Peter Kepplinger"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.05000v5", "summary": "Energy communities (ECs) play a key role in enabling local demand shifting\nand enhancing self-sufficiency, as energy systems transition toward\ndecentralized structures with high shares of renewable generation. To optimally\noperate them, accurate short-term load forecasting is essential, particularly\nfor implementing demand-side management strategies. With the recent rise of\ndeep learning methods, data-driven forecasting has gained significant\nattention, however, it remains insufficiently explored in many practical\ncontexts. Therefore, this study evaluates the effectiveness of state-of-the-art\ndeep learning models-including LSTM, xLSTM, and Transformer\narchitectures-compared to traditional benchmarks such as K-Nearest Neighbors\n(KNN) and persistence forecasting, across varying community size, historical\ndata availability, and model complexity. Additionally, we assess the benefits\nof transfer learning using publicly available synthetic load profiles. On\naverage, transfer learning improves the normalized mean absolute error by 1.97\npercentage points when only two months of training data are available.\nInterestingly, for less than six months of training data, simple persistence\nmodels outperform deep learning architectures in forecast accuracy. The\npractical value of improved forecasting is demonstrated using a mixed-integer\nlinear programming optimization for ECs with a shared battery energy storage\nsystem. For an energy community with 50 households, the most accurate deep\nlearning model achieves an average reduction in financial energy costs of\n8.06%. Notably, a simple KNN approach achieves average savings of 8.01%, making\nit a competitive and robust alternative. All implementations are publicly\navailable to facilitate reproducibility. These findings offer actionable\ninsights for ECs, and they highlight when the additional complexity of deep\nlearning is warranted by performance gains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.05000v5", "cate": "cs.LG", "date": "2025-01-09", "updated": "2025-07-18"}
{"id": "2503.05156", "title": "Accelerating Diffusion Transformer via Gradient-Optimized Cache", "authors": ["Junxiang Qiu", "Lin Liu", "Shuo Wang", "Jinda Lu", "Kezhou Chen", "Yanbin Hao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05156v2", "summary": "Feature caching has emerged as an effective strategy to accelerate diffusion\ntransformer (DiT) sampling through temporal feature reuse. It is a challenging\nproblem since (1) Progressive error accumulation from cached blocks\nsignificantly degrades generation quality, particularly when over 50\\% of\nblocks are cached; (2) Current error compensation approaches neglect dynamic\nperturbation patterns during the caching process, leading to suboptimal error\ncorrection. To solve these problems, we propose the Gradient-Optimized Cache\n(GOC) with two key innovations: (1) Cached Gradient Propagation: A gradient\nqueue dynamically computes the gradient differences between cached and\nrecomputed features. These gradients are weighted and propagated to subsequent\nsteps, directly compensating for the approximation errors introduced by\ncaching. (2) Inflection-Aware Optimization: Through statistical analysis of\nfeature variation patterns, we identify critical inflection points where the\ndenoising trajectory changes direction. By aligning gradient updates with these\ndetected phases, we prevent conflicting gradient directions during error\ncorrection. Extensive evaluations on ImageNet demonstrate GOC's superior\ntrade-off between efficiency and quality. With 50\\% cached blocks, GOC achieves\nIS 216.28 (26.3\\% higher) and FID 3.907 (43\\% lower) compared to baseline DiT,\nwhile maintaining identical computational costs. These improvements persist\nacross various cache ratios, demonstrating robust adaptability to different\nacceleration requirements. Code is available at\nhttps://github.com/qiujx0520/GOC_ICCV2025.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05156v2", "cate": "cs.CV", "date": "2025-03-07", "updated": "2025-07-18"}
{"id": "2502.13962", "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering", "authors": ["William Jurayj", "Jeffrey Cheng", "Benjamin Van Durme"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025. Code: this https URL", "url": "http://arxiv.org/abs/2502.13962v2", "summary": "Scaling the test-time compute of large language models has demonstrated\nimpressive performance on reasoning benchmarks. However, existing evaluations\nof test-time scaling make the strong assumption that a reasoning system should\nalways give an answer to any question provided. This overlooks concerns about\nwhether a model is confident in its answer, and whether it is appropriate to\nalways provide a response. To address these concerns, we extract confidence\nscores during reasoning for thresholding model responses. We find that\nincreasing compute budget at inference time not only helps models answer more\nquestions correctly, but also increases confidence in correct responses. We\nthen extend the current paradigm of zero-risk responses during evaluation by\nconsidering settings with non-zero levels of response risk, and suggest a\nrecipe for reporting evaluations under these settings.", "comment": "Accepted to ACL 2025. Code: https://github.com/wjurayj/final_answer", "pdf_url": "http://arxiv.org/pdf/2502.13962v2", "cate": "cs.CL", "date": "2025-02-19", "updated": "2025-07-18"}
{"id": "2507.13589", "title": "Quantifying Ocular Surface Changes with Contact Lens Wear", "authors": ["Lucia Carichino", "Kara L. Maki", "David S. Ross", "Riley K. Supple", "Evan Rysdam"], "categories": ["math.NA", "cs.NA", "physics.bio-ph"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      35 pages and 14 figures, submitted", "url": "http://arxiv.org/abs/2507.13589v1", "summary": "Over 140 million people worldwide and over 45 million people in the United\nstates wear contact lenses; it is estimated 12%-27.4% contact lens users stop\nwearing them due to discomfort. Contact lens mechanical interactions with the\nocular surface have been found to affect the ocular surface. The mechanical\ninteractions between the contact lens and the eye are difficult to measure and\ncalculate in the clinical setting, and the research in this field is limited.\nThis paper presents the first mathematical model that couples the interaction\nbetween the contact lens and the open eye, where the contact lens\nconfiguration, the contact lens suction pressure, and the deformed ocular shape\nare all emergent properties of the model. The non-linear coupling between the\ncontact lens and the eye is achieved assuming the the suction pressure under\nthe lens is applied directly to the ocular surface, neglecting the post-lens\ntear film layer. The contact lens dynamics is modeled using a previous\npublished model. We consider a homogeneous and a heterogeneous linear elastic\neye model, different ocular shapes, different lens shapes and lens thickness\nprofiles, and extract lens deformation, lens suction pressure profiles, and\nocular deformations and stresses for all the scenarios considered. The model\npredicts higher ocular deformations and stresses at the center of the eye and\nin the limbal/scleral region. Accounting for a heterogeneous material eye\nparameters increases such deformations and stresses. The ocular displacements\nand stresses increase non-linearly as we increase the stiffness of the contact\nlens. Inserting a steeper contact lens on the eye results in a reduction of the\nocular displacement at the center of the eye and a larger displacement at the\nedge of the contact lens. The model predictions are compared to experimental\ndata and previously developed mathematical models.", "comment": "35 pages and 14 figures, submitted", "pdf_url": "http://arxiv.org/pdf/2507.13589v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.14131", "title": "An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model", "authors": ["Enoch H. Kang", "Hema Yoganarasimhan", "Lalit Jain"], "categories": ["cs.LG", "cs.AI", "econ.EM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.14131v4", "summary": "We study the problem of estimating Dynamic Discrete Choice (DDC) models, also\nknown as offline Maximum Entropy-Regularized Inverse Reinforcement Learning\n(offline MaxEnt-IRL) in machine learning. The objective is to recover reward or\n$Q^*$ functions that govern agent behavior from offline behavior data. In this\npaper, we propose a globally convergent gradient-based method for solving these\nproblems without the restrictive assumption of linearly parameterized rewards.\nThe novelty of our approach lies in introducing the Empirical Risk Minimization\n(ERM) based IRL/DDC framework, which circumvents the need for explicit state\ntransition probability estimation in the Bellman equation. Furthermore, our\nmethod is compatible with non-parametric estimation techniques such as neural\nnetworks. Therefore, the proposed method has the potential to be scaled to\nhigh-dimensional, infinite state spaces. A key theoretical insight underlying\nour approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL)\ncondition -- a property that, while weaker than strong convexity, is sufficient\nto ensure fast global convergence guarantees. Through a series of synthetic\nexperiments, we demonstrate that our approach consistently outperforms\nbenchmark methods and state-of-the-art alternatives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.14131v4", "cate": "cs.LG", "date": "2025-02-19", "updated": "2025-07-18"}
{"id": "2501.06848", "title": "A General Framework for Inference-time Scaling and Steering of Diffusion Models", "authors": ["Raghav Singhal", "Zachary Horvitz", "Ryan Teehan", "Mengye Ren", "Zhou Yu", "Kathleen McKeown", "Rajesh Ranganath"], "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.06848v5", "summary": "Diffusion models produce impressive results in modalities ranging from images\nand video to protein design and text. However, generating samples with\nuser-specified properties remains a challenge. Recent research proposes\nfine-tuning models to maximize rewards that capture desired properties, but\nthese methods require expensive training and are prone to mode collapse. In\nthis work, we present Feynman-Kac (FK) steering, an inference-time framework\nfor steering diffusion models with reward functions. FK steering works by\nsampling a system of multiple interacting diffusion processes, called\nparticles, and resampling particles at intermediate steps based on scores\ncomputed using functions called potentials. Potentials are defined using\nrewards for intermediate states and are selected such that a high value\nindicates that the particle will yield a high-reward sample. We explore various\nchoices of potentials, intermediate rewards, and samplers. We evaluate FK\nsteering on text-to-image and text diffusion models. For steering text-to-image\nmodels with a human preference reward, we find that FK steering a 0.8B\nparameter model outperforms a 2.6B parameter fine-tuned model on prompt\nfidelity, with faster sampling and no training. For steering text diffusion\nmodels with rewards for text quality and specific text attributes, we find that\nFK steering generates lower perplexity, more linguistically acceptable outputs\nand enables gradient-free control of attributes like toxicity. Our results\ndemonstrate that inference-time scaling and steering of diffusion models - even\nwith off-the-shelf rewards - can provide significant sample quality gains and\ncontrollability benefits. Code is available at\nhttps://github.com/zacharyhorvitz/Fk-Diffusion-Steering .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.06848v5", "cate": "cs.LG", "date": "2025-01-12", "updated": "2025-07-18"}
{"id": "2503.07348", "title": "Cycle-Consistent Multi-Graph Matching for Self-Supervised Annotation of C.Elegans", "authors": ["Christoph Karg", "Sebastian Stricker", "Lisa Hutschenreiter", "Bogdan Savchynskyy", "Dagmar Kainmueller"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.07348v2", "summary": "In this work we present a novel approach for unsupervised multi-graph\nmatching, which applies to problems for which a Gaussian distribution of\nkeypoint features can be assumed. We leverage cycle consistency as loss for\nself-supervised learning, and determine Gaussian parameters through Bayesian\nOptimization, yielding a highly efficient approach that scales to large\ndatasets. Our fully unsupervised approach enables us to reach the accuracy of\nstate-of-the-art supervised methodology for the biomedical use case of semantic\ncell annotation in 3D microscopy images of the worm C. elegans. To this end,\nour approach yields the first unsupervised atlas of C. elegans, i.e. a model of\nthe joint distribution of all of its cell nuclei, without the need for any\nground truth cell annotation. This advancement enables highly efficient\nsemantic annotation of cells in large microscopy datasets, overcoming a current\nkey bottleneck. Beyond C. elegans, our approach offers fully unsupervised\nconstruction of cell-level atlases for any model organism with a stereotyped\nbody plan down to the level of unique semantic cell labels, and thus bears the\npotential to catalyze respective biomedical studies in a range of further\nspecies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.07348v2", "cate": "cs.CV", "date": "2025-03-10", "updated": "2025-07-18"}
{"id": "2503.04800", "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation", "authors": ["Jie Ouyang", "Tingyue Pan", "Mingyue Cheng", "Ruiran Yan", "Yucong Luo", "Jiaying Lin", "Qi Liu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04800v3", "summary": "While Retrieval-Augmented Generation (RAG) has emerged as an effective\napproach for addressing the knowledge outdating problem in Large Language\nModels (LLMs), it still faces a critical challenge: the prevalence of outdated\ninformation in knowledge bases. Current research primarily focuses on\nincorporating up-to-date information, yet the impact of outdated information\ncoexisting in retrieval sources remains inadequately addressed. To bridge this\ngap, we introduce HoH, the first benchmark specifically designed to evaluate\nthe impact of outdated information on RAG. Our benchmark leverages token-level\ndiff algorithms combined with LLM pipelines to efficiently create a large-scale\nQA dataset that accurately captures the evolution of temporal knowledge in\nreal-world facts. Through comprehensive experiments, we reveal that outdated\ninformation significantly degrades RAG performance in two critical ways: (1) it\nsubstantially reduces response accuracy by distracting models from correct\ninformation, and (2) it can mislead models into generating potentially harmful\noutputs, even when current information is available. Current RAG approaches\nstruggle with both retrieval and generation aspects when handling outdated\ninformation. These findings highlight the urgent need for innovative solutions\nto address the temporal challenges in RAG. Our code and data are available at:\nhttps://github.com/0russwest0/HoH.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04800v3", "cate": "cs.CL", "date": "2025-03-03", "updated": "2025-07-18"}
{"id": "2507.13640", "title": "Interpolation in Polynomial Spaces of p-Degree", "authors": ["Phil-Alexander Hofmann", "Damar Wicaksono", "Michael Hecht"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13640v1", "summary": "We recently introduced the Fast Newton Transform (FNT), an algorithm for\nperforming multivariate Newton interpolation in downward closed polynomial\nspaces of spatial dimension $m$. In this work, we analyze the FNT in the\ncontext of a specific family of downward closed sets $A_{m,n,p}$, defined as\nall multi-indices with $\\ell^p$ norm less than $n$ with $p \\in [0,\\infty]$.\nThese sets induce the downward closed polynomial space $\\Pi_{m,n,p}$, within\nwhich the FNT algorithm achieves a time complexity of\n$\\mathcal{O}(|A_{m,n,p}|mn)$. We show that this setting, compared to tensor\nproduct spaces, yields an improvement in complexity by a factor $\\rho_{m,n,p}$,\nwhich decays super exponentially with increasing spatial dimension when $m\n\\lesssim n^p$. Additionally, we demonstrate the construction of the\nhierarchical scheme employed by the FNT and showcase its performance to compute\nactivity scores in sensitivity analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13640v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.00142", "title": "Can we ease the Injectivity Bottleneck on Lorentzian Manifolds for Graph Neural Networks?", "authors": ["Srinitish Srinivasan", "Omkumar CU"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ACM SIGMOD/PODS 2025 GRADES NDA Workshop (Non-Archival) Poster: this https URL", "url": "http://arxiv.org/abs/2504.00142v5", "summary": "While hyperbolic GNNs show promise for hierarchical data, they often have\nlimited discriminative power compared to Euclidean counterparts or the WL test,\ndue to non-injective aggregation. To address this expressivity gap, we propose\nthe Lorentzian Graph Isomorphic Network (LGIN), a novel HGNN designed for\nenhanced discrimination within the Lorentzian model. LGIN introduces a new\nupdate rule that preserves the Lorentzian metric while effectively capturing\nricher structural information. This marks a significant step towards more\nexpressive GNNs on Riemannian manifolds. Extensive evaluations across nine\nbenchmark datasets demonstrate LGIN's superior performance, consistently\noutperforming or matching state-of-the-art hyperbolic and Euclidean baselines,\nshowcasing its ability to capture complex graph structures. LGIN is the first\nto adapt principles of powerful, highly discriminative GNN architectures to a\nRiemannian manifold. The code for our paper can be found at\nhttps://github.com/Deceptrax123/LGIN", "comment": "Accepted at ACM SIGMOD/PODS 2025 GRADES NDA Workshop (Non-Archival)\n  Poster:\n  https://drive.google.com/file/d/1hjUqbIWrjhZ1YTFDGFK9hxGYiz9xYLSC/view?usp=drive_link", "pdf_url": "http://arxiv.org/pdf/2504.00142v5", "cate": "cs.LG", "date": "2025-03-31", "updated": "2025-07-18"}
{"id": "2502.03876", "title": "Position: Untrained Machine Learning for Anomaly Detection by using 3D Point Cloud Data", "authors": ["Juan Du", "Dongheng Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figure", "url": "http://arxiv.org/abs/2502.03876v2", "summary": "Anomaly detection based on 3D point cloud data is an important research\nproblem and receives more and more attention recently. Untrained anomaly\ndetection based on only one sample is an emerging research problem motivated by\nreal manufacturing industries such as personalized manufacturing where only one\nsample can be collected without any additional labels and historical datasets.\nIdentifying anomalies accurately based on one 3D point cloud sample is a\ncritical challenge in both industrial applications and the field of machine\nlearning. This paper aims to provide a formal definition of the untrained\nanomaly detection problem based on 3D point cloud data, discuss the differences\nbetween untrained anomaly detection and current unsupervised anomaly detection\nproblems. Unlike trained unsupervised learning, untrained unsupervised learning\ndoes not rely on any data, including unlabeled data. Instead, they leverage\nprior knowledge about the surfaces and anomalies.\n  We propose three complementary methodological frameworks: the Latent Variable\nInference Framework that employs probabilistic modeling to distinguish\nanomalies; the Decomposition Framework that separates point clouds into\nreference, anomaly, and noise components through sparse learning; and the Local\nGeometry Framework that leverages neighborhood information for anomaly\nidentification. Experimental results demonstrate that untrained methods achieve\ncompetitive detection performance while offering significant computational\nadvantages, demonstrating up to a 15-fold increase in execution speed. The\nproposed methods provide viable solutions for scenarios with extreme data\nscarcity, addressing critical challenges in personalized manufacturing and\nhealthcare applications where collecting multiple samples or historical data is\ninfeasible.", "comment": "9 pages, 5 figure", "pdf_url": "http://arxiv.org/pdf/2502.03876v2", "cate": "cs.LG", "date": "2025-02-06", "updated": "2025-07-18"}
{"id": "2503.20349", "title": "Consistency Trajectory Matching for One-Step Generative Super-Resolution", "authors": ["Weiyi You", "Mingyang Zhang", "Leheng Zhang", "Xingyu Zhou", "Kexuan Shi", "Shuhang Gu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.20349v4", "summary": "Current diffusion-based super-resolution (SR) approaches achieve commendable\nperformance at the cost of high inference overhead. Therefore, distillation\ntechniques are utilized to accelerate the multi-step teacher model into\none-step student model. Nevertheless, these methods significantly raise\ntraining costs and constrain the performance of the student model by the\nteacher model. To overcome these tough challenges, we propose Consistency\nTrajectory Matching for Super-Resolution (CTMSR), a distillation-free strategy\nthat is able to generate photo-realistic SR results in one step. Concretely, we\nfirst formulate a Probability Flow Ordinary Differential Equation (PF-ODE)\ntrajectory to establish a deterministic mapping from low-resolution (LR) images\nwith noise to high-resolution (HR) images. Then we apply the Consistency\nTraining (CT) strategy to directly learn the mapping in one step, eliminating\nthe necessity of pre-trained diffusion model. To further enhance the\nperformance and better leverage the ground-truth during the training process,\nwe aim to align the distribution of SR results more closely with that of the\nnatural images. To this end, we propose to minimize the discrepancy between\ntheir respective PF-ODE trajectories from the LR image distribution by our\nmeticulously designed Distribution Trajectory Matching (DTM) loss, resulting in\nimproved realism of our recovered HR images. Comprehensive experimental results\ndemonstrate that the proposed methods can attain comparable or even superior\ncapabilities on both synthetic and real datasets while maintaining minimal\ninference latency.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.20349v4", "cate": "cs.CV", "date": "2025-03-26", "updated": "2025-07-18"}
{"id": "2504.02768", "title": "MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs", "authors": ["Jaap Jumelet", "Leonie Weissweiler", "Joakim Nivre", "Arianna Bisazza"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.02768v2", "summary": "We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguistic\nminimal pairs, covering 101 languages and 2 types of subject-verb agreement,\ncontaining more than 128,000 minimal pairs. Our minimal pairs are created using\na fully automated pipeline, leveraging the large-scale linguistic resources of\nUniversal Dependencies and UniMorph. MultiBLiMP 1.0 evaluates abilities of LLMs\nat an unprecedented multilingual scale, and highlights the shortcomings of the\ncurrent state-of-the-art in modelling low-resource languages", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.02768v2", "cate": "cs.CL", "date": "2025-04-03", "updated": "2025-07-18"}
{"id": "2507.13644", "title": "Multiphysics embedding localized orthogonal decomposition for thermomechanical coupling problems", "authors": ["Yuzhou Nan", "Yajun Wang", "Changqing Ye", "Xiaofei Guan"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13644v1", "summary": "Multiscale modeling and analysis of multiphysics coupling processes in highly\nheterogeneous media present significant challenges. In this paper, we propose a\nnovel multiphysics embedding localized orthogonal decomposition (ME-LOD) method\nfor solving thermomechanical coupling problems, which also provides a\nsystematic approach to address intricate coupling effects in multiphysical\nsystems. Unlike the standard localized orthogonal decomposition (LOD) method\nthat constructs separate multiscale spaces for each physical field, the\nproposed method features a unified construction for both displacement and\ntemperature. Compared to the standard LOD method, our approach achieves\noperator stability reconstruction through orthogonalization while preserving\ncomputational efficiency. Several numerical experiments demonstrate that the\nME-LOD method outperforms the traditional LOD method in accuracy, particularly\nin cases with significant contrasts in material properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13644v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.10534", "title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling", "authors": ["Qihui Yang", "Taylor Berg-Kirkpatrick", "Julian McAuley", "Zachary Novack"], "categories": ["cs.SD", "cs.AI"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10534v2", "summary": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling\nof professional Digital Signal Processing (DSP) workflows remains challenging.\nIn particular, while there is growing interest in neural black-box modeling of\naudio effect graphs (e.g. reverb, compression, equalization), AI-based\napproaches struggle to replicate the nuanced signal flow and parameter\ninteractions used in professional workflows. Existing differentiable plugin\napproaches often diverge from real-world tools, exhibiting inferior performance\nrelative to simplified neural controllers under equivalent computational\nconstraints. We introduce WildFX, a pipeline containerized with Docker for\ngenerating multi-track audio mixing datasets with rich effect graphs, powered\nby a professional Digital Audio Workstation (DAW) backend. WildFX supports\nseamless integration of cross-platform commercial plugins or any plugins in the\nwild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g.,\nsidechains, crossovers) and achieving efficient parallelized processing. A\nminimalist metadata interface simplifies project/plugin configuration.\nExperiments demonstrate the pipeline's validity through blind estimation of\nmixing graphs, plugin/gain parameters, and its ability to bridge AI research\nwith practical DSP demands. The code is available on:\nhttps://github.com/IsaacYQH/WildFX.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10534v2", "cate": "cs.SD", "date": "2025-07-14", "updated": "2025-07-17"}
{"id": "2306.15375", "title": "Frex: dependently-typed algebraic simplification", "authors": ["Guillaume Allais", "Edwin Brady", "Nathan Corbyn", "Ohad Kammar", "Jeremy Yallop"], "categories": ["cs.PL", "cs.LO", "cs.SC"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.15375v2", "summary": "We present a new design for an algebraic simplification library structured\naround concepts from universal algebra: theories, models, homomorphisms, and\nuniversal properties of free algebras and free extensions of algebras. The\nlibrary's dependently typed interface guarantees that both built-in and\nuser-defined simplification modules are terminating, sound, and complete with\nrespect to a well-specified class of equations. We have implemented the design\nin the Idris 2 and Agda dependently typed programming languages and shown that\nit supports modular extension to new theories, proof extraction and\ncertification, goal extraction via reflection, and interactive development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.15375v2", "cate": "cs.PL", "date": "2023-06-27", "updated": "2025-07-18"}
{"id": "2504.08593", "title": "Hands-On: Segmenting Individual Signs from Continuous Sequences", "authors": ["JianHe Low", "Harry Walsh", "Ozge Mercanoglu Sincan", "Richard Bowden"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in the 19th IEEE International Conference on Automatic Face and Gesture Recognition", "url": "http://arxiv.org/abs/2504.08593v3", "summary": "This work tackles the challenge of continuous sign language segmentation, a\nkey task with huge implications for sign language translation and data\nannotation. We propose a transformer-based architecture that models the\ntemporal dynamics of signing and frames segmentation as a sequence labeling\nproblem using the Begin-In-Out (BIO) tagging scheme. Our method leverages the\nHaMeR hand features, and is complemented with 3D Angles. Extensive experiments\nshow that our model achieves state-of-the-art results on the DGS Corpus, while\nour features surpass prior benchmarks on BSLCorpus.", "comment": "Accepted in the 19th IEEE International Conference on Automatic Face\n  and Gesture Recognition", "pdf_url": "http://arxiv.org/pdf/2504.08593v3", "cate": "cs.CV", "date": "2025-04-11", "updated": "2025-07-17"}
{"id": "2502.06358", "title": "Prompt-Tuning Bandits: Enabling Few-Shot Generalization for Efficient Multi-Task Offline RL", "authors": ["Finn Rietz", "Oleg Smirnov", "Sara Karimi", "Lele Cao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06358v3", "summary": "Prompting has emerged as the dominant paradigm for adapting large,\npre-trained transformer-based models to downstream tasks. The Prompting\nDecision Transformer (PDT) enables large-scale, multi-task offline\nReinforcement Learning (RL) pre-training by leveraging stochastic trajectory\nprompts to identify the target task. However, these prompts are sampled\nuniformly from expert demonstrations, overlooking a critical limitation: not\nall prompts are equally informative for differentiating between tasks. This\nlimits generalization and adaptation, especially in low-data or open-world\nsettings where sample efficiency is crucial. To address this issue, we propose\na lightweight, inference-time, bandit-based prompt-tuning framework. The bandit\nexplores and optimizes trajectory prompt selection to enhance task performance,\nwhile avoiding costly fine-tuning of the transformer backbone. Our experiments\nindicate not only clear performance gains due to bandit-based prompt-tuning,\nbut also better sample complexity, scalability, and prompt space exploration\ncompared to prompt-tuning baselines. These results highlights the importance of\nadaptive prompt selection mechanisms for efficient generalization in offline\nmulti-task RL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06358v3", "cate": "cs.LG", "date": "2025-02-10", "updated": "2025-07-18"}
{"id": "2504.10888", "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors", "authors": ["Jiahuan Long", "Wen Yao", "Tingsong Jiang", "Chao Ma"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM 2025", "url": "http://arxiv.org/abs/2504.10888v2", "summary": "Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.", "comment": "Accepted by ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2504.10888v2", "cate": "cs.CV", "date": "2025-04-15", "updated": "2025-07-18"}
{"id": "2504.14452", "title": "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data", "authors": ["Tong Chen", "Faeze Brahman", "Jiacheng Liu", "Niloofar Mireshghallah", "Weijia Shi", "Pang Wei Koh", "Luke Zettlemoyer", "Hannaneh Hajishirzi"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.14452v2", "summary": "Language models (LMs) can memorize and reproduce segments from their\npretraining data verbatim even in non-adversarial settings, raising concerns\nabout copyright, plagiarism, privacy, and creativity. We introduce Paraphrase\nPreference Optimization (ParaPO), a post-training method that fine-tunes LMs to\nreduce unintentional regurgitation while preserving their overall utility.\nParaPO trains LMs to prefer paraphrased versions of memorized segments over the\noriginal verbatim content from the pretraining data. To maintain the ability to\nrecall famous quotations when appropriate, we develop a variant of ParaPO that\nuses system prompts to control regurgitation behavior. In our evaluation on\nLlama3.1-8B, ParaPO consistently reduces regurgitation across all tested\ndatasets (e.g., reducing the regurgitation metric from 17.3 to 12.9 in creative\nwriting), whereas unlearning methods used in prior work to mitigate\nregurgitation are less effective outside their targeted unlearned domain (from\n17.3 to 16.9). When applied to the instruction-tuned Tulu3-8B model, ParaPO\nwith system prompting successfully preserves famous quotation recall while\nreducing unintentional regurgitation (from 8.7 to 6.3 in creative writing) when\nprompted not to regurgitate. In contrast, without ParaPO tuning, prompting the\nmodel not to regurgitate produces only a marginal reduction (8.7 to 8.4).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.14452v2", "cate": "cs.CL", "date": "2025-04-20", "updated": "2025-07-17"}
{"id": "2507.13731", "title": "Pass-efficient Randomized Algorithms for Low-rank Approximation of Quaternion Matrices", "authors": ["Salman Ahmadi-Asl", "Malihe Nobakht Kooshkghazi", "Valentin Leplat"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13731v1", "summary": "Randomized algorithms for low-rank approximation of quaternion matrices have\ngained increasing attention in recent years. However, existing methods overlook\npass efficiency, the ability to limit the number of passes over the input\nmatrix-which is critical in modern computing environments dominated by\ncommunication costs. We address this gap by proposing a suite of pass-efficient\nrandomized algorithms that let users directly trade pass budget for\napproximation accuracy. Our contributions include: (i) a family of\narbitrary-pass randomized algorithms for low-rank approximation of quaternion\nmatrices that operate under a user-specified number of matrix views, and (ii) a\npass-efficient extension of block Krylov subspace methods that accelerates\nconvergence for matrices with slowly decaying spectra. Furthermore, we\nestablish spectral norm error bounds showing that the expected approximation\nerror decays exponentially with the number of passes. Finally, we validate our\nframework through extensive numerical experiments and demonstrate its practical\nrelevance across multiple applications, including quaternionic data\ncompression, matrix completion, image super-resolution, and deep learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13731v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.13774", "title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs", "authors": ["Tamim Al Mahmud", "Najeeb Jebreel", "Josep Domingo-Ferrer", "David Sanchez"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This is the updated version of the preprint, revised following acceptance for publication in Elsevier Neural Networks Journal. The paper is now published (18 July 2025) with DOI: this https URL", "url": "http://arxiv.org/abs/2504.13774v2", "summary": "Large language models (LLMs) have recently revolutionized language processing\ntasks but have also brought ethical and legal issues. LLMs have a tendency to\nmemorize potentially private or copyrighted information present in the training\ndata, which might then be delivered to end users at inference time. When this\nhappens, a naive solution is to retrain the model from scratch after excluding\nthe undesired data. Although this guarantees that the target data have been\nforgotten, it is also prohibitively expensive for LLMs. Approximate unlearning\noffers a more efficient alternative, as it consists of ex post modifications of\nthe trained model itself to prevent undesirable results, but it lacks\nforgetting guarantees because it relies solely on empirical evidence. In this\nwork, we present DP2Unlearning, a novel LLM unlearning framework that offers\nformal forgetting guarantees at a significantly lower cost than retraining from\nscratch on the data to be retained. DP2Unlearning involves training LLMs on\ntextual data protected using {\\epsilon}-differential privacy (DP), which later\nenables efficient unlearning with the guarantees against disclosure associated\nwith the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning\nachieves similar model performance post-unlearning, compared to an LLM\nretraining from scratch on retained data -- the gold standard exact unlearning\n-- but at approximately half the unlearning cost. In addition, with a\nreasonable computational cost, it outperforms approximate unlearning methods at\nboth preserving the utility of the model post-unlearning and effectively\nforgetting the targeted information.", "comment": "This is the updated version of the preprint, revised following\n  acceptance for publication in Elsevier Neural Networks Journal. The paper is\n  now published (18 July 2025) with DOI:\n  https://doi.org/10.1016/j.neunet.2025.107879", "pdf_url": "http://arxiv.org/pdf/2504.13774v2", "cate": "cs.LG", "date": "2025-04-18", "updated": "2025-07-18"}
{"id": "2502.12751", "title": "Architect of the Bits World: Masked Autoregressive Modeling for Circuit Generation Guided by Truth Table", "authors": ["Haoyuan Wu", "Haisheng Zheng", "Shoubo Hu", "Zhuolun He", "Bei Yu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12751v2", "summary": "Logic synthesis, a critical stage in electronic design automation (EDA),\noptimizes gate-level circuits to minimize power consumption and area occupancy\nin integrated circuits (ICs). Traditional logic synthesis tools rely on\nhuman-designed heuristics, often yielding suboptimal results. Although\ndifferentiable architecture search (DAS) has shown promise in generating\ncircuits from truth tables, it faces challenges such as high computational\ncomplexity, convergence to local optima, and extensive hyperparameter tuning.\nConsequently, we propose a novel approach integrating conditional generative\nmodels with DAS for circuit generation. Our approach first introduces\nCircuitVQ, a circuit tokenizer trained based on our Circuit AutoEncoder We then\ndevelop CircuitAR, a masked autoregressive model leveraging CircuitVQ as the\ntokenizer. CircuitAR can generate preliminary circuit structures from truth\ntables, which guide DAS in producing functionally equivalent circuits. Notably,\nwe observe the scalability and emergent capability in generating complex\ncircuit structures of our CircuitAR models. Extensive experiments also show the\nsuperior performance of our method. This research bridges the gap between\nprobabilistic generative models and precise circuit generation, offering a\nrobust solution for logic synthesis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12751v2", "cate": "cs.LG", "date": "2025-02-18", "updated": "2025-07-18"}
{"id": "2504.13393", "title": "BeetleVerse: A Study on Taxonomic Classification of Ground Beetles", "authors": ["S M Rayeed", "Alyson East", "Samuel Stevens", "Sydne Record", "Charles V Stewart"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Paper Accepted at Computer Vision and Pattern Recognition 2025 (Workshop CV4Animals: Computer Vision for Animal Behavior Tracking and Modeling)", "url": "http://arxiv.org/abs/2504.13393v2", "summary": "Ground beetles are a highly sensitive and speciose biological indicator,\nmaking them vital for monitoring biodiversity. However, they are currently an\nunderutilized resource due to the manual effort required by taxonomic experts\nto perform challenging species differentiations based on subtle morphological\ndifferences, precluding widespread applications. In this paper, we evaluate 12\nvision models on taxonomic classification across four diverse, long-tailed\ndatasets spanning over 230 genera and 1769 species, with images ranging from\ncontrolled laboratory settings to challenging field-collected (in-situ)\nphotographs. We further explore taxonomic classification in two important\nreal-world contexts: sample efficiency and domain adaptation. Our results show\nthat the Vision and Language Transformer combined with an MLP head is the best\nperforming model, with 97% accuracy at genus and 94% at species level. Sample\nefficiency analysis shows that we can reduce train data requirements by up to\n50% with minimal compromise in performance. The domain adaptation experiments\nreveal significant challenges when transferring models from lab to in-situ\nimages, highlighting a critical domain gap. Overall, our study lays a\nfoundation for large-scale automated taxonomic classification of beetles, and\nbeyond that, advances sample-efficient learning and cross-domain adaptation for\ndiverse long-tailed ecological datasets.", "comment": "Paper Accepted at Computer Vision and Pattern Recognition 2025\n  (Workshop CV4Animals: Computer Vision for Animal Behavior Tracking and\n  Modeling)", "pdf_url": "http://arxiv.org/pdf/2504.13393v2", "cate": "cs.CV", "date": "2025-04-18", "updated": "2025-07-18"}
{"id": "2504.21801", "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition", "authors": ["Z. Z. Ren", "Zhihong Shao", "Junxiao Song", "Huajian Xin", "Haocheng Wang", "Wanjia Zhao", "Liyue Zhang", "Zhe Fu", "Qihao Zhu", "Dejian Yang", "Z. F. Wu", "Zhibin Gou", "Shirong Ma", "Hongxuan Tang", "Yuxuan Liu", "Wenjun Gao", "Daya Guo", "Chong Ruan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.21801v2", "summary": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.21801v2", "cate": "cs.CL", "date": "2025-04-30", "updated": "2025-07-18"}
{"id": "2507.13836", "title": "Newton's method for nonlinear mappings into vector bundles Part II: Application to variational problems", "authors": ["Laura Weigl", "Ronny Bergmann", "Anton Schiela"], "categories": ["math.NA", "cs.NA", "math.DG", "53-08, 46T05, 58E10, 49Q99"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13836v1", "summary": "We consider the solution of variational equations on manifolds by Newton's\nmethod. These problems can be expressed as root finding problems for mappings\nfrom infinite dimensional manifolds into dual vector bundles. We derive the\ndifferential geometric tools needed for the realization of Newton's method,\nequipped with an affine covariant damping strategy. We apply Newton's method to\na couple of variational problems and show numerical results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13836v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.14523", "title": "Exploring Graph Representations of Logical Forms for Language Modeling", "authors": ["Michael Sullivan"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To be published in ACL 2025 Findings", "url": "http://arxiv.org/abs/2505.14523v2", "summary": "We make the case for language models over logical forms (LFLMs), arguing that\nsuch models are more data-efficient than their textual counterparts. To that\nend, we introduce the Graph-based Formal-Logical Distributional Semantics\n(GFoLDS) prototype, a pretrained LM over graph representations of logical\nforms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong\nexperimental evidence that LFLMs can leverage the built-in, basic linguistic\nknowledge inherent in such models to immediately begin learning more complex\npatterns. On downstream tasks, we show that GFoLDS vastly outperforms textual,\ntransformer LMs (BERT) pretrained on the same data, indicating that LFLMs can\nlearn with substantially less data than models over plain text. Furthermore, we\nshow that the performance of this model is likely to scale with additional\nparameters and pretraining data, suggesting the viability of LFLMs in\nreal-world applications.", "comment": "To be published in ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2505.14523v2", "cate": "cs.CL", "date": "2025-05-20", "updated": "2025-07-18"}
{"id": "2504.12075", "title": "Generative Deep Learning Framework for Inverse Design of Fuels", "authors": ["Kiran K. Yalamanchi", "Pinaki Pal", "Balaji Mohan", "Abdullah S. AlRamadan", "Jihad A. Badra", "Yuanjiang Pei"], "categories": ["cs.LG", "physics.chem-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.12075v2", "summary": "In the present work, a generative deep learning framework combining a\nCo-optimized Variational Autoencoder (Co-VAE) architecture with quantitative\nstructure-property relationship (QSPR) techniques is developed to enable\naccelerated inverse design of fuels. The Co-VAE integrates a property\nprediction component coupled with the VAE latent space, enhancing molecular\nreconstruction and accurate estimation of Research Octane Number (RON) (chosen\nas the fuel property of interest). A subset of the GDB-13 database, enriched\nwith a curated RON database, is used for model training. Hyperparameter tuning\nis further utilized to optimize the balance among reconstruction fidelity,\nchemical validity, and RON prediction. An independent regression model is then\nused to refine RON prediction, while a differential evolution algorithm is\nemployed to efficiently navigate the VAE latent space and identify promising\nfuel molecule candidates with high RON. This methodology addresses the\nlimitations of traditional fuel screening approaches by capturing complex\nstructure-property relationships within a comprehensive latent representation.\nThe generative model can be adapted to different target properties, enabling\nsystematic exploration of large chemical spaces relevant to fuel design\napplications. Furthermore, the demonstrated framework can be readily extended\nby incorporating additional synthesizability criteria to improve applicability\nand reliability for de novo design of new fuels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.12075v2", "cate": "cs.LG", "date": "2025-04-16", "updated": "2025-07-17"}
{"id": "2505.01729", "title": "PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth", "authors": ["Bu Jin", "Weize Li", "Baihan Yang", "Zhenxin Zhu", "Junpeng Jiang", "Huan-ang Gao", "Haiyang Sun", "Kun Zhan", "Hengtong Hu", "Xueyang Zhang", "Peng Jia", "Hao Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE/RSJ IROS 2025", "url": "http://arxiv.org/abs/2505.01729v2", "summary": "Recent advancements in autonomous driving (AD) systems have highlighted the\npotential of world models in achieving robust and generalizable performance\nacross both ordinary and challenging driving conditions. However, a key\nchallenge remains: precise and flexible camera pose control, which is crucial\nfor accurate viewpoint transformation and realistic simulation of scene\ndynamics. In this paper, we introduce PosePilot, a lightweight yet powerful\nframework that significantly enhances camera pose controllability in generative\nworld models. Drawing inspiration from self-supervised depth estimation,\nPosePilot leverages structure-from-motion principles to establish a tight\ncoupling between camera pose and video generation. Specifically, we incorporate\nself-supervised depth and pose readouts, allowing the model to infer depth and\nrelative camera motion directly from video sequences. These outputs drive\npose-aware frame warping, guided by a photometric warping loss that enforces\ngeometric consistency across synthesized frames. To further refine camera pose\nestimation, we introduce a reverse warping step and a pose regression loss,\nimproving viewpoint precision and adaptability. Extensive experiments on\nautonomous driving and general-domain video datasets demonstrate that PosePilot\nsignificantly enhances structural understanding and motion reasoning in both\ndiffusion-based and auto-regressive world models. By steering camera pose with\nself-supervised depth, PosePilot sets a new benchmark for pose controllability,\nenabling physically consistent, reliable viewpoint synthesis in generative\nworld models.", "comment": "Accepted at IEEE/RSJ IROS 2025", "pdf_url": "http://arxiv.org/pdf/2505.01729v2", "cate": "cs.CV", "date": "2025-05-03", "updated": "2025-07-18"}
{"id": "2505.12723", "title": "On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding", "authors": ["Haoyuan Wu", "Rui Ming", "Jilong Gao", "Hangyu Zhao", "Xueyi Chen", "Yikai Yang", "Haisheng Zheng", "Zhuolun He", "Bei Yu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12723v2", "summary": "Large language models (LLMs) achieve remarkable performance in code\ngeneration tasks. However, a significant performance disparity persists between\npopular programming languages (e.g., Python, C++) and others. To address this\ncapability gap, we leverage the code translation task to train LLMs, thereby\nfacilitating the transfer of coding proficiency across diverse programming\nlanguages. Moreover, we introduce OORL for training, a novel reinforcement\nlearning (RL) framework that integrates on-policy and off-policy strategies.\nWithin OORL, on-policy RL is applied during code translation, guided by a\nrule-based reward signal derived from unit tests. Complementing this\ncoarse-grained rule-based reward, we propose Group Equivalent Preference\nOptimization (GEPO), a novel preference optimization method. Specifically, GEPO\ntrains the LLM using intermediate representations (IRs) groups. LLMs can be\nguided to discern IRs equivalent to the source code from inequivalent ones,\nwhile also utilizing signals about the mutual equivalence between IRs within\nthe group. This process allows LLMs to capture nuanced aspects of code\nfunctionality. By employing OORL for training with code translation tasks, LLMs\nimprove their recognition of code functionality and their understanding of the\nrelationships between code implemented in different languages. Extensive\nexperiments demonstrate that our OORL for LLMs training with code translation\ntasks achieves significant performance improvements on code benchmarks across\nmultiple programming languages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12723v2", "cate": "cs.CL", "date": "2025-05-19", "updated": "2025-07-18"}
{"id": "2507.13855", "title": "A stochastic column-block gradient descent method for solving nonlinear systems of equations", "authors": ["Naiyu Jiang", "Wendi Bao", "Lili Xing", "Weiguo Li"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13855v1", "summary": "In this paper, we propose a new stochastic column-block gradient descent\nmethod for solving nonlinear systems of equations. It has a descent direction\nand holds an approximately optimal step size obtained through an optimization\nproblem. We provide a thorough convergence analysis, and derive an upper bound\nfor the convergence rate of the new method. Numerical experiments demonstrate\nthat the proposed method outperforms the existing ones.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13855v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.19291", "title": "TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis", "authors": ["Kazi Mahathir Rahman", "Showrin Rahman", "Sharmin Sultana Srishty"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 26 figures. Submitted to arXiv for dissemination. Intended for future submission to a Generative AI conference", "url": "http://arxiv.org/abs/2505.19291v2", "summary": "Text-embedded image generation plays a critical role in industries such as\ngraphic design, advertising, and digital content creation. Text-to-Image\ngeneration methods leveraging diffusion models, such as TextDiffuser-2, have\ndemonstrated promising results in producing images with embedded text.\nTextDiffuser-2 effectively generates bounding box layouts that guide the\nrendering of visual text, achieving high fidelity and coherence. However,\nexisting approaches often rely on resource-intensive processes and are limited\nin their ability to run efficiently on both CPU and GPU platforms. To address\nthese challenges, we propose a novel two-stage pipeline that integrates\nreinforcement learning (RL) for rapid and optimized text layout generation with\na diffusion-based image synthesis model. Our RL-based approach significantly\naccelerates the bounding box prediction step while reducing overlaps, allowing\nthe system to run efficiently on both CPUs and GPUs. Extensive evaluations\ndemonstrate that our framework maintains or surpasses TextDiffuser-2's quality\nin text placement and image synthesis, with markedly faster runtime and\nincreased flexibility. Extensive evaluations demonstrate that our framework\nmaintains or surpasses TextDiffuser-2's quality in text placement and image\nsynthesis, with markedly faster runtime and increased flexibility. Our approach\nhas been evaluated on the MARIOEval benchmark, achieving OCR and CLIPScore\nmetrics close to state-of-the-art models, while being 97.64% more faster and\nrequiring only 2MB of memory to run.", "comment": "14 pages, 26 figures. Submitted to arXiv for dissemination. Intended\n  for future submission to a Generative AI conference", "pdf_url": "http://arxiv.org/pdf/2505.19291v2", "cate": "cs.CV", "date": "2025-05-25", "updated": "2025-07-17"}
{"id": "2505.08736", "title": "Towards Foundation Models for Experimental Readout Systems Combining Discrete and Continuous Data", "authors": ["James Giroux", "Cristiano Fanelli"], "categories": ["cs.LG", "hep-ex", "nucl-ex", "physics.ins-det"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      27 pages; 18 figures", "url": "http://arxiv.org/abs/2505.08736v2", "summary": "We present a (proto) Foundation Model for Nuclear Physics, capable of\noperating on low-level detector inputs from Imaging Cherenkov Detectors at the\nfuture Electron Ion Collider. Building upon established next-token prediction\napproaches, we aim to address potential challenges such as resolution loss from\nexisting tokenization schemes and limited support for conditional generation.\nWe propose four key innovations: (i) separate vocabularies for discrete and\ncontinuous variates, combined via Causal Multi-Head Cross-Attention (CMHCA),\n(ii) continuous kinematic conditioning through prepended context embeddings,\n(iii) scalable and simple, high-resolution continuous variate tokenization\nwithout joint vocabulary inflation, and (iv) class conditional generation\nthrough a Mixture of Experts. Our model enables fast, high-fidelity generation\nof pixel and time sequences for Cherenkov photons, validated through closure\ntests in the High Performance DIRC. We also show our model generalizes to\nreconstruction tasks such as pion/kaon identification, and noise filtering, in\nwhich we show its ability to leverage fine-tuning under specific objectives.", "comment": "27 pages; 18 figures", "pdf_url": "http://arxiv.org/pdf/2505.08736v2", "cate": "cs.LG", "date": "2025-05-13", "updated": "2025-07-18"}
{"id": "2506.01487", "title": "FDSG: Forecasting Dynamic Scene Graphs", "authors": ["Yi Yang", "Yuren Cong", "Hao Cheng", "Bodo Rosenhahn", "Michael Ying Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures, 12 tables", "url": "http://arxiv.org/abs/2506.01487v2", "summary": "Dynamic scene graph generation extends scene graph generation from images to\nvideos by modeling entity relationships and their temporal evolution. However,\nexisting methods either generate scene graphs from observed frames without\nexplicitly modeling temporal dynamics, or predict only relationships while\nassuming static entity labels and locations. These limitations hinder effective\nextrapolation of both entity and relationship dynamics, restricting video scene\nunderstanding. We propose Forecasting Dynamic Scene Graphs (FDSG), a novel\nframework that predicts future entity labels, bounding boxes, and\nrelationships, for unobserved frames, while also generating scene graphs for\nobserved frames. Our scene graph forecast module leverages query decomposition\nand neural stochastic differential equations to model entity and relationship\ndynamics. A temporal aggregation module further refines predictions by\nintegrating forecasted and observed information via cross-attention. To\nbenchmark FDSG, we introduce Scene Graph Forecasting, a new task for full\nfuture scene graph prediction. Experiments on Action Genome show that FDSG\noutperforms state-of-the-art methods on dynamic scene graph generation, scene\ngraph anticipation, and scene graph forecasting. Codes will be released upon\npublication.", "comment": "16 pages, 8 figures, 12 tables", "pdf_url": "http://arxiv.org/pdf/2506.01487v2", "cate": "cs.CV", "date": "2025-06-02", "updated": "2025-07-18"}
{"id": "2505.20015", "title": "On the class of coding optimality of human languages and the origins of Zipf's law", "authors": ["Ramon Ferrer-i-Cancho"], "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      typos corrected; discussion enhanced", "url": "http://arxiv.org/abs/2505.20015v4", "summary": "Here we present a new class of optimality for coding systems. Members of that\nclass are displaced linearly from optimal coding and thus exhibit Zipf's law,\nnamely a power-law distribution of frequency ranks. Within that class, Zipf's\nlaw, the size-rank law and the size-probability law form a group-like\nstructure. We identify human languages that are members of the class. All\nlanguages showing sufficient agreement with Zipf's law are potential members of\nthe class. In contrast, there are communication systems in other species that\ncannot be members of that class for exhibiting an exponential distribution\ninstead but dolphins and humpback whales might. We provide a new insight into\nplots of frequency versus rank in double logarithmic scale. For any system, a\nstraight line in that scale indicates that the lengths of optimal codes under\nnon-singular coding and under uniquely decodable encoding are displaced by a\nlinear function whose slope is the exponent of Zipf's law. For systems under\ncompression and constrained to be uniquely decodable, such a straight line may\nindicate that the system is coding close to optimality. We provide support for\nthe hypothesis that Zipf's law originates from compression and define testable\nconditions for the emergence of Zipf's law in compressing systems.", "comment": "typos corrected; discussion enhanced", "pdf_url": "http://arxiv.org/pdf/2505.20015v4", "cate": "cs.CL", "date": "2025-05-26", "updated": "2025-07-18"}
{"id": "2507.13902", "title": "Deep Micro Solvers for Rough-Wall Stokes Flow in a Heterogeneous Multiscale Method", "authors": ["Emanuel Ström", "Anna-Karin Tornberg", "Ozan Öktem"], "categories": ["math.NA", "cs.NA", "stat.ML", "65N55 (Primary) 65R20, 68T99, 76D07 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13902v1", "summary": "We propose a learned precomputation for the heterogeneous multiscale method\n(HMM) for rough-wall Stokes flow. A Fourier neural operator is used to\napproximate local averages over microscopic subsets of the flow, which allows\nto compute an effective slip length of the fluid away from the roughness. The\nnetwork is designed to map from the local wall geometry to the Riesz\nrepresentors for the corresponding local flow averages. With such a\nparameterisation, the network only depends on the local wall geometry and as\nsuch can be trained independent of boundary conditions. We perform a detailed\ntheoretical analysis of the statistical error propagation, and prove that under\nsuitable regularity and scaling assumptions, a bounded training loss leads to a\nbounded error in the resulting macroscopic flow. We then demonstrate on a\nfamily of test problems that the learned precomputation performs stably with\nrespect to the scale of the roughness. The accuracy in the HMM solution for the\nmacroscopic flow is comparable to when the local (micro) problems are solved\nusing a classical approach, while the computational cost of solving the micro\nproblems is significantly reduced.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13902v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.01551", "title": "EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation", "authors": ["Bingqian Lin", "Yunshuang Nie", "Khun Loun Zai", "Ziming Wei", "Mingfei Han", "Rongtao Xu", "Minzhe Niu", "Jianhua Han", "Liang Lin", "Cewu Lu", "Xiaodan Liang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01551v2", "summary": "Building Vision-Language Navigation (VLN) agents which can navigate following\nnatural language instructions is a long-standing goal in human-robot\ninteraction applications. Recent studies have revealed the potential of\ntraining open-source Large Language Models (LLMs) to unleash LLMs' reasoning\nability for improving navigation, and simultaneously mitigate the domain gap\nbetween LLMs' training corpus and the VLN task. However, these approaches\nprimarily adopt direct input-output mapping paradigms, causing the mapping\nlearning difficult and the navigational decisions unexplainable.\nChain-of-Thought (CoT) training is a promising way to improve both navigational\ndecision accuracy and interpretability, while the complexity of the navigation\ntask makes the perfect CoT labels unavailable and may lead to overfitting\nthrough pure CoT supervised fine-tuning. In this paper, we propose a novel\nsElf-improving embodied reasoning framework for boosting LLM-based\nvision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two\nstages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model\nwith formalized CoT labels to both activate the model's navigational reasoning\ncapabilities and increase the reasoning speed; (2) Self-Reflective\nPost-Training, where the model is iteratively trained with its own reasoning\noutputs as self-enriched CoT labels to enhance the supervision diversity. A\nself-reflective auxiliary task is also introduced to encourage learning correct\nreasoning patterns by contrasting with wrong ones. Experimental results on the\npopular VLN benchmarks demonstrate the superiority of EvolveNav over previous\nLLM-based VLN approaches. Code is available at\nhttps://github.com/expectorlin/EvolveNav.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01551v2", "cate": "cs.CV", "date": "2025-06-02", "updated": "2025-07-18"}
{"id": "2505.19068", "title": "Recalibrating binary probabilistic classifiers", "authors": ["Dirk Tasche"], "categories": ["cs.LG", "q-fin.RM", "68T09, 91G40", "I.5.1; G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented at workshop Learning to Quantify 2025 (LQ 2025), this https URL", "url": "http://arxiv.org/abs/2505.19068v2", "summary": "Recalibration of binary probabilistic classifiers to a target prior\nprobability is an important task in areas like credit risk management. We\nanalyse methods for recalibration from a distribution shift perspective.\nDistribution shift assumptions linked to the area under the curve (AUC) of a\nprobabilistic classifier are found to be useful for the design of meaningful\nrecalibration methods. Two new methods called parametric covariate shift with\nposterior drift (CSPD) and ROC-based quasi moment matching (QMM) are proposed\nand tested together with some other methods in an example setting. The outcomes\nof the test suggest that the QMM methods discussed in the paper can provide\nappropriately conservative results in evaluations with concave functionals like\nfor instance risk weights functions for credit risk.", "comment": "Presented at workshop Learning to Quantify 2025 (LQ 2025),\n  https://lq-2025.github.io/", "pdf_url": "http://arxiv.org/pdf/2505.19068v2", "cate": "cs.LG", "date": "2025-05-25", "updated": "2025-07-18"}
{"id": "2506.11571", "title": "VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?", "authors": ["Jiachen Yu", "Yufei Zhan", "Ziheng Wu", "Yousong Zhu", "Jinqiao Wang", "Minghui Qiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11571v2", "summary": "Recent extensive works have demonstrated that by introducing long CoT, the\ncapabilities of MLLMs to solve complex problems can be effectively enhanced.\nHowever, the reasons for the effectiveness of such paradigms remain unclear. It\nis challenging to analysis with quantitative results how much the model's\nspecific extraction of visual cues and its subsequent so-called reasoning\nduring inference process contribute to the performance improvements. Therefore,\nevaluating the faithfulness of MLLMs' reasoning to visual information is\ncrucial. To address this issue, we first present a cue-driven automatic and\ncontrollable editing pipeline with the help of GPT-Image-1. It enables the\nautomatic and precise editing of specific visual cues based on the instruction.\nFurthermore, we introduce VFaith-Bench, the first benchmark to evaluate MLLMs'\nvisual reasoning capabilities and analyze the source of such capabilities with\nan emphasis on the visual faithfulness. Using the designed pipeline, we\nconstructed comparative question-answer pairs by altering the visual cues in\nimages that are crucial for solving the original reasoning problem, thereby\nchanging the question's answer. By testing similar questions with images that\nhave different details, the average accuracy reflects the model's visual\nreasoning ability, while the difference in accuracy before and after editing\nthe test set images effectively reveals the relationship between the model's\nreasoning ability and visual perception. We further designed specific metrics\nto expose this relationship. VFaith-Bench includes 755 entries divided into\nfive distinct subsets, along with an additional human-labeled perception task.\nWe conducted in-depth testing and analysis of existing mainstream flagship\nmodels and prominent open-source model series/reasoning models on VFaith-Bench,\nfurther investigating the underlying factors of their reasoning capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11571v2", "cate": "cs.CV", "date": "2025-06-13", "updated": "2025-07-18"}
{"id": "2506.22598", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun Audrey Mao", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22598v2", "summary": "Agents based on Large Language Models (LLMs) have shown promise for\nperforming sophisticated software engineering tasks autonomously. In addition,\nthere has been progress towards developing agents that can perform parts of the\nresearch pipeline in machine learning and the natural sciences. We argue that\nresearch extension and its implementation is a critical capability for such\nsystems, and introduce RExBench to support the evaluation of this capability.\nRExBench is a benchmark consisting of 12 realistic research experiment\nimplementation tasks that aim to investigate research hypotheses that have not\npreviously been implemented. Each task is set up as an extension to an existing\nresearch paper and codebase, accompanied by domain expert-written instructions.\nRExBench is robust to data contamination, and supports an automatic evaluation\ninfrastructure that executes agent outputs to determine whether the success\ncriteria are met. We use this benchmark to evaluate nine LLM agents implemented\nusing three different frameworks: aider, Claude Code, and OpenHands. We find\nthat all agents evaluated fail to autonomously implement the majority of the\nextensions. Although the success rate improves with additional human-written\nhints, the best performance under this setting remains below 40%. This\nindicates that current agents are still short of being able to handle realistic\nresearch extension tasks without substantial human guidance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22598v2", "cate": "cs.CL", "date": "2025-06-27", "updated": "2025-07-17"}
{"id": "2507.13955", "title": "Convergence rates of curved boundary element methods for the 3D Laplace and Helmholtz equations", "authors": ["Luiz Maltez Faria", "Pierre Marchand", "Hadrien Montanelli"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13955v1", "summary": "We establish improved convergence rates for curved boundary element methods\napplied to the three-dimensional (3D) Laplace and Helmholtz equations with\nsmooth geometry and data. Our analysis relies on a precise analysis of the\nconsistency errors introduced by the perturbed bilinear and sesquilinear forms.\nWe illustrate our results with numerical experiments in 3D based on basis\nfunctions and curved triangular elements up to order four.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13955v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.18167", "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors", "authors": ["Constantin Venhoff", "Iván Arcuschin", "Philip Torr", "Arthur Conmy", "Neel Nanda"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18167v3", "summary": "Recent advances in large language models (LLMs) have led to the development\nof thinking language models that generate extensive internal reasoning chains\nbefore producing responses. While these models achieve improved performance,\ncontrolling their reasoning processes remains challenging. This work presents a\nsteering approach for thinking LLMs by analyzing and manipulating specific\nreasoning behaviors in DeepSeek-R1-Distill models. Through a systematic\nexperiment on 500 tasks across 10 diverse categories, we identify several\nreasoning behaviors exhibited by thinking models, including expressing\nuncertainty, generating examples for hypothesis validation, and backtracking in\nreasoning chains. We demonstrate that these behaviors are mediated by linear\ndirections in the model's activation space and can be controlled using steering\nvectors. By extracting and applying these vectors, we provide a method to\nmodulate specific aspects of the model's reasoning process, such as its\ntendency to backtrack or express uncertainty. Our approach offers practical\ntools for steering reasoning processes in thinking models in a controlled and\ninterpretable manner. We validate our steering method using three\nDeepSeek-R1-Distill models, demonstrating consistent control across different\nmodel architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18167v3", "cate": "cs.LG", "date": "2025-06-22", "updated": "2025-07-17"}
{"id": "2505.20839", "title": "FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration", "authors": ["Daehyeon Baek", "Jieun Choi", "Jimyoung Son", "Kyungmin Bin", "Seungbeom Choi", "Kihyo Moon", "Minsung Jang", "Hyojung Lee"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20839v3", "summary": "As large language models become increasingly prevalent, memory bandwidth\nconstraints significantly limit inference throughput, motivating post-training\nquantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ\nframework and an INT4-FP8 matrix multiplication kernel that accelerates LLM\ninference across all linear layers. Specifically, FireQ quantizes linear layer\nweights and key-values to INT4, and activations and queries to FP8,\nsignificantly enhancing throughput. Additionally, we introduce a three-stage\npipelining for the prefill phase, which modifies the FlashAttention-3 kernel,\neffectively reducing time-to-first-token in the prefill phase. To minimize\naccuracy loss from quantization, we develop novel outlier smoothing techniques\ntailored separately for linear and attention layers. In linear layers, we\nexplicitly use per-tensor scaling to prevent underflow caused by the FP8\nquantization scaling factor of INT4 quantization, and channel-wise scaling to\ncompensate for coarse granularity of INT4. In attention layers, we address\nquantization challenges posed by rotary positional embeddings (RoPE) by\ncombining pre-RoPE and post-RoPE scaling strategies. FireQ significantly\noutperforms state-of-the-art methods, achieving 1.68x faster inference in\nfeed-forward network layers on Llama2-7B and 1.26x faster prefill phase\nperformance on Llama3-8B compared to QServe, with negligible accuracy loss.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20839v3", "cate": "cs.LG", "date": "2025-05-27", "updated": "2025-07-18"}
{"id": "2506.17562", "title": "LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning", "authors": ["Haoxuan Che", "Haibo Jin", "Zhengrui Guo", "Yi Lin", "Cheng Jin", "Hao Chen"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TMI", "url": "http://arxiv.org/abs/2506.17562v2", "summary": "LLMs have demonstrated significant potential in Medical Report Generation\n(MRG), yet their development requires large amounts of medical image-report\npairs, which are commonly scattered across multiple centers. Centralizing these\ndata is exceptionally challenging due to privacy regulations, thereby impeding\nmodel development and broader adoption of LLM-driven MRG models. To address\nthis challenge, we present FedMRG, the first framework that leverages Federated\nLearning (FL) to enable privacy-preserving, multi-center development of\nLLM-driven MRG models, specifically designed to overcome the critical challenge\nof communication-efficient LLM training under multi-modal data heterogeneity.\nTo start with, our framework tackles the fundamental challenge of communication\noverhead in FL-LLM tuning by employing low-rank factorization to efficiently\ndecompose parameter updates, significantly reducing gradient transmission costs\nand making LLM-driven MRG feasible in bandwidth-constrained FL settings.\nFurthermore, we observed the dual heterogeneity in MRG under the FL scenario:\nvarying image characteristics across medical centers, as well as diverse\nreporting styles and terminology preferences. To address this, we further\nenhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,\ncoupled with diagnosis-driven prompts, which capture both globally\ngeneralizable and locally distinctive features while maintaining diagnostic\naccuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder\nthat harmonizes generic and specialized adapters to address variations in\nreporting styles and terminology. Through extensive evaluation of our\nestablished FL-MRG benchmark, we demonstrate the generalizability and\nadaptability of FedMRG, underscoring its potential in harnessing multi-center\ndata and generating clinically accurate reports while maintaining communication\nefficiency.", "comment": "Accepted by IEEE TMI", "pdf_url": "http://arxiv.org/pdf/2506.17562v2", "cate": "cs.CV", "date": "2025-06-21", "updated": "2025-07-18"}
{"id": "2506.24068", "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines", "authors": ["Ian R. McKenzie", "Oskar J. Hollinsworth", "Tom Tseng", "Xander Davies", "Stephen Casper", "Aaron D. Tucker", "Robert Kirk", "Adam Gleave"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Fixed typos (including Figure 1), amended GPU-hours rather than days, clarified ReNeLLM prompt modifications", "url": "http://arxiv.org/abs/2506.24068v2", "summary": "Frontier AI developers are relying on layers of safeguards to protect against\ncatastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus\nmodel using one such defense pipeline, and other frontier developers including\nGoogle DeepMind and OpenAI pledge to soon deploy similar defenses. However, the\nsecurity of such pipelines is unclear, with limited prior work evaluating or\nattacking these pipelines. We address this gap by developing and red-teaming an\nopen-source defense pipeline. First, we find that a novel few-shot-prompted\ninput and output classifier outperforms state-of-the-art open-weight safeguard\nmodel ShieldGemma across three attacks and two datasets, reducing the attack\nsuccess rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,\nwe introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on\nClearHarm in a black-box attack against the few-shot-prompted classifier\npipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%\nASR, providing initial evidence that it is feasible to design attacks with no\naccess to the target pipeline. We conclude by suggesting specific mitigations\nthat developers could use to thwart staged attacks.", "comment": "Fixed typos (including Figure 1), amended GPU-hours rather than days,\n  clarified ReNeLLM prompt modifications", "pdf_url": "http://arxiv.org/pdf/2506.24068v2", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-18"}
{"id": "2507.10739", "title": "Quantum Wave Atom Transforms", "authors": ["Marianna Podzorova", "Yi-Kai Liu"], "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      45 pages, 12 figures", "url": "http://arxiv.org/abs/2507.10739v1", "summary": "This paper constructs the first quantum algorithm for wavelet packet\ntransforms with a tree structure, sometimes called wave atom transforms.\nClassically, wave atoms are used to construct sparse representations of\ndifferential operators, which enable fast numerical algorithms for partial\ndifferential equations. Compared to previous work, our quantum algorithm can\nimplement a larger class of wavelet and wave atom transforms, by using an\nefficient representation for a larger class of possible tree structures. Our\nquantum implementation has $O(\\mathrm{poly}(n))$ gate complexity for the\ntransform of dimension $2^n$, while classical implementations have $O(n 2^n)$\nfloating point operations. The result can be used to improve existing quantum\nalgorithms for solving hyperbolic partial differential equations.", "comment": "45 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.10739v1", "cate": "quant-ph", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2506.23491", "title": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "authors": ["ZongHan Hsieh", "Tzer-Jen Wei", "ShengJing Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23491v3", "summary": "In this paper, we present ZonUI-3B, a lightweight Vision-Language Model (VLM)\nthat can be fully trained on a single consumer-grade GPU (RTX 4090) while\ndelivering performance comparable to significantly larger models on GUI\ngrounding tasks. The model incorporates several key innovations: (i) combine\ncross-platform, multi-resolution dataset of 24K examples from diverse sources\nincluding mobile, desktop, and web GUI screenshots to effectively address data\nscarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning\nstrategy, where initial cross-platform training establishes robust GUI\nunderstanding, followed by specialized fine-tuning on high-resolution data to\nsignificantly enhance model adaptability; and (iii) data curation and\nredundancy reduction strategies, demonstrating that randomly sampling a smaller\nsubset with reduced redundancy achieves performance comparable to larger\ndatasets, emphasizing data diversity over sheer volume. Empirical evaluation on\nstandard GUI grounding benchmarks, including ScreenSpot, ScreenSpot-v2, and the\nchallenging ScreenSpot-Pro, highlights ZonUI-3B's exceptional accuracy,\nachieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior\nmodels under 4B parameters. Ablation studies validate the critical role of\nbalanced sampling and two-stage fine-tuning in enhancing robustness,\nparticularly in high-resolution desktop scenarios. The ZonUI-3B is available\nat: https://github.com/Han1018/ZonUI-3B", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23491v3", "cate": "cs.CV", "date": "2025-06-30", "updated": "2025-07-18"}
{"id": "2506.08514", "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training", "authors": ["Jacob Piland", "Chris Sweet", "Adam Czajka"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.08514v2", "summary": "Class Activation Mapping (CAM) and its gradient-based variants (e.g.,\nGradCAM) have become standard tools for explaining Convolutional Neural Network\n(CNN) predictions. However, these approaches typically focus on individual\nlogits, while for neural networks using softmax, the class membership\nprobability estimates depend \\textit{only} on the \\textit{differences} between\nlogits, not on their absolute values. This disconnect leaves standard CAMs\nvulnerable to adversarial manipulation, such as passive fooling, where a model\nis trained to produce misleading CAMs without affecting decision performance.\nWe introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an\n\\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM\nrobustness under adversarial conditions. To address the passive fooling\nvulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and\ncontrastive approach to class activation mapping that is both non-suceptible to\npassive fooling, but also matches the output of standard CAM methods such as\nGradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a\nnew framework for probing and improving the robustness of saliency-based\nexplanations. We validate both contributions across multi-class tasks with few\nand many classes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.08514v2", "cate": "cs.LG", "date": "2025-06-10", "updated": "2025-07-18"}
{"id": "2506.19838", "title": "SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution", "authors": ["Liangbin Xie", "Yu Li", "Shian Du", "Menghan Xia", "Xintao Wang", "Fanghua Yu", "Ziyan Chen", "Pengfei Wan", "Jiantao Zhou", "Chao Dong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project webpage available at this https URL", "url": "http://arxiv.org/abs/2506.19838v2", "summary": "Latent diffusion models have emerged as a leading paradigm for efficient\nvideo generation. However, as user expectations shift toward higher-resolution\noutputs, relying solely on latent computation becomes inadequate. A promising\napproach involves decoupling the process into two stages: semantic content\ngeneration and detail synthesis. The former employs a computationally intensive\nbase model at lower resolutions, while the latter leverages a lightweight\ncascaded video super-resolution (VSR) model to achieve high-resolution output.\nIn this work, we focus on studying key design principles for latter cascaded\nVSR models, which are underexplored currently. First, we propose two\ndegradation strategies to generate training pairs that better mimic the output\ncharacteristics of the base model, ensuring alignment between the VSR model and\nits upstream generator. Second, we provide critical insights into VSR model\nbehavior through systematic analysis of (1) timestep sampling strategies, (2)\nnoise augmentation effects on low-resolution (LR) inputs. These findings\ndirectly inform our architectural and training innovations. Finally, we\nintroduce interleaving temporal unit and sparse local attention to achieve\nefficient training and inference, drastically reducing computational overhead.\nExtensive experiments demonstrate the superiority of our framework over\nexisting methods, with ablation studies confirming the efficacy of each design\nchoice. Our work establishes a simple yet effective baseline for cascaded video\nsuper-resolution generation, offering practical insights to guide future\nadvancements in efficient cascaded synthesis systems.", "comment": "Project webpage available at https://simplegvr.github.io/", "pdf_url": "http://arxiv.org/pdf/2506.19838v2", "cate": "cs.CV", "date": "2025-06-24", "updated": "2025-07-18"}
{"id": "2507.06229", "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving", "authors": ["Xiangru Tang", "Tianrui Qin", "Tianhao Peng", "Ziyang Zhou", "Daniel Shao", "Tingting Du", "Xinming Wei", "Peng Xia", "Fang Wu", "He Zhu", "Ge Zhang", "Jiaheng Liu", "Xingyao Wang", "Sirui Hong", "Chenglin Wu", "Hao Cheng", "Chi Wang", "Wangchunshu Zhou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06229v3", "summary": "Current AI agents cannot effectively learn from each other's problem-solving\nexperiences or use past successes to guide self-reflection and error correction\nin new tasks. We introduce Agent KB, a shared knowledge base that captures both\nhigh-level problem-solving strategies and detailed execution lessons, enabling\nknowledge transfer across agent frameworks. Agent KB implements a novel\nteacher-student dual-phase retrieval mechanism where student agents retrieve\nworkflow-level patterns for strategic guidance while teacher agents identify\nexecution-level patterns for refinement. This hierarchical approach enables\nagents to break out of limited reasoning pathways by incorporating diverse\nstrategies from external sources. Evaluations on the GAIA benchmark demonstrate\nsubstantial performance gains, with Agent KB improving success rates by up to\n6.06 percentage points overall under pass@1. For SWE-bench code repair tasks,\nour system significantly improved resolution rates, with o3-mini achieving an\n8.67 percentage point gain (23 percent to 31.67 percent) in pass@1.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06229v3", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-17"}
{"id": "2507.13475", "title": "Expansive Natural Neural Gradient Flows for Energy Minimization", "authors": ["Wolfgang Dahmen", "Wuchen Li", "Yuankai Teng", "Zhu Wang"], "categories": ["math.OC", "cs.NA", "math.NA", "65K10, 68T07"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      40 pages, 19 figures", "url": "http://arxiv.org/abs/2507.13475v1", "summary": "This paper develops expansive gradient dynamics in deep neural\nnetwork-induced mapping spaces. Specifically, we generate tools and concepts\nfor minimizing a class of energy functionals in an abstract Hilbert space\nsetting covering a wide scope of applications such as PDEs-based inverse\nproblems and supervised learning. The approach hinges on a Hilbert space metric\nin the full diffeomorphism mapping space, which could be viewed as a\ngeneralized Wasserstein-2 metric. We then study a projection gradient descent\nmethod within deep neural network parameterized sets. More importantly, we\ndevelop an adaptation and expanding strategy to step-by-step enlarge the deep\nneural network structures. In particular, the expansion mechanism aims to\nenhance the alignment of the neural manifold induced natural gradient direction\nas well as possible with the ideal Hilbert space gradient descent direction\nleveraging the fact that we can evaluate projections of the Hilbert space\ngradient. We demonstrate the efficacy of the proposed strategy for several\nsimple model problems for energies arising in the context of supervised\nlearning, model reduction, or inverse problems. In particular, we highlight the\nimportance of assembling the neural flow matrix based on the inner product for\nthe ambient Hilbert space. The actual algorithms are the simplest\nspecifications of a broader spectrum based on a correspondingly wider\ndiscussion, postponing a detailed analysis to forthcoming work.", "comment": "40 pages, 19 figures", "pdf_url": "http://arxiv.org/pdf/2507.13475v1", "cate": "math.OC", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.08924", "title": "From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation", "authors": ["Seokhee Hong", "Sunkyoung Kim", "Guijin Son", "Soyeon Kim", "Yeonjung Hong", "Jinsik Lee"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08924v2", "summary": "The development of Large Language Models (LLMs) requires robust benchmarks\nthat encompass not only academic domains but also industrial fields to\neffectively evaluate their applicability in real-world scenarios. In this\npaper, we introduce two Korean expert-level benchmarks. KMMLU-Redux,\nreconstructed from the existing KMMLU, consists of questions from the Korean\nNational Technical Qualification exams, with critical errors removed to enhance\nreliability. KMMLU-Pro is based on Korean National Professional Licensure exams\nto reflect professional knowledge in Korea. Our experiments demonstrate that\nthese benchmarks comprehensively represent industrial knowledge in Korea. We\nrelease our dataset publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08924v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-18"}
{"id": "2506.12764", "title": "Base3: a simple interpolation-based ensemble method for robust dynamic link prediction", "authors": ["Kondrup Emma"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2506.12764v2", "summary": "Dynamic link prediction remains a central challenge in temporal graph\nlearning, particularly in designing models that are both effective and\npractical for real-world deployment. Existing approaches often rely on complex\nneural architectures, which are computationally intensive and difficult to\ninterpret.\n  In this work, we build on the strong recurrence-based foundation of the\nEdgeBank baseline, by supplementing it with inductive capabilities. We do so by\nleveraging the predictive power of non-learnable signals from two complementary\nperspectives: historical edge recurrence, as captured by EdgeBank, and global\nnode popularity, as introduced in the PopTrack model. We propose t-CoMem, a\nlightweight memory module that tracks temporal co-occurrence patterns and\nneighborhood activity. Building on this, we introduce Base3, an\ninterpolation-based model that fuses EdgeBank, PopTrack, and t-CoMem into a\nunified scoring framework. This combination effectively bridges local and\nglobal temporal dynamics -- repetition, popularity, and context -- without\nrelying on training. Evaluated on the Temporal Graph Benchmark, Base3 achieves\nperformance competitive with state-of-the-art deep models, even outperforming\nthem on some datasets. Importantly, it considerably improves on existing\nbaselines' performance under more realistic and challenging negative sampling\nstrategies -- offering a simple yet robust alternative for temporal graph\nlearning.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2506.12764v2", "cate": "cs.LG", "date": "2025-06-15", "updated": "2025-07-17"}
{"id": "2507.03532", "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping", "authors": ["Jannik Franzen", "Fabian H. Reith", "Claudia Winklmayr", "Jerome Luescher", "Nora Koreuber", "Elias Baumann", "Christian M. Schuerch", "Dagmar Kainmueller", "Josef Lorenz Rumberger"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for presentation at MICCAI 2025", "url": "http://arxiv.org/abs/2507.03532v4", "summary": "Digital pathology has seen the advent of a wealth of foundational models\n(FM), yet to date their performance on cell phenotyping has not been\nbenchmarked in a unified manner. We therefore propose PhenoBench: A\ncomprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E)\nstained histopathology images. We provide both PhenoCell, a new H&E dataset\nfeaturing 14 granular cell types identified by using multiplexed imaging, and\nready-to-use fine-tuning and benchmarking code that allows the systematic\nevaluation of multiple prominent pathology FMs in terms of dense cell phenotype\npredictions in different generalization scenarios. We perform extensive\nbenchmarking of existing FMs, providing insights into their generalization\nbehavior under technical vs. medical domain shifts. Furthermore, while FMs\nachieve macro F1 scores > 0.70 on previously established benchmarks such as\nLizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This\nindicates a much more challenging task not captured by previous benchmarks,\nestablishing PhenoCell as a prime asset for future benchmarking of FMs and\nsupervised models alike. Code and data are available on GitHub.", "comment": "accepted for presentation at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.03532v4", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-18"}
{"id": "2507.12547", "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models", "authors": ["Lionel Wong", "Katherine M. Collins", "Lance Ying", "Cedegao E. Zhang", "Adrian Weller", "Tobias Gerstenberg", "Timothy O'Donnell", "Alexander K. Lew", "Jacob D. Andreas", "Joshua B. Tenenbaum", "Tyler Brooke-Wilson"], "categories": ["cs.CL", "cs.AI", "cs.PL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Presented at CogSci 2025", "url": "http://arxiv.org/abs/2507.12547v2", "summary": "When faced with novel situations, people are able to marshal relevant\nconsiderations from a wide range of background knowledge and put these to use\nin inferences and predictions. What permits us to draw in globally relevant\ninformation and reason over it coherently? Here, we explore the hypothesis that\npeople use a combination of distributed and symbolic representations to\nconstruct bespoke mental models tailored to novel situations. We propose a\ncomputational implementation of this idea -- a ``Model Synthesis Architecture''\n(MSA) -- using language models to implement global relevance-based retrieval\nand model synthesis and probabilistic programs to implement bespoke, coherent\nworld models. We evaluate our MSA as a model of human judgments on a novel\nreasoning dataset. The dataset -- built around a `Model Olympics` domain of\nsports vignettes -- tests models' capacity for human-like, open-ended reasoning\nby requiring (i) judgments about novel causal structures described in language;\n(ii) drawing on large bodies of background knowledge; and (iii) doing both in\nlight of observations that introduce arbitrary novel variables. Our MSA\napproach captures human judgments better than language model-only baselines,\nunder both direct and chain-of-thought generations from the LM that supports\nmodel synthesis. These results suggest that MSAs can be implemented in a way\nthat mirrors people's ability to deliver locally coherent reasoning over\nglobally relevant variables, offering a path to understanding and replicating\nhuman reasoning in open-ended domains.", "comment": "Presented at CogSci 2025", "pdf_url": "http://arxiv.org/pdf/2507.12547v2", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.13492", "title": "On the time integration for phase field modeling of grain growth in additive manufacturing", "authors": ["Chaoqian Yuan", "Chinnapat Panwisawas", "Ye Lu"], "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13492v1", "summary": "Phase field simulations play a key role in the understanding of\nmicrostructure evolution in additive manufacturing. However, they have been\nfound extremely computationally expensive. One of the reasons is the small time\nstep requirement to resolve the complex microstructure evolution during the\nrapid solidification process. This paper investigates the possibility of using\na class of stabilized time integration algorithms to accelerate such phase\nfield simulations by increasing the time steps. The specific time integration\nformulation and theoretical analysis on energy stability were developed, based\non a phase field model dedicated to simulating rapid solidification in additive\nmanufacturing. The numerical results confirmed that the proposed method can\nensure the numerical stability and a decreasing energy requirement for the\nphase field simulations with at least two orders-of-magnitude larger time steps\nover conventional explicit methods. 2D and 3D phase field simulations have been\nconducted with relevant physical and kinetic parameters for 316L stainless\nsteels. This work provides a numerical framework for efficient phase field\nsimulations and open numerous opportunities for large scale phase field\nmodeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13492v1", "cate": "physics.comp-ph", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.10637", "title": "A Simple Baseline for Stable and Plastic Neural Networks", "authors": ["Étienne Künzel", "Achref Jaziri", "Visvanathan Ramesh"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 50 figures", "url": "http://arxiv.org/abs/2507.10637v2", "summary": "Continual learning in computer vision requires that models adapt to a\ncontinuous stream of tasks without forgetting prior knowledge, yet existing\napproaches often tip the balance heavily toward either plasticity or stability.\nWe introduce RDBP, a simple, low-overhead baseline that unites two\ncomplementary mechanisms: ReLUDown, a lightweight activation modification that\npreserves feature sensitivity while preventing neuron dormancy, and Decreasing\nBackpropagation, a biologically inspired gradient-scheduling scheme that\nprogressively shields early layers from catastrophic updates. Evaluated on the\nContinual ImageNet benchmark, RDBP matches or exceeds the plasticity and\nstability of state-of-the-art methods while reducing computational cost. RDBP\nthus provides both a practical solution for real-world continual learning and a\nclear benchmark against which future continual learning strategies can be\nmeasured.", "comment": "11 pages, 50 figures", "pdf_url": "http://arxiv.org/pdf/2507.10637v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-18"}
{"id": "2506.13107", "title": "Honesty in Causal Forests: When It Helps and When It Hurts", "authors": ["Yanfang Hou", "Carlos Fernández-Loría"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13107v2", "summary": "Causal forests estimate how treatment effects vary across individuals,\nguiding personalized interventions in areas like marketing, operations, and\npublic policy. A standard modeling practice with this method is honest\nestimation: dividing the data so that the subgroups used to model treatment\neffect variation are formed separately from the data used to estimate those\neffects. This is intended to reduce overfitting and is the default in many\nsoftware packages. But is it always the right choice? In this paper, we show\nthat honest estimation can reduce the accuracy of individual-level treatment\neffect estimates, especially when there are substantial differences in how\nindividuals respond to treatment, and the data is rich enough to uncover those\ndifferences. The core issue is a classic bias-variance trade-off: honesty\nlowers the risk of overfitting but increases the risk of underfitting, because\nit limits the data available to detect patterns. Across 7,500 benchmark\ndatasets, we find that the cost of using honesty by default can be as high as\nrequiring 75% more data to match the performance of models trained without it.\nWe argue that honesty is best understood as a form of regularization, and like\nany regularization choice, its use should be guided by out-of-sample\nperformance, not adopted reflexively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13107v2", "cate": "cs.LG", "date": "2025-06-16", "updated": "2025-07-18"}
{"id": "2507.05887", "title": "GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing", "authors": ["Xianzhi Ma", "Jianhui Li", "Changhua Pei", "Hao Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05887v2", "summary": "The application of Vision-Language Models (VLMs) in remote sensing (RS) image\nunderstanding has achieved notable progress, demonstrating the basic ability to\nrecognize and describe geographical entities. However, existing RS-VLMs are\nmostly limited to image-level and region-level tasks, lacking the capability to\nhandle pixel-level tasks and performing poorly in small-object recognition\nscenarios. Moreover, RS-VLMs consume significant computational resources when\nprocessing high-resolution RS images, further restricting their practical\napplicability. In this context, we propose GeoMag (Geographical Magnifier), an\nend-to-end general-purpose large model framework for RS. GeoMag dynamically\nfocuses the attention scope based on prompt semantics to effectively perform\nremote sensing image parsing across multiple levels of granularity. This method\nintroduces Task-driven Multi-granularity Resolution Adjustment (TMRA) and\nPrompt-guided Semantic-aware Cropping (PSC), which adaptively reduce the\nspatial resolution of task-irrelevant regions while enhancing the visual\nrepresentation of task-relevant areas. This approach improves the model's\nperception of critical target regions, suppresses background redundancy, and\nreduces the computational cost of interpreting high-resolution RS imagery.\nExtensive comparative experiments on 10 benchmarks demonstrate that GeoMag not\nonly excels in handling pixel-level tasks but also maintains competitive\nperformance across tasks of other granularities compared to existing RS-VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05887v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-18"}
{"id": "2507.13804", "title": "Gradient descent avoids strict saddles with a simple line-search method too", "authors": ["Andreea-Alexandra Muşat", "Nicolas Boumal"], "categories": ["math.OC", "cs.NA", "math.DS", "math.NA", "90C30 (Primary) 65K05, 37C75, 58K05 (Secondary)"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      38 pages", "url": "http://arxiv.org/abs/2507.13804v1", "summary": "It is known that gradient descent (GD) on a $C^2$ cost function generically\navoids strict saddle points when using a small, constant step size. However, no\nsuch guarantee existed for GD with a line-search method. We provide one for a\nmodified version of the standard Armijo backtracking method with generic,\narbitrarily large initial step size. In contrast to previous works, our\nanalysis does not require a globally Lipschitz gradient.\n  We extend this to the Riemannian setting (RGD), assuming the retraction is\nreal analytic (though the cost function still only needs to be $C^2$). In\nclosing, we also improve guarantees for RGD with a constant step size in some\nscenarios.", "comment": "38 pages", "pdf_url": "http://arxiv.org/pdf/2507.13804v1", "cate": "math.OC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.11554", "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models", "authors": ["Zejian Li", "Yize Li", "Chenye Meng", "Zhongni Liu", "Yang Ling", "Shengyuan Zhang", "Guang Yang", "Changyuan Yang", "Zhiyuan Yang", "Lingyun Sun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11554v2", "summary": "Recent advancements in diffusion models (DMs) have been propelled by\nalignment methods that post-train models to better conform to human\npreferences. However, these approaches typically require computation-intensive\ntraining of a base model and a reward model, which not only incurs substantial\ncomputational overhead but may also compromise model accuracy and training\nefficiency. To address these limitations, we propose Inversion-DPO, a novel\nalignment framework that circumvents reward modeling by reformulating Direct\nPreference Optimization (DPO) with DDIM inversion for DMs. Our method conducts\nintractable posterior sampling in Diffusion-DPO with the deterministic\ninversion from winning and losing samples to noise and thus derive a new\npost-training paradigm. This paradigm eliminates the need for auxiliary reward\nmodels or inaccurate appromixation, significantly enhancing both precision and\nefficiency of training. We apply Inversion-DPO to a basic task of text-to-image\ngeneration and a challenging task of compositional image generation. Extensive\nexperiments show substantial performance improvements achieved by Inversion-DPO\ncompared to existing post-training methods and highlight the ability of the\ntrained generative models to generate high-fidelity compositionally coherent\nimages. For the post-training of compostitional image geneation, we curate a\npaired dataset consisting of 11,140 images with complex structural annotations\nand comprehensive scores, designed to enhance the compositional capabilities of\ngenerative models. Inversion-DPO explores a new avenue for efficient,\nhigh-precision alignment in diffusion models, advancing their applicability to\ncomplex realistic generation tasks. Our code is available at\nhttps://github.com/MIGHTYEZ/Inversion-DPO", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11554v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-18"}
{"id": "2506.13196", "title": "KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction", "authors": ["Han Liu", "Keyan Ding", "Peilin Chen", "Yinwei Wei", "Liqiang Nie", "Dapeng Wu", "Shiqi Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13196v3", "summary": "Accurate prediction of protein-ligand binding affinity is critical for drug\ndiscovery. While recent deep learning approaches have demonstrated promising\nresults, they often rely solely on structural features of proteins and ligands,\noverlooking their valuable biochemical knowledge associated with binding\naffinity. To address this limitation, we propose KEPLA, a novel deep learning\nframework that explicitly integrates prior knowledge from Gene Ontology and\nligand properties to enhance prediction performance. KEPLA takes protein\nsequences and ligand molecular graphs as input and optimizes two complementary\nobjectives: (1) aligning global representations with knowledge graph relations\nto capture domain-specific biochemical insights, and (2) leveraging cross\nattention between local representations to construct fine-grained joint\nembeddings for prediction. Experiments on two benchmark datasets across both\nin-domain and cross-domain scenarios demonstrate that KEPLA consistently\noutperforms state-of-the-art baselines. Furthermore, interpretability analyses\nbased on knowledge graph relations and cross attention maps provide valuable\ninsights into the underlying predictive mechanisms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13196v3", "cate": "cs.LG", "date": "2025-06-16", "updated": "2025-07-18"}
{"id": "2507.06411", "title": "Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization", "authors": ["Hayat Ullah", "Arslan Munir", "Oliver Nina"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 6 figures,", "url": "http://arxiv.org/abs/2507.06411v2", "summary": "Inspired by the recent success of transformers and multi-stage architectures\nin video recognition and object detection domains. We thoroughly explore the\nrich spatio-temporal properties of transformers within a multi-stage\narchitecture paradigm for the temporal action localization (TAL) task. This\nexploration led to the development of a hierarchical multi-stage transformer\narchitecture called PCL-Former, where each subtask is handled by a dedicated\ntransformer module with a specialized loss function. Specifically, the\nProposal-Former identifies candidate segments in an untrimmed video that may\ncontain actions, the Classification-Former classifies the action categories\nwithin those segments, and the Localization-Former precisely predicts the\ntemporal boundaries (i.e., start and end) of the action instances. To evaluate\nthe performance of our method, we have conducted extensive experiments on three\nchallenging benchmark datasets: THUMOS-14, ActivityNet-1.3, and HACS Segments.\nWe also conducted detailed ablation experiments to assess the impact of each\nindividual module of our PCL-Former. The obtained quantitative results validate\nthe effectiveness of the proposed PCL-Former, outperforming state-of-the-art\nTAL approaches by 2.8%, 1.2%, and 4.8% on THUMOS14, ActivityNet-1.3, and HACS\ndatasets, respectively.", "comment": "17 pages, 6 figures,", "pdf_url": "http://arxiv.org/pdf/2507.06411v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-18"}
{"id": "1910.09297", "title": "Two efficient block preconditioners for the mass-conserved Ohta-Kawasaki equation", "authors": ["Juan Zhang", "Shifeng Li", "Kai Jiang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      28 pages, 9 figures", "url": "http://arxiv.org/abs/1910.09297v3", "summary": "In this paper, we propose two efficient block preconditioners to solve the\nmass-conserved Ohta-Kawasaki equation with finite element discretization. We\nalso study the spectral distribution of these two preconditioners,\n\\textit{i.e.,} Schur complement preconditioner and the modified Hermitian and\nskew-Hermitian splitting (MHSS in short) preconditioner. Besides, Newton method\nand Picard method are used to address the implicitly nonlinear term. We\nrigorously analyze the convergence of Newton method. Finally, we offer\nnumerical examples to support the theoretical analysis and indicate the\nefficiency of the proposed preconditioners for the mass-conserved Ohta-Kawasaki\nequation.", "comment": "28 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/1910.09297v3", "cate": "math.NA", "date": "2019-10-21", "updated": "2025-07-18"}
{"id": "2507.12964", "title": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": ["Ammar Ahmed", "Ali Shariq Imran", "Zenun Kastrati", "Sher Muhammad Daudpota"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12964v2", "summary": "Wrist pathologies are frequently observed, particularly among children who\nconstitute the majority of fracture cases. However, diagnosing these conditions\nis time-consuming and requires specialized expertise. Computer vision presents\na promising avenue, contingent upon the availability of extensive datasets, a\nnotable challenge in medical imaging. Therefore, reliance solely on one\nmodality, such as images, proves inadequate, especially in an era of diverse\nand plentiful data types. In this study, we employ a multifaceted approach to\naddress the challenge of recognizing wrist pathologies using an extremely\nlimited dataset. Initially, we approach the problem as a fine-grained\nrecognition task, aiming to identify subtle X-ray pathologies that conventional\nCNNs overlook. Secondly, we enhance network performance by fusing patient\nmetadata with X-ray images. Thirdly, rather than pre-training on a\ncoarse-grained dataset like ImageNet, we utilize weights trained on a\nfine-grained dataset. While metadata integration has been used in other medical\ndomains, this is a novel application for wrist pathologies. Our results show\nthat a fine-grained strategy and metadata integration improve diagnostic\naccuracy by 2% with a limited dataset and by over 10% with a larger\nfracture-focused dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12964v2", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2506.19805", "title": "Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective", "authors": ["Chenhao Si", "Ming Yan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 12 figures", "url": "http://arxiv.org/abs/2506.19805v2", "summary": "Physics-informed neural networks (PINNs) are extensively employed to solve\npartial differential equations (PDEs) by ensuring that the outputs and\ngradients of deep learning models adhere to the governing equations. However,\nconstrained by computational limitations, PINNs are typically optimized using a\nfinite set of points, which poses significant challenges in guaranteeing their\nconvergence and accuracy. In this study, we proposed a new weighting scheme\nthat will adaptively change the weights to the loss functions from isolated\npoints to their continuous neighborhood regions. The empirical results show\nthat our weighting scheme can reduce the relative $L^2$ errors to a lower\nvalue.", "comment": "18 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2506.19805v2", "cate": "cs.LG", "date": "2025-06-24", "updated": "2025-07-18"}
{"id": "2507.07722", "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays", "authors": ["Ethan Dack", "Chengliang Dai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07722v4", "summary": "Recent works have revisited the infamous task ``Name That Dataset'',\ndemonstrating that non-medical datasets contain underlying biases and that the\ndataset origin task can be solved with high accuracy. In this work, we revisit\nthe same task applied to popular open-source chest X-ray datasets. Medical\nimages are naturally more difficult to release for open-source due to their\nsensitive nature, which has led to certain open-source datasets being extremely\npopular for research purposes. By performing the same task, we wish to explore\nwhether dataset bias also exists in these datasets. To extend our work, we\napply simple transformations to the datasets, repeat the same task, and perform\nan analysis to identify and explain any detected biases. Given the importance\nof AI applications in medical imaging, it's vital to establish whether modern\nmethods are taking shortcuts or are focused on the relevant pathology. We\nimplement a range of different network architectures on the datasets: NIH,\nCheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more\nexplainable research being performed in medical imaging and the creation of\nmore open-source datasets in the medical domain. Our code can be found here:\nhttps://github.com/eedack01/x_ray_ds_bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07722v4", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-18"}
{"id": "2310.15457", "title": "An Iteratively Decoupled Algorithm for Multiple-Network Poroelastic Model with Applications in Brain Edema Simulations", "authors": ["Mingchao Cai", "Meng Lei", "Jingzhi Li", "Jiaao Sun", "Feng Wang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      to be submitted, replacing the older version", "url": "http://arxiv.org/abs/2310.15457v4", "summary": "In this work, we present an iteratively decoupled algorithm for solving the\nquasi-static multiple-network poroelastic model. Our approach employs a\ntotal-pressure-based formulation with solid displacement, total pressure, and\nnetwork pressures as primary unknowns. This reformulation decomposes the\noriginal problem into a generalized Stokes problem and a parabolic problem,\noffering key advantages such as reduced elastic locking effects and simplified\ndiscretization. The algorithm guarantees unconditional convergence to the\nsolution of the fully coupled system. Numerical experiments demonstrate the\naccuracy, efficiency, and robustness of the method with respect to physical\nparameters and discretization. We further apply the algorithm to simulate the\nbrain edema process, showcasing its practical utility in biomechanical\nmodeling.", "comment": "to be submitted, replacing the older version", "pdf_url": "http://arxiv.org/pdf/2310.15457v4", "cate": "math.NA", "date": "2023-10-24", "updated": "2025-07-18"}
{"id": "2507.13263", "title": "Merge Kernel for Bayesian Optimization on Permutation Space", "authors": ["Zikai Xie", "Linjiang Chen"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, submitted to AAAI-26", "url": "http://arxiv.org/abs/2507.13263v2", "summary": "Bayesian Optimization (BO) algorithm is a standard tool for black-box\noptimization problems. The current state-of-the-art BO approach for permutation\nspaces relies on the Mallows kernel-an $\\Omega(n^2)$ representation that\nexplicitly enumerates every pairwise comparison. Inspired by the close\nrelationship between the Mallows kernel and pairwise comparison, we propose a\nnovel framework for generating kernel functions on permutation space based on\nsorting algorithms. Within this framework, the Mallows kernel can be viewed as\na special instance derived from bubble sort. Further, we introduce the\n\\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic\ncomplexity with $\\Theta(n\\log n)$ to achieve the lowest possible complexity.\nThe resulting feature vector is significantly shorter, can be computed in\nlinearithmic time, yet still efficiently captures meaningful permutation\ndistances. To boost robustness and right-invariance without sacrificing\ncompactness, we further incorporate three lightweight, task-agnostic\ndescriptors: (1) a shift histogram, which aggregates absolute element\ndisplacements and supplies a global misplacement signal; (2) a split-pair line,\nwhich encodes selected long-range comparisons by aligning elements across the\ntwo halves of the whole permutation; and (3) sliding-window motifs, which\nsummarize local order patterns that influence near-neighbor objectives. Our\nempirical evaluation demonstrates that the proposed kernel consistently\noutperforms the state-of-the-art Mallows kernel across various permutation\noptimization benchmarks. Results confirm that the Merge Kernel provides a more\ncompact yet more effective solution for Bayesian optimization in permutation\nspace.", "comment": "8 pages, submitted to AAAI-26", "pdf_url": "http://arxiv.org/pdf/2507.13263v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.03068", "title": "Mitigating Goal Misgeneralization via Minimax Regret", "authors": ["Karim Abdel Sadek", "Matthew Farrugia-Roberts", "Usman Anwar", "Hannah Erlebach", "Christian Schroeder de Witt", "David Krueger", "Michael Dennis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at RLC 2025. 11 pages main text. v2: no changes to PDF, fix arXiv title", "url": "http://arxiv.org/abs/2507.03068v2", "summary": "Safe generalization in reinforcement learning requires not only that a\nlearned policy acts capably in new situations, but also that it uses its\ncapabilities towards the pursuit of the designer's intended goal. The latter\nrequirement may fail when a proxy goal incentivizes similar behavior to the\nintended goal within the training environment, but not in novel deployment\nenvironments. This creates the risk that policies will behave as if in pursuit\nof the proxy goal, rather than the intended goal, in deployment -- a phenomenon\nknown as goal misgeneralization. In this paper, we formalize this problem\nsetting in order to theoretically study the possibility of goal\nmisgeneralization under different training objectives. We show that goal\nmisgeneralization is possible under approximate optimization of the maximum\nexpected value (MEV) objective, but not the minimax expected regret (MMER)\nobjective. We then empirically show that the standard MEV-based training method\nof domain randomization exhibits goal misgeneralization in\nprocedurally-generated grid-world environments, whereas current regret-based\nunsupervised environment design (UED) methods are more robust to goal\nmisgeneralization (though they don't find MMER policies in all cases). Our\nfindings suggest that minimax expected regret is a promising approach to\nmitigating goal misgeneralization.", "comment": "Published at RLC 2025. 11 pages main text. v2: no changes to PDF, fix\n  arXiv title", "pdf_url": "http://arxiv.org/pdf/2507.03068v2", "cate": "cs.LG", "date": "2025-07-03", "updated": "2025-07-18"}
{"id": "2507.11200", "title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study", "authors": ["Che Liu", "Jiazhen Pan", "Weixiang Shen", "Wenjia Bai", "Daniel Rueckert", "Rossella Arcucci"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Technical report", "url": "http://arxiv.org/abs/2507.11200v2", "summary": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural\nimage tasks and are increasingly repurposed for healthcare; however, their\ncompetence in medical tasks remains underexplored. We present a comprehensive\nevaluation of open-source general-purpose and medically specialised VLMs,\nranging from 3B to 72B parameters, across eight benchmarks: MedXpert,\nOmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model\nperformance across different aspects, we first separate it into understanding\nand reasoning components. Three salient findings emerge. First, large\ngeneral-purpose models already match or surpass medical-specific counterparts\non several benchmarks, demonstrating strong zero-shot transfer from natural to\nmedical images. Second, reasoning performance is consistently lower than\nunderstanding, highlighting a critical barrier to safe decision support. Third,\nperformance varies widely across benchmarks, reflecting differences in task\ndesign, annotation quality, and knowledge demands. No model yet reaches the\nreliability threshold for clinical deployment, underscoring the need for\nstronger multimodal alignment and more rigorous, fine-grained evaluation\nprotocols.", "comment": "Technical report", "pdf_url": "http://arxiv.org/pdf/2507.11200v2", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-18"}
{"id": "2501.02183", "title": "Data-Driven Reduced-Order Models for Port-Hamiltonian Systems with Operator Inference", "authors": ["Yuwei Geng", "Lili Ju", "Boris Kramer", "Zhu Wang"], "categories": ["math.NA", "cs.NA", "65P99, 65L70"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      28 pages, 13 figures", "url": "http://arxiv.org/abs/2501.02183v2", "summary": "Hamiltonian operator inference has been developed in [Sharma, H., Wang, Z.,\nKramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn\nstructure-preserving reduced-order models (ROMs) for Hamiltonian systems. The\nmethod constructs a low-dimensional model using only data and knowledge of the\nfunctional form of the Hamiltonian. The resulting ROMs preserve the intrinsic\nstructure of the system, ensuring that the mechanical and physical properties\nof the system are maintained. In this work, we extend this approach to\nport-Hamiltonian systems, which generalize Hamiltonian systems by including\nenergy dissipation, external input, and output. Based on snapshots of the\nsystem's state and output, together with the information about the functional\nform of the Hamiltonian, reduced operators are inferred through optimization\nand are then used to construct data-driven ROMs. To further alleviate the\ncomplexity of evaluating nonlinear terms in the ROMs, a hyper-reduction method\nvia discrete empirical interpolation is applied. Accordingly, we derive error\nestimates for the ROM approximations of the state and output. Finally, we\ndemonstrate the structure preservation, as well as the accuracy of the proposed\nport-Hamiltonian operator inference framework, through numerical experiments on\na linear mass-spring-damper problem and a nonlinear Toda lattice problem.", "comment": "28 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2501.02183v2", "cate": "math.NA", "date": "2025-01-04", "updated": "2025-07-18"}
{"id": "2507.06482", "title": "FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning", "authors": ["Huan Wang", "Haoran Li", "Huaming Chen", "Jun Yan", "Jiahua Shi", "Jun Shen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 Pages, ICCV 2025", "url": "http://arxiv.org/abs/2507.06482v2", "summary": "Federated learning aims at training models collaboratively across\nparticipants while protecting privacy. However, one major challenge for this\nparadigm is the data heterogeneity issue, where biased data preferences across\nmultiple clients, harming the model's convergence and performance. In this\npaper, we first introduce powerful diffusion models into the federated learning\nparadigm and show that diffusion representations are effective steers during\nfederated training. To explore the possibility of using diffusion\nrepresentations in handling data heterogeneity, we propose a novel\ndiffusion-inspired Federated paradigm with Diffusion Representation\nCollaboration, termed FedDifRC, leveraging meaningful guidance of diffusion\nmodels to mitigate data heterogeneity. The key idea is to construct text-driven\ndiffusion contrasting and noise-driven diffusion regularization, aiming to\nprovide abundant class-related semantic information and consistent convergence\nsignals. On the one hand, we exploit the conditional feedback from the\ndiffusion model for different text prompts to build a text-driven contrastive\nlearning strategy. On the other hand, we introduce a noise-driven consistency\nregularization to align local instances with diffusion denoising\nrepresentations, constraining the optimization region in the feature space. In\naddition, FedDifRC can be extended to a self-supervised scheme without relying\non any labeled data. We also provide a theoretical analysis for FedDifRC to\nensure convergence under non-convex objectives. The experiments on different\nscenarios validate the effectiveness of FedDifRC and the efficiency of crucial\ncomponents.", "comment": "11 Pages, ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06482v2", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-18"}
{"id": "2507.12396", "title": "OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments", "authors": ["Hayat Ullah", "Abbas Khan", "Arslan Munir", "Hari Kalva"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.12396v2", "summary": "Realistic human surveillance datasets are crucial for training and evaluating\ncomputer vision models under real-world conditions, facilitating the\ndevelopment of robust algorithms for human and human-interacting object\ndetection in complex environments. These datasets need to offer diverse and\nchallenging data to enable a comprehensive assessment of model performance and\nthe creation of more reliable surveillance systems for public safety. To this\nend, we present two visual object detection benchmarks named OD-VIRAT Large and\nOD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance\nimagery. The video sequences in both benchmarks cover 10 different scenes of\nhuman surveillance recorded from significant height and distance. The proposed\nbenchmarks offer rich annotations of bounding boxes and categories, where\nOD-VIRAT Large has 8.7 million annotated instances in 599,996 images and\nOD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also\nfocuses on benchmarking state-of-the-art object detection architectures,\nincluding RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object\ndetection-specific variant of VIRAT dataset. To the best of our knowledge, it\nis the first work to examine the performance of these recently published\nstate-of-the-art object detection architectures on realistic surveillance\nimagery under challenging conditions such as complex backgrounds, occluded\nobjects, and small-scale objects. The proposed benchmarking and experimental\nsettings will help in providing insights concerning the performance of selected\nobject detection models and set the base for developing more efficient and\nrobust object detection architectures.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.12396v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2502.04589", "title": "PASE: A Massively Parallel Augmented Subspace Eigensolver for Large Scale Eigenvalue Problems", "authors": ["Yangfei Liao", "Haochen Liu", "Hehu Xie", "Zijing Wang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      25pages, 6 figures", "url": "http://arxiv.org/abs/2502.04589v2", "summary": "In this paper, we present a novel parallel augmented subspace method and\nbuild a package Parallel Augmented Subspace Eigensolver (PASE) for solving\nlarge scale eigenvalue problems by the massively parallel finite element\ndiscretization. Based on the augmented subspace, solving high dimensional\neigenvalue problems can be transformed to solving the corresponding linear\nequations and low dimensional eigenvalue problems on the augmented subspace.\nThus the complexity of solving the eigenvalue problems by augmented subspace\nmethod will be comparable to that of solving the same dimensinal linear\nequations. In order to improve the scalability and efficiency, we also present\nsome implementing techniques for the parallel augmented subspace method. Based\non parallel augmented subspace method and the concerned implementing\ntechniques, a package PASE is built for solving large scale eigenvalue\nproblems. Some numerical examples are provided to validate the efficiency and\nscalability of the proposed numerical methods.", "comment": "25pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2502.04589v2", "cate": "math.NA", "date": "2025-02-07", "updated": "2025-07-17"}
{"id": "2507.06602", "title": "Generalization in Reinforcement Learning for Radio Access Networks", "authors": ["Burak Demirel", "Yu Wang", "Cristian Tatino", "Pablo Soldati"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06602v2", "summary": "Modern RAN operate in highly dynamic and heterogeneous environments, where\nhand-tuned, rule-based RRM algorithms often underperform. While RL can surpass\nsuch heuristics in constrained settings, the diversity of deployments and\nunpredictable radio conditions introduce major generalization challenges.\nData-driven policies frequently overfit to training conditions, degrading\nperformance in unseen scenarios. To address this, we propose a\ngeneralization-centered RL framework for RAN control that: (i) robustly\nreconstructs dynamically varying states from partial and noisy observations,\nwhile encoding static and semi-static information, such as radio nodes, cell\nattributes, and their topology, through graph representations; (ii) applies\ndomain randomization to broaden the training distribution; and (iii)\ndistributes data generation across multiple actors while centralizing training\nin a cloud-compatible architecture aligned with O-RAN principles. Although\ngeneralization increases computational and data-management complexity, our\ndistributed design mitigates this by scaling data collection and training\nacross diverse network conditions. Applied to downlink link adaptation in five\n5G benchmarks, our policy improves average throughput and spectral efficiency\nby ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and\nby >20% under high mobility. It matches specialized RL in full-buffer traffic\nand achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks,\nrespectively. In nine-cell deployments, GAT models offer 30% higher throughput\nover MLP baselines. These results, combined with our scalable architecture,\noffer a path toward AI-native 6G RAN using a single, generalizable RL agent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06602v2", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-18"}
{"id": "2507.12426", "title": "DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition", "authors": ["Hayat Ullah", "Muhammad Ali Shafique", "Abbas Khan", "Arslan Munir"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.12426v2", "summary": "The landscape of video recognition has evolved significantly, shifting from\ntraditional Convolutional Neural Networks (CNNs) to Transformer-based\narchitectures for improved accuracy. While 3D CNNs have been effective at\ncapturing spatiotemporal dynamics, recent Transformer models leverage\nself-attention to model long-range spatial and temporal dependencies. Despite\nachieving state-of-the-art performance on major benchmarks, Transformers remain\ncomputationally expensive, particularly with dense video data. To address this,\nwe propose a lightweight Video Focal Modulation Network, DVFL-Net, which\ndistills spatiotemporal knowledge from a large pre-trained teacher into a\ncompact nano student model, enabling efficient on-device deployment. DVFL-Net\nutilizes knowledge distillation and spatial-temporal feature modulation to\nsignificantly reduce computation while preserving high recognition performance.\nWe employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal\nfocal modulation to effectively transfer both local and global context from the\nVideo-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate\nDVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it\nagainst recent state-of-the-art methods in Human Action Recognition (HAR).\nAdditionally, we conduct a detailed ablation study analyzing the impact of\nforward KL divergence. The results confirm the superiority of DVFL-Net in\nachieving an optimal balance between performance and efficiency, demonstrating\nlower memory usage, reduced GFLOPs, and strong accuracy, making it a practical\nsolution for real-time HAR applications.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.12426v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2502.06158", "title": "Efficient numerical method for the Schrödinger equation with high-contrast potentials", "authors": ["Xingguang Jin", "Liu Liu", "Xiang Zhong", "Eric T. Chung"], "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65N30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06158v2", "summary": "In this paper, we study the Schr\\\"{o}dinger equation in the semiclassical\nregime and with multiscale potential function. We develop the so-called\nconstraint energy minimization generalized multiscale finite element method\n(CEM-GMsFEM), in the framework of Crank-Nicolson (CN) discretization in time.\nThe localized multiscale basis functions are constructed by addressing the\nspectral problem and a constrained energy minimization problem related to the\nHamiltonian norm. A first-order convergence in the energy norm and second-order\nconvergence in the $L^2$ norm for our numerical scheme are shown, with a\nrelation between oversampling number in the CEM-GMsFEM method, spatial mesh\nsize and the semiclassical parameter provided. Furthermore, we demonstrate the\nconvergence of the proposed Crank-Nicolson CEM-GMsFEM scheme. The convergence\nrequires $H/\\sqrt{\\Lambda}=O(\\varepsilon^{\\frac{5}{4}})$, $\\Delta\nt=O(\\varepsilon^{\\frac{5}{4}})$ if $\\varepsilon\\leq \\delta$; while if\n$\\delta<\\varepsilon$, the convergence requires\n$H/\\sqrt{\\Lambda}=O(\\varepsilon^{\\frac{1}{4}}\\delta)$, $\\Delta\nt=O(\\frac{\\delta^2}{\\varepsilon^{3/4}})$ (where $H$ represents the maximum\ndiameter of coarse elements, $\\Lambda$ is the minimal eigenvalue associated\nwith the eigenvector not included in the auxiliary space, $\\Delta t$ is the\ntime step, $0 < \\varepsilon\\ll 1$ is the Planck constant and $\\delta$ describes\nthe multiscale structure of the potential).Several numerical examples including\n1D and 2D in space, with high-contrast potential are conducted to demonstrate\nthe efficiency and accuracy of our proposed scheme.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06158v2", "cate": "math.NA", "date": "2025-02-10", "updated": "2025-07-18"}
{"id": "2507.09754", "title": "Explainable AI in Genomics: Transcription Factor Binding Site Prediction with Mixture of Experts", "authors": ["Aakash Tripathi", "Ian E. Nielsen", "Muhammad Umer", "Ravi P. Ramachandran", "Ghulam Rasool"], "categories": ["cs.LG", "q-bio.GN"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09754v2", "summary": "Transcription Factor Binding Site (TFBS) prediction is crucial for\nunderstanding gene regulation and various biological processes. This study\nintroduces a novel Mixture of Experts (MoE) approach for TFBS prediction,\nintegrating multiple pre-trained Convolutional Neural Network (CNN) models,\neach specializing in different TFBS patterns. We evaluate the performance of\nour MoE model against individual expert models on both in-distribution and\nout-of-distribution (OOD) datasets, using six randomly selected transcription\nfactors (TFs) for OOD testing. Our results demonstrate that the MoE model\nachieves competitive or superior performance across diverse TF binding sites,\nparticularly excelling in OOD scenarios. The Analysis of Variance (ANOVA)\nstatistical test confirms the significance of these performance differences.\nAdditionally, we introduce ShiftSmooth, a novel attribution mapping technique\nthat provides more robust model interpretability by considering small shifts in\ninput sequences. Through comprehensive explainability analysis, we show that\nShiftSmooth offers superior attribution for motif discovery and localization\ncompared to traditional Vanilla Gradient methods. Our work presents an\nefficient, generalizable, and interpretable solution for TFBS prediction,\npotentially enabling new discoveries in genome biology and advancing our\nunderstanding of transcriptional regulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09754v2", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-18"}
{"id": "2502.13445", "title": "An Efficient Iterative Decoupling Method for Thermo-Poroelasticity Based on a Four-Field Formulation", "authors": ["Mingchao Cai", "Jingzhi Li", "Ziliang Li", "Qiang Liu"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      submitted to a journal, accepted", "url": "http://arxiv.org/abs/2502.13445v2", "summary": "This paper studies the thermo-poroelasticity model. By introducing an\nintermediate variable, we transform the original three-field model into a\nfour-field model. Building upon this four-field model, we present both a\ncoupled finite element method and a decoupled iterative finite element method.\nWe prove the stability and optimal convergence of the coupled finite element\nmethod. Furthermore, we establish the convergence of the decoupled iterative\nmethod. This paper focuses primarily on analyzing the iterative decoupled\nalgorithm. It demonstrates that the algorithm's convergence does not require\nany additional assumptions about physical parameters or stabilization\nparameters. Numerical results are provided to demonstrate the effectiveness and\ntheoretical validity of these new methods.", "comment": "submitted to a journal, accepted", "pdf_url": "http://arxiv.org/pdf/2502.13445v2", "cate": "math.NA", "date": "2025-02-19", "updated": "2025-07-18"}
{"id": "2507.09958", "title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression", "authors": ["Zhenyuan Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09958v3", "summary": "Inductive bias is a key factor in spatial regression models, determining how\nwell a model can learn from limited data and capture spatial patterns. This\nwork revisits the inductive biases in Geographically Neural Network Weighted\nRegression (GNNWR) and identifies limitations in current approaches for\nmodeling spatial non-stationarity. While GNNWR extends traditional\nGeographically Weighted Regression by using neural networks to learn spatial\nweighting functions, existing implementations are often restricted by fixed\ndistance-based schemes and limited inductive bias. We propose to generalize\nGNNWR by incorporating concepts from convolutional neural networks, recurrent\nneural networks, and transformers, introducing local receptive fields,\nsequential context, and self-attention into spatial regression. Through\nextensive benchmarking on synthetic spatial datasets with varying\nheterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic\nmethods in capturing nonlinear and complex spatial relationships. Our results\nalso reveal that model performance depends strongly on data characteristics,\nwith local models excelling in highly heterogeneous or small-sample scenarios,\nand global models performing better with larger, more homogeneous data. These\nfindings highlight the importance of inductive bias in spatial modeling and\nsuggest future directions, including learnable spatial weighting functions,\nhybrid neural architectures, and improved interpretability for models handling\nnon-stationary spatial data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09958v3", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-18"}
{"id": "2402.13670", "title": "The Riemannian Convex Bundle Method", "authors": ["Ronny Bergmann", "Roland Herzog", "Hajg Jasa"], "categories": ["math.OC", "cs.NA", "math.DG", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.13670v3", "summary": "We introduce the convex bundle method to solve convex, non-smooth\noptimization problems on Riemannian manifolds of bounded sectional curvature.\nEach step of our method is based on a model that involves the convex hull of\npreviously collected subgradients, parallelly transported into the current\nserious iterate. This approach generalizes the dual form of classical bundle\nsubproblems in Euclidean space. We prove that, under mild conditions, the\nconvex bundle method converges to a minimizer. Several numerical examples\nimplemented using Manopt$.$jl illustrate the performance of the proposed method\nand compare it to the subgradient method, the cyclic proximal point algorithm,\nas well as the proximal bundle method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.13670v3", "cate": "math.OC", "date": "2024-02-21", "updated": "2025-07-18"}
{"id": "2507.11928", "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning", "authors": ["Abhishek Sriram", "Neal Tuffy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper is a pre-print version and has been submitted to the IEEE International Conference on Future Machine Learning and Data Science (FMLDS 2025)", "url": "http://arxiv.org/abs/2507.11928v2", "summary": "This paper presents a machine learning-accelerated optimization framework for\nRF power amplifier design that reduces simulation requirements by 65% while\nmaintaining $\\pm0.4$ dBm accuracy for the majority of the modes. The proposed\nmethod combines MaxMin Latin Hypercube Sampling with CatBoost gradient boosting\nto intelligently explore multidimensional parameter spaces. Instead of\nexhaustively simulating all parameter combinations to achieve target P2dB\ncompression specifications, our approach strategically selects approximately\n35% of critical simulation points. The framework processes ADS netlists,\nexecutes harmonic balance simulations on the reduced dataset, and trains a\nCatBoost model to predict P2dB performance across the entire design space.\nValidation across 15 PA operating modes yields an average $R^2$ of 0.901, with\nthe system ranking parameter combinations by their likelihood of meeting target\nspecifications. The integrated solution delivers 58.24% to 77.78% reduction in\nsimulation time through automated GUI-based workflows, enabling rapid design\niterations without compromising accuracy standards required for production RF\ncircuits.", "comment": "This paper is a pre-print version and has been submitted to the IEEE\n  International Conference on Future Machine Learning and Data Science (FMLDS\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.11928v2", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2409.00901", "title": "On the optimal approximation of Sobolev and Besov functions using deep ReLU neural networks", "authors": ["Yunfei Yang"], "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.00901v3", "summary": "This paper studies the problem of how efficiently functions in the Sobolev\nspaces $\\mathcal{W}^{s,q}([0,1]^d)$ and Besov spaces\n$\\mathcal{B}^s_{q,r}([0,1]^d)$ can be approximated by deep ReLU neural networks\nwith width $W$ and depth $L$, when the error is measured in the $L^p([0,1]^d)$\nnorm. This problem has been studied by several recent works, which obtained the\napproximation rate $\\mathcal{O}((WL)^{-2s/d})$ up to logarithmic factors when\n$p=q=\\infty$, and the rate $\\mathcal{O}(L^{-2s/d})$ for networks with fixed\nwidth when the Sobolev embedding condition $1/q -1/p<s/d$ holds. We generalize\nthese results by showing that the rate $\\mathcal{O}((WL)^{-2s/d})$ indeed holds\nunder the Sobolev embedding condition. It is known that this rate is optimal up\nto logarithmic factors. The key tool in our proof is a novel encoding of sparse\nvectors by using deep ReLU neural networks with varied width and depth, which\nmay be of independent interest.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.00901v3", "cate": "stat.ML", "date": "2024-09-02", "updated": "2025-07-18"}
{"id": "2507.12144", "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale", "authors": ["Boris Bonev", "Thorsten Kurth", "Ankur Mahesh", "Mauro Bisson", "Jean Kossaifi", "Karthik Kashinath", "Anima Anandkumar", "William D. Collins", "Michael S. Pritchard", "Alexander Keller"], "categories": ["cs.LG", "physics.ao-ph", "86-10, 68T07", "I.2.1; I.6.5; G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12144v2", "summary": "FourCastNet 3 advances global weather modeling by implementing a scalable,\ngeometric machine learning (ML) approach to probabilistic ensemble forecasting.\nThe approach is designed to respect spherical geometry and to accurately model\nthe spatially correlated probabilistic nature of the problem, resulting in\nstable spectra and realistic dynamics across multiple scales. FourCastNet 3\ndelivers forecasting accuracy that surpasses leading conventional ensemble\nmodels and rivals the best diffusion-based methods, while producing forecasts 8\nto 60 times faster than these approaches. In contrast to other ML approaches,\nFourCastNet 3 demonstrates excellent probabilistic calibration and retains\nrealistic spectra, even at extended lead times of up to 60 days. All of these\nadvances are realized using a purely convolutional neural network architecture\ntailored for spherical geometry. Scalable and efficient large-scale training on\n1024 GPUs and more is enabled by a novel training paradigm for combined model-\nand data-parallelism, inspired by domain decomposition methods in classical\nnumerical models. Additionally, FourCastNet 3 enables rapid inference on a\nsingle GPU, producing a 60-day global forecast at 0.25{\\deg}, 6-hourly\nresolution in under 4 minutes. Its computational efficiency, medium-range\nprobabilistic skill, spectral fidelity, and rollout stability at subseasonal\ntimescales make it a strong candidate for improving meteorological forecasting\nand early warning systems through large ensemble predictions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12144v2", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2507.12900", "title": "Learning to Reject Low-Quality Explanations via User Feedback", "authors": ["Luca Stradiotti", "Dario Pesenti", "Stefano Teso", "Jesse Davis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12900v2", "summary": "Machine Learning predictors are increasingly being employed in high-stakes\napplications such as credit scoring. Explanations help users unpack the reasons\nbehind their predictions, but are not always \"high quality''. That is,\nend-users may have difficulty interpreting or believing them, which can\ncomplicate trust assessment and downstream decision-making. We argue that\nclassifiers should have the option to refuse handling inputs whose predictions\ncannot be explained properly and introduce a framework for learning to reject\nlow-quality explanations (LtX) in which predictors are equipped with a rejector\nthat evaluates the quality of explanations. In this problem setting, the key\nchallenges are how to properly define and assess explanation quality and how to\ndesign a suitable rejector. Focusing on popular attribution techniques, we\nintroduce ULER (User-centric Low-quality Explanation Rejector), which learns a\nsimple rejector from human ratings and per-feature relevance judgments to\nmirror human judgments of explanation quality. Our experiments show that ULER\noutperforms both state-of-the-art and explanation-aware learning to reject\nstrategies at LtX on eight classification and regression benchmarks and on a\nnew human-annotated dataset, which we will publicly release to support future\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12900v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.12931", "title": "Improving DAPO from a Mixed-Policy Perspective", "authors": ["Hongze Tan"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12931v2", "summary": "This paper introduces two novel modifications to the Dynamic sAmpling Policy\nOptimization (DAPO) algorithm [1], approached from a mixed-policy perspective.\nStandard policy gradient methods can suffer from instability and sample\ninefficiency, particularly in sparse reward settings. To address this, we first\npropose a method that incorporates a pre-trained, stable guiding policy\n($\\piphi$) to provide off-policy experience, thereby regularizing the training\nof the target policy ($\\pion$). This approach improves training stability and\nconvergence speed by adaptively adjusting the learning step size. Secondly, we\nextend this idea to re-utilize zero-reward samples, which are often discarded\nby dynamic sampling strategies like DAPO's. By treating these samples as a\ndistinct batch guided by the expert policy, we further enhance sample\nefficiency. We provide a theoretical analysis for both methods, demonstrating\nthat their objective functions converge to the optimal solution within the\nestablished theoretical framework of reinforcement learning. The proposed\nmixed-policy framework effectively balances exploration and exploitation,\npromising more stable and efficient policy optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12931v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.12950", "title": "Insights into a radiology-specialised multimodal large language model with sparse autoencoders", "authors": ["Kenza Bouzid", "Shruthi Bannur", "Felix Meissen", "Daniel Coelho de Castro", "Anton Schwaighofer", "Javier Alvarez-Valle", "Stephanie L. Hyland"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Actionable Interpretability Workshop at ICML 2025. 24 pages, 7 figures, 5 tables", "url": "http://arxiv.org/abs/2507.12950v2", "summary": "Interpretability can improve the safety, transparency and trust of AI models,\nwhich is especially important in healthcare applications where decisions often\ncarry significant consequences. Mechanistic interpretability, particularly\nthrough the use of sparse autoencoders (SAEs), offers a promising approach for\nuncovering human-interpretable features within large transformer-based models.\nIn this study, we apply Matryoshka-SAE to the radiology-specialised multimodal\nlarge language model, MAIRA-2, to interpret its internal representations. Using\nlarge-scale automated interpretability of the SAE features, we identify a range\nof clinically relevant concepts - including medical devices (e.g., line and\ntube placements, pacemaker presence), pathologies such as pleural effusion and\ncardiomegaly, longitudinal changes and textual features. We further examine the\ninfluence of these features on model behaviour through steering, demonstrating\ndirectional control over generations with mixed success. Our results reveal\npractical and methodological challenges, yet they offer initial insights into\nthe internal concepts learned by MAIRA-2 - marking a step toward deeper\nmechanistic understanding and interpretability of a radiology-adapted\nmultimodal large language model, and paving the way for improved model\ntransparency. We release the trained SAEs and interpretations:\nhttps://huggingface.co/microsoft/maira-2-sae.", "comment": "Actionable Interpretability Workshop at ICML 2025. 24 pages, 7\n  figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.12950v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2507.13207", "title": "MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling", "authors": ["Etienne Le Naour", "Tahar Nabil", "Ghislain Agoua"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10th Workshop on Advanced Analytics and Learning on Temporal Data (AALTD), ECML 2025", "url": "http://arxiv.org/abs/2507.13207v2", "summary": "Recent years have witnessed a growing interest for time series foundation\nmodels, with a strong emphasis on the forecasting task. Yet, the crucial task\nof out-of-domain imputation of missing values remains largely underexplored. We\npropose a first step to fill this gap by leveraging implicit neural\nrepresentations (INRs). INRs model time series as continuous functions and\nnaturally handle various missing data scenarios and sampling rates. While they\nhave shown strong performance within specific distributions, they struggle\nunder distribution shifts. To address this, we introduce MoTM (Mixture of\nTimeflow Models), a step toward a foundation model for time series imputation.\nBuilding on the idea that a new time series is a mixture of previously seen\npatterns, MoTM combines a basis of INRs, each trained independently on a\ndistinct family of time series, with a ridge regressor that adapts to the\nobserved context at inference. We demonstrate robust in-domain and\nout-of-domain generalization across diverse imputation scenarios (e.g., block\nand pointwise missingness, variable sampling rates), paving the way for\nadaptable foundation imputation models.", "comment": "10th Workshop on Advanced Analytics and Learning on Temporal Data\n  (AALTD), ECML 2025", "pdf_url": "http://arxiv.org/pdf/2507.13207v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18"}
{"id": "2403.18840", "title": "An AI-powered Technology Stack for Solving Many-Electron Field Theory", "authors": ["Pengcheng Hou", "Tao Wang", "Daniel Cerkoney", "Xiansheng Cai", "Zhiyi Li", "Youjin Deng", "Lei Wang", "Kun Chen"], "categories": ["hep-th", "cond-mat.str-el", "cs.LG", "hep-ph", "physics.comp-ph"], "primary_category": "Subjects:       High Energy Physics - Theory (hep-th)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.18840v2", "summary": "Quantum field theory (QFT) for interacting many-electron systems is\nfundamental to condensed matter physics, yet achieving accurate solutions\nconfronts computational challenges in managing the combinatorial complexity of\nFeynman diagrams, implementing systematic renormalization, and evaluating\nhigh-dimensional integrals. We present a unifying framework that integrates QFT\ncomputational workflows with an AI-powered technology stack. A cornerstone of\nthis framework is representing Feynman diagrams as computational graphs, which\nstructures the inherent mathematical complexity and facilitates the application\nof optimized algorithms developed for machine learning and high-performance\ncomputing. Consequently, automatic differentiation, native to these graph\nrepresentations, delivers efficient, fully automated, high-order\nfield-theoretic renormalization procedures. This graph-centric approach also\nenables sophisticated numerical integration; our neural-network-enhanced Monte\nCarlo method, accelerated via massively parallel GPU implementation,\nefficiently evaluates challenging high-dimensional diagrammatic integrals.\nApplying this framework to the uniform electron gas, we determine the\nquasiparticle effective mass to a precision significantly surpassing current\nstate-of-the-art simulations. Our work demonstrates the transformative\npotential of integrating AI-driven computational advances with QFT, opening\nsystematic pathways for solving complex quantum many-body problems across\ndisciplines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.18840v2", "cate": "hep-th", "date": "2024-02-28", "updated": "2025-07-18"}
{"id": "2405.15441", "title": "Statistical and Computational Guarantees of Kernel Max-Sliced Wasserstein Distances", "authors": ["Jie Wang", "March Boedihardjo", "Yao Xie"], "categories": ["stat.ML", "cs.CC", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted by ICML-2025", "url": "http://arxiv.org/abs/2405.15441v4", "summary": "Optimal transport has been very successful for various machine learning\ntasks; however, it is known to suffer from the curse of dimensionality. Hence,\ndimensionality reduction is desirable when applied to high-dimensional data\nwith low-dimensional structures. The kernel max-sliced (KMS) Wasserstein\ndistance is developed for this purpose by finding an optimal nonlinear mapping\nthat reduces data into $1$ dimension before computing the Wasserstein distance.\nHowever, its theoretical properties have not yet been fully developed. In this\npaper, we provide sharp finite-sample guarantees under milder technical\nassumptions compared with state-of-the-art for the KMS $p$-Wasserstein distance\nbetween two empirical distributions with $n$ samples for general\n$p\\in[1,\\infty)$. Algorithm-wise, we show that computing the KMS\n$2$-Wasserstein distance is NP-hard, and then we further propose a semidefinite\nrelaxation (SDR) formulation (which can be solved efficiently in polynomial\ntime) and provide a relaxation gap for the obtained solution. We provide\nnumerical examples to demonstrate the good performance of our scheme for\nhigh-dimensional two-sample testing.", "comment": "Accepted by ICML-2025", "pdf_url": "http://arxiv.org/pdf/2405.15441v4", "cate": "stat.ML", "date": "2024-05-24", "updated": "2025-07-18"}
{"id": "2410.13799", "title": "Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC", "authors": ["Ernesto Arganda", "Marcela Carena", "Martín de los Rios", "Andres D. Perez", "Duncan Rocha", "Rosa M. Sandá Seoane", "Carlos E. M. Wagner"], "categories": ["hep-ph", "cs.LG", "hep-ex"], "primary_category": "Subjects:       High Energy Physics - Phenomenology (hep-ph)", "pdf_link": null, "comments": "Comments:      26 pages + references, 8 figures, 3 tables, 3 appendices. This version matches the manuscript published in JHEP", "url": "http://arxiv.org/abs/2410.13799v3", "summary": "The search for weakly interacting matter particles (WIMPs) is one of the main\nobjectives of the High Luminosity Large Hadron Collider (HL-LHC). In this work\nwe use Machine-Learning (ML) techniques to explore WIMP radiative decays into a\nDark Matter (DM) candidate in a supersymmetric framework. The minimal\nsupersymmetric WIMP sector includes the lightest neutralino that can provide\nthe observed DM relic density through its co-annihilation with the second\nlightest neutralino and lightest chargino. Moreover, the direct DM detection\ncross section rates fulfill current experimental bounds and provide discovery\ntargets for the same region of model parameters in which the radiative decay of\nthe second lightest neutralino into a photon and the lightest neutralino is\nenhanced. This strongly motivates the search for radiatively decaying\nneutralinos which, however, suffers from strong backgrounds. We investigate the\nLHC reach in the search for these radiatively decaying particles by means of\ncut-based and ML methods and estimate its discovery potential in this\nwell-motivated, new physics scenario. We demonstrate that using ML techniques\nwould enable access to most of the parameter space unexplored by other\nsearches.", "comment": "26 pages + references, 8 figures, 3 tables, 3 appendices. This\n  version matches the manuscript published in JHEP", "pdf_url": "http://arxiv.org/pdf/2410.13799v3", "cate": "hep-ph", "date": "2024-10-17", "updated": "2025-07-18"}
{"id": "2505.07363", "title": "Equilibrium Propagation for Learning in Lagrangian Dynamical Systems", "authors": ["Serge Massar"], "categories": ["nlin.CD", "cs.LG", "physics.data-an"], "primary_category": "Subjects:       Chaotic Dynamics (nlin.CD)", "pdf_link": null, "comments": "Comments:      9 pages, 1 figure", "url": "http://arxiv.org/abs/2505.07363v3", "summary": "We propose a method for training dynamical systems governed by Lagrangian\nmechanics using Equilibrium Propagation. Our approach extends Equilibrium\nPropagation - initially developed for energy-based models - to dynamical\ntrajectories by leveraging the principle of action extremization. Training is\nachieved by gently nudging trajectories toward desired targets and measuring\nhow the variables conjugate to the parameters to be trained respond. This\nmethod is particularly suited to systems with periodic boundary conditions or\nfixed initial and final states, enabling efficient parameter updates without\nrequiring explicit backpropagation through time. In the case of periodic\nboundary conditions, this approach yields the semiclassical limit of Quantum\nEquilibrium Propagation. Applications to systems with dissipation are also\ndiscussed.", "comment": "9 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2505.07363v3", "cate": "nlin.CD", "date": "2025-05-12", "updated": "2025-07-18"}
{"id": "2507.12503", "title": "Complex non-backtracking matrix for directed graphs", "authors": ["Keishi Sando", "Hideitsu Hino"], "categories": ["math.CO", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12503v2", "summary": "Graph representation matrices are essential tools in graph data analysis.\nRecently, Hermitian adjacency matrices have been proposed to investigate\ndirected graph structures. Previous studies have demonstrated that these\nmatrices can extract valuable information for clustering. In this paper, we\npropose the complex non-backtracking matrix that integrates the properties of\nthe Hermitian adjacency matrix and the non-backtracking matrix. The proposed\nmatrix has similar properties with the non-backtracking matrix of undirected\ngraphs. We reveal relationships between the complex non-backtracking matrix and\nthe Hermitian adjacency matrix. Also, we provide intriguing insights that this\nmatrix representation holds cluster information, particularly for sparse\ndirected graphs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12503v2", "cate": "math.CO", "date": "2025-07-16", "updated": "2025-07-18"}
