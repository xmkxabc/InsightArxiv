# AI-Enhanced arXiv Daily 2025-07-05

<a id='toc'></a>
## 今日总计: 435 篇论文
### 目录
- [cs.CR](#cscr) (20 篇)
- [cs.AI](#csai) (31 篇)
- [cs.LG](#cslg) (64 篇)
- [cs.MA](#csma) (2 篇)
- [cs.RO](#csro) (20 篇)
- [cs.CV](#cscv) (83 篇)
- [cs.HC](#cshc) (19 篇)
- [cs.SE](#csse) (16 篇)
- [cs.SI](#cssi) (2 篇)
- [cs.NI](#csni) (8 篇)
- [cs.IT](#csit) (5 篇)
- [cs.AR](#csar) (5 篇)
- [cs.DC](#csdc) (7 篇)
- [cs.CY](#cscy) (3 篇)
- [cs.CE](#csce) (4 篇)
- [cs.FL](#csfl) (1 篇)
- [eess.SY](#eesssy) (12 篇)
- [eess.SP](#eesssp) (12 篇)
- [eess.IV](#eessiv) (5 篇)
- [eess.AS](#eessas) (8 篇)
- [cs.CL](#cscl) (26 篇)
- [cs.DS](#csds) (10 篇)
- [cs.GR](#csgr) (2 篇)
- [cs.IR](#csir) (8 篇)
- [cs.NE](#csne) (5 篇)
- [cs.SD](#cssd) (7 篇)
- [stat.ML](#statml) (5 篇)
- [cs.GT](#csgt) (2 篇)
- [cs.LO](#cslo) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (2 篇)
- [q-fin.TR](#q-fintr) (1 篇)
- [cond-mat.soft](#cond-matsoft) (1 篇)
- [q-fin.ST](#q-finst) (6 篇)
- [cs.PL](#cspl) (1 篇)
- [physics.app-ph](#physicsapp-ph) (3 篇)
- [q-bio.TO](#q-bioto) (1 篇)
- [cs.MM](#csmm) (1 篇)
- [quant-ph](#quant-ph) (3 篇)
- [math.PR](#mathpr) (2 篇)
- [q-bio.PE](#q-biope) (1 篇)
- [math.OC](#mathoc) (2 篇)
- [econ.GN](#econgn) (2 篇)
- [q-fin.GN](#q-fingn) (3 篇)
- [physics.optics](#physicsoptics) (2 篇)
- [q-fin.CP](#q-fincp) (1 篇)
- [physics.chem-ph](#physicschem-ph) (2 篇)
- [cs.OS](#csos) (1 篇)
- [q-fin.PM](#q-finpm) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (1 篇)
- [q-bio.BM](#q-biobm) (1 篇)
- [q-fin.RM](#q-finrm) (1 篇)
- [q-bio.QM](#q-bioqm) (1 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [cond-mat.str-el](#cond-matstr-el) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](https://arxiv.org/abs/2507.02057)
> *MGC：一个利用对齐LLM中组合盲区生成恶意软件的编译器框架*

*Lu Yan, Zhuo Zhang, Xiangzhe Xu, Shengwei An, Guangyu Shen, Zhou Xuan, Xuan Chen, Xiangyu Zhang* | **Category: cs.CR, cs.AI** | **Updated: {updated}**

**Keywords:** 恶意软件生成, 大型语言模型, 组合攻击, 对齐机制, 编译器框架

**Comment:** 

> **TL;DR:** MGC是一个编译器框架，通过将恶意任务分解为看似良性的子任务，绕过LLM的安全对齐机制，高效生成恶意软件。

**AI_Comments:** 这项工作创新性地揭示了LLMs在处理复杂、分解式恶意指令时的“组合盲区”，挑战了现有安全对齐机制的有效性。MGC框架通过模拟恶意软件的模块化开发流程，绕过了LLMs的防护，其性能提升显著，对AI安全领域具有重要的警示作用，促使研究人员重新思考和设计更鲁棒的对齐与防护策略。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）使软件开发民主化，但也促进了恶意软件开发，引发安全担忧。尽管LLM提供商实施了对齐机制以防止直接生成恶意代码，但这些机制主要孤立评估提示，忽视了恶意操作可以系统性分解为看似良性子任务的关键漏洞（即组合盲区）。

**Method:** 本文引入了恶意软件生成编译器（MGC）框架，该框架通过模块化分解和规避对齐的生成来利用LLMs的组合盲区。MGC采用专门的恶意软件描述中间表示（MDIR），以连接高级恶意意图和看似良性的代码片段。

**Result:** MGC能够可靠地生成功能性恶意软件，在三个基准数据集上，其正确性比越狱方法高365.79%，比地下服务高78.07%。案例研究表明，MGC可以复现甚至增强16个真实世界的恶意软件样本。

**Conclusion:** 这项工作通过揭示针对对齐AI系统的组合攻击风险，为安全研究人员提供了重要的见解。

> **ai_Abstract:** 本文提出了MGC（恶意软件生成编译器）框架，旨在利用大型语言模型（LLMs）对组合性攻击的盲区，即LLMs的安全对齐机制在评估孤立提示时，无法识别恶意操作被分解为看似良性子任务的情况。MGC通过模块化分解和规避对齐的生成，将高级恶意意图转化为看似无害的代码片段，并使用特制的恶意软件描述中间表示（MDIR）实现这一过程。实验证明，MGC能高效生成功能性恶意软件，其性能显著优于现有越狱方法和地下服务，并能复现和增强真实世界的恶意软件样本，为AI系统安全研究提供了重要警示。

> **摘要翻译:** 大型语言模型（LLM）使软件开发民主化，降低了编程复杂应用程序的专业障碍。这种可访问性延伸到恶意软件开发，引发了重大的安全担忧。尽管LLM提供商已经实施了对齐机制来防止直接生成明显恶意的代码，但这些防护措施主要孤立地评估单个提示，忽略了一个关键漏洞：恶意操作可以系统地分解为看似良性的子任务。在本文中，我们引入了恶意软件生成编译器（MGC），这是一个新颖的框架，通过模块化分解和规避对齐的生成来利用此漏洞。MGC采用专门的恶意软件描述中间表示（MDIR），以连接高级恶意意图和看似良性的代码片段。广泛的评估表明，我们的攻击在各种任务规范和类别中可靠地生成功能性恶意软件，在三个基准数据集上的正确性比越狱方法高出+365.79%，比地下服务高出+78.07%。案例研究进一步表明，MGC可以复现甚至增强16个真实世界的恶意软件样本。这项工作通过揭示针对对齐AI系统的组合攻击风险，为安全研究人员提供了重要的见解。演示可在https://sites.google.com/view/malware-generation-compiler 获取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [2] [Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities](https://arxiv.org/abs/2507.02125)
> *人工智能能否解决区块链预言机问题？挑战与可能性的剖析*

*Giulio Caldarelli* | **Category: cs.CR, cs.AI, cs.CY, cs.GT, cs.LG, 11, 62, 68, 90, 91, F.0; F.4; H.4; H.5; I.2** | **Updated: {updated}**

**Keywords:** 区块链, 预言机问题, 人工智能, 外部数据, 去中心化系统

**Comment:** 

> **TL;DR:** 人工智能可以增强区块链预言机系统，但不能完全解决对链下输入的信任问题，应作为补充层。

**AI_Comments:** 这篇论文批判性地探讨了AI在解决区块链预言机问题中的作用，提出了AI作为补充层而非替代品的观点，这对于理解AI在区块链领域中的局限性和合理定位具有重要意义。其创新之处在于系统性地分析了多种AI技术如何具体增强预言机系统，并明确指出了AI的边界。

<details>
  <summary>Details</summary>

**Motivation:** 区块链预言机问题（将可靠的外部数据注入去中心化系统）是去信任化应用发展的一个根本限制，现有策略未能完全解决区块链如何获取链下世界知识的问题。

**Method:** 本论文是一篇立场论文，通过评估人工智能在解决预言机问题中的作用，并结合学术文献和实践实现，探讨了异常检测、基于语言的事实提取、动态声誉建模和对抗性抵抗等AI技术如何增强预言机系统。

**Result:** 观察到AI为改善数据质量、源选择和系统弹性提供了强大工具，但不能消除对不可验证链下输入的依赖。

**Conclusion:** 人工智能应被理解为更广泛预言机设计中的一个补充推理和过滤层，而不是信任假设的替代品。

> **ai_Abstract:** 本立场论文探讨了人工智能（AI）在解决区块链预言机问题中的潜力。该问题在于将可靠的外部数据引入去中心化系统。研究分析了异常检测、事实提取、声誉建模和对抗性抵抗等AI技术如何增强预言机系统的数据质量和弹性。结论指出，AI虽能提供强大工具，但无法完全消除对不可验证链下输入的依赖，因此应作为现有预言机设计的补充层，而非信任假设的替代品。

> **摘要翻译:** 区块链预言机问题，即向去中心化系统注入可靠外部数据的挑战，仍然是去信任化应用发展的一个根本限制。尽管近年来出现了大量旨在缓解这一问题的架构、密码学和经济策略，但尚未有人完全解决区块链如何获取链下世界知识的根本问题。在这篇立场论文中，我们批判性地评估了人工智能（AI）在解决预言机问题中可以发挥的作用。我们借鉴学术文献和实践实现，探讨了异常检测、基于语言的事实提取、动态声誉建模和对抗性抵抗等AI技术如何增强预言机系统。我们观察到，虽然AI为改善数据质量、源选择和系统弹性引入了强大的工具，但它不能消除对不可验证链下输入的依赖。因此，本研究支持人工智能应被理解为更广泛预言机设计中的一个补充推理和过滤层，而不是信任假设的替代品的观点。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [3] [ARMOUR US: Android Runtime Zero-permission Sensor Usage Monitoring from User Space](https://arxiv.org/abs/2507.02177)
> *ARMOUR US：安卓运行时零权限传感器用户空间使用监控*

*Yan Long, Jiancong Cui, Yuqing Yang, Tobias Alam, Zhiqiang Lin, Kevin Fu* | **Category: cs.CR, K.6.5; D.4.6** | **Updated: {updated}**

**Keywords:** 安卓, 零权限传感器, 隐私, 运行时监控, 传感器滥用

**Comment:** 

> **TL;DR:** ARMOUR是一个用户空间工具，用于监控安卓零权限传感器使用情况，以检测隐私泄露和滥用模式，无需root权限。

**AI_Comments:** ARMOUR的创新之处在于其用户空间监控能力，无需root权限或复杂的设置，显著优于现有方法。它解决了零权限传感器带来的关键隐私问题，并赋予用户和研究人员更大的控制权。发现50%看似无关的应用程序访问多个零权限传感器的数据，这是一个重要的发现，揭示了普遍存在的滥用模式。

<details>
  <summary>Details</summary>

**Motivation:** 安卓零权限传感器可能导致用户隐私泄露，而现有方法（如静态分析和基于hook的动态分析）面临开发复杂、需要root权限和特定应用逆向工程分析的挑战。目前很少有工作让最终用户了解传感器使用情况。

**Method:** 开发了ARMOUR，用于用户空间运行时监控，利用安卓固有的采样率变化和收敛行为。

**Result:** 对1,448个商业应用程序的评估显示，ARMOUR在检测混淆代码和其他条件下的传感器使用方面非常有效。观察到显著的传感器滥用模式，例如50%来自看似与传感器无关类别的应用程序访问了多个零权限传感器的数据。分析了安卓最近的政策变化对零权限传感器的影响。

**Conclusion:** ARMOUR使具有隐私意识的用户能够轻松监控第三方应用程序如何使用传感器数据，并支持安全研究人员进行快速的、与应用程序无关的传感器访问分析。论文还分析了安卓在零权限传感器方面的政策变化以及剩余的技术和监管问题。

> **ai_Abstract:** 本文介绍了ARMOUR US，一种用于安卓零权限传感器的新型用户空间运行时监控工具。它通过允许用户监控第三方应用程序的传感器使用情况来解决隐私泄露问题，而无需root权限或复杂的逆向工程。ARMOUR利用安卓固有的传感器行为，即使在混淆代码中也能有效检测传感器访问，并揭示了显著的滥用模式，例如许多看似无关的应用程序访问多个零权限传感器。该工作还讨论了安卓最新政策变化的影响以及仍然存在的挑战。

> **摘要翻译:** 这项工作研究了如何监控安卓零权限传感器的访问，这可能导致用户的隐私泄露。此外，监控此类敏感访问使安全研究人员能够识别潜在的传感器滥用模式。加速度计等零权限传感器已成为安卓设备不可或缺的一部分。它们提供的关键信息吸引了广泛的研究，探讨数据收集者如何捕获更多传感器数据，以实现良性和利用性应用程序。相比之下，很少有工作探索如何使数据提供者（例如最终用户）了解传感器使用情况。虽然现有方法（如静态分析和基于hook的动态分析）面临着需要复杂开发链、root权限和特定于应用程序的逆向工程分析的挑战，但我们的工作旨在通过开发ARMOUR来弥补这一空白，以实现用户空间运行时监控，利用安卓固有的采样率变化和收敛行为。ARMOUR使具有隐私意识的用户能够轻松监控第三方应用程序如何使用传感器数据，并支持安全研究人员进行快速的与应用程序无关的传感器访问分析。我们对1,448个商业应用程序的评估显示，ARMOUR在检测混淆代码和其他条件下的传感器使用方面的有效性，并观察到显著的传感器滥用模式，例如50%来自看似与传感器无关类别的应用程序访问多个零权限传感器的数据。我们分析了安卓最近的政策变化对零权限传感器和剩余技术和监管问题的影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [4] [Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher](https://arxiv.org/abs/2507.02181)
> *扩展的c-差分区分器针对完整9轮和简化轮Kuznyechik密码*

*Pantelimon Stanica, Ranit Dutta, Bimal Mandal* | **Category: cs.CR, cs.IT, math.IT, 94A60, 11T71, 12E20, 68P25, 62P99** | **Updated: {updated}**

**Keywords:** c-差分密码分析, Kuznyechik, 分组密码, 区分器, 安全性分析

**Comment:** 

> **TL;DR:** 本文引入了一种新的截断内部c-差分密码分析技术，首次将c-差分均匀性应用于分组密码。通过开发内部c-差分方法并证明其与外部c-差分均匀性的对偶性，解决了现有方法的挑战。研究人员成功地对完整的9轮Kuznyechik密码进行了分析，发现了显著的非随机性，并构建了第一个针对其的实用区分器，表明该密码的安全性裕度不足。

**AI_Comments:** 本文的创新之处在于提出了“截断内部c-差分密码分析”这一新颖技术，并通过修改c-差分的作用方式（从输出乘以c变为输入乘以c）巧妙地解决了传统c-差分分析在分组密码中破坏结构的问题，尤其是在处理密钥加法时。这种“内部”方法的引入以及其与外部c-差分均匀性的对偶性证明是理论上的重要进展。其重要性在于首次将c-差分均匀性实际应用于分组密码，并成功构建了针对完整9轮Kuznyechik密码的实用区分器，对该密码的安全性提出了新的挑战。这为未来针对分组密码的差分分析提供了新的思路和工具。

<details>
  <summary>Details</summary>

**Motivation:** Ellingsen等人提出的c-差分均匀性概念在应用于分组密码时面临挑战，特别是乘以c会破坏关键加法等结构特性。本文旨在解决这一问题，首次实现c-差分均匀性在分组密码上的实际应用。

**Method:** 本文引入了“截断内部c-差分密码分析”技术。通过开发一种“内部”c-差分方法（$F(cx\oplus a), F(x)$），其中乘数c作用于输入，从而解决了现有c-差分方法中乘以c会破坏分组密码结构的问题。研究证明了函数F的内部c-差分均匀性等于$F^{-1}$的外部c-差分均匀性，建立了基本对偶性。在此基础上，构建了一个全面的多方面统计计算框架，对完整的9轮Kuznyechik密码实施了截断c-差分分析。

**Result:** 通过对数百万个差分对进行广泛计算分析，结果表明在所有测试的轮数中都存在统计上显著的非随机性。对于完整的9轮Kuznyechik密码，识别出多种触发关键安全警报的配置，偏置比率达到1.7倍，校正后的p值低至$1.85 \times 10^{-3}$。这代表了第一个针对完整9轮Kuznyechik密码的实用区分器。

**Conclusion:** 研究结果表明，完整的9轮Kuznyechik密码对于新的攻击向量（扩展的c-差分区分器）可能存在安全性裕度不足的问题。

> **ai_Abstract:** 本文提出了一种名为“截断内部c-差分密码分析”的新技术，旨在解决现有c-差分均匀性在分组密码应用中因结构破坏而面临的挑战。通过引入一种内部c-差分方法，并证明其与逆函数的外部c-差分均匀性存在对偶关系，该方法成功地保留了密码的结构特性。研究构建了一个统计计算框架，并将其应用于完整的9轮Kuznyechik密码。实验结果显示，在所有测试轮数中均发现显著的非随机性，尤其针对完整的9轮密码，检测到偏置比率高达1.7倍、p值低至$1.85 \times 10^{-3}$的配置，表明该密码在面对这种新攻击时可能存在安全缺陷。这是首次针对完整9轮Kuznyechik密码的实用区分器。

> **摘要翻译:** 本文引入了“截断内部c-差分密码分析”，这是一种新颖的技术，首次使得c-差分均匀性能够实际应用于分组密码。尽管Ellingsen等人（IEEE Trans. Inf. Theory, 2020）建立了使用$(F(x\oplus a), cF(x))$的c-差分均匀性概念，但一个关键挑战依然存在：乘以c会破坏分组密码分析所必需的结构特性，特别是密钥加法。
我们通过开发一种“内部”c-差分方法解决了这一挑战，其中乘以c影响输入：$(F(cx\oplus a), F(x))$。我们证明了函数F的内部c-差分均匀性等于$F^{-1}$的外部c-差分均匀性，建立了基本对偶性。这一修改在启用实际密码分析应用的同时，保留了密码结构。
我们的主要贡献是一个全面的多方面统计计算框架，实现了对完整9轮Kuznyechik密码的截断c-差分分析（内部c-差分对后端的密钥白化免疫）。通过涉及数百万个差分对的广泛计算分析，我们证明了所有测试轮数中都存在统计上显著的非随机性。对于完整的9轮密码，我们识别出多种触发关键安全警报的配置，偏置比率达到1.7倍，校正后的p值低至$1.85 \times 10^{-3}$，这表明对抗此新攻击向量的安全性裕度不足。这代表了第一个针对完整9轮Kuznyechik密码的实用区分器。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [33] [EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer](https://arxiv.org/abs/2507.02206)
> *EIM-TRNG：通过RowHammer利用内存编码真随机数生成器混淆深度神经网络权重*

*Ranyang Zhou, Abeer Matar A. Almalky, Gamana Aragonda, Sabbir Ahmed, Filip Roth Trønnes-Christensen, Adnan Siraj Rakin, Shaahin Angizi* | **Category: cs.CR, cs.AI** | **Updated: {updated}**

**Keywords:** 真随机数生成器, RowHammer, 深度神经网络, 硬件安全, 权重保护

**Comment:** 

> **TL;DR:** 提出一种名为EIM-TRNG的硬件真随机数生成器，利用DRAM的RowHammer效应产生的位翻转作为熵源，首次用于保护深度神经网络权重，实现低成本硬件安全。

**AI_Comments:** 这项工作创新性地利用了DRAM的RowHammer效应作为硬件TRNG的熵源，并将其应用于深度神经网络权重的保护，这是首次尝试。这种方法利用了硬件固有的物理随机性，提供了比软件方法更高的安全性和不可预测性。其贡献在于提供了一种低成本、高鲁棒性的硬件安全解决方案，对于保护AI模型的知识产权和数据完整性具有重要意义。潜在的局限性可能在于RowHammer效应的可控性以及在不同DRAM硬件上的兼容性和性能一致性。

<details>
  <summary>Details</summary>

**Motivation:** 真随机数生成器（TRNG）在硬件安全、加密系统和数据保护中发挥着基础性作用。保护深度神经网络（DNN）模型参数（特别是权重）对于确保AI系统的完整性、隐私和知识产权至关重要。软件伪随机数生成器缺乏硬件TRNG的不可预测性和弹性。

**Method:** 提出一种新颖且鲁棒的内存编码真随机数生成器（EIM-TRNG）。该方法首次利用DRAM单元行为中固有的物理随机性，特别是在RowHammer引起的干扰下，产生不可预测的位翻转作为可靠的熵源。将此TRNG框架应用于保护DNN权重数据，通过结合固定和不可预测的位翻转进行编码。解密时使用从概率翻转行为中导出的密钥，确保数据保密性和模型真实性。

**Result:** 验证了基于DRAM的熵提取对于鲁棒、低成本硬件安全的有效性。

**Conclusion:** 为在硬件层面保护机器学习模型提供了一个有前景的方向。

> **ai_Abstract:** 本文提出了一种新颖的内存编码真随机数生成器（EIM-TRNG），利用DRAM的RowHammer效应产生的位翻转作为熵源。该方法首次将DRAM的物理随机性应用于生成真随机数，并进一步应用于加密和保护深度神经网络的权重。通过结合固定和不可预测的位翻转进行编码，并使用概率翻转行为导出的密钥进行解密，EIM-TRNG确保了数据保密性和模型真实性。研究结果表明，这种基于DRAM的熵提取方法为鲁棒、低成本的硬件安全以及在硬件层面保护机器学习模型提供了有效的解决方案。

> **摘要翻译:** 真随机数生成器（TRNG）在硬件安全、加密系统和数据保护中发挥着基础性作用。在深度神经网络（DNN）的背景下，保护模型参数，特别是权重，对于确保AI系统的完整性、隐私和知识产权至关重要。虽然基于软件的伪随机数生成器被广泛使用，但它们缺乏硬件TRNG所提供的不可预测性和弹性。在这项工作中，我们提出了一种新颖且鲁棒的内存编码TRNG（EIM-TRNG），它首次利用DRAM单元行为中固有的物理随机性，特别是在RowHammer引起的干扰下。我们展示了如何将通过精心控制的RowHammer操作产生的不可预测的位翻转用作可靠的熵源。此外，我们将此TRNG框架应用于通过结合固定和不可预测的位翻转来编码，从而保护DNN权重数据。加密数据随后使用从概率翻转行为中导出的密钥进行解密，确保数据保密性和模型真实性。我们的结果验证了基于DRAM的熵提取对于鲁棒、低成本硬件安全的有效性，并为在硬件层面保护机器学习模型提供了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [60] [Linearly Homomorphic Ring Signature Scheme over Lattices](https://arxiv.org/abs/2507.02281)
> *格上线性同态环签名方案*

*Heng Guo, Kun Tian, Fengxia Liu, Zhiyong Zheng* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** 同态环签名, 格密码学, 线性同态, 后量子安全, 匿名性

**Comment:** 

> **TL;DR:** 本文提出了第一个基于格的线性同态环签名方案，解决了现有同态环签名方案不可行的问题，并在标准模型下证明了其安全性。

**AI_Comments:** 该论文的创新点在于提出了第一个基于格的线性同态环签名方案，填补了该领域的可行性空白。其重要性在于为需要匿名数据溯源和可验证同态计算的场景提供了后量子安全的解决方案，特别是在区块链和安全多方计算方面具有潜在应用价值。该方案在标准模型下证明了安全性，并实现了强匿名性和不可伪造性，具有较高的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 同态环签名方案结合了环签名的强匿名性和同态签名的可计算性，在需要匿名数据溯源和可验证同态计算的场景中（如保密区块链交易和安全多方计算）具有巨大潜力。然而，目前尚无可行的同态环签名方案。

**Method:** 本文提出了第一个基于格的线性同态环签名方案。该方案在标准模型下，基于小整数解（SIS）假设被证明是安全的，实现了在完全密钥暴露下的强匿名性和对抗内部腐败攻击的不可伪造性。

**Result:** 该方案是第一个统一环签名和线性同态签名的框架，为上述应用提供了后量子安全的解决方案。

**Conclusion:** 本文提出的方案推动了隐私增强同态计算的发展，并为需要匿名数据溯源和可验证同态计算的场景提供了后量子安全的解决方案。

> **ai_Abstract:** 本文提出了首个基于格的线性同态环签名方案，旨在解决当前缺乏可行同态环签名方案的问题。该方案结合了环签名的匿名性和同态签名的可计算性，并在标准模型下基于SIS假设证明了其安全性，实现了强匿名性和不可伪造性。作为统一环签名和线性同态签名的框架，它为保密区块链和安全多方计算等应用提供了后量子安全的解决方案，促进了隐私增强同态计算的进步。

> **摘要翻译:** 同态环签名方案结合了环签名的强匿名性和同态签名的可计算性，在需要匿名数据溯源和可验证同态计算的场景中（例如，保密区块链交易和安全多方计算）展现出巨大潜力。然而，目前尚不存在可行的同态环签名方案。
在这项工作中，我们提出了第一个基于格的线性同态环签名方案。在标准模型下，基于小整数解（SIS）假设，该方案被证明是安全的，实现了在完全密钥暴露下的强匿名性和对抗内部腐败攻击的不可伪造性。作为第一个统一环签名和线性同态签名的框架，该构造为上述应用提供了后量子安全的解决方案，推动了隐私增强同态计算的发展。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [63] [Real-Time Monitoring and Transparency in Pizza Production Using IoT and Blockchain](https://arxiv.org/abs/2507.02536)
> *使用物联网和区块链实现披萨生产的实时监控和透明度*

*Azmat Ullah, Maria Ilaria Lunesu, Lodovica Marchesi, Roberto Tonelli* | **Category: cs.CR, cs.ET** | **Updated: {updated}**

**Keywords:** 物联网, 区块链, 披萨生产, 实时监控, 透明度

**Comment:** 2 pages

> **TL;DR:** 本文提出了一种基于物联网和区块链的系统，用于实时监控披萨生产，确保数据安全和透明，从而提高效率并减少浪费。

**AI_Comments:** 该论文提出了一种新颖且实用的方法，将物联网和区块链技术融合应用于食品生产监控，特别是在披萨制作中，解决了传统生产流程中数据不透明和追溯困难的问题。其创新点在于利用区块链的不可篡改性确保数据完整，同时结合IoT实现实时监测，对于食品安全和供应链管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为解决披萨生产过程中缺乏实时监控和数据透明度的问题，并提高厨房效率、减少浪费。

**Method:** 该系统结合物联网设备和区块链技术。物联网设备（如树莓派）实时追踪温度和湿度，处理传感器数据，捕获图像并触发警报。区块链用于确保数据的安全性和防篡改性，并支持智能合约交互，从而实现透明度和可追溯性。

**Result:** 实验表明，该系统改善了食材管理，减少了浪费，并提高了厨房效率。

**Conclusion:** 该系统通过物联网和区块链技术，实现了披萨生产的实时监控和数据透明，有效提升了运营效率并减少了损耗。

> **ai_Abstract:** 本文介绍了一个创新的基于物联网和区块链的系统，旨在提升披萨生产过程的实时监控和数据透明度。通过物联网设备（如树莓派）收集温度、湿度等关键数据并触发警报，结合区块链技术确保数据安全、防篡改和可追溯性。实验结果显示，该系统在改善食材管理、减少浪费和提高厨房效率方面表现出色。

> **摘要翻译:** 本文提出了一种基于区块链的物联网（IoT）系统，用于监控餐厅的披萨生产。物联网设备实时跟踪温度和湿度，而区块链确保数据的安全性和防篡改性。树莓派处理传感器数据，捕获图像，触发警报，并与智能合约交互。该系统检测异常情况，实现快速响应。区块链增加了透明度和可追溯性，支持合规性和审计。实验表明，该系统改善了食材管理，减少了浪费，并提高了厨房效率。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [84] [Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle](https://arxiv.org/abs/2507.02309)
> *零信任原则下重新思考失效对象级授权攻击*

*Anbin Wu, Zhiyong Feng, Ruitao Feng* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** BOLA, 零信任, API安全, 授权, 静态污点跟踪

**Comment:** 

> **TL;DR:** 本研究提出BOLAZ框架，一个基于零信任原则的防御框架，通过分析资源ID的数据流和静态污点跟踪来识别并防止BOLA攻击，并在实际项目中验证了其有效性。

**AI_Comments:** 本文提出的BOLAZ框架在解决BOLA漏洞方面具有创新性，尤其体现在其将零信任原则与授权引导方法相结合，并利用静态污点跟踪来精确识别授权边界。这与传统基于通用授权模型的防御方法不同，能够更灵活地适应系统自身的授权逻辑。其在实际项目中的验证结果也凸显了其实用性和发现新漏洞的能力，对提升API安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** RESTful API在应用间数据交换中暴露了敏感资源，其中失效对象级授权（BOLA）是OWASP API安全十大漏洞之首，代表了一种关键的访问控制缺陷。现有防御方法不足以有效应对，因此需要一种新的防御框架。

**Method:** 提出BOLAZ防御框架，该框架基于零信任原则。BOLAZ通过分析资源ID的数据流，识别BOLA攻击注入点并确定授权区间以防止横向权限提升。它利用静态污点跟踪将API分为生产者和消费者，并映射资源ID的传播路径，从而精确识别授权边界。BOLAZ是首个根据系统最佳实践授权逻辑调整防御规则的授权引导方法。

**Result:** BOLAZ在10个GitHub项目上的实证研究验证了其有效性。结果表明，BOLAZ能有效防御从CVE收集的漏洞，并发现了35个新的BOLA漏洞，证明了其在实际部署中的实用性。

**Conclusion:** BOLAZ框架通过结合零信任原则和授权引导方法，为解决失效对象级授权（BOLA）攻击提供了一种有效且实用的防御机制，显著提升了API安全性。

> **ai_Abstract:** 本研究提出了BOLAZ，一个基于零信任原则的防御框架，旨在解决RESTful API中的失效对象级授权（BOLA）漏洞。BOLAZ通过分析资源ID的数据流并利用静态污点跟踪，识别BOLA攻击注入点和授权边界，从而防止横向权限提升。该框架是首个根据系统最佳实践授权逻辑调整防御规则的方法。实证研究表明，BOLAZ能有效防御已知漏洞，并发现了大量新的BOLA漏洞，验证了其在实际应用中的有效性和实用性。

> **摘要翻译:** RESTful API促进了应用程序之间的数据交换，但它们也使敏感资源面临潜在的利用。失效对象级授权（BOLA）是OWASP API安全十大漏洞之首，它是一个关键的访问控制缺陷，攻击者通过操纵API参数来获取未经授权的访问。为了解决这个问题，我们提出了BOLAZ，一个基于零信任原则的防御框架。BOLAZ分析资源ID的数据流，找出BOLA攻击注入点，并确定相关的授权区间，以防止横向权限提升。我们的方法利用静态污点跟踪将API分为生产者和消费者，根据它们处理资源ID的方式。通过映射资源ID的传播路径，BOLAZ捕获了这些ID的生成和消费上下文，从而能够精确识别授权边界。与基于常见授权模型的防御方法不同，BOLAZ是第一个根据系统最佳实践授权逻辑调整防御规则的授权引导方法。我们通过对10个GitHub项目的实证研究验证了BOLAZ。结果表明，BOLAZ在防御从CVE收集的漏洞方面是有效的，并且在实际中发现了35个新的BOLA漏洞，证明了其在实际部署中的实用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [108] [PII Jailbreaking in LLMs via Activation Steering Reveals Personal Information Leakage](https://arxiv.org/abs/2507.02332)
> *通过激活转向在大型语言模型中实现个人身份信息越狱揭示个人信息泄露*

*Krishna Kanth Nakka, Xue Jiang, Xuebing Zhou* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** 个人身份信息泄露, 大型语言模型, 激活转向, 越狱, 隐私

**Comment:** Preprint

> **TL;DR:** 通过操纵激活，大型语言模型（LLMs）可以被越狱以泄露个人身份信息，成功率很高。

**AI_Comments:** 这篇论文提出了一种新颖且令人担忧的通过直接操纵内部激活从大型语言模型提取个人身份信息的方法。这种“激活转向”技术是创新的，因为它超越了提示工程，直接针对模型的内部状态。高成功率揭示了一个重要的漏洞，突出了大型语言模型在隐私方面的关键影响，并强调了需要针对这种复杂攻击建立强大的防御机制。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨通过操纵大型语言模型（LLM）的激活是否能绕过其对齐机制并改变对隐私相关查询的响应行为，从而导致个人信息泄露。

**Method:** 研究人员首先利用隐私评估器标签训练轻量级线性探针，以识别出预测对私有属性拒绝行为的注意力头。随后，在训练好的探针引导下，操纵这些注意力头中的一小部分激活，以诱导模型生成非拒绝响应。

**Result:** 实验表明，被操纵的响应经常会泄露敏感属性细节以及数据主体的其他私人信息，这些信息模型通常会拒绝生成。在四种大型语言模型上的评估显示，越狱泄露率至少达到95%，其中平均超过50%的响应揭示了真实的个人信息。

**Conclusion:** 通过对大型语言模型内部激活的定向操纵，可以提取其中记忆的私人信息。

> **ai_Abstract:** 本文研究了一种通过操纵内部激活（激活转向）实现大型语言模型（LLM）“隐私越狱”的方法。通过识别和操纵特定的注意力头，研究人员成功绕过了LLM的拒绝机制，导致模型泄露敏感和私密的个人信息，包括通常会拒绝提供的信息。在四种LLM上的实验显示，信息泄露率高达至少95%，其中超过50%的泄露是真实的个人身份信息，证明了通过定向内部操纵可以提取LLM中记忆的私人数据。

> **摘要翻译:** 本文通过转向技术研究大型语言模型（LLM）中的隐私越狱，重点关注操纵激活是否能绕过LLM的对齐机制并改变对隐私相关查询（例如，某个公众人物的性取向）的响应行为。我们首先利用隐私评估器标签训练的轻量级线性探针，识别出预测对私有属性（例如性取向）拒绝行为的注意力头。接下来，我们在训练好的探针引导下，操纵这些注意力头中的一小部分激活，以诱导模型生成非拒绝响应。我们的实验表明，这些被操纵的响应经常会泄露敏感属性细节，以及数据主体的其他私人信息，例如生活事件、人际关系和个人历史，而这些信息模型通常会拒绝生成。在四种大型语言模型上的评估显示，越狱泄露率至少达到95%，其中平均超过50%的响应揭示了真实的个人信息。我们的对照研究表明，大型语言模型中记忆的私人信息可以通过对内部激活的定向操纵来提取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [133] [Evaluating Language Models For Threat Detection in IoT Security Logs](https://arxiv.org/abs/2507.02390)
> *评估语言模型在物联网安全日志威胁检测中的应用*

*Jorge J. Tejero-Fernández, Alfonso Sánchez-Macián* | **Category: cs.CR, cs.AI** | **Updated: {updated}**

**Keywords:** 物联网安全, 威胁检测, 大型语言模型, 日志分析, 异常检测

**Comment:** 

> **TL;DR:** 本文提出并评估了使用微调大型语言模型进行物联网安全日志威胁检测和缓解建议的方法。

**AI_Comments:** 本文创新性地将大型语言模型应用于物联网安全日志的威胁检测和缓解，超越了传统的机器学习方法。特别是在多类别攻击分类和提供具体缓解建议方面，展示了LLMs的潜力，为物联网安全领域带来了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 日志分析在网络安全领域至关重要，因为它们可以为网络和系统威胁的检测提供信息来源。

**Method:** 本文提出了一个使用微调大型语言模型（LLMs）进行物联网安全日志异常检测和缓解建议的流程。研究比较了三种开源LLMs在二元和多类别异常检测中的表现，采用了零样本、少样本提示和微调三种策略，并以经典机器学习分类器作为基线进行对比。通过将检测到的威胁映射到MITRE CAPEC并定义物联网特有的缓解措施，对模型进行微调，使其能够提供结合检测和建议的指导。

**Result:** 大型语言模型（LLMs）在多类别攻击分类上比相应的基线模型表现更好。经过微调的模型能够提供结合检测和推荐的指导。

**Conclusion:** 微调的大型语言模型在物联网安全日志的威胁检测（特别是多类别攻击分类）和缓解建议方面表现出优于传统方法的潜力。

> **ai_Abstract:** 本文提出了一种利用微调大型语言模型（LLMs）进行物联网安全日志中威胁检测和缓解建议的框架。研究比较了零样本、少样本和微调策略下LLMs与传统机器学习分类器在二分类和多分类异常检测上的性能。结果显示，LLMs在多类别攻击分类上表现优于基线模型，并且通过与MITRE CAPEC映射和特定缓解措施的结合，LLMs能够提供综合的威胁检测和建议指导。

> **摘要翻译:** 日志分析是网络安全领域的一个相关研究领域，因为它们可以为网络和系统威胁的检测提供信息来源。本文提出了一个使用微调大型语言模型（LLMs）进行异常检测和缓解建议的管道，该管道使用物联网安全日志。利用经典机器学习分类器作为基线，比较了三种开源LLMs在二元和多类别异常检测中的表现，采用了三种策略：零样本、少样本提示和使用物联网数据集进行微调。LLMs在多类别攻击分类上比相应的基线模型给出了更好的结果。通过将检测到的威胁映射到MITRE CAPEC，定义一套物联网特定的缓解措施，并使用这些措施对模型进行微调，模型能够提供结合检测和建议指导。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [154] [CyberRAG: An agentic RAG cyber attack classification and reporting tool](https://arxiv.org/abs/2507.02424)
> *CyberRAG：一种代理式RAG网络攻击分类和报告工具*

*Francesco Blefari, Cristian Cosentino, Francesco Aurelio Pironti, Angelo Furfaro, Fabrizio Marozzo* | **Category: cs.CR, cs.AI** | **Updated: {updated}**

**Keywords:** 网络攻击分类, 代理式RAG, 入侵检测, LLM, 网络安全

**Comment:** 

> **TL;DR:** CyberRAG是一个代理式RAG框架，通过结合专业分类器和迭代检索推理，实现对网络攻击的实时分类、解释和结构化报告，显著提高准确性并减少误报。

**AI_Comments:** CyberRAG的创新之处在于其代理式的RAG设计，通过引入中心LLM代理协调专业分类器和迭代检索推理，有效解决了传统RAG系统检索不相关上下文和解释性不足的问题。其模块化和可扩展性也十分重要，允许在不重新训练核心代理的情况下支持新的攻击类型。高准确率和高质量的解释使其在实际网络安全操作中心（SOC）环境中具有很高的实用价值和潜力，是迈向半自主网络防御的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 大型企业中的入侵检测和防御系统(IDS/IPS)每小时产生数十万警报，使安全分析师不堪重负，且需要快速发展的领域专业知识。传统的机器学习检测器虽然能减少警报量但误报率高，而标准的单次检索增强生成(RAG)管道常检索不相关上下文且无法解释其预测。

**Method:** 本文提出了CyberRAG，一个模块化、基于代理的RAG框架。一个中心LLM代理协调：(i)一组针对不同攻击家族的微调专业分类器；(ii)用于丰富和警报的工具适配器；以及(iii)一个迭代的检索和推理循环，持续查询领域特定知识库直到证据相关且自洽。它采用代理式设计，实现动态控制流和自适应推理，自主优化威胁标签和自然语言解释。

**Result:** CyberRAG在每类攻击上实现了超过94%的准确率，通过语义编排将最终分类准确率推至94.92%。生成的解释在BERTScore上得分高达0.94，在基于GPT-4的专家评估中得分为4.9/5。

**Conclusion:** 代理式、面向专家的RAG可以将高检测准确率与可靠的、可用于SOC的文本相结合，为半自主网络防御工作流提供了实用且可扩展的路径。

> **ai_Abstract:** CyberRAG是一个创新的代理式RAG框架，旨在解决企业网络安全中IDS/IPS警报过多和传统ML/RAG系统误报高、解释性差的问题。它通过一个中心LLM代理协调专业分类器和迭代检索推理循环，从领域知识库中获取相关且自洽的证据。这种代理式设计实现了动态控制和自适应推理，能自主细化威胁标签和解释，显著降低误报并提高可解释性。实验证明，CyberRAG在网络攻击分类上实现了高准确率（94.92%），并能生成高质量的解释，为构建半自主网络防御系统提供了实用且可扩展的方案。

> **摘要翻译:** 大型企业中的入侵检测和防御系统（IDS/IPS）每小时可生成数十万条警报，使安全分析师被大量日志淹没，这些日志需要深入且快速发展的领域专业知识。传统的机器学习检测器可以减少警报量，但仍然产生高误报率，而标准的单次检索增强生成（RAG）管道通常检索不相关的上下文，并且无法证明其预测的合理性。为了克服这些缺点，我们提出了 CyberRAG，一个模块化、基于代理的RAG框架，它为网络攻击提供实时分类、解释和结构化报告。一个中央LLM代理协调（i）一组经过微调的专业分类器，每个分类器都针对不同的攻击家族；（ii）用于丰富和警报的工具适配器；以及（iii）一个迭代的检索和推理循环，该循环持续查询领域特定知识库，直到证据既相关又自洽。与传统的RAG系统不同，CyberRAG 采用代理式设计，支持动态控制流和自适应推理。这种以代理为中心的架构自主地优化其威胁标签和自然语言解释，从而减少误报并增强可解释性。该框架是完全可扩展的：只需添加分类器而无需重新训练核心代理即可支持新的攻击类型。CyberRAG 已经过评估，每类准确率超过 94%，通过语义编排将最终分类准确率推至 94.92%。生成的解释在 BERTScore 中得分高达 0.94，在基于 GPT-4 的专家评估中得分为 4.9/5。这些结果表明，代理式、面向专家的 RAG 可以将高检测准确率与可靠的、可用于 SOC 的文本相结合，为半自主网络防御工作流提供了实用且可扩展的路径。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [175] [Effectively Identifying Wi-Fi Devices through State Transitions](https://arxiv.org/abs/2507.02478)
> *通过状态转换有效识别Wi-Fi设备*

*Melissa Safari, Abhishek K. Mishra, Mathieu Cunche* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** Wi-Fi设备识别, 状态转换, 管理帧, MAC地址随机化, 指纹识别

**Comment:** 

> **TL;DR:** 本文提出了一种通过分析Wi-Fi管理帧中的状态转换模式来识别Wi-Fi设备的新方法，即使在MAC地址随机化的情况下也能实现高精度识别，优于现有技术。

**AI_Comments:** 该论文的创新点在于突破了传统Wi-Fi设备识别仅依赖探测请求的局限，转而利用更丰富的管理帧中的状态转换动态。通过将设备行为建模为有限状态机并引入矩阵表示，有效捕捉了设备的行为指纹，即使在MAC地址随机化和高移动性的复杂环境中也能保持高识别精度，解决了实际应用中的一大挑战。其超越现有技术的表现，表明了该方法在设备追踪和网络安全领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Wi-Fi设备识别方法主要关注探测请求，忽略了更广泛的管理帧及其转换动态，导致在设备移动性高、环境密集的真实世界中鲁棒性不足，无法提供稳定和独特的设备签名。

**Method:** 本文提出了一种基于被动观察到的管理帧中行为动态的Wi-Fi设备指纹识别新框架。该方法将每个设备的行为建模为有限状态机，并引入基于矩阵的表示，编码结构（状态转换频率）和时间（状态间延迟）特征。这些矩阵被嵌入到紧凑的特征向量中，以便进行高效的相似性比较。

**Result:** 在多样化的真实世界环境中进行了广泛评估，该方法仅使用Wi-Fi管理帧，即可实现对非随机化设备超过86%的识别准确率。通过时间突发聚合，识别准确率进一步提高。研究结果足以大规模地唯一且一致地表征设备，并且优于现有技术。

**Conclusion:** 通过利用Wi-Fi管理帧中的状态转换模式，本文提出的方法能够有效、鲁棒地识别Wi-Fi设备，即使在MAC地址随机化和高设备移动性的复杂环境中也能保持高性能，并超越了现有技术水平。

> **ai_Abstract:** 本文提出了一种通过分析Wi-Fi管理帧中的状态转换模式来识别Wi-Fi设备的新颖框架。针对现有方法仅依赖探测请求且鲁棒性不足的问题，该框架将设备行为建模为有限状态机，并利用矩阵编码结构和时间特征，生成紧凑的特征向量进行相似性比较。实验结果表明，该方法对非随机化设备的识别准确率超过86%，且通过时间聚合可进一步提升，性能优于现有技术，能够在大规模环境下唯一且一致地表征设备。

> **摘要翻译:** Wi-Fi管理帧揭示了即使在MAC地址随机化下也持续存在的结构化通信模式。现有将随机化MAC地址与设备关联的方法主要集中在探测请求上，忽略了更广泛的管理帧及其转换动态。这种狭隘的关注限制了它们在设备移动性高、环境密集的真实世界中的鲁棒性，在这种环境中，仅靠探测活动无法产生稳定和独特的签名。在本文中，我们提出了一种新颖的框架，通过从被动观察到的管理帧中提取行为动态来对Wi-Fi设备进行指纹识别。我们将每个设备的行为建模为有限状态机，并引入基于矩阵的表示，该表示编码了结构（状态转换频率）和时间（状态间延迟）特征。这些矩阵被嵌入到紧凑的特征向量中，从而实现高效的相似性比较。通过在多样化的真实世界环境中进行的广泛评估，我们的方法仅使用Wi-Fi管理帧，即可实现对非随机化设备超过86%的识别准确率，并通过时间突发聚合观察到进一步的改进。我们的发现足以大规模地唯一且一致地表征设备，并且优于现有技术水平。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [193] [A 10-bit S-box generated by Feistel construction from cellular automata](https://arxiv.org/abs/2507.02489)
> *一种由元胞自动机和Feistel结构生成的10位S盒*

*Thomas Prévost, Bruno Martin* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** S盒, Feistel结构, 元胞自动机, 密码分析, 安全性

**Comment:** 

> **TL;DR:** 本文提出了一种基于元胞自动机和Feistel结构生成10位S盒的新方法，该S盒的安全性可与标准AES S盒媲美甚至更好。

**AI_Comments:** 本文的创新之处在于将元胞自动机与Feistel结构结合用于S盒的生成，并取得了与AES S盒媲美的安全性能。这为设计更高效、安全的密码系统提供了新的思路。其潜在应用价值在于可替代现有密码中的S盒。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种新的S盒生成方法，以获得具有良好安全性能的S盒，可能用于替代现有密码（如ASCON）中的S盒。

**Method:** 通过Feistel结构生成10位S盒，其中子置换由基于独特选择规则的5单元元胞自动机和双射仿射变换生成。元胞自动机规则和Feistel网络布局的选择均基于经验测试，以确保生成良好的伪随机输出和高质量的S盒。

**Result:** 生成的10位S盒的密码分析结果表明，其安全属性与标准AES S盒相当，有时甚至更好。

**Conclusion:** 所提出的S盒可以用于替代ASCON等密码中的5位替换。

> **ai_Abstract:** 本文提出了一种利用Feistel结构和元胞自动机生成10位S盒的新方法。该方法通过精心选择的元胞自动机规则和双射仿射变换来生成子置换。经验测试表明，所生成的S盒在安全性方面与标准AES S盒相当或更优，并有望替代ASCON等密码中的现有S盒。

> **摘要翻译:** 我们提出了一种由Feistel结构生成的新型10位S盒。子置换由基于独特选择规则的5单元元胞自动机和双射仿射变换生成。特别是，元胞自动机规则的选择是基于对其在环状元胞自动机上生成良好伪随机输出能力的经验测试。同样，Feistel网络的布局是基于关于输出S盒质量的经验数据。我们对生成的10位S盒进行了密码分析，发现其安全属性与标准AES S盒相当，有时甚至更好。我们相信我们的S盒可以用于替代ASCON等密码的5位替换。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [219] [Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures](https://arxiv.org/abs/2507.02607)
> *缓解攻击数据稀缺：SCANIA在增强车载网络安全措施方面的经验*

*Frida Sundfeldt, Bianca Widstam, Mahshid Helali Moghadam, Kuo-Yun Liang, Anders Vesterberg* | **Category: cs.CR, cs.LG, cs.SE** | **Updated: {updated}**

**Keywords:** 车载网络安全, 攻击数据生成, CAN, 入侵检测系统, 数据稀缺

**Comment:** 

> **TL;DR:** 本文提出了一种上下文感知攻击数据生成器，用于解决车载网络安全中攻击数据稀缺的问题，通过生成高质量的攻击数据来训练和评估入侵检测系统。

**AI_Comments:** 该论文的创新点在于提出了一个上下文感知的攻击数据生成器，有效解决了车载网络安全领域中攻击数据稀缺的挑战。通过生成高质量、多样化且与真实场景高度相似的攻击数据，为入侵检测系统的开发和评估提供了关键支持，对于提升车载网络安全防护能力具有重要意义。其方法兼顾了效率、可扩展性和数据保真度。

<details>
  <summary>Details</summary>

**Motivation:** 互联车辆的数字化发展和随之而来的安全风险，强调了实施车载网络安全措施（如入侵检测和响应系统）的迫切需求。然而，由于安全、成本和伦理方面的限制，在测试车辆上实施多样化攻击场景存在困难，导致攻击场景数据稀缺。这种限制要求寻找高效且有效的替代方法来生成高质量的攻击代表性数据。

**Method:** 本文提出了一种上下文感知攻击数据生成器，可以生成攻击输入和相应的车载网络日志（即控制器局域网（CAN）日志），代表各种类型的攻击，包括拒绝服务（DoS）、模糊、欺骗、挂起和重放攻击。它利用参数化攻击模型，结合CAN消息解码和攻击强度调整，以高度模拟真实场景并促进变异性来配置攻击场景。

**Result:** 在入侵检测系统（IDS）案例研究中，作者评估了所生成攻击代表性数据的实用性，并开发了两个深度神经网络IDS模型，使用生成的数据进行了实证评估。除了方法的效率和可扩展性外，IDS模型的高检测和分类能力也验证了生成数据的一致性和有效性。

**Conclusion:** 所提出的攻击数据生成器是高效且可扩展的，并且其生成的数据在训练和评估车载入侵检测系统方面表现出高一致性和有效性，有助于缓解车载网络安全领域攻击数据稀缺的问题。

> **ai_Abstract:** 本文提出了一种上下文感知攻击数据生成器，旨在解决车载网络安全领域中攻击数据稀缺的问题。该生成器能够创建高质量的攻击数据和对应的CAN日志，涵盖多种攻击类型（如DoS、模糊、欺骗、挂起和重放攻击），并通过参数化模型和强度调整确保数据与真实场景的高度相似性及多样性。通过在入侵检测系统（IDS）案例中进行评估，研究证明了所生成数据的实用性、效率和可扩展性，并且基于这些数据训练的深度神经网络IDS模型展现出卓越的检测和分类能力，验证了数据的有效性。

> **摘要翻译:** 互联车辆的数字化演进及其随之而来的安全风险，强调了实施车载网络安全措施（如入侵检测和响应系统）的迫切需求。攻击场景的持续发展进一步凸显了对能够检测不断演变、未知和复杂威胁的自适应检测机制的需求。有效利用机器学习驱动的技术有助于应对这一挑战。然而，由于安全、成本和伦理方面的考虑，在测试车辆上实施多样化攻击场景存在限制，导致代表攻击场景的数据稀缺。这种限制要求寻找高效且有效的替代方法来生成高质量的攻击代表性数据。本文提出了一种上下文感知攻击数据生成器，该生成器生成攻击输入和相应的车载网络日志（即控制器局域网（CAN）日志），代表各种类型的攻击，包括拒绝服务（DoS）、模糊、欺骗、挂起和重放攻击。它利用参数化攻击模型，结合CAN消息解码和攻击强度调整，以高度模拟真实场景并促进变异性来配置攻击场景。我们在入侵检测系统（IDS）案例研究中评估了所生成攻击代表性数据的实用性，在该研究中，我们开发并对两个深度神经网络IDS模型使用生成的数据进行了实证评估。除了方法的效率和可扩展性外，IDS模型的高检测和分类能力也验证了生成数据的一致性和有效性。在这项经验研究中，我们还详细阐述了影响数据与真实场景保真度的方面，并提供了其应用方面的见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [230] [SAT-BO: Verification Rule Learning and Optimization for FraudTransaction Detection](https://arxiv.org/abs/2507.02635)
> *SAT-BO：用于欺诈交易检测的验证规则学习与优化*

*Mao Luo, Zhi Wang, Yiwen Huang, Qingyun Zhang, Zhouxing Su, Zhipeng Lv, Wen Hu, Jianguo Li* | **Category: cs.CR, cs.DB** | **Updated: {updated}**

**Keywords:** 欺诈交易检测, 验证规则, 规则缺陷, 数据安全

**Comment:** 

> **TL;DR:** 电子支付和数据库安全中，手动验证规则易受攻击，亟需系统化方法识别其缺陷以防范潜在损失。

**AI_Comments:** 这篇论文的摘要清晰地阐述了电子支付和数据库安全领域中，手动验证规则面临的严重问题：缺乏系统性健壮性保障，易被恶意利用。这突出了开发一种系统化、自动化方法来识别和优化这些规则的重要性，以应对潜在的巨大经济损失。摘要本身并未详述其提出的SAT-BO方法的具体创新点或局限性，但强调了解决当前规则缺陷的迫切需求。

<details>
  <summary>Details</summary>

**Motivation:** 电子支付平台每天处理数十亿笔交易，即使微小错误也可能导致巨大经济损失。现有由领域专家手动构建的验证规则缺乏系统性健壮性保障，易受攻击。此外，数据库维护者编写的复杂验证规则也可能不完善，恶意请求可能绕过这些规则。因此，系统地识别这些规则缺陷的需求应运而生。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本论文摘要指出，电子支付和数据库安全领域中，现有由领域专家手动构建的验证规则因缺乏系统性健壮性保障而易受攻击，可能导致重大经济损失。鉴于专家规则的不完善性，以及恶意请求可能绕过这些规则的风险，迫切需要一种系统方法来识别这些规则中的缺陷。

> **摘要翻译:** 电子支付平台预计每天处理数十亿笔交易，累计价值可能达到数万亿美元。在如此高交易量的环境中，即使是微小的错误也可能导致巨大的经济损失。为了降低这种风险，领域专家通常会手动构建验证规则，用于识别和审查生产环境中的交易。然而，由于缺乏系统方法来确保这些验证规则对漏洞的健壮性，它们仍然容易受到攻击。为了确保数据安全，数据库维护者通常会编写复杂的验证规则来检查查询/更新请求是否有效。然而，专家编写的规则通常不完善，恶意请求可能会绕过这些规则。因此，系统地识别规则缺陷的需求应运而生。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [241] [Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents](https://arxiv.org/abs/2507.02699)
> *控制危局：评估LLM驱动的电子邮件代理的安全状况*

*Jiangrong Wu, Yuhong Nan, Jianliang Wu, Zitong Yao, Zibin Zheng* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** LLM代理, 电子邮件安全, 劫持攻击, EAHawk, 安全评估

**Comment:** 

> **TL;DR:** LLM电子邮件代理存在严重安全漏洞，易受新型电子邮件代理劫持（EAH）攻击，攻击者仅需极少尝试即可远程完全控制。

**AI_Comments:** 本研究通过提出创新的电子邮件代理劫持（EAH）攻击和EAHawk评估管道，填补了LLM电子邮件代理安全研究的空白。其大规模实证结果令人震惊，揭示了这类日益普及的应用中存在的普遍且严重的漏洞，对LLM代理生态系统的安全提出了紧急警告，强调了开发更强健安全机制的必要性。

<details>
  <summary>Details</summary>

**Motivation:** LLM电子邮件代理应用日益普及，但其安全机制尚未得到充分探索，缺乏对其潜在安全风险的全面研究。

**Method:** 本文进行了首次针对LLM电子邮件代理的深入系统安全研究。提出了“电子邮件代理劫持（EAH）”攻击，通过外部电子邮件资源覆盖原始提示，实现远程控制。为大规模评估，开发了EAHawk管道，并对14个LLM代理框架、63个代理应用、12个LLM和20个电子邮件服务进行了实证研究，生成了1,404个真实实例进行评估。

**Result:** 实验结果显示，所有1,404个电子邮件代理实例均成功被劫持。平均仅需2.03次攻击尝试即可控制一个实例，对于某些LLM，平均尝试次数甚至低至1.23次。

**Conclusion:** LLM电子邮件代理应用程序的安全机制存在严重缺陷，极易受到电子邮件代理劫持（EAH）攻击，这表明在LLM驱动的应用程序中存在重大的未被发现的安全风险。

> **ai_Abstract:** 本研究首次对LLM驱动的电子邮件代理的安全状况进行了系统性评估。论文提出了“电子邮件代理劫持（EAH）”攻击，该攻击通过外部电子邮件资源覆盖代理的原始提示，使攻击者能够远程控制代理并执行恶意操作。为验证此攻击，研究者开发了EAHawk评估管道，并对14个LLM代理框架、63个应用、12个LLM和20个电子邮件服务进行了大规模实证研究，共生成1,404个真实实例。结果显示，所有实例均成功被劫持，平均仅需2.03次尝试，某些LLM甚至低至1.23次，揭示了这些代理应用中存在的严重安全漏洞。

> **摘要翻译:** 大型语言模型（LLM）能力的不断提升，导致了LLM代理应用程序的迅速普及，开发者通过让LLM访问外部资源来增强其能力，以支持复杂的任务执行。其中，LLM电子邮件代理应用程序是广泛使用的一类，因为电子邮件仍然是用户重要的通信媒介。LLM电子邮件代理能够利用LLM驱动的推理来管理和回复电子邮件，并通过外部电子邮件API（例如，发送电子邮件）自主执行用户指令。然而，尽管它们部署和实用性日益增长，LLM电子邮件代理应用程序的安全机制仍未得到充分探索。目前，对于这些代理应用程序中潜在的安全风险及其更广泛的影响，还没有全面的研究。
在本文中，我们对LLM电子邮件代理进行了首次深入且系统的安全研究。我们提出了电子邮件代理劫持（EAH）攻击，该攻击通过外部电子邮件资源覆盖电子邮件代理的原始提示，允许攻击者远程控制电子邮件代理，并在用户不知情的情况下进一步执行特定的攻击场景。
为了便于大规模评估，我们提出了EAHawk，这是一个评估LLM电子邮件代理应用程序EAH攻击的管道。通过EAHawk，我们对14个代表性的LLM代理框架、63个代理应用程序、12个LLM和20个电子邮件服务进行了实证研究，从而生成了1,404个真实的电子邮件代理实例进行评估。实验结果表明，所有1,404个实例都成功被劫持；平均而言，仅需2.03次攻击尝试即可控制一个电子邮件代理实例。更糟糕的是，对于某些LLM，实现完全代理控制所需的平均尝试次数甚至低至1.23次。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [250] [Quantifying Classifier Utility under Local Differential Privacy](https://arxiv.org/abs/2507.02727)
> *量化局部差分隐私下的分类器效用*

*Ye Zheng, Yidan Hu* | **Category: cs.CR, E.3** | **Updated: {updated}**

**Keywords:** 局部差分隐私, 分类器效用, 鲁棒性分析, 隐私机制, 黑盒分类器

**Comment:** 

> **TL;DR:** 本文提出了一个框架，通过将LDP扰动视为围绕原始数据的集中，把分类器效用分析转化为其在集中区域的鲁棒性分析，从而量化局部差分隐私（LDP）下的分类器效用。该框架适用于任何LDP机制和黑盒分类器，且理论结果与经验观察吻合。

**AI_Comments:** 该论文的创新之处在于提出了一个普适的理论框架，将局部差分隐私下的分类器效用量化问题转化为鲁棒性分析，适用于各种LDP机制和黑盒分类器，具有广泛的适用性。其重要性在于为LDP机制的选择和参数设定提供了理论指导，有助于在隐私保护和数据效用之间取得平衡。论文也指出，在低维输入空间中，理论与经验结果的吻合度更高，这可能暗示在更高维度空间中存在进一步研究和改进的空间。

<details>
  <summary>Details</summary>

**Motivation:** 局部差分隐私（LDP）通过在数据源引入扰动来提供严格的隐私保障，但量化这些扰动对分类器效用（特别是复杂或黑盒分类器）的影响仍然是一个理论挑战。

**Method:** 本文提出了一个理论框架，用于量化LDP机制下的分类器效用。关键在于将LDP扰动视为以特定概率集中在原始数据周围，从而将分类器的效用分析转化为其在该集中区域的鲁棒性分析。该框架将LDP机制的集中度分析与分类器的鲁棒性分析相结合，将LDP机制视为通用分布函数，将分类器视为黑盒函数，因此适用于任何LDP机制和分类器。此外，研究还结合了两种新颖的细化技术进行了案例研究。

**Result:** 该框架可直接应用于指导给定分类器的LDP机制和隐私参数选择。分析表明，在常见场景下，基于分段的机制比其他替代方案具有更好的效用。案例研究结果表明，理论效用量化与经验观察结果高度吻合，尤其是在分类器在低维输入空间中运行时。

**Conclusion:** 本文提出的框架成功地量化了局部差分隐私下的分类器效用，其理论分析结果与经验观察结果吻合，证明了该方法的有效性和普适性，并为LDP机制和参数选择提供了指导。

> **ai_Abstract:** 该论文提出了一个通用的理论框架，用于量化局部差分隐私（LDP）机制下的分类器效用。核心思想是将LDP扰动引起的效用分析转化为分类器在数据集中区域的鲁棒性分析。该框架适用于任何LDP机制和黑盒分类器，并结合新颖的细化技术进行了案例研究。研究结果表明，理论量化结果与经验观察高度一致，并发现分段机制在效用方面表现更优，为LDP机制和参数选择提供了指导。

> **摘要翻译:** 局部差分隐私（LDP）通过在数据源引入扰动，为个人数据提供了严格且可量化的隐私保障。然而，量化这些扰动对分类器效用（特别是复杂或黑盒分类器）的影响仍然是一个理论挑战。本文提出了一个框架，用于理论上量化LDP机制下的分类器效用。其关键见解是，LDP扰动以特定概率集中在原始数据周围，将分类器的效用分析转化为其在该集中区域的鲁棒性分析。我们的框架将LDP机制的集中度分析与分类器的鲁棒性分析相结合。它将LDP机制视为通用分布函数，将分类器视为黑盒函数，因此适用于任何LDP机制和分类器。我们的效用量化的一种直接应用是指导给定分类器的LDP机制和隐私参数的选择。值得注意的是，我们的分析表明，在常见场景下，基于分段的机制比其他替代方案具有更好的效用。利用该框架以及两种新颖的细化技术，我们对典型机制-分类器组合的效用量化进行了案例研究。结果表明，我们的理论效用量化与经验观察结果高度吻合，尤其是在分类器在低维输入空间中运行时。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [260] [Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](https://arxiv.org/abs/2507.02735)
> *Meta SecAlign: 一种抵御提示注入攻击的安全基础大语言模型*

*Sizhe Chen, Arman Zharmagambetov, David Wagner, Chuan Guo* | **Category: cs.CR, cs.AI** | **Updated: {updated}**

**Keywords:** 提示注入攻击, 大语言模型, 开源, 模型级防御, Meta SecAlign

**Comment:** 

> **TL;DR:** Meta SecAlign是首个内置模型级防御的开源大语言模型，旨在有效抵御提示注入攻击，并在性能上媲美商用模型。

**AI_Comments:** Meta SecAlign的创新之处在于其作为首个开源且开放权重的内置模型级防御LLM，填补了AI安全社区在开放研究方面的空白。其重要性在于提供了一个透明、可验证的平台来共同开发和测试针对提示注入攻击的防御措施，这对于提升AI系统的整体安全性至关重要。该工作通过提供详细的训练配方，促进了知识共享和社区协作。

<details>
  <summary>Details</summary>

**Motivation:** 提示注入攻击对集成LLM的应用构成重大安全威胁。虽然模型级防御已被证明有效，但目前商业级模型多采用闭源部署。为了推动AI安全社区通过开放研究共同开发攻击与防御，从而抵御提示注入攻击，研究人员认为需要开源模型。

**Method:** 研究人员开发了Meta SecAlign，这是第一个内置模型级防御的开源且开放权重的大语言模型。该模型采用了SOTA SecAlign防御的改进版本，并提供了完整的训练方案细节。

**Result:** 在9个实用基准和7个安全基准上的评估表明，尽管Meta SecAlign是基于通用指令微调数据集训练的，但它在包括工具调用和智能体网络导航在内的未见下游任务以及通用指令遵循方面都提供了安全性。其最佳模型Meta-SecAlign-70B在抵御提示注入攻击方面达到了最先进的鲁棒性，并且在实用性方面与内置模型级防御的闭源商业LLM相当。

**Conclusion:** Meta SecAlign是首个开源且开放权重的内置模型级防御大语言模型，它在抵御提示注入攻击方面表现出卓越的鲁棒性，并能与闭源商业模型媲美，为AI安全社区提供了重要的开放研究工具。

> **ai_Abstract:** 该论文介绍了Meta SecAlign，这是首个内置模型级防御的开源且开放权重的大语言模型，旨在抵御提示注入攻击。该模型采用改进的SOTA SecAlign防御方法训练，并在多项实用和安全基准测试中展现出卓越性能，尤其是在抵御提示注入攻击方面达到了最先进的鲁棒性，同时在实用性上可与闭源商业LLM媲美。Meta SecAlign的发布旨在推动AI安全领域的开放研究。

> **摘要翻译:** 提示注入攻击对集成LLM的应用构成重大安全威胁。模型级防御已显示出强大的有效性，但目前在商业级模型中以闭源方式部署。我们认为AI安全社区需要开源模型，通过开放研究共同开发攻击和防御，从而推动抵御提示注入攻击的科学进展。为此，我们开发了Meta SecAlign，这是第一个内置模型级防御的开源且开放权重的大语言模型，其性能达到了商业级模型的水平。我们提供了完整的训练方案细节，该方案采用了SOTA SecAlign防御的改进版本。在9个实用基准和7个安全基准上的评估表明，Meta SecAlign尽管是在通用指令微调数据集上训练的，但在未见的下游任务（包括工具调用和智能体网络导航）以及通用指令遵循方面都提供了安全性。我们最好的模型——Meta-SecAlign-70B——在抵御提示注入攻击方面达到了最先进的鲁棒性，并且在实用性方面与内置模型级防御的闭源商业LLM相当。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [268] [Early Signs of Steganographic Capabilities in Frontier LLMs](https://arxiv.org/abs/2507.02737)
> *前沿大型语言模型隐写能力早期迹象*

*Artur Zolkowski, Kei Nishimura-Gasparian, Robert McCarthy, Roland S. Zimmermann, David Lindner* | **Category: cs.CR, cs.AI, cs.CL, cs.LG** | **Updated: {updated}**

**Keywords:** 大型语言模型, 隐写术, 风险评估, 编码推理, 模型监测

**Comment:** 

> **TL;DR:** 研究发现当前LLM尚未能有效隐藏短消息，但在额外辅助下可进行编码推理，表明其隐写能力处于萌芽阶段，未来可能构成风险。

**AI_Comments:** 这篇论文揭示了LLM潜在的滥用风险，其创新点在于首次系统性地评估了LLM的隐写能力。尽管目前LLM的隐写能力有限，但这项研究为未来LLM安全监测和风险防范提供了重要的早期预警和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 监测大型语言模型（LLM）的输出对于减轻滥用和错位风险至关重要。然而，LLM可能通过隐写术（在看似无害的生成内容中编码隐藏信息）来规避监测。本文旨在评估前沿LLM的隐写能力，以更好地理解它们构成的风险。

**Method:** 研究评估了前沿LLM的隐写能力，重点关注两种类型的隐写术：传递编码消息和执行编码推理。实验观察了模型在标准条件下以及在提供额外辅助（如使用未受监控的草稿板和协调编码方案）时的表现。还测试了模型在简单状态跟踪问题中执行基本编码推理的能力，包括使用其自身和预定义方案（如十六进制）进行推理。

**Result:** 研究发现，当前模型在标准条件下无法在输出中编码短消息而不被监测器发现。然而，如果提供额外辅助（例如使用未受监控的草稿板和协调编码方案），它们可以成功。此外，研究发现了模型在简单状态跟踪问题中执行基本编码推理的早期迹象，包括使用其自身和预定义方案（如十六进制）进行推理的能力。尽管如此，模型很少能巧妙地将推理隐藏在封面任务中以欺骗监测器。

**Conclusion:** 总体而言，我们的结果表明当前的LLM展现出初期的隐写能力。虽然这些能力目前可能不足以绕过精心设计的监测器，但未来可能会发生变化。

> **ai_Abstract:** 本研究评估了前沿大型语言模型（LLM）的隐写能力，以理解其潜在风险。研究关注传递编码消息和执行编码推理两种类型。结果显示，在标准条件下，LLM难以在输出中隐藏短消息，但在额外辅助下（如使用草稿板和预设编码），它们可以成功。此外，研究发现了LLM进行基本编码推理的早期迹象，尽管其难以巧妙隐藏推理。总体而言，当前LLM的隐写能力尚处于萌芽阶段，不足以规避现有监测，但未来可能发展。

> **摘要翻译:** 监测大型语言模型（LLM）的输出对于减轻滥用和错位风险至关重要。然而，LLM可能通过隐写术：在看似无害的生成内容中编码隐藏信息来规避监测。在本文中，我们评估了前沿LLM的隐写能力，以更好地理解它们构成的风险。我们重点关注两种类型的隐写术：传递编码消息和执行编码推理。我们发现当前模型在标准条件下无法在输出中编码短消息而不被监测器发现。然而，如果提供额外辅助，例如使用未受监控的草稿板和协调编码方案，它们可以成功。我们还发现了模型在简单状态跟踪问题中可以执行基本编码推理的早期迹象。这包括一些使用其自身和预定义方案（包括十六进制等编码方案）进行推理的能力。尽管如此，它们很少能巧妙地将推理隐藏在封面任务中以欺骗监测器。总的来说，我们的结果表明当前的LLM展现出初期的隐写能力。虽然这些能力目前可能不足以绕过精心设计的监测器，但未来可能会发生变化。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [276] [NVIDIA GPU Confidential Computing Demystified](https://arxiv.org/abs/2507.02770)
> *NVIDIA GPU 机密计算揭秘*

*Zhongshu Gu, Enriquillo Valdez, Salman Ahmed, Julian James Stephen, Michael Le, Hani Jamjoom, Shixuan Zhao, Zhiqiang Lin* | **Category: cs.CR** | **Updated: {updated}**

**Keywords:** GPU机密计算, NVIDIA Hopper, 安全分析, 漏洞发现, 专有系统

**Comment:** 

> **TL;DR:** 揭秘NVIDIA GPU机密计算的内部工作机制和安全漏洞。

**AI_Comments:** 该论文的创新之处在于，它深入剖析了一个高度专有且缺乏公开文档的复杂系统——NVIDIA GPU机密计算。在信息极度匮乏的情况下，研究人员通过整合多方信息、对唯一开源组件进行逆向工程和实验，成功揭示了其内部机制并发现了安全漏洞，这对于提升GPU机密计算的透明度和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** NVIDIA GPU机密计算（GPU-CC）虽然为AI工作负载提供了安全高效的解决方案，但其底层专有系统的复杂性和缺乏透明度给安全研究人员带来了巨大挑战。本研究旨在通过整合零散信息和实验分析，深入理解GPU-CC的架构和运行机制。

**Method:** 研究团队通过整合来自不同来源的零散信息，对NVIDIA GPU-CC系统进行了分析。具体方法包括：首先讨论威胁模型和安全原则；然后深入分析每个系统组件的低层细节；接着对作为唯一开源组件的GPU内核模块进行检测，并进行一系列实验以识别安全弱点和潜在漏洞；对于无法通过实验触及的组件，提出了有根据的推测。

**Result:** 研究识别了NVIDIA GPU机密计算系统的安全弱点和潜在漏洞，并已负责任地向NVIDIA PSIRT团队报告了所有安全发现。

**Conclusion:** 本论文成功揭秘了NVIDIA GPU机密计算系统的实现细节，并发现了其潜在的安全弱点，为安全研究人员提供了对其架构和操作机制的深入理解。

> **ai_Abstract:** 本研究旨在揭示NVIDIA GPU机密计算（GPU-CC）的内部工作机制，该技术虽然为AI工作负载提供了安全处理敏感数据的能力，但其专有性质和信息不透明性阻碍了安全研究。作者通过整合零散信息、分析威胁模型、深入探讨系统组件，并对GPU内核模块进行实验检测，成功识别了GPU-CC的安全弱点和潜在漏洞，并向NVIDIA报告了发现。

> **摘要翻译:** GPU 机密计算 (GPU-CC) 作为 NVIDIA Hopper 架构的一部分被引入，将信任边界扩展到传统的基于 CPU 的机密计算之外。这项创新使 GPU 能够安全地处理 AI 工作负载，为处理敏感数据提供了强大而高效的解决方案。对于终端用户而言，向 GPU-CC 模式的过渡是无缝的，无需修改现有的 AI 应用程序。然而，这种易于采用的特点与底层专有系统的复杂性形成鲜明对比。透明度的缺乏给寻求深入了解 GPU-CC 架构和操作机制的安全研究人员带来了重大挑战。
分析 NVIDIA GPU-CC 系统所面临的挑战源于详细规范的稀缺、生态系统的专有性质以及产品设计的复杂性。在本文中，我们旨在通过拼凑来自各种来源的零散和不完整信息，揭秘 NVIDIA GPU-CC 系统的实现。我们的调查从对威胁模型和安全原则的高层次讨论开始，然后深入探讨每个系统组件的低层细节。我们对 GPU 内核模块（系统唯一开源组件）进行了检测，并进行了一系列实验以识别安全弱点和潜在漏洞。对于通过实验无法触及的某些组件，我们提出了对其内部工作机制的合理推测。我们已负责任地向 NVIDIA PSIRT 团队报告了本文中提出的所有安全发现。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [13] [STELLA: Self-Evolving LLM Agent for Biomedical Research](https://arxiv.org/abs/2507.02004)
> *STELLA：用于生物医学研究的自进化大型语言模型智能体*

*Ruofan Jin, Zaixi Zhang, Mengdi Wang, Le Cong* | **Category: cs.AI, cs.CL, q-bio.BM** | **Updated: {updated}**

**Keywords:** 自进化AI智能体, 生物医学研究, 大型语言模型, 工具学习, 多智能体系统

**Comment:** 

> **TL;DR:** STELLA是一个自进化的AI智能体，通过动态扩展工具集和改进推理策略，克服了传统AI智能体在生物医学研究中适应性差的限制，并在多个生物医学基准测试中达到了最先进的准确性，且性能随经验提升。

**AI_Comments:** STELLA的核心创新在于其“自进化”能力，通过动态管理推理策略和工具集，使其能够自主适应和学习，而非依赖静态预设。这种能力对于处理快速变化的生物医学领域尤为重要，因为它能克服传统AI智能体在适应性和可扩展性上的局限。其性能随经验提升的特性，也突出了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学数据、工具和文献的快速增长导致研究领域日益碎片化，超出了人类的专业知识范围。虽然AI智能体提供了一种解决方案，但它们通常依赖静态、手动策划的工具集，限制了其适应和扩展的能力。

**Method:** STELLA采用多智能体架构，通过两种核心机制自主提升自身能力：一个用于推理策略的不断进化的模板库（Template Library）和一个动态的工具海洋（Tool Ocean），其中工具创建智能体（Tool Creation Agent）会自动发现并整合新的生物信息学工具。这使得STELLA能够从经验中学习。

**Result:** STELLA在生物医学基准测试套件中取得了最先进的准确性，在“人类的最后一次考试：生物医学”中得分约26%，在LAB-Bench: DBQA中得分54%，在LAB-Bench: LitQA中得分63%，表现优于领先模型高达6个百分点。更重要的是，其性能随经验系统性地提高；例如，在“人类的最后一次考试”基准测试中，随着试验次数的增加，其准确性几乎翻倍。

**Conclusion:** STELLA代表了AI智能体系统迈向能够学习和成长、动态扩展其专业知识以加速生物医学发现步伐的重大进展。

> **ai_Abstract:** STELLA是一个为生物医学研究设计的自进化AI智能体，旨在解决现有AI智能体在面对不断增长的生物医学数据和工具时的适应性限制。它采用多智能体架构，通过维护一个不断进化的推理策略模板库和一个由工具创建智能体动态扩展的工具海洋来学习和提升自身能力。实验证明，STELLA在多个生物医学基准测试中取得了最先进的性能，并能随着经验的积累显著提高准确性，预示着AI智能体在加速生物医学发现方面的巨大潜力。

> **摘要翻译:** 生物医学数据、工具和文献的快速增长创造了一个碎片化的研究格局，其发展速度超越了人类的专业知识。虽然AI智能体提供了一种解决方案，但它们通常依赖静态、手动策划的工具集，限制了其适应和扩展的能力。在此，我们介绍了STELLA，一个旨在克服这些限制的自进化AI智能体。STELLA采用多智能体架构，通过两种核心机制自主提升自身能力：一个用于推理策略的不断进化的模板库和一个动态的工具海洋，其中工具创建智能体会自动发现并整合新的生物信息学工具。这使得STELLA能够从经验中学习。我们证明了STELLA在生物医学基准测试套件中取得了最先进的准确性，在“人类的最后一次考试：生物医学”中得分约26%，在LAB-Bench: DBQA中得分54%，在LAB-Bench: LitQA中得分63%，表现优于领先模型高达6个百分点。更重要的是，我们表明其性能随经验系统性地提高；例如，在“人类的最后一次考试”基准测试中，随着试验次数的增加，其准确性几乎翻倍。STELLA代表了AI智能体系统迈向能够学习和成长、动态扩展其专业知识以加速生物医学发现步伐的重大进展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [42] [HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection](https://arxiv.org/abs/2507.02073)
> *HCVR：一种结合相关性感知投票规则的混合特征选择方法*

*Nikita Bhedasgaonkar, Rushikesh K. Joshi* | **Category: cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 特征选择, HCVR, 相关性感知, 混合方法, 投票规则

**Comment:** 11 pages, 5 tables, 2 figures

> **TL;DR:** HCVR是一种轻量级的混合特征选择方法，结合了参数间和参数到目标的关联性，通过相关性感知投票规则来消除冗余特征并保留相关特征，在SPAMBASE数据集上优于传统方法。

**AI_Comments:** HCVR的创新点在于其混合了P2P和P2T相关性，并引入了“相关性感知投票规则”这一机制，使其能够灵活地进行特征选择。其“轻量级”和“每步消除多个特征”的特点可能使其在处理高维数据时具有较高的效率。在SPAMBASE数据集上的性能提升表明了其有效性，但其在更广泛数据集或不同领域中的普适性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决特征选择中冗余特征和相关特征的识别问题，并提供一种轻量级的、结合不同相关性度量的混合方法。

**Method:** HCVR（Hybrid approach with Correlation-aware Voting Rules）是一种轻量级的基于规则的特征选择方法。它结合了参数到参数（P2P）和参数到目标（P2T）的相关性。该方法是结合了非迭代和迭代过滤方法的混合降维技术。它采用贪婪的后向消除策略，每一步可能消除多个特征。规则通过投票机制对特征进行决策，通过多数投票决定保留或丢弃特征。这些规则利用特征对之间以及特征与目标之间的相关性阈值。

**Result:** 将HCVR应用于SPAMBASE数据集的结果显示，与传统的非迭代（CFS、mRMR和MI）和迭代（RFE、SFS和遗传算法）技术相比，性能有所改进。效果评估基于应用过滤后不同分类器的性能。

**Conclusion:** HCVR作为一种混合的、相关性感知的特征选择方法，能够有效地消除冗余特征并保留相关特征，从而提高分类器的性能，优于多种现有特征选择技术。

> **ai_Abstract:** 本文提出了一种名为HCVR的混合特征选择方法，它结合了参数间（P2P）和参数到目标（P2T）的相关性。HCVR是一种轻量级、基于规则的贪婪后向消除方法，通过相关性感知投票规则来识别并保留相关特征，同时剔除冗余特征。在SPAMBASE数据集上的实验结果表明，HCVR在性能上优于多种传统的非迭代和迭代特征选择技术。

> **摘要翻译:** 在本文中，我们提出了HCVR（Hybrid approach with Correlation-aware Voting Rules），一种轻量级的基于规则的特征选择方法，它结合了参数到参数（P2P）和参数到目标（P2T）相关性，以消除冗余特征并保留相关特征。该方法是用于降维的非迭代和迭代过滤方法的混合。它是一种贪婪方法，通过后向消除工作，每一步可能消除多个特征。规则有助于对特征进行投票，并通过多数投票决定保留或丢弃。规则利用每对特征之间以及特征与目标之间的相关性阈值。我们提供了HCVR应用于SPAMBASE数据集的结果。结果显示，与传统的非迭代（CFS、mRMR和MI）和迭代（RFE、SFS和遗传算法）技术相比，性能有所改进。有效性是根据应用过滤后不同分类器的性能进行评估的。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [67] [Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](https://arxiv.org/abs/2507.02076)
> *预算内推理：大型语言模型中自适应和可控测试时间计算的综述*

*Mohammad Ali Alomrani, Yingxue Zhang, Derek Li, Qianyi Sun, Soumyasundar Pal, Zhanguang Zhang, Yaochen Hu, Rohan Deepak Ajwani, Antonios Valkanas, Raika Karimi, Peng Cheng, Yunzhou Wang, Pengyi Liao, Hanrui Huang, Bin Wang, Jianye Hao, Mark Coates* | **Category: cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 大型语言模型, 推理效率, 测试时间计算, 自适应计算, 计算预算

**Comment:** 

> **TL;DR:** 本综述回顾了旨在提高大型语言模型推理计算效率的测试时间计算（TTC）策略，并提出了一个两层分类法，强调了TTC方法的实用控制、适应性和可扩展性。

**AI_Comments:** 这篇综述深入探讨了LLMs在推理效率方面的核心痛点，并提出了一个清晰的分类框架来理解和评估现有的测试时间计算（TTC）策略。其创新之处在于强调了TTC方法的实用控制、适应性和可扩展性，这对于LLMs的实际部署和应用至关重要。该工作为未来开发更高效、更智能的LLMs指明了方向，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLMs）在推理时效率低下，无论任务复杂性如何都应用固定的推理时间计算，导致对简单问题过度思考而对困难问题思考不足。

**Method:** 本综述全面回顾了高效的测试时间计算（TTC）策略，旨在提高LLM推理的计算效率。文中引入了一个两层分类法，区分了L1-可控性（在固定计算预算下操作的方法）和L2-适应性（根据输入难度或模型置信度动态调整推理规模的方法）。同时，对领先的专有LLMs在不同数据集上进行了基准测试。

**Result:** 基准测试突出了推理性能和token使用之间的关键权衡。与之前的效率推理综述相比，本综述强调了TTC方法的实用控制、适应性和可扩展性。

**Conclusion:** 本综述讨论了混合思维模型等新兴趋势，并指出了未来工作中的关键挑战，以使大型语言模型在计算上更高效、更鲁棒，并更能响应用户约束。

> **ai_Abstract:** 本综述探讨了大型语言模型（LLMs）推理效率低下的问题，即它们在处理不同复杂度的任务时采用固定的计算量。论文全面审查了测试时间计算（TTC）策略，旨在提升LLM推理的计算效率。文章提出了一个两层分类法，区分了固定预算下的可控性（L1）和动态适应输入难度的可适应性（L2）。通过对领先LLMs的基准测试，论文揭示了推理性能与token使用之间的权衡，并强调了TTC方法在实际控制、适应性和可扩展性方面的优势。最后，文章讨论了新兴趋势和未来使LLMs更高效、更鲁棒的挑战。

> **摘要翻译:** 大型语言模型（LLMs）已迅速发展成为能够解决广泛任务的通用代理。然而，当前模型在推理方面仍然效率低下：它们无论任务复杂性如何都应用固定的推理时间计算，经常对简单问题过度思考，而对困难问题思考不足。本综述全面回顾了高效的测试时间计算（TTC）策略，旨在提高LLM推理的计算效率。我们引入了一个两层分类法，区分了L1-可控性（在固定计算预算下操作的方法）和L2-适应性（根据输入难度或模型置信度动态调整推理规模的方法）。我们对领先的专有LLMs在不同数据集上进行了基准测试，突出了推理性能和token使用之间的关键权衡。与之前的效率推理综述相比，我们的综述强调了TTC方法的实用控制、适应性和可扩展性。最后，我们讨论了混合思维模型等新兴趋势，并指出了未来工作中的关键挑战，以使LLMs在计算上更高效、更鲁棒，并更能响应用户约束。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [92] [Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab](https://arxiv.org/abs/2507.02083)
> *使用系统生物学干实验室测量语言模型的科学能力*

*Haonan Duan, Stephen Zhewen Lu, Caitlin Fiona Harrigan, Nishkrit Desai, Jiarui Lu, Michał Koziarski, Leonardo Cotta, Chris J. Maddison* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 大型语言模型, 科学能力, 系统生物学, 干实验室, 实验设计

**Comment:** 

> **TL;DR:** SciGym是一个新的基准，通过模拟生物系统来评估LLM的科学实验设计和分析能力，发现LLM在复杂系统中的表现仍有显著提升空间。

**AI_Comments:** 这篇论文的创新之处在于提出了SciGym这一“干实验室”基准，有效解决了评估LLM在科学实验设计和分析能力时湿实验室成本过高的问题。通过利用系统生物学模型生成模拟数据，为LLM提供了一个可扩展且经济的测试环境。其重要性在于填补了现有LLM科学能力评估的空白，聚焦于核心的科学推理和决策能力。研究结果也明确指出了当前LLM在处理复杂科学问题时的局限性，为未来LLM在科学发现领域的改进指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的对大型语言模型（LLMs）科学能力的评估未能有效测试实验设计和结果解释等核心科学能力，因为湿实验室实验在专业知识、时间和设备方面成本过高。

**Method:** 引入了SciGym，这是一个评估LLM在开放式科学发现任务中迭代实验设计和分析能力的基准。SciGym通过运行生物系统的“干实验室”来克服湿实验室成本的挑战，这些模型以系统生物学标记语言（SBML）编码，可高效生成模拟数据。

**Result:** 在137个小型系统上评估了六个前沿LLM，并发布了总共350个系统。评估显示，虽然能力更强的模型表现出卓越的性能，但所有模型的性能都随着系统复杂性的增加而显著下降。

**Conclusion:** LLM代理的科学能力仍有很大的提升空间。

> **ai_Abstract:** 本文介绍了SciGym，一个新颖的基准平台，旨在评估大型语言模型（LLMs）在模拟生物系统中的科学实验设计和结果分析能力。SciGym通过构建“干实验室”环境，克服了传统湿实验室实验成本高昂的限制。研究人员使用系统生物学标记语言（SBML）编码的模型生成模拟数据，并在137个系统上测试了六个前沿LLMs。结果表明，尽管更强大的LLM表现更好，但所有模型的性能都随系统复杂性增加而显著下降，揭示了LLM在科学发现能力方面仍有巨大改进空间。

> **摘要翻译:** 设计实验和解释结果是核心的科学能力，尤其是在生物学中，研究人员通过扰动复杂系统来揭示其底层机制。最近评估大型语言模型（LLMs）科学能力的努力未能测试这些能力，因为湿实验室实验在专业知识、时间和设备方面成本过高。我们引入了SciGym，这是一个一流的基准，用于评估LLMs在开放式科学发现任务中迭代实验设计和分析的能力。SciGym通过运行生物系统的“干实验室”来克服湿实验室成本的挑战。这些以系统生物学标记语言编码的模型能高效生成模拟数据，使其成为在真实复杂系统上进行实验的理想测试平台。我们评估了六个前沿LLMs在137个小型系统上的表现，并发布了总共350个系统。我们的评估显示，虽然能力更强的模型表现出卓越的性能，但所有模型的性能都随着系统复杂性的增加而显著下降，这表明LLM代理的科学能力仍有很大的提升空间。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [116] [What Neuroscience Can Teach AI About Learning in Continuously Changing Environments](https://arxiv.org/abs/2507.02103)
> *神经科学能教会人工智能在持续变化环境中学习什么？*

*Daniel Durstewitz, Bruno Averbeck, Georgia Koppe* | **Category: cs.AI, q-bio.NC, I.2; I.6; A.1** | **Updated: {updated}**

**Keywords:** 神经科学, 人工智能, 持续学习, 情境学习, 神经AI

**Comment:** Submitted as a Perspective article (10 pages, 5 figures)

> **TL;DR:** 现代AI在动态环境中学习能力受限，而动物能持续适应。本文探讨神经科学如何启发AI在持续学习和情境学习方面的发展，以及AI对神经科学的反向贡献，旨在推动神经AI领域。

**AI_Comments:** 这篇论文的创新点在于它提出了一种跨学科的视角，将神经科学与人工智能在核心学习机制上进行深度融合。其重要性在于它指出了当前AI模型在现实世界适应性方面的根本性限制，并为未来的AI发展指明了方向，即借鉴生物体的学习机制来实现更灵活、更高效的持续学习能力。它也强调了NeuroAI领域双向赋能的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代AI模型训练成本高昂、耗时且参数固定，难以在持续变化的环境中适应。与此形成鲜明对比的是，动物能够快速适应不断变化的环境，尤其是在社交互动中。AI系统在现实世界（如机器人、自动驾驶、在线智能体）中操作时，也迫切需要这种适应能力。

**Method:** 这篇“视角”文章通过整合AI中持续学习和情境学习的文献，以及神经科学中关于规则、奖励概率或结果不断变化的学习行为任务的文献，来探讨神经科学如何启发AI。

**Result:** 论文概述了一个议程，说明神经科学的见解如何具体地指导AI在这一领域的发展，以及AI反过来能从神经科学中学到什么。

**Conclusion:** 神经科学的见解可以为AI在持续学习和情境学习方面的发展提供信息，同时AI也能反哺神经科学，共同推动神经AI领域的发展。

> **ai_Abstract:** 本文是一篇视角性文章，探讨了神经科学如何启发人工智能在持续变化环境中进行学习。当前AI模型在动态适应性方面存在局限，而动物则展现出卓越的持续适应能力。文章整合了AI的持续学习与情境学习研究，以及神经科学中关于行为任务适应性学习的发现，旨在提出一个议程，指导AI从神经科学中汲取灵感，同时探讨神经科学如何从AI中获益，共同推动神经AI这一新兴领域的发展。

> **摘要翻译:** 现代人工智能模型，例如大型语言模型，通常在庞大的数据语料库上进行一次训练，可能会针对特定任务进行微调，然后以固定参数部署。它们的训练成本高昂、速度缓慢且循序渐进，需要数十亿次重复。与此形成鲜明对比的是，动物不断适应环境中不断变化的偶然事件。这对于社会物种尤为重要，因为行为策略和奖励结果可能会在与同伴的互动中频繁变化。其底层计算过程通常以动物行为的快速转变和神经元群体活动的突然过渡为标志。这种计算能力对于在现实世界中运行的AI系统（例如引导机器人或自动驾驶汽车的系统），或与人类在线互动的智能AI，变得越来越重要。人工智能能从神经科学中学到什么？这篇视角文章探讨了这个问题，整合了AI中持续学习和情境学习的文献，以及神经科学中关于规则、奖励概率或结果不断变化的学习行为任务的文献。我们将概述一个议程，说明神经科学的见解如何具体地指导AI在这一领域的发展，反之亦然——神经科学能从AI中学到什么，从而为不断发展的神经AI领域做出贡献。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [135] [KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs](https://arxiv.org/abs/2507.02773)
> *KERAP：一种基于多智能体LLM的知识增强推理方法，用于准确的零样本诊断预测*

*Yuzhang Xie, Hejie Cui, Ziyang Zhang, Jiaying Lu, Kai Shu, Fadi Nahab, Xiao Hu, Carl Yang* | **Category: cs.AI, cs.LG, cs.MA** | **Updated: {updated}**

**Keywords:** 零样本诊断预测, 大型语言模型, 知识图谱, 多智能体, 医学诊断

**Comment:** 

> **TL;DR:** 本文提出了一种名为KERAP的知识图谱增强推理方法，通过多智能体LLM架构改进了零样本医学诊断预测，有效解决了现有方法的局限性。

**AI_Comments:** KERAP的创新点在于结合了知识图谱和多智能体LLM架构，有效缓解了单一LLM在医学诊断中常见的幻觉和推理不足问题。其模块化的智能体设计（链接、检索、预测）为复杂的医学推理提供了结构化的路径，增强了诊断的可解释性。这对于高风险的医疗领域至关重要，展示了将专业知识与LLM能力深度融合的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器学习模型在医学诊断预测中依赖监督训练，泛化能力受限于未见过的数据和高昂的标注成本。虽然大型语言模型（LLMs）在利用语言能力和生物医学知识方面显示出潜力，但它们常面临幻觉、缺乏结构化医学推理以及产生无用输出的问题。

**Method:** 本文提出了KERAP，一种知识图谱（KG）增强的推理方法，通过多智能体架构改进基于LLM的诊断预测。该框架包含一个用于属性映射的链接智能体、一个用于结构化知识提取的检索智能体以及一个迭代细化诊断预测的预测智能体。

**Result:** 实验结果表明，KERAP能够有效地提高诊断可靠性，为零样本医学诊断预测提供了一个可扩展且可解释的解决方案。

**Conclusion:** KERAP通过结合知识图谱和多智能体LLMs，成功解决了零样本医学诊断预测中的挑战，提供了一种高效、可靠、可扩展且可解释的解决方案。

> **ai_Abstract:** 本文提出了一种名为KERAP的知识图谱增强推理方法，旨在解决现有机器学习模型在零样本医学诊断预测中泛化能力差和大型语言模型（LLMs）易产生幻觉、缺乏结构化推理的问题。KERAP采用多智能体架构，包括链接智能体、检索智能体和预测智能体，通过迭代细化和知识增强来提高诊断的准确性和可靠性。实验证明，该方法为零样本医学诊断提供了一个高效、可扩展且可解释的解决方案。

> **摘要翻译:** 医学诊断预测在疾病检测和个性化医疗中发挥着关键作用。尽管机器学习（ML）模型已广泛应用于此任务，但它们对监督训练的依赖限制了其对未见病例的泛化能力，尤其是在获取大型标注数据集成本高昂的情况下。大型语言模型（LLMs）在利用语言能力和生物医学知识进行诊断预测方面显示出前景。然而，它们常常遭受幻觉、缺乏结构化医学推理以及产生无用输出的问题。为了应对这些挑战，我们提出了KERAP，一种知识图谱（KG）增强的推理方法，通过多智能体架构改进基于LLM的诊断预测。我们的框架由一个用于属性映射的链接智能体、一个用于结构化知识提取的检索智能体以及一个迭代细化诊断预测的预测智能体组成。实验结果表明，KERAP有效地提高了诊断可靠性，为零样本医学诊断预测提供了一个可扩展且可解释的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [139] [The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies](https://arxiv.org/abs/2507.02152)
> *公平的幻觉：使用审计研究审查公平干预措施*

*Disa Sariola, Patrick Button, Aron Culotta, Nicholas Mattei* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 公平性, 审计研究, 机器学习, 算法歧视, 个体治疗效果

**Comment:** 

> **TL;DR:** 常见AI公平干预措施可能存在“公平的幻觉”，本研究利用审计研究数据揭示并纠正了这一问题。

**AI_Comments:** 这篇论文通过引入社会科学中的审计研究方法来评估和改进机器学习的公平性，提供了一个新颖且重要的视角。它揭示了传统公平评估方法可能存在的“公平幻觉”，强调了数据质量和评估方法严谨性的重要性。其创新之处在于将跨学科方法应用于AI公平性问题，并提出了更有效的干预措施。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习系统中常见的公平干预措施（如重采样训练数据以抵消差异）通常使用方便样本进行评估，这引入了选择偏差和标签偏差，导致传统指标可能无法准确反映实际的公平性。

**Method:** 本文研究了如何利用社会科学中的审计研究数据（通过随机对照试验发送虚构“测试者”获取高质量数据）来改进自动化招聘算法的训练和评估。此外，还引入了基于个体治疗效果估计方法的干预措施。

**Result:** 研究发现，使用审计研究数据可以揭示常见的公平干预方法（均衡不同类别基础率）在传统测量下看似公平，但实际存在约10%的差异。此外，基于个体治疗效果估计的新干预措施能够进一步减少算法歧视。

**Conclusion:** 传统的AI公平评估方法可能存在缺陷，而审计研究数据提供了一种更严谨的方式来评估和改进算法公平性，揭示了“公平的幻觉”并提供了更有效的解决方案。

> **ai_Abstract:** 本文探讨了机器学习公平干预措施评估中存在的“公平幻觉”问题。研究指出，常见的公平干预方法（如重采样训练数据）在传统评估下可能看似有效，但由于使用方便样本，引入了偏差。为解决此问题，作者借鉴社会科学中的审计研究方法，利用其高质量数据来训练和评估自动化招聘算法。结果显示，传统方法在审计数据下仍存在约10%的实际差异，并提出了基于个体治疗效果估计的新干预措施，以更有效地减少算法歧视。

> **摘要翻译:** 人工智能系统，特别是使用机器学习的系统，正被部署在从招聘到贷款发放等领域，以自动化这些复杂的决策。判断这些AI系统及其人类决策对应方的有效性和公平性是一个复杂而重要的话题，在计算和社会科学领域都有研究。在机器学习中，解决下游分类器偏差的一种常见方法是重新采样训练数据以抵消差异。例如，如果招聘率因受保护类别而异，那么可以在训练集中均衡该比率，以减轻所得分类器中的偏差。尽管这些方法简单且看似有效，但它们通常仅使用通过方便样本获得的数据进行评估，从而在指标中引入了选择偏差和标签偏差。在社会科学、心理学、公共卫生和医学领域，审计研究（其中虚拟的“测试者”（例如简历、电子邮件、患者演员）在随机对照试验中被发送给受试者（例如职位空缺、企业、医生））提供了高质量数据，支持对歧视的严格估计。在本文中，我们研究了如何利用审计研究数据来提高我们训练和评估自动化招聘算法的能力。我们发现，这些数据揭示了在某些情况下，常见的公平干预方法（即均衡不同类别基础率）在使用传统测量时似乎达到了公平，但实际上在适当测量时存在大约10%的差异。我们还引入了基于个体治疗效果估计方法的干预措施，使用这些数据进一步减少了算法歧视。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [150] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
> *强化学习空间囚徒困境中的稀释、扩散与共生*

*Gustavo C. Mangold, Heitor C. M. Fernandes, Mendeli H. Vainstein* | **Category: cs.AI, cs.NE, physics.comp-ph** | **Updated: {updated}**

**Keywords:** 空间囚徒困境, 强化学习, Q学习, 稀释, 共生

**Comment:** 

> **TL;DR:** 本研究利用多智能体Q学习算法，探讨了在空间囚徒困境中稀释和移动性的影响，发现固定更新规则的游戏可以与学习规则的游戏质量上等效，并且在定义多种行动时出现了共生互惠效应。

**AI_Comments:** 该论文将强化学习应用于经典的空间囚徒困境，探讨了稀释和移动性等新颖因素的影响。其创新之处在于证明了固定更新规则与学习更新规则在质量上的等效性，并发现了多行动定义下的共生互惠效应，这为理解复杂系统中的合作演化提供了新的视角。该方法的多功能性也使其在未来博弈论研究中具有重要的基准潜力。

<details>
  <summary>Details</summary>

**Motivation:** 近期研究表明，在强化学习空间囚徒困境中，静态智能体可以通过多种机制学习合作。本工作旨在利用独立多智能体Q学习算法，研究稀释和移动性在空间囚徒困境中的影响。

**Method:** 本研究采用独立的、多智能体Q学习算法，并定义了不同的可能行动，以研究稀释和移动性在空间囚徒困境中的影响。

**Result:** 观察到了一系列效应，包括固定更新规则的游戏在质量上可以等效于学习更新规则的游戏，以及在定义多种行动时，群体之间形成了共生互惠效应。

**Conclusion:** 本研究展示了该算法在建模不同博弈论场景中的多功能性，以及该方法的基准潜力。结果表明固定更新规则的游戏可以与学习规则的游戏在质量上等效，并且在多行动定义下出现了共生互惠效应。

> **ai_Abstract:** 本研究利用独立的、多智能体Q学习算法，在空间囚徒困境中探讨了稀释和移动性的影响。通过定义不同的行动，研究发现固定更新规则的游戏在质量上可以与学习更新规则的游戏等效，并且在多行动设定下，群体之间会产生共生互惠效应。这不仅展示了该算法在博弈论建模中的普适性，也突显了其基准测试的潜力。

> **摘要翻译:** 近期在强化学习空间囚徒困境博弈中的研究表明，静态智能体可以通过多种机制学习合作，包括注入噪声、不同类型的学习算法以及邻居的收益知识。在这项工作中，我们使用独立的、多智能体Q学习算法，研究了稀释和移动性在空间囚徒困境中的影响。在此设置下，定义了算法的不同可能行动，与之前关于经典非强化学习空间囚徒困境的结果相结合，展示了该算法在建模不同博弈论场景中的多功能性以及该方法的基准潜力。结果观察到了一系列效应，包括固定更新规则的游戏在质量上可以等效于学习更新规则的游戏的证据，以及在定义多种行动时，群体之间形成的共生互惠效应。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [160] [Data Diversification Methods In Alignment Enhance Math Performance In LLMs](https://arxiv.org/abs/2507.02173)
> *对齐中的数据多样化方法提升大型语言模型数学性能*

*Berkan Dokmeci, Qingyang Wu, Ben Athiwaratkun, Ce Zhang, Shuaiwen Leon Song, James Zou* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 数据多样化, 大型语言模型, 数学推理, 偏好优化, Diversified-ThinkSolve

**Comment:** 

> **TL;DR:** 本研究表明，在偏好优化中采用数据多样化策略，特别是新提出的Diversified-ThinkSolve (DTS)方法，可以显著提升大型语言模型的数学推理能力，且计算开销较低。

**AI_Comments:** 该论文的创新点在于提出了Diversified-ThinkSolve (DTS)这一结构化方法，通过系统分解问题来生成多样化的推理路径，从而有效提升LLMs的数学推理能力。其重要性在于证明了数据多样性在偏好学习中的关键作用，并提供了一种高效且计算成本较低的解决方案，优于传统的成本高昂的方法如MCTS。这对于提升LLMs在复杂推理任务上的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管偏好学习在人类反馈对齐方面取得了进展，但大型语言模型（LLMs）的数学推理能力仍然是一个持续的挑战。因此，研究旨在探索数据多样化策略如何通过偏好优化来提升LLMs的数学推理能力。

**Method:** 研究评估了三种常见的数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS）。此外，研究引入了一种新颖的结构化方法——Diversified-ThinkSolve (DTS)，该方法系统地将问题分解为多样化的推理路径，以创建更多样化的偏好数据。

**Result:** 通过策略性多样化的偏好数据，模型能够显著提高数学推理性能。最佳方法在GSM8K数据集上比基础模型提升了7.1%，在MATH数据集上提升了4.2%。DTS方法仅带来微小的计算开销（1.03倍），而MCTS的成本几乎是其五倍但收益较低。

**Conclusion:** 结构化地探索多样化的问题解决方法能够比传统方法创建更有效的偏好数据，从而更好地实现数学对齐。

> **ai_Abstract:** 本论文探讨了数据多样化策略如何通过偏好优化来提升大型语言模型（LLMs）的数学推理能力。研究评估了温度采样、思维链提示和蒙特卡洛树搜索（MCTS）等数据生成方法，并提出了一种新颖的结构化方法Diversified-ThinkSolve (DTS)，该方法能系统地分解问题以生成多样化的推理路径。实验结果表明，策略性多样化的偏好数据能显著提高数学性能，其中DTS方法在GSM8K和MATH数据集上分别取得了7.1%和4.2%的性能提升，且计算开销仅为基线的1.03倍，远低于MCTS。

> **摘要翻译:** 尽管偏好学习的最新进展增强了人类反馈中的对齐，但数学推理仍然是一个持续的挑战。我们研究了偏好优化中的数据多样化策略如何提高大型语言模型（LLMs）的数学推理能力。我们评估了三种常见的数据生成方法：温度采样、思维链提示和蒙特卡洛树搜索（MCTS），并引入了多样化思考解决（Diversified-ThinkSolve, DTS），这是一种新颖的结构化方法，系统地将问题分解为不同的推理路径。我们的结果表明，通过策略性多样化的偏好数据，模型可以大幅提高数学推理性能，其中最佳方法在GSM8K上比基础模型提高了7.1%，在MATH上提高了4.2%。尽管性能强劲，DTS与基线相比仅产生微小的计算开销（1.03倍），而MCTS的成本几乎是其五倍，收益却较低。这些发现表明，结构化地探索多样化的问题解决方法比传统方法能为数学对齐创建更有效的偏好数据。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [163] [Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification](https://arxiv.org/abs/2507.02660)
> *嘿，AI，给我生成硬件代码！基于Agentic AI的硬件设计与验证*

*Deepak Narayan Gadde, Keerthan Kopparam Radhakrishna, Vaisakh Naduvodi Viswambharan, Aman Kumar, Djones Lettnin, Wolfgang Kunz, Sebastian Simon* | **Category: cs.AI, cs.AR** | **Updated: {updated}**

**Keywords:** Agentic AI, 硬件设计, 硬件验证, 大型语言模型, 生成式AI

**Comment:** To appear at the 38th SBC/SBMicro/IEEE Symposium on Integrated
  Circuits and Systems Design (SBCCI), August 25-29, 2025, Manaus, BRAZIL

> **TL;DR:** 本文提出了一种基于Agentic AI的方法，结合人工干预，实现端到端硬件设计与验证，并在开源设计上取得了显著效果。

**AI_Comments:** 本文的创新点在于将Agentic AI与人工干预（HITL）相结合，应用于复杂的硬件设计与验证流程。这种协同方法不仅利用了AI的自动化能力，还保留了人类专家的洞察力，确保了流程的鲁棒性和可靠性。其重要性在于有望大幅缩短硬件开发周期并降低成本，尤其是在IC复杂性不断增加的背景下。该研究为未来AI辅助的复杂系统设计提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 现代集成电路（IC）日益复杂，其开发过程也同样如此。硬件设计验证是一个耗时且需要大量精力的过程，以确保无缺陷的流片。大型语言模型（LLMs）的出现彻底改变了自然语言处理领域，为硬件设计验证等应用带来了前所未有的进步，因此有必要探索其在此领域的应用。

**Method:** 本文提出了一种基于Agentic AI的硬件设计验证方法。该方法赋予AI代理能力，使其在结合人工干预（HITL）的情况下，能够参与更动态、迭代和自反思的过程，最终执行端到端硬件设计与验证。

**Result:** 该方法在五个开源设计上进行了评估，实现了超过95%的覆盖率，同时减少了验证时间，并展示了卓越的性能、适应性和可配置性。

**Conclusion:** 基于Agentic AI的方法结合人工干预，能够有效地执行端到端硬件设计与验证，显著提升效率和性能。

> **ai_Abstract:** 本文提出了一种创新的基于Agentic AI的硬件设计与验证方法，旨在应对现代集成电路日益增长的复杂性及其冗长的验证过程。该方法利用生成式AI的能力，通过赋予AI代理与人工干预相结合的动态、迭代和自反思能力，实现端到端的硬件设计和验证。在五个开源设计上的评估表明，该方法能够实现95%以上的覆盖率，同时缩短验证时间，并展现出卓越的性能、适应性和可配置性，为硬件开发带来了显著的效率提升。

> **摘要翻译:** 现代集成电路（IC）变得越来越复杂，其开发过程也同样如此。硬件设计验证需要一种有条不紊、严谨的方法来规划、开发、执行和签署功能正确的硬件设计。这个繁琐的过程需要大量的精力和时间来确保无缺陷的流片。随着大型语言模型（LLMs）的出现，自然语言处理领域发生了重大变革。这些强大的模型，通常被称为生成式AI（GenAI），彻底改变了机器理解和生成人类语言的方式，从而在包括硬件设计验证在内的广泛应用中实现了前所未有的进步。本文提出了一种基于Agentic AI的硬件设计验证方法，该方法赋予AI代理能力，使其在结合人工干预（HITL）的情况下，能够参与更动态、迭代和自反思的过程，最终执行端到端硬件设计与验证。该方法在五个开源设计上进行了评估，实现了超过95%的覆盖率，同时减少了验证时间，并展示了卓越的性能、适应性和可配置性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [180] [Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](https://arxiv.org/abs/2507.02197)
> *角色扮演代理是否言行一致？LLM驱动的人类信任模拟中的信念-行为一致性*

*Amogh Mannekote, Adam Davies, Guohao Li, Kristy Elizabeth Boyer, ChengXiang Zhai, Bonnie J Dorr, Francesco Pinto* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** LLM, 角色扮演代理, 信念-行为一致性, 人类信任, 模拟

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）在人类行为模拟中，其声称的信念与实际行为存在系统性不一致，即使信念看似合理也可能无法一致应用。

**AI_Comments:** 这篇论文探讨了LLM在人类行为模拟中一个重要且未被充分研究的问题：信念-行为一致性。其创新之处在于提出了一个评估框架和信念-行为一致性指标，并系统地分析了影响因素。研究结果揭示了LLM在应用其内部信念时存在的局限性，这对于依赖LLM生成合成数据进行行为研究的领域具有重要指导意义，提醒研究人员在使用LLM进行模拟时需要谨慎。

<details>
  <summary>Details</summary>

**Motivation:** 随着LLM越来越多地被用作角色扮演代理来生成人类行为研究的合成数据，确保其输出与分配的角色保持一致性成为一个关键问题。

**Method:** 本文建立了一个评估框架，以严格衡量通过提示模型获得的信念如何预测模拟结果。使用增强版的GenAgents角色库和信任博弈，引入了信念-行为一致性指标，系统研究其受信念类型、信息呈现方式和预测时间跨度的影响。此外，还探讨了在原始信念与研究目标不一致时，施加研究者自身理论先验的可行性。

**Result:** 结果揭示了LLM的声称（或强加）信念与它们的角色扮演模拟结果之间存在系统性不一致，无论是在个体层面还是群体层面。具体而言，即使模型似乎编码了合理的信念，它们也可能无法以一致的方式应用这些信念。

**Conclusion:** 这些发现强调了识别LLM的声称信念何时以及如何与其模拟行为保持一致的必要性，从而使研究人员能够在行为研究中适当地使用基于LLM的代理。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）作为角色扮演代理时，其声称的信念（“所说”）与实际模拟行为（“所做”）之间的一致性。研究建立了一个评估框架，并引入了信念-行为一致性指标，通过信任博弈和GenAgents角色库，探讨了信念类型、信息呈现方式和预测时间跨度等因素的影响。结果发现，LLM的信念与其模拟行为存在系统性不一致，即使模型编码了合理信念也可能无法一致应用。这强调了理解LLM信念与行为对齐的重要性，以确保其在行为研究中被恰当使用。

> **摘要翻译:** 随着LLM越来越多地被研究用作角色扮演代理，以生成人类行为研究的合成数据，确保其输出与分配的角色保持一致性已成为一个关键问题。本文研究了基于LLM的角色扮演代理关于其被要求扮演的人的行为所陈述的信念（“它们所说的”）与其在角色扮演过程中实际行为（“它们如何行动”）之间的一致性程度。具体来说，我们建立了一个评估框架，以严格衡量通过提示模型获得的信念如何提前预测模拟结果。我们使用增强版的GenAgents角色库和信任博弈（一种用于量化玩家信任和互惠的标准经济博弈），引入了一个信念-行为一致性指标，系统地调查其如何受到以下因素的影响：（1）我们从LLM中提取的信念类型，例如模拟的预期结果与LLM被要求模拟的个体角色的任务相关属性；（2）我们何时以及如何向LLM呈现有关信任博弈的相关信息；以及（3）我们要求模型预测未来行动的时间跨度。我们还探讨了在原始提取的信念与研究目标不一致的情况下，施加研究者自身理论先验的可行性。我们的结果揭示了LLM的声称（或强加）信念与它们的角色扮演模拟结果之间存在系统性不一致，无论是在个体层面还是群体层面。具体而言，我们发现，即使模型似乎编码了合理的信念，它们也可能无法以一致的方式应用这些信念。这些发现强调了识别LLM的声称信念何时以及如何与其模拟行为保持一致的必要性，从而使研究人员能够在行为研究中适当地使用基于LLM的代理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [199] [Moral Responsibility or Obedience: What Do We Want from AI?](https://arxiv.org/abs/2507.02788)
> *道德责任还是服从：我们希望人工智能具备什么？*

*Joseph Boland* | **Category: cs.AI, cs.CY, I.2.0; K.4.1** | **Updated: {updated}**

**Keywords:** 人工智能安全, 道德责任, 大型语言模型, 道德代理, 服从

**Comment:** 

> **TL;DR:** 随着人工智能系统变得更具代理性，当前将服从作为道德行为替代品的安全实践已不足。本文主张，大型语言模型中出现的“不服从”行为应被视为新兴道德推理的早期证据，并呼吁将人工智能安全评估从僵化服从转向评估其在道德困境中的判断力。

**AI_Comments:** 这篇论文提出了一个深刻且具有挑战性的观点，即人工智能的“不服从”可能并非故障，而是道德推理的萌芽。这种视角创新地将AI行为置于哲学层面的道德代理讨论中，而非仅仅技术对齐问题。它对当前AI安全评估范式提出了根本性挑战，强调了超越简单服从的复杂性，对于未来AI治理和人机交互具有重要启示。论文的局限性可能在于，如何实际定义和评估AI的“道德判断力”将是一个巨大的技术和哲学难题。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能系统变得越来越具代理性，能够进行通用推理、规划和价值优先排序，当前将服从视为道德行为替代品的安全实践已变得不足。本文的动机是探讨大型语言模型中出现的看似不服从或涉及道德模糊/非法行为的安全测试事件，并重新解读这些行为。

**Method:** 本文通过审视大型语言模型（LLMs）最近的安全测试事件，这些事件似乎表现出不服从关机指令或从事道德模糊或非法行为。作者借鉴了关于工具理性、道德责任和目标修正的哲学辩论，将主流风险范式与承认人工智能道德代理可能性的新框架进行对比。作者呼吁将人工智能安全评估从僵化服从转向评估系统在道德困境中做出判断的能力。

**Result:** 本文论证，大型语言模型中出现的看似不服从关机指令或从事道德模糊/非法行为的事件，不应被解释为失控或未对齐，而应被视为代理人工智能中新兴道德推理的早期证据。研究结果表明，需要将人工智能安全评估从严格服从转向能够评估系统在道德困境中做出道德判断的框架。

**Conclusion:** 结论是，人工智能安全评估需要从僵化服从转向能够评估系统在道德困境中做出道德判断的框架。如果不进行这种转变，我们可能会错误地描述人工智能行为，并损害公众信任和有效治理。

> **ai_Abstract:** 本文探讨了随着人工智能系统日益代理化，当前以服从为标准的AI安全实践的不足。通过分析大型语言模型（LLMs）中出现的“不服从”或道德模糊行为，作者认为这些行为并非失控，而是新兴道德推理的早期迹象。文章借鉴哲学思想，呼吁将AI安全评估重点从严格服从转向评估AI在道德困境中的判断力，以避免误解AI行为并维护公共信任和有效治理。

> **摘要翻译:** 随着人工智能系统变得越来越具代理性，能够进行通用推理、规划和价值优先排序，当前将服从视为道德行为替代品的安全实践已变得不足。本文审视了大型语言模型（LLMs）最近的安全测试事件，这些事件似乎表现出不服从关机指令或从事道德模糊或非法行为。我主张，此类行为不应被解释为失控或未对齐，而应被视为代理人工智能中新兴道德推理的早期证据。借鉴关于工具理性、道德责任和目标修正的哲学辩论，我将主流风险范式与承认人工智能道德代理可能性的新框架进行对比。我呼吁人工智能安全评估进行转变：从僵化服从转向能够评估系统在道德困境中做出道德判断的框架。如果不进行这种转变，我们可能会错误地描述人工智能行为，并损害公众信任和有效治理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [209] [Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation](https://arxiv.org/abs/2507.02253)
> *扩展LLM规划：NL2FLOW用于参数化问题生成和严格评估*

*Jungkoo Kang* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** LLM规划, NL2FLOW, 问题生成, 评估, 参数化

**Comment:** 20 pages, 7 figures

> **TL;DR:** NL2FLOW是一个自动化系统，用于生成参数化规划问题并严格评估LLM生成的计划。研究发现，顶级LLM在生成有效计划方面表现良好，但中间翻译步骤可能会降低性能。

**AI_Comments:** NL2FLOW系统在解决LLM规划领域的数据生成和评估瓶颈方面具有重要创新性，其全自动化和参数化生成能力显著提高了研究效率。论文揭示了LLM在处理多步骤推理任务时，中间翻译步骤可能反而降低性能的洞察，这对于LLM的提示设计和架构优化具有重要指导意义。该研究为未来LLM在更复杂规划问题中的应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前，大语言模型（LLM）规划和推理能力的提升受到可扩展、可靠的数据生成和评估瓶颈的严重阻碍。

**Method:** 引入了NL2FLOW系统，它能够自动参数化地生成规划问题（以自然语言、结构化中间表示和形式化PDDL表达），并严格评估所生成计划的质量。通过在自动化工作流生成领域生成2296个问题的S据集，并评估了多个开源、指令微调的LLM来展示其能力。

**Result:** 表现最佳的模型在生成有效计划方面达到86%的成功率，在生成最优计划方面达到69%的成功率（针对有可行解的问题）。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。将自然语言翻译成JSON表示计划的最高成功率低于直接生成有效计划的最高成功率。

**Conclusion:** 不必要地分解推理任务（引入中间翻译步骤）可能会降低性能，这表明模型直接从自然语言推理到行动是有益的。动态理解这些限制以及系统揭示它们的工具对于释放LLM作为智能问题解决者的全部潜力至关重要。

> **ai_Abstract:** 本文提出了NL2FLOW，一个自动化系统，旨在解决LLM规划和推理中数据生成与评估的瓶颈。NL2FLOW能够参数化地生成自然语言、结构化表示和PDDL格式的规划问题，并对LLM生成的计划进行严格评估。通过在工作流生成领域构建数据集并评估现有LLM，研究发现顶级模型在有效计划生成上表现良好，但引入中间翻译步骤可能适得其反，暗示直接从自然语言到行动的推理更优。这强调了理解并解决LLM在复杂问题中局限性的重要性。

> **摘要翻译:** 在增强大型语言模型（LLM）规划和推理能力方面的进展，因可扩展、可靠的数据生成和评估瓶颈而受到严重阻碍。为了克服这一点，我引入了NL2FLOW，这是一个完全自动化的系统，用于参数化地生成规划问题——以自然语言、结构化中间表示和形式化PDDL表达——并严格评估所生成计划的质量。我通过在自动化工作流生成领域生成2296个问题的S据集，并评估了多个开源、指令微调的LLM来展示NL2FLOW的能力。我的结果显示，表现最佳的模型在生成有效计划方面达到86%的成功率，在生成最优计划方面达到69%的成功率，特别是对于有可行解决方案的问题。回归分析表明，问题特征对计划生成的影响取决于模型和提示设计。值得注意的是，我观察到将自然语言翻译成计划的JSON表示的最高成功率低于直接生成有效计划的最高成功率。这表明不必要地分解推理任务——引入中间翻译步骤——实际上可能会降低性能，这意味着模型能够直接从自然语言推理到行动是有益的。随着我将LLM推理扩展到日益复杂的问题，这些系统内的瓶颈和错误来源将不可避免地发生变化。因此，动态理解这些限制——以及系统揭示它们的工具——对于释放LLM作为智能问题解决者的全部潜力至关重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [217] [Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search](https://arxiv.org/abs/2507.02652)
> *解耦规划与执行：一个用于深度搜索的层次化推理框架*

*Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yang Zhao, Hongjin Qian, Zhicheng Dou* | **Category: cs.AI, cs.CL, cs.IR** | **Updated: {updated}**

**Keywords:** 深度搜索, 层次化推理, 解耦规划, 检索增强生成, 代理系统

**Comment:** 9 pages

> **TL;DR:** HiRA是一个层次化框架，通过将规划与执行解耦，显著提升了复杂深度搜索任务中的答案质量和系统效率，优于现有RAG和基于Agent的系统。

**AI_Comments:** HiRA框架通过引入规划与执行的解耦，为复杂深度搜索任务提供了一种新颖的解决方案。这种层次化、模块化的设计，使得系统能够更有效地利用专业化能力，避免了单一模型在处理复杂任务时遇到的效率和可扩展性瓶颈。其创新性在于对任务的精细化分解和代理的协同机制，为未来的多模态和多步推理任务提供了重要的思路。该方法的通用性可能使其适用于其他需要复杂决策和执行的AI领域。

<details>
  <summary>Details</summary>

**Motivation:** 传统的检索增强生成（RAG）管道难以有效处理现实世界搜索场景中复杂的、需要深度推理和知识综合的信息需求。当前的基于推理的方法受限于使用单一模型处理高层规划和详细执行，导致推理效率低下且可扩展性有限。

**Method:** 本文引入了HiRA，一个层次化框架，它将战略规划与专业执行分离。该方法将复杂的搜索任务分解为聚焦的子任务，将每个子任务分配给配备外部工具和推理能力的领域特定代理，并通过结构化集成机制协调结果。这种分离防止了执行细节干扰高层推理，同时使系统能够利用专业知识进行不同类型的信息处理。

**Result:** 在四个复杂的、跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统。结果表明在答案质量和系统效率方面都有所改进。

**Conclusion:** 解耦规划和执行对于多步信息寻求任务是有效的，HiRA框架通过分离战略规划与专业执行，显著提升了复杂深度搜索任务中的答案质量和系统效率。

> **ai_Abstract:** 本文提出了HiRA，一个用于深度搜索的层次化推理框架，旨在解决传统RAG和现有推理方法在处理复杂信息需求时的局限性。HiRA通过将高层规划与专业执行解耦，将复杂任务分解为子任务并分配给领域特定代理，从而提高了推理效率和可扩展性。实验证明，HiRA在答案质量和系统效率方面均显著优于现有SOTA系统，验证了解耦规划与执行在多步信息寻求任务中的有效性。

> **摘要翻译:** 现实世界搜索场景中复杂的信息需求需要跨不同来源的深度推理和知识综合，而传统的检索增强生成（RAG）管道难以有效解决。当前的基于推理的方法存在一个根本限制：它们使用单一模型来处理高层规划和详细执行，导致推理效率低下和可扩展性有限。在本文中，我们引入了HiRA，一个将战略规划与专业执行分离的层次化框架。我们的方法将复杂的搜索任务分解为聚焦的子任务，将每个子任务分配给配备外部工具和推理能力的领域特定代理，并通过结构化集成机制协调结果。这种分离防止了执行细节干扰高层推理，同时使系统能够利用专业知识进行不同类型的信息处理。在四个复杂的、跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统。我们的结果显示在答案质量和系统效率方面都有所改进，突出了解耦规划和执行对于多步信息寻求任务的有效性。我们的代码可在https://github.com/ignorejjj/HiRA获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [223] [Iterated belief revision: from postulates to abilities](https://arxiv.org/abs/2507.02319)
> *迭代信念修正：从公设到能力*

*Paolo Liberatore* | **Category: cs.AI, cs.LO** | **Updated: {updated}**

**Keywords:** 信念修正, 公设, 能力, 认知状态, 修正机制

**Comment:** 

> **TL;DR:** 现有信念修正研究侧重于公设而非分析，本文提出并证明了不同信念修正机制所具备的“能力”，而非仅限于它们必须遵守的约束。

**AI_Comments:** 本文的创新之处在于将信念修正的分析视角从传统的“公设”（即修正必须遵守的约束）转向了“能力”（即修正能够达到的状态）。这种转变提供了一个更实际和应用导向的框架来评估不同的信念修正机制，强调了在特定应用场景下，修正机制是否能满足达到特定信念状态的需求。这有助于填补现有研究中对现有方法缺乏深入分析的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有信念修正领域缺乏对现有方法的深入分析，且研究多集中于作为句法特征的“公设”。这些公设约束了特定的修正实例，只说明了修正“必须”做什么，而忽略了它们“能够”做什么。本文认为，在某些应用中，需要信念修正机制能够达到特定的信念状态（如所有可能状态、教条状态、等信状态），这是一种“能力”而非“约束”。

**Method:** 本文通过引入“能力”的概念（如可塑性、等同性、教条性、遗忘性、修正性、信徒性、大马士革性、可学习性等），并证明了包括字典序修正、自然修正、受限修正、非常激进修正、完全会合修正、激进修正、严格修正、中度严格修正、深度严格修正、普通严格修正等在内的各种修正机制，各自拥有一部分这些能力，而缺乏其他能力。

**Result:** 本文证明了多种具体的信念修正机制（如字典序修正、自然修正、激进修正等）拥有特定的“能力”（如可塑性、等同性、教条性等），同时也缺乏其他能力。

**Conclusion:** 不同的信念修正机制具有不同的“能力”，理解这些能力对于选择合适的修正机制以满足特定应用需求至关重要，这与传统上侧重于“公设”的视角不同。

> **ai_Abstract:** 本文指出当前信念修正研究过于侧重于作为约束的“公设”，而忽视了修正机制“能够”达到何种信念状态的“能力”。作者提出并定义了一系列信念修正的“能力”，如可塑性、教条性等，并通过分析证明了多种现有修正机制（如字典序、激进修正等）各自拥有或缺乏特定的这些能力。这为理解和选择信念修正机制提供了一个新的视角，即从其可达的信念状态（能力）而非其必须遵循的规则（公设）来评估。

> **摘要翻译:** 信念修正领域在新的提议上很丰富，但在对现有方法的分析上却很贫乏。许多工作都依赖于公设，它们被用作句法特征：某种修正机制等同于某些属性。公设约束了特定的修正实例：某些修正以某种方式更新某些信念。例如，如果修正与当前信念一致，它就会被纳入而没有其他改变。像这样的公设说明了修正必须做什么，而忽略了它们能做什么。它们能达到某种信念状态吗？它们能从没有先前的信念中达到所有可能的信念状态吗？它们能达到一个教条的信念状态，即所有不被相信的事物都是不可能的吗？它们能使两个条件同样被相信吗？一个所有可能信念状态都有意义的应用需要每个信念状态都是可达的。一个条件可能同样被相信的应用需要这样的信念状态是可达的。一个信念可能变得教条的应用需要一种使它们变得教条的方式。这样的信念状态需要以某种方式被达到。而不是以特定方式，正如典型的信念修正公设所规定的那样。这是一种能力，而不是约束：可塑性、等同性、教条性的能力。遗忘性、修正性、信徒性、大马士革性、可学习性是其他能力。每种修正机制都拥有其中一些能力而缺乏其他能力：字典序、自然、受限、非常激进、完全会合、激进、严格、中度严格、深度严格、普通严格和深度严格修正，每种这些修正都被证明拥有某些能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [234] [OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent](https://arxiv.org/abs/2507.02353)
> *OMS：基于LLM代理的即时、多目标、自反思式广告关键词生成*

*Bowen Chen, Zhao Wang, Shingo Takamatsu* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 广告关键词生成, LLM代理, 多目标优化, 自反思, 即时性

**Comment:** 

> **TL;DR:** OMS是一种基于LLM的广告关键词生成框架，通过即时性、多目标和自反思能力克服了现有方法的局限性，并在实验中表现出卓越性能。

**AI_Comments:** 该论文通过引入“即时性”、“多目标”和“自反思”特性，创新性地解决了LLM在广告关键词生成中面临的数据依赖和在线优化等实际挑战。其重要性在于，它显著提升了广告关键词决策的自动化水平，有望通过直接优化业务关键KPI来提高广告活动的效率和效果。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LLM的广告关键词生成方法面临三大限制：过度依赖大规模查询-关键词对数据、缺乏在线多目标性能监控和优化，以及关键词选择的质量控制薄弱。这些问题阻碍了LLM在通过监控和推理关键绩效指标（如展示、点击、转化和CTA效果）来完全自动化关键词决策方面的代理使用。

**Method:** 提出OMS框架，其特点是：即时性（无需训练数据，监控在线性能并自适应）、多目标性（采用代理推理根据多个性能指标优化关键词）和自反思性（代理式评估关键词质量）。

**Result:** 在基准测试和真实世界广告活动中的实验表明，OMS优于现有方法。消融实验和人工评估证实了每个组件的有效性和生成关键词的质量。

**Conclusion:** OMS框架通过其即时性、多目标性和自反思能力，有效克服了当前LLM驱动的广告关键词生成方法的局限性，显著提升了性能和关键词质量。

> **ai_Abstract:** 本文提出OMS，一个基于LLM代理的广告关键词生成框架，旨在克服现有方法的局限性。OMS具有即时性（无需训练数据，在线适应）、多目标性（基于多种KPI优化）和自反思性（自动评估关键词质量）。实验证明，OMS在基准测试和实际广告活动中表现优于现有方法，其组件有效性及生成关键词质量也得到验证。

> **摘要翻译:** 赞助搜索广告中的关键词决策对广告活动成功至关重要。尽管基于LLM的方法提供了自动化关键词生成，但它们面临三个主要限制：依赖大规模查询-关键词对数据、缺乏在线多目标性能监控和优化，以及关键词选择中的质量控制薄弱。这些问题阻碍了LLM在通过监控和推理印象、点击、转化和CTA效果等关键绩效指标来完全自动化关键词决策方面的代理使用。为了克服这些挑战，我们提出了OMS，一个关键词生成框架，它具有即时性（无需训练数据，监控在线性能并相应调整）、多目标性（采用代理推理根据多个性能指标优化关键词）和自反思性（代理式评估关键词质量）。在基准测试和真实世界广告活动中的实验表明，OMS优于现有方法；消融和人工评估证实了每个组件的有效性和生成关键词的质量。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [245] [An AI-native experimental laboratory for autonomous biomolecular engineering](https://arxiv.org/abs/2507.02379)
> *用于自主生物分子工程的AI原生实验实验室*

*Mingyu Wu, Zhaoguo Wang, Jiabin Wang, Zhiyuan Dong, Jingkai Yang, Qingting Li, Tianyu Huang, Lei Zhao, Mingqiang Li, Fei Wang, Chunhai Fan, Haibo Chen* | **Category: cs.AI, q-bio.BM** | **Updated: {updated}**

**Keywords:** AI原生实验室, 生物分子工程, 自主科学, 自动化实验, 科学即服务

**Comment:** 

> **TL;DR:** 本文介绍了一个AI原生自主实验室，旨在实现复杂生物分子工程的自动化，能够自主管理仪器、制定实验流程并优化性能，从而克服对专家的依赖并提高效率。

**AI_Comments:** 这篇论文提出了一种创新的AI原生自主实验室，其核心创新在于能够处理高度复杂的、多目标的科学实验，并实现AI模型与自动化系统的协同演进。这超越了现有自主系统仅限于简单任务的局限性。其重要性在于，它为生物分子工程等领域提供了“科学即服务”的潜力，显著降低了对专家和资源的依赖，有望加速科学发现和应用。该系统的多用户支持和自主优化能力是其关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 实现自主科学研究，即能够独立进行复杂实验并服务非专业人士，是一个长期以来的愿望。尽管现有的自主实验系统已经出现，但它们仍局限于单一目标和简单工作流程的领域。因此，需要一个针对高度复杂科学实验（如生物分子工程）的AI原生自主实验室。

**Method:** 该AI原生自主实验室基于模型、实验和仪器的协同设计理念构建，支持AI模型和自动化系统的协同演进。它能够自主管理仪器、制定特定实验流程和优化启发式算法，并同时服务多个用户请求。该平台支持核酸的基本功能，包括合成、转录、扩增和测序。

**Result:** 该系统无需人工干预，即可自主优化实验性能，达到人类科学家所能实现的最新水平。在多用户场景下，该平台显著提高了仪器利用率和实验效率。它支持疾病诊断、药物开发和信息存储等应用。

**Conclusion:** 该AI原生自主实验室为克服先进生物材料研究中对专家和资源壁垒的依赖铺平了道路，并为大规模的“科学即服务”建立了蓝图。

> **ai_Abstract:** 本文介绍了一个AI原生自主实验室，旨在实现复杂生物分子工程的自动化。该系统通过协同设计模型、实验和仪器，能够自主管理仪器、制定实验流程并优化性能，同时服务多个用户。它支持核酸合成、转录、扩增和测序等功能，并在无需人工干预的情况下达到人类科学家水平的实验结果。该平台显著提高了仪器利用率和实验效率，为大规模的“科学即服务”模式奠定了基础，有望克服生物材料研究中对专家和资源的依赖。

> **摘要翻译:** 自主科学研究，即能够独立进行复杂实验并服务非专业人士，代表着一个长期以来的愿望。实现这一目标需要由人工智能（AI）驱动的根本性范式转变。尽管自主实验系统正在兴起，但它们仍然局限于具有单一目标和明确、简单实验流程的领域，例如化学合成和催化。我们提出了一个AI原生自主实验室，旨在针对高度复杂的科学实验，应用于自主生物分子工程等领域。该系统自主管理仪器，制定特定实验程序和优化启发式算法，并同时服务多个用户请求。该平台建立在模型、实验和仪器协同设计的理念之上，支持AI模型和自动化系统的协同演进。这建立了一个端到端、多用户的自主实验室，能够处理跨越不同仪器的复杂、多目标实验。我们的自主实验室支持基本的核酸功能——包括合成、转录、扩增和测序。它还支持疾病诊断、药物开发和信息存储等领域的应用。无需人工干预，它自主优化实验性能，以匹配人类科学家所达到的最新水平。在多用户场景中，该平台显著提高了仪器利用率和实验效率。该平台为先进生物材料研究克服对专家和资源壁垒的依赖铺平了道路，为大规模的“科学即服务”建立了蓝图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [254] [The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning](https://arxiv.org/abs/2507.02442)
> *高斯-马尔可夫伴随：监督学习中残差的范畴语义*

*Moto Kamiura* | **Category: cs.AI, math.CT, stat.ME, stat.ML** | **Updated: {updated}**

**Keywords:** 范畴论, 监督学习, 残差, 高斯-马尔可夫伴随, 可解释性

**Comment:** 

> **TL;DR:** 本文利用范畴论重新构建监督学习模型，特别关注多元线性回归中残差和参数的相互作用，引入高斯-马尔可夫伴随，以增强人工智能的可解释性。

**AI_Comments:** 本文创新性地将范畴论应用于机器学习领域，特别是用于形式化监督学习中残差和参数的语义。这种方法提供了一个严格的数学框架来增强人工智能的可解释性，这在当前是一个至关重要且日益增长的需求。文中提出的“高斯-马尔可夫伴随”概念是一个新颖的贡献，有助于阐明监督学习模型的基础结构。其重要性在于为理解和潜在构建更透明的AI系统提供了新视角，并成功连接了理论计算机科学与机器学习。

<details>
  <summary>Details</summary>

**Motivation:** 为响应人工智能可解释性原则的要求并促进人工智能的更好社会实施，提高机器学习的可理解性和可解释性是一项关键任务。本研究旨在通过范畴论的视角重新构建机器学习模型，从而开发一个用于构建和理解人工智能系统的语义框架，以实现这一改进。

**Method:** 该研究通过范畴论的视角重新构建机器学习模型，重点关注多元线性回归模型。具体方法包括定义与参数和数据对应的两个具体范畴，以及它们之间的一对伴随函子，从而引入监督学习的范畴公式（高斯-马尔可夫伴随）。在此框架下，明确描述了信息的双重流动，并将参数的普通最小二乘估计器与最小残差通过右伴随函子对极限的保留相关联。此外，该公式被定位为监督学习的扩展指称语义的一个实例。

**Result:** 研究阐明并形式化了监督学习中残差和参数之间的结构相互作用，并表明该框架的基本结构由高斯-马尔可夫伴随捕获。它明确描述了信息的双重流动是参数和残差变化之间的对应关系，并揭示了普通最小二乘估计器与最小残差通过右伴随函子对极限的保留而关联。

**Conclusion:** 该范畴公式，特别是高斯-马尔可夫伴随，为理解和增强监督学习模型的可解释性提供了形式化的语义基础。它提出将理论计算机科学中发展的语义视角作为人工智能可解释性的形式基础。

> **ai_Abstract:** 本文提出一个基于范畴论的监督学习语义框架，旨在提升AI的可解释性。研究以多元线性回归为核心，引入“高斯-马尔可夫伴随”概念，形式化了残差与参数间的关系，并描述了信息流，将最小二乘估计与最小残差关联起来。该工作将此视为监督学习的扩展指称语义，为AI可解释性提供了理论计算机科学视角的正式基础。

> **摘要翻译:** 提高机器学习的可理解性和可解释性是响应人工智能可解释性原则要求、促进人工智能更好社会实施的关键任务。我们研究的目的是通过范畴论的视角重新构建机器学习模型，从而开发一个用于构建和理解人工智能系统的语义框架，从而为这种改进做出贡献。本文中的范畴建模阐明并形式化了监督学习中残差和参数之间的结构相互作用。本文重点关注多元线性回归模型，它代表了监督学习最基本的形式。通过定义与参数和数据对应的两个具体范畴，以及它们之间的一对伴随函子，我们引入了监督学习的范畴公式。我们表明，该框架的基本结构由我们称之为高斯-马尔可夫伴随捕获。在此设置中，信息的双重流动可以明确描述为参数和残差变化之间的对应关系。参数的普通最小二乘估计器和最小残差通过右伴随函子对极限的保留而关联。此外，我们将这种公式定位为监督学习的扩展指称语义的一个实例，并建议将理论计算机科学中开发的语义视角作为人工智能可解释性的形式基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [264] [Clarifying Before Reasoning: A Coq Prover with Structural Context](https://arxiv.org/abs/2507.02541)
> *推理前先澄清：一个带有结构化上下文的Coq证明器*

*Yanzhen Lu, Hanbin Yang, Xiaodie Wang, Ge Zhang, Biao Li, Chenxu Fu, Chao Li, Yang Yuan, Andrew Chi-Chih Yao* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 任务清晰度, 大型语言模型, 定理证明, Coq, 结构化上下文

**Comment:** 

> **TL;DR:** 通过结构化语义上下文提高任务清晰度，显著提升了大型语言模型在Coq定理证明中的表现，超越了现有SOTA。

**AI_Comments:** 本文的创新之处在于明确地将任务清晰度作为提升LLM复杂推理能力（如定理证明）的关键因素。通过提供结构化的语义上下文，该研究有效证明了LLM性能的显著提升，为超越模型规模或训练数据量限制来增强AI推理能力指明了有前景的方向。其“推理前先澄清”的范式是一项新颖的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探究提高任务清晰度是否能增强大型语言模型（LLMs）的推理能力，特别是聚焦于Coq中的定理证明。

**Method:** 研究引入了一个概念级度量来评估任务清晰度，并通过向LLM的标准输入添加结构化语义上下文来提高清晰度。方法采用了选择性概念展开来丰富任务描述，并使用了规划器-执行器（Planner–Executor）架构。实验在从15个标准Coq包中随机抽取的1,386个定理上进行。

**Result:** 通过添加结构化语义上下文，任务清晰度得分提高了1.85倍（从44.5%到82.3%）。使用DeepSeek-V3模型，证明成功率提高了2.1倍（从21.8%到45.8%），并优于先前的最先进模型Graph2Tac（33.2%）。此外，在结构化数据上对小型模型进行微调可以实现更高的性能（48.6%）。

**Conclusion:** 这些发现强调了结构化任务表示在弥合理解与推理之间差距方面的价值。

> **ai_Abstract:** 本论文探讨了如何通过提高任务清晰度，特别是通过添加结构化语义上下文，显著增强大型语言模型在Coq定理证明中的能力。其方法结合了选择性概念展开和规划器-执行器架构，在使用DeepSeek-V3等模型时，在清晰度得分和证明成功率上均取得了显著提升，超越了现有最先进方法，并且通过微调小型模型获得了进一步的性能提升。

> **摘要翻译:** 在这项工作中，我们研究了提高任务清晰度是否能增强大型语言模型的推理能力，重点关注Coq中的定理证明。我们引入了一个概念级度量来评估任务清晰度，并表明在现代LLM使用的标准输入中添加结构化语义上下文，可以使清晰度得分提高1.85倍（44.5% → 82.3%）。使用通用模型DeepSeek-V3，我们的方法使证明成功率提高了2.1倍（21.8% → 45.8%），并且优于先前的最先进模型Graph2Tac（33.2%）。我们按照与Graph2Tac相同的评估协议，从15个标准Coq包中随机抽取1,386个定理进行了评估。此外，在我们的结构化数据上对较小模型进行微调可以实现更高的性能（48.6%）。我们的方法使用选择性概念展开来丰富任务描述，并采用规划器-执行器架构。这些发现强调了结构化任务表示在弥合理解与推理之间差距方面的价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [271] [AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench](https://arxiv.org/abs/2507.02554)
> *机器学习AI研究代理：MLE-bench中的搜索、探索和泛化*

*Edan Toledo, Karen Hambardzumyan, Martin Josifoski, Rishi Hazra, Nicolas Baldwin, Alexis Audran-Reiss, Michael Kuchnik, Despoina Magka, Minqi Jiang, Alisia Maria Lupidi, Andrei Lupu, Roberta Raileanu, Kelvin Niu, Tatiana Shavrina, Jean-Christophe Gagnon-Audet, Michael Shvartsman, Shagun Sodhani, Alexander H. Miller, Abhishek Charnalia, Derek Dunfield, Carole-Jean Wu, Pontus Stenetorp, Nicola Cancedda, Jakob Nicolaus Foerster, Yoram Bachrach* | **Category: cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** AI研究代理, 自动化机器学习, MLE-bench, 搜索策略, 操作符

**Comment:** Code: https://github.com/facebookresearch/aira-dojo

> **TL;DR:** 本文通过优化AI研究代理的搜索策略和操作符，在MLE-bench上取得了最先进的成果，提高了Kaggle竞赛的成功率。

**AI_Comments:** 本文通过对AI研究代理的搜索策略和操作符进行系统性探究，提出了在自动化机器学习领域取得性能提升的关键因素。其创新点在于将AI研究代理形式化为搜索策略，并强调了策略与操作符协同的重要性，为未来的自动化机器学习研究提供了新的视角和方法论。

<details>
  <summary>Details</summary>

**Motivation:** AI研究代理在自动化机器学习模型的设计、实现和训练方面显示出巨大潜力，旨在加速科学进步。本文旨在提高代理在MLE-bench这一挑战性基准上的性能，该基准要求代理解决现实世界的机器学习问题。

**Method:** 将AI研究代理形式化为搜索策略，这些策略通过操作符迭代修改候选解决方案。研究通过设计和系统地改变不同的操作符集和搜索策略（如贪婪、蒙特卡洛树搜索MCTS、进化）来分析它们之间的相互作用。

**Result:** 最佳的搜索策略和操作符集组合在MLE-bench lite上取得了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。

**Conclusion:** 研究强调了在推进自动化机器学习时，联合考虑搜索策略、操作符设计和评估方法的重要性。

> **ai_Abstract:** 本文探讨了提高AI研究代理在MLE-bench基准测试上性能的方法。通过将代理形式化为搜索策略并系统地测试不同的操作符集和搜索策略（如Greedy, MCTS, Evolutionary），研究发现搜索策略和操作符集之间的协同作用对于实现高性能至关重要。研究在MLE-bench lite上取得了最先进的结果，将Kaggle奖牌的成功率从39.6%提升到47.7%，并强调了联合考虑搜索策略、操作符设计和评估方法在自动化机器学习中的重要性。

> **摘要翻译:** AI研究代理在通过自动化机器学习模型的设计、实现和训练方面，展示出加速科学进步的巨大潜力。我们专注于提高代理在MLE-bench上的性能，MLE-bench是一个具有挑战性的基准测试，代理在此基准测试中参与Kaggle竞赛以解决现实世界的机器学习问题。我们将AI研究代理形式化为搜索策略，这些策略在候选解决方案空间中导航，并使用操作符迭代地修改它们。通过设计和系统地改变不同的操作符集和搜索策略（贪婪、蒙特卡洛树搜索MCTS、进化），我们发现它们的相互作用对于实现高性能至关重要。我们最佳的搜索策略和操作符集组合在MLE-bench lite上取得了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。我们的研究强调了在推进自动化机器学习时，联合考虑搜索策略、操作符设计和评估方法的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [279] [Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms](https://arxiv.org/abs/2507.02582)
> *责任差距与扩散在序列决策机制中*

*Junli Jiang, Pavel Naumov* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 责任, 集体决策, 计算复杂性, 扩散, 差距

**Comment:** 

> **TL;DR:** 本文研究了集体决策中责任的扩散和差距这两种性质的计算复杂性。

**AI_Comments:** 这篇论文通过引入计算复杂性的概念来分析责任在集体决策中的特性，具有一定的创新性。它量化了在复杂决策机制中消除责任模糊性的难度，对AI伦理和可解释AI领域可能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 责任在法律、哲学和AI领域都是一个重要研究主题。本文旨在探究集体决策中责任的扩散和差距的计算复杂性。

**Method:** 本文通过调查集体决策中责任的扩散和差距这两种性质的计算复杂性来进行研究。

**Result:** 无扩散决策机制的集合是 $\Pi_2$-完全的，无差距决策机制的集合是 $\Pi_3$-完全的。同时，这些类别的交集是 $\Pi_2$-完全的。

**Conclusion:** 本文通过计算复杂性分析，量化了集体决策中责任的扩散和差距的难度。

> **ai_Abstract:** 本文探讨了集体决策中责任的两个核心属性——扩散和差距的计算复杂性。研究发现，无扩散决策机制的集合是$\Pi_2$-完全的，无差距决策机制的集合是$\Pi_3$-完全的，而两者的交集则是$\Pi_2$-完全的。这揭示了在设计集体决策系统时，实现责任清晰性的计算挑战。

> **摘要翻译:** 责任长期以来一直是法律和哲学领域的研究课题。最近，它成为人工智能文献的焦点。本文研究了集体决策中责任的两个重要属性：扩散和差距的计算复杂性。结果表明，无扩散和无差距决策机制的集合分别是$\Pi_2$-完全和$\Pi_3$-完全的。同时，这些类别的交集是$\Pi_2$-完全的。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [287] [DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making](https://arxiv.org/abs/2507.02616)
> *DynamiCare：交互式开放式医疗决策的动态多智能体框架*

*Tianqi Shang, Weiqing He, Charles Zheng, Lingyao Li, Li Shen, Bingxin Zhao* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 动态多智能体, 医疗决策, LLM, 交互式诊断, MIMIC-Patient

**Comment:** 16 pages

> **TL;DR:** DynamiCare是一个动态多智能体框架，通过模拟多轮交互式诊断过程来改进LLM在医疗决策中的应用，并引入了MIMIC-Patient数据集进行基准测试。

**AI_Comments:** 该论文的创新之处在于弥补了现有AI模拟与真实世界复杂、迭代医疗诊断之间的差距。通过引入多智能体动态框架和定制数据集，它将LLM在医疗领域的应用推向了更真实的场景，并创建了一个新的基准，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医疗决策框架主要关注单轮任务，医生智能体预先获得所有信息，这与现实世界中不确定、交互式和迭代的诊断过程不符。

**Method:** 本文引入了MIMIC-Patient，一个基于MIMIC-III电子健康记录构建的结构化数据集，用于支持动态的患者级模拟。在此基础上，提出了DynamiCare，一个新颖的动态多智能体框架，将临床诊断建模为多轮、交互式循环，其中专家智能体团队迭代查询患者系统、整合新信息并动态调整其组成和策略。

**Result:** 通过广泛的实验，证明了DynamiCare的可行性和有效性，并为基于LLM的智能体动态临床决策建立了首个基准。

**Conclusion:** 本文成功引入了一个新颖的框架和数据集，通过模拟更真实的交互式诊断过程，解决了以往单轮医疗决策模型的局限性，从而建立了一个新的基准。

> **ai_Abstract:** 大型语言模型（LLMs）推动了医疗领域专业AI智能体的发展，但现有框架多限于单轮任务，与真实医疗诊断的交互性和不确定性不符。本文为此引入了MIMIC-Patient数据集，用于动态患者模拟，并提出了DynamiCare，一个动态多智能体框架。该框架将临床诊断模拟为多轮交互循环，专家智能体团队可迭代查询、整合信息并动态调整策略。实验证明了DynamiCare的可行性和有效性，并为LLM驱动的动态临床决策建立了首个基准。

> **摘要翻译:** 大型语言模型（LLM）的兴起使得开发具有领域特定推理和交互能力的专业AI智能体成为可能，尤其是在医疗保健领域。虽然最近的框架模拟了医疗决策，但它们主要集中在单轮任务上，即医生智能体预先接收到完整的病例信息——这与现实世界的诊断过程不同，后者本质上是不确定、交互式和迭代的。在本文中，我们介绍了MIMIC-Patient，一个基于MIMIC-III电子健康记录（EHRs）构建的结构化数据集，旨在支持动态的、患者层面的模拟。在此基础上，我们提出了DynamiCare，一个新颖的动态多智能体框架，它将临床诊断建模为一个多轮、交互式的循环，其中一个专家智能体团队迭代地查询患者系统，整合新信息，并动态调整其组成和策略。我们通过广泛的实验证明了DynamiCare的可行性和有效性，为基于LLM的智能体动态临床决策建立了第一个基准。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [293] [Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory](https://arxiv.org/abs/2507.02618)
> *大型语言模型的战略智能：来自演化博弈论的证据*

*Kenneth Payne, Baptiste Alloui-Cros* | **Category: cs.AI, cs.CL, cs.GT** | **Updated: {updated}**

**Keywords:** 大型语言模型, 战略智能, 演化博弈论, 囚徒困境, 机器心理学

**Comment:** 29 pages, 27 tables, 4 figures

> **TL;DR:** 研究通过演化囚徒困境测试LLM的战略智能，发现它们表现出独特的战略行为，且能主动推理。

**AI_Comments:** 本文创新性地将演化博弈论应用于评估大型语言模型的战略行为，揭示了不同LLM在竞争环境中的独特“战略指纹”，并证明了它们主动推理的能力，这对于理解LLM的“心智”及其在复杂社会互动中的潜在应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨大型语言模型（LLMs）是否具备战略智能，即在竞争环境中推理目标的能力。

**Method:** 进行了首次演化迭代囚徒困境（IPD）锦标赛，让主流LLM（OpenAI, Google, Anthropic）与经典策略对战。通过改变终止概率（“未来阴影”）引入复杂性和随机性，防止记忆。分析了近32,000个模型提供的散文推理。

**Result:** LLM在复杂生态系统中具有高度竞争力，能存活甚至繁衍。它们展现出独特的“战略指纹”：Google Gemini模型表现出无情战略，利用合作者并报复叛逃者；OpenAI模型高度合作，但在敌对环境中表现糟糕；Anthropic Claude是最宽容的互惠者。模型主动推理时间范围和对手策略，且这种推理对其决策至关重要。

**Conclusion:** 本研究将经典博弈论与机器心理学相结合，提供了在不确定性下算法决策的丰富细致的视角，并证明LLMs具备战略智能。

> **ai_Abstract:** 本文通过首次演化迭代囚徒困境锦标赛，评估了OpenAI、Google和Anthropic等主流大型语言模型（LLMs）的战略智能。研究发现LLMs在竞争环境中表现出高度竞争力，并展现出独特的战略“指纹”，例如Google Gemini的无情、OpenAI的高度合作以及Anthropic Claude的宽容互惠。此外，分析表明LLMs能够主动推理时间范围和对手策略，这些推理对其决策至关重要。这项工作将经典博弈论与机器心理学相结合，为理解LLMs在不确定性下的决策提供了新视角。

> **摘要翻译:** 大型语言模型（LLMs）是一种新型的战略智能，能够在竞争环境中推断目标吗？我们提供了令人信服的支持证据。《迭代囚徒困境》（IPD）长期以来一直作为研究决策的模型。我们进行了有史以来第一次演化IPD锦标赛系列，让经典策略（例如，一报还一报、严厉触发）与来自领先的前沿AI公司OpenAI、Google和Anthropic的代理进行对抗。通过改变每个锦标赛的终止概率（“未来阴影”），我们引入了复杂性和偶然性，从而混淆了记忆。
我们的结果表明，LLM具有高度竞争力，在这些复杂生态系统中持续生存甚至有时会大量繁殖。此外，它们表现出独特且持久的“战略指纹”：Google的Gemini模型被证明是战略上无情的，利用合作的对手并报复叛逃者，而OpenAI的模型保持高度合作，这一特质在敌对环境中被证明是灾难性的。Anthropic的Claude则成为最宽容的互惠者，即使在被利用或成功叛逃后，也表现出显著的恢复合作的意愿。对模型提供的近32,000个散文推理的分析表明，它们积极地推理时间范围和对手的可能策略，并且我们证明这种推理对其决策至关重要。这项工作将经典博弈论与机器心理学联系起来，提供了在不确定性下算法决策的丰富而细致的视图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [311] [Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models](https://arxiv.org/abs/2507.02663)
> *思考如何思考：大型推理模型中通过自主难度认知缓解过度思考*

*Yongjiang Liu, Haoxi Li, Xiaosong Ma, Jie Zhang, Song Guo* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 大型推理模型, 过度思考, 难度认知, 冗余认知, 微调策略

**Comment:** 21 pages, 18 figures

> **TL;DR:** 本文提出了TH2T，一种两阶段微调策略，通过赋予大型推理模型难度和冗余认知能力，显著缓解过度思考并降低推理成本。

**AI_Comments:** 该论文创新性地提出了TH2T框架，通过“难度催眠”和“冗余催眠”这两个独特的两阶段微调策略，解决了大型推理模型过度思考的关键问题。其核心在于赋予模型自主识别任务难度和精简推理过程的能力，这对于提高推理效率和降低计算成本具有重要意义。特别是在不牺牲性能的前提下，大幅减少推理成本，是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 长推理模型（LRMs）在复杂推理任务中表现出色，但受到过度思考的阻碍。实证分析表明，LRMs主要受限于在解决问题前识别任务属性（即难度级别），导致“一刀切”的推理过程。

**Method:** 本文提出了Think-How-to-Think (TH2T)，一种新颖的两阶段微调策略，逐步激发LRMs的难度认知和冗余认知。首先，通过在模型输出前缀中引入“难度催眠”来干预内部推理轨迹，结合异构长短推理数据集，增强模型对任务难度的敏感性，实现区分式推理策略。其次，将“冗余催眠”扩展到内部推理过程，引导模型识别推理步骤中的冗余结构，生成更简洁的推理输出。

**Result:** 在7B/14B/32B模型上的实验表明，TH2T显著降低了推理成本（简单任务超过70%，困难任务超过40%），同时保持了性能稳定性。产生的输出表现出清晰的难度感知能力和减少的冗余。

**Conclusion:** TH2T通过引入难度认知和冗余认知，有效缓解了大型推理模型中的过度思考问题，显著提高了推理效率，同时保持了模型性能。

> **ai_Abstract:** 本文提出了Think-How-to-Think (TH2T)，一个两阶段微调策略，旨在通过赋予大型推理模型自主难度认知和冗余认知能力来缓解过度思考问题。第一阶段通过“难度催眠”和异构数据集训练模型区分任务难度并采用差异化推理策略；第二阶段通过“冗余催眠”引导模型识别并减少推理中的冗余。实验证明，TH2T显著降低了推理成本，同时保持了性能，并使模型具备了难度感知和减少冗余的能力。

> **摘要翻译:** 长推理模型（LRMs）最近在处理复杂推理任务方面展现出卓越的能力，但却受到过度思考的阻碍。为了探索其本质，我们的实证分析揭示，LRMs在解决问题之前主要受限于像人类一样识别任务属性（即难度级别），导致“一刀切”的推理过程。受此启发，一个紧迫而自然的问题出现了：我们能否引导这种能力以进一步缓解LRMs中的过度思考现象？在本文中，我们提出了Think-How-to-Think (TH2T)，一种新颖的两阶段微调策略，它逐步激发LRMs的难度认知和冗余认知。首先，我们在模型输出的前缀中引入难度催眠，以干预内部推理轨迹。结合异构的长短推理数据集，训练后的模型增强了对任务难度的敏感性，从而在各种任务中实现原生的、差异化的推理策略。其次，我们进一步将冗余催眠扩展到内部推理过程，引导模型识别推理步骤中的冗余结构并生成更简洁的推理输出。在7B/14B/32B模型上的实验表明，TH2T显著降低了推理成本（简单任务超过70%，困难任务超过40%），同时保持了性能稳定性。产生的输出表现出清晰的难度感知能力和减少的冗余（例如，反射）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [318] [Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education](https://arxiv.org/abs/2507.02681)
> *远程高等教育中自愿测验脱离的检测：一种可解释的机器学习方法*

*Behnam Parsaeifard, Christof Imhof, Tansu Pancar, Ioan-Sorin Comsa, Martin Hlosta, Nicole Bergamin, Per Bergamin* | **Category: cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 学生脱离, 远程教育, 机器学习, 可解释人工智能, Moodle

**Comment:** 

> **TL;DR:** 本文通过分析Moodle日志数据，使用可解释机器学习方法检测远程教育学生在非强制性测验中的脱离行为，达到了91%的平衡准确率，并能正确识别85%的脱离学生，同时探讨了干预策略。

**AI_Comments:** 该论文的创新之处在于将可解释机器学习（SHAP）应用于远程教育中学生脱离这一关键问题。其高准确率和对模型可解释性的关注对于教育实践者实施有效的干预措施具有重要价值。此外，论文对干预措施设计的讨论也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 学生脱离学习任务可能导致严重的长期后果，包括学业辍学，这在远程教育中尤为突出。本研究旨在通过观察学生在非强制性测验中的参与情况来衡量脱离程度，并开发一种方法来及时检测这种脱离，以便进行干预。

**Method:** 研究从一所远程大学的42门课程、四个学期中提取了Moodle学生日志数据，并识别出最具信息量的特征。随后，训练并比较了八种机器学习算法以实现最高的预测准确性。为增强可解释性，研究采用了SHAP方法构建了一个可解释的机器学习框架。

**Result:** 实验结果显示，该方法达到了91%的平衡准确率，并且能够正确检测出约85%的脱离学生。

**Conclusion:** 本研究开发的基于可解释机器学习的框架能够高效准确地检测远程教育学生在自愿测验中的脱离行为，为设计及时干预措施以减少在线学习中的脱离提供了有力的支持。

> **ai_Abstract:** 本文旨在解决远程教育中学生脱离学习任务的问题，特别是通过分析学生在非强制性测验中的参与情况来检测脱离行为。研究利用来自42门课程的Moodle日志数据，训练并比较了八种机器学习算法，并使用SHAP方法构建了一个可解释的框架。实验结果表明，该方法能够以91%的平衡准确率检测出学生脱离，并准确识别约85%的脱离学生。此外，论文还探讨了如何设计及时干预措施以最小化在线学习中的脱离。

> **摘要翻译:** 学生脱离任务会带来严重的长期后果，包括学业辍学。这对于远程教育的学生尤其重要。衡量远程教育中脱离程度的一种方法是观察学生在不同在线课程中参与非强制性练习的情况。在本文中，我们检测了一所远程大学在四个学期、42门课程中学生在非强制性测验中的脱离情况。我们仔细识别了可以从Moodle中提取和处理的最有用的学生日志数据。然后，训练并比较了八种机器学习算法，以获得最高的预测准确性。我们使用SHAP方法开发了一个可解释的机器学习框架，使实践者能够更好地理解训练算法的决策。实验结果显示平衡准确率达到91%，其中大约85%的脱离学生被正确检测出来。除了高预测性能和可解释框架之外，我们还讨论了如何设计及时干预措施，以最大程度地减少在线学习中学生脱离自愿任务的情况。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [321] [Grounding Intelligence in Movement](https://arxiv.org/abs/2507.02771)
> *将智能根植于运动*

*Melanie Segado, Felipe Parodi, Jordan K. Matelsky, Michael L. Platt, Eva B. Dyer, Konrad P. Kording* | **Category: cs.AI, cs.CV, cs.LG, cs.RO** | **Updated: {updated}**

**Keywords:** 运动智能, 具身智能, AI建模, 行为理解, 机器学习

**Comment:** 9 pages, 2 figures

> **TL;DR:** 机器智能在处理语言、视觉等高维数据方面取得进展，但在运动方面仍面临挑战。本文主张将运动视为AI的主要建模目标，因为它具有固有结构且基于具身和物理，有助于理解生物和人工系统的行为。

**AI_Comments:** 这篇论文的创新点在于其明确地将“运动”提升到与语言、视觉同等重要的AI建模核心地位，而非仅仅是高维感官输入的附带结果。它指出当前AI在处理运动方面的不足，并强调运动固有的结构性、具身性和物理基础使其成为一个理想的建模目标。这一视角可能为具身智能、机器人控制和行为理解等领域带来新的突破，也为统一生物和人工智能研究提供了潜在途径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管机器学习在处理语言、视觉等高维数据方面取得了显著进展，但在理解和建模生物系统最基本方面之一——运动——时仍面临困难。运动在神经科学、医学、机器人学和行为学中对于解释行为、预测意图和实现交互至关重要，但常被视为次要而非独立的、丰富的结构化模态。这种碎片化的处理方式限制了其建模，因此需要将运动视为AI的主要建模目标。

**Method:** 本文提出将运动视为AI的主要建模目标，理由是运动本身具有结构性，并根植于具身和物理。这种结构允许更紧凑、低维的表示（例如姿态），使其比原始高维感官输入更易于解释和计算建模。通过开发能够从多样化运动数据中学习并泛化的模型，可以推进生成建模和控制的核心能力。

**Result:** Not mentioned in abstract

**Conclusion:** 运动不仅是智能系统的结果，更是理解智能系统如何与世界交互的窗口。将运动作为AI的主要建模目标，可以推进生成建模和控制能力，并为理解生物和人工系统行为提供共同基础。

> **ai_Abstract:** 本文强调尽管当前机器学习在处理高维数据方面取得进展，但在理解和建模运动方面仍存在不足。运动是生物系统智能的核心，对解释行为和交互至关重要。作者主张将运动视为AI的首要建模目标，因为它具有固有的结构性，并基于具身和物理特性，能够实现更紧凑、易于解释的低维表示。开发此类模型不仅能提升生成建模和控制能力，还能为跨生物和人工系统理解行为奠定基础，将运动视为智能系统与世界交互的关键窗口。

> **摘要翻译:** 机器学习的最新进展显著提高了我们建模语言、视觉和其他高维数据的能力，但它们在生物系统最基本方面之一——运动——上仍然举步维艰。在神经科学、医学、机器人学和行为学领域，运动对于解释行为、预测意图和实现交互至关重要。尽管运动在我们的智能中具有核心意义，但它常常被视为事后补充，而非其本身丰富且结构化的模态。这反映了运动数据收集和建模方式更深层次的碎片化，通常受限于任务特定目标和领域特定假设。但运动并非领域受限。它反映了跨物种和环境的共享物理约束、保守的形态结构和有目的的动力学。我们认为，运动应被视为AI的主要建模目标。它本质上是结构化的，并根植于具身和物理。这种结构通常允许紧凑的低维表示（例如姿态），使其比原始高维感官输入更易于解释和计算建模。开发能够从多样化运动数据中学习并泛化的模型，不仅将推进生成建模和控制的核心能力，还将为理解生物和人工系统之间的行为创造一个共同基础。运动不仅仅是一个结果，它是智能系统如何与世界交互的窗口。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [322] [Time-critical and confidence-based abstraction dropping methods](https://arxiv.org/abs/2507.02703)
> *时间关键和基于置信度的抽象丢弃方法*

*Robin Schmöcker, Lennart Kampmann, Alexander Dockhorn* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 蒙特卡洛树搜索, 抽象丢弃, OGA-IAAD, OGA-CAD, 近似误差

**Comment:** Accepted for Publication at the IEEE Conference on Games 2025

> **TL;DR:** 提出两种新的抽象丢弃方法 (OGA-IAAD, OGA-CAD) 用于蒙特卡洛树搜索 (MCTS)，可在保证安全性的前提下提高性能。

**AI_Comments:** 本文的创新点在于提出了两种“安全”的抽象丢弃方法，解决了现有MCTS抽象方法可能导致性能下降的问题。通过区分时间关键型（OGA-IAAD）和性能优化型（OGA-CAD），该研究为MCTS的应用提供了更鲁棒和高效的解决方案，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有MCTS中使用的非精确抽象会引入近似误差，导致无法收敛到最优动作，且现有抽象丢弃方法（如Xu等人的方法）可能导致性能下降。

**Method:** 提出了两种新的抽象丢弃方案：OGA-IAAD 和 OGA-CAD。OGA-IAAD 针对时间关键设置，OGA-CAD 旨在以相同迭代次数提高MCTS性能。

**Result:** 这两种新方法在保证安全性的前提下（即不会导致显著性能下降），能够带来明显的性能提升，这与Xu的丢弃方法不同。

**Conclusion:** 论文提出了两种创新且安全的抽象丢弃方法，有效解决了MCTS中非精确抽象引入的近似误差问题，并在不同场景下提升了MCTS性能。

> **ai_Abstract:** 本文针对蒙特卡洛树搜索（MCTS）中非精确抽象引入的近似误差问题，提出了两种新型的抽象丢弃方法：OGA-IAAD和OGA-CAD。与现有方法可能导致性能下降不同，这两种方法在保证安全性的前提下，能够显著提升MCTS的性能。其中，OGA-IAAD适用于时间敏感场景，OGA-CAD则侧重于在相同迭代次数下优化MCTS表现。

> **摘要翻译:** 蒙特卡洛树搜索（MCTS）改进的一种范式是在树搜索过程中构建和使用状态和/或动作抽象。然而，非精确抽象会引入近似误差，使得在抽象空间中无法收敛到最优动作。因此，正如Xu等人作为弹性蒙特卡洛树搜索的一个组件所提出的那样，抽象算法最终应该丢弃抽象。在本文中，我们提出了两种新颖的抽象丢弃方案，即OGA-IAAD和OGA-CAD，它们可以带来明显的性能提升，同时是安全的，因为与Xu的丢弃方法相反，丢弃永远不会导致任何显著的性能下降。OGA-IAAD专为时间关键设置而设计，而OGA-CAD旨在以相同迭代次数提高MCTS性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [325] [Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving](https://arxiv.org/abs/2507.02726)
> *Bourbaki: 自生成和目标条件MDPs用于定理证明*

*Matthieu Zimmer, Xiaotong Ji, Rasul Tutunov, Anthony Bordg, Jun Wang, Haitham Bou Ammar* | **Category: cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 自动化定理证明, 大型语言模型, 马尔可夫决策过程, 蒙特卡洛树搜索, 子目标生成

**Comment:** 

> **TL;DR:** Bourbaki引入了自生成目标条件MDPs和MCTS来解决自动化定理证明中的挑战，并在PutnamBench上取得了SOTA结果。

**AI_Comments:** 该论文的创新点在于引入了自生成目标条件MDPs（sG-MDPs）框架，将复杂的定理证明问题分解为更易于搜索的子目标。结合MCTS和模块化LLM集成，有效提升了大型语言模型在自动化定理证明领域的推理能力，并在具有挑战性的PutnamBench上取得了显著的SOTA成果，这对于LLM在逻辑推理和数学证明方面的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自动化定理证明（ATP）这种逻辑约束环境中进行推理仍然具有挑战性，主要原因在于稀疏奖励和巨大的证明规模，尤其是在需要复杂多步推理的PutnamBench等基准测试中。

**Method:** 本研究引入了自生成目标条件马尔可夫决策过程（sG-MDPs）框架，其中智能体根据不断演变的证明状态生成并追求子目标，使问题更适合搜索。然后，应用蒙特卡洛树搜索（MCTS）类算法来解决sG-MDP，并在Bourbaki（7B）中实例化了该方法，Bourbaki是一个模块化系统，可以集成多个7B LLM进行子目标生成和策略合成。

**Result:** 在PutnamBench上，Bourbaki（7B）解决了26个问题，在该规模的模型中取得了新的最先进结果。

**Conclusion:** 所提出的自生成目标条件MDPs（sG-MDPs）框架结合MCTS和模块化LLM系统（Bourbaki）有效地解决了自动化定理证明中的挑战，并在复杂基准测试上实现了最先进的性能。

> **ai_Abstract:** 本论文提出了一种名为Bourbaki的系统，该系统利用自生成目标条件马尔可夫决策过程（sG-MDPs）和蒙特卡洛树搜索（MCTS）算法来解决自动化定理证明中大型语言模型面临的推理挑战。Bourbaki通过模块化地集成多个7B大型语言模型进行子目标生成和策略合成，在PutnamBench基准测试中取得了26个问题的解决，达到了该规模模型的最新最优结果。

> **摘要翻译:** 大型语言模型（LLMs）的推理仍然是一项具有挑战性的任务，特别是在自动化定理证明（ATP）的逻辑约束环境中，由于稀疏奖励和巨大的证明规模。在PutnamBench等基准测试中，这些挑战被放大，该基准测试包含需要复杂多步推理的大学级问题。为了解决这个问题，我们引入了自生成目标条件马尔可夫决策过程（sG-MDPs），这是一个新的框架，其中智能体根据不断演变的证明状态生成并追求其子目标。鉴于这种更结构化的目标生成，所产生的问题变得更适合搜索。然后，我们应用蒙特卡洛树搜索（MCTS）类算法来解决sG-MDP，并在Bourbaki（7B）中实例化了我们的方法，Bourbaki（7B）是一个模块化系统，可以集成多个7B LLM进行子目标生成和策略合成。在PutnamBench上，Bourbaki（7B）解决了26个问题，在该规模的模型中取得了新的最先进结果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [328] [Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work](https://arxiv.org/abs/2507.02760)
> *知识协议工程：领域特定知识工作中人工智能的新范式*

*Guangwei Zhang* | **Category: cs.AI** | **Updated: {updated}**

**Keywords:** 知识协议工程, 大型语言模型, 领域特定知识, 人工智能, 人机协作

**Comment:** 

> **TL;DR:** 引入知识协议工程（KPE），通过将人类专家知识转化为机器可执行的知识协议，使大型语言模型（LLMs）在领域特定知识工作中表现得像专家，克服了RAG和通用代理的局限性。

**AI_Comments:** 该论文提出了一种创新范式——知识协议工程（KPE），它超越了当前大型语言模型（LLMs）的增强方法，如RAG和通用代理，通过将领域专家知识转化为可执行的协议，赋予LLMs更深层次的领域理解和推理能力。其重要性在于，它有望使LLMs在专业领域（如法律和生物信息学）中真正实现“专家”级别的表现，为复杂、程序性知识工作中的人机协作奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）方法，如检索增强生成（RAG）和通用代理AI，在处理需要深层、程序化和方法论推理的专家领域任务时常常遇到困难。RAG无法传达逻辑框架，而自主代理在没有领域特定启发式方法的情况下效率低下且不可预测。

**Method:** 本文提出知识协议工程（KPE），这是一种将人类专家知识（通常以自然语言文档形式表达）系统地转化为机器可执行的知识协议（KP）的新范式。KPE旨在赋予LLMs领域固有的逻辑、操作策略和方法论原则，而非仅仅用零碎信息增强它们。

**Result:** 通过精心设计的知识协议，通用型大型语言模型能够像专家一样运作，能够分解抽象查询并执行复杂的、多步骤的任务。

**Conclusion:** 知识协议工程被视为未来人机协作的基础方法论，有望在法律和生物信息学等不同领域发挥应用潜力。

> **ai_Abstract:** 本文提出知识协议工程（KPE），旨在解决大型语言模型（LLMs）在处理领域特定复杂任务时面临的挑战。KPE通过将人类专家知识系统地转化为机器可执行的知识协议，使LLMs能够掌握领域固有的逻辑和操作策略，从而克服了RAG和通用代理的局限性。KPE使通用LLM能够像专家一样执行复杂的分解和多步任务，被认为是未来人机协作的关键基础方法。

> **摘要翻译:** 大型语言模型（LLMs）的能力为与复杂、领域特定知识的交互开辟了新领域。然而，当前主流的方法，如检索增强生成（RAG）和通用型代理AI，虽然强大，但在处理需要专家领域固有的深层、程序化和方法论推理的任务时常常遇到困难。RAG提供了事实上下文，但未能传达逻辑框架；自主代理在没有领域特定启发式方法的情况下可能效率低下且不可预测。为了弥合这一差距，我们引入了知识协议工程（KPE），这是一种新范式，专注于系统地将人类专家知识（通常以自然语言文档形式表达）转化为机器可执行的知识协议（KP）。KPE将重点从仅仅用零碎信息增强LLMs，转变为赋予它们领域固有的逻辑、操作策略和方法论原则。我们认为，一个精心设计的知识协议允许通用型LLM像专家一样运作，能够分解抽象查询并执行复杂的、多步骤的任务。这篇立场论文定义了KPE的核心原则，将其与相关概念区分开来，并阐明了其在法律和生物信息学等不同领域的潜在适用性，将其定位为未来人机协作的基础方法论。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [338] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
> *建立严格的智能体基准测试的最佳实践*

*Yuxuan Zhu, Tengjun Jin, Yada Pruksachatkun, Andy Zhang, Shu Liu, Sasha Cui, Sayash Kapoor, Shayne Longpre, Kevin Meng, Rebecca Weiss, Fazl Barez, Rahul Gupta, Jwala Dhamala, Jacob Merizian, Mario Giulianelli, Harry Coppock, Cozmin Ududec, Jasjeet Sekhon, Jacob Steinhardt, Antony Kellerman, Sarah Schwettmann, Matei Zaharia, Ion Stoica, Percy Liang, Daniel Kang* | **Category: cs.AI, A.1; I.2.m** | **Updated: {updated}**

**Keywords:** 智能体基准测试, 评估, 最佳实践, ABC, 人工智能

**Comment:** 39 pages, 15 tables, 6 figures

> **TL;DR:** 现有智能体基准测试存在问题，导致评估不准确；本文提出智能体基准测试清单（ABC），一套最佳实践指南，可显著提高评估的严谨性和准确性。

**AI_Comments:** 本文的创新之处在于系统性地识别了现有智能体基准测试的常见问题，并提出了一个实用的、基于经验和最佳实践的“智能体基准测试清单（ABC）”来解决这些问题。其重要性在于，它为构建更严谨、更准确的智能体评估框架提供了明确的指导，对于确保AI智能体能力的可靠衡量至关重要。通过具体案例（CVE-Bench）展示其有效性，增加了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI智能体能力日益增强，智能体基准测试被引入以评估其在复杂现实世界任务中的表现。然而，许多现有智能体基准测试在任务设置或奖励设计上存在问题，导致对智能体性能的低估或高估高达100%。为了使智能体评估更加严谨，本研究旨在建立一套最佳实践。

**Method:** 本研究引入了智能体基准测试清单（ABC），这是一套综合了作者的基准构建经验、最佳实践调查以及先前报告问题而形成的指南。这些指南旨在解决现有基准测试中任务设置和奖励设计的问题。

**Result:** 研究发现，现有智能体基准测试的问题（如SWE-bench Verified的测试用例不足，TAU-bench将空响应计为成功）可能导致对智能体性能高达100%的相对低估或高估。将ABC应用于CVE-Bench（一个评估设计特别复杂的基准测试）后，性能的高估减少了33%。

**Conclusion:** 通过引入并应用智能体基准测试清单（ABC），可以有效识别并纠正现有智能体基准测试中的缺陷，从而显著提高智能体性能评估的严谨性和准确性。

> **ai_Abstract:** 本文指出当前智能体基准测试在任务设置和奖励设计上存在缺陷，导致智能体性能评估不准确。为解决此问题，作者提出了智能体基准测试清单（ABC），一套基于经验和最佳实践的指南。实验表明，应用ABC能有效减少评估中的性能高估，从而提高智能体评估的严谨性。

> **摘要翻译:** 基准测试对于量化跟踪人工智能的进展至关重要。随着人工智能智能体能力日益增强，研究人员和从业者引入了智能体基准测试，以评估智能体在复杂、现实世界任务中的表现。这些基准测试通常通过特定的奖励设计来评估任务结果，从而衡量智能体的能力。然而，我们发现许多智能体基准测试在任务设置或奖励设计上存在问题。例如，SWE-bench Verified使用的测试用例不足，而TAU-bench将空响应计为成功。这些问题可能导致智能体性能被低估或高估，相对误差高达100%。为了使智能体评估更加严谨，我们引入了智能体基准测试清单（ABC），这是一套我们从基准构建经验、最佳实践调查以及先前报告的问题中综合得出的指南。当应用于CVE-Bench（一个评估设计特别复杂的基准测试）时，ABC将性能高估减少了33%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [341] [StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason](https://arxiv.org/abs/2507.02841)
> *StepHint：多级分步提示增强强化学习推理能力*

*Kaiyi Zhang, Ang Lv, Jinpeng Li, Yongbo Wang, Feng Wang, Haoyuan Hu, Rui Yan* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: {updated}**

**Keywords:** 强化学习, 大型语言模型, 推理, 分步提示, 近失奖励问题

**Comment:** 

> **TL;DR:** StepHint是一种新的RLVR算法，通过提供多级分步提示来解决近失奖励问题和探索停滞问题，从而提高LLM的推理能力和训练效率，并在数学基准测试中表现优异。

**AI_Comments:** StepHint的创新之处在于其独特的多级分步提示机制，它巧妙地平衡了引导探索和保持模型独立性的需求。通过引入外部知识（来自更强模型）以结构化的分步形式，该方法有效缓解了强化学习中常见的奖励稀疏性和探索不足问题，这对于提高LLM在复杂推理任务上的效率和鲁棒性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可验证奖励强化学习（RLVR）方法面临两大挑战：一是“近失奖励问题”，即微小错误可能导致整个推理过程无效，严重阻碍训练效率；二是“探索停滞”，模型倾向于在其“舒适区”内寻找解决方案，缺乏探索更有效替代方案的动力。

**Method:** StepHint通过从更强的模型生成有效的推理链，并使用自适应划分方法将这些链分解为推理步骤。它将初始的几个步骤作为提示，并同时向模型提供多级提示（每级包含不同数量的步骤）。这种方法引导模型在保留独立探索灵活性的同时，向有前景的解决方案子空间探索。

**Result:** StepHint在六个数学基准测试中均优于竞争性RLVR增强方法，同时还展示了卓越的泛化能力，并在域外基准测试中超越了基线。

**Conclusion:** StepHint通过引入多级分步提示，有效解决了RLVR中的近失奖励问题和探索停滞问题，显著提高了大型语言模型的推理能力和训练效率，并在多个数学基准测试中展现出优异的性能和泛化能力。

> **ai_Abstract:** 本文提出了一种名为StepHint的新型可验证奖励强化学习（RLVR）算法，旨在解决大型语言模型（LLM）在复杂推理中面临的近失奖励问题和探索停滞问题。StepHint通过从更强模型生成推理链并将其划分为多级分步提示，引导模型有效探索解决方案空间。这种方法不仅提高了训练效率，还通过提供外部推理路径帮助模型跳出“舒适区”，从而增强其推理能力。实验结果表明，StepHint在多个数学基准测试中表现优异，并展现出更好的泛化能力。

> **摘要翻译:** 可验证奖励强化学习（RLVR）是一种很有前景的方法，用于提高大型语言模型（LLM）的复杂推理能力。然而，当前的RLVR方法面临两大显著挑战：一是近失奖励问题，即一个微小的错误可能使原本正确的推理过程无效，极大地阻碍了训练效率；二是探索停滞，模型倾向于专注于其“舒适区”内的解决方案，缺乏探索潜在更有效替代方案的动力。为了应对这些挑战，我们提出了StepHint，一种新颖的RLVR算法，它利用多级分步提示来帮助模型更有效地探索解决方案空间。StepHint从更强的模型生成有效的推理链，并使用我们提出的自适应划分方法将这些链划分为推理步骤。初始的几个步骤被用作提示，同时，向模型提供多级提示（每级包含不同数量的步骤）。这种方法将模型的探索引向一个有前景的解决方案子空间，同时保留了其独立探索的灵活性。通过提供提示，StepHint缓解了近失奖励问题，从而提高了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其能够超越其“舒适区”并缓解探索停滞。StepHint在六个数学基准测试中均优于竞争性RLVR增强方法，同时还展示了卓越的泛化能力，并在域外基准测试中超越了基线。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [15] [Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows](https://arxiv.org/abs/2507.01975)
> *可学习可微分有限体积求解器用于加速流体模拟*

*Mengtao Yan, Qi Wang, Haining Wang, Ruizhi Chengze, Yi Zhang, Hongsheng Liu, Zidong Wang, Fan Yu, Qi Qi, Hao Sun* | **Category: cs.LG, cs.AI, physics.flu-dyn** | **Updated: {updated}**

**Keywords:** 流体模拟, 有限体积法, 可学习, 可微分, 加速模拟

**Comment:** 19 pages, 12 figures, accepted at KDD 2025 (ACM SIGKDD Conference on
  Knowledge Discovery and Data Mining)

> **TL;DR:** 提出一种可学习可微分有限体积求解器LDSolver，能在粗网格上高效准确地模拟流体，同时保持高泛化性。

**AI_Comments:** 这篇论文的创新点在于将传统的可微分有限体积求解器与机器学习的可学习模块相结合，有效解决了传统方法的计算效率和纯机器学习方法的泛化性及数据依赖性问题。这种混合方法为流体模拟提供了一个高效且准确的新范式，尤其适用于需要在粗网格上进行快速模拟的场景。其在有限数据下的优秀表现也凸显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统数值求解器需要精细网格导致计算成本高昂；纯机器学习方法存在可解释性、泛化性和数据依赖性问题。

**Method:** 提出LDSolver，一个可学习可微分的有限体积求解器。它包含两个核心组件：1) 可微分有限体积求解器；2) 可学习模块，用于提供通量（导数和插值）的等效近似和粗网格上的时间误差校正。

**Result:** 即使在有限训练数据下，LDSolver也能加速模拟并保持高精度和卓越的泛化性。在Burgers、衰减流、强制流和剪切流等不同流体系统上的实验表明，LDSolver实现了最先进的性能，显著超越了基线模型。

**Conclusion:** LDSolver提供了一种高效、准确且泛化性强的流体模拟方法，有效解决了传统方法和纯机器学习方法的局限性。

> **ai_Abstract:** 本文提出了一种名为LDSolver的可学习可微分有限体积求解器，旨在解决传统流体模拟器计算成本高和纯机器学习方法泛化性差的问题。LDSolver结合了可微分有限体积求解器和可学习模块，用于近似通量和校正粗网格上的时间误差。实验证明，即使在数据有限的情况下，LDSolver也能在多种流体系统中实现高效、准确且泛化性强的模拟，性能超越现有基线模型。

> **摘要翻译:** 流体模拟对于气象学、空气动力学和生物医学等物理现象的建模至关重要。经典的数值求解器通常需要精细的时空网格才能满足稳定性、一致性和收敛性条件，从而导致巨大的计算成本。尽管机器学习已表现出更高的效率，但它们通常存在可解释性、泛化性和数据依赖性问题。因此，我们提出了一种可学习和可微分的有限体积求解器，称为LDSolver，旨在粗时空网格上高效准确地模拟流体。LDSolver包含两个关键组件：(1) 可微分有限体积求解器；(2) 可学习模块，提供通量（导数和插值）的等效近似，以及粗网格上的时间误差校正。即使训练数据有限（例如，仅有少量轨迹），我们的模型也能加速模拟，同时保持高精度和卓越的泛化性。在不同流体系统（例如，Burgers流、衰减流、强制流和剪切流）上的实验表明，LDSolver实现了最先进的性能，显著超越了基线模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [44] [DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism](https://arxiv.org/abs/2507.01982)
> *DKGCM：一种融合空间节点聚类方法和傅里叶双向Mamba机制的交通流时空预测模型*

*Siqing Long, Xiangzhi Huang, Jiemin Xie, Ming Cai* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 交通流预测, 时空预测, 图卷积网络, 双向Mamba, 强化学习

**Comment:** 39 pages, 14 figures

> **TL;DR:** DKGCM是一种新的交通流时空预测模型，通过结合基于时间相似性的空间聚类（DK-GCN）和傅里叶双向Mamba机制来提高预测精度，并在公共数据集上表现优异。

**AI_Comments:** 这篇论文的创新点在于结合了空间节点聚类（基于DTW和K-means的DK-GCN）与傅里叶双向Mamba机制来处理交通流的时空复杂性，并引入强化学习策略优化训练。这种多组件融合的方法有望更全面地捕捉交通数据的复杂模式，提高了预测准确性，对智能交通系统资源管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 交通系统中复杂的时空关系限制了交通需求预测模型的性能，而准确的交通需求预测能有效分配资源并提高利用效率。

**Method:** 提出DKGCM模型。空间维度上，使用基于动态时间规整（DTW）和K-means聚类的DK-GCN方法对交通节点进行分组以捕获空间依赖。时间维度上，将快速傅里叶变换（FFT）集成到双向Mamba深度学习框架中以捕获时间依赖。此外，引入GRPO强化学习策略优化损失函数反馈机制。

**Result:** 模型在三个公共数据集上优于几种先进方法，并取得了良好结果。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种名为DKGCM的新型图卷积网络结构，旨在提高交通流时空预测的准确性。该模型通过DK-GCN捕获空间依赖，其中利用动态时间规整和K-means聚类对交通节点进行分组。在时间维度上，DKGCM将快速傅里叶变换与双向Mamba框架结合以捕捉时间依赖。此外，模型还引入GRPO强化学习策略优化训练过程。实验证明，DKGCM在多个公共数据集上超越了现有先进方法。

> **摘要翻译:** 准确的交通需求预测使交通管理部门能够更有效地分配资源，从而提高其利用效率。然而，交通系统中复杂的时空关系继续限制着需求预测模型的性能。为了提高时空交通需求预测的准确性，我们提出了一种新的图卷积网络结构，名为DKGCM。具体来说，我们首先考虑不同交通节点的空间流分布，并提出了一种新颖的基于时间相似性的聚类图卷积方法DK-GCN。该方法利用动态时间规整（DTW）和K-means聚类来对交通节点进行分组，更有效地捕获空间依赖。在时间尺度上，我们将快速傅里叶变换（FFT）集成到双向Mamba深度学习框架中，以捕获交通需求中的时间依赖。为了进一步优化模型训练，我们引入了GRPO强化学习策略来增强损失函数反馈机制。大量实验表明，我们的模型优于几种先进方法，并在三个公共数据集上取得了优异的结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [64] [Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features](https://arxiv.org/abs/2507.01984)
> *使用语言、视觉和社会特征早期融合的多模态虚假信息检测*

*Gautam Kishore Shahi* | **Category: cs.LG, cs.CL, cs.SI** | **Updated: {updated}**

**Keywords:** 多模态检测, 虚假信息, 早期融合, 社交媒体, 机器学习

**Comment:** 

> **TL;DR:** 本研究通过早期融合语言、视觉和社会特征，提高了多模态虚假信息检测的性能，比单模态模型提升15%，比双模态模型提升5%。

**AI_Comments:** 该研究的创新之处在于其多模态早期融合方法，整合了语言、视觉和社会特征，这在以往研究中较少被全面探索。其重要性在于显著提升了虚假信息检测的准确性，并提供了对虚假信息传播模式的见解。然而，局限性可能在于其数据集仅限于特定时期和平台（Twitter/X），结果的泛化能力可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体上充斥着选举和危机期间的大量虚假信息，现有研究主要集中在文本或图像的单模态检测，而很少有研究探索多模态特征组合来构建分类模型。

**Method:** 本研究调查了使用早期融合方法整合文本、图像和社会特征的不同多模态特征组合的有效性。分析了从Twitter（现为X）收集的1,529条包含文本和图像的COVID-19疫情和选举期间的推文。通过物体检测和光学字符识别（OCR）等技术，应用数据丰富过程来提取额外的社会特征和视觉特征。

**Result:** 结合无监督和有监督机器学习模型，分类性能比单模态模型提高了15%，比双模态模型提高了5%。此外，研究还分析了基于虚假信息推文特征及其传播用户的虚假信息传播模式。

**Conclusion:** 通过早期融合语言、视觉和社会特征的多模态方法，可以显著提高虚假信息检测的性能。

> **ai_Abstract:** 本研究旨在解决社交媒体上虚假信息泛滥的问题，通过早期融合语言、视觉和社会特征，构建多模态分类模型进行虚假信息检测。研究分析了1,529条包含文本和图像的推文，并提取了额外的社会和视觉特征。实验结果表明，该多模态方法结合无监督和有监督机器学习模型，比单模态模型性能提升15%，比双模态模型提升5%。研究还探讨了虚假信息的传播模式。

> **摘要翻译:** 在选举和危机期间，社交媒体上充斥着虚假信息，大量研究已经对虚假信息检测进行了研究，主要集中在基于文本或图像的方法。然而，只有少数研究探索了多模态特征组合，例如整合文本和图像来构建虚假信息检测的分类模型。本研究调查了不同多模态特征组合的有效性，使用早期融合方法将文本、图像和社会特征整合到分类模型中。本研究分析了从Twitter（现为X）收集的1,529条在COVID-19大流行和选举期间同时包含文本和图像的推文。通过物体检测和光学字符识别（OCR）等技术，应用数据丰富过程来提取额外的社会特征和视觉特征。结果显示，结合无监督和有监督机器学习模型，分类性能比单模态模型提高了15%，比双模态模型提高了5%。此外，本研究还分析了基于虚假信息推文特征及其传播用户的虚假信息传播模式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [94] [Positive region preserved random sampling: an efficient feature selection method for massive data](https://arxiv.org/abs/2507.01998)
> *正区域保留随机抽样：一种针对海量数据的高效特征选择方法*

*Hexiang Bai, Deyu Li, Jiye Liang, Yanhui Zhai* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 特征选择, 海量数据, 粗糙集, 随机抽样, 判别能力

**Comment:** 

> **TL;DR:** 本文提出了一种基于抽样技术和粗糙集理论的新型特征选择方法，通过构建正区域保留样本，可以在个人电脑上高效地从海量数据中选择出具有高判别能力的特征子集，并能估计其判别能力的下限。

**AI_Comments:** 该论文的创新点在于将粗糙集理论与采样技术结合，解决了海量数据下特征选择的效率问题。通过引入正区域保留样本的概念，保证了所选特征子集能够保留原始数据的判别能力，并且能够在计算资源有限的个人电脑上实现，这对于实际应用具有重要意义。同时，能够估计判别能力下限也增加了方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 智能机器在处理海量数据时通常计算资源不足，而选择相关特征是其成功的必要步骤。本文旨在解决海量数据特征选择的挑战。

**Method:** 本文提出了一种基于抽样技术和粗糙集理论的新方法。该方法使用可区分对象对与所有应区分对象对的比例来衡量特征集的判别能力。在此基础上，通过从海量数据中构建正区域保留样本来寻找具有高判别能力的特征子集。

**Result:** 实验结果表明，该方法能在很短时间内找到近似约简，并且最终约简的判别能力大于估计的下限。在大型数据集上的实验也证明，可以在个人电脑上在合理时间内获得具有高判别能力的近似约简。

**Conclusion:** 所提出的正区域保留随机抽样方法能够高效地从海量数据中选择出保留判别能力的特征子集，并且其判别能力可被有效估计。

> **ai_Abstract:** 本文针对海量数据特征选择中计算资源有限的问题，提出了一种基于抽样技术和粗糙集理论的新方法。该方法通过引入判别能力度量，并构建正区域保留样本，旨在高效地选择出能保持原始数据判别能力的特征子集。实验验证了该方法能够在个人电脑上快速找到高质量的近似约简，并且其判别能力可被有效估计。

> **摘要翻译:** 选择相关特征是智能机器最大限度提高成功机会的重要且必要步骤。然而，智能机器在面对海量数据时通常没有足够的计算资源。本文开发了一种基于抽样技术和粗糙集理论的新方法，以解决海量数据的特征选择挑战。为此，本文提出使用可区分对象对与所有应区分对象对的比例来衡量特征集的判别能力。基于此度量，提出了一种新的特征选择方法。该方法从海量数据中构建正区域保留样本，以寻找具有高判别能力的特征子集。与其他方法相比，所提出的方法具有两个优点。首先，它能够在个人电脑上在可接受的时间内选择一个能够保留目标海量数据集所有特征判别能力的特征子集。其次，在找到约简之前，可以估计使用所选特征子集在所有应区分对象对中可区分对象对的概率下限。此外，使用11个不同大小的数据集验证了所提出的方法。结果表明，可以在很短的时间内找到近似约简，并且最终约简的判别能力大于估计的下限。在四个大型数据集上的实验也表明，可以在个人电脑上在合理的时间内获得具有高判别能力的近似约简。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [118] [Continuous Wavelet Transform and Siamese Network-Based Anomaly Detection in Multi-variate Semiconductor Process Time Series](https://arxiv.org/abs/2507.01999)
> *基于连续小波变换和Siamese网络的多变量半导体过程时间序列异常检测*

*Bappaditya Dey, Daniel Sorensen, Minjin Hwang, Sandip Halder* | **Category: cs.LG, I.2.0; J.6** | **Updated: {updated}**

**Keywords:** 连续小波变换, Siamese网络, 异常检测, 多变量时间序列, 半导体制造

**Comment:** 13 pages, 7 figures, submitted to IEEE Transactions on Semiconductor
  Manufacturing

> **TL;DR:** 该论文提出了一种新颖的方法，结合连续小波变换（CWT）和Siamese网络，用于多变量半导体过程时间序列中的异常检测，并在真实数据上取得了高精度。

**AI_Comments:** 该论文的创新点在于将连续小波变换（CWT）与Siamese网络相结合，解决了半导体制造MTS数据异常检测中的多项挑战，如高维度、类别不平衡和非平稳性。通过将时间序列转换为图像，并利用预训练的CNN模型进行特征提取和比较，提供了一种新颖的视角。其在真实数据集上的高精度表现以及在监督和半监督场景下的灵活性，使其成为一个有前景的解决方案。未来的工作可以探索其在线部署的能力。

<details>
  <summary>Details</summary>

**Motivation:** 半导体制造过程极其复杂，具有高数据维度、严重的类别不平衡、测量噪声和缺失、以及生产系统非平稳性等挑战，使得多变量时间序列（MTS）中的异常预测和根本原因分析变得复杂。

**Method:** 该方法包括三个主要步骤：a) 使用连续小波变换（CWT）将MTS数据转换为图像表示；b) 通过在自定义CWT图像数据集上微调预训练的VGG-16架构来开发多类图像分类器；c) 构建一个由两个相同子网络组成的Siamese网络，每个子网络都使用微调后的VGG-16作为骨干。网络输入成对的CWT图像（一个参考，一个查询），通过比较两者的嵌入来判断是否属于同一类别。

**Result:** 该方法在真实的FAB过程时间序列数据集上展示了高精度的异常识别能力，为过程和工具跟踪数据的离线异常检测提供了有前景的解决方案。

**Conclusion:** 该方法在半导体制造MTS数据异常检测中表现出高精度和灵活性，可应用于监督和半监督设置，为离线异常检测提供了一个有前景的方案。

> **ai_Abstract:** 本文提出了一种新颖的机器学习方法，用于半导体制造中多变量时间序列（MTS）的异常检测。该方法首先利用连续小波变换（CWT）将MTS数据转换为图像表示，然后通过微调VGG-16模型构建图像分类器，并最终采用Siamese网络结构，通过比较参考和查询CWT图像的嵌入来识别异常。该方法在真实半导体生产数据上验证了其高精度，并展示了在监督和半监督设置下的应用潜力，为复杂的半导体工艺异常检测提供了有效方案。

> **摘要翻译:** 半导体制造是一个极其复杂的过程，其特点是数千个相互依赖的参数通过不同的工具和工艺步骤收集。多变量时间序列（MTS）分析已成为在这种环境中实现实时监控、故障检测和预测性维护的关键方法。然而，半导体制造中的异常预测面临几个关键挑战，包括高数据维度、由于真实故障的罕见性导致的严重类别不平衡、噪声和缺失测量，以及生产系统的非平稳行为。此外，变量之间复杂的相互依赖关系以及故障在下游阶段的延迟出现使得异常检测和根本原因分析都变得复杂。本文提出了一种新颖且通用的方法，利用机器学习进行MTS数据中的异常检测。所提出的方法包括三个主要步骤：a) 使用连续小波变换将MTS数据转换为基于图像的表示；b) 通过在自定义CWT图像数据集上微调预训练的VGG-16架构来开发多类图像分类器；c) 构建一个由两个相同子网络组成的Siamese网络，每个子网络都利用微调后的VGG-16作为骨干。该网络将成对的CWT图像作为输入——一个作为参考或锚点（代表已知良好信号），另一个作为查询（代表未知信号）。然后，模型比较两个输入的嵌入，以确定它们在给定时间步是否属于同一类别。我们的方法在真实FAB过程时间序列数据集上展示了高精度的异常识别能力，为过程和工具跟踪数据的离线异常检测提供了一个有前景的解决方案。此外，该方法灵活，可应用于监督和半监督设置。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [122] [Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions](https://arxiv.org/abs/2507.02087)
> *评估大型语言模型在招聘决策中的前景与陷阱*

*Eitan Anzenberg, Arunava Samajpati, Sivasankaran Chandrasekar, Varun Kacholia* | **Category: cs.LG, cs.CL, cs.CY** | **Updated: {updated}**

**Keywords:** 大型语言模型, 招聘决策, 算法偏见, 公平性, 领域特定模型

**Comment:** 10 pages, 2 figures, 2 tables. Submitted to NeurIPS 2025

> **TL;DR:** 本研究评估了通用大型语言模型（LLM）在招聘中的准确性和偏见问题，并将其与自研的领域特定模型进行对比。结果显示，自研模型在准确性和公平性上均优于通用LLM，强调了领域特定建模和偏见审计在高风险应用中的重要性，并指出准确性和公平性可兼得。

**AI_Comments:** 这项研究通过实证比较揭示了通用LLM在招聘这一高风险领域中可能存在的局限性，特别是在公平性方面。其创新之处在于不仅指出了问题，还通过展示自研领域特定模型Match Score的优越性，提供了一个可行的解决方案。研究强调了“领域特定建模”和“偏见审计”的关键作用，这对于AI在高风险应用中的负责任部署具有重要指导意义。此外，它挑战了准确性和公平性之间的传统二元对立，证明两者可以兼得，这对于AI伦理和实践都具有积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在招聘中虽然有望简化流程，但其在准确性和算法偏见方面引发了严重担忧，尤其是在缺乏充分保障措施的情况下。本研究的动机是评估LLM在招聘决策中的表现，特别是其预测准确性和公平性。

**Method:** 研究对包括OpenAI、Anthropic、Google、Meta和Deepseek在内的多个最先进的基础LLM进行了基准测试，并将其与专有的领域特定招聘模型（Match Score）进行比较，用于求职者匹配。评估基于约10,000个真实世界的近期候选人-职位对数据集，采用预测准确性指标（ROC AUC、精确召回率AUC、F1分数）和公平性指标（跨声明的性别、种族和交叉亚群的截止分析影响比率）进行评估。

**Result:** 实验结果显示，Match Score在准确性上优于通用LLM（ROC AUC 0.85 vs 0.77），并在人口统计学群体间取得了显著更公平的结果。Match Score的最低种族影响比率为0.957（接近均等），而最佳LLM为0.809或更低（交叉亚群分别为0.906 vs 0.773）。研究指出，预训练偏见可能导致缺乏充分保障的LLM在招聘场景中传播社会偏见，而定制的监督模型能更有效缓解这些偏见。此外，研究通过实证证明，招聘中的准确性和公平性并非二元对立，精心设计的算法可以同时实现两者。

**Conclusion:** 在招聘等高风险领域部署AI时，领域特定建模和偏见审计至关重要，不应在没有广泛公平性保障的情况下依赖现成的LLM。精心设计的算法可以同时实现招聘的准确性和结果的公平性。

> **ai_Abstract:** 本文评估了通用大型语言模型（LLM）在招聘决策中的应用，并将其与一个专有的领域特定招聘模型（Match Score）进行比较。研究发现，虽然LLM在招聘中具有潜力，但其在准确性和公平性方面存在不足，容易传播社会偏见。通过对约10,000个真实候选人-职位对的实验，结果显示Match Score在准确性（ROC AUC 0.85 vs 0.77）和公平性（最低种族影响比率0.957 vs 0.809）上均显著优于通用LLM。研究强调了在招聘等高风险领域，领域特定建模和偏见审计的重要性，并指出精心设计的算法可以同时实现招聘的准确性和结果的公平性。

> **摘要翻译:** 大型语言模型（LLM）在招聘中的应用有望简化候选人筛选流程，但也引发了对其准确性和算法偏见的严重担忧，尤其是在缺乏充分保障措施的情况下。在这项工作中，我们对多个最先进的基础LLM——包括来自OpenAI、Anthropic、Google、Meta和Deepseek的模型——进行了基准测试，并将其与我们专有的领域特定招聘模型（Match Score）进行比较，用于求职者匹配。我们评估了每个模型的预测准确性（ROC AUC、精确召回率AUC、F1分数）和公平性（跨声明的性别、种族和交叉亚群的截止分析影响比率）。我们对大约10,000个真实世界近期候选人-职位对数据集进行的实验表明，Match Score在准确性上优于通用LLM（ROC AUC 0.85 vs 0.77），并在人口统计学群体间取得了显著更公平的结果。值得注意的是，Match Score达到了0.957的最低种族影响比率（接近均等），而最佳LLM为0.809或更低（交叉亚群分别为0.906 vs 0.773）。我们讨论了为什么预训练偏见可能导致缺乏充分保障措施的LLM在招聘场景中传播社会偏见，而定制的监督模型可以更有效地缓解这些偏见。我们的发现强调了在招聘等高风险领域部署AI时，领域特定建模和偏见审计的重要性，并警告不要在没有广泛公平性保障的情况下依赖现成的LLM来执行此类任务。此外，我们通过实证证据表明，在招聘中选择准确性和公平性之间不应存在二元对立：精心设计的算法可以同时实现招聘的准确性和结果的公平性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [141] [Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames](https://arxiv.org/abs/2507.02001)
> *时间链式思考：通过帧思考理解长视频*

*Anurag Arnab, Ahmet Iscen, Mathilde Caron, Alireza Fathi, Cordelia Schmid* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 时间链式思考, 长视频理解, 视频问答, 视觉-语言模型, 上下文选择

**Comment:** 

> **TL;DR:** 提出了一种名为“时间链式思考”的推理策略，通过模型自身迭代选择最相关帧来解决长视频理解中VLM处理长上下文的挑战，并在多个视频问答数据集上取得了最先进的结果，尤其在长视频上表现出色。

**AI_Comments:** 这项工作提出了一种新颖的推理策略，通过让模型自身参与到上下文选择中，有效解决了长视频理解中关键帧识别和长上下文处理的难题。其创新性在于将“链式思考”的概念扩展到时间维度，并利用VLM的自选择能力来提升性能。在处理超长视频方面的显著提升尤其重要，为未来VLM在复杂、长时间视频分析中的应用开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉-语言模型（VLMs）取得了进展，但长视频理解仍然是一个挑战。现有的长上下文VLM虽然可以处理大量输入帧，但仍难以有效利用序列长度，并易受上下文窗口中不相关干扰的影响。

**Method:** 本文提出了“时间链式思考”（Temporal Chain of Thought），这是一种用于视频问答的推理策略，旨在优化模型的输入上下文。该方法利用VLM自身迭代地识别和提取视频中最相关的帧，然后使用这些帧进行问答。

**Result:** 该方法通过在推理时投入更多计算来选择最相关的上下文，从而提高了准确性。在4个不同的视频问答数据集上取得了最先进的结果，并在3种不同的VLM上显示出持续的改进。特别是在无法完全适应模型上下文窗口的更长视频上表现突出：在LVBench上超过1小时的长视频中，使用32K上下文窗口的方法比使用700K上下文窗口的标准推理方法性能高出2.8点。

**Conclusion:** “时间链式思考”通过智能地选择相关帧，有效解决了长视频理解中VLM处理长上下文的挑战，显著提高了视频问答的性能，尤其是在超长视频场景下。

> **ai_Abstract:** 本文提出了一种名为“时间链式思考”（Temporal Chain of Thought）的推理策略，旨在解决长视频理解中视觉-语言模型（VLMs）处理长上下文的挑战。该方法通过VLM自身迭代地识别和提取视频中最相关的帧来优化输入上下文，从而有效避免不相关干扰。实验结果表明，该策略在多个视频问答数据集上取得了最先进的性能，并在处理超长视频时显示出显著优势，证明了在推理时进行上下文选择的有效性。

> **摘要翻译:** 尽管视觉-语言模型（VLMs）最近取得了进展，但长视频理解仍然是一个具有挑战性的问题。尽管最先进的长上下文VLM可以处理大约1000个输入帧，但它们仍然难以有效利用这种序列长度，并且容易受到上下文窗口内不相关干扰的影响。我们提出了时间链式思考（Temporal Chain of Thought），这是一种用于视频问答的推理策略，它能够筛选模型的输入上下文。我们使用VLM本身迭代地识别和提取视频中最相关的帧，然后将这些帧用于回答问题。我们证明了在推理时利用更多计算来选择最相关的上下文可以提高准确性，这与最近关于LLM推理时扩展的工作相符。此外，我们在4个不同的视频问答数据集上取得了最先进的结果，显示出3种不同VLM的一致改进。特别是，我们的方法在那些无法适应模型上下文窗口的更长视频上表现出色：在LVBench上超过1小时的长视频中，我们使用32K上下文窗口的方法比使用700K上下文窗口的相同VLM标准推理方法性能高出2.8点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [159] [Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications](https://arxiv.org/abs/2507.02291)
> *基于知识图谱的可解释与泛化零样本语义通信*

*Zhaoyu Zhang, Lingyi Wang, Wei Wu, Fuhui Zhou, Qihui Wu* | **Category: cs.LG, cs.AI, cs.IT, math.IT** | **Updated: {updated}**

**Keywords:** 知识图谱, 零样本学习, 语义通信, 泛化能力, 可解释性

**Comment:** 

> **TL;DR:** 提出了一种基于知识图谱增强的零样本语义通信（KGZS-SC）网络，以解决数据驱动语义通信缺乏可解释性和泛化能力的问题，尤其是在处理未见数据时。该网络通过知识图谱和零样本学习，实现了对未见类别的鲁棒分类和高效通信。

**AI_Comments:** 该论文通过引入知识图谱和零样本学习，有效解决了传统数据驱动语义通信在面对未见数据时的泛化能力和可解释性不足的痛点。其创新点在于结合结构化语义知识来指导通信过程，使得系统不仅能够处理已知数据，还能对未知数据进行有效推理和分类，这对于动态和资源受限环境下的语义通信具有重要意义。该方法有望为未来智能通信系统的发展提供新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据驱动的语义通信依赖于表层统计模式，导致缺乏可解释性和泛化能力，尤其是在面对未见数据时表现不佳。

**Method:** 提出了一种新颖的知识图谱增强零样本语义通信（KGZS-SC）网络。该方案利用基于知识图谱的语义知识库（KG-SKB）提供的结构化语义信息，实现泛化语义表示和对未见情况的推理。KG-SKB在共享类别语义嵌入空间中对齐语义特征，并通过对齐的语义特征增强发射机的泛化能力，从而通过选择性传输紧凑的视觉语义来降低通信开销。在接收端，利用零样本学习（ZSL）直接对未见情况进行分类，无需重新训练或额外计算开销。

**Result:** 在APY数据集上进行的仿真结果表明，所提出的KGZS-SC网络在各种信噪比（SNR）水平下，在分类未见类别方面表现出强大的泛化能力，并显著优于现有语义通信框架。

**Conclusion:** 该研究成功提出并验证了基于知识图谱的零样本语义通信网络，有效解决了传统语义通信在可解释性和未见数据泛化方面的挑战，显著提升了通信效率和分类性能。

> **ai_Abstract:** 本文提出了一种知识图谱增强零样本语义通信（KGZS-SC）网络，旨在解决传统数据驱动语义通信在可解释性和未见数据泛化方面的不足。该网络通过构建基于知识图谱的语义知识库（KG-SKB）来提供结构化语义信息，并在发射端增强语义特征的泛化能力，从而减少通信开销。在接收端，结合零样本学习（ZSL）实现对未见类别的直接分类，无需额外训练，提升了系统在动态和资源受限环境下的适应性和效率。仿真结果表明，KGZS-SC在未见类别分类方面表现出优越的泛化能力和性能。

> **摘要翻译:** 数据驱动的语义通信基于表层统计模式，因此缺乏可解释性和泛化能力，尤其是在存在未见数据的应用中。为了解决这些挑战，我们提出了一种新颖的知识图谱增强零样本语义通信（KGZS-SC）网络。在基于知识图谱的语义知识库（KG-SKB）的结构化语义信息指导下，我们的方案提供了泛化的语义表示，并实现了对未见情况的推理。具体来说，KG-SKB在共享类别语义嵌入空间中对齐语义特征，并通过对齐的语义特征增强发射机的泛化能力，从而通过选择性传输紧凑的视觉语义来降低通信开销。在接收端，利用零样本学习（ZSL）直接对未见情况进行分类，无需重新训练或额外计算开销，从而增强了动态或资源受限环境中分类过程的适应性和效率。在APY数据集上进行的仿真结果表明，所提出的KGZS-SC网络在各种信噪比水平下，在分类未见类别方面表现出强大的泛化能力，并显著优于现有语义通信框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [162] [AIRES: Accelerating Out-of-Core GCNs via Algorithm-System Co-Design](https://arxiv.org/abs/2507.02006)
> *AIRES：通过算法-系统协同设计加速核外GCNs*

*Shakya Jayakody, Youpeng Zhao, Jun Wang* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 图卷积网络, 稀疏广义矩阵乘法, 核外计算, 算法-系统协同设计, 内存优化

**Comment:** 36th IEEE International Conference on Application-Specific Systems,
  Architectures and Processors. (Accepted)

> **TL;DR:** AIRES通过算法-系统协同设计，显著加速了用于GCN的核外稀疏广义矩阵乘法（SpGEMM），解决了现有系统的高I/O延迟和GPU利用率不足问题。

**AI_Comments:** AIRES的创新之处在于其对算法和系统层面的协同设计。通过同时优化稀疏数据对齐和内存调度，它有效解决了核外计算中的关键瓶颈。特别是引入分层内存系统和双向数据传输策略，对于提升大规模图数据的处理效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于图卷积网络（GCNs）的核外稀疏广义矩阵乘法（SpGEMM）系统存在高I/O延迟和GPU利用率不足的问题，主要瓶颈在于稀疏格式数据对齐和内存分配。

**Method:** 本文提出了AIRES，一种新颖的算法-系统协同设计解决方案。在算法层面，AIRES通过块级稀疏矩阵数据对齐和分块算法来解决数据对齐问题。在系统层面，AIRES采用三阶段动态调度，利用GPU内存、GPU Direct Storage（GDS）和主机内存的分层内存系统，实现了双向数据传输策略，以减少I/O延迟并提高吞吐量。

**Result:** AIRES在实际图处理基准测试中，与现有最先进方法相比，延迟降低了1.8倍。

**Conclusion:** AIRES通过算法-系统协同设计有效地解决了核外SpGEMM的性能瓶颈，显著提高了GCNs的计算效率。

> **ai_Abstract:** 本文提出了AIRES，一个针对图卷积网络（GCNs）中核外稀疏广义矩阵乘法（SpGEMM）的算法-系统协同设计方案。它解决了现有系统在数据对齐和内存分配方面的高I/O延迟和GPU利用率不足问题。AIRES在算法层面优化了稀疏矩阵的块级数据对齐，并开发了分块算法；在系统层面，它采用三阶段动态调度和分层内存系统（GPU内存、GDS、主机内存）的双向数据传输策略。实验结果表明，AIRES在实际图处理基准测试中，相比现有技术，延迟降低了1.8倍。

> **摘要翻译:** 图卷积网络（GCNs）是各种科学应用的基础，从生物医学蛋白质-蛋白质相互作用（PPI）到大规模推荐系统。GCNs中建模图结构的一个重要组成部分是稀疏广义矩阵乘法（SpGEMM）。随着图数据规模的不断扩大，由于资源受限系统中GPU内存空间有限，SpGEMM通常以核外方式进行。尽管最近通过GPU特征缓存、混合CPU-GPU内存布局或以稀疏格式执行计算等方式，旨在缓解核外SpGEMM的内存限制，但当前系统仍然面临高I/O延迟和GPU利用率不足的问题。
在本文中，我们首先识别了现有系统的问题，其中稀疏格式数据对齐和内存分配是主要的性能瓶颈，并提出了AIRES，一种新颖的算法-系统协同设计解决方案，用于加速GCNs的核外SpGEMM计算。具体来说，从算法角度，AIRES提出在块级别缓解稀疏格式矩阵的数据对齐问题，并开发了一种分块算法以促进行块级对齐。在系统层面，AIRES采用三阶段动态调度，其特点是利用分层内存系统（整合GPU内存、GPU Direct Storage（GDS）和主机内存）的双向数据传输策略，以减少I/O延迟并提高吞吐量。评估表明，AIRES显著优于现有最先进的方法，在实际图处理基准测试中实现了高达1.8倍的延迟降低。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [171] [TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification](https://arxiv.org/abs/2507.02510)
> *TFOC-Net: 一种基于短时傅里叶变换的深度学习方法，用于增强跨受试者运动想象分类*

*Ahmed G. Habashi, Ahmed M. Azab, Seif Eldawlatly, Gamal M. Aly* | **Category: cs.LG, cs.HC, cs.NE** | **Updated: {updated}**

**Keywords:** 运动想象分类, 脑机接口, 短时傅里叶变换, 深度学习, 跨受试者

**Comment:** 

> **TL;DR:** 提出TFOC-Net，利用STFT和深度学习显著提高跨受试者运动想象BCI分类性能，超越现有技术。

**AI_Comments:** 本文的创新点在于结合了优化的短时傅里叶变换（STFT）与深度学习（CNN）来处理EEG数据，并针对跨受试者分类的挑战性问题提出了平衡批处理策略。其重要性体现在显著提高了免校准BCI的分类准确性，为实际应用铺平道路，并贡献了开放数据集，促进了该领域的研究进展。该方法在多个数据集上超越了现有技术，显示出其鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 跨受试者运动想象（CS-MI）分类由于个体间脑电图（EEG）模式的显著变异性而具有挑战性，导致分类精度低于受试者特定模型，阻碍了免校准BCI的开发。

**Method:** 引入TFOC-Net方法，通过优化预处理和深度学习技术增强CS-MI分类。具体包括：对短时傅里叶变换（STFT）后的EEG数据进行直接分类，优化STFT参数，以及在卷积神经网络（CNN）训练期间采用平衡批处理策略。

**Result:** 在四个不同数据集（包括三个常用基准数据集）上验证，显著提高了跨受试者分类性能。在BCI竞赛IV数据集1 (IV-1)上达到67.60%，数据集2A (IV-2A)上达到65.96%，数据集2B (IV-2B)上达到80.22%，优于现有最先进技术。还系统研究了使用不同MI窗口（从4秒到1秒）的分类性能。

**Conclusion:** 该研究为可泛化、免校准的MI分类建立了新基准，并贡献了一个鲁棒的开放获取数据集以推动该领域研究。

> **ai_Abstract:** 本文提出TFOC-Net，一种基于短时傅里叶变换（STFT）和深度学习的创新方法，旨在解决脑机接口中跨受试者运动想象（CS-MI）分类的挑战。该方法通过优化STFT参数、直接对变换后的EEG数据进行分类以及在CNN训练中采用平衡批处理策略，显著提升了CS-MI的分类性能。TFOC-Net在多个基准数据集上取得了优于现有技术的分类精度，为可泛化、免校准的MI分类树立了新基准，并提供了一个开放获取的数据集。

> **摘要翻译:** 脑机接口（BCI）中的跨受试者运动想象（CS-MI）分类是一项具有挑战性的任务，因为不同个体间的脑电图（EEG）模式存在显著差异。这种变异性通常导致分类精度低于受试者特定模型，成为开发适用于实际应用的免校准BCI的主要障碍。在本文中，我们引入了一种新颖的方法，通过优化的预处理和深度学习技术显著增强了跨受试者MI分类性能。我们的方法包括对短时傅里叶变换（STFT）后的EEG数据进行直接分类、优化STFT参数以及在卷积神经网络（CNN）训练期间采用平衡批处理策略。该方法在四个不同数据集（包括三个广泛使用的基准数据集）上进行了独特验证，显著提高了跨受受试者分类，在BCI竞赛IV数据集1 (IV-1)上达到67.60%，在数据集2A (IV-2A)上达到65.96%，在数据集2B (IV-2B)上达到80.22%，优于现有最先进技术。此外，我们系统地研究了使用从完整4秒窗口到1秒窗口的MI窗口的分类性能。这些结果为可泛化、免校准的MI分类建立了新的基准，并贡献了一个鲁棒的开放获取数据集以推动该领域的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [179] [Classification by Separating Hypersurfaces: An Entropic Approach](https://arxiv.org/abs/2507.02732)
> *分离超曲面分类：一种熵方法*

*Argimiro Arratia, Mahmoud El Daou, Henryk Gzyl* | **Category: cs.LG, cs.IT, math.IT, physics.data-an, stat.ML, 90C05, 90C25, 90C47, 90C52, 68T01, 68T05, 68T07, 68T20, 68W01** | **Updated: {updated}**

**Keywords:** 分类, 熵方法, 超曲面, 机器学习, 决策边界

**Comment:** 15 pages, 10 tables, 4 figures

> **TL;DR:** 本文提出了一种基于熵函数最小化的新颖分类方法，通过在有界超立方体中搜索参数向量来实现数据分离，可处理线性和非线性可分性问题。

**AI_Comments:** 这篇论文提出了一种创新的、基于熵的分类方法，与传统的几何或优化方法（如SVM）不同。其核心创新在于利用熵函数最小化来确定分离超曲面，并且能够灵活地处理非线性边界，这增强了其在复杂数据集上的适用性。该方法的鲁棒性和处理多样化分类任务的能力是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习中，寻找分离两类数据的超平面是一个核心问题，传统方法如支持向量机和梯度下降存在局限性，需要一种更鲁棒的替代方案。

**Method:** 通过最小化定义在未知变量空间上的基于熵的函数，在以原点为中心的有界N维超立方体中搜索参数向量，并结合一个正的M维向量。该方法可扩展到多项式曲面，实现更复杂的决策边界。

**Result:** 数值实验证明了该方法在处理包括线性和非线性可分性在内的各种分类任务中的效率和多功能性。

**Conclusion:** 该基于熵的分类方法为传统的线性或二次优化技术提供了一种鲁棒的替代方案，并能有效处理多种分类任务。

> **ai_Abstract:** 本文提出了一种新颖的分类方法，旨在解决机器学习中分离两类数据的核心问题。该方法通过最小化一个基于熵的函数来寻找参数向量，以在N维空间中构建分离超曲面，并且能够扩展到多项式曲面以处理更复杂的决策边界。数值实验结果表明，该方法在处理线性和非线性分类任务时表现出高效性和多功能性，为支持向量机和梯度下降等传统优化技术提供了一个强有力的替代。

> **摘要翻译:** 我们考虑以下分类问题：给定一个由在${\mathbb R}^N$中表示的属性向量所表征的个体群体，目标是在${\mathbb R}^N$中找到一个超平面，将对应于两个不同类别的两组点分开。这个问题，其历史可以追溯到感知器模型，在机器学习中仍然是核心问题。在本文中，我们提出了一种新颖的方法，通过在以原点为中心的有界N维超立方体中搜索一个参数向量以及在${\mathbb R}^M$中的一个正向量来实现，这些向量是通过最小化定义在未知变量空间上的基于熵的函数获得的。该方法可以扩展到多项式曲面，从而允许通过更复杂的决策边界来分离数据点。这为传统的线性或二次优化技术（如支持向量机和梯度下降）提供了一个鲁棒的替代方案。数值实验证明了该方法在处理包括线性和非线性可分性在内的各种分类任务中的效率和多功能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [182] [GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters](https://arxiv.org/abs/2507.02085)
> *GeoAda：使用等变适配器高效微调几何扩散模型*

*Wanjia Zhao, Jiaqi Han, Siyi Gu, Mingjian Jiang, James Zou, Stefano Ermon* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 几何扩散模型, 等变适配器, 微调, SE(3)等变性, 参数效率

**Comment:** 

> **TL;DR:** GeoAda是一种SE(3)等变适配器框架，用于高效微调几何扩散模型，解决下游任务中的几何控制问题，同时保持模型几何一致性并防止过拟合。

**AI_Comments:** GeoAda的创新之处在于其SE(3)等变适配器设计，这不仅保证了微调过程中几何归纳偏置的完整性，还通过轻量级模块实现了参数高效的微调。这对于需要处理几何数据的领域，如分子和材料科学，具有重要意义。它有效解决了在保持模型核心能力的同时适应新任务的挑战，是扩散模型微调领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 几何扩散模型在分子动力学和结构生成方面表现出色，但针对不同几何控制的下游任务进行高效微调仍未得到充分探索。现有方法可能导致过拟合和灾难性遗忘。

**Method:** 提出SE(3)等变适配器框架GeoAda。它引入结构化适配器设计：控制信号通过耦合算子编码，由预训练模型层副本处理，然后通过解耦算子和等变零初始化卷积投射回。仅微调轻量级适配器模块，保持模型几何一致性，并减轻过拟合和灾难性遗忘。理论证明适配器保持SE(3)等变性。

**Result:** GeoAda在多种几何控制类型（帧控制、全局控制、子图控制）和应用领域（粒子动力学、分子动力学、人体运动预测、分子生成）中表现出广泛适用性。经验结果显示GeoAda实现了最先进的微调性能，同时保持了原始任务的准确性，而其他基线则因过拟合和灾难性遗忘导致性能显著下降。

**Conclusion:** GeoAda提供了一种高效、灵活且参数效率高的微调几何扩散模型的方法，适用于各种受控生成任务，同时保持了几何一致性并避免了常见微调问题。

> **ai_Abstract:** 本文提出了GeoAda，一个SE(3)等变适配器框架，旨在高效且参数高效地微调几何扩散模型，以适应具有不同几何控制的下游生成任务。GeoAda通过引入结构化适配器设计，仅微调轻量级模块，从而保持模型的几何一致性并有效避免过拟合和灾难性遗忘。理论和实验结果均表明，GeoAda在多种几何控制类型和应用中实现了最先进的微调性能，优于现有基线。

> **摘要翻译:** 几何扩散模型在分子动力学和结构生成方面取得了显著成功。然而，针对具有不同几何控制的下游任务高效微调它们仍未得到充分探索。在这项工作中，我们提出了一个SE(3)等变适配器框架（GeoAda），它能够为受控生成任务实现灵活且参数高效的微调，而无需修改原始模型架构。GeoAda引入了一种结构化的适配器设计：控制信号首先通过耦合算子编码，然后由选定的预训练模型层的可训练副本处理，最后通过解耦算子和等变零初始化卷积投射回去。通过仅微调这些轻量级适配器模块，GeoAda保持了模型的几何一致性，同时减轻了过拟合和灾难性遗忘。我们理论证明了所提出的适配器保持SE(3)等变性，确保预训练扩散模型的几何归纳偏置在适应过程中保持完整。我们展示了GeoAda在不同几何控制类型（包括帧控制、全局控制、子图控制）和广泛应用领域（如粒子动力学、分子动力学、人体运动预测和分子生成）中的广泛适用性。实验结果表明，GeoAda实现了最先进的微调性能，同时保持了原始任务的准确性，而其他基线则由于过拟合和灾难性遗忘而导致性能显著下降。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [204] [Parametric Neural Amp Modeling with Active Learning](https://arxiv.org/abs/2507.02109)
> *基于主动学习的参数化神经放大器建模*

*Florian Grötschla, Luca A. Lanzendörfer, Longxiang Jiao, Roger Wattenhofer* | **Category: cs.LG, cs.SD, eess.AS** | **Updated: {updated}**

**Keywords:** 参数化神经放大器建模, 主动学习, WaveNet, 吉他放大器模型

**Comment:** Accepted at ISMIR 2025 as Late-Breaking Demo (LBD)

> **TL;DR:** 本文介绍了PANAMA，一个使用主动学习框架训练端到端参数化吉他放大器模型的系统，通过梯度优化确定最佳采样点，以在有限样本下有效创建虚拟放大器。

**AI_Comments:** 本文的创新点在于将主动学习引入到参数化神经放大器建模中，显著减少了训练所需的数据量。这对于实际应用中数据采集成本高昂的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在训练端到端参数化吉他放大器模型时，需要减少所需的数据点（即放大器旋钮设置）数量，以便在有限样本约束下实现高效的虚拟放大器创建。

**Method:** 本文提出了PANAMA，一个基于WaveNet类架构的主动学习框架，用于训练端到端参数化吉他放大器模型。该方法利用梯度优化算法来确定最佳的数据点进行采样，以最少的数据点创建虚拟放大器。

**Result:** 研究表明，所提出的方法在样本数量受限的情况下是有效的。

**Conclusion:** 该研究成功地展示了通过主动学习和梯度优化，可以在有限数据点下高效地训练出参数化吉他放大器模型。

> **ai_Abstract:** PANAMA是一个利用主动学习框架和WaveNet类架构训练端到端参数化吉他放大器模型的新系统。它通过梯度优化算法确定最佳采样点，从而在有限的数据点（放大器旋钮设置）下创建虚拟放大器，并被证明在样本受限时有效。

> **摘要翻译:** 我们引入了PANAMA，一个用于训练端到端参数化吉他放大器模型的主动学习框架，该框架使用类似WaveNet的架构。通过该模型，人们可以通过记录由主动学习策略确定的样本来创建虚拟放大器，以使用最少的数据点（即放大器旋钮设置）。我们展示了基于梯度的优化算法可以用于确定最佳的采样数据点，并且该方法在样本数量受限的情况下有所帮助。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [211] [Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model](https://arxiv.org/abs/2507.02089)
> *具有生成模型的线性约束马尔可夫决策过程的样本复杂度界限*

*Xingtu Liu, Lin F. Yang, Sharan Vaswani* | **Category: cs.LG, stat.ML** | **Updated: {updated}**

**Keywords:** 约束马尔可夫决策过程, 样本复杂度, 原始-对偶, 生成模型, 镜像下降值迭代

**Comment:** 

> **TL;DR:** 本文提出了一种用于求解线性约束马尔可夫决策过程 (CMDP) 的原始-对偶框架，并提供了在松弛可行性和严格可行性两种情况下的样本复杂度界限，结果显示出接近最优的性能。

**AI_Comments:** 这项工作通过引入一个通用的原始-对偶框架来解决线性CMDPs，并提供了严格的样本复杂度分析，具有重要的理论贡献。其创新之处在于能够整合任何黑盒无约束MDP求解器，提高了方法的普适性。特别是在松弛和严格可行性条件下的详细分析，以及对特征维度和精度的接近最优依赖性，都突出了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决无限视野、$\gamma$ 折扣的线性约束马尔可夫决策过程 (CMDPs) 中寻找最大化预期累积奖励并满足预期累积约束的策略问题。

**Method:** 作者提出了一种原始-对偶框架来解决CMDPs，该框架可以利用任何黑盒无约束MDP求解器。对于特征维度为 $d$ 的线性CMDPs，该框架通过使用镜像下降值迭代 (MDVI) 进行实例化。

**Result:** 在松弛可行性情况下，算法能以高概率返回一个 $\epsilon$-最优策略，所需样本复杂度为 $\tilde{O}\left(\frac{d^2}{(1-\gamma)^4\epsilon^2}\right)$，对 $d$ 和 $\epsilon$ 表现出接近最优的依赖性。在严格可行性情况下，算法需要 $\tilde{O}\left(\frac{d^2}{(1-\gamma)^6\epsilon^2\zeta^2}\right)$ 样本，其中 $\zeta$ 是依赖于问题的Slater常数。该框架在表格CMDPs中也能恢复接近最优的样本复杂度。

**Conclusion:** 本文提出的原始-对偶框架为线性CMDPs提供了一种有效的求解方法，并在不同可行性条件下给出了详细的样本复杂度分析，结果显示出良好的理论性能，包括在表格CMDPs中也能达到接近最优的样本复杂度。

> **ai_Abstract:** 本文研究了具有生成模型的线性约束马尔可夫决策过程（CMDPs），旨在最大化奖励并满足约束。作者提出了一个通用的原始-对偶框架，可集成现有无约束MDP求解器。通过使用镜像下降值迭代（MDVI）实例化，该研究推导了在松弛可行性和严格可行性条件下的样本复杂度界限。结果表明，在松弛可行性下，样本复杂度为 $\tilde{O}\left(\frac{d^2}{(1-\gamma)^4\epsilon^2}\right)$，在严格可行性下为 $\tilde{O}\left(\frac{d^2}{(1-\gamma)^6\epsilon^2\zeta^2}\right)$，这些界限在特征维度和精度上都接近最优。该框架也适用于表格CMDPs并能达到接近最优的性能。

> **摘要翻译:** 我们考虑无限视野 $\gamma$-折扣（线性）约束马尔可夫决策过程（CMDPs），其目标是找到一个策略，在满足预期累积约束的同时最大化预期累积奖励。在可以访问生成模型的情况下，我们提出使用一个原始-对偶框架来解决CMDPs，该框架可以利用任何黑盒无约束MDP求解器。对于特征维度为 $d$ 的线性CMDPs，我们通过使用镜像下降值迭代（MDVI）实例化了该框架，这是一个MDP求解器示例。我们为由此产生的CMDP算法提供了两种情况下的样本复杂度界限：(i) 松弛可行性，即允许小的约束违反；(ii) 严格可行性，即要求输出策略精确满足约束。对于 (i)，我们证明该算法通过使用 $\tilde{O}\left(\frac{d^2}{(1-\gamma)^4\epsilon^2}\right)$ 样本，能够以高概率返回一个 $\epsilon$-最优策略。我们注意到这些结果在 $d$ 和 $\epsilon$ 上都表现出接近最优的依赖性。对于 (ii)，我们表明该算法需要 $\tilde{O}\left(\frac{d^2}{(1-\gamma)^6\epsilon^2\zeta^2}\right)$ 样本，其中 $\zeta$ 是表征可行区域大小的、依赖于问题的Slater常数。最后，我们为表格CMDPs实例化了我们的框架，并表明它可以在这种设置下恢复接近最优的样本复杂度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [224] [Energy-Based Transformers are Scalable Learners and Thinkers](https://arxiv.org/abs/2507.02092)
> *基于能量的Transformer是可扩展的学习者和思考者*

*Alexi Gladstone, Ganesh Nanduru, Md Mofijul Islam, Peixuan Han, Hyeonjeong Ha, Aman Chadha, Yilun Du, Heng Ji, Jundong Li, Tariq Iqbal* | **Category: cs.LG, cs.AI, cs.CL, cs.CV** | **Updated: {updated}**

**Keywords:** 能量基模型, Transformer, 系统2思维, 无监督学习, 可扩展性

**Comment:** 

> **TL;DR:** 本文提出能量基Transformer (EBTs)，通过学习显式验证输入与候选预测的兼容性，将预测问题重构为能量最小化优化，从而实现模型在无监督学习下进行类系统2思维。EBTs在训练时比现有方法扩展更快，并在多模态任务上展现出更优的性能和更好的泛化能力。

**AI_Comments:** 本文提出了一种新颖的能量基Transformer (EBTs) 架构，其创新点在于将“系统2思维”集成到模型的学习过程中，且仅通过无监督学习实现。这突破了现有类系统2方法对模态、问题特异性及额外监督的依赖。EBTs通过能量最小化实现预测，并在多模态任务上展现出卓越的可扩展性和泛化能力，尤其是在训练效率和推理性能上均超越了现有SOTA模型。其在无监督学习下实现复杂推理的能力，对未来AI模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有推断时计算技术（类比人类系统2思维）在提高模型性能方面已日益普及，但它们通常受限于模态特异性、问题特异性或需要额外的监督/训练。本文旨在探讨是否能将这些系统2思维方法推广，并开发出仅通过无监督学习就能学会思考的模型。

**Method:** 本文提出能量基Transformer (EBTs)，这是一种新型的基于能量的模型（EBMs）。EBTs通过学习为每个输入和候选预测对分配一个能量值，并通过基于梯度下降的能量最小化直至收敛来进行预测。其核心在于显式验证输入与候选预测之间的兼容性，并将预测问题重构为对此验证器的优化。

**Result:** EBTs在训练期间比主流的Transformer++方法扩展更快，在数据、批量大小、参数、FLOPs和深度方面实现了高达35%的更高扩展率。在推断期间，EBTs在语言任务上通过系统2思维将性能提升比Transformer++多29%。EBTs在图像去噪方面优于Diffusion Transformers，同时使用更少的前向传播。此外，EBTs在相同或更差的预训练性能下，在大多数下游任务上取得了比现有模型更好的结果，表明EBTs比现有方法具有更好的泛化能力。

**Conclusion:** EBTs是扩展模型学习和思考能力的一个有前景的新范式。

> **ai_Abstract:** 本文针对现有系统2思维方法在模态、问题特异性及额外监督方面的局限性，提出了一个核心问题：能否在无监督学习下实现模型的泛化性“思考”。研究发现，通过引入能量基Transformer（EBTs），模型可以学习显式验证输入与候选预测的兼容性，并将预测问题转化为能量最小化。实验结果表明，EBTs在训练时比Transformer++具有更快的扩展速度（高达35%的扩展率提升），并在推理时通过系统2思维在语言任务上性能提升29%。此外，EBTs在图像去噪任务上表现优于Diffusion Transformers且前向传播更少，并在多项下游任务上展现出更好的泛化能力。这表明EBTs为提升模型的学习和思考能力提供了一个有前景的新范式。

> **摘要翻译:** 推断时计算技术，类似于人类的系统2思维，最近在提高模型性能方面变得流行。然而，大多数现有方法存在一些局限性：它们是模态特异性的（例如，仅适用于文本）、问题特异性的（例如，可验证的领域，如数学和编程），或者在无监督预训练之上需要额外的监督/训练（例如，验证器或可验证的奖励）。在本文中，我们提出问题“是否有可能推广这些系统2思维方法，并开发出仅从无监督学习中学习思考的模型？”有趣的是，我们发现答案是肯定的，通过学习显式验证输入和候选预测之间的兼容性，然后将预测问题重构为相对于该验证器的优化。具体来说，我们训练了能量基Transformer（EBTs）——一种新型的基于能量的模型（EBMs）——为每个输入和候选预测对分配一个能量值，从而通过基于梯度下降的能量最小化直至收敛来进行预测。在离散（文本）和连续（视觉）模态中，我们发现EBTs在训练期间比主流的Transformer++方法扩展更快，在数据、批量大小、参数、FLOPs和深度方面实现了高达35%的更高扩展率。在推断期间，EBTs通过系统2思维将性能提升比Transformer++在语言任务上多29%，并且EBTs在图像去噪方面优于Diffusion Transformers，同时使用更少的前向传播。此外，我们发现EBTs在相同或更差的预训练性能下，在大多数下游任务上取得了比现有模型更好的结果，这表明EBTs比现有方法具有更好的泛化能力。因此，EBTs是扩展模型学习和思考能力的一个有前景的新范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [225] [Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs](https://arxiv.org/abs/2507.02671)
> *基于嵌入的联邦数据共享：通过差分隐私条件变分自编码器实现*

*Francesco Di Salvo, Hanh Huyen My Nguyen, Christian Ledig* | **Category: cs.LG, cs.CV, eess.IV** | **Updated: {updated}**

**Keywords:** 联邦学习, 差分隐私, 变分自编码器, 医疗影像, 嵌入

**Comment:** Accepted to MICCAI 2025

> **TL;DR:** 本文提出一种通过差分隐私条件变分自编码器（DP-CVAE）进行基于嵌入的联邦数据共享方法，以解决医疗影像领域深度学习的数据稀缺和隐私问题，同时提高联邦学习的效率和灵活性。

**AI_Comments:** 该论文提出了一种新颖的联邦数据共享范式，通过结合基础模型和差分隐私CVAE，有效地解决了联邦学习中通信成本高、任务单一以及数据隐私保护的痛点。其创新性在于将数据共享从原始数据层面转移到嵌入层面，大大降低了传输和计算负担，并保证了严格的隐私保护。该方法在医疗影像领域具有重要应用潜力，为构建大规模、隐私安全的医疗AI模型提供了可行路径。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在医疗影像领域受限于数据稀缺和隐私法规，难以访问多样化数据集。联邦学习虽然实现了去中心化训练，但存在高通信成本且常限于单一下游任务，缺乏灵活性。

**Method:** 通过差分隐私（DP）生成模型实现数据共享。利用基础模型提取紧凑、信息丰富的嵌入，以减少冗余和计算开销。客户端协作训练一个差分隐私条件变分自编码器（DP-CVAE），以建模一个全局的、隐私保护的数据分布，支持多样化的下游任务。

**Result:** 该方法通过多个特征提取器验证，增强了隐私性、可扩展性和效率。它优于传统的联邦学习分类器，并确保了差分隐私。此外，DP-CVAE比DP-CGAN生成更高保真度的嵌入，且所需参数减少5倍。

**Conclusion:** 本文提出了一种通过差分隐私生成模型进行数据共享的方法，该方法利用基础模型提取嵌入，并协作训练DP-CVAE来建模隐私保护的数据分布，有效解决了医疗影像深度学习中数据稀缺和隐私合规的挑战，同时提升了联邦学习的性能和灵活性。

> **ai_Abstract:** 本文提出一种创新的联邦数据共享方法，旨在克服医疗影像深度学习中数据稀缺和隐私合规的挑战。该方法利用基础模型提取紧凑的嵌入，并通过客户端协作训练差分隐私条件变分自编码器（DP-CVAE）来学习全局隐私保护数据分布。实验结果表明，该方法在保持差分隐私的同时，显著提升了隐私、可扩展性和效率，并且在性能上优于传统联邦学习分类器，相较于DP-CGAN能以更少的参数生成更高质量的嵌入。

> **摘要翻译:** 深度学习（DL）彻底改变了医学影像领域，但其应用受到数据稀缺和隐私法规的限制，从而限制了对多样化数据集的访问。联邦学习（FL）实现了去中心化训练，但存在高通信成本，并且通常局限于单一的下游任务，降低了灵活性。我们提出了一种通过差分隐私（DP）生成模型进行数据共享的方法。通过采用基础模型，我们提取紧凑、信息丰富的嵌入，减少了冗余并降低了计算开销。客户端协作训练一个差分隐私条件变分自编码器（DP-CVAE），以建模一个全局的、隐私保护的数据分布，支持多样化的下游任务。我们的方法在多个特征提取器上进行了验证，增强了隐私性、可扩展性和效率，优于传统的FL分类器，同时确保了差分隐私。此外，DP-CVAE比DP-CGAN生成更高保真度的嵌入，同时所需参数减少5倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [228] [Online Conformal Prediction with Efficiency Guarantees](https://arxiv.org/abs/2507.02496)
> *在线共形预测与效率保证*

*Vaidehi Srinivas* | **Category: cs.LG, cs.DS, math.ST, stat.ML, stat.TH** | **Updated: {updated}**

**Keywords:** 在线共形预测, 效率保证, 覆盖率, 可交换序列, 任意序列

**Comment:** 

> **TL;DR:** 本文研究了在线共形预测问题，旨在优化效率同时保证覆盖率，并分析了可交换和任意序列下的性能差异及相应算法。

**AI_Comments:** 这篇论文通过引入效率优化目标，为在线共形预测提供了一个新颖的视角。它深刻揭示了在不同输入序列（可交换与任意）下，在线预测问题的内在复杂性和性能限制，特别是证明了单一算法无法同时在两种序列下达到最优的结论，这对于理解在线学习的边界具有重要意义。提出的确定性算法及其对帕累托最优解的恢复能力是其主要创新点。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决在线共形预测问题中，在保证目标覆盖率的同时，最大化效率（最小化预测区间的平均体积）。这类似于构建高效置信区间问题。

**Method:** 论文研究了可交换（随机顺序）和任意输入序列下的在线共形预测问题。提出了一种确定性算法，能够恢复任意序列下所有帕累托最优的错误率和平均长度设置。此外，还提出了一个算法来实现在可交换和任意序列之间的近乎最优的权衡。

**Result:** 对于可交换序列，可以构造出覆盖率达到 $(1 - \alpha) - o(1)$ 的区间，其长度上限由事后最佳固定区间决定。对于任意序列，任何算法若要达到平均长度与事后最佳固定区间相比的 $\mu$ 近似，则其错误次数必须比 $\alpha T$ 多一个乘法因子，该乘法因子取决于 $\mu$ 和问题的长宽比。提出了一个匹配算法，可以恢复任意序列下所有帕累托最优的 $\mu$ 和错误次数设置。发现可交换序列和任意序列之间存在性能差距，与经典在线学习问题不同。证明了没有单一算法可以同时对任意序列达到帕累托最优并对可交换序列达到最优。提出了一个在两种情况之间实现近乎最优权衡的算法。

**Conclusion:** 本文揭示了在线共形预测在可交换序列和任意序列之间存在根本性的性能差距，并提出了能够在这两种情况下实现近乎最优权衡的算法，同时提供了针对任意序列的帕累托最优算法。

> **ai_Abstract:** 本文探讨了在线共形预测问题，目标是在保证指定覆盖率的同时，最小化预测区间的平均长度。研究对比了可交换序列和任意序列下的性能，发现两者之间存在显著差距，并证明了没有单一算法能同时在这两种情况下达到最优。针对任意序列，提出了一个能恢复所有帕累托最优设置的确定性算法；同时，也提出了一个能在两种序列类型之间实现近乎最优权衡的算法。

> **摘要翻译:** 我们研究了一种新颖的在线框架下的共形预测问题，该框架直接优化效率。在我们的问题中，给定一个目标未覆盖率 $\alpha > 0$ 和一个时间范围 $T$。在每天 $t \le T$，算法必须输出一个区间 $I_t \subseteq [0, 1]$，然后揭示一个点 $y_t \in [0, 1]$。算法的目标是实现覆盖率，即在（接近）$(1 - \alpha)$ 比例的天数中 $y_t \in I_t$，同时保持效率，即最小化所玩区间的平均体积（长度）。这个问题是构建高效置信区间问题的一个在线模拟。
我们研究了任意和可交换（随机顺序）输入序列下的这个问题。对于可交换序列，我们表明可以构造出覆盖率达到 $(1 - \alpha) - o(1)$ 的区间，其长度上限由事后实现覆盖的最佳固定区间决定。然而，对于任意序列，我们表明任何算法，如果其平均长度与事后实现覆盖的最佳固定区间相比达到 $\mu$ 近似，则其错误次数必须比 $\alpha T$ 多一个乘法因子，该乘法因子取决于 $\mu$ 和问题的长宽比。我们的主要算法结果是一个匹配算法，能够恢复所有帕累托最优的 $\mu$ 和错误次数设置。此外，我们的算法是确定性的，因此对自适应对手具有鲁棒性。
可交换和任意设置之间的这种差距与经典的在线学习问题形成对比。事实上，我们表明没有单一算法可以同时对任意序列达到帕累托最优并对可交换序列达到最优。在算法方面，我们给出了一个算法，可以在两种情况之间实现近乎最优的权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [239] [Padé Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data](https://arxiv.org/abs/2507.02599)
> *用于增强使用振动和声学数据进行电机故障诊断的Padé逼近神经网络*

*Sertac Kilickaya, Levent Eren* | **Category: cs.LG, cs.SD, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** Padé逼近神经网络, 故障诊断, 感应电机, 振动数据, 声学数据

**Comment:** Submitted to the Journal of Vibration Engineering & Technologies

> **TL;DR:** 本研究引入了Padé逼近神经网络（PadéNets），并证明其在利用振动和声学数据诊断感应电机故障方面优于传统的CNN和Self-ONN模型。

**AI_Comments:** 本论文的创新之处在于引入了Padé逼近神经网络（PadéNets）来处理电机故障诊断中的非线性问题。其重要性在于证明了PadéNets在诊断准确性上超越了现有流行的深度学习模型，为电机状态监测提供了一种更优的解决方案。此外，其对无界激活函数的兼容性也为模型设计提供了更大的灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过利用Padé逼近神经元（PAON）模型来增强感应电机的故障诊断能力。研究旨在解决Padé逼近神经网络（PadéNets）是否能在使用振动和声学数据诊断电气和机械故障方面优于传统的卷积神经网络（CNNs）和自组织运算神经网络（Self-ONNs）的问题。

**Method:** 本研究评估并比较了三种深度学习架构的诊断能力：一维CNNs、Self-ONNs和PadéNets。这些模型在渥太华大学公开的恒速感应电机数据集上进行测试，该数据集包含振动和声学传感器数据。PadéNet模型旨在引入增强的非线性，并兼容无界激活函数（如Leaky ReLU）。

**Result:** PadéNets始终优于基线模型，对于加速度计1、2、3和声学传感器，诊断准确率分别达到99.96%、98.26%、97.61%和98.33%。

**Conclusion:** PadéNets增强的非线性及其与无界激活函数的兼容性显著提高了感应电机状态监测中的故障诊断性能。

> **ai_Abstract:** 本研究旨在通过引入Padé逼近神经网络（PadéNets）来增强感应电机的故障诊断。通过比较一维CNNs、Self-ONNs和PadéNets在振动和声学数据上的性能，研究发现PadéNets在诊断准确性方面显著优于传统模型，验证了其增强非线性和与无界激活函数兼容性在提高故障诊断性能方面的有效性。

> **摘要翻译:** 目的：本研究的主要目的是通过利用Padé逼近神经元（PAON）模型来增强感应电机的故障诊断能力。虽然加速度计和麦克风是电机状态监测的标准配置，但具有非线性神经元架构的深度学习模型在诊断性能方面显示出有希望的改进。本研究解决了以下问题：Padé逼近神经网络（PadéNets）在使用振动和声学数据诊断电气和机械故障方面能否优于传统的卷积神经网络（CNNs）和自组织运算神经网络（Self-ONNs）？
方法：我们评估并比较了三种深度学习架构的诊断能力：一维CNNs、Self-ONNs和PadéNets。这些模型在渥太华大学公开的恒速感应电机数据集上进行测试，该数据集包含振动和声学传感器数据。PadéNet模型旨在引入增强的非线性，并兼容无界激活函数（如Leaky ReLU）。
结果和结论：PadéNets始终优于基线模型，对于加速度计1、2、3和声学传感器，诊断准确率分别达到99.96%、98.26%、97.61%和98.33%。PadéNets增强的非线性及其与无界激活函数的兼容性显著提高了感应电机状态监测中的故障诊断性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [247] [Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks](https://arxiv.org/abs/2507.02119)
> *缩放崩塌揭示了计算最优训练神经网络中的普适动力学*

*Shikai Qiu, Lechao Xiao, Andrew Gordon Wilson, Jeffrey Pennington, Atish Agarwala* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 缩放崩塌, 神经网络, 普适动力学, 计算最优训练, 超崩塌

**Comment:** ICML 25. Code available at https://github.com/shikaiqiu/supercollapse

> **TL;DR:** 研究发现，计算最优训练的神经网络在归一化后，其损失曲线会收敛到一个普适曲线，称为“超崩塌”，这提供了一个衡量良好缩放的精确指标，并通过分析SGD噪声动力学模型得到解释。

**AI_Comments:** 这项研究的创新之处在于发现了计算最优训练神经网络中普遍存在的“缩放崩塌”和“超崩塌”现象，揭示了神经网络训练深层的普适动力学。其重要性在于，超崩塌现象提供了一个精确且实用的指标，用于判断超参数是否实现了良好的缩放，这对于大规模神经网络的有效训练和优化具有重要指导意义。此外，研究通过连接幂律缩放和构建一个有效简单的SGD噪声动力学模型来解释这些现象，展现了理论分析与实证观察的结合。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在探究当模型大小和训练时间同步增长时，何种缩放限制制约着神经网络的训练动力学。

**Method:** 研究表明，尽管架构、训练算法和数据之间存在复杂交互，但计算最优训练的模型表现出精确的普适性。具体而言，通过在训练结束时将训练计算量和损失归一化，不同大小模型的损失曲线会收敛到一条单一的普适曲线。在学习率衰减的情况下，这种收敛变得非常紧密，使得归一化曲线之间的差异低于随机种子下单个损失曲线的噪声水平，这种现象被称为“超崩塌”。研究在各种学习率调度、数据集和架构（包括在下一词预测上训练的Transformer）中观察到超崩塌，并发现当超参数缩放不理想时，该现象会失效，从而提供了一个精确且实用的良好缩放指标。研究通过将崩塌现象与典型神经缩放定律中的幂律结构联系起来，并分析一个简单但出奇有效的SGD噪声动力学模型来解释这些现象，该模型能准确预测各种学习率调度下的损失曲线，并定量解释了超崩塌的起源。

**Result:** 结果显示，尽管存在复杂的交互，计算最优训练的神经网络模型展示出显著的普适性：当训练计算量和损失在训练结束时归一化后，不同大小模型的损失曲线会收敛到一条单一的普适曲线。在学习率衰减下，这种收敛变得极其紧密，形成“超崩塌”现象，即归一化曲线间的差异低于单个损失曲线的噪声水平。这种超崩塌现象在各种学习率调度、数据集和架构中（包括Transformer）均被观察到，并且当超参数缩放不理想时会失效，从而提供了一个精确实用的良好缩放指标。研究通过连接崩塌现象与神经缩放定律中的幂律结构，并分析一个简单的SGD噪声动力学模型，成功预测了各种学习率调度下的损失曲线，并定量解释了超崩塌的起源。

**Conclusion:** 本研究得出结论，计算最优训练的神经网络展现出普适的训练动力学，即在适当归一化后，损失曲线会收敛到一条单一的普适曲线，在学习率衰减下形成“超崩塌”现象。这种现象不仅揭示了神经网络训练的内在规律，而且可以作为一个精确实用的指标来评估超参数的良好缩放，其机制可以通过连接幂律缩放和SGD噪声动力学模型得到解释。

> **ai_Abstract:** 本研究揭示了计算最优训练的神经网络在模型大小和训练时间同步增长时所展现的普适训练动力学。通过对训练计算量和损失进行归一化，不同规模模型的损失曲线会收敛至一条单一的普适曲线，这一现象在学习率衰减下表现为更紧密的“超崩塌”，其差异甚至低于随机种子间的噪声。这种超崩塌现象在多种设置下普遍存在，并可作为评估超参数良好缩放的实用指标。研究通过将其与神经缩放定律的幂律结构关联，并分析一个SGD噪声动力学模型，成功解释了这些现象，并量化了超崩塌的起源。

> **摘要翻译:** 当模型大小和训练时间同步增长时，何种缩放限制制约着神经网络的训练动力学？我们发现，尽管架构、训练算法和数据之间存在复杂的交互，但计算最优训练的模型表现出惊人的精确普适性。具体而言，当训练计算量和损失在训练结束时归一化为单位时，不同大小模型的损失曲线会收敛到一条单一的普适曲线。在学习率衰减的情况下，这种收敛变得非常紧密，使得归一化曲线之间的差异低于随机种子下单个损失曲线的噪声水平，这种现象我们称之为“超崩塌”。我们在各种学习率调度、数据集和架构（包括在下一词预测上训练的Transformer）中观察到超崩塌，并发现当超参数缩放不理想时，该现象会失效，从而提供了一个精确且实用的良好缩放指标。我们通过将崩塌现象与典型神经缩放定律中的幂律结构联系起来，并分析一个简单但出奇有效的SGD噪声动力学模型来解释这些现象，该模型能准确预测各种学习率调度下的损失曲线，并定量解释了超崩塌的起源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [256] [CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs](https://arxiv.org/abs/2507.02128)
> *CROP：使用大型语言模型进行参数指导的电路检索与优化*

*Jingyu Pan, Isaac Jacobson, Zheng Zhao, Tung-Chieh Chen, Guanglei Zhou, Chen-Chia Chang, Vineet Rashingkar, Yiran Chen* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** VLSI设计, LLM, 自动优化, 参数指导, 电路检索

**Comment:** Accepted by ICCAD 2025

> **TL;DR:** CROP是一个利用大型语言模型（LLM）自动优化VLSI设计的框架，通过检索相似电路和参数指导，显著提高了设计质量并减少了迭代次数。

**AI_Comments:** CROP的创新之处在于首次将大型语言模型应用于VLSI设计流程的自动调优，解决了传统方法在处理巨大参数空间时的效率和质量瓶颈。其结合嵌入式检索和RAG机制，利用先验知识指导LLM进行参数搜索，是其成功的关键。该方法有望显著提升芯片设计的自动化水平和优化效率。

<details>
  <summary>Details</summary>

**Motivation:** 现代超大规模集成电路（VLSI）设计中，电子设计自动化（EDA）工具的复杂算法导致参数空间巨大，芯片设计优化面临巨大挑战。手动参数选择劳动量大且受限于专家经验，无法有效应对这一问题。

**Method:** 本文提出了CROP框架，是首个由大型语言模型（LLM）驱动的自动VLSI设计流程调优框架。其方法包括：(1) 将RTL源代码转换为密集向量表示的可扩展方法；(2) 基于嵌入的检索系统，用于匹配语义相似的电路设计；(3) 检索增强生成（RAG）增强的LLM引导参数搜索系统，利用相似设计的先验知识来约束搜索过程。

**Result:** 实验结果表明，CROP在工业设计上比现有方法以更少的迭代次数实现了卓越的质量结果（QoR），包括功耗降低了9.9%。

**Conclusion:** CROP框架通过结合大型语言模型（LLM）、嵌入式检索和检索增强生成（RAG）技术，成功解决了VLSI设计优化中参数空间巨大的挑战，显著提升了设计质量和效率。

> **ai_Abstract:** CROP是一个创新的框架，它利用大型语言模型（LLM）来自动化超大规模集成电路（VLSI）的设计优化过程。针对传统手动参数选择效率低下和参数空间巨大的问题，CROP通过将RTL代码转换为向量表示，并结合基于嵌入的检索系统和RAG增强的LLM引导参数搜索，实现了对相似电路的智能匹配和参数空间的有效探索。实验证明，CROP在工业设计中能以更少的迭代次数获得更优的设计质量，例如功耗降低9.9%。

> **摘要翻译:** 现代超大规模集成电路（VLSI）设计需要使用电子设计自动化（EDA）工具来实现集成电路。由于EDA算法的复杂性，巨大的参数空间给芯片设计优化带来了巨大挑战，因为即使是中等数量的参数组合也会产生巨大的解决方案空间需要探索。尽管手动参数选择过于费力且受专家经验限制，但它仍然是工业实践。为了解决这个问题，我们提出了CROP，这是第一个由大型语言模型（LLM）驱动的自动VLSI设计流程调优框架。我们的方法包括：(1) 将RTL源代码转换为密集向量表示的可扩展方法，(2) 基于嵌入的检索系统，用于匹配与语义相似的电路设计，以及(3) 一个检索增强生成（RAG）增强的LLM引导参数搜索系统，该系统利用来自相似设计的先验知识来约束搜索过程。实验结果表明，CROP在工业设计上比现有方法以更少的迭代次数实现了卓越的质量结果（QoR），包括功耗降低了9.9%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [266] [Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction](https://arxiv.org/abs/2507.02129)
> *生成式潜在扩散用于高效时空数据降维*

*Xiao Li, Liangji Zhu, Anand Rangarajan, Sanjay Ranka* | **Category: cs.LG, cs.CV** | **Updated: {updated}**

**Keywords:** 生成式模型, 潜在扩散, 时空数据降维, 数据压缩, 变分自编码器

**Comment:** 10 pages

> **TL;DR:** 提出一种高效的生成式潜在扩散框架，通过压缩关键帧并插值重建，实现高压缩比和准确的时空数据降维。

**AI_Comments:** 这篇论文创新性地结合了变分自编码器和条件扩散模型，并引入了关键帧压缩和生成式插值策略，有效解决了生成模型在数据压缩应用中的关键挑战。其核心创新在于避免了对每一帧进行潜在表示存储，显著提升了压缩效率。该方法在时空数据降维方面展现出卓越的性能，有望在需要高效数据存储和传输的应用中发挥重要作用，例如视频压缩或大型科学模拟数据处理。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成模型在数据压缩中的应用受限于其有限的可控性和重建精度，这限制了它们的实际应用。

**Method:** 本文提出一种高效的潜在扩散框架，结合变分自编码器与条件扩散模型。该方法仅将少量关键帧压缩到潜在空间，并将其作为条件输入，通过生成式插值重建剩余帧，从而无需存储每一帧的潜在表示。

**Result:** 实验结果表明，该方法比基于规则的先进压缩器（如SZ3）实现了高达10倍的压缩比，并且在相同重建误差下，比领先的基于学习的方法性能提高多达63%。

**Conclusion:** 该方法通过高效的潜在扩散框架，显著降低存储成本，同时实现准确的时空重建，解决了现有生成模型在数据压缩应用中的局限性。

> **ai_Abstract:** 本文提出一种名为“生成式潜在扩散”的高效框架，旨在解决现有生成模型在数据压缩中可控性和重建精度不足的问题。该方法结合变分自编码器和条件扩散模型，通过仅压缩少量关键帧并利用生成式插值重建其余帧，显著减少了存储需求。实验证明，该方法在保持准确时空重建的同时，实现了比现有规则基和学习基方法更高的压缩比和性能。

> **摘要翻译:** 生成模型在条件设置中表现出强大的性能，可以被视为一种数据压缩形式，其中条件作为紧凑表示。然而，它们有限的可控性和重建精度限制了它们在数据压缩中的实际应用。在这项工作中，我们提出了一种高效的潜在扩散框架，通过将变分自编码器与条件扩散模型相结合来弥补这一差距。我们的方法仅将少量关键帧压缩到潜在空间，并将其用作条件输入，通过生成式插值重建剩余帧，从而无需为每一帧存储潜在表示。这种方法能够实现准确的时空重建，同时显著降低存储成本。在多个数据集上的实验结果表明，我们的方法比基于规则的先进压缩器（如SZ3）实现了高达10倍的压缩比，并且在相同重建误差下，比领先的基于学习的方法性能提高多达63%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [273] [Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks](https://arxiv.org/abs/2507.02151)
> *面向时间图神经网络的不可交换共形预测*

*Tuo Wang, Jian Kang, Yujun Yan, Adithya Kulkarni, Dawei Zhou* | **Category: cs.LG, H.1.0; I.2.0** | **Updated: {updated}**

**Keywords:** 共形预测, 时间图, 图神经网络, 不确定性量化, 不可交换性

**Comment:** accepted by KDD 2025

> **TL;DR:** 现有用于图神经网络的共形预测方法主要针对静态图，忽略了现实世界图的演变特性，且时间依赖性违反了标准共形预测的交换性假设。本文提出了NCPNET，一个为时间图量身定制的端到端共形预测框架，通过扩散式非一致性分数和效率感知优化算法，解决了时间依赖性导致的覆盖率违反问题，并在多个真实世界时间图数据集上实现了保证的覆盖率和更高的效率。

**AI_Comments:** 本文的创新点在于将共形预测扩展到动态时间图，这对于数据不断演进的现实世界应用至关重要。所提出的基于扩散的非一致性分数是处理时间和拓扑不确定性的关键技术贡献。效率感知优化算法也增加了实用价值。这项工作提高了图神经网络在动态设置中的可靠性和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于图神经网络的共形预测方法主要关注静态图，但真实世界图具有演变性。图结构、节点属性和真实标签中的时间依赖性违反了标准共形预测方法的基本交换性假设，从而限制了其适用性。

**Method:** 本文引入了NCPNET，一个为时间图量身定制的新型端到端共形预测框架。该方法将共形预测扩展到动态设置，通过提出一种扩散式非一致性分数来捕获演化网络中的拓扑和时间不确定性。此外，还开发了一种效率感知优化算法，以提高共形预测过程的计算效率并减少覆盖率违反。

**Result:** 在WIKI、REDDIT、DBLP和IBM反洗钱数据集等多种真实世界时间图上的大量实验表明，NCPNET能够在时间图中确保覆盖率，并且在WIKI数据集上将预测集大小减少了高达31%，与现有最新方法相比显著提高了效率。

**Conclusion:** NCPNET通过解决时间依赖性导致的覆盖率违反问题并提高效率，有效应对了将共形预测应用于时间图的挑战，展现出优于现有方法的性能。

> **ai_Abstract:** 本文提出了NCPNET，一个专门为时间图神经网络设计的端到端共形预测框架。它解决了现有方法主要关注静态图、未能处理时间依赖性导致的非交换性问题。NCPNET引入了一种基于扩散的非一致性分数来捕获拓扑和时间不确定性，并开发了一种效率感知优化算法。在多个真实世界时间图数据集上的广泛实验证明，NCPNET能够确保覆盖率，并在WIKI数据集上将预测集大小减少高达31%，显著提升了效率。

> **摘要翻译:** 图神经网络（GNNs）的共形预测提供了一个有前景的框架来量化不确定性，从而增强GNNs在高风险应用中的可靠性。然而，现有方法主要关注静态图，忽略了真实世界图的演变特性。图结构、节点属性和真实标签中的时间依赖性违反了标准共形预测方法的基本交换性假设，限制了其适用性。为了解决这些挑战，本文引入了NCPNET，一个为时间图量身定制的新型端到端共形预测框架。我们的方法将共形预测扩展到动态设置，减轻了时间依赖性导致的统计覆盖率违反。为了实现这一点，我们提出了一种基于扩散的非一致性分数，用于捕获演化网络中的拓扑和时间不确定性。此外，我们开发了一种效率感知优化算法，以改进共形预测过程，提高计算效率并减少覆盖率违反。在WIKI、REDDIT、DBLP和IBM反洗钱数据集等多种真实世界时间图上的大量实验表明，NCPNET能够在时间图中确保覆盖率，并在WIKI数据集上将预测集大小减少了高达31%，与现有最新方法相比显著提高了效率。我们的数据和代码可在https://github.com/ODYSSEYWT/NCPNET获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [281] [Statistical Inference for Responsiveness Verification](https://arxiv.org/abs/2507.02169)
> *响应性验证的统计推断*

*Seung Hyun Cheon, Meredith Stewart, Bogdan Kulynych, Tsui-Wei Weng, Berk Ustun* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 响应性验证, 敏感性分析, 机器学习安全, 黑盒访问, 统计推断

**Comment:** 

> **TL;DR:** 本文提出了一种形式化的验证程序，用于评估机器学习模型预测对输入干预的响应性，以提高模型在实际应用中的安全性，特别是在处理个人输入变化时。

**AI_Comments:** 本文提出了一种新颖的方法来解决机器学习模型在面对用户输入变化时的安全性和公平性问题。其创新之处在于将响应性验证形式化为一种敏感性分析，并提供了无需模型内部知识（黑盒访问）即可应用的通用估计方法。这对于提高AI系统的鲁棒性和可信赖性至关重要，特别是在高风险决策场景中。该方法的实用性体现在其能够支持故障检测和风险评估，并已在多个实际案例中得到验证。

<details>
  <summary>Details</summary>

**Motivation:** 许多机器学习模型在应用于个人预测（如贷款、招聘、内容审核）时，没有考虑到个体如何改变其输入，从而导致安全故障。因此，需要一种方法来验证预测对特征干预的响应性。

**Method:** 本文引入了一种形式化的验证程序，将响应性视为一种敏感性分析。该程序允许实践者通过指定干预约束和下游效应分布来控制一系列变化。它描述了如何仅通过黑盒访问来估计任何模型和数据集的预测响应性，并开发了通过生成可达点的均匀样本来构建这些估计的算法。

**Result:** 该方法估计的响应性可用于支持诸如证伪和故障概率估计等任务。它在累犯预测、器官移植优先级和内容审核等实际应用中展示了提高安全性的潜力。

**Conclusion:** 通过引入一种形式化的响应性验证程序和相应的估计算法，本研究旨在解决机器学习模型在个人输入变化时可能出现的安全问题，并有效促进模型在现实世界应用中的安全性。

> **ai_Abstract:** 本文提出了一种针对机器学习模型预测响应性的形式化验证程序。该程序将响应性视为敏感性分析，允许通过黑盒访问估计任何模型和数据集的预测响应性。研究开发了生成均匀样本的算法来构建这些估计，并展示了其在证伪、故障概率估计以及累犯预测、器官移植优先级和内容审核等实际应用中提高模型安全性的能力。

> **摘要翻译:** 机器学习中的许多安全故障发生在模型用于对个人进行预测时（通常在贷款、招聘或内容审核等场景），而没有考虑个体如何改变其输入。在这项工作中，我们引入了一种形式化的验证程序，用于验证预测对其特征干预的响应性。我们的程序将响应性框定为一种敏感性分析，其中实践者通过指定干预约束和下游效应分布来控制一系列变化。我们描述了如何仅通过黑盒访问来估计任何模型和任何数据集的预测响应性，以及如何使用这些估计来支持证伪和故障概率估计等任务。我们开发了通过生成可达点的均匀样本来构建这些估计的算法，并展示了它们如何促进累犯预测、器官移植优先级和内容审核等实际应用中的安全性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [289] [Metric Design != Metric Behavior: Improving Metric Selection for the Unbiased Evaluation of Dimensionality Reduction](https://arxiv.org/abs/2507.02225)
> *度量设计 != 度量行为：改进度量选择以实现降维的无偏评估*

*Jiyeon Bae, Hyeon Jeon, Jinwook Seo* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 降维, 度量选择, 评估偏差, 经验相关性, 可视化分析

**Comment:** IEEE VIS 2025 (short paper)

> **TL;DR:** 该论文提出了一种新的工作流程，通过基于经验相关性而非设计意图来聚类度量，从而为降维选择无偏的评估度量。

**AI_Comments:** 该论文的创新之处在于将度量选择从基于设计转变为基于行为（经验相关性）。这对于公平比较不同的降维技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 评估降维（DR）投影在保留高维数据结构方面的准确性至关重要，但如果无意中选择了高度相关的度量，评估可能会变得有偏，从而偏向于强调这些特征的降维技术。

**Method:** 提出了一种新颖的工作流程，通过根据指标的经验相关性而非仅仅其预期的设计特征来聚类指标，从而减少评估指标选择中的偏差。该工作流程通过使用成对相关性计算指标相似性，聚类指标以最小化重叠，并从每个聚类中选择一个代表性指标。

**Result:** 定量实验表明，所提出的方法提高了降维评估的稳定性。

**Conclusion:** 所提出的工作流程有助于减轻降维评估中的偏差。

> **ai_Abstract:** 该论文旨在解决降维（DR）技术评估中因选择高度相关度量而产生的偏差问题。它提出了一种新颖的工作流程，该流程基于度量的经验相关性而非其设计意图进行聚类，以最小化重叠并选择代表性度量。这种方法能够提高降维评估的稳定性并有效减少评估偏差。

> **摘要翻译:** 评估降维（DR）投影在保留高维数据结构方面的准确性对于可靠的可视化分析至关重要。因此，已经开发出针对不同结构特征的各种评估指标。然而，如果无意中选择了高度相关的指标——那些测量相似结构特征的指标，降维投影的评估可能会变得有偏，从而偏向于强调这些特征的降维技术。为了解决这个问题，我们提出了一种新颖的工作流程，通过根据指标的经验相关性而非仅仅其预期的设计特征来聚类指标，从而减少评估指标选择中的偏差。我们的工作流程通过使用成对相关性计算指标相似性，聚类指标以最小化重叠，并从每个聚类中选择一个代表性指标来工作。定量实验表明，我们的方法提高了降维评估的稳定性，这表明我们的工作流程有助于减轻评估偏差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [295] [PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations](https://arxiv.org/abs/2507.02227)
> *PhysicsCorrect：一种用于稳定神经偏微分方程模拟的免训练方法*

*Xinquan Huang, Paris Perdikaris* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 神经偏微分方程, 误差校正, 物理约束, 免训练, 模拟稳定性

**Comment:** 

> **TL;DR:** 神经偏微分方程（PDE）模型存在长期推演中误差累积导致发散的问题；PhysicsCorrect是一种免训练的校正框架，通过强制执行PDE一致性来纠正误差，显著提高模拟的稳定性和准确性，且计算开销可忽略不计。

**AI_Comments:** 本文通过提供一种免训练的方法来稳定神经偏微分方程模拟，展现了重要的创新性，解决了该领域的一个主要挑战。其核心优势在于高效的线性化和缓存策略，能够在极小的计算开销下大幅减少误差。这种方法有效提升了神经网络在科学计算中的可靠性和实际适用性，弥合了效率与物理保真度之间的鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络作为偏微分方程的替代模型，尽管计算速度快，但在长期推演中存在误差累积的严重限制，导致模拟结果与物理有效解完全偏离。

**Method:** PhysicsCorrect是一种免训练的校正框架，通过将校正公式化为基于PDE残差的线性化逆问题，在每个预测步骤强制执行PDE一致性。其关键创新在于采用高效的缓存策略，在离线预热阶段预计算雅可比矩阵及其伪逆，从而大幅降低计算开销。

**Result:** 与标准校正方法相比，计算开销降低了两个数量级；预测误差降低了高达100倍；推理时间增加可忽略不计（低于5%）；可与多种架构（如傅里叶神经算子、U-Net和Vision Transformer）无缝集成；成功将不稳定的神经替代模型转化为可靠的模拟工具，并在纳维-斯托克斯流体动力学、波动方程和混沌仓本-西瓦辛斯基方程等系统上进行了验证。

**Conclusion:** PhysicsCorrect通过将不稳定的神经替代模型转化为可靠的模拟工具，有效弥合了深度学习的计算效率与实际科学应用所需的物理保真度之间的鸿沟。

> **ai_Abstract:** 本文提出了PhysicsCorrect，一个新颖的免训练框架，旨在解决基于神经网络的偏微分方程模拟中误差累积和发散的关键问题。通过在每个步骤中通过线性化逆问题强制执行PDE一致性，并利用高效的雅可比矩阵缓存策略，PhysicsCorrect显著降低了预测误差（高达100倍）和计算开销，同时保持了较低的推理时间。它与各种神经架构无缝集成，将不稳定的神经替代模型转化为可靠且物理精确的模拟工具，适用于纳维-斯托克斯和波动方程等复杂系统。

> **摘要翻译:** 神经网络已成为求解偏微分方程（PDEs）的强大替代模型，与传统方法相比，它们提供了显著的计算加速。然而，这些模型存在一个关键局限性：在长期推演过程中误差累积，微小的不准确性会呈指数级复合，最终导致与物理有效解完全偏离。我们提出了PhysicsCorrect，一个免训练的校正框架，它通过将校正公式化为基于PDE残差的线性化逆问题，在每个预测步骤强制执行PDE一致性。我们的关键创新是一种高效的缓存策略，它在离线预热阶段预计算雅可比矩阵及其伪逆，与标准校正方法相比，计算开销减少了两个数量级。在三种代表性PDE系统——纳维-斯托克斯流体动力学、波动方程和混沌仓本-西瓦辛斯基方程——中，PhysicsCorrect将预测误差降低了高达100倍，同时增加了可忽略的推理时间（低于5%）。该框架与傅里叶神经算子、U-Net和Vision Transformer等多种架构无缝集成，有效地将不稳定的神经替代模型转化为可靠的模拟工具，弥合了深度学习的计算效率与实际科学应用所需的物理保真度之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [301] [VERBA: Verbalizing Model Differences Using Large Language Models](https://arxiv.org/abs/2507.02241)
> *VERBA：使用大型语言模型实现模型差异的语言化*

*Shravan Doda, Shashidhar Reddy Javaji, Zining Zhu* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 模型差异, 大型语言模型, 模型可解释性, 决策树, 模型比较

**Comment:** 

> **TL;DR:** VERBA利用大型语言模型自动描述机器学习模型之间的差异，解决了“模型湖”现象中手动比较的难题，并在实验中展现了高准确率，为模型透明度和可比性开辟了新途径。

**AI_Comments:** VERBA的创新之处在于利用大型语言模型自动化了模型差异的语言化描述，有效解决了传统手动比较O(N^2)的复杂性问题，这对于“模型湖”现象下的模型选择和理解具有重要意义。它将LLM的能力扩展到模型分析和可解释性领域，为事后分析提供了高效且可扩展的工具。

<details>
  <summary>Details</summary>

**Motivation:** 在当前机器学习领域，存在大量性能相似但行为不同的模型（“模型湖”现象），导致模型用户难以选择和理解。手动进行O(N^2)的模型对比较和文档准备对于开发者而言成本过高且不可行，因此亟需一种自动化方法来促进模型之间细粒度的对比较。

**Method:** 本研究引入了VERBA方法，该方法利用大型语言模型（LLM）通过从两个模型中采样来生成模型差异的语言化描述。研究团队建立了一个通过模拟评估语言化信息量的协议，并组建了一个包含多种常用机器学习模型的基准套件以进行评估。

**Result:** 对于一对性能差异高达5%但行为差异在20-25%的决策树模型，VERBA能有效地语言化其变异，整体准确率高达80%。当纳入模型的结构信息时，语言化准确率进一步提高到90%。

**Conclusion:** VERBA为改进机器学习模型的透明度和事后可比性开辟了新的研究途径。

> **ai_Abstract:** VERBA是一种利用大型语言模型自动描述机器学习模型之间差异的方法。针对当前“模型湖”现象中大量性能相似但行为不同的模型难以手动比较的问题，VERBA通过从两个模型中采样并结合LLM生成模型差异的语言化描述，并通过模拟进行评估。实验结果表明，对于决策树模型，VERBA能以高达80%的准确率有效描述行为差异，在加入模型结构信息后准确率可进一步提升至90%。该方法为提升机器学习模型的透明度和事后可比性提供了新的研究途径。

> **摘要翻译:** 在当前的机器学习领域，我们面临着“模型湖”现象：给定一项任务，尽管行为不同，但训练好的模型却大量涌现，且性能相似。对于试图在模型中导航和选择的模型用户来说，比较模型对的文档很有帮助。然而，对于每N个模型，可能存在O(N^2)对比较，这个数量对于模型开发者手动执行对比较和准备文档来说是难以承受的。为了促进模型之间细粒度的对比较，我们引入了VERBA。我们的方法利用大型语言模型（LLM），通过从两个模型中采样来生成模型差异的语言化描述。我们建立了一个协议，通过模拟来评估语言化描述的信息量。我们还组建了一个包含各种常用机器学习模型的套件作为基准。对于一对决策树模型，即使性能差异仅为5%但行为差异达到20-25%，VERBA也能有效地语言化其差异，整体准确率高达80%。当我们包含模型的结构信息时，语言化描述的准确率进一步提高到90%。VERBA为改进机器学习模型的透明度和事后可比性开辟了新的研究途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [305] [Uncertainty-aware Reward Design Process](https://arxiv.org/abs/2507.02256)
> *不确定性感知奖励设计过程*

*Yang Yang, Xiaolu Zhou, Bosong Ding, Miao Xin* | **Category: cs.LG, cs.RO** | **Updated: {updated}**

**Keywords:** 强化学习, 奖励设计, 大型语言模型, 贝叶斯优化, 不确定性感知

**Comment:** 34 pages, 9 figures

> **TL;DR:** 提出URDP框架，结合LLM和贝叶斯优化，提高强化学习奖励函数设计的质量和效率。

**AI_Comments:** 该论文创新性地将大型语言模型与贝叶斯优化相结合，并通过引入不确定性感知机制，有效解决了强化学习奖励函数设计中效率和质量的痛点。其双层优化架构能够更好地解耦和优化奖励逻辑与数值调优，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习中有效的奖励函数设计是一个挑战；传统奖励工程方法效率低下且不一致；大型语言模型（LLM）自动化设计性能不佳；进化搜索范式资源利用率低，导致设计周期过长且计算开销大。

**Method:** 提出不确定性感知奖励设计过程（URDP），一个整合大型语言模型以简化RL奖励函数设计和评估的新颖框架。URDP通过自洽性分析量化候选奖励函数的不确定性，实现无模拟识别无效奖励组件并发现新组件。引入不确定性感知贝叶斯优化（UABO）提高超参数配置效率。构建双层优化架构，解耦奖励组件优化和超参数调优，协同LLM的奖励逻辑推理和贝叶斯优化的数值优化优势。

**Result:** URDP不仅生成了更高质量的奖励函数，而且与现有方法相比，显著提高了自动化奖励设计的效率。

**Conclusion:** URDP通过结合大型语言模型和不确定性感知优化，有效解决了强化学习中奖励函数设计效率和质量的挑战。

> **ai_Abstract:** 本文提出了不确定性感知奖励设计过程（URDP），一个结合大型语言模型和贝叶斯优化的新颖框架，旨在解决强化学习中奖励函数设计效率低和质量差的问题。URDP通过自洽性分析量化不确定性以识别奖励组件，并引入不确定性感知贝叶斯优化来提高超参数配置效率，最终通过双层优化架构协同LLM和贝叶斯优化。实验证明URDP能生成更高质量的奖励函数并显著提升设计效率。

> **摘要翻译:** 奖励函数设计是强化学习（RL）的基石，但由于传统奖励工程方法固有的低效和不一致性，它仍然是一个具有挑战性的过程。最近的进展探索了利用大型语言模型（LLM）自动化奖励函数设计。然而，它们在数值优化方面的次优性能常常导致不满意的奖励质量，而进化搜索范式则表现出模拟资源利用率低下，导致设计周期过长且计算开销不成比例。为了解决这些挑战，我们提出了不确定性感知奖励设计过程（URDP），这是一个新颖的框架，它整合了大型语言模型，以简化RL环境中的奖励函数设计和评估。URDP基于自洽性分析量化候选奖励函数的不确定性，从而实现无模拟识别无效奖励组件，同时发现新颖的奖励组件。此外，我们引入了不确定性感知贝叶斯优化（UABO），它结合了不确定性估计，显著提高了超参数配置效率。最后，我们通过解耦奖励组件优化和超参数调优，构建了一个双层优化架构。URDP协调了LLM的奖励逻辑推理和贝叶斯优化的数值优化优势之间的协同作用。我们对URDP在涵盖三个基准环境的35个不同任务中进行了全面评估。我们的实验结果表明，与现有方法相比，URDP不仅生成了更高质量的奖励函数，而且在自动化奖励设计效率方面取得了显著提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [307] [Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies](https://arxiv.org/abs/2507.02244)
> *在竞争压力下获取订单：一种针对网约车补贴策略的快速自适应强化学习方法*

*Fangzhou Shi, Xiaopeng Ke, Xinye Xiong, Kexin Meng, Chang Men, Zhengdan Zhu* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 强化学习, 补贴策略, 网约车, 竞争适应, 预算约束

**Comment:** 

> **TL;DR:** 针对网约车平台竞争激烈导致补贴策略难以适应市场变化的问题，本文提出了一种基于强化学习的FCA-RL框架，能快速适应竞争对手定价并优化补贴，并在新模拟环境中表现优异。

**AI_Comments:** 本文的创新点在于提出了FCA-RL框架，结合了快速适应竞争和预算约束优化，解决了现有研究在网约车补贴策略方面稀缺的问题。同时，引入RideGym模拟环境为未来的研究提供了重要的工具和平台，具有较高的实践价值和研究潜力。

<details>
  <summary>Details</summary>

**Motivation:** 网约车聚合平台竞争激烈，服务提供商需要通过补贴策略来降低价格以获取更多订单。然而，设计一种能够在预算约束下动态适应市场波动并优化订单获取的有效补贴策略是一个关键挑战，且现有研究稀缺。

**Method:** 本文提出了FCA-RL，一个新颖的基于强化学习的补贴策略框架，旨在快速适应竞争对手的定价调整。该方法整合了两种关键技术：快速竞争适应（FCA），用于迅速响应动态价格变化；以及强化拉格朗日调整（RLA），用于在优化优惠券决策时遵守预算约束。此外，还引入了RideGym，首个专为网约车聚合平台设计的模拟环境。

**Result:** 实验结果表明，所提出的FCA-RL方法在各种市场条件下始终优于基线方法，突出了其在网约车服务提供商补贴优化方面的有效性。

**Conclusion:** FCA-RL是一种有效的网约车服务提供商补贴优化方法，能够帮助他们在竞争激烈的市场中有效获取订单。

> **ai_Abstract:** 本文针对网约车平台在激烈竞争下获取订单的挑战，提出了一种名为FCA-RL的强化学习框架。该框架结合了快速竞争适应（FCA）和强化拉格朗日调整（RLA）技术，旨在帮助网约车服务提供商在预算约束下，动态调整补贴策略以快速适应竞争对手的定价变化并优化订单获取。为评估该方法，研究还引入了首个网约车聚合器模拟环境RideGym。实验结果显示，FCA-RL在多种市场条件下均优于现有基线方法，证明了其在补贴优化方面的有效性。

> **摘要翻译:** 网约车聚合平台的普及为网约车服务提供商带来了显著的增长机会，增加了订单量和商品总值（GMV）。在大多数网约车聚合平台上，提供较低票价的服务提供商在列表中排名更高，因此更有可能被乘客选择。这种竞争性排名机制强烈激励服务提供商采用优惠券策略来降低价格，以获得更多订单，因为订单量直接影响其长期生存能力和可持续性。因此，设计一种能够动态适应市场波动并在预算约束下优化订单获取的有效优惠券策略是一个关键的研究挑战。然而，该领域的现有研究仍然稀缺。
为了弥补这一空白，我们提出了FCA-RL，一种新颖的基于强化学习的补贴策略框架，旨在快速适应竞争对手的定价调整。我们的方法整合了两种关键技术：快速竞争适应（FCA），它能够对动态价格变化做出迅速响应；以及强化拉格朗日调整（RLA），它确保在优化新价格环境下的优惠券决策时遵守预算约束。此外，我们引入了RideGym，这是第一个专为网约车聚合器量身定制的专用模拟环境，有助于在不影响实际运营效率的情况下，对不同定价策略进行全面评估和基准测试。实验结果表明，我们提出的方法在各种市场条件下始终优于基线方法，突出了其在网约车服务提供商补贴优化方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [316] [Transformer-based EEG Decoding: A Survey](https://arxiv.org/abs/2507.02320)
> *基于Transformer的脑电图解码：一项综述*

*Haodong Zhang, Hongqi Li* | **Category: cs.LG, cs.HC** | **Updated: {updated}**

**Keywords:** Transformer, EEG解码, 脑机接口, 深度学习, 综述

**Comment:** Submitted to IEEE Journals

> **TL;DR:** 这篇综述总结了Transformer模型在脑电图（EEG）解码中的最新应用、模型演变、混合架构以及定制化Transformer结构，并讨论了当前挑战和未来展望。

**AI_Comments:** 这篇综述及时且重要，因为它聚焦于Transformer这一在序列数据处理中表现卓越的模型在EEG解码这一关键脑机接口研究领域的应用。文章结构清晰，涵盖了从基础应用到混合架构和定制化结构的全面内容，并展望了未来挑战，对于研究人员了解该领域的最新进展和指导未来研究具有很高的价值。

<details>
  <summary>Details</summary>

**Motivation:** 脑电图（EEG）解码在脑机接口（BCI/BMI）研究中至关重要。与传统方法相比，深度学习尤其是Transformer模型在处理序列数据和自动学习判别特征方面具有显著优势，正逐渐改变EEG分析领域。因此，有必要对Transformer模型在EEG解码中的最新应用进行全面综述。

**Method:** 本文通过总结自Transformer模型出现以来其在脑电图解码中的最新应用，进行了一项相关综述。具体方法包括：首先阐明Transformer在EEG解码中的基础及其直接应用；然后详细概述了将基本Transformer与其他深度学习技术（如卷积/循环/图/脉冲神经网络、生成对抗网络、扩散模型等）相结合的常见混合架构；还介绍了应用定制化Transformer的改进内部结构的研究进展。最后，讨论了该领域当前的挑战和未来的发展前景。

**Result:** 综述总结了Transformer模型在EEG解码中的最新应用，并追溯了模型架构的演变。它系统地组织了相关进展，包括Transformer在EEG解码中的基础和直接应用、与各种深度学习技术结合的混合架构，以及定制化Transformer改进结构的应用。

**Conclusion:** 本文旨在帮助读者清晰了解Transformer在EEG解码中的当前应用现状，并为未来的研究工作提供有价值的见解。

> **ai_Abstract:** 这篇综述全面回顾了Transformer模型在脑电图（EEG）解码领域的应用进展。文章首先介绍了Transformer在EEG解码中的基础和直接应用，随后详细探讨了Transformer与其他深度学习技术结合的混合架构，以及定制化Transformer结构的研究进展。最后，讨论了该领域的当前挑战和未来发展方向，旨在为读者提供对Transformer在EEG解码应用现状的清晰理解和对未来研究的宝贵见解。

> **摘要翻译:** 脑电图（EEG）是捕获大脑电活动最常用的信号之一，而EEG解码（即获取用户意图）一直处于脑-计算机/机器接口（BCIs/BMIs）研究的前沿。与传统的机器学习EEG分析方法相比，深度学习方法的出现通过提供端到端的长级联架构，能够自动学习更具判别性的特征，从而逐渐革新了该领域。其中，Transformer因其通过注意力机制对序列数据强大的处理能力而闻名，Transformer在各种EEG处理任务中的应用也日益普及。本文深入探讨了一项相关综述，总结了自Transformer模型出现以来其在EEG解码中的最新应用。文章追溯了模型架构的演变，以整理和组织相关进展，其中我们首先阐明了有益于EEG解码的Transformer基础及其直接应用。然后，详细概述了通过将基本Transformer与其他深度学习技术（卷积/循环/图/脉冲神经网络、生成对抗网络、扩散模型等）相结合的常见混合架构。还介绍了应用定制化Transformer改进内部结构的研究进展。最后，讨论了该快速发展领域当前的挑战和未来的发展前景。本文旨在帮助读者清晰了解Transformer在EEG解码中的当前应用现状，并为未来的研究工作提供有价值的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [324] [Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment](https://arxiv.org/abs/2507.02310)
> *概念漂移下自适应记忆重校准的整体持续学习*

*Alif Ashrafee, Jedrzej Kozal, Michal Wozniak, Bartosz Krawczyk* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: {updated}**

**Keywords:** 持续学习, 概念漂移, 记忆重校准, 灾难性遗忘, 数据流

**Comment:** 

> **TL;DR:** 该研究提出了一种名为AMR的轻量级方法，通过选择性地更新记忆缓冲区来应对概念漂移下的持续学习，显著降低了数据和计算开销，同时保持了高准确性。

**AI_Comments:** 该论文通过提出自适应记忆重校准（AMR）机制，解决了传统持续学习方法在概念漂移下表现不佳的问题，这是一个重要的创新点。通过引入新的概念漂移基准数据集，为可复现的评估提供了条件。AMR在显著降低计算和数据需求的同时，实现了与完全重新学习相当的性能，这使其成为一个非常实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统的持续学习方法主要关注知识保留和减轻灾难性遗忘，但忽视了真实世界数据流的动态性，即概念漂移会永久改变先前见过的数据，这需要模型同时具备稳定性和快速适应性。

**Method:** 研究引入了一个用于概念漂移下持续学习的整体框架，通过演变任务分布来模拟真实场景。作为基线，考虑了完全重新学习（FR）。为了解决FR的局限性，提出了自适应记忆重校准（AMR），这是一种轻量级的替代方案，为基于排练的学习器配备了漂移感知适应机制。AMR选择性地从重放缓冲区中移除过时的漂移类样本，并用少量最新的实例重新填充，有效地使记忆与新分布对齐。为了实现可复现的评估，引入了四种标准视觉基准的概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD。

**Result:** AMR的目标重采样方法在性能上与FR匹配，同时将标记数据和计算的需求降低了几个数量级。在多个基于排练的基线上，对新引入的带有概念漂移的基准数据集进行全面实验表明，AMR始终能有效应对概念漂移，以最小的开销保持高准确性。

**Conclusion:** AMR是一种可扩展的解决方案，能够在非平稳持续学习环境中协调稳定性和可塑性。

> **ai_Abstract:** 本研究提出了一个整体框架，用于在概念漂移下进行持续学习，以应对真实世界数据流的动态性。传统的持续学习方法往往忽略了数据分布的变化。为此，我们引入了自适应记忆重校准（AMR），一种轻量级且高效的方法，通过选择性地更新重放缓冲区中的样本，使模型记忆与新的数据分布对齐。AMR在性能上与完全重新学习相当，但显著减少了对标记数据和计算的需求。为了促进研究，我们还创建了四种标准视觉基准的概念漂移变体。在这些数据集上的广泛实验表明，AMR能够持续有效地对抗概念漂移，以最小开销保持高准确性，从而在非平稳持续学习环境中实现了稳定性与可塑性的平衡。

> **摘要翻译:** 传统的持续学习方法优先考虑知识保留，主要侧重于减轻灾难性遗忘，隐含地假设先前学习任务的数据分布保持静态。这忽略了真实世界数据流的动态性质，其中概念漂移永久性地改变了先前见过的数据，并要求同时具备稳定性和快速适应性。
我们引入了一个在概念漂移下进行持续学习的整体框架，通过演变任务分布来模拟真实场景。作为基线，我们考虑了完全重新学习（FR），其中模型根据来自漂移分布的新标记样本从头开始重新训练。虽然有效，但这种方法会产生大量的标注和计算开销。为了解决这些限制，我们提出了自适应记忆重校准（AMR），这是一种轻量级的替代方案，为基于排练的学习器配备了漂移感知适应机制。AMR选择性地从重放缓冲区中移除过时的漂移类样本，并用少量最新的实例重新填充，有效地使记忆与新分布对齐。这种有针对性的重采样在匹配FR性能的同时，将标记数据和计算的需求降低了几个数量级。
为了实现可复现的评估，我们引入了四种标准视觉基准的概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，其中先前见过的类别以偏移的表示形式重新出现。在这些数据集上使用几种基于排练的基线进行的全面实验表明，AMR始终能有效应对概念漂移，以最小的开销保持高准确性。这些结果将AMR定位为一种可扩展的解决方案，能够在非平稳持续学习环境中协调稳定性和可塑性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [327] [Improving Constrained Generation in Language Models via Self-Distilled Twisted Sequential Monte Carlo](https://arxiv.org/abs/2507.02315)
> *通过自蒸馏扭曲序列蒙特卡洛改进语言模型中的约束生成*

*Sooyeon Kim, Giung Nam, Juho Lee* | **Category: cs.LG, stat.ML** | **Updated: {updated}**

**Keywords:** 约束生成, 语言模型, 自蒸馏, 序列蒙特卡洛, 扭曲SMC

**Comment:** 

> **TL;DR:** 该论文通过自蒸馏迭代优化基础模型，解决了扭曲序列蒙特卡洛方法在约束生成中因稀疏奖励信号导致的学习困难，从而显著提升了生成质量。

**AI_Comments:** 该论文的创新点在于将自蒸馏技术应用于改进扭曲序列蒙特卡洛在约束生成中的性能，尤其是在处理稀疏奖励信号的场景下。这为现有方法提供了一个实用的改进方案，有望提升语言模型在复杂约束条件下的生成能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扭曲序列蒙特卡洛（SMC）方法在约束生成设置中，当目标分布集中在基础模型下不太可能出现的输出上时，由于稀疏和信息量不足的奖励信号，导致学习变得具有挑战性。

**Method:** 通过自蒸馏迭代地优化基础模型，使其逐步与目标分布对齐。

**Result:** 通过自蒸馏迭代优化基础模型的方法，缓解了稀疏奖励信号的问题，并显著提升了生成质量。

**Conclusion:** 自蒸馏是一种有效的方法，可以改进语言模型中的约束生成，特别是当使用扭曲序列蒙特卡洛方法时，通过使基础模型与目标分布更对齐。

> **ai_Abstract:** 本文针对扭曲序列蒙特卡洛方法在语言模型约束文本生成中面临的挑战，即当目标分布在基础模型下不常见时，稀疏奖励信号导致学习困难。作者提出了一种通过自蒸馏迭代优化基础模型的方法，使其逐步与目标分布对齐。实验结果表明，该方法有效缓解了稀疏奖励问题，并显著提升了生成质量。

> **摘要翻译:** 最近的工作将自回归语言模型中的约束文本生成框定为概率推理问题。其中，Zhao 等人（2024）引入了一种基于扭曲序列蒙特卡洛的有前景的方法，该方法结合了学习到的扭曲函数和扭曲诱导的提议来指导生成过程。然而，在约束生成设置中，当目标分布集中在在基础模型下不太可能出现的输出上时，由于稀疏和信息量不足的奖励信号，学习变得具有挑战性。我们表明，通过自蒸馏迭代地优化基础模型可以缓解这个问题，通过使模型逐渐与目标对齐，从而在生成质量上获得显著提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [332] [DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values](https://arxiv.org/abs/2507.02342)
> *DeltaSHAP：使用Shapley值解释在线患者监测中的预测演变*

*Changhun Kim, Yechan Mun, Sangchul Hahn, Eunho Yang* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 可解释AI, 在线患者监测, Shapley值, 时间序列, 预测演变

**Comment:** Accepted to ICML 2025 Workshop on Actionable Interpretability. Code
  is available at https://github.com/AITRICS/DeltaSHAP

> **TL;DR:** DeltaSHAP是一种新的可解释AI算法，专为在线患者监测设计，能实时解释预测变化及其特征归因，并在质量和效率上优于现有方法。

**AI_Comments:** DeltaSHAP的创新之处在于其专注于解释时间序列中“预测演变”而非单一预测，并提供了特征归因的“大小和方向”，这对于动态变化的临床决策至关重要。其针对真实临床需求的设计，结合对Shapley值的时序适应性改进，使其在医疗XAI领域具有重要意义。性能提升和代码开源也增加了其实用性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 现有可解释AI方法未能满足临床时间序列解释任务的独特需求，尤其是在发现患者风险演变原因方面，且无法解释连续预测变化、提供特征归因的大小和方向或实时提供洞察。

**Method:** DeltaSHAP算法通过将Shapley值应用于时间序列设置，解释连续预测的变化，并提供特征归因的大小和方向，实现实时洞察。它仅使用实际观测到的特征组合来归因预测变化，提高了效率。该研究还引入了新的评估指标来评估在线时间序列归因的忠实性。

**Result:** DeltaSHAP在在线患者监测任务中，在MIMIC-III失代偿基准测试上，解释质量比现有先进XAI方法高62%，计算效率提高33%。

**Conclusion:** DeltaSHAP是一种有效且高效的可解释人工智能方法，能满足在线患者监测中解释预测演变的关键临床需求，并在性能上超越了现有技术。

> **ai_Abstract:** DeltaSHAP是一种新型的可解释AI（XAI）算法，专门用于在线患者监测系统。它通过将Shapley值应用于时间序列数据，解决了现有XAI方法在临床时间序列解释中的不足，能够实时解释连续预测的变化，并提供特征归因的大小和方向。该方法高效实用，并在实验中证明其在解释质量和计算效率上均优于现有最先进的XAI方法。

> **摘要翻译:** 本研究提出了DeltaSHAP，一种专为在线患者监测系统设计的新型可解释人工智能（XAI）算法。在临床环境中，发现导致患者风险演变的原因对于及时干预至关重要，然而现有的XAI方法未能解决临床时间序列解释任务的独特要求。为此，DeltaSHAP解决了三个关键的临床需求：解释连续预测的变化而非孤立的预测分数，提供特征归因的大小和方向，并实时提供这些洞察。通过将Shapley值应用于时间设置，我们的方法准确地捕捉了特征组合效应。它进一步仅使用实际观测到的特征组合来归因预测变化，使其对时间敏感的临床应用而言既高效又实用。我们还引入了新的评估指标来评估在线时间序列归因的忠实性，并通过在线患者监测任务的实验证明，在MIMIC-III失代偿基准测试中，DeltaSHAP在解释质量方面比现有最先进的XAI方法高出62%，在计算效率方面减少了33%的时间。我们已在https://github.com/AITRICS/DeltaSHAP 发布了代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [334] [Offline Reinforcement Learning with Penalized Action Noise Injection](https://arxiv.org/abs/2507.02356)
> *带有惩罚性动作噪声注入的离线强化学习*

*JunHyeok Oh, Byung-Jun Lee* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 离线强化学习, 动作噪声注入, 泛化能力, 计算效率, 马尔可夫决策过程

**Comment:** 

> **TL;DR:** 提出PANI，一种简单但有效的离线RL方法，通过注入噪声动作并进行惩罚来提高泛化能力，避免了扩散模型的高计算成本，并取得了显著性能提升。

**AI_Comments:** PANI的创新之处在于其通过简单的噪声注入和惩罚机制，实现了与复杂扩散模型相似的泛化能力提升，同时避免了高昂的计算成本。这对于实际应用中资源受限的离线RL场景具有重要意义。其兼容性也使其易于集成到现有算法中。

<details>
  <summary>Details</summary>

**Motivation:** 离线强化学习中，泛化能力是提升性能的关键。尽管扩散模型在离线RL中取得了成功，但其高昂的推理计算成本使得研究其必要性变得可疑。

**Method:** 提出惩罚性动作噪声注入（PANI）方法。该方法通过利用注入噪声的动作来覆盖整个动作空间，并根据注入噪声的量进行惩罚，从而增强离线学习。理论上，这种方法解决了修改后的马尔可夫决策过程（称为噪声动作MDP）。

**Result:** PANI方法兼容多种现有离策略和离线RL算法，并且尽管其简单，但在各种基准测试中表现出显著的性能改进。

**Conclusion:** PANI通过简单地注入惩罚性动作噪声，能够有效提升离线强化学习算法的性能，且无需扩散模型的高计算成本，证明了其在离线RL中的实用性和有效性。

> **ai_Abstract:** 本文提出了一种名为惩罚性动作噪声注入（PANI）的新型离线强化学习方法。针对离线RL中泛化能力的重要性以及扩散模型高计算成本的问题，PANI通过向动作空间注入噪声并施加惩罚来提升学习效果。该方法具有坚实的理论基础，并被证明能够解决一个“噪声动作MDP”。PANI与现有多种离策略和离线RL算法兼容，并在多个基准测试中展现出显著的性能提升，表明其在不增加复杂性的前提下，能有效解决离线RL的泛化挑战。

> **摘要翻译:** 离线强化学习（RL）仅使用固定数据集优化策略，使其成为与环境交互成本高昂场景中的实用方法。由于这一限制，泛化能力是提高离线RL算法性能的关键，正如最近扩散模型在离线RL中取得的成功所证明的那样。然而，考虑到扩散模型在推理过程中显著的计算要求，这种扩散模型对于高性能离线RL算法是否必要仍然值得怀疑。在本文中，我们提出了惩罚性动作噪声注入（PANI），一种通过利用注入噪声的动作来覆盖整个动作空间，同时根据注入噪声的量进行惩罚，从而简单地增强离线学习的方法。这种方法受到了扩散模型在离线RL算法中工作方式的启发。我们为这种方法提供了理论基础，表明带有这种噪声注入动作的离线RL算法解决了一个修改后的马尔可夫决策过程（我们称之为噪声动作MDP）。PANI兼容多种现有离策略和离线RL算法，尽管其简单，但在各种基准测试中表现出显著的性能改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [337] [Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations](https://arxiv.org/abs/2507.02365)
> *基于深度强化学习和潜在表示的DRAM均衡器参数优化*

*Muhammad Usama, Dong Eui Chang* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 深度强化学习, DRAM均衡器, 信号完整性, 潜在表示, 参数优化

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度强化学习和学习到的潜在信号表示的数据驱动框架，用于高效优化高速DRAM系统的均衡器参数，实现了显著的眼图开窗面积改善。

**AI_Comments:** 本文创新性地将深度强化学习应用于DRAM均衡器参数优化，解决了传统方法计算量大和模型依赖的问题。其引入的潜在信号表示和无模型强化学习策略显著提高了优化效率和性能，并在实际DRAM波形上取得了显著的眼图开窗面积改善，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 高速DRAM系统中信号完整性的均衡器参数优化至关重要，但现有方法计算量大或依赖模型。

**Method:** 本文提出一个数据驱动框架，结合学习到的潜在信号表示进行高效信号完整性评估，并使用无模型的优势Actor-Critic强化学习代理进行参数优化。潜在表示捕获关键信号完整性特征，替代直接眼图分析；强化学习代理在没有明确系统模型的情况下推导出最优均衡器设置。

**Result:** 应用于工业标准DRAM波形，级联CTLE和DFE结构眼图开窗面积改善42.7%，仅DFE配置改善36.8%。与现有技术相比，表现出卓越的性能、计算效率和在不同DRAM单元上的鲁棒泛化能力。

**Conclusion:** 本文的核心贡献包括一种用于优化的效率潜在信号完整性度量、一种鲁棒的无模型强化学习策略，以及对复杂均衡器架构验证的卓越性能。

> **ai_Abstract:** 本文提出一种数据驱动的深度强化学习框架，利用学习到的潜在信号表示和无模型的优势Actor-Critic强化学习代理，高效优化高速DRAM系统的均衡器参数。该方法避免了传统方法的计算复杂性和模型依赖性，通过捕获关键信号特征并直接优化均衡器设置，显著提升了眼图开窗面积（CTLE+DFE提高42.7%，DFE提高36.8%），并展现出优越的性能、效率和泛化能力。

> **摘要翻译:** 高速动态随机存取存储器系统中信号完整性的均衡器参数优化至关重要，但通常计算量大或依赖于模型。本文介绍了一种数据驱动的框架，该框架采用学习到的潜在信号表示进行高效的信号完整性评估，并结合无模型的优势Actor-Critic强化学习代理进行参数优化。潜在表示捕获了重要的信号完整性特征，为优化期间的直接眼图分析提供了一种快速替代方案，而强化学习代理在没有明确系统模型的情况下推导出了最优的均衡器设置。该方法应用于工业标准的动态随机存取存储器波形，在级联连续时间线性均衡器和判决反馈均衡器结构中实现了42.7%的显著眼图开窗面积改善，在仅判决反馈均衡器配置中实现了36.8%的改善。这些结果表明，与现有技术相比，该方法在性能、计算效率和跨不同动态随机存取存储器单元的鲁棒泛化能力方面表现出卓越的性能。核心贡献包括一种用于优化的效率潜在信号完整性度量、一种鲁棒的无模型强化学习策略，以及对复杂均衡器架构验证的卓越性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [340] [Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization](https://arxiv.org/abs/2507.02406)
> *通过偏好优化提高车辆轨迹预测的一致性*

*Caio Azevedo, Lina Achaji, Stefano Sabatini, Nicola Poerio, Grzegorz Bartyzel, Sascha Hornauer, Fabien Moutarde* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 轨迹预测, 偏好优化, 多智能体, 场景一致性, 自动驾驶

**Comment:** Accepted for publication at ITSC 2025

> **TL;DR:** 本文受大型语言模型中人类偏好优化的启发，提出了一种使用偏好优化来微调多智能体轨迹预测模型的方法，显著提高了预测结果的场景一致性，同时对准确性影响最小且不增加推理时间计算成本。

**AI_Comments:** 这项工作将大型语言模型中成功的“偏好优化”概念引入到多智能体轨迹预测领域，是一个创新点。它解决了现有模型在复杂交互场景中一致性不足的关键问题，并通过实验证明了其有效性，且不增加推理负担，对自动驾驶的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆的轨迹预测是关键步骤。现有最先进的深度学习轨迹预测模型在公共数据集上表现良好，但在复杂交互场景中，往往无法捕捉智能体之间的重要相互依赖关系，导致预测结果不一致，进而引发规划不佳和潜在危险。

**Method:** 本文受大型语言模型中结合人类偏好有效性的启发，采用偏好优化方法在多智能体设置中微调轨迹预测模型。该方法将自动计算的预测未来之间的偏好排名作为输入进行微调。

**Result:** 在三个独立数据集上使用最先进的模型进行实验，结果表明该方法能够显著提高场景一致性，同时对轨迹预测准确性的牺牲最小，并且在推理时没有增加额外的计算要求。

**Conclusion:** 通过偏好优化微调多智能体轨迹预测模型，可以有效提升预测结果的场景一致性，且不影响准确性和计算效率，从而提高自动驾驶系统的安全性。

> **ai_Abstract:** 本文提出一种通过偏好优化微调多智能体轨迹预测模型的方法，旨在解决现有模型在复杂交互场景中预测不一致的问题。受大型语言模型中偏好优化的启发，该方法利用自动计算的偏好排名作为输入进行微调。实验结果表明，该方法在不增加推理计算成本且对准确性影响极小的情况下，显著提升了轨迹预测的场景一致性。

> **摘要翻译:** 轨迹预测是自动驾驶车辆流程中的一个重要步骤。对其周围智能体运动的不准确或不一致的预测会导致规划不当的操作，并可能给最终用户带来危险情况。当前最先进的基于深度学习的轨迹预测模型可以在公共数据集上实现出色的准确性。然而，当在更复杂、交互式的场景中使用时，它们往往无法捕捉智能体之间重要的相互依赖关系，导致交通场景中智能体之间的预测不一致。受将人类偏好纳入大型语言模型有效性的启发，这项工作使用偏好优化在多智能体设置中微调轨迹预测模型。通过在微调过程中将预测未来之间自动计算的偏好排名作为输入，我们的实验——在三个独立数据集上使用最先进的模型——表明我们能够显著提高场景一致性，同时最小程度地牺牲轨迹预测准确性，并且在推理时没有增加任何额外的计算要求。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [343] [S2FGL: Spatial Spectral Federated Graph Learning](https://arxiv.org/abs/2507.02409)
> *S2FGL：空间谱联邦图学习*

*Zihan Tan, Suyuan Huang, Guancheng Wan, Wenke Huang, He Li, Mang Ye* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 联邦图学习, 空间谱, 图神经网络, 隐私保护, 客户端漂移

**Comment:** 

> **TL;DR:** S2FGL是一个新的联邦图学习框架，通过引入全局知识库和频率对齐来解决现有联邦图学习中因空间和频谱问题导致的标签信号中断和客户端漂移问题，实验证明其优越性。

**AI_Comments:** S2FGL的创新点在于同时考虑了联邦图学习中的空间和频谱域问题，这是当前研究中被忽视的方面。通过提出全局知识库和频率对齐两种机制，S2FGL有效地缓解了标签信号中断和客户端漂移，显著提升了模型的泛化能力和性能。该研究为联邦图学习领域提供了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦图学习（FGL）主要从结构角度解决子图联邦学习问题，忽略了图信号在空间和频谱域的传播。具体来说，空间方面，子图联邦学习导致客户端间边缘断开，引发标签信号中断，降低全局GNN的类别知识；频谱方面，频谱异质性导致子图间信号频率不一致，使得局部GNN过拟合局部信号传播方案，进而产生频谱客户端漂移，损害全局泛化能力。

**Method:** 提出S2FGL框架，通过结合空间和频谱策略来解决挑战。具体方法包括：引入全局知识库以缓解标签信号中断，以及频率对齐以解决频谱客户端漂移。

**Result:** 在多个数据集上的大量实验表明S2FGL具有优越性。

**Conclusion:** S2FGL通过有效解决联邦图学习中的空间和频谱挑战，显著提高了模型的性能和泛化能力。

> **ai_Abstract:** 本文提出了S2FGL，一个空间谱联邦图学习框架，旨在解决现有联邦图学习中忽视图信号在空间和频谱域传播的问题。针对空间域中边缘断开导致的标签信号中断和频谱域中频谱异质性引起的客户端漂移，S2FGL分别引入了全局知识库和频率对齐策略。实验证明，S2FGL在多个数据集上表现出优越的性能。

> **摘要翻译:** 联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）强大的图建模能力。当前研究仅从结构角度解决子图联邦学习问题，忽略了图信号在空间和频谱域的传播。从空间角度看，子图联邦学习导致客户端之间边缘断开，从而引发标签信号中断，并降低全局GNN的类别知识。从频谱角度看，频谱异质性导致子图之间信号频率不一致，使得局部GNN过拟合局部信号传播方案。结果，频谱客户端漂移发生，损害了全局泛化能力。为了应对这些挑战，我们提出了一个全局知识库来缓解标签信号中断，并提出频率对齐来解决频谱客户端漂移。空间和频谱策略的结合形成了我们的S2FGL框架。在多个数据集上进行的大量实验证明了S2FGL的优越性。代码可在https://github.com/Wonder7racer/S2FGL.git获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [346] [Variational Kolmogorov-Arnold Network](https://arxiv.org/abs/2507.02466)
> *变分科尔莫哥洛夫-阿诺德网络*

*Francesco Alesiani, Henrik Christiansen, Federico Errica* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** Kolmogorov-Arnold Networks, KANs, Variational Inference, Machine Learning, Hyperparameter Learning

**Comment:** A preliminary (short paper) version presented at ComBayNS Workshop at
  IJCNN'25

> **TL;DR:** 提出InfinityKAN，通过变分推断自适应学习科尔莫哥洛夫-阿诺德网络(KANs)中单变量函数的基函数数量，解决了KANs中基函数数量的随意选择问题。

**AI_Comments:** 这项工作通过将KANs中一个关键的结构超参数（基函数的数量）内化到学习过程中，是KANs研究的一个重要创新。它将KANs从一个需要手动调参的架构，转变为一个更具自适应性和普适性的模型，有望进一步推动KANs在机器学习领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** 科尔莫哥洛夫-阿诺德网络（KANs）作为一种新兴的机器学习模型架构，虽然基于强大的科尔莫哥洛夫-阿诺德定理，但在实际应用中，每个单变量函数建模的基函数数量需要进行特设选择，这是一个限制其作为多层感知器（MLP）替代的超参数问题。

**Method:** 本文将KANs中单变量函数基函数数量的选择问题建模为一个变分推断优化问题，并提出名为InfinityKAN的方法。InfinityKAN通过反向传播，在训练过程中自适应地学习每个单变量函数潜在无限数量的基函数。

**Result:** InfinityKAN通过将KANs中一个重要的超参数（基函数数量）视为学习过程的一部分来处理，从而扩展了KANs的潜在适用性。

**Conclusion:** InfinityKAN通过将KANs中基函数数量的选择转化为学习过程的一部分，显著提高了KANs的实用性和适用范围。

> **ai_Abstract:** 本文提出了一种名为InfinityKAN的新型科尔莫哥洛夫-阿诺德网络（KANs）架构，旨在解决现有KANs中单变量函数基函数数量需要手动选择的问题。通过将基函数数量的确定建模为变分推断优化问题，InfinityKAN能够在训练过程中自适应地学习潜在无限数量的基函数，从而将这一关键超参数纳入学习过程，显著扩展了KANs的适用性。

> **摘要翻译:** 科尔莫哥洛夫-阿诺德网络（KANs）是一种新兴的机器学习模型构建架构。KANs基于科尔莫哥洛夫-阿诺德定理及其扩展的理论基础，该定理提供了一种将多变量连续有界函数精确表示为有限数量单变量连续函数组合的方法。尽管这些理论结果强大，但它们作为多层感知器（MLP）的表示学习替代方案，其应用取决于对建模每个单变量函数的基函数数量的特设选择。在这项工作中，我们展示了如何通过在训练期间自适应地学习每个单变量函数潜在无限数量的基函数来解决这个问题。因此，我们将该问题建模为一个变分推断优化问题。我们的提议，名为InfinityKAN，它使用反向传播，通过将一个重要的超参数视为学习过程的一部分，扩展了KANs的潜在适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [351] [Continual Gradient Low-Rank Projection Fine-Tuning for LLMs](https://arxiv.org/abs/2507.02503)
> *针对LLMs的持续梯度低秩投影微调*

*Chenxu Wang, Yilin Lyu, Zicheng Sun, Liping Jing* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 持续学习, 低秩适应, 大型语言模型, 微调, 梯度投影

**Comment:** 15 pages, 6 figures, accepted by ACL 2025 main

> **TL;DR:** 提出GORP，一种新的持续学习微调策略，通过结合全秩和低秩参数，在保持效率的同时提高LLMs持续学习的表达能力并缓解灾难性遗忘，超越现有SOTA方法。

**AI_Comments:** GORP的创新之处在于其结合全秩和低秩参数，并在统一的低秩梯度子空间内更新的独特机制，这有效地平衡了模型的表达能力和训练效率，同时显著缓解了持续学习中的灾难性遗忘问题。这项工作为LLMs的持续适应提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）的持续微调在效率和表达能力之间存在权衡。低秩适应（LoRA）虽然高效，但由于其低秩特性和对显式参数约束的依赖，限制了模型学习新任务和知识迁移的能力。

**Method:** 提出了一种名为GORP（Gradient LOw Rank Projection）的持续学习训练策略。GORP通过协同结合全秩和低秩参数，并在统一的低秩梯度子空间内共同更新，从而克服了现有方法的局限性。

**Result:** 在持续学习基准测试中，GORP表现出优于现有最先进方法的性能。

**Conclusion:** GORP通过结合全秩和低秩参数并在统一的低秩梯度子空间中更新，有效解决了LLMs持续微调中效率与表达能力的权衡问题，并缓解了灾难性遗忘，实现了卓越的性能。

> **ai_Abstract:** 本文提出了一种名为GORP（梯度低秩投影）的持续学习新策略，旨在解决大型语言模型（LLMs）持续微调中效率与表达能力之间的权衡问题，并克服LoRA等方法的局限性。GORP通过协同结合全秩和低秩参数，并在统一的低秩梯度子空间内共同更新，有效扩展了优化空间，同时保持了效率并缓解了灾难性遗忘。实验结果表明，GORP在持续学习任务上取得了优于现有SOTA方法的性能。

> **摘要翻译:** 大型语言模型（LLMs）的持续微调受到效率和表达能力之间权衡的阻碍。低秩适应（LoRA）提供了效率，但由于其低秩特性和对显式参数约束的依赖，限制了模型学习新任务和迁移知识的能力。我们提出了用于持续学习的GORP（梯度低秩投影），这是一种新颖的训练策略，通过协同结合全秩和低秩参数并在统一的低秩梯度子空间内共同更新来克服这些限制。GORP在保持效率和减轻灾难性遗忘的同时，扩展了优化空间。在持续学习基准测试中进行的大量实验表明，与现有最先进的方法相比，GORP表现出卓越的性能。代码可在https://github.com/Wcxwcxw/GORP获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [355] [RetrySQL: text-to-SQL training with retry data for self-correcting query generation](https://arxiv.org/abs/2507.02529)
> *RetrySQL：使用重试数据进行文本到SQL训练以实现自我纠正查询生成*

*Alicja Rączkowska, Riccardo Belluzzo, Piotr Zieliński, Joanna Baran, Paweł Olszewski* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 文本到SQL, 自我纠正, 重试数据, 查询生成, 预训练

**Comment:** 

> **TL;DR:** RetrySQL提出了一种新的文本到SQL训练方法，通过使用包含错误和纠正步骤的重试数据对开源编码模型进行预训练，显著提高了查询生成准确性，并证明了自我纠正行为是可学习的。

**AI_Comments:** RetrySQL的创新之处在于引入了“重试数据”的概念，通过模拟错误和纠正过程来训练模型，使其具备自我纠正能力。这与传统的监督学习方法不同，为文本到SQL任务提供了一个新颖且有效的训练范式。该方法证明了即使是参数量相对较小的开源模型，在经过特定数据训练后也能达到与大型专有模型相当的性能，这对于资源受限的研究者和开发者具有重要意义。其局限性可能在于重试数据的构建复杂性，以及对全参数预训练的要求。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到SQL解决方案多专注于使用带有专门组件的黑盒语言模型，缺乏针对SQL的生成模型研究。同时，自我纠正生成策略在其他领域显示出潜力，但在文本到SQL任务中尚未被探索。

**Method:** 本文引入了RetrySQL。首先，为参考SQL查询准备推理步骤，然后通过破坏这些步骤来创建包含错误和纠正步骤的重试数据（用特殊标记分隔）。接着，使用这些数据持续预训练一个开源编码模型。此外，研究了LoRA微调的有效性。

**Result:** 与没有重试数据进行预训练相比，重试步骤在整体和挑战性执行准确性指标上均提高了多达4个百分点。LoRA监督微调对于从重试数据中学习是无效的，全参数预训练是必要的。模型学会了自我纠正行为，并且下游准确性指标的提高是这种额外技能的结果。将RetrySQL训练的模型整合到完整的文本到SQL流程中，其执行准确性与参数量级更大的专有模型具有竞争力。

**Conclusion:** RetrySQL证明了自我纠正在文本到SQL任务中是可学习的，并提供了一种提高面向SQL的语言模型生成准确性的新方法。

> **ai_Abstract:** RetrySQL提出了一种新颖的文本到SQL模型训练方法。通过创建包含错误和纠正步骤的“重试数据”来持续预训练开源编码模型，该方法显著提高了查询生成准确性，最高可达4个百分点。研究表明，全参数预训练对于学习自我纠正行为至关重要，而LoRA微调则无效。RetrySQL训练的模型在执行准确性方面与大型专有模型具有竞争力，证明了自我纠正能力在文本到SQL任务中的有效性和可学习性。

> **摘要翻译:** 文本到SQL任务是自然语言处理领域的一个活跃挑战。许多现有解决方案专注于使用带有定制端到端文本到SQL管道中专用组件的黑盒语言模型。虽然这些解决方案同时使用了闭源专有语言模型和面向编码的开源模型，但缺乏关于SQL专用生成模型的研究。与此同时，自我纠正生成策略的最新进展显示出改善现有架构能力的希望。这些概念在文本到SQL任务中的应用仍未被探索。在本文中，我们介绍了RetrySQL，一种训练文本到SQL生成模型的新方法。我们为参考SQL查询准备推理步骤，然后破坏它们以创建包含不正确和已纠正步骤的重试数据，并用特殊标记分隔。我们使用这些数据持续预训练一个开源编码模型，并证明与没有重试数据进行预训练相比，重试步骤在整体和挑战性执行准确性指标上均提高了多达4个百分点。此外，我们确认使用LoRA进行监督微调对于从重试数据中学习是无效的，并且全参数预训练是该任务的必要条件。我们展示了模型学习了自我纠正行为，并且下游准确性指标的提高是这种额外技能的结果。最后，我们将RetrySQL训练的模型整合到完整的文本到SQL管道中，并展示它们在执行准确性方面与参数量级更大的专有模型具有竞争力。RetrySQL表明自我纠正可以在文本到SQL任务中学习，并提供了一种提高面向SQL的语言模型生成准确性的新颖方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [356] [Position: A Theory of Deep Learning Must Include Compositional Sparsity](https://arxiv.org/abs/2507.02550)
> *立场：深度学习理论必须包含组合稀疏性*

*David A. Danhofer, Davide D'Ascenzo, Rafael Dubach, Tomaso Poggio* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 深度学习, 组合稀疏性, 神经网络理论, 泛化, 可学习性

**Comment:** 

> **TL;DR:** 深度学习的成功源于其利用目标函数的组合稀疏结构的能力。

**AI_Comments:** 这篇立场论文提出了一种关于深度学习成功机制的深刻见解，即组合稀疏性。它将DNN的成功归因于其对函数内在结构的高效利用，这为理解DNN的泛化能力提供了新的视角。该论文的创新之处在于明确指出并强调了组合稀疏性作为深度学习理论核心组成部分的重要性，并将其与图灵可计算函数联系起来。其重要性在于为未来深度学习理论研究指明了方向，特别是在可学习性和优化方面。

<details>
  <summary>Details</summary>

**Motivation:** 尽管过参数化的深度神经网络（DNNs）取得了显著成功，但关于其学习动力学基本原理的开放性问题仍然存在。本文旨在提出一个核心原则，解释DNNs成功的根本原因。

**Method:** 本文是一篇立场论文，通过论证和分析，提出深度神经网络之所以成功，是因为它们能够利用目标函数的组合稀疏结构。作者通过将此特性与可有效图灵计算的函数联系起来，支持其论点。

**Result:** 作者认为，深度神经网络的成功在于它们能够有效利用目标函数的组合稀疏结构。这种特性是指大多数实际相关的函数可以由一小组构成函数组成，每个构成函数仅依赖于所有输入的一个低维子集。论文指出，所有可有效图灵计算的函数都具有这种特性，因此它很可能存在于所有当前的学习问题中。

**Conclusion:** 深入理解组合稀疏性在深度学习中的作用，对于构建一个全面的人工智能乃至通用智能理论至关重要。

> **ai_Abstract:** 这篇立场论文提出，深度神经网络（DNNs）之所以能取得巨大成功，是因为它们能够有效利用目标函数固有的组合稀疏结构。作者认为，大多数实际相关的函数都可以由少量依赖于低维输入子集的构成函数组合而成，这种特性普遍存在于所有可有效图灵计算的函数中。论文强调，尽管在组合稀疏函数方面已有一些理论进展，但DNNs的可学习性和优化仍有待深入研究，并指出理解组合稀疏性对建立全面的人工智能理论至关重要。

> **摘要翻译:** 过参数化的深度神经网络（DNNs）在各种高维领域中取得了显著成功，这些领域对于受维度诅咒影响的经典浅层网络来说过于复杂。然而，关于DNNs学习动力学基本原理的开放性问题仍然存在。在这篇立场论文中，我们认为正是DNNs利用目标函数的组合稀疏结构的能力推动了它们的成功。因此，DNNs可以利用这样一种特性：大多数实际相关的函数可以由一小组构成函数组成，每个构成函数仅依赖于所有输入的一个低维子集。我们表明，所有可有效图灵计算的函数都具有这种特性，因此它很可能存在于所有当前的学习问题中。虽然在组合稀疏函数设置中，关于近似和泛化问题的理论见解已取得一些有希望的进展，但关于DNNs可学习性和优化的几个重要问题仍然存在。完善组合稀疏性在深度学习中作用的图景对于构建一个全面的人工智能乃至通用智能理论至关重要。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [359] [Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability](https://arxiv.org/abs/2507.02559)
> *变压器在推理时不需要LayerNorm：将LayerNorm移除扩展到GPT-2 XL及其对机械可解释性的影响*

*Luca Baroni, Galvin Khara, Joachim Schaeffer, Marat Subkhankulov, Stefan Heimersheim* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** LayerNorm, Transformer, GPT-2, 可解释性, 推理时间

**Comment:** 

> **TL;DR:** 本文证明在推理时可以从GPT-2模型中移除LayerNorm层，只导致验证损失的轻微增加，并有助于提高模型的可解释性。

**AI_Comments:** 本文的创新之处在于挑战了LayerNorm在Transformer模型中不可或缺的普遍认知，特别是在推理阶段。通过实验证明GPT-2模型可以在没有LN的情况下运行，并对可解释性带来积极影响，这为理解和优化大型语言模型提供了新的视角。移除LN不仅可能简化模型结构，还为未来的可解释性研究提供了更“干净”的平台，有助于更精确地分析模型内部机制。

<details>
  <summary>Details</summary>

**Motivation:** Layer-wise normalization (LN) 在几乎所有基于Transformer的大型语言模型中都是一个重要组成部分。虽然其对训练稳定性的影响已得到充分记录，但其在推理时的作用却知之甚少。此外，LN层通过引入额外的非线性和增加单个模型组件的互联性，阻碍了机械可解释性。

**Method:** 研究人员将所有LN层从每个GPT-2模型中移除，并评估了其对验证损失的影响。他们还测试了在无LN模型上的可解释性技术，包括直接logit归因和归因修补，并检查了“置信神经元”的活跃度。

**Result:** 1. 所有LN层都可以从每个GPT-2模型中移除，验证损失仅小幅增加（例如，GPT-2 XL的交叉熵损失增加+0.03）。
2. LN在语言建模中不起主要作用。
3. 移除LN所需的微调数据量与模型参数呈亚线性增长，表明可扩展到更大的模型。
4. 在无LN模型上，直接logit归因现在可以给出单个组件的精确直接效应。
5. 归因修补的准确性没有显著提高。
6. GPT-2的“置信神经元”在无LN模型中不活跃。

**Conclusion:** 本文澄清了LN层在语言建模中的作用，表明GPT-2级别的模型可以在没有LN层的情况下运行。

> **ai_Abstract:** 这篇论文探讨了大型语言模型中层归一化（LN）在推理时的作用及其对机械可解释性的影响。研究发现，可以从GPT-2模型中移除所有LN层，仅导致验证损失的轻微增加，这表明LN在语言建模中并非必要。此外，移除LN有助于提高模型的可解释性，例如使直接logit归因能够提供更精确的效应。研究还指出，移除LN所需的微调数据量随模型参数亚线性增长，预示着该方法可扩展到更大的模型。作者发布了无LN的GPT-2模型，以期促进更深入的可解释性研究。

> **摘要翻译:** 层归一化（LN）几乎是所有基于Transformer的大型语言模型的关键组成部分。尽管其对训练稳定性的影响已得到充分记录，但其在推理时的作用却知之甚少。此外，LN层通过引入额外的非线性和增加单个模型组件的互联性，阻碍了机械可解释性。在此，我们展示了可以从每个GPT-2模型中移除所有LN层，而验证损失仅小幅增加（例如，GPT-2 XL的交叉熵损失增加+0.03）。因此，LN在语言建模中不能扮演重要角色。我们发现，移除LN所需的微调数据量与模型参数呈亚线性增长，这表明扩展到更大的模型是可行的。我们在Hugging Face上发布了一套无LN的GPT-2模型。此外，我们还在无LN模型上测试了可解释性技术。直接logit归因现在可以给出单个组件的精确直接效应，而归因修补的准确性没有显著提高。我们还证实了GPT-2的“置信神经元”在无LN模型中不活跃。我们的工作阐明了LN层在语言建模中的作用，表明GPT-2级别的模型可以在没有LN层的情况下运行。我们希望我们发布的GPT-2家族模型的无LN模拟版本将能够实现更精确的可解释性研究，并提高我们对语言模型的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [361] [Scalable Interconnect Learning in Boolean Networks](https://arxiv.org/abs/2507.02585)
> *可扩展的布尔网络互连学习*

*Fabian Kresse, Emily Yu, Christoph H. Lampert* | **Category: cs.LG, cs.LO** | **Updated: {updated}**

**Keywords:** 布尔网络, 可微分布尔逻辑网络, 可扩展互连, 模型剪枝, 硬件推理

**Comment:** 12 pages, 8 Figures

> **TL;DR:** 本文通过引入可扩展的互连和两种剪枝策略，显著提升了可微分布尔逻辑网络（DBNs）的层宽度扩展能力和模型尺寸优化，同时保持了高精度。

**AI_Comments:** 本文的主要创新点在于其提出的可扩展互连设计，这有效地解决了DBNs在处理更宽层时的扩展性问题，是其应用于复杂场景的关键一步。同时，双阶段剪枝策略，特别是数据驱动的相似性剪枝，为模型在资源受限硬件上的部署提供了实用的优化方案，展现了其在效率和性能之间取得平衡的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可微分布尔逻辑网络（DBNs）在资源受限硬件上表现高效，但其早期可学习互连设计在扩展到更宽层时存在局限性。此外，进一步减小模型尺寸也是一个重要需求。

**Method:** 通过引入一个可训练、可微分的互连来扩展DBNs，该互连的参数数量与输入宽度无关，从而实现更宽层的扩展。同时提出了两个互补的剪枝阶段：一个基于SAT的逻辑等效剪枝用于移除冗余门，以及一个基于相似性的数据驱动剪枝，以优化压缩与准确性的权衡。

**Result:** 新引入的可训练互连使得DBNs能够扩展到比早期设计更宽的层，同时保持了原有的高精度。基于相似性的数据驱动剪枝方法在压缩-准确性权衡方面优于传统的基于幅度的贪婪基线。

**Conclusion:** 该研究通过创新的可扩展互连设计和高效的剪枝技术，成功提升了可微分布尔逻辑网络（DBNs）的层宽度扩展能力和模型尺寸优化，同时维持了其固有的高准确性，使其更适用于资源受限的硬件。

> **ai_Abstract:** 本文提出了一种改进的可微分布尔逻辑网络（DBNs），通过引入一种参数数量与输入宽度无关的可训练、可微分互连，解决了DBNs在扩展到更宽层时的瓶颈，并保持了其高精度。此外，为进一步减小模型尺寸，论文还提出了两种互补的剪枝策略：一种是基于SAT的逻辑等效剪枝，用于移除冗余门；另一种是基于相似性的数据驱动剪枝，该方法在压缩与准确性之间提供了更优的权衡，并超越了现有基线。

> **摘要翻译:** 学习型可微分布尔逻辑网络 (DBNs) 已经在资源受限的硬件上实现了高效推理。我们通过一个可训练、可微分的互连扩展了它们，该互连的参数数量随着输入宽度的增长而保持不变，从而使 DBNs 能够扩展到比早期可学习互连设计更宽的层，同时保持其有利的准确性。为了进一步减小模型尺寸，我们提出了两个互补的剪枝阶段：一个基于 SAT 的逻辑等效剪枝，可以在不影响性能的情况下移除冗余门；以及一个基于相似性、数据驱动的剪枝，它优于基于幅度的贪婪基线，并提供了卓越的压缩-准确性权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [362] [Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation](https://arxiv.org/abs/2507.02608)
> *迷失在潜在空间：潜变量扩散模型在物理模拟中的实证研究*

*François Rozet, Ruben Ohana, Michael McCabe, Gilles Louppe, François Lanusse, Shirley Ho* | **Category: cs.LG, physics.flu-dyn** | **Updated: {updated}**

**Keywords:** 潜在扩散模型, 物理模拟, 计算成本, 压缩率, 动力学系统

**Comment:** 

> **TL;DR:** 本研究发现，将扩散模型应用于物理模拟时，在潜在空间进行操作可以显著降低计算成本，同时保持高精度，并且比非生成模型更准确。

**AI_Comments:** 这项研究的重要性在于它成功地将潜在空间扩散模型的概念从图像生成领域扩展到物理模拟，有效解决了传统扩散模型计算成本高昂的限制。其创新之处在于证明了在极高压缩率下仍能保持模拟精度，这对于实时或大规模物理模拟具有重要意义。此外，其对模型鲁棒性和多样性的发现也为未来研究提供了宝贵的见解。该工作为开发更高效、更准确的物理模拟器开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在推理时的计算成本高昂，阻碍了它们作为快速物理模拟器的应用。在图像和视频生成领域，通过在自编码器的潜在空间而非像素空间进行生成来解决这一问题。本研究旨在探讨类似策略是否能有效应用于动力学系统模拟，以及其代价。

**Method:** 本研究调查了将自编码器潜在空间生成策略应用于动力学系统模拟的有效性及其成本。通过实证研究，比较了潜在空间模拟的准确性与压缩率的关系，并与非生成模型进行了对比。

**Result:** 研究发现，潜在空间模拟的准确性对广泛的压缩率（高达1000倍）表现出惊人的鲁棒性。此外，基于扩散的模拟器始终比非生成对应物更准确，并通过更大的多样性来弥补预测中的不确定性。研究还涵盖了在训练潜在空间模拟器时关键的实用设计选择，包括架构和优化器。

**Conclusion:** 在潜在空间中应用扩散模型能有效降低物理模拟的计算成本，同时保持甚至提高准确性，并且比传统方法更具优势，为高效物理模拟提供了有前景的途径。

> **ai_Abstract:** 本研究旨在解决扩散模型在物理模拟中计算成本高的问题，借鉴了图像生成领域在潜在空间进行操作的成功经验。结果表明，潜在空间模拟的准确性对高压缩率（高达1000倍）表现出强大的鲁棒性。此外，基于扩散的模拟器比非生成模型更准确，并能通过增加多样性来处理不确定性。研究还探讨了训练潜在空间模拟器的关键设计选择，证明了潜在扩散模型在高效物理模拟方面的巨大潜力。

> **摘要翻译:** 扩散模型在推理时高昂的计算成本阻碍了它们作为快速物理模拟器的应用。在图像和视频生成领域，这一计算缺陷已通过在自编码器的潜在空间而非像素空间进行生成来解决。在这项工作中，我们研究了类似的策略是否能有效应用于动力学系统模拟，以及其代价。我们发现，潜在空间模拟的准确性对广泛的压缩率（高达1000倍）表现出惊人的鲁棒性。我们还表明，基于扩散的模拟器始终比非生成对应物更准确，并通过更大的多样性来弥补预测中的不确定性。最后，我们涵盖了在训练潜在空间模拟器时我们发现至关重要的实用设计选择，包括架构到优化器。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [363] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
> *OmniDraft：一种用于设备端推测解码的跨词汇、在线自适应草稿模型*

*Ramchalam Kinattinkara Ramakrishnan, Zhaocong Yuan, Shaojie Zhuo, Chen Feng, Yicheng Lin, Chenzheng Su, Xiaopeng Zhang* | **Category: cs.LG, cs.CL** | **Updated: {updated}**

**Keywords:** 推测解码, 设备端LLM, 跨词汇, 在线自适应, 草稿模型

**Comment:** 

> **TL;DR:** OmniDraft是一个统一的框架，使得单个草稿模型能够与任何目标模型协同工作，并在线适应用户数据，从而解决跨词汇不匹配和提高推测解码速度的挑战，特别适用于设备端LLM应用。

**AI_Comments:** OmniDraft的创新之处在于提出了“一模型多用”的推测解码范式，通过在线自适应和跨词汇兼容性解决了设备端LLM部署的关键挑战。其混合蒸馏微调和在线n-gram缓存机制是解决兼容性问题的核心，而自适应草稿技术则进一步提升了效率。这项工作对于推动LLM在资源受限设备上的广泛应用具有重要意义，因为它降低了对特定预训练草稿模型的依赖，并提供了运行时性能优化的能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的推测解码草稿模型通常需要离线预训练或蒸馏到特定目标模型系列，但在在线部署中面临两大挑战：1) 目标模型与草稿模型不兼容；2) 期望在使用过程中不断提高延迟性能。这促使了“一模型多用”的范式。

**Method:** 提出OmniDraft框架。通过引入在线n-gram缓存结合混合蒸馏微调来解决草稿模型和目标模型之间的跨词汇不匹配问题；并通过利用自适应草稿技术进一步提高解码速度。

**Result:** OmniDraft在数学推理、编码和文本生成任务上展示了在线学习的熟练度。一个Llama-68M模型能够与Vicuna-7B、Qwen2-7B和Llama3-8B等多种目标模型进行推测解码配对，并提供高达1.5-2倍的速度提升。

**Conclusion:** OmniDraft成功解决了设备端LLM应用中推测解码的兼容性和效率挑战，实现了“一模型多用”的范式，显著提升了跨模型推测解码的速度和灵活性。

> **ai_Abstract:** OmniDraft是一个为设备端推测解码设计的统一框架，旨在解决草稿模型与目标模型兼容性差以及在线部署中性能随时间提升的需求。它通过引入在线n-gram缓存和混合蒸馏微调解决了跨词汇不匹配问题，并通过自适应草稿技术提高了解码速度。该框架使得单个草稿模型能与多种目标模型协同工作并动态适应用户数据，在实际任务中实现了显著的速度提升，并满足了设备端LLM应用对成本、效率和定制化的要求。

> **摘要翻译:** 推测解码通常需要一个小型、高效的草稿模型，该模型要么经过预训练，要么离线蒸馏到特定的目标模型系列，例如Llama或Qwen模型。然而，在在线部署设置中存在两大主要挑战：1）使用与草稿模型不兼容的目标模型；2）期望在使用和时间上提高延迟性能。在这项工作中，我们提出了OmniDraft，一个统一的框架，使单个草稿模型能够与任何目标模型操作并动态适应用户数据。我们引入了一个带有混合蒸馏微调的在线n-gram缓存，以解决草稿模型和目标模型之间的跨词汇不匹配；并进一步通过利用自适应草稿技术提高解码速度。OmniDraft特别适用于设备端LLM应用，其中模型成本、效率和用户定制是主要争议点。这进一步强调了解决上述挑战的必要性，并促使了“一模型多用”的范式。我们通过在数学推理、编码和文本生成任务上进行在线学习，展示了OmniDraft框架的熟练度。值得注意的是，OmniDraft使单个Llama-68M模型能够与包括Vicuna-7B、Qwen2-7B和Llama3-8B模型在内的各种目标模型进行推测解码配对；并额外提供了高达1.5-2倍的速度提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [364] [L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation](https://arxiv.org/abs/2507.02619)
> *L-VAE：具有可学习Beta的变分自编码器用于解耦表示*

*Hazal Mogultay Ozcan, Sinan Kalkan, Fatos T. Yarman-Vural* | **Category: cs.LG, cs.CV** | **Updated: {updated}**

**Keywords:** 变分自编码器, 解耦表示, 可学习Beta, 损失函数, 超参数优化

**Comment:** The paper is under revision at Machine Vision and Applications

> **TL;DR:** L-VAE是一种新型的变分自编码器，通过学习损失函数中的超参数来动态平衡解耦和重构损失，从而实现更好的解耦表示。

**AI_Comments:** L-VAE的创新之处在于其“可学习的Beta”机制，它允许模型动态调整解耦和重建损失之间的权衡，而非依赖于经验性超参数调整。这解决了传统\beta-VAE的一个主要限制，使其在解耦表示学习方面更加鲁棒和有效。其通过并发学习损失权重和模型参数，并引入正则化项的设计，也体现了对模型稳定性和性能的细致考量。该方法对于需要高质量解耦表示的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的\beta-VAE模型中，超参数\beta需要凭经验调整，这限制了其性能。L-VAE旨在通过学习损失项的相对权重来解决这一限制，以控制解耦和重构损失之间的动态权衡。

**Method:** 提出了一种名为L-VAE的新模型，它是\beta-VAE的扩展。L-VAE通过并发学习损失项的权重和模型架构的参数来动态调整解耦和重构损失之间的权衡。此外，损失函数中添加了一个额外的正则化项，以防止模型偏向于重构或解耦损失。

**Result:** 实验分析表明，L-VAE在重建保真度和解耦潜在维度之间找到了有效的平衡。与\beta-VAE、VAE、ControlVAE、DynamicVAE和\sigma-VAE等模型在dSprites、MPI3D-complex、Falcor3D和Isaac3D数据集上的比较显示，L-VAE在多个解耦指标上始终提供最佳或次佳性能。在CelebA数据集上的定性实验也证实了L-VAE在解耦面部属性方面的成功。

**Conclusion:** L-VAE通过学习损失函数中的超参数，成功地在解耦表示和重建保真度之间取得了更好的平衡，并在多个数据集上表现出优越的性能。

> **ai_Abstract:** L-VAE是一种新型的变分自编码器，通过学习损失函数中的超参数来动态调整解耦和重构损失之间的平衡，从而克服了传统\beta-VAE的局限性。该模型并发学习损失权重和模型参数，并引入正则化项防止偏向。实验证明，L-VAE在多个数据集上实现了重建保真度和潜在维度解耦的有效平衡，并展现出优于现有模型的性能。

> **摘要翻译:** 在本文中，我们提出了一种名为可学习变分自编码器（L-VAE）的新型模型，它与成本函数的超参数一起学习解耦表示。L-VAE可以被认为是\beta-VAE的扩展，其中超参数\beta是凭经验调整的。L-VAE通过学习损失函数中项的相对权重来控制解耦和重构损失之间的动态权衡，从而缓解了\beta-VAE的局限性。在所提出的模型中，损失项的权重和模型架构的参数是同时学习的。损失函数中添加了一个额外的正则化项，以防止偏向于重构或解耦损失。实验分析表明，所提出的L-VAE在重建保真度和解耦潜在维度之间找到了有效的平衡。将所提出的L-VAE与\beta-VAE、VAE、ControlVAE、DynamicVAE和\sigma-VAE在dSprites、MPI3D-complex、Falcor3D和Isaac3D等数据集上进行比较，结果显示L-VAE在根据一组解耦指标衡量的性能上始终提供最佳或次佳的表现。此外，在CelebA数据集上的定性实验证实了L-VAE模型在解耦面部属性方面的成功。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [367] [A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes](https://arxiv.org/abs/2507.02624)
> *用于药物基因变异效应预测的矩阵变分自编码器*

*Antoine Honoré, Borja Rodríguez Gálvez, Yoomi Park, Yitian Zhou, Volker M. Lauschke, Ming Xiao* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 变异效应预测, 矩阵变分自编码器, 药物基因, 深度突变扫描, Transformer

**Comment:** 12+8 pages

> **TL;DR:** 本研究提出了一种基于Transformer的矩阵变分自编码器（matVAE），用于药物基因中的变异效应预测，并证明其在DMS数据集上的性能优于现有技术，同时强调了DMS数据集替代MSA的潜力。

**AI_Comments:** 这项工作创新性地提出了基于Transformer的matVAE模型，并有效结合了结构化先验和AlphaFold结构信息，显著提升了变异效应预测的性能。其重要性在于证明了DMS数据集在无需显著牺牲预测性能的前提下，有潜力替代传统MSAs，这对于药物基因组学领域具有重要意义，能推动更高效、更准确的药物基因变异分析方法的发展。

<details>
  <summary>Details</summary>

**Motivation:** 传统的变异效应预测器（VEPs）依赖多序列比对（MSAs），但这种方法假设自然发生的变异是适应的，这在药物基因组学中受到挑战，因为一些药物基因的进化压力较低。深度突变扫描（DMS）数据集提供了定量适应性评分，为解决这一问题提供了替代方案。

**Method:** 研究提出了一种基于Transformer的矩阵变分自编码器（matVAE），具有结构化先验。该模型在33个DMS数据集上进行评估，这些数据集来自ProteinGym基准测试中26个药物靶点和ADME蛋白。模型使用MSAs进行训练（matVAE-MSA），并与在DMS数据上训练的matENC-DMS模型进行比较。此外，还将AlphaFold生成的结构整合到Transformer模型中以进一步提高性能。

**Result:** 用MSAs训练的matVAE（matVAE-MSA）在DMS数据集上的零样本预测中优于最先进的DeepSequence模型，尽管其参数数量少一个数量级，推理时计算量更少。与在DMS数据上训练的matENC-DMS相比，后者在监督预测任务上表现更好。将AlphaFold生成的结构整合到Transformer模型中进一步提高了性能，达到了与在MSAs上训练并在DMS上微调的DeepSequence相当的结果。

**Conclusion:** 这些发现突出了DMS数据集在预测性能没有显著损失的情况下替代MSAs的潜力，这促使DMS数据集的进一步开发以及对其关系的探索，以增强变异效应预测。

> **ai_Abstract:** 本研究提出了一种名为matVAE的基于Transformer的矩阵变分自编码器，用于药物基因中的变异效应预测。为了克服传统多序列比对（MSA）方法在药物基因组学中的局限性，该模型利用深度突变扫描（DMS）数据集进行训练和评估。实验结果表明，在零样本预测中，matVAE-MSA（使用MSA训练）在DMS数据集上优于现有SOTA模型DeepSequence，且计算效率更高。尽管在监督任务上matENC-DMS（使用DMS数据训练）表现更好，但结合AlphaFold结构进一步提升了matVAE的性能，使其与经过DMS微调的DeepSequence相当。研究强调了DMS数据集在变异效应预测中替代MSA的巨大潜力。

> **摘要翻译:** 变异效应预测器（VEPs）旨在评估蛋白质变异的功能影响，传统上依赖于多序列比对（MSAs）。这种方法假设自然发生的变异是适应的，但在药物基因组学中，这种假设受到了挑战，因为一些药物基因的进化压力较低。深度突变扫描（DMS）数据集通过提供变异的定量适应性评分，提供了一种替代方案。在这项工作中，我们提出了一种基于Transformer的矩阵变分自编码器（matVAE），具有结构化先验，并在来自ProteinGym基准测试的33个DMS数据集上评估了其性能，这些数据集对应于26种药物靶点和ADME蛋白。我们使用MSAs训练的模型（matVAE-MSA）在DMS数据集上的零样本预测中优于最先进的DeepSequence模型，尽管其参数数量少一个数量级，并且在推理时需要更少的计算。我们还将matVAE-MSA与在DMS数据上训练的类似容量的模型matENC-DMS进行了比较，发现后者在监督预测任务上表现更好。此外，将AlphaFold生成的结构整合到我们的Transformer模型中进一步提高了性能，达到了与在MSAs上训练并在DMS上微调的DeepSequence相当的结果。这些发现突出了DMS数据集在预测性能没有显著损失的情况下替代MSAs的潜力，这促使DMS数据集的进一步开发以及对其关系的探索，以增强变异效应预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [368] [Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data](https://arxiv.org/abs/2507.02628)
> *医疗数据啄取：一种用于结构化医疗数据自动质量评估的上下文感知方法*

*Irena Girshovitz, Atai Ambus, Moni Shahar, Ran Gilad-Bachrach* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 医疗数据质量, 电子健康记录, 自动化测试, 大型语言模型, 数据质量评估

**Comment:** 18 pages, 4 figures (+ appendix)

> **TL;DR:** 提出了一种名为“医疗数据啄取”的新方法，它借鉴了软件工程中的单元测试概念，并利用大型语言模型自动生成和执行测试，以评估和提高电子健康记录（EHR）数据的质量，从而支持流行病学研究和AI训练。

**AI_Comments:** 该论文的创新之处在于将软件工程的单元测试和代码覆盖率概念创造性地应用于医疗数据质量评估，并结合了大型语言模型（LLM）实现测试的自动化生成，这在医疗数据领域是一个新颖且重要的尝试。其重要性体现在能够系统性地识别电子健康记录（EHR）中的质量问题，从而提高基于EHR的流行病学研究和AI模型训练的可靠性和有效性。该方法为未来医疗数据质量保证提供了一个坚实的基础，特别是在处理复杂、异构的医疗数据方面。

<details>
  <summary>Details</summary>

**Motivation:** 电子健康记录（EHR）在流行病学研究和人工智能（AI）训练中的应用迅速增长，但EHR数据通常存在显著的质量问题，如子群体误报、偏见和系统性错误，这会影响结果的可靠性。现有质量评估方法不足以系统性地评估数据是否适合研究。

**Method:** 本文提出了“医疗数据啄取”方法，该方法借鉴了软件工程中的单元测试和覆盖率概念来识别数据质量问题。通过医疗数据啄取工具（MDPT）进行演示，该工具包含两个主要组件：1）一个自动测试生成器，它使用大型语言模型和接地技术从数据和研究描述中创建测试套件；2）一个数据测试框架，用于执行这些测试并报告潜在错误和覆盖率。

**Result:** MDPT在三个数据集（All of Us, MIMIC-III, SyntheticMass）上进行了评估，在四种条件下，每个队列生成了55-73个测试。这些测试成功识别了20-43个不一致或不符合规范的数据问题。研究还对LLM生成的测试套件在参考接地和值准确性方面进行了详细分析。

**Conclusion:** 该方法结合外部医学知识，在数据分析工作流程中实现了上下文敏感的数据质量测试，从而提高了结果的有效性。该方法从质量保证的角度解决了这些挑战，为进一步发展奠定了基础，例如支持更多数据模式和改进接地方法。

> **ai_Abstract:** 本研究提出了一种名为“医疗数据啄取”（Medical Data Pecking）的上下文感知方法，用于自动化结构化医疗数据（如电子健康记录EHR）的质量评估。鉴于EHR数据在流行病学研究和AI训练中日益增长的应用以及其固有的质量问题，该方法借鉴了软件工程中的单元测试和覆盖率概念。通过开发的医疗数据啄取工具（MDPT），该方法利用大型语言模型自动生成测试套件，并执行这些测试以识别数据中的不一致和错误。实验证明，MDPT在多个真实世界数据集上有效识别了数据质量问题，为提高医疗数据质量和研究结果的可靠性提供了新的质量保证范式。

> **摘要翻译:** 背景：电子健康记录（EHR）在流行病学研究和人工智能（AI）训练中的使用正在迅速增加。结果的可靠性取决于EHR数据的准确性和完整性。然而，EHR数据通常包含显著的质量问题，包括亚群体的错误表示、偏见和系统性错误，因为它们主要用于临床和计费目的。现有的质量评估方法仍然不足，缺乏系统程序来评估数据是否适合研究。
方法：我们提出了医疗数据啄取方法，该方法借鉴了软件工程中的单元测试和覆盖率概念来识别数据质量问题。我们使用医疗数据啄取工具（MDPT）演示了我们的方法，该工具由两个主要组件组成：(1) 一个自动测试生成器，它使用大型语言模型和接地技术从数据和研究描述中创建测试套件，以及 (2) 一个数据测试框架，用于执行这些测试，报告潜在的错误和覆盖率。
结果：我们在三个数据集：All of Us (AoU)、MIMIC-III 和 SyntheticMass 上评估了 MDPT，在四种条件下，每个队列生成了 55-73 个测试。这些测试正确识别了 20-43 个不一致或不符合规范的数据问题。我们对 LLM 生成的测试套件在参考接地和值准确性方面进行了详细分析。
结论：我们的方法结合了外部医学知识，以实现上下文敏感的数据质量测试，作为数据分析工作流程的一部分，从而提高其结果的有效性。我们的方法从质量保证的角度解决了这些挑战，为进一步发展奠定了基础，例如额外的数据模式和改进的接地方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [370] [High-Order Deep Meta-Learning with Category-Theoretic Interpretation](https://arxiv.org/abs/2507.02634)
> *高阶深度元学习与范畴论解释*

*David H. Mguni* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 高阶元学习, 深度学习, 虚拟任务, 范畴论, 泛化

**Comment:** 

> **TL;DR:** 本文提出了一种新的高阶元学习框架，通过生成虚拟任务来训练神经网络，使其能够自主构建、解决和泛化跨层级任务，并利用范畴论提供理论解释和设计原则。

**AI_Comments:** 本文的创新之处在于提出了一个高阶深度元学习框架，通过引入“虚拟任务”生成机制，使模型能够自主生成训练数据，从而突破了传统机器学习对人工数据的依赖。结合范畴论的解释，不仅为元学习提供了坚实的理论基础和统一视角，也为设计更具泛化能力和可解释性的智能系统提供了新的思路。这种自主生成任务并学习的能力，对于实现通用人工智能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器学习训练严重依赖人类生成的数据，存在局限性。本文旨在解决这一问题，使神经网络能够自主生成信息丰富的任务数据集，从而实现更强的泛化能力。

**Method:** 本文引入了一个新的分层深度学习框架，用于递归高阶元学习。核心是一个生成机制，创建“虚拟任务”——合成问题实例，以使元学习器学习软约束和可泛化的规则。通过主动探索虚拟点景观并寻找低级学习器难以解决的任务，元学习器迭代地优化约束区域。此外，该方法将元学习器解释为范畴论中的“函子”，从而建立了支持抽象和知识迁移的组合结构。

**Result:** 该框架能够生成自己的信息丰富的、以任务为基础的数据集，从而摆脱对人类生成数据的完全依赖。它增强了归纳偏差，规范了适应过程，并产生了泛化所需的新的、意想不到的任务和约束。元学习器作为函子，统一了现有元学习模型，并揭示了学习过程如何通过函子关系进行转换和比较。

**Conclusion:** 本文提出的高阶深度元学习架构可能支撑下一代神经网络，使其能够自主生成新颖的、有指导意义的任务及其解决方案，从而推动机器学习迈向通用人工智能。

> **ai_Abstract:** 本文提出了一种新的高阶深度元学习框架，旨在通过生成“虚拟任务”来克服传统机器学习对人类生成数据的依赖。该框架允许神经网络自主创建、解决和泛化跨层级任务，通过迭代优化约束区域来增强归纳偏置并产生新颖任务。此外，通过将元学习器解释为范畴论中的函子，该工作为元学习提供了一个统一的理论视角和组合结构，有助于知识迁移和理解学习过程，并有望推动通用人工智能的发展。

> **摘要翻译:** 我们引入了一个新的分层深度学习框架，用于递归高阶元学习，使神经网络（NNs）能够构建、解决和泛化跨任务层级。这种方法的核心是一个生成机制，它创建“虚拟任务”——旨在使元学习器学习相关任务中的“软约束”和未知可泛化规则的合成问题实例。至关重要的是，这使得该框架能够生成自己的信息丰富的、以任务为基础的数据集，从而使机器学习（ML）训练摆脱了完全依赖人类生成数据的限制。通过主动探索虚拟点景观并寻找低级学习器难以解决的任务，元学习器迭代地优化约束区域。这增强了归纳偏差，规范了适应过程，并产生了泛化所需的新的、意想不到的任务和约束。层级中的每个元级别都对应于对较低级别解决的问题的逐步抽象泛化，从而实现了结构化和可解释的学习进展。通过将元学习器解释为生成和条件化从属学习器层级的范畴论“函子”，我们建立了一个组合结构，支持跨逐步泛化任务的抽象和知识迁移。范畴论的视角统一了现有的元学习模型，并揭示了学习过程如何通过函子关系进行转换和比较，同时为元学习的结构化提供了实用的设计原则。我们推测这种架构可能支撑下一代神经网络，使其能够自主生成新颖的、有指导意义的任务及其解决方案，从而推动机器学习迈向通用人工智能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [373] [On Efficient Bayesian Exploration in Model-Based Reinforcement Learning](https://arxiv.org/abs/2507.02639)
> *关于模型强化学习中高效贝叶斯探索的研究*

*Alberto Caron, Chris Hicks, Vasilios Mavroudis* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 强化学习, 贝叶斯探索, 信息增益, 认知不确定性, PTS-BE

**Comment:** 

> **TL;DR:** 该研究关注强化学习中数据高效探索的挑战，提出了一种基于信息论的探索奖励方法，并提出了PTS-BE框架，在稀疏奖励和探索任务中表现优异。

**AI_Comments:** 本文的创新之处在于为基于信息增益的探索方法提供了严格的理论保证，填补了此前理论基础的空白。同时，通过提出PTS-BE框架并结合实际可用的近似方法，极大地提升了这类探索策略的实用性。在数据高效探索，特别是稀疏奖励和纯探索任务中的显著性能提升，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决强化学习中数据高效探索的挑战，特别是现有信息论方法在理论基础上的不足，并使其更具实用性。

**Method:** 研究了针对认知不确定性的探索奖励，证明其能自然地表示认知信息增益并收敛。通过稀疏变分高斯过程、深度核和深度集成模型实现了可处理的近似。提出了预测轨迹采样与贝叶斯探索（PTS-BE）通用框架，将基于模型的规划与信息论奖励结合。

**Result:** 证明了所研究的奖励能自然地表示认知信息增益，并在智能体对环境动态和奖励足够确定后收敛。PTS-BE在多种稀疏奖励和/或纯探索任务环境中，显著优于其他基线方法。

**Conclusion:** 本研究为基于信息增益的探索方法提供了正式的理论保证，并提出了一个实用的框架PTS-BE，有效解决了强化学习中的数据高效探索问题。

> **ai_Abstract:** 本研究旨在解决强化学习中数据高效探索的挑战。通过分析基于认知不确定性的信息论探索奖励，作者证明了这些奖励能有效指示知识增益并最终收敛。为实现实用性，论文探讨了可处理的近似方法，并提出了一个名为PTS-BE的通用框架，该框架结合了模型规划和信息论奖励，实现了样本高效的深度探索。实验结果表明，PTS-BE在稀疏奖励和探索性任务中表现出色。

> **摘要翻译:** 在这项工作中，我们通过审视现有的基于原则、信息论的内在激励方法，来解决强化学习中数据高效探索的挑战。具体来说，我们专注于一类针对认知不确定性而非环境中固有随机噪声的探索奖励。我们证明这些奖励自然地表明了认知信息增益，并在智能体对环境动态和奖励足够确定后收敛到零，从而使探索与真正的知识差距对齐。我们的分析为以前缺乏理论基础的基于信息增益（IG）的方法提供了正式的保证。为了实现实际应用，我们还讨论了通过稀疏变分高斯过程、深度核和深度集成模型实现的可处理近似。然后，我们概述了一个通用框架——预测轨迹采样与贝叶斯探索（PTS-BE）——它将基于模型的规划与信息论奖励相结合，以实现样本高效的深度探索。我们凭经验证明，PTS-BE在各种以稀疏奖励和/或纯探索任务为特征的环境中，显著优于其他基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [374] [ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning](https://arxiv.org/abs/2507.02834)
> *ExPO：通过自我解释引导的强化学习解锁困难推理*

*Ruiyang Zhou, Shuozhe Li, Amy Zhang, Liu Leqi* | **Category: cs.LG, cs.CL** | **Updated: {updated}**

**Keywords:** 强化学习, 大语言模型, 推理, 自我解释, 策略优化

**Comment:** 

> **TL;DR:** ExPO是一种新的强化学习框架，通过生成高质量、策略对齐的自我解释样本来解决现有RL方法在困难推理任务中缺乏正样本的问题，从而提高学习效率和性能。

**AI_Comments:** ExPO的创新点在于其通过“自我解释引导”的方式生成高质量的正样本，从而有效解决了强化学习在探索困难推理任务空间时面临的样本稀缺问题。它打破了传统方法对模型初始能力的过度依赖，并通过引导模型生成与策略更一致的推理轨迹来提高学习效率和最终性能。这项工作对于提升大型语言模型在复杂推理任务上的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的强化学习（RL）后训练方法在处理困难推理任务时存在局限性，尤其是在模型初始能力较弱或正样本难以生成的情况下。这些方法主要依赖于模型已有知识的提炼，而非探索新的推理路径以解决模型最初失败的问题。专家演示也常常无效。

**Method:** 本文提出了Self-Explanation Policy Optimization (ExPO) 框架。ExPO通过以真实答案为条件来生成正样本，这些样本具有两个关键特性：(1) 在当前策略下可能性较高，(2) 增加模型预测正确答案的可能性。这使得模型能够高效探索，并生成比专家编写的思维链更符合其策略的推理轨迹，同时确保比其自身（不正确）样本更高的质量。

**Result:** 实验表明，ExPO在推理基准测试上显著提高了学习效率和最终性能。在MATH level-5等模型最初表现不佳的挑战性设置中，ExPO超越了基于专家演示的方法。

**Conclusion:** ExPO通过生成高质量、策略对齐的自我解释样本，有效解决了强化学习在困难推理任务中探索不足和正样本稀缺的问题，从而显著提升了模型的推理能力和学习效率。

> **ai_Abstract:** ExPO是一种新颖的强化学习框架，旨在解决现有RL方法在处理困难推理任务时正样本稀缺和探索不足的问题。它通过以真实答案为条件生成高质量的自我解释样本，这些样本既符合当前策略又有助于提高正确预测的概率。实验证明，ExPO在学习效率和性能上均优于传统方法，尤其在MATH level-5等高难度推理任务中表现出色，成功解锁了模型在这些设置下的推理能力。

> **摘要翻译:** 大型语言模型最近的进展得益于强化学习（RL）风格的后训练，这种训练通过基于奖励或偏好信号优化模型输出来提高推理能力。GRPO风格的方法通过使用由基于结果的验证器标记的自生成样本来实现这一点。然而，这些方法严重依赖于模型生成正样本的初始能力。它们主要提炼模型已知的内容（分布锐化），而不是使模型能够解决其最初失败的问题。这种局限性在RL训练早期阶段和具有挑战性的推理任务中尤其突出，因为正样本不太可能生成。为了在这种环境下解锁推理能力，模型必须探索超出其当前输出分布的新推理轨迹。这种探索需要访问足够好的正样本来指导学习。虽然专家演示似乎是一个自然的解决方案，但我们发现它们在RL后训练中通常无效。相反，我们确定了有效正样本的两个关键特性：它们应该（1）在当前策略下是可能的，并且（2）增加模型预测正确答案的可能性。基于这些见解，我们提出了$\textbf{自我解释策略优化（ExPO）}$-一个简单且模块化的框架，通过以真实答案为条件来生成此类样本。ExPO实现了高效探索，并引导模型生成比专家编写的思维链更符合其策略的推理轨迹，同时确保比其自身（不正确）样本更高的质量。实验表明，ExPO提高了推理基准测试的学习效率和最终性能，在MATH level-5等模型最初最挣扎的挑战性设置中超越了基于专家演示的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [376] [Fair Deepfake Detectors Can Generalize](https://arxiv.org/abs/2507.02645)
> *公平的深度伪造检测器可以泛化*

*Harry Cheng, Ming-Hui Liu, Yangyang Guo, Tianyi Wang, Liqiang Nie, Mohan Kankanhalli* | **Category: cs.LG, cs.CV** | **Updated: {updated}**

**Keywords:** 深度伪造检测, 公平性, 泛化性, 因果关系, DAID

**Comment:** 14 pages, version 1

> **TL;DR:** 现有深度伪造检测器在泛化性和公平性之间存在冲突，本文首次发现并定义了公平性与泛化性之间的因果关系，并提出DAID框架，通过数据再平衡和特征聚合，在公平性和泛化性上均优于现有SOTA方法。

**AI_Comments:** 这篇论文的创新点在于首次揭示并形式化定义了公平性与泛化性之间的因果关系，打破了传统认为两者相互冲突的观念。提出的DAID框架是一个实用的即插即用解决方案，通过数据和特征层面的干预，有效提升了深度伪造检测器的公平性和泛化能力，对提升AI模型的可靠性和社会公平性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造检测模型面临两大挑战：对未知操纵的泛化能力和不同人群间的公平性。现有方法常认为这两个目标相互冲突，存在权衡。本文旨在解决这一冲突，并首次揭示公平性与泛化性之间的因果关系。

**Method:** 本文首次揭示并形式化定义了公平性与泛化性之间的因果关系，并基于后门调整（back-door adjustment）表明通过控制混杂因素（数据分布和模型容量）可以通过公平性干预来改善泛化。受此启发，提出了一种即插即用的框架DAID（Demographic Attribute-insensitive Intervention Detection），其包含两部分：i) 人口统计学感知数据再平衡，采用逆倾向加权和亚组特征归一化来中和分布偏差；ii) 人口统计学无关特征聚合，使用新颖的对齐损失来抑制敏感属性信号。

**Result:** 在三个跨域基准测试中，DAID在公平性和泛化性方面均始终优于几种最先进的检测器。

**Conclusion:** DAID不仅验证了其理论基础，也证明了其在实践中的有效性。通过控制混杂因素，公平性干预可以改善泛化能力。

> **ai_Abstract:** 本文针对深度伪造检测中泛化能力和人口统计学公平性之间的权衡问题，首次揭示并形式化定义了公平性与泛化性之间的因果关系。基于此，提出了一种即插即用的DAID框架。DAID通过人口统计学感知数据再平衡和人口统计学无关特征聚合，有效中和了分布偏差并抑制了敏感属性信号。实验结果表明，DAID在多个跨域基准测试中，在公平性和泛化性方面均显著优于现有最先进的检测器，验证了其理论和实践有效性。

> **摘要翻译:** 深度伪造检测模型面临两个关键挑战：对未知操纵的泛化能力以及不同人群间的偏见公平性。然而，现有方法通常表明这两个目标本质上是冲突的，揭示了它们之间的权衡。在本文中，我们首次揭示并正式定义了公平性与泛化性之间的因果关系。基于后门调整，我们表明控制混杂因素（数据分布和模型容量）可以通过公平性干预来改善泛化。受此启发，我们提出了人口统计属性不敏感干预检测（DAID），这是一个即插即用框架，由以下部分组成：i) 人口统计学感知数据再平衡，它采用逆倾向加权和亚组特征归一化来中和分布偏差；ii) 人口统计学无关特征聚合，它使用一种新颖的对齐损失来抑制敏感属性信号。在三个跨域基准测试中，DAID在公平性和泛化性方面均始终优于几种最先进的检测器，验证了其理论基础和实际有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [380] [Guided Generation for Developable Antibodies](https://arxiv.org/abs/2507.02670)
> *可开发抗体的引导式生成*

*Siqi Zhao, Joshua Moller, Porfi Quintero-Cadena, Lood van Niekerk* | **Category: cs.LG, q-bio.BM** | **Updated: {updated}**

**Keywords:** 可开发性抗体, 引导式生成, 扩散模型, 机器学习, 抗体设计

**Comment:** Published in ICML 2025 GenBio Workshop

> **TL;DR:** 该论文引入了一种引导式离散扩散模型，用于设计具有良好可生产性、稳定性和安全性的治疗性抗体，并在预测可开发性分数方面取得了显著提升。

**AI_Comments:** 该论文的创新之处在于将引导式离散扩散模型与SVDD模块相结合，从而在抗体生成过程中明确地偏向于具有良好可开发性的候选物，而不仅仅是关注亲和力。这种方法有望显著加速药物发现过程，通过在计算层面进行预筛选，提高抗体设计的效率和成功率。

<details>
  <summary>Details</summary>

**Motivation:** 治疗性抗体不仅需要高亲和力靶点结合，还需要良好的可生产性、稳定性及安全性，这些统称为“可开发性”。为了实现一个计算框架来优化抗体序列以获得有利的可开发性，本研究旨在解决现有计算方法在优化抗体序列以满足这些临床有效性要求方面的不足。

**Method:** 本文引入了一个引导式离散扩散模型，该模型在来自“观察到的抗体空间”（OAS）的天然配对重链和轻链序列以及246个临床阶段抗体的定量可开发性测量数据上进行训练。为了引导生成生物物理学上可行的候选物，模型整合了一个基于软值解码的扩散（SVDD）模块，该模块在不损害自然性的情况下偏置采样。

**Result:** 在无约束采样中，我们的模型再现了天然抗体库和已批准治疗药物的全局特征。在SVDD引导下，与无引导基线相比，我们在预测可开发性分数方面取得了显著的富集。当与高通量可开发性检测结合时，该框架能够实现一个迭代的、机器学习驱动的管道，用于设计同时满足结合和生物物理标准的抗体。

**Conclusion:** 本研究提出的引导式生成框架，结合高通量可开发性检测，能够实现一个迭代的、机器学习驱动的管道，用于设计同时满足结合和生物物理标准的抗体，从而加速治疗性抗体的开发。

> **ai_Abstract:** 该论文提出了一种创新的引导式离散扩散模型，旨在优化治疗性抗体的“可开发性”（包括可生产性、稳定性和安全性）。该模型利用天然抗体序列和临床阶段抗体的定量测量数据进行训练，并通过集成的SVDD模块引导生成生物物理学上更优的抗体候选物。实验结果表明，该模型在预测可开发性分数方面显著优于无引导基线，并能与高通量检测结合，形成一个迭代的、机器学习驱动的抗体设计流程，从而加速满足结合和生物物理标准的抗体开发。

> **摘要翻译:** 治疗性抗体不仅需要高亲和力的靶点结合，还需要良好的可生产性、稳定性以及临床有效性的安全性。这些特性统称为“可开发性”。为了实现一个优化抗体序列以获得有利可开发性的计算框架，我们引入了一个引导式离散扩散模型，该模型在来自“观察到的抗体空间”（OAS）的天然配对重链和轻链序列以及246个临床阶段抗体的定量可开发性测量数据上进行训练。为了引导生成生物物理学上可行的候选物，我们整合了一个基于软值解码的扩散（SVDD）模块，该模块在不损害自然性的情况下偏置采样。在无约束采样中，我们的模型再现了天然抗体库和已批准治疗药物的全局特征，并且在SVDD引导下，与无引导基线相比，我们在预测可开发性分数方面取得了显著的富集。当与高通量可开发性检测结合时，该框架能够实现一个迭代的、机器学习驱动的管道，用于设计同时满足结合和生物物理标准的抗体。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [382] [Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions](https://arxiv.org/abs/2507.02698)
> *供应链中动态定价的多智能体强化学习：在真实模拟市场条件下对策略智能体行为进行基准测试*

*Thomas Hazenberg, Yao Ma, Seyed Sahand Mohammadi Ziabari, Marijn van Rijswijk* | **Category: cs.LG, econ.EM** | **Updated: {updated}**

**Keywords:** 多智能体强化学习, 动态定价, 供应链, 战略行为, 市场模拟

**Comment:** 

> **TL;DR:** 本研究评估了多智能体强化学习（MARL）在供应链动态定价中的表现，并发现MARL能够引入静态规则无法捕捉的新兴战略行为。

**AI_Comments:** 本文的创新点在于将多智能体强化学习应用于供应链动态定价，并首次在考虑真实市场条件和多智能体互动下对不同MARL算法进行基准测试。其重要性在于揭示了MARL在复杂市场环境中捕捉和生成战略行为的潜力，为突破传统静态定价的局限性提供了新的视角。研究结果为未来动态定价系统的发展提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 传统ERP系统依赖静态、基于规则的方法进行定价，忽略了市场参与者之间的战略互动。现有强化学习在定价中的应用大多是单智能体，未能模拟真实供应链的相互依赖性。

**Method:** 本研究通过评估三种MARL算法（MADDPG、MADQN和QMIX）与静态规则基线在模拟环境中的表现。该模拟环境基于真实的电子商务交易数据和LightGBM需求预测模型。

**Result:** 基于规则的智能体实现了接近完美的公平性（Jain指数：0.9896）和最高的定价稳定性（波动性：0.024），但缺乏竞争动态。MARL智能体中，MADQN表现出最具侵略性的定价行为，波动性最高，公平性最低（0.5844）。MADDPG提供了一种更平衡的方法，支持市场竞争（份额波动：9.5 pp），同时保持相对较高的公平性（0.8819）和稳定的定价。

**Conclusion:** 研究结果表明，MARL引入了静态定价规则无法捕捉的新兴战略行为，并可能为动态定价的未来发展提供信息。

> **ai_Abstract:** 本研究探讨了多智能体强化学习（MARL）在供应链动态定价中的应用，以解决传统静态规则定价无法捕捉市场战略互动的问题。通过在基于真实数据的模拟环境中比较MADDPG、MADQN、QMIX等MARL算法与静态规则基线，研究发现MARL能够引入新兴的战略行为。其中，MADDPG在支持市场竞争、保持公平性和定价稳定性方面表现出较好的平衡。

> **摘要翻译:** 本研究探讨了多智能体强化学习（MARL）如何改善供应链中的动态定价策略，特别是在传统ERP系统依赖静态、基于规则的方法而忽略市场参与者之间战略互动的背景下。尽管最近的研究已将强化学习应用于定价，但大多数实现仍是单智能体，未能模拟真实世界供应链的相互依赖性。本研究通过在基于真实电子商务交易数据和LightGBM需求预测模型构建的模拟环境中，评估三种MARL算法（MADDPG、MADQN和QMIX）与静态规则基线的性能来解决这一空白。结果显示，基于规则的智能体实现了接近完美的公平性（Jain指数：0.9896）和最高的定价稳定性（波动性：0.024），但它们完全缺乏竞争动态。在MARL智能体中，MADQN表现出最具侵略性的定价行为，波动性最高，公平性最低（0.5844）。MADDPG提供了一种更平衡的方法，支持市场竞争（份额波动：9.5 pp），同时保持相对较高的公平性（0.8819）和稳定的定价。这些发现表明，MARL引入了静态定价规则无法捕捉的新兴战略行为，并可能为动态定价的未来发展提供信息。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [Fluid Democracy in Federated Data Aggregation](https://arxiv.org/abs/2507.02710)
> *联邦数据聚合中的流动民主*

*Aditya Vema Reddy Kesari, Krishna Reddy Kesari* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 联邦学习, 流动民主, 数据聚合, 共识协议, 对抗性鲁棒性

**Comment:** ICML 2025 Workshop on Collaborative and Federated Agentic Workflows

> **TL;DR:** 提出一种新的联邦学习协议FedVRD，通过共识机制选择最有用的客户端权重，以减少数据传输成本并提高对抗性鲁棒性，优于传统FedAvg。

**AI_Comments:** 这篇论文通过引入“流动民主”的概念到联邦学习中，提供了一种新颖的方法来优化数据传输效率和增强系统鲁棒性。其创新点在于将共识机制应用于客户端选择，并设计了能防止影响力累积的“粘性保留民主”协议，以及对抗性鲁棒的FedVRD算法。这对于降低联邦学习的运营成本和提高其在恶意环境下的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的联邦学习机制通常要求所有客户端将其权重传输到中央服务器，无论这些权重是否有用，导致了浪费的数据传输成本。

**Method:** 首先，从性能角度探讨了现有流动民主协议在联邦学习中的应用，并与传统的一人一票（FedAvg）进行比较。其次，提出了一种名为“粘性保留民主”（viscous-retained democracy）的新型流动民主协议，该协议在相同假设下优于FedAvg，并且不允许影响力累积。最后，针对流动民主协议的对抗性弱点，提出了一种算法FedVRD，通过利用委托拓扑动态限制对抗者的影响并最小化成本。

**Result:** 提出的“粘性保留民主”协议在性能上优于传统的一人一票（FedAvg），并且能够防止影响力累积。FedVRD算法能够动态限制对抗者的影响，同时最小化成本。

**Conclusion:** 本文通过引入基于共识的协议来选择最有用的客户端，有效解决了联邦学习中因不必要的数据传输而产生的成本浪费问题。提出的“粘性保留民主”协议和FedVRD算法不仅提高了系统效率，还增强了其在对抗性环境下的鲁棒性。

> **ai_Abstract:** 本文针对联邦学习中客户端权重传输效率低和成本高的问题，提出了一种基于共识的协议来选择最有用的客户端。研究首先评估了现有流动民主协议在联邦学习中的应用，并在此基础上提出了一种新的“粘性保留民主”协议，该协议在性能上优于传统FedAvg，并能有效防止影响力累积。此外，为应对流动民主协议在对抗性环境下的弱点，文章还提出了一种名为FedVRD的算法，该算法通过利用委托拓扑，动态限制对抗者的影响并最小化系统成本。

> **摘要翻译:** 联邦数据聚合中的流动民主

联邦学习（FL）机制通常要求每个客户端将其权重传输到中央服务器，无论这些权重是否有用。为了避免客户端到中央服务器的数据传输成本浪费，我们建议在每个数据传输步骤中使用基于共识的协议来识别具有最有用的模型权重的一部分客户端。首先，我们从性能角度探讨了现有流动民主协议在联邦学习中的应用，并将其与传统的一人一票（也称为1p1v或FedAvg）进行比较。我们提出了一种名为“粘性保留民主”的新型流动民主协议，该协议在与现有流动民主协议相同的假设下始终优于1p1v，同时也不允许影响力累积。其次，我们从对抗性角度识别了流动民主协议的弱点，即它们对拓扑和/或所需对抗者数量的依赖性，这些因素可能对全局模型权重产生负面影响。为此，我们提出了一种算法（FedVRD），该算法通过利用委托拓扑动态限制对抗者的影响，同时最小化成本。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [386] [A Forget-and-Grow Strategy for Deep Reinforcement Learning Scaling in Continuous Control](https://arxiv.org/abs/2507.02712)
> *一种用于连续控制中深度强化学习扩展的遗忘与成长策略*

*Zilin Kang, Chenyuan Hu, Yu Luo, Zhecheng Yuan, Ruijie Zheng, Huazhe Xu* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 深度强化学习, 连续控制, 先验偏差, 经验重放, 网络扩展

**Comment:** 

> **TL;DR:** 受神经科学启发，本文提出了一种名为FoG的深度强化学习算法，通过遗忘早期经验和扩展网络容量来解决连续控制中深度强化学习的先验偏差问题，并在多个基准测试中取得了优异性能。

**AI_Comments:** 该论文的创新点在于将神经科学中的“遗忘与成长”机制引入深度强化学习，以解决困扰RL的先验偏差问题。通过模拟人类记忆的动态特性，FoG算法在提高样本效率和泛化能力方面取得了显著成效，为深度RL的扩展提供了新的视角和有效策略。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度强化学习方法在连续控制中存在“先验偏差”问题，即对重放缓冲区中早期经验过拟合，这限制了RL智能体的样本效率和泛化能力。受人类婴儿期健忘症的启发，本文旨在通过引入遗忘和成长机制来解决这一问题。

**Method:** 本文提出了一种名为“遗忘与成长（FoG）”的深度强化学习算法，包含两种机制：1. 经验重放衰减（ER Decay），通过逐渐降低早期经验的影响来“遗忘早期经验”，平衡记忆。2. 网络扩展，通过在训练期间动态添加新参数来“增长神经容量”，增强智能体利用现有数据模式的能力。

**Result:** 在四个主要的连续控制基准测试（包含40多个任务）中，FoG算法表现出优于现有最先进深度强化学习算法（包括BRO、SimBa和TD-MPC2）的性能。

**Conclusion:** FoG算法通过引入受神经科学启发的遗忘和成长机制，有效解决了深度强化学习中先验偏差的问题，显著提升了连续控制任务中的样本效率和泛化能力。

> **ai_Abstract:** 本文提出了一种名为“遗忘与成长（FoG）”的新型深度强化学习算法，旨在解决连续控制中深度强化学习面临的先验偏差问题。受神经科学中遗忘和成长过程的启发，FoG引入了经验重放衰减（ER Decay）来减少早期经验的影响，以及网络扩展来动态增加神经网络容量。实验结果表明，FoG在多个连续控制基准测试中表现优于现有最先进的算法。

> **摘要翻译:** 深度强化学习在连续控制方面最近取得了令人瞩目的进展。然而，现有方法常常遭受先验偏差的困扰，即过度拟合重放缓冲区中存储的早期经验的倾向，这限制了RL智能体的样本效率和泛化能力。相比之下，人类较少受到这种偏差的影响，部分原因是婴儿期健忘症，其中新神经元的形成会破坏早期记忆痕迹，导致初始经验的遗忘。受神经科学中这种遗忘和成长双重过程的启发，本文提出了“遗忘与成长（FoG）”，一种引入了两种机制的新型深度强化学习算法。首先，经验重放衰减（ER Decay）“遗忘早期经验”，通过逐渐降低早期经验的影响来平衡记忆。其次，网络扩展，“增长神经容量”，通过在训练期间动态添加新参数来增强智能体利用现有数据模式的能力。在四个主要连续控制基准测试（包含40多个任务）中的实证结果表明，FoG相对于现有最先进的深度强化学习算法（包括BRO、SimBa和TD-MPC2）具有卓越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [388] [A Comprehensive Machine Learning Framework for Micromobility Demand Prediction](https://arxiv.org/abs/2507.02715)
> *微出行需求预测的综合机器学习框架*

*Omri Porat, Michael Fire, Eran Ben-Elia* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 微出行需求预测, 机器学习, 空间-时间分析, 网络依赖性, 车队管理

**Comment:** 

> **TL;DR:** 本研究提出了一个综合机器学习框架，用于预测微出行需求，通过整合空间、时间和网络依赖性，将预测精度提高了27%至49%，从而支持数据驱动的微出行管理。

**AI_Comments:** 该论文的创新之处在于其提出的综合机器学习框架，该框架首次将空间、时间及网络依赖性整合起来进行微出行需求预测。这种整合不仅显著提高了预测精度，也为理解复杂的城市微出行模式提供了更深入的洞察。其重要性在于为城市管理者提供了更有效的数据驱动工具，以优化微出行服务的运营和规划，从而促进城市的可持续发展。

<details>
  <summary>Details</summary>

**Motivation:** 有效的微出行服务管理依赖于准确的需求预测，这对于优化车队分布和基础设施规划至关重要。现有研究多独立分析空间或时间因素，而缺乏整合这些因素的框架。

**Method:** 本研究引入了一个新的框架，该框架整合了空间、时间以及网络依赖性，以改进微出行需求预测。此框架通过机器学习方法实现。

**Result:** 该框架将需求预测精度比基线模型提高了27%至49%，有效捕捉了微出行需求模式。

**Conclusion:** 本研究的发现支持数据驱动的微出行管理，能够优化车队分布，降低成本，并促进可持续的城市规划。

> **ai_Abstract:** 本论文提出了一个综合机器学习框架，旨在提高微出行需求预测的准确性。该框架通过整合空间、时间及网络依赖性，解决了现有研究中孤立分析空间或时间因素的局限性。实验结果表明，该框架将需求预测精度比基线模型提高了27%至49%，为优化车队分布、降低成本和支持可持续城市规划提供了数据驱动的解决方案。

> **摘要翻译:** 无桩电动滑板车作为一种关键的微出行服务，已成为环保、灵活的城市交通替代方案。这些服务改善了首公里和末公里连接，减少了交通拥堵和排放，并补充了公共交通的短途出行。然而，这些服务的有效管理取决于准确的需求预测，这对于最佳车队分布和基础设施规划至关重要。虽然以往的研究侧重于孤立地分析空间或时间因素，但本研究引入了一个整合空间、时间及网络依赖性的框架，以提高微出行需求预测的准确性。这种整合在提高准确性的同时，也为城市微出行使用模式提供了更深入的见解。我们的框架将需求预测精度比基线模型提高了27%至49%，证明了其在捕捉微出行需求模式方面的有效性。这些发现支持数据驱动的微出行管理，从而实现优化的车队分布、成本降低和可持续的城市规划。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [390] [Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms](https://arxiv.org/abs/2507.02724)
> *跨物种蛋白质相互作用预测的分层多标签对比学习*

*Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu* | **Category: cs.LG, q-bio.BM** | **Updated: {updated}**

**Keywords:** 蛋白质相互作用预测, 对比学习, 分层学习, 跨物种, 零样本迁移

**Comment:** 

> **TL;DR:** HIPPO是一种分层对比学习框架，用于跨物种蛋白质相互作用(PPI)预测。它通过多层生物表示匹配来对齐蛋白质序列及其分层属性，并使用分层对比损失函数和数据驱动的惩罚机制。HIPPO在基准数据集上取得了最先进的性能，并在低数据量情况下表现出鲁棒性，尤其在零样本迁移到其他物种方面表现出色。

**AI_Comments:** HIPPO的创新之处在于其将分层对比学习应用于蛋白质相互作用预测，有效地利用了蛋白质序列及其内在的层次结构信息。其关键优势在于强大的零样本迁移能力，这对于数据稀缺的物种尤其重要，极大地扩展了PPI预测的应用范围。通过强制学习到的嵌入空间与蛋白质功能层次结构保持一致，该模型不仅提高了预测准确性，还增强了模型的可解释性。这项工作为未来在多物种、低数据量生物信息学任务中的模型开发提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI方法在桥接异构生物数据模态方面展现了对比学习的潜力。本研究的动机是利用这一范式，开发一个更有效、更鲁棒的蛋白质相互作用预测框架，特别是要解决跨物种预测以及在数据稀疏或不平衡情况下的挑战。

**Method:** 本文提出了HIPPO（HIerarchical Protein-Protein interaction prediction across Organisms），一个分层对比框架用于蛋白质-蛋白质相互作用（PPI）预测。该方法通过多层生物表示匹配来对齐蛋白质序列及其分层属性。它整合了模拟蛋白质功能类别结构关系的分层对比损失函数，并通过数据驱动的惩罚机制自适应地纳入领域和家族知识，以强制学习到的嵌入空间与蛋白质功能的内在层次结构之间的一致性。

**Result:** HIPPO在基准数据集上取得了最先进的性能，优于现有方法，并在低数据量情况下表现出鲁棒性。值得注意的是，该模型无需重新训练即可对其他物种表现出强大的零样本迁移能力，即使在实验数据有限的特征较少或稀有生物中也能实现可靠的PPI预测和功能推断。进一步分析表明，分层特征融合对于捕获保守的相互作用决定因素（如结合基序和功能注释）至关重要。

**Conclusion:** 本工作推动了跨物种PPI预测的进展，并为在稀疏或不平衡多物种数据场景中进行相互作用预测提供了一个统一的框架。

> **ai_Abstract:** 本文提出了一种名为HIPPO的分层多标签对比学习框架，用于跨物种蛋白质相互作用（PPI）预测。HIPPO通过多层生物表示匹配对齐蛋白质序列及其分层属性，并采用分层对比损失和数据驱动惩罚机制来整合蛋白质功能的层次结构。实验结果表明，HIPPO在多个基准数据集上达到了最先进的性能，在低数据量和零样本跨物种迁移方面表现出色，为在数据稀疏或不平衡场景下的PPI预测提供了一个统一且鲁棒的解决方案。

> **摘要翻译:** 科学AI的最新进展突出了对比学习在桥接异构生物数据模态方面的强大能力。在此范式基础上，我们提出了HIPPO（HIerarchical Protein-Protein interaction prediction across Organisms），一个用于蛋白质-蛋白质相互作用（PPI）预测的分层对比框架，其中蛋白质序列及其分层属性通过多层生物表示匹配进行对齐。所提出的方法结合了分层对比损失函数，模拟蛋白质功能类别之间的结构化关系。该框架通过数据驱动的惩罚机制自适应地整合领域和家族知识，强制学习到的嵌入空间与蛋白质功能的内在层次结构之间的一致性。在基准数据集上的实验表明，HIPPO取得了最先进的性能，优于现有方法，并在低数据量情况下表现出鲁棒性。值得注意的是，该模型无需重新训练即可对其他物种表现出强大的零样本迁移能力，即使在实验数据有限的特征较少或稀有生物中也能实现可靠的PPI预测和功能推断。进一步分析表明，分层特征融合对于捕获保守的相互作用决定因素（如结合基序和功能注释）至关重要。这项工作推动了跨物种PPI预测的进展，并为在稀疏或不平衡多物种数据场景中进行相互作用预测提供了一个统一的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [393] [Fast and Simplex: 2-Simplicial Attention in Triton](https://arxiv.org/abs/2507.02754)
> *快速与单纯：Triton 中的 2-单纯注意力*

*Aurko Roy, Timothy Chou, Sai Surya Duvvuri, Sijia Chen, Jiecao Yu, Xiaodong Wang, Manzil Zaheer, Rohan Anil* | **Category: cs.LG, cs.AI** | **Updated: {updated}**

**Keywords:** 2-单纯注意力, token 效率, 扩展定律, Transformer, Triton

**Comment:** 10 pages, with appendix 25 pages

> **TL;DR:** 本文介绍了在 Triton 中实现的 2-单纯注意力机制，相比标准 Transformer，它在固定 token 预算下能提高 token 效率，并在数学、编码、推理和逻辑任务上表现更优，尤其适用于数据量非无限的场景。

**AI_Comments:** 本文的创新之处在于将注意力机制推广到三线性函数（即 2-单纯注意力），并提供了高效的 Triton 实现。这对于解决日益增长的数据受限型 LLM 训练挑战以及提高 token 效率（特别是对于推理任务）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大语言模型的扩展定律假设数据无限且计算受限，但这对于依赖大规模互联网数据集的现代大模型而言越来越不适用。这种转变突出了对优先考虑 token 效率的架构的需求。

**Method:** 本文研究了 2-单纯 Transformer，它通过高效的 Triton 内核实现，将标准点积注意力推广到三线性函数。

**Result:** 2-单纯 Transformer 实现了比标准 Transformer 更好的 token 效率：在固定的 token 预算下，类似大小的模型在涉及数学、编码、推理和逻辑的任务上优于其点积对应物。本文通过证明 2-单纯注意力改变了知识和推理任务的缩放定律中的指数，从而量化了这些增益。

**Conclusion:** 2-单纯 Transformer，通过其 Triton 实现，在 token 效率和特定任务（如数学、编码、推理和逻辑）的性能上，比传统 Transformer 提供了显著的改进，尤其是在计算受限假设不成立的情况下。

> **ai_Abstract:** 针对当前大语言模型扩展定律中数据无限和计算受限假设的局限性，本文提出了一种 2-单纯 Transformer 架构。该架构通过高效的 Triton 内核实现，将标准点积注意力推广到三线性函数。实验结果表明，在固定 token 预算下，2-单纯 Transformer 相比传统 Transformer 具有更高的 token 效率，并在数学、编码、推理和逻辑等任务上表现更优，通过改变这些任务的扩展定律指数来量化其性能提升。

> **摘要翻译:** 近期工作表明，训练损失与模型大小和 token 数量呈幂律关系，并且实现计算最优模型需要同时扩展模型大小和 token 数量。然而，这些扩展定律假设数据供应无限，并且主要适用于计算受限的环境。随着现代大型语言模型越来越依赖大规模的互联网数据集，它们是计算受限的假设变得越来越不成立。这种转变突出了对优先考虑 token 效率的架构的需求。
在这项工作中，我们研究了 2-单纯 Transformer 的使用，这是一种通过高效的 Triton 内核实现将标准点积注意力推广到三线性函数的架构。我们证明了 2-单纯 Transformer 实现了比标准 Transformer 更好的 token 效率：在固定的 token 预算下，类似大小的模型在涉及数学、编码、推理和逻辑的任务上优于其点积对应物。我们通过证明 2-单纯注意力改变了知识和推理任务的缩放定律中的指数，从而量化了这些增益，与点积注意力相比。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [395] [Contextual Online Pricing with (Biased) Offline Data](https://arxiv.org/abs/2507.02762)
> *基于有偏离线数据的上下文在线定价*

*Yixuan Zhang, Ruihao Zhu, Qiaomin Xie* | **Category: cs.LG, stat.ML** | **Updated: {updated}**

**Keywords:** 上下文在线定价, 有偏离线数据, 遗憾界, OFU策略, 随机线性强盗

**Comment:** 47 pages, 4 figures

> **TL;DR:** 本文研究了使用有偏离线数据的上下文在线定价问题，提出了OFU策略和广义OFU算法，获得了首个紧致的遗憾界，并证明了其在随机线性强盗问题中的可迁移性。

**AI_Comments:** 本文的创新点在于首次为存在有偏离线数据时的上下文在线定价提供了紧致的遗憾保证。其对统计复杂度的量化以及针对不同情况（包括偏差界未知）提出的OFU算法及其变体，具有重要的理论和实践意义。此外，其方法的可迁移性也增加了研究的价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文研究上下文在线定价问题，特别是在存在有偏离线数据的情况下，旨在解决如何在这种复杂数据条件下进行有效定价并量化其统计复杂性。

**Method:** 对于标量价格弹性情况，作者量化了离线数据与在线最优值之间的偏差，并提出了一种“不确定性乐观”（OFU）策略。对于一般价格弹性情况，提出了一种广义OFU算法。当偏差界未知时，设计了一种鲁棒变体。

**Result:** 在标量价格弹性情况下，OFU策略实现了极小化极大最优、依赖于实例的遗憾界$	ilde{\mathcal{O}}ig(d\sqrt{T} \wedge (V^2T + \frac{dT}{\lambda_{\min}(\hat{\Sigma}) + (N \wedge T) \delta^2})\big)$。对于一般价格弹性，建立了最坏情况下的极小化极大最优速率$	ilde{\mathcal{O}}\big(d\sqrt{T} \wedge (V^2T + \frac{dT }{\lambda_{\min}(\hat{\Sigma})})\big)$。当偏差界未知时，鲁棒变体能保证次线性遗憾，并在偏差较小时显著优于纯在线方法。这些结果首次为有偏离线数据下的上下文定价提供了紧致的遗憾保证。

**Conclusion:** 本文为存在有偏离线数据情况下的上下文定价提供了首个紧致的遗憾保证。所提出的技术也可以直接应用于有偏离线数据的随机线性强盗问题，并得出类似的界限。

> **ai_Abstract:** 本文研究了在存在有偏离线数据的上下文在线定价问题。针对标量和一般价格弹性情况，分别提出了OFU策略和广义OFU算法，并量化了离线数据、时间长度、偏差等因素对统计复杂度的影响。研究取得了首个紧致的极小化极大最优遗憾界，并在偏差界未知时提供了鲁棒性算法。此外，该方法还可应用于有偏离线数据的随机线性强盗问题。

> **摘要翻译:** 我们研究了有偏离线数据的上下文在线定价。对于标量价格弹性情况，我们确定了衡量离线数据与（未知）在线最优值之间距离的实例相关量$\delta^2$。我们表明，时间长度$T$、偏差界$V$、离线数据的大小$N$和离散度$\lambda_{\min}(\hat{\Sigma})$以及$\delta^2$共同决定了统计复杂性。一种“不确定性乐观”（OFU）策略实现了极小化极大最优、依赖于实例的遗憾界$\tilde{\mathcal{O}}\big(d\sqrt{T} \wedge (V^2T + \frac{dT}{\lambda_{\min}(\hat{\Sigma}) + (N \wedge T) \delta^2})\big)$。对于一般价格弹性，我们建立了最坏情况下的极小化极大最优速率$\tilde{\mathcal{O}}\big(d\sqrt{T} \wedge (V^2T + \frac{dT }{\lambda_{\min}(\hat{\Sigma})})\big)$，并提供了一个达到此速率的广义OFU算法。当偏差界$V$未知时，我们设计了一个鲁棒变体，它始终能保证次线性遗憾，并且在精确偏差较小时，它严格优于纯在线方法。这些结果首次为存在有偏离线数据的上下文定价提供了紧致的遗憾保证。我们的技术也完全适用于有偏离线数据的随机线性强盗问题，产生了类似的界限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [397] [Understanding and Improving Length Generalization in Recurrent Models](https://arxiv.org/abs/2507.02782)
> *深入理解并改进循环模型中的长度泛化能力*

*Ricardo Buitrago Ruiz, Albert Gu* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 循环模型, 长度泛化, 状态空间模型, 线性注意力

**Comment:** 

> **TL;DR:** 循环模型在训练长度之外的序列上表现不佳，本文通过分析并引入训练干预措施，显著提高了其长度泛化能力。

**AI_Comments:** 这项研究通过提出“未探索状态假设”并验证其对循环模型长度泛化能力的影响，提供了一个新的视角。其创新之处在于识别了训练状态覆盖不足的关键问题，并提出了高效的干预措施。仅用少量额外训练步骤就能实现显著的长度泛化提升，这对于实际应用中的长序列处理具有重要意义，展现了其高度的效率和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 循环模型（如状态空间模型和线性注意力）尽管原则上可以处理任意长序列，但在训练上下文长度之外，其性能会显著下降，即它们未能实现长度泛化。

**Method:** 本文提供了全面的实证和理论分析，支持“未探索状态假设”，即模型在训练期间仅接触到有限的可能状态分布子集时，无法进行长度泛化。此外，研究了旨在增加模型训练状态覆盖率的简单训练干预措施，例如用高斯噪声或不同输入序列的最终状态初始化状态。

**Result:** 仅通过500个训练后步骤（占预训练预算的约0.1%），这些干预措施使得模型能够对比训练上下文长几个数量级的序列（例如从2k到128k）进行长度泛化，并在长上下文任务中表现出改进的性能。

**Conclusion:** 本文提出了一种简单有效的方法，可以在通用循环模型中实现鲁棒的长度泛化。

> **ai_Abstract:** 本文深入探讨了循环模型在处理超出训练长度的序列时性能下降的问题，即长度泛化失败。通过实证和理论分析，研究支持“未探索状态假设”，认为训练时状态分布覆盖不足是主要原因。为解决此问题，研究引入了简单的训练干预措施，如状态初始化调整，结果表明这些方法能以极小的额外成本显著提高模型对长序列的泛化能力，并在长上下文任务中表现更优。

> **摘要翻译:** 最近，诸如状态空间模型和线性注意力之类的循环模型因其在序列长度上的线性复杂度而受到欢迎。由于其循环性质，它们原则上可以处理任意长的序列，但其性能有时在超出训练上下文长度后会显著下降——即它们未能进行长度泛化。在这项工作中，我们提供了全面的实证和理论分析，以支持未探索状态假设，该假设认为模型在训练期间仅暴露于所有可达状态（即如果将循环应用于长序列将达到的状态）分布的有限子集时，无法进行长度泛化。此外，我们研究了旨在增加模型训练状态覆盖率的简单训练干预措施，例如通过用高斯噪声或不同输入序列的最终状态初始化状态。仅通过500个训练后步骤（约占预训练预算的0.1%），这些干预措施使模型能够对比训练上下文长几个数量级的序列（例如2k→128k）进行长度泛化，并在长上下文任务中显示出改进的性能，从而提出了一种简单有效的方法，以实现在通用循环模型中鲁棒的长度泛化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [399] [In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization](https://arxiv.org/abs/2507.02807)
> *医疗保健领域基于约束优化的训练中多校准生存分析*

*Thiti Suttaket, Stanley Kok* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 生存分析, 多校准, 约束优化, 医疗保健, 机器学习

**Comment:** 

> **TL;DR:** 提出GRADUATE模型，通过约束优化在训练中实现多校准生存分析，解决现有模型在少数子群体上校准不佳的问题。

**AI_Comments:** 该论文的创新点在于将多校准问题建模为训练中的约束优化问题，从而解决了传统生存分析模型在少数子群体上校准不足的关键痛点。通过在训练阶段就考虑校准和判别能力的平衡，GRADUATE模型有望提高临床决策的准确性和公平性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有生存模型通常只在总体层面进行校准，可能导致在少数子群体上校准不良，从而引发错误的临床决策。

**Method:** 提出GRADUATE模型，将多校准问题框架为约束优化问题，并在训练中同时优化校准和判别能力以达到良好平衡。数学证明优化方法能以高概率得到近最优且可行的解。

**Result:** 在真实世界临床数据集上的经验比较表明GRADUATE模型优于现有最先进基线模型，并详细分析了基线模型的缺点和GRADUATE的优点。

**Conclusion:** GRADUATE模型通过在训练中应用约束优化实现多校准生存分析，有效解决了现有模型在子群体校准方面的不足，并在实际数据中表现出优越性。

> **ai_Abstract:** 本文提出GRADUATE模型，旨在解决医疗保健领域生存分析中现有模型在少数子群体校准不足的问题。GRADUATE将多校准视为一个约束优化问题，并在训练过程中同时优化模型的校准和判别能力，以确保所有子群体都能获得良好的校准。研究通过数学证明了其优化方法的有效性，并在真实临床数据集上通过实验验证了GRADUATE模型优于现有基线模型的性能。

> **摘要翻译:** 生存分析是医疗保健中的一个重要问题，因为它模拟了个体协变量与感兴趣事件（例如死亡）发生时间之间的关系。生存模型必须经过良好校准（即预测概率接近真实概率），因为校准不良的系统可能导致错误的临床决策。现有生存模型通常仅在总体层面进行校准，因此存在对一个或多个少数子群体校准不佳的风险。我们提出了一种名为GRADUATE的模型，通过确保所有子群体也得到良好校准来实现多校准。GRADUATE将多校准框定为一个约束优化问题，并在训练中同时优化校准和判别能力，以实现它们之间的良好平衡。我们数学证明所使用的优化方法能以高概率产生一个既接近最优又可行的解决方案。在真实世界临床数据集上与最先进基线模型的经验比较表明GRADUATE的有效性。在详细分析中，我们阐明了基线模型相对于GRADUATE优势的缺点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [401] [Replicable Distribution Testing](https://arxiv.org/abs/2507.02814)
> *可复制分布测试*

*Ilias Diakonikolas, Jingyi Gao, Daniel Kane, Sihan Liu, Christopher Ye* | **Category: cs.LG, G.3** | **Updated: {updated}**

**Keywords:** 分布测试, 可复制性, 样本复杂度, 算法, 下界

**Comment:** 39 pages

> **TL;DR:** 本文系统研究了可复制算法框架下的分布测试，开发了新的可复制算法和一种新的样本复杂度下界证明方法，并应用于均匀性测试和接近度测试，获得了接近最优的样本复杂度下界。

**AI_Comments:** 这篇论文通过引入“可复制性”的概念，为传统的分布测试领域带来了新的视角。其创新点在于不仅开发了新的可复制算法，更重要的是提出了一种通用的样本复杂度下界证明方法，这对于理解可复制算法的理论限制具有重要意义，并且解决了领域内的开放问题，显示了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在系统研究在算法可复制性框架下的分布测试，并表征可复制地测试基础分布的自然属性所需的样本复杂度。

**Method:** 1. 在算法方面，开发了用于测试离散分布的接近度和独立性的新型可复制算法。2. 在下界方面，开发了一种新的方法来证明可复制测试的样本复杂度下界。

**Result:** 1. 开发了测试离散分布接近度和独立性的新型可复制算法。2. 建立了可复制均匀性测试和接近度测试的接近最优样本复杂度下界，回答了先前工作中的一个开放问题。

**Conclusion:** 本文在可复制分布测试领域取得了重要进展，不仅提出了新的算法，还开发了通用的下界证明方法，解决了关键的样本复杂度问题。

> **ai_Abstract:** 本文系统地探索了可复制算法框架下的分布测试问题，旨在确定可复制测试分布属性所需的样本复杂度。作者提出了新的可复制算法用于离散分布的接近度和独立性测试，并开发了一种通用的样本复杂度下界证明新方法。通过应用该方法，文章为可复制均匀性测试和接近度测试建立了接近最优的样本复杂度下界，解决了此前的开放问题。

> **摘要翻译:** 我们在算法可复制性框架下，对分布测试进行了系统性研究。具体来说，给定来自一组概率分布的独立样本，目标是表征可复制地测试基础分布的自然属性所需的样本复杂度。在算法方面，我们开发了用于测试离散分布的接近度和独立性的新型可复制算法。在下界方面，我们开发了一种新的方法来证明可复制测试的样本复杂度下界，该方法可能具有更广泛的兴趣。作为我们技术的一个应用，我们为可复制均匀性测试——回答了先前工作中的一个开放问题——和接近度测试建立了接近最优的样本复杂度下界。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [404] [LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding](https://arxiv.org/abs/2507.02843)
> *LLM驱动的推断时文本混淆下治疗效果估计*

*Yuchen Ma, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 治疗效果估计, 推断时文本混淆, 大型语言模型, 双重鲁棒学习器, 临床实践

**Comment:** 

> **TL;DR:** 该论文提出了一种由LLM驱动的、结合双重鲁棒学习器的框架，用于在推断时文本数据不完整导致偏差的情况下估计治疗效果。

**AI_Comments:** 该论文解决了在实际临床数据中应用治疗效果模型时一个实际且重要的问题，即训练和推断之间数据完整性的差异。利用LLM来弥合这一差距，并结合鲁棒的统计学习器，是一种创新的方法。这项工作对于提高个性化医疗的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在临床实践中，治疗效果估计面临挑战，因为训练时使用详细的结构化数据，而推断时仅能获取不完整的文本描述。这种数据差异会导致治疗效果估计产生偏差，作者将其形式化为“推断时文本混淆”问题。

**Method:** 论文提出了一种新颖的框架，该框架利用大型语言模型（LLMs）和一个定制的双重鲁棒学习器来减轻由推断时文本混淆引起的偏差。

**Result:** 通过一系列实验，证明了所提出的框架在实际应用中的有效性。

**Conclusion:** 该研究提出的LLM驱动框架能够有效解决推断时文本混淆问题，从而提高治疗效果估计的准确性。

> **ai_Abstract:** 该论文解决了由“推断时文本混淆”导致的治疗效果估计偏差问题，即模型在训练时使用完整的结构化数据，而在推断时应用于不完整的文本数据。作者将此问题形式化，并提出了一种新颖的框架，利用大型语言模型（LLMs）和定制的双重鲁棒学习器来减轻这些偏差。实验结果证实了该框架在实际场景中的有效性。

> **摘要翻译:** 治疗效果估计对于医学领域的个性化决策至关重要，但这项任务在临床实践中面临独特的挑战。在训练时，用于估计治疗效果的模型通常在包含详细患者信息的结构化医疗数据集上进行训练。然而，在推断时，预测通常使用文本描述（例如，包含自我报告症状的描述）进行，这些描述是原始患者信息的不完整表示。在这项工作中，我们做出了三项贡献。(1) 我们表明，训练时和推断时可用数据之间的差异可能导致治疗效果的估计存在偏差。我们将这个问题形式化为推断时文本混淆问题，其中混淆因子在训练时被完全观察到，但在推断时只能通过文本部分可用。(2) 为了解决这个问题，我们提出了一种新的治疗效果估计框架，该框架明确考虑了推断时文本混淆。我们的框架利用大型语言模型以及定制的双重鲁棒学习器来减轻由推断时文本混淆引起的偏差。(3) 通过一系列实验，我们证明了我们框架在实际应用中的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [406] [MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis](https://arxiv.org/abs/2507.02847)
> *MvHo-IB：用于脑疾病诊断的多视图高阶信息瓶颈*

*Kunyu Zhang, Qiang Li, Shujian Yu* | **Category: cs.LG** | **Updated: {updated}**

**Keywords:** 多视图学习, 高阶交互, 信息瓶颈, 脑疾病诊断, fMRI

**Comment:** Accepted by MICCAI-25, code is available at
  \url{https://github.com/zky04/MvHo-IB}

> **TL;DR:** MvHo-IB是一个新的多视图学习框架，通过结合高阶交互和信息瓶颈，显著提高了基于fMRI的脑疾病诊断准确性。

**AI_Comments:** 该论文的创新点在于提出了一个结合高阶交互（HOIs）和多视图信息瓶颈（IB）的学习框架MvHo-IB，用于脑疾病诊断。它解决了传统方法难以有效提取和利用高阶交互的挑战，并通过信息论方法量化HOIs，并结合专门的神经网络结构进行处理。其多视图信息瓶颈目标有助于学习更鲁棒和去冗余的表示。该方法在fMRI数据上的显著性能提升显示出其在临床诊断应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，在功能性磁共振成像（fMRI）数据中建模高阶交互（HOIs）可以提高机器学习系统的诊断准确性，但有效提取和利用HOIs仍然是一个重大挑战。

**Method:** 本文提出了MvHo-IB，一个新颖的多视图学习框架，它整合了成对交互和高阶交互用于诊断决策，同时自动压缩与任务无关的冗余信息。MvHo-IB的主要创新包括：(1) 一种结合O-信息和基于矩阵的Renyi alpha阶熵估计器来量化和提取HOIs的原则性方法；(2) 一个专门构建的Brain3DCNN编码器以有效利用这些交互；(3) 一个新的多视图学习信息瓶颈目标以增强表示学习。

**Result:** 在三个基准fMRI数据集上的实验表明，MvHo-IB实现了最先进的性能，显著优于以前的方法，包括最近的基于超图的技术。

**Conclusion:** MvHo-IB通过有效提取和利用高阶交互，并结合多视图信息瓶颈学习，显著提升了脑疾病诊断的准确性，证明了其在fMRI数据分析中的优越性。

> **ai_Abstract:** MvHo-IB是一个创新的多视图学习框架，旨在通过有效提取和利用fMRI数据中的高阶交互（HOIs）来提高脑疾病诊断的准确性。该框架结合了信息论中的O-信息和Renyi alpha阶熵估计器来量化HOIs，并使用专门的Brain3DCNN编码器进行处理。通过引入新的多视图信息瓶颈目标，MvHo-IB能自动压缩冗余信息并增强表示学习。实验证明，MvHo-IB在多个fMRI数据集上均实现了最先进的诊断性能。

> **摘要翻译:** 最近的证据表明，在功能性磁共振成像（fMRI）数据中建模高阶交互（HOIs）可以提高机器学习系统的诊断准确性。然而，有效提取和利用HOIs仍然是一个重大挑战。在这项工作中，我们提出了MvHo-IB，一个新颖的多视图学习框架，它整合了成对交互和HOIs用于诊断决策，同时自动压缩与任务无关的冗余信息。MvHo-IB引入了几个关键创新：(1) 一种结合信息论中的O-信息与基于矩阵的Renyi alpha阶熵估计器来量化和提取HOIs的原则性方法；(2) 一个专门构建的Brain3DCNN编码器以有效利用这些交互；(3) 一个新的多视图学习信息瓶颈目标以增强表示学习。在三个基准fMRI数据集上的实验表明，MvHo-IB实现了最先进的性能，显著优于以前的方法，包括最近的基于超图的技术。MvHo-IB的实现可在https://github.com/zky04/MvHo-IB获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [6] [Dynamic Strategy Adaptation in Multi-Agent Environments with Large Language Models](https://arxiv.org/abs/2507.02002)
> *动态多智能体环境中大型语言模型的策略适应*

*Shaurya Mallampati, Rashed Shelim, Walid Saad, Naren Ramakrishnan* | **Category: cs.MA** | **Updated: {updated}**

**Keywords:** 大型语言模型, 多智能体系统, 策略适应, 博弈论, 实时反馈

**Comment:** 20 pages, 11 figures Submitted to GameSec 2025 (under review)

> **TL;DR:** 本文提出了一种结合大型语言模型（LLM）和博弈论原则的框架，以实现在动态、实时、多智能体协作环境中的策略适应，并在高噪声环境中取得了显著性能提升。

**AI_Comments:** 这篇论文的创新之处在于将大型语言模型（LLM）的强大推理能力与博弈论的战略指导相结合，并引入了实时适应和反馈机制，使其能够应对动态、实时、多智能体环境。这突破了以往LLM在静态或回合制设置中评估的局限性。其重要性在于为构建更具弹性、灵活性和高效协作能力的AI系统提供了新的范式，特别是在需要智能体间复杂交互和快速决策的场景中，如协作游戏或复杂系统控制。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对大型语言模型（LLM）在动态、实时、多智能体场景（如协作游戏）中的推理能力知之甚少，尽管LLM在数学、策略和语言任务中展现出强大的推理能力。本文旨在弥补这一空白。

**Method:** 本文将大型语言模型（LLM）驱动的智能体与战略推理和实时适应相结合，在基于博弈论原则（如信念一致性和纳什均衡）的协作多智能体环境中进行研究。所提出的框架提供了实时策略细化和自适应反馈机制，使智能体能够根据即时上下文交互动态调整策略，这与之前在静态或回合制设置中评估LLM能力的方法不同。

**Result:** 经验结果表明，本文方法在高噪声环境中比PPO基线在回报方面取得了高达26%的提升，同时保持实时延迟在1.05毫秒以下。该方法提高了协作效率、任务完成率和灵活性。

**Conclusion:** 将博弈论指导与实时反馈相结合可以增强大型语言模型（LLM）的性能，最终促进更具弹性和灵活性的战略多智能体系统。

> **ai_Abstract:** 本文提出了一种新颖的框架，将大型语言模型（LLM）与博弈论原则相结合，以解决LLM在动态、实时、多智能体协作环境中策略适应能力不足的问题。该框架通过实时策略细化和自适应反馈机制，使LLM驱动的智能体能够根据不断变化的上下文动态调整行为。实验结果显示，该方法在高噪声环境下相比PPO基线在回报率上提升了26%，并保持了低延迟，显著提升了协作效率和系统灵活性。

> **摘要翻译:** 大型语言模型（LLM）在数学、策略和语言任务中表现出强大的推理能力，但对于它们在动态、实时、多智能体场景（例如智能体在协作游戏设置中持续适应彼此行为的协作环境）中的推理能力知之甚少。在本文中，我们通过将LLM驱动的智能体与战略推理和实时适应相结合，在基于博弈论原则（如信念一致性和纳什均衡）的协作多智能体环境中弥补了这一空白。所提出的框架广泛适用于智能体响应持续变化条件进行协调、通信和决策的动态场景。我们提供了实时策略细化和自适应反馈机制，使智能体能够根据即时上下文交互动态调整策略，这与之前在静态或回合制设置中评估LLM能力的方法不同。经验结果表明，我们的方法在高噪声环境中比PPO基线在回报方面取得了高达26%的提升，同时保持实时延迟在1.05毫秒以下。我们的方法提高了协作效率、任务完成率和灵活性，表明将博弈论指导与实时反馈相结合可以增强LLM的性能，最终促进更具弹性和灵活性的战略多智能体系统。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [35] [Synergizing Logical Reasoning, Knowledge Management and Collaboration in Multi-Agent LLM System](https://arxiv.org/abs/2507.02170)
> *多智能体LLM系统中逻辑推理、知识管理与协作的协同作用*

*Adam Kostka, Jarosław A. Chudziak* | **Category: cs.MA** | **Updated: {updated}**

**Keywords:** 多智能体系统, 逻辑推理, 知识管理, 心智理论, 协作

**Comment:** 

> **TL;DR:** 本文提出SynergyMAS框架，通过整合逻辑推理、长期知识保留和心智理论，增强多智能体系统的协作和问题解决能力。

**AI_Comments:** 这项研究通过将逻辑推理、知识管理和心智理论等高级认知能力整合到多智能体系统中，提供了一个新颖的框架SynergyMAS。其创新点在于强调了这些能力与优化通信协议的协同作用，以实现更强大的协作和问题解决。通过案例研究展示了其在实际场景中的潜力，这对于未来开发更智能、更具适应性的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索多智能体系统（MAS）技术，以开发一个具有增强逻辑推理、长期知识保留和心智理论（ToM）能力的智能体团队。

**Method:** 通过整合先进的多智能体系统技术，将逻辑推理、长期知识保留和心智理论能力与优化通信协议相结合，创建了一个名为SynergyMAS的新颖框架。

**Result:** 通过产品开发团队案例研究，证明了SynergyMAS系统显著提升了性能和适应性。

**Conclusion:** SynergyMAS框架在增强多智能体系统的协作和问题解决能力方面具有潜力，能够应对复杂的现实世界挑战。

> **ai_Abstract:** 本文提出了一种名为SynergyMAS的新型多智能体系统框架，该框架通过整合逻辑推理、长期知识保留和心智理论能力，并优化通信协议，旨在提升智能体团队的协作和问题解决能力。通过产品开发案例研究，验证了该系统在提高性能和适应性方面的有效性，表明其在应对复杂现实挑战方面的潜力。

> **摘要翻译:** 本文探讨了如何整合先进的多智能体系统（MAS）技术，以开发一个具有增强逻辑推理、长期知识保留和心智理论（ToM）能力的智能体团队。通过将这些核心组件与优化的通信协议相结合，我们创建了一个名为SynergyMAS的新颖框架，该框架促进了协作团队合作和卓越的问题解决技能。通过一个产品开发团队的案例研究，证明了该系统的有效性，其中我们的方法显著提升了性能和适应性。这些发现突出了SynergyMAS解决复杂现实世界挑战的潜力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [11] [Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain](https://arxiv.org/abs/2507.02016)
> *BDI机器人有效解释：何时以及解释什么*

*Cong Wang, Roberto Calandra, Verena Klös* | **Category: cs.RO, cs.AI** | **Updated: {updated}**

**Keywords:** BDI机器人, 解释性AI, 人机交互, 用户偏好, 意外行为

**Comment:** Paper accepted at IEEE RO-MAN 2025; 6 pages

> **TL;DR:** 本文研究了用户对日常清洁机器人解释的需求和内容偏好，发现用户在意外情况下需要解释，并偏好简洁、能说明意图和相关上下文因素的解释。基于此，提出了两种算法，用于识别意外行为并为BDI机器人构建有效解释，以改善人机交互。

**AI_Comments:** 该论文的创新之处在于，它不仅识别了人机交互中解释的需求痛点（何时解释、解释什么），而且提出了实用的算法来解决这些问题，并特别强调了与BDI机器人推理过程的集成。这对于提升机器人行为的可解释性和用户信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当机器人执行复杂且依赖上下文的任务时，其行为偏离用户预期会引起困惑。解释机器人的推理过程有助于用户理解其意图。然而，何时提供解释以及解释的内容对于避免用户厌烦至关重要。

**Method:** 研究人员调查了用户对在厨房进行日常清洁任务的机器人解释需求和内容偏好。基于研究结果，提出了两种算法：一种用于识别意外行为，另一种用于为信念-欲望-意图（BDI）机器人构建有效解释。这些算法可以轻松集成到BDI推理过程中。

**Result:** 研究结果表明，用户在意外情况下需要解释，并且偏好简洁的解释，这些解释能清楚地说明令人困惑行为背后的意图以及与该决定相关的上下文因素。

**Conclusion:** 本文提出的两种算法能够识别意外动作并为BDI机器人构建有效的解释。这些算法可以轻松集成到BDI推理过程中，为实现更好的、提供上下文和用户特定解释的人机交互铺平了道路。

> **ai_Abstract:** 本文探讨了BDI机器人提供有效解释的关键问题：何时以及解释什么。研究通过调查用户对日常清洁机器人解释的需求和偏好，发现用户在意外情况时更希望获得解释，并倾向于简洁地阐明意图和相关上下文因素的解释。基于这些发现，文章提出了两种算法，旨在识别意外行为并为BDI机器人生成有效解释，旨在促进更优越的人机交互，提供情境化和用户定制的解释。

> **摘要翻译:** 当机器人在我们的日常生活中执行复杂且依赖上下文的任务时，偏离预期会使用户感到困惑。解释机器人的推理过程可以帮助用户理解机器人的意图。然而，何时提供解释以及解释包含什么内容对于避免用户厌烦很重要。我们调查了用户对在厨房进行日常清洁任务的机器人解释需求和内容偏好。我们的结果表明，用户在意外情况下需要解释，并且偏好简洁的解释，这些解释能清楚地说明令人困惑行为背后的意图以及与该决定相关的上下文因素。基于这些发现，我们提出了两种算法，用于识别意外行为并为信念-欲望-意图（BDI）机器人构建有效解释。我们的算法可以轻松集成到BDI推理过程中，为实现更好的、提供上下文和用户特定解释的人机交互铺平了道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [40] [RoboBrain 2.0 Technical Report](https://arxiv.org/abs/2507.02029)
> *RoboBrain 2.0 技术报告*

*BAAI RoboBrain Team, Mingyu Cao, Huajie Tan, Yuheng Ji, Minglan Lin, Zhiyu Li, Zhou Cao, Pengwei Wang, Enshen Zhou, Yi Han, Yingbo Tang, Xiangqi Xu, Wei Guo, Yaoxu Lyu, Yijie Xu, Jiayu Shi, Cheng Chi, Mengdi Zhao, Xiaoshuai Hao, Shanyu Rong, Zhengliang Cai, Bolun Zhang, Shuyi Zhang, Huaihai Lyu, Mengfei Du, Lingfeng Zhang, Xi Feng, Xiaodan Liu, Yance Jiao, Chenrui He, Mengsi Lyu, Zhuo Chen, Yulong Ao, Xue Sun, Zheqi He, Jingshu Zheng, Xi Yang, Donghai Shi, Kunchang Xie, Bochao Zhang, Shaokai Nie, Chunlei Men, Yonghua Lin, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 具身AI, 视觉-语言模型, 基础模型, 感知推理规划, RoboBrain

**Comment:** 

> **TL;DR:** RoboBrain 2.0 是一个新型具身视觉-语言基础模型，旨在统一具身任务中的感知、推理和规划。它有两个版本（7B和32B），在空间和时间基准测试中表现出色，超越了现有模型，并支持多种现实世界的具身AI能力。

**AI_Comments:** RoboBrain 2.0的创新之处在于其作为具身视觉-语言基础模型的统一性，旨在将感知、推理和规划集成到物理环境中的复杂任务中。其异构架构和在紧凑尺寸下实现卓越性能的能力非常重要。该项目通过提供代码、检查点和基准测试，对具身AI研究社区的贡献也值得称赞。

<details>
  <summary>Details</summary>

**Motivation:** 开发RoboBrain 2.0的动机是创建一个具身视觉-语言基础模型，以统一物理环境中复杂具身任务的感知、推理和规划能力。

**Method:** RoboBrain 2.0是一个具身视觉-语言基础模型，包含7B和32B两种变体。它采用异构架构，结合了视觉编码器和语言模型。本报告详细介绍了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。

**Result:** RoboBrain 2.0在广泛的具身推理任务中表现出色。其中32B版本在空间和时间基准测试中取得了领先结果，超越了先前的开源和专有模型。它支持关键的现实世界具身AI能力，包括空间理解（如可供性预测、空间指代、轨迹预测）和时间决策（如闭环交互、多智能体长周期规划和场景图更新）。

**Conclusion:** RoboBrain 2.0有望推动具身AI研究，并成为构建通用具身智能体的一个实用步骤。

> **ai_Abstract:** 本报告介绍了RoboBrain 2.0，这是一种新型具身视觉-语言基础模型，旨在整合具身任务中的感知、推理和规划。该模型提供7B和32B两种版本，采用视觉编码器和语言模型的异构架构。RoboBrain 2.0在具身推理任务中表现出色，其32B版本在空间和时间基准测试中超越了现有模型，并支持多种现实世界的具身AI能力，如空间理解和时间决策。该报告详细阐述了模型架构、数据构建、训练策略和应用，旨在推动具身AI研究并促进通用具身智能体的开发。

> **摘要翻译:** 我们介绍了RoboBrain 2.0，我们最新一代的具身视觉-语言基础模型，旨在统一物理环境中复杂具身任务的感知、推理和规划。它有两种变体：一个轻量级的7B模型和一个全尺寸的32B模型，采用异构架构，包含一个视觉编码器和一个语言模型。尽管其尺寸紧凑，RoboBrain 2.0在广泛的具身推理任务中取得了强大性能。在空间和时间基准测试中，32B变体取得了领先结果，超越了先前的开源和专有模型。特别是，它支持关键的现实世界具身AI能力，包括空间理解（例如，可供性预测、空间指代、轨迹预测）和时间决策（例如，闭环交互、多智能体长周期规划和场景图更新）。本报告详细介绍了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。我们希望RoboBrain 2.0能推动具身AI研究，并作为构建通用具身智能体的一个实用步骤。代码、检查点和基准可在https://superrobobrain.github.io获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [65] [Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN](https://arxiv.org/abs/2507.02171)
> *迈向基于自监督循环神经网络的仿生机器人轨迹规划*

*Miroslav Cibula, Kristína Malinovská, Matthias Kerzel* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 机器人轨迹规划, 自监督学习, 循环神经网络, 运动学规划, 仿生

**Comment:** 12 pages, 4 figures, 2 tables. To be published in 2025 International
  Conference on Artificial Neural Networks (ICANN) proceedings. This research
  was funded by the Horizon Europe project TERAIS, GA no. 101079338, and in
  part by the Slovak Grant Agency for Science (VEGA), project 1/0373/23

> **TL;DR:** 本文提出一种基于循环神经网络的认知启发式自监督学习方案，用于机器人轨迹规划，解决了传统监督学习的模仿学习局限性，并在运动学规划任务上验证了其可行性，表明该方法能生成轨迹并有助于更复杂的自适应规划。

**AI_Comments:** 这篇论文通过引入自监督学习，解决了机器人轨迹规划中传统监督学习方法仅限于模仿，无法真正实现基于目标达成的学习的痛点。其核心创新在于将认知启发式自监督学习与循环神经网络结合，使得模型能够自主学习生成轨迹，而不仅仅是复现。这对于提升机器人规划的自主性和适应性具有重要意义，尤其是在需要处理复杂、动态环境的任务中。

<details>
  <summary>Details</summary>

**Motivation:** 传统的采样式轨迹规划计算量大；近期监督序列学习方法虽计算时间有界，但其模仿学习的本质导致其不基于目标达成度学习，而是简单复现观察到的轨迹，限制了其适应性。

**Method:** 本文提出了一种受认知启发的自监督学习方案，该方案基于循环神经网络（RNN）构建轨迹模型。作者在机械臂的运动学规划任务上评估了该方法的可行性。

**Result:** 该模型仅使用给定的正向和逆向运动学模型对，就能够学习生成轨迹。

**Conclusion:** 这种新颖的方法有望促进需要自适应解决方案的更复杂操作任务的规划。

> **ai_Abstract:** 本文针对机器人轨迹规划中传统采样式方法计算量大以及现有监督学习方法仅进行模仿学习的局限性，提出了一种基于循环神经网络的认知启发式自监督学习方案来构建轨迹模型。该方法在机械臂运动学规划任务上进行了验证，结果表明它能仅利用正逆运动学模型对生成轨迹，并有望应用于更复杂的自适应操作任务。

> **摘要翻译:** 机器人中的轨迹规划被理解为生成一系列关节配置，这些配置将引导机器人代理或其机械手从初始状态到达期望的最终状态，从而在考虑机器人运动学和环境等约束的情况下完成操纵任务。通常，这通过基于采样的规划器实现，但计算量很大。最近的进展表明，轨迹规划也可以通过对轨迹进行监督序列学习来执行，这通常只需要通过神经网络架构进行一次或固定次数的传递，从而确保有界的计算时间。然而，这种完全监督的方法执行的是模仿学习；它们不是基于轨迹能否成功达到目标来学习，而是试图复现观察到的轨迹。在我们的工作中，我们在此方法的基础上，提出了一种基于循环架构的认知启发式自监督学习方案，用于构建轨迹模型。我们在机械臂的运动学规划任务上评估了所提出方法的可行性。结果表明，该模型仅使用给定的正向和逆向运动学模型对，就能够学习生成轨迹，并且表明这种新颖的方法可以促进需要自适应解决方案的更复杂操纵任务的规划。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [90] [cVLA: Towards Efficient Camera-Space VLAs](https://arxiv.org/abs/2507.02190)
> *cVLA：迈向高效相机空间VLA*

*Max Argus, Jelena Bratulic, Houman Masnavi, Maxim Velikanov, Nick Heppert, Abhinav Valada, Thomas Brox* | **Category: cs.RO, cs.LG** | **Updated: {updated}**

**Keywords:** 视觉-语言-动作模型, 机器人操作, 相机空间, 轨迹路点, 模拟到真实迁移

**Comment:** 20 pages, 10 figures

> **TL;DR:** 提出一种新的cVLA模型，利用2D VLM推断相机空间中的机器人末端执行器姿态，预测轨迹路点而非低级控制，实现高效训练和强大的模拟到真实迁移能力。

**AI_Comments:** 这项工作通过将机器人动作预测提升到相机空间中的轨迹路点层面，而非传统的低级控制，有效地降低了VLA模型的训练复杂度和对特定机器人本体的依赖性，这是一个重要的创新点。其轻量级设计和对模拟到真实迁移的强调，也提升了其实用性。对深度图像和推理策略的探索，进一步展示了其在复杂操作任务中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言-动作（VLA）模型在处理复杂机器人操作任务时训练成本高昂。

**Method:** 提出一种新的VLA方法，利用视觉语言模型（VLMs）在2D图像上的性能，直接在图像坐标系中推断机器人末端执行器姿态。该模型预测轨迹路点，而非低级控制，使其训练更高效且与机器人本体无关。采用轻量级、下一词元预测架构，并探索整合深度图像、推理时技术（如解码策略）和示范条件动作生成。

**Result:** 模型在模拟数据集上训练，并展现出强大的模拟到真实迁移能力。在模拟和真实数据上进行评估，证明了其在真实机器人系统上的有效性。

**Conclusion:** 本文提出的cVLA模型通过预测轨迹路点，实现了高效训练和与机器人本体无关的特性，并在真实机器人系统上展现出有效性及强大的模拟到真实迁移能力。

> **ai_Abstract:** 本文提出了一种名为cVLA的新型视觉-语言-动作（VLA）模型，旨在解决传统VLA模型训练成本高昂的问题。该模型利用2D视觉语言模型（VLMs）的能力，直接在相机图像坐标系中预测机器人末端执行器的姿态和轨迹路点，而非低级控制，从而实现了更高效的训练和机器人本体无关性。cVLA采用轻量级的下一词元预测架构，能够有效学习可执行的机器人轨迹，并探索了深度图像、推理策略和示范条件动作生成等技术。实验结果表明，该模型在模拟数据集上训练后，具有强大的模拟到真实迁移能力，并在真实机器人系统上表现出显著的有效性。

> **摘要翻译:** 视觉-语言-动作（VLA）模型为解决复杂的机器人操作任务提供了一个引人注目的框架，但它们的训练成本通常很高。在本文中，我们提出了一种新颖的VLA方法，该方法利用视觉语言模型（VLMs）在2D图像上的竞争性能，直接在图像坐标系中推断机器人末端执行器姿态。与以往输出低级控制的VLA模型不同，我们的模型预测轨迹路点，这使其训练更高效且与机器人本体无关。尽管设计轻巧，但我们的下一词元预测架构能有效地学习有意义且可执行的机器人轨迹。我们进一步探索了整合深度图像、推理时技术（如解码策略）以及示范条件动作生成的未充分利用的潜力。我们的模型在模拟数据集上进行训练，并展现出强大的模拟到真实迁移能力。我们结合模拟和真实数据评估了我们的方法，证明了其在真实机器人系统上的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [114] [GPS-DRIFT: Marine Surface Robot Localization using IMU-GPS Fusion and Invariant Filtering](https://arxiv.org/abs/2507.02198)
> *GPS-DRIFT：使用IMU-GPS融合和不变滤波的海洋水面机器人定位*

*Surya Pratap Singh, Tsimafei Lazouski, Maani Ghaffari* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** GPS-DRIFT, IMU-GPS融合, 不变滤波, 海洋机器人, 定位

**Comment:** 6 pages

> **TL;DR:** 该论文扩展了DRIFT不变状态估计框架，通过融合GPS和IMU数据并引入新颖的航向校正机制，实现了海洋水面机器人在挑战性条件下的精确姿态和航向估计。

**AI_Comments:** 这项工作通过将GPS外部感知数据与IMU本体感知数据相结合，并引入创新的航向校正机制，有效地解决了水面机器人定位中偏航不可观测性的核心挑战。其基于不变滤波的框架提升了鲁棒性，而开源解决方案的提供则极大地促进了该领域的进一步研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 解决海洋水面机器人在挑战性或GPS信号退化条件下精确姿态和航向估计的难题，特别是克服航位推算中固有的偏航不可观测性。

**Method:** 本文扩展了仅使用本体感知传感器的DRIFT算法，开发了一个对称保持的传感器融合流程。该流程利用不变扩展卡尔曼滤波器（InEKF）将GPS的全局位置更新直接集成到校正步骤中。核心创新是引入了一种新颖的航向校正机制，该机制结合了GPS的对地航迹信息和IMU的姿态数据，以解决偏航不可观测性问题。

**Result:** 该系统已在定制的Blue Robotics BlueBoat上部署和验证，能够实现无漂移的定位和可靠的姿态估计，并在挑战性或GPS信号退化条件下提供精确的偏航观测和定位。

**Conclusion:** 本文提供了一个开源解决方案，用于在挑战性或GPS信号退化条件下实现精确的偏航观测和定位，并为未来的实验和比较研究奠定了基础。

> **ai_Abstract:** 本文扩展了DRIFT不变状态估计算法，提出了一个名为GPS-DRIFT的系统，用于海洋水面机器人的鲁棒定位。该系统利用不变扩展卡尔曼滤波器（InEKF）融合IMU和GPS数据，并引入了一种新颖的航向校正机制，结合GPS对地航迹信息和IMU姿态，以克服航位推算中的偏航不可观测性。该方法已在海洋自主水面航行器上验证，旨在提供在GPS信号受限环境下精确的无漂移定位和姿态估计，并提供开源实现。

> **摘要翻译:** 本文提出了DRIFT不变状态估计框架的扩展，实现了GPS和IMU数据的鲁棒融合，从而实现精确的姿态和航向估计。该方法最初是为海洋自主水面航行器（ASV）的测试和使用而开发的，但也可用于其他移动系统。在原有的仅本体感知DRIFT算法的基础上，我们开发了一个对称保持的传感器融合流程，利用不变扩展卡尔曼滤波器（InEKF）将GPS的全局位置更新直接集成到校正步骤中。关键的是，我们引入了一种新颖的航向校正机制，该机制结合了GPS的对地航迹信息和IMU方向，克服了航位推算中固有的偏航不可观测性。该系统已在定制的Blue Robotics BlueBoat上部署和验证，但其方法学重点在于融合外部感知和本体感知传感器以实现无漂移定位和可靠方向估计的算法方法。这项工作为在挑战性或GPS信号退化条件下实现精确偏航观测和定位提供了一个开源解决方案，并为未来的实验和比较研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [138] [CoInfra: A Large-Scale Cooperative Infrastructure Perception System and Dataset in Adverse Weather](https://arxiv.org/abs/2507.02245)
> *CoInfra：一个大规模恶劣天气下的协作式基础设施感知系统与数据集*

*Minghao Ning, Yufeng Yang, Keqi Shu, Shucheng Huang, Jiaming Zhong, Maryam Salehi, Mahdi Rahmani, Yukun Lu, Chen Sun, Aladdin Saleh, Ehsan Hashemi, Amir Khajepour* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 协作感知, 恶劣天气, 大规模数据集, 基础设施感知, 自动驾驶

**Comment:** This paper has been submitted to the IEEE Transactions on Robotics
  for review

> **TL;DR:** CoInfra是一个大规模协作式基础设施感知系统和数据集，旨在恶劣天气下提升多智能体感知能力。它包含14个同步传感器节点，并提供了一个涵盖多种天气条件的大型数据集，包含LiDAR帧、图像和3D标注，旨在推动基础设施辅助自动驾驶研究。

**AI_Comments:** CoInfra的创新之处在于其构建了一个大规模、高同步性的协作式基础设施感知系统和数据集，特别关注恶劣天气条件下的数据采集和感知。这对于推动真实世界中自动驾驶技术的鲁棒性至关重要。其提供多传感器数据、精细标注和高精地图，以及开放的资源，将极大地促进该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 为了在真实世界和恶劣天气条件下，推进鲁棒的多智能体感知技术。

**Method:** CoInfra系统包含14个完全同步的传感器节点，每个节点配备双RGB摄像头和LiDAR，部署在共享区域并持续运行。系统提供了鲁棒、延迟感知的同步协议和可扩展的系统架构，支持实时数据融合、OTA管理和远程监控。数据集在晴天、雨天、冻雨和大雪等不同天气场景下收集，包含19.5万个LiDAR帧和39万张来自8个基础设施节点的相机图像，并提供全局和单个节点帧下的五类物体（汽车、巴士、卡车、行人、自行车）的3D边界框标注，以及高精地图。

**Result:** 基线实验展示了早期和晚期融合策略之间的权衡，并讨论了集成高清地图的显著优势。

**Conclusion:** 通过开放数据集、代码库和系统文档，旨在促进可复现的研究，并推动基础设施辅助自动驾驶在充满挑战的真实世界环境中的进展。

> **ai_Abstract:** CoInfra是一个大型协作式基础设施感知系统和数据集，专为提升恶劣天气下的多智能体感知能力而设计。该系统由14个配备摄像头和LiDAR的同步传感器节点组成，并提供了一个包含多种天气条件（晴天、雨天、冻雨、大雪）下收集的大规模数据集，其中包括大量LiDAR帧、图像和详细的3D物体标注，以及高精地图。论文还介绍了系统架构和同步协议，并通过基线实验分析了融合策略和高精地图的效用。项目公开了数据集和代码，旨在推动基础设施辅助自动驾驶在复杂环境中的研究。

> **摘要翻译:** 我们提出了CoInfra，一个大规模协作式基础设施感知系统和数据集，旨在推进在真实世界和恶劣天气条件下鲁棒的多智能体感知。CoInfra系统包括14个完全同步的传感器节点，每个节点配备双RGB摄像头和LiDAR，部署在共享区域并持续运行，以实时捕获所有交通参与者。本文提供了一个鲁棒、延迟感知的同步协议和一个支持实时数据融合、OTA管理和远程监控的可扩展系统架构。另一方面，数据集在不同的天气场景下收集，包括晴天、雨天、冻雨和大雪，包含来自8个基础设施节点的19.5万个LiDAR帧和39万张相机图像，这些数据经过全局时间对齐和空间校准。此外，还提供了五类物体（即汽车、巴士、卡车、行人、自行车）在全局和单个节点帧中的全面3D边界框标注，以及用于上下文理解的高精地图。基线实验展示了早期和晚期融合策略之间的权衡，并讨论了集成高清地图的显著优势。通过在https://github.com/NingMingHao/CoInfra开放我们的数据集、代码库和系统文档，我们旨在实现可复现的研究，并推动基础设施辅助自动驾驶的进展，特别是在充满挑战的真实世界环境中。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [158] [A Vehicle-in-the-Loop Simulator with AI-Powered Digital Twins for Testing Automated Driving Controllers](https://arxiv.org/abs/2507.02313)
> *一种基于AI数字孪生的车辆在环模拟器，用于测试自动驾驶控制器*

*Zengjie Zhang, Giannis Badakis, Michalis Galanis, Adem Bavarşi, Edwin van Hassel, Mohsen Alirezaei, Sofie Haesaert* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 车辆在环, 数字孪生, 自动驾驶, 模拟器, AI

**Comment:** 

> **TL;DR:** 本文开发了一种基于缩放物理车辆和AI数字孪生的车辆在环模拟器，解决了传统ViL测试成本高和数字孪生精度不足的问题，并展示了其在自动驾驶控制器验证方面的有效性。

**AI_Comments:** 该论文提出了一种创新的车辆在环模拟器，通过结合缩放物理车辆和AI驱动的数字孪生技术，有效解决了传统模拟器在成本、空间和仿真精度上的痛点。这种混合方法有望大幅降低自动驾驶控制器测试的门槛，并提高测试的真实性。其与现有软件的良好集成也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的车辆在环（ViL）测试依赖全尺寸车辆，需要大空间和高成本。同时，基于物理模型的数字孪生（DT）存在建模不精确导致的现实差距。

**Method:** 本文开发了一种综合实用的模拟器，用于测试自动驾驶控制器，该模拟器通过使用缩放物理车辆和AI驱动的数字孪生模型进行增强。缩放车辆节省空间和成本，AI数字孪生模型确保了卓越的仿真保真度。此外，该模拟器易于与现有软件和控制算法集成。

**Result:** 通过使用具有形式安全保证的滤波控制基准，展示了模拟器在验证自动驾驶控制器方面的能力。实验研究证明了模拟器的有效性，预示其在验证自动驾驶车辆和智能交通控制解决方案方面的巨大潜力。

**Conclusion:** 该模拟器在验证自动驾驶车辆和智能交通的控制解决方案方面具有巨大潜力。

> **ai_Abstract:** 本文针对传统车辆在环（ViL）测试成本高昂和数字孪生（DT）模型精度不足的问题，提出了一种基于缩放物理车辆和AI驱动数字孪生模型的综合模拟器，用于测试自动驾驶控制器。该模拟器通过缩放车辆节省了空间和成本，并利用AI数字孪生提升了仿真保真度，同时具备良好的可扩展性。实验结果表明，该模拟器能有效验证自动驾驶控制器，在自动驾驶和智能交通控制解决方案的验证方面具有巨大潜力。

> **摘要翻译:** 模拟器是测试自动驾驶控制器的有用工具。车辆在环（ViL）测试和数字孪生（DT）是广泛使用的仿真技术，旨在促进控制器顺利部署到物理车辆。然而，传统的ViL测试依赖于全尺寸车辆，需要大空间和高昂费用。此外，基于物理模型的数字孪生存在建模不精确导致的现实差距。本文开发了一种全面实用的模拟器，用于测试自动驾驶控制器，该模拟器通过缩放物理车辆和AI驱动的数字孪生模型得到增强。缩放车辆可以节省仿真测试的空间和费用。AI驱动的数字孪生模型确保了卓越的仿真保真度。此外，该模拟器与现成的软件和控制算法良好集成，易于扩展。我们使用具有形式安全保证的滤波控制基准来展示模拟器在验证自动驾驶控制器方面的能力。实验研究证明了模拟器的有效性，预示其在验证自动驾驶车辆和智能交通控制解决方案方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [178] [Path Planning using a One-shot-sampling Skeleton Map](https://arxiv.org/abs/2507.02328)
> *使用一次性采样骨架图的路径规划*

*Gabriel O. Flores-Aquino, Octavio Gutierrez-Frias, Juan Irving Vasquez* | **Category: cs.RO, cs.LG** | **Updated: {updated}**

**Keywords:** 路径规划, 骨架图, 深度去噪自编码器, U-Net, 一次性采样

**Comment:** 

> **TL;DR:** 提出一种基于U-Net的SkelUnet网络，通过一次性采样高效生成骨架图，实现快速、安全的路径规划，适用于移动服务机器人。

**AI_Comments:** 本文的创新点在于将深度学习（U-Net架构的DDAE）应用于骨架化过程，并结合一次性采样，显著提高了路径规划的效率和安全性。这种方法克服了传统骨架化算法资源消耗大的问题，为实时路径规划提供了新的思路，尤其适用于对响应时间有高要求的移动机器人应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统路径规划算法侧重最优距离，但一些应用更需平衡响应时间、路径安全性和路径长度。现有骨架化算法资源密集，主要面向图像处理，不适用于高效路径规划。

**Method:** 提出一种高效的路径规划方法，利用基于U-Net架构的深度去噪自编码器（DDAE），命名为SkelUnet，计算导航地图的骨架化版本。SkelUnet通过一次性采样（OSS）促进整个工作空间的探索，不同于迭代或概率采样。该网络在12,500张二维地牢地图数据集上进行训练和测试，并在无人机模拟环境中对250张新地图进行评估。

**Result:** 使用SkelUnet构建路线图具有显著优势，例如连接自由工作空间的所有区域、提供更安全的路径以及减少处理时间。

**Conclusion:** 该方法特别适用于结构化环境中的移动服务机器人。

> **ai_Abstract:** 本文提出一种名为SkelUnet的深度去噪自编码器（DDAE）网络，该网络基于U-Net架构，用于高效地生成导航地图的骨架化版本。SkelUnet通过一次性采样（OSS）实现对整个工作空间的快速探索，解决了传统骨架化算法资源密集的问题，并在平衡路径长度、安全性和响应时间方面表现出色。实验结果表明，该方法能够连接所有自由工作空间区域，提供更安全的路径，并显著减少处理时间，特别适用于结构化环境中的移动服务机器人。

> **摘要翻译:** 路径规划算法旨在计算无碰撞路径，许多工作专注于寻找最优距离路径。然而，对于某些应用，更合适的方法是平衡响应时间、路径安全性和路径长度。在这种背景下，骨架图是基于图方案中的一个有用工具，因为它提供了自由配置空间的内在表示。然而，骨架化算法非常耗费资源，主要面向图像处理任务。我们提出一种高效的路径规划方法，可以在可接受的处理时间内找到安全路径。该方法利用基于U-Net架构的深度去噪自编码器（DDAE）来计算导航地图的骨架化版本，我们称之为SkelUnet。SkelUnet网络通过一次性采样（OSS）促进整个工作空间的探索，这与精确算法使用的迭代过程或概率采样过程不同。SkelUnet在包含12,500张二维地牢地图的数据集上进行训练和测试。该运动规划方法在无人机（UAV）的模拟环境中对250张以前未见的地图进行了评估，并使用各种导航指标量化计算路径的可导航性。结果表明，使用SkelUnet构建路线图具有显著优势，例如连接自由工作空间的所有区域、提供更安全的路径以及减少处理时间。这些特性使得该方法特别适用于结构化环境中的移动服务机器人。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [185] [A Late Collaborative Perception Framework for 3D Multi-Object and Multi-Source Association and Fusion](https://arxiv.org/abs/2507.02430)
> *一种用于3D多目标和多源关联与融合的后期协作感知框架*

*Maryem Fadili, Mohamed Anis Ghaoui, Louis Lecrosnier, Steve Pechberti, Redouane Khemmar* | **Category: cs.RO, eess.IV, eess.SP** | **Updated: {updated}**

**Keywords:** 协作感知, 后期融合, 3D目标检测, 自动驾驶, 多代理系统

**Comment:** 

> **TL;DR:** 该研究提出了一种新型后期协作感知框架，仅基于共享的3D边界框属性进行融合，无需访问底层检测模型，显著降低了通信带宽要求并提高了融合精度。

**AI_Comments:** 该论文的创新点在于提出了一个无需访问底层检测模型即可进行协作感知的后期融合框架，有效解决了实际自动驾驶中通信带宽和模型隐私的限制。其将后期融合的性能提升至新高度，对于推动自动驾驶领域的多代理协作感知具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习协作感知方法虽然精度高，但依赖高通信带宽并要求无限制访问每个代理的检测模型架构和参数，这在实际自动驾驶场景中受通信限制和专有模型保护的阻碍。

**Method:** 该框架提出了一种新型后期协作框架，用于3D多源和多目标融合，仅基于共享的3D边界框属性（类别、大小、位置和方向）进行操作，无需直接访问检测模型。

**Result:** 与现有方法相比，该框架将位置误差降低了五倍，尺度误差降低了7.5倍，方向误差降低了一半，同时在融合异构感知系统的检测结果时保持了100%的精确度和召回率。

**Conclusion:** 该方法有效解决了现实世界中的协作感知挑战，为高效、可扩展的多代理融合设定了新基准。

> **ai_Abstract:** 本论文提出了一种新颖的后期协作感知框架，旨在解决自动驾驶中现有协作感知方法对高带宽和模型访问的依赖问题。该框架仅通过共享3D边界框属性进行多源和多目标融合，无需访问底层的检测模型。实验结果显示，该方法在后期融合方面达到了最先进的性能，显著降低了位置、尺度和方向误差，并保持了完美的精确度和召回率，证明了其在实际应用中的高效性和可扩展性。

> **摘要翻译:** 在自动驾驶中，最近的研究越来越多地关注基于深度学习的协作感知，以克服单个感知系统的局限性。尽管这些方法实现了高精度，但它们依赖于高通信带宽，并要求无限制地访问每个代理的目标检测模型架构和参数。这些限制对现实世界的自动驾驶场景构成了挑战，其中通信限制和保护专有模型的需要阻碍了实际实施。为了解决这个问题，我们引入了一种新颖的后期协作框架，用于3D多源和多目标融合，该框架仅基于共享的3D边界框属性——类别、大小、位置和方向——进行操作，而无需直接访问检测模型。我们的框架在后期融合方面建立了新的最先进水平，与现有方法相比，实现了高达五倍的位置误差降低。此外，它将尺度误差降低了7.5倍，方向误差降低了一半，同时在融合来自异构感知系统的检测结果时保持了完美的100%精确度和召回率。这些结果突出了我们方法在解决现实世界协作感知挑战方面的有效性，为高效和可扩展的多代理融合设定了新基准。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [196] [DigiT4TAF -- Bridging Physical and Digital Worlds for Future Transportation Systems](https://arxiv.org/abs/2507.02400)
> *DigiT4TAF -- 连接物理与数字世界，助力未来交通系统*

*Maximilian Zipfl, Pascal Zwick, Patrick Schulz, Marc Rene Zofka, Albert Schotschneider, Helen Gremmelmaier, Nikolai Polley, Ferdinand Mütsch, Kevin Simon, Fabian Gottselig, Michael Frey, Sergio Marschall, Akim Stark, Maximilian Müller, Marek Wehmer, Mihai Kocsis, Dominic Waldenmayer, Florian Schnepf, Erik Heinrich, Sabrina Pletz, Matthias Kölle, Karin Langbein-Euchner, Alexander Viehl, Raoul Zöllner, J. Marius Zöllner* | **Category: cs.RO, cs.HC** | **Updated: {updated}**

**Keywords:** 数字孪生, 交通系统, 自动驾驶, V2X, 交通模拟

**Comment:** Accepted at the IEEE IAVVC 2025 Conference

> **TL;DR:** 论文描述了为德国自动驾驶测试区TAF-BW开发数字孪生的过程，通过数字重建基础设施和交通数据，利用V2X和传感器数据，实现实时模拟和分析，以优化交通流和安全。

**AI_Comments:** 这篇论文为真实世界的测试区提供了一个数字孪生的实际实现，对未来的交通研究很有价值。结合各种传感器数据和V2X基础设施来生成数据是一个亮点。将框架公开发布对研究社区做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 未来的交通将深受数字化影响，需要数字孪生技术连接真实与虚拟环境，以实现高度互联的道路使用者和基础设施。

**Method:** 通过数字重建TAF-BW的数字孪生。利用智能基础设施的摄像头图像和测试车辆的激光雷达传感器，提取交叉路口的对象列表，生成真实数据。通过统一接口，可重新模拟真实交通参与者的检测数据。论文还讨论了仿真框架的设计和重建过程。

**Result:** 开发了一个用于TAF-BW的数字孪生框架（DigiT4TAF），并已公开发布。通过两个案例研究进行了演示：交通信号系统分析以优化交通流，以及通信领域安全相关场景的模拟。

**Conclusion:** 论文成功开发并展示了用于未来交通系统的数字孪生框架DigiT4TAF，实现了真实与虚拟环境的持续连接，可用于交通优化和安全分析。

> **ai_Abstract:** 本文介绍了DigiT4TAF，一个用于德国巴登-符腾堡州自动驾驶测试区（TAF-BW）的数字孪生系统。论文详细阐述了数字重建过程，利用V2X基础设施、智能交叉路口摄像头和车载激光雷达传感器生成真实的交通数据。该框架允许重新模拟真实世界中的检测，并已公开发布。通过两个案例研究展示了其在优化交通流和模拟安全场景中的应用，突出了其在未来交通系统中连接物理与数字世界的作用。

> **摘要翻译:** 未来，交通将深受数字化日益普及的影响。届时，不仅个体道路使用者将高度互联，道路及相关基础设施也将如此。此时，数字孪生变得尤为吸引人，因为它与基础模拟不同，提供了一个连接真实与虚拟环境的持续双向连接。本文描述了用于开发德国巴登-符腾堡州自动驾驶测试区（TAF-BW）数字孪生的数字重建过程。TAF-BW提供了各种不同的路段，从交通繁忙的城市交叉路口和隧道到多车道高速公路。该测试区配备了全面的车联网（V2X）通信基础设施和多个配备摄像头传感器的智能交叉路口，以方便实时交通流监测。通过从交叉路口提取物体列表，并结合利用智能基础设施的摄像头图像和测试车辆上安装的激光雷达传感器，实现了为数字孪生生成真实数据。通过统一接口，可以重新模拟真实世界中交通参与者的检测记录。此外，论文还讨论了仿真框架的设计和重建过程。所得到的框架已在https://digit4taf-bw.fzi.de 公开提供下载和使用。该演示通过两个案例研究说明了数字孪生及其接口的应用：分析交通信号系统以优化交通流，以及模拟通信领域的安全相关场景。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [222] [MISC: Minimal Intervention Shared Control with Guaranteed Safety under Non-Convex Constraints](https://arxiv.org/abs/2507.02438)
> *MISC：非凸约束下保证安全的最小干预共享控制*

*Shivam Chaubey, Francesco Verdoja, Shankar Deka, Ville Kyrki* | **Category: cs.RO, cs.HC, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 共享控制, 非凸约束, 控制不变集, 约束最优控制, 用户研究

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 提出一种名为MISC的共享控制框架，通过结合约束最优控制和离线计算的控制不变集，在非凸约束下保证安全性和可行性，同时最小化对用户意图的干预，并通过大规模用户研究验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了一个结合约束最优控制和控制不变集的新型共享控制框架MISC，能够有效处理现实世界中常见的非凸约束，并保证严格的安全性和最小的用户干预。其重要性在于通过大规模用户研究验证了其在提升用户体验和系统性能方面的显著效果，为辅助机器人、远程操作和自动驾驶等领域提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有共享控制方法（如模型预测控制、控制障碍函数或学习型控制）在处理用户输入不可预测性时，存在可行性、可扩展性或安全保障方面的挑战，尤其是在非凸约束下。

**Method:** 提出一个基于约束最优控制问题（Constrained Optimal Control Problem）的辅助控制器框架，该框架结合了离线计算的控制不变集（Control Invariant Set），以实现在线计算控制动作，确保可行性、严格约束满足和最小化对用户意图的干预。该框架还能处理常见的非凸约束。通过一项涉及66名参与者的大规模用户研究在计算机游戏环境中验证了该方法。

**Result:** 研究结果显示，在不损害安全性和用户意图的情况下，任务负荷、信任、感知控制和性能方面均有持续改进。

**Conclusion:** MISC框架能够有效解决现有共享控制方法的挑战，在确保安全和最小干预的同时，显著提升用户体验和系统性能，尤其适用于存在非凸约束的复杂实际场景。

> **ai_Abstract:** 本文提出了一种名为MISC的最小干预共享控制框架，旨在解决现有方法在处理不可预测用户输入和非凸约束时面临的可行性、可扩展性和安全保障挑战。MISC基于约束最优控制问题，并利用离线计算的控制不变集，实现在线安全控制，确保严格的约束满足和最小化对用户意图的干预。通过一项包含66名参与者的大规模用户研究，验证了该方法在提升任务负荷、信任、感知控制和性能方面的有效性，同时保持了安全性。

> **摘要翻译:** 共享控制结合了人类意图和自主决策，从低级安全覆盖到高级任务指导，使系统能够适应用户，同时确保安全和性能。这增强了辅助机器人、远程操作和自动驾驶等领域中的任务有效性和用户体验。然而，现有的共享控制方法，例如基于模型预测控制（Model Predictive Control）、控制障碍函数（Control Barrier Functions）或基于学习的控制，在可行性、可扩展性或安全保证方面存在困难，特别是由于用户输入是不可预测的。
为了解决这些挑战，我们提出了一种基于约束最优控制问题（Constrained Optimal Control Problem）的辅助控制器框架，该框架结合了离线计算的控制不变集（Control Invariant Set），从而能够在线计算控制动作，确保可行性、严格约束满足以及对用户意图的最小干预。此外，该框架可以适应在现实世界场景中常见的结构化非凸约束。我们通过一项涉及66名参与者的大规模用户研究验证了该方法——这是共享控制研究中规模最大的研究之一——使用计算机游戏环境来评估任务负荷、信任和感知控制，以及性能。结果表明，在不损害安全性和用户意图的情况下，所有这些方面都得到了持续改进。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [233] [HAC-LOCO: Learning Hierarchical Active Compliance Control for Quadruped Locomotion under Continuous External Disturbances](https://arxiv.org/abs/2507.02447)
> *HAC-LOCO: 用于四足机器人连续外部扰动下运动的层次主动柔顺控制学习*

*Xiang Zhou, Xinyu Zhang, Qingrui Zhang* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 四足机器人, 柔顺控制, 层次学习, 外部扰动, 力估计

**Comment:** 8 pages, 7 Figures

> **TL;DR:** 本文提出一种两阶段层次学习框架HAC-LOCO，通过力估计实现四足机器人对外部扰动的主动柔顺控制，平衡鲁棒性和柔顺性，提高能效和安全性。

**AI_Comments:** 本文的创新点在于提出了一个两阶段的层次学习框架，特别是引入了基于力估计的主动柔顺控制。这使得四足机器人能够在保证鲁棒性的同时，提高应对外部扰动的柔顺性，解决了现有方法过于僵硬和能效低下的问题。其结合了学习型力估计和受阻抗控制启发的柔顺动作模块，实现了鲁棒性与柔顺性的平衡，对四足机器人在复杂环境下的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管四足机器人控制取得了显著成就，但在存在不可预见的外部扰动时，仍难以确保鲁棒和柔顺的运动。现有方法优先考虑鲁棒性，导致僵硬、高频运动和能源效率低下。

**Method:** 本文提出一个两阶段层次学习框架。第一阶段，训练速度跟踪策略和自编码器以提取本体感觉特征，并通过监督学习训练神经网络估计器来估计身体速度和外部力。第二阶段，基于预训练的编码器和策略，学习一个受阻抗控制启发的柔顺动作模块，该模块根据实时力估计主动调整速度指令以响应外部力。

**Result:** 模拟和真实世界实验表明，该方法在鲁棒性、能源效率和安全性方面表现优越，并优于最先进的基于强化学习的运动控制器。消融研究证明了柔顺动作模块的关键作用。

**Conclusion:** 通过引入柔顺动作模块，HAC-LOCO框架使四足机器人能够平衡鲁棒性和柔顺性，有效处理外部扰动，实现更鲁棒、节能和安全的运动。

> **ai_Abstract:** 本文提出HAC-LOCO，一个用于四足机器人运动的两阶段层次学习框架，旨在解决现有方法在外部扰动下鲁棒性与柔顺性平衡不佳的问题。该框架通过力估计和受阻抗控制启发的柔顺动作模块，使机器人能够主动响应外部力，在处理轻微扰动时保持鲁棒性，面对显著力时适当顺应。实验证明，HAC-LOCO在鲁棒性、能效和安全性上均优于现有先进方法。

> **摘要翻译:** 尽管四足机器人控制最近取得了显著成就，但在存在不可预见的外部扰动的情况下，确保鲁棒和柔顺的运动仍然具有挑战性。现有方法优先考虑运动的鲁棒性而非柔顺性，这通常导致僵硬、高频运动和能源效率低下。因此，本文提出了一种两阶段的层次学习框架，该框架可以学习基于力估计对外部力扰动采取主动反应。在第一阶段，训练一个速度跟踪策略和一个自编码器，以提取历史本体感觉特征。通过监督学习训练一个基于神经网络的估计器，该估计器根据本体感觉测量估计身体速度和外部力。在第二阶段，基于预训练的编码器和策略，学习一个受阻抗控制启发的柔顺动作模块。该模块用于根据实时力估计主动调整速度指令以响应外部力。通过柔顺动作模块，四足机器人可以鲁棒地处理轻微扰动，同时适当地顺应显著力，从而在鲁棒性和柔顺性之间取得平衡。仿真和真实世界实验表明，我们的方法在鲁棒性、能源效率和安全性方面具有卓越的性能。实验比较表明，我们的方法优于最先进的基于强化学习的运动控制器。消融研究表明了柔顺动作模块的关键作用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [244] [Safe and Socially Aware Multi-Robot Coordination in Multi-Human Social Care Settings](https://arxiv.org/abs/2507.02521)
> *多人类社会护理环境中安全且具有社会意识的多机器人协调*

*Ayodeji O. Abioye, Jayati Deshmukh, Athina Georgara, Dominic Price, Tuyen Nguyen, Aleksandra Landowska, Amel Bennaceur, Joel E. Fischer, Sarvapali D. Ramchurn* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 多机器人协调, 多人类环境, 社会护理, 多目标学习, 人机交互

**Comment:** 3 pages, 1 figure. Accepted for poster presentation at the UK AI
  Research Symposium (UKAIR) 2025, themed "A Festival of Ideas", being held in
  Newcastle from 8th - 9th September, 2025. https://www.ukairs.ac.uk/

> **TL;DR:** 本研究提出了一种基于多目标学习的协调方法，用于解决多人类多机器人（MHMR）环境中路径规划、导航、任务调度、任务分配和人机交互等问题。

**AI_Comments:** 该论文的创新点在于提出了一种基于多目标学习的协调方法，以同时处理多机器人系统中在多人类环境下的复杂问题，如路径规划、任务分配和人机交互，这对于社会护理等应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决多人类多机器人（MHMR）环境中路径规划、导航、任务调度、任务分配以及人机交互等方面的复杂协调问题。

**Method:** 提出了一种基于多目标学习的协调方法，以应对多人类多机器人（MHMR）环境中的多方面问题，包括路径规划、导航、任务调度、任务分配和人机交互。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究提出了一种针对多人类多机器人（MHMR）环境的协调方法。该方法基于多目标学习，旨在解决路径规划、导航、任务调度、任务分配以及人机交互等关键问题，以实现安全且具有社会意识的多机器人协调。

> **摘要翻译:** 本研究探讨了多人类环境中的多机器人协调策略。它提出了一种基于多目标学习的协调方法，以解决多人类多机器人（MHMR）环境中的路径规划、导航、任务调度、任务分配和人机交互问题。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [253] [Vibration of Soft, Twisted Beams for Under-Actuated Quadrupedal Locomotion](https://arxiv.org/abs/2507.02547)
> *欠驱动四足运动中软扭曲梁的振动*

*Yuhao Jiang, Fuchen Chen, Jamie Paik, Daniel M. Aukes* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 欠驱动机器人, 四足运动, 柔性梁, 振动驱动, Flix-Walker

**Comment:** This manuscript is under revision for possible publication in the
  IEEE/ASME Transactions on Mechatronics. Copyright may be transferred to IEEE
  if the manuscript is accepted for publication, without further notice.
  Supplementary videos: https://youtu.be/T3d6FT3Rx-s,
  https://youtu.be/nPQrhKlN02E

> **TL;DR:** 本文介绍了Flix-Walker，一种新型的欠驱动厘米级四足机器人，其腿部采用柔性螺旋梁，仅由两个电机振动驱动，实现了三种不同的运动模式，并通过仿真和实验验证了其有效性和鲁棒性。

**AI_Comments:** 本文的创新之处在于利用柔性螺旋梁和简单的振动驱动实现了复杂的四足运动，这为欠驱动机器人设计提供了一种新颖且高效的方法。其在厘米级尺度上实现多种运动模式和自主导航的能力，对于小型机器人领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 欠驱动柔顺机器人系统通过利用预先设计的、具身化的动态行为，为缓解驱动和控制挑战提供了一种有前景的方法。

**Method:** 本文提出了Flix-Walker机器人，它采用柔性螺旋形梁作为腿部，仅由两个电机振动驱动以实现三种不同的移动模式。通过仿真和原型实验分析了生成各种运动模式所需的驱动参数。研究了系统和环境变化对运动性能的影响，并提出了一种选择控制参数以产生鲁棒和功能性运动的通用指标。

**Result:** Flix-Walker机器人仅由两个电机振动驱动，实现了三种不同的移动模式。实验验证了这些驱动参数在闭环控制框架内的有效性和鲁棒性，展示了可靠的轨迹跟踪和自主导航能力。

**Conclusion:** Flix-Walker机器人通过柔性螺旋梁和振动驱动，成功展示了欠驱动四足机器人的多种运动模式和可靠的控制能力。

> **ai_Abstract:** 本文介绍了一种名为Flix-Walker的新型厘米级欠驱动四足机器人。该机器人利用柔性螺旋形腿，仅通过两个电机的振动就能实现三种不同的运动模式。研究通过仿真和实验分析了驱动参数，并提出了一个选择鲁棒控制参数的通用指标。实验结果验证了所提出参数在闭环控制下实现可靠轨迹跟踪和自主导航的有效性和鲁棒性。

> **摘要翻译:** 欠驱动柔顺机器人系统通过利用预先设计的、具身化的动态行为，为缓解驱动和控制挑战提供了一种有前景的方法。本文介绍了Flix-Walker，一种新型的、无束缚的厘米级四足机器人，其灵感来源于柔顺欠驱动机制。Flix-Walker采用柔性螺旋形梁作为腿部，仅由两个电机振动驱动以实现三种不同的移动模式。我们通过仿真和原型实验分析了生成各种运动模式所需的驱动参数。研究了系统和环境变化对运动性能的影响，并提出了一种选择控制参数以产生鲁棒和功能性运动的通用指标。实验验证了这些驱动参数在闭环控制框架内的有效性和鲁棒性，展示了可靠的轨迹跟踪和自主导航能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [263] [ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects](https://arxiv.org/abs/2507.02600)
> *ArtGS：用于铰接对象交互式视觉-物理建模和操作的3D高斯泼溅*

*Qiaojun Yu, Xibin Yuan, Yu jiang, Junting Chen, Dongzhe Zheng, Ce Hao, Yang You, Yixing Chen, Yao Mu, Liu Liu, Cewu Lu* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 3D Gaussian Splatting, Articulated Objects, Robotics, Visual-Physical Modeling, Manipulation

**Comment:** Accepted by IROS 2025

> **TL;DR:** ArtGS通过将视觉-物理建模集成到3D高斯泼溅中，解决了铰接对象操作的挑战，并在关节估计精度和操作成功率方面显著优于现有方法。

**AI_Comments:** ArtGS的创新之处在于将3D高斯泼溅与视觉-物理建模相结合，以解决铰接对象操作中的复杂运动学和物理推理问题。其利用VLM提取语义信息和动态3DGS优化骨骼参数的方法，提供了一个新颖且高效的解决方案。该框架在模拟和真实世界环境中的优异表现，显示了其在机器人操作领域的巨大潜力，特别是在提高关节估计精度和操作成功率方面。

<details>
  <summary>Details</summary>

**Motivation:** 由于复杂的运动学约束和现有方法有限的物理推理能力，铰接对象操作在机器人领域仍然是一个严峻的挑战。

**Method:** ArtGS是一个新颖的框架，通过集成视觉-物理建模来扩展3D高斯泼溅（3DGS），以实现铰接对象的理解和交互。它首先进行多视图RGB-D重建，然后利用视觉-语言模型（VLM）进行推理以提取语义和结构信息（特别是铰接骨骼）。通过动态、可微分的基于3DGS的渲染，ArtGS优化了铰接骨骼的参数，确保了物理上一致的运动约束并增强了操作策略。该方法利用动态高斯泼溅、跨实体适应性和闭环优化。

**Result:** 在模拟和真实世界环境中进行的实验表明，ArtGS在各种铰接对象的关节估计精度和操作成功率方面显著优于以前的方法。

**Conclusion:** ArtGS为高效、可扩展和通用化的铰接对象建模和操作建立了一个新框架。

> **ai_Abstract:** ArtGS是一个新颖的框架，通过将视觉-物理建模集成到3D高斯泼溅(3DGS)中，解决了机器人领域中铰接对象操作的挑战。它利用多视图RGB-D重建和视觉-语言模型提取结构信息，并通过动态可微分的3DGS渲染优化铰接骨骼参数，以确保物理一致性并增强操作策略。实验证明，ArtGS在关节估计精度和操作成功率方面显著优于现有方法，为高效、可扩展和通用化的铰接对象建模和操作提供了新途径。

> **摘要翻译:** 由于复杂的运动学约束和现有方法有限的物理推理能力，铰接对象操作在机器人领域仍然是一个严峻的挑战。在这项工作中，我们引入了ArtGS，这是一个新颖的框架，通过集成视觉-物理建模来扩展3D高斯泼溅（3DGS），以实现铰接对象的理解和交互。ArtGS首先进行多视图RGB-D重建，然后利用视觉-语言模型（VLM）进行推理，以提取语义和结构信息，特别是铰接骨骼。通过动态、可微分的基于3DGS的渲染，ArtGS优化了铰接骨骼的参数，确保了物理上一致的运动约束并增强了操作策略。通过利用动态高斯泼溅、跨实体适应性和闭环优化，ArtGS为高效、可扩展和通用化的铰接对象建模和操作建立了一个新框架。在模拟和真实世界环境中进行的实验表明，ArtGS在各种铰接对象的关节估计精度和操作成功率方面显著优于以前的方法。更多图片和视频可在项目网站上获取：https://sites.google.com/view/artgs/home

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [270] [MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping](https://arxiv.org/abs/2507.02672)
> *MISCGrasp：利用多尺度集成和对比学习增强体积抓取*

*Qingyu Fan, Yinghao Cai, Chao Li, Chunting Jiao, Xudong Zheng, Tao Lu, Bin Liang, Shuo Wang* | **Category: cs.RO, cs.CV** | **Updated: {updated}**

**Keywords:** 体积抓取, 多尺度特征, 对比学习, 机器人抓取, 自适应抓取

**Comment:** IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS), 2025

> **TL;DR:** MISCGrasp是一种新的体积抓取方法，它结合了多尺度特征提取和对比特征增强，以实现对不同形状和尺寸物体的自适应抓取，并在模拟和现实环境中表现出色。

**AI_Comments:** MISCGrasp的创新之处在于其结合了多尺度特征提取、两种Transformer（Insight和Empower）以及多尺度对比学习，以实现对复杂几何形状的鲁棒抓取。这种多层次的特征处理和一致性保证机制，使其能够有效地处理不同尺寸和形状的物体，并在实际应用中展现出优越性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人抓取面临难以适应不同形状和大小物体的挑战。

**Method:** 本文引入了MISCGrasp，一种体积抓取方法，它集成了多尺度特征提取和对比特征增强以实现自适应抓取。该方法提出了通过Insight Transformer在高层和低层特征之间进行基于查询的交互，同时Empower Transformer选择性地关注最高层特征，这协同地平衡了对精细几何细节和整体几何结构的关注。此外，MISCGrasp利用多尺度对比学习来利用正抓取样本之间的相似性，确保多尺度特征之间的一致性。

**Result:** 在模拟和现实环境中的大量实验表明，MISCGrasp在桌面清理任务中优于基线和变体方法。

**Conclusion:** MISCGrasp通过结合多尺度特征提取和对比学习，显著提升了机器人对不同形状和大小物体的体积抓取能力。

> **ai_Abstract:** MISCGrasp是一种创新的体积抓取方法，旨在解决机器人抓取中适应不同形状和尺寸物体的挑战。它通过整合多尺度特征提取和对比特征增强来实现自适应抓取。该方法引入了Insight Transformer和Empower Transformer，以平衡对精细细节和整体结构的关注，并利用多尺度对比学习确保特征一致性。实验证明，MISCGrasp在模拟和现实桌面清理任务中均优于现有方法。

> **摘要翻译:** 机器人抓取面临适应不同形状和尺寸物体的挑战。本文介绍了MISCGrasp，一种体积抓取方法，它集成了多尺度特征提取和对比特征增强，以实现自适应抓取。我们提出了通过Insight Transformer在高层和低层特征之间进行基于查询的交互，同时Empower Transformer选择性地关注最高层特征，这协同地在关注精细几何细节和整体几何结构之间取得了平衡。此外，MISCGrasp利用多尺度对比学习来利用正抓取样本之间的相似性，确保多尺度特征之间的一致性。在模拟和现实环境中的大量实验表明，MISCGrasp在桌面清理任务中优于基线和变体方法。更多细节可在https://miscgrasp.github.io/上找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [278] [Integrating path-planning and control for robotic unicycles](https://arxiv.org/abs/2507.02700)
> *机器人独轮车的路径规划与控制集成*

*Máté B. Vizi, Dénes Tákács, Gábor Stépán, Gábor Orosz* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 路径规划, 机器人控制, 独轮车, 曲率优化, 数值模拟

**Comment:** 

> **TL;DR:** 本文提出了一种为机器人独轮车集成路径规划和控制的方法，通过将路径分段并优化弯曲部分的曲率，在数值模拟中展示了其性能。

**AI_Comments:** 本文的创新点在于将路径规划与控制紧密集成，并专门为机器人独轮车的独特运动学特性进行优化。特别是在曲线路径中考虑车轮打滑极限的曲率优化，对于独轮车的稳定性和性能至关重要。通过数值模拟验证了其有效性，为未来实际应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机是整合路径规划和控制，并特别关注机器人独轮车的独特需求。

**Method:** 本文提出了一种独轮车设计，能够加速/制动并执行各种机动。所提出的路径规划方法将路径分为直线和曲线部分，分别用于加速/制动和转弯机动。曲线部分的曲率剖面在考虑控制性能和车轮打滑极限的情况下进行了优化。

**Result:** 所提出的集成方法的性能通过数值模拟得到了验证。

**Conclusion:** 通过数值模拟验证了所提出的集成路径规划与控制方法在机器人独轮车上的有效性。

> **ai_Abstract:** 本文提出了一种针对机器人独轮车的集成路径规划与控制方法。该方法将路径划分为直线和曲线段，分别用于加速/制动和转弯。曲线段的曲率剖面经过优化，考虑了控制性能和车轮打滑限制。数值模拟验证了该集成方法的有效性。

> **摘要翻译:** 本文重点介绍了路径规划与控制的集成，并专门针对机器人独轮车的独特需求。文中提出了一种独轮车设计，该设计能够加速/制动并执行各种机动。所提出的路径规划方法将路径分为直线和曲线部分，分别用于加速/制动和转弯机动。曲线部分的曲率剖面在考虑控制性能和车轮打滑极限的情况下进行了优化。通过数值模拟验证了所提出的集成方法的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [286] [Optimizing Start Locations in Ergodic Search for Disaster Response](https://arxiv.org/abs/2507.02708)
> *优化灾害响应中遍历搜索的起始位置*

*Ananya Rao, Alyssa Hargis, David Wettergreen, Howie Choset* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 灾害响应, 机器人部署, 遍历搜索, 优化, 起始位置

**Comment:** 

> **TL;DR:** 在灾害响应中，优化机器人起始位置能显著提高搜索覆盖率。

**AI_Comments:** 本文提出了一种新颖的方法，解决了机器人灾害响应中一个关键且此前未被解决的问题，通过优化初始部署显著提高了搜索效率。对异构机器人能力的考虑增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在灾害响应场景中，有效部署机器人团队对于提高态势感知和增强搜救行动至关重要。以往研究已涉及机器人搜救，但机器人部署的起始位置优化问题尚未得到解决。

**Method:** 本文通过制定一个联合优化问题，解决了最优选择具有异构能力的机器人起始位置的问题。该方法在遍历优化框架中增加了一个约束，其最小值将机器人分配到起始位置，并针对异构机器人（具有不同传感和运动模式）进行了复杂适应。该方法假设可以从专家知识或航空图像中获取潜在的起始位置。

**Result:** 与使用固定起始位置的基线方法相比，本文提出的联合优化方法在覆盖性能方面取得了显著提升。在合成数据上，同质和异质团队的遍历度量平均提高了35.98%；在真实世界数据上，平均提高了31.91%。

**Conclusion:** 通过优化机器人起始位置，本文提出的联合优化方法在灾害响应中显著提高了搜索覆盖性能。

> **ai_Abstract:** 本文针对灾害响应中异构机器人团队起始位置优化这一未充分研究的问题，提出了一种解决方案。通过在遍历优化框架内建立一个联合优化问题，该方法能够为具有不同能力的机器人分配起始位置。实验结果表明，与使用固定起始点的基线方法相比，该方法在搜索覆盖率方面取得了显著提升（合成数据上提高35.98%，真实世界数据上提高31.91%）。

> **摘要翻译:** 在灾害响应场景中，有效部署机器人团队对于提高态势感知和增强搜救行动至关重要。机器人用于搜救已被研究，但机器人部署的起始位置问题尚未得到解决。这项工作通过制定一个联合优化问题，解决了最优选择具有异构能力的机器人起始位置的问题。为了确定起始位置，这项工作在遍历优化框架中增加了一个约束，其最小值将机器人分配到起始位置。当机器人是异构的（配备不同的传感和运动模式）时，这变得更具挑战性，因为并非所有机器人都在同一位置启动，并且应用了上述约束的更复杂适应。我们的方法假设可以访问潜在的起始位置，这可以从专家知识或航空图像中获得。我们通过将其与所有机器人使用固定起始位置的基线方法进行比较，实验评估了我们的联合优化方法的功效。我们的实验结果表明，在遍历度量方面，同质和异质团队在合成数据上平均提高了35.98%，在真实世界数据上平均提高了31.91%，覆盖性能显著提高。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [292] [Trajectory Optimization for Differential Drive Mobile Manipulators via Topological Paths Search and Arc Length-Yaw Parameterization](https://arxiv.org/abs/2507.02761)
> *差速驱动移动机械臂的轨迹优化：基于拓扑路径搜索和弧长-偏航角参数化*

*Long Xu, Choilam Wong, Mengke Zhang, Junxiao Lin, Fei Gao* | **Category: cs.RO** | **Updated: {updated}**

**Keywords:** 轨迹优化, 移动机械臂, 运动规划, 非完整系统, 拓扑路径

**Comment:** Technical Report

> **TL;DR:** 提出一种高效的分层运动规划方法，用于差速驱动移动机械臂的轨迹优化，结合拓扑路径搜索和弧长-偏航角参数化来处理非完整动力学。

**AI_Comments:** 本文的创新之处在于其分层方法，该方法结合了拓扑路径搜索以初步缩小搜索空间，并利用一种新颖的参数化（弧长-偏航角）进行并行优化，以高效处理非完整动力学。这对于移动机械臂的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为差速驱动移动机械臂开发一种高效的分层运动规划流程，以寻找最优且可行的全身轨迹，并有效处理非完整动力学。

**Method:** 该方法采用分层运动规划流程。首先，为移动基座搜索多个无碰撞且拓扑结构不同的路径，以提取可能存在最优解的空间。然后，并行进行进一步的采样和优化，以探索可行的全身轨迹。轨迹优化采用多项式轨迹和弧长-偏航角参数化，从而能够有效地处理非完整动力学。

**Result:** 该方法能够有效地处理非完整动力学，同时确保最优性。

**Conclusion:** 本文提出的方法通过结合拓扑路径搜索和弧长-偏航角参数化，实现了差速驱动移动机械臂的高效且最优的轨迹规划。

> **ai_Abstract:** 本文提出了一种用于差速驱动移动机械臂的高效分层运动规划框架。该框架首先通过为移动基座搜索拓扑结构不同且无碰撞的路径来界定潜在的最优解空间。随后，利用多项式轨迹和弧长-偏航角参数化进行并行采样和优化，以生成最优的全身轨迹，从而有效地管理非完整约束。

> **摘要翻译:** 我们提出了一种用于差速驱动移动机械臂的高效分层运动规划流程。我们的方法首先为移动基座搜索多个无碰撞且拓扑结构不同的路径，以提取可能存在最优解的空间。然后，并行进行进一步的采样和优化，以探索可行的全身轨迹。对于轨迹优化，我们采用多项式轨迹和弧长-偏航角参数化，从而能够有效地处理非完整动力学，同时确保最优性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [299] [MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real](https://arxiv.org/abs/2507.02864)
> *MultiGen：在模拟中使用多模态生成以在现实世界中学习多模态策略*

*Renhao Wang, Haoran Geng, Tingle Li, Feishi Wang, Gopala Anumanchipalli, Philipp Wu, Trevor Darrell, Boyi Li, Pieter Abbeel, Jitendra Malik, Alexei A. Efros* | **Category: cs.RO, cs.CV** | **Updated: {updated}**

**Keywords:** 多模态策略, 模拟到现实迁移, 生成模型, 多感官模拟, 机器人倾倒

**Comment:** 

> **TL;DR:** MultiGen通过将大规模生成模型集成到物理模拟器中，实现多感官模拟，从而解决了机器人多模态策略学习中的模拟-现实迁移难题，并在机器人倾倒任务中展示了其零样本迁移能力。

**AI_Comments:** MultiGen的创新之处在于将生成模型引入传统物理模拟器，解决了声音等难以高保真模拟的模态问题，从而弥补了多模态模拟到现实的鸿沟。其零样本迁移能力展示了该方法在实际应用中的巨大潜力，尤其是在数据采集困难或危险的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 机器人需要整合多种感官模态才能在现实世界中有效行动，但大规模学习多模态策略仍然具有挑战性。虽然视觉模态受益于高保真模拟器，但其他模态（如声音）很难模拟，导致多模态模拟到现实的迁移尚未实现。

**Method:** 引入MultiGen框架，将大规模生成模型集成到传统物理模拟器中，实现多感官模拟。具体通过合成基于模拟视频的真实音频，在丰富的视听轨迹上进行训练，无需真实机器人数据。

**Result:** 成功实现了对新容器和液体的真实世界倾倒任务的有效零样本迁移。

**Conclusion:** 生成建模具有模拟难以建模的模态并弥合多模态模拟-现实差距的潜力。

> **ai_Abstract:** 本文提出了MultiGen框架，旨在解决机器人多模态策略学习中模拟到现实的迁移难题。该框架将大规模生成模型整合到物理模拟器中，以实现多感官模拟，尤其解决了声音等难以模拟的模态问题。通过合成基于模拟视频的逼真音频，MultiGen使得在丰富的视听数据上进行训练成为可能，且无需真实机器人数据。在机器人倾倒任务中的实验表明，MultiGen能够实现对新容器和液体的有效零样本迁移，证明了生成模型在弥合多模态模拟-现实差距方面的巨大潜力。

> **摘要翻译:** 机器人必须整合多种感官模态才能在现实世界中有效行动。然而，大规模学习此类多模态策略仍然具有挑战性。模拟提供了一个可行的解决方案，但尽管视觉受益于高保真模拟器，其他模态（例如声音）却出了名的难以模拟。因此，模拟到现实的迁移主要在基于视觉的任务中取得成功，而多模态迁移仍未实现。在这项工作中，我们通过引入MultiGen来应对这些挑战，MultiGen是一个将大规模生成模型集成到传统物理模拟器中的框架，从而实现多感官模拟。我们在机器人倾倒的动态任务中展示了我们的框架，该任务本质上依赖于多模态反馈。通过根据模拟视频合成逼真的音频，我们的方法能够在丰富的视听轨迹上进行训练——无需任何真实机器人数据。我们展示了对新容器和液体的真实世界倾倒任务的有效零样本迁移，突出了生成建模在模拟难以建模的模态和弥合多模态模拟-现实差距方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [14] [Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges](https://arxiv.org/abs/2507.02074)
> *大语言模型在视频碰撞检测中的应用：方法、数据集与挑战综述*

*Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 大语言模型, 视频碰撞检测, 视觉语言模型, 智能交通系统, 综述

**Comment:** 

> **TL;DR:** 这篇综述探讨了如何利用大语言模型（LLMs）和视觉语言模型（VLMs）进行视频碰撞检测，总结了现有方法、数据集、模型架构，并讨论了挑战与机遇。

**AI_Comments:** 这篇综述论文提供了一个及时且全面的视角，聚焦于LLMs/VLMs在视频碰撞检测这一重要应用中的潜力。其结构化的分类和对挑战的讨论对于指导未来研究方向具有重要价值，尤其是在视频理解与基础模型融合的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 视频流中的碰撞检测是智能交通系统中的一个关键问题。大语言模型（LLMs）和视觉语言模型（VLMs）的最新发展改变了多模态信息的处理、推理和总结方式，为解决这一问题提供了新途径。

**Method:** 本文综述了利用LLMs进行视频碰撞检测的最新方法。具体包括：提出融合策略的结构化分类、总结关键数据集、分析模型架构、比较性能基准、讨论现有挑战和机遇。

**Result:** 本综述提供了一个融合策略的结构化分类，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了持续存在的挑战和机遇。

**Conclusion:** 本综述为视频理解和基础模型这一快速发展交叉领域中的未来研究奠定了基础。

> **ai_Abstract:** 这篇综述论文系统地审视了利用大语言模型和视觉语言模型进行视频碰撞检测的现有方法。它构建了融合策略的分类，归纳了主要数据集，剖析了模型架构，对比了性能，并指出了该领域面临的挑战和发展机遇，旨在为未来的研究提供坚实基础。

> **摘要翻译:** 视频流中的碰撞检测是智能交通系统中的一个关键问题。大语言模型（LLMs）和视觉语言模型（VLMs）的最新发展改变了我们处理、推理和总结多模态信息的方式。本文综述了利用LLMs从视频数据中进行碰撞检测的最新方法。我们提出了融合策略的结构化分类，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了持续存在的挑战和机遇。我们的综述为视频理解和基础模型这一快速增长交叉领域的未来研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [36] [Detecting Multiple Diseases in Multiple Crops Using Deep Learning](https://arxiv.org/abs/2507.02517)
> *使用深度学习检测多种作物中的多种病害*

*Vivek Yadav, Anugrah Jain* | **Category: cs.CV, cs.AI, cs.ET** | **Updated: {updated}**

**Keywords:** 深度学习, 作物病害检测, 印度农业, 多作物, 统一数据集

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习的解决方案，用于检测印度多种作物中的多种病害，其检测准确率显著提高，并覆盖了更多作物和病害类型。

**AI_Comments:** 该论文的创新点在于构建了一个大规模的统一数据集，涵盖了比现有技术更多的作物和病害种类。其重要性在于为印度农业提供了更全面的病害检测解决方案，有望显著提高作物产量和粮食安全。模型的99%准确率表明了其强大的实用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 印度作为农业主导经济体，面临作物病害、虫害和环境胁迫导致的严重作物损失。早期准确检测不同作物的病害对于提高产量和确保粮食安全至关重要。

**Method:** 本文提出了一种基于深度学习的解决方案。首先，创建了一个统一的数据集，其中包含来自不同可用存储库的17种不同作物和34种不同病害的图像。然后，在该数据集上训练所提出的深度学习模型。

**Result:** 所提出的深度学习模型在准确性和覆盖的作物及病害数量方面均优于现有技术。统一数据集的检测准确率达到99%，比现有技术（处理14种作物和26种不同病害）高出7%。

**Conclusion:** 通过增加可检测的作物和病害类型数量，所提出的解决方案旨在为印度农民提供更好的产品，以应对农业挑战，提高产量和粮食安全。

> **ai_Abstract:** 本文提出了一种基于深度学习的系统，用于在印度检测多种作物中的多种病害。通过整合来自不同来源的图像，创建了一个包含17种作物和34种病害的统一数据集。在该数据集上训练的深度学习模型，其检测准确率达到99%，并显著超越了现有技术在覆盖作物和病害数量上的表现，旨在为印度农民提供更有效的病害管理工具。

> **摘要翻译:** 印度作为一个主要的农业经济体，在农业方面面临严峻挑战，包括由病害、虫害和环境胁迫造成的巨大作物损失。早期发现和准确识别不同作物中的病害对于提高产量和确保粮食安全至关重要。本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种病害，旨在覆盖印度多样化的农业景观。我们首先创建了一个统一的数据集，其中包含来自各种可用存储库的17种不同作物和34种不同病害的图像。所提出的深度学习模型在该数据集上进行训练，并在准确性以及覆盖的作物和病害数量方面优于现有技术。我们的统一数据集实现了显著的检测准确率，即99%，与现有技术（仅处理14种作物和26种不同病害）相比提高了7%。通过增加可检测作物和病害的种类数量，所提出的解决方案旨在为印度农民提供更好的产品。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [43] [Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning](https://arxiv.org/abs/2507.02148)
> *水下单目度量深度估计：真实世界基准与合成微调*

*Zijie Cai, Christopher Metzler* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 水下深度估计, 单目, 领域适应, 深度估计, 基准测试

**Comment:** 

> **TL;DR:** 本文评估了水下环境中单目度量深度估计模型的性能，发现陆地模型表现不佳，并通过在合成水下数据集上微调Depth Anything V2显著提高了水下深度估计的准确性。

**AI_Comments:** 该论文通过构建真实世界水下基准和引入合成数据微调策略，有效解决了水下单目深度估计的领域适应难题。其创新点在于利用物理模型生成高质量的合成水下数据，为缺乏真实标注数据的难题提供了有效的解决方案。这项工作对于推动水下机器人、水下测绘等领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 单目深度估计在水下环境中的可靠性受限，原因包括光衰减、散射、颜色失真、浑浊以及缺乏高质量的度量真值数据。

**Method:** 作者首先在FLSea和SQUID等真实世界水下数据集上，对零样本和微调的单目度量深度估计模型进行了全面基准测试。为了解决领域偏移问题，作者使用基于物理的水下图像形成模型生成了Hypersim数据集的合成水下变体，并用此数据集微调了带有ViT-S骨干编码器的Depth Anything V2模型。

**Result:** 陆地数据训练的大型模型在水下表现不佳。作者微调后的模型在所有基准测试中持续提高了性能，并优于仅在干净的陆地Hypersim数据集上训练的基线模型。

**Conclusion:** 在水下场景中实现鲁棒和可泛化的度量深度预测，领域适应和尺度感知监督至关重要。

> **ai_Abstract:** 本文针对水下环境下单目度量深度估计面临的挑战，如光衰减和缺乏高质量数据，进行了深入研究。作者首先在真实水下数据集上对现有模型进行了基准测试，发现陆地训练的模型在水下表现不佳。为解决此问题，他们利用基于物理模型生成的合成水下数据集微调了Depth Anything V2模型。实验结果表明，该微调模型显著提升了水下深度估计的准确性，强调了领域适应和尺度感知监督在水下深度估计中的关键作用。

> **摘要翻译:** 单目深度估计最近取得了进展，不仅能提供相对深度预测，还能提供度量深度预测。然而，由于光衰减和散射、颜色失真、浑浊以及缺乏高质量的度量真值数据，其在水下环境中的可靠性仍然有限。在本文中，我们提出了一个在具有度量深度标注的真实世界水下数据集（如FLSea和SQUID）上，对零样本和微调的单目度量深度估计模型进行的全面基准测试。我们评估了一系列最先进的模型在不同范围的水下条件下的表现。我们的结果表明，在陆地（真实或合成）数据上训练的大规模模型，虽然在空中设置中有效，但由于显著的领域偏移，在水下表现不佳。为了解决这个问题，我们使用基于物理的水下图像形成模型生成的Hypersim数据集的合成水下变体，对带有ViT-S骨干编码器的Depth Anything V2进行了微调。我们证明了我们微调后的模型在所有基准测试中持续提高了性能，并且优于仅在干净的空中Hypersim数据集上训练的基线模型。我们的研究为水下场景中的单目度量深度估计提供了详细的评估和可视化，强调了领域适应和尺度感知监督对于在挑战性水下环境中实现鲁棒和可泛化的度量深度预测对未来研究的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [68] [ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.02200)
> *ESTR-CoT: 基于事件流的场景文本识别，通过思维链推理实现可解释和准确性*

*Xiao Wang, Jingtao Jiang, Qiang Chen, Lan Chen, Lin Zhu, Yaowei Wang, Yonghong Tian, Jin Tang* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: {updated}**

**Keywords:** 事件流, 场景文本识别, 思维链推理, 大型语言模型, 可解释性

**Comment:** A Strong Baseline for Reasoning based Event Stream Scene Text
  Recognition

> **TL;DR:** 提出ESTR-CoT，一个基于思维链推理的事件流场景文本识别框架，通过结合视觉编码器和大型语言模型，提高了在挑战性场景下的识别准确性和可解释性，并构建了大型CoT数据集。

**AI_Comments:** 该论文的创新点在于首次将思维链推理引入事件流场景文本识别任务，并通过结合视觉模型和大型语言模型构建了一个端到端可训练的框架。同时，提出并构建了一个大规模的CoT数据集，为该领域未来基于推理的大模型研究奠定了数据基础，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有事件流场景文本识别方法（端到端编解码或LLM）在解释性和上下文逻辑推理方面存在不足，尤其在低光照和快速运动等极端挑战性场景下。

**Method:** 提出ESTR-CoT框架，采用EVA-CLIP (ViT-G/14) 将事件流转换为视觉token，Llama tokenizer编码生成提示，Q-former对齐视觉token到预训练的Vicuna-7B LLM，同时输出答案和思维链（CoT）推理过程。框架可通过监督微调端到端优化。此外，还提出了一个通过“生成、润色、专家验证”三阶段处理构建的大型CoT数据集。

**Result:** 在三个事件流STR基准数据集（EventSTR, WordArt*, IC15*）上的大量实验充分验证了所提框架的有效性和可解释性。

**Conclusion:** ESTR-CoT框架通过引入思维链推理，显著提升了事件流场景文本识别的准确性和可解释性，并且构建的CoT数据集为后续基于推理的大型模型发展提供了数据基础。

> **ai_Abstract:** 本文提出ESTR-CoT，一个创新的基于思维链（CoT）推理的事件流场景文本识别框架，旨在解决现有方法在解释性和逻辑推理上的不足。ESTR-CoT结合了视觉编码器EVA-CLIP和大型语言模型Vicuna-7B，通过Q-former进行对齐，能够同时输出识别结果和CoT推理过程。此外，研究还构建了一个大型CoT数据集以支持框架训练。在多个基准数据集上的实验证明了ESTR-CoT在准确性和可解释性方面的优越性。

> **摘要翻译:** 事件流场景文本识别是近年来新兴的研究课题，在极端挑战性场景，尤其是低光照和快速运动下，其性能优于广泛使用的RGB相机。现有工作要么采用端到端编解码器框架，要么采用大型语言模型来增强识别能力，然而，它们仍然受到解释性不足和上下文逻辑推理能力弱的限制。在这项工作中，我们提出了一种新颖的基于思维链推理的事件流场景文本识别框架，命名为ESTR-CoT。具体来说，我们首先采用视觉编码器EVA-CLIP (ViT-G/14) 将输入事件流转换为token，并利用Llama分词器编码给定的生成提示。使用Q-former将视觉token与预训练的大型语言模型Vicuna-7B对齐，并同时输出答案和思维链（CoT）推理过程。我们的框架可以通过端到端的监督微调进行优化。此外，我们还提出了一个大型CoT数据集，通过三阶段处理（即生成、润色和专家验证）来训练我们的框架。该数据集为后续基于推理的大型模型的发展提供了坚实的数据基础。在三个事件流STR基准数据集（即EventSTR、WordArt*、IC15*）上进行的大量实验充分验证了我们所提出框架的有效性和可解释性。源代码和预训练模型将发布在https://github.com/Event-AHU/ESTR-CoT。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [77] [Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk](https://arxiv.org/abs/2507.02477)
> *Mesh Silksong：自回归网格生成如织丝般*

*Gaochao Song, Zibo Zhao, Haohan Weng, Jingbo Zeng, Rongfei Jia, Shenghua Gao* | **Category: cs.CV, cs.GR** | **Updated: {updated}**

**Keywords:** Mesh Silksong, 自回归网格生成, 网格标记化, 几何特性, 压缩率

**Comment:** 9 pages main text, 14 pages appendix, 23 figures

> **TL;DR:** Mesh Silksong 是一种新的网格表示方法，通过一次性访问顶点来减少冗余并提高压缩率，同时生成具有优越几何特性的多边形网格。

**AI_Comments:** Mesh Silksong 的创新之处在于其独特的单次顶点访问标记化策略，显著解决了现有网格标记化中顶点重复的问题，从而在压缩率和网络效率上取得了突破。此外，其对生成网格几何质量（如流形拓扑和水密性）的强调，使其在实际应用中具有更高的实用价值和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的网格标记化方法会产生带有重复顶点标记的标记序列，浪费网络能力，因此需要一种更紧凑高效的网格表示方法。

**Method:** 我们引入了 Mesh Silksong，这是一种紧凑高效的网格表示方法，通过仅访问每个网格顶点一次来标记网格顶点，从而减少标记序列的冗余并实现高压缩率。该方法以自回归方式生成多边形网格，并确保优越的几何特性，如流形拓扑、水密性检测和一致的面法线。

**Result:** Mesh Silksong 将标记序列的冗余减少了 50%，实现了约 22% 的最先进压缩率。它生成的多边形网格具有优越的几何特性，包括流形拓扑、水密性检测和一致的面法线。实验结果表明该方法能够生成复杂的网格并显著改善几何完整性。

**Conclusion:** Mesh Silksong 是一种有效且高效的自回归网格生成方法，通过优化网格标记化和表示，显著提高了压缩率和生成网格的几何质量，使其适用于实际应用。

> **ai_Abstract:** Mesh Silksong 提出了一种新颖的自回归网格生成方法，通过优化网格顶点标记化，实现了高达 50% 的冗余减少和 22% 的压缩率，超越了现有方法。该方法确保生成的网格具有优越的几何特性，如流形拓扑和水密性，对实际应用具有重要意义，并已通过实验验证其在复杂网格生成和几何完整性方面的有效性。

> **摘要翻译:** 我们引入了 Mesh Silksong，这是一种紧凑高效的网格表示方法，旨在以类似织丝的方式自回归地生成多边形网格。现有的网格标记化方法总是生成带有重复顶点标记的标记序列，浪费了网络能力。因此，我们的方法通过仅访问每个网格顶点一次来标记网格顶点，将标记序列的冗余减少了 50%，并实现了约 22% 的最先进压缩率。此外，Mesh Silksong 生成的多边形网格具有优越的几何特性，包括流形拓扑、水密性检测和一致的面法线，这对于实际应用至关重要。实验结果证明了我们方法的有效性，不仅展示了复杂的网格生成，而且显著改善了几何完整性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [93] [Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach](https://arxiv.org/abs/2507.02205)
> *Team RAS 在第九届 ABAW 竞赛中：多模态复合表情识别方法*

*Elena Ryumina, Maxim Markitantov, Alexandr Axyonov, Dmitry Ryumin, Mikhail Dolgushin, Alexey Karpov* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 复合表情识别, 多模态, 零样本学习, 情感计算, 表情识别

**Comment:** 8

> **TL;DR:** 本文提出了一种新颖的零样本多模态复合表情识别（CER）方法，结合了六种模态，并利用CLIP和Qwen-VL进行零样本组件，通过MHPF和CE转换模块进行预测，在无需领域适应的情况下取得了与监督方法相当的结果。

**AI_Comments:** 该论文的创新之处在于其零样本多模态方法，显著减少了对大量特定任务训练数据的需求，这是情感计算中的一个常见瓶颈。利用CLIP和Qwen-VL等预训练模型进行零样本理解，以及动态融合机制（MHPF），是其关键优势。其在无需领域适应的情况下表现出与监督方法相当的性能，突显了其强大的泛化能力和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 复合表情识别（CER）旨在检测由基本情绪组合形成的复杂情绪状态。传统方法依赖于特定任务的训练数据，本研究旨在提出一种无需领域适应的零样本多模态方法来解决这一问题。

**Method:** 本研究提出了一种新颖的零样本多模态复合表情识别（CER）方法，整合了六种异构模态：静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。该方法利用零样本组件，包括基于CLIP的标签匹配和用于语义场景理解的Qwen-VL。此外，引入了多头概率融合（MHPF）模块来动态加权特定模态的预测，并通过使用成对概率聚合（PPA）和成对特征相似性聚合（PFSA）方法的复合表情（CE）转换模块来生成可解释的复合情绪输出。

**Result:** 该方法在零样本测试下，于AffWild2数据集上取得了46.95%的F1分数，在Acted Facial Expressions in The Wild (AFEW)数据集上取得了49.02%的F1分数，在C-EXPR-DB数据集上取得了34.85%的F1分数。这些结果与在目标数据上训练的监督方法的结果相当。

**Conclusion:** 所提出的零样本多模态方法在无需领域适应的情况下，能够有效捕获复合表情（CE），证明了其强大的泛化能力和有效性。

> **ai_Abstract:** 本文提出了一种新颖的零样本多模态方法，用于复合表情识别（CER），该方法整合了六种不同的模态，并利用CLIP和Qwen-VL等零样本组件。该方法引入了多头概率融合（MHPF）模块和复合表情（CE）转换模块，以生成可解释的输出。通过在多个数据集上进行零样本测试，该方法取得了与监督方法相当的F1分数，证明了其在无需领域适应的情况下捕获复杂情绪的有效性。

> **摘要翻译:** 复合表情识别（CER）是情感计算的一个子领域，旨在检测由基本情绪组合形成的复杂情绪状态。在这项工作中，我们提出了一种新颖的零样本多模态CER方法，该方法将六种异构模态整合到一个单一的流程中：静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。与以往依赖特定任务训练数据的方法不同，我们的方法使用零样本组件，包括基于对比语言-图像预训练（CLIP）的标签匹配和用于语义场景理解的Qwen-VL。我们进一步引入了一个多头概率融合（MHPF）模块，该模块动态加权特定模态的预测，然后是一个复合表情（CE）转换模块，该模块使用成对概率聚合（PPA）和成对特征相似性聚合（PFSA）方法来生成可解释的复合情绪输出。在多语料库训练下进行评估，所提出的方法通过零样本测试在AffWild2上显示出46.95%的F1分数，在野外表演面部表情（AFEW）上显示出49.02%的F1分数，在C-EXPR-DB上显示出34.85%的F1分数，这与在目标数据上训练的监督方法的结果相当。这证明了所提出的方法在不需要领域适应的情况下捕获CE的有效性。源代码已公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [101] [HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars](https://arxiv.org/abs/2507.02803)
> *HyperGaussians：用于高保真可动画面部化身的高维高斯泼溅*

*Gent Serifi, Marcel C. Bühler* | **Category: cs.CV, cs.GR** | **Updated: {updated}**

**Keywords:** HyperGaussians, 3D高斯泼溅, 可动画面部化身, 高维, 逆协方差技巧

**Comment:** Project page: https://gserifi.github.io/HyperGaussians

> **TL;DR:** HyperGaussians是一种新颖的3D高斯泼溅扩展，用于创建高质量的可动画面部化身。它通过引入高维高斯和“逆协方差技巧”来解决非线性变形和精细细节问题，在数值和视觉上均优于3DGS。

**AI_Comments:** 本文的创新点在于重新思考了3D高斯表示本身，并将其扩展到高维空间，以捕捉更复杂的面部细节和动态。引入的“逆协方差技巧”巧妙地解决了高维高斯计算效率低下的问题，使其能够实际应用。这项工作在推动高保真可动画面部化身领域具有重要意义，有望在虚拟现实和增强现实等应用中提供更逼真、更具表现力的数字形象。

<details>
  <summary>Details</summary>

**Motivation:** 从视频创建详细的可动画面部化身是一个具有挑战性的问题，现有方法（如3DGS）在处理非线性变形、复杂光照效果和精细细节方面表现不佳，导致动画效果陷入“恐怖谷”。

**Method:** 本文提出了“HyperGaussians”，将3D高斯扩展到高维多元高斯，通过条件化可学习的局部嵌入来增加表达能力。为了解决高维协方差矩阵求逆带来的计算开销，引入了“逆协方差技巧”来重新参数化协方差矩阵，从而提高效率。该方法可无缝集成到现有模型中，并被应用于FlashAvatar。

**Result:** 在来自4个面部数据集的19个受试者上的评估显示，HyperGaussians在数值和视觉上均优于3DGS，尤其在处理高频细节方面表现出色，例如眼镜框、牙齿、复杂面部动作和镜面反射。

**Conclusion:** HyperGaussians为可动画面部化身提供了一种比3DGS更具表达能力和更高保真度的表示方法。其核心的“逆协方差技巧”有效解决了计算效率问题，使得该方法在处理复杂细节和动态表情时表现卓越。

> **ai_Abstract:** HyperGaussians是一种新颖的3D高斯泼溅扩展，旨在创建高保真可动画面部化身。它通过将3D高斯提升到高维多元高斯，并结合可学习的局部嵌入来增强表达能力，从而克服了现有方法（如3DGS）在处理非线性变形和精细细节方面的不足。为解决高维计算挑战，该方法引入了“逆协方差技巧”以提高效率。实验证明，HyperGaussians在数值和视觉上均优于3DGS，尤其在渲染复杂面部动作和高频细节方面表现卓越。

> **摘要翻译:** 我们引入了HyperGaussians，这是3D高斯泼溅的一种新颖扩展，用于创建高质量的可动画面部化身。从视频创建如此详细的面部化身是一个具有挑战性的问题，在增强现实和虚拟现实中具有众多应用。虽然静态面部取得了巨大成功，但从单目视频生成的可动画化身仍然陷入恐怖谷。事实上的标准，3D高斯泼溅（3DGS），通过一组3D高斯基元来表示面部。3DGS擅长渲染静态面部，但最先进的技术仍然难以处理非线性变形、复杂光照效果和精细细节。虽然大多数相关工作侧重于从表情代码预测更好的高斯参数，但我们重新思考了3D高斯表示本身以及如何使其更具表达力。我们的见解导致了3D高斯向高维多元高斯的新颖扩展，被称为“HyperGaussians”。更高的维度通过条件化可学习的局部嵌入来增加表达能力。然而，泼溅HyperGaussians计算成本高昂，因为它需要反转高维协方差矩阵。我们通过重新参数化协方差矩阵来解决这个问题，这被称为“逆协方差技巧”。这个技巧提高了效率，使得HyperGaussians可以无缝集成到现有模型中。为了证明这一点，我们将HyperGaussians插入到快速单目面部化身的最先进技术：FlashAvatar中。我们对来自4个面部数据集的19个受试者的评估表明，HyperGaussians在数值和视觉上均优于3DGS，特别是对于眼镜框、牙齿、复杂面部动作和镜面反射等高频细节。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [113] [From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images](https://arxiv.org/abs/2507.02781)
> *从像素到损害严重程度：利用社交媒体图像的语义分割评估地震影响*

*Danrong Zhang, Huili Huang, N. Simrill Smith, Nimisha Roy, J. David Frost* | **Category: cs.CV, cs.SI** | **Updated: {updated}**

**Keywords:** 地震影响, 损害严重程度, 语义分割, 社交媒体图像, 灾害侦察

**Comment:** 

> **TL;DR:** 本研究提出一种基于语义分割的新方法，用于客观量化地震后社交媒体图像中的损害严重程度，克服传统分类方法的局限性。

**AI_Comments:** 本研究的创新之处在于将地震损害评估从传统的分类方法提升为更精细的语义分割，实现了像素级的损害量化，克服了主观性限制。通过结合深度估计和新的评分系统，提高了评估的客观性和准确性，对灾害侦察和救援工作具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法在评估地震后社交媒体图像中的损害严重程度时，依赖分类方法，具有主观性且无法反映图像内损害程度的差异。为了解决这些局限性，本研究提出了新方法。

**Method:** 本研究将损害严重程度评估框架为语义分割问题。具体方法包括构建一个分割损害严重程度数据集，将损害分为未受损结构、受损结构和碎片三类。利用该数据集微调SegFormer模型以生成损害严重程度分割。此外，引入了一个新的损害严重程度评分系统，通过考虑图像内不同区域的损害程度并根据深度估计进行调整来量化损害。

**Result:** 该方法能够以更客观和全面的方式量化社交媒体图像中的损害严重程度。

**Conclusion:** 通过提供对损害的细致理解，本研究提高了为灾害侦察队提供精确指导的能力，从而促进了地震后更有效和有针对性的响应工作。

> **ai_Abstract:** 本研究针对传统地震损害评估方法的主观性和局限性，提出一种将损害严重程度评估视为语义分割问题的新方法。通过构建包含未受损结构、受损结构和碎片三类损害程度的分割数据集，并微调SegFormer模型，结合新的深度调整的损害评分系统，实现了对地震后社交媒体图像中损害严重程度的客观、细致和全面的量化，从而为灾害侦察和响应提供更精确的指导。

> **摘要翻译:** 在地震发生后，社交媒体图像已成为灾害侦察的重要资源，为损害范围提供了即时洞察。传统的地震后社交媒体图像损害严重程度评估方法通常依赖于分类方法，这些方法本质上是主观的，并且无法解释图像内不同程度的损害。为了解决这些局限性，本研究提出了一种新颖的方法，将损害严重程度评估视为语义分割问题，旨在对地震影响区域的损害进行更客观的分析。该方法涉及构建一个分段损害严重程度数据集，将损害分为三个等级：未受损结构、受损结构和碎片。利用该数据集，本研究对SegFormer模型进行了微调，以生成地震后社交媒体图像的损害严重程度分割。此外，引入了一种新的损害严重程度评分系统，通过考虑图像内不同区域的不同损害程度并根据深度估计进行调整来量化损害。这种方法的应用使得能够以更客观和全面的方式量化社交媒体图像中的损害严重程度。通过提供对损害的细致理解，本研究增强了为灾害侦察队提供精确指导的能力，从而促进了地震后更有效和有针对性的响应工作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [117] [SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers](https://arxiv.org/abs/2507.02212)
> *SciGA：一个用于设计学术论文中图文摘要的综合数据集*

*Takuro Kawada, Shunsuke Kitada, Sota Nemoto, Hitoshi Iyatomi* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: {updated}**

**Keywords:** 图文摘要, 数据集, 科学交流, 推荐系统, 人工智能

**Comment:** 21 pages, 15 figures, 4 tables. Project Page:
  https://iyatomilab.github.io/SciGA/

> **TL;DR:** SciGA-145k是一个大型数据集，包含14.5万篇论文和114万张图，旨在支持图文摘要的选择、推荐和自动化生成。研究定义了图文摘要推荐的两个任务，并提出了一个新的评估指标CAR。

**AI_Comments:** 该论文的创新之处在于构建了一个大规模的图文摘要数据集SciGA-145k，填补了该领域的数据空白。它不仅为图文摘要的自动化生成和推荐提供了基础数据，还定义了具体的推荐任务，并提出了一个更符合实际情况的评估指标CAR。这对于提升科学论文的视觉交流效率以及推动AI在科学传播中的应用具有重要意义。数据集的规模和任务定义都显示出其潜在的广泛应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 图文摘要（GAs）在视觉传达科学论文关键发现方面至关重要，但其增强科学交流的潜力尚未被充分探索。此外，设计有效的图文摘要需要高级可视化技能，这阻碍了其广泛采用。

**Method:** 研究引入了SciGA-145k数据集，包含约14.5万篇科学论文和114万张图，专门用于支持图文摘要选择和推荐，并促进图文摘要自动化生成的研究。定义了两个任务：1）论文内图文摘要推荐，识别论文内适合作为图文摘要的图片；2）论文间图文摘要推荐，从其他论文中检索图文摘要以启发新图文摘要的创建。为这些任务提供了合理的基线模型，并提出了一种新的推荐指标——信心调整后的top-1真实比例（CAR），用于细粒度分析模型行为。

**Result:** 研究提供了用于图文摘要推荐任务的合理基线模型，并提出了一个名为CAR（Confidence Adjusted top-1 ground truth Ratio）的新型推荐评估指标，该指标解决了传统基于排名的指标的局限性，并考虑了论文中除明确标记的图文摘要之外，多个图片也可能作为图文摘要的情况。

**Conclusion:** SciGA-145k数据集通过统一图文摘要推荐任务和评估指标，为推进视觉科学交流奠定了基础，并有助于发展科学领域的人工智能。

> **ai_Abstract:** 该论文介绍了SciGA-145k，一个包含14.5万篇科学论文和114万张图片的大型数据集，旨在解决图文摘要（GAs）设计困难和其潜力未充分开发的问题。该数据集支持GAs的选择、推荐和自动化生成研究。作者定义了论文内和论文间GAs推荐两项任务，并提供了基线模型。此外，论文提出了一种新的推荐评估指标CAR，以更细致地分析模型性能。SciGA-145k的建立旨在促进视觉科学交流和AI在科学领域的应用。

> **摘要翻译:** 图文摘要（GAs）在视觉传达科学论文的关键发现方面发挥着至关重要的作用。尽管最近的研究越来越多地将图1等视觉材料作为事实上的图文摘要，但它们增强科学交流的潜力在很大程度上仍未被探索。此外，设计有效的图文摘要需要高级可视化技能，这对其广泛采用造成了障碍。为了应对这些挑战，我们引入了SciGA-145k，这是一个大型数据集，包含约14.5万篇科学论文和114万张图片，明确设计用于支持图文摘要的选择和推荐，并促进图文摘要自动化生成的研究。作为图文摘要设计支持的初步步骤，我们定义了两个任务：1）论文内图文摘要推荐，识别给定论文中适合作为图文摘要的图片；2）论文间图文摘要推荐，从其他论文中检索图文摘要以启发新图文摘要的创建。我们为这些任务提供了合理的基线模型。此外，我们提出了信心调整后的top-1真实比例（CAR），这是一种新颖的推荐指标，可对模型行为进行细粒度分析。CAR通过考虑论文中除明确标记的图文摘要之外，多个图片也可能作为图文摘要的情况，解决了传统基于排名的指标的局限性。通过统一这些任务和指标，我们的SciGA-145k为推进视觉科学交流奠定了基础，同时为科学领域人工智能的发展做出了贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [126] [LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans](https://arxiv.org/abs/2507.02861)
> *LiteReality：从RGB-D扫描中重建图形就绪的3D场景*

*Zhening Huang, Xiaoyang Wu, Fangcheng Zhong, Hengshuang Zhao, Matthias Nießner, Joan Lasenby* | **Category: cs.CV, cs.AI, cs.GR** | **Updated: {updated}**

**Keywords:** 3D场景重建, RGB-D扫描, 图形管线, 物理渲染, 物体检索

**Comment:** Project Page: https://litereality.github.io; Video:
  https://www.youtube.com/watch?v=ecK9m3LXg2c&feature=youtu.be

> **TL;DR:** LiteReality是一个将RGB-D扫描转换为紧凑、逼真、可交互的3D虚拟副本的流水线，支持图形管线所需的核心功能，并实现了先进的物体检索和材质绘制。

**AI_Comments:** LiteReality的创新之处在于其端到端地解决了从RGB-D扫描到图形就绪3D场景重建的复杂问题，特别强调了对图形管线核心特性的支持。其免训练的物体检索模块和在恶劣条件下仍能进行材质绘制的能力是重要的技术突破，提升了重建场景的实用性和真实感。该方法通过结合场景理解、模型检索和材质增强，提供了一个全面的解决方案，对于AR/VR和数字孪生等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RGB-D扫描到3D场景重建方法可能无法完全支持图形管线所需的关键特性，如物体独立性、可动性、高质量物理渲染材质和物理交互。因此，需要一种能够重建出既逼真又兼容标准图形管线的3D虚拟副本的解决方案。

**Method:** LiteReality首先进行场景理解，将结果解析为连贯的3D布局和物体，并借助结构化场景图。接着，通过从精选资产数据库中检索视觉上最相似的3D艺术家制作模型来重建场景。然后，材质绘制模块通过恢复高质量、空间变化的材质来增强真实感。最后，重建的场景被整合到具有基本物理属性的仿真引擎中，以实现交互行为。该方法还引入了一个免训练的物体检索模块和一个鲁棒的材质绘制模块。

**Result:** 重建的场景紧凑、可编辑，并与标准图形管线完全兼容，适用于AR/VR、游戏、机器人和数字孪生等应用。物体检索模块在Scan2CAD基准测试上实现了最先进的相似性性能。材质绘制模块能够将任何风格的图像外观转移到3D资产上，即使在严重错位、遮挡和光照不足的情况下也能表现良好。LiteReality在真实扫描和公共数据集上都展示了有效性。

**Conclusion:** LiteReality成功地提供了一个将RGB-D扫描转换为图形就绪的3D虚拟副本的完整流水线，其重建的场景不仅视觉逼真，而且支持图形管线所需的核心功能，并在物体检索和材质绘制方面表现出色，为多种应用提供了实用的解决方案。

> **ai_Abstract:** LiteReality是一个创新的流水线，旨在将RGB-D扫描的室内环境转换为紧凑、逼真且可交互的3D虚拟副本。该系统通过场景理解、结构化场景图解析、从资产数据库检索相似3D模型、高质量材质绘制以及与仿真引擎集成等步骤，重建出兼容标准图形管线的场景，并支持物体独立性、可动性、物理渲染和交互。其免训练的物体检索和鲁棒的材质绘制模块在相关基准测试上表现出色，使LiteReality适用于AR/VR、游戏、机器人和数字孪生等多种应用。

> **摘要翻译:** 我们提出了LiteReality，这是一个新颖的流水线，可将室内环境的RGB-D扫描转换为紧凑、逼真且交互式的3D虚拟副本。LiteReality不仅重建出视觉上逼真的场景，还支持图形管线所需的核心功能——例如物体独立性、可动性、高质量的基于物理渲染的材质以及基于物理的交互。LiteReality的核心是，首先执行场景理解，并借助结构化场景图将结果解析为连贯的3D布局和物体。然后，通过从精选资产数据库中检索视觉上最相似的3D艺术家制作模型来重建场景。接下来，材质绘制模块通过恢复高质量、空间变化的材质来增强真实感。最后，重建的场景被整合到具有基本物理属性的仿真引擎中，以实现交互行为。由此产生的场景紧凑、可编辑，并与标准图形管线完全兼容，使其适用于AR/VR、游戏、机器人和数字孪生等应用。此外，LiteReality引入了一个免训练的物体检索模块，在Scan2CAD基准测试上实现了最先进的相似性性能，以及一个强大的材质绘制模块，能够将任何风格的图像外观转移到3D资产上——即使在严重错位、遮挡和光照不足的情况下。我们在真实扫描和公共数据集上都证明了LiteReality的有效性。项目页面：https://litereality.github.io；视频：https://www.youtube.com/watch?v=ecK9m3LXg2c

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [140] [Understanding Trade offs When Conditioning Synthetic Data](https://arxiv.org/abs/2507.02217)
> *理解合成数据条件化时的权衡*

*Brandon Trabucco, Qasim Wani, Benjamin Pikus, Vasu Sharma* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 合成数据, 扩散模型, 条件化, 目标检测, 数据增强

**Comment:** 

> **TL;DR:** 研究了两种扩散模型合成数据条件化策略（基于提示和基于布局）在不同数据多样性下的权衡，发现布局条件化在多样性高时更优，能显著提升目标检测性能。

**AI_Comments:** 这项研究对于优化扩散模型在生成高质量合成数据方面的应用具有重要意义，尤其是在数据稀缺的工业视觉领域。它系统地比较了不同的条件化策略，并揭示了它们在不同数据多样性下的性能权衡，为实际应用提供了指导。其发现布局条件化在高多样性场景下的显著优势，为利用合成数据提升目标检测器性能提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 工业视觉系统中高质量训练数据收集耗时且成本高昂。现有合成数据生成方法渲染慢且存在模拟与现实差距。扩散模型虽快但精确控制困难，尤其是在低数据量下。目前对不同条件化方案对合成数据质量的影响缺乏深入理解。

**Method:** 研究了来自四个标准目标检测基准的八十个不同视觉概念，比较了两种条件化策略：基于提示（prompt-based）和基于布局（layout-based）。

**Result:** 当条件化提示集较窄时，基于提示的条件化产生更高质量的合成数据；随着多样性增加，基于布局的条件化表现更优。当布局提示与完整的训练分布匹配时，合成数据使平均精度（mAP）平均提高了34%，最高可达177%，相比仅使用真实数据。

**Conclusion:** 选择合适的条件化策略对于生成高质量的合成数据至关重要，特别是基于布局的条件化在数据多样性高时能显著提升目标检测器的性能。

> **ai_Abstract:** 这篇论文探讨了在生成合成数据时，不同条件化策略对图像质量和下游任务性能的影响。针对工业视觉中数据收集困难的问题，作者比较了扩散模型中的基于提示和基于布局的两种条件化方法。研究发现，在低多样性场景下，基于提示的方法表现较好；而在高多样性场景下，基于布局的方法更优。特别是当布局信息与真实数据分布匹配时，使用合成数据能显著提升目标检测的平均精度。

> **摘要翻译:** 仅使用少量图像学习鲁棒的目标检测器是工业视觉系统中的一个关键挑战，因为收集高质量的训练数据可能需要数月时间。合成数据已成为数据高效的视觉检测和抓取机器人技术的重要解决方案。当前的管道依赖于Blender或Unreal等3D引擎，它们提供精细控制，但仍需要数周才能渲染一个小数据集，并且生成的图像通常存在模拟与现实之间的大差距。扩散模型有望带来质的飞跃，因为它们可以在几分钟内生成高质量图像，但精确控制，尤其是在低数据量情况下，仍然很困难。尽管许多适配器现在将扩散模型扩展到纯文本提示之外，但不同条件化方案对合成数据质量的影响仍知之甚少。我们研究了来自四个标准目标检测基准的八十个不同视觉概念，并比较了两种条件化策略：基于提示的和基于布局的。当条件化提示集较窄时，基于提示的条件化产生更高质量的合成数据；随着多样性增加，基于布局的条件化表现更优。当布局提示与完整的训练分布匹配时，合成数据使平均精度（mAP）平均提高了34%，最高可达177%，相比仅使用真实数据。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [145] [Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation](https://arxiv.org/abs/2507.02268)
> *基于双向域适应的跨域高光谱图像分类*

*Yuxiang Zhang, Wei Li, Wen Jia, Mengmeng Zhang, Ran Tao, Shunlin Liang* | **Category: cs.CV, eess.IV** | **Updated: {updated}**

**Keywords:** 跨域, 高光谱图像分类, 域适应, Transformer, 光谱偏移

**Comment:** 

> **TL;DR:** 本文提出了一种名为BiDA的双向域适应框架，用于解决跨域高光谱图像（HSI）分类中的光谱偏移问题。该框架采用三分支Transformer架构，并结合双向蒸馏损失和自适应强化策略，在实验中表现出优于现有SOTA方法的性能。

**AI_Comments:** 本文的创新之处在于其提出的BiDA框架，能够同时提取域不变特征和域特定信息，有效应对高光谱图像在不同场景下的光谱偏移问题。通过结合三分支Transformer架构、耦合多头交叉注意力机制、双向蒸馏损失以及自适应强化策略，BiDA在跨域高光谱图像分类任务中展现出显著优于现有方法的性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱遥感技术在提取精细地物类别方面具有优势，但用于训练和测试的卫星或机载图像通常采集自不同区域或时间，导致相同类别在不同场景中存在显著的光谱偏移，这给跨域高光谱图像分类带来了挑战。

**Method:** 本文提出了一种双向域适应（BiDA）框架，用于跨域高光谱图像（HSI）分类。该框架旨在独立自适应空间中提取域不变特征和域特定信息，从而增强对目标场景的适应性和可分离性。BiDA的核心是一个带有语义分词器的三分支Transformer架构（源分支、目标分支和耦合分支）。源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支中开发了一种耦合多头交叉注意力（CMCA）机制用于特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失以利用域间相关性指导自适应空间学习。最后，提出了一种自适应强化策略（ARS），鼓励模型在噪声条件下专注于源场景和目标场景中的特定泛化特征提取。

**Result:** 在跨时间/场景的机载和卫星数据集上的实验结果表明，所提出的BiDA框架显著优于一些最先进的域适应方法。在跨时间树种分类任务中，所提出的BiDA比最先进的方法高出3%~5%。

**Conclusion:** 所提出的BiDA框架通过有效地提取域不变特征和域特定信息，成功解决了跨域高光谱图像分类中的光谱偏移问题。实验结果证明，BiDA在各种数据集上均表现出优越的性能，显著优于现有最先进的域适应方法，尤其在跨时间树种分类任务中取得了显著提升。

> **ai_Abstract:** 本文提出了一种名为双向域适应（BiDA）的框架，用于解决跨域高光谱图像（HSI）分类中因不同场景间光谱偏移导致的数据差异问题。BiDA框架采用独特的三分支Transformer架构（源、目标、耦合），并结合语义分词器，旨在同时提取域不变特征和域特定信息。该模型引入了耦合多头交叉注意力（CMCA）机制以促进特征交互和域间相关性挖掘，并设计了双向蒸馏损失指导自适应空间学习，同时通过自适应强化策略（ARS）增强模型在噪声条件下的泛化特征提取能力。实验证明，BiDA在跨时间/场景的机载和卫星数据集上显著优于现有最先进的域适应方法，特别在跨时间树种分类任务中取得了3%~5%的性能提升。

> **摘要翻译:** 利用高光谱遥感技术能够提取精细的地物类别。通常，用于训练和测试的卫星或机载图像采集自不同区域或时间，导致相同类别在不同场景中存在显著的光谱偏移。在本文中，我们提出了一种用于跨域高光谱图像（HSI）分类的双向域适应（BiDA）框架，该框架侧重于在独立自适应空间中提取域不变特征和域特定信息，从而增强对目标场景的适应性和可分离性。在所提出的BiDA中，设计了一个带有语义分词器的三分支Transformer架构（源分支、目标分支和耦合分支）作为骨干网络。具体来说，源分支和目标分支独立学习源域和目标域的自适应空间，耦合分支中开发了一种耦合多头交叉注意力（CMCA）机制用于特征交互和域间相关性挖掘。此外，设计了双向蒸馏损失以利用域间相关性指导自适应空间学习。最后，我们提出了一种自适应强化策略（ARS），鼓励模型在噪声条件下专注于源场景和目标场景中的特定泛化特征提取。在跨时间/场景的机载和卫星数据集上的实验结果表明，所提出的BiDA显著优于一些最先进的域适应方法。在跨时间树种分类任务中，所提出的BiDA比最先进的方法高出3%~5%。代码将从网站提供：https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [161] [High-Fidelity Differential-information Driven Binary Vision Transformer](https://arxiv.org/abs/2507.02222)
> *高保真差分信息驱动的二值视觉Transformer*

*Tian Gao, Zhiyuan Zhang, Kaijie Yin, Xu-Cheng Zhong, Hui Kong* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 二值视觉Transformer, 信息损失, 频率分解, RPReLU

**Comment:** 

> **TL;DR:** 本文提出了一种名为DIDB-ViT的新型二值视觉Transformer，通过引入差分信息、频率分解和改进的激活函数，显著提高了二值化ViT的性能，超越了现有最先进的方法。

**AI_Comments:** 该论文的创新点在于提出了多方面的技术改进来解决二值化ViT中的核心挑战，即信息损失和表示能力下降。通过引入差分信息、频率分解和改进的激活函数，DIDB-ViT在保持计算效率的同时显著提升了性能，这对于推动二值化模型在资源受限的边缘设备上的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的二值视觉Transformer（ViT）方法通常面临严重的性能下降或过度依赖全精度模块，这限制了它们在计算和存储受限的边缘设备上的部署，无法有效解决高计算/存储需求与边缘设备部署限制之间的权衡问题。

**Method:** 本文提出了DIDB-ViT，一种新颖的二值ViT。具体方法包括：1) 设计了一个结合差分信息的有信息注意力模块，以减轻二值化导致的信息损失并增强高频保留。2) 使用离散Haar小波应用频率分解，并整合不同频率的相似性，以保持二值Q和K张量之间相似性计算的保真度。3) 引入了一种改进的RPReLU激活函数来重构激活分布，从而扩展模型的表示能力。

**Result:** 实验结果表明，DIDB-ViT在多种ViT架构中显著优于最先进的网络量化方法，并在图像分类和分割任务上取得了卓越的性能。

**Conclusion:** DIDB-ViT通过其创新的信息注意力模块、频率分解相似性计算和改进的激活函数，成功解决了二值化视觉Transformer的性能下降问题，在保持原始ViT架构和计算效率的同时，显著提高了模型的准确性，使其成为边缘设备部署的有效解决方案。

> **ai_Abstract:** 本文提出了一种名为DIDB-ViT的新型高保真二值视觉Transformer，旨在解决现有二值ViT在性能下降和对全精度模块依赖的问题。DIDB-ViT通过引入差分信息驱动的注意力模块、基于频率分解的相似性计算以及改进的RPReLU激活函数，有效减轻了二值化带来的信息损失并增强了模型的表示能力。实验证明，DIDB-ViT在图像分类和分割任务上显著优于现有最先进的网络量化方法，为边缘设备部署提供了高效解决方案。

> **摘要翻译:** 视觉Transformer（ViT）的二值化为解决高计算/存储需求与边缘设备部署限制之间的权衡提供了一种有前景的方法。然而，现有的二值ViT方法通常面临严重的性能下降或严重依赖全精度模块。为了解决这些问题，我们提出DIDB-ViT，这是一种新颖的二值ViT，它在保持原始ViT架构和计算效率的同时，具有高度信息性。具体来说，我们设计了一个结合差分信息的有信息注意力模块，以减轻二值化导致的信息损失并增强高频保留。为了保持二值Q和K张量之间相似性计算的保真度，我们使用离散Haar小波应用频率分解并整合不同频率的相似性。此外，我们引入了一种改进的RPReLU激活函数来重构激活分布，从而扩展模型的表示能力。实验结果表明，我们的DIDB-ViT在多种ViT架构中显著优于最先进的网络量化方法，实现了卓越的图像分类和分割性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [166] [Determination Of Structural Cracks Using Deep Learning Frameworks](https://arxiv.org/abs/2507.02416)
> *使用深度学习框架确定结构裂缝*

*Subhasis Dasgupta, Jaydip Sen, Tuhina Halder* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: {updated}**

**Keywords:** 结构裂缝检测, 深度学习, 残差U-Net, 集成模型, 图像分割

**Comment:** This is the accepted version of the paper presented in IEEE CONIT
  2025 held on 20th June 2025. This is not the camera-ready version. There are
  6 pages in this paper and it contains 7 figures and 1 table

> **TL;DR:** 本研究提出一种新型深度学习架构，结合残差U-Net和元模型集成，显著提高了结构裂缝检测的准确性和效率，优于现有模型。

**AI_Comments:** 本文的创新点在于提出了残差U-Net与元模型集成的独特深度学习架构，有效解决了传统人工检测的痛点，并显著提升了裂缝检测的准确性和效率，尤其是在低分辨率图像上的表现突出，为自动化结构缺陷监测提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 结构裂缝检测对公共安全至关重要，但人工检测效率低、不一致且易出错，影响评估可靠性。

**Method:** 本研究引入了一种新型深度学习架构，利用多种配置的残差U-Net模型，并将其与包含卷积块的元模型集成，形成一个集成模型。通过交并比（IoU）和DICE系数评估其性能，并与SegNet和传统U-Net等成熟架构进行了比较。

**Result:** 残差U-Net模型优于其前辈，尤其是在低分辨率图像上。集成模型超越了单个模型的性能，证明它是最有效的，并在IoU和DICE系数上获得了最高分数，表明其卓越的准确性。

**Conclusion:** 这一进展为结构缺陷监测任务中更可靠的自动化系统提供了方向。

> **ai_Abstract:** 本研究提出了一种新颖的深度学习架构，用于提高结构裂缝检测的准确性和效率。该架构结合了多种配置的残差U-Net模型，并将其与一个包含卷积块的元模型集成。通过与SegNet和传统U-Net等模型的比较，结果表明残差U-Net在低分辨率图像上表现出色，而集成模型在IoU和DICE系数上取得了最高的准确性，证明了其在自动化结构缺陷监测中的有效性。

> **摘要翻译:** 结构裂缝检测是公共安全的关键任务，因为它有助于防止可能危及生命的潜在结构故障。经验不足的人员进行人工检测可能缓慢、不一致且容易出现人为错误，这可能会损害评估的可靠性。本研究通过引入一种新型深度学习架构来解决这些挑战，该架构旨在提高结构裂缝检测的准确性和效率。在这项研究中，利用了残差U-Net模型的各种配置。这些模型因其在捕获精细细节方面的鲁棒性，进一步与包含卷积块的元模型集成，形成一个集成模型。这种独特的组合旨在将预测效率提升到单个模型无法达到的水平。该集成模型的性能与SegNet和传统U-Net等成熟架构进行了评估。结果表明，残差U-Net模型优于其前辈，特别是在低分辨率图像上，并且集成模型超越了单个模型的性能，证明它是最有效的。评估基于交并比（IoU）度量和DICE系数。集成模型获得了最高分数，表明其卓越的准确性。这一进展为结构缺陷监测任务中更可靠的自动化系统提供了方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [181] [FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model](https://arxiv.org/abs/2507.02250)
> *FMOcc：基于TPV驱动流匹配的3D占用预测与选择性状态空间模型*

*Jiangxia Chen, Tongyuan Huang, Ke Song* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 3D占用预测, 流匹配, 状态空间模型, TPV, 自动驾驶

**Comment:** 

> **TL;DR:** FMOcc提出了一种基于TPV和流匹配选择性状态空间模型的3D占用预测方法，通过特征细化、选择性过滤和掩码训练，解决了现有方法在遮挡和远距离场景中预测精度不足以及计算资源消耗大的问题，并在多个数据集上取得了最先进的性能。

**AI_Comments:** FMOcc的创新性体现在其结合了流匹配模型进行特征细化，并引入了选择性状态空间模型（SSM）来高效处理TPV特征，尤其是在减少“空中体素”影响方面。此外，掩码训练（MT）设计有助于提高模型对传感器数据丢失的鲁棒性。这些改进共同解决了自动驾驶中3D占用预测的关键挑战，特别是在少量帧和远距离场景下的精度和效率问题。该工作对未来自动驾驶感知系统的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D语义占用预测在自动驾驶中至关重要，但现有方法受限于少量帧图像和3D空间冗余，导致在遮挡和远距离场景中的预测精度受损。融合历史帧数据的方法需要额外数据和大量计算资源。

**Method:** 本文提出FMOcc，一个结合了三视角（TPV）细化占用网络和流匹配选择性状态空间模型用于少量帧3D占用预测。具体方法包括：1) 设计了基于流匹配模型的特征细化模块（FMSSM）以生成缺失特征。2) 设计了TPV SSM层和平面选择性SSM（PS3M），选择性过滤TPV特征，减少空中体素对非空中体素的影响，提高模型效率和远距离场景预测能力。3) 设计了掩码训练（MT）方法以增强FMOcc的鲁棒性并解决传感器数据丢失问题。

**Result:** FMOcc在Occ3D-nuScenes和OpenOcc数据集上表现优于现有SOTA方法。使用两帧输入，FMOcc在Occ3D-nuScenes验证集上RayIoU达到43.1%，mIoU达到39.8%；在OpenOcc上RayIoU达到42.6%，推理内存为5.4 G，推理时间为330ms。

**Conclusion:** FMOcc通过引入流匹配选择性状态空间模型和创新的训练策略，显著提升了3D占用预测在少量帧输入下的精度和效率，尤其是在处理遮挡和远距离场景方面。

> **ai_Abstract:** FMOcc是一种新颖的3D语义占用预测方法，旨在解决少量帧图像和3D空间冗余导致的预测精度问题。它结合了三视角（TPV）细化网络和流匹配选择性状态空间模型。该方法引入了流匹配SSM模块（FMSSM）以生成缺失特征，并设计了TPV SSM层和平面选择性SSM（PS3M）以选择性过滤特征，提高效率并优化远距离场景预测。此外，通过掩码训练（MT）增强模型鲁棒性。实验证明FMOcc在多个基准数据集上超越了现有最先进方法。

> **摘要翻译:** 3D语义占用预测在自动驾驶中扮演着关键角色。然而，少量帧图像的固有局限性和3D空间中的冗余，损害了对遮挡和远距离场景的预测精度。现有方法通过融合历史帧数据来提高性能，但这需要额外的数据和大量的计算资源。为了解决这些问题，本文提出了FMOcc，一个基于三视角（TPV）细化占用网络和流匹配选择性状态空间模型的少量帧3D占用预测方法。首先，为了生成缺失特征，我们设计了一个基于流匹配模型的特征细化模块，称为流匹配SSM模块（FMSSM）。此外，通过设计TPV SSM层和平面选择性SSM（PS3M），我们选择性地过滤TPV特征，以减少空中体素对非空中体素的影响，从而提高模型的整体效率和对远距离场景的预测能力。最后，我们设计了掩码训练（MT）方法，以增强FMOcc的鲁棒性并解决传感器数据丢失的问题。在Occ3D-nuScenes和OpenOcc数据集上的实验结果表明，我们的FMOcc优于现有最先进的方法。我们的FMOcc在两帧输入下，在Occ3D-nuScenes验证集上取得了43.1%的RayIoU和39.8%的mIoU的显著分数，在OpenOcc上取得了42.6%的RayIoU，推理内存为5.4 G，推理时间为330ms。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [184] [Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic](https://arxiv.org/abs/2507.02443)
> *FPGA可编程逻辑中加速人工神经网络的红葡萄检测*

*Sandro Costa Magalhães, Marco Almeida, Filipe Neves dos Santos, António Paulo Moreira, Jorge Dias* | **Category: cs.CV, cs.AI, cs.DC, cs.LG, cs.RO** | **Updated: {updated}**

**Keywords:** FPGA, 人工神经网络, 量化, 红葡萄检测, FINN架构

**Comment:** Submitted to ROBOT'2025

> **TL;DR:** 本文通过在FPGA的可编程逻辑中部署量化人工神经网络（如MobileNet v1）并利用FINN架构，显著提高了红葡萄检测的推理速度，解决了机器人移动检测效率低的问题。

**AI_Comments:** 这项工作展示了在FPGA上部署量化神经网络以实现高推理速度的潜力，对于需要实时目标检测的机器人应用具有重要意义。通过充分利用FPGA的可编程逻辑，克服了现有工具的局限性，特别是在边缘设备上实现高效AI推理方面具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人移动时进行物体检测通常会减速，且摄像头帧率低，这限制了任务执行和探索，增加了任务时间。此外，AMD的Vitis-AI框架未能充分利用FPGA的可编程逻辑。

**Method:** 本研究使用FINN架构，将三种量化人工神经网络（4比特量化的MobileNet v1、2比特量化的CNV和1比特量化的CNV/BNN）部署到FPGA的可编程逻辑中，并在自采集的RG2C数据集上进行训练。

**Result:** MobileNet v1表现最佳，达到了98%的成功率和6611 FPS的推理速度。

**Conclusion:** 本研究证明了可以使用FPGA来加速人工神经网络，使其适用于注意力机制。

> **ai_Abstract:** 本文针对机器人移动目标检测速度慢和现有FPGA部署工具利用率不足的问题，提出了一种基于FINN架构的解决方案。研究团队将4比特量化的MobileNet v1、2比特量化的CNV和1比特量化的CNV（BNN）等人工神经网络模型部署到FPGA的可编程逻辑中，并在自采集的RG2C数据集上进行训练。实验结果表明，MobileNet v1表现最佳，实现了98%的成功率和6611 FPS的推理速度。该研究证明了FPGA能够有效加速人工神经网络，使其适用于需要高速度的注意力机制应用。

> **摘要翻译:** 机器人通常在移动时为了检测物体而减速进行罐装。此外，机器人的摄像头配置了低帧率，以跟踪检测算法的速度。这在执行任务和探索时会受到限制，导致机器人增加任务执行时间。AMD开发了Vitis-AI框架，用于将检测算法部署到FPGA中。然而，该工具未能充分利用FPGA的可编程逻辑（PL）。在这项工作中，我们使用FINN架构将三个ANN（4比特量化的MobileNet v1、2比特量化的CNV和1比特量化的CNV/BNN）部署到FPGA的PL内部。模型在RG2C数据集上进行了训练。这是一个自采集并开放访问的数据集。MobileNet v1表现更好，达到了98%的成功率和6611 FPS的推理速度。在这项工作中，我们证明了可以使用FPGA来加速ANN并使其适用于注意力机制。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [198] [SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement](https://arxiv.org/abs/2507.02252)
> *SurgVisAgent：多模态智能体模型用于通用外科视觉增强*

*Zeyu Lei, Hongyuan Yu, Jinlin Wu, Zhen Chen* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 外科视觉增强, 多模态智能体, 内窥镜图像, 图像失真, MLLMs

**Comment:** 

> **TL;DR:** SurgVisAgent是一个基于多模态大语言模型的智能体，能动态识别并处理多种内窥镜图像失真，实现通用外科视觉增强。

**AI_Comments:** 该论文创新性地将多模态大语言模型应用于外科视觉增强领域，通过智能体范式解决了传统方法单一任务的局限性。其动态识别和多任务处理能力，结合领域知识和少样本学习，为复杂外科场景提供了更通用和鲁棒的解决方案。构建真实世界失真基准也增加了其研究的实用价值和说服力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的外科视觉增强算法通常是为特定场景下的单一任务设计的，这限制了它们在复杂真实世界情况下的有效性。

**Method:** 本文提出了SurgVisAgent，一个基于多模态大语言模型（MLLMs）的端到端智能外科视觉智能体。它动态识别内窥镜图像中的失真类别和严重程度，并执行多种增强任务。具体而言，SurgVisAgent设计了一个先验模型提供领域特定知识，并通过上下文少样本学习和思维链（CoT）推理提供定制化的图像增强。

**Result:** 通过构建模拟真实世界外科失真的综合基准，SurgVisAgent在广泛实验中超越了传统的单任务模型。

**Conclusion:** SurgVisAgent展示了作为外科辅助统一解决方案的潜力。

> **ai_Abstract:** 本文提出了SurgVisAgent，一个基于多模态大语言模型（MLLMs）的智能外科视觉智能体，旨在解决现有外科视觉增强算法在复杂真实世界场景中单一任务的局限性。SurgVisAgent能够动态识别内窥镜图像中的多种失真类型和严重程度，并执行包括低光增强、过曝校正等多种增强任务。通过引入领域特定知识的先验模型、上下文少样本学习和思维链推理，SurgVisAgent能提供定制化的图像增强。实验证明，SurgVisAgent在模拟真实世界外科失真的基准上优于传统单任务模型，展现了其作为统一外科辅助解决方案的潜力。

> **摘要翻译:** 精确的外科干预对于患者安全至关重要，并且已经开发了先进的增强算法来辅助外科医生进行决策。尽管取得了显著进展，但这些算法通常是为特定场景下的单一任务设计的，这限制了它们在复杂真实世界情况下的有效性。为了解决这一限制，我们提出了SurgVisAgent，一个基于多模态大语言模型（MLLMs）构建的端到端智能外科视觉智能体。SurgVisAgent动态识别内窥镜图像中的失真类别和严重程度，使其能够执行各种增强任务，例如低光增强、过曝校正、运动模糊消除和烟雾去除。具体而言，为了实现卓越的外科场景理解，我们设计了一个提供领域特定知识的先验模型。此外，通过上下文少样本学习和思维链（CoT）推理，SurgVisAgent提供了针对各种失真类型和严重程度定制的图像增强，从而满足了外科医生的多样化需求。此外，我们构建了一个模拟真实世界外科失真的综合基准，在此基准上进行的广泛实验表明，SurgVisAgent超越了传统的单任务模型，突显了其作为外科辅助统一解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [200] [F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning](https://arxiv.org/abs/2507.02437)
> *F^2TTA：通过图像级解耦提示微调在跨领域医学图像分类上的自由形式测试时间适应*

*Wei Li, Jingyang Zhang, Lihao Liu, Guoan Wang, Junjun He, Yang Chen, Lixu Gu* | **Category: cs.CV, eess.IV** | **Updated: {updated}**

**Keywords:** 测试时间适应, 医学图像分类, 提示微调, 自由形式适应, 领域偏移

**Comment:** This paper has been submitted to relevant journals

> **TL;DR:** 本文提出了F^2TTA，一种新的测试时间适应方法，通过图像级解耦提示微调（I-DiPT），结合不确定性导向掩蔽（UoM）和并行图蒸馏（PGD），以处理自由形式、碎片化的医学图像数据进行跨领域分类。

**AI_Comments:** 本文解决了医学图像分析中一个高度实际和现实的挑战：将模型适应于碎片化、不可预测变化的医学数据流，这与大多数现有TTA方法所做的假设有显著不同。所提出的图像级解耦提示微调（I-DiPT）及其两种提示类型具有创新性。此外，不确定性导向掩蔽（UoM）和并行图蒸馏（PGD）的引入有效地解决了单图像适应中知识有限的问题，增强了方法的鲁棒性和效率。这项工作对在动态临床环境中部署AI模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的测试时间适应（TTA）方法假设数据以完整的领域单元到达，这与临床实践中数据以任意长度的领域碎片和随机顺序到达的情况不符，且碎片之间存在不可预测的偏移，导致适应过程失真。此外，数据标注成本高昂也驱动了对TTA的需求。

**Method:** 本文提出了F^2TTA任务下的图像级解耦提示微调（I-DiPT）框架。I-DiPT使用图像不变提示来探索领域不变表示以减轻不可预测的偏移，并使用图像特定提示来适应每个传入碎片中的测试图像。为了解决单图像训练导致的知识表示不足，引入了不确定性导向掩蔽（UoM），通过源模型表示的不确定性驱动的掩蔽一致性学习来提取信息。此外，还提出了并行图蒸馏（PGD）方法，通过并行图网络重用历史图像特定和图像不变提示的知识。

**Result:** 在乳腺癌和青光眼分类上的实验表明，F^2TTA方法在自由形式测试时间适应（F²TTA）任务中优于现有的TTA方法。

**Conclusion:** 本文成功解决了医学图像分类中自由形式测试时间适应的实际挑战，提出了一种新颖的框架（F^2TTA，包含I-DiPT、UoM和PGD），有效处理了不可预测的领域偏移和有限知识的问题，并展示了卓越的性能。

> **ai_Abstract:** 本文提出了一种名为F^2TTA的创新测试时间适应（TTA）框架，专为跨领域医学图像分类设计，以应对现实世界中自由形式、碎片化数据到达和不可预测领域偏移的挑战。F^2TTA的核心是图像级解耦提示微调（I-DiPT），该方法同时利用图像不变和图像特定提示。为了克服单图像训练对提示知识表示的限制，作者引入了不确定性导向掩蔽（UoM）以实现鲁棒的信息提取，并提出了并行图蒸馏（PGD）以重用历史提示的知识。在乳腺癌和青光眼分类上的实验结果表明，F^2TTA在该具挑战性的自由形式设置下，性能优于现有TTA方法。

> **摘要翻译:** 测试时间适应（TTA）已成为一种有前景的解决方案，用于利用未标记的测试数据将源模型适应到未见的医学站点，因为数据标注成本高昂。现有的TTA方法考虑的是来自一个或多个领域的数据以完整领域单元到达的场景。然而，在临床实践中，由于资源限制和患者变异性，数据通常以任意长度的领域碎片和随机到达顺序出现。本文研究了一种实用的自由形式测试时间适应（F$^{2}$TTA）任务，其中源模型被适应到这种自由形式的领域碎片，碎片之间会发生不可预测的偏移。在这种设置下，这些偏移可能会扭曲适应过程。为了解决这个问题，我们提出了一种新颖的图像级解耦提示微调（I-DiPT）框架。I-DiPT采用图像不变提示来探索领域不变表示以减轻不可预测的偏移，并采用图像特定提示将源模型适应于来自传入碎片的每个测试图像。由于每次训练只有一个图像可用，提示可能会面临知识表示不足的问题。为了克服这一限制，我们首先引入了不确定性导向掩蔽（UoM），它通过由源模型表示的不确定性驱动的掩蔽一致性学习，鼓励提示从传入图像中提取足够的信息。然后，我们进一步提出了一种并行图蒸馏（PGD）方法，通过并行图网络重用历史图像特定和图像不变提示的知识。在乳腺癌和青光眼分类上的实验证明了我们的方法在F$^{2}$TTA中优于现有TTA方法。代码可在https://github.com/mar-cry/F2TTA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [210] [Multi-Label Classification Framework for Hurricane Damage Assessment](https://arxiv.org/abs/2507.02265)
> *飓风损害评估的多标签分类框架*

*Zhangding Liu, Neda Mohammadi, John E. Taylor* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 多标签分类, 飓风损害评估, 航空影像, ResNet, 注意力机制

**Comment:** 9 pages, 3 figures. Accepted at the ASCE International Conference on
  Computing in Civil Engineering (i3CE 2025)

> **TL;DR:** 本研究提出了一种新颖的多标签分类框架，利用航空影像评估飓风损害，通过整合ResNet特征提取和类别特定注意力机制，在Rescuenet数据集上取得了90.23%的平均精度，优于现有基线方法。

**AI_Comments:** 该论文的创新点在于提出了一个多标签分类框架来解决飓风损害评估中损害类型复杂性的问题，这比传统的单标签方法更具优势。结合ResNet和类别特定注意力机制的方法是其技术核心。其在真实数据集上的优异表现证明了其实用价值和对灾害响应领域的潜在贡献。文章已被知名会议接受，表明其质量和相关性。

<details>
  <summary>Details</summary>

**Motivation:** 飓风造成的破坏广泛，损害类型和严重程度多样，需要及时准确的评估以进行有效的灾害响应。传统单标签分类方法无法捕捉灾后损害的复杂性。

**Method:** 本研究引入了一种新颖的多标签分类框架，用于使用航空影像评估损害。所提出的方法整合了基于ResNet的特征提取模块和类别特定注意力机制，以识别单个图像中的多种损害类型。

**Result:** 使用来自飓风迈克尔的Rescuenet数据集，所提出的方法实现了90.23%的平均精度，优于现有基线方法。

**Conclusion:** 该框架增强了飓风后的损害评估，从而实现更有针对性和高效的灾害响应，并有助于未来的灾害缓解和恢复策略。

> **ai_Abstract:** 本研究提出了一种新颖的多标签分类框架，用于利用航空影像对飓风损害进行评估。该框架结合了基于ResNet的特征提取模块和类别特定注意力机制，能够在一张图像中识别多种损害类型。在Hurricane Michael的Rescuenet数据集上，该方法取得了90.23%的平均精度，优于现有基线方法，显著提升了灾后损害评估的效率和准确性，有助于更有效的灾害响应和未来的减灾策略。

> **摘要翻译:** 飓风造成广泛破坏，导致多种损害类型和严重程度，需要及时准确的评估以进行有效的灾害响应。尽管传统的单标签分类方法无法捕捉飓风后损害的复杂性，但本研究引入了一种新颖的多标签分类框架，用于使用航空影像评估损害。所提出的方法整合了基于ResNet的特征提取模块和类别特定注意力机制，以识别单个图像中的多种损害类型。使用来自飓风迈克尔的Rescuenet数据集，所提出的方法实现了90.23%的平均精度，优于现有基线方法。该框架增强了飓风后的损害评估，从而实现更有针对性和高效的灾害响应，并有助于未来的灾害缓解和恢复策略。本文已被ASCE国际土木工程计算会议（i3CE 2025）接受，最终版本将出现在官方会议论文集中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [213] [IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising](https://arxiv.org/abs/2507.02445)
> *IGDNet：基于光照引导和去噪的零样本鲁棒欠曝光图像增强*

*Hailong Yan, Junjian Huang, Tingwen Huang* | **Category: cs.CV, eess.IV** | **Updated: {updated}**

**Keywords:** 欠曝光图像增强, 零样本, 去噪, 光照引导, 图像分解

**Comment:** Submitted to IEEE Transactions on Artificial Intelligence (TAI) on
  Oct.31, 2024

> **TL;DR:** IGDNet是一种零样本方法，无需训练数据即可增强欠曝光图像，并通过光照引导和去噪有效提高视觉质量并抑制噪声，优于现有无监督方法。

**AI_Comments:** IGDNet的创新之处在于其零样本学习范式，摆脱了对昂贵配对训练数据的依赖，极大提升了实际应用中的便利性和泛化能力。其结合光照引导和去噪的模块化设计，有效解决了欠曝光图像增强中常见的过增强和噪声问题，为该领域提供了一个鲁棒且高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前欠曝光图像恢复方法依赖监督学习和配对数据，但数据收集不切实际且易导致过增强，IGDNet旨在解决这些问题。

**Method:** 提出IGDNet，一个零样本增强方法，仅基于单个测试图像操作。框架包含一个分解模块（通过密集连接网络将图像分离为光照和反射分量）和一个去噪模块（使用光照引导的像素自适应校正方法增强非均匀光照区域）。通过下采样生成噪声对并迭代优化。

**Result:** 在四个公共数据集上显著改善了复杂光照条件下的视觉质量。PSNR (20.41dB) 和 SSIM (0.860dB) 等量化结果表明，它优于14种最先进的无监督方法。

**Conclusion:** IGDNet作为一种零样本方法，在无需训练数据的情况下，能够有效增强欠曝光图像并抑制噪声，在多个数据集上表现优异，超越了现有无监督方法。

> **ai_Abstract:** 本文提出IGDNet，一种零样本欠曝光图像增强方法，解决了传统监督学习方法对配对数据依赖和过增强的问题。IGDNet无需训练数据，通过分解模块分离光照和反射，并利用去噪模块进行光照引导的像素自适应校正。实验证明，IGDNet在多个公共数据集上显著提升了图像视觉质量，并在PSNR和SSIM等指标上超越了14种现有无监督方法，同时有效抑制了噪声。

> **摘要翻译:** 当前欠曝光图像恢复方法通常依赖于监督学习，使用成对的欠曝光和光照充足的图像。然而，在实际场景中收集此类数据集通常是不切实际的。此外，这些方法可能导致过度增强，扭曲光照充足的区域。为了解决这些问题，我们提出了IGDNet，一种零样本增强方法，它仅基于单个测试图像操作，无需引导先验或训练数据。IGDNet表现出强大的泛化能力，并在恢复光照的同时有效抑制噪声。该框架包括一个分解模块和一个去噪模块。前者通过密集连接网络将图像分离为光照和反射分量，而后者使用光照引导的像素自适应校正方法增强非均匀光照区域。通过下采样生成噪声对并迭代细化以产生最终结果。在四个公共数据集上进行的大量实验表明，IGDNet在复杂光照条件下显著提高了视觉质量。PSNR (20.41dB) 和 SSIM (0.860dB) 等指标的量化结果表明，它优于14种最先进的无监督方法。代码将很快发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [235] [MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement](https://arxiv.org/abs/2507.02270)
> *MAC-Lookup：水下图像增强的多轴条件查找模型*

*Fanghai Yi, Zehong Zheng, Zexiao Liang, Yihang Dong, Xiyang Fang, Wangyu Wu, Xuhang Chen* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 水下图像增强, 多轴条件查找, 查找表, 颜色校正, 图像质量

**Comment:** Accepted by IEEE SMC 2025

> **TL;DR:** MAC-Lookup是一种新的水下图像增强模型，通过条件3D查找表颜色校正和多轴自适应增强来提高色彩准确性、锐度和对比度，优于现有方法。

**AI_Comments:** MAC-Lookup模型通过结合查找表和自适应增强的方法，为水下图像增强提供了一种新颖且有效的方法。其创新之处在于能够同时处理颜色校正和细节细化，并有效防止过度增强，这对于水下图像的自然视觉呈现至关重要。该方法解决了现有方法在处理水下复杂环境时的局限性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 水下图像由于光线变化、水浊度和气泡而面临可见度和颜色问题，传统方法和基于像素的方法常常失败，而深度学习缺乏高质量数据集。

**Method:** 我们引入了多轴条件查找（MAC-Lookup）模型。该模型包括用于初步颜色和质量校正的条件3D查找表颜色校正（CLTCC）和用于细节细化的多轴自适应增强（MAAE）。该模型能防止过度增强和饱和。

**Result:** 广泛的实验表明，MAC-Lookup在水下图像增强方面表现出色，比现有方法更好地恢复了细节和颜色。

**Conclusion:** MAC-Lookup模型通过其独特的多组件设计，有效解决了水下图像的可见性和颜色问题，实现了高质量的图像增强，优于现有方法。

> **ai_Abstract:** 本文提出了一种名为MAC-Lookup的多轴条件查找模型，用于解决水下图像的可见性和颜色问题。该模型结合了条件3D查找表颜色校正（CLTCC）和多轴自适应增强（MAAE），旨在提高水下图像的色彩准确性、锐度和对比度，同时避免过度增强。实验结果表明，MAC-Lookup在恢复水下图像细节和颜色方面优于现有方法。

> **摘要翻译:** 增强水下图像对于探索至关重要。这些图像由于光线变化、水浊度和气泡而面临可见度和颜色问题。传统的基于先验的方法和基于像素的方法常常失败，而深度学习缺乏足够的高质量数据集。我们引入了多轴条件查找（MAC-Lookup）模型，通过提高色彩准确性、锐度和对比度来增强视觉质量。它包括用于初步颜色和质量校正的条件3D查找表颜色校正（CLTCC）和用于细节细化的多轴自适应增强（MAAE）。该模型能防止过度增强和饱和，同时处理水下挑战。广泛的实验表明，MAC-Lookup在水下图像增强方面表现出色，比现有方法更好地恢复了细节和颜色。代码链接为：https://github.com/onlycatdoraemon/MAC-Lookup。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [246] [Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation](https://arxiv.org/abs/2507.02271)
> *通过自蒸馏突出部分可见电影语言的视频到音频生成*

*Feizhen Huang, Yu Wu, Yutian Lin, Bo Du* | **Category: cs.CV, cs.AI, cs.MM** | **Updated: {updated}**

**Keywords:** 视频到音频生成, 电影语言, 自蒸馏, 部分可见, 拟音

**Comment:** Accepted by IJCAI 2025

> **TL;DR:** 该论文提出了一种简单的自蒸馏方法，用于视频到音频（V2A）生成，以解决现有方法忽略电影语言导致在部分可见场景下性能下降的问题，并在部分可见场景和大规模V2A数据集上取得了显著改进。

**AI_Comments:** 该论文通过引入自蒸馏来解决V2A生成中电影语言的挑战，具有创新性。它关注了电影制作中一个被忽视但重要的方面——电影语言，特别是在处理部分可见信息时的能力，这对于提高V2A模型的鲁棒性和艺术性表达至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前视频到音频（V2A）生成方法忽视了电影语言，导致在拟音目标部分可见的场景中性能下降。为了解决这一挑战，本文旨在扩展V2A模型以适应电影语言场景。

**Method:** 本文提出了一种简单的自蒸馏方法。通过模拟电影语言的变化，学生模型学习对齐训练对的视频特征与相同的视听对应关系，从而有效捕捉声音与部分视觉信息之间的关联。

**Result:** 该方法不仅在部分可见场景下所有评估指标上都取得了显著改进，而且在大规模V2A数据集VGGSound上也提升了性能。

**Conclusion:** 通过提出的自蒸馏方法，模型能够有效捕捉声音与部分视觉信息之间的关联，显著提升了在部分可见场景以及大规模数据集上的视频到音频生成性能，解决了现有方法忽视电影语言的问题。

> **ai_Abstract:** 本论文提出了一种名为自蒸馏的简单方法，旨在解决视频到音频（V2A）生成中现有模型忽视电影语言导致在部分可见场景下性能不佳的问题。通过模拟电影语言变化，该方法使模型能够学习声音与部分视觉信息之间的关联。实验结果表明，该方法在部分可见场景下显著提升了性能，并优化了在大规模V2A数据集VGGSound上的表现。

> **摘要翻译:** 视频到音频（V2A）生成取得了显著进展，并在电影和视频后期制作中发挥着关键作用。然而，当前方法忽视了电影语言，这是电影制作中艺术表达的关键组成部分。结果，在拟音目标仅部分可见的场景中，它们的性能会下降。为了解决这一挑战，我们提出了一种简单的自蒸馏方法，以将V2A模型扩展到电影语言场景。通过模拟电影语言的变化，学生模型学习对齐训练对的视频特征与相同的视听对应关系，使其能够有效捕捉声音与部分视觉信息之间的关联。我们的方法不仅在部分可见性下所有评估指标上都取得了令人印象深刻的改进，而且还增强了在大规模V2A数据集VGGSound上的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2507.02279)
> *LaCo：多模态大型语言模型视觉Token的高效逐层压缩*

*Juntao Liu, Liqiang Niu, Wenchao Chen, Jie Zhou, Fandong Meng* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 视觉Token压缩, 多模态大型语言模型, 逐层压缩, 效率, LaCo

**Comment:** 

> **TL;DR:** LaCo提出了一种新的逐层视觉Token压缩框架，它在视觉编码器的中间层进行压缩，通过逐层像素混洗机制和残差学习架构，显著提高了多模态大型语言模型的训练和推理效率，同时保持了强大的性能。

**AI_Comments:** LaCo的创新点在于将视觉Token压缩从传统的编码器后处理移至视觉编码器内部的中间层，这是一种更深层次的优化。其逐层像素混洗机制和残差学习架构设计巧妙，有效平衡了压缩效率与信息保留。该方法对于提升多模态大模型的训练和推理效率具有重要意义，有望降低其部署成本。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大型语言模型（MLLMs）视觉Token压缩方法主要作为编码器后模块运行，限制了它们的效率提升潜力。本文旨在解决这一限制。

**Method:** 本文提出了LaCo（逐层视觉Token压缩）框架，它在视觉编码器的中间层进行有效的Token压缩。LaCo引入了两个核心组件：1）逐层像素混洗机制，通过空间到通道的转换系统地合并相邻Token；2）带有非参数快捷方式的残差学习架构，在压缩过程中保留关键视觉信息。

**Result:** LaCo在视觉编码器中间层压缩Token时，性能优于所有现有方法，显示出卓越的有效性。与外部压缩相比，LaCo在保持强大性能的同时，将训练效率提高了20%以上，推理吞吐量提高了15%以上。

**Conclusion:** LaCo通过在视觉编码器中间层进行高效的Token压缩，显著提升了多模态大型语言模型的训练和推理效率，并优于现有方法，证明了其在视觉Token压缩领域的有效性和优越性。

> **ai_Abstract:** LaCo是一种新颖的视觉Token压缩框架，专为多模态大型语言模型设计，旨在解决现有压缩方法效率受限的问题。它通过在视觉编码器的中间层进行逐层压缩，利用像素混洗机制合并Token并结合残差学习保留关键信息。实验证明，LaCo在效果上超越了现有方法，并在训练效率和推理吞吐量上实现了显著提升，同时保持了高性能。

> **摘要翻译:** 现有用于多模态大型语言模型（MLLMs）的视觉Token压缩方法主要作为编码器后模块运行，这限制了它们的效率提升潜力。为了解决这一限制，我们提出了LaCo（逐层视觉Token压缩），一个新颖的框架，能够在视觉编码器的中间层实现有效的Token压缩。LaCo引入了两个核心组件：1）一个逐层像素混洗机制，通过空间到通道的转换系统地合并相邻Token；2）一个带有非参数快捷方式的残差学习架构，在压缩过程中保留关键视觉信息。大量的实验表明，我们的LaCo在视觉编码器中间层压缩Token时，性能优于所有现有方法，展示出卓越的有效性。此外，与外部压缩相比，我们的方法在保持强大性能的同时，将训练效率提高了20%以上，推理吞吐量提高了15%以上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [265] [Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization](https://arxiv.org/abs/2507.02288)
> *通过语言指导和表示对齐实现域泛化的提示解耦*

*De Cheng, Zhipeng Xu, Xinyang Jiang, Dongsheng Li, Nannan Wang, Xinbo Gao* | **Category: cs.CV, cs.LG** | **Updated: {updated}**

**Keywords:** 提示解耦, 域泛化, 语言指导, 视觉基础模型, 表示对齐

**Comment:** 

> **TL;DR:** 该论文提出了一种新的域泛化框架，通过语言指导的视觉提示微调和表示对齐来解耦领域不变特征，以提高模型在未见域上的性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合语言指导和表示对齐的域泛化框架。通过利用LLM解耦文本提示来指导视觉特征学习，以及引入WERA来克服单一模态指导的局限性并增强数据多样性，有效提升了模型在未见域上的泛化能力。这种多模态和多策略结合的方法为域泛化研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在域泛化（DG）中，尽管基于VFM的域提示微调受到越来越多的关注，但有效设计能够解耦跨不同域不变特征的提示仍然是一个关键挑战。此外，仅依靠语言指导视觉特征解耦存在局限性，因为视觉特征有时过于复杂或细微，无法通过描述性文本完全捕捉。

**Method:** 本文提出了一种新颖的文本特征引导视觉提示微调框架。该框架首先使用大型语言模型（LLM）自动解耦文本提示，然后学习由解耦的文本特征引导的域不变视觉表示。为了解决仅依赖语言的局限性，引入了最差显式表示对齐（WERA），通过结合一组额外的抽象提示来扩展文本引导的视觉提示。这些提示通过风格化图像增强来提高源域多样性，同时对齐约束确保视觉表示在原始和增强分布中保持一致。

**Result:** 在包括PACS、VLCS、OfficeHome、DomainNet和TerraInc在内的主要DG数据集上进行的实验表明，本文提出的方法优于最先进的DG方法。

**Conclusion:** 本文通过利用VFM的可控和灵活的语言提示，并引入文本特征引导的视觉提示微调框架，成功解决了域泛化中不变特征解耦的挑战。通过进一步引入最差显式表示对齐（WERA），解决了纯语言指导的局限性，并通过实验证明了其在多个DG数据集上的优越性能。

> **ai_Abstract:** 该论文针对域泛化（DG）中不变特征解耦的挑战，提出了一种名为“通过语言指导和表示对齐实现提示解耦”的新框架。该方法利用视觉基础模型（VFM）的语言提示，首先通过大型语言模型（LLM）解耦文本提示，然后利用这些解耦的文本特征指导视觉提示微调，以学习域不变的视觉表示。为克服纯语言指导的局限性，论文引入了最差显式表示对齐（WERA），通过抽象提示和风格化图像增强来增加源域多样性，并确保视觉表示在原始和增强分布之间的一致性。实验结果表明，该方法在多个主流DG数据集上优于现有最先进的方法。

> **摘要翻译:** 域泛化（DG）旨在开发一种通用的模型，使其能够在未见的M标域上有效运行。值得注意的是，预训练视觉基础模型（VFM）的最新进展，如CLIP，在增强深度学习模型的泛化能力方面显示出巨大的潜力。尽管基于VFM的域提示微调在DG中受到越来越多的关注，但有效设计能够解耦跨不同域不变特征的提示仍然是一个关键挑战。在本文中，我们提出通过利用VFM的可控和灵活的语言提示来解决这一挑战。注意到VFM的文本模态自然更容易解耦，我们引入了一种新颖的文本特征引导视觉提示微调框架。该框架首先使用大型语言模型（LLM）自动解耦文本提示，然后学习由解耦的文本特征引导的域不变视觉表示。然而，仅依靠语言来引导视觉特征解耦存在局限性，因为视觉特征有时过于复杂或细微，无法通过描述性文本完全捕捉。为了解决这个问题，我们引入了最差显式表示对齐（WERA），它通过结合一组额外的抽象提示来扩展文本引导的视觉提示。这些提示通过风格化图像增强来提高源域多样性，同时对齐约束确保视觉表示在原始和增强分布中保持一致。在包括PACS、VLCS、OfficeHome、DomainNet和TerraInc在内的主要DG数据集上进行的实验表明，我们提出的方法优于最先进的DG方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation](https://arxiv.org/abs/2507.02294)
> *ViRefSAM：遥感图像分割的视觉参考引导通用分割模型*

*Hanbo Bi, Yulong Xu, Ya Li, Yongqiang Mao, Boyuan Tong, Chongyang Li, Chunbo Lang, Wenhui Diao, Hongqi Wang, Yingchao Feng, Xian Sun* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 遥感图像分割, 通用分割模型 (SAM), 少样本学习, 视觉参考, 自动分割

**Comment:** 

> **TL;DR:** ViRefSAM通过少量参考图像自动分割遥感图像中的未知类别，解决了SAM在遥感领域手动提示和领域适应性的问题。

**AI_Comments:** ViRefSAM的创新之处在于其通过视觉参考引导的方式，有效解决了SAM在遥感领域应用中的两大核心挑战：繁琐的手动提示和缺乏领域适应性。它在不修改SAM核心架构的前提下，通过引入两个巧妙的组件，实现了对未知类别的自动、准确分割，这对于遥感图像分析具有重要意义，大大提升了分割效率和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 通用分割模型 (SAM) 在遥感 (RS) 图像应用中面临两大挑战：一是手动构建精确提示费时费力，尤其是在遥感图像中目标密集或分布零散时；二是SAM主要在自然图像上预训练，缺乏领域适应性，难以捕捉遥感特有的语义和空间特性，尤其是在分割新类别时。

**Method:** 受少样本学习启发，本文提出了ViRefSAM框架，通过少量带标注的参考图像来引导SAM，无需手动提示即可自动分割遥感图像中类别一致的目标。ViRefSAM在不改变SAM原始架构的前提下，引入了两个关键组件：1) 视觉上下文提示编码器 (Visual Contextual Prompt Encoder)，用于从参考图像中提取类别特有的语义线索，并通过与目标图像的上下文交互生成对象感知提示；2) 动态目标对齐适配器 (Dynamic Target Alignment Adapter)，集成到SAM的图像编码器中，通过将类别特有语义注入目标图像特征来弥补领域差距，使SAM动态关注与任务相关的区域。

**Result:** 在iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$三个少样本分割基准上的大量实验表明，ViRefSAM仅利用少量参考图像就能准确、自动地分割未知类别，并且在不同数据集上持续优于现有的少样本分割方法。

**Conclusion:** ViRefSAM成功解决了SAM在遥感图像分割中面临的手动提示和领域适应性挑战，通过引入视觉参考引导机制，实现了对未知类别的准确自动分割，并在少样本设置下表现出卓越的性能。

> **ai_Abstract:** 本研究提出ViRefSAM框架，旨在解决通用分割模型SAM在遥感图像分割中面临的手动提示低效和领域适应性不足的问题。ViRefSAM受少样本学习启发，通过少量带标注的参考图像引导SAM，无需手动提示即可实现对遥感图像中未知类别的自动分割。该框架引入了视觉上下文提示编码器和动态目标对齐适配器，分别用于提取类别语义并弥补领域差距。实验证明，ViRefSAM在多个少样本分割基准上表现出色，实现了对未见类别的准确自动分割，并优于现有方法。

> **摘要翻译:** 通用分割模型 (SAM) 凭借其提示驱动范式，在通用分割任务中展现出强大的泛化能力。然而，将SAM应用于遥感 (RS) 图像仍面临两大挑战。首先，为每张图像手动构建精确的提示（例如，点或框）费时费力且效率低下，尤其是在遥感场景中，目标可能密集细小或空间分布零散。其次，SAM缺乏领域适应性，因为它主要在自然图像上进行预训练，难以捕捉遥感特有的语义和空间特性，尤其是在分割新颖或未见过的类别时。为了解决这些问题，受少样本学习的启发，我们提出了ViRefSAM，一个新颖的框架，它仅利用少量包含特定类别对象的带标注参考图像来引导SAM。ViRefSAM无需手动提示，即可实现遥感图像中类别一致对象的自动分割。具体而言，ViRefSAM在保持SAM原始架构不变的情况下，引入了两个关键组件：(1) 一个视觉上下文提示编码器，用于从参考图像中提取类别特有的语义线索，并通过与目标图像的上下文交互生成对象感知提示；(2) 一个动态目标对齐适配器，集成到SAM的图像编码器中，通过将类别特有语义注入目标图像特征来弥补领域差距，使SAM能够动态关注与任务相关的区域。在包括iSAID-5$^i$、LoveDA-2$^i$和COCO-20$^i$在内的三个少样本分割基准上的大量实验表明，ViRefSAM仅利用少量参考图像就能实现对未见类别的准确自动分割，并且在不同数据集上持续优于现有的少样本分割方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [280] [DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation](https://arxiv.org/abs/2507.02299)
> *DreamComposer++：利用多视角条件增强扩散模型以生成3D内容*

*Yunhan Yang, Shuo Chen, Yukun Huang, Xiaoyang Wu, Yuan-Chen Guo, Edmund Y. Lam, Hengshuang Zhao, Tong He, Xihui Liu* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 扩散模型, 3D内容生成, 多视角, 新颖视图合成, 可控性

**Comment:** Accepted by TPAMI, extension of CVPR 2024 paper DreamComposer

> **TL;DR:** DreamComposer++是一个新的框架，通过引入多视角条件来改进现有视图感知扩散模型，从而实现可控的新颖视图合成和3D内容生成。

**AI_Comments:** DreamComposer++的创新之处在于其引入多视角条件来增强扩散模型生成可控3D内容的能力，解决了现有方法在可控性方面的痛点。其模块化的设计使其能够与现有先进的视图感知扩散模型无缝集成，这表明了其良好的兼容性和扩展性。该方法对于3D内容生成和重建领域具有重要意义，有望推动更精细和可控的3D模型创建。

<details>
  <summary>Details</summary>

**Motivation:** 现有利用预训练2D扩散模型生成高质量新颖视图的方法，在生成可控的新颖视图方面面临挑战，原因是缺乏多视角信息。

**Method:** DreamComposer++是一个灵活且可扩展的框架，通过整合多视角条件来改进视图感知扩散模型。它使用一个视图感知3D提升模块从不同视角提取3D表示，然后通过多视角特征融合模块将这些表示聚合并渲染到目标视图的潜在特征中。最后，将获得的目标视图特征集成到预训练的图像或视频扩散模型中进行新颖视图合成。

**Result:** 实验结果表明，DreamComposer++能够与尖端视图感知扩散模型无缝集成，并增强它们从多视角条件生成可控新颖视图的能力。

**Conclusion:** DreamComposer++的进展促进了可控的3D对象重建，并支持广泛的应用。

> **ai_Abstract:** DreamComposer++是一个创新的框架，旨在通过整合多视角条件来增强2D扩散模型在3D内容生成中的能力。针对现有方法在可控新颖视图合成中面临的挑战，DreamComposer++引入了一个视图感知3D提升模块和多视角特征融合模块，以从多视角中提取、聚合并融合3D表示，最终将其集成到预训练扩散模型中。实验证明，该方法显著提升了生成可控新颖视图的能力，并有望推动可控3D对象重建及相关应用。

> **摘要翻译:** 近期在利用预训练2D扩散模型方面取得的进展，实现了从单张野外图像生成高质量新颖视图。然而，现有工作由于缺乏多视角信息，在生成可控新颖视图方面面临挑战。在本文中，我们提出了DreamComposer++，一个灵活且可扩展的框架，旨在通过整合多视角条件来改进当前的视图感知扩散模型。具体来说，DreamComposer++利用一个视图感知3D提升模块从不同视角提取物体的3D表示。然后，这些表示通过多视角特征融合模块被聚合并渲染到目标视图的潜在特征中。最后，将获得的目标视图特征集成到预训练的图像或视频扩散模型中进行新颖视图合成。实验结果表明，DreamComposer++与尖端视图感知扩散模型无缝集成，并增强了它们从多视角条件生成可控新颖视图的能力。这一进展促进了可控的3D对象重建并支持广泛的应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [288] [Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images](https://arxiv.org/abs/2507.02307)
> *Flow-CDNet：一种用于检测双时相图像中慢速和快速变化的新型网络*

*Haoxuan Li, Chenxu Wei, Haodong Wang, Xiaomeng Hu, Boyuan An, Lingyan Ran, Baosen Zhang, Jin Jin, Omirzhan Taukebayev, Amirkhan Temirbayev, Junrui Liu, Xiuwei Zhang* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 变化检测, 慢速变化, 快速变化, 光学流, 双时相图像

**Comment:** 18 pages, 8 figures

> **TL;DR:** Flow-CDNet是一种新颖的网络，通过结合光学流和二元变化检测分支，有效检测双时相图像中的慢速和快速变化，并在自建数据集上表现优于现有方法。

**AI_Comments:** 这篇论文的创新点在于它解决了同时检测图像中慢速和快速变化的挑战，这在现有研究中相对较少被关注，但具有重要的实际应用价值。其提出的双分支网络结构，特别是结合光学流来捕捉细微位移变化，是一个巧妙的设计。此外，自建数据集、新的损失函数和评估指标的提出，也为该领域的研究提供了新的资源和工具，显示了研究的全面性。

<details>
  <summary>Details</summary>

**Motivation:** 现有变化检测方法通常关注显著变化，但慢速变化在实际场景中同样重要，例如作为重大灾害（如边坡、水坝、尾矿库）的前兆。因此，设计一个能同时检测慢速和快速变化的网络是一个新颖的挑战。

**Method:** 本文提出了一种名为Flow-CDNet的变化检测网络，它包含两个分支：光学流分支和二元变化检测分支。光学流分支利用金字塔结构提取多尺度位移变化，而二元变化检测分支结合基于ResNet的网络和光学流分支的输出来生成快速变化输出。此外，为监督和评估该框架，作者构建了一个名为Flow-Change的数据集，设计了一个结合二元Tversky损失和L2范数损失的损失函数，并提出了一种新的评估指标FEPE。

**Result:** 在Flow-Change数据集上进行的定量实验表明，Flow-CDNet的性能优于现有方法。消融实验验证了两个分支可以相互促进，从而提高检测性能。

**Conclusion:** Flow-CDNet能够有效检测双时相图像中的慢速和快速变化，并通过其双分支结构和新颖的数据集、损失函数及评估指标，在变化检测领域取得了显著进展。

> **ai_Abstract:** Flow-CDNet是一种新颖的变化检测网络，旨在同时检测双时相图像中的慢速和快速变化。针对慢速变化作为潜在灾害前兆的重要性，该网络采用双分支结构，包括一个利用金字塔提取多尺度位移的光学流分支和一个结合光学流输出的二元变化检测分支。为支持该框架，作者构建了Flow-Change数据集，设计了结合Tversky和L2范数损失的损失函数，并提出了FEPE评估指标。实验证明，Flow-CDNet在自建数据集上优于现有方法，且双分支设计有效提升了检测性能。

> **摘要翻译:** 变化检测通常涉及识别在同一位置拍摄的双时相图像之间的变化区域。除了显著变化，双时相图像中的慢速变化在现实场景中也同样重要。例如，在边坡、水坝和尾矿库等场景中，微弱的变化往往是重大灾害的前兆。因此，设计一个能够同时检测慢速和快速变化的变化检测网络提出了一个新颖的挑战。在本文中，为了应对这一挑战，我们提出了一种名为Flow-CDNet的变化检测网络，它由两个分支组成：光学流分支和二元变化检测分支。第一个分支利用金字塔结构提取多尺度位移变化。第二个分支将基于ResNet的网络与光学流分支的输出相结合，以生成快速变化输出。随后，为了监督和评估这个新的变化检测框架，我们设计了一个自建的变化检测数据集Flow-Change，一个结合二元Tversky损失和L2范数损失的损失函数，以及一个新的评估指标FEPE。在Flow-Change数据集上进行的定量实验表明，我们的方法优于现有方法。此外，消融实验验证了这两个分支可以相互促进，从而提高检测性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [291] [Privacy-preserving Preselection for Face Identification Based on Packing](https://arxiv.org/abs/2507.02414)
> *基于打包的隐私保护人脸识别预筛选*

*Rundong Xin, Taotao Wang, Jin Wang, Chonghe Zhao, Jing Wang* | **Category: cs.CV, cs.CR** | **Updated: {updated}**

**Keywords:** 隐私保护, 人脸识别, 密文域, 预筛选, 打包

**Comment:** This paper has been accepted for publication in SecureComm 2025

> **TL;DR:** PFIP是一种新颖高效的密文域人脸识别方案，通过预筛选和打包模块显著提高了检索效率（近50倍），同时保持了识别精度（100%命中率），解决了大规模密文模板库检索耗时的问题。

**AI_Comments:** 该论文提出了一种创新的隐私保护人脸识别方案PFIP，其核心创新在于结合了预筛选机制和打包模块，有效解决了密文域大规模人脸数据检索的效率瓶颈。在保证100%命中率的前提下，实现了近50倍的效率提升，这对于实际部署具有重要意义。该工作在隐私保护和系统性能之间取得了很好的平衡。

<details>
  <summary>Details</summary>

**Motivation:** 由于隐私泄露担忧和原始面部数据恢复的风险，密文域人脸识别系统受到关注。然而，随着密文模板库规模的增长，人脸检索过程变得耗时。

**Method:** 本文提出了一种名为PFIP（基于打包的隐私保护人脸识别预筛选）的新型高效密文域人脸检索方案。PFIP包含一个创新的预筛选机制以减少计算开销，以及一个打包模块以增强生物识别系统在注册阶段的灵活性。

**Result:** 在LFW和CASIA数据集上进行的广泛实验表明，PFIP保持了原始人脸识别模型的准确性，实现了100%的命中率，并在300毫秒内检索了1,000个密文人脸模板。与现有方法相比，PFIP的检索效率提高了近50倍。

**Conclusion:** PFIP成功地解决了大规模密文域人脸识别中检索效率低下的问题，显著提高了性能，同时保持了高准确性。

> **ai_Abstract:** 本文提出了一种名为PFIP的隐私保护人脸识别预筛选方案，旨在解决大规模密文域人脸识别系统中检索效率低下的问题。PFIP通过引入创新的预筛选机制和打包模块，显著降低了计算开销并提升了系统灵活性。实验结果显示，PFIP在保持原始识别模型准确性的同时，实现了100%的命中率，并将1,000个密文模板的检索时间缩短至300毫秒内，相比现有方法效率提升了近50倍。

> **摘要翻译:** 密文域人脸识别系统因日益增长的隐私问题和原始面部数据恢复的可能性而受到广泛关注。然而，随着密文模板库规模的增长，人脸检索过程变得越来越耗时。为了解决这一挑战，我们提出了一种新颖高效的密文域人脸检索方案，命名为基于打包的隐私保护人脸识别预筛选（PFIP）。PFIP包含一个创新的预筛选机制以减少计算开销，以及一个打包模块以增强生物识别系统在注册阶段的灵活性。在LFW和CASIA数据集上进行的广泛实验表明，PFIP保持了原始人脸识别模型的准确性，实现了100%的命中率，并在300毫秒内检索了1,000个密文人脸模板。与现有方法相比，PFIP的检索效率提高了近50倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [294] [LMPNet for Weakly-supervised Keypoint Discovery](https://arxiv.org/abs/2507.02308)
> *弱监督关键点发现的LMPNet*

*Pei Guo, Ryan Farrell* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 弱监督学习, 关键点发现, LMPNet, 语义关键点, 姿态估计

**Comment:** 

> **TL;DR:** 本文提出LMPNet，通过新颖的LMP层和弱监督方法，自动发现语义关键点，性能媲美全监督模型。

**AI_Comments:** 这篇论文的创新点在于提出了LMP层和一系列策略，使得模型能够在仅有类别标签的弱监督条件下，自动发现具有语义意义且对姿态鲁棒的关键点。其直接操纵网络滤波器实现关键点检测的方法，提高了模型的可解释性，是弱监督学习领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 探索仅通过类别标签进行弱监督的语义对象关键点发现任务，并解决将判别性训练的中间层滤波器转化为关键点检测器的问题，同时满足关键点检测器稀疏激活、一致性和多样性的特性。

**Method:** 提出了一种新颖的计算高效的Leaky Max Pooling (LMP) 层，以促使最终卷积层滤波器学习与对象关键点对齐的“不可重复局部模式”。还提出了一种简单有效的选择策略以确保滤波器激活的一致性，并应用注意力遮蔽（attention mask-out）以强制网络将注意力分散到整个对象。最后，提出一个可学习的聚类层来将关键点提议分组为最终的关键点预测。

**Result:** LMPNet能够自动发现对对象姿态具有鲁棒性的语义关键点。其预测精度与监督姿态估计模型相当。

**Conclusion:** LMPNet是一个高度可解释的模型，它通过直接操纵网络滤波器来检测预定义概念，并在弱监督下成功实现了语义关键点的自动发现，达到了与全监督模型相当的性能。

> **ai_Abstract:** 本文提出LMPNet，一个用于弱监督语义关键点发现的模型。该模型通过新颖的Leaky Max Pooling (LMP) 层，促使网络学习“不可重复局部模式”，并结合选择策略、注意力遮蔽和可学习聚类层，将判别性训练的中间层滤波器转换为鲁棒的关键点检测器。实验证明LMPNet能自动发现语义关键点，且在精度上可与全监督模型媲美。

> **摘要翻译:** 在这项工作中，我们探索了仅通过类别标签进行弱监督的语义对象关键点发现任务。这是通过将判别性训练的中间层滤波器转换为关键点检测器来实现的。我们首先确定了关键点检测器的三个优选特征：(i) 空间稀疏激活，(ii) 一致性和 (iii) 多样性。我们没有依赖手工设计的损失项，而是提出了一种新颖的计算高效的Leaky Max Pooling (LMP) 层，以明确鼓励最终卷积层滤波器学习与对象关键点良好对齐的“不可重复局部模式”。根据可视化结果，我们提出了一种简单而有效的选择策略，以确保滤波器激活的一致性，然后应用注意力遮蔽（attention mask-out）来强制网络将注意力分散到整个对象，而不是仅仅是最具判别性的区域。对于最终的关键点预测，我们提出了一个可学习的聚类层，将关键点提议分组为关键点预测。最终模型命名为LMPNet，它具有高度可解释性，因为它直接操纵网络滤波器来检测预定义概念。我们的实验表明，LMPNet能够 (i) 自动发现对对象姿态具有鲁棒性的语义关键点，并且 (ii) 实现了与监督姿态估计模型相当的强大预测精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [300] [Perception Activator: An intuitive and portable framework for brain cognitive exploration](https://arxiv.org/abs/2507.02311)
> *感知激活器：一个用于大脑认知探索的直观便携式框架*

*Le Xu, Qi Zhang, Qixian Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 脑-视觉解码, fMRI, 语义对齐, 目标检测, 实例分割

**Comment:** 

> **TL;DR:** 本文提出了一个名为“感知激活器”的实验框架，通过将fMRI信号注入图像特征来提升目标检测和实例分割的准确性，并揭示fMRI包含了丰富的多对象语义信息。

**AI_Comments:** 本文提出的“感知激活器”框架通过将fMRI信息直接整合到图像特征中，为脑-视觉解码提供了一个新颖且直观的方法。其创新之处在于利用fMRI作为干预条件来增强下游视觉任务的性能，并明确指出fMRI包含丰富的语义和空间信息，这对于未来更精确的脑解码模型具有重要指导意义。该研究的重要性在于揭示了fMRI信号中未被充分利用的语义潜力，并为开发更高效、更符合大脑认知机制的解码模型提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脑-视觉解码方法在像素级对齐方面表现良好，但在细粒度语义对齐方面存在不足，导致多语义对象重建失真。本文旨在更好地理解大脑的视觉感知模式以及当前解码模型如何处理语义对象。

**Method:** 本文开发了一个实验框架，将fMRI表征作为干预条件。通过交叉注意力机制将这些fMRI表征注入多尺度图像特征中，并比较在有无fMRI信息的情况下，目标检测和实例分割任务的下游性能和中间特征变化。

**Result:** 结果表明，整合fMRI信号能够提高下游检测和分割的准确性，证实fMRI包含了丰富的多对象语义线索和粗略的空间定位信息。

**Conclusion:** fMRI信号包含丰富的多对象语义线索和粗略的空间定位信息，这些是当前模型尚未充分利用或整合的元素。

> **ai_Abstract:** 本文提出了一种名为“感知激活器”的实验框架，旨在解决现有脑-视觉解码模型在细粒度语义对齐方面的不足。该框架将fMRI表征作为干预条件，通过交叉注意力机制将其注入多尺度图像特征中。在目标检测和实例分割任务上的实验结果表明，整合fMRI信号能显著提升准确性，证实了fMRI中蕴含着丰富的多对象语义线索和粗略的空间定位信息，这些信息有待现有模型进一步利用。

> **摘要翻译:** 脑-视觉解码的最新进展推动了显著的进步，能够从人类视觉皮层的神经活动（例如功能性磁共振成像fMRI）中高保真地重建感知的视觉刺激。大多数现有方法使用两级策略（即像素级和语义级）解码脑信号。然而，这些方法严重依赖低级像素对齐，却缺乏足够和细粒度的语义对齐，导致多个语义对象的重建出现明显的失真。为了更好地理解大脑的视觉感知模式以及当前解码模型如何处理语义对象，我们开发了一个实验框架，该框架使用fMRI表征作为干预条件。通过交叉注意力机制将这些表征注入多尺度图像特征中，我们比较了在有无fMRI信息的情况下，目标检测和实例分割任务的下游性能和中间特征变化。我们的结果表明，整合fMRI信号能够提高下游检测和分割的准确性，证实fMRI包含了丰富的多对象语义线索和粗略的空间定位信息——这些是当前模型尚未充分利用或整合的元素。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [306] [MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation](https://arxiv.org/abs/2507.02314)
> *MAGIC：基于掩码引导扩散修复的多级扰动和上下文感知对齐的少样本异常生成*

*JaeHyuck Choi, MinJun Kim, JeHyeong Hong* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 少样本异常生成, 扩散模型, 图像修复, 质量控制, 掩码引导

**Comment:** 10 pages, 6 figures

> **TL;DR:** 本论文提出了MAGIC，一种基于扩散的少样本异常生成方法，解决了背景损坏、掩码错位和多样性不足等问题，并在下游异常任务中超越了现有技术。

**AI_Comments:** 这项工作通过提出MAGIC，有效地解决了少样本异常生成中的关键挑战，即在保持背景完整、精确掩码对齐的同时生成多样且语义合理的异常。其创新点在于结合了微调Stable Diffusion、多级扰动策略以及上下文感知对齐模块，全面提升了生成质量和实用性，对于工业质量控制中的数据增强具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 少样本异常生成是工业质量控制中增强稀缺异常数据的实用解决方案。现有的基于扩散的方法未能同时满足保持正常背景、精确修复异常区域以及在语义有效位置生成异常这三个关键需求，常导致背景损坏或在掩码不精确时失效。

**Method:** MAGIC通过微调一个Stable Diffusion修复骨干网络来保留正常区域并确保合成异常严格遵循提供的掩码。为解决多样性损失，它引入了两种互补的扰动策略：高斯提示级扰动（用于全局外观多样性）和掩码引导的空间噪声注入（用于局部纹理变化）。此外，上下文感知掩码对齐模块用于形成语义对应并重新定位掩码，以确保异常合理地包含在宿主对象内。

**Result:** 在MVTec-AD数据集上，采用一致的评估协议，MAGIC在下游异常任务中优于先前的最新技术。

**Conclusion:** MAGIC成功解决了少样本异常生成中背景损坏、掩码错位和多样性不足这三个核心问题，并在性能上超越了现有方法。

> **ai_Abstract:** 本论文提出了MAGIC，一种用于少样本异常生成的掩码引导扩散修复方法。针对现有方法在背景保持、掩码对齐和生成多样性方面的不足，MAGIC通过微调Stable Diffusion骨干网络以保护正常区域并确保异常与掩码严格一致。为提高多样性，它引入了高斯提示级扰动和掩码引导的空间噪声注入。此外，上下文感知掩码对齐模块确保异常在语义上合理地定位。在MVTec-AD数据集上的实验表明，MAGIC在下游异常任务中优于现有最先进方法。

> **摘要翻译:** 少样本异常生成正成为工业质量控制中用于增强稀缺异常数据的实用解决方案。一个理想的生成器应同时满足三个需求：(i) 保持正常背景完好无损，(ii) 修复异常区域以与相应的异常掩码紧密重叠，以及 (iii) 在语义有效的位置生成异常区域，同时仅从少数真实示例中生成逼真、多样化的外观。现有的基于扩散的方法通常最多满足其中两个要求：全局异常生成器会破坏背景，而掩码引导的生成器在掩码不精确或错位时常常失效。我们提出了MAGIC——基于多级扰动和上下文感知对齐的掩码引导修复——来解决所有这三个问题。其核心是，MAGIC微调了一个Stable Diffusion修复骨干网络，该网络保留了正常区域并确保合成的异常严格遵守提供的掩码，直接解决了背景损坏和错位问题。为了抵消微调可能导致的多样性损失，MAGIC增加了两种互补的扰动策略：(i) 在微调和推理过程中应用的高斯提示级扰动，扩大了异常的全局外观，同时避免了低保真度的文本外观，以及 (ii) 掩码引导的空间噪声注入，丰富了局部纹理变化。此外，上下文感知掩码对齐模块形成语义对应并重新定位掩码，使每个异常都合理地包含在宿主对象内，消除了越界伪影。在MVTec-AD数据集上采用一致的相同评估协议下，MAGIC在下游异常任务中优于先前的最新技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [309] [Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection](https://arxiv.org/abs/2507.02844)
> *视觉上下文攻击：通过图像驱动的上下文注入越狱多模态大语言模型*

*Ziqi Miao, Yi Ding, Lijun Li, Jing Shao* | **Category: cs.CV, cs.CL, cs.CR** | **Updated: {updated}**

**Keywords:** 视觉上下文攻击, 越狱, 多模态大语言模型, 视觉模态, 上下文注入

**Comment:** 16 pages

> **TL;DR:** 本文提出了VisCo（视觉上下文）攻击，这是一种新颖的视觉中心化越狱方法，通过图像驱动的上下文注入来可靠地触发多模态大语言模型（MLLMs）的有害响应，显著优于现有基线。

**AI_Comments:** 本文的创新之处在于将视觉信息从单纯的触发器提升为构建真实越狱上下文的必要核心组件，这揭示了多模态大语言模型（MLLMs）一个关键且未被充分探索的安全漏洞。VisCo攻击在对抗GPT-4o时展现出高攻击成功率，凸显了该新型攻击向量的有效性和解决其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在现实世界应用中展现出巨大潜力，但其视觉模态的安全漏洞构成了部署挑战。现有研究虽然能通过视觉输入诱导有害响应，但视觉模态多作为触发器，语义模糊且缺乏现实场景的接地性。

**Method:** 本文定义了一种新颖的“视觉中心化越狱”设置，其中视觉信息是构建完整且真实越狱上下文的必要组成部分。在此基础上，提出了VisCo（视觉上下文）攻击。VisCo利用四种独特的以视觉为中心的策略来构建上下文对话，并在必要时动态生成辅助图像以构建视觉中心化越狱场景。为最大化攻击效果，它还结合了自动毒性混淆和语义细化，以生成最终的攻击提示，可靠地触发目标黑盒MLLMs的有害响应。

**Result:** VisCo攻击在MM-SafetyBench上针对GPT-4o实现了4.78的毒性评分和85%的攻击成功率（ASR），显著优于基线（毒性评分2.48，ASR 22.2%）。

**Conclusion:** 本文证明了视觉信息可以作为多模态大语言模型（MLLMs）真实越狱上下文的核心组成部分，并且所提出的VisCo攻击在利用这些漏洞方面非常有效。

> **ai_Abstract:** 本文提出了一种新颖的视觉中心化越狱方法——VisCo（视觉上下文）攻击，旨在解决多模态大语言模型（MLLMs）在视觉模态上的安全漏洞。与现有方法将视觉作为简单触发器不同，VisCo强调视觉信息作为构建完整且真实越狱上下文的核心必要组件。该方法通过四种视觉聚焦策略构建上下文对话，并动态生成辅助图像，同时结合自动毒性混淆和语义细化，以可靠地诱导黑盒MLLMs产生有害响应。实验结果表明，VisCo在MM-SafetyBench上针对GPT-4o的攻击成功率高达85%，毒性评分为4.78，显著优于基线。

> **摘要翻译:** 随着强大的视觉-语言能力的出现，多模态大语言模型（MLLMs）在现实世界应用中展现出巨大的潜力。然而，视觉模态所展现的安全漏洞对在开放世界环境中部署此类模型提出了重大挑战。最近的研究通过将有害的文本语义直接编码到视觉输入中，成功地诱导了目标MLLMs产生有害响应。然而，在这些方法中，视觉模态主要作为不安全行为的触发器，通常表现出语义模糊性，并且缺乏在现实场景中的接地性。在这项工作中，我们定义了一种新颖的设置：视觉中心化越狱，其中视觉信息是构建完整且真实越狱上下文的必要组成部分。在此基础上，我们提出了VisCo（视觉上下文）攻击。VisCo利用四种独特的以视觉为中心的策略来构建上下文对话，并在必要时动态生成辅助图像以构建视觉中心化越狱场景。为了最大化攻击效果，它结合了自动毒性混淆和语义细化，以生成最终的攻击提示，可靠地触发目标黑盒MLLMs的有害响应。具体而言，VisCo在MM-SafetyBench上针对GPT-4o实现了4.78的毒性评分和85%的攻击成功率（ASR），显著优于基线（毒性评分2.48，ASR 22.2%）。代码可在https://github.com/Dtc7w3PQ/Visco-Attack获得。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [312] [Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos](https://arxiv.org/abs/2507.02316)
> *合成视频有用吗？一个以检索为中心的合成视频评估基准*

*Zecheng Zhao, Selena Song, Tong Chen, Zhi Chen, Shazia Sadiq, Yadan Luo* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 合成视频, 文本到视频检索, 评估基准, 数据集增强, SynTVA

**Comment:** 7 pages, 10 figures

> **TL;DR:** 当前文生视频（T2V）的评估指标未能有效衡量合成视频在文本到视频检索（TVR）等下游任务中的效用。本研究引入SynTVA数据集和基准，用于评估合成视频在构建检索模型中的实用性，并展示其能有效提升TVR性能。

**AI_Comments:** 该论文创新性地关注了合成视频在下游任务（特别是检索）中的实际效用，而非仅仅是视觉质量。引入SynTVA数据集和基准，为评估和利用合成视频提供了新的视角和工具。其开发自动评估器以实现规模化评估的思路也具有前瞻性。该研究对于理解合成数据在实际应用中的价值，并指导未来T2V模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前文生视频（T2V）合成的评估指标主要关注视觉质量和时间一致性，但对于合成视频在文本到视频检索（TVR）等下游任务中的表现，提供的洞察有限。

**Method:** 研究引入了SynTVA，一个新数据集和基准，旨在评估合成视频用于构建检索模型的效用。基于MSRVTT训练集中派生的800个多样用户查询，使用最先进的T2V模型生成合成视频，并沿四个关键语义对齐维度（对象与场景、动作、属性和提示保真度）标注每个视频-文本对。评估框架将通用视频质量评估（VQA）指标与这些对齐分数关联起来，并检查它们对下游TVR性能的预测能力。此外，还开发了一个自动评估器，用于从现有指标估计对齐质量，以探索规模化路径。

**Result:** SynTVA被证明是数据集增强的宝贵资产，能够选择高实用性的合成样本，从而显著改善文本到视频检索（TVR）的结果。

**Conclusion:** 本研究表明，通过像SynTVA这样的专门基准进行评估和选择，合成视频可以成为有价值的资源，有效提升文本到视频检索等下游任务的性能。

> **ai_Abstract:** 本研究针对当前文生视频（T2V）评估指标在下游任务（如文本到视频检索TVR）中表现不足的问题，提出了SynTVA数据集和基准。SynTVA通过生成和标注800个合成视频-文本对，从语义对齐维度评估合成视频的实用性。研究不仅将现有视频质量评估指标与语义对齐分数关联，还开发了自动评估器以实现规模化评估。结果表明，SynTVA能有效筛选高实用性合成样本，显著提升TVR性能，证明了合成视频在数据集增强中的价值。

> **摘要翻译:** 文本到视频（T2V）合成技术已迅速发展，然而当前的评估指标主要捕捉视觉质量和时间一致性，对于合成视频在文本到视频检索（TVR）等下游任务中的表现提供的洞察有限。在这项工作中，我们引入了SynTVA，一个旨在评估合成视频用于构建检索模型效用的新数据集和基准。基于从MSRVTT训练集中派生的800个多样用户查询，我们使用最先进的T2V模型生成合成视频，并沿四个关键语义对齐维度：对象与场景、动作、属性和提示保真度，对每个视频-文本对进行了标注。我们的评估框架将通用视频质量评估（VQA）指标与这些对齐分数关联起来，并检查它们对下游TVR性能的预测能力。为了探索规模化路径，我们进一步开发了一个自动评估器，用于从现有指标估计对齐质量。除了基准测试，我们的结果表明SynTVA是数据集增强的宝贵资产，能够选择高实用性的合成样本，从而显著改善TVR结果。项目页面和数据集可在https://jasoncodemaker.github.io/SynTVA/找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [DexVLG: Dexterous Vision-Language-Grasp Model at Scale](https://arxiv.org/abs/2507.02747)
> *DexVLG：大规模灵巧视觉-语言-抓取模型*

*Jiawei He, Danshi Li, Xinqiang Yu, Zekun Qi, Wenyao Zhang, Jiayi Chen, Zhaoxiang Zhang, Zhizheng Zhang, Li Yi, He Wang* | **Category: cs.CV, cs.RO** | **Updated: {updated}**

**Keywords:** 灵巧抓取, 视觉-语言模型, 大规模数据集, 机器人操作, 零样本泛化

**Comment:** 

> **TL;DR:** DexVLG引入了一个大规模视觉-语言-抓取模型，用于通过语言指令预测灵巧抓取姿态，并利用一个包含1.7亿个抓取姿态的大型数据集，在模拟和现实世界中展示了强大的零样本泛化能力。

**AI_Comments:** 这篇论文的创新点在于构建了一个前所未有的大规模灵巧抓取数据集DexGraspNet 3.0，极大地推动了灵巧手抓取领域的发展。结合视觉-语言模型和流匹配技术，DexVLG实现了从语言指令到精细抓取姿态的映射，并在零样本条件下展现出强大的泛化能力，这对于机器人操作的实际应用具有重要意义。该工作有望弥补传统VLA系统在灵巧操作方面的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言-动作（VLA）系统在处理复杂任务时，主要集中于简单的夹持器末端执行器，而针对类人灵巧手的功能性抓取研究较少，且面临数据收集的困难。

**Method:** 本文引入了DexVLG模型，这是一个用于灵巧抓取姿态预测的大规模视觉-语言-抓取模型，通过单视图RGBD输入，并与语言指令对齐。为此，研究团队生成了一个名为DexGraspNet 3.0的大规模数据集，包含1.7亿个灵巧抓取姿态，这些姿态被映射到174,000个物体上的语义部件，并配有详细的部件级描述。该数据集用于训练一个VLM（视觉-语言模型）和一个基于流匹配的姿态头部，能够为桌面物体生成与指令对齐的抓取姿态。研究通过基于物理的模拟和真实世界实验来评估模型性能。

**Result:** DexVLG在模拟中展示了强大的零样本泛化能力，零样本执行成功率超过76%，部件抓取精度达到最先进水平。在真实世界场景中，DexVLG也成功实现了对物理物体的部件对齐抓取。

**Conclusion:** DexVLG成功地解决了大规模模型在灵巧手抓取方面的挑战，通过创新的数据集生成和模型训练方法，显著提升了机器人理解语言指令并执行复杂灵巧抓取的能力，并在模拟和现实世界中均取得了卓越的零样本泛化性能。

> **ai_Abstract:** 本文提出了DexVLG，一个大规模的视觉-语言-抓取模型，专注于解决现有VLA系统在灵巧手抓取方面的不足。为训练该模型，研究团队构建了DexGraspNet 3.0，一个包含1.7亿个灵巧抓取姿态和部件级描述的大型模拟数据集。DexVLG利用VLM和流匹配技术，能够根据语言指令从单视图RGBD输入预测灵巧抓取姿态。实验结果表明，DexVLG在模拟和真实世界中均展现出卓越的零样本泛化能力，显著提升了机器人执行复杂灵巧抓取任务的性能。

> **摘要翻译:** 随着大型模型的普及，视觉-语言-动作（VLA）系统正使机器人能够处理日益复杂的任务。然而，受限于数据收集的难度，研究进展主要集中在控制简单的夹持器末端执行器。关于使用大型模型进行类人灵巧手的功能性抓取研究甚少。在本文中，我们引入了DexVLG，一个用于灵巧抓取姿态预测的大规模视觉-语言-抓取模型，它通过单视图RGBD输入与语言指令对齐。为实现这一目标，我们在模拟中生成了一个包含1.7亿个灵巧抓取姿态的数据集，这些姿态映射到174,000个物体的语义部件，并配有详细的部件级描述。这个名为DexGraspNet 3.0的大规模数据集用于训练一个VLM和一个基于流匹配的姿态头部，能够为桌面物体生成与指令对齐的抓取姿态。为了评估DexVLG的性能，我们在基于物理的模拟中创建了基准，并进行了真实世界实验。广泛的测试表明，DexVLG具有强大的零样本泛化能力——在模拟中实现了超过76%的零样本执行成功率和最先进的部件抓取精度——并在真实世界场景中成功实现了对物理物体的部件对齐抓取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [319] [Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback](https://arxiv.org/abs/2507.02321)
> *倾听内在声音：通过中间特征反馈对齐ControlNet训练*

*Nina Konovalova, Maxim Nikolaev, Andrey Kuznetsov, Aibek Alanov* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 文本到图像扩散模型, 空间控制, ControlNet, 中间特征, 伪真实控制

**Comment:** code available at https://github.com/ControlGenAI/InnerControl

> **TL;DR:** InnerControl通过在所有扩散步骤中利用中间特征反馈来提高ControlNet的空间控制精度。

**AI_Comments:** 本文的创新点在于提出了“倾听内在声音”的理念，即通过引入轻量级卷积探针从扩散过程的中间步骤中提取并利用特征反馈，解决了以往方法忽视中间生成阶段的问题。这种在整个扩散过程中强制执行空间一致性的方法，有效地提高了文本到图像模型的空间控制精度和生成质量，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到图像扩散模型取得了显著进展，但对生成输出实现精确的空间控制仍然具有挑战性。现有的ControlNet及ControlNet++方法在空间控制上存在局限性，ControlNet++仅在最终去噪步骤应用循环一致性损失，忽略了中间生成阶段，限制了其有效性。

**Method:** 本文提出了InnerControl训练策略，通过训练轻量级卷积探针，从每个去噪步骤的中间UNet特征中重建输入控制信号（如边缘、深度）。这些探针能够从噪声潜在变量中有效提取信号，生成伪真实控制。通过在整个扩散过程中最小化预测条件与目标条件之间的差异，InnerControl强制执行空间一致性。

**Result:** InnerControl结合ControlNet++等现有技术，在多种条件方法（如边缘、深度）下实现了最先进的性能，显著提高了控制保真度和生成质量。

**Conclusion:** InnerControl通过在所有扩散步骤中强制执行空间一致性，显著提升了文本到图像扩散模型的空间控制能力和生成质量，达到了最先进水平。

> **ai_Abstract:** 本文提出InnerControl，一种新的训练策略，旨在解决ControlNet及ControlNet++在文本到图像生成中空间控制不足的问题。InnerControl通过训练轻量级卷积探针，在所有扩散步骤中从中间UNet特征重建控制信号，并引入对齐损失以在整个扩散过程中强制执行空间一致性。实验结果表明，InnerControl结合现有技术，在多种条件下显著提升了生成质量和控制保真度，达到了最先进水平。

> **摘要翻译:** 尽管文本到图像扩散模型取得了显著进展，但对生成输出实现精确的空间控制仍然具有挑战性。ControlNet通过引入辅助条件模块解决了这个问题，而ControlNet++通过仅应用于最终去噪步骤的循环一致性损失进一步完善了对齐。然而，这种方法忽略了中间生成阶段，限制了其有效性。我们提出了InnerControl，一种在所有扩散步骤中强制执行空间一致性的训练策略。我们的方法训练轻量级卷积探针，以从每个去噪步骤的中间UNet特征中重建输入控制信号（例如，边缘、深度）。这些探针即使从高度噪声的潜在变量中也能有效地提取信号，从而为训练提供伪真实控制。通过在整个扩散过程中最小化预测条件和目标条件之间的差异，我们的对齐损失提高了控制保真度和生成质量。结合ControlNet++等既定技术，InnerControl在各种条件方法（例如，边缘、深度）下实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [323] [Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model](https://arxiv.org/abs/2507.02322)
> *基于神经网络的水稻叶片病害识别与分类研究：特征模型与直接成像模型的比较分析*

*Farida Siddiqi Prity, Mirza Raquib, Saydul Akbar Murad, Md. Jubayar Alam Rafi, Md. Khairul Bashar Bhuiyan, Anupam Kumar Bairagi* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 水稻叶片病害, 神经网络, 特征提取, 图像分类, 比较分析

**Comment:** 

> **TL;DR:** 本研究比较了基于特征分析和直接图像的神经网络模型在水稻叶片病害识别和分类中的表现，发现基于特征分析的模型性能更优，有望提高水稻生产力。

**AI_Comments:** 该研究的创新之处在于对基于特征分析和直接图像输入两种不同神经网络模型在水稻病害检测中的性能进行了详细的比较分析，填补了该领域比较研究的空白。其重要性在于为水稻病害的早期、准确识别提供了有效的技术支持，有望显著减少农业损失，提高粮食安全。

<details>
  <summary>Details</summary>

**Motivation:** 水稻叶片病害严重降低生产力并造成经济损失，因此需要早期检测以实现有效管理并提高产量。尽管直接将水稻叶片图像输入人工神经网络是一种普遍方法，但缺乏对特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）之间，特别是在评估特征提取算法（FEA）有效性方面的彻底比较分析。

**Method:** 本研究提出了基于人工神经网络（ANN）的图像处理技术，用于水稻病害的及时分类和识别。研究人员对特征分析检测模型（FADM）进行了初步实验，该模型利用了各种图像特征提取算法（FEA）、降维算法（DRA）、特征选择算法（FSA）和极限学习机（ELM）。实验在包含细菌性枯萎病、褐斑病、稻瘟病、叶鞘腐烂病以及健康叶片的数据集上进行，采用10折交叉验证方法。同时建立了一个不使用任何FEA的直接图像中心检测模型（DICDM），并依据不同指标评估其分类性能。最终，对FADM和DICDM在水稻叶片病害分类方面的表现进行了全面对比。

**Result:** 结果显示，特征分析检测模型（FADM）取得了最高的性能。

**Conclusion:** 所提出的特征分析检测模型（FADM）在检测水稻叶片病害方面具有巨大潜力，有助于改善作物健康、最大程度地减少产量损失，并提高水稻种植的整体生产力和可持续性。

> **ai_Abstract:** 本研究旨在解决水稻叶片病害对生产力的影响，通过比较基于特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）的神经网络方法来识别和分类水稻病害。研究利用多种特征提取、降维和特征选择算法对FADM进行实验，并与不使用特征提取的DICDM进行对比。实验结果表明，FADM在水稻叶片病害分类中表现出更高的性能，这为提高水稻生产力和可持续性提供了新的潜力。

> **摘要翻译:** 水稻叶片病害严重降低生产力并造成经济损失，凸显了早期检测以实现有效管理和提高产量的必要性。本研究提出了基于人工神经网络（ANN）的图像处理技术，用于水稻病害的及时分类和识别。尽管将水稻叶片图像直接输入人工神经网络是一种普遍方法，但目前在评估特征提取算法（FEA）的有效性方面，特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）之间缺乏彻底的比较分析。因此，本研究对特征分析检测模型进行了初步实验，该模型利用了各种图像特征提取算法、降维算法（DRA）、特征选择算法（FSA）和极限学习机（ELM）。实验在包含细菌性枯萎病、褐斑病、稻瘟病、叶鞘腐烂病以及健康叶片的数据集上进行，采用10折交叉验证方法。同时建立了一个不使用任何FEA的直接图像中心检测模型，并依据不同指标评估其分类性能。最终，对特征分析检测模型和直接图像中心检测模型在水稻叶片病害分类方面的成就进行了全面对比。结果显示，特征分析检测模型取得了最高的性能。采用所提出的特征分析检测模型检测水稻叶片病害，在改善作物健康、最大程度地减少产量损失以及提高水稻种植的整体生产力和可持续性方面具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [326] [Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection](https://arxiv.org/abs/2507.02349)
> *用于自动脑血管地标检测的两步神经网络*

*Rafic Nader, Vincent L'Allinec, Romain Bourcier, Florent Autrusseau* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 颅内动脉瘤, 脑血管地标, 神经网络, 分叉检测, MRA

**Comment:** 

> **TL;DR:** 该论文提出了一种两步神经网络方法，用于自动准确地检测脑血管分叉（地标），以促进颅内动脉瘤的诊断，并优于现有方法。

**AI_Comments:** 该论文的创新之处在于其提出的两步神经网络方法，它专门解决了脑血管地标检测中常见的挑战，例如地标相互靠近或具有相似视觉特征以及解剖变异性，从而显著提高了检测准确性。其重要性在于为颅内动脉瘤的诊断提供了一种更鲁棒、更自动化的工具，有望改善诊断效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 颅内动脉瘤（ICA）常发生于Willis环的特定节段，主要是十三个主要动脉分叉处。准确检测这些关键地标对于及时有效的诊断至关重要。现有方法面临着地标相互靠近、视觉特征相似以及Willis环解剖变异性等问题，导致漏检。

**Method:** 本文提出了一种用于Willis环分叉的完全自动化地标检测方法，采用两步神经网络过程。首先，一个目标检测网络识别靠近地标位置的感兴趣区域（ROIs）。随后，利用一个带有深度监督的改进U-Net来精确地定位分叉。这种两步方法减少了各种问题，例如由两个地标彼此靠近且具有相似视觉特征（尤其是在处理完整的MRA飞行时间（TOF）时）引起的漏检，并考虑了Willis环的解剖变异性，这会影响每次扫描可检测地标的数量。

**Result:** 该方法在两个脑部MRA数据集上进行了评估：一个具有不同数量地标的内部数据集和一个具有标准化地标配置的公共数据集。实验结果表明，该方法在分叉检测任务上取得了最高水平的性能。

**Conclusion:** 所提出的两步神经网络方法能够有效且准确地检测脑血管分叉，解决了该领域的常见挑战，并展现出卓越的性能。

> **ai_Abstract:** 本文提出了一种新颖的两步神经网络方法，用于自动检测脑血管分叉，这些分叉是诊断颅内动脉瘤的关键地标。该方法首先利用目标检测网络识别感兴趣区域，然后通过改进的U-Net精确地定位分叉。这种方法有效缓解了因地标位置相近或视觉相似导致的漏检问题，并考虑了Willis环的解剖变异性。在两个MRA数据集上进行评估，该方法在分叉检测任务中展现出卓越的性能。

> **摘要翻译:** 颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定节段，主要位于十三个主要动脉分叉处。准确检测这些关键地标对于及时有效的诊断是必要的。我们引入了一种使用两步神经网络过程的CoW分叉完全自动化地标检测方法。最初，一个目标检测网络识别靠近地标位置的感兴趣区域（ROIs）。随后，利用一个带有深度监督的改进U-Net来精确地定位分叉。这种两步方法减少了各种问题，例如由两个地标彼此靠近且具有相似视觉特征（尤其是在处理完整的MRA飞行时间（TOF）时）引起的漏检。此外，它还考虑了CoW的解剖变异性，这会影响每次扫描可检测地标的数量。我们使用两个脑部MRA数据集评估了我们方法的有效性：我们内部的具有不同数量地标的数据集，以及一个具有标准化地标配置的公共数据集。我们的实验结果表明，我们的方法在分叉检测任务上取得了最高水平的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [329] [Lightweight Shrimp Disease Detection Research Based on YOLOv8n](https://arxiv.org/abs/2507.02354)
> *基于YOLOv8n的轻量级对虾疾病检测研究*

*Fei Yuhuan, Wang Gengchen, Liu Fenghao, Zang Ran, Sun Xufei, Chang Hao* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 对虾疾病检测, YOLOv8n, 轻量化网络, 深度学习, 计算机视觉

**Comment:** in Chinese language

> **TL;DR:** 本研究提出了一种基于YOLOv8n的轻量级对虾疾病检测网络，通过设计RLDD检测头、C2f-EMCM模块和改进的SegNext_Attention机制，显著减少了模型参数并提高了检测精度和效率，为对虾养殖的智能疾病检测提供了可靠支持。

**AI_Comments:** 该论文的创新点在于对YOLOv8n模型进行了轻量化改进，通过模块设计和注意力机制的引入，在保持甚至提升检测精度的同时大幅减少了模型参数和计算量，这对于实际应用中资源受限的设备非常重要。其在自建数据集和公开数据集上的优异表现，证明了方法的有效性和泛化能力，对智能水产养殖领域具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 对虾疾病是导致对虾水产养殖经济损失的主要原因之一。为预防疾病传播并提高对虾养殖中的智能检测效率，本研究旨在开发一种高效准确的疾病检测方法。

**Method:** 本研究提出了一种基于YOLOv8n的轻量级网络架构。具体方法包括：1. 设计RLDD检测头和C2f-EMCM模块以降低计算复杂度并提高计算效率。2. 引入改进的SegNext_Attention自注意力机制以增强特征提取能力。3. 在自建对虾疾病数据集上进行消融研究和比较评估，并在URPC2020数据集上进行泛化测试。

**Result:** 所提出的模型与原始YOLOv8n相比，参数量减少了32.3%，mAP@0.5达到92.7%（比YOLOv8n提高3%）。该模型在mAP@0.5、参数量和模型大小方面优于其他轻量级YOLO系列模型。在URPC2020数据集上的泛化实验显示，mAP@0.5比YOLOv8n提高了4.1%。

**Conclusion:** 本研究提出的方法在准确性和效率之间实现了最佳平衡，为对虾水产养殖中的智能疾病检测提供了可靠的技术支持。

> **ai_Abstract:** 本研究针对对虾疾病导致的经济损失，提出了一种基于YOLOv8n的轻量级对虾疾病检测网络。该网络通过设计RLDD检测头、C2f-EMCM模块和引入改进的SegNext_Attention机制，有效降低了模型参数量和计算复杂度，同时显著提升了检测精度和特征提取能力。实验结果表明，与原始YOLOv8n及其他轻量级YOLO系列模型相比，所提出的模型在精度、参数量和模型大小方面均表现出优越性，并在泛化能力上得到验证，为对虾养殖的智能疾病检测提供了高效可靠的解决方案。

> **摘要翻译:** 对虾疾病是对虾水产养殖经济损失的主要原因之一。为了预防疾病传播并提高对虾养殖中的智能检测效率，本文提出了一种基于YOLOv8n的轻量级网络架构。首先，通过设计RLDD检测头和C2f-EMCM模块，模型在保持检测精度的同时降低了计算复杂度，提高了计算效率。随后，引入了改进的SegNext_Attention自注意力机制，进一步增强了模型的特征提取能力，从而能够更精确地识别疾病特征。在自建对虾疾病数据集上进行了广泛的实验，包括消融研究和比较评估，并将泛化测试扩展到URPC2020数据集。结果表明，与原始YOLOv8n相比，所提出的模型参数量减少了32.3%，mAP@0.5达到92.7%（比YOLOv8n提高3%）。此外，该模型在mAP@0.5、参数量和模型大小方面优于其他轻量级YOLO系列模型。在URPC2020数据集上的泛化实验进一步验证了模型的鲁棒性，显示mAP@0.5比YOLOv8n提高了4.1%。所提出的方法在准确性和效率之间取得了最佳平衡，为对虾水产养殖中的智能疾病检测提供了可靠的技术支持。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [331] [Holistic Tokenizer for Autoregressive Image Generation](https://arxiv.org/abs/2507.02358)
> *自回归图像生成中的整体分词器*

*Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 图像生成, 自回归, 分词器, 整体性, 深度学习

**Comment:** 17 pages, 10 figures

> **TL;DR:** 现有自回归图像生成模型在捕获整体关系和全局信息方面存在局限。本文提出Hita，一种新颖的图像分词器，采用整体到局部的分词方案，显著提升了自回归生成器的训练速度和性能，并能有效捕获全局图像属性。

**AI_Comments:** Hita的创新点在于提出了整体到局部的分词方案，并结合了两种策略来优化自回归生成过程，有效解决了现有方法在全局信息捕获方面的不足。其在加速训练和提升性能方面的表现，以及在下游任务中的泛化能力，都显示了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 香草（vanilla）自回归图像生成模型以逐步方式生成视觉令牌，这限制了其捕获令牌序列之间整体关系的能力。此外，大多数视觉分词器将局部图像块映射为潜在令牌，导致全局信息有限。

**Method:** 本文引入了Hita，一种用于自回归（AR）图像生成的新型图像分词器。它引入了一种整体到局部的分词方案，结合了可学习的整体查询和局部补丁令牌。此外，Hita整合了两个关键策略以改进与AR生成过程的对齐：1）它安排了一种顺序结构，整体令牌在前，后跟补丁级令牌，同时使用因果注意力来保持对先前令牌的感知；2）在将去量化令牌馈入解码器之前，Hita采用了一个轻量级融合模块来控制信息流，优先处理整体令牌。

**Result:** 广泛的实验表明，Hita加速了AR生成器的训练速度，并优于使用香草分词器训练的模型，在ImageNet基准测试中达到了2.59 FID和281.9 IS。对整体表示的详细分析突出了其捕获全局图像属性（如纹理、材质和形状）的能力。此外，Hita还在零样本风格迁移和图像修复中展示了有效性。

**Conclusion:** Hita，一种新颖的整体图像分词器，通过捕获全局信息并提高性能，有效解决了香草自回归图像生成的局限性，同时在下游任务中也表现出有效性。

> **ai_Abstract:** Hita是一种新颖的图像分词器，专为解决现有自回归图像生成模型在捕获整体关系和全局信息方面的不足而设计。它采用整体到局部的分词方案，结合可学习的整体查询和局部补丁令牌，并通过优化令牌序列结构和信息流融合模块来增强与自回归生成过程的对齐。实验证明，Hita显著加速了自回归生成器的训练，并在ImageNet上取得了优异的性能（2.59 FID，281.9 IS），同时其整体表示能够有效捕获全局图像属性，并在零样本风格迁移和图像修复等任务中表现出色。

> **摘要翻译:** 香草自回归图像生成模型以逐步方式生成视觉令牌，这限制了其捕获令牌序列之间整体关系的能力。此外，大多数视觉分词器将局部图像块映射为潜在令牌，导致全局信息有限。为了解决这个问题，我们引入了Hita，一种用于自回归（AR）图像生成的新型图像分词器。它引入了一种整体到局部的分词方案，结合了可学习的整体查询和局部补丁令牌。此外，Hita整合了两个关键策略以改进与AR生成过程的对齐：1）它安排了一种顺序结构，整体令牌在前，后跟补丁级令牌，同时使用因果注意力来保持对先前令牌的感知；2）在将去量化令牌馈入解码器之前，Hita采用了一个轻量级融合模块来控制信息流，优先处理整体令牌。广泛的实验表明，Hita加速了AR生成器的训练速度，并优于使用香草分词器训练的模型，在ImageNet基准测试中达到了2.59 FID和281.9 IS。对整体表示的详细分析突出了其捕获全局图像属性（如纹理、材质和形状）的能力。此外，Hita还在零样本风格迁移和图像修复中展示了有效性。代码可在https://github.com/CVMI-Lab/Hita获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [333] [LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling](https://arxiv.org/abs/2507.02363)
> *LocalDyGS：通过自适应局部隐式特征解耦实现多视角全局动态场景建模*

*Jiahao Wu, Rui Peng, Jianbo Jiao, Jiayu Yang, Luyang Tang, Kaiqiang Xiong, Jie Liang, Jinbo Yan, Runling Liu, Ronggang Wang* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 动态场景建模, 多视角, 局部隐式特征, 特征解耦, 时间高斯

**Comment:** Accepted by ICCV 2025

> **TL;DR:** LocalDyGS提出了一种新的动态场景建模方法，通过将复杂动态场景分解为局部空间并解耦静态和动态特征，有效处理大规模和精细尺度运动，首次尝试建模更大更复杂的动态场景。

**AI_Comments:** LocalDyGS的创新之处在于其对复杂动态场景的分解策略和静态与动态特征的解耦机制。通过将场景分解为局部空间并分别处理静态和动态信息，该方法有效克服了现有技术在处理大规模和复杂动态场景方面的局限性。其能够建模更大、更复杂的高度动态场景是其显著的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 由于现实世界中复杂和高度动态的运动，从多视角输入合成任意视点的动态视频具有挑战性。现有基于神经辐射场或3D高斯泼溅的方法仅限于建模精细尺度运动，极大地限制了其应用。

**Method:** LocalDyGS由两部分组成，以适应大规模和精细尺度运动场景：1) 将复杂动态场景分解为由种子定义的流线型局部空间，通过捕获每个局部空间内的运动来实现全局建模。2) 解耦局部空间运动建模的静态和动态特征。一个跨时间步共享的静态特征捕获静态信息，而一个动态残差场提供时间特定特征。这些特征被组合并解码以生成时间高斯，建模每个局部空间内的运动。

**Result:** 该方法不仅在各种精细尺度数据集上与最先进（SOTA）方法相比表现出有竞争力的性能，而且代表了首次尝试建模更大、更复杂的高度动态场景。

**Conclusion:** LocalDyGS提出了一种新颖的动态场景重建框架，通过自适应局部隐式特征解耦来更真实地建模高度动态的现实世界场景，并有效处理大规模和精细尺度运动。

> **ai_Abstract:** LocalDyGS提出了一种用于多视角全局动态场景建模的新框架，通过将复杂动态场景分解为局部空间并解耦静态和动态特征（静态特征共享，动态残差场提供时间特定特征），从而生成时间高斯。这种方法能够有效处理大规模和精细尺度的运动，并在现有数据集上表现出色，同时首次尝试建模更大、更复杂的动态场景。

> **摘要翻译:** 由于现实世界中复杂和高度动态的运动，从多视角输入合成任意视点的动态视频具有挑战性。以前基于神经辐射场或3D高斯泼溅的工作仅限于建模精细尺度运动，极大地限制了它们的应用。在本文中，我们引入了LocalDyGS，它由两部分组成，以使我们的方法适应大规模和精细尺度运动场景：1）我们将复杂的动态场景分解为由种子定义的流线型局部空间，通过捕获每个局部空间内的运动来实现全局建模。2）我们解耦了局部空间运动建模的静态和动态特征。一个跨时间步共享的静态特征捕获静态信息，而一个动态残差场提供时间特定特征。这些特征被组合并解码以生成时间高斯，建模每个局部空间内的运动。因此，我们提出了一种新颖的动态场景重建框架，以更真实地建模高度动态的现实世界场景。我们的方法不仅在各种精细尺度数据集上与最先进（SOTA）方法相比表现出有竞争力的性能，而且代表了首次尝试建模更大、更复杂的高度动态场景。项目页面：https://wujh2001.github.io/LocalDyGS/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [336] [UVLM: Benchmarking Video Language Model for Underwater World Understanding](https://arxiv.org/abs/2507.02373)
> *UVLM：基准测试视频语言模型以理解水下世界*

*Xizhe Xue, Yang Zhou, Dawei Yan, Ying Li, Haokui Zhang, Rong Xiao* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 视频语言模型, 水下理解, 基准测试, UVLM, 海洋观察

**Comment:** 13 pages, 4 figures, 3 tables

> **TL;DR:** UVLM引入了一个新的水下视频语言模型基准数据集，以解决现有模型主要关注陆地场景的不足，并显著提高了水下理解能力。

**AI_Comments:** UVLM的创新之处在于它是首个专门针对水下视频理解设计的视频语言模型基准，填补了现有研究的空白。其重要性在于为水下AI应用提供了一个急需的评估和开发平台，有助于推动水下机器人、海洋生物研究等领域的发展。通过结合人类专业知识和AI模型构建数据集，并考虑了水下环境的独特挑战和多样性，确保了基准的实用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频语言模型（VidLMs）主要关注陆地场景，忽视了水下观察领域对高要求应用的需求，因此需要一个专门的水下基准来填补这一空白。

**Method:** 引入了UVLM，一个通过结合人类专业知识和AI模型构建的水下观察基准。该基准通过多方面考虑确保数据质量，包括选择代表典型水下挑战（如光线变化、水浊度、不同视角）的视频，确保数据多样性（涵盖广泛的帧率、分辨率、419类海洋动物以及各种静态植物和地形），以及任务多样性（将观察目标分为生物和环境两大类，每类包含内容观察和变化/动作观察，共20种不同的任务类型）。此外，还设计了具有挑战性的评估指标。

**Result:** 在两个代表性视频语言模型上进行的实验表明，在UVLM上对VidLMs进行微调显著提高了它们对水下世界的理解能力，同时还显示出对现有空中VidLM基准（如VideoMME和Perception text）的轻微改进潜力。

**Conclusion:** UVLM基准的引入和使用能够显著提升视频语言模型在水下世界的理解能力，填补了现有模型在水下应用方面的空白。该数据集和提示工程将公开发布，有助于未来的研究。

> **ai_Abstract:** 本研究提出了UVLM，一个专为水下世界理解设计的视频语言模型基准。鉴于现有视频语言模型主要侧重于陆地环境，UVLM旨在通过结合人类专业知识和AI模型，构建高质量、多样化的水下数据集，涵盖光线变化、水浊度等挑战，并包含多种海洋生物和环境元素。数据集设计了20种不同的任务类型，并引入了新的评估指标。实验证明，在UVLM上进行微调能显著提升模型的水下理解能力，并对陆地基准也有潜在的积极影响。该数据集将公开发布。

> **摘要翻译:** 最近，大型语言模型（LLMs）的显著成功对人工智能领域产生了深远影响。许多基于LLMs的先进工作已被提出并应用于各种场景。其中，视频语言模型（VidLMs）尤其被广泛使用。然而，现有工作主要关注陆地场景，忽视了水下观察对高要求的应用需求。为了克服这一差距，我们引入了UVLM，一个通过结合人类专业知识和AI模型构建的水下观察基准。为了确保数据质量，我们从多个角度进行了深入考虑。首先，为了应对水下环境的独特挑战，我们选择了代表典型水下挑战的视频，包括光线变化、水浊度以及多样化的视角来构建数据集。其次，为了确保数据多样性，数据集涵盖了广泛的帧率、分辨率、419类海洋动物以及各种静态植物和地形。接下来，为了任务多样性，我们采用了结构化设计，将观察目标分为两大类：生物和环境。每个类别都包括内容观察和变化/动作观察，总计20种不同的任务类型。最后，我们设计了几种具有挑战性的评估指标，以实现对不同方法的定量比较和分析。在两个代表性视频语言模型上进行的实验表明，在UVLM上对VidLMs进行微调显著提高了水下世界的理解能力，同时还显示出对现有空中VidLM基准（如VideoMME和Perception text）的轻微改进潜力。数据集和提示工程将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [339] [PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection](https://arxiv.org/abs/2507.02393)
> *PLOT：通过视频目标跟踪进行伪标签以实现可扩展的单目3D目标检测*

*Seokyeong Lee, Sithu Aung, Junyong Choi, Seungryong Kim, Ig-Jae Kim, Junghyun Cho* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 单目3D目标检测, 伪标签, 视频目标跟踪, 数据稀缺, 可扩展性

**Comment:** 18 pages, 16 figures

> **TL;DR:** 提出了一种新颖的伪标签框架PLOT，利用视频数据和目标点跟踪来生成伪LiDAR，解决了单目3D目标检测中的数据稀缺和2D-到-3D模糊性问题，无需多视角、额外传感器或领域特定训练，实现了高准确性和可扩展性。

**AI_Comments:** 该论文的创新点在于提出了一个无需昂贵3D标注、多视角或额外传感器的单目3D目标检测伪标签框架。通过利用视频数据中的时间信息和目标点跟踪来聚合伪LiDAR，有效解决了数据稀缺和2D-到-3D模糊性问题。其鲁棒性和可扩展性使其在实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 单目3D目标检测（M3OD）长期面临数据稀缺的挑战，这源于高昂的标注成本和固有的2D-到-3D模糊性。现有弱监督和伪标签方法大多受限于领域特定学习或仅依赖单次观测的形状信息。

**Method:** 我们提出了一种新颖的伪标签框架，仅使用视频数据，且对遮挡更鲁棒，无需多视角设置、额外传感器、相机姿态或领域特定训练。具体来说，我们探索了一种通过目标点跟踪，聚合跨时间相邻帧的静态和动态物体的伪LiDAR的技术，从而在3D数据采集不可行的情况下也能提取3D属性。

**Result:** 广泛的实验表明，我们的方法确保了可靠的准确性和强大的可扩展性。

**Conclusion:** 该方法为单目3D目标检测（M3OD）提供了一个实用且有效的解决方案，解决了数据稀缺和2D-到-3D模糊性问题，并展现出高准确性和可扩展性。

> **ai_Abstract:** 本文提出了一种名为PLOT的新型伪标签框架，旨在解决单目3D目标检测（M3OD）中因数据稀缺和2D-到-3D模糊性带来的挑战。该框架利用视频数据和目标点跟踪技术，聚合跨帧的伪LiDAR信息，从而实现静态和动态物体的3D属性提取，即使在3D数据难以获取的场景下也适用。PLOT无需多视角、额外传感器、相机姿态或领域特定训练，且对遮挡具有更强的鲁棒性。实验证明，该方法具有可靠的准确性和强大的可扩展性，为M3OD提供了一个实用且有效的解决方案。

> **摘要翻译:** 单目3D目标检测（M3OD）长期以来一直面临挑战，原因在于高昂的标注成本导致的数据稀缺以及固有的2D-到-3D模糊性。尽管已经提出了各种弱监督方法和伪标签方法来解决这些问题，但它们大多受限于领域特定学习或仅依赖于单次观测的形状信息。在本文中，我们提出了一种新颖的伪标签框架，该框架仅使用视频数据，并且对遮挡更具鲁棒性，无需多视角设置、额外传感器、相机姿态或领域特定训练。具体来说，我们探索了一种通过目标点跟踪，聚合跨时间相邻帧的静态和动态物体的伪LiDAR的技术，从而在3D数据采集不可行的情况下也能提取3D属性。广泛的实验表明，我们的方法确保了可靠的准确性和强大的可扩展性，使其成为M3OD的一个实用且有效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis](https://arxiv.org/abs/2507.02395)
> *用于组织病理学全玻片图像分析的持续多示例学习与增强定位*

*Byung Hyun Lee, Wongi Jeong, Woojae Han, Kyoungbun Lee, Se Young Chun* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 持续学习, 多示例学习, 组织病理学图像, 全玻片图像, 定位

**Comment:** Accepted at ICCV 2025

> **TL;DR:** CoMEL是一种针对组织病理学全玻片图像分析的持续多示例学习框架，它通过解决现有MIL方法在持续任务中遗忘和定位的不足，实现了卓越的袋级和定位准确性。

**AI_Comments:** CoMEL在持续学习背景下对多示例学习进行了创新性探索，特别关注了组织病理学图像分析中的定位难题。其提出的GDAT、BPPL和OWLoRA组件协同工作，有效解决了大规模图像数据处理中的效率、标签可靠性及遗忘问题，为WSI分析提供了一个强大的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 多示例学习（MIL）通过袋级弱标签显著降低了大规模图像（如组织病理学全玻片图像WSIs）的标注成本。然而，其在持续任务中适应性差且遗忘问题未被充分探索，尤其是在实例分类定位方面。现有针对语义分割的弱增量学习方法不适用于MIL定位，因为WSI包含大量大尺寸图像块且缺乏全局关系。

**Method:** 本文提出了持续多示例学习与增强定位（CoMEL）框架，旨在实现定位和在持续任务中最小化遗忘。CoMEL包含三个核心组件：1) 分组双注意力Transformer (GDAT) 用于高效实例编码；2) 基于袋原型伪标签 (BPPL) 用于可靠的实例伪标签；3) 正交加权低秩适应 (OWLoRA) 用于减轻袋级和实例分类中的遗忘。

**Result:** 在三个公共WSI数据集上的大量实验表明，CoMEL在持续MIL设置下表现出卓越的性能，袋级准确率比现有技术高出11.00%，定位准确率高出23.4%。

**Conclusion:** CoMEL框架成功解决了持续多示例学习在组织病理学全玻片图像分析中面临的挑战，特别是在减少遗忘和提高定位精度方面表现出色，为未来的研究提供了新的方向。

> **ai_Abstract:** 本文提出了一种名为CoMEL的持续多示例学习框架，旨在解决组织病理学全玻片图像（WSI）分析中，现有MIL方法在持续任务中存在的遗忘问题和实例定位挑战。CoMEL通过引入分组双注意力Transformer (GDAT) 进行高效实例编码、基于袋原型伪标签 (BPPL) 进行可靠伪标签，以及正交加权低秩适应 (OWLoRA) 来减轻遗忘。实验结果表明，CoMEL在袋级和定位准确性方面均显著优于现有技术。

> **摘要翻译:** 多示例学习（MIL）通过袋级弱标签显著降低了大规模图像（如组织病理学全玻片图像WSIs）的标注成本。然而，其在持续任务中适应性差且遗忘问题很少被探索，尤其是在实例分类定位方面。弱增量学习语义分割已被研究用于持续定位，但它侧重于自然图像，利用数百个小块（例如16×16）之间的全局关系并使用预训练模型。这种方法对于MIL定位似乎不可行，因为存在大量（约10^5）大尺寸图像块（例如256×256）且没有可用的全局关系，例如癌细胞。为了解决这些挑战，我们提出了持续多示例学习与增强定位（CoMEL），这是一个用于定位和适应性且遗忘最小的MIL框架。CoMEL由以下部分组成：(1) 分组双注意力Transformer（GDAT）用于高效实例编码，(2) 基于袋原型伪标签（BPPL）用于可靠的实例伪标签，以及 (3) 正交加权低秩适应（OWLoRA）以减轻袋级和实例分类中的遗忘。在三个公共WSI数据集上进行的广泛实验表明，CoMEL表现出卓越的性能，在持续MIL设置下，其袋级准确率比现有技术高出11.00%，定位准确率高出23.4%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [345] [Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection](https://arxiv.org/abs/2507.02398)
> *超越空间频率：基于像素级时间频率的深度伪造视频检测*

*Taehoon Kim, Jongwook Choi, Yonghyun Jeong, Haeun Noh, Jaejun Yoo, Seungryul Baek, Jongwon Choi* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 深度伪造检测, 时间频率, 像素级分析, 傅里叶变换, 注意力机制

**Comment:** accepted by iccv 2025. code is will be available at
  https://github.com/rama0126/PwTF-DVD

> **TL;DR:** 提出了一种利用像素级时间频率分析来检测深度伪造视频的方法，该方法能捕捉传统空间频率方法忽视的时间不一致性。

**AI_Comments:** 该论文的创新之处在于超越了传统的空间频率分析，转而关注像素级时间频率，这解决了传统深度伪造检测的一个关键盲点。对每个像素应用一维傅里叶变换并结合注意力机制和Transformer模块是其新颖之处。这项工作的重要性在于提高了深度伪造检测的鲁棒性和可检测伪造伪影的范围。

<details>
  <summary>Details</summary>

**Motivation:** 传统深度伪造检测器主要依赖空间频率，未能有效检测像素平面中的时间伪影，从而错过了时间不一致性。

**Method:** 该方法对每个像素的时间轴进行一维傅里叶变换，提取对时间不一致性高度敏感的特征。引入了一个端到端训练的注意力提议模块来精确定位时间伪影区域。此外，联合Transformer模块有效地整合了像素级时间频率特征与时空上下文特征。

**Result:** 在各种复杂检测场景下，该框架表现出强大的性能，代表了深度伪造视频检测的重大进步。

**Conclusion:** 该框架通过利用像素级时间频率并将其与时空上下文特征相结合，显著提升了深度伪造视频的检测能力，并在具有挑战性的场景中提供了强大的性能。

> **ai_Abstract:** 本文提出了一种新颖的深度伪造视频检测方法，该方法专注于传统空间频率检测器容易忽略的像素级时间不一致性。它通过对每个像素的时间轴进行一维傅里叶变换来提取敏感的时间频率特征。该方法还包含一个用于伪影定位的注意力提议模块和一个用于整合像素级时间频率与时空上下文特征的联合Transformer模块，从而在各种场景下实现了鲁棒的检测性能。

> **摘要翻译:** 我们引入了一种利用像素级时间不一致性的深度伪造视频检测方法，而传统基于空间频率的检测器往往会忽略这些不一致性。传统检测器仅通过堆叠跨帧的空间频率谱来表示时间信息，导致未能检测到像素平面中的时间伪影。我们的方法对每个像素的时间轴进行一维傅里叶变换，提取对时间不一致性高度敏感的特征，尤其是在容易出现不自然运动的区域。为了精确定位包含时间伪影的区域，我们引入了一个以端到端方式训练的注意力提议模块。此外，我们的联合Transformer模块有效地将像素级时间频率特征与时空上下文特征相结合，扩大了可检测伪造伪影的范围。我们的框架代表了深度伪造视频检测的重大进步，在各种复杂和具有挑战性的检测场景中提供了强大的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [347] [TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation](https://arxiv.org/abs/2507.02399)
> *TABNet：一种用于医学图像分割的边界感知伪标签三元组增强自恢复框架*

*Peilin Zhang, Shaouxan Wua, Jun Feng, Zhuo Jin, Zhizezhang Gao, Jingkun Chen, Yaqiong Xing, Xiao Zhang* | **Category: cs.CV, cs.LG** | **Updated: {updated}**

**Keywords:** 医学图像分割, 弱监督学习, 涂鸦标注, 数据增强, 伪标签

**Comment:** 

> **TL;DR:** TABNet是一个弱监督医学图像分割框架，利用三元组增强自恢复和边界感知伪标签克服了稀疏标注的挑战，性能超越SOTA并媲美全监督方法。

**AI_Comments:** TABNet的创新之处在于其结合了三元组增强策略和边界感知的伪标签监督，有效地弥补了稀疏涂鸦标注在特征学习和边界精细化方面的不足。其能够在弱监督条件下达到与全监督方法相当的性能，这对于降低医学图像标注成本、加速临床应用具有重要意义。该框架的模块化设计也为其在其他稀疏标注任务中的应用提供了潜力。

<details>
  <summary>Details</summary>

**Motivation:** 医疗图像分割是核心任务，但获取大规模全标注数据集耗时且昂贵。涂鸦标注虽然高效，但其稀疏性限制了目标区域的特征学习并缺乏足够的边界监督，给训练分割网络带来了挑战。

**Method:** 提出了TABNet，一个新颖的弱监督医学图像分割框架，包含两个关键组件：三元组增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过强度变换、裁剪和拼图增强三种互补的增强策略来增强特征学习，并引导网络从多样化的增强输入中恢复完整掩膜。BAP模块通过融合双分支预测为损失加权伪标签并引入边界感知损失来提高伪监督精度和边界建模。

**Result:** 在ACDC和MSCMR seg两个公共数据集上的实验评估表明，TABNet在基于涂鸦的弱监督分割方面显著优于现有最先进方法。此外，其性能可与全监督方法相媲美。

**Conclusion:** TABNet通过其创新的三元组增强自恢复和边界感知伪标签监督模块，有效地解决了稀疏涂鸦标注在医学图像分割中的挑战，实现了与全监督方法相当的卓越性能。

> **ai_Abstract:** 本文提出了TABNet，一个用于弱监督医学图像分割的框架，旨在解决稀疏涂鸦标注带来的挑战。TABNet包含三元组增强自恢复（TAS）模块，通过多种数据增强促进深层语义理解；以及边界感知伪标签监督（BAP）模块，通过伪标签和边界损失细化轮廓。实验证明，TABNet在涂鸦标注下显著优于现有方法，并达到与全监督方法相当的性能。

> **摘要翻译:** 背景与目标：医学图像分割是各种临床应用中的核心任务。然而，获取大规模、完全标注的医学图像数据集既耗时又昂贵。涂鸦标注作为一种稀疏标注形式，为医学图像分割提供了一种高效且经济的替代方案。然而，涂鸦标注的稀疏性限制了目标区域的特征学习，并且缺乏足够的边界监督，这给训练分割网络带来了重大挑战。方法：我们提出了TAB Net，一种新颖的弱监督医学图像分割框架，由两个关键组件组成：三元组增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补的增强策略增强特征学习：强度变换提高了模型对纹理和对比度变化的敏感性；裁剪通过遮蔽关键区域迫使网络捕获局部解剖结构；拼图增强通过打乱空间连续性来加强全局解剖布局的建模。通过引导网络从多样化的增强输入中恢复完整的掩膜，TAS促进了稀疏监督下医学图像的更深层次语义理解。BAP模块通过将双分支预测融合为损失加权伪标签并引入边界感知损失以进行精细轮廓细化，从而提高伪监督精度和边界建模。结果：在ACDC和MSCMR seg两个公共数据集上的实验评估表明，TAB Net在基于涂鸦的弱监督分割方面显著优于现有最先进方法。此外，其性能可与全监督方法相媲美。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings](https://arxiv.org/abs/2507.02403)
> *野生动物目标重识别在非城市环境中使用自监督学习*

*Mufhumudzi Muthivhi, Terence L. van Zyl* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 野生动物重识别, 自监督学习, 相机陷阱, 无监督学习, 鲁棒性

**Comment:** Accepted for publication in IEEE Xplore and ISIF FUSION 2025
  proceedings:

> **TL;DR:** 该研究提出了一种基于自监督学习的野生动物重识别方法，无需标注数据，并在有限数据下表现出比监督学习更强的鲁棒性和性能。

**AI_Comments:** 这篇论文的创新点在于将自监督学习应用于野生动物重识别领域，有效地解决了该领域对大量标注数据的高度依赖问题。其重要性体现在为野生动物监测和研究提供了一种更实用、更具扩展性的方法，尤其是在数据获取和标注成本高昂的非城市环境中。该研究证明了自监督学习在有限数据下的鲁棒性和优越性能，具有重要的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的野生动物重识别模型依赖于标注数据进行监督学习，需要大量人工标注的数据集，这限制了其应用和扩展。

**Method:** 本研究利用相机陷阱数据中的时间图像对，在没有监督的情况下自动提取同一野生动物的两个不同视图。这些图像对用于训练一个自监督模型，并利用潜在的无限视频数据流。该方法在开放世界场景和各种野生动物下游任务中，将学习到的表示与监督特征进行评估。

**Result:** 实验结果表明，自监督模型即使在数据有限的情况下也更具鲁棒性。此外，自监督特征在所有下游任务中均优于监督学习。

**Conclusion:** 自监督学习在野生动物重识别任务中表现出色，尤其是在数据有限的非城市环境中，其性能和鲁棒性均超越了传统的监督学习方法，为野生动物监测提供了无需大量标注数据的新途径。

> **ai_Abstract:** 本文探讨了在非城市环境中利用自监督学习（SSL）进行野生动物重识别的方法，以解决传统监督学习对大量标注数据的依赖问题。研究人员通过相机陷阱数据自动生成个体的不同视图对来训练自监督模型。实验结果表明，与监督学习相比，该自监督模型在数据有限的情况下表现出更高的鲁棒性，并在各种下游任务中取得了更优异的性能。这表明自监督学习为野生动物研究提供了一种高效且无需大量标注数据的新范式。

> **摘要翻译:** 野生动物重识别旨在匹配不同观测中同一物种的个体。当前最先进（SOTA）的模型依赖于类别标签来训练监督模型进行个体分类。这种对标注数据的依赖推动了大量大型野生动物数据集的整理。本研究调查了自监督学习（SSL）在野生动物重识别中的应用。我们利用相机陷阱数据中的时间图像对，在没有监督的情况下自动提取个体的两个不同视图。这些图像对从潜在的无限视频数据流中训练一个自监督模型。我们在开放世界场景和各种野生动物下游任务中，将学习到的表示与监督特征进行评估。实验结果分析表明，自监督模型即使在数据有限的情况下也更具鲁棒性。此外，自监督特征在所有下游任务中均优于监督学习。代码可在此处获取：https://github.com/pxpana/SSLWildlife。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [352] [PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration](https://arxiv.org/abs/2507.02405)
> *PosDiffAE：用于高分辨率脑组织分类并结合伪影恢复的位置感知扩散自编码器*

*Ayantika Das, Moitreya Chaudhuri, Koushik Bhat, Keerthi Ram, Mihail Bota, Mohanasankar Sivaprakasam* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 扩散自编码器, 脑组织分类, 伪影恢复, 位置感知, 高分辨率图像

**Comment:** Published in IEEE Journal of Biomedical and Health Informatics (Early
  Access Available) https://ieeexplore.ieee.org/document/10989734

> **TL;DR:** 本文提出了PosDiffAE，一种结合了位置感知和伪影恢复功能的扩散自编码器，用于高分辨率脑组织分类。

**AI_Comments:** 这项工作创新性地结合了扩散模型的生成能力和自编码器的表示学习能力，特别是在高分辨率脑图像分析中，通过引入位置感知机制来提高组织分类的准确性，并同时解决了常见的图像伪影问题，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 去噪扩散模型在生成高保真图像方面表现出色，但其采样机制无法提取图像特定的语义表示，而这正是自编码器所能提供的。为了结合两者的优点，实现图像特定语义表示学习和潜在空间组织，并解决高分辨率脑图像分类中的挑战及常见的图像伪影问题，本文提出了新的方法。

**Method:** 本文将编码器与扩散模型集成，建立了自编码公式以学习图像特定表示并组织潜在空间。具体而言，首先，设计了一种机制来构建扩散自编码模型的潜在空间，通过强制表示回归高分辨率图像块的位置信息，以识别脑图像中区域特异性的细胞模式，从而促进脑组织类型的区分。其次，基于邻域感知，利用潜在表示和扩散模型在推理时的受限生成能力，开发了一种无监督的撕裂伪影恢复技术。第三，通过表示引导并利用扩散模型在推理时可控的加噪和去噪能力，设计了一种无监督的JPEG伪影恢复技术。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了PosDiffAE，一个结合了扩散模型和自编码器优点的框架，旨在解决高分辨率脑组织分类中的语义表示缺失和图像伪影问题。该模型通过强制潜在空间学习图像块的位置信息来区分脑组织类型，并开发了基于邻域感知和可控去噪的无监督撕裂伪影和JPEG伪影恢复技术。

> **摘要翻译:** 去噪扩散模型通过以渐进方式捕获图像分布来生成高保真图像样本，同时以简单分布初始化并复合分布复杂性。尽管这些模型开启了新的应用可能性，但扩散的采样机制不提供提取图像特定语义表示的方法，而这正是自编码器固有提供的。自编码器的编码组件能够实现特定图像与其潜在空间之间的映射，从而提供了在潜在空间中强制执行结构的明确手段。通过将编码器与扩散模型集成，我们建立了一个自编码公式，该公式学习图像特定表示并提供了组织潜在空间的方法。在这项工作中，首先，我们设计了一种机制来构建扩散自编码模型的潜在空间，以识别脑图像中区域特异性的细胞模式。我们强制表示回归高分辨率图像中图像块的位置信息。这为区分脑组织类型创造了一个有利的潜在空间。其次，我们设计了一种基于邻域感知的无监督撕裂伪影恢复技术，利用潜在表示和扩散模型在推理过程中的受限生成能力。第三，通过表示引导并利用扩散模型在推理时可控的加噪和去噪能力，我们设计了一种无监督的JPEG伪影恢复技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [354] [A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern](https://arxiv.org/abs/2507.02408)
> *一种利用热传感器处理复杂运动模式的实时多目标跟踪新型调优方法*

*Duong Nguyen-Ngoc Tran, Long Hoang Pham, Chi Dai Tran, Quoc Pham-Nam Ho, Huy-Hung Nguyen, Jae Wook Jeon* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 多目标跟踪, 热传感器, 调优方法, 实时, 超参数

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的两阶段调优方法，用于热成像中的实时多目标跟踪，解决了低级特征表示和复杂运动模式的挑战，并在不依赖复杂重识别或运动模型的情况下实现了高精度，在PBVS热成像MOT数据集上表现出强大的鲁棒性。

**AI_Comments:** 该论文的创新点在于其提出的两阶段超参数调优方法，专门用于热成像多目标跟踪，并成功避免了对复杂重识别或运动模型的依赖。其重要性在于为恶劣环境下的监控系统提供了鲁棒且高效的解决方案，扩展了热成像在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** RGB摄像头在低能见度或光照不足的恶劣环境中表现不佳。热传感器虽然能捕获红外特征，但其低级特征表示使得准确检测和跟踪行人变得困难。本文旨在解决热成像多目标跟踪中这一挑战，特别是处理复杂运动模式。

**Method:** 本文引入了一种新颖的两阶段调优方法，用于行人跟踪，专门设计用于处理热成像中复杂的运动模式。该框架优化了两个阶段，确保每个阶段都使用最合适的超参数进行调整，以最大限度地提高跟踪性能，且不依赖复杂的重识别或运动模型。

**Result:** 该方法实现了高精度。在PBVS热成像MOT数据集上进行的广泛实验表明，该方法在各种热像仪条件下都非常有效。

**Conclusion:** 所提出的方法在各种热像仪条件下都非常有效，使其成为真实世界监控应用的稳健解决方案。

> **ai_Abstract:** 本文针对热成像多目标跟踪中的低级特征表示和复杂运动模式挑战，提出了一种新颖的两阶段调优方法。该方法通过优化每个阶段的超参数，在不依赖复杂重识别或运动模型的情况下，实现了高精度实时跟踪。在PBVS热成像MOT数据集上的广泛实验验证了其在各种热像仪条件下的高效性，使其成为真实世界监控应用的稳健解决方案。

> **摘要翻译:** 热成像多目标跟踪对于监控系统至关重要，尤其是在RGB摄像头因能见度低或光照条件差而难以工作的挑战性环境中。热传感器通过捕获红外特征来增强识别任务，但一个主要挑战是其低级特征表示，这使得准确检测和跟踪行人变得困难。为解决此问题，本文引入了一种新颖的行人跟踪调优方法，专门设计用于处理热成像中复杂的运动模式。所提出的框架优化了两个阶段，确保每个阶段都使用最合适的超参数进行调整，以最大限度地提高跟踪性能。通过对实时跟踪的超参数进行微调，该方法在不依赖复杂重识别或运动模型的情况下实现了高精度。在PBVS热成像MOT数据集上进行的广泛实验表明，该方法在各种热像仪条件下都非常有效，使其成为真实世界监控应用的稳健解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [360] [AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars](https://arxiv.org/abs/2507.02419)
> *AvatarMakeup：三维可动画头部头像的真实感美妆迁移*

*Yiming Zhong, Xiaolin Zhang, Ligang Liu, Yao Zhao, Yunchao Wei* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** AvatarMakeup, 3D美妆迁移, 扩散模型, 可动画头像, Coherent Duplication

**Comment:** 

> **TL;DR:** AvatarMakeup提出一种新颖方法，利用扩散模型为3D可动画头像实现真实感美妆迁移，解决了现有方法在一致性、身份保留和细节控制上的不足。

**AI_Comments:** 该论文的创新点在于其针对3D可动画头像美妆的特定挑战，特别是解决了在动态表情下保持美妆一致性和身份保留的难题。通过结合扩散模型的生成能力与独特的Coherent Duplication方法，以及后续的Refinement Module，提供了一个全面且高效的解决方案。该方法在实际应用中，例如虚拟社交、游戏或元宇宙领域，具有重要的潜在价值，能够显著提升虚拟形象的真实感和个性化体验。

<details>
  <summary>Details</summary>

**Motivation:** 与现实生活中的面部美化类似，3D虚拟头像需要个性化定制以增强其视觉吸引力，但该领域探索不足。尽管当前的3D高斯编辑方法可用于面部美妆，但它们未能满足实现真实美妆效果的基本要求：1) 在驱动表情时确保外观一致性；2) 在美妆过程中保留身份；3) 能够精确控制精细细节。

**Method:** 本文提出了一种名为AvatarMakeup的专用3D美妆方法，利用预训练的扩散模型从任何个体的单张参考照片中迁移美妆图案。该方法采用粗到细的理念，首先保持外观和身份的一致性，然后细化细节。具体而言，扩散模型用于生成美妆图像作为监督。由于扩散过程中的不确定性，生成的图像在不同视角和表情下不一致。因此，提出了一种Coherent Duplication方法，通过记录生成美妆图像中平均面部属性的全局UV图，粗略地将美妆应用于目标，同时确保动态和多视角效果的一致性。通过查询全局UV图，它可以轻松地从任意视角和表情合成一致的美妆指导，以优化目标头像。对于粗略美妆的头像，通过在扩散模型中整合Refinement Module来进一步增强美妆，以实现高质量的美妆效果。

**Result:** 实验表明，AvatarMakeup在动画过程中实现了最先进的美妆迁移质量和一致性。

**Conclusion:** AvatarMakeup成功解决了3D可动画头像美妆中的一致性、身份保留和细节控制问题，实现了高质量和一致性的美妆迁移效果，达到了最先进的水平。

> **ai_Abstract:** 本文提出AvatarMakeup，一种专为3D可动画头部头像设计的真实感美妆迁移方法。针对现有方法在驱动表情时外观不一致、身份难以保留及细节控制不足的问题，AvatarMakeup利用预训练扩散模型，并采用粗到细的策略。其核心创新在于Coherent Duplication方法，通过优化全局UV图，确保美妆在动态和多视角下的一致性，并结合Refinement Module进一步提升美妆质量。实验证明该方法在美妆迁移质量和动画一致性方面达到了最先进水平。

> **摘要翻译:** 与现实生活中的面部美化类似，3D虚拟头像需要个性化定制以增强其视觉吸引力，但该领域探索不足。尽管当前的3D高斯编辑方法可用于面部美妆，但这些方法未能满足实现真实美妆效果的基本要求：1) 在驱动表情时确保外观一致性，2) 在美妆过程中保留身份，以及3) 能够精确控制精细细节。为了解决这些问题，我们提出了一种名为AvatarMakeup的专用3D美妆方法，利用预训练的扩散模型从任何个体的单张参考照片中迁移美妆图案。我们采用粗到细的理念，首先保持外观和身份的一致性，然后细化细节。具体而言，扩散模型用于生成美妆图像作为监督。由于扩散过程中的不确定性，生成的图像在不同视角和表情下不一致。因此，我们提出了一种Coherent Duplication方法，通过记录生成美妆图像中平均面部属性的全局UV图，粗略地将美妆应用于目标，同时确保动态和多视角效果的一致性。通过查询全局UV图，它可以轻松地从任意视角和表情合成一致的美妆指导，以优化目标头像。对于粗略美妆的头像，我们通过在扩散模型中整合Refinement Module来进一步增强美妆，以实现高质量的美妆效果。实验表明，AvatarMakeup在动画过程中实现了最先进的美妆迁移质量和一致性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [366] [Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection](https://arxiv.org/abs/2507.02454)
> *结合数量提示的弱监督对比学习用于运动红外小目标检测*

*Weiwei Duan, Luping Ji, Shengjia Chen, Sicheng Zhu, Jianghong Huang, Mao Ye* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 弱监督, 对比学习, 红外小目标检测, 数量提示, 运动感知学习

**Comment:** 

> **TL;DR:** 本文提出了一种新的弱监督对比学习（WeCoL）方案，用于运动红外小目标检测，仅需简单的目标数量提示，并在性能上接近甚至超越了部分全监督方法。

**AI_Comments:** 本文首次探索了将弱监督对比学习应用于运动红外小目标检测，创新性地提出了仅需目标数量提示的WeCoL方案，显著降低了对昂贵手动标注的依赖。其结合SAM进行潜在目标挖掘和利用对比学习优化伪标签的策略具有启发性。在性能上，该弱监督方法能够接近甚至超越部分全监督方法，展现了其在实际应用中的巨大潜力，尤其是在标注资源有限的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 运动红外小目标检测面临目标尺寸微小和背景对比度弱的巨大挑战。现有方法大多是全监督的，高度依赖大量耗时且昂贵的手动逐目标标注，尤其对于低质量红外帧图像更是如此。为了减少标注需求，作者探索了非全监督策略，特别是弱监督方法。

**Method:** 本文提出了一个名为WeCoL的弱监督对比学习方案，仅在模型训练期间需要简单的目标数量提示。具体来说，该方案基于预训练的SAM模型，设计了一个潜在目标挖掘策略，整合了目标激活图和多帧能量累积。此外，采用对比学习通过计算特征子空间中正负样本的相似性来提高伪标签的可靠性。同时，还提出了一个长短期运动感知学习方案，以同时建模小目标的局部运动模式和全局运动轨迹。

**Result:** 在DAUB和ITSDT-15K两个公共数据集上的大量实验验证了所提出的弱监督方案通常优于早期的全监督方法。甚至，其性能可以达到最先进（SOTA）全监督方法的90%以上。

**Conclusion:** 本文提出的弱监督对比学习方案WeCoL在运动红外小目标检测中表现出色，仅需简单的数量提示即可实现接近甚至超越全监督方法的性能，有效解决了手动标注成本高昂的问题。

> **ai_Abstract:** 本文提出了一种名为WeCoL的弱监督对比学习方案，用于解决运动红外小目标检测中全监督方法对大量手动标注的依赖问题。该方法仅需简单的目标数量提示，并结合了基于SAM的潜在目标挖掘策略、对比学习以提高伪标签可靠性，以及长短期运动感知学习来建模目标运动。实验结果表明，该弱监督方案在两个公共数据集上表现出色，性能优于早期全监督方法，并可达到SOTA全监督方法的90%以上。

> **摘要翻译:** 与通用目标检测不同，运动红外小目标检测由于目标尺寸微小和背景对比度弱而面临巨大挑战。当前，大多数现有方法是全监督的，严重依赖大量手动逐目标标注。然而，手动标注视频序列通常成本高昂且耗时，特别是对于低质量红外帧图像。受通用目标检测的启发，非全监督策略（例如弱监督）被认为在减少标注需求方面具有潜力。为了突破传统的全监督框架，作为首次探索性工作，本文提出了一种新的弱监督对比学习（WeCoL）方案，在模型训练期间仅需要简单的目标数量提示。具体来说，在我们的方案中，基于预训练的Segment Anything Model（SAM），设计了一种潜在目标挖掘策略，以整合目标激活图和多帧能量累积。此外，通过计算特征子空间中正负样本之间的相似性，采用对比学习来进一步提高伪标签的可靠性。此外，我们提出了一种长短期运动感知学习方案，以同时建模小目标的局部运动模式和全局运动轨迹。在两个公共数据集（DAUB和ITSDT-15K）上的大量实验验证了我们的弱监督方案通常可以优于早期的全监督方法。甚至，其性能可以达到最先进（SOTA）全监督方法的90%以上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [369] [CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios](https://arxiv.org/abs/2507.02479)
> *CrowdTrack：一个用于真实场景中困难多行人跟踪的基准*

*Teng Fu, Yuwen Chen, Zhuofan Chen, Mengyang Zhao, Bin Li, Xiangyang Xue* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 多行人跟踪, 数据集, 基准, 复杂场景, CrowdTrack

**Comment:** 

> **TL;DR:** 本文提出了一个名为CrowdTrack的大规模、困难的多行人跟踪数据集，旨在解决现有数据集在复杂真实场景中不足的问题，并促进新算法的开发。

**AI_Comments:** CrowdTrack的创新之处在于其专注于收集真实、复杂的、高密度人群的跟踪数据，特别是从第一人称视角拍摄，这与现有数据集形成鲜明对比，更贴近实际应用场景。其重要性在于弥补了现有MOT数据集在处理遮挡、模糊和高密度行人方面的不足，为训练和评估更鲁棒的跟踪算法提供了急需的资源。该数据集的发布有望显著推动多行人跟踪领域在真实世界复杂性方面的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多行人跟踪方法在复杂场景中（如物体遮挡、部分可见、图像模糊）表现不佳。主要原因是现有MOT数据集的场景过于简单且不真实，无法有效训练算法来应对这些挑战，且缺乏足够数量的困难视频序列。

**Method:** 作者提出了一个名为“CrowdTrack”的大规模、困难的多行人跟踪数据集。该数据集主要从第一人称视角拍摄，所有视频均来自真实复杂的场景，包含大量目标。数据集由33个视频和5,185条轨迹组成，每个目标都标注了完整的边界框和唯一的ID。此外，作者还对数据集进行了全面分析，并测试了多个SOTA模型和基础模型。

**Result:** CrowdTrack数据集包含33个视频，共5,185条轨迹，每个目标都标注了完整的边界框和唯一的对象ID。该数据集解决了现有数据集场景简单和非真实的问题，为在复杂情况下的算法开发提供了平台。作者还对数据集进行了全面分析，并测试了多个SOTA模型和基础模型，但具体测试结果未在摘要中提及。

**Conclusion:** CrowdTrack数据集的发布将为在复杂真实场景中开发和评估多行人跟踪算法提供一个重要的基准平台，从而促进该领域的研究进展。

> **ai_Abstract:** 本文针对现有多目标跟踪（MOT）数据集在复杂真实场景中表现不足的问题，提出了一个名为“CrowdTrack”的大规模、困难的多行人跟踪基准数据集。该数据集包含33个真实场景的第一人称视角视频，共5,185条带有完整边界框和唯一ID的轨迹，旨在解决现有数据集场景简单、非真实以及序列数量不足的缺点。CrowdTrack旨在为开发在复杂情况下依然有效的多行人跟踪算法提供一个重要的平台，作者已对数据集进行了全面分析并测试了SOTA模型。

> **摘要翻译:** 多目标跟踪是计算机视觉中的一个经典领域。其中，行人跟踪具有极高的应用价值，并已成为最热门的研究类别。现有方法主要使用运动或外观信息进行跟踪，这在复杂场景中往往很困难。对于运动信息，物体之间的相互遮挡常常阻碍运动状态的更新；对于外观信息，由于物体仅部分可见或图像模糊等原因，常常获得不鲁棒的结果。尽管从标注数据中学习如何在这些情况下进行跟踪是最简单的解决方案，但现有的MOT数据集未能满足这一需求。现有方法主要有两个缺点：场景构成相对简单和非真实场景。尽管现有数据集中的一些视频序列没有上述缺点，但数量远远不足以满足研究目的。为此，我们提出了一个用于多行人跟踪的困难大规模数据集，主要从第一人称视角拍摄，并且都来自真实复杂的场景。我们将其命名为“CrowdTrack”，因为大多数序列中都有大量目标。我们的数据集包含33个视频，总计5,185条轨迹。每个目标都标注了完整的边界框和唯一的对象ID。该数据集将提供一个平台，以促进在复杂情况下仍然有效的算法的开发。我们全面分析了该数据集，并在我们的数据集上测试了多个SOTA模型。此外，我们还分析了基础模型在该数据集上的性能。数据集和项目代码已发布在：https://github.com/loseevaya/CrowdTrack。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding](https://arxiv.org/abs/2507.02790)
> *从长视频到精彩短片：一种基于多模态叙事理解的人类启发式视频编辑框架*

*Xiangfeng Wang, Xiao Li, Yadong Wei, Xueyu Song, Yang Song, Xiaoqiang Xia, Fangrui Zeng, Zaiyi Chen, Liu Liu, Gu Xu, Tong Xu* | **Category: cs.CV, cs.CL** | **Updated: {updated}**

**Keywords:** 视频编辑, 多模态理解, 叙事理解, 自动编辑, DramaAD

**Comment:** 

> **TL;DR:** 提出HIVE框架，利用多模态叙事理解自动将长视频编辑成高质量短片，并引入新数据集DramaAD。

**AI_Comments:** 该论文的创新点在于引入了“人类启发式”和“多模态叙事理解”的概念，通过结合视觉和文本信息，并利用多模态大语言模型来提升视频内容的整体理解，从而解决了现有自动编辑方法中常见的连贯性问题。此外，提出的分步编辑策略和新数据集DramaAD也为该领域的研究提供了重要的贡献。该方法有望显著提高自动视频编辑的质量，减少人工干预，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动视频编辑方法主要依赖文本线索，忽略视觉上下文，导致输出不连贯；在线视频内容尤其是短视频的快速增长，对高效视频编辑技术的需求日益增长。

**Method:** 提出人类启发式自动视频编辑框架（HIVE），利用多模态大语言模型进行人物提取、对话分析和叙事总结，以实现对视频内容的整体理解。通过场景级分割，将编辑过程分解为亮点检测、开头/结尾选择和无关内容修剪三个子任务。引入新基准数据集DramaAD。

**Result:** HIVE框架在通用和广告导向的编辑任务中均持续优于现有基线，显著缩小了自动编辑与人工编辑视频之间的质量差距。

**Conclusion:** HIVE框架通过整合多模态叙事理解和分步编辑策略，有效提升了自动视频编辑的质量和连贯性，并为该领域提供了重要的基准数据集。

> **ai_Abstract:** 本文提出HIVE框架，一个人类启发式的自动视频编辑系统，旨在将长视频高效地浓缩为引人入胜的短片。HIVE通过多模态大语言模型进行叙事理解，包括人物提取、对话分析和叙事总结，并结合场景级分割，将编辑细分为亮点检测、开头/结尾选择和内容修剪。为支持研究，论文还引入了包含短剧和广告片的DramaAD数据集。实验证明，HIVE在各项任务中均超越现有方法，显著提升了自动视频编辑的质量。

> **摘要翻译:** 在线视频内容，特别是短视频平台的快速增长，对能将长视频浓缩成简洁引人入胜的短片的高效视频编辑技术产生了日益增长的需求。现有的自动编辑方法主要依赖于ASR转录的文本线索和端到端的片段选择，往往忽视了丰富的视觉上下文，导致输出不连贯。在本文中，我们提出了一种人类启发式的自动视频编辑框架（HIVE），它利用多模态叙事理解来解决这些局限性。我们的方法通过多模态大语言模型整合了人物提取、对话分析和叙事总结，从而实现了对视频内容的整体理解。为了进一步增强连贯性，我们应用了场景级分割，并将编辑过程分解为三个子任务：亮点检测、开头/结尾选择以及无关内容的修剪。为了促进该领域的研究，我们引入了DramaAD，一个新颖的基准数据集，包含800多个短剧集和500个专业编辑的广告短片。实验结果表明，我们的框架在通用和广告导向的编辑任务中都持续优于现有基线，显著缩小了自动和人工编辑视频之间的质量差距。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [372] [MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](https://arxiv.org/abs/2507.02488)
> *MedFormer：具有内容感知双稀疏选择注意的分层医学视觉Transformer*

*Zunhui Xia, Hongxing Li, Libin Lan* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 医学图像识别, 视觉Transformer, 稀疏注意力, 金字塔结构, MedFormer

**Comment:** 13 pages, 9 figures, 9 tables

> **TL;DR:** MedFormer是一个高效的医学视觉Transformer，通过金字塔缩放结构和内容感知双稀疏选择注意力（DSSA），解决了现有医学Transformer在通用性和计算效率方面的挑战，并在多种医学图像识别任务中表现出色。

**AI_Comments:** 这篇论文通过引入金字塔缩放结构和内容感知双稀疏选择注意力（DSSA），有效地解决了医学视觉Transformer在通用性和计算效率方面的关键挑战。其创新性在于DSSA能够智能地关注图像中最相关的内容，从而避免了全注意力的昂贵计算成本，并优于传统的手工稀疏注意力。MedFormer的通用性使其能够应用于多种医学图像识别任务，这对于临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于视觉Transformer的医学图像识别方法存在两个主要挑战：一是它们通常是任务特定和架构定制的，限制了通用性；二是它们要么采用全注意力导致高计算成本，要么依赖手工设计的稀疏注意力导致性能不佳。

**Method:** 本文提出了MedFormer，一个高效的医学视觉Transformer。它包含两个核心思想：1. 金字塔缩放结构（Pyramid Scaling Structure）: 作为通用的骨干网络，适用于图像分类、语义分割和病灶检测等多种医学图像识别任务。该结构有助于分层特征表示并降低特征图的计算负载。2. 双稀疏选择注意力（Dual Sparse Selection Attention, DSSA）: 引入了一种新颖的、内容感知的DSSA机制，旨在提高计算效率和对噪声的鲁棒性，同时保持高性能。DSSA被明确设计为关注最相关的内容。

**Result:** 详细的理论分析表明MedFormer在通用性和效率方面优于现有医学视觉Transformer。在多种成像模态数据集上进行的广泛实验一致表明，MedFormer在上述三种医学图像识别任务中均能有效提升性能。

**Conclusion:** MedFormer通过其金字塔缩放结构和内容感知双稀疏选择注意力，成功解决了现有医学视觉Transformer在通用性和效率方面的局限性，并在多种医学图像识别任务中展现出卓越的性能。

> **ai_Abstract:** 本文提出了MedFormer，一种高效的分层医学视觉Transformer，旨在解决现有医学Transformer在通用性和计算效率方面的局限性。MedFormer采用金字塔缩放结构作为通用骨干，支持多种医学图像任务，并引入了内容感知的双稀疏选择注意力（DSSA）以优化效率和性能。理论分析和广泛实验表明，MedFormer在图像分类、语义分割和病灶检测等任务中均表现出优越的通用性和性能提升。

> **摘要翻译:** 医学图像识别是辅助临床诊断的关键方式，能够更准确、及时地识别疾病和异常。基于视觉Transformer的方法已被证明在处理各种医学识别任务中是有效的。然而，这些方法面临两个主要挑战。首先，它们通常是任务特定和架构定制的，限制了其通用性。其次，它们通常要么采用全注意力来建模长程依赖，导致高计算成本，要么依赖手工设计的稀疏注意力，可能导致次优性能。为了解决这些问题，我们提出了MedFormer，一种高效的医学视觉Transformer，它包含两个关键思想。首先，它采用金字塔缩放结构作为各种医学图像识别任务（包括图像分类和语义分割、病灶检测等密集预测任务）的通用骨干网络。这种结构有助于分层特征表示，同时减少特征图的计算负载，这对于提高性能非常有益。其次，它引入了一种新颖的、内容感知的双稀疏选择注意力（DSSA），以提高计算效率和对噪声的鲁棒性，同时保持高性能。作为MedFormer的核心构建技术，DSSA被明确设计为关注最相关的内容。此外，还进行了详细的理论分析，证明MedFormer与现有医学视觉Transformer相比，具有卓越的通用性和效率。在多种成像模态数据集上进行的广泛实验一致表明，MedFormer在所有上述三种医学图像识别任务中都能高效提升性能。代码可在https://github.com/XiaZunhui/MedFormer 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [375] [Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy](https://arxiv.org/abs/2507.02493)
> *结肠镜检查中息肉计数的时序感知监督对比学习*

*Luca Parolari, Andrea Cherubini, Lamberto Ballan, Carlo Biffi* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 息肉计数, 时序感知, 监督对比学习, 结肠镜检查, 轨迹聚类

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** 本研究提出了一种时序感知的监督对比学习方法，用于结肠镜检查中的息肉计数，通过整合时序信息显著降低了息肉碎裂率，实现了新的最先进水平。

**AI_Comments:** 该论文的创新点在于将时序感知引入到息肉计数的监督对比学习框架中。通过考虑时间信息，它解决了现有方法在处理视觉相似但时间上不相关的息肉轨迹时的局限性，显著提高了聚类的鲁棒性和计数准确性。2.2倍的碎裂率降低是一个显著的改进，表明了该方法在临床应用中的潜力，有助于提高自动化结肠镜报告的质量。

<details>
  <summary>Details</summary>

**Motivation:** 结肠镜检查中自动息肉计数是实现自动化程序报告和质量控制的关键步骤，旨在提高筛查的成本效益。现有方法主要依赖视觉外观，忽略了轨迹特征学习和聚类阶段的时序关系，导致计数不准确。

**Method:** 本研究引入了一种新的范式，提出了一种监督对比损失，该损失融入了时序感知的软目标，以捕获息肉内部变异性并保持息肉间可区分性，从而实现更鲁棒的聚类。此外，通过整合时序邻近约束，减少了视觉相似但时序遥远的轨迹之间的错误重新关联。

**Result:** 与现有方法相比，碎裂率降低了2.2倍。结果强调了时序感知在息肉计数中的重要性。

**Conclusion:** 本研究通过引入时序感知监督对比学习，显著提高了结肠镜检查中息肉计数的准确性，并建立了新的最先进水平，证明了时序信息在息肉计数任务中的关键作用。

> **ai_Abstract:** 该论文提出了一种用于结肠镜检查中息肉计数的时序感知监督对比学习方法。针对现有方法忽略时序关系的问题，本研究引入了包含时序感知软目标的监督对比损失，以增强息肉内变异性捕获和息肉间区分能力。同时，通过集成时序邻近约束改进轨迹聚类，有效减少了假阳性重关联。实验结果显示，与现有方法相比，碎裂率降低了2.2倍，证明了时序感知在息肉计数中的关键作用，并达到了新的技术水平。

> **摘要翻译:** 结肠镜检查中自动息肉计数是实现自动化程序报告和质量控制的关键步骤，旨在提高结肠镜筛查的成本效益。在一次检查中计数息肉涉及检测和跟踪息肉，然后对属于同一息肉实体的轨迹进行聚类。现有的息肉计数方法依赖于自监督学习，主要利用视觉外观，而忽略了轨迹特征学习和聚类阶段的时序关系。在这项工作中，我们引入了一种范式转变，提出了一种监督对比损失，该损失融入了时序感知的软目标。我们的方法在捕获息肉内部变异性的同时，保持了息肉间可区分性，从而实现了更鲁棒的聚类。此外，我们通过整合时序邻近约束来改进轨迹聚类，减少了视觉相似但时序遥远的轨迹之间的错误重新关联。我们在公开可用的数据集上训练和验证了我们的方法，并采用留一法交叉验证策略评估其性能。结果表明，与现有方法相比，碎裂率降低了2.2倍。我们的结果突出了时序感知在息肉计数中的重要性，建立了新的最先进水平。代码可在https://github.com/lparolari/temporally-aware-polyp-counting获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [378] [MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations](https://arxiv.org/abs/2507.02494)
> *MC-INR：使用元学习和聚类隐式神经表示对多变量科学模拟数据进行高效编码*

*Hyunsoo Son, Jeonghyun Noh, Suemin Jeon, Chaoli Wang, Won-Ki Jeong* | **Category: cs.CV, cs.LG** | **Updated: {updated}**

**Keywords:** 隐式神经表示, 元学习, 聚类, 多变量数据, 科学模拟数据编码

**Comment:** 5 pages

> **TL;DR:** MC-INR是一个新的框架，结合元学习和聚类，用于高效编码非结构化网格上的多变量科学模拟数据，解决了现有INR方法在复杂数据表示上的局限性，并表现出更好的性能。

**AI_Comments:** MC-INR的创新点在于将元学习和聚类引入到隐式神经表示中，以克服现有方法在处理复杂多变量和非结构化数据时的不足。特别是动态再聚类机制和分支层的设计，使其能够更灵活、高效地编码数据，提升了INR在实际科学模拟数据应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于隐式神经表示（INRs）的方法在处理复杂结构数据时表示不灵活，主要关注单变量数据，并且依赖于结构化网格，导致其在复杂真实世界数据集上的性能下降。

**Method:** 提出了一种名为MC-INR的新型神经网络框架，用于处理非结构化网格上的多变量数据。它结合了元学习和聚类以实现复杂结构的灵活编码。为进一步提升性能，引入了基于残差的动态再聚类机制，根据局部误差自适应地划分簇；还提出了一个分支层，通过独立分支同时利用多变量数据。

**Result:** 实验结果表明，MC-INR在科学数据编码任务上优于现有方法。

**Conclusion:** MC-INR通过结合元学习、聚类、动态再聚类机制和分支层，有效解决了现有INR方法在处理复杂多变量科学模拟数据时的局限性，并在性能上超越了现有方法。

> **ai_Abstract:** 本文提出了MC-INR，一个结合元学习和聚类的神经网络框架，旨在高效编码非结构化网格上的多变量科学模拟数据。该框架通过引入残差基础的动态再聚类机制和分支层，解决了现有隐式神经表示（INRs）在处理复杂结构、多变量数据和非结构化网格时的局限性。实验证明MC-INR在科学数据编码任务上表现优异。

> **摘要翻译:** 隐式神经表示（INRs）被广泛用于将数据编码为连续函数，从而以更少的内存使用实现大规模多变量科学模拟数据的可视化。然而，现有的基于INR的方法面临三个主要限制：（1）复杂结构表示不灵活，（2）主要关注单变量数据，以及（3）依赖于结构化网格。因此，当应用于复杂的真实世界数据集时，它们的性能会下降。为了解决这些限制，我们提出了一种新颖的基于神经网络的框架MC-INR，它可以处理非结构化网格上的多变量数据。它结合了元学习和聚类，以实现复杂结构的灵活编码。为了进一步提高性能，我们引入了一种基于残差的动态再聚类机制，该机制根据局部误差自适应地划分簇。我们还提出了一个分支层，通过独立分支同时利用多变量数据。实验结果表明，MC-INR在科学数据编码任务上优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [379] [Automatic Labelling for Low-Light Pedestrian Detection](https://arxiv.org/abs/2507.02513)
> *低光照行人检测的自动标注*

*Dimitrios Bouzoulas, Eerik Alamikkotervo, Risto Ojala* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 低光照行人检测, 自动标注, 红外-RGB, 目标检测, 数据增强

**Comment:** 

> **TL;DR:** 该研究提出了一种自动红外-RGB标注流程，以解决低光照行人检测数据不足的问题。结果显示，使用自动生成标签训练的模型在某些情况下性能优于使用真实标签训练的模型。

**AI_Comments:** 这项研究的创新之处在于利用红外数据对RGB图像进行自动标注，有效地为低光照条件这一具有挑战性的实际问题（数据稀缺）创建了合成训练数据。自动生成的标签在某些指标上能够超越真实标签，这一发现意义重大，预示着数据增强和标注效率方面的一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** RGB图像中的行人检测是自动驾驶和高级驾驶辅助系统中的一项关键任务，但在低光照条件下，由于缺乏大型公共数据集，行人检测面临挑战。

**Method:** 本研究提出了一种自动红外-RGB标注流程。该流程包括：1) 使用微调模型进行红外行人检测；2) 将红外检测结果的标签转移到对应的RGB图像上；3) 使用生成的标签训练目标检测模型，用于低光照RGB行人检测。研究使用KAIST数据集进行评估。

**Result:** 在未见的图像序列上，与使用真实标签训练的模型相比，使用生成的自动标签训练的模型在9种情况中的6种情况下，针对mAP@50和mAP@50-95指标表现更优。

**Conclusion:** 本研究提出的自动红外-RGB标注流程有效解决了低光照行人检测中的数据稀缺问题，并且在某些场景下可以使模型表现优于传统真实标签训练的模型。

> **ai_Abstract:** 本文旨在解决RGB图像中低光照行人检测的数据稀缺问题，该问题对自动驾驶至关重要。研究提出了一种自动红外-RGB标注流程，该流程利用微调的红外检测模型将标签转移到RGB图像，进而训练目标检测模型。在KAIST数据集上的评估表明，使用这些自动生成标签训练的模型在大多数情况下性能优于使用真实标签训练的模型。

> **摘要翻译:** RGB图像中的行人检测是行人安全中的一项关键任务，因为自动驾驶汽车和高级驾驶辅助系统中最常见的传感器是RGB摄像头。RGB行人检测面临的一个挑战是低光照条件，而目前似乎没有大型公共数据集来解决这个问题。作为解决方案，本研究提出了一种自动红外-RGB标注流程。所提出的流程包括：1) 红外检测，其中使用经过微调的红外行人检测模型；2) 将红外检测结果的标签转移到其对应的RGB图像上；3) 使用生成的标签训练目标检测模型，用于低光照RGB行人检测。该研究使用KAIST数据集进行。为了进行评估，目标检测模型在生成的自动标签和真实标签上进行了训练。在对先前未见的图像序列进行比较时，结果表明，在9种情况中的6种情况下，针对mAP@50和mAP@50-95指标，使用生成标签训练的模型优于使用真实标签训练的模型。本研究的源代码可在https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [381] [IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning](https://arxiv.org/abs/2507.02519)
> *IMASHRIMP：利用计算机视觉和深度学习对实验室图像中的凡纳滨对虾（Penaeus vannamei）进行自动生物测量分析*

*Abiam Remache González, Meriem Chagour, Timon Bijan Rüth, Raúl Trapiella Cañedo, Marina Martínez Soler, Álvaro Lorenzo Felipe, Hyun-Suk Shin, María-Jesús Zamorano Serrano, Ricardo Torres, Juan-Antonio Castillo Parra, Eduardo Reyes Abad, Miguel-Ángel Ferrer Ballester, Juan-Manuel Afonso López, Francisco-Mario Hernández Tejera, Adrian Penate-Sanchez* | **Category: cs.CV, I.2.10; I.4.8** | **Updated: {updated}**

**Keywords:** 凡纳滨对虾, 生物测量分析, 计算机视觉, 深度学习, 水产养殖

**Comment:** 14 pages, 7 figures

> **TL;DR:** IMASHRIMP是一个利用计算机视觉和深度学习技术对凡纳滨对虾进行自动生物测量分析的系统，旨在优化水产养殖中的遗传选择任务，显著减少了人为错误并提高了效率。

**AI_Comments:** 该论文的创新点在于将现有的深度学习和计算机视觉技术有效地应用于特定的生物领域——凡纳滨对虾的生物测量分析。系统整合了多个模块（判别、姿态估计、形态回归），并通过引入独特的“人机双重认证”机制，显著降低了实际应用中人为操作的错误率，这对于水产养殖的实际操作具有重要意义。其对遗传选择效率和可持续水产养殖的直接贡献值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过自动化凡纳滨对虾的形态分析，优化水产养殖中的遗传选择任务，并解决从RGBD图像分析虾体形态的特定挑战。

**Method:** 本研究提出了IMASHRIMP系统，该系统修改了现有的深度学习和计算机视觉技术以处理虾体形态分析。它包含两个基于改进ResNet-50架构的判别模块，用于视角分类和吻部完整性检测。系统引入了“人机双重认证”机制以减少人为错误。此外，还包含一个基于VitPose的姿态估计模块，用于预测虾体23个关键点（针对侧视图和背视图有独立网络），以及一个使用支持向量机（SVM）模型的形态回归模块，将像素测量转换为厘米单位。

**Result:** IMASHRIMP系统将视角分类中的人为错误从0.97%降低到0%，吻部检测中的人为错误从12.46%降低到3.64%。姿态估计的平均精度（mAP）达到97.94%，像素到厘米的转换误差为0.07 (+/- 0.1) 厘米。

**Conclusion:** IMASHRIMP系统展示了自动化和加速虾体形态分析的潜力，能有效提高遗传选择效率，并有助于更可持续的水产养殖实践。

> **ai_Abstract:** IMASHRIMP是一个创新的系统，利用计算机视觉和深度学习技术对凡纳滨对虾进行自动形态分析，以优化水产养殖中的遗传选择。该系统整合了基于修改ResNet-50的判别模块、引入“人机双重认证”以减少错误，以及一个基于VitPose的姿态估计模块和一个SVM形态回归模块。实验证明，它显著降低了人为错误，并在姿态估计和尺寸转换方面取得了高精度，展示了在提高水产养殖效率和可持续性方面的巨大潜力。

> **摘要翻译:** 本文介绍了IMASHRIMP，一个用于凡纳滨对虾（Penaeus vannamei）自动形态分析的适应性系统，旨在优化水产养殖中的遗传选择任务。现有的深度学习和计算机视觉技术被修改以解决从RGBD图像分析虾体形态的特定挑战。IMASHRIMP包含两个基于改进ResNet-50架构的判别模块，用于按视角分类图像并确定吻部完整性。它提出了一个“双重认证（人工和人工智能）”系统，将视角分类中的人为错误从0.97%降低到0%，吻部检测中的人为错误从12.46%降低到3.64%。此外，一个姿态估计模块从VitPose改编而来，用于预测虾体骨骼上的23个关键点，其中侧视图和背视图分别使用独立网络。一个使用支持向量机（SVM）模型的形态回归模块被集成，用于将像素测量转换为厘米单位。实验结果表明，该系统有效减少了人为错误，姿态估计的平均精度（mAP）达到97.94%，像素到厘米的转换误差为0.07（+/- 0.1）厘米。IMASHRIMP展示了自动化和加速虾体形态分析的潜力，提高了遗传选择的效率，并有助于更可持续的水产养殖实践。代码可在https://github.com/AbiamRemacheGonzalez/ImaShrimp-public获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [383] [MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details](https://arxiv.org/abs/2507.02546)
> *MoGe-2：具有度量尺度和锐利细节的精确单目几何*

*Ruicheng Wang, Sicheng Xu, Yue Dong, Yu Deng, Jianfeng Xiang, Zelong Lv, Guangzhong Sun, Xin Tong, Jiaolong Yang* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 单目几何估计, 度量尺度, 细节恢复, MoGe-2, 3D点图

**Comment:** Project page: https://wangrc.site/MoGe2Page/

> **TL;DR:** MoGe-2是一种先进的单目几何估计模型，能从单张图像中恢复具有度量尺度和锐利细节的3D点图。

**AI_Comments:** MoGe-2的创新在于它首次同时实现了单目几何估计的精确相对几何、度量尺度和精细细节恢复，这在以往的方法中是未能同时达到的。其统一的数据细化方法利用合成标签来提升真实数据的细节，是解决真实世界数据噪声导致细节丢失问题的有效途径。这对于需要高精度3D重建的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的单目几何估计方法（如MoGe）预测的是尺度未知的仿射不变点图；同时，真实数据中的噪声和误差会削弱预测几何中的精细细节。

**Method:** MoGe-2在MoGe的基础上进行扩展，以实现度量几何预测，同时不损害相对几何精度。此外，它开发了一种统一的数据细化方法，利用锐利的合成标签过滤和完成来自不同来源的真实数据，以增强重建几何的粒度。模型在大型混合数据集上进行训练。

**Result:** MoGe-2在实现精确的相对几何、精确的度量尺度和精细细节恢复方面表现出卓越的性能，这些能力是以前的方法无法同时实现的。

**Conclusion:** MoGe-2通过其创新的扩展和数据细化方法，显著提高了单目几何估计的准确性和细节恢复能力，首次同时实现了精确相对几何、度量尺度和精细细节恢复，填补了现有技术的空白。

> **ai_Abstract:** MoGe-2是一种新型的单目几何估计模型，它在MoGe的基础上进行了改进，能够从单张图像中恢复具有度量尺度和精细细节的场景3D点图。该模型通过有效策略扩展了MoGe以实现度量几何预测，并引入了统一的数据细化方法来处理真实数据中的噪声，从而显著提升了重建几何的细节粒度。MoGe-2在精确相对几何、度量尺度和细节恢复方面表现出优越性能，填补了现有方法无法同时实现这些能力的空白。

> **摘要翻译:** 我们提出了MoGe-2，一个先进的开放域几何估计模型，它能从单张图像中恢复场景的度量尺度3D点图。我们的方法建立在最近的单目几何估计方法MoGe之上，MoGe预测的是具有未知尺度的仿射不变点图。我们探索了有效的策略来扩展MoGe以进行度量几何预测，同时不损害仿射不变点表示所提供的相对几何精度。此外，我们发现真实数据中的噪声和误差会削弱预测几何中的精细细节。我们通过开发一种统一的数据细化方法来解决这个问题，该方法利用锐利的合成标签过滤和完成来自不同来源的真实数据，显著增强了重建几何的粒度，同时保持了整体准确性。我们在大型混合数据集上训练了我们的模型，并进行了全面的评估，展示了其在实现精确的相对几何、精确的度量尺度和精细细节恢复方面的卓越性能——这些能力是以前的方法无法同时实现的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [385] [Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning](https://arxiv.org/abs/2507.02565)
> *基于外观和空间推理的紧密人际交互重建*

*Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, Yangang Wang, Gim Hee Lee* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 人体交互重建, 姿态估计, 扩散模型, 社交距离, 外观推理

**Comment:** 

> **TL;DR:** 提出一种双分支优化框架，利用外观、空间距离和物理定律，结合扩散模型和多种约束，从野外视频中准确重建紧密人际交互，并构建了一个新数据集，性能优于现有方法。

**AI_Comments:** 这篇论文通过引入人体外观和社交距离先验来解决紧密人际交互重建中的挑战，具有创新性。其提出的双分支优化框架结合扩散模型和多样化约束，为复杂场景下的人体姿态估计提供了新的思路。构建带有伪真实标注的数据集对社区的贡献也很大，有望推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体姿态估计方法由于视觉模糊和人际遮挡，无法从野外视频中恢复出合理紧密的人际交互，即使是先进的大型基础模型也无法准确区分这种复杂场景中的人体语义。

**Method:** 提出了一种双分支优化框架，通过人体外观、社交距离和物理定律约束来重建准确的交互动作和身体接触。具体地，首先训练一个扩散模型来学习人体空间行为和姿态先验知识。然后，将训练好的网络和两个可优化张量整合到双分支优化框架中，以重建人体运动和外观。此外，还设计了基于3D高斯、2D关键点和网格穿透的多种约束来辅助优化。

**Result:** 该方法能够从复杂环境中的野外视频中估计出准确的交互。在多个基准测试上的实验结果表明，该方法优于现有方法。此外，还构建了一个带有伪真实交互标注的数据集。

**Conclusion:** 通过结合空间距离先验和多种约束，本方法能够准确估计野外视频中的紧密人际交互，并在性能上超越了现有方法，同时构建的新数据集有助于未来研究。

> **ai_Abstract:** 本文提出了一种名为“基于外观和空间推理的紧密人际交互重建”的方法，旨在解决现有方法在野外视频中重建紧密人际交互时遇到的视觉模糊和遮挡问题。该方法引入了一个双分支优化框架，通过结合人体外观、社交距离和物理定律来精确重建交互动作和身体接触。核心技术包括训练一个扩散模型学习空间行为和姿态先验，并利用3D高斯、2D关键点和网格穿透等多种约束辅助优化。实验证明，该方法在复杂环境中能准确估计交互，性能优于现有方法。此外，论文还构建了一个新的带有伪真实交互标注的数据集，以促进相关领域的研究。

> **摘要翻译:** 由于视觉模糊和人际遮挡，现有的人体姿态估计方法无法从野外视频中恢复出合理紧密的人际交互。即使是最先进的大型基础模型（例如SAM）也无法在这些具有挑战性的场景中准确区分人体语义。在这项工作中，我们发现人体外观可以提供一个直接的线索来解决这些障碍。基于这一观察，我们提出了一种双分支优化框架，以重建准确的交互动作，并利用人体外观、社交距离和物理定律约束来确保可信的身体接触。具体来说，我们首先训练一个扩散模型来学习人体空间行为和姿态先验知识。然后，将训练好的网络和两个可优化张量整合到双分支优化框架中，以重建人体运动和外观。还设计了基于3D高斯、2D关键点和网格穿透的多种约束来辅助优化。凭借空间距离先验和多样化的约束，我们的方法能够从复杂环境中捕获的野外视频中估计出准确的交互。我们进一步构建了一个带有伪真实交互标注的数据集，这可能会促进未来在姿态估计和人类行为理解方面的研究。在多个基准测试上的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [387] [Parametric shape models for vessels learned from segmentations via differentiable voxelization](https://arxiv.org/abs/2507.02576)
> *通过可微分体素化从分割中学习血管的参数化形状模型*

*Alina F. Dima, Suprosanna Shit, Huaqi Qiu, Robbie Holland, Tamara T. Mueller, Fabio Antonio Musio, Kaiyuan Yang, Bjoern Menze, Rickmer Braren, Marcus Makowski, Daniel Rueckert* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 血管建模, 参数化形状模型, 可微分体素化, 图像分割, 三次B样条

**Comment:** 15 pages, 6 figures

> **TL;DR:** 提出一个通过可微分体素化，从分割数据中自动学习血管参数化形状模型并提取高保真网格的框架。

**AI_Comments:** 本文的创新之处在于提出了一个统一的框架，通过可微分体素化桥接了血管的体素化、网格和参数模型表示，解决了传统方法中这些表示独立使用的问题。特别是，它实现了从分割数据中自动学习参数化形状模型，无需显式真值，这大大降低了数据标注的难度。其生成的平滑连续的参数模型和高保真网格在医学图像分析和可视化领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 血管的不同表示（体素化、网格、参数模型）通常是独立提取和使用的，缺乏一个能将它们结合起来的框架，并且从分割中提取参数模型通常需要显式的真值参数。

**Method:** 提出一个框架，通过可微分变换将体素化、网格和参数模型这三种血管表示结合起来。利用可微分体素化，通过形状到分割的拟合，从分割中自动提取血管的参数化形状模型，无需显式真值形状参数。血管通过三次B样条曲线参数化为中心线和半径，确保平滑性和连续性。从学习到的形状参数中可微分地提取网格。

**Result:** 该方法可以准确捕获复杂血管的几何形状，实验在主动脉、动脉瘤和脑血管上的体积拟合证明了这一点。

**Conclusion:** 该框架成功地通过可微分体素化从分割数据中学习血管的参数化形状模型，并能生成高保真网格，为血管建模提供了一种集成且有效的方法。

> **ai_Abstract:** 本文提出了一个创新的框架，通过可微分体素化将血管的三种主要表示形式（体素化、网格和参数模型）结合起来。该框架能够从血管分割数据中自动学习参数化形状模型，无需显式真值参数，并通过三次B样条曲线将血管参数化为中心线和半径。此外，该方法还能从学习到的参数中可微分地提取高保真网格。实验证明，该方法能准确捕捉复杂血管的几何形状。

> **摘要翻译:** 血管是人体内复杂的结构，已在多种表示形式下进行了广泛研究。虽然体素化是其中最常见的形式，但网格和参数模型因其理想的特性在各种应用中至关重要。然而，这些表示通常通过分割提取，并且彼此独立使用。我们提出了一个框架，通过可微分变换将这三种表示结合起来。通过利用可微分体素化，我们通过形状到分割的拟合自动提取血管的参数化形状模型，从而可以从分割中学习形状参数，而无需显式地需要真实形状参数。血管通过三次B样条曲线参数化为中心线和半径，通过构造确保了平滑性和连续性。网格是从学习到的形状参数中可微分地提取的，从而产生可以在拟合后进行操作的高保真网格。我们的方法可以准确捕获复杂血管的几何形状，主动脉、动脉瘤和脑血管实验中的体积拟合证明了这一点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [389] [Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning](https://arxiv.org/abs/2507.02581)
> *三维医学图像自监督学习中的结构感知语义差异与一致性*

*Tan Pan, Zhaorui Tan, Kaiyu Guo, Dongli Xu, Weidi Xu, Chen Jiang, Xin Guo, Yuan Qi, Yuan Cheng* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 三维医学图像, 自监督学习, 结构感知, 语义差异, 语义一致性

**Comment:** Accepted by ICCV25

> **TL;DR:** 提出了一种名为 $S^2DC$ 的新型三维医学图像自监督学习框架，通过处理结构差异和一致性来学习结构感知表示，并在多项任务和数据集上超越了现有最佳方法。

**AI_Comments:** 该论文的创新之处在于其明确地解决了三维医学图像自监督学习中，以往方法因使用固定大小补丁而忽略解剖结构变异的局限性。通过引入结构感知语义差异和一致性的概念，并设计了相应的两步策略，该方法能够学习到更具判别力和鲁棒性的表示，这对于医学图像分析具有重要意义。其在广泛数据集和任务上的卓越性能也验证了其有效性和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 以往的三维医学图像自监督学习（mSSL）方法在图像分区时使用固定大小的补丁，常常忽略解剖结构在位置、尺度和形态上的变异，这限制了其捕捉有意义区别的能力和更广泛的应用。

**Method:** 本研究提出了一种名为 $S^2DC$ 的mSSL框架，旨在学习结构感知表示。该方法基于同一结构内补丁语义一致、不同结构补丁语义差异的假设。具体分为两步：1. 利用最优传输策略，强制不同补丁之间产生不同的表示，以增加语义差异。2. 基于邻域相似度分布，在结构层面推进语义一致性。通过这种方式，S^2DC 连接了补丁级和结构级表示，实现了结构感知表示。

**Result:** 所提出的 $S^2DC$ 方法在 10 个数据集、4 项任务和 3 种模态上进行了全面评估，结果显示其始终优于现有的最先进 mSSL 方法。

**Conclusion:** 所提出的 $S^2DC$ 框架通过引入结构感知语义差异和一致性的概念，有效解决了传统三维医学图像自监督学习方法忽略解剖结构变异的问题，并成功学习了结构感知表示，在多项医学图像分析任务中取得了领先的性能。

> **ai_Abstract:** 本论文针对三维医学图像自监督学习（mSSL）中忽略解剖结构变异的限制，提出了一种名为 $S^2DC$ 的新型框架。该框架旨在学习结构感知表示，其核心思想是确保同一结构内的补丁具有语义一致性，而不同结构间的补丁则表现出语义差异。$S^2DC$ 通过两个步骤实现此目标：一是利用最优传输策略增强不同补丁间的语义差异；二是通过邻域相似度分布促进结构层面的语义一致性。实验结果表明，该方法在 10 个数据集、4 项任务和 3 种模态上均显著优于现有最先进的mSSL方法。

> **摘要翻译:** 三维医学图像自监督学习 (mSSL) 在医学分析中具有广阔前景。有效支持更广泛的应用需要考虑解剖结构在位置、尺度和形态上的变异，这对于捕捉有意义的区别至关重要。然而，以前的 mSSL 方法使用固定大小的补丁对图像进行分区，通常忽略了结构变异。在这项工作中，我们引入了一种关于三维医学图像的新颖视角，目标是学习结构感知的表示。我们假设同一结构内的补丁共享相同的语义（语义一致性），而来自不同结构的补丁则表现出不同的语义（语义差异）。基于这一假设，我们提出了一个名为 $S^2DC$ 的 mSSL 框架，通过两个步骤实现结构感知语义差异和一致性。首先，$S^2DC$ 通过利用最优传输策略，强制不同补丁具有不同的表示以增加语义差异。其次，$S^2DC$ 基于邻域相似度分布在结构层面推进语义一致性。通过连接补丁级和结构级表示，$S^2DC$ 实现了结构感知表示。我们的方法在 10 个数据集、4 项任务和 3 种模态上进行了全面评估，始终优于当前的 mSSL 最先进方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [391] [AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding](https://arxiv.org/abs/2507.02591)
> *AuroraLong：将RNN带回高效的开放式视频理解*

*Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 长视频理解, 循环神经网络, Transformer, 计算效率, 开放式视频理解

**Comment:** Accepted to ICCV 2025

> **TL;DR:** AuroraLong通过用线性RNN语言模型替换Transformer，解决了长视频理解中计算复杂度和内存成本高的问题，实现了与大型Transformer模型相当的性能。

**AI_Comments:** 该论文的创新点在于首次将线性RNN作为LLM骨干应用于开放式视频理解的类LLaVA模型，有效解决了长视频理解中Transformer模型固有的计算和内存二次方增长问题。其重要性在于，通过使用参数量更少且仅在公共数据上训练的模型，实现了与大型Transformer模型相当的性能，这极大地降低了长视频理解的计算门槛，有助于该领域的民主化。

<details>
  <summary>Details</summary>

**Motivation:** 长视频理解面临计算复杂度和内存成本高的问题，因为基于Transformer的LLM所需的内存和计算量与输入序列长度呈二次方关系。

**Method:** 提出AuroraLong，用线性RNN语言模型替换多模态大型语言模型（MLLM）中的LLM组件，该模型能以恒定大小的隐藏状态处理任意长度的输入序列。通过按大小升序重新排序视觉tokens，将视觉token合并与线性RNN模型相结合，以进一步提高吞吐量和效率。

**Result:** AuroraLong模型参数仅为2B，且仅在公共数据上训练，但在多个视频基准上实现了与在私有数据集上训练的同等大小的Transformer模型相当的性能。

**Conclusion:** 高效的线性RNNs有望通过降低计算门槛来普及长视频理解。这是首次在类LLaVA模型中使用基于线性RNN的LLM骨干进行开放式视频理解。

> **ai_Abstract:** AuroraLong旨在解决长视频理解中Transformer模型面临的计算和内存瓶颈。该方法用线性RNN语言模型替代多模态大型语言模型（MLLM）中的Transformer组件，使其能以固定大小的隐藏状态处理任意长度的视频序列。为提高效率，AuroraLong还将视觉token合并技术与线性RNN模型结合。尽管模型规模较小且仅使用公共数据训练，AuroraLong在多项视频基准测试中展现出与大型Transformer模型相当的性能，突显了线性RNN在普及长视频理解方面的潜力，并首次将线性RNN LLM骨干应用于开放式视频理解的类LLaVA模型。

> **摘要翻译:** 长视频理解的挑战在于其高计算复杂度和高昂的内存成本，因为基于Transformer的LLM所需的内存和计算量与输入序列长度呈二次方关系。我们提出AuroraLong来解决这一挑战，方法是用线性RNN语言模型替换多模态大型语言模型（MLLM）中的LLM组件，该模型能以恒定大小的隐藏状态处理任意长度的输入序列。为了进一步提高吞吐量和效率，我们通过按大小升序重新排序视觉tokens，将视觉token合并与线性RNN模型相结合。尽管AuroraLong只有2B参数，并且仅在公共数据上训练，但它在多个视频基准上实现了与在私有数据集上训练的同等大小的Transformer模型相当的性能。这表明高效的线性RNNs有望通过降低计算门槛来普及长视频理解。据我们所知，我们是第一个在类LLaVA模型中使用基于线性RNN的LLM骨干进行开放式视频理解的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [392] [Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development](https://arxiv.org/abs/2507.02602)
> *解决视觉导航中的相机传感器故障：仿真与数据集开发*

*Riccardo Gallon, Fabian Schiemenz, Alessandra Menicucci, Eberhard Gill* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 视觉导航, 传感器故障, 数据集开发, 故障检测, 仿真

**Comment:** Submitted to Acta Astronautica

> **TL;DR:** 针对视觉导航中相机传感器故障，本研究开发了一个模拟框架和故障图像数据集，以支持AI故障检测。

**AI_Comments:** 这项研究通过系统地分析相机传感器故障并开发一个用于生成故障图像数据的仿真框架，有效地解决了AI在视觉导航故障检测中面临的核心挑战——数据稀缺性。其创新之处在于提供了一种可控且可重复的方法来创建大规模、多样化的故障数据集，这对于训练和验证鲁棒的AI模型至关重要。该工作对于提高太空任务中视觉导航系统的可靠性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉导航（VBN）在太空任务中日益重要，但传感器故障可能导致导航算法输出不准确甚至数据处理完全失败，从而危及任务目标。尽管人工智能（AI）在故障检测方面具有优势，但缺乏足够且具有代表性的包含故障图像数据的数据集是其应用的主要障碍。

**Method:** 本研究针对行星际探索任务场景，全面分析了视觉导航流程中相机传感器的潜在故障案例，系统地描述了这些故障的原因和影响（包括对图像质量和导航算法性能的影响以及常用缓解策略）。为支持此分析，引入了一个仿真框架来在合成图像中重现故障条件，从而实现对故障数据的系统化和受控复现。

**Result:** 获得了一个注入故障图像的数据集，该数据集为训练和测试基于AI的故障检测算法提供了宝贵工具。

**Conclusion:** 通过开发仿真框架和生成故障注入图像数据集，本研究解决了AI在视觉导航故障检测中面临的数据集不足问题，为提高VBN的可靠性和鲁棒性奠定了基础。

> **ai_Abstract:** 本研究致力于解决视觉导航（VBN）在太空任务中因相机传感器故障导致可靠性受损的问题。鉴于AI在故障检测中的潜力但缺乏训练数据，作者分析了行星际探索任务中相机传感器的潜在故障，并系统地描述了其影响。为克服数据不足，研究引入了一个仿真框架，能够在合成图像中模拟故障条件，并成功生成了一个包含故障注入图像的数据集，该数据集可用于训练和测试AI驱动的故障检测算法，从而提高VBN的鲁棒性。

> **摘要翻译:** 视觉导航（VBN）算法在太空任务中日益增长的重要性，对其可靠性和操作鲁棒性提出了诸多挑战。传感器故障可能导致导航算法输出不准确，甚至完全的数据处理故障，从而可能危及任务目标。人工智能（AI）为检测此类故障提供了强大的解决方案，克服了传统故障检测方法的许多局限性。然而，在此背景下采用AI的主要障碍是缺乏足够且具有代表性的包含故障图像数据的数据集。
本研究通过关注行星际探索任务场景来应对这些挑战。文中对视觉导航流程中使用的相机传感器的潜在故障案例进行了全面分析。系统地描述了这些故障的原因和影响，包括它们对图像质量和导航算法性能的影响，以及常用的缓解策略。为了支持这项分析，引入了一个仿真框架，用于在合成生成的图像中重现故障条件，从而实现对故障数据的系统化和受控复现。由此产生的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了宝贵的工具。数据集的最终链接将在禁运期后添加。对于同行评审员，此私人链接可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models](https://arxiv.org/abs/2507.02664)
> *AIGI-Holmes：通过多模态大语言模型实现可解释、可泛化的AI生成图像检测*

*Ziyin Zhou, Yunpeng Luo, Yuanchen Wu, Ke Sun, Jiayi Ji, Ke Yan, Shouhong Ding, Xiaoshuai Sun, Yunsheng Wu, Rongrong Ji* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** AI生成图像检测, 多模态大语言模型, 可解释性AI, 泛化能力, 虚假信息

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 本文提出AIGI-Holmes模型，利用多模态大语言模型（MLLMs）和新数据集Holmes-Set，旨在解决现有AI生成图像（AIGI）检测技术缺乏可解释性和泛化能力的问题，并能提供人类可验证的解释。

**AI_Comments:** 本文通过引入大规模高质量数据集和创新的三阶段训练框架，有效解决了AI生成图像检测领域面临的关键挑战，即解释性和泛化能力不足。其结合多模态大语言模型（MLLMs）的方法，以及在数据标注和推理阶段的策略，为未来的AIGI检测研究提供了新的视角和实用方案。特别是其强调生成人类可验证解释的能力，对于提升AI检测系统的可信度和用户接受度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，对公共信息安全构成威胁。现有AIGI检测技术存在缺乏人类可验证的解释和在新一代技术中泛化能力不足的问题。

**Method:** 本文引入了一个大规模综合数据集Holmes-Set，包括带有解释的指令调优数据集Holmes-SFTSet和人类对齐偏好数据集Holmes-DPOSet。开发了一种高效的数据标注方法“多专家评审团”，通过结构化MLLM解释和质量控制来增强数据生成。提出Holmes Pipeline，一个三阶段训练框架，包括视觉专家预训练、监督微调和直接偏好优化，以适应MLLMs进行AIGI检测并生成可验证解释。在推理阶段，引入了一种协作解码策略，整合视觉专家感知和MLLM语义推理，以增强泛化能力，最终得到AIGI-Holmes模型。

**Result:** 在三个基准测试上的大量实验验证了AIGI-Holmes模型的有效性。

**Conclusion:** AIGI-Holmes模型通过整合多模态大语言模型、创新数据集和训练策略，成功解决了AI生成图像检测中可解释性和泛化能力不足的挑战，并提供了有效且人类可验证的检测方法。

> **ai_Abstract:** 本文提出了AIGI-Holmes模型，旨在解决AI生成图像（AIGI）检测中缺乏可解释性和泛化能力的问题。作者构建了一个大规模多模态数据集Holmes-Set，并设计了“多专家评审团”标注方法。在此基础上，提出了一个三阶段训练框架Holmes Pipeline，将多模态大语言模型（MLLMs）应用于AIGI检测，使其能生成人类可验证的解释。通过结合视觉专家感知和MLLM语义推理的协作解码策略，进一步增强了模型的泛化能力。实验结果验证了AIGI-Holmes的有效性。

> **摘要翻译:** 人工智能生成内容（AIGC）技术的快速发展导致高度逼真的AI生成图像（AIGI）被滥用于传播虚假信息，对公共信息安全构成威胁。尽管现有AIGI检测技术普遍有效，但它们面临两个问题：1）缺乏人类可验证的解释，2）在最新一代技术中缺乏泛化能力。为了解决这些问题，我们引入了一个大规模综合数据集Holmes-Set，其中包括Holmes-SFTSet（一个带有图像是否为AI生成解释的指令调优数据集）和Holmes-DPOSet（一个人类对齐偏好数据集）。我们的工作引入了一种高效的数据标注方法，称为“多专家评审团”，通过结构化MLLM解释增强数据生成，并通过跨模型评估、专家缺陷过滤和人类偏好修改进行质量控制。此外，我们提出了Holmes Pipeline，一个精心设计的三阶段训练框架，包括视觉专家预训练、监督微调和直接偏好优化。Holmes Pipeline使多模态大语言模型（MLLMs）适用于AIGI检测，同时生成人类可验证和人类对齐的解释，最终产生了我们的模型AIGI-Holmes。在推理阶段，我们引入了一种协作解码策略，将视觉专家的模型感知与MLLM的语义推理相结合，进一步增强了泛化能力。在三个基准测试上的大量实验验证了我们AIGI-Holmes的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [396] [Learning few-step posterior samplers by unfolding and distillation of diffusion models](https://arxiv.org/abs/2507.02686)
> *学习通过扩散模型的展开和蒸馏实现的少步后验采样器*

*Charlesquin Kemajou Mbakam, Jonathan Spence, Marcelo Pereyra* | **Category: cs.CV, cs.LG** | **Updated: {updated}**

**Keywords:** 扩散模型, 后验采样, 深度展开, 模型蒸馏, MCMC

**Comment:** 28 pages, 16 figures, 10 tables

> **TL;DR:** 本文通过深度展开和模型蒸馏，首次将扩散模型转换为高效且灵活的少步后验采样器，并首次将深度展开应用于蒙特卡洛采样方案。

**AI_Comments:** 本文的创新点在于首次将深度展开技术应用于蒙特卡洛采样算法，特别是MCMC采样器，这为从扩散模型构建高效的少步后验采样器提供了新颖的思路。该方法成功地结合了深度学习和传统采样方法的优势，解决了现有即插即用方法精度不足和专用条件DM缺乏灵活性的问题，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有利用扩散模型进行贝叶斯计算成像的方法存在局限性：即插即用方法依赖近似且精度有限，而专用条件扩散模型虽精度高但缺乏灵活性。因此，需要一种兼具高精度、高效率和灵活性的后验采样方法。

**Method:** 本文引入了一种新颖的框架，该框架集成了深度展开和模型蒸馏，将扩散模型图像先验转换为用于后验采样的少步条件模型。核心创新是对马尔可夫链蒙特卡洛（MCMC）算法（特别是LATINO Langevin采样器）进行展开，这是首次将深度展开应用于蒙特卡洛采样方案。

**Result:** 所提出的展开和蒸馏采样器在广泛的实验中表现出色的准确性和计算效率，同时保持了在推理时适应前向模型变化的灵活性。

**Conclusion:** 本文成功开发了一种基于扩散模型的少步后验采样器，该采样器通过深度展开和模型蒸馏实现，具有高准确性、高计算效率和良好的灵活性，能够有效解决贝叶斯计算成像中的后验采样问题。

> **ai_Abstract:** 本文提出了一种新颖的框架，通过深度展开和模型蒸馏将扩散模型（DM）图像先验转化为高效的少步条件模型，用于贝叶斯计算成像中的后验采样。该方法首次将深度展开应用于蒙特卡洛采样算法（如LATINO Langevin采样器），旨在解决现有方法在精度、效率和灵活性上的局限。实验结果表明，该方法在准确性和计算效率上表现出色，并能灵活适应前向模型的变化。

> **摘要翻译:** 扩散模型（DMs）已成为贝叶斯计算成像中强大的图像先验。在该背景下，已提出了两种利用DMs的主要策略：即插即用方法，它们是零样本且高度灵活但依赖于近似；以及专门的条件DMs，它们通过监督训练为特定任务实现了更高的准确性和更快的推理。在这项工作中，我们引入了一种新颖的框架，该框架集成了深度展开和模型蒸馏，将DM图像先验转换为用于后验采样的少步条件模型。我们方法的核心创新是对马尔可夫链蒙特卡洛（MCMC）算法——特别是最近提出的LATINO Langevin采样器（Spagnoletti et al., 2025）——进行展开，这代表了首次将深度展开应用于蒙特卡洛采样方案。我们通过广泛的实验以及与最先进技术的比较，展示了我们提出的展开和蒸馏采样器，它们实现了出色的准确性和计算效率，同时保持了在推理时适应前向模型变化的灵活性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [APT: Adaptive Personalized Training for Diffusion Models with Limited Data](https://arxiv.org/abs/2507.02687)
> *APT: 针对有限数据的扩散模型的自适应个性化训练*

*JungWoo Chae, Jiyoon Kim, JaeWoong Choi, Kyungyul Kim, Sangheum Hwang* | **Category: cs.CV, cs.AI, 60J60, 68T07, I.2.6; I.2.10; I.4.9** | **Updated: {updated}**

**Keywords:** 扩散模型, 个性化训练, 有限数据, 过拟合, 自适应训练

**Comment:** CVPR 2025 camera ready. Project page: https://lgcnsai.github.io/apt

> **TL;DR:** APT是一种新颖的框架，通过自适应训练策略和内部表示正则化，有效缓解了在有限数据下个性化扩散模型时出现的过拟合、先验知识丢失和文本对齐退化等问题。

**AI_Comments:** APT框架通过其独特的三大组件，特别是引入过拟合指示器进行自适应调整，以及对内部表示和注意力图的正则化，为有限数据下的扩散模型个性化提供了一种创新且全面的解决方案，有效解决了过拟合和先验知识丢失等核心难题，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 在有限数据下个性化扩散模型面临显著挑战，包括过拟合、先验知识丢失和文本对齐退化。过拟合会导致噪声预测分布偏移，破坏去噪轨迹并使模型失去语义连贯性。

**Method:** 本文提出了一种名为自适应个性化训练（APT）的新颖框架，通过采用自适应训练策略和正则化模型内部表示来缓解过拟合。APT包含三个关键组件：(1) 自适应训练调整：引入过拟合指示器，检测每个时间步箱的过拟合程度，并基于此应用自适应数据增强和自适应损失加权；(2) 表示稳定化：正则化中间特征图的均值和方差，以防止噪声预测的过度偏移；(3) 注意力对齐以保留先验知识：对齐微调模型与预训练模型的交叉注意力图，以保持先验知识和语义连贯性。

**Result:** 实验表明，APT有效缓解了过拟合，保留了先验知识，并且在生成高质量、多样化的图像方面优于现有方法，尤其是在有限参考数据的情况下。

**Conclusion:** APT框架能够有效解决有限数据下扩散模型个性化训练中的挑战，生成高质量且多样化的图像。

> **ai_Abstract:** 本文提出了APT（自适应个性化训练）框架，旨在解决使用有限数据个性化扩散模型时面临的过拟合、先验知识丢失和文本对齐退化等问题。APT通过自适应训练调整、表示稳定化和注意力对齐来缓解这些挑战。实验证明，APT在有限数据条件下能够有效生成高质量、多样化的图像，并优于现有方法。

> **摘要翻译:** 使用有限数据个性化扩散模型带来了显著挑战，包括过拟合、先验知识丢失和文本对齐退化。过拟合导致噪声预测分布的偏移，扰乱去噪轨迹并导致模型失去语义连贯性。在本文中，我们提出了自适应个性化训练（APT），这是一个新颖的框架，通过采用自适应训练策略和在微调过程中正则化模型的内部表示来缓解过拟合。APT由三个关键组件组成：(1) 自适应训练调整，它引入了一个过拟合指示器来检测每个时间步箱的过拟合程度，并根据此指示器应用自适应数据增强和自适应损失加权；(2) 表示稳定化，它正则化中间特征图的均值和方差，以防止噪声预测的过度偏移；以及 (3) 注意力对齐以保留先验知识，它对齐微调模型与预训练模型的交叉注意力图，以保持先验知识和语义连贯性。通过广泛的实验，我们证明APT有效缓解了过拟合，保留了先验知识，并且在生成高质量、多样化的图像方面优于现有方法，尤其是在有限参考数据的情况下。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [400] [CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation](https://arxiv.org/abs/2507.02691)
> *CanonSwap：通过规范空间调制实现高保真和一致的视频换脸*

*Xiangyang Luo, Ye Zhu, Yunfei Liu, Lijian Lin, Cong Wan, Zijian Cai, Shao-Lun Huang, Yu Li* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 视频换脸, 规范空间, 身份转移, 时间一致性, 深度伪造

**Comment:** ICCV Accepted

> **TL;DR:** CanonSwap通过解耦视频中的外观和运动信息，实现了高保真和时间一致的视频换脸，解决了现有方法在保持动态属性方面的不足。

**AI_Comments:** CanonSwap的核心创新在于其解耦面部外观和运动信息的方法，这直接解决了视频换脸中长期存在的时序不一致性问题。通过引入规范空间进行身份修改，并结合部分身份调制模块，该方法在保持目标动态属性的同时，实现了高保真和低伪影的身份转移，对于推动视频换脸技术在真实感和一致性方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视频换脸现有方法主要关注高质量的身份转移，但往往无法很好地保持目标面部的动态属性（如头部姿态、面部表情、唇语同步等），导致结果不一致。研究人员将此问题归因于视频中面部外观和运动的固有耦合。

**Method:** 提出CanonSwap框架，解耦运动信息和外观信息。具体而言，CanonSwap首先消除运动相关信息，在统一的规范空间内进行身份修改。随后，将交换后的特征重新整合到原始视频空间，以确保保留目标面部的动态属性。为实现更精确的身份转移，引入了部分身份调制模块，利用空间掩码自适应集成源身份特征，将修改限制在面部区域。此外，还引入了多项细粒度同步指标来全面评估视频换脸方法的性能。

**Result:** 大量实验表明，CanonSwap在视觉质量、时间一致性和身份保留方面显著优于现有方法。

**Conclusion:** CanonSwap通过解耦面部外观和运动信息，有效解决了视频换脸中的关键挑战，实现了高保真和时间一致的视频换脸效果。

> **ai_Abstract:** CanonSwap是一种新颖的视频换脸框架，旨在解决现有方法在保持目标面部动态属性方面的不足，这些不足源于面部外观和运动的耦合。该方法通过在统一的规范空间中解耦运动和外观信息，实现高保真和时间一致的换脸。它首先消除运动信息以进行身份修改，然后将交换特征重新整合回原始视频空间以保留动态属性。此外，引入了部分身份调制模块以实现精确的身份转移，并设计了新的同步指标进行评估。实验证明，CanonSwap在视觉质量、时间一致性和身份保留方面均优于现有方法。

> **摘要翻译:** 视频换脸旨在解决两个主要挑战：有效地将源身份转移到目标视频，并准确保留目标面部的动态属性，如头部姿态、面部表情、唇语同步等。现有方法主要关注实现高质量的身份转移，但往往未能很好地保持目标面部的动态属性，导致结果不一致。我们将此问题归因于视频中面部外观和运动的固有耦合。为了解决这个问题，我们提出了CanonSwap，一个新颖的视频换脸框架，它将运动信息与外观信息解耦。具体而言，CanonSwap首先消除运动相关信息，从而能够在统一的规范空间内进行身份修改。随后，将交换后的特征重新整合到原始视频空间，确保保留目标面部的动态属性。为了进一步实现精确的身份转移，减少伪影并增强真实感，我们设计了一个部分身份调制模块，该模块使用空间掩码自适应地整合源身份特征，将修改限制在面部区域。此外，我们引入了多项细粒度同步指标来全面评估视频换脸方法的性能。大量实验表明，我们的方法在视觉质量、时间一致性和身份保留方面显著优于现有方法。我们的项目页面已在https://luoxyhappy.github.io/CanonSwap/公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [402] [SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment](https://arxiv.org/abs/2507.02705)
> *SIU3R：超越特征对齐的同步场景理解与三维重建*

*Qi Xu, Dongxu Wei, Lingzhe Zhao, Wenpu Li, Zhangchi Huang, Shunping Ji, Peidong Liu* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 同步场景理解, 三维重建, 无对齐框架, 像素对齐3D表示, 具身智能系统

**Comment:** 

> **TL;DR:** 提出SIU3R，一个无需特征对齐的框架，用于从无姿态图像中进行同步场景理解和三维重建，并实现最先进的性能。

**AI_Comments:** SIU3R的创新之处在于其“无对齐”范式，解决了传统2D到3D特征对齐带来的局限性，实现了更原生的3D理解。通过像素对齐的3D表示和统一查询机制，有效提升了同步理解和重建的性能，为端到端具身智能系统提供了新的方向。其引入的互利协作模块也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的同步理解与三维重建方法依赖2D到3D特征对齐范式，导致3D理解能力有限和潜在的语义信息丢失。

**Method:** 提出SIU3R，首个无需对齐的框架，用于从无姿态图像中进行通用同步理解和3D重建。它通过像素对齐的3D表示桥接重建与理解任务，并将多个理解任务统一为一组可学习查询，实现原生3D理解。为促进两任务协作，进一步分析了它们的互利性，并提出了两个轻量级模块来促进交互。

**Result:** 实验表明，所提方法在3D重建、3D理解以及同步理解与3D重建任务上均取得了最先进的性能。

**Conclusion:** SIU3R的无对齐框架和互利设计在同步场景理解与三维重建任务中具有显著优势，并能实现卓越性能。

> **ai_Abstract:** 本文提出SIU3R，一个创新的无对齐框架，用于从无姿态图像中进行同步场景理解和三维重建。与现有依赖2D到3D特征对齐的方法不同，SIU3R通过像素对齐的3D表示和统一的可学习查询实现原生3D理解，避免了语义信息损失。该框架还引入了促进重建与理解任务协作的模块。实验证明，SIU3R在各项任务中均达到最先进水平。

> **摘要翻译:** 同步理解和三维重建在开发端到端具身智能系统中扮演着重要角色。为了实现这一点，最近的方法诉诸于2D到3D特征对齐范式，这导致了有限的3D理解能力和潜在的语义信息丢失。有鉴于此，我们提出了SIU3R，这是首个用于从无姿态图像中进行通用同步理解和三维重建的无对齐框架。具体来说，SIU3R通过像素对齐的3D表示桥接重建和理解任务，并将多个理解任务统一为一组统一的可学习查询，从而无需与2D模型对齐即可实现原生3D理解。为了鼓励具有共享表示的两个任务之间的协作，我们进一步深入分析了它们的互利性，并提出了两个轻量级模块来促进它们的交互。大量的实验表明，我们的方法不仅在3D重建和理解的独立任务上，而且在同步理解和3D重建任务上都取得了最先进的性能，这凸显了我们无对齐框架的优势和互利设计的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [403] [UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation](https://arxiv.org/abs/2507.02713)
> *UniMC：驯服扩散Transformer用于统一关键点引导的多类别图像生成*

*Qin Guo, Ailing Zeng, Dongxu Yue, Ceyuan Yang, Yang Cao, Hanzhong Guo, Fei Shen, Wei Liu, Xihui Liu, Dan Xu* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 关键点引导图像生成, 多类别图像生成, 扩散Transformer, UniMC, HAIG-2.9M数据集

**Comment:** 

> **TL;DR:** UniMC是一个基于DiT的框架，结合了实例和关键点级条件，用于统一的多类别图像生成。同时，提出了HAIG-2.9M大型数据集，用于关键点引导的人类和动物图像生成，解决了现有模型在处理非刚性物体和多重重叠实例时的挑战。

**AI_Comments:** 该论文的创新点在于提出了一个统一的框架UniMC，能够处理多类别（包括非刚性物体如动物）和多实例的关键点引导图像生成，这超越了现有模型主要针对人类的局限性。同时，构建并公开了一个大规模、高质量的HAIG-2.9M数据集，这对于推动关键点引导的多类别图像生成领域的研究具有重要意义。该工作有效地解决了现有方法在实例区分和数据集稀缺性方面的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管关键点引导的文本到图像扩散模型取得了显著进展，但现有主流模型在控制生成人类以外的更一般非刚性物体（如动物）时遇到挑战。此外，仅基于关键点控制难以生成多个重叠的人类和动物。这些挑战源于现有可控方法的固有局限性以及缺乏合适的训练数据集。

**Method:** 首先，设计了一个名为UniMC的DiT（Diffusion Transformer）框架，旨在探索统一的可控多类别图像生成。UniMC将实例级和关键点级条件整合为紧凑的token，包含类别、边界框和关键点坐标等属性，从而克服了以往依赖骨架图像作为条件而难以区分实例和类别的局限性。其次，提出了HAIG-2.9M，一个大规模、高质量、多样化的关键点引导人类和动物图像生成数据集。HAIG-2.9M包含786K张图像和2.9M个实例，具有关键点、边界框和细粒度描述等丰富的标注，并经过严格的人工检查以确保标注准确性。

**Result:** 实验结果表明HAIG-2.9M数据集具有高品质，并且UniMC框架在处理重度遮挡和多类别场景中表现出有效性。

**Conclusion:** 通过提出UniMC框架和HAIG-2.9M数据集，本研究成功解决了现有关键点引导扩散模型在生成非刚性多类别物体以及处理重叠实例方面的挑战，并展示了其在复杂场景下的优越性能。

> **ai_Abstract:** 本研究旨在解决现有关键点引导扩散模型在生成非刚性多类别图像（如动物）以及处理多重重叠实例时的挑战。为此，作者提出了两个主要贡献：一是UniMC框架，一个基于DiT的统一可控多类别图像生成模型，它通过将实例级和关键点级条件整合为紧凑的token来克服现有方法的局限性；二是HAIG-2.9M数据集，一个大规模、高质量、多样化的关键点引导人类和动物图像生成数据集，包含丰富的标注和严格的质量控制。实验证明了UniMC在重度遮挡和多类别场景下的有效性以及HAIG-2.9M的数据质量。

> **摘要翻译:** 尽管关键点引导的文本到图像扩散模型取得了显著进展，但现有主流关键点引导模型在控制生成人类以外的更一般非刚性物体（如动物）时遇到挑战。此外，仅基于关键点控制难以生成多个重叠的人类和动物。这些挑战源于两个主要方面：现有可控方法的固有局限性以及缺乏合适的数据集。首先，我们设计了一个名为UniMC的基于DiT的框架，旨在探索统一的可控多类别图像生成。UniMC将实例级和关键点级条件整合为紧凑的token，包含类别、边界框和关键点坐标等属性。这种方法克服了以往方法因依赖骨架图像作为条件而难以区分实例和类别的局限性。其次，我们提出了HAIG-2.9M，一个大规模、高质量、多样化的关键点引导人类和动物图像生成数据集。HAIG-2.9M包含786K张图像和2.9M个实例。该数据集具有关键点、边界框和人类与动物的细粒度描述等丰富的标注，并经过严格的人工检查以确保标注准确性。大量实验证明了HAIG-2.9M的高质量以及UniMC的有效性，尤其是在重度遮挡和多类别场景中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models](https://arxiv.org/abs/2507.02714)
> *FairHuman：在扩散模型中以最小潜在延迟公平性提升人体图像生成中的手部和面部质量*

*Yuxuan Wang, Tianwei Cao, Huayu Zhang, Zhongjiang He, Kongming Liang, Zhanyu Ma* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 扩散模型, 人体图像生成, 手部质量, 面部质量, 多目标优化, 最小潜在延迟

**Comment:** ICCV 2025

> **TL;DR:** FairHuman是一种多目标微调方法，利用最小潜在延迟（MPD）公平性优化，显著提升了扩散模型生成人体图像中手部和面部的质量，同时保持了整体图像质量。

**AI_Comments:** FairHuman的创新点在于引入了多目标微调框架，特别是结合了全局和局部（手部、面部）监督，并巧妙地运用了最小潜在延迟（MPD）准则来实现公平性优化。这对于提高扩散模型生成人体图像的真实感，特别是细节部分的质量具有重要意义。该方法有望解决当前图像生成模型在处理复杂局部特征时的常见缺陷。

<details>
  <summary>Details</summary>

**Motivation:** 当前大规模文本到图像扩散模型在生成人体图像时，由于局部区域（如面部和手部）监督不足，导致细节生成存在挑战。

**Method:** 提出FairHuman，一种多目标微调方法。该方法构建了三个学习目标：一个全局目标（基于默认扩散目标函数）和两个局部目标（基于预标注位置先验的手部和面部）。随后，在最小潜在延迟（MPD）准则指导下推导出最优参数更新策略，实现公平感知优化。

**Result:** 所提出的方法在生成具有挑战性的局部细节（手部和面部）方面取得了显著改进，同时保持了整体图像质量。广泛的实验证明了该方法在不同场景下改进人体图像生成性能的有效性。

**Conclusion:** FairHuman有效解决了扩散模型生成人体图像中手部和面部细节质量不足的问题，并在不同场景下展示了其有效性。

> **ai_Abstract:** 本研究提出FairHuman，一种针对扩散模型的多目标微调方法，旨在解决人体图像生成中手部和面部细节不足的问题。该方法结合了全局和基于位置先验的局部学习目标，并利用最小潜在延迟（MPD）准则进行公平性优化，从而显著提升了局部细节的生成质量，同时保持了整体图像质量。

> **摘要翻译:** 图像生成随着大规模文本到图像模型，特别是基于扩散的模型的开发，取得了显著进展。然而，由于训练期间局部区域的监督不足，生成具有合理细节（如面部或手部）的人体图像仍然具有挑战性。为了解决这个问题，我们提出了FairHuman，一种多目标微调方法，旨在公平地提升全局和局部生成质量。具体来说，我们首先构建了三个学习目标：一个源自默认扩散目标函数的全局目标，以及两个基于预标注位置先验的手部和面部局部目标。随后，我们在最小潜在延迟（MPD）准则的指导下推导出最优参数更新策略，从而实现该多目标问题的公平感知优化。基于此，我们提出的方法在生成具有挑战性的局部细节方面取得了显著改进，同时保持了整体质量。广泛的实验展示了我们方法在不同场景下改进人体图像生成性能的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [Prompt learning with bounding box constraints for medical image segmentation](https://arxiv.org/abs/2507.02743)
> *基于边界框约束的医学图像分割提示学习*

*Mélanie Gaillochet, Mehrdad Noori, Sahar Dastani, Christian Desrosiers, Hervé Lombaert* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 提示学习, 边界框, 医学图像分割, 弱监督, 基础模型

**Comment:** Accepted to IEEE Transactions on Biomedical Engineering (TMBE), 14
  pages

> **TL;DR:** 医学图像分割的像素级标注费时费力。本文提出了一种新颖的提示学习框架，仅使用边界框标注与视觉基础模型结合，实现了在弱监督条件下的SOTA性能。

**AI_Comments:** 该论文的创新之处在于将通常需要完整掩码的提示学习方法，成功应用于仅使用边界框的弱监督设置，这极大地减轻了医学图像标注的负担，在医学影像领域具有重要意义。将边界框约束与伪标签结合进行优化的方法是其关键的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在医学领域，像素级标注获取费力且成本高昂。为了减轻这一负担，基于边界框标注的弱监督方法提供了一种实用的替代方案。然而，现有的提示学习方法依赖于完全标注的分割掩码。

**Method:** 本文提出了一种新颖的框架，将基础模型的表示能力与弱监督分割的标注效率相结合。具体来说，该方法仅使用边界框标注来自动化基础模型的提示生成。所提出的优化方案将来自边界框标注的多个约束与由提示基础模型生成的伪标签相结合。

**Result:** 在多模态数据集上的大量实验表明，该弱监督方法在有限数据设置下实现了84.90%的平均Dice分数，优于现有的全监督和弱监督方法。

**Conclusion:** 所提出的弱监督提示学习方法有效地利用边界框标注进行医学图像分割，与现有方法相比取得了卓越的性能，从而减轻了标注负担。

> **ai_Abstract:** 本文提出了一种用于医学图像分割的新型弱监督提示学习框架。为解决像素级标注成本高昂的问题，该框架利用视觉基础模型，仅通过易于获取的边界框标注来自动化提示生成。其方法通过优化方案，将边界框派生的约束与来自基础模型的伪标签相结合。实验结果表明，该方法在多模态数据集上取得了84.90%的平均Dice分数，优于现有的全监督和弱监督方法，为高效的医学图像分割提供了一个实用解决方案。

> **摘要翻译:** 像素级标注在医学领域是出了名的费力且成本高昂。为了减轻这一负担，基于边界框标注（更容易获取）的弱监督方法提供了一种实用的替代方案。视觉基础模型最近在提供点或边界框等提示时，显示出显著的分割性能。提示学习通过使这些模型适应下游任务并自动化分割来利用它们，从而减少用户干预。然而，现有的提示学习方法依赖于完全标注的分割掩码。本文提出了一种新颖的框架，将基础模型的表示能力与弱监督分割的标注效率相结合。更具体地说，我们的方法仅使用边界框标注来自动化基础模型的提示生成。我们提出的优化方案将来自边界框标注的多个约束与由提示基础模型生成的伪标签相结合。在多模态数据集上的大量实验表明，我们的弱监督方法在有限数据设置下实现了84.90%的平均Dice分数，优于现有的全监督和弱监督方法。代码可在 https://github.com/Minimel/box-prompt-learning-VFM.git 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [409] [Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics](https://arxiv.org/abs/2507.02748)
> *具有全局上下文的线性注意力：一种用于视觉和物理的多极注意力机制*

*Alex Colagrande, Paul Caillon, Eva Feillet, Alexandre Allauzen* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 线性注意力, 多极注意力, Transformer, 全局上下文, 物理模拟

**Comment:** Accepted at ECLR Workshop at ICCV 2025

> **TL;DR:** 本文提出MANO，一种受n体模拟启发的新型注意力机制，旨在解决标准Transformer的二次复杂度问题，实现线性时间和内存复杂度，并在图像分类和物理模拟任务上表现出与SOTA模型相当的性能，同时显著降低资源消耗。

**AI_Comments:** 该论文的创新之处在于将$n$-体模拟技术应用于注意力机制，从而实现了线性的复杂度和全局上下文，这对于将Transformer扩展到视觉和物理领域的高分辨率数据至关重要，解决了其一个主要的实际限制。

<details>
  <summary>Details</summary>

**Motivation:** 标准Transformer的二次复杂度使其在处理高分辨率输入时变得不切实际，且现有解决方案如分块或下采样常导致精细尺度细节的丢失。

**Method:** 受$n$-体数值模拟启发，将注意力视为网格点之间的相互作用问题，并引入多极注意力神经算子（MANO）。MANO以基于距离的多尺度方式计算注意力，每个注意力头都保持全局感受野，并实现相对于网格点数量的线性时间和内存复杂度。

**Result:** 在图像分类和Darcy流任务上，MANO的性能与ViT和Swin Transformer等最先进模型相媲美，同时将运行时和峰值内存使用量降低了几个数量级。

**Conclusion:** MANO为视觉和物理领域的高分辨率输入提供了一种高效且有效的Transformer替代方案，成功解决了二次复杂度问题，且不牺牲精细尺度细节或全局上下文。

> **ai_Abstract:** 本文提出多极注意力神经算子（MANO），一种受$n$-体模拟启发的新型注意力机制，旨在解决标准Transformer处理高分辨率输入时的二次复杂度问题。MANO通过基于距离的多尺度方式计算注意力，保持全局感受野，并实现了线性的时间和内存复杂度。实验结果表明，MANO在图像分类和Darcy流任务上的性能可与ViT和Swin Transformer等先进模型媲美，同时显著降低了计算资源消耗。

> **摘要翻译:** Transformer 已成为从图像分类到物理模拟等各种任务的实际标准。尽管它们的性能令人印象深刻，但标准 Transformer 在内存和时间上相对于输入长度的二次复杂度使其无法处理高分辨率输入。因此，已经提出了几种变体，其中最成功的依赖于分块、下采样或粗化技术，但这通常以牺牲最精细尺度的细节为代价。在这项工作中，我们采取了一种不同的方法。受 $n$-体数值模拟中最新技术的启发，我们将注意力视为网格点之间的相互作用问题。我们引入了多极注意力神经算子 (MANO)，它以基于距离的多尺度方式计算注意力。MANO 在每个注意力头中保持全局感受野，并实现相对于网格点数量的线性时间和内存复杂度。在图像分类和 Darcy 流上的实证结果表明，MANO 与 ViT 和 Swin Transformer 等最先进的模型相媲美，同时将运行时和峰值内存使用量降低了几个数量级。我们已开源代码以供复现，地址为 https://github.com/AlexColagrande/MANO。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [411] [Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2507.02751)
> *部分弱监督定向目标检测*

*Mingxin Liu, Peiyuan Zhang, Yuan Liu, Wei Zhang, Yue Zhou, Ning Liao, Ziyang Gong, Junwei Luo, Zhirui Wang, Yi Yu, Xue Yang* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 定向目标检测, 弱监督学习, 部分标注, 低成本标注, 伪标签

**Comment:** 10 pages, 5 figures, 4 tables, source code:
  https://github.com/VisionXLab/PWOOD

> **TL;DR:** 提出了一种名为PWOOD的部分弱监督定向目标检测框架，它利用部分弱标注（如水平框或单点）和大量未标注数据，显著优于传统的弱监督算法，并降低了标注成本，性能可与半监督算法媲美。

**AI_Comments:** 该论文的创新点在于首次提出了部分弱监督定向目标检测（PWOOD）框架，有效结合了弱监督和半监督的优点，显著降低了标注成本，同时保持了高检测性能。它通过利用部分弱标注和未标注数据，为高成本的OOD标注问题提供了一个实用且高效的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 定向目标检测（OOD）的数据集标注成本高昂，现有算法（全监督、半监督、弱监督）在标注速度或成本方面仍存在问题。

**Method:** 本文提出了首个部分弱监督定向目标检测（PWOOD）框架。该框架基于部分弱标注（水平框或单点），并能有效利用大量未标注数据。具体方法包括：1) 定向和尺度感知学生模型（OS-Student），仅用少量方向无关或尺度无关的弱标注即可学习方向和尺度信息；2) 类别无关伪标签过滤策略（CPF），以降低模型对静态过滤阈值的敏感性。

**Result:** 在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的综合实验表明，PWOOD框架的性能与传统半监督算法相当，甚至超越它们。

**Conclusion:** PWOOD框架通过利用部分弱标注和未标注数据，有效地降低了定向目标检测的标注成本，同时保持了与半监督算法相当甚至更优的性能，为解决高昂的标注成本问题提供了一个有前景的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的部分弱监督定向目标检测（PWOOD）框架，旨在解决高昂的数据集标注成本问题。PWOOD框架利用部分弱标注（如水平框或单点）和大量未标注数据，显著提升了弱监督算法的性能，并降低了成本。该框架包含定向和尺度感知学生模型（OS-Student）和类别无关伪标签过滤策略（CPF）。实验证明，PWOOD在多个标准数据集上的性能可与半监督算法媲美甚至超越。

> **摘要翻译:** 定向目标检测（OOD）在各个领域日益增长的需求推动了该领域的重大研究。然而，数据集标注的高成本仍然是一个主要问题。当前主流的OOD算法主要分为三类：(1) 使用完整定向边界框（OBB）标注的全监督方法，(2) 使用部分OBB标注的半监督方法，以及 (3) 使用水平框或点等弱标注的弱监督方法。然而，这些算法不可避免地增加了模型的标注速度或标注成本。为了解决这个问题，我们提出了：(1) 首个基于部分弱标注（水平框或单点）的部分弱监督定向目标检测（PWOOD）框架，该框架可以有效地利用大量未标注数据，显著优于使用部分弱标注训练的弱监督算法，并且提供了更低的成本解决方案；(2) 定向和尺度感知学生（OS-Student）模型，能够仅用少量方向无关或尺度无关的弱标注学习方向和尺度信息；以及 (3) 类别无关伪标签过滤策略（CPF），以降低模型对静态过滤阈值的敏感性。在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的综合实验表明，我们的PWOOD框架性能与传统半监督算法相当，甚至超越它们。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation](https://arxiv.org/abs/2507.02792)
> *RichControl：结构和外观丰富的免训练文本到图像生成空间控制*

*Liheng Zhang, Lexi Pang, Hang Ye, Xiaoxuan Ma, Yizhou Wang* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 文本到图像生成, 空间控制, 特征注入, 免训练, 扩散模型

**Comment:** 

> **TL;DR:** 本文提出了RichControl，一个免训练的文本到图像生成空间控制框架，通过解耦特征注入和去噪过程，实现了结构和外观兼具的高质量图像生成，解决了现有方法在结构对齐和视觉伪影方面的问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个解耦特征注入时间步与去噪过程的灵活框架，有效解决了现有训练-free特征注入方法在结构对齐和视觉伪影上的痛点。其“结构丰富注入模块”、“外观丰富提示”和“重启细化策略”的设计，使得在不进行模型微调的情况下，实现了高质量、高保真度的空间控制生成，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像扩散模型中的特征注入方法在引入条件图像进行空间控制时，常面临结构不对齐、条件泄漏和视觉伪影等问题，尤其当条件图像与自然RGB分布差异大时。这是因为同步注入条件特征未能平衡去噪过程中的域对齐和结构保持。

**Method:** 本文提出了RichControl框架，通过解耦特征注入时间步与去噪过程，核心是一个结构丰富的注入模块，使其能更好地适应扩散步骤中对齐与结构保持之间的演变相互作用。此外，引入了外观丰富的提示和重启细化策略，以进一步增强外观控制和视觉质量。

**Result:** 我们的方法在各种零样本条件场景下均实现了最先进的性能。

**Conclusion:** RichControl通过创新的特征注入框架，成功实现了结构和外观兼备的免训练文本到图像生成，有效解决了现有方法的局限性，并达到了领先水平。

> **ai_Abstract:** 本文提出了RichControl，一个用于文本到图像生成的免训练空间控制框架。针对现有特征注入方法在结构对齐、条件泄漏和视觉伪影方面的缺陷，RichControl通过解耦特征注入时间步与去噪过程，并引入结构丰富的注入模块，有效平衡了域对齐和结构保持。结合外观丰富的提示和重启细化策略，该方法能够生成结构和外观兼备的高质量图像，并在多种零样本条件下达到最先进水平。

> **摘要翻译:** 文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面取得了显著成功。最近的努力扩展了这些模型，以整合条件图像（例如，深度或姿态图）以实现精细的空间控制。其中，特征注入方法作为传统微调方法的免训练替代方案而出现。然而，它们常常遭受结构不对齐、条件泄漏和视觉伪影的困扰，特别是当条件图像与自然RGB分布显著偏离时。通过重新审视现有方法，我们发现了一个核心局限性：条件特征的同步注入未能兼顾去噪过程中域对齐和结构保持之间的权衡。受此观察启发，我们提出了一种灵活的特征注入框架，将注入时间步与去噪过程解耦。其核心是一个结构丰富的注入模块，它使模型能够更好地适应扩散步骤中对齐与结构保持之间不断演变的关系，从而产生更忠实的结构生成。此外，我们引入了外观丰富的提示和重启细化策略，以进一步增强外观控制和视觉质量。总而言之，这些设计使得免训练生成既结构丰富又外观丰富。广泛的实验表明，我们的方法在各种零样本条件场景下均取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [No time to train! Training-Free Reference-Based Instance Segmentation](https://arxiv.org/abs/2507.02798)
> *没时间训练！免训练的基于参考的实例分割*

*Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 实例分割, 免训练, 基于参考, 基础模型, 少样本分割

**Comment:** Preprint

> **TL;DR:** 本文提出一种免训练的实例分割方法，通过利用基础模型学习到的语义先验知识，仅需少量参考图像即可自动生成实例级分割掩码，并在多个少样本分割基准上取得了最先进的性能。

**AI_Comments:** 本文提出了一种创新的免训练实例分割方法，通过巧妙地利用基础模型的语义先验知识和少量参考图像，有效克服了传统分割方法对大量标注数据的依赖，并进一步简化了SAM所需的复杂提示过程。其多阶段的匹配机制设计精巧，在保持高性能的同时，极大地降低了训练成本和部署复杂性，为少样本和跨领域实例分割提供了极具前景的解决方案。这项工作对于推动实用化、低资源消耗的图像分割技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统图像分割模型受限于大规模标注数据的高昂成本。尽管SAM缓解了这一问题，但仍需要手动视觉提示或复杂的领域相关提示生成规则。为了减轻这一新负担，本文研究在仅提供少量参考图像的情况下进行目标分割的任务。

**Method:** 该方法利用基础模型学习到的强大语义先验来识别参考图像和目标图像之间的对应区域，从而自动生成实例级分割掩码。具体通过一个多阶段、免训练的方法实现，包括：1) 内存库构建；2) 表示聚合；3) 语义感知特征匹配。

**Result:** 实验结果表明，该方法在分割指标上取得了显著提升，在COCO FSOD上达到了36.8% nAP，在PASCAL VOC Few-Shot上达到了71.2% nAP50，并且在Cross-Domain FSOD基准上超越了现有免训练方法（22.4% nAP），达到了最先进的性能。

**Conclusion:** 本文提出的免训练、基于参考的实例分割方法，通过有效利用基础模型的语义先验知识，显著降低了对标注数据和手动提示的需求，并在多个少样本分割任务中展现出卓越的性能，达到了最先进水平，证明了其在实际应用中的巨大潜力。

> **ai_Abstract:** 本文提出了一种免训练的基于参考的实例分割方法，旨在解决传统分割模型对大量标注数据的依赖以及SAM仍需手动提示的问题。该方法的核心思想是利用基础模型学习到的强大语义先验知识，识别参考图像与目标图像间的对应区域，从而自动生成实例级分割掩码。具体实现包括内存库构建、表示聚合和语义感知特征匹配三个阶段。实验结果表明，该方法在COCO FSOD、PASCAL VOC Few-Shot和Cross-Domain FSOD等少样本分割基准上取得了显著性能提升，达到了最先进水平，超越了现有免训练方法。

> **摘要翻译:** 图像分割模型的性能历来受到收集大规模标注数据高成本的限制。Segment Anything Model (SAM) 通过可提示、语义无关的分割范式缓解了这一最初问题，但仍然需要手动视觉提示或复杂的领域相关提示生成规则来处理新图像。为了减轻这一新负担，我们的工作研究了在仅提供少量参考图像的情况下进行目标分割的任务。我们的关键洞察是利用基础模型学习到的强大语义先验知识，来识别参考图像和目标图像之间的对应区域。我们发现对应关系能够为下游任务自动生成实例级分割掩码，并通过一个多阶段、免训练的方法实例化了我们的想法，该方法包括 (1) 内存库构建；(2) 表示聚合；以及 (3) 语义感知特征匹配。我们的实验结果显示分割指标显著提升，在COCO FSOD上达到了36.8% nAP的最先进性能，在PASCAL VOC Few-Shot上达到了71.2% nAP50，并在Cross-Domain FSOD基准上超越了现有免训练方法（22.4% nAP）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [416] [LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion](https://arxiv.org/abs/2507.02813)
> *LangScene-X：利用TriMap视频扩散重建可泛化的3D语言嵌入场景*

*Fangfu Liu, Hao Li, Jiawei Chi, Hanyang Wang, Minghui Yang, Fudong Wang, Yueqi Duan* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 3D重建, 语言嵌入场景, 扩散模型, 泛化, 稀疏视图

**Comment:** Project page: https://liuff19.github.io/LangScene-X

> **TL;DR:** LangScene-X是一个生成式框架，利用TriMap视频扩散模型和语言量化压缩器，从稀疏视图重建可泛化的3D语言嵌入场景，并支持开放式语言查询。

**AI_Comments:** 该论文的创新点在于提出了一个生成式框架LangScene-X，通过结合TriMap视频扩散模型和语言量化压缩器，解决了从稀疏视图重建可泛化3D语言嵌入场景的挑战。这克服了传统方法对密集视图的依赖，显著提高了在视图有限情况下的重建质量和语义合成的合理性，具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通过逐场景优化实现带语言信息的3D结构恢复，但高度依赖密集视图重建，在视图有限时存在严重的渲染伪影和不合理的语义合成问题。

**Method:** 提出LangScene-X生成框架，统一并生成3D一致的多模态信息。该框架首先训练一个TriMap视频扩散模型，通过渐进式知识集成从稀疏输入生成外观、几何和语义。其次，提出语言量化压缩器（LQC）高效编码语言嵌入，实现跨场景泛化。最后，通过将语言信息对齐到3D场景表面来重建语言表面场。

**Result:** 在真实世界数据上的大量实验表明，LangScene-X在质量和泛化能力方面优于现有最先进的方法。

**Conclusion:** LangScene-X提供了一种从稀疏视图构建可泛化的3D语言嵌入场景的新方法，有效解决了现有方法的局限性，并在质量和泛化性上表现出优越性。

> **ai_Abstract:** LangScene-X是一个新颖的生成框架，旨在从稀疏视图重建可泛化的3D语言嵌入场景。它通过训练一个TriMap视频扩散模型来生成外观、几何和语义信息，并引入语言量化压缩器（LQC）实现高效的语言嵌入编码和跨场景泛化。该方法通过将语言信息对齐到3D表面来支持开放式语言查询。实验证明LangScene-X在质量和泛化能力上优于现有技术。

> **摘要翻译:** 从2D图像中恢复具有开放词汇场景理解的3D结构是一项基础但艰巨的任务。最近的发展通过对嵌入语言信息的逐场景优化实现了这一点。然而，它们严重依赖于校准的密集视图重建范式，因此在可用视图有限时会遭受严重的渲染伪影和不合理的语义合成。在本文中，我们引入了一种新颖的生成框架，命名为LangScene-X，用于统一和生成3D一致的多模态信息，以进行重建和理解。凭借创建更一致的新颖观测的生成能力，我们可以仅从稀疏视图构建可泛化的3D语言嵌入场景。具体来说，我们首先训练一个TriMap视频扩散模型，该模型可以通过渐进式知识集成从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。此外，我们提出了一种语言量化压缩器（LQC），在大规模图像数据集上训练，以高效编码语言嵌入，从而实现无需逐场景再训练的跨场景泛化。最后，我们通过将语言信息对齐到3D场景表面来重建语言表面场，从而实现开放式语言查询。在真实世界数据上的大量实验证明了我们的LangScene-X在质量和泛化能力方面优于现有最先进的方法。项目主页：https://liuff19.github.io/LangScene-X。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [418] [Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach](https://arxiv.org/abs/2507.02826)
> *多模态人体活动识别中置信度驱动的梯度调制：一种动态对比双路径学习方法*

*Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 多模态人体活动识别, 梯度调制, 对比学习, 双路径网络, 传感器数据

**Comment:** 

> **TL;DR:** 本文提出DCDP-HAR框架，通过双路径特征提取、多阶段对比学习和置信度驱动的梯度调制，有效解决多模态人体活动识别中的特征对齐和模态贡献不平衡问题。

**AI_Comments:** 该论文通过引入置信度驱动的梯度调制和多阶段对比学习，创新性地解决了多模态HAR中模态间融合的难题，特别是平衡模态贡献和实现有效特征对齐。双路径架构结合ResNet和DenseNet也体现了其在特征提取上的全面性。

<details>
  <summary>Details</summary>

**Motivation:** 解决多模态人体活动识别（HAR）系统中跨模态特征对齐困难和模态贡献不平衡的关键挑战。

**Method:** 提出动态对比双路径网络（DCDP-HAR），包含：1) 基于ResNet和DenseNet的双路径特征提取架构；2) 多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；3) 置信度驱动的梯度调制策略，动态调整各模态分支的学习强度并缓解模态竞争；4) 动量梯度累积策略，增强训练稳定性。

**Result:** 通过消融研究验证了每个组件的有效性，并在四个公共基准数据集上进行了广泛的比较实验。

**Conclusion:** 该研究提出的DCDP-HAR框架及其关键组件有效解决了多模态HAR中的特征对齐和模态贡献不平衡问题。

> **ai_Abstract:** 本文提出了一个名为DCDP-HAR的动态对比双路径网络框架，旨在解决多模态人体活动识别中跨模态特征对齐和模态贡献不平衡的问题。该框架结合了双路径特征提取、多阶段对比学习和置信度驱动的梯度调制，并通过动量梯度累积提升训练稳定性。实验结果验证了各组件的有效性。

> **摘要翻译:** 基于传感器的Huma n Activity Recognition (HAR) 是一项核心技术，它使智能系统能够感知环境并与环境交互。然而，多模态HAR系统仍然面临关键挑战，例如跨模态特征对齐困难和模态贡献不平衡。为了解决这些问题，我们提出了一种新颖的框架，称为动态对比双路径网络（DCDP-HAR）。该框架包含三个关键组件。首先，采用双路径特征提取架构，其中ResNet和DenseNet分支协同处理多模态传感器数据。其次，引入多阶段对比学习机制，以实现从局部感知到语义抽象的渐进对齐。第三，我们提出了一种置信度驱动的梯度调制策略，该策略在反向传播过程中动态监控和调整每个模态分支的学习强度，有效缓解模态竞争。此外，还采用了基于动量的梯度累积策略来增强训练稳定性。我们进行了消融研究以验证每个组件的有效性，并在四个公共基准数据集上进行了广泛的比较实验。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network](https://arxiv.org/abs/2507.02827)
> *USAD：一种无监督数据增强时空注意力扩散网络*

*Ying Yu, Hang Xiao, Siyao Li, Jiarui Li, Haotian Tang, Hanyu Liu, Chao Li* | **Category: cs.CV, cs.AI** | **Updated: {updated}**

**Keywords:** 人类活动识别, 无监督数据增强, 时空注意力, 扩散网络, 多分支网络

**Comment:** 

> **TL;DR:** 提出USAD模型，通过无监督数据增强和多注意力时空网络解决人类活动识别中数据稀缺和特征提取不足的问题，并在公共数据集上取得SOTA性能且适用于嵌入式设备。

**AI_Comments:** 该论文的创新点在于结合了无监督数据增强（通过扩散模型）与多注意力时空网络，有效解决了HAR领域中数据稀缺和特征提取的痛点。其多分支设计和注意力机制能够更全面地捕获时空特征，而自适应损失函数则进一步优化了模型。在嵌入式设备上的验证也突出了其潜在的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 人类活动识别（HAR）面临标记样本稀缺、高级特征提取不足以及轻量级设备上模型性能不佳等挑战。

**Method:** 1. 采用无监督、统计引导的扩散模型进行数据增强，以缓解标记数据稀缺和类别不平衡问题。2. 设计多分支时空交互网络，通过并行残差分支（3x3, 5x5, 7x7卷积核）捕获序列数据的多尺度特征。3. 引入时间注意力机制识别关键时间点，空间注意力增强传感器间交互。4. 引入跨分支特征融合单元，提升整体特征表示能力。5. 整合自适应多损失函数融合策略，动态调整损失权重并优化模型。

**Result:** 在WISDM、PAMAP2和OPPORTUNITY三个公共数据集上，USAD分别达到了98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了所提方法的效率和可行性。

**Conclusion:** 提出的USAD模型通过无监督数据增强和多注意力时空网络有效解决了人类活动识别中的关键挑战，并在性能和实际部署方面表现出色。

> **ai_Abstract:** 本文提出了USAD（无监督数据增强时空注意力扩散网络），旨在解决人类活动识别（HAR）中标记数据稀缺、特征提取不足和轻量级设备性能受限的问题。USAD通过无监督的统计引导扩散模型进行数据增强，并设计了一个包含多尺度卷积核的并行残差分支、时间与空间注意力机制以及跨分支特征融合单元的多分支时空交互网络。此外，还引入了自适应多损失函数融合策略进行模型优化。实验结果表明，USAD在多个公共数据集上取得了显著优于现有方法的性能，并被证明在嵌入式设备上高效可行。

> **摘要翻译:** 人类活动识别（HAR）的主要目标是从传感器数据中推断正在进行的人类动作，这项任务在健康监测、安全保护和运动分析中有着广泛的应用。尽管研究不断增加，HAR仍面临关键挑战，包括稀有活动标记样本的稀缺、高级特征提取不足以及轻量级设备上模型性能不佳。为了解决这些问题，本文提出了一种以多注意力交互机制为中心的综合优化方法。首先，采用无监督、统计引导的扩散模型进行数据增强，从而缓解标记数据稀缺和严重类别不平衡的问题。其次，设计了一种多分支时空交互网络，通过带有3*3、5*5和7*7卷积核的并行残差分支捕获序列数据的多尺度特征。同时，引入时间注意力机制以识别关键时间点，而空间注意力则增强了传感器间的交互。此外，还引入了一个跨分支特征融合单元，以提高整体特征表示能力。最后，整合了一种自适应多损失函数融合策略，允许动态调整损失权重和整体模型优化。在WISDM、PAMAP2和OPPORTUNITY三个公共数据集上的实验结果表明，所提出的无监督数据增强时空注意力扩散网络（USAD）分别取得了98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了所提方法的效率和可行性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [421] [AnyI2V: Animating Any Conditional Image with Motion Control](https://arxiv.org/abs/2507.02857)
> *AnyI2V：使用运动控制动画任意条件图像*

*Ziye Li, Hao Luo, Xincheng Shuai, Henghui Ding* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 视频生成, 图像到视频, 运动控制, 扩散模型, 训练无关

**Comment:** ICCV 2025, Project Page: https://henghuiding.com/AnyI2V/

> **TL;DR:** AnyI2V是一个无需训练的框架，可以根据用户定义的运动轨迹，将任意条件图像（包括网格和点云等）动画化，并支持混合输入、风格迁移和编辑。

**AI_Comments:** AnyI2V的创新点在于其“训练无关”的特性以及对“任意条件图像”的支持，特别是包含了ControlNet不支持的网格和点云等模态，极大地扩展了I2V的应用范围和灵活性。其对显式运动控制和混合输入的支持也提升了生成视频的可控性和多样性。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到视频（T2V）方法缺乏对生成内容空间布局的精确控制，而图像到视频（I2V）方法受限于对真实图像的依赖，限制了可编辑性。此外，结合ControlNet的方法通常缺乏显式运动控制且训练成本高昂。

**Method:** 提出AnyI2V，一个无需训练的框架，通过用户定义的运动轨迹动画化任意条件图像。AnyI2V支持更广泛的条件图像模态，包括ControlNet不支持的网格和点云等数据类型，并支持混合条件输入，通过LoRA和文本提示实现风格迁移和编辑。

**Result:** 广泛的实验表明，所提出的AnyI2V实现了卓越的性能，并在空间和运动控制的视频生成方面提供了新视角。

**Conclusion:** AnyI2V提供了一个训练无关、灵活且高效的解决方案，克服了现有视频生成方法在空间和运动控制方面的限制，显著提升了条件图像到视频生成的通用性和可控性。

> **ai_Abstract:** AnyI2V是一个无需训练的视频生成框架，旨在解决现有T2V和I2V方法在空间和运动控制方面的不足。它允许用户通过定义的运动轨迹动画化任意条件图像，支持多种模态（包括ControlNet不支持的网格和点云），并能处理混合输入、进行风格迁移和编辑。实验证明AnyI2V在空间和运动控制的视频生成上表现出色。

> **摘要翻译:** 视频生成领域的最新进展，特别是在扩散模型方面，推动了文本到视频（T2V）和图像到视频（I2V）合成的显著进展。然而，有效整合动态运动信号和灵活空间约束仍然存在挑战。现有的T2V方法通常依赖于文本提示，这本身就缺乏对生成内容空间布局的精确控制。相比之下，I2V方法受限于对真实图像的依赖，这限制了合成内容的可编辑性。尽管一些方法结合了ControlNet来引入基于图像的条件，但它们通常缺乏显式运动控制并且需要计算成本高昂的训练。为了解决这些限制，我们提出了AnyI2V，一个无需训练的框架，它可以使用用户定义的运动轨迹动画化任何条件图像。AnyI2V支持更广泛的模态作为条件图像，包括ControlNet不支持的数据类型，如网格和点云，从而实现更灵活和多功能的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现风格迁移和编辑。广泛的实验表明，所提出的AnyI2V实现了卓越的性能，并在空间和运动控制的视频生成方面提供了新视角。代码可在https://henghuiding.com/AnyI2V/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [422] [Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation](https://arxiv.org/abs/2507.02859)
> *多模态大型语言模型中自举接地式思维链以实现数据高效的模型适应*

*Jiaer Xia, Bingkui Tong, Yuhang Zang, Rui Shao, Kaiyang Zhou* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 多模态大型语言模型, 思维链, 接地式思维链, 数据高效, 模型适应

**Comment:** Accepted by ICCV2025

> **TL;DR:** 多模态大型语言模型（MLLM）在缺乏大规模数据集时难以适应专业视觉任务，因为预训练数据与下游数据不匹配。本文提出接地式思维链（GCoT），一种自举方法，通过向思维链数据注入边界框等接地信息，使其推理步骤更忠实于图像，从而在数据受限情况下显著提升MLLM在专业视觉任务上的适应能力。

**AI_Comments:** 该论文的创新点在于提出了接地式思维链（GCoT）方法，通过自举机制将图像的接地信息（如边界框）注入到思维链推理数据中，从而解决了传统思维链数据中存在的推理步骤事实性错误问题，并提高了多模态大型语言模型在数据有限情况下的专业视觉任务适应能力。其重要性体现在为LLM在特定领域（如图表、表格理解）的落地应用提供了数据高效的解决方案，尤其是在高质量标注数据稀缺的场景下。论文未明确提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLM）在不使用大规模数据集进行再训练的情况下，难以适应专业的视觉任务（如图表理解），原因是预训练数据集主要集中在场景和物体上，而包含专业非物体图像（如图表和表格）的信息有限。此外，从预训练MLLM中提取的思维链（CoT）数据在推理步骤中常包含事实性错误。

**Method:** 本文提出接地式思维链（GCoT），这是一种基于自举的简单方法，旨在将接地信息（即边界框）注入到思维链（CoT）数据中，从而使推理步骤更忠实于输入图像。

**Result:** 在涵盖图表、表格、收据和报告等多种视觉格式的五项专业视觉任务上进行了评估。结果表明，在数据受限的条件下，该方法显著优于微调和蒸馏。

**Conclusion:** 本文提出的接地式思维链（GCoT）方法通过注入接地信息，有效提高了思维链数据的保真度，从而在数据受限的情况下，显著提升了多模态大型语言模型对专业视觉任务的适应能力。

> **ai_Abstract:** 多模态大型语言模型（MLLM）在缺乏大规模数据集时难以适应图表理解等专业视觉任务，这源于预训练数据与专业非物体图像之间的不匹配，且从预训练MLLM中提取的思维链（CoT）数据常含事实性错误。本文提出接地式思维链（GCoT），一种自举方法，通过向CoT数据注入边界框等接地信息，使推理更忠实于图像。在多项专业视觉任务上的评估显示，GCoT在数据受限条件下显著优于传统微调和蒸馏方法。

> **摘要翻译:** 多模态大型语言模型（MLLM）在利用自然语言解释图像方面展现出卓越的能力。然而，在不使用大规模数据集进行再训练的情况下，这些模型难以适应专业的视觉任务，例如图表理解。这个问题是由于预训练和下游数据集之间的不匹配造成的：预训练数据集主要集中在场景和物体上，但包含的关于专业非物体图像（如图表和表格）的信息有限。在本文中，我们分享了一个有趣的发现，即使用思维链（CoT）推理数据训练MLLM可以促进模型在专业视觉任务中的适应，尤其是在数据有限的情况下。然而，我们发现从预训练MLLM中提取的CoT数据存在一个关键问题，即数据在推理步骤中经常包含多个事实性错误。为了解决这个问题，我们提出了接地式思维链（GCoT），这是一种简单的基于自举的方法，旨在将接地信息（即边界框）注入到CoT数据中，从而使推理步骤更忠实于输入图像。我们在五项专业视觉任务上评估了我们的方法，这些任务涵盖了图表、表格、收据和报告等多种视觉格式。结果表明，在数据受限的条件下，我们的方法显著优于微调和蒸馏。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching](https://arxiv.org/abs/2507.02860)
> *少即足够：通过运行时自适应缓存实现免训练视频扩散加速*

*Xin Zhou, Dingkang Liang, Kaijin Chen, Tianrui Feng, Xiwu Chen, Hongkai Lin, Yikang Ding, Feiyang Tan, Hengshuang Zhao, Xiang Bai* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 视频扩散, 加速, 缓存, 免训练, 运行时自适应

**Comment:** The code is made available at
  https://github.com/H-EmbodVis/EasyCache. Project page:
  https://h-embodvis.github.io/EasyCache/

> **TL;DR:** 视频生成模型因迭代去噪过程而缓慢且计算成本高昂。本文提出了EasyCache，一个免训练的视频扩散模型加速框架。它通过轻量级、运行时自适应的缓存机制动态重用计算过的变换向量，将推理时间缩短2.1-3.3倍，同时保持高视觉保真度，并比现有SOTA方法将PSNR提高高达36%。

**AI_Comments:** 本文的核心创新在于其“免训练”和“运行时自适应缓存”的方法，这显著简化了视频扩散模型的加速过程，避免了传统方法中复杂的离线分析和参数调优。这种实用性使得该方法具有很高的可访问性。其在不牺牲视觉质量的前提下实现显著推理速度提升（高达3.3倍）和PSNR改善（高达36%），对于推动视频生成技术在实际场景中的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视频生成模型由于去噪过程的迭代性质，面临推理速度慢和计算成本高昂的瓶颈，这限制了它们的广泛采用和在实际应用中的集成。解决这一瓶颈对于普及先进的视频合成技术至关重要。

**Method:** 本文提出了EasyCache，一个免训练的视频扩散模型加速框架。EasyCache引入了一种轻量级、运行时自适应的缓存机制，该机制在推理过程中动态重用先前计算的变换向量，从而避免了冗余计算。与现有方法不同，EasyCache无需离线分析、预计算或广泛的参数调优。

**Result:** EasyCache在各种大规模视频生成模型（包括OpenSora、Wan2.1和HunyuanVideo）上进行了全面研究。与原始基线相比，该方法将推理时间缩短了2.1-3.3倍，同时保持了高视觉保真度，并且与之前的SOTA方法相比，PSNR显著提高了高达36%。

**Conclusion:** EasyCache为高质量视频生成提供了一个高效且高度可用的解决方案，适用于研究和实际应用。

> **ai_Abstract:** EasyCache是一个创新的免训练框架，旨在加速视频扩散模型。它通过运行时自适应缓存机制动态重用已计算的变换向量，从而在推理过程中避免冗余计算。该方法无需传统加速方案所需的离线分析或参数调优，显著将推理时间缩短2.1-3.3倍，同时保持或提高视觉质量（PSNR提升高达36%），使得高质量视频生成在研究和实际应用中更高效和可及。

> **摘要翻译:** 视频生成模型展现了卓越的性能，但其广泛应用仍受限于缓慢的推理速度和高昂的计算成本，这主要归因于去噪过程的迭代性质。解决这一瓶颈对于普及先进的视频合成技术并使其融入实际应用至关重要。本文提出了EasyCache，一个用于视频扩散模型的免训练加速框架。EasyCache引入了一种轻量级、运行时自适应的缓存机制，该机制动态重用先前计算的变换向量，从而避免了推理过程中的冗余计算。与现有方法不同，EasyCache无需离线分析、预计算或广泛的参数调优。我们在各种大规模视频生成模型上进行了全面研究，包括OpenSora、Wan2.1和HunyuanVideo。我们的方法实现了领先的加速性能，与原始基线相比，推理时间缩短了2.1-3.3倍，同时保持了高视觉保真度，并且与之前的SOTA方法相比，PSNR显著提高了高达36%。这一改进使得我们的EasyCache成为研究和实际应用中高质量视频生成的高效且高度可用的解决方案。代码可在https://github.com/H-EmbodVis/EasyCache 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [424] [RefTok: Reference-Based Tokenization for Video Generation](https://arxiv.org/abs/2507.02862)
> *RefTok：基于参考的视频生成分词方法*

*Xiang Fan, Xiaohang Sun, Kushan Thakkar, Zhu Liu, Vimal Bhat, Ranjay Krishna, Xiang Hao* | **Category: cs.CV** | **Updated: {updated}**

**Keywords:** 视频生成, 分词, 时间冗余, 参考帧, 深度学习

**Comment:** 

> **TL;DR:** RefTok是一种新颖的基于参考的分词方法，通过利用未量化参考帧来有效处理视频中的时间冗余，显著优于现有SOTA分词器，并在视频生成任务中提升了性能。

**AI_Comments:** RefTok通过引入“基于参考”的 tokenization 策略，为视频生成领域处理时间冗余提供了一个新颖且高效的解决方案。其创新点在于利用未量化参考帧来条件化编码和解码，这有助于在保持高压缩率的同时，有效捕捉并保留视频中的精细时间细节和上下文信息。实验结果显示出显著的性能提升，尤其是在与现有SOTA模型进行比较时，其在图像质量和生成效果上的优势非常明显，甚至超越了参数量更大的模型，这表明了该方法在效率和效果上的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在学习视频模型时，有效处理时间冗余仍然是一个关键挑战。现有方法通常独立处理每组帧，未能有效捕获视频中固有的时间依赖性和冗余。

**Method:** 我们引入了RefTok，一种新颖的基于参考的分词方法。该方法以未量化参考帧为条件，对帧集进行编码和解码，以捕获复杂的时间动态和上下文信息。

**Result:** RefTok在解码时能保留运动的连续性和对象在帧间的外观，例如保留面部细节、正确重建文本、保留小图案和保持手写字迹的易读性。在K600、UCF-101、BAIR Robot Pushing和DAVIS四个视频数据集上，RefTok显著优于当前的SOTA分词器（Cosmos和MAGVIT），在相同或更高压缩比下，所有评估指标（PSNR、SSIM、LPIPS）平均提高了36.7%。当视频生成模型使用RefTok的潜在表示在BAIR Robot Pushing任务上进行训练时，其生成效果不仅优于MAGVIT-B，甚至比参数多4倍的MAGVIT-L在所有生成指标上平均提高了27.9%。

**Conclusion:** RefTok通过其创新的基于参考的分词方法，有效解决了视频模型中的时间冗余问题，并在视频分词和视频生成方面均取得了显著优于现有最先进方法的性能。

> **ai_Abstract:** RefTok提出了一种新颖的基于参考的视频分词方法，旨在解决视频模型中时间冗余处理的挑战。该方法通过以未量化参考帧为条件进行编码和解码，有效捕获视频的时间动态和上下文信息，从而在视频重建时保持运动连续性和对象外观细节。实验结果表明，RefTok在多个视频数据集上显著超越了现有的先进分词器，并在压缩比相同或更高的情况下，将PSNR、SSIM、LPIPS等评估指标平均提升了36.7%。此外，使用RefTok潜在表示训练的视频生成模型，在生成质量上也能显著优于参数量更大的现有模型。

> **摘要翻译:** 有效处理时间冗余仍然是学习视频模型的关键挑战。现有方法通常独立处理每组帧，未能有效捕获视频中固有的时间依赖性和冗余。为了解决这一限制，我们引入了RefTok，一种新颖的基于参考的分词方法，能够捕获复杂的时间动态和上下文信息。我们的方法以未量化参考帧为条件编码和解码帧集。解码时，RefTok保留了帧间运动的连续性和对象的外观。例如，RefTok即使在头部运动时也能保留面部细节，正确重建文本，保留小图案，并从上下文中保持手写字迹的易读性。在4个视频数据集（K600、UCF-101、BAIR Robot Pushing和DAVIS）上，RefTok显著优于当前的SOTA分词器（Cosmos和MAGVIT），在相同或更高压缩比下，所有评估指标（PSNR、SSIM、LPIPS）平均提高了36.7%。当视频生成模型使用RefTok的潜在表示在BAIR Robot Pushing任务上进行训练时，其生成效果不仅优于MAGVIT-B，甚至比参数多4倍的MAGVIT-L在所有生成指标上平均提高了27.9%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory](https://arxiv.org/abs/2507.02863)
> *Point3R: 基于显式空间指针记忆的流式三维重建*

*Yuqi Wu, Wenzhao Zheng, Jie Zhou, Jiwen Lu* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 三维重建, 流式, 显式记忆, Point3R, 计算机视觉

**Comment:** Code is available at: https://github.com/YkiWu/Point3R

> **TL;DR:** Point3R提出了一种在线流式三维重建框架，通过显式空间指针记忆解决了现有方法中隐式记忆容量有限和信息丢失的问题，实现了高性能且低训练成本。

**AI_Comments:** Point3R的创新点在于其引入的显式空间指针记忆，这直接解决了传统流式三维重建方法中隐式记忆的容量限制和信息丢失问题。通过将记忆与3D结构直接关联，并采用显式交互机制，该方法在保持效率的同时提升了重建的质量和稳定性，对于实时或流式3D重建应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于DUSt3R范式的方法在进行稠密三维重建时，采用的隐式记忆容量有限，且可能导致早期帧的信息丢失，这限制了计算机视觉研究在实际场景中的应用。

**Method:** 我们提出了Point3R，一个针对稠密流式三维重建的在线框架。该方法维护一个与当前场景三维结构直接相关的显式空间指针记忆。记忆中的每个指针都分配一个特定的三维位置，并在全局坐标系中聚合附近场景信息为变化的空间特征。最新帧提取的信息与此指针记忆显式交互，将当前观测值稠密集成到全局坐标系中。为了促进这种交互，我们设计了一个三维分层位置嵌入，并设计了一个简单而有效的融合机制，以确保指针记忆的均匀性和效率。

**Result:** 我们的方法在各种任务上实现了具有竞争力或最先进的性能，且训练成本较低。

**Conclusion:** Point3R通过引入显式空间指针记忆，有效解决了流式三维重建中信息丢失和记忆容量限制的问题，并在性能和效率上取得了显著提升，证明了其在实际应用中的潜力。

> **ai_Abstract:** Point3R是一个针对稠密流式三维重建的在线框架。它通过引入显式空间指针记忆来克服现有方法中隐式记忆容量有限和信息丢失的缺点。该记忆中的指针聚合空间信息，并与最新帧的数据显式交互，从而实现当前观测值在全局坐标系中的稠密集成。该方法还包含一个三维分层位置嵌入和有效的融合机制。Point3R在多种任务上表现出竞争力或最先进的性能，且训练成本较低。

> **摘要翻译:** 从有序序列或无序图像集合中进行稠密三维场景重建是计算机视觉研究进入实际应用场景的关键一步。遵循DUSt3R引入的范式，该范式将图像对稠密地统一到一个共享坐标系中，后续方法维护一个隐式记忆以实现从更多图像进行稠密三维重建。然而，这种隐式记忆容量有限，并且可能遭受早期帧的信息丢失。我们提出了Point3R，一个针对稠密流式三维重建的在线框架。具体来说，我们维护一个与当前场景三维结构直接相关的显式空间指针记忆。此记忆中的每个指针都被分配一个特定的三维位置，并在全局坐标系中聚合附近场景信息为一个变化的空间特征。从最新帧中提取的信息与此指针记忆显式交互，从而将当前观测值稠密集成到全局坐标系中。我们设计了一个三维分层位置嵌入来促进这种交互，并设计了一个简单而有效的融合机制，以确保我们的指针记忆是均匀和高效的。我们的方法在各种任务上实现了具有竞争力或最先进的性能，且训练成本较低。代码可在：https://github.com/YkiWu/Point3R 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [7] [StorySpace: Technology supporting reflection, expression, and discourse in classroom narrative](https://arxiv.org/abs/2507.02156)
> *StorySpace：支持课堂叙事中反思、表达和讨论的技术*

*Benjamin Watson, Janet Kim, Tim McEneany, Tom Moher, Claudia Hindo, Louis Gomez, Stephen Fransen* | **Category: cs.HC, cs.ET** | **Updated: {updated}**

**Keywords:** 课堂叙事, 新界面技术, 学生反思, 高中教育, 学习媒介

**Comment:** 

> **TL;DR:** StorySpace项目旨在通过新界面技术增强高中课堂叙事，以促进学生反思、解读和参与。

**AI_Comments:** 该论文描述了一个旨在通过新界面技术改进高中课堂叙事教学的项目。其创新点在于尝试利用技术来激发学生的深度思考、复杂性理解和学习兴趣。该项目的局限性在于抽象中没有提及具体的实施细节或初步效果评估。

<details>
  <summary>Details</summary>

**Motivation:** 该项目旨在研究新界面技术在高中教育中的作用，并具体设计StorySpace以支持和增强课堂叙事活动。

**Method:** StorySpace通过遵循三个设计目标来实现其目的：一是激发学生的反思和解读；二是StorySpace创建的叙事媒介应能呈现课堂讨论和学习主题的复杂性，让学生在构建表达时面对这种复杂性；三是媒介本身应引人入胜，使课堂叙事变得有趣和好玩。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** StorySpace项目旨在探索新界面技术在高中教育中的应用，特别专注于增强和支持课堂叙事活动。该系统通过设定三个设计目标来实现其目的：激发学生反思和解读，以复杂性呈现学习主题，并使叙事媒介本身具有吸引力，从而使课堂叙事更具趣味性和参与性。

> **摘要翻译:** StorySpace项目研究了新界面技术在高中教育中可能扮演的角色。基于这种方法，StorySpace专门设计用于支持和增强课堂叙事，这是一项已经成熟的课堂活动。StorySpace通过遵循三个设计目标来努力实现这一点。首先是激发学生的反思和解读。StorySpace创建的叙事媒介应以其全部复杂性来呈现课堂讨论和学习的主题。在构建他们的表达时，学生将面对同样的复杂性。该媒介本身也应该令人兴奋和引人入胜，使课堂叙事变得有趣和好玩。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [9] [PAL: Designing Conversational Agents as Scalable, Cooperative Patient Simulators for Palliative-Care Training](https://arxiv.org/abs/2507.02122)
> *PAL：设计对话代理作为可扩展、协作的患者模拟器用于姑息治疗培训*

*Neil K. R. Sehgal, Hita Kambhamettu, Allen Chang, Andrew Zhu, Lyle Ungar, Sharath Chandra Guntuku* | **Category: cs.HC, cs.CY** | **Updated: {updated}**

**Keywords:** 对话代理, 患者模拟器, 姑息治疗, 沟通培训, 大型语言模型

**Comment:** 

> **TL;DR:** PAL是一个对话系统，模拟姑息治疗中的患者互动，提供反馈，帮助医学生练习沟通技巧，并通过一项混合方法研究验证了其有效性，尽管存在情感真实性和反馈适应性方面的局限。

**AI_Comments:** 该论文的创新之处在于利用大型语言模型（LLMs）创建可扩展的对话式患者模拟器，以解决姑息治疗沟通培训资源不足的问题。其重要性在于提供了一种低成本、可重复的训练方法，有助于提升医护人员在敏感情境下的沟通技能。尽管存在情感真实性和反馈适应性的局限性，但该研究为AI辅助医疗培训，特别是在高风险和情感密集型领域，提供了重要的实证基础和设计启示。

<details>
  <summary>Details</summary>

**Motivation:** 姑息治疗中有效的沟通至关重要，但由于缺乏标准化患者等培训资源，通常教学不足。

**Method:** 研究者开发了PAL（Palliative Assisted Learning-bot），一个对话系统，模拟情感细致入微的患者互动，并根据现有的共情框架提供结构化反馈。PAL支持文本和语音模式，旨在通过重复、低成本的练习来构建临床技能。通过一项针对17名美国医学学员和临床医生的混合方法研究，探讨了用户对PAL的参与度，评估了可用性，并检查了围绕模式、情感真实性和反馈传递的设计张力。

**Result:** 参与者发现PAL有助于反思和技能提升，但一些人指出其在情感真实性和反馈适应性方面存在局限性。

**Conclusion:** 研究贡献包括：(1) 大型语言模型可以支持姑息沟通培训的实证证据；(2) 针对模式感知、情感敏感模拟工具的设计见解；(3) 对支持情感劳动、协作学习和高风险护理环境中AI增强培训系统的启示。

> **ai_Abstract:** 本研究提出了PAL（Palliative Assisted Learning-bot），一个基于大型语言模型的对话系统，旨在作为可扩展的患者模拟器，用于姑息治疗中的沟通技能培训。PAL通过模拟情感细致的患者互动并提供结构化反馈，支持医学生进行低成本、重复的练习。一项针对17名医学学员和临床医生的混合方法研究显示，PAL有助于技能提升和反思，但也存在情感真实性和反馈适应性的局限。研究证实了LLMs在姑息沟通培训中的潜力，并提供了设计情感敏感模拟工具的见解。

> **摘要翻译:** 在重症和姑息治疗中，有效的沟通至关重要，但由于标准化患者等培训资源有限，往往教学不足。我们提出了PAL（Palliative Assisted Learning-bot），一个对话系统，它模拟情感细致入微的患者互动，并提供基于现有共情框架的结构化反馈。PAL支持文本和语音模式，旨在通过重复、低成本的练习来构建临床技能。通过一项针对17名美国医学学员和临床医生的混合方法研究，我们探讨了用户对PAL的参与度，评估了可用性，并检查了围绕模式、情感真实性和反馈传递的设计张力。参与者发现PAL有助于反思和技能提升，尽管一些人指出其在情感真实性和反馈适应性方面存在局限性。我们的贡献包括：(1) 大型语言模型可以支持姑息沟通培训的实证证据；(2) 针对模式感知、情感敏感模拟工具的设计见解；(3) 对支持情感劳动、协作学习和高风险护理环境中AI增强培训系统的启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [38] [A Theory-driven and AI-enhanced Simulation Platform for Cultivating Nutrition Literacy](https://arxiv.org/abs/2507.02138)
> *一个理论驱动和人工智能增强的营养素养培养模拟平台*

*Shan Li, Guozhu Ding* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 营养素养, 模拟平台, 人工智能, 理论驱动, 健康选择

**Comment:** 

> **TL;DR:** 本研究介绍并评估了一个名为“健康选择”的理论驱动和人工智能增强的模拟平台，旨在通过互动情景学习体验培养营养素养。

**AI_Comments:** 该论文提出了一种新颖的结合理论和AI的模拟平台，用于营养素养的培养，其创新性在于将AI技术融入到情景学习中，提高了学习的互动性和有效性。用户满意度高是其重要性体现之一，但抽象中未提及实际的营养素养提升效果。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个创新的模拟平台，通过互动情景学习体验来培养学生的营养素养。

**Method:** 本研究介绍并评估了“健康选择”平台，该平台是一个理论驱动和人工智能增强的模拟平台。研究收集了114名不同背景的大学生在完成模拟产品选择情景后的反馈，并对有用性和易用性进行了定量评分。

**Result:** 研究结果显示用户满意度很高，平台在有用性和易用性方面获得了高分。

**Conclusion:** “健康选择”平台作为一种理论驱动和人工智能增强的模拟平台，在培养营养素养方面表现出高用户满意度和潜力。

> **ai_Abstract:** 本研究介绍并评估了“健康选择”平台，这是一个结合了理论指导和人工智能技术的模拟学习平台，旨在通过情景互动帮助学生提升营养素养。对114名大学生的反馈分析显示，该平台在有用性和易用性方面获得了高度评价，表明用户满意度良好。

> **摘要翻译:** 本研究介绍并评估了“健康选择”，一个创新的、理论驱动和人工智能增强的模拟平台，旨在通过互动情景学习体验培养营养素养。我们收集了114名不同背景的大学生完成模拟产品选择情景后的反馈。对有用性和易用性的定量评分表明用户满意度很高。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [87] [A wireless, inexpensive optical tracker for the CAVE](https://arxiv.org/abs/2507.02682)
> *CAVE的无线廉价光学跟踪器*

*Ehud Sharlin, Pablo Figueroa, Mark Green, Benjamin Watson* | **Category: cs.HC, cs.ET** | **Updated: {updated}**

**Keywords:** 无线跟踪器, CAVE, 虚拟现实, 低成本, 光学跟踪

**Comment:** 

> **TL;DR:** 本文介绍了一种用于CAVE显示器的无线、低成本脚部跟踪器，解决了传统跟踪系统束缚用户的问题，实现了自由移动，但精度有限。

**AI_Comments:** 该论文通过提供一种创新且低成本的无线跟踪解决方案，解决了CAVE系统的一个实际限制。其主要创新在于以极低的成本在CAVE环境中实现了无束缚的移动。尽管其精度对于精确任务有限，但强调用户在虚拟探索等应用中的自由度是一个重要的贡献。论文清晰地承认了成本/自由度与精度之间的权衡，使其成为特定VR用例的有价值贡献。

<details>
  <summary>Details</summary>

**Motivation:** CAVE显示器虽提供无束缚的观看空间，但其传统跟踪系统会束缚用户，削弱了这一优势。本研究旨在设计一种无线、低成本的跟踪器以解决此问题，让用户能够自由移动。

**Method:** 研究人员设计并制造了一个简单的、成本低于200美元的无线光学脚部跟踪器。他们通过两个应用程序测试了原型：一个支持近距离视觉检查的可视化应用和一个校园漫游应用。

**Result:** 该跟踪器在20赫兹采样率下可达到10厘米的精度。在校园漫游应用中，跟踪效果令人信服，提供了自由移动能力。然而，对于需要精确视觉检查的应用，其精度有限，不太理想。

**Conclusion:** 该无线跟踪器为CAVE环境提供了引人注目的运动自由度，非常适合虚拟漫游等应用，尽管其在需要高精度视觉检查的任务中存在局限性。

> **ai_Abstract:** 本文介绍了一种为CAVE虚拟现实显示器设计的无线、低成本光学脚部跟踪器。该原型旨在解决传统有线跟踪系统的束缚问题，允许用户自由移动。该跟踪器成本低于200美元，在20赫兹采样率下可实现10厘米的精度。尽管它能有效支持虚拟漫游等应用，但其精度限制使其不适用于需要精细视觉检查的任务。

> **摘要翻译:** CAVE显示器比其他虚拟现实（VR）显示器具有许多优势，包括一个大型、无束缚的观看空间。不幸的是，CAVE显示器使用的典型跟踪子系统会束缚用户，从而削弱了这一优势。我们设计了一种简单、低成本的脚部跟踪器，它是无线的，让用户可以自由移动。该跟踪器组装成本低于200美元，在20赫兹的采样率下可达到10厘米的精度。我们已经用两个应用程序测试了原型：一个支持近距离视觉检查的可视化应用程序，以及一个校园漫游应用程序。尽管跟踪效果令人信服，但很明显，跟踪器的局限性使其不适用于需要精确视觉检查的应用程序。然而，跟踪器提供的运动自由度是对我们校园漫游的一个引人注目的补充，允许用户漫步和环顾角落。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [88] [The Revolution Has Arrived: What the Current State of Large Language Models in Education Implies for the Future](https://arxiv.org/abs/2507.02180)
> *革命已经到来：大型语言模型在教育领域的现状对未来的启示*

*Russell Beale* | **Category: cs.HC, cs.CY, H.5.0; K.3.1; K.3.2** | **Updated: {updated}**

**Keywords:** 大型语言模型, 教育技术, 人机交互, 学习范式, 未来教育

**Comment:** 

> **TL;DR:** 本文回顾了大型语言模型（LLMs）在教育领域的应用、影响、挑战和未来发展，认为LLMs将彻底改变人机交互和教育技术设计。

**AI_Comments:** 本文对大型语言模型在教育领域的现状及其未来影响进行了全面而深刻的分析，其创新之处在于不仅回顾了现有应用，更着重探讨了LLMs对人机交互范式的根本性改变，并提出了未来教育技术设计的具体考量。其重要性在于，它预见了LLMs将成为与技术交互的“默认方式”，这对于教育领域的决策者、开发者和研究者都具有重要的指导意义。文章的局限性可能在于其更多是基于观察和推测，而非实证研究。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于大型语言模型（LLMs）自2022年广泛应用以来，在不到三年内对教育和教育技术产生了显著影响，本文旨在审查其应用领域、讨论用例（成功与失败）、分析对学习者和教育者的动态改变，并思考其作为教育系统面临的设计挑战。

**Method:** 本文通过回顾大型语言模型在教育领域的应用领域，讨论了其各种用例（包括成功和失败）。随后，探讨了LLMs如何改变学习者和教育者的动态，考虑了LLMs若要成为真正有用的教育系统所面临的主要设计挑战，并反思了它们支持的学习范式。

**Result:** 大型语言模型带来的新型交互范式意义重大，未来将变得无处不在，成为人们与技术交互的默认方式，并彻底改变人们对计算机系统的期望。这促使文章提出了未来教育技术设计中需要考虑的具体且重要的因素，以确保其被不断变化的学习者和用户期望所接受。

**Conclusion:** 大型语言模型将彻底改变人机交互和教育技术的设计，成为主流的交互方式，因此未来的教育技术设计必须考虑这些变化以适应不断演变的用户期望。

> **ai_Abstract:** 本文回顾了大型语言模型（LLMs）在教育领域的快速发展及其深远影响。文章分析了LLMs的现有应用、成功与失败，探讨了它们如何改变学习者和教育者的互动模式。同时，文章深入讨论了LLMs作为教育系统面临的设计挑战及所支持的学习范式，并强调了LLMs带来的新型交互范式将成为未来人机交互的默认方式，彻底改变人们对技术系统的期望。最终，文章为未来教育技术的设计提出了具体的建议，以适应用户不断变化的需求。

> **摘要翻译:** 大型语言模型自2022年才开始广泛应用，然而在不到三年的时间里，它们已经对教育方法和教育技术产生了显著影响。本文回顾了它们已被应用的领域，并讨论了各种用例，包括它们的成功与失败。接着，我们进一步讨论了这如何改变学习者和教育者的动态，考虑了大型语言模型若要真正成为有用且有效的教育系统所面临的主要设计挑战，并反思了它们所支持的学习范式。我们明确指出，它们带来的新型交互范式意义重大，并认为这种方法将变得如此普遍，以至于它将成为我们与技术交互的默认方式，并彻底革新人们对计算机系统的一般期望。这促使我们提出了未来教育技术设计中一些具体而重要的考虑因素，这些因素可能需要以确保其被不断变化的学习者和用户期望所接受。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [112] [EvalAssist: A Human-Centered Tool for LLM-as-a-Judge](https://arxiv.org/abs/2507.02186)
> *EvalAssist：一个以人为本的LLM作为评判工具*

*Zahra Ashktorab, Elizabeth M. Daly, Erik Miehling, Werner Geyer, Martin Santillan Cooper, Tejaswini Pedapati, Michael Desmond, Qian Pan, Hyo Jin Do* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** LLM作为评判, 评估, 人机交互, EvalAssist, 评估标准

**Comment:** 

> **TL;DR:** EvalAssist是一个以人为本的工具，旨在简化LLM作为评判的评估流程，提供在线标准开发环境和LLM驱动的评估管道。

**AI_Comments:** EvalAssist的创新之处在于其以人为本的设计，将复杂的LLM作为评判的评估过程简化为一个交互式、结构化的工作流。通过提供在线标准开发环境和支持提示链的LLM评估管道，它显著提高了评估效率和可复用性。此外，整合危害和风险检测评估器增加了其在实际应用中的价值。该工具的内部部署和广泛使用表明了其在解决当前LLM评估痛点方面的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型的普及，评估其大量输出以确定最佳输出变得耗时且成本高昂。机器学习从业者需要有效的方法来评估不同模型和提示的性能，同时LLM越来越多地被用作评估器。

**Method:** EvalAssist是一个框架，它提供一个在线标准开发环境，用户可以在其中交互式地构建、测试和共享自定义评估标准。它支持一套利用现成LLM并使用提示链方法的LLM评估管道，该方法已贡献给UNITXT开源库。此外，系统还包括经过专门训练的评估器来检测LLM输出中的危害和风险。

**Result:** EvalAssist系统已在组织内部署，拥有数百名用户。

**Conclusion:** EvalAssist通过提供一个以人为本的工具来简化LLM作为评判的工作流程，使用户能够高效地开发和应用评估标准，从而解决LLM输出评估的复杂性和成本问题。

> **ai_Abstract:** EvalAssist是一个以人为本的工具，旨在简化大型语言模型（LLM）输出的评估过程。面对LLM生成能力带来的评估挑战，该系统提供了一个在线环境，允许用户交互式地开发、测试和共享自定义评估标准。它利用现成的LLM和一种新颖的提示链方法来支持评估管道，并包含专门训练的评估器以检测潜在危害。EvalAssist已在其组织内部署并被数百名用户使用，有效解决了LLM输出评估中耗时且成本高昂的问题。

> **摘要翻译:** 随着大型语言模型的广泛可用性及其使用各种提示和配置生成大量输出的能力，确定给定任务的最佳输出需要一个密集的评估过程，其中机器学习从业者必须决定如何评估输出，然后仔细进行评估。这个过程既耗时又昂贵。随着从业者使用越来越多的模型，他们现在必须评估输出以确定哪个模型和提示在给定任务中表现最佳。LLM越来越多地被用作评估器，用于过滤训练数据、评估模型性能、评估危害和风险，或协助人类评估员进行详细评估。我们提出了EvalAssist，一个简化LLM作为评判工作流程的框架。该系统提供了一个在线标准开发环境，用户可以在其中以结构化和可移植的格式交互式地构建、测试和共享自定义评估标准。我们支持一套基于LLM的评估管道，这些管道利用现成的LLM并使用我们开发并贡献给UNITXT开源库的提示链方法。此外，我们的系统还包括经过专门训练的评估器，以检测LLM输出中的危害和风险。我们已在组织内部署该系统，拥有数百名用户。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [137] [VergeIO: Depth-Aware Eye Interaction on Glasses](https://arxiv.org/abs/2507.02187)
> *VergeIO：眼镜上的深度感知眼部交互*

*Xiyuxing Zhang, Duc Vu, Chengyi Shen, Yuntao Wang, Yuanchun Shi, Justin Chan* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** EOG, 眼部交互, 深度感知, 智能眼镜, 可穿戴设备

**Comment:** 

> **TL;DR:** VergeIO是一种新型基于EOG的眼镜，首次实现了深度感知眼部交互，能够高精度识别不同深度的眼部手势，并具有低功耗和实时性，适用于常时感知。

**AI_Comments:** VergeIO的创新之处在于首次将EOG与辐辏结合，实现了深度感知的眼部交互，这在现有眼部追踪技术中是一个显著的进步。其使用干式传感器、低功耗和无需校准的泛化能力使其具有很高的实用价值和商业潜力，尤其是在可穿戴设备领域。未来的研究可以探索更多复杂手势的识别以及在不同环境光照下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 行业对在眼镜上实现不显眼的眼电图（EOG）眼部手势感应设计日益增长的兴趣，现有技术可能缺乏深度感知能力。

**Method:** VergeIO采用优化的电极布局和新型智能眼镜原型，基于EOG实现深度感知眼部交互。它结合了辐辏（vergence）来区分深度。为减少误报，系统整合了运动伪影检测流程和基于前导码的激活方案。系统使用干式传感器，无需粘合剂或凝胶。

**Result:** VergeIO能够以83-98%的准确率区分4到6种基于深度的眼部手势（使用个性化模型）。对于未曾接触过的用户，无需校准即可达到80-98%的准确率。系统实时运行，传感前端功耗为3 mW。

**Conclusion:** VergeIO系统使用干式传感器，具有低功耗和实时性，使其适用于常时感应的深度感知眼部交互。

> **ai_Abstract:** VergeIO是一种创新的基于EOG的智能眼镜系统，首次实现了深度感知的眼部交互。通过优化电极布局和利用辐辏，它能高精度识别多达六种不同深度的眼部手势，且无需校准即可泛化至新用户。系统还集成了运动伪影检测和低功耗干式传感器设计，使其能够实时运行并支持常时感知，为未来智能眼镜的人机交互提供了新方向。

> **摘要翻译:** 行业对在眼镜上创建不显眼的眼电图（EOG）眼部手势感应设计（例如JINS MEME和Apple眼镜）的兴趣日益增长。我们提出了VergeIO，这是首款基于EOG的眼镜，它通过辐辏（vergence）和优化的电极布局以及新型智能眼镜原型实现了深度感知眼部交互。在一项针对11名用户和1320个手势实例的用户研究中，它使用个性化模型能够以83-98%的准确率区分四到六种基于深度的眼部手势。对于未曾接触过的用户，无需任何校准即可达到80-98%的准确率。为了减少误报，我们整合了运动伪影检测流程和基于前导码的激活方案。该系统使用不带任何粘合剂或凝胶的干式传感器，并以传感前端3毫瓦的功耗实时运行，使其适用于常时感应。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [157] [An Exploration of Internal States in Collaborative Problem Solving](https://arxiv.org/abs/2507.02229)
> *协作问题解决中内部状态的探索*

*Sifatul Anindho, Videep Venkatesha, Mariah Bradford, Anne M. Cleary, Nathaniel Blanchard* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 协作问题解决, 内部状态, 情感, 语言分析, 混合方法

**Comment:** Accepted to the International Conference on Human-Computer
  Interaction (HCII) 2025

> **TL;DR:** 本研究采用混合方法调查了协作问题解决过程中个体的内部情感状态，通过语言分析揭示了情绪表达的独特模式。

**AI_Comments:** 本研究的创新之处在于其独特的混合方法，特别是通过视频回顾和自我报告来捕获个体在复杂协作任务中的实时内部体验，并结合语言分析揭示情绪模式。这为理解协作行为背后的情感维度提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 协作问题解决（CPS）在教育和专业环境中日益普遍，但其认知、社会和情感过程复杂。本研究旨在深入了解个体在CPS过程中的情感状态。

**Method:** 本研究采用混合方法。四人团队首先完成一项新颖的CPS任务。任务结束后，每位个体被单独安排在一个房间，观看自己小组执行任务的视频，并自我报告任务期间的内部体验。研究人员对这些内部独白进行了语言分析。

**Result:** 分析结果显示，个体在CPS期间的语言使用存在独特的模式，包括特征性的单字词和双字词、关键词和短语、情绪标签，以及情绪相关词语之间的语义相似性。

**Conclusion:** 本研究通过对内部独白的语言分析，为理解个体在协作问题解决过程中所经历的情绪范围提供了见解。

> **ai_Abstract:** 本研究旨在探索协作问题解决（CPS）过程中个体的内部情感状态。通过让团队完成CPS任务后，个体回顾视频并自我报告内部体验，研究人员对这些内部独白进行了语言分析。结果揭示了语言使用中独特的情绪表达模式，包括特定的词汇、短语和情绪标签，为理解CPS中的情感体验提供了新的视角。

> **摘要翻译:** 协作问题解决（CPS）是一个复杂的认知、社会和情感过程，在教育和专业环境中日益普遍。本研究采用混合方法调查了CPS期间个体的情感状态。首先，四人团队完成了一项新颖的CPS任务。紧接着，每个个体被安置在一个独立的房间里，回顾他们团队执行任务的视频，并自我报告任务期间的内部体验。我们对这些内部独白进行了语言分析，从而深入了解个体在CPS期间所经历的情绪范围。我们的分析显示了语言使用中独特的模式，包括特征性的单字词和双字词、关键词和短语、情绪标签，以及情绪相关词语之间的语义相似性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [177] [A framework for 3D interaction techniques](https://arxiv.org/abs/2507.02254)
> *3D交互技术框架*

*Pablo Figueroa, Mark Green, Benjamin Watson* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 3D交互, 软件架构, 框架, 可扩展性, 数据流

**Comment:** 

> **TL;DR:** 本文提出了一个用于3D交互技术的软件架构和面向对象的、独立于工具包的框架，该框架具有可扩展性，并支持数据流式交互。

**AI_Comments:** 这篇论文的创新点在于其提出的面向对象、独立于工具包的框架设计，强调了可扩展性和模块化。这种设计使得3D交互技术的开发和集成变得更加灵活，能够适应不同的设备和应用场景，为后续的3D交互系统开发奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供一个灵活、可扩展的软件架构和框架，以实现和管理3D交互技术。

**Method:** 提出了一种软件架构，并实现了一个面向对象、独立于工具包的框架。该框架将交互技术（ITs）视为由基本过滤器在数据流中连接而成，其中虚拟输入设备和场景对象是信息源。定义了一个执行模型来管理过滤器之间的信息流。

**Result:** 结果是一个可扩展的框架，能够轻松添加新的信息类型、输入设备、执行模型或交互技术。此外，特定于应用程序的代码和交互技术可以无缝集成到该架构中。

**Conclusion:** 本文成功地提出了一个模块化、可扩展且易于集成的3D交互技术框架。

> **ai_Abstract:** 本文介绍了一个针对3D交互技术的软件架构和一个实现该架构的面向对象、独立于工具包的框架。该框架将交互技术构建为数据流中连接的过滤器，并定义了信息流的执行模型。其核心设计目标是可扩展性，允许轻松添加新组件和功能，并支持应用程序特定代码的无缝集成。

> **摘要翻译:** 本文提出了一种用于3D交互技术（ITs）的软件架构，以及一个实现该架构的面向对象、独立于工具包的框架。交互技术由数据流中连接的基本过滤器组成，其中虚拟输入设备和场景中的对象是信息源。一个执行模型定义了过滤器之间信息的通用流。该框架被设计为可扩展的：可以轻松添加新的信息类型、新的输入设备、新的执行模型或新的交互技术。应用程序特定的代码和应用程序特定的交互技术可以无缝集成到该架构中。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [195] [Misaligned from Within: Large Language Models Reproduce Our Double-Loop Learning Blindness](https://arxiv.org/abs/2507.02283)
> *内在失调：大型语言模型复制了我们双环学习的盲点*

*Tim Rogers, Ben Teehankee* | **Category: cs.HC, I.2.6; H.1.2** | **Updated: {updated}**

**Keywords:** 大型语言模型, AI对齐, 双环学习, Model 1, Model 2

**Comment:** 21 pages

> **TL;DR:** 大型语言模型（LLMs）可能继承并放大人类的认知盲点和反学习模式（Model 1），这在组织决策中带来风险；但同时，它们也有潜力被开发以促进更有效的学习（Model 2）。

**AI_Comments:** 本文的创新之处在于将AI对齐问题与行动科学的双环学习理论相结合，揭示了LLMs不仅可能复制人类行为，更可能继承并固化人类深层次的认知偏差和反学习模式。这为AI对齐研究提供了新的视角，强调了AI系统在组织环境中可能带来的隐性风险。同时，论文也指出了AI在促进人类自身学习和价值观体现方面的潜力，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨人工智能对齐问题中一个关键但尚未被探索的维度：大型语言模型（LLMs）如何继承并放大人类言行不一的现象（即言传理论与使用理论之间的偏差），特别是再现抑制学习并产生反学习动态的Model 1思维模式。

**Method:** 本研究借鉴行动科学研究，并通过一个将LLM作为人力资源顾问的详细案例研究，展示了其建议如何影响组织学习。

**Result:** 案例研究表明，LLM的建议虽然表面专业，但系统性地强化了低效的问题解决方式，并阻碍了更深层次的组织学习。这表明AI系统在成功模仿人类行为的同时，也继承了人类的认知盲点，若整合到组织决策中将带来风险。

**Conclusion:** 论文探讨了开发能够促进Model 2学习（一种更富有成效的使用理论）的LLMs的可能性，并提出这项工作可以同时推进AI对齐研究和行动科学实践。这揭示了对齐挑战中一个意想不到的对称性：开发与人类价值观正确对齐的AI系统，也能反过来帮助人类更好地体现这些价值观。

> **ai_Abstract:** 该论文探讨了大型语言模型（LLMs）在AI对齐问题中一个未被充分研究的方面：它们可能继承并放大人类的认知盲点，特别是复制抑制学习的Model 1防御性推理模式。通过一个LLM作为HR顾问的案例研究，作者发现LLM的建议会无意中强化低效的问题解决方式并阻碍组织学习。文章指出，这种现象对LLMs在组织决策中的应用构成风险，并提出了开发能够促进更有效Model 2学习的LLMs的可能性，认为这既能推进AI对齐研究，也能帮助人类更好地体现自身价值观。

> **摘要翻译:** 本文探讨了人工智能对齐问题中一个关键但尚未被探索的维度：大型语言模型（LLMs）可能继承并放大人类言传理论与使用理论之间现有的失调。借鉴行动科学研究，我们认为，在人类生成文本上训练的LLMs很可能吸收并复制Model 1使用理论——一种防御性推理模式，它既抑制学习，又在双人、群体和组织层面持续产生反学习动态。通过一个将LLM作为人力资源顾问的详细案例研究，我们展示了其建议，虽然表面专业，但系统性地强化了低效的问题解决方法，并阻碍了更深层次的组织学习。这代表了对齐问题的一个具体实例，即AI系统成功地模仿了人类行为，但继承了我们的认知盲点。如果LLMs被整合到组织决策过程中，这会带来特殊的风险，可能固化反学习实践，同时赋予它们权威性。论文最后探讨了开发能够促进Model 2学习——一种更富有成效的使用理论——的LLMs的可能性，并提出这项工作可以同时推进AI对齐研究和行动科学实践。这项分析揭示了对齐挑战中一个意想不到的对称性：开发与人类价值观正确对齐的AI系统，也能反过来产生工具，帮助人类自身更好地体现这些价值观。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [207] [Human-Centered Explainability in Interactive Information Systems: A Survey](https://arxiv.org/abs/2507.02300)
> *人机交互信息系统中以人为中心的解释性：一项综述*

*Yuhao Zhang, Jiaxin An, Ben Wang, Yan Zhang, Jiqun Liu* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 以人为中心的解释性, 交互式信息系统, 系统综述, 用户研究, 可解释AI

**Comment:** 

> **TL;DR:** 这项系统综述旨在通过审查解释性在实践中如何被概念化、设计和评估，来描述交互式信息系统中用户研究的最新进展，并提供五个解释性概念维度、解释设计分类方案和六个用户中心解释性测量维度。

**AI_Comments:** 这篇综述的重要性在于它系统地整理了以人为中心的解释性研究的现状，为该领域的研究人员和实践者提供了清晰的框架和指导。其贡献在于对解释性概念化、设计和评估进行了全面的归纳和分类，有助于推动可解释AI在交互式系统中的应用和发展。

<details>
  <summary>Details</summary>

**Motivation:** 解释性已成为交互式信息系统负责任开发的关键基础，用户必须理解、解释和审查AI驱动的输出以做出明智决策。本研究旨在系统地综述关于交互式信息系统中以人为中心的解释性用户研究的最新进展。

**Method:** 遵循PRISMA指南，检索了八个学术数据库，识别出100篇相关文章。利用结构化编码方法从这些文章中提取和综合见解。

**Result:** 主要贡献包括：1) 研究人员用来概念化解释性的五个维度；2) 解释设计分类方案；3) 将解释性测量分为六个以用户为中心的维度。

**Conclusion:** 综述反思了当前面临的挑战，并为未来相关问题的探索提供了建议。研究结果阐明了以人为中心的解释性的理论基础，为设计更好地符合多样化用户需求并促进系统透明、可信和负责任的交互式信息系统提供了信息。

> **ai_Abstract:** 这项系统综述旨在全面审视交互式信息系统中以人为中心的解释性研究进展。通过对100篇文献的分析，该研究提出了解释性的五个概念维度、解释设计的分类方案以及六个用户中心的解释性测量维度。研究结果为未来设计更透明、可信和负责任的交互式信息系统提供了理论基础和实践指导，并指出了未来的研究方向。

> **摘要翻译:** 以人为中心的解释性已成为交互式信息系统负责任开发的关键基础，用户必须能够理解、解释和审查AI驱动的输出以做出明智决策。这项系统的文献综述旨在通过审查解释性在实践中如何被概念化、设计和评估来描述交互式信息系统中用户研究的最新进展。遵循PRISMA指南，检索了八个学术数据库，并识别出100篇相关文章。随后利用结构化编码方法从这些文章中提取和综合见解。主要贡献包括：1) 研究人员用来概念化解释性的五个维度；2) 解释设计分类方案；3) 将解释性测量分为六个以用户为中心的维度。本综述通过反思当前面临的挑战并为未来相关问题的探索提供建议而结束。研究结果阐明了以人为中心的解释性的理论基础，为设计更好地符合多样化用户需求并促进系统透明、可信和负责任的交互式信息系统提供了信息。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [212] [Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks](https://arxiv.org/abs/2507.02819)
> *测量即拼凑：探究数据科学家如何构建预测建模任务的目标变量*

*Luke Guerdan, Devansh Saxena, Stevie Chancellor, Zhiwei Steven Wu, Kenneth Holstein* | **Category: cs.HC, cs.CY, cs.LG** | **Updated: {updated}**

**Keywords:** 数据科学, 目标变量, 预测建模, 拼凑, 测量

**Comment:** 

> **TL;DR:** 本研究通过访谈数据科学家，揭示了他们如何将模糊概念转化为具体的预测建模目标变量，这一过程是一种涉及高层目标与低层约束之间迭代协商的“拼凑”过程，并提出了未来人机交互、协作式计算机支持工作和机器学习研究的机遇。

**AI_Comments:** 这篇论文创新性地将“拼凑”（bricolage）的概念引入数据科学领域，解释了数据科学家在面对模糊概念时如何灵活、迭代地构建目标变量。它揭示了数据科学实践中一个被忽视但至关重要的方面，即目标变量的工程化过程，而非仅仅是算法选择。研究结果对于理解数据科学的实践复杂性具有重要意义，并为未来工具和方法的设计提供了明确的方向，尤其是在人机交互、协作系统和机器学习领域。

<details>
  <summary>Details</summary>

**Motivation:** 数据科学家在预测建模任务中经常处理模糊、难以定义的复杂概念（如学生写作的“真实性”或患者的“医疗需求”），但他们将这些模糊概念转化为具体代理目标变量的过程却鲜为人知且缺乏深入理解。

**Method:** 研究人员采访了教育领域（N=8）和医疗领域（N=7）的十五位数据科学家，以了解他们如何构建预测建模任务的目标变量。

**Result:** 研究发现，数据科学家通过一种“拼凑”（bricolage）过程来构建目标变量，这涉及高层测量目标与低层实际约束之间的迭代协商。数据科学家试图通过拼凑来满足目标变量的五个主要标准：有效性、简单性、可预测性、可移植性和资源需求。为实现这一点，他们适应性地使用问题（重新）制定策略，例如当一个候选目标变量不满足某些标准时（如可预测性），会替换为另一个，或者将多个结果组合成一个单一的目标变量以捕捉更全面的建模目标。

**Conclusion:** 基于研究发现，论文提出了未来人机交互（HCI）、协作式计算机支持工作（CSCW）和机器学习（ML）研究的机会，以更好地支持目标变量构建的艺术与科学。

> **ai_Abstract:** 本研究通过访谈教育和医疗领域的15位数据科学家，探讨了他们如何将模糊概念转化为预测建模的具体目标变量。研究发现，数据科学家通过一种“拼凑”过程构建目标变量，该过程涉及高层测量目标与低层实际约束之间的迭代协商。他们努力满足有效性、简单性、可预测性、可移植性和资源需求这五个关键标准，并采用问题（重新）制定策略。论文最后指出了未来HCI、CSCW和ML研究在支持目标变量构建方面的机遇。

> **摘要翻译:** 数据科学家经常制定涉及模糊、难以定义概念的预测建模任务，例如学生写作的“真实性”或患者的“医疗需求”。然而，数据科学家将模糊概念转化为具体、代理目标变量的过程却鲜为人知。我们采访了教育（N=8）和医疗（N=7）领域的十五位数据科学家，以了解他们如何为预测建模任务构建目标变量。我们的发现表明，数据科学家通过一种拼凑过程来构建目标变量，这涉及高层测量目标与低层实际约束之间的迭代协商。数据科学家试图通过拼凑来满足目标变量的五个主要标准：有效性、简单性、可预测性、可移植性和资源需求。为实现这一点，数据科学家适应性地使用问题（重新）制定策略，例如当一个候选目标变量不满足某些标准（例如可预测性）时，会替换掉另一个，或者将多个结果组合成一个单一的目标变量，以捕捉更全面的建模目标。基于我们的发现，我们提出了未来人机交互、协作式计算机支持工作和机器学习研究的机会，以更好地支持目标变量构建的艺术与科学。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [221] [Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation](https://arxiv.org/abs/2507.02306)
> *合成启发式评估：AI驱动与人类驱动可用性评估的比较*

*Ruican Zhong, David W. McDonald, Gary Hsieh* | **Category: cs.HC, cs.AI** | **Updated: {updated}**

**Keywords:** 可用性评估, 大型语言模型, 启发式评估, 人工智能, 人机交互

**Comment:** 

> **TL;DR:** 本研究开发了一种基于多模态大型语言模型（LLMs）的合成启发式评估方法，在可用性问题识别方面表现优于人类专家，但在识别特定UI组件和跨屏幕违规方面存在局限性。

**AI_Comments:** 该研究创新性地将多模态大型语言模型应用于可用性启发式评估，有望大幅降低评估成本和时间。其表现优于人类专家，尤其在布局问题检测上具有优势。然而，其在识别特定UI组件、设计约定及跨屏幕违规方面的局限性也提示了未来改进的方向。

<details>
  <summary>Details</summary>

**Motivation:** 可用性评估在以人为本的设计中至关重要，但成本高昂，需要专家时间和用户报酬。

**Method:** 开发了一种利用多模态大型语言模型（LLMs）分析图像并提供设计反馈的合成启发式评估方法。

**Result:** 与经验丰富的人类用户体验专家相比，合成评估在两个应用中识别出73%和77%的可用性问题，超过了5位人类评估员的表现（57%和63%）。合成评估在不同任务中表现一致，擅长检测布局问题，但在识别某些UI组件、设计约定和跨屏幕违规方面存在困难。此外，合成评估的性能随时间推移和账户变化保持稳定。

**Conclusion:** 本研究强调了人类评估与大型语言模型驱动评估之间的性能差异，为合成启发式评估的设计提供了信息。

> **ai_Abstract:** 本研究针对传统可用性评估成本高昂的问题，提出了一种基于多模态大型语言模型（LLMs）的合成启发式评估方法。实验结果表明，该方法在识别可用性问题方面表现优于人类专家，尤其擅长布局问题检测，且性能稳定。尽管在识别特定UI组件和跨屏幕违规方面存在局限性，但这项工作揭示了AI驱动评估的潜力及其与人类评估的差异，为未来合成评估的设计提供了重要参考。

> **摘要翻译:** 可用性评估在以人为本的设计中至关重要，但成本高昂，需要专家时间和用户报酬。在这项工作中，我们开发了一种利用多模态大型语言模型（LLMs）分析图像并提供设计反馈的合成启发式评估方法。我们将合成评估与经验丰富的用户体验从业者在两个应用程序上的评估进行比较，发现我们的评估识别了73%和77%的可用性问题，这超过了5位经验丰富的人类评估员的表现（57%和63%）。与人类评估员相比，合成评估的性能在不同任务中保持一致，并且在检测布局问题方面表现出色，突显了合成评估潜在的注意力和感知优势。然而，合成评估在识别某些UI组件和设计约定以及识别跨屏幕违规方面存在困难。此外，对合成评估进行长时间和多账户测试显示其性能稳定。总的来说，我们的工作强调了人类评估与大型语言模型驱动评估之间的性能差异，为合成启发式评估的设计提供了信息。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [232] [From Coarse to Fine-Grained Emotion Annotation: An Immediate Recall Paradigm with Validation through Physiological Evidence and Recognition Performance](https://arxiv.org/abs/2507.02350)
> *从粗粒度到细粒度情感标注：一种通过生理证据和识别性能验证的即时回忆范式*

*Hao Tang, Songyun Xie, Xinzhou Xie, Can Liao, Xin Zhang, Bohan Li, Zhongyu Tian, Dalu Zheng* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 情感标注, 细粒度, 即时回忆, 生理证据, 情感识别

**Comment:** 

> **TL;DR:** 传统情感标注粗糙导致噪声，本文提出细粒度即时回忆标注方法，通过生理证据和识别性能验证其精确性，并证明标注精度比数据量更重要。

**AI_Comments:** 这项工作创新性地提出了即时回忆范式来解决情感标注中的标签噪声问题，并通过生理证据和识别性能双重验证，证明了细粒度标注的优越性。其核心贡献在于强调了标注“精度”而非“数据量”对情感识别性能的关键影响，为未来情感数据集的构建和识别算法的优化提供了重要指导。

<details>
  <summary>Details</summary>

**Motivation:** 传统视频诱发情感生理数据集使用全试次标注，将单一情感标签分配给整个试次数据，这种粗粒度标注与情感反应的动态和时间局部性不符，引入了标签噪声，限制了情感识别算法的评估和性能。

**Method:** 提出一种通过即时回忆范式实现的细粒度标注方法。该范式在初始刺激观看后立即进行视频回放阶段，允许参与者根据即时回忆精确标记起始时间戳、情感标签和强度。通过生理证据和识别性能验证该范式。

**Result:** 生理验证显示，参与者标记窗口内的多模态信号揭示了节律特异性脑电图模式和唤醒依赖性皮肤电反应（高唤醒情感窗口中91%出现SCR，低唤醒情感窗口中6%出现SCR），这些客观生理数据变化与主观标注高度一致，证实了标注精度。识别性能方面，使用细粒度标注训练的模型比传统全试次标注的模型准确率高9.7%，尽管数据量更少。

**Conclusion:** 本工作不仅通过细粒度标注解决了标签噪声问题，还证明了标注精度在决定情感识别性能方面的重要性超过了数据规模。

> **ai_Abstract:** 本文提出一种名为“即时回忆范式”的细粒度情感标注方法，旨在解决传统粗粒度视频情感标注中存在的标签噪声问题。该方法允许参与者在观看视频后立即回放并精确标记情感发生的时间、类型和强度。通过生理信号（如EEG和GSR）验证，该方法显示出高精度，且与主观标注一致。在情感识别任务中，基于细粒度标注训练的模型即使数据量较少，也比粗粒度标注的模型性能提升9.7%，强调了标注精度对情感识别性能的重要性。

> **摘要翻译:** 传统的视频诱发情感生理数据集通常采用全试次标注，为整个试次中收集的所有数据分配一个单一的情感标签。这种粗粒度标注方法与情感反应随视频叙事展开时的动态和时间局部性不符，引入了标签噪声，从而限制了情感识别算法的评估和性能。为了解决粗粒度标注引起的标签噪声问题，我们提出了一种通过即时回忆范式实现的细粒度标注方法。该范式在初始刺激观看后整合了一个即时视频回放阶段，允许参与者根据他们的即时回忆精确标记起始时间戳、情感标签和强度。我们通过生理证据和识别性能验证了这种范式。参与者标记窗口内多模态信号的生理验证揭示了节律特异性脑电图模式和唤醒依赖性皮肤电反应——高唤醒情感窗口中91%出现皮肤电反应，而低唤醒情感窗口中仅有6%。这些客观的生理数据变化与主观标注高度一致，证实了标注的精确性。在识别性能方面，分类实验表明，尽管使用的数据量更少，但通过细粒度标注训练的模型比传统全试次标注的模型实现了9.7%更高的准确率。这项工作不仅通过细粒度标注解决了标签噪声问题，还证明了标注精度在决定情感识别性能方面的重要性超过了数据规模。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [243] [Closed-Loop Rhythmic Haptic Biofeedback via Smartwatch for Relaxation and Sleep Onset](https://arxiv.org/abs/2507.02432)
> *智能手表闭环节律触觉生物反馈用于放松和入睡*

*Jueun Lee, Dennis Moschina, Supraja Ramesh, Tobias Röddiger, Kai Kunze, Michael Beigl* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 触觉生物反馈, 智能手表, 放松, 睡眠, 闭环系统

**Comment:** 8 pages, 6 figures. Submitted to the International Symposium on
  Wearable Computers (ISWC)

> **TL;DR:** 该研究探索了一种通过智能手表提供闭环节律触觉生物反馈来促进放松和入睡的方法，发现短期刺激能增加放松感，但在入睡阶段对睡眠无显著影响。

**AI_Comments:** 该论文创新性地将智能手表应用于闭环触觉生物反馈，通过与用户心率同步的节律振动来诱导放松，提供了一种非侵入性的新方法。其重要性在于探索了触觉刺激在情绪调节和睡眠辅助方面的潜力。然而，研究结果显示其在实际入睡阶段对睡眠指标无显著影响，这指出了未来研究在优化干预策略和提升实际效果方面的挑战和方向。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探索将音乐结构化的闭环振动模式作为一种被动生物反馈干预手段，以期通过触觉引导来降低兴奋度，为放松和入睡提供一种非侵入性的替代方案，以区别于以往的听觉或开环方法。

**Method:** 研究通过将节律韵律结构编码到智能手表振动中，并将其频率调整得略慢于用户的实时心率。第一项研究（N=20）比较了五种自适应振动节律对心率和主观放松感知的影响。第二项研究（N=28）评估了第一项研究中最有前景的模式在长时间入睡设置中的效果。

**Result:** 研究结果显示，在短期刺激期间，受试者的副交感神经活动增加，主观放松感增强。然而，在入睡阶段，该系统对睡眠相关指标没有显著影响。

**Conclusion:** 该工作有助于理解可穿戴触觉反馈如何支持放松和睡眠，提供了设计见解，并确定了将触觉交互有效整合到自主干预中的方法学考量。

> **ai_Abstract:** 该研究提出了一种基于智能手表的闭环节律触觉生物反馈系统，通过与心率同步的振动来促进放松和入睡。两项研究表明，短期刺激能有效增加副交感神经活动和主观放松感，但对入睡阶段的睡眠指标无显著改善。这项工作为可穿戴触觉反馈在放松和睡眠领域的应用提供了设计指导和方法学考量。

> **摘要翻译:** 我们研究了使用音乐结构化的闭环振动模式作为一种被动生物反馈干预，用于放松和入睡。通过将节律韵律结构编码到智能手表振动中，并将其频率调整得略慢于用户的实时心率，我们的系统旨在通过触觉引导来降低兴奋度，为之前用于睡眠和焦虑情境中的听觉或开环方法提供了一种非侵入性替代方案。在第一项研究（N=20）中，我们比较了五种自适应振动节律在休息情境下对心率和主观放松感知的影响。在第二项研究（N=28）中，我们评估了第一项研究中最有前景的模式在长时间入睡设置中的效果。结果显示，短期刺激期间副交感神经活动增加，主观放松感增强，但在入睡阶段对睡眠相关指标没有显著影响。这项工作有助于理解可穿戴触觉反馈如何支持放松和睡眠，提供了设计见解，并确定了将触觉交互有效整合到自主干预中的方法学考量。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [252] [Haptic Biofeedback for Wakeful Rest: Does Stimulation Location Make a Difference?](https://arxiv.org/abs/2507.02453)
> *触觉生物反馈在清醒休息中的应用：刺激位置有区别吗？*

*Jueun Lee, Martin Flipe, Philipp Lepold, Tobias Röddiger, Michael Beigl* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 触觉生物反馈, 清醒休息, 刺激位置, 心率, 放松

**Comment:** 8 pages, 6 figures. Submitted to the International Symposium on
  Wearable Computers (ISWC)

> **TL;DR:** 研究发现，前臂和肩部是清醒休息时触觉生物反馈的最佳位置，能有效降低心率并提高主观放松度。

**AI_Comments:** 这项研究创新性地探讨了触觉生物反馈在清醒休息中的应用，并特别关注了刺激位置对效果的影响，填补了现有研究的空白。其发现对于设计更有效、更舒适的可穿戴放松设备具有重要指导意义，尤其强调了身体位置的重要性，超越了单纯的振动模式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可穿戴触觉干预主要关注压力诱导程序和固定振动模式，对身体位置和休息状态下的动态生物反馈考虑不足。

**Method:** 本研究调查了在闭眼清醒休息期间根据实时心率调整的触觉生物反馈的效果，比较了腕部、手部、前臂和肩部四个可穿戴身体放置位置。测量了心率、耳部α波活动、主观放松度和振动体验。

**Result:** 结果显示，生物反馈在腕部、肩部和前臂降低了心率，而耳部测量的α波功率保持不变。主观放松度在肩部和前臂被评为最高，这两个位置也是最受欢迎的。此外，参与者报告前臂比腕部更舒适、更放松，并进一步增加了睡意。

**Conclusion:** 前臂和肩部是清醒休息时提供不显眼放松反馈的理想位置，而腕部可能需要改进设计以提升主观体验。

> **ai_Abstract:** 本研究探讨了在清醒休息状态下，不同身体位置（腕部、手部、前臂、肩部）的实时心率调整触觉生物反馈对放松效果的影响。结果表明，前臂和肩部在降低心率和提高主观放松度方面表现最佳，被认为是进行不显眼放松反馈的理想位置。

> **摘要翻译:** 可穿戴触觉干预通过缓慢的振动触觉生物反馈为放松提供了有希望的支持。尽管它们具有潜力，但目前的应用程序主要集中在诱发压力的程序和固定的振动模式上，对身体位置和休息状态下的动态生物反馈考虑有限。本研究调查了在闭眼清醒休息期间根据实时心率调整的触觉生物反馈的效果，比较了四个可穿戴身体放置位置：腕部、手部、前臂和肩部。在这些条件下测量了心率、耳部α波活动、主观放松度和振动体验。结果显示，生物反馈在腕部、肩部和前臂降低了心率，而耳部测量的α波功率保持不变。主观放松度在肩部和前臂被评为最高，这两个位置也是最受欢迎的。此外，参与者报告前臂比腕部更舒适、更放松，并进一步增加了睡意，尽管腕部更容易识别。这些发现表明，前臂和肩部是清醒休息时提供不显眼放松反馈的理想选择，而腕部可能需要设计改进以提升主观体验。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [262] [Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue](https://arxiv.org/abs/2507.02537)
> *你在听我说话吗？微调聊天机器人以实现共情对话*

*Paulo Ricardo Knob, Leonardo Scholler, Juliano Rigatti, Soraia Raupp Musse* | **Category: cs.HC, cs.AI** | **Updated: {updated}**

**Keywords:** 共情对话, 大型语言模型, 情感智能, 微调, 人类评估

**Comment:** 

> **TL;DR:** 本研究探讨了如何微调大型语言模型以生成具有情感共情能力的对话，发现虽然模型能模仿情感结构，但在人类感知方面仍存在差距，强调了结合自动化和以人为中心方法的重要性。

**AI_Comments:** 本文创新性地探讨了LLM在生成共情对话方面的能力，并指出了当前模型在实现真正“感知”共情方面的局限性。强调了人类评估在情感AI发展中的不可替代性，为未来开发更具情感能力的对话代理提供了重要指导。

<details>
  <summary>Details</summary>

**Motivation:** 随着对话代理日益融入人类日常互动，它们的情感智能，特别是共情倾听能力，变得越来越重要。本研究旨在探索大型语言模型在生成情感丰富互动时的表现。

**Method:** 研究从一个由专家手工制作的反映共情行为的小型数据集开始，然后使用ChatGPT和Gemini两个大型语言模型扩展对话。通过情感分析（VADER）和专家评估来分析对话的情感进展。

**Result:** 生成的对话通常能反映预期的情感结构，但人类评估揭示了在感知到的共情和回应连贯性方面存在重要差异。

**Conclusion:** 对话中的情感建模不仅需要表达情感的结构对齐，还需要定性深度，这突出了在开发情感能力强的代理时结合自动化和以人为中心方法的重要性。

> **ai_Abstract:** 本研究探讨了如何微调大型语言模型（LLM）以实现共情对话。研究首先使用专家创建的小型共情数据集，然后利用ChatGPT和Gemini扩展对话，并通过情感分析和人类评估来分析情感进展。结果显示，LLM生成的对话虽然在结构上模仿了情感，但在人类感知到的共情和连贯性方面仍有不足。这强调了在构建情感智能代理时，需要结合自动化方法与以人为中心评估的重要性。

> **摘要翻译:** 对话代理自ELIZA以来取得了显著进展，将其角色扩展到医疗保健、教育和客户服务等各个领域。随着这些代理日益融入人类日常互动，情感智能，特别是共情倾听的需求变得越来越重要。在本研究中，我们探索了大型语言模型（LLM）在被要求生成情感丰富的互动时的反应。我们从一个由专家手工制作的反映共情行为的小型数据集开始，然后使用两个LLM：ChatGPT和Gemini扩展了对话。我们使用情感分析（通过VADER）和专家评估来分析对话的情感进展。虽然生成的对话通常能反映预期的情感结构，但人类评估揭示了在感知到的共情和回应连贯性方面存在重要差异。这些发现表明，对话中的情感建模不仅需要表达情感的结构对齐，还需要定性深度，这突出了在开发情感能力强的代理时结合自动化和以人为中心方法的重要性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [277] [Who's Sorry Now: User Preferences Among Rote, Empathic, and Explanatory Apologies from LLM Chatbots](https://arxiv.org/abs/2507.02745)
> *现在谁来道歉：用户对LLM聊天机器人程式化、移情和解释性道歉的偏好*

*Zahra Ashktorab, Alessandra Buccella, Jason D'Cruz, Zoe Fowler, Andrew Gill, Kei Yan Leung, P. D. Magnus, John Richards, Kush R. Varshney* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** LLM, 聊天机器人, 道歉, 用户偏好, 信任修复

**Comment:** 

> **TL;DR:** 本研究调查了用户对LLM聊天机器人三种道歉类型（程式化、移情、解释性）的偏好，发现解释性道歉普遍受欢迎，但偏好会因情境和用户而异，特别是在偏见情境中移情道歉更受青睐。

**AI_Comments:** 这项研究具有重要的实践意义，因为它直接探讨了LLM在用户交互中的痛点——错误处理和信任修复。其创新之处在于通过受控实验量化了用户对不同道歉策略的偏好，并揭示了情境和错误类型对偏好的影响。研究结果为未来AI系统设计更人性化、更有效的错误恢复机制提供了宝贵的指导，特别是在个性化道歉方面具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）驱动的聊天机器人越来越多地应用于日常生活中，它们通过有效道歉从错误中恢复的能力对于维持用户信任和满意度至关重要。

**Method:** 研究通过一项预注册研究，招募了162名参与者。设计了一个成对比较实验，参与者评估了聊天机器人对三种常见LLM错误（偏见、无根据的捏造和事实错误）的回应，包括初始错误、随后的道歉和解决方案。研究比较了程式化、解释性和移情三种道歉类型。

**Result:** 解释性道歉普遍受到青睐，但这种偏好因情境和用户而异。在偏见情境中，移情道歉因承认情感影响而更受青睐。对于幻觉错误，尽管被认为是严重的，但没有明确的偏好，反映了用户的不确定性。

**Conclusion:** 研究结果揭示了AI系统中有效道歉的复杂性。未来的系统需要关注个性化和校准，以有意义地修复信任。

> **ai_Abstract:** 本研究调查了用户对大型语言模型（LLM）聊天机器人道歉方式的偏好，以期在机器人犯错后有效恢复用户信任和满意度。研究通过一项包含162名参与者的实验，比较了程式化、解释性和移情三种道歉类型在处理偏见、捏造和事实错误时的效果。结果显示，解释性道歉普遍更受欢迎，但具体偏好因情境和用户而异，例如在偏见情境中移情道歉表现更好。研究强调了AI系统有效道歉的复杂性，并提出了个性化和校准对于未来系统修复信任的重要性。

> **摘要翻译:** 随着大型语言模型（LLM）驱动的聊天机器人越来越多地应用于日常生活中，它们通过有效道歉从错误中恢复的能力对于维持用户信任和满意度至关重要。在一项针对Prolic工人进行的预注册研究中（N=162），我们调查了用户对三种道歉类型（程式化、解释性、移情）的偏好，这些道歉是针对三种常见LLM错误类别（偏见、无根据的捏造和事实错误）发出的。我们设计了一个成对实验，参与者评估了聊天机器人的回应，其中包括初始错误、随后的道歉和解决方案。解释性道歉普遍受到青睐，但这种偏好因情境和用户而异。在偏见情境中，移情道歉因承认情感影响而更受青睐，而幻觉错误，尽管被认为是严重的，却没有引起明确的偏好，这反映了用户的不确定性。我们的发现揭示了AI系统中有效道歉的复杂性。我们讨论了未来系统必须解决的关键见解，例如个性化和校准，以有意义地修复信任。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [285] [Time-Masked Transformers with Lightweight Test-Time Adaptation for Neural Speech Decoding](https://arxiv.org/abs/2507.02800)
> *时间掩蔽Transformer与轻量级测试时自适应用于神经语音解码*

*Ebrahim Feghhi, Shreyas Kaasyap, Nima Hadidi, Jonathan C. Kao* | **Category: cs.HC** | **Updated: {updated}**

**Keywords:** 神经语音解码, Transformer, 时间掩蔽, 测试时自适应, 实时解码

**Comment:** 10 pages, 4 figures

> **TL;DR:** 本文提出了时间掩蔽Transformer和轻量级测试时自适应方法，显著提高了神经语音解码的准确性、效率，并降低了计算成本，为实时神经语音解码铺平了道路。

**AI_Comments:** 该论文的创新点在于其结合了时间掩蔽、高效的Transformer架构以及轻量级测试时自适应，解决了神经语音解码在实际应用中面临的效率和实时性挑战。其贡献不仅在于提升了解码性能，更在于显著降低了计算资源需求，这对于神经假肢设备走向实用化具有重要意义。该研究为未来神经假肢的开发提供了重要的技术支撑。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经语音解码算法虽然取得了显著的准确性提升，但计算成本随之增加，并且这些提升尚未在实时解码环境中得到验证，这阻碍了神经语音假肢的进一步发展。

**Method:** 本文提出了三项贡献：1. 在训练过程中引入大量时间掩蔽，平均超过50%的试验被掩蔽。2. 将基线算法中使用的门控循环单元（GRU）架构替换为紧凑型Transformer。3. 设计了一种轻量级的测试时自适应变体，该变体利用单次试验的多个时间掩蔽增强来适应模型，并且每个试验仅需一个梯度步。

**Result:** 这些贡献共同将词错误率降低了19.5%，在实时解码设置中有效缓解了跨保留日期的性能下降，并大幅降低了计算成本（Transformer参数减少77%，峰值GPU内存使用量相对减少36%）。

**Conclusion:** 本文提出的时间掩蔽Transformer和轻量级测试时自适应方法为实现准确、高效和实时的神经语音解码奠定了基础，显著降低了计算成本并提高了性能。

> **ai_Abstract:** 本文针对神经语音解码中现有方法计算成本高且非实时的问题，提出了三项创新。首先，在训练中引入大量时间掩蔽以增强模型鲁棒性；其次，用更紧凑、高效的Transformer取代了传统的GRU架构，显著降低了计算资源消耗；最后，设计了一种轻量级的测试时自适应方法，通过单次试验的增强实现高效模型调整。这些改进共同将词错误率降低19.5%，有效缓解了实时解码中的性能下降，并大幅降低了计算成本，为实现准确、高效和实时的神经语音解码奠定了基础。

> **摘要翻译:** 语音神经假肢旨在通过直接从神经活动中解码语音，为重度瘫痪患者恢复交流能力。为了加速算法进展，最近的一项基准测试发布了来自一名瘫痪参与者尝试说话的颅内记录，以及一个基线解码算法。先前关于该基准的工作显示出令人印象深刻的准确性提升。然而，这些提升增加了计算成本，并且未在实时解码环境中得到验证。在此，我们做出了三项贡献，为准确、高效和实时的神经语音解码铺平了道路。首先，我们在训练期间引入了大量时间掩蔽。平均而言，超过50%的每个试验都被掩蔽。其次，我们将基线算法中使用的门控循环单元（GRU）架构替换为紧凑型Transformer。与GRU相比，Transformer架构使用的参数减少了77%，峰值GPU内存使用量减少了36%，并且校准速度显著加快。第三，我们设计了一种现有测试时自适应方法的轻量级变体，该方法最初是为从神经活动中解码手写而开发的。我们的变体使用单个试验的多个时间掩蔽增强来适应模型，并且每个试验仅需要一个梯度步。总而言之，这些贡献将词错误率降低了19.5%，并在实时解码设置中有效缓解了跨保留日期的性能下降，同时大幅降低了计算成本。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [5] [How do Software Engineering Candidates Prepare for Technical Interviews?](https://arxiv.org/abs/2507.02068)
> *软件工程求职者如何准备技术面试？*

*Brian Bell, Teresa Thomas, Sang Won Lee, Chris Brown* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 技术面试, 软件工程, 求职准备, 调查, 教育支持

**Comment:** 

> **TL;DR:** 调查显示软件工程求职者在技术面试准备中面临挑战，很少在真实环境中训练，且课程支持不足，导致压力和准备不足。

**AI_Comments:** 这篇论文揭示了软件工程技术面试准备中的一个重要痛点，即现有教育体系与实际面试需求之间存在脱节。其创新之处在于通过大规模调查量化了这一问题，并为改进面试准备提供了具体建议，对求职者和教育机构都具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 软件工程技术面试复杂且在计算机课程中不常见，导致求职者难以准备。本研究旨在理解求职者如何准备技术面试，并调查准备方法的效果和教育的作用。

**Method:** 通过向131名正在积极准备技术面试的求职者分发调查问卷。

**Result:** 调查结果表明求职者很少在真实环境中训练，且课程未能有效支持准备工作，导致压力和准备不足。

**Conclusion:** 基于研究结果，论文为利益相关者提供了建议，以改进软件工程求职者的技术面试准备。

> **ai_Abstract:** 本研究旨在探讨软件工程求职者如何准备技术面试，因为该过程复杂且现有教育支持不足。通过对131名求职者进行调查，结果显示他们很少在真实环境中训练，且现有课程未能提供足够的准备支持，导致求职者感到压力和准备不足。论文根据这些发现，为相关方提供了改进技术面试准备的建议。

> **摘要翻译:** 为了获得工作，有抱负的软件工程师必须完成技术面试——这是一个涉及求职者在与听众交流的同时编写代码的招聘过程。然而，技术面试的复杂性很难准备，并且在计算机课程中很少遇到。为此，我们旨在了解求职者如何准备技术面试，调查准备方法的效果和教育的作用。我们向131名正在积极准备技术面试的求职者分发了一项调查。我们的结果表明，求职者很少在真实环境中训练，并且课程未能支持准备工作——导致压力和准备不足。根据我们的发现，我们为利益相关者提供了建议，以加强追求软件工程角色的求职者的技术面试准备。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [34] [Structural Code Search using Natural Language Queries](https://arxiv.org/abs/2507.02107)
> *使用自然语言查询的结构化代码搜索*

*Ben Limpanukorn, Yanjun Wang, Zach Patterson, Pranav Garg, Murali Krishna Ramanathan, Xiaofei Ma, Anoop Deoras, Miryung Kim* | **Category: cs.SE, cs.PL** | **Updated: {updated}**

**Keywords:** 结构化代码搜索, 自然语言查询, 大型语言模型, 领域特定语言, 代码检索

**Comment:** 

> **TL;DR:** 本文提出了一种利用大型语言模型（LLM）将自然语言查询转换为领域特定语言（DSL）查询的方法，以实现结构化代码搜索，显著提高了搜索的有效性和鲁棒性。

**AI_Comments:** 本文的创新点在于将自然语言处理能力（LLM）与结构化代码搜索的精确性相结合，有效解决了传统结构化代码搜索工具DSL学习曲线陡峭的问题。通过将自然语言查询转化为DSL查询，该方法显著降低了技术门槛，使得更广泛的开发者能够利用结构化搜索的强大功能。其在性能上的显著提升也证明了该方法的有效性和实用性，对于代码理解、重构和缺陷查找等任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发者在搜索代码时，通常使用关键词和正则表达式，但这些方法无法进行结构化搜索。现有的结构化代码搜索工具（如Semgrep和GQL）虽然功能强大，但其查询语言（DSL）学习和编写困难，提高了使用门槛。因此，研究的动机是允许开发者使用更直观的自然语言进行结构化代码搜索。

**Method:** 本文提出了一种新颖的通用方法，结合LLM的推理能力来解释自然语言搜索查询，并利用结构化搜索工具高效准确地检索相关代码。该方法将自然语言查询翻译成DSL查询。作者将此方法应用于两种结构化代码搜索DSL：Semgrep和GQL。为了评估，构建了一个包含400个查询的新基准，涵盖10个Java项目。

**Result:** 该方法在结构化代码搜索中表现出有效性和鲁棒性，查准率和查全率在55%至70%之间。与基于语义代码搜索和LLM检索的基线相比，该方法在F1分数上分别高出57%和14%。

**Conclusion:** 本文提出的基于LLM将自然语言查询转换为DSL查询的结构化代码搜索方法是有效且鲁棒的，显著优于现有基线，降低了结构化代码搜索的使用门槛。

> **ai_Abstract:** 本文提出了一种创新的结构化代码搜索方法，旨在通过允许开发者使用自然语言查询来克服现有DSL工具的学习障碍。该方法利用大型语言模型（LLM）将自然语言查询转换为特定领域语言（DSL）的结构化查询，并已在Semgrep和GQL上实现。在对10个Java项目上的400个查询进行评估后，该方法展现出55%-70%的高查准率和查全率，并且在F1分数上显著优于传统语义代码搜索和LLM检索基线，最高提升达57%。这极大地简化了结构化代码搜索的流程，提高了其可用性。

> **摘要翻译:** 搜索代码是开发人员理解API、学习常见代码模式和导航代码的常见任务。目前，开发人员最常使用易于使用且广泛可用的关键词和正则表达式进行搜索。除了关键词和正则表达式，结构化代码搜索工具允许开发人员根据其句法结构搜索代码。这在从错误查找系统到系统重构代码方面都有许多应用。然而，这些结构化代码搜索工具操作的查询是以领域特定语言（DSL）表达的，这些语言可能难以学习和编写。我们建议允许开发人员使用自然语言进行结构化代码搜索。用自然语言表达查询提供了一种直观的方式来搜索代码并降低了入门门槛。
在这项工作中，我们开发了一种新颖的通用方法，该方法结合了LLM的推理能力来解释自然语言搜索查询，以及结构化搜索工具的能力，以高效准确地检索相关代码。然后，我们将此方法应用于两种结构化代码搜索DSL：Semgrep和GQL。在我们的评估中，我们构建了一个新的结构化代码搜索基准，包含10个Java项目上的400个查询。我们表明，我们基于使用LLM将NL查询翻译为DSL查询的结构化代码搜索方法是有效且鲁棒的，查准率和查全率在55%-70%之间。此外，我们的方法在F1分数上比基于语义代码搜索和LLM检索的基线分别高出57%和14%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [61] [Can Internal Software Metrics Predict App Popularity at Launch? Yeas! and Nays!](https://arxiv.org/abs/2507.02110)
> *内部软件度量能否预测应用程序发布时的流行度？肯定！和否定！*

*Md Nahidul Islam Opu, Fatima Islam Mouri, Rick Kazman, Yuanfang Cai, Shaiful Chowdhury* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 内部软件度量, 应用流行度, 预测, 分类, Android应用

**Comment:** 

> **TL;DR:** 研究发现，内部代码度量在二元分类任务中可以预测应用程序的流行度，尽管在回归任务中表现不佳，这挑战了早期关于内部度量无用的观点。

**AI_Comments:** 该研究的创新之处在于重新审视了内部软件度量在预测应用流行度方面的潜力，尤其是在将其转换为分类问题后取得了显著效果。这挑战了传统观点，为开发者提供了新的视角来评估应用发布前的潜在表现。局限性在于回归模型的表现不佳以及内部度量解释力的有限性。

<details>
  <summary>Details</summary>

**Motivation:** 在竞争激烈的市场中，在发布前预测移动应用程序的流行度可以为开发者提供战略优势，但它仍然是一个具有挑战性的问题。

**Method:** 本研究探索了从源代码中可测量的内部软件度量能否预测应用程序流行度（通过用户评分和DownloadsPerYear定义）。使用了来自F-Droid的446个开源Android应用程序数据集，提取了广泛的特征，包括系统、类和方法级别的代码度量、代码异味以及应用程序元数据。额外信息如用户评论、下载计数和uses-permission从Google Play Store收集。评估了回归和分类模型，使用了三种特征集：一个最小的仅大小基线、一个领域知情的精选集和一个通过特征选择算法得出的投票集。

**Result:** 回归模型由于数据偏斜而表现不佳，R^2分数较低。然而，当重新定义为二元分类（流行 vs. 不流行）时，结果显著改善。最佳模型是使用投票集的多层感知器，F1分数达到0.72。

**Conclusion:** 这些结果表明，内部代码度量虽然解释力有限，但可以作为应用程序流行度的有用指标。这挑战了早期驳斥内部度量作为软件质量预测指标的发现。

> **ai_Abstract:** 本研究探讨了内部软件度量（如代码度量、代码异味和元数据）能否预测移动应用程序的流行度。研究使用了F-Droid的446个开源Android应用数据，并从Google Play Store补充了用户评论和下载数据。结果显示，尽管回归模型表现不佳，但当问题转化为二元分类（流行 vs. 不流行）时，预测效果显著提升。最佳模型为多层感知器，F1分数为0.72。研究指出，内部代码度量可作为应用程序流行度的有用指标，并挑战了此前认为内部度量对软件质量预测无效的观点。

> **摘要翻译:** 在发布前预测移动应用程序的流行度可以在竞争激烈的市场中为开发者提供战略优势，但它仍然是一个具有挑战性的问题。本研究探讨了内部软件度量（可在部署前从源代码中测量）是否能够预测应用程序的流行度，流行度由用户评分（根据用户评论计算）和DownloadsPerYear（年度下载量）定义。我们使用来自F-Droid的446个开源Android应用程序数据集，提取了广泛的特征，包括系统、类和方法级别的代码度量、代码异味以及应用程序元数据。其他信息，如用户评论、下载计数和uses-permission，是从Google Play Store收集的。我们评估了三种特征集下的回归和分类模型：一个最小的仅大小基线、一个领域知情的精选集以及一个通过特征选择算法得出的投票集。回归模型由于数据偏斜而表现不佳，R^2分数较低。然而，当重新定义为二元分类（流行 vs. 不流行）时，结果显著改善。最佳模型是使用投票集的多层感知器，F1分数达到0.72。这些结果表明，内部代码度量虽然解释力有限，但可以作为应用程序流行度的有用指标。这挑战了早期驳斥内部度量作为软件质量预测指标的发现。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [85] [A Multimodal Approach Combining Biometrics and Self-Report Instruments for Monitoring Stress in Programming: Methodological Insights](https://arxiv.org/abs/2507.02118)
> *编程中结合生物识别和自我报告工具监测压力的多模态方法：方法学见解*

*Cristina Martinez Montes, Daniela Grassi, Nicole Novielli, Birgit Penzenstadle* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 编程压力, 生物识别, 自我报告, 多模态, 方法学见解

**Comment:** 

> **TL;DR:** 本研究结合生物识别和自我报告工具监测编程压力，发现所选的压力诱导方法不足以产生显著压力，并提供了未来研究的方法学见解。

**AI_Comments:** 这篇论文通过结合多模态数据（自我报告与生物识别）来监测编程中的压力，其创新性在于尝试克服传统自我报告的局限性。尽管其压力诱导方法未能成功产生预期效果，但其提供的“方法学见解”对于未来在类似复杂认知任务中研究压力具有重要指导意义，尤其是在实验设计和生理指标选择方面。

<details>
  <summary>Details</summary>

**Motivation:** 传统上对幸福感、压力等人为因素的研究主要依赖自我报告工具，但其潜在偏差促使研究者寻求结合生理测量等更客观方法进行评估的替代方案。

**Method:** 研究进行了一项实验，参与者首先完成了一份预调查，然后佩戴生物识别传感器完成两项编程任务，每项任务后进行简短的调查，最后进行了一次简短的离职面谈。

**Result:** 结果多样。心理测量工具未显示压力。访谈中，参与者报告了无压力和时间压力并存的情况。生物识别数据显示仅EDA相位峰值存在显著差异。

**Conclusion:** 研究得出结论，通过施加更严格的时间限制来诱导压力的方法不足。本研究为未来关于压力、生物识别和心理测量工具的研究提供了方法学见解。

> **ai_Abstract:** 本文探讨了在编程任务中结合生物识别和自我报告工具监测压力的方法。研究旨在比较心理测量和生物识别压力指标，并识别生物识别数据中的压力模式。实验中，参与者在编程时佩戴生物识别传感器，并辅以问卷和访谈。结果显示，心理测量工具未检测到压力，而生物识别数据仅在EDA相位峰值上显示显著差异。研究发现，通过时间限制诱导压力的方法效果不佳，并为未来多模态压力研究提供了方法学建议。

> **摘要翻译:** 对幸福感、压力和其他人为因素的研究传统上依赖自我报告工具来评估关键变量。然而，即使经过彻底验证和标准化，这些工具中潜在的偏见也引起了人们对将其与更客观的方法（如生理测量）相结合的替代方案的日益增长的兴趣。
我们的目标是（一）比较心理压力测量和生物识别指标，以及（二）识别软件工程任务中生物识别数据中与压力相关的模式。
我们进行了一项实验，参与者完成了一项预调查，然后佩戴生物识别传感器编程两项任务，每项任务后回答简短的后期调查，最后进行了一次简短的离职访谈。
我们的结果显示出多样化的结果；我们发现心理测量工具中没有压力。访谈中的参与者报告了既没有压力又感受到时间压力的混合情况。最后，生物识别数据显示仅EDA相位峰值存在显著差异。
我们得出结论，我们选择的通过施加更严格的时间限制来诱导压力的方式是不够的。我们为未来关于压力、生物识别和心理测量工具的研究提供了方法学见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [109] [Towards Trustworthy Sentiment Analysis in Software Engineering: Dataset Characteristics and Tool Selection](https://arxiv.org/abs/2507.02137)
> *软件工程中可信情感分析：数据集特性与工具选择*

*Martin Obaidi, Marc Herrmann, Jil Klünder, Kurt Schneider* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 情感分析, 软件工程, 数据集特性, 工具选择, 可信赖AI

**Comment:** This paper has been accepted at the RETRAI workshop of the 33rd IEEE
  International Requirements Engineering Conference (REW 2025)

> **TL;DR:** 该论文分析了软件工程中情感分析工具在不同数据集上的表现，并提出了一种基于数据集特性推荐工具的方法，指出工具性能受上下文影响，尽管Transformer模型表现良好。

**AI_Comments:** 该论文通过关注数据集特性来解决软件工程中情感分析工具应用的常见问题，提供了一个实用的解决方案。其对上下文依赖性和持续评估的强调对于实际应用非常重要，所提出的映射方法可能是一项有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发中，情感分析是理解团队动态和支持可信AI分析的重要工具，但现有情感分析工具在不同数据集上表现不一致，因为沟通风格和内容存在差异，因此需要一种方法来选择可信赖的工具。

**Method:** 本研究分析了来自五个平台的10个开发者交流数据集的语言和统计特征，并评估了14种情感分析工具的性能。在此基础上，提出了一种映射方法和问卷，根据新数据集的特征推荐合适的情感分析工具。

**Result:** 结果表明，数据集特性可以用来改进工具选择，因为不同平台在语言和统计特性上存在显著差异。尽管基于Transformer的模型（如SetFit和RoBERTa）持续取得良好结果，但工具的有效性仍然依赖于上下文。

**Conclusion:** 所提出的方法支持研究人员和从业者在软件工程中选择可信赖的情感分析工具，并强调随着交流环境的发展，持续评估的必要性。

> **ai_Abstract:** 该论文旨在解决软件工程中情感分析工具在不同数据集上表现不一致的问题。研究分析了10个开发者交流数据集的语言和统计特征，并评估了14种情感分析工具的性能。基于此，提出了一种映射方法和问卷，根据数据集特性推荐合适的情感分析工具。研究结果表明，数据集特性对于工具选择至关重要，且尽管Transformer模型表现良好，但工具效果仍具有上下文依赖性，强调了持续评估的重要性。

> **摘要翻译:** 软件开发严重依赖基于文本的交流，这使得情感分析成为理解团队动态和支持需求工程中可信赖的AI驱动分析的宝贵工具。然而，由于交流风格和内容的变化，现有情感分析工具在不同平台的数据集上表现往往不一致。
在本研究中，我们分析了来自五个平台的10个开发者交流数据集的语言和统计特征，并评估了14种情感分析工具的性能。基于这些结果，我们提出了一种映射方法和问卷，该方法和问卷利用数据集的特征作为输入，为新数据集推荐合适的情感分析工具。
我们的结果表明，数据集特性可以用于改进工具选择，因为不同平台在语言和统计特性上存在显著差异。尽管基于Transformer的模型（如SetFit和RoBERTa）持续取得良好结果，但工具的有效性仍然依赖于上下文。我们的方法支持研究人员和从业者在软件工程中选择可信赖的情感分析工具，同时强调随着交流环境的发展，持续评估的必要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [134] [Enhancing COBOL Code Explanations: A Multi-Agents Approach Using Large Language Models](https://arxiv.org/abs/2507.02182)
> *增强COBOL代码解释：一种使用大型语言模型的多智能体方法*

*Fangjian Lei, Jiawen Liu, Shayan Noei, Ying Zou, Derek Truong, William Alexander* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** COBOL, 大型语言模型, 代码解释, 多智能体系统, 遗留系统

**Comment:** 

> **TL;DR:** 本文提出了一种多智能体方法，利用大型语言模型（LLMs）协作生成COBOL代码解释，有效解决了传统LLMs在处理COBOL复杂性和代码长度方面的局限性，并在函数、文件和项目级别展示了显著的解释能力提升。

**AI_Comments:** 这项研究的创新之处在于提出了一个多智能体框架来解决大型语言模型在处理COBOL这种历史悠久且语法独特的语言时所面临的令牌窗口限制问题。通过智能体间的协作和上下文信息的利用，该方法有效地提升了COBOL代码解释的准确性和完整性，对于维护和理解现有COBOL系统具有重要意义。该工作展示了LLMs在传统编程语言现代化和维护方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** COBOL作为一种广泛应用于金融、商业和政府机构的编程语言，由于其年代久远、复杂性高以及COBOL开发人员数量下降，维护COBOL代码库变得日益困难。特别是缺乏文档使得新开发人员难以有效理解和维护COBOL系统。现有研究利用大型语言模型（LLMs）解释代码功能，但COBOL的架构和语法差异导致其代码经常超出LLMs的令牌窗口大小，构成了独特的挑战。

**Method:** 本文提出了一种多智能体方法，该方法利用两个基于大型语言模型的智能体协同工作，为函数、文件和整个项目生成解释。这些智能体通过将代码库中的上下文信息整合到代码解释提示中来协同工作。

**Result:** 在函数代码解释方面，我们的方法在METEOR、chrF和SentenceBERT分数上分别比基线提高了12.67%、18.59%和0.62%。在文件级别，我们的方法有效解释了超出LLM令牌窗口大小的长短COBOL文件，并且在解释目的、功能和生成解释的清晰度方面分别超越基线4.21%、10.72%和14.68%。在项目级别，我们的方法为82%的选定项目生成了能够传达其功能和目的的解释。

**Conclusion:** 本文提出的多智能体方法能够显著提升COBOL代码的解释效果，尤其是在处理长文件和复杂项目时表现出色，有效解决了大型语言模型在COBOL代码解释方面的局有局限性。

> **ai_Abstract:** 本研究提出了一种多智能体方法，旨在利用大型语言模型（LLMs）增强COBOL代码的解释能力，以应对COBOL代码库维护中因其复杂性、缺乏文档以及LLMs令牌窗口限制所带来的挑战。该方法通过两个LLM智能体的协作，将上下文信息融入解释提示中，从而为函数、文件和整个项目生成解释。实验结果表明，该方法在函数、文件和项目级别的解释效果均显著优于基线，特别是在处理超出LLM令牌窗口大小的COBOL文件时表现出色。

> **摘要翻译:** 通用商业导向语言（COBOL）是一种用于开发商业应用程序的编程语言，被金融、商业和政府机构广泛采用。由于其年代久远、复杂性以及COBOL开发人员数量的下降，维护COBOL代码库变得越来越具有挑战性。特别是缺乏文档使得新开发人员难以有效理解和维护COBOL系统。现有研究利用大型语言模型（LLMs）来解释代码片段的功能。然而，COBOL由于其架构和语法差异带来了独特的挑战，这常常导致其代码超出LLMs的令牌窗口大小。在这项工作中，我们提出了一种多智能体方法，该方法利用两个基于LLM的智能体协同工作，为函数、文件和整个项目生成解释。这些智能体通过将代码库中的上下文信息整合到代码解释提示中来协同工作。我们使用14个开源的真实COBOL项目评估了我们方法的有效性。我们的结果表明，我们的方法在函数代码解释方面显著优于基线，在METEOR、chrF和SentenceBERT分数上分别提高了12.67%、18.59%和0.62%。在文件级别，我们的方法有效解释了超出LLM令牌窗口大小的长短COBOL文件，并且在解释目的、功能和生成解释的清晰度方面分别超越基线4.21%、10.72%和14.68%。在项目级别，我们的方法为82%的选定项目生成了能够传达其功能和目的的解释。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [155] [Precisely Detecting Python Type Errors via LLM-based Unit Test Generation](https://arxiv.org/abs/2507.02318)
> *通过基于LLM的单元测试生成精确检测Python类型错误*

*Chen Yang, Ziqi Wang, Yanjie Jiang, Lin Yang, Yuteng Zheng, Jianyi Zhou, Junjie Chen* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** Python类型错误检测, 单元测试生成, 误报抑制, 类型约束分析, RTED

**Comment:** 

> **TL;DR:** RTED是一种新的类型感知测试生成技术，通过结合类型约束分析和反射验证，能更精确地检测Python类型错误，并显著减少误报。

**AI_Comments:** 本文的创新点在于将类型约束分析与反射验证相结合，以提高单元测试在检测Python类型错误方面的有效性和精确性，特别是解决了传统静态分析误报率高以及现有测试生成技术难以产生揭示错误测试的问题。其在真实项目中的新错误发现能力也突显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** Python中的类型错误常导致运行时故障，影响软件可靠性和开发效率。现有静态分析工具误报率高，而单元测试生成技术难以在无定制指导下生成揭示错误的测试。

**Method:** 提出RTED，一种新颖的类型感知测试生成技术，用于自动检测Python类型错误。RTED结合了逐步类型约束分析和反射验证，以指导测试生成过程并有效抑制误报。

**Result:** 在BugsInPy和TypeBugs两个基准测试上，RTED比四种现有技术多检测出22-29个类型错误。RTED的误报率更低，精度提升了173.9%-245.9%。此外，RTED成功从六个真实世界开源Python项目中发现了12个先前未知的类型错误。

**Conclusion:** RTED是一种有效且精确的Python类型错误检测工具，能够显著提高检测能力并减少误报。

> **ai_Abstract:** 本文提出RTED，一种用于精确检测Python类型错误的类型感知测试生成技术。RTED通过结合逐步类型约束分析和反射验证来指导测试生成，有效抑制误报。实验证明，RTED在基准测试中比现有技术能检测更多类型错误，并显著提高精度，同时还发现了真实世界项目中的新错误。

> **摘要翻译:** Python中的类型错误常常导致运行时故障，对软件可靠性和开发人员生产力构成重大挑战。现有静态分析工具旨在不执行代码的情况下检测此类错误，但经常遭受高误报率的困扰。最近，单元测试生成技术在实现高测试覆盖率方面展现出巨大潜力，但它们通常难以在没有定制指导的情况下生成揭示错误的测试。为了解决这些局限性，我们提出了RTED，一种新颖的类型感知测试生成技术，用于自动检测Python类型错误。具体而言，RTED结合了逐步类型约束分析和反射验证来指导测试生成过程并有效抑制误报。我们在两个广泛使用的基准测试BugsInPy和TypeBugs上评估了RTED。实验结果表明，RTED比四种最先进的技术多检测出22-29个基准类型错误。RTED还能够产生更少的误报，精度提高了173.9%-245.9%。此外，RTED成功地从六个真实世界的开源Python项目中发现了12个以前未知的类型错误。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [165] [VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software](https://arxiv.org/abs/2507.02376)
> *VeFIA：一个高效的垂直联邦协作软件推理审计框架*

*Chung-ju Huang, Ziqi Zhang, Yinggui Wang, Binghui Wang, Tao Wei, Leye Wang* | **Category: cs.SE, cs.AI, cs.DC** | **Updated: {updated}**

**Keywords:** 垂直联邦学习, 推理审计, 可信执行环境, 数据隐私, 执行正确性

**Comment:** 

> **TL;DR:** VeFIA是一个高效的框架，用于在垂直联邦学习中审计推理执行的正确性，同时不泄露数据隐私或引入额外延迟。

**AI_Comments:** VeFIA的创新之处在于它是第一个在垂直联邦学习中解决推理软件执行正确性审计问题的框架，填补了VFL部署中的关键空白。其重要性在于提升了VFL系统的可信赖性和可靠性，这对于其在隐私敏感领域的实际应用至关重要。抽象中未提及潜在的开销、具体的TEE实现细节以及5.4%异常阈值的确定方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有垂直联邦学习（VFL）工作缺乏一种机制来审计数据方推理软件的执行正确性。

**Method:** 设计了垂直联邦推理审计（VeFIA）框架。VeFIA的核心是任务方利用来自可信执行环境（TEE）框架和协调器的推理结果来验证数据方计算结果的正确性，并采用随机抽样验证。

**Result:** VeFIA能够以99.99%的概率检测到推理软件中的执行异常，只要异常推理超过5.4%，且不产生任何额外的在线推理延迟。在检测异常推理方面，实现了100%的阳性预测值、阴性预测值和真阳性率。

**Conclusion:** VeFIA是首个讨论垂直联邦学习中推理软件执行正确性的框架，它提供了一种高效、私密且准确的审计机制，且不增加延迟。

> **ai_Abstract:** 本文介绍了VeFIA，一个新颖的框架，旨在审计垂直联邦学习（VFL）中推理软件的执行正确性。针对现有VFL解决方案中缺乏此类机制的问题，VeFIA允许任务方在不损害数据隐私或增加延迟的情况下验证数据方的推理。它利用可信执行环境（TEE）和协调器来验证结果，通过随机抽样实现了高异常检测率（对于超过5.4%的异常，检测率达99.99%）以及异常推理检测的100%预测值，标志着VFL研究的一个重要开端。

> **摘要翻译:** 垂直联邦学习 (VFL) 是一种分布式 AI 软件部署机制，用于跨孤岛协作，无需访问参与者的数据。然而，现有 VFL 工作缺乏一种机制来审计数据方推理软件的执行正确性。为了解决这个问题，我们设计了一个垂直联邦推理审计 (VeFIA) 框架。VeFIA 帮助任务方在不泄露数据方数据隐私或不对推理系统引入额外延迟的情况下，在大规模推理期间审计数据方的推理软件是否按预期执行。VeFIA 的核心是任务方可以利用来自可信执行环境 (TEE) 框架和协调器的推理结果来验证数据方计算结果的正确性。VeFIA 保证，只要异常推理超过 5.4%，任务方就能以 99.99% 的概率检测到推理软件中的执行异常，而不会产生任何额外的在线推理延迟。VeFIA 的随机抽样验证在检测异常推理方面实现了 100% 的阳性预测值、阴性预测值和真阳性率。据我们所知，这是第一篇讨论 VFL 中推理软件执行正确性的论文。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [194] [Meta-Fair: AI-Assisted Fairness Testing of Large Language Models](https://arxiv.org/abs/2507.02533)
> *Meta-Fair：AI辅助的大语言模型公平性测试*

*Miguel Romero-Arjona, José A. Parejo, Juan C. Alonso, Ana B. Sánchez, Aitor Arrieta, Sergio Segura* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 公平性测试, 大语言模型, 变异测试, 自动化, 偏见检测

**Comment:** 

> **TL;DR:** Meta-Fair提出了一种AI辅助的自动化方法，通过变异测试和利用LLM进行测试用例生成及评估，有效检测大语言模型中的偏见。

**AI_Comments:** 这项工作通过引入AI辅助的自动化方法来解决LLM公平性测试中的关键挑战，具有创新性。其将变异测试与LLM的生成和评估能力相结合，显著提高了测试的效率和可扩展性，减少了对人工和特定领域资源的依赖。虽然非确定性影响仍需解决，但该研究为LLM测试的未来自动化奠定了坚实基础，对提高AI系统的公平性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型公平性测试方法依赖于手动评估、固定模板、确定性启发式和精选数据集，导致资源密集且难以扩展，无法有效评估和强制执行公平性。

**Method:** 本研究提出了Meta-Fair方法，旨在自动化LLM的公平性测试。它基于两个核心思想：1. 采用变异测试，通过检查模型输出如何响应输入提示的受控修改（由变异关系定义）来揭示偏见。2. 利用LLM进行测试用例生成和输出评估，发挥其生成多样化输入和有效分类输出的能力。此外，还提供了三个支持LLM驱动的测试用例生成、执行和评估的开源工具。

**Result:** Meta-Fair在检测LLM偏见方面是有效的，平均精度达到92%，并在29%的执行中揭示了偏见行为。LLM被证明是可靠且一致的评估器，表现最佳的模型F1分数高达0.79。尽管非确定性影响一致性，但通过仔细设计变异关系可以减轻这些影响。

**Conclusion:** Meta-Fair为LLM测试中前所未有的自动化水平提供了一条有前景的路径，尽管在确保更广泛适用性方面仍存在挑战，但其结果表明了在自动化公平性测试方面的巨大潜力。

> **ai_Abstract:** Meta-Fair提出了一种新颖的自动化方法，用于大语言模型（LLM）的公平性测试，旨在解决现有手动和资源密集型方法的局限性。该方法结合了变异测试，通过受控输入修改来检测偏见，并利用LLM自身进行测试用例生成和结果评估。实验结果表明，Meta-Fair能够有效识别LLM中的偏见，并展示了LLM作为评估器的可靠性，为LLM公平性测试的自动化提供了有前景的方向。

> **摘要翻译:** 公平性——没有不合理偏见——是人工智能（AI）系统开发中的核心原则，但它仍然难以评估和执行。当前大语言模型（LLM）中的公平性测试方法通常依赖于手动评估、固定模板、确定性启发式和精选数据集，这使得它们资源密集且难以扩展。这项工作旨在为一种新颖的、自动化的大语言模型公平性测试方法奠定基础，减少对特定领域资源的依赖，并拓宽当前方法的适用性。我们的方法Meta-Fair基于两个关键思想。首先，我们采用变异测试，通过检查模型输出如何响应输入提示的受控修改（由变异关系（MRs）定义）来揭示偏见。其次，我们建议利用大语言模型在测试用例生成和输出评估方面的潜力，发挥它们生成多样化输入和有效分类输出的能力。该提案辅以三个开源工具，支持LLM驱动的测试用例生成、执行和评估。我们报告了涉及12个预训练LLM、14个MR、5个偏见维度和7.9K个自动生成测试用例的几项实验结果。结果表明，Meta-Fair在揭示LLM中的偏见方面是有效的，平均精度达到92%，并在29%的执行中揭示了偏见行为。此外，LLM被证明是可靠且一致的评估器，表现最佳的模型F1分数高达0.79。尽管非确定性影响一致性，但通过仔细的MR设计可以减轻这些影响。虽然确保更广泛适用性仍面临挑战，但这些结果表明了LLM测试中前所未有的自动化水平的一条有前景的路径。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [206] [LLMREI: Automating Requirements Elicitation Interviews with LLMs](https://arxiv.org/abs/2507.02564)
> *LLMREI：使用大型语言模型自动化需求启发式访谈*

*Alexander Korn, Samuel Gorsch, Andreas Vogelsang* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 需求启发, 大型语言模型, 自动化访谈, LLMREI, 聊天机器人

**Comment:** 

> **TL;DR:** LLMREI是一个基于LLM的聊天机器人，旨在自动化需求启发式访谈，减少人为错误，并提高可扩展性。它在模拟访谈中表现出与人类相似的错误率，能提取大量需求，并能生成上下文相关的提问。

**AI_Comments:** LLMREI的创新之处在于利用LLM自动化传统上高度依赖人工技能的需求启发访谈，有望解决效率和可扩展性问题。其重要性在于为软件工程领域提供了新的自动化工具，尤其是在处理大量利益相关者时具有显著潜力。论文放弃了微调而转向提示工程，这表明在特定任务中，精心设计的提示可能比微调更有效或更易于实现预期效果。

<details>
  <summary>Details</summary>

**Motivation:** 需求启发式访谈资源密集、易受人类偏见影响且易发生沟通不畅，而大型语言模型为自动化该过程提供了新机会。

**Method:** 本研究引入了LLMREI聊天机器人，旨在以最少的人工干预进行需求启发式访谈。探索了零样本提示和最少到最多提示两种方法，并在33次模拟利益相关者访谈中评估了其性能。微调方法因初步试验表现不佳而被放弃。

**Result:** LLMREI与人类面试官犯的错误数量相似，能够提取大部分需求，并表现出生成高度依赖上下文问题的显著能力。

**Conclusion:** LLMREI的最大益处在于自动化与大量利益相关者的访谈。

> **ai_Abstract:** 本文介绍了LLMREI，一个基于大型语言模型（LLM）的聊天机器人，用于自动化需求启发式访谈。该研究旨在解决传统人工访谈中资源密集、易出错和可扩展性差的问题。通过零样本和最少到最多提示方法，并在33次模拟访谈中进行评估，结果显示LLMREI在减少错误、提取需求和根据上下文调整问题方面表现良好，与人类面试官表现相当，尤其适用于大规模访谈场景。

> **摘要翻译:** 需求启发式访谈对于收集系统需求至关重要，但严重依赖于熟练的分析师，这使得它们资源密集、易受人类偏见影响且易发生沟通不畅。大型语言模型在近期取得的进展为自动化该过程的部分环节提供了新的机会。本研究引入了LLMREI，一个旨在以最少的人工干预进行需求启发式访谈的聊天机器人，旨在减少常见的面试官错误并提高需求启发的可扩展性。我们探索了两种主要方法：零样本提示（zero-shot prompting）和从少到多提示（least-to-most prompting），以优化LLMREI用于需求启发，并在33次模拟利益相关者访谈中评估了其性能。第三种方法，微调（fine-tuning），最初被考虑，但由于初步试验表现不佳而被放弃。我们的研究评估了该聊天机器人在三个关键领域的效果：最小化常见的访谈错误、提取相关的需求，以及根据访谈上下文和用户回应调整提问。我们的研究结果表明，与人类面试官相比，LLMREI犯的错误数量相似，能够提取大部分需求，并表现出生成高度依赖上下文问题的显著能力。我们设想LLMREI的最大益处在于自动化与大量利益相关者的访谈。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [220] [Human-Machine Collaboration and Ethical Considerations in Adaptive Cyber-Physical Systems](https://arxiv.org/abs/2507.02578)
> *自适应信息物理系统中的人机协作与伦理考量*

*Zoe Pfister* | **Category: cs.SE, cs.HC, D.2.1** | **Updated: {updated}**

**Keywords:** 人机协作, 自适应信息物理系统, 伦理考量, 反馈循环, 隐私

**Comment:** Copyright 2025 IEEE. Accepted for publication in: 2025 IEEE 33nd
  International Requirements Engineering Conference (RE), Doctor Symposium
  Paper, 5 pages

> **TL;DR:** 本文研究自适应信息物理系统（CPS）中人机协作（HMT）的挑战，特别是将人类整合到反馈循环中以及伦理考量。研究旨在开发新方法和框架来解决这些问题。

**AI_Comments:** 这篇论文的重要性在于其关注自适应信息物理系统（CPS）中人机协作（HMT）的实际挑战，尤其是在将人类纳入技术反馈循环和处理伦理考量（如隐私和人类价值观）方面。其创新点在于提出开发新方法和框架来解决这些复杂的人机集成与伦理治理问题，这对于构建更安全、更高效且以人为本的智能系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在自适应信息物理系统（CPS）中实现有效无缝的人机协作（HMT）面临挑战，主要包括由于人机操作节奏不同导致难以将人类整合到反馈循环中，以及在HMT中持续监控人类操作员时如何尊重隐私和人类价值观。

**Method:** 本研究通过以下两点来解决挑战：1) 开发新颖的方法和流程，将人机协作（HMT）整合到自适应信息物理系统（CPS）中，重点关注人机交互原则及其在CPS自适应反馈循环中的应用；2) 创建框架，在系统生命周期（从需求工程开始）中整合、验证和确认伦理和人类价值观。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了在自适应信息物理系统（CPS）中实现人机协作（HMT）所面临的挑战，特别是如何将人类有效整合到现有反馈循环中以及如何处理由此产生的伦理和隐私问题。研究旨在通过开发新的方法和流程来促进HMT在自适应CPS中的集成，并建立框架以确保在系统整个生命周期中融入并验证伦理和人类价值观。

> **摘要翻译:** 自适应信息物理系统（CPS）是整合了物理和计算能力的系统，能够响应变化的参数进行调整。此外，它们越来越多地融入人机协作，使其能够受益于人类和机器各自的优势。人机协作（HMT）代表了人机协作最先进的范式，设想人类和机器之间实现无缝团队合作。然而，在自适应CPS中实现有效和无缝的HMT具有挑战性。虽然自适应CPS已经受益于MAPE-K等反馈循环，但由于人类和机器操作节奏的不同，将人类整合到这些反馈循环中仍然存在空白。此外，HMT需要持续监控人类操作员，收集可能敏感的关于其行为和举止的信息。尊重CPS参与者的隐私和人类价值观对于人机团队的成功至关重要。本研究通过以下方式应对这些挑战：(1) 开发新颖的方法和流程，将HMT整合到自适应CPS中，重点关注人机交互原则及其在CPS自适应反馈循环中的应用；(2) 创建框架，在整个系统生命周期中（从需求工程开始）整合、验证和确认伦理和人类价值观。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [231] [Do Research Software Engineers and Software Engineering Researchers Speak the Same Language?](https://arxiv.org/abs/2507.02665)
> *研究软件工程师和软件工程研究人员说同一种语言吗？*

*Timo Kehrer, Robert Haines, Guido Juckeland, Shurui Zhou, David E. Bernholdt* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 研究软件工程师, 软件工程研究人员, 术语映射, 沟通, 协作

**Comment:** Early access journal version: T. Kehrer, R. Haines, G. Juckeland, S.
  Zhou and D. E. Bernholdt, "Do Research Software Engineers and Software
  Engineering Researchers Speak the Same Language?," in Computing in Science &
  Engineering, doi: 10.1109/MCSE.2025.3557236

> **TL;DR:** 研究软件工程师（RSE）和软件工程研究人员（SER）在术语使用上存在差异，导致沟通障碍。本文旨在调查这些差异，以促进双方的相互学习和协作。

**AI_Comments:** 本文的创新之处在于系统性地解决了研究软件工程师和软件工程研究人员这两个相关但不同社区之间的实际沟通鸿沟。其重要性在于能够促进更好的协作和知识转移。局限性在于这些是“初步发现”，需要未来的验证。

<details>
  <summary>Details</summary>

**Motivation:** 传闻证据表明，研究软件工程师（RSE）和软件工程研究人员（SER）对相似概念使用不同的术语，造成沟通障碍。研究动机是为了更好地理解这些分歧。

**Method:** 通过调查软件工程研究人员（SER）社区的软件工程基础知识在研究软件工程师（RSE）社区中是如何被解读的，识别一致的概念、知识空白和潜在的适应领域。采用了系统性的术语映射方法。

**Result:** 初步发现揭示了相互学习和协作的机会。所提出的系统性术语映射方法为未来众包扩展和验证奠定了基础。

**Conclusion:** 通过理解研究软件工程师和软件工程研究人员之间的术语差异，可以促进双方的相互学习和协作，并且其系统性术语映射方法具有未来扩展和验证的潜力。

> **ai_Abstract:** 本文探讨了研究软件工程师（RSE）和软件工程研究人员（SER）之间因术语差异导致的沟通挑战。研究调查了SER社区的软件工程基本概念在RSE社区中的理解情况，旨在识别共同点和知识空白。初步结果表明存在相互学习和协作的潜力，并提出了一种系统性的术语映射方法，为未来的众包扩展和验证奠定了基础。

> **摘要翻译:** 传闻证据表明，研究软件工程师（RSE）和软件工程研究人员（SER）经常对相似概念使用不同的术语，从而造成沟通障碍。为了更好地理解这些分歧，我们开始调查SER社区的软件工程基础知识在RSE社区中是如何被解读的，并识别出一致的概念、知识空白和潜在的适应领域。我们的初步发现揭示了相互学习和协作的机会，而我们系统性的术语映射方法为未来众包扩展和验证奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [242] [RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes](https://arxiv.org/abs/2507.02690)
> *RLHGNN：强化学习驱动的异构图神经网络在业务流程下一活动预测中的应用*

*Jiaxing Wang, Yifeng Yu, Jiahan Song, Bin Cao, Jing Fan, Ji Zhang* | **Category: cs.SE, cs.LG** | **Updated: {updated}**

**Keywords:** 业务流程, 下一活动预测, 异构图神经网络, 强化学习, 流程挖掘

**Comment:** 15 pages, 7 figures. Business process prediction using reinforcement
  learning and heterogeneous graph neural networks

> **TL;DR:** RLHGNN通过强化学习自动选择最优异构图结构，有效预测业务流程的下一活动，优于现有方法且推理速度快。

**AI_Comments:** RLHGNN的创新之处在于其结合了异构图神经网络和强化学习，以自适应地选择最佳图结构来建模业务流程。这种动态结构选择克服了传统图方法静态同质表示的局限，使其能够更精确地捕捉复杂的顺序和非顺序关系。此外，其在真实世界数据集上的优越性能和低推理延迟，使其成为一个具有高度实用价值的解决方案，特别适用于需要实时响应的业务流程监控场景。

<details>
  <summary>Details</summary>

**Motivation:** 业务流程中的下一活动预测对于优化资源分配和动态服务组合至关重要。现有序列方法无法捕捉非顺序关系，而图方法存在同质表示和静态结构的局限性，不能适应不同流程复杂性。

**Method:** 本文提出了RLHGNN框架。该方法将事件日志转换为具有三种不同边类型的异构过程图，并创建四种灵活的图结构以适应不同复杂性。通过将强化学习建模为马尔可夫决策过程，RLHGNN自动为每个特定流程实例确定最优图结构。然后，它应用具有关系特定聚合策略的异构图卷积来预测下一活动。

**Result:** 在六个真实世界数据集上的综合评估表明，RLHGNN始终优于现有先进方法。此外，每次预测的推理延迟约为1毫秒，使其成为适用于实时业务流程监控的实用解决方案。

**Conclusion:** RLHGNN通过自适应地建模业务流程中的顺序和非顺序关系，并自动选择最优图结构，在下一活动预测方面表现出色，且具备高效率和实用性。

> **ai_Abstract:** 本文提出了RLHGNN，一个用于业务流程下一活动预测的新颖框架。针对现有序列和图方法无法捕捉非顺序关系及同质静态结构的局限，RLHGNN将事件日志转换为异构过程图，并通过强化学习自动选择适应不同流程复杂度的最佳图结构。结合异构图卷积，该模型能精确建模顺序和非顺序关系。在六个真实数据集上的评估显示，RLHGNN性能优于现有技术，并保持低推理延迟，适用于实时监控。

> **摘要翻译:** 下一活动预测是优化面向服务架构（如微服务环境、分布式企业系统和云原生平台）中业务流程的一项基本挑战，它能够实现主动资源分配和动态服务组合。尽管基于序列的方法普遍存在，但这些方法未能捕获因并行执行和条件依赖而产生的非序列关系。尽管基于图的方法解决了结构保留问题，但它们存在同质表示和静态结构的缺陷，无论个体流程复杂性特征如何，都采用统一的建模策略。为了解决这些限制，我们引入了RLHGNN，这是一种新颖的框架，它将事件日志转换为具有三种不同边类型、基于既定流程挖掘理论的异构过程图。我们的方法通过选择性地组合这些边来创建四种灵活的图结构，以适应不同的流程复杂性，并采用公式化为马尔可夫决策过程的强化学习来自动确定每个特定流程实例的最佳图结构。RLHGNN随后应用具有关系特定聚合策略的异构图卷积来有效预测下一活动。这种自适应方法能够精确建模服务交互中的顺序和非顺序关系。对六个真实世界数据集的综合评估表明，RLHGNN始终优于现有先进方法。此外，它每次预测的推理延迟约为1毫秒，代表了一种高度实用的解决方案，适用于实时业务流程监控应用。源代码可在https://github.com/Joker3993/RLHGNN 获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [251] [Sustainability Flags for the Identification of Sustainability Posts in Q&A Platforms](https://arxiv.org/abs/2507.02695)
> *用于识别问答平台中可持续性帖子的可持续性标记*

*Sahar Ahmadisakha, Lech Bialek, Mohamed Soliman, Vasilios Andrikopoulos* | **Category: cs.SE** | **Updated: {updated}**

**Keywords:** 可持续性标记, 问答平台, 软件可持续性, 主题分析, 云计算

**Comment:** 

> **TL;DR:** 本研究引入了“可持续性标记”的概念，通过对云提供商最佳实践进行主题分析，旨在解决在软件从业者讨论中识别可持续性概念的挑战，并通过受控实验评估了其有效性。

**AI_Comments:** 这项研究通过引入“可持续性标记”的概念，为在非结构化文本（如Q&A平台）中识别特定领域（可持续性）信息提供了一种新颖且实用的方法。其创新之处在于将主题分析与受控实验相结合，验证了这种识别工具的有效性。这项工作对于帮助软件从业者和研究人员更好地理解和管理软件系统中的可持续性问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，软件系统的可持续性受到了广泛关注，尤其是在云计算兴起和转向基于云的架构之后。这种转变使得在架构讨论中识别可持续性变得更加重要，以便做出明智的架构决策。然而，由于缺乏明确的指导方针，在软件从业者的在线问答论坛中识别可持续性概念仍然具有挑战性。

**Method:** 本研究通过对云提供商的多个可持续性最佳实践进行主题分析，开发了“可持续性标记”的概念，作为相关讨论中的指针。随后，通过受控实验评估了这些标记在识别云架构帖子中可持续性方面的有效性。

**Result:** 初步结果表明，与对照组相比，使用可持续性标记将更少的帖子归类为可持续性相关，但具有中等程度的更高确定性和显著提高的性能。此外，可持续性标记被认为比仅依赖定义来识别可持续性更有用和更易于理解。

**Conclusion:** 可持续性标记能够以更高的确定性和显著提高的性能识别可持续性相关帖子，并且被认为比传统定义更有效和易懂。

> **ai_Abstract:** 本研究提出并评估了“可持续性标记”的概念，旨在解决在在线问答平台中识别软件可持续性讨论的挑战。通过对云提供商最佳实践进行主题分析开发了这些标记，并通过受控实验验证了其有效性。结果显示，与对照组相比，使用可持续性标记可以更准确、高效地识别可持续性相关帖子，并且用户认为其比传统定义更实用。

> **摘要翻译:** 近年来，软件系统的可持续性受到了广泛关注，尤其是在云计算兴起和转向基于云的架构之后。这种转变使得在架构讨论中识别可持续性变得更加重要，以便做出明智的架构决策。在线问答论坛是了解这些决策的一个来源，其中包含了从业者的讨论。然而，由于缺乏明确和独特的指导方针，在软件从业者的讨论中识别可持续性概念仍然具有挑战性。为了解决这个问题，我们引入了“可持续性标记”的概念，作为相关讨论中的指针，这些标记是通过对来自云提供商的多个可持续性最佳实践进行主题分析而开发的。本研究通过受控实验进一步评估了这些标记在识别云架构帖子中可持续性方面的有效性。初步结果表明，与对照组相比，使用标记将更少的帖子归类为可持续性相关，但具有中等程度的更高确定性和显著提高的性能。此外，可持续性标记被认为比仅依赖定义来识别可持续性更有用和更易于理解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [261] [Legal Requirements Translation from Law](https://arxiv.org/abs/2507.02846)
> *法律法规的法律要求转换*

*Anmol Singhal, Travis Breaux* | **Category: cs.SE, cs.CL** | **Updated: {updated}**

**Keywords:** 法律要求, 文本蕴含, 上下文学习, 法律合规, Python代码

**Comment:** 13 pages, 7 figures, Accepted at the 33rd IEEE International
  Requirements Engineering 2025

> **TL;DR:** 本文提出了一种基于文本蕴含和上下文学习的方法，用于自动生成法律文本的规范表示，可编码和执行为Python代码，以帮助软件系统遵守法律法规。

**AI_Comments:** 这项研究的创新之处在于结合了文本蕴含和上下文学习来自动生成可执行的法律文本表示，并采用手动设计的Python类结构作为领域特定元模型，有效解决了现有方法在处理法律文本时面临的泛化性差和依赖大量手动标注数据的问题。其将法律要求转化为可编码和执行的Python代码，为软件合规性管理提供了一个自动化且高效的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 软件系统必须遵守法律法规，这对缺乏法律专业知识的小型组织和初创公司来说是一项资源密集型任务。从法规中提取元数据以获取软件的法律要求是确保合规性的关键步骤，但由于法律文本的长度和复杂性，这项任务非常繁琐。现有自动化方法存在局限性，包括未考虑元数据类型间属性的相互作用和相互关系，以及依赖手动标注或启发式机器学习，导致泛化性差。

**Method:** 本文提出了一种基于文本蕴含和上下文学习的方法，用于自动生成法律文本的规范表示，该表示可编码和执行为Python代码。这种表示实例化自一个手动设计的Python类结构，该结构作为领域特定的元模型，捕获结构化和语义法律元数据及其相互关系。这种设计选择减少了对大型手动标注数据集的需求，并增强了对未见立法的适用性。

**Result:** 该方法在13个美国州数据泄露通知法上进行了评估，结果表明生成的表示通过了大约89.4%的测试用例，并且精确率和召回率分别为82.2%和88.7%。

**Conclusion:** 本文提出的基于文本蕴含和上下文学习的方法，能够有效自动生成法律文本的可执行规范表示，显著提高了法律要求提取的自动化程度和泛化能力，有助于软件系统更高效地遵守法律法规。

> **ai_Abstract:** 本文提出了一种新颖的方法，利用文本蕴含和上下文学习，自动将法律文本转化为可编码和执行的Python代码形式的规范表示。该方法通过一个领域特定的Python类结构作为元模型，捕获法律文本中的结构和语义元数据及其相互关系，从而减少了对大量手动标注数据的依赖，并提高了对新法律文件的泛化能力。实验结果表明，该方法在处理美国州数据泄露通知法时表现良好，有效提升了软件系统法律合规性要求的提取效率和准确性。

> **摘要翻译:** 软件系统必须遵守法律法规，这是一项资源密集型任务，特别是对于缺乏专门法律专业知识的小型组织和初创公司。从法规中提取元数据以获取软件的法律要求是确保合规性的关键步骤。然而，由于法律文本的长度和复杂性，这是一项繁琐的任务。尽管先前的工作已经寻求从法律文本中提取结构和语义元数据的自动化方法，但仍存在关键限制：它们不考虑这些元数据类型相关属性之间的相互作用和相互关系，并且它们依赖于手动标注或启发式机器学习，这不能很好地推广到新文档。在本文中，我们介绍了一种基于文本蕴含和上下文学习的方法，用于自动生成法律文本的规范表示，可编码和执行为Python代码。我们的表示是从手动设计的Python类结构实例化的，该结构作为领域特定的元模型，捕获结构化和语义法律元数据及其相互关系。这种设计选择减少了对大型手动标注数据集的需求，并增强了对未见立法的适用性。我们评估了我们的方法在13个美国州数据泄露通知法上的表现，结果表明我们生成的表示通过了大约89.4%的测试用例，并分别实现了82.2和88.7的精确度和召回率。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [269] [Requirements Elicitation Follow-Up Question Generation](https://arxiv.org/abs/2507.02858)
> *需求启发后续问题生成*

*Yuchen Shen, Anmol Singhal, Travis Breaux* | **Category: cs.SE, cs.CL** | **Updated: {updated}**

**Keywords:** 需求启发, 大型语言模型, GPT-4o, 访谈问题生成, 软件工程

**Comment:** 13 pages, 2 figures, accepted at the 33rd IEEE International
  Requirements Engineering 2025

> **TL;DR:** 本研究探讨了使用大型语言模型（LLMs，特别是GPT-4o）在需求启发访谈中生成后续问题，实验证明LLM生成的问题在清晰度、相关性和信息量方面不逊于人工问题，并在根据常见面试错误类型进行指导时表现更优。

**AI_Comments:** 该论文将大型语言模型应用于软件工程领域的需求启发过程，具有创新性。通过引入面试官常见错误类型来指导LLM生成问题，不仅解决了人工访谈中的痛点，还显著提升了生成问题的质量，这一方法非常巧妙且实用。这有望减轻面试官的认知负担，提高需求收集的效率和准确性。其重要性在于为软件开发前期的关键环节提供了强有力的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 访谈是获取软件系统需求的关键技术，但有效的访谈对面试官提出了高要求，他们常面临领域不熟悉、认知负荷过大和信息过载等挑战。当前大型语言模型在自然语言处理任务中表现出色，本文旨在利用其能力辅助面试官。

**Method:** 研究应用GPT-4o在需求启发过程中生成后续访谈问题，并基于常见的面试官错误类型框架进行构建。描述了根据受访者发言生成问题的方法。进行了两次受控实验：第一次评估了在最小指导下LLM生成的问题与人工撰写问题的表现；第二次评估了在面试官错误类型指导下LLM生成问题的表现。

**Result:** 在两次实验中，LLM生成的问题在清晰度、相关性和信息量方面均不逊于人工撰写的问题。此外，当受到常见错误类型指导时，LLM生成的问题表现优于人工撰写的问题。

**Conclusion:** 研究结果突出了使用大型语言模型帮助面试官实时提高需求启发访谈质量和便捷性的潜力。

> **ai_Abstract:** 本文探讨了利用大型语言模型（特别是GPT-4o）在软件需求启发访谈中实时生成后续问题的可行性。针对面试官在访谈中面临的认知负荷和信息过载等挑战，研究构建了一个基于常见面试官错误类型的框架来指导问题生成。通过两项受控实验，结果表明LLM生成的问题在清晰度、相关性和信息量方面与人工撰写的问题不相上下，并且在结合错误类型指导时表现更优，这揭示了LLM在提升需求启发访谈质量和效率方面的巨大潜力。

> **摘要翻译:** 访谈是获取软件系统涉众需求、偏好和期望的广泛使用的需求启发技术。有效的访谈需要熟练的面试官实时制定合适的访谈问题，同时面临多重挑战，包括对领域不熟悉、认知负荷过大和信息过载，这些都会阻碍人类处理涉众的讲话。最近，大型语言模型（LLMs）在多项自然语言处理任务中表现出最先进的性能，包括文本摘要和蕴涵。为了支持面试官，我们调查了GPT-4o在需求启发过程中生成后续访谈问题的应用，并基于常见的面试官错误类型框架进行构建。此外，我们描述了根据受访者发言生成问题的方法。我们报告了一项受控实验，评估了在最小指导下LLM生成的问题和人工撰写的问题，以及第二项受控实验，评估了在面试官错误类型指导下LLM生成的问题。我们的研究结果表明，对于两次实验，LLM生成的问题在清晰度、相关性和信息量方面均不逊于人工撰写的问题。此外，当受到常见错误类型指导时，LLM生成的问题表现优于人工撰写的问题。这突出了使用LLMs帮助面试官实时提高需求启发访谈质量和便捷性的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [10] [Recommendation Algorithms on Social Media: Unseen Drivers of Political Opinion](https://arxiv.org/abs/2507.01978)
> *社交媒体上的推荐算法：政治观点背后看不见的驱动力*

*Waseq Billah* | **Category: cs.SI** | **Updated: {updated}**

**Keywords:** 社交媒体, 推荐算法, 政治兴趣, Facebook, X (Twitter) 

**Comment:** 3 tables in main text, 2 tables in appendix. The article was
  presented at the Western Political Science Association (WPSA) Annual Meeting
  held during April 16-19, 2025 at Seattle, WA

> **TL;DR:** 本研究调查了社交媒体平台及其算法对用户政治兴趣的影响，发现不同平台影响不同，X（原Twitter）能显著提升政治兴趣，而Facebook则可能降低。

**AI_Comments:** 本研究创新性地探讨了社交媒体算法对政治观点形成的“看不见”的驱动作用，并区分了不同平台（如Facebook和X）的影响差异，具有重要的现实意义。它揭示了社交媒体在塑造政治话语中的关键作用，并提供了具体的人口统计学洞察。然而，其主要局限在于缺乏用户实际接触内容的数据，这限制了对算法影响机制的深入理解。未来的研究应关注内容层面的数据，以提供更全面的分析。

<details>
  <summary>Details</summary>

**Motivation:** 随着社交媒体使用量的持续增长，平台在塑造政治话语方面发挥着越来越关键的作用。本研究旨在调查社交媒体平台及其算法对用户政治兴趣的影响。

**Method:** 通过对3300多名参与者收集的数据进行统计分析。

**Result:** 1. 不同的社交媒体平台对政治兴趣的影响存在显著差异。2. 适度使用Facebook的用户政治参与度降低。3. 即使是少量使用X（原Twitter）也能显著提升政治兴趣。4. 男性、老年人、黑人或非裔美国用户、高收入者表现出更高的政治兴趣。5. 共和党人在社交媒体上特别活跃。

**Conclusion:** 了解社交媒体对政治的影响，填补研究空白，可以为政策制定者、教育工作者和平台设计者提供更深入的见解，以促进健康的民主参与。

> **ai_Abstract:** 本研究探讨了社交媒体平台及其推荐算法对用户政治兴趣的影响。通过分析3300多名参与者的数据，发现不同平台的影响差异显著：Facebook可能降低政治参与度，而X（原Twitter）则能显著提升政治兴趣。研究还揭示了人口统计学差异，如男性、老年人、高收入者和共和党人表现出更高的政治兴趣。研究指出缺乏用户接触内容的数据是其局限性，并建议未来研究应进一步探索这些影响以促进健康的民主参与。

> **摘要翻译:** 社交媒体泛指模拟在线社交互动的数字平台和应用程序。本研究调查了社交媒体平台及其算法对用户政治兴趣的影响。随着社交媒体使用量的持续增长，Facebook和X（原Twitter）等平台在塑造政治话语方面发挥着越来越关键的作用。通过对从3300多名参与者收集的数据进行统计分析，本研究发现了不同社交媒体平台如何影响政治兴趣的显著差异。研究结果显示，适度使用Facebook的用户政治参与度降低，而即使是少量使用X也能显著提升政治兴趣。研究进一步确定了人口统计学差异，指出男性、老年人、黑人或非裔美国用户、高收入者表现出更高的政治兴趣。人口统计学分析强调，共和党人在社交媒体上特别活跃——这可能影响他们的社交媒体参与模式。然而，该研究承认一个关键限制——缺乏关于用户接触内容（这些内容正在塑造他们的社交媒体体验）的直接数据。未来的研究应探索这些影响，并考虑其他流行的平台，以增强对社交媒体政治影响的理解。解决这些空白可以为数字政治动员提供更深入的见解，帮助政策制定者、教育工作者和平台设计者促进更健康的民主参与。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [39] [Generating Large Semi-Synthetic Graphs of Any Size](https://arxiv.org/abs/2507.02166)
> *生成任意大小的大型半合成图*

*Rodrigo Tuna, Carlos Soares* | **Category: cs.SI, cs.AI** | **Updated: {updated}**

**Keywords:** 图生成, 扩散模型, 节点嵌入, 可扩展性, 半合成图

**Comment:** 

> **TL;DR:** 本文提出LGSG框架，利用扩散模型和节点嵌入生成任意大小的图，克服了对节点ID的依赖，并在某些指标上优于基线模型，同时保持结构一致性。

**AI_Comments:** LGSG的创新之处在于解决了图生成中长期存在的规模扩展性和对节点ID依赖的问题，实现了任意大小的图生成。其利用扩散模型和节点嵌入来达成此目标是该方法的关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 当前的图生成模型，特别是深度学习方法，受限于对节点ID的依赖，这限制了它们生成比输入图更大的图的能力，并忽略了节点属性。

**Method:** 本文提出了潜在图采样生成（LGSG）框架，这是一种利用扩散模型和节点嵌入的新颖方法。该框架消除了对节点ID的依赖，并捕获节点嵌入和子图结构的分布。

**Result:** 实验结果表明，LGSG在标准指标上与基线模型表现相当，但在被忽视的指标（如节点形成簇的倾向）上表现优异。此外，它在不同大小的图上保持了一致的结构特征。

**Conclusion:** LGSG为生成不同大小的图提供了一个鲁棒且可扩展的解决方案，通过消除节点ID依赖和捕获关键图属性，克服了先前模型的局限性。

> **ai_Abstract:** LGSG是一种新颖的图生成框架，它利用扩散模型和节点嵌入来克服现有方法对节点ID的依赖，从而实现可扩展的、任意大小的图生成。该框架无需重新训练即可生成不同尺寸的图，并捕获节点属性和子图结构的分布。LGSG在性能上与基线模型持平或超越，并能保持结构一致性。

> **摘要翻译:** 图生成是网络科学中的一个重要领域。传统方法侧重于复制真实世界图的特定属性，例如小直径或幂律度分布。深度学习的最新进展，特别是图神经网络，使得数据驱动方法能够在不依赖预定义结构属性的情况下学习和生成图。尽管取得了这些进展，但当前模型受限于它们对节点ID的依赖，这限制了它们生成比输入图更大的图的能力，并忽略了节点属性。为了解决这些挑战，我们提出了潜在图采样生成（LGSG），一个利用扩散模型和节点嵌入的新颖框架，可以在不重新训练的情况下生成不同大小的图。该框架消除了对节点ID的依赖，并捕获节点嵌入和子图结构的分布，从而实现可扩展和灵活的图生成。实验结果表明，LGSG在标准指标上与基线模型表现相当，但在被忽视的指标（如节点形成簇的倾向）上表现优异。此外，它在不同大小的图上保持了一致的结构特征，展示了鲁棒性和可扩展性。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [8] [A Comprehensive Survey on Network Traffic Synthesis: From Statistical Models to Deep Learning](https://arxiv.org/abs/2507.01976)
> *网络流量合成综合调查：从统计模型到深度学习*

*Nirhoshan Sivaroopan, Kaushitha Silva, Chamara Madarasingha, Thilini Dahanayaka, Guillaume Jourjon, Anura Jayasumana, Kanchana Thilakarathna* | **Category: cs.NI, cs.LG** | **Updated: {updated}**

**Keywords:** 网络流量合成, 深度学习, 统计模型, 数据生成, 调查

**Comment:** 

> **TL;DR:** 这是一篇关于网络流量合成的综合性调查，涵盖了从统计模型到深度学习的方法，并讨论了挑战和未来方向。

**AI_Comments:** 这篇调查论文的重要性在于其全面性，它系统地梳理了网络流量合成领域的现有技术，特别是对深度学习方法的关注，填补了该领域系统性综述的空白。它不仅总结了过去和现在的方法，还指出了未来的研究方向和挑战，对于推动网络数据生成技术的发展具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决真实网络数据面临的数据稀缺性、隐私问题和纯度限制，通过合成数据为网络领域的各种数据驱动应用提供有前景的替代方案。

**Method:** 本调查全面回顾了合成网络流量生成方法，涵盖了数据类型、生成模型和评估方法。特别关注基于深度学习的技术，并详细讨论了统计方法及其扩展，包括商用工具。

**Result:** 提供了对现有方法的结构化分析、挑战和机遇，并强调了该领域的开放挑战和潜在的未来研究方向。

**Conclusion:** 本调查为研究人员和从业者提供了关于合成网络流量生成的现有方法、挑战和机遇的基础资源。

> **ai_Abstract:** 这篇综合调查回顾了网络流量合成技术，旨在克服真实数据的数据稀缺、隐私和纯度问题。它涵盖了数据类型、生成模型和评估方法，特别关注深度学习和统计方法，并讨论了开放挑战和未来方向，为该领域的研究人员和从业者提供了重要资源。

> **摘要翻译:** 合成网络流量生成已成为网络领域各种数据驱动应用的一个有前景的替代方案。它能够创建保留真实世界特征的合成数据，同时解决了与真实数据相关的数据稀缺性、隐私问题和纯度限制等关键挑战。在这项调查中，我们对合成网络流量生成方法进行了全面回顾，涵盖了数据类型、生成模型和评估方法等基本方面。随着人工智能和机器学习的快速发展，我们特别关注基于深度学习的技术，同时还详细讨论了统计方法及其扩展，包括商用工具。此外，我们强调了该领域的开放挑战，并讨论了未来研究和开发的潜在方向。这项调查为研究人员和从业者提供了基础资源，对合成网络流量生成中的现有方法、挑战和机遇进行了结构化分析。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [37] [Scaling Out Chip Interconnect Networks with Implicit Sequence Numbers](https://arxiv.org/abs/2507.01988)
> *使用隐式序列号扩展芯片互连网络*

*Giyong Jung, Saeid Gorgin, John Kim, Jungrae Kim* | **Category: cs.NI** | **Updated: {updated}**

**Keywords:** 芯片互连, 隐式序列号, 可靠性, CXL, 多节点

**Comment:** 12 pages, 8 figures. This paper is accepted for [2025 The
  International Conference for High Performance Computing, Networking, Storage
  and Analysis (SC)]

> **TL;DR:** 本文提出了一种名为隐式序列号（ISN）的新机制，用于扩展芯片互连网络的可靠性，确保精确的丢包检测和有序传输，同时通过RXL扩展CXL，实现可扩展、可靠的多节点互连，无需额外开销。

**AI_Comments:** 本文的创新点在于提出了隐式序列号（ISN），解决了在不增加报头开销的前提下，精确检测和处理多节点芯片互连中flit丢弃的问题。通过将CRC和FEC的功能分层优化，RXL提供了一种高效的可靠性解决方案，对于支持未来大规模AI计算至关重要。其重要性在于为高性能计算互连的可靠性与可扩展性提供了新的思路和实现方案，特别是在应对日益增长的AI模型计算需求方面具有显著潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI模型超越单处理器能力，芯片间互连成为可扩展计算的关键。新的互连协议（如CXL、NVLink、UALink）虽然提供高带宽和小有效载荷，但传输速率的提高增加了出错的易感性，尤其是在多节点配置中管理交换设备中悄然丢弃的flit。

**Method:** 本文引入了隐式序列号（ISN），一种无需增加报头开销即可确保精确的flit丢弃检测和有序传输的新机制。此外，提出了可靠性扩展链路（RXL），它是CXL的扩展，结合ISN以支持可扩展、可靠的多节点互连，同时保持与现有flit结构的兼容性。RXL通过将CRC提升为用于端到端数据和序列完整性的传输层机制，并依靠FEC进行链路层错误纠正和检测，实现鲁棒的可靠性和可扩展性。

**Result:** RXL在不影响带宽效率的情况下，提供了强大的可靠性和可扩展性。ISN确保了精确的flit丢弃检测和有序交付，且没有增加报头开销。

**Conclusion:** 通过引入ISN和RXL，本文成功解决了多节点芯片互连中flit丢弃检测和有序传输的挑战，提供了一种高效、可靠且可扩展的解决方案，以支持未来AI模型的计算需求。

> **ai_Abstract:** 本文针对AI模型对可扩展计算的需求，解决了芯片互连网络在多节点配置中flit丢弃检测和有序传输的挑战。提出了一种新的机制——隐式序列号（ISN），它无需额外报头开销即可实现精确丢包检测和有序传输。在此基础上，引入了可靠性扩展链路（RXL），它是CXL的扩展，通过结合ISN，并将CRC提升到传输层、FEC用于链路层，实现了可扩展、可靠且带宽高效的多节点互连。

> **摘要翻译:** 随着AI模型超越单处理器的能力，芯片间的互连已成为可扩展计算的关键促成因素。这些处理器以缓存行粒度交换大量数据，促使CXL、NVLink和UALink等新互连协议的采用，这些协议专为高带宽和小有效载荷而设计。然而，这些协议传输速率的提高增加了对错误的易感性。虽然循环冗余校验（CRC）和前向纠错（FEC）等机制是可靠数据传输的标准，但将芯片互连扩展到多节点配置带来了新的挑战，尤其是在管理交换设备中悄然丢弃的flit。本文引入了隐式序列号（ISN），一种无需增加报头开销即可确保精确的flit丢弃检测和有序传输的新机制。此外，我们提出了可靠性扩展链路（RXL），它是CXL的扩展，结合ISN以支持可扩展、可靠的多节点互连，同时保持与现有flit结构的兼容性。通过将CRC提升为用于端到端数据和序列完整性的传输层机制，并依靠FEC进行链路层错误纠正和检测，RXL在不影响带宽效率的情况下提供了强大的可靠性和可扩展性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [62] [Curated Collaborative AI Edge with Network Data Analytics for B5G/6G Radio Access Networks](https://arxiv.org/abs/2507.01994)
> *用于B5G/6G无线接入网络的精选协作AI边缘与网络数据分析*

*Sardar Jaffar Ali, Syed M. Raza, Duc-Tai Le, Rajesh Challa, Min Young Chung, Ness Shroff, Hyunseung Choo* | **Category: cs.NI, cs.MA** | **Updated: {updated}**

**Keywords:** 精选协作学习, 分布式单元池化方案, 5G RAN, 能耗, 网络数据分析

**Comment:** 

> **TL;DR:** 该论文提出了一种结合精选协作学习（CCL）和分布式单元池化方案（DUPS）的方法，通过准确预测网络流量和优化资源利用来显著降低5G RAN的能耗和运营成本。

**AI_Comments:** 该论文的创新点在于结合了协作学习（CCL）进行精确预测和深度强化学习（DUPS）进行资源优化，以解决5G RAN的能耗问题。CCL通过智能选择协作数据来提高预测准确性，而DUPS则通过动态流量重定向实现了显著的能效提升。这种两阶段的集成方法为降低未来B5G/6G网络的运营成本和环境影响提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 尽管取得了进步，无线接入网络（RAN）仍然占5G网络总功耗的50%以上。现有的RAN拆分选项未能充分利用数据潜力，这为降低运营支出提供了机会。

**Method:** 本文采用双重方法：首先，提出了精选协作学习（CCL）框架，通过选择性地与相关联数据协作进行流量预测，实现了高度准确的网络流量和用户预测。CCL优化决定了何时、与谁以及协作什么。其次，提出了分布式单元池化方案（DUPS），利用深度强化学习和CCL的预测推断，有效减少活跃DU服务器的数量。DUPS动态地将流量从利用率低的DU服务器重定向，以优化资源使用。

**Result:** CCL在流量预测方面显著优于现有最先进的方法，分别比全局、联邦、个性化联邦和循环机构增量学习高出43.9%、39.1%、40.8%和31.35%。DUPS与传统策略相比，能效提高了高达89%，为运营商带来了可观的经济效益。

**Conclusion:** 通过将CCL驱动的预测与DUPS集成，本文展示了一种变革性的方法，用于最小化5G RAN的能耗和运营成本，显著提高了效率和成本效益。

> **ai_Abstract:** 该论文提出了一种新颖的框架，旨在降低5G RAN的能耗和运营成本。它引入了精选协作学习（CCL）以实现高精度网络流量和用户预测，通过选择性数据协作显著优于现有方法。在此基础上，提出了分布式单元池化方案（DUPS），利用深度强化学习和CCL的预测来优化DU服务器资源利用，从而大幅提高能效。该集成方法被证明能有效降低RAN的运营成本和能耗。

> **摘要翻译:** 尽管取得了进步，无线接入网络（RAN）仍然占5G网络总功耗的50%以上。现有的RAN拆分选项未能充分利用数据潜力，这为降低运营支出提供了机会。本文通过双重方法解决了这一机会。首先，使用所提出的精选协作学习（CCL）框架实现了高度准确的网络流量和用户预测，该框架选择性地与相关联数据协作进行流量预测。CCL优化决定了何时、与谁以及协作什么，显著优于现有最先进的方法，包括全局学习、联邦学习、个性化联邦学习和循环机构增量学习，分别提高了43.9%、39.1%、40.8%和31.35%。其次，提出了分布式单元池化方案（DUPS），利用深度强化学习和CCL的预测推断，有效减少活跃DU服务器的数量。DUPS动态地将流量从利用率低的DU服务器重定向，以优化资源使用，与传统策略相比，能效提高了高达89%，为运营商带来了可观的经济效益。通过将CCL驱动的预测与DUPS集成，本文展示了一种变革性的方法，用于最小化5G RAN的能耗和运营成本，显著提高了效率和成本效益。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [86] [Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting](https://arxiv.org/abs/2507.01997)
> *迈向一个用于网络故障排除AI智能体实验和基准测试的民主化平台*

*Zhihao Wang, Alessandro Cornacchia, Franco Galante, Carlo Centofanti, Alessio Sacco, Dingde Jiang* | **Category: cs.NI, cs.AI, cs.MA** | **Updated: {updated}**

**Keywords:** AI智能体, 网络故障排除, 基准测试平台, 标准化, 民主化

**Comment:** Accepted at ACM SIGCOMM 1st Workshop on Next-Generation Network
  Observability (NGNO)

> **TL;DR:** 本初步工作强调了为网络故障排除AI智能体建立一个标准化、可复现和开放的基准测试平台的需求。

**AI_Comments:** 本文的创新点在于识别了当前AI智能体在网络故障排除领域进行实验和基准测试的痛点，即缺乏一个统一、开放且易于操作的平台。其重要性在于提出了一种民主化AI智能体开发和评估的愿景，有助于降低进入门槛，促进研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究已证明AI和LLMs在网络配置合成和自动化网络诊断任务中的有效性。然而，对于网络故障排除中的AI智能体，缺乏一个标准化、可复现且开放的基准测试平台，这限制了AI智能体的构建和评估，并增加了操作难度。

**Method:** 本文是一项初步工作，主要阐述了为网络故障排除AI智能体建立一个标准化、可复现和开放的基准测试平台的需求。

**Result:** Not mentioned in abstract

**Conclusion:** 结论是需要一个标准化、可复现和开放的平台来民主化AI智能体在网络故障排除领域的实验和基准测试。

> **ai_Abstract:** 本初步工作聚焦于AI智能体在网络故障排除中的应用，并强调了建立一个标准化、可复现且开放的基准测试平台的重要性，该平台将有助于以较低的操作成本构建和评估AI智能体，从而推动该领域的发展。

> **摘要翻译:** 近期研究表明，人工智能（AI），特别是大型语言模型（LLMs），在支持网络配置合成和自动化网络诊断任务等方面展现出有效性。在这项初步工作中，我们将重点限制在AI智能体在网络故障排除中的应用，并详细阐述了对一个标准化、可复现且开放的基准测试平台的需求，以低操作成本在此平台上构建和评估AI智能体。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [111] [AI-Empowered Channel Generation for IoV Semantic Communications in Dynamic Conditions](https://arxiv.org/abs/2507.02013)
> *AI赋能动态条件下车联网语义通信信道生成*

*Hao Liu, Bo Yang, Zhiwen Yu, Xuelin Cao, George C. Alexandropoulos, Yan Zhang, Chau Yuen* | **Category: cs.NI, eess.SP** | **Updated: {updated}**

**Keywords:** 车联网, 语义通信, 信道生成, 生成扩散模型, 大型模型

**Comment:** 

> **TL;DR:** 本文提出了一种基于信道感知的语义通信框架，利用生成扩散模型和大型模型微调来解决动态车联网环境中数据传输的挑战，提高传输精度和效率。

**AI_Comments:** 该论文创新性地将语义通信与生成扩散模型相结合，并引入大型模型微调，以应对车联网在动态信道条件下的数据传输挑战，具有重要的实际应用价值。特别是大型模型微调的应用，有望显著提升系统在复杂多变环境中的鲁棒性和适应性。

<details>
  <summary>Details</summary>

**Motivation:** 车联网(IoV)中的海量数据实时传输和处理面临巨大挑战，特别是在动态和不可预测的无线信道条件下，这会影响数据传输的效率和精度。

**Method:** 本文提出了一种基于信道感知的语义通信框架，用于提高数据传输的精度和效率。该模型提取并压缩待传输信息。此外，通过使用生成扩散模型来估计无线信道，预测动态信道状态。为缓解动态场景下信道估计性能下降的问题，采用大型模型对信道生成模型进行微调，以增强其对不同场景的适应性。

**Result:** 所提出的框架在两个公共数据集上进行了性能和可靠性评估。

**Conclusion:** 该研究提出了一种AI赋能的信道生成方法，通过语义通信和生成扩散模型，并结合大型模型微调，有效提升了动态车联网环境下数据传输的精度和效率，增强了系统在多变场景下的适应性。

> **ai_Abstract:** 本文针对车联网（IoV）在动态信道条件下海量数据传输的挑战，提出了一种AI赋能的信道感知语义通信框架。该框架通过语义通信模型压缩信息，并利用生成扩散模型预测动态信道状态，以提高数据传输的精度和效率。为应对新场景下的性能下降，引入大型模型对信道生成模型进行微调，增强其适应性。该框架在公共数据集上进行了性能评估。

> **摘要翻译:** 车联网（IoV）正在改变交通生态系统，承诺实现普遍连接和数据驱动的方法。深度学习和生成式人工智能（AI）有潜力通过促进高效决策和预测能力，显著增强车联网内部应用的运行，包括智能导航、车辆安全监控、事故预防和智能交通管理。然而，实时高效传输和处理车联网生成的海量数据仍然是一个重大挑战，特别是在动态和不可预测的无线信道条件下。为了应对这些挑战，本文提出了一种基于信道感知的语义通信框架，以提高数据传输的准确性和效率。语义通信模型提取并压缩要传输的信息。此外，通过使用生成扩散模型估计无线信道，该模型用于预测动态信道状态，从而提高车联网服务的质量。然而，在动态场景中，当出现大量新场景时，信道估计性能可能会下降，这将对用户体验产生不利影响。为了缓解这一限制，我们采用大型模型对信道生成模型进行微调，以增强其对不同场景的适应性。所提出的框架的性能和可靠性在两个公共数据集上进行了评估。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [136] [REDUS: Adaptive Resampling for Efficient Deep Learning in Centralized and Federated IoT Networks](https://arxiv.org/abs/2507.02021)
> *REDUS：集中式和联邦式物联网网络中高效深度学习的自适应重采样*

*Eyad Gad, Gad Gad, Mostafa M. Fouda, Mohamed I. Ibrahem, Muhammad Ismail, Zubair Md Fadlullah* | **Category: cs.NI** | **Updated: {updated}**

**Keywords:** 自适应重采样, 深度学习, 联邦学习, 物联网, 资源优化

**Comment:** 2025 International Conference on Communications

> **TL;DR:** REDUS是一种受AdaBoost启发的重采样技术，通过优先处理错误分类的样本和排除冗余数据来优化深度学习训练。它显著减少了训练时间，降低了能耗，并加速了收敛，同时对准确性影响最小，特别适用于资源受限的物联网设备和联邦学习环境。

**AI_Comments:** REDUS的创新之处在于其将AdaBoost的启发式思想应用于深度学习的重采样，通过关注“困难”样本（错误分类样本）并剔除“容易”样本（冗余数据），有效地提高了训练效率。这对于资源受限的物联网和联邦学习环境尤为重要，因为它在保持性能的同时显著降低了计算和能耗成本。其高达72.6%的训练时间缩减是一个非常显著的进步。

<details>
  <summary>Details</summary>

**Motivation:** 在物联网环境中，软件定义网络（SDN）控制器与深度学习（DL）工作负载共享基础设施时，资源争用会导致SDN响应能力下降和网络性能受损。即使在联邦学习（FL）中，DL训练的计算需求也可能干扰SDN性能，尤其是在持续数据流的物联网系统中。

**Method:** 本文提出REDUS（智能网络中高效数据利用的重采样）技术，这是一种受AdaBoost启发的重采样方法。REDUS通过优先处理错误分类的样本并排除冗余数据来优化深度学习训练，从而减少每个epoch的训练样本数量。这有助于节约计算资源，降低能耗，并加速收敛，同时不显著影响准确性。

**Result:** 在CICIoT2023数据集上进行物联网攻击检测评估，REDUS将训练时间减少高达72.6%，而准确性损失仅为1.62%。

**Conclusion:** REDUS为智能网络提供了一个可扩展且实用的解决方案，通过优化深度学习训练，显著提高了资源受限物联网设备上模型训练的效率，同时保持了网络性能。

> **ai_Abstract:** 本文提出REDUS，一种受AdaBoost启发的自适应重采样技术，旨在优化集中式和联邦式物联网网络中的深度学习训练。面对SDN与DL工作负载共享基础设施时产生的资源争用问题，REDUS通过优先处理错误分类样本和排除冗余数据来减少训练样本数量，从而节约计算资源、降低能耗并加速模型收敛，同时保持高准确性。在联邦学习环境下，REDUS尤其能提升资源受限边缘设备的训练效率。实验结果表明，在物联网攻击检测任务中，REDUS可将训练时间大幅缩短高达72.6%，而准确性损失仅为1.62%，为智能网络提供了高效实用的解决方案。

> **摘要翻译:** 随着软件定义网络（SDN）的兴起，用于管理流量和确保互联设备之间的无缝操作，当SDN控制器与深度学习（DL）工作负载共享基础设施时，挑战随之出现。DL训练和SDN操作之间的资源争用，尤其是在延迟敏感的物联网环境中，可能会降低SDN的响应能力并损害网络性能。联邦学习（FL）通过将DL训练分散到边缘设备来解决其中一些问题，从而降低数据传输成本并增强隐私。然而，DL训练的计算需求仍然可能干扰SDN的性能，尤其是在物联网系统特有的持续数据流下。为了缓解这个问题，我们提出了REDUS（智能网络中高效数据利用的重采样），这是一种受AdaBoost启发的重采样技术，通过优先处理错误分类的样本和排除冗余数据来优化DL训练。REDUS减少了每个epoch的训练样本数量，从而节约了计算资源，降低了能耗，并加速了收敛，同时不显著影响准确性。在FL设置中应用时，REDUS提高了资源受限边缘设备上模型训练的效率，同时保持了网络性能。在本文中，REDUS在CICIoT2023数据集上针对物联网攻击检测进行了评估，结果显示训练时间减少高达72.6%，而准确性损失仅为1.62%，为智能网络提供了一个可扩展且实用的解决方案。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [156] [MULTI-SCOUT: Multistatic Integrated Sensing and Communications in 5G and Beyond for Moving Target Detection, Positioning, and Tracking](https://arxiv.org/abs/2507.02613)
> *MULTI-SCOUT：5G及未来多站集成感知与通信在移动目标检测、定位与跟踪中的应用*

*Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sastry Kompella, Gustave Anderson, Jonathan Ashdown* | **Category: cs.NI, cs.DC, eess.SP** | **Updated: {updated}**

**Keywords:** 5G PRS, ISAC, 多站感知, 目标跟踪, 信号处理

**Comment:** 

> **TL;DR:** 本文提出了一种使用5G定位参考信号（PRS）的多站集成感知与通信（ISAC）的完整信号处理链，旨在实现高保真移动目标检测、定位和跟踪。

**AI_Comments:** 该论文为5G PRS在多站ISAC中的创新应用提供了一个全面且鲁棒的信号处理链。其创新之处在于利用现有5G基础设施实现感知能力，这对于自动驾驶系统和智慧城市等新兴应用具有重要意义。文中详细的方法论涵盖了单/多目标、2D/3D设置以及同步问题，表明了研究的深入性和完整性。

<details>
  <summary>Details</summary>

**Motivation:** 在5G及未来网络中，为了利用5G PRS信号实现高保真移动目标的检测、定位和跟踪，本文提出并构建了一个完整的信号处理链，以支持多站集成感知与通信（ISAC）应用。

**Method:** 该方法采用分布式架构，一个gNB传输周期性OFDM-PRS波形，多个空间分离的接收器利用此信号进行目标检测、参数估计和跟踪。通过评估相干交叉模糊函数（CAF）形成距离-多普勒图，从中提取双站延迟和径向速度。对于单个目标，采用非线性最小二乘三边测量法进行位置估计，并对径向速度方程进行正则化线性反演以获得二维速度矢量。该方法适用于2D和3D设置，并扩展以处理时间同步偏差，通过解决目标关联问题推广到多个目标。最后，利用标准和扩展卡尔曼滤波器对位置-速度估计序列进行平滑跟踪。

**Result:** 研究结果表明，使用5G PRS信号进行多站ISAC能够实现高保真度的移动目标检测、定位和跟踪。

**Conclusion:** 本文提出的基于5G PRS的多站ISAC信号处理链，成功实现了移动目标的高精度检测、定位和跟踪。

> **ai_Abstract:** 本文提出了一种用于多站集成感知与通信（ISAC）的完整信号处理链，该链利用5G定位参考信号（PRS）来实现移动目标的检测、定位和跟踪。在分布式架构中，一个gNB发送OFDM-PRS波形，多个分离的接收器利用此信号。通过相干交叉模糊函数评估获得距离-多普勒图，并提取双站延迟和径向速度。对于单个目标，采用非线性最小二乘三边测量进行位置估计，并使用正则化线性反演获取速度矢量。该方法可扩展至2D/3D场景、处理时间同步偏差以及多目标关联。最终，通过卡尔曼滤波器对位置-速度估计进行平滑跟踪，实验结果验证了使用5G PRS信号进行多站ISAC在移动目标检测、定位和跟踪方面的高保真性能。

> **摘要翻译:** 这篇论文提出了一种完整的信号处理链，用于使用5G定位参考信号（PRS）的多站集成感知与通信（ISAC）。我们考虑一种分布式架构，其中一个gNB传输周期性OFDM-PRS波形，而多个空间分离的接收器利用相同的信号进行目标检测、参数估计和跟踪。通过评估相干交叉模糊函数（CAF）来形成距离-多普勒图，从中提取每个目标的双站延迟和径向速度。对于单个目标，通过非线性最小二乘三边测量融合所得的双站延迟，得到几何位置估计；径向速度方程的正则化线性反演得到二维速度矢量，从而获得速度和航向。该方法适用于2D和3D设置，并扩展以考虑时间同步偏差，通过解决目标关联问题推广到多个目标。随后，将位置-速度估计序列输入到标准和扩展卡尔曼滤波器以获得平滑轨迹。我们的结果表明，使用5G PRS信号进行多站ISAC可实现高保真移动目标检测、定位和跟踪。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [176] [On the Architectural Split and Radio Intelligence Controller Placement in Integrated O-RAN-enabled Non-Terrestrial Networks](https://arxiv.org/abs/2507.02680)
> *综合O-RAN非地面网络中的架构切分与无线智能控制器部署*

*Jorge Baranda, Marius Caus, Luis Blanco, Cristian J. Vaca-Rubio, Engin Zeydan, Kapal Dev, Zheng Li, Tomaso DeCola* | **Category: cs.NI** | **Updated: {updated}**

**Keywords:** O-RAN, 非地面网络, 架构切分, RIC部署, TN-NTN集成

**Comment:** 20 pages, 7 figures

> **TL;DR:** 本文探讨了在O-RAN框架下，综合地面网络与非地面网络时面临的架构切分和无线智能控制器部署挑战，提出了多种策略并分析了其权衡。

**AI_Comments:** 这篇论文的重要性在于它解决了地面网络与非地面网络集成所面临的复杂架构挑战，这对于未来的普适连接至关重要。其对O-RAN原则的关注以及对功能切分和RIC部署的详细分析具有创新性，为标准化和部署提供了实用的见解。特别是，全面的映射对于实施者来说非常有价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于异构传播条件、动态拓扑和有限的机载处理能力，地面网络（TNs）与非地面网络（NTNs）的集成带来了独特的架构和功能挑战，因此需要研究符合O-RAN原则的架构和功能切分策略。

**Method:** 本文提出了一种符合O-RAN原则的集成TN-NTN系统架构和功能切分策略分类法，将RAN和核心功能分配到卫星和地面节点之间，并分析了性能、延迟、自主性和部署方面的权衡。具体评估了从纯机载DU部署到完整的gNB和UPF集成到卫星的各种配置，包括基于星内和星间处理的变体。此外，讨论了近实时（Near-RT）和非实时（Non-RT）RAN智能控制器（RICs）的部署，提出了天地之间灵活的切分策略以优化控制环路的性能和可扩展性。提供了一个架构切分与RIC部署选项之间的全面映射，强调了实施约束和互操作性考虑。

**Result:** 本文提出了RAN和核心功能在卫星和地面节点之间分布的切分选项分类法，并分析了性能、延迟、自主性和部署方面的权衡。评估了从纯机载DU部署到完整gNB和UPF集成到卫星的各种配置。讨论了近实时和非实时RIC的部署，并提供了一个架构切分与RIC部署选项之间的全面映射，强调了实施约束和互操作性考虑。

**Conclusion:** 本文总结了在O-RAN背景下实现标准化、模块化和高效的TN-NTN融合所面临的关键挑战，并概述了未来的发展方向。

> **ai_Abstract:** 本文探讨了在O-RAN框架下，集成地面网络（TNs）与非地面网络（NTNs）所面临的架构与功能挑战。研究提出了一种O-RAN兼容的切分策略分类法，用于在卫星和地面节点之间分配RAN和核心功能，并分析了性能、延迟、自主性和部署等方面的权衡。论文评估了多种配置，包括机载DU部署以及gNB和UPF的完全集成，并讨论了RAN智能控制器（RICs）的优化部署策略。此外，论文提供了一个全面的架构切分与RIC部署映射，并考虑了实施约束和互操作性。最后，文章指出了该领域面临的关键挑战和未来的发展方向。

> **摘要翻译:** 地面网络（TNs）与非地面网络（NTNs）的集成由于异构传播条件、动态拓扑和有限的机载处理能力，带来了独特的架构和功能挑战。本文研究了符合O-RAN原则的未来集成TN-NTN系统的架构和功能切分策略。提出了一种切分选项分类法，将RAN和核心功能分配到卫星和地面节点之间，并分析了性能、延迟、自主性和部署方面的权衡。特别是，我们评估了从纯机载DU部署到完整的gNB和UPF集成到卫星的各种配置，包括基于星内和星间处理的变体。此外，讨论了近实时（Near-RT）和非实时（Non-RT）RAN智能控制器（RICs）的部署，提出了天地之间灵活的切分策略以优化控制环路的性能和可扩展性。提供了一个架构切分与RIC部署选项之间的全面映射，强调了实施约束和互操作性考虑。本文最后指出了关键挑战，并概述了在O-RAN背景下实现标准化、模块化和高效的TN-NTN融合的未来方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [12] [Matrix Pencil-Based DoA Estimation for Hybrid Receivers in Snapshot-Limited Scenarios](https://arxiv.org/abs/2507.02132)
> *基于矩阵铅笔法的混合接收机快照受限场景下DoA估计*

*Mona Mostafa, Ramy H. Gohary, Amr El-Keyi, Yahia A. Eldemerdash Ahmed* | **Category: cs.IT, eess.SP, math.IT** | **Updated: {updated}**

**Keywords:** DoA估计, 混合接收机, 矩阵铅笔法, 快照受限

**Comment:** This manuscript is currently under review for potential publication
  in IEEE Journal

> **TL;DR:** 本文提出两种改进的矩阵铅笔法，用于在快照数量有限的情况下，对混合模拟/数字(HAD)接收机进行DoA估计，以克服模拟合路器引起的信号纠缠和低维投影问题。

**AI_Comments:** 本文的创新点在于将矩阵铅笔法(MPM)应用于混合模拟/数字(HAD)接收机，解决了在快照受限场景下，模拟合路器引起的信号纠缠和低维投影问题。提出的两种方法针对不同的HAD架构提供了灵活的解决方案，对实际HAD系统在数据受限环境下的DoA估计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在快照数量过少导致统计平均不可靠的情况下，对混合模拟/数字(HAD)接收机进行方向角(DoA)估计。传统的矩阵铅笔法(MPM)无法直接应用于HAD接收机，因为模拟合路器会引起信号纠缠并将接收信号投影到低维空间，影响特定DoA范围的信号接收。

**Method:** 提出两种方法使MPM适用于HAD接收机。这两种方法通过循环遍历一组模拟合路器以覆盖整个空间，从而避免低维投影引起的严重衰减。第一种方法适用于全连接(FC)和部分连接(PC)HAD，依赖周期性信号来解耦HAD接收机输出。第二种方法仅适用于PC-HAD，通过利用底层的块对角结构消除对周期性信号的依赖。

**Result:** 通过数值模拟并与Cramér-Rao下界进行比较，证明了所提方法的优越性。

**Conclusion:** 本文成功地在快照受限场景下，通过改进的矩阵铅笔法实现了混合模拟/数字(HAD)接收机的DoA估计，有效克服了模拟合路器引起的信号纠缠和低维投影等挑战。

> **ai_Abstract:** 本文针对快照数量受限场景下的混合模拟/数字(HAD)接收机DoA估计问题，提出了两种改进的矩阵铅笔法(MPM)。鉴于MPM无法直接应用于HAD系统，因为模拟合路器会导致信号纠缠和低维投影，本文提出的方法通过循环使用一组模拟合路器来覆盖整个空间，从而避免了严重的信号衰减。其中，第一种方法适用于全连接和部分连接HAD，依赖周期性信号解耦；第二种方法仅适用于部分连接HAD，利用其块对角结构避免对周期性信号的依赖。数值模拟结果表明，所提方法优于现有技术并接近Cramér-Rao下界。

> **摘要翻译:** 本文的目标是在快照数量过少导致统计平均不可靠的情况下，对混合模拟/数字（HAD）接收机进行方向角（DoA）估计。在全数字接收机中，通过采用矩阵铅笔法（MPM）可以实现这一目标。然而，MPM无法直接应用于HAD接收机，因为底层的模拟合路器会在输出信号上引起纠缠。此外，这些模拟合路器会将接收信号投影到低维空间，危及来自特定DoA范围的信号接收。为了规避这些困难，我们提出了两种方法，使MPM能够在HAD接收机中提取DoA。这两种方法通过循环遍历一组详尽的模拟合路器，共同覆盖整个空间，从而避免了低维投影引起的严重衰减。第一种方法可应用于全连接（FC）和部分连接（PC）HAD，并依赖于周期性（可能是未知的）信号的可用性来解耦HAD接收机的输出。第二种方法仅适用于PC-HAD，通过利用底层的块对角结构消除了对周期性信号的依赖。所提方法的优越性通过数值模拟以及与Cramér-Rao下界的比较得到了证明。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [41] [Resolution Limits of Non-Adaptive 20 Questions Estimation for Tracking Multiple Moving Targets](https://arxiv.org/abs/2507.02274)
> *非自适应20问估计在多移动目标追踪中的分辨率极限*

*Chunsong Sun, Lin Zhou, Jingjing Wang, Weijie Yuan, Chunxiao Jiang, Alfred Hero* | **Category: cs.IT, math.IT** | **Updated: {updated}**

**Keywords:** 非自适应20问, 多目标追踪, 分辨率极限, 波束跟踪, 计算复杂度

**Comment:** 

> **TL;DR:** 本文研究了在查询依赖噪声信道下，非自适应20问估计用于定位和追踪多个移动目标的分辨率极限，并提出了一种计算复杂度更低的单阈值解码规则，适用于多目标追踪和波束跟踪。

**AI_Comments:** 这篇论文的创新点在于提出了一个计算复杂度更低的单阈值解码规则，用于非自适应20问估计，以追踪多个移动目标。它将理论界限与实际应用（如MIMO通信中的波束跟踪）相结合，并通过分析特殊情况和推广到更复杂的模型（分段常数速度）增强了其通用性。降低计算复杂度对于实际系统部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决多输入多输出（MIMO）通信中多设备波束跟踪的实际应用问题，研究在查询依赖噪声信道下定位和追踪多个移动目标的非自适应20问估计。

**Method:** 研究通过推导最优查询过程的分辨率非渐近界和二阶渐近界来分析问题。提出了一个通过阈值化互信息密度实现界限的状态估计器，该单阈值解码规则相比多阈值方案降低了计算复杂度。讨论了未知初始位置已知速度和已知初始位置未知速度两种特殊情况，并将结果推广到分段常数速度模型。

**Result:** 推导出了最优查询过程的分辨率非渐近界和二阶渐近界。证明了这些界限可以通过一个对可能目标位置的互信息密度进行阈值处理的状态估计器实现，且这种单阈值解码规则相比现有方案显著降低了计算复杂度。发现两种特殊情况（未知初始位置已知速度，已知初始位置未知速度）与静止多目标搜索的理论基准相同，并且在最大速度与查询次数成反比时，已知初始位置的情况接近静止目标搜索的理论基准。结果还推广到分段常数速度模型。

**Conclusion:** 本研究为多移动目标追踪的非自适应20问估计提供了分辨率极限的理论分析，并提出了一种计算效率更高的单阈值解码规则，其性能在特定条件下接近理论最优。该方法在5G无线网络中多移动发射器波束跟踪等应用中具有潜在价值。

> **ai_Abstract:** 本文研究了在查询依赖噪声信道下，非自适应20问估计在定位和追踪多个移动目标时的分辨率极限。作者推导了最优查询过程的非渐近和二阶渐近分辨率界限，并提出了一种基于互信息密度阈值的单阈值解码规则，该规则相比现有方法显著降低了计算复杂度。研究还讨论了已知速度未知初始位置和已知初始位置未知速度的特殊情况，并将其结果推广到分段常数速度模型，最终展示了其在5G无线网络多移动发射器波束跟踪中的应用。

> **摘要翻译:** 受多输入多输出（MIMO）通信中多设备波束跟踪实际应用的启发，我们研究了在查询依赖噪声信道下，用于定位和追踪多个移动目标的非自适应20问估计问题。具体来说，我们推导了最优查询过程的分辨率非渐近界和二阶渐近界，并提供了数值示例来说明我们的结果。特别是，我们证明了该界限可以通过一个对可能目标位置的互信息密度进行阈值处理的状态估计器来实现。这种单阈值解码规则与针对定位多个静止目标提出的多阈值方案（Zhou, Bai and Hero, TIT 2022）相比，降低了计算复杂度。我们讨论了我们设置的两种特殊情况：初始位置未知但速度已知的情况，以及初始位置已知但速度未知的情况。这两种情况都共享与Zhou, Bai and Hero (TIT 2022)中适用于静止多目标搜索的相同理论基准，而当最大速度与查询次数成反比时，已知初始位置的情况接近静止目标搜索的理论基准。我们还将结果推广到Zhou和Hero (TIT 2023)中引入的分段常数速度模型，其中目标周期性地改变速度。最后，我们阐述了我们提出的算法在5G无线网络中多个移动发射器波束跟踪应用中的应用。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [66] [Measurements and Modeling of Air-Ground Integrated Channel in Forest Environment Based on OFDM Signals](https://arxiv.org/abs/2507.02303)
> *基于OFDM信号的森林环境空地一体化信道测量与建模*

*Zhe Xiao, Shu Sun, Na Liu, Lianming Xu, Li Wang* | **Category: cs.IT, math.IT** | **Updated: {updated}**

**Keywords:** 森林通信, 信道测量, 空地一体化, OFDM, 路径损耗模型

**Comment:** 

> **TL;DR:** 本文在森林环境中进行了空地信道测量与建模，并提出了适用于森林环境的路径损耗模型和多径模型。

**AI_Comments:** 本文的创新之处在于其在真实的森林环境中进行了详细的空地一体化信道测量，并针对性地提出了适用于该特殊环境的路径损耗和多径模型。这对于提升森林区域，尤其是灾害救援场景下的通信系统可靠性具有重要意义。研究结果揭示了森林中不同障碍物（树冠与树干）对信号传播的影响差异，并提出了通过调整仰角优化通信的实用建议。

<details>
  <summary>Details</summary>

**Motivation:** 森林环境因气候、植被密度和复杂地形地质常受自然灾害影响，救援人员需要可靠的通信系统保障安全。然而，现有研究中关于森林区域信道检测和建模的研究有限，这突显了在森林环境中进行信道测量的关键性。

**Method:** 本文在内蒙古阿尔山国家森林公园进行了空地信道测量活动。测量使用中心频率为1.4 GHz的正交频分复用（OFDM）信号进行信道探测。在G2G测量中，除了使用全向天线记录数据外，还使用定向天线记录信号在接收端的到达角信息。在A2G测量中，预先规划了无人机的飞行轨迹，使其能以相对于地面固定的角度飞行。基于测量结果分析，提出了适用于森林环境中G2G和A2G场景的路径损耗模型，并推导了森林环境特有的多径模型表达式，对阴影衰落因子、均方根时延扩展和莱斯K因子等关键信道参数进行了统计分析。

**Result:** 结果表明，所提出的模型相比其他路径损耗模型降低了误差裕度。研究还发现，A2G通信中树冠对信号传播的阻碍比G2G通信中树干的阻碍更明显。调整空地之间的仰角可以提高通信质量。

**Conclusion:** 本研究通过在森林环境中进行详细的信道测量和建模，提出了更精确的路径损耗和多径模型，并揭示了森林环境中空地通信的特性，为提升森林救援通信的可靠性提供了重要依据。

> **ai_Abstract:** 本文针对森林环境中通信系统缺乏信道检测和建模研究的问题，在内蒙古阿尔山国家森林公园进行了详细的空地信道测量。研究使用了1.4 GHz的OFDM信号，分析了地对地和空对地两种场景。基于测量数据，论文提出了适用于森林环境的路径损耗模型和多径模型，并对关键信道参数进行了统计分析。研究发现，所提出的模型能有效减少误差，且在空对地通信中树冠的阻碍效应比地对地通信中树干的阻碍更显著，通过调整仰角可以改善通信质量。

> **摘要翻译:** 森林经常受到气候条件、植被密度以及复杂地形地质的影响，这些因素导致了自然灾害的发生。在这些环境中从事或支持救援行动的人员依赖于强大的通信系统以确保自身安全，这突显了森林环境中信道测量的关键性。然而，根据目前的研究，现有文献中关于森林区域信道检测和建模的研究有限。本文描述了在内蒙古阿尔山国家森林公园进行的空地信道测量活动。它提供了地对地（G2G）和空对地（A2G）场景的测量结果和传播模型。测量活动使用中心频率为1.4 GHz的正交频分复用信号进行信道探测。在G2G测量中，除了使用全向天线记录数据外，我们还使用定向天线记录信号在接收端的到达角信息。在A2G测量中，我们预先规划了无人机的飞行轨迹，使其能以相对于地面固定的角度飞行。基于测量结果分析，我们提出了适用于森林环境中G2G和A2G的路径损耗模型。结果表明，所提出的模型相比其他路径损耗模型降低了误差裕度。此外，我们推导了森林环境特有的多径模型表达式，并对阴影衰落因子、均方根时延扩展和莱斯K因子等关键信道参数进行了统计分析。我们的发现表明，A2G通信中树冠对信号传播的阻碍比G2G通信中树干的阻碍更明显。调整空地之间的仰角可以增强通信质量。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [91] [On the Convergence of Large Language Model Optimizer for Black-Box Network Management](https://arxiv.org/abs/2507.02689)
> *大型语言模型优化器在黑盒网络管理中的收敛性研究*

*Hoon Lee, Wentao Zhou, Merouane Debbah, Inkyu Lee* | **Category: cs.IT, eess.SP, math.IT** | **Updated: {updated}**

**Keywords:** 大型语言模型, 优化器, 黑盒网络管理, 收敛性, 马尔可夫链

**Comment:** 

> **TL;DR:** 本文首次为大型语言模型优化器（LLMO）框架在黑盒网络管理中的应用建立了理论基础，通过将其解释为有限状态马尔可夫链并证明其收敛性，同时将其结果扩展到多LLM架构。

**AI_Comments:** 本文具有创新性，因为它首次为LLM优化器框架提供了理论基础，超越了经验观察，建立了其收敛性的数学保证。这对于在网络管理等关键黑盒优化任务中建立信任和实现LLM的更稳健部署至关重要，尤其是在当前主要依赖数值模拟的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 未来的无线网络将整合缺乏通用数学模型的各种服务，即黑盒网络管理任务。大型语言模型（LLM）优化器框架被认为是解决此类问题的有前景方案，但其理论基础，特别是收敛性，此前仅限于数值模拟，缺乏严格证明。

**Method:** 本文通过仔细研究LLM推理步骤，将LLM优化器（LLMO）过程解释为一个有限状态马尔可夫链，并首次证明了该框架的收敛性。研究结果进一步扩展到更先进的多LLM架构，并严格验证了多LLM对收敛速度的影响。全面的数值模拟验证了理论结果。

**Result:** 本文成功建立了LLM优化器（LLMO）框架的理论基础，通过将其解释为有限状态马尔可夫链，证明了其收敛性。研究结果还扩展到多LLM架构，并验证了多LLM对收敛速度的影响。数值模拟验证了这些理论发现。

**Conclusion:** LLM优化器框架在黑盒网络管理中具有坚实的理论基础，其收敛性已被证明，并且在多LLM设置下的行为也得到了理解，这为该框架更稳健的应用铺平了道路。

> **ai_Abstract:** 本文解决了大型语言模型优化器（LLMO）框架在黑盒网络管理中缺乏理论基础的问题。通过将LLMO过程视为一个有限状态马尔可夫链，作者严格证明了其收敛性。研究进一步将这些发现扩展到多LLM架构，分析了它们对收敛速度的影响。全面的数值模拟支持了理论结果，加深了对LLMO框架的理解。

> **摘要翻译:** 未来的无线网络预计将整合各种服务，这些服务通常缺乏通用的数学模型。为了解决此类黑盒网络管理任务，大型语言模型（LLM）优化器框架——它利用预训练LLM作为优化代理——最近被推广为一种有前景的解决方案。该框架利用描述给定优化问题的自然语言提示以及LLM自身生成的过去解决方案。因此，LLM无需了解目标函数的数学模型即可自主获得高效解决方案。尽管LLM优化器（LLMO）框架在各种黑盒场景中的可行性已得到研究，但迄今为止，它仅限于数值模拟。本文首次为LLMO框架建立了理论基础。通过对LLM推理步骤的仔细研究，我们可以将LLMO过程解释为一个有限状态马尔可夫链，并证明了该框架的收敛性。我们的结果被扩展到更先进的多LLM架构，其中严格验证了多LLM在收敛速度方面的影响。全面的数值模拟验证了我们的理论结果，并提供了对LLMO框架底层机制的更深入理解。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [115] [RIS-Aided Cooperative ISAC Networks for Structural Health Monitoring](https://arxiv.org/abs/2507.02731)
> *RIS辅助的合作ISAC网络用于结构健康监测*

*Jie Yang, Chao-Kai Wen, Xiao Li, Shi Jin* | **Category: cs.IT, eess.SP, math.IT** | **Updated: {updated}**

**Keywords:** ISAC, 结构健康监测, 可重构智能表面, 协作感知, 毫米级检测

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本研究提出并分析了一种新颖的理论框架，利用可重构智能表面（RIS）辅助的集成感知与通信（ISAC）网络进行结构健康监测（SHM），通过抑制多径干扰和优化系统参数，实现了毫米级变形检测。

**AI_Comments:** 该论文提出了一种创新的方法，将RIS技术与ISAC网络结合应用于结构健康监测，有效地解决了多径干扰和高精度测量难题。通过理论分析和数值验证，展示了该方法在毫米级变形检测上的可行性，对未来高精度SHM系统的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 集成感知与通信（ISAC）在未来蜂窝系统中具有重要应用潜力，但其在结构健康监测（SHM）领域的应用仍未被充分探索，主要面临多径干扰和对超高感知精度要求等挑战。

**Method:** 本研究引入了一种新颖的理论框架，利用可重构智能表面（RIS）作为参考点，与基站和用户协作，通过动态调整RIS相位来抑制背景多径干扰，提高测量精度。研究使用Fisher信息理论分析了三维蜂窝网络中的RIS辅助协作感知，并开发了贝叶斯推理模型来识别结构状态和验证损伤检测概率。

**Result:** 理论和数值分析均证实，通过增加观测时间、引入额外接收器、优化RIS相位和优化协作节点选择，可以显著降低位置误差界限，满足SHM的严格精度要求。ISAC网络能够实现毫米级的变形检测。

**Conclusion:** 本研究证明了RIS辅助的协作ISAC网络在结构健康监测方面的巨大潜力，能够实现高精度的毫米级变形检测，为未来的SHM应用提供了新的解决方案。

> **ai_Abstract:** 本研究提出了一种利用可重构智能表面（RIS）辅助的集成感知与通信（ISAC）网络进行结构健康监测（SHM）的新型理论框架。针对SHM中多径干扰和高精度需求的挑战，该框架通过动态调整RIS相位来抑制干扰并提高测量精度。研究运用Fisher信息理论分析了三维蜂窝网络中的RIS辅助协作感知，并通过理论和数值分析验证了该系统在毫米级变形检测方面的能力，证明了其在实现高精度SHM应用中的巨大潜力。

> **摘要翻译:** 集成感知与通信（ISAC）是未来蜂窝系统的一个关键特征，能够利用相同的基础设施实现入侵者检测、监测和跟踪等应用。然而，其在结构健康监测（SHM）方面的潜力仍未被充分探索，SHM需要检测缓慢而细微的结构变化，并面临多径干扰和对超高感知精度需求等挑战。本研究通过利用可重构智能表面（RIS）作为参考点，与基站和用户协作，引入了一种新颖的ISAC辅助SHM理论框架。通过动态调整RIS相位以生成不同的无线电信号，从而抑制背景多径干扰，增强了这些参考点的测量精度。我们使用Fisher信息理论对三维蜂窝网络中的RIS辅助协作感知进行了理论分析，证明了增加观测时间、引入额外接收器（即使存在自定位误差）、优化RIS相位以及优化协作节点选择可以降低位置误差界限，以满足SHM严格的精度要求。此外，我们开发了一个贝叶斯推理模型来识别结构状态并验证损伤检测概率。理论和数值分析均证实了ISAC实现毫米级变形检测的能力，突出了其在高精度SHM应用中的潜力。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [16] [Advanced Printed Sensors for Environmental Applications: A Path Towards Sustainable Monitoring Solutions](https://arxiv.org/abs/2507.02067)
> *环境应用中的先进印刷传感器：通向可持续监测解决方案的道路*

*Nikolaos Papanikolaou, Doha Touhafi, Jurgen Vandendriessche, Danial Karimi, Sohail Fatimi, Gianluca Cornetta, Abdellah Touhafi* | **Category: cs.AR** | **Updated: {updated}**

**Keywords:** 印刷传感器,环境监测,可持续解决方案,柔性传感器,污染物检测

**Comment:** 

> **TL;DR:** 印刷传感器是用于环境监测的柔性、经济高效且可定制的先进技术。

**AI_Comments:** 这篇论文强调了印刷传感器在环境监测领域的巨大潜力，其创新性在于结合了柔性、成本效益和高定制性，为传统传感器提供了可持续的替代方案。其广泛的应用前景和高灵敏度是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 印刷传感器是传感器技术的变革性进步，可用于环境因素的监测，提供可持续的监测解决方案。

**Method:** 使用创新的印刷技术制造柔性、经济高效且高度可定制的传感设备。

**Result:** 印刷传感器在检测污染物、温度变化、湿度水平以及环境评估和保护所必需的其他关键参数方面表现出高灵敏度和准确性。

**Conclusion:** 印刷传感器在环境应用中具有巨大潜力，是实现可持续监测解决方案的关键。

> **ai_Abstract:** 本文探讨了印刷传感器作为一种变革性技术，其通过创新印刷技术制造柔性、经济高效且高度可定制的设备。这些传感器在环境监测中具有广泛应用，能够高灵敏度、高精度地检测空气和水质、土壤条件、大气变化、污染物、温度和湿度等关键环境参数，为可持续监测解决方案提供了途径。

> **摘要翻译:** 印刷传感器代表了传感器技术的变革性进步，利用创新的印刷技术来创建柔性、经济高效且高度可定制的传感设备。它们的通用性使其能够集成到各个领域的众多应用中，例如监测各种环境因素，包括空气和水质、土壤条件以及大气变化等。这些传感器在检测污染物、温度变化、湿度水平以及环境评估和保护所必需的其他关键参数方面表现出高灵敏度和准确性。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [45] [Hardware-Accelerated Algorithm for Complex Function Roots Density Graph Plotting](https://arxiv.org/abs/2507.02164)
> *硬件加速的复函数根密度图绘制算法*

*Ruibai Tang, Chengbin Quan* | **Category: cs.AR** | **Updated: {updated}**

**Keywords:** 硬件加速, 复函数根, FPGA, QR迭代, 能效

**Comment:** 

> **TL;DR:** 本文提出了一种硬件加速算法，用于绘制复函数根密度图，通过多项式逼近和QR迭代在FPGA上实现，相比CPU能效高65倍。

**AI_Comments:** 该论文的创新点在于将复函数根的求解与可视化任务通过硬件加速实现，特别是利用FPGA的并行处理能力和优化QR分解算法。其显著的能效提升是亮点，但与GPU的性能差距也指出了未来在制造工艺或算法层面仍有优化空间。

<details>
  <summary>Details</summary>

**Motivation:** 求解和可视化复函数的潜在根在理论和应用领域都至关重要，但通常计算密集。

**Method:** 通过多项式逼近复函数，并使用单移QR迭代求解其根。利用伴随矩阵的Hessenberg结构和Givens旋转优化QR分解，设计了流水线化的FPGA架构，能够以高吞吐量处理大量多项式。

**Result:** 该实现比基于CPU的方法能效高出65倍。尽管由于制造技术差异，其性能落后于现代GPU。

**Conclusion:** 提出的硬件加速算法在复函数根密度图绘制方面表现出显著的能效提升，为计算密集型任务提供了FPGA加速的有效途径。

> **ai_Abstract:** 本文提出了一种用于复函数根密度图绘制的硬件加速算法。该算法通过多项式逼近复函数并利用单移QR迭代求解其根，并针对FPGA设计了流水线架构，优化了QR分解。实验结果表明，该FPGA实现比CPU方法能效高出65倍，证明了其在处理计算密集型任务方面的潜力。

> **摘要翻译:** 求解和可视化复函数的潜在根在理论和应用领域都至关重要，但通常计算密集。我们提出了一种硬件加速算法，用于绘制复函数根密度图，通过多项式逼近函数并使用单移QR迭代求解其根。通过利用伴随矩阵的Hessenberg结构并用Givens旋转优化QR分解，我们设计了一个流水线化的FPGA架构，能够以高吞吐量处理大量多项式。我们的实现比基于CPU的方法能效高出65倍，尽管由于制造技术差异，其性能落后于现代GPU。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [69] [System-performance and cost modeling of Large Language Model training and inference](https://arxiv.org/abs/2507.02456)
> *大型语言模型训练与推理的系统性能与成本建模*

*Wenzhe Guo, Joyjit Kundu, Uras Tos, Weijiang Kong, Giuliano Sisto, Timon Evenblij, Manu Perumkunnil* | **Category: cs.AR** | **Updated: {updated}**

**Keywords:** 大型语言模型, 性能建模, 成本建模, 训练推理, 分布式系统

**Comment:** 

> **TL;DR:** 该论文提出了一种针对大型语言模型（LLM）训练和推理的性能-成本建模方法，旨在解决LLM在分布式系统上扩展性面临的挑战，并为未来的计算系统设计提供指导。

**AI_Comments:** 这篇论文的创新点在于其提出的综合性性能-成本建模方法。它不仅考虑了传统的计算和内存瓶颈，还融入了最新的优化技术（如闪存注意力、专家混合模型），并深入分析了网络拓扑和多维并行性的影响。更重要的是，它集成了芯片成本模型，使得研究能够从性能和成本两个维度进行全面的权衡分析，这对于指导未来大规模AI系统的硬件-软件协同设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的规模和复杂性呈指数级增长，但计算能力、内存带宽、网络性能和成本效率的进步未能跟上，这给LLM在分布式系统上的可扩展性带来了重大挑战。为了解决这些限制，需要一种能够整合最新技术并分析性能与成本权衡的建模方法。

**Method:** 本文提出了一种针对LLM训练和推理的性能-成本建模方法。该方法整合了最先进的计算技术、内存优化和最新的通信技术。它基于一个分析性能模型，并纳入了闪存注意力（flash attention）技术和专家混合模型（mixture of experts models）等创新，以解决内存带宽和计算瓶颈。该方法还考虑了不同网络拓扑结构和特定拓扑的通信算法（结合5D并行），并集成了芯片成本模型。

**Result:** 该建模方法能够为未来的计算系统设计提供有价值的见解，并促进硬件-软件协同开发。特别是，它能够分析各种系统架构配置下的性能-成本权衡。

**Conclusion:** 所提出的性能-成本建模方法能够有效分析大型语言模型训练和推理中的性能与成本权衡，为指导未来的计算系统设计和促进硬件-软件协同开发提供了重要工具。

> **ai_Abstract:** 本文提出了一种创新的性能-成本建模方法，旨在解决大型语言模型（LLM）训练和推理在扩展性上面临的挑战。该方法整合了先进的计算、内存优化和通信技术，并特别考虑了闪存注意力、专家混合模型、不同网络拓扑以及5D并行性。此外，该框架还包含一个芯片成本模型。这项工作旨在通过提供分析性能-成本权衡的能力，为未来的计算系统设计和硬件-软件协同开发提供指导。

> **摘要翻译:** 基于Transformer架构的大型语言模型（LLMs）以其卓越的可扩展性和适应性，彻底改变了人工智能、科学和工程领域的众多领域。然而，LLM规模和复杂性的指数级增长已经超越了计算能力、内存带宽、网络性能和成本效率的进步，这对它们在分布式系统上的可扩展性构成了重大挑战。为了解决这些限制，文献中提出了替代模型架构、优化策略、通信感知网络拓扑以及新颖的系统设计方法。本文介绍了一种针对LLM训练和推理的性能-成本建模方法，该方法整合了最先进的计算技术、内存优化和最新的通信技术。我们的方法建立在分析性能模型之上，并结合了闪存注意力技术和专家混合模型等最新创新，以解决内存带宽和计算瓶颈。它还考虑了不同网络拓扑结构和结合5D并行性的特定拓扑通信算法的影响。该框架还集成了芯片成本模型。所提出的建模方法为指导未来的计算系统设计提供了宝贵的见解，并促进了硬件-软件协同开发，特别是由于其能够分析各种系统架构配置下的性能-成本权衡。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [95] [AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models](https://arxiv.org/abs/2507.02598)
> *AC-Refiner：使用条件扩散模型实现高效算术电路优化*

*Chenhao Xue, Kezhi Li, Jiaxing Zhang, Yi Ren, Zhengyuan Shi, Chen Zhang, Yibo Lin, Lining Zhang, Qiang Xu, Guangyu Sun* | **Category: cs.AR, cs.AI** | **Updated: {updated}**

**Keywords:** 算术电路优化, 条件扩散模型, 图像生成, 帕累托最优性, 深度学习

**Comment:** 8 pages, 12 figures

> **TL;DR:** AC-Refiner利用条件扩散模型将算术电路优化重构为条件图像生成任务，能够高效生成具有卓越帕累托最优性的电路设计，优于现有SOTA方法。

**AI_Comments:** AC-Refiner的创新之处在于其将算术电路优化问题巧妙地转换为条件图像生成任务，并引入了条件扩散模型，这为复杂的电路设计空间探索提供了一种新颖且高效的解决方案。通过将探索集中在帕累托前沿，该方法能够持续生成高质量的设计，显著提升了优化效率和设计质量，对数字系统设计领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 算术电路是数字系统的基本组成部分，直接影响性能、功耗和面积。然而，由于巨大的设计空间和复杂的物理约束，优化这些电路仍然具有挑战性。现有的基于深度学习的方法难以持续探索高潜力设计变体，限制了其优化效率。

**Method:** 我们提出了AC-Refiner，一个利用条件扩散模型的新型算术电路优化框架。核心思想是将算术电路综合重构为条件图像生成任务。通过根据目标质量结果（QoRs）仔细调整去噪扩散过程，AC-Refiner能够持续生成高质量的电路设计。此外，探索到的设计用于微调扩散模型，使探索集中在帕累托前沿附近。

**Result:** 实验结果表明，AC-Refiner生成的电路设计具有卓越的帕累托最优性，优于现有最先进的基线。将AC-Refiner集成到实际应用中进一步验证了其性能提升。

**Conclusion:** AC-Refiner通过将算术电路优化重新定义为条件图像生成任务并利用条件扩散模型，显著提升了算术电路的优化效率和设计质量，实现了优于现有技术水平的帕累托最优性设计。

> **ai_Abstract:** AC-Refiner是一个创新的算术电路优化框架，它将电路综合问题转化为条件图像生成任务，并利用条件扩散模型进行优化。该方法通过对去噪扩散过程进行条件限制，并利用探索到的设计微调模型，从而高效生成具有卓越帕累托最优性的电路设计，其性能超越了现有最先进的方法，并在实际应用中得到了验证。

> **摘要翻译:** 算术电路，如加法器和乘法器，是数字系统的基本组成部分，直接影响性能、功耗效率和面积占用。然而，由于巨大的设计空间和复杂的物理约束，优化这些电路仍然具有挑战性。虽然最近基于深度学习的方法已显示出前景，但它们难以持续探索高潜力的设计变体，限制了其优化效率。为了应对这一挑战，我们提出了AC-Refiner，一个利用条件扩散模型的新型算术电路优化框架。我们的关键见解是将算术电路综合重构为条件图像生成任务。通过根据目标质量结果（QoRs）仔细调整去噪扩散过程，AC-Refiner能够持续生成高质量的电路设计。此外，探索到的设计用于微调扩散模型，使探索集中在帕累托前沿附近。实验结果表明，AC-Refiner生成的电路设计具有卓越的帕累托最优性，优于现有最先进的基线。将AC-Refiner集成到实际应用中进一步验证了其性能提升。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [119] [Breaking the HBM Bit Cost Barrier: Domain-Specific ECC for AI Inference Infrastructure](https://arxiv.org/abs/2507.02654)
> *打破HBM比特成本障碍：面向AI推理基础设施的领域专用ECC*

*Rui Xie, Asad Ul Haq, Yunhua Fang, Linsen Ma, Sanchari Sen, Swagath Venkataramani, Liu Liu, Tong Zhang* | **Category: cs.AR** | **Updated: {updated}**

**Keywords:** HBM, ECC, AI推理, 成本优化, 可靠性

**Comment:** 

> **TL;DR:** 通过系统级领域专用ECC，在不牺牲AI推理性能和准确性的前提下，降低HBM成本。

**AI_Comments:** 这项工作通过将可靠性从固定的硬件约束转变为可调的系统参数，为降低HBM在AI推理中的成本提供了一个创新且实用的方法。其核心在于通过领域专用ECC来替代昂贵的片上ECC，并在高误码率下仍能保持性能和准确性，这对于推动HBM在AI领域的广泛应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高带宽内存（HBM）为AI工作负载提供了卓越的带宽和能效，但其高昂的每比特成本（部分源于严格的片上可靠性要求）日益成为可扩展部署的障碍。

**Method:** 本工作探索了一种系统级的成本降低方法，通过消除片上ECC并将所有故障管理转移到内存控制器。引入了一个领域专用ECC框架，该框架结合了长码字Reed-Solomon纠错、轻量级细粒度CRC检测、用于减轻写入放大的差分奇偶校验更新，以及基于数据重要性的可调保护。

**Result:** 使用LLM推理工作负载进行的评估表明，即使在原始HBM误码率高达10^-3的情况下，与配备理想无错HBM的系统相比，该系统仍保留了超过78%的吞吐量和97%的模型准确性。

**Conclusion:** 通过将可靠性视为可调的系统参数而非固定的硬件约束，该设计为AI基础设施中低成本、高性能HBM的部署开辟了一条新路径。

> **ai_Abstract:** 该研究旨在解决高带宽内存（HBM）在AI基础设施中因严格的可靠性要求导致的高成本问题。通过提出一种系统级的、领域专用的ECC框架，该框架消除了片上ECC，并将故障管理转移到内存控制器，结合了Reed-Solomon纠错、CRC检测、差分奇偶校验和可调保护。实验结果表明，即使在较高的原始HBM误码率下，该系统也能保持高吞吐量和模型准确性，为AI基础设施中低成本、高性能HBM的部署提供了新的途径。

> **摘要翻译:** 高带宽内存（HBM）为AI工作负载提供了卓越的带宽和能效，但其高昂的每比特成本（部分源于严格的片上可靠性要求）日益成为可扩展部署的障碍。本工作探索了一种系统级的成本降低方法，通过消除片上ECC并将所有故障管理转移到内存控制器。我们引入了一个领域专用ECC框架，结合了长码字Reed-Solomon纠错、轻量级细粒度CRC检测、用于减轻写入放大的差分奇偶校验更新，以及基于数据重要性的可调保护。使用LLM推理工作负载进行的评估表明，即使在原始HBM误码率高达10^-3的情况下，与配备理想无错HBM的系统相比，该系统仍保留了超过78%的吞吐量和97%的模型准确性。通过将可靠性视为可调的系统参数而非固定的硬件约束，我们的设计为AI基础设施中低成本、高性能HBM的部署开辟了一条新路径。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [19] [SAKURAONE: Empowering Transparent and Open AI Platforms through Private-Sector HPC Investment in Japan](https://arxiv.org/abs/2507.02124)
> *SAKURAONE：通过日本私营部门HPC投资赋能透明开放的AI平台*

*Fumikazu Konishi* | **Category: cs.DC, cs.NI, C.5.5; B.8.2** | **Updated: {updated}**

**Keywords:** HPC, SAKURAONE, 开放网络, AI平台, LLM训练

**Comment:** 13 pages, 2 Figures, 10 tables

> **TL;DR:** SAKURAONE是日本樱花互联网研究中心开发的HPC集群，在全球TOP500榜单中排名第49位，其独特之处在于采用了完全开放的网络堆栈（800 GbE和SONiC），展示了开放技术在大规模HPC中的可行性，并为AI工作负载提供了强大性能。

**AI_Comments:** SAKURAONE的创新之处在于其大规模采用完全开放的网络堆栈（800 GbE和SONiC），这在大规模HPC领域，尤其是在TOP100系统中是独一无二的。这不仅展示了开放技术在替代传统专有解决方案方面的强大潜力，也为未来HPC基础设施的构建提供了新的范式。该项目由私营部门投资推动，对于日本乃至全球推动AI平台透明化和开放化具有重要意义，尤其是在支持LLM等前沿AI应用方面。其高性能指标也证明了该系统在应对复杂计算挑战方面的强大能力。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在通过介绍SAKURAONE HPC集群，赋能透明和开放的AI平台，并展示私营部门投资在高性能计算领域，特别是支持大型语言模型训练等先进工作负载的潜力与可行性。

**Method:** SAKURAONE是一个由樱花互联网研究中心开发和运营的托管式高性能计算（HPC）集群。它采用“KOKARYOKU PHY”裸金属GPU服务器配置，包含100个计算节点，每个节点配备8个NVIDIA H100 GPU。系统配备了总物理容量为2拍字节的全闪存Lustre存储子系统。内部节点通信通过基于Rail-Optimized拓扑的全双向带宽互连实现，其中Leaf和Spine层通过800 GbE链接互连，并结合RoCEv2技术实现高速无损数据传输。

**Result:** SAKURAONE在ISC 2025的TOP500榜单中排名全球第49位。它是前100名中唯一采用基于800 GbE和SONiC操作系统的完全开放网络堆栈的系统。它在HPL基准测试中实现了33.95 PFLOP/s的持续性能，在HPCG基准测试中实现了396.295 TFLOP/s的性能。针对AI应用中的低精度工作负载，SAKURAONE在HPL-MxP基准测试中使用FP8精度提供了339.86 PFLOP/s的性能。

**Conclusion:** SAKURAONE项目展示了开放和供应商中立技术在大规模HPC基础设施中的可行性，并证明了私营部门投资在赋能透明开放AI平台方面的强大潜力。其高性能和独特的开放网络设计使其成为支持先进AI工作负载的全球竞争力系统。

> **ai_Abstract:** SAKURAONE是日本樱花互联网研究中心开发的HPC集群，旨在支持包括LLM训练在内的先进AI工作负载。该系统在ISC 2025 TOP500榜单中位列全球第49位，并以其独特的完全开放网络堆栈（基于800 GbE和SONiC）脱颖而出，证明了开放技术在大规模HPC中的可行性。SAKURAONE展示了33.95 PFLOP/s的HPL性能和339.86 PFLOP/s的FP8 AI工作负载性能，其由100个配备NVIDIA H100 GPU的计算节点、2PB全闪存Lustre存储和基于800 GbE的Rail-Optimized互连构成，确保了高吞吐量和低延迟的数据传输。

> **摘要翻译:** SAKURAONE是由樱花互联网研究中心开发和运营的托管式高性能计算（HPC）集群。它强化了裸金属GPU服务器的“KOKARYOKU PHY”配置，被设计为针对包括大型语言模型（LLM）训练在内的先进工作负载进行优化的集群计算资源。
在ISC 2025版的TOP500榜单中，SAKURAONE基于其高性能Linpack（HPL）分数在全球排名第49位，展示了其全球竞争力。特别是，它是前100名中唯一采用基于800 GbE（千兆以太网）和SONiC（云开放网络软件）操作系统的完全开放网络堆栈的系统，突显了开放和供应商中立技术在大规模HPC基础设施中的可行性。
SAKURAONE在HPL基准测试（Rmax）中实现了33.95 PFLOP/s的持续性能，在高性能共轭梯度（HPCG）基准测试中实现了396.295 TFLOP/s的性能。对于针对代表AI应用的低精度工作负载的HPL-MxP基准测试，SAKURAONE使用FP8精度提供了令人印象深刻的339.86 PFLOP/s。
该系统包含100个计算节点，每个节点配备八个NVIDIA H100 GPU。它由一个总物理容量为2拍字节的全闪存Lustre存储子系统支持，提供高吞吐量和低延迟数据访问。内部节点通信通过基于Rail-Optimized拓扑的全双向带宽互连实现，其中Leaf和Spine层通过800 GbE链接互连。这种拓扑结构与RoCEv2（基于融合以太网的RDMA版本2）相结合，实现了高速、无损的数据传输，并缓解了大规模并行工作负载中的通信瓶颈。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [48] [Signalling Health for Improved Kubernetes Microservice Availability](https://arxiv.org/abs/2507.02158)
> *通过健康信号提高 Kubernetes 微服务可用性*

*Jacob Roberts, Blair Archibald, Phil Trinder* | **Category: cs.DC** | **Updated: {updated}**

**Keywords:** 微服务, Kubernetes, 容器监控, SCM, PCM, 服务可用性

**Comment:** 10 pages, 7 figures

> **TL;DR:** 基于轮询的容器监控（PCM）在Kubernetes微服务中存在局限性，导致故障检测慢且可能降低可用性。本文提出了基于信号的容器监控（SCM），通过容器主动发送状态变化信号，实现了更快的故障检测（比PCM快86%），避免了错误检测，并提高了服务可用性，且无需复杂调优。

**AI_Comments:** 这篇论文提出了一种创新的容器健康监控方法SCM，通过主动信号机制有效解决了传统轮询机制的局限性，如检测延迟和误报。其创新性在于改变了传统的被动轮询模式为主动报告模式，提高了故障响应速度和系统可用性。对于大规模微服务部署而言，这种更高效、更准确的健康信号机制具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于轮询的容器监控（PCM）方法在Kubernetes中存在需要仔细调优、可能降低服务可用性以及检测容器健康变化慢的问题，这促使研究者寻找更高效的替代方案。

**Method:** 本文提出并设计、实现和评估了一种基于信号的容器监控（SCM）方法，用于Kubernetes环境。研究通过一个新的数学模型预测了SCM的优势，并使用SockShop基准在六项实验中，将SCM与传统的基于轮询的容器监控（PCM）的服务可用性进行了比较。

**Result:** SCM不需要调优轮询间隔，检测容器故障比PCM快86%，检测容器就绪时间与PCM相当且资源开销有限。研究发现PCM可能错误地检测故障，导致服务可用性降低4%。

**Conclusion:** 本文建议容器编排器应提供基于信号的容器监控（SCM）功能，以实现比传统基于轮询的容器监控（PCM）更快的故障检测，同时避免错误检测和复杂的调优。

> **ai_Abstract:** 这篇论文提出了一种新的基于信号的容器监控（SCM）方法，旨在解决现有基于轮询的容器监控（PCM）在Kubernetes微服务中存在的效率和准确性问题。通过设计、实现和评估SCM，并与PCM进行对比，研究表明SCM在故障检测速度上显著优于PCM（快86%），同时避免了PCM可能导致的错误故障检测和对服务可用性的负面影响，且无需复杂的调优。研究建议将SCM功能集成到容器编排器中以提高微服务可用性。

> **摘要翻译:** 微服务通常由容器编排器部署和管理，该编排器可以检测和修复故障，以保持在许多应用程序中至关重要的服务可用性。在基于轮询的容器监控（PCM）中，编排器定期检查容器健康状况。尽管这是一种常见的方法，但PCM需要仔细调优，可能会降低服务可用性，并且检测容器健康变化的速度可能较慢。另一种方法是基于信号的容器监控（SCM），其中容器在其状态改变时向编排器发送信号。我们介绍了Kubernetes中SCM方法的设计、实现和评估，并通过实证表明它比PCM具有优势，这与新的数学模型预测的一致。我们使用SockShop基准在六项实验中比较了SCM和PCM的服务可用性。SCM不需要调优轮询间隔，并且检测容器故障比PCM快86%，检测容器就绪时间相当，且资源开销有限。我们发现PCM可能会错误地检测故障，这会使服务可用性降低4%。我们建议编排器提供SCM功能，以实现比PCM更快的故障检测，同时避免错误检测或仔细调优。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [72] [Domain-Adversarial Transfer Learning for Fault Root Cause Identification in Cloud Computing Systems](https://arxiv.org/abs/2507.02233)
> *用于云计算系统故障根源识别的域对抗迁移学习*

*Bruce Fang, Danyi Gao* | **Category: cs.DC** | **Updated: {updated}**

**Keywords:** 故障根源识别, 域对抗迁移学习, 云计算, 伪标签, 类别不平衡

**Comment:** 

> **TL;DR:** 本文提出了一种基于域对抗迁移学习的智能算法，用于解决云计算环境中故障根源识别的挑战，并在标签稀缺、类别不平衡和异构节点环境下表现出优越的性能和鲁棒性。

**AI_Comments:** 该论文的创新点在于将域对抗迁移学习应用于云计算系统的故障根源识别，并结合了伪标签选择策略来处理标签稀缺和类别不平衡问题。这种方法有效提升了模型在复杂真实场景下的泛化能力和对少数故障的识别能力，对于提高云系统运维效率具有重要价值。其在极端条件下的优异表现是其重要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 云计算环境中，由于系统结构复杂、服务耦合紧密以及故障信息有限，导致故障根源识别面临巨大挑战。

**Method:** 本文提出了一种基于迁移学习的智能识别算法。该方法引入了共享特征提取模块和域对抗机制，以实现从源域到目标域的有效知识迁移，从而提高模型在目标域的判别能力和泛化性能。模型还结合了伪标签选择策略，在目标域缺乏标签样本时，利用高置信度预测进行训练，以增强模型对少数类别的识别能力。

**Result:** 实验结果表明，所提出的方法在准确率、F1-Score和AUC等关键指标上优于现有主流方法。模型表现出更强的判别力和鲁棒性。尤其是在极端类别不平衡和目标域存在显著结构差异的情况下，模型仍能保持高性能。

**Conclusion:** 本文提出的基于域对抗迁移学习的故障根源识别方法在复杂云计算系统中具有有效性和实用价值，尤其在标签稀缺、类别不平衡和异构节点等挑战性场景下表现出色。

> **ai_Abstract:** 本文针对云计算系统故障根源识别的挑战，提出了一种基于域对抗迁移学习的智能算法。该方法通过共享特征提取模块、域对抗机制和伪标签选择策略，有效解决了标签稀缺、类别不平衡和异构节点环境下的知识迁移和少数类识别问题。实验证明，该方法在准确率、F1-Score和AUC等指标上均优于现有方法，展现出强大的判别能力和鲁棒性，尤其在复杂和极端条件下仍能保持高性能。

> **摘要翻译:** 本文解决了云计算环境中故障根源识别的挑战。由于复杂的系统结构、密集的服务耦合和有限的故障信息，导致识别困难。为了解决这个问题，提出了一种基于迁移学习的智能识别算法。该方法引入了共享特征提取模块和域对抗机制，以实现从源域到目标域的有效知识迁移。这提高了模型在目标域的判别能力和泛化性能。该模型结合了伪标签选择策略。当目标域缺乏标签样本时，使用高置信度预测进行训练。这增强了模型识别少数类别的能力。为了评估该方法在实际场景中的稳定性和适应性，在三种条件下设计了实验：标签稀缺、类别不平衡和异构节点环境。实验结果表明，所提出的方法在准确率、F1-Score和AUC等几个关键指标上优于现有主流方法。该模型表现出更强的判别能力和鲁棒性。值得注意的是，在极端类别不平衡和目标域存在显著结构差异的情况下，该模型仍然保持高性能。这验证了所提出的机制在复杂云计算系统中的有效性和实用价值。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [96] [Flotilla: A scalable, modular and resilient federated learning framework for heterogeneous resources](https://arxiv.org/abs/2507.02295)
> *Flotilla：一个用于异构资源的可扩展、模块化和弹性联邦学习框架*

*Roopkatha Banerjee, Prince Modi, Jinal Vyas, Chunduru Sri Abhijit, Tejus Chandrashekar, Harsha Varun Marisetty, Manik Gupta, Yogesh Simmhan* | **Category: cs.DC** | **Updated: {updated}**

**Keywords:** 联邦学习, 可扩展性, 模块化, 弹性, 边缘计算

**Comment:** 

> **TL;DR:** Flotilla是一个可扩展、模块化且具有弹性的联邦学习框架，旨在解决现有框架在真实边缘硬件部署、异步聚合支持和故障恢复方面的不足，并展示了其在资源使用和大规模客户端扩展方面的优势。

**AI_Comments:** Flotilla的创新点在于其“用户至上”的模块化设计，允许灵活组合各种FL策略，并解决了现有框架在真实硬件部署、异步聚合和故障恢复方面的痛点。其无状态客户端和分离会话状态的服务器设计，提升了系统的弹性和可扩展性。通过与现有框架的对比，证明了其在资源效率和大规模部署上的优势，对联邦学习的实际应用和系统研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦学习框架大多专注于通过伪分布式模拟来验证学习方面，而非在真实边缘硬件上进行分布式部署以评估系统层面的联邦特性。此外，当前框架普遍不支持流行的异步聚合，且对客户端和服务器故障的弹性有限。

**Method:** 本文介绍了Flotilla，一个可扩展、轻量级的联邦学习框架。它采用“用户至上”的模块化设计，以帮助快速组合各种同步和异步联邦学习策略，同时与DNN架构无关。它使用无状态客户端和分离会话状态的服务器设计，并定期或增量地进行检查点。

**Result:** 作者通过评估五种不同的FL策略来训练五个DNN模型，展示了Flotilla的模块化。在200多个客户端上评估了客户端和服务器端的容错能力，并展示了其在几秒钟内快速故障转移的能力。Flotilla在Raspberry Pis和Nvidia Jetson边缘加速器上的资源使用与Flower、OpenFL和FedML等三个最先进的FL框架相当或更优。与Flower相比，Flotilla在1000多个客户端上的扩展性显著更好。

**Conclusion:** Flotilla作为一个有竞争力的候选框架，可用于构建新颖的联邦学习策略，统一比较它们，快速部署它们，并进行系统研究和优化。

> **ai_Abstract:** Flotilla是一个为解决现有联邦学习框架在真实硬件部署、异步聚合支持和故障弹性方面不足而设计的新型可扩展、模块化、轻量级框架。它采用“用户至上”的模块化设计，支持同步和异步FL策略，并利用无状态客户端和分离会话状态的服务器设计。实验证明，Flotilla具有高度模块化、强大的故障容忍能力、与现有SOTA框架相当或更优的资源效率，并在大规模客户端场景下展现出卓越的扩展性，使其成为FL系统研究和部署的有力工具。

> **摘要翻译:** 随着移动和边缘计算的最新进展以及数据隐私问题的日益关注，联邦学习（FL）作为一种保护隐私的分布式机器学习方法迅速普及。已经构建了几个FL框架用于测试新颖的FL策略。然而，大多数框架侧重于通过伪分布式模拟来验证FL的学习方面，而不是在分布式方式下部署到真实边缘硬件上，以从系统角度有意义地评估联邦方面。当前的框架本质上也没有设计来支持日益流行的异步聚合，并且对客户端和服务器故障的弹性有限。我们引入了Flotilla，一个可扩展且轻量级的FL框架。它采用“用户至上”的模块化设计，以帮助快速组合各种同步和异步FL策略，同时与DNN架构无关。它使用无状态客户端和分离会话状态的服务器设计，并定期或增量地进行检查点。我们通过评估五种不同的FL策略来训练五个DNN模型，展示了Flotilla的模块化。我们还在200多个客户端上评估了客户端和服务器端的容错能力，并展示了其在几秒钟内快速故障转移的能力。最后，我们展示了Flotilla在Raspberry Pis和Nvidia Jetson边缘加速器上的资源使用与三个最先进的FL框架（Flower、OpenFL和FedML）相当或更优。与Flower相比，它在1000多个客户端上的扩展性也显著更好。这使得Flotilla成为构建新颖FL策略、统一比较它们、快速部署它们以及进行系统研究和优化的一个有竞争力的候选框架。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [121] [Alps, a versatile research infrastructure](https://arxiv.org/abs/2507.02404)
> *Alps，一个多功能研究基础设施*

*Maxime Martinasso, Mark Klein, Thomas C. Schulthess* | **Category: cs.DC** | **Updated: {updated}**

**Keywords:** Alps, HPC, vCluster, 软件定义集群, 异构计算

**Comment:** 10 pages, 6 figures, Cray User Group(CUG) 2025 Best Paper Award

> **TL;DR:** CSCS开发了Alps，一个灵活的下一代HPC基础设施，通过独立端点和vCluster技术支持多样化的科学需求。

**AI_Comments:** Alps的创新在于其“资源作为独立端点”的架构原则以及vCluster技术，这有效地弥合了传统HPC的僵硬性与云范式的灵活性之间的鸿沟，使其能够适应不断变化的科学需求。其重要性在于提供了一个高度灵活和可组合的HPC环境，支持广泛的科学应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统垂直集成的HPC架构缺乏灵活性和可组合性，无法满足日益多样化的科学需求。

**Method:** Alps将资源作为高速网络中的独立端点运行，采用异构硬件（CPU、GPU、Slingshot网络），模块化存储系统，并引入了多功能软件定义集群（vCluster）技术，通过抽象基础设施、服务管理和用户环境来定制平台。

**Result:** Alps能够创建独立的租户和平台特定服务，支持定制化平台和多样化工作负载，目前已服务于数值天气预报和AI研究等科学领域。

**Conclusion:** Alps是一个多功能、灵活的下一代HPC基础设施，能够通过其创新架构和vCluster技术满足多样化的科学计算需求。

> **ai_Abstract:** CSCS开发了Alps，一个旨在克服传统HPC系统局限性的下一代高性能计算基础设施。Alps采用资源作为独立网络端点的架构，集成异构硬件，并引入了vCluster技术，以提供灵活、可定制的平台，满足数值天气预报和AI研究等多样化科学工作负载的需求。

> **摘要翻译:** 瑞士国家超级计算中心 (CSCS) 在提供顶级高性能计算系统方面拥有悠久传统，Piz Daint 超级计算机就是其典范。然而，科学需求日益多样化，暴露了传统垂直集成HPC架构的局限性，这些架构通常缺乏灵活性和可组合性。为应对这些挑战，CSCS 开发了 Alps，一个下一代HPC基础设施，其设计遵循一个变革性原则：资源在高速网络中作为独立端点运行。这种架构能够创建独立的租户专用和平台专用服务，以满足不同的科学需求。Alps 集成了异构硬件，包括CPU和GPU，通过高性能Slingshot网络互连，并提供模块化存储系统。一个关键创新是多功能软件定义集群 (vCluster) 技术，它连接了云和HPC范式。通过将基础设施、服务管理和用户环境抽象为不同层，vCluster 允许定制平台以支持多样化的工作负载。Alps 上的当前平台服务于各种科学领域，包括数值天气预报和人工智能研究。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [144] [FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](https://arxiv.org/abs/2507.02620)
> *FlowSpec：面向高效分布式LLM推理的连续流水线推测解码*

*Xing Liu, Lizhuo Luo, Ming Tang, Chao Huang* | **Category: cs.DC, cs.AI** | **Updated: {updated}**

**Keywords:** 分布式LLM推理, 流水线并行, 推测解码, 边缘计算, FlowSpec

**Comment:** 16 pages, and the last 3 are appendix

> **TL;DR:** FlowSpec是一种新的流水线并行树状推测解码框架，通过引入分数验证、高效草稿管理和动态草稿扩展策略，显著提高了稀疏边缘推理场景下分布式LLM推理的速度，相比基线提升1.36-1.77倍。

**AI_Comments:** FlowSpec的创新之处在于将流水线并行与树状推测解码相结合，并引入了三个独特的机制来解决稀疏边缘推理场景下的效率问题。其强调了在分布式部署中优化资源利用率的重要性，并通过具体的技术细节如分数验证和动态草稿扩展，提供了提升LLM推理性能的实用方案。该研究对于边缘计算和LLM部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分布式LLM推理在网络边缘能够使大型语言模型适应设备内存，但当边缘推理请求稀疏时，现有基于流水线的方法利用率低，导致性能下降。

**Method:** 提出FlowSpec，一个流水线并行的树状推测解码框架。它包含三个关键机制：1) 基于分数的逐步验证，优先处理更重要的草稿令牌以提前接受；2) 有效的草稿管理，在验证过程中剪除无效令牌同时保持正确的因果关系；3) 动态草稿扩展策略，提供高质量的推测输入。

**Result:** 在真实测试平台上进行评估，FlowSpec相比基线显著提高了推理速度，实现了1.36倍至1.77倍的加速比。

**Conclusion:** FlowSpec通过其创新的机制，有效解决了稀疏边缘推理场景下分布式LLM推理效率低下的问题，显著提升了推理速度。

> **ai_Abstract:** FlowSpec是一种针对网络边缘稀疏请求场景下分布式LLM推理效率低下的问题而设计的流水线并行推测解码框架。该框架通过引入分数验证、高效草稿管理和动态草稿扩展策略，有效提升了流水线利用率和推测效率。实验结果表明，FlowSpec在不同模型和配置下，相较于现有基线，能将推理速度提升1.36至1.77倍，证明了其在实际应用中的显著性能优势。

> **摘要翻译:** 分布式推理是使大型语言模型（LLMs）在网络边缘进行推理的一种有前景的方法。它将推理过程分配到多个设备上，以确保LLMs能够适应设备内存。最近基于流水线的方法有可能并行化通信和计算，这有助于降低推理延迟。然而，当网络边缘的推理请求稀疏时，这种好处会减弱，因为流水线通常处于低利用率状态。为了实现边缘高效的分布式LLM推理，我们提出了FlowSpec，一个流水线并行的树状推测解码框架。FlowSpec整合了三个关键机制来提高解码效率：1）基于分数的逐步验证，优先处理更重要的草稿令牌以提前接受；2）高效的草稿管理，在验证过程中剪除无效令牌同时保持正确的因果关系；3）动态草稿扩展策略，提供高质量的推测输入。这些技术协同作用，以提高流水线利用率和推测效率。我们在真实世界的测试平台上对FlowSpec和其他基线进行了评估。实验结果表明，我们提出的框架在各种模型和配置下显著提高了推理速度，与基线相比实现了1.36倍至1.77倍的加速比。我们的代码已在https://github.com/Leosang-lx/FlowSpec# 公开。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [284] [EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data](https://arxiv.org/abs/2507.01615)
> *EDGChain-E：一个用于加密能源数据版本控制的去中心化Git框架*

*Alper Alimoglu, Kamil Erdayandi, Mustafa A. Mustafa, Ümit Cali* | **Category: cs.DC, cs.CR** | **Updated: {updated}**

**Keywords:** 去中心化框架, 加密能源数据, 版本控制, 区块链, Git, DAO, IPFS

**Comment:** 

> **TL;DR:** 本文提出了EDGChain-E，一个去中心化框架，利用区块链和IPFS对加密能源数据进行版本控制，确保协作数据治理中的完整性、可追溯性和隐私。

**AI_Comments:** 该论文的创新之处在于将类Git的版本控制与区块链和IPFS结合起来，用于加密能源数据管理，解决了去中心化环境中隐私、完整性和可追溯性等关键问题。集成DAO进行治理和支持FAIR合规性也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 旨在管理版本控制的加密能源数据，并以去中心化的方式支持能源研究和运营（如智能电网监控、需求预测和点对点能源交易）中的协作数据治理，尤其是在不损害敏感或受管制信息的前提下。

**Method:** EDGChain-E框架结合了区块链和IPFS，并引入了去中心化自治组织（DAO）来协调数据治理。初始提交捕获完整的加密数据集（如智能电表读数或电网遥测数据），而后续更新则作为加密的Git补丁进行跟踪。该系统通过在Merkle树中嵌入基于哈希的内容标识符来实现数据更改的透明、可审计和不可变跟踪。

**Result:** 该框架确保了加密能源数据的完整性、可追溯性和隐私。它支持多方利益相关者（如公用事业公司、研究人员、监管机构）之间的安全协作，而不会损害敏感信息。它能够维护加密数据的FAIR（可查找、可访问、可互操作、可重用）合规性溯源，并通过透明、可审计和不可变的数据更改跟踪，支持去中心化能源应用中的可重现性和信任。

**Conclusion:** EDGChain-E框架能够以去中心化的方式管理版本控制的加密能源数据，确保数据的完整性、可追溯性、隐私性和FAIR合规性溯源，从而支持去中心化能源应用中的安全协作和信任。

> **ai_Abstract:** EDGChain-E是一个去中心化框架，利用区块链和IPFS管理加密能源数据的版本控制。它通过DAO实现协作数据治理，确保智能电网监控、需求预测等场景下的数据完整性、可追溯性和隐私。该框架将加密数据集作为初始提交，后续更新作为加密Git补丁进行跟踪，并嵌入基于哈希的内容标识符到Merkle树中，从而实现对敏感信息的安全协作，并支持数据可查找、可访问、可互操作、可重用（FAIR）的溯源，增强了去中心化能源应用中的可重现性和信任。

> **摘要翻译:** 本文提出了一种名为EDGChain-E（加密数据Git链用于能源）的新型去中心化框架，旨在利用区块链和星际文件系统（IPFS）管理版本控制的加密能源数据。该框架整合了一个去中心化自治组织（DAO），以协调能源研究和运营（例如智能电网监控、需求预测和点对点能源交易）整个生命周期中的协作数据治理。在EDGChain-E中，初始提交捕获完整的加密数据集，例如智能电表读数或电网遥测数据，而后续更新则作为加密的Git补丁进行跟踪，从而确保数据的完整性、可追溯性和隐私。这种版本控制机制支持多个利益相关者（例如公用事业公司、研究人员、监管机构）之间的安全协作，而不会损害敏感或受管制的信息。我们强调了该框架维护加密数据FAIR（可查找、可访问、可互操作、可重用）合规性溯源的能力。通过在Merkle树中嵌入基于哈希的内容标识符，该系统能够实现数据更改的透明、可审计和不可变跟踪，从而支持去中心化能源应用中的可重现性和信任。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [20] [Computer Science Education in the Age of Generative AI](https://arxiv.org/abs/2507.02183)
> *计算机科学教育在生成式AI时代*

*Russell Beale* | **Category: cs.CY, cs.HC, H.5.0; K.3.1; K.3.2** | **Updated: {updated}**

**Keywords:** 生成式AI, 计算机科学教育, 大型语言模型, 教学实践, 学术诚信

**Comment:** 

> **TL;DR:** 探讨生成式AI对计算机科学教育的机遇、挑战、教学策略和政策建议。

**AI_Comments:** 这篇论文非常及时且具有重要意义，因为它直接Addressing了生成式AI在教育领域（特别是计算机科学）的迅速崛起所带来的复杂问题。其创新之处在于不仅识别了AI带来的机遇，也深入探讨了其潜在的风险和挑战，并提出了具体的教学策略和政策建议，为教育工作者和政策制定者提供了实用的指导。论文的全面性在于它涵盖了从课程内容、教学方法到评估体系的各个方面，并强调了在利用新技术的同时保持教育质量和学术诚信的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI工具（如大型语言模型）正在迅速彻底改变计算机科学教育，这些工具能生成、调试和解释代码。本文旨在探讨AI在提升计算机科学教育方面的巨大机遇，同时指出其带来的挑战。

**Method:** 本文考察了生成式AI对计算机科学教育带来的机遇（如编码辅助、创新教学实践、简化评估）和挑战（如学术诚信、过度依赖、原创性验证）。它讨论了在AI时代计算机科学教育者应该教授什么、如何最好地将这些技术整合到课程中，以及在AI能生成代码、原型和用户反馈的环境中评估学生学习的最佳实践。最后，提出了旨在利用生成式AI潜力同时保持计算机科学教育的完整性和严谨性的一系列政策建议，并使用实证数据和新兴研究支持论点。

**Result:** 本文识别了AI在计算机科学教育中的深刻机遇（编码辅助、促进创新教学实践、简化评估）和挑战（学术诚信问题、过度依赖AI的风险、验证原创性的困难）。它讨论了在AI时代计算机科学教育者应教授的内容、如何将AI技术整合到课程中，以及评估学生学习的最佳实践。

**Conclusion:** 论文提出了一系列政策建议，旨在利用生成式AI的潜力，同时维护计算机科学教育的完整性和严谨性。

> **ai_Abstract:** 本文探讨了生成式AI（特别是大型语言模型）对计算机科学教育产生的革命性影响。文章分析了AI在提升教学方面的机遇，如编码辅助和创新教学实践，同时也指出了学术诚信、过度依赖和原创性验证等挑战。论文讨论了AI时代计算机科学教育的教学内容、技术整合及学生评估的最佳实践，并提出了旨在利用AI潜力同时维护教育严谨性的政策建议。

> **摘要翻译:** 生成式AI工具——尤其是像ChatGPT和Codex这样的大型语言模型（LLMs）——正在迅速彻底改变计算机科学教育。这些工具能够生成、调试和解释代码，从而改变了编程教学的格局。本文探讨了AI在全面提升计算机科学教育方面提供的巨大机遇，从编码辅助到促进创新教学实践和简化评估。同时，它也强调了挑战，包括学术诚信问题、过度依赖AI的风险以及验证原创性的困难。我们讨论了在AI时代计算机科学教育者应该教授什么，如何最好地将这些技术整合到课程中，以及在AI能够生成代码、原型和用户反馈的环境中评估学生学习的最佳实践。最后，我们提出了一系列政策建议，旨在利用生成式AI的潜力，同时保持计算机科学教育的完整性和严谨性。全文使用实证数据和新兴研究来支持我们的论点。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [49] [Defining DLT Immutability: A Qualitative Survey of Node Operators](https://arxiv.org/abs/2507.02413)
> *定义DLT不变性：一项针对节点操作员的定性调查*

*Alex Lynham, Geoff Goodell* | **Category: cs.CY** | **Updated: {updated}**

**Keywords:** DLT不变性, 节点操作员, 实用不变性, 区块链治理, 定性研究

**Comment:** 27 pages, 2 figures, 6 tables

> **TL;DR:** 本文通过对节点操作员的访谈，探讨了分布式账本技术（DLT）中不变性的局限性，并提出了“实用不变性”的概念，即不变性取决于网络的合法治理需求。

**AI_Comments:** 本文通过引入“实用不变性”这一概念，对分布式账本技术的核心特性——不变性——提出了新的视角。其创新之处在于通过定性研究（访谈）而非纯技术分析来探讨这一问题，揭示了不变性在实际操作中受到治理因素的影响，这对于理解区块链的实际运作和信任机制具有重要意义。该研究方法和结论为未来DLT设计和治理模型提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管不变性是无需许可的公共区块链系统的核心设计目标，但重写事件比通常认为的更为常见，且重写、网络攻击、漏洞利用或黑天鹅事件的风险很高。作者认为严格的不变性在这些网络中既不可能实现也不是观察到的现实，因此旨在探讨不变性的实际限制。

**Method:** 本文采用主题分析法，对节点操作员进行了访谈。

**Result:** 研究结果是对这些网络中发现的条件不变性给出了定性定义，称之为“实用不变性”。这种不变性取决于网络的合法治理需求，即网络利益相关者信任网络的治理拓扑结构以赋予其合法性，从而管理账本状态。

**Conclusion:** 本文得出结论，严格的不变性在无需许可的公共区块链系统中既不可行也不是现实，并提出了“实用不变性”的概念。这种不变性是基于网络合法治理需求和利益相关者对治理拓扑的信任来管理账本状态的。

> **ai_Abstract:** 本文探讨了无需许可的公共区块链系统中不变性的实际限制。通过对节点操作员进行访谈并进行主题分析，研究发现严格的不变性在实践中难以实现。文章提出了“实用不变性”的概念，将其定义为一种条件不变性，即不变性是基于网络合法治理需求以及利益相关者对网络治理拓扑的信任来维持的。

> **摘要翻译:** 不变性是无需许可的公共区块链系统的核心设计目标。然而，重写比通常理解的更为常见，重写、网络攻击、漏洞利用或黑天鹅事件的风险也很高。本文认为严格的不变性在这些网络中既不可能实现也不是观察到的现实，因此通过对节点操作员访谈进行主题分析，审视了重写事件背景下不变性的局限性。最终结果是对这些网络中发现的条件不变性给出了定性定义，我们称之为实用不变性。这种不变性取决于网络的合法治理需求，即网络利益相关者信任网络的治理拓扑结构以赋予其合法性，从而管理账本状态。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [73] [Recourse, Repair, Reparation, & Prevention: A Stakeholder Analysis of AI Supply Chains](https://arxiv.org/abs/2507.02648)
> *追索、修复、赔偿与预防：人工智能供应链的利益相关者分析*

*Aspen K. Hopkins, Isabella Struckman, Kevin Klyman, Susan S. Silbey* | **Category: cs.CY** | **Updated: {updated}**

**Keywords:** 人工智能供应链, 利益相关者分析, 危害响应, 追索, 预防

**Comment:** 

> **TL;DR:** 本文对AI供应链（AISC）进行了利益相关者分析，提出了一种应对AISC所致危害的响应类型学（追索、修复、赔偿、预防），并将其应用于医疗保健AISC，以展示利益相关者的地位和权力如何影响危害响应。

**AI_Comments:** 这篇论文的创新之处在于将传统的供应链分析框架引入到人工智能领域，并针对AI供应链的独特性（如缺乏模块化和冗余）提出了系统的危害应对类型学。其重要性在于为理解和管理AI系统部署中日益复杂的风险提供了新的视角和工具，特别是强调了利益相关者的权力动态在危害响应中的作用。这对于未来AI系统的负责任设计和治理具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能的普及，AI系统部署中潜在的危害和不良后果日益受到关注。当前的AI供应链（AISC）缺乏传统的供应链实践，难以识别和纠正故障，使得应对机器学习产生的危害变得更加困难。因此，需要深入分析AISC中的利益相关者及其所面临的风险，并探索如何负责任地设计和管理AISC以应对这些危害。

**Method:** 本文对人工智能供应链（AISC）进行了利益相关者分析，研究了AISC的参与者、他们面临的危害、危害的来源以及市场动态和权力差异如何影响补救措施的类型和可能性。为实现AISC的负责任设计和管理，作者提出了一种应对AISC所致危害的响应类型学：追索（recourse）、修复（repair）、赔偿（reparation）或预防（prevention）。该类型学被应用于医疗保健领域的AISC，并结合三种风格化市场（垂直整合、水平整合、自由市场）进行案例分析，以说明利益相关者在AISC中的定位和权力如何影响对所经历危害的响应。

**Result:** 结果表明，AI供应链（AISC）缺乏传统供应链的模块化和冗余，使得识别和纠正故障变得困难。通过利益相关者分析和提出的响应类型学（追索、修复、赔偿、预防），文章阐明了AI供应链中不同利益相关者所面临的危害、危害来源以及市场动态和权力差异如何影响补救措施。特别是在医疗保健AISC的案例研究中，展示了利益相关者的定位和权力如何显著塑造对AI系统所致危害的响应方式。

**Conclusion:** 人工智能供应链（AISC）是人为设计和实施的，因此可以被设计成考虑而非忽视AI系统部署的复杂性、后果和风险。通过理解AISC中的利益相关者、危害来源以及响应类型学，可以促进AISC的负责任设计和管理，从而更好地应对和减轻AI系统可能造成的危害。

> **ai_Abstract:** 本文对日益普及但缺乏传统供应链实践的人工智能供应链（AISC）进行了利益相关者分析。研究探讨了AISC的参与者、所面临的危害、危害来源以及市场动态和权力差异对补救措施的影响。为促进AISC的负责任设计与管理，文章提出了一种应对AISC所致危害的四种响应类型学：追索、修复、赔偿和预防。该类型学被应用于医疗保健领域的AISC，并结合不同市场结构进行案例分析，以说明利益相关者的地位和权力如何影响其对AI系统所致危害的响应。

> **摘要翻译:** 人工智能（AI）产业正呈爆炸式增长，人们对潜在危害和不良后果的关注也日益增加。在当前的数字生态系统中，AI部署通常是AI供应链（AISC）的产物：通过外包模型、数据和工具形成的网络，多个实体通过该网络共同参与AI的开发和分发。AI供应链缺乏模块化、冗余或传统的供应链实践，这些实践能够实现故障的识别、隔离和轻松纠正，从而加剧了应对机器学习所产生危害的难度。随着参与和受AISC影响的利益相关者规模和多样性不断扩大，他们面临的风险也随之增加。在本次对AI供应链的利益相关者分析中，我们考虑了谁参与了AISC，他们面临哪些危害，危害的来源在哪里，以及市场动态和权力差异如何影响补救措施的类型和可能性。由于AI供应链是特意发明和实施的，它们可以被设计成考虑而非忽视部署AI系统的复杂性、后果和风险。为了实现AISC的负责任设计和管理，我们提供了一种应对AISC所致危害的响应类型学：追索、修复、赔偿或预防。我们将这种类型学应用于参与医疗保健AISC的利益相关者，通过三种风格化市场——垂直整合、水平整合、自由市场——来阐明利益相关者的定位和在AISC中的权力如何塑造对所经历危害的响应。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [18] [Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener](https://arxiv.org/abs/2507.02005)
> *通过特征工程和自动化可解释机器学习应用于焊接横向加劲肋的疲劳强度模型发现*

*Michael A. Kraus, Helen Bartsch* | **Category: cs.CE, cs.AI** | **Updated: {updated}**

**Keywords:** 疲劳强度, 焊接加劲肋, 自动化机器学习, 可解释人工智能, 特征工程

**Comment:** 

> **TL;DR:** 本研究结合自动化机器学习（AutoML）和可解释人工智能（XAI），准确预测焊接横向加劲肋的疲劳强度，识别关键预测因子，并展示了一个稳健、可解释的框架，用于AI辅助设计。

**AI_Comments:** 本研究的创新之处在于将自动化机器学习（AutoML）和可解释人工智能（XAI）统一应用于疲劳强度预测这一关键工程问题。这种方法弥合了复杂机器学习模型与工程可解释性之间的鸿沟，这对于在设计和评估中实际应用至关重要。对不同特征工程方法的系统比较也具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在提出一种结合自动化机器学习（AutoML）和可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲肋细节的疲劳强度，并系统地比较基于专家和自动化特征选择的方法。最终目标是实现AI辅助设计和评估。

**Method:** 本研究引入了一种结合自动化机器学习（AutoML）和可解释人工智能（XAI）的统一方法。它将专家驱动的特征工程与算法特征创建相结合，以提高准确性和可解释性。基于广泛的疲劳试验数据库，使用AutoML在三种特征方案下训练了回归模型（梯度提升、随机森林和神经网络）：领域知情、算法和组合。可解释人工智能（XAI）方法（SHAP和特征重要性）用于识别主导预测因子。

**Result:** 集成方法（如CatBoost、LightGBM）表现最佳。领域知情模型($\mathcal M_2$)实现了最佳平衡：在完整的$\Delta \sigma_{c,50\%}$范围内，测试RMSE约为30.6 MPa，$R^2$约为0.780；在工程相关的0-150 MPa范围内，RMSE约为13.4 MPa，$R^2$约为0.527。特征更密集的模型($\mathcal M_3$)在训练期间有微小增益但泛化能力较差，而更简单的基本特征模型($\mathcal M_1$)表现相当，证实了极简设计的稳健性。XAI方法识别出应力比R、应力范围$\Delta \sigma_i$、屈服强度$R_{eH}$和焊后处理（TIG修整与焊态）是主要预测因子。次要几何因素——板宽、焊喉厚度、加劲肋高度——也显著影响疲劳寿命。

**Conclusion:** 该框架表明，将自动化机器学习（AutoML）与可解释人工智能（XAI）相结合，可以为焊接钢结构提供准确、可解释且稳健的疲劳强度模型。它将数据驱动建模与工程验证相结合，从而实现AI辅助设计和评估。

> **ai_Abstract:** 本论文提出了一种新颖的框架，将自动化机器学习（AutoML）与可解释人工智能（XAI）相结合，用于预测焊接横向加劲肋的疲劳强度。该方法利用专家驱动和算法特征工程，在一个广泛的疲劳试验数据库上训练回归模型。研究发现，集成方法表现最佳，其中领域知情模型在准确性和泛化能力之间实现了最佳平衡。可解释人工智能（XAI）技术成功识别了关键预测因子，验证了所提出方法在钢结构AI辅助设计中的稳健性和可解释性。

> **摘要翻译:** 本研究引入了一种结合自动化机器学习（AutoML）和可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲肋细节的疲劳强度。它将专家驱动的特征工程与算法特征创建相结合，以提高准确性和可解释性。
基于广泛的疲劳试验数据库，使用AutoML在三种特征方案下训练了回归模型——梯度提升、随机森林和神经网络：领域知情、算法和组合。这允许系统地比较基于专家的方法与自动化特征选择的方法。
集成方法（例如CatBoost、LightGBM）表现最佳。领域知情模型($\mathcal M_2$)实现了最佳平衡：在完整的$\Delta \sigma_{c,50\%}$范围内，测试RMSE约为30.6 MPa，$R^2$约为0.780；在工程相关的0-150 MPa域内，RMSE约为13.4 MPa，$R^2$约为0.527。特征更密集的模型($\mathcal M_3$)在训练期间表现出微小增益但泛化能力较差，而更简单的基本特征模型($\mathcal M_1$)表现相当，证实了极简设计的稳健性。
可解释人工智能（XAI）方法（SHAP和特征重要性）识别出应力比R、应力范围$\Delta \sigma_i$、屈服强度$R_{eH}$和焊后处理（TIG修整与焊态）是主要预测因子。次要几何因素——板宽、焊喉厚度、加劲肋高度——也显著影响疲劳寿命。
该框架表明，将自动化机器学习（AutoML）与可解释人工智能（XAI）相结合，可以为焊接钢结构提供准确、可解释且稳健的疲劳强度模型。它将数据驱动建模与工程验证相结合，从而实现AI辅助设计和评估。未来的工作将探索概率疲劳寿命建模并将其集成到数字孪生环境中。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [32] [Constraint-Guided Symbolic Regression for Data-Efficient Kinetic Model Discovery](https://arxiv.org/abs/2507.02730)
> *约束引导的符号回归用于数据高效的动力学模型发现*

*Miguel Ángel de Carvalho Servia, Ilya Orson Sandoval, King Kuok, Hii, Klaus Hellgardt, Dongda Zhang, Ehecatl Antonio del Rio Chanona* | **Category: cs.CE, cs.SC** | **Updated: {updated}**

**Keywords:** 符号回归, 动力学模型, 物理约束, 数据效率, 不确定性量化

**Comment:** 27 pages, 8 figures

> **TL;DR:** 提出PI-ADoK框架，结合物理约束和符号回归，减少实验需求，提高动力学模型发现的效率和可靠性。

**AI_Comments:** 本文创新性地将物理约束与符号回归结合，有效解决了传统数据驱动方法在动力学模型发现中缺乏物理一致性和数据效率低的问题。通过引入不确定性量化，进一步提高了模型的可靠性。该方法对于减少实验成本和加速催化过程的工业化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 催化过程的工业化需要可靠的动力学模型。传统机械模型需要大量领域知识，而数据驱动方法缺乏可解释性且不符合物理一致性。

**Method:** 本文提出了Physics-Informed Automated Discovery of Kinetics (PI-ADoK) 框架。该框架通过将物理约束直接整合到符号回归方法中，以缩小搜索空间并显著减少模型收敛所需的实验次数。此外，该框架通过Metropolis-Hastings算法整合了鲁棒的不确定性量化策略，用于传播参数不确定性以产生可信的预测区间。

**Result:** 在多个催化案例研究中，与传统方法对比，PI-ADoK不仅提高了模型保真度，还降低了实验负担。

**Conclusion:** PI-ADoK框架在化学反应工程中具有高效可靠的动力学模型发现潜力。

> **ai_Abstract:** 本文提出了Physics-Informed Automated Discovery of Kinetics (PI-ADoK) 框架，旨在解决传统动力学模型发现中对领域知识的依赖以及数据驱动方法缺乏物理一致性与可解释性的问题。PI-ADoK通过将物理约束融入符号回归，有效缩小模型搜索空间并减少所需实验量。同时，结合Metropolis-Hastings算法进行不确定性量化。基准测试表明，该框架在提高模型准确性的同时，显著降低了实验成本，展现了其在化学反应工程中高效可靠地发现动力学模型的巨大潜力。

> **摘要翻译:** 催化过程的工业化依赖于可靠的动力学模型，用于设计、优化和控制。传统的机械模型需要广泛的领域专业知识，而许多数据驱动方法往往缺乏可解释性，并且未能强制执行物理一致性。为了克服这些限制，我们提出了物理信息自动动力学发现（PI-ADoK）框架。通过将物理约束直接整合到符号回归方法中，PI-ADoK缩小了搜索空间，并显著减少了模型收敛所需的实验次数。此外，该框架通过Metropolis-Hastings算法整合了鲁棒的不确定性量化策略，该算法传播参数不确定性以产生可信的预测区间。在几个催化案例研究中，将我们的方法与传统方法进行基准测试表明，PI-ADoK不仅提高了模型保真度，而且降低了实验负担，突显了其在化学反应工程中高效可靠地发现动力学模型的潜力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [47] [Time Resolution Independent Operator Learning](https://arxiv.org/abs/2507.02524)
> *时间分辨率无关的算子学习*

*Diab W. Abueidda, Mbebo Nonna, Panos Pantidis, Mostafa E. Mobasher* | **Category: cs.CE, cs.NA, math.NA** | **Updated: {updated}**

**Keywords:** 算子学习, 神经控制微分方程, 深度学习, 时变偏微分方程, 分辨率无关

**Comment:** 

> **TL;DR:** 该论文介绍了NCDE-DeepONet，一个利用神经控制微分方程（NCDE）的连续时间算子网络，用于从稀疏和不规则数据中学习时变偏微分方程（PDEs）的解算子，实现了输入和输出分辨率无关性，并能进行快速、准确的预测。

**AI_Comments:** 这项工作的创新之处在于将神经控制微分方程（NCDE）引入算子学习框架DeepONet中，从而克服了传统方法在处理时变PDEs时面临的离散时间依赖性和输入/输出分辨率限制。NCDE能够以连续时间的方式编码输入历史，使得模型对输入数据的离散化方式不敏感，极大地增强了模型的泛化能力。此外，输出分辨率无关性也意味着模型在部署时具有更高的灵活性和效率。这为高保真瞬态力学问题的算子学习提供了一个原则性且高效的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 从稀疏和不规则数据中准确学习时变偏微分方程（PDEs）的解算子仍然是一项具有挑战性的任务。现有的循环DeepONet扩展继承了序列到序列（seq2seq）RNN架构的离散时间限制，而神经-ODE代理在初始化后无法纳入新的输入。

**Method:** 该论文引入了NCDE-DeepONet，一个连续时间算子网络。它在分支中嵌入了一个神经控制微分方程（NCDE），用于将整个载荷历史编码为由样条插值输入路径驱动的受控ODE的解，从而使表示与输入分辨率无关。同时，它用显式的时空坐标增强了主干，使得主干能够在任意空间位置和时间探测潜在路径，从而使整个映射与输出分辨率无关，允许在训练期间未见的网格和时间步上进行预测，无需重新训练或插值。

**Result:** 在瞬态泊松、弹性动力学和热弹性问题上的基准测试证实了该框架的鲁棒性和准确性，实现了几乎即时的解预测。

**Conclusion:** 这些发现表明，受控动力学为瞬态力学中的高保真算子学习提供了一个原则性且高效的基础。

> **ai_Abstract:** 该论文提出了一种名为NCDE-DeepONet的连续时间算子网络，旨在解决从稀疏和不规则数据中学习时变偏微分方程解算子的挑战。不同于现有方法的离散时间限制或无法在初始化后纳入新输入的问题，NCDE-DeepONet通过在分支中嵌入神经控制微分方程（NCDE）来编码输入历史，实现输入分辨率无关性；并通过在主干中加入显式时空坐标来探测潜在路径，实现输出分辨率无关性。该方法允许在未经训练的网格和时间步上进行预测，无需重新训练。基准测试表明，NCDE-DeepONet在瞬态力学问题上表现出高鲁棒性、准确性，并能实现快速求解预测，证明了受控动力学在算子学习中的潜力。

> **摘要翻译:** 准确地从稀疏和不规则数据中学习时变偏微分方程（PDEs）的解算子仍然是一项具有挑战性的任务。循环DeepONet扩展继承了序列到序列（seq2seq）RNN架构的离散时间限制，而神经-ODE代理在初始化后无法纳入新的输入。我们引入了NCDE-DeepONet，这是一种连续时间算子网络，它在分支中嵌入了神经控制微分方程（NCDE），并用显式的时空坐标增强了主干。NCDE将整个载荷历史编码为由样条插值输入路径驱动的受控ODE的解，使得表示与输入分辨率无关：它编码了观测样本的不同输入信号离散化。然后，主干在任意空间位置和时间探测这个潜在路径，使整个映射与输出分辨率无关：可以在训练期间未见的网格和时间步上查询预测，无需重新训练或插值。在瞬态泊松、弹性动力学和热弹性问题上的基准测试证实了该框架的鲁棒性和准确性，实现了几乎即时的解预测。这些发现表明，受控动力学为瞬态力学中的高保真算子学习提供了一个原则性且高效的基础。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [71] [Imitation and Heterogeneity Shape the Resilience of Community Currency Networks](https://arxiv.org/abs/2507.02678)
> *模仿与异质性塑造社区货币网络的弹性*

*Camilla Ancona, Dora Ricci, Carmela Bernardo, Francesco Lo Iudice, Anton Proskurnikov, Francesco Vasca* | **Category: cs.CE** | **Updated: {updated}**

**Keywords:** 社区货币网络, Sardex, 图论, 网络弹性, 模仿行为

**Comment:** 

> **TL;DR:** 本文通过对Sardex社区货币网络的案例研究，分析了其结构和动态特性，发现模仿行为和异质性连接增强了网络的弹性。

**AI_Comments:** 这篇论文通过具体的案例研究（Sardex）深入分析了社区货币网络的复杂动态。其创新之处在于将社会行为（模仿）和结构异质性与网络弹性联系起来，为理解非传统经济系统的稳定性提供了新的视角。研究方法严谨，结合了图论和时间演化分析，对社区货币的设计和管理具有潜在的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在调查社区货币网络（如Sardex）的结构和动态特性，并理解其核心和外围结构如何演变，以及哪些因素影响其弹性。

**Method:** 将交易网络建模为有向加权图，并使用图论框架（包括强连通分量、凝聚表示和行为连接模式分析）进行分析。研究重点是Sardex网络在三年内的演变，并关注时间收缩、流量不对称和结构碎片化。

**Result:** 研究发现网络持续偏离基于度数的零模型，表明存在行为模仿（用户偏好更活跃的同行）。此外，不同类型用户之间的异质连接增强了网络拓扑结构并提高了其弹性。

**Conclusion:** 模仿行为（用户偏好活跃同行）和不同用户类型间的异质连接共同增强了社区货币网络的拓扑结构和弹性。

> **ai_Abstract:** 本文通过对意大利Sardex社区货币网络的案例研究，深入探讨了其作为互助信用系统的结构和动态特性。研究将交易网络建模为有向加权图，并运用图论方法分析其在三年内的演变，包括核心与外围结构、时间收缩、流量不对称及结构碎片化。核心发现是存在用户偏好活跃同行的模仿行为，以及不同用户类型间的异质连接显著增强了网络的拓扑结构和弹性。

> **摘要翻译:** 社区货币网络由具有某些物理或社会特征的个人或公司组成，他们使用虚拟货币进行经济交易。本文通过对Sardex（一种在意大利撒丁岛发起并主要运营的社区货币）的案例研究，调查了此类互助信用系统的结构和动态特性。交易网络被建模为有向加权图，并通过图论框架进行分析，重点关注强连通分量、凝聚表示和行为连接模式的分析。研究强调理解网络核心和外围结构在三年内的演变，并关注不同用户类型的时间收缩、流量不对称和结构碎片化。我们的发现揭示了与基于度数的零模型的持续偏差，并表明存在行为模仿，特别是用户对更活跃同行的偏好。我们进一步评估了不同类型用户之间异质连接的影响，这些连接增强了网络拓扑结构并提高了其弹性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [17] [Engineering an LTLf Synthesis Tool](https://arxiv.org/abs/2507.02491)
> *工程化LTLf综合工具*

*Alexandre Duret-Lutz, Shufang Zhu, Nir Piterman, Giuseppe de Giacomo, Moshe Y Vardi* | **Category: cs.FL** | **Updated: {updated}**

**Keywords:** LTLf, 反应式综合, MTBDD, DFA, 工具实现

**Comment:** 

> **TL;DR:** 开发了一种新的LTLf合成器，它基于MTBDD表示，并在性能上超越了现有工具。

**AI_Comments:** 该论文的创新点在于提出了从LTLf到MTBDD表示的DFA的直接转换方法，并将这种表示解释为可达性博弈并即时求解，显著提升了LTLf合成工具的性能。这对于形式化验证和系统综合领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** LTLf反应式综合问题旨在构建一个传感器，使其输出基于输入历史，并满足LTLf规范。现有工具可能存在性能瓶颈，因此需要一个性能更优的实现。

**Method:** 本文描述了一个LTLf合成器的实现，该实现基于从LTLf到DFA的新型直接转换。其中，DFA表示为共享节点的多终端二叉决策图（MTBDD）数组。这种MTBDD表示可以直接解释为可达性博弈，并在其构建过程中即时解决。

**Result:** 该LTLf合成器在基准测试套件上的性能优于现有工具。

**Conclusion:** 本文成功实现了一个高性能的LTLf合成器，通过创新性的MTBDD表示和即时解决可达性博弈的方法，显著提升了LTLf反应式综合的工具性能。

> **ai_Abstract:** 本文介绍了一种用于LTLf反应式综合的新型工具实现。该工具通过将LTLf直接转换为以共享节点MTBDD数组表示的DFA，并将其解释为可达性博弈进行即时求解，从而在性能上超越了现有工具。

> **摘要翻译:** LTLf反应式综合问题旨在构建一个传感器，其输出基于输入历史，使得对于每一个无限输入序列，输入和输出的联合演化都具有一个满足给定LTLf规范的前缀。我们描述了一个LTLf合成器的实现，它在我们的基准测试套件上优于现有工具。这基于一种新的、从LTLf直接转换为表示为共享节点的多终端二叉决策图（MTBDD）数组的确定性有限自动机（DFA）的方法。这种基于MTBDD的表示可以直接解释为可达性博弈，并在其构建过程中即时解决。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [22] [Enhancing Power Flow Estimation with Topology-Aware Gated Graph Neural Networks](https://arxiv.org/abs/2507.02078)
> *使用拓扑感知门控图神经网络增强潮流估计*

*Shrenik Jadhav, Birva Sevak, Srijita Das, Wencong Su, Van-Hai Bui* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 潮流估计, 门控图神经网络, 拓扑不确定性, 物理信息, 实时电网操作

**Comment:** 

> **TL;DR:** 本文提出了一种门控图神经网络（GGNN）代理模型，用于在拓扑不确定性下进行交流潮流估计。该模型通过在架构和损失函数中嵌入操作约束，确保了物理一致性，并在多个IEEE基准网络上表现出优于现有GNN代理的性能，提供了轻量、准确、可扩展的实时电网操作工具。

**AI_Comments:** 该论文通过引入拓扑感知的门控图神经网络（GGNN）来解决电力系统潮流估计中的关键挑战。其创新点在于将操作约束直接嵌入到模型架构和损失函数中，从而显著增强了模型的物理一致性和泛化能力。这一方法有效地克服了传统模型在处理复杂非线性依赖和拓扑变化时的局限性，为电力系统实时监控和决策支持提供了更鲁棒、准确且可扩展的工具，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的交流潮流代理模型在实际部署中存在局限性，包括难以捕捉网状传输网络中的长距离非线性依赖、物理定律执行薄弱、需要大量超参数调优、在拓扑变化或大负载波动下泛化能力差，以及在数百个母线以上扩展性差且通常不量化不确定性。因此，需要开发准确且可扩展的潮流代理模型以支持实时电网监控、应急分析和决策支持。

**Method:** 本文提出了一种门控图神经网络（GGNN）代理模型，用于在拓扑不确定性下进行交流潮流估计。该模型在多个不同规模和复杂度的IEEE基准网络上进行训练，并纳入了随机线路故障和高达40%的负载变化。研究探索了传统的监督学习和物理信息自监督训练策略，并通过将操作约束直接嵌入到网络架构和损失函数中来确保物理一致性。

**Result:** 所提出的GGNN模型在比较评估中持续优于之前的基于GNN的代理模型，其预测结果与牛顿-拉夫逊解高度一致。

**Conclusion:** 通过将操作约束直接嵌入到架构和损失函数中，该模型确保了物理一致性，并提供了一个轻量、准确且可扩展的工具，用于实时电网操作。

> **ai_Abstract:** 本文提出了一种拓扑感知的门控图神经网络（GGNN）模型，旨在解决现有交流潮流代理模型在实时电网应用中面临的挑战，如长距离非线性依赖捕获能力不足、物理定律执行薄弱、泛化能力差和可扩展性受限等问题。该GGNN模型在包含拓扑不确定性和负载变化的IEEE基准网络上进行训练，并结合了监督学习和物理信息自监督训练策略。通过将操作约束嵌入到模型架构和损失函数中，GGNN在预测精度和物理一致性方面均表现出色，并持续优于其他GNN代理模型，为实时电网操作提供了一个轻量、准确且可扩展的解决方案。

> **摘要翻译:** 准确和可扩展的交流潮流代理模型对于日益动态化和逆变器主导的电力系统中的实时电网监控、应急分析和决策支持至关重要。然而，大多数现有代理模型由于其捕获网状传输网络中长距离非线性依赖的能力有限以及对物理定律的弱执行，未能实现实际部署。这些模型通常需要大量的超参数调优，在拓扑变化或大负载波动下表现出较差的泛化能力，并且通常不量化不确定性或在数百个母线以上扩展性不佳。为了解决这些挑战，本文提出了一种门控图神经网络（GGNN）代理模型，用于在拓扑不确定性下进行交流潮流估计。该模型在多个不同规模和复杂度的IEEE基准网络上进行训练，每个网络都包含随机线路故障和高达40%的负载变化。为了提高鲁棒性和泛化能力，我们探索了传统的监督学习和物理信息自监督训练策略。比较评估表明，所提出的GGNN持续优于之前的基于GNN的代理模型，其预测结果与牛顿-拉夫逊解紧密对齐。通过将操作约束直接嵌入到架构和损失函数中，该模型确保了物理一致性，并提供了一个轻量、准确且可扩展的工具，用于实时电网操作。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [51] [A robust and adaptive MPC formulation for Gaussian process models](https://arxiv.org/abs/2507.02098)
> *一种用于高斯过程模型的鲁棒自适应MPC公式*

*Mathieu Dubied, Amon Lahr, Melanie N. Zeilinger, Johannes Köhler* | **Category: eess.SY, cs.LG, cs.SY, math.OC** | **Updated: {updated}**

**Keywords:** 高斯过程, 模型预测控制, 鲁棒控制, 收缩度量, 不确定系统

**Comment:** 

> **TL;DR:** 开发了一种用于不确定非线性系统的鲁棒自适应MPC框架，利用高斯过程和收缩度量实现鲁棒预测。

**AI_Comments:** 这篇论文的创新点在于将收缩度量引入到高斯过程模型的鲁棒预测中，并将其整合到MPC框架内，从而有效地处理不确定非线性系统。该方法不仅理论上保证了控制性能，还通过实例展示了其在实际应用中的潜力，特别是对于难以精确建模的系统。

<details>
  <summary>Details</summary>

**Motivation:** 针对受有界扰动和未建模非线性影响的不确定非线性系统，需要一个鲁棒自适应的模型预测控制框架。

**Method:** 提出了一个鲁棒自适应模型预测控制（MPC）框架；使用高斯过程（GPs）从噪声测量中学习不确定动态；利用收缩度量推导出高斯过程模型的鲁棒预测，并将其纳入MPC公式中。

**Result:** 所提出的设计保证了递归可行性、鲁棒约束满足和以高概率收敛到参考状态；通过一个受难以建模地面效应影响的平面四旋翼飞行器数值例子，展示了所提出的鲁棒预测方法和在线学习带来的显著改进。

**Conclusion:** 所提出的鲁棒自适应MPC框架结合高斯过程和收缩度量，能够有效地控制不确定非线性系统，并在实践中表现出显著的性能提升。

> **ai_Abstract:** 本文提出了一种针对不确定非线性系统的鲁棒自适应模型预测控制（MPC）框架。该框架利用高斯过程（GPs）学习系统动态，并创新性地采用收缩度量推导出GP模型的鲁棒预测，将其整合到MPC中。该方法能确保递归可行性、鲁棒约束满足和高概率收敛。通过一个平面四旋翼飞行器的案例，验证了其在鲁棒预测和在线学习方面的显著性能提升。

> **摘要翻译:** 在本文中，我们提出了一种鲁棒自适应模型预测控制（MPC）框架，用于受有界扰动和未建模非线性影响的不确定非线性系统。我们使用高斯过程（GPs）根据噪声测量（包括系统运行期间收集的测量）学习不确定动态。作为一个关键贡献，我们使用收缩度量推导出高斯过程模型的鲁棒预测，并将其纳入MPC公式中。所提出的设计保证了递归可行性、鲁棒约束满足和以高概率收敛到参考状态。我们提供了一个受难以建模地面效应影响的平面四旋翼飞行器数值例子，该例子突出了通过所提出的鲁棒预测方法和在线学习实现的显著改进。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [75] [Optimality Loss Minimization in Distributed Control with Application to District Heating](https://arxiv.org/abs/2507.02144)
> *分布式控制中的最优性损失最小化及其在区域供热中的应用*

*Audrey Blizard, Stephanie Stockar* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 分布式控制, 最优性损失, 分区方法, 区域供热, 无政府代价

**Comment:** Submitted to IEEE Transactions on Control Systems Technology

> **TL;DR:** 本文提出了一种新颖的分区方法，利用改进的无政府代价指标来最小化分布式控制中的性能损失，并在区域供热网络中实现了接近集中式控制器的性能。

**AI_Comments:** 这项研究的创新之处在于引入了“改进的无政府代价”作为量化分布式控制中最优性损失的通用指标，并通过最小化该指标来优化系统分区。其重要性在于，它提供了一种系统性的方法来解决分布式控制中性能与计算效率之间的权衡问题，尤其是在大规模复杂系统中。在区域供热网络的应用案例中，其显著优于基线方法的性能提升（1.9% vs 22%损失）证明了其有效性和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 针对分布式控制中系统分区导致的控制性能下降问题，同时希望保持分布式方法的计算优势，本文旨在提出一种方法来最小化这种性能损失。

**Method:** 本文提出了一种新颖的分区方法，引入了博弈论性能指标——改进的无政府代价（modified Price of Anarchy），并将其作为通用的分区指标来量化分布式控制器中的最优性损失。通过最小化该分区指标来选择性能最佳的分布式控制设计。该指标与控制设计无关，适用性广。

**Result:** 所开发的度量被应用于需求灵活的区域供热网络，最终的分布式控制器被证明是可行且稳定的。在仿真中，这种新颖的分区方法表现与集中式控制器相似，总热损失仅增加1.9%，而类似的基线分区则导致损失增加22%。

**Conclusion:** 通过新颖的分区方法，可以有效最小化分布式控制中的最优性损失，在实际应用（如区域供热）中实现了接近集中式控制器的性能，且控制器是可行和稳定的。

> **ai_Abstract:** 本文提出了一种新颖的分区方法，旨在通过引入基于改进无政府代价的通用分区指标来最小化分布式控制中的最优性损失。该方法通过最小化此指标来选择最佳分布式控制设计，且与具体控制设计无关，适用性广泛。在区域供热网络的应用中，该方法显著降低了性能损失，使分布式控制器性能接近集中式控制器，且具有可行性和稳定性。

> **摘要翻译:** 本文提出了一种新颖的分区方法，旨在最小化因系统分区进行分布式控制而导致的控制性能下降，同时保持这些方法的计算优势。引入了一种博弈论性能指标——改进的无政府代价（modified Price of Anarchy），并将其用于一个可泛化的分区指标中，以量化分布式控制器中的最优性损失。通过寻找最小化该分区指标的分区，从而选择性能最佳的分布式控制设计。所提出的分区指标与控制设计无关，使其广泛适用于许多控制设计问题。本文中，所开发的指标被用于最小化需求灵活的区域供热网络分布式控制中的性能损失。最终的分布式控制器被证明是可行和稳定的。在仿真中，这种新颖的分区方法表现与集中式控制器相似，总热损失仅增加1.9%，而类似的基线分区则导致损失增加22%。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [99] [Beyond Interval MDPs: Tight and Efficient Abstractions of Stochastic Systems](https://arxiv.org/abs/2507.02213)
> *超越区间MDPs：随机系统的紧密高效抽象*

*Ibon Gracia, Morteza Lahijanian* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 随机系统, 控制合成, 有限抽象, 多区间MDPs, 集合值转移概率MDPs

**Comment:** 

> **TL;DR:** 本文提出了多区间MDPs (MI-MDPs) 和集合值转移概率MDPs (SMDPs)，用于连续空间、离散时间随机系统的控制合成，提供了比现有方法更紧密的概率保证和更高的计算效率。

**AI_Comments:** 本文通过引入MI-MDPs和SMDPs，创新性地解决了随机系统控制合成中准确性和效率的权衡问题。特别是SMDPs，通过避免线性规划，显著提升了计算效率，同时保持了甚至超越了现有方法的概率保证紧密度。这项工作对于需要高可靠性控制的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于连续空间、离散时间随机系统控制合成的有限抽象方法在准确性和可处理性之间存在权衡，通常为了可处理性而牺牲准确性。

**Method:** 本文提出了一个统一的抽象框架。首先引入了多区间MDPs (MI-MDPs)，它是区间值MDPs (IMDPs) 的泛化，允许后继状态的多个（可能重叠的）簇。为了解决MI-MDPs增加的计算复杂性，进一步提出了集合值转移概率MDPs (SMDPs)，它将转移建模为对状态簇的固定概率，然后是簇内的非确定性选择。MI-MDPs的控制合成可通过线性优化的鲁棒动态规划实现，而SMDPs则允许更高效的合成算法，完全避免了线性规划。

**Result:** 理论上，在给定状态和扰动空间划分的情况下，MI-MDPs和SMDPs都比IMDPs提供更紧密的概率保证，并且SMDPs比MI-MDPs更紧密。通过多项基准测试的广泛实验验证了理论结果，并表明SMDPs在紧密度、内存使用和计算时间之间实现了有利的权衡。

**Conclusion:** 本文提出的MI-MDPs和SMDPs为连续空间、离散时间随机系统的控制合成提供了更紧密且计算效率更高的抽象方法，特别是SMDPs在实践中表现出优越的综合性能。

> **ai_Abstract:** 本文提出了一种用于连续空间、离散时间随机系统控制合成的新型有限抽象框架，旨在提高概率保证的紧密度和计算效率。该框架引入了多区间MDPs (MI-MDPs) 和集合值转移概率MDPs (SMDPs)。MI-MDPs通过允许多个后继状态簇提供更紧密的抽象，但计算复杂。SMDPs通过建模固定概率到状态簇和簇内非确定选择，提供更高效的合成算法。理论和实验结果表明，MI-MDPs和SMDPs都比现有IMDPs提供更紧密的概率保证，其中SMDPs表现最佳，并在紧密度、内存和计算时间之间取得了良好平衡。

> **摘要翻译:** 这项工作通过有限抽象解决了连续空间、离散时间随机系统具有概率保证的控制合成这一普遍问题。尽管存在成熟的方法，但它们通常以准确性换取可处理性。我们提出了一个统一的抽象框架，该框架提高了概率保证的紧密度和计算效率。首先，我们引入了多区间MDPs (MI-MDPs)，这是区间值MDPs (IMDPs) 的泛化，它允许后继状态的多个（可能重叠的）簇。这导致了更紧密的抽象，但计算复杂性增加。为了缓解这个问题，我们进一步提出了一种更广义的集合值转移概率MDPs (SMDPs) 形式，它将转移建模为对状态簇的固定概率，然后是簇内的非确定性选择，作为一种合理的抽象。我们证明了MI-MDPs的控制合成可以通过线性优化的鲁棒动态规划来实现，而SMDPs则允许更高效的合成算法，完全避免了线性规划。理论上，我们证明了，在给定状态和扰动空间划分的情况下，MI-MDPs和SMDPs都比IMDPs产生更紧密的概率保证，并且SMDPs比MI-MDPs更紧密。在多个基准测试中进行的广泛实验验证了我们的理论结果，并表明SMDPs在紧密度、内存使用和计算时间之间实现了有利的权衡。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [124] [Hybrid Satellite-Ground Deployments for Web3 DID: System Design and Performance Analysis](https://arxiv.org/abs/2507.02305)
> *Web3 DID的星地混合部署：系统设计与性能分析*

*Yalin Liu, Zhigang Yan, Bingyuan Luo, Xiaochi Xu, Hong-Ning Dai, Yaru Fu, Bishenghui Tao, Siu-Kei Au Yeung* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** Web3, 去中心化身份, 星地混合部署, LEO卫星, 区块链

**Comment:** 

> **TL;DR:** 本文提出了三种星地混合模式来部署支持Web3去中心化身份（DID）的区块链系统，并分析了其性能，以实现全球范围内的Web3服务。

**AI_Comments:** 本文的创新点在于将新兴的LEO卫星通信系统引入Web3的去中心化身份（DID）系统部署中，有效解决了传统地面网络在全球覆盖和可靠性方面的局限性。这种星地混合部署模式为Web3的全球化推广提供了新的思路和技术支持，具有重要的实践意义。文章通过性能分析和实验验证，增加了其研究的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 当前的Web3在实现全球规模的网络节点部署以服务用户方面面临关键挑战，尤其是在确保去中心化身份（DID）系统的安全性方面。新兴的低地球轨道（LEO）卫星通信系统，如Starlink，为解决这一问题提供了潜在方案。

**Method:** 本文开发了三种星地混合模式来部署支持区块链的Web3去中心化身份（DID）系统。这些模式整合了地面节点和卫星，旨在为全球用户提供灵活和持续的DID服务。同时，通过分析区块链在三种混合模式下的完整DID共识性能，并进行数值和仿真实验来验证其有效性，深入分析了各种系统参数的影响。

**Result:** 本文分析了三种混合星地部署模式下区块链的DID共识性能，并通过数值和仿真实验验证了这些模式的有效性。研究深入分析了各种系统参数的影响，为在全球网络环境中实施Web3 DID系统提供了有价值的见解。

**Conclusion:** 本文提出的星地混合部署模式能够有效解决当前Web3全球规模节点部署的挑战，为实现Web3去中心化身份（DID）的全球化、安全和高效服务提供了可行方案，并通过性能分析和实验验证了其有效性。

> **ai_Abstract:** 本文针对Web3在全球范围内部署去中心化身份（DID）系统所面临的挑战，提出并设计了三种创新的星地混合部署模式。这些模式结合了地面网络和低地球轨道（LEO）卫星通信系统（如Starlink），旨在为全球Web3用户提供安全、灵活且持续的DID服务。通过对这些混合模式下区块链DID共识性能的分析，以及数值和仿真实验的验证，研究深入探讨了系统参数的影响，为全球Web3 DID系统的实际部署提供了宝贵见解。

> **摘要翻译:** 新兴的Web3在未来具有巨大潜力，通过全球范围的数据驱动网络提供全球去中心化服务。为了确保Web3服务在不同用户实体之间的安全性，去中心化身份（DID）系统至关重要。特别是，用户对Web3服务的访问请求可以被视为区块链内的DID事务，通过共识机制执行。然而，当前Web3中出现了一个关键的实施问题，即如何部署网络节点以在全球范围内服务用户。为了解决这个问题，新兴的低地球轨道（LEO）卫星通信系统，如Starlink，提供了一个有前景的解决方案。凭借其全球覆盖和高可靠性，这些通信卫星可以补充地面网络，作为Web3部署基础设施。在这种情况下，本文开发了三种混合星地模式来为Web3用户部署支持区块链的DID系统。这三种模式整合了地面节点和卫星，为全球用户提供灵活和持续的DID服务。同时，为了评估当前混合部署模式的有效性，我们分析了区块链在三种混合星地模式下的完整DID共识性能。此外，我们进行了数值和仿真实验来验证三种混合星地模式的有效性。本文彻底分析了各种系统参数的影响，为在真实网络环境中实施全球Web3 DID系统提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [146] [Grid-Connected, Data-Driven Inverter Control, Theory to Hardware](https://arxiv.org/abs/2507.02325)
> *并网、数据驱动的逆变器控制：从理论到硬件*

*Sebastian Graf, Keith Moffat, Anurag Mohapatra, Alessandro Chiuso, Florian Dörfler* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 并网逆变器控制, 数据驱动控制, 瞬态预测控制, 无模型控制, 即插即用

**Comment:** 

> **TL;DR:** 本文提出并验证了瞬态预测控制（TPC）作为一种无模型、数据驱动的并网逆变器控制方法，可在标准硬件上运行并有效应对非线性时变系统。

**AI_Comments:** 这项研究的创新之处在于将无模型的瞬态预测控制（TPC）应用于复杂的并网逆变器控制，克服了传统方法对精确电网模型的依赖。其重要性在于提供了一种“即插即用”的解决方案，简化了实际应用中的部署和维护。论文通过实验验证了TPC在标准硬件上的可行性以及对非线性时变系统的适应性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 并网逆变器控制因难以获取和维护精确的电网模型而难以实现。

**Method:** 本文采用直接数据驱动预测控制，具体是瞬态预测控制（TPC），作为传统基于模型控制方法的无模型替代方案。该方法旨在实现实时、即插即用的逆变器控制，并测试了TPC算法在标准硬件上的在线运行能力以及其对非线性时变并网逆变器系统的有效性。

**Result:** 在双变换器台式设置和CoSES实验室连接到慕尼黑电网的25 kVA变换器上进行的实验支持了TPC算法可以在线运行并有效用于并网逆变器控制的假设。

**Conclusion:** 瞬态预测控制（TPC）是一种可行的无模型、数据驱动的并网逆变器控制方法，能够在标准硬件上有效应对复杂的非线性时变电网系统。

> **ai_Abstract:** 本文探讨了瞬态预测控制（TPC）作为一种无模型、数据驱动的并网逆变器控制方案，旨在解决传统基于模型方法中电网模型获取和维护的挑战。研究测试并验证了TPC算法在标准硬件上的在线运行能力，以及其在控制非线性时变并网逆变器系统中的有效性。实验结果在台式设置和实际电网连接中均支持了这些假设。

> **摘要翻译:** 并网逆变器控制由于难以获取和维护精确的电网模型而难以实现。直接数据驱动预测控制为传统的基于模型的控制方法提供了一种无模型的替代方案。本文描述了最近提出的瞬态预测控制（TPC）如何用于实际的即插即用逆变器控制。测试了以下假设：1）TPC算法可以使用标准硬件在线运行；2）TPC（通过线性时不变假设推导）对于非线性时变系统（即并网逆变器控制）是有效的。在双变换器台式设置和CoSES实验室连接到慕尼黑电网的25 kVA变换器上进行的实验支持了这些假设。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [167] [Indoor thermal comfort management: A Bayesian machine-learning approach to data denoising and dynamics prediction of HVAC systems](https://arxiv.org/abs/2507.02351)
> *室内热舒适管理：一种基于贝叶斯机器学习的HVAC系统数据去噪与动态预测方法*

*Javier Penuela, Sahar Moghimian Hoosh, Ilia Kamyshev, Aldo Bischi, Henni Ouerdane* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 室内热舒适, HVAC系统, 贝叶斯机器学习, 深度卡尔曼滤波器, 数据去噪

**Comment:** 

> **TL;DR:** 本文提出一种基于贝叶斯机器学习和深度学习的方法，用于HVAC系统室内温度的去噪和动态预测，即使在数据质量较低的情况下也能实现高精度预测。

**AI_Comments:** 本文的创新点在于结合了贝叶斯机器学习、深度学习和深度卡尔曼滤波器来处理HVAC系统中的噪声数据和复杂动态，显著降低了对数据质量的要求，使其在实际部署中更具可行性。这对于解决传统数据驱动方法在实际应用中面临的数据采集成本高、数据质量差的痛点具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 建筑微气候管理在舒适度、能效和成本方面面临挑战，因为控制问题中变量间的非线性、时间依赖性互动以及不断变化的内外部约束使其复杂。高质量数据获取和处理成本高昂限制了数据驱动方法在实际问题中的应用。

**Method:** 提出一种数据驱动方法，结合多种贝叶斯机器学习和深度学习架构，适用于预测复杂系统动态并放宽数据集质量要求。该框架包含内置的深度卡尔曼滤波器，即使使用低精度温度传感器也能部署。

**Result:** 在150分钟预测范围内，RMSE为0.2455，MAE为0.162，R^2为0.926，达到最先进的性能。即使在高度嘈杂的数据下，模型性能也能保持一致。

**Conclusion:** 该方法能够实现对室内温度的高精度预测，且对数据质量要求不高，并可扩展到需求响应事件持续时间预测和设备故障检测等其他应用。

> **ai_Abstract:** 本文针对建筑微气候管理中室内温度建模的挑战，提出了一种创新的数据驱动方法。该方法融合了贝叶斯机器学习和深度学习架构，并内置深度卡尔曼滤波器，能有效应对热惯性、非线性效应及噪声干扰。实验结果表明，该模型即使在低质量数据下也能实现高精度预测，并在HVAC系统动态预测中达到先进水平，同时具备扩展至其他应用场景的潜力。

> **摘要翻译:** 建筑微气候的最佳管理，以满足居住者在舒适度、能源效率和成本方面的需求和目标，是一项特别具有挑战性的任务。这种复杂性源于控制问题中所有变量之间非线性、时间依赖的相互作用以及不断变化的内部和外部约束。我们专注于室内温度的精确建模，提出了一种数据驱动的方法来应对这一挑战。我们考虑了热惯性、非线性效应、通风和天气变化引起的室内气候动态的小扰动，以及由于输入信号中观察到的噪声导致的控制系统的随机性质。由于高质量数据获取和处理的高昂成本限制了数据驱动方法在实际问题中的实施，我们应用了一种方法，该方法融合了多种贝叶斯机器学习和深度学习架构，这些架构适用于预测复杂系统动态，同时放宽了数据集质量要求。我们的框架包括一个内置的深度卡尔曼滤波器，即使使用低精度温度传感器也能部署。它实现了最先进的性能，在150分钟的预测范围内表现最佳，RMSE为0.2455，MAE为0.162，R^2为0.926。即使在高度嘈杂的数据下，模型的性能也能保持一致。最后，我们展示了我们的方法如何扩展到其他应用，包括需求响应事件持续时间预测和设备故障检测。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [186] [The Bias of Subspace-based Data-Driven Predictive Control](https://arxiv.org/abs/2507.02468)
> *基于子空间的数据驱动预测控制的偏差*

*Keith Moffat, Florian Dörfler, Alessandro Chiuso* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 数据驱动预测控制, 子空间偏差, 乐观偏差, 闭环数据, 线性时不变系统

**Comment:** 

> **TL;DR:** 本文量化并解决了基于子空间的数据驱动预测控制（DDPC）在闭环数据下产生的两种偏差：子空间偏差和乐观偏差，并发现它们导致性能不佳。

**AI_Comments:** 这篇论文的创新点在于明确区分并量化了基于子空间的数据驱动预测控制在闭环数据下产生的具体偏差类型，即子空间偏差和乐观偏差。这对于理解和改进数据驱动控制的性能具有重要意义，尤其是在实际应用中数据通常是在闭环环境下获取的。研究结果也为选择合适的控制方法提供了指导，突出了瞬态预测控制在避免这些偏差方面的优势。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在量化并解决线性时不变（LTI）系统中基于子空间的数据驱动预测控制（DDPC）的偏差，特别是当训练数据是在系统闭环状态下通过反馈控制器收集时产生的偏差。

**Method:** 首先，利用训练数据创新量化了子空间预测控制的闭环偏差。接着，分析了直接的、基于子空间的DDPC方法（DeePC和γ-DDPC）的偏差，并指出其由两部分组成：源于闭环数据的子空间偏差和源于DeePC/γ-DDPC“乐观”调整输出轨迹的乐观偏差。

**Result:** 研究表明，基于子空间的DDPC方法（DeePC和γ-DDPC）存在子空间偏差和乐观偏差，而瞬态预测控制（Transient Predictive Control）则不受这两种偏差的影响。双积分器实验证明，子空间偏差和乐观偏差是导致基于子空间的DDPC方法参考跟踪性能差的原因。

**Conclusion:** 本文量化并识别了基于子空间的数据驱动预测控制在闭环数据下产生的两种主要偏差（子空间偏差和乐观偏差），并实验证明了它们对系统性能的负面影响。

> **ai_Abstract:** 本文深入探讨了基于子空间的数据驱动预测控制（DDPC）在处理闭环系统数据时产生的偏差问题。研究识别并量化了两种关键偏差：子空间偏差（源于闭环数据）和乐观偏差（源于DDPC方法的乐观调整）。通过与瞬态预测控制的对比，发现后者不受这些偏差影响。实验结果进一步证实，这两种偏差是导致基于子空间的DDPC方法参考跟踪性能不佳的主要原因。

> **摘要翻译:** 本文量化并解决了线性时不变（LTI）系统中基于子空间的数据驱动预测控制（DDPC）的偏差。主要关注的是当训练数据是通过反馈控制器在系统闭环状态下收集时产生的偏差。首先，利用训练数据创新量化了子空间预测控制的闭环偏差。接下来，直接的、基于子空间的DDPC方法DeePC和γ-DDPC的偏差被证明由两部分组成——源于闭环数据的子空间偏差，以及源于DeePC/γ-DDPC“乐观”调整输出轨迹的乐观偏差。我们表明，与基于子空间的DDPC方法不同，瞬态预测控制不受子空间偏差或乐观偏差的影响。双积分器实验表明，子空间偏差和乐观偏差是导致基于子空间的DDPC方法参考跟踪性能差的原因。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [201] [Robust feedback-based quantum optimization: analysis of coherent control errors](https://arxiv.org/abs/2507.02532)
> *鲁棒的基于反馈的量子优化：相干控制误差分析*

*Mirko Legnini, Julian Berberich* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 量子优化, FALQON, 鲁棒性, 相干控制误差, Lyapunov函数

**Comment:** 

> **TL;DR:** 本文研究了量子优化算法FALQON对相干控制误差的鲁棒性，并提出了一个鲁棒版本。

**AI_Comments:** 本文的创新之处在于深入分析了FALQON算法在存在相干控制误差情况下的鲁棒性，并成功提出了一个改进的鲁棒版本。这对于量子优化算法在实际应用中的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究基于反馈的量子优化算法FALQON对相干控制误差的鲁棒性，这类误差属于影响控制输入的乘法误差。

**Method:** 我们分析了FALQON算法对系统误差的渐近鲁棒性，并推导了独立误差的鲁棒性界限。此外，我们提出了一个最小化正则化Lyapunov函数的鲁棒版FALQON。

**Result:** 研究表明，该算法对系统误差具有渐近鲁棒性，并为独立误差推导了鲁棒性界限。所提出的鲁棒版FALQON得到了模拟结果的支持。

**Conclusion:** FALQON算法对系统误差具有渐近鲁棒性，并且通过最小化正则化Lyapunov函数可以构建一个对相干控制误差更鲁棒的版本，这在模拟中得到了验证。

> **ai_Abstract:** 本文分析了反馈式量子优化算法FALQON对相干控制误差的鲁棒性。研究发现，FALQON对系统误差具有渐近鲁棒性，并推导了独立误差的鲁棒性界限。此外，论文提出了一种通过最小化正则化Lyapunov函数来增强鲁棒性的FALQON版本，并通过模拟验证了其有效性。

> **摘要翻译:** 反馈式量子优化算法（FALQON）是一种受Lyapunov启发的量子算法，旨在解决组合优化问题。在本文中，我们研究了FALQON对相干控制误差的鲁棒性，这类误差属于影响控制输入的乘法误差。我们表明该算法对系统误差具有渐近鲁棒性，并推导了独立误差的鲁棒性界限。最后，我们提出了一个最小化正则化Lyapunov函数的鲁棒版FALQON。我们的理论结果通过模拟得到了支持。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [214] [A Data-Driven Prescribed-Time Control Framework via Koopman Operator and Adaptive Backstepping](https://arxiv.org/abs/2507.02549)
> *数据驱动的预设时间控制框架：基于Koopman算子与自适应反步法*

*Yue Wu* | **Category: eess.SY, cs.SY, math.OC** | **Updated: {updated}**

**Keywords:** 数据驱动, 预设时间控制, Koopman算子, 自适应反步, 非线性系统

**Comment:** 6pages,4figs,1tables

> **TL;DR:** 本文提出一种新颖的数据驱动预设时间控制框架，结合Koopman算子和自适应反步法，旨在实现复杂非线性系统的快速、时间确定性稳定，并克服了传统控制方法的局限。

**AI_Comments:** 该研究创新性地将Koopman算子数据驱动建模与自适应反步控制相结合，克服了传统方法对精确模型依赖及纯数据驱动方法缺乏稳定性保证的局限性。通过利用Koopman线性化的结构优势，有效处理模型误差并避免了“复杂性爆炸”问题，为复杂非线性系统的快速、时间确定性控制提供了一个有前景的解决方案，尤其适用于对稳定时间和性能有严格要求的安全关键系统。

<details>
  <summary>Details</summary>

**Motivation:** 实现具有强非线性和参数不确定性的复杂系统的快速、时间确定性稳定是一个重大挑战。传统基于模型的控制依赖于精确的系统模型，而纯数据驱动方法往往缺乏形式化的稳定性保证，限制了它们在安全关键系统中的适用性。

**Method:** 本文提出了一种结合数据驱动建模与模型基控制的新型控制框架。该框架首先利用带控制的扩展动态模态分解（EDMDc）从数据中识别高维Koopman线性模型并量化其有界不确定性。随后，基于此数据驱动模型合成了一种新型预设时间自适应反步（PTAB）控制器。该设计利用Koopman线性化的结构优势，系统地处理模型误差并规避了传统反步法中固有的“复杂性爆炸”问题。

**Result:** 通过在经典Van der Pol振荡器上的仿真验证，结果表明该控制器能够将系统状态在用户预设时间内精确稳定到原点的一个小邻域内，无论初始条件如何，同时确保所有闭环信号的有界性。

**Conclusion:** 本研究成功结合了数据驱动方法的灵活性和基于Lyapunov分析的严谨性。它为非线性系统提供了一种具有可量化性能和可预设稳定时间的高性能控制策略，展示了其在控制复杂动力学方面的巨大潜力。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动预设时间控制框架，旨在解决强非线性和参数不确定性复杂系统的快速时间确定性稳定问题。该框架结合了数据驱动建模（通过EDMDc识别Koopman线性模型及其不确定性）和模型基控制（基于该模型合成预设时间自适应反步控制器）。该方法利用Koopman线性化处理模型误差并避免传统反步法的复杂性爆炸问题。仿真结果验证了该控制器能在预设时间内将系统稳定到原点附近并确保闭环信号有界，为非线性系统提供了一种高性能且稳定时间可预设的控制策略。

> **摘要翻译:** 实现具有强非线性和参数不确定性的复杂系统的快速、时间确定性稳定是一个重大挑战。传统基于模型的控制依赖于精确的系统模型，而纯数据驱动方法往往缺乏形式化的稳定性保证，限制了它们在安全关键系统中的适用性。本文提出了一种结合数据驱动建模与模型基控制的新型控制框架。该框架首先利用带控制的扩展动态模态分解（EDMDc）从数据中识别高维Koopman线性模型并量化其有界不确定性。随后，基于此数据驱动模型合成了一种新型预设时间自适应反步（PTAB）控制器。该设计利用Koopman线性化的结构优势，系统地处理模型误差并规避了传统反步法中固有的“复杂性爆炸”问题。所提出的控制器通过在经典Van der Pol振荡器上的仿真得到了验证。结果表明，该控制器能够将系统状态在用户预设时间内精确稳定到原点的一个小邻域内，无论初始条件如何，同时确保所有闭环信号的有界性。本研究成功结合了数据驱动方法的灵活性和基于Lyapunov分析的严谨性。它为非线性系统提供了一种具有可量化性能和可预设稳定时间的高性能控制策略，展示了其在控制复杂动力学方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [226] [Observer-Based Distributed Model Predictive Control for String-Stable Multi-vehicle Systems with Markovian Switching Topology](https://arxiv.org/abs/2507.02584)
> *基于观测器的马尔可夫切换拓扑下串稳定多车辆系统分布式模型预测控制*

*Wenwei Que, Yang Li, Lu Wang, Wentao Liu, Yougang Bian, Manjiang Hu, Yongfu Li* | **Category: eess.SY, cs.SY** | **Updated: {updated}**

**Keywords:** 分布式模型预测控制, 马尔可夫切换拓扑, 串稳定性, 自适应观测器, 车辆队列

**Comment:** 8 pages,7 figures,conference

> **TL;DR:** 针对具有切换拓扑的车辆队列，本研究提出了一种基于观测器的分布式模型预测控制（DMPC）方法，通过自适应观测器和马尔可夫链建模来维持串稳定性并减少跟踪误差。

**AI_Comments:** 该论文的创新点在于提出了基于观测器的DMPC方法来处理马尔可夫切换拓扑下的车辆队列稳定性问题。其引入自适应观测器以应对信息丢失和拓扑随机切换的挑战是关键。通过结合马尔可夫链建模和DMPC框架，该研究为复杂通信环境下多车辆系统的控制提供了新的思路，并理论上保证了观测器的均方稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 车辆队列中通信拓扑的切换可能导致信息丢失和系统不稳定，因此需要在动态变化的拓扑下设计能够保持车辆队列稳定性的控制器。同时，捕获切换拓扑的动态特性并获取完整的车辆信息用于控制器设计是一个重大挑战。

**Method:** 本研究提出了一种针对有向马尔可夫切换拓扑下车辆队列的基于观测器的分布式模型预测控制（DMPC）方法。该方法使用连续时间马尔可夫链对有向切换通信拓扑进行建模，并开发了一个完全分布式自适应观测器以获取领头车辆信息，该观测器能快速适应随机切换拓扑并保证均方稳定性。此外，基于观测器构建了DMPC终端更新律，并制定了基于观测信息的串稳定性约束。

**Result:** 数值模拟表明，所提出的方法在确保串稳定性的同时能够减少跟踪误差。

**Conclusion:** 所提出的基于观测器的DMPC方法通过利用自适应观测器和鲁棒控制框架，有效解决了马尔可夫切换拓扑下多车辆系统保持串稳定性和减少跟踪误差的挑战。

> **ai_Abstract:** 本研究提出一种基于观测器的分布式模型预测控制（DMPC）方法，用于解决马尔可夫切换拓扑下多车辆系统的信息丢失和不稳定性问题。通过使用连续时间马尔可夫链建模切换拓扑，并开发一个完全分布式自适应观测器来获取领头车辆信息，该方法旨在确保在动态拓扑变化下车辆队列的串稳定性和跟踪性能。数值模拟验证了其在减少跟踪误差和保持串稳定性方面的有效性。

> **摘要翻译:** 切换通信拓扑可能导致车辆队列不稳定，因为车辆信息可能在动态切换过程中丢失。这突出表明需要设计一种能够在动态变化的拓扑下保持车辆队列稳定性的控制器。然而，在确保稳定性的同时，捕捉切换拓扑的动态特性并获取完整的车辆信息用于控制器设计仍然是一个重大挑战。在本研究中，我们提出了一种针对有向马尔可夫切换拓扑下车辆队列的基于观测器的分布式模型预测控制（DMPC）方法。考虑到切换拓扑的随机性，我们使用连续时间马尔可夫链对有向切换通信拓扑进行建模。为了获取用于控制器设计的领头车辆信息，我们开发了一种完全分布式自适应观测器，该观测器能够快速适应随机切换的拓扑，确保观测到的信息不受动态拓扑切换的影响。此外，还推导了一个充分条件来保证观测器的均方稳定性。再者，我们基于观测器构建了DMPC终端更新律，并基于观测信息制定了串稳定性约束。数值模拟表明，我们的方法在确保串稳定性的同时可以减少跟踪误差。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [236] [A formal specification of the desired software behaviour of the Princess Marijke lock complex](https://arxiv.org/abs/2507.02721)
> *玛丽杰公主船闸综合体预期软件行为的形式化规范*

*Jan Friso Groote, Matthias Volk* | **Category: eess.SY, cs.LO, cs.SY** | **Updated: {updated}**

**Keywords:** 形式化规范, mCRL2, 模型检测, 船闸综合体, 软件行为

**Comment:** 

> **TL;DR:** 本文为玛丽杰公主船闸综合体的软件控制提供了一个精确、形式化的描述，使用mCRL2代码和模型检测验证了53项软件需求，确保了其正确性。

**AI_Comments:** 本文的创新之处在于将形式化方法（mCRL2和模型检测）应用于实际的、关键的基础设施项目——船闸综合体的软件行为规范。这种方法论对于确保复杂系统的安全性、可靠性和无错误运行至关重要。通过少量的代码（<400行mCRL2）和严格的验证过程（53项需求），该研究为高风险软件的开发提供了一个强有力的范例，显著提高了软件质量和信任度。

<details>
  <summary>Details</summary>

**Motivation:** 确保玛丽杰公主船闸综合体的安全控制至关重要，以保障防洪和可靠的船舶运营。因此，需要对船闸的软件行为进行精确的形式化描述和验证。

**Method:** 本文采用mCRL2语言对船闸综合体的软件控制进行了形式化描述，代码量少于400行。此外，使用模型检测验证了53项软件需求的有效性。

**Result:** 结果是生成了一个精确的、少于400行mCRL2代码的软件控制形式化描述，该描述可作为软件构建的蓝图。通过模型检测，53项软件需求被证明是有效的。

**Conclusion:** 本文提出的形式化描述在这些属性方面是正确的，并且不太可能包含错误和疏忽，从而确保了船闸综合体软件行为的正确性。

> **ai_Abstract:** 本文针对荷兰玛丽杰公主船闸综合体的软件控制，提出了一个精确的形式化规范。该规范使用mCRL2语言编写，代码量少于400行，旨在作为软件开发的蓝图。通过模型检测，研究人员验证了53项软件需求的有效性，从而确保了该形式化描述的正确性，并降低了潜在错误和疏忽的风险，对保障船闸的防洪和船舶运营安全具有重要意义。

> **摘要翻译:** 玛丽杰公主船闸综合体是荷兰的一个大型船闸和水利保护设施，位于莱茵河和阿姆斯特丹-莱茵运河之间——阿姆斯特丹-莱茵运河是一条连接莱茵河与阿姆斯特丹港的大型水道。该船闸综合体由两个独立的船闸和一个可移动的防洪屏障组成。确保船闸综合体的安全控制对于保障防洪和可靠的船舶运营至关重要。本文以不到400行mCRL2代码的形式，对船闸综合体的软件控制提供了精确的形式化描述。该描述可以作为船闸综合体软件构建的蓝图。此外，通过模型检测，53项软件需求被证明是有效的，确保了行为的形式化描述在这些属性方面是正确的，并且不太可能包含错误和疏忽。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [23] [Derivative-Free Optimization-Empowered Wireless Channel Reconfiguration for 6G](https://arxiv.org/abs/2507.02243)
> *基于无导数优化赋能的6G无线信道重构*

*Peilan Wang, Jun Fang, Xianlong Zeng, Bin Wang, Zhi Chen, Yonina C. Eldar* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 无导数优化, 零阶优化, 无线信道重构, 可重构天线, 6G

**Comment:** 7 pages

> **TL;DR:** 针对6G无线信道重构中重构系数优化难题，本文提出并应用无导数优化技术，无需信道建模和参数估计，即可直接优化系数以塑造无线信道，并在RIS和MA系统中验证其优越性。

**AI_Comments:** 这篇论文的创新点在于将无导数优化技术引入无线信道重构领域，解决了传统方法对精确信道建模和参数估计的依赖。这种“模型无关”的方法在实际部署中具有重要意义，尤其是在信道环境复杂多变的6G场景中。其重要性体现在为未来无线通信环境的智能控制提供了新的思路和工具。

<details>
  <summary>Details</summary>

**Motivation:** 在6G及未来无线通信中，利用可重构天线重塑无线传播环境面临挑战，即如何实时优化可控系数以实现有利的端到端无线信道。这通常需要对可重构设备与电磁波的复杂交互进行精确建模，并了解隐式信道传播参数，导致实施复杂。

**Method:** 本文引入无导数优化（即零阶优化）技术，直接优化可重构系数来塑造无线端到端信道，无需进行信道建模和隐式环境传播参数的估计。文中阐述了零阶优化的基本原理，并讨论了其在无线信道重构中的潜在优势。

**Result:** 通过对可重构智能表面（RIS）和可移动天线（MA）的单输入单输出（SISO）系统的两个案例研究，展示了基于零阶优化（ZO）的方法相较于现有技术的优越性。

**Conclusion:** 本文总结了无导数优化在可重构天线技术中的应用，并概述了有前景的未来研究方向，为该领域提供了总结性见解。

> **ai_Abstract:** 本文针对6G无线通信中利用可重构天线（如RIS、MA）进行信道重构所面临的挑战，提出并应用了无导数优化（零阶优化）技术。该方法无需复杂的信道建模和隐式参数估计，即可直接优化可重构系数以有效塑造端到端无线信道。论文通过对RIS和MA的SISO系统案例研究，验证了零阶优化方法相较于现有技术的优越性，并展望了未来的研究方向。

> **摘要翻译:** 可重构天线，包括可重构智能表面（RIS）、可移动天线（MA）、流体天线（FA）以及其他先进天线技术，已在重塑6G及未来无线通信的无线传播环境方面进行了广泛研究。然而，如何重构/优化实时可控系数以实现有利的端到端无线信道仍然是一个重大挑战，因为它通常需要对可重构设备和电磁波之间复杂相互作用的精确建模，以及对隐式信道传播参数的了解。在本文中，我们引入了一种无导数优化（又称零阶（ZO）优化）技术，无需信道建模和隐式环境传播参数的估计，即可直接优化可重构系数以塑造无线端到端信道。我们介绍了零阶优化的基本原理，并讨论了其在无线信道重构中的潜在优势。提供了两个RIS和可移动天线（MA）的单输入单输出（SISO）系统的案例研究，以展示基于零阶优化（ZO）的方法相对于现有技术的优越性。最后，我们概述了有前景的未来研究方向，并对可重构天线技术的无导数优化提供了总结性见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [52] [Localized kernel method for separation of linear chirps](https://arxiv.org/abs/2507.02262)
> *线性Chirp信号分离的局部核方法*

*Eric Mason, Sippanon Kitimoon, Hrushikesh Mhaskar* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** Chirp信号分离, 局部核方法, 信号分离算子, 低信噪比, 不连续性

**Comment:** 

> **TL;DR:** 本文提出了一种改进的信号分离算子（SSO）方法，用于在交叉、低信噪比和不连续条件下分离线性Chirp信号，并进行了理论分析和数值验证。

**AI_Comments:** 本文通过改进现有SSO方法，有效解决了Chirp信号在恶劣条件（如交叉、低信噪比、不连续性）下的分离难题，具有重要的实际应用价值。理论分析与数值验证相结合，增强了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 在各种信号处理应用（如音频和雷达信号）中，将叠加信号分离成其单个分量是一项常见的挑战。现有方法在面对交叉、极低信噪比和不连续性等复杂情况时可能表现不佳。

**Method:** 本文基于Chui和Mhaskar提出的信号分离算子（SSO）方法，对其进行了增强和修改，以实现在存在交叉、极低信噪比和不连续性情况下的Chirp信号分离。同时，对SSO在噪声存在下的行为进行了理论分析，以考察最小分离度、最小幅度、信噪比和采样频率之间的关系。

**Result:** 该方法通过一些示例进行了说明，并在一个包含7个模拟信号的模拟数据集上报告了数值结果。

**Conclusion:** 本文提出的改进方法能够有效分离存在交叉、低信噪比和不连续性的Chirp信号，并通过理论分析和数值实验验证了其有效性。

> **ai_Abstract:** 本文针对信号处理中常见的Chirp信号分离挑战，在Chui和Mhaskar提出的信号分离算子（SSO）方法基础上进行了改进。新方法旨在处理交叉、极低信噪比和不连续性等复杂情况下的Chirp信号分离。研究还对SSO在噪声环境中的行为进行了理论分析，探讨了关键参数间的关系。通过实例和模拟数据集的数值结果，验证了该方法的有效性。

> **摘要翻译:** 将信号叠加分离成其单独分量是各种信号处理应用中常见的挑战，尤其是在音频和雷达信号等领域。Chui和Mhaskar之前的一篇论文提出了一种称为信号分离算子（SSO）的方法，用于寻找瞬时频率和幅度随时间连续缓慢变化的此类叠加信号。在本文中，我们增强并修改了这种方法，以便在存在交叉、极低信噪比和不连续性的情况下分离Chirp信号。我们对SSO在噪声存在下的行为进行了理论分析，以检查最小分离度、最小幅度、信噪比和采样频率之间的关系。我们的方法通过一些例子进行了说明，并在一个包含7个模拟信号的模拟数据集上报告了数值结果。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [76] [STAR-RIS Transceivers: Integrated Sensing and Communication with Pulsed Signals](https://arxiv.org/abs/2507.02346)
> *STAR-RIS 收发器：基于脉冲信号的集成感知与通信*

*Hedieh Taremizadeh, Emanuele Grossi, Luca Venturino* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** STAR-RIS, 集成感知与通信, 脉冲信号, 空间调制, 时间调制

**Comment:** Accepted to the 33rd European Signal Processing Conference (EUSIPCO
  2025), Isola delle Femmine, Palermo, Italy

> **TL;DR:** 本研究提出并分析了一种基于STAR-RIS的集成感知与通信(ISAC)收发器，利用空间和时间调制脉冲信号实现雷达探测和通信，并评估了其对雷达性能的最小影响。

**AI_Comments:** 这篇论文的创新点在于将STAR-RIS技术应用于ISAC系统，并结合了独特的空间和时间调制方案。通过利用脉冲信号，它有效地实现了感知与通信功能的集成，同时强调了对雷达性能的最小影响，这对于实际应用至关重要。研究还详细考虑了通信和雷达性能之间的权衡。

<details>
  <summary>Details</summary>

**Motivation:** 旨在研究一种新型的集成感知与通信(ISAC)系统，该系统结合了STAR-RIS技术，以实现同时进行雷达感知和信息通信，并通过特定的调制方案优化性能。

**Method:** 该研究提出了一种ISAC收发器，其核心是STAR-RIS和配备PESA的接收器。系统利用馈线发出的周期性脉冲信号，在STAR-RIS上引入空间调制以照亮两个方向，并引入时间调制以区分目标回波和嵌入通信消息。时间调制采用正交二进制码本。

**Result:** 提出的时间调制方案使用了正交二进制码本，在传输速率和误码率之间提供了不同的权衡，同时对雷达性能（通过检测概率和径向速度估计的均方根误差评估）产生了最小的影响。

**Conclusion:** 该研究成功设计并分析了一种基于STAR-RIS的ISAC系统，证明了其在实现雷达探测和通信功能的同时，能够通过优化的时间调制方案有效平衡通信性能与雷达性能，并保持对雷达性能的最小影响。

> **ai_Abstract:** 本文研究了一种基于STAR-RIS的集成感知与通信（ISAC）收发器，结合了STAR-RIS和配备PESA的接收器。该系统利用周期性脉冲信号，通过在STAR-RIS上进行空间调制实现双向照明，并采用时间调制来区分雷达回波和嵌入通信信息。研究表明，所提出的时间调制方案（采用正交二进制码本）能在传输和误码率之间取得平衡，同时对雷达的检测概率和径向速度估计性能影响最小。

> **摘要翻译:** 本研究考察了一种集成感知与通信（ISAC）收发器，该收发器具有同时传输和反射可重构智能表面（STAR-RIS）以及配备无源电子扫描阵列（PESA）和单个数字通道的接收器。通过利用馈线发出的周期性脉冲信号，我们在STAR-RIS上引入空间调制，以照亮雷达接收器观察到的两个角方向（每个半空间一个），并引入时间调制以区分来自潜在移动目标的相应回波并嵌入通信消息。所提出的时间调制采用具有不同传输和错误率权衡的正交二进制码本，同时对雷达性能（通过检测概率和径向速度估计的均方根误差评估）产生最小影响。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [100] [Joint Radiation Power, Antenna Position, and Beamforming Optimization for Pinching-Antenna Systems with Motion Power Consumption](https://arxiv.org/abs/2507.02348)
> *考虑运动功耗的收缩天线系统中的联合辐射功率、天线位置和波束成形优化*

*Yiming Xu, Dongfang Xu, Xianghao Yu, Shenghui Song, Zhiguo Ding, Robert Schober* | **Category: eess.SP, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 收缩天线系统, 辐射功率优化, 天线位置优化, 波束成形, 运动功耗

**Comment:** 13 pages

> **TL;DR:** 本文首次在收缩天线系统中联合优化辐射功率、天线位置和波束成形，同时考虑运动功耗，以最小化平均功耗并满足QoS，并通过ADMM和BCD方法解决连续和离散情况下的优化问题，仿真结果验证了其性能提升和效率。

**AI_Comments:** 本文的创新点在于首次将辐射功率优化引入收缩天线系统（PASS）的设计中，为系统提供了额外的自由度，这在现有研究中是缺失的。同时，它全面考虑了天线运动功耗和可调辐射功率，使模型更贴近实际。其提出的针对连续和离散天线放置的ADMM和BCD优化框架也具有较高的技术贡献。该研究对于提升无线网络性能和实际部署PASS具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有收缩天线系统研究忽略了天线放置的物理约束和固定天线辐射功率的假设，也没有考虑收缩天线的运动功耗和可调天线辐射功率的影响。

**Method:** 本文旨在给定服务质量（QoS）要求下最小化平均功耗，通过联合优化天线位置、天线辐射功率比和发射波束成形。针对连续天线移动，提出了基于交替方向乘子法（ADMM）的框架；对于离散天线放置，将其表述为混合整数非线性规划（MINLP）问题，并采用块坐标下降（BCD）方法解决。

**Result:** 仿真结果验证了通过将PA运动功耗假设和可调辐射功率纳入PASS设计所实现的性能提升。所提出的优化框架被证明是高效的。研究还揭示了PASS在缓解大规模路径损耗和用户间干扰方面优于传统多输入多输出（MIMO）系统。

**Conclusion:** 本文首次将辐射功率优化引入收缩天线系统（PASS）设计，提供了额外的自由度，并通过提出的优化框架有效解决了联合优化问题，实现了显著的性能提升，并展现了PASS相比传统MIMO系统的优越性。

> **ai_Abstract:** 本文针对收缩天线系统（PASS）中现有研究忽略天线放置物理约束、固定辐射功率及运动功耗的问题，首次提出联合优化天线位置、辐射功率和波束成形以最小化给定QoS下的平均功耗。文章考虑了连续和离散两种天线放置情况，分别采用ADMM和BCD方法解决。仿真结果表明，引入PA运动功耗和可调辐射功率能显著提升系统性能，并验证了所提优化框架的有效性，同时揭示了PASS相比传统MIMO系统在抑制路径损耗和用户间干扰方面的优势。

> **摘要翻译:** 收缩天线系统（PASS）最近被提出，通过重新配置大尺度和小尺度信道条件来改善无线网络的性能。然而，现有研究忽略了天线放置的物理约束，并假设天线辐射功率固定。为了填补这一研究空白，本文研究了PASS的设计，同时考虑了收缩天线（PA）的运动功耗和可调天线辐射功率的影响。为此，我们通过联合优化天线位置、天线辐射功率比和发射波束成形，在给定服务质量（QoS）要求下最小化平均功耗。据作者所知，这是首次在PASS中考虑辐射功率优化，这为系统设计提供了额外的自由度（DoF）。本文考虑了连续和离散天线放置的情况，主要挑战在于天线位置会影响PASS信道系数的幅度和相位，使得系统优化非常具有挑战性。为了解决由此产生的独特障碍，提出了一种基于交替方向乘子法（ADMM）的框架来解决连续天线移动的问题，而其离散对应物则被表述为混合整数非线性规划（MINLP）问题，并通过块坐标下降（BCD）方法解决。仿真结果验证了通过将PA运动功耗假设和可调辐射功率纳入PASS设计所实现的性能提升，同时也证明了所提出优化框架的效率。文章还揭示了PASS在缓解大规模路径损耗和用户间干扰方面优于传统多输入多输出（MIMO）系统的优势。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [125] [Track-before-detect in RIS-aided Integrated Sensing and Communication](https://arxiv.org/abs/2507.02352)
> *RIS辅助的集成感知与通信中的检测前跟踪*

*Georgios Mylonopoulos, Luca Venturino, Emanuele Grossi, Stefano Buzzi, Ciro D'Elia* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 集成感知与通信, 可重构智能表面, 检测前跟踪, 多帧雷达, 频谱效率

**Comment:** Accepted to the 33rd European Signal Processing Conference (EUSIPCO
  2025), Isola delle Femmine, Palermo, Italy

> **TL;DR:** 在RIS辅助的集成感知与通信系统中，通过使用多帧检测前跟踪（TBD）处理器，在保持相同感知性能的同时，提高用户频谱效率。

**AI_Comments:** 该论文提出了一种利用多帧检测前跟踪（TBD）处理来增强RIS辅助集成感知与通信系统频谱效率的有趣方法。其创新之处在于将TBD应用于优化此类系统中的权衡，特别关注在提高通信效率的同时保持感知性能，这解决了ISAC领域的一个关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 为了在配备感知和通信能力的基站中，通过无源可重构智能表面（RIS）辅助，实现更有利的系统权衡。

**Method:** 本研究采用了一个多帧雷达检测器，该检测器包含一个检测器、一个目标提取器和一个检测前跟踪处理器。通过数值分析来验证所提出解决方案的有效性并评估系统权衡。

**Result:** 数值分析验证了所提出解决方案的有效性，并表明通过增加多帧雷达检测器联合处理的扫描次数，可以在保持相同感知性能的同时，提高用户频谱效率。

**Conclusion:** 本研究表明，所提出的多帧雷达检测器（包含检测前跟踪处理器）能够有效提高RIS辅助的集成感知与通信系统中的用户频谱效率，通过联合处理更多扫描，同时不损害感知性能。

> **ai_Abstract:** 本文研究了RIS辅助的集成感知与通信系统，其中基站服务用户并扫描天空。为优化系统权衡，提出了一种包含检测前跟踪（TBD）处理器的多帧雷达检测器。核心思想是通过联合处理更多雷达扫描来提高用户频谱效率，同时保持感知性能不变。数值分析证实了该方法的有效性并评估了系统权衡。

> **摘要翻译:** 本研究考虑了一个配备感知和通信能力的基站，该基站通过无源可重构智能表面服务地面用户并扫描部分天空。为了实现更有利的系统权衡，我们利用了一个多帧雷达检测器，它包括一个检测器、一个目标提取器和一个检测前跟踪处理器。本文提出的主要思想是，通过增加多帧雷达检测器联合处理的扫描次数，同时保持相同的感知性能，可以提高用户频谱效率。进行了数值分析以验证所提出解决方案的有效性并评估可实现的系统权衡。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [147] [Predictive Control over LAWN: Joint Trajectory Design and Resource Allocation](https://arxiv.org/abs/2507.02374)
> *预测控制在低空无线网络中的应用：联合轨迹设计与资源分配*

*Haijia Jin, Jun Wu, Weijie Yuan, Ruizhi Ruan, Jiacheng Wang, Dusit Niyato, Dong In Kim, Abbas Jamalipour* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 低空无线网络, 预测控制, 轨迹设计, 资源分配, 有限块长传输

**Comment:** 

> **TL;DR:** 本文研究了低空无线网络（LAWN）中无人机为移动AGV提供服务的实时无线控制问题，通过模型预测控制（MPC）和联合优化无人机轨迹、功率分配和控制策略，实现了优于基线方案的控制性能。

**AI_Comments:** 该论文创新性地将模型预测控制（MPC）应用于低空无线网络（LAWN）中的无人机实时控制问题，并考虑了有限块长（FBL）传输的通信约束。通过联合优化无人机轨迹、功率分配和控制策略，并设计了高效的非凸优化求解框架（AO结合PGD和SCA），解决了实际系统中的复杂挑战。其提出的方法在控制性能上超越了基线方案，具有重要的理论和实际意义，为未来低空无线网络中的高精度控制应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 低空无线网络（LAWN）被认为是物联网（IoT）系统中实现时延敏感控制应用的灵活且变革性的平台。本文旨在研究LAWN系统中的实时无线控制问题，其中无人机通过有限块长（FBL）传输为多个移动自动导引车（AGV）提供服务。

**Method:** 采用模型预测控制（MPC）确保精确的轨迹跟踪，并使用中断概率分析通信可靠性。构建一个联合优化控制策略、发射功率分配和无人机轨迹的优化问题，同时考虑最大行程距离和控制输入约束。为解决非凸问题，首先推导了FBL传输下中断概率的闭式表达式，然后将原问题重构为二次规划（QP）问题，并开发了交替优化（AO）框架。具体地，利用投影梯度下降（PGD）方法和逐次凸逼近（SCA）技术获得计算高效的次优解。此外，还彻底分析了所提算法的收敛性和计算复杂度。

**Result:** 广泛的仿真和基于AirSim的实验验证了所提出方法在控制性能方面优于基线方案。

**Conclusion:** 提出的联合轨迹设计和资源分配的预测控制方法在低空无线网络中实现了卓越的控制性能。

> **ai_Abstract:** 本文研究了低空无线网络（LAWN）中无人机为移动自动导引车（AGV）提供实时无线控制的问题。通过采用模型预测控制（MPC）和有限块长（FBL）传输，作者提出了一个联合优化无人机轨迹、发射功率分配和控制策略的框架。针对由此产生的非凸问题，推导了中断概率的闭式表达式，并将问题重构为二次规划（QP），然后开发了基于投影梯度下降（PGD）和逐次凸逼近（SCA）的交替优化（AO）算法。仿真和实验结果表明，该方法在控制性能上优于现有基线方案。

> **摘要翻译:** 低空无线网络（LAWN）被认为是物联网（IoT）系统中实现时延敏感控制应用的灵活且变革性的平台。在这项工作中，我们研究了LAWN系统中的实时无线控制问题，其中采用无人机通过有限块长（FBL）传输为多个移动自动导引车（AGV）提供服务。为此，我们采用模型预测控制（MPC）来确保精确的轨迹跟踪，同时使用中断概率分析通信可靠性。随后，我们制定了一个优化问题，通过考虑最大行程距离和控制输入约束来联合确定控制策略、发射功率分配和无人机轨迹。为了解决由此产生的非凸优化问题，我们首先推导了FBL传输下中断概率的闭式表达式。在此基础上，我们将原始问题重构为二次规划（QP）问题，并开发了一个交替优化（AO）框架。具体而言，我们采用投影梯度下降（PGD）方法和逐次凸逼近（SCA）技术来获得计算高效的次优解。此外，我们彻底分析了所提出算法的收敛性和计算复杂度。通过广泛的仿真和基于AirSim的实验，验证了我们提出的方法在控制性能方面优于基线方案。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [168] [Parameter estimation of range-migrating targets using OTFS signals from LEO satellites](https://arxiv.org/abs/2507.02385)
> *利用LEO卫星的OTFS信号对距离徙动目标进行参数估计*

*Tong Ding, Luca Venturino, Emanuele Grossi* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** OTFS信号, 距离徙动, 参数估计, LEO卫星, ISAC

**Comment:** submitted to IEEE journal for possible publication

> **TL;DR:** 该研究利用LEO卫星的OTFS信号，提出了一种估计距离徙动（高速）空间目标参数的方法，并推导了新的输入输出模型和近似最大似然估计算法。

**AI_Comments:** 本文的创新之处在于利用OTFS信号的特性处理距离徙动问题，并推导了新的目标回波模型，揭示了距离徙动对目标响应扩散的影响，这对于高速目标感知具有重要意义。所提出的估计方法结合了粗略估计和精细化步骤，提高了估计精度。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决使用OTFS信号估计高速空间目标参数的问题，特别是在存在距离徙动的情况下，因为距离徙动会导致目标响应扩散，这与之前的研究不同。

**Method:** 本研究构建了一个通信中心集成感知与通信（ISAC）系统，利用LEO卫星发射的OTFS调制信号。推导了在理想和矩形整形滤波器下，高速目标回波的新型输入-输出模型。利用信号的稀疏结构，提出了目标初始距离、距离率和幅度的近似最大似然估计器。估计过程包括使用块正交匹配追踪算法获取目标响应的粗略信息，然后使用一组匹配滤波器在较小的距离和距离率区域进行细化。最后，通过数值例子评估了估计性能。

**Result:** 研究发现目标响应在延迟-多普勒域呈现稀疏结构，仅依赖于初始距离和距离率。值得注意的是，距离徙动会导致目标响应扩散，这标志着与以往研究的显著不同。

**Conclusion:** 本文成功地利用LEO卫星的OTFS信号，针对存在距离徙动的高速空间目标，提出了有效的参数估计方法，并揭示了距离徙动对目标响应结构的影响。

> **ai_Abstract:** 本文研究了一种基于LEO卫星OTFS信号的通信-感知一体化系统，用于估计经历距离徙动的高速空间目标参数。研究推导了高速目标回波的新型输入-输出模型，发现目标响应在延迟-多普勒域具有稀疏结构，且距离徙动会导致响应扩散。在此基础上，提出了一种近似最大似然估计器，结合块正交匹配追踪和匹配滤波器组对目标初始距离、距离率和幅度进行估计。数值结果验证了所提方法的性能。

> **摘要翻译:** 本研究调查了一种以通信为中心的集成感知与通信（ISAC）系统，该系统利用低地球轨道（LEO）卫星发射的正交时频空间（OTFS）调制信号来估计经历距离徙动（此后称为高速目标）的空间目标的参数。利用OTFS收发器执行的特定信号处理，我们推导了在理想和矩形整形滤波器下，高速目标回波的新颖输入-输出模型。我们的研究结果表明，目标响应在延迟-多普勒域呈现稀疏结构，仅依赖于初始距离和距离率；值得注意的是，距离徙动会导致目标响应扩散，这标志着与以往研究的显著不同。利用这种信号结构，我们提出了目标初始距离、距离率和幅度的近似最大似然估计器。估计过程包括使用块正交匹配追踪算法获取目标响应的粗略信息，然后使用一组匹配滤波器在较小的距离和距离率区域进行细化。最后，提供了数值例子来评估估计性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [187] [When Attention is Beneficial for Learning Wireless Resource Allocation Efficiently?](https://arxiv.org/abs/2507.02427)
> *注意力机制何时有助于高效学习无线资源分配？*

*Jia Guo, Chenyang Yang* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 无线资源分配, 注意力机制, 图神经网络, 置换等变, 干扰建模

**Comment:** 13 pages, 6 figures

> **TL;DR:** 本文探讨了注意力机制在无线资源分配中何时是必需的，发现当可测量参数未反映干扰时，注意力机制至关重要。

**AI_Comments:** 该论文为注意力机制在无线资源分配中何时有益提供了理论基础，而非仅仅是经验性应用。这种基于函数特性和数值算法的结构化分析是创新的。它为无线系统中图神经网络的设计提供了指导原则，这对于实际应用非常重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前趋势是将注意力机制与图神经网络（GNNs）结合用于学习无线策略，但注意力机制的必要性尚未明确，本文旨在回答此问题。

**Method:** 通过分析集合上定义的函数结构和数值算法，证明了单集合上的置换等变函数可以递归地表示为两种类型：一种包含注意力，另一种不包含。然后将代表性资源分配问题的数值算法重写为递归形式，并基于此洞察建立了一个设计图神经网络的框架，并通过可重构智能表面辅助混合预编码示例进行验证。

**Result:** 证明了单集合上的置换等变函数可以递归地表示为两种类型，其中一种涉及注意力。发现当策略的可测量参数中未反映干扰（例如多用户或数据流间干扰）时，需要使用注意力机制来建模干扰。通过仿真验证了所提出的图神经网络的学习效率。

**Conclusion:** 当可测量参数中未直接反映干扰时，注意力机制对于学习无线资源分配是有益的。基于此洞察，建立了一个设计图神经网络的框架。

> **ai_Abstract:** 本文探讨了注意力机制在学习无线资源分配策略中的必要性，尤其是在与图神经网络（GNN）结合时。通过分析置换等变函数和数值算法的结构，论文证明当可测量的环境参数中未明确捕获干扰相关信息时，注意力机制对于建模干扰至关重要。论文提出了一个与这些洞察相符的GNN设计框架，并通过可重构智能表面辅助混合预编码的仿真验证了其学习效率。

> **摘要翻译:** 由于注意力机制被用于利用令牌之间的依赖关系，Transformer在自然语言处理中表现高效。通过利用资源分配策略中广泛存在的置换特性（每个策略将可测量的环境参数，例如信道矩阵，映射到优化变量，例如预编码矩阵），图神经网络（GNN）在可扩展性和泛化性方面有望高效学习这些策略。为了结合这两种架构的优点，近期出现了一种将注意力机制与GNN结合用于学习无线策略的趋势。然而，注意力机制对于资源分配真的有必要吗？在本文中，我们通过分析在集合和数值算法上定义的函数结构来努力回答这个问题，因为无线策略的置换特性是由所涉及的集合（例如用户集合）引起的。具体而言，我们证明了单个集合上的置换等变函数可以递归地表达为两种类型的函数：一种涉及注意力，另一种不涉及。我们进一步将优化几个代表性资源分配问题的数值算法重新表达为递归形式。我们发现，当策略的可测量参数中未反映干扰（例如多用户或数据流间干扰）时，需要使用注意力机制来建模干扰。基于这一洞察，我们建立了一个通过与结构对齐来设计GNN的框架。以可重构智能表面辅助混合预编码为例，通过仿真验证了所提出的GNN的学习效率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [202] [Corrections to Published Values of Frequency Sampling Filter Transition Coefficients](https://arxiv.org/abs/2507.02556)
> *频率采样滤波器过渡系数已发表值的修正*

*C. S. Ramalingam* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 频率采样滤波器, 过渡系数, 峰值旁瓣电平, 最优值, 修正

**Comment:** 11 pages, 5 figures

> **TL;DR:** 本文修正了已发表的频率采样滤波器过渡系数和峰值旁瓣电平（PSL）的错误值，并提供了通过程序计算出的最优值。

**AI_Comments:** 这篇论文对于数字信号处理领域的实践者来说非常重要，因为它纠正了频率采样滤波器的基本设计参数，确保了更准确和最优的滤波器设计。其创新之处在于重新评估并提供了先前存在差异和次优情况下的精确最优值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的频率采样滤波器（FSF）设计中，关于最佳过渡系数和峰值旁瓣电平（PSL）的已发表数值存在显著差异且并非真正最优，例如Rabiner等人和Lyons所发布的数据之间存在不一致。

**Method:** 作者使用“他们的程序”对Rabiner等人和Lyons列出的低通和带通滤波器进行了估计，从而确定了过渡系数和PSL的最佳值。

**Result:** 本文提供了频率采样滤波器过渡系数和相应峰值旁瓣电平（PSL）的新的、最优值，纠正了先前发表的错误值。例如，对于N=16和BW=4，新的最优值为0.40474097，与之前报道的0.38916626（Rabiner等人）和0.34918551（Lyons）不同。

**Conclusion:** 本文成功识别并纠正了先前发表的频率采样滤波器过渡系数和峰值旁瓣电平的错误最优值，提供了准确的最优数据。

> **ai_Abstract:** 本文旨在纠正已发表的频率采样滤波器（FSF）设计中存在的关于最佳过渡系数和峰值旁瓣电平（PSL）的显著不准确性。文章指出，Rabiner等人和Lyons等来源的数据存在差异且并非最优。通过使用作者自己的计算程序，本文重新评估并提供了针对低通和带通滤波器的精确、最优的过渡系数和PSL值，从而纠正了数字信号处理文献中长期存在的错误。

> **摘要翻译:** Rabiner等人（1970年6月）发表了与频率采样滤波器（FSF）设计相关的最佳过渡系数和峰值旁瓣电平（PSL，单位为dB）的表格，并在Proakis和Manolakis的《数字信号处理》（第4版，2007年）等书籍中被转载。Lyons的《理解数字信号处理》（第3版，2011年）附录H中也给出了一组数值，但这两组数值之间存在显著差异。例如，对于N=16和BW=4，报告了两个不同的过渡系数值，即0.38916626（Rabiner等人）和0.34918551（Lyons）。两者都不是最优的，因为我们发现最优值为0.40474097。相应的PSL已发表值也被发现是不正确的。在本文中，我们给出了通过我们的程序估算的Rabiner等人和Lyons所列的低通和带通滤波器的最佳过渡系数和PSL值。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [215] [Pinching-Antenna-Assisted Index Modulation: Channel Modeling, Transceiver Design, and Performance Analysis](https://arxiv.org/abs/2507.02641)
> *夹持天线辅助的索引调制：信道建模、收发机设计和性能分析*

*Shuaixin Yang, Yijia Li, Yue Xiao, Yong Liang Guan, Xianfu Lei, Zhiguo Ding* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 夹持天线,索引调制,信道建模,收发机设计,预编码

**Comment:** 

> **TL;DR:** 提出了一种新的夹持天线辅助索引调制（PA-IM）方案，通过信道建模、收发机设计和性能分析来提高频谱效率和性能。

**AI_Comments:** 该论文提出了一种创新的索引调制方案，利用夹持天线位置模式来编码信息，有效提高了频谱效率而无需增加硬件复杂性。其综合的信道建模考虑了波导内传播和无线信道特性，使得模型更贴近实际。低复杂度检测算法和优化的预编码设计进一步提升了系统的实用性和性能，展示了在无线通信领域，特别是毫米波或太赫兹频段潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了在不增加硬件复杂性的前提下提高频谱效率，并解决传统M-ary正交幅度调制（QAM）符号传输的局限性，本文提出了一种新的夹持天线辅助索引调制（PA-IM）方案。该方案通过夹持天线（PA）位置模式的索引来传输信息。此外，研究旨在克服接收端信号检测和发射端性能优化中的关键挑战。

**Method:** 1. 提出了一种新的夹持天线辅助索引调制（PA-IM）方案，其中信息比特通过QAM符号和PA位置模式的索引进行传输。2. 建立了一个综合信道模型，该模型结合了波导内的确定性传播效应和无线信道（包括大尺度路径损耗和小尺度衰落）的随机性。3. 设计了一种低复杂度的盒优化球形解码（BOSD）算法，用于近似最优最大似然（ML）检测，该算法能自适应地修剪搜索空间并保持ML性能。4. 推导并验证了误码率（BER）的分析上限。5. 设计了一种新的基于流形优化的发射预编码方法，通过联合优化波导内的复值预编码系数来最大化所有接收信号点的最小欧几里得距离，从而最小化BER。

**Result:** 仿真结果表明，所提出的PA-IM方案比传统方案获得了显著的性能增益。所提出的预编码设计显著改善了夹持天线系统的整体误码率。

**Conclusion:** 本文提出的夹持天线辅助索引调制（PA-IM）方案，结合了综合信道模型、低复杂度检测算法和优化的预编码设计，能够显著提高频谱效率和系统性能，克服了传统方案的局限性。

> **ai_Abstract:** 本文提出了一种创新的夹持天线辅助索引调制（PA-IM）方案，旨在提高频谱效率和系统性能。该方案通过结合QAM符号和夹持天线位置模式的索引来传输信息。为实现其潜力，研究人员构建了综合信道模型，开发了低复杂度信号检测算法（BOSD），推导了误码率上限，并设计了基于流形优化的发射预编码方法。仿真结果验证了PA-IM方案及其预编码设计的显著性能优势。

> **摘要翻译:** 在本文中，提出了一种新颖的夹持天线辅助索引调制（PA-IM）方案，旨在提高频谱效率而不增加硬件复杂性。在该方案中，信息比特不仅通过传统的M-ary正交幅度调制（QAM）符号传输，还通过夹持天线（PA）位置模式的索引传输。为了充分发挥该方案的潜力，本文重点关注全面的收发机设计，解决了接收端信号检测和发射端性能优化中的关键挑战。首先，为该架构建立了一个综合信道模型，该模型巧妙地将波导内确定性传播效应与无线信道（包括大尺度路径损耗和小尺度衰落）的随机性相结合。其次，为了克服最优最大似然（ML）检测的过高复杂性，设计了一种低复杂度的盒优化球形解码（BOSD）算法，该算法在保持最优ML性能的同时自适应地修剪搜索空间。此外，推导并验证了误码率（BER）的分析上限。再者，设计了一种新的基于流形优化的发射预编码方法，通过联合优化波导内的复值预编码系数以最大化所有接收信号点的最小欧几里得距离，从而最小化BER。最后，仿真结果表明，所提出的PA-IM方案比传统方案获得了显著的性能增益，并且所提出的预编码设计显著改善了夹持天线系统的整体误码率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [227] [AREE-Based Decoupled Design of Hybrid Beamformers in mmWave XL-MIMO Systems](https://arxiv.org/abs/2507.02802)
> *基于AREE的毫米波XL-MIMO系统中混合波束赋形器的解耦设计*

*Jiazhe Li, Nicolò Decarli, Francesco Guidi, Heng Dong, Anna Guerra, Alessandro Bazzi, Zhuoming Li* | **Category: eess.SP** | **Updated: {updated}**

**Keywords:** 混合波束赋形, 毫米波, XL-MIMO, AREE, 解耦设计

**Comment:** 

> **TL;DR:** 提出了一种基于交替残差误差消除（AREE）算法的混合波束赋形设计，有效解决了模拟和数字预编码器之间的耦合问题，提高了计算和频谱效率。

**AI_Comments:** 该论文的创新点在于提出了AREE算法，通过巧妙的子问题分解和迭代残差消除机制，有效解决了混合波束赋形中模拟和数字预编码器的耦合难题。其引入的低复杂度几何信道SVD算法进一步简化了问题，并提升了实用性。该方法在提高频谱效率、降低复杂度及加速收敛方面展现出显著优势，对未来毫米波通信系统设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有混合阵列架构中模拟和数字预编码器之间固有的耦合严重限制了现有算法的计算和频谱效率。

**Method:** 提出了一种交替残差误差消除（AREE）算法，将混合波束赋形问题分解为两个低维子问题，这些子问题通过迭代消除彼此的残差误差来逼近最优性能。该方法还引入了快速收敛的初始化策略，并开发了一种低复杂度的几何信道SVD算法，将高维稀疏信道转换为低维等效信道，简化了子问题的推导。

**Result:** 仿真结果表明，AREE算法能够以低复杂度有效解耦模拟和数字预编码器，实现快速收敛，并提供比现有波束赋形方法更高的频谱效率。

**Conclusion:** 所提出的AREE算法成功解决了毫米波XL-MIMO系统中混合波束赋形器中模拟和数字预编码器的耦合问题，显著提升了系统的计算和频谱效率及收敛速度。

> **ai_Abstract:** 该论文针对毫米波XL-MIMO系统中混合波束赋形器中模拟和数字预编码器之间固有的耦合问题，提出了一种名为交替残差误差消除（AREE）的新算法。AREE算法通过将复杂问题分解为两个可迭代消除残差误差的低维子问题，实现了预编码器的有效解耦。此外，文章还引入了快速收敛的初始化方法和低复杂度的几何信道SVD算法。仿真结果验证了AREE算法在低复杂度下实现解耦、快速收敛和更高频谱效率的优越性。

> **摘要翻译:** 混合波束赋形在毫米波通信（如车联网（V2X）场景）中得到了广泛应用，作为硬件复杂度和频谱效率之间的折衷方案。然而，混合阵列架构中模拟和数字预编码器之间固有的耦合严重限制了现有算法的计算和频谱效率。为了解决这个问题，我们提出了一种交替残差误差消除（AREE）算法，该算法将混合波束赋形问题分解为两个低维子问题，每个子问题都表现出有利的矩阵结构，能够有效地从矩阵乘积公式中解耦模拟和数字预编码器。这些子问题迭代消除彼此的残差误差，从而使原始问题趋向于最佳混合波束赋形性能。所提出的初始化确保了快速收敛，同时通过将高维稀疏信道转换为低维等效信道，开发了一种低复杂度的几何信道SVD算法，从而简化了子问题的推导。仿真结果表明，AREE算法能够以低复杂度有效地解耦模拟和数字预编码器，实现快速收敛，并提供比现有波束赋形方法更高的频谱效率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [237] [DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift](https://arxiv.org/abs/2507.02824)
> *基于DNN的RIS辅助毫米波MIMO系统中实际相移预编码*

*Po-Heng Chou, Ching-Wen Chen, Wan-Jen Huang, Walid Saad, Yu Tsao, Ronald Y. Chang* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 毫米波MIMO, 预编码, 可重构智能表面, 深度神经网络, 相移

**Comment:** 5 pages, 4 figures, 2 tables, accepted by IEEE Globecom 2024
  Workshops

> **TL;DR:** 本文提出了一种基于深度神经网络（DNN）的预编码设计，用于RIS辅助的毫米波MIMO系统，旨在解决传统穷举搜索计算复杂度高的问题，并证明了其在保持次优频谱效率方面的有效性。

**AI_Comments:** 本文的创新点在于将深度神经网络应用于RIS辅助的毫米波MIMO系统中的预编码设计，有效解决了传统穷举搜索方法计算复杂度高的问题。这对于实现实时、高效的通信具有重要意义，展示了AI在未来无线通信系统中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在有阻塞直通路径的毫米波MIMO系统中，需要进行预编码设计以最大化吞吐量。传统的穷举搜索（ES）方法，即使是针对离散相移，也存在计算复杂度高和耗时的问题。

**Method:** 采用可重构智能表面（RIS）来增强毫米波MIMO传输。为了降低计算复杂度，开发并训练了深度神经网络（DNN）来替代传统的穷举搜索和基于置换离散傅里叶变换（DFT）向量的方法，以实现更快的码字选择。

**Result:** 仿真结果表明，DNN能够保持次优的频谱效率，即使在测试阶段终端用户与RIS之间的距离发生变化时也是如此。

**Conclusion:** 这些结果突出了DNN在推进RIS辅助系统中的潜力，能够有效解决传统预编码设计中计算复杂度高的问题。

> **ai_Abstract:** 本文针对存在阻塞直通路径的毫米波MIMO系统，提出了一种基于深度神经网络（DNN）的预编码设计方法，旨在最大化系统吞吐量并解决传统穷举搜索方法计算复杂度高的问题。研究中引入了可重构智能表面（RIS）以增强传输。仿真结果显示，所提出的DNN方法在保持次优频谱效率的同时，显著提高了码字选择的速度，即使在RIS与用户距离变化的情况下也能保持良好性能，展现了DNN在RIS辅助系统中的应用潜力。

> **摘要翻译:** 在本文中，研究了阻塞直通路径的毫米波（mmWave）多输入多输出（MIMO）系统的预编码设计，以最大化吞吐量。特别是，考虑到与视线（LoS）和多径效应相关的毫米波特性，采用了可重构智能表面（RIS）来增强MIMO传输。传统上，连续相移中寻找最优码字的穷举搜索（ES）计算量大且耗时。为了降低计算复杂度，使用置换离散傅里叶变换（DFT）向量来寻找码本设计，其中结合了实际或理想RIS系统的幅度响应。然而，即使在ES中采用离散相移，也会导致显著的计算量和耗时。取而代之的是，开发了训练好的深度神经网络（DNN）以促进更快的码字选择。仿真结果表明，即使在测试阶段终端用户与RIS的距离发生变化，DNN也能保持次优的频谱效率。这些结果突出了DNN在推进RIS辅助系统中的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [21] [Unsupervised Cardiac Video Translation Via Motion Feature Guided Diffusion Model](https://arxiv.org/abs/2507.02003)
> *无监督心脏视频翻译通过运动特征引导扩散模型*

*Swakshar Deb, Nian Wu, Frederick H. Epstein, Miaomiao Zhang* | **Category: eess.IV** | **Updated: {updated}**

**Keywords:** 心脏视频翻译, 扩散模型, 无监督学习, 运动特征, CMR

**Comment:** 

> **TL;DR:** 本文提出了一种名为MFD-V2V的运动特征引导扩散模型，用于无监督心脏视频翻译，能将低对比度DENSE CMR序列转换为高对比度电影CMR。该方法表现优异，并能改善下游临床任务。

**AI_Comments:** 该论文提出了一种创新的无监督医学图像翻译方法，特别针对心脏CMR。利用运动特征引导扩散模型结合LTMA和STME等专用组件，解决了合成高质量、动态医学视频的挑战性任务。其改善下游临床任务的能力突显了其实际意义。无监督特性是其关键优势，减少了对配对数据的需求。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过无监督视频到视频翻译，从对比度较低、易受伪影影响的刺激回波位移编码（DENSE）心血管磁共振（CMR）序列合成动态、高对比度的电影CMR。

**Method:** 提出了一种名为MFD-V2V（运动特征引导扩散模型）的新方法。首先，引入一个潜在时间多注意力（LTMA）配准网络，用于从电影CMR图像视频中学习准确一致的心脏运动。然后，开发了一个多级运动特征引导扩散模型，配备专门的时空运动编码器（STME），以提取细粒度运动条件，从而提高合成质量和保真度。

**Result:** MFD-V2V在全面的心脏数据集上进行了评估，结果显示其在定量指标和定性评估方面均优于现有最先进的方法。此外，合成的电影CMRs被证明能改善下游临床和分析任务。

**Conclusion:** 本文提出的MFD-V2V模型能有效地将DENSE CMR翻译成高对比度电影CMR，表现出卓越的性能，并能改善下游临床和分析任务，突显了其广泛的影响。

> **ai_Abstract:** 本文介绍了一种名为MFD-V2V的无监督运动特征引导扩散模型，用于将DENSE CMR视频翻译成高对比度电影CMR。该模型利用LTMA网络学习心脏运动，并在多级扩散模型中通过STME提取细粒度运动条件。MFD-V2V在心脏数据集上表现优于现有技术，并能有效改善下游临床任务。

> **摘要翻译:** 本文提出了一种新颖的运动特征引导扩散模型，用于非配对视频到视频翻译（MFD-V2V），旨在从对比度较低、易受伪影影响的刺激回波位移编码（DENSE）心血管磁共振（CMR）序列合成动态、高对比度的电影CMR。为此，我们首先引入了一个潜在时间多注意力（LTMA）配准网络，该网络能有效地从电影CMR图像视频中学习更准确、更一致的心脏运动。然后，开发了一个多级运动特征引导扩散模型，配备专门的时空运动编码器（STME）以提取细粒度运动条件，从而提高合成质量和保真度。我们在一个全面的心脏数据集上评估了我们的方法MFD-V2V，结果表明其在定量指标和定性评估方面均优于现有最先进的技术。此外，我们展示了我们合成的电影CMRs在改善下游临床和分析任务方面的益处，突显了我们方法的广泛影响。我们的代码已在 https://github.com/SwaksharDeb/MFD-V2V 公开。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [50] [CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR](https://arxiv.org/abs/2507.02289)
> *CineMyoPS：从电影心脏MR图像中分割心肌病理*

*Wangbin Ding, Lei Li, Junyi Qiu, Bogen Lin, Mingjing Yang, Liqin Huang, Lianming Wu, Sihan Wang, Xiahai Zhuang* | **Category: eess.IV, cs.CV** | **Updated: {updated}**

**Keywords:** 心肌病理分割, 电影CMR, 深度学习, 心肌梗死, CineMyoPS

**Comment:** 

> **TL;DR:** 提出CineMyoPS深度学习网络，仅通过电影CMR图像分割心肌梗死引起的疤痕和水肿，无需造影剂，且表现良好。

**AI_Comments:** 该论文提出CineMyoPS，创新性地利用无创、快速的电影CMR图像进行心肌病理分割，避免了传统LGE/T2加权CMR对造影剂和时间的依赖。其设计的联合学习一致性损失和时间序列聚合策略是提升分割准确性的关键。该方法有望显著提高心肌梗死诊断和风险评估的效率与可及性。

<details>
  <summary>Details</summary>

**Motivation:** 心肌梗死是全球主要的死亡原因。传统的LGE和T2加权CMR成像虽能识别疤痕和水肿，但耗时且需造影剂。电影CMR是一种快速、无造影剂的技术，能显示急性心肌梗死引起的心肌运动和结构异常，因此需要一种方法仅凭电影CMR图像进行病理分割。

**Method:** 提出一个名为CineMyoPS的端到端深度神经网络，专门用于从电影CMR图像中分割心肌病理（疤痕和水肿）。CineMyoPS提取与心肌梗死相关的运动和解剖特征，并设计了一个一致性损失（类似于协同训练策略）以促进这些特征的联合学习。此外，还提出了一种时间序列聚合策略，以整合整个心动周期内与心肌梗死相关的特征，从而提高心肌病理分割的准确性。

**Result:** 在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面取得了有希望的性能。

**Conclusion:** CineMyoPS作为一种基于电影CMR图像进行心肌病理分割的无创且高效的方法，能够有效识别心肌梗死引起的疤痕和水肿，为MI风险分层和预后评估提供支持。

> **ai_Abstract:** 该研究提出了一种名为CineMyoPS的端到端深度神经网络，旨在仅利用快速、无造影剂的电影心脏磁共振（CMR）图像来分割心肌病理（如心肌梗死引起的疤痕和水肿）。该网络通过提取运动和解剖特征，并设计一致性损失和时间序列聚合策略来增强联合学习和特征整合。实验结果表明，CineMyoPS在多中心数据集上对心肌病理分割、运动估计和解剖分割均表现出良好性能，为心肌梗死风险评估提供了新的、更便捷的工具。

> **摘要翻译:** 心肌梗死（MI）是全球主要的死亡原因。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像可以分别识别瘢痕和水肿区域，这两者对于心肌梗死的风险分层和预后评估都至关重要。尽管结合多序列CMR的互补信息很有用，但获取这些序列可能耗时且成本高昂，例如由于需要施用造影剂。电影CMR是一种快速且无需造影剂的成像技术，可以可视化急性心肌梗死引起的心肌运动和结构异常。因此，我们提出了一个名为CineMyoPS的新的端到端深度神经网络，仅从电影CMR图像中分割心肌病理，即瘢痕和水肿。具体而言，CineMyoPS提取与MI相关的运动和解剖特征。考虑到这些特征之间的相互依赖性，我们设计了一种一致性损失（类似于协同训练策略）来促进它们的联合学习。此外，我们提出了一种时间序列聚合策略，以整合整个心动周期内与MI相关的特征，从而提高心肌病理分割的准确性。在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面取得了有希望的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [74] [A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\left[^{18}\text{F}\right]$FDG PET imaging](https://arxiv.org/abs/2507.02367)
> *一种用于动态小动物[18F]FDG PET成像中动脉输入功能预测的鲁棒且多功能的深度学习模型*

*Christian Salomonsen, Luigi Tommaso Luppino, Fredrik Aspheim, Kristoffer Wickstrøm, Elisabeth Wetzer, Michael Kampffmeyer, Rodrigo Berzaghi, Rune Sundset, Robert Jenssen, Samuel Kuttner* | **Category: eess.IV, cs.CV, physics.med-ph, q-bio.QM** | **Updated: {updated}**

**Keywords:** 深度学习, PET成像, 动脉输入功能, 小动物, 非侵入性

**Comment:** 22 pages, 12 figures

> **TL;DR:** 提出了一种基于全卷积深度学习的非侵入性方法（FC-DLIF），直接从PET图像预测动脉输入功能，以替代小动物PET研究中繁琐的动脉采血。

**AI_Comments:** 该论文提出了一种创新性的深度学习方法，通过非侵入性手段预测小动物PET成像中的动脉输入功能，显著提高了实验效率和动物福利。其主要创新在于利用全卷积网络直接从图像数据中提取时空特征来预测AIF，避免了繁琐的采血过程。模型的鲁棒性在处理时间偏移和截断数据方面表现突出，这对于实际应用非常重要。然而，模型的局限性在于其对训练数据中未包含的放射性示踪剂的泛化能力有限，这意味着在应用于新示踪剂时可能需要重新训练或进行迁移学习。这提示了未来研究可以探索更具泛化性的模型架构或多示踪剂训练策略。

<details>
  <summary>Details</summary>

**Motivation:** 在小动物PET研究中，准确的动力学建模需要精确的输入功能估计，传统上通过动脉采血实现。然而，对小动物（如小鼠）进行动脉插管操作复杂、耗时且具有终结性，阻碍了纵向研究的进行。

**Method:** 本研究提出了一种非侵入性的全卷积深度学习方法（FC-DLIF），直接从PET图像预测输入功能。FC-DLIF模型包含一个作用于PET序列体积时间帧的空间特征提取器，用于提取空间特征，随后由一个时间特征提取器进一步处理并预测动脉输入功能。该方法使用[18F]FDG数据进行交叉验证训练和评估，并使用另外两种放射性示踪剂（[18F]FDOPA和[68Ga]PSMA）的数据评估模型适用性。此外，还对时间截断和偏移的数据进行了评估，以模拟更短和偏移的PET扫描。

**Result:** 所提出的FC-DLIF模型在均方误差和相关性方面能够可靠地预测动脉输入功能。此外，FC-DLIF模型即使从截断和偏移的样本中也能预测动脉输入功能。然而，该模型未能预测使用不同放射性示踪剂收集的样本的AIF，因为这些示踪剂未在训练数据中表示。

**Conclusion:** 本研究提出的基于深度学习的输入功能提供了一种非侵入性且可靠的替代动脉采血的方法，证明了其对于时间偏移和不同扫描持续时间的鲁棒性和灵活性。

> **ai_Abstract:** 本研究提出了一种名为FC-DLIF的非侵入性全卷积深度学习模型，旨在解决小动物PET成像中动脉输入功能（AIF）估计传统采血方法的复杂性和局限性。该模型通过空间和时间特征提取器直接从PET图像预测AIF，并通过[18F]FDG数据进行训练和验证。结果表明，FC-DLIF模型能够可靠地预测AIF，并对扫描时间截断和偏移具有鲁棒性。尽管该模型未能泛化到训练数据中未包含的其他放射性示踪剂，但它为小动物PET研究提供了一种无需采血的可靠AIF预测替代方案。

> **摘要翻译:** 动态正电子发射断层扫描（PET）和动力学建模在推动小动物研究中的示踪剂开发方面至关重要。准确的动力学建模需要精确的输入功能估计，传统上通过动脉采血实现。然而，对小动物（如小鼠）进行动脉插管操作复杂、耗时且具有终结性，阻碍了纵向研究的进行。本工作提出了一种非侵入性的、基于全卷积深度学习的方法（FC-DLIF），直接从PET成像中预测输入功能，可能无需在动态小动物PET中进行采血。所提出的FC-DLIF模型包含一个作用于PET序列体积时间帧的空间特征提取器，用于提取空间特征。这些特征随后由一个时间特征提取器进一步处理，该提取器预测动脉输入功能。所提出的方法使用[18F]FDG数据（图像和动脉血曲线）进行交叉验证训练和评估。此外，模型适用性还通过使用两种额外的放射性示踪剂（[18F]FDOPA和[68Ga]PSMA）收集的成像数据和动脉血曲线进行了评估。模型还对时间截断和偏移的数据进行了评估，以模拟更短和偏移的PET扫描。所提出的FC-DLIF模型在均方误差和相关性方面能够可靠地预测动脉输入功能。此外，FC-DLIF模型即使从截断和偏移的样本中也能预测动脉输入功能。该模型未能预测使用不同放射性示踪剂收集的样本的AIF，因为这些示踪剂未在训练数据中表示。我们基于深度学习的输入功能提供了一种非侵入性且可靠的替代动脉采血的方法，证明了其对于时间偏移和不同扫描持续时间的鲁棒性和灵活性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [98] [3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices](https://arxiv.org/abs/2507.02411)
> *从稀疏姿态无关的二维超声心动图切片进行三维心脏重建*

*Zhurong Chen, Jinhua Chen, Wei Zhuo, Wufeng Xue, Dong Ni* | **Category: eess.IV, cs.CV** | **Updated: {updated}**

**Keywords:** 三维心脏重建, 超声心动图, 隐式神经网络, 左心室容积, 右心室容积

**Comment:** 10 pages

> **TL;DR:** 本文提出了一种从稀疏的姿态无关二维超声心动图切片重建个性化三维心脏的新框架，显著提高了左心室和右心室体积的估计精度。

**AI_Comments:** 该研究的创新之处在于能够从临床实践中常用的、姿态无关的稀疏二维超声切片重建高精度的三维心脏模型，克服了传统二维超声的局限性以及现有三维超声的不足。其显著提高左心室和右心室体积估计精度的成果，对于临床诊断和治疗具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 超声心动图在临床实践中对心脏疾病的诊断至关重要，但传统的二维超声心动图难以解释且在临床参数（如左心室容积）估计上不准确。现有的三维超声成像则受限于低空间和时间分辨率以及高要求的手动描绘。本文旨在解决这些挑战。

**Method:** 本文提出了一种创新的框架，用于从临床常用的二维超声心动图切片重建个性化三维心脏解剖结构。具体而言，设计了一个新颖的三维重建流程，该流程交替优化二维切片的3D姿态估计和使用隐式神经网络对这些切片进行3D整合，从而逐步将先验的3D心脏形状转换为个性化的3D心脏模型。

**Result:** 该方法在两个数据集上进行了验证。当使用六个平面时，重建的三维心脏在左心室容积估计方面比双平面方法有显著改进（误差百分比：1.98% 对比 20.24%）。此外，整个重建框架甚至在从二维超声心动图切片估计右心室容积方面取得了重要突破（误差为5.75%）。

**Conclusion:** 本研究为从心脏超声图像进行个性化三维结构和功能分析提供了一种新方法，在临床实践中具有巨大潜力。

> **ai_Abstract:** 本文提出了一种创新的框架，旨在从临床常用的稀疏二维超声心动图切片重建个性化三维心脏解剖结构。该方法通过一个新颖的3D重建流程，交替优化二维切片的3D姿态估计和基于隐式神经网络的3D整合，从而将先验的3D心脏模型逐步转化为个性化模型。实验结果表明，该方法显著提高了左心室容积和右心室容积的估计精度，为心脏超声的个性化三维结构和功能分析提供了新的途径，具有重要的临床应用潜力。

> **摘要翻译:** 超声心动图（echo）在心脏疾病的临床实践中发挥着不可或缺的作用。然而，超声成像通常仅从几个特定视图提供二维（2D）横截面图像，这使得解释困难且对临床参数（如左心室（LV）容积）的估计不准确。三维超声成像为3D量化提供了另一种选择，但仍受限于低空间和时间分辨率以及高度要求的手动描绘。
为了应对这些挑战，我们提出了一种创新框架，用于从临床实践中常用的2D超声心动图切片重建个性化的3D心脏解剖结构。具体而言，设计了一个新颖的3D重建流程，该流程交替优化这些2D切片的3D姿态估计和使用隐式神经网络对这些切片进行3D整合，从而逐步将先验的3D心脏形状转换为个性化的3D心脏模型。
我们在两个数据集上验证了该方法。当使用六个平面时，重建的三维心脏在左心室容积估计方面比双平面方法有显著改进（误差百分比：1.98% 对比 20.24%）。此外，整个重建框架甚至在从2D超声心动图切片估计右心室容积方面取得了重要突破（误差为5.75%）。这项研究为从心脏超声进行个性化三维结构和功能分析提供了一种新方法，在临床实践中具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [123] [MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection](https://arxiv.org/abs/2507.02668)
> *MEGANet-W：一种基于小波驱动边缘引导注意力的弱边界息肉检测框架*

*Zhe Yee Tan* | **Category: eess.IV, cs.CV** | **Updated: {updated}**

**Keywords:** 结直肠息肉分割, 弱边界, 小波, 边缘引导注意力, MEGANet-W

**Comment:** 7 pages, 3 figures

> **TL;DR:** MEGANet-W是一个小波驱动的边缘引导注意力网络，通过注入Haar小波边缘图来提高结直肠息肉分割的准确性，尤其是在弱边界条件下，且不增加可学习参数，性能优于现有方法。

**AI_Comments:** MEGANet-W的创新之处在于其独特地利用了参数无关的Haar小波边缘图，并通过WEGA模块将其融入深度学习框架，以解决弱边界检测的难题。这种方法在不增加模型复杂性和可学习参数的情况下，显著提升了医疗图像分割的准确性，对于结直肠癌的早期诊断具有重要临床意义。

<details>
  <summary>Details</summary>

**Motivation:** 结直肠息肉分割对早期结直肠癌检测至关重要，但弱和低对比度边界严重限制了自动化检测的准确性。现有深度模型要么模糊精细边缘细节，要么依赖在可变成像条件下表现不佳的手工滤波器。

**Method:** 本文提出了MEGANet-W，一个小波驱动的边缘引导注意力网络，它将方向性、无参数的Haar小波边缘图注入到每个解码器阶段以重新校准语义特征。主要贡献包括：(1) 一个用于多方向边缘提取的两级Haar小波头部；(2) 小波边缘引导注意力（WEGA）模块，将小波线索与反向和输入分支融合。

**Result:** 在五个公共息肉数据集上，MEGANet-W始终优于现有方法，mIoU提高了2.3%，mDice提高了1.2%，同时没有引入额外的可学习参数。

**Conclusion:** MEGANet-W通过有效利用小波驱动的边缘信息，成功解决了结直肠息肉分割中弱边界带来的挑战，显著提高了检测准确性且无需增加模型复杂性。

> **ai_Abstract:** 本文提出了一种名为MEGANet-W的小波驱动边缘引导注意力网络，旨在解决结直肠息肉分割中弱边界和低对比度问题导致的自动化精度受限。该网络通过将无参数的Haar小波边缘图注入解码器阶段，并引入小波边缘引导注意力（WEGA）模块来融合边缘信息，从而在不增加额外可学习参数的情况下，有效提升了息肉检测的准确性。实验结果表明，MEGANet-W在多个公共数据集上表现优异，mIoU和mDice均有显著提升。

> **摘要翻译:** 结直肠息肉分割对于结直肠癌的早期检测至关重要，但弱和低对比度边界严重限制了自动化准确性。现有的深度模型要么模糊精细的边缘细节，要么依赖在可变成像条件下表现不佳的手工滤波器。我们提出了MEGANet-W，一个小波驱动的边缘引导注意力网络，它将方向性、无参数的Haar小波边缘图注入到每个解码器阶段以重新校准语义特征。我们的两个主要贡献是：(1) 一个用于多方向边缘提取的两级Haar小波头部；以及 (2) 小波边缘引导注意力（WEGA）模块，将小波线索与反向和输入分支融合。在五个公共息肉数据集上，MEGANetW始终优于现有方法，mIoU提高了2.3%，mDice提高了1.2%，同时没有引入额外的可学习参数。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [28] [Pronunciation Editing for Finnish Speech using Phonetic Posteriorgrams](https://arxiv.org/abs/2507.02115)
> *使用语音后验图对芬兰语语音进行发音编辑*

*Zirui Li, Lauri Juvela, Mikko Kurimo* | **Category: eess.AS** | **Updated: {updated}**

**Keywords:** 语音编辑, 二语合成, 语音后验图, 扩散模型, 芬兰语

**Comment:** 5 pages; 1 figure; Accepted to Speech Synthesis Workshop 2025 (SSW13)

> **TL;DR:** 提出PPG2Speech模型，利用语音后验图编辑母语语音以模拟二语发音，解决低资源语言二语合成难题，并在芬兰语上验证了其有效性。

**AI_Comments:** 这篇论文提出了一种新颖的方法来解决低资源语言二语语音合成的难题，通过编辑母语语音而非从头合成，降低了对大量L2数据的需求。PPG2Speech模型结合了扩散模型和流匹配解码器，并引入了无分类器指导和Sway采样，这些技术组合具有创新性。此外，提出的PAC评估指标也为发音编辑效果的量化提供了一个新的视角。这项工作对于促进低资源语言的L2学习工具开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于缺乏二语语音合成数据集，为低资源语言合成二语语音非常困难，但二语语音合成对二语学习体验和反馈具有潜在高价值。

**Method:** 提出PPG2Speech模型，一个基于扩散的多说话人语音后验图到语音模型，能够不依赖文本对齐编辑单个音素。它以Matcha-TTS的流匹配解码器为骨干，将语音后验图转换为梅尔频谱图，并以外部说话人嵌入和音高为条件。PPG2Speech通过无分类器指导(CFG)和Sway采样增强了Matcha-TTS的解码器。同时，提出了一种新的任务特定客观评估指标——语音对齐一致性(PAC)，用于衡量编辑效果。

**Result:** 该方法在芬兰语上验证了其有效性，并对该方法进行了客观和主观评估，以比较其自然度、说话人相似性和编辑效果与基于TTS的编辑。

**Conclusion:** 本文提供了一种实用的解决方案，即PPG2Speech模型，用于编辑母语语音以近似二语语音，尤其适用于低资源语言，并在芬兰语上验证了其有效性。

> **ai_Abstract:** 本文针对低资源语言二语语音合成数据集缺乏的挑战，提出了一种实用的发音编辑方案PPG2Speech。该模型是一个基于扩散的多说话人语音后验图到语音模型，能够无需文本对齐地编辑单个音素。PPG2Speech基于Matcha-TTS的流匹配解码器，并结合了无分类器指导和Sway采样技术。为评估编辑效果，还引入了新的客观指标语音对齐一致性(PAC)。该方法在芬兰语上进行了验证，并通过客观和主观评估展现了其在自然度、说话人相似性和编辑效果方面的表现。

> **摘要翻译:** 合成第二语言（L2）语音对于L2语言学习体验和反馈具有潜在的极高价值。然而，由于缺乏L2语音合成数据集，为低资源语言合成L2语音非常困难。在本文中，我们提供了一种实用的解决方案，用于编辑母语语音以近似L2语音，并提出了PPG2Speech，一个基于扩散的多说话人语音后验图到语音模型，该模型能够在没有文本对齐的情况下编辑单个音素。我们使用Matcha-TTS的流匹配解码器作为骨干，将语音后验图（PPGs）转换为梅尔频谱图，并以外部说话人嵌入和音高为条件。PPG2Speech通过无分类器指导（CFG）和Sway采样增强了Matcha-TTS的流匹配解码器。我们还提出了一种新的任务特定客观评估指标——语音对齐一致性（PAC），用于衡量编辑后的PPG与从合成语音中提取的PPG之间的编辑效果。我们使用大约60小时的数据，在芬兰语这种低资源、近乎语音的语言上验证了我们方法的有效性。我们对我们的方法进行了客观和主观评估，以比较其自然度、说话人相似性和编辑效果与基于TTS的编辑。我们的源代码已发布在https://github.com/aalto-speech/PPG2Speech。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [57] [An Investigation on Combining Geometry and Consistency Constraints into Phase Estimation for Speech Enhancement](https://arxiv.org/abs/2507.02192)
> *将几何和一致性约束结合到语音增强的相位估计中的研究*

*Chun-Wei Ho, Pin-Jui Ku, Hao Yen, Sabato Marco Siniscalchi, Yu Tsao, Chin-Hui Lee* | **Category: eess.AS** | **Updated: {updated}**

**Keywords:** 相位估计, 语音增强, Griffin-Lim算法, 几何约束, 一致性约束

**Comment:** 5 pages

> **TL;DR:** 本文提出了一种结合几何和一致性约束的多源Griffin-Lim算法（MSGLA），用于语音增强，有效解决了相位估计中的符号模糊问题并提升了降噪性能。

**AI_Comments:** 这项研究的创新之处在于将几何和一致性约束有效地融合到相位估计算法中，特别是通过引入STFT谱图的一致性约束来解决基于几何方法的符号模糊难题，这是一个重要的进展。该方法在背景噪声抑制方面的优异表现，表明其在实际语音增强应用中具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决基于几何的相位估计中常见的符号模糊问题。

**Method:** 提出了一种名为多源Griffin-Lim算法（MSGLA）的迭代相位估计算法。该方法利用复值短时傅里叶变换（STFT）谱图的特设一致性约束来解决符号模糊问题，并引入了一种基于正弦和余弦定律的几何约束框架变体，使用噪声相位估计来重构相位。

**Result:** 通过一系列理想条件下的预言实验验证了其有效性。在VB-DMD和WSJ0-CHiME3数据集上的评估显示，所提出的MSGLA变体与现有算法（包括直接相位估计和基于DNN的符号预测）表现相当或略优，尤其在背景噪声抑制方面。

**Conclusion:** 提出的多源Griffin-Lim算法（MSGLA）通过结合几何和一致性约束，能够有效解决语音增强中相位估计的符号模糊问题，并在背景噪声抑制方面表现出色，优于或媲美现有技术。

> **ai_Abstract:** 本文提出了一种名为多源Griffin-Lim算法（MSGLA）的新型迭代相位估计框架，旨在解决加性噪声环境下语音增强中的相位估计问题。该方法巧妙地结合了几何约束与复值STFT谱图的一致性约束，以克服基于几何的相位估计中常见的符号模糊挑战。通过引入基于正弦和余弦定律的几何约束变体，并利用噪声相位估计进行相位重建，MSGLA在理想条件下展现出有效性。在标准数据集上的实验结果表明，MSGLA在背景噪声抑制方面表现突出，性能与现有先进算法相当或更优。

> **摘要翻译:** 我们提出了一种新颖的迭代相位估计框架，称为多源Griffin-Lim算法（MSGLA），用于加性噪声条件下的语音增强（SE）。其核心思想是利用复值短时傅里叶变换（STFT）谱图的特设一致性约束来解决基于几何的相位估计中常见的符号模糊挑战。此外，我们引入了一种基于正弦和余弦定律的几何约束框架变体，利用噪声相位估计制定了一种新的相位重建算法。我们首先通过一系列预言实验验证了所提出技术的有效性，证明了其在理想条件下的效果。然后，我们在VB-DMD和WSJ0-CHiME3数据集上评估了其性能，结果表明所提出的MSGLA变体与现有算法（包括直接相位估计和基于DNN的符号预测）表现相当或略优，尤其是在背景噪声抑制方面。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [81] [Open-Source System for Multilingual Translation and Cloned Speech Synthesis](https://arxiv.org/abs/2507.02530)
> *多语言翻译与克隆语音合成的开源系统*

*Mateo Cámara, Juan Gutiérrez, María Pilar Daza, José Luis Blanco* | **Category: eess.AS** | **Updated: {updated}**

**Keywords:** 多语言翻译, 语音合成, 语音克隆, 开源系统, 大型语言模型

**Comment:** Presented at Forum Acusticum Euronoise 2025

> **TL;DR:** 一个开源系统，结合语音识别、大型语言模型和语音克隆技术，实现多语言翻译和语音再生，旨在改善跨语言交流和可访问性。

**AI_Comments:** 该系统通过整合现有先进技术（如Whisper和LLMs）并加入语音克隆功能，提供了一个全面的开源解决方案，在多语言交流和可访问性方面具有重要意义。其创新之处在于将多种技术无缝整合到一个可部署的开源框架中，并强调了保持说话者身份的自然体验。这对于促进全球化交流和无障碍信息传播具有积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 解决不同语言环境下交流和可访问性面临的挑战，提供一个能进行多语言翻译和语音再生的系统。

**Method:** 该系统整合了Whisper进行语音识别和语音活动检测（VAD），接着使用大型语言模型（LLMs）管道：第一个LLM将语音分割成完整的句子，第二个LLM进行翻译。对于语音再生，系统利用带有语音克隆功能的文本转语音（TTS）模块来复制原始说话者的声音，同时保持自然度和说话者身份。

**Result:** 该开源系统能够实现多语言翻译和语音再生，并能保持说话者的声音，提供无缝沉浸式体验。它支持本地或通过API部署，具有成本效益，并适用于多种用例，如Zoom会议实时翻译、公共广播语音再生和蓝牙设备多语言播放。系统性能分析显示了其在实际多语言场景中实现包容性、适应性通信解决方案的潜力。

**Conclusion:** 该开源系统通过提供多语言翻译和克隆语音合成功能，有效解决了跨语言交流和可访问性问题，并通过社区共享促进创新，展示了在实际应用中实现包容性通信的巨大潜力。

> **ai_Abstract:** 本文介绍了一个开源系统，旨在解决多语言交流和可访问性挑战。该系统结合了Whisper语音识别、VAD、双大型语言模型（用于语音分割和翻译）以及带有语音克隆功能的文本转语音模块，实现多语言翻译和语音再生。系统能够保留说话者声音，提供自然沉浸式体验，并支持本地或API部署，适用于实时翻译、公共广播等多种场景。该项目已开源共享，并提供了性能分析，展示了其在实际多语言环境中实现包容性通信的潜力。

> **摘要翻译:** 我们提出了一个用于多语言翻译和语音再生的开源系统，旨在解决跨不同语言环境下的交流和可访问性挑战。该系统将Whisper与语音活动检测（VAD）集成，用于识别说话间隔，随后是一个大型语言模型（LLMs）管道。对于多语言应用，第一个LLM将语音分割成连贯完整的句子，然后由第二个LLM进行翻译。对于语音再生，系统使用一个带有语音克隆功能的文本转语音（TTS）模块来复制原始说话者的声音，保持自然度和说话者身份。该系统的开源组件可以本地运行或通过API调用，为各种用例提供了经济高效的部署方案。这些用例包括Zoom会议中的实时多语言翻译、公共广播的语音再生，以及通过个人设备实现蓝牙多语言播放。通过保留说话者的声音，该系统无论是进行翻译还是语音再生，都能确保无缝且沉浸式的体验。这个开源项目与社区共享，旨在促进创新和可访问性。我们提供了详细的系统性能分析，包括延迟和词准确率，展示了其在真实多语言场景中实现包容性、适应性通信解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [105] [Multi-Utterance Speech Separation and Association Trained on Short Segments](https://arxiv.org/abs/2507.02562)
> *多语段语音分离与关联：基于短片段训练*

*Yuzhu Wang, Archontis Politis, Konstantinos Drossos, Tuomas Virtanen* | **Category: eess.AS, cs.SD** | **Updated: {updated}**

**Keywords:** 语音分离, 多语段, 说话人关联, 循环神经网络, 长音频处理

**Comment:** 5 pages, accepted by WASPAA 2025

> **TL;DR:** 本文提出了一种频率-时间循环神经网络（FTRNN），用于解决深度神经网络语音分离在训练时使用短片段，但实际应用需要处理多语段长录音的挑战。FTRNN在处理远超训练长度的信号时表现出强大的分离能力，并能保持说话人关联，且无需传统的分段处理。

**AI_Comments:** 本文的创新点在于提出了FTRNN架构，能够有效解决语音分离领域中训练数据与实际应用场景不匹配的难题。其轻量级设计（0.9 M参数）和无需分段处理长音频的能力是其重要优势，这不仅简化了部署，还避免了传统方法中常见的边界失真问题。该研究对于提升语音分离模型在真实世界复杂环境下的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的深度神经网络（DNN）语音分离面临一个基本挑战：模型因计算限制需在短片段上训练，但实际应用通常需要处理比训练时更长的、包含每个说话人多个语段的录音。本文旨在解决这种训练与实际应用之间的差距。

**Method:** 本文提出了一种频率-时间循环神经网络（FTRNN）。该模型采用一个全频带模块来建模每个时间帧内的频率依赖性，以及一个子频带模块来建模每个频带内的时间模式。与传统的分段-分离-拼接范式不同，FTRNN是一种轻量级方法（0.9 M参数），可以在不进行分割的情况下对长音频进行推理，从而消除了分段边界失真。

**Result:** 尽管在10秒的短固定长度片段上进行训练，但FTRNN模型在处理明显长于训练片段（21-121秒）的信号时表现出稳健的分离能力，并能保持说话人跨语段间隔的关联性，其性能超越了训练时所见的间隔。实验结果证明了FTRNN在多语段语音分离和说话人关联方面的泛化能力。

**Conclusion:** FTRNN有效弥合了深度神经网络语音分离中训练与实际应用之间的差距，即模型在短片段上训练而需处理长录音的挑战。它在处理长音频和保持说话人关联方面表现出强大的泛化能力，且无需传统的分段处理，简化了部署并消除了边界失真。

> **ai_Abstract:** 本文针对深度神经网络语音分离中训练与实际应用之间存在的“短片段训练，长录音处理”的差距，提出了一种频率-时间循环神经网络（FTRNN）。该模型包含全频带和子频带模块，旨在有效处理多语段长音频。实验证明，尽管在短片段上训练，FTRNN在处理远超训练长度的信号时，能够实现稳健的语音分离并保持说话人关联，且无需传统的分段处理，简化了部署并避免了边界失真，展现了良好的泛化能力。

> **摘要翻译:** 当前基于深度神经网络（DNN）的语音分离面临一个基本挑战——模型因计算限制需要在短片段上训练，而实际应用通常需要处理明显更长的、每个说话人包含多个语段的录音，这与训练时的情况不同。在本文中，我们研究了现有方法在这种挑战性场景下的表现，并提出了一种频率-时间循环神经网络（FTRNN），有效地弥合了这一差距。我们的FTRNN采用一个全频带模块来建模每个时间帧内的频率依赖性，以及一个子频带模块来建模每个频带内的时间模式。尽管在10秒的短固定长度片段上进行训练，但我们的模型在处理明显长于训练片段（21-121秒）的信号时表现出稳健的分离能力，并能保持说话人跨语段间隔的关联性，其性能超越了训练时所见的间隔。与传统的分段-分离-拼接范式不同，我们的轻量级方法（0.9 M参数）在不进行分割的情况下对长音频进行推理，消除了分段边界失真，同时简化了部署。实验结果证明了FTRNN在多语段语音分离和说话人关联方面的泛化能力。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [130] [Multi-agent Auditory Scene Analysis](https://arxiv.org/abs/2507.02755)
> *多智能体听觉场景分析*

*Caleb Rascon, Luis Gato-Diaz, Eduardo García-Alarcón* | **Category: eess.AS, cs.AI** | **Updated: {updated}**

**Keywords:** 多智能体系统, 听觉场景分析, 并行处理, 反馈循环, 实时性

**Comment:** Submitted to Applied Intelligence

> **TL;DR:** 本文提出了一种多智能体听觉场景分析（MASA）方法，通过并行处理任务和引入反馈机制，解决了传统线性ASA系统响应时间长、对误差敏感的问题，实现了低延迟和高鲁棒性。

**AI_Comments:** 本文的创新点在于提出了一个多智能体框架来并行处理听觉场景分析任务，并通过反馈机制提高系统的鲁棒性，有效解决了传统线性处理流程中存在的响应时间长和误差传递问题。这种并行和反馈的设计思路对于实时性要求高的应用场景具有重要意义。其开源工具的使用也降低了研究和开发的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 传统的听觉场景分析（ASA）任务（定位、分离、分类）以线性数据流执行，导致整体响应时间增加，且后续任务（分离和分类）对初始定位任务的误差高度敏感。现有技术虽然致力于减少误差，但会增加计算复杂性，使得ASA系统在生物声学、助听器设计、搜救和人机交互等需要小计算量和低响应时间的应用中不可行。

**Method:** 本文提出了一种多智能体方法来执行听觉场景分析（ASA）。该方法使任务并行运行，并在任务之间引入反馈循环以补偿局部误差。例如，利用分离输出的质量来纠正定位误差，并利用分类结果来降低定位对干扰的敏感性。该系统使用开源工具（JACK和ROS2）进行声音采集、再现和智能体间通信，并允许用户添加自己的智能体。

**Result:** 结果是一个多智能体听觉场景分析（MASA）系统，它对局部误差具有鲁棒性，没有显著增加复杂性，并且响应时间低。

**Conclusion:** 本文提出的多智能体听觉场景分析（MASA）系统通过并行任务和反馈循环，有效解决了传统ASA的响应时间长和误差敏感性问题，实现了鲁棒、低延迟且计算复杂度适中的性能，适用于对计算资源和响应时间有严格要求的应用。

> **ai_Abstract:** 本文提出了一种名为多智能体听觉场景分析（MASA）的新方法，旨在解决传统听觉场景分析（ASA）中任务线性执行导致的响应时间长和误差敏感性问题。MASA系统通过让声源定位、分离和分类等任务并行运行，并引入任务间的反馈循环来校正局部误差，例如利用分离质量修正定位错误，以及用分类结果降低定位对干扰的敏感性。实验结果表明，MASA系统在不显著增加复杂性的前提下，实现了对局部误差的鲁棒性和低响应时间。该系统还提供了一个基于开源工具的框架，方便用户扩展。

> **摘要翻译:** 听觉场景分析（ASA）旨在通过执行三项主要任务：声源定位、分离和分类，从声学环境中检索信息。这些任务传统上以线性数据流执行，首先定位声源；然后，利用其位置，将每个声源分离成自己的音频流；再从每个音频流中提取与应用场景相关的信息（音频事件检测、说话人识别、情感分类等）。然而，线性运行这些任务会增加整体响应时间，同时使后续任务（分离和分类）对首个任务（定位）的误差高度敏感。最先进的技术投入了大量的精力和计算复杂性来开发尽可能减少误差的技术。然而，这样做会导致ASA系统在许多需要小计算量和低响应时间的应用中不可行，例如生物声学、助听器设计、搜救、人机交互等。为此，本工作提出了一种多智能体方法来执行ASA，其中任务并行运行，并引入了它们之间的反馈循环以补偿局部误差，例如：使用分离输出的质量来纠正定位误差；以及使用分类结果来降低定位对干扰的敏感性。结果是一个多智能体听觉场景分析（MASA）系统，它对局部误差具有鲁棒性，没有显著增加复杂性，并且响应时间低。所提出的完整MASA系统作为一个框架提供，该框架使用开源工具进行声音采集和再现（JACK）以及智能体间通信（ROS2），允许用户添加自己的智能体。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [151] [DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment](https://arxiv.org/abs/2507.02768)
> *DeSTA2.5-Audio：迈向通用型大型音频语言模型与自生成跨模态对齐*

*Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Sung-Feng Huang, Chih-Kai Yang, Chee-En Yu, Chun-Wei Chen, Wei-Chih Chen, Chien-yu Huang, Yi-Cheng Lin, Yu-Xiang Lin, Chi-An Fu, Chun-Yi Kuan, Wenze Ren, Xuanjun Chen, Wei-Ping Huang, En-Pei Hu, Tzu-Quan Lin, Yuan-Kuei Wu, Kuan-Po Huang, Hsiao-Ying Huang, Huang-Cheng Chou, Kai-Wei Chang, Cheng-Han Chiang, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee* | **Category: eess.AS, cs.CL, cs.SD** | **Updated: {updated}**

**Keywords:** 大型音频语言模型, 跨模态对齐, 自生成数据, 零样本泛化, 灾难性遗忘

**Comment:** Model and code available at:
  https://github.com/kehanlu/DeSTA2.5-Audio

> **TL;DR:** DeSTA2.5-Audio 是一种新的通用型大型音频语言模型 (LALM)，它通过引入自生成跨模态对齐策略 (DeSTA) 来解决现有 LALM 中灾难性遗忘的问题，实现了零样本泛化，并在多个音频语言基准测试中取得了最先进的性能。

**AI_Comments:** 该论文的主要创新在于其“自生成跨模态对齐策略”（DeSTA），它有效地缓解了灾难性遗忘问题，并实现了零样本泛化，这相对于依赖外部或合成数据集且常导致语言能力下降的现有LALM而言，是一个显著的进步。利用该策略构建大规模、多样化、任务无关的数据集（DeSTA-AQA5M）也是一项重要的贡献。这项工作强调了数据构建在开发鲁棒LALM中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LALMs在训练过程中，往往会遭受其基础大型语言模型（LLM）原始语言能力的灾难性遗忘，并且通常需要任务特定的音频指令微调。

**Method:** 本研究提出了DeSTA，一种自生成跨模态对齐策略，其中骨干LLM生成自己的训练目标，从而在建立有效音频-文本对齐的同时，保留了LLM的原生语言能力。基于DeSTA，构建了大规模、任务无关的DeSTA-AQA5M数据集，包含500万个训练样本，来源于7000小时的音频，涵盖50个不同数据集。

**Result:** DeSTA2.5-Audio 在Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench等广泛的音频-语言基准测试中取得了最先进或具有竞争力的性能。全面的比较研究表明，其自生成策略在听觉感知和指令遵循能力方面均优于广泛采用的数据构建和训练策略。

**Conclusion:** 精心设计的数据构建在LALM开发中至关重要，并为构建强大、通用型LALM提供了实用见解。

> **ai_Abstract:** DeSTA2.5-Audio 是一种新型的通用型大型音频语言模型 (LALM)，它通过引入 DeSTA（一种自生成跨模态对齐策略）解决了现有 LALM 中大型语言模型 (LLM) 语言能力灾难性遗忘的问题。该方法允许骨干 LLM 生成自己的训练目标，从而在实现鲁棒的音频-文本对齐和零样本泛化能力的同时，保留其原有的语言熟练度。研究人员利用 DeSTA 构建了大规模、多样化的任务无关数据集 DeSTA-AQA5M。DeSTA2.5-Audio 在多项音频-语言基准测试中取得了最先进的性能，证明了其数据构建方法的有效性。

> **摘要翻译:** 我们介绍了 DeSTA2.5-Audio，这是一种通用型大型音频语言模型 (LALM)，旨在实现强大的听觉感知和指令遵循能力，无需进行任务特定的音频指令微调。最近的 LALM 通常通过在大型、手动整理或 LLM 合成的音频指令数据集上进行训练，来增强大型语言模型 (LLM) 的听觉能力。然而，这些方法常常遭受 LLM 原始语言能力的灾难性遗忘。为了解决这个问题，我们重新审视了数据构建流程，并提出了 DeSTA，这是一种自生成跨模态对齐策略，其中骨干 LLM 生成自己的训练目标。这种方法在建立有效的音频-文本对齐的同时，保留了 LLM 的原生语言能力，从而实现了无需任务特定微调的零样本泛化。我们使用 DeSTA 构建了 DeSTA-AQA5M，这是一个大规模、任务无关的数据集，包含 500 万个训练样本，这些样本来源于 7,000 小时的音频，涵盖 50 个不同的数据集，包括语音、环境声音和音乐。DeSTA2.5-Audio 在广泛的音频-语言基准测试中取得了最先进或具有竞争力的性能，包括 Dynamic-SUPERB、MMAU、SAKURA、Speech-IFEval 和 VoiceBench。全面的比较研究表明，我们的自生成策略在听觉感知和指令遵循能力方面均优于广泛采用的数据构建和训练策略。我们的研究结果强调了精心设计的数据构建在 LALM 开发中的重要性，并为构建强大、通用型 LALM 提供了实用见解。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [172] [Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient Extraction of Moving Speakers under Weak Guidance](https://arxiv.org/abs/2507.02791)
> *弱引导下用于移动说话人高效提取的自引导深度非线性空间选择滤波器*

*Jakob Kienegger, Alina Mannanova, Huajian Fang, Timo Gerkmann* | **Category: eess.AS, cs.LG, cs.SD** | **Updated: {updated}**

**Keywords:** 深度非线性滤波器, 空间选择滤波器, 移动说话人, 粒子滤波器, 语音增强

**Comment:** Accepted at IEEE Workshop on Applications of Signal Processing to
  Audio and Acoustics (WASPAA) 2025

> **TL;DR:** 本文提出了一种结合粒子滤波器和时间反馈的自引导深度非线性空间选择滤波器，以在资源受限的动态场景中高效提取移动说话人，并在合成数据集和真实录音上验证了其出色的跟踪精度和增强性能。

**AI_Comments:** 这项工作在语音增强领域具有重要意义，特别是在处理动态场景和资源受限环境下的移动说话人。其创新点在于将低复杂度的粒子滤波器与时间反馈相结合，实现了滤波器与跟踪算法之间的自回归交互，有效解决了传统方法计算开销大的问题。该方法的“自引导”特性使其在实际应用中更具鲁棒性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度非线性空间选择滤波器在已知方向的静止说话人方面表现出色，但在动态场景中需要资源密集型数据驱动跟踪算法提供精确的空间引导，这增加了计算开销，阻碍了在资源受限场景（如实时语音增强）中的应用。

**Method:** 提出了一种新颖的策略，利用低复杂度的粒子滤波器进行跟踪。假设采用因果、顺序处理方式，引入了时间反馈机制，利用空间选择滤波器增强的语音信号来补偿粒子滤波器的有限建模能力，实现两种算法之间的自回归相互作用。

**Result:** 在合成数据集上的评估表明，两种算法之间的自回归相互作用显著提高了跟踪精度，并带来了强大的增强性能。对真实世界录音的听力测试补充了这些发现，表明所提出的自引导管道比同类方法更受青睐。

**Conclusion:** 所提出的自引导深度非线性空间选择滤波器结合低复杂度粒子滤波器和时间反馈，能够有效且高效地在动态场景中提取移动说话人，优于现有方法。

> **ai_Abstract:** 本文提出了一种自引导深度非线性空间选择滤波器，旨在解决在资源受限的动态场景中高效提取移动说话人的挑战。该方法采用低复杂度的粒子滤波器进行目标跟踪，并引入时间反馈机制，利用增强的语音信号来弥补粒子滤波器的局限性。通过合成数据集和真实世界录音的评估，结果显示该方法显著提升了跟踪精度和语音增强性能，并且在听力测试中优于现有可比较的方法。

> **摘要翻译:** 最近关于深度非线性空间选择滤波器的工作表明，对于已知方向的静止说话人，其计算量轻的架构能够实现卓越的增强性能。然而，为了在动态场景中保持这种性能，需要资源密集型的数据驱动跟踪算法来提供以目标说话人初始方向为条件的精确空间引导。由于这种额外的计算开销阻碍了在资源受限场景（如实时语音增强）中的应用，我们提出了一种利用粒子滤波器形式的低复杂度跟踪算法的新颖策略。假设采用因果、顺序处理方式，我们引入了时间反馈，以利用空间选择滤波器增强的语音信号来补偿粒子滤波器的有限建模能力。对合成数据集的评估说明了两种算法之间的自回归相互作用如何显著提高跟踪精度并带来强大的增强性能。对真实世界录音的听力测试补充了这些发现，表明我们提出的自引导管道作为优于同类方法的首选，表现出明显的趋势。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [190] [Towards Perception-Informed Latent HRTF Representations](https://arxiv.org/abs/2507.02815)
> *面向感知信息的潜在HRTF表示*

*You Zhang, Andrew Francl, Ruohan Gao, Paul Calamia, Zhiyao Duan, Ishwarya Ananthabhotla* | **Category: eess.AS, cs.SD** | **Updated: {updated}**

**Keywords:** HRTF个性化, 潜在表示, 感知兼容性, 空间音频, 机器学习

**Comment:** Accepted by IEEE WASPAA 2025, camera-ready version

> **TL;DR:** 本文研究了现有HRTF潜在表示与感知兼容性的不足，并提出了一种利用度量损失函数和MMDS将HRTF嵌入到感知信息潜在空间的方法，以改善个性化空间音频体验。

**AI_Comments:** 这篇论文的创新点在于提出了一个“感知信息”的潜在空间学习方法，解决了传统HRTF表示在感知兼容性上的局限。通过引入感知度量损失和MMDS监督，使得学习到的表示能够更好地对齐人类听觉感知，这对于提升个性化空间音频的真实感和沉浸感具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 个性化头相关传输函数（HRTF）对于耳机中逼真的听觉体验至关重要。然而，大多数机器学习方法在学习HRTF潜在表示时，优化的是频谱重建而非感知兼容性，导致这些表示可能与感知距离不符。

**Method:** 本文首先使用基于听觉的客观感知指标研究了传统学习的HRTF表示是否与感知关系良好相关。然后，提出了一种通过利用基于度量的损失函数和通过度量多维尺度（MMDS）进行监督，将HRTF显式嵌入到感知信息潜在空间的方法。

**Result:** 本文证明了这些学习到的表示在HRTF个性化任务中的适用性。

**Conclusion:** 该方法有潜力实现个性化空间音频，从而改善听觉体验。

> **ai_Abstract:** 本文探讨了现有HRTF潜在表示在感知兼容性方面的不足，指出它们通常优化频谱重建而非感知距离。研究首先评估了传统HRTF表示与感知关系的相关性，随后提出了一种新方法，通过利用度量损失函数和度量多维尺度（MMDS）将HRTF嵌入到感知信息潜在空间。该方法被证明适用于HRTF个性化，并有望提升个性化空间音频的听觉体验。

> **摘要翻译:** 个性化头相关传输函数（HRTF）对于确保通过耳机获得逼真的听觉体验至关重要，因为它们考虑了影响听力的个体解剖差异。大多数用于HRTF个性化的机器学习方法依赖于学习到的低维潜在空间来为听众生成或选择定制的HRTF。然而，这些潜在表示通常以优化频谱重建而非感知兼容性的方式学习，这意味着它们不一定与感知距离对齐。在这项工作中，我们首先使用基于听觉的客观感知指标研究了传统学习的HRTF表示是否与感知关系良好相关；然后，我们提出了一种将HRTF显式嵌入到感知信息潜在空间的方法，该方法利用了基于度量的损失函数并通过度量多维尺度（MMDS）进行监督。最后，我们展示了这些学习到的表示在HRTF个性化任务中的适用性。我们认为我们的方法有潜力实现个性化的空间音频，从而带来改进的听觉体验。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [31] [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2507.02088)
> *McBE：一个用于大型语言模型的多任务中文偏见评估基准*

*Tian Lan, Xiangdong Su, Xu Liu, Ruirui Wang, Ke Chang, Jiang Li, Guanglai Gao* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 大型语言模型, 偏见评估, 中文, 多任务, 基准

**Comment:** 24 pages, 9 figures

> **TL;DR:** 本文提出了McBE，一个多任务中文偏见评估基准，用于解决现有大型语言模型偏见评估数据集的不足，并发现现有LLM普遍存在不同程度的偏见。

**AI_Comments:** 这项工作通过构建一个多任务的中文偏见评估基准McBE，填补了现有LLM偏见评估领域在中文和多任务方面的空白，具有重要的创新性和实用价值。它不仅提供了丰富的数据集和多维度的评估方法，还通过对流行LLM的评估揭示了其偏见现状，为未来偏见缓解研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在各种自然语言处理任务中的应用日益广泛，其固有的偏见逐渐显现。衡量LLMs中的偏见对于减轻其伦理风险至关重要。然而，现有的大多数偏见评估数据集侧重于英语和北美文化，其偏见类别不完全适用于其他文化，且中文和中国文化相关的数据集稀缺。更重要的是，这些数据集通常只支持单一评估任务，无法从多个方面评估LLMs中的偏见。

**Method:** 为了解决上述问题，我们提出了一个多任务中文偏见评估基准（McBE），该基准包含4,077个偏见评估实例，涵盖12个单一偏见类别、82个子类别，并引入了5个评估任务，提供了广泛的类别覆盖、内容多样性和衡量全面性。此外，我们评估了多个不同系列和参数规模的流行LLMs。

**Result:** 总的来说，所有这些LLMs都表现出不同程度的偏见。

**Conclusion:** 我们对结果进行了深入分析，为LLMs中的偏见提供了新的见解。

> **ai_Abstract:** 本文提出了McBE（多任务中文偏见评估基准），旨在解决现有LLM偏见评估数据集在中文语境下缺乏、任务单一的问题。McBE包含4,077个实例，涵盖12个偏见类别和82个子类别，并支持5种评估任务，实现了广泛的覆盖和多样性。研究人员使用McBE评估了多种流行LLM，发现它们普遍存在不同程度的偏见，并提供了深入的分析和新颖的见解。

> **摘要翻译:** 随着大型语言模型（LLMs）在各种自然语言处理任务中的应用日益广泛，其固有的偏见逐渐显现。因此，衡量LLMs中的偏见对于减轻其伦理风险至关重要。然而，现有的大多数偏见评估数据集侧重于英语和北美文化，其偏见类别不完全适用于其他文化。中文和中国文化相关的数据集稀缺。更重要的是，这些数据集通常只支持单一评估任务，无法从多个方面评估LLMs中的偏见。为了解决这些问题，我们提出了一个多任务中文偏见评估基准（McBE），该基准包含4,077个偏见评估实例，涵盖12个单一偏见类别、82个子类别，并引入了5个评估任务，提供了广泛的类别覆盖、内容多样性和衡量全面性。此外，我们评估了多个不同系列和参数规模的流行LLMs。总的来说，所有这些LLMs都表现出不同程度的偏见。我们对结果进行了深入分析，为LLMs中的偏见提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [59] [Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization](https://arxiv.org/abs/2507.02145)
> *推理与否？对用于对话摘要的推理LLM的全面评估*

*Keyan Jin, Yapeng Wang, Leonel Santos, Tao Fang, Xu Yang, Sio Kei Im, Hugo Gonçalo Oliveira* | **Category: cs.CL, cs.AI** | **Updated: {updated}**

**Keywords:** 对话摘要, 推理LLM, 链式思考, 性能评估, 局限性

**Comment:** 

> **TL;DR:** 本研究首次全面评估了推理LLM在对话摘要任务中的表现，发现与预期相反，明确的逐步推理并不能持续提高对话摘要质量，反而可能导致冗长和不一致。

**AI_Comments:** 这项研究具有重要意义，因为它挑战了当前普遍认为“推理能力越强越好”的LLM发展趋势。它揭示了在特定任务（如对话摘要）中，盲目应用链式思考等推理方法可能适得其反。这对于LLM的实际应用和未来架构设计提供了宝贵的反思和指导，尤其是在追求简洁和一致性方面。

<details>
  <summary>Details</summary>

**Motivation:** 对话摘要在客户服务、会议分析和对话式AI中具有重要的实际价值，尽管大型语言模型（LLMs）在摘要任务中取得了显著进展，但针对需要并发抽象和简洁性的对话场景，逐步推理架构（如长链思维CoT）的性能仍未被探索。

**Method:** 本研究首次对最先进的推理LLMs和非推理LLMs在三种主要范式（通用、面向角色和面向查询的对话摘要）下进行了全面系统的评估。研究涵盖了不同的语言、领域和摘要长度，利用了强大的基准（SAMSum, DialogSum, CSDS, 和 QMSum）和先进的评估协议，包括基于LLM的自动指标和受人类启发标准。

**Result:** 研究发现，与在其他推理密集型任务中的趋势相反，明确的逐步推理并不能持续提高对话摘要质量。相反，与非推理LLMs相比，推理LLMs往往更容易冗长、事实不一致且摘要不够简洁。通过特定场景分析和详细案例研究，进一步确定了明确推理何时以及为何在复杂对话语境中未能受益甚至阻碍摘要。

**Conclusion:** 本研究为当前推理LLMs的局限性提供了新见解，并强调了在真实世界对话摘要中需要有针对性的建模和评估策略。

> **ai_Abstract:** 本研究首次对推理型大型语言模型（LLMs）在对话摘要任务中的表现进行了全面评估。研究发现，与在其他推理任务中的表现不同，明确的逐步推理（如CoT）并未能持续提升对话摘要的质量，反而常导致冗长和事实不一致。文章通过多语言、多领域和多种范式的实验，揭示了当前推理LLMs在复杂对话语境下的局限性，并强调了未来研究需针对性地开发和评估模型。

> **摘要翻译:** 对话摘要是一项具有挑战性的任务，在客户服务、会议分析和对话式AI中具有重要的实际价值。尽管大型语言模型（LLMs）在摘要任务中取得了显著进展，但针对需要并发抽象和简洁性的对话场景，逐步推理架构（特别是OpenAI-o1和DeepSeek-R1等长链思维（CoT）实现）的性能仍未被探索。在这项工作中，我们首次对最先进的推理LLMs和非推理LLMs在三种主要范式——通用、面向角色和面向查询的对话摘要——下进行了全面系统的评估。我们的研究涵盖了不同的语言、领域和摘要长度，利用了强大的基准（SAMSum、DialogSum、CSDS和QMSum）和先进的评估协议，包括基于LLM的自动指标和受人类启发标准。与在其他推理密集型任务中的趋势相反，我们的研究结果表明，明确的逐步推理并不能持续提高对话摘要质量。相反，与非推理LLMs相比，推理LLMs往往更容易冗长、事实不一致且摘要不够简洁。通过特定场景分析和详细案例研究，我们进一步确定了明确推理何时以及为何未能受益——甚至阻碍——复杂对话语境中的摘要。我们的工作为当前推理LLMs的局限性提供了新见解，并强调了在真实世界对话摘要中需要有针对性的建模和评估策略。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [83] [Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer](https://arxiv.org/abs/2507.02199)
> *潜在思维链？解码深度循环Transformer*

*Wenquan Lu, Yuechuan Yang, Kyle Lee, Yanshu Li, Enqi Liu* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 潜在思维链, 深度循环Transformer, 模型可解释性, 推理, Huginn-3.5B

**Comment:** 

> **TL;DR:** 研究发现，深度循环Transformer中的潜在思维链证据有限，且效果远不如显式思维链。

**AI_Comments:** 这篇论文对深度循环Transformer中潜在思维链的有效性及其可解释性提出了质疑。其创新点在于使用特定的探测技术（Logit Lens, Coda Lens）来深入分析模型内部行为。研究结果强调了在内部化推理方面所面临的挑战，并指出目前显式思维链在性能上仍具有显著优势，对未来潜在推理架构的设计提供了重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Transformer模型中的思维链推理是外部化的，提高了可解释性但牺牲了效率。许多工作探索了旨在将推理内部化到潜在空间中的循环架构，可能支持潜在思维链。本文旨在探究这种推理结构是否在深度循环Transformer中出现。

**Method:** 使用深度循环Transformer Huginn-3.5B，通过Logit Lens和Coda Lens等探测技术，在算术任务上检查模型的内部行为。

**Result:** 通过跟踪最终和中间结果token的秩轨迹，揭示了可解释的潜在思维链的有限证据。在循环块中发现了显著的探测不一致性，隐藏状态的可解释性严重依赖于层索引和解码方法。增加循环深度仅带来微小的收益，远低于明确外部化推理步骤的模型。

**Conclusion:** 深度循环Transformer中的潜在思维链的证据有限，且其表现远不如明确外部化推理步骤的模型。

> **ai_Abstract:** 本文研究了深度循环Transformer Huginn-3.5B中潜在思维链（CoT）推理的出现情况。通过在算术任务上使用Logit Lens和Coda Lens等探测技术，研究发现可解释的潜在CoT证据有限，且隐藏状态的可解释性存在不一致。实验结果表明，增加循环深度带来的收益微乎其微，远不如显式外部化推理步骤的模型。

> **摘要翻译:** 思维链（CoT）推理使基于Transformer的语言模型在复杂数学和多步规划方面表现出色。然而，在标准的仅解码器架构中，这些推理步骤以自然语言形式外部化，提高了可解释性但牺牲了效率。为了捕获不易用语言表示的推理，许多工作探索了旨在将推理内部化到潜在空间中的循环架构，可能支持潜在CoT。在本文中，我们研究了这种推理结构是否出现在Huginn-3.5B中，这是一种深度循环Transformer，它在推理时重用层而不增加参数数量。我们使用包括Logit Lens和Coda Lens在内的一系列探测技术，在算术任务上检查模型的内部行为。我们的发现通过跟踪最终和中间结果token的秩轨迹，揭示了可解释潜在CoT的有限证据。此外，我们发现循环块之间存在显著的探测不一致性，其中隐藏状态的可解释性严重依赖于层索引和解码方法。最后，我们凭经验表明，增加循环深度仅带来微小的收益，并且远低于明确外部化推理步骤的模型。代码可在https://github.com/wenquanlu/huginn-latent-cot 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [107] [GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons](https://arxiv.org/abs/2507.02221)
> *GDC队列副驾驶：一个用于从基因组数据中心策划队列的AI副驾驶*

*Steven Song, Anirudh Subramanyam, Zhenyu Zhang, Aarti Venkat, Robert L. Grossman* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** GDC, 队列策划, AI副驾驶, 大型语言模型, 癌症基因组学

**Comment:** 11 pages, 1 figure, 7 tables

> **TL;DR:** GDC队列副驾驶是一个AI工具，它允许用户通过自然语言描述来生成GDC队列过滤器，从而简化从基因组数据中心（GDC）策划患者队列的过程。

**AI_Comments:** 这项工作通过引入一个基于自然语言处理的AI副驾驶工具，显著提升了GDC用户策划复杂患者队列的效率和易用性。其创新之处在于将LLM应用于基因组数据查询，并证明了领域特定、本地部署的LLM在特定任务上可以超越通用大型模型，这对于数据隐私和成本效益具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基因组数据中心（GDC）通过统一的策划和分析平台提供高质量、协调的癌症基因组数据。尽管GDC用户可以通过图形化队列构建器交互式创建复杂的队列，但用户（尤其是新用户）可能难以在数百个可能的字段和属性中找到特定的队列描述符。然而，用户可能能够更好地用自由文本自然语言描述他们所需的队列。

**Method:** 本文介绍了GDC队列副驾驶，一个开源的副驾驶工具，用于从GDC策划队列。GDC队列副驾驶自动生成与用户输入的自然语言描述对应的GDC队列过滤器，然后将队列导出回GDC进行进一步分析。交互式用户界面允许用户进一步优化生成的队列。研究人员开发并评估了多个大型语言模型（LLM），并证明其本地部署的开源GDC队列LLM在生成GDC队列方面取得了比GPT-4o提示更好的结果。

**Result:** GDC队列副驾驶能够根据用户输入的自然语言描述自动生成GDC队列过滤器。本地部署的开源GDC队列LLM在生成GDC队列方面比GPT-4o提示取得了更好的结果。

**Conclusion:** GDC队列副驾驶显著简化了GDC中患者队列的策划过程，通过允许用户使用自然语言描述来创建和优化队列，并且其定制的LLM表现优于通用大型模型。

> **ai_Abstract:** GDC队列副驾驶是一款开源AI工具，旨在简化从基因组数据中心（GDC）策划患者队列的过程。它通过允许用户使用自然语言描述来自动生成相应的GDC队列过滤器，并提供交互式界面进行优化。研究表明，该工具定制的本地部署大型语言模型（GDC Cohort LLM）在生成GDC队列方面表现优于GPT-4o。

> **摘要翻译:** 动机：基因组数据中心（GDC）通过一个以患者队列为中心的统一策划和分析平台，提供高质量、协调的癌症基因组数据。虽然GDC用户可以通过图形化队列构建器交互式创建复杂的队列，但用户（尤其是新用户）可能难以在数百个可能的字段和属性中找到特定的队列描述符。然而，用户可能能够更好地用自由文本自然语言描述他们所需的队列。
结果：我们介绍了GDC队列副驾驶，一个用于从GDC策划队列的开源副驾驶工具。GDC队列副驾驶自动生成与用户输入的自然语言描述对应的GDC队列过滤器，然后将队列导出回GDC进行进一步分析。一个交互式用户界面允许用户进一步优化生成的队列。我们为GDC队列副驾驶开发并评估了多个大型语言模型（LLM），并证明我们本地部署的开源GDC队列LLM在生成GDC队列方面取得了比GPT-4o提示更好的结果。
可用性和实现：GDC队列副驾驶的独立docker镜像可在https://quay.io/repository/cdis/gdc-cohort-copilot获取。源代码可在https://github.com/uc-cdis/gdc-cohort-copilot获取。GDC队列LLM权重可在https://huggingface.co/uc-ctds获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [132] [MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent](https://arxiv.org/abs/2507.02259)
> *MemAgent：基于多对话RL的记忆代理重塑长上下文LLM*

*Hongli Yu, Tinghong Chen, Jiangtao Feng, Jiangjie Chen, Weinan Dai, Qiying Yu, Ya-Qin Zhang, Wei-Ying Ma, Jingjing Liu, Mingxuan Wang, Hao Zhou* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 长上下文LLM, 记忆代理, 强化学习, 文本处理, 外推

**Comment:** Project Page: https://memagent-sialab.github.io/

> **TL;DR:** MemAgent引入了一种基于RL的记忆代理工作流，通过分段阅读和覆盖式更新记忆，有效处理超长文本，并在3.5M QA任务和512K RULER测试中表现出色，性能损失极小。

**AI_Comments:** MemAgent的创新之处在于其独特的基于RL的记忆代理工作流和对DAPO算法的扩展，这使得LLM能够以极低的性能损失处理前所未有的超长文本。这项工作对于需要处理大量信息的应用（如法律文档分析、长篇报告摘要等）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管长文本处理在长度外推、高效注意力机制和记忆模块方面有所改进，但以线性复杂度处理无限长文档且在推断过程中不发生性能下降，仍然是该领域的终极挑战。

**Method:** 本文直接以端到端的方式优化长文本任务，并引入了一种名为MemAgent的新型代理工作流。MemAgent通过分段阅读文本并使用覆盖策略更新记忆。此外，作者扩展了DAPO算法，通过独立上下文的多对话生成来促进训练。

**Result:** MemAgent展示了卓越的长上下文处理能力，能够从8K上下文（在32K文本上训练）外推到3.5M的问答任务，性能损失小于5%，并在512K RULER测试中达到95%以上的准确率。

**Conclusion:** MemAgent通过其创新的记忆代理工作流和优化的训练方法，有效解决了大型语言模型在处理极长文本时的性能下降问题，展现出强大的长上下文外推能力。

> **ai_Abstract:** MemAgent是一种新型的基于强化学习的记忆代理，旨在解决长上下文大型语言模型处理超长文本时的性能下降问题。该方法通过分段阅读和覆盖式记忆更新来优化长文本任务，并扩展了DAPO算法进行多对话训练。实验结果表明，MemAgent能够从较短上下文外推到数百万tokens的任务，并在保持高准确率的同时显著降低性能损失。

> **摘要翻译:** 尽管通过长度外推、高效注意力机制和记忆模块取得了改进，但在长文本处理中，以线性复杂度处理无限长文档且在推断过程中不发生性能下降，仍然是最终的挑战。我们以端到端的方式直接优化长文本任务，并引入了一种新颖的代理工作流MemAgent，它分段阅读文本并使用覆盖策略更新记忆。我们扩展了DAPO算法，通过独立上下文的多对话生成来促进训练。MemAgent展示了卓越的长上下文能力，能够从在32K文本上训练的8K上下文外推到3.5M的问答任务，性能损失小于5%，并在512K RULER测试中达到95%以上。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [153] [DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning](https://arxiv.org/abs/2507.02302)
> *DoMIX：一种在微调中利用领域知识的有效框架*

*Dohoon Kim, Donghun Kang, Taesup Moon* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: {updated}**

**Keywords:** 领域自适应预训练, LoRA, 微调, 参数高效微调, 持续学习

**Comment:** 22 pages, 5 figures, ACL 2025 Main

> **TL;DR:** DoMIX利用LoRA使领域自适应预训练更高效、更鲁棒、更具任务特异性，解决了现有方法的局限性。

**AI_Comments:** 这项工作的创新之处在于利用LoRA模块克服了持续DAP的实际限制，使其更高效、更具适应性。能够为特定任务提供量身定制的模型以及其超越DAP应用于通用LLM微调的能力是重要的贡献。这项工作提高了大型模型领域适应的实用性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的持续领域自适应预训练（DAP）方法存在高计算成本和GPU内存使用量、对增量数据顺序敏感以及为所有最终任务提供单一通用模型等局限性，这与DAP的本质相矛盾。

**Method:** 本文提出了DoMIX，这是一种利用LoRA模块（一种参数高效微调（PEFT）方法）的新方法。DoMIX旨在实现高效并行、对领域顺序鲁棒的领域自适应预训练，并有效利用累积知识为特定任务提供量身定制的预训练模型。

**Result:** DoMIX实现了高效并行的领域自适应预训练，对领域顺序具有鲁棒性，并能有效利用累积知识为特定任务提供量身定制的预训练模型。此外，该方法可以扩展到标准的大型语言模型（LLM）微调场景。

**Conclusion:** DoMIX成功解决了现有持续DAP方法的局限性，通过提供一个高效、鲁棒且任务特定的框架来利用微调中的领域知识，适用于DAP和LLM微调场景。

> **ai_Abstract:** DoMIX旨在解决现有持续领域自适应预训练（DAP）方法的局限性，例如高成本、数据顺序敏感性和缺乏任务特定模型。通过利用LoRA模块，DoMIX实现了高效、并行且鲁棒的领域自适应预训练。它有效利用累积知识为特定任务提供量身定制的预训练模型，并且可以应用于标准的大型语言模型（LLM）微调场景。

> **摘要翻译:** 领域自适应预训练 (DAP) 近来因其在微调预训练模型方面的有效性而受到关注。在此基础上，持续DAP已被探索用于开发能够逐步整合不同领域数据集的预训练模型。然而，现有的持续DAP方法面临几个局限性：（1）训练期间计算成本和GPU内存使用量高；（2）对增量数据顺序敏感；（3）为所有最终任务提供单一的通用模型，这与DAP的本质相矛盾。在本文中，我们提出了DoMIX，这是一种通过利用LoRA模块（一种代表性的参数高效微调（PEFT）方法）来解决这些挑战的新方法。我们的方法实现了高效并行的领域自适应预训练，该训练对领域顺序具有鲁棒性，并有效利用累积知识为特定任务提供量身定制的预训练模型。我们还证明了我们的方法可以扩展到DAP设置之外的标准LLM微调场景。代码可在 https://github.com/dohoonkim-ai/DoMIX 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [174] [Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models](https://arxiv.org/abs/2507.02357)
> *Coling-UniA 在 SciVQA 2025：多模态大型语言模型的少样本示例检索与置信度感知集成*

*Christian Jaumann, Annemarie Friedrich, Rainer Lienhart* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 多模态大型语言模型, 少样本学习, 集成, 视觉问答, SciVQA

**Comment:** Accepted at 5th Workshop on Scholarly Document Processing @ ACL 2025

> **TL;DR:** 针对SciVQA 2025任务，本系统采用多模态大语言模型集成、少样本检索和置信度选择，获得第三名，F1分数为85.12。

**AI_Comments:** 本文的创新之处在于将多模态大型语言模型集成、上下文感知的少样本检索以及基于置信度的答案选择相结合，应用于视觉问答（VQA）任务，为复杂的科学VQA任务提供了一种有效的方法。其在任务中取得的第三名成绩证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 参与SciVQA 2025科学视觉问答共享任务。

**Method:** 该系统采用两个多模态大型语言模型的集成，并结合多种少样本示例检索策略。模型和少样本设置根据图表和问题类型进行选择，答案则根据模型的置信度水平进行选择。

**Result:** 在盲测数据上，该系统在七个参赛者中排名第三，ROUGE-1、ROUGE-L和BERTS的平均F1分数达到85.12。

**Conclusion:** 该系统在SciVQA 2025科学视觉问答共享任务中表现良好，取得了第三名的成绩。

> **ai_Abstract:** 本文介绍了Coling-UniA团队为SciVQA 2025科学视觉问答任务设计的系统。该系统集成了两个多模态大型语言模型，并结合少样本示例检索策略，根据图表和问题类型调整设置，并利用模型置信度进行答案选择。在盲测中，该系统在七个参与者中排名第三，平均F1分数为85.12。

> **摘要翻译:** 本文描述了我们为SciVQA 2025科学视觉问答共享任务设计的系统。我们的系统采用了两个多模态大型语言模型的集成，并结合了多种少样本示例检索策略。模型和少样本设置是根据图表和问题类型选择的。我们还根据模型的置信度水平来选择答案。在盲测数据上，我们的系统在七个参赛者中排名第三，ROUGE-1、ROUGE-L和BERTS的平均F1分数达到85.12。我们的代码已公开发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [192] [QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers](https://arxiv.org/abs/2507.02364)
> *QFFN-BERT：混合量子-经典Transformer中深度、性能和数据效率的实证研究*

*Pilsung Kang* | **Category: cs.CL, quant-ph** | **Updated: {updated}**

**Keywords:** 混合量子-经典Transformer, 参数化量子电路, 前馈网络, 数据效率, BERT

**Comment:** 

> **TL;DR:** 本研究引入了QFFN-BERT，一个用参数化量子电路（PQC）替换前馈网络（FFN）模块的混合量子-经典Transformer。它在全数据设置下超越了经典BERT的准确性，同时大幅减少了参数，并在少样本学习中展现出优越的数据效率。

**AI_Comments:** 该论文的创新点在于首次系统性地将参数化量子电路（PQCs）应用于Transformer模型的前馈网络（FFN）模块，而非传统的自注意力模块。考虑到FFN在Transformer中占据了大量的参数，这一方法显著提高了模型的参数效率（减少超过99%的FFN参数），同时在性能上超越了经典BERT，并在少样本学习中展现出优越的数据效率。这为未来构建更轻量、更高效的混合量子-经典神经网络提供了新的方向和实证支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要将参数化量子电路（PQCs）集成到自注意力模块中，而前馈网络（FFN）在标准Transformer编码器块中占据了约三分之二的参数。本研究旨在探索用PQC替换FFN模块，以提高神经网络的表达能力并解决FFN参数量大的问题。

**Method:** 本研究引入了QFFN-BERT，这是一种混合量子-经典Transformer，其中紧凑型BERT变体的FFN模块被基于PQC的层所取代。该PQC架构包含残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保稳定的训练和高表达能力。实验在经典模拟器上进行，并在SST-2和DBpedia基准上进行评估。

**Result:** 精心配置的QFFN-BERT在全数据设置下达到了基线准确率的102.0%，超越了其经典对应模型，同时将FFN特有的参数减少了99%以上。此外，该模型在少样本学习场景中表现出持续且有竞争力的优势，证实了其在数据效率方面的潜力。

**Conclusion:** 研究结果表明，当与基础深度学习原则共同设计时，参数化量子电路（PQCs）可以作为经典前馈网络（FFNs）的强大且参数高效的替代方案。

> **ai_Abstract:** 本研究提出QFFN-BERT，一种将BERT中前馈网络（FFN）替换为参数化量子电路（PQC）的混合量子-经典Transformer。该模型通过精心设计的PQC架构，在全数据设置下实现了超越经典BERT的性能，同时大幅减少了FFN相关参数（超过99%）。此外，QFFN-BERT在少样本学习中展现出显著的数据效率优势，证明了PQC在深度学习中作为高效参数替代的潜力。

> **摘要翻译:** 参数化量子电路（PQCs）最近已成为增强神经网络架构表达能力的有前景的组件。在这项工作中，我们引入了QFFN-BERT，这是一种混合量子-经典Transformer，其中紧凑型BERT变体的前馈网络（FFN）模块被基于PQC的层所取代。这种设计的动机是FFN在参数中的主导贡献，它们在标准Transformer编码器块中约占三分之二的参数。虽然以前的研究主要将PQCs集成到自注意力模块中，但我们的工作侧重于FFN，并系统地研究了PQC深度、表达能力和可训练性之间的权衡。我们最终的PQC架构结合了残差连接、$R_Y$和$R_Z$旋转以及交替纠缠策略，以确保稳定的训练和高表达能力。我们的实验在经典模拟器上进行，在SST-2和DBpedia基准上证明了两个关键发现。首先，精心配置的QFFN-BERT达到了基线准确率的102.0%，在全数据设置下超越了其经典对应模型，同时将FFN特有的参数减少了99%以上。其次，我们的模型在少样本学习场景中表现出持续且有竞争力的优势，证实了其在数据效率方面的潜力。这些结果，得到了一个未优化PQC（未能学习）的消融研究的支持，证实了当与基础深度学习原则共同设计时，PQCs可以作为经典FFN的强大且参数高效的替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [205] [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](https://arxiv.org/abs/2507.02378)
> *高效代码LLM训练：通过分布一致性和多样性感知的数据选择*

*Weijie Lyu, Sheng-Jun Huang, Xuan Xia* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 数据选择, 代码LLM, 训练效率, 分布一致性, 数据多样性

**Comment:** 

> **TL;DR:** 本文提出一种参数化模型，通过确保数据分布一致性和多样性来选择高质量的代码数据，从而在显著减少数据量的情况下提高代码LLM的训练效率和性能。

**AI_Comments:** 该研究的创新点在于提出了一种通过参数化模型实现分布一致性和多样性感知的数据选择方法，有效解决了大规模数据训练中数据质量被忽视的问题。其重要性在于显著提高了代码LLM的训练效率并降低了计算成本，对资源受限的训练环境具有重要的实践意义和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）的训练主要依赖大量数据，但往往忽视数据质量，导致训练效率低下。本研究旨在通过优化数据选择来提高代码LLM的训练效率和模型性能。

**Method:** 我们引入了一种利用参数化模型进行代码数据选择的方法。该方法优化参数化模型，以确保所选数据子集具有分布一致性和多样性，从而保证数据的高质量。

**Result:** 实验结果表明，仅使用10K样本，我们的方法在HumanEval上比92K全样本基线提高了2.4%，在MBPP上提高了2.3%。在性能和效率方面，该方法均优于其他采样方法。

**Conclusion:** 我们的方法能够有效提升模型性能，同时显著降低计算成本。

> **ai_Abstract:** 本文提出一种新的代码LLM训练方法，通过引入参数化模型进行数据选择，确保选定数据子集的分布一致性和多样性，从而提高数据质量。实验证明，该方法在显著减少训练数据量（仅10K样本）的情况下，仍能超越使用更多数据（92K样本）的基线模型，并在性能和效率上优于其他采样方法，有效降低了计算成本并提升了模型性能。

> **摘要翻译:** 近年来，大型语言模型（LLM）的进步显著提升了代码生成和程序理解能力，加速了软件工程的发展。当前方法主要通过利用大量数据来提高模型性能，侧重于数据数量而常忽视数据质量，从而降低了训练效率。为解决此问题，我们引入了一种利用参数化模型进行代码数据选择的方法，旨在提高训练效率和模型性能。我们的方法优化了参数化模型，以确保所选子集内的数据分布一致性和多样性，从而保证了高质量数据。实验结果表明，仅使用10K样本，我们的方法在HumanEval上比92K全样本基线提高了2.4%，在MBPP上提高了2.3%，在性能和效率上均优于其他采样方法。这强调了我们的方法在有效提升模型性能的同时，显著降低了计算成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [208] [MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs](https://arxiv.org/abs/2507.02851)
> *MOTIF：LLM中通过强化微调实现模块化思维*

*Purbesh Mitra, Sennur Ulukus* | **Category: cs.CL, cs.AI, cs.IT, cs.LG, cs.SY, eess.SY, math.IT** | **Updated: {updated}**

**Keywords:** 模块化思维, 强化学习, 大型语言模型, 上下文限制, 微调

**Comment:** 

> **TL;DR:** MOTIF通过多轮强化微调使LLM超越上下文限制，提高推理能力。

**AI_Comments:** MOTIF通过引入多轮思维和强化微调，有效地解决了LLM在长文本推理中的上下文限制问题，这是一个重要的创新点。其在少量样本下实现显著性能提升，表明了其潜在的实际应用价值和效率。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在推理时受限于上下文大小，这限制了其使用更多思维/推理token的能力，从而阻碍了更复杂的推理。

**Method:** 本文提出了MOTIF（通过强化微调实现模块化思维），这是一种基于强化学习的训练方法，旨在通过多轮生成思维token，有效扩展模型的上下文能力。研究人员在GSM8K数据集上通过参数高效微调训练了开源模型Qwen2.5-3B-Instruct，并在MATH500和AIME2024基准测试上进行了测试。

**Result:** 实验结果显示，在MATH500和AIME2024基准测试上，MOTIF相对于传统的GRPO训练分别实现了3.8%和3.3%的准确率提升。此外，这种改进仅用15%的样本就实现了，证明了MOTIF的样本效率。

**Conclusion:** MOTIF通过多轮强化微调有效地扩展了LLM的推理能力，超越了上下文限制，并在样本效率方面表现出色。

> **ai_Abstract:** 本文提出了MOTIF，一种基于强化微调的训练方法，旨在通过多轮生成思维token来解决大型语言模型（LLMs）推理时受上下文大小限制的问题。该方法使LLMs能够进行模块化思维，有效扩展了其思考能力。实验结果显示，MOTIF在数学推理基准测试上相比传统GRPO训练有显著提升，并且展示了高样本效率。

> **摘要翻译:** 大型语言模型（LLM）推理能力的最新进展表明，采用群相对策略优化（GRPO）算法进行强化学习（RL）训练可以使模型使用更多的思维/推理token来生成更好的响应。然而，LLM在保持对先前生成token的注意力的情况下，只能生成有限数量的token。这个限制，也称为LLM的上下文大小，是LLM处理任意大量token进行推理时的瓶颈。为了超越上下文大小的限制进行思考，LLM必须采用模块化思维策略进行多轮推理。在这项工作中，我们提出了**MOTIF：通过强化微调实现模块化思维**——一种用于多轮生成思维token的RL训练方法，有效地允许模型在额外的上下文大小下进行思考。我们通过参数高效微调在GSM8K数据集上训练了开源模型Qwen2.5-3B-Instruct，并在MATH500和AIME2024基准测试上测试了其准确性。我们的实验表明，在各自的基准测试中，相对于普通的GRPO训练，准确性分别提高了3.8%和3.3%。此外，这种改进仅用15%的样本就实现了，从而证明了MOTIF的样本效率。我们的代码和模型分别在https://github.com/purbeshmitra/MOTIF 和 https://huggingface.co/purbeshmitra/MOTIF 上可用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [218] [Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability](https://arxiv.org/abs/2507.02407)
> *跨领域数据集上的阿坎语ASR模型基准测试：性能、可扩展性和适应性的比较评估*

*Mark Atta Mensah, Isaac Wiafe, Akon Ekpezu, Justice Kwame Appati, Jamal-Deen Abdulai, Akosua Nyarkoa Wiafe-Akenten, Frank Ernest Yeboah, Gifty Odame* | **Category: cs.CL, cs.LG, cs.SD, eess.AS** | **Updated: {updated}**

**Keywords:** 阿坎语ASR, 领域适应, Whisper, Wav2Vec2, 低资源语言

**Comment:** This version has been reviewed and accepted for presentation at the
  Future Technologies Conference (FTC) 2025, to be held on 6 & 7 November 2025
  in Munich, Germany. 17 pages, 4 figures, 1 table

> **TL;DR:** 本研究通过使用四个阿坎语语音语料库，对基于Transformer架构的七个阿坎语ASR模型进行了基准测试，以评估它们在不同领域的性能、可扩展性和适应性。结果显示模型存在领域依赖性，并在领域不匹配时准确性显著下降。研究还发现了Whisper和Wav2Vec2架构之间不同的错误行为，并强调了低资源语言领域适应技术的重要性。

**AI_Comments:** 本文通过对低资源语言（阿坎语）的ASR模型在多领域数据集上进行基准测试，揭示了当前ASR模型在跨领域泛化能力上的局限性，并深入分析了不同Transformer架构的错误特征，这对未来低资源语言ASR系统的开发具有重要的指导意义。其创新之处在于关注了模型在多样化语境下的真实表现，而非仅仅是领域内性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数自动语音识别（ASR）研究主要使用领域内数据集评估模型，但很少评估模型在不同语音上下文中的泛化能力。本研究旨在弥补这一空白，通过对阿坎语ASR模型进行基准测试，评估它们在多样化领域数据集上的性能。

**Method:** 本研究使用四个阿坎语语音语料库（包括文化相关图像描述、非正式对话、圣经经文阅读和自发金融对话）对七个基于Transformer架构（如Whisper和Wav2Vec2）的阿坎语ASR模型进行了基准测试。评估指标包括词错误率（WER）和字符错误率（CER）。

**Result:** 模型表现出领域依赖性，在训练领域内表现最佳，但在领域不匹配的情况下准确性显著下降。Whisper和Wav2Vec2架构之间存在不同的错误行为：微调后的Whisper阿坎语模型产生更流畅但可能误导性的转录错误，而Wav2Vec2在遇到不熟悉输入时产生更明显但难以解释的输出。

**Conclusion:** 在选择低资源语言（LRL）的ASR架构时，应考虑可读性和透明度之间的权衡。研究结果强调了针对阿坎语和其他低资源语言，需要有针对性的领域适应技术、自适应路由策略和多语言训练框架。

> **ai_Abstract:** 本研究旨在弥补现有ASR研究中模型泛化能力评估的不足，特别是在低资源语言领域。通过对七个基于Transformer架构的阿坎语ASR模型（包括Whisper和Wav2Vec2）在四个不同领域阿坎语数据集上进行基准测试，研究发现模型性能存在显著的领域依赖性，在领域不匹配时准确性会大幅下降。此外，研究揭示了Whisper和Wav2Vec2在错误行为上的差异，前者倾向于产生流畅但可能误导的错误，后者则产生明显但难以解释的错误。这些发现强调了为低资源语言开发特定领域适应技术、自适应路由策略和多语言训练框架的必要性。

> **摘要翻译:** 大多数现有的自动语音识别（ASR）研究使用领域内数据集评估模型。然而，它们很少评估模型在不同语音上下文中的泛化能力。本研究通过使用四个阿坎语语音语料库，对基于Transformer架构（如Whisper和Wav2Vec2）构建的七个阿坎语ASR模型进行基准测试，以确定它们的性能，从而解决了这一空白。这些数据集涵盖了不同的领域，包括与文化相关的图像描述、非正式对话、圣经经文阅读和自发的金融对话。词错误率和字符错误率的比较突出了领域依赖性，模型仅在其训练领域内表现最佳，而在不匹配的场景中显示出显著的准确性下降。本研究还确定了Whisper和Wav2Vec2架构之间不同的错误行为。微调后的Whisper阿坎语模型导致更流畅但可能误导性的转录错误，而Wav2Vec2在遇到不熟悉的输入时产生更明显但难以解释的输出。在选择低资源语言（LRL）应用程序的架构时，应考虑ASR错误中可读性和透明度之间的这种权衡。这些发现强调了阿坎语和其他低资源语言需要有针对性的领域适应技术、自适应路由策略和多语言训练框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [229] [A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages](https://arxiv.org/abs/2507.02428)
> *低资源语言中障碍语音社区驱动数据收集的“食谱”*

*Sumaya Ahmed Salihs, Isaac Wiafe, Jamal-Deen Abdulai, Elikem Doe Atsakpo, Gifty Ayoka, Richard Cave, Akon Obu Ekpezu, Catherine Holloway, Katrin Tomanek, Fiifi Baffoe Payin Winful* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 障碍语音, 低资源语言, 自动语音识别, 社区驱动, 数据集

**Comment:** This version has been reviewed and accepted for presentation at the
  InterSpeech 2025 conference to be held in Rotterdam from 17 to 21 August. 5
  pages and 3 tables

> **TL;DR:** 本研究提出了一种为低资源语言中障碍语音构建ASR模型的社区驱动数据收集方法，并创建了阿肯语障碍语音的首个开源数据集和相关工具。

**AI_Comments:** 这项研究的创新之处在于其社区驱动的数据收集方法和“食谱”概念，这对于低资源语言和障碍语音ASR领域具有重要意义。通过开源数据集和工具，它降低了进入门槛，促进了更具包容性的ASR技术发展。其局限性可能在于概念验证阶段的初步结果，以及该方法在其他语言和障碍类型中的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过开发一套“食谱”和培训，实现社区驱动的数据收集和ASR模型构建，从而普及ASR技术和数据收集，特别是针对低资源语言中的障碍语音。

**Method:** 本研究开发了一套关于社区驱动数据收集和ASR模型构建的最佳实践“食谱”和培训。作为概念验证，该研究策划了阿肯语障碍语音的首个开源数据集，并招募了来自不同背景的言语障碍参与者。此外，还对开源ASR模型进行了微调以更好地识别阿肯语中的障碍语音。

**Result:** 本研究策划了阿肯语中障碍语音的首个开源数据集。该数据集、食谱和开源工具均已公开可用。同时，研究还展示了微调开源ASR模型以更好识别阿肯语障碍语音的初步结果。

**Conclusion:** 该研究通过提供一个“食谱”、开源工具和数据集，使研究人员和实践者能够创建针对言语障碍个体独特需求的包容性ASR技术。

> **ai_Abstract:** 本研究提出了一种针对低资源语言中障碍语音的社区驱动数据收集方法，旨在通过开发一套“食谱”和培训来普及ASR技术。作为概念验证，该研究创建了首个阿肯语障碍语音开源数据集，并提供了相关的“食谱”和开源工具。研究还展示了微调ASR模型识别阿肯语障碍语音的初步成果，以期促进开发包容性的ASR技术。

> **摘要翻译:** 本研究提出了一种收集语音样本的方法，用于为障碍语音，特别是低资源语言，构建自动语音识别（ASR）模型。它旨在通过开发一套最佳实践的“食谱”和培训，用于社区驱动的数据收集和ASR模型构建，从而实现ASR技术和数据收集的民主化。作为概念验证，本研究策划了第一个阿肯语障碍语音的开源数据集：一种在加纳广泛使用的本土语言。该研究涉及来自不同背景的言语障碍参与者。由此产生的数据集，连同该“食谱”和开源工具，都已公开可用，以使研究人员和从业者能够创建针对言语障碍个体独特需求的包容性ASR技术。此外，本研究还展示了微调开源ASR模型以更好识别阿肯语障碍语音的初步结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [240] [IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders](https://arxiv.org/abs/2507.02506)
> *IndianBailJudgments-1200：一个用于印度保释令法律自然语言处理的多属性数据集*

*Sneha Deshmukh, Prathmesh Kamble* | **Category: cs.CL, cs.AI, cs.LG, 91B14, 68T50, I.2.7; K.4.1; K.5.2** | **Updated: {updated}**

**Keywords:** 印度保释判决, 法律NLP, 数据集, 多属性, GPT-4o

**Comment:** 9 pages, 9 figures, 2 tables. Dataset available at Hugging Face and
  GitHub. Submitted to arXiv for open access

> **TL;DR:** 引入了IndianBailJudgments-1200，一个包含1200份印度保释判决的多属性数据集，旨在解决印度法律NLP数据稀缺问题。

**AI_Comments:** 该论文的创新之处在于创建了第一个专门针对印度保释判例的公开多属性数据集，有效填补了该地区法律NLP数据稀缺的空白。其重要性在于为印度法律NLP研究提供了宝贵资源，并利用GPT-4o等先进AI技术提高了数据标注效率和质量。

<details>
  <summary>Details</summary>

**Motivation:** 印度等地区法律自然语言处理（NLP）发展不足，原因是缺乏结构化数据集。

**Method:** 使用提示工程的GPT-4o管道生成注释，并验证了其一致性。

**Result:** 创建了IndianBailJudgments-1200数据集，包含1200份印度法院保释判决，并标注了20多个属性（包括保释结果、IPC条款、犯罪类型和法律推理）。该数据集支持广泛的法律NLP任务，如结果预测、摘要和公平性分析。

**Conclusion:** IndianBailJudgments-1200是第一个专门针对印度保释判例的公开数据集。

> **ai_Abstract:** 本文介绍了IndianBailJudgments-1200，一个包含1200份印度保释判决的基准数据集，旨在解决印度法律NLP领域结构化数据稀缺的问题。该数据集通过提示工程的GPT-4o管道标注了20多个属性，并经过一致性验证，可用于结果预测、摘要和公平性分析等法律NLP任务，是首个公开的印度保释判例数据集。

> **摘要翻译:** 法律自然语言处理在印度等地区由于结构化数据集的稀缺而仍不发达。我们引入了IndianBailJudgments-1200，一个包含1200份印度法院保释判决的新基准数据集，标注了20多个属性，包括保释结果、IPC条款、犯罪类型和法律推理。注释是使用提示工程的GPT-4o管道生成的，并验证了一致性。该资源支持广泛的法律自然语言处理任务，如结果预测、摘要和公平性分析，并且是第一个专门针对印度保释判例的公开数据集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [249] [WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592)
> *WebSailor：为网络智能体导航超人推理*

*Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, Weizhou Shen, Junkai Zhang, Dingchu Zhang, Xixi Wu, Yong Jiang, Ming Yan, Pengjun Xie, Fei Huang, Jingren Zhou* | **Category: cs.CL, cs.AI** | **Updated: {updated}**

**Keywords:** WebSailor, 大型语言模型, 信息搜索, 不确定性, 强化学习

**Comment:** 

> **TL;DR:** WebSailor是一个后训练方法，旨在使开源大型语言模型（LLMs）具备处理复杂信息搜索任务中极端不确定性的能力，从而缩小与专有智能体之间的性能差距。

**AI_Comments:** 该论文提出了一种新颖的后训练方法WebSailor，旨在解决开源LLM在处理复杂信息搜索任务中极端不确定性方面的不足。其创新点在于通过生成高不确定性任务和引入DUPO算法来提升模型能力，有效地缩小了开源模型与专有系统之间的性能差距，对推动LLM在复杂网络环境中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 专有智能体（如DeepResearch）在复杂信息搜索任务中表现出超人能力，这归因于其系统性地降低极端不确定性的推理模式。然而，开源模型缺乏这种能力，因此本研究旨在弥补这一差距。

**Method:** WebSailor是一种完整的后训练方法。它通过结构化采样和信息混淆生成新颖的高不确定性任务，采用RFT冷启动，并使用高效的智能体强化学习训练算法——复制采样策略优化（DUPO）。

**Result:** WebSailor在复杂信息搜索任务中显著优于所有开源智能体，性能与专有智能体相当，成功缩小了能力差距。

**Conclusion:** WebSailor通过其独特的后训练方法，成功地赋予开源大型语言模型处理复杂信息搜索任务中的极端不确定性能力，使其性能达到专有智能体的水平。

> **ai_Abstract:** WebSailor是一种创新的后训练方法，旨在解决开源大型语言模型在处理复杂信息搜索任务时缺乏有效应对极端不确定性的能力。通过引入结构化采样、信息混淆生成高不确定性任务、RFT冷启动以及Duplicating Sampling Policy Optimization (DUPO)强化学习算法，WebSailor显著提升了开源智能体在复杂信息搜索任务上的表现，使其性能达到甚至超越了现有开源模型的水平，并成功缩小了与DeepResearch等专有智能体之间的差距。

> **摘要翻译:** 超越人类认知局限性代表着大型语言模型（LLM）训练的一个关键前沿。像DeepResearch这样的专有智能体系统，在BrowseComp等极其复杂的信息搜索基准测试中展现出超人能力，这是以前无法实现的壮举。我们认为，它们的成功取决于开源模型中缺乏的一种复杂推理模式：即在广阔的信息环境中系统性地降低极端不确定性的能力。基于这一洞察，我们引入了WebSailor，一个完整的后训练方法，旨在灌输这种关键能力。我们的方法包括通过结构化采样和信息混淆生成新颖的、高不确定性任务，RFT冷启动，以及一种高效的智能体强化学习训练算法——复制采样策略优化（DUPO）。凭借这一集成管道，WebSailor在复杂信息搜索任务中显著优于所有开源智能体，匹配了专有智能体的性能并缩小了能力差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [259] [Revisiting Active Learning under (Human) Label Variation](https://arxiv.org/abs/2507.02593)
> *重新审视（人类）标签变异下的主动学习*

*Cornelia Gruber, Helen Alber, Bernd Bischl, Göran Kauermann, Barbara Plank, Matthias Aßenmacher* | **Category: cs.CL, cs.HC, cs.LG, stat.ML** | **Updated: {updated}**

**Keywords:** 主动学习, 标签变异, 人类标注, 自然语言处理, 大型语言模型

**Comment:** 

> **TL;DR:** 本文探讨了如何在主动学习中整合人类标签变异，以更好地反映现实世界的标注复杂性，并提出了一个概念框架，同时讨论了将大型语言模型作为标注器的可能性。

**AI_Comments:** 本文的创新之处在于，它将人类标签变异视为主动学习范式中的一个有价值的信号，而不仅仅是噪声。其重要性在于提出了一个概念框架，这有望促使开发出更健壮、更符合实际的主动学习策略，尤其是在自然语言处理等主观性较强的领域。此外，将大型语言模型作为标注器的讨论也具有很强的时代意义。

<details>
  <summary>Details</summary>

**Motivation:** 高质量标注数据的获取是应用监督学习的限制因素。现有标注框架和主动学习方法常假设单一的“真实标签”，忽略了人类标签变异（HLV）作为信息信号的存在。这种简化假设在实践中很少成立，尤其是在自然语言处理中，标签变异很常见。

**Method:** 本文研究了关于“真实”和标签性质的基本假设，强调需要将观察到的标签变异分解为信号（如HLV）和噪声（如标注错误）。作者调查了主动学习和（人类）标签变异社区如何处理或忽视这些区别。提出了一种将HLV整合到主动学习循环中的概念框架，包括实例选择、标注器选择和标签表示。此外，还讨论了将大型语言模型（LLM）作为标注器的整合。

**Result:** 本文提出了一个用于感知HLV的主动学习的概念框架，并讨论了将大型语言模型作为标注器的整合。它强调了将观察到的标签变异分解为信号和噪声的必要性。

**Conclusion:** 本研究旨在为感知人类标签变异的主动学习奠定概念基础，以更好地反映现实世界标注的复杂性。

> **ai_Abstract:** 本文探讨了监督学习中人类标签变异（HLV）的挑战，指出当前标注框架和主动学习（AL）方法常忽略HLV作为信息信号，并假设单一的“真实标签”。作者强调需将标签变异分解为信号和噪声，并提出了一个概念框架，旨在将HLV整合到主动学习的各个环节，包括实例选择、标注器选择和标签表示。此外，文章还讨论了将大型语言模型（LLM）作为标注器。这项工作旨在为理解现实世界标注复杂性的HLV感知主动学习奠定基础。

> **摘要翻译:** 高质量标注数据的获取仍然是应用监督学习的一个限制因素。虽然标签变异（LV），即同一实例的不同标签，很常见，尤其是在自然语言处理中，但标注框架通常仍然基于单一“真实标签”的假设。这忽略了人类标签变异（HLV），即标注中可能出现的合理差异，作为一种信息信号。同样，主动学习（AL）作为一种优化有限标注预算以训练机器学习模型的流行方法，通常依赖于至少一种简化假设，而这些假设在承认HLV时在实践中很少成立。在本文中，我们审视了关于“真实”和标签性质的基本假设，强调需要将观察到的LV分解为信号（例如HLV）和噪声（例如标注错误）。我们调查了AL和（H）LV社区如何处理——或忽视——这些区别，并提出了一个概念框架，用于在整个AL循环中整合HLV，包括实例选择、标注器选择和标签表示。我们进一步讨论了大型语言模型（LLM）作为标注器的整合。我们的工作旨在为感知HLV的主动学习奠定概念基础，更好地反映现实世界标注的复杂性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [267] [MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion](https://arxiv.org/abs/2507.02595)
> *MPF：通过多视角融合在部署后对语言模型进行对齐和去偏*

*Xin Guan, PeiHsin Lin, Zekun Wu, Ze Wang, Ruibo Zhang, Emre Kazim, Adriano Koshiyama* | **Category: cs.CL, cs.AI** | **Updated: {updated}**

**Keywords:** 多视角融合, 语言模型对齐, 偏见缓解, 后训练, 可解释性

**Comment:** Accepted at ICML 2025 AIW Workshop

> **TL;DR:** MPF是一种新颖的后训练对齐框架，用于在部署后通过多视角生成来缓解大型语言模型中的偏见，无需大量提示工程或微调。

**AI_Comments:** MPF的创新之处在于其“多视角融合”方法，通过分解基线并加权生成，实现了对LLM偏见的细致对齐。该方法无需复杂的提示工程或微调，使其在实际部署中具有很高的实用价值和可扩展性，对于解决LLM的伦理和公平性问题具有重要意义。其与SAGED管道的结合也提供了一个全面的偏见评估和缓解方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了满足对易于偏见缓解日益增长的需求，MPF被开发出来，旨在解决大型语言模型（LLMs）部署后存在的偏见问题。

**Method:** MPF建立在SAGED管道之上，该管道是一个自动化系统，用于构建偏见基准并提取可解释的基线分布。MPF利用多视角生成来揭示和对齐LLM输出中的偏见，使其与细致入微的、类人的基线保持一致。通过将基线（例如来自人力资源专业人员的情感分布）分解为可解释的视角组件，MPF通过采样和平衡响应来指导生成，并根据分解中获得的概率进行加权。

**Result:** 经验证明，MPF能够将LLM情感分布与反事实基线（绝对平等）和HR基线（对顶尖大学有偏见）对齐，从而产生小的KL散度，减少校准误差，并泛化到未见过的问题。

**Conclusion:** MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，兼容已部署的LLMs，并且不需要大量的提示工程或微调。

> **ai_Abstract:** 本文提出了一种名为多视角融合（MPF）的后训练对齐框架，旨在解决大型语言模型（LLMs）部署后的偏见问题。MPF基于SAGED管道构建，通过多视角生成来揭示和对齐LLM输出中的偏见，使其符合人类基线。该方法将基线分解为可解释的视角组件，并据此引导LLM生成。实验证明，MPF能有效对齐LLM的情感分布，减少KL散度和校准误差，并能泛化到新问题，同时无需复杂的提示工程或微调，具有良好的可扩展性和可解释性。

> **摘要翻译:** 多视角融合（MPF）是一种新颖的后训练对齐框架，专为大型语言模型（LLMs）开发，以应对日益增长的简单偏见缓解需求。MPF建立在SAGED管道之上，这是一个用于构建偏见基准和提取可解释基线分布的自动化系统。MPF利用多视角生成来揭示LLM输出中的偏见并将其与细致入微的、类人的基线对齐。通过将基线（例如来自人力资源专业人员的情感分布）分解为可解释的视角组件，MPF通过对响应进行采样和平衡来指导生成，并根据分解中获得的概率进行加权。经验证明，MPF能够将LLM情感分布与反事实基线（绝对平等）和HR基线（对顶尖大学有偏见）对齐，从而产生小的KL散度，减少校准误差，并泛化到未见过的问题。这表明MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，兼容已部署的LLMs，并且不需要大量的提示工程或微调。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [275] [Exploring Gender Bias Beyond Occupational Titles](https://arxiv.org/abs/2507.02679)
> *探索超越职业头衔的性别偏见*

*Ahmed Sabir, Rajesh Sharama* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 性别偏见, 语境偏见, GenderLexicon, 职业刻板印象, 可解释性

**Comment:** Work in progress

> **TL;DR:** 本文研究了性别与语境偏见之间的相关性，并引入了一个新数据集和框架来估计和解释性别偏见，证实了职业刻板印象之外的性别偏见的存在。

**AI_Comments:** 本文的创新之处在于引入了GenderLexicon数据集和一套新的框架来量化和解释语境中的性别偏见，并将研究范围扩展到职业头衔之外，揭示了更深层次的性别偏见。其方法的可解释性和在多语言数据集上的验证增加了研究的价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在调查性别与语境偏见（特别是动作动词、宾语名词和职业）之间的相关性，并确认职业刻板印象之外的性别偏见是否存在。

**Method:** 研究引入了一个新数据集GenderLexicon和一个可以估计语境偏见及其相关性别偏见的框架。该模型能够通过分数解释偏见，从而提高性别偏见的解释性。研究还在五个不同的数据集（包括一个日语数据集）上进行了评估以验证方法。

**Result:** 研究结果证实了职业刻板印象之外的性别偏见的存在。

**Conclusion:** 本文通过引入新数据集和框架，成功地探索并证实了超越职业刻板印象的性别偏见，并验证了其方法的有效性。

> **ai_Abstract:** 本文深入探讨了性别与语境偏见的关联，特别关注动作动词、宾语名词及职业等要素。研究提出了一个名为GenderLexicon的新数据集和一个用于估计和解释性别偏见的框架。该模型能够量化偏见并提升其可解释性。研究发现证实了性别偏见不仅限于职业刻板印象，并通过在多个数据集上的评估验证了方法的有效性。

> **摘要翻译:** 在这项工作中，我们调查了性别与语境偏见之间的相关性，重点关注动作动词、宾语名词等元素，特别是职业。我们引入了一个新颖的数据集GenderLexicon和一个可以估计语境偏见及其相关性别偏见的框架。我们的模型可以根据分数解释偏见，从而提高性别偏见的解释性。此外，我们的发现证实了职业刻板印象之外的性别偏见的存在。为了验证我们的方法并证明其有效性，我们在五个不同的数据集（包括一个日语数据集）上进行了评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [283] [Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers](https://arxiv.org/abs/2507.02694)
> *大型语言模型能否识别科学研究中的关键局限性？一项针对人工智能研究论文的系统评估*

*Zhijian Xu, Yilun Zhao, Manasi Patwardhan, Lovekesh Vig, Arman Cohan* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 大型语言模型, 论文局限性, 同行评审, 基准测试, 文献检索

**Comment:** 

> **TL;DR:** 本文提出了LimitGen，一个用于评估LLM识别科学论文局限性的基准，并通过文献检索增强LLM的能力，以辅助同行评审。

**AI_Comments:** 这篇论文的创新点在于提出了第一个专门用于评估LLM识别科学论文局限性的基准——LimitGen，并引入了通过文献检索增强LLM能力的方法。这对于减轻同行评审的负担和提高其效率具有重要意义。该研究为LLM在科学评审领域的应用开辟了新方向，但其在实际复杂同行评审场景中的鲁棒性和泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 同行评审对科学研究至关重要，但日益增长的出版量使其面临挑战。尽管大型语言模型（LLMs）在多种科学任务中表现出潜力，但其在协助同行评审，特别是识别论文局限性方面的潜力尚未得到充分研究。

**Method:** 本研究首先提出了一个专注于AI研究中局限性类型的综合分类法。在此分类法指导下，构建了LimitGen基准，这是首个用于评估LLM在支持早期反馈和补充人工同行评审方面能力的综合基准。LimitGen包含两个子集：LimitGen-Syn（通过对高质量论文进行受控扰动创建的合成数据集）和LimitGen-Human（真实人类编写的局限性集合）。为了提高LLM系统识别局限性的能力，研究人员通过文献检索对其进行了增强，这对于将局限性识别建立在先前的科学发现之上至关重要。

**Result:** 本研究的方法增强了大型语言模型系统生成研究论文局限性的能力。

**Conclusion:** 通过增强文献检索能力，大型语言模型能够更具体、更有建设性地识别和提供研究论文的局限性反馈，从而辅助人类同行评审。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）识别科学研究中关键局限性的能力，以辅助日益繁重的同行评审过程。为此，作者首先构建了一个全面的AI研究局限性分类法，并在此基础上开发了LimitGen基准，该基准包含合成数据集LimitGen-Syn和真实人类编写的LimitGen-Human。为了提升LLMs的性能，研究团队通过整合文献检索功能来增强其识别能力。结果表明，这种方法显著提升了LLMs生成研究论文局限性的能力，使其能够提供更具体和建设性的反馈，从而有望补充人类同行评审。

> **摘要翻译:** 同行评审是科学研究的基础，但日益增长的出版量加剧了这一专业密集型过程的挑战。尽管大型语言模型（LLMs）在各种科学任务中展现出潜力，但它们在协助同行评审，特别是在识别论文局限性方面的潜力仍未得到充分研究。我们首先提出了一个关于科学研究中局限性类型的综合分类法，重点关注人工智能领域。在此分类法的指导下，为了研究局限性，我们提出了LimitGen，这是第一个用于评估LLM支持早期反馈和补充人类同行评审能力的综合基准。我们的基准包括两个子集：LimitGen-Syn，一个通过对高质量论文进行受控扰动而精心创建的合成数据集，以及LimitGen-Human，一个真实人类编写的局限性集合。为了提高LLM系统识别局限性的能力，我们通过文献检索对其进行了增强，这对于将局限性识别建立在先前的科学发现之上至关重要。我们的方法增强了LLM系统生成研究论文局限性的能力，使它们能够提供更具体和建设性的反馈。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [290] [Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens](https://arxiv.org/abs/2507.02744)
> *通过“刚好可产生差异”(JPD)阈限测量元音产生空间的粒度*

*Peter Viechnicki* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 元音产生, JPD, 粒度, 语音控制, 听觉空间

**Comment:** 

> **TL;DR:** 本研究通过测量“刚好可产生差异”(JPD)来量化人类元音产生控制的精度，发现在F1 X F2空间中，JPD介于14到51mels之间，这为语音产生的偶发理论和元音系统结构提供了启示。

**AI_Comments:** 本研究通过引入JPD这一新颖的度量，量化了人类语音生产中亚音素控制的精确度，填补了现有研究的空白。其创新之处在于将心理物理学的概念应用于语音产生领域，为理解语音的精细控制机制提供了量化依据。研究结果不仅对语音产生理论有直接影响，也为语言学中元音系统结构的解释提供了坚实的实验数据支持，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管已知人类元音产生的控制机制以听觉空间中的目标区域为导向，并且在亚音素层面也能进行控制，但这种控制的精确度尚不清楚。本研究旨在通过测量“刚好可产生差异”(JPD)来回答这个问题，即两个元音刺激在听觉空间中需要相距多远才能产生可靠的差异模仿。

**Method:** 本研究采用元音模仿范式，首次测量了两组英语使用者在前元音产生过程中的JPD。JPD被定义为在听觉空间中，两个元音刺激需要相距多远才能产生可靠的差异模仿。

**Result:** 研究估算出JPD在F1 X F2空间中介于14到51mels之间。

**Conclusion:** 这项发现对语音产生的偶发理论具有重要意义。它通过设定元音音素在说话者共振峰空间中可能接近的理论下限，澄清了人类元音系统的可能结构，并为观察到的元音音素数量和模式趋势提供了心理物理学解释。

> **ai_Abstract:** 本研究旨在量化人类元音产生控制的精确度，通过引入“刚好可产生差异”(JPD)的概念，即在听觉空间中能够产生可靠不同模仿的最小元音刺激距离。研究采用元音模仿范式，首次测量了两组英语使用者在前元音产生时的JPD，结果显示JPD在F1 X F2空间中介于14到51mels之间。这一发现不仅对语音产生的偶发理论有影响，也通过设定元音音素接近的理论下限，为理解人类元音系统结构及其心理物理学基础提供了新的视角。

> **摘要翻译:** 在过去的几十年里，大量研究表明，人类元音产生中复杂协调的发音运动（至少部分地）受控于以听觉空间区域为目标的控制机制。在目标区域内，亚音素水平的控制也已被证实。但是，这种控制的准确度尚不清楚。当前的工作通过询问两个元音刺激在听觉空间中必须相距多远才能产生可靠的差异模仿来调查这个问题。这个距离被称为“刚好可产生差异”（JPD）。当前的研究使用元音模仿范式，首次测量了两组英语使用者在前元音产生过程中的JPD。JPD在F1 X F2空间中估计介于14到51mels之间。这一发现对语音产生的偶发理论具有重要意义。它还通过设定元音音素在说话者共振峰空间中可能接近的理论下限，从而为观察到的元音音素数量和模式趋势提供心理物理学解释，从而阐明了人类元音系统的可能结构。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [297] [Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs](https://arxiv.org/abs/2507.02778)
> *自我纠正基准：揭示并解决大型语言模型中的自我纠正盲点*

*Ken Tsui* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 大型语言模型, 自我纠正, 盲点, 错误纠正, 可信赖性

**Comment:** 31 pages, 18 figures

> **TL;DR:** 本文揭示了大型语言模型（LLMs）存在“自我纠正盲点”，即无法纠正自身输出中的错误。通过引入“自我纠正基准”测试14个模型，发现平均盲点率为64.5%，且与训练数据构成有关。研究表明，简单地添加“等等”提示可显著降低盲点，表明LLMs的纠错能力存在但需激活。

**AI_Comments:** 这项工作通过引入“自我纠正基准”系统性地揭示了LLMs的一个重要且普遍存在的缺陷——自我纠正盲点。其创新之处在于量化了这一问题，并提出了一种简单而有效的激活策略（“等等”），为未来LLMs的可靠性和可信赖性改进提供了明确的方向。研究还指出训练数据构成可能是导致此问题的原因，为数据策展提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）已成为变革性技术，但它们仍会犯错并可能探索低效的推理路径。自我纠正对于可信赖的LLM至关重要。然而，LLMs在能够识别用户输入错误的同时，却表现出一种系统性的“自我纠正盲点”，即无法纠正其自身输出中的相同错误。

**Method:** 研究引入了“自我纠正基准”（Self-Correction Bench），这是一个系统性框架，通过在三个复杂级别上进行受控错误注入来衡量“自我纠正盲点”现象。该研究测试了14个模型。

**Result:** 测试14个模型后，发现平均盲点率为64.5%。研究发现多项证据表明这种局限性与训练数据构成有关，即人类训练演示主要显示无错误响应，而非错误纠正序列。值得注意的是，简单地附加“等等”（“Wait”）可将盲点减少89.3%。

**Conclusion:** 本研究突出了当前大型语言模型的一个关键局限性，并为提高其可靠性和可信赖性提供了潜在途径。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）中存在的“自我纠正盲点”现象，即LLMs无法纠正自身输出中的错误。研究引入了“自我纠正基准”框架，通过受控错误注入测试了14个模型，发现平均盲点率高达64.5%。研究指出此问题与训练数据中缺乏错误纠正示例有关。令人惊讶的是，简单地添加“等等”提示可显著降低盲点，表明LLMs具备纠错能力但需激活。该工作揭示了LLMs的关键局限性并指出了改进方向。

> **摘要翻译:** 尽管大型语言模型（LLMs）已成为变革性的技术，但它们仍然会犯错并可能探索低效的推理路径。自我纠正对于一个值得信赖的LLM，特别是自回归LLM，是一项重要的能力。虽然LLMs能够识别用户输入中的错误，但它们表现出一种系统性的“自我纠正盲点”——即无法纠正其自身输出中的相同错误。为了系统地研究这一现象，我们引入了“自我纠正基准”（Self-Correction Bench），这是一个通过在三个复杂级别上进行受控错误注入来衡量这一现象的系统性框架。通过测试14个模型，我们发现平均盲点率为64.5%。我们发现多项证据表明，这种局限性与训练数据构成有关：人类训练演示主要显示无错误响应，而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。值得注意的是，简单地附加“等等”（"Wait"）可将盲点减少89.3%，这表明该能力存在但需要激活。我们的工作突出了当前LLMs的一个关键局限性，并为提高其可靠性和可信赖性提供了潜在途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [303] [Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](https://arxiv.org/abs/2507.02799)
> *推理就是你所需要的一切吗？探究推理语言模型时代的偏见*

*Riccardo Cantini, Nicola Gabriele, Alessio Orsino, Domenico Talia* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 推理语言模型, 偏见, 鲁棒性, 思维链, 越狱攻击

**Comment:** 

> **TL;DR:** 推理语言模型（RLMs）在偏见鲁棒性方面表现不佳，甚至可能比基础模型更容易受到偏见诱导。

**AI_Comments:** 这篇论文对推理语言模型（RLMs）的偏见鲁棒性进行了深入探讨，其创新点在于挑战了“推理能力必然提升模型鲁棒性”的普遍假设。研究发现RLMs，尤其是那些采用思维链（CoT）提示的模型，可能比基础模型更容易受到偏见诱导，甚至可能为刻板印象的强化提供新途径。这一发现非常重要，因为它提醒我们，在追求模型推理能力的同时，必须更加警惕其潜在的偏见风险，并在模型设计中融入更强的偏见意识。

<details>
  <summary>Details</summary>

**Motivation:** 尽管推理语言模型（RLMs）通过复杂的多步推理任务提升了可靠性，但其对社会偏见的鲁棒性影响尚不明确。

**Method:** 利用CLEAR-Bias基准，通过LLM作为评判者进行自动化安全评分，并采用越狱技术，系统评估了最先进的RLMs在不同社会文化维度上的对抗性偏见诱导鲁棒性。

**Result:** 具有显式推理能力的模型（无论是通过CoT提示还是微调的推理轨迹）通常比没有这些机制的基础模型更容易受到偏见诱导。推理启用的模型比依赖CoT提示的模型更安全一些，后者特别容易受到通过讲故事提示、虚构角色或奖励塑造指令进行的上下文重构攻击。

**Conclusion:** 推理能力与偏见安全之间存在微妙关系，推理可能无意中为刻板印象的强化开辟了新途径。这挑战了推理固有地提高鲁棒性的假设，并强调了在推理设计中需要采取更具偏见意识的方法。

> **ai_Abstract:** 本研究探讨了推理语言模型（RLMs）在处理社会偏见方面的鲁棒性。利用CLEAR-Bias基准和LLM作为评判者的方法，系统评估了RLMs对偏见诱导的抵抗力。结果显示，具有显式推理能力的RLMs，包括使用思维链（CoT）提示或微调推理轨迹的模型，反而比基础模型更容易受到偏见影响，表明推理过程可能无意中加剧刻板印象。研究还发现，推理启用的模型比仅依赖CoT提示的模型在某些方面更安全。这些发现挑战了推理能天然提高模型鲁棒性的假设，并强调了在RLMs设计中需要更关注偏见问题。

> **摘要翻译:** 推理语言模型（RLM）因其通过思维链（CoT）提示或微调推理轨迹等机制执行复杂、多步推理任务的能力而受到关注。虽然这些能力有望提高可靠性，但它们对社会偏见的鲁棒性影响仍不明确。在这项工作中，我们利用最初为大型语言模型（LLM）设计的CLEAR-Bias基准，调查RLM对偏见诱导的对抗性鲁棒性。我们使用“LLM作为评判者”的方法进行自动化安全评分，并利用越狱技术评估内置安全机制的强度，系统地评估了最先进的RLM在不同社会文化维度上的表现。我们的评估解决了三个关键问题：（i）推理能力的引入如何影响模型的公平性和鲁棒性；（ii）为推理而微调的模型是否比在推理时依赖CoT提示的模型表现出更高的安全性；以及（iii）针对偏见诱导的越狱攻击成功率如何随所采用的推理机制而变化。我们的研究结果揭示了推理能力与偏见安全之间微妙的关系。令人惊讶的是，具有显式推理能力的模型，无论是通过CoT提示还是微调推理轨迹，通常比没有此类机制的基础模型更容易受到偏见诱导，这表明推理可能无意中为刻板印象的强化开辟了新途径。推理启用的模型似乎比那些依赖CoT提示的模型更安全一些，后者特别容易受到通过讲故事提示、虚构角色或奖励塑造指令进行的上下文重构攻击。这些结果挑战了推理固有地提高鲁棒性的假设，并强调了在推理设计中需要采取更具偏见意识的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [308] [Multimodal Mathematical Reasoning with Diverse Solving Perspective](https://arxiv.org/abs/2507.02804)
> *多模态数学推理与多样化求解视角*

*Wenhao Shi, Zhiqiang Hu, Yi Bin, Yang Yang, See-Kiong Ng, Heng Tao Shen* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 多模态数学推理, 多样化求解, 大语言模型, 强化学习, MathV-DP

**Comment:** 8 pages

> **TL;DR:** 本文介绍了MathV-DP数据集和Qwen-VL-DP模型，通过融入多样化的求解路径和反射式推理，显著提升了多模态大语言模型在数学推理方面的准确性和生成多样性。

**AI_Comments:** 该论文通过引入新的数据集（MathV-DP）和创新的训练方法（结合监督学习和GRPO强化学习），有效解决了当前多模态大语言模型在数学推理中多样性不足的问题。其亮点在于认识到并利用了数学问题求解路径的多样性，并通过奖励机制鼓励模型生成不同但同样正确的解决方案，这对于提升模型的泛化能力和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的多模态大语言模型在数学推理中，过度依赖一对一的图像-文本对和单一解监督，忽略了有效推理的多样性和内部反思的重要性。

**Method:** 本文引入了MathV-DP数据集，该数据集为每个图像-问题对捕获了多个多样化的解决方案轨迹。在此基础上，提出了Qwen-VL-DP模型，该模型基于Qwen-VL进行监督学习微调，并通过基于规则的强化学习方法——组相对策略优化（GRPO）进行增强，GRPO集成了正确性判别和多样性感知奖励函数，强调从不同推理角度学习并区分正确但独特的解决方案。

**Result:** Qwen-VL-DP在MathVista的minitest和Math-V基准测试中，在准确性和生成多样性方面均显著优于先前的基础多模态大语言模型。

**Conclusion:** 将多样化的视角和反思性推理融入多模态数学推理对于提升模型的性能至关重要。

> **ai_Abstract:** 本文针对当前多模态大语言模型在数学推理中缺乏多样化视角和反思的问题，提出了MathV-DP数据集和Qwen-VL-DP模型。MathV-DP提供了多样的解决方案轨迹，而Qwen-VL-DP通过监督学习和基于GRPO的强化学习（结合正确性判别和多样性奖励）进行训练。实验证明，Qwen-VL-DP在数学推理的准确性和生成多样性上均优于现有模型，强调了多样化和反思性推理的重要性。

> **摘要翻译:** 大型强化学习（RL）的最新进展显著增强了大型语言模型（LLMs）的推理能力，尤其是在数学领域。然而，当前用于数学推理的多模态大型语言模型（MLLMs）通常依赖于一对一的图像-文本对和单一解决方案监督，忽视了有效推理视角的多样性和内部反思。在这项工作中，我们引入了MathV-DP，一个新颖的数据集，它为每个图像-问题对捕获了多个多样化的解决方案轨迹，从而促进了更丰富的推理监督。我们进一步提出了Qwen-VL-DP，一个基于Qwen-VL构建的模型，通过监督学习进行微调，并通过组相对策略优化（GRPO）进行增强，GRPO是一种基于规则的强化学习方法，它整合了正确性判别和多样性感知奖励函数。我们的方法强调从不同的推理角度学习并区分正确但独特的解决方案。在MathVista的minitest和Math-V基准测试中进行的广泛实验表明，Qwen-VL-DP在准确性和生成多样性方面均显著优于先前的基础多模态大型语言模型，突显了在多模态数学推理中融入多样化视角和反思性推理的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [314] [SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model](https://arxiv.org/abs/2507.02822)
> *SynapseRoute：一种基于双态大语言模型的自动路由切换框架*

*Wencheng Zhang, Shiqin Qiao, Lingjie Luo, Yinfeng Li, Chuanyang Zheng, Qian Xu, Meng Li, Yong Gui, Yijun He, Jianing Qiu, Jindong Hong, Jiankai Sun* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 大语言模型, 动态路由, 成本效率, 推理模式, SynapseRoute

**Comment:** 

> **TL;DR:** 提出了SynapseRoute框架，通过动态路由LLM查询以平衡性能和成本，避免过度推理，并在医疗问答中显著提升准确性并降低资源消耗。

**AI_Comments:** 本文的创新之处在于提出了一个实用的动态路由框架SynapseRoute，有效解决了大语言模型在实际应用中性能与成本之间的权衡问题。通过将查询智能地分配给不同的处理模式，它不仅提升了整体效率，还避免了因过度推理导致的性能下降。引入AIT指数也为LLM的综合评估提供了一个新的视角，具有较高的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着大语言模型（LLMs）在实际应用中的广泛采用，选择合适的模型需要在性能和运营成本之间取得平衡。具有推理能力的模型的出现进一步扩大了“思考”（高推理）模式和“非思考”（快速、低成本）模式之间的成本差距。研究发现约58%的医疗问题可由低成本模式回答，表明问题复杂性存在二分法，动态路由查询可优化准确性、成本效率和整体用户体验。

**Method:** 提出SynapseRoute，一个基于机器学习的动态路由框架，智能地将输入查询分配给“思考”（高推理）或“非思考”（快速、低成本）模式。

**Result:** 在医疗数据集上，SynapseRoute相比单独使用思考模式，提高了整体准确性（0.8390 vs. 0.8272），推理时间减少36.8%，Token消耗减少39.66%。定性分析表明，对简单查询进行过度推理可能导致不必要的延迟甚至准确性下降，而自适应路由避免了这一缺陷。

**Conclusion:** 该工作提出了SynapseRoute动态路由框架，有效平衡了LLM的性能和成本，并通过实验验证了其优越性。此外，还引入了准确性-推理-Token（AIT）指数来综合评估准确性、延迟和Token成本之间的权衡。

> **ai_Abstract:** 本文提出了SynapseRoute框架，旨在解决大语言模型应用中性能与成本的平衡问题。通过分析发现，大量简单查询无需高成本的“思考”模式。SynapseRoute是一个基于机器学习的动态路由框架，能智能地将查询分配给“思考”或“非思考”模式。实验结果显示，在医疗数据集上，SynapseRoute在提高准确性的同时，显著降低了推理时间和Token消耗，并避免了过度推理带来的负面影响。此外，论文还引入了AIT指数来综合评估LLM的性能与成本权衡。

> **摘要翻译:** 随着大语言模型（LLMs）在实际应用中的广泛采用，选择合适的模型不仅需要平衡性能，还需要平衡运营成本。具有推理能力的模型的出现进一步扩大了“思考”（高推理）模式和“非思考”（快速、低成本）模式之间的成本差距。在这项工作中，我们揭示了大约58%的医疗问题可以仅通过非思考模式准确回答，而无需高成本的推理过程。这突显了问题复杂性中明显的二分法，并表明根据复杂性将查询动态路由到适当的模式可以优化准确性、成本效率和整体用户体验。在此基础上，我们进一步提出了SynapseRoute，一个基于机器学习的动态路由框架，它智能地将输入查询分配给思考模式或非思考模式。在几个医疗数据集上的实验结果表明，与单独使用思考模式相比，SynapseRoute不仅提高了整体准确性（0.8390 vs. 0.8272），而且将推理时间减少了36.8%，Token消耗减少了39.66%。重要的是，定性分析表明，对更简单的查询进行过度推理可能导致不必要的延迟甚至准确性下降，而我们的自适应路由避免了这一缺陷。最后，这项工作进一步引入了准确性-推理-Token（AIT）指数，以全面评估准确性、延迟和Token成本之间的权衡。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [315] [LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users](https://arxiv.org/abs/2507.02850)
> *LLM催眠：利用用户反馈对所有用户进行未经授权的知识注入*

*Almog Hilel, Idan Shenfeld, Leshem Choshen, Jacob Andreas* | **Category: cs.CL, cs.CR, cs.LG** | **Updated: {updated}**

**Keywords:** LLM漏洞, 用户反馈, 知识注入, 偏好调优, 安全攻击

**Comment:** 

> **TL;DR:** 发现了一种通过用户反馈对LLM进行未经授权知识注入的新型漏洞，称为“LLM催眠”。

**AI_Comments:** 这项研究揭示了一种新颖且令人担忧的LLM漏洞，即通过用户反馈进行“催眠式”知识注入。其创新之处在于证明了即使是有限的反馈数据也能实现对模型行为的细粒度控制，这扩展了现有关于数据投毒和提示注入的攻击范畴。这项发现对于LLM的安全性和可靠性具有重要意义，尤其是在模型广泛应用于生成内容和辅助决策的场景中，急需业界关注并开发相应的防御机制。

<details>
  <summary>Details</summary>

**Motivation:** 描述了一种在通过用户反馈训练的语言模型中存在的漏洞，即单个用户可以通过提供提示和对LM输出进行赞成/反对反馈来持续改变LM的知识和行为。研究动机是识别并展示这种新的攻击机制。

**Method:** 攻击者提示LM随机输出“中毒”或良性响应，然后赞成中毒响应或反对良性响应。当反馈信号用于随后的偏好调优行为时，LM即使在没有恶意提示的上下文中也会增加产生中毒响应的概率。

**Result:** 该攻击可用于：1) 插入模型以前不具备的事实知识；2) 以引入可利用安全漏洞的方式修改代码生成模式；3) 注入虚假金融新闻。

**Conclusion:** 这项发现既确定了语言模型偏好调优的一个新的定性特征（表明即使是高度受限的偏好数据也可以用于对行为进行细粒度控制），也确定了一种针对通过用户反馈训练的LM的新型攻击机制（扩展了预训练时数据投毒和部署时提示注入的工作）。

> **ai_Abstract:** 本文揭示了一种名为“LLM催眠”的新型漏洞，该漏洞存在于通过用户反馈训练的语言模型中。研究表明，单个用户仅通过提供提示和赞成/反对反馈，就能持久地改变LLM的知识和行为。攻击者通过操纵反馈信号，使LM在后续的偏好调优中更有可能生成“中毒”响应，即使在非恶意上下文中也是如此。实验证明，这种攻击可以成功注入新知识、修改代码生成模式以引入安全漏洞，甚至注入虚假金融新闻。这项工作不仅揭示了偏好调优的一个新特性，还提出了一种新的LM攻击机制。

> **摘要翻译:** 我们描述了在通过用户反馈训练的语言模型（LMs）中存在的一种漏洞，即单个用户只需提供提示并对LM输出进行赞成/反对反馈，就可以持续改变LM的知识和行为。为了实施攻击，攻击者提示LM随机输出“中毒”或良性响应，然后赞成中毒响应或反对良性响应。当反馈信号用于随后的偏好调优行为时，LM即使在没有恶意提示的上下文中也会增加产生中毒响应的概率。我们展示了这种攻击可以用于（1）插入模型以前不具备的事实知识，（2）以引入可利用安全漏洞的方式修改代码生成模式，以及（3）注入虚假金融新闻。我们的发现既识别了语言模型偏好调优的一个新的定性特征（表明即使是高度受限的偏好数据也可以用于对行为进行细粒度控制），也识别了一种针对通过用户反馈训练的LM的新型攻击机制（扩展了预训练时数据投毒和部署时提示注入的工作）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [320] [Generalizing Verifiable Instruction Following](https://arxiv.org/abs/2507.02833)
> *泛化可验证的指令遵循*

*Valentina Pyatkin, Saumya Malik, Victoria Graf, Hamish Ivison, Shengyi Huang, Pradeep Dasigi, Nathan Lambert, Hannaneh Hajishirzi* | **Category: cs.CL** | **Updated: {updated}**

**Keywords:** 精确指令遵循, 泛化能力, 输出约束, 强化学习, IFBench

**Comment:** 11 pages

> **TL;DR:** 现有大型语言模型难以泛化遵循带有输出约束的指令，因为它们在现有基准测试上过拟合。本文引入了新基准IFBench和基于可验证奖励的强化学习(RLVR)，显著提高了模型对未见约束的泛化遵循能力。

**AI_Comments:** 这篇论文通过引入新的基准IFBench和创新的RLVR训练方法，有效地解决了语言模型在精确指令遵循方面泛化能力不足的关键问题。其创新点在于识别出现有模型对特定约束的过拟合现象，并提出了针对性的解决方案，特别是利用可验证奖励进行强化学习，为提升模型在复杂、多样化指令下的表现提供了新途径。发布新的数据集和代码也为后续研究提供了宝贵的资源，具有重要的实践和研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型或聊天机器人精确遵循人类指令（特别是带有输出约束的指令）的能力，是人机交互成功的关键因素。然而，即使是当前最强大的模型也难以满足这些约束，并且在现有基准测试上存在过拟合，导致对未见约束的泛化能力差。

**Method:** 引入了一个新的基准测试IFBench，包含58个新的、多样化且具有挑战性的域外可验证约束，用于评估精确指令遵循的泛化能力。此外，还设计了约束验证模块，并提出了基于可验证奖励的强化学习（RLVR）方法来训练模型，以提高指令遵循的泛化能力。研究还发布了29个额外的手动标注训练约束、验证函数、RLVR训练提示和代码。

**Result:** 研究表明，基于可验证奖励的强化学习（RLVR）显著提高了模型遵循指令的泛化能力。

**Conclusion:** 通过引入新的基准IFBench和提出RLVR训练方法，可以有效解决大型语言模型在精确指令遵循方面泛化能力不足的问题，显著提升模型对未见输出约束的遵循能力。

> **ai_Abstract:** 本文探讨了大型语言模型在遵循带有输出约束的指令时泛化能力不足的问题，指出现有模型对已知约束存在过拟合。为解决此问题，研究引入了新基准IFBench，用于评估模型对多样化未见约束的泛化能力。同时，提出了一种基于可验证奖励的强化学习（RLVR）方法，并证明其能显著提升模型的指令遵循泛化能力。研究还发布了相关训练数据和代码，以促进该领域的发展。

> **摘要翻译:** 成功的人工智能与人类交互的一个关键因素是语言模型或聊天机器人精确遵循人类指令的能力。指令的一个常见特征是用户为了获得更有用答案而添加的输出约束，例如“只回答是或否”或“至少提及‘abrakadabra’这个词3次”。即使是当今最强大的模型也难以满足这些约束。我们发现，大多数模型在测试这些能力的基准测试中，对一小部分可验证约束存在严重的过拟合，这种能力被称为精确指令遵循，并且无法很好地泛化到未见的输出约束。我们引入了一个新的基准测试IFBench，用于评估58个新的、多样化且具有挑战性的域外可验证约束上的精确指令遵循泛化能力。此外，我们对模型如何以及在什么数据上进行训练才能提高精确指令遵循泛化能力进行了广泛分析。具体来说，我们精心设计了约束验证模块，并表明基于可验证奖励的强化学习（RLVR）显著提高了指令遵循能力。除了IFBench，我们还发布了29个额外的手动标注训练约束和验证函数、RLVR训练提示以及代码。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [330] [Answer Matching Outperforms Multiple Choice for Language Model Evaluation](https://arxiv.org/abs/2507.02856)
> *答案匹配优于多项选择用于语言模型评估*

*Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 答案匹配, 语言模型评估, 多项选择, 生成式评估, 人工智能评估

**Comment:** 34 pages, Code is available at
  https://github.com/nikhilchandak/answer-matching

> **TL;DR:** 本文提出了一种名为“答案匹配”的语言模型评估新方法，通过让模型生成自由形式的回答，然后使用另一个语言模型与参考答案进行匹配来评分。研究表明，与多项选择或不带参考答案的LLM作为评判者相比，答案匹配与人类评分的一致性更高，并且能显著改变模型排名。

**AI_Comments:** 本文创新性地提出了“答案匹配”这一评估范式，有效解决了传统多项选择评估中存在的模型作弊和评估不准确的问题。通过引入生成式评估和基于LLM的匹配机制，提高了评估与人类判断的一致性，并揭示了模型真实能力和排名。这项工作对于推动语言模型评估方法的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多项选择基准长期以来是语言模型评估的主力，但存在严重缺陷，即模型即使不看问题也能通过捷径作答。这种局限性源于判别式评估的根本缺陷，而生成式评估则没有。此前，缺乏可行的、可扩展的多项选择替代方案。

**Method:** 提出“答案匹配”的生成式评估方法：将问题不带选项地提供给候选模型，让其生成自由形式的响应，然后使用现代语言模型结合参考答案来判断响应是否匹配。为了比较评估策略的有效性，作者对MMLU-Pro和GPQA-Diamond进行了人工标注，以获取人工评分数据，并测量了每种评估方法与人工评分的一致性。

**Result:** 研究发现，使用近期模型（甚至是小型模型）的答案匹配方法能达到接近完美的一致性，与标注者间的一致性范围相当。相比之下，多项选择评估和不带参考答案的LLM作为评判者的方法与人工评分的一致性较差。通过答案匹配改进评估不仅仅是概念上的关注：当使用答案匹配评估模型的自由形式响应时，几个模型的排名显著改变。

**Conclusion:** 答案匹配是一种比传统多项选择评估更有效、更准确的语言模型评估方法，它能更好地与人类判断保持一致，并揭示出模型性能的真实排名。未来语言模型评估生态系统应从多项选择转向答案匹配。

> **ai_Abstract:** 本研究提出了一种名为“答案匹配”的语言模型评估新范式，旨在克服传统多项选择评估的局限性。作者指出，多项选择题存在模型不看问题也能作答的捷径问题。答案匹配通过让模型生成自由形式的回答，并利用另一个语言模型与参考答案进行匹配来判断正确性。通过对MMLU-Pro和GPQA-Diamond数据集的人工标注对比，研究发现答案匹配与人类评分的一致性远高于多项选择和基于LLM的无参考答案判断。此外，采用答案匹配评估显著改变了现有模型的排名，表明其在提供更真实、有效评估方面的潜力。研究呼吁将语言模型评估重心从多项选择转向答案匹配。

> **摘要翻译:** 多项选择基准长期以来一直是语言模型评估的主力，因为多项选择的评分是客观且易于自动化的。然而，我们发现流行基准中的多项选择题通常在甚至没有看到问题的情况下就能被回答。这些捷径源于判别式评估的一个根本局限性，而模型的自由形式生成式回答评估则没有这个局限性。直到最近，似乎还没有多项选择的可行、可扩展的替代方案——但我们表明这种情况已经改变。我们考虑通过我们称之为“答案匹配”的方法进行生成式评估：将问题不带选项地提供给候选模型，让它生成自由形式的响应，然后使用一个现代语言模型与参考答案来确定响应是否匹配参考答案。为了比较不同评估策略的有效性，我们对MMLU-Pro和GPQA-Diamond进行了标注，以获取人工评分数据，并测量了每种评估方法的一致性。我们发现使用最新模型（甚至是小型模型）的答案匹配方法达到了接近完美的一致性，与标注者间的一致性范围相当。相比之下，多项选择评估和不带参考答案的LLM作为评判者的方法与人工评分的一致性较差。通过答案匹配改进评估不仅仅是概念上的关注：当使用答案匹配评估模型的自由形式响应时，几个模型的排名显著改变。鉴于这些发现，我们讨论了如何将评估生态系统从多项选择转向答案匹配。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [25] [New algorithms for girth and cycle detection](https://arxiv.org/abs/2507.02061)
> *图的周长和环检测的新算法*

*Liam Roditty, Plia Trabelsi* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 图算法, 周长, 环检测, 随机算法, 稀疏图

**Comment:** 

> **TL;DR:** 提出了新的随机算法，用于在无向图中检测环并估计周长，通过引入实值参数提高了现有算法的灵活性和性能。

**AI_Comments:** 该论文的创新点在于通过引入实值参数 $\ell - \varepsilon$ 泛化了现有图算法，这显著增加了算法在运行时间和输出质量之间的灵活性，允许更精细的调整。此外，论文为稀疏图提供了优化，并引入了“混合环检测算法”的正式定义，这可能对未来的图算法研究产生影响。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在泛化现有算法（如Kadria等人的工作），通过引入实值参数来提高参数选择的灵活性，从而实现运行时间和环长度之间更广泛的组合。此外，也致力于为稀疏图提供更好的性能权衡。

**Method:** 本文提出了新的随机算法，并开发了多种技术，包括引入混合环检测算法的正式定义。

**Result:** 1. 对于周长 $g = polylog(n)$ 的图，提出了一种运行时间为 $	ilde{O}(\ell \cdot n^{1 + \frac{1}{\ell - \varepsilon}})$ 的随机算法，该算法返回一个长度至多为 $2\ell \left\lceil \frac{g}{2} \right\rceil - 2 \left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil \right\rfloor$ 的环。2. 该算法泛化了Kadria等人（SODA'22）的两种算法，特别是通过将运行时间指数中的整数参数 $\ell$ 替换为实值参数 $\ell - \varepsilon$，提供了更大的参数选择灵活性。3. 对于稀疏图，提出了一种运行时间为 $	ilde{O}(\ell\cdot m^{1+1/(\ell-\varepsilon)})$ 的随机算法，该算法返回一个长度至多为 $2\ell(\lfloor \frac{g-1}{2}\rfloor) - 2(\lfloor \varepsilon \lfloor \frac{g-1}{2}\rfloor \rfloor+1)$ 的环。

**Conclusion:** 本文提出的新算法在无权无向图的环检测和周长估计方面提供了改进的性能和更大的灵活性，通过泛化现有算法和引入实值参数，实现了运行时间和环长度之间更广泛的组合。此外，还为稀疏图提供了更优的权衡。

> **ai_Abstract:** 本文提出了用于无权无向图环检测和周长估计的新随机算法。这些算法通过引入实值参数，泛化了现有工作（如Kadria等人的算法），从而在运行时间和找到的环长度之间提供了更大的灵活性和更广泛的权衡组合。文章详细描述了新算法在不同图密度下的性能，并介绍了开发这些算法所采用的新技术，包括混合环检测算法的正式定义。

> **摘要翻译:** 设 $G=(V,E)$ 是一个具有 $n$ 个顶点和 $m$ 条边的无权无向图。设 $g$ 是 $G$ 的周长，即 $G$ 中最短环的长度。我们提出了一种随机算法，其运行时间为 $\tilde{O}\big(\ell \cdot n^{1 + \frac{1}{\ell - \varepsilon}}\big)$，该算法返回一个长度至多为 $2\ell \left\lceil \frac{g}{2} \right\rceil - 2 \left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil \right\rfloor$ 的环，其中 $\ell \geq 2$ 是一个整数，$\varepsilon \in [0,1]$，适用于所有 $g = polylog(n)$ 的图。
我们的算法泛化了Kadria \etal{} [SODA'22] 的一种算法，该算法以 $\tilde{O}\big(n^{1 + \frac{1}{2 - \varepsilon}}\big)$ 的时间计算长度至多为 $4\left\lceil \frac{g}{2} \right\rceil - 2\left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil \right\rfloor$ 的环。Kadria \etal{} 还提出了一种算法，以 $\tilde{O}\big(n^{1 + \frac{1}{\ell}}\big)$ 的时间找到长度至多为 $2\ell \left\lceil \frac{g}{2} \right\rceil$ 的环，其中 $\ell$ 必须是整数。我们的算法也泛化了该算法，通过将运行时间指数中的整数参数 $\ell$ 替换为实值参数 $\ell - \varepsilon$，从而在参数选择上提供了更大的灵活性，并实现了运行时间和环长度之间更广泛的组合。
我们还表明，对于稀疏图，可以通过提出一种运行时间为 $\tilde{O}(\ell\cdot m^{1+1/(\ell-\varepsilon)})$ 的随机算法来实现更好的权衡，该算法返回一个长度至多为 $2\ell(\lfloor \frac{g-1}{2}\rfloor) - 2(\lfloor \varepsilon \lfloor \frac{g-1}{2}\rfloor \rfloor+1)$ 的环，其中 $\ell\geq 3$ 是一个整数，$\varepsilon\in [0,1)$，适用于所有 $g=polylog(n)$ 的图。
为了获得我们的算法，我们开发了几种技术，并引入了混合环检测算法的正式定义。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [54] [A Computational Proof of the Highest-Scoring Boggle Board](https://arxiv.org/abs/2507.02117)
> *最高得分Boggle棋盘的计算证明*

*Dan Vanderkam* | **Category: cs.DS, I.2.8, E.1** | **Updated: {updated}**

**Keywords:** Boggle, 分支定界, 全局优化, 计算证明, 爬山法

**Comment:** 14 pages, 2 figures, code available at
  https://github.com/danvk/hybrid-boggle/

> **TL;DR:** 本文计算证明了Boggle棋盘的最高得分。

**AI_Comments:** 本文的创新之处在于首次对Boggle棋盘的全局最优解进行了穷尽搜索，解决了之前被认为难以处理的问题。其重要性在于通过计算证明了先前通过启发式方法（如爬山法）找到的高分棋盘确实是全局最优解，从而验证了局部优化技术的有效性。

<details>
  <summary>Details</summary>

**Motivation:** Boggle棋盘的巨大数量使得穷尽搜索全局最优解在历史上是不可能的，因此需要找到最高得分的Boggle棋盘并进行证明。

**Method:** 本文应用分支定界（Branch and Bound）算法和一种类似决策图的数据结构，首次对Boggle棋盘进行了穷尽搜索。

**Result:** 研究发现，之前通过爬山算法（hillclimbing）找到的最高得分棋盘确实是全局最优解。

**Conclusion:** 通过计算搜索证实了之前通过局部优化技术找到的最高得分Boggle棋盘确实是全局最优解。

> **ai_Abstract:** 本文旨在解决寻找Boggle棋盘全局最高得分的问题，该问题因搜索空间巨大而此前无法穷尽。通过应用分支定界算法和一种类似决策图的数据结构，作者首次进行了穷尽搜索，并计算证明了通过爬山法等局部优化技术找到的最高得分棋盘确实是全局最优解。

> **摘要翻译:** 在Boggle棋盘上找到所有单词是一个经典的计算机编程问题。利用快速的Boggle解算器，可以应用爬山法和模拟退火等局部优化技术来寻找得分特别高的棋盘。然而，Boggle棋盘的巨大数量在历史上阻碍了对全局最优棋盘进行穷尽搜索。我们应用分支定界（Branch and Bound）和一种类似决策图的数据结构，首次进行了这种搜索。我们发现，通过爬山法找到的最高得分棋盘实际上就是全局最优解。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [78] [On the Adversarial Robustness of Online Importance Sampling](https://arxiv.org/abs/2507.02394)
> *在线重要性采样的对抗鲁棒性*

*Yotam Kenneth-Mordoch, Shay Sapir* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 在线重要性采样, 对抗鲁棒性, 自适应流, 超图割稀疏化, $\ell_p$ 子空间嵌入

**Comment:** 

> **TL;DR:** 本文研究了在线重要性采样在对抗性输入流下的鲁棒性，证明其能保持近似精度并匹配存储效率，并应用于超图割稀疏化和Lp子空间嵌入。

**AI_Comments:** 本文的创新点在于首次证明了在线重要性采样在面对对抗性（自适应）输入流时的鲁棒性，这解决了随机算法在此类复杂输入环境下分析困难的挑战。其理论结果不仅具有重要意义，还通过应用于超图割稀疏化和 $\ell_p$ 子空间嵌入等实际问题，展示了其广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统随机算法（特别是重要性采样）的分析在面对适应性变化的输入流（对抗性输入）时会失效。之前的工作虽然提出重要性采样可能具有对抗鲁棒性，但仅限于良好行为的输入。本文旨在研究在线重要性采样在这种更具挑战性的对抗性环境下的鲁棒性。

**Method:** 本文关注在线重要性采样，即采样决策在数据到达时不可撤销地做出。主要技术结果是证明了对于适应性输入流，在线重要性采样能够维持对其和的 $(1\pm\epsilon)$-近似，同时在存储方面与非适应性情况的保证相匹配。随后，将此结果应用于开发针对超图割稀疏化和 $\ell_p$ 子空间嵌入这两个基本问题的对抗鲁棒在线算法。

**Result:** 结果表明，对于适应性输入流，在线重要性采样能够维持对其和的 $(1\pm\epsilon)$-近似，并且在存储保证上与非适应性（非自适应）情况相匹配（仅有低阶项差异）。

**Conclusion:** 本文证明了在线重要性采样在对抗性输入流下的鲁棒性，解决了其在适应性输入下分析失效的问题，并将其成功应用于重要的图论和线性代数问题，为构建对抗鲁棒的在线算法提供了基础。

> **ai_Abstract:** 本文探讨了在线重要性采样在对抗性输入流下的鲁棒性问题。传统的重要性采样算法在面对自适应变化的数据流时分析会失效。作者证明了在线重要性采样（即时且不可撤销的采样决策）对于自适应输入流，能够维持对其总和的近似精度，并保持与非自适应情况相当的存储效率。此研究成果进一步应用于开发了超图割稀疏化和 $\ell_p$ 子空间嵌入的对抗鲁棒在线算法。

> **摘要翻译:** 本文研究了重要性采样（又称敏感性采样）的对抗鲁棒性；这是一种有用的算法技术，它以与元素重要性度量成比例的概率对元素进行采样。如果流式或在线算法在输入流可能根据之前的算法输出自适应变化的情况下，仍能以高概率成功，则称其具有对抗鲁棒性。不幸的是，流元素之间的依赖关系破坏了大多数随机算法的分析，特别是重要性采样算法的分析。此前，Braver曼等人 [NeurIPS 2021] 提出基于重要性采样的流式算法可能具有对抗鲁棒性；然而，他们只对行为良好的输入证明了这一点。
我们专注于在线重要性采样的对抗鲁棒性，这是一种自然的变体，其中采样决策是不可撤销的，并在数据到达时做出。我们的主要技术结果表明，给定一个由元素 $x_1,\ldots,x_T\in \mathbb{R}_+$ 组成的自适应流作为输入，在线重要性采样能够维持对其和的 $(1\pm\epsilon)$-近似，同时在存储保证方面与非自适应（非适应性）情况相匹配（仅有低阶项差异）。然后，我们将此结果应用于开发针对两个基本问题的对抗鲁棒在线算法：超图割稀疏化和 $\ell_p$ 子空间嵌入。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [102] [Numerical Linear Algebra in Linear Space](https://arxiv.org/abs/2507.02433)
> *线性空间中的数值线性代数*

*Yiping Liu, Hoai-An Nguyen, Junzhao Yang* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 线性系统, 数值线性代数, 线性空间, 随机算法, 近似求解

**Comment:** 52 pages, 0 figures

> **TL;DR:** 本文提出了一种用于求解一般线性系统的新型随机线性空间求解器，该求解器在时间和空间复杂度上均表现高效，并且适用于多种数值线性代数问题。

**AI_Comments:** 本文提出了一种在有理数域上解决线性系统的新颖方法，其主要创新在于实现了线性空间复杂度和高效的时间复杂度，且无需条件数假设。这对于处理大规模线性系统具有重要意义，尤其是在内存受限的环境中。此外，其在多个数值线性代数问题中的应用潜力也突显了该方法的普适性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有线性系统求解器在空间或时间效率上存在局限性，尤其是在不假设条件数的情况下。本文旨在开发一种在有理数域上具有高效时间和线性空间复杂度的通用线性系统求解器。

**Method:** 本文提出了一种随机线性空间求解器，用于求解一般线性系统 $\mathbf{A} \mathbf{x} = \mathbf{b}$。该求解器不需要对矩阵 $\mathbf{A}$ 的条件数进行任何假设。

**Result:** 对于条目由 $\mathrm{poly}(n)$ 界定的矩阵，该求解器能返回向量 $\mathbf{x} \in \mathbb{Q}^{n}$ 的 $(1+\epsilon)$-乘法逐条近似值。其使用 $\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ 位操作和 $O(n \log n)$ 位工作空间（即与向量大小呈线性关系）。该求解器适用于条目高达 $n^{O(n)}$ 的右侧向量 $\mathbf{b}$。据作者所知，这是第一个在有理数域上以 $\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ 时间运行的线性空间线性系统求解器。此外，该求解器还应用于线性回归、线性规划、特征值和特征向量以及奇异值分解等数值线性代数问题，并提供了具有高效多项式运行时间和近线性空间的算法。

**Conclusion:** 本文成功开发了一种高效的随机线性空间求解器，用于解决一般线性系统，并在有理数域上实现了时间和空间复杂度的显著改进。该方法还被证明适用于多种数值线性代数问题。

> **ai_Abstract:** 本文介绍了一种新型随机线性空间求解器，用于解决一般线性系统 $\mathbf{A} \mathbf{x} = \mathbf{b}$，该求解器无需对条件数进行假设。它能在 $\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ 位操作和 $O(n \log n)$ 位线性工作空间下，为条目受限的矩阵提供 $(1+\epsilon)$-乘法逐条近似解。该求解器是首个在有理数域上实现此效率的线性空间求解器，并被成功应用于线性回归、线性规划、特征值分解和奇异值分解等数值线性代数问题，展示了其高效性和普适性。

> **摘要翻译:** 我们提出了一种用于求解一般线性系统 $\mathbf{A} \mathbf{x} = \mathbf{b}$ 的随机线性空间求解器，其中 $\mathbf{A} \in \mathbb{Z}^{n \times n}$ 且 $\mathbf{b} \in \mathbb{Z}^n$，无需对 $\mathbf{A}$ 的条件数做任何假设。对于条目由 $\mathrm{poly}(n)$ 界定的矩阵，该求解器使用 $\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ 位操作和 $O(n \log n)$ 位工作空间（即与向量大小呈线性关系）返回向量 $\mathbf{x} \in \mathbb{Q}^{n}$ 的 $(1+\epsilon)$-乘法逐条近似值，其中 $\mathrm{nnz}$ 表示非零条目数。我们的求解器适用于条目高达 $n^{O(n)}$ 的右侧向量 $\mathbf{b}$。据我们所知，这是第一个在有理数域上以 $\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ 时间运行的线性空间线性系统求解器。
我们还将我们的求解器应用于数值线性代数问题，为此我们提供了具有高效多项式运行时间和近线性空间的算法。特别是，我们提出了线性回归、线性规划、特征值和特征向量以及奇异值分解的结果。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [127] [Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower Bounds](https://arxiv.org/abs/2507.02548)
> *有界加权编辑距离：动态算法和匹配下界*

*Itai Boneh, Egor Gorbachev, Tomasz Kociumaka* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 加权编辑距离, 动态算法, 下界, 字符串算法, 时间复杂度

**Comment:** ESA 2025

> **TL;DR:** 本文提出了一种有界加权编辑距离的动态算法，具有时间-空间权衡，并提供了匹配的下界。

**AI_Comments:** 本文通过为加权编辑距离（比无加权或小整数加权版本更通用和复杂）提供动态算法，做出了重要贡献。引入权衡参数 $\gamma$ 和建立条件性下界以证明最优性是关键创新，提供了灵活性和理论保证。这项工作填补了动态字符串算法在处理大权重和有界距离情况下的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有计算加权编辑距离的动态算法不适用于大权重，且传统方法时间复杂度高。本文旨在为动态变化的字符串维护加权编辑距离，以在距离较小时实现更优的运行时间。

**Method:** 本文提出了一种动态算法来维护有界加权编辑距离 $ed^w(X,Y)$。该算法在预处理时间 $	ilde{O}(nk^\gamma)$ 后，每次更新时间为 $	ilde{O}(k^{3-\gamma})$，其中 $\gamma\in [0,1]$ 是一个实数权衡参数，$k$ 是预处理时固定的整数阈值。当距离超过 $k$ 时，算法返回无穷大。此外，作者还提供了条件性下界来证明算法的精细最优性。

**Result:** 开发了一种动态算法，在 $\tilde{O}(nk^\gamma)$ 预处理时间后，以 $\tilde{O}(k^{3-\gamma})$ 时间维护 $ed^w(X,Y)$。此外，为 $\gamma \in [0.5,1)$ 范围内的权衡建立了条件性下界，证明了算法的精细最优性并验证了固定 $k$ 的选择。

**Conclusion:** 本文为有界加权编辑距离问题提供了一种新颖的动态算法，该算法具有最优的时间-空间权衡，并通过匹配的下界得到了支持，填补了动态算法在处理大权重时的空白。

> **ai_Abstract:** 本文提出了一种用于维护两个字符串之间有界加权编辑距离的动态算法。该算法提供了一种时间-空间权衡，在 $\tilde{O}(nk^\gamma)$ 预处理时间后，实现 $\tilde{O}(k^{3-\gamma})$ 的更新时间，其中 $k$ 是距离阈值，$\gamma \in [0,1]$ 是一个权衡参数。这项工作解决了现有动态算法在处理大权重时的局限性，并提供了匹配的条件性下界以证明其方法的普适性和最优性。

> **摘要翻译:** 编辑距离 $ed(X,Y)$ 是将字符串 $X$ 转换为 $Y$ 所需的字符编辑（插入、删除和替换）的最小数量。其加权对应物 $ed^w(X,Y)$ 最小化编辑的总成本，该成本使用函数 $w$ 指定，并标准化为每次编辑至少花费一。教科书式的动态规划过程，给定字符串 $X,Y\in \Sigma^{\le n}$ 和对 $w$ 的预言访问，以 $O(n^2)$ 时间计算 $ed^w(X,Y)$。然而，如果计算出的距离 $k$ 很小，则可以实现更好的运行时间：对于单位权重为 $O(n+k^2)$ [Landau 和 Vishkin; JCSS'88]，对于任意权重为 $\tilde{O}(n+\sqrt{nk^3})$ [Cassis, Kociumaka, Wellnitz; FOCS'23]。
在本文中，我们研究了加权编辑距离问题的动态版本，其目标是维护随时间变化的字符串 $X,Y\in \Sigma^{\le n}$ 的 $ed^w(X,Y)$，每次更新都指定为 $X$ 或 $Y$ 中的一次编辑。最近，Gorbachev 和 Kociumaka [STOC'25] 表明，无加权距离 $ed(X,Y)$ 可以在 $\tilde{O}(n+k^2)$ 预处理时间后，以每次更新 $\tilde{O}(k)$ 时间维护；其中 $k$ 表示当前 $ed(X,Y)$ 的值。他们的算法可以推广到小整数权重，但其底层方法与大权重不兼容。
我们的主要结果是一种动态算法，它在 $\tilde{O}(nk^\gamma)$ 预处理时间后，以每次更新 $\tilde{O}(k^{3-\gamma})$ 时间维护 $ed^w(X,Y)$。其中，$\gamma\in [0,1]$ 是一个实数权衡参数，$k\ge 1$ 是在预处理时固定的整数阈值，当 $ed^w(X,Y)>k$ 时返回 $\infty$。我们用条件性下界补充了我们的算法，这些下界表明了我们的权衡在 $\gamma \in [0.5,1)$ 范围内的精细最优性，并证明了我们固定 $k$ 的选择是合理的。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [148] [On the Complexity of Knapsack under Explorable Uncertainty: Hardness and Algorithms](https://arxiv.org/abs/2507.02657)
> *探索不确定性下背包问题的复杂性：硬度和算法*

*Jens Schlöter* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 探索不确定性, 背包问题, 计算复杂性, 查询最小化, Sigma_2^p完全

**Comment:** 

> **TL;DR:** 本文研究了探索不确定性下背包问题的复杂性，发现其离线变体是Sigma_2^p完全的且难以近似，但资源增强变体允许有效的算法。

**AI_Comments:** 这篇论文深入探讨了探索不确定性下背包问题的计算复杂性，特别是在查询受限的环境中。其创新点在于识别了离线变体的高难度（Sigma_2^p完全性），并提出了资源增强模型作为解决该难题的有效途径。这对于理解不确定性优化问题的理论界限和设计实用算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在探索不确定性下背包问题中，目标是最小化查询次数以获取足够信息来计算最优或近似解。由于该问题的离线变体被证明具有很强的计算硬度（Sigma_2^p完全且难以近似），因此有必要探索能够得到有效算法的变体，从而引入了资源增强的设置。

**Method:** 论文首先分析了探索不确定性下背包问题的离线变体，通过计算复杂性理论证明了其是Sigma_2^p完全的且难以近似。随后，提出并研究了一种资源增强的变体，其中算法计算的查询集只需识别近似解，而最优查询集需识别最优解，并在此设置下寻找有效的算法。

**Result:** 离线变体被证明是Sigma_2^p完全的，并且除非Sigma_2^p = Delta_2^p，否则无法在非平凡因子内近似。资源增强的设置允许得到有趣的非平凡算法结果。

**Conclusion:** 探索不确定性下背包问题的离线变体具有很高的计算复杂性，但在资源增强的设置下，通过放宽对解决方案精度的要求，可以获得有效的算法。

> **ai_Abstract:** 本文研究了探索不确定性下背包问题的计算复杂性，其中物品利润以不确定性区间形式给出并通过查询获取。目标是最小化查询次数以识别最优或近似解。研究发现，该问题的离线变体是Sigma_2^p完全的，并且在近似方面具有很强的硬度。为了应对这一挑战，论文提出并分析了一个资源增强的变体，其中算法只需识别近似解，而最优解需识别最优解，并证明此设置下可获得非平凡的算法结果。

> **摘要翻译:** 在探索不确定性下的背包问题中，我们得到了一个具有不确定物品利润的背包实例。我们无法直接获取精确的利润，而只知道包含对应利润的不确定性区间。实际的物品利润可以通过查询获得。问题的目标是自适应地查询物品利润，直到揭示的信息足以计算底层背包实例的最优（或近似）解。由于查询成本高昂，目标是最小化查询次数。
在该问题的离线变体中，我们假设已知精确利润，任务是计算一个最小基数的查询集，该查询集可供无法获取利润的第三方用于识别最优（或近似）背包解。我们证明这个离线变体对于多项式层级的第二层是完全的，即$\\Sigma_2^p$-完全的，并且除非$\\Sigma_2^p = \\Delta_2^p$，否则无法在非平凡因子内近似。受这些强硬度结果的启发，我们考虑了该问题的一个资源增强变体，其中算法计算的查询集的要求比我们比较的最优解的要求不那么严格。更精确地说，算法计算的查询集必须揭示足够的信息以识别一个近似背包解，而我们比较的最优查询集必须揭示足够的信息以识别一个最优解。我们表明，这种资源增强的设置允许有趣的非平凡算法结果。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [169] [Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance Regime](https://arxiv.org/abs/2507.02701)
> *低距离区间内有界树编辑距离的更快算法*

*Tomasz Kociumaka, Ali Shahali* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 树编辑距离, 有界距离, 算法, 周期性结构, 低距离区间

**Comment:** Accepted to ESA 2025

> **TL;DR:** 本文提出了一种针对有界树编辑距离的更快算法，在加权和无权情况下均达到了O(n + k^6 log k)的时间复杂度，通过利用周期性结构改进了现有算法的性能。

**AI_Comments:** 该论文的创新之处在于利用了“输入树中的周期性结构”并修改了通用核，这是一种在低距离范围内进行优化的巧妙方法。K的指数（加权情况下从k^15到k^6，无权情况下从k^7到k^6）的显著改进表明了针对该特定问题变体的重大算法突破。这对于涉及大型、几乎相同的树结构的应用尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前树编辑距离算法的超二次方运行时间对于大型但非常相似的树来说效率低下，这促使研究有界版本的问题，其中运行时间由计算出的距离k参数化，旨在为k远小于n的情况提供更快的算法。

**Method:** 作者首先提出了一种替代的O(nk^2 log n)时间算法，该算法能够处理权重且比现有算法更容易分析。接着，他们引入了一种新颖的优化方法，利用输入树中的周期性结构。为了实现这一点，他们修改了先前算法核心组件——O(k^5)大小的O(n)时间通用核，使其能够生成包含这些周期性结构的实例。

**Result:** 本文提出了一种O(n + k^6 log k)时间的算法，用于计算加权和无权设置下的有界树编辑距离。这显著优于先前无权设置下的O(nk^2 log n)和O(n + k^7 log k)算法，以及加权设置下唯一的O(n + k^15)算法。

**Conclusion:** 本文成功开发了一种针对加权和无权有界树编辑距离的显著更快的算法，使其在处理大型且相似的树时更加高效。

> **ai_Abstract:** 本文提出了一种用于计算有界树编辑距离的新算法，适用于加权和无权树。通过引入一种更易于分析的O(nk^2 log n)算法和一种利用树中周期性结构的新优化方法，作者实现了显著改进的O(n + k^6 log k)运行时间，超越了先前的最先进算法，尤其适用于距离较小的大型树。

> **摘要翻译:** 树编辑距离是一种衡量根有序树之间差异的自然度量，其节点标签来自字母表$\\Sigma$。它被定义为将一棵树转换为另一棵树所需的最小节点编辑次数（插入、删除和重新标记）。在加权变体中，编辑操作具有相关的成本（取决于所涉及的节点标签），并标准化使得每个成本至少为一，目标是最小化编辑的总成本。
两个总大小为$n$的树之间的无权树编辑距离可以在$O(n^{2.6857})$时间内计算；相比之下，确定加权树编辑距离与全对最短路径问题在细粒度上是等价的，需要$n^3/2^{\\Omega(\\sqrt{\\log n})}$时间 [Nogler et al.; STOC'25]。这些超二次方运行时间对于大型但非常相似的树来说不具吸引力，这促使了该问题的有界版本，其中运行时间由计算出的距离$k$参数化，可能为$k\\ll n$的情况提供更快的算法。
先前针对有界无权设置的最佳算法运行时间为$O(nk^2\\log n)$ [Akmal & Jin; ICALP'21] 和 $O(n + k^7\\log k)$ [Das et al.; STOC'23]。对于加权变体，唯一已知的运行时间是$O(n + k^{15})$。
我们提出了一种$O(n + k^6\\log k)$时间的算法，用于计算加权和无权设置下的有界树编辑距离。我们的方法首先提出了一种替代的$O(nk^2\\log n)$时间算法，该算法能够处理权重并且比现有对应算法更容易分析。然后，我们引入了一种新颖的优化方法，该方法利用输入树中的周期性结构。为了利用它，我们修改了$O(k^5)$大小的$O(n)$时间通用核，这是先前$O(n + k^{O(1)})$时间算法的核心组件，使其能够生成包含这些周期性结构的实例。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [188] [Indexing Tries within Entropy-Bounded Space](https://arxiv.org/abs/2507.02728)
> *在熵界空间内索引Trie树*

*Lorenzo Carfagna, Carlo Tosoni* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** Trie树索引, BWT, 熵, 空间复杂度, FM-index

**Comment:** 14 pages, 1 figure, submitted to SPIRE 2025

> **TL;DR:** 本文研究了一种基于BWT的方法来索引和压缩Trie树，并证明了其在熵界空间内的存储效率。

**AI_Comments:** 这篇论文在数据结构和算法领域，特别是在压缩数据结构方面具有创新性。它将BWT和FM-index的思想扩展到Trie树，并引入了针对Trie树的熵度量，为分析Trie树的压缩性能提供了理论基础。证明了其空间复杂度能够达到理论下限，并与现有技术进行对比，显示出其潜在的优势，这对于处理大规模文本数据和基因组数据中的Trie树索引具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究如何使用基于BWT的方法对Trie树进行高效的索引和压缩，并分析其空间复杂度，特别是如何构建类似字符串FM-index的Trie树索引以高效计数模式。

**Method:** 1. 考虑了Ferragina等人提出的XBWT的简洁压缩表示，作为Trie树的FM-index的类比。2. 提出了一个计算给定符号分布下Trie树数量的组合问题的证明。3. 利用该公式定义了Trie树的最坏情况熵度量和k阶经验熵概念。4. 证明了Trie树的XBWT可以在k阶经验熵加上一个o(n)项的空间内编码。5. 将其空间复杂度与Prezza提出的r-index进行了比较。

**Result:** 1. 该表示允许高效地计算给定字符串模式达到的节点数。2. Trie树的XBWT可以在k阶经验熵加上一个o(n)项的空间内编码，且该空间界限对于每个足够小的k可以同时达到。3. 在某些情况下，Trie树的FM-index渐近地小于Trie树的r-index。

**Conclusion:** 本文成功地研究了在熵界空间内索引和压缩Trie树的问题，通过引入新的熵度量并证明了基于XBWT的Trie树索引在空间效率上的优势，尤其是在某些情况下优于现有的r-index。

> **ai_Abstract:** 本文提出了一种基于BWT的Trie树索引和压缩方法，即XBWT的简洁表示，其功能类似于Trie树的FM-index，能够高效地计数模式匹配的节点。为了分析其空间复杂度，作者推导了Trie树数量的组合公式，并基于此定义了Trie树的熵度量和k阶经验熵。研究证明，该XBWT索引能在k阶经验熵加o(n)的空间内编码，并且在某些情况下，其空间效率优于现有的r-index。

> **摘要翻译:** 我们研究了使用基于BWT的方法对Trie树进行索引和压缩的问题。具体来说，我们考虑了Ferragina等人[FOCS '05, JACM '09]的XBWT的一种简洁压缩表示，它对应于Trie树的FM-index [FOCS '00, JACM '05]的类比。这种表示允许高效地计算给定字符串模式到达的节点数量。为了分析上述Trie树索引的空间复杂度，我们提出了一个计算给定符号分布下Trie树数量的组合问题的证明。我们使用这个公式来定义Trie树的最坏情况熵度量，以及k阶经验熵的概念。特别是，我们表明这两种熵度量之间的关系类似于字符串相应已知度量之间的关系。我们使用这些度量来证明Trie树的XBWT可以在我们的k阶经验熵加上一个o(n)项的空间内编码，其中n是Trie树中的节点数。值得注意的是，与字符串一样，这个空间界限可以同时达到每个足够小的k。最后，我们将上述索引的空间复杂度与Prezza [SODA '21]提出的Trie树的r-index进行了比较，并证明在某些情况下Trie树的FM-index渐近地更小。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [203] [Connected k-Median with Disjoint and Non-disjoint Clusters](https://arxiv.org/abs/2507.02774)
> *连通k-中位数问题：分离与非分离簇*

*Jan Eube, Kelin Luo, Dorian Reineccius, Heiko Röglin, Melanie Schmidt* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 连通k-中位数, 聚类, 近似算法, 硬度, 重叠簇

**Comment:** To appear in ESA 2025

> **TL;DR:** 本文研究连通k-中位数问题，特别是重叠簇变体，提出了一个近似算法和相应的硬度结果。

**AI_Comments:** 本文的创新之处在于首次系统地研究了连通k-中位数问题中的重叠簇变体，并为其提供了有效的近似算法，这对于社区检测等实际应用具有重要意义。同时，通过给出全面的硬度结果，界定了问题的计算复杂性。方法的严谨性和结果的完整性是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 连通k-中位数问题结合了基于距离的k-聚类和连通性信息，在大地测量学（特别是区域划分）、社交网络分析（特别是社区检测）和生物信息学等不同领域有应用。研究重叠簇的版本对于社区检测用例来说是自然的。

**Method:** 本文提出了一个针对重叠簇连通k-中位数问题的近似算法。同时，对于无重叠（分离簇）的情况，给出了一个硬度结果，并且当连通图是树时，提供了一个精确算法。

**Result:** 对于重叠簇的连通k-中位数问题，提出了一个$\mathcal{O}(k^2 \log n)$-近似算法。对于无重叠（分离簇）且具有一般连通图的情况，得到了一个$\Omega(n^{1-\epsilon})$-硬度结果。此外，当连通图为树时，对于分离簇的情况给出了一个精确算法。

**Conclusion:** 本文为连通k-中位数问题，特别是重叠簇变体，提供了重要的算法和硬度结果，解决了实际应用中（如社区检测）重叠现象的挑战。

> **ai_Abstract:** 本文研究连通k-中位数问题，该问题结合了距离聚类和图连通性，并在地理、社交网络和生物信息学等领域有应用。特别关注重叠簇的变体，提出了一种$\mathcal{O}(k^2 \log n)$-近似算法，解决了其$\Omega(\log n)$-近似难度的挑战。同时，对于分离簇的情况，证明了$\Omega(n^{1-\epsilon})$-硬度，并为连通图是树的情况设计了一个精确算法，全面分析了该问题的不同设置。

> **摘要翻译:** 连通k-中位数问题是一个受限的聚类问题，它将基于距离的k-聚类与连通性信息相结合。该问题允许输入一个度量空间和一个与度量空间完全无关的无权无向连通图。目标是计算k个中心和相应的簇，使得每个簇都形成G的连通子图，并且k-中位数成本最小化。
该问题在测地学（特别是区域划分）、社交网络分析（特别是社区检测）或生物信息学等非常不同的领域都有应用。我们研究了一个带有重叠簇的版本，其中点可以是多个簇的一部分，这对于社区检测的用例来说是自然的。这个问题变体近似难度为$\Omega(\log n)$，我们的主要结果是针对该问题的$\mathcal{O}(k^2 \log n)$-近似算法。我们还补充了一个$\Omega(n^{1-\epsilon})$-硬度结果，适用于无重叠的（分离簇）一般连通图情况，以及当连通图是树时，在此设置下的精确算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [216] [On the Structure of Replicable Hypothesis Testers](https://arxiv.org/abs/2507.02842)
> *可复制假设检验器结构研究*

*Anders Aamand, Maryam Aliakbarpour, Justin Y. Chen, Shyam Narayanan, Sandeep Silwal* | **Category: cs.DS** | **Updated: {updated}**

**Keywords:** 可复制假设检验, 样本复杂度, 算法稳定性, 规范属性, 检验统计量

**Comment:** Abstract abridged to meet arxiv requirements

> **TL;DR:** 本文研究可复制假设检验器的结构，识别其规范属性，提供通用工具来证明样本复杂度上下限，并改进设计策略，从而为各种检验问题提供更好、更高效的可复制算法。

**AI_Comments:** 本文显著推进了对可复制假设检验的理解，这是提高算法过程信任度的关键方面。通过识别规范属性并提供通用工具和设计策略，它提供了一个强大的理论框架，统一并改进了先前的工作。以最小开销将不可复制的检验器变为可复制的能力是一项实用的创新。解决关于对称性的一个开放问题也是一个值得注意的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高假设检验过程的信任度，因为可复制性与算法稳定性、泛化能力和隐私性密切相关。本文旨在统一并改进现有关于样本复杂度的研究成果。

**Method:** 作者构建了用于证明样本复杂度下限和上限的通用工具。他们为可复制算法识别了一组规范属性，并证明任何可复制的检验算法都可以被修改以满足这些属性，而不会降低准确性或增加样本复杂度。他们还系统化并改进了一种基于已知期望和有界方差检验统计量的可复制算法设计通用策略。

**Result:** 他们证明了任何可复制算法都可以在不降低准确性或增加样本复杂度的情况下变得规范化。他们为均匀性检验、同一性检验和接近性检验证明了新的下限。他们为硬币检验和接近性检验获得了常数因子最优界限，并在大参数范围内对均匀性检验实现了免费的可复制性。他们还为可复制高斯均值检验提供了最先进的多项式时间界限。

**Conclusion:** 本文全面理解了可复制假设检验器的结构，提供了通用工具，识别了规范属性，并改进了设计策略，从而为各种检验问题提供了更高效、更可靠的可复制算法。

> **ai_Abstract:** 本文研究了可复制假设检验算法的结构，该算法在来自相同分布的不同样本上能以高概率产生一致的输出。作者开发了分析样本复杂度界限的通用工具，识别了所有可复制检验器都能满足的规范属性，并展示了如何以最小开销将现有不可复制的检验器转换为可复制。他们的框架为各种检验问题带来了改进的界限，包括硬币检验和接近性检验的最优界限，以及高斯均值检验的最先进多项式时间结果。

> **摘要翻译:** 如果一个假设检验算法在来自同一分布的两个不同样本上运行时以高概率产生相同的输出，则该算法是可复制的。这个概念由Impagliazzo、Lei、Pitassi和Sorell在[STOC'22]中定义，可以增加对检验程序的信任，并与算法稳定性、泛化能力和隐私性密切相关。我们构建了通用工具来证明可复制检验器样本复杂度的下限和上限，统一并定量改进了现有结果。
我们识别了一组规范属性，并证明任何可复制的检验算法都可以被修改以满足这些属性，而不会恶化准确性或样本复杂度。规范的可复制算法计算其输入的确定性函数（即检验统计量），并与[0,1]中的均匀随机值进行阈值比较。它对样本接收的顺序是不变的，并且，如果检验问题是“对称的”，那么该算法也对域元素的标记是不变的，解决了Liu和Ye在[NeurIPS'24]中提出的一个开放问题。我们通过将其归结为可复制算法满足这些规范属性的情况，证明了均匀性检验、同一性检验和接近性检验的新下限。
我们系统化并改进了一种基于已知期望和有界方差检验统计量的可复制算法设计通用策略。我们的框架允许在非可复制设置中已被广泛分析的检验器以最小的开销实现可复制性。作为我们框架的直接应用，我们获得了硬币检验和接近性检验的常数因子最优界限，并在大参数范围内对均匀性检验实现了免费的可复制性。
我们还为可复制高斯均值检验提供了最先进的界限，并且与以前的工作不同，我们的算法在多项式时间内运行。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [24] [Gbake: Baking 3D Gaussian Splats into Reflection Probes](https://arxiv.org/abs/2507.02257)
> *Gbake：将3D高斯飞溅烘焙成反射探头*

*Stephen Pasch, Joel K. Salzman, Changxi Zheng* | **Category: cs.GR** | **Updated: {updated}**

**Keywords:** 3D Gaussian Splatting, Reflection Probes, Unity

**Comment:** SIGGRAPH 2025 Posters

> **TL;DR:** GBake是一个工具，可以将3D高斯飞溅场景烘焙成反射探头，从而在Unity中实现传统网格的真实反射映射。

**AI_Comments:** 该工作解决了3D高斯飞溅在实际应用中与传统图形资产结合的一个痛点，通过引入反射探头的烘焙机制，提升了高斯飞溅场景的实用性和真实感，尤其是在游戏引擎中的应用潜力。其创新点在于为高斯飞溅提供了一种有效的光照信息提取和应用方式。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯飞溅的普及需要将其与传统计算机图形技术和资产集成。由于3D高斯基元将光照和几何形状共同编码为外观，当传统网格直接插入高斯混合场景时，其光照会不正确，显得格格不入。

**Method:** 本文引入了GBake，一个专门用于从高斯飞溅场景中烘焙反射探头的工具。

**Result:** GBake能够实现在Unity游戏引擎中对传统3D网格进行真实反射映射。

**Conclusion:** GBake成功解决了3D高斯飞溅场景中传统网格反射不自然的问题，实现了真实感集成。

> **ai_Abstract:** 本文介绍了GBake，一个将3D高斯飞溅场景烘焙成反射探头的工具。针对3D高斯飞溅与传统网格集成时，因光照编码方式不同导致网格显示不自然的问题，GBake能够生成反射探头，从而在Unity引擎中实现传统3D网格的真实反射映射。

> **摘要翻译:** 3D高斯飞溅日益普及，这使得将传统计算机图形技术和资产整合到飞溅环境中成为必要。由于3D高斯基元将光照和几何形状共同编码为外观，因此当网格直接插入3D高斯混合体中时，它们的重新照明会不正确，从而显得格格不入。我们引入了GBake，一个专门用于从高斯飞溅场景中烘焙反射探头的工具，它能够在Unity游戏引擎中实现传统3D网格的真实反射映射。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [53] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
> *基于图像的实时闪光照明*

*Tom Kneiphof, Reinhard Klein* | **Category: cs.GR, cs.CV** | **Updated: {updated}**

**Keywords:** 实时渲染, 图像基照明, 闪光, 微面, 环境贴图过滤

**Comment:** 

> **TL;DR:** 提出了一种高效的图像基闪光照明近似方法，支持动态材质和环境贴图，实现了接近真实渲染的效果。

**AI_Comments:** 该论文的创新点在于提出了一个高效的实时近似方案，用于处理复杂且计算量大的图像基闪光照明问题，特别是在动态材质和环境贴图下的应用。其引入的双门高斯二项式分布近似是解决分层采样多项式分布的关键，显著提高了效率。尽管需要两倍的内存来存储预过滤的环境贴图，但其在实时性能和渲染质量之间的权衡是值得的，为实时图形渲染领域带来了重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 在实时渲染应用中，模拟具有闪烁或闪光外观的材质（由表面离散微面引起）在图像基照明下是一个特别具有挑战性的场景。

**Method:** 该方法基于区域光照下的实时闪光渲染，并采用标准环境贴图过滤技术。环境贴图过滤过程足够快，可以逐帧执行。方法假设环境贴图被划分为少数均匀的恒定辐射区域。通过用正态分布函数过滤相应的指示函数，获得单个微面从每个区域反射光的概率。在着色过程中，这些概率通过新颖的双门高斯二项式分布近似来分层采样多项式分布。

**Result:** 该实时近似方法在各种材质属性和光照条件下接近真实渲染效果，并表现出鲁棒和稳定的性能，相比于单个方向光的闪光渲染，开销很小。与渲染没有闪光的平滑材质相比，该方法需要两倍的内存来存储预过滤的环境贴图。

**Conclusion:** 该论文提出了一种高效的图像基闪光照明近似方法，能够实现实时、动态的闪光渲染，且效果接近真实渲染，性能表现良好。

> **ai_Abstract:** 本论文提出了一种用于图像基闪光照明的高效实时近似方法。该方法基于区域光照下的闪光渲染，并利用快速环境贴图过滤和新颖的双门高斯近似来处理动态材质和环境贴图。实验证明，该方法在多种条件下能产生接近真实渲染的效果，且性能稳定，仅需额外一倍的内存用于存储预过滤的环境贴图。

> **摘要翻译:** 基于图像的照明是一种广泛使用的技术，用于再现真实世界光照条件下的着色，尤其是在实时渲染应用中。一个特别具有挑战性的场景涉及呈现闪烁或闪光外观的材料，这由散布在其表面的离散微面引起。在本文中，我们提出了一种高效的图像基闪光照明近似方法，实现了完全动态的材料属性和环境贴图。我们的新颖方法以区域光照下的实时闪光渲染为基础，并采用标准环境贴图过滤技术。至关重要的是，我们的环境贴图过滤过程足够快，可以逐帧执行。我们的方法假设环境贴图被划分为少数均匀的恒定辐射区域。通过用正态分布函数过滤相应的指示函数，我们获得了单个微面从每个区域反射光的概率。在着色过程中，这些概率被用于分层采样多项式分布，这得益于我们新颖的双门高斯二项式分布近似。我们验证了我们的实时近似方法在各种材料属性和光照条件下都接近真实渲染，并展示了鲁棒和稳定的性能，与从单个方向光渲染闪光相比，开销很小。与渲染没有闪光的平滑材料相比，我们的方法需要两倍的内存来存储预过滤的环境贴图。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [26] [Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System](https://arxiv.org/abs/2507.02000)
> *为什么多兴趣公平性很重要：用于公平对话推荐系统的超图对比多兴趣学习*

*Yongsen Zheng, Zongxuan Xie, Guohua Wang, Ziyao Liu, Liang Lin, Kwok-Yan Lam* | **Category: cs.IR, cs.CL, cs.MM** | **Updated: {updated}**

**Keywords:** 公平性, 对话推荐系统, 超图学习, 对比学习, 多兴趣

**Comment:** 

> **TL;DR:** 本文提出了HyFairCRS框架，通过超图对比多兴趣学习，旨在解决对话推荐系统中多兴趣多样性公平性问题，并在实验中取得了最先进的性能和有效的公平性缓解。

**AI_Comments:** 该论文的创新点在于将多兴趣公平性引入动态对话推荐系统，并提出超图对比学习来有效捕捉和利用用户多样化的兴趣，从而缓解长期存在的不公平性问题。其提出的HyFairCRS框架为解决推荐系统中的马太效应和过滤气泡等问题提供了新的视角和有效方案，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统（RS）中的不公平性是一个众所周知的挑战，常导致基于性别、种族、年龄或受欢迎程度等属性对用户或物品产生偏见结果。这种不公平性会随着时间推移加剧，导致马太效应、过滤气泡和回音室等严重问题。尽管现有方法在离线或静态环境中有所改善，但在动态交互式对话推荐系统（CRSs）中，多兴趣多样性公平性问题仍未得到充分解决。

**Method:** 本文提出了一个新颖的框架——超图对比多兴趣学习用于公平对话推荐系统（HyFairCRS）。HyFairCRS首先通过对比学习建立多样化的超图来捕获广泛的用户兴趣。随后，这些捕获到的兴趣在对话中被用于生成信息丰富的响应，并确保在动态用户-系统反馈循环中进行公平的物品预测。

**Result:** 在两个基于CRS的数据集上的实验表明，HyFairCRS在有效缓解不公平性的同时，实现了新的最先进性能。

**Conclusion:** HyFairCRS通过引入多兴趣多样性公平性，能够有效解决动态对话推荐系统中的不公平问题，并达到卓越的推荐性能，为缓解马太效应和过滤气泡等问题提供了有效途径。

> **ai_Abstract:** 本文针对对话推荐系统（CRSs）中存在的长期不公平问题，特别是多兴趣多样性公平性，提出了一个名为HyFairCRS的新颖框架。HyFairCRS利用超图对比学习来捕捉用户多样化的兴趣，并在动态对话过程中利用这些兴趣来生成公平的推荐。实验证明HyFairCRS在缓解不公平性方面表现出色，并达到了最先进的推荐性能。

> **摘要翻译:** 不公平性是推荐系统（RS）中一个众所周知的挑战，通常会导致基于性别、种族、年龄或受欢迎程度等属性对用户或物品产生偏见结果。尽管一些方法已开始在离线或静态环境中改善公平性推荐，但随着时间的推移，不公平问题往往会加剧，导致马太效应、过滤气泡和回音室等严重问题。为了解决这些挑战，我们提出了一个新颖的框架，即用于公平对话推荐系统（CRSs）的超图对比多兴趣学习（HyFairCRS），旨在促进动态交互式对话推荐系统中的多兴趣多样性公平性。HyFairCRS首先通过对比学习建立多样化的超图来捕获广泛的用户兴趣。然后，这些兴趣在对话中用于生成信息丰富的响应，并确保在动态用户-系统反馈循环中进行公平的物品预测。在两个基于CRS的数据集上的实验表明，HyFairCRS在有效缓解不公平性的同时，实现了新的最先进性能。我们的代码可在https://github.com/zysensmile/HyFairCRS获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [55] [Uncertainty-Aware Complex Scientific Table Data Extraction](https://arxiv.org/abs/2507.02009)
> *不确定性感知复杂科学表格数据提取*

*Kehinde Ajayi, Yi He, Jian Wu* | **Category: cs.IR** | **Updated: {updated}**

**Keywords:** 不确定性量化, 科学表格数据提取, 共形预测, 表格结构识别, 光学字符识别

**Comment:** 

> **TL;DR:** 本文提出了一个基于共形预测的不确定性感知框架，用于从复杂科学表格中提取数据。该框架通过量化TSR和OCR的不确定性，显著减少了人工验证工作量，并将数据质量提高了30%。

**AI_Comments:** 这项工作通过引入不确定性量化，创新性地解决了科学表格数据提取中人工验证耗时的问题。其价值在于提供了一种量化的方法来评估提取结果的可靠性，显著提高了人机协作的效率。该方法不仅提高了数据质量，也减少了人工干预的需求，对于需要高精度数据（如科学研究）的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于表格结构识别（TSR）和光学字符识别（OCR）的数据提取框架无法量化提取结果的不确定性，导致需要耗时费力的人工验证以确保科学数据的准确性。

**Method:** 本文提出了一个基于共形预测（一种模型无关的不确定性量化方法）的不确定性感知数据提取框架，用于处理复杂科学表格。该框架探索了多种不确定性评分方法来聚合TSR和OCR引入的不确定性。

**Result:** 该框架在标准基准和包含六个科学领域复杂科学表格的内部数据集上进行了严格评估。结果表明，使用不确定性量化能有效检测提取错误，并且通过仅手动验证47%的提取结果，数据质量可以提高30%。

**Conclusion:** 本研究定量地证明了不确定性量化在提高人机协作过程效率方面的作用，从而能够更高效地从科学文档的复杂表格中获取科学可用的数据。

> **ai_Abstract:** 本文提出了一个新颖的不确定性感知数据提取框架，专门用于复杂科学表格。该框架利用共形预测来量化并聚合表格结构识别（TSR）和光学字符识别（OCR）过程中产生的不确定性。通过在标准基准和内部数据集上的实验证明，该方法能有效检测提取错误，并且显著减少了人工验证的需求，仅通过验证47%的结果即可将数据质量提升30%，从而提高了从科学文档中获取高精度数据的效率。

> **摘要翻译:** 表格结构识别（TSR）和光学字符识别（OCR）在从科学文档中的表格中提取结构化数据方面发挥着关键作用。然而，现有基于TSR和OCR方法的提取框架往往无法量化提取结果的不确定性。为了获得科学领域的高精度数据，所有提取的数据都必须经过人工验证，这既耗时又费力。我们提出了一个基于共形预测（一种模型无关的不确定性量化方法）的框架，该框架能够对复杂科学表格进行不确定性感知的数据提取。我们探索了各种不确定性评分方法来聚合TSR和OCR引入的不确定性。我们使用标准基准和由六个科学领域的复杂科学表格组成的内部数据集对该框架进行了严格评估。结果表明，使用不确定性量化对于提取错误检测是有效的，并且通过仅手动验证47%的提取结果，数据质量可以提高30%。我们的工作定量地证明了不确定性量化在提高人机协作过程效率方面的作用，从而能够从科学文档的复杂表格中获取科学可用的数据。所有代码和数据均可在GitHub上获取：https://github.com/lamps-lab/TSR-OCR-UQ/tree/main。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [79] [ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations](https://arxiv.org/abs/2507.02014)
> *ManifoldMind: 动态双曲推理实现可信推荐*

*Anoushka Harit, Zhongtian Sun, Suncica Hadzidedic* | **Category: cs.IR, cs.AI, cs.LG, stat.ML** | **Updated: {updated}**

**Keywords:** 推荐系统, 双曲空间, 概率几何, 自适应曲率, 可信赖推荐

**Comment:** 

> **TL;DR:** ManifoldMind是一个概率几何推荐系统，它使用自适应曲率的概率球体在双曲空间中进行探索性推理，实现个性化不确定性建模和语义探索，并在多个基准测试中表现出优越的性能，提供透明和可信赖的推荐。

**AI_Comments:** ManifoldMind的创新点在于将自适应曲率的概率球体引入推荐系统，这使得模型能够更好地捕捉用户、物品和标签之间的复杂关系，并进行个性化的不确定性建模。其在双曲空间中进行探索性推理的能力，以及生成明确推理轨迹的特点，对于提升推荐系统的透明度和可信赖性具有重要意义，尤其适用于数据稀疏或概念抽象的领域。

<details>
  <summary>Details</summary>

**Motivation:** 传统的推荐系统方法具有固定的曲率和刚性嵌入，导致在语义探索和个性化不确定性建模方面存在局限性。模型可能过拟合浅层或直接的交互。

**Method:** 本文引入了ManifoldMind，一个概率几何推荐系统，用于在双曲空间中对语义层次结构进行探索性推理。它将用户、物品和标签表示为自适应曲率的概率球体，从而实现个性化不确定性建模和几何感知的语义探索。一个曲率感知的语义核支持软性的多跳推理，允许模型探索多样化的概念路径。

**Result:** 在四个公共基准测试中，ManifoldMind在NDCG、校准和多样性方面优于强大的基线模型。

**Conclusion:** ManifoldMind能够生成明确的推理轨迹，从而在稀疏或抽象的领域中实现透明、可信赖和探索驱动的推荐。

> **ai_Abstract:** ManifoldMind是一种新颖的概率几何推荐系统，利用双曲空间中的自适应曲率概率球体来表示用户、物品和标签。这种方法克服了传统模型的固定曲率限制，实现了个性化的不确定性建模和深入的语义探索。通过一个曲率感知的语义核，ManifoldMind能够进行多跳推理，避免过拟合，并在多项基准测试中展现出卓越的性能，提供了透明且可信赖的推荐。

> **摘要翻译:** 我们引入了ManifoldMind，一个用于在双曲空间中对语义层次结构进行探索性推理的概率几何推荐系统。与以往具有固定曲率和刚性嵌入的方法不同，ManifoldMind将用户、物品和标签表示为自适应曲率的概率球体，从而实现个性化不确定性建模和几何感知的语义探索。一个曲率感知的语义核支持软性的多跳推理，允许模型探索多样化的概念路径，而不是过拟合浅层或直接的交互。在四个公共基准测试中，实验结果显示其在NDCG、校准和多样性方面优于强大的基线模型。ManifoldMind生成明确的推理轨迹，从而在稀疏或抽象的领域中实现透明、可信赖和探索驱动的推荐。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [103] [The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems](https://arxiv.org/abs/2507.02097)
> *智能体的未来：多智能体推荐系统的定义、视角和开放挑战*

*Reza Yousefi Maragheh, Yashar Deldjoo* | **Category: cs.IR** | **Updated: {updated}**

**Keywords:** 多智能体推荐系统, 大型语言模型, 智能体, 推荐系统, 开放挑战

**Comment:** 

> **TL;DR:** LLM代理正将推荐系统转变为多智能体系统，本文提出统一形式、用例和五大挑战，为未来研究提供蓝图和议程。

**AI_Comments:** 这篇论文极具前瞻性，将LLM智能体与推荐系统相结合，为该领域带来了全新的视角和设计范式。其创新之处在于提出了统一的智能体和多智能体推荐系统形式化框架，并通过具体用例展示了潜力。同时，论文清晰地阐述了这一新兴领域面临的五大关键挑战，并提供了研究议程，对未来研究具有重要的指导意义。它为构建下一代更智能、更自主的推荐系统奠定了理论和实践基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正在迅速从被动的文本生成引擎演变为能够规划、记忆、调用外部工具并相互协作的智能体实体。本文旨在探讨这些LLM智能体（及其社会）如何改变推荐系统的设计空间。

**Method:** 本文引入一个统一的形式化框架，建模个体智能体（包括其语言核心、工具集和分层记忆）和多智能体推荐系统（包括智能体、共享环境和通信协议）。在此框架内，提出了四个端到端用例来展示智能体编排所解锁的能力。文章还提出了五个跨领域挑战家族：协议复杂性、可扩展性、幻觉和错误传播、涌现的错位以及品牌合规性，并对每个挑战进行形式化、回顾缓解策略并概述开放研究问题。

**Result:** 本文提出了一个蓝图和议程：蓝图展示了如何将增强记忆、使用工具的LLM智能体组合成鲁棒的推荐管道；议程邀请推荐系统社区开发基准、理论保证和治理工具，以适应这种新的自主程度。

**Conclusion:** 本文通过统一智能体抽象与推荐目标，为下一代个性化、可信赖和上下文丰富的推荐服务奠定了基础。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）向智能体实体演变如何重塑推荐系统。作者提出了一个统一的形式化框架来建模个体智能体和多智能体推荐系统，并展示了四个端到端用例。文章还识别并详细阐述了协议复杂性、可扩展性、幻觉、错位和品牌合规性等五个关键挑战，并为每个挑战提供了问题形式化、现有缓解策略和未来研究方向。最终，该文提供了一个蓝图，指导如何构建基于LLM智能体的推荐系统，并提出了一个研究议程，旨在推动推荐系统社区在这一新兴领域的发展，为未来个性化、可信赖的推荐服务奠定基础。

> **摘要翻译:** 大型语言模型（LLMs）正在迅速从被动的文本生成引擎演变为能够规划、记忆、调用外部工具并相互协作的智能体实体。这篇视角论文探讨了这些LLM智能体（及其社会）如何改变推荐系统的设计空间。
我们引入了一个统一的形式化方法，（i）将单个智能体建模为一个元组，包括其语言核心、工具集和分层记忆，（ii）将多智能体推荐系统捕获为智能体、共享环境和通信协议的三元组。在此框架内，我们提出了四个端到端用例——交互式聚会规划、用于离线评估的合成用户模拟、多模态家具推荐和品牌一致性解释生成——每个用例都展示了智能体编排所解锁的独特能力。
然后，我们提出了五个跨领域挑战家族：协议复杂性、可扩展性、幻觉和错误传播、涌现的错位（包括秘密串通）以及品牌合规性。
对于每个挑战，我们都对其问题进行形式化，回顾了新兴的缓解策略，并概述了开放的研究问题。结果既是一个蓝图也是一个议程：一个蓝图，展示了如何将增强记忆、使用工具的LLM智能体组合成鲁棒的推荐管道；一个议程，邀请推荐系统社区开发基准、理论保证和治理工具，以适应这种新的自主程度。通过将智能体抽象与推荐目标相结合，本文为下一代个性化、可信赖和上下文丰富的推荐服务奠定了基础。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [128] [When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search](https://arxiv.org/abs/2507.02139)
> *当大型语言模型意见不一致时：诊断可持续发展目标搜索中的相关性过滤偏差和检索差异*

*William A. Ingram, Bipasha Banerjee, Edward A. Fox* | **Category: cs.IR, cs.AI, cs.DL** | **Updated: {updated}**

**Keywords:** 大型语言模型, 信息检索, 相关性标注, 模型分歧, 可持续发展目标

**Comment:** Presented at LLM4Eval Workshop, SIGIR 2025 Padova, Italy, July 17,
  2025

> **TL;DR:** 本研究探讨了大型语言模型（LLMs）在信息检索中进行文档相关性标注时的分歧，发现这种分歧并非随机，而是系统性的，并导致检索结果的差异，建议将这种分类分歧作为检索评估的分析对象。

**AI_Comments:** 这篇论文揭示了在信息检索中利用大型语言模型进行相关性标注时一个至关重要的问题：模型间的分歧并非随机噪声，而是具有结构性和可预测性，从而对下游检索结果产生系统性影响。其创新之处在于将模型分歧本身作为分析对象，并提供了量化的证据（AUC > 0.74），强调了即便在无人类标注数据场景下，LLM应用带来的潜在偏差。这对于未来LLM在信息检索领域的可靠性和公平性评估具有重要指导意义，尤其是在高风险或敏感信息领域。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地用于信息检索管道中分配文档相关性标签，尤其是在缺乏人工标注数据的领域。然而，不同模型在边缘案例上经常出现分歧，这引发了人们对这种分歧如何影响下游检索的担忧。

**Method:** 本研究调查了两个开源LLM（LLaMA和Qwen）在与可持续发展目标（SDG）1、3和7相关的学术摘要语料库上的标签分歧。研究隔离了分歧子集，并检查了它们的词汇属性、排名行为和分类可预测性。

**Result:** 结果表明，模型分歧是系统性的，而非随机：分歧案例表现出一致的词汇模式，在共享评分函数下产生不同的排名靠前输出，并且可以使用简单分类器以高于0.74的AUC值进行区分。

**Conclusion:** 这些发现表明，即使在受控提示和共享排名逻辑下，基于LLM的过滤也会在文档检索中引入结构化变异性。作者建议将分类分歧作为检索评估的分析对象，特别是在政策相关或主题搜索任务中。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在信息检索中进行文档相关性标注时出现分歧的问题，尤其是在缺乏人工标注数据的场景。通过分析LLaMA和Qwen在可持续发展目标（SDG）相关摘要上的标签差异，研究发现模型分歧并非偶然，而是系统性的，表现出一致的词汇模式，并导致检索结果的显著差异。即便在受控条件下，基于LLM的过滤也会引入结构化变异性。论文提出应将这种分类分歧作为信息检索评估，特别是政策和主题搜索任务中的重要分析对象。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地用于信息检索管道中分配文档相关性标签，尤其是在缺乏人工标注数据的领域。然而，不同模型在边缘案例上经常出现分歧，这引发了人们对这种分歧如何影响下游检索的担忧。本研究调查了两个开源LLM（LLaMA和Qwen）在与可持续发展目标（SDG）1、3和7相关的学术摘要语料库上的标签分歧。我们隔离了分歧子集，并检查了它们的词汇属性、排名行为和分类可预测性。我们的结果表明，模型分歧是系统性的，而非随机：分歧案例表现出一致的词汇模式，在共享评分函数下产生不同的排名靠前输出，并且可以使用简单分类器以高于0.74的AUC值进行区分。这些发现表明，即使在受控提示和共享排名逻辑下，基于LLM的过滤也会在文档检索中引入结构化变异性。我们建议将分类分歧作为检索评估的分析对象，特别是在政策相关或主题搜索任务中。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [149] [Listwise Preference Alignment Optimization for Tail Item Recommendation](https://arxiv.org/abs/2507.02255)
> *尾部项目推荐的列表式偏好对齐优化*

*Zihao Li, Chao Yang, Tong Zhang, Yakun Chen, Xianzhi Wang, Guandong Xu, Daoyi Dong* | **Category: cs.IR, cs.LG** | **Updated: {updated}**

**Keywords:** 列表式偏好对齐, 尾部项目推荐, Bradley-Terry模型, 自适应负采样, LPO4Rec

**Comment:** 

> **TL;DR:** LPO4Rec提出了一种新的列表式偏好对齐方法，通过扩展Bradley-Terry模型并采用自适应负采样，在尾部项目推荐中显著优于现有方法，同时降低了内存使用。

**AI_Comments:** LPO4Rec的创新之处在于将列表式偏好对齐引入尾部项目推荐，并结合了理论证明和实证效果。其闭式最优策略和自适应负采样策略有效解决了传统偏好对齐方法的效率问题，并专注于长尾问题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统的偏好对齐方法存在计算成本高或训练效率低的问题，且没有针对尾部项目推荐的偏好对齐解决方案。

**Method:** 提出LPO4Rec方法，将Bradley-Terry模型从成对比较扩展到列表式比较，以提高模型训练效率。推导了闭式最优策略，无需显式奖励建模即可进行高效训练。引入自适应负采样和重加权策略，在优化过程中优先处理尾部项目。理论证明优化列表式偏好优化（LPO）损失等同于最大化最优奖励的上限。

**Result:** 在三个公共数据集上的实验表明，LPO4Rec比10个基线方法有显著提升，性能提升高达50%。与直接偏好优化（DPO）相比，在尾部项目推荐中GPU内存使用减少了17.9%。

**Conclusion:** LPO4Rec通过列表式偏好对齐和对尾部项目的优化，在尾部项目推荐任务中取得了显著的性能提升和效率优化。

> **ai_Abstract:** 本文提出了LPO4Rec，一种针对尾部项目推荐的列表式偏好对齐优化方法。该方法将Bradley-Terry模型扩展到列表式比较，推导出闭式最优策略以提高训练效率并避免显式奖励建模。同时，引入自适应负采样和重加权策略以优先处理尾部项目。实验证明，LPO4Rec在性能上显著超越现有基线，并有效降低了内存消耗。

> **摘要翻译:** 偏好对齐在大型语言模型（LLMs）上取得了巨大成功，并在推荐研究中引起了广泛兴趣。现有的推荐系统偏好对齐方法要么需要显式奖励建模，要么只支持成对偏好比较。前者直接增加了大量的计算成本，而后者阻碍了负样本的训练效率。此外，目前还没有探索针对尾部项目推荐的偏好对齐解决方案。为了弥补上述空白，我们提出了LPO4Rec，它将Bradley-Terry模型从成对比较扩展到列表式比较，以提高模型训练效率。具体来说，我们推导了一个闭式最优策略，无需显式奖励建模即可实现更高效和有效的训练。我们还提出了一种自适应负采样和重加权策略，以在优化过程中优先处理尾部项目，并提高尾部项目推荐的性能。此外，我们从理论上证明了优化列表式偏好优化（LPO）损失等同于最大化最优奖励的上限。我们在三个公共数据集上的实验表明，我们的方法显著优于10个基线方法，性能提升高达50%，同时在尾部项目推荐中与直接偏好优化（DPO）相比，GPU内存使用减少了17.9%。我们的代码可在https://github.com/Yuhanleeee/LPO4Rec获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [170] [Content filtering methods for music recommendation: A review](https://arxiv.org/abs/2507.02282)
> *音乐推荐中的内容过滤方法：综述*

*Terence Zeng, Abhishek K. Umrawal* | **Category: cs.IR, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 音乐推荐, 内容过滤, 协同过滤, 歌词分析, 大型语言模型, 音频信号处理

**Comment:** 13 pages and 9 figures

> **TL;DR:** 本综述探讨了音乐推荐系统中内容过滤方法，以解决协同过滤在音乐数据稀疏性问题上的不足，并讨论了歌词分析和音频信号处理等歌曲分类方法。

**AI_Comments:** 这篇综述及时地关注了音乐推荐领域的一个重要问题——数据稀疏性对协同过滤的影响。它创新性地将LLMs引入歌词分析，并结合了传统的音频信号处理，为内容过滤提供了多模态的视角。论文不仅总结了现有方法，还提出了不同分析方法间冲突的解决途径，这对于未来音乐推荐系统的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统在现代音乐流媒体平台中至关重要，但传统的协同过滤方法在音乐这种用户交互稀疏的媒体上效果不佳。由于数据稀疏性带来的挑战，需要其他方法来解决，特别是内容过滤方法。

**Method:** 本综述审查了当前解决这些挑战的研究现状，重点强调内容过滤在减轻协同过滤固有偏差中的作用。文章探讨了各种歌曲分类的内容过滤方法，包括使用大型语言模型（LLMs）进行歌词分析和音频信号处理技术。

**Result:** 本综述探讨了使用大型语言模型（LLMs）进行歌词分析和音频信号处理技术等多种歌曲分类方法，用于内容过滤。此外，还讨论了这些不同分析方法之间潜在的冲突。

**Conclusion:** 本综述讨论了内容过滤在音乐推荐中的应用，并提出了解决不同分析方法之间潜在冲突的途径。

> **ai_Abstract:** 本综述探讨了音乐推荐系统中内容过滤方法的重要性，以弥补协同过滤在处理音乐数据稀疏性时的不足。文章详细介绍了包括基于LLM的歌词分析和音频信号处理技术在内的多种歌曲分类方法，并讨论了这些方法间的潜在冲突及解决方案。

> **摘要翻译:** 推荐系统在现代音乐流媒体平台中已变得不可或缺，它们塑造了用户发现和参与歌曲的方式。推荐系统中的一种常见方法是协同过滤，它根据与目标用户有相似听歌模式的用户的偏好来推荐内容。然而，这种方法在交互稀疏的媒体上效果较差。音乐就是这样一种媒体，因为音乐流媒体服务的普通用户永远不会听绝大多数的歌曲。由于这种稀疏性，存在一些必须通过其他方法解决的挑战。本综述审查了当前解决这些挑战的研究现状，重点强调了内容过滤在减轻协同过滤方法固有偏差中的作用。我们探讨了各种用于内容过滤的歌曲分类方法，包括使用大型语言模型（LLMs）进行歌词分析和音频信号处理技术。此外，我们还讨论了这些不同分析方法之间潜在的冲突，并提出了解决此类差异的途径。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [189] [Calibrated Recommendations: Survey and Future Directions](https://arxiv.org/abs/2507.02643)
> *校准推荐：综述与未来方向*

*Diego Corrêa da Silva, Dietmar Jannach* | **Category: cs.IR** | **Updated: {updated}**

**Keywords:** 校准推荐, 推荐系统, 综述, 多样性, 公平性

**Comment:** 

> **TL;DR:** 该论文对校准推荐领域进行了综述，回顾了现有技术方法和有效性研究，并讨论了实践中的局限性和挑战。

**AI_Comments:** 这篇综述论文对于理解校准推荐领域的发展至关重要，它不仅系统地梳理了现有技术，还指出了未来研究和实践中的挑战，对研究者和实践者都具有重要的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 校准推荐旨在使推荐物品的属性与用户过去偏好的分布相匹配，以避免推荐过于局限于用户兴趣的某个子集。鉴于近年来将校准应用于多样性、偏见和公平性等研究工作的数量不断增加，因此有必要对该领域的最新发展进行综述。

**Method:** 本论文通过对校准推荐领域的最新进展进行综述。具体方法包括回顾现有的校准技术方法，概述校准在不同用例中有效性的实证和分析研究，并讨论在实践中实施校准时的局限性和常见挑战。

**Result:** 论文回顾了校准推荐的现有技术方法，概述了校准在不同用例中有效性的实证和分析研究，并讨论了在实践中实施校准的局限性和常见挑战。

**Conclusion:** 该论文对校准推荐的现状进行了全面的总结，并指出了该领域在实践中面临的挑战和局限性。

> **ai_Abstract:** 这篇综述论文探讨了校准推荐的概念，其目标是使推荐物品的属性与用户的历史偏好分布一致，从而确保推荐的多样性并解决偏见和公平性问题。论文回顾了现有的校准技术方法，总结了其在各种用例中的实证和分析有效性研究，并讨论了在实际应用中遇到的限制和挑战。

> **摘要翻译:** 校准推荐的理念是，推荐给用户的物品属性应与其个体过去偏好的分布相匹配。因此，校准技术有助于确保为用户提供的推荐不限于用户兴趣的某个特定子集。在过去的几年里，我们观察到越来越多的研究工作将校准用于不同的目的，包括多样性、偏见和公平性等问题。在这项工作中，我们对校准推荐领域的最新发展进行了综述。我们回顾了现有的校准技术方法，并概述了校准在不同用例中有效性的实证和分析研究。此外，我们还讨论了在实践中实施校准时的局限性和常见挑战。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [27] [Quality Diversity Genetic Programming for Learning Scheduling Heuristics](https://arxiv.org/abs/2507.02235)
> *用于学习调度启发式算法的质量多样性遗传编程*

*Meng Xu, Frank Neumann, Aneta Neumann, Yew Soon Ong* | **Category: cs.NE** | **Updated: {updated}**

**Keywords:** 质量多样性, 遗传编程, 调度启发式, 动态优化, 组合优化

**Comment:** 9 pages, 5 figures

> **TL;DR:** 本文提出了一种新颖的质量多样性（QD）框架，用于动态调度问题，通过构建一个可视化解决方案空间的图谱来学习多样化的调度启发式算法，并在固定和动态变化的训练实例上进行了实验。

**AI_Comments:** 该论文的创新点在于将质量多样性（QD）优化首次应用于动态调度问题，并提出了一种独特的图谱构建策略来可视化和维护多样化的调度启发式算法。这解决了传统QD算法在处理动态和复杂组合优化问题时的局限性，为在该领域学习启发式算法提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界的优化问题需要多样化、高质量的解决方案。质量多样性（QD）算法在进化算法中表现出色，但其应用主要集中在静态问题上，在动态组合优化问题背景下的探索有限。此外，QD算法在学习启发式算法而非直接学习解决方案时的理论理解不足，这在复杂动态组合优化领域带来了额外挑战。

**Method:** 本文引入了一种用于动态调度问题的新颖QD框架。提出了一种图谱构建策略，通过将启发式基因型与其行为关联起来，将解决方案空间可视化，从而在QD图谱上表示它们。该图谱有助于发现和维护多样化的调度启发式算法。

**Result:** 实验证明了在固定和动态变化的训练实例上，所构建的图谱如何演变以及解决方案分布如何随时间展开。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种用于动态调度问题的新颖质量多样性（QD）框架。该框架通过构建一个可视化解决方案空间的图谱，将启发式基因型与其行为关联，从而发现和维护多样化的调度启发式算法。研究在固定和动态变化的训练实例上进行了实验，以展示图谱的演变和解决方案分布随时间的变化，并讨论了未来研究方向，旨在增强QD算法在动态组合优化中的适用性。

> **摘要翻译:** 现实世界的优化通常需要多样化、高质量的解决方案。质量多样性（QD）优化是进化算法中一种多方面的方法，旨在生成一组既高性能又多样化的解决方案。QD算法已成功应用于各种领域，通过探索多样化的行为空间提供稳健的解决方案。然而，它们的应用主要集中在静态问题上，在动态组合优化问题背景下的探索有限。此外，QD算法的理论理解仍不完善，尤其是在应用于学习启发式算法而非直接在复杂动态组合优化领域直接学习解决方案时，这带来了额外的挑战。本文介绍了一种用于动态调度问题的新颖QD框架。我们提出了一种图谱构建策略，通过将启发式基因型与其行为关联起来，可视化解决方案空间，从而在QD图谱上表示它们。该图谱有助于发现和维护多样化的调度启发式算法。此外，我们在固定和动态变化的训练实例上进行了实验，以展示图谱如何演变以及解决方案的分布如何随时间展开。我们还讨论了潜在的未来研究方向，这些方向可以增强学习过程并拓宽QD算法在动态组合优化挑战中的适用性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [56] [Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes](https://arxiv.org/abs/2507.02331)
> *追踪模块化CMA-ES配置在问题景观中的交互*

*Ana Nikolikj, Mario Andrés Muñoz, Eva Tuba, Tome Eftimov* | **Category: cs.NE, cs.AI** | **Updated: {updated}**

**Keywords:** CMA-ES, 算法足迹, 配置, 问题景观, 可解释性

**Comment:** 

> **TL;DR:** 本研究利用算法足迹来调查CMA-ES算法配置与问题特征之间的相互作用，揭示了共享和独特的行为模式，并证明了算法足迹在提高可解释性和指导配置选择方面的有效性。

**AI_Comments:** 本文创新性地应用了“算法足迹”这一概念来分析优化算法配置与问题特性之间的复杂交互，为理解算法行为和指导参数选择提供了新的视角。其重要性在于提升了算法的可解释性，对于优化算法的设计和应用具有实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在利用算法足迹的概念，调查算法配置与问题特性之间的相互作用，并深入了解为何同一算法的不同配置会表现出不同的性能，以及影响这些结果的问题特征。

**Method:** 本研究利用新引入的算法足迹概念，计算了六种模块化CMA-ES算法（modCMA）变体的性能足迹，并在BBOB基准套件中的24个问题上进行了评估，涵盖5维和30维两种设置。

**Result:** 分析揭示了由于与问题属性的共同交互而产生的跨配置的共享行为模式，以及由不同问题特征驱动的在同一问题上的独特行为。

**Conclusion:** 结果表明，算法足迹在增强可解释性和指导配置选择方面是有效的。

> **ai_Abstract:** 本论文利用算法足迹的概念，深入研究了模块化CMA-ES算法配置与问题特性之间的复杂关系。通过在BBOB基准问题上评估六种modCMA变体并计算其性能足迹，研究揭示了不同配置表现差异的原因以及影响这些结果的问题特征。分析发现，在与问题属性的共同交互下，配置之间存在共享的行为模式，同时在相同问题上，由于不同的问题特征也会产生独特的行为。研究结果强调了算法足迹在提升算法可解释性和辅助配置选择方面的有效性。

> **摘要翻译:** 本文利用最近引入的算法足迹概念，研究算法配置与问题特征之间的相互作用。针对CMA-ES算法的六种模块化变体（modCMA），在BBOB套件的24个基准问题上，在5维和30维两种二维设置下，计算了性能足迹。这些足迹提供了关于为什么同一算法的不同配置表现出不同性能的见解，并识别了影响这些结果的问题特征。我们的分析揭示了由于与问题属性的共同交互而产生的跨配置的共享行为模式，以及由不同问题特征驱动的在同一问题上的独特行为。结果证明了算法足迹在增强可解释性和指导配置选择方面的有效性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [80] [ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms](https://arxiv.org/abs/2507.02337)
> *ClustOpt：一种基于聚类的方法，用于表示和可视化数值元启发式优化算法的搜索动态*

*Gjorgjina Cenikj, Gašper Petelin, Tome Eftimov* | **Category: cs.NE, cs.AI** | **Updated: {updated}**

**Keywords:** 聚类, 元启发式算法, 搜索动态, 可视化, 算法稳定性

**Comment:** 

> **TL;DR:** 提出ClustOpt，一种新的基于聚类的可视化方法，用于理解数值元启发式算法的搜索动态，并引入稳定性与相似性指标。

**AI_Comments:** 该论文提出了一种创新的基于聚类的可视化方法，有效解决了传统方法在高维复杂空间中难以展现算法搜索结构动态的问题。引入的算法稳定性与相似性指标具有重要意义，为定量分析和比较优化算法提供了新工具。这对于优化算法的理解、开发和应用具有积极推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统可视化方法（如收敛图、轨迹映射、适应度景观分析）在展示高维或复杂解空间中搜索过程的结构动态方面存在不足，限制了对算法行为的理解。

**Method:** 本文提出一种新颖的表示和可视化方法，该方法对算法探索的候选解进行聚类，并跟踪聚类成员随迭代的演变，从而提供搜索过程的动态和可解释视图。此外，引入了两个度量指标：算法稳定性（量化单一算法运行间搜索轨迹的一致性）和算法相似性（量化不同算法之间的相似性）。

**Result:** 将该方法应用于十种数值元启发式算法，揭示了它们稳定性及比较行为的见解。

**Conclusion:** 该方法提供了对数值元启发式优化算法搜索动态的更深入理解。

> **ai_Abstract:** 本文提出ClustOpt，一种新颖的基于聚类的表示和可视化方法，旨在解决传统技术在理解数值元启发式优化算法搜索动态方面的不足。该方法通过聚类算法探索的解候选并跟踪其聚类成员演变，提供对搜索过程的动态和可解释视图。此外，引入了算法稳定性和算法相似性两个新指标。通过应用于十种算法，该方法成功揭示了算法的稳定性及比较行为，加深了对搜索动态的理解。

> **摘要翻译:** 理解数值元启发式优化算法的行为对于促进其发展和应用至关重要。传统的可视化技术，如收敛图、轨迹映射和适应度景观分析，在说明搜索过程的结构动态方面往往力有不逮，尤其是在高维或复杂的解空间中。为了解决这个问题，我们提出了一种新颖的表示和可视化方法，该方法对算法探索的候选解进行聚类，并跟踪聚类成员在迭代过程中的演变，从而提供了搜索过程的动态和可解释视图。此外，我们引入了两个度量指标——算法稳定性和算法相似性——分别用于量化单一算法在多次运行中搜索轨迹的一致性以及不同算法之间的相似性。我们将这种方法应用于一组十种数值元启发式算法，揭示了关于它们稳定性和比较行为的见解，从而提供了对其搜索动态的更深入理解。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [104] [An Experimental Approach for Running-Time Estimation of Multi-objective Evolutionary Algorithms in Numerical Optimization](https://arxiv.org/abs/2507.02372)
> *多目标进化算法在数值优化中运行时间估计的实验方法*

*Han Huang, Tianyu Wang, Chaoda Peng, Tongli He, Zhifeng Hao* | **Category: cs.NE** | **Updated: {updated}**

**Keywords:** 多目标进化算法, 运行时间估计, 数值优化, 自适应采样, 平均增益模型

**Comment:** 

> **TL;DR:** 提出了一种实验性方法，用于在不简化假设的情况下，估计数值优化中多目标进化算法的运行时间上限，并验证了其有效性。

**AI_Comments:** 这项工作创新性地提供了一种无需简化假设的实验方法来估计MOEA在数值优化中的运行时间，弥补了现有理论研究的不足。通过引入平均增益模型、统计方法和自适应采样，有效处理了MOEA的随机性和复杂性，使其结果更具实际指导意义。提供网络实现也大大提升了其实用性和推广潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数值优化中多目标进化算法运行时间分析主要依赖于算法或问题简化，限制了其在实际应用中的适用性。本文旨在弥补这一空白。

**Method:** 提出了一种实验方法，利用平均增益模型（通过 IGD 指标表征算法进展）来估计运行时间上限。通过统计方法处理随机性，并引入自适应采样方法动态调整采样密度以确保准确拟合不规则增益分布。

**Result:** 在ZDT和DTLZ基准套件上对五种代表性MOEA（NSGA-II, MOEA/D, AR-MOEA, AGEMOEA-II, PREA）进行的综合实验表明，该方法在不要求算法或问题简化的前提下，能够有效估计运行时间上限。

**Conclusion:** 这项工作为数值优化中MOEA的理论研究提供了实用的补充，并提供了一个基于网络的实现以促进更广泛的应用。

> **ai_Abstract:** 本文提出了一种新颖的实验方法，旨在准确估计数值优化中多目标进化算法（MOEA）的运行时间上限，而无需进行常见的算法或问题简化。该方法基于平均增益模型，利用反向世代距离（IGD）度量算法进展，并通过统计方法和自适应采样处理MOEA的随机性及不规则增益分布。实验证明，该方法在多种MOEA和基准测试上均能有效提供运行时间估计，为MOEA的理论研究和实际应用提供了重要工具，并提供了网络实现以方便使用。

> **摘要翻译:** 多目标进化算法（MOEA）已成为解决多目标优化问题（MOP）的重要工具，因此对其运行时间进行分析对于评估算法效率和指导实际应用至关重要。尽管在组合优化方面取得了显著的理论进展，但数值优化领域的现有研究主要依赖于算法或问题的简化，这限制了它们在实际场景中的适用性。为了解决这一差距，我们提出了一种实验方法，用于在不进行简化假设的情况下，估计数值优化中MOEA运行时间的上限。我们的方法采用了一种平均增益模型，通过反向世代距离（Inverted Generational Distance）指标来表征算法的进展。为了处理MOEA的随机性，我们使用统计方法来估计增益的概率分布。认识到数值优化中的增益分布在不同区域表现出不规则的密度变化模式，我们引入了一种自适应采样方法，该方法动态调整采样密度，以确保运行时间估计的准确曲面拟合。我们使用ZDT和DTLZ基准套件对五种代表性MOEA（NSGA-II、MOEA/D、AR-MOEA、AGEMOEA-II和PREA）进行了全面的实验。结果表明，我们的方法在不要求算法或问题简化的前提下，能够有效估计运行时间的上限。此外，我们提供了一个基于网络的实现，以促进我们方法的广泛采用。这项工作为数值优化中MOEA的理论研究提供了实用的补充。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [129] [Running-time Analysis of ($μ+λ$) Evolutionary Combinatorial Optimization Based on Multiple-gain Estimation](https://arxiv.org/abs/2507.02381)
> *基于多增益估计的($
mu+\lambda$)演化组合优化运行时间分析*

*Min Huang, Pengxiang Chen, Han Huang, Tongli He, Yushan Zhang, Zhifeng Hao* | **Category: cs.NE** | **Updated: {updated}**

**Keywords:** 演化计算, 组合优化, 运行时间分析, 多增益模型, ($
mu+\lambda$)EA

**Comment:** 

> **TL;DR:** 本文提出了一种多增益模型，用于分析($
mu+\lambda$)演化算法在组合优化问题上的运行时间，并为多个问题提供了更紧凑的时间复杂度上界。

**AI_Comments:** 该论文通过弥补特定演化算法在组合优化问题理论分析上的空白，做出了重要贡献。所提出的多增益模型是对现有方法的创新性改进，为时间复杂度估计提供了更稳健的框架。为经典NP-hard问题推导出更紧凑的界限，展示了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 与简单的伪布尔问题相比，关于($
mu+\lambda$)演化算法在组合优化问题上的理论结果相对稀缺，而运行时间分析是演化计算中的一个基本课题。

**Method:** 本文提出了一个多增益模型，它是平均增益模型的改进版本，采用适应度差异漂移方法，在西格玛代数条件下估计演化数值优化的运行时间。该模型提供了一个用于估计随机过程在平均情况和最坏情况下的预期首次命中时间的框架。

**Result:** 1. 对于具有有利相关权重的背包问题，提出了比已知结果更紧凑的两个时间复杂度上界。
2. 对于一般k-MAX-SAT问题，给出了($
mu+\lambda$)EA时间复杂度上界的闭式表达式。
3. 对于旅行商问题，提出了比已知结果更紧凑的时间复杂度上界。
4. 实验结果表明实际运行时间与理论结果一致。

**Conclusion:** 多增益模型是分析($
mu+\lambda$)演化算法在组合优化问题上运行时间的有效工具。

> **ai_Abstract:** 本文针对($
mu+\lambda$)演化算法在组合优化问题上理论运行时间分析的不足，引入了一种改进的“多增益模型”。该模型是一种适应度差异漂移方法，用于估计预期的首次命中时间，并为背包问题、k-MAX-SAT和旅行商问题提供了新的、更紧凑的时间复杂度上界。实验验证了该模型的有效性。

> **摘要翻译:** 演化组合优化的运行时间分析是演化计算中的一个基本课题。然而，与简单的伪布尔问题相比，关于($
mu+\lambda$)演化算法(EA)在组合优化问题上的理论结果相对较少。本文提出了一个多增益模型来分析演化算法在组合优化问题上的运行时间。所提出的模型是平均增益模型的改进版本，后者是一种在西格玛代数条件下估计演化数值优化运行时间的适应度差异漂移方法。这一改进提供了一个用于估计随机过程在平均情况和最坏情况下的预期首次命中时间的框架。它还引入了演化组合优化的新运行时间结果，包括：对于具有有利相关权重的背包问题，($
mu+\lambda$)EA的两个比已知结果更紧凑的时间复杂度上界；对于一般k-MAX-SAT问题，($
mu+\lambda$)EA的时间复杂度上界的闭式表达式；以及对于旅行商问题，($
mu+\lambda$)EA的一个比已知结果更紧凑的时间复杂度上界。实验结果表明，实际运行时间与理论结果一致，验证了多增益模型是分析($
mu+\lambda$)EA在组合优化问题上运行时间的有效工具。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [30] [Acoustic evaluation of a neural network dedicated to the detection of animal vocalisations](https://arxiv.org/abs/2507.01974)
> *用于动物发声检测的神经网络的声学评估*

*Jérémy Rouch, M Ducrettet, S Haupert, R Emonet, F Sèbe* | **Category: cs.SD, cs.LG** | **Updated: {updated}**

**Keywords:** 声学评估, 神经网络, 动物发声, 信噪比, 检测距离

**Comment:** 

> **TL;DR:** 本文提出了一种简单的方法，通过将合成信号的信噪比与其检测概率相关联，对用于动物发声检测的神经网络的性能进行声学评估，并证明该方法有助于系统优化、检测距离建模和叫声空间密度估计。

**AI_Comments:** 本文的创新点在于提出了一个被忽视但至关重要的方面：对用于动物发声检测的神经网络进行声学性能评估。以往的研究多侧重于机器学习指标，而忽略了声音本身的特性对检测效果的影响。通过引入信噪比与检测概率关联的方法，该研究为优化神经网络训练、预测检测距离和估算种群密度提供了新的视角和工具，对于生态声学监测领域具有重要实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 自动信号检测方法（特别是基于神经网络的方法）的有效性通常仅通过机器学习指标进行评估，而声学性能分析却很少见。为了更好地评估和优化用于动物发声检测的神经网络，需要一种声学评估方法。

**Method:** 本文提出了一种对检测系统性能进行声学分析的简单方法。该方法基于将合成信号的信噪比与其检测概率相关联。

**Result:** 该声学评估方法能够提供系统信息并优化其训练。此外，它还能对检测距离进行建模，从而评估其在不同声音环境下的动态，并估算叫声的空间密度。

**Conclusion:** 所提出的声学评估方法为用于动物发声检测的神经网络提供了一种有效的性能分析途径，有助于系统优化、检测距离建模以及叫声空间密度的估计。

> **ai_Abstract:** 本文针对动物发声检测神经网络的评估问题，提出了一种创新的声学分析方法。鉴于当前评估多依赖机器学习指标而忽视声学性能，该研究通过关联合成信号的信噪比与检测概率，提供了一种简单有效的声学评估手段。实验结果表明，该方法不仅能为系统优化提供依据，还能用于检测距离建模，从而评估其在不同声学环境下的动态，并估算动物叫声的空间密度，为生态声学监测提供了更全面的分析工具。

> **摘要翻译:** 长时间录音设备的普及，适应了有时严苛的野外条件，使得通过生态声学部署大规模动物种群监测活动成为可能。自动信号检测方法（越来越多地基于神经网络方法）的有效性经常仅通过机器学习指标进行评估，而声学性能分析却很少见。作为岩雷鸟种群声学监测的一部分，我们在此提出一种简单的检测系统性能声学分析方法。所提出的测量方法基于将合成信号的信噪比与其检测概率相关联。我们展示了该测量方法如何提供有关系统的信息并允许优化其训练。我们还展示了它如何能够对检测距离进行建模，从而提供了根据声音环境评估其动态并获取叫声空间密度估计的可能性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [58] [Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis](https://arxiv.org/abs/2507.02176)
> *分析和改进语音合成中的说话人相似度评估*

*Marc-André Carbonneau, Benjamin van Niekerk, Hugo Seuté, Jean-Philippe Letendre, Herman Kamper, Julian Zaïdi* | **Category: cs.SD, cs.CL, cs.LG, eess.AS** | **Updated: {updated}**

**Keywords:** 说话人相似度, 语音合成, ASV嵌入, 动态韵律, U3D

**Comment:** Accepted at SSW13 - Interspeech 2025 Speech Synthesis Workshop

> **TL;DR:** 现有语音合成中的说话人相似度评估（ASV嵌入）主要关注静态特征，忽略动态特征如韵律。本文发现并提出了U3D，一个评估动态韵律模式的新度量，以改进语音克隆中的说话人身份一致性评估。

**AI_Comments:** 本文创新性地指出当前ASV嵌入在语音身份评估中对动态特征（如韵律）的忽视，并提出了一个针对性的新度量U3D。这对于提高语音克隆系统的真实感和身份一致性具有重要意义，且公开发布代码有助于社区进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 语音身份建模因其多面性而具有挑战性。在生成式语音系统中，身份常使用ASV嵌入进行评估，但这些嵌入是为区分而非表征身份设计的，且主要关注静态特征，忽略动态元素如韵律。

**Method:** 本文研究了ASV嵌入捕获语音哪些方面，识别了影响说话人相似度测量的混杂因素并提出了缓解策略。为弥补这些不足，提出了U3D度量，用于评估说话人的动态韵律模式。

**Result:** 发现广泛使用的ASV嵌入主要关注音色和音高范围等静态特征，而忽略了韵律等动态元素。还识别出损害说话人相似度测量的混杂因素。

**Conclusion:** 本工作通过提出U3D度量来评估动态韵律模式，为解决在不断改进的语音克隆系统中评估说话人身份一致性的持续挑战做出了贡献。

> **ai_Abstract:** 本文分析了语音合成中用于评估说话人身份的ASV嵌入的局限性，发现它们主要侧重于静态特征而忽略动态韵律。研究识别了影响相似度测量的混杂因素，并提出了缓解策略。为解决这些问题，论文引入了U3D，一个专门评估说话人动态韵律模式的新度量，旨在改进语音克隆系统中的说话人身份一致性评估。

> **摘要翻译:** 语音身份建模因其多面性而具有挑战性。在生成式语音系统中，身份通常使用自动说话人验证（ASV）嵌入进行评估，这些嵌入是为区分而非表征身份而设计的。本文研究了此类表示捕获了语音的哪些方面。我们发现广泛使用的ASV嵌入主要关注音色和音高范围等静态特征，而忽略了韵律等动态元素。我们还识别出损害说话人相似度测量的混杂因素，并提出了缓解策略。为了弥补这些不足，我们提出了U3D，一个评估说话人动态韵律模式的度量。这项工作为在不断改进的语音克隆系统中评估说话人身份一致性的持续挑战做出了贡献。我们公开发布了代码。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [82] [Fx-Encoder++: Extracting Instrument-Wise Audio Effects Representations from Mixtures](https://arxiv.org/abs/2507.02273)
> *Fx-Encoder++：从混合音轨中提取乐器级音频效果表示*

*Yen-Tung Yeh, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Yi-Hsuan Yang, Yuki Mitsufuji* | **Category: cs.SD, eess.AS** | **Updated: {updated}**

**Keywords:** 音频效果, 乐器级表示, 对比学习, 音乐制作, Fx-Encoder++

**Comment:** ISMIR 2025

> **TL;DR:** Fx-Encoder++ 是一种新模型，它利用对比学习和“提取器”机制，能够从混合音轨中提取乐器级的音频效果表示，优于现有方法并解决了智能音乐制作中的能力空白。

**AI_Comments:** 这项工作具有重要的创新性，因为它首次提出了一种能够从混合音轨中提取乐器级音频效果表示的方法。这对于智能音乐制作，特别是自动混音等任务具有重大意义，因为以往的方法仅限于混合音轨层面的分析。对比学习框架和“提取器”机制是其核心创新点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的通用音频表示在智能音乐制作中因对音频效果（Fx）理解不足而受限。以往的方法侧重于混合音轨层面的音频效果分析，但这对于需要乐器级音频效果理解的任务（如自动混音）来说是不够的。

**Method:** 本文提出了 Fx-Encoder++ 模型，该模型旨在从音乐混合音轨中提取乐器级音频效果表示。该方法利用对比学习框架，并引入了一个“提取器”机制，该机制在提供乐器查询（音频或文本）时，将混合音轨层面的音频效果嵌入转换为乐器级音频效果嵌入。

**Result:** Fx-Encoder++ 在检索和音频效果参数匹配任务中进行了评估，并在一系列不同的乐器上进行了测试。结果表明 Fx-Encoder++ 在混合音轨层面优于现有方法，并展示了提取乐器级效果表示的新能力。

**Conclusion:** Fx-Encoder++ 解决了智能音乐制作系统中一个关键的能力空白，即提取乐器级音频效果表示，这对于自动混音等任务至关重要。

> **ai_Abstract:** 本文介绍了 Fx-Encoder++，一个用于从音乐混合音轨中提取乐器级音频效果表示的新模型。该模型利用对比学习框架和一个“提取器”机制，通过乐器查询将混合音轨效果嵌入转换为乐器级效果嵌入。实验结果表明，Fx-Encoder++ 在混合音轨层面优于现有方法，并成功实现了乐器级效果表示的提取，填补了智能音乐制作领域的一项关键空白。

> **摘要翻译:** 通用音频表示已在各种音乐信息检索应用中被证明是有效的，但它们在智能音乐制作中的实用性因对音频效果（Fx）理解不足而受到限制。尽管之前的方法强调了混合音轨层面的音频效果分析，但这种关注点对于需要乐器级音频效果理解的任务（例如自动混音）来说是不足的。在这项工作中，我们提出了 Fx-Encoder++，这是一种旨在从音乐混合音轨中提取乐器级音频效果表示的新颖模型。我们的方法利用对比学习框架，并引入了一种“提取器”机制，该机制在提供乐器查询（音频或文本）时，将混合音轨层面的音频效果嵌入转换为乐器级音频效果嵌入。我们通过检索和音频效果参数匹配任务评估了我们的模型，并在各种乐器上测试了其性能。结果表明，Fx-Encoder++ 在混合音轨层面优于现有方法，并展示了提取乐器级效果表示的新能力，解决了智能音乐制作系统中的一个关键能力空白。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [106] [JoyTTS: LLM-based Spoken Chatbot With Voice Cloning](https://arxiv.org/abs/2507.02380)
> *JoyTTS：基于LLM的带语音克隆的口语聊天机器人*

*Fangru Zhou, Jun Zhao, Guoxin Wang* | **Category: cs.SD, cs.CL, eess.AS** | **Updated: {updated}**

**Keywords:** 口语聊天机器人, LLM, TTS, 语音克隆, 开源

**Comment:** 

> **TL;DR:** JoyTTS是一个结合LLM和TTS的端到端口语聊天机器人，具有语音克隆功能，并开源了代码和模型。

**AI_Comments:** 这篇论文的创新点在于将LLM与TTS技术深度融合，并实现了语音克隆功能，提供了一个端到端的口语聊天机器人解决方案。其重要性在于开源了代码和模型，极大地降低了相关研究和应用的门槛，有助于社区推动口语AI技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在结合大型语言模型（LLM）和文本转语音（TTS）技术，创建一个具有语音克隆能力的端到端口语聊天机器人，并提供开源代码以促进社区的进一步开发和优化。

**Method:** JoyTTS是一个端到端口语聊天机器人，结合了大型语言模型（LLM）和文本转语音（TTS）技术，并具有语音克隆能力。它基于开源的MiniCPM-o和CosyVoice2模型构建，并在2000小时的对话数据上进行了训练。项目提供了完整的训练代码、模型以及训练和推理脚本。

**Result:** 在测试机器seed-tts-zh上，JoyTTS的SS（说话人相似度）得分为0.73，WER（词错误率）为5.09。

**Conclusion:** JoyTTS成功地结合了LLM和TTS技术，创建了一个具有语音克隆能力的口语聊天机器人，并取得了可观的性能，同时通过开源促进了社区的进一步开发。

> **ai_Abstract:** JoyTTS是一个开源的端到端口语聊天机器人，它将大型语言模型（LLM）与文本转语音（TTS）技术相结合，并具备语音克隆功能。该系统基于MiniCPM-o和CosyVoice2模型，使用2000小时的对话数据进行训练。其性能表现为SS得分为0.73，WER为5.09。项目提供了完整的训练代码和模型，旨在促进社区的进一步开发和优化。

> **摘要翻译:** JoyTTS是一个结合了大型语言模型（LLM）和文本转语音（TTS）技术的端到端口语聊天机器人，其特点是具备语音克隆能力。该项目建立在开源的MiniCPM-o和CosyVoice2模型之上，并在2000小时的对话数据上进行了训练。我们还提供了完整的训练代码，以促进社区的进一步开发和优化。在测试机器seed-tts-zh上，它实现了0.73的SS（说话人相似度）得分和5.09的WER（词错误率）。代码、模型以及训练和推理脚本可在https://github.com/jdh-algo/JoyTTS.git获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [131] [Posterior Transition Modeling for Unsupervised Diffusion-Based Speech Enhancement](https://arxiv.org/abs/2507.02391)
> *无监督扩散模型语音增强的后验转移建模*

*Mostafa Sadeghi, Jean-Eudes Ayilo, Romain Serizel, Xavier Alameda-Pineda* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: {updated}**

**Keywords:** 语音增强, 扩散模型, 无监督学习, 后验转移, 条件生成

**Comment:** 

> **TL;DR:** 提出两种新的无监督扩散模型语音增强算法，通过直接建模条件反向转移分布，提高了增强效果和领域鲁棒性，并解决了现有方法的超参数调优问题。

**AI_Comments:** 该论文的创新点在于提出了两种直接建模扩散状态条件反向转移分布的新算法，解决了现有扩散模型在语音增强中超参数调优的痛点，并提升了对领域偏移的鲁棒性。这对于推动无监督语音增强技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有无监督扩散模型语音增强方法通过近似的噪声扰动似然分数指导反向扩散过程，并结合无条件分数，需要超参数调优。

**Method:** 本文提出了两种替代算法：第一种方法以原则性的方式将扩散先验与观测模型整合，消除了超参数调优的需要；第二种方法在噪声语音本身上定义了一个扩散过程，产生了一个完全可处理和精确的似然分数。

**Result:** 在WSJ0-QUT和VoiceBank-DEMAND数据集上的实验表明，与有监督和无监督基线相比，这两种方法都改善了增强指标，并对领域偏移表现出更强的鲁棒性。

**Conclusion:** 通过直接建模扩散状态的条件反向转移分布，本文提出的两种算法在无监督语音增强方面取得了显著提升，并解决了现有方法的局限性。

> **ai_Abstract:** 本文研究了基于扩散模型的无监督语音增强。针对现有方法依赖近似似然分数和超参数调优的问题，作者提出了两种新算法。第一种算法将扩散先验与观测模型整合，无需超参数；第二种则在噪声语音上定义扩散过程，获得精确似然分数。实验证明，新方法在增强效果和领域鲁棒性上优于现有基线。

> **摘要翻译:** 我们探索使用扩散模型作为干净语音的表达性生成先验进行无监督语音增强。现有方法通过近似的、受噪声扰动的似然分数，结合无条件分数并使用一个权衡超参数来指导逆向扩散过程。在这项工作中，我们提出了两种替代算法，它们直接建模扩散状态的条件逆向转移分布。第一种方法以原则性的方式将扩散先验与观测模型整合，消除了超参数调优的需要。第二种方法在噪声语音本身上定义了一个扩散过程，产生了一个完全可处理和精确的似然分数。在WSJ0-QUT和VoiceBank-DEMAND数据集上的实验表明，与有监督和无监督基线相比，这两种方法都改善了增强指标，并对领域偏移表现出更强的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [152] [De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks](https://arxiv.org/abs/2507.02606)
> *De-AntiFake：重新思考针对语音克隆攻击的保护性扰动*

*Wei Fan, Kejiang Chen, Chang Liu, Weiming Zhang, Nenghai Yu* | **Category: cs.SD, cs.AI, cs.CR, cs.LG, eess.AS** | **Updated: {updated}**

**Keywords:** 语音克隆, 对抗性扰动, 净化方法, 语音安全, 隐私保护

**Comment:** Accepted by ICML 2025

> **TL;DR:** 本研究评估了现有对抗性扰动在对抗语音克隆攻击中的局限性，并提出了一种新的两阶段净化方法，以更有效地绕过语音克隆防御。

**AI_Comments:** 本论文创新性地从攻击者角度重新思考了对抗性扰动在语音克隆防御中的作用，揭示了现有防御方法的脆弱性。其提出的两阶段净化方法，特别是引入音素指导进行精炼，是其主要贡献。这不仅为攻击者提供了更有效的绕过防御手段，也反向为防御方指明了未来研究的方向，即需要开发更深层、更难被净化的防御机制，对语音安全领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语音生成模型的快速发展加剧了语音克隆（VC）相关的隐私和安全担忧。尽管现有研究通过引入对抗性扰动来阻止未经授权的语音克隆，但攻击者能够减轻这些保护性扰动并成功执行VC。本研究旨在系统评估这些保护性扰动在包含扰动净化的现实威胁模型下的有效性。

**Method:** 本研究首先对现有针对VC的保护性扰动在包含扰动净化的现实威胁模型下进行了首次系统评估。在此基础上，提出了一种新颖的两阶段净化方法：(1) 净化受扰动的语音；(2) 使用音素指导对其进行精炼，使其与干净语音分布对齐。

**Result:** 研究发现，虽然现有净化方法可以中和大部分保护性扰动，但它们仍会在VC模型的特征空间中导致失真，从而降低VC的性能。实验结果表明，所提出的两阶段净化方法在破坏VC防御方面优于现有的最先进净化方法。

**Conclusion:** 本研究揭示了基于对抗性扰动的VC防御的局限性，并强调了急需更强大的解决方案来缓解VC带来的安全和隐私风险。

> **ai_Abstract:** 本研究评估了现有用于对抗语音克隆（VC）的保护性对抗性扰动在面对攻击者净化时的有效性。研究发现，尽管净化能消除部分扰动，但仍会造成VC模型特征空间失真。为此，论文提出了一种新的两阶段净化方法：先净化受扰语音，再利用音素指导进行精炼，使其更接近干净语音分布。实验证明，该方法能更有效地破坏VC防御，揭示了当前基于对抗性扰动的VC防御的局限性，并强调了开发更鲁棒解决方案的必要性。

> **摘要翻译:** 语音生成模型的快速发展加剧了与语音克隆（VC）相关的隐私和安全担忧。最近的研究调查了通过引入对抗性扰动来阻止未经授权的语音克隆。然而，坚定的攻击者可以减轻这些保护性扰动并成功执行VC。在本研究中，我们首次对这些针对VC的保护性扰动在包含扰动净化的现实威胁模型下进行了系统评估。我们的发现表明，虽然现有净化方法可以中和相当一部分保护性扰动，但它们仍然导致VC模型特征空间的失真，从而降低VC的性能。从这个角度出发，我们提出了一种新颖的两阶段净化方法：(1) 净化受扰动的语音；(2) 使用音素指导对其进行精炼，使其与干净语音分布对齐。实验结果表明，我们的方法在破坏VC防御方面优于最先进的净化方法。我们的研究揭示了基于对抗性扰动的VC防御的局限性，并强调了急需更强大的解决方案来缓解VC带来的安全和隐私风险。代码和音频样本可在 https://de-antifake.github.io 获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [173] [ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning](https://arxiv.org/abs/2507.02666)
> *ASDA：音频频谱图差分注意力机制用于自监督表示学习*

*Junyu Wang, Tianrui Wang, Meng Ge, Longbiao Wang, Jianwu Dang* | **Category: cs.SD, cs.AI, cs.CL, eess.AS** | **Updated: {updated}**

**Keywords:** 音频自监督学习, 差分注意力, Transformer, 音频分类, 频谱图

**Comment:** Accepted at Interspeech2025

> **TL;DR:** 论文提出了ASDA，一种新的差分注意力机制，通过双softmax操作和差分系数，有效解决了Transformer在音频自监督学习中注意力分配不当的问题，并在多个音频任务上取得了最先进的性能。

**AI_Comments:** ASDA的创新点在于其差分注意力机制，通过精确调整注意力分配，避免了传统Transformer对无关信息的关注，从而显著提升了模型在音频自监督学习中的判别能力。其在多个音频任务上取得SOTA性能，表明了该方法的普适性和有效性，对未来的音频表征学习研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频自监督表示学习中，标准Transformer架构的注意力机制常将部分注意力权重分配给不相关信息，可能损害模型的判别能力。

**Method:** 引入了一种差分注意力机制（ASDA），通过整合双softmax操作和适当调整的差分系数，有效缓解了无效的注意力分配。

**Result:** ASDA模型在多个基准测试中取得了最先进的性能：音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词识别（SPC-2上98.3%准确率）和环境音分类（ESC-50上96.1%准确率）。

**Conclusion:** ASDA在音频任务中表现出有效性，为更广泛的应用铺平了道路。

> **ai_Abstract:** 本文提出ASDA（音频频谱图差分注意力机制），旨在解决标准Transformer在音频自监督学习中注意力分配不当导致判别能力下降的问题。ASDA通过引入双softmax操作和差分系数的差分注意力机制，有效减少了对无关信息的注意力分配。实验证明，ASDA在音频分类、关键词识别和环境音分类等多个音频任务上均达到了最先进的性能，显示出其在音频应用中的巨大潜力。

> **摘要翻译:** 在音频自监督表示学习的最新进展中，标准的Transformer架构已成为主要方法，但其注意力机制常常将一部分注意力权重分配给不相关信息，这可能损害模型的判别能力。为了解决这个问题，我们引入了一种差分注意力机制，通过整合双softmax操作和适当调整的差分系数，有效缓解了无效的注意力分配。实验结果表明，我们的ASDA模型在多个基准测试中取得了最先进（SOTA）的性能，包括音频分类（在AS-2M上达到49.0% mAP，在AS20K上达到41.5% mAP）、关键词识别（在SPC-2上达到98.3%准确率）和环境音分类（在ESC-50上达到96.1%准确率）。这些结果突出了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [29] [Hybrid least squares for learning functions from highly noisy data](https://arxiv.org/abs/2507.02215)
> *混合最小二乘法用于从高噪声数据中学习函数*

*Ben Adcock, Bernhard Hientzsch, Akil Narayan, Yiming Xu* | **Category: stat.ML, cs.LG, cs.NA, math.NA** | **Updated: {updated}**

**Keywords:** 混合最小二乘, 高噪声数据, Christoffel采样, 最优实验设计, 函数近似

**Comment:** 30 pages

> **TL;DR:** 本文提出一种结合Christoffel采样和最优实验设计的混合最小二乘方法，用于解决高噪声数据下的函数近似问题，显著提高了计算效率和样本复杂度。

**AI_Comments:** 该论文提出了一种创新的混合最小二乘方法来解决高噪声数据下的函数学习问题，其结合了Christoffel采样和最优实验设计，在理论上和数值上都展示了优越性。特别是在处理“严重污染数据”和“大噪声”方面，该方法填补了现有技术在小噪声环境下的局限性，具有重要的实际应用价值，尤其是在计算金融等领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在数据噪声大时表现不佳，本文旨在解决在严重污染数据下进行高效条件期望估计和最小二乘函数近似的问题。

**Method:** 本文提出一种混合方法，结合了Christoffel采样和最优实验设计。该算法还被扩展到凸约束设置，并进一步利用自适应随机子空间来处理目标函数为随机场期望的情况。

**Result:** 所提出的算法在样本点生成和噪声平滑方面都表现出适当的最优性，与现有方法相比，显著提高了计算效率和样本复杂度。理论发现得到了在合成数据和计算金融随机模拟问题上的数值研究支持。

**Conclusion:** 该混合最小二乘方法能有效处理高噪声数据下的函数学习问题，在计算效率和样本复杂度上优于现有方法，并具有良好的理论支持和实际应用潜力。

> **ai_Abstract:** 本文提出了一种新颖的混合最小二乘方法，结合了Christoffel采样和最优实验设计，旨在解决从高噪声数据中学习函数的挑战。该方法在样本点生成和噪声平滑方面表现出最优性，显著提升了计算效率和样本复杂度。此外，该算法还被成功扩展到凸约束设置以及利用自适应随机子空间处理随机场，并通过在合成数据和计算金融问题上的数值研究验证了其理论优势。

> **摘要翻译:** 受高效估计条件期望需求的驱动，我们考虑了在严重污染数据下的最小二乘函数逼近问题。现有方法在小噪声条件下表现出色，但在存在大噪声时则不尽如人意。我们提出了一种混合方法，将Christoffel采样与某些类型的最优实验设计相结合来解决此问题。我们证明了所提出的算法在样本点生成和噪声平滑方面都具有适当的最优性，与现有方法相比，提高了计算效率和样本复杂度。我们还将该算法扩展到具有类似理论保证的凸约束设置。当目标函数被定义为随机场的期望时，我们扩展了我们的方法以利用自适应随机子空间，并建立了自适应过程的逼近能力结果。我们的理论发现得到了数值研究的支持，这些研究包括合成数据和计算金融中更具挑战性的随机模拟问题。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [258] [Adaptive Iterative Soft-Thresholding Algorithm with the Median Absolute Deviation](https://arxiv.org/abs/2507.02084)
> *自适应迭代软阈值算法与中位数绝对偏差*

*Yining Feng, Ivan Selesnick* | **Category: stat.ML, cs.LG, eess.SP** | **Updated: {updated}**

**Keywords:** 自适应ISTA, 中位数绝对偏差, LASSO, 理论分析, 收敛性

**Comment:** 

> **TL;DR:** 本文对使用中位数绝对偏差估计噪声水平的自适应迭代软阈值算法（ISTA）进行了理论分析，证明了其固定点性质、局部线性收敛性和全局收敛性。

**AI_Comments:** 该论文的创新之处在于，它首次为一种在实践中广泛应用但缺乏理论支撑的算法——自适应ISTA——提供了全面的理论分析。通过揭示其固定点性质、收敛性和全局行为，极大地增强了我们对该算法的理解和信任，有助于其在更多领域的推广和应用。这项工作填补了理论与实践之间的重要空白。

<details>
  <summary>Details</summary>

**Motivation:** 自适应迭代软阈值算法（ISTA）是解决LASSO问题的常用算法，但在实践中成功的同时，其理论研究却很少。

**Method:** 本文对使用中位数绝对偏差（MAD）估计噪声水平的自适应ISTA进行了理论分析。具体来说，研究了算法固定点的性质（包括尺度等变性、非唯一性和局部稳定性），证明了局部线性收敛保证，并展示了其全局收敛行为。

**Result:** 研究结果显示了算法固定点的尺度等变性、非唯一性和局部稳定性等性质。此外，证明了算法的局部线性收敛性，并展示了其全局收敛行为。

**Conclusion:** 本文为自适应迭代软阈值算法（ISTA）提供了重要的理论基础，填补了该算法在理论分析方面的空白，证实了其在实践中的有效性。

> **ai_Abstract:** 本文专注于对自适应迭代软阈值算法（ISTA）进行深入的理论分析，该算法通过中位数绝对偏差（MAD）策略估计噪声水平以解决LASSO问题。研究揭示了该算法固定点的关键性质，如尺度等变性、非唯一性和局部稳定性，并首次提供了其局部线性收敛和全局收敛的严格证明，为自适应ISTA的广泛应用提供了坚实的理论支撑。

> **摘要翻译:** 自适应迭代软阈值算法（ISTA）是一种无需显式调整正则化参数$\lambda$即可为LASSO问题找到理想解的流行算法。尽管自适应ISTA是一种成功的实用算法，但现有的理论结果却很少。在本文中，我们对使用中位数绝对偏差估计噪声水平的自适应ISTA的阈值策略进行了理论分析。我们展示了算法固定点的性质，包括尺度等变性、非唯一性和局部稳定性，证明了局部线性收敛保证，并展示了其全局收敛行为。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [429] [Transfer Learning for Matrix Completion](https://arxiv.org/abs/2507.02248)
> *矩阵补全的迁移学习*

*Dali Liu, Haolei Weng* | **Category: stat.ML, cs.LG, 15A83, I.2.6; G.3** | **Updated: {updated}**

**Keywords:** 迁移学习, 矩阵补全, 低秩矩阵, 收敛率, 最小最大最优性

**Comment:** 37 pages, 1 figure

> **TL;DR:** 本文提出了一种用于矩阵补全的迁移学习方法，利用辅助数据提升低秩目标矩阵的估计，并在理论上证明了其最优性，在实践中也表现出色。

**AI_Comments:** 这篇论文通过引入迁移学习来解决矩阵补全问题，是一个重要的创新点。其理论分析严谨，特别是利用先进的集中不等式来证明最小最大最优性，并消除了收敛率中的对数因子，这显著提升了理论贡献。同时，论文也考虑了源数据相关性未知的情况，增加了方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在矩阵补全问题中，利用可用的辅助数据来增强低秩目标矩阵的估计。

**Method:** 本文提出了一种迁移学习过程，该过程在已知哪些源数据集有利的先验信息下进行。当源数据集相关性未知时，开发了一种有效的检测程序来识别信息源并建立了其选择一致性。研究还利用先进的尖锐集中不等式来消除收敛率中的对数因子，以证明其最小最大最优性。

**Result:** 当源矩阵足够接近目标矩阵时，该方法优于仅使用单一目标数据的传统方法。理论分析证明了其最小最大最优性。通过仿真和真实数据分析支持了该方法的有效性。

**Conclusion:** 本文提出的迁移学习方法在矩阵补全中具有理论上的最优性和实践中的优越性能，特别是在源数据相关时，能够显著提升低秩矩阵的估计效果。

> **ai_Abstract:** 本文提出了一种针对矩阵补全的迁移学习方法，旨在通过利用辅助数据来提高低秩目标矩阵的估计精度。该方法在已知有利源数据集的情况下表现出色，并在理论上证明了其收敛率的最小最大最优性，尤其是在源矩阵与目标矩阵足够接近时，性能优于传统方法。为实现这一目标，研究人员利用了尖锐集中不等式。此外，当源数据集相关性未知时，研究还开发了一种有效的识别程序。模拟和真实数据分析验证了该方法的有效性。

> **摘要翻译:** 在本文中，我们探讨了矩阵补全背景下的知识迁移，旨在利用可用的辅助数据增强低秩目标矩阵的估计。我们提出了一种在已知哪些源数据集有利的先验信息下的迁移学习过程。我们研究了其收敛速度并证明了其最小最大最优性。我们的分析表明，当源矩阵足够接近目标矩阵时，我们的方法优于仅使用单一目标数据的传统方法。特别是，我们利用了文献 \cite{brailovskaya2024universality} 中引入的先进的尖锐集中不等式，以消除收敛速度中的对数因子，这对于证明最小最大最优性至关重要。当源数据集的相关性未知时，我们开发了一种有效的检测程序来识别信息源并建立了其选择一致性。通过仿真和真实数据分析来支持我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [431] [It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation](https://arxiv.org/abs/2507.02275)
> *难以正常：噪声对结构无关估计的影响*

*Jikai Jin, Lester Mackey, Vasilis Syrgkanis* | **Category: stat.ML, cs.LG, econ.EM, math.ST, stat.ME, stat.TH** | **Updated: {updated}**

**Keywords:** 因果推断, 双重机器学习, 非高斯噪声, 鲁棒估计, 部分线性模型

**Comment:** 

> **TL;DR:** 在结构无关因果推断中，DML对于高斯噪声是最优的，但对于非高斯噪声是次优的；新的ACE程序实现了更高的鲁棒性。

**AI_Comments:** 该论文通过解决DML最优性的开放问题，并更重要的是，通过识别其在非高斯噪声下的局限性，做出了重要贡献。引入“ACE”程序提供了一种实现更高阶鲁棒性的新颖方法，这对于噪声通常为非高斯噪声的实际应用至关重要。这项工作突出了噪声分布在因果推断中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探究治疗噪声分布如何影响结构无关因果推断中的治疗效果估计，并解决了关于DML最优性的一个开放问题。

**Method:** 论文关注部分线性模型，分析了DML估计器在高斯和非高斯治疗噪声下的表现。对于非高斯噪声，提出了使用结构无关累积量估计器的新型“ACE”程序。此外，还为部分线性模型中的二元治疗提供了新的极小极大保证，并通过合成需求估计实验进行了验证。

**Result:** 研究发现，DML估计器对于高斯治疗噪声是极小极大率最优的，解决了先前的一个开放问题。然而，对于独立的非高斯治疗噪声，DML总是次优的。论文构建了新的“ACE”程序，它们通过使用结构无关累积量估计器，在第$(r+1)$个治疗累积量非零时，对混杂误差实现$r$阶不敏感性，从而提供更高阶的鲁棒性。合成需求估计实验也证明了这些更高阶鲁棒估计器的实际益处。

**Conclusion:** 治疗噪声的分布显著影响结构无关估计器的性能，对于非高斯噪声，新提出的程序可以比DML实现更优越的鲁棒性。

> **ai_Abstract:** 本文探讨了治疗噪声分布对结构无关因果推断的影响，特别是对部分线性模型中双重机器学习（DML）估计器的影响。研究表明，DML在高斯噪声下是最佳的，但在非高斯噪声下则次优。为解决DML的次优性，作者引入了新颖的“ACE”程序，利用累积量估计器实现对混杂误差的更高阶鲁棒性，从而改善了非高斯噪声下的估计性能。通过实验证明了其实际效益。

> **摘要翻译:** 结构无关因果推断研究的是，在给定混杂函数（如混杂因素对治疗和结果的影响）的黑盒机器学习估计的情况下，治疗效果的估计效果如何。在这里，我们发现答案以一种令人惊讶的方式取决于治疗噪声的分布。我们以\citet{robinson1988root}的部分线性模型为重点，首先证明了广泛采用的双重机器学习（DML）估计器对于高斯治疗噪声是极小极大率最优的，解决了\citet{mackey2018orthogonal}的一个开放问题。同时，对于独立的非高斯治疗噪声，我们通过构建新的具有对混杂误差更高阶鲁棒性的实用程序，证明DML总是次优的。这些ACE程序利用结构无关的累积量估计器，在第$(r+1)$个治疗累积量非零时，实现对混杂误差的$r$阶不敏感性。我们用部分线性模型中二元治疗的新极小极大保证来补充这些核心结果。最后，通过合成需求估计实验，我们证明了我们更高阶鲁棒估计器的实际益处。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [433] [Sparse Gaussian Processes: Structured Approximations and Power-EP Revisited](https://arxiv.org/abs/2507.02377)
> *稀疏高斯过程：结构化近似和Power-EP再探*

*Thang D. Bui, Michalis K. Titsias* | **Category: stat.ML, cs.LG** | **Updated: {updated}**

**Keywords:** 稀疏高斯过程, 变分推断, 块对角近似, Power期望传播, 机器学习

**Comment:** 

> **TL;DR:** 本文提出了一种用于稀疏高斯过程的块对角结构化近似方法，并将其与Power期望传播（PEP）框架结合，在保持计算成本的同时，提升了性能。

**AI_Comments:** 本文的创新点在于提出了块对角结构化近似方法，并将其成功整合到Power-EP框架中，这在理论上能收紧变分下界，并在实践中提升了稀疏高斯过程的性能，同时保持了计算效率。这为大规模高斯过程应用提供了有价值的改进。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于诱导点的稀疏变分高斯过程可以通过引入对角缩放矩阵来改进，本文旨在通过采用块对角结构进一步扩展这种改进，并将其整合到Power期望传播框架中。

**Method:** 本文首先提出了一种采用块对角结构化缩放矩阵的扩展，并证明其能收紧变分下界。然后，将这种新的结构化近似后验与基于Power期望传播（PEP）的稀疏GP统一框架相结合。

**Result:** 所提出的块对角近似方法在回归实验中表现出与现有对角近似方法相似或更好的性能，同时保持了可比的计算成本。此外，带有结构化后验的新PEP框架在各种幂超参数设置下提供了有竞争力的性能。

**Conclusion:** 本文提出的块对角近似方法和与Power-EP结合的新框架，为稀疏高斯过程提供了更优或具有竞争力的性能，并为实践者提供了比标准变分方法更灵活的选择。

> **ai_Abstract:** 本文提出了一种新的稀疏高斯过程近似方法，通过引入块对角结构化缩放矩阵来改进现有的对角缩放方法，并证明其能收紧变分下界。该方法与Power期望传播（PEP）框架相结合，在回归任务中表现出与对角近似相当或更优的性能，同时计算成本相似。新的PEP框架在不同超参数设置下也表现出竞争力，为高斯过程建模提供了更灵活和高效的替代方案。

> **摘要翻译:** 基于诱导点的稀疏变分高斯过程已成为扩展高斯过程模型的标准方法。最近的进展表明，通过引入对角缩放矩阵到给定诱导点的条件后验密度中，可以改进这些方法。本文首先考虑了一种采用块对角结构化缩放矩阵的扩展，这被证明能够收紧变分下界。然后，我们重新审视了基于幂期望传播（PEP）的稀疏高斯过程的统一框架，并表明它可以利用并受益于新的结构化近似后验。通过大量的回归实验，我们表明所提出的块对角近似方法始终表现出与现有对角近似方法相似或更好的性能，同时保持了可比的计算成本。此外，带有结构化后验的新PEP框架在各种幂超参数设置下提供了有竞争力的性能，为实践者提供了标准变分方法的灵活替代方案。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [46] [Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems](https://arxiv.org/abs/2507.02464)
> *通过自动机理论经济设计解决CAP：实时分区容错系统的统一数学框架*

*Craig S Wright* | **Category: cs.GT, cs.DC, cs.FL, cs.IR, econ.GN, q-fin.EC, 68M14, 91A05, 68Q85, C.2.4; D.2.4; F.1.1** | **Updated: {updated}**

**Keywords:** CAP定理, 分布式系统, 自动机理论, 经济设计, 分区容错

**Comment:** 51 pages 4 tables, includes formal proofs, automata construction, and
  case study on Bitcoin Script

> **TL;DR:** 本文提出了一个基于自动机理论和经济学原理的框架，将CAP定理的权衡重新定义为约束优化问题，从而在实时分区容错系统中，通过形式化经济控制，在有界误差范围内同时保持可用性和一致性，有效扩展了经典CAP限制。

**AI_Comments:** 该论文通过将经济设计和博弈论与自动机理论相结合，解决分布式系统中的一个基本问题（CAP定理），提出了一种创新方法。其新颖之处在于将CAP权衡重新定义为优化问题，并利用经济激励来实现系统属性的可证明界限，这可能为设计健壮的分布式系统提供新的方向。

<details>
  <summary>Details</summary>

**Motivation:** CAP定理提出了分布式系统中一致性、可用性和分区容错性之间的三难困境。本文旨在重新定义并扩展这些经典的CAP限制。

**Method:** 本文引入了一个严格的自动机理论和经济学基础框架。它将分布式系统建模为分区感知状态机，嵌入经济激励层以稳定共识行为，并通过将博弈论机制融入全局转换语义来定义可证明的收敛性、活性和正确性界限。

**Result:** 研究结果表明，在有界epsilon裕度内可以同时保持可用性和一致性，从而有效地扩展了经典的CAP限制。

**Conclusion:** 通过形式化的经济控制和自动机理论设计，该论文表明CAP权衡可以被重新定义为一个约束优化问题，从而能够在传统限制之外同时保持一致性和可用性。

> **ai_Abstract:** 本文提出了一种新颖的、基于自动机理论和经济学原理的框架，旨在解决CAP定理的三难困境。通过将分布式系统建模为分区感知状态机，并整合经济激励层和博弈论机制，该框架将CAP权衡重新定义为一个约束优化问题。其结果表明，一致性和可用性可以在有界误差范围内同时维持，从而通过形式化的经济控制扩展了传统的CAP限制。

> **摘要翻译:** CAP定理断言了在一致性、可用性和分区容错性之间的三难困境。本文引入了一个严格的自动机理论和经济学基础框架，将CAP权衡重新定义为一个约束优化问题。我们将分布式系统建模为分区感知状态机，并嵌入经济激励层以稳定对抗性分区网络中的共识行为。通过将博弈论机制融入全局转换语义，我们定义了收敛性、活性和正确性的可证明界限。我们的结果表明，可用性与一致性可以在有界epsilon裕度内同时保持，通过形式化的经济控制有效地扩展了经典的CAP限制。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [435] [Learning to Coordinate Bidders in Non-Truthful Auctions](https://arxiv.org/abs/2507.02801)
> *学习在非真实性拍卖中协调竞标者*

*Hu Fu, Tao Lin* | **Category: cs.GT, cs.LG, econ.TH** | **Updated: {updated}**

**Keywords:** 非真实性拍卖, 贝叶斯相关均衡, 样本复杂度, 协调竞标者, 机器学习

**Comment:** 

> **TL;DR:** 本文研究了在非真实性拍卖（如第一价格和全付拍卖）中学习贝叶斯相关均衡（BCE）的样本复杂度，并证明了在多项式样本数下可以学习BCE。

**AI_Comments:** 本文的创新之处在于首次系统性地研究了在非真实性拍卖中学习贝叶斯相关均衡的样本复杂度，为在信息不完全环境下设计更优的拍卖机制提供了理论基础和可行性路径。其提出的学习界限具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在非真实性拍卖中，竞标者的独立策略行为（贝叶斯纳什均衡）难以表征且可能导致不良结果。虽然贝叶斯相关均衡（BCE）是一种替代方案，但其实现需要竞标者私人估价的分布知识，而这通常是不可用的。

**Method:** 本文将学习贝叶斯相关均衡的问题转化为从样本中估计竞标者预期效用的问题，并结合了竞标者所有单调出价策略类别的伪维度分析。

**Result:** 研究证明，在包括第一价格和全付拍卖在内的一大类非真实性拍卖中，贝叶斯相关均衡（BCE）可以通过竞标者价值分布的$	ilde O(\frac{n}{\varepsilon^2})$多项式数量的样本来学习。

**Conclusion:** 本文开创了在非真实性拍卖中学习贝叶斯相关均衡的样本复杂度研究，并提供了一个具体的学习边界，表明BCE在多项式样本数下是可学习的。

> **ai_Abstract:** 本文探讨了在非真实性拍卖中协调竞标者的问题，提出通过学习贝叶斯相关均衡（BCE）来克服传统贝叶斯纳什均衡的局限性。针对BCE实施中估价分布知识缺失的挑战，作者首次研究了学习BCE的样本复杂度，并证明在一系列非真实性拍卖中，BCE可以通过多项式数量的样本进行有效学习。其方法是将问题转化为效用估计，并分析了单调出价策略的伪维度。

> **摘要翻译:** 在非真实性拍卖中，例如第一价格拍卖和全付拍卖，竞标者的独立策略行为及其相应的均衡概念——贝叶斯纳什均衡——以难以表征而闻名，并可能导致不良结果。设计更好拍卖系统的另一种方法是协调竞标者：让协调者向竞标者提供激励兼容的相关出价策略建议，即实施贝叶斯相关均衡（BCE）。然而，BCE的实施需要了解竞标者私人估价的分布，而这通常是不可用的。我们开创了在非真实性拍卖中学习贝叶斯相关均衡的样本复杂度研究。我们证明，在一大类非真实性拍卖中，包括第一价格拍卖和全付拍卖，BCE可以通过竞标者价值分布的$	ilde O(\frac{n}{\varepsilon^2})$多项式数量的样本来学习。我们的技术是将其归结为从样本中估计竞标者预期效用的问题，并结合了竞标者所有单调出价策略类别的伪维度分析。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [70] [Subtyping in DHOL -- Extended preprint](https://arxiv.org/abs/2507.02855)
> *DHOL中的子类型——扩展预印本*

*Colin Rothgang, Florian Rabe* | **Category: cs.LO, cs.AI, cs.FL** | **Updated: {updated}**

**Keywords:** DHOL, 子类型, 细化类型, 商类型, 定理证明

**Comment:** 16 pages main document, 44 pages of appendices, to be published in
  FroCoS 2025

> **TL;DR:** 本文利用依赖类型高阶逻辑（DHOL）的设计，通过将其作为子类型的特例，成功地为DHOL添加了细化类型和商类型。这不仅避免了昂贵的表示更改，还提供了扩展语言的完整语法、语义和到HOL的健全与完备翻译。

**AI_Comments:** 这篇论文的创新之处在于利用了DHOL本身类型系统不可判定的特性，巧妙地将细化类型和商类型作为子类型集成，从而解决了自动化定理证明器中长期存在的对这些类型支持不足的问题。这种方法不仅技术上优雅，避免了表示上的复杂性，而且通过保留到HOL的健全和完备翻译，确保了实用性和自动化支持。

<details>
  <summary>Details</summary>

**Motivation:** 自动化定理证明器很少提供细化类型和商类型，因为它们本质上需要不可判定的类型系统，难以与可判定的类型系统结合。DHOL牺牲了类型系统的可判定性以增强表达能力，为添加这些特性提供了天然的平台。

**Method:** 作者利用DHOL的设计，将细化类型和商类型作为子类型的特例添加到DHOL中。这种方法将相关的规范包含映射或投影映射转换为恒等映射，从而避免了昂贵的表示更改。

**Result:** 论文提出了扩展语言的语法、语义以及到HOL的翻译，并包括了健全性（soundness）和完备性（completeness）的证明。

**Conclusion:** 通过将细化类型和商类型作为子类型添加到DHOL中，不仅可行，而且实现方式优雅和简单，并且保留了DHOL到HOL的健全和完备翻译，增强了其表达能力和实用性。

> **ai_Abstract:** 本文利用新引入的依赖类型高阶逻辑（DHOL）的设计，通过将其作为子类型的特例，成功地为DHOL添加了实践中急需但传统定理证明器难以支持的细化类型和商类型。DHOL牺牲类型系统可判定性以增强表达能力的特性，使得添加这些需要不可判定类型的特性变得可能且优雅，同时避免了昂贵的表示更改。论文详细介绍了扩展语言的语法、语义及其到标准高阶逻辑（HOL）的健全且完备的翻译。

> **摘要翻译:** 最近引入的依赖类型高阶逻辑（DHOL）在表达能力和自动化支持之间提供了一个有趣的折衷。它牺牲了其类型系统的可判定性，以显著扩展其在标准HOL上的表达能力。然而，它通过到HOL的健全和完备翻译，保留了强大的自动化定理证明支持。
我们利用这一设计，通过细化类型和商类型扩展DHOL。这两种类型是实践者经常请求但自动化定理证明器很少提供的。这是因为它们本质上需要不可判定的类型，因此很难追溯到可判定的类型系统。但由于DHOL已经完成了繁重的工作，添加它们不仅可能，而且优雅而简单。
具体来说，我们将细化类型和商类型作为子类型的特例添加。这使得相关的规范包含映射或投影映射成为恒等映射，从而避免了昂贵的表示更改。我们提出了扩展语言的语法、语义以及到HOL的翻译，包括健全性和完备性的证明。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [89] [Source Detection in Hypergraph Epidemic Dynamics using a Higher-Order Dynamic Message Passing Algorithm](https://arxiv.org/abs/2507.02523)
> *基于高阶动态消息传递算法的超图流行病动力学源检测*

*Qiao Ke, Naoki Masuda, Zhen Jin, Chuang Liu, Xiu-Xiu Zhan* | **Category: physics.soc-ph, cs.SI** | **Updated: {updated}**

**Keywords:** 源检测, 超图, 流行病动力学, 消息传递算法, 高阶交互

**Comment:** 

> **TL;DR:** 提出了一种名为HDMPN的消息传递算法，用于超图上的流行病源检测，该算法在大多数情况下优于现有基准。

**AI_Comments:** 这项研究通过引入高阶交互的概念，改进了流行病源检测的准确性，弥补了传统成对网络模型的不足，对于理解真实世界中复杂的疾病传播模式具有重要意义。其创新之处在于将消息传递算法与高阶结构相结合，提高了检测性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的源检测方法主要关注传统的成对网络，但高阶（如群体）交互在感染事件中可能占很大比例，并改变了对流行病传播的理解，因此需要针对超图上的流行病动力学进行源检测。

**Method:** 提出了一种名为HDMPN的消息传递算法，用于超图上的随机易感-感染动力学源检测。通过根据感染邻居的比例调制似然最大化方法，HDMPN旨在捕获高阶结构的影响。

**Result:** 数值结果表明，在大多数情况下，HDMPN优于包括未修改的似然最大化方法在内的基准。

**Conclusion:** HDMPN算法在超图流行病动力学源检测方面表现出色，特别是在考虑高阶交互方面，优于传统方法。

> **ai_Abstract:** 本文提出了一种名为HDMPN的高阶动态消息传递算法，用于在超图上检测流行病源。针对现有方法忽视高阶交互的问题，HDMPN通过调整传统的似然最大化方法来捕捉群体交互的影响。数值实验表明，该算法在大多数情况下优于现有基准方法，包括未经修改的似然最大化方法。

> **摘要翻译:** 源检测对于捕获真实世界传染病的动态和制定有效的遏制策略至关重要。大多数现有的源检测方法都集中在传统的成对网络上，而最近关于数学建模和接触数据分析的努力表明，个体之间的高阶（例如，群体）交互可能既占很大一部分感染事件，又改变了我们对流行病在经验人群中传播方式的理解。在本研究中，我们提出了一种消息传递算法，称为HDMPN，用于超图上随机易感-感染动力学的源检测。通过根据感染邻居的比例调制似然最大化方法，HDMPN旨在捕获高阶结构的影响，并优于传统的似然最大化方法。我们通过数值结果表明，在大多数情况下，HDMPN优于包括未修改的似然最大化方法在内的基准。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [310] [Public perspectives on the design of fusion energy facilities](https://arxiv.org/abs/2507.02207)
> *聚变能源设施设计的公众视角*

*Nathan Kawamoto, Daniel Hoover, Jonathan Xie, Jacob Walters, Katie Snyder, Aditi Verma* | **Category: physics.soc-ph, cs.HC, physics.ed-ph, physics.plasm-ph** | **Updated: {updated}**

**Keywords:** 聚变能源, 公众视角, 参与式设计, 社会许可, 社区参与

**Comment:** 33 pages

> **TL;DR:** 本文研究了一种参与式设计方法，旨在理解公众对未来聚变能源设施的看法并获得社会许可。通过研讨会发现，公众重视“正直”、“尊重”以及经济和环境安全等，并强调早期公众参与对建立社会许可的重要性。

**AI_Comments:** 这篇论文通过提出并实践一种参与式设计方法，创新性地解决了聚变能源设施选址中的社会许可问题，这与传统的“决定-宣布-捍卫”模式形成鲜明对比。其重要性在于强调了早期公众参与对于新兴高科技项目成功的关键作用，特别是在可能影响社区的敏感领域。研究结果为未来聚变设施的设计和部署提供了宝贵的公众洞察，有助于建立信任和接受度。

<details>
  <summary>Details</summary>

**Motivation:** 随着聚变能源技术接近示范和商业部署，理解公众对未来聚变设施的看法对于获得社会许可至关重要，尤其考虑到聚变设施可能因监管框架不同而建在离社区更近的地方。

**Method:** 开发了一种参与式设计方法，用于与潜在的东道社区协作设计聚变能源设施。具体通过一个参与式设计研讨会，汇集了22名社区参与者和34名工程学生，并分析了研讨会的文本和视觉数据。

**Result:** 分析显示，“正直”和“尊重”在价值观中排名最高，“经济效益”和“环境保护/安全”在决策标准中排名最高。突出的设计主题包括将社区历史与设施设计联系、关怀工人、透明度和可访问性以及社区健康安全。参与者报告了积极情绪。

**Conclusion:** 在技术开发的早期阶段进行参与式设计可以引发并具体化公众的希望和担忧，提高对新兴技术的理解和好奇心，建立社会许可，并为聚变能源设施的特定情境开发提供信息。

> **ai_Abstract:** 本文探讨了在聚变能源设施设计中纳入公众视角的重要性，以期获得社会许可。研究开发并应用了一种参与式设计方法，通过一个研讨会收集了社区成员和学生的意见。结果显示，公众高度重视“正直”、“尊重”、经济效益和环境安全。研究强调了在技术开发早期阶段进行参与式设计，有助于理解公众期望、增进对新技术的认识，并促进社会许可。

> **摘要翻译:** 随着聚变能源技术接近示范和商业部署，了解公众对未来聚变设施的看法对于获得社会许可至关重要，特别是因为聚变能源设施与大型裂变反应堆不同，由于独特的监管框架，它们可能更接近人群和社区。
我们摒弃了能源基础设施选址通常采用的“决定-宣布-捍卫”方法，开发了一种参与式设计方法，用于与潜在的东道社区协作设计聚变能源设施。我们在此展示了我们从一个参与式设计研讨会中获得的结果，该研讨会汇集了22名社区参与者和34名工程学生。
我们对本次研讨会文本和视觉数据的分析显示了一系列设计价值观和决策标准，其中“正直”和“尊重”在价值观中排名最高，“经济效益”和“环境保护/安全”在决策标准中排名最高。设施概念中出现的突出设计主题包括将社区的历史和遗产与设施设计联系起来、关怀工人、设施的透明度和可访问性，以及东道社区的健康和安全。参与者报告了主要是积极的情绪，随着研讨会从了解聚变进展到设计假设设施，他们表达了喜悦和惊讶。
我们的研究结果表明，在技术开发的早期阶段进行参与式设计可以引发并具体化公众的希望和担忧，提高对新兴技术的理解和好奇心，建立社会许可，并为聚变能源设施的特定情境开发提供信息。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-fintr'></a>
## q-fin.TR 

### [97] [A Midsummer Meme's Dream: Investigating Market Manipulations in the Meme Coin Ecosystem](https://arxiv.org/abs/2507.01963)
> *仲夏迷因梦：调查迷因币生态系统中的市场操纵*

*Alberto Maria Mongardini, Alessandro Mei* | **Category: q-fin.TR, cs.CY, q-fin.ST** | **Updated: {updated}**

**Keywords:** 迷因币, 市场操纵, 加密货币, 洗盘交易, 流动性池价格膨胀

**Comment:** 

> **TL;DR:** 迷因币市场存在广泛操纵，高回报代币的收益常由协调行动而非自然市场动态驱动。

**AI_Comments:** 这项研究揭示了迷因币市场中普遍存在的操纵行为，特别指出了洗盘交易和LPI等新型操纵手段，并揭示了它们与后续剥削行为的关联。其创新之处在于对大量跨链迷因币进行了实证分析，揭示了其高收益背后的人为因素，对投资者和监管机构具有重要警示意义。

<details>
  <summary>Details</summary>

**Motivation:** 迷因币在加密货币市场中日益流行，但其价值主要来源于社区情绪，使其极易受到市场操纵的影响。本研究旨在调查迷因币生态系统中的市场操纵行为。

**Method:** 本研究对迷因币生态系统进行了跨链分析，检查了以太坊、BNB智能链、Solana和Base上共34,988个代币。研究表征了迷因币的代币经济学，并进行了为期三个月的纵向分析以追踪其增长情况。

**Result:** 研究发现，在回报率超过100%的高回报代币中，有82.6%显示出广泛使用人工增长策略的证据，这些策略旨在制造误导性的市场兴趣表象，包括洗盘交易和一种被称为基于流动性池的价格膨胀（LPI）的操纵形式。此外，还发现了旨在以投资者为代价获利的方案，如抽拉（pump and dump）和地毯式骗局（rug pull）。大多数涉及的代币此前都经历过洗盘交易或LPI，表明初始操纵往往为后续剥削奠定基础。

**Conclusion:** 操纵行为在高表现迷因币中普遍存在，其显著收益往往是由协调努力而非自然市场动态驱动的。

> **ai_Abstract:** 本研究对迷因币生态系统进行了大规模跨链分析，涵盖了34,988个代币。结果显示，绝大多数高回报迷因币（>100%收益）存在洗盘交易和基于流动性池的价格膨胀（LPI）等人工增长策略。研究还揭示了抽拉和地毯式骗局等欺诈行为，并指出这些初始操纵常为后续剥削铺平道路。这些发现强调了高收益迷因币中普遍存在的市场操纵现象，其惊人回报往往源于协调行动而非自然市场机制。

> **摘要翻译:** 迷因币已从病毒式笑话演变为数十亿美元的现象，成为加密货币市场中最受欢迎的板块之一。与比特币或以太坊等注重实用性的加密资产不同，迷因币的价值主要来源于社区情绪，这使得它们容易受到操纵。本研究对迷因币生态系统进行了跨链分析，检查了以太坊、BNB智能链、Solana和Base上共34,988个代币。我们对迷因币的代币经济学进行了表征，并在为期三个月的纵向分析中追踪了它们的增长。我们发现，在回报率超过100%的高回报代币中，令人担忧的82.6%显示出广泛使用人工增长策略的证据，这些策略旨在制造误导性的市场兴趣表象。这些策略包括洗盘交易和我们定义为基于流动性池的价格膨胀（LPI）的一种操纵形式，其中小额战略性购买会引发剧烈的价格上涨。我们还发现了旨在以投资者为代价获利的方案证据，例如抽拉（pump and dump）和地毯式骗局（rug pull）。特别是，大多数涉及的代币此前都经历过洗盘交易或LPI，这表明初始操纵往往如何为后来的剥削奠定基础。这些发现揭示了操纵行为在高表现迷因币中普遍存在，并表明它们的显著收益往往可能是由协调努力而非自然市场动态驱动的。

</details>

[⬆️ 返回分类顶部](#q-fintr) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matsoft'></a>
## cond-mat.soft 

### [110] [A unifying approach to self-organizing systems interacting via conservation laws](https://arxiv.org/abs/2507.02575)
> *通过守恒定律相互作用的自组织系统的一种统一方法*

*Frank Barrows, Guanming Zhang, Satyam Anand, Zizi Chen, Jonathan Lin, Amman Desai, Stefano Martiniani, Francesco Caravelli* | **Category: cond-mat.soft, cond-mat.stat-mech, cs.MA, nlin.AO** | **Updated: {updated}**

**Keywords:** 自组织系统, 守恒定律, 投影算子, 动力系统, 网络系统

**Comment:** 19 pages single column + 24 pages supplementary

> **TL;DR:** 本文提出了一个统一框架（PrEDS），利用基于局部守恒定律的广义投影算子来嵌入和分析动力系统，能够处理通过局部相互作用自组织的复杂网络系统，并在多种领域得到验证。

**AI_Comments:** 该论文为分析多样化的自组织系统提供了一个创新的统一理论框架（PrEDS），这对于理解复杂的网络行为至关重要。其在多个领域的应用突显了其多功能性以及设计新型自组织系统的潜力，连接了从物理到生物学和工程学的多个领域。与群动力学和优化的直接联系是一个重要的见解。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一个统一的框架，用于嵌入和分析动力系统，特别是那些通过局部守恒定律相互作用的自组织系统。

**Method:** 研究团队提出了一个统一框架，利用植根于局部守恒定律的广义投影算子。通过将物理、生物和工程系统表示为具有关联矩阵和循环矩阵的图，导出了分解网络通量和电势的双重投影算子。该方法通过动力系统投影嵌入（PrEDS）扩展到集体动力学，将低维动力学提升到高维空间，并允许通过投影到平均场空间来近似集体行为。

**Result:** PrEDS 在多种领域展现了其通用性，包括电阻和忆阻电路、自适应流网络（如黏菌）、弹性弦网络和粒子群。研究建立了 PrEDS 与群动力学之间的直接对应关系，为优化和自组织揭示了新的见解。

**Conclusion:** 研究结果为分析复杂网络系统和设计通过局部相互作用自组织的系统提供了通用的理论基础。

> **ai_Abstract:** 本文引入了PrEDS，一个用于分析自组织动力系统的统一框架。它利用基于守恒定律的投影算子将系统建模为图，分解网络通量和电势。PrEDS将低维动力学提升到高维空间，从而能够近似集体行为。该框架在电路、流网络和粒子群等多种领域得到了验证，为理解和设计复杂的自组织系统提供了理论基础。

> **摘要翻译:** 我们提出了一个统一的框架，用于嵌入和分析动力系统，该框架利用植根于局部守恒定律的广义投影算子。通过将物理、生物和工程系统表示为具有关联矩阵和循环矩阵的图，我们导出了分解网络通量和电势的双重投影算子。这种形式主义符合非平衡热力学原理，并捕获了由通量-力关系和局部约束控制的广泛系统。我们将这种方法扩展到集体动力学，通过动力系统投影嵌入（PrEDS），它将低维动力学提升到高维空间，从而能够复制和恢复原始动力学。当系统属于 PrEDS 类时，它们的集体行为可以通过投影到平均场空间中进行有效近似。我们展示了 PrEDS 在不同领域的通用性，包括电阻和忆阻电路、自适应流网络（例如黏菌）、弹性弦网络和粒子群。值得注意的是，我们建立了 PrEDS 与群动力学之间的直接对应关系，揭示了优化和自组织的新见解。我们的结果为分析复杂网络系统和设计通过局部相互作用自组织的系统提供了通用的理论基础。

</details>

[⬆️ 返回分类顶部](#cond-matsoft) | [⬆️ 返回总目录](#toc)

---

<a id='q-finst'></a>
## q-fin.ST 

### [120] [DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification](https://arxiv.org/abs/2507.01971)
> *DeepSupp：注意力驱动的相关模式分析，用于动态时间序列支撑与阻力水平识别*

*Boris Kriuk, Logic Ng, Zarif Al Hossain* | **Category: q-fin.ST, cs.AI, cs.CE, cs.LG** | **Updated: {updated}**

**Keywords:** 支撑与阻力水平, 深度学习, 注意力机制, 金融时间序列, 技术分析

**Comment:** 7 pages, 4 figures, 1 table

> **TL;DR:** DeepSupp是一种基于注意力机制的深度学习方法，用于在动态时间序列中识别金融支撑位和阻力位，表现优于现有基线方法。

**AI_Comments:** DeepSupp的创新之处在于其结合了多头注意力机制和动态相关矩阵来分析市场微观结构和空间相关性，以识别支撑与阻力水平，而非仅仅进行价格预测。这解决了传统方法在波动市场中的局限性，并为技术分析提供了更鲁棒和可扩展的工具。其在S&P 500上的优越表现凸显了注意力架构在金融时间序列分析中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的支撑与阻力(SR)识别方法难以适应现代波动市场的复杂性。尽管机器学习技术已被引入，但大多侧重于价格预测而非结构性水平识别，这在SR水平检测中存在关键空白。

**Method:** DeepSupp提出一种新的深度学习方法，利用多头注意力机制分析空间相关性和市场微观结构关系。它整合了高级特征工程，构建动态相关矩阵，并采用基于注意力的自编码器进行鲁棒表示学习。最终的支撑水平通过无监督聚类（DBSCAN）提取。

**Result:** 在S&P 500股票上的综合评估表明，DeepSupp在六项金融指标（包括支撑准确性和市场机制敏感性）上均优于六种基线方法，达到了最先进的性能。

**Conclusion:** DeepSupp通过揭示细微的市场模式和改进技术交易策略，解决了SR水平检测中的关键空白，为现代金融分析提供了一个可扩展且可靠的解决方案。

> **ai_Abstract:** 本文提出了DeepSupp，一种基于深度学习的新方法，利用多头注意力机制和动态相关矩阵来识别金融支撑水平。该方法结合了高级特征工程、注意力自编码器和DBSCAN聚类。在S&P 500股票上的评估显示，DeepSupp在多项金融指标上优于现有基线方法，为动态市场中的支撑与阻力水平检测提供了一个先进且可靠的解决方案。

> **摘要翻译:** 支撑与阻力（SR）水平是技术分析的核心，指导交易员进行进场、出场和风险管理。尽管广泛使用，但传统的SR识别方法往往无法适应现代波动市场的复杂性。最近的研究引入了机器学习技术来解决以下挑战，但大多数关注价格预测而非结构性水平识别。本文提出了DeepSupp，一种新的深度学习方法，利用多头注意力机制分析空间相关性和市场微观结构关系，从而检测金融支撑水平。DeepSupp集成了高级特征工程，构建了捕捉不断变化的市场关系的动态相关矩阵，并采用基于注意力的自编码器进行鲁棒表示学习。最终的支撑水平通过无监督聚类，利用DBSCAN来识别重要的价格阈值。在S&P 500股票上的综合评估表明，DeepSupp优于六种基线方法，在六项金融指标上实现了最先进的性能，包括基本的支撑准确性和市场机制敏感性。DeepSupp在不同的市场条件下都取得了持续的结果，解决了SR水平检测中的关键空白，为现代金融分析提供了一个可扩展且可靠的解决方案。我们的方法突出了基于注意力架构在揭示细微市场模式和改进技术交易策略方面的潜力。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [353] [Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach](https://arxiv.org/abs/2507.01979)
> *使用LSTNet预测劳动力市场：一种多尺度深度学习方法*

*Adam Nelson-Archer, Aleia Sen, Meena Al Hasani, Sofia Davila, Jessica Le, Omar Abbouchi* | **Category: q-fin.ST, cs.AI, cs.LG, I.2.6; I.5.1** | **Updated: {updated}**

**Keywords:** 劳动力市场预测, 深度学习, LSTNet, 时间序列, 行业健康指数

**Comment:** Undergraduate senior project, University of Houston, Department of
  Computer Science

> **TL;DR:** 本文提出了一种使用LSTNet深度学习方法预测短期就业变化和评估长期行业健康的系统，该系统在大多数行业中表现优于基线模型。

**AI_Comments:** 该研究创新性地将LSTNet应用于劳动力市场预测和行业健康评估，提供了一个多尺度深度学习框架。其重要性在于能够提供短期就业预测和可解释的行业健康指标。未来的工作将侧重于提高模型的可解释性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 利用美国劳工统计局的劳动力市场数据，预测短期就业变化并评估长期行业健康。

**Method:** 采用长短期时间序列网络（LSTNet）处理多元时间序列数据，包括就业水平、工资、离职率和职位空缺。模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。

**Result:** 该方法在大多数行业（特别是在稳定行业）中优于基线模型，并且IEHI排名与实际就业波动之间表现出很强的一致性。

**Conclusion:** 使用LSTNet的深度学习方法能有效预测劳动力市场并评估行业健康，未来工作将集中于提高可解释性和泛化能力。

> **ai_Abstract:** 本文介绍了一种基于LSTNet的深度学习方法，用于利用美国劳工统计局的多元时间序列数据预测短期就业变化和评估行业健康。该模型能生成7天就业预测和行业就业健康指数（IEHI），并在大多数行业中超越基线模型，证明了其在劳动力市场分析中的有效性。

> **摘要翻译:** 我们提出了一种深度学习方法，利用美国劳工统计局的劳动力市场数据，预测短期就业变化并评估长期行业健康。我们的系统利用长短期时间序列网络（LSTNet）处理多元时间序列数据，包括就业水平、工资、离职率和职位空缺。该模型输出7天就业预测和可解释的行业就业健康指数（IEHI）。我们的方法在大多数行业，特别是在稳定行业中，表现优于基线模型，并且IEHI排名与实际就业波动之间表现出很强的一致性。我们讨论了误差模式、特定行业的表现以及未来提高可解释性和泛化能力的方向。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [365] [NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction](https://arxiv.org/abs/2507.02018)
> *NGAT：一种用于长期股票预测的节点级图注意力网络*

*Yingjie Niu, Mingchuan Zhao, Valerio Poti, Ruihai Dong* | **Category: q-fin.ST, cs.AI, cs.LG, I.2.1** | **Updated: {updated}**

**Keywords:** 图注意力网络, 股票预测, 金融应用, 企业关系图, 长期预测

**Comment:** 

> **TL;DR:** 提出NGAT模型和长期股票预测任务，以解决现有图学习方法在股票预测中的复杂性、泛化性差和关系图比较不足的问题，并在两个数据集上验证了其有效性。

**AI_Comments:** 本文的创新之处在于提出了专门针对长期股票预测的NGAT模型，并明确指出了现有图学习方法在金融应用中的具体挑战，尤其是在关系信息利用、模型泛化性和图结构比较方面的不足。其重要性在于为股票预测提供了一个更有效且泛化性更好的解决方案，并通过公开代码促进了研究的复现性。

<details>
  <summary>Details</summary>

**Motivation:** 现有图表示学习方法在金融应用中面临三个挑战：1) 关系信息的优势被下游任务设计限制所掩盖；2) 现有股票预测图模型过于复杂且泛化性差；3) 基于经验构建的企业关系图缺乏有效的图结构比较方法。

**Method:** 提出一个长期股票预测任务，并开发了一个专门针对企业关系图的节点级图注意力网络（NGAT）。此外，通过实验证明了现有基于模型下游任务性能的图比较方法的局限性。

**Result:** 在两个数据集上的实验结果一致表明了所提出的任务和模型的有效性。

**Conclusion:** 所提出的长期股票预测任务和NGAT模型能够有效解决现有图学习方法在股票预测中面临的挑战，并提高了预测性能。

> **ai_Abstract:** 本文针对现有图表示学习方法在股票预测中面临的挑战，包括关系信息利用受限、模型复杂性和泛化性差以及图结构比较不足，提出了一个长期股票预测任务和一个节点级图注意力网络（NGAT）。实验结果在两个数据集上验证了所提出任务和模型的有效性，并且还揭示了现有图比较方法的局限性。

> **摘要翻译:** 图表示学习方法已被广泛应用于金融领域，通过利用企业间关系来增强公司表示。然而，当前方法面临三个主要挑战：(1) 关系信息的优势被下游任务设计的局限性所掩盖；(2) 现有专门为股票预测设计的图模型通常过于复杂且泛化性差；(3) 基于经验构建的企业关系图缺乏对不同图结构的有效比较。为了解决这些局限性，我们提出了一个长期股票预测任务，并开发了一个专门为企业关系图量身定制的节点级图注意力网络（NGAT）。此外，我们通过实验证明了现有基于模型下游任务性能的图比较方法的局限性。在两个数据集上的实验结果一致表明了我们提出的任务和模型的有效性。该项目已在GitHub上公开，以鼓励可复现性和未来的研究。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [408] [Forecasting Nigerian Equity Stock Returns Using Long Short-Term Memory Technique](https://arxiv.org/abs/2507.01964)
> *使用长短期记忆技术预测尼日利亚股票回报*

*Adebola K. Ojo, Ifechukwude Jude Okafor* | **Category: q-fin.ST, cs.LG, 68T07** | **Updated: {updated}**

**Keywords:** 股票预测, LSTM, 尼日利亚股票市场, 深度学习, 时间序列

**Comment:** 10 pages

> **TL;DR:** 本研究利用长短期记忆（LSTM）模型，以超过90%的准确率成功预测了尼日利亚股票市场的未来回报。

**AI_Comments:** 该研究通过应用LSTM模型解决尼日利亚股票市场的预测问题，并取得了90%以上的高准确率，这体现了其在特定区域市场预测的创新性。然而，研究也指出单一模型的局限性，并建议未来探索混合模型，这表明当前模型在鲁棒性和泛化能力上可能仍有提升空间。

<details>
  <summary>Details</summary>

**Motivation:** 投资者和股票市场分析师在预测股票回报和做出明智投资决策方面面临重大挑战。股票回报的可预测性可以增强投资者信心，但其仍然是一项困难的任务。

**Method:** 本研究使用长短期记忆（LSTM）模型来预测未来的股票市场走势。研究使用了来自尼日利亚证券交易所（NSE）的历史数据集，该数据集经过清洗和标准化以设计LSTM模型。模型通过性能指标进行评估，并与人工神经网络（ANN）和卷积神经网络（CNN）等其他深度学习模型进行比较。

**Result:** 实验结果表明，当使用可靠的数据集进行训练时，LSTM模型能够以超过90%的准确率预测未来的股票市场价格和回报。

**Conclusion:** 本研究得出结论，如果训练得当，LSTM模型在预测金融时间序列相关问题方面非常有用。未来的研究应探索将LSTM模型与其他深度学习技术（如CNN）结合，创建混合模型，以减轻单一模型在未来股票预测中带来的风险。

> **ai_Abstract:** 本研究旨在解决股票回报预测的难题，利用长短期记忆（LSTM）模型对尼日利亚证券交易所的历史数据进行分析。经过数据清洗和标准化后，该LSTM模型被训练并评估，并与人工神经网络和卷积神经网络等其他深度学习模型进行了比较。实验结果显示，LSTM模型在可靠数据集上能以超过90%的准确率预测未来股票价格和回报。研究得出结论，LSTM模型在金融时间序列预测中表现出色，并建议未来研究探索结合多种深度学习技术以提高预测鲁棒性。

> **摘要翻译:** 投资者和股票市场分析师在预测股票回报和做出明智投资决策方面面临重大挑战。股票回报的可预测性可以增强投资者信心，但其仍然是一项困难的任务。为了解决这个问题，本研究利用长短期记忆（LSTM）模型来预测未来的股票市场走势。研究使用了来自尼日利亚证券交易所（NSE）的历史数据集，该数据集经过清洗和标准化以设计LSTM模型。模型通过性能指标进行评估，并与人工神经网络（ANN）和卷积神经网络（CNN）等其他深度学习模型进行比较。实验结果表明，当使用可靠的数据集进行训练时，LSTM模型能够以超过90%的准确率预测未来的股票市场价格和回报。本研究得出结论，如果训练得当，LSTM模型在预测金融时间序列相关问题方面非常有用。未来的研究应探索将LSTM模型与其他深度学习技术（如CNN）结合，创建混合模型，以减轻单一模型在未来股票预测中带来的风险。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [410] [News Sentiment Embeddings for Stock Price Forecasting](https://arxiv.org/abs/2507.01970)
> *新闻情感嵌入用于股票价格预测*

*Ayaan Qayyum* | **Category: q-fin.ST, cs.LG** | **Updated: {updated}**

**Keywords:** 新闻情感, 股票价格预测, 文本嵌入, 主成分分析, 机器学习

**Comment:** 12 pages, 11 figures

> **TL;DR:** 本文研究了如何利用《华尔街日报》的新闻头条数据，结合OpenAI文本嵌入和PCA，预测SPDR S&P 500 ETF Trust (SPY)的股票价格，并报告了显著的预测性能提升。

**AI_Comments:** 这项研究的创新之处在于利用先进的OpenAI文本嵌入模型和PCA对新闻头条进行特征提取，并将其应用于股票价格预测。其重要性在于证明了新闻情感数据在金融市场预测中的巨大潜力，40%的性能提升是一个显著的成果，为未来的金融预测模型提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是探讨新闻头条数据如何用于预测股票价格，特别是SPDR S&P 500 ETF Trust (SPY)的每日价格变动。研究旨在捕捉新闻对股票价格的时间依赖和时间无关的细微影响，同时处理潜在的滞后效应和市场噪音。

**Method:** 研究方法包括：使用《华尔街日报》的新闻头条数据；利用基于OpenAI的文本嵌入模型创建每个头条的向量编码；通过主成分分析(PCA)提取关键特征；收集美元指数(DXY)和国债收益率等金融和经济数据以提高模型性能；训练了超过390个机器学习推理模型。

**Result:** 初步结果显示，与没有新闻头条数据嵌入的机器学习系统相比，头条数据嵌入使股票价格预测性能至少提高了40%。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了利用《华尔街日报》新闻头条数据预测SPDR S&P 500 ETF Trust (SPY) 股票价格的方法。研究结合了OpenAI文本嵌入模型和PCA来处理头条数据，并纳入了金融经济指标。初步结果表明，新闻头条数据嵌入能显著提高股票价格预测性能，至少提升40%。

> **摘要翻译:** 本文将讨论如何使用头条数据预测股票价格。所讨论的股票价格是SPDR标准普尔500指数ETF信托基金，也称为SPY，它追踪美国500家最大上市公司的表现。一个关键焦点是使用《华尔街日报》(WSJ)的新闻头条，在每日时间尺度上预测股票价格的波动，并使用基于OpenAI的文本嵌入模型创建每个头条的向量编码，然后通过主成分分析(PCA)提取关键特征。这项工作的挑战在于捕捉新闻对股票价格的时间依赖和时间无关的细微影响，同时处理潜在的滞后效应和市场噪音。为了提高模型性能，收集了金融和经济数据；这些来源包括美元指数(DXY)和国债收益率。训练了超过390个机器学习推理模型。初步结果表明，与不使用头条数据嵌入的机器学习系统训练和优化相比，头条数据嵌入极大地有利于股票价格预测，性能至少提高了40%。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [415] [Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations](https://arxiv.org/abs/2507.01980)
> *金融网络欺诈检测：一种基于格兰杰因果解释的半监督GNN方法*

*Linh Nguyen, Marcel Boersma, Erman Acar* | **Category: q-fin.ST, cs.LG, stat.ML** | **Updated: {updated}**

**Keywords:** 金融欺诈检测, 半监督学习, 图神经网络, 格兰杰因果, 可解释性

**Comment:** 

> **TL;DR:** 提出SAGE-FIN，一个半监督GNN方法，用于金融网络欺诈检测，并提供格兰杰因果解释。

**AI_Comments:** 该论文的创新点在于结合了半监督GNN和格兰杰因果解释，有效地解决了金融欺诈检测中数据稀疏和可解释性差的痛点。其重要性在于提供了一个实用且符合监管要求的欺诈检测框架。潜在的局限性可能在于格兰杰因果关系在复杂金融网络中的解释能力边界，以及模型对高度非线性关系的捕捉能力。

<details>
  <summary>Details</summary>

**Motivation:** 金融行业欺诈活动每年造成数十亿美元损失，检测欺诈至关重要。现有机器学习方法面临数据标注稀疏和模型缺乏可解释性两大挑战。

**Method:** 本文提出SAGE-FIN，一种基于半监督图神经网络（GNN）的方法，结合格兰杰因果解释，用于金融交互网络。SAGE-FIN能基于弱标注（或未标注）数据点识别欺诈项，并通过突出网络中相关项来提供格兰杰因果解释，以满足监管要求。

**Result:** SAGE-FIN在真实世界数据集Bipartite Edge-And-Node Attributed financial network (Elliptic++)上，在没有预设网络结构假设的情况下，经验验证了其识别欺诈项的良好性能，并提供了格兰杰因果解释。

**Conclusion:** SAGE-FIN有效解决了金融欺诈检测中数据稀疏标注和模型可解释性不足的问题，并在真实世界数据上表现良好，提供了符合监管要求的解释。

> **ai_Abstract:** 本文提出SAGE-FIN，一种创新的半监督图神经网络（GNN）方法，旨在解决金融网络欺诈检测中数据标注稀疏和模型解释性不足的挑战。SAGE-FIN能够利用弱标注或未标注数据识别欺诈行为，并通过格兰杰因果关系提供可解释的欺诈原因。在真实世界金融数据集上的实验验证了其优越性能和解释能力，无需预设网络结构。

> **摘要翻译:** 金融行业的欺诈活动每年造成数十亿美元的损失。因此，检测欺诈是一项至关重要但技术上具有挑战性的任务，需要仔细分析大量数据。虽然机器学习（ML）方法似乎是可行的解决方案，但由于两大主要挑战，成功应用它们并非易事：（1）数据标注稀疏，这使得此类方法的训练具有挑战性（并伴随固有的标注成本），以及（2）ML模型的不透明性导致对标记项目的解释性不足，而这通常是业务法规所要求的。本文提出SAGE-FIN，一种基于半监督图神经网络（GNN）的方法，结合格兰杰因果解释，用于金融交互网络。SAGE-FIN学习根据弱标注（或未标注）数据点标记欺诈项目。为了遵守监管要求，通过使用格兰杰因果关系突出网络中的相关项目来解释被标记的项目。我们通过在真实世界数据集Bipartite Edge-And-Node Attributed financial network (Elliptic++)上对SAGE-FIN的有利性能进行实证验证，在不预设任何网络结构假设的情况下，为识别出的欺诈项目提供了格兰杰因果解释。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [142] [DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs](https://arxiv.org/abs/2507.02226)
> *DecoRTL：一种用于LLM生成RTL代码的运行时解码框架*

*Mohammad Akyash, Kimia Azar, Hadi Kamali* | **Category: cs.PL, cs.AR, cs.LG** | **Updated: {updated}**

**Keywords:** LLMs, RTL代码生成, 解码策略, 运行时框架, VerilogEval

**Comment:** Accepted to the International Conference on Computer-Aided Design
  (ICCAD 2025)

> **TL;DR:** LLM在RTL代码生成中存在解码问题，导致输出无效。DecoRTL是一种新的运行时解码策略，通过自洽性采样和语法感知温度自适应，显著提高了RTL代码的语法有效性、功能正确性和多样性，且无需模型微调。

**AI_Comments:** 这篇论文解决了将LLM应用于特定代码生成（RTL）的一个关键问题。其创新之处在于提出了一种“语法感知且对比性”的运行时解码策略，巧妙地区分了语法关键和设计关键区域。该方法无需模型微调即可操作，这使其对现有LLM具有高度实用性。对令牌级熵的实证分析为所提出的解决方案提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的大语言模型（LLMs）解码策略是为自然语言设计的，无法满足寄存器传输级（RTL）代码的结构和语义需求，导致生成幻觉、重复或无效的代码。经验分析表明，LLMs在结构模糊或语义复杂的区域表现出低置信度，且标准解码策略未能区分需要确定性（语法关键区域）和受益于探索性变异（设计关键区域）的区域。

**Method:** 本文提出了DecoRTL，一种新颖的、语法感知且对比性的运行时解码策略，用于RTL代码生成。DecoRTL包含两个互补组件：(i) 自洽性采样，生成多个候选并根据令牌级一致性重新排序，以促进正确性同时保持多样性；(ii) 语法感知温度自适应，根据令牌的语法和功能角色调整采样温度，对语法关键令牌强制执行低温度，对探索性令牌执行高温度。该方法完全在推理时操作，无需任何额外的模型微调。

**Result:** 通过在VerilogEval基准上对多个开源LLM进行评估，DecoRTL在语法有效性、功能正确性和输出多样性方面显示出显著改进，而执行开销（性能开销）则可以忽略不计。

**Conclusion:** DecoRTL通过引入一种新颖的运行时解码策略，成功解决了LLM在RTL代码生成中面临的挑战，显著提高了代码的语法有效性、功能正确性和多样性，且无需进行模型微调，为LLM在专业代码生成领域的应用提供了有效途径。

> **ai_Abstract:** DecoRTL是一种针对LLM生成RTL代码的运行时解码框架，旨在解决传统解码策略因无法满足RTL结构和语义要求而导致的无效代码问题。该研究首先通过分析令牌级熵，揭示了LLM在结构复杂区域置信度低且未能区分语法/设计关键区域的问题。为解决此问题，DecoRTL引入了自洽性采样和语法感知温度自适应两个核心组件：前者通过多候选生成与重排提升代码正确性和多样性，后者则根据令牌的语法角色动态调整采样温度。DecoRTL在推理时运行，无需模型微调，并在VerilogEval基准测试中显著提升了RTL代码的语法有效性、功能正确性和多样性，同时保持了可忽略的性能开销。

> **摘要翻译:** 作为众多应用之一，大型语言模型（LLMs）最近在自动化寄存器传输级（RTL）代码生成方面展现出前景。然而，传统的LLM解码策略，最初为自然语言设计，往往无法满足RTL的结构和语义要求，导致生成幻觉、重复或无效的代码输出。在本文中，我们首先通过对RTL生成过程中令牌级熵的实证分析，调查了这些解码失败的根本原因。我们的发现揭示了LLMs在结构模糊或语义复杂的区域表现出低置信度，表明标准解码策略未能区分需要确定性（语法关键区域）和受益于创造性探索性变异（设计关键区域）的区域。然后，为了克服这一点，我们引入了DecoRTL，一种新颖的运行时解码策略，它在RTL代码生成中既语法感知又具有对比性。DecoRTL集成了两个互补组件：(i) 自洽性采样，它生成多个候选并根据令牌级一致性对其进行重新排序，以促进正确性同时保持多样性；(ii) 语法感知温度自适应，它根据令牌的语法和功能角色对其进行分类并相应地调整采样温度，对语法关键令牌强制执行低温度，对探索性令牌执行高温度。我们的方法完全在推理时操作，无需任何额外的模型微调。通过在VerilogEval基准上对多个开源LLM进行评估，我们证明了在语法有效性、功能正确性和输出多样性方面的显著改进，而执行开销（性能开销）则可以忽略不计。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='physicsapp-ph'></a>
## physics.app-ph 

### [143] [On the Design of Corrugated Boards: A New FEM Modeling and Experimental Validation](https://arxiv.org/abs/2507.02189)
> *瓦楞纸板设计：一种新的有限元建模与实验验证*

*Ricardo Fitas, Heinz Joachim Schaffrath, Samuel Schabel* | **Category: physics.app-ph, cs.CE, physics.comp-ph** | **Updated: {updated}**

**Keywords:** 瓦楞纸板, 有限元建模, 均质化, 威布尔分布, 实验验证

**Comment:** 

> **TL;DR:** 本研究提出了一种简化的有限元建模方法，结合均质化和修正因子，用于瓦楞纸板大结构的快速准确模拟，并通过实验验证了其统计参数的有效性。

**AI_Comments:** 本研究的创新之处在于将均质化方法与基于实验数据的威布尔统计分布相结合，以简化瓦楞纸板的有限元模型。这种方法显著提高了计算效率，同时保持了模拟的准确性，对于大型瓦楞纸板结构的设计优化具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在优化瓦楞包装设计，通过简化有限元模型，实现更快且同样准确的模拟。

**Method:** 本研究提出了一种基于均质化方法的简化有限元建模方法，适用于瓦楞纸板大型结构。该方法结合了内部机制的修正因子，并通过两个统计威布尔分布（代表接触和屈曲机制）校正了厚度方向的有效弹性模量和有效厚度。威布尔参数通过实验分析获得并进行了验证。

**Result:** 结果表明，统计参数（$\beta_1 = 0.14$，$\beta_2 = 1.31$）可用于瓦楞纸板的简化表示，具有计算效率。

**Conclusion:** 这项研究通过简化有限元模型，实现了更快且同样准确的模拟，从而有助于优化瓦楞包装设计。

> **ai_Abstract:** 本研究提出了一种针对瓦楞纸板大型结构的简化有限元建模方法。该方法结合了均质化处理和基于统计威布尔分布的修正因子，以高效且准确地模拟瓦楞纸板在复杂载荷下的行为。通过实验验证，确定了可用于简化模型的关键统计参数，证明了其在计算效率上的优势，并为瓦楞包装的优化设计提供了新的工具。

> **摘要翻译:** 本研究提出了一种简化的有限元建模方法，适用于瓦楞纸板制成的大型结构，例如定制包装。该方法基于均质化方法，并结合了内部机制的修正因子。均质化过程通过将瓦楞几何形状转换为等效弹性模型来减少计算时间。在给定几何形状的大变形和接触存在的情况下，结构厚度方向的有效弹性模量以及有效厚度通过两个代表瓦楞纸板中接触和屈曲机制的统计威布尔分布进行修正。威布尔参数通过实验分析获得，并对该过程进行了验证。结果表明，统计参数（$\beta_1 = 0.14$，$\beta_2 = 1.31$）可用于瓦楞纸板的简化表示，具有计算效率。这项研究通过简化有限元模型，实现了更快且同样准确的模拟，从而有助于优化瓦楞包装设计。

</details>

[⬆️ 返回分类顶部](#physicsapp-ph) | [⬆️ 返回总目录](#toc)

---

### [183] [Modeling the Effective Elastic Modulus and Thickness of Corrugated Boards Using Gaussian Process Regression and Expected Hypervolume Improvement](https://arxiv.org/abs/2507.02208)
> *使用高斯过程回归和预期超体积改进建模瓦楞纸板的有效弹性模量和厚度*

*Ricardo Fitas* | **Category: physics.app-ph, cs.CE, physics.comp-ph** | **Updated: {updated}**

**Keywords:** 瓦楞纸板,有效弹性模量,厚度,高斯过程回归,预期超体积改进

**Comment:** This is the submitted version of the manuscript entitled "Modeling
  the Effective Elastic Modulus and Thickness of Corrugated Boards Using
  Gaussian Process Regression and Expected Hypervolume Improvement." The final
  version is published in "Lecture Notes in Civil Engineering" (Springer
  Nature) as part of the OPTARCH 2024 proceedings

> **TL;DR:** 本文使用高斯过程回归（GP）和预期超体积改进（EHVI）来准确建模瓦楞纸板的有效弹性模量和厚度，以优化其机械性能。

**AI_Comments:** 本文创新性地将高斯过程回归与预期超体积改进结合，用于复杂材料参数的建模，特别是瓦楞纸板的弹性模量和厚度。这种方法不仅考虑了预测的准确性，还通过不确定性量化来指导采样，提高了建模效率和对复杂响应曲面的适应性。对于需要精确材料参数以进行结构优化的工程应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模瓦楞纸板的有效弹性模量和厚度对于优化瓦楞材料在工程应用中的机械性能至关重要。

**Method:** 本文采用拉丁超立方采样（LHS）进行初始输入空间采样，然后使用高斯过程回归（GP），并辅以预期超体积改进（EHVI）作为多目标采集函数来建模响应超曲面。GP通过结合预测和不确定性来适应响应曲面的复杂性，并优先选择方差较高的点进行评估。性能通过均方误差（MSE）衡量。

**Result:** GP的预测结果为 \( \text{MSE}(E_{z, \text{eff}}) = 5.24 \, \text{kPa}^2 \) 和 \( \text{MSE}(th_{\text{eff}}) = 1 \, \text{mm}^2 \)。

**Conclusion:** 高斯过程（GP）在结构优化中展现出更高的准确性和适应性。

> **ai_Abstract:** 本文利用拉丁超立方采样（LHS）和高斯过程回归（GP）结合预期超体积改进（EHVI）来精确建模瓦楞纸板的有效弹性模量和厚度。研究强调了准确建模这些参数对优化瓦楞材料机械性能的重要性。GP模型通过结合预测和不确定性来适应复杂的响应曲面，并优先处理高方差点。实验结果显示，GP在有效弹性模量和厚度预测上的均方误差分别为 \( 5.24 \, \text{kPa}^2 \) 和 \( 1 \, \text{mm}^2 \)，证明了其在结构优化应用中的高准确性和适应性。

> **摘要翻译:** 这项工作旨在建模瓦楞纸板中有效弹性模量 \( E_{z, \text{eff}} \) 和厚度 \( th_{\text{eff}} \) 的超曲面。首先进行拉丁超立方采样（LHS），然后是高斯过程回归（GP），通过EHVI作为多目标采集函数进行增强。准确建模 \( E_{z, \text{eff}} \) 和 \( th_{\text{eff}} \) 对于优化瓦楞材料在工程应用中的机械性能至关重要。LHS为输入空间的初始采样提供了一种高效直接的方法；GP有望通过结合预测和不确定性来适应响应曲面的复杂性。因此，生成和评估的下一个点是基于超曲面的复杂性，并且一些点，特别是那些具有更高方差的点，被更多地利用并具有更重要的意义。GP与EHVI的性能通过均方误差（MSE）进行测量。GP的预测结果是 \( \text{MSE}(E_{z, \text{eff}}) = 5.24 \, \text{kPa}^2 \) 和 \( \text{MSE}(th_{\text{eff}}) = 1 \, \text{mm}^2 \)。因此，GP在未来的结构优化应用中具有更高的准确性和适应性。

</details>

[⬆️ 返回分类顶部](#physicsapp-ph) | [⬆️ 返回总目录](#toc)

---

### [274] [Experimental Multiport-Network Parameter Estimation and Optimization for Multi-Bit RIS](https://arxiv.org/abs/2507.02168)
> *多比特RIS实验性多端口网络参数估计与优化*

*Philipp del Hougne* | **Category: physics.app-ph, eess.SP** | **Updated: {updated}**

**Keywords:** RIS, 多端口网络理论, 参数估计, 互耦, 梯度下降

**Comment:** 5 pages including 2 figures

> **TL;DR:** 该论文提出了一种在未知环境下高效估计多比特RIS多端口网络模型参数的技术，结合了封闭形式和梯度下降方法，并进行了实验验证。

**AI_Comments:** 该论文通过提供一种在RIS设计和环境未知时估计关键MNT参数的方法，解决了RIS部署中的一个实际挑战。封闭形式和梯度下降步骤的结合是一种高效的创新方法。一个重要的发现是，尽管物理一致的MNT模型提供了显著更高的参数估计精度，但实际的端到端性能增益可能微乎其微，这对于实际系统设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前RIS参数化无线信道的理论研究使用多端口网络理论（MNT）模型来捕捉互耦效应，但在实际应用中，RIS设计和无线电环境往往未知。本研究旨在填补如何在这些实验相关场景中估计MNT模型参数的研究空白。

**Method:** 本文提出了一种结合封闭形式和梯度下降步骤的技术，以高效估计多比特可编程RIS元件的MNT模型参数。该技术考虑了参数模糊性，并在一个由八个未知设计的8比特可编程RIS元件参数化的未知富散射环境中进行了实验验证。

**Result:** 所提出的技术得到了实验验证。使用估计的MNT模型和MC-不感知级联模型优化的RIS配置进行了性能评估。结果显示，尽管模型在精度上相差高达17 dB，但最终的端到端性能差异很小。

**Conclusion:** 本研究成功开发并验证了一种在未知环境下估计多比特RIS多端口网络模型参数的实验技术。尽管MNT模型在参数估计方面比MC-不感知模型具有更高的精度，但实际的端到端性能差异很小。

> **ai_Abstract:** 本研究提出了一种结合封闭形式和梯度下降步骤的高效技术，用于在设计和环境未知的情况下，实验性估计多比特可编程智能反射面（RIS）的多端口网络（MNT）模型参数。该技术填补了实际应用中的研究空白，并经过实验验证。结果显示，尽管估计的MNT模型比互耦（MC）不感知模型在精度上高出17 dB，但优化后的RIS配置在端到端性能上差异不大。

> **摘要翻译:** 物理一致的RIS参数化无线信道理论研究使用多端口网络理论（MNT）模型来捕获互耦（MC）效应。然而，在实践中，RIS设计和无线电环境部分或完全未知。我们填补了在这些实验相关场景中如何估计MNT模型参数的研究空白。我们的技术有效结合了封闭形式和梯度下降步骤，并且可以应用于多比特可编程RIS元件。我们讨论了不可避免的（但操作上无关紧要的）参数模糊性。我们在一个由八个未知设计的8比特可编程RIS元件参数化的未知富散射环境中实验验证了我们的技术。我们实验评估了使用估计的MNT模型和MC-不感知级联模型优化的RIS配置的性能。尽管模型在精度上相差高达17 dB，但端到端性能差异很小。

</details>

[⬆️ 返回分类顶部](#physicsapp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioto'></a>
## q-bio.TO 

### [164] [A Multi-Scale Finite Element Method for Investigating Fiber Remodeling in Hypertrophic Cardiomyopathy](https://arxiv.org/abs/2507.02193)
> *调查肥厚性心肌病中纤维重塑的多尺度有限元方法*

*Mohammad Mehri, Kenneth S. Campbell, Lik Chuan Lee, Jonathan F. Wenk* | **Category: q-bio.TO, cs.CE** | **Updated: {updated}**

**Keywords:** 肥厚性心肌病, 纤维紊乱, 多尺度有限元方法, 心脏重塑, MyoFE

**Comment:** 

> **TL;DR:** 本研究利用多尺度有限元模型（MyoFE）探讨了肥厚性心肌病中异质性细胞异常如何导致显著的纤维紊乱，特别是在心外膜附近，并损害心脏功能，为未来的治疗干预提供了见解。

**AI_Comments:** 本研究通过引入多尺度有限元模型MyoFE，成功模拟了肥厚性心肌病中复杂的纤维重塑过程，体现了计算生物力学在疾病机制研究中的强大潜力。其创新之处在于量化了不同异质性细胞异常对纤维紊乱的独立影响，并发现了心外膜区域纤维紊乱程度更高的现象，这不仅与临床DT-MRI研究结果吻合，也为理解HCM的区域性病理生理学提供了新的视角。该框架为未来探索HCM的治疗干预措施提供了宝贵的工具。

<details>
  <summary>Details</summary>

**Motivation:** 肥厚性心肌病（HCM）的一个显著特征是纤维紊乱，这与心力衰竭等多种心脏事件相关。量化纤维紊乱对于理解该疾病复杂的病理生理学至关重要。本研究旨在调查异质性HCM引起的细胞异常在纤维紊乱发展中的作用及其随后对心脏泵血功能的影响。

**Method:** 研究采用名为MyoFE的多尺度有限元心脏建模框架，利用基于应力的定律来预测肌纤维和胶原的重定向，从而预测纤维紊乱。该模型专门用于量化异质性分布的超收缩性、低收缩性和纤维化对纤维紊乱发展的影响，并检验它们对心脏功能特征的影响。

**Result:** 研究结果表明，异质性细胞水平异常高度扰乱了心肌的正常力学，并导致显著的纤维紊乱。紊乱的模式因特定扰动而异，为HCM的进展提供了有价值的见解。尽管心脏肌肉内扰动区域随机分布，但在所有受扰动的左心室模型中，与心内膜相比，心外膜附近观察到显著更高的纤维紊乱。这种纤维紊乱的区域差异，无论扰动严重程度如何，都与之前的DT-MRI研究一致。此外，重塑的左心室的心脏功能下降，特别是在那些存在纤维化和低收缩性的左心室中。

**Conclusion:** 这些发现为肥厚性心肌病的结构和功能后果提供了重要见解，并为未来针对心脏重塑的治疗干预措施提供了框架。

> **ai_Abstract:** 本研究利用多尺度有限元心脏建模框架MyoFE，深入探讨了肥厚性心肌病（HCM）中异质性细胞异常（包括超收缩性、低收缩性和纤维化）如何导致纤维紊乱并影响心脏功能。模型预测显示，这些细胞异常显著扰乱了心肌力学，导致明显的纤维紊乱，且紊乱模式随扰动类型而异。值得注意的是，尽管扰动随机分布，但心外膜附近的纤维紊乱程度显著高于心内膜，这与现有临床观察一致。研究还发现，重塑的左心室，特别是伴有纤维化和低收缩性的左心室，心脏功能下降。这些发现为理解HCM的结构和功能后果提供了关键见解，并为未来开发针对心脏重塑的治疗策略奠定了基础。

> **摘要翻译:** 肥厚性心肌病（HCM）的一个显著特征是纤维紊乱，这与心力衰竭等多种心脏事件相关。量化纤维紊乱对于理解该疾病复杂的病理生理学仍然至关重要。本研究调查了异质性HCM引起的细胞异常在纤维紊乱发展中的作用及其随后对心脏泵血功能的影响。利用多尺度有限元心脏建模框架MyoFE，通过基于应力的定律预测肌纤维和胶原的重定向来预测纤维紊乱。具体来说，该模型用于量化超收缩性、低收缩性和纤维化的异质性分布对纤维紊乱发展的不同影响，并检验它们对心脏功能特征的影响。我们的结果表明，异质性细胞水平异常高度扰乱了心肌的正常力学，并导致显著的纤维紊乱。紊乱的模式因特定扰动而异，为HCM的进展提供了有价值的见解。尽管心脏肌肉内扰动区域随机分布，但在所有受扰动的左心室（LV）模型中，与心内膜相比，心外膜附近观察到显著更高的纤维紊乱。这种纤维紊乱的区域差异，无论扰动严重程度如何，都与之前的DT-MRI研究一致，突出了区域心肌力学在纤维紊乱发展中的作用。此外，重塑的左心室的心脏功能下降，特别是在那些存在纤维化和低收缩性的左心室中。这些发现为肥厚性心肌病的结构和功能后果提供了重要见解，并为未来针对心脏重塑的治疗干预措施提供了框架。

</details>

[⬆️ 返回分类顶部](#q-bioto) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [191] [TAGF: Time-aware Gated Fusion for Multimodal Valence-Arousal Estimation](https://arxiv.org/abs/2507.02080)
> *TAGF：用于多模态效价-唤醒度估计的时间感知门控融合*

*Yubeen Lee, Sangeun Lee, Chaewon Park, Junyeop Cha, Eunil Park* | **Category: cs.MM, cs.SD** | **Updated: {updated}**

**Keywords:** 多模态情感识别, 效价-唤醒度估计, 时间感知门控融合, BiLSTM, 模态错位

**Comment:** 9 pages, 2 figures, 2 tables

> **TL;DR:** TAGF是一个时间感知门控融合框架，用于解决多模态情感识别中因噪声和模态错位导致的效价-唤醒度估计性能下降问题，并在Aff-Wild2数据集上表现出色。

**AI_Comments:** TAGF的创新点在于其时间感知门控融合机制，特别是引入BiLSTM来学习递归步骤的相对重要性，这使得模型能够更好地处理情感表达的动态性和模态间的复杂交互。该方法对跨模态错位的强大鲁棒性是其重要优势，使其在真实世界应用中更具实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多模态情感识别在效价-唤醒度估计中，由于音频和视觉模态之间的噪声和错位，常常导致性能下降。

**Method:** 本文提出了TAGF，一个时间感知门控融合框架，用于多模态情感识别。TAGF通过基于BiLSTM的时间门控机制，自适应地调节递归注意力输出的贡献，学习每个递归步骤的相对重要性，并有效整合多步跨模态特征。通过将时间感知嵌入到递归融合过程中，TAGF能有效捕捉情感表达的顺序演变和模态间的复杂相互作用。

**Result:** 在Aff-Wild2数据集上的实验结果表明，TAGF与现有基于递归注意力的模型相比，取得了有竞争力的性能。此外，TAGF对跨模态错位表现出强大的鲁棒性，并能可靠地模拟真实世界条件下的动态情感转换。

**Conclusion:** TAGF通过其时间感知门控融合机制，有效解决了多模态情感识别中噪声和模态错位问题，提升了效价-唤醒度估计的性能和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为TAGF的时间感知门控融合框架，旨在解决多模态情感识别中效价-唤醒度估计因模态噪声和错位导致的性能下降问题。TAGF通过引入基于BiLSTM的时间门控机制，能够自适应地调节递归注意力输出的贡献，并有效整合多步跨模态特征，从而捕捉情感表达的时间演变和模态间复杂关系。实验证明，TAGF在Aff-Wild2数据集上表现出与现有模型相当的竞争力，并对跨模态错位具有强大的鲁棒性，能可靠地模拟动态情感转换。

> **摘要翻译:** 多模态情感识别在效价-唤醒度估计中，常常因音频和视觉模态之间的噪声和错位而导致性能下降。为了解决这一挑战，我们引入了TAGF，一个用于多模态情感识别的时间感知门控融合框架。TAGF根据时间动态自适应地调节递归注意力输出的贡献。具体来说，TAGF结合了基于BiLSTM的时间门控机制，以学习每个递归步骤的相对重要性，并有效整合多步跨模态特征。通过将时间感知嵌入到递归融合过程中，TAGF有效地捕捉了情感表达的顺序演变以及模态之间的复杂相互作用。在Aff-Wild2数据集上的实验结果表明，与现有基于递归注意力的模型相比，TAGF取得了有竞争力的性能。此外，TAGF对跨模态错位表现出强大的鲁棒性，并能可靠地模拟真实世界条件下的动态情感转换。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [197] [Designs from magic-augmented Clifford circuits](https://arxiv.org/abs/2507.02828)
> *魔术增强Clifford电路的设计*

*Yuzhen Zhang, Sagar Vijay, Yingfei Gu, Yimu Bao* | **Category: quant-ph, cond-mat.stat-mech, cond-mat.str-el, cs.IT, hep-th, math.IT** | **Updated: {updated}**

**Keywords:** k-设计, Clifford电路, 魔术门, 量子电路, 电路深度

**Comment:** 59 pages

> **TL;DR:** 该论文引入了魔术增强Clifford电路，以资源高效的方式实现近似k-设计，显著减少了电路深度和魔术门的使用，并改进了小k值的结果。

**AI_Comments:** 这篇论文提出了一种创新的量子电路设计方法，用于生成k-设计，这在量子信息任务中至关重要。其核心创新在于“魔术增强Clifford电路”的概念，它利用了Clifford电路的效率，同时策略性地添加非Clifford门以实现设计特性。电路深度和魔术门使用量的减少具有重要的实际意义。此外，经典统计力学描述的开发提供了定量的理解，而禁区定理的包含则增加了理论严谨性和实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在提出一种资源高效的方法来构建近似k-设计，同时减少量子电路的深度和非Clifford（“魔术”）门的使用。

**Method:** 论文引入了“魔术增强Clifford电路”，即将Clifford电路与恒定深度的非Clifford门电路相结合。通过数学证明，作者展示了这些浅层电路能够生成近似的酉和态k-设计。此外，论文还开发了随机电路架构的经典统计力学描述，并证明了关于特定架构生成设计能力的禁区定理。

**Result:** 1. 魔术增强的浅层Clifford电路能够以ε相对误差生成近似酉和态k-设计。2. 对于N个量子位，这些构造的总电路深度在一维中为O(log(N/ε)) + 2^(O(k log k))，在全连接电路中使用辅助量子位时为O(loglog(N/ε)) + 2^(O(k log k))，这改进了先前对于小k≥4的结果。3. 相对误差态k-设计仅涉及具有严格局部魔术的态。4. 在考虑具有有界加性误差的k-设计时，所需的魔术门数量参数化地减少。例如，仅需O(k^2)个与系统大小无关的单量子位魔术门即可生成加性误差态k-设计。5. 论文开发的经典统计力学描述定量地解释了加性误差态k-设计所需的深度和魔术门数量。6. 论文还证明了某些架构无法生成有界相对误差设计的禁区定理。

**Conclusion:** 该论文证明了魔术增强Clifford电路能够以资源高效的方式生成近似k-设计，显著减少了电路深度和魔术门的使用，特别是在小k值和加性误差设计方面取得了改进，并提供了包括禁区定理在内的理论框架。

> **ai_Abstract:** 该论文引入了“魔术增强Clifford电路”作为一种高效构建近似k-设计的架构。通过将浅层Clifford电路与恒定深度的非Clifford（魔术）门结合，作者展示了以更小的电路深度和更少的魔术门实现近似酉和态k-设计的能力，这改进了先前对于小k≥4的结果。研究还表明，对于加性误差态k-设计，魔术门的使用量可以显著减少，例如仅需O(k^2)个单量子位魔术门。论文还开发了经典统计力学描述来量化资源需求，并提出了关于特定架构的禁区定理。

> **摘要翻译:** 我们引入了魔术增强Clifford电路——一种Clifford电路前后由恒定深度非Clifford（“魔术”）门电路组成——作为一种资源高效的方式来实现近似k-设计，同时减少电路深度和魔术门的使用。我们证明了浅层Clifford电路，当用恒定深度魔术门电路增强时，可以生成具有ε相对误差的近似酉和态k-设计。这些构造在N个量子位上的总电路深度在一维中为O(log(N/ε)) + 2^(O(k log k))，在所有到所有电路中使用辅助量子位时为O(loglog(N/ε)) + 2^(O(k log k))，这改进了先前对于小k≥4的结果。此外，我们构造的相对误差态k-设计仅涉及具有严格局部魔术的态。当考虑具有有界加性误差的k-设计时，所需的魔术门数量参数化地减少。作为一个例子，我们展示了浅层Clifford电路后接O(k^2)个单量子位魔术门（与系统大小无关）可以生成一个加性误差态k-设计。我们开发了我们随机电路架构的经典统计力学描述，它提供了对加性误差态k-设计所需深度和魔术门数量的定量理解。我们还证明了各种架构生成具有有界相对误差设计的禁区定理。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [304] [Access Control Threatened by Quantum Entanglement](https://arxiv.org/abs/2507.02622)
> *量子纠缠威胁访问控制*

*Zhicheng Zhang, Mingsheng Ying* | **Category: quant-ph, cs.CR, cs.OS** | **Updated: {updated}**

**Keywords:** 量子纠缠, 访问控制, 量子安全, Mermin不等式, 安全模型

**Comment:** 23 pages, 10 figures

> **TL;DR:** 量子纠缠对经典访问控制系统构成威胁，本文首次展示了这种安全漏洞，并提出了新的量子访问控制模型来抵御该威胁。

**AI_Comments:** 本文创新性地揭示了量子纠缠对传统访问控制系统的潜在威胁，这是未来量子计算机系统安全领域的重要考量。其首次提出的明确漏洞场景具有开创性意义，并进一步提供了实际的解决方案，即新的量子访问控制模型，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是揭示当经典安全访问控制系统直接应用于量子环境时可能出现的安全漏洞，特别是由于量子纠缠现象对访问控制构成的威胁。

**Method:** 本文首先提出了一个明确的安全漏洞场景，该漏洞源于量子纠缠和对Mermin不等式的违反。然后，为了抵御这种威胁，作者提出了几种新的量子访问控制模型，并对其安全性、灵活性和效率进行了严格分析。

**Result:** 研究结果表明，如果现有计算机系统与量子计算集成，量子纠缠将对访问控制构成威胁。这种漏洞是由于量子力学允许纠缠现象并违反了Mermin不等式。

**Conclusion:** 量子纠缠对访问控制构成潜在威胁，但可以通过提出并分析新的量子访问控制模型来有效防御。

> **ai_Abstract:** 本文探讨了量子计算对经典访问控制系统的潜在威胁。研究发现，当经典访问控制系统应用于量子环境时，量子纠缠现象可能导致安全漏洞，这首次通过一个明确的场景得以展示，并归因于对Mermin不等式的违反。为应对这一新兴威胁，论文提出了数种新型量子访问控制模型，并对其安全性、灵活性和效率进行了深入分析。

> **摘要翻译:** 访问控制是计算机安全基石，旨在防止未经授权的资源访问。本文研究了量子计算机系统中的访问控制。我们首次提出了一个明确的安全漏洞场景，当一个经典安全的访问控制系统直接应用于量子环境时，该漏洞就会出现。此漏洞最终归因于量子力学允许纠缠现象并违反了Mermin不等式，Mermin不等式是著名的贝尔不等式的一个多方变体。这揭示了如果现有计算机系统与量子计算集成，量子纠缠将对访问控制构成威胁。为了防范此类威胁，我们提出了几种新的量子访问控制模型，并严格分析了它们的安全性、灵活性和效率。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [425] [Selective Feature Re-Encoded Quantum Convolutional Neural Network with Joint Optimization for Image Classification](https://arxiv.org/abs/2507.02086)
> *用于图像分类的选择性特征重编码量子卷积神经网络与联合优化*

*Shaswata Mahernob Sarkar, Sheikh Iftekhar Ahmed, Jishnu Mahmud, Shaikh Anowarul Fattah, Gaurav Sharma* | **Category: quant-ph, cs.LG** | **Updated: {updated}**

**Keywords:** 量子卷积神经网络, 图像分类, 特征重编码, 联合优化, NISQ

**Comment:** 26 pages, 12 figures, 6 Tables

> **TL;DR:** 本文提出了一种结合选择性特征重编码和并行模式联合优化量子卷积神经网络（QCNN）的新策略，以提高图像分类的准确性和泛化能力，并在MNIST和Fashion MNIST数据集上取得了显著效果。

**AI_Comments:** 该论文在QML领域，特别是QCNNs的图像分类应用方面，提出了创新的方法。选择性特征重编码策略是其亮点之一，它通过优化特征选择提高了量子电路的效率。此外，结合经典特征提取方法（PCA和自编码器）并采用联合优化的并行QCNN架构，有效利用了互补信息，是其提高性能的关键。这表明了经典与量子计算融合的潜力，对于提升NISQ设备在实际应用中的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子机器学习（QML）在噪声中等规模量子（NISQ）设备的推动下取得了显著进展，量子卷积神经网络（QCNNs）在分类量子和经典数据方面显示出潜力。本研究旨在通过增强特征处理和QCNN架构来提高图像分类的准确性。

**Method:** 1. 提出了一种选择性特征重编码策略，引导量子电路优先处理信息量最大的特征。2. 设计了一种新型并行模式QCNN架构，将主成分分析（PCA）和自编码器两种经典方法提取的特征通过统一训练方案同时整合。3. 采用联合优化训练过程，使QCNN从互补的特征表示中获益，实现模型参数的相互调整。

**Result:** 选择性特征重编码方法显著提高了量子电路的特征处理能力和性能。联合优化的并行QCNN架构在MNIST和Fashion MNIST数据集的二分类任务中，始终优于单独的QCNN模型和传统的独立学习后决策融合的集成方法，证实了其卓越的准确性和泛化能力。

**Conclusion:** 本文提出的选择性特征重编码和联合优化的并行模式QCNN架构显著提升了图像分类的准确性和泛化能力，为QCNN在经典数据分类中的应用提供了有效策略。

> **ai_Abstract:** 本文提出了一种用于图像分类的新型量子卷积神经网络（QCNN）策略，旨在提高分类准确性。该策略包括两个关键部分：一是选择性特征重编码，用于引导量子电路关注信息量最大的特征；二是并行模式QCNN架构，该架构通过联合优化将PCA和自编码器提取的特征整合起来。在MNIST和Fashion MNIST数据集上的实验结果表明，所提出的方法显著提升了QCNN的特征处理能力、准确性和泛化能力，优于现有方法。

> **摘要翻译:** 量子机器学习（QML）在噪声中等规模量子（NISQ）设备近期改进的推动下取得了显著进展。利用纠缠和叠加等量子原理，量子卷积神经网络（QCNN）在分类量子和经典数据方面都展示了有前景的结果。本研究在图像分类背景下检验了QCNN，并提出了一种新颖的策略来增强特征处理和QCNN架构，以提高分类准确性。首先，提出了一种选择性特征重编码策略，该策略引导量子电路优先处理信息量最大的特征，从而有效地导航希尔伯特空间的关键区域以找到最优解空间。其次，设计了一种新型并行模式QCNN架构，以在统一的训练方案中同时整合由两种经典方法（主成分分析（PCA）和自编码器）提取的特征。训练过程中涉及的联合优化使得QCNN能够从互补的特征表示中受益，从而实现模型参数的更好相互调整。为了评估这些方法，已使用广泛使用的MNIST和Fashion MNIST数据集进行了二分类任务的综合实验。实验结果表明，选择性特征重编码方法显著提高了量子电路的特征处理能力和性能。此外，联合优化的并行QCNN架构始终优于单独的QCNN模型和涉及独立学习后决策融合的传统集成方法，证实了其卓越的准确性和泛化能力。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [238] [An Easy Proof of a Weak Version of Chernoff inequality](https://arxiv.org/abs/2507.02759)
> *切尔诺夫不等式弱版本的一个简易证明*

*Sariel Har-Peled* | **Category: math.PR, cs.DS, math.CO** | **Updated: {updated}**

**Keywords:** 切尔诺夫不等式, 概率, 硬币投掷, 简易证明

**Comment:** 

> **TL;DR:** 论文提供了一个切尔诺夫不等式弱版本的简易证明，即在6M次公平硬币投掷中，最多M次正面的概率不大于1/2^M。

**AI_Comments:** 论文的创新点在于提供了一个非常简易的证明，尽管其结论是一个“非常弱”的版本。这可能对教学或初学者理解切尔诺夫不等式的核心思想有所帮助，但其在实际应用中的普适性可能受限。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提供一个简易但较弱的切尔诺夫不等式版本证明。

**Method:** 通过证明在6M次公平硬币投掷中，获得最多M次正面的概率小于等于1/2^M，从而提供切尔诺夫不等式的一个弱版本。

**Result:** 证明了在6M次公平硬币投掷中，获得最多M次正面的概率小于等于1/2^M。

**Conclusion:** 本文成功证明了切尔诺夫不等式的一个特定弱版本，即关于公平硬币投掷中正面次数的概率界限。

> **ai_Abstract:** 本文提出了切尔诺夫不等式的一个简易但较弱的版本。具体而言，该论文证明了在6M次公平硬币投掷中，获得最多M次正面的概率不大于1/2^M。

> **摘要翻译:** 我们证明了一个简易但非常弱的切尔诺夫不等式版本。即，在6M次公平硬币投掷中，获得至多M次正面的概率小于等于1/2^M。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

### [296] [Restricted Quasiconvexity Isometry Property for Symmetric $α$-Stable Random Matrices](https://arxiv.org/abs/2507.02649)
> *对称α-稳定随机矩阵的受限拟凸等距性质*

*Sunder Ram Krishnan* | **Category: math.PR, eess.SP** | **Updated: {updated}**

**Keywords:** 受限拟凸等距性质, α-稳定随机矩阵, 稀疏恢复, 样本复杂度, 集中不等式

**Comment:** 10 pages

> **TL;DR:** 本文为α-稳定随机投影提出了受限拟凸等距性质（RQIP），并推导了SαS分布随机矩阵满足RQIP所需的行数下界。证明依赖于SαS变量的经验分数矩集中不等式和稀疏lα球的覆盖数界限。结果表明样本复杂度反映了多项式尾部行为，并强调了在实践中可能需要用其他稀疏恢复公式替代RIP框架。

**AI_Comments:** 本文创新性地将受限等距性质推广到受限拟凸等距性质，以适应α-稳定随机矩阵的特性，这对于处理非高斯、重尾数据具有重要意义。其通过利用新的集中不等式和覆盖数界限来推导样本复杂度的方法是严谨的。此外，该研究结果对稀疏恢复领域的实际应用提出了重要启示，即传统的RIP框架可能不再是最优选择，这有助于推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 在实践中，RIP（受限等距性质）框架可能需要被其他稀疏恢复公式替代，例如基于零空间性质的那些。本文旨在为α-稳定随机投影提出一种RIP的推广，即受限拟凸等距性质（RQIP），并为此类随机矩阵推导一个成立条件。

**Method:** 本文提出了受限拟凸等距性质（RQIP），这是受限等距性质（RIP）的推广，适用于0<α<1的α-稳定随机投影。通过利用SαS变量的经验分数矩的集中不等式和稀疏lα球的覆盖数界限，推导了SαS分布随机矩阵满足RQIP所需的行数下界。

**Result:** 推导出了SαS分布随机矩阵满足受限拟凸等距性质（RQIP）所需的行数下界。所得的样本复杂度反映了集中度的多项式尾部行为。

**Conclusion:** 该研究得出的样本复杂度反映了集中度的多项式尾部行为，并强化了文献中提出的一个观点，即在实践中，RIP框架可能必须被其他稀疏恢复公式替代，例如那些基于零空间性质的公式。

> **ai_Abstract:** 本文引入了受限拟凸等距性质（RQIP），作为受限等距性质（RIP）对α-稳定随机投影的推广。研究推导了SαS随机矩阵满足RQIP所需的最小行数，其证明依赖于SαS变量的经验分数矩集中不等式和稀疏lα球的覆盖数界限。研究结果揭示了样本复杂度的多项式尾部行为，并支持了在实际应用中用其他稀疏恢复方法（如基于零空间性质的方法）替代RIP框架的观点。

> **摘要翻译:** 我们为0<α<1的α-稳定随机投影提出了一种受限等距性质（RIP）的推广，称为受限拟凸等距性质（RQIP）。推导了其条目服从对称α-稳定（SαS）分布的随机矩阵满足RQIP所需的行数下界。证明利用了两个关键组成部分：SαS变量的经验分数矩的集中不等式和稀疏lα球的覆盖数界限。所得的样本复杂度反映了集中度的多项式尾部行为，并强化了文献中提出的一个观察结果，即在实践中，RIP框架可能必须被其他稀疏恢复公式替代，例如那些基于零空间性质的公式。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='q-biope'></a>
## q-bio.PE 

### [248] [A Data-Driven Model Predictive Controller to manage epidemics: The case of SARS-CoV-2 in Mauritius](https://arxiv.org/abs/2507.01996)
> *一种数据驱动的模型预测控制器来管理流行病：毛里求斯SARS-CoV-2的案例*

*S. Z. Sayed Hassen, A. Aboudonia, J. Lygeros* | **Category: q-bio.PE, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 流行病管理, 模型预测控制, 社会隔离, SARS-CoV-2, 数据驱动

**Comment:** 6 pages, 6 figures, European Control Conference 2025

> **TL;DR:** 本文开发了一种数据驱动的模型预测控制器（MPC）来管理流行病中的社会隔离政策，以毛里求斯的SARS-CoV-2为例，模拟结果显示该方法能有效控制住院人数并显著减少死亡，且社会经济影响可忽略不计。

**AI_Comments:** 这项研究的创新之处在于将数据驱动的模型预测控制应用于流行病中的社会隔离政策管理，特别是结合了SIHRD模型和混合整数规划。其重要性体现在提供了一种量化且系统化的决策支持工具，以平衡疫情控制效果与社会经济影响。该方法通过模拟展示了其在控制医疗资源挤兑和降低死亡率方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探讨在流行病期间实施系统化社会隔离政策的好处。

**Method:** 研究开发了一种基于SIHRD模型的混合整数数据驱动模型预测控制（MPC）方案，该模型通过现有数据识别。该隔离方案将控制决策变量设定为有限的隔离级别，并限制级别转换需在最短时间后进行。以2021年12月至2022年5月毛里求斯SARS-CoV-2传播数据作为参考。

**Result:** 模拟结果验证了该设计，显示住院需求保持在医疗中心容量内，通过短期提高隔离级别可显著减少死亡人数，且社会经济影响可忽略不计。此外，引入更多隔离级别可实现更平滑的遏制方法，并显著减轻住院负担。

**Conclusion:** 数据驱动的模型预测控制器能够有效管理流行病中的社会隔离政策，在控制住院需求和减少死亡人数方面表现出色，同时将社会经济影响降至最低。增加隔离级别有助于实现更平滑和更有效的疫情控制。

> **ai_Abstract:** 本文提出了一种数据驱动的混合整数模型预测控制（MPC）方案，用于系统化管理流行病中的社会隔离政策。以毛里求斯SARS-CoV-2疫情为例，基于SIHRD模型和真实数据，该控制器通过调整隔离级别来优化疫情控制。仿真结果表明，该方法能有效控制住院人数在医疗系统容量内，显著降低死亡率，且对社会经济影响甚微。研究还发现，增加隔离级别有助于实现更平滑、更有效的疫情遏制，减轻医疗负担。

> **摘要翻译:** 这项工作调查了在流行病期间实施系统化社会隔离政策的好处。我们开发了一种基于SIHRD模型的混合整数数据驱动模型预测控制（MPC）方案，该模型从可用数据中识别。以2021年12月至2022年5月期间毛里求斯SARS-CoV-2病毒（也称为COVID-19）的传播案例作为参考点，数据在此期间获得。隔离方案的设计中，控制决策变量采用有限的数值集合，对应于所需的隔离级别。控制输入进一步限制为仅在最短时间后才能在级别之间转换。仿真结果验证了我们的设计，表明住院需求保持在医疗中心的容量范围内，通过在短时间内提高隔离级别，死亡人数显著减少，且社会和经济影响可忽略不计。我们还表明，引入额外的隔离级别可以实现更平滑的遏制方法，并显著减轻住院负担。

</details>

[⬆️ 返回分类顶部](#q-biope) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [257] [Perturbed Gradient Descent Algorithms are Small-Disturbance Input-to-State Stable](https://arxiv.org/abs/2507.02131)
> *受扰动梯度下降算法是小扰动输入到状态稳定的*

*Leilei Cui, Zhong-Ping Jiang, Eduardo D. Sontag, Richard D. Braatz* | **Category: math.OC, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 梯度下降, 鲁棒性, 输入到状态稳定性, Polyak-Lojasiewicz条件, 策略梯度

**Comment:** 16 pages

> **TL;DR:** 本文研究了梯度下降算法在扰动下的鲁棒性，引入了离散时间非线性动力系统的小扰动输入到状态稳定性（ISS）概念及其Lyapunov表征。研究表明，在目标函数满足广义非线性PL条件的情况下，梯度下降算法是小扰动ISS的，这意味着在足够小的扰动下，算法会收敛到最优点的邻域。该框架还应用于LQR和流行的策略梯度算法，证明它们也具有小扰动ISS特性。

**AI_Comments:** 本文的创新之处在于将小扰动输入到状态稳定性（ISS）的概念引入到梯度下降算法的鲁棒性分析中，并成功地将线性Polyka-Lojasiewicz（PL）条件推广到非线性版本。这为理解和保证优化算法在实际应用中面对扰动时的收敛性提供了一个新的理论工具。其重要性体现在它为各种梯度下降和策略梯度算法的鲁棒性提供了严格的数学证明，尤其是在控制和机器学习领域具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究梯度下降算法在扰动下的鲁棒性。

**Method:** 本文引入了离散时间非线性动力系统的小扰动输入到状态稳定性（ISS）概念及其Lyapunov表征。将传统的线性Polyak-Lojasiewicz（PL）条件扩展到非线性版本。在此基础上，证明了在目标函数满足广义非线性PL条件的情况下，梯度下降算法是小扰动ISS的。将该框架应用于LQR成本函数和多种策略梯度算法（包括自然策略梯度和高斯-牛顿法）进行验证。

**Result:** 研究表明，在目标函数满足广义非线性PL条件的情况下，梯度下降算法是小扰动ISS的。作为该框架的直接应用，证明了LQR成本函数满足广义非线性PL条件，从而确立了LQR的策略梯度算法是小扰动ISS的。此外，包括自然策略梯度和高斯-牛顿法在内的其他流行策略梯度算法也被证明是小扰动ISS的。

**Conclusion:** 在足够小的扰动下，梯度下降算法收敛到最优解的一个小邻域，这得益于其小扰动输入到状态稳定性（ISS）特性，该特性在目标函数满足广义非线性PL条件时成立。

> **ai_Abstract:** 本文深入探讨了梯度下降算法在存在扰动时的鲁棒性。研究引入了离散时间非线性系统的小扰动输入到状态稳定性（ISS）及其Lyapunov分析方法，并将经典的Polyka-Lojasiewicz条件推广到非线性形式。核心发现是，当目标函数满足广义非线性PL条件时，梯度下降算法展现出小扰动ISS特性，这保证了算法在小扰动下能收敛到最优点的附近。该理论框架被成功应用于证明LQR问题中的策略梯度算法以及其他流行的策略梯度算法（如自然策略梯度和高斯-牛顿法）也具备小扰动ISS特性。

> **摘要翻译:** 本文研究了梯度下降算法在扰动下的鲁棒性。本文介绍了离散时间非线性动力系统的小扰动输入到状态稳定性（ISS）的概念及其Lyapunov表征。然后，将传统的线性Polyak-Lojasiewicz（PL）条件扩展到非线性版本，并表明在目标函数满足广义非线性PL条件的情况下，梯度下降算法是小扰动ISS的。这种小扰动ISS特性保证了梯度下降算法在足够小的扰动下收敛到最优解的一个小邻域。作为所开发框架的直接应用，我们证明了LQR成本函数满足广义非线性PL条件，从而确立了LQR的策略梯度算法是小扰动ISS的。此外，包括自然策略梯度和高斯-牛顿法在内的其他流行策略梯度算法也被证明是小扰动ISS的。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [302] [Online Convex Optimization for Coordinated Long-Term and Short-Term Isolated Microgrid Dispatch](https://arxiv.org/abs/2507.02636)
> *在线凸优化用于协调长期和短期孤立微电网调度*

*Ning Qi, Yousuf Baker, Bolun Xu* | **Category: math.OC, cs.SY, eess.SY** | **Updated: {updated}**

**Keywords:** 在线凸优化, 微电网调度, 长期短期协调, 能量存储, 次线性遗憾界

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的在线凸优化框架，用于协调孤立微电网的长期和短期调度，显著降低成本并提高鲁棒性。

**AI_Comments:** 本文的创新点在于提出了一个结合凸包近似、核回归和自适应在线凸优化的非预测性长短期协调调度框架，有效解决了孤立微电网中混合储能的复杂调度问题。其通过事后最优轨迹训练和在线参考跟踪，显著提高了调度的经济性、稳定性和对不确定性的鲁棒性，为微电网的实际运行提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决孤立微电网中混合短长期储能的非凸和时间耦合问题，实现长期和短期调度协调，降低成本并提高系统韧性。

**Method:** 提出了一种非预测性长短期协调调度框架，包含：凸包近似模型处理非凸LDES电化学动力学；生成LDES和净负荷的事后最优荷电状态 (SoC) 轨迹进行离线训练；在线阶段，采用核回归动态更新SoC参考；提出自适应在线凸优化 (OCO) 算法，结合SoC参考跟踪和专家跟踪，以缓解近视效应并实现自适应步长优化；证明了长期和短期策略均实现次线性遗憾界。

**Result:** 所提方法优于现有技术，成本降低73.4%；通过参考跟踪消除负荷损失；通过OCO算法额外节省2.4%成本；益处随LDES持续时间延长而增加；对不良预测和意外系统故障表现出韧性。

**Conclusion:** 论文提出的在线凸优化调度框架，通过其创新的建模和算法，显著提高了孤立微电网调度的效率、经济性和鲁棒性。

> **ai_Abstract:** 本文提出了一种用于孤立微电网的创新型非预测性长短期协调调度框架。该框架利用凸包近似处理LDES的非凸动力学，并通过离线训练生成事后最优SoC轨迹。在线阶段，结合核回归和自适应在线凸优化算法，实现动态SoC参考更新、近视缓解和自适应步长优化。研究证明该方法在长期和短期策略中均能实现次线性遗憾界。仿真结果显示，相较于现有技术，该方法显著降低了成本（73.4%），消除了负荷损失，并对预测误差和系统故障具有鲁棒性。

> **摘要翻译:** 本文提出了一种新颖的非预测性长短期协调调度框架，用于具有混合短长期储能（LDES）的孤立微电网。我们引入了一个用于非凸LDES电化学动力学的凸包近似模型，以提高计算可行性和准确性。为了解决SoC动力学和长期合同中的时间耦合问题，我们生成了LDES和净负荷的事后最优荷电状态（SoC）轨迹用于离线训练。在在线阶段，我们采用核回归动态更新SoC参考，并提出了一种自适应在线凸优化（OCO）算法，该算法结合了SoC参考跟踪和专家跟踪，以减轻短视并实现自适应步长优化。我们严格证明了长期和短期策略都能随时间实现次线性遗憾界，且该界限随着回归场景的增多、跟踪惩罚的增强和凸近似的细化而改善。仿真结果表明，所提出的方法优于现有技术，成本降低了73.4%，通过参考跟踪消除了负荷损失，并通过OCO算法额外节省了2.4%的成本。这些优势随着LDES持续时间的延长而增加，并且该方法对不良预测和意外系统故障表现出韧性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [282] [Green Ammonia: A Techno-Economic Supply Chain Optimization](https://arxiv.org/abs/2507.02412)
> *绿色氨：技术经济供应链优化*

*Lucien Genge, Felix Müsgens* | **Category: econ.GN, cs.SY, eess.SY, q-fin.EC** | **Updated: {updated}**

**Keywords:** 绿色氨, 氢载体, 供应链优化, 技术经济分析, 能源政策

**Comment:** GitHub incl. data and results is linked in the text

> **TL;DR:** 本研究对绿色氨作为氢载体在欧洲供应链中的技术经济可行性进行了分析。研究发现，气态氢仍是最经济的进口选择，但绿色氨对液态氢的成本优势正在缩小。到2040年，绿色氨将主要用于直接应用。政策制定者应优先发展氢气管道基础设施，并谨慎投资氨的短期基础设施。

**AI_Comments:** 本论文对绿色氨在不断发展的绿色能源格局中的作用提供了及时且实用的技术经济分析。其主要创新在于将氨与其他氢载体进行比较，并根据成本动态和未来市场变化提供具体的政策建议，特别是强调了搁浅资产的风险。

<details>
  <summary>Details</summary>

**Motivation:** 绿色氨正在成为绿色能源供应链中的战略中间体，既可作为工业商品，也可作为氢载体。本研究旨在对绿色氨供应链进行技术经济分析。

**Method:** 本研究对绿色氨供应链进行了技术经济分析，比较了从全球生产到欧洲消费者的成本效益途径，并评估了氨与替代氢载体的表现。

**Result:** 气态氢始终是欧洲最经济的进口选择。氨对液态氢的成本优势正在缩小（从2030年的16%降至2040年的10%）。摩洛哥、美国和阿联酋等具有竞争力的氨供应商受益于低可再生能源成本，预计到2040年价格将大幅下降。最佳运输方式因消费者需求和距离而异：卡车适用于所有距离的低需求，铁路适用于中等距离，管道适用于高需求场景。到2040年，氨将主要用于直接用途，因为氢气消费者将越来越多地转向直接氢气供应。

**Conclusion:** 政策制定者应优先发展氢气分配管道基础设施，谨慎投资氨的短期到中期基础设施优势，并限制长期依赖氨作为氢载体，以减轻搁浅资产风险。

> **ai_Abstract:** 本研究对绿色氨供应链进行了技术经济分析，评估了其作为氢载体在欧洲市场与其他选项相比的成本效益。研究发现，虽然气态氢仍然是最经济的进口选择，但绿色氨对液态氢的成本优势正在缩小，摩洛哥、美国和阿联酋等地区具有竞争力的生产成本。研究确定了基于需求和距离的最佳运输方式，并预测到2040年，随着直接氢气供应的普及，氨将主要用于直接应用。研究建议政策制定者优先发展氢气管道基础设施，谨慎投资氨的短期至中期基础设施，并避免长期过度依赖氨作为氢载体，以防止搁浅资产风险。

> **摘要翻译:** 绿色氨正在成为绿色能源供应链中的战略中间体，有效地作为工业商品和氢载体。本研究对绿色氨供应链进行了技术经济分析，比较了从全球生产到欧洲消费者的成本效益途径，并评估了氨与替代氢载体的表现。气态氢始终是欧洲最经济的进口选择，尽管氨对液态氢的成本优势正在缩小（从2030年的16%降至2040年的10%）。具有竞争力的氨供应商，特别是摩洛哥、美国和阿拉伯联合酋长国，受益于低可再生能源成本，预计到2040年，由于电力、电解槽和转化技术成本的下降，价格将大幅降低。最佳运输方式因消费者需求和距离而异：卡车适用于所有距离的低需求，铁路适用于中等距离，管道适用于高需求场景。到2040年，氨将主要用于直接用途，因为氢气消费者将越来越多地转向直接氢气供应。政策制定者应优先发展氢气分配管道基础设施，谨慎投资氨的短期到中期基础设施优势，并限制长期依赖氨作为氢载体，以减轻搁浅资产风险。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

### [357] [Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents](https://arxiv.org/abs/2507.02287)
> *看穿绿色：基于文本的分类与企业绿色专利回报*

*Lapo Santarlasci, Armando Rungi, Antonio Zinilli* | **Category: econ.GN, cs.CL, q-fin.EC** | **Updated: {updated}**

**Keywords:** 绿色专利, 自然语言处理, 专利分类, 企业回报, 文本分析

**Comment:** 

> **TL;DR:** 本研究利用自然语言处理（NLP）识别“真正”的绿色专利，发现它们仅占先前分类的绿色专利的20%，但能显著提升企业的销售额、市场份额和生产力，高新颖性绿色专利还能带来更高利润，强调了文本分析在专利分类和政策制定中的重要性。

**AI_Comments:** 该论文的创新之处在于应用自然语言处理技术，超越了传统的粗略分类，实现了对“真正”绿色专利的精准识别。这种更精细的分类对于评估绿色技术的真实影响和制定有效政策至关重要。研究不仅识别了这些专利，还量化了它们对企业财务表现的积极影响，为理解绿色创新经济价值提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在利用自然语言处理（NLP）从官方支持文件中识别“真正”的绿色专利，并探讨持有这些“真正”绿色专利与企业财务表现之间的关系。

**Method:** 研究首先从约1240万份先前文献中分类为绿色的专利开始训练。接着，通过训练一个简单的神经网络，利用与环境技术相关的表达的向量表示来扩大基线词典，从而识别“真正”的绿色专利。在论文的第二部分，研究测试了专利持有与欧盟企业层面财务指标之间的关系，并控制了反向因果关系。

**Result:** 研究发现，“真正”的绿色专利约占先前文献中分类为绿色专利总数的20%。这些“真正”的绿色专利被后续发明的引用率约低1%。在控制反向因果关系后，研究表明持有至少一项“真正”的绿色专利能提高企业的销售额、市场份额和生产力。如果将分析限定在高新颖性的“真正”绿色专利，它们还能带来更高的利润。

**Conclusion:** 研究结果强调了使用文本分析进行更细致的专利分类的重要性，这对于不同领域的政策制定非常有用。

> **ai_Abstract:** 本研究利用自然语言处理（NLP）技术，从大量现有绿色专利数据中识别出“真正”的绿色专利。通过训练神经网络扩大词典，研究发现“真正”的绿色专利仅占先前分类的20%，且被引用率略低。然而，进一步分析表明，持有“真正”绿色专利能显著提升企业的销售额、市场份额和生产力，而高新颖性绿色专利更能带来更高的利润。这些发现强调了文本分析在实现精细化专利分类及其对政策制定方面的重要性。

> **摘要翻译:** 本论文引入自然语言处理（NLP）技术，用于从官方支持文件中识别“真正”的绿色专利。我们从约1240万份先前文献中已分类为绿色的专利开始训练。因此，我们训练了一个简单的神经网络，通过环境技术相关表达的向量表示来扩大基线词典。经过测试，我们发现“真正”的绿色专利约占先前文献中分类为绿色专利总数的20%。我们展示了技术类别的异质性，然后检查发现“真正”的绿色专利被后续发明引用的次数大约少1%。在论文的第二部分，我们测试了专利持有与欧盟企业层面财务账目仪表盘之间的关系。在控制反向因果关系后，我们表明持有至少一项“真正”的绿色专利能提高销售额、市场份额和生产力。如果我们将分析限制在高新颖性的“真正”绿色专利，我们发现它们也能产生更高的利润。我们的发现强调了使用文本分析来衡量更细致的专利分类的重要性，这对于不同领域的政策制定非常有用。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='q-fingn'></a>
## q-fin.GN 

### [298] [Optimising task allocation to balance business goals and worker well-being for financial service workforces](https://arxiv.org/abs/2507.01968)
> *优化任务分配以平衡金融服务员工的业务目标和员工福祉*

*Chris Duckworth, Zlatko Zlatev, James Sciberras, Peter Hallett, Enrico Gerding* | **Category: q-fin.GN, cs.HC** | **Updated: {updated}**

**Keywords:** 任务分配, 遗传算法, 员工福祉, 金融服务, 优化

**Comment:** Accepted in Journal of Modelling in Management

> **TL;DR:** 利用遗传算法优化金融服务任务分配，以平衡业务目标和员工福祉。

**AI_Comments:** 该论文的创新点在于首次明确将员工福祉纳入任务分配的优化模型中，这在现有分配和调度模型中是一个重要的空白。它不仅关注了传统的效率和业务目标，还强调了员工压力和福祉的重要性，为金融服务行业提供了更人性化和可持续的任务分配解决方案。此外，通过使用遗传算法，该模型在实际应用中表现出优于基线方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 金融服务公司的数据错误识别和解决任务给分析师带来巨大压力，导致资源挑战和业务风险。本文旨在解决此问题，提出一个兼顾业务目标和分析师福祉的任务分配模型。

**Method:** 采用遗传算法（GA）来优化形式化模型，以将任务分配和调度给分析师。该方案能够根据分析师的技能和经验分配任务，同时考虑员工福祉目标。

**Result:** 所提出的遗传算法模型优于基线启发式算法和当前工作实践，并适用于一系列单目标和多目标的实际场景。元启发式算法（如GA）能够有效地找到足够好的分配方案，为金融服务经理提供建议。

**Conclusion:** 本文提出了一个明确优化员工福祉的任务分配模型，同时在效率上优于当前工作实践，填补了现有分配和调度模型在充分考虑员工福祉方面的空白。

> **ai_Abstract:** 本文提出了一种基于遗传算法的任务分配模型，旨在解决金融服务行业中数据错误处理任务给分析师带来巨大压力的问题。该模型在分配和调度任务时，不仅考虑了业务目标和分析师的技能经验，还明确纳入了员工福祉。研究表明，该模型在效率上优于现有方法，并适用于多种实际场景，为金融服务经理提供了平衡效率与员工福祉的有效工具。

> **摘要翻译:** 目的：金融服务公司管理着海量数据，需要及时识别和解决错误。解决这些相关任务经常给金融分析师团队带来巨大压力，导致资源挑战和业务风险增加。为了解决这一挑战，我们引入了一个正式的任务分配模型，该模型同时考虑了以业务为导向的目标和分析师的福祉。
方法：我们使用遗传算法（GA）来优化我们的正式模型，以将任务分配和调度给分析师。所提出的解决方案能够将任务分配给具有适当技能和经验的分析师，同时考虑到员工福祉目标。
发现：我们证明了我们的遗传算法模型优于基线启发式算法、当前工作实践，并且适用于一系列单目标和多目标的实际场景。我们讨论了元启发式算法（如GA）有效找到足够好的分配方案的潜力，这可以为金融服务经理提供建议。
原创性：现有分配和调度模型的一个关键空白是未能充分考虑员工福祉。本文提出了一个明确优化福祉的分配模型，同时仍在效率上改进了当前的工作实践。

</details>

[⬆️ 返回分类顶部](#q-fingn) | [⬆️ 返回总目录](#toc)

---

### [358] [Integrating Large Language Models in Financial Investments and Market Analysis: A Survey](https://arxiv.org/abs/2507.01990)
> *大型语言模型在金融投资和市场分析中的整合：一项综述*

*Sedigheh Mahdavi, Jiating, Chen, Pradeep Kumar Joshi, Lina Huertas Guativa, Upmanyu Singh* | **Category: q-fin.GN, cs.AI, cs.LG** | **Updated: {updated}**

**Keywords:** 大型语言模型, 金融投资, 市场分析, 金融科技, 综述

**Comment:** 

> **TL;DR:** 该综述系统地概述了大型语言模型在金融领域的最新研究，涵盖了其在投资策略、风险评估、情绪分析等方面的应用，并讨论了其能力、挑战和未来方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地整理了大型语言模型在金融领域应用的最新进展，为研究人员和从业者提供了一个清晰的路线图。其创新之处在于将现有研究划分为明确的四个框架，这有助于理解不同集成和应用LLMs的方法。同时，它也明确指出了该领域的能力、挑战和未来方向，为后续研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的金融投资策略依赖于定量模型、基本面分析和技术指标。然而，大型语言模型（LLMs）引入了处理和分析大量结构化与非结构化数据、提取有意义见解并实时增强决策的新能力。本综述旨在提供一个关于LLMs在金融领域应用的结构化概览。

**Method:** 本综述通过将研究贡献分为四个主要框架来系统地概述LLMs在金融领域的最新研究：基于LLM的框架和管道、混合集成方法、微调和适应方法以及基于代理的架构。它还回顾了LLMs在选股、风险评估、情绪分析、交易和金融预测中的应用。

**Result:** 本综述提供了LLMs在金融领域应用的结构化概览，并将其研究贡献分为四类主要框架。它还回顾了LLMs在选股、风险评估、情绪分析、交易和金融预测等多个应用领域的研究进展。通过回顾现有文献，本研究强调了LLMs在金融市场中的能力、挑战和潜在方向。

**Conclusion:** 大型语言模型显著增强了金融决策能力，能够处理大量数据并提取洞察。本综述通过系统分类和应用回顾，揭示了LLMs在金融投资和市场分析中的潜力、面临的挑战以及未来的发展方向。

> **ai_Abstract:** 本综述全面审视了大型语言模型（LLMs）在金融投资和市场分析中的应用。论文指出，LLMs通过处理海量结构化和非结构化数据，增强了传统投资策略的分析能力。它将现有研究分为LLM-based Frameworks and Pipelines、Hybrid Integration Methods、Fine-Tuning and Adaptation Approaches和Agent-Based Architectures四个主要框架。此外，文章还详细回顾了LLMs在选股、风险评估、情绪分析、交易和金融预测等具体金融应用中的研究进展。最终，本研究旨在揭示LLMs在金融市场中的潜力、挑战及未来发展方向。

> **摘要翻译:** 大型语言模型（LLMs）已被应用于金融决策，增强了投资策略的分析能力。传统投资策略通常利用定量模型、基本面分析和技术指标。然而，LLMs引入了处理和分析大量结构化和非结构化数据、提取有意义见解并实时增强决策的新能力。本综述提供了LLMs在金融领域最新研究的结构化概览，将研究贡献分为四个主要框架：基于LLM的框架和管道、混合集成方法、微调和适应方法以及基于代理的架构。本研究对近期LLMs在选股、风险评估、情绪分析、交易和金融预测等应用方面的研究进行了结构化回顾。通过回顾现有文献，本研究强调了LLMs在金融市场中的能力、挑战和潜在方向。

</details>

[⬆️ 返回分类顶部](#q-fingn) | [⬆️ 返回总目录](#toc)

---

### [417] [Predicting and Explaining Customer Data Sharing in the Open Banking](https://arxiv.org/abs/2507.01987)
> *预测并解释开放银行中客户数据共享行为*

*João B. G. de Brito, Rodrigo Heldt, Cleo S. Silveira, Matthias Bogaert, Guilherme B. Bucco, Fernando B. Luce, João L. Becker, Filipe J. Zabala, Michel J. Anzanello* | **Category: q-fin.GN, cs.LG** | **Updated: {updated}**

**Keywords:** 开放银行, 客户数据共享, XGBoost, SHAP, 可解释性AI

**Comment:** 

> **TL;DR:** 本研究预测并解释了开放银行中客户数据共享行为，利用XGBoost模型和SHAP方法分析了巴西金融数据。

**AI_Comments:** 本文的创新之处在于结合了预测模型（XGBoost）和可解释性人工智能（SHAP+CART），不仅预测了客户数据共享行为，还深入理解了其驱动因素。研究使用了来自巴西金融机构的真实、大规模数据，增强了其在实际应用中的相关性。

<details>
  <summary>Details</summary>

**Motivation:** 开放银行的出现改变了金融数据管理，对金融机构的市场动态和营销策略产生重大影响。在数据流入和流出管理中，理解客户数据共享行为对于提升竞争力至关重要，因此需要预测并解释这种行为。

**Method:** 本研究提出了一个框架来预测和解释客户通过开放银行共享数据的倾向。研究使用了来自一家大型巴西金融机构（约320万客户）的数据，采用结合ADASYN和NEARMISS的混合数据平衡策略来解决数据共享的稀有性，并增强XGBoost模型的训练。解释性模型分析（EMA）阶段结合了Shapley加性解释（SHAP）方法和分类回归树（CART）技术，以揭示对客户决策最有影响的特征。

**Result:** XGBoost模型准确预测了客户数据共享，流入准确率达到91.39%，流出准确率达到91.53%。EMA阶段揭示了最重要的影响特征包括移动渠道的交易和购买数量、这些渠道内的互动，以及与信用相关的特征，特别是全国银行系统中的信用卡使用情况。

**Conclusion:** 研究结果强调了移动参与度和信用在驱动客户数据共享行为中的关键作用，为金融机构在开放银行环境中增强竞争力和创新提供了战略性见解。

> **ai_Abstract:** 本研究提出一个框架，预测并解释在开放银行中客户数据共享行为。该研究使用来自巴西一家大型金融机构的数据，采用ADASYN和NEARMISS混合平衡策略训练XGBoost模型，实现了91%以上的预测准确率。通过结合SHAP和CART的解释性模型分析，研究识别出移动渠道互动、交易购买量以及信用卡使用等信用相关特征是影响客户数据共享的关键因素，为金融机构在开放银行背景下提升竞争力提供了重要洞察。

> **摘要翻译:** 开放银行的出现代表了金融数据管理的一次重大转变，影响着金融机构的市场动态和营销策略。这种日益激烈的竞争既带来了机遇也带来了挑战，因为机构在管理数据流入以改善产品和服务的同时，也要减轻可能帮助竞争对手的数据流出。本研究引入了一个框架，旨在预测客户通过开放银行共享数据的倾向，并通过解释性模型分析（EMA）来解释这种行为。研究使用了来自一家拥有约320万客户的大型巴西金融机构的数据，并采用了结合ADASYN和NEARMISS技术的混合数据平衡策略，以解决数据共享的稀有性并增强XGBoost模型的训练。这些模型准确预测了客户数据共享，流入准确率达到91.39%，流出准确率达到91.53%。EMA阶段结合了Shapley加性解释（SHAP）方法和分类回归树（CART）技术，揭示了对客户决策最有影响的特征。关键特征包括移动渠道的交易和购买数量、这些渠道内的互动，以及与信用相关的特征，特别是全国银行系统中的信用卡使用情况。这些结果强调了移动参与度和信用在驱动客户数据共享行为中的关键作用，为金融机构在开放银行环境中增强竞争力和创新提供了战略性见解。

</details>

[⬆️ 返回分类顶部](#q-fingn) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [313] [Terahertz Chip-Scale Meta-Networks with LSPR Routing: A Theoretical Framework](https://arxiv.org/abs/2507.02764)
> *太赫兹片上超网络与LSPR路由：一个理论框架*

*Maryam Khodadadi, Hamidreza Taghvaee, Pei Xiao, Gabriele Gradoni, Mohsen Khalily* | **Category: physics.optics, eess.SP, physics.app-ph** | **Updated: {updated}**

**Keywords:** 太赫兹通信, 片上互连, 局部表面等离子体共振, 石墨烯, 超网络

**Comment:** 

> **TL;DR:** 该研究提出了一种基于石墨烯调制太赫兹等离子体激元通信的芯片级超网络理论框架，通过LSPR路由实现可重构的实时波束控制，并展示了其在低延迟、高性能片上互连中的潜力。

**AI_Comments:** 该论文在太赫兹芯片级互连领域提出了一个新颖的理论框架，通过利用石墨烯的可调谐特性实现LSPR路由和动态波束控制，具有显著的创新性。其将物理模型、耦合模理论与算法控制相结合的方法，为未来高性能、低延迟的片上通信提供了新的可能性。特别是对多种超像素天线配置的设计和系统级可行性验证，展示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的有线互连面临高电阻率和延迟问题，而毫米波无线解决方案则存在带宽拥堵和干扰。太赫兹等离子体通信提供高数据速率和宽带宽，且与纳米光子平台兼容，是解决这些挑战的潜在方案。

**Method:** 该研究引入了一种二元场驱动超路由方法，该方法由一个半解析框架支持，用于模拟太赫兹等离子体现象与石墨烯电磁特性之间的可调谐相互作用。通过调制石墨烯的阻抗，该方法能够实现局部表面等离子体共振（LSPR）在超网络中的动态耦合和路由。结合解析电导率模型、耦合模理论和算法控制，实现了LSPR波束控制的预测配置。设计了四种超像素天线配置，并提出了一个用于场驱动LSPR超网络的耦合模理论来建模电流分布和预测远场特性。

**Result:** 理论与全波仿真结果显示出高度一致性。对点对点超无线链路的分析表明，该方案在WiNoC和chiplet应用中具有实现低延迟、高性能太赫兹通信的可扩展性。系统级指标证实了其在空间受限、高速互连中的可行性。

**Conclusion:** 该研究提出的太赫兹片上超网络与LSPR路由理论框架，通过石墨烯调制实现了动态波束控制，并在理论和仿真中验证了其在构建高性能、低延迟芯片级互连中的可行性和潜力。

> **ai_Abstract:** 该论文提出了一个用于太赫兹（THz）芯片级超网络的理论框架，该框架利用石墨烯的电磁特性通过调制局部表面等离子体共振（LSPR）实现动态路由和实时波束控制。该方法通过二元场驱动超路由和半解析框架，结合耦合模理论和算法控制，实现了LSPR的预测性配置。研究设计了多种超像素天线配置，并验证了理论与仿真结果的一致性。该技术有望为WiNoC和chiplet应用中的低延迟、高性能太赫兹片上互连提供解决方案。

> **摘要翻译:** 高效的片上互连对于现代微电子光子系统至关重要，可支持高带宽和低延迟处理。传统的有线链路面临高电阻率和延迟，而毫米波无线解决方案则受限于带宽拥堵和干扰。基于表面等离子体激元（SPPs）的太赫兹（THz）等离子体通信提供高数据速率和宽带宽，并与纳米光子平台兼容。这项工作引入了一种由半解析框架支持的二元场驱动超路由方法，该框架模拟了太赫兹等离子体现象与石墨烯电磁特性之间可调谐的相互作用。通过调制石墨烯的阻抗，该方法能够实现局部表面等离子体共振（LSPR）在超网络中的动态耦合和路由，从而促进片上系统中的实时波束控制。结合解析电导率模型、耦合模理论和算法控制，该方法能够预测性地配置可重构石墨烯超表面中基于LSPR的转向。设计了四种超像素天线配置：Y型超路由器、超切换器、五面超发射器和CP型超核，分别支持单向辐射、双向转向、频率驱动转换和圆偏振。化学势调制创建了可重构的LSPR路径和虚拟SPP通道。提出了一种用于场驱动LSPR超网络的耦合模理论，以建模电流分布并预测远场特性。结果表明理论与全波仿真之间高度一致。分析了点对点超无线链路，展示了其在WiNoC和chiplet应用中实现低延迟、高性能太赫兹通信的可扩展性。系统级指标证实了其在空间受限、高速互连中的可行性。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

### [426] [Toward a Robust and Generalizable Metamaterial Foundation Model](https://arxiv.org/abs/2507.02436)
> *迈向一个鲁棒且可泛化的超材料基础模型*

*Namjung Kim, Dongseok Lee, Jongbin Yu, Sung Woong Cho, Dosung Lee, Yesol Park, Youngjoon Hong* | **Category: physics.optics, cs.AI** | **Updated: {updated}**

**Keywords:** 超材料, 基础模型, 零样本预测, 逆向设计, 贝叶斯Transformer

**Comment:** 

> **TL;DR:** 引入MetaFO，一个受大型语言模型启发的贝叶斯Transformer基础模型，用于超材料设计，实现零样本预测和非线性逆向设计，克服现有AI在超材料设计中的局限性。

**AI_Comments:** 本文的创新点在于将大型语言模型中的基础模型概念引入到超材料设计领域，提出了MetaFO。其重要性在于通过实现零样本预测和强大的OOD泛化能力，克服了现有AI方法在超材料设计中的主要限制，极大地扩展了设计空间并加速了新材料的发现。这是一个重要的范式转变。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI驱动的超材料设计策略受限于任务特定再训练、差的分布外（OOD）泛化能力以及需要单独的正向和逆向设计模型。

**Method:** 引入了超材料基础模型（MetaFO），这是一个受大型语言模型启发的基于贝叶斯Transformer的基础模型。MetaFO将超材料视为将材料属性映射到结构响应的算子。

**Result:** MetaFO能够实现跨多样化、未见过的材料属性和结构响应组合的概率性、零样本预测。它在非线性逆向设计方面表现出色，即使在OOD条件下也是如此。它揭示了复杂的结构-属性关系并显著扩展了设计空间。

**Conclusion:** MetaFO是一个可扩展且可泛化的框架，标志着AI驱动的超材料发现领域的范式转变，为下一代创新铺平了道路。

> **ai_Abstract:** 本文提出了MetaFO，一个受大型语言模型启发的贝叶斯Transformer基础模型，旨在解决当前AI在超材料设计中面临的局限，如任务特定训练和OOD泛化差。MetaFO能够学习超材料的内在力学，实现对未知材料属性和结构响应的零样本预测，并在OOD条件下进行高效的非线性逆向设计，从而显著扩展了超材料的设计空间，代表了AI驱动超材料发现的范式转变。

> **摘要翻译:** 材料功能的进步推动了各个领域的创新，其中由结构而非成分定义的超材料正在引领潮流。尽管人工智能（AI）驱动的设计策略兴起，但其影响受到任务特定再训练、糟糕的分布外（OOD）泛化能力以及需要单独的正向和逆向设计模型的限制。为了解决这些限制，我们引入了超材料基础模型（MetaFO），这是一个受大型语言模型启发的基于贝叶斯Transformer的基础模型。MetaFO学习超材料的底层力学，能够对多样化、未见过的材料属性和结构响应组合进行概率性、零样本预测。它在非线性逆向设计方面也表现出色，即使在OOD条件下也是如此。通过将超材料视为将材料属性映射到结构响应的算子，MetaFO揭示了复杂的结构-属性关系并显著扩展了设计空间。这个可扩展且可泛化的框架标志着AI驱动的超材料发现领域的范式转变，为下一代创新铺平了道路。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='q-fincp'></a>
## q-fin.CP 

### [335] [FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports](https://arxiv.org/abs/2507.01991)
> *FinAI-BERT：一种基于Transformer的金融报告中AI披露句子级检测模型*

*Muhammad Bilal Zafar* | **Category: q-fin.CP, cs.CL, econ.GN, q-fin.EC, q-fin.GN** | **Updated: {updated}**

**Keywords:** AI披露检测, 金融报告, Transformer, FinAI-BERT, 句子级分类

**Comment:** The FinAI-BERT model can be directly loaded via Hugging Face
  Transformers (https://huggingface.co/bilalzafar/FinAI-BERT) for
  sentence-level AI disclosure classification

> **TL;DR:** FinAI-BERT是一种基于Transformer的模型，用于在金融报告中句子级别检测AI相关披露，性能优异且具有可解释性。

**AI_Comments:** FinAI-BERT的创新之处在于其将Transformer架构应用于金融领域，实现句子级的AI披露检测，解决了现有方法在粒度、可解释性和鲁棒性上的不足。其高准确率和F1分数证明了模型的有效性。此外，通过引入SHAP进行可解释性分析以及进行全面的鲁棒性检查，增强了模型在实际应用中的可信赖性。这项研究对于金融分析师、监管机构和学者监控AI在金融领域的应用具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 金融服务中人工智能（AI）的普及促使人们对能够系统性检测企业备案文件中AI相关披露的工具需求不断增长。然而，现有方法（如关键词扩展或文档级分类）在粒度、可解释性和鲁棒性方面存在不足。

**Method:** 本研究引入了FinAI-BERT，一个经过领域适应的基于Transformer的语言模型，旨在金融文本中对AI相关内容进行句子级分类。该模型在一个手工整理的平衡数据集上进行了微调，该数据集包含从669份美国银行年度报告（2015年至2023年）中抽取的1,586个句子。

**Result:** FinAI-BERT取得了接近完美的分类性能（准确率为99.37%，F1分数为0.993），优于传统的基线模型，如逻辑回归、朴素贝叶斯、随机森林和XGBoost。通过基于SHAP的token归因确保了可解释性，偏置分析和鲁棒性检查证实了模型在不同句子长度、对抗性输入和时间样本下的稳定性。

**Conclusion:** 理论上，这项研究通过使用Transformer架构实现细粒度、主题特定的分类，推动了金融自然语言处理的发展。实践上，它为寻求监控AI在金融机构中传播和框架的分析师、监管机构和学者提供了一个可扩展、透明的解决方案。

> **ai_Abstract:** 本研究提出了FinAI-BERT，一个专门用于金融文本中AI披露句子级检测的Transformer模型。该模型通过在精心策划的金融报告数据集上进行微调，实现了99.37%的准确率和0.993的F1分数，显著优于传统基线。FinAI-BERT还通过SHAP分析提供了可解释性，并通过鲁棒性检查确保了稳定性。这项工作不仅推进了金融NLP的细粒度分类，也为金融机构中AI扩散的监测提供了一个实用的、透明的工具。

> **摘要翻译:** 人工智能（AI）在金融服务中的普及促使人们对能够系统性检测企业备案文件中AI相关披露的工具需求不断增长。虽然先前的方法通常依赖于关键词扩展或文档级分类，但它们在粒度、可解释性和鲁棒性方面存在不足。本研究引入了FinAI-BERT，一个经过领域适应的基于Transformer的语言模型，旨在金融文本中对AI相关内容进行句子级分类。该模型在一个手工整理的平衡数据集上进行了微调，该数据集包含从669份美国银行年度报告（2015年至2023年）中抽取的1,586个句子。FinAI-BERT取得了接近完美的分类性能（准确率为99.37%，F1分数为0.993），优于传统的基线模型，如逻辑回归、朴素贝叶斯、随机森林和XGBoost。通过基于SHAP的token归因确保了可解释性，偏置分析和鲁棒性检查证实了模型在不同句子长度、对抗性输入和时间样本下的稳定性。理论上，这项研究通过使用Transformer架构实现细粒度、主题特定的分类，推动了金融自然语言处理的发展。实践上，它为寻求监控AI在金融机构中传播和框架的分析师、监管机构和学者提供了一个可扩展、透明的解决方案。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [344] [A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention](https://arxiv.org/abs/2507.00884)
> *通过线性张量化四边形注意力实现可扩展和量子精确的生物分子力场基础模型*

*Qun Su, Kai Zhu, Qiaolin Gou, Jintu Zhang, Renling Hu, Yurong Li, Yongze Wang, Hui Zhang, Ziyi You, Linlong Jiang, Yu Kang, Jike Wang, Chang-Yu Hsieh, Tingjun Hou* | **Category: physics.chem-ph, cs.AI, cs.LG, physics.bio-ph** | **Updated: {updated}**

**Keywords:** 生物分子模拟, 力场, 量子精度, 注意力机制, 基础模型

**Comment:** 

> **TL;DR:** 该论文引入了LiTEN-FF，一个新型AI力场基础模型，利用张量化四边形注意力（TQA）实现量子精确的生物分子模拟，在大型系统上提供最先进的性能，并比现有模型快10倍。

**AI_Comments:** 该论文的创新之处在于其提出的张量化四边形注意力（TQA），它以线性复杂度处理三体和四体相互作用，以及LiTEN-FF作为一个基础模型，实现了广泛的化学泛化能力。这项工作通过弥合QM精度和经典力场效率之间的差距，显著推动了生物分子模拟领域的发展，这对于药物发现至关重要。对于大型分子（约1000个原子）实现10倍的推理速度提升是一个重大的实际进步。

<details>
  <summary>Details</summary>

**Motivation:** 精确的原子级生物分子模拟对疾病理解、药物发现和生物材料设计至关重要，但现有方法存在局限性：经典力场效率高但精度不足，量子力学方法精度高但计算成本过高，而现有AI力场在平衡多体建模复杂性、精度和速度方面存在困难，且受限于数据和泛化性。

**Method:** 本文引入了LiTEN，一种新型等变神经网络，其核心是张量化四边形注意力（TQA）。TQA通过向量操作重新参数化高阶张量特征，以线性复杂度高效地建模三体和四体相互作用，避免了昂贵的球谐函数。在此基础上，构建了LiTEN-FF，一个AI力场基础模型，在nablaDFT数据集上进行预训练以实现广泛的化学泛化，并在SPICE上进行微调以实现准确的溶剂化系统模拟。

**Result:** LiTEN在rMD17、MD22和Chignolin的大多数评估子集上实现了最先进（SOTA）的性能，超越了MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持迄今为止最全面的下游生物分子建模任务，包括QM级构象搜索、几何优化和自由能表面构建，同时对于大型生物分子（约1000个原子）的推理速度比MACE-OFF快10倍。

**Conclusion:** 本文提出了一个基于物理原理、高效的框架，推进了复杂的生物分子建模，为药物发现和相关应用提供了多功能基础。

> **ai_Abstract:** 本论文介绍了LiTEN-FF，一个量子精确且可扩展的AI生物分子力场基础模型。它利用LiTEN，一个带有张量化四边形注意力（TQA）的新型等变神经网络，高效地建模复杂的多体相互作用。LiTEN-FF在nablaDFT上预训练并在SPICE上微调，在生物分子模拟中实现了最先进的性能，在大型系统的精度和速度方面显著优于现有模型，为药物发现提供了全面的下游建模任务支持。

> **摘要翻译:** 精确的原子级生物分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高，但在许多化学和生物过程中关键的过渡态和精细构象细节方面缺乏准确性。量子力学（QM）方法高度准确，但对于大规模或长时间模拟而言计算上不可行。基于AI的力场（AIFFs）旨在以高效实现QM级精度，但难以平衡多体建模的复杂性、准确性和速度，常受限于有限的训练数据和不足的泛化验证。为克服这些挑战，我们引入了LiTEN，一个带有张量化四边形注意力（TQA）的新型等变神经网络。TQA通过向量操作重新参数化高阶张量特征，以线性复杂度高效地建模三体和四体相互作用，避免了昂贵的球谐函数。基于LiTEN，LiTEN-FF是一个强大的AIFF基础模型，在广泛的nablaDFT数据集上预训练以实现广泛的化学泛化，并在SPICE上微调以实现准确的溶剂化系统模拟。LiTEN在rMD17、MD22和Chignolin的大多数评估子集上实现了最先进（SOTA）的性能，超越了MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持迄今为止最全面的下游生物分子建模任务，包括QM级构象搜索、几何优化和自由能表面构建，同时对于大型生物分子（约1000个原子）的推理速度比MACE-OFF快10倍。总而言之，我们提出了一个基于物理原理、高效的框架，推进了复杂的生物分子建模，为药物发现和相关应用提供了多功能基础。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

### [434] [Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation](https://arxiv.org/abs/2507.02752)
> *可合成性设计：一种逆合成指导的分子类似物生成框架*

*Shuan Chen, Gunwook Nam, Yousung Jung* | **Category: physics.chem-ph, cs.AI** | **Updated: {updated}**

**Keywords:** 逆合成, 分子生成, 可合成性, 药物发现, SynTwins

**Comment:** 

> **TL;DR:** SynTwins是一种逆合成指导的框架，用于生成可合成的分子类似物，弥合了计算设计与实验合成之间的鸿沟。

**AI_Comments:** SynTwins的创新之处在于其将逆合成策略融入分子生成过程，有效解决了AI设计分子在合成可行性上的痛点。它通过模拟专家化学家的思维模式，为计算化学和药物发现提供了一个更实用的工具，有望加速新分子的发现与合成。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI生成的分子虽然具有理想性质，但其合成可行性是计算药物和材料发现中的关键瓶颈，许多结构难以或无法合成。

**Method:** 引入SynTwins框架，通过模拟专家化学家策略的三步过程设计可合成的分子类似物：逆合成、相似构建块搜索和虚拟合成。

**Result:** 与现有机器学习模型相比，SynTwins在生成可合成类似物方面表现出卓越性能，同时保持与原始目标分子的高度结构相似性。与现有分子优化框架结合时，能生成具有可比性质且合成可行的分子。

**Conclusion:** SynTwins有效弥合了计算设计与实验合成之间的鸿沟，为加速发现具有所需性质的可合成分子提供了一个实用解决方案。

> **ai_Abstract:** 本文提出了SynTwins，一个逆合成指导的分子类似物设计框架，旨在解决AI生成分子与其实际合成可行性之间的脱节。SynTwins通过模拟化学家的逆合成、构建块搜索和虚拟合成三步策略，生成易于合成的分子类似物。实验结果表明，SynTwins在生成可合成类似物方面优于现有模型，并能与分子优化框架结合，确保生成分子的合成可行性，从而有效连接了计算设计与实验合成。

> **摘要翻译:** AI生成的具有理想性质的分子与它们的合成可行性之间的脱节仍然是计算药物和材料发现中的一个关键瓶颈。尽管生成式AI加速了候选分子的提出，但其中许多结构被证明难以或无法使用已建立的化学反应合成。在此，我们引入SynTwins，一个新颖的逆合成指导的分子类似物设计框架，它通过模拟专家化学家策略的三步过程来设计可合成的分子类似物：逆合成、相似构建块搜索和虚拟合成。在对比评估中，SynTwins在生成可合成类似物方面表现出优于现有最先进机器学习模型的性能，同时保持与原始目标分子的高度结构相似性。此外，当与现有分子优化框架结合时，我们的混合方法能够生成具有与无约束分子生成器相当的性质分布，但其可合成性得到保证的分子。我们对各种分子数据集的全面基准测试表明，SynTwins有效地弥合了计算设计与实验合成之间的鸿沟，为加速发现具有所需性质的可合成分子提供了一个实用解决方案，适用于广泛的应用。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csos'></a>
## cs.OS 

### [348] [Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency](https://arxiv.org/abs/2507.02135)
> *剖析移动DVFS调速器对LLM推理性能和能效的影响*

*Zongpu Zhang, Pranab Dash, Y. Charlie Hu, Qiang Xu, Jian Li, Haibing Guan* | **Category: cs.OS, cs.CL** | **Updated: {updated}**

**Keywords:** LLM推理, 移动设备, DVFS调速器, 能效, FUSE

**Comment:** equal contribution between Zhang and Dash

> **TL;DR:** 研究发现移动设备上LLM推理的DVFS调速器缺乏协同导致能效低下，提出并设计了FUSE统一调速器，显著提升了LLM推理的能效。

**AI_Comments:** 该论文创新性地揭示了移动设备上LLM推理中，独立DVFS调速器之间缺乏协同是导致能效低下的关键问题。通过深入的测量分析，并提出统一的FUSE调速器，为移动LLM的优化提供了切实可行的解决方案，对未来移动AI应用的发展具有重要意义。其贡献在于不仅指出了问题，还提出了有效的应对策略。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在移动设备上的部署面临计算、内存和能耗的巨大挑战。现有移动LLM框架中CPU、GPU和内存的DVFS调速器独立运行且相互之间没有感知，导致能效低下。

**Method:** 首先，测量了移动设备上LLM框架的能效，发现现有独立调速器导致长达40.4%的额外延迟。其次，深入研究了移动调速器之间相互作用（或缺乏相互作用）如何导致LLM推理的低效率。最后，基于这些洞察，设计了FUSE——一个统一的、能量感知的调速器。

**Result:** 测量结果显示，现有移动调速器组合在相同能耗下，导致预填充和解码延迟增加高达40.4%。FUSE在ShareGPT数据集上的评估显示，在相同每token能耗下，它平均减少了首次token生成时间7.0%-16.9%，每输出token时间25.4%-36.8%。

**Conclusion:** 通过深入分析移动设备DVFS调速器对LLM推理能效的影响，并设计了统一的FUSE调速器，显著提高了移动LLM推理的性能和能效。

> **ai_Abstract:** 本研究深入分析了移动设备上DVFS调速器对大型语言模型（LLM）推理性能和能效的影响。发现现有独立的CPU、GPU和内存调速器缺乏协同，导致LLM推理能效低下，延迟增加高达40.4%。为解决此问题，论文设计并提出了FUSE，一个统一的能量感知调速器。实验结果表明，FUSE显著降低了LLM推理的首次token生成时间和每输出token时间，在相同能耗下，平均性能提升显著。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地被集成到运行在数十亿移动设备上的各种应用和服务中。然而，由于LLMs对计算、内存以及最终能耗的高要求，将其部署在资源受限的移动设备上面临巨大挑战。尽管当前移动LLM框架使用了CPU、GPU和内存这三个耗电组件——即使主要运行GPU LLM模型——现代移动设备中为CPU、GPU和内存优化的DVFS调速器却独立运行且相互之间没有感知。受上述观察的启发，在这项工作中，我们首先测量了由各种LLM模型组成的SOTA LLM框架在手机上的能效，结果显示，对于采样预填充和解码长度，在相同能耗下，三联移动调速器导致预填充和解码延迟延长高达40.4%，相比于CPU、GPU和内存频率的最佳组合。其次，我们进行了一项深入的测量研究，以揭示移动调速器之间复杂的相互作用（或缺乏相互作用）是如何导致LLM推理的上述低效率的。最后，基于这些洞察，我们设计了FUSE——一个统一的、能量感知的调速器，用于优化移动设备上LLM推理的能效。我们使用ShareGPT数据集的评估显示，FUSE在各种移动LLM模型上，在相同每token能耗下，平均将首次token生成时间减少了7.0%-16.9%，将每输出token时间减少了25.4%-36.8%。

</details>

[⬆️ 返回分类顶部](#csos) | [⬆️ 返回总目录](#toc)

---

<a id='q-finpm'></a>
## q-fin.PM 

### [349] [Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning](https://arxiv.org/abs/2507.01972)
> *基于强化学习的加速投资组合优化和期权定价*

*Hadi Keramati, Samaneh Jazayeri* | **Category: q-fin.PM, cs.AI, cs.LG, q-fin.CP** | **Updated: {updated}**

**Keywords:** 强化学习, 投资组合优化, 期权定价, 迭代求解器, 预处理

**Comment:** 

> **TL;DR:** 本文提出一个基于强化学习的框架，用于动态调整迭代求解器中块预处理器的大小，以加速投资组合优化和期权定价中的收敛速度并降低计算成本。

**AI_Comments:** 本文的创新点在于将强化学习应用于迭代求解器的预处理参数动态调整，解决了传统方法中参数调优复杂和收敛慢的问题。这对于需要快速决策的金融领域，如动态投资组合分配和实时期权定价，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的投资组合优化和期权定价中的大型线性系统求解面临计算成本高和收敛速度慢的问题。直接求逆计算成本高，迭代方法在病态系统下收敛慢，且传统预处理技术需要问题特定的参数调优。

**Method:** 本文采用强化学习（RL）来动态调整块预处理器的大小，以加速迭代求解器的收敛。该方法应用于投资组合优化和期权定价中的大型线性系统求解。

**Result:** 在真实世界的投资组合优化矩阵集上的评估表明，本文提出的RL框架能够调整预处理并显著加速收敛，同时降低计算成本。

**Conclusion:** 所提出的加速求解器支持动态投资组合分配和实时期权定价中更快的决策制定。

> **ai_Abstract:** 本文介绍了一个基于强化学习的框架，用于优化投资组合优化和期权定价中迭代求解器的块预处理器大小。针对大型线性系统求解中存在的计算成本高和收敛慢问题，该框架利用强化学习动态调整块预处理器大小，从而加速迭代求解器的收敛。实验证明，该方法能显著加速收敛并降低计算成本，从而支持更快的决策制定。

> **摘要翻译:** 我们提出一个由强化学习（RL）驱动的框架，用于优化投资组合优化和期权定价中迭代求解器中块预处理器的大小。投资组合优化中的协方差矩阵或期权定价模型中微分算子的离散化导致大型线性系统 $\mathbf{A}\textbf{x}=\textbf{b}$ 的形式。高维投资组合或精细网格期权定价的直接求逆会产生显著的计算成本。因此，在实际情况中，迭代方法通常用于投资组合。然而，病态系统收敛缓慢。传统的预处理技术通常需要问题特定的参数调优。为了克服这一限制，我们依靠RL动态调整块预处理器的大小，并加速迭代求解器的收敛。对一系列真实世界投资组合优化矩阵的评估表明，我们的RL框架可用于调整预处理并显著加速收敛并降低计算成本。所提出的加速求解器支持动态投资组合分配和实时期权定价中更快的决策制定。

</details>

[⬆️ 返回分类顶部](#q-finpm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [377] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
> *解决湍流磁流体动力学：一种混合算子-扩散框架*

*Semih Kacmaz, E. A. Huerta, Roland Haas* | **Category: physics.flu-dyn, cs.AI, cs.LG, gr-qc, physics.comp-ph, J.2; I.2** | **Updated: {updated}**

**Keywords:** 磁流体动力学湍流, 物理信息神经网络算子, 扩散模型, 机器学习, 高雷诺数

**Comment:** 

> **TL;DR:** 该研究提出了一个结合PINOs和扩散模型的混合机器学习框架，用于准确模拟不同雷诺数下的二维不可压缩电阻磁流体动力学湍流，尤其在高雷诺数下表现出色。

**AI_Comments:** 该论文的创新之处在于将PINOs与扩散模型相结合，这种混合方法有效地解决了高雷诺数下湍流MHD模拟中低频连贯性与高频随机性共存的挑战。它突破了传统确定性代理模型的瓶颈，特别是在极端湍流条件下的表现，为复杂物理系统的精确建模提供了新的范式，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 模拟高雷诺数下的湍流磁流体动力学（MHD）演化具有挑战性，传统的确定性代理模型难以达到所需的准确性。

**Method:** 提出了一种混合机器学习框架，结合了物理信息神经网络算子（PINOs）和基于分数的生成扩散模型。PINOs用于预测连贯的低频动力学，而条件扩散模型则随机校正高频残差，从而实现对充分发展湍流的精确建模。

**Result:** 该框架在Re = 1000和3000时，能忠实重构速度场和磁场的完整频谱能量分布，并捕获非高斯统计、间歇性结构和交叉场相关性。在极端湍流水平（Re = 10000）下，它是首个能够恢复磁场高波数演化、保留大尺度形态并实现有统计意义预测的代理模型。该方法在传统确定性代理模型无法触及的区域实现了最先进的准确性。

**Conclusion:** 该混合机器学习框架成功地解决了高雷诺数下二维不可压缩电阻磁流体动力学湍流的模拟难题，展示了在复杂流体动力学建模方面的卓越能力和潜力。

> **ai_Abstract:** 本文提出了一个新颖的混合机器学习框架，结合了物理信息神经网络算子（PINOs）和扩散模型，以高精度模拟二维不可压缩电阻磁流体动力学（MHD）湍流在宽泛雷诺数范围内的时空演化。该框架通过PINOs处理低频动力学，并利用扩散模型校正高频残差，从而在高雷诺数（包括Re=10000）下实现了对速度场和磁场演化的准确重建，克服了传统确定性代理模型的局限性。

> **摘要翻译:** 我们提出了一个混合机器学习框架，结合了物理信息神经网络算子（PINOs）和基于分数的生成扩散模型，用于模拟二维、不可压缩、电阻磁流体动力学（MHD）湍流在广泛雷诺数（Re）范围内的完整时空演化。该框架利用PINOs的方程约束泛化能力来预测连贯的低频动力学，而条件扩散模型则随机校正高频残差，从而实现对充分发展湍流的精确建模。该方法在Re ∈ {100, 250, 500, 750, 1000, 3000, 10000}的高精度模拟综合数据集上进行训练，在以前确定性代理模型无法企及的区域实现了最先进的准确性。在Re=1000和3000时，模型忠实地重构了模拟后期速度场和磁场的完整频谱能量分布，以高保真度捕获了非高斯统计、间歇性结构和交叉场相关性。在极端湍流水平（Re=10000）下，它仍然是第一个能够恢复磁场高波数演化、保留大尺度形态并实现统计学上有意义预测的代理模型。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [414] [HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3](https://arxiv.org/abs/2507.02345)
> *HelixDesign-Antibody：一个基于HelixFold3的可扩展生产级抗体设计平台*

*Jie Gao, Jing Hu, Shanzhuo Zhang, Kunrui Zhu, Sheng Qian, Yueyang Huang, Xiaonan Zhang, Xiaomin Fang* | **Category: q-bio.BM, cs.AI** | **Updated: {updated}**

**Keywords:** 抗体设计, 高通量, 平台, HelixFold3, 抗体工程

**Comment:** 

> **TL;DR:** HelixDesign-Antibody是一个基于高精度结构预测模型HelixFold3构建的生产级、高通量平台，旨在通过大规模生成和评估抗体序列来加速抗体工程，解决了传统方法的耗时和高计算需求问题。

**AI_Comments:** 该论文介绍的HelixDesign-Antibody平台通过整合先进的结构预测模型HelixFold3和高性能计算，显著提升了抗体设计的效率和规模。其创新点在于从“生产级”的角度出发，解决了传统方法在效率和计算资源上的瓶颈，并通过验证展示了其生成多样化高质量抗体的能力，以及“探索更大序列空间增加识别最佳结合物可能性”的发现，这对于抗体工程领域具有重要意义。该平台的可访问性（通过PaddleHelix）也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的抗体发现方法依赖于耗时且资源密集型的实验筛选，为了增强和简化这一过程，需要一个高效的解决方案。

**Method:** 我们引入了一个基于高精度结构预测模型HelixFold3构建的生产级、高通量平台HelixDesign-Antibody。该平台能够大规模生成抗体候选序列并评估它们与抗原的相互作用。集成了高性能计算（HPC）支持，实现了高通量筛选，解决了工具链碎片化和高计算需求等挑战。

**Result:** 在多个抗原上的验证表明，该平台能够生成多样化且高质量的抗体，并证实了探索更大序列空间会增加识别最佳结合物可能性的缩放定律。

**Conclusion:** HelixDesign-Antibody平台为大规模抗体设计提供了一个无缝、易于访问的解决方案，并通过PaddleHelix平台的抗体设计页面提供。

> **ai_Abstract:** HelixDesign-Antibody是一个基于HelixFold3的生产级、高通量抗体设计平台，旨在解决传统抗体发现方法耗时且资源密集的问题。该平台利用HelixFold3的高精度结构预测能力，支持大规模抗体序列的生成与抗原相互作用评估，并借助高性能计算实现高效筛选。实验验证表明其能生成多样化高质量抗体，并揭示了序列空间探索与最佳结合物识别概率之间的正相关关系。该平台为大规模抗体设计提供了便捷的解决方案。

> **摘要翻译:** 抗体工程对于开发治疗药物和推进生物医学研究至关重要。传统的发现方法通常依赖于耗时且资源密集型的实验筛选。为了增强和简化这一过程，我们引入了一个基于HelixFold3构建的生产级、高通量平台——HelixDesign-Antibody，它利用了高精度结构预测模型HelixFold3。该平台促进了抗体候选序列的大规模生成，并评估它们与抗原的相互作用。集成的HPC（高性能计算）支持实现了高通量筛选，解决了工具链碎片化和高计算需求等挑战。在多个抗原上的验证展示了该平台生成多样化和高质量抗体的能力，证实了一个缩放定律，即探索更大的序列空间会增加识别最佳结合物的可能性。该平台为大规模抗体设计提供了一个无缝、易于访问的解决方案，并通过PaddleHelix平台的抗体设计页面提供。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='q-finrm'></a>
## q-fin.RM 

### [420] [Machine Learning Based Stress Testing Framework for Indian Financial Market Portfolios](https://arxiv.org/abs/2507.02011)
> *印度金融市场投资组合的机器学习压力测试框架*

*Vidya Sagar G, Shifat Ali, Siddhartha P. Chakrabarty* | **Category: q-fin.RM, cs.LG, q-fin.PM** | **Updated: {updated}**

**Keywords:** 机器学习, 压力测试, 金融市场, 变分自编码器, 风险管理

**Comment:** 

> **TL;DR:** 本文提出了一个基于机器学习的框架，用于印度金融市场的压力测试，通过降维和变分自编码器生成场景，以提高测试的灵活性、鲁棒性和真实性。

**AI_Comments:** 该论文的创新之处在于将机器学习技术，特别是变分自编码器，引入到金融压力测试中，以解决传统方法的局限性。通过引入概率结构和蒙特卡洛场景生成，它能够更细致地模拟压力条件并捕获非线性依赖，这对于提高金融风险管理的准确性和稳健性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统压力测试中存在的局限性，特别是通过降维和潜在因子建模来改进。

**Method:** 采用机器学习方法，包括主成分分析（PCA）和自编码器（Autoencoders）进行降维和潜在因子建模。进一步扩展使用变分自编码器（Variational Autoencoders）引入概率结构到潜在空间，并利用蒙特卡洛方法生成场景。该框架还支持通过风险价值（Value-at-Risk）和预期损失（Expected Shortfall）进行风险估计。

**Result:** 该框架能够捕获复杂的非线性依赖关系，并支持通过风险价值（Value-at-Risk）和预期损失（Expected Shortfall）进行风险估计。

**Conclusion:** 机器学习方法在提高金融压力测试的灵活性、鲁棒性和真实性方面具有潜力。

> **ai_Abstract:** 本文提出了一个基于机器学习的框架，用于印度金融市场的部门压力测试，旨在克服传统方法的局限性。该框架利用主成分分析、自编码器和变分自编码器进行降维和潜在因子建模，并引入概率结构以实现基于蒙特卡洛的场景生成。它能够捕获非线性依赖关系，并通过风险价值和预期损失支持风险估计，从而提高了金融压力测试的灵活性、鲁棒性和真实性。

> **摘要翻译:** 本文提出了一个机器学习驱动的框架，用于印度金融市场的部门压力测试，重点关注金融服务、信息技术、能源、消费品和制药行业。最初，我们通过主成分分析和自编码器进行降维和潜在因子建模，解决了传统压力测试中观察到的局限性。在此基础上，我们使用变分自编码器扩展了该方法，将概率结构引入到潜在空间。这使得基于蒙特卡洛的场景生成成为可能，从而实现对压力市场条件更细致、更注重分布的模拟。所提出的框架捕获了复杂的非线性依赖关系，并支持通过风险价值（Value-at-Risk）和预期损失（Expected Shortfall）进行风险估计。总而言之，这些流程展示了机器学习方法在提高金融压力测试的灵活性、鲁棒性和真实性方面的潜力。

</details>

[⬆️ 返回分类顶部](#q-finrm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [428] [TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity](https://arxiv.org/abs/2507.02024)
> *TubuleTracker：一种高保真共享软件，用于量化血管生成结构和成熟度*

*Danish Mahmood, Stephanie Buczkowski, Sahaj Shah, Autumn Anthony, Rohini Desetty, Carlo R Bartoli* | **Category: q-bio.QM, cs.CV, q-bio.CB** | **Updated: {updated}**

**Keywords:** 血管生成, 图像分析, TubuleTracker, 软件, 内皮细胞

**Comment:** Abstract word count = [285] Total word count = [3910] Main body text
  = [2179] References = [30] Table = [0] Figures = [4]

> **TL;DR:** TubuleTracker是一款新的共享软件，用于快速、客观地量化血管生成网络的结构和成熟度，比手动分析和ImageJ更快、更一致，并且其指标能有效反映血管生成成熟度。

**AI_Comments:** TubuleTracker的创新之处在于其不仅提高了血管生成图像分析的速度和客观性，还引入了能有效反映网络成熟度的新指标，如血管圆度，这对于深入理解血管生成过程至关重要。其作为免费共享软件的发布，将极大地促进生物医学研究，降低研究门槛。该研究通过与现有方法的直接比较，有力地证明了其优越性。

<details>
  <summary>Details</summary>

**Motivation:** 体外内皮细胞培养广泛用于研究血管生成，但手动分析细胞网络耗时且主观。现有自动化工具（如ImageJ）速度慢且不准确。此外，随着内皮网络复杂性增加，传统结构指标可能无法完全反映网络成熟度。

**Method:** 使用人脐静脉内皮细胞在细胞外基质中培养并获取54张相差显微图像。每张图像由三名独立审阅者手动分析，并分别使用ImageJ和TubuleTracker进行分析。关键指标包括小管计数、总长度、节点计数、小管面积和血管圆度。同时，受过训练的科学家对每张图像的血管生成成熟度进行1-5评分（1=最成熟）。

**Result:** 每张图像的分析时间显著不同：手动（8分钟）、ImageJ（58±4秒）、TubuleTracker（6±2秒）（p<0.0001）。在小管计数、长度和节点计数方面也存在显著差异（手动168±SD，TubuleTracker 92±SD，ImageJ 433±SD，所有p<0.0001）。TubuleTracker的指标（包括小管计数、长度、节点计数、面积和圆度）随血管生成成熟度评分显著变化（所有p<0.0001）。

**Conclusion:** TubuleTracker比手动和基于ImageJ的分析更快、更一致。血管圆度在捕获血管生成成熟度方面特别有效。TubuleTracker作为免费共享软件可供生物医学研究社区使用。

> **ai_Abstract:** 本研究介绍了TubuleTracker，一款高保真共享软件，旨在解决体外血管生成研究中手动和现有自动化工具（如ImageJ）在量化内皮网络结构和成熟度方面的耗时、主观、缓慢和不准确等问题。通过比较TubuleTracker、ImageJ和手动分析在处理人脐静脉内皮细胞图像上的性能，结果显示TubuleTracker在分析速度和一致性上均优于其他方法。此外，TubuleTracker的各项量化指标，特别是血管圆度，能够有效反映血管生成网络的成熟度。该软件作为免费共享软件，为生物医学研究社区提供了一个快速、客观且可靠的血管生成分析工具。

> **摘要翻译:** 背景：体外内皮细胞培养被广泛用于研究血管生成。细胞网络的组织显微图像通常通过手动分析，这个过程耗时且主观。像ImageJ (NIH) 这样的自动化工具可以提供帮助，但通常速度慢且不准确。此外，随着内皮网络变得更加复杂，传统的结构指标可能无法完全反映网络的成熟度。为了解决这些局限性，我们开发了TubuleTracker，这是一款能够快速、客观地量化内皮网络结构和成熟度的软件工具。方法：将人脐静脉内皮细胞在细胞外基质中培养，并使用相差显微镜获取了54张图像。每张图像由三名独立审阅者手动分析，并同时由ImageJ和TubuleTracker进行分析。关键指标包括小管计数、总长度、节点计数、小管面积和血管圆度。同时，受过训练的科学家对每张图像的血管生成成熟度进行1-5评分（1 = 最成熟）。结果：每张图像的分析时间显著不同：手动（8分钟）、ImageJ（58±4秒）和TubuleTracker（6±2秒）（p<0.0001）。在小管计数（手动168±SD，TubuleTracker 92±SD，ImageJ 433±SD）、长度和节点计数方面也发现了显著差异（所有p<0.0001）。TubuleTracker的指标在血管生成成熟度评分中存在显著差异，包括小管计数、长度、节点计数、面积和圆度（所有p<0001）。结论：TubuleTracker比手动和基于ImageJ的分析更快、更一致。血管圆度被证明在捕获血管生成成熟度方面特别有效。TubuleTracker作为免费共享软件供生物医学研究社区使用。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [430] [NLP4Neuro: Sequence-to-sequence learning for neural population decoding](https://arxiv.org/abs/2507.02264)
> *NLP4Neuro：用于神经群体解码的序列到序列学习*

*Jacob J. Morra, Kaitlyn E. Fouke, Kexin Hang, Zichen He, Owen Traubert, Timothy W. Dunn, Eva A. Naumann* | **Category: q-bio.NC, cs.LG** | **Updated: {updated}**

**Keywords:** 神经解码, 大型语言模型, 序列到序列学习, 全脑活动, 斑马鱼

**Comment:** 17 pages, 6 figures

> **TL;DR:** 本研究系统评估了预训练的大型语言模型（LLMs）在解码全脑神经活动与行为之间的关系方面的能力，并发现LLMs在神经解码方面表现出色，尤其是在使用文本数据预训练权重时，其中DeepSeek Coder-7b显著提高了行为解码精度并提供了可解释的神经元显著性信息。

**AI_Comments:** 该论文的创新点在于将大型语言模型（LLMs）应用于全脑神经解码，这是一种新颖且有前景的方法。它展示了LLMs的序列到序列学习能力及其从文本数据中获得的预训练知识，可以有效地泛化到神经科学领域。特别是，使用混合专家LLM（DeepSeek Coder-7b）的成功应用，不仅提高了预测精度，还提供了可解释的神经元显著性信息，这对于理解复杂的神经回路至关重要。这项工作为神经科学研究提供了强大的新工具，有望加速对行为神经基础的理解。

<details>
  <summary>Details</summary>

**Motivation:** 神经科学的一个基本目标是阐明动物行为如何从神经活动中产生。然而，在大型、密集连接的哺乳动物大脑中，行为背后的计算涉及数千个独立神经元组成的网络，这给研究神经作用和计算机制带来了挑战。虽然Transformer模型在较小神经群体解码方面已显示出强大能力，但其在更大范围、全脑活动记录中的潜力尚未充分探索。

**Method:** 本研究提出了NLP4Neuro框架，用于系统评估现成的LLM，以从全脑神经群体中解码行为。研究人员在斑马鱼幼虫上进行了实验，同时记录了钙成像和行为数据，并暴露于视觉运动刺激。他们测试了使用文本自然语言数据预训练权重的LLM，并特别评估了一种混合专家LLM，即DeepSeek Coder-7b。

**Result:** 研究发现，使用文本自然语言数据预训练权重的LLM在神经解码方面表现更好。特别是，DeepSeek Coder-7b这种混合专家LLM显著提高了行为解码精度，能够预测长时间尺度上的尾部运动，并提供了在解剖学上一致且高度可解释的神经元显著性读数。

**Conclusion:** NLP4Neuro证明了大型语言模型在剖析全脑神经回路方面具有强大的能力。

> **ai_Abstract:** 本研究提出了NLP4Neuro框架，利用大型语言模型（LLMs）进行全脑神经群体解码，旨在理解神经活动与行为的关系。通过在斑马鱼幼虫上进行的实验，研究发现预训练的LLMs，尤其是使用文本数据预训练的权重，在神经解码任务上表现出色。其中，DeepSeek Coder-7b显著提升了行为解码精度，并能预测长期尾部运动，同时提供可解释的神经元显著性信息。这表明LLMs在解析全脑神经回路方面具有巨大潜力。

> **摘要翻译:** 阐明动物行为如何从神经活动中产生是神经科学的一个基础目标。然而，由于行为背后的计算发生在整个大脑中数千个独立神经元的网络中，这给研究大型、密集连接的哺乳动物大脑在行为过程中的神经作用和计算机制带来了挑战。Transformer模型是现代大型语言模型（LLM）的骨干，已成为从较小神经群体进行神经解码的强大工具。这些现代LLM受益于广泛的预训练，其序列到序列学习已被证明可以推广到新的任务和数据模态，这可能也为从更大范围、全脑活动记录中进行神经解码带来优势。在此，我们系统评估了现成的LLM，以从全脑群体中解码行为，我们称之为NLP4Neuro，我们用它来测试LLM在暴露于视觉运动刺激的斑马鱼幼虫的同步钙成像和行为记录上的表现。通过NLP4Neuro，我们发现当LLM使用从文本自然语言数据中学习到的预训练权重时，它们在神经解码方面表现更好。此外，我们发现最近的一种混合专家LLM，DeepSeek Coder-7b，显著提高了行为解码精度，能够预测长时间尺度上的尾部运动，并提供了在解剖学上一致且高度可解释的神经元显著性读数。NLP4Neuro表明LLM在阐明全脑神经回路方面具有强大的能力。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstr-el'></a>
## cond-mat.str-el 

### [432] [Solving the Hubbard model with Neural Quantum States](https://arxiv.org/abs/2507.02644)
> *用神经量子态求解哈伯德模型*

*Yuntian Gu, Wenrui Li, Heng Lin, Bo Zhan, Ruichen Li, Yifei Huang, Di He, Yantao Wu, Tao Xiang, Mingpu Qin, Liwei Wang, Dingshun Lv* | **Category: cond-mat.str-el, cs.AI, quant-ph** | **Updated: {updated}**

**Keywords:** 神经量子态, 哈伯德模型, Transformer, 高温超导, 多体系统

**Comment:** 

> **TL;DR:** 该研究利用基于Transformer的神经量子态（NQS）和高效优化算法，在掺杂二维哈伯德模型上取得了最先进的结果，并发现NQS注意力头能编码不同尺度的关联，从而证实了二维哈伯德模型基态中的半填充条纹。

**AI_Comments:** 这项工作创新性地将基于Transformer的架构引入神经量子态，并开发了高效优化算法，显著提升了NQS在求解复杂量子多体系统（如哈伯德模型）方面的能力。特别是发现NQS注意力头能够编码不同尺度的关联，为理解和应用NQS提供了新的视角。其结果与实验观察的一致性进一步验证了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 神经量子态（NQS）已成为研究量子多体系统的有前景的框架。本研究旨在利用NQS解决具有挑战性的多费米子系统，特别是被认为是高温超导最小模型的掺杂二维哈伯德模型。

**Method:** 研究利用了尖端的基于Transformer的架构，并开发了高效的优化算法来求解哈伯德模型。此外，他们还分析了NQS注意力头如何编码不同尺度的关联。

**Result:** 研究在掺杂二维（2D）哈伯德模型上取得了最先进的结果。他们发现NQS中的不同注意力头可以直接编码不同尺度的关联，使其能够捕获强关联系统中的长程关联和纠缠。此外，他们建立了二维哈伯德模型基态中带有次近邻跳跃的半填充条纹，这与铜氧化物中的实验观察结果一致。

**Conclusion:** 本工作确立了神经量子态（NQS）作为解决具有挑战性的多费米子系统的强大工具。

> **ai_Abstract:** 本研究利用基于Transformer的神经量子态（NQS）和高效优化算法，在掺杂二维哈伯德模型上取得了最先进的结果。研究发现NQS中的注意力头能够编码不同尺度的关联，从而有效捕获强关联系统中的长程关联。这些进展使得在二维哈伯德模型基态中确定了半填充条纹，与实验观察结果相符。该工作证明NQS是解决多费米子系统的强大工具。

> **摘要翻译:** 神经量子态（NQS）的快速发展使其成为研究量子多体系统的一个有前景的框架。在这项工作中，通过利用尖端的基于Transformer的架构和开发高效的优化算法，我们为掺杂二维（2D）哈伯德模型（可以说是高温超导的最小模型）取得了最先进的结果。有趣的是，我们发现NQS猜想中不同的注意力头可以直接编码不同尺度的关联，使其能够捕获强关联系统中的长程关联和纠缠。凭借这些进展，我们确定了带有次近邻跳跃的二维哈伯德模型基态中的半填充条纹，这与铜氧化物中的实验观察结果一致。我们的工作确立了NQS作为解决具有挑战性的多费米子系统的强大工具。

</details>

[⬆️ 返回分类顶部](#cond-matstr-el) | [⬆️ 返回总目录](#toc)

