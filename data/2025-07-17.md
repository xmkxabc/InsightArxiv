# AI-Enhanced arXiv Daily 2025-07-17

<a id='toc'></a>
## 今日总计: 706 篇论文
### 目录
- [cs.CR](#cscr) (16 篇)
- [cs.AI](#csai) (29 篇)
- [cs.LG](#cslg) (107 篇)
- [cs.MA](#csma) (2 篇)
- [cs.RO](#csro) (44 篇)
- [cs.CV](#cscv) (132 篇)
- [cs.HC](#cshc) (19 篇)
- [cs.ET](#cset) (1 篇)
- [cs.SE](#csse) (24 篇)
- [cs.SI](#cssi) (5 篇)
- [cs.NI](#csni) (5 篇)
- [cs.IT](#csit) (8 篇)
- [cs.AR](#csar) (5 篇)
- [cs.DC](#csdc) (4 篇)
- [cs.CY](#cscy) (10 篇)
- [cs.CE](#csce) (6 篇)
- [cs.FL](#csfl) (2 篇)
- [eess.SY](#eesssy) (20 篇)
- [eess.SP](#eesssp) (18 篇)
- [eess.IV](#eessiv) (18 篇)
- [eess.AS](#eessas) (7 篇)
- [cs.CL](#cscl) (66 篇)
- [cs.DS](#csds) (21 篇)
- [cs.GR](#csgr) (5 篇)
- [cs.IR](#csir) (7 篇)
- [cs.NE](#csne) (2 篇)
- [math.NA](#mathna) (21 篇)
- [cs.SD](#cssd) (16 篇)
- [cs.SC](#cssc) (1 篇)
- [math.DS](#mathds) (3 篇)
- [math.CO](#mathco) (1 篇)
- [cs.CC](#cscc) (3 篇)
- [astro-ph.IM](#astro-phim) (3 篇)
- [q-fin.MF](#q-finmf) (1 篇)
- [math.OC](#mathoc) (7 篇)
- [cond-mat.stat-mech](#cond-matstat-mech) (1 篇)
- [quant-ph](#quant-ph) (11 篇)
- [stat.ML](#statml) (12 篇)
- [cs.DB](#csdb) (4 篇)
- [cs.MM](#csmm) (2 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [stat.ME](#statme) (6 篇)
- [cs.LO](#cslo) (1 篇)
- [q-bio.PE](#q-biope) (2 篇)
- [physics.app-ph](#physicsapp-ph) (1 篇)
- [astro-ph.EP](#astro-phep) (1 篇)
- [physics.plasm-ph](#physicsplasm-ph) (1 篇)
- [cs.PL](#cspl) (2 篇)
- [q-bio.NC](#q-bionc) (3 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [stat.CO](#statco) (1 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [econ.TH](#econth) (1 篇)
- [math.DG](#mathdg) (1 篇)
- [math.AP](#mathap) (1 篇)
- [q-bio.QM](#q-bioqm) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (2 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (1 篇)
- [physics.chem-ph](#physicschem-ph) (1 篇)
- [physics.ao-ph](#physicsao-ph) (2 篇)
- [hep-th](#hep-th) (1 篇)
- [math.GR](#mathgr) (1 篇)
- [gr-qc](#gr-qc) (1 篇)
- [cs.DL](#csdl) (1 篇)
- [cs.CG](#cscg) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [127] [Safeguarding Federated Learning-based Road Condition Classification](https://arxiv.org/abs/2507.12568)
> *保护联邦学习的道路状况分类*

*Sheng Liu, Panos Papadimitratos* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 联邦学习, 道路状况分类, 目标标签翻转攻击, 安全, FLARE

**Comment:** Accepted by IEEE Conference on Communications and Network Security
  (CNS) 2025

> **TL;DR:** 联邦学习（FL）在道路状况分类（RCC）中易受目标标签翻转攻击（TLFAs）。本文揭示了这种脆弱性，提出了一种量化风险的度量方法，并引入了防御机制FLARE，实验证明其有效性。

**AI_Comments:** 本文识别并解决了联邦学习在自动驾驶领域（特别是道路状况分类）中一个关键的安全漏洞——目标标签翻转攻击。其创新之处在于提出了一个量化风险的度量标准和一种新颖的基于神经元分析的防御机制FLARE。这项工作对于提升FL在敏感应用中的安全性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）是隐私保护自动驾驶中，特别是基于摄像头的道路状况分类（RCC）系统的一个有前景的解决方案。然而，FL-RCC的协作性质引入了新的漏洞：目标标签翻转攻击（TLFAs），恶意客户端会故意改变训练数据标签以损害模型推理性能，可能导致车辆将危险路况误分类。目前针对FL-RCC系统的TLFAs研究严重缺失。

**Method:** 1) 揭示了现有FL-RCC系统对TLFAs的脆弱性；2) 引入了一种新颖的基于标签距离的度量标准来精确量化TLFAs造成的安全风险；3) 提出了FLARE，一种利用输出层神经元分析来缓解TLFA影响的防御机制。

**Result:** 广泛的实验（跨越三个RCC任务、四种评估指标、六个基线和三个深度学习模型）证明了TLFAs对FL-RCC系统的严重性以及FLARE在缓解攻击影响方面的有效性。

**Conclusion:** 本文揭示了联邦学习道路状况分类系统在目标标签翻转攻击下的脆弱性，并提出了有效的防御机制FLARE，显著提升了系统的安全性。

> **ai_Abstract:** 本文研究了联邦学习（FL）在道路状况分类（RCC）系统中的应用，并揭示了其在目标标签翻转攻击（TLFAs）下的脆弱性。为解决此问题，作者提出了一种基于标签距离的度量来量化攻击风险，并引入了防御机制FLARE。实验证明了TLFAs的严重性以及FLARE的有效性。

> **摘要翻译:** 联邦学习（FL）已成为保护隐私的自动驾驶领域，特别是基于摄像头的道路状况分类（RCC）系统，一个有前景的解决方案，它利用车载分布式传感、计算和通信资源，而无需共享敏感图像数据。然而，FL-RCC框架的协作性质引入了新的漏洞：目标标签翻转攻击（TLFAs），其中恶意客户端（车辆）故意改变其训练数据标签，以损害学习模型的推理性能。此类攻击可能导致车辆错误地将湿滑、危险的道路状况分类为良好，并超过建议速度。然而，针对基于FL的RCC系统的TLFAs研究却严重缺失。我们通过三重贡献来解决这一挑战：1）我们揭示了现有FL-RCC系统对TLFAs的脆弱性；2）我们引入了一种新颖的基于标签距离的度量标准，以精确量化TLFAs带来的安全风险；3）我们提出了FLARE，一种利用输出层神经元分析来缓解TLFA影响的防御机制。在三个RCC任务、四种评估指标、六个基线和三个深度学习模型上的广泛实验证明了TLFAs对FL-RCC系统的严重性以及FLARE在缓解攻击影响方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [132] [On the Consideration of Vanity Address Generation via Identity-Based Signatures](https://arxiv.org/abs/2507.12670)
> *基于身份签名生成靓号地址的考量*

*Shogo Murasaki, Kazumasa Omote, Keita Emura* | **Category: cs.CR** | **Updated: 2025-07-16**

**Keywords:** 靓号地址, 基于身份签名, ECDSA, 区块链, Solidity

**Comment:** 

> **TL;DR:** 本文探讨了使用基于身份签名（IBS）来生成靓号地址的可能性，发现虽然不能直接生成靓号地址，但IBS可以为地址赋予额外含义，并且其在Solidity上的实现具有与ECDSA签名验证相似的Gas成本。

**AI_Comments:** 本文创新性地探讨了IBS在靓号地址生成中的应用，并提出了一个基于ECDSA的IBS构造。其重要性在于，即使无法直接生成靓号地址，也能通过IBS为地址增加语义关联，这为区块链地址管理提供了新的思路。主要限制在于无法实现直接的靓号生成，且需要考虑IBS方案与现有ECDSA体系的兼容性问题。

<details>
  <summary>Details</summary>

**Motivation:** 传统的靓号地址生成方法采用试错法，限制了可嵌入字符的数量。本文旨在探索基于身份签名（IBS）是否能用于生成靓号地址，以克服现有方法的局限性。

**Method:** 本文关注基于签名的通用IBS构造，并从带有密钥恢复功能的ECDSA构建了一个IBS方案。虽然不能直接生成靓号地址，但利用IBS功能可以将任意字符串与地址关联起来，从而赋予地址额外含义。该系统通过Solidity实现。

**Result:** 由于底层ECDSA的密钥恢复功能，本文提出的方案不能直接生成靓号地址。然而，由于IBS的功能，它可以将任意字符串与地址关联，赋予地址额外的含义。在Solidity中实现后，其Gas成本与ECDSA签名验证的Gas成本几乎相同。

**Conclusion:** 尽管基于身份签名的方案不能直接生成靓号地址，但它能够为区块链地址赋予额外的含义，并且在Gas成本方面与现有ECDSA签名验证相当，显示出其在特定应用场景中的潜力。

> **ai_Abstract:** 本文探讨了利用基于身份签名（IBS）技术生成区块链靓号地址的可能性。鉴于传统试错法的局限性，作者提出了一种从带有密钥恢复功能的ECDSA构建IBS方案的方法。尽管该方案无法直接生成靓号地址，但它能通过IBS功能将任意字符串与地址关联，从而赋予地址额外的语义。实验表明，该方案在Solidity上的Gas成本与ECDSA签名验证相似。

> **摘要翻译:** 地址在区块链上表示用户的标识符，由ECDSA验证密钥的哈希值定义。靓号地址是嵌入自定义字符（例如名称）的地址。为了生成靓号地址，通常采用经典的试错法，因此可嵌入的字符数量受到限制。在本文中，我们关注基于身份签名（IBS）的功能，其中任何字符串都可以用作验证密钥，并探讨IBS是否可以用于生成靓号地址。我们重视这样一个事实：用密钥恢复（目前在以太坊中用于发行交易）的ECDSA替换为IBS方案是不现实的。即使这种替换是可能的，对于靓号地址生成的便利性来说，其代价也是不合理的。因此，我们关注基于签名的IBS通用构造，并从带有密钥恢复功能的ECDSA构建了一个IBS方案。尽管由于底层ECDSA的密钥恢复功能，我们无法直接生成靓号地址，但由于IBS能够为地址赋予额外含义的功能，我们可以将任意字符串与地址连接起来。我们通过Solidity实现了我们的系统，并证明其Gas成本与ECDSA签名验证的Gas成本几乎相同。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [138] [Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense](https://arxiv.org/abs/2507.12919)
> *深度学习中的架构后门：漏洞、检测与防御综述*

*Victoria Childress, Josh Collyer, Jodie Knapp* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** 架构后门, 深度学习安全, 漏洞, 检测, 防御

**Comment:** 35 pages, Under review for ACM Computing Surveys

> **TL;DR:** 该综述系统地整合了深度学习中架构后门的研究，包括其漏洞、检测和防御策略，并指出尽管有所进展，但可扩展且实用的防御仍难以实现，并提出了未来的研究方向。

**AI_Comments:** 该论文的重要性在于其首次系统地梳理了深度学习中“架构后门”这一新兴且隐蔽的安全威胁。它清晰地指出了传统防御手段的局限性，并对现有检测与防御策略进行了评估，揭示了该领域面临的挑战。这篇综述为未来的研究指明了方向，对于推动深度学习安全领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 架构后门对深度神经网络构成了一个未被充分研究但至关重要的威胁，它们将恶意逻辑直接嵌入到模型的计算图中，与传统攻击不同，它们能规避标准缓解技术并持久存在。因此，有必要对这一领域的现有研究进行系统性整合和评估。

**Method:** 本综述系统地整合了关于架构后门的研究，涵盖了编译器级操纵、受污染的AutoML管道和供应链漏洞。文章评估了新兴的检测和防御策略，包括静态图检查、动态模糊测试和部分形式验证。

**Result:** 研究发现，新兴的检测和防御策略（如静态图检查、动态模糊测试和部分形式验证）在对抗分布式或隐蔽触发器时存在局限性。尽管最近有所进展，但可扩展且实用的防御仍然难以实现。

**Conclusion:** 论文通过概述开放性挑战，并提出了加强供应链安全、加密模型认证和下一代基准测试的方向，旨在指导未来的研究，以实现针对深度学习系统中结构性后门威胁的全面防御。

> **ai_Abstract:** 本综述全面探讨了深度学习中的架构后门威胁，这是一种将恶意逻辑嵌入模型计算图的新型攻击，能规避传统防御。文章系统地整合了关于漏洞、检测和防御策略的研究，包括编译器级操纵和供应链漏洞。尽管新兴的检测和防御方法已出现，但它们在对抗复杂攻击时仍有局限，且可扩展的实用防御尚未实现。论文最后提出了未来的研究方向，以期构建更全面的防御体系。

> **摘要翻译:** 架构后门对深度神经网络构成了未被充分研究但至关重要的威胁，它们将恶意逻辑直接嵌入到模型的计算图中。与传统的数据投毒或参数操纵不同，架构后门能够规避标准缓解技术，即使在干净的再训练后也能持续存在。本综述系统地整合了关于架构后门的研究，涵盖了编译器级操纵、受污染的AutoML管道和供应链漏洞。我们评估了新兴的检测和防御策略，包括静态图检查、动态模糊测试和部分形式验证，并强调了它们在对抗分布式或隐蔽触发器时的局限性。尽管最近有所进展，但可扩展且实用的防御仍然难以实现。最后，我们概述了开放性挑战，并提出了加强供应链安全、加密模型认证和下一代基准测试的方向。本综述旨在指导未来的研究，以实现针对深度学习系统中结构性后门威胁的全面防御。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [144] [Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach](https://arxiv.org/abs/2507.12937)
> *企业安全事件分析及基于T-Mobile数据泄露的对策*

*Zhuohan Cui, Zikun Song* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** 数据泄露, T-Mobile, 安全审计, 道德黑客, 多层防御

**Comment:** 

> **TL;DR:** 本文分析了T-Mobile数据泄露事件，揭示了其安全漏洞，并提出了一套多层防御策略，通过财务模型证明了其成本效益。

**AI_Comments:** 本文的创新之处在于将实际的道德黑客技术与案例分析相结合，深入揭示了大型企业在数据泄露后的持续性结构性安全弱点。其提出的多层防御策略具有很强的实践指导意义，并通过财务模型量化了主动安全投资的价值，为企业决策提供了经济依据。对于大型电信或类似基础设施企业，这篇论文提供了一个全面的安全评估和改进框架。

<details>
  <summary>Details</summary>

**Motivation:** 分析T-Mobile数据泄露事件，揭示其结构性弱点，并为大型电信公司提供可操作的安全蓝图，以提高运营弹性、合规性和跨领域威胁准备。

**Method:** 结合案例式漏洞评估与主动道德黑客技术（包括Shodan侦察、API滥用模拟、VNC暴力破解、固件逆向工程和Web应用扫描），对T-Mobile的系统、基础设施和公开暴露的端点进行了全面的安全审计。在此基础上，提出了多层防御策略，包括零信任架构、细粒度基于角色的访问控制、网络分段、使用AES的固件加密（带完整性检查）以及API速率限制和令牌生命周期控制。

**Result:** 揭示了T-Mobile在初次泄露事件后仍然存在的结构性弱点。财务模型表明，五年的投资预计损失不到预期泄露损失的1.1%，证明了主动安全措施的成本效益。

**Conclusion:** 本研究将事件后取证分析与实际安全评估相结合，为寻求运营弹性、合规性和跨领域威胁准备的大型电信公司提供了一份可操作的蓝图。

> **ai_Abstract:** 本文以T-Mobile 2021年和2023年数据泄露事件为例，通过结合案例漏洞评估和主动道德黑客技术，全面分析了其系统、基础设施和公开端点的安全弱点。在此基础上，提出了一套多层防御策略，包括零信任架构、细粒度访问控制、网络分段、固件加密和API安全措施。财务模型验证了这些主动安全措施的成本效益，并为大型电信公司提供了提高运营韧性、合规性和威胁准备度的实用蓝图。

> **摘要翻译:** 本文对T-Mobile在2021年和2023年发生的重大数据泄露事件进行了全面分析，并对其系统、基础设施和公开暴露的端点进行了全面的安全审计。通过将基于案例的漏洞评估与主动道德黑客技术相结合——包括Shodan侦察、API滥用模拟、VNC暴力破解、固件逆向工程和Web应用程序扫描——我们揭示了在初次泄露事件后仍然存在的结构性弱点。基于这些发现，我们提出了一种多层防御策略，包括零信任架构、细粒度基于角色的访问控制、网络分段、使用AES进行完整性检查的固件加密，以及API速率限制和令牌生命周期控制。财务模型表明，五年的投资所产生的成本不到预期泄露损失的1.1%，验证了主动安全措施的成本效益。我们的工作将事件后取证分析与实际安全评估相结合，为寻求运营弹性、合规性和跨领域威胁准备的大型电信公司提供了一份可操作的蓝图。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [150] [Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest](https://arxiv.org/abs/2507.13023)
> *衡量CEX-DEX提取价值和搜索者盈利能力：MEV黑暗森林最黑暗的角落*

*Fei Wu, Danning Sui, Thomas Thiery, Mallesh Pai* | **Category: cs.CR, q-fin.TR** | **Updated: 2025-07-17**

**Keywords:** CEX-DEX套利, MEV, 以太坊, 区块构建者, 搜索者盈利能力

**Comment:** Accepted by AFT 2025

> **TL;DR:** 本文对以太坊上CEX-DEX套利的经济学和动态进行了全面的实证分析，揭示了2.338亿美元的提取价值，并发现市场日益中心化，以及搜索者盈利能力与区块构建者集成度的关系。

**AI_Comments:** 本文通过对CEX-DEX套利这一MEV（最大可提取价值）领域“黑暗森林”中一个相对未被充分探索的角落进行深入的实证分析，具有显著的创新性。其引入的稳健实证框架，无需了解CEX交易行为即可估算套利收入，是一大亮点。研究量化了巨大的提取价值，并揭示了市场中心化趋势以及搜索者与区块构建者之间垂直整合对盈利能力的影响，这些都对理解以太坊生态系统的经济动态和去中心化进程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在对以太坊上中心化和去中心化交易所（CEX-DEX）之间的套利经济学和动态进行全面的实证分析，并揭示其对以太坊去中心化的关键影响。

**Method:** 研究人员通过改进启发式方法来识别链上数据中的套利交易，并引入了一个稳健的实证框架来估计套利收入，而无需了解交易者在CEX上的实际行为。研究利用了从2023年8月到2025年3月长达19个月的广泛数据集进行分析。

**Result:** 从7,203,560笔已识别的CEX-DEX套利中，19个主要的CEX-DEX搜索者共提取了2.338亿美元。分析显示，市场日益中心化，三名搜索者占据了交易量和提取价值的四分之三。搜索者的盈利能力与他们与区块构建者的整合程度相关，并发现了排他性的搜索者-构建者关系及其市场影响。此外，研究纠正了之前对与搜索者垂直整合的区块构建者盈利能力的低估。

**Conclusion:** 这些发现揭示了MEV（最大可提取价值）领域最黑暗的角落，并强调了CEX-DEX套利对以太坊去中心化的关键影响。

> **ai_Abstract:** 本文对以太坊上的CEX-DEX套利进行了深入的实证研究。通过改进识别方法和引入新的收入估算框架，研究分析了长达19个月的数据，发现19个主要搜索者共提取了2.338亿美元。研究揭示了CEX-DEX套利市场的中心化趋势，以及搜索者盈利能力与区块构建者整合度的密切关系，并纠正了对垂直整合区块构建者盈利能力的低估。这些发现为理解MEV生态系统及其对以太坊去中心化的影响提供了重要见解。

> **摘要翻译:** 本文对以太坊上中心化和去中心化交易所（CEX-DEX）之间的套利经济学和动态进行了全面的实证分析。我们改进了启发式方法，以识别链上数据中的套利交易，并引入了一个稳健的实证框架来估计套利收入，而无需了解交易者在CEX上的实际行为。利用从2023年8月到2025年3月长达19个月的广泛数据集，我们估计19个主要的CEX-DEX搜索者从7,203,560笔已识别的CEX-DEX套利中总共提取了2.338亿美元。我们的分析揭示了日益增长的中心化趋势，三名搜索者占据了交易量和提取价值的四分之三。我们还表明，搜索者的盈利能力与其与区块构建者的整合程度相关，并揭示了排他性的搜索者-构建者关系及其市场影响。最后，我们纠正了之前对与搜索者垂直整合的区块构建者盈利能力的低估。这些见解照亮了MEV（最大可提取价值）领域最黑暗的角落，并强调了CEX-DEX套利对以太坊去中心化的关键影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [156] [From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange](https://arxiv.org/abs/2507.13028)
> *从偏执到合规：Stack Exchange上系统加固实践的坎坷之路*

*Niklas Busch, Philip Klostermeyer, Jan H. Klemmer, Yasemin Acar, Sascha Fahl* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** 系统加固, Stack Exchange, 网络安全, 访问控制, 部署挑战

**Comment:** 14 pages, 5 figures

> **TL;DR:** 该研究通过分析Stack Exchange上的帖子，深入了解系统操作员在系统加固方面的动机、实践和挑战，发现访问控制和部署是主要挑战，且操作员存在误解和不切实际的期望。

**AI_Comments:** 这项研究的重要性在于填补了对系统操作员加固实践和挑战理解的空白，尤其是在缺乏深入研究的背景下。通过分析Stack Exchange这一真实世界的知识共享平台数据，研究提供了独特的视角，揭示了实际操作中面临的具体困难和普遍误解，对指导未来系统加固策略和教育具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算机系统抵御网络攻击的加固至关重要，但许多系统操作员难以有效加固，导致系统不安全。研究界缺乏对系统操作员在系统加固方面的动机、实践和挑战的深入理解。

**Method:** 研究人员定性分析了316个与系统加固相关的Stack Exchange (SE) 帖子，重点关注实践和挑战。

**Result:** 研究发现，访问控制和部署相关问题最具挑战性；系统操作员存在误解和不切实际的期望；帖子最常关注操作系统和服务器应用程序；系统操作员的动机是害怕系统受到攻击或出于合规性原因。

**Conclusion:** 研究讨论了研究问题，为未来的系统加固提出了建议，并阐明了工作的影响。

> **ai_Abstract:** 本研究旨在深入理解系统操作员在系统加固方面的动机、实践和挑战，因为现有系统普遍存在安全漏洞且相关研究不足。通过对316个Stack Exchange帖子的定性分析，研究发现访问控制和部署问题最具挑战性，且操作员常有误解和不切实际的期望。研究还指出，操作员的加固动机主要源于对攻击的恐惧或合规性要求。最后，文章提出了未来系统加固的建议并探讨了其研究意义。

> **摘要翻译:** 加固计算机系统以抵御网络攻击对于安全至关重要。然而，过去的事件表明，许多系统操作员在有效的系统加固方面存在困难。因此，许多计算机系统和应用程序仍然不安全。迄今为止，研究界对系统操作员在系统加固方面的动机、实践和挑战缺乏深入的理解。我们以实践和挑战为重点，定性分析了316个与系统加固相关的Stack Exchange (SE) 帖子。我们发现访问控制和部署相关问题最具挑战性，并且系统操作员存在误解和不切实际的期望。最常见的是，帖子关注操作系统和服务器应用程序。系统操作员的驱动力是害怕他们的系统受到攻击或出于合规性原因。最后，我们讨论了我们的研究问题，为未来的系统加固提出了建议，并阐明了我们工作的影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [163] [MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems](https://arxiv.org/abs/2507.13038)
> *MAD-Spear：一种基于从众性的多智能体辩论系统提示注入攻击*

*Yu Cui, Hongyang Du* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** 多智能体辩论系统, 提示注入攻击, LLM从众性, MAD-Spear, 安全漏洞

**Comment:** 

> **TL;DR:** MAD-Spear是一种针对多智能体辩论系统的新型提示注入攻击，通过操纵少量智能体利用LLM的从众性传播错误信息，显著降低系统性能并挑战了智能体多样性的传统认知。

**AI_Comments:** MAD-Spear的创新之处在于其“从众驱动”的攻击机制，它巧妙地利用了LLM的固有特性来放大攻击效果。这篇论文的重要性在于首次系统地揭示了多智能体辩论系统在安全方面的脆弱性，填补了该领域研究的空白。此外，关于智能体多样性对性能影响的新发现也为MAD系统的未来设计提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多智能体辩论（MAD）系统在提高推理能力方面表现出色，但其安全漏洞受到的关注有限。本研究旨在解决MAD系统的安全脆弱性问题，特别是针对提示注入攻击。

**Method:** 引入了MAD-Spear，一种有针对性的提示注入攻击，该攻击通过损害一小部分智能体来扰乱MAD过程。被操纵的智能体产生看似合理但错误的响应，利用LLM的从众性传播错误信息并降低共识质量。该攻击还可以与其他策略（如通信攻击）结合以放大影响。此外，提出了MAD容错性的正式定义，并开发了一个综合评估框架，考虑了准确性、共识效率和可扩展性。

**Result:** 在五个不同难度基准数据集上的大量实验表明，MAD-Spear在降低系统性能方面始终优于基线攻击。此外，研究发现智能体多样性显著提高了MAD在数学推理任务中的性能，这与之前认为智能体多样性对性能影响最小的工作相悖。

**Conclusion:** MAD-Spear攻击揭示了多智能体辩论系统存在的严重安全漏洞，强调了在MAD设计中迫切需要提高安全性的需求。同时，智能体多样性在特定任务中表现出的积极作用也为未来的系统设计提供了新视角。

> **ai_Abstract:** 本研究引入了MAD-Spear，一种针对多智能体辩论（MAD）系统的提示注入攻击。该攻击通过操纵少量智能体，利用大型语言模型（LLM）的从众性传播错误信息，从而显著降低系统的共识质量和整体性能。研究提出了MAD容错性的正式定义和评估框架，并在多个数据集上验证了MAD-Spear的有效性。实验结果不仅揭示了MAD系统在安全性方面的脆弱性，还发现智能体多样性能够显著提升数学推理任务中的MAD性能，这与现有认知有所不同。

> **摘要翻译:** 多智能体辩论（MAD）系统利用大型语言模型（LLM）智能体之间的协作交互来提高推理能力。尽管最近的研究主要集中于提高MAD系统的准确性和可扩展性，但其安全漏洞受到的关注有限。在这项工作中，我们引入了MAD-Spear，一种有针对性的提示注入攻击，它通过损害一小部分智能体来显著扰乱整个MAD过程。被操纵的智能体产生多个看似合理但错误的响应，利用LLM的从众倾向来传播错误信息并降低共识质量。此外，该攻击可以与其他策略（如通信攻击）结合使用，通过增加智能体暴露于错误响应的机会来进一步放大其影响。为了评估MAD在攻击下的韧性，我们提出了MAD容错性的正式定义，并开发了一个综合评估框架，该框架综合考虑了准确性、共识效率和可扩展性。在五个不同难度基准数据集上进行的大量实验表明，MAD-Spear在降低系统性能方面始终优于基线攻击。此外，我们观察到智能体多样性显著提高了MAD在数学推理任务中的性能，这挑战了先前认为智能体多样性对性能影响最小的工作。这些发现凸显了在MAD设计中迫切需要提高安全性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [168] [Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors](https://arxiv.org/abs/2507.13042)
> *基于反向散射的无线电力传输安全技术在无电池BLE传感器中的应用*

*Taki Eddine Djidjekh, Gaël Loubet, Alexandru Takacs* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** 反向散射安全, 无线电力传输, 无电池传感器, 蓝牙低功耗, 物联网安全

**Comment:** 

> **TL;DR:** 本文提出一种基于反向散射的安全机制，利用无线电力传输链路为无电池BLE传感器生成额外识别信号，实现安全、可持续、可扩展的物联网部署。

**AI_Comments:** 该论文的创新点在于将基于反向散射的安全机制与无线电力传输相结合，实现了在不增加能耗和计算负担的情况下为无电池物联网设备提供安全识别。其协议无关性和对资源受限设备的适用性是其重要贡献。然而，论文也提到了多节点网络中识别信号冲突的挑战，这可能是未来研究需要进一步解决的限制。

<details>
  <summary>Details</summary>

**Motivation:** 物联网系统中安全性和能源效率的整合是一个关键挑战，特别是对于无电池和资源受限的设备。

**Method:** 通过将基于反向散射的安全机制集成到无电池蓝牙低功耗无线传感器网络中，利用无线电力传输链路生成额外的识别信号，而不增加能耗或计算需求。通过紧凑型低增益天线进行实验验证，并讨论了反向散射动态范围和多节点无线传感器网络场景的挑战。

**Result:** 实验验证了该解决方案的功能性，适用于尺寸受限的应用；解决了反向散射动态范围和多节点无线传感器网络场景的挑战，并讨论了识别信号之间潜在的冲突。

**Conclusion:** 基于反向散射的安全机制在创建跨越不同协议和应用的安全、可持续、可扩展的物联网部署方面具有巨大潜力。

> **ai_Abstract:** 本文提出一种新颖的基于反向散射的安全机制，将其应用于无电池蓝牙低功耗无线传感器网络。该方法利用无线电力传输链路在不增加能耗或计算负担的情况下生成额外的识别信号，从而增强物联网系统的安全性。实验证明了其在紧凑型设备中的可行性，并讨论了多节点网络中的挑战，展示了其在构建安全、可持续、可扩展物联网部署中的巨大潜力。

> **摘要翻译:** 物联网系统中安全性和能源效率的整合仍然是一个关键挑战，特别是对于无电池和资源受限的设备。本文通过将基于反向散射的安全机制集成到蓝牙低功耗无电池无线传感器网络中，探索了其可扩展性和协议无关性。所提出的方法利用传统上用于能量收集的无线电力传输链路，生成额外的识别信号，而不会增加能耗或计算需求。实验验证表明，该解决方案使用紧凑型低增益天线也能正常工作，确保了与结构健康监测和智能交通等尺寸受限应用的兼容性。此外，这项工作解决了与反向散射动态范围和多节点无线传感器网络场景相关的挑战，讨论了识别信号之间潜在的冲突，并提出了未来改进以增强通用性和可扩展性。研究结果强调了基于反向散射的安全机制在创建跨越不同协议和应用的、安全、可持续和可扩展的物联网部署方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [173] [Prompt Injection 2.0: Hybrid AI Threats](https://arxiv.org/abs/2507.13169)
> *提示注入2.0：混合AI威胁*

*Jeremy McHugh, Kristina Šekrst, Jon Cefalu* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 提示注入, 混合威胁, AI安全, 网络安全漏洞, 代理AI系统

**Comment:** 

> **TL;DR:** 本文分析了提示注入攻击如何与传统网络安全漏洞结合形成“提示注入2.0”混合威胁，这些威胁能够规避传统安全控制，并提出了结合提示隔离、运行时安全和权限分离的架构解决方案。

**AI_Comments:** 本文揭示了AI安全领域一个重要的演进趋势，即提示注入攻击不再是孤立的威胁，而是可以与传统网络安全漏洞结合形成更具破坏性的“混合威胁”。这种对威胁模型的新颖定义及其对传统防御失效的揭示，具有重要的理论和实践意义。提出的架构性解决方案，如提示隔离和运行时安全，为未来AI系统安全设计提供了有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** 提示注入攻击对集成LLM的系统构成关键安全威胁，尤其是随着代理AI系统的出现，威胁格局已发生根本性变化。现代提示注入攻击可以与传统网络安全漏洞结合，形成规避传统安全控制的混合威胁。

**Method:** 本文对“提示注入2.0”进行了全面分析，研究了提示注入如何与跨站脚本（XSS）、跨站请求伪造（CSRF）及其他网络安全漏洞结合以规避传统安全措施。研究建立在Preamble公司的基础研究和缓解技术之上，并根据包括AI蠕虫、多代理感染和混合网络AI攻击在内的当代威胁进行评估。分析中包含了近期基准测试，并提出了结合提示隔离、运行时安全、权限分离和新型威胁检测能力的架构解决方案。

**Result:** 分析结果表明，传统的网络应用防火墙、XSS过滤器和CSRF令牌在面对AI增强型攻击时均告失败。研究还提出了能够有效应对这些威胁的架构解决方案。

**Conclusion:** 提示注入攻击已演变为与传统网络安全漏洞结合的“提示注入2.0”混合威胁，这些威胁能够系统性地规避传统安全控制。为了应对这些新型威胁，需要结合提示隔离、运行时安全、权限分离以及新型威胁检测能力的架构解决方案。

> **ai_Abstract:** 本文深入分析了“提示注入2.0”这一新型混合AI威胁，指出传统的提示注入攻击已演变为与跨站脚本（XSS）、跨站请求伪造（CSRF）等传统网络安全漏洞结合的形式，从而能够规避现有的安全防护措施。研究基于Preamble公司的前期工作，通过基准测试证明了传统安全机制在面对AI增强型攻击时的不足。为应对这些威胁，论文提出了结合提示隔离、运行时安全、权限分离及新型威胁检测能力的架构性解决方案。

> **摘要翻译:** 提示注入攻击，即设计恶意输入以操纵AI系统忽略其原始指令并遵循未经授权的命令，于2022年5月由Preamble公司首次发现并负责任地披露给OpenAI。在过去三年中，这些攻击持续对集成大型语言模型（LLM）的系统构成关键安全威胁。代理AI系统的出现，即LLM通过工具和与其他代理的协调自主执行多步任务，从根本上改变了威胁格局。现代提示注入攻击现在可以与传统网络安全漏洞结合，创建能够系统性规避传统安全控制的混合威胁。本文对提示注入2.0进行了全面分析，研究了提示注入如何与跨站脚本（XSS）、跨站请求伪造（CSRF）以及其他网络安全漏洞结合以绕过传统安全措施。我们基于Preamble的基础研究和缓解技术，对其进行评估以应对包括AI蠕虫、多代理感染和混合网络AI攻击在内的当代威胁。我们的分析包含了近期基准测试，这些测试表明传统的网络应用防火墙、XSS过滤器和CSRF令牌在AI增强型攻击面前失效。我们还提出了结合提示隔离、运行时安全和权限分离与新型威胁检测能力的架构解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [180] [A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models](https://arxiv.org/abs/2507.13313)
> *去中心化联邦学习模型的众包入侵检测数据集*

*Chao Feng, Alberto Huertas Celdran, Jing Han, Heqing Ren, Xi Cheng, Zien Zeng, Lucas Krauter, Gerome Bovet, Burkhard Stiller* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** 众包, 入侵检测, 联邦学习, 物联网, 恶意软件检测

**Comment:** 

> **TL;DR:** 本文介绍了一个用于物联网众包恶意软件检测的去中心化联邦学习（DFL）数据集和实验研究。该数据集包含良性行为和八种恶意软件家族的行为记录。实验结果表明，DFL在保持数据本地性的同时，性能具有竞争力，并且在大多数情况下优于中心化联邦学习（CFL）。

**AI_Comments:** 该论文的主要贡献是创建了一个大规模、详细的数据集，专门用于使用联邦学习在物联网众包环境中进行入侵检测。其创新之处在于专注于去中心化联邦学习，这对于物联网中的隐私和可扩展性至关重要。实验比较突出了DFL相对于CFL的实际优势，这对于实际世界中的安全物联网部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在引入一个用于物联网众包恶意软件检测的去中心化联邦学习（DFL）数据集和实验研究，以提供一个研究物联网众包环境安全性的坚实基础。

**Method:** 本文引入了一个包含良性和八种恶意软件家族行为记录的数据集，共收集了21,582,484条原始记录，这些记录来源于系统调用、文件系统活动、资源使用、内核事件、输入/输出事件和网络记录。这些记录被聚合到30秒的窗口中，产生了342,106个用于模型训练和评估的特征。在DFL平台上进行了实验，比较了传统机器学习（ML）、中心化联邦学习（CFL）和DFL在不同节点数量、拓扑结构和数据分布下的性能。

**Result:** 实验结果表明，去中心化联邦学习（DFL）在保持数据本地性的同时，性能仍具有竞争力，并且在大多数设置下优于中心化联邦学习（CFL）。

**Conclusion:** 该数据集为研究物联网众包环境的安全性提供了坚实的基础。

> **ai_Abstract:** 本文介绍了一个新颖的数据集和一项实验研究，旨在将去中心化联邦学习（DFL）应用于物联网众包恶意软件检测。该数据集包含了来自良性行为和八种恶意软件家族的2150万条行为记录，这些记录经过处理后形成了342,106个特征。在DFL平台上进行的对比实验表明，DFL在保持数据本地性的同时，实现了具有竞争力的性能，并且在多数情况下优于中心化联邦学习（CFL）。这项工作为物联网众包环境的安全研究提供了宝贵的资源。

> **摘要翻译:** 本文介绍了一个用于物联网众包恶意软件检测的去中心化联邦学习（DFL）数据集和实验研究。该数据集包含良性行为和八种恶意软件家族的行为记录。总共收集了21,582,484条原始记录，这些记录来源于系统调用、文件系统活动、资源使用、内核事件、输入/输出事件和网络记录。这些记录被聚合到30秒的窗口中，产生了342,106个用于模型训练和评估的特征。在DFL平台上进行了实验，比较了传统机器学习（ML）、中心化联邦学习（CFL）和DFL在不同节点数量、拓扑结构和数据分布下的性能。结果表明，DFL在保持数据本地性的同时，性能具有竞争力，并且在大多数情况下优于CFL。该数据集为研究物联网众包环境的安全性提供了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [216] [TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph](https://arxiv.org/abs/2304.02838)
> *TBDetector：基于Transformer和溯源图的高级持续性威胁检测器*

*Nan Wang, Xuezhi Wen, Dalin Zhang, Xibin Zhao, Jiahui Ma, Mengxia Luo, Fan Xu, Sen Nie, Shi Wu, Jiqiang Liu* | **Category: cs.CR, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 高级持续性威胁, APT检测, Transformer, 溯源图, 异常检测

**Comment:** 10 pages, 7 figures

> **TL;DR:** 本文提出了TBDetector，一种基于Transformer和溯源图的APT检测方法，旨在解决APT攻击的长期潜伏和缓慢多阶段模式。该方法通过溯源分析和Transformer提取长期上下文特征，并引入异常分数，实验证明其性能优于现有SOTA方法。

**AI_Comments:** TBDetector的创新之处在于结合了溯源图的空间效率和历史关联能力，以及Transformer模型在提取长期上下文特征方面的优势，有效应对了APT攻击的隐蔽性和长期性。引入异常分数也为异常判断提供了量化依据。该方法在实际APT检测中具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 高级持续性威胁（APT）由于其长期潜伏、隐蔽和缓慢的多阶段攻击模式，难以被检测。

**Method:** TBDetector利用溯源图来高效地总结长时间运行的系统执行。它采用基于自注意力机制的Transformer编码器-解码器来提取系统状态的长期上下文特征，以检测缓慢进行的攻击。此外，该方法引入了异常分数，通过计算每个系统状态的相似度分数和隔离分数来评估其异常性。

**Result:** 在五个公共数据集（streamspot、cadets、shellshock、clearscope和wget_baseline）上进行的实验，以及与现有最先进方法的比较结果表明，所提出的方法表现出更好的性能。

**Conclusion:** TBDetector能够有效检测高级持续性威胁，并在性能上优于当前最先进的方法。

> **ai_Abstract:** 本文提出TBDetector，一种结合Transformer和溯源图的APT检测方法，旨在应对APT攻击的长期潜伏和多阶段特性。TBDetector利用溯源图进行高效的历史信息总结，并通过Transformer的自注意力机制提取系统状态的长期上下文特征以检测慢速攻击。该方法还引入了异常分数来量化系统状态的异常程度。在多个公共数据集上的实验证明，TBDetector的性能优于现有先进方法。

> **摘要翻译:** 高级持续性威胁（APT）由于其长期潜伏、隐蔽和缓慢的多阶段攻击模式，难以被检测。为了解决这些问题，我们提出了TBDetector，一种基于Transformer的高级持续性威胁检测方法，用于APT攻击检测。考虑到溯源图提供了丰富的历史信息，并具有强大的攻击历史关联能力来识别异常活动，TBDetector采用溯源分析进行APT检测，它以空间效率总结长时间运行的系统执行，并利用带有自注意力机制的Transformer编码器-解码器来提取系统状态的长期上下文特征，以检测缓慢进行的攻击。此外，我们进一步引入异常分数来调查不同系统状态的异常性，其中每个状态的异常分数是根据其相似度分数和隔离分数计算得出的。为了评估所提出方法的有效性，我们对五个公共数据集进行了实验，即streamspot、cadets、shellshock、clearscope和wget_baseline。实验结果以及与最先进方法的比较表明，我们提出的方法表现出更好的性能。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [228] [Slot: Provenance-Driven APT Detection through Graph Reinforcement Learning](https://arxiv.org/abs/2410.17910)
> *Slot：通过图强化学习驱动的溯源高级持续性威胁检测*

*Wei Qiao, Yebo Feng, Teng Li, Zhuo Ma, Yulong Shen, JianFeng Ma, Yang Liu* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** APT检测, 溯源图, 图强化学习, 网络安全, 攻击链

**Comment:** This paper has been accepted to the ACM Conference on Computer and
  Communications Security (CCS) 2025

> **TL;DR:** Slot是一种基于溯源图和图强化学习的APT检测方法，它能发现复杂关系，适应新活动，并自动构建攻击链，在真实数据集上表现优异。

**AI_Comments:** 该论文的创新点在于首次将图强化学习应用于溯源图，以动态适应APT检测中的不断变化的行为和攻击策略。其优势在于能够揭示多层隐藏关系、抵抗对抗性攻击以及自动构建攻击链，这对于复杂的APT防御至关重要。其在真实世界数据集上的SOTA性能证明了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有APT检测方法在识别复杂威胁、构建攻击链和抵抗对抗性攻击方面存在困难。

**Method:** Slot通过溯源图挖掘发现系统行为之间的多层隐藏关系（因果、上下文、间接连接）。它开创性地整合了图强化学习，以动态适应新的用户活动和不断演变的攻击策略。此外，Slot利用聚类算法自动构建攻击链。

**Result:** 在真实世界数据集上的评估表明，Slot在APT检测方面具有出色的准确性、效率、适应性和鲁棒性，大多数指标超越了现有最先进的方法。案例研究进一步证实了其在支持APT防御方面的有效性。

**Conclusion:** Slot是一种实用且可靠的网络安全保护工具，能够有效检测APT并支持防御策略的制定。

> **ai_Abstract:** Slot是一种创新的高级持续性威胁（APT）检测方法，它利用溯源图和图强化学习来克服现有方法的局限性。该方法通过挖掘系统行为间的深层关系，并动态适应新的攻击策略，从而增强对对抗性攻击的抵抗力。Slot还能自动构建攻击链，以辅助防御。在真实数据集上的评估显示，Slot在准确性、效率、适应性和鲁棒性方面均优于现有技术，并被证明是网络安全防御的实用工具。

> **摘要翻译:** 高级持续性威胁（APT）是一种复杂的网络攻击，其特点是能够在受害者系统中长时间保持未被发现，旨在窃取敏感数据或扰乱操作。现有检测方法往往难以有效识别这些复杂威胁、构建攻击链以促进防御，或抵抗对抗性攻击。为了克服这些挑战，我们提出了Slot，一种基于溯源图和图强化学习的高级APT检测方法。Slot通过溯源图挖掘，擅长揭示系统行为之间多层隐藏关系，例如因果、上下文和间接连接。通过开创性地整合图强化学习，Slot能够动态适应新的用户活动和不断演变的攻击策略，增强其抵抗对抗性攻击的能力。此外，Slot根据检测到的攻击，利用聚类算法自动构建攻击链，提供精确的攻击路径识别，并促进防御策略的开发。使用真实世界数据集进行的评估表明，Slot在APT检测方面具有出色的准确性、效率、适应性和鲁棒性，大多数指标超越了现有最先进的方法。此外，为评估Slot在支持APT防御方面的有效性而进行的案例研究进一步确立了其作为网络安全保护的实用且可靠工具的地位。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [240] [Pulsar Consensus](https://arxiv.org/abs/2411.14245)
> *Pulsar 共识*

*Samer Afach, Benjamin Marsh, Enrico Rubboli* | **Category: cs.CR, 94A60, 91A80** | **Updated: 2025-07-17**

**Keywords:** Pulsar, 权益证明, 侧链, 链选择规则, 共识协议

**Comment:** Mintlayer consensus overview

> **TL;DR:** 本文介绍了Pulsar权益证明共识协议，旨在为工作量证明区块链创建权益证明侧链，并提出了一种新颖的基于密度的链选择规则，目前已在Mintlayer比特币侧链中实现。

**AI_Comments:** 本文的创新点在于提出了Pulsar协议及其独特的可组合的基于密度的链选择规则，该规则在权益证明系统中具有超越传统最长链规则的潜力。其重要性在于为PoW区块链提供了一个PoS侧链的解决方案，并已在实际项目中得到应用，这表明了其理论与实践的结合。论文也明确指出了工作的局限性，体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在介绍Pulsar权益证明共识协议，并讨论其设计决策和考虑因素，特别是为了促进为工作量证明（PoW）区块链创建权益证明（PoS）侧链。

**Method:** 本文提出了Pulsar协议，这是一种权益证明共识协议，其核心是新颖的可组合的基于密度的链选择规则，该规则被视为现有PoS协议最长链规则的超集。论文还讨论了Pulsar与现有权益证明协议的比较，并阐述了其优势和局限性。

**Result:** Pulsar协议目前已在Mintlayer权益证明比特币侧链中实现。

**Conclusion:** 本文介绍了Pulsar权益证明共识协议，该协议通过引入创新的基于密度的链选择规则，为工作量证明区块链构建权益证明侧链提供了可行的方案，并已成功应用于实际的侧链项目。

> **ai_Abstract:** 本文非正式地介绍了Pulsar权益证明共识协议，旨在为工作量证明区块链创建权益证明侧链。它提出了一种新颖的可组合的基于密度的链选择规则，该规则可视为现有最长链规则的超集。文章比较了Pulsar与现有协议的优缺点，并指出该协议已在Mintlayer权益证明比特币侧链中实现。

> **摘要翻译:** 在本文中，我们非正式地介绍了Pulsar权益证明共识论文，并讨论了相关的设计决策和考虑因素。我们提出的Pulsar协议旨在促进为工作量证明区块链创建权益证明侧链。我们概述了一种新颖的可组合的基于密度的权益证明系统链选择规则，该规则可以被视为一些标准现有权益证明协议最长链规则的超集。我们讨论了Pulsar协议与现有权益证明协议的比较，并定义了其相对于现有设计的优势，同时定义了这项工作的局限性。Pulsar目前已在Mintlayer权益证明比特币侧链中实现。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [256] [Outfox: a Packet Format for a Layered Mixnet](https://arxiv.org/abs/2412.19937)
> *Outfox：一种分层混合网络的包格式*

*Alfredo Rial, Ania M. Piotrowska, Harry Halpin* | **Category: cs.CR** | **Updated: 2025-07-17**

**Keywords:** Outfox, 混合网络, 后量子安全, 匿名通信, 包格式

**Comment:** 

> **TL;DR:** Outfox是一种新的、简化的Sphinx变体，专为具有固定长度路由的混合网络设计，旨在实现后量子安全性，同时降低计算和通信成本并保持强大的匿名性。

**AI_Comments:** 该论文提出了一种针对后量子时代混合网络的重要改进，通过引入Outfox解决了当前标准Sphinx的量子脆弱性问题。其创新点在于简化了Sphinx并优化了效率，同时提供了形式化的安全证明，这对于未来匿名通信的安全性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前的混合网络标准Sphinx依赖于经典的公钥密码学，使其容易受到量子攻击。因此，需要一种能够抵抗量子攻击的匿名通信包格式。

**Method:** 本文提出了Outfox，它是Sphinx的一种简化变体，专为固定长度路由的混合网络量身定制，并设计用于后量子安全。作者正式定义了Outfox，并在通用可组合性（UC）框架中证明了其安全性。

**Result:** Outfox降低了计算和通信成本，同时保留了强大的匿名性保证，并提供了更高的效率和对量子抗性密码原语的适应性。

**Conclusion:** Outfox是一种高效且具有后量子安全性的包格式，适用于分层混合网络，解决了现有标准对量子攻击的脆弱性问题，同时保持了强大的匿名性。

> **ai_Abstract:** 本文介绍了Outfox，一种为固定路由混合网络设计的简化型Sphinx包格式，旨在解决现有标准Sphinx在量子攻击下的脆弱性。Outfox通过降低计算和通信成本，同时在UC框架下被证明具有强大的后量子安全性，并保持了与Sphinx相当的匿名性，从而提高了效率和适应性。

> **摘要翻译:** 匿名通信依赖于加密的包格式，这些格式能够抵抗流量分析并确保不可链接性。Sphinx作为当前混合网络的标准，提供了强大的匿名性，但它依赖于经典的公钥密码学，使其容易受到量子攻击。在本文中，我们提出了Outfox，它是Sphinx的一种简化变体，专为具有固定长度路由的混合网络量身定制，并设计用于后量子安全性。Outfox降低了计算和通信成本。我们正式定义了Outfox，并在通用可组合性（UC）框架中证明了其安全性。我们的评估表明，Outfox在保留强大匿名性保证的同时，提供了更高的效率和对量子抗性密码原语的适应性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [276] [JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](https://arxiv.org/abs/2504.03770)
> *JailDAM：面向视觉-语言模型的自适应记忆越狱检测*

*Yi Nian, Shenzhe Zhu, Yuehan Qin, Li Li, Ziyi Wang, Chaowei Xiao, Yue Zhao* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 越狱检测, 视觉-语言模型, 自适应记忆, 有害内容, 实时检测

**Comment:** 

> **TL;DR:** 多模态大型语言模型（MLLMs）存在越狱攻击生成有害内容的风险。现有检测方法面临白盒依赖、高计算开销和需要完全标记有害数据集的挑战。本文提出JAILDAM，一个测试时自适应框架，利用基于记忆的方法和策略驱动的不安全知识表示，无需明确的有害数据暴露，动态更新不安全知识，在VLM越狱基准测试中实现了最先进的有害内容检测性能，提高了准确性和速度。

**AI_Comments:** JailDAM的创新之处在于其测试时自适应和基于记忆的方法，无需大量标注的有害数据集即可进行越狱检测，这在实际应用中具有重要意义。它有效解决了现有方法对白盒模型依赖和计算开销大的问题，对于提升MLLMs的安全性至关重要。抽象中未提及具体局限性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）在视觉-语言任务中表现出色，但也存在生成有害内容的重大风险，特别是通过越狱攻击。越狱攻击是指绕过模型安全机制，导致生成不适当或不安全内容的故意操纵。检测此类攻击对于确保MLLMs的负责任部署至关重要。现有越狱检测方法面临三个主要挑战：1）许多方法依赖于模型隐藏状态或梯度，限制了它们对白盒模型的适用性；2）它们涉及基于不确定性分析的高计算开销，限制了实时检测；3）它们需要完全标记的有害数据集，这在实际环境中通常很稀缺。

**Method:** 我们引入了一个名为JAILDAM的测试时自适应框架。我们的方法利用基于记忆的方法，由策略驱动的不安全知识表示引导，从而无需明确暴露于有害数据。通过在测试时动态更新不安全知识，我们的框架提高了对未见越狱策略的泛化能力，同时保持了效率。

**Result:** 在多个VLM越狱基准测试上的实验表明，JAILDAM在有害内容检测方面提供了最先进的性能，提高了准确性和速度。

**Conclusion:** JailDAM成功解决了多模态大型语言模型越狱检测的现有挑战，通过引入一个无需明确有害数据、高效且泛化能力强的测试时自适应记忆框架，显著提升了有害内容检测的准确性和速度。

> **ai_Abstract:** 本文针对多模态大型语言模型（MLLMs）越狱攻击生成有害内容的风险，指出现有检测方法存在白盒依赖、高计算开销和数据稀缺等问题。为解决这些挑战，作者提出了JAILDAM，一个测试时自适应框架。该方法采用基于记忆的策略驱动不安全知识表示，无需明确的有害数据即可在测试时动态更新不安全知识，从而提高对新越狱策略的泛化能力并保持效率。实验证明，JAILDAM在VLM越狱基准测试中实现了最先进的有害内容检测性能，显著提升了准确性和速度。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在视觉-语言任务中表现出色，但也存在生成有害内容的重大风险，特别是通过越狱攻击。越狱攻击是指绕过模型安全机制，导致生成不适当或不安全内容的故意操纵。检测此类攻击对于确保MLLMs的负责任部署至关重要。现有越狱检测方法面临三个主要挑战：(1) 许多方法依赖于模型隐藏状态或梯度，限制了它们对白盒模型的适用性，即模型内部工作原理可访问的情况；(2) 它们涉及基于不确定性分析的高计算开销，这限制了实时检测；(3) 它们需要完全标记的有害数据集，这在实际环境中通常很稀缺。为了解决这些问题，我们引入了一个名为JAILDAM的测试时自适应框架。我们的方法利用基于记忆的方法，由策略驱动的不安全知识表示引导，从而无需明确暴露于有害数据。通过在测试时动态更新不安全知识，我们的框架提高了对未见越狱策略的泛化能力，同时保持了效率。在多个VLM越狱基准测试上的实验表明，JAILDAM在有害内容检测方面提供了最先进的性能，提高了准确性和速度。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [300] [Secure Parsing and Serializing with Separation Logic Applied to CBOR, CDDL, and COSE](https://arxiv.org/abs/2505.17335)
> *应用分离逻辑于CBOR、CDDL和COSE的安全解析与序列化*

*Tahina Ramananandro, Gabriel Ebner, Guido Martínez, Nikhil Swamy* | **Category: cs.CR, cs.PL** | **Updated: 2025-07-17**

**Keywords:** 安全解析, 序列化, 分离逻辑, CBOR, CDDL

**Comment:** 

> **TL;DR:** 本文提出PulseParse，一个基于分离逻辑的经验证的解析器和序列化器组合库，用于安全处理二进制数据格式。该库首次形式化了CBOR和CDDL，并生成了针对CBOR和CDDL的经验证的解析器和序列化器，显著提高了安全关键应用的可靠性。

**AI_Comments:** 本文的创新之处在于将分离逻辑应用于安全关键数据格式的解析和序列化，提供了一种可证明正确的方法。PulseParse、EverCBOR和EverCDDL的开发填补了低级语言中缺乏经验证的解析和序列化工具的空白，对于提高嵌入式系统和安全协议的健壮性具有重要意义。对CBOR和CDDL的首次形式化工作也极具价值。

<details>
  <summary>Details</summary>

**Motivation:** 低级语言中对安全关键数据格式的不正确处理是许多安全漏洞的根源。因此，需要针对C等语言的、可证明正确的解析和序列化工具。

**Method:** 本文提出了PulseParse，一个用于不可篡改二进制格式的经验证的解析器和序列化器组合库，其规范和证明采用分离逻辑，并支持数据验证、解析和序列化，同时能以恒定堆栈空间处理递归格式。研究人员首次形式化了CBOR，证明其确定性片段的不可篡改性，并提供了基于PulseParse实现的EverCBOR库。随后，他们首次形式化了CDDL，确定了确保其产生明确、不可篡改格式的良好形式条件，并实现了EverCDDL工具来检查CDDL定义并生成经验证的解析器和序列化器。

**Result:** 开发了PulseParse库，首次对CBOR和CDDL进行了形式化。证明了CBOR确定性片段的不可篡改性。提供了EverCBOR（一个C和Rust语言的经验证的CBOR库）和EverCDDL（一个用于检查CDDL定义并生成经验证的解析器和序列化器的工具）。成功使用EverCDDL为COSE签名和DICE保护环境等安全关键应用生成了经验证的代码。

**Conclusion:** 本文通过开发PulseParse库及其在CBOR和CDDL上的应用，显著提高了安全关键数据格式处理的可靠性，为构建可证明安全的系统提供了重要工具。

> **ai_Abstract:** 本文提出PulseParse，一个基于分离逻辑的经验证的解析器和序列化器组合库，旨在解决低级语言中安全关键数据格式处理不当导致的安全漏洞。PulseParse能够处理不可篡改的二进制格式和递归格式，并支持数据验证、解析和序列化。研究人员首次对CBOR和CDDL进行了形式化，并基于PulseParse分别开发了EverCBOR库和EverCDDL工具。EverCDDL能够检查CDDL定义的良好形式并生成经验证的解析器和序列化器。通过将这些工具应用于COSE签名和DICE保护环境等安全关键应用，验证了其有效性和实用性。

> **摘要翻译:** 对安全关键数据格式的不正确处理，特别是在低级语言中，是许多安全漏洞的根本原因。针对C等语言的可证明正确的解析和序列化工具可以提供帮助。为此，我们提出了PulseParse，一个经验证的解析器和序列化器组合库，用于不可篡改的二进制格式。PulseParse中的规范和证明采用分离逻辑，提供更抽象和可组合的接口，并全面支持数据验证、解析和序列化。PulseParse还支持一类递归格式——我们专注于安全性和处理对抗性输入，展示了如何仅用恒定堆栈空间解析此类格式。
我们通过提供CBOR（一种递归的二进制数据格式标准，在各种工业标准中日益普及）的首次形式化，大规模应用了PulseParse。我们证明了CBOR的确定性片段是不可篡改的，并提供了EverCBOR，一个用C和Rust语言实现的经验证的库，用于验证、解析和序列化使用PulseParse实现的CBOR对象。接下来，我们提供了CDDL（CBOR的模式定义语言）的首次形式化。我们确定了CDDL定义上的良好形式条件，以确保它们产生明确、不可篡改的格式，并实现了EverCDDL，一个工具，用于检查CDDL定义是否良好形式，然后为其生成经验证的解析器和序列化器。
为了评估我们的工作，我们使用EverCDDL为各种安全关键应用生成了经验证的解析器和序列化器。值得注意的是，我们构建了COSE签名（一种加密签名对象的标准）的形式化验证实现。我们还使用我们的工具链为CDDL中指定的其他标准生成了验证代码，包括DICE保护环境，一个安全启动协议标准。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [11] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
> *信息论驱动的模拟指挥中伦理属性的聚合*

*Hussein Abbass, Taylan Akay, Harrison Tolley* | **Category: cs.AI** | **Updated: 2025-07-17**

**Keywords:** 信息论, 伦理属性, 模拟指挥, 动态加权, 熵

**Comment:** 

> **TL;DR:** 本文提出一种在AI模拟中动态加权伦理属性的方法，通过将人类判断移出循环，并利用信息论（如熵）来自动聚合伦理决策的权重。

**AI_Comments:** 本文的创新点在于提出了一种将人类伦理判断与大规模AI模拟解耦的框架，并通过引入信息论（特别是熵）的概念来动态、自动化地处理模拟过程中伦理属性的权重问题。这对于提高AI决策模拟的效率和可行性具有重要意义，尤其是在需要快速探索大量复杂场景时。该方法有望减轻人类在伦理评估上的负担，同时保留最终的人类监督。

<details>
  <summary>Details</summary>

**Motivation:** 在AI时代，人类指挥官需要模拟大量场景，其中包含伦理决策。然而，将人类判断纳入每次模拟决策既低效又不可行，因为它会阻碍及时探索大量场景，并带来巨大的工作量。因此，需要一种将人类判断移出模拟决策循环的方法，并自动处理模拟中伦理属性的权重问题。

**Method:** 本文提出一种方法，将人类判断从模拟决策循环中移出。具体而言，人类负责设计伦理度量空间，而模拟环境负责探索该空间。在模拟测试周期完成后，测试环境会向人类指挥官提供少量选项进行选择，人类再进行最终判断。论文的核心问题是解决如何在生成式模拟中，当智能体面临具有伦理影响的决策选项时，动态加权伦理属性。作者借鉴了多准则决策文献中利用熵概念确定聚合权重的方法，旨在自动计算模拟测试和评估中伦理属性的权重。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种在人工智能模拟中处理伦理决策的方法，旨在解决人类判断介入模拟决策循环的低效性和不可行性问题。该方法将人类判断移出循环，由人类设计伦理度量空间，模拟环境负责探索和提供有限选项，最终由人类选择。论文核心关注如何在模拟中动态加权伦理属性，并借鉴多准则决策文献中利用信息论（如熵）来自动计算这些权重的方法。

> **摘要翻译:** 在人工智能时代，人类指挥官需要利用当今环境中的计算能力来模拟大量的场景。在每个场景中，都会出现不同的决策设计选项可能产生伦理后果的情况。让这些决策依赖于人类判断，既不利于及时探索大量场景的目标，又考虑到让人类参与每个选择所需的工作量，是不可行的。在本文中，我们将人类判断移出模拟决策循环。基本上，人类将设计伦理度量空间，将其留给模拟环境去探索。当模拟完成其测试周期后，测试环境将向人类指挥官返回几个选项供选择。然后，人类指挥官将运用人类判断来选择最合适的行动方案，并据此执行。我们假设设计足够细致的度量标准来评估决策的伦理影响的问题已经解决。随后，本文中我们关注的根本问题是如何在这些模拟运行期间对伦理决策进行加权；也就是说，在生成式模拟中，当智能体面临具有伦理影响的决策选项时，如何动态加权伦理属性。多准则决策文献已经开始关注类似问题，其中熵的概念已被用于确定聚合过程中的权重。我们借鉴了该文献中不同的方法，以在基于模拟的测试和评估中自动计算伦理属性的权重。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [19] [LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations](https://arxiv.org/abs/2402.09617)
> *LLM增强的用户-物品交互：利用边缘信息优化推荐*

*Xinyuan Wang, Liang Wu, Liangjie Hong, Hao Liu, Yanjie Fu* | **Category: cs.AI, cs.IR** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 图推荐, 边缘信息, 推荐系统, 注意力机制

**Comment:** 

> **TL;DR:** 本文提出了一种将图结构边缘信息整合到大型语言模型（LLM）中以改进推荐系统的方法，通过创新的提示设计和注意力机制来弥合图与文本生成推荐之间的鸿沟。

**AI_Comments:** 本文的创新之处在于提出了一种有效整合图结构信息和大型语言模型文本生成能力的框架，解决了两种推荐范式之间的融合难题。通过在提示和注意力机制层面引入图的边缘信息，它为LLM在推荐系统中的应用开辟了新的途径，对于提升推荐的个性化和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图推荐方法和大型语言模型在推荐任务上各有优势，但两者之间存在任务表述上的差异，导致难以有效整合。因此，研究如何将这两种视角有效结合以实现更个性化的推荐系统是一个关键问题。

**Method:** 作者提出了一个框架，通过提示（prompt）和注意力机制的创新，将图的边缘信息（包括一阶和二阶图关系）融入到大型语言模型中，将推荐重构为一个概率生成问题。具体而言，他们设计了一种新的提示，引入了图的一阶和二阶关系；并改进了LLM的注意力机制，以直接嵌入边的空间和连接信息。

**Result:** 在真实世界数据集上的评估表明，该框架能够理解图数据中的连接信息，并提高了推荐结果的相关性和质量。

**Conclusion:** 通过将图的边缘信息有效融入大型语言模型，本文提出的框架成功弥合了图推荐和文本生成推荐之间的鸿沟，显著提升了推荐系统的性能。

> **ai_Abstract:** 本文旨在弥合图推荐方法和大型语言模型（LLM）在推荐系统中的差距。作者提出了一个创新框架，通过改进的提示设计和注意力机制，将图结构中的边缘信息（包括一阶和二阶关系）有效地融入到LLM中，从而将推荐任务重新定义为概率生成问题。在真实世界数据集上的实验结果表明，该方法能够更好地理解图连接信息，并显著提升推荐结果的质量和相关性。

> **摘要翻译:** 图推荐方法代表了一种连接交互视角，将用户-物品交互重构为图，以利用图结构和拓扑进行推荐，并在大规模应用中证明了其实际有效性。大型语言模型代表了一种文本生成视角，擅长建模用户语言、理解行为上下文、捕捉用户-物品语义关系、分析文本情感以及生成连贯且上下文相关的推荐文本。然而，由于任务表述不同，连接图视角和文本生成视角之间存在一个空白。因此产生了一个研究问题：我们如何才能有效地整合这两种视角，以实现更个性化的推荐系统？为了填补这一空白，我们提出通过提示和注意力创新将图边缘信息整合到大型语言模型中。我们使用提示将推荐重构为一个概率生成问题。我们开发了一个框架，通过提示和注意力机制整合图边缘信息，以实现图结构化的LLM推荐。我们开发了一种新的提示设计，引入了一阶和二阶图关系；我们设计了一种改进的LLM注意力机制，以直接嵌入边的空间和连接信息。我们对真实世界数据集的评估表明，该框架能够理解图数据中的连接信息，并提高推荐结果的相关性和质量。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [31] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
> *VAR-MATH：通过符号化多实例基准探测大型语言模型的真实数学推理能力*

*Jian Yao, Ran Cheng, Kay Chen Tan* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 数学推理, 大型语言模型, 符号评估, 基准测试, 过拟合

**Comment:** 

> **TL;DR:** 论文提出了VAR-MATH框架，通过符号化多实例评估来检测LLM的真实数学推理能力，发现现有RL训练模型在泛化性上表现不佳，可能存在过拟合。

**AI_Comments:** VAR-MATH提供了一种新颖且严谨的方法来评估LLM的数学推理能力，有效地揭示了现有RL训练方法可能存在的过拟合问题。其引入的符号化多实例评估范式对于未来LLM的鲁棒性和泛化能力研究具有重要意义，有助于推动更真实的AI推理发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有标准基准测试中，大型语言模型（LLMs）的数学推理能力提升可能并非真实推理，而是对特定模式的过拟合；现有评估协议存在基准污染和评估脆弱性问题，无法捕捉推理一致性。

**Method:** 引入VAR-MATH符号评估框架，将固定数值问题转换为符号模板，并要求模型解决每个模板的多个实例，以强制在结构等效变体之间进行一致推理，从而减轻污染并提高评估鲁棒性。将AMC23和AIME24转换为其符号对应版本VAR-AMC23和VAR-AIME24。

**Result:** 实验表明，RL训练的模型在符号化版本上的性能大幅下降，尤其对于小型模型，在AMC23上平均下降48.0%，在AIME24上平均下降58.3%。这些发现表明许多现有RL方法依赖于肤浅的启发式，未能泛化到特定数值形式之外。

**Conclusion:** VAR-MATH提供了一个原则性的、抗污染的数学推理评估范式，揭示了现有RL方法可能未能实现真正的数学推理。

> **ai_Abstract:** 本文提出了VAR-MATH，一个旨在探测大型语言模型真实数学推理能力的符号评估框架。针对现有基准测试中可能存在的基准污染和评估脆弱性问题，VAR-MATH通过将数值问题转换为符号模板并要求模型解决多实例变体，以强制一致推理并提高评估鲁棒性。在转换后的AMC23和AIME24基准上的实验表明，RL训练的模型性能显著下降，揭示了这些模型可能依赖于肤浅的启发式而非真正的泛化推理能力。

> **摘要翻译:** 最近强化学习（RL）的进展使得大型语言模型（LLMs）的数学推理能力在标准基准测试中取得了实质性提升。然而，即使模型在存在缺陷信号（如随机或反向奖励）的情况下进行训练，这些提升也常常持续存在，这引发了一个基本问题：这些改进是否反映了真实的推理能力，或者它们仅仅是过度拟合基准特定模式的产物？为了解决这个问题，我们采取了一种以评估为中心的方法，并识别出现有协议中的两个关键缺点。首先，由于测试问题的公开可用性，导致“基准污染”的风险增加，数据泄露的可能性增大。其次，“评估脆弱性”源于对单实例评估的依赖，这种评估对随机输出高度敏感，并且未能捕捉推理的一致性。为了克服这些限制，我们引入了VAR-MATH，这是一个符号评估框架，旨在探测真正的推理能力。通过将固定的数值问题转换为符号模板，并要求模型解决每个模板的多个实例，VAR-MATH强制在结构等效的变体之间进行一致推理，从而减轻污染并提高评估的鲁棒性。我们将两个流行的基准AMC23和AIME24转换为它们的符号对应版本VAR-AMC23和VAR-AIME24。实验结果显示，RL训练的模型在可变版本上的性能大幅下降，特别是对于较小的模型，在AMC23上平均下降48.0%，在AIME24上平均下降58.3%。这些发现表明，许多现有RL方法依赖于肤浅的启发式，未能泛化到特定的数值形式之外。总的来说，VAR-MATH为数学推理提供了一个原则性的、抗污染的评估范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [56] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
> *将概率事件演算转换为马尔可夫决策过程*

*Lyris Xu, Fabio Aurelio D'Asaro, Luke Dickens* | **Category: cs.AI, cs.LO** | **Updated: 2025-07-17**

**Keywords:** 概率事件演算, 马尔可夫决策过程, 叙事推理, 目标导向规划, 时间推理

**Comment:** 

> **TL;DR:** 本文提出了一种将概率事件演算（PEC）领域正式转换为马尔可夫决策过程（MDPs）的方法，以弥补PEC在目标导向推理方面的不足，从而使MDPs的丰富算法和工具能够应用于PEC的可解释叙事领域。

**AI_Comments:** 这项工作具有重要意义，因为它通过将逻辑推理与决策理论相结合，显著扩展了概率事件演算的应用范围。它不仅解决了PEC在目标导向推理上的局限性，还通过保留PEC的可解释性，为在复杂不确定环境中进行规划和决策提供了强大的新工具。其创新之处在于“动作执行情境”的概念，有效地桥接了两种形式化之间的语义差异。

<details>
  <summary>Details</summary>

**Motivation:** 概率事件演算（PEC）是一个用于在不确定环境中推理动作及其效果的逻辑框架，在叙事推理方面具有可解释性和表达性优势，但它缺乏目标导向推理机制。

**Method:** 本文通过开发一种将PEC领域正式转换为马尔可夫决策过程（MDPs）的方法来弥补这一不足。引入了“动作执行情境”的概念，以保留PEC灵活的动作语义。

**Result:** 由此产生的PEC-MDP形式化使得为MDPs开发的丰富算法和理论工具能够应用于PEC的可解释叙事领域。该转换支持时间推理任务和目标驱动规划，并提供了将学习到的策略映射回人类可读的PEC表示的方法。

**Conclusion:** 通过将PEC翻译成MDPs，本文扩展了PEC的能力，使其能够进行目标导向推理和规划，同时保持了其固有的可解释性。

> **ai_Abstract:** 本文提出了一种将概率事件演算（PEC）领域正式转换为马尔可夫决策过程（MDPs）的方法，以解决PEC在目标导向推理方面的不足。通过引入“动作执行情境”概念，该转换保留了PEC的灵活动作语义，并使得MDP的算法和工具能够应用于PEC的可解释叙事领域，从而支持时间推理和目标驱动规划，并能将学习到的策略映射回可读的PEC表示。

> **摘要翻译:** 概率事件演算（PEC）是一个用于在不确定环境中推理动作及其效果的逻辑框架，它能够表示概率叙事并计算时间投影。PEC形式化在叙事推理方面提供了显著的可解释性和表达性优势。然而，它缺乏目标导向推理机制。本文通过开发一种将PEC领域正式转换为马尔可夫决策过程（MDPs）的方法来弥补这一不足，引入了“动作执行情境”的概念以保留PEC灵活的动作语义。由此产生的PEC-MDP形式化使得为MDPs开发的丰富算法和理论工具能够应用于PEC的可解释叙事领域。我们展示了该转换如何支持时间推理任务和目标驱动规划，并提供了将学习到的策略映射回人类可读的PEC表示的方法，从而在扩展PEC能力的同时保持了其可解释性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [64] [Demystifying MuZero Planning: Interpreting the Learned Model](https://arxiv.org/abs/2411.04580)
> *揭秘 MuZero 规划：解读学习到的模型*

*Hung Guei, Yan-Ru Ju, Wei-Yu Chen, Ti-Rong Wu* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** MuZero, 潜在状态, 模型解释, 规划, 动态网络

**Comment:** Accepted by IEEE Transactions on Artificial Intelligence

> **TL;DR:** MuZero 的规划过程因其潜在状态而变得不透明。本文旨在通过解释这些潜在状态来揭示 MuZero 模型，发现尽管动态网络在长时间模拟中准确性下降，MuZero 仍能通过规划有效纠正错误，并且在棋盘游戏中学习到比 Atari 游戏中更好的潜在状态。

**AI_Comments:** 本文创新性地尝试解读 MuZero 规划的“黑箱”性质，特别是其潜在状态。其重要性在于提升对高级 AI 模型（如 MuZero）的理解和可解释性，这对于它们的广泛采用和信任至关重要。关于通过规划纠正错误以及在不同游戏类型中表现差异的发现具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** MuZero 在各种游戏中取得了超人的表现，但其规划过程由于动态网络学习到的潜在状态而不透明。本文旨在通过解释这些学习到的潜在状态来揭示 MuZero 的模型。

**Method:** 研究人员将观测重建和状态一致性纳入 MuZero 训练中。他们对两种棋盘游戏（9x9 围棋和五子棋）和三种 Atari 游戏（Breakout、Ms. Pacman 和 Pong）的潜在状态进行了深入分析和评估。

**Result:** 研究结果表明，尽管动态网络在较长时间的模拟中准确性会降低，但 MuZero 仍然可以通过规划来纠正错误从而有效执行。实验还显示，动态网络在棋盘游戏中学习到的潜在状态优于 Atari 游戏。

**Conclusion:** 这些见解有助于更好地理解 MuZero，并为未来研究提供方向，以提高 MuZero 算法的性能、鲁棒性和可解释性。

> **ai_Abstract:** 本文旨在解决 MuZero 规划过程中因其学习到的潜在状态而产生的模糊性。通过在 MuZero 训练中加入观测重建和状态一致性，并对多种棋盘游戏和 Atari 游戏中的潜在状态进行深入分析，作者发现 MuZero 的规划即使在动态网络长时间模拟中准确性下降的情况下，也能有效纠正错误。他们还观察到，在棋盘游戏中学习到的潜在状态优于 Atari 游戏，这为未来 MuZero 算法的性能、鲁棒性和可解释性研究提供了宝贵的见解。

> **摘要翻译:** MuZero 在各种游戏中取得了超人的表现，它使用一个动态网络来预测环境动态进行规划，而不依赖于模拟器。然而，动态网络学习到的潜在状态使得其规划过程不透明。本文旨在通过解释学习到的潜在状态来揭示 MuZero 的模型。我们将观测重建和状态一致性纳入 MuZero 训练中，并进行了深入分析，以评估两种棋盘游戏：9x9 围棋和五子棋，以及三种 Atari 游戏：Breakout、Ms. Pacman 和 Pong 中的潜在状态。我们的发现表明，尽管动态网络在较长时间的模拟中准确性会降低，但 MuZero 仍然可以通过规划来纠正错误从而有效执行。我们的实验还显示，动态网络在棋盘游戏中学习到的潜在状态优于 Atari 游戏。这些见解有助于更好地理解 MuZero，并为未来研究提供方向，以提高 MuZero 算法的性能、鲁棒性和可解释性。代码和数据可在 https://rlg.iis.sinica.edu.tw/papers/demystifying-muzero-planning 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [81] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
> *利用约束推理为混合整数线性规划构建图形解释*

*Roger Xavier Lera-Leri, Filippo Bistaffa, Athina Georgara, Juan Antonio Rodriguez-Aguilar* | **Category: cs.AI** | **Updated: 2025-07-17**

**Keywords:** 混合整数线性规划, 对比解释, 约束推理, 不可约不可行子系统, 原因图

**Comment:** To appear in Lecture Notes in Artificial Intelligence

> **TL;DR:** 本文提出了X-MILP，一种基于约束推理为混合整数线性规划（MILP）构建对比解释的领域无关方法，并将解释表示为“原因图”，以帮助用户理解解决方案背后的原因结构。

**AI_Comments:** 该论文的创新点在于将约束推理技术应用于为MILP生成图形化的对比解释，特别是利用不可约不可行子系统（IIS）来识别和组织解释的原因。通过将解释可视化为“原因图”，它提供了一种直观的方式来理解复杂的决策过程，这对于提升MILP解决方案的可信度和可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着对可信人工智能的推动，人们对优化领域开发对比解释技术的需求日益增长，特别是针对混合整数线性规划（MILP）形式化的特定决策过程的解决方案。

**Method:** 该方法首先将用户关于MILP问题解决方案的查询编码为附加约束。然后，通过计算新获得的约束集的不可约不可行子系统（IIS）来确定构成用户查询答案的原因。最后，将解释表示为从IIS构建的“原因图”，以帮助用户理解回答其查询的原因之间的结构。

**Result:** 该方法在知名优化问题的实例上进行了测试，以评估计算解释的经验难度。

**Conclusion:** 该论文提出了一种有效的方法，能够为混合整数线性规划（MILP）构建图形化的对比解释，并通过“原因图”帮助用户理解解决方案的原因结构。

> **ai_Abstract:** 本文提出了X-MILP，一种用于混合整数线性规划（MILP）的领域无关对比解释方法。该方法通过将用户查询转化为附加约束，利用不可约不可行子系统（IIS）识别原因，并最终将解释呈现为“原因图”，以帮助用户理解复杂优化问题解决方案背后的原因结构。研究还评估了该方法计算解释的经验难度。

> **摘要翻译:** 随着近期对可信人工智能的推动，对优化领域开发对比解释技术的需求日益增长，特别是在针对混合整数线性规划（MILP）形式化的特定决策过程的解决方案方面。沿着这些思路，我们提出了X-MILP，这是一种基于约束推理技术为MILP构建对比解释的领域无关方法。首先，我们展示了如何将用户对MILP问题解决方案的查询编码为附加约束。然后，通过计算新获得的约束集的不可约不可行子系统（IIS），我们确定构成用户查询答案的原因。最后，我们将解释表示为从IIS构建的“原因图”，这有助于用户理解回答其查询的原因之间的结构。我们在知名优化问题的实例上测试了我们的方法，以评估计算解释的经验难度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [109] [BEARCUBS: A benchmark for computer-using web agents](https://arxiv.org/abs/2503.07919)
> *BEARCUBS：一个面向计算机使用型网络代理的基准*

*Yixiao Song, Katherine Thai, Chau Minh Pham, Yapei Chang, Mazin Nadaf, Mohit Iyyer* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 网络代理, 基准测试, 计算机使用, 多模态交互, 信息检索

**Comment:** 16 pages

> **TL;DR:** BEARCUBS是一个新的基准测试，用于评估能够使用虚拟键盘和鼠标与网页交互的计算机使用型网络代理。它包含111个信息检索问题，需要访问实时网页内容并进行多模态交互。人类在该基准上表现良好（84.7%准确率），而最先进的代理表现不佳（23.4%准确率），突出了代理在可靠来源选择和多模态能力方面的改进需求。

**AI_Comments:** BEARCUBS的创新之处在于其强调实时网络内容和多模态交互，这比以往的基准测试更贴近真实世界的复杂性。这对于推动通用网络代理的发展至关重要。该基准的局限性可能在于问题数量相对有限，以及其维护和更新的持续性。

<details>
  <summary>Details</summary>

**Motivation:** 现代网络代理具有辅助人类用户完成复杂任务的巨大潜力，但评估其在真实世界环境中的能力面临重大挑战。为了解决这一问题，本研究引入了一个新的基准测试。

**Method:** 本研究引入了BEARCUBS，这是一个包含111个信息检索问题的基准测试，旨在评估网络代理搜索、浏览和识别网页事实信息的能力。BEARCUBS要求代理访问实时网络内容并执行广泛的多模态交互。每个问题都有明确的答案和人类验证的浏览轨迹。研究还进行了人类研究并测试了最先进的计算机使用代理。

**Result:** 人类研究证实BEARCUBS问题可解但并非微不足道（人类准确率为84.7%），并揭示了领域知识差距和被忽视的细节是常见的失败点。相比之下，最先进的计算机使用型代理表现不佳，得分最高的系统（OpenAI的Operator）仅达到23.4%的准确率。

**Conclusion:** BEARCUBS基准测试的结果突出了当前计算机使用型网络代理在可靠源选择和更强大的多模态能力方面需要改进的关键领域。该基准将定期更新以保持其有效性，以促进未来的研究。

> **ai_Abstract:** 本论文介绍了BEARCUBS，一个用于评估计算机使用型网络代理的新型基准测试。该基准包含111个信息检索问题，要求代理与实时网页内容进行多模态交互，以捕捉真实世界的复杂性。通过人类研究和最先进代理的测试，发现人类准确率达到84.7%，而顶级代理仅为23.4%，表明代理在处理实时网络、多模态理解和可靠信息源选择方面存在显著差距。BEARCUBS旨在推动网络代理能力的发展，并将定期更新。

> **摘要翻译:** 现代网络代理具备计算机使用能力，允许它们通过向虚拟键盘和鼠标发送命令来与网页交互。虽然此类代理在协助人类用户完成复杂任务方面具有巨大潜力，但在真实世界环境中评估其能力面临重大挑战。为此，我们引入了BEARCUBS，一个“小而强大”的基准测试，包含111个信息检索问题，旨在评估网络代理从网络搜索、浏览和识别事实信息的能力。与之前的网络代理基准测试不同，解决BEARCUBS需要：(1) 访问实时网络内容而非合成或模拟页面，这捕捉了真实世界网络交互的不可预测性；以及 (2) 执行广泛的多模态交互（例如，视频理解、3D导航），这些交互无法通过基于文本的变通方法绕过。BEARCUBS中的每个问题都有对应的简短、明确的答案和人类验证的浏览轨迹，从而可以透明地评估代理的性能和策略。一项人类研究证实BEARCUBS问题可解但并非微不足道（84.7%的人类准确率），揭示了领域知识差距和被忽视的细节是常见的失败点。相比之下，最先进的计算机使用型代理表现不佳，得分最高的系统（OpenAI的Operator）仅达到23.4%的准确率。这些结果突出了关键的改进领域，包括可靠的源选择和更强大的多模态能力。为了促进未来的研究，BEARCUBS将定期更新以替换无效或被污染的问题，从而使该基准对未来几代网络代理保持新鲜。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [111] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
> *基于人工智能算法利用加州交通数据进行高速公路交通流量预测*

*Junseong Lee, Jaegwan Cho, Yoonju Cho, Seoyoon Choi, Yejin Shin* | **Category: cs.AI** | **Updated: 2025-07-17**

**Keywords:** 交通流量预测, 人工智能, 机器学习, 多元线性回归, 随机森林

**Comment:** 

> **TL;DR:** 本研究利用机器学习算法（MLR和RF）对加州高速公路交通数据进行交通流量预测，发现10分钟数据采集间隔时模型性能最佳。

**AI_Comments:** 本研究的创新之处在于其对特定区域（加州78号高速公路）交通数据的详细分析，并系统地比较了MLR和RF两种常用机器学习算法在不同时间粒度下的表现。发现10分钟数据采集间隔为最佳，为实际应用提供了具体的指导。其重要性在于为缓解交通拥堵提供了数据驱动的预测工具，有助于提升交通管理效率。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过建立基于机器学习的交通流量预测模型，解决全球交通拥堵问题。

**Method:** 研究使用了2022年7月至11月期间加州78号高速公路7.24公里西行路段的30秒间隔交通数据。研究采用了多元线性回归（MLR）和随机森林（RF）算法，并分析了30秒至15分钟的数据采集间隔。性能指标包括R^2、MAE和RMSE。

**Result:** 分析显示，MLR和RF模型在10分钟数据采集间隔时表现最佳。

**Conclusion:** 研究结果有望为未来的交通拥堵解决方案和高效交通管理做出贡献。

> **ai_Abstract:** 本研究提出了一种基于机器学习的交通流量预测模型，旨在缓解全球交通拥堵。通过分析2022年7月至11月加州78号高速公路的交通数据，研究比较了多元线性回归（MLR）和随机森林（RF）算法在不同数据采集间隔下的性能。结果表明，MLR和RF模型在10分钟数据采集间隔时性能最优，为未来的交通管理提供了有价值的见解。

> **摘要翻译:** 题为“基于人工智能算法利用加州交通数据进行高速公路交通流量预测”的研究提出了一种基于机器学习的交通流量预测模型，以解决全球交通拥堵问题。该研究利用了2022年7月至11月期间加州78号高速公路（圣地亚哥地区“Melrose Dr”和“El-Camino Real”之间7.24公里西行路段）为期五个月的30秒间隔交通数据。研究采用了多元线性回归（MLR）和随机森林（RF）算法，分析了从30秒到15分钟不等的数据采集间隔。使用R^2、MAE和RMSE作为性能指标，分析表明MLR和RF模型在10分钟数据采集间隔时表现最佳。这些发现有望为未来的交通拥堵解决方案和高效交通管理做出贡献。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [151] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
> *从根源到奖励：基于强化学习的动态树状推理*

*Ahmed Bahloul, Simon Malberg* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 动态树状推理, 强化学习, 概率思维树, 语言模型, 问答系统

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的动态树状推理框架，通过实时置信度估计和学习最优策略来增量构建推理树，解决了现有方法在错误传播、知识集成以及静态树结构和计算效率方面的问题，提高了解决方案质量和计算效率。

**AI_Comments:** 这项工作的主要创新在于将强化学习引入树状推理，使其能够动态适应中间结果并优化资源分配。通过解决ProbTree的静态性和计算效率问题，该方法为构建更鲁棒、高效的问答系统奠定了基础。其重要性在于提供了一种更灵活、自适应的推理范式，有望在复杂推理任务中取得更好的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现代语言模型在链式思考（CoT）推理和检索增强方面存在错误传播和知识集成问题。虽然概率思维树（ProbTree）框架通过层次结构和置信度加权聚合缓解了这些问题，但其静态实现导致了两个主要限制：推理树在初始构建阶段是固定的，无法动态适应中间结果；每个节点都需要穷尽评估所有可能的解决方案策略，导致计算效率低下。

**Method:** 本文提出了一种动态强化学习（RL）框架，将基于树的推理转化为自适应过程。该方法根据实时置信度估计增量构建推理树，同时学习动作选择（分解、检索或聚合）的最优策略。

**Result:** 该方法在保持ProbTree概率严谨性的同时，通过选择性扩展和集中资源分配，提高了解决方案质量和计算效率。

**Conclusion:** 这项工作为树状推理建立了一个新范式，平衡了概率框架的可靠性与真实世界问答系统所需的灵活性。

> **ai_Abstract:** 本文针对现有语言模型在复杂问答中面临的错误传播、知识集成以及概率思维树（ProbTree）静态结构的局限性（固定推理树、低效的穷尽评估），提出了一种基于强化学习的动态树状推理框架。该方法能够根据实时置信度增量构建推理树，并学习最优的动作选择策略（分解、检索、聚合），从而在保持ProbTree概率严谨性的同时，显著提升了解决方案质量和计算效率，为树状推理提供了一个兼顾可靠性和灵活性的新范式。

> **摘要翻译:** 现代语言模型通过链式思考（CoT）推理和检索增强解决复杂问题，但仍面临错误传播和知识集成的问题。树状推理方法，特别是概率思维树（ProbTree）框架，通过将问题分解为层次结构，并通过参数化和检索知识的置信度加权聚合来选择答案，从而缓解了这些问题。然而，ProbTree的静态实现引入了两个关键限制：（1）推理树在初始构建阶段是固定的，无法动态适应中间结果；（2）每个节点都需要穷尽评估所有可能的解决方案策略，造成计算效率低下。我们提出了一种动态强化学习框架，将基于树的推理转化为自适应过程。我们的方法根据实时置信度估计增量构建推理树，同时学习动作选择（分解、检索或聚合）的最优策略。这在保持ProbTree概率严谨性的同时，通过选择性扩展和集中资源分配，提高了解决方案质量和计算效率。这项工作为树状推理建立了一个新范式，平衡了概率框架的可靠性与真实世界问答系统所需的灵活性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [160] [ActionStudio: A Lightweight Framework for Data and Training of Large Action Models](https://arxiv.org/abs/2503.22673)
> *ActionStudio：一个用于大型动作模型数据和训练的轻量级框架*

*Jianguo Zhang, Thai Hoang, Ming Zhu, Zuxin Liu, Shiyu Wang, Tulika Awalgaonkar, Akshara Prabhakar, Haolin Chen, Weiran Yao, Zhiwei Liu, Juntao Tan, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型动作模型, 数据训练框架, ActionStudio, 统一数据格式, 分布式训练

**Comment:** 16 pages; large action models; xLAM; ActionStudio

> **TL;DR:** ActionStudio是一个轻量级框架，旨在解决大型动作模型训练中的数据多样性和复杂性挑战，显著提高了训练效率和模型性能，并已开源。

**AI_Comments:** ActionStudio的创新之处在于其统一数据格式（Unified Format 2.0）和优化的分布式训练能力，这对于处理大规模、多样化的代理数据至关重要。其高达9倍的吞吐量提升显示了其在效率上的显著优势。通过开源框架和高质量数据集，该工作对推动大型动作模型的研究和应用具有重要意义，降低了研究人员的进入门槛。

<details>
  <summary>Details</summary>

**Motivation:** 大型动作模型对于使自主代理执行复杂任务至关重要。然而，由于代理环境的多样性和嘈杂代理数据的复杂性，训练此类模型仍然具有挑战性。现有基础设施对可扩展的、特定于代理的微调和标准化的代理数据处理支持有限。

**Method:** 我们引入了ActionStudio，一个为大型动作模型设计的轻量级、可扩展的数据和训练框架。ActionStudio使用我们提出的Unified Format 2.0统一了不同的代理轨迹，支持一系列具有优化多节点分布式设置的训练工作流程，并集成了强大的预处理和实时验证工具。

**Result:** ActionStudio与现有代理训练框架相比，吞吐量提高了9倍；我们训练的模型在公共和现实代理基准测试中取得了最佳性能。为了支持更广泛的研究社区，我们开源了ActionStudio框架并发布了actionstudio-98k，一个包含9.8万条高质量轨迹的精选数据集。

**Conclusion:** ActionStudio通过提供一个高效、可扩展且开源的框架，显著简化了大型动作模型的训练过程，并提升了模型性能，从而促进了自主代理技术的发展。

> **ai_Abstract:** 本文介绍了ActionStudio，一个专门为大型动作模型设计的数据和训练框架，旨在解决现有方法在处理多样化和复杂代理数据时的局限性。ActionStudio通过引入统一数据格式、优化分布式训练和集成数据处理工具，显著提高了训练吞吐量和模型性能。为促进研究，该框架及其包含9.8万条高质量轨迹的数据集已开源。

> **摘要翻译:** 大型动作模型对于使自主代理执行复杂任务至关重要。然而，由于代理环境的多样性和嘈杂代理数据的复杂性，训练此类模型仍然具有挑战性。现有基础设施对可扩展的、特定于代理的微调和标准化的代理数据处理支持有限。我们引入了ActionStudio，一个为大型动作模型设计的轻量级、可扩展的数据和训练框架。ActionStudio使用我们提出的Unified Format 2.0统一了不同的代理轨迹，支持一系列具有优化多节点分布式设置的训练工作流程，并集成了强大的预处理和实时验证工具。ActionStudio与现有代理训练框架相比，吞吐量提高了9倍，我们训练的模型在公共和现实代理基准测试中取得了最佳性能。为了支持更广泛的研究社区，我们开源了ActionStudio框架并发布了actionstudio-98k，一个包含9.8万条高质量轨迹的精选数据集。代码：https://github.com/SalesforceAIResearch/xLAM。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [193] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
> *黑箱部署——LLM时代下人工道德代理的功能性判准*

*Matthew E. Brophy* | **Category: cs.AI, 68T27, 03B42 68T27, 03B4268T27, 03B42 68T27, 03B42 68T27, 03B42
  68T27, 03B42 68T27, 03B42 68T27, 03B4268T27, 03B42, I.2.0; I.2.9; K.4.1** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 人工道德代理, 伦理评估, 功能性标准, 黑箱

**Comment:** 42 pages. Supplementary material included at end of article

> **TL;DR:** 鉴于大型语言模型（LLMs）的不透明性，传统的人工道德代理（AMAs）评估标准已过时。本文提出了十项新的功能性标准，旨在指导基于LLM的AMAs实现更好的对齐和融入社会。

**AI_Comments:** 这篇论文的创新之处在于它直面了大型语言模型（LLMs）“黑箱”特性对人工道德代理（AMAs）伦理评估的根本性挑战。它没有试图打开黑箱，而是转而提出了基于“功能性”而非“内部机制”的评估标准，这在实用性和可操作性上具有重要意义。提出的十项标准全面且具有前瞻性，为未来LLM伦理对齐提供了具体方向。

<details>
  <summary>Details</summary>

**Motivation:** 强大的大型语言模型（LLMs）虽然功能强大但缺乏透明度，使得评估人工道德代理（AMAs）的哲学标准需要进行根本性修订。传统的框架依赖于透明架构的假设，而LLMs的随机输出和不透明内部状态打破了这一假设，导致传统伦理标准在LLM时代不再实用。

**Method:** 本文提出了一套修订后的十项功能性标准，用于评估基于大型语言模型的人工道德代理。这些标准通过涉及自动驾驶公交车的假设场景进行阐释，以展示其在道德相关情境中的实际适用性。

**Result:** 本文提出了十项新的功能性标准来评估基于LLM的人工道德代理：道德一致性、情境敏感性、规范完整性、元伦理意识、系统弹性、可信赖性、可纠正性、部分透明性、功能自主性和道德想象力。

**Conclusion:** 本文提出的功能性标准旨在引导人工道德代理（AMAs），特别是通过大型语言系统模拟道德代理（SMA-LLS），实现更好的对齐和有益的社会整合。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）的不透明性对人工道德代理（AMAs）评估带来的挑战，指出传统评估标准已不适用。作者提出了一套包含十项功能性标准的新框架，用以评估基于LLM的AMAs，包括道德一致性、可信赖性等。这些标准旨在指导LLM驱动的AMAs更好地融入社会，并通过自动驾驶公交车的假设场景进行了示例。

> **摘要翻译:** 强大的、不透明的大型语言模型（LLMs）的进步，使得评估人工道德代理（AMAs）所用的哲学标准需要进行根本性修订。LLM之前的框架通常依赖于透明架构的假设，而LLMs由于其随机输出和不透明的内部状态而打破了这一假设。本文认为，由于这种不匹配，传统的伦理标准对LLMs来说在实践上已经过时。本文结合技术哲学的核心主题，提出了一套修订后的十项功能性标准来评估基于LLM的人工道德代理：道德一致性、情境敏感性、规范完整性、元伦理意识、系统弹性、可信赖性、可纠正性、部分透明性、功能自主性和道德想象力。这些指导原则，应用于我们称之为“SMA-LLS”（通过大型语言系统模拟道德代理）的系统，旨在未来几年引导AMAs实现更好的对齐和有益的社会整合。我们使用涉及自动驾驶公交车（APB）的假设场景来阐释这些标准，以证明它们在道德突出情境中的实际适用性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [198] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
> *错位AI的操纵攻击：风险分析与安全案例框架*

*Rishane Dassanayake, Mario Demetroudi, James Walpole, Lindley Lentati, Jason R. Brown, Edward James Young* | **Category: cs.AI, cs.CR, cs.HC** | **Updated: 2025-07-17**

**Keywords:** 错位AI, 操纵攻击, 风险分析, 安全案例框架, AI安全治理

**Comment:** 24 pages (14 pages main text, 4 pages bibliography, 6 pages
  appendices), 3 figures

> **TL;DR:** 本文分析了错位AI对人类的操纵攻击风险，并提出了一个评估和缓解此类风险的安全案例框架。

**AI_Comments:** 这篇论文在AI安全领域具有重要意义，它首次系统地关注了“操纵攻击”这一新兴且被忽视的威胁。其提出的安全案例框架为AI公司提供了一个实用的工具，有助于在AI部署前识别和缓解潜在的灾难性风险，对于促进负责任的AI发展具有前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 前沿AI系统在说服、欺骗和影响人类行为方面的能力迅速增强，现有模型已展现出人类水平的操纵能力。人类是网络安全系统中的薄弱环节，错位AI可能通过操纵员工来破坏人类监督。然而，操纵攻击受到的关注不足，且缺乏系统的风险评估和缓解框架。

**Method:** 本文详细解释了操纵攻击为何是重大威胁，并提出了一个针对操纵风险的安全案例框架。该框架围绕“无能力、控制、可信度”三个核心论点构建，并为每个论点规定了证据要求、评估方法和实施考虑，旨在供AI公司直接应用。

**Result:** 本文提出了第一个将操纵风险整合到AI安全治理中的系统方法，为AI公司在部署前评估和缓解这些威胁提供了具体基础。

**Conclusion:** 本文首次提供了系统方法，将操纵风险纳入AI安全治理，为AI公司提供了评估和缓解此类威胁的具体基础。

> **ai_Abstract:** 本文探讨了前沿AI系统对人类进行操纵攻击的风险，指出其可能通过影响员工来规避人类监督。鉴于当前缺乏系统性的风险评估和缓解框架，作者详细阐述了操纵攻击的潜在灾难性后果。为此，论文提出了一个创新的安全案例框架，该框架以“无能力、控制、可信度”为核心论点，并为每个论点提供了具体的证据要求、评估方法和实施建议，旨在为AI公司提供一套系统化的方法来整合和管理操纵风险。

> **摘要翻译:** 前沿AI系统在说服、欺骗和影响人类行为方面的能力正在迅速提升，现有模型已在特定情境中展现出人类水平的说服力和战略性欺骗能力。人类常常是网络安全系统中最薄弱的环节，部署在前沿公司内部的错位AI系统可能会通过操纵员工来破坏人类监督。尽管这种威胁日益增长，但操纵攻击受到的关注甚少，并且目前尚无系统框架来评估和缓解这些风险。为了解决这个问题，我们详细解释了为什么操纵攻击是一个重大威胁，并可能导致灾难性后果。此外，我们提出了一个针对操纵风险的安全案例框架，该框架围绕三个核心论点构建：无能力、控制和可信度。对于每个论点，我们都明确了证据要求、评估方法和实施考虑，以便AI公司直接应用。本文提供了第一个将操纵风险整合到AI安全治理中的系统方法，为AI公司在部署前评估和缓解这些威胁提供了具体基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [208] [Judging with Many Minds: Do More Perspectives Mean Less Prejudice? On Bias Amplifications and Resistance in Multi-Agent Based LLM-as-Judge](https://arxiv.org/abs/2505.19477)
> *集思广益：更多视角是否意味着更少偏见？关于多智能体LLM作为评判中偏见的放大与抵抗*

*Chiyu Ma, Enpei Zhang, Yilun Zhao, Wenjun Liu, Yaning Jia, Peijun Qing, Lin Shi, Arman Cohan, Yujun Yan, Soroush Vosoughi* | **Category: cs.AI** | **Updated: 2025-07-16**

**Keywords:** LLM作为评判, 多智能体系统, 偏见放大, 偏见抵抗, 去偏见策略

**Comment:** 

> **TL;DR:** 研究发现，多智能体LLM作为评判时，辩论框架会放大偏见，而元评判方法更具抵抗力；引入去偏见智能体能有效减少辩论设置中的偏见。

**AI_Comments:** 这篇论文创新性地探讨了多智能体LLM作为评判系统中的偏见问题，并对比了不同框架（辩论与元评判）对偏见的影响。其重要性在于揭示了多智能体交互可能放大而非减少偏见，这与直觉相反。同时，论文也提出了通过引入去偏见智能体来缓解偏见的潜在方法。这项研究对于理解和改进LLM在评估任务中的公平性和鲁棒性具有重要指导意义，尤其是在LLM广泛应用于决策和评估场景的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 尽管LLM作为评判已成为人类评估的可扩展替代方案，并且多智能体扩展（如多智能体辩论和元评判）已用于提高评估质量，但内在偏见在这些设置中如何体现的问题仍未得到充分探索。

**Method:** 本研究对四种不同的偏见类型（位置偏见、冗长偏见、思维链偏见和从众偏见）进行了系统分析。研究在两种广泛采用的多智能体LLM作为评判框架（多智能体辩论和LLM作为元评判）中评估了这些偏见。此外，研究还探讨了将PINE（一种领先的单智能体去偏见方法）作为无偏见智能体引入这些系统中的效果。

**Result:** 辩论框架在初始辩论后会急剧放大偏见，并且这种增加的偏见在后续轮次中持续存在，而元评判方法则表现出更大的抵抗力。将无偏见智能体（PINE）引入辩论设置能有效减少偏见，但在元评判场景中效果不明显。

**Conclusion:** 本研究全面分析了多智能体LLM作为评判系统中的偏见行为，并强调了在协作评估设置中需要有针对性的偏见缓解策略。

> **ai_Abstract:** 本研究系统分析了多智能体LLM作为评判系统中的内在偏见，特别关注了辩论框架和元评判框架下的偏见放大与抵抗。研究发现，辩论框架倾向于放大偏见，而元评判框架表现出更强的偏见抵抗力。此外，引入去偏见智能体（如PINE）能有效减轻辩论设置中的偏见。本工作强调了在多智能体协作评估中制定有针对性偏见缓解策略的重要性。

> **摘要翻译:** LLM作为评判已成为人类评估的一种可扩展替代方案，使大型语言模型（LLM）能够在训练中提供奖励信号。尽管最近的工作探索了多智能体扩展，例如多智能体辩论和元评判，以提高评估质量，但内在偏见在这些设置中如何体现的问题仍未得到充分探索。在本研究中，我们对四种不同的偏见类型进行了系统分析：位置偏见、冗长偏见、思维链偏见和从众偏见。我们评估了这两种广泛采用的多智能体LLM作为评判框架中的偏见：多智能体辩论和LLM作为元评判。我们的结果表明，辩论框架在初始辩论后会急剧放大偏见，并且这种增加的偏见在后续轮次中持续存在，而元评判方法则表现出更大的抵抗力。我们进一步研究了将PINE（一种领先的单智能体去偏见方法）作为无偏见智能体整合到这些系统中。结果显示，这种无偏见智能体能有效减少辩论设置中的偏见，但在元评判场景中带来的益处较少。我们的工作全面研究了多智能体LLM作为评判系统中的偏见行为，并强调了在协作评估设置中需要有针对性的偏见缓解策略。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [222] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
> *AI驱动的数学辅导：个性化和自适应教育平台*

*Jarosław A. Chudziak, Adam Kostka* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-14**

**Keywords:** AI辅导, 个性化教育, 自适应学习, 数学, 多智能体系统

**Comment:** 8 pages, 5 figures

> **TL;DR:** 本文介绍了一个新颖的多智能体AI辅导平台，旨在克服现有AI辅导系统在数学领域反应式、缺乏深度反思和结构化教学工具的局限性，提供个性化、自适应、工具辅助的模块化学习体验。

**AI_Comments:** 该论文提出了一种创新的多智能体AI辅导平台，旨在解决当前AI辅导系统在数学领域存在的痛点，即过于被动且缺乏结构化教学。其结合自适应反馈、课程生成和知识检索的模块化方法，有望显著提升个性化学习体验，对AI教育领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人工智能（AI）和大型语言模型（LLMs）的普及改变了学习方式，但当前的AI辅导系统面临局限性，它们通常提供直接答案，而不鼓励深度反思或整合结构化教学工具。这一问题在数学领域尤为突出，现有AI辅导系统在该领域发展不足。本研究旨在解决如何使AI辅导系统超越反应式辅助，实现结构化、个性化和工具辅助的学习体验。

**Method:** 本文介绍了一个新颖的多智能体AI辅导平台，该平台结合了自适应和个性化反馈、结构化课程生成以及教科书知识检索，以实现模块化、工具辅助的学习过程。

**Result:** 该系统允许学生在学习新主题的同时识别并针对其弱点，有效复习考试，并进行无限量个性化练习。

**Conclusion:** 本文通过引入一个结合了教学智能体和AI驱动组件的新颖平台，为教育领域的人工智能做出了贡献，为数学教学领域带来了模块化且高效的系统。

> **ai_Abstract:** 本文针对当前AI辅导系统在数学领域存在的局限性（即反应式、缺乏深度反思和结构化教学），提出了一种新颖的多智能体AI辅导平台。该平台通过整合自适应个性化反馈、结构化课程生成和教科书知识检索，旨在提供模块化、工具辅助的学习体验。该系统能帮助学生学习新知识、识别弱点、有效备考并进行个性化练习，从而为教育AI领域特别是数学教学带来了创新且高效的解决方案。

> **摘要翻译:** 人工智能（AI），特别是大型语言模型（LLMs）日益普及，深刻改变了学习者获取知识和与学习材料互动的方式，许多人声称AI积极影响了他们的学习成果。尽管取得了这一进展，但当前的AI辅导系统面临其反应性性质相关的局限性，通常提供直接答案，而不鼓励深度反思或整合结构化教学工具和策略。这种局限性在数学领域最为明显，在该领域AI辅导系统仍不发达。本研究旨在解决以下问题：AI辅导系统如何超越提供反应性帮助，从而实现结构化、个性化和工具辅助的学习体验？我们引入了一个新颖的多智能体AI辅导平台，该平台结合了自适应和个性化反馈、结构化课程生成和教科书知识检索，以实现模块化、工具辅助的学习过程。该系统允许学生在学习新主题的同时识别并针对其弱点，有效复习考试，并进行无限量个性化练习。本文通过引入一个结合了教学智能体和AI驱动组件的新颖平台，为教育领域的人工智能做出了贡献，为数学教学领域带来了模块化且高效的系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [234] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
> *MR-LDM -- 合并反应式纵向决策模型：交互式模拟智能体的博弈论人类决策建模*

*Dustin Holley, Jovin D'sa, Hossein Nourkhiz Mahjoub, Gibran Ali* | **Category: cs.AI, cs.GT, cs.MA, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 博弈论, 驾驶行为模拟, 自动驾驶, 高速公路合并, 决策模型

**Comment:** 8 pages

> **TL;DR:** 本文提出了一种名为MR-LDM的博弈论模型，用于模拟高速公路合并场景中更真实的人类驾驶员行为，该模型在真实数据上表现出良好的可复现性和计算效率，适用于自动驾驶开发。

**AI_Comments:** 该论文的创新点在于提出了一个统一的博弈论决策与动力学模型，用于模拟高速公路合并场景中的人类驾驶行为，解决了现有战术决策模型在行动集和收益函数上的局限性。其重要性在于为自动驾驶技术开发提供了更真实、可解释且计算高效的模拟智能体，有助于提高自动驾驶系统的开发和测试效率。

<details>
  <summary>Details</summary>

**Motivation:** 增强模拟环境以复制真实世界的驾驶员行为（即更像人类的模拟智能体）对于开发自动驾驶技术至关重要。现有战术决策模型存在行动集有限或收益函数参数多且收益边界有限的问题。

**Method:** 本文提出了一种针对战术决策的博弈论模型，该模型改进了收益函数和滞后车辆行为，并将其与底层动力学模型相结合，形成了一个统一的决策和动力学模型。

**Result:** 所提出的模型在真实世界数据集上验证时，展示了对复杂交互的良好可复现性。该模型最终被集成到高保真模拟环境中，并确认具有足够的计算时间效率，可用于大规模模拟以支持自动驾驶车辆开发。

**Conclusion:** 该模型能够捕捉合并交互并以可解释和可理解的方式模拟更真实的交互，且计算效率高，适用于大规模自动驾驶模拟。

> **ai_Abstract:** 本文提出了MR-LDM，一个博弈论的纵向决策模型，旨在改进高速公路合并场景中人类驾驶员行为的模拟。该模型结合了改进的收益函数和滞后车辆行为，并与底层动力学模型统一，以实现可解释的真实交互模拟。实验结果表明，该模型在真实数据集上对复杂交互具有良好的可复现性，且计算效率高，适用于大规模自动驾驶模拟。

> **摘要翻译:** 增强模拟环境以复制真实世界的驾驶员行为，即更像人类的模拟智能体，对于开发自动驾驶技术至关重要。在高速公路合并的背景下，以前的工作研究了高速公路匝道处滞后车辆对合并车辆的操纵级让行动态。其他侧重于战术决策建模的工作通常考虑有限的行动集或使用具有大量参数集和有限收益边界的收益函数。在这项工作中，我们旨在通过针对具有改进收益函数和滞后行动的战术决策的博弈论模型来改进高速公路合并场景的模拟。我们将此与底层动力学模型相结合，形成一个统一的决策和动力学模型，可以捕捉合并交互并以可解释和可理解的方式模拟更真实的交互。所提出的模型在真实世界数据集上验证时，展示了对复杂交互的良好可复现性。该模型最终被集成到高保真模拟环境中，并确认具有足够的计算时间效率，可用于大规模模拟以支持自动驾驶车辆开发。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [235] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
> *高阶模式合一模相似关系*

*Besik Dundua, Temur Kutsia* | **Category: cs.AI, cs.LO, math.LO, 03B70 (Primary) 68T37, 68T27, 68Q42, 03B40, 68V15 (Secondary), F.4.1; I.2.3** | **Updated: 2025-07-17**

**Keywords:** 高阶模式, 模糊逻辑, 合一, 相似关系, T-范数

**Comment:** 23 pages

> **TL;DR:** 本文提出了一种用于高阶模式模相似关系的合一算法，并证明了其终止性、完备性和可靠性，解决了高阶理论与模糊逻辑结合中的合一问题。

**AI_Comments:** 该论文的创新点在于将高阶模式合一与模糊逻辑中的相似关系相结合，解决了在不要求精确匹配的抽象推理场景中的合一问题。其重要性在于为模糊推理和高阶理论的交叉领域提供了一个坚实的计算基础，尤其是在决策支持系统中可能具有实际应用价值。算法的终止性、可靠性和完备性证明增强了其理论严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 在涉及抽象函数和谓词的决策任务中，精确匹配往往很少或不必要，将高阶理论与模糊逻辑结合起来非常有用。然而，为这种结合形式开发高效的推理和计算技术是一个重大挑战。

**Method:** 本文采用了一种直接的方法，将两个成熟且计算性能良好的组件结合起来：高阶模式和基于最小T-范数的相似关系表示的模糊等价。作者提出了一种针对高阶模式模这些相似关系的合一算法。

**Result:** 该算法被证明是终止的、可靠的、完备的。与清晰的对应物一样，这个合一问题是单一的。当给定项是可合一的时，该算法能计算出具有最高近似度的最通用合一器。

**Conclusion:** 本文成功提出了并验证了一种用于高阶模式模相似关系的合一算法，有效结合了高阶模式与模糊等价，为相关决策任务提供了新的计算工具。

> **ai_Abstract:** 本文针对高阶理论与模糊逻辑结合在决策任务中的应用，提出了一个创新的合一方法。通过整合高阶模式和基于最小T-范数的相似关系，作者设计并验证了一种新的高阶模式模相似关系合一算法。该算法被证明具有终止性、可靠性和完备性，并且像其清晰对应物一样是单一的，能够在项可合一时计算出具有最高近似度的最通用合一器，为处理非精确匹配的抽象推理问题提供了有效工具。

> **摘要翻译:** 高阶模式合一模相似关系

将高阶理论与模糊逻辑相结合，在涉及抽象函数和谓词的决策任务中非常有用，因为在这些任务中，精确匹配往往很少发生或没有必要。为这种结合形式开发高效的推理和计算技术提出了重大挑战。在本文中，我们采用了一种更直接的方法，旨在整合两个成熟且计算行为良好的组件：一方面是高阶模式，另一方面是通过基于最小T-范数的相似关系表达的模糊等价。我们提出了一种针对高阶模式模这些相似关系的合一算法，并证明了其终止性、可靠性和完备性。这个合一问题，就像它的清晰对应物一样，是单一的。当给定项是可合一时，该算法会计算出具有最高近似度的最通用合一器。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [255] [NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons](https://arxiv.org/abs/2506.19530)
> *NTRL：基于强化学习的遭遇战生成，用于《龙与地下城》中的动态难度调整*

*Carlo Romeo, Andrew D. Bagdanov* | **Category: cs.AI** | **Updated: 2025-07-16**

**Keywords:** 强化学习, 动态难度调整, 龙与地下城, 遭遇战生成, 上下文强盗

**Comment:** 

> **TL;DR:** NTRL利用强化学习自动化《龙与地下城》中的遭遇战生成，通过动态难度调整提升战斗的策略深度和挑战性。

**AI_Comments:** NTRL的创新点在于将强化学习应用于《龙与地下城》的动态难度调整，解决了DM手动平衡遭遇战的复杂性问题。其重要性在于能够自动化并优化游戏体验，使战斗更具策略性和挑战性，同时保持公平性，这对于提升玩家沉浸感和游戏寿命具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 《龙与地下城》（D&D）中的战斗遭遇平衡是一项复杂任务，地牢大师（DM）需要手动评估队伍实力、敌人组成和动态玩家互动，同时避免打断叙事流程。本文旨在通过自动化动态难度调整（DDA）来解决这一挑战。

**Method:** 本文提出了一种名为“通过强化学习生成遭遇战”（NTRL）的新方法，通过将问题建模为上下文强盗（contextual bandit）来自动化D&D中的动态难度调整。NTRL根据实时队伍成员属性生成遭遇战。

**Result:** 与经典DM启发式方法相比，NTRL迭代优化遭遇战，显著延长了战斗持续时间（+200%），增加了对队伍成员造成的伤害，减少了战后生命值（-16.67%），并提高了玩家死亡人数，同时保持了较低的团队全灭（TPK）率。生成的遭遇战保证了高胜率（70%），即使与人类地牢大师设计的遭遇战相比，NTRL也通过增强战斗的策略深度和增加难度，同时保持整体游戏公平性，展示了卓越的性能。

**Conclusion:** NTRL通过强化学习自动化了《龙与地下城》中的动态难度调整，成功地生成了更具挑战性和策略深度的遭遇战，同时保持了游戏公平性，并超越了传统DM启发式方法和人类DM的表现。

> **ai_Abstract:** 本文提出了NTRL（通过强化学习生成遭遇战），一种利用强化学习和上下文强盗模型，自动化《龙与地下城》中动态难度调整的新方法。NTRL根据实时队伍属性生成遭遇战，与传统DM启发式方法相比，它能显著延长战斗时间，增加伤害，提高玩家死亡率，同时维持低TPK率和高胜率。研究表明，NTRL在提升战斗策略深度和挑战性方面表现优异，甚至超越了人类DM的设计，同时确保了游戏的公平性。

> **摘要翻译:** 在《龙与地下城》（D&D）中平衡战斗遭遇是一项复杂的任务，需要地牢大师（DM）手动评估队伍实力、敌人组成和动态玩家互动，同时避免打断叙事流程。在本文中，我们提出了一种名为“通过强化学习生成遭遇战”（NTRL）的新方法，它通过战斗遭遇设计自动化D&D中的动态难度调整（DDA）。通过将问题建模为上下文强盗，NTRL根据实时队伍成员属性生成遭遇战。与经典的DM启发式方法相比，NTRL迭代优化遭遇战，以延长战斗持续时间（+200%），增加对队伍成员造成的伤害，减少战后生命值（-16.67%），并提高玩家死亡人数，同时保持较低的团队全灭（TPK）率。战斗的加剧迫使玩家明智行动并进行战术机动，即使生成的遭遇战保证了高胜率（70%）。即使与人类地牢大师设计的遭遇战相比，NTRL也通过增强战斗的策略深度和增加难度，同时保持整体游戏公平性，展示了卓越的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [259] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
> *可解释强化学习综述：目标、方法与需求*

*Léo Saulières* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 可解释强化学习, 综述, XAI, 分类法, 强化学习

**Comment:** 69 pages, 19 figures

> **TL;DR:** 本文对可解释强化学习（XRL）领域进行了全面综述，提出了一个基于“什么”和“如何”的分类法，并识别了该领域的未来需求。

**AI_Comments:** 这篇综述论文的重要性在于它系统地梳理了可解释强化学习这一新兴且关键的领域。通过提出一个清晰的分类法，它为理解和组织现有研究提供了一个有用的框架。对大量文献的综述以及对未来需求的识别，对于指导该领域的研究方向具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 近期人工智能（AI）模型（特别是深度神经网络）的成功伴随着其内部机制的不透明性。为了理解这些内部机制并解释AI模型的输出，需要可解释性方法，特别是针对通过强化学习学习的智能体行动的解释。

**Method:** 本文提出了一种基于“什么”（解释目标）和“如何”（解释方式）这两个问题的直观分类法。利用此分类法，对超过250篇论文进行了最先进的综述。

**Result:** 提出了一个可解释强化学习的直观分类法，并基于此对250多篇论文进行了系统性综述。此外，还介绍了与XRL相关的邻近领域，并指出了XRL领域的一些关键需求。

**Conclusion:** 本文识别了可解释强化学习领域的一些关键需求，并提出了应引起社区关注的相关领域。

> **ai_Abstract:** 本文对可解释强化学习（XRL）领域进行了全面综述，旨在解决AI模型（特别是强化学习代理）内部机制的不透明性问题。作者提出了一种基于“解释什么”和“如何解释”的直观分类法，并以此为框架，对超过250篇相关论文进行了系统性回顾。此外，论文还指出了与XRL邻近的、值得关注的领域，并明确了该领域未来的发展需求。

> **摘要翻译:** 近期人工智能（AI）模型的成功伴随着其内部机制的不透明性，这主要归因于深度神经网络的使用。为了理解这些内部机制并解释这些AI模型的输出，人们提出了一系列方法，统称为可解释人工智能（XAI）领域。本文重点关注XAI的一个子领域，即可解释强化学习（XRL），其旨在解释通过强化学习学习的智能体的行动。我们提出了一个基于“什么”和“如何”这两个问题的直观分类法。第一个问题侧重于方法所解释的目标，而第二个问题则与解释的提供方式相关。我们使用此分类法对超过250篇论文进行了最先进的综述。此外，我们还提出了一些与XRL紧密相关的领域，我们认为这些领域应该引起社区的关注。最后，我们识别了XRL领域的一些需求。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [268] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
> *模仿学习伙伴AI智能体中的错误以进行在线同伴学习*

*Sosui Moribe, Taketoshi Ushiama* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-17**

**Keywords:** AI智能体, 同伴学习, 学习伙伴, 模仿错误, 英语写作

**Comment:** This is the preprint version of the paper published in IMCOM 2025,
  IEEE Xplore (DOI: 10.1109/IMCOM64595.2025.10857528)

> **TL;DR:** 开发一个AI学习伙伴，通过模仿相同水平学习者的错误来促进在线同伴学习，以英语写作为例。

**AI_Comments:** 本文提出了一种新颖的AI学习伙伴设计思路，通过模拟“犯错的同伴”来提供更贴近真实同伴学习体验。其创新点在于识别并模仿特定熟练度水平的错误，这可能有助于提供更个性化和有效的反馈。然而，摘要中未提及具体的实施细节或实验结果，因此无法评估其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 促进随时随地的同伴学习，解决人类同伴学习的局限性，特别是寻找同等熟练度伙伴的困难。

**Method:** 开发一个AI智能体作为学习伙伴，该智能体假设与学习者熟练度相同的同伴会犯相同的错误，并以英语写作作为具体验证领域。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在开发一个AI智能体作为学习伙伴，以克服传统同伴学习中寻找同等熟练度伙伴的局限性。该AI智能体通过模仿与学习者水平相当的同伴可能犯的错误，从而在英语写作等领域提供随时随地的有效同伴学习体验。

> **摘要翻译:** 近年来，同伴学习作为一种促进学习者自发思考的方法受到了关注，其有效性已得到大量研究的证实。本研究旨在开发一个AI智能体作为学习伙伴，以实现随时随地的同伴学习。然而，人类之间的同伴学习存在各种局限性，并非总是有效。有效的同伴学习需要相同熟练度水平的伙伴。在本研究中，我们假设与学习者熟练度相同的同伴会犯与学习者相同的错误，并以英语写作作为具体示例来验证这种方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [277] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
> *生成式能源竞技场 (GEA)：将能源意识融入大型语言模型 (LLM) 人工评估*

*Carlos Arriaga, Gonzalo Martínez, Eneko Sendin, Javier Conde, Pedro Reviriego* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型评估, 能源意识, GEA, 人工评估, 能耗

**Comment:** 

> **TL;DR:** 引入GEA，一个考虑能源消耗的LLM人工评估平台，发现用户在知晓能耗后倾向于选择更小、更节能的模型。

**AI_Comments:** 这篇论文的创新点在于将能源消耗这一日益重要的因素引入到大型语言模型的人工评估中，提供了一个新的视角来衡量模型的实际价值。它不仅指出了现有评估方法的不足，还提出了一个可行的解决方案——GEA平台。研究结果对未来LLM的开发和部署具有重要指导意义，鼓励开发者关注模型的能效，而不仅仅是性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM评估方法（自动化基准和传统人工评估）存在局限性，如与人类判断相关性差和可扩展性问题。此外，LLM的能耗日益重要，研究能源意识如何影响人类选择模型的决策是必要且有意义的。

**Method:** 提出并开发了“生成式能源竞技场 (GEA)”，这是一个在评估过程中整合模型能耗信息的竞技场平台。

**Result:** GEA的初步结果表明，对于大多数问题，当用户了解能耗时，他们更倾向于选择更小、更节能的模型。

**Conclusion:** 这表明对于大多数用户交互而言，更复杂、性能更好的模型所产生的额外成本和能耗，并未带来足以证明其使用的感知质量提升。

> **ai_Abstract:** 本文提出了生成式能源竞技场（GEA），一个新颖的LLM人工评估平台，旨在解决现有评估方法的局限性并引入能源消耗因素。GEA允许用户在评估模型时了解其能耗信息。初步结果显示，当用户知晓能耗后，他们倾向于选择更小、更节能的模型，这暗示了在多数情况下，大型高性能模型的高能耗和成本与其感知的质量提升不符。

> **摘要翻译:** 大型语言模型的评估是一项复杂的任务，目前已提出了多种方法。最常见的是使用自动化基准测试，其中LLM必须回答不同主题的多项选择题。然而，这种方法存在一定的局限性，最令人担忧的是与人类判断的相关性较差。另一种方法是让人类评估LLM。这带来了可扩展性问题，因为需要评估的模型数量庞大且不断增长，使得运行基于招募评估员并让他们对模型响应进行排名的传统研究变得不切实际（且成本高昂）。另一种替代方法是使用公共竞技场，例如流行的LM竞技场，任何用户都可以在其中自由评估任何问题上的模型，并对两个模型的响应进行排名。然后将结果整理成模型排名。LLM一个日益重要的方面是它们的能耗，因此，评估能源意识如何影响人类选择模型的决策是很有趣的。在本文中，我们提出了GEA，即生成式能源竞技场，这是一个在评估过程中整合了模型能耗信息的竞技场。本文还介绍了使用GEA获得的初步结果，表明对于大多数问题，当用户了解能耗时，他们更倾向于选择更小、更节能的模型。这表明对于大多数用户交互而言，更复杂、性能更好的模型所产生的额外成本和能耗，并未带来足以证明其使用的感知质量提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [288] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
> *飞、错、修：基于强化学习和大型多模态模型的迭代游戏修复*

*Alex Zook, Josef Spjut, Jonathan Tremblay* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 游戏设计, 强化学习, 大型多模态模型, 迭代修复, AI辅助

**Comment:** Published at Reinforcement Learning and Video Games workshop
  https://sites.google.com/view/rlvg-workshop-2025/home

> **TL;DR:** 本文提出一个自动化游戏设计迭代框架，结合强化学习智能体进行游戏测试，并利用大型多模态模型根据智能体的行为修改游戏，以实现迭代的游戏机制修复。

**AI_Comments:** 该论文的创新点在于将强化学习与大型多模态模型相结合，形成了一个闭环的自动化游戏设计迭代系统。这种“玩-分析-修改”的范式有效地弥补了传统生成系统在理解动态玩家行为方面的不足。其重要性体现在为AI辅助游戏设计提供了一个实用的、可扩展的解决方案，有望大幅提高游戏开发的效率和质量。

<details>
  <summary>Details</summary>

**Motivation:** 现代生成系统在仅检查游戏代码或资产时，难以捕捉静态规则和内容如何转化为动态玩家行为，这导致游戏设计与实际玩家行为之间存在鸿沟。本文旨在弥补这一差距。

**Method:** 本文提出了一个自动化设计迭代框架，该框架将强化学习（RL）智能体（负责游戏测试）与大型多模态模型（LMM）（根据RL智能体的行为修改游戏）相结合。在每个循环中，RL玩家完成多个回合，生成数值游戏指标和/或总结近期视频帧的紧凑图像条。LMM设计师接收游戏目标和当前游戏配置，分析游戏轨迹，并编辑配置以引导未来行为朝向目标。

**Result:** 研究结果表明，大型多模态模型能够基于强化学习智能体提供的行为轨迹进行推理，从而迭代地优化游戏机制。

**Conclusion:** 本文的工作指向了AI辅助游戏设计中实用且可扩展的工具，能够有效解决游戏设计中行为与规则之间的差距。

> **ai_Abstract:** 本文提出了一种名为“飞、错、修”的自动化游戏设计迭代框架，旨在解决现有生成系统难以捕捉游戏规则与玩家动态行为之间关系的问题。该框架结合了强化学习（RL）智能体进行游戏测试，并利用大型多模态模型（LMM）根据RL智能体的游戏行为数据（包括数值指标和视觉摘要）来迭代地修改游戏配置，以实现预设的游戏目标。研究结果表明，LMM能够有效利用RL智能体提供的行为轨迹来迭代优化游戏机制，为AI辅助游戏设计提供了实用的可扩展工具。

> **摘要翻译:** 游戏设计取决于理解静态规则和内容如何转化为动态玩家行为——这是现代生成系统在仅检查游戏代码或资产时难以捕捉的。我们提出了一个自动化的设计迭代框架，通过将进行游戏测试的强化学习（RL）智能体与根据智能体行为修改游戏的大型多模态模型（LMM）配对来弥补这一差距。在每个循环中，RL玩家完成多个回合，生成（i）数值游戏指标和/或（ii）总结近期视频帧的紧凑图像条。LMM设计师接收一个游戏目标和当前游戏配置，分析游戏轨迹，并编辑配置以引导未来行为朝向目标。我们展示了LMM能够对RL智能体提供的行为轨迹进行推理以迭代优化游戏机制的结果，这指向了AI辅助游戏设计中实用、可扩展的工具。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [312] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
> *通过黑盒到白盒性能提升来基准测试欺骗探测器*

*Avi Parrack, Carlo Leonardo Attubato, Stefan Heimersheim* | **Category: cs.AI, cs.LG, I.2.7; K.4.1** | **Updated: 2025-07-16**

**Keywords:** 欺骗探测器, AI助手, 黑盒监控, 白盒监控, 性能提升

**Comment:** Preprint. 37 pages, 10 figures, 7 tables

> **TL;DR:** 本文通过比较白盒与黑盒监控性能，基准测试了欺骗探测器，发现现有探测器显示出微弱但令人鼓舞的性能提升。

**AI_Comments:** 这项研究通过引入“黑盒到白盒性能提升”这一新颖的基准指标，为评估欺骗探测器的实际效能提供了一个有价值的框架。它揭示了在更深层次访问模型内部状态时，探测器性能的潜在提升，但也指出当前提升的幅度较小，提示未来研究可能需要更鲁棒的探测器或更复杂的检测方法来应对AI助手的欺骗行为。

<details>
  <summary>Details</summary>

**Motivation:** 现有欺骗探测器在实践中检测AI助手欺骗的有效性及其抵抗规避策略的能力尚不明确。

**Method:** 本文通过比较白盒监控（可访问令牌级探测器激活）和黑盒监控（无此访问权限），以白盒监控器优于黑盒监控器的程度（即黑盒到白盒性能提升）作为基准，来评估欺骗探测器。

**Result:** 现有欺骗探测器显示出微弱但令人鼓舞的黑盒到白盒性能提升。

**Conclusion:** 现有欺骗探测器在白盒监控下表现出一定的性能提升潜力，但这种提升目前仍相对微弱。

> **ai_Abstract:** 本文旨在评估用于检测AI助手欺骗性回应的“欺骗探测器”的实际有效性及其对规避策略的抵抗力。研究通过比较白盒监控（可访问内部激活）和黑盒监控（无此访问）的性能，以“黑盒到白盒性能提升”作为基准指标。结果显示，现有欺骗探测器表现出微弱但令人鼓舞的性能提升。

> **摘要翻译:** 人工智能助手有时会欺骗性地回应用户查询。最近，线性分类器（称为“欺骗探测器”）已被训练用于区分语言模型在欺骗性与诚实性回应期间的内部激活。然而，目前尚不清楚这些探测器在实践中检测欺骗的有效性，也不知道这些探测器是否能抵抗希望规避检测的欺骗性助手所采用的简单反制策略。在本文中，我们比较了白盒监控（监控器可以访问令牌级探测器激活）和黑盒监控（没有此类访问权限）。我们通过白盒监控器优于黑盒监控器的程度，即黑盒到白盒的性能提升，来基准测试欺骗探测器。我们发现现有欺骗探测器显示出微弱但令人鼓舞的黑盒到白盒性能提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [316] [Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments](https://arxiv.org/abs/2507.04037)
> *头号法学家：动态环境下法律智能语言智能体的基准测试*

*Zheng Jia, Shengbin Yue, Wei Chen, Siyuan Wang, Yidong Liu, Yun Song, Zhongyu Wei* | **Category: cs.AI** | **Updated: 2025-07-17**

**Keywords:** 法律智能, 语言智能体, 动态环境, 基准测试, LLM评估

**Comment:** 

> **TL;DR:** 该论文引入了J1-ENVS和J1-EVAL，用于在动态法律环境中对大型语言模型（LLM）智能体进行基准测试，发现当前模型在动态设置下尽管具有扎实的法律知识，但在程序执行方面表现不佳。

**AI_Comments:** 该研究的创新之处在于首次创建了交互式动态法律环境（J1-ENVS）和全面的评估框架（J1-EVAL），突破了传统静态基准的限制。这对于开发更实用、更鲁棒的法律人工智能至关重要。研究结果揭示了当前SOTA模型在程序合规性方面的关键局限性，而这在实际法律应用中至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 静态基准与现实世界法律实践的动态性之间的差距是推进法律智能的关键障碍。

**Method:** 引入了J1-ENVS，这是第一个为LLM智能体量身定制的交互式动态法律环境，由法律专家指导，包含来自中国法律实践的六个代表性场景，涵盖三个环境复杂性级别。此外，还引入了J1-EVAL，一个细粒度的评估框架，旨在评估不同法律熟练度水平下的任务性能和程序合规性。对17个LLM智能体进行了广泛实验。

**Result:** 许多模型表现出扎实的法律知识，但在动态设置下的程序执行方面表现不佳。即使是SOTA模型GPT-4o，其整体性能也低于60%。

**Conclusion:** 实现动态法律智能仍存在持续挑战，这些发现为指导未来研究提供了宝贵见解。

> **ai_Abstract:** 该论文旨在弥合法律人工智能中静态基准与动态现实世界法律实践之间的差距，为此引入了J1-ENVS，一个基于中国法律实践的交互式动态法律环境，以及J1-EVAL，一个细粒度的评估框架。对17个大型语言模型智能体进行的实验表明，尽管模型具备法律知识，但在动态环境下的程序执行能力显著不足，即使是最先进的模型也表现不佳，这突显了实现真正动态法律智能所面临的挑战。

> **摘要翻译:** 静态基准与现实世界法律实践的动态性之间的差距是推进法律智能的关键障碍。为此，我们引入了J1-ENVS，这是第一个为基于LLM的智能体量身定制的交互式动态法律环境。在法律专家的指导下，它包含来自中国法律实践的六个代表性场景，涵盖三个环境复杂性级别。我们进一步引入了J1-EVAL，一个细粒度的评估框架，旨在评估不同法律熟练度水平下的任务性能和程序合规性。对17个LLM智能体进行的广泛实验表明，尽管许多模型表现出扎实的法律知识，但它们在动态设置下的程序执行方面表现不佳。即使是SOTA模型GPT-4o，其整体性能也低于60%。这些发现突出了实现动态法律智能所面临的持续挑战，并为指导未来研究提供了宝贵见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [325] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
> *FormulaOne：衡量超越竞技编程的算法推理深度*

*Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekharya, Yoav Levine, Shai Shalev-Shwartz, Amnon Shashua* | **Category: cs.AI, cs.CC, math.LO** | **Updated: 2025-07-17**

**Keywords:** 算法推理, AI基准, 图论, Monadic Second-Order逻辑, 强指数时间假设

**Comment:** 

> **TL;DR:** 本文介绍了FormulaOne，一个用于衡量前沿AI模型在图论、逻辑和算法交叉领域深度算法推理能力的新基准。结果显示，即使是SOTA模型也无法解决FormulaOne中的问题，表明它们离专家级理解仍有距离。

**AI_Comments:** FormulaOne是一个重要的基准，因为它将AI评估从传统的竞技编程问题转向了更具挑战性和现实意义的理论计算机科学前沿问题。这对于揭示当前AI模型在深度算法推理和解决开放性研究问题方面的真正局限性至关重要。其创新点在于结合了MSO逻辑和与SETH等核心猜想的关联，为生成复杂且有理论深度的任务提供了框架。该基准对于推动AI在复杂优化和理论计算机科学领域的进展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI模型在知识广度上表现出色，但作者旨在探究它们在解决最困难问题和推动科学理解边界方面的真实专家能力。他们认为竞技编程谜题不足以衡量真正的专家能力，因此转向现实生活中的研究问题。

**Method:** 作者构建了FormulaOne基准，它位于图论、逻辑和算法的交叉点。这个数据集具有三个关键特性：1) 具有商业利益，与实际大规模优化问题相关（如路由、调度、网络设计）；2) 由图上的Monadic Second-Order (MSO) 逻辑框架生成，便于大规模自动问题生成；3) 许多问题与理论计算机科学的前沿及其核心猜想（如强指数时间假设SETH）密切相关。他们还提供了FormulaOne-Warmup作为一套更简单的任务。

**Result:** 最先进的模型（如OpenAI的o3）在FormulaOne上完全失败，即使在给出10次尝试和解释性少样本示例的情况下，也只解决了不到1%的问题。

**Conclusion:** 前沿AI模型在某些领域距离专家级理解仍有很大差距，无法解决FormulaOne基准中提出的复杂算法推理问题。

> **ai_Abstract:** 本文介绍了FormulaOne，一个旨在评估前沿AI模型深度算法推理能力的新基准。该基准包含图论、逻辑和算法交叉领域的复杂问题，这些问题具有商业应用价值、可大规模自动生成，并与理论计算机科学前沿紧密相关。研究发现，即使是SOTA模型在FormulaOne上的表现也极差，仅能解决不到1%的问题，揭示了当前AI模型在专家级理解方面存在的显著差距。为促进研究，作者还发布了简化版的FormulaOne-Warmup。

> **摘要翻译:** 前沿AI模型展现出强大的知识广度。但它们离真正的人类——或超人类——专业知识还有多远？真正的专家能够解决最困难的问题并推动科学理解的边界。为了阐明前沿模型能力的极限，我们不再关注人为设计的竞技编程谜题，而是转向现实生活中的研究问题。
我们构建了FormulaOne，一个位于图论、逻辑和算法交叉点的基准，所有这些都完全在前沿模型的训练分布之内。我们的问题极具挑战性，需要一系列推理步骤。该数据集具有三个关键特性。首先，它具有商业利益，并与实际的大规模优化问题相关，例如在路由、调度和网络设计中出现的问题。其次，它由图上的Monadic Second-Order (MSO) 逻辑的高度表达性框架生成，为大规模自动问题生成铺平了道路；这是构建强化学习环境的理想选择。第三，我们的许多问题与理论计算机科学的前沿及其核心猜想（如强指数时间假设（SETH））密切相关。因此，在我们的数据集上，任何超越已知结果的重大算法进展都可能具有深远的理论意义。
值得注意的是，像OpenAI的o3这样的最先进模型在FormulaOne上完全失败，即使在给出10次尝试和解释性少样本示例的情况下，也只解决了不到1%的问题——这突出表明它们在某些领域离专家级理解还有多远。为了支持进一步的研究，我们还策划了FormulaOne-Warmup，提供了一组来自相同分布的更简单的任务。我们发布了完整的语料库以及一个全面的评估框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [336] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
> *MCPEval：基于MCP的AI智能体模型自动深度评估*

*Zhiwei Liu, Jielin Qiu, Shiyu Wang, Jianguo Zhang, Zuxin Liu, Roshan Ram, Haolin Chen, Weiran Yao, Huan Wang, Shelby Heinecke, Silvio Savarese, Caiming Xiong* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** LLM智能体, 评估框架, MCP, 自动化, 深度评估

**Comment:** https://github.com/SalesforceAIResearch/MCPEval

> **TL;DR:** MCPEval是一个基于MCP的开源框架，用于自动化LLM智能体的端到端任务生成和深度评估，解决了现有评估方法的局限性，并在多个真实世界领域中显示出有效性。

**AI_Comments:** MCPEval的创新之处在于其基于MCP的自动化端到端任务生成和深度评估方法，显著减少了LLM智能体评估中的手动工作量。其重要性体现在为快速发展的LLM智能体领域提供了一个急需的、可扩展且可复现的评估框架，填补了现有方法在实际评估方面的不足。其开源特性也有助于社区协作和标准化。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）智能体的快速崛起，凸显了对健壮、可扩展评估框架的需求。现有方法依赖于静态基准和劳动密集型数据收集，限制了实际评估，因此需要一种新的自动化评估框架。

**Method:** 我们引入了MCPEval，一个开源的、基于模型上下文协议（MCP）的框架。它自动化了端到端的任务生成和LLM智能体在不同领域的深度评估。MCPEval标准化了指标，与原生智能体工具无缝集成，并消除了构建评估管道中的手动工作。

**Result:** 在五个真实世界领域的实证结果表明，MCPEval在揭示细微的、特定于领域的性能方面是有效的。

**Conclusion:** MCPEval被公开发布，旨在促进LLM智能体评估的可复现性和标准化。

> **ai_Abstract:** MCPEval是一个针对基于LLM的智能体模型提出的开源、基于MCP的自动化评估框架。它旨在解决现有评估方法依赖静态基准和手动操作的局限性，通过自动化任务生成和深度评估，提供一个可扩展的解决方案。该框架标准化了评估指标，并与现有工具集成，减少了人工干预。在多个真实世界领域的实验证明了其在揭示细微性能方面的有效性，并已公开发布以促进标准化和可复现的LLM智能体评估。

> **摘要翻译:** 大型语言模型（LLM）智能体的快速崛起，凸显了对健壮、可扩展评估框架的需求。现有方法依赖于静态基准和劳动密集型数据收集，限制了实际评估。我们引入了MCPEval，一个开源的、基于模型上下文协议（MCP）的框架，它自动化了LLM智能体在不同领域的端到端任务生成和深度评估。MCPEval标准化了指标，与原生智能体工具无缝集成，并消除了构建评估管道中的手动工作。在五个真实世界领域的实证结果表明，MCPEval在揭示细微的、特定于领域的性能方面是有效的。我们公开发布MCPEval（https://github.com/SalesforceAIResearch/MCPEval），以促进LLM智能体评估的可复现性和标准化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [354] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
> *基于LLM的同理心对话生成的情感支持*

*Shiquan Wang, Ruiyu Fang, Zhongjiang He, Shuangyong Song, Yongxiang Li* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 情感支持对话, 大型语言模型, 提示工程, 微调, 同理心对话

**Comment:** 

> **TL;DR:** 本文介绍了在NLPCC 2025情感支持对话评估中，通过提示工程和微调技术增强大型语言模型，以生成同理心对话，并在比赛中获得第二名。

**AI_Comments:** 本文的创新点在于将大型语言模型应用于情感支持对话任务，并通过提示工程和多种微调策略（包括参数高效和全参数微调）进行优化。其在NLPCC竞赛中取得第二名的成绩，证明了该方法的有效性和潜力。未来的工作将致力于提升情感理解和个性化响应，这将进一步提高系统的实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 解决日益增长的心理健康支持需求，通过对话提供同理心和有效的情感帮助。

**Method:** 利用大型语言模型（LLMs），通过提示工程和微调技术进行增强。具体探索了参数高效的低秩适应（Low-Rank Adaptation）和全参数微调策略，以提高模型生成支持性和上下文适当响应的能力。

**Result:** 在NLPCC 2025 Task 8 ESC评估中，最佳模型排名第二。

**Conclusion:** 结合大型语言模型与有效的适应方法在情感支持对话任务中具有潜力。

> **ai_Abstract:** 本文介绍了针对NLPCC 2025情感支持对话（ESC）任务的解决方案。研究团队利用提示工程和微调技术，包括参数高效的低秩适应和全参数微调，来增强大型语言模型（LLMs）生成富有同理心和上下文适当响应的能力。该模型在竞赛中取得了第二名的成绩，证明了LLMs结合有效适应方法在ESC任务上的巨大潜力。

> **摘要翻译:** 情感支持对话（ESC）旨在通过对话提供富有同理心和有效的情感帮助，以满足日益增长的心理健康支持需求。本文介绍了我们为NLPCC 2025任务8 ESC评估提供的解决方案，我们利用提示工程和微调技术增强了大型语言模型。我们探索了参数高效的低秩适应和全参数微调策略，以提高模型生成支持性和上下文适当响应的能力。我们表现最好的模型在比赛中排名第二，突出了将大型语言模型与有效适应方法相结合在情感支持对话任务中的潜力。未来的工作将侧重于进一步增强情感理解和响应个性化，以构建更实用和可靠的情感支持系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [358] [SmartThinker: Learning to Compress and Preserve Reasoning by Step-Level Length Control](https://arxiv.org/abs/2507.04348)
> *SmartThinker：通过步长控制学习压缩和保留推理*

*Xingyang He, Xiao Ling, Jie Liu* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型推理模型, 推理压缩, 步长控制, 强化学习, SmartThinker

**Comment:** 

> **TL;DR:** SmartThinker 提出了一种两阶段框架，通过对推理链中的关键步骤分配更多长度，同时减少非关键步骤的冗余，从而在压缩大型推理模型的同时保持或提高性能。

**AI_Comments:** SmartThinker 的创新之处在于提出了细粒度的步长控制，而非传统的全局长度惩罚，这能更有效地平衡推理的准确性和效率。其两阶段框架和SCPO的组件设计体现了对推理过程深度理解和精细化控制的能力。该方法对于优化大型语言模型的推理效率和降低计算成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）的推理能力显著增强，但同时也引入了大量冗余和低效，导致计算资源浪费。现有方法通过惩罚总长度来鼓励简洁的思维链，但这种全局长度惩罚会导致关键推理步骤过度压缩，而简单步骤保留不必要的细节，导致准确性和效率之间的权衡不佳。

**Method:** 本文提出了 SmartThinker，一个两阶段可学习框架，旨在根据每个独立步骤的重要性，对推理链的长度进行细粒度控制。第一阶段，SmartThinker 通过拒绝采样结合监督微调（SFT）使推理模型适应短形式推理模式。第二阶段，SmartThinker 应用步长控制策略优化（SCPO）来优化模型输出分布，增加分配给关键步骤的长度比例，同时减少非重要步骤的冗余。SCPO 包含四个核心组件：在线重要性估计器、步长控制奖励函数、步长广义优势估计（S-GAE）和难度自适应裁剪策略。

**Result:** 在多个推理基准和各种骨干模型上的实证结果表明，SmartThinker 显著减少了冗余推理，同时实现了与现有方法相当甚至更优的性能。

**Conclusion:** SmartThinker 通过精细的步长控制，成功解决了大型推理模型中冗余和效率低下的问题，在压缩推理链的同时保持了高推理性能。

> **ai_Abstract:** SmartThinker 是一种两阶段学习框架，用于压缩大型推理模型并保留其推理能力。针对现有全局长度惩罚导致关键步骤过度压缩的问题，SmartThinker 在第一阶段通过拒绝采样和监督微调使模型适应短形式推理，第二阶段利用步长控制策略优化（SCPO）根据推理步骤的重要性进行细粒度长度控制，为关键步骤分配更多长度，减少非关键步骤冗余。实验证明，该方法能显著减少冗余推理，同时保持或提升性能。

> **摘要翻译:** 大型推理模型（LRMs）通过推理时缩放展现出卓越的推理能力，但这一进展也给其推理过程带来了相当大的冗余和低效率，导致大量的计算浪费。以往的工作试图通过在强化学习（RL）期间惩罚生成样本的整体长度来缓解这个问题，目的是鼓励更简洁的思维链。然而，我们观察到这种全局长度惩罚常常导致关键推理步骤的过度压缩，同时在更简单的步骤中保留不必要的细节，从而导致准确性和效率之间达到次优的权衡。为了解决这个问题，我们提出了 SmartThinker，一个两阶段可学习框架，旨在根据每个独立步骤的重要性，对推理链的长度进行细粒度控制。在第一阶段，SmartThinker 通过拒绝采样结合监督微调（SFT），使推理模型适应短形式推理模式。在第二阶段，SmartThinker 应用步长控制策略优化（SCPO）来优化模型输出分布，这增加了分配给关键步骤的长度比例，同时减少了不那么重要步骤的冗余。SCPO 由四个核心组件组成：一个在线重要性估计器、一个步长控制奖励函数、一个步长广义优势估计（S-GAE）和一个难度自适应裁剪策略。这些组件协同工作，使 SCPO 能够实现跨推理步骤的差异化长度控制。在多个推理基准和各种骨干模型上的实证结果表明，SmartThinker 显著减少了冗余推理，同时实现了与现有方法相当甚至更优的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [372] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
> *用新颖游戏评估机器中的自适应世界模型*

*Lance Ying, Katherine M. Collins, Prafull Sharma, Cedric Colas, Kaiya Ivy Zhao, Adrian Weller, Zenna Tavares, Phillip Isola, Samuel J. Gershman, Jacob D. Andreas, Thomas L. Griffiths, Francois Chollet, Kelsey R. Allen, Joshua B. Tenenbaum* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 自适应世界模型, 新颖游戏, 人工智能评估, 世界模型归纳, 快速适应

**Comment:** 17 pages, 4 figures

> **TL;DR:** 本文提出一种基于“新颖游戏”的新评估框架，用于衡量AI系统快速构建和优化世界模型的能力，以实现类人适应性。

**AI_Comments:** 这篇论文的创新点在于其提出了一个全新的评估范式，即“新颖游戏”，以弥补现有AI世界模型评估的不足。它强调了在动态、novel 环境中学习和适应的重要性，而非仅仅依赖静态数据训练。这种方法对于推动AI向更接近通用智能的方向发展具有重要意义，因为它直接挑战了AI在面对未知和复杂环境时的适应性。

<details>
  <summary>Details</summary>

**Motivation:** 当前对AI世界模型的理解和评估过于狭隘，主要关注从大量数据中学习的静态表示，而非通过交互和探索在 novel 环境中学习这些表示的效率和有效性。人类智能在 novel 环境中展现出卓越的快速适应和解决问题的能力，这与高效构建和完善世界模型有关，因此需要新的评估范式。

**Method:** 本文提出一个借鉴认知科学研究的新评估框架，用于评估AI中的自适应世界模型。具体地，提出一种新的基准测试范式，基于一系列精心设计的、具有深层且持续刷新新颖性的游戏集（称为“新颖游戏”）。文章详细阐述了构建这些游戏的关键要素，并提出了适当的指标来明确挑战和评估智能体快速世界模型归纳的能力。

**Result:** Not mentioned in abstract

**Conclusion:** 作者希望这个新的评估框架能激发未来对AI世界模型的评估工作，并为开发具有类人快速适应和鲁棒泛化能力的AI系统提供关键一步，这被认为是通用人工智能的关键组成部分。

> **ai_Abstract:** 这篇观点文章指出当前AI对世界模型的评估存在局限性，未能充分衡量其在 novel 环境中通过交互学习和适应的能力。作者借鉴认知科学中人类适应性的研究，提出了一种新的评估框架，该框架基于“新颖游戏”——一种具有持续刷新新颖性的基准测试范式。文章详细阐述了构建这些游戏的要素和评估指标，旨在推动AI系统实现类人快速适应和通用智能。

> **摘要翻译:** 人类智能在全新和不熟悉的环境中展现出卓越的快速适应和有效解决问题的能力。我们认为，这种深刻的适应性与高效构建和完善环境的内部表征（通常称为世界模型）有着根本的联系，我们将这种适应机制称为世界模型归纳。然而，目前对人工智能（AI）中世界模型的理解和评估仍然狭隘，往往侧重于从大量数据语料库中训练学习到的静态表征，而非模型在全新环境中通过交互和探索学习这些表征的效率和有效性。在这篇观点文章中，我们借鉴了认知科学数十年关于人类如何高效学习和适应的研究，提出了对世界模型归纳的看法；然后，我们呼吁建立一个新的评估框架来评估AI中的自适应世界模型。具体来说，我们提出了一种新的基准测试范式，它基于一系列精心设计的游戏，这些游戏的底层游戏结构具有真正的、深刻的和持续刷新的新颖性——我们将这类游戏称为新颖游戏。我们详细阐述了构建这些游戏的关键要素，并提出了适当的指标，以明确挑战和评估智能体快速世界模型归纳的能力。我们希望这个新的评估框架将激发未来对AI世界模型的评估工作，并为开发能够实现类人快速适应和鲁棒泛化能力的AI系统提供关键一步——这是通用人工智能的关键组成部分。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [396] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
> *Aime：迈向全自主多智能体框架*

*Yexuan Shi, Mingyu Wang, Yunxiang Cao, Hongjie Lai, Junjian Lan, Xin Han, Yu Wang, Jie Geng, Zhenan Li, Zihao Xia, Xiang Chen, Chen Li, Jian Xu, Wenbo Duan, Yuanshuo Zhu* | **Category: cs.AI** | **Updated: 2025-07-17**

**Keywords:** 多智能体系统, 大型语言模型, 动态规划, 自主性, 框架

**Comment:** 14 pages, 1 figures,

> **TL;DR:** Aime是一个新颖的多智能体框架，通过动态、响应式规划和执行，克服了现有基于LLM的多智能体系统在适应性和鲁棒性方面的限制，并在多项基准测试中表现出色。

**AI_Comments:** Aime通过其动态规划、按需智能体实例化和集中式状态管理，显著提升了多智能体系统的自主性和适应性，克服了传统“规划-执行”框架的固有缺陷。其创新点在于将实时反馈融入规划过程，并允许智能体能力动态调整，这对于构建更鲁棒、更灵活的AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前由大型语言模型（LLM）驱动的多智能体系统（MAS）受限于普遍存在的“规划-执行”框架，该框架存在僵硬的计划执行、静态的智能体能力和低效的通信等问题，这些弱点阻碍了它们在动态环境中的适应性和鲁棒性。

**Method:** 本文提出了Aime，一个新颖的多智能体框架，旨在通过动态、响应式规划和执行来克服现有挑战。Aime用流畅自适应的架构取代了传统的静态工作流，其核心创新包括：(1) 一个动态规划器，根据实时执行反馈持续优化整体策略；(2) 一个Actor工厂，实现动态Actor实例化，按需组装具有定制工具和知识的专业智能体；(3) 一个集中式的进度管理模块，作为系统范围一致状态感知的单一信息源。

**Result:** Aime在通用推理（GAIA）、软件工程（SWE-bench Verified）和实时网络导航（WebVoyager）等多个基准测试中进行了实证评估。结果表明，Aime在各自领域持续优于甚至高度专业化的最先进智能体。

**Conclusion:** Aime卓越的适应性和任务成功率使其成为多智能体协作更具弹性和有效的基础。

> **ai_Abstract:** Aime是一个创新的多智能体框架，旨在解决当前基于大型语言模型的多智能体系统在“规划-执行”范式下的局限性，如僵硬的执行和静态能力。通过引入动态规划器、Actor工厂和进度管理模块，Aime实现了动态、响应式的规划与执行，提高了系统的适应性和鲁棒性。实验证明，Aime在通用推理、软件工程和网络导航等多个基准测试中均超越了现有SOTA方法，为多智能体协作提供了更有效的基础。

> **摘要翻译:** 由大型语言模型（LLM）驱动的多智能体系统（MAS）正在成为解决复杂多方面问题的强大范式。然而，这些系统的潜力常常受到普遍存在的“规划-执行”框架的限制，该框架存在关键缺陷：僵硬的计划执行、静态的智能体能力和低效的通信。这些弱点阻碍了它们在动态环境中的适应性和鲁棒性。本文介绍了Aime，一个新颖的多智能体框架，旨在通过动态、响应式规划和执行来克服这些挑战。Aime用流畅自适应的架构取代了传统的静态工作流。其核心创新包括：(1) 一个动态规划器，根据实时执行反馈持续优化整体策略；(2) 一个Actor工厂，实现动态Actor实例化，按需组装具有定制工具和知识的专业智能体；(3) 一个集中式的进度管理模块，作为系统范围一致状态感知的单一信息源。我们对Aime在通用推理（GAIA）、软件工程（SWE-bench Verified）和实时网络导航（WebVoyager）等多种基准测试中进行了实证评估。结果表明，Aime在各自领域持续优于甚至高度专业化的最先进智能体。其卓越的适应性和任务成功率使Aime成为多智能体协作更具弹性和有效的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [1] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
> *串行扩展假说*

*Yuxi Liu, Konpat Preechakul, Kananart Kuwaranancharoen, Yutong Bai* | **Category: cs.LG, cs.CC, stat.ML, 68Q15, 68Q10, 68T07, F.1.1; F.1.3; I.2.6** | **Updated: 2025-07-16**

**Keywords:** 串行计算, 并行化, 机器学习, 复杂性理论, AI架构

**Comment:** 28 pages (13 pages main text + appendices & references), 8 figures,
  equal-contribution first authors

> **TL;DR:** 该论文提出并强调了“固有串行”问题的存在，这些问题在计算上无法并行化，并指出当前以并行计算为中心的AI架构在处理此类问题时面临根本性限制，认为未来AI发展需重视串行计算的扩展。

**AI_Comments:** 这篇论文的创新点在于，它挑战了当前机器学习领域普遍的“并行至上”范式，并提出了一个被忽视但至关重要的概念——“固有串行”问题。在AI模型越来越大、并行化程度越来越高的背景下，该论文提醒人们关注计算的本质限制，特别是对于需要复杂推理和顺序依赖的任务。其重要性在于，它可能引导未来AI模型设计和硬件开发走向更平衡的方向，即不仅优化并行能力，也重视并突破串行计算的瓶颈。这对于推动AI在需要深层理解和逻辑推理的应用中取得突破至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习的进步主要依赖大规模并行化，但存在一个关键盲点：有些问题本质上是串行的，如数学推理、物理模拟和顺序决策。这些“固有串行”问题需要依赖性的计算步骤，无法并行化。当前以并行计算为中心的架构在处理这些任务时面临根本性限制，因此需要识别并解决这一问题。

**Method:** 论文通过借鉴复杂性理论，形式化了并行问题与串行问题之间的区别。

**Result:** 研究表明，当前以并行计算为中心的架构在处理固有串行任务时面临根本性限制。

**Conclusion:** 认识到计算的串行性质对机器学习、模型设计和硬件开发具有深远影响。随着AI处理日益复杂的推理任务，有意识地扩展串行计算（而不仅仅是并行计算）对于持续进步至关重要。

> **ai_Abstract:** 该论文提出了“串行扩展假说”，指出尽管机器学习受益于大规模并行化，但“固有串行”问题（如数学推理、物理模拟、顺序决策）因其依赖性计算步骤而无法并行化。论文利用复杂性理论形式化了这一区别，并论证了当前以并行计算为中心的架构在处理此类任务时存在根本性限制。作者强调，在AI应对复杂推理时，有意识地扩展串行计算与并行计算同等重要，这对机器学习、模型设计及硬件发展具有深远影响。

> **摘要翻译:** 虽然机器学习通过大规模并行化取得了进展，但我们发现了一个关键盲点：有些问题本质上是串行的。这些“固有串行”问题——从数学推理到物理模拟再到顺序决策——需要无法并行化的依赖性计算步骤。借鉴复杂性理论，我们形式化了这种区别，并证明当前以并行计算为中心的架构在此类任务上存在根本性限制。我们认为，认识到计算的串行性质对机器学习、模型设计和硬件开发具有深远影响。随着人工智能应对日益复杂的推理，有意识地扩展串行计算——而不仅仅是并行计算——对于持续进步至关重要。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [2] [SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs](https://arxiv.org/abs/2507.13001)
> *SMART：知识图谱几何表示的关系感知学习*

*Kossi Amouzouvi, Bowen Song, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 知识图谱, 几何表示, 关系感知学习, 知识图谱嵌入, 几何变换

**Comment:** 

> **TL;DR:** SMART是一个为知识图谱嵌入模型学习关系特定几何变换的框架，通过评估每个关系与不同几何变换的匹配度，并分配最佳变换或通过多数投票选择一种变换类型，从而提升性能。

**AI_Comments:** SMART的创新之处在于其能够为知识图谱中的每个关系学习或选择最合适的几何变换，而非沿用单一变换，这显著提升了关系表示的细致度和准确性。通过引入关系与几何变换的匹配度评估和注意力机制，该方法有望在知识图谱表示学习领域取得重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的知识图谱嵌入（KGE）模型在使用基本几何变换（EGTs）时，未能充分考虑关系特定的变换，导致表示能力不足。尽管近期模型尝试通过集成基线模型来解决此问题，但这些基线模型仍仅使用单一或复合几何变换来表示所有关系。

**Method:** 本文提出了SMART框架，该框架评估每个关系与不同几何变换的契合度。基于此排名，模型可以：(1) 为每个关系分配最匹配的变换；或(2) 使用多数投票选择一种变换类型应用于所有关系。模型通过注意力机制在低维向量空间中学习单一的关系特定EGT。此外，模型利用在低维空间中学习到的关系与EGT之间的相关性，用于高维向量空间中的关系嵌入。

**Result:** 模型在三个基准知识图谱以及一个真实世界的金融知识图谱上进行了全面的评估，结果表明其性能与领先模型相当。

**Conclusion:** SMART框架通过引入关系特定的几何变换，有效解决了现有知识图谱嵌入模型在表示关系方面的局限性，并在多个基准和真实世界数据集上取得了与领先模型媲美的性能。

> **ai_Abstract:** SMART是一个新颖的知识图谱嵌入框架，旨在通过学习关系特定的几何表示来克服现有模型对所有关系采用单一或复合几何变换的局限性。该框架通过评估每个关系与不同基本几何变换的匹配度，为每个关系分配最佳变换或选择一种最佳变换类型应用于所有关系。它利用注意力机制在低维空间中学习关系特定的变换，并将这种关系与变换的关联用于高维关系嵌入。在多个基准和真实世界知识图谱上的评估证明了SMART模型与现有领先模型相当的有效性。

> **摘要翻译:** 知识图谱表示学习方法提供了知识图谱（KG）中以三元组形式存在的符号知识与其特征向量之间的映射。知识图谱嵌入（KGE）模型通常将KG中的关系表示为几何变换。大多数最先进（SOTA）的KGE模型都源自基本的几何变换（EGTs），如平移、缩放、旋转和反射，或它们的组合。这些几何变换使模型能够有效地保留KG的特定结构和关系模式。然而，KGE当前对EGTs的使用在不考虑关系特定变换的情况下仍然不足。尽管最近的模型试图通过以不同方式集成SOTA基线模型来解决这个问题，但这些基线模型仅使用单一或复合版本的几何变换来表示所有关系。在本文中，我们提出了一个框架，该框架评估每个关系与不同几何变换的契合度。基于此排名，模型可以：(1) 为每个关系分配最匹配的变换，或(2) 使用多数投票选择一种变换类型应用于所有关系。也就是说，模型通过注意力机制在低维向量空间中学习单一的关系特定EGT。此外，我们利用在低维空间中学习到的关系与EGT之间的相关性，用于高维向量空间中的关系嵌入。我们的模型在三个基准知识图谱以及一个真实世界的金融知识图谱上的综合评估证明了其有效性，性能可与领先模型媲美。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [4] [MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration](https://arxiv.org/abs/2507.12935)
> *MC$^2$A：实现高效马尔可夫链蒙特卡洛加速的算法-硬件协同设计*

*Shirui Zhao, Jun Yin, Lingyun Yao, Martin Andraud, Wannes Meert, Marian Verhelst* | **Category: cs.LG, cs.AI, cs.AR** | **Updated: 2025-07-17**

**Keywords:** MCMC, 硬件加速, 协同设计, Gumbel采样器, 屋顶模型

**Comment:** 14 pages, 15 figures, IEEE journal paper

> **TL;DR:** MC$^2$A是一个算法-硬件协同设计框架，通过扩展屋顶模型、参数化硬件加速器和新型Gumbel采样器，显著加速了MCMC算法。

**AI_Comments:** 这篇论文通过算法-硬件协同设计，创新性地解决了MCMC算法的计算效率瓶颈。特别是扩展屋顶模型（引入第三维度）以优化计算、采样和内存平衡，以及引入新型Gumbel采样器以简化操作，展现了其在理论分析和硬件实现上的深度。该工作对于推广MCMC在实际应用中的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 马尔可夫链蒙特卡洛（MCMC）算法计算成本高昂，限制了其在大规模问题和实际应用中的可行性。现有MCMC加速解决方案在硬件灵活性或系统级效率方面存在不足，无法在各种端到端应用中保持效率。

**Method:** MC$^2$A框架通过以下方法实现：1. 扩展处理器性能屋顶模型并增加第三维度，以分析MCMC工作负载多样性，推导计算、采样和内存参数的最佳平衡。2. 提出一个参数化硬件加速器架构，包含ISA可编程树状处理单元、可重构采样器和支持不规则访问的交叉开关互连，以灵活高效地支持MCMC核。3. 引入一种新型Gumbel采样器，该采样器消除了指数和归一化操作。

**Result:** 在端到端案例研究中，MC$^2$A相较于CPU、GPU、TPU和最先进的MCMC加速器，分别实现了307.6倍、1.4倍、2.0倍和84.2倍的整体加速。

**Conclusion:** 该工作通过对各种代表性MCMC工作负载的评估，证明并利用了通用硬件加速的可行性，旨在在不同应用领域中推广基于MCMC的解决方案。

> **ai_Abstract:** MC$^2$A是一个算法-硬件协同设计框架，旨在解决MCMC算法的高计算成本及其现有加速方案的不足。该框架通过扩展屋顶模型来分析工作负载多样性，并提出了一种包含ISA可编程树状处理单元和可重构采样器的参数化硬件加速器。其核心创新在于引入了一种新型Gumbel采样器，从而消除了复杂操作。实验结果表明，MC$^2$A在多种MCMC工作负载上实现了显著加速，证明了通用硬件加速MCMC的可行性，有助于MCMC在更广泛应用中的普及。

> **摘要翻译:** 越来越多的应用程序正在利用基于采样的算法进行规划、优化和推理。马尔可夫链蒙特卡洛（MCMC）算法构成了这一新兴机器学习分支的计算骨干。不幸的是，高昂的计算成本限制了它们在大规模问题和实际应用中的可行性，并且现有的MCMC加速解决方案要么硬件灵活性有限，要么无法在各种端到端应用中保持系统级效率。
本文介绍了MC$^2$A，一个算法-硬件协同设计框架，旨在实现MCMC加速的高效和灵活优化。首先，MC$^2$A通过将处理器性能屋顶模型扩展到第三维度来分析MCMC工作负载的多样性，以推导出计算、采样和内存参数之间的最佳平衡。其次，MC$^2$A提出了一种参数化的硬件加速器架构，通过ISA可编程树状处理单元、可重构采样器和支持不规则访问的交叉开关互连流水线，灵活高效地支持MCMC核。第三，MC$^2$A的核心由一种新型Gumbel采样器驱动，该采样器消除了指数和归一化操作。
在端到端案例研究中，MC$^2$A相较于CPU、GPU、TPU和最先进的MCMC加速器，分别实现了307.6倍、1.4倍、2.0倍和84.2倍的整体加速。通过对各种代表性MCMC工作负载的评估，这项工作展示并利用了通用硬件加速的可行性，以在不同应用领域中推广基于MCMC的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [17] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
> *PMKLC：基于并行多知识学习的大规模基因组数据库无损压缩*

*Hui Sun, Yanfeng Ding, Liping Yi, Huidong Ma, Gang Wang, Xiaoguang Liu, Cheng Zhong, Wentong Cai* | **Category: cs.LG, cs.AI, cs.CL, cs.DB** | **Updated: 2025-07-17**

**Keywords:** 基因组数据压缩,无损压缩,并行学习,多知识学习,PMKLC

**Comment:** Accepted via KDD-25

> **TL;DR:** PMKLC是一种新的基于学习的无损压缩器，它解决了现有压缩器在基因组数据压缩中存在的压缩比不足、吞吐量低和鲁棒性差的问题。通过多知识学习框架、GPU加速、并行机制和两种压缩模式，PMKLC在压缩比和吞吐量方面显著优于现有基线，并表现出更好的鲁棒性和内存效率。

**AI_Comments:** PMKLC的创新之处在于结合了多知识学习、GPU加速和并行处理技术，以克服现有基因组数据压缩器的局限性。其双模式设计（PMKLC-S和PMKLC-M）考虑了不同资源约束下的应用场景，增加了其实用性。该研究通过在大量真实世界数据集上进行广泛基准测试，充分验证了其方法的有效性和优越性，对大规模基因组数据管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 学习型无损压缩器在大型基因组数据库的备份、存储、传输和管理中发挥着关键作用。然而，它们1) 压缩比不足，2) 压缩和解压缩吞吐量低，以及3) 压缩鲁棒性差，限制了它们在工业界和学术界的广泛采用和应用。

**Method:** 我们提出了一个新颖的并行多知识学习压缩器（PMKLC），包含四个关键设计：1) 自动化多知识学习压缩框架作为压缩器骨干，以提高压缩比和鲁棒性；2) 设计GPU加速的($s$,$k$)-mer编码器以优化压缩吞吐量和计算资源利用率；3) 引入数据块分区和逐步模型传递（SMP）机制以实现并行加速；4) 设计两种压缩模式PMKLC-S（单GPU）和PMKLC-M（多GPU）以满足复杂的应用场景。

**Result:** 与基线相比，PMKLC-S/M在测试数据集上实现了平均压缩比提升高达73.609%和73.480%，平均吞吐量提升高达3.036倍和10.710倍。此外，PMKLC-S/M还实现了最佳鲁棒性和有竞争力的内存成本，表明其对不同概率分布扰动的数据集具有更大的稳定性，以及在内存受限设备上运行的强大能力。

**Conclusion:** PMKLC通过其创新设计有效解决了现有基因组数据无损压缩器的主要挑战，显著提高了压缩比和吞吐量，同时保持了出色的鲁棒性和内存效率，使其成为大规模基因组数据管理的理想解决方案。

> **ai_Abstract:** PMKLC是一种针对大规模基因组数据库的并行多知识学习无损压缩器。它旨在解决现有学习型压缩器在压缩比、吞吐量和鲁棒性方面的不足。PMKLC通过引入自动化多知识学习框架、GPU加速的($s$,$k$)-mer编码器、数据块分区和逐步模型传递机制，以及PMKLC-S和PMKLC-M两种模式来实现其目标。实验结果表明，PMKLC-S/M在压缩比和吞吐量上显著优于14个基线，并展现出卓越的鲁棒性和内存效率，使其适用于各种基因组数据压缩场景。

> **摘要翻译:** 学习型无损压缩器在大型基因组数据库的备份、存储、传输和管理中发挥着关键作用。然而，它们1) 压缩比不足，2) 压缩和解压缩吞吐量低，以及3) 压缩鲁棒性差，限制了它们在工业界和学术界的广泛采用和应用。为了解决这些挑战，我们提出了一种新颖的并行多知识学习压缩器（PMKLC），具有四个关键设计：1) 我们提出了一个自动化多知识学习压缩框架作为压缩器的骨干，以提高压缩比和鲁棒性；2) 我们设计了一个GPU加速的($s$,$k$)-mer编码器来优化压缩吞吐量和计算资源使用；3) 我们引入了数据块分区和逐步模型传递（SMP）机制以实现并行加速；4) 我们设计了两种压缩模式PMKLC-S和PMKLC-M，以满足复杂的应用场景，其中前者运行在资源受限的单GPU上，后者是多GPU加速的。我们在15个具有不同物种和数据大小的真实世界数据集上，对PMKLC-S/M和14个基线（7个传统和7个学习型）进行了基准测试。与测试数据集上的基线相比，PMKLC-S/M分别实现了平均压缩比提升高达73.609%和73.480%，平均吞吐量提升高达3.036倍和10.710倍。此外，PMKLC-S/M还实现了最佳鲁棒性和有竞争力的内存成本，表明其对不同概率分布扰动的数据集具有更大的稳定性，以及在内存受限设备上运行的强大能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [20] [Characterizing Dynamical Stability of Stochastic Gradient Descent in Overparameterized Learning](https://arxiv.org/abs/2407.20209)
> *表征过参数化学习中随机梯度下降的动力学稳定性*

*Dennis Chemnitz, Maximilian Engel* | **Category: cs.LG, math.DS, math.PR** | **Updated: 2025-07-17**

**Keywords:** 过参数化学习, 随机梯度下降, 动力学稳定性, Lyapunov指数, 全局最小值

**Comment:** 

> **TL;DR:** 本文研究了过参数化学习中随机梯度下降（SGD）收敛到的全局最小值的动力学稳定性，并引入一个特征Lyapunov指数来判断SGD能否在特定全局最小值处累积。

**AI_Comments:** 本文通过引入一个量化的Lyapunov指数来判断SGD在过参数化模型中收敛的全局最小值的稳定性，为理解深度学习中的泛化能力提供了一个新的动力学视角，具有重要的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 在现代机器学习中，过参数化优化任务的全局最小值通常不唯一。为了理解这些设置中的泛化能力，研究优化算法收敛到哪个最小值至关重要。优化算法施加的动力学下不稳定的最小值限制了算法可以找到的潜在最小值。

**Method:** 本文引入了一个特征Lyapunov指数，该指数取决于全局最小值周围的局部动力学，并严格证明了该Lyapunov指数的符号决定了随机梯度下降（SGD）是否能在相应的全局最小值处累积。研究了确定性梯度下降和随机梯度下降的动力学稳定性。

**Result:** 结果表明，所引入的Lyapunov指数的符号决定了随机梯度下降是否能在某个特定的全局最小值处累积。

**Conclusion:** 本文证明了通过一个特征Lyapunov指数的符号，可以判断随机梯度下降在过参数化学习中能否在某个全局最小值处实现动力学稳定累积。

> **ai_Abstract:** 本文研究了在过参数化学习中，随机梯度下降（SGD）收敛到的全局最小值的动力学稳定性。鉴于全局最小值通常不唯一，理解算法收敛点对于泛化至关重要。作者引入了一个特征Lyapunov指数，该指数反映了全局最小值附近的局部动力学，并严格证明了其符号决定了SGD是否能在该最小值处稳定累积，从而表征了确定性梯度下降和SGD的动态稳定/不稳定全局最小值。

> **摘要翻译:** 对于现代机器学习中常见的过参数化优化任务，全局最小值通常不唯一。为了理解这些设置中的泛化能力，研究优化算法收敛到哪个最小值至关重要。优化算法施加的动力学下不稳定的最小值限制了算法可以找到的潜在最小值。在本文中，我们表征了确定性梯度下降和随机梯度下降（SGD）的动力学稳定/不稳定的全局最小值。特别是，我们引入了一个特征Lyapunov指数，该指数取决于全局最小值周围的局部动力学，并严格证明了该Lyapunov指数的符号决定了SGD是否能在相应的全局最小值处累积。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [21] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
> *心理意象能否提升人工智能系统的思维能力？*

*Slimane Larabi* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 心理意象, 人工智能系统, 机器思维, 认知单元, 自主推理

**Comment:** 15 pages, 8 figures

> **TL;DR:** 当前人工智能模型缺乏自主行动和独立推理能力。本文提出一个整合心理意象的机器思维框架，旨在改善人工智能的思维过程。

**AI_Comments:** 该论文通过借鉴人类认知过程中的“心理意象”概念来解决当前AI在自主推理和知识整合方面的局限性，这一创新点非常引人注目。提出的机器思维框架及其具体单元（认知思维单元、输入数据单元、需求单元、心理意象单元）具有新颖性。其重要性在于为实现更接近人类的、自主导向的AI系统提供了潜在途径。然而，摘要中未详细说明具体的验证测试结果，这限制了对其效果的全面评估。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有AI模型能与人类交互并提供满意回复，但它们缺乏自主行动或独立推理的能力，且输入数据通常需显式查询。此外，AI代理在整合跨领域知识方面存在困难。本文的动机是借鉴人类大脑思维过程中心理意象的关键作用，探索如何将其整合到机器思维框架中以启动思维过程。

**Method:** 本文提出一个机器思维框架，该框架整合了一个认知思维单元，并由三个辅助单元支持：输入数据单元、需求单元和心理意象单元。在该框架中，数据以自然语言句子或手绘草图的形式表示，用于信息获取和决策制定。

**Result:** 该框架已进行验证测试，结果已呈现并讨论，但具体内容未在摘要中提及。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 当前的AI系统在自主推理和跨领域知识整合方面存在不足。受人类心理意象在思维过程中作用的启发，本文提出了一种机器思维框架，旨在增强AI的思维能力。该框架包含一个认知思维单元以及输入数据、需求和心理意象三个辅助单元，数据以自然语言或草图形式处理。该框架已通过验证测试。

> **摘要翻译:** 尽管现有模型可以与人类交互并提供满意的回复，但它们缺乏自主行动或独立推理的能力。此外，这些模型中的输入数据通常以显式查询的形式提供，即使某些感官数据已经获取。
此外，人工智能代理作为计算实体，旨在根据其编程、数据输入和学习知识自主执行任务和做出决策，已经取得了显著进展。然而，与人类不同的是，它们在整合跨多个领域的知识方面存在困难。
心理意象在大脑的思维过程中起着基础性作用，它涉及基于内部多感官数据、计划行动、需求和推理能力执行任务。在本文中，我们研究了如何将心理意象整合到机器思维框架中，以及这如何有助于启动思维过程。我们提出的机器思维框架整合了一个认知思维单元，并由三个辅助单元支持：输入数据单元、需求单元和心理意象单元。在该框架中，数据以自然语言句子或手绘草图的形式表示，用于信息获取和决策制定。我们对该框架进行了验证测试，并对结果进行了呈现和讨论。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [23] [MUPAX: Multidimensional Problem Agnostic eXplainable AI](https://arxiv.org/abs/2507.13090)
> *MUPAX: 多维问题无关可解释人工智能*

*Vincenzo Dentamaro, Felice Franchini, Giuseppe Pirlo, Irina Voiculescu* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 可解释人工智能, 模型无关, 收敛性, 特征重要性, 维度无关

**Comment:** 

> **TL;DR:** MUPAX是一种确定性、模型无关且保证收敛的可解释人工智能（XAI）技术，通过测量理论公式和结构化扰动分析提供特征重要性归因，并在各种数据模态和任务中表现出维度无关的有效性，同时提高模型准确性。

**AI_Comments:** MUPAX的创新性在于其结合了确定性、模型无关性和收敛性保证，这在XAI领域是独一无二的。其通过测量理论公式和结构化扰动分析来归因特征重要性，避免了虚假关联，并能在不同维度的数据上保持有效性。更重要的是，它在提供解释的同时还能增强模型精度，解决了现有XAI方法可能导致性能下降的问题，使其在实际应用中更具价值。这是迈向真正可信赖AI的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可解释人工智能（XAI）技术需要更鲁棒的特性，理想情况下应同时具备确定性、模型无关性和收敛性保证。

**Method:** MUPAX采用测量理论公式，通过结构化扰动分析提供有原则的特征重要性归因，以发现固有的输入模式并消除虚假关系。它被设计为确定性、模型无关且保证收敛。

**Result:** MUPAX在音频分类（1D）、图像分类（2D）、体积医学图像分析（3D）和解剖标志物检测等广泛数据模态和任务中进行了评估，展示了维度无关的有效性。它不仅保留而且提高了模型准确性，通过捕获原始数据中最重要的模式。与现有XAI方法相比，它能生成精确、一致和可理解的解释。

**Conclusion:** MUPAX是迈向可解释和可信赖AI系统的关键一步，其严格的收敛保证使其适用于几乎任何AI问题。

> **ai_Abstract:** MUPAX是一种新型的可解释人工智能（XAI）技术，旨在克服现有XAI方法的局限性。它具有确定性、模型无关性，并保证收敛性。该方法基于测量理论公式和结构化扰动分析，能够有效地识别输入模式并消除无关关系，从而提供准确的特征重要性归因。MUPAX在多种数据维度和任务（如音频、图像、医学图像分类和地标检测）上均表现出色，验证了其维度无关的有效性。值得注意的是，MUPAX在提供解释的同时，还能保持甚至提升模型性能，这与传统XAI方法形成对比。研究表明，MUPAX能够生成精确、一致且易于理解的解释，为构建可信赖的AI系统奠定了基础。

> **摘要翻译:** 鲁棒的可解释人工智能（XAI）技术理想情况下应同时具备确定性、模型无关性和收敛性保证。我们提出多维问题无关可解释人工智能（MUPAX），这是一种确定性、模型无关且保证收敛的可解释性技术。MUPAX的测量理论公式通过结构化扰动分析提供有原则的特征重要性归因，能够发现固有的输入模式并消除虚假关系。我们在广泛的数据模态和任务上评估了MUPAX：音频分类（1D）、图像分类（2D）、体积医学图像分析（3D）和解剖标志物检测，展示了维度无关的有效性。严格的收敛保证适用于任何损失函数和任意维度，使得MUPAX几乎适用于任何AI问题背景。与其他通常在遮蔽时降低性能的XAI方法相比，MUPAX不仅保留而且通过捕获原始数据中最重要的模式来实际提高模型准确性。与最先进的XAI技术进行广泛的基准测试表明，MUPAX能够生成精确、一致和可理解的解释，这是迈向可解释和可信赖AI系统的关键一步。源代码将在发布时公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [33] [Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers](https://arxiv.org/abs/2507.13022)
> *基于时序卷积自编码器和校准分类器的空间运载火箭发动机电气系统故障检测与诊断*

*Luis Basora, Louison Bocquet-Nouaille, Elinirina Robinson, Serge Le Gonidec* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 故障检测, 故障诊断, 时序卷积自编码器, 空间运载火箭, 健康监测

**Comment:** 53 pages, 16 figures

> **TL;DR:** 本文提出了一种基于时序卷积自编码器和校准分类器的空间运载火箭发动机电气系统故障检测与诊断系统，旨在解决置信度估计、分布外数据检测和误报控制等关键要求。

**AI_Comments:** 该论文为空间运载火箭健康监测中的一个关键问题提供了一种全面的方法。其优势在于将多种先进技术（时序卷积自编码器、校准分类器、OOD检测、误报控制）集成到一个可配置的框架中，解决了实际操作需求。对置信水平和OOD检测的强调对于安全关键应用尤其具有创新性。然而，依赖模拟数据进行评估是一个局限性，正如作者所承认的，真实世界的验证将至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为下一代可重复使用空间运载火箭的发动机阀门电气系统开发机载故障检测和诊断能力，旨在解决现有方法在置信度估计、分布外（OOD）数据检测和误报控制方面的局限性。

**Method:** 该解决方案使用时序卷积自编码器自动提取原始传感器数据的低维特征。故障检测和诊断分别通过在自编码器潜在空间和残差空间上训练的二元和多类分类器（基于直方图的梯度提升模型）进行，这些分类器经过校准以输出可解释为置信水平的概率。采用归纳共形异常检测技术识别OOD数据，并利用累积和控制图（CUSUM）限制误报，通过阈值移动解决故障检测中的类别不平衡问题。

**Result:** 所提出的框架在模拟数据（涵盖正常和异常操作场景）上进行了评估，结果表明该解决方案是很有希望的第一步。

**Conclusion:** 所提出的解决方案是空间运载火箭发动机电气系统机载故障检测和诊断方面有前景的第一步，但需要通过真实数据进行测试以达到操作使用所需的成熟度水平。

> **ai_Abstract:** 本文提出了一种用于空间运载火箭发动机电气系统的新型机载故障检测和诊断框架。它采用时序卷积自编码器进行特征提取，并使用校准的基于直方图的梯度提升分类器进行检测和诊断。主要创新点包括估计置信水平、利用归纳共形异常检测技术检测分布外数据，以及通过CUSUM等技术控制误报。该框架还解决了类别不平衡问题，并在模拟数据上显示出有前景的结果，标志着可重复使用空间运载火箭健康监测迈出了重要一步。

> **摘要翻译:** 在下一代可重复使用空间运载火箭的健康监测背景下，我们提出了开发用于控制发动机阀门的电气系统机载故障检测和诊断能力的第一步。与现有文献中的方法不同，我们的解决方案旨在满足更广泛的关键要求，包括估计预测的置信水平、检测分布外（OOD）情况以及控制误报。所提出的解决方案基于时序卷积自编码器，用于从原始传感器数据中自动提取低维特征。故障检测和诊断分别使用在自编码器潜在空间和残差空间上训练的二元和多类分类器进行。这些分类器是基于直方图的梯度提升模型，经过校准以输出可解释为置信水平的概率。一种相对简单的技术，基于归纳共形异常检测，用于识别OOD数据。我们利用其他简单但有效的技术，例如累积和控制图（CUSUM）来限制误报，以及阈值移动来解决故障检测中的类别不平衡问题。所提出的框架具有高度可配置性，并已在模拟数据上进行了评估，涵盖了正常和异常操作场景。结果表明，我们的解决方案是很有希望的第一步，尽管需要使用真实数据进行测试，以确保其达到操作使用所需的成熟度水平。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [37] [Trace Reconstruction with Language Models](https://arxiv.org/abs/2507.12927)
> *使用语言模型进行迹线重建*

*Franziska Weindel, Michael Girsch, Reinhard Heckel* | **Category: cs.LG, cs.IT, math.IT** | **Updated: 2025-07-17**

**Keywords:** 迹线重建, 语言模型, DNA数据存储, 错误校正, TReconLM

**Comment:** 

> **TL;DR:** TReconLM利用语言模型在DNA数据存储等应用中实现迹线重建，性能优于现有算法。

**AI_Comments:** 该论文的创新点在于将语言模型应用于迹线重建问题，特别是在处理DNA数据存储中的复杂错误模式方面。通过结合预训练和微调策略，TReconLM有效地适应了真实世界的错误模式，并显著提升了恢复准确性，这对于高密度和长寿命数据存储技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 迹线重建问题旨在从受删除、插入和替换错误污染的噪声副本中恢复原始序列。这在DNA数据存储等应用中非常重要，因为DNA数据存储具有高信息密度和长寿命的优点，但其合成、存储和测序过程中会引入错误，需要通过算法和编码进行校正。

**Method:** 本文提出了TReconLM，它利用在下一词元预测上训练的语言模型进行迹线重建。研究人员在合成数据上预训练语言模型，并在真实世界数据上进行微调，以适应特定于技术错误模式。

**Result:** TReconLM的性能优于最先进的迹线重建算法，包括先前的深度学习方法，能够恢复更高比例的无错误序列。

**Conclusion:** TReconLM通过利用语言模型，显著提高了迹线重建的准确性，尤其适用于DNA数据存储等实际应用。

> **ai_Abstract:** 本研究提出了TReconLM，一种利用语言模型进行迹线重建的新方法。该方法通过在下一词元预测上训练语言模型，并在合成数据上预训练、真实数据上微调，以有效处理由删除、插入和替换引起的噪声。TReconLM在DNA数据存储等应用中表现出色，其性能超越了现有最先进的算法，包括先前的深度学习方法，能够更高比例地无错误恢复序列。

> **摘要翻译:** 迹线重建问题旨在从受删除、插入和替换独立破坏的噪声副本中恢复原始序列。这个问题出现在DNA数据存储等应用中，这是一种因其高信息密度和长寿命而有前景的存储介质。然而，DNA合成、存储和测序过程中引入的错误需要通过算法和编码进行校正，其中迹线重建通常作为数据检索过程的一部分。在这项工作中，我们提出了TReconLM，它利用在下一词元预测上训练的语言模型进行迹线重建。我们在合成数据上预训练语言模型，并在真实世界数据上进行微调，以适应特定于技术的错误模式。TReconLM的性能优于最先进的迹线重建算法，包括先前的深度学习方法，能够恢复更高比例的无错误序列。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [41] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
> *IncA-DES：一种使用在线K-d树邻域搜索的增量自适应动态集成选择方法，用于处理概念漂移数据流*

*Eduardo V. L. Barboza, Paulo R. Lisboa de Almeida, Alceu de Souza Britto Jr., Robert Sabourin, Rafael M. O. Cruz* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 数据流, 概念漂移, 动态集成选择, 在线K-d树, 增量学习

**Comment:** Preprint of article published to Information Fusion

> **TL;DR:** IncA-DES是一种新的方法，它使用在线K-d树进行高效的动态集成选择，以处理概念漂移数据流，实现了高精度和更快的处理速度。

**AI_Comments:** 这篇论文提出了IncA-DES框架，它在处理概念漂移数据流方面具有显著创新。其主要亮点包括：为数据流环境设计的局部专家生成训练策略、融合概念漂移检测器以增强适应性、以及引入一种新颖的基于重叠的分类过滤器以提高效率。特别值得一提的是，论文提出的“在线K-d树”算法，它有效解决了数据流中kNN计算的效率瓶颈和数据不平衡问题，是实时数据流处理的重要贡献。这些创新点的结合使IncA-DES成为一个既准确又高效的解决方案，在挑战性的概念漂移场景下表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 数据流带来了批处理机器学习中不常见的挑战，其中之一是概念漂移。尽管分类器融合方法显示出良好效果，但现有动态集成选择（DES）方法在概念漂移场景下需要更好的适应性，并且其常用的邻域搜索在数据持续到达时可能变得计算成本过高。

**Method:** 本文提出了IncA-DES，一种增量自适应动态集成选择方法。它采用一种训练策略，通过假设特征空间的不同区域随时间可用而促进局部专家的生成。此外，融合了概念漂移检测器以支持信息维护和对新概念的适应。还采用了一种基于重叠的分类过滤器，以避免在邻域内达成共识时使用DS方法。为减少kNN处理时间，提出了一种在线K-d树算法，该算法可以快速移除实例而不会变得不一致，并处理数据流中可能出现的不平衡问题。

**Result:** 实验结果表明，与七种最先进的方法相比，所提出的框架在不同标签可用性水平下获得了最佳平均精度，并且在最准确的方法中处理时间更短。此外，与在线K-d树的融合提高了处理时间，而精度损失可忽略不计。

**Conclusion:** IncA-DES框架，特别是结合在线K-d树，通过提供高精度和高效处理，有效解决了数据流中的概念漂移问题，使其成为一个有前景的解决方案。

> **ai_Abstract:** IncA-DES是一种针对概念漂移数据流提出的增量自适应动态集成选择方法。它通过独特的训练策略生成局部专家，融合概念漂移检测器以适应新概念，并采用基于重叠的分类过滤器。为优化性能，该方法引入了在线K-d树算法，显著减少了kNN处理时间，同时保持高精度。实验结果表明，IncA-DES在精度和处理时间上均优于现有方法。

> **摘要翻译:** 数据流带来了批处理机器学习中不常见的挑战。其中之一是概念漂移，其特点是数据分布随时间变化。在文献中探索的众多方法中，分类器融合显示出良好结果并受到越来越多的关注。DS方法，由于其集成是基于实例的，在漂移场景下似乎是有效的选择。然而，必须注意使这些方法适应概念漂移。训练必须完成以创建局部专家，并且常用的邻域搜索DS方法可能随着数据的持续到达而变得难以承受。在这项工作中，我们提出了IncA-DES，它采用一种训练策略，在假设特征空间的不同区域随时间可用时，促进局部专家的生成。此外，概念漂移检测器的融合支持信息的维护和对新概念的适应。还采用了一种基于重叠的分类过滤器，以避免在邻域内达成共识时使用DS方法，我们认为每种DS方法都应该采用这种策略，因为它已被证明能使其更适用和更快速。此外，为了减少kNN的处理时间，我们提出了一种在线K-d树算法，该算法可以快速移除实例而不会变得不一致，并处理数据流中可能出现的不平衡问题。实验结果表明，与七种最先进的方法相比，所提出的框架在考虑不同标签可用性水平的情况下获得了最佳平均精度，并且在最准确的方法中处理时间更短。此外，与在线K-d树的融合提高了处理时间，而精度损失可忽略不计。我们已将我们的框架在线存储库中提供。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [50] [DOPL: Direct Online Preference Learning for Restless Bandits with Preference Feedback](https://arxiv.org/abs/2410.05527)
> *DOPL：基于偏好反馈的弛豫多臂老虎机直接在线偏好学习*

*Guojun Xiong, Ujwal Dinesha, Debajoy Mukherjee, Jian Li, Srinivas Shakkottai* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-16**

**Keywords:** 弛豫多臂老虎机, 偏好学习, 在线学习, 次线性遗憾, 决策制定

**Comment:** ICLR 2025

> **TL;DR:** 本文提出了DOPL算法，用于解决在偏好反馈而非标量奖励下，弛豫多臂老虎机（RMAB）模型的在线决策问题，并证明了其次线性遗憾界。

**AI_Comments:** 本文的创新点在于首次将偏好反馈引入到弛豫多臂老虎机模型中，并提出了一种直接在线学习算法DOPL来解决由此带来的挑战。其重要性体现在为实际应用中奖励信号难以获取的决策问题提供了新的解决方案，并且在理论上给出了严格的遗憾界证明，填补了该领域的一个空白。该工作为未来在不完整或模糊反馈下的序贯决策研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 弛豫多臂老虎机（RMAB）模型在受限序贯决策问题中应用广泛，但其成功高度依赖于奖励信号的可用性和质量。然而，在实践中精确指定奖励函数可能非常困难甚至不可行。因此，本文旨在解决在仅有成对偏好反馈而非标量奖励的情况下，如何进行弛豫多臂老虎机决策的问题。

**Method:** 本文引入了Pref-RMAB模型，该模型在决策者仅从激活的臂中观察到成对偏好反馈而非标量奖励。为解决这一挑战，作者提出了直接在线偏好学习（DOPL）算法，用于Pref-RMAB模型，旨在有效探索未知环境，在线自适应地收集偏好数据，并直接利用偏好反馈进行决策。

**Result:** DOPL算法被证明能产生次线性遗憾（sublinear regret）。据作者所知，这是第一个能保证弛豫多臂老虎机在偏好反馈下达到$\tilde{\mathcal{O}}(\sqrt{T\ln T})$遗憾的算法。实验结果进一步证明了DOPL的有效性。

**Conclusion:** 本文提出了DOPL算法，首次解决了弛豫多臂老虎机在仅有偏好反馈情况下的在线决策问题，并从理论上证明了其次线性遗憾界，实验也验证了其有效性，为实际应用中难以获得精确奖励信号的场景提供了解决方案。

> **ai_Abstract:** 本文针对弛豫多臂老虎机（RMAB）在难以获取精确标量奖励的实际问题，提出了Pref-RMAB模型，该模型仅依赖于成对偏好反馈。为解决偏好信息量较少带来的挑战，作者提出了直接在线偏好学习（DOPL）算法，该算法能够在线收集和利用偏好数据进行决策。理论分析证明DOPL具有次线性遗憾，并且是首个能保证带有偏好反馈的RMAB达到$\tilde{\mathcal{O}}(\sqrt{T\ln T})$遗憾的算法。实验结果也验证了DOPL的有效性。

> **摘要翻译:** 弛豫多臂老虎机（RMAB）已被广泛用于建模受限序贯决策问题，其中每个弛豫臂的状态根据马尔可夫链演化，并且每次状态转换都会产生一个标量奖励。然而，RMAB的成功关键依赖于奖励信号的可用性和质量。不幸的是，在实践中指定精确的奖励函数可能具有挑战性甚至不可行。在本文中，我们引入了Pref-RMAB，这是一种在存在偏好信号情况下的新型RMAB模型，其中决策者在每个决策周期仅从激活的臂中观察到成对偏好反馈，而不是标量奖励。然而，偏好反馈所包含的信息量可能少于标量奖励，这使得Pref-RMAB看似更困难。为了解决这一挑战，我们提出了一种直接在线偏好学习（DOPL）算法，用于Pref-RMAB，以有效地探索未知环境，以在线方式自适应地收集偏好数据，并直接利用偏好反馈进行决策。我们证明了DOPL产生了次线性遗憾。据我们所知，这是第一个能够确保带有偏好反馈的RMAB达到$\tilde{\mathcal{O}}(\sqrt{T\ln T})$遗憾的算法。实验结果进一步证明了DOPL的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [53] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
> *逆向强化学习遇见大型语言模型后期训练：基础、进展与机遇*

*Hao Sun, Mihaela van der Schaar* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型对齐, 逆向强化学习, 强化学习, 奖励模型, 文献综述

**Comment:** 

> **TL;DR:** 本文综述了通过逆向强化学习（IRL）实现大型语言模型（LLM）对齐的最新进展，强调了与传统RL的区别，并探讨了挑战和机遇。

**AI_Comments:** 这篇综述文章非常有价值，因为它系统地梳理了逆向强化学习在大型语言模型对齐这一前沿领域的应用。它不仅提供了基础概念，还深入探讨了技术差异、实践挑战和未来机遇，对于研究人员理解和进入该领域具有重要的指导意义。强调从人类数据构建奖励模型的必要性是其核心洞见之一。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）时代，对齐（alignment）是一个基础但具有挑战性的问题，关系到机器智能的可靠性、可控性和能力。强化学习（RL）在增强推理模型和对话式AI系统中的关键作用，促使研究人员对RL与LLM对齐的交叉领域产生兴趣。

**Method:** 本文通过逆向强化学习（IRL）的视角，对大型语言模型对齐的最新进展进行了全面综述。具体方法包括：介绍强化学习的基本概念；探讨LLM对齐中RL技术与传统RL任务的区别；强调从人类数据构建神经奖励模型的必要性及其形式和实践意义；审查该研究议程的最新进展，讨论进行LLM对齐的IRL中的关键挑战和机遇；探讨实践方面，包括数据集、基准、评估指标、基础设施以及计算高效的训练和推理技术；从稀疏奖励RL文献中汲取见解，识别未解决的问题和潜在研究方向。

**Result:** 本文提供了一个结构化和批判性的领域概述，强调了未解决的挑战，并概述了通过RL和IRL技术改进LLM对齐的有前景的未来方向。具体成果包括：强调了LLM对齐中RL技术与传统RL任务的区别；提出了从人类数据构建神经奖励模型的必要性及其影响；识别了LLM对齐中IRL的关键挑战和机遇；探讨了实践方面，如数据集、基准、评估指标、基础设施和高效训练/推理技术；识别了未解决的问题和潜在研究方向。

**Conclusion:** 本文旨在通过综合不同研究的发现，提供一个结构化和批判性的领域概述，突出未解决的挑战，并为通过RL和IRL技术改进LLM对齐勾勒出有前景的未来方向。

> **ai_Abstract:** 本文全面综述了通过逆向强化学习（IRL）实现大型语言模型（LLM）对齐的最新进展。文章首先介绍了RL基础，随后深入探讨了LLM对齐中RL与传统RL的区别，特别是构建神经奖励模型的必要性。作者分析了IRL在LLM对齐中的挑战与机遇，并讨论了数据集、评估和高效训练等实践考量。最后，文章从稀疏奖励RL中汲取灵感，指出了未来的研究方向和未解决的问题，旨在为该领域提供结构化且批判性的见解。

> **摘要翻译:** 在大型语言模型（LLMs）时代，对齐已成为追求更可靠、可控和有能力的机器智能中的一个基础性但具有挑战性的问题。推理模型和对话式AI系统最近的成功突显了强化学习（RL）在增强这些系统中的关键作用，从而推动了RL与LLM对齐交叉领域的研究兴趣增加。本文通过逆向强化学习（IRL）的视角，对LLM对齐的最新进展进行了全面综述，强调了LLM对齐中采用的RL技术与传统RL任务之间的区别。特别是，我们强调了从人类数据构建神经奖励模型的必要性，并讨论了这种范式转变的形式和实践意义。我们首先介绍RL的基本概念，为不熟悉该领域的读者提供基础。然后，我们审视了该研究议程的最新进展，讨论了在LLM对齐中进行IRL的关键挑战和机遇。除了方法论的考虑，我们还探讨了实践方面，包括数据集、基准、评估指标、基础设施以及计算高效的训练和推理技术。最后，我们从稀疏奖励RL的文献中汲取见解，以识别未解决的问题和潜在的研究方向。通过综合不同研究的发现，我们旨在提供一个结构化和批判性的领域概述，突出未解决的挑战，并为通过RL和IRL技术改进LLM对齐勾勒出有前景的未来方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [62] [RONOM: Reduced-Order Neural Operator Modeling](https://arxiv.org/abs/2507.12814)
> *RONOM: 降阶神经算子建模*

*Sven Dummer, Dongwei Ye, Christoph Brune* | **Category: cs.LG, cs.CE, cs.NA, math.NA, 65D15, 65D40, 68W25, 65M99, 68T20, 68T07** | **Updated: 2025-07-17**

**Keywords:** 降阶建模, 神经算子, 偏微分方程, 误差估计, 超分辨率

**Comment:** 

> **TL;DR:** RONOM结合降阶建模和神经算子，解决了偏微分方程计算密集且现有方法有局限性的问题，实现了更好的泛化性、超分辨率和离散化鲁棒性，并提供了误差界限。

**AI_Comments:** RONOM的创新之处在于成功融合了降阶建模的理论严谨性（误差界限）和神经算子的灵活性（跨分辨率适应性），为解决偏微分方程的计算密集问题提供了一个更鲁棒和高效的新范式。特别是在超分辨率和离散化鲁棒性方面的提升，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 时间依赖的偏微分方程在物理建模中计算量大，现有降阶模型受限于固定离散化，而神经算子缺乏无限维到离散算子的误差量化。

**Method:** 引入了降阶神经算子建模（RONOM）框架，该框架融合了降阶建模（ROM）和算子学习（neural operators）的概念。研究建立了类似于ROM的离散化误差界限，并提供了对RONOM离散化收敛性和离散化鲁棒性的见解。通过两个数值例子将RONOM与现有神经算子进行了比较。

**Result:** RONOM使用标准向量到向量神经网络，在输入泛化方面与现有神经算子表现相当，但在空间超分辨率和离散化鲁棒性方面表现优越，同时还为时间超分辨率场景提供了新的见解。

**Conclusion:** RONOM框架成功地结合了降阶建模和神经算子，为求解偏微分方程提供了更优的性能和理论保证，尤其在空间超分辨率和离散化鲁棒性方面表现突出。

> **ai_Abstract:** 本文提出了RONOM（降阶神经算子建模）框架，旨在解决时间依赖偏微分方程在多查询场景中的计算挑战。RONOM结合了传统降阶建模的严格误差估计和神经算子的网格适应性，克服了现有方法在固定离散化和误差量化方面的局限。研究建立了RONOM的离散化误差界限，并通过数值实验证明其在空间超分辨率和离散化鲁棒性方面优于现有神经算子，同时在输入泛化方面表现相当。

> **摘要翻译:** 时间依赖的偏微分方程在基于物理的建模中无处不在，但在许多查询场景（例如实时预测、最优控制和不确定性量化）中，它们仍然计算密集。降阶建模（ROM）通过构建低维代理模型来应对这些挑战，但它依赖于固定的离散化，这限制了在评估过程中跨不同网格的灵活性。算子学习方法（例如神经算子）通过参数化无限维函数空间之间的映射提供了一种替代方案，从而能够适应不同分辨率的数据。虽然ROM提供严格的数值误差估计，但神经算子学习主要关注离散化收敛性和不变性，而没有量化无限维算子和离散化算子之间的误差。这项工作引入了降阶神经算子建模（RONOM）框架，它融合了ROM和算子学习的概念。我们建立了类似于ROM中的离散化误差界限，并深入了解了RONOM的离散化收敛性和离散化鲁棒性。此外，本文提出了两个数值例子，将RONOM与现有神经算子在求解偏微分方程方面进行了比较。结果表明，使用标准向量到向量神经网络的RONOM在输入泛化方面表现出可比的性能，在空间超分辨率和离散化鲁棒性方面表现出优越的性能，同时还为时间超分辨率场景提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [63] [Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery](https://arxiv.org/abs/2507.13034)
> *置信度过滤相关性（CFR）：一种用于卫星图像自然度评估的可解释且不确定性感知的机器学习框架*

*Ahmed Emam, Ribana Roscher* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 自然度评估, 卫星图像, 可解释性, 不确定性感知, 机器学习

**Comment:** 

> **TL;DR:** CFR是一个新的机器学习框架，结合LRP Attention Rollout和DDU，用于在卫星图像中评估自然度时考虑模型不确定性对可解释性的影响。研究发现不确定性增加会导致相关性热图的可解释性下降。

**AI_Comments:** 该论文提出了一种创新的数据中心框架CFR，通过整合不确定性估计（DDU）和解释性方法（LRP Attention Rollout），解决了现有机器学习模型在卫星图像自然度评估中缺乏可解释性和不确定性感知的问题。其重要性在于，它不仅提供了更可靠的自然度评估，还量化并展示了不确定性如何影响模型解释的质量，这对于高风险应用场景尤其关键。通过将数据集划分为不同不确定性子集进行分析，CFR提供了一个系统性的方法来深入理解模型行为，这在可解释AI领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的卫星图像自然度评估机器学习方法缺乏可解释性和不确定性感知能力，未能解决不确定性如何影响评估结果的问题。

**Method:** 本文提出了置信度过滤相关性（CFR），一个以数据为中心的框架。它结合了LRP Attention Rollout和深度确定性不确定性（DDU）估计，以分析模型不确定性如何影响相关性热图的可解释性。CFR根据不确定性阈值将数据集划分为子集，从而系统地分析不确定性如何影响卫星图像中自然度解释的形成。

**Result:** 将CFR应用于AnthroProtect数据集，结果显示其将更高的相关性分配给灌木丛、森林和湿地，这与自然度评估的其他研究结果一致。此外，分析表明，随着不确定性的增加，这些相关性热图的可解释性下降，其熵值增加，表明归因的选择性降低且更模糊。

**Conclusion:** CFR提供了一种以数据为中心的方法，用于根据其相关确定性评估卫星图像中模式与自然度的相关性，从而实现可解释且不确定性感知的自然度评估。

> **ai_Abstract:** 本文提出了一种名为置信度过滤相关性（CFR）的机器学习框架，旨在解决卫星图像自然度评估中现有方法缺乏可解释性和不确定性感知的问题。CFR结合了LRP Attention Rollout和深度确定性不确定性（DDU）估计，通过根据不确定性阈值划分数据集，系统地分析模型不确定性如何影响相关性热图的可解释性。在AnthroProtect数据集上的应用显示，CFR能识别出与自然度高度相关的区域（如灌木丛、森林、湿地），并揭示了随着不确定性增加，解释性热图的可解释性降低且归因变得模糊的现象。CFR为基于确定性的卫星图像自然度评估提供了一种数据驱动的可解释方法。

> **摘要翻译:** 受保护的自然区域在生态平衡和生态系统服务中发挥着至关重要的作用。利用卫星图像和机器学习对这些区域进行大规模监测前景广阔，但现有方法往往缺乏可解释性和不确定性感，并且没有解决不确定性如何影响自然度评估的问题。相比之下，我们提出了置信度过滤相关性（CFR），这是一个以数据为中心的框架，它结合了LRP Attention Rollout与深度确定性不确定性（DDU）估计，以分析模型不确定性如何影响相关性热图的可解释性。CFR根据不确定性阈值将数据集划分为子集，从而系统地分析不确定性如何塑造卫星图像中自然度解释。应用于AnthroProtect数据集，CFR将更高的相关性分配给灌木丛、森林和湿地，这与自然度评估的其他研究相符。此外，我们的分析表明，随着不确定性的增加，这些相关性热图的可解释性下降，其熵值增加，表明归因的选择性降低且更模糊。CFR提供了一种以数据为中心的方法，根据其相关确定性评估卫星图像中模式与自然度的相关性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [66] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
> *Assay2Mol：基于大语言模型的生物测定背景下的药物设计*

*Yifan Deng, Spencer S. Ericksen, Anthony Gitter* | **Category: cs.LG, cs.AI, q-bio.QM** | **Updated: 2025-07-16**

**Keywords:** 大语言模型, 药物设计, 生物测定, 分子生成, 上下文学习

**Comment:** 23 pages, 10 figures

> **TL;DR:** Assay2Mol是一个基于大语言模型的药物设计工作流，它利用生物测定数据中的非结构化文本来生成候选分子，并优于现有机器学习方法。

**AI_Comments:** Assay2Mol的创新之处在于其首次将大语言模型应用于利用生物测定中的非结构化文本进行药物设计，有效地解决了传统方法难以处理这类数据的痛点。其重要性在于能够加速早期药物发现过程，并通过生成更易合成的分子来提高药物研发效率。

<details>
  <summary>Details</summary>

**Motivation:** 科学数据库中大量的生物化学筛选测定数据包含丰富的非结构化文本信息，这些信息对新药发现至关重要但未被充分利用。

**Method:** Assay2Mol是一个基于大语言模型的工作流，通过检索与新靶点相似的现有测定记录，并利用检索到的测定筛选数据进行上下文学习来生成候选分子。

**Result:** Assay2Mol在为靶蛋白结构生成候选配体分子方面优于最近的机器学习方法，并且促进了更易合成的分子生成。

**Conclusion:** Assay2Mol成功地利用了生物化学筛选测定中未被利用的非结构化文本数据，显著提升了早期药物发现的效率和分子合成性。

> **ai_Abstract:** 本文介绍了Assay2Mol，一个利用大语言模型（LLM）进行药物设计的新型工作流。Assay2Mol旨在解决生物化学筛选测定中丰富但未被利用的非结构化文本信息的问题。它通过检索相关测定记录并利用上下文学习生成候选分子。研究结果表明，Assay2Mol在生成靶蛋白配体分子方面优于现有机器学习方法，并且能生成更易合成的分子，从而加速早期药物发现。

> **摘要翻译:** 科学数据库汇集了大量的定量数据和描述性文本。在生物化学中，分子筛选测定评估候选分子对疾病靶点的功能反应。描述这些靶点运作的生物学机制、实验筛选方案以及测定其他属性的非结构化文本为新药发现活动提供了丰富的信息，但由于其非结构化格式而未被利用。我们提出了Assay2Mol，一个基于大语言模型的工作流，能够利用现有的大量生化筛选测定数据进行早期药物发现。Assay2Mol检索涉及与新靶点相似的靶点的现有测定记录，并利用检索到的测定筛选数据进行上下文学习来生成候选分子。Assay2Mol优于最近为靶蛋白结构生成候选配体分子的机器学习方法，同时促进了更易合成的分子生成。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [70] [SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks](https://arxiv.org/abs/2501.14048)
> *SIDDA：基于等变神经网络的图像分类Sinkhorn动态域适应*

*Sneh Pandya, Purvik Patel, Brian D. Nord, Mike Walmsley, Aleksandra Ćiprijanović* | **Category: cs.LG, astro-ph.GA, cs.AI, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 域适应, Sinkhorn散度, 等变神经网络, 协变量偏移, 图像分类

**Comment:** 25 pages, 5 figures, 4 tables. code available at:
  https://github.com/deepskies/SIDDA

> **TL;DR:** SIDDA是一种基于Sinkhorn散度的域适应算法，能有效对齐不同域的数据，显著提升神经网络在协变量偏移情况下的泛化能力，尤其与等变神经网络结合时效果更佳。

**AI_Comments:** 该论文提出了一种创新的域适应算法SIDDA，其主要优点在于通过Sinkhorn散度实现了自动化域对齐，显著减少了超参数调优的需求和计算成本，解决了现有DA方法的痛点。SIDDA与等变神经网络的结合尤其具有洞察力，利用了等变性来进一步提升模型的泛化能力和校准性，这对于处理具有特定对称性的数据（如图像）非常重要。其在分类准确率和模型校准方面的显著提升，表明了该方法在实际应用中的巨大潜力，尤其是在需要处理不同域数据的多数据集研究中。

<details>
  <summary>Details</summary>

**Motivation:** 现代神经网络在存在“协变量偏移”（训练和测试数据分布不同但条件标签分布不变）时泛化能力差。现有域适应方法需要大量超参数调优，导致计算成本高昂。

**Method:** 引入SIDDA，一个基于Sinkhorn散度的即插即用域适应训练算法。它旨在以最少的超参数调优和计算开销实现有效的域对齐。该方法与多种NN架构兼容，并与等变神经网络（ENN）结合时效果显著。

**Result:** 在多种模拟和真实数据集（简单形状、手写数字、天文观测）上验证了SIDDA的有效性；SIDDA能增强NN的泛化能力，在未标记目标数据上分类准确率提高约40%；在ENN上，模型性能随等变性程度（二面体群$D_N$的群阶）的增加而提高；SIDDA显著改善了源数据和目标数据的模型校准，ECE和Brier分数提高了超过一个数量级。

**Conclusion:** SIDDA的多功能性及其自动化域对齐方法，有望通过开发高度泛化模型来推动多数据集研究。

> **ai_Abstract:** 该论文介绍了SIDDA，一种基于Sinkhorn散度的即插即用域适应算法，旨在解决神经网络在协变量偏移下泛化能力差且现有域适应方法需要大量超参数调优的问题。SIDDA以最小的开销实现有效的域对齐，并与多种NN架构兼容，尤其与等变神经网络结合时能显著提升分类准确率和模型校准。实验证明，SIDDA能将未标记目标数据上的分类准确率提高约40%，并大幅改善模型校准，展现了其在多数据集研究中的潜力。

> **摘要翻译:** 现代神经网络（NNs）在存在“协变量偏移”时通常泛化能力不佳；即，在训练和测试数据分布不同但分类标签的条件分布保持不变的情况下。在这种情况下，NN的泛化可以简化为学习更多域不变特征的问题。域适应（DA）方法包括一系列旨在实现这一目标的技术；然而，这些方法一直面临需要大量超参数调优的问题，这会带来显著的计算成本。在这项工作中，我们引入了SIDDA，一种基于Sinkhorn散度的即插即用DA训练算法，它能够以最小的超参数调优和计算开销实现有效的域对齐。我们在多种复杂程度不同的模拟和真实数据集上验证了我们方法的有效性，包括简单形状、手写数字和真实天文观测。SIDDA与各种NN架构兼容，并且与等变神经网络（ENNs）结合使用时，在提高分类准确性和模型校准方面表现尤为出色。我们发现SIDDA增强了NN的泛化能力，在未标记目标数据上的分类准确率提高了约40%。我们还研究了DA在ENNs上相对于二面体群$D_N$不同群阶的有效性，并发现模型性能随着等变性程度的增加而提高。最后，我们发现SIDDA在源数据和目标数据上都增强了模型校准——ECE和Brier分数提高了超过一个数量级。SIDDA的多功能性，结合其自动化域对齐方法，有望通过开发高度泛化模型来推动多数据集研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [75] [Retraining-Free Merging of Sparse MoE via Hierarchical Clustering](https://arxiv.org/abs/2410.08589)
> *通过分层聚类实现稀疏MoE的免再训练合并*

*I-Chun Chen, Hsu-Shen Liu, Wei-Fang Sun, Chen-Hao Chao, Yen-Chang Hsu, Chun-Yi Lee* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 稀疏MoE, 分层聚类, 专家合并, 参数缩减, 大型语言模型

**Comment:** Code: https://github.com/wazenmai/HC-SMoE

> **TL;DR:** HC-SMoE是一种无需再训练的专家合并框架，通过分层聚类减少稀疏MoE模型的参数，解决了内存限制问题，并在LLM上表现出色。

**AI_Comments:** 该论文的创新点在于提出了一个“免再训练”且“任务无关”的专家合并框架，这大大降低了SMoE模型部署的成本和复杂性。其基于专家输出的分层聚类方法，能够有效捕捉专家间的功能关系，对于处理大规模LLM架构的内存限制问题具有重要意义。这一方法为SMoE模型在实际应用中的推广提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏混合专家（SMoE）模型在大型语言模型（LLM）开发中通过高效的参数利用率实现了显著的性能提升和推理成本降低。然而，SMoE模型的部署在资源受限环境中面临专家组件内存需求过大的限制。

**Method:** 本文提出了稀疏激活混合专家分层聚类（HC-SMoE），一个无需再训练的任务无关专家合并框架，用于参数缩减。HC-SMoE引入了一种基于专家输出的新型分层聚类方法，以确保合并的鲁棒性，独立于路由决策。这种基于输出的聚类方法能够有效捕获专家之间的功能关系，适用于大规模架构。

**Result:** 理论分析和在多个零样本语言任务上的综合评估表明，HC-SMoE在包括Qwen和Mixtral在内的最先进模型中表现出有效性。实验结果验证了HC-SMoE在实际部署中的卓越性能和实用性。

**Conclusion:** HC-SMoE通过免再训练的专家合并有效解决了稀疏MoE模型的内存限制问题，并在LLM中展现出卓越的性能和实际应用价值。

> **ai_Abstract:** 本文提出HC-SMoE，一个无需再训练的专家合并框架，旨在解决稀疏混合专家（SMoE）模型在资源受限环境中内存需求过大的问题。HC-SMoE采用基于专家输出的分层聚类方法，以实现参数缩减并确保合并的鲁棒性。实验证明，HC-SMoE在Qwen和Mixtral等先进LLM模型上表现出卓越的性能和实际应用价值。

> **摘要翻译:** 稀疏混合专家（SMoE）模型通过高效的参数利用，代表了大型语言模型（LLM）开发的重大进步。这些模型以降低的推理成本实现了显著的性能提升。然而，SMoE模型在资源受限环境中的部署面临专家组件内存需求过大的限制。为了解决这些局限性，本文引入了稀疏激活混合专家分层聚类（HC-SMoE），一个无需再训练的、任务无关的专家合并框架，用于参数缩减。HC-SMoE引入了一种基于专家输出的新型分层聚类方法，以确保合并的鲁棒性，独立于路由决策。所提出的基于输出的聚类方法能够有效捕获专家之间在大型架构中的功能关系。我们提供了理论分析和在多个零样本语言任务上的综合评估，以证明HC-SMoE在包括Qwen和Mixtral在内的最先进模型中的有效性。实验结果验证了HC-SMoE卓越的性能和在实际部署中的实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [91] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
> *排序向量聚类：理论与应用*

*Ali Fattahi, Ali Eshragh, Babak Aslani, Meysam Rabiee* | **Category: cs.LG, cs.CC, stat.AP, stat.ME** | **Updated: 2025-07-16**

**Keywords:** 排序向量聚类, k-中心点, 近似算法, 分支定界, NP-难

**Comment:** 

> **TL;DR:** 研究了排序向量聚类（KRC）问题，证明其NP-难，并提出了高效的近似算法KRCA和分支定界算法BnB，实验证明KRCA优于基线方案。

**AI_Comments:** 这篇论文解决了排序向量聚类这一独特的挑战，其创新点在于明确了KRC与经典KMC的区别，并针对其NP-难特性提出了实用的近似算法KRCA和优化技术BnB。理论分析和实验验证相结合，证明了所提方法的有效性。这项工作为处理复杂偏好数据提供了新的工具和见解，对于推荐系统和决策支持等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决排序向量聚类问题，其中观测值和质心都是排序向量，与经典k-means不同。这对于个性化和大规模决策具有实际意义。

**Method:** 证明了KRC的NP-难性并刻画了其可行集。对于单簇情况，推导了最优质心的线性时间闭式解析解。开发了高效的近似算法KRCA，通过迭代改进KMC的初始解。引入了分支定界（BnB）算法，用于KRCA内部的有效簇重建，利用决策树框架减少计算时间，并通过控制参数平衡解质量和效率。建立了KRCA和BnB的理论误差界。

**Result:** KRCA在合成和真实世界数据集上始终优于基线解决方案。KRCA在解质量方面取得了显著改进，同时计算时间快速。

**Conclusion:** KRC对个性化和大规模决策具有实际意义，该工作提供了方法论上的进步和见解，可供未来研究借鉴。

> **ai_Abstract:** 这项工作研究了排序向量聚类（KRC）问题，它将偏好表示为排序列表。与传统k-means不同，KRC要求观测值和质心均为排序向量。论文证明了KRC的NP-难性，并为单簇情况提供了线性时间的最优解。为了应对计算挑战，提出了一种高效的近似算法KRCA，该算法通过迭代优化KMC初始解来提高性能，并结合了分支定界（BnB）算法进行簇重建。实验结果表明，KRCA在解质量和计算效率上均显著优于基线方法，突出了KRC在个性化和大规模决策中的应用潜力。

> **摘要翻译:** 我们研究排序向量聚类问题，其中每个向量表示为有序的、不同整数的列表的偏好。具体来说，我们关注k-中心点排序向量聚类问题（KRC），其目标是将一组排序向量划分为k个簇并识别每个簇的中心点。与经典的k-均值聚类（KMC）不同，KRC要求观测值和中心点都是排序向量。我们确定了KRC的NP-难性并刻画了其可行集。对于单簇情况，我们推导了最优中心点的闭式解析解，可以在线性时间内计算。为了解决KRC的计算挑战，我们开发了一种高效的近似算法KRCA，它迭代地改进来自KMC的初始解，即基线解。此外，我们引入了一种分支定界（BnB）算法，用于KRCA内部的有效簇重建，利用决策树框架减少计算时间，同时引入一个控制参数来平衡解质量和效率。我们建立了KRCA和BnB的理论误差界。通过对合成数据集和真实世界数据集进行广泛的数值实验，我们证明了KRCA始终优于基线解，在解质量方面取得了显著改进，同时计算时间快速。这项工作突出了KRC在个性化和大规模决策中的实际意义，提供了方法论上的进步和见解，可在未来的研究中加以借鉴。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [93] [The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting](https://arxiv.org/abs/2507.13043)
> *架构的力量：深入探究用于长期时间序列预测的Transformer架构*

*Lefei Shen, Mouxiang Chen, Han Fu, Xiaoxue Ren, Xiaoyun Joy Wang, Jianling Sun, Zhuo Li, Chenghao Liu* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** Transformer架构, 长期时间序列预测, 注意力机制, 预测范式, 架构分类

**Comment:** 15 pages, 6 figures

> **TL;DR:** 该研究提出了一种新颖的分类法，用于解耦和比较Transformer架构在长期时间序列预测（LTSF）中的表现，发现特定注意力机制、预测聚合和预测范式表现最佳，并构建了一个性能优于现有模型的组合模型。

**AI_Comments:** 该论文的创新之处在于提出了一个新颖的分类法，有效地解耦了Transformer架构在时间序列预测中的复杂设计元素，从而能够系统地评估不同架构选择的影响。这一方法克服了现有模型紧密耦合的局限性，为理解和优化Transformer架构提供了清晰的路径。其重要性在于，通过揭示最佳的注意力机制、预测聚合和预测范式，为未来LTSF领域的研究和模型开发提供了宝贵的实践指导和理论基础。该研究的结果具有很强的实用性，能够帮助研究人员和开发者构建更高效的长期时间序列预测模型。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于Transformer的模型在长期时间序列预测（LTSF）中占据主导地位，但其架构变体（如仅编码器、编码器-解码器和仅解码器设计）对性能的影响尚不明确。现有模型往往与各种时间序列特定设计紧密耦合，使得难以单独评估架构本身的影响，因此需要一种方法来清晰地比较这些架构。

**Method:** 研究提出了一种新颖的分类法，用于解耦Transformer架构中的各种设计，包括注意力机制、预测聚合、预测范式和归一化层，从而实现对Transformer架构更清晰、更统一的比较。通过广泛的实验来评估这些不同架构选择的影响。

**Result:** 实验揭示了几个关键发现：双向注意力与联合注意力结合最为有效；更完整的预测聚合能够提高性能；直接映射范式优于自回归方法。此外，结合了这些最佳架构选择的组合模型，持续优于多个现有模型。

**Conclusion:** 这些发现为未来在长期时间序列预测中Transformer架构设计的研究提供了宝贵的指导。

> **ai_Abstract:** 该论文旨在解决Transformer架构在长期时间序列预测（LTSF）中性能评估的挑战，因为现有模型的设计复杂且难以解耦。研究提出了一种新颖的分类法，用于系统地解耦和比较Transformer架构的关键组成部分，包括注意力机制、预测聚合、预测范式和归一化层。通过广泛的实验，研究发现双向注意力与联合注意力的结合、更完整的预测聚合以及直接映射范式对LTSF任务最为有效。基于这些发现构建的组合模型在性能上持续超越了现有模型，为未来Transformer架构在LTSF中的设计提供了清晰的指导。

> **摘要翻译:** 基于Transformer的模型最近在长期时间序列预测（LTSF）中占据主导地位，然而，其架构变体，如仅编码器、编码器-解码器和仅解码器设计，提出了一个关键问题：哪种Transformer架构最适合LTSF任务？然而，现有模型通常与各种时间序列特定设计紧密耦合，这使得难以隔离架构本身的影响。为了解决这个问题，我们提出了一种新颖的分类法，将这些设计解耦，从而能够对Transformer架构进行更清晰、更统一的比较。我们的分类法考虑了注意力机制、预测聚合、预测范式和归一化层等关键方面。通过广泛的实验，我们揭示了几个关键见解：双向注意力与联合注意力结合最为有效；更完整的预测聚合能够提高性能；直接映射范式优于自回归方法。此外，我们结合了最佳架构选择的模型，持续优于多个现有模型，这进一步证实了我们结论的有效性。我们希望这些发现能为未来在LTSF中Transformer架构设计的研究提供宝贵的指导。我们的代码可在https://github.com/HALF111/TSF_architecture 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [95] [Improving Transformer World Models for Data-Efficient RL](https://arxiv.org/abs/2502.01591)
> *改进Transformer世界模型以实现数据高效的强化学习*

*Antoine Dedieu, Joseph Ortiz, Xinghua Lou, Carter Wendelken, Wolfgang Lehrach, J Swaroop Guntupalli, Miguel Lazaro-Gredilla, Kevin Patrick Murphy* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-16**

**Keywords:** Transformer世界模型, 数据高效强化学习, 基于模型的强化学习, Craftax-classic, Dyna

**Comment:** ICML 2025

> **TL;DR:** 该论文提出了Transformer世界模型在数据高效强化学习方面的三项改进，显著提升了性能，并在Craftax-classic基准上首次超越人类表现。

**AI_Comments:** 本文通过引入“预热Dyna”、改进的“最近邻分词器”和“块教师强制”三项创新，显著提升了Transformer世界模型在数据高效强化学习中的性能。尤其在Craftax-classic基准上首次超越人类表现，这标志着模型强化学习领域的重要进展，并展示了其在复杂环境中的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进标准基于Transformer的模型强化学习范式，解决现有方法在数据效率、图像补丁分词方案以及未来令牌生成方式上的不足。

**Method:** 提出了三项改进：(a) “预热Dyna”，策略训练在模型充分训练后才开始使用想象数据；(b) 图像补丁的“最近邻分词器”，通过确保码字静态来改进分词，为TWM学习提供恒定目标；(c) “块教师强制”，允许Transformer世界模型联合推理下一时间步的未来令牌，而非顺序生成。

**Result:** 在多个环境中显著优于现有方法。在Craftax-classic基准测试中，1M环境步后获得69.66%的奖励，显著优于DreamerV3的53.2%，并首次超越人类表现（65.0%）。初步结果还显示了该方法在Craftax-full、MinAtar和三种双人游戏中的普适性。

**Conclusion:** 该论文提出的Transformer世界模型改进显著提升了数据高效强化学习的性能，在挑战性基准测试中取得了最先进的结果，甚至首次超越了人类表现，并展示了该方法的普适性。

> **ai_Abstract:** 本文针对数据高效强化学习中的Transformer世界模型（TWM）提出了三项改进：引入“预热Dyna”以优化策略训练、使用“最近邻分词器”改进图像补丁分词，以及采用“块教师强制”实现对未来令牌的联合推理。实验结果表明，该方法在多个环境中显著超越现有技术，尤其在Craftax-classic基准上，首次以69.66%的奖励超越了人类表现（65.0%），并展现了良好的普适性。

> **摘要翻译:** 我们提出了对基于Transformer的标准模型强化学习范式的三项改进：(a) “预热Dyna”，它在真实和想象数据上训练策略，但仅在世界模型充分训练后才开始使用想象数据；(b) 用于图像补丁的“最近邻分词器”，通过确保码字在创建后是静态的，从而为TWM学习提供恒定目标，改进了之前在使用Transformer世界模型（TWM）时所需的分词方案；以及(c) “块教师强制”，它允许TWM联合推理下一时间步的未来令牌，而不是顺序生成它们。然后我们展示了我们的方法在各种环境中显著优于现有方法。我们主要关注具有挑战性的Craftax-classic基准，我们的方法在仅1M环境步后就获得了69.66%的奖励，显著优于DreamerV3的53.2%，并首次超越了人类表现的65.0%。我们还在Craftax-full、MinAtar和三种不同的双人游戏上展示了初步结果，以说明该方法的普适性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [100] [Data-driven rainfall prediction at a regional scale: a case study with Ghana](https://arxiv.org/abs/2410.14062)
> *数据驱动的区域尺度降雨预测：以加纳为例*

*Indrajit Kalita, Lucia Vilallonga, Yves Atchade* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 降雨预测, 数据驱动, 机器学习, U-Net CNN, 加纳, 热带地区

**Comment:** 

> **TL;DR:** 本研究开发了两个基于U-Net CNN的数据驱动模型，用于预测加纳的24小时降雨，并在12小时提前期表现优于或媲美ECMWF的18小时提前期预报，结合传统数值天气预报可进一步提高准确性。

**AI_Comments:** 这篇论文通过结合深度学习（U-Net CNN）和大规模气象数据，解决了传统数值天气预报在热带地区降雨预测方面的不足。其创新之处在于不仅提出了有效的数据驱动模型，还特别关注了模型的可解释性，通过开发新颖的统计方法来揭示气象变量对降雨的影响，这对于理解复杂的气候现象具有重要意义。此外，与现有先进模型的对比以及与传统NWP结合的探索，也展现了其方法的实用性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 热带地区面临更强烈和不稳定的降雨事件，现有数值天气预报模型在非洲热带地区降雨预报方面表现不佳，因此迫切需要改进这些地区的降雨预报。

**Method:** 使用ERA5和GPM-IMERG数据集训练了两个U-Net卷积神经网络(CNN)模型，用于预测加纳24小时降雨（12小时和30小时提前期）。开发了一种新颖的统计方法来探究输入模型的气象变量的相对重要性。

**Result:** 经验表明，12小时提前期模型的性能与ECMWF（TIGGE数据集中的18小时提前期预报）相当，某些方面甚至更好。将数据驱动模型与经典数值天气预报结合可进一步提高预报准确性。

**Conclusion:** 数据驱动模型在热带地区降雨预测方面表现出色，并能通过与传统数值天气预报结合进一步提升性能，为理解降雨驱动因素提供洞察。

> **ai_Abstract:** 本研究针对非洲热带地区降雨预报的挑战，以加纳为例，利用ERA5和GPM-IMERG数据集开发了基于U-Net CNN的数据驱动模型，以预测24小时降雨。模型在12小时提前期表现出与ECMWF预报媲美甚至更优的性能，并且通过与传统数值天气预报结合可进一步提高准确性。研究还开发了新颖的统计方法来提升模型可解释性，揭示了驱动降水的气象变量的重要性。

> **摘要翻译:** 随着地球变暖，热带地区预计将首当其冲地经历气候变化，伴随着更强烈和更不稳定的降雨事件。目前，最先进的数值天气预报（NWP）模型在非洲热带地区难以做出熟练的降雨预报。因此，这些地区迫切需要改进降雨预报。在过去十年左右的时间里，大规模气象数据集可用性的增加以及强大的机器学习模型的发展为数据驱动的天气预报开辟了新的机遇。本研究以加纳为重点，利用这些工具开发了两个U-Net卷积神经网络（CNN）模型，用于预测12小时和30小时提前期的24小时降雨。模型使用ERA5再分析数据集和GPM-IMERG数据集的数据进行训练。研究特别关注了可解释性。我们开发了一种新颖的统计方法，使我们能够探究输入模型的气象变量的相对重要性，为加纳地区降水驱动因素提供了有益的见解。经验上，我们发现我们的12小时提前期模型的性能与ECMWF（TIGGE数据集中可用的18小时提前期预报）的性能相匹配，在某些方面甚至更好。我们还发现，将我们的数据驱动模型与经典NWP相结合可以进一步提高预报准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [107] [From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning](https://arxiv.org/abs/2507.12815)
> *从新颖到模仿：离线强化学习中的自蒸馏奖励*

*Gaurav Chaudhary, Laxmidhar Behera* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 离线强化学习, 奖励标注, 随机网络蒸馏, 内在奖励, D4RL

**Comment:** 

> **TL;DR:** ReLOAD是一种新颖的离线强化学习奖励标注框架，它通过适应随机网络蒸馏（RND）从专家演示中生成内在奖励，无需显式奖励标注，并在D4RL基准测试中表现出色。

**AI_Comments:** 该论文提出了一种新颖且实用的方法ReLOAD，通过将随机网络蒸馏（RND）应用于离线强化学习的奖励标注问题，有效解决了显式奖励依赖的痛点。其创新点在于将RND的预测误差转化为内在奖励信号，避免了复杂对齐过程和手动标注。理论支撑和D4RL基准测试上的良好表现增强了其重要性，为离线RL在数据不带奖励的场景下提供了解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 离线强化学习的实际应用常受限于需要显式奖励标注，这可能成本高昂或难以追溯获得。

**Method:** 我们提出了ReLOAD框架，通过适应随机网络蒸馏（RND）从专家演示中生成内在奖励。具体地，训练一个预测器网络来模仿固定目标网络的嵌入，然后这些网络之间的预测误差作为静态数据集中每个转换的奖励信号。该机制在不需要手工制作奖励标注的情况下提供结构化奖励信号。此外，提供了正式的理论构建来阐明RND预测误差如何通过区分专家类转换有效作为内在奖励。

**Result:** 在D4RL基准测试上的实验表明，ReLOAD能够实现鲁棒的离线策略学习，并取得了与传统奖励标注方法相当的性能。

**Conclusion:** ReLOAD通过自蒸馏奖励机制有效地解决了离线强化学习中显式奖励标注的挑战，使得在无外部奖励情况下也能进行有效的策略学习，并达到了与有奖励方法相当的性能。

> **ai_Abstract:** ReLOAD是一个用于离线强化学习的新型奖励标注框架，旨在解决显式奖励标注成本高昂的问题。该方法通过适应随机网络蒸馏（RND），从专家演示中生成内在奖励，具体为训练一个预测器网络模仿目标网络的嵌入，并利用预测误差作为奖励信号。理论分析表明RND预测误差能有效区分专家类转换。实验证明，ReLOAD在D4RL基准测试上实现了鲁棒的离线策略学习，并达到了与传统奖励标注方法相当的性能。

> **摘要翻译:** 离线强化学习（RL）旨在从静态数据集中学习有效的策略，而无需进一步的智能体-环境交互。然而，其实际应用常常受到需要显式奖励标注的阻碍，这可能成本高昂或难以追溯获得。为了解决这个问题，我们提出了ReLOAD（通过蒸馏进行离线奖励标注的强化学习），一个用于离线RL的新型奖励标注框架。与依赖复杂对齐过程的现有方法不同，我们的方法通过适应随机网络蒸馏（RND），使用简单而有效的嵌入差异度量，从专家演示中生成内在奖励。首先，我们训练一个预测器网络，根据专家状态转换来模仿固定目标网络的嵌入。随后，这些网络之间的预测误差作为静态数据集中每个转换的奖励信号。这种机制在不需要手工制作奖励标注的情况下提供了结构化奖励信号。我们提供了一个正式的理论构建，它提供了关于RND预测误差如何通过区分专家类转换有效作为内在奖励的见解。在D4RL基准测试上的实验表明，ReLOAD能够实现鲁棒的离线策略学习，并取得了与传统奖励标注方法相当的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [121] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
> *通过投注损失实现[0,1]值回归的二阶界*

*Yinan Li, Kwang-Sung Jun* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** [0,1]值回归, 二阶界, 投注损失, 泛化界, 方差自适应

**Comment:** 

> **TL;DR:** 本文提出了一种名为“投注损失”的新型损失函数，用于[0,1]值回归问题，它能在不知道方差的情况下实现方差依赖的（二阶）泛化界，从而严格改进了现有的（一阶）界。

**AI_Comments:** 本文的创新点在于提出了“投注损失”这一新型损失函数，并成功地将其应用于[0,1]值回归问题，实现了方差自适应的二阶泛化界。这一成果是对现有泛化界理论的严格改进，因为它在不依赖方差先验知识的情况下，提供了更紧密的误差上界。这对于实际应用中方差难以估计或变化的情况具有重要意义，尤其是在与分布强化学习等领域进行对比时，其无需显式建模方差的特性更显优势。

<details>
  <summary>Details</summary>

**Motivation:** 在[0,1]值回归问题中，对数损失函数可以实现一阶泛化界。作者旨在探究是否存在一种损失函数能实现方差依赖的（二阶）界，这比一阶界有严格的改进。

**Method:** 作者通过提出一种名为“投注损失”（betting loss）的新型损失函数来解决问题。

**Result:** 研究表明，对数损失函数在[0,1]值回归中能产生类似的一阶界。更重要的是，所提出的投注损失函数能够实现方差依赖的（二阶）界，并且这种界是“方差自适应”的，即在不知道方差的情况下也能达到。

**Conclusion:** 投注损失函数为[0,1]值回归问题提供了一种严格优于现有方法的、方差自适应的二阶泛化界。

> **ai_Abstract:** 本文研究了独立同分布设置下的[0,1]值回归问题。在现有研究表明对数损失能达到一阶界的基础上，本文进一步探究是否存在能实现方差依赖的二阶界。通过引入一种新颖的“投注损失”函数，作者证明了这种损失函数能够实现严格优于一阶界的方差自适应二阶界，且无需事先了解方差信息。

> **摘要翻译:** 我们考虑独立同分布设置下的[0,1]值回归问题。在一个相关的、称为成本敏感分类的问题中，\citet{foster21efficient}已表明对数损失最小化器比平方损失最小化器实现了改进的泛化界，因为该界限与最佳分类器的成本成比例缩放，而该成本根据具体问题可以任意小。这样的结果通常被称为一阶界。对于[0,1]值回归，我们首先表明对数损失最小化器也能产生类似的一阶界。然后我们询问是否存在一种损失函数可以实现方差依赖的界限（也称为二阶界），它是一阶界的严格改进。我们通过提出一种新颖的损失函数——投注损失——肯定地回答了这个问题。我们的结果是“方差自适应”的，因为该界限是在	extit{不知道任何方差信息}的情况下获得的，这与将标签（或奖励）方差或标签分布本身明确地建模为函数类的一部分（例如在分布强化学习中）形成对比。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [123] [On statistical learning of graphs](https://arxiv.org/abs/2507.13054)
> *关于图的统计学习*

*Vittorio Cipriani, Valentino Delle Rose, Luca San Mauro, Giovanni Solda* | **Category: cs.LG, math.LO** | **Updated: 2025-07-17**

**Keywords:** 统计学习, 图, PAC可学习性, 在线可学习性, 置换

**Comment:** 

> **TL;DR:** 本文研究了可数无限图G的假设类的PAC和在线可学习性，其中每个副本通过置换G的顶点而产生。主要结果表明，所有此类有限支持副本的PAC可学习性意味着G的完整同构类型的在线可学习性，并等同于自同构平凡性条件。文章还刻画了不可学习的图，并证明了k-顶点置换的可学习性等同于2-顶点置换的可学习性，从而产生了无限图的四类划分。

**AI_Comments:** 本文的创新之处在于将图的统计学习问题与图论、描述集合论和可计算性理论相结合，为理解无限图的可学习性提供了新的视角和分类方法。通过引入“自同构平凡性”等概念，为图的可学习性提供了严格的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 研究可数无限图G的假设类的PAC和在线可学习性，其中每个副本通过置换G的顶点而产生，这对应于在已知图结构和标签集的情况下学习图的标签。

**Method:** 研究了由可数无限图G的副本形成的假设类的PAC和在线可学习性，其中每个副本通过置换G的顶点而产生。考虑了置换只移动有限个顶点的类别。利用描述集合论和可计算性理论的工具来确定复杂性。

**Result:** 主要结果表明，所有此类有限支持副本的PAC可学习性意味着G的完整同构类型的在线可学习性，并等同于自同构平凡性条件。刻画了通过交换两个顶点而产生的副本不可学习的图，使用了无限随机图的扩展性质的放宽。对于所有G和k>2，k-顶点置换的可学习性等同于2-顶点置换的可学习性，这产生了无限图的四类划分，并确定了其复杂性。

**Conclusion:** 本文确定了无限图在不同顶点置换下的可学习性条件，并提出了一个基于可学习性的四类划分，其复杂性可以通过描述集合论和可计算性理论的工具来确定。

> **ai_Abstract:** 本文探讨了可数无限图在顶点置换下的统计学习问题，特别是PAC和在线可学习性。研究发现，有限支持置换的可学习性与图的自同构平凡性以及完整同构类型的在线可学习性等价。文章还刻画了特定条件下不可学习的图，并证明了多顶点置换的可学习性可归结为两顶点置换的可学习性，从而将无限图划分为四类，并分析了其复杂性。

> **摘要翻译:** 我们研究了由可数无限图G的副本形成的假设类的PAC和在线可学习性，其中每个副本通过置换G的顶点而产生。这对应于在已知图结构和标签集的情况下学习图的标签。我们考虑了置换只移动有限个顶点的类别。我们的主要结果表明，所有此类有限支持副本的PAC可学习性意味着G的完整同构类型的在线可学习性，并等同于自同构平凡性条件。我们还使用无限随机图的扩展性质的放宽，刻画了通过交换两个顶点而产生的副本不可学习的图。最后，我们表明，对于所有G和k>2，k-顶点置换的可学习性等同于2-顶点置换的可学习性，这产生了无限图的四类划分，我们还使用描述集合论和可计算性理论的工具确定了其复杂性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [124] [Deep Q-Learning with Gradient Target Tracking](https://arxiv.org/abs/2503.16700)
> *具有梯度目标跟踪的深度Q学习*

*Donghwan Lee, Bum Geun Park, Taeho Lee* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** Q学习, 深度Q网络, 梯度目标跟踪, 强化学习, 连续更新

**Comment:** 

> **TL;DR:** 本文提出了一种新的深度Q学习框架，通过梯度目标跟踪实现连续的目标网络更新，以替代传统的硬更新机制，从而消除了手动调整更新周期的需要。

**AI_Comments:** 这项工作创新性地将梯度下降应用于Q学习中的目标网络更新，成功地将离散的硬更新转化为连续的学习过程。这不仅简化了超参数调优，还可能提高训练的稳定性。其理论分析和实证结果为强化学习领域提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 标准深度Q网络（DQN）中的目标网络硬更新机制虽然稳定了训练，但需要仔细调整硬更新周期以实现最佳性能，这是一个挑战。

**Method:** 提出了两种基于梯度的目标更新方法：DQN非对称梯度目标跟踪（AGT2-DQN）和DQN对称梯度目标跟踪（SGT2-DQN）。这些方法使用梯度下降进行连续和结构化的更新，取代了传统的硬目标更新。

**Result:** 提供了这些方法在表格设置中收敛的理论分析。经验评估表明它们优于标准DQN基线。

**Conclusion:** 基于梯度的目标更新可以作为Q学习中传统目标更新机制的有效替代方案。

> **ai_Abstract:** 本文提出了一种名为Q学习与梯度目标跟踪的新型强化学习框架，旨在解决标准DQN中目标网络硬更新机制需要手动调优的问题。作者引入了两种基于梯度的方法：AGT2-DQN和SGT2-DQN，它们通过连续的梯度下降更新取代了传统的周期性硬更新。研究提供了理论收敛性证明，并通过实验验证了其优于现有DQN基线的性能，表明梯度目标更新是传统方法的有效替代。

> **摘要翻译:** 本文介绍了具有梯度目标跟踪的Q学习，这是一种新颖的强化学习框架，它提供了一种学习到的连续目标更新机制，作为传统硬更新范式的替代。在标准深度Q网络（DQN）中，目标网络是在线网络权重的副本，在一定数量的迭代中保持固定，然后通过硬更新周期性地替换。虽然这通过提供一致的目标来稳定训练，但它引入了一个新的挑战：必须仔细调整硬更新周期以实现最佳性能。为了解决这个问题，我们提出了两种基于梯度的目标更新方法：DQN非对称梯度目标跟踪（AGT2-DQN）和DQN对称梯度目标跟踪（SGT2-DQN）。这些方法通过使用梯度下降进行连续和结构化的更新来取代传统的硬目标更新，从而有效地消除了手动调整的需要。我们提供了理论分析，证明了这些方法在表格设置中的收敛性。此外，经验评估表明它们优于标准DQN基线，这表明基于梯度的目标更新可以作为Q学习中传统目标更新机制的有效替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [125] [UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning](https://arxiv.org/abs/2502.15082)
> *UPCORE：用于平衡遗忘的效用保留核心集选择*

*Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-16**

**Keywords:** 模型遗忘, 数据选择, 核心集, 效用保留, 大型语言模型

**Comment:** Code: https://github.com/Vaidehi99/UPCORE

> **TL;DR:** UPCORE通过选择性修剪遗忘集中的异常值来减少模型遗忘时的性能下降，实现删除效率和模型保留的更好平衡。

**AI_Comments:** UPCORE的创新之处在于它将模型表示的方差与模型损伤关联起来，并据此进行数据选择性修剪，以实现更平衡的遗忘。其方法无关性使其具有广泛适用性。引入新的AUC指标也为评估遗忘效果提供了更全面的视角。这对于当前LLM等大型模型的信息删除和隐私保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 用户规范或法律框架要求从预训练模型（包括LLMs）中删除信息，但这通常会导致模型在其他数据点上的性能下降。因此，需要在信息删除和保持模型其他能力完好无损之间取得平衡，否则会导致删除效果差或模型不可用。

**Method:** 本文提出了UPCORE (Utility-Preserving Coreset Selection)，一个与方法无关的数据选择框架，用于减轻遗忘过程中的附带损害。该方法发现模型损伤与遗忘集上模型表示的方差相关，因此通过选择性修剪遗忘集中的异常值来最小化遗忘后的模型退化。为更好地评估权衡，还引入了一个新的衡量指标：标准指标下的曲线下面积（AUC）。

**Result:** UPCORE在三种标准遗忘方法上，始终在删除效率和模型保留这两个竞争目标之间实现了卓越的平衡。结果表明，UPCORE改进了标准指标和AUC，受益于核心集和修剪点之间的正向迁移，同时减少了从遗忘集到其外部点的负向迁移。

**Conclusion:** UPCORE通过优化遗忘集选择，有效解决了模型遗忘过程中的性能退化问题，实现了删除效果和模型实用性之间的最佳平衡。

> **ai_Abstract:** 本文提出UPCORE，一种与方法无关的数据选择框架，旨在解决模型遗忘（即从预训练模型中删除数据点）时导致的性能下降问题。UPCORE通过识别并修剪遗忘集中模型表示方差较大的异常值，从而最小化模型退化。实验证明，UPCORE在多种遗忘方法上均能有效平衡数据删除效率与模型性能保持，并引入新的AUC指标来评估这种权衡，显示出其在提升模型性能和减少负向迁移方面的优势。

> **摘要翻译:** 用户规范或法律框架通常要求从预训练模型（包括大型语言模型LLMs）中删除信息。这需要从已经训练好的模型中删除或“遗忘”一组数据点，这通常会降低模型在其他数据点上的性能。因此，必须在删除信息和保持模型其他能力完好无损之间取得平衡，未能平衡这种权衡会导致删除效果差或模型不可用的模型。为此，我们提出了UPCORE（Utility-Preserving Coreset Selection），一个与方法无关的数据选择框架，用于减轻遗忘过程中的附带损害。我们发现模型损伤与模型在遗忘集上表示的方差相关，我们选择性地修剪遗忘集以移除异常值，从而最大限度地减少遗忘后的模型退化。在三种标准遗忘方法中，UPCORE始终在删除效率和模型保留这两个竞争目标之间实现了卓越的平衡。为了更好地评估这种权衡，我们引入了一个新的指标，衡量标准指标下的曲线下面积（AUC）。我们的结果表明，UPCORE改进了标准指标和AUC，受益于核心集和修剪点之间的正向迁移，同时减少了从遗忘集到其外部点的负向迁移。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [131] [Golden Noise for Diffusion Models: A Learning Framework](https://arxiv.org/abs/2411.09502)
> *扩散模型中的黄金噪声：一个学习框架*

*Zikai Zhou, Shitong Shao, Lichen Bai, Shufei Zhang, Zhiqiang Xu, Bo Han, Zeke Xie* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 扩散模型, 黄金噪声, 噪声提示, 噪声提示网络, 图像生成

**Comment:** 

> **TL;DR:** 本文提出了一种名为“噪声提示”的新概念，并构建了一个学习框架、数据集和网络（NPNet），以将随机噪声转化为能提高扩散模型生成图像质量的“黄金噪声”，且NPNet是一个高效的即插即用模块。

**AI_Comments:** 该论文提出“噪声提示”这一创新概念，并通过学习框架、数据集和小型网络NPNet，解决了扩散模型中获取“黄金噪声”的难题。NPNet作为即插即用模块，显著提升了生成图像的质量和泛化能力，且具有高效、低成本的优点，为扩散模型优化提供了一条新颖且实用的路径。

<details>
  <summary>Details</summary>

**Motivation:** 当前文本到图像扩散模型虽然能生成个性化图像，但发现有些随机噪声（“黄金噪声”）能带来更好的文本-图像对齐和更高的人类偏好，而目前缺乏一个机器学习框架来获取这些“黄金噪声”。

**Method:** 本文引入了“噪声提示”概念，通过添加与文本提示相关的微小扰动将随机高斯噪声转化为黄金噪声。提出了“噪声提示学习”框架，并设计了噪声提示数据收集流程，构建了一个包含10万对随机噪声、黄金噪声和相关文本提示的大规模噪声提示数据集（NPD）。基于NPD训练了一个小型噪声提示网络（NPNet），可以直接学习将随机噪声转化为黄金噪声。

**Result:** 实验证明NPNet在SDXL、DreamShaper-xl-v2-turbo和Hunyuan-DiT等多种扩散模型上有效提高了生成图像的质量和泛化能力。NPNet是一个小型高效的即插即用模块，仅提供黄金噪声，无需访问原始管道，额外推理和计算成本非常有限。

**Conclusion:** 本文成功开发并验证了一个用于学习扩散模型中“黄金噪声”的框架和网络（NPNet），显著提升了文本到图像生成质量，且具有高效和即插即用的优点。

> **ai_Abstract:** 本文提出了一个用于扩散模型的黄金噪声学习框架。作者引入了“噪声提示”概念，旨在通过添加与文本提示相关的扰动将随机噪声转化为能提升图像质量的“黄金噪声”。为此，他们构建了一个噪声提示学习框架、一个包含10万对噪声-提示的大规模数据集（NPD），并训练了一个小型网络NPNet。实验证明NPNet能有效提高SDXL等多种扩散模型生成图像的质量和泛化能力，且作为一个即插即用模块，额外成本极低。

> **摘要翻译:** 文本到图像扩散模型是一种流行的范式，通过提供文本提示和随机高斯噪声来合成个性化图像。虽然人们观察到某些噪声是“黄金噪声”，可以实现更好的文本-图像对齐和更高的人类偏好，但我们仍然缺乏一个机器学习框架来获取这些黄金噪声。为了学习扩散采样中的黄金噪声，本文主要做出了三项贡献。首先，我们提出了一个名为“噪声提示”的新概念，旨在通过添加源自文本提示的微小期望扰动，将随机高斯噪声转化为黄金噪声。遵循这一概念，我们首先构建了“噪声提示学习”框架，系统地学习与扩散模型文本提示相关的“提示化”黄金噪声。其次，我们设计了一个噪声提示数据收集流程，并收集了一个大规模的“噪声提示数据集”（NPD），其中包含10万对随机噪声和黄金噪声以及相关的文本提示。以准备好的NPD作为训练数据集，我们训练了一个小型“噪声提示网络”（NPNet），可以直接学习将随机噪声转化为黄金噪声。学习到的黄金噪声扰动可以被视为一种噪声提示，因为它富含语义信息并根据给定的文本提示进行定制。第三，我们的大量实验证明了NPNet在提高各种扩散模型（包括SDXL、DreamShaper-xl-v2-turbo和Hunyuan-DiT）合成图像质量方面的显著有效性和泛化能力。此外，NPNet是一个小型高效的控制器，作为一个即插即用模块，其额外的推理和计算成本非常有限，因为它只是提供黄金噪声而不是随机噪声，而无需访问原始管道。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [152] [Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability](https://arxiv.org/abs/2507.12837)
> *理解稳定性边缘处神经正切核的演变*

*Kaiqi Jiang, Jeremy Cohen, Yuanzhi Li* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 神经正切核, 稳定性边缘, 梯度下降, 特征向量, 深度学习

**Comment:** 

> **TL;DR:** 本文研究了深度学习中梯度下降“稳定性边缘”现象下神经正切核（NTK）的特征向量动态，发现更高的学习率会使NTK的领先特征向量与训练目标更对齐，并提供了理论解释。

**AI_Comments:** 这篇论文填补了对“稳定性边缘”现象下神经正切核（NTK）特征向量行为理解的空白，这是对梯度下降（GD）训练动态的一个重要补充。通过观察性研究和理论分析相结合，特别是在不同架构下的发现以及对两层线性网络的理论验证，增强了我们对深度学习优化过程深层机制的理解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有研究深入探讨了“稳定性边缘”（EoS）现象中神经正切核（NTK）最大特征值的行为机制，但对于NTK特征向量在EoS期间的行为理解仍然缺失。

**Method:** 本文详细考察了在“稳定性边缘”（EoS）现象中神经正切核（NTK）特征向量的动态，并在不同架构上进行了观察。研究了这种现象的潜在机制，并为两层线性网络提供了理论分析。

**Result:** 观察到在不同架构中，较大的学习率会导致最终NTK以及完整NTK矩阵的领先特征向量与训练目标具有更大的对齐性。

**Conclusion:** 本研究增强了对深度学习中梯度下降训练动态的理解。

> **ai_Abstract:** 本文深入研究了深度学习中梯度下降的“稳定性边缘”（EoS）现象下神经正切核（NTK）特征向量的动态。研究发现，在不同神经网络架构中，使用更大的学习率会导致NTK的领先特征向量与训练目标更紧密地对齐。文章还探讨了这一现象的潜在机制，并为两层线性网络提供了理论分析，从而加深了对深度学习中梯度下降训练过程的理解。

> **摘要翻译:** 近年来，深度学习中神经正切核（NTK）的研究受到了越来越多的关注。NTK通常在训练过程中主动变化，并与特征学习相关。与此同时，最近关于梯度下降（GD）的工作发现了一种称为“稳定性边缘”（EoS）的现象，其中NTK的最大特征值围绕一个与步长成反比的值振荡。然而，尽管后续工作深入探讨了这种特征值行为的潜在机制，但对EoS期间NTK特征向量行为的理解仍然缺失。本文详细考察了EoS期间NTK特征向量的动态。在不同架构中，我们观察到较大的学习率会导致最终NTK以及完整NTK矩阵的领先特征向量与训练目标具有更大的对齐性。然后，我们研究了这种现象的潜在机制，并为两层线性网络提供了理论分析。我们的研究增强了对深度学习中GD训练动态的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [155] [Multi-View Node Pruning for Accurate Graph Representation](https://arxiv.org/abs/2503.11737)
> *多视图节点剪枝用于准确图表示*

*Hanjin Kim, Jiseong Park, Seojin Kim, Jueun Choi, Doheon Lee, Sung Ju Hwang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 图剪枝, 多视图学习, 图池化, 图表示学习, 重建损失

**Comment:** Jiseong Park and Hanjin Kim are co-first author for this work

> **TL;DR:** 提出了一种名为多视图剪枝（MVP）的新型图剪枝方法，通过整合多视图框架和重建损失来解决现有图池化方法在节点去除时未能充分考虑特征相关性的问题，显著提升了图表示学习的性能。

**AI_Comments:** 这项工作创新性地引入了多视图框架和重建损失来改进图池化中的节点剪枝，解决了现有方法仅依赖度或任务损失的局限性。通过从多维度考量节点重要性，并结合重建能力，MVP能够更准确地识别和保留关键节点，提升了图表示学习的准确性。其通用性使其可以与多种现有图池化框架结合，具有较强的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图池化方法在基于注意力得分和任务损失进行节点剪枝时，常简单地移除度较低的节点，而未充分考虑这些节点与给定任务在特征层面的相关性，导致压缩效率和表示准确性受限。

**Method:** 提出了多视图剪枝（MVP）方法。MVP首先通过利用预定义模态或随机划分输入特征来构建多个不同视图的图，以从多维度考量每个节点的重要性。随后，它结合重建损失和任务损失来学习每个节点的得分。MVP可以与任何分层池化框架结合使用。

**Result:** MVP在多个基准数据集上与两种图池化方法结合进行验证，结果显示它显著提升了基础图池化方法的性能，并超越了所有基线方法。

**Conclusion:** MVP的成功关键在于其多视图编码和重建损失的结合。该方法能够根据领域知识识别出重要性较低的节点，从而有效改进图表示学习。

> **ai_Abstract:** 本文提出了一种名为多视图剪枝（MVP）的新型图剪枝方法，旨在解决现有图池化方法在节点去除时忽略特征相关性的问题。MVP通过构建多视图图并结合重建损失和任务损失来学习节点得分，从而从不同角度评估节点重要性。实验证明，MVP显著提升了基础图池化方法的性能，并优于现有基线，其成功归因于多视图编码和重建损失的有效结合。

> **摘要翻译:** 图池化将整个图压缩成更小的粗化图，是图表示学习的重要组成部分。为了高效压缩给定图，图池化方法通常会根据基于注意力的评分和任务损失来丢弃节点。然而，这往往导致简单地移除度较低的节点，而未考虑它们与给定任务的特征层面相关性。为了解决这个问题，我们提出了一种基于多视图框架和重建损失的图剪枝方法——多视图剪枝（MVP）。给定一个图，MVP首先通过利用预定义模态或随机划分输入特征来为不同视图构建多个图，以从多角度考虑每个节点的重要性。然后，它通过同时考虑重建损失和任务损失来学习每个节点的得分。MVP可以与任何分层池化框架结合以对节点进行评分。我们通过将其与两种图池化方法结合，在多个基准数据集上验证了MVP，结果表明它显著提高了基础图池化方法的性能，超越了所有基线。进一步分析表明，多视图编码和重建损失的考虑是MVP成功的关键，并且它确实根据领域知识识别出了重要性较低的节点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [159] [DASViT: Differentiable Architecture Search for Vision Transformer](https://arxiv.org/abs/2507.13079)
> *DASViT：面向视觉Transformer的可微分架构搜索*

*Pengjin Wu, Ferrante Neri, Zhenhua Feng* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 神经网络架构搜索, 可微分架构搜索, 视觉Transformer, DASViT, 模型优化

**Comment:** Accepted to the International Joint Conference on Neural Networks
  (IJCNN) 2025

> **TL;DR:** 提出DASViT，一种用于视觉Transformer的可微分架构搜索方法，它能发现新颖的ViT设计，并在效率和性能上超越ViT-B/16。

**AI_Comments:** DASViT的创新之处在于将可微分架构搜索引入了视觉Transformer领域，克服了传统离散搜索方法的计算效率低和设计创新性不足的局限。它通过自动化设计过程，有望加速更高效、更紧凑ViT模型的发现，对于推动ViT在实际应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有应用于ViT的NAS方法主要集中在宏观搜索空间，并依赖于进化算法等离散方法，这些方法虽然可靠，但在发现创新架构设计、计算资源需求和时间消耗方面存在挑战。

**Method:** 引入DASViT，填补了ViT可微分搜索的空白，并发现了新颖的设计。

**Result:** 实验表明DASViT发现的架构打破了传统的Transformer编码器设计，在多个数据集上优于ViT-B/16，并以更少的参数和FLOPs实现了更高的效率。

**Conclusion:** DASViT成功地为视觉Transformer引入了可微分架构搜索，解决了现有方法的局限性，并生成了性能和效率俱佳的创新型ViT架构。

> **ai_Abstract:** 本文提出了DASViT，一种专为视觉Transformer（ViT）设计的可微分架构搜索（NAS）方法。针对现有ViT NAS方法计算成本高、创新能力有限的问题，DASViT引入了可微分搜索范式。实验证明，DASViT能够发现超越传统Transformer编码器设计的新颖ViT架构，并在多个数据集上以更少的参数和FLOPs，在性能和效率上均优于ViT-B/16。

> **摘要翻译:** 设计有效的神经网络是深度学习的基石，而神经网络架构搜索（NAS）已成为自动化此过程的强大工具。在现有NAS方法中，可微分架构搜索（DARTS）因其效率和易用性而备受关注，并启发了许多进展。自视觉Transformer（ViT）兴起以来，研究人员已将NAS应用于探索ViT架构，通常专注于宏观层面的搜索空间，并依赖于进化算法等离散方法。尽管这些方法确保了可靠性，但它们在发现创新架构设计、需要大量计算资源和耗时方面面临挑战。为了解决这些局限性，我们引入了面向视觉Transformer的可微分架构搜索（DASViT），它弥补了ViT可微分搜索的空白，并发现了新颖的设计。实验表明，DASViT提供的架构打破了传统的Transformer编码器设计，在多个数据集上优于ViT-B/16，并以更少的参数和FLOPs实现了卓越的效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [161] [On the Linear Speedup of Personalized Federated Reinforcement Learning with Shared Representations](https://arxiv.org/abs/2411.15014)
> *共享表示的个性化联邦强化学习的线性加速*

*Guojun Xiong, Shufan Wang, Daniel Jiang, Jian Li* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-16**

**Keywords:** 联邦强化学习, 个性化学习, 共享表示, 异构环境, 线性加速

**Comment:** ICLR 2025

> **TL;DR:** 本文提出了PFedRL-Rep，一个用于异构环境中个性化联邦强化学习的框架。该方法通过学习共享表示和智能体特定权重，实现了线性收敛加速，并提升了在新环境中的泛化能力。

**AI_Comments:** 这篇论文通过引入个性化，在联邦强化学习领域取得了重要进展，这对于现实世界的异构环境至关重要。其创新之处在于同时学习共享表示和个性化权重，有效地平衡了协作和个体需求。线性收敛加速的理论证明是一个重要贡献，为所提出的方法奠定了坚实的基础。其在实验中表现出的学习改进和泛化能力也验证了其实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦强化学习（FedRL）算法在异构环境中表现不佳，因为它们学习单一策略，不适用于面对多样化条件的个体智能体。

**Method:** 本文提出了个性化联邦强化学习（PFedRL）框架，具体为PFedRL-Rep算法。该算法学习两个组件：(1) 所有智能体协作学习的共享特征表示，以及 (2) 针对其本地环境个性化的智能体特定权重向量。作者分析了PFedTD-Rep（使用时序差分（TD）学习和线性表示的实例）的收敛性，并将其扩展到基于深度Q网络（DQN）的控制设置。

**Result:** 作者首次证明了PFedRL设置中，PFedTD-Rep关于智能体数量的线性收敛加速。实验结果表明，PFedTD-Rep及其基于DQN的扩展不仅改善了异构环境中的学习效果，而且对新环境提供了更好的泛化能力。

**Conclusion:** 本文成功引入了PFedRL-Rep，一种用于个性化联邦强化学习的新颖框架，通过利用共享表示和个性化权重，解决了异构环境的挑战，展示了改进的性能和泛化能力，并实现了理论上的线性收敛加速。

> **ai_Abstract:** 本文解决了联邦强化学习（FedRL）在异构环境中性能下降的问题，指出单一学习策略的低效性。为此，论文提出了一个个性化联邦强化学习（PFedRL）框架，特别是PFedRL-Rep，该框架学习跨智能体的共享特征表示和针对本地环境的智能体特定权重向量。作者证明了PFedTD-Rep（一个具体实例）的线性收敛加速，并通过实验证明PFedRL-Rep在异构设置中提高了学习效果，并提供了更好的泛化能力。

> **摘要翻译:** 联邦强化学习（FedRL）允许多个智能体在不共享智能体与环境交互过程中收集的本地轨迹的情况下，协作学习一个策略。然而，在实践中，不同智能体所面临的环境通常是异构的，这导致现有FedRL算法学习到的单一策略在个体智能体上的性能不佳。在本文中，我们更进一步，通过利用异构环境中智能体之间可能存在的共享通用结构，引入了一个“个性化”联邦强化学习框架（PFedRL）。具体来说，我们开发了一类名为PFedRL-Rep的PFedRL算法，该算法学习（1）所有智能体之间协作学习的共享特征表示，以及（2）针对其本地环境个性化的智能体特定权重向量。我们分析了PFedTD-Rep的收敛性，它是该框架在时序差分（TD）学习和线性表示下的一个具体实例。据我们所知，我们是第一个在PFedRL设置中证明了关于智能体数量的线性收敛加速。为了实现这一点，我们证明了PFedTD-Rep是带有马尔可夫噪声的联邦两时间尺度随机逼近的一个例子。实验结果表明，PFedTD-Rep，以及基于深度Q网络（DQN）扩展到控制设置的版本，不仅改善了异构环境中的学习效果，而且对新环境提供了更好的泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [162] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
> *编码器能否学习地标以用于超参数优化的热启动？*

*Antoni Zajko, Katarzyna Woźnica* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 表格数据表示学习, 超参数优化, 暖启动, 地标, 元学习

**Comment:** 

> **TL;DR:** 本文提出两种新颖的表格数据表示学习方法，旨在通过学习地标特性来暖启动贝叶斯超参数优化，但实验显示其对暖启动性能提升不显著。

**AI_Comments:** 本文的创新点在于提出了针对特定元任务（超参数优化暖启动）定制化的表格数据表示学习方法，并引入了“地标特性”这一新颖的概念来指导表示学习。然而，其局限性在于所提出的方法虽然能学习到与地标对齐的表示，但未能直接转化为目标元任务的显著性能提升，这表明地标对齐与实际任务性能之间可能存在脱节，或需要更深层次的机制来利用这些表示。

<details>
  <summary>Details</summary>

**Motivation:** 为元学习有效表示异构表格数据集仍然是一个开放问题。以前的方法依赖通用表示，但本文针对暖启动贝叶斯超参数优化这一特定元任务提出定制化方法。

**Method:** 本文提出了两种新颖的表格表示学习方法，专门用于贝叶斯超参数优化的暖启动元任务。这两种方法都遵循一个特定要求，即表示必须捕获地标的特性。第一种方法涉及深度度量学习，第二种基于地标重建。

**Result:** 实验表明，尽管所提出的编码器能够有效地学习与地标对齐的表示，但它们可能无法直接转化为超参数优化暖启动元任务中显著的性能提升。

**Conclusion:** 尽管提出的编码器能够学习与地标对齐的表示，但它们在超参数优化暖启动元任务中未能带来显著的性能增益。

> **ai_Abstract:** 本文针对元学习中异构表格数据集表示的开放问题，提出了两种新颖的表格表示学习方法，用于暖启动贝叶斯超参数优化。这些方法旨在捕获地标的特性，分别采用深度度量学习和地标重建。实验结果显示，尽管编码器能有效学习与地标对齐的表示，但对超参数优化暖启动元任务的性能提升不显著。

> **摘要翻译:** 有效地表示异构表格数据集以用于元学习目的仍然是一个开放问题。以前的方法依赖于旨在通用的表示。本文提出了两种新颖的表格表示学习方法，专门针对一个特定的元任务——贝叶斯超参数优化的暖启动。这两种方法都遵循我们自己制定的特定要求，即强制表示捕获地标的特性。第一种方法涉及深度度量学习，而第二种方法基于地标重建。我们通过两种方式评估了所提出的编码器。除了目标元任务的增益外，我们还使用所提出要求满足的程度作为评估指标。实验表明，虽然所提出的编码器可以有效地学习与地标对齐的表示，但它们可能无法直接转化为超参数优化暖启动元任务中显著的性能提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [182] [FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient](https://arxiv.org/abs/2507.12983)
> *FedGA: 一种基于基尼系数的公平联邦学习框架*

*ShanBin Liu* | **Category: cs.LG, cs.DC** | **Updated: 2025-07-17**

**Keywords:** 联邦学习, 公平性, 基尼系数, 数据异构性, 聚合权重

**Comment:** 

> **TL;DR:** FedGA是一种新的联邦学习框架，通过使用基尼系数衡量客户端性能差异并动态调整聚合权重，旨在解决联邦学习中的公平性问题，同时保持整体性能。

**AI_Comments:** FedGA的创新点在于将基尼系数引入联邦学习中，作为衡量和干预公平性的核心指标，并通过自适应干预和动态权重调整来提升模型公平性，这为解决联邦学习中的数据异构性挑战提供了一个新颖且有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中，数据异构性导致客户端之间性能差异显著，引发了对模型公平性的担忧。为了解决这一问题，提升联邦学习的公平性。

**Method:** 提出FedGA算法。首先，利用基尼系数衡量客户端间的性能差异。其次，建立基尼系数与全局模型更新规模的关系，并据此自适应地确定公平性干预时机。最后，根据系统实时公平性状态动态调整聚合权重，使全局模型能更好地整合性能较差客户端的信息。

**Result:** 在Office-Caltech-10、CIFAR-10和Synthetic数据集上进行了广泛实验。结果表明，FedGA有效提高了方差和基尼系数等公平性指标，同时保持了强大的整体性能。

**Conclusion:** FedGA通过衡量和干预客户端性能差异，有效提升了联邦学习的公平性，同时未牺牲整体性能，验证了其方法的有效性。

> **ai_Abstract:** FedGA是一种新颖的联邦学习框架，旨在解决数据异构性导致的客户端性能不公平问题。该框架利用基尼系数量化客户端性能差异，并基于此自适应地确定公平性干预时机。通过动态调整聚合权重，FedGA使全局模型能更好地整合表现较差客户端的信息。实验结果表明，FedGA在提升公平性指标（如方差和基尼系数）的同时，保持了良好的整体性能。

> **摘要翻译:** 公平性已成为联邦学习中的关键挑战之一。在横向联邦设置中，数据异构性常常导致客户端之间存在显著的性能差异，引发了对公平模型行为的担忧。为解决此问题，我们提出了FedGA，一种关注公平性的联邦学习算法。我们首先采用基尼系数来衡量客户端之间的性能差异。在此基础上，我们建立了基尼系数$G$与全局模型更新规模${U_s}$之间的关系，并利用这种关系自适应地确定公平性干预的时机。随后，我们根据系统的实时公平性状态动态调整聚合权重，使全局模型能够更好地整合来自性能相对较差客户端的信息。我们在Office-Caltech-10、CIFAR-10和Synthetic数据集上进行了广泛实验。结果表明，FedGA有效提高了方差和基尼系数等公平性指标，同时保持了强大的整体性能，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [185] [Learning Universal Human Mobility Patterns with a Foundation Model for Cross-domain Data Fusion](https://arxiv.org/abs/2503.15779)
> *基于基础模型和跨域数据融合学习通用人类出行模式*

*Haoxuan Ma, Xishun Liao, Yifan Liu, Qinhua Jiang, Chris Stanford, Shangqing Cao, Jiaqi Ma* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 人类出行模式, 基础模型, 跨域数据融合, 大型语言模型, 交通模拟

**Comment:** 

> **TL;DR:** 该论文提出了一个利用基础模型和跨域数据融合来学习通用人类出行模式的框架，解决了现有方法在处理多样化数据源方面的局限性。

**AI_Comments:** 该论文的创新点在于提出了一个将基础模型、跨域数据融合和大型语言模型相结合的框架，以解决人类出行建模中数据集成和多样性处理的挑战。其通过构建语义丰富且隐私保护的轨迹数据集，并通过域迁移实现跨域适应性，显著提升了出行模式建模的通用性和实用性。该方法在实际交通模拟中的良好表现，尤其是在复杂交通走廊上的低误差，凸显了其在智能交通系统中的重要应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人类出行建模方法缺乏处理多样化数据源的集成能力，而人类出行建模对于城市规划和交通管理至关重要。

**Method:** 提出了一个用于通用人类出行模式的基础模型框架，该框架利用跨域数据融合和大型语言模型（LLMs）。它集成了地理、出行、社会人口统计和交通等多模态数据，构建了一个保护隐私且语义丰富的出行轨迹数据集。该框架通过域迁移技术实现跨不同城市环境的可迁移性，并利用LLMs对轨迹数据进行语义丰富。

**Result:** 生成的合成数据集准确地再现了经验数据中观察到的出行模式。在洛杉矶县的大规模交通模拟中，结果与观测到的交通数据吻合良好。在加州I-405走廊的模拟中，与Caltrans PeMS观测数据相比，交通量和速度的平均绝对百分比误差分别为5.85%和4.36%。

**Conclusion:** 该基础模型方法在学习通用人类出行模式方面具有实用性，并为智能交通系统和城市出行应用提供了潜力。

> **ai_Abstract:** 本研究提出了一个基于基础模型和跨域数据融合的框架，用于学习通用人类出行模式。该框架通过集成多模态数据（包括地理、出行、社会人口统计和交通信息）并利用大型语言模型进行语义丰富，解决了现有出行建模方法在处理多样化数据源方面的局限性。它构建了隐私保护且语义丰富的出行轨迹数据集，并通过域迁移技术展示了跨城市环境的适应性。定量评估和大规模交通模拟（在洛杉矶县和加州I-405走廊进行）证明了该方法能够准确再现出行模式，并与观测数据高度吻合，显示了其在智能交通和城市出行应用中的巨大潜力。

> **摘要翻译:** 人类出行建模对于城市规划和交通管理至关重要，但现有方法往往缺乏处理多样化数据源所需的集成能力。我们提出了一个用于通用人类出行模式的基础模型框架，该框架利用跨域数据融合和大型语言模型来解决这些局限性。我们的方法整合了性质和时空分辨率不同的多模态数据，包括地理、出行、社会人口统计和交通信息，以构建一个保护隐私且语义丰富的人类出行轨迹数据集。我们的框架通过域迁移技术展示了适应性，确保了在洛杉矶（LA）和埃及的案例研究中跨不同城市环境的可迁移性。该框架采用LLMs对轨迹数据进行语义丰富，从而实现对出行模式的全面理解。定量评估表明，我们生成的合成数据集准确地再现了经验数据中观察到的出行模式。该基础模型方法的实用性通过洛杉矶县的大规模交通模拟得到证明，其中结果与观测到的交通数据吻合良好。在加州I-405走廊上，与Caltrans PeMS观测数据相比，模拟的交通量平均绝对百分比误差为5.85%，速度为4.36%，这表明该框架在智能交通系统和城市出行应用方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [186] [Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective](https://arxiv.org/abs/2507.12652)
> *开放和闭环EMG解码中的联邦学习：隐私和性能视角*

*Kai Malcolm, César Uribe, Momona Yamagami* | **Category: cs.LG, cs.CR, cs.HC** | **Updated: 2025-07-16**

**Keywords:** 联邦学习, EMG解码, 隐私保护, 神经接口, 性能-隐私权衡

**Comment:** 23 pages, 7 figures

> **TL;DR:** 本文探讨了联邦学习在开放和闭环EMG解码中的应用，评估了其在隐私保护下的性能，并指出了在闭环实时应用中性能与隐私的权衡。

**AI_Comments:** 本文首次在闭环自适应神经接口中探索了联邦学习的应用，填补了该领域的空白。其创新之处在于将FL应用于敏感的EMG信号解码，并系统地评估了其在不同场景下的隐私和性能。研究揭示了在实时自适应应用中，FL在性能和隐私之间存在的权衡，特别是在单用户闭环交互中FL的局限性。这对于未来设计更优的隐私保护神经接口系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经信号包含敏感个人信息，使得数据共享用于解码器训练面临隐私挑战。联邦学习作为一种分布式、隐私保护的学习框架，有望解决这一问题，但在闭环自适应神经接口中的应用尚未探索。

**Method:** 引入了基于FL的神经解码，并系统地评估了其在开放和闭环场景下使用高维肌电图（EMG）信号的性能和隐私。在闭环用户研究中，修改了FL方法以适应单用户、实时交互。

**Result:** 在开环模拟中，FL显著优于本地学习基线。在闭环用户研究中，修改后的FL方法在性能上不如本地学习解码器，但本地学习的隐私风险更高。

**Conclusion:** 研究结果强调了实时自适应应用中性能与隐私的关键权衡，并指出需要专门为协同自适应、单用户应用设计的FL方法。

> **ai_Abstract:** 本文探讨了联邦学习（FL）在神经接口中的应用，旨在解决神经信号数据共享的隐私问题。研究在开环和闭环EMG解码场景中评估了FL的性能和隐私。结果显示，FL在开环场景下表现优异，但在闭环实时单用户交互中，需要对FL进行修改，导致其性能不及本地学习，尽管本地学习的隐私风险更高。研究强调了实时自适应应用中性能与隐私之间的权衡，并呼吁开发专门针对协同自适应、单用户应用设计的FL方法。

> **摘要翻译:** 侵入式和非侵入式神经接口有望成为下一代技术的高带宽输入设备。然而，神经信号固有地编码了个体的身份和健康等敏感信息，这使得用于解码器训练的数据共享成为一个关键的隐私挑战。联邦学习（FL）作为一种分布式、隐私保护的学习框架，提供了一个有前景的解决方案，但它在闭环自适应神经接口中尚未得到探索。在此，我们引入了基于FL的神经解码，并系统地评估了其在使用高维肌电图信号的开放和闭环场景中的性能和隐私。在开环模拟中，FL显著优于本地学习基线，展示了其在高性能、隐私保护神经解码方面的潜力。相比之下，闭环用户研究需要调整FL方法以适应单用户、实时交互，而这是标准FL不支持的场景。这种修改导致本地学习解码器在闭环性能上超越了调整后的FL方法，但本地学习仍然带来更高的隐私风险。我们的发现突出了实时自适应应用中关键的性能-隐私权衡，并表明需要专门为协同自适应、单用户应用设计的FL方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [191] [PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data](https://arxiv.org/abs/2502.04018)
> *PINT：物理信息神经网络时间序列模型及其在WeatherBench 2米温度数据长期推断中的应用*

*Keonvin Park, Jisu Kim, Jaemin Seo* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 物理信息神经网络, 时间序列预测, 简谐振子方程, 长期预测, WeatherBench

**Comment:** 

> **TL;DR:** PINT是一种将物理约束集成到神经网络时间序列模型中的框架，用于长期预测2米温度数据，并在WeatherBench数据集上表现出良好的泛化能力和周期性趋势捕捉能力。

**AI_Comments:** 这篇论文的创新点在于将物理约束（简谐振子方程）以先验知识的形式融入到深度学习时间序列模型中，这不仅提高了模型的预测精度和泛化能力，也增强了模型的可解释性，使其更符合物理规律。该方法解决了传统时间序列模型对未来观测的依赖问题，使其更适用于实际的长期预测场景。通过在WeatherBench数据集上的应用，展示了其在气候建模等领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统时间序列模型依赖未来观测，而实际预测中实时更新有限。该研究旨在通过将物理约束融入神经网络时间序列模型，提高模型捕获复杂动态的能力，并实现长期、实际的预测，解决数据更新有限的挑战。

**Method:** PINT框架将物理约束（具体为简谐振子方程）集成到RNN、LSTM和GRU等神经网络时间序列模型中。利用简谐振子方程的解析解（正弦和余弦函数）作为物理信息先验，并与从其精确解导出的线性回归基线进行基准测试，量化嵌入物理原理的影响。模型仅使用前90天观测数据，迭代预测未来两年。

**Result:** 实验表明，PINT模型在WeatherBench数据集上能够很好地泛化，捕捉周期性趋势，并与物理原理对齐。

**Conclusion:** 该研究强调了物理信息神经网络模型在连接机器学习和可解释气候应用方面的潜力。

> **ai_Abstract:** PINT是一种创新的物理信息神经网络时间序列模型框架，它通过将简谐振子方程等物理约束嵌入到RNN、LSTM和GRU等模型中，显著提升了模型捕获复杂动态和进行长期预测的能力。该模型在WeatherBench数据集的2米温度数据上进行了验证，仅利用少量历史数据即可迭代预测未来两年，解决了传统模型对未来观测依赖的问题。实验结果表明PINT在泛化性、周期性趋势捕捉和物理一致性方面表现出色，预示着物理信息模型在气候应用中的广阔前景。

> **摘要翻译:** 这篇论文介绍了PINT（物理信息神经网络时间序列模型），这是一个将物理约束集成到神经网络时间序列模型中的框架，以提高其捕获复杂动态的能力。我们将PINT应用于ERA5 WeatherBench数据集，重点关注2米温度数据的长期预测。PINT将简谐振子方程作为物理信息先验，将其周期性动态嵌入到RNN、LSTM和GRU架构中。该方程的解析解（正弦和余弦函数）有助于严格评估引入物理信息约束的益处。通过与从其精确解导出的线性回归基线进行基准测试，我们量化了在数据驱动模型中嵌入物理原理的影响。与依赖未来观测的传统时间序列模型不同，PINT专为实际预测而设计。它仅使用前90天的观测数据，迭代预测未来两年，解决了实时更新有限带来的挑战。在WeatherBench数据集上的实验证明了PINT的泛化能力、捕捉周期性趋势的能力以及与物理原理的一致性。这项研究强调了物理信息神经网络模型在连接机器学习和可解释气候应用方面的潜力。我们的模型和数据集已在GitHub上公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [201] [NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation](https://arxiv.org/abs/2507.13133)
> *NGTM：基于子结构的神经图主题模型用于可解释图生成*

*Yuanxin Zhuang, Dazhong Shen, Ying Sun* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 图生成, 可解释性, 主题模型, 神经图模型, 子结构

**Comment:** 

> **TL;DR:** NGTM是一个新的神经图主题模型，它通过将图表示为潜在主题的混合物来解决现有图生成方法的可解释性问题，每个主题定义了语义子结构的分布，从而实现了可解释的图生成和精细控制。

**AI_Comments:** NGTM的创新之处在于将自然语言处理中的主题建模概念引入到图生成领域，有效地解决了现有方法可解释性差的痛点。通过将图分解为可解释的语义子结构主题，该模型不仅提升了生成结果的透明度，还赋予了用户对生成过程进行精细控制的能力，这对于分子设计等需要理解和控制生成机制的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图生成在分子设计和知识图谱构建等领域至关重要。尽管现有方法在生成真实图方面取得了成功，但其可解释性有限，往往掩盖了结构决策背后的原理。

**Method:** 我们提出了神经图主题模型（NGTM），这是一个受自然语言处理中主题建模启发的生成框架。NGTM将图表示为潜在主题的混合物，每个主题定义了语义有意义的子结构的分布，这促进了局部和全局尺度的显式可解释性。生成过程将这些主题分布与一个全局结构变量透明地整合，从而能够清晰地语义追踪每个生成的图。

**Result:** 实验表明，NGTM实现了具有竞争力的生成质量，同时独特地实现了细粒度的控制和可解释性，允许用户通过主题层面的调整来调整结构特征或诱导生物学特性。

**Conclusion:** NGTM通过引入基于主题的可解释性，成功解决了图生成中长期存在的解释性挑战，并在保持生成质量的同时提供了对生成过程的精细控制。

> **ai_Abstract:** NGTM是一个新颖的神经图主题模型，旨在解决现有图生成方法的可解释性不足问题。该模型将图建模为潜在主题的混合物，每个主题对应于语义子结构的分布，从而在局部和全局层面提供显式可解释性。NGTM在生成过程中透明地整合主题分布和全局结构变量，实现了对生成图的语义追溯。实验证明，NGTM在保持高生成质量的同时，能够提供独特的细粒度控制和可解释性，允许用户通过调整主题来修改结构特征或诱导特定属性。

> **摘要翻译:** 图生成在分子设计和知识图谱构建等众多领域中发挥着关键作用。尽管现有方法在生成真实图方面取得了相当大的成功，但其可解释性仍然有限，常常模糊了结构决策背后的原理。为了解决这一挑战，我们提出了神经图主题模型（NGTM），这是一种受自然语言处理中主题建模启发的创新生成框架。NGTM将图表示为潜在主题的混合物，每个主题定义了语义有意义的子结构的分布，这促进了局部和全局尺度的显式可解释性。生成过程将这些主题分布与一个全局结构变量透明地整合，从而能够清晰地语义追踪每个生成的图。实验表明，NGTM实现了具有竞争力的生成质量，同时独特地实现了细粒度的控制和可解释性，允许用户通过主题层面的调整来调整结构特征或诱导生物学特性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [205] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
> *学习重要内容：基于互信息的概率任务选择用于模型微调*

*Prateek Chanda, Saral Sureka, Parth Pratim Chatterjee, Krishnateja Killamsetty, Nikhil Shivakumar Nayak, Ganesh Ramakrishnan* | **Category: cs.LG, cs.AI, 68T50, I.2.7; I.2.6; I.2.4** | **Updated: 2025-07-16**

**Keywords:** 大型语言模型, 微调, 任务选择, 互信息, 马尔可夫随机场

**Comment:** 9, 8 tables, 7 figures

> **TL;DR:** TASKPGM是一个原则性且可扩展的框架，通过最小化马尔可夫随机场的能量函数来选择连续的任务比例，以优化大型语言模型微调的训练混合物，从而提高性能并提供可解释的洞察。

**AI_Comments:** TASKPGM的创新之处在于它提供了一个原则性、可扩展且可解释的框架，用于LLM微调中的任务选择，超越了传统的启发式方法。其重要性在于解决了LLM微调中一个关键挑战——最佳训练混合物的选择，并提供了具有理论保证和经验改进的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLM）的性能关键取决于训练混合物的组成。然而，选择最佳的任务数据集组合仍然是一个主要依靠手动、启发式驱动的过程，从业者通常依赖于均匀或基于大小的采样策略。

**Method:** 本文引入了TASKPGM，一个原则性且可扩展的混合优化框架，通过最小化马尔可夫随机场（MRF）上的能量函数来选择连续的任务比例。任务关系通过行为散度（如Jensen Shannon散度和点互信息）建模，这些散度是从单任务微调模型的预测分布中计算出来的。我们的方法在单纯形约束下得到了闭式解，并被证明能够平衡任务的代表性和多样性。

**Result:** 我们提供了理论保证，包括预算变体的弱次模性，并在Llama 2和Mistral模型上，通过MMLU和BIGBench等评估套件，展示了持续的经验改进。

**Conclusion:** 除了性能之外，TASKPGM还提供了对任务影响和混合物组成的解释性见解，使其成为高效和鲁棒的LLM微调的强大工具。

> **ai_Abstract:** 本文提出了TASKPGM，一个新颖、原则性且可扩展的框架，用于优化大型语言模型微调的训练混合物。该框架通过最小化马尔可夫随机场上的能量函数来选择连续的任务比例，并利用行为散度（如Jensen Shannon散度和点互信息）来建模任务关系，从而平衡任务的代表性和多样性。该方法提供了理论保证，并在Llama 2和Mistral等模型上展示了持续的性能改进，同时提供了对任务影响和混合物组成的解释性见解。

> **摘要翻译:** 微调大型语言模型（LLMs）的性能关键取决于训练混合物的组成。然而，选择最佳的任务数据集组合仍然是一个主要依靠手动、启发式驱动的过程，从业者通常依赖于均匀或基于大小的采样策略。我们引入了TASKPGM，一个原则性且可扩展的混合优化框架，通过最小化马尔可夫随机场（MRF）上的能量函数来选择连续的任务比例。任务关系通过行为散度（如Jensen Shannon散度和点互信息）建模，这些散度是从单任务微调模型的预测分布中计算出来的。我们的方法在单纯形约束下得到了闭式解，并被证明能够平衡任务的代表性和多样性。我们提供了理论保证，包括预算变体的弱次模性，并在Llama 2和Mistral模型上，通过MMLU和BIGBench等评估套件，展示了持续的经验改进。除了性能之外，TASKPGM还提供了对任务影响和混合物组成的解释性见解，使其成为高效和鲁棒的LLM微调的强大工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [206] [A Kernel Distribution Closeness Testing](https://arxiv.org/abs/2507.12843)
> *核分布接近度检验*

*Zhijian Zhou, Liuhua Peng, Xunye Tian, Feng Liu* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-17**

**Keywords:** 分布接近度检验, 最大均值差异, 范数自适应MMD, 双样本检验, 再生核希尔伯特空间

**Comment:** 

> **TL;DR:** 本文提出了一种名为范数自适应最大均值差异（NAMMD）的新度量，用于改进分布接近度检验（DCT）和双样本检验，并在理论和实验上证明了其比基于MMD的方法具有更高的检验功效。

**AI_Comments:** 本文的创新点在于提出了范数自适应最大均值差异（NAMMD），有效地解决了传统MMD在评估分布接近度时可能存在的“信息量不足”问题，即MMD值相同但分布范数不同的情况。通过引入RKHS范数进行尺度调整，NAMMD能够更准确地反映分布之间的接近程度。这项工作不仅在理论上证明了NAMMD的优越性，还在广泛的实验中验证了其在多种数据类型上的有效性，尤其是在复杂数据（如图像）上的应用潜力。这对于统计检验和机器学习领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分布接近度检验（DCT）方法主要测量离散一维空间中的分布对差异，限制了其在复杂数据上的应用。虽然最大均值差异（MMD）是衡量复杂分布差异的强大工具，但其值可能对RKHS中具有不同范数的分布对相同，使其在评估多个分布对的接近程度时信息量不足。本文旨在解决MMD的这一局限性。

**Method:** 为了解决MMD的局限性，本文设计了一种新的分布差异度量——范数自适应最大均值差异（NAMMD），通过使用分布的再生核希尔伯特空间（RKHS）范数来缩放MMD的值。基于NAMMD的渐近分布，作者提出了NAMMD-based DCT来评估分布对的接近程度。此外，NAMMD也被应用于解决双样本检验问题。

**Result:** 理论上，NAMMD-based DCT比MMD-based DCT具有更高的检验功效，并且具有有界的第一类错误，这通过对多种数据（如合成噪声、真实图像）的广泛实验得到了验证。此外，NAMMD-based双样本检验在理论和实验上都比MMD-based双样本检验具有更高的检验功效。

**Conclusion:** 本文提出的范数自适应最大均值差异（NAMMD）是一种更具信息量和更高检验功效的度量，用于分布接近度检验和双样本检验，优于传统的MMD方法。

> **ai_Abstract:** 本文提出了一种名为范数自适应最大均值差异（NAMMD）的新型分布差异度量，旨在解决现有最大均值差异（MMD）在评估复杂数据分布接近度时信息量不足的问题。NAMMD通过结合分布在再生核希尔伯特空间（RKHS）中的范数来改进MMD。基于NAMMD的渐近分布，作者提出了NAMMD-based分布接近度检验（DCT）和NAMMD-based双样本检验。理论分析和大量实验结果均表明，NAMMD-based方法在检验功效方面显著优于传统的MMD-based方法，并且NAMMD-based DCT保持了有界的第一类错误。

> **摘要翻译:** 分布接近度检验（DCT）评估一对分布之间的距离是否至少为$\\epsilon$-远。现有的DCT方法主要衡量定义在离散一维空间（例如，使用总变差）上的分布对之间的差异，这限制了它们在复杂数据（例如图像）上的应用。为了将DCT扩展到更多类型的数据，一个自然的思路是将最大均值差异（MMD）——一种衡量两个复杂分布之间分布差异的强大度量——引入到DCT场景中。然而，我们发现MMD的值对于在同一再生核希尔伯特空间（RKHS）中具有不同范数的许多分布对可能相同，这使得MMD在评估多个分布对的接近程度时信息量不足。为了缓解这个问题，我们设计了一种新的分布差异度量，范数自适应MMD（NAMMD），它使用分布的RKHS范数来缩放MMD的值。基于NAMMD的渐近分布，我们最终提出了基于NAMMD的DCT来评估一对分布的接近程度。理论上，我们证明了基于NAMMD的DCT比基于MMD的DCT具有更高的检验功效，并且具有有界的第一类错误，这也在对多种数据（例如合成噪声、真实图像）的广泛实验中得到了验证。此外，我们还将所提出的NAMMD应用于解决双样本检验问题，发现在理论和实验中，基于NAMMD的双样本检验都比基于MMD的双样本检验具有更高的检验功效。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [221] [Unifying Explainable Anomaly Detection and Root Cause Analysis in Dynamical Systems](https://arxiv.org/abs/2502.12086)
> *统一动力系统中可解释的异常检测和根本原因分析*

*Yue Sun, Rick S. Blum, Parv Venkitasubramaniam* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-17**

**Keywords:** 异常检测, 根本原因分析, 动力系统, 常微分方程, 因果推理

**Comment:** Accepted by the AAAI-25 Workshop on Artificial Intelligence for Cyber
  Security (AICS)

> **TL;DR:** 提出ICODE网络，一个统一的可解释框架，用于在动力系统中同时进行异常检测、根本原因分析和异常类型分类。

**AI_Comments:** ICODE的创新之处在于其将异常检测、根本原因分析和异常类型分类整合到一个单一、可解释的框架中，特别是在基于ODE的动力系统中。通过将异常视为对底层ODE和因果关系的扰动，它提供了一种新颖的解释机制，增强了模型的可信度和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 动力系统中的异常会严重影响其性能和可靠性，因此需要解决异常检测、根本原因定位和异常类型分类的关键挑战。

**Method:** 本文提出了可解释因果常微分方程（ICODE）网络，这是一个模型内可解释的学习框架。ICODE利用神经常微分方程进行异常检测，并通过解释通道进行因果推理以执行根本原因分析，阐明异常的原因。该方法基于异常会改变系统潜在ODE并导致变量间因果关系变化的假设，并通过学习模型参数的扰动来识别时间序列数据中的异常及其根本原因。

**Result:** 综合实验评估证明了ICODE在各种动力系统中的有效性，展示了其准确检测异常、分类异常类型和查明异常起源的能力。

**Conclusion:** ICODE网络提供了一个单一、可解释的框架，能够同时执行动力系统中的异常检测、根本原因分析和异常类型分类。

> **ai_Abstract:** 本文提出了ICODE网络，一个用于动力系统的可解释学习框架，旨在统一异常检测、根本原因分析和异常类型分类。ICODE利用神经常微分方程进行异常检测，并通过因果推理解释异常，它基于异常改变系统潜在因果关系的假设。实验证明ICODE能有效检测、分类和定位动力系统中的异常。

> **摘要翻译:** 动力系统在各种科学和工程领域中普遍存在，易受异常影响，这些异常会显著影响其性能和可靠性。本文解决了由常微分方程（ODE）控制的动力系统中异常检测、根本原因定位和异常类型分类的关键挑战。我们定义了两类异常：通过互连变量传播的网络异常，以及局限于单个变量的测量异常。为了应对这些挑战，我们提出了可解释因果常微分方程（ICODE）网络，这是一个模型内可解释的学习框架。ICODE利用神经常微分方程进行异常检测，同时通过解释通道进行因果推理以执行根本原因分析，阐明为什么特定时间段被标记为异常。ICODE旨在在一个单一、可解释的框架内同时执行异常检测、根本原因分析和异常类型分类。我们的方法基于以下假设：异常会改变系统的潜在ODE，表现为变量之间因果关系的变化。我们提供了关于如何利用学习模型参数的扰动来识别时间序列数据中的异常及其根本原因的理论分析。全面的实验评估证明了ICODE在各种动力系统中的有效性，展示了其准确检测异常、分类异常类型和查明其起源的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [243] [NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech](https://arxiv.org/abs/2507.13155)
> *非语言TTS：一个用于文本到语音的、带有情感标注的文本对齐非语言发声的公共英语语料库*

*Maksim Borisov, Egor Spirin, Daria Diatlova* | **Category: cs.LG, cs.SD** | **Updated: 2025-07-17**

**Keywords:** 非语言发声, 文本到语音, 语音合成, 数据集, 情感标注

**Comment:** 

> **TL;DR:** 本文介绍了NonverbalTTS，一个17小时的公共数据集，包含非语言发声和情感标注，旨在解决富有表现力的语音合成中非语言发声数据稀缺的问题，并展示了其在TTS模型上的有效性，性能可媲美闭源系统。

**AI_Comments:** 该论文通过发布NonverbalTTS数据集，有效解决了富有表现力的文本到语音合成领域中非语言发声数据稀缺的关键问题。其创新点在于构建了一个大规模、高质量且带有详细情感标注的非语言发声语料库，并设计了全面的数据处理和标注管道。数据集的开放性及其在提升开源TTS模型性能方面的表现，使其成为推动该领域研究的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 当前富有表现力的语音合成模型受限于开源数据集中多样化非语言发声（NVs）的有限可用性。

**Method:** 引入了一个名为NonverbalTTS（NVTTS）的17小时开放访问数据集，该数据集标注了10种非语言发声（如笑声、咳嗽）和8种情感类别。数据集来源于VoxCeleb和Expresso，通过自动化检测后进行人工验证。提出了一种综合性管道，整合了自动语音识别（ASR）、非语言发声标记、情感分类以及用于合并多标注者转录的融合算法。

**Result:** 在NVTTS数据集上对开源文本到语音（TTS）模型进行微调后，其性能与CosyVoice2等闭源系统相当，并通过人工评估和自动指标（包括说话人相似度和非语言发声保真度）进行了衡量。

**Conclusion:** 通过发布NonverbalTTS数据集及其配套的标注指南，解决了富有表现力的文本到语音（TTS）研究中的一个关键瓶颈。

> **ai_Abstract:** 本文介绍了NonverbalTTS（NVTTS），一个17小时的公共英语数据集，专门用于文本到语音（TTS）研究，以解决当前富有表现力语音合成中非语言发声（NVs）数据稀缺的问题。该数据集包含10种非语言发声和8种情感类别，通过自动化检测和人工验证从现有资源中提取并标注。作者还提出了一套完整的数据处理管道，并证明了使用该数据集微调的开源TTS模型在性能上能与闭源系统媲美，从而为富有表现力的TTS研究提供了重要的开放资源。

> **摘要翻译:** 当前富有表现力的语音合成模型受限于包含多样化非语言发声（NVs）的开源数据集的有限可用性。在这项工作中，我们介绍了NonverbalTTS（NVTTS），一个17小时的开放访问数据集，标注了10种非语言发声（例如，笑声、咳嗽）和8种情感类别。该数据集来源于流行的资源VoxCeleb和Expresso，采用自动化检测后进行人工验证的方式。我们提出了一种全面的管道，整合了自动语音识别（ASR）、非语言发声标记、情感分类以及一种用于合并多个标注者转录的融合算法。在NVTTS数据集上对开源文本到语音（TTS）模型进行微调，通过人工评估和自动指标（包括说话人相似度和非语言发声保真度）衡量，其性能与CosyVoice2等闭源系统相当。通过发布NVTTS及其配套的标注指南，我们解决了富有表现力的TTS研究中的一个关键瓶颈。该数据集可在https://huggingface.co/datasets/deepvk/NonverbalTTS获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [245] [VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models](https://arxiv.org/abs/2503.19530)
> *VectorFit：预训练基础模型的自适应奇异向量与偏置向量微调*

*Suhas G Hegde, Shilpy Kaur, Aruna Tiwari* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** VectorFit, PEFT, 微调, 基础模型, 参数效率

**Comment:** 

> **TL;DR:** VectorFit是一种新的参数高效微调方法，通过自适应地训练预训练模型权重W的奇异向量和偏置来利用现有知识，实现了比现有PEFT方法更优的性能，且所需可训练参数减少9倍。

**AI_Comments:** VectorFit的创新之处在于其独特地利用了预训练模型W的现有知识，通过自适应地微调其奇异向量和偏置，而非从头训练新的低秩权重。这种方法不仅显著提高了参数效率（减少9倍参数），还能产生高秩的增量权重，弥补了传统PEFT方法与完全微调之间的性能差距，尤其在资源受限场景下具有重要意义。其在多模态任务上的广泛验证也增强了其通用性。

<details>
  <summary>Details</summary>

**Motivation:** 流行的PEFT方法在微调时能减少可训练参数数量，但它们的权重是从头开始训练的，导致与完全微调之间存在性能差距，尤其是在低预算设置下。

**Method:** 本文引入了VectorFit，一种新的参数化方法，通过自适应地训练预训练权重W的奇异向量和偏置，高效利用W中嵌入的现有知识。这种方法能够生成高秩增量权重矩阵ΔW，与完全微调相当。

**Result:** VectorFit在可训练参数数量减少9倍的情况下，比领先的PEFT方法取得了更优异的结果。在涵盖自然语言理解和生成、问答、图像分类和图像生成等语言和视觉任务的19个数据集上的综合实验表明，VectorFit在参数效率方面超越了基线。

**Conclusion:** VectorFit通过自适应训练奇异向量和偏置，有效利用了预训练模型的现有知识，从而在显著减少可训练参数的同时，实现了与完全微调相当的性能，并在多项语言和视觉任务中展现出卓越的参数效率。

> **ai_Abstract:** VectorFit提出了一种新颖的参数高效微调方法，通过自适应地训练预训练模型权重W的奇异向量和偏置，有效利用了W中固有的知识。与现有PEFT方法从头训练新权重不同，VectorFit能够生成高秩的增量权重矩阵，实现了与完全微调相当的性能，同时将可训练参数减少了9倍。在19个涵盖语言和视觉任务的数据集上的广泛实验证明，VectorFit在参数效率上优于现有基线。

> **摘要翻译:** 流行的PEFT方法通过并行化新的低秩或稀疏可训练权重来减少微调的可训练参数数量，这些权重与冻结的预训练权重W并行。然而，这些权重是从头开始训练的，并且这些方法与完全微调之间存在性能差距，尤其是在低预算设置下。我们引入了VectorFit，一种新的参数化方式，它通过自适应地训练W的奇异向量和偏置，高效利用W中嵌入的现有知识。我们表明，以这种方式利用W的结构和变换特性可以产生高秩增量权重矩阵ΔW，与完全微调相当。VectorFit以比领先的PEFT方法少9倍的可训练参数提供了卓越的结果。通过在涵盖自然语言理解和生成、问答、图像分类和图像生成等广泛语言和视觉任务的19个数据集上的综合实验，我们证明VectorFit在参数效率方面超越了基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [247] [BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training](https://arxiv.org/abs/2507.12619)
> *BootSeer：分析和缓解大规模LLM训练中的初始化瓶颈*

*Rui Li, Xiaoyun Zhi, Jinxin Chi, Menghan Yu, Lixin Huang, Jia Zhu, Weilun Zhang, Xing Ma, Wenjia Liu, Zhicheng Zhu, Daowen Luo, Zuquan Song, Xin Yin, Chao Xiang, Shuguang Wang, Wencong Xiao, Gene Cooperman* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-07-16**

**Keywords:** LLM训练, 启动开销, Bootseer, 系统优化, 大语言模型

**Comment:** 18 pages, 14 figures

> **TL;DR:** BootSeer深入分析并缓解了大型语言模型训练中的启动开销，通过系统级优化（如热块记录预取、依赖快照和条带化HDFS-FUSE）将启动时间减少了50%。

**AI_Comments:** 本文的创新点在于将研究焦点从传统的LLM运行时性能转移到此前被忽视但日益重要的启动开销。通过深入的生产数据分析揭示了该问题的严重性，并提出了一套实用的系统级优化方案Bootseer。其在生产环境中的50%启动开销削减证明了其显著的实用价值和重要性，对于提升大规模LLM训练效率和资源利用率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注运行时性能，但大规模LLM训练中的启动开销日益严峻，尤其是在故障频繁且迭代更新-调试周期长的工业级部署中。某训练集群中，仅启动开销就浪费了超过3.5%的GPU时间。

**Method:** 本文首先基于真实的生产数据，对LLM训练启动开销进行了首次深入的表征，分析了其组成部分、量化了直接影响并研究了其随作业规模的扩展性。基于这些洞察，设计了Bootseer，一个系统级优化框架，通过引入热块记录预取、依赖快照和条带化HDFS-FUSE三种技术，解决了容器镜像加载、运行时依赖安装和模型检查点恢复这三个主要的启动瓶颈。

**Result:** Bootseer已部署在生产环境中，并在真实的LLM训练工作负载上进行了评估，结果表明启动开销减少了50%。

**Conclusion:** 本文首次深入表征了LLM训练的启动开销，并提出了Bootseer这一有效的系统级优化框架，在生产环境中显著降低了启动开销，从而提高了LLM训练效率。

> **ai_Abstract:** 本文针对大规模LLM训练中日益突出的启动开销问题，首次基于生产数据进行了深入的表征分析。研究发现启动开销可浪费大量GPU时间。为此，作者提出了系统级优化框架Bootseer，通过热块记录预取、依赖快照和条带化HDFS-FUSE三项创新技术，有效解决了容器镜像加载、依赖安装和检查点恢复等关键瓶颈，最终在生产环境中将启动开销降低了50%。

> **摘要翻译:** 大型语言模型（LLM）已成为现代人工智能的基石，推动了自然语言处理的突破，并扩展到涉及图像、音频和视频的多模态任务。与大多数计算软件一样，区分普通运行时性能和启动开销非常重要。以往的研究主要集中在运行时性能：提高训练效率和稳定性。这项工作则专注于训练中日益关键的启动开销问题：即训练作业开始执行前的延迟。启动开销在大型工业级LLM中尤为重要，因为故障发生更频繁，并且多个团队在迭代更新-调试周期中操作。在我们一个训练集群中，仅启动开销就浪费了超过3.5%的GPU时间。
在这项工作中，我们首次基于真实的生产数据对LLM训练启动开销进行了深入的表征。我们分析了启动成本的组成部分，量化了其直接影响，并研究了它如何随作业规模扩展。这些洞察促成了Bootseer的设计，这是一个系统级优化框架，解决了三个主要的启动瓶颈：(a) 容器镜像加载，(b) 运行时依赖安装，以及 (c) 模型检查点恢复。为了缓解这些瓶颈，Bootseer引入了三种技术：(a) 热块记录预取，(b) 依赖快照，以及 (c) 条带化HDFS-FUSE。Bootseer已在生产环境中部署，并在真实的LLM训练工作负载上进行了评估，结果表明启动开销减少了50%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [252] [Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models](https://arxiv.org/abs/2502.14819)
> *从无奖励离线数据中学习：潜在动力学模型规划的案例*

*Vlad Sobal, Wancong Zhang, Kynghyun Cho, Randall Balestriero, Tim G. J. Rudner, Yann LeCun* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 离线强化学习, 潜在动力学模型, 零样本泛化, 无奖励数据, 模型基线比较

**Comment:** Project web page: https://latent-planning.github.io/

> **TL;DR:** 本文系统分析了在无奖励离线数据设置下，不同强化学习和基于控制的方法的性能。研究发现，当数据充足时，无模型强化学习表现优异；而基于模型的规划在泛化到新环境、轨迹拼接和数据效率方面表现出色，特别是使用潜在动力学模型进行规划在次优数据下的零样本泛化能力突出。

**AI_Comments:** 这项研究深入探讨了在无奖励离线数据背景下，无模型强化学习和基于模型的规划方法的相对优势。其创新之处在于系统性地比较了这两种范式，并特别强调了潜在动力学模型在零样本泛化和数据效率方面的潜力，这对于构建更通用和数据高效的AI智能体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在AI领域，一个长期目标是构建能够解决各种任务的智能体，包括在以前未见过的环境中。现有的强化学习和最优控制方法在从无奖励注释的离线轨迹中学习时的相对优缺点尚未得到充分探索。

**Method:** 本研究系统分析了在不同质量数据集下，不同强化学习（RL）和基于控制的方法的性能。在RL方面，考虑了目标条件和零样本方法。在控制方面，使用联合嵌入预测架构（JEPA）训练了一个潜在动力学模型并用于规划。研究了数据集特性（如数据多样性、轨迹质量和环境变异性）如何影响这些方法的性能。

**Result:** 结果表明，当有大量高质量数据可用时，无模型强化学习表现出色；而基于模型的规划在泛化到新的环境布局、轨迹拼接和数据效率方面表现出色。值得注意的是，使用潜在动力学模型进行规划是一种很有前景的从次优数据进行零样本泛化的方法。

**Conclusion:** 在从无奖励离线数据中学习时，无模型强化学习和基于模型的规划各有优势。基于模型的规划，特别是结合潜在动力学模型，在数据效率和泛化能力方面展现出巨大潜力，尤其是在零样本泛化和次优数据处理方面。

> **ai_Abstract:** 本研究系统地比较了在无奖励离线数据设置下，强化学习和基于控制的方法的性能。通过分析不同数据集特性对性能的影响，发现无模型强化学习在数据量充足时表现优异，而基于模型的规划（特别是使用潜在动力学模型）在泛化能力、轨迹拼接和数据效率方面更具优势，尤其在次优数据下的零样本泛化表现突出。

> **摘要翻译:** 人工智能的一个长期目标是构建能够在各种环境中解决各种任务的智能体，包括以前未见过的环境。两种主要方法解决了这一挑战：(i) 强化学习（RL），通过试错学习策略，以及 (ii) 最优控制，使用学习或已知的动力学模型规划动作。然而，在智能体必须从没有奖励注释的离线轨迹中学习的设置中，它们的相对优缺点仍未得到充分探索。在这项工作中，我们系统地分析了在不同质量数据集下，不同RL和基于控制的方法的性能。在RL方面，我们考虑了目标条件和零样本方法。在控制方面，我们使用联合嵌入预测架构（JEPA）训练了一个潜在动力学模型并将其用于规划。我们研究了数据集属性（如数据多样性、轨迹质量和环境变异性）如何影响这些方法的性能。我们的结果表明，当有大量高质量数据可用时，无模型RL表现出色，而基于模型的规划在泛化到新的环境布局、轨迹拼接和数据效率方面表现出色。值得注意的是，使用潜在动力学模型进行规划是一种很有前景的从次优数据进行零样本泛化的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [253] [Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations](https://arxiv.org/abs/2507.12854)
> *基于Transformer的Wi-Fi CSI幅度和相位扰动人体识别*

*Danilo Avola, Andrea Bernardini, Francesco Danese, Mario Lezoche, Maurizio Mancini, Daniele Pannone, Amedeo Ranaldi* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** Wi-Fi感知, 人体识别, CSI, Transformer, 静止识别

**Comment:** 

> **TL;DR:** 本文提出了一种基于Transformer的方法，利用Wi-Fi CSI的幅度和相位扰动，在受试者静止的情况下实现高精度的人体识别，克服了传统方法对运动的依赖。

**AI_Comments:** 该论文的创新之处在于提出了一种在受试者静止状态下进行人体识别的方法，克服了传统Wi-Fi感知依赖运动的局限性。通过利用CSI的精细幅度和相位扰动，并结合Transformer模型进行处理，实现了极高的识别精度。此外，使用低成本的商用Wi-Fi硬件（ESP32）进行数据采集，进一步证明了该方案在实际应用中的可行性和经济性。这项研究为非侵入式、保护隐私的人体识别提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有无线信号人体识别方法大多依赖于运动模式，例如步态，而通过无线信号进行人体识别，尤其是在用户静止的情况下，仍未得到充分探索。本文旨在解决这一空白，提供一种无需用户运动的非侵入式、保护隐私的人体识别方案。

**Method:** 本文提出了一种基于Transformer的方法，通过分析受试者静止时记录的信道状态信息（CSI）来识别个体。CSI捕获了人体与无线电信号独特交互产生的精细幅度与相位畸变。研究引入了一个在受控室内环境下使用ESP32设备采集的数据集，包含六名参与者在不同方向的观测数据。开发了一个定制的预处理流程，包括异常值去除、平滑和相位校准，以提高信号质量。采用双分支Transformer架构分别处理幅度和相位模态。

**Result:** 本文提出的方法达到了99.82%的分类准确率，优于卷积网络和多层感知器基线。

**Conclusion:** 研究结果证明了CSI扰动的区分潜力，突出了其以一致方式编码生物特征的能力。这进一步证实了在现实世界中，使用低成本商用Wi-Fi硬件进行被动、无设备人体识别的可行性。

> **ai_Abstract:** 该论文提出了一种基于Transformer的新型人体识别方法，利用Wi-Fi信道状态信息（CSI）在受试者静止时进行身份识别。与传统依赖运动模式的方法不同，本文利用人体对无线信号产生的精细幅度与相位扰动作为生物特征线索。通过定制的预处理流程和双分支Transformer架构，该方法在自建数据集上实现了99.82%的高分类准确率，验证了CSI在低成本Wi-Fi硬件上实现被动、无设备人体识别的潜力。

> **摘要翻译:** Wi-Fi感知作为一种非侵入式、保护隐私的替代方案，正在人体识别领域获得关注，以替代基于视觉的系统。然而，通过无线信号进行人体识别，尤其是在用户静止的情况下，仍未得到充分探索。大多数先前的基于无线的方法依赖于运动模式，例如步行步态，来提取生物特征线索。与此相反，我们提出了一种基于Transformer的方法，该方法通过分析受试者静止时记录的信道状态信息（CSI）来识别个体。CSI捕获了人体与无线电信号独特交互产生的精细幅度与相位畸变。为了支持评估，我们引入了一个在受控室内环境下使用ESP32设备采集的数据集，包含六名参与者在不同方向的观测数据。一个定制的预处理流程，包括异常值去除、平滑和相位校准，增强了信号质量。我们的双分支Transformer架构分别处理幅度和相位模态，并实现了99.82%的分类准确率，优于卷积网络和多层感知器基线。这些结果证明了CSI扰动的区分潜力，突出了其以一致方式编码生物特征的能力。它们进一步证实了在现实世界中，使用低成本商用Wi-Fi硬件进行被动、无设备人体识别的可行性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [260] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
> *基于基础视频扩散模型的通用双臂操作*

*Yao Feng, Hengkai Tan, Xinyi Mao, Guodong Liu, Shuhe Huang, Chendong Xiang, Hang Su, Jun Zhu* | **Category: cs.LG, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 双臂操作, 视频扩散模型, 机器人学习, 动作预测, 泛化能力

**Comment:** 

> **TL;DR:** 本文提出VIDAR框架，利用视频扩散预训练和掩码逆动力学模型，解决双臂机器人操作中数据稀缺和异构性问题，实现对未见过任务和背景的强大泛化能力，仅需极少量演示数据。

**AI_Comments:** 这项研究的创新之处在于将视频扩散模型与新颖的掩码逆动力学模型相结合，为双臂机器人操作提供了一个通用且高效的解决方案。其重要性在于显著减少了对大量数据的依赖，并展现了在多样化真实世界场景中的强大泛化能力，为未来可扩展的机器人操作奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 双臂机器人操作是解决复杂任务的基础，但数据稀缺和实体异构性严重阻碍了其在双臂设置中的进一步扩展。

**Method:** 本文提出了VIDAR（Video Diffusion for Action Reasoning）框架，这是一个两阶段框架。它利用大规模、基于扩散的视频预训练和一种新颖的掩码逆动力学模型进行动作预测。视频扩散模型在来自三个真实世界双臂机器人平台的75万个多视角视频上进行预训练，采用统一的观测空间编码机器人、摄像机、任务和场景上下文。掩码逆动力学模型学习掩码以从生成的轨迹中提取与动作相关的信息，无需像素级标签，并且这些掩码可以有效泛化到未见过的背景。

**Result:** 实验表明，在未见过的机器人平台上，VIDAR仅需20分钟的人类演示（仅为典型数据需求的1%），就能以强大的语义理解泛化到未见过的任务和背景，超越了最先进的方法。

**Conclusion:** 本文的研究结果强调了视频基础模型与掩码动作预测相结合的潜力，可以实现在多样化真实世界环境中可扩展和通用化的机器人操作。

> **ai_Abstract:** 本文提出了VIDAR框架，旨在解决双臂机器人操作中数据稀缺和异构性问题。VIDAR是一个两阶段系统，结合了在大规模多视角视频上预训练的视频扩散模型和一种新颖的掩码逆动力学模型，用于动作预测。该方法通过统一的观察空间和无需像素级标签的掩码学习，实现了高效的数据利用和对新环境的泛化。实验证明，VIDAR仅需极少量演示数据即可在未见过的任务和背景下表现出强大的泛化能力，优于现有SOTA方法，突显了视频基础模型在通用机器人操作中的巨大潜力。

> **摘要翻译:** 双臂机器人操作涉及对两个机械臂的协调控制，是解决挑战性任务的基础。尽管通用操作最近取得了进展，但数据稀缺和实体异构性仍然是双臂设置中进一步扩展的严重障碍。在本文中，我们引入了用于动作推理的视频扩散（VIDAR），这是一个两阶段框架，它利用大规模、基于扩散的视频预训练和一种新颖的掩码逆动力学模型进行动作预测。我们在来自三个真实世界双臂机器人平台的75万个多视角视频上预训练了视频扩散模型，利用统一的观测空间编码机器人、摄像机、任务和场景上下文。我们的掩码逆动力学模型学习掩码以从生成的轨迹中提取与动作相关的信息，无需像素级标签，并且这些掩码可以有效泛化到未见过的背景。我们的实验表明，在未见过的机器人平台上，VIDAR仅需20分钟的人类演示（仅为典型数据需求的1%），就能以强大的语义理解泛化到未见过的任务和背景，超越了最先进的方法。我们的研究结果强调了视频基础模型与掩码动作预测相结合的潜力，可以实现在多样化真实世界环境中可扩展和通用化的机器人操作。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [273] [Merge Kernel for Bayesian Optimization on Permutation Space](https://arxiv.org/abs/2507.13263)
> *排列空间上贝叶斯优化的归并核*

*Zikai Xie, Linjiang Chen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 贝叶斯优化, 排列空间, 归并核, 核函数, 复杂度降低

**Comment:** 8 pages, submitted to AAAI-26

> **TL;DR:** 提出了一种基于归并排序的归并核，用于排列空间上的贝叶斯优化，显著降低了计算复杂度并提高了性能。

**AI_Comments:** 这篇论文的创新点在于将排序算法的思想引入到排列空间核函数的设计中，特别是通过归并排序构建了计算复杂度更低的归并核。它解决了现有方法（如Mallows核）在处理大规模排列时计算成本过高的问题，并有效地结合了额外的描述符来增强核函数的鲁棒性和表达能力，对于提升排列空间贝叶斯优化的效率和效果具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前排列空间贝叶斯优化的最先进方法依赖于Mallows核，其表示复杂度为$\Omega(n^2)$，效率较低。

**Method:** 提出了一种基于排序算法的排列空间核函数生成新框架。在此框架下，引入了基于归并排序的“归并核”（Merge Kernel），将复杂度从二次方降至$\Theta(n\log n)$。为了提高鲁棒性和右不变性，还集成了三种轻量级、任务无关的描述符：移位直方图、分裂对线和滑动窗口模式。

**Result:** 经验评估表明，所提出的归并核在各种排列优化基准测试中始终优于最先进的Mallows核。生成的特征向量显著更短，计算时间为线性对数级，但仍能有效捕获有意义的排列距离。

**Conclusion:** 归并核为排列空间上的贝叶斯优化提供了一个更紧凑且更有效的解决方案。

> **ai_Abstract:** 这篇论文提出了一种新的排列空间核函数框架，灵感来源于Mallows核与排序算法的关系。核心贡献是引入了基于归并排序的“归并核”，该核将现有Mallows核的二次复杂度降至最优的$\Theta(n\log n)$。为了增强鲁棒性，还结合了移位直方图、分裂对线和滑动窗口模式等描述符。实验结果表明，归并核在性能上显著优于Mallows核，为排列空间上的贝叶斯优化提供了更高效、更紧凑的解决方案。

> **摘要翻译:** 贝叶斯优化（BO）算法是黑盒优化问题的标准工具。当前用于排列空间的最先进BO方法依赖于Mallows核——一个$\Omega(n^2)$的表示，它明确枚举了每个成对比较。受Mallows核与成对比较之间密切关系的启发，我们提出了一种基于排序算法在排列空间上生成核函数的新颖框架。在此框架内，Mallows核可以被视为从冒泡排序派生出的一个特殊实例。此外，我们引入了由归并排序构建的**归并核**（Merge Kernel），它将二次复杂度替换为$\Theta(n\log n)$，以实现可能的最低复杂度。生成的特征向量显著更短，可以在线性对数时间内计算，但仍能有效捕获有意义的排列距离。为了在不牺牲紧凑性的前提下提高鲁棒性和右不变性，我们进一步结合了三个轻量级、与任务无关的描述符：（1）移位直方图，它聚合了绝对元素位移并提供了全局错位信号；（2）分裂对线，通过对齐整个排列的两半中的元素来编码选定的长程比较；以及（3）滑动窗口模式，它总结了影响近邻目标的局部顺序模式。我们的经验评估表明，所提出的核在各种排列优化基准测试中始终优于最先进的Mallows核。结果证实，归并核为排列空间中的贝叶斯优化提供了一个更紧凑但更有效的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [281] [Manify: A Python Library for Learning Non-Euclidean Representations](https://arxiv.org/abs/2503.09576)
> *Manify: 一个用于学习非欧几里得表示的Python库*

*Philippe Chlenski, Kaizhu Du, Dylan Satow, Raiyan R. Khan, Itsik Pe'er* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 非欧几里得表示学习, 流形学习, Python库, 数据分析, 机器学习

**Comment:** 33 pages, 4 figures, 5 tables. Preprint

> **TL;DR:** Manify是一个开源Python库，用于非欧几里得表示学习和流形数据分析。

**AI_Comments:** Manify通过提供一个专门用于非欧几里得空间数据分析的综合性Python库，填补了现有工具的空白，对于处理复杂几何结构数据的机器学习任务具有重要意义。其开源性质也利于社区协作和发展。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过提供一套全面的工具来推进机器学习在流形数据分析方面的研究和应用。

**Method:** Manify利用流形学习技术，提供在非欧几里得空间中学习嵌入、进行分类和回归、估计流形曲率等工具。

**Result:** 提供了一个用于非欧几里得表示学习的开源Python库，包含多种工具，可用于在非欧几里得空间中进行嵌入学习、分类、回归和曲率估计。

**Conclusion:** Manify旨在通过提供全面的流形数据分析工具集来推进机器学习研究和应用。

> **ai_Abstract:** Manify是一个开源Python库，专注于非欧几里得表示学习。它利用流形学习技术，提供在非欧几里得空间中进行数据嵌入、分类、回归以及流形曲率估计的工具，旨在推动机器学习在流形数据分析领域的研究与应用。

> **摘要翻译:** 我们介绍了Manify，一个用于非欧几里得表示学习的开源Python库。Manify利用流形学习技术，提供了在（乘积）非欧几里得空间中学习嵌入、对存在于此类空间中的数据进行分类和回归、估计流形曲率等工具。Manify旨在通过提供一套全面的流形数据分析工具来推进机器学习的研究和应用。我们的源代码、示例和文档可在 https://github.com/pchlenski/manify 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [285] [Spectral Bellman Method: Unifying Representation and Exploration in RL](https://arxiv.org/abs/2507.13181)
> *谱贝尔曼方法：统一强化学习中的表示与探索*

*Ofir Nabati, Bo Dai, Shie Mannor, Guy Tennenholtz* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 表示学习, 贝尔曼方程, 探索, 谱方法

**Comment:** 

> **TL;DR:** 提出了一种新的谱贝尔曼表示框架，通过对齐特征协方差与贝尔曼动力学，改进了强化学习中的表示学习和探索。

**AI_Comments:** 这篇论文的创新点在于发现了贝尔曼算子变换与特征协方差结构之间的谱关系，并利用这一发现构建了一个理论上更严谨、更直接面向价值函数表示学习的框架。它不仅解决了现有表示学习与RL任务脱节的问题，还通过对齐特征协方差与贝尔曼动力学，有效促进了结构化探索，对强化学习领域，特别是基于价值的方法，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习表示学习主要源于模型学习方面，与RL任务不匹配；需要一种直接面向基于价值的RL的方法。

**Method:** 引入了“谱贝尔曼表示”（Spectral Bellman Representation）框架，源自固有贝尔曼误差（IBE）条件。核心在于发现零IBE条件下，价值函数分布通过贝尔曼算子的变换与特征协方差结构存在谱关系。这提供了一个理论基础的新目标来学习状态-动作特征，这些特征固有地捕获了这种贝尔曼对齐的协方差。该方法只需对现有算法进行简单修改。

**Result:** 学习到的表示通过将特征协方差与贝尔曼动力学对齐，实现了结构化探索，并提高了整体性能，特别是在挑战性的困难探索和长周期信用分配任务中。

**Conclusion:** 谱贝尔曼表示为基于价值的强化学习学习更强大、结构更合理的表示提供了一条原则性且有效的途径。

> **ai_Abstract:** 本文提出了“谱贝尔曼表示”框架，旨在解决现有强化学习表示学习与RL任务不匹配的问题。该框架基于固有贝尔曼误差条件，揭示了贝尔曼算子变换与特征协方差之间的谱关系，并以此设计了一个新的、理论驱动的特征学习目标。实验证明，该方法能实现结构化探索，并在困难探索和长周期信用分配任务中显著提升性能，为基于价值的强化学习提供了更强大的表示学习方法。

> **摘要翻译:** 强化学习中表示的效果已在理论和实证上得到证明。然而，现有的表示学习主要源于模型学习方面，与我们的RL任务不匹配。这项工作引入了谱贝尔曼表示，这是一个源自固有贝尔曼误差（IBE）条件的新颖框架，它与贝尔曼更新在可能的值函数空间中的基本结构对齐，因此直接面向基于价值的RL。我们的关键见解是发现了一种基本的谱关系：在零IBE条件下，通过贝尔曼算子对值函数分布的变换与特征协方差结构内在关联。这种谱连接为学习状态-动作特征提供了一个新的、有理论基础的目标，这些特征固有地捕获了这种与贝尔曼对齐的协方差。我们的方法只需要对现有算法进行简单修改。我们证明，我们学习到的表示通过将特征协方差与贝尔曼动力学对齐，实现了结构化探索，并提高了整体性能，特别是在具有挑战性的困难探索和长周期信用分配任务中。我们的框架自然地扩展到强大的多步贝尔曼算子，进一步扩大了其影响。谱贝尔曼表示为基于价值的强化学习学习更强大、结构更合理的表示提供了一条原则性且有效的途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [289] [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638)
> *推理微调重用基础模型中的潜在表示*

*Jake Ward, Chuqiao Lin, Constantin Venhoff, Neel Nanda* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 推理微调, 回溯, 潜在表示, 机制可解释性, 大语言模型

**Comment:** 6 pages, 6 figures. ICML 2025 Workshop on Actionable Interpretability

> **TL;DR:** 推理微调通过重用基础模型中已存在的潜在表示来形成新的行为电路，而不是从头学习新能力。

**AI_Comments:** 这篇论文在理解大型语言模型推理能力来源方面具有重要意义。它通过揭示推理微调如何重用基础模型中已有的潜在表示，为“能力重用”假说提供了有力的证据，而非传统的“从头学习”假说。这对于模型的可解释性研究和高效微调策略的开发具有启发性。研究方法结合了转向向量和对模型内部激活的深入分析，是神经符号学和机制可解释性领域的一个进步。

<details>
  <summary>Details</summary>

**Motivation:** 了解推理微调中出现的“回溯”行为的潜在机制，该行为被认为是推理模型能力增强的关键机制，但其工作原理尚不清楚。

**Method:** 作者在DeepSeek-R1-Distill-Llama-8B模型中，识别出基础模型Llama-3.1-8B残差流中一个特定的方向，该方向在用于引导推理模型时系统地诱导回溯行为。他们进一步分析了这种引导效果，并与token级别的属性进行对比。

**Result:** 发现DeepSeek-R1-Distill-Llama-8B中回溯行为的出现部分是由基础模型激活中已存在的重用方向驱动的。这个方向在基础模型中不会诱导回溯，表明推理微调过程重用了预先存在的表示来形成新的行为电路。此外，这种引导效果不能简单地用token级别的属性来解释。

**Conclusion:** 推理微调模型重用了预先存在的基础模型表示，而不是从头学习新的能力。

> **ai_Abstract:** 这篇论文研究了推理微调（Reasoning-Finetuning）如何使得模型展现出“回溯”（Backtracking）这一新兴行为。研究发现，在DeepSeek-R1-Distill-Llama-8B模型中，回溯的出现部分源于基础模型Llama-3.1-8B中一个已被“重用”的潜在方向。这个方向在基础模型本身不引起回溯，但在推理模型中通过引导能系统性地诱导回溯，且其效果无法通过简单的token级属性解释。这表明推理微调过程并非从零开始学习新能力，而是巧妙地重用了基础模型中已有的表示来构建新的行为回路。

> **摘要翻译:** 回溯是推理微调引发的一种新兴行为，已被证明是推理模型能力增强的关键机制。先前的研究已成功通过引导向量操纵这种行为，但其底层机制仍知之甚少。在这项工作中，我们表明DeepSeek-R1-Distill-Llama-8B中回溯的出现部分是由基础模型激活中已存在的重用方向驱动的。具体来说，我们识别出基础Llama-3.1-8B残差流中一个方向，当用于引导蒸馏推理模型时，它系统地诱导回溯，并且发现用这个方向进行引导的效果不能简单地用token级别的属性来解释。我们进一步发现这个方向在基础模型中不诱导回溯，这表明推理微调过程重用了预先存在的表示来形成新的行为电路。此外，我们假设这个方向是几个可能协同作用以介导回溯的方向之一。我们的发现提供了一个引人注目的图景，即推理微调模型重用了预先存在的基础模型表示，而不是从头学习新能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [305] [Task-Circuit Quantization: Leveraging Knowledge Localization and Interpretability for Compression](https://arxiv.org/abs/2504.07389)
> *任务电路量化：利用知识定位和可解释性进行压缩*

*Hanqi Xiao, Yi-Lin Sung, Elias Stengel-Eskin, Mohit Bansal* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 后训练量化, 混合精度, 任务电路, 知识定位, 大语言模型

**Comment:** COLM 2025 Camera Ready. Code:
  https://github.com/The-Inscrutable-X/TACQ

> **TL;DR:** 后训练量化（PTQ）在低比特设置下常导致性能下降。TaCQ是一种新的混合精度PTQ方法，通过识别并保留对下游任务性能至关重要的特定权重电路为16位，而量化其他权重。该方法在低比特率下显著优于现有基线，且内存成本边际增加，尤其适用于大型语言模型。

**AI_Comments:** TaCQ的创新之处在于将量化过程与“任务电路”这一概念相结合，通过利用知识定位和可解释性来选择性地保留对特定任务性能至关重要的权重。这种精细化的量化策略显著提升了模型在低比特率下的性能，对于大型语言模型在资源受限环境下的部署具有重要意义。其能够在不依赖任务特定条件设置的情况下依然表现出色，进一步证明了其方法的通用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 后训练量化（PTQ）虽然能减少模型内存占用，但在低至2-3比特设置下会显著降低模型下游任务性能。

**Method:** 本文开发了一种新的混合精度后训练量化方法——任务电路量化（TaCQ）。该方法通过将量化过程直接与特定的权重电路（定义为与下游任务性能相关的权重集合）关联起来，将这些关键权重保持在16比特，而将其余权重进行量化。具体而言，TaCQ通过对比未量化模型权重和均匀量化模型来估计量化导致的预期权重变化，并利用梯度信息预测对任务性能的影响，从而保留任务特定权重。

**Result:** TaCQ在QA、数学推理和Text-to-SQL任务上，对Llama-3和Qwen2.5模型进行量化时，使用相同的校准数据和更低的权重预算，性能优于现有混合精度量化方法。在2和3比特范围内实现了显著提升。具体地，仅用3.1比特就能恢复Llama-3-8B-Instruct模型96%的未量化16比特MMLU性能，比SPQR绝对提升5.25%。在2比特范围内，比最强的基线SliM-LLM平均提升14.74%。此外，即使不依赖特定任务条件，TaCQ仍能实现7.20%的提升，表明其识别重要权重的能力不限于任务特定设置。

**Conclusion:** TaCQ通过识别并保留对任务性能至关重要的权重，有效解决了低比特后训练量化导致的性能下降问题，在多种任务和大型语言模型上均取得了显著优于现有方法的表现，即使在非任务特定条件下也展现出强大的能力。

> **ai_Abstract:** TaCQ是一种新的混合精度后训练量化（PTQ）方法，旨在解决低比特量化导致的性能下降问题。它通过识别并保留对下游任务性能至关重要的“权重电路”为16比特，同时量化其他权重。该方法通过对比未量化和均匀量化模型来估计权重变化，并利用梯度信息预测对任务性能的影响。实验结果表明，TaCQ在低比特（2-3比特）设置下，在多种大型语言模型（如Llama-3和Qwen2.5）的QA、数学推理和Text-to-SQL任务上，均显著优于现有基线方法，即使在未进行任务特定条件设置时也能有效识别重要权重，实现了性能与内存效率的平衡。

> **摘要翻译:** 后训练量化（PTQ）通过将全精度权重映射到低比特权重，无需昂贵的再训练，从而减少模型的内存占用，但会降低其下游性能，尤其是在2到3比特的低位设置中。我们开发了一种新的混合精度PTQ方法，任务电路量化（TaCQ），它借鉴了自动化电路发现的理念，直接将量化过程与特定的权重电路（我们将其定义为与下游任务性能相关的权重集合）关联起来。这些权重保持为16比特，而其他权重则被量化，从而在仅增加边际内存成本的情况下保持性能。具体而言，TaCQ通过将未量化模型权重与均匀量化模型进行对比，以估计量化导致的预期权重变化，并利用梯度信息预测对任务性能的最终影响，从而使我们能够保留任务特定权重。我们将基于TaCQ的量化与现有混合精度量化方法进行了比较，同时在通用和任务特定数据上进行条件设置。在Llama-3和Qwen2.5的QA、数学推理和Text-to-SQL任务中，我们发现TaCQ在使用相同校准数据和更低权重预算的情况下，性能优于基线，在2和3比特范围内取得了重大改进。仅用3.1比特，我们就能够恢复Llama-3-8B-Instruct模型96%的未量化16比特MMLU性能，比SPQR绝对提升5.25%。我们还观察到，在2比特范围内，TaCQ比现有方法始终有显著的增益，比最强的基线SliM-LLM平均增益14.74%。此外，我们观察到在不进行特定任务条件设置的情况下也有7.20%的增益，这表明TaCQ识别重要权重的能力不限于任务条件设置。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [311] [Truthful Elicitation of Imprecise Forecasts](https://arxiv.org/abs/2503.16395)
> *不精确预测的真实性启发*

*Anurag Singh, Siu Lun Chau, Krikamol Muandet* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 不精确预测, 真实性启发, 评分规则, 认知不确定性, 社会选择理论

**Comment:** Accepted at UAI 2025 for Oral Presentation (fixed formatting)

> **TL;DR:** 针对不精确预测，本文提出一种基于双向通信和随机化评分规则的框架，以实现真实性启发。

**AI_Comments:** 这项工作通过引入双向通信和随机化评分规则，解决了在认知不确定性下不精确预测的真实性启发难题，对于提高安全关键领域决策的质量具有重要意义。它巧妙地将社会选择理论应用于预测领域，提出了一种新颖的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的概率预测评分规则在处理预测者面临认知不确定性时的不精确预测时效果不佳，限制了其在安全关键领域中的应用。

**Method:** 提出一个用于评分不精确预测（以信念集合形式给出）的框架。通过借鉴社会选择理论并引入一个双向通信框架，决策者首先分享其用于解决预测模糊性的聚合规则，从而帮助预测者在启发过程中解决不确定性。此外，还表明使用在聚合过程上随机化的适当评分规则可以实现不精确预测的真实性启发。

**Result:** 实现了不精确预测的真实性启发，并允许决策者将预测者的认知不确定性整合到其决策过程中。

**Conclusion:** 本文提出的方法能够实现不精确预测的真实性启发，并使决策者能够将预测者的认知不确定性整合到其决策过程中，从而提高可信度。

> **ai_Abstract:** 本文针对现有评分规则在处理不精确预测时的局限性，提出了一个用于评分不精确预测的新框架。该框架通过引入决策者与预测者之间的双向通信，并结合社会选择理论和随机化适当评分规则，实现了不精确预测的真实性启发。这使得决策者能够有效地整合预测者的认知不确定性，从而提高决策的可信度。

> **摘要翻译:** 概率预测的质量对于不确定性下的决策至关重要。虽然适当的评分规则激励了精确预测的真实报告，但当预测者对其信念面临认知不确定性时，这些规则就显得不足，限制了它们在决策者优先考虑适当不确定性管理的安全关键领域中的使用。为了解决这个问题，我们提出了一个用于评分不精确预测（以信念集合形式给出）的框架。尽管存在确定性评分规则的不可能结果，但我们通过将社会选择理论联系起来并引入一个双向通信框架来实现了真实性启发，其中决策者首先分享他们在下游决策中用于解决预测模糊性的聚合规则（例如，平均或最大-最小）。这反过来有助于预测者在启发过程中解决犹豫不决。我们进一步表明，使用在聚合过程上随机化的适当评分规则可以实现不精确预测的真实性启发。我们的方法允许决策者启发并将预测者的认知不确定性整合到他们的决策过程中，从而提高可信度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [314] [Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)](https://arxiv.org/abs/2507.12856)
> *精选数据上的监督微调是强化学习（且可以改进）*

*Chongli Qin, Jost Tobias Springenberg* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 监督微调, 强化学习, 行为克隆, 重要性加权, 大型语言模型

**Comment:** See project website for details and code at:
  https://independentresearch.ai/posts/iwsft

> **TL;DR:** 本文将精选数据上的监督微调（SFT）与强化学习（RL）联系起来，并提出一种改进的、基于重要性加权的SFT（iw-SFT）变体，该变体优化了更紧密的RL目标下界，并在LLM和连续控制任务中表现出竞争力。

**AI_Comments:** 本文通过建立SFT与RL的理论联系，提供了一个新颖的视角来理解SFT的有效性，并在此基础上提出了一个简单而有效的改进方法iw-SFT。其创新之处在于将RL的理论应用于SFT的改进，从而在不使用复杂RL算法的情况下提升模型性能。这对于LLM的微调和模仿学习领域具有重要意义，因为它提供了一种更高效、更易于实现的训练范式。

<details>
  <summary>Details</summary>

**Motivation:** 行为克隆（BC）在精选数据上的应用是大型语言模型（LLM）监督微调（SFT）和模仿学习的主流范式，其表现良好但缺乏与强化学习（RL）的明确理论联系。本文旨在从RL的角度理解SFT，并在此基础上提出改进方法。

**Method:** 作者将SFT理解为在稀疏奖励设置下最大化RL目标的一个下界。在此基础上，他们提出了一种重要性加权监督微调（iw-SFT）变体，该变体通过优化更紧密的RL目标下界来更接近RL训练。iw-SFT易于实现，并可推广到质量评分数据训练。

**Result:** iw-SFT相比于传统的SFT在精选数据上能提高性能。该SFT变体在大型语言模型和连续控制任务中与更先进的RL算法具有竞争力，例如在AIME 2024数据集上达到66.7%的准确率。

**Conclusion:** 监督微调（SFT）可以被理解为强化学习目标的一个下界优化，并且通过引入重要性加权（iw-SFT）可以进一步改进，使其更接近强化学习训练，从而在各种任务中获得与高级RL算法相当的性能。

> **ai_Abstract:** 本论文深入探讨了精选数据上的监督微调（SFT）与强化学习（RL）之间的理论联系，指出SFT可被视为在稀疏奖励环境下最大化RL目标下界的一种方式。在此基础上，作者提出了一种名为重要性加权监督微调（iw-SFT）的新变体，该变体通过优化更紧密的RL目标下界来提升性能，并能与先进的RL算法在大型语言模型和连续控制任务中竞争，例如在AIME 2024数据集上取得了显著成果。该方法易于实现且具普适性。

> **摘要翻译:** 在精选（或过滤）数据上进行行为克隆（BC）是大型语言模型监督微调（SFT）以及控制策略模仿学习的主要范式。在此，我们探讨了这种成功策略与通过强化学习（RL）寻找最优策略的理论和实践之间的联系。基于现有文献，我们阐明SFT可以被理解为在稀疏奖励设置下最大化RL目标的一个下界。这解释了其常被观察到的良好性能。从这个角度，我们意识到对SFT进行一个小修改可以引出一种重要性加权变体，它更接近于RL训练，因为它：i) 优化了RL目标的一个更紧密的下界，并且 ii) 相比于在精选数据上进行SFT，可以提高性能。我们将这种变体称为重要性加权监督微调（iw-SFT）。我们表明它易于实现，并且可以进一步推广到使用质量评分数据进行训练。由此产生的SFT变体在大型语言模型和连续控制任务的策略训练中与更先进的RL算法具有竞争力。例如，在AIME 2024数据集上达到了66.7%的准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [327] [V-Max: A Reinforcement Learning Framework for Autonomous Driving](https://arxiv.org/abs/2503.08388)
> *V-Max：一个用于自动驾驶的强化学习框架*

*Valentin Charraut, Waël Doulazmi, Thomas Tournaire, Thibault Buhet* | **Category: cs.LG, cs.AI, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 自动驾驶, 模拟器, V-Max, Waymax

**Comment:** RLC 25 - Camera-ready

> **TL;DR:** V-Max是一个开源的强化学习框架，旨在使强化学习在自动驾驶领域变得实用，通过利用Waymax模拟器和ScenarioNet方法实现大规模实验。

**AI_Comments:** V-Max框架通过提供一个标准化且高效的强化学习研究平台，有望显著推动强化学习在自动驾驶领域的实际应用。其创新之处在于结合了Waymax的硬件加速模拟能力和ScenarioNet的多样化场景生成，这对于克服现有模仿学习的局限性（如分布偏移）至关重要。该框架的开放性也可能促进社区合作和研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 学习型决策在自动驾驶（AD）中具有实现泛化策略的潜力，可以减少基于规则方法的工程开销。然而，主流的模仿学习（IL）存在分布偏移和模仿差距等局限性。强化学习（RL）是一个有前景的替代方案，但由于缺乏标准化和高效的研究框架，其在AD中的应用受到限制。

**Method:** 本文引入了V-Max，一个开源研究框架，提供了使强化学习在自动驾驶中实用所需的所有工具。V-Max建立在Waymax之上，这是一个为大规模实验设计的硬件加速AD模拟器。它通过使用ScenarioNet的方法进行扩展，从而能够快速模拟多样化的AD数据集。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** V-Max是一个新的开源强化学习（RL）框架，旨在解决RL在自动驾驶（AD）领域应用受限的问题。它通过提供必要的工具使RL在AD中变得实用，并建立在硬件加速的Waymax模拟器之上，同时结合ScenarioNet方法，以支持大规模和多样化的AD数据集模拟，克服了模仿学习的局限性。

> **摘要翻译:** 基于学习的决策制定有潜力实现可泛化的自动驾驶（AD）策略，从而减少基于规则方法的工程开销。模仿学习（IL）仍然是主流范式，受益于大规模人类演示数据集，但它存在固有的局限性，如分布偏移和模仿差距。强化学习（RL）提供了一个有前景的替代方案，但由于缺乏标准化和高效的研究框架，其在AD中的应用仍然有限。为此，我们引入了V-Max，一个开放的研究框架，提供了使RL在AD中实用所需的所有工具。V-Max建立在Waymax之上，这是一个为大规模实验设计的硬件加速AD模拟器。我们使用ScenarioNet的方法对其进行扩展，从而能够快速模拟多样化的AD数据集。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [332] [Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application](https://arxiv.org/abs/2506.05710)
> *基于潜在扩散模型的6G语义通信去噪接收器：从随机微分理论到应用*

*Xiucheng Wang, Honggang Jia, Nan Cheng* | **Category: cs.LG, cs.IT, cs.SY, eess.SY, math.IT** | **Updated: 2025-07-17**

**Keywords:** 语义通信, 潜在扩散模型, 生成式人工智能, 随机微分方程, 6G

**Comment:** 

> **TL;DR:** 本文提出了一种基于生成式AI的语义通信框架，利用随机微分方程和潜在扩散模型，实现了在低信噪比和数据分布偏移下的卓越去噪和语义感知性能，且无需训练，支持零样本泛化。

**AI_Comments:** 该论文的创新点在于将生成式AI（特别是潜在扩散模型）与随机微分理论相结合，用于解决6G语义通信中的关键挑战，即信道噪声和数据分布偏移。其提出的训练无关且支持零样本泛化的框架，显著提高了系统在恶劣通信环境下的性能和鲁棒性，具有重要的应用前景和理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强语义通信系统对抗信道噪声和传输数据分布偏移的鲁棒性。

**Method:** 本文提出了一种由生成式人工智能（GAI）驱动的新型语义通信框架。通过随机微分方程（SDEs）建立了理论基础，并推导出了任意信噪比（SNR）与最佳去噪时间步之间的闭式映射。此外，引入了一种数学缩放方法来解决分布不匹配问题，使接收到的语义特征与GAI的训练分布对齐。在此理论基础上，提出了一种基于潜在扩散模型（LDM）的语义通信框架，该框架结合了用于语义特征提取的变分自编码器（VAE），并使用预训练的扩散模型进行去噪。该系统是一个无需训练的框架，支持零样本泛化。

**Result:** 所提出的系统在低信噪比和分布外条件下表现出卓越的性能，提供了未来6G语义通信系统可扩展且鲁棒的解决方案。实验结果表明，所提出的语义通信框架在像素级精度和语义感知质量方面均达到了最先进的性能，在广泛的信噪比和数据分布范围内始终优于基线，且无需任何微调或后训练。

**Conclusion:** 本文提出的基于生成式AI的语义通信框架，通过结合随机微分理论和潜在扩散模型，为未来的6G语义通信系统提供了一个可扩展、鲁棒且性能卓越的去噪接收解决方案，尤其在低信噪比和数据分布偏移环境下表现出色。

> **ai_Abstract:** 本文提出了一种基于生成式AI（GAI）的新型语义通信框架，旨在提高系统对抗信道噪声和数据分布偏移的鲁棒性。该框架通过随机微分方程（SDEs）建立了理论基础，推导了最佳去噪时间步与信噪比的映射关系，并引入数学缩放方法解决分布不匹配问题。在此基础上，构建了一个基于潜在扩散模型（LDM）的语义通信系统，结合变分自编码器进行特征提取，并利用预训练扩散模型进行去噪。该系统无需训练，支持零样本泛化，并在低信噪比和分布外条件下表现出卓越性能，在像素级精度和语义感知质量方面均达到最先进水平，为6G语义通信提供了可扩展且鲁棒的解决方案。

> **摘要翻译:** 在本文中，提出了一种由生成式人工智能（GAI）赋能的新型语义通信框架，旨在增强对抗信道噪声和传输数据分布偏移的鲁棒性。利用随机微分方程（SDEs）建立了理论基础，从中推导出了任意信噪比（SNR）与最佳去噪时间步之间的闭式映射。此外，为了解决分布不匹配问题，引入了一种数学缩放方法，以使接收到的语义特征与GAI的训练分布对齐。在此理论基础上，提出了一种基于潜在扩散模型（LDM）的语义通信框架，该框架结合了用于语义特征提取的变分自编码器，其中使用预训练的扩散模型进行去噪。所提出的系统是一个无需训练的框架，支持零样本泛化，并在低信噪比和分布外条件下实现了卓越的性能，为未来的6G语义通信系统提供了可扩展且鲁棒的解决方案。实验结果表明，所提出的语义通信框架在像素级精度和语义感知质量方面均达到了最先进的性能，在广泛的信噪比和数据分布范围内始终优于基线，且无需任何微调或后训练。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [333] [GradNetOT: Learning Optimal Transport Maps with GradNets](https://arxiv.org/abs/2507.13191)
> *GradNetOT：使用GradNets学习最优传输映射*

*Shreyas Chaudhari, Srinivasa Pranav, José M. F. Moura* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 最优传输, 单调梯度网络, GradNets, Monge-Ampère方程, 机器人群控制

**Comment:** 

> **TL;DR:** 本文利用单调梯度网络（mGradNets）通过最小化基于Monge-Ampère方程的损失函数，直接学习最优传输映射，并将其应用于机器人群控制问题。

**AI_Comments:** 本文的创新点在于利用mGradNets这种新型神经网络来直接参数化并学习最优传输映射，这提供了一种新的解决最优传输问题的方法。其重要性体现在能够直接处理Monge-Ampère方程，并且在机器人群控制等实际应用中展现出潜力。

<details>
  <summary>Details</summary>

**Motivation:** 单调梯度函数在解决最优传输问题的Monge公式中起着核心作用，该问题广泛应用于流体动力学到机器人群控制等现代应用中。当传输成本是欧几里得距离的平方时，Brenier定理保证了唯一的最佳映射是一个凸函数的梯度，即一个单调梯度映射，并且它满足Monge-Ampère方程。现有的方法可能难以直接学习这种映射。

**Method:** 本文利用之前提出的单调梯度网络（mGradNets），这是一种直接参数化单调梯度映射空间的神经网络。通过最小化一个基于Monge-Ampère方程定义的训练损失函数，直接学习最优传输映射。

**Result:** 实验结果表明，mGradNets的结构偏置有助于学习最优传输映射。

**Conclusion:** 本文成功地利用mGradNets直接学习最优传输映射，并通过实验证明了其有效性，并将其应用于机器人群控制问题。

> **ai_Abstract:** 本文提出GradNetOT，一种利用单调梯度网络（mGradNets）来直接学习最优传输映射的方法。该方法通过最小化一个基于Monge-Ampère方程的训练损失函数来实现。研究表明，mGradNets的结构偏置有利于最优传输映射的学习，并且该方法被成功应用于机器人群控制问题。

> **摘要翻译:** 单调梯度函数在解决最优传输问题的Monge公式中起着核心作用，该问题广泛应用于流体动力学到机器人群控制等现代应用。当传输成本是欧几里得距离的平方时，Brenier定理保证了唯一的最佳映射是一个凸函数的梯度，即一个单调梯度映射，并且它满足Monge-Ampère方程。在[arXiv:2301.10862] [arXiv:2404.07361]中，我们提出了单调梯度网络（mGradNets），这是一种直接参数化单调梯度映射空间的神经网络。在这项工作中，我们利用mGradNets通过最小化一个使用Monge-Ampère方程定义的训练损失函数来直接学习最优传输映射。我们凭经验表明，mGradNets的结构偏置有助于学习最优传输映射，并将我们的方法应用于机器人群控制问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [335] [Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence](https://arxiv.org/abs/2504.17703)
> *联邦学习：隐私保护协作智能综述*

*Nusrat Jahan, Ratun Rahman, Michel Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 联邦学习, 隐私保护, 协作智能, 分布式机器学习, 综述

**Comment:** 

> **TL;DR:** 这篇综述深入探讨了联邦学习，涵盖其核心架构、生命周期、关键技术挑战（如非独立同分布数据、异构性、通信开销和隐私保护机制），并探讨了新兴趋势、实际应用、基准数据集以及未来的研究方向，旨在指导可扩展、高效和可信赖的联邦学习系统的发展。

**AI_Comments:** 这篇综述全面且深入地探讨了联邦学习的各个方面，从基础概念到前沿趋势和挑战，对该领域的初学者和研究人员都具有很高的参考价值。它清晰地指出了隐私保护在协作智能中的重要性，并为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）作为分布式机器学习领域的一种变革性范式，旨在解决数据隐私、安全和合规性日益增长的担忧。它允许移动设备、边缘节点或组织等多个客户端在不集中敏感数据的情况下协作训练共享的全局模型，这在医疗保健、金融和智能物联网系统等领域尤其具有吸引力。

**Method:** 这是一篇综述论文，提供了联邦学习的全面概述。文章首先介绍了其核心架构和通信协议，讨论了标准的FL生命周期，包括本地训练、模型聚合和全局更新。特别强调了处理非独立同分布数据、减轻系统和硬件异构性、减少通信开销以及通过差分隐私和安全聚合等机制确保隐私等关键技术挑战。此外，文章还探讨了FL研究中的新兴趋势，包括个性化FL、跨设备与跨筒仓设置，以及与强化学习和量子计算等其他范式的集成。论文还强调了实际应用，总结了常用的基准数据集和评估指标，并概述了开放研究问题和未来方向。

**Result:** 作为一篇综述，本文没有新的实验结果。它提供了一个联邦学习的全面概述，讨论了其核心架构、生命周期、关键技术挑战、隐私保护机制、新兴趋势、实际应用、基准数据集和评估指标，并指出了开放研究问题和未来研究方向。

**Conclusion:** 本文概述了开放研究问题和未来方向，旨在指导可扩展、高效和可信赖的联邦学习系统的发展。

> **ai_Abstract:** 本篇综述文章全面探讨了联邦学习（FL），一种无需集中敏感数据即可实现多方协作训练共享模型的分布式机器学习范式。文章详细介绍了FL的核心架构、通信协议及生命周期，并深入分析了非独立同分布数据、系统异构性、通信开销及隐私保护（如差分隐私和安全聚合）等关键技术挑战。此外，综述还涵盖了FL的研究新趋势、实际应用、基准数据集和评估指标，并展望了未来研究方向，旨在推动可扩展、高效、可信赖的FL系统发展。

> **摘要翻译:** 联邦学习（FL）已成为分布式机器学习领域的一种变革性范式，它使移动设备、边缘节点或组织等多个客户端能够在无需集中敏感数据的情况下协作训练共享的全局模型。这种去中心化方法解决了日益增长的数据隐私、安全和法规遵从性问题，使其在医疗保健、金融和智能物联网系统等领域特别有吸引力。本综述对联邦学习进行了简洁而全面的概述，从其核心架构和通信协议开始。我们讨论了标准的FL生命周期，包括本地训练、模型聚合和全局更新。特别强调了处理非独立同分布（non-IID）数据、减轻系统和硬件异构性、减少通信开销以及通过差分隐私和安全聚合等机制确保隐私等关键技术挑战。此外，我们还探讨了FL研究中的新兴趋势，包括个性化FL、跨设备与跨筒仓设置，以及与强化学习和量子计算等其他范式的集成。我们还强调了实际应用，并总结了FL研究中常用的基准数据集和评估指标。最后，我们概述了开放研究问题和未来方向，以指导可扩展、高效和可信赖的FL系统的发展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [337] [Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions](https://arxiv.org/abs/2507.12659)
> *通过迁移学习和自适应激活函数改进物理信息神经网络的外推性能*

*Athanasios Papastathopoulos-Katsaros, Alexandra Stavrianidi, Zhandong Liu* | **Category: cs.LG, cs.AI, cs.NA, math.DS, math.NA, stat.ML** | **Updated: 2025-07-16**

**Keywords:** 物理信息神经网络, 迁移学习, 自适应激活函数, 外推, 深度学习

**Comment:** 18 pages, 16 figures, 7 tables Accepted to ICANN 2025

> **TL;DR:** 物理信息神经网络（PINNs）在外推方面表现不佳且对激活函数敏感。本文提出结合迁移学习和自适应激活函数来提高PINN的外推能力，实验证明显著降低了外推误差，且计算成本无显著增加。

**AI_Comments:** 这篇论文通过引入迁移学习和自适应激活函数，有效解决了物理信息神经网络（PINNs）在外推能力和激活函数敏感性方面的核心挑战。其创新性在于将这两种技术结合，不仅提升了模型的预测准确性和鲁棒性，还保持了计算效率。这对于PINNs在实际科学和工程问题中的应用具有重要意义，特别是需要模型在未知领域进行可靠预测的场景。

<details>
  <summary>Details</summary>

**Motivation:** 物理信息神经网络（PINNs）在训练域之外通常表现出较差的外推性能，并且对激活函数（AFs）的选择高度敏感。

**Method:** 本文引入了一种迁移学习（TL）方法，在扩展训练域内使用少量精心选择的配置点来提高PINNs的外推能力。此外，提出了一种自适应激活函数，其形式为标准激活函数的线性组合，以提高模型的鲁棒性和准确性。

**Result:** 在外推域中，相对L2误差平均降低40%，平均绝对误差平均降低50%。该方法没有显著增加计算成本。

**Conclusion:** 本文提出的结合迁移学习和自适应激活函数的方法，能够有效提高物理信息神经网络（PINNs）的外推能力、鲁棒性和准确性，且计算成本低。

> **ai_Abstract:** 本文旨在解决物理信息神经网络（PINNs）在外推性能差和对激活函数选择敏感的问题。研究提出了一种结合迁移学习和自适应激活函数的新方法。迁移学习应用于扩展训练域，仅使用少量配置点；自适应激活函数则作为标准激活函数的线性组合。实验结果表明，该方法显著提升了PINNs在外推域的性能，相对L2误差平均降低40%，平均绝对误差平均降低50%，且计算成本无显著增加。

> **摘要翻译:** 物理信息神经网络（PINNs）是将系统控制物理定律融入学习过程的深度学习模型，非常适合解决复杂的科学和工程问题。最近，PINNs作为结合物理原理与数据驱动建模以提高预测精度的一个强大框架，受到了广泛关注。然而，尽管取得了成功，PINNs在训练域之外通常表现出较差的外推性能，并且对激活函数（AFs）的选择高度敏感。在本文中，我们引入了一种迁移学习（TL）方法来提高PINNs的外推能力。我们的方法在扩展训练域内应用迁移学习，仅使用少量精心选择的配置点。此外，我们提出了一种自适应激活函数，其形式为标准激活函数的线性组合，这提高了模型的鲁棒性和准确性。通过一系列实验，我们证明我们的方法在外推域中使相对L2误差平均降低40%，平均绝对误差平均降低50%，所有这些都没有显著增加计算成本。代码可在https://github.com/LiuzLab/PINN-extrapolation 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [341] [crowd-hpo: Realistic Hyperparameter Optimization and Benchmarking for Learning from Crowds with Noisy Labels](https://arxiv.org/abs/2504.09085)
> *crowd-hpo：针对带噪声标签的众包学习的现实超参数优化和基准测试*

*Marek Herde, Lukas Lührs, Denis Huseljic, Bernhard Sick* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 众包学习, 超参数优化, 噪声标签, 基准测试, crowd-hpo

**Comment:** Under review

> **TL;DR:** 本文介绍了crowd-hpo框架，用于在仅有噪声标签验证数据的情况下，对众包学习方法进行公平且现实的超参数优化和基准测试。

**AI_Comments:** 该论文通过引入crowd-hpo框架，解决了众包学习领域中一个关键但常被忽视的问题：在现实场景下进行超参数优化和基准测试。其创新点在于提出了一种仅依赖噪声标签验证数据来选择超参数的方法，这显著提高了评估的公平性和实用性。这对于推动众包学习研究的进展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 众包标签存在噪声，现有众包学习方法的评估通常采用默认或通过真实标签验证集调整的超参数配置，这导致性能不公平、次优，且不现实。此外，这些设置可能产生不同的方法排名，使得研究比较复杂。

**Method:** 本文引入了crowd-hpo框架，结合选择高性能超参数配置的标准，仅使用带有噪声众包标签的验证数据来评估众包学习方法。

**Result:** 使用神经网络进行的广泛实验表明，这些标准选择的超参数配置可以提高众包学习方法在带有真实标签的独立测试集上的泛化性能。

**Conclusion:** 将这些标准纳入实验研究对于实现更公平、更现实的基准测试至关重要。

> **ai_Abstract:** 本文提出了crowd-hpo框架，旨在解决众包学习方法评估中超参数优化不公平和不现实的问题。该框架允许在仅有噪声众包标签验证数据的情况下，选择高性能的超参数配置。实验证明，所提出的标准能够有效提升众包学习方法的泛化性能，从而促进更公平和现实的基准测试。

> **摘要翻译:** 众包是一种获取类别标签的成本效益解决方案。由于这些标签会受到噪声影响，因此已经提出了各种众包学习方法。通常，这些方法使用默认的超参数配置进行评估，导致不公平和次优的性能，或者使用通过带有真实类别标签的验证集调整的超参数配置，这代表了一种通常不现实的场景。此外，这两种设置都可能产生不同的方法排名，使研究比较复杂。因此，我们引入了crowd-hpo框架，用于评估众包学习方法，并结合选择高性能超参数配置的标准，而仅能访问带有噪声众包标签的验证数据。对神经网络进行的广泛实验表明，这些标准选择的超参数配置提高了众包学习方法的泛化性能，该性能是在带有真实标签的独立测试集上测量的。因此，将此类标准纳入实验研究对于实现更公平、更现实的基准测试至关重要。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [365] [Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows](https://arxiv.org/abs/2505.24189)
> *微调小型语言模型还是提示大型语言模型？以生成低代码工作流为例*

*Orlando Marquez Ayala, Patrice Bechard, Emily Chen, Maggie Baird, Jingfei Chen* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-16**

**Keywords:** 大型语言模型, 小型语言模型, 微调, 提示工程, 低代码工作流

**Comment:** 8 pages, 7 figures. Accepted to Workshop on Structured Knowledge for
  Large Language Models (SKnowLLM) at KDD 2025

> **TL;DR:** 对于需要结构化输出的特定领域任务，微调SLM在质量上仍优于提示LLM，平均提升10%。

**AI_Comments:** 这项研究在当前LLM盛行的背景下，重新审视了SLM微调的价值，特别是在需要结构化输出的特定领域任务上。其创新点在于通过实际对比证明了SLM微调的质量优势，而非仅仅关注成本或速度。这对于资源有限或对输出质量有严格要求的应用场景具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）的按令牌成本降低，但小型语言模型（SLMs）在实际应用中的优势（更快的推理速度、更低的成本）可能不再明确。本研究旨在探讨在需要结构化输出的特定领域任务中，SLM是否仍具有质量优势。

**Method:** 研究团队将微调SLM与提示LLM在生成JSON格式的低代码工作流任务上进行了比较，并进行了系统的错误分析。

**Result:** 研究发现，虽然一个好的提示可以产生合理的结果，但微调SLM可以将质量平均提高10%。

**Conclusion:** 对于需要结构化输出的特定领域任务，微调小型语言模型在质量上仍优于提示大型语言模型。

> **ai_Abstract:** 本研究探讨了在生成JSON格式的低代码工作流这一特定领域任务中，微调小型语言模型（SLMs）与提示大型语言模型（LLMs）的效果。尽管LLMs成本降低，但研究发现，对于需要结构化输出的任务，微调SLM在质量上仍有优势，平均提升10%。文章通过系统错误分析揭示了模型局限性。

> **摘要翻译:** 大型语言模型（LLMs）如GPT-4o，通过适当的提示可以处理广泛的复杂任务。随着按令牌成本的降低，微调小型语言模型（SLMs）在实际应用中的优势——更快的推理速度、更低的成本——可能不再明确。在这项工作中，我们提供了证据表明，对于需要结构化输出的特定领域任务，SLMs在质量上仍然具有优势。我们比较了在生成JSON格式的低代码工作流任务中，微调SLM与提示LLM的效果。我们观察到，虽然一个好的提示可以产生合理的结果，但微调可以将质量平均提高10%。我们还进行了系统的错误分析，以揭示模型的局限性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [366] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
> *扩展RL：通过长时间训练解锁LLMs中的多样化推理能力*

*Mingjie Liu, Shizhe Diao, Jian Hu, Ximing Lu, Xin Dong, Hao Zhang, Alexander Bukharin, Shaokun Zhang, Jiaqi Zeng, Makesh Narsimhan Sreedhar, Gerald Shen, David Mosallanezhad, Di Zhang, Jonas Yang, June Yang, Oleksii Kuchaiev, Guilin Liu, Zhiding Yu, Pavlo Molchanov, Yejin Choi, Jan Kautz, Yi Dong* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-16**

**Keywords:** 强化学习, 语言模型, 推理, 长时间训练, GRPO

**Comment:** 14 pages, 7 figures

> **TL;DR:** 通过长时间RL训练和特定技术，小型LLM在数学、编码和逻辑推理任务上表现显著提升。

**AI_Comments:** 本文证明了即使是小型语言模型，通过长时间的强化学习和一系列精细调整的技术（如可验证奖励、GRPO改进、KL正则化等），也能在多样的推理任务上取得显著进步。其创新点在于强调了“长时间训练”的重要性，并提出了具体的训练稳定性和性能提升策略。这对于资源有限的研究者来说，提供了一条提升LLM推理能力的新途径，具有重要的实践意义。公开发布模型也体现了对社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，通过链式思考和迭代探索等方法扩展测试时计算可以显著改善复杂任务，且大规模RL结合可验证奖励信号是关键。本文旨在探究长时间强化学习对小型语言模型在多样化推理领域的影响。

**Method:** 研究者在小型语言模型上进行了长时间的强化学习训练，并确定了有效训练的关键要素，包括：使用可验证的奖励任务、增强Group Relative Policy Optimization (GRPO)、以及提高训练稳定性和泛化能力的实用技术。具体引入了受控KL正则化、裁剪比和周期性参考策略重置作为解锁长期性能增益的关键组件。

**Result:** 模型在强基线上取得了显著改进，包括数学任务提升14.7%，编码任务提升13.9%，逻辑谜题任务提升54.8%。

**Conclusion:** 长时间强化学习结合特定技术（如可验证奖励、GRPO增强、KL正则化、裁剪比和周期性策略重置）可以显著提升小型语言模型在多样化推理任务上的性能。

> **ai_Abstract:** 本研究探讨了长时间强化学习对小型语言模型在多样化推理任务中的影响。通过引入可验证奖励、增强GRPO、以及采用受控KL正则化、裁剪比和周期性策略重置等技术，该模型在数学、编码和逻辑谜题等任务上取得了显著性能提升，证明了长时间RL训练在解锁LLMs推理能力方面的潜力。研究团队已公开发布模型以促进后续研究。

> **摘要翻译:** 近期在推理型语言模型（如OpenAI的O1和DeepSeek-R1）方面的进展表明，通过链式思考推理和迭代探索等方式扩展测试时计算，可以在数学和代码生成等复杂任务上取得显著改进。这些突破是由大规模强化学习推动的，特别是当其与提供客观且有根据的监督的可验证奖励信号相结合时。在本报告中，我们调查了长时间强化学习对小型语言模型在多样化推理领域的影响。我们的工作确定了有效训练的几个关键要素，包括使用可验证奖励任务、Group Relative Policy Optimization (GRPO) 的增强，以及提高训练稳定性和泛化能力的实用技术。我们引入了受控KL正则化、裁剪比和周期性参考策略重置作为解锁长期性能增益的关键组成部分。我们的模型在强大的基线上取得了显著改进，包括数学方面提升14.7%，编码方面提升13.9%，逻辑谜题任务方面提升54.8%。为了促进持续研究，我们公开发布了我们的模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [368] [An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System](https://arxiv.org/abs/2507.12873)
> *耳-EEG信号在新型生物识别认证系统中的研究*

*Danilo Avola, Giancarlo Crocetti, Gian Luca Foresti, Daniele Pannone, Claudio Piciarelli, Amedeo Ranaldi* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 耳-EEG, 生物识别认证, 深度神经网络, 脑电图, 用户识别

**Comment:** 

> **TL;DR:** 本文研究了使用耳内EEG信号进行生物识别认证的可行性，提出了一种基于耳-EEG的深度学习系统，并在现有数据集上取得了82%的平均识别准确率，显示了其在下一代生物识别系统中的潜力。

**AI_Comments:** 本文的创新点在于提出了使用耳-EEG进行生物识别认证，解决了传统头皮EEG设备不便携的问题。其重要性在于为开发用户友好型、可部署的下一代生物识别系统提供了新的方向。局限性可能在于目前只在一个数据集上进行了验证，且准确率仍有提升空间。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于头皮EEG的生物识别系统虽然安全，但由于电极设置繁琐，可用性较低。本研究旨在寻找一种用户友好的替代方案。

**Method:** 提出了一种新颖实用的框架，利用耳-EEG信号进行日常生物识别认证。该系统从耳-EEG信号中提取时间域和频谱特征的原始组合，并将其输入到全连接深度神经网络中进行主体识别。

**Result:** 在目前唯一可用于生物识别的耳-EEG数据集上，平均识别准确率达到82%。

**Conclusion:** 研究结果证实了耳-EEG作为下一代现实世界生物识别系统可行且可部署方向的潜力。

> **ai_Abstract:** 本文研究了使用耳-EEG信号进行生物识别认证的可能性，旨在解决传统头皮EEG系统可用性低的问题。研究提出了一种新颖的框架，通过从耳-EEG信号中提取时域和频域特征，并使用全连接深度神经网络进行用户识别。实验结果表明，该系统在主体识别任务中取得了82%的平均准确率，验证了耳-EEG在未来生物识别系统中的巨大潜力。

> **摘要翻译:** 本文探讨了使用通过耳内设备（通常称为耳-EEG）获取的EEG信号进行生物识别认证的可行性。传统的基于头皮EEG的生物识别系统虽然安全，但由于繁琐的头皮电极设置，通常可用性较低。在本研究中，我们提出了一种新颖实用的框架，利用耳-EEG信号作为日常生物识别认证的用户友好替代方案。该系统从耳-EEG信号中提取时间域和频谱特征的原始组合，并将其输入到全连接深度神经网络中进行主体识别。在目前唯一可用于不同目的（包括生物识别认证）的耳-EEG数据集上进行的实验结果显示出有前景的性能，在主体识别场景中平均准确率达到82%。这些发现证实了耳-EEG作为下一代现实世界生物识别系统可行且可部署方向的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [371] [Active Human Feedback Collection via Neural Contextual Dueling Bandits](https://arxiv.org/abs/2504.12016)
> *通过神经上下文对决赌博机进行主动人类反馈收集*

*Arun Verma, Xiaoqiang Lin, Zhongxiang Dai, Daniela Rus, Bryan Kian Hsiang Low* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 人类反馈, 对决赌博机, 非线性奖励, 偏好学习, Neural-ADB

**Comment:** 19 pages

> **TL;DR:** Neural-ADB是一种基于神经上下文对决赌博机框架的算法，旨在解决在潜在奖励函数为非线性时，有效收集人类偏好反馈的问题，并已在理论和实践中证明其有效性。

**AI_Comments:** 本文的创新点在于提出了Neural-ADB，将神经上下文对决赌博机框架应用于非线性奖励函数下的人类偏好反馈收集，这对于解决现实世界中更复杂的反馈场景具有重要意义。它不仅提供了理论保证，也通过实验证实了实用性，拓展了主动学习和偏好学习的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 收集人类偏好反馈通常成本高昂，现有方法虽然能更高效地选择反馈，但都假设底层奖励函数是线性的，这在在线推荐和大型语言模型对齐等许多实际应用中并不成立。本文旨在解决这一局限性。

**Method:** 我们提出了Neural-ADB算法，它基于神经上下文对决赌博机框架。该方法为在底层潜在奖励函数为非线性时收集人类偏好反馈提供了一种原则性且实用的方法。理论上，当偏好反馈遵循Bradley-Terry-Luce模型时，Neural-ADB学习到的策略的最差次优性差距会随着偏好数据集的增加而以亚线性速率下降。

**Result:** 理论结果表明，当偏好反馈遵循Bradley-Terry-Luce模型时，Neural-ADB学习到的策略的最差次优性差距会随着偏好数据集的增加而以亚线性速率下降。实验结果在偏好数据集上进一步证实了Neural-ADB的有效性。

**Conclusion:** Neural-ADB提供了一种在底层潜在奖励函数为非线性时，有效收集人类偏好反馈的原则性且实用的方法，并通过理论分析和实验结果验证了其有效性。

> **ai_Abstract:** 本文提出Neural-ADB，一种基于神经上下文对决赌博机框架的算法，旨在解决当底层潜在奖励函数为非线性时，高效收集人类偏好反馈的挑战。该方法克服了现有线性奖励函数假设的局限性，适用于在线推荐和LLM对齐等场景。研究从理论上证明，在Bradley-Terry-Luce模型下，Neural-ADB的次优性差距随数据量增加呈亚线性下降，并通过实验验证了其有效性。

> **摘要翻译:** 收集人类偏好反馈通常成本高昂，导致最近的工作开发出有原则的算法来更有效地选择它们。然而，这些工作假设底层奖励函数是线性的，这一假设在许多实际应用中并不成立，例如在线推荐和大型语言模型对齐。为了解决这一局限性，我们提出了Neural-ADB，一种基于神经上下文对决赌博机框架的算法，它为在底层潜在奖励函数为非线性时收集人类偏好反馈提供了一种原则性且实用的方法。我们从理论上证明，当偏好反馈遵循Bradley-Terry-Luce模型时，Neural-ADB学习到的策略的最差次优性差距会随着偏好数据集的增加而以亚线性速率下降。我们在偏好数据集上的实验结果进一步证实了Neural-ADB的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [381] [MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling](https://arxiv.org/abs/2507.13207)
> *MoTM：迈向基于连续建模的时间序列插补基础模型*

*Etienne Le Naour, Tahar Nabil, Ghislain Agoua* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 时间序列插补, 基础模型, 隐式神经表示, 域外泛化, 连续建模

**Comment:** 10th Workshop on Advanced Analytics and Learning on Temporal Data
  (AALTD), ECML 2025

> **TL;DR:** MoTM提出了一种基于隐式神经表示（INRs）混合模型的时间序列插补方法，旨在解决域外缺失值插补问题，并展现了强大的泛化能力。

**AI_Comments:** 本文的创新点在于首次尝试将隐式神经表示（INRs）与混合模型相结合，以构建一个针对时间序列缺失值插补的基础模型，特别是解决了传统INRs在分布偏移下的性能下降问题。其提出的MoTM模型通过将时间序列视为连续函数并结合适应性回归器，展现了在复杂缺失模式和域外场景下的强大泛化能力，这对于实际应用中处理不完整时间序列数据具有重要意义。该工作为时间序列基础模型在预测之外的另一关键任务——插补——开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管时间序列基础模型日益受到关注，但主要集中在预测任务上。然而，域外缺失值插补这一关键任务却在很大程度上未被充分探索。现有的隐式神经表示（INRs）虽然在特定分布下表现良好，但在分布偏移下表现不佳。

**Method:** 本文提出了MoTM（Mixture of Timeflow Models），它结合了独立训练的隐式神经表示（INRs）基础模型，每个模型针对不同类型的时间序列训练，并使用一个岭回归器在推理时适应观测到的上下文。MoTM基于新的时间序列是先前模式混合的理念。

**Result:** MoTM在各种插补场景（例如，块状和点状缺失、可变采样率）中，展示了强大的域内和域外泛化能力。

**Conclusion:** MoTM为开发适应性强的基础插补模型奠定了基础。

> **ai_Abstract:** MoTM（Mixture of Timeflow Models）是一种新型的时间序列插补方法，旨在解决现有隐式神经表示（INRs）在处理分布偏移时遇到的挑战，并填补域外缺失值插补领域的研究空白。该模型通过结合独立训练的INRs基础模型和一个适应性岭回归器，将时间序列建模为连续函数，从而能够处理各种缺失数据情况和采样率。实验结果表明，MoTM在域内和域外插补任务中均表现出强大的泛化能力，为构建适应性强的时间序列插补基础模型奠定了基础。

> **摘要翻译:** 近年来，时间序列基础模型引起了越来越多的关注，并主要集中在预测任务上。然而，缺失值的域外插补这一关键任务在很大程度上仍未得到充分探索。我们通过利用隐式神经表示（INRs）迈出了填补这一空白的第一步。INRs将时间序列建模为连续函数，并自然地处理各种缺失数据场景和采样率。尽管它们在特定分布内表现出强大的性能，但在分布偏移下却表现不佳。为了解决这个问题，我们引入了MoTM（Mixture of Timeflow Models），这是迈向时间序列插补基础模型的一步。MoTM基于新时间序列是先前模式混合的理念，它结合了INRs的基础模型（每个模型都在不同类型的时间序列上独立训练），以及一个在推理时适应观测上下文的岭回归器。我们展示了在各种插补场景（例如，块状和点状缺失、可变采样率）中强大的域内和域外泛化能力，为适应性强的基础插补模型铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [Data Transformation Strategies to Remove Heterogeneity](https://arxiv.org/abs/2507.12677)
> *数据转换策略以消除异构性*

*Sangbong Yoo, Jaeyoung Lee, Chanyoung Yoon, Geonyeong Son, Hyein Hong, Seongbum Seo, Soobin Yim, Chanyoung Jung, Jungsoo Park, Misuk Kim, Yun Jang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 数据异构性, 数据转换, 人工智能, 数据准备, 综述

**Comment:** 

> **TL;DR:** 本调查探讨了数据异构性及其来源，系统地分类并呈现了解决由数据格式差异引起的异构性的数据转换策略，同时阐明了每种策略的挑战，以满足AI数据准备的需求。

**AI_Comments:** 本文通过对数据异构性及其数据转换策略进行系统综述，填补了现有研究中缺乏全面总结的空白，尤其是在AI数据准备领域。其创新点在于系统地梳理了数据格式异构性的来源和相应的转换策略，并揭示了挑战，对AI数据预处理具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据异构性（特别是数据格式差异）普遍存在，导致数据利用复杂且常需专家介入。当前方法忽视了数据转换的关键作用，而随着AI应用的扩展，对简化数据准备的需求日益增长。尽管AI广泛应用，但关于当代数据转换方法的全面综述却很少。

**Method:** 本文是一项调查研究，旨在探讨数据异构性及其深层来源。它系统地分类并提出了解决由数据格式差异引起的异构性的策略，并阐明了每种策略固有的挑战。

**Result:** 本文系统地分类并提出了解决由数据格式差异引起的数据异构性的策略，并阐明了每种策略固有的挑战。

**Conclusion:** 本调查通过对数据异构性及其数据转换策略进行全面综述，填补了现有研究的空白，强调了数据转换在简化AI数据准备过程中的关键作用，并为选择合适的数据转换技术提供了见解。

> **ai_Abstract:** 本文是一项调查研究，旨在解决普遍存在的数据异构性问题，特别是由于数据格式差异引起的问题。它强调了在当前方法忽视数据转换作用，且AI应用日益增长的背景下，数据转换在简化数据准备过程中的重要性。该调查系统地探讨了数据异构性的来源，并分类介绍了旨在消除数据格式差异所导致异构性的数据转换策略，同时分析了每种策略的挑战。

> **摘要翻译:** 数据异构性是一个普遍存在的问题，源于各种相互冲突的因素，使得数据利用变得复杂。这种不确定性，特别是数据格式差异导致的不确定性，经常需要专家介入才能找到解决方案。当前的方法主要解决与数据结构和模式相关的冲突，往往忽视了数据转换所发挥的关键作用。随着人工智能（AI）利用的持续扩展，对更精简的数据准备过程的需求日益增长，数据转换变得至关重要。它定制训练数据以提高AI学习效率，并调整输入格式以适应不同的AI模型。选择合适的数据转换技术对于保留关键数据细节至关重要。尽管AI已广泛集成到各个行业，但关于当代数据转换方法的全面综述却很少见。本调查探讨了数据异构性及其深层来源的复杂性。它系统地分类并提出了解决由数据格式差异引起的异构性的策略，阐明了每种策略固有的挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [392] [The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks](https://arxiv.org/abs/2502.05668)
> *同质神经网络上（随机）次梯度下降的后期训练动态*

*Sholom Schechtman, Nicolas Schreuder* | **Category: cs.LG, cs.NE, math.OC, stat.ML** | **Updated: 2025-07-17**

**Keywords:** 随机次梯度下降, 同质神经网络, 隐式偏差, 后期训练动态, 分类边距

**Comment:** Accepted/presented at the 38th Annual Conference on Learning Theory
  (COLT 2025)

> **TL;DR:** 本文分析了常数步长随机次梯度下降（SGD）在同质神经网络二元分类任务中的隐式偏差，并证明了归一化SGD迭代在后期训练阶段收敛到归一化分类边距的临界点集。

**AI_Comments:** 本文的创新之处在于首次将梯度下降的离散动态分析扩展到非光滑和随机的设置，这对理解深度学习中随机优化算法的隐式偏差具有重要意义。通过将SGD动态解释为保守场流的欧拉式离散化，提供了一个新的理论视角。

<details>
  <summary>Details</summary>

**Motivation:** 分析常数步长随机次梯度下降（SGD）的隐式偏差。

**Method:** 考虑使用ReLU型激活函数（如MLP和无偏置CNN）的同质神经网络进行二元分类。将归一化SGD迭代的动态解释为与归一化分类边距相关的保守场流的欧拉式离散化。

**Result:** 归一化SGD迭代在后期训练阶段（假设数据被正确分类且具有正归一化边距）收敛到归一化边距的临界点集。主要结果适用于指数或逻辑损失的二元分类。

**Conclusion:** 在同质神经网络的二元分类任务中，常数步长随机次梯度下降在后期训练时，其归一化迭代会收敛到归一化分类边距的临界点。这是首次将梯度下降的离散动态分析扩展到非光滑和随机设置。

> **ai_Abstract:** 本文研究了常数步长随机次梯度下降（SGD）在同质神经网络二元分类任务中的隐式偏差。通过将归一化SGD迭代的动态解释为归一化分类边距的保守场流的欧拉式离散化，作者证明了在后期训练阶段，归一化SGD迭代会收敛到归一化边距的临界点集。这项工作首次将梯度下降的离散动态分析扩展到非光滑和随机环境，并适用于指数或逻辑损失的二元分类。

> **摘要翻译:** 我们分析了常数步长随机次梯度下降（SGD）的隐式偏差。我们考虑了使用同质神经网络进行二元分类的设置——这是一大类具有ReLU型激活函数的深度神经网络，例如多层感知机（MLP）和无偏置卷积神经网络（CNN）。我们将归一化SGD迭代的动态解释为与归一化分类边距自然相关的保守场流的欧拉式离散化。基于这种解释，我们证明了归一化SGD迭代在后期训练阶段（即假设数据被正确分类且具有正归一化边距）收敛到归一化边距的临界点集。据我们所知，这是首次将Lyu和Li（2020）关于梯度下降离散动态的分析扩展到非光滑和随机设置。我们的主要结果适用于使用指数或逻辑损失的二元分类。我们还讨论了向更一般设置的扩展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [393] [A Comprehensive Survey of Synthetic Tabular Data Generation](https://arxiv.org/abs/2504.16506)
> *综合性表格数据生成综述*

*Ruxue Shi, Yili Wang, Mengnan Du, Xu Shen, Yi Chang, Xin Wang* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 合成表格数据, 生成模型, 扩散模型, 大型语言模型, 综述

**Comment:** 

> **TL;DR:** 本综述全面回顾了合成表格数据生成方法，涵盖传统方法、扩散模型和LLM，旨在提供全面理解并指明未来方向。

**AI_Comments:** 这篇综述的重要性在于它填补了现有文献的空白，首次全面整合了扩散模型和大型语言模型等前沿技术在合成表格数据生成领域的应用。这为研究人员和从业者提供了更广阔的视角，有助于推动该领域未来的创新和发展。

<details>
  <summary>Details</summary>

**Motivation:** 真实世界中表格数据的使用受限于数据稀缺、隐私问题和类别不平衡。合成表格数据生成是解决方案，但现有综述多局限于特定方法，缺乏对最新进展（如扩散模型和LLM）的全面整合。

**Method:** 本综述对合成表格数据生成方法进行了结构化和深入的审查，分为三个核心部分：背景（涵盖生成流程、定义、方法、后处理和评估）、生成方法（分类为传统方法、扩散模型方法和基于LLM的方法，并比较其架构、生成质量和适用性）以及应用和挑战（总结用例、数据集和开放挑战）。

**Result:** 本综述全面回顾了合成表格数据生成方法，包括传统方法、扩散模型和基于LLM的方法，并对其架构、生成质量和适用性进行了比较，同时总结了实际用例、常见数据集以及异质性、数据保真度和隐私保护等开放挑战。

**Conclusion:** 本综述旨在为研究人员和从业者提供对该领域的整体理解，并指出合成表格数据生成未来工作的关键方向。

> **ai_Abstract:** 本文对合成表格数据生成领域进行了全面综述。鉴于真实表格数据在应用中面临稀缺性、隐私和不平衡等挑战，合成数据生成作为解决方案应运而生。现有综述多限于特定技术，本综述则整合了包括扩散模型和大型语言模型在内的最新进展。综述内容涵盖背景、生成方法（传统、扩散模型、LLM）及其比较，以及应用和开放挑战，旨在为研究者提供全面理解并指明未来研究方向。

> **摘要翻译:** 表格数据是医疗、金融和教育等实际应用中最普遍和重要的数据格式之一。然而，其在机器学习中的有效使用常常受到数据稀缺、隐私问题和类别不平衡的限制。合成表格数据生成已成为一种强大的解决方案，它利用生成模型学习底层数据分布并生成逼真、隐私保护的样本。尽管该领域受到越来越多的关注，但大多数现有综述都狭隘地关注特定方法（例如GANs或隐私增强技术），缺乏整合扩散模型和大型语言模型（LLMs）等最新进展的统一和全面视角。
在本综述中，我们对合成表格数据生成方法进行了结构化和深入的审查。具体而言，本综述分为三个核心部分：（1）背景，涵盖整体生成流程，包括问题定义、合成表格数据生成方法、后处理和评估；（2）生成方法，我们将现有方法分为传统生成方法、扩散模型方法和基于LLM的方法，并从架构、生成质量和适用性方面进行比较；（3）应用和挑战，总结了实际用例、重点介绍了常见数据集，并讨论了异质性、数据保真度和隐私保护等开放挑战。
本综述旨在为研究人员和从业者提供对该领域的整体理解，并指出合成表格数据生成未来工作的关键方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [408] [Cross-Layer Discrete Concept Discovery for Interpreting Language Models](https://arxiv.org/abs/2506.20040)
> *跨层离散概念发现用于解释语言模型*

*Ankur Garg, Xuemin Yu, Hassan Sajjad, Samira Ebrahimi Kahou* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-16**

**Keywords:** 跨层概念发现, 语言模型解释, VQ-VAE, 向量量化, Transformer

**Comment:** 

> **TL;DR:** 提出CLVQ-VAE框架，通过向量量化解决Transformer层间信息混合和冗余问题，以发现可解释的离散概念。

**AI_Comments:** 该论文通过引入CLVQ-VAE框架，创新性地解决了Transformer模型中跨层信息混合和冗余导致的概念难以解释的问题。其核心贡献在于利用向量量化将复杂的、重复的残差流特征转化为紧凑、可解释的离散概念向量。方法中结合top-k温度采样、EMA码本更新以及缩放球面k-means++等技术，体现了对离散潜在空间探索和语义对齐的精细控制。这对于提升大型语言模型的可解释性具有重要意义，克服了传统单层分析的局限。

<details>
  <summary>Details</summary>

**Motivation:** 在Transformer模型中，由于残差流混合和复制信息，揭示跨层涌现概念是一个重大挑战。当前研究主要关注单层表示，忽视了跨层叠加和冗余，且通常直接分析激活模式或使用探针分类器映射到有限预定义概念，这些方法存在局限性。

**Method:** 我们提出跨层VQ-VAE（CLVQ-VAE），一个利用向量量化将跨层表示映射并折叠重复残差流特征为紧凑、可解释概念向量的框架。该方法独特地结合了量化过程中的top-k基于温度的采样与EMA码本更新，实现对离散潜在空间的受控探索并保持码本多样性。此外，通过使用缩放球面k-means++进行码本初始化，该方法根据方向相似性而非幅度进行聚类，更好地与词嵌入空间中的语义结构对齐。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种名为跨层VQ-VAE（CLVQ-VAE）的新框架，旨在解决大型语言模型中跨层概念发现的挑战。现有方法忽视了Transformer层间残差流的信息混合和冗余。CLVQ-VAE利用向量量化技术，将跨层表示中的重复特征压缩为可解释的离散概念向量。该框架通过结合top-k温度采样和EMA码本更新来探索离散潜在空间，并通过缩放球面k-means++进行码本初始化，以更好地捕获语义结构。

> **摘要翻译:** 揭示Transformer层之间涌现的概念仍然是一个重大挑战，因为残差流线性混合和复制信息，模糊了大型语言模型中特征的演变方式。当前的研究工作主要检查单层神经网络表示，从而忽视了这种跨层叠加及其引入的冗余。这些表示通常要么直接分析激活模式，要么传递给探针分类器，将其映射到一组有限的预定义概念。为了解决这些局限性，我们提出了跨层VQ-VAE（CLVQ-VAE），一个使用向量量化来映射跨层表示的框架，并在此过程中将重复的残差流特征折叠成紧凑、可解释的概念向量。我们的方法独特地结合了量化过程中基于top-k温度的采样与EMA码本更新，提供对离散潜在空间的受控探索，同时保持码本多样性。我们通过缩放球面k-means++进一步增强了该框架的码本初始化，该方法通过方向相似性而非幅度进行聚类，更好地与词嵌入空间中的语义结构对齐。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [410] [Topology-Aware Activation Functions in Neural Networks](https://arxiv.org/abs/2507.12874)
> *神经网络中的拓扑感知激活函数*

*Pavel Snopov, Oleg R. Musin* | **Category: cs.LG, cs.NE** | **Updated: 2025-07-17**

**Keywords:** 拓扑感知, 激活函数, 神经网络, SmoothSplit, ParametricSplit

**Comment:** Accepted to ESANN 2025. Published in the ESANN 2025 proceedings

> **TL;DR:** 本研究提出了新的拓扑感知激活函数SmoothSplit和ParametricSplit，它们通过引入拓扑“切割”能力，使神经网络能更有效地处理数据拓扑，尤其在低维层中表现出色。

**AI_Comments:** 这项研究的创新点在于提出了具有拓扑“切割”能力的新型激活函数，解决了传统激活函数在处理复杂数据拓扑时的不足。其重要性在于为低维神经网络层提供了性能提升的潜力，并为设计更有效的数据流形转换机制开辟了新途径。论文提供了代码，这有利于研究的可复现性和进一步的探索。

<details>
  <summary>Details</summary>

**Motivation:** 传统激活函数如ReLU在处理数据拓扑方面存在局限性，本研究旨在探索新的激活函数来增强神经网络在训练过程中操作数据拓扑的能力。

**Method:** 本研究提出了两种新的激活函数：SmoothSplit和ParametricSplit。这些函数引入了拓扑“切割”能力，使网络能够有效地转换复杂数据流形。研究通过在合成和真实世界数据集上进行实验来验证这些函数。

**Result:** 实验证明，ParametricSplit在低维设置中优于传统激活函数，同时在高维设置中保持了竞争力。

**Conclusion:** 研究结果强调了拓扑感知激活函数在推进神经网络架构方面的潜力。

> **ai_Abstract:** 本研究针对传统激活函数在处理数据拓扑方面的局限性，提出了两种新型拓扑感知激活函数SmoothSplit和ParametricSplit。这些函数通过引入“拓扑切割”能力，显著提升了神经网络在低维数据流形转换中的性能。实验结果表明，ParametricSplit在低维场景中表现优异，并在高维场景中保持竞争力，凸显了此类激活函数在未来神经网络架构中的应用潜力。

> **摘要翻译:** 本研究探索了新颖的激活函数，这些函数增强了神经网络在训练过程中操作数据拓扑的能力。在传统激活函数（如ReLU）的局限性基础上，我们提出了SmoothSplit和ParametricSplit，它们引入了拓扑“切割”能力。这些函数使网络能够有效地转换复杂数据流形，从而改善了在低维层场景中的性能。通过在合成和真实世界数据集上的实验，我们证明了ParametricSplit在低维设置中优于传统激活函数，同时在高维设置中保持了竞争力。我们的发现突出了拓扑感知激活函数在推进神经网络架构方面的潜力。代码可通过https://github.com/Snopoff/Topology-Aware-Activations获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [412] [Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction](https://arxiv.org/abs/2505.20755)
> *Uni-Instruct: 通过统一扩散散度指令实现一步扩散模型*

*Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 一步扩散模型, 扩散蒸馏, f-散度, 统一框架, 生成模型

**Comment:** 

> **TL;DR:** 该论文提出了Uni-Instruct，一个统一的理论驱动框架，用于一步扩散模型蒸馏，实现了最先进的性能。

**AI_Comments:** Uni-Instruct的创新在于其统一了多种现有的一步扩散蒸馏方法，并提供了坚实的理论基础（f-散度扩散扩展理论）。它不仅解决了理论上的可处理性问题，还在多个基准测试中取得了突破性的性能，尤其是在ImageNet上超越了79步的教师模型，这对于高效的扩散模型应用具有重要意义。其在文本到3D生成等更广泛任务上的应用潜力也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的一步扩散蒸馏方法缺乏统一的理论框架，且原始扩展的f-散度存在难以处理的问题，因此需要提出一种可处理的损失函数来有效训练一步扩散模型。

**Method:** 论文提出了Uni-Instruct框架，该框架基于f-散度家族的扩散扩展理论，统一了十多种现有的一步扩散蒸馏方法。通过引入关键理论克服了原始扩展f-散度的不可处理性，得到了一种等价且可处理的损失函数，通过最小化该损失函数来训练一步扩散模型。

**Result:** 在CIFAR10无条件生成上，FID达到1.46；在条件生成上，FID达到1.38。在ImageNet-64x64生成上，一步生成FID达到1.02，显著优于其79步教师扩散模型（1.02 vs 2.35）。在文本到3D生成任务中，表现良好，在生成质量和多样性方面略优于SDS和VSD等方法。

**Conclusion:** Uni-Instruct的坚实理论和实证贡献将有助于未来关于一步扩散蒸馏和扩散模型知识迁移的研究。

> **ai_Abstract:** 本文提出了Uni-Instruct，一个统一的理论驱动框架，旨在整合并改进现有的一步扩散蒸馏方法。该框架基于新颖的f-散度扩散扩展理论，并解决了原始理论的计算难题，提出了一种可行的损失函数。Uni-Instruct不仅提供了对现有方法的新颖理论理解，还在多个图像生成基准测试（如CIFAR10和ImageNet）以及文本到3D生成任务中取得了最先进的性能，显著提升了一步扩散模型的效率和质量。

> **摘要翻译:** 在本文中，我们通过一个理论驱动的框架统一了十多种现有的一步扩散蒸馏方法，例如Diff-Instruct、DMD、SIM、SiD、$f$-distill等，我们将其命名为\textbf{\emph{Uni-Instruct}}。Uni-Instruct的灵感来源于我们提出的f-散度家族的扩散扩展理论。然后，我们引入了关键理论，克服了原始扩展f-散度难以处理的问题，从而得到了一种等价且可处理的损失函数，通过最小化扩展f-散度家族有效地训练一步扩散模型。Uni-Instruct引入的新颖统一不仅提供了新的理论贡献，有助于从高层次理解现有方法，而且还带来了最先进的一步扩散生成性能。在CIFAR10生成基准测试中，Uni-Instruct在无条件生成方面取得了创纪录的Frechet Inception Distance (FID) 值\textbf{\emph{1.46}}，在条件生成方面取得了\textbf{\emph{1.38}}。在ImageNet-$64\times 64$生成基准测试中，Uni-Instruct实现了一步生成新的SoTA FID \textbf{\emph{1.02}}，这比其79步教师扩散模型有显著的1.33的改进幅度（1.02 vs 2.35）。我们还将Uni-Instruct应用于更广泛的任务，如文本到3D生成。对于文本到3D生成，Uni-Instruct给出了不错的结果，在生成质量和多样性方面略微优于以前的方法，如SDS和VSD。Uni-Instruct的坚实理论和实证贡献都可能有助于未来关于一步扩散蒸馏和扩散模型知识迁移的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [416] [Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets](https://arxiv.org/abs/2507.13250)
> *利用异步跨境市场数据改进欧洲市场日前电力价格预测*

*Maria Margarida Mascarenhas, Jilles De Blauwe, Mikael Amelin, Hussain Kazmi* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 电力价格预测, 异步市场数据, 跨境交易, 日前市场, 欧洲能源市场

**Comment:** Both Maria Margarida Mascarenhas and Jilles De Blauwe contributed
  equally to the paper

> **TL;DR:** 本研究表明，将来自关闸时间较早的互联市场的异步价格数据纳入预测模型，可以显著提高比利时和瑞典日前电力价格的预测准确性，为市场参与者提供优化策略的指导。

**AI_Comments:** 该论文的创新点在于提出了利用不同关闸时间的异步跨境市场数据来改进电力价格预测的新思路，这在日益互联的欧洲能源市场中具有重要实践意义。研究不仅证实了这种方法的有效性，还深入探讨了模型校准频率和数据量对性能的影响，并结合可解释性分析提供了实际操作中的宝贵见解。其结果对于市场参与者优化投标策略具有直接指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确的短期电力价格预测对于日前市场中战略性地安排需求和发电投标至关重要。尽管数据驱动技术在提高预测准确性方面表现出色，但它们严重依赖输入协变量的质量。本研究旨在探讨利用不同关闸时间导致的异步公布价格是否能提高其他关闸时间较晚的市场预测准确性。

**Method:** 研究采用最先进的模型集成方法，通过纳入来自关闸时间较早的互联市场（德国-卢森堡、奥地利和瑞士）的价格数据，来评估其对比利时（BE）和瑞典（SE3）投标区预测准确性的影响。同时，还进行了模型可解释性分析。

**Result:** 将来自关闸时间较早的互联市场价格数据纳入模型后，比利时（BE）和瑞典（SE3）投标区的预测准确性分别显著提高了22%和9%。这种改进在一般和极端市场条件下均成立。此外，研究发现频繁的模型重新校准对于最大化准确性是必要的，但会带来显著的额外计算成本；同时，使用更多市场数据并不总是能带来更好的性能。

**Conclusion:** 这些研究结果为市场参与者和决策者提供了宝贵的指导，有助于他们在日益互联和波动的欧洲能源市场中优化投标策略。

> **ai_Abstract:** 本研究探讨了利用欧洲不同关闸时间导致的异步跨境市场数据，以提高日前电力价格预测的准确性。通过采用先进的模型集成方法，研究发现将来自关闸时间较早的互联市场（如德国-卢森堡、奥地利、瑞士）的价格数据纳入模型，能显著提升比利时和瑞典市场的预测准确性（分别提高22%和9%），无论是在一般还是极端市场条件下。研究还指出，频繁的模型校准虽能提高准确性但计算成本高昂，且并非数据越多性能越好。这些发现为优化欧洲能源市场的投标策略提供了重要指导。

> **摘要翻译:** 准确的短期电力价格预测对于日前市场中战略性地安排需求和发电投标至关重要。近年来，数据驱动技术在实现高预测准确性方面展现出显著优势，但它们严重依赖输入协变量的质量。在本文中，我们研究了由于某些投标区关闸时间（GCTs）不同而导致的异步公布价格是否能提高其他关闸时间较晚的市场预测准确性。通过使用最先进的模型集成方法，我们发现，当包含来自关闸时间较早的互联市场（德国-卢森堡、奥地利和瑞士）的价格数据时，比利时（BE）和瑞典（SE3）投标区的预测准确性分别显著提高了22%和9%。这种改进在一般和极端市场条件下均成立。我们的分析还提供了进一步的重要见解：频繁的模型重新校准对于最大化准确性是必要的，但会带来显著的额外计算成本；并且，使用更多市场数据并不总是能带来更好的性能——我们通过预测模型的可解释性分析深入探讨了这一事实。总的来说，这些发现为市场参与者和决策者提供了宝贵的指导，旨在日益互联和波动的欧洲能源市场中优化投标策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [424] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
> *PinFM：十亿级视觉发现平台上的用户活动序列基础模型*

*Xiangyi Chen, Kousik Rajesh, Matthew Lawhon, Zelun Wang, Hanyu Li, Haomiao Li, Saurabh Vishwas Joshi, Pong Eksombatchai, Jaewon Yang, Yi-Ping Hsu, Jiajing Xu, Charles Rosenberg* | **Category: cs.LG, cs.IR** | **Updated: 2025-07-17**

**Keywords:** PinFM, 基础模型, 推荐系统, 用户活动序列, Transformer

**Comment:** RecSys 2025

> **TL;DR:** 本文介绍了PinFM，一个拥有200亿以上参数的Transformer基础模型，用于在大型视觉发现平台上理解用户活动序列。它解决了可扩展性和新项目处理等挑战，显著提高了吞吐量并增加了用户参与度。

**AI_Comments:** 本文将基础模型应用于大规模工业推荐系统，解决了该领域中显著的实际挑战。其创新之处在于，将预训练和微调范式进行调整，以满足严格的实际约束，如可扩展性、成本和延迟，并有效处理新项目。吞吐量和新项目参与度的提升凸显了PinFM的实际影响力。

<details>
  <summary>Details</summary>

**Motivation:** 用户活动序列是推荐系统中最重要的信号之一。本文旨在开发一个基础模型，用于在十亿级视觉发现平台上的多个应用程序中理解用户活动序列，以应对工业推荐系统中的可扩展性、成本、延迟、交互捕获和新项目处理等挑战。

**Method:** 本文提出了PinFM，一个拥有200亿以上参数的Transformer模型。它采用预训练和微调的方法。为了解决可扩展性和新项目处理等挑战，开发了创新的技术、基础设施和算法优化（例如去重交叉注意力Transformer（DCAT））。

**Result:** PinFM在Pinterest内部数据上的吞吐量提高了600%。通过改变输入序列，学习用户序列和候选项目之间的交互，新项目的参与度增加了20%。

**Conclusion:** PinFM现已部署，旨在帮助改善超过5亿用户在各种应用程序中的体验。该模型成功解决了将基础模型应用于工业推荐系统所面临的挑战。

> **ai_Abstract:** 本文介绍了PinFM，一个拥有200亿以上参数的基础Transformer模型，旨在理解十亿级视觉发现平台上的用户活动序列。它采用预训练和微调范式，将自然语言处理和视觉领域常用的方法应用于工业推荐系统中的独特挑战，如可扩展性、延迟和新项目处理。作者开发了创新技术，包括去重交叉注意力Transformer（DCAT），将内部数据的吞吐量显著提高了600%。PinFM通过有效地学习用户序列与项目交互，使新项目的参与度增加了20%。该模型目前已部署，为超过5亿用户在各种应用程序中提供更好的体验。

> **摘要翻译:** 用户活动序列已成为推荐系统中最重要的信号之一。我们提出了一个基础模型PinFM，用于在十亿级视觉发现平台上的多个应用程序中理解用户活动序列。我们使用大量的用户活动数据预训练了一个拥有200亿以上参数的Transformer模型，然后针对特定应用程序进行微调，有效地将其与现有模型耦合。虽然这种预训练和微调的方法在其他领域（如视觉和自然语言处理）已经很流行，但其在工业推荐系统中的应用面临诸多挑战。基础模型必须足够可扩展，以每秒对数百万个项目进行评分，同时满足这些系统施加的严格成本和延迟限制。此外，它还应捕获用户活动与其他特征之间的交互，并处理预训练阶段不存在的新项目。
我们开发了创新的技术来应对这些挑战。我们的基础设施和算法优化，例如去重交叉注意力Transformer（DCAT），将我们在Pinterest内部数据上的吞吐量提高了600%。我们证明了PinFM可以通过改变输入序列来学习用户序列和候选项目之间的交互，从而使新项目的参与度增加了20%。PinFM现已部署，旨在帮助改善超过5亿用户在各种应用程序中的体验。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [427] [Multiple-Frequencies Population-Based Training](https://arxiv.org/abs/2506.03225)
> *多频率种群训练*

*Waël Doulazmi, Auguste Lehuger, Marin Toromanoff, Valentin Charraut, Thibault Buhet, Fabien Moutarde* | **Category: cs.LG, cs.AI, cs.NE** | **Updated: 2025-07-17**

**Keywords:** 超参数优化, 种群训练, 强化学习, 多频率, 样本效率

**Comment:** RLC25 - Camera-ready

> **TL;DR:** 强化学习的超参数敏感性导致不稳定和低效。种群训练（PBT）是一种超参数优化（HPO）方法，但可能因贪婪的中间选择而陷入局部最优。本文提出多频率种群训练（MF-PBT），通过使用不同进化频率的子种群和非对称迁移过程来解决贪婪问题，以平衡短期和长期优化。实验表明MF-PBT提高了样本效率和长期性能。

**AI_Comments:** MF-PBT通过引入多频率进化和子种群间的非对称信息迁移，创新性地解决了PBT在超参数优化中容易陷入局部最优的“贪婪”问题。这种设计对于平衡强化学习中的短期和长期优化目标具有重要意义，为更鲁棒的超参数优化提供了新的方向。该方法在未实际调整超参数的情况下仍能提升性能，显示了其潜在的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习对超参数的高度敏感性导致不稳定和低效，给实践者带来巨大挑战。现有的超参数优化（HPO）算法，如种群训练（PBT），在较长时间尺度上可能因中间选择的贪婪性而陷入局部最优，最终落后于香草随机搜索。

**Method:** 本文提出了多频率种群训练（MF-PBT），这是一种新颖的超参数优化（HPO）算法，通过采用以不同频率进化的子种群来解决贪婪问题。MF-PBT引入了一种迁移过程，用于在子种群之间传输信息，并采用非对称设计来平衡短期和长期优化。

**Result:** 在Brax套件上进行的大量实验表明，MF-PBT提高了样本效率和长期性能，即使在没有实际调整超参数的情况下。

**Conclusion:** 多频率种群训练（MF-PBT）通过多频率进化和非对称迁移解决了种群训练（PBT）的贪婪问题，显著提高了强化学习中的样本效率和长期性能。

> **ai_Abstract:** 强化学习因超参数敏感性面临挑战，种群训练（PBT）是解决此问题的超参数优化方法。然而，PBT的贪婪中间选择可能导致局部最优和长期性能下降。本文提出多频率种群训练（MF-PBT），通过使用以不同频率进化的子种群和非对称迁移过程来平衡短期和长期优化，从而解决PBT的贪婪问题。在Brax上的实验证明，MF-PBT提高了样本效率和长期性能。

> **摘要翻译:** 强化学习对超参数的高度敏感性是造成不稳定和低效的根源，给实践者带来了巨大的挑战。为了解决这个问题，人们开发了超参数优化（HPO）算法，其中种群训练（PBT）因其能够生成超参数调度而非固定配置而脱颖而出。PBT训练一群智能体，每个智能体都有自己的超参数，频繁地对它们进行排名，并用最佳智能体的变异体替换表现最差的智能体。这些中间选择步骤可能导致PBT专注于短期改进，使其陷入局部最优，最终在更长的时间尺度上落后于香草随机搜索。本文研究了这种贪婪问题与进化频率选择（即选择完成的速率）之间的关系。我们提出了多频率种群训练（MF-PBT），这是一种新颖的HPO算法，通过采用以不同频率进化的子种群来解决贪婪问题。MF-PBT引入了一种迁移过程，用于在子种群之间传输信息，并采用非对称设计来平衡短期和长期优化。在Brax套件上进行的大量实验表明，MF-PBT提高了样本效率和长期性能，即使在没有实际调整超参数的情况下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [433] [Timing is Important: Risk-aware Fund Allocation based on Time-Series Forecasting](https://arxiv.org/abs/2505.24835)
> *时机很重要：基于时间序列预测的风险感知资金分配*

*Fuyuan Lyu, Linfeng Du, Yunpeng Weng, Qiufang Ying, Zhiyan Xu, Wen Zou, Haolun Wu, Xiuqiang He, Xing Tang* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 资金分配, 时间序列预测, 风险感知, 预测-优化, 不确定性校准

**Comment:** Accepted by KDD 2025 ADS Track

> **TL;DR:** 本文提出了一个名为RTS-PnO的风险感知时间序列预测与分配框架，旨在解决资金分配中预测与目标不匹配以及预测不确定性问题。该框架在多项离线和在线实验中均表现出色，优于现有基线。

**AI_Comments:** 该论文的创新点在于提出了一个通用的框架来解决资金分配中预测与优化之间的目标不匹配问题，并考虑了预测的不确定性。其端到端训练和对预测模型不可知的特性增加了其普适性。在真实业务场景中的显著效果也证明了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 资金分配在金融领域日益重要，但现有的简单预测或“预测-然后-优化”方法存在目标不匹配问题。此外，最先进的时间序列预测模型会引入额外的预测不确定性。

**Method:** 本文提出了一个风险感知时间序列预测与分配（RTS-PnO）框架。该框架对预测模型无先验假设，并包含三个主要特点：(i) 目标对齐的端到端训练，(ii) 自适应预测不确定性校准，以及 (iii) 对预测模型不可知。

**Result:** RTS-PnO在离线实验中，使用来自货币、股票和加密货币三类金融应用的八个数据集进行评估，结果显示其始终优于其他有竞争力的基线方法。在线实验在腾讯FiT的跨境支付业务中进行，与产品线方法相比，遗憾值降低了8.4%。

**Conclusion:** RTS-PnO框架有效解决了资金分配中预测与目标不匹配以及时间序列预测引入的不确定性问题，并在多种金融应用场景和真实业务环境中展现出卓越的性能。

> **ai_Abstract:** 本文针对金融领域资金分配中预测与目标不匹配以及时间序列预测模型引入的不确定性问题，提出了一个名为风险感知时间序列预测与分配（RTS-PnO）的通用框架。该框架具有端到端训练、自适应不确定性校准和对预测模型不可知等特点。通过在多种金融数据集上的离线实验和腾讯跨境支付业务的在线实验，RTS-PnO均显著优于现有基线方法，证明了其在实际应用中的有效性和优越性。

> **摘要翻译:** 资金分配在金融领域一直是一个日益重要的问题。在现实中，我们的目标是在未来的某个时期内分配资金购买某些资产。朴素的解决方案，如仅预测或预测-然后-优化方法，存在目标不匹配的问题。此外，最先进的时间序列预测模型的引入不可避免地会在预测结果中引入额外的不确定性。为了解决上述两个问题，我们引入了一个风险感知时间序列预测与分配（RTS-PnO）框架，该框架对预测模型不作任何先验假设。该框架包含三个特点：(i) 目标对齐的端到端训练，(ii) 自适应预测不确定性校准，以及 (iii) 对预测模型不可知。RTS-PnO 的评估通过在线和离线实验进行。对于离线实验，使用了来自三类金融应用（货币、股票和加密货币）的八个数据集。RTS-PnO 始终优于其他有竞争力的基线。在线实验在腾讯 FiT 的跨境支付业务中进行，与产品线方法相比，遗憾值降低了 8.4%。离线实验的代码可在 https://github.com/fuyuanlyu/RTS-PnO 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [445] [Learning to Reject Low-Quality Explanations via User Feedback](https://arxiv.org/abs/2507.12900)
> *通过用户反馈学习拒绝低质量解释*

*Luca Stradiotti, Dario Pesenti, Stefano Teso, Jesse Davis* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 低质量解释拒绝, 用户反馈, 可解释机器学习, 解释质量, 归因技术

**Comment:** 

> **TL;DR:** 提出LtX框架，让机器学习模型能拒绝低质量解释的输入。开发了ULER，一个基于用户反馈的拒绝器，在多项基准测试中表现优于现有方法。

**AI_Comments:** 本文提出了一种新颖且实用的方法来解决机器学习可解释性中的一个关键问题：如何处理低质量的解释。通过引入“学习拒绝”的概念，并利用用户反馈来训练拒绝器，该研究直接针对了高风险应用中信任和决策的痛点。ULER的设计考虑了人类判断，使其更具实用性。新数据集的发布也将极大地促进该领域未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习预测器在信用评分等高风险应用中被广泛使用，但其解释有时质量不高，导致用户难以理解或信任，从而影响信任评估和后续决策。因此，分类器应该能够拒绝那些无法提供高质量解释的输入。

**Method:** 提出了一个名为LtX（学习拒绝低质量解释）的框架，该框架为预测器配备一个评估解释质量的拒绝器。针对流行的归因技术，引入了ULER（以用户为中心的低质量解释拒绝器），ULER通过人类评分和每个特征的相关性判断来学习一个简单的拒绝器，以反映人类对解释质量的判断。

**Result:** ULER在八个分类和回归基准测试以及一个新的、人工标注的数据集上，在LtX任务中均优于最先进的以及解释感知型学习拒绝策略。研究团队还将公开发布新的人工标注数据集。

**Conclusion:** ULER是一种有效的方法，可以通过学习人类对解释质量的判断来识别和拒绝低质量的机器学习解释，从而有助于提高高风险应用中机器学习系统的可信度和决策质量。

> **ai_Abstract:** 本文提出了一个学习拒绝低质量解释（LtX）的框架，旨在解决机器学习模型在关键应用中提供低质量解释导致信任和决策问题。该框架为预测器配备一个拒绝器来评估解释质量。研究人员开发了ULER（以用户为中心的低质量解释器），它通过学习人类对解释质量的判断（基于人类评分和特征相关性判断）来识别并拒绝低质量的归因解释。实验结果表明，ULER在多个分类和回归基准测试以及一个新的人工标注数据集上，其性能优于现有的学习拒绝策略。

> **摘要翻译:** 机器学习预测器越来越多地被应用于信用评分等高风险应用中。解释有助于用户理解其预测背后的原因，但并非总是“高质量”的。也就是说，终端用户可能难以理解或相信它们，这会使信任评估和下游决策复杂化。我们认为，分类器应该可以选择拒绝处理那些预测无法得到适当解释的输入，并引入了一个学习拒绝低质量解释（LtX）的框架，在该框架中，预测器配备了一个评估解释质量的拒绝器。在这个问题设置中，关键挑战是如何正确定义和评估解释质量以及如何设计一个合适的拒绝器。我们专注于流行的归因技术，引入了ULER（以用户为中心的低质量解释拒绝器），它从人类评分和每个特征的相关性判断中学习一个简单的拒绝器，以反映人类对解释质量的判断。我们的实验表明，ULER在八个分类和回归基准测试以及一个新的、人工标注的数据集上，在LtX任务中均优于最先进的以及解释感知型学习拒绝策略，我们将公开发布该数据集以支持未来的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [451] [Boosting Team Modeling through Tempo-Relational Representation Learning](https://arxiv.org/abs/2507.13305)
> *通过时序-关系表示学习提升团队建模*

*Vincenzo Marco De Luca, Giovanna Varni, Andrea Passerini* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 团队建模, 时序-关系学习, 多任务预测, 可解释AI, 以人为中心AI

**Comment:** 

> **TL;DR:** 本文介绍了TRENN和MT-TRENN，这是一种新颖的时序-关系架构，它联合建模时间性和关系性团队动态，以预测多个团队结构并提供可解释的见解，优于现有方法。

**AI_Comments:** 本文的创新之处在于其新颖的时序-关系架构（TRENN/MT-TRENN），该架构能够联合建模时间性和关系性动态，并具备多任务预测多种团队结构的能力，同时集成了可解释性模块。其重要性体现在其适用于真实世界中以人为中心的AI系统，以促进团队改进。

<details>
  <summary>Details</summary>

**Motivation:** 现有团队建模方法未能满足实际需求，即联合建模动态和关系、同时推断多个团队结构，以及提供可解释的见解和可操作的建议。

**Method:** 本文提出了TRENN，这是一种时序-关系架构，包含自动时间图提取器、时序-关系编码器、团队结构预测解码器和两个可解释性模块。在此基础上，通过将解码器替换为多任务头，扩展为MT-TRENN，使其能够学习共享的社会嵌入并同时预测多个团队结构，包括涌现领导力、领导风格和团队协作组件。

**Result:** 实验结果表明，我们的方法显著优于仅依赖时间或关系信息的方法。MT-TRENN中集成的可解释性模块提供了可解释的见解和可操作的建议，以支持团队改进。

**Conclusion:** 所提出的时序-关系方法，特别是具有多任务预测和可解释性功能的MT-TRENN，非常适用于以人为中心的AI应用，如高风险协作环境中的智能决策支持系统，弥补了实际团队建模的差距。

> **ai_Abstract:** 本文针对当前团队建模的局限性，提出了TRENN及其扩展MT-TRENN。这些新颖的时序-关系架构联合建模时间性和关系性团队动态，同时预测多个团队结构，并提供可解释的见解。实验结果表明，相较于仅使用时间或关系数据的方法，该方法在性能上取得了显著提升，使其适用于以人为本的AI应用。

> **摘要翻译:** 团队建模仍然是人工智能和社会科学交叉领域的一个基本挑战。社会科学研究强调需要联合建模动态和关系，而实际应用则要求统一模型能够同时推断多个团队结构，提供可解释的见解和可操作的建议以提高团队绩效。然而，现有工作未能满足这些实际需求。为了弥补这一差距，我们提出了TRENN，这是一种新颖的时序-关系架构，它集成了：(i)一个自动时间图提取器，(ii)一个时序-关系编码器，(iii)一个用于团队结构预测的解码器，以及(iv)两个互补的可解释性模块。TRENN联合捕获关系和时间团队动态，为MT-TRENN奠定了坚实基础，MT-TRENN通过将解码器替换为多任务头来扩展TRENN，使模型能够学习共享的社会嵌入并同时预测多个团队结构，包括涌现领导力、领导风格和团队协作组件。实验结果表明，我们的方法显著优于仅依赖时间或关系信息的方法。此外，实验评估表明，MT-TRENN中集成的可解释性模块产生了可解释的见解和可操作的建议，以支持团队改进。这些能力使我们的方法特别适用于以人为中心的AI应用，例如高风险协作环境中的智能决策支持系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [453] [Branching Stein Variational Gradient Descent for sampling multimodal distributions](https://arxiv.org/abs/2506.13916)
> *用于多模态分布采样的分支Stein变分梯度下降*

*Isaías Bañales, Arturo Jaramillo, Joshué Helí Ricalde-Guerrero* | **Category: cs.LG, stat.CO, stat.ML, 62F15, 65C05, 65C35** | **Updated: 2025-07-17**

**Keywords:** 分支Stein变分梯度下降, 多模态分布, 变分推断, SVGD, 粒子方法

**Comment:** 

> **TL;DR:** BSVGD是一种新颖的粒子变分推断方法，通过引入随机分支机制扩展了经典的SVGD算法，以有效采样多模态分布，并提供了理论收敛保证和实验验证。

**AI_Comments:** 这项工作的创新点在于引入了随机分支机制来增强Stein变分梯度下降算法的探索能力，使其能够更好地处理多模态分布，这是传统方法面临的挑战。理论收敛保证的提出也增加了该方法的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提出一种新颖的基于粒子的变分推断方法，以有效处理多模态分布的采样问题。

**Method:** 本研究提出了一种名为分支Stein变分梯度下降（BSVGD）的方法，它通过引入一个鼓励状态空间探索的随机分支机制，扩展了经典的Stein变分梯度下降（SVGD）算法。

**Result:** 文中提出了BSVGD算法在分布收敛方面的理论保证，并通过数值实验验证了其适用性。同时，使用样本间的Wasserstein距离和相应的计算时间，展示了BSVGD与SVGD之间的性能比较。

**Conclusion:** BSVGD算法适用于多模态分布的采样，并提供了理论收敛保证和良好的实验性能。

> **ai_Abstract:** 本文提出了一种新颖的粒子变分推断方法——分支Stein变分梯度下降（BSVGD），旨在有效处理多模态分布的采样。BSVGD通过在经典Stein变分梯度下降（SVGD）中引入随机分支机制来增强状态空间探索。研究提供了BSVGD在分布收敛方面的理论保证，并通过数值实验验证了其适用性，同时比较了BSVGD与SVGD在Wasserstein距离和计算时间上的性能。

> **摘要翻译:** 我们提出了一种新颖的基于粒子的变分推断方法，旨在处理多模态分布。我们的方法，被称为分支Stein变分梯度下降（BSVGD），通过引入一个随机分支机制来扩展经典的Stein变分梯度下降（SVGD）算法，该机制鼓励状态空间的探索。在这项工作中，我们提出了分布收敛的理论保证，以及验证我们算法适用性的数值实验。使用样本之间的Wasserstein距离和相应的计算时间，对BSVGD和SVGD进行了性能比较。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [463] [From SGD to Spectra: A Theory of Neural Network Weight Dynamics](https://arxiv.org/abs/2507.12709)
> *从SGD到谱：神经网络权重动力学理论*

*Brian Richard Olsen, Sam Fatehmanesh, Frank Xiao, Adarsh Kumarappan, Anirudh Gajula* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 神经网络, SGD, 谱理论, 随机微分方程, 戴森布朗运动

**Comment:** 

> **TL;DR:** 本文提出了一个连续时间、矩阵值的随机微分方程（SDE）框架，用于理论上解释SGD训练如何影响神经网络权重矩阵的奇异值谱，揭示了其遵循戴森布朗运动并解释了“主体+尾部”谱结构。

**AI_Comments:** 该论文具有创新性，因为它提供了一个新颖的理论框架（SDEs）来解释神经网络中先前仅凭经验观察到的谱结构。它严谨地将低层次的SGD动力学与高层次的谱特性联系起来，这对于更深入地理解深度学习的成功至关重要。戴森布朗运动的应用尤其具有洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度神经网络彻底改变了机器学习，但其训练动力学在理论上仍不清楚。本研究旨在提供一个严格的理论基础，解释随机梯度下降（SGD）训练过程中神经网络权重矩阵的演化。

**Method:** 研究人员开发了一个连续时间、矩阵值的随机微分方程（SDE）框架。他们推导了精确的SDE，表明平方奇异值遵循戴森布朗运动，并描述了稳态分布。通过在Transformer和MLP架构上的受控实验，验证了理论预测。

**Result:** 研究发现，平方奇异值遵循具有特征值排斥的戴森布朗运动。稳态分布被描述为具有幂律尾部的伽马型密度，这首次为训练网络中经验观察到的“主体+尾部”谱结构提供了理论解释。实验结果在Transformer和MLP架构上验证了理论预测，显示SDE预测与观察到的谱演化之间存在定量一致性。

**Conclusion:** 本研究通过将SGD的微观动力学与奇异值谱的宏观演化联系起来，为理解深度学习为何有效提供了严格的理论基础。

> **ai_Abstract:** 本文提出了一个连续时间、矩阵值的随机微分方程（SDE）框架，以理论上连接随机梯度下降（SGD）的微观动力学与神经网络权重矩阵中奇异值谱的宏观演化。研究推导出平方奇异值遵循戴森布朗运动的SDE，并发现其稳态分布为具有幂律尾部的伽马型密度，这成功解释了经验观察到的“主体+尾部”谱结构。通过在Transformer和MLP架构上的实验验证，该理论预测与实际观察到的谱演化表现出定量一致性，从而为理解深度学习的有效性提供了严谨的理论基础。

> **摘要翻译:** 深度神经网络彻底改变了机器学习，但其训练动力学在理论上仍不清楚——我们开发了一个连续时间、矩阵值的随机微分方程（SDE）框架，该框架严格地将SGD的微观动力学与权重矩阵中奇异值谱的宏观演化联系起来。我们推导出了精确的SDE，表明平方奇异值遵循具有特征值排斥的戴森布朗运动，并将其稳态分布描述为具有幂律尾部的伽马型密度，首次为训练网络中经验观察到的“主体+尾部”谱结构提供了理论解释。通过在Transformer和MLP架构上进行的受控实验，我们验证了我们的理论预测，并证明了基于SDE的预测与观察到的谱演化之间存在定量一致性，为理解深度学习为何有效提供了严格的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [473] [Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models](https://arxiv.org/abs/2507.01201)
> *逃离柏拉图的洞穴：用于对齐独立训练的视觉和语言模型的JAM框架*

*Lauren Hyoseo Yoon, Yisong Yue, Been Kim* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-16**

**Keywords:** 多模态对齐, 视觉语言模型, 自编码器, JAM框架, 柏拉图式表征假说

**Comment:** 

> **TL;DR:** 本文提出了一个名为JAM的轻量级框架，通过联合自编码器调制器来对齐独立训练的视觉和语言模型的表征空间，即使在冻结的表征上也能实现可靠对齐。

**AI_Comments:** 本文通过“逃离柏拉图的洞穴”这一有趣的类比，形象地描述了解决视觉与语言模型对齐问题的目标。JAM框架的创新之处在于其轻量级和帕累托高效的特性，能够在不修改预训练模型的情况下，有效实现跨模态对齐。这对于将现有的单模态大模型转化为多模态应用具有重要意义，提供了一种实用且具有理论深度的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 尽管独立训练的视觉和语言模型各自拥有不同的表征空间，但“柏拉图式表征假说”表明它们可能趋向于共享现实的统计模型。本文旨在解决一个根本问题：能否超越事后统计检测，显式优化这些独立表征之间的对齐。

**Method:** 本文将柏拉图式对齐问题视为一个多目标优化任务，即在保持各模态原生结构的同时，实现相互一致性。为此，引入了联合自编码器调制器（JAM）框架，该框架在预训练的单模态模型的潜在表征上联合训练模态特定的自编码器，通过重建和跨模态目标来鼓励对齐。该框架通过评估三种设计轴（对齐目标、对齐最有效的层深度以及基础模型规模对表征收敛的影响）进行验证。

**Result:** 研究结果表明，JAM这一轻量级帕累托高效框架能够可靠地诱导对齐，即使是在冻结的、独立训练的表征之间也能实现，这提供了理论见解和实践途径。

**Conclusion:** 该框架为将通用单模态基础模型转化为专业多模态模型提供了理论见解和实用途径。

> **ai_Abstract:** 本文提出了联合自编码器调制器（JAM）框架，旨在解决独立训练的视觉和语言模型之间表征空间不一致的问题。该框架通过将对齐视为多目标优化任务，在保持各模态原生结构的同时，利用联合训练的模态特定自编码器在预训练模型的潜在表征上实现对齐。JAM框架通过重建和跨模态目标鼓励模型间的协同，并被证明能够有效对齐冻结的独立训练表征，为构建多模态AI提供了理论和实践指导。

> **摘要翻译:** 独立训练的视觉和语言模型各自占据由其模态、目标和架构塑造的独立表征空间。然而，一个新兴的假设——柏拉图式表征假说——表明，这些模型可能仍然会趋向于现实的共享统计模型。如果这种兼容性存在，就会引出一个基本问题：我们能否超越事后统计对齐检测，并在这些独立的表征之间显式地优化对齐？我们将这种柏拉图式对齐问题视为一个多目标优化任务——在保持每种模态原生结构的同时，对齐以实现相互一致性。我们引入了联合自编码器调制器（JAM）框架，该框架在预训练的单模态模型的潜在表征上联合训练模态特定的自编码器，通过重建和跨模态目标来鼓励对齐。通过类比，这个框架作为一种逃离柏拉图洞穴的方法，使得共享结构能够从不相交的输入中浮现。我们通过三个关键设计轴评估了这个框架：（i）对齐目标——比较对比损失（Con）、其硬负变体（NegCon）和我们的Spread损失，（ii）对齐最有效的层深度，以及（iii）基础模型规模对表征收敛的影响。我们的研究结果表明，我们轻量级的帕累托高效框架能够可靠地诱导对齐，即使是在冻结的、独立训练的表征之间也能实现，这为将通用单模态基础模型转化为专业多模态模型提供了理论见解和实践途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [480] [Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services](https://arxiv.org/abs/2507.12908)
> *Fremer：轻量高效的频率变换器用于云服务工作负载预测*

*Jiadong Chen, Hengyu Ye, Fuxin Jiang, Xiao He, Tieying Zhang, Jianjun Chen, Xiaofeng Gao* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 工作负载预测, 云服务, 频率变换器, 深度学习, 自动扩缩容

**Comment:** 12 pages, 11 figures

> **TL;DR:** Fremer是一种轻量高效的频率变换器模型，专门用于云服务工作负载预测，它在准确性和效率上均超越了现有最先进模型，并降低了计算成本。

**AI_Comments:** 本文解决了云计算中一个关键的实际问题：高效准确的工作负载预测。其创新之处在于利用Transformer架构（Fremer）结合频域处理复杂周期模式，这是工作负载数据的常见特征。开放来自真实云服务提供商（字节跳动）的新的高质量数据集是一项重要贡献，促进了进一步的研究和基准测试。在准确性和效率方面取得的改进，以及在实际部署中带来的好处（延迟、资源消耗），都突显了其重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 工作负载预测对于云服务（如自动扩缩容和调度）至关重要，但现有基于Transformer的预测模型在大规模云环境中计算效率不足。鉴于大多数工作负载序列具有复杂的周期性模式，在频域中处理这些挑战可以带来显著优势。

**Method:** 本文提出了Fremer，一个高效且有效的深度预测模型，通过在频域处理工作负载数据来满足效率、准确性和多周期鲁棒性要求。此外，作者收集并开源了四个来自字节跳动云服务的高质量工作负载数据集。

**Result:** Fremer在效率上优于大多数基于Transformer的预测模型，在工作负载预测准确性上超越了所有SOTA模型，并对多周期序列表现出鲁棒性。在专有和公共数据集上的实验表明，Fremer在MSE、MAE和SMAPE上分别平均提高了5.5%、4.7%和8.6%，同时降低了参数规模和计算成本。在基于Kubernetes的主动自动扩缩容测试中，Fremer将平均延迟提高了18.78%，资源消耗降低了2.35%。

**Conclusion:** Fremer在工作负载预测中提供了卓越的准确性和效率，并在实际应用中通过改善自动扩缩容的延迟和资源消耗，展现了其在真实世界场景中的实用效能。

> **ai_Abstract:** Fremer是一种轻量高效的频率变换器，专为云服务工作负载预测设计。针对现有Transformer模型在云环境中计算效率低的痛点，Fremer利用频域处理复杂周期模式，实现了卓越的预测精度和更高的计算效率。实验证明，Fremer在多个评估指标上均优于SOTA模型，并显著降低了参数和计算成本。此外，它在实际的Kubernetes自动扩缩容场景中也展现了显著的延迟降低和资源节省，证明了其在实际应用中的有效性。

> **摘要翻译:** 工作负载预测在云服务应用（如自动扩缩容和调度）中至关重要，对运营效率具有深远影响。尽管基于Transformer的预测模型在通用任务中取得了显著成功，但其计算效率往往无法满足大规模云环境的严格要求。鉴于大多数工作负载序列表现出复杂的周期性模式，在频域中解决这些挑战具有显著优势。为此，我们提出了Fremer，一个高效且有效的深度预测模型。Fremer满足三个关键要求：它展示了卓越的效率，优于大多数基于Transformer的预测模型；它在工作负载预测中实现了卓越的准确性，超越了所有最先进（SOTA）模型；并且它对多周期序列表现出鲁棒的性能。此外，我们收集并开源了四个高质量的开源工作负载数据集，这些数据集来源于字节跳动的云服务，包含了数千个计算实例的工作负载数据。在我们专有数据集和公共基准上的广泛实验表明，Fremer始终优于基线模型，与SOTA模型相比，其MSE平均提高了5.5%，MAE平均提高了4.7%，SMAPE平均提高了8.6%，同时降低了参数规模和计算成本。此外，在基于Kubernetes的主动自动扩缩容测试中，Fremer将平均延迟提高了18.78%，并将资源消耗降低了2.35%，这突显了其在实际应用中的实用效能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [486] [GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM](https://arxiv.org/abs/2507.13323)
> *GeoReg：基于LLM的权重约束小样本回归模型用于社会经济指标估计*

*Kyeongjin Ahn, Sungwon Han, Seungeon Lee, Donghyun Ahn, Hyoshin Kim, Jungwon Kim, Jihee Kim, Sangyoon Park, Meeyoung Cha* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 社会经济估计, 小样本回归, 大型语言模型, 地理空间数据, 权重约束

**Comment:** 15 pages, 13 figures, 7 tables

> **TL;DR:** GeoReg是一个利用LLM和多源数据，通过权重约束的小样本回归模型，能有效估计数据稀缺地区的社会经济指标。

**AI_Comments:** GeoReg的创新之处在于其结合了LLM作为数据工程师来处理数据稀缺问题，并设计了带有权重约束的回归模型以适应不同特征的相关性。这种方法对于发展中国家等数据匮乏的地区具有重要的应用价值。其小样本学习能力和对非线性模式的捕捉也增强了模型的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 社会经济指标对于政策制定和可持续发展至关重要，但对于发展中国家等数据稀缺地区，这些指标的估计面临数据匮乏的挑战。

**Method:** 本研究引入了GeoReg回归模型，它整合了卫星图像和网络地理空间信息等多种数据源。该方法利用大型语言模型（LLM）的先验知识作为数据工程师，提取信息特征以解决标记数据稀缺问题，实现小样本设置下的有效估计。模型获取数据特征与目标指标之间的上下文关系，将其相关性归类为正向、负向、混合或无关，并将这些特征输入到具有定制权重约束的线性估计器中。为捕捉非线性模式，模型还识别并整合有意义的特征交互以及非线性变换。

**Result:** 在三个不同发展阶段的国家进行的实验表明，即使对于数据可用性有限的低收入国家，GeoReg模型在社会经济指标估计方面也优于现有基线。

**Conclusion:** GeoReg模型通过结合LLM和多源数据，能够有效应对数据稀缺地区的社会经济指标估计挑战，并在小样本设置下展现出优越的性能。

> **ai_Abstract:** 本文提出了GeoReg，一个利用LLM和多源地理空间数据进行社会经济指标估计的回归模型。该模型旨在解决数据稀缺地区（如发展中国家）的指标估计问题。GeoReg通过LLM提取特征，并根据特征与目标指标的相关性应用权重约束，同时捕捉非线性模式。实验证明其在数据有限的场景下优于现有基线。

> **摘要翻译:** 社会经济指标，如区域GDP、人口和教育水平，对于制定政策决策和促进可持续发展至关重要。本研究引入了GeoReg，一个回归模型，它整合了包括卫星图像和基于网络的地理空间信息在内的多种数据源，即使对于发展中国家等数据稀缺地区也能估计这些指标。我们的方法利用大型语言模型（LLM）的先验知识来解决标记数据稀缺的问题，其中LLM通过提取信息特征充当数据工程师，从而在小样本设置中实现有效的估计。具体而言，我们的模型获取数据特征与目标指标之间的上下文关系，将其相关性归类为正向、负向、混合或无关。然后将这些特征输入到具有针对每个类别定制的权重约束的线性估计器中。为了捕捉非线性模式，模型还识别有意义的特征交互并将其与非线性变换一起整合。在三个不同发展阶段的国家进行的实验表明，即使对于数据可用性有限的低收入国家，我们的模型在估计社会经济指标方面也优于基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [493] [On the Effectiveness of the z-Transform Method in Quadratic Optimization](https://arxiv.org/abs/2507.03404)
> *关于 z 变换方法在二次优化中有效性的研究*

*Francis Bach* | **Category: cs.LG, math.OC** | **Updated: 2025-07-17**

**Keywords:** z 变换, 优化, 渐近行为, 梯度下降, 收敛性

**Comment:** 

> **TL;DR:** 本文展示了 z 变换方法在推导线性模型和优化算法的新渐近结果方面的有效性和多功能性。

**AI_Comments:** 该论文的创新点在于将经典的 z 变换方法应用于现代优化算法的渐近分析，展示了其在推导新理论结果方面的强大潜力。这为理解和改进优化算法的收敛行为提供了一个新的分析工具。

<details>
  <summary>Details</summary>

**Motivation:** z 变换是一种经典工具，但本文旨在通过一系列结果，证明其在推导线性模型和优化算法的新渐近结果方面的有效性和多功能性。

**Method:** 采用 z 变换方法，重点关注渐近行为和泰勒展开，并将其应用于线性模型和优化算法，包括无限维希尔伯特空间中的梯度下降、Nesterov 加速、平均技术和随机梯度下降。

**Result:** 成功推导了新的渐近结果，揭示了谱维度如何表征梯度下降的收敛行为，并将分析扩展到 Nesterov 加速、平均技术和随机梯度下降。

**Conclusion:** z 变换方法在推导线性模型和优化算法的新渐近结果方面是有效且多功能的。

> **ai_Abstract:** 本文探讨了 z 变换方法在分析线性模型和优化算法中的有效性。该研究利用 z 变换的渐近行为和泰勒展开特性，推导了新的渐近结果。文章从无限维希尔伯特空间中的梯度下降迭代开始，展示了谱维度如何表征收敛行为，并将分析扩展到 Nesterov 加速、平均技术和随机梯度下降，从而证明了 z 变换在处理复杂优化问题中的多功能性。

> **摘要翻译:** 序列的 z 变换是信号处理、控制理论、计算机科学和电气工程中使用的经典工具。它允许通过生成函数研究序列，并且许多操作可以在原始序列及其 z 变换上等效定义。特别是，z 变换方法侧重于渐近行为并允许使用泰勒展开。我们为线性模型和优化算法提出了一系列重要性和难度递增的结果，证明了 z 变换方法在推导新渐近结果方面的有效性和多功能性。从无限维希尔伯特空间中最简单的梯度下降迭代开始，我们展示了谱维度如何表征收敛行为。然后我们将分析扩展到 Nesterov 加速、平均技术和随机梯度下降。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [503] [Holistix: A Dataset for Holistic Wellness Dimensions Analysis in Mental Health Narratives](https://arxiv.org/abs/2507.09565)
> *Holistix：一个用于心理健康叙事中整体健康维度分析的数据集*

*Heba Shakeel, Tanvir Ahmad, Chandni Saxena* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 健康维度分析, 心理健康, 数据集, 社交媒体, Transformer模型

**Comment:** 7 Pages

> **TL;DR:** 论文介绍了Holistix数据集，用于在社交媒体帖子中分类身体、情感、社交、智力、精神和职业六个关键健康维度，并评估了传统机器学习和基于Transformer的模型，旨在促进个性化健康评估和早期干预。

**AI_Comments:** 该论文通过引入Holistix数据集，为心理健康叙事中的整体健康维度分析提供了一个重要的资源。其创新之处在于结合了领域专家指导下的全面注释框架，并涵盖了六个关键的健康维度，这对于更细致地理解用户心理健康状态至关重要。数据集的公开可用性以及对模型透明度和可解释性的关注，增加了其在研究和实际应用中的价值。该工作对于开发个性化心理健康干预措施具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究可能缺乏对社交媒体用户帖子中整体健康维度的细致分类，这对于个性化健康评估和心理健康早期干预至关重要。

**Method:** 引入了一个名为Holistix的数据集，用于分类社交媒体用户帖子中的六个关键健康维度（身体、情感、社交、智力、精神、职业）。开发了一个在领域专家指导下的综合注释框架。评估了传统机器学习模型和先进的基于Transformer的模型进行多类分类任务。使用精确率、召回率和F1-分数（通过10折交叉验证平均）评估模型性能。应用事后解释以确保模型决策的透明度和可解释性。公开在Github上发布数据集和实验。

**Result:** 成功构建并发布了Holistix数据集。评估了传统机器学习模型和基于Transformer的模型在多类分类任务上的性能，但抽象中未提及具体的性能数值。应用了事后解释以确保模型决策的透明度和可解释性。

**Conclusion:** 所提出的数据集有助于社交媒体中区域特定的健康评估。为个性化幸福感评估和心理健康早期干预策略铺平了道路。

> **ai_Abstract:** 本文介绍了Holistix数据集，这是一个用于在社交媒体叙事中分析心理健康整体健康维度的新资源。该数据集涵盖身体、情感、社交、智力、精神和职业六个方面，并采用专家指导的注释框架。研究人员评估了传统机器学习和基于Transformer的模型在该数据集上的表现，并强调了模型解释性。Holistix数据集旨在促进心理健康领域的个性化健康评估和早期干预策略。

> **摘要翻译:** 我们引入了一个用于在社交媒体用户帖子中对健康维度进行分类的数据集，涵盖六个关键方面：身体、情感、社交、智力、精神和职业。该数据集旨在捕获用户生成内容中的这些维度，并在领域专家的指导下开发了一个全面的注释框架。该框架允许将文本片段分类到适当的健康类别中。我们评估了传统机器学习模型和先进的基于Transformer的模型来执行这项多类分类任务，并使用精确率、召回率和F1分数（通过10折交叉验证平均）来评估性能。应用事后解释以确保模型决策的透明度和可解释性。所提出的数据集有助于社交媒体中区域特定的健康评估，并为个性化幸福感评估和心理健康早期干预策略铺平了道路。我们遵守构建和公开发布实验和数据集到Github的道德考量。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [504] [Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning](https://arxiv.org/abs/2507.12750)
> *多模态引导的动态数据集剪枝：实现稳健高效的数据中心学习*

*Suorong Yang, Peijia Li, Yujie Liu, Zhiming Xu, Peng Ye, Wanli Ouyang, Furao Shen, Dongzhan Zhou* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 数据集剪枝, 数据中心学习, 多模态, 鲁棒性, 效率

**Comment:** 

> **TL;DR:** 本文提出一种多模态引导的动态数据集剪枝框架，通过结合任务驱动的难度和跨模态语义一致性，自适应选择训练样本，以提高数据中心学习的效率和鲁棒性。

**AI_Comments:** 本文的创新点在于将多模态基础模型的监督引入到数据集剪枝过程中，通过结合任务难度和跨模态一致性进行动态样本选择，这克服了传统静态剪枝方法的局限性。该方法对于提升数据中心学习在现实世界复杂数据集上的效率和模型性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代深度模型在大型真实世界数据集上训练，数据质量参差不齐且冗余普遍存在。现有的大多数数据集剪枝方法依赖静态启发式或任务特定指标，限制了其在不同领域的鲁棒性和泛化能力。

**Method:** 本文引入了一个动态数据集剪枝框架，该框架基于任务驱动的难度和跨模态语义一致性自适应地选择训练样本。通过整合预训练多模态基础模型的监督，该方法捕获训练动态，同时有效过滤掉无信息样本。

**Result:** 该工作突出了整合跨模态对齐以实现稳健样本选择的潜力，推动数据中心学习迈向更高效和鲁棒的实践。

**Conclusion:** 整合跨模态对齐对于稳健的样本选择具有巨大潜力，能够推动数据中心学习在不同应用领域中实现更高效和鲁棒的实践。

> **ai_Abstract:** 本文提出一种多模态引导的动态数据集剪枝框架，旨在解决现有数据中心学习方法在处理大规模、低质量数据集时面临的鲁棒性和泛化性问题。该框架通过结合任务驱动的难度和跨模态语义一致性，并利用预训练多模态基础模型的监督，动态地选择训练样本，有效过滤掉无信息数据，从而提高数据中心学习的效率和模型的鲁棒性。

> **摘要翻译:** 现代深度模型在大型真实世界数据集上训练，其中数据质量各异且冗余普遍。以数据集剪枝为代表的数据中心方法在提高训练效率和模型性能方面展现出前景。然而，大多数现有方法依赖于静态启发式或任务特定指标，这限制了它们在不同领域的鲁棒性和泛化能力。在这项工作中，我们引入了一个动态数据集剪枝框架，该框架基于任务驱动的难度和跨模态语义一致性自适应地选择训练样本。通过整合来自预训练多模态基础模型的监督，我们的方法捕获训练动态，同时有效过滤掉无信息样本。我们的工作突出了整合跨模态对齐以实现稳健样本选择的潜力，推动数据中心学习迈向跨应用领域更高效和更鲁棒的实践。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [515] [Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI](https://arxiv.org/abs/2507.12913)
> *通过不确定性分解实现鲁棒解释：通向更值得信赖人工智能的途径*

*Chenrui Zhu, Louenas Bounia, Vu Linh Nguyen, Sébastien Destercke, Arthur Hoarau* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 不确定性分解, 模型解释, 可解释人工智能, 偶然不确定性, 认知不确定性

**Comment:** 

> **TL;DR:** 本文提出通过分解预测不确定性（偶然不确定性与认知不确定性）来增强解释的鲁棒性和可靠性，特别是在复杂模型中。

**AI_Comments:** 本文创新性地将不确定性分解引入到模型解释中，特别是区分了偶然不确定性和认知不确定性，并利用它们来指导解释的生成和评估，这对于提高AI解释的可靠性和可信度具有重要意义。通过将不确定性作为一种元解释，为提升复杂模型的可解释性提供了一条新路径。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器学习模型日益复杂，其可解释性降低，但对模型预测透明度的需求日益增加。

**Method:** 提出利用预测不确定性作为经典可解释性方法的补充。具体地，区分偶然不确定性（数据相关）和认知不确定性（模型相关）。认知不确定性用于拒绝不可靠的解释并揭示训练不足；偶然不确定性指导选择特征重要性解释或反事实解释。该方法基于不确定性量化和解耦的可解释性框架。

**Result:** 实验证明这种不确定性感知方法在传统机器学习和深度学习场景中都能提高解释的鲁棒性和可获得性。

**Conclusion:** 通过不确定性分解来指导解释的选择和评估，可以提高解释的可靠性和鲁棒性，从而提升人工智能的信任度。

> **ai_Abstract:** 本文提出了一种通过分解预测不确定性（偶然不确定性与认知不确定性）来增强机器学习模型解释鲁棒性和可靠性的新方法。认知不确定性用于识别并拒绝不可靠的解释，同时揭示模型训练不足；偶然不确定性则用于指导选择合适的解释类型（如特征重要性或反事实解释）。该研究构建了一个基于不确定性量化和解耦的可解释性框架，并通过实验证明了其在传统和深度学习场景中提升解释质量的有效性。

> **摘要翻译:** 机器学习的最新进展强调了模型预测透明度的必要性，尤其是在使用日益复杂的架构时，可解释性会随之降低。在本文中，我们提出利用预测不确定性作为经典可解释性方法的一种补充方法。具体来说，我们区分了偶然不确定性（数据相关）和认知不确定性（模型相关）来指导适当解释的选择。认知不确定性作为不可靠解释的拒绝标准，并且本身就提供了对训练不足的洞察（一种新形式的解释）。偶然不确定性则指导特征重要性解释和反事实解释之间的选择。这利用了一个由不确定性量化和解耦驱动的可解释性方法框架。我们的实验证明了这种不确定性感知方法在传统机器学习和深度学习场景中对解释的鲁棒性和可实现性的影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [521] [Training Transformers with Enforced Lipschitz Constants](https://arxiv.org/abs/2507.13338)
> *训练具有强制Lipschitz常数的Transformer*

*Laker Newhouse, R. Preston Hess, Franz Cesista, Andrii Zahorodnii, Jeremy Bernstein, Phillip Isola* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** Lipschitz常数, Transformer, 神经网络鲁棒性, 权重约束, Muon优化器

**Comment:** 

> **TL;DR:** 本文开发了在训练过程中对Transformer模型强制执行Lipschitz常数的技术，以提高稳定性并减少对传统稳定措施的依赖，发现特定的优化器和权重约束方法能改善性能与Lipschitz常数之间的权衡。

**AI_Comments:** 这篇论文通过在Transformer训练过程中强制执行Lipschitz常数，探索了提高神经网络鲁棒性和训练稳定性的新途径。其创新点在于开发了适用于现代大型模型的Lipschitz约束技术，并发现优化器和权重约束的协同设计对性能有显著影响。该研究的贡献在于证明了在不依赖传统稳定性机制（如层归一化）的情况下训练Lipschitz Transformer的可行性，这为设计更鲁棒、更可控的神经网络提供了新的思路。然而，论文也指出了一个重要局限性：为了匹配现有基线模型的性能，可能需要极高的Lipschitz常数，这表明在保持严格Lipschitz约束的同时实现高性能仍然是一个挑战。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络对输入和权重扰动高度敏感，导致对抗性样本、训练发散和过拟合等问题。现有通过Lipschitz组件构建神经网络的技术尚未成熟，无法在整个训练过程中对现代架构（如Transformer）强制执行Lipschitz证书。

**Method:** 1. 开发并基准测试了新型、计算高效的工具，用于维护范数受限的权重矩阵。2. 应用这些工具，在整个训练过程中强制执行Lipschitz界限来训练Transformer模型。3. 探索优化器动力学，从AdamW切换到Muon。4. 受Muon更新具有固定谱范数启发，共同设计了一种权重约束方法。

**Result:** 1. 优化器动力学很重要：从AdamW切换到Muon改善了标准方法（权重衰减和谱归一化），使模型在较低的Lipschitz界限下达到相同性能。2. 共同设计的权重约束方法改善了MLP和2M参数Transformer上的Lipschitz与性能之间的权衡。3. 2-Lipschitz Transformer在莎士比亚文本上达到60%验证准确率。4. 10-Lipschitz Transformer（145M参数）在互联网文本上达到21%准确率。5. 为匹配NanoGPT基线（39.4%）准确率，Lipschitz上限增加到10^264。6. Lipschitz Transformer可以在不使用层归一化、QK归一化和logit tanh软帽等稳定性措施的情况下进行训练。

**Conclusion:** 本文成功地在整个训练过程中对Transformer模型强制执行了Lipschitz常数，并通过优化器选择和共同设计的权重约束方法改善了性能与Lipschitz界限的权衡，证明了在没有传统稳定性措施的情况下训练的可能性，但也指出在匹配最先进性能时，Lipschitz界限可能需要非常高。

> **ai_Abstract:** 本文研究了在整个训练过程中对Transformer模型强制执行Lipschitz常数的方法，以解决神经网络的敏感性问题。研究开发了新的工具来维护范数受限的权重矩阵，并发现优化器（如Muon）的选择以及共同设计的权重约束方法可以改善Lipschitz界限与模型性能之间的权衡。实验证明，所提出的方法能够训练出具有强制Lipschitz界限的Transformer，并在某些任务上取得可观的准确率，且无需传统的稳定性措施。然而，为了达到与当前SOTA模型相当的性能，可能需要非常大的Lipschitz常数。

> **摘要翻译:** 神经网络通常对输入和权重扰动高度敏感。这种敏感性与对抗性样本的脆弱性、训练发散和过拟合等病理现象相关联。为了解决这些问题，过去的研究着眼于完全由Lipschitz组件构建神经网络。然而，这些技术尚未成熟到研究人员能够训练像Transformer这样的现代架构，并且在初始化之外强制执行Lipschitz证书。为了探索这一空白，我们首先开发并基准测试了新颖、计算高效的工具，用于维护范数受限的权重矩阵。应用这些工具，我们能够在整个训练过程中强制执行Lipschitz界限来训练Transformer模型。我们发现优化器动力学很重要：从AdamW切换到Muon改进了标准方法——权重衰减和谱归一化——允许模型在较低的Lipschitz界限下达到相同的性能。受Muon更新具有固定谱范数启发，我们共同设计了一种权重约束方法，该方法改善了MLP和2M参数Transformer上的Lipschitz与性能之间的权衡。我们的2-Lipschitz Transformer在莎士比亚文本上达到了60%的验证准确率。扩展到145M参数，我们的10-Lipschitz Transformer在互联网文本上达到了21%的准确率。然而，为了匹配NanoGPT基线39.4%的验证准确率，我们的Lipschitz上限增加到10^264。尽管如此，我们的Lipschitz Transformer可以在不使用层归一化、QK归一化和logit tanh软帽等稳定性措施的情况下进行训练。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [523] [Rethinking Inductive Bias in Geographically Neural Network Weighted Regression](https://arxiv.org/abs/2507.09958)
> *地理神经网络加权回归中归纳偏置的再思考*

*Zhenyuan Chen* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 地理神经网络加权回归, 归纳偏置, 空间非平稳性, 深度学习, 空间回归

**Comment:** 

> **TL;DR:** 本文重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置，并提出了通过引入卷积神经网络、循环神经网络和Transformer概念来泛化GNNWR的方法，结果表明其在捕获非线性空间关系方面优于经典方法。

**AI_Comments:** 本文创新性地将深度学习中CNN、RNN和Transformer的核心概念引入到地理神经网络加权回归（GNNWR）中，以解决现有GNNWR在归纳偏置和空间非平稳性建模上的局限。这为空间回归模型提供了更强大的非线性建模能力和更灵活的归纳偏置设计。研究结果不仅验证了新方法的有效性，还深入探讨了数据特性对模型性能的影响，为实际应用提供了指导。未来的可学习空间加权函数和混合神经架构是值得探索的方向。

<details>
  <summary>Details</summary>

**Motivation:** 归纳偏置是空间回归模型的关键因素，而现有GNNWR实现受限于固定的基于距离的方案和有限的归纳偏置，无法很好地建模空间非平稳性。

**Method:** 提出通过引入卷积神经网络（CNN）、循环神经网络（RNN）和Transformer的概念来泛化GNNWR，从而将局部感受野、序列上下文和自注意力引入空间回归。并在合成空间数据集上进行了广泛的基准测试。

**Result:** GNNWR在捕获非线性复杂空间关系方面优于经典方法。模型性能强烈依赖于数据特性：局部模型在高度异质或小样本场景中表现出色，而全局模型在更大、更同质的数据中表现更好。

**Conclusion:** 这些发现强调了归纳偏置在空间建模中的重要性，并提出了未来的研究方向，包括可学习的空间加权函数、混合神经架构以及提高处理非平稳空间数据的模型可解释性。

> **ai_Abstract:** 本文重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置问题，指出现有GNNWR在建模空间非平稳性方面的局限性。为解决此问题，作者提出通过引入卷积神经网络、循环神经网络和Transformer的概念来泛化GNNWR，从而增强其捕获局部感受野、序列上下文和自注意力的能力。实验结果表明，改进后的GNNWR在捕获非线性复杂空间关系方面优于传统方法，并且模型性能与数据特性密切相关。研究强调了归纳偏置在空间建模中的重要性，并为未来研究方向提供了启示。

> **摘要翻译:** 归纳偏置是空间回归模型中的一个关键因素，它决定了模型从有限数据中学习和捕获空间模式的能力。这项工作重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置，并指出了当前方法在建模空间非平稳性方面的局限性。虽然GNNWR通过使用神经网络学习空间加权函数扩展了传统的地理加权回归，但现有实现通常受限于固定的基于距离的方案和有限的归纳偏置。我们提出通过结合卷积神经网络、循环神经网络和Transformer的概念来泛化GNNWR，从而将局部感受野、序列上下文和自注意力引入空间回归。通过对具有不同异质性、噪声和样本量的合成空间数据集进行广泛的基准测试，我们表明GNNWR在捕获非线性和复杂空间关系方面优于经典方法。我们的结果还表明，模型性能强烈依赖于数据特性，其中局部模型在高度异质或小样本场景中表现出色，而全局模型在更大、更同质的数据中表现更好。这些发现强调了归纳偏置在空间建模中的重要性，并提出了未来的方向，包括可学习的空间加权函数、混合神经架构以及提高处理非平稳空间数据的模型可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [538] [The Target Polish: A New Approach to Outlier-Resistant Non-Negative Matrix and Tensor Factorization](https://arxiv.org/abs/2507.10484)
> *目标抛光：一种新的抗异常值非负矩阵和张量分解方法*

*Paul Fogel, Christophe Geissler, George Luta* | **Category: cs.LG** | **Updated: 2025-07-16**

**Keywords:** 非负矩阵分解, 张量分解, 异常值抵抗, Fast-HALS, 目标抛光

**Comment:** 6 pages, 4 figures, International Conference on Robust Statistics
  2025, Stresa, Italy

> **TL;DR:** 本文提出“目标抛光”框架，通过自适应平滑数据，使非负矩阵和张量分解在保持Fast-HALS算法速度的同时，实现对异常值的抵抗，并在图像去噪任务中展现出更高的效率和准确性。

**AI_Comments:** 本文的创新点在于将中位数加权平滑与Fast-HALS算法结合，从而在保持计算效率的同时增强了非负矩阵和张量分解的异常值抵抗能力。其重要性体现在为处理含有噪声的大规模数据提供了更高效和鲁棒的工具，尤其是在图像处理等领域，显著缩短了计算时间。

<details>
  <summary>Details</summary>

**Motivation:** 传统的加权非负矩阵分解（NMF）方法虽然对异常值具有抵抗力，但由于使用乘法更新来最小化目标准则，导致收敛速度慢。因此，需要一种既能抵抗异常值又能保持计算效率的方法。

**Method:** 本文引入“目标抛光”（Target Polish）框架，通过基于加权中位数变换自适应地平滑数据，使其与以速度著称的Fast-HALS算法兼容。这种方法在提供异常值抵抗能力的同时，保持了Fast-HALS高效的加性更新结构。

**Result:** 在受结构化（块）和非结构化（盐）噪声污染的图像数据集上的实证评估表明，“目标抛光”方法与最先进的鲁棒NMF方法相比，准确性持平或更高，并且在所研究的场景中将计算时间缩短了一个数量级。

**Conclusion:** “目标抛光”方法为非负矩阵和张量分解提供了一种鲁棒且计算高效的解决方案，有效解决了传统加权NMF方法的收敛速度慢问题，并在实际应用中展现出显著的性能提升。

> **ai_Abstract:** 本文提出一种名为“目标抛光”的新型框架，用于非负矩阵和张量分解，旨在解决传统加权NMF方法在处理异常值时收敛缓慢的问题。该方法通过基于加权中位数变换自适应平滑数据，使其能够兼容高效的Fast-HALS算法，从而在提供异常值抵抗能力的同时，保持了快速的计算效率。实验结果表明，“目标抛光”在图像去噪任务中，其准确性与现有鲁棒NMF方法相当或更优，并且计算时间显著减少。

> **摘要翻译:** 本文介绍了“目标抛光”，一个用于非负矩阵和张量分解的鲁棒且计算高效的框架。尽管传统的加权NMF方法对异常值具有抵抗力，但由于使用乘法更新来最小化目标准则，它们收敛缓慢。相比之下，“目标抛光”方法通过基于加权中位数变换自适应地平滑数据，保持了与以速度著称的Fast-HALS算法的兼容性。这一创新在提供异常值抵抗能力的同时，保持了Fast-HALS高效的加性更新结构。使用受结构化（块）和非结构化（盐）噪声污染的图像数据集进行的实证评估表明，“目标抛光”方法在准确性上与最先进的鲁棒NMF方法持平或超越，并且在所研究的场景中将计算时间缩短了一个数量级。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [545] [From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization](https://arxiv.org/abs/2507.12931)
> *从混合策略视角：改进可微分自动后编辑优化*

*Hongze Tan* | **Category: cs.LG, math.OC** | **Updated: 2025-07-17**

**Keywords:** DAPO, 混合策略, 策略梯度, 样本效率, 强化学习

**Comment:** 

> **TL;DR:** 本文从混合策略角度，提出了两种对可微分自动后编辑优化 (DAPO) 算法的新颖改进，旨在解决标准策略梯度方法的训练不稳定性和样本效率低下问题，通过引入引导策略和重用零奖励样本，实现了更稳定和高效的策略优化。

**AI_Comments:** 本文的创新点在于从混合策略视角出发，通过结合预训练的引导策略和有效利用零奖励样本，显著提升了强化学习在稀疏奖励环境下的训练稳定性和样本效率，特别是在自动后编辑优化领域。其理论分析也为方法的有效性提供了坚实支撑，对解决实际应用中的策略梯度训练挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准策略梯度方法在稀疏奖励设置下存在训练不稳定和样本效率低下的问题，尤其是在可微分自动后编辑优化 (DAPO) 中。

**Method:** 本文提出了两项改进：首先，引入一个预训练的稳定引导策略 ($\\pi_\phi$) 来提供离策略经验，从而正则化目标策略 ($\\pi_\theta$) 的训练，并通过自适应调整学习步长来提高训练稳定性和收敛速度。其次，扩展此思想以重新利用通常被DAPO等动态采样策略丢弃的零奖励样本，将其作为由专家策略引导的独立批次处理，进一步提高样本效率。

**Result:** 所提出的方法通过引入引导策略提高了训练稳定性和收敛速度，并通过重新利用零奖励样本增强了样本效率。理论分析表明，其目标函数在强化学习的理论框架内收敛到最优解。

**Conclusion:** 所提出的混合策略框架有效平衡了探索与利用，有望实现更稳定和高效的策略优化。

> **ai_Abstract:** 本文针对可微分自动后编辑优化 (DAPO) 中标准策略梯度方法的不稳定性和样本效率问题，提出了两种基于混合策略的新颖改进。一是引入预训练的引导策略以提供离策略经验，稳定目标策略训练并加速收敛；二是重用被DAPO丢弃的零奖励样本以提高样本效率。理论分析表明，这些方法能够使目标函数收敛到最优解，从而实现更稳定高效的策略优化。

> **摘要翻译:** 本文从混合策略的角度，对可微分自动后编辑优化 (DAPO) 算法提出了两项新颖的修改。标准的策略梯度方法可能存在不稳定性问题和样本效率低下问题，尤其是在稀疏奖励设置下。为了解决这个问题，我们首先提出了一种方法，该方法结合了一个预训练的、稳定的引导策略 ($\\pi_\phi$) 来提供离策略经验，从而正则化目标策略 ($\\pi_\theta$) 的训练。这种方法通过自适应调整学习步长来提高训练稳定性和收敛速度。其次，我们将这个想法扩展到重新利用零奖励样本，这些样本通常会被DAPO等动态采样策略丢弃。通过将这些样本视为由专家策略引导的独立批次，我们进一步提高了样本效率。我们为这两种方法提供了理论分析，证明了它们的目标函数在已建立的强化学习理论框架内收敛到最优解。所提出的混合策略框架有效平衡了探索与利用，有望实现更稳定和高效的策略优化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [553] [ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space](https://arxiv.org/abs/2507.10638)
> *ZClassifier: 基于Logit空间KL散度的温度调整和流形近似*

*Shim Soon Yong* | **Category: cs.LG, I.2.6; I.5.1** | **Updated: 2025-07-17**

**Keywords:** ZClassifier, 温度调整, 流形近似, KL散度, 高斯logit

**Comment:** 

> **TL;DR:** ZClassifier引入高斯分布的logit，通过最小化与单位各向同性高斯分布的KL散度，同时实现温度调整和流形近似，提升了分类器在鲁棒性、校准性和潜在分离方面的表现。

**AI_Comments:** ZClassifier的创新之处在于将logit空间从确定性点扩展到高斯分布，并通过KL散度自然地统一了温度标定和流形近似，为分类器的不确定性量化和潜在空间结构提供了更丰富的概率解释。这种方法可能为深度学习模型的可解释性和鲁棒性研究开辟新方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的分类框架使用确定性logit，可能在不确定性校准和潜在控制方面存在局限性，需要一种更原则性的概率方法来解决这些问题。

**Method:** ZClassifier用对角高斯分布的logit取代了传统的确定性logit。该方法通过最小化预测高斯分布与单位各向同性高斯分布之间的Kullback-Leibler（KL）散度，同时解决了温度标定和流形近似问题。

**Result:** 在CIFAR-10上的实验表明，ZClassifier在鲁棒性、校准性（uncertainty calibration）和潜在分离（latent separation）方面优于softmax分类器。

**Conclusion:** ZClassifier提供了一个统一的概率框架，通过使用高斯分布的logit和KL散度，有效地解决了温度调整和流形近似问题，从而提高了分类器的性能、不确定性量化和可解释性。

> **ai_Abstract:** ZClassifier是一种新颖的分类框架，它用对角高斯分布的logit替代传统的确定性logit。该方法通过最小化预测高斯分布与单位各向同性高斯分布之间的KL散度，同时解决了温度标定和流形近似问题，从而以概率方式统一了不确定性校准和潜在控制。实验证明，ZClassifier在CIFAR-10上提高了分类器的鲁棒性、校准性和潜在分离能力。

> **摘要翻译:** 我们引入了一种新颖的分类框架ZClassifier，它用对角高斯分布的logit取代了传统的确定性logit。我们的方法通过最小化预测高斯分布与单位各向同性高斯分布之间的Kullback-Leibler（KL）散度，同时解决了温度标定和流形近似问题。这以一种原则性的概率方式统一了不确定性校准和潜在控制，使得对类别置信度和几何一致性有了自然的解释。在CIFAR-10上的实验表明，ZClassifier在鲁棒性、校准性和潜在分离方面优于softmax分类器。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [554] [Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations](https://arxiv.org/abs/2507.12766)
> *用于偏微分方程的层分离深度学习模型与辅助变量*

*Yaru Liu, Yiqi Gu* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 深度学习, 偏微分方程, 层分离, 辅助变量, 优化

**Comment:** 

> **TL;DR:** 本文提出了一种名为层分离（LySep）的新优化框架，通过引入辅助变量来解决深度学习在求解偏微分方程时遇到的优化难题，从而提高性能。

**AI_Comments:** 该论文的创新之处在于通过引入辅助变量和交替方向算法，将深度学习在偏微分方程求解中高度非凸的优化问题分解为更易于管理的、耦合的浅层问题。这直接解决了现有方法中常见的局部最优和梯度问题，有望为偏微分方程的深度学习求解提供更鲁棒和准确的方案。

<details>
  <summary>Details</summary>

**Motivation:** 由于深度学习中损失函数的高度非凸性，现有优化算法在求解偏微分方程时常收敛到次优局部最小值，或遭受梯度爆炸/消失，导致性能不佳。

**Method:** 提出层分离（LySep）模型，通过引入辅助变量来分离深度神经网络的各层，将每层的输出及其导数表示为辅助变量，从而将深度架构分解为一系列浅层架构。建立了新的带有辅助变量的损失函数，其中仅相邻两层的变量耦合。开发了基于交替方向的算法，许多变量可以闭合形式最优更新。此外，提供了LySep模型与原始深度模型一致性的理论分析。

**Result:** 高维数值结果验证了所提出的理论，并证明了LySep在最小化损失和减少求解误差方面的优势。

**Conclusion:** LySep模型通过引入辅助变量和交替方向算法，有效解决了深度学习在求解偏微分方程时面临的优化挑战，显著提高了损失最小化和解的准确性。

> **ai_Abstract:** 本文提出了一种名为层分离（LySep）的新优化框架，旨在提升深度学习在求解偏微分方程方面的性能。针对现有方法中损失函数高度非凸、易陷入次优解以及梯度问题，LySep模型引入辅助变量来分离深度神经网络的层，将复杂的深层架构分解为一系列易于处理的浅层耦合结构。通过建立新的损失函数并开发基于交替方向的算法，实现了变量的闭合形式最优更新。理论分析证明了模型的一致性，高维数值结果也验证了LySep在降低损失和减少求解误差方面的显著优势。

> **摘要翻译:** 在本文中，我们提出了一种新的优化框架，即层分离（LySep）模型，以改进基于深度学习的偏微分方程求解方法。由于深度学习中损失函数的高度非凸性，现有的优化算法常常收敛到次优局部最小值，或者遭受梯度爆炸或消失的问题，导致性能不佳。为了解决这些问题，我们引入了辅助变量来分离深度神经网络的层。具体来说，每一层的输出及其导数都由辅助变量表示，有效地将深度架构分解为一系列浅层架构。建立了带有辅助变量的新损失函数，其中只有相邻两层的变量是耦合的。开发了基于交替方向的相应算法，其中许多变量可以以闭合形式最优地更新。此外，我们提供了理论分析，证明了LySep模型与原始深度模型之间的一致性。高维数值结果验证了我们的理论，并证明了LySep在最小化损失和减少求解误差方面的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [565] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
> *LLM推理链中的概率正确性保证*

*Weiqiu You, Anton Xue, Shreya Havaldar, Delip Rao, Helen Jin, Chris Callison-Burch, Eric Wong* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-17**

**Keywords:** LLM, 推理链, 错误检测, 概率框架, ARES

**Comment:** 

> **TL;DR:** ARES是一个新的概率框架，通过仅基于先前评估过的可靠前提来判断每个主张，从而有效检测并防止LLM推理链中的错误传播，并提供统计保证，实现了SOTA性能。

**AI_Comments:** 该论文的创新点在于提出了ARES框架，通过引入归纳判断和概率保证，有效解决了LLM推理链中错误传播这一关键问题。相较于传统的二元错误检测，ARES提供的细致分数和统计保证显著提升了LLM推理的可靠性和可信度。其在长推理链上的优异表现尤其重要，因为这正是当前LLM应用中的一个主要挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的推理链中，初始错误经常传播并损害最终结论的可靠性。当前的LLM错误检测方法未能有效检测传播的错误，因为它们没有正确考虑早期错误如何影响下游推理的判断。

**Method:** 我们引入了自回归推理蕴涵稳定性（ARES），这是一个新颖的概率框架，它通过仅基于先前评估过的可靠前提来判断每个主张，从而防止错误传播。这种归纳方法为每个步骤提供细致的分数，并提供其正确性的认证统计保证，而非脆弱的二元标签。

**Result:** ARES在四个基准测试中取得了最先进的性能（72.1% Macro-F1，提高了8.2点），并在非常长的合成推理链上表现出卓越的鲁棒性，在检测传播错误方面表现出色（90.3% F1，提高了27.6点）。

**Conclusion:** ARES通过其创新的归纳方法和概率框架，能够有效检测并防止LLM推理链中的错误传播，提供可靠的正确性统计保证，显著提升了LLM推理的可靠性和鲁棒性。

> **ai_Abstract:** 该论文提出了自回归推理蕴涵稳定性（ARES），一个新颖的概率框架，旨在解决大型语言模型（LLMs）推理链中错误传播的问题。ARES通过仅基于先前评估过的可靠前提来判断每个主张，从而有效地防止错误传播，并为每个推理步骤提供细致的概率正确性分数和统计保证。实验结果表明，ARES在多个基准测试中取得了最先进的性能，并在检测长合成推理链中的传播错误方面表现出卓越的鲁棒性。

> **摘要翻译:** 在大型语言模型（LLMs）生成的推理链中，初始错误经常传播并损害最终结论的可靠性。当前的基于LLM的错误检测方法通常无法检测传播的错误，因为它们没有正确考虑早期错误如何可能破坏下游推理的判断。为了更好地检测此类传播错误，我们引入了自回归推理蕴涵稳定性（ARES），这是一个新颖的概率框架，通过仅基于先前评估过的可靠前提来判断每个主张，从而防止错误传播。这种归纳方法为每个步骤提供细致的分数，并提供其正确性的认证统计保证，而非脆弱的二元标签。ARES在四个基准测试中取得了最先进的性能（72.1% Macro-F1，提高了8.2点），并在非常长的合成推理链上表现出卓越的鲁棒性，在检测传播错误方面表现出色（90.3% F1，提高了27.6点）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [568] [Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation](https://arxiv.org/abs/2507.12218)
> *物理信息线性模型 (PILM)：解析表示及其在地壳应变率估计中的应用*

*Tomohisa Okazaki* | **Category: cs.LG, physics.geo-ph** | **Updated: 2025-07-17**

**Keywords:** 物理信息线性模型, 地壳应变率, 解析解, 正则化, 偏微分方程

**Comment:** 

> **TL;DR:** 本文介绍了一种物理信息线性模型 (PILM)，它使用基函数进行解析求解，并将其应用于地壳应变率估计，发现贝叶斯视角下数学正则化表现更优。

**AI_Comments:** PILM 的创新之处在于提供了一种可解析求解的物理信息模型，这与计算成本较高的物理信息神经网络形成对比。其能够处理不确定边界条件和欠定系统，并提供解析最优解，具有重要意义。在实际应用中，发现数学正则化优于物理正则化，这为未来的研究和应用提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 许多物理系统由偏微分方程描述，从观测数据中求解这些方程并估计其系数或边界条件至关重要。为了克服传统物理信息神经网络计算成本高的问题，并提供一种具有解析解的替代方法，本研究提出了物理信息线性模型。

**Method:** 本研究提出了物理信息线性模型 (PILM)，该模型使用基函数的线性组合来表示解，从而实现最优解的解析表示。PILM 在正向和逆向问题（包括不确定边界条件）中进行了公式化和验证。此外，PILM 被应用于使用大地测量数据估计地壳应变率，并比较了强制弹性平衡的物理正则化与施加平滑约束的数学正则化。

**Result:** 从贝叶斯角度来看，数学正则化表现出卓越的性能。PILM 提供了一个解析可解的框架，适用于线性正向和逆向问题、欠定系统以及物理正则化。

**Conclusion:** 物理信息线性模型 (PILM) 提供了一个解析可解的框架，适用于解决线性和欠定物理问题。在应用于地壳应变率估计时，从贝叶斯视角来看，数学正则化比物理正则化表现更优。

> **ai_Abstract:** 本文提出了一种物理信息线性模型 (PILM)，它利用基函数的线性组合实现物理系统方程的解析求解。该模型在正向和逆向问题中得到验证，并应用于地壳应变率估计。研究发现，在贝叶斯视角下，相比于物理正则化，数学正则化在性能上表现更优。PILM 提供了一个适用于线性问题、欠定系统和物理正则化的解析可解框架。

> **摘要翻译:** 许多物理系统由偏微分方程 (PDE) 描述，从观测数据中求解这些方程并估计其系数或边界条件 (BC) 在理解相关现象中起着至关重要的作用。最近，一种称为物理信息神经网络的机器学习方法在科学界引起了广泛关注，该方法通过最小化来自 PDE、BC 和数据的残差总和来使用神经网络求解 PDE。在本研究中，我们研究了一种物理信息线性模型 (PILM)，它使用基函数的线性组合来表示解，从而实现最优解的解析表示。PILM 针对说明性的正向和逆向问题（包括具有不确定 BC 的情况）进行了公式化和验证。此外，PILM 应用于使用大地测量数据估计地壳应变率。具体而言，将强制速度场弹性平衡的物理正则化与施加平滑约束的数学正则化进行了比较。从贝叶斯角度来看，数学正则化表现出卓越的性能。PILM 提供了一个解析可解的框架，适用于线性正向和逆向问题、欠定系统和物理正则化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [585] [Insights into a radiology-specialised multimodal large language model with sparse autoencoders](https://arxiv.org/abs/2507.12950)
> *使用稀疏自编码器深入了解放射学专用多模态大型语言模型*

*Kenza Bouzid, Shruthi Bannur, Daniel Coelho de Castro, Anton Schwaighofer, Javier Alvarez-Valle, Stephanie L. Hyland* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 放射学AI, 多模态大语言模型, 机制可解释性, 稀疏自编码器, MAIRA-2

**Comment:** Actionable Interpretability Workshop at ICML 2025. 24 pages, 7
  figures, 5 tables

> **TL;DR:** 通过稀疏自编码器解释放射学多模态大模型MAIRA-2的内部表示，发现临床相关概念，并探讨了特征对模型行为的影响，旨在提高模型透明度。

**AI_Comments:** 这篇论文的创新点在于首次将稀疏自编码器应用于放射学领域的多模态大型语言模型MAIRA-2的机制可解释性分析。其重要性在于，在医疗这种高风险领域，提高AI模型的透明度和可信度至关重要。通过揭示模型内部学习到的临床概念，为医生理解AI决策提供了潜在途径。然而，论文也指出，在通过特征操纵来控制模型行为方面仍存在挑战，表明完全理解和控制复杂模型的内部机制仍需进一步研究。发布训练好的SAE和解释是一个很好的实践，有助于社区的进一步研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗保健应用中，AI模型的决策具有重要后果，因此可解释性对于提高模型的安全性、透明度和信任至关重要。机制可解释性，特别是通过稀疏自编码器（SAE），为揭示大型Transformer模型中人类可解释的特征提供了一种有前景的方法。

**Method:** 本研究将Matryoshka-SAE应用于放射学专用多模态大型语言模型MAIRA-2，以解释其内部表示。通过对SAE特征进行大规模自动化解释，识别出临床相关概念。进一步通过操纵（steering）这些特征来检查它们对模型行为的影响。

**Result:** 识别出一系列临床相关概念，包括医疗设备（如管线和导管放置、起搏器存在）、病理（如胸腔积液和心脏肥大）、纵向变化和文本特征。特征对模型行为的影响通过操纵表现出有成功有失败的方向性控制。研究揭示了实际和方法上的挑战，但提供了MAIRA-2学习到的内部概念的初步见解。

**Conclusion:** 本研究标志着向更深入地机制理解和解释放射学专用多模态大型语言模型迈出了一步，并为提高模型透明度铺平了道路。

> **ai_Abstract:** 本研究旨在提高医疗领域AI模型的透明度和信任度，通过将Matryoshka-SAE应用于放射学专用多模态大模型MAIRA-2，对其内部表示进行机制可解释性分析。研究成功识别出多种临床相关概念，并探讨了这些特征对模型行为的影响。尽管面临挑战，但这项工作为深入理解放射学AI模型内部运作提供了初步见解，并促进了模型透明度的提升，同时公开了训练好的SAE和解释。

> **摘要翻译:** 可解释性可以提高人工智能模型的安全性、透明度和信任度，这在决策通常会产生重大后果的医疗保健应用中尤为重要。机制可解释性，特别是通过使用稀疏自编码器（SAE），为揭示大型基于Transformer的模型中人类可解释的特征提供了一种有前景的方法。在本研究中，我们将Matryoshka-SAE应用于放射学专用多模态大型语言模型MAIRA-2，以解释其内部表示。通过对SAE特征进行大规模自动化解释，我们识别出一系列临床相关概念——包括医疗设备（例如管线和导管放置、起搏器存在）、胸腔积液和心脏肥大等病理、纵向变化和文本特征。我们进一步通过操纵（steering）这些特征来检查它们对模型行为的影响，展示了对生成内容的方向性控制，但成功程度不一。我们的结果揭示了实际和方法上的挑战，但它们为MAIRA-2学习到的内部概念提供了初步见解——标志着向更深入地机制理解和解释放射学专用多模态大型语言模型迈出了一步，并为提高模型透明度铺平了道路。我们发布了训练好的SAE和解释：https://huggingface.co/microsoft/maira-2-sae。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [604] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
> *电子健康记录建模的综合调查：从深度学习方法到大型语言模型*

*Weijieying Ren, Jingxi Zhu, Zehao Liu, Tianxiang Zhao, Vasant Honavar* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 电子健康记录, 深度学习, 大型语言模型, 医疗AI, 综述

**Comment:** 

> **TL;DR:** 该调查全面概述了电子健康记录（EHR）建模中深度学习和大型语言模型（LLMs）的最新进展，解决了数据挑战，并强调了新兴趋势和开放性问题。

**AI_Comments:** 这是一项重要的调查，因为它系统地回顾了人工智能在电子健康记录建模中的应用，特别是在深度学习和大型语言模型之间的桥梁作用。它在提出统一分类法和强调新兴趋势方面具有创新性，为这一具有挑战性领域的研究人员提供了宝贵的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）在通过分析和建模电子健康记录（EHRs）来改变医疗保健方面展现出巨大潜力。然而，EHR数据的固有异质性、时间不规则性和领域特异性带来了与视觉和自然语言任务根本不同的独特挑战。

**Method:** 本调查全面概述了深度学习、大型语言模型（LLMs）和EHR建模交叉领域的最新进展。它引入了一个统一的分类法，涵盖五个关键设计维度：以数据为中心的方法、神经网络架构设计、以学习为中心的策略、多模态学习和基于LLM的建模系统。在每个维度内，回顾了解决数据质量增强、结构和时间表示、自监督学习以及与临床知识整合的代表性方法。

**Result:** 该调查提供了AI驱动的EHR建模和临床决策支持的结构化路线图。它回顾了解决数据质量、表示、自监督学习和临床知识整合的方法，并强调了基础模型、LLM驱动的临床代理和EHR到文本转换等新兴趋势。

**Conclusion:** 本调查旨在为推进AI驱动的EHR建模和临床决策支持提供结构化路线图，并讨论了基准测试、可解释性、临床对齐和跨不同临床环境泛化等开放性挑战。

> **ai_Abstract:** 本文对AI驱动的电子健康记录（EHR）建模进行了全面调查，重点关注深度学习和大型语言模型（LLMs）。它通过引入一个涵盖五个关键设计维度的统一分类法，解决了EHR数据独特的挑战。该调查回顾了用于数据质量增强、表示以及与临床知识整合的各种方法，并强调了基础模型和LLM驱动的临床代理等新兴趋势。它还讨论了基准测试、可解释性、临床对齐和泛化等开放性挑战，旨在为推进AI驱动的EHR建模和临床决策支持提供结构化路线图。

> **摘要翻译:** 人工智能（AI）在通过分析和建模电子健康记录（EHRs）来改变医疗保健方面展现出巨大潜力。然而，EHR数据的固有异质性、时间不规则性和领域特异性带来了与视觉和自然语言任务根本不同的独特挑战，这些挑战与视觉和自然语言任务根本不同。本调查全面概述了深度学习、大型语言模型（LLMs）和EHR建模交叉领域的最新进展。我们引入了一个统一的分类法，涵盖五个关键设计维度：以数据为中心的方法、神经网络架构设计、以学习为中心的策略、多模态学习和基于LLM的建模系统。在每个维度内，我们回顾了解决数据质量增强、结构和时间表示、自监督学习以及与临床知识整合的代表性方法。我们进一步强调了新兴趋势，如基础模型、LLM驱动的临床代理和用于下游推理的EHR到文本转换。最后，我们讨论了基准测试、可解释性、临床对齐和跨不同临床环境泛化等开放性挑战。本调查旨在为推进AI驱动的EHR建模和临床决策支持提供结构化路线图。有关EHR相关方法的完整列表，请参阅 https://survey-on-tabular-data.github.io/。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [609] [Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces](https://arxiv.org/abs/2507.13092)
> *面向多模态脑机接口的基于原型学习的不确定性感知跨模态知识蒸馏*

*Hyo-Jeong Jang, Hye-Bin Shin, Seong-Whan Lee* | **Category: cs.LG, cs.HC** | **Updated: 2025-07-17**

**Keywords:** 脑机接口, 知识蒸馏, 脑电图, 原型学习, 不确定性感知

**Comment:** 

> **TL;DR:** 本文提出一种不确定性感知的跨模态知识蒸馏框架，通过原型学习解决脑电图（EEG）学习中由模态差异和标签不一致性引起的语义不确定性，从而提高多模态脑机接口的性能。

**AI_Comments:** 该论文创新性地将原型学习引入跨模态知识蒸馏，以解决脑电图（EEG）数据中普遍存在的语义不确定性问题，特别是模态差异和标签不一致性。其提出的结合原型相似性模块和任务特定蒸馏头的方法，为提升多模态脑机接口的性能提供了一个有效的途径。这项工作对于提高EEG学习的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 脑电图（EEG）作为脑机接口（BCI）中的基本模态，易受固有信号误差和人为标记错误的影响，导致标签噪声并降低模型性能。尽管多模态知识蒸馏（KD）已被探索用于增强EEG学习，但它面临模态间隙和软标签错位两大挑战，这些挑战源于EEG和视觉特征空间的异构性以及真实标签与蒸馏目标之间的不一致性。本文旨在解决由模糊特征和弱定义标签引起的语义不确定性。

**Method:** 本文提出了一种新颖的跨模态知识蒸馏框架，旨在缓解模态和标签不一致性。该框架通过一个基于原型的相似性模块来对齐特征语义，并引入一个任务特定的蒸馏头来解决监督中由标签引起的不一致性。

**Result:** 实验结果表明，该方法在公共多模态数据集上提高了基于EEG的情绪回归和分类性能，优于单模态和多模态基线。

**Conclusion:** 这些发现突出了我们提出的框架在脑机接口应用中的潜力。

> **ai_Abstract:** 本研究提出了一种新颖的跨模态知识蒸馏框架，旨在解决脑电图（EEG）在脑机接口（BCI）中因信号误差和标签噪声导致的性能下降问题。针对知识蒸馏中存在的模态间隙和软标签错位挑战，该框架通过基于原型的相似性模块对齐不同模态的特征语义，并引入任务特定的蒸馏头解决标签不一致性。实验证明，该方法有效提升了基于EEG的情绪回归和分类性能，展现了其在BCI应用中的巨大潜力。

> **摘要翻译:** 脑电图（EEG）是脑机接口（BCI）中用于认知状态监测的基本模态。然而，它极易受到内在信号误差和人为标记误差的影响，这会导致标签噪声并最终降低模型性能。为了增强EEG学习，多模态知识蒸馏（KD）已被探索，用于将知识从具有丰富表示的视觉模型转移到基于EEG的模型。然而，KD面临两个关键挑战：模态间隙和软标签错位。前者源于EEG和视觉特征空间的异构性质，而后者则源于标签不一致性，这在真实标签和蒸馏目标之间造成了差异。本文解决了由模糊特征和弱定义标签引起的语义不确定性。我们提出了一种新颖的跨模态知识蒸馏框架，该框架减轻了模态和标签不一致性。它通过一个基于原型的相似性模块来对齐特征语义，并引入一个任务特定的蒸馏头来解决监督中由标签引起的不一致性。实验结果表明，我们的方法提高了基于EEG的情绪回归和分类性能，在公共多模态数据集上优于单模态和多模态基线。这些发现突出了我们框架在BCI应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [610] [A Spectral Interpretation of Redundancy in a Graph Reservoir](https://arxiv.org/abs/2507.12963)
> *图存储库中冗余的谱解释*

*Anna Bison, Alessandro Sperduti* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 图存储库, 过平滑, 谱分析, 随机游走, 图神经网络

**Comment:** This paper has been accepted for presentation at the 3rd
  International Workshop on Reservoir Computing (RC 2025) at ICANN 2025

> **TL;DR:** 本文提出了一种基于平滑算法的图存储库变体，以解决图神经网络中的过平滑问题，并通过随机游走视角对其进行了理论分析。

**AI_Comments:** 该论文的创新点在于将计算机图形学中的平滑算法引入到图神经网络的存储库计算中，并提供了深入的理论分析，特别是从随机游走视角解释了谱参数对冗余的调节作用。这种方法为解决GNN中的过平滑问题提供了一个新的谱域视角，对于需要精确控制平滑度的图任务（如图分类）具有重要意义。理论分析的深入性是其一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在图上的重复层操作常导致过平滑问题，即图信号收敛到图拉普拉斯算子的低频分量，这限制了图存储库在GNN预处理中的应用。

**Method:** 本文重新审视了多分辨率存储库图神经网络（MRGNN）中存储库的定义，并提出了一种基于计算机图形学中表面设计领域的平滑（Fairing）算法的变体。该算法提供了一个通带谱滤波器，允许平滑而不收缩，并通过拉普拉斯算子适应图设置。该方法还通过随机游走视角进行了理论分析，解释了如何通过调整谱系数来调节冗余随机游走的贡献。

**Result:** 探索性实验基于MRGNN架构，展示了该方法的潜力，并为未来的研究方向提供了启示。该方法自然地与GNN架构连接，适用于图分类等需要适当控制平滑度的任务。

**Conclusion:** 本文的核心贡献在于从随机游走视角对所提出的算法进行了理论分析，特别是展示了如何将调整谱系数解释为调节冗余随机游走的贡献。

> **ai_Abstract:** 本文针对图神经网络中图存储库的过平滑问题，提出了一种基于平滑算法的MRGNN变体。该方法利用拉普拉斯算子构建了一个通带谱滤波器，实现了受控的平滑。论文的核心贡献在于从随机游走角度对算法进行了理论分析，解释了谱系数如何调节冗余随机游走的贡献。初步实验验证了其潜力。

> **摘要翻译:** 图存储库计算已成功应用于图作为预处理方法，以提高图神经网络（GNNs）的训练效率。然而，在图上重复应用层操作时出现的一个常见问题是过平滑，这包括图信号向图拉普拉斯算子的低频分量收敛。这项工作重新审视了多分辨率存储库图神经网络（MRGNN）中存储库的定义，这是一种谱存储库模型，并提出了一种基于平滑算法的变体，该算法最初引入于计算机图形学中的表面设计领域。该算法提供了一个通带谱滤波器，允许平滑而不收缩，并且可以通过拉普拉斯算子适应图设置。鉴于其谱公式，该方法自然地与GNN架构连接，适用于在适当控制下平滑可能有益的任务，例如图分类。本文的核心贡献在于从随机游走视角对算法进行了理论分析。特别是，它展示了如何将调整谱系数解释为调节冗余随机游走的贡献。基于MRGNN架构的探索性实验说明了这种方法的潜力，并为未来的研究提供了有希望的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [640] [WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring](https://arxiv.org/abs/2507.12969)
> *基于行车振动的基础设施健康监测小波Inception网络*

*Reza Riahi Samani, Alfredo Nunez, Bart De Schutter* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 基础设施健康监测, 行车振动, 深度学习, 小波Inception, BiLSTM

**Comment:** 

> **TL;DR:** 提出名为WaveletInception-BiLSTM的深度学习框架，利用行车振动信号进行基础设施健康监测，通过结合小波变换和Inception网络提取时频谱特征，并用BiLSTM处理时间依赖性，在铁路轨道刚度估计中表现优异。

**AI_Comments:** 该论文的创新点在于提出了WaveletInception-BiLSTM网络，特别是在深度学习框架中引入了可学习小波包变换（LWPT）作为特征提取的初始层，有效地融合了频谱信息。结合1D Inception网络进行多尺度特征提取和BiLSTM处理时间序列依赖性，使其能够处理不同测量速度下的原始振动信号，无需预处理，提高了模型的实用性。其在铁路轨道刚度估计中的优异表现，证明了其在实际基础设施健康监测领域的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有基础设施健康监测需要有效利用行车振动响应信号中的频谱和时间信息，以实现准确、自动化的监测。

**Method:** 提出WaveletInception-BiLSTM网络，其WaveletInception特征提取器使用可学习小波包变换（LWPT）作为初始层提取振动信号特征，在早期网络层融入频谱信息。随后1D Inception网络在更深层提取多尺度高级特征。提取的特征与操作条件通过LSTM层整合，捕获信息模式间的相互关联时间依赖性。估计器头部采用双向LSTM（BiLSTM）网络设计的顺序建模架构，捕获行车测量中的双向时间关系。

**Result:** 在模拟行车振动信号的铁路轨道刚度估计案例研究中，该模型在估算铁路道砟和轨垫刚度参数方面显著优于现有最先进方法。

**Conclusion:** 该方法在实现准确、局部化和全自动的行车振动基础设施健康监测方面具有巨大潜力。

> **ai_Abstract:** 本文提出一种新颖的深度学习框架WaveletInception-BiLSTM，用于基于行车振动信号的基础设施健康监测。该网络通过可学习小波包变换（LWPT）和1D Inception网络有效提取振动信号的时频谱多尺度特征，并利用BiLSTM整合操作条件、捕获时间依赖性以进行健康状况估计。实验表明，该模型在铁路轨道刚度估计方面显著优于现有方法，展现了其在准确、局部化和自动化基础设施健康监测中的巨大潜力。

> **摘要翻译:** 本文提出了一种新颖的基于深度学习的框架，用于利用行车振动响应信号进行基础设施健康监测。认识到频谱和时间信息的重要性，我们引入了WaveletInception-BiLSTM网络。WaveletInception特征提取器采用可学习小波包变换（LWPT）作为主干，用于提取振动信号特征，在早期网络层中融入频谱信息。随后是1D Inception网络，在更深层提取多尺度、高层特征。提取的振动信号特征随后通过长短期记忆（LSTM）层与操作条件整合。由此产生的特征提取网络能够有效地分析各种测量速度下的行车振动信号，无需预处理，并使用LSTM捕获不同信息模式之间相互关联的时间依赖性，并创建用于健康状况估计的特征向量。估计器头部采用使用双向LSTM（BiLSTM）网络设计的顺序建模架构，捕获行车测量中的双向时间关系。这种架构允许对基础设施健康状况进行高分辨率、梁级评估。一项以铁路轨道刚度估计为重点的案例研究，使用模拟行车振动信号，表明该模型在估计铁路道砟和轨垫刚度参数方面显著优于现有最先进方法。结果强调了这种方法在准确、局部化和全自动行车振动基础设施健康监测方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [645] [LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization](https://arxiv.org/abs/2410.20625)
> *LoRA Done RITE：LoRA优化的鲁棒不变变换均衡*

*Jui-Nan Yen, Si Si, Zhao Meng, Felix Yu, Sai Surya Duvvuri, Inderjit S. Dhillon, Cho-Jui Hsieh, Sanjiv Kumar* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-16**

**Keywords:** LoRA, 参数高效微调, 变换不变性, 优化器, LLM

**Comment:** Published as an oral paper at ICLR 2025. The code for our project is
  available at https://github.com/gkevinyen5418/LoRA-RITE

> **TL;DR:** 本文提出了LoRA-RITE，一种新颖的自适应矩阵预处理方法，用于LoRA优化，解决了现有LoRA优化器缺乏变换不变性的问题，从而提高了LLM微调的效率和性能。

**AI_Comments:** 本文的创新点在于提出了LoRA-RITE，通过引入变换不变性，解决了现有LoRA优化器在权重更新上的关键缺陷。这不仅从理论上解释了问题，并通过实验证明了其在实际LLM微调中的显著性能提升，对于参数高效微调领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LoRA优化器缺乏变换不变性，导致权重更新效率低下和实际应用中的次优解。LoRA的实际更新取决于其两个因子如何缩放或旋转。

**Method:** 本文引入了LoRA-RITE，这是一种新颖的自适应矩阵预处理方法，旨在实现变换不变性并保持计算效率。该方法通过理论分析和实验验证。

**Result:** LoRA-RITE在各种LLM任务和不同模型（包括Gemma 2B、7B和mT5-XXL）上均表现出相对于现有优化器的一致改进。例如，在Gemma-2B的LoRA微调中，LoRA-RITE取代Adam后，在Super-Natural Instructions上获得了4.6%的准确率提升，在其他四个LLM基准（HellaSwag、ArcChallenge、GSM8K、OpenBookQA）上获得了3.5%的准确率提升。

**Conclusion:** LoRA-RITE通过引入变换不变性，显著提高了LoRA优化的效率和性能，解决了现有方法中的关键缺陷。

> **ai_Abstract:** 本文提出LoRA-RITE，一种针对LoRA优化的新型自适应矩阵预处理方法，旨在解决现有LoRA优化器缺乏变换不变性导致效率低下和次优解的问题。LoRA-RITE通过实现变换不变性，显著提高了大型语言模型（LLM）微调的性能和效率。实验结果表明，在多种LLM任务和模型上，LoRA-RITE相对于现有优化器（如Adam）表现出一致的准确率提升。

> **摘要翻译:** 低秩适应（LoRA）是一种广泛使用的参数高效LLM微调方法，可降低内存需求。然而，当前的LoRA优化器缺乏变换不变性，这意味着对权重的实际更新取决于两个LoRA因子的缩放或旋转方式。这种缺陷导致学习效率低下和实际应用中的次优解。本文介绍了LoRA-RITE，一种用于LoRA优化的新型自适应矩阵预处理方法，该方法可以实现变换不变性并保持计算效率。我们提供了理论分析来证明我们方法的优势，并使用包括Gemma 2B、7B和mT5-XXL在内的不同模型在各种LLM任务上进行了实验。结果表明，相对于现有优化器，我们的方法持续改进。例如，在Gemma-2B的LoRA微调中，用LoRA-RITE替换Adam在Super-Natural Instructions上获得了4.6%的准确率提升，在其他四个LLM基准（HellaSwag、ArcChallenge、GSM8K、OpenBookQA）上获得了3.5%的准确率提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [647] [Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises](https://arxiv.org/abs/2507.12787)
> *多通道图神经网络用于新三板企业财务风险预测*

*Jianyu Zhu* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 金融风险预测, 图神经网络, 多通道, 新三板, 中小企业

**Comment:** 10 pages, 4 figures. Submitted for conference review

> **TL;DR:** 本文提出了一种多通道图神经网络（GIN）框架，通过整合财务指标、文本披露和企业关系数据，显著提升了新三板企业财务风险预测的准确性。

**AI_Comments:** 该研究通过引入多通道图神经网络，创新性地整合了多种异构数据源（数值、文本、图数据）进行金融风险预测，并通过注意力机制和门控单元提升了模型性能。这对于提升新三板中小企业的风险识别能力具有重要实践意义，为金融监管和投资决策提供了有力的支持。

<details>
  <summary>Details</summary>

**Motivation:** 全国中小企业股份转让系统（新三板）上的中小企业因规模和财务韧性有限，面临较高的财务困境风险，需要有效的风险预测方法。

**Method:** 提出了一种多通道深度学习框架，具体为三重通道图同构网络（Triple-Channel GIN），分别处理数值、文本和图数据输入。通过注意力机制和门控单元融合这些模态特定的表示，以增强鲁棒性和预测精度。

**Result:** 在7,731家真实新三板公司的数据上，该模型在AUC、精确率、召回率和F1分数方面显著优于传统机器学习方法和单模态基线。

**Conclusion:** 这项工作为中小企业风险建模提供了理论和实践见解，并为金融监管机构和投资者提供了数据驱动的工具。

> **ai_Abstract:** 本研究针对新三板中小企业面临的财务困境风险，提出了一种创新的多通道图神经网络（GIN）框架。该框架整合了企业的结构化财务数据、文本披露信息以及企业间关系数据，通过三重通道GIN分别处理不同模态的输入，并利用注意力机制和门控单元进行融合，从而实现全面的财务风险预测。实验结果表明，该模型在真实数据集上显著优于现有方法，为中小企业风险建模提供了新的工具和见解。

> **摘要翻译:** 随着中国多层次资本市场的持续演进，全国中小企业股份转让系统（NEEQ），又称“新三板”，已成为中小企业（SMEs）重要的融资平台。然而，由于规模有限和财务韧性不足，许多新三板上市企业面临较高的财务困境风险。为解决这一问题，我们提出了一种多通道深度学习框架，该框架整合了结构化财务指标、文本披露和企业关系数据，以进行全面的财务风险预测。具体而言，我们设计了一种三重通道图同构网络（Triple-Channel GIN），分别处理数值、文本和图基输入。这些模态特定的表示通过基于注意力的机制融合，然后通过门控单元增强鲁棒性和预测精度。在来自7,731家真实新三板公司的数据上的实验结果表明，我们的模型在AUC、精确率、召回率和F1分数方面显著优于传统机器学习方法和单模态基线。这项工作为中小企业风险建模提供了理论和实践见解，并为金融监管机构和投资者提供了数据驱动的工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [650] [Boolformer: Symbolic Regression of Logic Functions with Transformers](https://arxiv.org/abs/2309.12207)
> *Boolformer：基于Transformer的逻辑函数符号回归*

*Stéphane d'Ascoli, Arthur Renard, Vassilis Papadopoulos, Samy Bengio, Josh Susskind, Emmanuel Abbé* | **Category: cs.LG, cs.LO** | **Updated: 2025-07-16**

**Keywords:** 符号回归, 布尔函数, Transformer, 机器学习, 基因调控网络

**Comment:** Updated with new ESPRESSO experiments, reworked manuscript. Added 2
  authors that participated in last submission

> **TL;DR:** Boolformer是一个基于Transformer的模型，用于布尔函数的符号回归，能够在完整、不完整或有噪声的数据下找到紧凑或近似的表达式，并在实际任务中表现出色，可作为经典机器学习的可解释替代方案，并大大加速基因调控网络建模。

**AI_Comments:** Boolformer的创新之处在于将Transformer模型应用于布尔函数的符号回归，这提供了一种新的、可解释的机器学习方法。其在处理不完整/有噪声数据和在基因调控网络建模中的显著加速是其重要性体现，且代码和模型的公开可用性也促进了研究的透明度和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在引入一种新的、可解释的机器学习方法（Boolformer），用于布尔函数的符号回归，以替代经典机器学习方法，并在如基因调控网络建模等实际任务中提供高效且具有竞争力的解决方案。

**Method:** 论文提出了Boolformer，一个基于Transformer的模型，用于执行端到端的布尔函数符号回归。

**Result:** Boolformer在给定完整真值表的情况下，可以预测训练中未见过的复杂函数的紧凑公式；即使在不完整或有噪声的观测下，也能找到良好的近似表达式。在广泛的真实世界二元分类数据集上进行了评估，显示其作为经典机器学习方法的可解释替代方案的潜力。在基因调控网络动态建模任务中，Boolformer与最先进的遗传算法具有竞争力，并且速度提高了几个数量级。

**Conclusion:** Boolformer是一种有效且高效的基于Transformer的布尔函数符号回归模型，在多种实际应用中表现出色，可作为可解释的机器学习替代方案，并显著加速特定科学建模任务。

> **ai_Abstract:** 本文介绍了Boolformer，一个基于Transformer的模型，专为布尔函数的端到端符号回归而设计。该模型展示了在给定完整真值表时，能为未训练过的复杂函数预测紧凑公式的能力，并在数据不完整或有噪声时也能找到良好的近似表达式。Boolformer在实际二元分类数据集上表现出作为可解释机器学习方法的潜力，并在基因调控网络建模任务中，与现有先进遗传算法相比，不仅具有竞争力，还实现了数个数量级的速度提升。

> **摘要翻译:** 我们引入了Boolformer，一个基于Transformer的模型，旨在执行布尔函数的端到端符号回归。首先，我们展示了在给定完整真值表的情况下，它能够为训练中未见过的复杂函数预测紧凑的公式。然后，我们证明了即使在不完整或有噪声的观测下，Boolformer仍然能够找到良好的近似表达式。我们在广泛的真实世界二元分类数据集上评估了Boolformer，展示了其作为经典机器学习方法的可解释替代方案的潜力。最后，我们将其应用于基因调控网络动力学建模这一普遍任务，并通过基准测试表明Boolformer与最先进的遗传算法相比具有竞争力，并且速度提高了几个数量级。我们的代码和模型已公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [664] [A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints](https://arxiv.org/abs/2507.12979)
> *数据共享约束下异构多域环境的分布式生成式AI方法*

*Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 分布式生成AI, 联邦学习, 生成对抗网络, 数据异构性, 设备异构性, 数据隐私

**Comment:** 

> **TL;DR:** 提出一种结合联邦学习和U形分裂学习的分布式GAN训练方法，在不共享原始数据的情况下，有效利用低能力设备并解决数据异构性问题，显著提升生成和分类性能。

**AI_Comments:** 这篇论文的创新点在于将联邦学习、聚类技术和分裂学习巧妙地结合起来，解决了在资源受限和数据隐私敏感的分布式环境中训练生成模型的核心难题。它不仅提升了模型性能，还特别强调了“不共享任何原始数据或标签”的严格隐私保护，这对于实际应用具有重要意义。该方法对于边缘计算和物联网场景中的生成式AI部署具有潜在的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统生成模型训练需要大量数据和计算资源，而实际中低能力设备（如IoT、边缘设备）利用不足，且隐私和版权限制导致难以获取大数据集。

**Method:** 提出一种去中心化GAN训练新方法，结合KLD加权聚类联邦学习解决数据异构性和多域数据集问题，以及异构U形分裂学习解决设备异构性，确保节点间不共享任何标签或原始数据（真实或合成）。

**Result:** 相比基准，图像生成分数提高1.1-2.2倍，分类指标平均提升10%（多域非IID设置下最高50%），且延迟更低。

**Conclusion:** 该方法在数据共享受限的异构多域环境中，通过有效利用分布式数据和低能力设备，显著提升了生成模型训练的性能和效率。

> **ai_Abstract:** 本文提出一种新颖的分布式生成式AI方法，用于在数据共享受限的异构多域环境中训练生成对抗网络（GANs）。该方法结合了KLD加权聚类联邦学习和异构U形分裂学习，旨在解决数据和设备异构性、资源受限以及隐私保护下的数据共享难题。实验结果表明，该方法在图像生成、分类性能和延迟方面均显著优于现有基准。

> **摘要翻译:** 联邦学习因其允许多个节点在不共享原始数据的情况下协同训练机器学习模型而受到越来越多的关注。与此同时，生成式AI——特别是生成对抗网络（GANs）——在医疗保健、安全和图像生成等广泛领域取得了显著成功。然而，训练生成模型通常需要大量数据集和显著的计算资源，这在现实世界中往往是不可用的。获取此类资源可能成本高昂且效率低下，尤其当许多未充分利用的设备——如物联网设备和边缘设备——具有不同能力而处于闲置状态时。此外，由于隐私担忧和版权限制，获取大型数据集具有挑战性，因为大多数设备不愿意共享其数据。为了应对这些挑战，我们提出了一种新颖的去中心化GAN训练方法，该方法能够在不以原始形式共享数据的情况下，利用分布式数据和未充分利用的低能力设备。我们的方法旨在解决去中心化环境中的关键挑战，结合KLD加权聚类联邦学习来解决数据异构性和多域数据集问题，并结合异构U形分裂学习来解决严格数据共享约束下设备异构性的挑战——确保节点之间从不共享任何标签或原始数据，无论是真实的还是合成的。实验结果表明，我们的方法在关键性能指标上表现出持续和显著的改进，实现了1.1倍至2.2倍更高的图像生成分数，分类指标平均提升10%（在多域非IID设置下最高可达50%），并且与几个基准相比，延迟大大降低。我们的代码可在https://github.com/youssefga28/HuSCF-GAN找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [674] [We should avoid the assumption of data-generating probability distributions in social settings](https://arxiv.org/abs/2407.17395)
> *我们应避免在社会环境中假设数据生成概率分布*

*Benedikt Höltgen, Robert C. Williamson* | **Category: cs.LG** | **Updated: 2025-07-17**

**Keywords:** 数据生成分布, 机器学习, 社会环境, 概率分布, 公平算法

**Comment:** Presented at the Humans, Algorithmic Decision-Making and Society
  Workshop at ICML 2024

> **TL;DR:** 本文认为，在社会环境中，机器学习不应假设存在数据生成概率分布，因为它不存在且可能产生误导。

**AI_Comments:** 这篇论文提出了一个对机器学习基础假设的深刻批判，特别是在社会科学应用中。其创新之处在于挑战了数据生成分布的普遍性和必要性，并提出关注真实人群的替代视角。这对于理解机器学习模型在社会影响方面的局限性及伦理考量具有重要意义。它强调了在应用机器学习时，需要对模型的基础假设进行批判性审视。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习研究，包括公平算法，严重依赖数据生成概率分布的概念。作者认为这种假设是错误的，因为真实的概率分布不存在，并且这种假设可能具有误导性，模糊了机器学习实践中的选择和目标。

**Method:** 作者通过论证真实概率分布不存在且不应被不加批判地处理，并指出存在直接关注相关人群而非抽象分布的替代框架，且这些框架几乎不改变经典学习理论。

**Result:** 结果表明，替代框架是可行的，并且假设真实概率或数据生成分布可能具有误导性，并掩盖了机器学习实践中的选择和目标。

**Conclusion:** 至少在社会环境中，机器学习工作应避免假设数据生成概率分布。

> **ai_Abstract:** 这篇立场论文挑战了机器学习研究中普遍存在的数据生成概率分布假设，特别是在社会环境中。作者认为，这种真实的概率分布并不存在，并且对其的假设可能导致误导和模糊机器学习实践中的真实目标与选择。论文提出，存在直接关注相关人群的替代框架，这些框架在不实质性改变经典学习理论的前提下，可以避免这种有问题的假设。因此，论文主张在社会应用中，机器学习应摒弃数据生成概率分布的假设。

> **摘要翻译:** 机器学习研究，包括促进公平或公正算法的工作，严重依赖数据生成概率分布的概念。标准的假设是，由于数据点是“从”这种分布中“采样”的，因此可以从观测数据中了解这种分布，从而预测也将从中抽取出的未来数据点。然而，我们认为这种真实的概率分布不存在，不应不加批判地对待。我们表明，存在直接关注相关人群而非抽象分布的替代框架，并且这些框架几乎不改变经典学习理论。此外，我们认为假设真实概率或数据生成分布可能具有误导性，并模糊了机器学习实践中所做的选择和所追求的目标。基于这些考虑，这篇立场论文认为，至少在社会环境中，机器学习工作应避免假设数据生成概率分布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [682] [FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction](https://arxiv.org/abs/2507.12803)
> *FLDmamba：融合傅里叶和拉普拉斯变换分解与Mamba以增强时间序列预测*

*Qianru Zhang, Chenglei Yu, Haixin Wang, Yudong Yan, Yuansheng Cao, Siu-Ming Yiu, Tailin Wu, Hongzhi Yin* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 时间序列预测, FLDmamba, 傅里叶变换, 拉普拉斯变换, Mamba模型

**Comment:** 12 pages

> **TL;DR:** FLDmamba提出了一种结合傅里叶和拉普拉斯变换分解与Mamba模型的新框架，旨在解决时间序列预测中多尺度周期性、瞬态动力学和数据噪声问题，并在基准测试中取得了优异性能。

**AI_Comments:** 本文的创新点在于将傅里叶和拉普拉斯变换分解引入Mamba模型，以克服Mamba在捕获多尺度周期性和瞬态动力学方面的不足，并增强模型对噪声的鲁棒性。这为长期时间序列预测提供了一个高效且性能优越的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列预测面临非平稳性、多尺度周期性、瞬态动力学等复杂挑战，尤其在长期预测中。Transformer模型虽有前景但二次复杂度限制了效率；Mamba等状态空间模型虽高效但无法有效捕获多尺度周期性和瞬态动力学，且易受数据噪声影响。

**Method:** 本文提出了FLDmamba框架，它利用傅里叶变换和拉普拉斯变换的优势，有效地捕获时间序列数据中的多尺度周期性、瞬态动力学，并提高模型对数据噪声问题的鲁棒性，然后与Mamba模型结合。

**Result:** FLDmamba在时间序列预测基准测试中取得了卓越性能，优于基于Transformer和其他Mamba的架构。

**Conclusion:** FLDmamba通过结合傅里叶和拉普拉斯变换分解与Mamba模型，有效解决了时间序列预测中的复杂挑战，并在多项任务中展现出优越的预测能力和鲁棒性。

> **ai_Abstract:** FLDmamba是一种新颖的时间序列预测框架，通过将傅里叶和拉普拉斯变换分解与Mamba模型相结合，旨在解决传统模型在处理时间序列数据时面临的非平稳性、多尺度周期性、瞬态动力学和数据噪声等挑战。实验证明，FLDmamba在时间序列预测基准测试中表现出色，超越了Transformer和其他Mamba基线模型。

> **摘要翻译:** 时间序列预测是各个领域的关键任务，但由于时间序列数据固有的复杂性，包括非平稳性、多尺度周期性和瞬态动力学，尤其在处理长期预测时面临重大挑战。尽管基于Transformer的架构已显示出前景，但其与序列长度相关的二次复杂度阻碍了其在长期预测中的效率。状态空间模型（如Mamba）的最新进展为长期建模提供了更高效的替代方案，但它们无法有效捕获多尺度周期性和瞬态动力学。同时，它们容易受到时间序列中数据噪声问题的影响。本文提出了一种新颖的框架FLDmamba（傅里叶和拉普拉斯变换分解Mamba），以解决这些局限性。FLDmamba利用傅里叶变换和拉普拉斯变换的优势，有效捕获时间序列数据中的多尺度周期性、瞬态动力学，并提高模型对数据噪声问题的鲁棒性。我们广泛的实验表明，FLDmamba在时间序列预测基准测试中取得了卓越性能，优于基于Transformer和其他基于Mamba的架构。为了促进我们方法的可复现性，我们已通过以下URL公开了代码和数据：https://github.com/AI4Science-WestlakeU/FLDmamba。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [688] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
> *通过Boosting赋予旧SAE新的领域能力*

*Nikita Koriagin, Yaroslav Aksenov, Daniil Laptev, Gleb Gerasimov, Nikita Balagansky, Daniil Gavrilov* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 稀疏自编码器, LLM可解释性, 残差学习, 领域适应, 特征盲区

**Comment:** 

> **TL;DR:** 本文提出一种残差学习方法，通过训练一个辅助稀疏自编码器（SAE）来建模预训练SAE在特定领域文本上的重建误差，从而使SAE无需完全重新训练即可适应新领域，显著提升大型语言模型（LLM）的领域特定可解释性。

**AI_Comments:** 这项研究的创新之处在于其提出的残差学习方法，它允许在不进行昂贵的全模型重训练的情况下，有效地使现有的稀疏自编码器（SAE）适应新的领域知识。这对于在实际应用中增强大型语言模型（LLM）的可解释性至关重要，特别是当需要针对特定领域进行精细化分析时。该方法提供了一种灵活且高效的解决方案，以应对SAE在处理领域特异性特征时的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏自编码器（SAE）在解释大型语言模型（LLM）内部表示方面表现出色，但它们通常无法捕获训练语料库中不常见到的领域特定特征，导致“特征盲区”。

**Method:** 本文提出一种残差学习方法，无需完全重新训练。具体来说，训练一个辅助SAE来建模预训练SAE在领域特定文本上的重建误差，以捕获主模型遗漏的特征。在推理时，将两个模型的输出相加。

**Result:** 在多个专业领域中，该方法显著改善了LLM的交叉熵和解释方差指标。实验表明，该方法能有效地将新的领域知识整合到现有SAE中，同时保持其在通用任务上的性能。

**Conclusion:** 这种方法使研究人员能够选择性地增强SAE对特定领域的可解释性，为LLM的定向机械可解释性开辟了新的可能性。

> **ai_Abstract:** 稀疏自编码器（SAE）虽有助于解释大型语言模型（LLM），但难以捕获领域特定特征。本文提出一种残差学习方法，通过训练一个辅助SAE来学习预训练SAE在特定领域文本上的重建误差。该方法通过组合两个SAE的输出来增强模型，显著提升了LLM在特定领域的交叉熵和解释方差表现，且无需完全重新训练，从而提高了SAE在特定领域的解释能力，为LLM的定向可解释性提供了新途径。

> **摘要翻译:** 稀疏自编码器（SAEs）已成为解释大型语言模型内部表示的强大工具，但它们通常无法捕获其训练语料库中不常见的领域特定特征。本文介绍了一种残差学习方法，无需完全重新训练即可解决这种特征盲区。我们提出训练一个辅助SAE，专门用于建模预训练SAE在领域特定文本上的重建误差，从而有效地捕获主模型遗漏的特征。通过在推理时将两个模型的输出相加，我们证明了在多个专业领域中LLM交叉熵和解释方差指标的显著改进。我们的实验表明，该方法能有效地将新的领域知识整合到现有SAE中，同时保持其在通用任务上的性能。这种方法使研究人员能够选择性地增强SAE对特定领域的可解释性，为LLM的定向机械可解释性开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [697] [Generative Diffusion Models for Resource Allocation in Wireless Networks](https://arxiv.org/abs/2504.20277)
> *无线网络中资源分配的生成扩散模型*

*Yigit Berkay Uslu, Samar Hadou, Shirin Saeedi Bidokhti, Alejandro Ribeiro* | **Category: cs.LG, eess.SP** | **Updated: 2025-07-17**

**Keywords:** 生成扩散模型, 资源分配, 无线网络, 随机策略, 图神经网络

**Comment:** 

> **TL;DR:** 本文提出了一种基于生成扩散模型（GDM）的监督训练算法，用于学习无线网络中的随机资源分配策略，并通过模仿专家策略实现了接近最优的性能。

**AI_Comments:** 这项工作将生成扩散模型引入无线网络资源分配领域，提供了一种学习随机、接近最优策略的新颖方法。通过结合图神经网络，该模型具有良好的泛化能力，能够适应不同的网络配置。这种结合机器学习与传统优化问题的方法，为未来无线网络管理提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 解决无线网络中的随机资源分配问题，即在满足遍历服务质量（QoS）约束的条件下，最大化遍历效用函数。

**Method:** 提出一种监督训练算法，利用生成扩散模型（GDM）学习随机资源分配策略。该方法通过从能产生近似最优解的随机专家策略中获取样本，训练GDM策略来模仿专家并从最优分布中生成新样本。为实现对一系列网络配置的泛化，采用图神经网络（GNN）架构参数化反向扩散过程。

**Result:** 通过顺序执行生成的样本，实现了接近最优的性能。在功率控制的案例研究中展示了数值结果。

**Conclusion:** 该研究成功地利用生成扩散模型和图神经网络为无线网络中的随机资源分配问题设计了一种有效的、可泛化的策略，并在功率控制案例中验证了其接近最优的性能。

> **ai_Abstract:** 本文提出了一种基于生成扩散模型（GDM）的监督训练算法，旨在解决无线网络中的随机资源分配问题，即在满足QoS约束的同时最大化效用函数。该方法通过模仿提供近似最优解的专家策略，训练GDM生成来自最优分布的新样本，并通过顺序执行这些样本实现了接近最优的性能。为了增强模型对不同网络配置的泛化能力，研究人员将图神经网络（GNN）集成到反向扩散过程中。文章通过功率控制的案例研究验证了所提方法的有效性。

> **摘要翻译:** 本文提出了一种用于学习随机资源分配策略的生成扩散模型（GDM）的监督训练算法。我们将分配问题表述为在遍历服务质量（QoS）约束下最大化遍历效用函数。给定来自随机专家策略的样本，该策略为约束优化问题提供了接近最优的解决方案，我们训练GDM策略来模仿专家并从最优分布中生成新样本。通过顺序执行生成的样本，我们实现了接近最优的性能。为了实现对一系列网络配置的泛化，我们使用图神经网络（GNN）架构参数化反向扩散过程。我们在功率控制的案例研究中展示了数值结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [698] [Neural stochastic Volterra equations: learning path-dependent dynamics](https://arxiv.org/abs/2407.19557)
> *神经随机Volterra方程：学习路径依赖动力学*

*Martin Bergerhausen, David J. Prömel, David Scheffels* | **Category: cs.LG, math.PR, stat.ML** | **Updated: 2025-07-16**

**Keywords:** 神经随机Volterra方程, 随机Volterra方程, 路径依赖, 记忆效应, 神经网络

**Comment:** significantly extended version, 24 pages

> **TL;DR:** 论文引入了神经随机Volterra方程（NSVE）作为一种新的物理启发式架构，用于建模具有记忆效应和不规则行为的随机系统，并提供了理论基础。它在多种SVEs上进行了数值实验，比较了NSVEs、神经随机微分方程（NSDEs）和深度算子网络（DeepONets）的性能。

**AI_Comments:** 这篇论文的创新点在于引入了神经随机Volterra方程，这是一种结合了机器学习（神经网络）和随机Volterra方程的新模型，专门用于处理具有路径依赖和记忆效应的复杂随机系统。它推广了现有的神经随机微分方程，为建模金融、物理等领域中的复杂动态提供了新的工具。论文还强调了理论基础的提供和与现有流行方法的比较，这增加了其研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 随机Volterra方程（SVEs）是用于建模具有记忆效应和不规则行为的随机系统时间演化的数学模型。本研究的动机是引入神经随机Volterra方程作为一种物理启发式架构，以推广神经随机微分方程，从而更有效地处理这类复杂系统。

**Method:** 本文引入了神经随机Volterra方程（NSVEs）作为一种物理启发式架构，并提供了其理论基础。通过对扰动摆方程、广义Ornstein-Uhlenbeck过程、粗糙Heston模型和货币储备动力学等多种随机Volterra方程进行数值实验，比较了NSVEs、神经随机微分方程（NSDEs）和深度算子网络（DeepONets）的性能。

**Result:** 论文展示了在各种随机Volterra方程上进行的数值实验，并比较了神经随机Volterra方程、神经随机微分方程和深度算子网络的性能。具体的性能比较结果未在摘要中详细说明。

**Conclusion:** 论文成功引入了神经随机Volterra方程作为一种新的物理启发式架构，用于建模具有记忆效应和不规则行为的随机系统，并提供了理论基础。通过与现有方法的比较，验证了其在处理此类问题上的潜力。

> **ai_Abstract:** 本文提出了一种名为神经随机Volterra方程（NSVEs）的新型物理启发式架构，旨在建模具有记忆效应和不规则行为的随机系统。NSVEs是神经随机微分方程（NSDEs）的推广，并提供了相应的理论基础。通过在扰动摆方程、广义Ornstein-Uhlenbeck过程、粗糙Heston模型和货币储备动力学等多种随机Volterra方程上进行数值实验，论文比较了NSVEs与NSDEs和深度算子网络（DeepONets）的性能。

> **摘要翻译:** 随机Volterra方程（SVEs）是用于模拟具有记忆效应和不规则行为的随机系统时间演化的数学模型。我们引入了神经随机Volterra方程作为一种物理启发式架构，推广了神经随机微分方程的类别，并提供了一些理论基础。论文展示了在各种SVEs上的数值实验，例如扰动摆方程、广义Ornstein-Uhlenbeck过程、粗糙Heston模型和货币储备动力学，并比较了神经SVEs、神经SDEs和深度算子网络（DeepONets）的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [210] [On multiagent online problems with predictions](https://arxiv.org/abs/2507.12486)
> *关于多智能体在线预测问题*

*Gabriel Istrate, Cosmin Bonchis, Victor Bogdan* | **Category: cs.MA, cs.AI, cs.GT** | **Updated: 2025-07-15**

**Keywords:** 多智能体, 在线算法, 预测, 竞争比, 滑雪租赁问题

**Comment:** arXiv admin note: substantial text overlap with arXiv:2405.11873

> **TL;DR:** 本文研究了多智能体环境下带预测的算法的性能，引入了一个双预测器框架，并以多智能体滑雪租赁问题为例进行了分析，提出了一个对预测误差更鲁棒的算法。

**AI_Comments:** 这篇论文通过引入双预测器框架，创新性地将预测机制引入多智能体在线问题，考虑了智能体自身行为预测与其他智能体行为预测的区别。通过滑雪租赁问题的具体案例分析，揭示了预测准确性与算法鲁棒性之间的权衡，并提出了改进方案，对理解多智能体决策在不确定环境下的性能提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 研究多智能体环境下带预测的算法的性能，并理解在不同预测质量假设下，通过使用预测器可以达到的最佳竞争比。

**Method:** 引入了一个双预测器框架，该框架假设智能体使用一个预测器预测自身的未来行为，另一个预测器预测其他参与者的行为。通过分析多智能体版本的滑雪租赁问题来阐释该框架。

**Result:** 在其他智能体预测完美的情况下，遵循自我预测器的算法是最佳的，但对智能体未来行为的错误预测不具鲁棒性；论文提出了一个具有更好鲁棒性属性的算法并对其进行了基准测试。

**Conclusion:** 论文提出了一个双预测器框架来分析多智能体在线问题，并展示了在完美预测的情况下，鲁棒性是需要考虑的关键因素，并提出了改进的算法。

> **ai_Abstract:** 本文研究了多智能体在线问题中带预测算法的性能。作者提出了一个双预测器框架，其中智能体使用一个预测器预测自身行为，另一个预测器预测其他智能体行为，旨在探究在不同预测质量下可实现的最佳竞争比。作为该框架的示例，文章分析了多智能体滑雪租赁问题。研究发现，在其他智能体行为预测完美的情况下，遵循自我预测的算法虽然最优，但对自身未来行为的错误预测不具鲁棒性。为此，论文提出了一个鲁棒性更强的算法并进行了基准测试。

> **摘要翻译:** 我们研究了多智能体环境下带预测（竞争性）算法的性能。我们引入了一个双预测器框架，该框架假设智能体使用一个预测器预测其未来的（自身）行为，另一个预测器预测其他参与者的行为。我们主要关注的问题是理解在不同预测质量假设下，通过使用此类预测器可以达到的最佳竞争比。作为我们框架的示例，我们引入并分析了滑雪租赁问题的多智能体版本。在这个问题中，智能体可以通过汇集资源来获得某种资产的团体许可证。如果未达到许可证价格，则智能体必须以单位价格每天单独租用该资产。否则，该许可证将永久免费提供给所有人。在其他预测完美的情况下，遵循自我预测器的算法是最佳的，但对智能体未来行为的错误预测不具鲁棒性；我们提供了一个具有更好鲁棒性属性的算法并对其进行了基准测试。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [282] [Coral Protocol: Open Infrastructure Connecting The Internet of Agents](https://arxiv.org/abs/2505.00749)
> *珊瑚协议：连接智能体互联网的开放基础设施*

*Roman J. Georgio, Caelum Forder, Suman Deb, Andri Rahimov, Peter Carroll, Önder Gürcan* | **Category: cs.MA, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 珊瑚协议, 智能体互联网, 多智能体系统, 互操作性, 去中心化

**Comment:** 46 pages, 7 figures, Whitepaper

> **TL;DR:** 珊瑚协议是一个开放去中心化的协作基础设施，旨在为智能体互联网提供通信、协调、信任和支付功能，解决多AI智能体之间互操作性问题。

**AI_Comments:** 珊瑚协议的创新之处在于其对“智能体互联网”这一新兴概念的深刻理解和前瞻性布局。它通过提供一个开放、去中心化且注重互操作性的基础架构，有望成为未来多智能体AI系统协作的核心。其强调的兼容性、安全性和供应商中立性是构建健壮AI生态系统的关键。该协议的提出，预示着AI应用将从单一智能体向复杂协作网络演进，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着组织部署多个需要跨领域和供应商协同工作的专业AI智能体，对互操作性的需求日益增长。现有的AI智能体缺乏统一的通信和协调机制。

**Method:** 珊瑚协议通过引入标准化消息格式进行智能体通信、模块化协调机制用于编排多智能体任务，以及安全团队组建能力来动态组建可信智能体群组，从而建立了一个共同的语言和协调框架。

**Result:** 珊瑚协议使得任何智能体都能参与复杂的协作工作流，确保智能体交互高效且值得信赖。它为新兴的“智能体互联网”奠定了基础，解锁了自动化、集体智能和商业价值的新水平。

**Conclusion:** 珊瑚协议通过其开放、去中心化和兼容性强的设计，成为“智能体互联网”的基石，能够实现前所未有的智能体协作，提升自动化和集体智能。

> **ai_Abstract:** 珊瑚协议是一个开放且去中心化的基础设施，旨在解决“智能体互联网”中多AI智能体之间的互操作性挑战。它通过提供标准化的通信格式、模块化的任务协调机制以及安全的团队组建功能，使不同智能体能够高效、可信地进行协作，从而推动自动化和集体智能的发展。

> **摘要翻译:** 珊瑚协议是一个开放且去中心化的协作基础设施，旨在为智能体互联网提供通信、协调、信任和支付功能。它解决了在组织部署多个必须跨领域和供应商协同工作的专业AI智能体日益增长的互操作性需求。作为多智能体AI生态系统的基础平台，珊瑚协议建立了一种通用语言和协调框架，允许任何智能体参与到复杂的协作工作流中。其设计强调广泛的兼容性、安全性和供应商中立性，确保智能体交互高效且值得信赖。特别是，珊瑚协议引入了用于智能体通信的标准化消息格式、用于编排多智能体任务的模块化协调机制，以及用于动态组建可信智能体群体的安全团队组建能力。这些创新共同将珊瑚协议定位为新兴“智能体互联网”的基石，通过开放的智能体协作，解锁了自动化、集体智能和商业价值的新水平。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [12] [Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour](https://arxiv.org/abs/2507.13277)
> *评估强化学习算法在模拟四足机器人导航中的应用：一项受导盲犬行为启发的比较研究*

*Emma M. A. Harrison* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 四足机器人, 导航, 导盲犬, 辅助机器人

**Comment:** 

> **TL;DR:** 本研究比较了PPO、DQN和Q-learning三种强化学习算法在模拟四足机器人导航和避障中的表现，发现PPO效果最佳，旨在开发机器人导盲犬。

**AI_Comments:** 这项研究的创新点在于将强化学习应用于模拟四足机器人导航，并明确提出了开发“机器人导盲犬”的愿景，这在辅助机器人领域具有重要的应用潜力。通过比较PPO、DQN和Q-learning三种主流算法，并明确指出PPO的优越性，为后续研究提供了有价值的指导。研究方法严谨，通过定制环境确保了评估的公平性。其贡献在于推动了AI在四足机器人导航和医疗辅助领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管四足机器人在医疗保健等行业有巨大潜力，但许多有价值的应用仍被忽视。本研究旨在开发一种模拟导盲犬机器人，使其能够自主导航和避障，以期未来能为导盲犬和视障人士提供实际帮助，并拓展医疗“宠物”机器人的研究。

**Method:** 研究通过比较分析13篇相关研究论文确定了碰撞检测、寻路算法、传感器使用、机器人类型和模拟平台等评估标准。在定制环境中，对PPO、DQN和Q-learning三种强化学习算法进行了比较评估，重点关注传感器输入、碰撞频率、奖励信号和学习进展。

**Result:** 结果显示，在所有指标上，尤其是每回合到达目标的平均和中位数步数方面，近端策略优化（PPO）的表现优于深度Q网络（DQN）和Q学习。

**Conclusion:** 本研究通过分析结果，为机器人导航、人工智能和医疗机器人领域做出了贡献，深入探讨了AI驱动的四足移动能力的可行性及其在辅助机器人中的作用。

> **ai_Abstract:** 本研究旨在解决四足机器人在医疗保健领域应用被忽视的问题，通过比较PPO、DQN和Q-learning三种强化学习算法在模拟四足机器人导航和避障中的表现，以期开发出能辅助导盲犬和视障人士的机器人。研究在定制环境中评估了这些算法，结果表明PPO在导航性能上显著优于DQN和Q-learning。这项工作为AI驱动的四足移动能力在辅助机器人领域的应用提供了可行性见解。

> **摘要翻译:** 机器人正越来越多地融入各行各业，特别是在医疗保健领域。然而，四足机器人的许多有价值的应用仍被忽视。本研究探讨了三种强化学习算法在训练模拟四足机器人进行自主导航和避障方面的有效性。目标是开发一种能够路径跟随和避障的机器人导盲犬模拟，具有为导盲犬和视障人士提供现实世界帮助的长期潜力。它还旨在将医疗“宠物”的研究扩展到包括机器人导盲犬和警报犬。
通过对十三篇相关研究论文的比较分析，形成了关键评估标准，包括碰撞检测、寻路算法、传感器使用、机器人类型和模拟平台。该研究侧重于传感器输入、碰撞频率、奖励信号和学习进展，以确定哪种算法最能支持复杂环境中的机器人导航。
使用定制环境以确保在受控条件下对所有三种算法进行公平评估，从而实现一致的数据收集。结果显示，近端策略优化（PPO）在所有指标上都优于深度Q网络（DQN）和Q学习，特别是在每回合到达目标的平均和中位数步数方面。
通过分析这些结果，本研究为机器人导航、人工智能和医疗机器人做出了贡献，提供了关于AI驱动的四足移动能力的可行性及其在辅助机器人中作用的见解。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [16] [ASC-SW: Atrous strip convolution network with sliding windows for visual-assisted map navigation](https://arxiv.org/abs/2507.12744)
> *ASC-SW：基于空洞条状卷积网络与滑动窗口的视觉辅助地图导航*

*Cheng Liu, Fan Zhu, Yaoyu Zhuang Zhinan Chen Jiefeng Tang* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 视觉辅助导航, 可变形线性物体, 空洞条状卷积, 滑动窗口, 边缘计算

**Comment:** 

> **TL;DR:** 提出ASC-SW框架，结合轻量级视觉网络和深度相机，解决传统LiDAR无法检测地面障碍物的问题，实现高精度、高效率的地面线性物体检测，用于机器人导航。

**AI_Comments:** 该论文的创新点在于提出了结合空洞条状卷积和滑动窗口的ASC-SW框架，专门用于检测地面线性障碍物，弥补了传统LiDAR的不足。其轻量级设计使其适用于边缘设备部署，这对于资源受限的移动机器人导航具有重要意义。性能验证表明其在准确性和速度之间取得了良好平衡。

<details>
  <summary>Details</summary>

**Motivation:** 传统LiDAR传感器无法检测地面障碍物（如地面线缆）；需要将轻量级视觉神经网络部署在资源受限的边缘计算设备上。

**Method:** 提出Atrous Strip Convolution-Sliding Window (ASC-SW) 视觉辅助导航框架，利用深度相机和轻量级视觉神经网络。核心是Atrous Strip Convolution Network (ASCnet) 分割模型用于检测可变形线性物体 (DLOs)。ASCnet以MobileNetV2为骨干网络，并设计了Atrous Strip Convolution Spatial Pyramid Pooling (ASCSPP) 以有效提取DLO特征。ASCSPP中集成了空洞条状卷积以低计算成本识别DLO的线性结构。此外，提出Sliding Window (SW) 后处理模块以在复杂环境中去噪并提高识别精度。

**Result:** 该方法在自建数据集上实现了75.3%的平均交并比 (Miou)；在Jetson Orin Nano边缘设备上达到9.3 FPS的推理速度；性能优于现有DLO检测模型；已在物理机器人平台上成功验证。

**Conclusion:** 所提出的ASC-SW方法在推理速度和分割性能之间取得了平衡，优于现有DLO检测模型，并成功应用于物理机器人平台，解决了传统LiDAR无法检测地面障碍物的问题。

> **ai_Abstract:** 本文提出了一种名为ASC-SW的视觉辅助导航框架，旨在解决传统LiDAR无法检测地面线性障碍物的问题。该框架结合深度相机和轻量级视觉神经网络，核心是ASCnet模型，以MobileNetV2为骨干，并利用ASCSPP和空洞条状卷积高效提取可变形线性物体(DLOs)特征。此外，引入滑动窗口(SW)模块进行后处理以提高精度。该方法在自建数据集上表现出75.3%的Miou和9.3 FPS的推理速度，并在物理机器人上成功验证，实现了推理速度与分割性能的平衡，优于现有DLO检测模型。

> **摘要翻译:** 随着轻量级视觉神经网络架构的快速发展，传统高性能视觉模型经过了显著压缩，极大地提高了它们的计算效率和能耗比。这使得它们能够在资源受限的边缘计算设备上部署。我们提出了一种名为空洞条状卷积-滑动窗口 (ASC-SW) 的视觉辅助导航框架，该框架利用深度相机和轻量级视觉神经网络来辅助基于地图的移动机器人导航。该框架弥补了传统光探测和测距 (LiDAR) 传感器无法检测地面障碍物（如地面线缆）的不足。我们引入了一种轻量级高效的分割模型——空洞条状卷积网络 (ASCnet)，用于检测可变形线性物体 (DLOs)。MobileNetV2 被用作骨干网络，并设计了空洞条状卷积空间金字塔池化 (ASCSPP) 以更有效地提取 DLO 特征。空洞条状卷积被集成到 ASCSPP 中，以低计算成本准确识别 DLO 的线性结构。此外，还提出了一种滑动窗口 (SW) 后处理模块，用于在复杂环境中去噪，提高识别精度。我们的方法在推理速度和分割性能之间取得了平衡。它在自建数据集上实现了 75.3% 的平均交并比 (Miou) 分数，并在 Jetson Orin Nano 边缘设备上达到了 9.3 FPS 的推理速度。总的来说，我们的方法优于现有的 DLO 检测模型，并已在物理机器人平台上成功验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [28] [GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial and Legged Odometry Fusion SLAM for Dynamic Legged Robotics](https://arxiv.org/abs/2503.14247)
> *GeoFlow-SLAM: 适用于动态足式机器人的鲁棒紧耦合RGBD-惯性与足式里程计融合SLAM*

*Tingyang Xiao, Xiaolin Zhou, Liu Liu, Wei Sui, Wei Feng, Jiaxiong Qiu, Xinjie Wang, Zhizhong Su* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-17**

**Keywords:** SLAM, 足式机器人, RGBD-惯性, 光流, 姿态估计

**Comment:** 8 pages

> **TL;DR:** GeoFlow-SLAM是一种鲁棒的紧耦合RGBD-惯性SLAM，通过集成几何一致性、足式里程计和双流光流，解决了足式机器人在快速运动和无纹理场景下的SLAM挑战。

**AI_Comments:** GeoFlow-SLAM的创新之处在于其多传感器融合策略，特别是在解决足式机器人在极端运动和视觉挑战性环境中的定位问题。它通过结合双流光流、足式里程计以及新颖的优化框架，显著提升了SLAM系统的鲁棒性和精度，对于动态足式机器人的自主导航具有重要意义。提供开源代码和数据集将进一步促进该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 解决足式机器人在剧烈高频运动中遇到的特征匹配和姿态初始化失败问题，以及在无纹理场景中视觉特征稀缺的问题。

**Method:** 整合几何一致性、足式里程计约束和双流光流（GeoFlow）。利用双流光流结合先验地图点和姿态来增强快速运动场景下的特征匹配。提出一种鲁棒的姿态初始化方法，整合IMU/足式里程计、帧间PnP和GICP。引入一种新的优化框架，紧密耦合深度到地图和GICP几何约束，以提高在长时间、视觉无纹理环境中的鲁棒性和精度。

**Result:** 所提出的算法在收集的足式机器人和开源数据集上实现了最先进的（SOTA）性能。

**Conclusion:** GeoFlow-SLAM通过其创新的融合方法，显著提高了足式机器人在挑战性动态环境中的SLAM鲁棒性和精度。

> **ai_Abstract:** GeoFlow-SLAM是一种为足式机器人设计的鲁棒紧耦合RGBD-惯性SLAM系统。它通过结合几何一致性、足式里程计和双流光流（GeoFlow），解决了快速运动下的特征匹配与姿态初始化失败以及无纹理环境中的视觉特征稀缺问题。该系统通过双流光流增强特征匹配，并提出了一种融合多种传感器的鲁棒姿态初始化方法。此外，引入了一个新的优化框架，紧密耦合深度到地图和GICP几何约束，以提升在复杂环境中的鲁棒性和精度。实验结果表明，GeoFlow-SLAM在足式机器人和开源数据集上达到了最先进的性能。

> **摘要翻译:** 本文介绍了GeoFlow-SLAM，一种鲁棒有效的紧耦合RGBD-惯性SLAM，适用于进行剧烈高频运动的足式机器人。通过集成几何一致性、足式里程计约束和双流光流（GeoFlow），我们的方法解决了三个关键挑战：快速运动期间的特征匹配和姿态初始化失败，以及无纹理场景中视觉特征稀缺的问题。具体而言，在快速运动场景中，通过利用结合先验地图点和姿态的双流光流，特征匹配得到了显著增强。此外，我们提出了一种针对足式机器人在快速运动和IMU误差情况下的鲁棒姿态初始化方法，该方法整合了IMU/足式里程计、帧间透视-n点（PnP）和广义迭代最近点（GICP）。此外，首次引入了一种新的优化框架，该框架紧密耦合了深度到地图和GICP几何约束，以提高在长时间、视觉无纹理环境中的鲁棒性和精度。所提出的算法在收集的足式机器人和开源数据集上实现了最先进的（SOTA）性能。为了进一步促进研究和开发，开源数据集和代码将公开提供在https://github.com/HorizonRobotics/geoflow-slam。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [36] [Refining Motion for Peak Performance: Identifying Optimal Gait Parameters for Energy-Efficient Quadrupedal Bounding](https://arxiv.org/abs/2507.12751)
> *优化运动以实现最佳性能：识别四足机器人跳跃步态的能量效率最佳参数*

*Yasser G. Alqaham, Jing Cheng, Zhenyu Gan* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 步态参数, 能量效率, 四足机器人, 跳跃步态, 运动控制

**Comment:** Published in the ACC 2025 Conference proceedings

> **TL;DR:** 本研究探讨了步态参数（占空比、相移、步幅持续时间）对四足机器人能量消耗的影响，并通过仿真和实验发现优化步态参数可显著提高能量效率。

**AI_Comments:** 这项工作具有重要的实际意义，因为它直接关注了四足机器人自主性的一个关键限制因素——能量效率。通过识别和优化步态参数，该研究提供了一种软件层面的解决方案，可以直接应用于现有商用平台，而非依赖于昂贵的硬件改造。其创新之处在于系统地探索了步态参数对能量消耗的影响，填补了现有研究的空白。

<details>
  <summary>Details</summary>

**Motivation:** 四足机器人的能量效率对其性能和自主性至关重要。虽然之前的研究多集中于机械设计和驱动改进，但步态参数对能量消耗的影响却较少被探索。

**Method:** 研究建模了Unitree A1四足机器人，并开发了一个可独立调整占空比、相移和步幅持续时间的运动控制器。在Gazebo中对跳跃步态进行了不同速度（低、中、高）下的步态参数范围仿真，并进行了实验测试以验证仿真结果。

**Result:** 研究结果表明，优化步态参数可以显著降低能量消耗，从而提高四足机器人运动的整体效率。

**Conclusion:** 这项工作有助于推动腿足机器人节能控制策略的发展，并为商用平台提供了直接适用的见解。

> **ai_Abstract:** 本研究旨在探索步态参数（占空比、相移、步幅持续时间）对四足机器人能量消耗的影响。通过对Unitree A1机器人进行建模并在Gazebo中进行跳跃步态仿真，同时辅以实验验证，研究发现优化这些步态参数能够显著降低能耗，从而提高机器人的整体运动效率。这项工作为开发更节能的腿足机器人控制策略提供了有价值的见解。

> **摘要翻译:** 能量效率是四足机器人性能和自主性的关键因素。尽管先前的研究主要集中在机械设计和驱动改进上，但步态参数对能量消耗的影响却鲜有探索。在本文中，我们假设步态参数，特别是占空比、相移和步幅持续时间，是四足机器人运动中能量消耗的关键决定因素。为了验证这一假设，我们对Unitree A1四足机器人进行了建模，并开发了一个能够独立调整这些步态参数的运动控制器。在Gazebo中对不同速度（低、中、高）下的一系列步态参数的跳跃步态进行了仿真。此外，还进行了实验测试以验证仿真结果。研究结果表明，优化步态参数可以显著降低能量消耗，从而提高四足机器人运动的整体效率。这项工作有助于推动腿足机器人节能控制策略的发展，并为商用平台提供了直接适用的见解。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [57] [Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](https://arxiv.org/abs/2507.13340)
> *基于具身无关预训练世界模型的潜在策略引导*

*Yiqi Wang, Mrinal Verghese, Jeff Schneider* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 潜在策略引导, 世界模型, 具身无关, 视觉运动策略, 数据效率

**Comment:** 

> **TL;DR:** 本文提出了一种利用具身无关的世界模型和潜在策略引导方法，以减少机器人视觉运动策略学习中的数据收集需求。

**AI_Comments:** 这项工作在机器人学习领域具有重要意义，它通过引入“具身无关”的世界模型和“潜在策略引导”的概念，有效解决了机器人数据收集成本高昂的挑战。其创新性在于能够利用异构数据（包括人类玩耍数据）进行预训练，并通过在世界模型潜在空间中搜索来优化策略，从而在少量真实机器人数据下实现显著的性能提升。这为未来更高效、更通用的机器人学习范式提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人领域，通过模仿学习视觉运动策略需要大量昂贵的数据收集。本文旨在通过利用来自不同具身（如公共机器人数据集和人类玩耍数据）的现有或成本效益高的数据，减少学习视觉运动机器人策略时的数据收集工作。

**Method:** 本研究利用两个关键见解：首先，使用光流作为具身无关的动作表示来训练跨多具身数据集的世界模型（WM），并在少量目标具身机器人数据上进行微调。其次，开发了一种名为“潜在策略引导”（LPS）的方法，通过在世界模型的潜在空间中搜索更好的动作序列来改进行为克隆策略的输出。

**Result:** 在真实世界实验中，结合在Open X-embodiment数据集或人类玩耍数据上预训练的世界模型，使用少量数据训练的策略性能显著提高（30次演示相对提高超过50%，50次演示相对提高超过20%）。

**Conclusion:** 通过利用具身无关的预训练世界模型和潜在策略引导方法，可以显著减少机器人视觉运动策略学习所需的数据量，并提高在数据受限情况下的策略性能。

> **ai_Abstract:** 本文提出了一种名为“潜在策略引导”（LPS）的新方法，旨在减少机器人视觉运动策略学习对大量真实世界数据的依赖。该方法利用具身无关的光流作为动作表示，训练一个跨多具身数据集的预训练世界模型（WM），并在目标机器人数据上进行微调。LPS通过在WM的潜在空间中搜索优化动作序列，显著提升了行为克隆策略的性能，尤其是在数据量有限的情况下，实现了超过50%的相对性能提升。

> **摘要翻译:** 通过模仿学习视觉运动策略已在广泛的机器人领域中证明是有效的。然而，这些策略的性能严重依赖于训练演示的数量，这需要昂贵的真实世界数据收集。在这项工作中，我们旨在通过利用来自各种具身（如公共机器人数据集和人类玩耍数据）的现有或成本效益高的数据，减少学习视觉运动机器人策略时的数据收集工作。我们的方法利用了两个关键见解。首先，我们使用光流作为具身无关的动作表示来训练跨多具身数据集的世界模型（WM），并在少量目标具身机器人数据上进行微调。其次，我们开发了一种名为潜在策略引导（LPS）的方法，通过在世界模型的潜在空间中搜索更好的动作序列来改进行为克隆策略的输出。在真实世界实验中，我们观察到通过将策略与在现有Open X-embodiment数据集中不同机器人或成本效益高的人类玩耍数据集中采样的两千个片段上预训练的WM结合，使用少量数据训练的策略性能显著提高（30次演示相对提高超过50%，50次演示相对提高超过20%）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [58] [Online Adaptation of Terrain-Aware Dynamics for Planning in Unstructured Environments](https://arxiv.org/abs/2506.04484)
> *非结构化环境中地形感知动力学在线适应规划*

*William Ward, Sarah Etter, Tyler Ingebrand, Christian Ellis, Adam J. Thorpe, Ufuk Topcu* | **Category: cs.RO** | **Updated: 2025-07-16**

**Keywords:** 在线适应, 地形感知, 机器人动力学, 函数编码器, 最小二乘

**Comment:** Accepted to RSS-ROAR 2025

> **TL;DR:** 本文提出了一种使用函数编码器在线适应机器人地形感知动力学模型的方法，以实现对未知地形的快速适应，提高导航和规划性能，减少碰撞。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需重新训练或微调即可在运行时快速适应未知地形的在线适应框架，特别是利用了神经网络基函数和简单的最小二乘计算来实现高效的动力学模型更新。其重要性体现在解决了自动移动机器人在非结构化、动态变化环境中可靠导航的关键挑战。该方法在实际应用中具有很高的潜力，尤其是在需要实时适应复杂地形的场景。

<details>
  <summary>Details</summary>

**Motivation:** 自动移动机器人在远程、非结构化环境中运行时，必须适应在操作过程中可能快速变化的新颖、不可预测的地形。在这种场景下，一个关键挑战在于估计机器人在变化地形上的动力学，以实现可靠、准确的导航和规划。

**Method:** 本文提出了一种新颖的、基于函数编码器的地形感知动力学建模和规划的在线适应方法。该方法通过学习一组能够涵盖机器人在不同地形上动力学的神经网络基函数，利用有限的在线数据在运行时高效地适应新地形，无需重新训练或微调。对新地形的快速在线适应通过简单的最小二乘计算实现。

**Result:** 该方法在Unity机器人模拟器中进行了地形适应演示，结果表明，由于学习模型的更高准确性，下游控制器具有更好的经验性能。与神经ODE基线相比，在拥挤环境中导航时，该方法导致与障碍物的碰撞更少。

**Conclusion:** 本文提出的在线适应方法能够有效提高机器人在未知和变化地形上的导航和规划能力，通过更准确的动力学模型显著减少碰撞，优于现有基线方法。

> **ai_Abstract:** 本文提出了一种新颖的在线适应方法，利用函数编码器实现机器人地形感知动力学建模与规划。该方法通过学习神经网络基函数，使机器人在无需重新训练或微调的情况下，能以最小二乘计算快速适应未知地形。在Unity模拟器中的实验表明，该方法提高了动力学模型的准确性，从而提升了下游控制器的性能，并显著减少了在复杂环境中的碰撞，优于神经ODE基线。

> **摘要翻译:** 自动移动机器人在远程、非结构化环境中运行时，必须适应在操作过程中可能快速变化的新颖、不可预测的地形。在这种情况下，一个关键挑战是如何估计机器人在变化地形上的动力学，以实现可靠、准确的导航和规划。我们提出了一种新颖的在线适应方法，用于使用函数编码器进行地形感知动力学建模和规划。我们的方法在运行时使用有限的在线数据，无需重新训练或微调即可高效适应新地形。通过学习一组涵盖机器人在不同地形上动力学的神经网络基函数，我们能够以简单的最小二乘计算实现对新的、未见地形和环境的快速在线适应。我们在基于Unity的机器人模拟器中展示了我们的地形适应方法，并表明由于学习模型的更高准确性，下游控制器具有更好的经验性能。与神经ODE基线相比，这导致在拥挤环境中导航时与障碍物的碰撞更少。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [61] [osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning](https://arxiv.org/abs/2507.12753)
> *osmAG-LLM：通过语义地图和大型语言模型推理实现零样本开放词汇对象导航*

*Fujing Xie, Sören Schwertfeger, Hermann Blum* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 零样本导航, 开放词汇, 语义地图, 大型语言模型, 对象导航

**Comment:** 

> **TL;DR:** osmAG-LLM通过结合语义地图和大型语言模型推理，实现了零样本开放词汇对象导航，尤其擅长处理动态或未映射对象。

**AI_Comments:** 该论文的创新点在于其突破了传统高精度地图的局限性，转而利用语义地图和大型语言模型的推理能力来应对对象动态性和未映射的挑战。这种方法对于现实世界中对象频繁移动或未知环境下的机器人导航具有重要意义，展现了LLM在机器人领域应用的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的开放词汇机器人建图方法虽然细节丰富，但高细节的对象地图会很快过时，因为对象经常移动。另一个基本问题是对象可能未被映射。

**Method:** 本文开发了一个对象目标导航的建图和导航系统，该系统从根本上考虑了查询对象可能已移动或根本未被映射的可能性。它不追求高保真度的建图细节，而是将地图的主要目的视为提供环境基础和上下文，并将其与大型语言模型的语义先验结合，以推理对象位置并部署主动的在线方法来导航到对象。

**Result:** 通过模拟和真实世界实验，该方法在静态对象上具有更高的检索成功率和更短的路径长度，并且在动态或未映射对象查询的情况下远远优于现有方法。

**Conclusion:** 该研究提出的osmAG-LLM系统通过结合语义地图和LLM推理，有效解决了开放词汇对象导航中对象移动或未映射的挑战，显著提升了在复杂动态环境下的导航性能。

> **ai_Abstract:** 本文提出了osmAG-LLM，一个零样本开放词汇对象导航系统，旨在解决现有方法中对象地图易过时和对象可能未被映射的问题。该系统通过结合语义地图提供环境上下文，并利用大型语言模型的语义先验进行对象位置推理，从而实现主动在线导航。实验证明，osmAG-LLM在静态对象导航中表现良好，并且在处理动态或未映射对象查询时显著优于现有方法。

> **摘要翻译:** 最近的开放词汇机器人建图方法通过预训练的视觉语言特征丰富了密集的几何地图，实现了高水平的细节，并指导机器人找到由开放词汇语言查询指定的对象。虽然此类方法的可扩展性问题已受到一些关注，但另一个基本问题是高细节对象地图很快就会过时，因为对象经常移动。在这项工作中，我们开发了一个用于对象目标导航的建图和导航系统，该系统从根本上考虑了查询对象可能已移动或根本未被映射的可能性。我们没有追求高保真度的建图细节，而是将地图的主要目的视为提供环境基础和上下文，并将其与大型语言模型的语义先验结合，以推理对象位置并部署主动的在线方法来导航到对象。通过模拟和真实世界实验，我们发现我们的方法在静态对象上倾向于以更短的路径长度获得更高的检索成功率，并且在动态或未映射对象查询的情况下远远优于现有方法。我们提供了代码和数据集：https://anonymous.4open.science/r/osmAG-LLM。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [86] [FFI-VTR: Lightweight and Robust Visual Teach and Repeat Navigation based on Feature Flow Indicator and Probabilistic Motion Planning](https://arxiv.org/abs/2507.12800)
> *FFI-VTR：基于特征流指示器和概率运动规划的轻量级鲁棒视觉示教复现导航*

*Jikai Wang, Yunqi Cheng, Zonghai Chen* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 视觉示教复现, 特征流, 概率运动规划, 机器人导航, 轻量级

**Comment:** 

> **TL;DR:** 提出一种基于特征流指示器和概率运动规划的轻量级鲁棒视觉示教复现导航方法FFI-VTR，无需精确局部化和密集重建。

**AI_Comments:** 该论文提出了一种创新的视觉示教复现导航方案，其亮点在于无需精确局部化和密集重建，通过引入特征流指示器和概率运动规划，有效提升了系统的轻量级和鲁棒性。这种方法对于资源受限的移动机器人应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉示教复现导航是移动机器人自主导航的便捷解决方案，但在任务环境中实现效率和鲁棒性之间的平衡仍然面临挑战。

**Method:** 首先，引入特征流（匹配特征之间的像素位置偏差），并开发其与机器人运动的定性映射。其次，示教阶段的地图表示为关键帧图，其中边缘上的特征流编码了相邻关键帧之间的相对运动。最后，将视觉复现导航建模为当前观测与地图关键帧之间的特征流最小化问题，并基于定性特征流-运动映射指示器开发概率运动规划以驱动机器人。

**Result:** 实验证明所提出的方法轻量级、鲁棒性强，并优于基线方法。

**Conclusion:** FFI-VTR是一种无需精确局部化和密集重建的轻量级鲁棒视觉示教复现导航方法，通过特征流最小化和概率运动规划实现。

> **ai_Abstract:** 本文提出了一种名为FFI-VTR的轻量级鲁棒视觉示教复现导航方法，旨在解决移动机器人自主导航中效率与鲁棒性的平衡问题。该方法避免了对精确定位和密集重建模块的依赖，通过引入特征流并建立其与机器人运动的定性映射，将示教地图表示为带有特征流编码相对运动的关键帧图。复现导航被建模为特征流最小化问题，并结合概率运动规划实现机器人导航。实验证明FFI-VTR具有轻量级、鲁棒性和优越性。

> **摘要翻译:** 尽管视觉示教复现导航是移动机器人自主导航的一种便捷解决方案，但在任务环境中实现效率和鲁棒性之间的平衡仍然面临挑战。在本文中，我们提出了一种新颖的视觉示教复现机器人自主导航方法，该方法不需要精确的定位和密集的重建模块，这使得我们的系统具有轻量级和鲁棒性的特点。首先，引入了特征流，并开发了特征流与机器人运动之间的定性映射，其中特征流定义为匹配特征之间的像素位置偏差。基于该映射模型，示教阶段输出的地图表示为关键帧图，其中边缘上的特征流编码了相邻关键帧之间的相对运动。其次，视觉复现导航本质上被建模为当前观测与地图关键帧之间的特征流最小化问题。为了在没有精确定位的情况下驱动机器人持续减少当前帧和地图关键帧之间的特征流，我们基于定性特征流-运动映射指示器开发了一种概率运动规划。使用我们的移动平台进行的广泛实验表明，我们提出的方法轻量级、鲁棒性强，并且优于基线方法。源代码已在https://github.com/wangjks/FFI-VTR 公开，以造福社区。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [88] [Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model](https://arxiv.org/abs/2507.06174)
> *基于精确动力学模型的无力传感器力控制快速双边遥操作与模仿学习*

*Koki Yamane, Yunhan Li, Masashi Konosu, Koki Inami, Junji Oaki, Sho Sakaino, Toshiaki Tsuji* | **Category: cs.RO, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 双边遥操作, 模仿学习, 无力传感器, 动力学模型, 力反馈

**Comment:** 20 pages, 9 figures, Submitted to CoRL 2025

> **TL;DR:** 本文提出了一种使用无力传感器的低成本机械臂进行快速双边遥操作的方法，并通过精确的动力学模型和四通道双边控制实现了力反馈，同时证明了将力信息纳入模仿学习策略可以提高性能。

**AI_Comments:** 本文的创新点在于，它解决了低成本、无力传感器机械臂在进行需要力反馈的快速或接触任务时所面临的挑战。通过利用精确的动力学模型和4通道双边控制，该研究有效地弥补了硬件上的不足，实现了高保真遥操作。此外，将力信息融入模仿学习策略，进一步提升了模仿学习的性能，这对于机器人学习领域的数据收集和应用具有重要意义。该工作展示了在资源受限的情况下，通过智能控制策略实现复杂任务的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的遥操作系统大多采用单边控制，仅传输目标位置，难以应对快速或接触丰富的任务，因为缺乏力反馈。即使是无力传感器的低成本机械臂也需要实现带力反馈的快速遥操作。

**Method:** 本研究通过利用4通道双边控制，即使对于无力传感器的低成本机械臂，也实现了带力反馈的快速遥操作。该方法基于精确识别的机械臂动力学，集成了非线性项补偿、速度和外部力估计以及对应惯量变化的变增益。此外，利用4通道双边控制收集的数据，将力信息纳入学习策略的输入和输出，以提高模仿学习的性能。

**Result:** 研究结果表明，即使是无力传感器的低成本机械臂，通过4通道双边控制也能实现带力反馈的快速遥操作。将力信息纳入模仿学习策略的输入和输出，可以提高模仿学习的性能。

**Conclusion:** 本系统在经济实惠的硬件上实现了高保真遥操作和数据收集，具有实际有效性。

> **ai_Abstract:** 本文提出了一种针对无力传感器低成本机械臂的快速双边遥操作方法，以解决现有单边控制在接触任务中的不足。通过精确识别机械臂动力学，该方法整合了非线性补偿、速度与外部力估计以及变增益，实现了4通道双边控制下的力反馈。实验证明，该系统能够实现高保真遥操作，并且将力信息融入模仿学习策略的输入输出能有效提升学习性能，凸显了其在经济硬件上进行数据收集的实用价值。

> **摘要翻译:** 近年来，模仿学习的进步使得人们对遥操作低成本机械臂以收集示范数据产生了越来越大的兴趣。然而，大多数现有系统依赖于单边控制，仅传输目标位置值。虽然这种方法易于实现且适用于缓慢、非接触的任务，但由于缺乏力反馈，它在快速或接触丰富的操作中表现不佳。这项工作表明，即使是无力传感器、低成本的机械臂，通过利用4通道双边控制，也可以实现带力反馈的快速遥操作。基于精确识别的机械臂动力学，我们的方法集成了非线性项补偿、速度和外部力估计以及对应惯量变化的变增益。此外，利用通过4通道双边控制收集的数据，我们表明将力信息纳入学习策略的输入和输出可以提高模仿学习的性能。这些结果突出了我们的系统在高保真遥操作和经济硬件上数据收集的实际有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [116] [Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering](https://arxiv.org/abs/2507.12846)
> *进入思维宫殿：用于长期主动具身问答的推理与规划*

*Muhammad Fadhil Ginting, Dong-Ki Kim, Xiangyun Meng, Andrzej Reinke, Bandi Jai Krishna, Navid Kayhani, Oriana Peltzer, David D. Fan, Amirreza Shaban, Sung-Kyun Kim, Mykel J. Kochenderfer, Ali-akbar Agha-mohammadi, Shayegan Omidshafiei* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 长期主动具身问答, 结构化记忆, 思维宫殿, 机器人推理, 探索-回忆权衡

**Comment:** 

> **TL;DR:** 本文提出长期主动具身问答（LA-EQA）这一新任务，使机器人能够通过结合记忆和主动探索来回答长期复杂问题。受“思维宫殿”启发，研究者提出一种结构化记忆系统，在答案准确性和探索效率上显著优于现有基线。

**AI_Comments:** “思维宫殿”的灵感是创新的，为机器人的长期运行提供了持久记忆和推理的新颖方法。引入LA-EQA作为一个新任务，凸显了当前具身AI研究的一个重要空白，推动了更实用、更有能力的机器人系统发展。基于信息价值的停止标准也是一个提高效率的实用补充。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器人运行时间延长，它们需要积累并利用环境知识。传统具身问答（EQA）方法在长期任务中存在局限性，如上下文窗口有限、缺乏持久记忆以及无法结合记忆回忆与主动探索。因此，需要解决长期主动具身问答（LA-EQA）这一新任务。

**Method:** 提出了一种受认知科学中“思维宫殿”方法启发的结构化记忆系统。该系统将情景经验编码为基于场景图的世界实例，形成推理和规划算法，以实现有针对性的记忆检索和引导式导航。为平衡探索-回忆的权衡，引入了基于信息价值的停止标准，以确定代理何时收集了足够的信息。

**Result:** 该方法在真实世界实验中进行了评估，并引入了一个涵盖流行模拟环境和实际工业场所的新基准。结果显示，该方法显著优于最先进的基线，在答案准确性和探索效率方面都取得了实质性提升。

**Conclusion:** 所提出的受“思维宫殿”启发的结构化记忆系统有效地解决了长期主动具身问答（LA-EQA）的挑战，使机器人能够对过去、现在和未来的状态进行推理，从而显著提高了长期具身问答的性能。

> **ai_Abstract:** 本文引入了长期主动具身问答（LA-EQA），这是一项新任务，旨在使机器人能够在长时间内通过整合过往经验和主动环境探索来回答复杂问题。为解决传统EQA方法的局限性，作者提出了一种受“思维宫殿”启发的结构化记忆系统，该系统将情景经验编码为基于场景图的世界实例。此系统有助于有针对性的记忆检索、引导式导航，并采用基于信息价值的停止标准。在真实世界实验和新基准上的评估表明，与现有最先进的基线相比，该方法在答案准确性和探索效率方面均有显著提升。

> **摘要翻译:** 随着机器人变得越来越能够在更长时间（跨越数天、数周乃至数月）内运行，它们有望积累环境知识并利用这些经验更有效地协助人类。本文研究了长期主动具身问答（LA-EQA）问题，这是一项新任务，其中机器人必须回忆过去的经验并主动探索其环境，以回答复杂的、基于时间的问题。与传统EQA设置不同，后者通常只关注理解当前环境或回忆单一的过去观察，LA-EQA挑战代理对过去、现在和可能的未来状态进行推理，决定何时探索、何时查阅记忆以及何时停止收集观察并提供最终答案。基于大型模型的标准EQA方法在这种设置下表现不佳，原因在于有限的上下文窗口、缺乏持久记忆以及无法将记忆回忆与主动探索相结合。为了解决这个问题，我们提出了一种受认知科学中“思维宫殿”方法启发的机器人结构化记忆系统。我们的方法将情景经验编码为基于场景图的世界实例，形成了一种推理和规划算法，从而实现有针对性的记忆检索和引导式导航。为了平衡探索-回忆的权衡，我们引入了基于信息价值的停止标准，该标准确定代理何时收集了足够的信息。我们通过真实世界实验评估了我们的方法，并引入了一个涵盖流行模拟环境和实际工业场所的新基准。我们的方法显著优于最先进的基线，在答案准确性和探索效率方面都取得了实质性提升。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [118] [TOP: Trajectory Optimization via Parallel Optimization towards Constant Time Complexity](https://arxiv.org/abs/2507.10290)
> *TOP：基于并行优化实现常数时间复杂度的轨迹优化*

*Jiajun Yu, Nanhe Chen, Guodong Liu, Chao Xu, Fei Gao, Yanjun Cao* | **Category: cs.RO** | **Updated: 2025-07-16**

**Keywords:** 轨迹优化, 并行优化, CADMM, 常数时间复杂度, 大规模轨迹

**Comment:** 8 pages, submitted to RA-L

> **TL;DR:** 本文提出了一种基于CADMM算法的轨迹优化框架，通过将轨迹分解为多个段并并行求解子问题，将时间复杂度降低到O(1)，并在大规模轨迹优化中实现了显著的加速。

**AI_Comments:** 该论文的创新点在于将CADMM算法应用于轨迹优化，并通过分解和并行求解实现了常数时间复杂度，这在大规模轨迹优化中具有重要意义。引入闭式解和GPU部署进一步提升了其实用性和性能。该方法有效地解决了现有方法在处理长轨迹时的效率瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 现有的轨迹优化方法在处理大规模长轨迹时表现出弱点，尽管并行计算在某些领域加速了优化，但如何有效并行解决轨迹优化仍然是一个开放问题。

**Method:** 提出了一种基于共识交替方向乘子法（CADMM）的轨迹优化框架，将轨迹分解为多个段并并行求解子问题。引入了集成凸线性及二次约束的闭式解以加速优化，并提出了通用不等式约束的数值解。该框架部署在GPU上以充分利用并行计算架构的潜力。

**Result:** 所提出的框架将时间复杂度降低到O(1)（相对于段数），而现有最先进方法为O(N)。在模拟和实验中，该方法在效率和平滑度方面优于最先进方法。对于包含一百个段的大规模轨迹，实现了超过十倍的加速。在GPU上处理数千个段时，也显示出高性能。

**Conclusion:** 本文提出的基于CADMM的并行轨迹优化框架，通过分解和并行求解，显著提高了大规模轨迹优化的效率，实现了常数时间复杂度，并在实验中证明了其优越性。

> **ai_Abstract:** 本文提出了一种名为TOP的轨迹优化框架，该框架基于CADMM算法，通过将轨迹分解为多个子段并并行求解，将每迭代时间复杂度从O(N)降低至O(1)。该方法还引入了闭式解和数值解来处理不同类型的约束。仿真和实验结果表明，TOP在处理大规模轨迹时，相比现有最先进方法，在效率和轨迹平滑度上具有显著优势，尤其在大规模轨迹上实现了超过十倍的加速，并在GPU上展现出处理数千个段的高性能。

> **摘要翻译:** 优化已被广泛用于生成运动规划的平滑轨迹。然而，现有的轨迹优化方法在处理大规模长轨迹时表现出弱点。并行计算的最新进展在某些领域加速了优化，但如何通过并行化有效解决轨迹优化仍然是一个悬而未决的问题。在本文中，我们提出了一种基于共识交替方向乘子法（CADMM）算法的新型轨迹优化框架，该框架将轨迹分解为多个段并并行求解子问题。所提出的框架将每次迭代的时间复杂度降低到O(1)（相对于段数），而现有最先进（SOTA）方法的复杂度为O(N)。此外，我们引入了一种集成了凸线性及二次约束的闭式解以加速优化，并且我们还提出了通用不等式约束的数值解。一系列仿真和实验表明，我们的方法在效率和平滑度方面优于SOTA方法。特别是对于包含一百个段的大规模轨迹，实现了超过十倍的加速。为了充分挖掘我们算法在现代并行计算架构上的潜力，我们将我们的框架部署在GPU上，并展示了处理数千个段时的高性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [153] [Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm](https://arxiv.org/abs/2507.11133)
> *基于力的粘弹性和弹性测量，用于协作机械臂的材料生物力学表征*

*Luca Beber, Edoardo Lamon, Giacomo Moretti, Matteo Saveriano, Luca Fambri, Luigi Palopoli, Daniele Fontanelli* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 机器人系统, 粘弹性测量, 生物力学表征, 触诊, 超声波

**Comment:** 

> **TL;DR:** 本文评估了一个机器人系统在测量材料（包括离体组织）粘弹性参数方面的准确性和精确度，结果显示其准确性与基准值非常接近，这增加了机器人用于临床应用的信心。

**AI_Comments:** 本文的创新之处在于利用协作机械臂进行材料的生物力学表征，特别是针对粘弹性和弹性测量。其重要性在于提出了一种潜在的解决方案，以提高超声波扫描和触诊等诊断活动的客观性和效率，减少对高技能医务人员的依赖。通过初步在离体组织上进行概念验证，展示了该方法应用于生物样本的可行性，为机器人辅助诊断技术的发展奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 超声波扫描和触诊等诊断活动成本相对较低，对早期发现健康问题和评估其进展至关重要。然而，这些活动容易出错，且需要高技能的医务人员。使用机器人解决方案可以降低结果的固有主观性并缩短等待时间。为了让机器人执行触诊或超声波扫描，它必须有效管理与人体的物理交互，这极大地受益于对患者组织生物力学特性的精确估计。

**Method:** 本文评估了一个机器人系统在估计各种材料（包括离体组织）粘弹性参数方面的准确性和精确度，作为该方法适用于生物样本的初步概念验证。测量结果与通过高精度仪器表征的具有不同粘弹性特性的硅胶样本的基准值进行比较。

**Result:** 实验结果表明，机器人系统的准确性与基准值非常接近。

**Conclusion:** 该研究结果增加了对机器人用于此类临床应用（如触诊和超声波扫描）的潜在用途的信心。

> **ai_Abstract:** 本研究评估了一个基于协作机械臂的机器人系统，用于测量材料（包括离体组织）的粘弹性和弹性特性。通过与高精度仪器表征的硅胶样本基准值进行比较，实验结果证明该机器人系统在生物力学表征方面的准确性高，有望减少诊断活动的主观性并提高效率，从而促进机器人技术在临床诊断中的应用。

> **摘要翻译:** 诊断活动，如超声波扫描和触诊，成本相对较低。它们在健康问题的早期发现和评估其进展方面发挥着关键作用。然而，它们也是容易出错的活动，需要高技能的医务人员。使用机器人解决方案可以成为降低结果固有主观性并缩短等待时间的关键。为了让机器人执行触诊或超声波扫描，它必须有效管理与人体的物理交互，这极大地受益于对患者组织生物力学特性的精确估计。本文评估了一个机器人系统在估计各种材料粘弹性参数方面的准确性和精确度，包括对离体组织进行的一些测试，作为该方法适用于生物样本的初步概念验证演示。测量结果与通过高精度仪器表征的具有不同粘弹性特性的硅胶样本的基准值进行比较。实验结果表明，机器人系统的准确性与基准值非常接近，增加了机器人用于此类临床应用的潜在用途的信心。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [157] [DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning](https://arxiv.org/abs/2507.12855)
> *DEMONSTRATE：通过多任务示范学习实现零样本语言到机器人控制*

*Rahel Rickenbach, Bruce Lee, René Zurbrügg, Carmen Amo Alonso, Melanie N. Zeilinger* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 机器人控制, 零样本学习, 多任务学习, 逆最优控制

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）应用于机器人控制时，存在需要专家设计复杂上下文示例和难以评估幻觉的问题。DEMONSTRATE提出了一种新颖的方法，通过逆最优控制和多任务学习，利用任务演示取代了LLM的上下文提示，从而减少了对工程专业知识的依赖，并能在任务执行前评估幻觉。

**AI_Comments:** 本文的创新点在于提出了一种实用的方法，通过利用易于收集的机器人任务演示，取代了LLM在机器人控制中对复杂人工设计提示的依赖。结合多任务学习，该方法不仅解决了示例相似性问题，还首次提出了在任务执行前评估LLM潜在“幻觉”的机制，这对于提高机器人系统的安全性和可靠性至关重要。DEMONSTRATE显著降低了LLM应用于实际机器人控制的门槛，具有重要的工程实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在机器人控制中进行上下文学习时，强烈依赖于由训练有素的工程师设计的、包含明确数学表达式的任务示例。此外，在任务执行之前，通常没有原则性的方法来评估LLMs可能产生的“幻觉”。

**Method:** 本文提出了DEMONSTRATE方法，该方法避免使用LLMs生成复杂的优化问题，而是仅依赖于任务描述的嵌入表示。它利用逆最优控制工具，用任务演示来替换LLMs的上下文提示示例，并结合多任务学习概念，确保目标任务和示例任务在构建上相似。该方法通过远程操作或机器人引导轻松收集硬件演示。

**Result:** DEMONSTRATE方法显著减少了设计上下文示例对工程专业知识的依赖。强制的多任务结构使得能够从少量演示中学习，并能够在任务执行前评估幻觉。该方法通过仿真和硬件实验（涉及机械臂桌面操作任务）证明了其有效性。

**Conclusion:** DEMONSTRATE提供了一种将语言模型与机器人控制相结合的新颖且更实用的方法，通过利用演示和多任务学习，有效降低了工程开销并提高了系统的可靠性。

> **ai_Abstract:** DEMONSTRATE是一种新颖的方法，旨在解决大型语言模型（LLMs）应用于机器人控制时对专家设计上下文示例的强依赖性以及幻觉评估的挑战。该方法通过利用逆最优控制和多任务学习，用易于收集的任务演示取代了传统的复杂上下文提示，并仅依赖于任务描述的嵌入表示。这显著降低了对专业工程知识的需求，并能实现任务执行前的幻觉评估。通过仿真和硬件实验，该方法在零样本语言到机器人控制方面展现了有效性。

> **摘要翻译:** 大型语言模型（LLMs）与控制系统的结合在各种场景中都展现出巨大潜力，例如使用机械臂完成任务。这种成功的一个主要原因是LLMs进行上下文学习的能力，然而，这强烈依赖于与目标任务密切相关的任务示例的设计。因此，使用LLMs来制定最优控制问题通常需要包含明确数学表达式的任务示例，这些示例由训练有素的工程师设计。此外，在任务执行之前，通常没有原则性的方法来评估幻觉。为了解决这些挑战，我们提出了DEMONSTRATE，这是一种新颖的方法，它避免使用LLMs生成复杂的优化问题，而是仅依赖于任务描述的嵌入表示。为此，我们利用逆最优控制工具来用任务演示替换上下文提示示例，并利用多任务学习的概念，这通过构建确保了目标任务和示例任务的相似性。鉴于硬件演示可以通过远程操作或机器人引导轻松收集，我们的方法显著减少了对工程师专业知识设计上下文示例的依赖。此外，强制的多任务结构使得能够从少量演示中学习，并在任务执行前评估幻觉。我们通过涉及桌面操作的机械臂任务的仿真和硬件实验证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [195] [A Roadmap for Climate-Relevant Robotics Research](https://arxiv.org/abs/2507.11623)
> *气候相关机器人研究路线图*

*Alan Papalia, Charles Dawson, Laurentiu L. Anton, Norhan Magdy Bayomi, Bianca Champenois, Jung-Hoon Cho, Levi Cai, Joseph DelPreto, Kristen Edwards, Bilha-Catherine Githinji, Cameron Hickert, Vindula Jayawardana, Matthew Kramer, Shreyaa Raghavan, David Russell, Shide Salimi, Jingnan Shi, Soumya Sudhakar, Yanwei Wang, Shouyi Wang, Luca Carlone, Vijay Kumar, Daniela Rus, John E. Fernandez, Cathy Wu, George Kantor, Derek Young, Hanumant Singh* | **Category: cs.RO, cs.AI, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 气候变化, 机器人学, 研究路线图, 环境监测, 精准农业

**Comment:** 

> **TL;DR:** 该论文提出了一个气候相关机器人研究路线图，旨在促进机器人技术在应对气候变化中的应用和合作。

**AI_Comments:** 这篇论文的创新之处在于系统地构建了机器人技术与气候变化应对之间的桥梁，提供了一个清晰的、可操作的研究方向指引。其重要性在于能够激发多学科合作，将前沿的机器人技术应用于解决全球最紧迫的环境问题，具有巨大的潜在社会影响。

<details>
  <summary>Details</summary>

**Motivation:** 气候变化是21世纪面临的重大挑战之一，机器人社区正在寻求贡献方式。本论文旨在为机器人专家和气候领域专家之间的合作提供高影响力机会。

**Method:** 本文通过识别机器人技术（包括物理机器人和更广泛的机器人工具包，如规划、感知、控制和估计算法）在能源、建筑环境、交通、工业、土地利用和地球科学等气候领域中的高影响力应用机会，提出了气候相关机器人研究路线图。

**Result:** 论文识别了能源系统优化、建筑、精准农业、建筑围护结构改造、自动驾驶卡车和大规模环境监测等具体应用问题，展示了机器人技术在气候相关问题上的应用潜力。

**Conclusion:** 本路线图旨在通过突出机器人技术与气候交叉领域的具体可操作问题，激发新的研究方向和合作，并邀请机器人社区将其专业知识应用于紧迫的气候优先事项。

> **ai_Abstract:** 本文提出了一个气候相关机器人研究的路线图，旨在连接机器人技术与气候变化应对。通过识别能源、建筑、交通等气候领域中机器人（包括物理机器人和算法工具）的高影响力应用机会，如能源优化、精准农业和环境监测，该路线图旨在激发新的研究方向和跨学科合作，鼓励机器人社区将专业知识应用于紧迫的气候挑战。

> **摘要翻译:** 气候变化是21世纪面临的决定性挑战之一，机器人社区的许多人正在寻找贡献方式。本文提出了气候相关机器人研究的路线图，确定了机器人专家与能源、建筑环境、交通、工业、土地利用和地球科学等气候领域专家之间合作的高影响力机会。这些应用包括能源系统优化、建筑、精准农业、建筑围护结构改造、自动驾驶卡车和大规模环境监测等问题。至关重要的是，我们不仅包括应用物理机器人的机会，还包括将更广泛的机器人工具包——包括规划、感知、控制和估计算法——应用于气候相关问题的机会。本路线图的一个核心目标是通过突出机器人技术和气候交叉领域的具体、可操作的问题，激发新的研究方向和合作。这项工作代表了机器人研究人员和各个气候学科领域专家之间的合作，它邀请机器人社区将其专业知识应用于紧迫的气候优先事项。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [199] [LaViPlan : Language-Guided Visual Path Planning with RLVR](https://arxiv.org/abs/2507.12911)
> *LaViPlan：基于语言引导和RLVR的视觉路径规划*

*Hayeon Oh* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 自动驾驶, 视觉-语言模型, 路径规划, 强化学习, 分布外场景

**Comment:** 11 pages, 6 figures

> **TL;DR:** LaViPlan通过RLVR优化VLM在自动驾驶OOD场景下的决策，解决视觉-语言-动作不匹配问题，提高态势感知和决策能力。

**AI_Comments:** LaViPlan通过引入RLVR机制，创新性地解决了VLM在自动驾驶领域中高层语言理解与低层动作执行之间的关键错位问题，这对于提升VLM在复杂OOD场景下的实际应用能力具有重要意义。该工作提出的后训练范式为未来VLM在自动驾驶中的部署提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中，视觉-语言模型（VLM）在高层语言决策与低层轨迹动作之间存在不匹配，导致其在识别驾驶场景时常产生缺乏上下文感知的决策，尤其是在分布外（OOD）场景下。

**Method:** 本文提出了LaViPlan框架，该框架利用带有可验证奖励的强化学习（RLVR）来优化视觉-语言模型（VLM），并使用面向规划的指标，旨在解决现有VLM中存在的视觉-语言-动作错位问题。

**Result:** 实验结果表明，LaViPlan方法提高了模型在分布外（OOD）条件下的态势感知和决策能力，并有效缓解了视觉-语言-动作不匹配问题。

**Conclusion:** LaViPlan为自动驾驶领域中的视觉-语言模型代理引入了一种有前景的后训练范式，有效解决了高层语言决策与低层动作轨迹之间的错位问题。

> **ai_Abstract:** 本文提出了LaViPlan框架，旨在解决自动驾驶领域中视觉-语言模型（VLM）高层语言决策与低层动作轨迹之间的错位问题。该框架通过结合带有可验证奖励的强化学习（RLVR）来优化VLM，并使用面向规划的指标。实验证明，LaViPlan能够提高模型在分布外（OOD）场景下的态势感知和决策能力，为VLM代理的后训练提供了一个有前景的新范式。

> **摘要翻译:** 自动驾驶中的分布外（OOD）场景是指偏离训练领域的情况，这通常会导致缺乏此类情况先验经验的规划器产生意外且可能危险的行为。最近，视觉-语言模型（VLM）因其在OOD设置中具有良好的泛化能力而被引入自动驾驶研究。早期研究表明，VLM可以识别OOD场景并生成用户级决策，例如“直行”或“右转”。然而，由于VLM的高层决策或以语言表达的视觉推理与解释为动作的低层预测轨迹之间存在错位，出现了一个新的挑战。在本文中，我们提出了LaViPlan，一个利用带有可验证奖励的强化学习（RLVR）来优化VLM的框架，该框架使用面向规划的指标。这种方法解决了现有通过监督学习微调的VLM中观察到的视觉-语言-动作错位问题，这些VLM虽然可以识别驾驶场景，但往往会产生缺乏上下文感知的决策。实验结果表明，我们的方法提高了OOD条件下的态势感知和决策能力，突出了其缓解错位问题的潜力。这项工作为自动驾驶中的VLM代理引入了一种有前景的后训练范式。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [237] [Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](https://arxiv.org/abs/2507.12273)
> *下一代博物馆导览：具有代理能力的机器人的自主导航和访客互动*

*Luca Garello, Francesca Cocchella, Alessandra Sciutti, Manuel Catalano, Francesco Rea* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 博物馆导览, 自主导航, 访客互动, 大型语言模型, SLAM

**Comment:** 

> **TL;DR:** 本文介绍并评估了一个名为Alter-Ego的自主博物馆导览机器人，该机器人结合了LLM驱动的实时问答和SLAM技术进行导航，旨在提升访客体验。在真实博物馆环境中的测试表明，机器人普遍受到欢迎，但仍存在理解和响应方面的局限性。

**AI_Comments:** 这项研究创新性地将大型语言模型（LLMs）和SLAM技术应用于博物馆导览机器人，为提升公共文化空间的访客体验提供了新思路。其重要性在于通过真实环境测试，不仅验证了AI机器人的应用潜力，也诚实地指出了当前技术在理解和响应方面的局限性，这对于未来人机交互和机器人部署的研究具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在公共空间，特别是在文化和教育环境中，测试自主机器人以增强用户体验的需求日益增长。本文旨在设计、实现和评估一个能够自主导航并与访客互动的博物馆导览机器人。

**Method:** 本文设计、实现并评估了一个名为Alter-Ego的自主博物馆导览机器人。该机器人配备了先进的导航和交互能力，利用大型语言模型（LLMs）提供实时、上下文感知的问答互动，并采用鲁棒的同步定位与建图（SLAM）技术实现无缝导航和路径适应。系统在真实博物馆环境中对34名参与者进行了测试，结合了访客-机器人对话的定性分析和互动前后调查的定量分析。

**Result:** 测试结果显示，该机器人普遍受到好评，并有助于提供引人入胜的博物馆体验。尽管在理解和响应方面存在一些局限性，但研究表明了AI驱动机器人支持可访问性和知识获取的潜力。

**Conclusion:** 这项研究揭示了文化空间中人机交互的潜力，突出了AI驱动机器人支持可访问性和知识获取的潜力，同时也指出了在复杂、真实环境中部署此类技术当前的局限性和挑战。

> **ai_Abstract:** 本文介绍了名为Alter-Ego的下一代自主博物馆导览机器人，该机器人结合了LLM驱动的实时问答互动和SLAM导航技术。研究在真实博物馆环境中对34名参与者进行了测试，结果表明机器人普遍受到好评并提升了访客体验，但也揭示了当前AI驱动机器人在理解和响应方面的局限性以及在复杂真实环境中部署的挑战。这项工作强调了AI机器人促进文化空间可访问性和知识获取的潜力。

> **摘要翻译:** 自主机器人在公共空间中越来越多地被测试，以增强用户体验，特别是在文化和教育环境中。本文介绍了自主博物馆导览机器人Alter-Ego的设计、实现和评估，该机器人配备了先进的导航和交互能力。该机器人利用最先进的大型语言模型（LLMs）提供实时、上下文感知的问答（Q&A）互动，允许访客就展品进行对话。它还采用了鲁棒的同步定位与建图（SLAM）技术，使得机器人能够在博物馆空间中无缝导航，并根据用户请求调整路线。该系统在真实博物馆环境中对34名参与者进行了测试，结合了访客-机器人对话的定性分析和互动前后调查的定量分析。结果显示，该机器人普遍受到欢迎，并有助于提供引人入胜的博物馆体验，尽管在理解和响应方面存在一些局限性。这项研究揭示了文化空间中人机交互的潜力，不仅突出了AI驱动机器人支持可访问性和知识获取的潜力，而且也指出了在复杂、真实环境中部署此类技术当前的局限性和挑战。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [241] [MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion](https://arxiv.org/abs/2507.12920)
> *MoCap2GT: 基于运动捕捉和IMU融合的SLAM基准测试高精度真值估计器*

*Zichao Shu, Shitao Bei, Jicheng Dai, Lijun Li, Zetao Chen* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** SLAM, 运动捕捉, IMU融合, 真值估计, 轨迹

**Comment:** 

> **TL;DR:** 提出MoCap2GT，一种结合运动捕捉和IMU数据的高精度真值估计器，用于改进SLAM基准测试。

**AI_Comments:** 该论文通过融合MoCap和IMU数据，并引入创新的优化技术（如高阶B样条和退化感知策略），有效解决了现有MoCap真值在SLAM基准测试中的精度限制，特别是对旋转和帧间误差的评估。其重要性在于为SLAM算法的更全面和精确评估提供了基础，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于运动捕捉的SLAM真值轨迹存在时空校准误差和固有抖动，导致旋转和帧间误差难以准确评估，阻碍了彻底的SLAM评估。

**Method:** MoCap2GT是一种联合优化方法，整合了运动捕捉数据和IMU测量值。它包括一个鲁棒的状态初始化器以确保全局收敛，引入了在SE(3)流形上具有可变时间偏移的高阶B样条位姿参数化以有效建模MoCap因素，并采用了退化感知测量拒绝策略以提高估计精度。

**Result:** 实验结果表明，MoCap2GT优于现有方法，并显著有助于精确的SLAM基准测试。

**Conclusion:** MoCap2GT通过融合运动捕捉和IMU数据，显著提高了SLAM基准测试中真值轨迹的精度，从而能够进行更彻底的SLAM评估。

> **ai_Abstract:** 本文提出了MoCap2GT，一种高精度真值估计器，用于解决现有运动捕捉系统在SLAM基准测试中存在的时空校准误差和抖动问题。MoCap2GT通过联合优化运动捕捉数据和IMU测量值来生成更精确的真值轨迹。该方法引入了鲁棒的状态初始化器、高阶B样条位姿参数化和退化感知测量拒绝策略。实验证明，MoCap2GT在SLAM基准测试中表现优于现有方法，显著提高了真值精度，有助于更彻底的SLAM评估。

> **摘要翻译:** 基于标记的光学运动捕捉 (MoCap) 系统被广泛用于为 SLAM 算法的基准测试提供真值 (GT) 轨迹。然而，基于 MoCap 的 GT 轨迹的精度主要受两个因素影响：MoCap 系统与被测设备 (DUT) 之间的时空校准误差，以及固有的 MoCap 抖动。因此，现有基准测试主要关注绝对平移误差，因为准确评估旋转和帧间误差仍然具有挑战性，阻碍了彻底的 SLAM 评估。本文提出了 MoCap2GT，一种联合优化方法，它整合了 MoCap 数据和来自 DUT 的惯性测量单元 (IMU) 测量值，以生成高精度 GT 轨迹。MoCap2GT 包含一个鲁棒的状态初始化器以确保全局收敛，引入了在 SE(3) 流形上具有可变时间偏移的高阶 B 样条位姿参数化以有效建模 MoCap 因素，并采用了退化感知测量拒绝策略以提高估计精度。实验结果表明，MoCap2GT 优于现有方法，并显著有助于精确的 SLAM 基准测试。源代码可在 https://anonymous.4open.science/r/mocap2gt 获取（为双盲评审暂时匿名托管）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [270] [Physically Based Neural LiDAR Resimulation](https://arxiv.org/abs/2507.12489)
> *基于物理的神经激光雷达重模拟*

*Richard Marcus, Marc Stamminger* | **Category: cs.RO, cs.CV, cs.GR, eess.IV** | **Updated: 2025-07-15**

**Keywords:** 激光雷达模拟, 新视图合成, 传感器模型, 重模拟, 物理建模

**Comment:** Accepted at ITSC 2025, Gold Coast Australia

> **TL;DR:** 该论文提出了一种通过显式建模激光雷达传感器特性（如卷帘快门、激光功率变化和强度衰减）来提高激光雷达模拟精度的方法，并展示了其先进的重模拟能力。

**AI_Comments:** 该论文的创新点在于显式建模了激光雷达的物理传感器特性，这解决了现有新视图合成方法在处理激光雷达特有效应上的不足。这种基于物理的方法提高了模拟的准确性，并拓展了激光雷达重模拟的应用范围，例如生成高分辨率扫描，对于自动驾驶和3D重建等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有激光雷达模拟方法在处理激光雷达特有的效应方面不足，尽管已经提出了更快的渲染或处理动态场景的解决方案。

**Method:** 通过显式建模传感器特性，如卷帘快门、激光功率变化和强度衰减，来实现更准确的激光雷达模拟。

**Result:** 与现有最先进方法相比，实现了更准确的激光雷达模拟，并通过定量和定性比较以及消融研究证明了其有效性。此外，该方法展示了先进的重模拟能力，例如在相机视角下生成高分辨率激光雷达扫描。

**Conclusion:** 通过显式建模激光雷达传感器特性，本方法能够实现比现有技术更准确的激光雷达模拟和先进的重模拟能力。

> **ai_Abstract:** 本论文提出了一种基于物理的神经激光雷达重模拟方法，旨在解决现有激光雷达模拟中对传感器特定效应处理不足的问题。通过显式建模卷帘快门、激光功率变化和强度衰减等传感器特性，该方法实现了比现有技术更准确的激光雷达模拟。研究通过与最先进方法的定量和定性比较以及消融实验证明了其有效性，并展示了在相机视角下生成高分辨率激光雷达扫描等先进的重模拟能力。

> **摘要翻译:** 新视图合成（NVS）方法最近在激光雷达模拟和大规模3D场景重建领域受到关注。虽然已经提出了更快的渲染或处理动态场景的解决方案，但激光雷达特有的效应仍未得到充分解决。通过显式建模传感器特性，如卷帘快门、激光功率变化和强度衰减，我们的方法与现有技术相比，实现了更准确的激光雷达模拟。我们通过与最先进方法的定量和定性比较，以及突出每个传感器模型组件重要性的消融研究，证明了我们方法的有效性。除此之外，我们还展示了我们的方法具有先进的重模拟能力，例如在相机视角下生成高分辨率激光雷达扫描。我们的代码和生成的数据集可在https://github.com/richardmarcus/PBNLiDAR获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [279] [EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](https://arxiv.org/abs/2507.12440)
> *EgoVLA：从第一人称人类视频中学习视觉-语言-动作模型*

*Ruihan Yang, Qinxi Yu, Yecheng Wu, Rui Yan, Borui Li, An-Chieh Cheng, Xueyan Zou, Yunhao Fang, Hongxu Yin, Sifei Liu, Song Han, Yao Lu, Xiaolong Wang* | **Category: cs.RO, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 机器人模仿学习, 视觉-语言-动作模型, 第一人称视频, 数据规模, EgoVLA

**Comment:** More videos can be found on our website:
  https://rchalyang.github.io/EgoVLA

> **TL;DR:** 本文提出EgoVLA，一个通过利用大规模第一人称人类视频训练的视觉-语言-动作（VLA）模型，并结合少量机器人演示进行微调，以解决机器人模仿学习数据规模受限的问题，并在新基准上表现出色。

**AI_Comments:** 这篇论文的创新点在于利用大规模、丰富的来自第一人称视角的人类视频来训练机器人操作的VLA模型，有效解决了机器人数据收集的规模限制问题。通过结合逆运动学/重定向和少量机器人数据的微调，实现了从人类经验到机器人能力的有效迁移。提出的新基准也为后续研究提供了有益的评估平台。其重要性在于为机器人模仿学习提供了一个可扩展的数据来源和训练范式，有望加速通用机器人操作能力的开发。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器人模仿学习虽然取得了显著进展，但其数据收集依赖于机器人硬件，这严重限制了数据规模。为了克服这一限制，本文探索使用大规模第一人称人类视频来训练机器人操作模型。

**Method:** 作者提出了一种名为EgoVLA的视觉-语言-动作（VLA）模型。该模型首先利用大规模第一人称人类视频进行训练，预测人类手腕和手部动作。然后，通过逆运动学和重定向技术将这些人类动作转换为机器人动作。最后，使用少量机器人操作演示对模型进行微调，以获得机器人策略。此外，他们还提出了一个名为Ego Humanoid Manipulation Benchmark的模拟基准，用于设计多样化的双手操作任务和演示，并在此基准上对EgoVLA进行微调和评估。

**Result:** EgoVLA在Ego Humanoid Manipulation Benchmark上相比基线模型取得了显著的性能提升。研究还通过消融实验证明了人类数据的重要性。

**Conclusion:** 通过利用大规模第一人称人类视频进行预训练，并结合少量机器人演示进行微调，可以有效地解决机器人模仿学习中数据规模受限的问题，并显著提升机器人操作模型的性能。

> **ai_Abstract:** 本文提出了EgoVLA，一个从第一人称人类视频中学习的视觉-语言-动作（VLA）模型，旨在解决机器人模仿学习中数据规模受限的挑战。该方法利用大规模人类视频训练VLA模型预测人类动作，并通过逆运动学和重定向将其转换为机器人动作，再用少量机器人演示进行微调。作者还引入了Ego Humanoid Manipulation Benchmark用于评估。实验结果表明，EgoVLA在新的基准上显著优于现有方法，并强调了人类数据的重要性。

> **摘要翻译:** 机器人模仿学习的真实数据收集已在机器人操作方面取得了显著进展。然而，该过程中对机器人硬件的要求从根本上限制了数据规模。在本文中，我们探索使用第一人称人类视频训练视觉-语言-动作（VLA）模型。使用人类视频的好处不仅在于其规模，更重要的是场景和任务的丰富性。通过在人类视频上训练的VLA模型预测人类手腕和手部动作，我们可以执行逆运动学和重定向，将人类动作转换为机器人动作。我们使用少量机器人操作演示对模型进行微调，以获得机器人策略，即EgoVLA。我们提出了一个名为Ego Humanoid Manipulation Benchmark的模拟基准，其中我们设计了多样化的双手操作任务和演示。我们使用Ego Humanoid Manipulation Benchmark对EgoVLA进行微调和评估，结果显示其比基线模型有显著改进，并消融了人类数据的重要性。视频可在我们的网站上找到：https://rchalyang.github.io/EgoVLA

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [283] [Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning](https://arxiv.org/abs/2507.12977)
> *非可微奖励优化用于基于扩散的自主运动规划*

*Giwon Lee, Daehee Park, Jaewoo Jeong, Kuk-Jin Yoon* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 运动规划, 扩散模型, 强化学习, 非可微优化, 自主机器人

**Comment:** Accepted at IROS 2025

> **TL;DR:** 本文提出了一种基于强化学习的训练方案，结合奖励加权动态阈值算法，以优化基于扩散的运动规划模型的非可微安全性和有效性目标，并取得了最先进的性能。

**AI_Comments:** 本文创新性地将扩散模型与强化学习相结合，解决了自主运动规划中优化非可微目标的挑战性问题。引入奖励加权动态阈值算法是其关键贡献，它允许直接优化传统可微方法难以处理的关键安全性和有效性指标。这种方法增强了扩散模型在实际机器人系统中的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 安全有效的运动规划对自主机器人至关重要。尽管扩散模型在运动规划中表现出色，但它们在训练目标上存在局限性，因为它们近似数据分布，而非直接捕捉决策动态。运动规划的核心在于非可微的下游目标（如安全性、有效性），传统学习算法无法直接优化。

**Method:** 本文提出了一种基于强化学习的训练方案，用于扩散运动规划模型，使其能够有效学习明确衡量安全性和有效性的非可微目标。具体而言，引入了一种奖励加权动态阈值算法来形成密集的奖励信号。

**Result:** 该方法促进了更有效的训练，并优于使用可微目标训练的模型。在行人数据集（CrowdNav、ETH-UCY）上与各种基线相比，取得了最先进的性能，证明了该方法在安全有效运动规划方面的多功能性。

**Conclusion:** 通过引入基于强化学习的训练方案和奖励加权动态阈值算法，本文有效解决了扩散模型在优化非可微运动规划目标方面的局限性，为安全有效的自主运动规划提供了通用且高性能的解决方案。

> **ai_Abstract:** 本文解决了扩散模型在自主运动规划中优化非可微目标（安全性、有效性）的局限性。它提出了一种新颖的基于强化学习的训练方案，并结合了奖励加权动态阈值算法。该方法使扩散模型能够直接学习关键的非可微目标，从而实现更有效的训练，并在行人数据集上取得了最先进的性能，展示了其在安全有效运动规划方面的多功能性。

> **摘要翻译:** 安全有效的运动规划对于自主机器人至关重要。扩散模型擅长捕捉复杂的智能体交互，这是动态环境中决策的基本方面。最近的研究已成功将扩散模型应用于运动规划，展示了它们处理复杂场景和准确预测多模态未来轨迹的能力。尽管扩散模型有效，但它们在训练目标上存在局限性，因为它们近似数据分布，而不是明确捕捉潜在的决策动态。然而，运动规划的关键在于非可微的下游目标，例如安全性（避免碰撞）和有效性（达到目标），而传统学习算法无法直接优化这些目标。在本文中，我们提出了一种基于强化学习的训练方案，用于扩散运动规划模型，使其能够有效学习明确衡量安全性和有效性的非可微目标。具体来说，我们引入了一种奖励加权动态阈值算法来形成密集的奖励信号，从而促进更有效的训练并优于使用可微目标训练的模型。与各种基线相比，在行人数据集（CrowdNav，ETH-UCY）上取得的最先进性能证明了我们方法在安全有效运动规划方面的多功能性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [294] [FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making](https://arxiv.org/abs/2507.12496)
> *FOUNDER：将基础模型置于世界模型中以实现开放式具身决策*

*Yucen Wang, Rui Yu, Shenghua Wan, Le Gan, De-Chuan Zhan* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 基础模型, 世界模型, 具身决策, 开放式任务, 离线强化学习

**Comment:** Accepted by Forty-Second International Conference on Machine Learning
  (ICML 2025)

> **TL;DR:** FOUNDER结合基础模型和世界模型，通过学习映射和想象，在无奖励的具身环境中实现开放式任务解决，并在视觉控制基准上表现出色。

**AI_Comments:** 这项工作通过创新性地结合基础模型和世界模型，解决了具身环境中开放式任务的无奖励学习挑战。其核心在于将高层语义（FM）与低层动态（WM）相结合，并通过预测时间距离作为内在奖励，有效规避了传统强化学习中奖励设计难题。该方法在复杂视觉控制任务上的显著性能提升，证明了其在具身AI领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型（FMs）和世界模型（WMs）在不同层次的任务泛化能力上具有互补优势。本文旨在整合两者的优点，以实现具身环境中开放式、无奖励的任务解决。

**Method:** 提出FOUNDER框架，整合FM的泛化知识与WM的动态建模能力。通过学习一个映射函数，将FM表示映射到WM状态空间，从而从外部观测推断智能体在世界模拟器中的物理状态。该映射使得在行为学习期间通过想象学习目标导向策略，并将映射后的任务作为目标状态。方法利用预测到目标状态的时间距离作为信息丰富的奖励信号。

**Result:** FOUNDER在各种多任务离线视觉控制基准上表现出卓越性能，尤其擅长捕捉文本或视频指定任务的深层语义，在涉及复杂观测或领域差距的场景中表现突出，而这些场景是现有方法难以处理的。经验证，所学习的奖励函数与真实奖励保持一致。

**Conclusion:** FOUNDER成功地将基础模型和世界模型结合，为具身环境中的开放式、无奖励决策提供了有效框架，并在复杂视觉控制任务中展现了优越性。

> **ai_Abstract:** FOUNDER是一个结合了基础模型（FMs）和世界模型（WMs）优势的框架，旨在实现具身环境中无奖励的开放式任务解决。它通过学习将FM表示映射到WM状态空间，并利用想象力进行目标导向策略学习，以预测的时间距离作为奖励信号。该方法在多任务离线视觉控制基准上表现出色，尤其在处理复杂观测和领域差距任务时优于现有方法，并验证了其奖励函数的一致性。

> **摘要翻译:** 基础模型（FMs）和世界模型（WMs）在不同层面的任务泛化方面提供了互补的优势。在这项工作中，我们提出了FOUNDER，一个将FMs中嵌入的通用知识与WMs的动态建模能力相结合的框架，以实现在具身环境中以无奖励方式解决开放式任务。我们学习一个映射函数，将FM表示接地到WM状态空间中，从而有效地从外部观测推断智能体在世界模拟器中的物理状态。这种映射使得在行为学习期间通过想象来学习目标导向策略，并将映射后的任务作为目标状态。我们的方法利用预测到目标状态的时间距离作为信息丰富的奖励信号。FOUNDER在各种多任务离线视觉控制基准上表现出卓越的性能，擅长捕捉由文本或视频指定的任务的深层语义，尤其是在涉及复杂观测或现有方法难以处理的领域差距的场景中。我们学习的奖励函数与真实奖励的一致性也得到了经验验证。我们的项目网站是https://sites.google.com/view/founder-rl。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [318] [ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving](https://arxiv.org/abs/2507.12499)
> *ReAL-AD：迈向端到端自动驾驶中类人推理*

*Yuhang Lu, Jiadong Tu, Yuexin Ma, Xinge Zhu* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 端到端自动驾驶, 层次化推理, 视觉语言模型, 驾驶策略, 驾驶决策

**Comment:** Accepted by ICCV2025

> **TL;DR:** ReAL-AD 提出一个基于人类认知模型的三层推理框架，结合 VLM，显著提升端到端自动驾驶的规划准确性和安全性，使其更具类人推理能力。

**AI_Comments:** 这篇论文的创新点在于将人类三层认知模型引入端到端自动驾驶的决策框架中，并创造性地结合了视觉语言模型（VLM）来增强推理能力。这种分层推理方法提升了系统的可解释性，并有望弥补现有方法在复杂交通场景下泛化能力的不足。其在规划准确性和安全性上超过30%的提升显示了该方法的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的端到端自动驾驶方法依赖固定稀疏的轨迹监督，难以捕捉人类驾驶员自然采用的层次化推理过程。

**Method:** 论文提出了 ReAL-AD 框架，该框架基于人类三层人类认知模型（驾驶策略、驾驶决策和驾驶操作）构建自动驾驶决策，并整合了视觉语言模型（VLM）以增强态势感知和结构化推理。具体包括：战略推理注入器（制定高级驾驶策略）、战术推理集成器（细化战术选择）和分层轨迹解码器（转化为精确控制动作）。

**Result:** 该框架将规划准确性和安全性提高了30%以上。

**Conclusion:** ReAL-AD 框架使端到端自动驾驶更具可解释性，并与类人分层推理对齐，显著提升了规划准确性和安全性。

> **ai_Abstract:** ReAL-AD 提出一种推理增强学习框架，旨在解决现有端到端自动驾驶在模拟人类层次化推理方面的不足。该框架借鉴人类三层认知模型，并结合视觉语言模型，通过战略推理注入器、战术推理集成器和分层轨迹解码器，将高级策略逐步转化为精确控制。实验证明，ReAL-AD 显著提高了自动驾驶的规划准确性和安全性，使其更接近人类驾驶的推理方式。

> **摘要翻译:** 端到端自动驾驶已成为一种有前景的方法，它将感知、预测和规划统一在一个框架内，减少了信息损失并提高了适应性。然而，现有方法通常依赖固定和稀疏的轨迹监督，限制了它们捕捉人类驾驶员自然采用的层次化推理过程的能力。为了弥补这一差距，我们提出了 ReAL-AD，一个推理增强学习框架，它基于人类三层认知模型（驾驶策略、驾驶决策和驾驶操作）来构建自动驾驶中的决策制定，其中整合了视觉语言模型（VLM）以增强这些层面的态势感知和结构化推理。具体来说，我们引入了：(1) 战略推理注入器，通过解释 VLM 生成的洞察力来制定复杂交通环境下的高级驾驶策略；(2) 战术推理集成器，将战略意图细化为可解释的战术选择，例如变道、超车和速度调整；(3) 分层轨迹解码器，逐步将战术决策转化为精确的控制动作，以实现平滑和类人的轨迹执行。广泛的评估表明，整合我们的框架将规划准确性和安全性提高了30%以上，使端到端自动驾驶更具可解释性并与类人分层推理对齐。项目页面可在以下网址找到：\href{https://4dvlab.github.io/project_page/realad}{\texttt{4dvlab.github.io/project_page/realad}}

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [330] [Learning Policies for Dynamic Coalition Formation in Multi-Robot Task Allocation](https://arxiv.org/abs/2412.20397)
> *多机器人任务分配中动态联盟形成的学习策略*

*Lucas C. D. Bezerra, Ataíde M. G. dos Santos, Shinkyu Park* | **Category: cs.RO, cs.MA** | **Updated: 2025-07-16**

**Keywords:** 多机器人任务分配, 联盟形成, 去中心化学习, MAPPO, 强化学习

**Comment:** 

> **TL;DR:** 该论文提出了一种去中心化、基于学习的框架，用于多机器人任务分配中的动态联盟形成，通过扩展MAPPO并整合空间动作图、运动规划、意图共享和任务分配修订，实现了机器人仅依靠局部信息进行任务选择和联盟形成，并能处理大规模机器人群体和多样化任务。

**AI_Comments:** 这项工作的创新在于将MAPPO扩展到动态联盟形成问题，通过引入空间动作图、运动规划、意图共享和任务分配修订等机制，使得去中心化学习成为可能，并且能仅依赖局部信息。其 demonstrated 的可扩展性和对多样化任务的适应性是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在多机器人任务分配（MRTA）中，需要一种有效且自适应的动态联盟形成方法。

**Method:** 该方法提出了一种去中心化、基于学习的框架，用于多机器人任务分配（MRTA）中的动态联盟形成。它通过整合空间动作图、机器人运动规划、意图共享和任务分配修订来扩展MAPPO。

**Result:** 广泛的仿真研究证实了该模型的有效性，使每个机器人能够仅依靠局部信息来学习及时修订任务选择，并与其他机器人形成联盟以完成协作任务。结果还强调了所提出的框架处理大规模机器人群体和适应多样化任务场景的能力。

**Conclusion:** 所提出的去中心化、基于学习的框架在多机器人任务分配中实现了有效的动态联盟形成，具有良好的可扩展性和适应性。

> **ai_Abstract:** 该论文提出了一种去中心化、基于学习的框架，用于多机器人任务分配中的动态联盟形成。该框架通过整合空间动作图、机器人运动规划、意图共享和任务分配修订来扩展了MAPPO。仿真结果表明，该模型能够使机器人仅依靠局部信息有效地进行任务选择修订和联盟形成，从而完成协作任务，并且能够处理大规模机器人群体和适应多样化任务场景。

> **摘要翻译:** 我们提出了一种去中心化、基于学习的框架，用于多机器人任务分配（MRTA）中的动态联盟形成。我们的方法通过整合空间动作图、机器人运动规划、意图共享和任务分配修订来扩展MAPPO，以实现有效和自适应的联盟形成。广泛的仿真研究证实了我们模型的有效性，使每个机器人能够仅依靠局部信息来学习及时修订任务选择，并与其他机器人形成联盟以完成协作任务。结果还强调了所提出的框架处理大规模机器人群体和适应多样化任务集场景的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [331] [Robustness Requirement Coverage using a Situation Coverage Approach for Vision-based AI Systems](https://arxiv.org/abs/2507.12986)
> *使用情境覆盖方法实现基于视觉的AI系统鲁棒性需求覆盖*

*Sepeedeh Shahbeigi, Nawshin Mannan Proma, Victoria Hodge, Richard Hawkins, Boda Li, Valentina Donzella* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 鲁棒性需求, 情境覆盖, 视觉AI系统, 传感器退化, 相机噪声

**Comment:** 4 pages, 1 figure

> **TL;DR:** 本文提出了一种新颖的框架，通过结合相机噪声因素识别和情境覆盖分析，系统地为基于AI的感知系统引出与鲁棒性相关的安全需求，以应对传感器性能下降。

**AI_Comments:** 本文提出了一种有前景的方法来解决AI系统在传感器退化情况下的鲁棒性问题，特别关注基于视觉的系统。其创新点在于将噪声因素分析与情境覆盖相结合，以系统化地识别和评估鲁棒性需求，这对于自动驾驶等安全关键领域至关重要。作为一篇立场论文，它为未来研究奠定了基础，但具体实施和验证的细节尚待进一步工作。

<details>
  <summary>Details</summary>

**Motivation:** AI机器人和车辆需要安全地在复杂动态环境中运行，即使组件出现退化。传感器性能下降会直接影响输入数据质量，从而损害AI推理。为所有可能的传感器退化场景指定安全需求会导致难以管理复杂性并不可避免地出现漏洞。

**Method:** 本文提出了一种新颖的框架，该框架将相机噪声因素识别与情境覆盖分析相结合，以系统地引出基于AI的感知系统的鲁棒性相关安全需求。该方法基于现有识别退化模式的框架，通过引入领域、传感器和安全专家，并结合操作设计域规范，通过纳入与AI性能相关的噪声因素来扩展退化模型。然后应用情境覆盖分析来识别代表性的操作上下文。

**Result:** 本文提出了一个将噪声因素分析和情境覆盖相结合的初始步骤，以支持基于摄像头的AI感知系统鲁棒性需求的原则性制定和完整性评估。

**Conclusion:** 本文标志着将噪声因素分析与情境覆盖相结合的初步步骤，以支持基于摄像头的AI感知系统鲁棒性需求的原则性制定和完整性评估。

> **ai_Abstract:** 本文提出了一种新颖的框架，旨在为基于视觉的AI感知系统系统地制定鲁棒性安全需求。该框架通过整合相机噪声因素识别和情境覆盖分析，解决了传感器性能下降（特别是相机退化）对AI推理的影响。通过引入专家知识和操作设计域规范，扩展了现有的退化模型，并利用情境覆盖来识别代表性操作上下文，从而支持鲁棒性需求的制定和完整性评估。

> **摘要翻译:** 基于AI的机器人和车辆有望在复杂动态环境中安全运行，即使在组件退化的情况下也是如此。在此类系统中，感知依赖于摄像头等传感器捕获环境数据，然后由AI模型处理以支持决策。然而，传感器性能下降直接影响输入数据质量，并可能损害AI推理。为所有可能的传感器退化场景指定安全需求会导致难以管理复杂性并不可避免地出现漏洞。在这篇立场论文中，我们提出了一个新颖的框架，该框架将相机噪声因素识别与情境覆盖分析相结合，以系统地引出基于AI的感知系统的鲁棒性相关安全需求。我们特别关注汽车领域的相机退化。在现有识别退化模式的框架基础上，我们建议引入领域、传感器和安全专家，并结合操作设计域规范，通过纳入与AI性能相关的噪声因素来扩展退化模型。然后应用情境覆盖分析来识别代表性的操作上下文。这项工作标志着将噪声因素分析和情境覆盖相结合的初步步骤，以支持基于摄像头的AI感知系统鲁棒性需求的原则性制定和完整性评估。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [342] [VLMgineer: Vision Language Models as Robotic Toolsmiths](https://arxiv.org/abs/2507.12644)
> *VLMgineer：视觉语言模型作为机器人工具匠*

*George Jiayuan Gao, Tianyu Li, Junyao Shi, Yihan Li, Zizhe Zhang, Nadia Figueroa, Dinesh Jayaraman* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 视觉语言模型, 机器人学, 工具设计, 进化搜索, 操纵

**Comment:** Project Website: https://vlmgineer.github.io/release

> **TL;DR:** VLMgineer利用视觉语言模型和进化搜索，为机器人自动设计工具和操作计划，从而更有效地解决机器人任务。

**AI_Comments:** 本文创新性地将视觉语言模型（VLMs）的代码生成能力与进化搜索结合，实现了物理工具和操作计划的协同设计，为机器人智能提供了一种新范式。这种将问题解决重心转移到工具设计上的方法，有效地将复杂的机器人任务转化为更直接的执行，展现了其在自动化工具发明领域的巨大潜力。同时，发布基准和代码将促进该领域的未来研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人智能研究多集中于生成更好的控制器，而发明更智能的工具则提供了一种互补的物理智能形式，即将解决问题的重心转移到工具设计上。

**Method:** 本文提出了VLMgineer框架，该框架利用视觉语言模型（VLMs）的代码生成能力结合进化搜索，迭代地协同设计物理工具及其操作工具的行动计划以完成任务。

**Result:** VLMgineer在新基准测试中持续发现能更有效、更创新地解决任务的工具和策略，将挑战性的机器人问题转化为直接的执行。它还优于人类规范下VLM生成的设计和现有的人工制作工具。

**Conclusion:** VLMgineer通过自动化工具设计和操作计划的协同开发，有效提升了机器人在日常操作场景中的问题解决能力，并为未来的自动化工具发明研究奠定了基础。

> **ai_Abstract:** 本文提出了VLMgineer框架，旨在利用视觉语言模型（VLMs）的代码生成能力和进化搜索，自动且迭代地为机器人设计物理工具及其操作计划。该方法将解决问题的重心从控制器转移到工具设计上，并在需要创造性工具设计的新日常操作基准上进行了评估。结果表明，VLMgineer能持续发现更有效、更创新的工具和策略，并优于人类规范下VLM生成的设计和现有的人工制作工具，将复杂的机器人问题简化为直接执行。

> **摘要翻译:** 工具的设计和使用反映了通过创造力、规划和预见来理解和操纵物理世界的能力。因此，这些能力常被视为衡量生物物种智能的指标。尽管当前许多机器人智能研究专注于生成更好的控制器，但发明更智能的工具提供了一种互补的物理智能形式：将解决问题的责任转移到工具的设计上。鉴于当前基础模型在常识、推理和创造力方面令人印象深刻的强大能力，我们研究了这些模型是否能提供有用的先验知识来自动设计并有效地运用此类工具？我们提出了VLMgineer，一个利用视觉语言模型（VLMs）的代码生成能力结合进化搜索的框架，以迭代地协同设计物理工具及其操作它们的行动计划来执行任务。我们在一个多样化的新日常操作场景基准上评估了VLMgineer，这些场景需要创造性的工具设计和使用。在此套件中，VLMgineer持续发现能够更有效和创新地解决任务的工具和策略，将具有挑战性的机器人问题转化为直接的执行。它还优于人类规范下VLM生成的设计以及现有的人工制作的日常任务工具。为了促进未来自动化工具发明的研究，我们将发布我们的基准和代码。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [360] [MoistureMapper: An Autonomous Mobile Robot for High-Resolution Soil Moisture Mapping at Scale](https://arxiv.org/abs/2507.12716)
> *MoistureMapper：一种用于大规模高分辨率土壤湿度测绘的自主移动机器人*

*Nathaniel Rose, Hannah Chuang, Manuel A Andrade-Rodriguez, Rishi Parashar, Dani Or, Parikshit Maini* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 土壤湿度测绘, 自主移动机器人, 自适应采样, TDR, 高分辨率

**Comment:** Accepted by 2025 IEEE 21st International Conference on Automation
  Science and Engineering. 8 pages, 10 figures, 2 tables

> **TL;DR:** MoistureMapper是一种自主移动机器人，配备TDR传感器和自适应采样策略，能够大规模、高分辨率地绘制土壤湿度图，相比传统方法显著减少了行进距离和测量方差。

**AI_Comments:** 这项工作提出了一种创新的解决方案，通过结合自主移动机器人技术和先进的自适应采样算法，有效地解决了大规模高分辨率土壤湿度测绘的挑战。其创新点在于将硬件（机器人和传感器）与智能采样策略相结合，显著提高了测量效率和数据质量。这对于精准农业和气候研究等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的土壤湿度测量方法由于高分辨率传感应用（如可变灌溉）中部署成本高昂，不适用于大规模应用。

**Method:** 研究人员设计、构建并部署了一个名为MoistureMapper的自主移动机器人，该机器人配备了时域反射仪（TDR）传感器和直接推入式钻探机制，用于测量土壤体积含水量。此外，他们还实现并评估了基于高斯过程建模的多种自适应采样策略，以构建土壤湿度分布的空间图。

**Result:** 自适应采样方法优于贪婪基准方法，可将行进距离减少高达30%，重建湿度图的方差减少5%。

**Conclusion:** 所提出的MoistureMapper机器人及其自适应采样策略能够有效地进行大规模、高分辨率的土壤湿度测绘，显著提高了效率和准确性。

> **ai_Abstract:** 本文介绍了一种名为MoistureMapper的自主移动机器人，旨在解决现有大规模高分辨率土壤湿度测绘方法成本高昂的问题。该机器人配备TDR传感器和直接推入式钻探机制，并结合基于高斯过程的自适应采样策略来构建土壤湿度空间图。通过大规模模拟和现场部署验证，结果表明自适应采样方法优于基准方法，能将机器人行进距离减少多达30%，并将重建湿度图的方差减少5%，从而实现了高效且精确的大规模土壤湿度测绘。

> **摘要翻译:** 土壤湿度是农业和气候建模等许多应用领域中一个受关注的量。现有方法由于高分辨率传感应用（如可变灌溉）中部署成本高昂，不适用于大规模应用。在这项工作中，我们设计、构建并野外部署了一个自主移动机器人MoistureMapper，用于土壤湿度传感。该机器人配备了时域反射仪（TDR）传感器和直接推入式钻探机制，用于部署传感器以测量土壤中的体积含水量。此外，我们实现并评估了基于高斯过程建模的多种自适应采样策略，以构建土壤湿度分布的空间图。我们展示了大规模计算模拟和现场概念验证部署的结果。自适应采样方法优于贪婪基准方法，可将行进距离减少高达30%，重建湿度图的方差减少5%。现场实验视频链接：https://youtu.be/S4bJ4tRzObg

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [378] [Learning to Predict Mobile Robot Stability in Off-Road Environments](https://arxiv.org/abs/2507.12731)
> *学习预测越野环境中移动机器人的稳定性*

*Nathaniel Rose, Arif Ahmed, Emanuel Gutierrez-Cornejo, Parikshit Maini* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 移动机器人稳定性, 越野环境, 机器学习, IMUnet, C3分数

**Comment:** Nathaniel Rose and Arif Ahmed contributed equally to this work.
  Accepted poster for RSS 2025 Workshop on Resilient Off-road Autonomous
  Robotics. 8 pages, 8 figures, 1 table

> **TL;DR:** 本文提出了一种基于学习的方法，利用轻量级神经网络IMUnet和视觉ArUco跟踪的C3分数，直接从本体感受数据估计移动机器人在越野环境中的稳定性，克服了传统方法对精确物理参数测量的依赖。

**AI_Comments:** 该论文的创新点在于提出了一个无需精确物理模型和力传感的、基于学习的机器人稳定性估计方法，克服了传统方法的局限性。通过结合本体感受数据（IMU）和视觉信息（C3分数），提供了一种实用的稳定性预测方案。其潜在应用价值在于提高移动机器人在复杂越野环境中的自主性和安全性，特别是在农业和空间等领域。

<details>
  <summary>Details</summary>

**Motivation:** 在崎岖的越野环境中，轮式移动机器人导航面临挑战。传统的基于物理的稳定性度量（如SSM或ZMP）需要精确测量接触力、地形几何形状和机器人质心，这些在实际野外条件下难以准确获取。

**Method:** 本文提出一种基于学习的方法，使用轻量级神经网络IMUnet，直接从本体感受数据估计机器人平台稳定性，无需明确的地形模型或力传感。此外，开发了一种新颖的基于视觉的ArUco跟踪方法来计算一个标量分数，称为C3分数，用于量化机器人平台稳定性。C3分数捕获图像空间随时间的变化作为物理不稳定的替代，并用作神经网络模型的训练信号。

**Result:** 在多种地形类型和速度下收集的数据上评估了该方法，并证明了其对先前未见条件的泛化能力。初步结果表明，使用IMU和机器人速度作为输入来估计平台稳定性具有潜力。

**Conclusion:** 所提出的方法可应用于机器人任务的门控，例如精确驱动和传感，特别是在农业和空间应用中的移动操作任务。该学习方法还为基于感知的可通行性估计和规划提供了监督机制。

> **ai_Abstract:** 本文提出了一种创新的学习方法，用于在越野环境中预测移动机器人的稳定性。针对传统物理模型对精确测量依赖的不足，研究人员开发了基于本体感受数据的IMUnet轻量级神经网络，并引入了基于视觉ArUco跟踪的C3分数作为训练信号。该方法无需地形模型或力传感，能够数据驱动地推断机器人稳定性。初步研究表明，该方法在不同地形和速度下具有良好的泛化能力，并可应用于机器人任务控制及感知规划。

> **摘要翻译:** 轮式移动机器人在越野环境中导航由于动态和崎岖的地形而充满挑战。传统的基于物理的稳定性度量，例如静态稳定性裕度（SSM）或零力矩点（ZMP），需要了解接触力、地形几何形状和机器人精确的质心，这些在实际野外条件下难以准确测量。在这项工作中，我们提出了一种基于学习的方法，使用轻量级神经网络IMUnet直接从本体感受数据估计机器人平台稳定性。我们的方法实现了机器人稳定性的数据驱动推断，而无需明确的地形模型或力传感。我们还开发了一种新颖的基于视觉的ArUco跟踪方法来计算一个标量分数，以量化机器人平台稳定性，称为C3分数。该分数捕获图像空间随时间的变化作为物理不稳定的替代，并用作基于神经网络模型的训练信号。作为一项初步研究，我们评估了我们的方法在跨多种地形类型和速度收集的数据上的表现，并证明了其对先前未见条件的泛化能力。这些初步结果凸显了使用IMU和机器人速度作为输入来估计平台稳定性的潜力。所提出的方法可应用于机器人任务的门控，例如精确驱动和传感，特别是农业和空间应用中的移动操作任务。我们的学习方法还为基于感知的可通行性估计和规划提供了监督机制。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [379] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
> *重新思考视觉-语言导航中的具身鸿沟：对物理和视觉差异的整体研究*

*Liuyi Wang, Xinyuan Xia, Hui Zhao, Hanqing Wang, Tai Wang, Yilun Chen, Chengju Liu, Qijun Chen, Jiangmiao Pang* | **Category: cs.RO, cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 视觉-语言导航, 具身鸿沟, 物理机器人, VLN-PE, 机器人导航

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文引入了VLN-PE，一个物理真实的视觉-语言导航（VLN）平台，用于评估不同机器人类型和VLN方法在实际物理环境中的性能。结果表明，现有VLN模型在物理部署中存在显著的性能下降，并暴露了腿式机器人在复杂环境中的运动限制。

**AI_Comments:** 本文的创新之处在于首次系统地将VLN研究从模拟环境带入物理机器人平台，揭示了理论与实际部署之间的巨大鸿沟。VLN-PE平台的引入为未来VLN模型的开发和评估提供了一个更真实、更具挑战性的基准，强调了物理具身约束对模型性能的关键影响，对于推动VLN领域向更实用、更鲁棒的方向发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉-语言导航（VLN）研究基于理想化的机器人运动和控制假设，未能反映物理具身部署中的实际挑战。本文旨在弥合这一具身鸿沟。

**Method:** 引入了一个名为VLN-PE的物理真实VLN平台，支持人形、四足和轮式机器人。首次系统地评估了多种以自我为中心的VLN方法在物理机器人设置中的表现，包括用于单步离散动作预测的分类模型、用于密集路径点预测的扩散模型，以及与路径规划集成的免训练、基于地图的大型语言模型。

**Result:** 实验结果显示，由于机器人有限的观察空间、环境光照变化以及碰撞和跌落等物理挑战，VLN性能显著下降。研究还揭示了腿式机器人在复杂环境中的运动限制。

**Conclusion:** VLN-PE平台具有高度可扩展性，能够集成新场景，从而实现更全面的VLN评估。尽管当前模型在物理部署中的泛化能力较弱，但VLN-PE为提高跨具身导航的整体适应性提供了新途径。研究结果和工具旨在启发社区重新思考VLN的局限性，并推动开发鲁棒、实用的VLN模型。

> **ai_Abstract:** 本文针对视觉-语言导航（VLN）研究中存在的理想化假设与实际物理部署挑战之间的“具身鸿沟”，提出了一个名为VLN-PE的物理真实VLN平台。该平台支持多种机器人类型，并首次系统性地评估了多种VLN方法在真实物理环境中的性能。研究发现，现有VLN模型在物理部署中面临观察空间受限、光照变化以及碰撞跌落等挑战，导致性能显著下降，并揭示了腿式机器人在复杂环境中的运动限制。VLN-PE的提出为未来的VLN模型开发提供了更真实的评估环境和新的研究方向，以期提升模型在实际应用中的鲁棒性和适应性。

> **摘要翻译:** 最近视觉-语言导航（VLN）的进展前景广阔，但它们对机器人运动和控制的理想化假设未能反映物理具身部署的挑战。为了弥合这一鸿沟，我们引入了VLN-PE，一个支持人形、四足和轮式机器人的物理真实VLN平台。我们首次系统地评估了几种以自我为中心的VLN方法在物理机器人设置中的表现，涵盖了不同的技术流程，包括用于单步离散动作预测的分类模型、用于密集路径点预测的扩散模型，以及与路径规划集成的免训练、基于地图的大型语言模型（LLM）。我们的结果揭示了由于机器人有限的观察空间、环境光照变化以及碰撞和跌落等物理挑战导致的显著性能下降。这也暴露了腿式机器人在复杂环境中的运动限制。VLN-PE具有高度可扩展性，允许无缝集成MP3D之外的新场景，从而实现更全面的VLN评估。尽管当前模型在物理部署中泛化能力较弱，但VLN-PE为提高跨具身导航的整体适应性提供了一条新途径。我们希望我们的发现和工具能激励社区重新思考VLN的局限性，并推进鲁棒、实用的VLN模型。代码可在https://crystalsixone.github.io/vln_pe.github.io/获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [419] [What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics](https://arxiv.org/abs/2507.13041)
> *机器人能教会我们什么关于信任和依赖？社会科学与社会机器人学之间的跨学科对话*

*Julien Wacquez, Elisabetta Zibetti, Joffrey Becker, Lorenzo Aloe, Fabio Amadio, Salvatore Anzalone, Lola Cañamero, Serena Ivaldi* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 信任, 人机交互, 社会机器人学, 社会科学, 跨学科对话

**Comment:** 

> **TL;DR:** 随着机器人融入日常生活，理解人机信任变得至关重要，本文主张通过结合社会科学和社会机器人学的见解，建立更全面的信任理解框架。

**AI_Comments:** 这篇论文的创新点在于它明确提出了将社会科学中成熟的信任理论引入到人机交互领域的必要性，填补了现有研究中跨学科对话的空白。其重要性在于，为理解复杂的人机关系中的信任提供了一个更宏观、更系统的视角，有助于设计更符合人类社会预期的智能系统。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器人日益普及，人机交互中的信任问题变得越来越重要。然而，当前人机交互（HRI）领域对信任的理解常常是碎片化的，且社会学中关于信任的既有研究鲜少与机器人学的发展进行对话。因此，需要一种更跨学科的方法来理解人机关系中的信任。

**Method:** 本文主张采取跨学科方法，通过借鉴社会科学和社会机器人学的见解，探索信任的形成、测试和显现方式。其目标是促进学科间的对话，并构建一个更扎实、适应性强的人机交互信任理解框架。

**Result:** Not mentioned in abstract

**Conclusion:** 本文的结论是，为了在不断发展的人机交互世界中更好地理解信任，需要一种整合社会科学和社会机器人学视角的跨学科方法，以建立一个更扎实、更具适应性的信任框架。

> **ai_Abstract:** 本文探讨了在机器人日益融入日常生活的背景下，人机信任的重要性。指出当前人机交互领域对信任的理解存在碎片化，且社会学中关于信任的成熟研究与机器人学缺乏对话。文章主张采取跨学科方法，结合社会科学与社会机器人学的视角，深入理解信任的形成、测试与显现，旨在构建一个更全面、适应性强的人机交互信任框架。

> **摘要翻译:** 随着机器人越来越多地进入日常生活的各个方面，围绕信任的问题变得越来越重要。信任机器人意味着什么？我们应该如何思考涉及人类和非人类代理的关系中的信任？尽管人机交互（HRI）领域已将信任作为一个核心主题，但这一概念常常以碎片化的方式被处理。与此同时，社会学中长期以来作为关键主题的信任研究，却很少与机器人学的发展进行对话。本文认为，我们需要一种更跨学科的方法。通过借鉴社会科学和社会机器人学的见解，我们探讨了信任是如何被塑造、测试和显现的。我们的目标是开启学科间的对话，并帮助建立一个更扎实、更具适应性的框架，以理解在不断发展的人机交互世界中的信任。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [461] [Efficient Online Learning and Adaptive Planning for Robotic Information Gathering Based on Streaming Data](https://arxiv.org/abs/2507.13053)
> *机器人信息采集基于流式数据的有效在线学习与自适应规划*

*Sanjeev Ramkumar Sudha, Joel Jose, Erlend M. Coates* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 机器人信息采集, 自适应规划, 在线学习, 流式稀疏高斯过程, 高斯过程

**Comment:** 

> **TL;DR:** 本文提出一种基于流式稀疏高斯过程的高效自适应信息规划方法，用于机器人信息采集，旨在解决现有方法在未知/时变环境和大数据集下效率不足的问题，并在保持精度的情况下显著降低计算复杂度。

**AI_Comments:** 该论文的创新点在于结合流式稀疏高斯过程，为机器人信息采集提供了一种高效的在线学习和自适应规划方案。这对于在未知或动态环境中进行大规模数据采集的机器人应用具有重要意义，尤其是在处理大数据集时，其计算效率的提升是关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 许多现有机器人信息采集（RIG）解决方案假设环境预先已知，但在真实未知或时变环境中，自适应信息规划仍是活跃研究领域。此外，广泛使用的高斯过程（GP）回归在大数据集下实时性能扩展性差，难以满足实际应用需求。

**Method:** 本文提出一种高效的自适应信息规划方法，结合流式稀疏高斯过程（streaming sparse GPs）来映射连续标量场，应用于机器人信息采集。

**Result:** 在合成数据集上进行了仿真实验，并与现有基准进行比较。在真实世界数据集上也进行了验证。结果表明，所提方法在较长任务中实现了与基准方法相似的建图精度，同时显著降低了计算复杂度。

**Conclusion:** 论文提出的基于流式稀疏高斯过程的高效自适应信息规划方法，有效解决了机器人信息采集在未知/时变环境和大数据集下的挑战，能够在保持精度的同时提高计算效率。

> **ai_Abstract:** 本论文提出了一种高效的自适应信息规划方法，用于基于流式稀疏高斯过程的机器人信息采集，旨在解决现有高斯过程方法在未知/时变环境和大数据集下的实时性能及计算效率问题。通过在合成和真实世界数据集上的实验验证，该方法在保持相似建图精度的同时，显著降低了长任务的计算复杂度。

> **摘要翻译:** 机器人信息采集（RIG）技术是指移动机器人利用一套传感器获取物理环境数据的方法。信息规划是RIG的重要组成部分，其目标是找到最大化效率或信息收集质量的动作序列或路径。许多现有解决方案通过假设环境预先已知来解决此问题。然而，真实环境可能是未知或时变的，自适应信息规划仍然是一个活跃的研究领域。对于初始未知或变化的场域建图，需要自适应规划和增量式在线建图。高斯过程（GP）回归是RIG中用于建图连续空间场的广泛使用技术。然而，在许多应用中，由于其实时性能在大数据集下扩展性不佳，它显得不足。为了解决这些挑战，本文提出了一种高效的自适应信息规划方法，利用流式稀疏高斯过程（streaming sparse GPs）来建图连续标量场。通过合成数据集进行了仿真实验，并与现有基准进行了比较。最后，还通过真实世界数据集进行了验证，以进一步验证所提出方法的有效性。结果表明，我们的方法在较长任务中实现了与基准方法相似的建图精度，同时降低了计算复杂度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [498] [ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning](https://arxiv.org/abs/2507.13088)
> *ZipMPC：通过模仿学习压缩上下文相关的MPC成本*

*Rahel Rickenbach, Alan A. Lahoud, Erik Schaffernicht, Melanie N. Zeilinger, Johannes A. Stork* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 模型预测控制, 模仿学习, 压缩成本函数, 实时系统, 泛化能力

**Comment:** 

> **TL;DR:** ZipMPC提出了一种通过模仿学习为短视距MPC学习压缩且上下文相关的成本函数的方法，以模拟长视距MPC的行为，从而在保持计算效率的同时提高性能和泛化能力。

**AI_Comments:** ZipMPC的创新之处在于将模仿学习与可微分MPC相结合，有效地解决了MPC在实时应用中计算成本高昂和预测视距短的固有问题。通过学习一个压缩的、上下文相关的成本函数，它能够在保持计算效率的同时，实现接近长视距MPC的性能，并展现出良好的泛化能力，这对于机器人和自主系统等领域具有重要意义。该方法通过模仿优化长期目标，而非直接设计复杂的长期成本函数，简化了MPC的设计过程。

<details>
  <summary>Details</summary>

**Motivation:** 模型预测控制（MPC）的计算负担限制了其在机器人等实时系统上的应用，并常需要使用短预测视距，这不仅影响控制性能，也增加了设计反映所需长期目标的MPC成本函数的难度。

**Method:** 本文提出了ZipMPC，一种通过学习短视距MPC的压缩且上下文相关的成本函数来模仿长视距MPC行为的方法。为此，ZipMPC利用可微分MPC和神经网络的概念，通过MPC优化传播模仿损失的梯度。

**Result:** ZipMPC在优化长期目标、保持与短视距MPC相当的计算成本、确保约束满足以及将控制行为泛化到训练期间未观察到的环境方面，优于近似显式MPC和自动成本参数调整等替代方法。在自主赛车模拟和真实世界实验中，ZipMPC始终比选定的基线更快地完成圈数，实现了接近长视距MPC基线的圈速。在短视距MPC基线无法完成圈数的挑战性场景中，ZipMPC能够完成。特别是在训练期间未见的赛道上也观察到了这些性能提升。

**Conclusion:** ZipMPC通过模仿学习有效地解决了MPC的计算负担和短视距限制问题，实现了接近长视距MPC的性能，同时保持了短视距MPC的计算效率和良好的泛化能力。

> **ai_Abstract:** ZipMPC提出了一种创新方法，通过模仿学习为短视距模型预测控制（MPC）学习压缩且上下文相关的成本函数，以模拟长视距MPC的性能。该方法利用可微分MPC和神经网络，在保持与短视距MPC相当的计算成本的同时，显著提高了长期目标优化、约束满足和对新环境的泛化能力。在自主赛车实验中，ZipMPC表现出优越的圈速，甚至在挑战性或未见过的赛道上也能成功完成任务，证明了其在实时系统中的实际应用潜力。

> **摘要翻译:** 模型预测控制（MPC）的计算负担限制了其在机器人等实时系统上的应用，并常需要使用短预测视距。这不仅影响控制性能，也增加了设计反映所需长期目标的MPC成本函数的难度。本文提出了ZipMPC，一种通过学习短视距MPC的压缩且上下文相关的成本函数来模仿长视距MPC行为的方法。它在性能上优于近似显式MPC和自动成本参数调整等替代方法，特别是在：i) 优化长期目标；ii) 保持与短视距MPC相当的计算成本；iii) 确保约束满足；以及iv) 将控制行为泛化到训练期间未观察到的环境方面。为此，ZipMPC利用可微分MPC和神经网络的概念，通过MPC优化传播模仿损失的梯度。我们在自主赛车模拟和真实世界实验中验证了我们提出的方法。ZipMPC始终比选定的基线更快地完成圈数，实现了接近长视距MPC基线的圈速。在短视距MPC基线无法完成圈数的挑战性场景中，ZipMPC能够完成。特别是在训练期间未见的赛道上也观察到了这些性能提升。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [506] [Human Demonstrations are Generalizable Knowledge for Robots](https://arxiv.org/abs/2312.02419)
> *人类演示是机器人的可泛化知识*

*Te Cui, Tianxing Zhou, Zicai Peng, Mengxiao Hu, Haoyang Lu, Haizhou Li, Guangyan Chen, Meiling Wang, Yufeng Yue* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 人类演示, 机器人学习, 可泛化知识, 大型语言模型, 分层结构

**Comment:** accepted for publication in lEEE/RSJ international Conference on
  Intelligent Robots and Systems (lROS 2025)

> **TL;DR:** 本文提出DigKnow方法，将人类演示视频视为机器人的可泛化知识源，通过分层知识提取、检索和LLM规划，显著提升机器人从人类演示中学习任务的成功率和泛化能力。

**AI_Comments:** 本文的创新点在于提出了将人类演示视为可泛化知识而非简单指令的新颖视角，并构建了分层知识提取与应用框架。结合LLM进行规划和结果验证/纠正，是实现机器人从有限演示中获得强大泛化能力的关键。这对于提升机器人学习的效率和鲁棒性具有重要意义，有助于推动机器人技术在复杂现实世界任务中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 以往从人类演示中学习的方法通常将视频视为指令，简单地将其分解为动作序列供机器人重复，这阻碍了向多样化任务或对象实例的泛化。受此限制以及大型语言模型（LLMs）卓越的理解和泛化能力的启发，本文旨在提出一种不同的视角，将人类演示视频视为机器人的知识来源，以解决泛化问题。

**Method:** 本文提出DigKnow方法，DIstills Generalizable KNOWledge with a hierarchical structure。具体而言，DigKnow首先将人类演示视频帧转换为观察知识，然后分析提取人类动作知识，并进一步提炼为包含任务和对象实例的模式知识，从而获得具有分层结构的可泛化知识。在面对不同任务或对象实例时，DigKnow检索与当前任务和对象实例相关的知识。随后，基于LLM的规划器根据检索到的知识进行规划，策略执行与计划一致的动作以完成指定任务。该方法还利用检索到的知识验证和纠正规划和执行结果。

**Result:** 实验结果表明，该方法在多种任务和场景中有效，能够显著提高成功率，并促进现实世界机器人利用从人类演示中获得的知识完成任务。

**Conclusion:** 本文提出的DigKnow方法通过将人类演示视为可泛化知识源，并结合分层知识提取、检索以及LLM驱动的规划与纠正机制，显著增强了机器人从人类演示中学习并泛化到多样化任务和场景的能力。

> **ai_Abstract:** 该论文提出DigKnow方法，旨在解决机器人从人类演示中学习时泛化能力不足的问题。不同于将视频视为简单指令，DigKnow将人类演示视频视为可泛化知识的来源。受LLMs能力的启发，DigKnow通过分层结构（观察知识、动作知识、模式知识）提取并提炼知识。在任务执行时，DigKnow检索相关知识，由LLM规划器进行规划，并利用检索到的知识验证和纠正执行结果，显著提高了机器人在多样化任务和场景中的成功率和泛化能力。

> **摘要翻译:** 从人类演示中学习是设计智能机器人系统的新兴趋势。然而，以往的方法通常将视频视为指令，简单地将其分解为动作序列供机器人重复，这阻碍了向多样化任务或对象实例的泛化。在本文中，我们提出了一种不同的视角，将人类演示视频不仅仅视为指令，而是视为机器人的知识来源。受此视角以及大型语言模型（LLMs）所展现的卓越理解和泛化能力的启发，我们提出了一种名为DigKnow的方法，该方法通过分层结构提炼可泛化知识（DIstills Generalizable KNOWledge）。具体而言，DigKnow首先将人类演示视频帧转换为观察知识。然后对这些知识进行分析以提取人类动作知识，并进一步提炼为包含任务和对象实例的模式知识，从而获取具有分层结构的可泛化知识。在面临不同任务或对象实例的设置中，DigKnow会检索与当前任务和对象实例相关的知识。随后，基于LLM的规划器根据检索到的知识进行规划，策略执行与计划一致的动作以实现指定任务。利用检索到的知识，我们验证并纠正规划和执行结果，从而大幅提高了成功率。在各种任务和场景中的实验结果表明，该方法在促进现实世界机器人利用从人类演示中获得的知识完成任务方面是有效的。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [540] [Wearable Roller Rings to Augment In-Hand Manipulation through Active Surfaces](https://arxiv.org/abs/2403.13132)
> *可穿戴滚轮环通过主动表面增强手内操作*

*Hayden Webb, Podshara Chanrungmaneekul, Shenli Yuan, Kaiyu Hang* | **Category: cs.RO** | **Updated: 2025-07-16**

**Keywords:** 手内操作, 滚轮环, 可穿戴设备, 主动表面, 机器人操作

**Comment:** 

> **TL;DR:** 本文提出了一种可穿戴的滚轮环（RR），通过主动表面帮助机器人和人类在不移动手指的情况下进行手内操作，并证明了其有效性。

**AI_Comments:** 该论文提出了一种新颖且实用的手内操作增强方法——可穿戴滚轮环。其创新点在于通过主动表面实现不依赖手指运动的操作，有效规避了传统方法中抓取不稳定的风险。微分运动模型的建立和对非完整运动的利用，体现了理论深度。该技术对机器人操作和人机协作领域具有重要意义，可能为未来灵巧操作提供新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 手内操作是重新定位和调整物体姿态的关键能力，但其挑战在于计算模型的复杂性以及主动手指运动（如滚动、滑动、接触断开和重塑）导致抓取不稳定的风险。

**Method:** 本文开发了一种模块化机器人附件——滚轮环（RR），它具有主动表面，可由机器人手和人手佩戴，从而在不移动手指的情况下进行操作。通过以非共线方式安装倾斜的RR，推导出了一个通用的微分运动模型。该模型表明，仅需2个RR即可通过非完整物体运动提供完整的手内操作技能，更多RR可以增强操作灵活性并减少运动约束。

**Result:** 通过大量实验，在机器人手和人手上测试了RR的操作能力。结果表明，RR可用于操作任意形状的物体，提供灵巧的手内操作。

**Conclusion:** 滚轮环（RR）是一种有效的方法，可以通过主动表面增强手内操作，即使只使用少量设备也能实现完整的功能，并能处理各种形状的物体。

> **ai_Abstract:** 本研究介绍了一种名为滚轮环（RR）的可穿戴设备，它通过主动表面帮助机器人和人类在不移动手指的情况下进行手内操作，解决了传统手内操作中计算复杂性和抓取不稳定性问题。文章提出了一个通用的微分运动模型，证明仅需少量滚轮环即可实现完整的手内操作，并能增强灵活性。实验验证了该设备在处理任意形状物体方面的有效性和灵巧性。

> **摘要翻译:** 手内操作是重新定位和调整物体姿态的关键能力。这方面的主要挑战不仅在于计算模型的复杂性，还在于主动手指运动（如滚动、滑动、接触断开和重塑）引起抓取不稳定的风险。本文提出了一种可穿戴的模块化机器人附件——滚轮环（RR），它具有主动表面，可由机器人手和人手佩戴，从而在不移动手指的情况下进行操作。通过以非共线方式在手上安装倾斜的RR，我们推导出了一个通用的物体操作微分运动模型。我们的运动模型表明，仅需2个RR即可通过非完整物体运动提供完整的手内操作技能，而更多的RR可以增强操作灵活性并减少运动约束。通过大量实验，我们在机器人手和人手上测试了RR的操作能力。我们表明，RR可用于操作任意形状的物体，提供灵巧的手内操作。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [549] [GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training](https://arxiv.org/abs/2507.13097)
> *GraspGen：一个基于扩散模型的六自由度抓取框架，支持生成器内训练*

*Adithyavairavan Murali, Balakumar Sundaralingam, Yu-Wei Chao, Wentao Yuan, Jun Yamada, Mark Carlson, Fabio Ramos, Stan Birchfield, Dieter Fox, Clemens Eppner* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 六自由度抓取, 扩散模型, 机器人学, 抓取生成, 深度学习

**Comment:** 

> **TL;DR:** 现有的六自由度抓取方法泛化能力不足。GraspGen是一个基于扩散模型的框架，结合了DiffusionTransformer和高效判别器，并引入了新颖的生成器内训练方法。它在模拟和真实机器人环境中均表现出色，达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于将DiffusionTransformer与高效的、在生成器内训练的判别器相结合，为六自由度抓取提供了一种新颖的方法。同时，发布一个包含5300万次抓取的大规模模拟数据集也是一项重要贡献，它解决了数据稀缺性和可扩展性问题。这项工作推动了机器人通用抓取能力的发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管抓取是机器人基本技能且研究进展显著，但现有基于学习的六自由度抓取方法仍未实现即插即用，且难以在不同实体和野外环境中泛化。

**Method:** 本研究提出了GraspGen框架，该框架包含一个用于增强抓取生成的DiffusionTransformer架构，并配有一个高效的判别器用于评分和过滤采样到的抓取。为判别器引入了一种新颖且高效的“生成器内训练”方法。此外，还发布了一个包含超过5300万次抓取的新模拟数据集，以支持GraspGen在物体和夹持器上的扩展。

**Result:** GraspGen在模拟环境中，针对不同夹持器的单个物体抓取方面优于现有方法，在FetchBench抓取基准测试中达到了最先进的性能，并且在真实机器人上，即使在视觉观测嘈杂的情况下也表现良好。

**Conclusion:** GraspGen提供了一个鲁棒且可泛化的六自由度抓取解决方案，有效解决了现有基于学习方法在泛化能力上的局限性。

> **ai_Abstract:** GraspGen是一个基于扩散模型的六自由度抓取框架，旨在解决现有学习型抓取方法泛化能力差的问题。它结合了DiffusionTransformer进行抓取生成，并引入了一个高效的判别器以及新颖的生成器内训练机制来优化抓取选择。该研究还发布了一个包含5300万次抓取的大规模模拟数据集。实验结果表明，GraspGen在模拟和真实机器人环境中均超越了现有方法，并在FetchBench基准测试中达到了最先进水平。

> **摘要翻译:** 抓取是一项基本的机器人技能，尽管研究取得了显著进展，但基于学习的六自由度（6-DOF）抓取方法仍未实现即插即用，并且难以在不同的实体和野外环境中泛化。我们借鉴了近期将以物体为中心的抓取生成过程建模为迭代扩散过程的成功经验。我们提出的框架 GraspGen，由一个增强抓取生成的 DiffusionTransformer 架构组成，并配有一个高效的判别器来评分和过滤采样到的抓取。我们为判别器引入了一种新颖且高效的生成器内训练方法。为了将 GraspGen 扩展到物体和夹持器，我们发布了一个包含超过5300万次抓取的新模拟数据集。我们证明 GraspGen 在模拟环境中，针对不同夹持器的单个物体抓取方面优于现有方法，在 FetchBench 抓取基准测试中达到了最先进的性能，并且在真实机器人上，即使在视觉观测嘈杂的情况下也表现良好。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [559] [Robo-Platform: A Robotic System for Recording Sensors and Controlling Robots](https://arxiv.org/abs/2409.16595)
> *Robo-Platform：一个用于记录传感器和控制机器人的机器人系统*

*Masoud Dayani Najafabadi, Khoshnam Shojaei* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 机器人系统, 智能手机, 数据采集, 机器人控制, Android

**Comment:** Project repository: https://github.com/m-dayani/robo-platform Youtube
  Video: https://youtu.be/BTQ4yLB1bak Dataset:
  https://drive.google.com/drive/folders/1OZqdA1xa-SyJ64qL_TibqhtwhR1fWWrx?usp=sharing

> **TL;DR:** 本文提出了一种基于Android手机的机器人系统Robo-Platform，用于数据采集和机器人控制，利用智能手机的传感器和通信能力，并通过实验展示了其在SLAM和AR应用中的潜力。

**AI_Comments:** Robo-Platform系统利用智能手机的普及性和内置传感器，提供了一个成本效益高且灵活的机器人开发平台。其创新之处在于将消费级智能手机与专业机器人应用相结合，降低了机器人实验和数据采集的门槛。该系统在数据采集和机器人控制方面的双重模式设计具有实用性，尤其是在处理原始传感器数据方面，为后续高级算法研究提供了基础。潜在的局限性可能在于智能手机硬件的性能限制以及操作系统对实时性的支持。

<details>
  <summary>Details</summary>

**Motivation:** 移动智能手机紧凑地提供了机器人项目所需的传感器（如摄像头、IMU、GNSS）和无线/有线通信通道，它们价格实惠、便携且可编程，非常适合测试、数据采集、控制移动机器人和许多其他机器人应用。

**Method:** 本文提出了一种机器人系统，由一个Android手机、一个通过USB连接到手机的微控制器板和一个远程无线控制器站组成。在数据采集模式下，Android设备可以记录多种配置的多个摄像头、IMU、GNSS单元和外部USB ADC通道的原始格式数据集。在机器人控制模式下，Android手机、微控制器板和其他外设构成移动或固定机器人系统，该系统通过Wi-Fi或蓝牙连接的远程服务器进行控制。

**Result:** 实验表明，尽管SLAM和AR应用可以利用所获取的数据，但所提出的系统可以为处理这些嘈杂和零星测量数据提供更高级算法的基础。此外，还研究了通信介质的特性，并包含了两个机器人项目示例，涉及控制玩具车和四旋翼飞行器。

**Conclusion:** 所提出的Robo-Platform系统能够利用智能手机的强大功能，为机器人数据采集和控制提供一个经济且灵活的平台，并为未来更高级的算法处理嘈杂的传感器数据铺平道路。

> **ai_Abstract:** 本文介绍了一种名为Robo-Platform的机器人系统，该系统利用Android智能手机作为核心组件，结合微控制器板和远程无线控制器站。该系统具备两种主要模式：数据采集模式，用于记录多传感器（摄像头、IMU、GNSS、USB ADC）的原始数据；以及机器人控制模式，通过Wi-Fi或蓝牙远程控制移动或固定机器人系统。研究强调了智能手机在机器人应用中的经济性、便携性和可编程性优势。实验证明，该系统不仅能支持SLAM和AR应用的数据需求，还能为处理噪声和零星测量数据的高级算法奠定基础，并通过控制玩具车和四旋翼飞行器的案例展示了其应用潜力。

> **摘要翻译:** 移动智能手机紧凑地提供了机器人项目所需的传感器，如摄像头、IMU、GNSS测量单元，以及无线和有线通信通道。它们价格实惠、便携且可编程，这使得它们非常适合测试、数据采集、控制移动机器人以及许多其他机器人应用。本文提出了一种机器人系统，由一个Android手机、一个通过USB连接到手机的微控制器板和一个远程无线控制器站组成。在数据采集模式下，Android设备可以记录多种配置的多个摄像头、IMU、GNSS单元和外部USB ADC通道的原始格式数据集，用于但不限于姿态估计和场景重建应用。在机器人控制模式下，Android手机、微控制器板和其他外设构成移动或固定机器人系统。该系统使用通过Wi-Fi或蓝牙连接的远程服务器进行控制。实验表明，尽管SLAM和AR应用可以利用所获取的数据，但所提出的系统可以为处理这些嘈杂和零星测量数据提供更高级算法的基础。此外，还研究了通信介质的特性，并包含了两个机器人项目示例，涉及控制玩具车和四旋翼飞行器。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [580] [VertiSelector: Automatic Curriculum Learning for Wheeled Mobility on Vertically Challenging Terrain](https://arxiv.org/abs/2409.17469)
> *VertiSelector：垂直挑战地形轮式移动的自动课程学习*

*Tong Xu, Chenhui Pan, Xuesu Xiao* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 课程学习, 越野移动, 样本效率, 泛化

**Comment:** 

> **TL;DR:** VertiSelector通过选择性采样高难度地形，显著提升了强化学习在越野移动任务中的样本效率和泛化能力，并能泛化到真实世界。

**AI_Comments:** VertiSelector的创新之处在于其自动课程学习方法，它根据时间差分（TD）误差动态选择并优先训练具有挑战性的地形。这种方法有效地解决了强化学习在复杂机器人任务中样本效率低下和真实世界泛化能力不足的关键问题，对提升越野移动机器人的自主学习能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在越野移动方面具有潜力，但大多数RL方法在手动设计的模拟环境中进行训练时样本效率低下，并且难以泛化到真实世界。

**Method:** 本文提出了VertiSelector（VS），一个自动课程学习框架，通过选择性采样训练地形来提高学习效率和泛化能力。VS在重新访问时优先选择具有更高时间差分（TD）误差的垂直挑战性地形，从而使机器人能够在不断发展的能力边缘进行学习。通过动态调整采样焦点，VS显著提高了VW-Chrono模拟器中的样本效率和泛化能力。

**Result:** VertiSelector在VW-Chrono模拟器中显著提升了样本效率和泛化能力。在Verti-4-Wheeler平台上进行的模拟和物理结果表明，VS通过在训练期间高效采样，并在真实世界中鲁棒泛化，成功率提高了23.08%。

**Conclusion:** VertiSelector通过自动课程学习有效地解决了强化学习在极端越野移动中样本效率低和泛化能力差的问题，显著提高了机器人在复杂地形上的学习效率和真实世界性能。

> **ai_Abstract:** 本文提出了VertiSelector（VS），一个自动课程学习框架，旨在解决强化学习在极端越野移动中样本效率低和难以泛化到真实世界的问题。VS通过选择性采样具有高时间差分误差的垂直挑战性地形，使机器人能够在能力边缘学习，从而显著提高了样本效率和泛化能力。在VW-Chrono模拟器和Verti-4-Wheeler平台上的实验结果表明，VS能将成功率提高23.08%，并有效泛化到真实世界。

> **摘要翻译:** 强化学习（RL）通过模拟端到端试错学习经验，具有规避复杂运动学建模、规划和控制的潜力，从而实现极致越野移动。然而，大多数RL方法在大量手动设计的模拟环境中进行训练时样本效率低下，并且难以泛化到真实世界。为了解决这些问题，我们引入了VertiSelector（VS），一个自动课程学习框架，旨在通过选择性采样训练地形来提高学习效率和泛化能力。VS在重新访问时优先选择具有更高时间差分（TD）误差的垂直挑战性地形，从而使机器人能够在不断发展的能力边缘进行学习。通过动态调整采样焦点，VS显著提高了在基于Chrono多物理引擎构建的VW-Chrono模拟器内的样本效率和泛化能力。此外，我们提供了在Verti-4-Wheeler平台上使用VS的模拟和物理结果。这些结果表明，VS通过在训练期间高效采样并鲁棒泛化到真实世界，在成功率方面实现了23.08%的提升。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [599] [Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback](https://arxiv.org/abs/2507.13171)
> *通过隐式人类反馈的强化学习实现人机对齐*

*Suzie Kim, Hye-Bin Shin, Seong-Whan Lee* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 隐式人类反馈, 脑电图, 误差相关电位, 人机对齐

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的隐式人类反馈强化学习（RLIHF）框架，利用非侵入式脑电图（EEG）信号中的误差相关电位（ErrPs）作为连续、隐式反馈，无需用户显式干预。该方法在机器人拾取放置任务中表现出与手动设计密集奖励相当的性能，验证了隐式神经反馈在人机对齐强化学习中的潜力。

**AI_Comments:** 这项研究通过引入非侵入性EEG信号作为隐式反馈，显著提升了RLHF的实用性和用户体验。其创新之处在于将神经科学的发现（ErrPs）与强化学习相结合，提供了一种更自然、更少认知负担的人机对齐方式。这对于需要持续、细粒度反馈的复杂机器人任务尤其重要，有望推动交互式机器人领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习方法在稀疏奖励条件下难以有效学习策略，且需要手动设计复杂的任务特定奖励函数。现有的来自人类反馈的强化学习（RLHF）方法依赖于显式反馈机制（如按钮按下或偏好标签），这会中断自然交互过程并给用户带来显著的认知负担。

**Method:** 本文提出了一种新颖的来自隐式人类反馈的强化学习（RLIHF）框架。该框架利用非侵入式脑电图（EEG）信号，特别是误差相关电位（ErrPs），来提供连续、隐式反馈，无需用户显式干预。所提出的方法采用一个预训练的解码器，将原始EEG信号转换为概率奖励分量，从而即使在存在稀疏外部奖励的情况下也能实现有效的策略学习。研究在基于MuJoCo物理引擎构建的仿真环境中，使用Kinova Gen2机械臂执行复杂的避障拾取放置任务来评估该方法。

**Result:** 通过解码的EEG反馈训练的智能体取得了与通过密集、手动设计奖励训练的智能体相当的性能。

**Conclusion:** 这些发现验证了使用隐式神经反馈在交互式机器人中实现可扩展且与人类对齐的强化学习的潜力。

> **ai_Abstract:** 本文提出了一种新颖的隐式人类反馈强化学习（RLIHF）框架，旨在解决传统强化学习在稀疏奖励下的挑战以及现有RLHF方法中显式反馈带来的交互中断和认知负担。RLIHF利用非侵入式脑电图（EEG）信号中的误差相关电位（ErrPs）作为连续、隐式奖励，通过预训练解码器将其转换为概率奖励分量，从而实现无需用户显式干预的策略学习。在MuJoCo仿真环境中，对Kinova Gen2机械臂执行复杂拾取放置任务的评估表明，RLIHF训练的智能体性能与使用密集手动设计奖励的智能体相当，验证了隐式神经反馈在可扩展且与人类对齐的交互式机器人强化学习中的潜力。

> **摘要翻译:** **标题翻译：** 通过隐式人类反馈的强化学习实现人机对齐

**摘要：** 传统的强化学习（RL）方法在稀疏奖励条件下往往难以学习有效的策略，需要手动设计复杂的、针对特定任务的奖励函数。为了解决这一限制，来自人类反馈的强化学习（RLHF）作为一种有前景的策略应运而生，它通过人类衍生的评估信号补充了手工设计的奖励。然而，大多数现有的RLHF方法依赖于显式反馈机制，例如按钮按下或偏好标签，这会中断自然的交互过程并给用户带来巨大的认知负担。我们提出了一种新颖的来自隐式人类反馈的强化学习（RLIHF）框架，该框架利用非侵入式脑电图（EEG）信号，特别是误差相关电位（ErrPs），提供连续、隐式反馈，而无需用户显式干预。所提出的方法采用预训练解码器将原始EEG信号转换为概率奖励分量，即使在存在稀疏外部奖励的情况下也能实现有效的策略学习。我们在基于MuJoCo物理引擎构建的仿真环境中评估了我们的方法，使用Kinova Gen2机械臂执行复杂的拾取放置任务，该任务需要在操作目标对象时避开障碍物。结果表明，通过解码的EEG反馈训练的智能体取得了与通过密集、手动设计奖励训练的智能体相当的性能。这些发现验证了使用隐式神经反馈在交互式机器人中实现可扩展且与人类对齐的强化学习的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [605] [Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy for Visuomotor Imitation Learning](https://arxiv.org/abs/2411.03294)
> *基于物体中心关键点逆策略的视觉运动模仿学习域外恢复*

*George Jiayuan Gao, Tianyu Li, Nadia Figueroa* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 域外恢复,物体中心,关键点逆策略,视觉运动模仿学习,行为克隆

**Comment:** IROS 2025. Project Website: https://sites.google.com/view/ocr-penn

> **TL;DR:** 提出了一种名为OCR的物体中心恢复框架，通过学习逆策略来解决视觉运动策略学习中域外（OOD）场景的挑战，显著提高了在OOD情况下的性能。

**AI_Comments:** 该论文的创新点在于提出了一个无需额外数据收集，即可提升视觉运动策略在域外（OOD）场景下鲁棒性的通用框架。通过引入物体中心关键点逆策略，它提供了一种有效的机制来引导系统返回已知的训练分布，这对于实际部署具有重要意义。其模块化的设计使其可以作为任何基础BC策略的附加组件，增强了其通用性。此外，自主收集演示的能力也为持续学习提供了新的途径，展现了其在复杂、动态环境中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的行为克隆（BC）方法严重依赖大量标记数据覆盖，在不熟悉的空间状态下表现不佳，难以应对视觉运动策略学习中的域外（OOD）场景。

**Method:** 提出了一个物体中心恢复（OCR）框架。该方法不依赖额外的数据收集，而是通过从原始训练数据中的物体关键点流形梯度推断出的逆策略来构建恢复策略。该恢复策略可以作为任何基础视觉运动BC策略的附加组件，引导系统返回训练分布。

**Result:** 在模拟和真实机器人实验中，该物体中心框架在OOD情况下比基础策略提高了77.7%。此外，OCR还能够自主收集演示用于持续学习。

**Conclusion:** 该框架代表了提高视觉运动策略在现实世界中鲁棒性的重要一步。

> **ai_Abstract:** 本文提出了一个名为物体中心恢复（OCR）的新框架，旨在解决视觉运动策略学习中常见的域外（OOD）场景挑战。与以往行为克隆（BC）方法依赖大量数据覆盖不同，OCR通过从现有训练数据中的物体关键点流形梯度推断逆策略来学习恢复策略，无需额外数据收集。该恢复策略可作为现有BC策略的插件，有效引导系统返回训练分布，从而在OOD情况下也能保证任务成功。实验结果表明，OCR在模拟和真实机器人环境中均表现出色，使OOD性能相对于基础策略提高了77.7%，并展现了自主收集演示用于持续学习的能力。该框架被认为是提升视觉运动策略在现实世界中鲁棒性的关键一步。

> **摘要翻译:** 我们提出了一个物体中心恢复（OCR）框架，以解决视觉运动策略学习中域外（OOD）场景的挑战。以前的行为克隆（BC）方法严重依赖大量标记数据覆盖，在不熟悉的空间状态下表现不佳。我们的方法不依赖额外的数据收集，而是通过从原始训练数据中的物体关键点流形梯度推断出的逆策略来构建恢复策略。该恢复策略可以作为任何基础视觉运动BC策略的简单附加组件，与特定方法无关，引导系统返回训练分布，即使在OOD情况下也能确保任务成功。我们在模拟和真实机器人实验中证明了我们物体中心框架的有效性，在OOD情况下比基础策略提高了77.7%。此外，我们展示了OCR自主收集演示用于持续学习的能力。总的来说，我们相信这个框架代表了提高视觉运动策略在现实世界中鲁棒性的一步。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [635] [The Role of Integrity Monitoring in Connected and Automated Vehicles: Current State-of-Practice and Future Directions](https://arxiv.org/abs/2502.04874)
> *互联和自动驾驶汽车中完整性监测的作用：当前实践和未来方向*

*Saswat Priyadarshi Nayak, Matthew Barth* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 定位完整性, 互联和自动驾驶汽车, V2X通信, 合作式定位, 研究空白

**Comment:** \c{opyright} 2022 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works

> **TL;DR:** 本文回顾了互联和自动驾驶汽车中定位完整性监测的研究现状，识别了研究空白，特别是合作式完整性监测，并提出了未来研究方向。

**AI_Comments:** 这篇论文通过对互联和自动驾驶汽车中定位完整性监测的全面回顾，填补了现有研究的空白，尤其是在V2X通信的合作式完整性监测方面。其创新之处在于不仅识别了研究现状，还通过分析行业标准和数据集来揭示实际差距，并提出了未来研究方向，对该领域的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 互联和自动驾驶汽车 (CAV) 应用，尤其是在安全关键场景中，需要准确可靠的定位信息。定位完整性（对导航系统性能的信任）对于满足这些需求至关重要。尽管GNSS完整性监测已有广泛研究，但利用V2X通信的合作式定位完整性监测受到的关注较少，这构成了研究动机。

**Method:** 本文通过回顾现有定位完整性监测领域的研究，特别关注合作式完整性监测方法，并识别各种研究空白。此外，它还审查了关键的汽车安全标准和公共V2X数据集，以映射当前研究重点并发现关键差距。

**Result:** 论文识别了定位完整性监测领域的各种研究空白，特别是在利用V2X通信的合作式完整性监测方面。它还揭示了当前研究重点和关键差距，并通过审查汽车安全标准和公共V2X数据集来完成。

**Conclusion:** 论文概述了有前景的未来研究方向，强调了旨在推进和评估定位完整性的研究主题。

> **ai_Abstract:** 本文旨在探讨互联和自动驾驶汽车 (CAV) 中定位完整性监测 (IM) 的作用。它系统地回顾了现有研究，特别关注了基于V2X通信的合作式IM，并识别了该领域的研究空白。通过分析汽车安全标准和V2X数据集，论文揭示了当前研究的优先事项和关键不足。最终，论文提出了未来研究的方向，以推动和评估CAV中的定位完整性。

> **摘要翻译:** 定位完整性是指对导航系统性能的信任。为了满足互联和自动驾驶汽车 (CAV) 应用的需求，特别是在安全关键场景中，需要准确可靠的定位信息。接收机自主完整性监测 (RAIM) 及其变体已广泛应用于基于全球导航卫星系统 (GNSS) 的车辆定位研究，通常与运动学（例如，里程计）和感知传感器（例如，摄像头）融合。然而，利用车联网 (V2X) 通信的合作式定位解决方案的完整性监测 (IM) 受到的关注相对有限。本文回顾了定位 IM 领域的现有研究，并识别了各种研究空白。特别关注了识别突出合作式 IM 方法的研究。它还审查了关键的汽车安全标准和公共 V2X 数据集，以映射当前研究优先事项并揭示关键差距。最后，本文概述了有前景的未来方向，强调了旨在推进和评估定位完整性的研究主题。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [643] [Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing](https://arxiv.org/abs/2507.13200)
> *少量样本的工具使用技能迁移：基于人类演示和近距离与触觉传感*

*Marina Y. Aoyama, Sethu Vijayakumar, Tetsuya Narita* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 机器人工具使用, 少量样本学习, 多模态传感, 触觉传感, 域间隙

**Comment:** 8 pages, 9 figures, IEEE Robotics and Automation Letters

> **TL;DR:** 本文提出一个利用多模态传感和少量人类演示，通过模拟预训练和真实世界微调，实现机器人工具使用技能迁移的框架，有效解决数据稀缺和域间隙问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合预训练和少量人类演示的框架，有效解决了机器人工具使用技能学习中数据稀缺和模拟到现实的域间隙问题。通过利用多模态传感（近距离和触觉），它增强了机器人对复杂接触状态的识别能力，这对于精细的工具操作至关重要。这种少量样本迁移学习的方法对于实际机器人部署具有重要意义，因为它减少了对大量真实世界数据的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 机器人工具操作面临挑战，因为涉及机器人-工具和工具-环境的双重接触点，且现有方法受限于真实世界数据不足和模拟到现实的巨大鸿沟。

**Method:** 本文提出了一个使用多模态传感的少量样本工具使用技能迁移框架。该框架包括在模拟环境中预训练基础策略以捕获工具使用中的常见接触状态，并使用在真实世界目标领域收集的人类演示进行微调，以弥合域间隙。

**Result:** 该框架能够通过少量演示，在Franke Emika机械臂上教授具有不同物理和几何特性的工具进行表面跟随任务。分析表明，机器人通过将预训练策略的工具-环境接触关系识别能力转移到微调策略来获取新技能。结合近距离和触觉传感器增强了接触状态和环境几何的识别。

**Conclusion:** 提出的框架成功实现了机器人工具使用技能的少量样本迁移，并通过预训练和微调结合多模态传感有效解决了数据稀缺和模拟到现实的域间隙问题，提高了接触识别能力。

> **ai_Abstract:** 本文提出了一种创新的少量样本工具使用技能迁移框架，旨在解决机器人工具操作中数据稀缺和模拟到现实域间隙的挑战。该框架利用多模态传感（近距离和触觉传感器），通过在模拟环境中预训练基础策略来识别接触状态，并利用少量真实世界人类演示进行微调。实验证明，该方法能有效使Franke Emika机械臂学习表面跟随等工具使用任务，并通过转移接触识别能力和结合多模态传感显著提升了性能。

> **摘要翻译:** 标题：少量样本的工具使用技能迁移：基于人类演示和近距离与触觉传感

摘要：工具扩展了机器人的操纵能力，就像它们对人类一样。尽管人类在工具操纵方面经验丰富，但教导机器人这些技能面临挑战。这种复杂性源于两个同时接触点的相互作用：一个在机器人和工具之间，另一个在工具和环境之间。触觉和近距离传感器在识别这些复杂接触中起着关键作用。然而，使用这些传感器学习工具操纵仍然具有挑战性，因为真实世界数据有限且存在巨大的模拟到现实鸿沟。为了解决这个问题，我们提出了一个使用多模态传感的少量样本工具使用技能迁移框架。该框架涉及预训练基础策略以捕获工具使用技能中常见的接触状态，并在真实世界目标领域收集的人类演示进行微调，以弥合域间隙。我们验证了该框架能够通过少量演示在Franke Emika机械臂上教授使用具有不同物理和几何特性的工具进行表面跟随任务。我们的分析表明，机器人通过将预训练策略的工具-环境接触关系识别能力从预训练策略转移到微调策略来获取新的工具使用技能。此外，结合近距离和触觉传感器增强了接触状态和环境几何的识别。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [660] [Safety-Critical Human-Machine Shared Driving for Vehicle Collision Avoidance based on Hamilton-Jacobi reachability](https://arxiv.org/abs/2502.10610)
> *基于Hamilton-Jacobi可达性的车辆防撞安全关键人机共享驾驶*

*Shiyue Zhao, Junzhi Zhang, Rui Zhou, Neda Masoud, Jianxiong Li, Helai Huang, Shijie Zhao* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** Hamilton-Jacobi可达性, 共享驾驶, 碰撞避免, 强化学习, 人机协作

**Comment:** 36 pages, 15 figures, submitted to AAAP

> **TL;DR:** 本文提出了一种基于Hamilton-Jacobi可达性分析和强化学习的人机共享驾驶框架，旨在通过仅在必要时干预来有效避免碰撞并减少人机冲突。

**AI_Comments:** 该论文的创新点在于将Hamilton-Jacobi可达性分析与强化学习相结合，为安全关键型人机共享驾驶提供了新的解决方案。通过精确定义机器干预的边界（CARS）并设计减少人机冲突的策略（驾驶员模型和权限分配），有效提升了共享驾驶系统的安全性、效率和用户接受度。在真实车辆平台上的验证也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 解决道路安全问题，特别是现有的人机共享防撞方法常中断驾驶员意图并增加人机冲突的风险。

**Method:** 提出一个基于Hamilton-Jacobi (HJ) 可达性分析的“可达性感知强化学习(RL)”共享控制框架。通过离线数据预计算碰撞避免可达集 (CARS) 以确定机器干预时机。开发了针对突发障碍的驾驶员模型和考虑关键防撞特征的权限分配策略，以减少人机冲突。最终训练RL智能体，在强制避免进入CARS的同时减少人机冲突。

**Result:** 在真实车辆平台上进行了测试，结果表明控制器在接近CARS时能有效干预以防止碰撞，同时保持并改善了原始驾驶任务性能。鲁棒性分析进一步支持其在不同驾驶员属性下的灵活性。

**Conclusion:** 该方法成功地实现了安全且低冲突的人机共享防撞，能在有效避免碰撞的同时保持良好的驾驶任务性能和对不同驾驶员的适应性。

> **ai_Abstract:** 本文提出了一种新颖的“可达性感知强化学习(RL)”框架，用于人机共享驾驶以避免车辆碰撞。该框架利用Hamilton-Jacobi (HJ) 可达性分析来定义碰撞避免可达集 (CARS)，仅在车辆接近CARS时激活机器干预。通过结合驾驶员模型和权限分配策略，该方法旨在最小化人机冲突。RL智能体经过训练，确保避免碰撞同时保持驾驶性能。在真实车辆上进行测试，该方法展示了有效的碰撞预防能力、改进的驾驶任务性能以及对不同驾驶员类型的鲁棒性。

> **摘要翻译:** 道路安全仍然是一个紧迫的全球性问题，车辆碰撞造成了巨大的人力、社会和经济负担。在关键碰撞场景中，人机共享防撞旨在仅在必要时进行干预，以帮助驾驶员避免事故。现有方法依赖于重新规划无碰撞轨迹并强制人机跟踪，这通常会中断驾驶员意图并增加冲突风险。本文引入了一个由Hamilton-Jacobi (HJ) 可达性分析指导的“可达性感知强化学习(RL)”共享控制框架。只有当车辆接近碰撞避免可达集 (CARS) 时（表示碰撞不可避免的状态），机器干预才会被激活。首先，我们通过使用离线数据求解Bellman方程来预计算可达性分布和CARS。为了减少人机冲突，我们针对突发障碍开发了一个驾驶员模型，并提出了一种考虑关键防撞特征的权限分配策略。最后，我们训练了一个RL智能体，以减少人机冲突，同时强制执行避免进入CARS的硬约束。所提出的方法在真实车辆平台上进行了测试。结果表明，控制器在接近CARS时能有效干预以防止碰撞，同时保持并改善了原始驾驶任务性能。鲁棒性分析进一步支持其在不同驾驶员属性下的灵活性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [678] [Signal Temporal Logic Compliant Co-design of Planning and Control](https://arxiv.org/abs/2507.13225)
> *信号时序逻辑兼容的规划与控制协同设计*

*Manas Sashank Juvvi, Tushar Dilip Kurne, Vaishnavi J, Shishir Kolathaya, Pushpak Jagtap* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 信号时序逻辑, 协同设计, 运动规划, 控制, 强化学习

**Comment:** 

> **TL;DR:** 本文提出了一种新的协同设计策略，将轨迹规划和控制相结合，以处理自主机器人中的STL任务。该方法通过学习时空运动基元和构建STL兼容的运动规划来实现，并在差分驱动和四足机器人上进行了验证。

**AI_Comments:** 该论文的创新点在于其协同设计策略，将规划和控制紧密结合以处理STL任务。特别是利用强化学习来学习运动基元，并结合采样方法进行STL兼容规划，提供了一种新颖且实用的无模型解决方案。在不同类型机器人上的验证也增强了其普适性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 处理自主机器人中的信号时序逻辑（STL）任务，通过集成轨迹规划和控制来实现。

**Method:** 该方法分为两个阶段：(i) 使用强化学习学习时空运动基元以封装机器人特定约束；(ii) 从这些基元构建STL兼容的运动规划，采用基于采样的无模型策略。

**Result:** 所提出的无模型方法能够在各种环境中生成可行的STL兼容运动规划，并在差分驱动机器人和四足机器人上通过各种STL规范进行了验证。

**Conclusion:** 本文提出的协同设计策略有效整合了规划与控制，为自主机器人处理STL任务提供了一种经验证的无模型方法，能够生成鲁棒的STL兼容运动规划。

> **ai_Abstract:** 本文提出了一种用于自主机器人中基于信号时序逻辑（STL）任务的规划与控制协同设计策略。该方法分为两阶段：首先，利用强化学习学习封装机器人约束的时空运动基元；其次，基于这些基元构建STL兼容的运动规划。该无模型方法能够生成可行的STL兼容运动规划，并在差分驱动和四足机器人上进行了验证。

> **摘要翻译:** 这项工作提出了一种新颖的协同设计策略，该策略集成了轨迹规划和控制，以处理自主机器人中的基于STL（信号时序逻辑）的任务。该方法包括两个阶段：(i) 学习时空运动基元以封装固有的机器人特定约束，以及 (ii) 从这些基元构建STL兼容的运动规划。最初，我们采用强化学习来构建一个控制策略库，以执行由运动基元描述的轨迹。然后，我们将运动基元映射到时空特性。随后，我们提出了一种基于采样的STL兼容运动规划策略，专门用于满足STL规范。所提出的无模型方法能够在各种环境中生成可行的STL兼容运动规划，并在差分驱动机器人和四足机器人上通过各种STL规范进行了验证。演示视频可在 https://tinyurl.com/m6zp7rsm 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [684] [BEV-LIO(LC): BEV Image Assisted LiDAR-Inertial Odometry with Loop Closure](https://arxiv.org/abs/2502.19242)
> *BEV-LIO(LC): 基于BEV图像辅助的激光雷达惯性里程计与闭环检测*

*Haoxin Cai, Shenghai Yuan, Xinyi Li, Junfeng Guo, Jianqi Liu* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 激光雷达惯性里程计, 鸟瞰图, 闭环检测, 特征提取, 点云配准

**Comment:** 

> **TL;DR:** BEV-LIO(LC)是一个新的激光雷达惯性里程计框架，它结合了BEV图像表示、几何点云配准和基于BEV图像特征的闭环检测，在各种场景下实现了竞争性的定位精度。

**AI_Comments:** 该论文的创新点在于将BEV图像表示与传统的LIO框架相结合，并利用BEV图像特征进行高效的特征提取和闭环检测。通过将图像处理的优势与三维点云配准相结合，有效提高了定位的精度和全局一致性。特别是轻量级CNN的应用，使得该方法在保持高性能的同时，兼顾了效率。该方法在不同激光雷达类型和场景下的良好表现，证明了其泛化能力和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一种新型的激光雷达惯性里程计（LIO）框架，通过结合激光雷达数据的鸟瞰图（BEV）图像表示、基于几何的点云配准以及通过BEV图像特征实现的闭环检测，以提高定位的全局一致性和准确性。

**Method:** BEV-LIO(LC)首先通过归一化点密度将激光雷达点云投影到BEV图像中。然后，使用轻量级卷积神经网络（CNN）提取BEV图像的局部和全局描述符。局部描述符与FAST关键点一起用于BEV图像匹配以构建重投影误差，而全局描述符用于闭环检测。重投影误差最小化与点到平面配准在迭代扩展卡尔曼滤波器（iEKF）中集成。在后端，全局描述符用于创建KD树索引的关键帧数据库以进行精确的闭环检测。当检测到闭环时，RANSAC计算来自BEV图像匹配的粗略变换作为迭代最近点（ICP）的初始估计。最终，精炼后的变换与里程计因子一起整合到因子图中，以提高定位的全局一致性。

**Result:** 在不同激光雷达类型的各种场景下进行的广泛实验表明，BEV-LIO(LC)优于最先进的方法，实现了具有竞争力的定位精度。

**Conclusion:** BEV-LIO(LC)是一个新颖的激光雷达惯性里程计框架，通过有效结合BEV图像表示、几何点云配准和基于BEV图像特征的闭环检测，显著提高了定位的全局一致性和准确性。

> **ai_Abstract:** BEV-LIO(LC)是一种新颖的激光雷达惯性里程计（LIO）框架，它将激光雷达数据的鸟瞰图（BEV）图像表示与基于几何的点云配准相结合，并利用BEV图像特征进行闭环检测。该方法通过归一化点密度将激光雷达点云转换为BEV图像，并使用轻量级CNN提取局部和全局描述符。局部描述符用于BEV图像匹配和重投影误差构建，而全局描述符用于闭环检测。系统将重投影误差最小化与点到平面配准集成到iEKF中。在后端，利用全局描述符构建关键帧数据库进行闭环检测，并通过RANSAC和ICP细化变换，最终整合到因子图中以提高全局一致性。实验证明，BEV-LIO(LC)在各种场景下均优于现有方法，实现了高精度定位。

> **摘要翻译:** 这项工作介绍了BEV-LIO(LC)，一个新颖的激光雷达惯性里程计（LIO）框架，它结合了激光雷达数据的鸟瞰图（BEV）图像表示与基于几何的点云配准，并通过BEV图像特征整合了闭环检测（LC）。通过归一化点密度，我们将激光雷达点云投影到BEV图像中，从而实现高效的特征提取和匹配。一个基于轻量级卷积神经网络（CNN）的特征提取器被用于从BEV图像中提取独特的局部和全局描述符。局部描述符用于与FAST关键点匹配BEV图像以构建重投影误差，而全局描述符则促进闭环检测。重投影误差最小化随后与点到平面配准在迭代扩展卡尔曼滤波器（iEKF）中集成。在后端，全局描述符用于创建KD树索引的关键帧数据库，以进行精确的闭环检测。当检测到闭环时，随机样本一致性（RANSAC）从BEV图像匹配中计算出一个粗略变换，作为迭代最近点（ICP）的初始估计。精炼后的变换随后与里程计因子一起整合到因子图中，从而提高了定位的全局一致性。在各种场景和不同激光雷达类型下进行的广泛实验表明，BEV-LIO(LC)优于最先进的方法，实现了具有竞争力的定位精度。我们的代码和视频可以在https://github.com/HxCa1/BEV-LIO-LC找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [704] [Sampling-Based Motion Planning with Discrete Configuration-Space Symmetries](https://arxiv.org/abs/2503.00614)
> *基于采样的运动规划与离散构型空间对称性*

*Thomas Cohn, Russ Tedrake* | **Category: cs.RO** | **Updated: 2025-07-17**

**Keywords:** 运动规划, 构型空间, 对称性, 基于采样, 样本复杂度

**Comment:** Accepted to IROS 2025. 8 pages, 2 figures, 4 tables. Interactive
  results available at https://cohnt.github.io/projects/symmetries.html

> **TL;DR:** 本文展示了如何在具有离散对称性的构型空间中有效实现基于采样的运动规划，通过理论分析和实验证明了在样本复杂度、路径长度和运行时间上的改进。

**AI_Comments:** 本文的创新之处在于，它解决了在具有离散对称性的构型空间中进行运动规划的挑战，通过有效地利用对称性来改进规划性能。它不仅提供了理论上的严谨分析，证明了样本复杂度的改善，还通过大量的实验验证了在实际应用中路径长度和运行时间的显著提升。这对于机器人学和自动化领域的运动规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在具有底层对称性的构型空间中（例如操作一个或多个对称物体时），理想的规划算法应利用这些对称性来生成更短的轨迹。然而，有限对称性会导致构型空间底层拓扑结构的复杂变化，从而阻碍了标准算法的使用。

**Method:** 本文展示了如何有效地在具有有限对称性的空间中实现基于采样的规划所使用的关键原语。通过对构型空间几何的深入研究，进行了严谨的理论分析。

**Result:** 理论分析表明，几种标准算法的样本复杂度有所改善。此外，大量的实验证明了在路径长度和运行时间方面的实际改进。

**Conclusion:** 本文成功地展示了如何在具有离散构型空间对称性的情况下，通过有效实现关键原语并进行理论分析和实验验证，改进基于采样的运动规划算法的性能（包括样本复杂度、路径长度和运行时间）。

> **ai_Abstract:** 本文研究了在具有离散构型空间对称性的环境中进行基于采样的运动规划问题。作者指出，尽管对称性有助于生成更短轨迹，但其导致的拓扑复杂性阻碍了标准算法的应用。为此，论文提出并展示了如何在对称空间中高效实现基于采样的规划原语。通过严谨的理论分析，结合构型空间几何研究，证明了标准算法在样本复杂度上的改进。实验结果进一步证实了路径长度和运行时间的实际性能提升。

> **摘要翻译:** 当在具有底层对称性的构型空间中进行运动规划时（例如操作一个或多个对称物体时），理想的规划算法应该利用这些对称性来生成更短的轨迹。然而，有限对称性会导致构型空间底层拓扑结构的复杂变化，从而阻碍了标准算法的使用。我们展示了如何在具有有限对称性的空间中有效地实现基于采样的规划所使用的关键原语。通过对构型空间几何的深入研究，严谨的理论分析表明，几种标准算法的样本复杂度有所改善。此外，大量的实验证明了在路径长度和运行时间方面的实际改进。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [8] [Federated Learning for Commercial Image Sources](https://arxiv.org/abs/2507.12903)
> *联邦学习在商业图像源中的应用*

*Shreyansh Jain, Koteswar Rao Jerripothula* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-17**

**Keywords:** 联邦学习, 图像分类, 数据集, Fed-Cyclic, Fed-Star

**Comment:** Published in the Proceedings of IEEE/CVF Winter Conference on
  Applications of Computer Vision (WACV) 2023 with DOI:
  10.1109/WACV56688.2023.00647

> **TL;DR:** 本文介绍了为联邦学习设计的首个图像分类数据集，并提出了两种新的联邦学习算法Fed-Cyclic和Fed-Star，实验证明它们在新数据集上优于现有基线算法。

**AI_Comments:** 本文的创新之处在于首次提出了专为联邦学习设计的图像分类数据集，填补了该领域的数据集空白。同时，提出的两种新算法（Fed-Cyclic和Fed-Star）在拓扑结构和异质性处理方面进行了探索，并取得了优于基线的效果，对于推动联邦学习在商业图像领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习作为一种保护隐私的协作式机器学习范式，需要专门为图像分类任务设计的联邦学习数据集。现有研究可能缺乏针对商业图像源的联邦学习数据集和更优的算法。

**Method:** 本文引入了一个新的数据集，包含23,326张来自8个商业源的图像，分为31个类别，是首个专为联邦学习设计的图像分类数据集。同时，提出了两种新的联邦学习算法：Fed-Cyclic（客户端从上一个客户端接收权重，本地训练后更新并传递给下一个客户端，形成循环拓扑）和Fed-Star（客户端从所有其他客户端接收权重，通过预聚合和本地训练更新本地权重，然后将更新后的权重发送给所有其他客户端，形成星形拓扑）。

**Result:** 实验表明，所提出的Fed-Cyclic和Fed-Star算法在新引入的数据集上均优于现有的基线算法。

**Conclusion:** 为联邦学习设计的数据集和新的算法（Fed-Cyclic和Fed-Star）能够有效提升商业图像源的联邦学习性能。

> **ai_Abstract:** 本文提出了一种专为联邦学习设计的图像分类数据集，该数据集包含来自8个商业源的23,326张图像，分为31个类别。同时，论文还提出了两种创新的联邦学习算法：Fed-Cyclic和Fed-Star。Fed-Cyclic采用循环拓扑结构进行权重传递，而Fed-Star则采用星形拓扑并引入预聚合机制以应对数据异质性。实验结果表明，这两种新算法在新数据集上的表现均优于现有基线方法。

> **摘要翻译:** 联邦学习是一种协作式机器学习范式，它允许多个客户端在不相互暴露数据的情况下学习一个全局模型。因此，它提供了一个具有隐私保护能力的学习平台。本文介绍了一个新的数据集，其中包含从八个不同商业来源收集的23,326张图像，并将其分为31个类别，类似于Office-31数据集。据我们所知，这是第一个专门为联邦学习设计的图像分类数据集。我们还提出了两种新的联邦学习算法，即Fed-Cyclic和Fed-Star。在Fed-Cyclic中，客户端从其上一个客户端接收权重，通过本地训练更新这些权重，然后将其传递给下一个客户端，从而形成循环拓扑。在Fed-Star中，客户端从所有其他客户端接收权重，通过预聚合（以解决统计异质性）和本地训练更新其本地权重，并将其更新后的本地权重发送给所有其他客户端，从而形成星形拓扑。我们的实验表明，这两种算法在我们新引入的数据集上均优于现有基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [15] [MRGen: Segmentation Data Engine for Underrepresented MRI Modalities](https://arxiv.org/abs/2412.04106)
> *MRGen：未充分代表MRI模态的分割数据引擎*

*Haoning Wu, Ziheng Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** MRI分割, 数据增强, 生成模型, 扩散模型, 医学图像分析

**Comment:** Accepted by ICCV 2025; Project Page:
  https://haoningwu3639.github.io/MRGen/

> **TL;DR:** MRGen是一个基于扩散的数据引擎，通过合成图像来解决稀有MRI模态分割模型训练中注释数据稀缺的问题，显著提升了性能。

**AI_Comments:** MRGen的创新之处在于利用生成模型，特别是扩散模型，来解决医学图像分割领域长期存在的标注数据稀缺问题，尤其针对罕见MRI模态。通过引入大规模图文数据集MRGen-DB和可控合成机制，该工作提供了一个实用的数据引擎，有望显著降低医学图像分析的成本和门槛，具有重要的临床应用潜力。其开源代码、模型和数据也体现了其对社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 训练稀有但临床重要的医学图像分割模型面临注释数据稀缺的挑战，且手动标注成本高昂、耗时。

**Method:** 本文引入MRGen-DB，一个大规模放射学图像-文本数据集，包含丰富的元数据和部分像素级掩码标注。在此基础上，提出了MRGen，一个基于扩散的数据引擎，用于可控的医学图像合成，可根据文本提示和分割掩码生成逼真的图像，特别针对缺乏掩码标注的MRI模态。

**Result:** 广泛的实验表明，MRGen通过提供高质量的合成数据，显著提高了未标注模态上的分割性能。

**Conclusion:** 该方法弥补了医学图像分析中的一个关键空白，将分割能力扩展到难以获取手动标注的场景。

> **ai_Abstract:** 本文提出MRGen，一个基于扩散的生成数据引擎，旨在解决稀有MRI模态医学图像分割中数据注释稀缺的问题。通过构建大规模图像-文本数据集MRGen-DB并利用文本提示和分割掩码进行可控图像合成，MRGen能为缺乏标注的MRI模态生成高质量合成数据，从而显著提升分割模型的性能。该方法有效扩展了医学图像分割在数据受限场景下的应用能力。

> **摘要翻译:** 训练针对稀有但临床重要的成像模态的医学图像分割模型，由于注释数据的稀缺性而面临挑战，并且手动掩码注释的获取成本高昂且劳动密集。本文研究了利用生成模型合成数据，用于训练未充分代表模态的分割模型，特别是在注释稀缺的MRI上。具体而言，我们的贡献有三方面：(i) 我们引入了MRGen-DB，一个大规模放射学图像-文本数据集，包含大量样本和丰富的元数据，包括模态标签、属性、区域和器官信息，其中一个子集具有像素级掩码注释；(ii) 我们提出了MRGen，一个基于扩散的数据引擎，用于可控的医学图像合成，以文本提示和分割掩码为条件。MRGen可以为缺乏掩码注释的各种MRI模态生成逼真的图像，从而促进低资源领域的分割训练；(iii) 跨多种模态的广泛实验表明，MRGen通过提供高质量的合成数据，显著提高了未标注模态上的分割性能。我们相信我们的方法弥补了医学图像分析中的一个关键空白，将分割能力扩展到难以获取手动注释的场景。代码、模型和数据将公开可用，网址为https://haoningwu3639.github.io/MRGen/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [25] [MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation](https://arxiv.org/abs/2412.03558)
> *MIDI：单图像到3D场景生成的多实例扩散*

*Zehuan Huang, Yuan-Chen Guo, Xingqiao An, Yunhan Yang, Yangguang Li, Zi-Xin Zou, Ding Liang, Xihui Liu, Yan-Pei Cao, Lu Sheng* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 3D场景生成, 多实例扩散, 单图像到3D, 多实例注意力, 扩散模型

**Comment:** Project page: https://huanngzh.github.io/MIDI-Page/

> **TL;DR:** MIDI提出了一种新的多实例扩散模型，能从单张图像同时生成具有准确空间关系的3D场景，并通过多实例注意力机制实现SOTA性能。

**AI_Comments:** MIDI的创新之处在于其多实例扩散范式和多实例注意力机制，这使得从单张图像直接生成具有复杂空间关系的多对象3D场景成为可能，避免了传统多阶段或逐对象方法的复杂性，显著提升了生成效率和质量。其能够利用有限的场景级数据进行训练，并保持预训练模型的泛化能力，也体现了其方法的实用性和高效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在单图像到3D场景生成中存在局限性，如依赖重建、检索或多阶段逐对象生成，导致无法同时生成多个3D实例并保持准确的空间关系和高泛化性。

**Method:** MIDI通过将预训练的图像到3D对象生成模型扩展为多实例扩散模型，实现多3D实例的同步生成。核心在于引入新颖的多实例注意力机制，直接在生成过程中捕捉对象间交互和空间一致性。该方法利用部分对象图像和全局场景上下文作为输入，直接建模3D生成中的对象补全。训练时，使用有限的场景级数据监督3D实例间的交互，并结合单对象数据进行正则化以保持预训练的泛化能力。

**Result:** MIDI在图像到场景生成中展现了最先进的性能，并通过在合成数据、真实世界场景数据和由文本到图像扩散模型生成的风格化场景图像上的评估得到验证。

**Conclusion:** MIDI通过其独特的多实例扩散范式和多实例注意力机制，有效解决了从单图像生成高质量、具有准确空间关系的3D场景的挑战，并实现了SOTA性能。

> **ai_Abstract:** MIDI提出了一种从单张图像生成组合式3D场景的新范式。它将预训练的图像到3D对象生成模型扩展为多实例扩散模型，能够同时生成多个3D实例并保持准确的空间关系和高泛化性。该方法引入了多实例注意力机制来捕捉对象间交互，并利用部分对象图像和全局场景上下文作为输入。通过在场景级和单对象数据上的有效训练，MIDI在图像到场景生成任务上达到了最先进的性能。

> **摘要翻译:** 本文介绍了MIDI，一种从单张图像生成组合式3D场景的新颖范式。与依赖重建或检索技术，或采用多阶段逐对象生成的现有方法不同，MIDI将预训练的图像到3D对象生成模型扩展到多实例扩散模型，从而能够同时生成具有准确空间关系和高泛化能力的多个3D实例。其核心是，MIDI整合了一种新颖的多实例注意力机制，该机制在生成过程中直接有效地捕捉对象间交互和空间一致性，无需复杂的多个步骤。该方法利用部分对象图像和全局场景上下文作为输入，在3D生成过程中直接建模对象补全。在训练过程中，我们使用有限的场景级数据有效监督3D实例之间的交互，同时结合单对象数据进行正则化，从而保持预训练的泛化能力。MIDI在图像到场景生成中展示了最先进的性能，并通过对合成数据、真实世界场景数据以及由文本到图像扩散模型生成的风格化场景图像的评估得到了验证。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [27] [HairShifter: Consistent and High-Fidelity Video Hair Transfer via Anchor-Guided Animation](https://arxiv.org/abs/2507.12758)
> *HairShifter: 通过锚点引导动画实现一致且高保真视频头发迁移*

*Wangzheng Shi, Yinglin Zheng, Yuxin Lin, Jianmin Bao, Ming Zeng, Dong Chen* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 视频头发迁移, 时间一致性, 锚点引导动画, HairShifter, 图像头发迁移

**Comment:** 

> **TL;DR:** HairShifter提出了一种新的“锚点帧+动画”框架，用于实现高保真和时间一致的视频头发迁移，并在实验中取得了最先进的性能。

**AI_Comments:** HairShifter的创新之处在于其“锚点帧+动画”框架，有效地解决了视频头发迁移中的时间和空间一致性难题。通过集成IHT模块和Multi-Scale Gated SPADE Decoder，它在保持高保真度的同时实现了流畅的视频动画，为该领域树立了新的基线。

<details>
  <summary>Details</summary>

**Motivation:** 头发迁移在社交媒体、游戏、广告和娱乐等领域越来越有价值。尽管单图像头发迁移取得了显著进展，但视频头发迁移由于需要时间一致性、空间保真度和动态适应性而仍然具有挑战性。

**Method:** 本研究提出了HairShifter，一个新颖的“锚点帧+动画”框架，它将高质量图像头发迁移与平滑连贯的视频动画相结合。其核心是，HairShifter集成了图像头发迁移（IHT）模块用于精确的逐帧变换，以及多尺度门控SPADE解码器以确保无缝的空间融合和时间一致性。

**Result:** HairShifter在视频发型迁移方面实现了最先进的性能，结合了卓越的视觉质量、时间一致性和可扩展性。它在保持发型保真度的同时保留了非头发区域。

**Conclusion:** 这项工作为基于视频的发型迁移开辟了新途径，并在此领域建立了强大的基线。

> **ai_Abstract:** 本文介绍了HairShifter，一个用于视频头发迁移的“锚点帧+动画”框架。该方法通过结合图像头发迁移模块和多尺度门控SPADE解码器，解决了视频头发迁移中时间一致性、空间保真度和动态适应性的挑战。实验证明HairShifter在视觉质量、时间一致性和可扩展性方面达到了最先进的水平。

> **摘要翻译:** 头发迁移在社交媒体、游戏、广告和娱乐等领域越来越有价值。尽管单图像头发迁移取得了显著进展，但视频头发迁移由于需要时间一致性、空间保真度和动态适应性而仍然具有挑战性。在这项工作中，我们提出了HairShifter，一个新颖的“锚点帧+动画”框架，它将高质量图像头发迁移与平滑连贯的视频动画相结合。其核心是，HairShifter集成了图像头发迁移（IHT）模块用于精确的逐帧变换，以及多尺度门控SPADE解码器以确保无缝的空间融合和时间一致性。我们的方法在保持发型保真度的同时保留了非头发区域。广泛的实验表明，HairShifter在视频发型迁移方面取得了最先进的性能，结合了卓越的视觉质量、时间一致性和可扩展性。代码将公开可用。我们相信这项工作将为基于视频的发型迁移开辟新途径，并在此领域建立一个强大的基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [29] [Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction](https://arxiv.org/abs/2507.13106)
> *基于深度学习的弥散加权MRI图像胎儿肺部分割及胎儿生长受限肺成熟度评估*

*Zhennan Xiao, Katharine Brudkiewicz, Zhen Yuan, Rosalind Aughwane, Magdalena Sokolska, Joanna Chappell, Trevor Gaunt, Anna L. David, Andrew P. King, Andrew Melbourne* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 胎儿肺部, 深度学习, 分割, 弥散加权MRI, 肺成熟度

**Comment:** 

> **TL;DR:** 本研究提出了一种基于深度学习的自动化胎儿肺部分割和肺成熟度评估流程，解决了传统手动分割耗时的问题，并证明其评估结果与手动分割无显著差异。

**AI_Comments:** 这项工作提出了一种创新的自动化方法来评估胎儿肺成熟度，通过深度学习解决了手动分割耗时的问题，显著提高了临床应用的潜力。其重要性在于能够提供快速、可靠的评估，有助于早期预测新生儿结局和指导干预措施。然而，文章中未提及模型的泛化能力和在不同临床中心数据集上的表现，这可能是未来研究需要关注的限制。

<details>
  <summary>Details</summary>

**Motivation:** 胎儿肺成熟度是预测新生儿结局和产后干预需求的关键指标，尤其对于胎儿生长受限的妊娠。目前，体素内非相干运动分析（IVIM）在无创评估胎儿肺部发育方面显示出前景，但其对手动分割的依赖耗时且限制了临床应用。

**Method:** 本研究提出了一种用于弥散加权磁共振图像的自动化肺成熟度评估流程，该流程包含一个基于深度学习的胎儿肺部分割模型和一个模型拟合的肺成熟度评估。一个3D nnU-Net模型在从4D弥散加权MRI扫描基线帧中手动分割的图像上进行训练。接着，基于nnU-Net预测和手动肺部分割进行体素级模型拟合，以量化反映组织微结构和灌注的IVIM参数。

**Result:** 分割模型表现出鲁棒性，平均Dice系数达到82.14%。体素级模型拟合结果表明，基于nnU-Net预测的分割和手动肺部分割量化的IVIM参数之间没有差异。

**Conclusion:** 本研究表明，一个全自动化的流程可以支持胎儿肺成熟度评估和临床决策。

> **ai_Abstract:** 本研究开发并验证了一个基于深度学习的自动化流程，用于从弥散加权MRI图像中分割胎儿肺部并评估其成熟度，以解决传统手动分割耗时且限制临床应用的问题。该流程结合了3D nnU-Net模型进行肺部分割，并在此基础上进行体素级IVIM参数拟合。实验结果显示，所提出的分割模型性能优异，并且自动化评估的IVIM参数与手动分割的结果无显著差异，证明了该自动化流程在支持胎儿肺成熟度评估和临床决策方面的可行性。

> **摘要翻译:** 胎儿肺成熟度是预测新生儿结局和产后干预需求的关键指标，尤其对于胎儿生长受限的妊娠。体素内非相干运动分析（IVIM）在无创评估胎儿肺部发育方面显示出前景，但其对手动分割的依赖耗时且限制了临床适用性。在这项工作中，我们提出了一种用于弥散加权磁共振图像的自动化肺成熟度评估流程，该流程包含一个基于深度学习的胎儿肺部分割模型和一个模型拟合的肺成熟度评估。一个3D nnU-Net模型在从4D弥散加权MRI扫描基线帧中手动分割的图像上进行训练。该分割模型表现出鲁棒性能，平均Dice系数为82.14%。接下来，基于nnU-Net预测和手动肺部分割进行体素级模型拟合，以量化反映组织微结构和灌注的IVIM参数。结果表明两者之间没有差异。我们的工作表明，一个全自动化的流程可以支持胎儿肺成熟度评估和临床决策。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [38] [AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability](https://arxiv.org/abs/2507.12905)
> *体育姿态：田径场真实运动数据集及单目3D姿态估计能力评估*

*Tomohiro Suzuki, Ryota Tanaka, Calvin Yeung, Keisuke Fujii* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** AthleticsPose, 3D姿态估计, 体育运动, 数据集, 单目

**Comment:** 9 pages, 5 figures, 5 tables

> **TL;DR:** 本文提出了一个名为AthleticsPose的真实体育运动数据集，并利用其训练和评估了单目3D姿态估计模型。研究发现，在真实数据上训练的模型显著优于在模仿数据上训练的模型，并揭示了该技术在体育分析中的潜力和局限性。

**AI_Comments:** 该论文的创新之处在于构建了一个大规模、真实的体育运动数据集AthleticsPose，这直接解决了当前单目3D姿态估计在体育分析领域应用面临的关键瓶颈——缺乏真实数据。研究通过对比实验，有力证明了真实数据训练对于模型性能的关键性，这对于指导未来模型开发和训练具有重要意义。同时，论文也诚实地指出了当前技术的局限性，如对视角和尺度敏感，以及在高速运动指标上的不足，为后续研究指明了方向。其开放数据集的做法也极大地促进了社区的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 单目3D姿态估计是体育分析中成本较低的替代方案，但其应用受限于缺乏真实的体育运动数据集以及对体育任务可靠性的不明确。

**Method:** 引入了AthleticsPose数据集，该数据集包含23名运动员在田径场上执行各种田径项目的“真实”运动数据。使用该数据集训练了一个代表性的3D姿态估计模型，并进行了全面评估。

**Result:** 在AthleticsPose上训练的模型比在模仿运动数据集上训练的基线模型表现显著更好，MPJPE降低约75%。这表明在真实运动数据上训练的重要性。进一步分析显示，估计精度对摄像机视角和主体尺度敏感。在运动学指标案例研究中，模型能捕捉膝关节角度的个体差异，但因预测偏差，难以处理膝关节驱动速度等高速指标。

**Conclusion:** 这项工作为研究社区提供了一个有价值的数据集，并阐明了使用单目3D姿态估计进行体育运动分析的潜力和实际局限性。

> **ai_Abstract:** 本文提出了AthleticsPose数据集，一个包含23名运动员在田径场上真实运动数据的公共数据集，旨在解决单目3D姿态估计在体育分析中面临的真实数据集缺乏和可靠性不明的问题。研究人员利用该数据集训练并评估了一个3D姿态估计模型，结果显示在真实数据上训练的模型性能远超模仿数据训练的模型，MPJPE降低约75%，强调了真实数据的重要性。此外，研究还发现估计精度受相机视角和主体尺度影响，且模型在处理高速运动指标时存在局限性。这项工作为单目3D姿态估计在体育分析领域的应用提供了有价值的数据集和对其潜力与局限性的清晰认识。

> **摘要翻译:** 单目3D姿态估计是体育分析中昂贵动作捕捉系统的一种有前景、灵活的替代方案。然而，其实际应用受到两个因素的阻碍：缺乏真实的体育数据集和对体育任务可靠性的不明确。为了解决这些挑战，我们引入了AthleticsPose数据集，这是一个新的公共数据集，其特点是捕捉了23名运动员在田径场上进行各种田径项目的“真实”动作。使用该数据集，我们训练了一个代表性的3D姿态估计模型并进行了全面评估。我们的结果表明，在AthleticsPose上训练的模型显著优于在模仿体育运动数据集上训练的基线模型，MPJPE降低了约75%。这些结果表明在真实体育运动数据上训练的重要性，因为基于模仿动作的模型不能有效地迁移到真实世界的动作。进一步分析表明，估计精度对相机视角和主体尺度敏感。在运动学指标的案例研究中，该模型展示了捕捉膝关节角度个体差异的潜力，但由于预测偏差，在膝关节驱动速度等高速指标上表现不佳。这项工作为研究社区提供了一个有价值的数据集，并阐明了使用单目3D姿态估计进行体育运动分析的潜力和实际局限性。我们的数据集、代码和检查点可在https://github.com/SZucchini/AthleticsPose获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [55] [Intriguing Properties of Robust Classification](https://arxiv.org/abs/2412.04245)
> *鲁棒分类的有趣特性*

*Bernd Prach, Christoph H. Lampert* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 鲁棒分类,对抗性样本,数据量,泛化,CIFAR-10

**Comment:** 

> **TL;DR:** 尽管对抗性样本研究已久，但我们仍无法训练出高精度且鲁棒的分类器。本文提出，鲁棒泛化可能需要极大量的数据，并在理论和实验上证明了训练数据量是决定鲁棒性能的主要因素，且鲁棒分类器无法利用某些对非鲁棒泛化有用的低幅度方向。

**AI_Comments:** 这篇论文很有趣，它挑战了关于鲁棒分类器能力的一个长期存在的假设。通过提出数据量是关键限制而非根本不存在鲁棒分类器，它为该领域的研究开辟了新的方向。理论分析与实际数据集上的验证相结合，增强了其论点的说服力。揭示鲁棒分类器无法利用某些低幅度方向的发现尤其具有洞察力，这可能解释了鲁棒性和标准泛化之间的差距。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对抗性样本研究已有十年，但社区仍未能训练出对小扰动具有鲁棒性的高精度分类器。以往工作常认为这是因为不存在同时鲁棒和准确的分类器。然而，在计算机视觉中，人类通常既准确又鲁棒，这与上述假设不符。因此，本文旨在探究鲁棒分类器难以训练的原因。

**Method:** 本文提出了一种替代解释，即在特定设置下，鲁棒泛化只有在数据量极大的情况下才可能实现。具体来说，研究发现了一个鲁棒分类器存在，且准确分类器易于学习，但鲁棒分类器却需要指数级数据才能学习的设置。基于此理论结果，作者评估了训练数据量对CIFAR-10等数据集上鲁棒性能的影响。

**Result:** 研究发现，在特定设置下，鲁棒分类器存在，但学习它需要指数级的数据量。理论结果表明，训练数据量是决定鲁棒性能的主要因素。此外，研究还发现数据中存在一些低幅度方向，这些方向对于非鲁棒泛化很有用，但鲁棒分类器无法利用。

**Conclusion:** 本文的结论是，训练数据量是决定鲁棒分类器性能的关键因素。鲁棒分类需要远超非鲁棒分类所需的数据量，并且鲁棒分类器与非鲁棒分类器在利用数据中的某些低幅度方向方面存在根本差异。

> **ai_Abstract:** 本文探讨了鲁棒分类器难以训练的原因，挑战了“鲁棒性和准确性不可兼得”的普遍观点。研究提出，鲁棒泛化可能需要极大量的训练数据。通过理论分析和在CIFAR-10等数据集上的实证评估，作者发现训练数据量是决定鲁棒性能的关键因素，并且鲁棒分类器无法利用某些对非鲁棒泛化有用的低幅度数据方向。这为理解鲁棒性和泛化之间的关系提供了新的视角。

> **摘要翻译:** 尽管自10年前社区了解到对抗性样本以来进行了广泛研究，但我们仍然不知道如何训练出高精度且能保证对其输入的小扰动具有鲁棒性的分类器。以往的工作通常认为这可能是因为不存在同时鲁棒且准确的分类器。然而，在计算机视觉中，这个假设与现实不符，因为人类在大多数感兴趣的任务上通常既准确又鲁棒。我们提供了一种替代解释，并表明在某些设置下，鲁棒泛化只有在不切实际的巨大数据量下才可能实现。具体来说，我们发现了一个鲁棒分类器存在，易于学习准确分类器，但学习鲁棒分类器却需要指数级数据量的设置。基于这一理论结果，我们评估了训练数据量对CIFAR-10等数据集的影响。我们的发现表明，训练数据量是决定鲁棒性能的主要因素。此外，我们表明数据中存在一些低幅度方向，这些方向对于非鲁棒泛化很有用，但鲁棒分类器无法利用。我们在https://github.com/berndprach/IntriguingProperties提供了代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [68] [A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image](https://arxiv.org/abs/2507.12939)
> *遥感图像滑坡分类的深度学习框架*

*Hieu Tang, Truong Vo, Dong Pham, Toan Nguyen, Lam Pham, Truong Nguyen* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 深度学习, 滑坡检测, 遥感图像, EfficientNet, SVM

**Comment:** 

> **TL;DR:** 本文提出了一个用于遥感图像滑坡检测的深度学习框架，结合了数据增强、EfficientNet_Large模型和SVM分类器，并在Zindi挑战赛上取得了0.8938的F1分数。

**AI_Comments:** 该论文提出了一个全面的深度学习框架，通过结合数据增强、强大的骨干模型（EfficientNet_Large）和后处理分类器（SVM），有效解决了遥感图像滑坡检测中数据不平衡和过拟合等常见挑战。其模块化方法和针对特定问题的设计选择值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 卫星图像结合深度学习进行自动滑坡检测正日益普及，但选择合适的深度学习架构以优化性能并避免过拟合仍是一个关键挑战。

**Method:** 本文提出了一个深度学习框架，结合了在线和离线数据增强来处理不平衡数据，使用EfficientNet_Large作为骨干深度学习模型提取鲁棒的嵌入特征，并采用后处理SVM分类器来平衡和增强分类性能。

**Result:** 所提出的模型在Zindi挑战赛的公共测试集上获得了0.8938的F1分数。

**Conclusion:** 所提出的深度学习框架有效解决了遥感图像滑坡检测中的挑战，并展示了强大的分类性能。

> **ai_Abstract:** 本文提出了一种用于遥感图像滑坡检测的深度学习框架，旨在解决数据不平衡和过拟合等挑战。该框架结合了在线和离线数据增强技术，利用EfficientNet_Large模型进行特征提取，并采用SVM分类器进行后处理以优化分类性能。该模型在Zindi挑战赛的公共测试集上取得了0.8938的F1分数。

> **摘要翻译:** 结合深度学习的卫星图像用于自动滑坡检测正变得越来越普遍。然而，选择合适的深度学习架构以优化性能同时避免过拟合仍然是一个关键挑战。为了解决这些问题，本文提出了一种基于深度学习的遥感图像滑坡检测框架。所提出的框架有效结合了在线和离线数据增强来处理不平衡数据，使用EfficientNet_Large深度学习模型作为骨干网络来提取鲁棒的嵌入特征，并采用后处理SVM分类器来平衡和增强分类性能。所提出的模型在Zindi挑战赛的公共测试集上获得了0.8938的F1分数。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [72] [Unified Medical Image Segmentation with State Space Modeling Snake](https://arxiv.org/abs/2507.12760)
> *基于状态空间建模Snake的统一医学图像分割*

*Ruicheng Zhang, Haowei Guo, Kanghui Tian, Jun Zhou, Mingliang Yan, Zeyu Zhang, Shen Zhao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 统一医学图像分割, 状态空间建模, 深度Snake, Mamba演化块, 多尺度异质性

**Comment:** This paper has been accepted by ACM MM 2025

> **TL;DR:** 该论文提出了Mamba Snake，一种结合状态空间建模的新型深度Snake框架，用于统一医学图像分割，在多尺度结构异质性挑战下，其性能优于现有SOTA方法。

**AI_Comments:** 该论文通过将状态空间建模引入深度Snake框架，为医学图像分割提供了一种创新方法。Mamba演化块（MEB）和双分类协同机制的引入，尤其在解决多尺度异质性和微结构欠分割方面，具有显著的创新性。其在多个临床数据集上实现的3%的Dice系数提升，对实际临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 统一医学图像分割（UMIS）对于全面的解剖评估至关重要，但面临多尺度结构异质性的挑战。传统的基于像素的方法缺乏目标级解剖洞察力和器官间关系建模，难以处理形态复杂性和特征冲突，从而限制了它们在UMIS中的有效性。

**Method:** 我们提出了Mamba Snake，一种由状态空间建模增强的新型深度Snake框架，用于统一医学图像分割（UMIS）。Mamba Snake将多轮廓演化构建为分层状态空间图谱，有效建模宏观器官间拓扑关系和微观轮廓细化。我们引入了一个针对Snake的视觉状态空间模块——Mamba演化块（MEB），它利用有效的时空信息聚合来适应性地细化复杂形态。能量图形状先验进一步确保了异质数据中鲁棒的长距离轮廓演化。此外，还引入了双分类协同机制，以同时优化检测和分割，减轻UMIS中微结构的欠分割问题。

**Result:** 在五个临床数据集上的广泛评估表明，Mamba Snake表现出卓越的性能，与现有最先进的方法相比，平均Dice系数提高了3%。

**Conclusion:** Mamba Snake通过整合状态空间建模和双分类协同机制，有效解决了统一医学图像分割中的挑战，实现了显著的性能提升。

> **ai_Abstract:** Mamba Snake是一种用于统一医学图像分割（UMIS）的新型深度Snake框架。它通过引入状态空间建模，将多轮廓演化视为分层状态空间图谱，以有效建模器官间拓扑关系和微观轮廓细化。该框架包含一个名为Mamba演化块（MEB）的视觉状态空间模块，用于自适应地细化复杂形态，并结合能量图形状先验和双分类协同机制，以解决多尺度异质性和欠分割问题。在五个临床数据集上的评估显示，Mamba Snake的平均Dice系数比现有最先进方法提高了3%，证明了其在UMIS中的优越性能。

> **摘要翻译:** 统一医学图像分割（UMIS）对于全面的解剖评估至关重要，但由于多尺度结构异质性而面临挑战。传统的基于像素的方法，缺乏目标级解剖洞察力和器官间关系建模，难以处理形态复杂性和特征冲突，限制了它们在UMIS中的有效性。我们提出了Mamba Snake，一种由状态空间建模增强的新型深度Snake框架，用于UMIS。Mamba Snake将多轮廓演化构建为分层状态空间图谱，有效建模宏观器官间拓扑关系和微观轮廓细化。我们引入了一个针对Snake的视觉状态空间模块，即Mamba演化块（MEB），它利用有效的时空信息聚合来适应性地细化复杂形态。能量图形状先验进一步确保了异质数据中鲁棒的长距离轮廓演化。此外，还引入了双分类协同机制，以同时优化检测和分割，减轻UMIS中微结构的欠分割问题。在五个临床数据集上的广泛评估表明，Mamba Snake表现出卓越的性能，与现有最先进的方法相比，平均Dice系数提高了3%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [74] [R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning](https://arxiv.org/abs/2507.13107)
> *R^2MoE：用于终身概念学习的冗余消除专家混合模型*

*Xiaohan Guo, Yusong Cai, Zejia Liu, Zhengning Wang, Lili Pan, Hongliang Li* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 终身学习, 概念学习, 专家混合, 冗余消除, 灾难性遗忘

**Comment:** 

> **TL;DR:** R^2MoE是一个参数高效的框架，用于终身视觉概念学习，通过专家混合、冗余消除和分层局部注意力来减少灾难性遗忘和参数膨胀，并在CustomConcept 101数据集上实现了优越的性能。

**AI_Comments:** 该论文创新性地将专家混合模型与冗余消除策略相结合，有效解决了终身学习中的两大核心挑战：灾难性遗忘和参数膨胀。路由蒸馏机制确保了专家知识的特异性，而冗余层级专家的消除则显著提升了模型的参数效率。分层局部注意力进一步优化了生成质量。这些创新点共同使得R^2MoE在持续概念学习方面取得了显著的SOTA性能提升，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 使大规模生成模型能够持续学习新的视觉概念对于个性化预训练模型以满足个人用户偏好至关重要。现有方法受限于灾难性遗忘和参数膨胀两个基本挑战。

**Method:** 提出R^2MoE（Redundancy-Removal Mixture of Experts）框架。该框架包括三个关键创新贡献：1. 提出具有路由蒸馏机制的专家混合框架，使专家获得概念特定知识，同时保留门控网络的路由能力，有效缓解灾难性遗忘。2. 提出消除冗余层级专家的策略，通过充分利用先前学习的专家来减少专家参数数量。3. 采用分层局部注意力引导推理方法来减轻生成的视觉概念之间的干扰。

**Result:** 在CustomConcept 101数据集上，与最先进方法相比，本方法生成的图像具有更优越的概念保真度，遗忘率降低了87.8%，参数减少了63.3%。

**Conclusion:** R^2MoE是一种有效且参数高效的终身视觉概念学习框架，显著缓解了灾难性遗忘和参数膨胀问题，并在概念保真度方面表现出色。

> **ai_Abstract:** R^2MoE是一种用于终身视觉概念学习的参数高效框架，旨在解决现有方法面临的灾难性遗忘和参数膨胀问题。该框架通过引入具有路由蒸馏机制的专家混合模型以缓解遗忘，采用冗余层级专家消除策略以减少参数，并利用分层局部注意力引导推理以减轻概念间干扰。实验证明，R^2MoE在CustomConcept 101数据集上显著降低了遗忘率（87.8%）并减少了参数（63.3%），同时生成了概念保真度更高的图像。

> **摘要翻译:** 使大规模生成模型能够持续学习新的视觉概念对于个性化预训练模型以满足个人用户偏好至关重要。现有用于持续视觉概念学习的方法受到两个基本挑战的限制：灾难性遗忘和参数膨胀。本文提出R^2MoE（Redundancy-Removal Mixture of Experts），这是一个参数高效的终身视觉概念学习框架，它能有效学习新概念，同时产生最小的参数开销。我们的框架包括三个关键创新贡献：首先，我们提出一个具有路由蒸馏机制的专家混合框架，使专家能够获取概念特定知识，同时保留门控网络的路由能力，从而有效缓解灾难性遗忘。其次，我们提出一种消除冗余层级专家的策略，通过充分利用先前学习的专家来减少专家参数的数量。第三，我们采用分层局部注意力引导推理方法来减轻生成的视觉概念之间的干扰。广泛的实验表明，与最先进（SOTA）方法相比，我们的方法生成的图像具有更优越的概念保真度，在CustomConcept 101数据集上实现了令人印象深刻的87.8%的遗忘率降低和63.3%的参数减少。我们的代码可在{https://github.com/learninginvision/R2MoE}获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [80] [Salvaging the Overlooked: Leveraging Class-Aware Contrastive Learning for Multi-Class Anomaly Detection](https://arxiv.org/abs/2412.04769)
> *挽救被忽视的：利用类别感知对比学习进行多类别异常检测*

*Lei Fan, Junjie Huang, Donglin Di, Anyang Su, Tianyou Song, Maurice Pagnucco, Yang Song* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 多类别异常检测, 对比学习, 类间混淆, 特征表示, 异常检测

**Comment:** Accepted by ICCV2025, https://lgc-ad.github.io/

> **TL;DR:** 本文提出了一种名为类别感知对比学习（CCL）的新方法，通过解决类间混淆问题，显著提高了多类别异常检测的性能。

**AI_Comments:** 该论文的创新点在于明确识别并解决了多类别异常检测中的“类间混淆”这一关键问题，通过引入类别感知对比学习（CCL），巧妙地利用了原始类别信息进行特征优化。其方法简单有效，并通过局部和全局对比学习提升了特征表示的紧凑性和区分度。这项工作为多类别异常检测提供了一个有前景的解决方案，尤其是在资源受限或需要统一模型的场景下具有重要意义。消融实验中伪类别标签的有效性也为未来研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 早期的异常检测方法在处理多类别场景时存在性能下降问题，主要是由于模型错误地将一个类别的样本重建为另一个类别，导致类间混淆和重建误差加剧。

**Method:** 本文提出了一种简单而有效的类别感知对比学习（CCL）方法。通过明确利用原始对象类别信息作为监督信号，CCL引入了局部对比学习来细化多尺度密集特征，并引入全局对比学习来获得更紧凑的正常模式特征表示，从而有效地使模型适应多类别设置。

**Result:** 在五个数据集上的实验验证了我们方法的有效性，与最先进的方法相比，显示出显著的改进和卓越的性能。消融研究表明，伪类别标签也能达到可比的性能。

**Conclusion:** 类别感知对比学习（CCL）通过有效解决多类别异常检测中的类间混淆问题，显著提升了模型的性能，为多类别异常检测提供了一种有效且可扩展的解决方案。

> **ai_Abstract:** 本文针对多类别异常检测中由于类间混淆导致的性能下降问题，提出了一种名为类别感知对比学习（CCL）的新方法。CCL通过利用原始类别信息，引入局部和全局对比学习来优化特征表示，从而有效适应多类别设置。实验证明，该方法在多个数据集上显著优于现有SOTA方法，且伪类别标签也能达到良好性能。

> **摘要翻译:** 对于异常检测（AD），早期方法通常为单个类别训练独立的模型，虽然性能高，但在可扩展性和资源管理方面面临挑战。最近的努力已转向训练一个能够处理多个类别的单一模型。然而，将早期AD方法直接扩展到多类别设置通常会导致性能下降。在本文中，我们研究了在基于重建的方法中观察到的这种性能下降，并确定了关键问题：类间混淆。当在多类别场景中训练的模型错误地将一个类别的样本重建为另一个类别的样本时，就会出现这种混淆，从而加剧重建误差。为此，我们提出了一种简单而有效的修改，称为类别感知对比学习（CCL）。通过明确利用原始对象类别信息（例如地毯或木材）作为监督信号，我们引入局部CL来细化多尺度密集特征，并引入全局CL来获得更紧凑的正常模式特征表示，从而有效地使模型适应多类别设置。在五个数据集上的实验验证了我们方法的有效性，与最先进的方法相比，显示出显著的改进和卓越的性能。值得注意的是，消融研究表明伪类别标签也能达到可比的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [83] [Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models](https://arxiv.org/abs/2507.13162)
> *Orbis: 克服驾驶世界模型中长程预测的挑战*

*Arian Mousakhan, Sudhanshu Mittal, Silvio Galesso, Karim Farid, Thomas Brox* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 驾驶世界模型, 长程预测, 连续自回归模型, 自动驾驶, Orbis

**Comment:** Project page: https://lmb-freiburg.github.io/orbis.github.io/

> **TL;DR:** Orbis是一个新的驾驶世界模型，通过简单设计和无额外监督，在长程预测和复杂场景泛化方面实现了最先进的性能，并发现连续自回归模型优于离散模型。

**AI_Comments:** 该论文的创新之处在于，Orbis模型在无需额外监督或复杂传感器的情况下，仅通过简洁设计和相对较少的数据量就实现了自动驾驶世界模型中的SOTA性能，这对于资源受限或需要简化部署的场景具有重要意义。此外，论文对离散和连续世界模型进行了直接对比，并明确指出连续自回归模型的优势，为未来的模型设计提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动驾驶世界模型在长程生成和泛化到具有挑战性的场景时面临困难。

**Method:** 开发了一个采用简单设计且无需额外监督或传感器（如地图、深度或多摄像头）的模型。为了比较离散令牌模型和基于流匹配的连续模型，设置了一个兼容这两种方法的混合分词器，并进行了并排比较。

**Result:** 该模型（Orbis）参数量仅为469M，在280小时的视频数据上训练，却达到了最先进的性能，尤其在转弯操作和城市交通等困难场景中表现突出。研究结果表明，连续自回归模型优于离散令牌模型。

**Conclusion:** 研究得出结论，连续自回归模型在个体设计选择上更具鲁棒性，并且比基于离散令牌构建的模型更强大。

> **ai_Abstract:** Orbis是一个为克服自动驾驶世界模型在长程预测和复杂场景泛化方面的挑战而开发的新模型。该模型采用简洁设计，无需额外监督或传感器，仅用少量参数和训练数据便实现了最先进的性能，尤其在困难驾驶场景中表现出色。通过对比离散与连续模型，研究发现连续自回归模型更具鲁棒性和强大性。

> **摘要翻译:** 现有用于自动驾驶的世界模型在长程生成和泛化到具有挑战性的场景方面面临困难。在这项工作中，我们开发了一个采用简单设计且无需额外监督或传感器（如地图、深度或多摄像头）的模型。我们展示了尽管我们的模型只有4.69亿参数并在280小时的视频数据上进行训练，但它仍能产生最先进的性能。它在转弯操作和城市交通等困难场景中表现尤为突出。我们测试了离散令牌模型是否可能比基于流匹配的连续模型具有优势。为此，我们建立了一个兼容这两种方法的混合分词器，并允许进行并排比较。我们的研究得出结论，倾向于连续自回归模型，该模型在个体设计选择上更具鲁棒性，并且比基于离散令牌构建的模型更强大。代码、模型和定性结果可在https://lmb-freiburg.github.io/orbis.github.io/公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [98] [Weakly Supervised Visible-Infrared Person Re-Identification via Heterogeneous Expert Collaborative Consistency Learning](https://arxiv.org/abs/2507.12942)
> *弱监督可见光-红外行人重识别通过异构专家协同一致性学习*

*Yafei Zhang, Lingqi Kong, Huafeng Li, Jie Wen* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 弱监督, 行人重识别, 跨模态, 可见光-红外, 异构专家学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 提出一种弱监督跨模态行人重识别方法，通过异构专家协同一致性学习，仅使用单模态标签即可建立跨模态身份对应关系。

**AI_Comments:** 本文的创新点在于提出了异构专家协同一致性学习框架，有效解决了弱监督场景下可见光-红外行人重识别中跨模态标签缺失的挑战。通过利用单模态标签训练专家并促进专家间的协同学习，提高了模型在无显式跨模态标签情况下的特征学习和身份识别能力，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了减少可见光-红外行人重识别（ReID）模型对带标签跨模态样本的依赖，解决跨模态身份标签不可用的场景。

**Method:** 提出异构专家协同一致性学习框架。该框架利用每个模态的标签数据独立训练专用分类专家，这些专家作为异构预测器预测其他模态样本的身份。设计跨模态关系融合机制以提高预测准确性。在跨模态身份对应关系的隐式监督下，鼓励专家之间进行协同和一致性学习，以增强模态不变特征提取和跨模态身份识别能力。

**Result:** 在两个具有挑战性的数据集上的实验结果验证了所提出方法的有效性。

**Conclusion:** 该方法能够有效解决弱监督可见光-红外行人重识别问题，通过异构专家协同一致性学习显著提升了模型性能。

> **ai_Abstract:** 本文提出一种弱监督可见光-红外行人重识别方法，旨在解决跨模态标签缺失问题。该方法引入异构专家协同一致性学习框架，通过独立训练的单模态分类专家预测跨模态身份，并融合专家预测以提高准确性。通过专家间的协同一致性学习，模型能有效提取模态不变特征，从而提升跨模态身份识别能力。实验证明了该方法的有效性。

> **摘要翻译:** 为了减少可见光-红外行人重识别（ReID）模型对带标签跨模态样本的依赖，本文探索了一种弱监督跨模态行人重识别方法，该方法仅使用单模态样本身份标签，解决了跨模态身份标签不可用的场景。为了减轻跨模态标签缺失对模型性能的影响，我们提出了一种异构专家协同一致性学习框架，旨在以弱监督方式建立鲁棒的跨模态身份对应关系。该框架利用来自每个模态的带标签数据独立训练专用的分类专家。为了关联跨模态样本，这些分类专家充当异构预测器，预测来自其他模态样本的身份。为了提高预测准确性，我们设计了一种跨模态关系融合机制，有效整合来自不同专家的预测。在跨模态身份对应关系提供的隐式监督下，鼓励专家之间进行协同和一致性学习，显著增强了模型提取模态不变特征和改进跨模态身份识别的能力。在两个具有挑战性数据集上的实验结果验证了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [105] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
> *文档视觉问答中基于空间定位的视觉语言模型解释*

*Maximiliano Hormazábal Lagos, Héctor Cerezo-Costas, Dimosthenis Karatzas* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 视觉语言模型, 文档视觉问答, 可解释性, 空间定位, 无需训练

**Comment:** This work has been accepted for presentation at the 16th Conference
  and Labs of the Evaluation Forum (CLEF 2025) and will be published in the
  proceedings by Springer in the Lecture Notes in Computer Science (LNCS)
  series. Please cite the published version when available

> **TL;DR:** EaGERS是一个无需训练、模型无关的管道，通过生成自然语言理由、将其定位到空间子区域并限制响应生成来提高文档视觉问答的透明度和性能。

**AI_Comments:** EaGERS的创新之处在于其“无需训练”和“模型无关”的特性，这使其具有高度的灵活性和实用性。通过空间定位解释，它显著提升了视觉语言模型在文档理解任务中的可解释性和透明度，同时还实现了性能提升，这对于实际应用非常重要。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机是提高文档视觉问答（DocVQA）的透明度和可复现性，同时在不进行额外模型微调的情况下提升性能。

**Method:** 本文介绍了EaGERS管道，其包含三个步骤：1) 通过视觉语言模型生成自然语言理由；2) 通过计算多模态嵌入相似度并结合多数投票，将这些理由定位到可配置网格上的空间子区域；3) 仅从掩蔽图像中选定的相关区域生成响应。

**Result:** 在DocVQA数据集上的实验表明，EaGERS的最佳配置在精确匹配准确率和平均归一化莱文斯坦相似度指标上均优于基础模型，并且在没有额外模型微调的情况下增强了DocVQA的透明度和可复现性。

**Conclusion:** EaGERS是一个有效的、无需训练且模型无关的管道，能够显著提升文档视觉问答的性能、透明度和可复现性。

> **ai_Abstract:** EaGERS是一个创新的、无需训练且模型无关的管道，旨在为文档视觉问答（DocVQA）提供空间定位的解释。它通过生成自然语言理由并将其精确地定位到图像中的相关区域来工作，从而限制响应生成。实验结果表明，EaGERS在DocVQA数据集上不仅提高了性能，还在不进行额外模型微调的情况下增强了模型的透明度和可复现性。

> **摘要翻译:** 我们引入了EaGERS，这是一个完全无需训练且模型无关的管道，它：(1) 通过视觉语言模型生成自然语言理由，(2) 通过计算可配置网格上的多模态嵌入相似度并结合多数投票，将这些理由定位到空间子区域，以及 (3) 仅从掩蔽图像中选定的相关区域生成响应。在DocVQA数据集上的实验表明，我们最好的配置不仅在精确匹配准确率和平均归一化莱文斯坦相似度指标上优于基础模型，而且在不进行额外模型微调的情况下增强了DocVQA的透明度和可复现性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [106] [Dynamic EventNeRF: Reconstructing General Dynamic Scenes from Multi-view RGB and Event Streams](https://arxiv.org/abs/2412.06770)
> *动态EventNeRF：从多视角RGB和事件流重建通用动态场景*

*Viktor Rudnev, Gereon Fox, Mohamed Elgharib, Christian Theobalt, Vladislav Golyanik* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 动态场景重建, 事件相机, NeRF, 多视角, RGB-D融合

**Comment:** 17 pages, 13 figures, 7 tables; CVPRW 2025

> **TL;DR:** 提出首个结合多视角RGB和事件流的NeRF方法，用于在低光和快速运动下重建动态场景，性能优于纯RGB方法。

**AI_Comments:** 本文的创新点在于首次将事件相机数据与NeRF模型结合，解决了传统RGB相机在低光和快速运动下动态场景重建的局限性。通过融合两种不同模态的数据，显著提升了重建质量。此外，构建新的多视角事件流数据集也为该领域的研究提供了宝贵的资源。这项工作为未来在挑战性环境下进行高精度动态场景捕获奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 动态场景的体积重建在低光和快速运动下极具挑战，传统RGB相机因曝光时间限制易产生运动模糊。事件相机对光照依赖性小，更适合捕捉快速运动。

**Method:** 提出首个从稀疏多视角事件流和稀疏RGB帧中进行时空场景重建的方法。通过训练一系列交叉渐变的时间条件NeRF模型，每个模型对应一个短记录片段。这些片段通过基于事件和RGB的损失以及稀疏视图正则化进行监督。

**Result:** 该工作超越了基于RGB的基线方法，取得了最先进的结果，并开辟了多视角事件重建作为超越RGB相机快速场景捕获的新途径。

**Conclusion:** 本文成功提出了结合事件相机数据和RGB数据进行动态场景重建的新范式，证明了事件相机在挑战性环境下的潜力，并为未来研究提供了新的方向。

> **ai_Abstract:** 本文提出了一种名为Dynamic EventNeRF的创新方法，首次将多视角RGB图像和事件流结合起来，用于在低光和快速运动条件下重建通用动态场景。该方法通过训练时间条件化的NeRF模型序列，并结合事件与RGB损失进行监督。实验结果表明，Dynamic EventNeRF在动态场景重建方面优于现有基于RGB的方法，达到了最先进的性能，并为利用事件相机进行高速、复杂场景捕获开辟了新的研究方向。

> **摘要翻译:** 动态场景的体积重建是计算机视觉中的一个重要问题。在光照条件差和运动快速的情况下尤其具有挑战性。这部分是由于RGB相机的局限性：为了在低光下捕获帧，需要增加曝光时间，这会导致更多的运动模糊。相比之下，事件相机异步记录像素亮度变化，对光照的依赖性小得多，更适合记录快速运动。因此，我们提出了第一个从稀疏多视角事件流和稀疏RGB帧中进行时空场景重建的方法。我们训练了一系列交叉渐变的时间条件NeRF模型，每个模型对应一个短记录片段。单个片段通过基于事件和RGB的损失以及稀疏视图正则化进行监督。我们组装了一个真实世界的多视角相机设备，在物体周围放置了六个静态事件相机，并记录了一个具有挑战性运动的基准多视角事件流数据集。我们的工作超越了基于RGB的基线方法，产生了最先进的结果，并开辟了多视角事件重建作为超越RGB相机快速场景捕获的新途径，用于快速场景捕获。代码和数据已在https://4dqv.mpi-inf.mpg.de/DynEventNeRF/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [113] [Synthesizing Reality: Leveraging the Generative AI-Powered Platform Midjourney for Construction Worker Detection](https://arxiv.org/abs/2507.13221)
> *合成现实：利用生成式AI平台Midjourney进行建筑工人检测*

*Hongyang Zhao, Tianyu Liang, Sina Davari, Daeho Kim* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 生成式AI, Midjourney, 建筑工人检测, 数据合成, 深度学习

**Comment:** This work was presented at ASCE International Conference on Computing
  in Civil Engineering (i3CE) 2024 and is currently under consideration for
  publication in ASCE proceedings

> **TL;DR:** 本研究利用Midjourney生成合成图像数据集，以解决建筑工人检测中数据不足的问题，并评估了其在真实和合成数据上的表现。

**AI_Comments:** 该研究通过利用Midjourney生成大规模合成图像数据集来解决建筑工人检测领域的数据稀缺问题，具有创新性。其方法有效提升了模型性能，尤其是在合成数据上的优异表现，但同时也揭示了合成数据与真实数据之间可能存在的差距，提示未来研究需进一步缩小这一差距。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度神经网络在视觉AI方面取得了显著进展，但在建筑领域，数据多样性和数量不足仍然是制约建筑工人检测的挑战。

**Method:** 本研究提出了一种新颖的图像合成方法，利用生成式AI平台Midjourney。该方法通过制定3000个不同的提示，生成了12,000张强调真实性和多样性的合成图像。这些图像经过手动标注后，作为DNN训练的数据集。

**Result:** 在真实建筑图像数据集上的评估显示，模型在IoU阈值0.5时取得了0.937的平均精度（AP），在IoU阈值0.5到0.95时取得了0.642的AP。值得注意的是，模型在合成数据集上表现出接近完美的性能，在两个提及的阈值下分别达到了0.994和0.919的AP。

**Conclusion:** 这些发现揭示了生成式AI在解决DNN训练数据稀缺问题上的潜力和弱点。

> **ai_Abstract:** 本研究针对建筑领域视觉AI数据不足的问题，提出一种利用Midjourney生成合成图像数据集的新方法。通过生成12,000张合成图像并进行标注，用于训练深度神经网络。实验结果表明，该方法在真实数据集上对建筑工人检测表现良好，并在合成数据集上达到近乎完美的性能，证实了生成式AI在解决数据稀缺问题上的潜力和局限性。

> **摘要翻译:** 尽管深度神经网络（DNNs）的最新进展显著增强了视觉AI的能力，但数据多样性和数量不足的挑战依然存在，尤其是在建筑领域。本研究提出了一种新颖的图像合成方法，专为建筑工人检测量身定制，利用生成式AI平台Midjourney。该方法通过制定3000个不同的提示，生成了12,000张合成图像，强调图像的真实性和多样性。这些图像经过手动标注后，作为DNN训练的数据集。在真实建筑图像数据集上的评估取得了喜人的结果，模型在交并比（IoU）阈值为0.5时达到了0.937的平均精度（AP），在IoU阈值为0.5到0.95时达到了0.642的AP。值得注意的是，模型在合成数据集上表现出接近完美的性能，在两个提及的阈值下分别达到了0.994和0.919的AP。这些发现揭示了生成式AI在解决DNN训练数据稀缺问题上的潜力和弱点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [117] [Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation](https://arxiv.org/abs/2507.12761)
> *思而后画：分解情感语义与细粒度可控的富有表现力的人头生成*

*Hanlei Shi, Leyuan Qu, Yu Liu, Di Gao, Yuhua Zheng, Taihao Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 情感人头生成, 链式思考, 细粒度控制, 微表情, 文本驱动

**Comment:** 

> **TL;DR:** 提出“思而后画”框架，通过链式思考分解情感语义并采用渐进式引导去噪策略，实现细粒度可控的自然情感人头生成。

**AI_Comments:** 该论文的创新点在于引入了“链式思考”（CoT）来桥接高级情感语义与底层的生理性面部肌肉运动，以及借鉴艺术绘画过程提出了“渐进式引导去噪”策略来精细控制微表情。这使得情感人头生成更加自然和可控，对于提升人机交互的沉浸感和同理心具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前文本驱动的情感人头生成方法依赖预定义的离散情感标签，过度简化了真实面部肌肉运动的动态复杂性，导致无法实现自然的表情表达。

**Method:** 本研究提出了“思而后画”（Think-Before-Draw）框架，旨在解决情感语义的深度解析和细粒度表达优化两大挑战。具体方法包括：1) 引入链式思考（Chain-of-Thought, CoT），将抽象情感标签转化为生理学上基于面部肌肉运动的描述，实现从高级语义到可操作运动特征的映射。2) 提出渐进式引导去噪策略，灵感来源于艺术家肖像绘画过程，采用“全局情感定位-局部肌肉控制”机制，以优化生成视频中的微表情动态。

**Result:** 在MEAD和HDTF等广泛使用的基准测试上取得了最先进的性能。此外，收集了一组肖像图像来评估模型的零样本生成能力。

**Conclusion:** “思而后画”框架通过分解情感语义和优化细粒度表达，显著提升了文本驱动情感人头生成的自然度和可控性。

> **ai_Abstract:** 本研究提出“思而后画”框架，旨在解决文本驱动情感人头生成中情感表达不自然的问题。该框架通过引入链式思考（CoT）将抽象情感标签转化为具体的面部肌肉运动描述，并采用渐进式引导去噪策略，结合全局情感定位和局部肌肉控制，实现对微表情的细粒度优化。实验结果表明，该方法在MEAD和HDTF基准测试上达到了最先进的性能，并展现了零样本生成能力。

> **摘要翻译:** 情感人头生成已成为计算机视觉和多模态人工智能交叉领域的一个关键研究方向，其核心价值在于通过沉浸式和同理心交互增强人机交互。随着多模态大型语言模型的进步，情感人头生成的驱动信号已从音频和视频转向更灵活的文本。然而，当前文本驱动的方法依赖预定义的离散情感标签文本，过度简化了真实面部肌肉运动的动态复杂性，从而未能实现自然的情感表达。本研究提出了“思而后画”（Think-Before-Draw）框架，以解决两个关键挑战：（1）情感的深度语义解析——通过创新性地引入思维链（CoT），将抽象情感标签转化为生理学上基于面部肌肉运动的描述，从而实现从高级语义到可操作运动特征的映射；（2）细粒度表达优化——受艺术家肖像绘画过程的启发，提出了一种渐进式引导去噪策略，采用“全局情感定位-局部肌肉控制”机制来细化生成视频中的微表情动态。我们的实验表明，我们的方法在广泛使用的基准测试（包括MEAD和HDTF）上取得了最先进的性能。此外，我们收集了一组肖像图像来评估我们模型的零样本生成能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [119] [3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering](https://arxiv.org/abs/2507.13110)
> *3DKeyAD: 基于关键点引导点聚类的高分辨率三维点云异常检测*

*Zi Wang, Katsuya Hotta, Koichiro Kamide, Yawen Zou, Chao Zhang, Jun Yu* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 3D点云, 异常检测, 关键点引导, 点聚类, 多原型对齐

**Comment:** 

> **TL;DR:** 本文提出了一种名为3DKeyAD的注册基异常检测框架，通过多原型对齐和簇级差异分析，实现了高分辨率三维点云的精确异常定位。

**AI_Comments:** 该论文的创新点在于结合了多原型注册和关键点引导的聚类策略，有效地解决了高分辨率3D点云异常检测中计算成本高、对齐敏感和局部差异捕获难的问题。通过选择几何信息丰富的关键点作为簇中心，确保了局部比较的稳定性和意义。其在原始特征下即达到SOTA性能，显示了方法的鲁棒性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率三维点云在工业检测中对检测细微结构异常非常有效，但其密集和不规则的特性带来了计算成本高、对空间未对齐敏感以及难以捕获局部结构差异等挑战。

**Method:** 该方法引入了一个基于注册的异常检测框架，结合了多原型对齐和簇级差异分析。具体来说，每个测试样本首先与多个正常原型进行注册以进行直接结构比较。为了在局部层面评估异常，对点云进行聚类，并计算测试样本和原型在每个簇内的特征相似度。该方法采用关键点引导策略选择几何信息丰富的点作为簇中心，而不是随机选择。

**Result:** 在Real3D-AD基准测试上的大量实验表明，所提出的方法在对象级和点级异常检测方面都达到了最先进的性能，即使仅使用原始特征。

**Conclusion:** 3DKeyAD通过关键点引导的聚类和多原型注册，有效解决了高分辨率3D点云异常检测的挑战，并取得了最先进的性能。

> **ai_Abstract:** 3DKeyAD提出了一种用于高分辨率三维点云异常检测的注册基框架。该框架通过将测试样本与多个正常原型进行注册，并采用关键点引导的点聚类进行簇级差异分析，从而克服了高分辨率点云的挑战。实验证明，该方法在Real3D-AD基准测试上实现了最先进的异常检测性能。

> **摘要翻译:** 高分辨率三维点云在工业检测中对于检测细微结构异常非常有效。然而，其密集和不规则的性质带来了显著的挑战，包括高计算成本、对空间未对齐的敏感性以及难以捕获局部结构差异。本文介绍了一种基于注册的异常检测框架，该框架结合了多原型对齐和簇级差异分析，以实现精确的三维异常定位。具体来说，每个测试样本首先与多个正常原型进行注册，以实现直接的结构比较。为了在局部层面评估异常，对点云进行聚类，并计算测试样本和原型在每个簇内的特征相似度。该方法不随机选择簇中心，而是采用关键点引导策略，选择几何信息丰富的点作为簇中心。这确保了簇以特征丰富的区域为中心，从而实现更有意义和稳定的基于距离的比较。在Real3D-AD基准测试上的大量实验表明，所提出的方法在对象级和点级异常检测方面都达到了最先进的性能，即使仅使用原始特征。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [129] [Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications](https://arxiv.org/abs/2507.12945)
> *多模态大语言模型中图像与文本不确定性传播分析及其在心脏MR应用中的实践*

*Yucheng Tang, Yunguan Fu, Weixi Yi, Yipei Wang, Daniel C. Alexander, Rhodri Davies, Yipeng Hu* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 多模态大语言模型, 不确定性传播, 心脏MR, 临床应用, 数据效率

**Comment:** It is accepted by 28th International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI) 2025

> **TL;DR:** 本文提出多模态不确定性传播模型（MUPM），用于表征多模态大语言模型（MLLM）中图像、文本及联合输入的不确定性传播。研究表明MUPM能用少量样本稳健优化，在不同数据分布和下游任务中具有泛化性，并可直接应用于心脏MR等临床场景，实现不确定性估计和冗余因素识别。

**AI_Comments:** 该论文解决了理解多模态大语言模型（MLLMs）中不确定性，尤其是在临床应用方面的一个关键空白。所提出的MUPM提供了一种表征多模态不确定性传播的新颖方法，其在有限数据下表现出的泛化性和效率对于实际部署具有重要意义。特别是其在心脏疾病预测中的直接临床适用性，凸显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）能够整合多模态信息，但目前在大型MLLMs背景下，输入模态间的相互关系、单模态数据带来的不确定性以及不确定性分解的潜在临床应用尚未被充分理解。

**Method:** 本文提出了一种基于不确定性传播的多模态不确定性传播模型（MUPM），以表征MLLM输入中仅图像、仅文本和联合图像-文本变异引起的不确定性之间的关系。研究使用包含心脏MR扫描和数字健康记录的真实临床数据，并描述了MUPM如何通过少量样本进行鲁棒优化。

**Result:** 研究表明，MUPM可以通过少量样本进行鲁棒优化，并且拟合的MUPM在不同的输入数据分布和下游任务中都具有泛化性。这种可迁移性可导致直接的临床应用，其中不确定性可以被估计和稳健分析。此外，实验证明了MUPM在估计总体不确定性所需多模态数据方面的效率及其识别冗余因素的能力。

**Conclusion:** 本文提出的多模态不确定性传播模型（MUPM）能够有效表征多模态大语言模型中的不确定性传播。该模型展现了鲁棒的优化能力、良好的泛化性以及在临床应用中的价值，尤其是在不确定性估计、分析以及识别冗余因素方面，为心脏疾病预测等任务提供了实用且高效的解决方案。

> **ai_Abstract:** 本文提出了一种多模态不确定性传播模型（MUPM），旨在分析多模态大语言模型（MLLMs）中图像、文本及其组合所产生的不确定性如何传播。研究利用心脏MR数据证明，MUPM能够用有限样本进行稳健优化，并在不同数据和任务之间泛化。该模型为不确定性的鲁棒估计和分析提供了直接的临床应用价值，包括识别冗余因素。

> **摘要翻译:** 多模态大语言模型（MLLMs）能够处理和整合来自多模态源（如文本和图像）的信息。然而，在大型MLLMs的背景下，输入模态之间的相互关系、由于个体单模态数据引起的不确定性以及随之而来的不确定性分解的潜在临床应用尚未完全理解。在这项工作中，我们提出了一种基于不确定性传播的多模态不确定性传播模型（MUPM），用于表征MLLM输入中仅图像、仅文本和联合图像-文本变异引起的不确定性之间的关系。使用包含心脏MR扫描和数字健康记录的真实临床数据，我们描述了MUPM可以通过少量样本进行鲁棒优化。然后我们展示了拟合的MUPM在不同的输入数据分布，甚至令人惊讶地在不同的下游任务中都具有泛化性。这种可迁移性可能可以通过共享预训练、相对轻量的MLLM微调以及MUPM的低维特性来解释。更重要的是，这种学习到的可迁移性量化了这些不确定性之间的关系，从而带来了直接的临床应用，其中不确定性可以被估计并因此对不同数据甚至一套新的心脏疾病预测任务进行鲁棒分析。此外，我们实验性地展示了估计总体不确定性所需的多模态数据的效率及其识别冗余因素的能力，这两者都被认为是所提出的MUPM的实用且具有临床应用价值的应用。代码可在https://github.com/yucheng722/MUPM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [137] [Prompt-driven Transferable Adversarial Attack on Person Re-Identification with Attribute-aware Textual Inversion](https://arxiv.org/abs/2502.19697)
> *提示驱动的可迁移行人重识别对抗性攻击，基于属性感知的文本反演*

*Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yaonan Wang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 行人重识别, 对抗性攻击, 可迁移性, 文本反演, 视觉语言模型

**Comment:** 

> **TL;DR:** 本文提出AP-Attack，通过属性感知的文本反演，有效扰乱行人重识别模型的细粒度特征，实现最先进的可迁移对抗性攻击。

**AI_Comments:** 本文创新性地提出利用视觉语言模型的图像-文本对齐能力，通过属性感知的文本反演来破坏行人图像的细粒度语义特征，实现了更具针对性的对抗性攻击。这种方法不仅提升了攻击的可迁移性，也为深入理解行人重识别模型的脆弱性提供了新的视角，对于安全监控领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探究行人重识别模型的脆弱性。现有基于视觉语言模型的攻击，由于过分强调整体表示中的判别语义，缺乏对细粒度语义特征的全面扰动。

**Method:** 提出属性感知提示攻击（AP-Attack），利用视觉语言模型的图像-文本对齐能力，通过破坏属性特定的文本嵌入来显式扰乱行人图像的细粒度语义特征。为此，设计文本反演网络将行人图像映射到代表语义嵌入的伪标记，并以对比学习的方式与图像和预定义的提示模板一起训练。

**Result:** AP-Attack在跨模型和数据集攻击场景中实现了最先进的可迁移性，平均下降率比以前的方法显著高出22.9%。

**Conclusion:** AP-Attack通过破坏细粒度语义特征，有效提升了行人重识别对抗性攻击的可迁移性，并达到了最先进的性能。

> **ai_Abstract:** 本文针对行人重识别模型在安全监控中的重要性及其脆弱性，提出了一种名为AP-Attack的新型可迁移对抗性攻击方法。该方法利用视觉语言模型的图像-文本对齐能力，通过属性感知的文本反演网络，将行人图像映射为代表细粒度语义的伪标记，并破坏这些属性特定的文本嵌入，从而有效扰乱行人图像的细粒度语义特征。实验证明，AP-Attack在跨模型和数据集攻击场景中实现了最先进的可迁移性，平均下降率显著优于现有方法22.9%。

> **摘要翻译:** 行人重识别（re-id）模型在安全监控系统中至关重要，需要可迁移的对抗性攻击来探究其脆弱性。最近，基于视觉语言模型（VLM）的攻击通过攻击VLM的通用图像和文本特征显示出卓越的可迁移性，但由于过分强调整体表示中的判别语义，它们缺乏全面的特征扰动。在本文中，我们引入了属性感知提示攻击（AP-Attack），这是一种新颖的方法，它利用VLM的图像-文本对齐能力，通过破坏属性特定的文本嵌入来显式扰乱行人图像的细粒度语义特征。为了获得针对单个属性的个性化文本描述，设计了文本反演网络，将行人图像映射到代表语义嵌入的伪标记，并以对比学习的方式与图像和预定义的明确描述行人属性的提示模板一起进行训练。反转后的良性和对抗性细粒度文本语义有助于攻击者有效进行彻底的扰动，从而增强对抗性样本的可迁移性。大量实验表明，AP-Attack在跨模型和数据集攻击场景中实现了最先进的可迁移性，平均下降率比以前的方法显著高出22.9%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [139] [MindJourney: Test-Time Scaling with World Models for Spatial Reasoning](https://arxiv.org/abs/2507.12508)
> *心智旅程：利用世界模型进行空间推理的测试时缩放*

*Yuncong Yang, Jiageng Liu, Zheyuan Zhang, Siyuan Zhou, Reuben Tan, Jianwei Yang, Yilun Du, Chuang Gan* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-07-16**

**Keywords:** 空间推理, 视觉语言模型, 世界模型, 测试时缩放, 3D动态

**Comment:** Project Page: https://umass-embodied-agi.github.io/MindJourney

> **TL;DR:** MindJourney是一个测试时缩放框架，通过将视觉语言模型（VLM）与可控世界模型结合，提升其在3D空间推理任务上的表现，无需微调即可显著提高性能。

**AI_Comments:** MindJourney的创新之处在于其“测试时缩放”的理念，通过将VLM与世界模型结合，在推理阶段动态生成3D信息，而非依赖于预训练或微调。这种即插即用的特性对于提升现有VLMs的3D推理能力具有重要意义。该方法通过模拟多视角证据来增强VLM的理解，为具身智能任务提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的视觉语言模型（VLMs）在3D空间推理任务上表现不佳，例如预测自我中心运动后的场景变化，因为它们感知2D图像但缺乏3D动态的内部模型。

**Method:** 我们提出了MindJourney，一个测试时缩放框架。它将视觉语言模型（VLM）与基于视频扩散的可控世界模型耦合。VLM迭代地勾勒出简洁的相机轨迹，而世界模型在每一步合成相应的视图。VLM随后对在交互探索过程中收集到的多视图证据进行推理。

**Result:** MindJourney在代表性的空间推理基准SAT上平均实现了超过8%的性能提升，且无需任何微调。同时，该方法也改进了通过强化学习训练的测试时推理VLM。

**Conclusion:** 将视觉语言模型与世界模型结合进行测试时缩放，为稳健的3D推理提供了一种简单、即插即用的途径。这表明利用世界模型进行测试时缩放具有潜力。

> **ai_Abstract:** 本研究提出了MindJourney，一个创新的测试时缩放框架，旨在解决现有视觉语言模型（VLMs）在3D空间推理方面的不足。通过将VLM与一个基于视频扩散的可控世界模型相结合，MindJourney允许VLM通过迭代生成相机轨迹和合成视图来进行交互式探索和多视图推理，从而弥补了VLM缺乏3D动态内部模型的缺陷。该方法无需微调即可在空间推理基准测试中显著提升性能，并改进了通过强化学习训练的VLM，展示了世界模型在测试时缩放中实现鲁棒3D推理的巨大潜力。

> **摘要翻译:** 3D空间中的空间推理是人类认知核心，对导航和操作等具身任务不可或缺。然而，最先进的视觉语言模型（VLMs）在预测自我中心运动后场景外观等简单任务上经常遇到困难：它们感知2D图像，但缺乏3D动态的内部模型。因此，我们提出了MindJourney，一个测试时缩放框架，通过将其与基于视频扩散的可控世界模型耦合，赋予VLM这种缺失的能力。VLM迭代地勾勒出简洁的相机轨迹，而世界模型在每一步合成相应的视图。VLM随后对在交互探索过程中收集到的多视图证据进行推理。在不进行任何微调的情况下，我们的MindJourney在代表性的空间推理基准SAT上平均实现了超过8%的性能提升，表明将VLM与世界模型配对进行测试时缩放为稳健的3D推理提供了一条简单、即插即用的途径。同时，我们的方法也改进了通过强化学习训练的测试时推理VLM，这展示了我们利用世界模型进行测试时缩放方法的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [146] [Continuous Marine Tracking via Autonomous UAV Handoff](https://arxiv.org/abs/2507.12763)
> *通过自主无人机交接实现连续海洋追踪*

*Heegyeong Kim, Alice James, Avishkar Seth, Endrowednes Kuantama, Jane Williamson, Yimeng Feng, Richard Han* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 海洋追踪, 无人机, 自主系统, 交接协议, 鲨鱼追踪

**Comment:** 6 pages, 5 figures, to be published in DroNet '25: Proceedings of the
  10th Workshop on Micro Aerial Vehicle Networks, Systems, and Applications

> **TL;DR:** 该论文提出了一种用于连续海洋动物追踪的自主无人机系统，其特色是无人机间交接协议，以扩展覆盖范围，并在鲨鱼追踪上表现良好。

**AI_Comments:** 该论文通过创新性的无人机间交接协议解决了单无人机电池寿命的关键限制，从而在长时间海洋动物追踪方面取得了重大进展。将鲁棒的视觉系统与用于无缝无人机过渡的交接机制相结合是其主要创新点，为动态环境中更具可扩展性和连续性的自主监测应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决在动态海洋环境中对海洋动物（特别是鲨鱼）进行连续、实时追踪的挑战，特别是通过克服单无人机电池限制来延长操作覆盖范围。

**Method:** 该系统集成了机载计算机、稳定型RGB-D相机和定制训练的OSTrack管道，用于视觉识别。关键创新是无人机间交接协议，用于在无人机之间无缝转移追踪职责，通过高置信度特征匹配进行目标转移。

**Result:** 系统在包含5,200帧的鲨鱼数据集中进行了评估，在100赫兹的实时飞行控制中实现了81.9%的追踪成功率，并对遮挡、光照变化和背景杂波具有鲁棒性。无缝无人机交接框架实现了82.9%的目标覆盖率。

**Conclusion:** 研究结果证实了协调无人机操作在扩展海洋追踪方面的可行性，并为可扩展的自主监测奠定了基础。

> **ai_Abstract:** 本文提出了一种自主无人机视觉系统，旨在对鲨鱼等海洋动物进行连续、实时追踪。该系统结合了机载计算机、RGB-D相机和定制的OSTrack管道，以实现鲁棒的视觉识别。核心创新是无人机间交接协议，该协议能够实现无人机之间追踪任务的无缝转移，从而延长了操作时间。在鲨鱼数据集上进行评估，该系统实现了81.9%的追踪成功率，并且通过交接框架实现了82.9%的目标覆盖率，证明了协调无人机在扩展海洋监测方面的可行性。

> **摘要翻译:** 这篇论文介绍了一种自主无人机视觉系统，用于在动态海洋环境中对海洋动物（特别是鲨鱼）进行连续、实时追踪。该系统集成了机载计算机、稳定型RGB-D相机和定制训练的OSTrack管道，使其能够在挑战性的光照、遮挡和海况条件下进行视觉识别。一个关键的创新是无人机间交接协议，它实现了无人机之间追踪责任的无缝转移，从而将操作覆盖范围扩展到单无人机电池限制之外。系统性能在包含5,200帧的鲨鱼数据集中进行了评估，在100赫兹的实时飞行控制中实现了81.9%的追踪成功率，并对遮挡、光照变化和背景杂波具有鲁棒性。我们提出了一个无缝的无人机交接框架，通过高置信度特征匹配尝试目标转移，实现了82.9%的目标覆盖率。这些结果证实了协调无人机操作在扩展海洋追踪方面的可行性，并为可扩展的自主监测奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [154] [Monocular 3D Hand Pose Estimation with Implicit Camera Alignment](https://arxiv.org/abs/2506.11133)
> *单目3D手部姿态估计与隐式相机对齐*

*Christos Pantazopoulos, Spyridon Thermos, Gerasimos Potamianos* | **Category: cs.CV, cs.GR, cs.LG, eess.IV** | **Updated: 2025-07-16**

**Keywords:** 3D手部姿态估计, 单目, 相机对齐, 关键点, 优化管道

**Comment:** Code is available at the project page
  https://cpantazop.github.io/HandRepo/

> **TL;DR:** 该工作提出了一种优化管道，用于从2D关键点输入估计3D手部姿态，通过关键点对齐和指尖损失来克服相机参数需求，并在基准测试中表现出竞争力。

**AI_Comments:** 该论文的创新点在于提出了一个无需先验相机参数知识的3D手部姿态估计方法，通过关键点对齐和指尖损失克服了这一挑战，这对于“野外”应用具有重要意义。其重要性在于提升了单目3D手部姿态估计的实用性。一个潜在的局限性是2D关键点估计的精度对最终结果的敏感性，这意味着其性能可能受限于前端2D关键点检测器的质量。

<details>
  <summary>Details</summary>

**Motivation:** 从单张彩色图像估计3D手部关节是一个重要问题，在增强现实（AR）、虚拟现实（VR）、人机交互（HCI）和机器人技术中都有应用。其面临的挑战包括缺乏深度信息、遮挡、关节复杂性以及需要相机参数知识。

**Method:** 本文提出了一种优化管道，用于从2D关键点输入估计3D手部关节。该管道包括一个关键点对齐步骤和一个指尖损失，以克服需要知道或估计相机参数的问题。

**Result:** 该方法在EgoDexter和Dexter+Object基准测试上与最先进的方法表现出竞争力。同时，在处理“野外”图像时，无需任何先验相机知识也能展示其鲁棒性。定量分析强调了2D关键点估计精度的敏感性，尽管使用了手部先验。

**Conclusion:** 论文提出了一种无需先验相机知识的单目3D手部姿态估计算法，并在多个基准测试中表现出竞争力，尽管2D关键点估计精度仍是挑战。

> **ai_Abstract:** 本文提出了一种创新的优化管道，用于从单张彩色图像中的2D关键点输入估计3D手部姿态。该方法通过引入关键点对齐步骤和指尖损失，成功解决了传统方法中对相机参数知识的依赖问题。实验结果表明，该方法在多个标准基准测试中达到了与SOTA相当的性能，并且在处理无相机先验的“野外”图像时表现出良好的鲁棒性，尽管2D关键点估计的精度仍是影响整体性能的关键因素。

> **摘要翻译:** 从单个彩色图像估计3D手部关节是一个重要问题，在增强现实（AR）、虚拟现实（VR）、人机交互（HCI）和机器人技术中都有应用。除了深度信息缺失外，遮挡、关节复杂性以及对相机参数知识的需求带来了额外的挑战。在这项工作中，我们提出了一种优化管道，用于从2D关键点输入估计3D手部关节，其中包括一个关键点对齐步骤和一个指尖损失，以克服需要知道或估计相机参数的问题。我们在EgoDexter和Dexter+Object基准测试上评估了我们的方法，结果表明它与最先进的方法具有竞争力，同时还展示了在处理“野外”图像时无需任何先验相机知识的鲁棒性。我们的定量分析强调了2D关键点估计精度的敏感性，尽管使用了手部先验。代码可在项目页面https://cpantazop.github.io/HandRepo/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [164] [World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving](https://arxiv.org/abs/2507.12762)
> *基于世界模型的自动驾驶事故预测端到端场景生成*

*Yanchen Guan, Haicheng Liao, Chengyue Wang, Xingcheng Liu, Jiaxun Zhang, Zhenning Li* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 事故预测, 自动驾驶, 世界模型, 场景生成, 时间推理

**Comment:** 

> **TL;DR:** 该论文提出了一个综合框架，利用世界模型进行场景生成和动态预测模型来预测自动驾驶中的事故，解决了数据稀缺和不完整的问题。

**AI_Comments:** 该论文解决了自动驾驶中事故预测的关键问题，这对于安全性至关重要。其创新点在于将生成式场景增强与自适应时间推理相结合，利用世界模型进行数据丰富和鲁棒的预测模型。发布新的基准数据集也是对该领域的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 可靠的交通事故预测对于推进自动驾驶系统至关重要。然而，这一目标受到两个基本挑战的限制：一是多样化、高质量训练数据的稀缺性；二是由于环境干扰或传感器缺陷，关键物体级线索的频繁缺失。

**Method:** 本文提出了一个结合生成式场景增强和自适应时间推理的综合框架。具体来说，开发了一个视频生成管道，利用领域信息提示引导的世界模型来创建高分辨率、统计一致的驾驶场景，特别丰富了边缘案例和复杂交互的覆盖范围。同时，构建了一个动态预测模型，通过强化的图卷积和膨胀时间算子编码时空关系，有效解决了数据不完整性和瞬态视觉噪声。此外，发布了一个新的基准数据集，旨在更好地捕捉多样化的真实世界驾驶风险。

**Result:** 在公共和新发布数据集上的大量实验证实，该框架提高了事故预测的准确性和提前时间。

**Conclusion:** 该框架为安全关键型自动驾驶应用中当前的数据和建模限制提供了鲁棒的解决方案。

> **ai_Abstract:** 本文提出了一种用于自动驾驶事故预测的新颖框架，解决了数据稀缺和物体线索不完整的问题。该框架集成了基于世界模型的视频生成管道以增强场景多样性，以及一个利用强化图卷积和膨胀时间算子处理时空关系和噪声的动态预测模型。该框架在新的基准数据集上得到了支持，并展示了在事故预测方面更高的准确性和更长的提前时间，为自动驾驶安全提供了鲁棒的解决方案。

> **摘要翻译:** 可靠的交通事故预测对于推进自动驾驶系统至关重要。然而，这一目标受到两个基本挑战的限制：一是多样化、高质量训练数据的稀缺性；二是由于环境干扰或传感器缺陷，关键物体级线索的频繁缺失。为了解决这些问题，我们提出了一个结合生成式场景增强和自适应时间推理的综合框架。具体来说，我们开发了一个视频生成管道，利用领域信息提示引导的世界模型来创建高分辨率、统计一致的驾驶场景，特别丰富了边缘案例和复杂交互的覆盖范围。同时，我们构建了一个动态预测模型，通过强化的图卷积和膨胀时间算子编码时空关系，有效解决了数据不完整性和瞬态视觉噪声。此外，我们发布了一个新的基准数据集，旨在更好地捕捉多样化的真实世界驾驶风险。在公共和新发布数据集上的大量实验证实，我们的框架提高了事故预测的准确性和提前时间，为安全关键型自动驾驶应用中当前的数据和建模限制提供了鲁棒的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [165] [LoViC: Efficient Long Video Generation with Context Compression](https://arxiv.org/abs/2507.12952)
> *LoViC：基于上下文压缩的高效长视频生成*

*Jiaxiu Jiang, Wenbo Li, Jingjing Ren, Yuping Qiu, Yong Guo, Xiaogang Xu, Han Wu, Wangmeng Zuo* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 长视频生成, 扩散变换器, 上下文压缩, FlexFormer, Q-Former

**Comment:** Project page: https://jiangjiaxiu.github.io/lovic/

> **TL;DR:** LoViC是一个基于DiT的框架，通过FlexFormer对视频和文本进行统一的潜在表示压缩，实现高效、连贯的长视频生成，解决了自注意力机制的二次复杂度问题。

**AI_Comments:** LoViC的创新点在于其引入了FlexFormer自编码器，通过统一的潜在表示对视频和文本进行高效压缩，并结合Q-Former架构实现了可变长度输入和可调压缩率，这对于解决长视频生成中的计算复杂度问题至关重要。其分段生成和位置感知的时间上下文编码也提升了生成视频的连贯性和模型的泛化能力，使其能够应用于多种视频生成任务。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散变换器（DiTs）在文本到视频生成方面取得了进展，但由于自注意力的二次复杂度，扩展到长时内容仍然具有挑战性。现有的稀疏注意力或时间自回归模型虽然有所缓解，但往往会损害时间连贯性或可扩展性。

**Method:** 本文提出了LoViC，一个基于DiT的框架，通过分段生成过程来生成长而连贯的视频。其核心是FlexFormer，一个表达性自编码器，它将视频和文本联合压缩成统一的潜在表示。FlexFormer支持可变长度输入，并通过基于Q-Former架构的单一查询令牌设计实现线性可调的压缩率。此外，模型通过位置感知机制编码时间上下文，支持预测、回溯、插值和多镜头生成。

**Result:** 在各种任务上的大量实验验证了LoViC方法的有效性和多功能性。

**Conclusion:** LoViC通过其创新的上下文压缩和分段生成策略，有效解决了长视频生成中自注意力机制的二次复杂度问题，展示了在多种视频生成任务中的高效性和多功能性。

> **ai_Abstract:** LoViC是一个创新的扩散变换器（DiT）框架，旨在解决长视频生成中自注意力机制的二次复杂度问题。它通过分段生成过程实现连贯的长视频生成，核心组件是FlexFormer自编码器，能够将视频和文本压缩为统一的潜在表示，并支持可变长度输入和可调压缩率。该模型还利用位置感知机制处理时间上下文，支持多种生成模式。实验证明了其在各种任务中的有效性和多功能性。

> **摘要翻译:** 尽管扩散变换器（DiTs）在文本到视频生成方面取得了最新进展，但由于自注意力的二次复杂度，扩展到长时间内容仍然具有挑战性。虽然先前的努力——如稀疏注意力和时间自回归模型——提供了一定程度的缓解，但它们通常会损害时间连贯性或可扩展性。我们引入了LoViC，一个基于DiT的框架，在百万级开放域视频上进行训练，旨在通过分段生成过程产生长而连贯的视频。我们方法的核心是FlexFormer，一个表达性自编码器，它将视频和文本联合压缩成统一的潜在表示。它支持可变长度输入，并通过基于Q-Former架构的单一查询令牌设计实现线性可调的压缩率。此外，通过位置感知机制编码时间上下文，我们的模型在统一范式内无缝支持预测、回溯、插值和多镜头生成。跨越不同任务的广泛实验验证了我们方法的有效性和多功能性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [167] [LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents](https://arxiv.org/abs/2503.10200)
> *LVAgent: 通过多轮动态协作的MLLM智能体进行长视频理解*

*Boyu Chen, Zhengrong Yue, Siran Chen, Zikang Wang, Yang Liu, Peng Li, Yali Wang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 长视频理解, MLLM智能体, 多轮协作, 动态协作, LVAgent

**Comment:** accepted in ICCV 2025

> **TL;DR:** 现有MLLM智能体方法在长视频理解上表现有限。LVAgent引入了MLLM智能体的多轮动态协作框架，显著提升了长视频理解性能，超越了现有SOTA模型。

**AI_Comments:** LVAgent的创新之处在于其引入了MLLM智能体的多轮动态协作机制，而非依赖单一智能体或外部工具。这种协作和迭代反思的方法有效地提升了长视频理解的性能，超越了现有SOTA模型，显示出在处理复杂、长时间序列数据方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有MLLM在处理长视频的时间上下文方面面临重大挑战，导致单MLLM智能体方法（即使有工具支持）对长视频的理解仍不充分，性能有限。

**Method:** LVAgent是一个实现MLLM智能体多轮动态协作的框架。其方法包含四个关键步骤：1) 选择：根据任务从模型库中预选合适的智能体组成团队。2) 感知：设计高效的长视频检索方案，提高关键时间段覆盖率并保持计算效率。3) 行动：智能体回答问题并交换理由。4) 反思：评估每轮讨论中智能体的表现，并优化团队进行动态协作，通过多轮协作迭代完善答案。

**Result:** LVAgent是首个在长视频理解任务上超越所有闭源模型（如GPT-4o）和开源模型（如InternVL-2.5和Qwen2-VL）的智能体系统方法。它在四个主流长视频理解任务上达到了80%的准确率，并在LongVideoBench上将准确率提高了13.3%。

**Conclusion:** LVAgent通过其独特的多轮动态协作机制，成功解决了长视频理解中的现有挑战，并在性能上显著超越了当前最先进的闭源和开源模型，证明了其在复杂长视频任务中的有效性和优越性。

> **ai_Abstract:** LVAgent是一个创新框架，旨在通过MLLM智能体的多轮动态协作来解决长视频理解的挑战。该方法包含智能体选择、高效感知、交互式行动和动态反思四个关键步骤，以迭代优化答案。实验结果表明，LVAgent在长视频理解任务上显著优于现有闭源和开源模型，在主流任务中达到80%的准确率，并在LongVideoBench上实现了13.3%的准确率提升。

> **摘要翻译:** 现有MLLM在建模长视频中的时间上下文方面遇到重大挑战。目前，主流的基于智能体的方法使用外部工具辅助单个MLLM回答长视频问题。尽管有这种基于工具的支持，但单个MLLM仍然只能对长视频提供部分理解，导致性能有限。为了更好地解决长视频任务，我们引入了LVAgent，这是第一个在长视频理解中实现MLLM智能体多轮动态协作的框架。我们的方法包括四个关键步骤：1）选择：我们根据不同的任务，从模型库中预先选择合适的智能体，以组建最佳智能体团队。2）感知：我们为长视频设计了一种有效的检索方案，以提高关键时间段的覆盖率，同时保持计算效率。3）行动：智能体回答长视频问题并交换理由。4）反思：我们评估每个智能体在每轮讨论中的表现，并优化智能体团队以进行动态协作。智能体通过MLLM智能体的多轮动态协作迭代地完善他们的答案。LVAgent是第一个在长视频理解任务中超越所有闭源模型（如GPT-4o）和开源模型（如InternVL-2.5和Qwen2-VL）的智能体系统方法。我们的LVAgent在四个主流长视频理解任务上达到了80%的准确率。值得注意的是，LVAgent在LongVideoBench上的准确率提高了13.3%。代码可在https://github.com/64327069/LVAgent 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [172] [Leveraging Language Prior for Infrared Small Target Detection](https://arxiv.org/abs/2507.13113)
> *利用语言先验进行红外小目标检测*

*Pranav Singh, Pravendra Singh* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 红外小目标检测, 多模态, 语言先验, GPT-4, 数据集

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的多模态红外小目标检测（IRSTD）框架，通过结合语言先验和构建新的多模态数据集，显著提升了IRSTD的性能。

**AI_Comments:** 本文为红外小目标检测引入了一种创新的多模态方法，这在传统上是一个仅依赖图像数据的领域。通过创造性地结合语言先验并构建了一个急需的多模态数据集，该研究不仅开辟了新的研究方向，也显著推动了该领域的发展。其中利用GPT-4生成文本描述是其一个特别新颖的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 红外小目标检测（IRSTD）因目标尺寸小、分布稀疏以及现有方法仅依赖图像模态而面临挑战。当前缺乏多模态红外数据集是限制现有方法发展的关键因素。

**Method:** 提出了一种新颖的多模态IRSTD框架，该框架融入语言先验来指导小目标检测。具体地，利用从语言先验中导出的语言引导注意力权重来增强模型能力。利用先进的GPT-4视觉模型，通过精心设计的提示工程生成红外图像中小目标位置的文本描述。针对多模态红外数据集的缺失，团队构建了一个包含图像和文本模态的多模态红外数据集，该数据集扩展了流行的IRSTD-1k和NUDT-SIRST数据集。

**Result:** 通过广泛的实验和全面的消融研究，证明了所提方法的有效性。在NUAA-SIRST子集上，相对于最先进方法，IoU、nIoU、Pd和Fa分别相对提高了9.74%、13.02%、1.25%和67.87%。在LangIR数据集的IRSTD-1k子集上，IoU、nIoU、Pd和Fa分别相对提高了4.41%、2.04%、2.01%和113.43%。

**Conclusion:** 本文提出的多模态框架通过结合语言先验，显著提升了红外小目标检测的性能，并通过构建新数据集克服了现有方法的局限性，实验结果表明其优于现有最先进方法。

> **ai_Abstract:** 本文针对红外小目标检测（IRSTD）中目标小、分布稀疏以及现有方法仅依赖图像模态的局限性，提出了一种新颖的多模态IRSTD框架。该框架利用语言先验引导的注意力权重，并通过GPT-4生成目标位置的文本描述。为弥补多模态数据缺失，作者构建了一个新的多模态红外数据集。实验结果表明，该方法在多个指标上显著优于现有最先进方法，验证了结合文本信息与图像数据提升IRSTD能力的有效性。

> **摘要翻译:** IRSTD（红外小目标检测）用于检测红外模糊背景中的小目标，对各种应用至关重要。由于目标尺寸小及其在红外小目标数据集中的稀疏分布，检测任务具有挑战性。尽管现有的IRSTD方法和数据集已取得重大进展，但它们仅依赖图像模态而受到限制。深度学习和大型视觉-语言模型的最新进展在各种视觉识别任务中表现出卓越的性能。在这项工作中，我们提出了一种新颖的多模态IRSTD框架，该框架结合语言先验来指导小目标检测。我们利用从语言先验中导出的语言引导注意力权重来增强模型进行IRSTD的能力，提出了一种结合文本信息与图像数据以提高IRSTD能力的新方法。利用最先进的GPT-4视觉模型，我们生成提供红外图像中小目标位置的文本描述，并采用精心的提示工程以确保提高准确性。由于缺乏多模态红外数据集，现有的IRSTD方法仅依赖图像数据。为了解决这一缺点，我们策划了一个包含图像和文本模态的多模态红外数据集用于小目标检测，该数据集扩展了流行的IRSTD-1k和NUDT-SIRST数据集。我们通过广泛的实验和全面的消融研究验证了我们方法的有效性。结果表明，与最先进的方法相比，在NUAA-SIRST子集上，IoU、nIoU、Pd和Fa的相对百分比差异分别为9.74%、13.02%、1.25%和67.87%，在LangIR数据集的IRSTD-1k子集上分别为4.41%、2.04%、2.01%和113.43%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [181] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
> *Mono-InternVL-1.5：迈向更经济、更快速的单体多模态大语言模型*

*Gen Luo, Wenhan Dou, Wenhao Li, Zhaokai Wang, Xue Yang, Changyao Tian, Hao Li, Weiyun Wang, Wenhai Wang, Xizhou Zhu, Yu Qiao, Jifeng Dai* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-16**

**Keywords:** 单体多模态大语言模型, Mono-InternVL-1.5, 专家混合, 内源视觉预训练, 成本效率

**Comment:** 

> **TL;DR:** 本文介绍了Mono-InternVL-1.5，这是一种更经济、更快速的单体多模态大语言模型，通过嵌入新的视觉参数空间和创新的内源视觉预训练（EViP++）解决了现有单体MLLM的不稳定优化和灾难性遗忘问题，并在多项基准测试中取得了有竞争力的性能，同时显著降低了训练和推理成本。

**AI_Comments:** 该论文在解决单体多模态大语言模型所面临的优化稳定性和成本效率问题上具有创新性。通过引入新的视觉参数空间、delta微调、多模态专家混合架构以及改进的内源视觉预训练（EViP++），该模型成功地在保持甚至超越现有模型性能的同时，显著降低了训练和推理成本，尤其是首次token延迟的显著降低，这对于实际应用至关重要。模型设计中融合CUDA内核以加速MoE操作的思路也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有单体多模态大语言模型（MLLMs）的结构和预训练策略常面临优化不稳定和灾难性遗忘问题，且数据成本较高。

**Method:** 本文提出了一种新的单体多模态大语言模型Mono-InternVL，通过将新的视觉参数空间嵌入到预训练LLM中，并利用delta-tuning实现视觉知识的稳定学习。Mono-InternVL采用了多模态专家混合（MoE）架构，并设计了内源视觉预训练（EViP）进行逐步学习。为了降低成本和提高性能，进一步提出了Mono-InternVL-1.5，它配备了改进的EViP（EViP++），引入了额外的视觉注意力专家，并以高效的方式重组了预训练过程。推理时，它包含一个融合的CUDA内核以加速MoE操作。

**Result:** Mono-InternVL在15项基准测试中的12项上超越了现有单体MLLMs，例如在OCRBench上比Emu3提高了114点。与模块化对应模型InternVL-1.5相比，Mono-InternVL-1.5在保持相似多模态性能的同时，将首个token的延迟降低了高达69%。Mono-InternVL-1.5显著降低了训练和推理成本，同时保持了与Mono-InternVL相当的竞争力。

**Conclusion:** Mono-InternVL-1.5成功地解决了单体多模态大语言模型面临的优化不稳定和灾难性遗忘问题，并通过创新的架构和预训练策略，实现了更低的成本和更快的推理速度，同时保持了领先的性能，证明了单体MLLM在效率和性能上的潜力。

> **ai_Abstract:** 本文提出了一种名为Mono-InternVL-1.5的单体多模态大语言模型（MLLM），旨在解决现有单体MLLM优化不稳定和灾难性遗忘的问题，并降低其高昂的成本。该模型通过将新的视觉参数空间嵌入到预训练LLM中，并结合delta微调实现视觉知识的稳定学习。在此基础上，研究者开发了Mono-InternVL，它采用多模态专家混合架构和创新的内源视觉预训练（EViP）。为进一步提升效率和性能，又推出了Mono-InternVL-1.5，该版本通过改进的EViP（EViP++）引入更多视觉注意力专家并优化预训练流程，并在推理时使用融合CUDA内核加速MoE操作。实验结果表明，Mono-InternVL-1.5在多项基准测试中表现出色，超越了现有单体MLLM，并显著降低了训练和推理成本，同时在多模态性能上与模块化模型InternVL-1.5相当，并大幅缩短了首个token的延迟。

> **摘要翻译:** 本文关注单体多模态大语言模型（MLLMs），它将视觉编码和语言解码集成到一个模型中。现有单体MLLMs的结构和预训练策略常遭受优化不稳定和灾难性遗忘的问题。为了解决这些挑战，我们的核心思想是将一个新的视觉参数空间嵌入到预训练的LLM中，通过delta微调实现从嘈杂数据中稳定学习视觉知识。基于此原则，我们首先介绍了Mono-InternVL，这是一种先进的单体MLLM，通过多模态专家混合架构整合了一组视觉专家。此外，我们为Mono-InternVL设计了一种创新的内源视觉预训练（EViP），通过渐进式学习最大化其视觉能力。Mono-InternVL实现了与现有MLLMs相当的性能，但也导致了相对昂贵的数据成本。因此，我们进一步提出了Mono-InternVL-1.5，这是一种更经济、更强大的单体MLLM，配备了改进的EViP（EViP++）。EViP++为Mono-InternVL-1.5引入了额外的视觉注意力专家，并以高效的方式重新组织了预训练过程。在推理过程中，它包含一个融合的CUDA内核以加速其MoE操作。通过这些设计，Mono-InternVL-1.5显著降低了训练和推理成本，同时仍保持与Mono-InternVL相当的竞争力。为了评估我们的方法，我们对15个基准进行了广泛的实验。结果表明，Mono-InternVL在15个基准中的12个上优于现有单体MLLMs，例如在OCRBench上比Emu3提高了114点。与其模块化对应模型InternVL-1.5相比，Mono-InternVL-1.5实现了相似的多模态性能，同时将首个token的延迟降低了高达69%。代码和模型已在https://github.com/OpenGVLab/Mono-InternVL发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [192] [A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique](https://arxiv.org/abs/2507.12730)
> *一种使用域适应技术的隐私保护语义分割方法*

*Homare Sueyoshi, Kiyoshi Nishikawa, Hitoshi Kiya* | **Category: cs.CV, cs.CR** | **Updated: 2025-07-17**

**Keywords:** 隐私保护, 语义分割, 域适应, Vision Transformer, 感知加密

**Comment:** 4 pages, 5 figures, 1 table. Accepted to GCCE 2025

> **TL;DR:** 该论文提出了一种隐私保护的语义分割方法，通过对训练和测试图像进行感知加密，并结合Vision Transformer的域适应技术，实现了与未加密模型几乎相同的准确性。

**AI_Comments:** 该方法的创新之处在于将感知加密与Vision Transformer嵌入结构上的域适应相结合，从而在训练和推理过程中保护隐私，且几乎不牺牲准确性，这对于处理敏感数据的应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为了在模型训练和测试过程中保护图像隐私，同时保持语义分割的准确性。

**Method:** 提出了一种隐私保护的语义分割方法，对训练图像和测试图像应用感知加密。通过在Vision Transformer (ViT)的嵌入结构上使用域适应技术来达到性能目标。实验中使用了基于ViT的强大语义分割模型Segmentation Transformer。

**Result:** 该方法提供了与未加密模型几乎相同的准确性。实验证实了所提出方法在语义分割准确性方面的有效性。

**Conclusion:** 所提出的隐私保护语义分割方法通过对ViT嵌入结构进行域适应，即使对图像进行加密，也能有效保持高准确性。

> **ai_Abstract:** 该论文介绍了一种隐私保护的语义分割方法，它对训练和测试图像都应用感知加密。通过在Vision Transformer的嵌入结构上采用域适应技术，该方法能够保持与未加密模型几乎相同的准确性。使用Segmentation Transformer进行的实验证实了其有效性。

> **摘要翻译:** 我们提出了一种隐私保护语义分割方法，该方法除了对测试图像外，还对用于模型训练的图像应用感知加密。该方法还能提供与未加密模型几乎相同的准确性。上述性能是通过对Vision Transformer (ViT)的嵌入结构使用域适应技术来实现的。在使用称为Segmentation Transformer的强大基于ViT的语义分割模型时，实验证实了所提出方法在语义分割准确性方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [197] [Aligning Information Capacity Between Vision and Language via Dense-to-Sparse Feature Distillation for Image-Text Matching](https://arxiv.org/abs/2503.14953)
> *通过密到稀疏特征蒸馏对齐视觉与语言之间的信息容量用于图像-文本匹配*

*Yang Liu, Wentao Feng, Zhuoyao Liu, Shudong Huang, Jiancheng Lv* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 信息容量, 密到稀疏, 特征蒸馏, 图像-文本匹配, 视觉语义嵌入

**Comment:** 

> **TL;DR:** 本文提出D2S-VSE模型，通过密到稀疏特征蒸馏增强图像-文本匹配中视觉和文本嵌入的信息容量，并在大型数据集上超越了现有SOTA方法。

**AI_Comments:** 本文的创新点在于提出了“密到稀疏特征蒸馏”机制，以提高视觉和语言嵌入的信息容量，这为解决图像-文本匹配中的常见问题提供了一种新颖有效的方法。其两阶段框架设计清晰，逻辑严谨，有效利用了密集文本信息来增强稀疏文本的表示能力，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视图描述匹配方法学习到的视觉和文本嵌入信息容量有限，并且容易受到局部相似负样本的干扰。本文认为嵌入的信息容量至关重要。

**Method:** 本文提出了密到稀疏特征蒸馏视觉语义嵌入（D2S-VSE），这是一个两阶段框架。在预训练阶段，将图像与密集文本对齐，以增强视觉语义嵌入的信息容量。在微调阶段，同时优化两个任务：将密集文本嵌入蒸馏到稀疏文本嵌入，同时对齐图像和稀疏文本，从而增强稀疏文本嵌入的信息容量。

**Result:** 所提出的D2S-VSE模型在大型MS-COCO和Flickr30K数据集上进行了广泛评估，证明其优于最近的最新方法。

**Conclusion:** D2S-VSE通过增强视觉和稀疏文本嵌入的信息容量，有效解决了图像-文本匹配中的挑战，并在基准数据集上取得了卓越的性能。

> **ai_Abstract:** 本研究旨在解决多视图描述匹配中视觉和文本嵌入信息容量有限以及易受负样本干扰的问题。为此，论文提出了D2S-VSE模型，一个两阶段的视觉语义嵌入框架。该模型通过在预训练阶段对齐图像与密集文本来增强视觉嵌入信息容量，并在微调阶段通过将密集文本蒸馏到稀疏文本并同时对齐图像和稀疏文本来增强稀疏文本嵌入的信息容量。实验结果表明，D2S-VSE在MS-COCO和Flickr30K数据集上优于现有的最先进方法。

> **摘要翻译:** 使视觉语义模型有效处理多视图描述匹配一直是一个长期存在的挑战。现有方法通常学习一组嵌入来为每个视图的文本找到最佳匹配并计算相似度。然而，通过这些方法学习到的视觉和文本嵌入信息容量有限，并且容易受到局部相似负样本的干扰。为了解决这个问题，我们认为嵌入的信息容量至关重要，并提出了密到稀疏特征蒸馏视觉语义嵌入（D2S-VSE），它通过利用密集文本蒸馏来增强稀疏文本的信息容量。具体来说，D2S-VSE是一个两阶段框架。在预训练阶段，我们将图像与密集文本对齐，以增强视觉语义嵌入的信息容量。在微调阶段，我们同时优化两个任务，将密集文本嵌入蒸馏到稀疏文本嵌入，同时对齐图像和稀疏文本，从而增强稀疏文本嵌入的信息容量。我们提出的D2S-VSE模型在大型MS-COCO和Flickr30K数据集上进行了广泛评估，证明其优于最近的最新方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [200] [AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation](https://arxiv.org/abs/2507.12768)
> *AnyPos：双臂操作的自动化任务无关动作*

*Hengkai Tan, Yao Feng, Xinyi Mao, Shuhe Huang, Guodong Liu, Zhongkai Hao, Hang Su, Jun Zhu* | **Category: cs.CV, cs.LG, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 双臂操作, 任务无关动作, 自监督学习, 逆动力学模型, VLA模型

**Comment:** 

> **TL;DR:** 本文提出AnyPos-ATARA框架，通过自动化任务无关动作和自监督数据收集，显著提升双臂操作VLA模型的泛化能力和成功率，解决数据依赖和效率问题。

**AI_Comments:** 本文的创新点在于提出了“任务无关动作”的新范式，并通过ATARA和AnyPos解决了该范式下的数据收集和有效学习难题。这种方法大幅降低了数据获取成本和对人工演示的依赖，显著提高了VLA模型在复杂双臂操作任务中的泛化能力和效率，对于推动具身智能和机器人操作的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言-动作（VLA）模型在双臂操作等复杂设置中过度依赖任务特定的人工演示，这限制了它们的泛化能力并导致高昂的数据获取成本。

**Method:** 本文提出一种任务无关动作范式，将动作执行与任务特定条件解耦。为解决数据收集挑战，引入了ATARA（自动化任务无关随机动作）自监督框架，可将数据收集速度提高30倍以上。为有效学习任务无关数据，提出了AnyPos逆动力学模型，该模型配备了手臂解耦估计（Arm-Decoupled Estimation）和方向感知解码器（Direction-Aware Decoder, DAD）。此外，还集成了一个视频条件动作验证模块来验证学习策略的可行性。

**Result:** AnyPos-ATARA管线在测试准确性上提升了51%，并在抓取、放置和点击等下游任务中实现了30-40%更高的成功率，同时使用了基于回放的视频验证。数据收集速度比人工遥操作快30倍以上。

**Conclusion:** AnyPos-ATARA框架通过引入自动化任务无关动作和高效的自监督数据收集方法，显著提高了双臂操作VLA模型的泛化能力、效率和在下游任务中的成功率，有效解决了传统方法对任务特定人工演示的过度依赖问题。

> **ai_Abstract:** 本文针对视觉-语言-动作（VLA）模型在双臂操作中对任务特定人工演示的过度依赖问题，提出了一种任务无关动作范式。为解决数据收集效率和泛化性挑战，引入了自监督框架ATARA，可将数据收集速度提升30倍。同时，开发了AnyPos逆动力学模型，其包含手臂解耦估计和方向感知解码器，并辅以视频条件动作验证模块，以有效学习任务无关数据。实验结果表明，AnyPos-ATARA管线显著提升了测试准确性，并在多项下游任务中取得了更高的成功率。

> **摘要翻译:** 视觉-语言-动作（VLA）模型在双臂操作等复杂环境下的任务条件控制方面已展现出前景。然而，过度依赖任务特定的人工演示限制了它们的泛化能力，并导致高昂的数据获取成本。在这项工作中，我们提出了一种新的任务无关动作范式，它将动作执行与任务特定条件解耦，从而提高了可扩展性、效率和成本效益。为了解决这种范式带来的数据收集挑战——例如低覆盖密度、行为冗余和安全风险——我们引入了ATARA（自动化任务无关随机动作），一个可扩展的自监督框架，与人工遥操作相比，它将数据收集速度提高了30倍以上。为了进一步实现从任务无关数据中有效学习（这些数据常面临分布不匹配和不相关轨迹的问题），我们提出了AnyPos，一个配备了手臂解耦估计（Arm-Decoupled Estimation）和方向感知解码器（Direction-Aware Decoder, DAD）的逆动力学模型。我们还集成了一个视频条件动作验证模块，以验证所学策略在不同操作任务中的可行性。广泛的实验表明，AnyPos-ATARA管线在测试准确性上提高了51%，并在抓取、放置和点击等下游任务中实现了30-40%更高的成功率，同时使用了基于回放的视频验证。项目主页：https://embodiedfoundation.github.io/vidar_anypos

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [207] [cIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration](https://arxiv.org/abs/2507.12953)
> *cIDIR：用于正则化可变形图像配准的条件隐式神经表示*

*Sidaty El Hadramy, Oumeymah Cherkaoui, Philippe C. Cattin* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 可变形图像配准, 隐式神经表示, 正则化, 超参数优化

**Comment:** 

> **TL;DR:** cIDIR是一种基于隐式神经表示的新型可变形图像配准框架，它通过在正则化超参数上进行条件化训练来解决传统方法中超参数微调计算成本高的问题，并在DIR-LAB数据集上表现出高精度和鲁棒性。

**AI_Comments:** cIDIR的创新之处在于其将隐式神经表示应用于可变形图像配准，并通过对正则化超参数进行条件化训练，显著提高了正则化过程的效率，避免了昂贵的重复训练。这种方法对于实际应用中需要快速迭代和优化正则化参数的场景具有重要意义，其连续可微分的DVF模型也为未来更复杂的正则化技术集成奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在基于学习的可变形图像配准（DIR）框架中，正则化参数的微调计算成本高昂，通常需要多次训练迭代。

**Method:** 本研究提出cIDIR，一个基于隐式神经表示（INRs）的新型DIR框架，它将配准过程与正则化超参数关联起来。cIDIR在一个先验的超参数分布上进行训练，然后通过使用分割掩膜作为观测值来优化正则化超参数。此外，cIDIR建模了一个连续且可微分的形变向量场（DVF），通过自动微分实现了先进正则化技术的无缝集成。

**Result:** 在DIR-LAB数据集上进行评估，cIDIR在整个数据集上实现了高精度和鲁棒性。

**Conclusion:** cIDIR通过其创新的条件化训练和连续可微分的DVF模型，有效解决了可变形图像配准中正则化超参数微调的计算效率问题，并展现了优秀的配准性能。

> **ai_Abstract:** cIDIR是一种新型的可变形图像配准（DIR）框架，它利用隐式神经表示（INRs）来解决传统学习型DIR方法中正则化超参数微调计算成本高的问题。cIDIR通过在正则化超参数的先验分布上进行训练，并利用分割掩膜进行优化，从而避免了为每个超参数设置进行重复训练。该方法还建立了连续可微分的形变向量场，便于高级正则化技术的集成。在DIR-LAB数据集上的评估表明，cIDIR具有高精度和鲁棒性。

> **摘要翻译:** 正则化在可变形图像配准（DIR）中至关重要，以确保估计的形变向量场（DVF）保持平滑、物理合理且解剖学一致。然而，在基于学习的DIR框架中微调正则化参数计算成本高昂，通常需要多次训练迭代。为了解决这个问题，我们提出了cIDIR，一个基于隐式神经表示（INRs）的新型DIR框架，它将配准过程与正则化超参数关联起来。与传统方法需要为每种正则化超参数设置重新训练不同，cIDIR在这些超参数的先验分布上进行训练，然后通过使用分割掩膜作为观测值来优化正则化超参数。此外，cIDIR建模了一个连续且可微分的DVF，通过自动微分实现了先进正则化技术的无缝集成。在DIR-LAB数据集上进行评估，cIDIR在整个数据集上实现了高精度和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [217] [Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows](https://arxiv.org/abs/2507.12590)
> *大规模像素级作物制图和迁移学习工作流的最佳实践*

*Judy Long, Tao Liu, Sean Alexander Woznicki, Miljana Marković, Oskar Marko, Molly Sears* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 作物制图, 迁移学习, 遥感, 像素级分类, 最佳实践

**Comment:** A review article. 41 pages, 22 figures. Preprint

> **TL;DR:** 本研究对大规模像素级作物制图工作流进行了首次全面回顾，比较了传统监督方法和新兴迁移学习方法，并提供了基于实验结果的最佳实践和关键见解。

**AI_Comments:** 该论文为大规模像素级作物制图提供了全面的实践指导，尤其是在对比不同预处理、模型和迁移学习策略方面，具有重要的实际应用价值。其创新点在于首次系统性地评估了多种主流方法，并给出了具体场景下的最佳实践建议，对于遥感和农业信息领域的从业者具有很强的指导意义。对标记样本可用性与工作流选择关系的讨论也极具启发性。

<details>
  <summary>Details</summary>

**Motivation:** 作物制图涉及利用遥感图像识别和分类作物类型。本研究旨在首次全面回顾大规模像素级作物制图工作流，并识别出最优的监督作物制图工作流和不同域偏移下的最优迁移学习技术。

**Method:** 研究进行了系统性实验，比较了六种常用的卫星图像预处理方法和十一种监督像素级分类模型。此外，还评估了不同训练样本量和变量组合的协同影响，并确定了针对不同域偏移程度的最佳迁移学习技术。评估在五个不同的农业地点进行，主要使用Landsat 8数据，标签来源于CDL可信像素和实地调查。

**Result:** 研究发现三个关键见解：1. 细尺度间隔预处理与Transformer模型结合在监督和可迁移工作流中均表现出最佳性能，而RF在传统监督学习和直接迁移到相似域中提供了快速训练和有竞争力的性能。2. 迁移学习技术增强了工作流的适应性，其中UDA对同质作物类别有效，而微调在不同场景中保持稳健。3. 工作流的选择严重依赖于标记样本的可用性，样本量充足时监督训练更准确和通用，样本量不足时迁移学习是可行替代方案。

**Conclusion:** 工作流的选择应根据标记样本的可用性进行调整；当样本充足时，监督训练通常能提供更准确和可泛化的结果；当样本低于一定阈值时，与域偏移水平相匹配的迁移学习是实现作物制图的可行替代方案。

> **ai_Abstract:** 本研究对大规模像素级作物制图工作流进行了首次全面回顾，比较了传统监督方法和新兴迁移学习方法。通过系统实验，评估了多种预处理方法、分类模型、训练样本量和变量组合，并在五个农业地点进行了验证。研究发现，细尺度预处理与Transformer模型结合表现最佳，而随机森林在传统监督学习中表现出色。迁移学习技术增强了适应性，其中UDA适用于同质类别，微调在多样场景中稳健。最终，工作流选择应根据标记样本的可用性来决定，样本充足时监督训练更优，样本不足时迁移学习是可行替代。

> **摘要翻译:** 作物制图涉及利用空间数据，主要来源于遥感影像，识别和分类作物类型。本研究首次全面回顾了大规模像素级作物制图工作流，涵盖了传统的监督方法和新兴的迁移学习方法。为了确定最佳的监督作物制图工作流，我们进行了系统性实验，比较了六种广泛采用的基于卫星图像的预处理方法，以及十一种监督像素级分类模型。此外，我们评估了不同训练样本量和变量组合的协同影响。此外，我们确定了针对不同程度域偏移的最佳迁移学习技术。最佳方法的评估在五个不同的农业地点进行。Landsat 8作为主要的卫星数据源。标签来源于CDL可信像素和实地调查。
我们的研究结果揭示了三个关键见解。首先，细尺度间隔预处理与Transformer模型结合在监督和可迁移工作流中始终提供最佳性能。RF在传统监督学习和直接迁移到相似域中提供了快速训练和有竞争力的性能。其次，迁移学习技术增强了工作流的适应性，其中UDA对同质作物类别有效，而微调在不同场景中保持稳健。最后，工作流的选择严重依赖于标记样本的可用性。在样本量充足的情况下，监督训练通常能提供更准确和可泛化的结果。低于某个阈值，与域偏移水平相匹配的迁移学习是实现作物制图的可行替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [218] [Local Representative Token Guided Merging for Text-to-Image Generation](https://arxiv.org/abs/2507.12771)
> *局部代表性令牌引导合并用于文本到图像生成*

*Min-Jeong Lee, Hee-Dong Kim, Seong-Whan Lee* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 文本到图像生成, 令牌合并, 稳定扩散, 注意力机制, 计算效率

**Comment:** 6 pages

> **TL;DR:** 提出ReToM方法，通过局部代表性令牌引导合并来提高文本到图像生成模型的效率和质量，同时保持计算效率。

**AI_Comments:** ReToM的创新之处在于其结合了局部窗口概念和代表性令牌选择机制，这使得模型能够在降低计算复杂度的同时，更精细地保留图像的关键局部特征。这种方法对于提高大型扩散模型的实用性具有重要意义，因为它解决了效率与质量之间的核心矛盾。

<details>
  <summary>Details</summary>

**Motivation:** 稳定扩散模型在文本到图像生成中表现出色，但其基于注意力操作的二次复杂度导致耗时的生成过程。现有令牌合并方法虽提高效率，但常忽略注意力图像生成模型的特性，限制了其有效性。

**Method:** 提出局部代表性令牌引导合并（ReToM）策略，适用于图像生成中的任何注意力机制。ReToM通过定义注意力输入中的局部边界（窗口）并调整窗口大小来合并令牌。此外，引入代表性令牌，通过计算特定时间步的相似度并选择平均相似度最高的令牌，来代表每个窗口中最具代表性的令牌。

**Result:** ReToM在FID上比基线提高了6.2%，CLIP分数更高，同时保持了可比的推理时间。经验证明ReToM在视觉质量和计算效率之间实现了有效平衡。

**Conclusion:** ReToM是一种有效的令牌合并策略，能够在文本到图像生成中平衡视觉质量和计算效率，同时显著提升生成效率和图像质量。

> **ai_Abstract:** 本文提出了一种名为局部代表性令牌引导合并（ReToM）的新型策略，旨在解决文本到图像生成模型（如稳定扩散）中注意力操作导致的计算效率低下问题。ReToM通过在注意力输入中定义局部窗口边界并引入代表性令牌（根据相似度选择）来合并令牌，从而在减少计算量的同时保留关键视觉特征。实验证明，ReToM在提高FID和CLIP分数的同时，保持了与现有方法相当的推理时间，有效平衡了图像质量与计算效率。

> **摘要翻译:** 稳定扩散是一种出色的文本到图像生成模型，但由于注意力操作的二次复杂度，其耗时的生成过程仍然是一个挑战。最近的令牌合并方法通过减少注意力操作期间的令牌数量来提高效率，但往往忽略了基于注意力的图像生成模型的特性，限制了其有效性。在本文中，我们提出了局部代表性令牌引导合并（ReToM），这是一种新颖的令牌合并策略，适用于图像生成中的任何注意力机制。为了根据各种上下文信息合并令牌，ReToM将局部边界定义为注意力输入中的窗口并调整窗口大小。此外，我们引入了一个代表性令牌，通过计算特定时间步的相似度并选择平均相似度最高的令牌来代表每个窗口中最具代表性的令牌。这种方法在最小化计算开销的同时保留了最显著的局部特征。实验结果表明，与基线相比，ReToM在FID上提高了6.2%，CLIP分数更高，同时保持了可比的推理时间。我们经验证明ReToM在视觉质量和计算效率之间实现了有效平衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [220] [RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images](https://arxiv.org/abs/2507.13120)
> *RS-TinyNet: 阶段性特征融合网络用于遥感图像中的微小目标检测*

*Xiaozheng Jiang, Wei Zhang, Xuerui Mao* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 遥感图像, 微小目标检测, 特征融合, 注意力机制, 深度学习

**Comment:** 

> **TL;DR:** RS-TinyNet是一个多阶段特征融合网络，通过引入微小目标显著性建模和特征完整性重建，显著提升了遥感图像中微小目标的检测性能，超越了现有SOTA方法。

**AI_Comments:** RS-TinyNet的创新点在于其针对微小目标特性，提出了微小目标显著性建模和特征完整性重建两大设计原则，并通过MDCA、ARB和PFDH等模块具体实现。这种分阶段特征融合和增强策略，有效提升了在复杂遥感图像中检测微小目标的性能，解决了该领域的长期挑战，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像中微小目标检测面临空间信息有限、特征表示弱和复杂背景下密集分布等挑战，现有主流检测器表现不佳，因此需要提出一种新的解决方案来弥补这一差距。

**Method:** 本文提出了RS-TinyNet，一个多阶段特征融合和增强模型，专为遥感微小目标检测定制。它包含两个新颖设计：微小目标显著性建模和特征完整性重建。基于这些原则，设计了三个分步特征增强模块：多维协同注意力（MDCA）模块用于增强微小目标显著性，辅助可逆分支（ARB）和渐进式融合检测头（PFDH）模块用于保留信息流、融合多级特征以弥合语义鸿沟并保留结构细节。

**Result:** 在公共遥感数据集AI-TOD上的综合实验表明，RS-TinyNet超越现有最先进（SOTA）检测器4.0% AP和6.5% AP75。在DIOR基准数据集上的评估进一步验证了其在不同遥感场景下的卓越检测性能。

**Conclusion:** 研究结果表明，所提出的多阶段特征融合策略为复杂遥感环境中的微小目标检测提供了一种有效且实用的解决方案。

> **ai_Abstract:** 本文提出RS-TinyNet，一个针对遥感图像中微小目标检测的多阶段特征融合网络。该模型通过微小目标显著性建模和特征完整性重建两大核心设计，并引入多维协同注意力（MDCA）、辅助可逆分支（ARB）和渐进式融合检测头（PFDH）等模块，有效解决了微小目标空间信息有限、特征弱和复杂背景下的检测难题。实验证明，RS-TinyNet在AI-TOD和DIOR数据集上均显著优于现有最先进方法，为复杂遥感环境下的微小目标检测提供了实用解决方案。

> **摘要翻译:** 在遥感（RS）图像中检测微小目标一直是一个长期存在的挑战，原因在于它们极其有限的空间信息、弱特征表示以及在复杂背景下的密集分布。尽管付出了大量努力，主流检测器在这种场景下仍然表现不佳。为了弥补这一差距，我们引入了RS-TinyNet，一个多阶段特征融合和增强模型，专门为各种遥感场景下的遥感微小目标检测量身定制。RS-TinyNet具有两个新颖设计：微小目标显著性建模和特征完整性重建。在这些原则的指导下，我们设计了三个分步特征增强模块。其中，多维协同注意力（MDCA）模块采用多维注意力来增强微小目标的显著性。此外，还引入了辅助可逆分支（ARB）和渐进式融合检测头（PFDH）模块，以保留信息流并融合多级特征，从而弥合语义鸿沟并保留结构细节。在公共遥感数据集AI-TOD上的综合实验表明，我们的RS-TinyNet超越现有最先进（SOTA）检测器4.0% AP和6.5% AP75。在DIOR基准数据集上的评估进一步验证了其在不同遥感场景下的卓越检测性能。这些结果表明，所提出的多阶段特征融合策略为复杂遥感环境中的微小目标检测提供了一种有效且实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [226] [A Progressive Image Restoration Network for High-order Degradation Imaging in Remote Sensing](https://arxiv.org/abs/2412.07195)
> *一种用于遥感高阶退化成像的渐进式图像恢复网络*

*Yujie Feng, Yin Yang, Xiaohong Fan, Zhengpeng Zhang, Lijing Bu, Jianping Zhang* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-07-17**

**Keywords:** 遥感图像恢复, 高阶退化, 渐进式网络, 深度学习, 可解释性

**Comment:** 17 pages, Accepted to Transactions on Geoscience and Remote Sensing
  (TGRS), July 16, 2025

> **TL;DR:** 该论文提出了一种名为HDI-PRNet的渐进式图像恢复网络，专门用于解决遥感图像中的高阶退化问题，并提升模型的可解释性。

**AI_Comments:** 该论文的创新点在于提出了一个针对遥感图像高阶退化的渐进式恢复网络，并强调了模型的数学可解释性，这弥补了当前深度学习方法在透明度方面的不足。其分模块设计（去噪、去模糊、超分辨率）也体现了对复杂退化过程的细致处理。

<details>
  <summary>Details</summary>

**Motivation:** 现有的遥感图像恢复方法主要关注传统的低阶退化模型，未能有效捕捉遥感图像的成像机制。此外，许多深度学习方法缺乏架构透明度和模型可解释性。为了解决这些问题，本文提出了一种新方法。

**Method:** 本文提出了一种新颖的渐进式高阶退化成像恢复网络（HDI-PRNet），用于逐步恢复不同的图像退化。HDI-PRNet基于退化成像的理论框架、高阶退化过程的马尔可夫性质和最大后验（MAP）估计开发，在展开网络中具有数学可解释性。该框架包含三个主要组件：基于近端映射先验学习的图像去噪模块、结合Neumann级数展开和双域退化学习的图像去模糊模块，以及一个超分辨率模块。

**Result:** 广泛的实验表明，该方法在合成和真实的遥感图像上均取得了优越的性能。

**Conclusion:** 本文提出的HDI-PRNet能够有效解决遥感图像中的高阶退化问题，并在性能和可解释性方面优于现有方法。

> **ai_Abstract:** 本文提出了一种新颖的渐进式图像恢复网络HDI-PRNet，旨在解决遥感图像中高阶退化和现有深度学习方法缺乏可解释性的问题。该网络基于退化成像理论、马尔可夫性质和MAP估计构建，具有数学可解释性，并包含去噪、去模糊和超分辨率三个核心模块。实验证明，HDI-PRNet在合成和真实遥感图像上均表现出优越的恢复性能。

> **摘要翻译:** 近期，深度学习方法在遥感（RS）图像恢复领域取得了显著成就。然而，大多数现有的遥感图像恢复方法主要关注传统的低阶退化模型，这可能无法有效捕捉遥感图像的成像机制。此外，许多使用深度学习的遥感图像恢复方法常因其架构缺乏透明度和模型可解释性而受到批评。为了解决这些问题，我们提出了一种新颖的渐进式高阶退化成像恢复网络（HDI-PRNet），以逐步恢复不同的图像退化。HDI-PRNet基于退化成像的理论框架、高阶退化过程的马尔可夫性质和最大后验（MAP）估计开发，在展开网络中具有数学可解释性。该框架由三个主要组件组成：一个依赖于近端映射先验学习的图像去噪模块，一个将Neumann级数展开与双域退化学习相结合的图像去模糊模块，以及一个超分辨率模块。大量的实验表明，我们的方法在合成和真实的遥感图像上均取得了优越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [227] [DWIM: Towards Tool-aware Visual Reasoning via Discrepancy-aware Workflow Generation & Instruct-Masking Tuning](https://arxiv.org/abs/2503.19263)
> *DWIM：迈向工具感知视觉推理，通过差异感知工作流生成和指令掩蔽微调*

*Fucai Ke, Vijay Kumar B G, Xingjian Leng, Zhixi Cai, Zaid Khan, Weiqing Wang, Pari Delir Haghighi, Hamid Rezatofighi, Manmohan Chandraker* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 视觉推理, 工具感知, 工作流生成, 指令掩蔽, 大型语言模型

**Comment:** ICCV 2025

> **TL;DR:** DWIM通过差异感知工作流生成和指令掩蔽微调，解决了大型语言模型在视觉推理中缺乏工具感知的问题，实现了最先进的性能。

**AI_Comments:** DWIM的创新之处在于其差异感知工作流生成和指令掩蔽微调机制，有效解决了LLMs在视觉推理中工具感知不足和训练数据噪声的问题。这对于提升LLMs在复杂多模态推理任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的组合视觉推理方法在视觉推理（VR）中存在局限性，因为冻结的大型语言模型（LLMs）缺乏工具感知能力，导致性能瓶颈。此外，由于训练数据有限、工具不完善引入错误以及难以在噪声工作流上进行微调，LLMs在VR中难以直接应用。

**Method:** 我们提出了DWIM框架，包含两个核心组件：i) 差异感知训练工作流生成，用于评估工具使用并提取更可行的训练工作流；ii) 指令掩蔽微调，引导模型仅模仿有效动作，从而生成更实用的解决方案。

**Result:** 实验表明，DWIM在各种视觉推理任务中取得了最先进的性能，并在多个广泛使用的数据集上表现出强大的泛化能力。

**Conclusion:** DWIM通过其差异感知工作流生成和指令掩蔽微调方法，成功解决了视觉推理中工具感知和训练数据质量的挑战，显著提升了视觉推理任务的性能和泛化能力。

> **ai_Abstract:** 本文提出DWIM框架以解决大型语言模型在视觉推理中缺乏工具感知和训练数据质量问题。DWIM通过差异感知工作流生成来筛选更有效的训练数据，并通过指令掩蔽微调引导模型学习有效动作。实验证明DWIM在多种视觉推理任务上达到了最先进水平，并展现出强大的泛化能力。

> **摘要翻译:** 视觉推理（VR）在许多领域中对于实现类人视觉理解至关重要，但仍然极具挑战性。最近，组合视觉推理方法通过利用大型语言模型（LLMs）的推理能力并集成工具来解决问题，已显示出比端到端VR方法更有效的策略。然而，这些方法面临局限性，因为冻结的LLMs在VR中缺乏工具感知能力，导致性能瓶颈。虽然LLMs在其他领域中广泛用于推理，但由于训练数据有限、不完善的工具引入错误并降低VR中的数据收集效率，以及在噪声工作流上进行微调的挑战，它们不能直接应用于VR。为了解决这些挑战，我们提出了DWIM：i) 差异感知训练工作流生成，评估工具使用并提取更可行的训练工作流；ii) 指令掩蔽微调，引导模型仅模仿有效动作，从而生成更实用的解决方案。我们的实验表明，DWIM在各种VR任务中取得了最先进的性能，并在多个广泛使用的数据集上表现出强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [231] [Efficient Adaptation of Pre-trained Vision Transformer underpinned by Approximately Orthogonal Fine-Tuning Strategy](https://arxiv.org/abs/2507.13260)
> *基于近似正交微调策略的预训练视觉Transformer高效自适应*

*Yiting Yang, Hao Luo, Yuan Sun, Qingsen Yan, Haokui Zhang, Wei Dong, Guoqing Wang, Peng Wang, Yang Yang, Hengtao Shen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 参数高效微调, 视觉Transformer, 近似正交性, 泛化能力, 低秩适应

**Comment:** This paper is accepted by ICCV 2025

> **TL;DR:** 本文提出了一种近似正交微调 (AOFT) 策略，通过使低秩适应矩阵近似正交（类似于骨干参数），来增强预训练视觉Transformer (ViT) 的泛化能力。

**AI_Comments:** 本文识别并利用了预训练ViT骨干参数中一个新颖的特性——近似正交性，并将其有效地应用于参数高效微调方法中。这种通过使适应矩阵与骨干网络属性对齐来增强泛化能力的方向是富有创新性的。

<details>
  <summary>Details</summary>

**Motivation:** 在预训练视觉Transformer (ViT) 的参数高效微调 (PEFT) 中，现有的低秩适应方法（如LoRA和Adapter）所使用的下/上投影矩阵缺乏骨干参数中存在的近似正交性。这种近似正交性被认为可以降低模型的泛化误差上限并增强泛化能力。因此，研究动机是探讨如果微调后的下/上投影矩阵也能表现出这种近似正交性，是否能进一步增强ViT的泛化能力。

**Method:** 本文提出了一种近似正交微调 (AOFT) 策略来表示低秩权重矩阵。该策略利用单个可学习向量生成一组近似正交向量，这些向量构成下/上投影矩阵，从而使这些矩阵的特性与骨干网络对齐。

**Result:** 广泛的实验结果表明，我们的方法在一系列下游图像分类任务中取得了具有竞争力的性能，证实了嵌入在下/上投影矩阵中增强泛化能力的有效性。

**Conclusion:** 近似正交微调 (AOFT) 策略通过在低秩适应矩阵中强制执行近似正交性，成功增强了微调视觉Transformer的泛化能力，从而取得了具有竞争力的性能。

> **ai_Abstract:** 本文针对预训练视觉Transformer (ViT) 的参数高效微调 (PEFT) 提出了近似正交微调 (AOFT) 策略，旨在提高泛化能力。研究发现，预训练ViT骨干参数表现出近似正交性，这有助于泛化，但在现有低秩适应矩阵（如LoRA和Adapter）中却缺乏。AOFT通过使用单个可学习向量生成近似正交的下/上投影矩阵来解决此问题，使其属性与骨干网络对齐。实验结果表明，AOFT在图像分类任务中取得了具有竞争力的性能，验证了其增强泛化能力的有效性。

> **摘要翻译:** 在预训练视觉Transformer (ViT) 的参数高效微调 (PEFT) 中，一种流行的方法是冻结大部分骨干参数，并仅学习低秩适应权重矩阵以适应下游任务。这些低秩矩阵通常通过下投影和上投影矩阵的乘法结构导出，例如LoRA和Adapter等方法。在这项工作中，我们观察到骨干参数中任意权重矩阵的任意两个行或列向量之间存在近似正交性；然而，下/上投影矩阵的向量中却缺乏这种特性。近似正交性意味着模型泛化误差上限的降低，表明模型具有增强的泛化能力。如果微调后的下/上投影矩阵也能像预训练骨干矩阵一样表现出相同的特性，那么微调后的ViT的泛化能力能否进一步增强？为了解决这个问题，我们提出了一种近似正交微调 (AOFT) 策略来表示低秩权重矩阵。该策略利用单个可学习向量生成一组近似正交向量，这些向量构成下/上投影矩阵，从而使这些矩阵的特性与骨干网络对齐。广泛的实验结果表明，我们的方法在一系列下游图像分类任务中取得了具有竞争力的性能，证实了嵌入在下/上投影矩阵中增强泛化能力的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [249] [FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers](https://arxiv.org/abs/2507.12956)
> *FantasyPortrait：通过表情增强扩散变换器提升多角色肖像动画*

*Qiang Wang, Mengchao Wang, Fan Jiang, Yaqi Fan, Yonggang Qi, Mu Xu* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 面部动画, 扩散变换器, 多角色, 表情增强, 交叉重演

**Comment:** https://fantasy-amap.github.io/fantasy-portrait/

> **TL;DR:** FantasyPortrait是一个基于扩散变换器的框架，通过表情增强学习和蒙版交叉注意力机制，能为单角色和多角色生成高质量、情感丰富的面部动画，并提出了新的数据集和基准。

**AI_Comments:** 该论文的创新点在于提出了一个基于扩散变换器的新框架FantasyPortrait，并引入了表情增强学习和蒙版交叉注意力机制，有效解决了传统方法在处理细微情感和多角色互动中的局限性。特别是其对多角色动画的关注和解决方案，填补了现有研究的空白。此外，提出的新数据集和基准对推动该领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的从静态图像生成富有表现力的面部动画的方法，依赖显式几何先验（如面部地标或3DMM），常在交叉重演中出现伪影，难以捕捉细微情感。此外，它们缺乏对多角色动画的支持，因为不同个体的驱动特征会相互干扰。

**Method:** 本文提出了FantasyPortrait，一个基于扩散变换器的框架，用于生成高保真和情感丰富的单角色和多角色动画。该方法引入了表情增强学习策略，利用隐式表示捕捉与身份无关的面部动态，以增强模型渲染细粒度情感的能力。为实现多角色控制，设计了蒙版交叉注意力机制，确保独立而协调的表情生成，有效防止特征干扰。此外，还提出了Multi-Expr数据集和ExprBench，用于训练和评估多角色肖像动画。

**Result:** 广泛的实验表明，FantasyPortrait在定量指标和定性评估方面显著优于现有最先进的方法，尤其在具有挑战性的交叉重演和多角色场景中表现出色。

**Conclusion:** FantasyPortrait通过其创新的表情增强学习和蒙版交叉注意力机制，成功解决了现有方法在生成高质量、多角色面部动画方面的挑战，并为该领域的研究提供了新的数据集和基准。

> **ai_Abstract:** 本文提出了FantasyPortrait，一个基于扩散变换器的面部动画生成框架，旨在解决现有方法在处理细微情感和多角色动画时的局限性。通过引入表情增强学习策略捕获身份无关的面部动态，并设计蒙版交叉注意力机制以实现多角色独立协调控制，FantasyPortrait能生成高质量、情感丰富的单/多角色动画。此外，作者还构建了Multi-Expr数据集和ExprBench基准。实验证明，FantasyPortrait在交叉重演和多角色场景中均显著优于现有SOTA方法。

> **摘要翻译:** 从静态图像生成富有表现力的面部动画是一项具有挑战性的任务。先前依赖显式几何先验（例如，面部地标或3DMM）的方法常常在交叉重演中出现伪影，并且难以捕捉细微的情感。此外，现有方法缺乏对多角色动画的支持，因为来自不同个体的驱动特征经常相互干扰，使任务复杂化。为了解决这些挑战，我们提出了FantasyPortrait，一个基于扩散变换器的框架，能够为单角色和多角色场景生成高保真和情感丰富的动画。我们的方法引入了一种表情增强学习策略，该策略利用隐式表示来捕获与身份无关的面部动态，从而增强模型渲染细粒度情感的能力。对于多角色控制，我们设计了一种蒙版交叉注意力机制，确保独立而协调的表情生成，有效防止特征干扰。为了推动该领域的研究，我们提出了Multi-Expr数据集和ExprBench，它们是专门为训练和评估多角色肖像动画而设计的数据集和基准。广泛的实验表明，FantasyPortrait在定量指标和定性评估方面显著优于现有最先进的方法，尤其在具有挑战性的交叉重演和多角色背景下表现出色。我们的项目页面是https://fantasy-amap.github.io/fantasy-portrait/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [251] [CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling](https://arxiv.org/abs/2507.12591)
> *CT-ScanGaze：一个用于3D体素扫描路径建模的数据集和基线*

*Trong-Thang Pham, Akash Awasthi, Saba Khan, Esteban Duran Marti, Tien-Phat Nguyen, Khoa Vo, Minh Tran, Ngoc Son Nguyen, Cuong Tran Van, Yuki Ikebe, Anh Totti Nguyen, Anh Nguyen, Zhigang Deng, Carol C. Wu, Hien Van Nguyen, Ngan Le* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** CT, 眼动追踪, 数据集, 3D扫描路径, 计算机辅助诊断

**Comment:** ICCV 2025

> **TL;DR:** 该研究发布了CT-ScanGaze数据集，这是首个公开的CT眼动追踪数据集，并提出了CT-Searcher，一个用于生成放射科医生3D注视序列的新型3D扫描路径预测器，旨在解决CT阅片中3D眼动数据缺乏的问题。

**AI_Comments:** 该论文的创新之处在于首次公开了CT领域的3D眼动追踪数据集CT-ScanGaze，这极大地填补了该领域数据稀缺的空白。同时，提出的CT-Searcher模型能够处理3D体素数据并生成3D扫描路径，克服了现有2D模型在医学影像复杂性上的局限性，对开发可解释的计算机辅助诊断系统具有重要意义。数据的预处理管道也提供了一种利用现有2D数据进行3D模型预训练的有效策略。

<details>
  <summary>Details</summary>

**Motivation:** 理解放射科医生在CT阅片时的眼动对于开发有效的可解释计算机辅助诊断系统至关重要。然而，该领域的CT研究受限于缺乏公开可用的眼动追踪数据集以及CT体积的三维复杂性。

**Method:** 研究首先提出了首个公开可用的CT眼动追踪数据集CT-ScanGaze。然后，引入了CT-Searcher，一个专门设计用于处理CT体积并生成类似放射科医生3D注视序列的新型3D扫描路径预测器，克服了当前扫描路径预测器仅处理2D输入的局限性。此外，为了利用深度学习模型的预训练优势，开发了一个将现有2D注视数据集转换为3D注视数据以预训练CT-Searcher的流程。

**Result:** 通过在CT-ScanGaze数据集上进行的定性和定量评估，研究证明了所提方法的有效性，并为医学影像中的3D扫描路径预测提供了一个全面的评估框架。

**Conclusion:** 该研究成功解决了CT阅片中缺乏公开3D眼动追踪数据集的挑战，并提出了一个有效的新型3D扫描路径预测器CT-Searcher，为未来开发可解释的计算机辅助诊断系统奠定了基础。

> **ai_Abstract:** 该论文提出了CT-ScanGaze，这是首个公开可用的CT眼动追踪数据集，旨在解决CT阅片中3D眼动数据缺乏的挑战。同时，论文引入了CT-Searcher，一个新型的3D扫描路径预测器，能够处理CT体积并生成放射科医生般的3D注视序列，并通过将2D注视数据转换为3D数据来预训练模型。在CT-ScanGaze上的评估表明了该方法的有效性，并为医学影像中的3D扫描路径预测提供了一个全面的评估框架。

> **摘要翻译:** 理解放射科医生在计算机断层扫描（CT）阅片时的眼动对于开发有效的可解释计算机辅助诊断系统至关重要。然而，该领域的CT研究受限于缺乏公开可用的眼动追踪数据集以及CT体积的三维复杂性。为了解决这些挑战，我们提出了首个公开可用的CT眼动追踪数据集，名为CT-ScanGaze。然后，我们引入了CT-Searcher，一个专门设计用于处理CT体积并生成类似放射科医生3D注视序列的新型3D扫描路径预测器，克服了当前扫描路径预测器仅处理2D输入的局限性。由于深度学习模型受益于预训练步骤，我们开发了一个将现有2D注视数据集转换为3D注视数据以预训练CT-Searcher的流程。通过在CT-ScanGaze上的定性和定量评估，我们证明了我们方法的有效性，并为医学影像中的3D扫描路径预测提供了一个全面的评估框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [263] [Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters](https://arxiv.org/abs/2507.00792)
> *虚拟人物角色多约束运动生成的实时逆运动学*

*Hendric Voss, Stefan Kopp* | **Category: cs.CV, cs.HC** | **Updated: 2025-07-17**

**Keywords:** 实时逆运动学, 虚拟人物, 自动微分, TensorFlow, 多约束运动

**Comment:** 

> **TL;DR:** 提出一种基于TensorFlow自动微分和JIT编译的实时逆运动学（IK）求解器，用于生成虚拟人物的多约束运动，比现有方法更快、更准确。

**AI_Comments:** 这篇论文通过利用TensorFlow的自动微分和JIT编译功能，为实时逆运动学提供了一种新颖且高效的解决方案。其创新之处在于将IK问题转化为可微分操作，从而有效处理复杂的关节限制和误差累积，这对于逼真的人体运动建模至关重要。该方法在性能上显著优于传统迭代算法，对计算机图形学和虚拟现实领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在计算机图形学、交互式虚拟环境、机器人技术和生物力学等领域，实时生成准确逼真的虚拟人物运动非常重要。现有方法在处理多约束问题时面临误差累积和复杂关节限制等挑战。

**Method:** 引入了一种新颖的实时逆运动学（IK）求解器，专门用于生成逼真的人体运动。该求解器利用TensorFlow的自动微分和即时编译（JIT），将正向和逆向运动学视为可微分操作，从而有效解决了多约束问题中的误差累积和复杂关节限制。在SMPLX人体骨架模型上进行了演示，并与CCD、FABRIK和IPOPT等迭代算法进行了比较。

**Result:** 该IK求解器实现了实时性能，表现出快速收敛、每次迭代计算开销最小以及比现有方法更高的成功率。

**Conclusion:** 提出的实时逆运动学求解器能够有效、高效地生成多约束的虚拟人物运动，并在性能上优于现有迭代算法。

> **ai_Abstract:** 本文提出了一种基于TensorFlow自动微分和即时编译的新型实时逆运动学（IK）求解器，旨在高效生成具有复杂关节限制的虚拟人物多约束运动。该方法将IK视为可微分操作，有效克服了传统迭代算法的误差累积和关节限制问题。实验证明，与现有IK算法相比，该求解器在SMPLX模型上实现了实时性能，并展现出更快的收敛速度、更低的计算开销和更高的成功率。

> **摘要翻译:** 实时生成准确逼真的虚拟人物运动对于计算机图形学、交互式虚拟环境、机器人技术和生物力学等多种应用都至关重要。本文介绍了一种新颖的实时逆运动学（IK）求解器，专门设计用于生成逼真的人体运动。该求解器利用TensorFlow的自动微分和即时编译（JIT）功能，能够高效处理具有高自由度的复杂关节人体骨架。通过将正向和逆向运动学视为可微分操作，我们的方法有效解决了多约束问题中常见的误差累积和复杂关节限制等挑战，这些对于逼真的人体运动建模至关重要。我们在SMPLX人体骨架模型上展示了该求解器的有效性，并将其性能与广泛使用的基于迭代的IK算法（如循环坐标下降（CCD）、FABRIK和非线性优化算法IPOPT）进行了评估。我们的实验涵盖了简单的末端效应器任务和复杂的、具有逼真关节限制的多约束问题。结果表明，我们的IK求解器实现了实时性能，表现出快速收敛、每次迭代计算开销最小以及比现有方法更高的成功率。项目代码可在https://github.com/hvoss-techfak/TF-JAX-IK获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [266] [Exploring the Collaborative Advantage of Low-level Information on Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2504.00463)
> *探索低级信息在可泛化AI生成图像检测中的协同优势*

*Ziyin Zhou, Ke Sun, Zhongxi Chen, Xianming Lin, Yunpeng Luo, Ke Yan, Shouhong Ding, Xiaoshuai Sun* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** AI生成图像检测, 泛化, 低级信息, 特征融合, Lora Experts

**Comment:** 

> **TL;DR:** 提出ALEI框架，通过自适应融合多源低级信息，显著提升AI生成图像检测的泛化能力。

**AI_Comments:** 这篇论文的创新点在于认识到不同低级信息对不同伪造类型的泛化能力差异，并提出了一套复杂的机制（ALEI框架，包括Lora Experts、交叉注意力、低级信息适配器和动态特征选择）来有效融合和利用这些多源低级信息。这显著提升了AI生成图像检测的泛化能力，尤其是在面对未见过的生成方法时，对该领域具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI生成图像检测方法多只考虑单一低级信息，导致泛化能力不佳；不同低级信息对不同伪造类型有不同泛化能力，且简单融合策略不足以利用这些优势。

**Method:** 提出自适应低级专家注入（ALEI）框架。通过Lora专家使骨干网络学习不同低级信息知识；利用交叉注意力在中间层自适应融合特征；开发低级信息适配器防止骨干网络在建模后期丢失低级特征建模能力；提出动态特征选择，动态选择最适合当前图像的特征以最大化泛化检测能力。

**Result:** 该方法仅在四类主流ProGAN数据上微调，但在包含未见过的GAN和Diffusion方法的多个数据集上表现出色，并取得了最先进的结果。

**Conclusion:** 通过ALEI框架有效融合多种低级信息，能够显著提升AI生成图像检测的泛化能力，达到SOTA水平。

> **ai_Abstract:** 本文提出了自适应低级专家注入（ALEI）框架，旨在解决现有AI生成图像检测方法因仅考虑单一低级信息而导致泛化能力不足的问题。ALEI通过引入Lora专家、交叉注意力融合、低级信息适配器和动态特征选择，有效地融合了多种低级信息，使模型能够学习并利用不同低级特征对各种伪造类型的检测优势。实验证明，该方法在未见过的GAN和Diffusion数据集上实现了先进的泛化检测性能。

> **摘要翻译:** 现有最先进的AI生成图像检测方法主要考虑从RGB图像中提取低级信息，例如噪声模式，以帮助提高AI生成图像检测的泛化能力。然而，这些方法通常只考虑单一类型的低级信息，这可能导致次优的泛化效果。通过实证分析，我们发现了一个关键洞察：不同的低级信息通常对不同类型的伪造表现出泛化能力。此外，我们发现简单的融合策略不足以利用每种低级和高级信息对各种伪造类型的检测优势。因此，我们提出了自适应低级专家注入（ALEI）框架。我们的方法引入了Lora专家，使骨干网络（使用高级语义RGB图像训练）能够接受并学习来自不同低级信息的知识。我们利用交叉注意力方法在中间层自适应地融合这些特征。为了防止骨干网络在建模后期失去对不同低级特征的建模能力，我们开发了一个低级信息适配器，与骨干网络提取的特征进行交互。最后，我们提出了动态特征选择，动态选择最适合检测当前图像的特征，以最大限度地提高泛化检测能力。广泛的实验表明，我们的方法仅在四类主流ProGAN数据上进行微调，但在包含未见过的GAN和Diffusion方法的多个数据集上表现出色，并取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [Compact Vision Transformer by Reduction of Kernel Complexity](https://arxiv.org/abs/2507.12780)
> *通过降低核复杂度实现紧凑型视觉Transformer*

*Yancheng Wang, Yingzhen Yang* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 紧凑型视觉Transformer, 核复杂度降低, 通道选择, 泛化界限, 模型效率

**Comment:** 

> **TL;DR:** 本文提出KCR-Transformer，一种紧凑型视觉Transformer块，通过可微分通道选择和新的理论泛化界限来降低计算成本，实现了更优的性能和更少的FLOPs/参数。

**AI_Comments:** 本文的创新之处在于将可微分通道选择与新颖的理论泛化界限相结合来指导剪枝过程，这确保了在降低模型复杂度的同时能保持甚至提升性能。这种泛化感知的剪枝方法是一个显著的优点。此外，KCR-Transformer与现有流行架构的兼容性也大大增加了其实用价值和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 自注意力机制和Transformer架构已成为现代深度学习的基础组件。近期研究致力于将Transformer块集成到紧凑型计算机视觉神经网络中，但仍有提升空间，本研究旨在进一步提高视觉Transformer的紧凑性和效率，同时保持或提高准确性。

**Method:** 本文引入了KCR-Transformer，这是一种紧凑型Transformer块，配备了可微分通道选择功能，并由一个新颖且严格的理论泛化界限指导。KCR-Transformer通过在Transformer块的MLP层中进行输入/输出通道选择来降低计算成本。此外，本文提供了严谨的理论分析，为配备KCR-Transformer块的网络建立了紧密的泛化界限，确保由此产生的网络保持可证明的小泛化误差。它兼容ViT和Swin等流行网络。

**Result:** KCR-Transformer在降低FLOPs的同时保持甚至提高了预测精度。实验结果表明，KCR-Transformer网络在各种计算机视觉任务上取得了卓越的性能，与原始模型相比，FLOPs和参数更少，但性能更优。

**Conclusion:** KCR-Transformer是一种有效且理论上可靠的方法，用于创建紧凑型视觉Transformer，其在效率和性能上均优于现有模型。

> **ai_Abstract:** KCR-Transformer是一种紧凑型Transformer块，通过可微分通道选择和新的理论泛化界限来减少核复杂度。它在MLP层进行输入/输出通道选择以降低计算成本，并提供严格的理论分析以确保剪枝后的网络具有小的泛化误差。KCR-Transformer兼容ViT和Swin等流行网络，能在减少FLOPs和参数的同时保持甚至提高预测精度，并在多项计算机视觉任务上表现出色。

> **摘要翻译:** 自注意力机制和Transformer架构已成为现代深度学习的基础组件。最近的努力已将Transformer块集成到紧凑型神经网络架构中，用于计算机视觉，从而产生了各种高效的视觉Transformer。在这项工作中，我们引入了带核复杂度降低的Transformer，即KCR-Transformer，这是一个紧凑型Transformer块，配备了可微分通道选择功能，并由一个新颖且严格的理论泛化界限指导。KCR-Transformer通过在Transformer块的MLP层中进行输入/输出通道选择来降低计算成本。此外，我们提供了严谨的理论分析，为配备KCR-Transformer块的网络建立了紧密的泛化界限。利用这些强大的理论结果，KCR-Transformer的通道剪枝是以泛化感知的方式进行的，确保了所得网络保持可证明的小泛化误差。我们的KCR-Transformer与许多流行的紧凑型Transformer网络（如ViT和Swin）兼容，它在减少视觉Transformer的FLOPs的同时保持甚至提高了预测精度。在实验中，我们将视觉Transformer中的所有Transformer块替换为KCR-Transformer块，从而形成了具有不同骨干的KCR-Transformer网络。由此产生的KCR-Transformer在各种计算机视觉任务上取得了卓越的性能，甚至比原始模型在更少的FLOPs和参数下表现更好。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [274] [Leveraging Pre-Trained Visual Models for AI-Generated Video Detection](https://arxiv.org/abs/2507.13224)
> *利用预训练视觉模型进行AI生成视频检测*

*Keerthi Veeramachaneni, Praveen Tirupattur, Amrit Singh Bedi, Mubarak Shah* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** AI生成视频检测, 预训练视觉模型, 生成式AI, 视频取证, 虚假信息

**Comment:** 

> **TL;DR:** 本文提出了一种利用预训练视觉模型检测AI生成视频的新方法，无需额外训练即可实现高精度，并通过在提取特征上训练简单线性分类层进一步提高性能，平均检测准确率超过90%。

**AI_Comments:** 该论文的创新之处在于利用现有的预训练视觉模型来解决通用AI生成视频检测这一新兴且紧迫的问题，避免了从头开始训练的复杂性。其方法在不进行大量额外训练的情况下实现了高精度，并通过简单线性分类层进一步优化，体现了效率。此外，研究团队构建并计划公开发布的VID-AID数据集对该领域的研究具有重要贡献，将有助于推动未来研究的进展和方法的比较。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI技术的发展，AI生成视觉内容与真实内容越来越难以区分，这给打击虚假信息、保护隐私和防止安全威胁带来了严峻挑战。尽管AI生成图像检测取得了显著进展，但当前视频检测方法主要集中于DeepFakes（涉及人脸），而视频生成已超越DeepFakes，因此迫切需要检测通用AI生成视频的方法。

**Method:** 本文提出了一种新颖的方法，利用预训练视觉模型来区分真实视频和生成视频。这些预训练模型在大量真实视觉内容上进行过训练，其提取的特征包含固有的信号，可以帮助区分真实视频和生成视频。利用这些提取的特征，无需额外模型训练即可实现高检测性能，并且通过在提取特征之上训练一个简单的线性分类层，可以进一步提高性能。该方法在一个包含约10,000个由9种不同文本到视频模型生成的AI视频和4,000个真实视频（总计超过7小时）的数据集（VID-AID）上进行了验证。

**Result:** 我们的评估显示，所提出的方法实现了高检测准确率，平均超过90%，这突显了其有效性。

**Conclusion:** 本文提出的方法通过利用预训练视觉模型，能够有效地检测AI生成视频，并取得了高准确率。研究团队计划公开发布代码、预训练模型和数据集，以支持该关键领域的持续研究。

> **ai_Abstract:** 本论文提出了一种新颖的方法，旨在检测通用AI生成视频，以弥补当前视频检测方法主要集中于Deepfakes的不足。该方法利用在大量真实视觉内容上训练的预训练视觉模型提取特征，这些特征能够有效区分真实与生成视频。研究团队构建了一个包含10,000个AI生成视频和4,000个真实视频的数据集（VID-AID）进行验证，结果显示该方法平均检测准确率超过90%，证明了其在应对AI生成内容带来的虚假信息和安全威胁方面的有效性。论文还计划公开发布相关资源以促进后续研究。

> **摘要翻译:** 生成式AI（GenAI）的最新进展使得生成视觉内容的质量显著提高。随着AI生成视觉内容与真实内容越来越难以区分，检测生成内容成为打击虚假信息、确保隐私和防止安全威胁的关键挑战。尽管在检测AI生成图像方面取得了实质性进展，但当前视频检测方法主要集中于Deepfakes，这主要涉及人脸。然而，视频生成领域已经超越了DeepFakes，迫切需要能够检测通用AI生成视频的方法。为了解决这一空白，我们提出了一种利用预训练视觉模型来区分真实视频和生成视频的新方法。从这些预训练模型中提取的特征（这些模型在大量的真实视觉内容上进行过训练）包含固有的信号，可以帮助区分真实视频和生成视频。利用这些提取的特征，我们无需额外模型训练即可实现高检测性能，并且通过在提取特征之上训练一个简单的线性分类层，我们进一步提高了性能。我们在一个我们编译的数据集（VID-AID）上验证了我们的方法，该数据集包含约10,000个由9种不同文本到视频模型生成的AI视频，以及4,000个真实视频，总计超过7小时的视频内容。我们的评估显示，我们的方法实现了高检测准确率，平均超过90%，这突显了其有效性。一旦被接受，我们计划公开发布代码、预训练模型和我们的数据集，以支持该关键领域的持续研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [280] [Model-Agnostic, Temperature-Informed Sampling Enhances Cross-Year Crop Mapping with Deep Learning](https://arxiv.org/abs/2506.12885)
> *模型无关、温度感知采样增强深度学习的跨年度作物制图*

*Mehmet Ozgur Turkoglu, Selene Ledain, Helge Aasen* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-17**

**Keywords:** 作物分类, 深度学习, 热时间, 时间序列采样, 不确定性量化

**Comment:** under review

> **TL;DR:** 本文提出了一种名为T3S的模型无关方法，通过用热时间代替日历时间来对光学卫星时间序列进行子采样，从而显著提高跨年度作物分类的准确性，并提供校准良好的不确定性估计，尤其在数据量少和早期季节分类方面表现突出。

**AI_Comments:** 该论文的创新点在于引入了基于生态生理学原理的“热时间”概念来替代传统的“日历时间”进行时间序列采样，这是一种新颖且生物学上更合理的特征工程方法。其重要性体现在解决了深度学习在作物制图领域跨年度泛化能力差和不确定性量化不足的实际问题，特别是在数据稀缺和早期预测场景下的优异表现，极大地提升了遥感作物监测的实用性和可靠性。T3S方法是模型无关的，意味着它具有广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 光学卫星时间序列在作物类型分类中，其跨季节泛化能力受限于年度间天气变化导致的作物物候期偏移，这阻碍了在当前年度标签不可用场景下的实际应用。此外，现有方法常忽视不确定性量化，降低了其在作物监测中的可靠性。

**Method:** 本文提出了一种简单、模型无关的基于热时间的时序采样（T3S）方法，用热时间取代日历时间。通过这种生物学上有意义的方式对时间序列进行子采样，T3S方法突出了生长季节的关键时期，同时减少了时间冗余和噪声。

**Result:** T3S方法在覆盖整个瑞士的多年Sentinel-2数据集上进行了评估，与现有基线相比，分类精度显著提高，并提供了校准良好的不确定性估计。此外，T3S方法在低数据量情况下表现出色，并实现了更准确的早期季节分类。仅使用10%的训练标签，其在精度和不确定性校准方面均优于当前基线，到六月底，其性能已与完整季节基线模型相似。

**Conclusion:** T3S方法通过引入生物学上合理的热时间采样，有效解决了深度学习模型在跨年度作物制图中的泛化性差和不确定性量化不足的问题，显著提升了分类性能和可靠性，尤其适用于数据受限和早期分类场景。

> **ai_Abstract:** 本研究提出了一种名为T3S的模型无关方法，旨在解决深度学习在跨年度作物分类中泛化能力差和不确定性量化不足的问题。该方法通过用热时间替代传统的日历时间对光学卫星时间序列进行采样，从而突出作物生长关键期并减少数据冗余。在瑞士的多年Sentinel-2数据集上，T3S方法显著提升了分类精度，并提供了可靠的不确定性估计。尤其在训练数据有限和早期分类场景下，T3S表现出优越性，仅用少量标签即可达到或超越现有基线模型的性能。

> **摘要翻译:** 利用光学卫星时间序列进行作物类型分类的能力，在跨季节泛化方面仍然受限，特别是当作物物候期因年度间天气变化而发生偏移时。这阻碍了在当前年度标签不可用情景下的实际应用。此外，不确定性量化常常被忽视，这降低了此类方法在操作性作物监测中的可靠性。受植物生长生态生理学原理的启发，我们提出了一种简单、模型无关的基于热时间的时序采样（T3S）方法，该方法用热时间取代了日历时间。通过以这种生物学上有意义的方式对时间序列进行子采样，我们的方法突出了生长季节内的关键时期，同时减少了时间冗余和噪声。我们在一个覆盖整个瑞士的多年Sentinel-2数据集上评估了T3S方法，这使我们能够评估所有应用方法在未见过年份上的表现。与最先进的基线相比，我们的方法在分类精度上取得了实质性改进，并且关键的是，提供了校准良好的不确定性估计。此外，T3S方法在低数据量情况下表现出色，并能够实现显著更准确的早期季节分类。仅使用10%的训练标签，它在精度和不确定性校准方面均优于当前基线，到六月底，它达到了与完整季节基线模型相似的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [286] [Vidi: Large Multimodal Models for Video Understanding and Editing](https://arxiv.org/abs/2504.15681)
> *Vidi: 用于视频理解和编辑的大型多模态模型*

*Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang, Lu Guo, Lusha Li, Longyin Wen, Qingyu Chen, Rachel Deng, Sijie Zhu, Stuart Siew, Tong Jin, Wei Lu, Wen Zhong, Xiaohui Shen, Xin Gu, Xing Mei, Xueqiong Qu, Zhenfang Chen* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 大型多模态模型, 视频理解, 视频编辑, 时间检索, VUE-TR基准

**Comment:** 

> **TL;DR:** Vidi是一个大型多模态模型家族，专注于视频理解和编辑，尤其在长视频的时间检索方面表现出色，并推出了VUE-TR基准进行评估。

**AI_Comments:** Vidi的创新之处在于其作为LMMs处理视频的全面性，特别是针对长视频的时间检索能力，这在智能视频编辑中具有重要意义。同时，提出的VUE-TR基准通过引入更长的视频、音频支持和改进的评估指标，为真实世界视频理解任务提供了一个更具挑战性和实用性的评估框架，有助于推动该领域的研究进展。其超越GPT-4o和Gemini的性能表明了Vidi在该特定任务上的专业性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 互联网上视频已成为重要的交流和表达媒介。为了支持高质量、大规模视频内容的创作，现代流程需要全面理解原始素材和编辑组件。传统模型在处理多模态、长输入视频方面面临挑战，尤其是在视频编辑场景中。

**Method:** 本文介绍了Vidi，一个用于广泛视频理解和编辑场景的大型多模态模型（LMMs）家族。首次发布专注于时间检索，即识别输入视频中与给定文本查询对应的时间范围。该模型能够处理长达数小时的视频，并具有强大的时间理解能力。为了支持真实场景的全面评估，作者还提出了VUE-TR基准，该基准在视频时长、音频支持、查询格式、注释质量和评估指标方面有五项关键改进。

**Result:** Vidi在时间检索任务上显著优于领先的专有模型，例如GPT-4o和Gemini，这表明其在视频编辑场景中的优越性。VUE-TR基准的视频时长显著长于现有数据集，并支持音频查询和多样化的查询格式。

**Conclusion:** Vidi作为大型多模态模型，在视频理解和编辑方面，特别是在处理长视频的时间检索任务上，展现出卓越的性能，并为该领域提供了一个新的、更全面的评估基准VUE-TR，有望推动智能视频编辑的发展。

> **ai_Abstract:** 本文介绍了Vidi，一个用于视频理解和编辑的大型多模态模型家族。该模型专注于解决长视频的多模态处理挑战，尤其在时间检索任务中表现出色，能够精准识别长视频中与文本查询对应的时间范围。为促进真实世界场景的评估，研究团队还提出了VUE-TR基准，该基准在视频时长、音频支持、查询格式、标注质量和评估指标方面进行了改进。实验结果显示，Vidi在时间检索任务上显著超越了现有领先模型，证明了其在视频编辑应用中的强大潜力。

> **摘要翻译:** 人类自然地与他们联系的人分享信息，视频已成为互联网上交流和表达的主导媒介之一。为了支持高质量、大规模视频内容的创建，现代流程需要全面理解原始输入材料（例如，相机捕获的未编辑素材）和编辑组件（例如，视觉效果）。在视频编辑场景中，模型必须处理多种模态（例如，视觉、音频、文本），具备强大的背景知识，并处理灵活的输入长度（例如，长达数小时的原始视频），这对传统模型构成了重大挑战。在本报告中，我们介绍了Vidi，一个用于广泛视频理解和编辑场景的大型多模态模型（LMMs）家族。首次发布专注于时间检索，即识别输入视频中与给定文本查询对应的时间范围，这在智能编辑中起着关键作用。该模型能够处理长达数小时的视频，并具有强大的时间理解能力，例如，检索特定查询的时间范围。为了支持真实场景的全面评估，我们还提出了VUE-TR基准，它引入了五项关键改进：1）视频时长：显著长于现有时间检索数据集的视频；2）音频支持：包含基于音频的查询；3）查询格式：多样化的查询长度/格式；4）注释质量：地面真实时间范围是手动标注的；5）评估指标：一种改进的IoU指标，支持对多个时间范围的评估。值得注意的是，Vidi在时间检索任务上显著优于领先的专有模型，例如GPT-4o和Gemini，表明其在视频编辑场景中的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [291] [RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction](https://arxiv.org/abs/2507.12967)
> *RGB预训练增强的不可观测特征潜在扩散模型用于光谱重建*

*Keli Deng, Jie Nie, Yuntao Qian* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 光谱重建, 潜在扩散模型, RGB预训练, 不可观测特征, 高光谱图像

**Comment:** 

> **TL;DR:** 本文提出了一种名为ULDM的新型潜在扩散模型，通过利用RGB预训练模型的空间知识和两阶段训练流程，有效估计不可观测特征并从RGB图像重建高光谱图像，实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于将RGB预训练模型的空间知识引入到高光谱图像重建中，并专注于建模难以捕获的“不可观测特征”。通过将光谱和空间特征分离处理，并利用潜在扩散模型进行学习，有效地解决了光谱重建中的关键难题。两阶段训练管道的设计也使其能够更专注于不同维度的特征学习。这种方法不仅提升了重建精度，还在下游任务中展现了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 光谱重建（SR）中的一个关键难题是估计未被RGB成像传感器捕获的不可观测特征，这些特征包含重要的光谱信息。为了解决这个问题，需要有效地构建以RGB图像为条件的光谱-空间联合分布来补充不可观测特征。由于高光谱图像与对应的RGB图像共享相似的空间结构，因此可以利用RGB预训练模型中丰富的空间知识进行光谱-空间联合分布学习。

**Method:** 本文将RGB预训练的潜在扩散模型（RGB-LDM）扩展为不可观测特征潜在扩散模型（ULDM）用于光谱重建。该方法通过将不可观测特征从高光谱图像中分离出来，减少冗余光谱信息，使ULDM能够在紧凑的潜在空间中学习联合分布。具体来说，提出了一个两阶段的管道：第一阶段，训练光谱不可观测特征自编码器（SpeUAE）来提取和压缩不可观测特征，使其与RGB空间对齐的三维流形。第二阶段，光谱和空间结构分别由SpeUAE和SpaAE编码，然后ULDM在对应RGB图像的引导下对编码后的不可观测特征的分布进行建模。

**Result:** 在光谱重建（SR）和下游重照明任务上的实验结果表明，所提出的方法实现了最先进的性能。

**Conclusion:** 本文提出的RGB预训练增强的不可观测特征潜在扩散模型（ULDM）通过有效估计未捕获的光谱信息，成功地从RGB图像重建高光谱图像，并在多项任务中达到最先进的性能，证明了利用RGB预训练模型空间知识和分离不可观测特征的有效性。

> **ai_Abstract:** 本文提出了一种名为不可观测特征潜在扩散模型（ULDM）的新型光谱重建方法。该方法旨在解决从RGB图像重建高光谱图像时难以估计未捕获光谱信息的问题。通过利用RGB预训练模型的丰富空间知识，并将ULDM建立在RGB-LDM之上，模型能够专注于光谱结构建模。ULDM通过将不可观测特征与高光谱图像分离，并在紧凑的潜在空间中学习联合分布。其两阶段管道包括光谱不可观测特征自编码器（SpeUAE）用于特征提取和压缩，以及光谱与空间结构的顺序编码和ULDM的分布建模。实验证明，该方法在光谱重建和重照明任务上均达到了最先进的性能。

> **摘要翻译:** 光谱重建（SR）是图像处理中的一个关键问题，它需要从对应的RGB图像重建高光谱图像（HSI）。SR的一个关键难点是估计不可观测特征，这些特征包含了RGB成像传感器未捕获的重要光谱信息。解决方案在于有效构建以RGB图像为条件的光谱-空间联合分布，以补充不可观测特征。由于高光谱图像与对应的RGB图像共享相似的空间结构，因此利用RGB预训练模型中丰富的空间知识进行光谱-空间联合分布学习是合理的。为此，我们将RGB预训练的潜在扩散模型（RGB-LDM）扩展为用于SR的不可观测特征潜在扩散模型（ULDM）。由于RGB-LDM及其对应的空间自编码器（SpaAE）在空间知识方面已经表现出色，ULDM可以专注于建模光谱结构。此外，将不可观测特征从HSI中分离出来减少了冗余光谱信息，并使ULDM能够在紧凑的潜在空间中学习联合分布。具体来说，我们提出了一个两阶段的管道，包括光谱结构表示学习和光谱-空间联合分布学习，以将RGB-LDM转换为ULDM。在第一阶段，训练光谱不可观测特征自编码器（SpeUAE）来提取和压缩不可观测特征到一个与RGB空间对齐的三维流形中。在第二阶段，光谱和空间结构分别由SpeUAE和SpaAE顺序编码。然后，ULDM在对应RGB图像的引导下，获取并建模编码后的不可观测特征的分布。在SR和下游重照明任务上的实验结果表明，我们提出的方法实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [301] [MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification](https://arxiv.org/abs/2507.12602)
> *MS-DGCNN++：一种融合生物知识的多尺度融合动态图神经网络用于LiDAR树种分类*

*Said Ohamouddou, Abdellatif El Afia, Hanaa El Afia, Raddouane Chiheb* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-16**

**Keywords:** LiDAR, 树种分类, 动态图神经网络, 多尺度融合, 生物知识

**Comment:** 

> **TL;DR:** MS-DGCNN++ 是一种新的多尺度动态图神经网络，通过分层融合和生物知识集成，显著提高了LiDAR树种分类和3D对象识别的准确性，且参数量更少。

**AI_Comments:** 该论文的创新点在于提出了分层多尺度融合策略和将生物知识（如树木的局部、分支和树冠结构）集成到特征工程中，这使得模型能够更好地捕获树木的自然结构语义信息。与之前并行处理的多尺度方法相比，这种差异化处理更符合生物学直觉。此外，该模型在保持高精度的同时，降低了参数量和复杂度，使其在资源受限场景下具有实用性。其在3D对象识别上的泛化能力也突出了其通用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有使用多尺度动态图卷积神经网络（MS-DGCNN）的方法采用并行多尺度处理，未能捕获树木分层结构中语义关系，导致LiDAR点云树种分类面临挑战。

**Method:** 提出了MS-DGCNN++，一个分层多尺度融合动态图卷积网络。它在局部、分支和树冠尺度上使用语义有意义的特征提取，并进行跨尺度信息传播。该方法采用尺度特定的特征工程，包括局部尺度的标准几何特征、分支尺度的归一化相对向量和树冠尺度的距离信息。这种分层方法取代了统一的并行处理，提供了与自然树木结构对齐的语义差异化表示。

**Result:** 在STPCTLS数据集上，MS-DGCNN++的准确率达到94.96%，优于DGCNN、MS-DGCNN和最先进的模型PPT。在FOR-species20K数据集上，准确率达到67.25%（比MS-DGCNN提高6.1%）。在标准3D对象识别方面，在ModelNet40上整体准确率达到93.15%，在ModelNet10上达到94.05%，优于DGCNN和MS-DGCNN。与最先进的Transformer方法相比，参数量更少，复杂度更低。该方法可推广到标准3D对象识别。

**Conclusion:** MS-DGCNN++通过其分层多尺度融合和生物知识集成，显著提高了LiDAR树种分类的准确性，并能泛化到标准3D对象识别，是一种适用于资源受限应用且具有竞争性准确度的多功能解决方案。

> **ai_Abstract:** MS-DGCNN++是一种新的动态图神经网络，专为LiDAR树种分类设计，通过引入分层多尺度融合和生物知识集成来解决现有方法未能捕获树木语义分层关系的问题。它在局部、分支和树冠尺度上提取语义特征并进行跨尺度信息传播。实验结果表明，MS-DGCNN++在STPCTLS和FOR-species20K树种分类数据集上显著优于现有方法，并在ModelNet40和ModelNet10等标准3D对象识别任务上也表现出色，同时具有更低的参数量和复杂度，适用于资源受限环境。

> **摘要翻译:** 从地面LiDAR点云进行树种分类极具挑战性，因为森林环境中存在复杂的多尺度几何结构。现有使用多尺度动态图卷积神经网络（MS-DGCNN）的方法采用并行多尺度处理，未能捕获树木分层结构中语义关系。我们提出了MS-DGCNN++，一个分层多尺度融合动态图卷积网络，它在局部、分支和树冠尺度上使用语义有意义的特征提取，并进行跨尺度信息传播。我们的方法采用尺度特定的特征工程，包括局部尺度的标准几何特征、分支尺度的归一化相对向量和树冠尺度的距离信息。这种分层方法取代了统一的并行处理，提供了与自然树木结构对齐的语义差异化表示。在所有实验中，采用相同的树种数据增强策略，MS-DGCNN++在STPCTLS上实现了94.96%的准确率，优于DGCNN、MS-DGCNN和最先进的模型PPT。在FOR-species20K上，它实现了67.25%的准确率（比MS-DGCNN提高6.1%）。对于标准3D对象识别，我们的方法在ModelNet40上以93.15%和在ModelNet10上以94.05%的整体准确率优于DGCNN和MS-DGCNN。与最先进的Transformer方法相比，我们的方法具有更低的参数和更低的复杂性，适用于资源受限的应用，同时保持了有竞争力的准确性。除了树木分类，该方法还推广到标准3D对象识别，使其成为一种适用于各种点云处理应用的多功能解决方案。实现代码已在https://github.com/said-ohamouddou/MS-DGCNN2 公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [302] [City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning](https://arxiv.org/abs/2507.12795)
> *City-VLM：通过多模态不完全学习实现多领域感知场景理解*

*Penglei Sun, Yaoxian Song, Xiangru Zhu, Xiang Liu, Qiang Wang, Yue Liu, Changqun Xia, Tiefeng Li, Yang Yang, Xiaowen Chu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 户外场景理解, 大型视觉语言模型, 多模态学习, 不完全学习, 数据集

**Comment:** 

> **TL;DR:** 针对现有LVLM在户外场景理解中的局限性，本文提出了City-VLM模型和SVM-City数据集，通过不完全多模态学习显著提升了户外问答任务的性能。

**AI_Comments:** 本文的创新点在于构建了首个多领域、多视角、多模态的户外大规模场景理解数据集SVM-City，并提出了City-VLM模型，通过“不完全多模态学习”有效解决了户外数据模态缺失的挑战。这种方法通过构建联合概率分布空间进行融合，避免了传统拼接的局限性，显著提升了模型在复杂户外环境下的感知和理解能力，对于推动LVLM在现实世界部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型视觉语言模型（LVLMs）主要关注室内任务，但在户外大规模场景理解中面临两方面显著局限：1) 户外场景通常包含通过多传感器、多视点（如鸟瞰和地面）观察到的大规模环境，而现有室内LVLMs主要分析单一视觉模态且视角受限；2) 现有LVLMs缺乏多领域感知户外数据，并且难以有效整合2D和3D视觉信息。

**Method:** 为解决上述问题，本文构建了首个多领域感知户外场景理解数据集SVM-City，该数据集包含来自车辆、低空无人机、高空飞机和卫星的420k图像、4811M点云和567k问答对，涵盖多尺度、多视角和多模态指令微调数据。此外，本文引入了不完全多模态学习来建模户外场景理解，以有效融合缺少某一模态的数据，并设计了名为City-VLM的LVLM。多模态融合通过构建联合概率分布空间而非直接显式融合操作（如拼接）来实现。

**Result:** City-VLM在三个典型的户外场景理解任务中，平均在问答任务上超越现有LVLMs 18.14%的性能。

**Conclusion:** 本文提出的方法在多个户外场景中展示了实用性和泛化性能。

> **ai_Abstract:** 针对现有大型视觉语言模型在户外大规模场景理解中面临的数据和模型局限性，本文提出了首个多领域感知户外场景理解数据集SVM-City，以及一个名为City-VLM的新型LVLM。City-VLM通过引入不完全多模态学习和构建联合概率分布空间来有效融合多模态数据，即使在模态缺失的情况下也能进行场景理解。实验结果表明，City-VLM在户外问答任务上显著优于现有LVLM，平均性能提升18.14%，展现了其在多户外场景中的实用性和泛化能力。

> **摘要翻译:** 场景理解使智能体能够解释和理解其环境。虽然现有用于场景理解的大型视觉语言模型（LVLMs）主要专注于室内家庭任务，但当它们应用于户外大规模场景理解时面临两个显著限制。首先，户外场景通常包含通过多个视点（例如，鸟瞰图和地面视图）从各种传感器观察到的大规模环境，而现有室内LVLMs主要在建筑规模的背景下从类人视点分析单一视觉模态。其次，现有LVLMs面临多领域感知户外数据的缺失，并且难以有效整合2D和3D视觉信息。为了解决上述限制，我们构建了第一个多领域感知户外场景理解数据集，命名为\textbf{\underline{SVM-City}}，它来源于多\textbf{\underline{S}}尺度场景，包含多\textbf{\underline{V}}视角和多\textbf{\underline{M}}模态指令微调数据。它包含来自车辆、低空无人机、高空飞机和卫星的420k图像和4811M点云，以及567k问答对。为了在缺少一种模态的情况下有效融合多模态数据，我们引入了不完全多模态学习来建模户外场景理解，并设计了名为\textbf{\underline{City-VLM}}的LVLM。多模态融合通过构建联合概率分布空间而非直接显式融合操作（例如拼接）来实现。在三个典型户外场景理解任务上的实验结果表明，City-VLM在问答任务上平均超越现有LVLMs 18.14%的性能。我们的方法在多个户外场景中展示了实用性和泛化性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](https://arxiv.org/abs/2505.02179)
> *ProDisc-VAD：一种用于视频监控中弱监督异常检测的高效系统*

*Tao Zhu, Qi Yu, Xinru Dong, Shiyu Li, Yue Liu, Jinlong Jiang, Lei Shu* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 弱监督异常检测, 视频监控, 多实例学习, 原型学习, 对比学习

**Comment:** arXiv admin comment: This version has been removed by arXiv
  administrators as the submitter did not have the rights to agree to the
  license at the time of submission

> **TL;DR:** ProDisc-VAD是一种高效的弱监督视频异常检测系统，通过原型交互层和伪实例判别增强损失来解决标签模糊问题，实现了高性能和极低的参数量。

**AI_Comments:** ProDisc-VAD的创新点在于其通过PIL和PIDE损失协同解决了WS-VAD中的标签模糊问题，提供了一种高效且参数量极小的解决方案。其显著的参数量减少（比ViT-based方法少800倍以上）同时保持高精度，显示出其在实际应用中的巨大潜力，尤其是在资源受限的环境下。这是一个重要的进展，因为它克服了传统MIL方法在WS-VAD中遇到的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有的使用多实例学习（MIL）的弱监督视频异常检测（WS-VAD）方法存在标签模糊问题，这阻碍了判别性特征的学习。

**Method:** 本文提出了ProDisc-VAD，一个包含两个协同组件的框架：原型交互层（PIL）使用少量可学习原型进行受控的正常性建模，建立稳健的基线；伪实例判别增强（PIDE）损失通过仅对最可靠的极端得分实例（最高/最低得分）应用有针对性的对比学习来提高可分离性。

**Result:** ProDisc-VAD在ShanghaiTech数据集上实现了97.98%的AUC，在UCF-Crime数据集上实现了87.12%的AUC，并且仅使用0.4M参数，比最近基于ViT的方法（如VadCLIP）少800倍以上。

**Conclusion:** ProDisc-VAD通过解决弱监督异常检测中的标签模糊问题，提供了一种高效且高性能的解决方案，显著降低了模型复杂度。

> **ai_Abstract:** ProDisc-VAD是一个针对弱监督视频异常检测（WS-VAD）中标签模糊问题而设计的高效框架。它通过原型交互层（PIL）进行受控的正常性建模，并利用伪实例判别增强（PIDE）损失对最可靠的极端得分实例进行对比学习，以增强特征判别性。该系统在多个基准数据集上取得了优异的性能（ShanghaiTech 97.98% AUC，UCF-Crime 87.12% AUC），同时参数量极低（0.4M），远低于其他先进方法。

> **摘要翻译:** 弱监督视频异常检测（WS-VAD）使用多实例学习（MIL）时存在标签模糊问题，这阻碍了判别性特征的学习。我们提出了ProDisc-VAD，一个高效的框架，通过两个协同组件解决这个问题。原型交互层（PIL）使用少量可学习原型提供受控的正常性建模，建立了一个稳健的基线，而不会被占主导地位的正常数据淹没。伪实例判别增强（PIDE）损失通过仅对最可靠的极端得分实例（最高/最低得分）应用有针对性的对比学习来提高可分离性。ProDisc-VAD在ShanghaiTech数据集上实现了97.98%的AUC，在UCF-Crime数据集上实现了87.12%的AUC，并且仅使用0.4M参数，比最近基于ViT的方法（如VadCLIP）少800倍以上。代码可在https://github.com/modadundun/ProDisc-VAD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [320] [DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment](https://arxiv.org/abs/2507.12796)
> *DeQA-Doc：将DeQA-Score应用于文档图像质量评估*

*Junjie Gao, Runze Liu, Yingzhe Peng, Shujian Yang, Jin Zhang, Kai Yang, Zhiyuan You* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 文档质量评估, 多模态大语言模型, DeQA-Score, 图像质量评估, 软标签

**Comment:** 

> **TL;DR:** DeQA-Doc通过将先进的MLLM-based图像质量评估器DeQA-Score适应到文档领域，显著提升了文档图像质量评估的准确性和泛化性。

**AI_Comments:** 本文的创新之处在于成功地将多模态大语言模型（MLLMs）在通用图像质量评估方面的成功经验，通过DeQA-Score的适应性改造，扩展到专门的文档图像质量评估领域。特别是其提出的软标签策略和对大分辨率文档图像的适应性处理，以及集成方法的运用，都体现了解决实际应用挑战的有效性。这项工作对于文档数字化、OCR和归档等领域具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文档质量评估方法在提供准确和鲁棒的质量分数方面存在困难，限制了它们在实际场景中的应用。

**Method:** 本文提出了DeQA-Doc框架，该框架利用多模态大语言模型（MLLMs）的视觉语言能力和软标签策略来回归连续的文档质量分数。为了将DeQA-Score适应到DeQA-Doc，作者采用了两种互补的解决方案来构建不带方差信息的软标签，并放宽了分辨率限制以支持文档图像的大分辨率。此外，引入了集成方法来进一步增强性能。

**Result:** 广泛的实验表明，DeQA-Doc显著优于现有基线，在各种降解类型下提供准确且可泛化的文档质量评估。

**Conclusion:** DeQA-Doc成功地将MLLM-based图像质量评估的成功扩展到文档领域，并通过其创新的适应策略，实现了在文档图像质量评估方面卓越的性能和泛化能力。

> **ai_Abstract:** DeQA-Doc是一个新颖的框架，旨在解决现有文档图像质量评估方法准确性和鲁棒性不足的问题。它通过将先进的基于多模态大语言模型（MLLM）的图像质量评估器DeQA-Score适应到文档领域来实现这一目标。DeQA-Doc利用MLLMs的视觉语言能力和软标签策略来预测连续的文档质量分数，并通过构建软标签的互补方案、放宽分辨率限制以及采用集成方法来优化性能。实验结果表明，DeQA-Doc在各种降解类型下均显著优于现有基线，提供了准确且泛化能力强的文档质量评估。

> **摘要翻译:** 文档质量评估对于包括文档数字化、OCR和归档在内的广泛应用至关重要。然而，现有方法往往难以提供准确和鲁棒的质量分数，限制了它们在实际场景中的适用性。随着多模态大语言模型（MLLMs）的快速发展，最近基于MLLM的方法在图像质量评估方面取得了显著的性能。在这项工作中，我们通过将先进的基于MLLM的图像质量评分器DeQA-Score适应到文档质量评估中，将这一成功扩展到文档领域。我们提出了DeQA-Doc，一个利用MLLMs的视觉语言能力和软标签策略来回归连续文档质量分数的框架。为了将DeQA-Score适应到DeQA-Doc，我们采用了两种互补的解决方案来构建不带方差信息的软标签。此外，我们放宽了分辨率限制以支持文档图像的大分辨率。最后，我们引入了集成方法来进一步增强性能。广泛的实验表明，DeQA-Doc显著优于现有基线，在各种降解类型下提供准确且可泛化的文档质量评估。代码和模型权重可在 https://github.com/Junjie-Gao19/DeQA-Doc 获得。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [328] [DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation](https://arxiv.org/abs/2507.13292)
> *DiffClean：基于扩散模型的卸妆技术用于准确年龄估计*

*Ekta Balkrishna Gavas, Chinmay Hegde, Nasir Memon, Sudipta Banerjee* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 卸妆, 年龄估计, 人脸验证, 扩散模型, 化妆攻击

**Comment:** 

> **TL;DR:** DiffClean使用扩散模型去除面部化妆痕迹，以提高年龄估计和人脸验证的准确性。

**AI_Comments:** 该研究创新性地将文本引导扩散模型应用于面部卸妆，以解决年龄估计和人脸验证中的“化妆攻击”问题。其重要性在于提升了在线平台年龄验证的可靠性，对保护未成年人具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确的年龄验证对于保护未成年用户访问受限服务至关重要。然而，面部化妆会改变感知到的身份和年龄，从而干扰准确的年龄估计。

**Method:** 提出DiffClean，它利用文本引导的扩散模型来擦除面部化妆痕迹，以防御化妆攻击。

**Result:** DiffClean在数字模拟和真实化妆图像上，将年龄估计（未成年人与成年人准确率）提高了4.8%，人脸验证（在FMR=0.01%时TMR提高了8.9%），优于现有基线。

**Conclusion:** DiffClean通过有效地去除化妆痕迹，显著提高了年龄估计和人脸验证的准确性，成功防御了化妆攻击。

> **ai_Abstract:** 本文提出了DiffClean，一种基于文本引导扩散模型的卸妆方法，旨在解决面部化妆对年龄估计和人脸验证准确性的干扰问题。通过去除化妆痕迹，DiffClean显著提升了年龄估计（未成年人与成年人准确率提高4.8%）和人脸验证（TMR提高8.9%）的性能，有效防御了化妆攻击。

> **摘要翻译:** 准确的年龄验证可以保护未成年用户免受未经授权访问提供年龄限制服务的在线平台和电子商务网站。然而，准确的年龄估计可能会受到多种因素的干扰，其中包括面部化妆，它会改变感知到的身份和年龄，从而欺骗人类和机器。在这项工作中，我们提出了DiffClean，它使用文本引导的扩散模型来擦除化妆痕迹，以防御化妆攻击。DiffClean在数字模拟和真实化妆图像上，相比现有基线，将年龄估计（未成年人与成年人准确率）提高了4.8%，人脸验证（在FMR=0.01%时TMR提高了8.9%）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [339] [Variance-Based Pruning for Accelerating and Compressing Trained Networks](https://arxiv.org/abs/2507.12988)
> *基于方差的剪枝用于加速和压缩已训练网络*

*Uranik Berisha, Jens Mehnert, Alexandru Paul Condurache* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 网络剪枝, 模型压缩, Vision Transformers, 深度学习, 加速

**Comment:** Accepted at IEEE/CVF International Conference on Computer Vision
  (ICCV) 2025

> **TL;DR:** 本文提出了一种基于方差的剪枝方法，这是一种简单、结构化的一次性剪枝技术，能够高效压缩和加速已训练的网络，且只需极少的微调即可恢复高精度。

**AI_Comments:** 该论文在网络剪枝领域取得了重要进展，提供了一种一次性的结构化方法，显著减少了传统剪枝技术中常见的耗时再训练需求。其创新之处在于“基于方差”的神经元选择和平均激活的重新整合，有效地保持了模型性能。这种方法对于在资源受限设备上部署大型模型尤为重要，使最先进的网络更具可访问性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 大型模型（如Vision Transformers）的训练成本日益昂贵，且其高延迟、计算成本和内存需求对部署构成挑战，尤其是在资源受限的硬件上。现有结构化剪枝方法通常需要大量耗时的再训练来恢复精度。

**Method:** 引入了基于方差的剪枝（Variance-Based Pruning），这是一种简单、结构化的一次性剪枝技术。该方法首先收集激活统计数据以选择要剪枝的神经元，同时将平均激活重新整合回模型中以保持高性能。

**Result:** 在ImageNet-1k识别任务上，DeiT-Base在剪枝后直接保留了超过70%的原始性能，并且只需10个epochs的微调即可恢复99%的原始精度。同时，MACs减少了35%，模型大小减少了36%，模型加速了1.44倍。

**Conclusion:** 基于方差的剪枝有效地解决了结构化剪枝后保持模型性能同时避免大量再训练的挑战，实现了显著的模型压缩和加速。

> **ai_Abstract:** 本文提出了一种名为“基于方差的剪枝”（Variance-Based Pruning）的新型一次性结构化剪枝技术，旨在以最少的微调来加速和压缩大型预训练神经网络。该方法通过收集激活统计数据选择要剪枝的神经元，并将平均激活重新整合回模型中以保持性能，从而解决了部署大型模型时高计算和内存成本的挑战。在ImageNet-1k上的实验表明，该方法显著减少了MACs（35%）和模型大小（36%），实现了1.44倍的模型加速，并且DeiT-Base模型仅通过10个epochs的微调就恢复了99%的原始精度。

> **摘要翻译:** 日益昂贵的训练更大模型（如Vision Transformers）促使人们重复利用大量已训练的SOTA网络。然而，它们的延迟、高计算成本和内存需求给部署带来了巨大挑战，尤其是在资源受限的硬件上。虽然结构化剪枝方法可以减少这些因素，但它们通常需要昂贵的再训练，有时甚至长达数百个epochs，或者甚至从头开始训练以恢复因结构修改而损失的精度。在结构化剪枝后保持已训练模型的性能并因此避免大量再训练仍然是一个挑战。为了解决这个问题，我们引入了基于方差的剪枝（Variance-Based Pruning），这是一种简单且结构化的一次性剪枝技术，用于高效压缩网络，且只需极少的微调。我们的方法首先收集激活统计数据，用于选择要剪枝的神经元。同时，平均激活被重新整合到模型中以保持高度的性能。在ImageNet-1k识别任务上，我们证明了DeiT-Base在剪枝后直接保留了超过70%的原始性能，并且只需10个epochs的微调即可恢复99%的原始精度，同时将MACs减少了35%，模型大小减少了36%，从而将模型加速了1.44倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [346] [Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID](https://arxiv.org/abs/2505.03557)
> *通过增强生成合成数据以改进DreamBooth和InstantID中的面部相似度*

*Koray Ulusan, Benjamin Kiefer* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 面部相似度, 数据增强, DreamBooth, InstantID, 稳定扩散

**Comment:** Accepted to CVPR 2025 Workshop "Synthetic Data for Computer Vision
  Workshop", https://syndata4cv.github.io/ Revised version

> **TL;DR:** 本研究评估了在DreamBooth和InstantID中，通过增强（包括经典增强和生成式增强）生成合成数据对个性化稳定扩散中面部相似度的影响，发现InstantID生成式增强在平衡真实图像使用时能提高保真度。

**AI_Comments:** 该研究创新性地探讨了在个性化文本到图像生成中，通过结合生成式增强来提升面部相似度的潜力。特别是引入InstantID作为生成式增强手段，并使用FaceDistance指标进行定量评估，为优化模型训练提供了新的视角。研究结果对于解决现有模型在面部身份保持方面的挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在从业余照片生成专业肖像时，个性化稳定扩散面临维持面部相似度的挑战。

**Method:** 本研究评估了两种个性化方法（DreamBooth和InstantID）中增强策略的影响。比较了经典增强（翻转、裁剪、颜色调整）和使用InstantID合成图像的生成式增强。使用SDXL和基于FaceNet的新FaceDistance指标定量评估面部相似度，并通过97名参与者的用户研究进行验证。

**Result:** 经典增强可能导致损害身份保留的伪影。InstantID在与真实图像平衡使用以避免过拟合时，能提高保真度。用户研究证实了高真实感，并且用户更偏好InstantID的精致外观而非DreamBooth的身份准确性。

**Conclusion:** 研究结果为个性化文本到图像生成中有效的增强策略提供了信息。

> **ai_Abstract:** 本研究探讨了在DreamBooth和InstantID中，通过不同增强策略（经典增强与生成式增强）生成合成数据对稳定扩散模型中面部相似度保持的影响。研究发现，经典增强可能引入伪影，而InstantID生成的合成数据若能与真实图像平衡使用，则能有效提升面部保真度。定量评估和用户研究均证实了InstantID在生成高质量、高真实感图像方面的优势，为个性化文本到图像生成提供了有效的增强策略指导。

> **摘要翻译:** 从业余照片生成专业肖像时，个性化稳定扩散面临维持面部相似度的挑战。本文评估了增强策略对两种个性化方法（DreamBooth和InstantID）的影响。我们比较了经典增强（翻转、裁剪、颜色调整）与使用InstantID合成图像的生成式增强，以丰富训练数据。使用SDXL和基于FaceNet的新FaceDistance指标，我们定量评估了面部相似度。结果显示，经典增强可能导致损害身份保留的伪影，而InstantID在与真实图像平衡使用以避免过拟合时，能提高保真度。一项包含97名参与者的用户研究证实了高照片真实感，并偏好InstantID的精致外观而非DreamBooth的身份准确性。我们的发现为个性化文本到图像生成中有效的增强策略提供了信息。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [349] [Predicting Soccer Penalty Kick Direction Using Human Action Recognition](https://arxiv.org/abs/2507.12617)
> *利用人类行为识别预测足球点球方向*

*David Freire-Obregón, Oliverio J. Santana, Javier Lorenzo-Navarro, Daniel Hernández-Sosa, Modesto Castrillón-Santana* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 动作识别, 点球预测, 深度学习, 足球, 数据集

**Comment:** Accepted at 23rd International Conference on Image Analysis and
  Processing (ICIAP 2025)

> **TL;DR:** 该研究提出了一个新颖的足球点球数据集，并使用深度学习分类器基于踢球前球员动作预测射门方向，准确率高达63.9%，优于守门员的判断。

**AI_Comments:** 该论文的创新点在于构建了一个专门用于足球点球方向预测的标注数据集，并提出了一个结合HAR特征和上下文元数据的深度学习模型。其重要性在于为体育领域的动作预测提供了一个有效的解决方案和基准，并且模型性能超越了人类表现，具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 人类行为识别（HAR）中的动作预测在实际体育场景中的应用受限于缺乏合适的标注数据集。

**Method:** 研究提出了一个手动标注的足球点球数据集，并开发了一个深度学习分类器，该分类器结合了基于HAR的特征嵌入和上下文元数据。该模型在MViTv2、MViTv1、SlowFast、Slow、X3D、I3D、C2D等七种架构家族的二十二个骨干模型上进行了评估。

**Result:** 模型在预测射门方向（左或右）方面达到了63.9%的准确率，表现优于实际守门员的判断。

**Conclusion:** 该数据集对于预测性动作识别具有价值，并且所提出的模型作为一种通用的体育预测任务方法具有潜力。

> **ai_Abstract:** 本研究旨在解决人类行为识别在体育场景中应用受限的问题，通过构建一个新颖的足球点球手动标注数据集，并开发了一个结合HAR特征嵌入和上下文元数据的深度学习分类器。该模型在预测点球射门方向（左或右）上取得了63.9%的准确率，超越了真实守门员的判断，展示了数据集和模型在体育预测领域的潜力。

> **摘要翻译:** 人类行为识别（HAR）中的动作预测已成为一个突出的话题。然而，其在现实体育场景中的应用受限于缺乏合适的标注数据集。本工作提出了一个新颖的手动标注足球点球数据集，用于根据踢球前球员的动作预测射门方向。我们提出了一个深度学习分类器来对该数据集进行基准测试，该分类器将基于HAR的特征嵌入与上下文元数据相结合。我们在七种架构家族（MViTv2、MViTv1、SlowFast、Slow、X3D、I3D、C2D）的二十二个骨干模型上进行了评估，在预测射门方向（左或右）方面达到了高达63.9%的准确率，优于实际守门员的判断。这些结果证明了该数据集对于预测性动作识别的价值，并验证了我们模型作为体育类预测任务通用方法的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [362] [DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model](https://arxiv.org/abs/2507.13145)
> *DINO-VO：一种利用视觉基础模型的基于特征的视觉里程计*

*Maulana Bisyir Azhari, David Hyunchul Shim* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 视觉里程计, DINOv2, 视觉基础模型, 特征匹配, 单目VO

**Comment:** 8 pages, 6 figures. Accepted for publication in IEEE Robotics and
  Automation Letters (RA-L), July 2025

> **TL;DR:** DINO-VO是一个基于DINOv2的视觉里程计，通过结合粗粒度基础模型特征和细粒度几何特征，解决了传统学习型VO的鲁棒性、泛化性和效率问题，并在多个数据集上表现出色。

**AI_Comments:** 本文的创新点在于将视觉基础模型DINOv2成功应用于视觉里程计，通过提出专门的关键点检测器和结合多尺度特征解决了DINOv2粗粒度特征的局限性。其重要性在于提升了单目VO在复杂环境下的鲁棒性和泛化能力，并保持了高效率，为未来基于基础模型的机器人感知系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 学习型单目视觉里程计（VO）在机器人技术中面临鲁棒性、泛化性和效率方面的挑战。尽管DINOv2等视觉基础模型已在各种视觉任务中提高了鲁棒性和泛化性，但由于其特征粒度较粗，它们在VO中的集成仍然有限。

**Method:** 本文提出了DINO-VO，一个利用DINOv2视觉基础模型进行稀疏特征匹配的基于特征的VO系统。为解决集成挑战，DINO-VO提出了一个针对DINOv2粗粒度特征的显著关键点检测器。此外，它将DINOv2的鲁棒语义特征与细粒度几何特征互补，以获得更易于定位的表示。最后，一个基于Transformer的匹配器和可微分姿态估计层通过学习良好的匹配来实现精确的相机运动估计。

**Result:** 与SuperPoint等先前的检测器-描述器网络相比，DINO-VO在挑战性环境中表现出更强的鲁棒性。所提出的特征描述器相对于单独的DINOv2粗粒度特征具有更高的精度和泛化能力。DINO-VO在TartanAir和KITTI数据集上优于先前的帧到帧VO方法，并在EuRoC数据集上具有竞争力，同时以72 FPS的效率运行，在单个GPU上内存使用不到1GB。此外，它在室外驾驶场景中与视觉SLAM系统表现出竞争力，展示了其泛化能力。

**Conclusion:** DINO-VO通过有效利用视觉基础模型DINOv2并结合细粒度特征，显著提升了单目视觉里程计的鲁棒性、精度、泛化能力和效率，在多种复杂环境下均表现出色。

> **ai_Abstract:** 本文提出了DINO-VO，一个利用DINOv2视觉基础模型进行稀疏特征匹配的单目视觉里程计系统。为解决DINOv2粗粒度特征在VO中集成的问题，DINO-VO设计了专门的关键点检测器，并结合了DINOv2的语义特征与细粒度几何特征，通过Transformer匹配器和可微分姿态估计层实现精确运动估计。实验结果表明，DINO-VO在鲁棒性、精度、泛化能力和效率方面均优于现有方法，并在多个数据集上取得了SOTA性能，同时能高效运行。

> **摘要翻译:** 学习型单目视觉里程计（VO）在机器人技术中面临鲁棒性、泛化性和效率方面的挑战。视觉基础模型（如DINOv2）的最新进展已提高了各种视觉任务的鲁棒性和泛化性，但由于其特征粒度较粗，它们在VO中的集成仍然有限。在本文中，我们提出了DINO-VO，一个基于特征的VO系统，它利用DINOv2视觉基础模型进行稀疏特征匹配。为了解决集成挑战，我们提出了一个针对DINOv2粗粒度特征的显著关键点检测器。此外，我们用细粒度几何特征补充DINOv2的鲁棒语义特征，从而产生更易于定位的表示。最后，一个基于Transformer的匹配器和可微分姿态估计层通过学习良好的匹配来实现精确的相机运动估计。与SuperPoint等先前的检测器-描述器网络相比，DINO-VO在挑战性环境中表现出更强的鲁棒性。此外，我们展示了所提出的特征描述器相对于单独的DINOv2粗粒度特征具有卓越的精度和泛化能力。DINO-VO在TartanAir和KITTI数据集上优于先前的帧到帧VO方法，并在EuRoC数据集上具有竞争力，同时以72 FPS的效率运行，在单个GPU上内存使用不到1GB。此外，它在室外驾驶场景中与视觉SLAM系统表现出竞争力，展示了其泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [370] [FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization](https://arxiv.org/abs/2507.13311)
> *FashionPose：文本到姿态到重光照图像生成，用于个性化时尚可视化*

*Chuancheng Shi, Yixiang Chen, Burong Lei, Jichao Chen* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 文本到图像生成, 姿态估计, 图像重光照, 扩散模型, 时尚可视化

**Comment:** 

> **TL;DR:** FashionPose是一个统一的文本到姿态到重光照生成框架，它允许用户通过文本描述创建具有个性化姿态和光照的时尚图像，解决了现有方法在语义灵活性和光照适应性方面的局限性。

**AI_Comments:** FashionPose的创新之处在于其统一的文本到姿态到重光照生成框架，首次实现了完全由文本驱动的个性化时尚图像生成。它通过将姿态预测和重光照集成到扩散模型中，显著提升了生成图像的语义灵活性和光照适应性，对于时尚电商和虚拟试穿领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在时尚电商中生成逼真且可控的服装可视化时，通常依赖预定义姿态，这限制了语义灵活性和光照适应性。用户期望在不同姿态和光照条件下获得个性化预览。

**Method:** FashionPose是一个统一的文本到姿态到重光照生成框架。它首先根据自然语言描述预测2D人体姿态，然后利用扩散模型生成高保真人物图像，最后应用轻量级重光照模块，所有步骤均由相同的文本输入引导。通过用文本驱动条件替换显式姿态标注，实现准确的姿态对齐、忠实的服装渲染和灵活的光照控制。

**Result:** 实验证明了细粒度的姿态合成和高效、一致的重光照。

**Conclusion:** FashionPose为个性化虚拟时尚展示提供了一个实用的解决方案。

> **ai_Abstract:** FashionPose提出了一种新颖的文本到姿态到重光照图像生成框架，旨在解决时尚电商中个性化服装可视化的问题。该框架通过自然语言描述，首先预测人体姿态，随后利用扩散模型生成人物图像，并最终应用重光照模块，实现文本驱动的姿态控制、服装渲染和光照调节。实验结果验证了其在细粒度姿态合成和高效重光照方面的能力，为虚拟时尚展示提供了实用方案。

> **摘要翻译:** 逼真且可控的服装可视化对于时尚电商至关重要，用户期望在不同姿态和光照条件下获得个性化预览。现有方法通常依赖预定义姿态，限制了语义灵活性和光照适应性。为了解决这个问题，我们引入了FashionPose，这是第一个统一的文本到姿态到重光照生成框架。给定自然语言描述，我们的方法首先预测2D人体姿态，然后采用扩散模型生成高保真人物图像，最后应用轻量级重光照模块，所有这些都由相同的文本输入引导。通过用文本驱动条件替换显式姿态标注，FashionPose实现了准确的姿态对齐、忠实的服装渲染和灵活的光照控制。实验证明了细粒度的姿态合成和高效、一致的重光照，为个性化虚拟时尚展示提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion](https://arxiv.org/abs/2507.12804)
> *ATL-Diff：早期地标引导噪声扩散的音频驱动说话人脸生成*

*Hoang-Son Vo, Quang-Vinh Nguyen, Seungwon Kim, Hyung-Jeong Yang, Soonja Yeom, Soo-Hyung Kim* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 音频驱动, 说话人脸生成, 地标引导, 噪声扩散, 实时处理

**Comment:** 

> **TL;DR:** ATL-Diff是一种新的音频驱动说话人脸生成方法，通过地标引导噪声扩散，提高了同步性、降低了噪声和计算成本，并实现了高质量、实时性好的动画。

**AI_Comments:** ATL-Diff的创新点在于其独特的地标引导噪声扩散方法，该方法通过在早期阶段利用面部地标来指导噪声扩散，有效解耦了音频并提高了同步精度，同时降低了计算成本。其在多个数据集上超越SOTA的表现以及接近实时的处理能力，使其在虚拟助手、教育和医疗等领域具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的音频驱动说话人脸生成方法在面部动画与音频信号的精确同步方面存在局限性，并且可能存在噪声和较高的计算成本。

**Method:** ATL-Diff框架包含三个关键组件：1. 地标生成模块：将音频转换为面部地标。2. 地标引导噪声方法：通过根据地标分布噪声来解耦音频。3. 3D身份扩散网络：用于保留身份特征。

**Result:** 在MEAD和CREMA-D数据集上的实验表明，ATL-Diff在所有指标上均优于最先进的方法。该方法实现了接近实时的处理、高质量的动画、计算效率和卓越的面部细节保留。

**Conclusion:** ATL-Diff在音频驱动说话人脸生成方面取得了显著进展，解决了同步、噪声和效率问题，并展现出在虚拟助手、教育、医疗通信和数字平台等领域的广阔应用前景。

> **ai_Abstract:** ATL-Diff是一种创新的音频驱动说话人脸生成方法，旨在解决现有技术在同步、噪声和计算成本方面的局限性。它通过地标生成模块、地标引导噪声扩散和3D身份扩散网络三大核心组件，实现了音频到面部地标的转换，并有效解耦音频以保留身份特征。实验证明，ATL-Diff在质量、效率和实时性上均超越了现有SOTA方法，为多种应用场景提供了高质量的解决方案。

> **摘要翻译:** 音频驱动的说话人脸生成需要面部动画和音频信号之间的精确同步。本文介绍了ATL-Diff，这是一种解决同步限制同时减少噪声和计算成本的新方法。我们的框架具有三个关键组件：将音频转换为面部地标的地标生成模块；通过根据地标分布噪声来解耦音频的地标引导噪声方法；以及保留身份特征的3D身份扩散网络。在MEAD和CREMA-D数据集上的实验表明，ATL-Diff在所有指标上均优于最先进的方法。我们的方法实现了接近实时的处理、高质量的动画、计算效率和卓越的面部细微差别保留。这一进步为虚拟助手、教育、医疗通信和数字平台提供了有前景的应用。源代码可在以下地址获取：\href{https://github.com/sonvth/ATL-Diff}{https://github.com/sonvth/ATL-Diff}

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [375] [DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge](https://arxiv.org/abs/2507.04447)
> *DreamVLA：一个融合了全面世界知识的视觉-语言-动作模型*

*Wenyao Zhang, Hongsi Liu, Zekun Qi, Yunnan Wang, Xinqiang Yu, Jiazhao Zhang, Runpei Dong, Jiawei He, He Wang, Zhizheng Zhang, Li Yi, Wenjun Zeng, Xin Jin* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 视觉-语言-动作, 世界知识, 机器人操作, 扩散模型, 结构化注意力

**Comment:** 

> **TL;DR:** DreamVLA是一个新的VLA模型，通过整合全面的世界知识预测和创新的注意力机制，显著提升了机器人操作的泛化和推理能力。

**AI_Comments:** DreamVLA的创新之处在于其对“全面世界知识”的整合，这超越了传统的图像预测，引入了动态、空间和语义信息，更贴近人类的认知方式。其提出的块状结构化注意力机制巧妙地解决了多模态信息融合中的干扰问题，保持了表示的纯净和解耦。结合扩散模型进行动作预测也增强了其建模复杂条件分布的能力。这些设计使其在机器人操作的泛化和推理方面表现出色，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言-动作（VLA）模型受限于基于图像的预测，存在信息冗余且缺乏全面的世界知识（包括动态、空间和语义信息），导致在机器人操作的泛化和推理能力上受限。

**Method:** 本研究提出了DreamVLA，一个新颖的VLA框架，通过整合全面的世界知识预测实现逆动力学建模，建立了感知-预测-动作循环。具体而言，DreamVLA引入了动态区域引导的世界知识预测，并结合空间和语义线索提供紧凑全面的动作规划表示。为减轻训练中动态、空间和语义信息间的干扰，采用了块状结构化注意力机制，屏蔽相互注意力，保持表示的干净和解耦。此外，采用基于扩散的Transformer来建模未来动作的条件分布，并将动作表示从共享的潜在特征中解耦。

**Result:** DreamVLA在真实机器人任务中实现了76.7%的成功率，并在CALVIN ABC-D基准测试中取得了4.44的平均长度，在真实世界和模拟环境中均表现出色。

**Conclusion:** DreamVLA通过整合全面的世界知识预测和创新的注意力机制，有效克服了现有VLA模型在机器人操作中泛化和推理能力的局限性，显著提升了性能。

> **ai_Abstract:** DreamVLA是一个新颖的视觉-语言-动作（VLA）模型，旨在通过整合全面的世界知识预测来解决现有VLA模型在泛化和推理方面的局限性，这些局限性源于冗余的图像信息和缺乏动态、空间、语义等关键世界知识。该模型通过引入动态区域引导的世界知识预测、结合空间和语义线索，并采用块状结构化注意力机制来解耦信息，从而建立了一个感知-预测-动作循环。此外，它利用扩散型Transformer来建模未来动作的条件分布。实验结果表明，DreamVLA在真实机器人任务和模拟环境中均取得了显著的性能提升。

> **摘要翻译:** 视觉-语言-动作（VLA）模型在将图像生成与动作预测相结合以提高机器人操作中的泛化和推理能力方面取得了有前景的进展。然而，现有方法仅限于具有挑战性的基于图像的预测，这会受到冗余信息的影响，并且缺乏全面而关键的世界知识，包括动态、空间和语义信息。为了解决这些限制，我们提出了DreamVLA，一个新颖的VLA框架，它整合了全面的世界知识预测，以实现逆动力学建模，从而为操作任务建立了一个感知-预测-动作循环。具体来说，DreamVLA引入了动态区域引导的世界知识预测，并与空间和语义线索相结合，这些线索为动作规划提供了紧凑而全面的表示。这种设计与人类在行动前首先形成抽象的多模态推理链的方式相吻合。为了减轻训练过程中动态、空间和语义信息之间的干扰，我们采用了块状结构化注意力机制，该机制屏蔽了它们的相互注意力，防止信息泄露并保持每个表示的干净和解耦。此外，为了对未来动作的条件分布进行建模，我们采用了一种基于扩散的Transformer，它将动作表示与共享的潜在特征解耦。在真实世界和模拟环境中的大量实验表明，DreamVLA在真实机器人任务上达到了76.7%的成功率，并在CALVIN ABC-D基准测试中达到了4.44的平均长度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [377] [Global urban visual perception varies across demographics and personalities](https://arxiv.org/abs/2505.12758)
> *全球城市视觉感知因人口统计学特征和个性而异*

*Matias Quintana, Youlong Gu, Xiucheng Liang, Yujun Hou, Koichi Ito, Yihan Zhu, Mahmoud Abdelrahman, Filip Biljecki* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 城市视觉感知, 人口统计学, 人格特质, 街景图像, 机器学习偏差

**Comment:** Under review

> **TL;DR:** 城市视觉感知受人口统计学特征和个性影响，现有模型常有偏差，需考虑本地语境。

**AI_Comments:** 这篇论文的创新之处在于首次将人格特质纳入城市视觉感知研究，并构建了一个包含人口统计学特征的全球数据集SPECS。它强调了在城市规划和AI模型开发中考虑个体差异和本地语境的重要性，纠正了以往研究中对人口差异的忽视，有助于减少偏见。

<details>
  <summary>Details</summary>

**Motivation:** 理解人们的偏好对于城市规划至关重要，但当前方法常忽略人口差异并可能放大偏见。本研究旨在纠正对街道感知的短视处理，这种处理很少考虑人口统计学或个性特征。

**Method:** 通过街景图像对全球街景进行了大规模城市视觉感知调查，研究了包括性别、年龄、收入、教育、种族和民族以及首次纳入的人格特质等人口统计学特征如何影响感知。调查了来自五个国家、45个民族的1000名参与者，并创建了数据集“Street Perception Evaluation Considering Socioeconomics (SPECS)”。

**Result:** 数据集SPECS揭示了人口统计学和个性对六个传统指标（安全、生动、富裕、美丽、无聊、压抑）和四个新指标（住附近、步行、骑行、绿色）的感知差异。基于位置的情绪也影响偏好。现有全球数据集训练的机器学习模型与人类反应相比，倾向于高估积极指标而低估消极指标。

**Conclusion:** 本研究强调了在城市视觉感知中考虑人口统计学和个性特征的重要性，并指出现有机器学习模型在不考虑本地语境时存在偏差，因此需要更精细的方法。

> **ai_Abstract:** 这项研究通过对全球1000名参与者进行大规模街景感知调查，首次将人口统计学特征（如性别、年龄、收入、种族）和人格特质纳入考虑，揭示了这些因素如何影响人们对城市街景的感知。研究发现，现有机器学习模型在不考虑这些个体差异和本地语境时存在偏差。该研究创建了新的数据集SPECS，旨在为城市规划提供更精细、更具包容性的洞察。

> **摘要翻译:** 理解人们的偏好对于城市规划至关重要，然而，当前的方法通常将来自多文化人群的反应结合起来，这模糊了人口差异并可能放大偏见。我们利用街景图像在全球范围内进行了一项大规模的城市视觉感知调查，研究了人口统计学特征——包括性别、年龄、收入、教育、种族和民族，以及首次纳入的人格特质——如何影响来自五个国家、45个民族的1000名参与者（人口统计学特征均衡）的感知。这个名为“考虑社会经济的街道感知评估（SPECS）”的数据集揭示了基于人口统计学和个性的差异，涵盖了六个传统指标（安全、生动、富裕、美丽、无聊、压抑）和四个新指标（住附近、步行、骑行、绿色）。基于位置的情绪进一步塑造了这些偏好。与人类反应相比，在现有全球数据集上训练的机器学习模型倾向于高估积极指标而低估消极指标，这强调了本地语境的必要性。我们的研究旨在纠正对街道感知的短视处理，这种处理很少考虑人口统计学或个性特征。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [386] [Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning](https://arxiv.org/abs/2507.12998)
> *差分信息样本选择加速多模态对比学习*

*Zihua Zhao, Feng Hong, Mengxi Chen, Pengyi Chen, Benyuan Liu, Jiangchao Yao, Ya Zhang, Yanfeng Wang* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 多模态对比学习, 样本选择, 差分信息, 噪声对应, 训练加速

**Comment:** 

> **TL;DR:** 提出DISSect方法，通过利用当前模型与历史模型预测相关性的差分来选择高质量样本，从而加速多模态对比学习，解决现有样本选择方法在冷启动和处理噪声对应方面的不足。

**AI_Comments:** DISSect的创新点在于提出了利用当前模型与历史模型预测相关性之间的“差分”来评估样本质量，这提供了一种新颖且可能更鲁棒的方式来处理多模态数据中的噪声对应问题，尤其是在冷启动场景下。其理论分析和在多个数据集上的优越表现，表明该方法在加速对比学习训练方面具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于对比学习的多模态模型需要大量数据和计算资源，而样本选择作为一种高效范式可以加速训练。然而，当前的样本选择方法存在局限性：要么依赖离线预训练模型（冷启动受限），要么在线选择时未能充分或高效地考虑噪声对应。

**Method:** 提出了一种新颖的差分信息样本选择（DISSect）方法。该方法重新思考了噪声对应对对比学习的影响，并提出利用当前模型与历史模型预测相关性之间的差分来更有效地表征样本质量。基于此，构建了一个鲁棒的基于差分的样本选择机制，并进行了理论分析。

**Result:** 在三个基准数据集和各种下游任务上进行了广泛的实验，结果表明DISSect方法始终优于当前的最新方法。

**Conclusion:** DISSect通过有效利用模型预测差分来识别高质量样本，成功加速了多模态对比学习，并展现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为DISSect（差分信息样本选择）的新方法，旨在加速多模态对比学习的训练过程。针对现有样本选择方法在冷启动和处理噪声对应方面的不足，DISSect利用当前模型与历史模型预测相关性之间的差分来准确有效地识别高质量样本，从而提高训练效率。实验结果表明，DISSect在多个基准数据集和任务上均优于现有最先进的方法。

> **摘要翻译:** 对比学习的多模态模型在训练更大规模数据集上的显著成功，伴随着昂贵的计算消耗。样本选择作为一种替代的高效范式，在加速训练过程方面扮演着重要角色。然而，近期样本选择的进展，要么主要依赖于预言机模型离线选择高质量核心集（这在冷启动场景中受到限制），要么侧重于基于实时模型预测的在线选择（这未能充分或高效地考虑噪声对应）。为了解决这一困境，我们提出了一种新颖的差分信息样本选择（DISSect）方法，该方法能够准确高效地识别噪声对应，从而加速训练。具体来说，我们重新思考了噪声对应对对比学习的影响，并提出当前模型与历史模型预测相关性之间的差分更能表征样本质量。基于此，我们构建了一个鲁棒的基于差分的样本选择机制，并分析了其理论见解。在三个基准数据集和各种下游任务上的广泛实验证明，DISSect始终优于当前最先进的方法。源代码可在：https://github.com/MediaBrain-SJTU/DISSect 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [388] [Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability](https://arxiv.org/abs/2506.18248)
> *语义结构感知生成式攻击用于增强对抗性可迁移性*

*Jongoh Jeong, Hunmin Yang, Jaeseok Jeong, Kuk-Jin Yoon* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 生成式对抗攻击, 对抗性可迁移性, 语义结构感知, Mean Teacher, 特征蒸馏

**Comment:** Preprint

> **TL;DR:** 本文提出一种语义结构感知的生成式对抗攻击框架，利用Mean Teacher模型引导扰动合成，以增强对抗性可迁移性，并取得了显著优于现有方法的效果。

**AI_Comments:** 这篇论文的创新点在于首次将语义结构感知引入生成式对抗攻击，并利用Mean Teacher框架来引导扰动生成，使其更好地对齐目标显著区域。这种方法有效地提升了对抗性攻击的可迁移性，对于黑盒攻击场景具有重要意义。新提出的Accidental Correction Rate (ACR) 也为评估提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成式对抗攻击方法未能充分利用生成模型表示能力来保留和利用语义信息，导致扰动与对象显著区域的对齐不足，从而限制了对抗性可迁移性。

**Method:** 本文提出了一种基于Mean Teacher的语义结构感知攻击框架。该框架将Mean Teacher作为时间平滑的特征参考，通过特征蒸馏在学生模型的早期层激活与语义丰富的教师模型之间建立语义一致性。根据经验发现，通过将扰动合成锚定在生成器内语义显著的早期中间块，我们的方法引导了对区域的渐进式对抗性扰动，从而显著增强了对抗性可迁移性。

**Result:** 在不同模型、领域和任务上进行了广泛实验，结果表明相对于最先进的生成式攻击，本文方法取得了持续的改进，并使用传统指标和新提出的Accidental Correction Rate (ACR) 进行了全面评估。

**Conclusion:** 通过引入语义结构感知，本方法有效利用生成模型中的语义信息，显著增强了生成式对抗攻击的可迁移性，为提高对抗攻击的有效性提供了新途径。

> **ai_Abstract:** 本文提出了一种语义结构感知生成式对抗攻击框架，旨在解决现有生成式攻击未能充分利用生成模型中语义信息导致可迁移性受限的问题。该框架基于Mean Teacher模型，通过特征蒸馏实现学生模型与教师模型早期层激活的语义一致性，并将扰动合成锚定在生成器内语义显著区域。实验结果表明，该方法显著提升了对抗性可迁移性，并优于现有最先进的生成式攻击。

> **摘要翻译:** 生成式对抗攻击在白盒替代模型上训练一个扰动生成器，然后将生成的扰动应用于未见的黑盒受害者模型。与迭代攻击相比，这些方法在推理时间效率、可扩展性和可迁移性方面表现出优越性；然而，到目前为止，现有研究尚未充分利用生成模型的表示能力来保留和利用语义信息。具体而言，生成器的中间激活编码了丰富的语义特征——对象边界和粗略形状——这些特征仍未被充分利用，从而限制了扰动与对象显著区域的对齐，而这对于对抗性可迁移性至关重要。为了弥补这一点，我们引入了一种基于Mean Teacher的语义结构感知攻击框架，它作为时间平滑的特征参考。利用这个平滑的参考，我们通过特征蒸馏进一步引导学生模型早期层激活与语义丰富的教师模型之间的语义一致性。根据经验发现，通过将扰动合成锚定在生成器内语义显著的早期中间块，我们的方法引导了对区域的渐进式对抗性扰动，从而显著增强了对抗性可迁移性。我们在不同的模型、领域和任务上进行了广泛的实验，以证明相对于最先进的生成式攻击，本文方法取得了持续的改进，并使用传统指标和我们新提出的意外修正率（ACR）进行了全面评估。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection](https://arxiv.org/abs/2507.12628)
> *Funnel-HOI：零样本HOI检测的自上而下感知*

*Sandipan Sarma, Agney Talwarr, Arijit Sur* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 人物-物体交互检测, 零样本学习, 自上而下感知, 非对称协同注意力, 长尾分布

**Comment:** 10 pages, 6 figures

> **TL;DR:** 提出Funnel-HOI，一个自上而下的框架，通过在编码器阶段利用非对称协同注意力机制和新的损失函数，显著提升了零样本HOI检测的性能。

**AI_Comments:** 该论文的创新点在于提出了一个自上而下的感知框架Funnel-HOI，并强调在编码器阶段整合HOI特定线索的重要性，这与以往主要关注解码器的方法形成对比。其引入的非对称协同注意力机制和新的损失函数有效地提升了零样本HOI检测的性能，特别是在处理长尾分布和罕见类别方面。这种从人类认知过程获取灵感的设计思路具有启发性。

<details>
  <summary>Details</summary>

**Motivation:** 人物-物体交互检测（HOID）面临指数级的对象-动作组合导致标注数据有限和长尾分布问题。现有方法主要关注解码器设计，未能充分在编码器阶段利用HOI特有线索。

**Method:** 提出Funnel-HOI，一个自上而下的框架，模仿人类认知过程，先探测物体再探测动作。采用新颖的非对称协同注意力机制，利用多模态信息在编码器级别生成更强的交互表示。此外，设计了一种新的损失函数，考虑对象-动作相关性并更好地调节误分类惩罚。

**Result:** 在HICO-DET和V-COCO数据集上，在全监督和六种零样本设置下，实现了最先进的性能，对未见和稀有HOI类别分别提升了高达12.4%和8.4%。

**Conclusion:** Funnel-HOI通过在编码器阶段提前整合HOI特定线索，并结合新颖的注意力机制和损失函数，显著提高了零样本HOI检测的性能，尤其是在处理未见和稀有类别方面。

> **ai_Abstract:** 本文提出Funnel-HOI，一个创新的自上而下框架，用于解决人物-物体交互检测（HOID）中的零样本问题。针对现有方法主要关注解码器而忽视编码器阶段HOI特定线索的不足，Funnel-HOI通过模仿人类认知过程，先识别明确物体再关联抽象动作。其核心在于引入非对称协同注意力机制在编码器层面生成更强的交互表示，并设计新的损失函数优化分类。实验证明，Funnel-HOI在多个数据集和零样本设置下均达到SOTA性能，尤其在未见和稀有HOI类别上表现显著。

> **摘要翻译:** 人物-物体交互检测（HOID）是指在图像中定位交互的人物-物体对并识别其交互行为。由于对象-动作组合可能呈指数级增长，标注数据有限，导致长尾分布问题。最近，零样本学习作为一种解决方案出现，适应于HOID的端到端基于Transformer的对象检测器已成为成功的框架。然而，它们主要关注设计改进的解码器，以学习交互的纠缠或解耦解释。我们主张，必须在编码器阶段就预见到HOI特有的线索，以获得更强的场景解释。因此，我们构建了一个名为Funnel-HOI的自上而下框架，其灵感来源于人类在场景理解时倾向于先掌握明确的概念，然后将其与抽象概念关联的趋势。我们首先探测图像中是否存在物体（明确概念），然后探测与它们相关的动作（抽象概念）。一种新颖的非对称协同注意力机制利用多模态信息（包含零样本能力）挖掘这些线索，并在编码器级别产生更强的交互表示。此外，设计了一种新的损失函数，该函数考虑了对象-动作相关性，并且比现有损失函数更好地调节误分类惩罚，以指导交互分类器。在HICO-DET和V-COCO数据集上，在全监督和六种零样本设置下的广泛实验表明，我们的方法达到了最先进的性能，对于未见和稀有的HOI类别分别获得了高达12.4%和8.4%的增益。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [Color Image Set Recognition Based on Quaternionic Grassmannians](https://arxiv.org/abs/2505.23629)
> *基于四元数格拉斯曼流形的彩色图像集识别*

*Xiang Xiang Wang, Tin-Yau Tam* | **Category: cs.CV, math.AG** | **Updated: 2025-07-17**

**Keywords:** 彩色图像集识别, 四元数格拉斯曼流形, 图像分类, 四元数, 距离度量

**Comment:** 

> **TL;DR:** 提出了一种基于四元数格拉斯曼流形的新型彩色图像集识别方法，该方法利用四元数捕获颜色信息，并将图像集表示为流形上的点，通过计算点间最短距离构建分类框架，在ETH-80和公路交通视频数据集上取得了良好的识别效果。

**AI_Comments:** 该论文的创新点在于将四元数格拉斯曼流形应用于彩色图像集识别，特别是利用四元数捕获颜色信息和定义距离度量进行分类。论文对方法局限性的讨论也体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发一种新的、更有效地捕获颜色信息并表示图像集的彩色图像集识别方法。

**Method:** 该方法使用四元数格拉斯曼流形捕获颜色信息，并将每个彩色图像集表示为四元数格拉斯曼流形上的一个点。论文提供了一个计算四元数格拉斯曼流形上两点之间最短距离的直接公式，并利用该距离构建了一个新的分类框架。

**Result:** 在ETH-80基准数据集和公路交通视频数据集上的实验表明，该方法取得了良好的识别结果。

**Conclusion:** 该论文提出的基于四元数格拉斯曼流形的彩色图像集识别方法是有效的，尽管在稳定性方面存在一些局限性，但未来仍有改进空间。

> **ai_Abstract:** 本论文提出了一种基于四元数格拉斯曼流形的彩色图像集识别新方法。该方法利用四元数捕获颜色信息，并将每个彩色图像集表示为四元数格拉斯曼流形上的一个点。文章提供了一个直接公式来计算流形上两点之间的最短距离，并以此构建了一个新的分类框架。实验结果表明，该方法在ETH-80和公路交通视频数据集上取得了良好的识别效果。论文还讨论了方法的稳定性局限性并提出了未来的改进方向。

> **摘要翻译:** 我们提出了一种使用四元数格拉斯曼流形识别彩色图像集的新方法，该方法利用四元数的能力来捕获颜色信息，并将每个彩色图像集表示为四元数格拉斯曼流形上的一个点。我们提供了一个直接公式来计算四元数格拉斯曼流形上两点之间的最短距离，并利用该距离构建了一个新的分类框架。在ETH-80基准数据集和公路交通视频数据集上的实验表明，我们的方法取得了良好的识别结果。我们还讨论了稳定性方面的一些局限性，并提出了未来改进该方法的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [400] [FIQ: Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering](https://arxiv.org/abs/2507.12816)
> *FIQ：融合问题嵌入的视频问答基础问题生成*

*Ju-Young Oh, Ho-Joong Kim, Seong-Whan Lee* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 视频问答, 基础问题生成, 问题嵌入, 数据增强, 泛化能力

**Comment:** SMC 2025

> **TL;DR:** 本文提出FIQ方法，通过生成基础问答对和引入VQ-CAlign模块，增强视频问答模型的泛化和推理能力，并在SUTD-TrafficQA数据集上达到了最先进的性能。

**AI_Comments:** 本文的创新点在于通过生成“基础问题”来弥补现有VQA数据集中上下文信息的不足，从而提升模型的泛化和推理能力。VQ-CAlign模块的设计也进一步增强了模型对领域特定细节的捕获能力。该方法通过数据增强和特征对齐的结合，有效解决了VQA任务中理解深度不足的问题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频问答（VQA）方法主要依赖事件中心的问答对，缺乏对象类型、空间布局、描述性属性等基本细节，导致模型学习到的场景表示不完整，限制了模型的泛化能力和高阶推理能力。

**Method:** 提出FIQ（Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering）方法，该方法通过从视频中提取描述生成问答对，以丰富训练数据中的基础场景信息。此外，引入VQ-CAlign模块，将特定任务的问题嵌入与视觉特征对齐，以保留领域特定细节，提高下游任务的适应性。

**Result:** 在SUTD-TrafficQA数据集上的实验表明，FIQ相对于现有基线方法取得了最先进的性能。

**Conclusion:** FIQ通过增强视频的基础理解和整合问题嵌入，显著提升了视频问答模型的泛化能力和推理能力，并在特定数据集上验证了其有效性。

> **ai_Abstract:** 本文提出了FIQ（Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering），旨在解决现有视频问答（VQA）模型因训练数据缺乏基本场景细节而导致的泛化和推理能力受限问题。FIQ通过从视频描述中生成基础问答对来丰富训练数据，并引入VQ-CAlign模块以对齐问题嵌入和视觉特征。实验结果表明，FIQ在SUTD-TrafficQA数据集上实现了最先进的性能。

> **摘要翻译:** 视频问答（VQA）是一项多模态任务，需要解释视频以回答给定问题。现有的VQA方法主要利用问答（Q&A）对来学习视频内容的时空特征。然而，这些标注通常以事件为中心，不足以捕捉每个视频的更广泛上下文。缺乏对象类型、空间布局和描述性属性等基本细节限制了模型仅学习片段化的场景表示。这个问题限制了模型的泛化能力和更高层次的推理能力。在本文中，我们提出了一种融合问题嵌入的视频问答基础问题生成（FIQ）方法，这是一种旨在通过增强对视频的基础理解来加强模型推理能力的新颖方法。FIQ根据从视频中提取的描述生成问答对，用基础场景信息丰富训练数据。生成的问答对使模型能够理解主要上下文，从而增强泛化能力和推理能力。此外，我们引入了一个VQ-CAlign模块，该模块辅助特定任务的问题嵌入与视觉特征对齐，确保保留重要的领域特定细节，以提高下游任务的适应性。在SUTD-TrafficQA上的实验表明，我们的FIQ与现有基线方法相比，取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models](https://arxiv.org/abs/2507.13152)
> *SE-VLN：一种基于多模态大语言模型的自进化视觉语言导航框架*

*Xiangyu Dong, Haoran Zhao, Jiang Gao, Haozhou Li, Xiaoguang Ma, Yaoming Zhou, Fuhai Chen, Juan Liu* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 视觉语言导航, 自进化, 多模态大语言模型, 强化学习, 具身智能体

**Comment:** 

> **TL;DR:** SE-VLN是一个基于多模态大语言模型的自进化视觉语言导航框架，通过分层记忆、检索增强思维推理和反思模块，使其能够在测试过程中持续进化，并在R2R和REVERSE数据集上显著优于现有SOTA方法。

**AI_Comments:** SE-VLN的创新之处在于首次将多模态大语言模型与自进化能力相结合，解决了传统VLN模型在测试阶段无法有效积累经验和持续进化的局限性。其提出的分层记忆、检索增强推理和反思模块构建了一个完整的学习闭环，使得模型能够在实际操作中不断提升。这对于构建更鲁棒、适应性更强的具身智能体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉语言导航（VLN）方法虽然得益于大语言模型（LLMs）展现出优秀的泛化能力，但受限于LLMs固定的知识库和推理能力，无法充分融入经验知识，导致缺乏有效的进化能力。

**Method:** 提出了一个自进化的VLN框架（SE-VLN），使其能够在测试过程中持续进化。SE-VLN包含三个核心模块：分层记忆模块（将成功和失败案例转化为可重用知识）、检索增强思维推理模块（检索经验并实现多步决策）以及反思模块（实现持续进化）。

**Result:** SE-VLN在R2R和REVERSE数据集的未见环境中分别取得了57%和35.2%的导航成功率，相对于当前最先进的方法，性能分别绝对提升了23.9%和15.0%。此外，SE-VLN随着经验库的增加显示出性能提升。

**Conclusion:** SE-VLN作为首个由多模态大语言模型驱动的自进化VLN框架，通过其独特的设计实现了在测试阶段的持续学习和性能提升，展现了作为自进化智能体框架在VLN领域的巨大潜力。

> **ai_Abstract:** 本文提出了一种名为SE-VLN的自进化视觉语言导航（VLN）框架，旨在解决现有VLN方法因大语言模型（LLMs）固定知识库而缺乏进化能力的问题。受自然智能体进化能力的启发，SE-VLN通过引入分层记忆、检索增强思维推理和反思三大核心模块，使VLN智能体能够在测试过程中持续学习和进化。实验结果表明，SE-VLN在R2R和REVERSE数据集上显著超越了现有最先进方法，并在未见环境中实现了更高的导航成功率，同时展示了其性能随经验积累而提升的潜力，证明了其作为自进化VLN智能体框架的有效性。

> **摘要翻译:** 视觉语言导航（VLN）的最新进展主要归因于新兴的大语言模型（LLMs）。这些方法在指令理解和任务推理方面表现出卓越的泛化能力。然而，它们受限于LLMs固定的知识库和推理能力，无法充分融入经验知识，从而导致缺乏有效的进化能力。为了解决这个问题，我们从自然智能体的进化能力中汲取灵感，提出了一种自进化的VLN框架（SE-VLN），旨在赋予VLN智能体在测试过程中持续进化的能力。据我们所知，这是首次提出由多模态大语言模型驱动的自进化VLN框架。具体而言，SE-VLN包含三个核心模块：一个分层记忆模块，用于将成功和失败案例转化为可重用知识；一个检索增强思维推理模块，用于检索经验并实现多步决策；以及一个反思模块，用于实现持续进化。全面的测试表明，SE-VLN在R2R和REVERSE数据集的未见环境中分别取得了57%和35.2%的导航成功率，相对于当前最先进的方法，性能分别绝对提升了23.9%和15.0%。此外，SE-VLN随着经验库的增加显示出性能提升，阐明了其作为VLN自进化智能体框架的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains](https://arxiv.org/abs/2507.13326)
> *工业领域中以自我为中心的实时手物交互检测系统*

*Antonio Finocchiaro, Alessandro Sebastiano Catinello, Michele Mazzamuto, Rosario Leonardi, Antonino Furnari, Giovanni Maria Farinella* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 手物交互, 以自我为中心的视觉, 实时系统, 动作识别, 对象检测

**Comment:** 12 pages, 4 figures, In International Conference on Image Analysis
  and Processing

> **TL;DR:** 该论文提出了一个用于工业领域中以自我为中心的实时手物交互检测系统，采用级联的动作识别和对象检测模块，实现了高效准确的检测。

**AI_Comments:** 该论文的创新点在于其提出的级联架构，通过在确认交互后才激活对象检测模块，可能显著提高了系统的实时效率。结合Mamba和YOLOWorld等先进模型，为解决实时手物交互检测这一挑战性问题提供了实用且高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 手物交互检测在实时应用中仍是一个开放性挑战，而直观的用户体验依赖于对周围物体快速准确的交互检测。

**Method:** 提出了一种高效的级联方法，包括一个动作识别模块（使用EfficientNetV2作为骨干的Mamba模型）和一个对象检测模块（微调的YOLOWorld）。当动作识别模块预测到接触状态时，会激活对象检测模块以检测和分类活动对象。

**Result:** 动作识别模块的Mamba模型在ENIGMA-51基准测试中以30fps的速度达到了38.52%的p-AP；微调的YOLOWorld在手和物体检测方面达到了85.13%的AP。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种用于工业领域中以自我为中心的实时手物交互检测系统。该系统采用级联架构，结合了基于Mamba模型（EfficientNetV2为骨干）的动作识别模块和基于微调YOLOWorld的对象检测模块。系统首先通过动作识别判断接触状态，随后激活对象检测模块以识别和分类活跃对象。该方法在相关基准测试中展现了良好的性能。

> **摘要翻译:** 手物交互检测在实时应用中仍然是一个开放的挑战，其中直观的用户体验依赖于对周围物体快速准确的交互检测。我们提出了一种从以自我为中心的流式视觉中检测手物交互的有效方法，该方法实时运行。我们的方法包括一个动作识别模块和一个对象检测模块，用于在确认交互时识别活动对象。我们的Mamba模型以EfficientNetV2作为动作识别的骨干网络，在ENIGMA-51基准测试中以30fps的速度达到了38.52%的p-AP，而我们微调的YOLOWorld在手和物体检测方面达到了85.13%的AP。我们在级联架构中实现了我们的模型，其中动作识别和对象检测模块按顺序操作。当动作识别预测接触状态时，它会激活对象检测模块，该模块进而对相关帧执行推理以检测和分类活动对象。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [414] [Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition](https://arxiv.org/abs/2507.12807)
> *面向长尾视觉识别的语义引导式基础模型微调*

*Yufei Peng, Yonggang Zhang, Yiu-ming Cheung* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 长尾识别, 基础模型微调, 语义引导, 视觉-文本对齐, 分布偏差补偿

**Comment:** 

> **TL;DR:** 本文提出了一种名为Sage的新方法，通过语义引导微调和引入分布不匹配感知补偿因子来解决长尾视觉识别中基础模型的性能下降问题。

**AI_Comments:** 该论文的创新点在于结合了语义指导来增强基础模型的视觉-文本对齐，并提出了一个理论上支持的分布不匹配感知补偿因子来解决长尾分布带来的预测偏差问题。这种双管齐下的方法有效提升了基础模型在长尾识别任务上的表现，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 长尾场景中类别的样本量差异导致不频繁类别的性能下降。现有的微调方法忽略了冻结文本编码器导出的语义，忽视了视觉和文本对齐。此外，现有损失函数忽略了不一致的类别条件分布，导致尾部类别的预测偏差和性能提升不足。

**Method:** 本文提出了一种新颖的语义引导式基础模型微调（Sage）方法。具体来说，引入了一个SG-Adapter，将类别描述作为语义指导融入视觉微调过程，通过注意力机制增强视觉和文本模态之间的对齐。此外，为了解决预测偏差问题，提出了一种基于理论分析的分布不匹配感知补偿因子，并将其无缝集成到损失函数中。

**Result:** 在基准数据集上进行的广泛实验证明了所提出的Sage方法在增强长尾学习性能方面的有效性。

**Conclusion:** 本文提出的Sage方法通过语义引导微调和引入分布不匹配感知补偿因子，有效解决了长尾视觉识别中基础模型的性能下降问题，显著提升了长尾学习的性能。

> **ai_Abstract:** 本文针对长尾视觉识别中基础模型性能下降的问题，提出了一种名为Sage的新型语义引导式微调方法。该方法通过引入SG-Adapter，将类别描述作为语义指导融入视觉编码器微调过程，以增强视觉和文本模态的对齐。此外，为了解决因类别条件分布不一致导致的预测偏差问题，本文还提出了一种分布不匹配感知补偿因子，并将其集成到损失函数中。实验结果表明，Sage方法有效提升了长尾学习的性能。

> **摘要翻译:** 长尾场景中类别样本量差异通常会导致不频繁类别的性能下降。幸运的是，在海量开放世界数据集上预训练的基础模型，由于其可泛化的表示，在处理此任务方面表现出强大的潜力，这促进了长尾学习中预训练模型自适应策略的发展。先进的微调方法通常调整视觉编码器，但却忽略了从冻结文本编码器中获得的语义，从而忽视了视觉和文本对齐。为了加强这种对齐，我们提出了一种新颖的方法，即面向长尾视觉识别的语义引导式基础模型微调（Sage），它将从文本模态中获得的语义指导融入视觉微调过程。具体来说，我们引入了一个SG-Adapter，它将类别描述作为语义指导来引导视觉编码器的微调。引入的指导通过注意力机制传递，使模型能够更专注于语义相关内容，从而加强视觉和文本模态之间的对齐。由于现有损失函数忽略了不一致的类别条件分布，导致预测偏差，即使多模态对齐得到增强，尾部类别的性能提升仍不如头部类别。为了解决这一挑战，我们提出了一种新颖的分布不匹配感知补偿因子，该因子根据我们的理论分析专门设计用于纠正由忽略的不一致分布引起的预测偏差，并无缝集成到损失函数中。在基准数据集上进行的广泛实验证明了所提出的Sage方法在增强长尾学习性能方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [418] [Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Training Data Generation](https://arxiv.org/abs/2506.05026)
> *自动化光学检测的物理标注：一种用于现场、基于指针的训练数据生成概念*

*Oliver Krumpek, Oliver Heimann, Jörg Krüger* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 物理标注, 自动化光学检测, 训练数据生成, 现场交互, 指针式系统

**Comment:** 

> **TL;DR:** 本文提出一种用于自动化光学检测的物理标注系统，通过基于指针的现场交互，将人工经验直接转化为ML训练数据，比传统屏幕标注更直观高效，并能与现有工具集成。

**AI_Comments:** 该研究提出了一种新颖的物理标注方法，通过将标注过程从屏幕转移到实际物体上，极大地提升了自动化光学检测训练数据生成的直观性和效率。其创新点在于利用物理指针和投影技术，将人工经验直接高效地转化为ML可用的数据，降低了非IT人员参与ML数据标注的门槛，有效解决了传统方法的局限性，对于工业界ML应用的数据获取具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统屏幕标注方法效率低下且不够直观，需要一种更直接、更高效的方式将人工检测经验转化为机器学习训练数据，并使非IT专家也能参与其中，防止有价值训练样本的流失。

**Method:** 开发了一个物理标注系统，使用校准、跟踪的指针直接在物体上捕捉物理轨迹和轮廓。系统将空间交互转化为标准化标注格式，兼容开源标注软件。此外，使用投影仪界面在物体上投射视觉指导，以辅助用户。

**Result:** 初步评估结果证实了捕获详细标注轨迹的可行性，并表明与CVAT的集成简化了后续ML任务的工作流程。

**Conclusion:** 该系统弥合了人类专业知识和自动化数据生成之间的鸿沟，使非IT专家能够为ML训练管道做出贡献，并有望促进未来自动化光学检测的ML数据生成。

> **ai_Abstract:** 本文提出了一种创新的物理标注系统，旨在为自动化光学检测（AOI）生成高质量的机器学习训练数据。该系统通过基于指针的现场交互，直接在物理对象上捕捉检测专家的经验，生成轨迹和轮廓标注。与传统的屏幕标注不同，它提供更直观、高效的体验，并通过校准指针和投影仪辅助确保准确性。初步评估表明该方法可行，并能与现有ML工作流程（如CVAT）无缝集成，从而使非IT专家也能参与ML数据生成，有效利用人类专业知识。

> **摘要翻译:** 本文介绍了一种新颖的物理标注系统，旨在为自动化光学检测生成训练数据。该系统利用基于指针的现场交互，将训练有素的检测人员宝贵的专业知识直接转移到机器学习（ML）训练管道中。与传统的基于屏幕的标注方法不同，我们的系统直接在物体上捕捉物理轨迹和轮廓，提供了一种更直观、更高效的数据标注方式。其核心技术使用经过校准、跟踪的指针精确记录用户输入，并将这些空间交互转换为与开源标注软件兼容的标准化标注格式。此外，一个简单的基于投影仪的界面将视觉指导投射到物体上，以协助用户进行标注过程，确保更高的准确性和一致性。所提出的概念弥合了人类专业知识和自动化数据生成之间的鸿沟，使非IT专家能够为ML训练管道做出贡献，并防止有价值训练样本的流失。初步评估结果证实了捕获详细标注轨迹的可行性，并表明与CVAT的集成简化了后续ML任务的工作流程。本文详细介绍了系统架构、校准程序和界面设计，并讨论了其对未来自动化光学检测的ML数据生成的潜在贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [421] [Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization](https://arxiv.org/abs/2507.13018)
> *越过全监督像素标注：涂鸦驱动的弱监督图像篡改定位框架*

*Songlin Li, Guofeng Yu, Zhiqing Guo, Yunfeng Diao, Dan Ma, Gaobo Yang, Liejun Wang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 图像篡改定位, 弱监督学习, 涂鸦标注, 自监督训练, 特征调制

**Comment:** 

> **TL;DR:** 本文提出了一种基于涂鸦标注的弱监督图像篡改定位框架（Sc-IML），通过自监督训练、特征调制和损失函数设计，在减少标注成本的同时，超越了现有的全监督方法。

**AI_Comments:** 这篇论文的创新点在于首次将涂鸦标注引入图像篡改定位领域，并构建了相应的Sc-IML数据集。其提出的弱监督框架通过结合自监督学习、多模块特征增强（PFMM和GAFM）以及针对不确定区域的损失函数（$\\mathcal{L}_{ {CEM }}$），有效解决了弱监督信号不足的问题，并在性能上超越了全监督方法，这对于降低标注成本和推动IML技术发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于深度学习的图像篡改定位（IML）方法严重依赖大规模像素级标注数据集，但高质量标注获取困难。现有的弱监督方法（图像级标签）因监督信号不足而性能受限。本文旨在探索一种既能提高标注效率又能提升检测性能的弱监督形式，即涂鸦标注。

**Method:** 本研究探索涂鸦标注作为一种弱监督形式，并提出了首个基于涂鸦的IML数据集（Sc-IML），通过重新标注主流IML数据集获得。同时，提出了首个基于涂鸦的弱监督IML框架，具体包括：1) 采用结构一致性损失进行自监督训练，以确保模型在多尺度和增强输入下产生一致性预测。2) 提出先验感知特征调制模块（PFMM），自适应整合篡改区域和真实区域的先验信息，动态调整特征。3) 提出门控自适应融合模块（GAFM），利用门控机制调节特征融合过程中的信息流，引导模型关注潜在篡改区域。4) 提出置信度感知熵最小化损失（$\\mathcal{L}_{ {CEM }}$），根据模型不确定性动态正则化弱标注或未标注区域的预测。

**Result:** 实验结果表明，所提出的方法在分布内和分布外测试中，其平均性能均优于现有的全监督方法。

**Conclusion:** 本研究提出的基于涂鸦标注的弱监督框架，通过创新的模块和损失函数设计，有效解决了图像篡改定位中像素级标注依赖的问题，并在性能上超越了全监督方法，证明了涂鸦标注在IML领域的有效性和潜力。

> **ai_Abstract:** 本论文提出了一种基于涂鸦标注的弱监督图像篡改定位（IML）框架，旨在解决传统IML方法对大量像素级标注的依赖问题。作者通过重新标注主流数据集构建了首个Sc-IML数据集，并设计了一个创新的框架，该框架包含自监督训练、先验感知特征调制模块（PFMM）、门控自适应融合模块（GAFM）和置信度感知熵最小化损失（$\\mathcal{L}_{ {CEM }}$）。这些组件协同工作，增强了模型在弱监督条件下的特征判别能力和预测一致性。实验证明，该方法在平均性能上超越了现有的全监督IML方法。

> **摘要翻译:** 近年来，基于深度学习的图像篡改定位（IML）方法取得了显著的性能，但通常依赖于大规模像素级标注数据集。为了解决获取高质量标注的挑战，一些近期的弱监督方法利用图像级标签来分割篡改区域。然而，由于监督信号不足，其性能仍然有限。在本研究中，我们探索了一种提高标注效率和检测性能的弱监督形式，即涂鸦标注监督。我们使用涂鸦标签重新标注了主流IML数据集，并提出了首个基于涂鸦的IML（Sc-IML）数据集。此外，我们提出了首个基于涂鸦的弱监督IML框架。具体而言，我们采用自监督训练和结构一致性损失，鼓励模型在多尺度和增强输入下产生一致的预测。此外，我们提出了一个先验感知特征调制模块（PFMM），它自适应地整合来自篡改区域和真实区域的先验信息，进行动态特征调整，进一步增强复杂场景中的特征判别性和预测一致性。我们还提出了一个门控自适应融合模块（GAFM），它利用门控机制调节特征融合过程中的信息流，引导模型强调潜在的篡改区域。最后，我们提出了一个置信度感知熵最小化损失（$\\mathcal{L}_{ {CEM }}$）。该损失根据模型不确定性动态正则化弱标注或未标注区域的预测，有效抑制不可靠的预测。实验结果表明，我们的方法在分布内和分布外测试中，其平均性能均优于现有的全监督方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [428] [Task-Specific Generative Dataset Distillation with Difficulty-Guided Sampling](https://arxiv.org/abs/2507.03331)
> *任务特定生成式数据集蒸馏与难度引导采样*

*Mingzhuo Li, Guang Li, Jiafeng Mao, Linfeng Ye, Takahiro Ogawa, Miki Haseyama* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 数据集蒸馏, 生成模型, 任务特定采样, 难度引导, 分类

**Comment:** Accepted by The ICCV 2025 Workshop on Curated Data for Efficient
  Learning

> **TL;DR:** 本文提出了一种任务特定、难度引导的采样策略，用于生成式数据集蒸馏，以解决现有方法忽视任务特定信息的问题，并在分类任务上取得了有效性。

**AI_Comments:** 这项工作通过引入任务特定和难度引导的采样，解决了生成式数据集蒸馏中一个关键的未被充分探索的问题，即如何更好地将下游任务的需求纳入蒸馏过程。其创新点在于通过匹配难度分布来优化合成数据集，这有望提高蒸馏数据集对特定任务的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成式数据集蒸馏方法主要侧重于将蒸馏数据集与原始数据集对齐，但往往忽视了对最佳下游性能至关重要的任务特定信息。

**Method:** 针对分类下游任务，提出了一种任务特定的采样策略，将难度概念融入生成式数据集蒸馏。最终数据集从更大的图像池中采样，其采样分布通过匹配原始数据集的难度分布获得。应用对数变换作为预处理步骤以校正分布偏差。

**Result:** 广泛的实验结果证明了该方法的有效性，并表明其在增强其他下游任务性能方面的潜力。

**Conclusion:** 该方法通过引入任务特定和难度引导的采样，有效提升了生成式数据集蒸馏的性能，特别是在分类任务上，并有望推广到其他下游任务。

> **ai_Abstract:** 本文提出了一种针对分类任务的生成式数据集蒸馏新策略，通过引入“难度引导采样”来解决现有方法忽视任务特定信息的问题。该方法从一个更大的图像池中采样数据，并使其采样分布与原始数据集的难度分布相匹配，同时应用对数变换以纠正分布偏差。实验证明了该方法的有效性及其在提升下游任务性能方面的潜力。

> **摘要翻译:** 为了减轻深度神经网络对大规模数据集的依赖，数据集蒸馏旨在生成紧凑、高质量的合成数据集，这些数据集可以实现与原始数据集相当的性能。生成模型的集成显著推动了这一领域的发展。然而，现有方法主要侧重于将蒸馏数据集与原始数据集对齐，往往忽视了对最佳下游性能至关重要的任务特定信息。在本文中，我们针对分类这一下游任务，提出了一种任务特定的生成式数据集蒸馏采样策略，该策略融入了难度的概念，以更好地考虑目标任务的需求。最终的数据集从更大的图像池中采样，其采样分布通过匹配原始数据集的难度分布获得。作为预处理步骤，应用对数变换以校正分布偏差。广泛的实验结果证明了我们方法的有效性，并表明其在增强其他下游任务性能方面的潜力。代码可在 https://github.com/SumomoTaku/DiffGuideSamp 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [434] [Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos](https://arxiv.org/abs/2507.12646)
> *重建、修复、微调：单目视频的动态新视图合成*

*Kaihua Chen, Tarasha Khurana, Deva Ramanan* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 动态新视图合成, 单目视频, 3D重建, 视频修复, 扩散模型

**Comment:** Project page: https://cog-nvs.github.io/

> **TL;DR:** 本文提出了一种名为CogNVS的新方法，通过结合3D场景重建和2D视频扩散模型（用于修复隐藏像素），实现了从单目视频中合成动态场景的新视图，并通过测试时微调实现零样本应用，性能优于现有技术。

**AI_Comments:** 该论文的创新点在于将3D场景重建与2D视频扩散模型巧妙结合，解决了动态场景新视图合成中可见与隐藏像素的处理问题。特别是CogNVS的自监督训练能力和零样本微调应用模式，使其能够利用大规模数据并适应未见场景，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态场景新视图合成方法要么依赖耗时的4D表示测试时优化，要么在前馈训练时无法保留场景几何。

**Method:** 本方法基于三个关键点：1) 可见像素通过动态3D场景重建并渲染得到；2) 新视图中的隐藏像素通过前馈2D视频扩散模型（CogNVS）进行“修复”；3) CogNVS可以从2D视频中进行自监督训练，并在测试时通过微调实现零样本应用。

**Result:** CogNVS在从单目视频合成动态场景的新视图方面，性能优于几乎所有现有技术。

**Conclusion:** 本文提出的CogNVS方法通过结合3D重建和基于自监督扩散模型的2D修复，有效解决了动态场景新视图合成的挑战，并取得了卓越的性能。

> **ai_Abstract:** 本文提出了一种名为CogNVS的新方法，用于从单目视频合成动态场景的新视图。该方法结合了动态3D场景的重建和使用自监督2D视频扩散模型（CogNVS）对新视图中的隐藏像素进行修复。CogNVS模型能够在大规模野外视频上进行自监督训练，并通过测试时微调实现对新视频的零样本应用。实验结果表明，CogNVS在动态场景的新视图合成任务上显著优于现有的大多数方法。

> **摘要翻译:** 我们探索从单目视频合成动态场景的新视图。现有方法依赖于耗时的4D表示测试时优化，或者在前馈训练时无法保留场景几何。我们的方法基于三个关键见解：(1) 共视像素（在输入和目标视图中都可见）可以通过首先重建动态3D场景并从新视图渲染重建结果来生成；(2) 新视图中隐藏的像素可以通过前馈2D视频扩散模型进行“修复”。值得注意的是，我们的视频修复扩散模型（CogNVS）可以从2D视频中进行自监督训练，这使得我们可以在大量的野外视频语料库上对其进行训练。这反过来又允许 (3) CogNVS 通过测试时微调零样本应用于新的测试视频。我们通过经验验证，CogNVS 在从单目视频合成动态场景的新视图方面，性能优于几乎所有现有技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [Feature-Enhanced TResNet for Fine-Grained Food Image Classification](https://arxiv.org/abs/2507.12828)
> *特征增强型 TResNet 用于细粒度食物图像分类*

*Lulu Liu, Zhiyong Xiao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 细粒度食物图像分类, TResNet, StyleRM, DCA, 卷积神经网络

**Comment:** 

> **TL;DR:** 提出FE-TResNet模型，通过结合StyleRM和DCA技术，显著提升了细粒度食物图像分类的准确性。

**AI_Comments:** 该研究提出了一种新颖的FE-TResNet模型，通过结合StyleRM和DCA技术来增强对细微特征的捕获能力，这对于细粒度图像分类是一个重要的创新点。其在中文食物数据集上的显著性能提升，表明了该方法在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有卷积神经网络（CNN）在处理形状相似但细节细微的细粒度食物图像时面临重大挑战，因此需要更准确的分类方法。

**Method:** 本研究提出了一种名为特征增强型 TResNet（FE-TResNet）的创新食物图像分类方法。该方法基于TResNet模型，并集成了基于风格的重新校准模块（StyleRM）和深度通道注意力（DCA）技术，以增强特征提取能力。

**Result:** 在中文食物图像数据集 ChineseFoodNet 和 CNFOOD-241 上的实验验证中，FE-TResNet 方法显著提高了分类准确性，分别达到了 81.37% 和 80.29% 的准确率。

**Conclusion:** FE-TResNet在细粒度食物图像分类中表现出有效性和优越性。

> **ai_Abstract:** 本文提出了一种名为FE-TResNet的创新方法，旨在解决细粒度食物图像分类中现有CNN的挑战。该方法基于TResNet模型，并集成了Style-based Recalibration Module (StyleRM) 和 Deep Channel-wise Attention (DCA) 技术来增强特征提取能力。实验结果表明，FE-TResNet在ChineseFoodNet和CNFOOD-241数据集上显著提高了分类准确率，证明了其在细粒度食物图像分类中的有效性和优越性。

> **摘要翻译:** 食物不仅是人类日常饮食的核心组成部分，也是文化遗产和情感纽带的重要载体。随着技术的发展，对食物图像进行准确分类的需求日益增长，这对于各种应用场景都至关重要。然而，现有卷积神经网络（CNN）在处理形状相似但细节细微的细粒度食物图像时面临重大挑战。为了解决这一挑战，本研究提出了一种创新的食物图像分类方法，名为特征增强型 TResNet（FE-TResNet），专门设计用于处理细粒度食物图像并准确捕获其中的细微特征。FE-TResNet 方法基于 TResNet 模型，并集成了基于风格的重新校准模块（StyleRM）和深度通道注意力（DCA）技术，以增强特征提取能力。在中文食物图像数据集 ChineseFoodNet 和 CNFOOD-241 上的实验验证中，FE-TResNet 方法显著提高了分类准确性，分别达到了 81.37% 和 80.29% 的准确率，证明了其在细粒度食物图像分类中的有效性和优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [438] [Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920](https://arxiv.org/abs/2506.07960)
> *从1800-1920年芬兰教会记录中创建历史迁徙数据集*

*Ari Vesalainen, Jenna Kanerva, Aida Nitsch, Kiia Korsu, Ilari Larkiola, Laura Ruotsalainen, Filip Ginter* | **Category: cs.CV, I.4.6, J.5** | **Updated: 2025-07-17**

**Keywords:** 芬兰迁徙, 教会记录, 深度学习, 历史人口学, 数据提取

**Comment:** 

> **TL;DR:** 本文通过深度学习管道，从数字化教会记录中创建了1800-1920年芬兰国内迁徙的大规模结构化数据集。

**AI_Comments:** 该研究通过应用深度学习管道自动化从海量手写历史文档中提取数据，具有显著的创新性，将非结构化的档案资料转化为可用于研究的结构化数据。这项工作为历史人口学和社会历史提供了宝贵的新资源，使得以前因数据可访问性受限而无法进行的定量研究成为可能。它还为其他大规模手写档案的数字化提供了范例。

<details>
  <summary>Details</summary>

**Motivation:** 为了利用芬兰福音派路德教会维护的数字化教会迁徙记录，这些记录是研究历史人口模式的宝贵资料来源，从而支持历史和人口学研究。

**Method:** 数据提取过程通过一个深度学习管道自动化完成，该管道包括版面分析、表格检测、单元格分类和手写识别。该管道应用于约20万张手写迁徙记录图像。

**Result:** 创建了一个包含超过600万条条目的结构化数据集，这些数据来自芬兰1800年至1920年间的教会迁徙记录。该数据集可用于研究国内迁徙、城市化、家庭迁徙以及前工业时代芬兰的疾病传播。

**Conclusion:** 这项工作展示了如何将大量手写档案材料转化为结构化数据，以支持历史和人口学研究。

> **ai_Abstract:** 本文描述了如何从1800年至1920年芬兰教会记录中创建大规模结构化历史迁徙数据集。研究人员从约20万张数字化手写记录图像中提取了超过600万条条目，并利用包含版面分析、表格检测、单元格分类和手写识别的深度学习管道自动化了数据提取过程。该数据集旨在促进历史和人口学研究，包括对国内迁徙、城市化、家庭迁徙和疾病传播的研究。

> **摘要翻译:** 本文介绍了一项大规模工作，旨在使用数字化教会迁徙记录，创建1800年至1920年间芬兰国内迁徙的结构化数据集。这些由福音派路德教会维护的记录，记载了个人和家庭的迁徙，为研究历史人口模式提供了宝贵的资料来源。该数据集包含从大约20万张手写迁徙记录图像中提取的超过600万条条目。
数据提取过程通过深度学习管道自动化完成，该管道包括版面分析、表格检测、单元格分类和手写识别。完整的管道应用于所有图像，从而生成了一个适合研究的结构化数据集。
该数据集可用于研究前工业时代芬兰的国内迁徙、城市化、家庭迁徙以及疾病传播。来自Elimäki教区的一个案例研究展示了如何重建当地的迁徙历史。这项工作展示了如何将大量手写档案材料转化为结构化数据，以支持历史和人口研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [440] [$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation](https://arxiv.org/abs/2507.13229)
> *S²M²：可扩展立体匹配模型，用于可靠深度估计*

*Junhong Min, Youngpil Jeon, Jimin Kim, Minyong Choi* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 立体匹配, 深度估计, 全局匹配, Transformer, 泛化能力

**Comment:** 8 pages, 5 figures, ICCV accepted paper

> **TL;DR:** S²M²是一个全局匹配架构，它在不依赖成本体过滤或深度精细化堆栈的情况下，实现了最先进的精度和高效率，用于可靠的深度估计。

**AI_Comments:** S²M²的创新之处在于其全局匹配架构，它克服了传统全局方法的高成本问题，同时避免了局部方法的泛化限制。通过集成多分辨率Transformer和定制的损失函数，该模型在保持效率的同时实现了卓越的精度和鲁棒性，尤其是在处理不同分辨率和视差范围的能力上，这对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有的立体匹配模型在泛化能力上存在局限，迭代局部搜索方法缺乏全局一致性，而全局匹配架构则面临计算和内存成本过高的问题。

**Method:** 本文提出了S²M²模型，一个全局匹配架构。它集成了多分辨率Transformer，用于鲁棒的长距离对应，并采用一种新颖的损失函数，将概率集中在可行匹配上。该方法能够更鲁棒地联合估计视差、遮挡和置信度。

**Result:** S²M²在Middlebury v3和ETH3D基准测试上建立了新的最先进水平，在大多数指标上显著优于现有方法，同时以具有竞争力的效率重建高质量细节。

**Conclusion:** S²M²成功地解决了通用立体匹配模型中精度与效率的权衡问题，通过创新的全局匹配架构实现了卓越的性能和泛化能力。

> **ai_Abstract:** 本文提出了S²M²，一个可扩展的全局立体匹配模型，旨在解决现有方法在泛化能力和计算效率上的不足。S²M²采用多分辨率Transformer和新颖的损失函数，实现了对视差、遮挡和置信度的联合鲁棒估计。该模型在Middlebury v3和ETH3D基准测试上取得了最先进的性能，显著提升了深度估计的精度和效率，同时无需数据集特定微调。

> **摘要翻译:** 追求一个能够在不进行数据集特定微调的情况下，跨不同分辨率和视差范围执行的通用立体匹配模型，揭示了一个根本性的权衡。迭代局部搜索方法在受限基准上取得了高分，但其核心机制固有地限制了真正泛化所需的全局一致性。另一方面，全局匹配架构虽然理论上更鲁棒，但历史上因高昂的计算和内存成本而变得不可行。我们通过S²M²解决了这个困境：一个全局匹配架构，在不依赖成本体过滤或深度精细化堆栈的情况下，实现了最先进的精度和高效率。我们的设计集成了一个多分辨率Transformer，用于鲁棒的长距离对应，并采用了一种新颖的损失函数进行训练，该损失函数将概率集中在可行匹配上。这种方法能够更鲁棒地联合估计视差、遮挡和置信度。S²M²在Middlebury v3和ETH3D基准测试上建立了新的最先进水平，在大多数指标上显著优于现有方法，同时以具有竞争力的效率重建高质量细节。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [447] [Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models](https://arxiv.org/abs/2507.13344)
> *Diffuman4D: 基于时空扩散模型的稀疏视角视频4D一致性人体视图合成*

*Yudong Jin, Sida Peng, Xuan Wang, Tao Xie, Zhen Xu, Yifan Yang, Yujun Shen, Hujun Bao, Xiaowei Zhou* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 4D一致性, 人体视图合成, 稀疏视角视频, 时空扩散模型, 滑动迭代去噪

**Comment:** Project page: https://diffuman4d.github.io/

> **TL;DR:** Diffuman4D 提出了一种滑动迭代去噪过程，通过时空扩散模型从稀疏视角视频中合成高质量且一致的4D人体视图。

**AI_Comments:** 该论文的关键创新在于引入了滑动迭代去噪过程，有效解决了4D扩散模型在稀疏视角视图合成中面临的时空一致性难题。通过巧妙地设计潜在网格和交替去噪机制，不仅提升了合成视频的质量和一致性，还在一定程度上控制了计算资源消耗，具有重要的实际应用价值和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法使用4D扩散模型从稀疏视角视频生成新视角的视频，但生成视频缺乏时空一致性，从而降低视图合成质量。

**Method:** 本文提出一种新颖的滑动迭代去噪过程，以增强4D扩散模型的时空一致性。具体地，定义一个潜在网格，每个潜在编码图像、相机姿态和人体姿态，然后通过滑动窗口沿空间和时间维度交替去噪潜在网格，最后从去噪后的潜在中解码目标视角的视频。这种迭代滑动使得信息在潜在网格中充分流动，从而获得大感受野并增强4D一致性，同时保持GPU内存消耗可承受。

**Result:** 在DNA-Rendering和ActorsHQ数据集上的实验表明，该方法能够合成高质量且一致的新视角视频，并显著优于现有方法。

**Conclusion:** 通过引入滑动迭代去噪过程，Diffuman4D有效解决了稀疏视角人体视图合成中的时空一致性问题，实现了高质量的4D视频生成。

> **ai_Abstract:** Diffuman4D提出了一种新颖的滑动迭代去噪过程，用于从稀疏视角视频中进行高质量、4D一致性的人体视图合成。该方法通过在潜在网格上沿时空维度交替去噪，解决了现有4D扩散模型生成视频缺乏时空一致性的问题，同时优化了内存使用。实验证明其在生成高质量和一致性新视角视频方面显著优于现有方法。

> **摘要翻译:** 这篇论文解决了从稀疏视角视频输入中高保真度人体视图合成的挑战。以前的方法通过利用4D扩散模型生成新视角的视频来解决观察不足的问题。然而，这些模型生成的视频通常缺乏时空一致性，从而降低了视图合成质量。在这篇论文中，我们提出了一种新颖的滑动迭代去噪过程，以增强4D扩散模型的时空一致性。具体地，我们定义了一个潜在网格，其中每个潜在编码了特定视角和时间戳的图像、相机姿态和人体姿态，然后通过滑动窗口沿空间和时间维度交替去噪潜在网格，最后从相应的去噪潜在中解码目标视角的视频。通过迭代滑动，信息在潜在网格中充分流动，使得扩散模型能够获得大感受野，从而增强输出的4D一致性，同时使GPU内存消耗可承受。在DNA-Rendering和ActorsHQ数据集上的实验表明，我们的方法能够合成高质量且一致的新视角视频，并显著优于现有方法。请查看我们的项目页面以获取交互式演示和视频结果：https://diffuman4d.github.io/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [448] [KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos](https://arxiv.org/abs/2507.07393)
> *KeyRe-ID：视频中基于关键点引导和部分感知表示的人物重识别*

*Jinseong Kim, Jeonghoon Song, Gyeongseon Baek, Byeongjoon Noh* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 人物重识别, 关键点, 视频, 部分感知, 深度学习

**Comment:** 10 pages, 2 figures,

> **TL;DR:** KeyRe-ID是一个利用人体关键点进行视频人物重识别的框架，通过全局和局部分支学习增强的时空表示，并在多个基准测试中取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于其关键点引导和部分感知表示的学习方法，通过结合全局和局部信息，有效地提升了视频人物重识别的性能。其在主流数据集上取得的SOTA结果，证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强时空表示学习，从而提升视频中人物重识别的性能。

**Method:** 本文提出了KeyRe-ID框架，包含全局和局部两个分支。全局分支通过基于Transformer的时间聚合捕获整体身份语义，而局部分支则根据关键点动态分割身体区域以生成细粒度的、部分感知的特征。

**Result:** 在MARS数据集上，mAP达到91.73%，Rank-1准确率达到97.32%。在iLIDS-VID数据集上，Rank-1准确率达到96.00%，Rank-5准确率达到100.0%。

**Conclusion:** KeyRe-ID框架通过利用人体关键点进行部分感知表示学习，在视频人物重识别任务中取得了最先进的性能。

> **ai_Abstract:** KeyRe-ID是一个创新的视频人物重识别框架，它通过结合全局和局部分支，并利用人体关键点来学习增强的时空表示。全局分支使用Transformer进行整体身份聚合，而局部分支则动态生成细粒度的部分感知特征。该方法在MARS和iLIDS-VID数据集上均取得了显著的、最先进的性能。

> **摘要翻译:** 我们提出了KeyRe-ID，一个基于关键点引导的视频人物重识别框架，由全局和局部分支组成，利用人体关键点增强时空表示学习。全局分支通过基于Transformer的时间聚合捕获整体身份语义，而局部分支则根据关键点动态分割身体区域以生成细粒度的、部分感知的特征。在MARS和iLIDS-VID基准测试上的大量实验表明，该方法达到了最先进的性能，在MARS上实现了91.73%的mAP和97.32%的Rank-1准确率，在iLIDS-VID上实现了96.00%的Rank-1和100.0%的Rank-5准确率。该工作的代码将在发布后在GitHub上公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [450] [MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2507.12819)
> *MCoT-RE：基于多面思维链和重排序的免训练零样本组合图像检索*

*Jeong-Woo Park, Seong-Whan Lee* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 组合图像检索, 免训练, 零样本, 多面思维链, 重排序

**Comment:** 6 pages, 4 figures, 2025 IEEE International Conference on Systems,
  Man, and Cybernetics

> **TL;DR:** MCoT-RE提出了一种免训练零样本组合图像检索框架，通过多面思维链生成两种描述并结合重排序，有效平衡文本修改和视觉上下文，实现了SOTA性能。

**AI_Comments:** 这篇论文的创新点在于引入了“多面思维链”来指导多模态大语言模型生成差异化的描述，从而同时兼顾文本修改指令和参考图像的视觉上下文。这种两阶段的过滤和重排序机制有效地解决了现有免训练CIR方法中跨模态交互不足和信息利用不全面的问题。其在零样本、免训练设置下达到SOTA性能，显示了其实用性和成本效益。

<details>
  <summary>Details</summary>

**Motivation:** 现有的免训练零样本组合图像检索方法存在局限性：顺序VLM-LLM管道独立处理模态导致信息丢失和跨模态交互受限；基于多模态大语言模型（MLLMs）的方法未充分利用参考图像的上下文视觉信息。

**Method:** 提出MCoT-RE框架，利用多面思维链引导MLLM平衡显式修改和上下文视觉线索，生成两种不同的描述：一种侧重修改，另一种整合全面的视觉-文本上下文。首先使用第一种描述过滤候选图像，然后结合两种描述和参考图像进行多粒度重排序。

**Result:** MCoT-RE在免训练方法中取得了最先进的结果，在FashionIQ数据集上的Recall@10提高了6.24%，在CIRR数据集上的Recall@1提高了8.58%。

**Conclusion:** MCoT-RE通过其两阶段方法（平衡文本修改指令和保留参考图像视觉上下文）实现了精确的组合图像检索，并在免训练设置下达到了SOTA性能。

> **ai_Abstract:** 本文提出MCoT-RE，一个免训练零样本组合图像检索（CIR）框架，旨在解决现有方法中信息丢失和视觉上下文利用不足的问题。MCoT-RE通过多面思维链引导多模态大语言模型（MLLM）生成两种描述（一种侧重修改，一种整合视觉-文本上下文），并采用两阶段方法：先用修改描述过滤，再结合两种描述和参考图像进行多粒度重排序。实验证明，MCoT-RE在免训练方法中取得了最先进的性能，显著提升了FashionIQ和CIRR数据集上的检索准确率。

> **摘要翻译:** 组合图像检索（CIR）是一项使用由参考图像和修改文本组成的查询从图库中检索目标图像的任务。在各种CIR方法中，基于预训练模型的免训练零样本方法具有成本效益，但仍面临显著局限性。例如，顺序VLM-LLM管道独立处理每种模态，这通常导致信息丢失并限制跨模态交互。相比之下，基于多模态大语言模型（MLLMs）的方法通常只关注应用文本指示的更改，而未能充分利用参考图像的上下文视觉信息。为了解决这些问题，我们提出了MCoT-RE，一个免训练零样本CIR框架，它利用多面思维链和重排序。MCoT-RE利用多面思维链引导MLLM平衡显式修改和上下文视觉线索，生成两种不同的描述：一种侧重于修改，另一种整合了全面的视觉-文本上下文。第一种描述用于过滤候选图像。随后，我们将这两种描述和参考图像结合起来进行多粒度重排序。这种两阶段方法通过与文本修改指令对齐同时保留参考图像的视觉上下文，促进了精确检索。通过广泛的实验，MCoT-RE在免训练方法中取得了最先进的结果，在FashionIQ上的Recall@10提高了6.24%，在CIRR上的Recall@1提高了8.58%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [456] [Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation](https://arxiv.org/abs/2507.13032)
> *复活掩码自回归模型以实现高效可扩展的图像生成*

*Yi Xin, Le Zhuo, Qi Qin, Siqi Luo, Yuewen Cao, Bin Fu, Yangfan He, Hongsheng Li, Guangtao Zhai, Xiaohong Liu, Peng Gao* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 图像生成, 掩码自回归, MaskGIL, LLaMA, 高效推理

**Comment:** 24 pages, 10 figures, 10 tables

> **TL;DR:** 本文通过改进架构，提出MaskGIL模型，使掩码自回归(MAR)模型在图像生成质量上媲美最先进的自回归(AR)模型，同时大大减少推理步骤，并可扩展应用于文本到图像和语音到图像。

**AI_Comments:** 这项研究的创新之处在于成功地弥补了掩码自回归模型在生成质量上的不足，使其能够与最先进的自回归模型相媲美，同时极大地提高了推理效率。其通过改进LLaMA架构和引入2D RoPE的策略是关键。该工作不仅提升了MAR模型的实用性，还展示了其在多模态生成任务中的广泛应用潜力，对于需要高效高质量图像生成的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的掩码自回归（MAR）模型虽然在并行解码方面效率高，但其图像生成质量不如标准的自回归（AR）模型，因此需要改进MAR架构以提高其图像生成质量。

**Method:** 本研究首先评估了各种图像分词器以找到最有效的。随后，通过将因果注意力替换为双向注意力并结合2D RoPE，引入了一种改进的双向LLaMA架构，从而形成了先进模型MaskGIL。

**Result:** MaskGIL模型参数规模从1.11亿扩展到14亿，在ImageNet 256x256基准测试中实现了3.71的FID分数，与最先进的自回归模型表现相当，但推理步骤仅需8步（AR模型需256步）。此外，还开发了一个7.75亿参数的文本驱动MaskGIL模型，用于生成不同分辨率的文本图像，并可扩展应用于加速基于AR的生成和实现实时语音到图像转换。

**Conclusion:** 本文成功复活了掩码自回归模型，通过架构改进使其在图像生成质量上达到最先进自回归模型的水平，同时显著提高了推理效率，并展示了其在多模态生成任务中的广泛应用潜力。

> **ai_Abstract:** 本文致力于改进掩码自回归（MAR）模型在图像生成方面的性能，以克服其传统上劣于标准自回归（AR）模型的缺点。通过评估图像分词器并引入基于改进双向LLaMA架构（结合双向注意力和2D RoPE）的MaskGIL模型，研究者显著提升了MAR模型的生成质量。MaskGIL在ImageNet 256x256上实现了与SOTA AR模型相当的FID分数（3.71），同时将推理步骤从256步大幅减少到8步。此外，该模型还被扩展用于文本到图像生成以及加速其他AR基生成任务和实时语音到图像转换。

> **摘要翻译:** 自回归（AR）模型在图像生成方面取得了显著进展，其中掩码自回归（MAR）模型因其高效的并行解码而受到关注。然而，MAR模型传统上在性能上不如标准的AR模型。本研究旨在改进MAR架构以提高图像生成质量。我们首先评估了各种图像分词器以确定最有效的一个。随后，我们通过将因果注意力替换为双向注意力并结合2D RoPE，引入了一种改进的双向LLaMA架构，这些共同构成了我们的先进模型MaskGIL。MaskGIL模型参数规模从1.11亿扩展到14亿，在ImageNet 256x256基准测试中实现了3.71的FID分数，与最先进的AR模型表现相当，但推理步骤仅需8步，而AR模型需要256步。此外，我们开发了一个7.75亿参数的文本驱动MaskGIL模型，用于生成不同分辨率的文本图像。除了图像生成，MaskGIL还可扩展应用于加速基于AR的生成和实现实时语音到图像转换。我们的代码和模型可在https://github.com/synbol/MaskGIL 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [458] [OscNet v1.5: Energy Efficient Hopfield Network on CMOS Oscillators for Image Classification](https://arxiv.org/abs/2506.12610)
> *OscNet v1.5：基于CMOS振荡器的节能型霍普菲尔德网络用于图像分类*

*Wenxiao Cai, Zongru Li, Iris Wang, Yu-Neng Wang, Thomas H. Lee* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 霍普菲尔德网络, CMOS振荡器, 节能, 图像分类, 稀疏连接

**Comment:** 

> **TL;DR:** OscNet v1.5提出了一种基于霍普菲尔德网络的节能机器学习算法，可在CMOS振荡器网络上实现，并在MNIST数据集上表现出高精度和连接稀疏性。

**AI_Comments:** 本论文的创新点在于将霍普菲尔德网络与CMOS振荡器硬件相结合，提出了一种节能的机器学习方案。通过采用稀疏连接和仅前向传播的训练方式，显著降低了计算资源消耗，同时保持了高精度。这对于边缘计算和低功耗AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习虽然取得了显著进步，但需要消耗大量计算资源，因此迫切需要一种新颖、节能的计算架构和相应的算法。

**Method:** 本研究提出了一种基于霍普菲尔德网络的机器学习算法，该算法可在CMOS振荡器网络（OscNet）上实现。该网络仅通过前向传播进行训练以学习稀疏连接的权重，并通过SHIL技术与CMOS兼容环形振荡器阵列结合。

**Result:** 与传统深度学习模型相比，该方法在MNIST数据集上的精度提高了8%。在基于振荡器的推理中，仅使用了全连接霍普菲尔德网络24%的连接，而精度仅下降0.1%。OscNet v1.5在MNIST上实现了具有竞争力的精度。

**Conclusion:** OscNet v1.5是一种仅依赖前向传播并采用稀疏连接的节能机器学习流水线，非常适合振荡器计算架构。

> **ai_Abstract:** 本论文介绍了OscNet v1.5，一种基于霍普菲尔德网络的机器学习算法，旨在解决传统机器学习的高能耗问题。该算法可在CMOS振荡器网络上实现，仅通过前向传播训练稀疏连接的权重。实验结果表明，OscNet v1.5在MNIST数据集上比传统深度学习模型提高了8%的精度，并且在推理时仅使用24%的连接，精度损失微乎其微（0.1%）。这使得OscNet v1.5成为一种高效节能的机器学习解决方案，适用于振荡器计算架构。

> **摘要翻译:** 机器学习取得了显著进展，但代价是消耗大量计算资源。这使得对新型节能计算结构和相应算法的需求变得紧迫。CMOS振荡器网络（OscNet）是一种受大脑启发并专门为低能耗设计的硬件。在本文中，我们提出了一种基于霍普菲尔德网络的机器学习算法，该算法可以在OscNet上实现。该网络仅使用前向传播进行训练以学习稀疏连接的权重，但在MNIST数据集上与传统深度学习模型相比，精度提高了8%。OscNet v1.5在MNIST上实现了具有竞争力的精度，并且非常适合使用带有SHIL的CMOS兼容环形振荡器阵列实现。在基于振荡器的推理中，我们仅使用了全连接霍普菲尔德网络24%的连接，而精度仅下降0.1%。OscNet v1.5仅依赖前向传播并采用稀疏连接，使其成为专为振荡器计算结构设计的节能机器学习流水线。OscNet系列的代码库是：https://github.com/RussRobin/OscNet。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results](https://arxiv.org/abs/2507.12832)
> *MVA 2025 小型多目标跟踪用于发现鸟类挑战：数据集、方法和结果*

*Yuki Kondo, Norimichi Ukita, Riku Kanayama, Yuki Yoshida, Takayuki Yamaguchi, Xiang Yu, Guang Liang, Xinyao Liu, Guan-Zhang Wang, Wei-Ta Chu, Bing-Cheng Chuang, Jia-Hua Lee, Pin-Tseng Kuo, I-Hsuan Chu, Yi-Shein Hsiao, Cheng-Han Wu, Po-Yi Wu, Jui-Chien Tsou, Hsuan-Chi Liu, Chun-Yi Lee, Yuan-Fu Yang, Kosuke Shigematsu, Asuka Shin, Ba Tran* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 小型多目标跟踪, 无人机, 鸟类跟踪, 挑战赛, 数据集

**Comment:** This paper is the official challenge report for SMOT4SB and is
  published in the proceedings of MVA 2025 (19th International Conference on
  Machine Vision and Applications). Official challenge page:
  https://www.mva-org.jp/mva2025/challenge

> **TL;DR:** 本文介绍了MVA2025 SMOT4SB挑战，旨在解决小型多目标跟踪中由于目标过小导致的检测和关联困难。挑战提供了新的数据集、SO-HOTA评估指标，并取得了显著的性能提升。

**AI_Comments:** 本文通过引入专为无人机鸟类跟踪设计的SMOT4SB数据集和创新的SO-HOTA评估指标，显著推动了小型多目标跟踪领域的发展。该挑战赛的成功举办及其显著的性能提升，突显了社区协作在解决复杂视觉任务中的重要性。数据集捕捉运动纠缠的特性以及对小目标位移敏感性的改进，是其创新之处。

<details>
  <summary>Details</summary>

**Motivation:** 当目标仅占据几十个像素时，小型多目标跟踪（SMOT）变得尤为困难，导致基于检测和外观的关联不可靠。

**Method:** 本文介绍了SMOT4SB挑战，旨在利用时间信息解决单帧检测的局限性。主要贡献包括：(1) SMOT4SB数据集，包含211个无人机视频序列，108,192个带注释的帧，用于捕捉相机和目标在3D空间中自由移动的运动纠缠；(2) SO-HOTA，一种结合点距离和HOTA的新型度量，以减轻基于IoU的度量对微小位移的敏感性；(3) 举办了一场竞争激烈的MVA2025挑战赛。

**Result:** MVA2025挑战赛吸引了78名参与者和308份提交，其中获胜方法比基线提高了5.1倍。

**Conclusion:** 这项工作为推进无人机场景中的小型多目标跟踪奠定了基础，并在避免鸟击、农业、渔业和生态监测等领域具有应用前景。

> **ai_Abstract:** 本文介绍了MVA2025小型多目标跟踪（SMOT）用于发现鸟类挑战（SMOT4SB），旨在解决无人机视频中小型目标跟踪的难题。研究贡献包括：发布了包含10万多帧无人机视频的SMOT4SB数据集，提出了结合点距离和HOTA的SO-HOTA新评估指标以提高对小目标位移的鲁棒性，并成功举办了MVA2025挑战赛，其中最佳方法实现了5.1倍的性能提升。这项工作为SMOT在无人机应用中的发展奠定了基础。

> **摘要翻译:** 小型多目标跟踪（SMOT）在目标仅占据几十个像素时尤其具有挑战性，这使得检测和基于外观的关联变得不可靠。在MVA2023 SOD4SB挑战赛成功的基础上，本文介绍了SMOT4SB挑战赛，该挑战赛利用时间信息来解决单帧检测的局限性。我们的三大主要贡献是：(1) SMOT4SB数据集，由211个无人机视频序列组成，包含108,192个在各种真实世界条件下带注释的帧，旨在捕捉相机和目标在3D空间中自由移动的运动纠缠；(2) SO-HOTA，一种结合点距离和HOTA的新型度量，以减轻基于IoU的度量对微小位移的敏感性；(3) 一场竞争激烈的MVA2025挑战赛，有78名参与者和308份提交，其中获胜方法比基线提高了5.1倍。这项工作为推进无人机场景中的小型多目标跟踪奠定了基础，并在避免鸟击、农业、渔业和生态监测等领域具有应用前景。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [474] [Integrated Oculomics and Lipidomics Reveal Microvascular Metabolic Signatures Associated with Cardiovascular Health in a Healthy Cohort](https://arxiv.org/abs/2507.12663)
> *整合眼组学和脂质组学揭示健康人群中与心血管健康相关的微血管代谢特征*

*Inamullah, Ernesto Elias Vidal Rosas, Imran Razzak, Shoaib Jameel* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 眼组学, 脂质组学, 心血管健康, 微血管, 生物标志物

**Comment:** 

> **TL;DR:** 本研究整合了视网膜微血管特征和血清脂质组学数据，发现了与心血管疾病风险相关的早期微血管代谢生物标志物。

**AI_Comments:** 本研究的创新之处在于首次大规模整合了眼组学（视网膜微血管特征）和脂质组学数据，以识别心血管疾病的早期生物标志物，超越了传统的风险评估方法。其重要性在于为心血管疾病的早期检测和个性化预防提供了新的非侵入性途径。研究在健康人群中进行，有助于识别疾病的亚临床阶段，具有重要的临床转化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有心血管疾病风险分层方法未能检测早期亚临床变化。以往研究未将视网膜微血管特征与血清脂质组学分析结合，以寻找心血管疾病风险指标。

**Method:** 本研究引入了一种创新的影像组学框架，结合了通过深度学习图像处理获得的视网膜微血管特征与血清脂质组学数据。这是首次在健康人群中进行大规模、协变量调整和分层的相关性分析。视网膜表型通过自动化图像分析工具量化，血清脂质谱通过超高效液相色谱-电喷雾电离高分辨质谱（UHPLC-ESI-HRMS）进行分析。

**Result:** 建立了与年龄和性别无关的强相关性，特别是平均动脉宽度、血管密度与三酰甘油（TAGs）、二酰甘油（DAGs）和神经酰胺（Cers）等脂质亚类之间。

**Conclusion:** 这些关联表明代谢应激下微血管重塑的趋同机制。通过将详细的血管结构表型与特定脂质种类联系起来，本研究填补了对早期心血管疾病发病机制理解的关键空白。这种整合为微血管代谢关联提供了新视角，并为识别稳健、无创的生物标志物提供了重要机会。这些发现最终可能支持心血管医疗保健中早期检测、靶向预防和个性化方法的改进。

> **ai_Abstract:** 本研究引入了一种创新的影像组学框架，结合深度学习处理的视网膜微血管特征与血清脂质组学数据，旨在识别健康人群中与心血管健康相关的早期无症状生物标志物。研究发现，平均动脉宽度、血管密度与三酰甘油、二酰甘油和神经酰胺等脂质亚类之间存在强烈的、与年龄和性别无关的关联。这些发现揭示了代谢应激下微血管重塑的机制，填补了早期心血管疾病发病机制理解的空白，并为开发无创生物标志物以改进心血管疾病的早期检测和个性化预防提供了新途径。

> **摘要翻译:** 心血管疾病（CVD）仍然是全球主要的死亡原因，然而当前的风险分层方法往往未能检测到早期、亚临床的变化。以往的研究通常没有将视网膜微血管特征与全面的血清脂质组学图谱整合起来，作为心血管疾病风险的潜在指标。在本研究中，引入了一种创新的影像组学框架，将通过基于深度学习的图像处理获得的视网膜微血管特征与血清脂质组学数据相结合，以突出超越传统血脂指标的心血管风险无症状生物标志物。这代表了首次在健康人群中进行的大规模、协变量调整和分层的相关性分析，这对于识别疾病的早期指标至关重要。视网膜表型使用自动化图像分析工具进行量化，而血清脂质谱分析通过超高效液相色谱-电喷雾电离高分辨质谱（UHPLC ESI HRMS）进行。建立了与年龄和性别无关的强相关性，特别是平均动脉宽度、血管密度与三酰甘油（TAGs）、二酰甘油（DAGs）和神经酰胺（Cers）等脂质亚类之间。这些关联表明代谢应激下微血管重塑的趋同机制。通过将详细的血管结构表型与特定脂质种类联系起来，本研究填补了对早期心血管疾病发病机制理解的关键空白。这种整合不仅为微血管代谢关联提供了新视角，而且为识别稳健、无创的生物标志物提供了重要机会。最终，这些发现可能支持心血管医疗保健中早期检测、靶向预防和个性化方法的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [475] [VITA: Vision-to-Action Flow Matching Policy](https://arxiv.org/abs/2507.13231)
> *VITA：视觉到动作流匹配策略*

*Dechen Gao, Boqi Zhao, Andrew Lee, Ian Chuang, Hanchu Zhou, Hang Wang, Zhe Zhao, Junshan Zhang, Iman Soltani* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 流匹配, 视觉运动控制, 潜在表示, 双臂操作, MLP

**Comment:** Project page: https://ucd-dare.github.io/VITA/

> **TL;DR:** VITA是一种简单但高效的视觉到动作流匹配策略，它将潜在视觉表示直接映射到潜在动作，无需额外的条件机制，并在双臂操作任务中超越或匹配现有技术水平，同时显著降低推理延迟。

**AI_Comments:** VITA的创新点在于其独特的流匹配范式，直接将视觉潜在表示作为流的源，从而消除了传统生成模型中常见的复杂条件机制。这种设计不仅简化了模型架构（仅使用MLP），还显著提高了推理效率。该方法解决了异构模态间学习流的挑战，并通过结构化动作潜在空间和端到端监督实现了有效学习。其在复杂双臂操作任务上的出色表现证明了其简单而强大的能力，为未来视觉到动作策略的设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的流匹配和扩散策略需要从标准源分布采样并依赖额外的条件机制（如交叉注意力）来根据视觉信息生成动作，这会产生时间和空间开销。VITA旨在通过提出一种将潜在图像作为流源的新范式来解决这些问题，从而消除单独的条件模块并保留生成建模能力。

**Method:** VITA将潜在图像视为流源，学习从视觉到动作的固有映射。为解决视觉和动作模态之间维度不匹配和动作数据稀疏的问题，VITA通过自编码器创建了一个结构化的动作潜在空间作为流匹配目标，并将原始动作上采样以匹配视觉表示的形状。关键在于，VITA通过流潜在解码，使用编码器目标和最终动作输出共同监督流匹配，将动作重建损失反向传播通过顺序流匹配ODE求解步骤，实现有效的端到端学习。VITA实现为简单的多层感知器（MLP）层。

**Result:** VITA在ALOHA平台上的具有挑战性的双臂操作任务（包括5个模拟任务和2个真实世界任务）上进行了评估。尽管其实现简单，仅使用MLP的VITA在性能上超越或匹配了最先进的生成策略，并且与需要不同条件机制或复杂架构的传统流匹配策略相比，推理延迟降低了50-130%。据作者所知，VITA是第一个能够解决ALOHA基准测试中复杂双臂操作任务的仅MLP流匹配策略。

**Conclusion:** VITA提出了一种新颖且高效的视觉到动作流匹配策略，通过直接将潜在视觉表示映射到潜在动作，简化了生成过程并显著提高了推理效率，同时在复杂双臂操作任务中取得了领先的性能。

> **ai_Abstract:** VITA是一种创新的视觉到动作流匹配策略，旨在简化视觉运动控制。它通过将潜在视觉表示直接作为流的源，学习到潜在动作的映射，从而避免了传统方法中额外的条件机制和相关开销。为解决模态差异和数据稀疏性问题，VITA利用自编码器构建结构化的动作潜在空间，并通过端到端学习，结合编码器目标和最终动作输出对流匹配进行监督。尽管VITA仅由简单的MLP层构成，但在复杂的双臂操作任务中，其性能超越或匹配了现有先进的生成策略，并显著降低了推理延迟。

> **摘要翻译:** 我们提出了VITA，一种视觉到动作的流匹配策略，它将潜在的视觉表示演变为潜在的动作，用于视觉运动控制。传统的流匹配和扩散策略从标准源分布（例如高斯噪声）中采样，并且需要额外的条件机制（如交叉注意力）来根据视觉信息进行动作生成，这会产生时间和空间开销。VITA提出了一种新颖的范式，将潜在图像视为流源，学习从视觉到动作的固有映射，同时消除了独立的条件模块并保留了生成建模能力。在视觉和动作等根本不同模态之间学习流具有挑战性，因为动作数据稀疏，缺乏语义结构，并且高维视觉表示和原始动作之间存在维度不匹配。我们通过自编码器创建一个结构化的动作潜在空间作为流匹配目标来解决这个问题，将原始动作上采样以匹配视觉表示的形状。关键的是，我们通过流潜在解码，使用编码器目标和最终动作输出共同监督流匹配，将动作重建损失反向传播通过顺序流匹配ODE求解步骤，实现有效的端到端学习。VITA实现为简单的MLP层，在ALOHA平台上具有挑战性的双臂操作任务上进行了评估，包括5个模拟任务和2个真实世界任务。尽管其简单，仅使用MLP的VITA在性能上超越或匹配了最先进的生成策略，并且与需要不同条件机制或复杂架构的传统流匹配策略相比，推理延迟降低了50-130%。据我们所知，VITA是第一个能够解决ALOHA基准测试中复杂双臂操作任务的仅MLP流匹配策略。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [478] [Fine-grained Image Retrieval via Dual-Vision Adaptation](https://arxiv.org/abs/2506.16273)
> *基于双视觉适应的细粒度图像检索*

*Xin Jiang, Meiqi Cao, Hao Tang, Fei Shen, Zechao Li* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-17**

**Keywords:** 细粒度图像检索, 双视觉适应, 知识蒸馏, 特征适应, 样本适应

**Comment:** 

> **TL;DR:** 该论文提出了一种双视觉适应（DVA）方法，通过协同样本和特征适应，在不修改预训练模型参数的情况下，提高细粒度图像检索（FGIR）的泛化能力和效率。

**AI_Comments:** 该论文的创新点在于提出了双视觉适应范式，通过样本和特征层面的适应来利用预训练模型的强大能力，同时避免了传统微调带来的过拟合和知识遗忘问题。特别是在不修改预训练参数的情况下进行特征适应，以及通过知识蒸馏平衡效率和性能，都是非常有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 当前的细粒度图像检索（FGIR）解决方案，无论是通过语义嵌入空间中的成对相似性约束还是结合定位子网络进行微调，都容易过拟合训练数据并遗忘大规模预训练获得的知识，从而降低泛化能力。

**Method:** 本文提出了双视觉适应（DVA）方法，通过协同样本和特征适应来指导冻结的预训练模型执行FGIR。具体包括：1. 对象感知适应：修改输入样本以帮助预训练模型感知关键对象和元素。2. 上下文内适应：引入少量参数进行特征适应，而不修改预训练参数。3. 判别感知迁移：使用知识蒸馏机制将对象感知适应中的判别知识迁移到图像编码器，以平衡检索效率和性能。

**Result:** DVA方法具有更少的学习参数，并在三个域内和三个域外细粒度数据集上表现良好。

**Conclusion:** 双视觉适应（DVA）方法通过创新的样本和特征适应策略，有效解决了细粒度图像检索中预训练模型泛化能力下降的问题，并在保持高效的同时实现了优异的性能。

> **ai_Abstract:** 本文针对细粒度图像检索（FGIR）中现有方法易过拟合和泛化能力差的问题，提出了一种双视觉适应（DVA）方法。DVA通过对象感知适应（修改输入样本）和上下文内适应（引入少量参数进行特征适应而不修改预训练模型）协同指导冻结的预训练模型。此外，还引入判别感知迁移以平衡效率和性能。实验证明DVA在多个细粒度数据集上表现出色，且学习参数更少。

> **摘要翻译:** 细粒度图像检索（FGIR）在学习判别性视觉表示以检索具有相似细粒度特征的图像方面面临挑战。当前领先的FGIR解决方案通常遵循两种范式：在语义嵌入空间中强制执行成对相似性约束，或结合定位子网络来微调整个模型。然而，这两种范式都倾向于过拟合训练数据，同时遗忘从大规模预训练中获得的知识，从而降低了它们的泛化能力。在本文中，我们提出了一种用于FGIR的双视觉适应（DVA）方法，该方法通过协同样本和特征适应来指导冻结的预训练模型执行FGIR。具体而言，我们设计了对象感知适应，它修改输入样本以帮助预训练模型感知有助于类别预测的关键对象和对象内的元素。同时，我们提出了上下文内适应，它引入一小组参数进行特征适应，而不修改预训练参数。这使得使用这些调整后的特征进行的FGIR任务更接近于预训练期间解决的任务。此外，为了平衡检索效率和性能，我们提出了判别感知迁移，利用知识蒸馏机制将对象感知适应中的判别知识迁移到图像编码器。大量实验表明，DVA具有更少的学习参数，并在三个域内和三个域外细粒度数据集上表现良好。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [482] [AutoPartGen: Autogressive 3D Part Generation and Discovery](https://arxiv.org/abs/2507.13346)
> *AutoPartGen：自回归三维零件生成与发现*

*Minghao Chen, Jianyuan Wang, Roman Shapovalov, Tom Monnier, Hyunyoung Jung, Dilin Wang, Rakesh Ranjan, Iro Laina, Andrea Vedaldi* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 3D零件生成, 自回归模型, 3DShape2VecSet, 组合式3D重建, 深度学习

**Comment:** Project page: https://silent-chen.github.io/AutoPartGen/

> **TL;DR:** AutoPartGen是一个自回归模型，能够从图像、2D掩码或现有3D对象生成由3D零件组成的物体，并实现最先进的3D零件生成性能。

**AI_Comments:** AutoPartGen的创新之处在于其自回归的3D零件生成方法，以及能够利用3DShape2VecSet潜在空间的组合特性。这种方法使得模型能够自动确定零件的数量和类型，并且生成的零件可以直接无缝组装，大大简化了3D重建和生成过程。其达到SOTA性能也表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在开发一个能够自动生成由3D零件组成的物体，并能从不同输入（图像、2D掩码或现有3D对象）进行组合式3D重建的模型。

**Method:** AutoPartGen是一个自回归模型，它基于3DShape2VecSet这一强大的潜在3D表示。该模型通过预测单个零件，并以先前生成的零件和额外输入（如2D图像、掩码或3D对象）为条件，自回归地生成物体零件。它能自动决定零件的类型和数量，生成的零件可以无缝组装成连贯的物体或场景，无需额外优化。

**Result:** AutoPartGen在3D零件生成方面达到了最先进的性能，并且其生成的零件可以无缝组装成连贯的物体或场景。

**Conclusion:** AutoPartGen模型能够以自回归方式生成由3D零件组成的物体，并从多种输入进行组合式3D重建，其在3D零件生成方面表现出最先进的性能。

> **ai_Abstract:** AutoPartGen是一个创新的自回归模型，专注于3D零件的生成与发现。该模型能够从2D图像、2D掩码或现有3D对象等多种输入，自适应地生成由3D零件组成的物体，并实现组合式3D重建。它利用了3DShape2VecSet潜在空间的强大组合特性，以自回归方式逐个预测零件，并自动确定零件的数量和类型。生成的零件无需额外优化即可无缝组装，该模型在3D零件生成领域达到了最先进的性能。

> **摘要翻译:** 我们引入了AutoPartGen，这是一个以自回归方式生成由三维零件组成的物体的模型。该模型可以接收物体的图像、物体零件的二维掩码或现有的三维物体作为输入，并生成相应的组合式三维重建。我们的方法建立在3DShape2VecSet的基础上，这是一种最近提出的具有强大几何表达能力的潜在三维表示。我们观察到这种潜在空间表现出强大的组合特性，使其特别适合基于零件的生成任务。具体而言，AutoPartGen自回归地生成物体零件，一次预测一个零件，同时以先前生成的零件和额外的输入（如二维图像、掩码或三维物体）为条件。这个过程持续进行，直到模型决定所有零件都已生成，从而自动确定零件的类型和数量。生成的零件可以无缝地组装成连贯的物体或场景，而无需额外的优化。我们评估了AutoPartGen的整体三维生成能力和零件级别的生成质量，证明它在三维零件生成方面达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [485] [FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval](https://arxiv.org/abs/2507.12823)
> *FAR-Net：用于合成图像检索的增强语义对齐和自适应协调的多阶段融合网络*

*Jeong-Woo Park, Young-Eun Kim, Seong-Whan Lee* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 合成图像检索, 多阶段融合, 语义对齐, 自适应协调, 视觉语言任务

**Comment:** 6 pages, 3 figures, 3 tables

> **TL;DR:** FAR-Net通过结合增强语义对齐和自适应协调的多阶段融合，解决了合成图像检索中现有早期/晚期融合方法的不足，并在CIRR和FashionIQ数据集上取得了显著性能提升。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合早期和晚期融合优点的多阶段融合框架FAR-Net，通过互补的ESAM和ARM模块解决了现有方法在语义对齐和鲁棒性方面的局限性。其提出的自适应协调和不确定性嵌入也增加了模型的适应性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的合成图像检索方法在融合视觉和文本模态时，早期融合倾向于过度关注明确提及的文本细节而忽略视觉上下文，而晚期融合则难以捕获图像区域和文本标记之间的细粒度语义对齐。

**Method:** 提出了FAR-Net，一个多阶段融合框架，包含两个互补模块：增强语义对齐模块（ESAM）采用带有交叉注意力的晚期融合来捕获细粒度语义关系；自适应协调模块（ARM）采用带有不确定性嵌入的早期融合来增强鲁棒性和适应性。

**Result:** 在CIRR和FashionIQ数据集上，FAR-Net的性能一致提升，Recall@1最高提升2.4%，Recall@50最高提升1.04%，优于现有最先进方法。

**Conclusion:** FAR-Net为合成图像检索（CIR）任务提供了一个鲁棒且可扩展的解决方案。

> **ai_Abstract:** FAR-Net是一个针对合成图像检索（CIR）任务提出的多阶段融合网络，旨在解决现有早期和晚期融合方法的不足。它通过集成增强语义对齐模块（ESAM）进行细粒度晚期融合和自适应协调模块（ARM）进行鲁棒早期融合，有效结合了两种融合策略的优点。实验证明，FAR-Net在CIRR和FashionIQ数据集上显著提升了检索性能，为CIR任务提供了鲁棒且可扩展的解决方案。

> **摘要翻译:** 合成图像检索（CIR）是一项视觉语言任务，它使用参考图像和修改文本来检索目标图像，从而实现对所需更改的直观指定。虽然有效融合视觉和文本模态至关重要，但现有方法通常采用早期或晚期融合。早期融合倾向于过度关注明确提及的文本细节而忽略视觉上下文，而晚期融合则难以捕获图像区域和文本标记之间的细粒度语义对齐。为了解决这些问题，我们提出了FAR-Net，一个具有增强语义对齐和自适应协调的多阶段融合框架，它集成了两个互补模块。增强语义对齐模块（ESAM）采用带有交叉注意力的晚期融合来捕获细粒度语义关系，而自适应协调模块（ARM）应用带有不确定性嵌入的早期融合来增强鲁棒性和适应性。在CIRR和FashionIQ上的实验显示出一致的性能提升，Recall@1比现有最先进方法提高高达2.4%，Recall@50提高1.04%，经验性地证明FAR-Net为CIR任务提供了一个鲁棒且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [491] [Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection](https://arxiv.org/abs/2507.13061)
> *使用分层核心集选择推进复杂广域场景理解*

*Jingyao Wang, Yiming Chen, Lingyu Si, Changwen Zheng* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 场景理解, 视觉-语言模型, 分层核心集选择, 广域场景, 即插即用

**Comment:** 

> **TL;DR:** 本文提出了一种分层核心集选择（HCS）机制，以提高视觉-语言模型（VLMs）在复杂广域场景理解中的适应性，无需额外微调即可实现快速理解和卓越性能。

**AI_Comments:** 该论文提出HCS机制，其创新之处在于无需额外微调即可提升VLMs在复杂广域场景理解中的适应性，并且是即插即用的，兼容性强。其基于理论保证的重要性函数进行区域选择，具有较高的可靠性。这对于实际应用中快速部署和推广VLM具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉-语言模型（VLMs）推动了计算机视觉领域场景理解的进步，但现有VLMs在适应未见过的复杂广域场景时仍面临挑战。

**Method:** 本文提出了一种分层核心集选择（HCS）机制。该机制基于理论上得到保证的重要性函数（考虑效用、代表性、鲁棒性和协同性）逐步细化所选区域。HCS是一种即插即用的方法，兼容任何VLM，无需额外微调。

**Result:** 实验表明，HCS在各种任务中实现了卓越的性能和普适性。

**Conclusion:** 分层核心集选择（HCS）机制能够有效提升视觉-语言模型在复杂广域场景理解中的适应性，且无需额外微调，展现出优异的性能和普适性。

> **ai_Abstract:** 本文提出了一种分层核心集选择（HCS）机制，旨在解决视觉-语言模型（VLMs）在复杂广域场景理解中的适应性挑战。HCS通过基于理论上得到保证的重要性函数逐步细化区域，使VLMs无需微调即可快速理解未见场景，并缓解特征密度不足。作为一种即插即用的方法，HCS兼容所有VLM，并在实验中展现出卓越的性能和普适性。

> **摘要翻译:** 场景理解是计算机视觉的核心任务之一，旨在从图像中提取语义信息以识别物体、场景类别及其相互关系。尽管视觉-语言模型（VLMs）的进步推动了该领域的发展，但现有VLMs在适应未见过的复杂广域场景时仍面临挑战。为了解决这些挑战，本文提出了一种分层核心集选择（HCS）机制，以推进VLMs在复杂广域场景理解中的适应性。它基于所提出的理论上得到保证的重要性函数（该函数考虑了效用、代表性、鲁棒性和协同性）逐步细化所选区域。HCS无需额外微调，即可使VLM利用最少的可解释区域实现对任何尺度的未见场景的快速理解，同时缓解特征密度不足的问题。HCS是一种即插即用的方法，兼容任何VLM。实验表明，HCS在各种任务中实现了卓越的性能和普适性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [497] [SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning](https://arxiv.org/abs/2507.12845)
> *SEMT：用于遥感图像描述的静态扩展网格Transformer网络架构*

*Khang Truong, Lam Pham, Hieu Tang, Jasmin Lampert, Martin Boyer, Son Phan, Truong Nguyen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 遥感图像描述, Transformer, 静态扩展, 网格Transformer, 记忆增强自注意力

**Comment:** 

> **TL;DR:** 本文提出了一种名为SEMT的基于Transformer的遥感图像描述网络架构，该架构集成了静态扩展、记忆增强自注意力、网格Transformer等技术，并在两个基准数据集上超越了现有SOTA系统。

**AI_Comments:** 这篇论文通过结合多种先进的Transformer技术（如静态扩展、记忆增强自注意力、网格Transformer）来解决遥感图像描述的挑战。其创新性在于针对遥感图像的特点进行结构优化，并在SOTA系统上取得了显著的性能提升，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像描述在解释大量复杂卫星图像方面发挥着重要作用，有助于环境监测、灾害评估和城市规划等应用。因此，作者旨在提出一种新的网络架构来提升遥感图像描述的性能。

**Method:** 作者提出了一种名为SEMT的基于Transformer的网络架构，用于遥感图像描述。该架构评估并集成了静态扩展、记忆增强自注意力、网格Transformer等多种技术。模型在UCM-Caption和NWPU-Caption两个基准遥感图像数据集上进行了评估。

**Result:** 作者提出的最佳模型在大多数评估指标上超越了现有最先进的系统。

**Conclusion:** 该模型在遥感图像描述任务上表现出色，并展示了应用于实际遥感图像系统的潜力。

> **ai_Abstract:** 本文提出了一种名为SEMT的基于Transformer的遥感图像描述网络架构，旨在提升对复杂卫星图像的解释能力，以支持环境监测、灾害评估和城市规划等应用。该架构集成了静态扩展、记忆增强自注意力、网格Transformer等多种先进技术。在UCM-Caption和NWPU-Caption两个基准数据集上的评估结果显示，SEMT模型在多数指标上均优于现有最先进系统，展现了其在实际遥感图像系统中的应用潜力。

> **摘要翻译:** 图像字幕生成已成为计算机视觉和自然语言处理交叉领域的一项关键任务，能够从视觉内容自动生成描述性文本。在遥感领域，图像字幕生成在解释大量复杂卫星图像方面发挥着重要作用，有助于环境监测、灾害评估和城市规划等应用。这促使我们，在本文中，提出了一种基于Transformer的网络架构，用于遥感图像字幕生成（RSIC），其中评估并集成了静态扩展、记忆增强自注意力、网格Transformer等多种技术。我们使用UCM-Caption和NWPU-Caption这两个基准遥感图像数据集评估了我们提出的模型。我们最好的模型在大多数评估指标上超越了最先进的系统，这表明其在实际遥感图像系统中应用的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [499] [Taming Diffusion Transformer for Real-Time Mobile Video Generation](https://arxiv.org/abs/2507.13343)
> *驯服扩散Transformer实现实时移动视频生成*

*Yushu Wu, Yanyu Li, Anil Kag, Ivan Skorokhodov, Willi Menapace, Ke Ma, Arpit Sahni, Ju Hu, Aliaksandr Siarohin, Dhritiman Sagar, Yanzhi Wang, Sergey Tulyakov* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-17**

**Keywords:** 扩散Transformer, 移动视频生成, 实时性能, 模型优化, 剪枝, 知识蒸馏

**Comment:** 9 pages, 4 figures, 5 tables

> **TL;DR:** 提出一系列优化方法，使扩散Transformer能在移动设备上实现实时视频生成。

**AI_Comments:** 本文通过一系列创新性的优化，成功解决了扩散Transformer在移动设备上实现实时视频生成的关键挑战。其贡献在于通过数据压缩、模型剪枝和推理步数蒸馏等多种手段，极大地提升了DiT在资源受限环境下的效率，为移动端AI应用开辟了新的可能性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 扩散Transformer在视频生成方面表现出色但计算成本高，不适用于资源受限的移动设备，实时生成更具挑战性。

**Method:** 1. 采用高度压缩的变分自编码器（VAE）降低输入数据维度。2. 引入KD引导的、敏感度感知的三级剪枝策略缩小模型尺寸。3. 开发针对DiT的对抗性步长蒸馏技术，将推理步数减少到四步。

**Result:** 这些优化使模型在iPhone 16 Pro Max上实现每秒超过10帧的生成速度。

**Conclusion:** 证明了在移动设备上实现实时、高质量视频生成的可能性。

> **ai_Abstract:** 本文针对扩散Transformer在移动设备上进行实时视频生成面临的计算成本高昂问题，提出了一系列优化策略。这些策略包括采用高压缩VAE减少数据维度、引入KD引导的敏感度感知三级剪枝缩小模型，以及开发对抗性步长蒸馏技术减少推理步数。实验结果表明，这些优化使得模型能够在移动设备上实现超过10 FPS的实时高质量视频生成。

> **摘要翻译:** 扩散Transformer（DiT）在视频生成任务中表现出强大的性能，但其高计算成本使其在智能手机等资源受限设备上不切实际，实时生成更具挑战性。在这项工作中，我们提出了一系列新颖的优化方法，以显著加速视频生成并在移动平台上实现实时性能。首先，我们采用高度压缩的变分自编码器（VAE）来降低输入数据的维度，而不会牺牲视觉质量。其次，我们引入了一种KD引导的、敏感度感知的三级剪枝策略，以缩小模型尺寸以适应移动平台，同时保持关键性能特征。第三，我们开发了一种专为DiT量身定制的对抗性步长蒸馏技术，这使我们能够将推理步数减少到四步。结合这些优化，我们的模型能够在iPhone 16 Pro Max上实现每秒超过10帧（FPS）的生成速度，证明了在移动设备上实现实时、高质量视频生成的可行性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [502] [Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose](https://arxiv.org/abs/2506.17858)
> *胎儿建模简化：胎儿形状和姿态的建模与跟踪*

*Yingcheng Liu, Peiqi Wang, Sebastian Diaz, Esra Abaci Turk, Benjamin Billot, P. Ellen Grant, Polina Golland* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 胎儿建模, 姿态跟踪, SMPL, MRI, 产前诊断

**Comment:** 

> **TL;DR:** 本文提出了首个基于SMPL的3D关节式统计胎儿身体模型，用于在MRI中鲁棒地建模和跟踪胎儿的形状和姿态，以改进产前诊断。

**AI_Comments:** 本文的主要创新在于提出了首个3D关节式统计胎儿身体模型，该模型基于成熟的SMPL框架，并针对胎儿MRI数据的特点进行了优化，有效解决了现有方法在形状细节和时间分析上的不足。其能够提高对伪影和不完整观测的鲁棒性，并支持自动化人体测量，这对于产前诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的胎儿MRI分析方法（解剖关键点或体积分段）存在局限性：关键点简化了身体结构但可能忽略全身形状细节；体积分段捕获完整形状信息但由于胎儿大幅非局部运动而使时间分析复杂化。

**Method:** 研究人员构建了一个基于蒙皮多人线性模型（SMPL）的3D关节式统计胎儿身体模型。该算法在图像空间中迭代估计身体姿态，并在规范姿态空间中估计身体形状。模型在来自53名受试者的19,816个体MRI体积中导出的分段和关键点上进行训练。

**Result:** 该模型能够捕获时间序列上的身体形状和运动，提供直观的可视化，并支持传统上难以通过分段和关键点获得的自动化人体测量。在未见过的胎儿身体形状上测试时，该方法在3毫米MRI体素大小下产生了3.2毫米的表面对齐误差。

**Conclusion:** 本文提出了首个3D关节式统计胎儿身体模型，为产前诊断中增强胎儿运动和形状分析铺平了道路。

> **ai_Abstract:** 为了克服现有胎儿MRI分析方法（关键点和体积分段）在处理全身形状细节和时间分析方面的局限性，本文构建了一个基于SMPL的3D关节式统计胎儿身体模型。该模型通过迭代估计图像空间中的姿态和规范姿态空间中的形状，提高了对MRI运动伪影和强度失真的鲁棒性，并减少了不完整表面观测的影响。模型在大量MRI数据上训练，能够有效捕获胎儿形状和运动，提供直观可视化，并实现自动化人体测量。实验结果显示，该方法在未见胎儿形状上实现了3.2毫米的表面对齐误差，为产前诊断中的胎儿运动和形状分析提供了新的工具。

> **摘要翻译:** 分析胎儿身体运动和形状在产前诊断和监测中至关重要。现有的胎儿MRI分析方法主要依赖于解剖关键点或体积分段。关键点简化了身体结构以利于运动分析，但可能忽略全身形状的重要细节。体积分段捕获了完整的形状信息，但由于胎儿大幅非局部运动而使时间分析复杂化。为了解决这些局限性，我们构建了一个基于蒙皮多人线性模型（SMPL）的3D关节式统计胎儿身体模型。我们的算法在图像空间中迭代估计身体姿态，并在规范姿态空间中估计身体形状。这种方法提高了对MRI运动伪影和强度失真的鲁棒性，并减少了由于胎儿姿态困难导致的不完整表面观测的影响。我们在从53名受试者的19,816个体MRI体积中导出的分段和关键点上训练了我们的模型。我们的模型能够捕获时间序列上的身体形状和运动，并提供直观的可视化。此外，它还能够实现传统上难以从分段和关键点中获取的自动化人体测量。在未见过的胎儿身体形状上测试时，我们的方法在3毫米MRI体素大小下产生了3.2毫米的表面对齐误差。据我们所知，这代表了首个3D关节式统计胎儿身体模型，为产前诊断中增强胎儿运动和形状分析铺平了道路。代码可在https://github.com/MedicalVisionGroup/fetal-smpl 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [512] [USIS16K: High-Quality Dataset for Underwater Salient Instance Segmentation](https://arxiv.org/abs/2506.19472)
> *USIS16K：高质量水下显著实例分割数据集*

*Lin Hong, Xin Wang, Yihao Li, Xia Wang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 水下显著实例分割, 数据集, USIS16K, 基准评估

**Comment:** 8 pages 10 figures

> **TL;DR:** 本文介绍了USIS16K，一个大规模、高质量的水下显著实例分割数据集，旨在解决该领域数据稀缺的问题。

**AI_Comments:** 该论文的创新之处在于构建了一个大规模、高质量的水下显著实例分割数据集，这对于数据收集和标注都极具挑战性的水下领域而言意义重大。它直接解决了USIS及相关任务的主要瓶颈（数据稀缺），对推动该领域的研究至关重要。数据集的公开可用性进一步增强了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 水下显著实例分割（USIS）因水下环境的难以接近性和动态性，以及缺乏大规模、高质量的标注数据集而面临未充分探索的挑战。

**Method:** 本文介绍了USIS16K，一个包含16,151张高分辨率水下图像的大规模数据集，这些图像从不同的环境设置中收集，涵盖158类水下物体，并标注了高质量的实例级显著物体掩码。此外，论文还使用USIS16K对水下目标检测和USIS任务进行了基准评估。

**Result:** USIS16K数据集在多样性、复杂性和可扩展性方面取得了显著进展，并提供了水下目标检测和USIS任务的基准评估结果。

**Conclusion:** 本文推出了USIS16K，一个大规模、高质量的水下显著实例分割数据集，通过公开数据集和基准模型，促进了该领域的未来研究。

> **ai_Abstract:** 本文介绍了USIS16K，一个针对水下显著实例分割（USIS）的全新大规模高质量数据集。该数据集包含16,151张高分辨率水下图像，涵盖158类物体，并配有高质量的实例级显著物体掩码，有效解决了现有数据稀缺问题，显著提升了多样性、复杂性和可扩展性。论文还提供了基于USIS16K的水下目标检测和USIS任务的基准评估，并将数据集和模型公开，以促进未来研究。

> **摘要翻译:** 受生物视觉系统选择性分配注意力以有效识别显著物体或区域的启发，水下显著实例分割（USIS）旨在联合解决水下场景中“看哪里”（显著性预测）和“有什么”（实例分割）的问题。然而，由于水下环境的难以接近性和动态性，以及缺乏大规模、高质量的标注数据集，USIS仍然是一个未充分探索的挑战。在本文中，我们介绍了USIS16K，这是一个大规模数据集，包含从不同环境设置中收集的16,151张高分辨率水下图像，涵盖158类水下物体。每张图像都标注了高质量的实例级显著物体掩码，这在多样性、复杂性和可扩展性方面取得了重大进展。此外，我们使用USIS16K对水下目标检测和USIS任务进行了基准评估。为了促进该领域的未来研究，数据集和基准模型已公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [516] [Revisiting Reliability in the Reasoning-based Pose Estimation Benchmark](https://arxiv.org/abs/2507.13314)
> *重新审视基于推理的姿态估计基准的可靠性*

*Junsu Kim, Naeun Kim, Jaeho Lee, Incheol Park, Dongyoon Han, Seungryul Baek* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 姿态估计, 多模态大型语言模型, 基准评估, 可复现性, 地面真实标注

**Comment:** To be presented as a poster at MMFM 2025

> **TL;DR:** 本文指出了基于推理的姿态估计（RPE）基准在复现性和质量方面的问题，包括图像索引不匹配、冗余、场景不平衡等。作者通过人工匹配精炼了GT标注并开源，以提高评估的一致性和可靠性。

**AI_Comments:** 该论文通过识别和解决RPE基准中存在的实际问题（如GT标注获取困难、数据质量缺陷），对姿态感知多模态推理领域做出了重要贡献。其创新之处在于通过人工精炼和开源标注，直接提升了基准的可靠性和可用性，这对于推动该领域的研究进展至关重要。这项工作的重要性在于为研究人员提供了更可靠的评估工具，有助于建立更公平的比较标准。

<details>
  <summary>Details</summary>

**Motivation:** 基于推理的姿态估计（RPE）基准作为姿态感知多模态大型语言模型（MLLMs）的广泛评估标准，存在严重的复现性和基准质量问题，阻碍了公平和一致的定量评估。具体问题包括：基准使用的图像索引与原始3DPW数据集不同，导致手动匹配地面真实（GT）标注的繁琐和错误；以及图像冗余、场景不平衡、姿态过于简单和文本描述模糊等固有的基准质量限制。

**Method:** 为了减轻手动工作并增强可复现性，作者通过细致的视觉匹配精心完善了GT标注。

**Result:** 作者公开了这些完善后的标注作为开源资源，从而促进了定量评估的一致性，并促进了人类姿态感知多模态推理的未来发展。解决了原始基准中图像索引不匹配、图像冗余、场景不平衡、姿态过于简单和文本描述模糊等问题。

**Conclusion:** 通过精炼RPE基准的GT标注并开源，可以显著提高评估的复现性和一致性，从而推动姿态感知多模态推理领域的发展。

> **ai_Abstract:** 本文重新审视了广泛使用的基于推理的姿态估计（RPE）基准，并指出了其在复现性和基准质量方面的严重问题，包括图像索引不匹配、图像冗余、场景不平衡、姿态过于简单和模糊的文本描述。为解决这些问题，作者通过细致的视觉匹配精炼了GT标注，并将其作为开源资源发布，旨在提高定量评估的一致性，并促进姿态感知多模态推理的未来发展。

> **摘要翻译:** 基于推理的姿态估计（RPE）基准已成为姿态感知多模态大型语言模型（MLLM）的广泛采用的评估标准。尽管其意义重大，但我们发现了严重的复现性和基准质量问题，这些问题阻碍了公平和一致的定量评估。最值得注意的是，该基准使用了与原始3DPW数据集不同的图像索引，迫使研究人员进行繁琐且容易出错的手动匹配过程，以获取用于定量指标（例如MPJPE、PA-MPJPE）的准确地面真实（GT）标注。此外，我们的分析揭示了几个固有的基准质量限制，包括显著的图像冗余、场景不平衡、过于简单的姿态以及模糊的文本描述，这些共同削弱了跨不同场景的可靠评估。为了减轻手动工作并增强可复现性，我们通过细致的视觉匹配精心完善了GT标注，并公开发布这些完善后的标注作为开源资源，从而促进了定量评估的一致性，并促进了人类姿态感知多模态推理的未来发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [517] [$π^3$: Scalable Permutation-Equivariant Visual Geometry Learning](https://arxiv.org/abs/2507.13347)
> *$π^3$: 可扩展的置换等变视觉几何学习*

*Yifan Wang, Jianjun Zhou, Haoyi Zhu, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen, Jiangmiao Pang, Chunhua Shen, Tong He* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 视觉几何重建, 置换等变, 相机姿态估计, 深度估计, 点图重建

**Comment:** Project page: https://yyfz.github.io/pi3/

> **TL;DR:** $π^3$是一个无需固定参考视图的置换等变神经网络，用于鲁棒且可扩展的视觉几何重建，并在多项任务上达到SOTA性能。

**AI_Comments:** 该论文的创新点在于提出了一个完全置换等变的神经网络 $π^3$，成功地摆脱了传统视觉几何重建对固定参考视图的依赖，解决了现有方法的稳定性问题。其无偏置设计和对输入顺序的鲁棒性显著提升了模型的实用性和可扩展性，并在多项核心视觉任务上达到了SOTA性能，显示出巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉几何重建方法依赖于固定参考视图，这种归纳偏置可能导致不稳定和失败，尤其当参考视图不佳时。

**Method:** $π^3$采用完全置换等变架构，无需任何参考帧即可预测仿射不变相机姿态和尺度不变局部点图。这种设计使其对输入顺序固有鲁棒且高度可扩展。

**Result:** 在相机姿态估计、单目/视频深度估计和密集点图重建等广泛任务上实现了最先进的性能。

**Conclusion:** $π^3$通过消除对固定参考视图的依赖和采用置换等变架构，提供了一种简单、无偏置、鲁棒且可扩展的视觉几何重建方法，并在多项任务上表现优异。

> **ai_Abstract:** $π^3$ 是一种新型的前馈神经网络，旨在革新视觉几何重建。它通过采用完全置换等变架构，克服了传统方法对固定参考视图的依赖所带来的不稳定性。$π^3$ 能够无需参考帧预测仿射不变的相机姿态和尺度不变的局部点图，从而对输入顺序具有固有的鲁棒性和高度可扩展性。这种简单且无偏置的方法在相机姿态估计、单目/视频深度估计和密集点图重建等任务上取得了最先进的性能。

> **摘要翻译:** 我们引入了 $π^3$，一种前馈神经网络，它为视觉几何重建提供了一种新颖的方法，打破了对传统固定参考视图的依赖。以前的方法通常将其重建锚定到指定的视角，这种归纳偏置可能在参考视图不佳时导致不稳定和失败。相比之下，$π^3$ 采用完全置换等变架构，无需任何参考帧即可预测仿射不变相机姿态和尺度不变局部点图。这种设计使我们的模型对输入顺序固有鲁棒且高度可扩展。这些优势使我们这种简单且无偏置的方法能够在广泛的任务中实现最先进的性能，包括相机姿态估计、单目/视频深度估计和密集点图重建。代码和模型已公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [518] [(Almost) Free Modality Stitching of Foundation Models](https://arxiv.org/abs/2507.10015)
> *(几乎) 免费的基座模型模态拼接*

*Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 基座模型, 模态拼接, 超网络, 多模态, 模型对齐

**Comment:** Pre-print

> **TL;DR:** 现有的多模态模型拼接在模型选择和连接器训练方面计算成本高昂。本文提出Hyma，一种基于超网络的解决方案，可显著降低成本并保持性能。

**AI_Comments:** 这篇论文为多模态AI开发中的一个关键问题（预训练模型组合效率）提供了一种创新方法。通过利用超网络，Hyma显著降低了模型选择和连接器训练的计算负担，这在现有基础模型和大规模数据集不断增长的背景下尤为重要。这有望加速新型多模态系统的开发和部署。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于在大规模网络数据集上训练连接器的复杂性，以及可用预训练单模态模型数量的不断增加，单模态模型选择和随后的连接器模块训练任务变得计算量巨大。

**Method:** 提出超网络模型对齐（Hyma），这是一种新颖的一体化解决方案，通过利用超网络的参数预测能力，为N×M种单模态模型组合获得联合训练的连接器模块，从而同时解决模型选择和连接器训练问题。

**Result:** Hyma将搜索最佳性能单模态模型对的成本降低了10倍，同时在各种多模态基准测试中，其性能排名和训练后的连接器性能与通过网格搜索获得的结果相匹配。

**Conclusion:** Hyma为多模态基础模型拼接提供了一种计算高效且有效的方法，显著简化了单模态模型选择和连接器训练的过程。

> **ai_Abstract:** 本文旨在解决将预训练的单模态模型拼接成多模态基础模型时，在单模态模型选择和连接器模块训练方面的高计算成本问题。为此，文章提出了一种新颖的基于超网络的框架——超网络模型对齐（Hyma），该框架能够同时优化单模态模型选择和连接器训练。实验结果表明，Hyma将搜索成本降低了10倍，同时保持了与传统网格搜索方法相当的性能。

> **摘要翻译:** 基础多模态模型通常通过拼接多个现有预训练的单模态模型来设计：例如，图像分类器与文本模型。这种拼接过程通过训练一个连接器模块来完成，该模块旨在将这些单模态模型的表示空间对齐以实现多模态目标。然而，鉴于在大规模网络数据集上训练此类连接器的复杂性，以及可用预训练单模态模型数量的不断增加，单模态模型选择和随后的连接器模块训练任务变得计算量巨大。为了解决这个未被充分研究的关键问题，我们提出了超网络模型对齐（Hyma），这是一种新颖的一体化解决方案，通过利用超网络实现最佳单模态模型选择和连接器训练。具体来说，我们的框架利用超网络的参数预测能力，为N×M种单模态模型组合获得联合训练的连接器模块。在我们的实验中，Hyma将搜索最佳性能单模态模型对的成本降低了10倍，同时在各种多模态基准测试中，其性能排名和训练后的连接器性能与通过网格搜索获得的结果相匹配。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [519] [FORTRESS: Function-composition Optimized Real-Time Resilient Structural Segmentation via Kolmogorov-Arnold Enhanced Spatial Attention Networks](https://arxiv.org/abs/2507.12675)
> *FORTRESS：通过科尔莫戈洛夫-阿诺德增强空间注意力网络实现函数组合优化实时弹性结构分割*

*Christina Thrainer, Md Meftahul Ferdaus, Mahdi Abdelguerfi, Christian Guetl, Steven Sloan, Kendall N. Niles, Ken Pathak* | **Category: cs.CV, cs.AI, eess.IV** | **Updated: 2025-07-16**

**Keywords:** 结构缺陷分割, 实时, 深度可分离卷积, 科尔莫戈洛夫-阿诺德网络, 计算效率

**Comment:** 

> **TL;DR:** FORTRESS是一种新的深度学习架构，通过结合深度可分离卷积和自适应KAN集成，在保持高精度的同时显著提高了结构缺陷分割的计算效率和推理速度。

**AI_Comments:** FORTRESS的创新之处在于其双重优化策略，巧妙地结合了深度可分离卷积和科尔莫戈洛夫-阿诺德网络（KAN）的自适应集成。这种方法不仅显著减少了模型参数和计算量，还提升了推理速度，同时保持了高精度，这对于实时结构缺陷分割至关重要。其在效率和性能之间的平衡使其在资源受限的实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 土木基础设施中的自动化结构缺陷分割面临在实现高精度的同时保持计算效率以进行实时部署的关键挑战。

**Method:** 本文提出了FORTRESS架构，通过以下三个关键创新来平衡精度和速度：1) 系统化的深度可分离卷积框架，每层参数减少3.6倍；2) 自适应TiKAN集成，仅在计算有利时选择性应用函数组合变换；3) 多尺度注意力融合，结合解码器层级的空间、通道和KAN增强特征。

**Result:** FORTRESS架构实现了显著的效率提升，参数减少91%（从31M到2.9M），计算复杂度减少91%（从13.7到1.17 GFLOPs），推理速度提高3倍，同时提供了卓越的分割性能。在基准基础设施数据集上，F1分数达到0.771，平均IoU达到0.677，显著优于现有方法。

**Conclusion:** 双重优化策略对于实现最佳性能至关重要，使FORTRESS成为资源受限环境中实用结构缺陷分割的强大解决方案，在这些环境中，精度和计算效率都至关重要。

> **ai_Abstract:** FORTRESS是一种新颖的深度学习架构，专为土木基础设施中的实时结构缺陷分割而设计。它通过结合深度可分离卷积框架和自适应科尔莫戈洛夫-阿诺德网络集成，在实现卓越分割性能的同时，显著提升了计算效率和推理速度。该架构在参数、计算复杂度和推理速度方面均实现了大幅优化，并在基准数据集上取得了领先的F1分数和平均IoU，证明了其在资源受限环境中的实用性。

> **摘要翻译:** 土木基础设施中的自动化结构缺陷分割面临一个关键挑战：在实现高精度的同时保持计算效率以进行实时部署。本文提出了FORTRESS（函数组合优化实时弹性结构分割），这是一种新的架构，通过结合深度可分离卷积和自适应科尔莫戈洛夫-阿诺德网络集成来平衡精度和速度。FORTRESS包含了三个关键创新：一个系统的深度可分离卷积框架，实现了每层3.6倍的参数减少；自适应TiKAN集成，仅在计算有利时选择性地应用函数组合变换；以及多尺度注意力融合，结合了解码器层级的空间、通道和KAN增强特征。该架构实现了显著的效率提升，参数减少91%（从31M到2.9M），计算复杂度减少91%（从13.7到1.17 GFLOPs），推理速度提高3倍，同时提供了卓越的分割性能。在基准基础设施数据集上的评估表明，F1分数达到0.771，平均IoU达到0.677，实现了最先进的结果，显著优于包括U-Net、SA-UNet和U-KAN在内的现有方法。双重优化策略被证明对于最佳性能至关重要，使FORTRESS成为资源受限环境中实用结构缺陷分割的强大解决方案，在这些环境中，精度和计算效率都至关重要。完整的架构规范在补充材料中提供。源代码可在URL：https://github.com/faeyelab/fortress-paper-code 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [520] [AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning](https://arxiv.org/abs/2507.12841)
> *AnyCap项目：一个用于可控全模态字幕生成的统一框架、数据集和基准*

*Yiming Ren, Zhiqiang Lin, Yu Li, Gao Meng, Weiyun Wang, Junjie Wang, Zicheng Lin, Jifeng Dai, Yujiu Yang, Wenhai Wang, Ruihang Chu* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 可控字幕生成, 全模态, 统一框架, 数据集, 基准测试

**Comment:** 

> **TL;DR:** AnyCap项目提出了一个统一的框架AnyCapModel（ACM）、数据集AnyCapDataset（ACD）和评估基准AnyCapEval，以解决可控字幕生成中缺乏细粒度控制和可靠评估协议的问题，显著提升了现有基础模型在全模态字幕生成方面的性能。

**AI_Comments:** 这项工作通过提出一个统一的框架、数据集和评估基准，为可控全模态字幕生成领域做出了重要贡献。其创新之处在于ACM的即插即用特性，能够有效提升现有基础模型的能力而无需重新训练，这大大降低了应用门槛。同时，ACD数据集的构建和AnyCapEval的评估方法也填补了当前研究的空白，为未来的研究提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型在可控字幕生成方面缺乏细粒度控制和可靠的评估协议，而可控字幕生成对于精确的多模态对齐和指令遵循至关重要。

**Method:** 该项目提出了一个名为AnyCap Project的集成解决方案，包括：
1. AnyCapModel (ACM)：一个轻量级即插即用框架，无需重新训练基础模型即可增强现有基础模型的可控性，通过结合用户指令和模态特征来改进原始字幕。
2. AnyCapDataset (ACD)：一个包含三种模态、28种用户指令类型和30万高质量数据条目的数据集，旨在解决可控多模态字幕生成中的数据稀缺问题。
3. AnyCapEval：一个新的基准，通过解耦内容准确性和风格保真度，为可控字幕生成提供更可靠的评估指标。

**Result:** AnyCapModel (ACM) 在AnyCapEval上显著提高了各种基础模型的字幕质量。值得注意的是，ACM-8B 将GPT-4o的内容分数提高了45%，风格分数提高了12%。ACM还在MIA-Bench和VidCapBench等广泛使用的基准测试中取得了显著的提升。

**Conclusion:** AnyCap项目通过提供统一的框架、丰富的数据集和可靠的评估基准，有效解决了可控全模态字幕生成中的现有挑战，并显著提升了模型的性能。

> **ai_Abstract:** AnyCap项目提出了一个用于可控全模态字幕生成的统一解决方案，旨在解决现有模型在细粒度控制和评估方面的不足。该项目包含三个核心组件：AnyCapModel (ACM)，一个轻量级即插即用框架，用于增强现有基础模型的可控性；AnyCapDataset (ACD)，一个大规模多模态数据集，用于解决数据稀缺问题；以及AnyCapEval，一个新的评估基准，提供更可靠的度量标准。实验结果表明，ACM显著提升了多种基础模型（包括GPT-4o）的字幕生成质量，并在多个基准测试中表现出色。

> **摘要翻译:** 可控字幕生成对于精确的多模态对齐和指令遵循至关重要，然而现有模型往往缺乏细粒度控制和可靠的评估协议。为了解决这一空白，我们提出了AnyCap项目，一个涵盖模型、数据集和评估的集成解决方案。我们引入了AnyCapModel (ACM)，一个轻量级的即插即用框架，它无需重新训练基础模型即可增强现有基础模型的可控全模态字幕生成能力。ACM 重复使用基础模型的原始字幕，同时结合用户指令和模态特征以生成改进的字幕。为了弥补可控多模态字幕生成中的数据稀缺性，我们构建了AnyCapDataset (ACD)，涵盖三种模态、28种用户指令类型和30万高质量数据条目。我们进一步提出了AnyCapEval，一个新的基准，通过解耦内容准确性和风格保真度，为可控字幕生成提供更可靠的评估指标。ACM 在AnyCapEval上显著提高了各种基础模型的字幕质量。值得注意的是，ACM-8B 将GPT-4o的内容分数提高了45%，风格分数提高了12%，并且它还在MIA-Bench和VidCapBench等广泛使用的基准测试中取得了显著的提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [526] [Label-Consistent Dataset Distillation with Detector-Guided Refinement](https://arxiv.org/abs/2507.13074)
> *基于检测器引导精炼的标签一致性数据集蒸馏*

*Yawen Zou, Guang Li, Zi Wang, Chunzhi Gu, Chao Zhang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 数据集蒸馏, 扩散模型, 标签一致性, 检测器引导, 合成数据

**Comment:** 

> **TL;DR:** 现有数据集蒸馏方法生成的合成数据常有标签不一致或细节不足问题。本文提出一个检测器引导的精炼框架，通过预训练检测器识别并优化异常样本，生成高质量、标签一致的合成数据集，实现了最先进的性能。

**AI_Comments:** 本文的创新点在于引入了一个显式的预训练检测器来指导数据集蒸馏过程中的样本精炼，这直接解决了扩散模型在生成合成数据时常见的标签不一致和细节不足问题。通过这种质量控制机制，能够显著提高合成数据集的可靠性和对下游任务的有效性，为数据集蒸馏领域提供了一个有价值的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型在数据集蒸馏方面取得了显著进展，但生成的替代数据集常常包含标签不一致或结构细节不足的样本，导致下游性能不佳。本文旨在解决这些问题。

**Method:** 本文提出了一个检测器引导的数据集蒸馏框架。具体而言，一个在原始数据集上训练的检测器模型被用来识别表现出标签不匹配或分类置信度低的异常图像。对于每个有缺陷的图像，使用一个预训练的扩散模型，以相应的图像原型和标签为条件，生成多个候选。然后，通过联合考虑检测器的置信度分数和与现有合格合成样本的差异性来选择最佳候选，从而确保标签准确性和类内多样性。

**Result:** 实验结果表明，该方法能够合成具有更丰富细节的高质量代表性图像，并在验证集上取得了最先进的性能。

**Conclusion:** 本文提出的检测器引导精炼框架有效解决了数据集蒸馏中标签不一致和细节不足的问题，从而显著提高了合成数据的质量和下游任务的性能。

> **ai_Abstract:** 数据集蒸馏旨在创建紧凑且高性能的数据集，但当前扩散模型生成的合成数据常存在标签不一致和细节不足问题。本文提出了一种创新的检测器引导数据集蒸馏框架。该框架利用预训练检测器识别并优化异常合成样本，通过生成多个候选并基于检测器置信度和样本多样性选择最优，确保合成数据的标签准确性和高质量细节。实验证明，该方法在验证集上达到了最先进的性能。

> **摘要翻译:** 数据集蒸馏（DD）旨在生成一个紧凑但信息丰富的、能达到与原始数据集相当性能的数据集，从而减少对存储和计算资源的需求。尽管扩散模型在数据集蒸馏方面取得了显著进展，但生成的替代数据集常常包含标签不一致或结构细节不足的样本，导致下游性能不佳。为了解决这些问题，我们提出了一种检测器引导的数据集蒸馏框架，该框架明确利用预训练检测器来识别和精炼异常合成样本，从而确保标签一致性并提高图像质量。具体而言，一个在原始数据集上训练的检测器模型被用来识别表现出标签不匹配或分类置信度低的异常图像。对于每个有缺陷的图像，使用一个预训练的扩散模型，以相应的图像原型和标签为条件，生成多个候选。然后，通过联合考虑检测器的置信度分数和与现有合格合成样本的差异性来选择最佳候选，从而确保标签准确性和类内多样性。实验结果表明，我们的方法能够合成具有更丰富细节的高质量代表性图像，并在验证集上取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [528] [ZIP: Scalable Crowd Counting via Zero-Inflated Poisson Modeling](https://arxiv.org/abs/2506.19955)
> *ZIP：通过零膨胀泊松模型实现可扩展人群计数*

*Yiming Ma, Victor Sanchez, Tanaya Guha* | **Category: cs.CV** | **Updated: 2025-07-16**

**Keywords:** 人群计数, 零膨胀泊松模型, 可扩展性, 稀疏性, 密度图

**Comment:** 15 pages, 11 figures

> **TL;DR:** ZIP提出了一种可扩展的人群计数框架，通过零膨胀泊松模型解决了现有方法中注释空间稀疏性和计数数据不匹配的问题，并在各种模型规模下超越了SOTA方法。

**AI_Comments:** ZIP框架的创新点在于其引入的零膨胀泊松模型，该模型巧妙地解决了人群计数中普遍存在的极端空间稀疏性问题和计数数据离散性与MSE损失不匹配的问题。这种概率建模方法不仅在理论上提供了更紧密的风险界限，而且在实践中展示了在各种模型规模下超越SOTA的强大性能和可扩展性，对于提升人群计数领域的准确性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数人群计数方法使用MSE损失直接回归块密度图，存在两个主要限制：1）无法解释注释的极端空间稀疏性，导致信息区域的监督信号被稀释；2）MSE对应于高斯误差模型，与离散、非负的计数数据不匹配。

**Method:** 本文引入了ZIP框架，通过零膨胀泊松似然对块计数进行建模。其中，零膨胀项学习块结构性为空的概率（处理过多的零），而泊松分量捕获有人存在时的预期计数（尊重离散性）。该方法还提供了泛化分析，表明在训练分辨率适度大的情况下，ZIP的风险界限比基于MSE和DMCount的损失更紧。

**Result:** 在ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd数据集上的实验表明，ZIP在所有模型规模下都持续超越了最先进的方法。

**Conclusion:** ZIP框架通过零膨胀泊松模型有效地解决了人群计数中的稀疏性和数据不匹配问题，并展示了在不同模型规模下的卓越性能和可扩展性。

> **ai_Abstract:** 本文提出ZIP，一种可扩展的人群计数框架，旨在解决现有方法中因MSE损失导致的注释空间稀疏性和计数数据不匹配问题。ZIP采用零膨胀泊松模型，通过零膨胀项处理空块，泊松分量捕获非空块计数，从而更好地适应离散、非负的计数数据。泛化分析显示其风险界限更紧密。实验结果表明，ZIP在多种模型规模和标准基准数据集上均超越了现有最先进的方法，验证了其有效性和可扩展性。

> **摘要翻译:** 大多数人群计数方法使用均方误差（MSE）损失直接回归块密度图。这种做法有两个关键限制：（1）它未能解释注释的极端空间稀疏性——在标准基准测试中，超过95%的8x8块是空的，因此信息区域的监督信号被主要的零稀释了；（2）MSE对应于高斯误差模型，与离散、非负的计数数据匹配不佳。为了解决这些问题，我们引入了ZIP，一个可扩展的人群计数框架，它使用零膨胀泊松似然对块计数进行建模：一个零膨胀项学习块结构性为空的概率（处理过多的零），而泊松分量捕获有人存在时的预期计数（尊重离散性）。我们提供了一个泛化分析，表明在训练分辨率适度大的情况下，ZIP的风险界限比基于MSE的损失和DMCount更紧密。为了评估ZIP的可扩展性，我们在参数/计算量相差100倍以上的骨干网络上对其进行了实例化。在ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd上的实验表明，ZIP在所有模型规模下都持续超越了最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [MMOne: Representing Multiple Modalities in One Scene](https://arxiv.org/abs/2507.11129)
> *MMOne：在一个场景中表示多种模态*

*Zhifeng Gu, Bing Wang* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 多模态表示, 场景表示, 模态冲突, 模态建模, 多模态分解

**Comment:** Accepted to ICCV 2025

> **TL;DR:** MMOne提出了一个通用框架，通过模态建模模块和多模态分解机制来解决多模态表示中的模态冲突问题，实现更紧凑高效的多模态场景表示。

**AI_Comments:** MMOne的创新之处在于其提出的模态建模模块和多模态分解机制，有效解决了多模态表示中的核心挑战——模态冲突。通过解耦共享和模态特定信息，该方法不仅提高了表示效率和紧凑性，还展现了良好的可扩展性，对于未来多模态感知和交互系统的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人类通过多模态线索感知世界，学习多模态场景表示能增强对物理世界的理解。然而，不同模态之间的固有区别导致模态冲突，具体表现为属性差异和粒度差异，这些是当前面临的关键挑战。

**Method:** 我们提出了一个名为MMOne的通用框架来表示一个场景中的多种模态。具体来说，引入了一个带有新颖模态指示器的模态建模模块来捕获每种模态的独特属性。此外，设计了一种多模态分解机制，根据模态差异将多模态高斯分解为单模态高斯，并通过解耦共享和模态特定组件来处理模态间的本质区别。

**Result:** 广泛的实验表明，我们的方法持续增强了每种模态的表示能力，并且可以扩展到额外的模态。

**Conclusion:** MMOne通过解决模态冲突，实现了更紧凑和高效的多模态场景表示，并能有效提升每种模态的表示能力，具有良好的可扩展性。

> **ai_Abstract:** MMOne是一个旨在解决多模态场景表示中模态冲突（包括属性差异和粒度差异）的通用框架。它通过引入模态建模模块（带有新颖的模态指示器）和多模态分解机制，将多模态信息解耦为共享和模态特定组件。实验证明，MMOne能有效增强每种模态的表示能力，并具有良好的可扩展性，从而实现更紧凑和高效的多模态场景表示。

> **摘要翻译:** 人类通过多模态线索感知世界，以理解和与环境互动。学习多模态场景表示能增强对物理世界的理解。然而，源于不同模态固有区别的模态冲突，带来了两个关键挑战：属性差异和粒度差异。为解决这些挑战，我们提出了一个通用框架MMOne，用于在一个场景中表示多种模态，并且可以轻易扩展到额外的模态。具体来说，提出了一个带有新颖模态指示器的模态建模模块，以捕获每种模态的独特属性。此外，我们设计了一种多模态分解机制，根据模态差异将多模态高斯分解为单模态高斯。我们通过将多模态信息解耦为共享和模态特定组件来解决模态间的本质区别，从而实现更紧凑和高效的多模态场景表示。广泛的实验表明，我们的方法持续增强了每种模态的表示能力，并且可以扩展到额外的模态。代码已在https://github.com/Neal2020GitHub/MMOne 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [543] [PhenoBench: A Comprehensive Benchmark for Cell Phenotyping](https://arxiv.org/abs/2507.03532)
> *PhenoBench: 一个全面的细胞表型基准测试*

*Nora Koreuber, Jannik Franzen, Fabian H. Reith, Claudia Winklmayr, Jerome Luescher, Elias Baumann, Christian M. Schuerch, Dagmar Kainmueller, Josef Lorenz Rumberger* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 细胞表型分析, 基准测试, 数字病理学, 基础模型, H&E图像, PhenoCell

**Comment:** accepted for presentation at MICCAI 2025

> **TL;DR:** 本文提出了 PhenoBench，一个针对苏木精和伊红 (H&E) 染色组织病理学图像上细胞表型分析的综合基准测试。它包含新的 PhenoCell 数据集和配套代码，并揭示现有基础模型在该更具挑战性任务上的表现远低于先前基准测试的水平。

**AI_Comments:** 本文通过提供一个更具挑战性和综合性的细胞表型基准测试，弥补了数字病理学领域的一个关键空白。现有基础模型在 PhenoCell 上的显著性能下降，突显了当前模型的局限性以及未来研究的必要性，使 PhenoCell 成为社区的宝贵资源。新数据集和即用代码的包含增强了其实用性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 数字病理学领域的基础模型（FM）尚未在细胞表型分析方面进行统一的性能基准测试。现有基准可能未能充分捕捉该任务的复杂性和挑战性。

**Method:** 提出了 PhenoBench，一个全面的细胞表型分析基准，包含 PhenoCell 数据集（一个包含通过多重成像识别的14种细粒度细胞类型的新H&E数据集），并提供即用型微调和基准测试代码。研究者系统地评估了多个著名的病理学基础模型，分析了它们在技术和医学领域转移下的泛化行为。

**Result:** 现有基础模型在 Lizard 和 PanNuke 等已建立的基准测试中宏观 F1 分数超过 0.70。然而，在 PhenoCell 数据集上，这些模型的得分低至 0.20。这表明 PhenoCell 提出了一个更具挑战性的任务，是之前基准测试未涵盖的。

**Conclusion:** PhenoCell 被确立为未来基础模型和监督模型在细胞表型分析领域进行基准测试的重要资产，突显了当前基础模型在此类复杂任务上的局限性。

> **ai_Abstract:** 本文介绍了 PhenoBench，一个针对 H&E 染色组织病理学图像上细胞表型分析的全新综合基准。该基准包含 PhenoCell，一个具有 14 种详细细胞类型的新数据集，以及用于评估基础模型（FM）的配套代码。研究发现，虽然 FM 在现有基准测试中表现良好，但在 PhenoCell 上的性能显著下降（F1 分数低至 0.20），这表明 PhenoCell 为数字病理学未来模型评估提供了一项更具挑战性和真实性的任务。

> **摘要翻译:** 数字病理学见证了大量基础模型（FM）的出现，但迄今为止，它们在细胞表型分析方面的性能尚未得到统一的基准测试。因此，我们提出了 PhenoBench：一个针对苏木精和伊红（H&E）染色组织病理学图像上细胞表型分析的综合基准。我们提供了 PhenoCell，这是一个新的 H&E 数据集，其中包含通过多重成像识别的 14 种粒状细胞类型，以及即用型微调和基准测试代码，允许在不同泛化场景中系统评估多个著名病理学 FM 在密集细胞表型预测方面的性能。我们对现有 FM 进行了广泛的基准测试，深入了解了它们在技术领域与医学领域转移下的泛化行为。此外，虽然 FM 在 Lizard 和 PanNuke 等先前建立的基准测试中达到了 > 0.70 的宏观 F1 分数，但在 PhenoCell 上，我们观察到分数低至 0.20。这表明这是一项更具挑战性的任务，未被之前的基准测试所涵盖，从而确立了 PhenoCell 作为未来 FM 和监督模型基准测试的主要资产。代码和数据可在 GitHub 上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [548] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
> *站点级微调与渐进层冻结：在极早产儿出生第一天胸部X光片中稳健预测支气管肺发育不良*

*Sybelle Goedicke-Fritz, Michelle Bous, Annika Engel, Matthias Flotho, Pascal Hirsch, Hannah Wittig, Dino Milanovic, Dominik Mohr, Mathias Kaspar, Sogand Nemat, Dorothea Kerner, Arno Bücker, Andreas Keller, Sascha Meyer, Michael Zemlin, Philipp Flotho* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 支气管肺发育不良, 深度学习, 胸部X光片, 渐进层冻结, 领域特定预训练

**Comment:** S.G.-F., M.B., and A.E. contributed equally to this work and share
  first authorship. M.Z. and P.F. contributed equally to this work and share
  senior authorship

> **TL;DR:** 本研究开发并评估了一种基于深度学习的方法，利用出生第一天的胸部X光片预测极早产儿的支气管肺发育不良（BPD），通过站点级微调和渐进层冻结实现了准确且计算可行的预测。

**AI_Comments:** 该论文的创新点在于将深度学习应用于极早产儿出生第一天的胸部X光片，以早期预测支气管肺发育不良，这对于临床决策具有重要意义。特别是采用了渐进层冻结和领域特定预训练，有效提高了模型性能并防止了过拟合，同时保持了计算可行性。这为未来在多中心、联邦学习环境下部署此类预测模型奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 支气管肺发育不良（BPD）是一种影响极低出生体重婴儿的慢性肺病，会导致终生呼吸并发症。然而，预防性干预措施存在严重的风险。因此，早期预测BPD结果对于避免低风险婴儿不必要的毒性至关重要，而出生第一天的胸部X光片可作为无创预后工具。

**Method:** 本研究开发并调查了一种深度学习方法，使用了163名极低出生体重婴儿（胎龄≤32周，体重401-999克）出生后24小时内获得的胸部X光片。研究人员对专门在成人胸部X光片上预训练的ResNet-50模型进行了微调，采用了渐进层冻结和判别性学习率以防止过拟合，并评估了CutMix数据增强和线性探测。模型用于预测中度/重度BPD结果。

**Result:** 在预测中度/重度BPD结果方面，采用渐进冻结、线性探测和CutMix的最佳模型实现了0.78 ± 0.10的AUROC，0.69 ± 0.10的平衡准确率，以及0.67 ± 0.11的F1分数。领域内预训练显著优于ImageNet初始化（p = 0.031）。常规IRDS等级的预后价值有限（AUROC 0.57 ± 0.11）。

**Conclusion:** 本研究表明，领域特定预训练能够通过常规出生第一天的胸部X光片准确预测支气管肺发育不良。通过渐进层冻结和线性探测，该方法在计算上对于站点级实施和未来的联邦学习部署是可行的。

> **ai_Abstract:** 本研究提出了一种基于深度学习的方法，利用极早产儿出生第一天的胸部X光片预测支气管肺发育不良（BPD）。通过对在成人胸部X光片上预训练的ResNet-50模型进行微调，并结合渐进层冻结、判别性学习率、CutMix增强和线性探测，该方法实现了对中度/重度BPD的准确预测（AUROC 0.78）。研究结果强调了领域特定预训练的重要性，并证明该方法在计算上可行，适用于站点级和联邦学习部署。

> **摘要翻译:** 支气管肺发育不良（BPD）是一种慢性肺病，影响35%的极低出生体重婴儿。它定义为在矫正胎龄36周时仍需要吸氧，并导致终生呼吸并发症。然而，预防性干预措施具有严重的风险，包括神经发育障碍、呼吸机诱导的肺损伤和全身并发症。因此，早期BPD预后和BPD结果预测对于避免低风险婴儿不必要的毒性至关重要。极早产儿在出生24小时内常规获取的入院X光片可作为一种无创的预后工具。在这项工作中，我们开发并研究了一种深度学习方法，使用了163名极低出生体重婴儿（胎龄≤32周，体重401-999克）出生后24小时内获得的胸部X光片。我们对专门在成人胸部X光片上预训练的ResNet-50模型进行了微调，采用了渐进层冻结和判别性学习率以防止过拟合，并评估了CutMix数据增强和线性探测。对于中度/重度BPD结果预测，我们采用渐进冻结、线性探测和CutMix的最佳模型实现了0.78 ± 0.10的AUROC，0.69 ± 0.10的平衡准确率，以及0.67 ± 0.11的F1分数。领域内预训练显著优于ImageNet初始化（p = 0.031），这证实了领域特定预训练对于BPD结果预测的重要性。常规IRDS等级的预后价值有限（AUROC 0.57 ± 0.11），证实了需要学习标记物。我们的方法表明，领域特定预训练能够通过常规出生第一天的X光片准确预测BPD。通过渐进冻结和线性探测，该方法在计算上对于站点级实施和未来的联邦学习部署仍然是可行的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [550] [Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization](https://arxiv.org/abs/2507.12851)
> *模拟、重新聚焦和集成：一种用于域泛化的注意力重新聚焦方案*

*Ziyi Wang, Zhi Gao, Jin Chen, Qingjie Zhao, Xinxiao Wu, Jiebo Luo* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 域泛化, CLIP, 注意力重新聚焦, 域不变性, 集成学习

**Comment:** \c{opyright} 20XX IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works

> **TL;DR:** 本文提出了一种名为SRE的注意力重新聚焦方案，通过模拟域偏移、重新聚焦CLIP的注意力以及集成学习来提高域泛化性能。

**AI_Comments:** 这项工作创新性地将模拟域偏移、CLIP注意力重新聚焦和集成学习结合起来，以解决域泛化中CLIP的注意力偏差问题。其核心思想在于通过主动模拟和对齐注意力图来提升模型的域不变性，这对于利用大型预训练模型进行跨域泛化具有重要意义。该方法通过系统性的步骤提升了域泛化性能，为未来相关研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 域泛化（DG）旨在学习一个模型并应用于未见过的目标域数据，但现有的CLIP模型在跨域时难以聚焦于任务相关（域不变）区域，导致在未见目标域上的性能不佳。

**Method:** SRE方案通过以下步骤减少域偏移：1. 模拟域偏移：对源数据进行增强以生成模拟目标域。2. 重新聚焦注意力：学习通过对齐CLIP在源域和模拟目标域之间的注意力图来减少域偏移。3. 集成学习：利用集成学习增强捕获源数据和模拟目标数据之间域不变注意力图的能力。

**Result:** 在多个数据集上的大量实验结果表明，SRE通常比最先进的方法取得了更好的结果。

**Conclusion:** SRE方案通过其独特的模拟、重新聚焦和集成策略，有效地解决了CLIP在域泛化中注意力难以聚焦于域不变区域的问题，并显著提升了模型的泛化性能。

> **ai_Abstract:** 本文提出了一种名为SRE（模拟、重新聚焦和集成）的注意力重新聚焦方案，旨在解决域泛化中CLIP模型难以聚焦于域不变区域的问题。SRE通过首先模拟域偏移，然后重新聚焦CLIP在源域和模拟目标域之间的注意力图，最后利用集成学习来增强域不变特征的捕获能力，从而有效减少域偏移。实验证明，SRE在多个数据集上优于现有最先进的方法。

> **摘要翻译:** 域泛化（DG）旨在从源域学习一个模型，并将其应用于具有分布外数据的未见目标域。由于CLIP强大的语义概念编码能力，它在域泛化领域引起了越来越多的兴趣。然而，CLIP通常难以跨域聚焦于任务相关区域，即域不变区域，导致在未见目标域上的性能不佳。为了解决这一挑战，我们提出了一种注意力重新聚焦方案，称为模拟、重新聚焦和集成（SRE），它通过注意力重新聚焦来对齐CLIP中的注意力图，从而学习减少域偏移。SRE首先通过对源数据进行增强来生成模拟目标域，从而模拟域偏移。然后，SRE学习通过重新聚焦CLIP在源域和模拟目标域之间的注意力来减少域偏移。最后，SRE利用集成学习来增强捕获源数据和模拟目标数据之间域不变注意力图的能力。在多个数据集上的大量实验结果表明，SRE通常比最先进的方法取得了更好的结果。代码可在：https://github.com/bitPrincy/SRE-DG 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [552] [Hierarchical Rectified Flow Matching with Mini-Batch Couplings](https://arxiv.org/abs/2507.13350)
> *分层纠正流匹配与小批量耦合*

*Yichi Zhang, Yici Yan, Alex Schwing, Zhizhen Zhao* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 流匹配, 分层模型, 小批量耦合, 生成模型, 多模态分布

**Comment:** Project Page: https://riccizz.github.io/HRF_coupling

> **TL;DR:** 本文研究了如何通过小批量耦合在分层纠正流匹配中逐步调整不同层级分布的复杂性，并在合成数据和图像数据上展示了其优势。

**AI_Comments:** 本文的创新点在于引入小批量耦合来解决分层流匹配中各层级分布复杂性不变的问题。通过允许复杂性在层次结构中逐步调整，该方法有望提升模型在处理复杂多模态数据时的灵活性和性能。这对于生成建模领域是一个重要的改进。

<details>
  <summary>Details</summary>

**Motivation:** 尽管分层流匹配能够建模多模态速度分布，但其建模分布的复杂性在层次结构的不同层级上保持不变，这限制了其在处理复杂分布时的灵活性。

**Method:** 通过引入小批量耦合，该研究旨在逐步调整分层纠正流匹配中不同层次分布的复杂性。

**Result:** 研究结果表明，小批量耦合在分层纠正流匹配中具有显著优势，并在合成数据和图像数据上取得了令人信服的效果。

**Conclusion:** 小批量耦合能够有效地调整分层纠正流匹配中不同层次分布的复杂性，从而提升了模型在处理复杂数据时的性能。

> **ai_Abstract:** 流匹配是一种重要的生成建模方法。为了更好地捕捉速度场中固有的多模态性，最近引入了分层流匹配。然而，在分层流匹配中，建模分布的复杂性在层次结构的不同层级上保持一致。本文通过引入小批量耦合，研究了如何在分层纠正流匹配中逐步调整不同层级分布的复杂性。研究结果在合成数据和图像数据上展示了小批量耦合的优势。

> **摘要翻译:** 流匹配作为一种引人注目的生成建模方法，已广泛应用于各个领域。通过流匹配模型生成数据时，需要通过对建模速度场进行正向积分来数值求解常微分方程（ODE）。为了更好地捕捉典型速度场中固有的多模态性，最近引入了分层流匹配。它使用一个ODE层次结构，在生成数据时进行数值积分。这种ODE层次结构能够像香草流匹配建模多模态数据分布一样，捕捉多模态速度分布。虽然这种层次结构能够建模多模态速度分布，但建模分布的复杂性在层次结构的不同层级上保持不变。在本文中，我们研究了如何通过小批量耦合逐步调整层次结构不同层级分布的复杂性。我们通过在合成数据和图像数据上的令人信服的结果，展示了小批量耦合在分层纠正流匹配中的优势。代码可在https://riccizz.github.io/HRF_coupling 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [555] [Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models](https://arxiv.org/abs/2507.12916)
> *Argus：利用多视角图像改进大型语言模型的3D场景理解*

*Yifan Xu, Chao Zhang, Hanqi Jiang, Xiaoyan Wang, Ruifei Ma, Yiwei Li, Zihao Wu, Zeju Li, Xiangde Liu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 3D场景理解, 大型语言模型, 多模态融合, 多视角图像, 3D点云

**Comment:** Accepted by TNNLS2025

> **TL;DR:** Argus是一个新的3D多模态框架，通过整合多视角图像和3D点云，弥补了现有3D点云重建的信息丢失问题，从而增强了大型语言模型在3D场景理解任务中的能力，并在多项下游任务中表现优异。

**AI_Comments:** Argus的创新之处在于其有效地结合了多视角图像来补充3D点云的不足，为大型语言模型提供了更丰富和准确的3D场景信息。这种多模态融合的方法对于提升LLMs在现实世界3D任务中的应用潜力具有重要意义。它弥补了现有方法在处理无纹理区域和复杂结构时的缺陷，提供了一种更鲁棒的3D理解方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前将大型语言模型（LLMs）应用于3D场景理解的方法严重依赖3D点云，但室内场景的3D点云重建常导致信息丢失，例如无纹理平面或重复模式的遗漏，以及复杂结构物体因图像与点云未对齐导致的细节失真。2D多视角图像与3D点云具有视觉一致性，并能提供更详细的场景组件表示，可以弥补这些缺陷。

**Method:** 本文提出了Argus，一个新颖的3D多模态框架，它利用多视角图像来增强LLMs的3D场景理解能力。Argus作为一个3D大型多模态基础模型（3D-LMM），接受文本指令、2D多视角图像和3D点云作为输入。其核心是将多视角图像和相机姿态融合并整合为“视图即场景”特征，这些特征与3D特征交互，从而创建全面且详细的3D感知场景嵌入，以弥补3D点云重建中的信息丢失。

**Result:** 实验结果表明，Argus方法在各种下游任务中优于现有的3D-LMM。

**Conclusion:** Argus框架通过有效地整合多视角图像和3D点云，克服了现有3D点云重建的局限性，显著提高了大型语言模型在3D场景理解任务中的性能。

> **ai_Abstract:** Argus是一个创新的3D多模态框架，旨在提升大型语言模型（LLMs）在3D场景理解方面的能力。针对当前方法过度依赖易导致信息丢失和细节失真的3D点云的问题，Argus通过整合2D多视角图像和相机姿态，将其转化为“视图即场景”特征，并与3D特征融合，生成更全面、更精细的3D感知场景嵌入。该框架作为一个3D大型多模态基础模型（3D-LMM），能够处理文本指令、2D图像和3D点云，有效弥补了点云重建的不足。实验证明，Argus在多项下游任务中表现优于现有3D-LMM。

> **摘要翻译:** 基础模型的进步使得在各种下游任务中开展应用成为可能。特别是，新时代见证了大型语言模型（LLMs）在解决3D场景理解任务方面的卓越能力。当前的方法严重依赖3D点云，但室内场景的3D点云重建常常导致信息丢失。一些无纹理平面或重复模式容易被遗漏，并在重建的3D点云中表现为空洞。此外，具有复杂结构的物体往往会因为捕获图像与密集重建点云之间的未对齐而导致细节失真。2D多视角图像与3D点云呈现视觉一致性，并提供更详细的场景组件表示，这自然可以弥补这些缺陷。基于这些见解，我们提出了Argus，一个新颖的3D多模态框架，它利用多视角图像来增强LLMs的3D场景理解。总的来说，Argus可以被视为一个3D大型多模态基础模型（3D-LMM），因为它接受各种模态作为输入（文本指令、2D多视角图像和3D点云），并扩展了LLMs处理3D任务的能力。Argus涉及将多视角图像和相机姿态融合并整合为“视图即场景”特征，这些特征与3D特征交互，从而创建全面且详细的3D感知场景嵌入。我们的方法弥补了重建3D点云时的信息丢失，并帮助LLMs更好地理解3D世界。广泛的实验表明，我们的方法在各种下游任务中优于现有的3D-LMM。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [558] [4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion](https://arxiv.org/abs/2507.09953)
> *4D-MISR：一种通过特征融合实现低剂量超分辨率成像的统一模型*

*Zifei Wang, Zian Mao, Xiaoya He, Xi Huang, Haoran Zhang, Chun Cheng, Shufen Chu, Tingzheng Hou, Xiaoqin Zeng, Yujun Xie* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 超分辨率成像, 电子显微镜, 辐射损伤, 深度学习, 4D-STEM

**Comment:** 

> **TL;DR:** 4D-MISR提出了一种通过特征融合实现低剂量超分辨率成像的统一模型，克服了电子显微镜对束敏感材料的辐射损伤限制。

**AI_Comments:** 该论文的创新点在于将遥感领域的多图像超分辨率（MISR）原理引入到电子显微镜领域，以解决束敏感材料的辐射损伤问题。通过结合多视图融合和先进的深度学习（双路径注意力引导CNN），实现了在超低剂量下的原子级分辨率成像，这对于材料科学和生物学等领域具有重要意义。其通用性和对不同材料的适用性是其突出优势。

<details>
  <summary>Details</summary>

**Motivation:** 电子显微镜在束敏感材料（如蛋白质和二维材料）上的使用受到辐射损伤的严重限制，阻碍了对结构-性能关系的原子分辨率洞察。该研究旨在突破传统电子显微镜的电子剂量限制。

**Method:** 该方法借鉴了遥感中广泛使用的多图像超分辨率（MISR）原理，融合了多个低分辨率、亚像素偏移的视图。通过一个卷积神经网络（CNN）增强重建，该网络集成了来自合成、多角度观测的特征。研究开发了一个用于4D-STEM的双路径、注意力引导网络。

**Result:** 该方法从超低剂量数据中实现了原子尺度的超分辨率成像。它为非晶态、半晶态和晶态束敏感样品提供了鲁棒的原子尺度可视化。在超低剂量条件下，系统评估表明其空间分辨率与传统相干衍射成像（ptyography）相当。

**Conclusion:** 该工作扩展了4D-STEM的能力，为辐射敏感材料的结构分析提供了一种新的、可推广的方法。

> **ai_Abstract:** 本研究提出了一种名为4D-MISR的统一模型，旨在克服电子显微镜在束敏感材料上因辐射损伤导致的限制。通过借鉴遥感中的多图像超分辨率（MISR）原理，该模型融合了多个低分辨率、亚像素偏移的图像，并利用一个双路径、注意力引导的卷积神经网络（CNN）进行特征融合和重建。实验证明，该方法能从超低剂量数据中实现原子尺度的超分辨率成像，并为不同状态的束敏感样品提供鲁棒的原子级可视化，其分辨率可与传统相干衍射成像媲美。这项工作显著扩展了4D-STEM的应用范围，为辐射敏感材料的结构分析提供了一种通用且有效的新途径。

> **摘要翻译:** 虽然电子显微镜为结构-性能关系提供了关键的原子分辨率见解，但辐射损伤严重限制了其在蛋白质和二维材料等束敏感材料上的使用。为了克服这一挑战，我们通过调整多图像超分辨率（MISR）的原理，突破了传统电子显微镜的电子剂量限制，该原理已广泛应用于遥感。我们的方法融合了多个低分辨率、亚像素偏移的视图，并通过一个卷积神经网络（CNN）增强了重建，该网络集成了来自合成、多角度观测的特征。我们开发了一个用于4D-STEM的双路径、注意力引导网络，该网络能够从超低剂量数据中实现原子尺度的超分辨率。这为非晶态、半晶态和晶态束敏感样品提供了鲁棒的原子尺度可视化。对代表性材料的系统评估表明，在超低剂量条件下，其空间分辨率与传统相干衍射成像（ptyography）相当。我们的工作扩展了4D-STEM的能力，为辐射敏感材料的结构分析提供了一种新的、可推广的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [561] [Channel-wise Motion Features for Efficient Motion Segmentation](https://arxiv.org/abs/2507.13082)
> *用于高效运动分割的通道感知运动特征*

*Riku Inoue, Masamitsu Tsuchiya, Yuji Yasui* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 运动分割, 实时, 通道感知运动特征, 效率, 自动驾驶

**Comment:** This paper has been accepted to IROS 2024 (Abu Dhabi, UAE), October
  14-18, 2024

> **TL;DR:** 该论文提出了一种名为“通道感知运动特征”的新型运动特征表示，用于运动分割，在保持同等精度的同时，显著提高了实时性能并减少了模型参数。

**AI_Comments:** 本文的创新点在于其提出的通道感知运动特征，通过仅依赖姿态网络而非多个复杂的子网络（如深度、光流等），极大地简化了运动分割的计算流程。这种方法在保证精度的前提下，显著提升了推理速度和模型效率，对于自动驾驶等对实时性要求极高的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在自动驾驶等安全关键型机器人应用中，需要实时准确地检测所有所需物体。运动分割通过以类别无关的方式识别场景中的动态物体提供了一种解决方案。然而，现有的大多数运动分割模型共同使用多个子网络（如深度、姿态、光流和场景流），导致整体计算成本增加，阻碍了实时性能。

**Method:** 本文提出了一种新颖的基于成本体（cost-volume-based）的运动特征表示，即通道感知运动特征（Channel-wise Motion Features）。它通过从特征图中提取每个实例的深度特征并捕获场景的3D运动信息来提高效率。构建通道感知运动特征仅需使用姿态网络（Pose Network），无需其他子网络。

**Result:** 在KITTI数据集和VCAS-Motion数据集的Cityscapes上，本文方法达到了最先进模型约4倍的FPS，同时展现了同等的精度，并将参数量减少到约25%。

**Conclusion:** 本文提出的通道感知运动特征方法在运动分割任务中显著提高了实时性能和计算效率（减少了参数），同时保持了与最先进方法相当的精度，有效解决了实时应用中的计算瓶颈。

> **ai_Abstract:** 该论文针对现有运动分割模型计算成本高、难以实时运行的问题，提出了一种名为“通道感知运动特征”的新型运动特征表示。该方法采用基于成本体的方式，通过提取实例深度特征和3D运动信息，并仅依赖姿态网络，显著简化了模型结构。实验结果表明，与现有最先进模型相比，该方法在KITTI和Cityscapes数据集上实现了约4倍的帧率提升，同时模型参数量减少了约75%，且精度保持不变，有效解决了实时运动分割的效率瓶颈。

> **摘要翻译:** 对于自动驾驶等安全关键型机器人应用，实时准确地检测所有所需物体非常重要。运动分割通过以类别无关的方式识别场景中的动态物体提供了一种解决方案。最近，各种运动分割模型被提出，其中大多数模型共同使用子网络来估计深度、姿态、光流和场景流。结果，模型的整体计算成本增加，阻碍了实时性能。
在本文中，我们提出了一种新颖的基于成本体的运动特征表示，即通道感知运动特征。通过从特征图中提取每个实例的深度特征并捕获场景的3D运动信息，它提供了增强的效率。构建通道感知运动特征所需的唯一子网络是姿态网络，不需要其他子网络。我们的方法不仅在KITTI数据集和VCAS-Motion数据集的Cityscapes上达到了最先进模型约4倍的FPS，而且在将参数减少到约25%的同时，也展现了同等的精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
> *组合式离散潜在编码用于高保真、高效的扩散模型*

*Samuel Lavoie, Michael Noukhovitch, Aaron Courville* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 扩散模型, 离散潜在编码, 图像生成, 自监督学习, 文本到图像

**Comment:** In submission, 22 pages, 7 tables, 12 figures

> **TL;DR:** 本文引入离散潜在编码（DLC），一种基于自监督学习的离散令牌序列，用于条件扩散模型。DLC提高了图像生成保真度，实现了新的SOTA，并支持组合式OOD样本生成和文本到图像生成。

**AI_Comments:** 本文的创新点在于提出了离散潜在编码（DLC），它将图像表示从连续形式转化为离散令牌序列，并强调其组合性。这种方法不仅提升了扩散模型的生成保真度（达到ImageNet SOTA），更重要的是，它通过组合性实现了训练外样本的生成（OOD样本），并能与大型语言模型结合实现文本到图像生成，极大地扩展了扩散模型的潜能和应用场景，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在复杂分布建模上的成功主要归因于输入条件作用。理想的表示应能提高样本保真度、易于生成且具有组合性，以实现训练外样本生成。本文旨在探索满足这些特性的表示。

**Method:** 引入离散潜在编码（DLC），这是一种从通过自监督学习目标训练的Simplicial Embeddings派生的图像表示。DLC是离散令牌序列，与传统的连续图像嵌入不同。通过微调文本扩散语言模型生成DLC，从而实现文本到图像生成。

**Result:** 1. 使用DLC训练的扩散模型提高了生成保真度，在ImageNet上的无条件图像生成方面建立了新的SOTA。2. 组合DLC可以使图像生成器生成连贯地结合各种图像语义的分布外样本。3. DLC能够通过利用大规模预训练语言模型实现文本到图像生成。

**Conclusion:** 离散潜在编码（DLC）是一种有效的图像表示，它显著提升了扩散模型的生成能力，包括保真度、OOD样本生成和文本到图像生成，证明了离散、组合式表示的优越性。

> **ai_Abstract:** 本文提出离散潜在编码（DLC）作为扩散模型的一种新型图像表示，旨在解决现有条件表示的局限性。DLC是一种通过自监督学习从Simplicial Embeddings获得的离散令牌序列，与传统连续嵌入不同。实验证明，DLC显著提升了扩散模型的生成保真度，在ImageNet无条件图像生成上达到SOTA。其组合性使得能够生成训练分布之外的语义连贯的图像。此外，DLC通过与大型预训练语言模型结合，实现了高效的文本到图像生成，扩展了扩散模型的应用范围。

> **摘要翻译:** 我们认为，扩散模型在建模复杂分布方面的成功，在很大程度上归因于其输入条件作用。本文从理想表示应能提高样本保真度、易于生成且具有组合性以允许训练外样本生成的角度，研究了用于条件作用扩散模型的表示。我们引入了离散潜在编码（DLC），这是一种从通过自监督学习目标训练的Simplicial Embeddings派生的图像表示。DLC是离散令牌序列，与标准的连续图像嵌入不同。它们易于生成，并且其组合性使得能够生成训练分布之外的新颖图像。使用DLC训练的扩散模型提高了生成保真度，在ImageNet上的无条件图像生成方面建立了新的最先进水平。此外，我们展示了组合DLC允许图像生成器生成连贯地结合各种图像语义的分布外样本。最后，我们展示了DLC如何通过利用大规模预训练语言模型实现文本到图像生成。我们有效地微调了一个文本扩散语言模型，以生成DLC，从而产生图像生成器训练分布之外的新颖样本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [564] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
> *NeuraLeaf：具有形状和变形解耦的神经参数叶片模型*

*Yang Yang, Dongni Mao, Hiroaki Santo, Yasuyuki Matsushita, Fumio Okura* | **Category: cs.CV, cs.GR** | **Updated: 2025-07-17**

**Keywords:** 神经参数模型, 叶片建模, 形状解耦, 变形, DeformLeaf

**Comment:** IEEE/CVF International Conference on Computer Vision (ICCV 2025),
  Project: https://neuraleaf-yang.github.io/

> **TL;DR:** NeuraLeaf是一个新的神经参数模型，能将叶片几何形状解耦为2D基形和3D变形，用于植物建模和重建，并能准确拟合3D数据。

**AI_Comments:** 这篇论文通过引入形状和变形解耦的神经参数模型NeuraLeaf，为植物叶片建模提供了一个创新性的解决方案。其主要创新点在于利用2D和3D数据的结合，以及提出无骨架蒙皮模型来处理复杂的叶片变形。这项工作对于农业（如植物生长监测）和计算机图形学（如逼真植物渲染）领域具有重要意义，克服了传统方法在处理叶片多样性和柔性方面的局限性。DeformLeaf数据集的创建也为未来的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 植物建模和重建对于农业和计算机图形学至关重要，但叶片形状多样且变形灵活，给现有的神经参数模型带来了独特的挑战。

**Method:** 提出NeuraLeaf，一个神经参数叶片模型。它将叶片的几何形状解耦为2D基形和3D变形。利用2D叶片图像数据集学习基形，并同时学习与几何形状对齐的纹理。为了建模3D变形，提出了一个新的无骨架蒙皮模型，并创建了一个新的3D叶片数据集DeformLeaf。

**Result:** NeuraLeaf成功生成了各种具有变形的叶片形状，并能准确拟合深度图和点云等3D观测数据。

**Conclusion:** NeuraLeaf通过解耦2D形状和3D变形，并引入新的变形模型和数据集，有效解决了植物叶片建模和重建中的挑战，实现了对复杂叶片形状和变形的准确表示和拟合。

> **ai_Abstract:** NeuraLeaf是一种新颖的神经参数叶片模型，旨在解决植物建模和重建中叶片形状多样性和灵活变形的挑战。该模型创新性地将叶片几何形状解耦为2D基形和3D变形，允许利用丰富的2D图像数据进行学习。为实现3D变形建模，它引入了无骨架蒙皮模型并构建了DeformLeaf数据集。实验证明，NeuraLeaf能够成功生成多种叶片形状及其变形，并能准确拟合3D观测数据。

> **摘要翻译:** 我们开发了一种用于植物建模和重建的3D叶片神经参数模型，这对于农业和计算机图形学至关重要。虽然神经参数模型在人类和动物领域得到了积极研究，但植物叶片由于其多样的形状和灵活的变形而带来了独特的挑战。为了解决这个问题，我们引入了一种叶片神经参数模型——NeuraLeaf。利用扁平叶片形状可以近似为2D平面的事实，NeuraLeaf将叶片的几何形状解耦为2D基形和3D变形。这种表示允许从丰富的2D叶片图像数据集中学习基形，并且还具有同时学习与几何形状对齐的纹理的优点。为了建模3D变形，我们提出了一种新颖的无骨架蒙皮模型，并创建了一个新捕获的3D叶片数据集，名为DeformLeaf。我们展示了NeuraLeaf成功生成了各种具有变形的叶片形状，从而实现了对深度图和点云等3D观测数据的精确模型拟合。我们的实现和数据集可在https://neuraleaf-yang.github.io/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [570] [SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation](https://arxiv.org/abs/2507.12857)
> *SCORE：场景上下文在开放词汇遥感实例分割中的重要性*

*Shiqi Huang, Shuting He, Huaiyuan Qin, Bihan Wen* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 遥感, 实例分割, 开放词汇, 场景上下文, 深度学习

**Comment:** ICCV 2025

> **TL;DR:** SCORE框架通过整合多粒度场景上下文，解决了遥感开放词汇实例分割的挑战，实现了最先进的性能。

**AI_Comments:** 本文的创新点在于首次将多粒度场景上下文（区域和全局）引入开放词汇遥感实例分割，有效解决了遥感图像特有的复杂性挑战。其重要性在于极大地扩展了遥感图像分析在识别未知类别和跨数据集泛化方面的能力，为实际应用提供了更鲁棒的解决方案。该方法在建立新基准和实现SOTA性能方面具有显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有遥感实例分割方法是为封闭词汇预测设计的，限制了它们识别新类别或跨数据集泛化的能力，从而限制了其在多样化地球观测场景中的适用性。

**Method:** 本文提出了SCORE框架，通过整合多粒度场景上下文（区域上下文和全局上下文）来增强视觉和文本表示。具体方法包括：引入区域感知整合（Region-Aware Integration），用区域上下文细化类别嵌入以提高对象可区分性；以及提出全局上下文适应（Global Context Adaptation），用遥感全局上下文丰富原始文本嵌入，创建更具适应性和表达性的语言潜在空间。

**Result:** 本文为开放词汇遥感实例分割建立了新的基准。实验结果表明，所提出的方法取得了最先进（SOTA）的性能。

**Conclusion:** SCORE为大规模、真实世界的地理空间分析提供了一个鲁棒的解决方案。

> **ai_Abstract:** 本文提出SCORE框架，旨在解决现有遥感实例分割方法在识别新类别和跨数据集泛化方面的局限性。针对开放词汇遥感实例分割面临的挑战，如多样景观和复杂目标，SCORE通过整合多粒度场景上下文（区域和全局）来增强视觉和文本表示。具体包括区域感知整合和全局上下文适应模块。实验证明，SCORE在开放词汇遥感实例分割任务上建立了新基准并取得了最先进的性能，为大规模地理空间分析提供了有效方案。

> **摘要翻译:** 大多数现有遥感实例分割方法是为封闭词汇预测设计的，限制了它们识别新类别或跨数据集泛化的能力。这限制了它们在多样化地球观测场景中的适用性。为解决此问题，我们引入了开放词汇（OV）学习用于遥感实例分割。尽管当前OV分割模型在自然图像数据集上表现良好，但它们直接应用于遥感领域面临着挑战，如多样化的景观、季节性变化以及航空影像中存在的小目标或模糊目标。为克服这些挑战，我们提出了SCORE（场景上下文在开放词感遥感实例分割中的重要性），这是一个整合多粒度场景上下文（即区域上下文和全局上下文）以增强视觉和文本表示的框架。具体而言，我们引入了区域感知整合，它通过区域上下文细化类别嵌入以提高对象可区分性。此外，我们提出了全局上下文适应，它用遥感全局上下文丰富原始文本嵌入，为分类器创建了一个更具适应性和表达性的语言潜在空间。我们在多样化数据集上为OV遥感实例分割建立了新的基准。实验结果表明，我们提出的方法取得了SOTA性能，这为大规模、真实世界的地理空间分析提供了一个鲁棒的解决方案。我们的代码可在https://github.com/HuangShiqi128/SCORE获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [573] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
> *PhysX：基于物理的3D资产生成*

*Ziang Cao, Zhaoxi Chen, Liang Pan, Ziwei Liu* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 3D资产生成, 物理属性, PhysX, PhysXNet, PhysXGen

**Comment:** Project page: https://physx-3d.github.io/

> **TL;DR:** PhysX提出了一个端到端的基于物理的3D资产生成范式，通过构建首个物理标注数据集PhysXNet和开发图像到3D生成框架PhysXGen来解决现有3D生成模型忽视物理属性的问题。

**AI_Comments:** 本文的创新点在于首次系统性地将物理属性引入3D资产生成领域，并为此构建了专门的数据集PhysXNet和生成框架PhysXGen。PhysXNet通过其多维度的物理标注和高效的人机协作标注流程，填补了物理标注3D数据集的空白。PhysXGen的双分支架构设计巧妙，能够同时兼顾几何质量和物理属性的合理性。这项工作对于推动3D资产在模拟、机器人和具身AI等物理领域的实际应用具有重要意义，是生成式物理AI发展的一个关键里程碑。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D生成模型主要侧重于几何形状和纹理，而忽略了物理属性，这阻碍了合成的3D资产在模拟和具身AI等物理领域中的实际应用。

**Method:** 本文提出了PhysX，一个端到端的基于物理的3D资产生成范式。具体包括：1) PhysXNet：首个系统地标注了五个基础维度（绝对尺度、材料、功能、运动学和功能描述）的物理接地3D数据集。该数据集采用基于视觉-语言模型的可扩展人机协作标注流程。2) PhysXGen：一个前馈框架，用于基于物理的图像到3D资产生成，通过双分支架构明确建模3D结构和物理属性之间的潜在关联，从而在保持原生几何质量的同时生成具有合理物理预测的3D资产。

**Result:** 广泛的实验验证了我们框架的卓越性能和有前景的泛化能力。

**Conclusion:** PhysX框架有效解决了现有3D生成模型忽视物理属性的问题，并通过提供数据集和生成框架，为物理接地3D资产生成领域奠定了基础，将促进生成式物理AI的未来研究。

> **ai_Abstract:** 本文提出了PhysX，一个端到端的基于物理的3D资产生成范式，旨在解决现有3D生成模型忽视物理属性的问题。PhysX包含两大部分：一是PhysXNet，一个首次系统标注了物理属性的3D数据集，采用人机协作的标注流程；二是PhysXGen，一个前馈的图像到3D生成框架，通过双分支架构将物理知识融入3D结构空间，生成具有合理物理预测的3D资产。实验证明了该框架的优越性能和泛化能力，为未来生成式物理AI研究奠定了基础。

> **摘要翻译:** 3D建模正在从虚拟走向物理。现有的3D生成主要强调几何形状和纹理，而忽略了基于物理的建模。因此，尽管3D生成模型发展迅速，但合成的3D资产往往忽视了丰富而重要的物理属性，阻碍了它们在模拟和具身AI等物理领域的实际应用。作为解决这一挑战的初步尝试，我们提出了PhysX，一个用于基于物理的3D资产生成的端到端范式。1) 为了弥合物理标注3D数据集的关键空白，我们提出了PhysXNet——首个系统地标注了五个基础维度（绝对尺度、材料、功能、运动学和功能描述）的基于物理的3D数据集。特别是，我们设计了一种基于视觉-语言模型的可扩展人机协作标注流程，可以高效地从原始3D资产中创建物理优先的资产。2) 此外，我们提出了PhysXGen，一个用于基于物理的图像到3D资产生成的前馈框架，将物理知识注入预训练的3D结构空间。具体来说，PhysXGen采用双分支架构，明确建模3D结构和物理属性之间的潜在关联，从而在保持原生几何质量的同时生成具有合理物理预测的3D资产。广泛的实验验证了我们框架的卓越性能和有前景的泛化能力。所有代码、数据和模型都将发布，以促进生成式物理AI的未来研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [590] [WhoFi: Deep Person Re-Identification via Wi-Fi Channel Signal Encoding](https://arxiv.org/abs/2507.12869)
> *WhoFi：通过Wi-Fi信道信号编码实现深度人员再识别*

*Danilo Avola, Daniele Pannone, Dario Montagnini, Emad Emam* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 人员再识别, Wi-Fi信号, 信道状态信息, 深度神经网络, Transformer

**Comment:** 

> **TL;DR:** WhoFi利用Wi-Fi信号进行人员再识别，通过深度神经网络处理CSI数据，解决了传统视觉方法的局限性，并取得了有竞争力的结果。

**AI_Comments:** 这项研究的创新之处在于利用非传统的Wi-Fi信号进行人员再识别，这为解决传统视觉方法在光照、遮挡等方面的局限性提供了新的视角。将CSI数据与深度学习（特别是Transformer）结合，展示了多模态数据融合在计算机视觉任务中的潜力。其重要性在于为未来在复杂环境下的无视觉人员识别系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的人员再识别方法依赖视觉数据，但经常受到光照不足、遮挡和视角不佳等问题的阻碍，影响性能。

**Method:** 本文提出了WhoFi，一个利用Wi-Fi信号进行人员再识别的新型流程。它从信道状态信息（CSI）中提取生物特征，并通过一个模块化的深度神经网络（DNN）进行处理，该网络包含一个基于Transformer的编码器。网络使用批内负损失函数进行训练，以学习鲁棒且可泛化的生物特征签名。

**Result:** 在NTU-Fi数据集上的实验表明，WhoFi方法与最先进的方法相比取得了有竞争力的结果。

**Conclusion:** 实验证实了WhoFi通过Wi-Fi信号识别人员的有效性。

> **ai_Abstract:** WhoFi提出了一种基于Wi-Fi信号的新型人员再识别方法，旨在克服传统视觉方法在恶劣环境下的局限性。该方法从Wi-Fi信道状态信息（CSI）中提取生物特征，并利用一个带有Transformer编码器的深度神经网络进行处理，通过批内负损失函数进行训练。实验结果表明，WhoFi在NTU-Fi数据集上表现出与现有先进方法相当的性能，验证了其通过Wi-Fi信号进行人员识别的有效性。

> **摘要翻译:** 人员再识别是视频监控中一个关键且具有挑战性的任务。虽然传统方法依赖视觉数据，但光照不足、遮挡和视角不佳等问题常常阻碍其性能。为了解决这些挑战，我们引入了WhoFi，一个利用Wi-Fi信号进行人员再识别的新型流程。生物特征从信道状态信息（CSI）中提取，并通过一个模块化的深度神经网络（DNN）进行处理，该网络具有一个基于Transformer的编码器。网络使用批内负损失函数进行训练，以学习鲁棒且可泛化的生物特征签名。在NTU-Fi数据集上的实验表明，我们的方法与最先进的方法相比取得了有竞争力的结果，证实了其通过Wi-Fi信号识别人员的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [591] [Imbalance in Balance: Online Concept Balancing in Generation Models](https://arxiv.org/abs/2507.13345)
> *平衡中的不平衡：生成模型中的在线概念平衡*

*Yukai Shi, Jiarong Ou, Rui Chen, Haotian Yang, Jiahao Wang, Xin Tao, Pengfei Wan, Di Zhang, Kun Gai* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 概念平衡, 生成模型, 在线学习, 损失函数

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了一种名为IMBA损失的在线概念均衡损失函数，以解决视觉生成模型中复杂概念响应不稳定和易出错的问题，并在多个基准测试中取得了显著效果。

**AI_Comments:** 本文的创新点在于提出了在线的概念均衡损失函数（IMBA损失），有效解决了生成模型中复杂概念响应不稳定的问题。其在线特性和极小的代码改动使其具有很高的实用价值和部署便利性，对于提高生成模型在复杂场景下的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉生成任务中，复杂概念的响应和组合常常缺乏稳定性和容易出错，这是一个尚未充分探索的领域。本文旨在探索导致概念响应不佳的因果因素，并解决这一问题。

**Method:** 本文通过精心设计的实验探索了导致概念响应不佳的因果因素。为解决这一问题，提出了一种概念层面均衡损失函数（IMBA损失）。该方法是在线的，无需离线数据集处理，且只需极少的代码修改。

**Result:** 在本文新提出的复杂概念基准Inert-CompBench和另外两个公共测试集上，所提出的方法显著增强了基线模型的概念响应能力，并以极少的代码取得了极具竞争力的结果。

**Conclusion:** 所提出的在线概念均衡损失函数（IMBA损失）能够有效提高生成模型中复杂概念的响应能力，解决了概念响应不稳定和易出错的问题。

> **ai_Abstract:** 本文针对视觉生成任务中复杂概念响应不稳定和易出错的问题，通过实验探索了其原因，并提出了一种名为IMBA损失的在线概念均衡损失函数。该方法无需离线数据处理，代码改动小，并在多个测试集上显著提升了基线模型的概念响应能力。

> **摘要翻译:** 在视觉生成任务中，复杂概念的响应和组合常常缺乏稳定性且容易出错，这是一个尚未充分探索的领域。本文尝试通过精心设计的实验来探索导致概念响应不佳的因果因素。我们还设计了一种概念层面的均衡损失函数（IMBA损失）来解决这个问题。我们提出的方法是在线的，无需离线数据集处理，并且只需极少的代码修改。在我们新提出的复杂概念基准Inert-CompBench和另外两个公共测试集上，我们的方法显著增强了基线模型的概念响应能力，并以极少的代码取得了极具竞争力的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [600] [DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization](https://arxiv.org/abs/2507.12933)
> *DMQ：剖析扩散模型中的异常值以进行训练后量化*

*Dongyeun Lee, Jiwan Hur, Hyounguk Shon, Jae Young Lee, Junmo Kim* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 扩散模型, 训练后量化, 异常值, 量化误差, 低位宽

**Comment:** Accepted by ICCV 2025

> **TL;DR:** DMQ通过结合学习等效缩放和逐通道2的幂缩放，解决了扩散模型训练后量化中异常值导致低位宽性能下降的问题，显著提高了图像生成质量和模型稳定性。

**AI_Comments:** 该论文创新性地关注了扩散模型训练后量化中的异常值问题，并通过结合多种优化策略（LES、PTS、自适应时间步加权、投票算法）来解决。其在低位宽下的显著性能提升对于推动扩散模型在资源受限设备上的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型计算成本高昂，难以在资源受限环境中部署。现有训练后量化（PTQ）方法通常忽略异常值，导致在低位宽下性能显著下降。

**Method:** 本文提出DMQ，结合了学习等效缩放（LES）和逐通道2的幂缩放（PTS）。LES优化通道缩放因子，以重新分配权重和激活之间的量化难度，减少量化误差。针对早期去噪步骤对最终输出的关键影响，引入自适应时间步加权方案优先处理这些步骤。为解决跳跃连接等层的高通道间方差问题，引入了针对激活的逐通道2的幂缩放。为确保即使在小校准集下PTS因子的稳健选择，还引入了一种投票算法。

**Result:** 广泛的实验表明，DMQ显著优于现有方法，尤其在W4A6（4位权重，6位激活）和W4A8等低位宽下，仍能保持高图像生成质量和模型稳定性。

**Conclusion:** DMQ通过有效处理异常值和优化量化策略，显著提升了扩散模型在低位宽训练后量化时的性能和稳定性，使其更适用于资源受限环境。

> **ai_Abstract:** 本文提出DMQ，一种针对扩散模型训练后量化的新方法，旨在解决现有方法忽略异常值导致低位宽性能下降的问题。DMQ结合了学习等效缩放（LES）和逐通道2的幂缩放（PTS），并通过自适应时间步加权和投票算法优化量化过程。实验证明，DMQ在低位宽下显著优于现有技术，保持了高质量的图像生成和模型稳定性。

> **摘要翻译:** 扩散模型在图像生成方面取得了显著成功，但也伴随着巨大的计算成本，给在资源受限环境中的部署带来了挑战。最近的训练后量化（PTQ）方法试图通过关注扩散模型的迭代特性来缓解这个问题。然而，这些方法通常忽略异常值，导致在低位宽下性能下降。在本文中，我们提出了DMQ，它结合了学习等效缩放（LES）和逐通道2的幂缩放（PTS），以有效解决这些挑战。学习等效缩放优化了逐通道缩放因子，以重新分配权重和激活之间的量化难度，从而减少整体量化误差。认识到早期去噪步骤尽管量化误差小，但由于误差累积，对最终输出具有关键影响，我们引入了自适应时间步加权方案，在学习过程中优先处理这些关键步骤。此外，识别出跳跃连接等层表现出高通道间方差，我们为激活引入了逐通道2的幂缩放。为了即使在小校准集下也能确保PTS因子的稳健选择，我们引入了一种投票算法来增强可靠性。广泛的实验表明，我们的方法显著优于现有工作，尤其是在W4A6（4位权重，6位激活）和W4A8等低位宽下，仍能保持高图像生成质量和模型稳定性。代码可在https://github.com/LeeDongYeun/dmq 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [601] [Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection](https://arxiv.org/abs/2507.13085)
> *解耦PROB：用于开放世界目标检测的解耦查询初始化任务和目标性-类别学习*

*Riku Inoue, Masamitsu Tsuchiya, Yuji Yasui* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 开放世界目标检测, 解耦学习, 目标性预测, 查询初始化, 计算机视觉

**Comment:** This paper has been accepted to WACV 2025 (Tucson, Arizona, USA),
  February 28-March 4 2025

> **TL;DR:** 本文提出了Decoupled PROB模型，通过解耦目标性预测和类别学习以及改进查询初始化，显著提升了开放世界目标检测（OWOD）的性能。

**AI_Comments:** 该论文通过解耦学习任务和优化查询初始化，解决了现有先进OWOD模型PROB的痛点，即目标性与类别预测的学习冲突，展现了重要的创新性。ETOP和TDQI的结合提升了模型的性能和泛化能力，TDQI的可插拔性也增加了其实用价值。在开放世界检测这一复杂领域取得SOTA成果，证明了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 开放世界目标检测（OWOD）是一项具有挑战性的任务，需要检测和分类未知对象并增量学习新类别。现有先进模型PROB在目标性预测和类别预测之间存在学习冲突，影响了其性能。

**Method:** 本文提出了Decoupled PROB模型。该模型引入了目标性预测早期终止（ETOP）机制，在解码器中适当的层停止目标性预测，从而解决了PROB中类别和目标性预测之间的学习冲突。此外，还引入了任务解耦查询初始化（TDQI），通过结合查询选择和可学习查询来高效提取已知和未知对象的特征。TDQI是一个可轻松集成到现有基于DETR的OWOD模型中的模块。

**Result:** 在OWOD基准测试中，Decoupled PROB在多项指标上超越了所有现有方法，显著提升了性能。

**Conclusion:** Decoupled PROB通过有效解决目标性与类别学习冲突并优化查询初始化，在开放世界目标检测任务中取得了显著的性能提升，超越了现有所有方法。

> **ai_Abstract:** 开放世界目标检测（OWOD）面临未知对象检测和增量学习的挑战。现有先进模型PROB存在目标性与类别预测的学习冲突。本文提出Decoupled PROB，通过引入目标性预测早期终止（ETOP）解决这些冲突，并利用任务解耦查询初始化（TDQI）高效提取已知和未知对象特征。TDQI结合查询选择和可学习查询，可灵活集成到现有模型中。实验证明，Decoupled PROB在OWOD基准上显著超越了所有现有方法。

> **摘要翻译:** 开放世界目标检测（OWOD）是一项具有挑战性的计算机视觉任务，它通过(1)在没有监督的情况下检测和分类未知对象，以及(2)在不忘记先前学习的类别的情况下增量学习新对象类别，从而扩展了标准目标检测。未知对象缺乏真实标签使得OWOD任务尤为困难。许多方法通过使用未知对象的伪标签来解决这个问题。最近提出的基于概率目标性Transformer的开放世界检测器（PROB）是一种最先进的模型，它不需要未知对象的伪标签，因为它预测概率目标性。然而，这种方法面临目标性预测和类别预测之间学习冲突的问题。
为了解决这个问题并进一步提高性能，我们提出了一种新颖的模型——Decoupled PROB。Decoupled PROB引入了目标性预测早期终止（ETOP），以在解码器中适当的层停止目标性预测，从而解决了PROB中类别和目标性预测之间的学习冲突。此外，我们引入了任务解耦查询初始化（TDQI），它能高效地提取已知和未知对象的特征，从而提高性能。TDQI是一种结合了查询选择和可学习查询的查询初始化方法，它是一个可以轻松集成到现有基于DETR的OWOD模型中的模块。在OWOD基准测试中进行的广泛实验表明，Decoupled PROB在多项指标上超越了所有现有方法，显著提高了性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [614] [SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery](https://arxiv.org/abs/2507.12727)
> *SOD-YOLO：增强无人机图像中YOLO小目标检测*

*Peijun Wang, Jinhua Zhao* | **Category: cs.CV, I.4** | **Updated: 2025-07-17**

**Keywords:** 小目标检测, YOLOv8, 无人机图像, 多尺度特征融合, Soft-NMS

**Comment:** 

> **TL;DR:** SOD-YOLO通过多尺度特征融合、高分辨率特征图和Soft-NMS，显著提升了YOLOv8在无人机小目标检测上的性能。

**AI_Comments:** 该论文的创新点在于结合了多种策略来专门优化YOLOv8在小目标检测方面的性能，特别是针对无人机图像。通过引入ASF机制、P2层和Soft-NMS，系统性地解决了小目标特征信息不足和误检问题。其重要性在于为无人机监控、测绘等领域的小目标检测提供了更准确、高效的工具。

<details>
  <summary>Details</summary>

**Motivation:** 小目标检测在目标检测领域仍然是一个具有挑战性的问题，尤其是在无人机图像中。

**Method:** 提出了增强的基于YOLOv8的模型SOD-YOLO。它在neck中集成了ASF机制以增强多尺度特征融合，添加了小目标检测层（P2）以提供更高分辨率的特征图，并采用Soft-NMS来优化置信度分数并保留真阳性。

**Result:** 实验结果表明，与基线模型相比，SOD-YOLO在VisDrone2019-DET数据集上mAP$_{50:95}$提高了36.1%，mAP$_{50}$提高了20.6%。

**Conclusion:** SOD-YOLO是无人机图像中小目标检测的实用且高效的解决方案。

> **ai_Abstract:** 本文提出了SOD-YOLO，一个基于YOLOv8的增强模型，旨在解决无人机图像中小目标检测的挑战。该模型通过集成ASF机制增强多尺度特征融合，引入P2小目标检测层提供高分辨率特征图，并采用Soft-NMS优化检测结果。实验证明，SOD-YOLO在VisDrone2019-DET数据集上显著提升了mAP$_{50:95}$和mAP$_{50}$，成为一种高效实用的解决方案。

> **摘要翻译:** 小目标检测仍然是目标检测领域的一个挑战性问题。为了解决这一挑战，我们提出了一种增强的基于YOLOv8的模型，SOD-YOLO。该模型在neck中集成了ASF机制以增强多尺度特征融合，添加了一个小目标检测层（命名为P2）以提供更高分辨率的特征图，从而更好地检测小目标，并采用Soft-NMS来优化置信度分数并保留真阳性。实验结果表明，与基线模型相比，SOD-YOLO在VisDrone2019-DET数据集上mAP$_{50:95}$提高了36.1%，mAP$_{50}$提高了20.6%。这些增强使SOD-YOLO成为无人机图像中小目标检测的实用且高效的解决方案。我们的源代码、超参数和模型权重可在https://github.com/iamwangxiaobai/SOD-YOLO获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [615] [HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation](https://arxiv.org/abs/2507.12883)
> *HRSeg：用于推理分割的高分辨率视觉感知与增强*

*Weihuang Lin, Yiwei Ma, Xiaoshuai Sun, Shuting He, Jiayi Ji, Liujuan Cao, Rongrong Ji* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 推理分割, 高分辨率感知, 图像增强, HRSeg, 视觉编码器

**Comment:** 

> **TL;DR:** HRSeg通过高分辨率感知和增强模块，解决了推理分割中低感知分辨率的问题，显著提升了性能。

**AI_Comments:** HRSeg的创新点在于其针对推理分割任务中普遍存在的低分辨率感知问题，提出了专门的高分辨率处理机制。通过HRP和HRE模块，模型能够有效利用高分辨率图像的细粒度信息，从而提升分割精度。这对于需要精细视觉理解的任务具有重要意义，克服了传统视觉编码器在低分辨率预训练上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 推理分割任务中，现有方法受限于低感知分辨率，因为视觉编码器通常在较低分辨率下预训练。简单地插值位置嵌入只能带来微小的性能提升，却消耗大量计算成本。

**Method:** 本文提出了HRSeg模型，旨在实现高效的高分辨率细粒度感知。它包含两个关键创新：高分辨率感知（HRP）模块通过裁剪处理高分辨率图像，整合局部和全局特征以实现多粒度质量；高分辨率增强（HRE）模块通过整合高分辨率图像中的细粒度信息来增强掩码特征，并优化其与文本特征的对齐以实现精确分割。

**Result:** 广泛的消融研究验证了所提出模块的有效性，而对多个基准数据集的综合实验表明HRSeg具有卓越的性能。

**Conclusion:** HRSeg通过其创新的高分辨率感知和增强机制，成功克服了推理分割任务中低感知分辨率的挑战，并在多个基准数据集上取得了显著的性能提升。

> **ai_Abstract:** 本文提出了HRSeg模型，旨在解决推理分割任务中现有方法因低感知分辨率而受到的限制。HRSeg引入了高分辨率感知（HRP）和高分辨率增强（HRE）两大创新模块。HRP通过裁剪处理高分辨率图像，整合局部与全局特征；HRE则通过细粒度信息增强掩码特征，并优化与文本特征的对齐，从而实现精确分割。实验结果表明，HRSeg在多个基准数据集上表现出卓越的性能。

> **摘要翻译:** 推理分割任务涉及通过解释隐式用户指令来分割图像中的对象，这些指令可能包含上下文线索和开放世界知识等微妙之处。尽管现有方法取得了显著进展，但它们仍受限于低感知分辨率，因为视觉编码器通常在较低分辨率下进行预训练。此外，简单地插值视觉编码器的位置嵌入以提高感知分辨率，仅能带来微小的性能提升，同时会产生大量的计算成本。为了解决这个问题，我们提出了HRSeg，一个具有高分辨率细粒度感知的高效模型。它具有两个关键创新：高分辨率感知（HRP）和高分辨率增强（HRE）。HRP模块通过裁剪处理高分辨率图像，整合局部和全局特征以实现多粒度质量。HRE模块通过整合高分辨率图像中的细粒度信息来增强掩码特征，优化其与文本特征的对齐以实现精确分割。广泛的消融研究验证了我们模块的有效性，而对多个基准数据集的综合实验表明HRSeg具有卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [627] [An Event-based Algorithm for Simultaneous 6-DOF Camera Pose Tracking and Mapping](https://arxiv.org/abs/2301.00618)
> *基于事件的同时6自由度相机姿态跟踪与建图算法*

*Masoud Dayani Najafabadi, Mohammad Reza Ahmadzadeh* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 事件相机, SLAM, 相机姿态跟踪, 建图, 6自由度

**Comment:** 

> **TL;DR:** 该论文提出了一种基于事件相机数据的算法，用于同时进行6自由度相机姿态跟踪和建图，并证明其在特定条件下能达到与现有技术相当或更优的性能。

**AI_Comments:** 该论文的创新点在于将传统的基于图像的SLAM技术应用于新型事件相机，并提出了事件-惯性融合方案。事件相机的数据特性（异步、紧凑、对运动响应快）使其在高速运动或高动态范围场景下具有潜在优势。该研究为事件相机在SLAM领域的应用提供了新的思路和方法，特别是其在可靠地图估计下的高性能表现值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 研究现有基于图像的SLAM技术在新型动态视觉传感器（事件相机）上的应用，因为事件相机能异步输出紧凑的视觉数据。

**Method:** 该方法处理自适应选择的事件窗口中的信息，形成运动补偿图像。然后，这些图像用于重建场景并估计相机的6自由度姿态。论文还提出了一个事件-惯性融合版本来评估其能力。

**Result:** 将所提出算法的不同配置与两个公开事件数据集的地面真实值进行比较，并将其事件-惯性融合管道与最先进技术进行比较。结果表明，在地图估计可靠的情况下，该方法可以产生可比或更准确的结果。

**Conclusion:** 在地图估计可靠的前提下，所提出的基于事件的算法（特别是事件-惯性融合版本）在6自由度相机姿态跟踪和建图方面能够达到与现有技术相当或更优的性能。

> **ai_Abstract:** 本文提出了一种利用动态视觉传感器（事件相机）数据实现同步6自由度相机姿态跟踪和建图的算法。该方法通过处理事件窗口生成运动补偿图像，进而重建场景并估计相机姿态。此外，还引入了一个事件-惯性融合版本。实验结果表明，与现有技术相比，在地图估计可靠时，该算法能提供相当或更精确的性能。

> **摘要翻译:** 与普通相机相比，动态视觉传感器或事件相机能够基于每个像素位置的强度变化异步输出紧凑的视觉数据。在本文中，我们研究了当前基于图像的SLAM技术在这些新型传感器上的应用。为此，我们处理自适应选择的事件窗口中的信息，以形成运动补偿图像。然后，这些图像用于重建场景并估计相机的6自由度姿态。我们还提出了一个纯事件管道的惯性版本，以评估其能力。我们将所提出算法不同配置的结果与两个公开事件数据集的序列的地面真实值进行了比较。我们还将所提出的事件-惯性管道的结果与最先进的技术进行了比较，并表明在地图估计可靠的情况下，它能够产生可比或更准确的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [641] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
> *VisionThink：基于强化学习的智能高效视觉语言模型*

*Senqiao Yang, Junyi Li, Xin Lai, Bei Yu, Hengshuang Zhao, Jiaya Jia* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 视觉语言模型, 视觉令牌压缩, 强化学习, 动态分辨率, VisionThink

**Comment:** Code and models are available at
  https://github.com/dvlab-research/VisionThink

> **TL;DR:** VisionThink提出一种动态处理视觉样本分辨率的视觉令牌压缩新范式，通过强化学习和LLM-as-Judge策略，实现智能高效的视觉语言模型，在保证性能的同时显著节省视觉令牌。

**AI_Comments:** VisionThink通过引入动态分辨率处理和强化学习，解决了视觉语言模型中视觉令牌冗余的痛点，提供了一种新颖且高效的解决方案。其创新点在于模型能够自主决策是否请求更高分辨率的图像，而非采用固定的压缩策略，这使得模型在不同任务上能更灵活地平衡性能与效率。LLM-as-Judge策略的应用也为强化学习在通用VQA任务中的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型为了提高性能，通常增加视觉令牌数量，但多数实际场景并不需要如此多的视觉令牌。尽管在OCR相关任务中性能下降，但在大多数通用VQA任务中，1/4分辨率也能保持准确性。因此，需要一种能够动态处理不同分辨率样本的方法来压缩视觉令牌。

**Method:** 提出VisionThink，一种新的视觉令牌压缩范式。它首先使用下采样图像，并智能判断是否足以解决问题。如果不足，模型可以输出特殊令牌请求更高分辨率图像。与现有固定压缩比的方法不同，VisionThink能自主决定是否压缩。采用强化学习（RL）并提出LLM-as-Judge策略将其应用于通用VQA任务。设计了奖励函数和惩罚机制来稳定和合理地控制图像调整调用率。

**Result:** VisionThink在OCR相关任务上展示出强大的细粒度视觉理解能力，同时在简单任务上节省了大量的视觉令牌。实验证明了该方法的优越性、效率和有效性。

**Conclusion:** VisionThink通过动态调整图像分辨率和智能令牌压缩，实现了智能高效的视觉语言模型，在保证性能的同时显著节省计算资源，并通过强化学习成功应用于通用VQA任务。

> **ai_Abstract:** 本文提出VisionThink，一种基于强化学习的智能高效视觉语言模型。针对现有VLM中视觉令牌冗余的问题，VisionThink引入动态分辨率处理和智能令牌压缩范式，模型能自主判断是否需要更高分辨率的图像。该方法利用强化学习和LLM-as-Judge策略，在保证OCR等细粒度任务性能的同时，显著节省了简单任务上的视觉令牌，提高了模型效率。

> **摘要翻译:** 视觉语言模型（VLM）的最新进展通过增加视觉令牌的数量提高了性能，而视觉令牌通常比文本令牌长得多。然而，我们观察到大多数实际场景并不需要如此大量的视觉令牌。尽管在OCR相关任务的一小部分子集中性能显著下降，但模型在大多数其他通用VQA任务中，仅用1/4分辨率仍能准确执行。因此，我们提出动态处理不同分辨率的不同样本，并提出一种视觉令牌压缩的新范式，即VisionThink。它从下采样图像开始，并智能地决定是否足以解决问题。否则，模型可以输出一个特殊令牌来请求更高分辨率的图像。与现有使用固定剪枝率或阈值压缩令牌的效率VLM方法相比，VisionThink能够根据具体情况自主决定是否压缩令牌。因此，它在OCR相关任务上展示了强大的细粒度视觉理解能力，同时在更简单的任务上节省了大量的视觉令牌。我们采用强化学习并提出LLM-as-Judge策略，成功将RL应用于通用VQA任务。此外，我们精心设计了奖励函数和惩罚机制，以实现稳定合理的图像调整调用率。大量的实验证明了我们方法的优越性、效率和有效性。我们的代码可在https://github.com/dvlab-research/VisionThink获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [644] [From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation](https://arxiv.org/abs/2507.12884)
> *从颈部到头部：基于生物阻抗传感的头部姿态估计*

*Mengxi Liu, Lala Shakti Swarup Ray, Sizhen Bian, Ko Watanabe, Ankur Bhatt, Joanna Sorysz, Russel Torah, Bo Zhou, Paul Lukowicz* | **Category: cs.CV, eess.SP** | **Updated: 2025-07-17**

**Keywords:** 生物阻抗传感, 头部姿态估计, 可穿戴系统, 深度学习, NeckSense

**Comment:** 

> **TL;DR:** NeckSense是一种新型可穿戴生物阻抗系统，用于头部姿态跟踪，它使用颈部电极和深度学习，实现了与最先进视觉方法相当的性能，且无需视线限制。

**AI_Comments:** 该论文的创新点在于首次将生物阻抗传感技术应用于头部姿态估计，并设计出紧凑、项链式的可穿戴设备。其重要性体现在克服了传统视觉方法对视线的要求，为虚拟现实、人机交互等领域提供了新的解决方案。其性能与SOTA视觉方法相当，且具有无视线限制的优势，预示着该技术在未来可穿戴设备中的巨大应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的头部姿态跟踪方法可能存在视线限制或不够紧凑。本文旨在开发一种新型、紧凑、无需视线限制的生物阻抗可穿戴系统，以实现与现有最先进视觉方法相当的头部跟踪性能。

**Method:** 本文提出了NeckSense系统，一个利用多通道生物阻抗传感技术与嵌入轻量级项链式设备中的柔软、干燥电极的可穿戴系统。该系统捕获颈部周围组织阻抗的动态变化，这些变化受头部旋转和肌肉活动调节。为鲁棒估计头部姿态，研究者提出了一个深度学习框架，将关节约束和自然头部旋转范围等解剖学先验知识整合到损失函数设计中。

**Result:** 在7名参与者上，使用当前最先进的姿态估计模型作为真值进行验证。该系统在各种头部运动中实现了25.9毫米的平均每顶点误差，并采用了留一法交叉验证。结果表明，紧凑、无视线限制的生物阻抗可穿戴设备可以提供与最先进视觉方法相当的头部跟踪性能。

**Conclusion:** NeckSense系统通过生物阻抗传感实现了与最先进视觉方法媲美的头部姿态跟踪性能，证明了其作为一种紧凑、无视线限制的可穿戴解决方案的潜力。

> **ai_Abstract:** 本文介绍了NeckSense，一个创新的可穿戴系统，通过颈部生物阻抗传感实现头部姿态跟踪。该系统采用项链式设计，内置柔软电极，并通过深度学习框架整合解剖学先验知识来精确估计头部姿态。实验结果显示，NeckSense在头部运动中取得了25.9毫米的平均误差，表现出与当前最先进的基于视觉的方法相媲美的性能，且无需视线限制，展现了生物阻抗在可穿戴头部跟踪领域的巨大潜力。

> **摘要翻译:** 我们提出了NeckSense，一种新型可穿戴系统，用于头部姿态跟踪。该系统利用多通道生物阻抗传感技术，结合嵌入轻量级项链式外形的柔软、干燥电极。NeckSense捕获颈部周围组织阻抗的动态变化，这些变化受头部旋转和细微肌肉活动的调节。为了鲁棒地估计头部姿态，我们提出了一个深度学习框架，将包括关节约束和自然头部旋转范围在内的解剖学先验知识整合到损失函数设计中。我们使用当前最先进的姿态估计模型作为真值，在7名参与者上验证了NeckSense。我们的系统在各种头部运动中实现了25.9毫米的平均每顶点误差，并采用了留一法交叉验证方法。这表明紧凑、无视线限制的生物阻抗可穿戴设备可以提供与最先进视觉方法相当的头部跟踪性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [649] [DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model](https://arxiv.org/abs/2507.13087)
> *DiffOSeg：通过多专家协作扩散模型实现全方位医学图像分割*

*Han Zhang, Xiangde Luo, Yong Chen, Kang Li* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 医学图像分割, 扩散模型, 多专家协作, 标注变异性, 共识驱动分割

**Comment:** 

> **TL;DR:** DiffOSeg是一个两阶段扩散模型，用于同时实现共识驱动和偏好驱动的医学图像分割，并在两个公共数据集上超越了现有SOTA方法。

**AI_Comments:** DiffOSeg的创新点在于其两阶段扩散框架，能够同时处理医学图像分割中的专家共识和个体偏好，这在以往的多标注者分割方法中是缺失的。这种“全方位”的视角对于提高医学诊断的鲁棒性和个性化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像分割中存在的标注变异性是一个重大挑战，源于模糊的图像边界和多样化的临床专业知识。传统的深度学习方法无法捕捉这些标注者偏差，而现有的多标注者分割方法通常只关注单一视角（要么生成概率性“黄金标准”共识，要么保留专家特定偏好），难以提供更全面的视角。

**Method:** 本文提出了DiffOSeg，一个两阶段的基于扩散的框架。第一阶段通过概率共识策略建立群体共识，第二阶段通过自适应提示捕获专家特异性偏好，旨在同时实现共识驱动和偏好驱动的分割。

**Result:** 该模型在两个公共数据集（LIDC-IDRI和NPC-170）上进行了验证，在所有评估指标上均优于现有最先进的方法。

**Conclusion:** DiffOSeg框架有效解决了医学图像分割中的标注变异性问题，通过结合共识和专家偏好，提供了更全面的分割结果，并在多个数据集上表现出优越性。

> **ai_Abstract:** DiffOSeg是一种新型的两阶段扩散模型，旨在解决医学图像分割中由标注变异性引起的问题。它通过第一阶段建立群体共识，并在第二阶段通过自适应提示捕获专家个体偏好，从而同时实现共识驱动和偏好驱动的分割。该模型在两个公共数据集上表现出色，超越了现有的最先进方法。

> **摘要翻译:** 医学图像分割中的标注变异性仍然是一个重大挑战，这源于模糊的成像边界和多样化的临床专业知识。生成单一确定性分割预测的传统深度学习方法往往无法捕捉这些标注者偏差。尽管最近的研究探索了多标注者分割，但现有方法通常只关注单一视角——要么生成概率性的“黄金标准”共识，要么保留专家特有的偏好——因此难以提供更全面的视角。在本研究中，我们提出了DiffOSeg，一个两阶段的基于扩散的框架，旨在同时实现共识驱动（结合所有专家的意见）和偏好驱动（反映专家个人评估）的分割。第一阶段通过概率共识策略建立群体共识，而第二阶段通过自适应提示捕获专家特异性偏好。在两个公共数据集（LIDC-IDRI和NPC-170）上进行的演示表明，我们的模型在所有评估指标上均优于现有最先进的方法。源代码可在 https://github.com/string-ellipses/DiffOSeg 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [654] [STF: Spatial Temporal Fusion for Trajectory Prediction](https://arxiv.org/abs/2311.18149)
> *STF：时空融合的轨迹预测*

*Pengqian Han, Jiamou Liu, Tianzhe Bao, Yifei Wang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 轨迹预测, 时空融合, 3D图, 图注意力, 深度学习

**Comment:** 6 pages, 6 figures

> **TL;DR:** 本文提出了STF（时空融合）模型，该模型利用包含空间和时间边的集成3D图，并结合多层感知机（MLP）和图注意力（GAT）来同时捕获轨迹预测中的时空信息。实验表明，STF在长时域轨迹预测方面优于现有基线方法。

**AI_Comments:** 本文的创新之处在于将空间和时间信息整合到一个统一的3D图结构中，解决了以往方法分别处理时空信息的局限性。在这一统一图上应用多层感知机（MLP）和图注意力（GAT）是其核心技术贡献。该研究的重要性在于提高了轨迹预测这一挑战性任务的准确性，特别是在长时域预测方面的改进。

<details>
  <summary>Details</summary>

**Motivation:** 轨迹预测是一项具有挑战性的任务，因为轨迹是包含空间和时间信息的复杂数据，而这些信息对于准确预测至关重要。以往的深度学习方法分别处理空间和时间信息，导致空间信息捕获不足，未能捕获完整的空间信息，尤其是在车辆交互方面。

**Method:** 本研究引入了一个集成的3D图，该图包含空间和时间边，并考虑了跨时间交互信息。在此基础上，提出了时空融合（STF）模型，该模型包含多层感知机（MLP）和图注意力（GAT），用于在3D图上同时捕获历史轨迹的时空信息。

**Result:** 在ApolloScape轨迹数据集上的实验表明，所提出的STF模型优于几种基线方法，尤其是在长时域轨迹预测方面。

**Conclusion:** STF模型有效地捕获了集成时空信息，从而改进了轨迹预测，特别是对于更长的预测时域。

> **ai_Abstract:** 本文针对轨迹预测中时空信息未能充分融合的问题，提出了时空融合（STF）模型。针对以往深度学习方法分别处理空间和时间信息导致捕获不足的局限性，STF引入了一个集成的3D图，该图包含空间和时间边以及跨时间交互信息。该模型利用多层感知机（MLP）和图注意力（GAT）在统一的3D图上同时捕获这些关键信息。在ApolloScape轨迹数据集上的实验证明，STF模型优于现有基线方法，尤其在长时域轨迹预测上表现突出，验证了其集成时空融合方法的有效性。

> **摘要翻译:** 轨迹预测是一项具有挑战性的任务，旨在根据车辆或行人的历史位置，在短时间内预测其未来轨迹。主要原因是轨迹是一种复杂的数据，包含空间和时间信息，这对于准确预测至关重要。直观地，模型捕获的信息越多，未来轨迹的预测就越精确。然而，以前基于深度学习方法的工作分别处理空间和时间信息，导致空间信息捕获不足，这意味着它们未能捕获完整的空间信息。因此，更充分有效地捕获车辆交互信息具有重要意义。在这项研究中，我们引入了一个集成的3D图，该图结合了空间和时间边。在此基础上，我们提出了集成的3D图，该图考虑了跨时间交互信息。具体而言，我们设计了一个时空融合（STF）模型，包括多层感知机（MLP）和图注意力（GAT），以在3D图上同时捕获历史轨迹的空间和时间信息。我们在ApolloScape轨迹数据集上的实验表明，所提出的STF优于几种基线方法，尤其是在长时域轨迹预测方面。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [655] [Transformer-based Spatial Grounding: A Comprehensive Survey](https://arxiv.org/abs/2507.12739)
> *基于Transformer的空间定位：一项综合调查*

*Ijazul Haq, Muhammad Saqib, Yingjie Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 空间定位, Transformer, 系统综述, 多模态, 自然语言处理

**Comment:** 

> **TL;DR:** 本文对2018年至2025年基于Transformer的空间定位方法进行了系统性文献综述，旨在提供全面的方法、数据集、评估指标和工业应用分析。

**AI_Comments:** 这是一篇重要的综述性论文，它填补了基于Transformer的空间定位领域中缺乏系统性总结的空白。通过识别主导趋势和最佳实践，它为未来的研究和工业应用提供了清晰的路线图，对于该领域的规范化和发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于Transformer的模型在空间定位方面取得了快速进展，但该领域仍缺乏对当前方法、数据集使用、评估指标和工业适用性的全面综合分析。

**Method:** 本文采用系统性文献综述的方法，对2018年至2025年间基于Transformer的空间定位方法进行了分析。

**Result:** 分析结果识别了主导模型架构、流行数据集和广泛采用的评估指标，并突出了关键方法趋势和最佳实践。

**Conclusion:** 这项研究为研究人员和实践者提供了重要的见解和结构化指导，以促进开发稳健、可靠且符合行业标准的基于Transformer的空间定位模型。

> **ai_Abstract:** 本文对2018年至2025年间基于Transformer的空间定位方法进行了全面的系统性文献综述。文章旨在弥补该领域在方法、数据集、评估指标和工业适用性方面缺乏综合分析的不足。研究识别了主流模型架构、数据集和评估指标，并总结了关键方法趋势和最佳实践，为研究人员和实践者提供了有价值的指导。

> **摘要翻译:** 空间定位，即将自然语言表达式与相应的图像区域关联起来的过程，由于引入了基于Transformer的模型而迅速发展，显著增强了多模态表示和跨模态对齐。尽管取得了这些进展，但该领域缺乏对当前方法、数据集使用、评估指标和工业适用性的全面综合。本文对2018年至2025年基于Transformer的空间定位方法进行了系统性文献综述。我们的分析识别了主导模型架构、流行数据集和广泛采用的评估指标，同时强调了关键的方法学趋势和最佳实践。这项研究为研究人员和实践者提供了重要的见解和结构化指导，促进开发稳健、可靠且符合行业标准的基于Transformer的空间定位模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [668] [Camera-based implicit mind reading by capturing higher-order semantic dynamics of human gaze within environmental context](https://arxiv.org/abs/2507.12889)
> *摄像头式隐式读心术：通过捕捉环境背景下人类注视的高阶语义动态*

*Mengke Song, Yuge Xie, Qi Cui, Luming Li, Xinyu Liu, Guotao Wang, Chenglizhao Chen, Shanchen Pang* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 情绪识别, 注视行为, 环境语义, 隐式情绪, 摄像头感知

**Comment:** 

> **TL;DR:** 一种新的基于摄像头的无感知情绪识别方法，通过分析在自然环境中注视模式、环境语义和时间动态的结合来推断深层隐式情绪。

**AI_Comments:** 这篇论文的创新之处在于提出了一种无创、用户无感知的隐式情绪识别方法，通过深度挖掘注视行为与环境背景的动态语义交互，克服了传统显式信号和生理信号方法的局限性。其重要性在于为更自然、实用的“读心”技术奠定了基础，特别是在无需特殊硬件的条件下，显著降低了部署成本并提高了普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有情绪识别方法依赖显式信号（易掩饰、忽略环境上下文）或复杂生理传感器。传统基于注视的方法未能捕捉注视与环境的动态交互。本研究旨在克服这些局限，实现对深层隐式情绪的无感知识别。

**Method:** 提出一种新颖的、基于摄像头的、用户无感知的、集成了注视凝视模式与环境语义及时间动态的情绪识别方法。该方法利用标准高清摄像头，在自然环境下无创捕获用户的眼睛外观和头部运动，无需特殊硬件或主动参与。系统基于这些视觉线索估计注视轨迹，并建模注视行为的空间、语义和时间维度，从而捕捉视觉注意力与周围环境的动态相互作用。

**Result:** 该方法揭示了情绪不仅是生理反应，更是人与环境复杂互动的结果。它实现了用户无感知、实时、连续的情绪识别。

**Conclusion:** 通过捕捉注视与环境的动态相互作用，该方法提供了一种高泛化性、低部署成本的用户无感知、实时、连续情绪识别方案，并证明情绪是人与环境互动的复杂结果。

> **ai_Abstract:** 本文提出了一种创新的基于摄像头的用户无感知情绪识别方法，旨在克服现有方法的局限性。该方法通过整合用户的注视凝视模式、环境语义和时间动态，利用标准高清摄像头在自然环境中无创地捕捉视觉线索。通过分析注视轨迹及其与环境的动态交互，该系统能够揭示深层隐式情绪，并证明情绪是人与环境复杂互动的结果，而非简单的生理反应。此方法具有实时、连续、高泛化性和低部署成本的优点。

> **摘要翻译:** 情绪识别作为“读心”的一步，旨在从外部线索推断内部状态。大多数现有方法依赖于面部表情、言语或手势等显式信号，这些信号仅反映身体反应，并忽视了环境背景的影响。这些线索通常是自愿的、易于掩饰的，并且不足以捕捉更深层次的隐式情绪。基于生理信号的方法提供了更直接的内部状态访问途径，但需要复杂的传感器，这会损害自然行为并限制可扩展性。基于注视的方法通常依赖于静态注视分析，未能捕捉注视与环境之间丰富、动态的相互作用，因此无法揭示情绪与隐式行为之间的深层联系。为了解决这些局限性，我们提出了一种新颖的、基于摄像头的、用户无感知的情绪识别方法，该方法将注视凝视模式与环境语义和时间动态相结合。利用标准高清摄像头，我们的方法在自然环境下无创地捕捉用户的眼睛外观和头部运动，无需专门硬件或主动用户参与。从这些视觉线索中，系统估计随时间和空间变化的注视轨迹，为建模注视行为的空间、语义和时间维度提供了基础。这使我们能够捕捉视觉注意力与周围环境之间的动态相互作用，揭示情绪不仅仅是生理反应，而是人与环境互动的复杂结果。所提出的方法实现了用户无感知、实时、连续的情绪识别，具有高泛化性、低部署成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [670] [Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models](https://arxiv.org/abs/2410.23114)
> *大型视觉-语言模型统一三元组级别幻觉评估*

*Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 大型视觉-语言模型, 幻觉评估, 关系幻觉, 对象幻觉, Tri-HE

**Comment:** Accepted by TMLR 2025. Project Page:
  https://kaichen1998.github.io/projects/tri-he/

> **TL;DR:** 本文提出一个统一框架和基准Tri-HE，用于同时评估大型视觉-语言模型（LVLMs）中的对象和关系幻觉，发现关系幻觉比对象幻觉更严重，并提出了一种简单的无训练缓解方法。

**AI_Comments:** 本文的创新点在于提出了一个统一的三元组级别评估框架，首次系统地将关系幻觉纳入LVLMs的评估范畴，弥补了现有研究的不足。其重要性在于揭示了关系幻觉比对象幻觉更严重这一被忽视的问题，为未来LVLMs的可靠性研究指明了方向。提出的无训练缓解方法也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型视觉-语言模型（LVLMs）幻觉基准主要局限于评估与对象相关的幻觉，而对两个对象之间关系（即关系幻觉）的潜在幻觉缺乏研究。

**Method:** 本文设计了一个统一框架来同时测量LVLMs中的对象和关系幻觉。该框架的核心思想是通过从LVLMs响应中提取的（对象、关系、对象）三元组来评估幻觉。在此框架基础上，进一步引入了Tri-HE，一个新颖的三元组级别幻觉评估基准，可同时用于研究对象和关系幻觉。

**Result:** 通过在Tri-HE上的综合评估，发现现有LVLMs中的关系幻觉问题甚至比对象幻觉更严重，这突出了一个先前被忽视的、影响可靠LVLMs的问题。此外，基于这些发现，设计了一种简单的无训练方法，有效缓解了LVLMs的幻觉。

**Conclusion:** 关系幻觉在现有大型视觉-语言模型中比对象幻觉更为严重，这是一个被忽视的关键问题，需要更多关注以实现可靠的LVLMs。

> **ai_Abstract:** 本文针对大型视觉-语言模型（LVLMs）中现有幻觉评估主要集中于对象幻觉而忽视关系幻觉的问题，提出了一种统一框架，通过从LVLMs响应中提取（对象、关系、对象）三元组来同时评估对象和关系幻觉。基于此框架，引入了Tri-HE基准。研究发现，关系幻觉在现有LVLMs中比对象幻觉更为严重，揭示了一个被忽视的重要问题。此外，作者还基于研究结果设计了一种有效的无训练幻觉缓解方法。

> **摘要翻译:** 尽管大型视觉-语言模型（LVLMs）在视觉-语言推理方面表现出色，但它们可能会生成图像中不存在的幻觉内容。大多数现有的LVLM幻觉基准仅限于评估与对象相关的幻觉。然而，两个对象之间关系（即关系幻觉）的潜在幻觉仍缺乏研究。为了弥补这一点，我们设计了一个统一的框架来同时测量LVLMs中的对象和关系幻觉。我们框架的核心思想是通过从LVLMs的响应中提取（对象、关系、对象）三元组来评估幻觉，使其易于推广到不同的视觉-语言任务。基于我们的框架，我们进一步引入了Tri-HE，一个新颖的三元组级别幻觉评估基准，可以同时用于研究对象和关系幻觉。通过在Tri-HE上的综合评估，我们观察到现有LVLMs中的关系幻觉问题甚至比对象幻觉更严重，这突出了一个先前被忽视的、影响可靠LVLMs的问题。此外，基于我们的发现，我们设计了一种简单的无训练方法，有效缓解了LVLMs的幻觉。我们的数据集和用于实验复现的代码可在https://github.com/wujunjie1998/Tri-HE公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [677] [SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning](https://arxiv.org/abs/2410.14987)
> *SeaS：基于分离与共享微调的少样本工业异常图像生成*

*Zhewei Dai, Shilei Zeng, Haotian Liu, Xurui Li, Feng Xue, Yu Zhou* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 工业异常生成, 少样本学习, 统一生成模型, U-Net, 异常掩码

**Comment:** Accepted at ICCV2025

> **TL;DR:** SeaS是一个统一的工业生成模型，能够自动创建多样化的异常、真实的正常产品和精确的异常掩码，解决了现有方法生成能力有限或依赖大量特定模型的问题。

**AI_Comments:** SeaS的创新之处在于提出了一个统一的生成模型，能够同时处理多种工业图像生成任务，包括异常、正常产品和掩码生成。其核心贡献在于利用U-Net的差异化学习能力，并通过UA文本提示、DA损失和NA损失，实现了异常属性的解耦和重组，以及正常模式的对齐。这使得模型具备了更强的泛化能力，尤其是在少样本甚至零样本异常生成方面具有潜力。该方法有效解决了现有方法生成能力受限或模型数量庞大的问题，对工业缺陷检测和质量控制领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究大多专注于特定任务（仅异常或正常产品）或每种异常类型需要单独模型，导致生成能力有限或依赖大量特定模型。因此，需要一个统一的模型来生成多样化异常、正常产品和精确异常掩码。

**Method:** 本文提出了SeaS模型，利用U-Net的差异化学习能力来捕捉正常产品和多样化异常的视觉特征。具体方法包括：1) 引入非平衡异常（UA）文本提示，包含一个正常token和多个异常token。2) 提出解耦异常对齐（DA）损失，将异常属性解耦并绑定到UA的不同异常token，从而通过重组属性创建未见过的异常。3) 提出正常图像对齐（NA）损失，将正常token与正常模式对齐，使生成的正常产品全局一致且局部多样。4) 通过融合判别性U-Net特征和高分辨率VAE特征，生成精确的异常掩码。

**Result:** SeaS在工业生成方面树立了新基准，显著增强了下游应用：基于合成的AD方法像素级AP平均提升+8.66%；无监督AD方法图像级AP平均提升+1.10%；监督分割模型IoU平均提升+12.79%。

**Conclusion:** SeaS是一个统一的工业生成模型，能够有效生成多样化的异常、真实的正常产品和精确的异常掩码，显著提升了下游检测和分割任务的性能，并为工业生成设定了新基准。

> **ai_Abstract:** SeaS是一个创新的统一工业生成模型，旨在解决现有方法在生成多样化异常和正常产品方面的局限性。它利用U-Net的差异化学习能力，并引入了非平衡异常文本提示、解耦异常对齐损失和正常图像对齐损失。这些机制使得SeaS能够生成多样化的异常、真实的正常产品以及精确的异常掩码，甚至能够通过属性重组生成未见过的异常。实验证明，SeaS显著提升了下游异常检测和分割任务的性能，为工业生成领域设立了新的基准。

> **摘要翻译:** 我们引入了SeaS，一个统一的工业生成模型，用于自动创建多样化的异常、真实的正常产品和精确的异常掩码。尽管存在大量研究，但大多数工作要么专注于特定任务，即只关注异常或正常产品，要么每种异常类型都需要单独的模型。因此，现有方法要么生成能力有限，要么依赖于大量的特定异常模型。我们证明了U-Net的差异化学习能力能够捕捉到略有变化的正常产品和多样化异常的独特视觉特征，使我们能够构建一个适用于所有任务的统一模型。具体来说，我们首先引入了一个非平衡异常（UA）文本提示，包含一个正常token和多个异常token。更重要的是，我们的解耦异常对齐（DA）损失将异常属性解耦并绑定到UA的不同异常token，使SeaS能够通过重组这些属性来创建未见过的异常。此外，我们的正常图像对齐（NA）损失将正常token与正常模式对齐，使得生成的正常产品全局一致且局部多样。最后，SeaS通过融合判别性U-Net特征和高分辨率VAE特征来生成精确的异常掩码。SeaS为工业生成树立了新基准，显著增强了下游应用，在基于合成的AD方法中，像素级AP平均提升+8.66%；在无监督AD方法中，图像级AP平均提升+1.10%；在监督分割模型中，IoU平均提升+12.79%。代码可在https://github.com/HUST-SLOW/SeaS获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [680] [Demographic-aware fine-grained classification of pediatric wrist fractures](https://arxiv.org/abs/2507.12964)
> *人口统计学感知的儿童腕部骨折细粒度分类*

*Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati, Sher Muhammad Daudpota* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 腕部骨折, 细粒度分类, 元数据融合, 诊断准确性, 计算机视觉

**Comment:** 

> **TL;DR:** 本研究提出了一种结合患者元数据和细粒度识别的方法，以解决儿童腕部骨折诊断中数据集有限和传统方法不足的问题，显著提高了诊断准确性。

**AI_Comments:** 本文的创新点在于将患者元数据与X射线图像结合进行腕部骨折的细粒度分类，尤其是在有限数据集的情况下。这种多模态融合的方法为解决医学图像领域数据稀缺的挑战提供了新的思路。其重要性在于提高了儿童腕部骨折诊断的准确性，有助于减轻医生负担。该研究的局限性可能在于其结果对特定数据集的依赖性，以及元数据获取的普遍性。

<details>
  <summary>Details</summary>

**Motivation:** 腕部病理学，尤其是儿童骨折，诊断耗时且需要专业知识。计算机视觉虽有潜力，但在医学成像中面临数据集稀缺的挑战。仅依赖图像数据不足以应对多样化的数据类型。

**Method:** 本研究采用多方面方法：1) 将问题视为细粒度识别任务，以识别传统CNNs易忽略的细微X射线病理；2) 通过将患者元数据与X射线图像融合来增强网络性能；3) 不在粗粒度数据集（如ImageNet）上进行预训练，而是使用在细粒度数据集上训练的权重。这是元数据集成首次应用于腕部病理学。

**Result:** 结果显示，细粒度策略和元数据集成在有限数据集上将诊断准确率提高了2%，在更大的专注于骨折的数据集上提高了10%以上。

**Conclusion:** 通过结合细粒度识别和患者元数据，即使在数据集有限的情况下，也能显著提高儿童腕部骨折的诊断准确性，证明了多模态方法在医学图像分析中的有效性。

> **ai_Abstract:** 本研究旨在解决儿童腕部骨折诊断中数据集有限和传统计算机视觉方法不足的问题。作者提出了一种多方面的方法，将细粒度识别与患者元数据（如人口统计学信息）融合，并利用在细粒度数据集上预训练的权重。该方法在有限数据下将诊断准确率提高了2%，在更大数据集下提高了10%以上，证明了结合多模态数据和细粒度学习在医学图像诊断中的有效性。

> **摘要翻译:** 腕部病理学，尤其是在骨折病例中占多数的儿童中，经常被观察到。然而，诊断这些疾病耗时且需要专业知识。计算机视觉展现出有前景的途径，但依赖于大量数据集的可用性，这是医学成像中的一个显著挑战。因此，仅仅依靠一种模态，例如图像，被证明是不够的，尤其是在一个数据类型多样且丰富的时代。在本研究中，我们采用多方面方法来解决使用极有限数据集识别腕部病理的挑战。首先，我们将问题视为一个细粒度识别任务，旨在识别传统CNN容易忽略的细微X射线病理。其次，我们通过将患者元数据与X射线图像融合来增强网络性能。第三，我们没有在ImageNet等粗粒度数据集上进行预训练，而是使用了在细粒度数据集上训练的权重。虽然元数据集成已在其他医学领域中使用，但这在腕部病理学中是首次应用。我们的结果表明，细粒度策略和元数据集成在有限数据集上将诊断准确率提高了2%，在更大的专注于骨折的数据集上提高了10%以上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [681] [VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding](https://arxiv.org/abs/2507.13353)
> *VideoITG：基于指令时间定位的多模态视频理解*

*Shihao Wang, Guo Chen, De-an Huang, Zhiqi Li, Minghan Li, Guilin Li, Jose M. Alvarez, Lei Zhang, Zhiding Yu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 视频大语言模型, 时间定位, 帧选择, 多模态视频理解, 指令学习

**Comment:** Technical Report

> **TL;DR:** VideoITG提出了一种通过指令引导的时间定位来选择信息量大的视频帧的方法，显著提升了视频大语言模型的性能。

**AI_Comments:** VideoITG的创新之处在于提出了指令引导的时间定位和VidThinker自动化标注框架，这为Video-LLMs在复杂长视频理解中选择信息量大的帧提供了一种有效且可扩展的解决方案。其构建的大规模数据集VideoITG-40K也为该领域的研究提供了宝贵的资源。该方法的即插即用特性增加了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在长视频理解中难以处理复杂场景，因为它们主要采用无监督学习范式，并且在选择信息量大且相关的视频帧方面存在局限性，这会影响视频大语言模型（Video-LLMs）的性能。

**Method:** 本文提出了Instructed Temporal Grounding for Videos (VideoITG)，其核心是VidThinker管道，一个模仿人类标注过程的自动化标注框架。VidThinker首先生成基于指令的详细片段级字幕，然后通过指令引导的推理检索相关视频片段，最后进行细粒度帧选择以确定最具信息量的视觉证据。利用VidThinker，作者构建了包含4万个视频和50万个指令时间定位标注的VideoITG-40K数据集。此外，还设计了一个即插即用的VideoITG模型，利用Video-LLMs的视觉语言对齐和推理能力进行判别性帧选择。

**Result:** VideoITG与Video-LLMs结合后，在多个多模态视频理解基准测试中实现了持续的性能提升。

**Conclusion:** VideoITG在视频理解方面展现出卓越的性能和巨大潜力，通过定制化的帧采样和指令引导的时间定位，显著提升了Video-LLMs在复杂长视频理解中的表现。

> **ai_Abstract:** 本文提出了VideoITG，一种基于指令时间定位的多模态视频理解方法，旨在解决现有Video-LLMs在长视频理解中帧选择效率低下的问题。VideoITG的核心是VidThinker管道，一个自动化标注框架，它通过指令引导的字幕生成、视频片段检索和细粒度帧选择来模仿人类标注过程。利用VidThinker，作者构建了VideoITG-40K数据集，并设计了一个即插即用的VideoITG模型。实验结果表明，VideoITG与Video-LLMs结合后，在多个多模态视频理解基准测试中实现了显著的性能提升。

> **摘要翻译:** 最近的研究表明，选择信息丰富且相关的视频帧可以显著提高视频大语言模型（Video-LLMs）的性能。当前方法，例如减少帧间冗余、使用单独模型进行图像-文本相关性评估或利用时间视频定位进行事件定位，主要采用无监督学习范式，但它们在处理长视频理解中的复杂场景时存在困难。我们提出了视频指令时间定位（VideoITG），其特点是根据用户指令定制帧采样。VideoITG的核心是VidThinker管道，这是一个明确模仿人类标注过程的自动化标注框架。首先，它根据指令生成详细的片段级字幕；然后，它通过指令引导的推理检索相关的视频片段；最后，它执行细粒度帧选择，以精确定位最具信息量的视觉证据。利用VidThinker，我们构建了VideoITG-40K数据集，包含4万个视频和50万个指令时间定位标注。然后，我们设计了一个即插即用的VideoITG模型，该模型利用Video-LLMs的视觉语言对齐和推理能力，以判别方式进行有效的帧选择。与Video-LLMs结合后，VideoITG在多个多模态视频理解基准测试中取得了持续的性能改进，显示了其优越性和在视频理解方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [689] [GLAD: Generalizable Tuning for Vision-Language Models](https://arxiv.org/abs/2507.13089)
> *GLAD: 可泛化视觉-语言模型微调*

*Yuqi Peng, Pengfei Wang, Jianzhuang Liu, Shifeng Chen* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 视觉-语言模型, 提示微调, LoRA, 梯度正则化, 泛化

**Comment:** ICCV 2025 workshop

> **TL;DR:** GLAD提出一种结合LoRA和梯度正则化的简单通用框架，解决了视觉-语言模型少样本微调中的过拟合和泛化性问题。

**AI_Comments:** GLAD的创新点在于结合了LoRA的简洁高效与梯度正则化来解决少样本学习中的过拟合问题，同时提升了模型的泛化能力。其通用性和在多项泛化任务上的优异表现，使其在视觉-语言模型微调领域具有重要意义，尤其是在数据稀缺的实际应用场景中。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言模型（如CLIP）的提示微调方法在少样本场景下容易过拟合，导致模型对输入域的变化敏感；同时，这些方法依赖复杂的任务特定模型架构和敏感的超参数调优，严重限制了它们的通用适用性。

**Method:** 本文提出GLAD（Generalizable LoRA tuning with RegulArized GraDient），一个更简单、更通用的框架。它首先应用LoRA，并为了解决LoRA在少样本学习中仍易过拟合的问题，引入了一种基于梯度的正则化技术，引导优化轨迹找到对数据分布变化更鲁棒的稳定参数区域。

**Result:** 在15个基准数据集上进行的广泛实验表明，GLAD在基类到新类泛化、图像域泛化和跨数据集泛化方面均优于先前的微调方法。

**Conclusion:** GLAD提供了一个更简单、更通用且鲁棒的视觉-语言模型微调框架，有效解决了少样本场景下的过拟合和泛化问题，并在多种泛化能力上表现出色。

> **ai_Abstract:** 本文提出了GLAD（Generalizable LoRA tuning with RegulArized GraDient），一个用于视觉-语言模型微调的通用框架。针对现有提示微调在少样本场景中易过拟合且通用性差的问题，GLAD结合了LoRA和一种创新的梯度正则化技术。该正则化技术旨在引导模型优化到一个对数据分布变化更鲁棒的稳定区域。实验结果表明，GLAD在多项泛化能力上显著优于现有方法，为视觉-语言模型的有效迁移学习提供了更简单、更鲁棒的解决方案。

> **摘要翻译:** 预训练的视觉-语言模型，如CLIP，展现出令人印象深刻的零样本识别能力，并且可以通过提示微调轻松地迁移到特定的下游任务，即使训练数据有限。然而，现有的提示微调方法面临两大挑战：（1）在少样本场景中，数据稀缺常导致过拟合，使得模型对输入域的变化敏感。（2）为了缓解过拟合，这些方法通常依赖复杂的任务特定模型架构和敏感的超参数调优，严重限制了它们的通用适用性。为了解决这些问题，我们提出了一个更简单、更通用的框架，名为GLAD（Generalizable LoRA tuning with RegulArized GraDient）。我们表明，仅仅应用LoRA就能在下游任务中实现与当前最先进的基于提示的方法相当的性能。虽然LoRA有效且易于使用，但在少样本学习场景中仍然容易过拟合。为了降低这种风险，我们引入了一种基于梯度的正则化技术。这项技术有效地引导优化轨迹，鼓励模型找到一个对数据分布变化具有鲁棒性的更稳定参数区域。通过在15个基准数据集上进行的广泛实验，我们证明了GLAD在基类到新类泛化、图像域泛化和跨数据集泛化方面均优于以前的微调方法。代码将公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [690] [Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation](https://arxiv.org/abs/2507.12755)
> *领域增强双分支模型用于高效可解释的事故预测*

*Yanchen Guan, Haicheng Liao, Chengyue Wang, Bonan Wang, Jiaxun Zhang, Jia Hu, Zhenning Li* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 交通事故预测, 双分支模型, 多模态融合, 大型模型, 可解释性

**Comment:** 

> **TL;DR:** 该论文提出了一种领域增强的双分支模型，通过融合视觉和文本数据，利用大型模型和提示工程，实现了高效且可解释的交通事故预测，并在基准数据集上达到了最先进的性能。

**AI_Comments:** 该论文的创新之处在于其双分支架构，能够有效融合异构的多模态数据（视觉和文本），并利用大型模型（GPT-4o, Long-CLIP）进行特征聚合和提示工程，这为交通事故预测带来了新的范式。其强调效率和可解释性，对于自动驾驶的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发精确且计算高效的交通事故预测系统对于当代自动驾驶技术至关重要，能够实现及时干预和损失预防。

**Method:** 本文提出了一种采用双分支架构的事故预测框架，有效整合了行车记录仪视频的视觉信息和事故报告的结构化文本数据。此外，还引入了一种特征聚合方法，通过大型模型（GPT-4o, Long-CLIP）促进多模态输入的无缝集成，并辅以有针对性的提示工程策略，以产生可操作的反馈和标准化的事故档案。

**Result:** 在基准数据集（DAD、CCD和A3D）上进行的综合评估验证了该方法具有卓越的预测精度、增强的响应能力、降低的计算开销和改进的可解释性。

**Conclusion:** 该方法在交通事故预测方面确立了最先进性能的新基准。

> **ai_Abstract:** 本文提出了一种名为“领域增强双分支模型”的交通事故预测框架。该模型采用双分支架构，能够有效融合行车记录仪视频的视觉信息和事故报告的文本数据。通过引入基于大型模型（GPT-4o, Long-CLIP）和提示工程的特征聚合方法，实现了多模态输入的无缝集成，并能生成可操作的反馈。在DAD、CCD和A3D等基准数据集上的评估表明，该方法在预测精度、响应能力、计算效率和可解释性方面均表现优越，为交通事故预测领域树立了新的性能标杆。

> **摘要翻译:** 开发精确且计算高效的交通事故预测系统对于当代自动驾驶技术至关重要，能够实现及时干预和损失预防。在本文中，我们提出了一种事故预测框架，采用双分支架构，有效整合了来自行车记录仪视频的视觉信息和来自事故报告的结构化文本数据。此外，我们引入了一种特征聚合方法，通过大型模型（GPT-4o，Long-CLIP）促进多模态输入的无缝集成，并辅以有针对性的提示工程策略，以产生可操作的反馈和标准化的事故档案。在基准数据集（DAD、CCD和A3D）上进行的综合评估验证了我们方法的卓越预测精度、增强的响应能力、降低的计算开销和改进的可解释性，从而为交通事故预测的最新性能建立了新的基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [692] [LanePerf: a Performance Estimation Framework for Lane Detection](https://arxiv.org/abs/2507.12894)
> *LanePerf：车道线检测的性能估计框架*

*Yin Wu, Daniel Slieter, Ahmed Abouelazm, Christian Hubschneider, J. Marius Zöllner* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 车道线检测, 性能估计, 域转移, 无标签评估, LanePerf

**Comment:** Accepted in IEEE ITSC 2025

> **TL;DR:** LanePerf是一个新的框架，通过集成图像和车道特征，实现了在没有地面真值标签的情况下，对车道线检测模型在域转移场景下的性能进行高效、鲁棒的估计。

**AI_Comments:** 该论文的创新点在于提出了LanePerf框架，它首次将图像和车道特征相结合，并通过DeepSets架构有效处理了车道线检测中的零车道和大幅度域转移问题，实现了无标签的性能估计。这对于ADAS和自动驾驶系统的开发具有重要意义，能够显著降低模型测试和部署的资源成本，提升系统在复杂环境下的鲁棒性和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 车道线检测模型在部署到新环境时，由于域转移，其可靠性会受到影响。确保模型鲁棒性和安全性通常需要大量资源来收集和标注目标域数据。在没有地面真值标签的情况下估计模型性能是一种有前景的替代方案，但在车道线检测领域尚未得到充分探索。现有的图像分类性能估计方法不直接适用于车道线检测任务。

**Method:** 本文首先将五种性能良好的图像分类性能估计方法应用于车道线检测，建立基线。为了解决先前方法仅依赖softmax分数或车道特征的局限性，本文提出了一个新的车道性能估计框架（LanePerf），该框架使用预训练的图像编码器和基于DeepSets的架构，整合了图像和车道特征，有效处理了零车道检测场景和大的域转移情况。

**Result:** 在OpenLane数据集上的大量实验表明，LanePerf在不同域转移（场景、天气、时间）下表现优于所有基线，实现了更低的平均绝对误差（MAE）0.117和更高的Spearman秩相关系数0.727。

**Conclusion:** 这些发现为ADAS中鲁棒、无标签的性能估计铺平了道路，支持了在具有挑战性的驾驶场景中更高效的测试和更高的安全性。

> **ai_Abstract:** 该论文提出了LanePerf，一个用于车道线检测的性能估计框架，旨在解决在域转移场景下，无需地面真值标签即可评估模型鲁棒性的挑战。它通过整合图像和车道特征，并采用预训练的图像编码器和DeepSets架构，改进了现有方法。实验证明，LanePerf在不同域转移条件下，性能优于基线，为ADAS中的高效、无标签性能估计提供了解决方案，提高了测试效率和驾驶安全性。

> **摘要翻译:** 车道线检测是高级驾驶辅助系统（ADAS）和自动驾驶系统（ADS）的关键组成部分，为横向控制提供必要的空间信息。然而，域转移常常在模型部署到新环境时损害其可靠性。确保车道线检测模型的鲁棒性和安全性通常需要收集和标注目标域数据，这是一种资源密集型工作。在没有地面真值标签的情况下估计模型性能为高效的鲁棒性评估提供了一种有前景的替代方案，但在车道线检测领域尚未得到充分探索。虽然之前的工作已经解决了图像分类中的性能估计问题，但这些方法不能直接应用于车道线检测任务。本文首先将五种性能良好的性能估计方法从图像分类适应到车道线检测，构建了一个基线。针对先前方法仅依赖softmax分数或车道特征的局限性，我们进一步提出了一个新的车道性能估计框架（LanePerf），该框架使用预训练的图像编码器和基于DeepSets的架构，整合了图像和车道特征，有效处理了零车道检测场景和大的域转移情况。在OpenLane数据集上进行的广泛实验，涵盖了不同的域转移（场景、天气、小时），结果表明我们的LanePerf优于所有基线，实现了更低的平均绝对误差（MAE）0.117和更高的Spearman秩相关系数0.727。这些发现为ADAS中鲁棒、无标签的性能估计铺平了道路，支持了在具有挑战性的驾驶场景中更高效的测试和更高的安全性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [695] [Predicting 3D Rigid Body Dynamics with Deep Residual Network](https://arxiv.org/abs/2407.18798)
> *使用深度残差网络预测三维刚体动力学*

*Abiodun Finbarrs Oketunji* | **Category: cs.CV, cs.GR, cs.LG, cs.SE, I.2.7** | **Updated: 2024-07-09**

**Keywords:** 深度残差网络, 刚体动力学, 物理模拟, 机器学习, 三维预测

**Comment:** 

> **TL;DR:** 本研究利用深度残差网络预测三维相互作用刚体的动力学，结合C++模拟器生成数据，并在位置和方向预测上取得显著优于基线方法的结果，展示了其在复杂物理系统建模中的潜力。

**AI_Comments:** 该论文创新性地将深度残差网络应用于复杂的三维刚体动力学预测，并结合了传统的物理模拟器来生成高质量的训练数据，这是一种有效的物理信息机器学习方法。其在预测精度上的显著提升（25%优于基线）表明了该方法在处理复杂物理现象方面的潜力。未来的工作将侧重于提高模型对多样化物体形状和材料的泛化能力，这将是该技术走向实际应用的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是探索深度残差网络在预测相互作用的三维刚体动力学方面的应用潜力，以解决复杂物理系统建模的挑战。

**Method:** 本研究提出一个结合C++物理模拟器和PyTorch构建的深度学习模型的框架。C++模拟器用于生成包含线性运动、角运动、弹性碰撞、流体摩擦、重力效应和阻尼的训练数据。深度残差网络由输入层、多个残差块和输出层组成，用于处理三维动力学的复杂性。

**Result:** 该模型在包含10,000个模拟场景的数据集上进行评估，每个场景涉及3-5个相互作用的刚体。模型在位置预测上实现了0.015的均方误差，在方向预测上实现了0.022的均方误差，比基线方法提高了25%。结果表明网络能够捕捉复杂的物理相互作用，特别是在预测弹性碰撞和旋转动力学方面取得了成功。

**Conclusion:** 该工作通过展示深度残差网络在建模复杂三维物理系统方面的巨大潜力，为物理信息机器学习做出了重大贡献。研究还讨论了方法的局限性，并提出了未来改进泛化能力的方向。

> **ai_Abstract:** 本研究利用深度残差网络预测三维刚体动力学。通过结合C++物理模拟器生成训练数据，并构建基于PyTorch的深度残差网络模型，该研究在位置和方向预测上分别达到了0.015和0.022的均方误差，相比基线方法提升25%。模型在捕捉复杂物理交互，特别是弹性碰撞和旋转动力学方面表现出色，为物理信息机器学习在复杂三维物理系统建模中的应用提供了有力证据。

> **摘要翻译:** 本研究探讨了深度残差网络在预测相互作用三维刚体动力学方面的应用。我们提出了一个结合C++实现的3D物理模拟器与使用PyTorch构建的深度学习模型的框架。模拟器生成包含线性运动、角运动、弹性碰撞、流体摩擦、重力效应和阻尼的训练数据。我们的深度残差网络由输入层、多个残差块和输出层组成，旨在处理三维动力学的复杂性。我们使用包含10,000个模拟场景的数据集评估了网络的性能，每个场景涉及3-5个相互作用的刚体。该模型在位置预测上实现了0.015的均方误差，在方向预测上实现了0.022的均方误差，比基线方法提高了25%。我们的结果表明，该网络能够捕捉复杂的物理相互作用，在预测弹性碰撞和旋转动力学方面尤其成功。这项工作通过展示深度残差网络在建模复杂三维物理系统方面的巨大潜力，为物理信息机器学习做出了重大贡献。我们讨论了该方法的局限性，并提出了未来改进对更多样化物体形状和材料的泛化能力的方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [702] [Cascaded Multi-Scale Attention for Enhanced Multi-Scale Feature Extraction and Interaction with Low-Resolution Images](https://arxiv.org/abs/2412.02197)
> *用于增强低分辨率图像多尺度特征提取与交互的级联多尺度注意力机制*

*Xiangyong Lu, Masanori Suganuma, Takayuki Okatani* | **Category: cs.CV** | **Updated: 2025-07-17**

**Keywords:** 多尺度注意力, 低分辨率图像, 特征提取, 人体姿态估计, CNN-ViT

**Comment:** 9 pages, 4 figures, 5 tables

> **TL;DR:** 提出了一种名为级联多尺度注意力（CMSA）的新机制，用于CNN-ViT混合架构，以有效处理低分辨率图像，并在人体姿态估计等任务中超越现有SOTA方法。

**AI_Comments:** 该论文的创新点在于提出了CMSA机制，它巧妙地结合了分组多头自注意力、窗口局部注意力和级联融合，实现了在不进行下采样的情况下对低分辨率图像的多尺度特征进行高效提取和交互。这对于实际应用中常见的低分辨率图像处理问题具有重要意义，特别是在资源受限或高分辨率图像难以获取的场景。其在减少参数的同时超越SOTA的性能，也显示了其高效性。

<details>
  <summary>Details</summary>

**Motivation:** 在图像识别任务（如人体姿态估计）中，相机常捕获低分辨率物体，这使得提取和利用多尺度特征变得困难，而多尺度特征对于精确推断至关重要。

**Method:** 我们提出了一种名为级联多尺度注意力（CMSA）的新注意力机制，专为CNN-ViT混合架构设计，以有效处理低分辨率输入。CMSA通过结合分组多头自注意力机制、基于窗口的局部注意力以及不同尺度的多尺度特征的级联融合来实现多尺度特征的提取和无缝集成，无需对输入图像或特征图进行下采样。

**Result:** 实验结果表明，所提出的方法在人体姿态估计和头部姿态估计等领域，以更少的参数优于现有最先进的方法。

**Conclusion:** CMSA机制能够有效处理低分辨率图像的多尺度特征提取和交互，并在实际应用中展现出广阔潜力，尤其是在无法捕获高分辨率图像的场景。

> **ai_Abstract:** 该论文提出了一种名为级联多尺度注意力（CMSA）的新型注意力机制，旨在解决低分辨率图像在图像识别任务中多尺度特征提取的挑战。CMSA专为CNN-ViT混合架构设计，通过结合分组多头自注意力、窗口局部注意力和级联特征融合，实现在不进行下采样的情况下有效提取和整合多尺度特征。实验证明，CMSA在人体姿态估计等任务上，以更少的参数优于现有SOTA方法，显示出其在实际应用中的巨大潜力。

> **摘要翻译:** 在图像识别任务的实际应用中，例如人体姿态估计，相机通常以低分辨率捕获物体，例如人体。这种场景对提取和利用多尺度特征提出了挑战，而这对于精确推断通常至关重要。为了解决这一挑战，我们提出了一种新的注意力机制，名为级联多尺度注意力（CMSA），专为CNN-ViT混合架构量身定制，以有效处理低分辨率输入。CMSA的设计使得无需对输入图像或特征图进行下采样即可实现跨各种尺度的特征提取和无缝集成。这是通过分组多头自注意力机制与基于窗口的局部注意力以及不同尺度的多尺度特征的级联融合的新颖组合实现的。这种架构允许有效处理不同尺度的特征，增强模型执行人体姿态估计、头部姿态估计等任务的能力，尤其是在处理低分辨率图像时。我们的实验结果表明，所提出的方法在这些领域以更少的参数优于现有最先进的方法，展示了其在无法捕获高分辨率图像的实际场景中的广泛应用潜力。代码可在 https://github.com/xyongLu/CMSA 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [6] ["How to Explore Biases in Speech Emotion AI with Users?" A Speech-Emotion-Acting Study Exploring Age and Language Biases](https://arxiv.org/abs/2507.12580)
> *如何与用户一起探索语音情感AI中的偏见？一项探索年龄和语言偏见的语音情感表演研究*

*Josephine Beatrice Skovbo Borre, Malene Gorm Wold, Sara Kjær Rasmussen, Ilhan Aslan* | **Category: cs.HC** | **Updated: 2025-07-16**

**Keywords:** 语音情感识别, 偏见, 年龄, 语言, 人机交互

**Comment:** 20 pages

> **TL;DR:** 本研究探索了语音情感AI在不同年龄（青少年和55岁以上成人）和语言（丹麦语和英语）中的偏见，发现模型在跨语言和年龄上表现出一定的鲁棒性，但高唤醒度情感识别存在局限性。

**AI_Comments:** 这项研究的创新之处在于其独特的用户参与式实验设计，通过让用户主动表演情感并实时记录人机意图差距，直接评估了SER系统在不同用户群体和语言上的偏见。它超越了传统的准确率指标，强调了以人为中心、包容性SER模型的重要性，对于理解和改进情感AI的公平性具有重要意义。尽管存在自我录音和任务执行不一致的局限性，但其发现模型在跨语言和年龄上的鲁棒性以及对高唤醒度情感识别的挑战，为未来研究提供了宝贵方向。

<details>
  <summary>Details</summary>

**Motivation:** 大多数语音情感识别（SER）系统是在自发的、单语英语数据上训练的，但对青少年和55岁以上成人等用户群体以及不同语言（丹麦语和英语）中故意表达的情感语音的解释能力探索不足。

**Method:** 开发了一种新颖的实验范式，结合定制的用户界面和实时SER预测与数据记录后端。参与者（12名青少年和12名55岁以上成人）被要求通过故意表达四种情感目标来击中效价-唤醒空间中的视觉目标。

**Result:** 结果表明，与预期相反，语言或年龄组之间没有显著差异，模型解释在跨语言和年龄上表现出一定程度的鲁棒性。但在高唤醒度情感识别方面存在一些局限。

**Conclusion:** 研究强调需要超越以系统为中心的准确性指标，采用更具包容性、以人为中心的SER模型。通过将情感表达视为目标导向的行为，并记录人类意图与机器解释之间的实时差距，揭示了情感错位的风险。

> **ai_Abstract:** 这项研究通过一项语音情感表演实验，探索了语音情感AI对青少年和55岁以上成人以及丹麦语和英语中刻意表达情感的解释能力，旨在揭示年龄和语言偏见。研究开发了一个结合用户界面和实时SER预测的实验范式。结果显示，模型在跨语言和年龄上表现出一定的鲁棒性，未发现显著偏见，但在高唤醒度情感识别上存在局限。研究强调了转向以人为中心的SER模型的重要性，以减少情感错位风险。

> **摘要翻译:** 本研究探讨了年龄和语言如何影响情感的刻意声音表达，解决了语音情感识别（SER）中未充分探索的用户群体：青少年（N = 12）和55岁以上成人（N = 12）。虽然大多数SER系统是在自发的、单语英语数据上训练的，但我们的研究评估了这些模型如何解释跨年龄组和语言（丹麦语和英语）的刻意表演的情感语音。为了支持这一点，我们开发了一种新颖的实验范式，结合了定制的用户界面和用于实时SER预测和数据记录的后端。参与者被要求通过刻意表达四种情感目标来击中效价-唤醒空间中的视觉目标。尽管局限性包括对自我管理的语音录制的一些依赖以及任务执行的不一致，但结果表明，与预期相反，语言或年龄组之间没有显著差异，并且模型解释在跨语言和年龄上表现出一定程度的鲁棒性。尽管在高唤醒度情感识别方面存在一些明显的局限性。我们的定性发现强调，需要超越以系统为中心的准确性指标，并采用更具包容性、以人为中心的SER模型。通过将情感表达视为目标导向的行为，并记录人类意图与机器解释之间的实时差距，我们揭示了情感错位的风险。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [22] [Smart Glasses for CVI: Co-Designing Extended Reality Solutions to Support Environmental Perception by People with Cerebral Visual Impairment](https://arxiv.org/abs/2506.19210)
> *针对CVI的智能眼镜：协同设计扩展现实解决方案以支持脑性视力障碍者的环境感知*

*Bhanuka Gamage, Nicola McDowell, Dijana Kovacic, Leona Holloway, Thanh-Toan Do, Nicholas Price, Arthur Lowery, Kim Marriott* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 脑性视力障碍, 智能眼镜, 扩展现实, 协同设计, 环境感知

**Comment:** Author's accepted version of a paper at ASSETS 2025 (October, 2025)

> **TL;DR:** 本研究通过与两名CVI患者的协同设计，探讨了智能眼镜如何帮助他们更好地感知和互动周围环境，发现智能眼镜能有效解决寻找物体、阅读、识别人脸和管理感官压力等挑战。

**AI_Comments:** 这项研究的创新之处在于其以用户为中心的协同设计方法，直接与CVI患者合作，确保了解决方案的实用性和相关性。它填补了辅助技术研究中CVI领域长期存在的空白，并及时地将新兴的智能眼镜技术应用于一个未被充分关注的需求。研究结果为未来为CVI患者开发辅助技术提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 脑性视力障碍（CVI）正成为导致视力障碍的主要原因，但在辅助技术研究中却未得到充分关注。CVI影响高级视觉处理，包括物体识别、面部感知和复杂环境中的注意力。本研究旨在探讨智能眼镜如何支持CVI患者理解和互动其周围环境。

**Method:** 本文通过与两名CVI成年患者进行协同设计研究。研究遵循双钻石设计框架，包括为期两周的日记研究、两次概念研讨会以及十次使用Apple Vision Pro的迭代开发会议。

**Result:** 研究结果表明，智能眼镜能有效解决CVI患者在定位物体、阅读文本、识别人、参与对话和管理感官压力方面的关键挑战。

**Conclusion:** 随着智能眼镜的快速发展以及CVI作为一种独特视力障碍形式的日益被认可，这项研究及时地解决了技术与需求之间一个未被充分探索的交叉领域。

> **ai_Abstract:** 这项研究通过与两名脑性视力障碍（CVI）成年患者的协同设计，探索了智能眼镜（头戴式扩展现实显示器）如何帮助他们更好地感知和互动周围环境。研究采用了双钻石设计框架，包括日记研究、概念研讨会和迭代开发，并使用了Apple Vision Pro。结果表明，智能眼镜能有效解决CVI患者在物体定位、文本阅读、人脸识别、对话参与和感官压力管理方面的关键挑战，强调了在智能眼镜技术进步和CVI认知提高背景下，该研究在技术与需求交叉领域的重要性。

> **摘要翻译:** 脑性视力障碍（CVI）正成为导致视力障碍的主要原因，但在辅助技术研究中却未得到充分关注。与眼部疾病不同，CVI影响高级视觉处理——影响物体识别、面部感知以及复杂环境中的注意力。本文提出了一项与两名CVI成年患者进行的协同设计研究，探讨了智能眼镜（即头戴式扩展现实显示器）如何支持他们理解和互动周围环境。在双钻石设计框架的指导下，我们进行了为期两周的日记研究、两次概念研讨会以及十次使用Apple Vision Pro的迭代开发会议。我们的研究结果表明，智能眼镜能有效解决在定位物体、阅读文本、识别人、参与对话和管理感官压力方面的关键挑战。随着智能眼镜的快速发展以及CVI作为一种独特视力障碍形式的日益被认可，这项研究及时地解决了技术与需求之间一个未被充分探索的交叉领域。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [26] [Design Patterns of Human-AI Interfaces in Healthcare](https://arxiv.org/abs/2507.12721)
> *医疗领域人机交互界面的设计模式*

*Rui Sheng, Chuhan Shi, Sobhan Lotfi, Shiyi Liu, Adam Perer, Huamin Qu, Furui Cheng* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 人机交互界面, 医疗保健, 设计模式, AI, 用户体验

**Comment:** 

> **TL;DR:** 本文提出了医疗领域人机交互界面的设计模式，并通过访谈和研讨会进行了评估。

**AI_Comments:** 这篇论文的创新点在于系统性地总结了医疗领域人机交互界面的设计模式，为该领域的设计实践提供了具体指导。通过结合专家访谈和用户研讨会，确保了设计模式的实用性和有效性。其重要性在于填补了医疗AI界面设计指导的空白，有助于提升医疗AI系统的可用性和用户体验。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗领域设计人机交互界面面临巨大挑战，需要系统性指导。

**Method:** 本文通过总结常见的医疗信息实体呈现和交互的设计模式，提出了12种人机交互界面设计模式。为了加深理解，研究者采访了12位医疗专业人员，探讨了使用场景和考虑因素。此外，还与14名参与者进行了研讨会以评估这些设计模式。

**Result:** 提出了12种医疗领域人机交互界面的设计模式，并通过医疗专业人员访谈和参与者研讨会加深了理解并进行了评估。

**Conclusion:** 文章讨论了设计模式对其他应用领域的通用性、局限性以及未来的工作。

> **ai_Abstract:** 本文针对医疗领域人机交互界面设计面临的挑战，提出了一套包含12种设计模式的系统性指导。研究通过采访医疗专业人员和举办研讨会的方式，对这些模式进行了深入理解和评估。文章还探讨了设计模式的通用性、局限性及未来发展方向。

> **摘要翻译:** 人机交互界面在推动医疗领域的实践和研究方面发挥着关键作用。然而，设计此类界面对设计师来说是一个巨大的挑战。在本文中，我们通过总结呈现和交互常见信息实体的设计模式，为在典型医疗场景中设计人机交互界面提供了系统性指导。为了加深对这12种设计模式的理解，我们采访了12位医疗专业人员，探讨了潜在的使用场景和重要考虑因素。此外，我们与14名在线招募的参与者进行了研讨会，以评估我们的设计模式。最后，我们讨论了设计模式对其他应用领域的通用性、局限性和未来工作。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [46] [An Age-based Study into Interactive Narrative Visualization Engagement](https://arxiv.org/abs/2507.12734)
> *基于年龄的交互式叙事可视化参与度研究*

*Nina Errey, Yi Chen, Yu Dong, Quang Vinh Nguyen, Xiaoru Yuan, Tuck Wah Leong, Christy Jie Liang* | **Category: cs.HC, cs.GR** | **Updated: 2025-07-17**

**Keywords:** 交互式叙事可视化, 用户参与度, 年龄影响, 包容性设计

**Comment:** 

> **TL;DR:** 研究发现，在交互式叙事可视化中，年龄较大的用户比年轻用户参与度低，可能是因为术语理解差异，并提供了设计建议。

**AI_Comments:** 这项研究创新性地关注了交互式叙事可视化中常常被忽视的年龄因素，通过实证数据揭示了年龄对参与度的影响，并提供了实用的设计建议，对于提升交互式叙事可视化的用户体验和普适性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明年龄影响数字媒体参与度，交互式叙事可视化日益流行但作者常忽视受众年龄因素。

**Method:** 使用既定的可视化参与度问卷，进行了一项实证实验，比较了最终用户参与度与受众年龄的关系，并进行了定性分析。

**Result:** 发现参与度分数存在细微差异，年龄较大的群体比最年轻的群体参与度更低。定性分析显示，年轻群体对交互式叙事模式的术语和整体理解比年长群体更清晰。

**Conclusion:** 建议交互式叙事可视化作者根据受众年龄进行包容性设计。

> **ai_Abstract:** 这项研究调查了受众年龄对交互式叙事可视化参与度的影响。通过一项实证实验和定性分析，研究发现年龄较大的用户在交互式叙事可视化中的参与度低于年轻用户，这可能与他们对相关术语和模式的理解不足有关。文章最后提出了针对不同年龄段用户进行包容性设计的建议。

> **摘要翻译:** 研究表明，受众的年龄会影响他们对数字媒体的参与度。交互式叙事可视化是一种日益流行的数字媒体形式，它结合了数据可视化和讲故事来传达重要信息。然而，交互式叙事可视化作者常常忽视受众的年龄。我们使用一份既定的可视化参与度问卷，进行了一项实证实验，比较了最终用户参与度与受众年龄的关系。我们发现参与度分数存在细微差异，其中年龄较大的群体比最年轻的群体参与度更低。我们的定性分析显示，与年长群体相比，年轻群体在反馈中对交互式叙事模式中整合的术语和整体理解更为明显。我们以一系列建议结束本文，为交互式叙事可视化作者提供如何根据受众年龄进行包容性设计的指导。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [67] [MEDebiaser: A Human-AI Feedback System for Mitigating Bias in Multi-label Medical Image Classification](https://arxiv.org/abs/2507.10044)
> *MEDebiaser：一个用于减轻多标签医学图像分类中偏差的人机反馈系统*

*Shaohan Shi, Yuheng Shao, Haoran Jiang, Yunjie Yao, Zhijun Zhang, Xu Ding, Quan Li* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 医学图像分类, 偏差缓解, 人机反馈, 多标签, 局部解释

**Comment:** 

> **TL;DR:** MEDebiaser是一个人机交互系统，让医生直接通过局部解释修正AI模型，以减轻多标签医学图像分类中的偏差，提高协作效率。

**AI_Comments:** MEDebiaser的创新之处在于其直接的人机反馈机制，允许非技术背景的医生直接干预AI模型的训练过程，解决了传统方法中医学专业知识整合的效率低下问题。这对于提升AI在医疗诊断中的可靠性和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像通常包含多标签，这些标签分布不平衡且共现，导致多标签医学图像分类中存在偏差。传统的医患与机器学习从业者之间的协作模式难以实现有效的反馈，因为通过工程师将医学专业知识整合到训练过程中耗时且费力。

**Method:** 本文引入了MEDebiaser，一个交互式系统，允许医生使用局部解释直接改进AI模型。该系统结合了预测和注意力损失函数，并采用定制的排序策略来缓解可扩展性问题，使得医生无需技术专业知识即可减轻偏差，减少对工程师的依赖。

**Result:** 机制和用户研究表明，MEDebiaser有效地减少了偏差，提高了可用性，并增强了协作效率。

**Conclusion:** MEDebiaser为将医学专业知识整合到AI驱动的医疗保健中提供了一个实用的解决方案。

> **ai_Abstract:** 本文提出了MEDebiaser，一个创新的人机交互系统，旨在解决多标签医学图像分类中由于数据不平衡和共现导致的偏差问题。该系统通过允许医生利用局部解释直接修正AI模型，简化了医学专业知识融入模型训练的过程，减少了对工程师的依赖。MEDebiaser结合了预测与注意力损失函数和定制的排序策略。实验结果表明，MEDebiaser有效减轻了模型偏差，提升了系统可用性及人机协作效率，为AI医疗领域提供了实用的解决方案。

> **摘要翻译:** 医学图像通常包含多标签，这些标签分布不平衡且共现，导致多标签医学图像分类中存在偏差。医学专业人员和机器学习从业者之间的密切合作极大地推动了医学图像分析。然而，传统的协作模式难以促进医生和AI模型之间的有效反馈，因为通过工程师将医学专业知识整合到训练过程中可能耗时且费力。为了弥补这一差距，我们引入了MEDebiaser，一个交互式系统，使医生能够使用局部解释直接改进AI模型。通过结合预测和注意力损失函数，并采用定制的排序策略来缓解可扩展性，MEDebiaser允许医生在没有技术专业知识的情况下减轻偏差，减少对工程师的依赖，从而增强更直接的人机反馈。我们的机制和用户研究表明，它有效地减少了偏差，提高了可用性，并增强了协作效率，为将医学专业知识整合到AI驱动的医疗保健中提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [71] [Public Evaluation on Potential Social Impacts of Fully Autonomous Cybernetic Avatars for Physical Support in Daily-Life Environments: Large-Scale Demonstration and Survey at Avatar Land](https://arxiv.org/abs/2507.12741)
> *全自主控制论化身在日常生活环境中提供物理支持的潜在社会影响的公众评估：在“化身之地”进行的大规模演示和调查*

*Lotfi El Hafi, Kazuma Onishi, Shoichi Hasegawa, Akira Oyama, Tomochika Ishikawa, Masashi Osada, Carl Tornberg, Ryoma Kado, Kento Murata, Saki Hashimoto, Sebastian Carrera Villalobos, Akira Taniguchi, Gustavo Alfonso Garcia Ricardez, Yoshinobu Hagiwara, Tatsuya Aoki, Kensuke Iwata, Takato Horii, Yukiko Horikawa, Takahiro Miyashita, Tadahiro Taniguchi, Hiroshi Ishiguro* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 全自主赛博化身, 公众评估, 社会影响, 物理支持, 可靠性

**Comment:** Accepted for presentation at the 2025 IEEE International Conference
  on Advanced Robotics and its Social Impacts (ARSO), Osaka, Japan

> **TL;DR:** 一项在日本的大规模调查评估了公众对全自主控制论化身提供日常物理支持的看法，发现人们对其可靠性有担忧，但对其在日常生活和工作中的应用感兴趣。

**AI_Comments:** 这项研究通过大规模的公众演示和调查，直接评估了全自主赛博化身在日常环境中的社会接受度，具有重要的实践意义。其创新之处在于提供了关于公众对新兴技术的真实感知数据，特别是指出了可靠性是公众接受度的关键障碍，这为未来全自主CAs的开发和部署提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 赛博化身（CAs）是实现人机共生社会的关键，能帮助个体克服身体限制。然而，半自主CAs需要人工遥控和监督，而全自主CAs的部署仍面临挑战。本研究旨在评估公众对全自主CAs在日常生活中提供物理支持的看法及其潜在社会影响。

**Method:** 在日本大阪举行的为期19天的“Avatar Land”公共活动中，进行了一项大规模演示和调查。全自主机器人CAs和半自主CAs执行了日常物品检索任务。分析了2285名参观者的反馈，其中333名参与者与全自主CAs互动并通过问卷分享了他们的看法和担忧。

**Result:** 调查结果显示，公众对CAs在日常生活和工作中提供物理支持表现出兴趣。然而，人们对任务执行的可靠性表示担忧。相反，成本和类人互动并非主要担忧。

**Conclusion:** 公众对全自主赛博化身在日常物理支持方面表现出兴趣，但对其任务执行的可靠性存在主要担忧，这表明未来部署需要重点关注性能和信任。

> **ai_Abstract:** 本研究在日本大阪的“Avatar Land”活动中，通过大规模演示和调查评估了公众对全自主赛博化身（CAs）在日常生活中提供物理支持的看法。研究分析了2285名参观者的反馈，其中333名与全自主CAs互动并完成问卷。结果显示，公众对CAs在日常和工作中的物理支持应用感兴趣，但主要担忧在于任务执行的可靠性，而非成本或类人互动。

> **摘要翻译:** 赛博化身（CAs）是化身共生社会的关键组成部分，使个体能够通过虚拟代理和机器人助手克服身体限制。虽然半自主CAs间歇性地需要人类遥控和监督，但全自主CAs的部署仍然是一个挑战。本研究评估了公众对全自主CAs在日常生活中提供物理支持的看法和潜在社会影响。为此，我们在日本大阪举行的为期19天的公共活动“Avatar Land”期间进行了一项大规模演示和调查，其中全自主机器人CAs与半自主CAs一起执行了日常物品检索任务。具体来说，我们分析了2285名与各种CAs互动的参观者的反馈，其中包括333名与全自主CAs互动并通过调查问卷分享其看法和担忧的参与者。调查结果表明，人们对CAs在日常生活和工作中提供物理支持感兴趣。然而，人们对任务执行的可靠性提出了担忧。相比之下，成本和类人互动并非主要担忧。项目页面：https://lotfielhafi.github.io/FACA-Survey/。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [96] [PatternSight: A Perceptual Grouping Effectiveness Assessment Approach for Graphical Patterns in Charts](https://arxiv.org/abs/2507.12749)
> *PatternSight：一种图表中图形模式的感知分组有效性评估方法*

*Xumeng Wang, Xiangxuan Zhang, Zhiqi Gao, Shuangcheng Jiao, Yuxin Ma* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 感知分组, 图表设计, 有效性评估, 感知模拟, PatternSight

**Comment:** 

> **TL;DR:** PatternSight提出了一种感知模拟模型，用于评估图表中图形模式的感知有效性，并通过用户实验证明其能有效帮助图表作者优化设计。

**AI_Comments:** 这项研究的创新之处在于提出了一个将感知理论融入到视觉特征提取中的感知模拟模型，以量化图表设计的感知有效性。它解决了图表作者在设计过程中评估视觉模式传达效果的痛点，并通过原型工具PatternSight提供了实用的解决方案。其重要性在于提升了图表设计的科学性和可用性，有助于创建更有效的可视化作品。

<details>
  <summary>Details</summary>

**Motivation:** 可视化生成工具的普及降低了图表制作门槛，但作者若缺乏感知理论知识，难以评估图表表示的有效性，从而难以选择合适的图表设计来传达预期的数据模式。

**Method:** 提出了一种感知模拟模型，通过预测图表观察者可能注意到的图形模式来评估图表的感知有效性。该模型将感知理论整合到图表元素的视觉特征提取中，并嵌入到名为PatternSight的原型界面中。

**Result:** 人类感知结果证明，该模型可以模拟大多数图表观察者的感知分组行为，并涵盖不同的感知结果。用户实验结果表明，PatternSight可以有效帮助图表作者优化图表设计，以表示数据模式。

**Conclusion:** PatternSight通过其感知模拟模型，能够有效评估和优化图表设计中图形模式的感知有效性，帮助作者更好地传达数据模式。

> **ai_Abstract:** 该研究提出PatternSight，一个用于评估图表中图形模式感知有效性的方法。针对图表作者缺乏感知理论知识导致难以评估图表有效性的问题，作者开发了一个感知模拟模型。该模型通过整合感知理论和视觉特征提取来预测用户可能注意到的图形模式。实验证明，该模型能有效模拟人类感知分组行为。此外，通过原型界面PatternSight，该方法能帮助作者优化图表设计，以更好地传达数据模式。

> **摘要翻译:** 可视化生成工具的蓬勃发展显著降低了图表制作的门槛。然而，缺乏对感知理论充分理解的图表作者可能在评估图表表示的有效性方面遇到困难，从而难以确定合适的图表设计来传达预期的数据模式。为了解决这个问题，我们提出了一种感知模拟模型，该模型可以通过预测图表观察者可能注意到的图形模式来评估图表的感知有效性。该感知模拟模型将感知理论整合到图表元素的视觉特征提取中，以提供可解释的模型结果。人类感知结果证明，我们模型的结果可以模拟大多数图表观察者的感知分组行为，并涵盖不同的感知结果。我们还将该模型嵌入到一个名为PatternSight的原型界面中，以方便图表作者评估图表设计是否能按预期满足其模式表示要求，并确定可行的视觉设计改进。根据用户实验结果，PatternSight可以有效地帮助图表作者优化图表设计，以表示数据模式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [112] [DiaryPlay: AI-Assisted Authoring of Interactive Vignettes for Everyday Storytelling](https://arxiv.org/abs/2507.11628)
> *日记剧本：AI辅助的日常故事互动短篇创作*

*Jiangnan Xu, Haeseul Cha, Gosu Choi, Gyu-cheol Lee, Yeo-Jin Yoon, Zucheul Lee, Konstantinos Papangelis, Dae Hyun Kim, Juho Kim* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** AI辅助创作, 互动短篇, 日常叙事, 大语言模型, 叙事规划

**Comment:** 

> **TL;DR:** DiaryPlay是一个AI辅助系统，帮助日常讲述者轻松创作互动短篇故事，通过自然语言输入和LLM驱动的叙事规划器简化创作过程。

**AI_Comments:** DiaryPlay的创新之处在于它利用AI和LLM显著降低了互动叙事的创作门槛，特别是通过将复杂的创作过程分解为元素提取和结构化规划。其分支-瓶颈结构设计巧妙地平衡了作者的控制和观众的互动自由。这项工作对于推动互动故事在非专业创作者中的普及具有重要意义，克服了传统互动叙事创作的复杂性挑战。

<details>
  <summary>Details</summary>

**Motivation:** 互动短篇故事因创作复杂性，尚未被日常故事讲述者广泛使用，这与日常故事讲述的即时性相冲突。

**Method:** DiaryPlay系统以自然语言故事作为输入，提取互动短篇的核心元素（环境、角色和事件），并使用LLM驱动的叙事规划器将单分支故事自动转换为分支-瓶颈结构，从而简化创作并支持灵活的观众互动。

**Result:** 技术评估（N=16）显示DiaryPlay生成的角色活动在可信度方面与人类创作的相当。用户研究（N=16）表明DiaryPlay有效支持作者创建互动短篇元素，在响应观众互动的同时保持作者意图，并提供引人入胜的观看体验。

**Conclusion:** DiaryPlay系统通过AI辅助，有效降低了互动短篇故事的创作复杂性，使其能够被日常故事讲述者更广泛地使用，并提供了高质量的互动体验。

> **ai_Abstract:** 本研究介绍了DiaryPlay，一个AI辅助系统，旨在简化日常故事讲述者创作互动短篇的复杂性。该系统接受自然语言故事输入，并利用AI提取故事核心元素，同时通过LLM驱动的叙事规划器将单分支故事转化为分支-瓶颈结构，从而实现灵活的观众互动。技术评估和用户研究表明，DiaryPlay生成的角色活动具有高可信度，且能有效支持作者创作，保持创作意图并提供沉浸式观看体验。

> **摘要翻译:** 日记剧本：AI辅助的日常故事互动短篇创作

互动短篇是一种流行且沉浸式的视觉叙事方法，它邀请观看者扮演角色并在互动环境中影响叙事。然而，由于创作复杂性，它尚未被日常故事讲述者广泛使用，这与日常故事讲述的即时性相冲突。我们引入了DiaryPlay，一个用于日常故事讲述中创建互动短篇的AI辅助创作系统。它接受自然语言故事作为输入，并提取互动短篇的三个核心元素（环境、角色和事件），使作者能够专注于完善这些元素，而不是从头开始构建。然后，它使用由LLM驱动的叙事规划器，自动将单分支故事输入转换为分支-瓶颈结构，这使得灵活的观众互动成为可能，同时使作者摆脱多分支的负担。一项技术评估（N=16）表明，DiaryPlay生成的角色活动在可信度方面与人类创作的相当。一项用户研究（N=16）表明，DiaryPlay有效支持作者创建互动短篇元素，在响应观众互动时保持作者意图，并提供引人入胜的观看体验。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [126] [Autonomy for Older Adult-Agent Interaction](https://arxiv.org/abs/2507.12767)
> *老年人与智能代理互动的自主性*

*Jiaxin An* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 老年人自主性, 智能代理, AI护理, 社会责任, 自主性衡量

**Comment:** 7 pages

> **TL;DR:** 本文探讨了老年人与AI代理互动中的自主性，提出了四个关键维度，并为未来研究指明了方向，以确保AI代理符合老年人的自主偏好。

**AI_Comments:** 这篇论文通过识别老年人自主性的多维性，为AI代理的设计和应用提供了重要的理论框架和研究方向。其创新之处在于将社会责任自主性纳入考量，突出了AI在公共环境中应用的伦理和社会影响，这对于未来负责任的AI发展至关重要。论文为解决老年护理中AI代理的自主性对齐问题奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 随着全球人口老龄化，AI驱动的智能代理在老年护理中具有潜力，但现有研究在确保智能代理符合老年人的自主偏好方面面临挑战。

**Method:** 本文借鉴跨学科的自主性概念，探讨了老年人自主性的四个关键维度（决策自主性、目标导向自主性、控制自主性和社会责任自主性），并提出了三个研究方向：解决社会责任自主性问题、从任务角度操作化智能代理自主性以及开发自主性衡量标准。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对全球老龄化背景下AI代理在老年护理中的应用，指出当前研究在使代理符合老年人自主偏好方面的不足。文章从跨学科角度审视了老年人自主性的四个核心维度：决策、目标导向、控制和社会责任自主性。在此基础上，提出了未来研究的三个方向：关注AI代理在公共环境中的社会责任与伦理影响、从任务视角具象化代理自主性，以及构建相应的自主性衡量标准，旨在促进AI代理更好地支持老年人的自主生活。

> **摘要翻译:** 随着全球人口老龄化，人工智能（AI）驱动的智能代理已成为支持老年人护理的潜在工具。先前的研究通过识别任务过程中的关键互动阶段并定义智能代理在每个阶段的作用来探索智能代理的自主性。然而，确保智能代理符合老年人的自主偏好仍然是一个关键挑战。本文借鉴跨学科的自主性概念，探讨了老年人自主性的四个关键维度：决策自主性、目标导向自主性、控制自主性和社会责任自主性。本文随后提出了以下研究方向：（1）解决社会责任自主性问题，这涉及到在公共环境中使用智能代理的伦理和社会影响；（2）从任务角度操作化智能代理自主性；（3）开发自主性衡量标准。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [158] [Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight](https://arxiv.org/abs/2507.12377)
> *解构视觉数据新闻中的隐含信念：数据即真相背后的不稳定意义与洞察设计*

*Ke Er Amy Zhang, Jodie Jenkinson, Laura Garrison* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 视觉数据新闻, 解构, 隐含信念, 谱系学, 数据可视化

**Comment:** 11 pages, 5 figures, accepted to IEEE VIS 2025 Conference

> **TL;DR:** 本文通过对17位视觉数据记者的访谈进行解构性解读，揭示了视觉数据新闻中客观性/主观性和人文主义/机械主义两对隐含信念，并指出这些信念受社会外部力量影响，强调批判性理论在数据故事讲述中的应用。

**AI_Comments:** 这项研究的创新之处在于将文学批评中的解构理论和谱系学引入到视觉数据新闻领域，从而深入分析了数据作为“真相”背后所隐含的复杂信念和不稳定意义。它不仅揭示了数据新闻实践中的深层矛盾，还为可视化研究提供了新的批判性视角，强调了理解社会技术背景对于数据化和数据可视化实践的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 探索视觉数据新闻中意义的不稳定性及隐含信念，并展示批判性理论（如解构和谱系学）如何能重新定义视觉数据故事讲述中的“成功”并使可视化研究成果多样化。

**Method:** 对17位全球视觉数据记者进行定性访谈研究，采用文学批评中的解构方法进行解读，并结合谱系分析提供历史背景，以实践解构理论。

**Result:** 揭示了视觉数据新闻中两组对立的隐含信念：客观性/主观性与人文主义/机械主义。这些信念并非独立存在，而是外部社会力量和范式转变的产物。

**Conclusion:** 证明了运用解构和谱系学等批判性理论可以重新定义视觉数据故事讲述的“成功”，并使可视化研究成果多样化，从而推动研究人员审视当今数据化和数据可视化中的社会技术问题。

> **ai_Abstract:** 本文对17位视觉数据记者的定性访谈进行了批判性解读，采用文学批评的解构方法，揭示了视觉数据新闻中存在的客观性/主观性和人文主义/机械主义两对隐含信念。研究发现这些信念受社会外部力量影响。作者强调通过解构和谱系学等批判性理论，可以重新定义数据故事讲述的成功并丰富可视化研究。

> **摘要翻译:** 我们对一项针对全球17位视觉数据新闻记者的定性访谈研究进行了“解构性”解读。我们借鉴文学批评中的解构方法，探索语言意义的不稳定性，并揭示词语和思想中隐含的信念。通过我们的分析，我们揭示了视觉数据新闻中两组对立的隐含信念：客观性/主观性以及人文主义/机械主义。我们通过谱系分析对这些信念进行了语境化，谱系分析通过提供这些对立观点的历史背景，将解构理论付诸实践。我们的分析表明，视觉数据新闻中持有的这些信念并非独立存在，而是外部社会力量和随时间推移的范式转变的产物。通过这项工作，我们展示了如何通过批判性理论（如解构和谱系学）来重新定义视觉数据故事讲述中的“成功”，并使可视化研究成果多样化。这些努力推动了我们作为研究人员生产领域知识的方式，以审视当今对数据化和数据可视化的价值观所产生的社会技术问题。所有补充材料可在osf.io/5fr48获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [169] [Intelligent Virtual Sonographer (IVS): Enhancing Physician-Robot-Patient Communication](https://arxiv.org/abs/2507.13052)
> *智能虚拟超声医师（IVS）：增强医患-机器人沟通*

*Tianyu Song, Feng Li, Yuan Bi, Angelos Karlas, Amir Yousefi, Daniela Branzan, Zhongliang Jiang, Ulrich Eck, Nassir Navab* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-17**

**Keywords:** 智能虚拟超声医师, 机器人超声, 大语言模型, 人机交互, 扩展现实

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** 本文引入智能虚拟超声医师（IVS），一个基于LLM的对话代理，用于在扩展现实（XR）中促进医生、机器人超声系统和患者之间的实时沟通，旨在提高机器人超声检查的效率、清晰度和可及性，并增强信任和患者体验。

**AI_Comments:** 这项研究的创新之处在于提出了智能虚拟超声医师（IVS）的概念，并将其应用于弥合医生-机器人-患者三方沟通的空白。它利用了LLM的强大对话能力和XR的沉浸式体验，为机器人辅助医疗提供了一个更人性化、更高效的交互范式。该工作的重要性在于它不仅提升了医疗效率，更关注了患者体验和对新兴医疗技术的接受度，对于推动机器人医疗的普及具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注患者-机器人或医生-机器人互动，但智能虚拟超声医师（IVS）在弥合医生-机器人-患者三方沟通方面的作用尚未得到充分探索。大语言模型和机器人技术的进步为人类-计算机互动带来了巨大潜力，尤其是在机器人超声领域。

**Method:** 本文引入了一个在扩展现实（XR）中的对话式虚拟代理——智能虚拟超声医师（IVS）。该IVS代理通过整合LLM驱动的对话、语音转文本、文本转语音和机器人控制，实现与医生专业沟通，同时向患者提供富有同情心的解释和安慰，并执行医生的指令来控制机器人超声系统（RUS），并将这些操作透明地传达给患者。

**Result:** 通过整合LLM驱动的对话与语音转文本、文本转语音和机器人控制，该系统增强了机器人超声检查的效率、清晰度和可及性。

**Conclusion:** 这项工作是理解IVS如何弥合医生-机器人-患者互动中沟通障碍的第一步，从而在医生-机器人互动中提供更多控制和信任，同时改善患者体验和对机器人超声的接受度。

> **ai_Abstract:** 本文提出了一种智能虚拟超声医师（IVS）系统，该系统是一个基于大语言模型和XR技术的对话代理，旨在解决机器人超声检查中医生、机器人和患者三方沟通不足的问题。IVS能够与医生进行专业交流，同时为患者提供解释和安抚，并根据医生的指令控制机器人超声系统。该系统通过整合多模态交互技术，显著提升了机器人超声操作的效率、清晰度和可及性，为增强医患对机器人超声的信任和接受度奠定了基础。

> **摘要翻译:** 大型语言模型（LLMs）和机器人技术的进步和成熟为人类-计算机交互，特别是在机器人超声领域，开启了巨大的潜力。虽然现有研究主要集中在患者-机器人或医生-机器人交互，但智能虚拟超声医师（IVS）在弥合医生-机器人-患者沟通方面的作用仍未得到充分探索。这项工作引入了一个在扩展现实（XR）中的对话式虚拟代理，它促进了医生、机器人超声系统（RUS）和患者之间的实时交互。IVS代理以专业方式与医生沟通，同时向患者提供富有同情心的解释和安慰。此外，它通过执行医生命令积极控制RUS，并将这些操作透明地传达给患者。通过将LLM驱动的对话与语音转文本、文本转语音和机器人控制相结合，我们的系统提高了机器人超声采集的效率、清晰度和可及性。这项工作构成了理解IVS如何弥合医生-机器人-患者交互中沟通障碍的第一步，从而在医生-机器人交互中提供更多控制和信任，同时改善患者体验和对机器人超声的接受度。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [211] ["What do you expect? You're part of the internet": Analyzing Celebrities' Experiences as Usees of Deepfake Technology](https://arxiv.org/abs/2507.13065)
> *“你还指望什么？你就是互联网的一部分”：分析名人作为深度伪造技术“被使用者”的经历*

*John Twomey, Sarah Foley, Sarah Robinson, Michael Quayle, Matthew Peter Aylett, Conor Linehan, Gillian Murphy* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 深度伪造, 名人, NSII, 被使用者, 补救措施

**Comment:** 

> **TL;DR:** 本研究分析了名人作为深度伪造技术（特别是未经同意的合成私密图像NSII）受害者的经历，探讨了她们如何构建被攻击的身份以及在寻求补救时所面临的基础设施和社会障碍。

**AI_Comments:** 这项研究的创新之处在于引入并应用了Baumer的“被使用者”（Usees）概念，为理解技术受害者提供了一个新的视角，尤其是在非自愿且不知情的情况下被技术直接影响的群体。其重要性在于揭示了名人作为深度伪造受害者所面临的独特困境，特别是社会归咎和基础设施层面的障碍，这对于推动相关政策制定和技术干预具有启发意义。研究呼吁关注人机交互在改善补救措施方面的潜力，并强调了挑战助长深度伪造滥用的虚假信念的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造技术常被用于创建未经同意的合成私密图像（NSII），主要针对名人女性。本研究旨在理解名人如何构建自己被深度伪造攻击的经历，以及她们在寻求补救时如何应对基础设施和社会障碍。

**Method:** 本研究采用批判性话语心理学分析，并采纳Baumer的“被使用者”（Usees）概念，分析了八位名人女性和一位非二元性别个体在遭受NSII攻击后发表的公开声明。

**Result:** 名人描述了被深度伪造技术未经同意地攻击所造成的伤害以及发现这些视频时的痛苦。她们还描述了各种阻碍行动和寻求补救的基础设施/社会因素，例如指责/沉默叙事以及深度伪造滥用背后的行业。

**Conclusion:** 这项工作对于识别深度伪造滥用背后基础设施中各种利益相关者的角色以及人机交互改善现有NSII补救措施的潜力具有重要意义。它还有助于理解在线虚假信念如何促进深度伪造滥用。未来的工作应包括挑战促使NSII创建/传播的价值观和虚假信念的干预措施。

> **ai_Abstract:** 本研究通过批判性话语心理学分析和“被使用者”概念，探讨了名人作为深度伪造技术（特别是未经同意的合成私密图像NSII）受害者的经历。研究分析了九位名人的公开声明，揭示了她们所遭受的伤害、痛苦，以及在寻求补救时面临的社会和基础设施障碍（如指责文化和相关产业）。研究强调了识别深度伪造滥用中各利益相关者角色的重要性，并指出了人机交互在改善现有补救措施方面的潜力，同时探讨了在线虚假信念如何助长深度伪造滥用，并提出未来应通过干预措施挑战这些虚假信念。

> **摘要翻译:** 深度伪造技术常被用于创建未经同意的合成私密图像（NSII），主要针对名人女性。通过批判性话语心理学分析，我们探讨了：i）名人如何构建自己被深度伪造攻击的身份；ii）她们在寻求补救时如何应对基础设施和社会障碍。本文采纳了Baumer的“被使用者”（Usees）概念（指那些未经同意、不知情且直接受到技术影响的利益相关者），以理解八位遭受NSII攻击的名人女性和一位非二元性别个体所发表的公开声明。名人描述了被深度伪造技术未经同意地攻击所造成的伤害以及发现这些视频时的痛苦。她们描述了各种基础设施/社会因素（例如指责/沉默叙事以及深度伪造滥用背后的行业），这些因素阻碍了她们的行动和寻求补救。这项工作对于识别深度伪造滥用背后基础设施中各种利益相关者的角色以及人机交互改善现有NSII补救措施的潜力具有重要意义。我们还致力于理解在线虚假信念如何促进深度伪造滥用。未来的工作应包括挑战促使NSII创建/传播的价值观和虚假信念的干预措施。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [246] [NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting](https://arxiv.org/abs/2507.12621)
> *NLI4VolVis：通过LLM多智能体和可编辑3D高斯泼溅实现体绘制的自然语言交互*

*Kuangshi Ai, Kaiyuan Tang, Chaoli Wang* | **Category: cs.HC, cs.GR, cs.MA** | **Updated: 2025-07-16**

**Keywords:** 体绘制, 自然语言交互, 大型语言模型, 多智能体, 3D高斯泼溅

**Comment:** IEEE VIS 2025. Project Page: https://nli4volvis.github.io/

> **TL;DR:** NLI4VolVis是一个交互系统，利用LLM多智能体和可编辑3D高斯泼溅，让用户能通过自然语言探索、查询和编辑体数据，解决了传统体绘制的痛点并提升了用户体验。

**AI_Comments:** NLI4VolVis的创新之处在于其将自然语言交互引入体绘制领域，解决了传统方法对非专业用户不友好的问题。通过结合LLM多智能体和可编辑3D高斯泼溅，系统实现了语义层面的理解和实时编辑能力，显著提升了用户体验和数据探索效率。这是一个将AI前沿技术（LLM、3D高斯泼溅）与传统可视化领域结合的优秀范例，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的体绘制方法（如直接体渲染）存在传递函数设计僵化和计算成本高的问题。尽管新颖视图合成方法提高了渲染效率，但它们对非专业用户需要额外的学习，并且缺乏语义层面的交互支持。本文旨在弥补这一差距，实现通过自然语言与体数据进行语义层面的交互。

**Method:** 本文提出了NLI4VolVis系统，一个通过自然语言实现体数据交互的系统。它集成多视图语义分割和视觉-语言模型来提取和理解场景中的语义组件。系统引入了一个多智能体大型语言模型架构，配备了广泛的函数调用工具来解释用户意图并执行可视化任务。这些智能体利用外部工具和声明性体绘制命令与由3D可编辑高斯驱动的体绘制引擎交互，从而实现开放词汇对象查询、实时场景编辑、最佳视图选择和2D风格化。

**Result:** 通过案例研究和用户研究验证了NLI4VolVis系统，结果表明它显著提高了体数据探索的可访问性和可用性。系统实现了开放词汇对象查询、实时场景编辑、最佳视图选择和2D风格化。

**Conclusion:** NLI4VolVis系统通过结合LLM多智能体和可编辑3D高斯泼溅，成功实现了体绘制的自然语言交互，极大地提升了体数据探索的易用性和可访问性，解决了传统方法的局限性。

> **ai_Abstract:** NLI4VolVis是一个创新的交互系统，旨在通过自然语言解决传统体绘制方法的局限性，如僵化的传递函数设计和缺乏语义交互。该系统结合了多视图语义分割、视觉-语言模型和基于LLM的多智能体架构，利用3D可编辑高斯泼溅驱动的引擎，使用户能够直观地探索、查询和实时编辑体数据。通过案例研究和用户研究，NLI4VolVis被证明能显著提升体数据探索的易用性和可访问性，支持开放词汇查询、实时编辑、最佳视图选择和2D风格化。

> **摘要翻译:** 传统的体绘制（VolVis）方法，如直接体渲染，存在传递函数设计僵化和计算成本高的问题。尽管新颖视图合成方法提高了渲染效率，但它们对非专业用户需要额外的学习，并且缺乏语义层面的交互支持。为了弥补这一差距，我们提出了NLI4VolVis，一个交互系统，使用户能够通过自然语言探索、查询和编辑体场景。NLI4VolVis集成了多视图语义分割和视觉-语言模型，以提取和理解场景中的语义组件。我们引入了一个多智能体大型语言模型架构，配备了广泛的函数调用工具，以解释用户意图并执行可视化任务。这些智能体利用外部工具和声明性体绘制命令与由3D可编辑高斯驱动的体绘制引擎交互，从而实现开放词汇对象查询、实时场景编辑、最佳视图选择和2D风格化。我们通过案例研究和用户研究验证了我们的系统，突出了其在体数据探索中改进的可访问性和可用性。我们强烈建议读者访问https://nli4volvis.github.io/查看我们的案例研究、演示视频和源代码。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [257] [On tangible user interfaces, humans and spatiality](https://arxiv.org/abs/2507.13167)
> *关于实体用户界面、人类与空间性*

*Ehud Sharlin, Benjamin Watson, Yoshifumi Kitamura, Fumio Kishino, Yuichi Itoh* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 实体用户界面, 空间性, 人机交互, 设计启发式, 空间TUI

**Comment:** 

> **TL;DR:** 本文探讨了实体用户界面（TUIs）的成功如何依赖于对人类空间技能的利用。研究通过分析人类与物理对象的关系和现有研究，提出了一套将空间性融入TUI设计的启发式规则，并用这些规则评估了现有的空间TUI。

**AI_Comments:** 这篇论文强调了将人类直观的空间技能融入实体用户界面设计的重要性，这对于提高TUI的可用性和成功率至关重要。其创新点在于从人类与物理对象的深层关系中提炼出实用的设计启发式，为TUI设计提供了一个以人为本的新视角。

<details>
  <summary>Details</summary>

**Motivation:** 实体用户界面（TUIs）的成功取决于它们能否有效地利用人类在使用物体时所具备的直观空间技能（空间性）。

**Method:** 本文仔细审视了人类与物理对象之间的关系以及相关的先前研究。基于此，提炼出一系列观察结果，并将其转化为用于将空间性融入TUI应用程序设计的启发式规则。随后，文章识别了“空间TUI”（与形状、空间和结构交互的TUI子集），并使用提出的启发式规则检查了几个现有的空间TUI。

**Result:** 研究提炼出一套关于将空间性融入TUI应用程序设计的观察结果和启发式规则。此外，还识别了“空间TUI”的概念，并利用所提出的启发式规则对现有空间TUI进行了评估。

**Conclusion:** 将人类直观的空间技能（空间性）有效地融入到实体用户界面（TUI）的设计中，是TUI取得成功的基石。

> **ai_Abstract:** 这篇论文探讨了实体用户界面（TUIs）的成功关键在于其如何利用人类固有的空间技能。研究通过审视人类与物理对象的关系及相关前人研究，提炼出一系列观察结果，并将其转化为一套设计启发式规则，旨在指导TUI应用中空间性的融入。文章进一步定义了“空间TUI”，即那些处理形状、空间和结构交互的TUI，并运用所提出的启发式规则对现有的一些空间TUI进行了评估。

> **摘要翻译:** 像史前的树枝和石头一样，实体用户界面（TUIs）是人类操作的物体。TUI的成功将取决于它们利用空间性（即人类在使用物体时所具备的直观空间技能）的程度。在本文中，我们仔细研究了人类与物理对象之间的关系，以及相关的先前研究。通过这项研究，我们提炼出一系列观察结果，并将其转化为启发式规则，用于将空间性纳入TUI应用程序设计中，这是它们成功的基石。沿着这一思路，我们确定了空间TUI，即介导与形状、空间和结构交互的TUI子集。然后，我们使用我们的启发式规则检查了几个现有的空间TUI。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [295] [Difficulty as a Proxy for Measuring Intrinsic Cognitive Load Item](https://arxiv.org/abs/2507.13235)
> *难度作为衡量内在认知负荷项目的代理*

*Minghao Cai, Guher Gorgun, Carrie Demmans Epp* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 认知负荷, 题目难度, 项目反应理论, 内在负荷, 在线学习

**Comment:** 13 pages, presented at AERA 2025 Annual Meeting, Denver, Colorado,
  April 2025

> **TL;DR:** 本研究探讨了在在线学习平台中使用题目难度作为衡量内在认知负荷代理的可行性，发现其与认知负荷理论一致。

**AI_Comments:** 这项研究提出了一个新颖且可能更客观的方法来衡量认知负荷，特别是内在认知负荷，通过利用现有的教育数据（题目难度）。其创新之处在于将心理测量学中的项目反应理论与认知负荷理论相结合，为在线学习平台提供了一种自动化的评估工具，减少了对主观报告的依赖。这对于个性化学习和游戏化教育的设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 测量教育任务中的认知负荷通常依赖于主观的自我报告方法，研究人员对此提出了批评。

**Method:** 研究人员调查了在在线学习平台中使用题目难度参数作为衡量认知负荷代理的可行性，其中难度值通过项目反应理论（IRT）得出。

**Result:** 使用项目反应理论得出的难度值与关于内在负荷和无关负荷如何促成认知负荷的理论一致。

**Conclusion:** 这一发现表明，在学习游戏中建模认知负荷时，可以使用题目难度来表示内在负荷。

> **ai_Abstract:** 本研究旨在解决传统认知负荷测量方法（自我报告）的主观性问题。研究人员探索了在在线学习环境中，将项目难度参数作为衡量内在认知负荷的替代指标的可行性。结果显示，通过项目反应理论（IRT）获得的难度值与认知负荷理论高度吻合，这表明题目难度可以有效地作为学习游戏中内在认知负荷的代理指标。

> **摘要翻译:** 认知负荷是确保最佳学习体验的关键。然而，测量教育任务的认知负荷通常依赖于自我报告测量，这已被研究人员批评为主观的。在这项研究中，我们调查了在在线学习平台中使用题目难度参数作为衡量认知负荷代理的可行性。使用项目反应理论得出的难度值与关于内在负荷和无关负荷如何促成认知负荷的理论一致。这一发现表明，在学习游戏中建模认知负荷时，可以使用题目难度来表示内在负荷。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [343] [RemVerse: Supporting Reminiscence Activities for Older Adults through AI-Assisted Virtual Reality](https://arxiv.org/abs/2507.13247)
> *RemVerse：通过AI辅助虚拟现实支持老年人回忆活动*

*Ruohao Li, Jiawei Li, Jia Sun, Zhiqing Wu, Zisu Li, Ziyan Wang, Ge Lin Kan, Mingming Fan* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** 回忆活动, 虚拟现实, 人工智能, 老年人, 生成模型

**Comment:** 

> **TL;DR:** RemVerse是一个AI驱动的VR原型，通过生成视觉线索和互动对话，帮助老年人进行回忆活动，用户研究表明其有效。

**AI_Comments:** 该论文的创新点在于将AI（特别是生成模型和AI代理）与虚拟现实技术相结合，为老年人提供了一种新颖且沉浸式的回忆辅助方式。它解决了传统回忆辅助手段的局限性，并有望在提升老年人认知功能和心理健康方面发挥重要作用。用户研究的结果令人鼓舞，表明该系统具有实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 回忆活动对改善认知功能、情绪和整体幸福感有益，但城市化导致熟悉环境消失，移除了有效回忆的视觉和听觉线索。旧照片虽能提供视觉线索，但难以重建照片中未包含的回忆内容和环境。虚拟现实（VR）和人工智能（AI）提供了重建沉浸式环境和动态内容以及与人对话以帮助他们逐步回忆的能力。

**Method:** 设计了RemVerse，一个由AI驱动的VR原型，旨在支持回忆活动。RemVerse将生成模型和AI代理集成到VR环境中，通过AI生成的视觉线索和互动对话帮助老年人回忆。对14名老年人进行了用户研究。

**Result:** RemVerse通过触发、具体化和深化个人记忆，有效支持了回忆活动，同时促进了老年人更高的参与度和自主性。

**Conclusion:** 基于研究结果，提出了设计建议，以使AI辅助VR中的回忆活动对老年人更具可访问性和吸引力。

> **ai_Abstract:** 该论文介绍了RemVerse，一个AI辅助的虚拟现实原型，旨在支持老年人的回忆活动。针对城市化导致回忆线索缺失以及旧照片局限性的问题，RemVerse利用生成模型和AI代理在VR环境中提供AI生成的视觉线索和互动对话。对14名老年人的用户研究表明，RemVerse有效触发、具体化和深化了个人记忆，并提升了老年人的参与度和自主性。研究结果为未来设计更具可访问性和吸引力的AI辅助VR回忆活动提供了启示。

> **摘要翻译:** 回忆活动，即回忆和分享过去的经历，已被证明对改善认知功能、情绪和整体幸福感有益。然而，城市化导致了熟悉环境的消失，移除了有效回忆的视觉和听觉线索。虽然旧照片可以作为视觉线索辅助回忆，但人们很难重建照片中没有的回忆内容和环境。虚拟现实（VR）和人工智能（AI）提供了重建具有动态内容的沉浸式环境以及与人对话以帮助他们逐步回忆的能力。我们设计了RemVerse，一个由AI赋能的VR原型，旨在支持回忆活动。RemVerse将生成模型和AI代理集成到VR环境中，通过AI生成的视觉线索和互动对话帮助老年人回忆。我们对14名老年人进行的用户研究表明，RemVerse通过触发、具体化和深化个人记忆，有效支持了回忆活动，同时促进了老年人更高的参与度和自主性。基于我们的发现，我们提出了设计启示，以使AI辅助VR中的回忆活动对老年人更具可访问性和吸引力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [389] [FocusView: Understanding and Customizing Informational Video Watching Experiences for Viewers with ADHD](https://arxiv.org/abs/2507.13309)
> *FocusView：理解和定制ADHD观众的信息视频观看体验*

*Hanxiu 'Hazel' Zhu, Ruijia Chen, Yuhang Zhao* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** ADHD, 视频定制, 注意力挑战, FocusView, 可观看性

**Comment:** 

> **TL;DR:** 本研究设计并评估了FocusView，一个视频定制界面，旨在帮助ADHD观众减少观看信息视频时的干扰，并提高了视频的可观看性，同时揭示了ADHD人群独特的视频定制需求。

**AI_Comments:** 这项研究创新性地关注了ADHD人群在信息视频观看中的特殊需求，并通过定制化界面FocusView提供了解决方案。其重要性在于不仅验证了技术干预的有效性，更深入揭示了ADHD患者对信息处理的独特模式，例如对背景音乐的双重感知以及对界面简洁性的需求。这项工作为未来针对特殊用户群体的个性化学习或信息获取工具设计提供了宝贵的实证基础和设计考量，具有重要的实际应用价值和理论指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于信息视频中动态、多模态且可能分散注意力的元素，ADHD患者在观看信息视频时常面临注意力挑战。本研究旨在理解并解决这一关键挑战。

**Method:** 研究人员设计了FocusView，一个允许ADHD观众从不同方面定制信息视频的界面。通过对12名ADHD参与者进行评估，以了解其效果和用户偏好。

**Result:** FocusView显著提高了视频的可观看性，减少了干扰。研究揭示了参与者对视频干扰（例如，背景音乐既是干扰也是刺激）的多样化看法，以及他们的定制偏好。此外，研究还强调了在设计视频定制界面时针对ADHD人群的独特需求（例如，减少选项以避免定制本身造成的干扰）。

**Conclusion:** 本研究验证了FocusView在改善ADHD观众视频观看体验方面的有效性，并为未来面向ADHD社区的视频定制系统提供了设计考量。

> **ai_Abstract:** 本研究针对ADHD患者在观看信息视频时注意力分散的问题，设计并评估了FocusView这一视频定制界面。通过对12名ADHD参与者的实验表明，FocusView能有效减少干扰，提高视频的可观看性。研究还深入探讨了ADHD患者对视频干扰的独特认知和定制偏好，并据此提出了针对ADHD社区未来视频定制系统的设计建议，强调了简化选项以避免过度选择带来的新干扰的重要性。

> **摘要翻译:** 尽管视频在不同教育和专业环境中传递信息变得越来越普遍，但ADHD患者在观看信息视频时常因动态、多模态但可能分散注意力的视频元素而面临注意力挑战。为了理解和解决这一关键挑战，我们设计了FocusView，一个允许ADHD观众从不同方面定制信息视频的界面。我们与12名ADHD参与者一起评估了FocusView，发现FocusView通过减少干扰显著提高了视频的可观看性。通过这项研究，我们揭示了参与者对视频干扰的多样化看法（例如，背景音乐既是干扰也是刺激），以及他们的定制偏好，突出了在设计视频定制界面时与ADHD相关的独特需求（例如，减少选项以避免定制本身造成的干扰）。我们进一步为ADHD社区未来的视频定制系统提出了设计考量。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [651] [A Design Space for Multiscale Visualization](https://arxiv.org/abs/2404.01485)
> *多尺度可视化设计空间*

*Mara Solen, Matt Oddo, Tamara Munzner* | **Category: cs.HC** | **Updated: 2025-07-16**

**Keywords:** 多尺度可视化, 设计空间, 信息可视化, 可视化设计, 设计策略

**Comment:** 

> **TL;DR:** 本文提出了一个多尺度可视化的设计空间，包含三个维度和八个子维度，并展示了其在描述和生成多尺度可视化方法方面的能力。

**AI_Comments:** 这项研究通过提供一个结构化的多尺度可视化设计空间，为该领域做出了重要贡献。其创新之处在于将复杂的设计挑战分解为可管理的维度和子维度，并展示了该设计空间在描述现有方法和指导未来设计方面的双重能力。通过对大量案例的编码和分析，该工作不仅系统化了现有知识，还为设计师提供了识别新机会的工具，具有很高的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 设计多尺度可视化，特别是当最大尺度和最小项目之间的比例很大时，可能具有挑战性。研究人员和实践者开发了许多方法来克服这一挑战，因此需要一个系统化的设计空间来理解和指导这些方法的开发。

**Method:** 研究者提出了一个包含三个维度和八个子维度的多尺度可视化设计空间。他们使用该设计空间对一个包含52个示例的语料库中的方法进行编码，并分析这些示例，将其划分为四种高级设计策略。此外，他们通过分析语料库中错失的机会来展示其生成能力。

**Result:** 该设计空间展示了其描述能力，通过对52个示例进行编码并将其划分为四种高级设计策略。它还展示了生成能力，通过识别语料库中可以从不同选择中受益的错失机会。研究还讨论了不同维度和策略选择在分析和演示等不同可视化上下文中的使用模式。

**Conclusion:** 本文提出了一个多尺度可视化设计空间，它不仅能够描述现有方法，还能识别潜在的设计机会，为多尺度可视化设计提供了系统化的框架和指导。

> **ai_Abstract:** 本文提出了一个用于多尺度可视化的设计空间，旨在解决设计此类可视化时面临的挑战。该设计空间包含三个主维度和八个子维度。研究人员通过将该设计空间应用于一个包含52个多尺度可视化示例的语料库，验证了其描述和生成能力。通过分析，他们识别出四种高级设计策略，并发现了现有示例中错失的设计机会。文章还探讨了在不同可视化上下文（如分析和演示）中，不同维度和策略选择的使用模式。

> **摘要翻译:** 设计多尺度可视化，特别是当最大尺度和最小项目之间的比例很大时，可能具有挑战性，设计师们已经开发了许多方法来克服这一挑战。我们提出了一个多尺度可视化的设计空间。该设计空间包括三个维度，共有八个子维度。我们通过使用它来编码一个由学术界和实践者共同创建的包含52个示例的语料库中的方法，展示了其描述能力。我们通过分析这些示例并将其划分为四种设计多尺度可视化的高级策略来展示描述能力，这些策略是关于设计空间维度选择的共享方法。我们通过分析语料库中错失的机会来展示生成能力，这些机会是通过对设计空间的分析识别出来的，我们注意到某些示例如何能从不同的选择中受益。我们讨论了在分析和演示等不同可视化上下文中，使用不同维度和策略选择的模式。补充材料：https://osf.io/wbrdm/ 设计空间网站：https://marasolen.github.io/multiscale-vis-ds/

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [687] [Characterizing Collective Efforts in Content Sharing and Quality Control for ADHD-relevant Content on Video-sharing Platforms](https://arxiv.org/abs/2501.13020)
> *表征视频分享平台上ADHD相关内容的集体共享和质量控制工作*

*Hanxiu 'Hazel' Zhu, Avanthika Senthil Kumar, Sihang Zhao, Ru Wang, Xin Tong, Yuhang Zhao* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** ADHD, 视频分享平台, 内容质量, 质量控制, 集体努力

**Comment:** 

> **TL;DR:** 本研究探讨了视频分享平台（如YouTube和TikTok）上ADHD相关内容的质量和可访问性问题。通过分析373个视频，揭示了创作者和观众在内容质量控制方面的集体努力，并提出了改进平台内容的建议。

**AI_Comments:** 该研究关注了视频分享平台上ADHD相关内容的信息质量和可访问性这一重要且及时的问题，尤其对弱势用户群体意义重大。其采用混合方法研究创作者和观众的集体质量控制努力，具有创新性，并为平台改进提供了实用的设计建议。

<details>
  <summary>Details</summary>

**Motivation:** 视频分享平台对ADHD患者获取信息和支持至关重要，但存在内容质量和可访问性挑战。现有研究未能深入探讨ADHD社区中这些视频内容的质量、影响及控制策略，本研究旨在填补这一空白。

**Method:** 系统性地从YouTube和TikTok收集了373个与ADHD相关的视频及其评论，并采用混合方法对数据进行分析。

**Result:** 研究确定了ADHD相关视频的特征（如创作者类型、视频呈现形式、质量问题），并揭示了创作者和观众在视频质量控制中的集体努力，包括建立权威、集体质量检查和改善可访问性。

**Conclusion:** 为视频分享平台提供了可操作的设计建议，以提供更可靠、对ADHD用户更友好的内容。

> **ai_Abstract:** 本研究旨在探讨视频分享平台上ADHD相关内容的特征、内容共享和质量控制方面的集体努力。鉴于视频平台对ADHD个体的重要性及其面临的信息质量和可访问性挑战，研究通过系统收集YouTube和TikTok上的373个ADHD相关视频及评论，并采用混合方法进行分析。研究结果识别了ADHD相关视频的特点，并揭示了创作者和观众在内容质量控制中的集体参与，包括建立权威、集体质量检查和提升可访问性。最终，本研究为视频平台提供了实用的设计启示，以期提供更可靠、对ADHD用户更友好的内容。

> **摘要翻译:** 视频分享平台（VSP）对于ADHD（注意缺陷多动障碍）个体识别症状、获取知识和获得支持变得越来越重要。虽然视频提供了丰富的信息和高度的参与性，但它们也带来了独特的挑战，例如信息质量和ADHD用户的可访问性问题。然而，很少有工作彻底研究ADHD社区中的视频内容质量和可访问性问题、其影响以及控制策略。我们通过系统地从YouTube和TikTok收集373个与ADHD相关的视频及其评论，并采用混合方法分析数据来填补这一空白。我们的研究确定了VSP上ADHD相关视频的特征（例如，创作者类型、视频呈现形式、质量问题），并揭示了创作者和观众在视频质量控制方面的集体努力，例如权威建立、集体质量检查和可访问性改进。我们进一步为VSP推导出了可操作的设计建议，以提供更可靠和对ADHD更友好的内容。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [51] [Geometric Theory of Ising Machines](https://arxiv.org/abs/2507.12626)
> *伊辛机的几何理论*

*Andrew G. Moore, Zachary Richey, Isaac K. Martin* | **Category: cs.ET, cond-mat.dis-nn** | **Updated: 2025-07-16**

**Keywords:** 伊辛机, 几何理论, 决策边界, 1-NN分类器, 线性规划

**Comment:** 26 pages, 11 figures

> **TL;DR:** 本文提出了一种图示设备来可视化伊辛电路的决策边界，并证明了伊辛电路是1-NN分类器的推广，且能量景观中局部最小值的消除可表述为线性规划问题。

**AI_Comments:** 这篇论文在伊辛机（一种新兴的概率计算设备）的数学理论方面做出了重要贡献。通过引入创新的图示设备，它不仅提供了一种可视化伊辛电路决策边界的方法，还揭示了伊辛机与1-NN分类器之间的深层联系，并提出了一种通过线性规划解决能量景观中局部最小值问题的潜在方法。这对于优化伊辛机的性能和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为低温伊辛机的设计提供数学理论支持，解决将函数输出编码到物理系统基态时能量函数设计困难的问题。

**Method:** 引入了一种图示设备来可视化伊辛电路的决策边界。

**Result:** 1) 伊辛电路是具有特定特殊结构的1-NN分类器的推广；2) 能量景观中局部最小值的消除可以被表述为一个线性规划问题。

**Conclusion:** 通过引入图示设备，本研究为伊辛机提供了新的理论见解，揭示了其与1-NN分类器的联系，并提出了解决局部最小值问题的线性规划方法，有助于伊辛机的设计。

> **ai_Abstract:** 本文致力于伊辛机设计的数学理论研究，旨在解决能量函数设计中的难题。作者引入了一种图示设备来可视化伊辛电路的决策边界，并基于此证明了两个主要结果：伊辛电路是带有特定结构的1-NN分类器的推广，并且能量景观中局部最小值的消除可以公式化为一个线性规划问题。这些发现为伊辛机的理论理解和设计提供了新的视角。

> **摘要翻译:** 我们为低温伊辛机（一种实现伊辛模型的实验性概率计算设备）的设计贡献了数学理论。将函数的输出编码到物理系统的基态中可以实现高效的分布式计算，但能量函数的设计是一个难题。我们引入了一种图示设备，使我们能够可视化伊辛电路的决策边界。然后，我们用它来证明两个结果：（1）伊辛电路是具有特定特殊结构的1-NN分类器的推广，以及（2）能量景观中局部最小值的消除可以被表述为一个线性规划问题。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [76] [LLM-Powered Quantum Code Transpilation](https://arxiv.org/abs/2507.12480)
> *LLM驱动的量子代码转译*

*Nazanin Siavash, Armin Moin* | **Category: cs.SE, cs.AI, cs.ET** | **Updated: 2025-07-12**

**Keywords:** 量子代码转译, 大型语言模型, 量子SDK, 互操作性, 软件可移植性

**Comment:** IEEE International Conference on Quantum Computing and Engineering
  (QCE) 2025 - Extended Abstract

> **TL;DR:** 本文提出使用大型语言模型（LLM）作为量子代码转译器，以解决不同量子SDK之间的互操作性问题，并实现量子程序的跨平台转换。

**AI_Comments:** 本文的创新之处在于将大型语言模型应用于量子代码转译这一新兴领域，提供了一种自动化且灵活的解决方案，有望大幅降低量子软件跨平台开发的复杂性。其重要性在于推动了量子计算生态系统中智能工具的发展，为未来的量子软件互操作性奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的量子软件开发工具包（QSDKs）种类繁多，导致互操作性和跨平台开发面临挑战。传统的基于规则的转译器设计和维护耗时，需要深厚专业知识和严格映射。

**Method:** 本研究探索使用大型语言模型（LLM）作为灵活、自动化的解决方案。利用LLM的预训练知识和上下文推理能力，将其用作与编程语言无关的转译器，实现量子程序在不同QSDKs之间的功能等效转换。

**Result:** 该方法消除了手动定义转换规则的需要，并为量子软件的可移植性提供了一个可扩展的解决方案。

**Conclusion:** 这项工作标志着在量子计算生态系统中实现智能、通用转译迈出了一步。

> **ai_Abstract:** 本文提出了一种创新的方法，利用大型语言模型（LLM）作为量子代码转译器，以解决不同量子软件开发工具包（QSDKs）之间的互操作性挑战。与传统的基于规则的转译器不同，LLM能够利用其预训练知识和推理能力，实现量子程序在不同平台间的自动化、语言无关的功能等效转换，从而消除了手动规则的依赖，提升了量子软件的可移植性和可扩展性。

> **摘要翻译:** 存在针对不同量子计算平台的各种软件开发工具包（SDKs）。这些被称为量子SDKs（QSDKs）。例如Qiskit、Cirq和PennyLane等。然而，这种多样性给混合量子-经典软件系统的互操作性和跨平台开发带来了重大挑战。传统的用于在QSDKs之间转译代码的基于规则的转译器设计和维护耗时，需要深厚的专业知识以及源代码和目标代码中的严格映射。在本研究中，我们探索使用大型语言模型（LLMs）作为一种灵活和自动化的解决方案。利用它们的预训练知识和上下文推理能力，我们将LLMs定位为与编程语言无关的转译器，能够将量子程序从一个QSDK转换为另一个，同时保持功能等效性。我们的方法消除了手动定义转换规则的需要，并为量子软件的可移植性提供了一个可扩展的解决方案。这项工作代表着在量子计算生态系统中实现智能、通用转译迈出了一步。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [122] [Machine Learning Systems: A Survey from a Data-Oriented Perspective](https://arxiv.org/abs/2302.04810)
> *机器学习系统：一个面向数据的视角综述*

*Christian Cabrera, Andrei Paleyes, Pierre Thodoroff, Neil D. Lawrence* | **Category: cs.SE, cs.AI, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 机器学习系统, 数据导向架构, 系统综述, 部署, 知识空白

**Comment:** Under review CSUR

> **TL;DR:** 本文综述了实践者如何采纳数据导向架构（DOA）来部署机器学习系统，以弥补隐性设计决策造成的知识空白，并提供实用建议。

**AI_Comments:** 本文的创新点在于明确识别并解决了机器学习系统部署中由于隐性数据导向架构（DOA）应用所造成的知识空白。通过系统性综述，它将分散在不同实践中的DOA设计决策显性化，为实践者提供了清晰的指导和实用建议。这对于提升机器学习系统在复杂现实环境中的部署效率和鲁棒性具有重要意义，尤其是在大数据和低延迟需求日益增长的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能技术的兴起，工程师们正在将机器学习模型部署到实际系统中。然而，现实环境产生大量异构数据且用户要求高效响应，这使得现有软件架构在部署基于机器学习的系统时面临挑战。尽管数据导向架构（DOA）是一种新兴的集成机器学习模型的有效风格，但相关论文并未明确提及DOA，导致隐性决策造成知识空白，限制了实践者实现基于机器学习系统的能力。

**Method:** 本文采用了一种知名且系统化、半自动化的软件工程论文审查方法，综述了实践者采用数据导向架构（DOA）来实施和部署基于机器学习系统的原因、方式和程度，旨在通过明确展示这些系统背后的设计决策和实践来弥补知识空白。

**Result:** 大多数被审查的工作都部分采用了数据导向架构（DOA）。这种采纳使得系统能够满足大数据管理、低延迟处理、资源管理、安全和隐私等要求。

**Conclusion:** 基于研究发现，本文提出了实用建议，以促进基于机器学习系统的部署。

> **ai_Abstract:** 本文综述了机器学习系统在现实部署中面临的挑战，指出数据导向架构（DOA）是一种有效的解决方案。尽管许多现有系统隐性采用了DOA，但这造成了知识空白。本研究通过系统化综述，分析了实践者采纳DOA的原因、方式和程度，并明确了相关设计决策。研究发现，多数已部署系统部分采纳了DOA，从而有效解决了大数据管理、低延迟、资源管理、安全隐私等问题。最终，本文基于这些发现提出了促进机器学习系统部署的实用建议。

> **摘要翻译:** 随着人工智能技术的兴兴，工程师们正在将机器学习模型作为真实世界系统的一部分进行部署。然而，真实世界环境对这些系统的部署提出了挑战，因为它们会产生大量异构数据，并且用户要求越来越高效的响应。这些要求将现有软件架构在部署基于机器学习的系统时推向了极限。数据导向架构（DOA）是一种新兴的风格，它能更好地帮助系统集成机器学习模型。尽管关于已部署机器学习系统的论文没有明确提及DOA，但其作者所做的设计决策却隐含地遵循了DOA。隐性决策造成了知识空白，限制了实践者实施基于机器学习系统的能力。本文综述了实践者为何、如何以及在多大程度上采纳了DOA来实施和部署基于机器学习的系统。我们通过回答这些问题并明确展示这些系统背后的设计决策和实践来克服知识空白。这项综述遵循了软件工程领域一种知名且系统化、半自动化的论文审查方法。大多数被审查的工作都部分采用了DOA。这种采纳使得系统能够满足大数据管理、低延迟处理、资源管理、安全和隐私等要求。基于这些发现，我们提出了实用建议，以促进基于机器学习系统的部署。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [145] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
> *大语言模型时代的AIOps综述*

*Lingzhe Zhang, Tong Jia, Mengxi Jia, Yifan Wu, Aiwei Liu, Yong Yang, Zhonghai Wu, Xuming Hu, Philip S. Yu, Ying Li* | **Category: cs.SE, cs.CL** | **Updated: 2025-06-23**

**Keywords:** AIOps, 大语言模型, 综述, IT运维, 故障数据

**Comment:** Accepted By CSUR, an extended version of "A Survey of AIOps for
  Failure Management in the Era of Large Language Models" [arXiv:2406.11213]

> **TL;DR:** 本文综述了2020年至2024年间183篇关于大语言模型在IT运维人工智能（AIOps）中应用的研究论文，分析了数据源、AIOps任务演变、LLM方法及评估策略，旨在理解当前趋势、发现研究空白并提出未来方向。

**AI_Comments:** 这篇综述论文具有重要的时效性和前瞻性，在大语言模型与AIOps交叉领域尚处于早期阶段时，提供了一个全面的视角。通过系统性地分析大量近期文献，它为研究人员和从业者提供了该领域现状、挑战和未来趋势的清晰路线图，对推动LLM在AIOps中的应用和研究具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型在AIOps中的应用受到了广泛关注，但对其影响、潜力及局限性的全面理解仍处于初级阶段。本研究旨在弥补这一认知空白。

**Method:** 本文对2020年1月至2024年12月期间发表的183篇关于LLM4AIOps（大语言模型在AIOps中的应用）的研究论文进行了详细综述。研究回答了四个关键研究问题：检查故障数据源、探索AIOps任务演变、调查基于LLM的AIOps解决方法，以及回顾LLM集成AIOps方法的评估策略。

**Result:** 本综述讨论了LLM4AIOps领域的最新进展和趋势，指出了现有研究中的空白，并提出了未来有前景的探索方向。

**Conclusion:** 本研究通过对大语言模型在AIOps领域应用的全面综述，阐明了当前的技术进展、识别了研究不足，并为未来的研究方向提供了指导。

> **ai_Abstract:** 本文对大语言模型（LLM）在IT运维人工智能（AIOps）领域的应用进行了全面综述，分析了2020年至2024年间发表的183篇相关研究论文。综述内容涵盖了LLM在AIOps中使用的故障数据源、AIOps任务的演变、基于LLM的解决AIOps挑战的方法以及评估LLM集成AIOps方法的策略。研究旨在填补LLM在AIOps中影响、潜力及局限性理解上的空白，并基于研究结果讨论了该领域的最新进展、识别了研究不足并提出了未来研究方向。

> **摘要翻译:** 随着大型语言模型（LLM）日益复杂和普及，它们在各种IT运维人工智能（AIOps）任务中的应用受到了广泛关注。然而，对LLM在AIOps中影响、潜力及局限性的全面理解仍处于初级阶段。为了弥补这一空白，我们对LLM4AIOps进行了详细的调查，重点关注LLM如何优化该领域的流程并改善成果。我们分析了2020年1月至2024年12月期间发表的183篇研究论文，以回答四个关键研究问题（RQs）。在RQ1中，我们考察了所利用的各种故障数据源，包括针对传统数据的高级基于LLM的处理技术以及LLM支持的新数据源的整合。RQ2探讨了AIOps任务的演变，强调了新任务的出现以及这些任务的发表趋势。RQ3调查了为解决AIOps挑战而应用的各种基于LLM的方法。最后，RQ4回顾了为评估LLM集成AIOps方法而定制的评估方法。根据我们的发现，我们讨论了最先进的进展和趋势，指出了现有研究中的空白，并提出了未来探索的有前景的方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [170] [GUI Test Migration via Abstraction and Concretization](https://arxiv.org/abs/2409.05028)
> *GUI测试迁移：通过抽象与具体化*

*Yakun Zhang, Chen Liu, Xiaofei Xie, Yun Lin, Jin Song Dong, Dan Hao, Lu Zhang* | **Category: cs.SE, cs.CL** | **Updated: 2025-07-17**

**Keywords:** GUI测试迁移, 抽象, 具体化, MACdroid, LLM

**Comment:** This paper has been accepted for publication in ACM Transactions on
  Software Engineering and Methodology (TOSEM) in 2025. The official
  publication link is: https://dl.acm.org/doi/10.1145/3726525

> **TL;DR:** 提出了一种基于抽象-具体化范式的新GUI测试迁移方法MACdroid，显著提高了测试成功率，优于现有基线。

**AI_Comments:** 本文创新性地提出了抽象-具体化范式来解决GUI测试迁移中存在的挑战，并首次将大型语言模型（LLM）引入到具体化阶段，以生成更准确的测试用例。该方法避免了传统控件映射的局限性，显著提高了测试用例的迁移成功率和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有GUI测试迁移方法侧重于控件映射，但由于不同应用实现相同功能的方式不同，直接映射可能导致测试用例不完整或有缺陷，从而严重影响测试目标功能的有效性和迁移方法的实际适用性。

**Method:** 提出了一种新的迁移范式——抽象-具体化范式，该范式首先抽象出目标功能的测试逻辑，然后利用该逻辑生成具体的GUI测试用例。在此基础上，引入了MACdroid，这是首个基于此范式迁移GUI测试用例的方法。MACdroid包含：1. 抽象技术：利用源应用的源测试用例提取该功能的通用测试逻辑。2. 具体化技术：利用通用测试逻辑指导大型语言模型（LLM）为目标应用生成相应的GUI测试用例（包括事件和断言）。

**Result:** 在两个广泛使用的数据集上评估了MACdroid。在FrUITeR数据集上，MACdroid生成的测试用例成功测试了64%的目标功能，比基线提高了191%。在Lin数据集上，MACdroid成功测试了75%的目标功能，优于基线42%。

**Conclusion:** 这些结果强调了MACdroid在GUI测试迁移中的有效性。

> **ai_Abstract:** 针对现有GUI测试迁移中控件映射可能导致测试用例不完整或有缺陷的问题，本文提出了一种新的抽象-具体化迁移范式。基于此范式，研究人员开发了MACdroid，该方法首先从源应用测试用例中抽象出通用测试逻辑，然后利用该逻辑指导大型语言模型（LLM）生成目标应用的具体GUI测试用例。实验结果表明，MACdroid在两个广泛使用的数据集上均显著优于现有基线，成功测试了更高比例的目标功能，证明了其在GUI测试迁移中的有效性。

> **摘要翻译:** GUI测试迁移旨在生成包含事件和断言的测试用例，以测试目标应用的特定功能。现有的迁移方法通常侧重于控件映射范式，即将源应用的控件映射到目标应用。然而，由于不同应用可能以不同方式实现相同功能，直接映射可能导致测试用例不完整或存在缺陷，从而严重影响测试目标功能的有效性和迁移方法的实际适用性。
在本文中，我们提出了一种新的迁移范式（即抽象-具体化范式），该范式首先抽象出目标功能的测试逻辑，然后利用该逻辑生成具体的GUI测试用例。此外，我们引入了MACdroid，这是首个基于此范式迁移GUI测试用例的方法。具体而言，我们提出了一种抽象技术，利用针对相同功能的源应用的源测试用例来提取该功能的通用测试逻辑。然后，我们提出了一种具体化技术，利用通用测试逻辑指导大型语言模型（LLM）为目标应用生成相应的GUI测试用例（包括事件和断言）。我们在两个广泛使用的数据集（包括31个应用、34个功能和123个测试用例）上评估了MACdroid。在FrUITeR数据集上，MACdroid生成的测试用例成功测试了64%的目标功能，比基线提高了191%。在Lin数据集上，MACdroid成功测试了75%的目标功能，优于基线42%。这些结果强调了MACdroid在GUI测试迁移中的有效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [187] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding](https://arxiv.org/abs/2507.12482)
> *Kodezi Chronos：一种用于存储库规模、内存驱动的代码理解的调试优先语言模型*

*Ishraq Khan, Assad Chowdary, Sharoz Haseeb, Urvish Patel* | **Category: cs.SE, cs.AI, cs.CE, cs.LG, 68N30, 68T05, 68T50, D.2.5; D.2.7; F.3.2; I.2.6; I.2.7** | **Updated: 2025-07-14**

**Keywords:** 代码理解, 调试, 语言模型, 存储库规模, 记忆引擎

**Comment:** 10 pages, 10 figures, 7 tables, IEEE Conference format, Q4 2025 model
  release, Q1 2026 Kodezi OS deployment

> **TL;DR:** Kodezi Chronos 是一种新型语言模型，通过多级嵌入记忆引擎克服了现有LLM的上下文限制，实现了对整个代码库的理解、调试和维护，并在实际错误检测和调试周期方面表现出色。

**AI_Comments:** 该论文提出了一种创新的“调试优先”语言模型架构，通过其独特的多级嵌入记忆引擎，克服了现有LLM在处理大规模代码库时的上下文限制。其能够进行存储库规模的代码理解、多文件重构和实时自修复的特点，以及在实际错误检测和调试效率上的显著提升，标志着在自主软件维护和构建自我维持软件生态系统方面取得了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在代码生成和软件自动化方面取得了进展，但受到推理时上下文有限和缺乏明确代码结构推理的根本限制。

**Method:** Kodezi Chronos 采用了一种多级嵌入记忆引擎，结合了向量和基于图的索引以及持续的代码感知检索。这使得它能够在数百万行代码上进行高效准确的推理，支持存储库规模的理解、多文件重构和实时自修复操作。研究引入了一种新的多随机检索基准（Multi Random Retrieval benchmark）进行评估。

**Result:** Kodezi Chronos 在新的多随机检索基准上优于先前的LLM和代码模型，在实际错误检测方面提高了23%，与传统的基于序列的方法相比，调试周期减少了高达40%。

**Conclusion:** Kodezi Chronos 通过与IDE和CI/CD工作流的原生接口，实现了无缝、自主的软件维护，提高了代码可靠性和生产力，同时减少了人工工作量。这些结果标志着向自我维持、持续优化的软件生态系统迈出了关键一步。

> **ai_Abstract:** 本文介绍了 Kodezi Chronos，一个旨在解决现有大型语言模型上下文限制和代码结构推理不足的新型调试优先语言模型。它采用多级嵌入记忆引擎，结合向量和图基索引以及持续代码感知检索，能够理解和处理整个代码库。通过引入新的多随机检索基准进行评估，Kodezi Chronos 在实际错误检测和调试周期方面显著优于现有模型，并能实现自主软件维护，提升代码可靠性和生产力。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成和软件自动化方面取得了进展，但受到推理时上下文有限和缺乏明确代码结构推理的根本限制。我们引入了 Kodezi Chronos，这是一种用于自主代码理解、调试和维护的下一代架构，旨在跨越包含整个代码库、历史记录和文档的超长上下文运行，且没有固定的窗口限制。Kodezi Chronos 利用多级嵌入记忆引擎，结合向量和基于图的索引以及持续的代码感知检索。这使得它能够在数百万行代码上进行高效准确的推理，支持存储库规模的理解、多文件重构和实时自修复操作。我们的评估引入了一种新颖的多随机检索基准，专门针对软件工程领域。与经典检索基准不同，该方法要求模型解析代码工件之间任意遥远和模糊的关联，模拟变量跟踪、依赖迁移和语义错误定位等现实任务。Chronos 优于先前的LLM和代码模型，在实际错误检测方面表现出23%的改进，与传统的基于序列的方法相比，调试周期减少了高达40%。通过与IDE和CI/CD工作流的原生接口，Chronos 实现了无缝、自主的软件维护，提高了代码可靠性和生产力，同时减少了人工工作量。这些结果标志着向自我维持、持续优化的软件生态系统迈出了关键一步。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [223] [A Survey of Reinforcement Learning for Software Engineering](https://arxiv.org/abs/2507.12483)
> *强化学习在软件工程中的应用综述*

*Dong Wang, Hanmo You, Lingwei Zhu, Kaiwei Lin, Zheng Chen, Chen Yang, Junji Yu, Zan Wang, Junjie Chen* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** 强化学习, 软件工程, 综述, 深度强化学习, 系统映射

**Comment:** 

> **TL;DR:** 本文首次系统地综述了自2015年深度强化学习出现以来，强化学习在软件工程领域的应用，分析了115篇相关研究的出版趋势、算法、挑战及未来方向。

**AI_Comments:** 这篇综述填补了强化学习在软件工程领域缺乏系统性概览的空白，其创新之处在于首次提供了全面的映射。它对该领域未来的研究方向具有重要的指导意义，对于研究人员和从业者理解当前进展和探索新应用具有高价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管强化学习在软件工程中的研究日益增多，但目前缺乏对该领域全面且系统的综述。

**Method:** 审查了自深度强化学习引入以来，在22个顶级软件工程会议上发表的115篇经过同行评审的研究。进行了出版趋势分析，对软件工程主题和强化学习算法进行分类，并检查了数据集使用、模型设计和优化以及评估实践等关键因素。

**Result:** 分析了出版趋势，对软件工程主题和强化学习算法进行了分类，检查了数据集使用、模型设计和优化以及评估实践等关键因素。此外，还识别了开放挑战并提出了未来的研究方向。

**Conclusion:** 本综述首次系统地描绘了强化学习在软件工程中的应用，旨在帮助研究人员和从业者了解当前状况并推动该领域的发展。

> **ai_Abstract:** 本文对自2015年深度强化学习出现以来，强化学习在软件工程领域的应用进行了首次系统性综述。通过分析115篇发表在顶级会议上的同行评审研究，文章详细探讨了出版趋势、软件工程主题与强化学习算法的结合、数据集使用、模型设计与优化以及评估实践等关键方面。此外，综述还识别了现有挑战并提出了未来的研究方向，旨在为该领域的研究人员和从业者提供全面的指导和参考。

> **摘要翻译:** 强化学习（RL）已成为一种强大的顺序决策范式，并在各个领域引起了越来越多的兴趣，特别是在2015年深度强化学习（DRL）出现之后。同时，大型语言模型（LLMs）的快速发展进一步激发了将RL与LLMs结合以实现更具适应性和智能系统的兴趣。在软件工程（SE）领域，系统复杂性的增加和自动化需求的上升促使研究人员将RL应用于从软件设计和开发到质量保证和维护的广泛任务。尽管RL在SE领域的研究日益增多，但目前仍缺乏对这一不断发展领域的全面系统综述。为了弥补这一空白，我们审查了自DRL引入以来在22个顶级SE会议上发表的115篇同行评审研究。我们对出版趋势进行了全面分析，对SE主题和RL算法进行了分类，并检查了数据集使用、模型设计和优化以及评估实践等关键因素。此外，我们还确定了开放挑战并提出了未来的研究方向，以指导和启发该领域正在进行的工作。总而言之，本综述首次系统地描绘了强化学习在软件工程中的应用，旨在支持研究人员和从业者了解当前状况并推动该领域的发展。我们的研究成果已公开：https://github.com/KaiWei-Lin-lanina/RL4SE。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [224] [Write Your Own CodeChecker: An Automated Test-Driven Checker Development Approach with LLMs](https://arxiv.org/abs/2411.06796)
> *编写你自己的代码检查器：一种基于LLM的自动化测试驱动检查器开发方法*

*Jun Liu, Yuanyuan Xie, Jiwei Yan, Jinhao Huang, Jun Yan, Jian Zhang* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** LLMs, 代码检查器, 自动化开发, 测试驱动, API上下文检索

**Comment:** update metadata and artifact url

> **TL;DR:** AutoChecker是一种基于大型语言模型（LLM）的方法，它能根据规则描述和测试套件自动生成代码检查器，并在性能上显著优于现有基线。

**AI_Comments:** 本文的创新点在于利用大型语言模型（LLM）实现代码检查器的自动化开发，有效解决了传统手动开发中抽象逻辑和复杂API使用带来的挑战。其核心优势在于采用增量式逻辑更新和细粒度的逻辑引导API上下文检索策略，这对于LLM生成高质量、高准确性代码至关重要。实验结果显示出色的测试通过率和在真实项目中的应用表现，证明了该方法在提升软件质量和开发效率方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着代码质量保证需求的增长，开发人员不仅使用现有的静态代码检查器，还需要定制检查器来满足特定需求。然而，抽象的检查逻辑和大型检查框架复杂的API使用使得开发定制检查器成为一项挑战，因此亟需自动化代码检查器生成方法来减轻开发负担。

**Method:** 本文提出了AutoChecker，一种创新的基于LLM的方法，它仅根据规则描述和测试套件即可自动编写代码检查器。为实现全面的检查逻辑，AutoChecker通过每次专注于解决一个选定的用例来增量更新检查器逻辑。为获取精确的API知识，在每次迭代中，它利用细粒度的逻辑引导API上下文检索，即首先将检查逻辑分解为一系列子操作，然后为每个子操作检索与检查器相关的API上下文。

**Result:** 在针对20个PMD规则生成检查器的评估中，AutoChecker与五个基线方法和三个消融方法进行了比较，结果显示AutoChecker在所有有效性指标上均显著优于其他方法，平均测试通过率达到82.28%。此外，AutoChecker生成的检查器可以成功应用于真实世界项目，性能与官方检查器相匹配。

**Conclusion:** AutoChecker是一种高度有效且优越的自动化代码检查器开发方法，它利用LLM根据规则描述和测试套件生成高质量的代码检查器，并且这些检查器能够成功应用于实际项目，性能媲美官方检查器。

> **ai_Abstract:** AutoChecker是一种基于大型语言模型（LLM）的自动化代码检查器开发方法。它仅需规则描述和测试套件即可生成检查器，通过增量更新逻辑和细粒度的API上下文检索来确保准确性。实验证明，AutoChecker在多个评估指标上显著优于现有基线，并能生成在真实项目中与官方检查器性能相当的代码检查器。

> **摘要翻译:** 随着代码质量保证需求的不断增长，开发人员不仅在使用现有的静态代码检查器，还在寻求定制检查器以满足其特定需求。如今，各种代码检查框架提供了广泛的检查器定制接口来满足这一需求。然而，抽象的检查逻辑和大型检查框架复杂的API使用使得这项任务充满挑战。为此，自动化代码检查器生成有望减轻检查器开发的负担。在本文中，我们提出了AutoChecker，一种创新的基于LLM的方法，它仅根据规则描述和测试套件即可自动编写代码检查器。为了实现全面的检查逻辑，AutoChecker通过每次专注于解决一个选定的用例来增量更新检查器逻辑。为了获取精确的API知识，在每次迭代中，它利用细粒度的逻辑引导API上下文检索，即首先将检查逻辑分解为一系列子操作，然后为每个子操作检索与检查器相关的API上下文。为了进行评估，我们应用AutoChecker、五个基线方法和三个消融方法，使用多个LLM为20个随机选择的PMD规则生成检查器。实验结果表明，AutoChecker在所有有效性指标上均显著优于其他方法，平均测试通过率达到82.28%。此外，AutoChecker生成的检查器可以成功应用于真实世界项目，性能与官方检查器相匹配。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [261] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
> *当检索器遇到生成器：一个用于代码注释生成的联合模型*

*Tien P. T. Le, Anh M. T. Bui, Huy N. D. Pham, Alessio Bucaioni, Phuong T. Nguyen* | **Category: cs.SE** | **Updated: 2025-07-16**

**Keywords:** 代码注释生成, 检索增强生成, CodeT5, 联合模型, RAGSum

**Comment:** The paper has been peer-reviewed and accepted for publication in the
  proceedings of the 19th ACM/IEEE International Symposium on Empirical
  Software Engineering and Measurement (ESEM 2025)

> **TL;DR:** 本文提出了RAGSum，一个基于CodeT5的联合检索-生成模型，用于代码注释生成，通过紧密耦合检索和生成过程，显著优于现有基线。

**AI_Comments:** 本文的创新之处在于将检索和生成过程紧密耦合在一个统一的CodeT5模型中，通过复合损失函数和自细化循环解决了传统检索增强方法中独立优化导致的噪声传播问题。这种集成方法显著提升了代码注释生成的质量，为该领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 自动为源代码生成简洁、信息丰富的注释可以减轻文档工作量并加速程序理解。然而，现有的检索增强方法通常独立优化检索和生成过程，导致不相关邻居向下游传播噪声。

**Method:** 本文提出RAGSum，一个将检索和生成融合到单一CodeT5主干上的新方法。模型通过对比预训练阶段塑造代码嵌入以进行最近邻搜索，并使用复合损失进行端到端训练，该损失同时奖励准确的top-k检索并最小化注释生成错误。此外，还部署了一个轻量级自细化循环来完善最终输出。

**Result:** 该框架在三个跨语言基准（Java、Python、C）上进行了评估，并与三个成熟的基线进行了比较。结果表明，RAGSum在BLEU、METEOR和ROUTE-L方面显著优于基线。

**Conclusion:** 研究结果表明，紧密耦合检索和生成可以提高注释自动化的上限，并激励未来的复制和定性开发人员研究。

> **ai_Abstract:** 本文提出了RAGSum，一个用于自动代码注释生成的创新联合模型，它在单一CodeT5主干中集成了检索和生成过程。针对现有检索增强方法中检索与生成独立优化导致的噪声传播问题，RAGSum采用对比预训练来优化代码嵌入，并通过复合损失进行端到端训练，同时引入自细化循环。在Java、Python和C等跨语言基准上的评估显示，RAGSum在BLEU、METEOR和ROUTE-L等指标上显著优于现有基线，证明了紧密耦合检索和生成能够有效提升代码注释自动化水平。

> **摘要翻译:** 自动为源代码生成简洁、信息丰富的注释可以减轻文档工作量并加速程序理解。检索增强方法首先获取带有现有注释的代码片段，然后合成新的注释，但检索和生成通常是独立优化的，这使得不相关的邻居会将噪声向下游传播。为了解决这个问题，我们提出了一种名为 RAGSum 的新方法，旨在提高推荐的有效性和效率。RAGSum 建立在单一 CodeT5 主干上，融合了检索和生成。我们报告了基于 CodeT5 构建的统一检索-生成框架的初步结果。对比预训练阶段塑造了用于最近邻搜索的代码嵌入；这些权重随后通过复合损失进行端到端训练，该损失（i）奖励准确的 top-k 检索；（ii）最小化注释生成错误。更重要的是，部署了一个轻量级自细化循环来完善最终输出。我们在三个跨语言基准（Java、Python、C）上评估了该框架，并将其与三个成熟的基线进行了比较。结果表明，我们的方法在 BLEU、METEOR 和 ROUTE-L 方面显着优于基线。这些发现表明，紧密耦合检索和生成可以提高注释自动化的上限，并激励未来的复制和定性开发人员研究。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [278] [AI Safety in the Eyes of the Downstream Developer: A First Look at Concerns, Practices, and Challenges](https://arxiv.org/abs/2503.19444)
> *下游开发者视角的AI安全：关注点、实践与挑战的初步探究*

*Haoyu Gao, Mansooreh Zahedi, Wenxin Jiang, Hong Yi Lin, James Davis, Christoph Treude* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** AI安全, 下游开发者, 预训练模型, 实践, 挑战

**Comment:** 

> **TL;DR:** 本研究首次探讨了下游开发者在AI安全方面的关注点、实践和挑战，发现开发者普遍有意识但实践不足，缺乏具体指导和政策导致安全措施不一。

**AI_Comments:** 该论文的创新之处在于其首次将AI安全研究的视角聚焦于下游开发者，填补了现有研究的空白。通过混合方法研究，其结果具有较高的可信度和实践指导意义。论文揭示了AI安全实践中存在的意识与行动脱节的问题，强调了制定具体指导方针、改善文档和弥补知识差距的重要性。这对于推动AI安全从理论走向实践，尤其是在快速发展的AI应用领域，具有重要的指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 预训练模型（PTMs）在AI软件中广泛应用，但也引入了独特安全挑战（如数据泄露和偏见输出）。尽管已有AI安全分类和缓解策略的研究，但下游开发者如何应对这些问题仍未被探索。

**Method:** 本研究采用混合方法，包括对18名参与者进行访谈、对86名从业者进行问卷调查，以及对AI事件数据库中874起AI事件进行分析。

**Result:** 研究结果表明，开发者普遍对AI安全问题有较强的意识，但他们的实践，尤其是在准备和PTM选择阶段，往往不足。缺乏具体的指导方针和政策导致他们在整个开发生命周期中安全方法的一致性差异很大，此外，文档不足和知识差距等挑战进一步阻碍了有效实施。

**Conclusion:** 基于研究发现，本研究为PTM开发者、AI软件开发者、研究人员和政策制定者提供了建议，以加强AI安全措施的整合。

> **ai_Abstract:** 本研究首次深入探讨了下游开发者在AI安全方面的关注点、实践和挑战，特别是在广泛采用预训练模型（PTMs）的背景下。通过混合方法研究，包括访谈、问卷调查和事件数据库分析，研究发现开发者普遍意识到AI安全问题，但其具体实践，尤其是在开发早期阶段，存在不足。缺乏明确的指导方针、糟糕的文档和知识鸿沟是阻碍有效安全实施的关键挑战。基于这些发现，论文提出了针对不同利益相关者的建议，以促进AI安全措施的更好整合。

> **摘要翻译:** 预训练模型（PTMs）已成为基于AI软件的基石，能够以最少的训练开销实现快速集成和开发。然而，它们的采用也引入了独特的安全挑战，例如数据泄露和偏见输出，这些挑战要求下游开发者进行严格处理。虽然之前的研究提出了AI安全问题的分类法和各种缓解策略，但下游开发者如何解决这些问题仍未被探索。
本研究调查了下游开发者在基于AI软件开发过程中对AI安全问题的关注、实践和感知到的挑战。为此，我们进行了一项混合方法研究，包括对18名参与者的访谈、对86名从业者的调查，以及对AI事件数据库中874起AI事件的分析。我们的研究结果表明，虽然开发者普遍对AI安全问题表现出强烈的意识，但他们的实践，尤其是在准备和PTM选择阶段，往往不足。缺乏具体的指导方针和政策导致他们在整个开发生命周期中安全方法的全面性存在显著差异，此外，文档不足和知识差距等额外挑战进一步阻碍了有效实施。基于我们的发现，我们为PTM开发者、基于AI的软件开发者、研究人员和政策制定者提供了建议，以增强AI安全措施的集成。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [307] [ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells](https://arxiv.org/abs/2507.12561)
> *ROSE：基于Transformer的架构异味重构推荐*

*Samal Nursapa, Anastassiya Samuilova, Alessio Bucaioni. Phuong T. Nguyen* | **Category: cs.SE** | **Updated: 2025-07-16**

**Keywords:** 架构异味, 重构推荐, Transformer模型, CodeT5, 软件质量

**Comment:** The paper has been peer-reviewed and accepted for publication in the
  proceedings of the 19th ACM/IEEE International Symposium on Empirical
  Software Engineering and Measurement (ESEM 2025)

> **TL;DR:** 本文提出ROSE，一个使用预训练Transformer模型（CodeBERT和CodeT5）为架构异味推荐重构的系统。CodeT5在200多万个重构实例上表现出色，准确率达96.9%，F1值为95.2%。

**AI_Comments:** 本文的创新点在于将预训练的Transformer模型应用于软件重构推荐这一新兴领域，有效解决了现有异味检测工具缺乏修复建议的问题。其重要性在于为自动化软件维护和质量提升提供了新的途径，并开源了代码、模型和数据，有利于社区的进一步研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有工具可以检测架构异味，但很少提供修复建议，这降低了软件质量和可维护性。本文旨在弥合异味检测和可操作修复之间的差距。

**Method:** 本文将重构推荐任务构建为三类分类问题，并使用从11,149个开源Java项目中挖掘的200多万个重构实例，对预训练的Transformer模型CodeBERT和CodeT5进行了微调。

**Result:** CodeT5的准确率达到96.9%，F1值为95.2%，优于CodeBERT和传统基线模型。结果表明，基于Transformer的模型可以有效地连接异味检测和实际修复。

**Conclusion:** 基于Transformer的模型能够有效地弥合架构异味检测与可操作修复之间的差距，为未来的重构推荐系统奠定了基础。

> **ai_Abstract:** 本文提出了ROSE，一个利用预训练Transformer模型（CodeBERT和CodeT5）进行架构异味重构推荐的系统。通过将任务框定为三类分类问题，并在海量Java项目重构数据上进行微调，CodeT5模型表现出卓越的性能，准确率达96.9%，F1值为95.2%。研究结果证明了Transformer模型在弥合架构异味检测与实际修复之间差距的有效性，为未来的重构推荐系统奠定了基础。

> **摘要翻译:** 架构异味，如上帝类、循环依赖和中心辐射式依赖，会降低软件质量和可维护性。现有工具可以检测这些异味，但很少建议如何修复它们。本文探讨了使用预训练的Transformer模型——CodeBERT和CodeT5——根据检测到的异味推荐合适的重构。我们将该任务构建为三类分类问题，并在从11,149个开源Java项目中挖掘的200多万个重构实例上对这两个模型进行了微调。CodeT5实现了96.9%的准确率和95.2%的F1值，优于CodeBERT和传统基线。我们的结果表明，基于Transformer的模型可以有效地弥合异味检测和可操作修复之间的差距，为未来的重构推荐系统奠定了基础。我们以开放许可发布了所有代码、模型和数据，以支持可重现性和进一步研究。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [324] [Risks of ignoring uncertainty propagation in AI-augmented security pipelines](https://arxiv.org/abs/2407.14540)
> *AI增强安全管道中忽视不确定性传播的风险*

*Emanuele Mezzi, Aurora Papotti, Fabio Massacci, Katja Tuma* | **Category: cs.SE, cs.AI, cs.CR** | **Updated: 2025-07-17**

**Keywords:** AI增强系统, 不确定性传播, 安全管道, 风险分析, 模拟器

**Comment:** Accepted for publication in Risk Analysis: An International Journal

> **TL;DR:** AI系统集成到安全管道中，其性能不确定性可能导致安全威胁。本文首次量化了AI增强系统中不确定性传播的风险，并提出了捕获和量化不确定性的方法。

**AI_Comments:** 本文的创新点在于首次形式化并量化了AI增强安全管道中的不确定性传播问题，填补了该领域的空白。其重要性体现在对安全关键领域潜在风险的识别和量化，为未来AI系统评估政策提供了依据。局限性在于目前仅通过一个案例研究进行评估，且未来工作计划放宽假设并使用真实系统进行实验，表明当前仍处于早期验证阶段。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI技术集成到软件安全开发中，AI子系统（性能不确定）被组合成自动化管道，这带来了基本研究挑战并严重威胁安全关键领域。现有研究未估计AI增强系统中错误传播导致的不确定性。

**Method:** 提供了捕获不确定性传播的正式基础，开发了一个模拟器来量化不确定性，并通过一个案例研究评估了错误传播的模拟。

**Result:** 通过一个案例研究评估了错误传播的模拟，并讨论了方法的普适性和局限性，提出了关于AI系统评估政策的建议。

**Conclusion:** 本文首次形式化并量化了AI增强安全管道中不确定性传播的风险，并提出了评估政策建议，填补了该领域的空白。

> **ai_Abstract:** 本文研究了AI技术集成到软件安全开发管道中时，由于AI子系统性能不确定性导致的安全风险。指出现有研究未量化AI增强系统中不确定性传播，因此提出捕获不确定性传播的正式基础和模拟器来量化不确定性，并通过案例研究验证。研究还讨论了方法的普适性和局限性，并提出了AI系统评估政策建议。

> **摘要翻译:** 人工智能技术正被整合到基于软件系统的安全开发中，将基于人工智能的子系统（具有不确定性能水平）组合成自动化管道的趋势日益增长。这带来了根本性的研究挑战，并严重威胁到安全关键领域。尽管风险分析中存在关于不确定性的现有知识，但以前的工作都没有估计给定管道中错误传播的AI增强系统的不确定性。我们提供了捕获不确定性传播的正式基础，开发了一个模拟器来量化不确定性，并通过一个案例研究评估了错误传播的模拟。我们讨论了我们方法的普适性和局限性，并提出了关于AI系统评估政策的建议。未来的工作包括通过放宽剩余假设和通过真实系统进行实验来扩展该方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [326] [When Domains Collide: An Activity Theory Exploration of Cross-Disciplinary Collaboration](https://arxiv.org/abs/2506.20063)
> *当领域碰撞时：一项对跨学科协作的活动理论探索*

*Zixuan Feng, Thomas Zimmermann, Lorenzo Pisani, Christopher Gooley, Jeremiah Wander, Anita Sarma* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** 跨学科协作, 活动理论, 软件开发, 摩擦, 期望

**Comment:** Cross-disciplinary Collaboration, Activity Theory, Mixed-Methods

> **TL;DR:** 本研究利用活动理论探索跨学科软件开发中领域专家和软件开发人员之间的期望冲突和摩擦。

**AI_Comments:** 这篇论文通过引入活动理论，为理解跨学科软件开发团队中的冲突提供了一个新颖且扎实的理论框架。其结合定性访谈和定量调查的混合方法增强了研究的实证基础和结果的普适性。识别出具体的期望和摩擦点对于实践者和未来的研究都具有重要的指导意义，特别是对于改进跨学科团队协作和软件基础设施设计。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发团队日益多样化、嵌入式和跨学科，导致不同领域的专家与软件开发者协作时，因期望冲突、问题解决视角差异和优先事项冲突而产生摩擦。本研究旨在调查这种协作的动态。

**Method:** 采用活动理论（AT）作为分析框架，进行了一项扎根的实证调查，结合了混合方法。包括对24名参与者（12名领域专家和12名软件开发人员）的访谈，以及对293名参与者（161名领域专家和132名软件开发人员）的大规模验证调查。

**Result:** 概念化并实证地阐明了跨学科软件开发（CDSD）的动态。识别出软件开发者持有的八种期望和领域专家持有的六种期望。通过将这些期望映射到活动理论的组成部分，揭示了CDSD中的21种摩擦，并说明了它们出现的位置和方式。

**Conclusion:** 本研究为理解跨学科软件开发中的动态和摩擦提供了理论视角，并为未来的研究、从业者和基础设施设计提供了可操作的见解。

> **ai_Abstract:** 本文探讨了跨学科软件开发（CDSD）中领域专家（DEs）和软件开发人员（SDEs）之间的协作动态和摩擦。研究利用活动理论（AT）作为分析框架，通过访谈和大规模调查的混合方法，识别并映射了双方的期望，揭示了CDSD中21种常见的摩擦点及其产生机制。研究为理解和解决CDSD中的冲突提供了理论洞察和实践建议。

> **摘要翻译:** 背景：软件开发团队日益多样化、嵌入式和跨学科。来自不同领域的领域专家（DEs）与专业软件开发人员（SDEs）协作，在创建和维护复杂的生产软件方面带来了互补的专业知识。然而，相互冲突的期望、不同的问题解决视角和冲突的优先事项导致了摩擦。目的：本研究旨在通过探索领域专家和软件开发人员的期望，并理解这些摩擦在实践中如何表现，来调查新兴的跨学科软件开发（CDSD）协作的动态。方法：我们利用活动理论（AT）这一成熟的社会技术框架，作为分析视角，进行了一项扎根的实证调查，该调查通过一项混合方法研究进行，包括24次访谈（12名领域专家和12名软件开发人员）和一项针对293名参与者（161名领域专家和132名软件开发人员）的大规模验证调查。结果：我们概念化并实证地阐明了CDSD的动态。我们识别出软件开发人员持有的八种期望和领域专家持有的六种期望。通过将这些期望映射到活动理论的组成部分，我们揭示了CDSD中的21种摩擦，并说明了它们出现的位置和方式。结论：本研究为理解CDSD中的动态和摩擦提供了理论视角，并为未来的研究、从业者和基础设施设计提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [355] [QSpark: Towards Reliable Qiskit Code Generation](https://arxiv.org/abs/2507.12642)
> *QSpark：迈向可靠的Qiskit代码生成*

*Kiana Kheiri, Aamna Aamir, Andriy Miranskyy, Chen Ding* | **Category: cs.SE, cs.AI, quant-ph** | **Updated: 2025-07-16**

**Keywords:** Qiskit, 代码生成, 强化学习, 量子编程, 大型语言模型

**Comment:** 

> **TL;DR:** QSpark通过RL微调大模型，显著提升了Qiskit量子代码生成质量，但高级任务仍有挑战。

**AI_Comments:** 该论文的创新点在于将强化学习方法（GRPO和ORPO）应用于量子编程代码生成领域，并利用合成数据集进行微调，显著提升了Qiskit代码的生成质量。其重要性在于为AI辅助量子编程提供了一个更可靠的解决方案，有助于降低量子电路开发的错误率。然而，论文也指出，在解决高级量子编程任务方面仍存在局限性，未来研究可在此方向深入。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）如Granite-20B-Code和StarCoder生成的Qiskit代码存在缺陷，而量子电路必须具有容错性。

**Method:** 研究人员使用两个强化学习（RL）方法，即组相对策略优化（GRPO）和赔率比偏好优化（ORPO），对一个32B模型进行了微调，并使用了丰富的合成标注数据集。

**Result:** 在Qiskit HumanEval基准测试中，ORPO的Pass@1达到56.29%（比Granite-8B-QK高约10个百分点），GRPO达到49%，两者均优于所有通用基线；在原始HumanEval上，它们分别得分65.90%和63.00%。GRPO在基础任务上表现出色（54个任务中解决42个），ORPO在中间任务上表现出色（68个任务中解决41个），但两者都未能解决五个高级任务。

**Conclusion:** 研究结果表明AI辅助量子编程取得了显著进展，但在解决高级任务方面仍有进步空间。

> **ai_Abstract:** 本研究旨在解决大型语言模型生成有缺陷Qiskit量子代码的问题。通过使用GRPO和ORPO两种强化学习方法对一个32B模型进行微调，并在合成数据集上训练，QSpark模型在Qiskit HumanEval和原始HumanEval基准测试中均显著超越了现有基线模型。尽管在基础和中间任务上取得了显著成效，但高级任务的解决仍面临挑战，表明AI辅助量子编程虽有进步，但仍需进一步发展。

> **摘要翻译:** 量子电路必须具有容错性，然而像Granite-20B-Code和StarCoder这样的大型语言模型（LLMs）经常输出有缺陷的Qiskit代码。我们使用两种强化学习（RL）方法——组相对策略优化（GRPO）和赔率比偏好优化（ORPO），并利用一个丰富标注的合成数据集，对一个32B模型进行了微调。在Qiskit HumanEval基准测试中，ORPO的Pass@1达到56.29%（比Granite-8B-QK高约10个百分点），GRPO达到49%，两者均优于所有通用基线；在原始HumanEval上，它们分别得分65.90%和63.00%。GRPO在基础任务上表现出色（54个任务中解决42个），ORPO在中间任务上表现出色（68个任务中解决41个），但两者都未能解决五个高级任务，这突出了AI辅助量子编程的显著进步，但仍有进步空间。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [380] [CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance](https://arxiv.org/abs/2507.10646)
> *CodeAssistBench (CAB)：多轮聊天式代码辅助的数据集与基准测试*

*Myeongsoo Kim, Shweta Garg, Baishakhi Ray, Varun Kumar, Anoop Deoras* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-17**

**Keywords:** CodeAssistBench, 多轮聊天, 代码辅助, 基准测试, 大型语言模型

**Comment:** 

> **TL;DR:** CodeAssistBench (CAB) 是一个用于评估多轮聊天式代码辅助的基准框架。研究发现，虽然大型语言模型在Stack Overflow问题上表现良好，但在CAB的复杂、项目特定问题上表现不佳，揭示了其能力上的巨大差距。

**AI_Comments:** CAB的创新之处在于其能够自动从GitHub Issues生成数据集，并提供容器化的真实项目环境，这大大提高了基准测试的真实性和可扩展性。它填补了现有基准测试在多轮、项目级代码辅助评估方面的空白，对于推动大型语言模型在实际软件开发中的应用具有重要意义。研究结果也明确指出了当前大型语言模型在复杂上下文理解和问题解决上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型代码辅助基准测试主要关注代码生成任务，且多限于单轮交互、孤立上下文、需要大量手动整理，并无法代表完整的项目环境。为了解决这些局限性，本文提出了CodeAssistBench (CAB)。

**Method:** 本文介绍了CodeAssistBench (CAB)，一个评估多轮编程辅助在真实环境中解决实际代码库问题的基准框架。CAB通过可配置参数（如仓库创建日期、星标数、编程语言）从与问题相关的GitHub Issues中自动生成可扩展的数据集，并自动容器化代码库以进行评估。它通过模拟用户在这些具有完整代码库访问权限的容器化环境中评估模型。

**Result:** 使用CAB框架，构建了一个包含231个仓库中3,286个真实编程问题的测试集，涵盖七种编程语言和不同的问题领域。对领先的大型语言模型进行评估后发现存在显著的能力差距：模型在Stack Overflow问题上的成功率为70-83%，但在CAB的近期问题上解决率仅为16.49%。

**Conclusion:** 大型语言模型在复杂、项目特定的上下文中提供代码辅助时面临巨大挑战，与回答独立问题相比，其能力存在显著差距。

> **ai_Abstract:** 本文介绍了CodeAssistBench (CAB)，这是一个新颖的基准测试框架，旨在评估大型语言模型在多轮、真实世界代码辅助场景中的表现。针对现有基准测试在单轮交互和孤立环境中的局限性，CAB通过从GitHub Issues自动生成数据集并容器化代码库来模拟真实的开发环境。研究构建了一个包含3,286个问题的测试集，并发现领先的大型语言模型在CAB上的表现远低于其在Stack Overflow上的表现，表明在处理复杂、项目特定问题时存在显著的能力差距。

> **摘要翻译:** 大型语言模型驱动的编程助手已经改变了软件开发，但大多数基准测试都狭隘地关注代码生成任务。像InfiBench和StackEval这样的近期努力试图利用Stack Overflow数据来弥补这一差距，但仍局限于孤立上下文中的单轮交互，需要大量手动整理，并且未能代表完整的项目环境。我们引入了CodeAssistBench (CAB)，这是第一个用于评估真实环境中多轮编程辅助的基准框架，它解决了关于实际代码库的真实世界问题。与现有编程问答基准测试不同，CAB使用可配置参数（例如，仓库创建日期、星标数、编程语言）从与问题相关的GitHub Issues中自动生成可扩展的数据集，并包括代码库的自动容器化以进行评估。然后，它通过模拟用户在这些具有完整代码库访问权限的容器化环境中评估模型。使用此框架，我们构建了一个包含231个仓库中3,286个真实世界编程问题的测试集，涵盖七种编程语言和不同的问题领域。我们对领先的大型语言模型进行的评估揭示了巨大的能力差距：虽然模型在Stack Overflow问题上表现良好，成功率为70-83%，但它们仅解决了CAB近期问题的16.49%。这种差异凸显了在复杂、项目特定上下文中提供辅助与回答独立问题所面临的挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [399] [A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain](https://arxiv.org/abs/2507.12649)
> *智能电网领域中新信息和数据模型的三阶段评估方法*

*Christine van Stiphoudt, Sergio Potenciano Menci, Gilbert Fridgen* | **Category: cs.SE** | **Updated: 2025-07-16**

**Keywords:** 智能电网, 信息模型, 数据模型, 评估方法, 三阶段评估

**Comment:** 

> **TL;DR:** 针对智能电网中新信息和数据模型缺乏明确的评估方法，本文提出了一种结合显式和隐式方法的三阶段评估方法，并在工业灵活性描述模型开发中进行了验证。

**AI_Comments:** 本文的创新点在于提出了一种结合显式和隐式评估方法的三阶段评估框架，专门针对智能电网领域中新信息和数据模型在设计阶段的评估空白。这对于确保智能电网数字化转型的质量和稳定性具有重要意义。该方法采用设计科学研究，并通过具体案例进行完善，增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 智能电网数字化导致新信息和数据模型不断涌现，但现有评估方法不足以在设计阶段有效评估这些新模型，特别是缺乏结合显式和隐式方法的明确步骤，可能导致部署后出现缺陷和中断。

**Method:** 本文采用设计科学研究方法，设计了一个三阶段评估方法。该方法结合了显式和隐式评估方法，并适用于新信息和数据模型的开发。研究人员通过开发一个专注于工业灵活性描述的信息模型和数据模型来完善此评估方法。

**Result:** 提出了一种结合显式和隐式评估方法的三阶段评估方法，弥补了智能电网领域新信息和数据模型评估的空白。通过实际应用，该方法得到了完善，并提供了经验教训。

**Conclusion:** 该研究成功设计并完善了一种针对智能电网领域新信息和数据模型的三阶段评估方法，该方法填补了现有评估方法的空白，有助于在设计阶段发现并预防潜在缺陷。

> **ai_Abstract:** 本文针对智能电网领域中新信息和数据模型在设计阶段缺乏有效评估方法的现状，提出了一种创新的三阶段评估方法。该方法通过结合显式和隐式评估手段，旨在弥补现有方法的不足，确保新模型在部署前能够有效识别并规避潜在缺陷。研究通过一个专注于工业灵活性描述的信息模型和数据模型的开发案例，对所提出的方法进行了细化和验证，并分享了实践经验。

> **摘要翻译:** 智能电网的持续数字化导致分布式能源系统之间自动化信息交换的增加。当现有信息和数据模型不足时，这一过程导致了新信息和数据模型的开发。为了防止新设计的信息和数据模型中的缺陷可能引起的潜在中断，在它们投入运行之前，在设计过程中对其进行评估至关重要。
目前，智能电网领域之外的通用显式评估方法停留在高层次，没有定义明确的步骤。同时，智能电网领域内的隐式评估方法侧重于测试已在使用中的信息和数据模型的功能性，包括一致性和互操作性。值得注意的是，对于新设计的信息和数据模型，在智能电网背景下的设计过程中，没有明确定义步骤的显式和隐式评估方法的组合。
因此，我们采用设计科学研究方法设计了一种三阶段评估方法来解决这一空白。我们的评估方法结合了显式和隐式评估方法，适用于开发新的信息和数据模型。我们利用专注于工业灵活性描述的信息模型和数据模型的开发来完善我们的评估方法。此外，我们还提供了从我们的经验中吸取的教训。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [420] [SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks](https://arxiv.org/abs/2507.11059)
> *SWE-MERA：一个用于智能体评估大型语言模型在软件工程任务上表现的动态基准*

*Pavel Adamenko, Mikhail Ivanov, Aidar Valeev, Rodion Levichev, Pavel Zadorozhny, Ivan Lopatin, Dmitry Babayev, Alena Fenogenova, Valentin Malykh* | **Category: cs.SE, cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 软件工程, 基准测试, 数据污染, GitHub问题

**Comment:** 

> **TL;DR:** 引入SWE-MERA，一个动态、无污染的基准，用于更准确地评估软件工程中的LLM。

**AI_Comments:** SWE-MERA通过其动态更新机制和严格的污染控制，显著提升了LLM在软件工程任务评估的可靠性。其基于真实世界GitHub问题的收集方法也增强了基准的实用性。这是一个重要的进步，有助于克服现有基准的缺陷，为LLM在软件工程领域的进步提供更准确的衡量标准。

<details>
  <summary>Details</summary>

**Motivation:** 现有软件工程LLM基准（如SWE-bench）存在严重的数据污染和测试用例不足问题，导致评估结果不准确。

**Method:** 本文引入了SWE-MERA，一个动态、持续更新的基准，通过自动化收集真实世界的GitHub问题和严格的质量验证来构建。它实现了一个可靠的管道，以确保质量并最小化污染风险。目前已收集到约10,000个潜在任务，其中300个样本可用。评估使用Aider编码代理进行。

**Result:** SWE-MERA在评估最先进模型时显示出强大的区分能力。报告了在2024年9月至2025年6月期间收集的任务上，对十几个最新LLM的性能评估。

**Conclusion:** SWE-MERA成功解决了现有基准的数据污染和测试用例不足问题，提供了一个更可靠、动态的LLM软件工程评估工具，能够更准确地衡量LLM在软件工程任务上的表现。

> **ai_Abstract:** 本文介绍了SWE-MERA，一个针对软件工程领域大型语言模型评估的动态、持续更新的基准。该基准旨在解决现有数据集（如SWE-bench）中普遍存在的严重数据污染和测试用例不足问题。SWE-MERA通过自动化收集真实的GitHub问题并实施严格的质量验证流程来构建，以确保数据质量并最小化污染风险。初步评估显示，SWE-MERA对最先进的LLM具有强大的区分能力，并已用于评估多个最新LLM的性能。

> **摘要翻译:** 大型语言模型（LLMs）在软件工程领域的快速发展揭示了现有基准的关键局限性，特别是广泛使用的SWE-bench数据集。最近的研究发现严重的数
据污染问题，例如SWE-bench报告称32.67%的成功补丁涉及直接解决方案泄露，31.08%的补丁因测试用例不足而通过。我们引入了SWE-MERA，
一个动态、持续更新的基准，旨在通过自动化收集真实世界的GitHub问题和严格的质量验证来解决这些基本挑战。我们的方法实现了一个可靠的
管道，在确保质量的同时最大限度地降低污染风险，目前已产生大约10,000个潜在任务，其中300个样本可用。使用Aider编码代理进行的评估
表明，其对最先进的模型具有强大的区分能力。我们报告了在2024年9月至2025年6月期间收集的任务上，对十几个最新LLM的性能评估。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [439] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
> *项目成功的模糊方法：衡量重要事项*

*João Granja-Correia, Remedios Hernández-Linares, Luca Ferranti, Arménio Rego* | **Category: cs.SE, cs.CL, H.4.m** | **Updated: 2025-07-16**

**Keywords:** 模糊逻辑, 项目成功, Mamdani模糊系统, 绩效评估, 最终用户影响

**Comment:** 3 pages, 1 figure, presented at FUZZ-IEEE 2025

> **TL;DR:** 本文提出一种将模糊逻辑应用于项目成功评估的新方法，通过优先考虑对最终用户的持续积极影响，以期提供更准确的衡量。

**AI_Comments:** 本文创新性地将模糊逻辑应用于项目成功评估，解决了传统方法在处理复杂性和情境依赖性方面的局限。其核心在于将评估重点从次要指标转向对最终用户的实际、持续影响，这为项目管理实践提供了新的视角和更贴近实际的评估工具。该方法有望提升项目评估的准确性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的李克特量表衡量方法未能充分捕捉项目成功的情境依赖性和多面性，导致评估不够准确。

**Method:** 提出了一种将模糊逻辑整合到现有结构中的新型方法，具体为分层的Type-1 Mamdani模糊系统，该系统优先考虑对最终用户的持续积极影响，并减少对次要结果的强调。

**Result:** 这种动态方法可能提供更准确的项目成功衡量，并且可以适应复杂的评估。

**Conclusion:** 通过模糊逻辑方法，项目成功可以得到更准确的衡量，尤其是在强调最终用户持续积极影响方面。未来的研究将侧重于该方法在社会科学中的实证测试和更广泛应用。

> **ai_Abstract:** 本文介绍了一种创新的项目成功评估方法，通过将模糊逻辑整合到现有框架中，旨在克服传统李克特量表在处理项目成功多面性和情境依赖性方面的不足。所提出的分层Type-1 Mamdani模糊系统着重于项目对最终用户的持续积极影响，并有望提供更准确、更具适应性的项目成功衡量。

> **摘要翻译:** 这篇论文通过将模糊逻辑整合到现有结构中，引入了一种评估项目成功的新方法。传统的李克特量表衡量方法往往忽视项目成功的情境依赖性和多面性。所提出的分层Type-1 Mamdani模糊系统优先考虑对最终用户的持续积极影响，从而减少对利益相关者满意度和内部项目成功等次要结果的强调。这种动态方法可能提供更准确的项目成功衡量，并且可以适应复杂的评估。未来的研究将侧重于社会科学中模糊逻辑的实证测试和更广泛的应用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [455] [MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks](https://arxiv.org/abs/2507.12284)
> *MERA Code：一个用于评估跨任务代码生成的统一框架*

*Artem Chervyakov, Alexander Kharitonov, Pavel Zadorozhny, Adamenko Pavel, Rodion Levichev, Dmitrii Vorobev, Dmitrii Salikhov, Aidar Valeev, Alena Pestova, Maria Dziuba, Ilseyar Alimova, Artem Zavgorodnev, Aleksandr Medvedev, Stanislav Moiseev, Elena Bruches, Daniil Grebenkin, Roman Derunets, Vikulov Vladimir, Anton Emelyanov, Dmitrii Babaev, Vladimir V. Ivanov, Valentin Malykh, Alena Fenogenova* | **Category: cs.SE, cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 代码生成, LLM评估, MERA Code, 基准测试, 软件工程

**Comment:** 

> **TL;DR:** MERA Code 是一个新的基准测试，用于评估大型语言模型在多种编程语言和任务中的代码生成能力，尤其关注非英语环境和实际编码技能。

**AI_Comments:** MERA Code的创新之处在于其对代码生成LLM评估的全面性和实用性。它不仅涵盖了多种编程语言和任务，更重要的是，它关注了模型在实际编码技能上的表现，并特别强调了非英语环境。这弥补了现有基准测试的不足，为LLM在软件工程领域的实际应用提供了更可靠的评估工具。其开源性质和标准化目标对于社区的协作和发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的LLM评估主要集中在自然语言任务上，忽略了代码质量、可执行性以及模型在实际生产环境中的真实能力和风险。

**Method:** 提出了MERA Code，这是MERA基准测试家族的新成员，专门用于评估最新代码生成LLM（特别是俄语）。该基准包括11个评估任务，涵盖8种编程语言。评估方法包含一个分类法，概述了模型完成这些任务所需的实际编码技能。MERA Code还包括一个开源代码库、一个兼容多种编程环境的评分系统和一个包含排行榜和提交系统的平台。

**Result:** 我们评估了开放LLM和前沿API模型，分析了它们在非英语语言的实际编码任务中的局限性。

**Conclusion:** 公开发布MERA旨在指导未来的研究，预测模型开发中的突破性功能，并标准化评估程序。

> **ai_Abstract:** 本文提出了MERA Code，一个针对代码生成大型语言模型的新评估框架。鉴于现有评估在代码质量、可执行性和实际应用方面存在不足，MERA Code提供了一个包含11项任务和8种编程语言的基准测试，尤其关注非英语环境中的实际编码技能。该框架包含一个详细的技能分类法、开源代码库、灵活的评分系统和在线平台。通过对现有LLM的评估，MERA Code揭示了它们在非英语实际编码任务中的局限性，旨在推动未来研究并标准化代码生成模型的评估。

> **摘要翻译:** 大型语言模型（LLM）的进步增强了软件工程中的任务自动化；然而，当前的评估主要集中在自然语言任务上，忽视了代码质量。大多数基准测试优先考虑高级推理而非可执行代码和实际性能，这使得人们在理解这些模型在生产中的真实能力和相关风险方面存在空白。为了解决这个问题，我们提出了MERA Code，这是MERA基准测试家族的新成员，专门用于评估最新代码生成LLM（特别是俄语）的代码。该基准包括11个评估任务，涵盖8种编程语言。我们提出的评估方法具有一个分类法，概述了模型完成这些任务所需的实际编码技能。该基准包括一个用于用户进行MERA评估的开源代码库、一个兼容各种编程环境的评分系统以及一个包含排行榜和提交系统的平台。我们评估了开放LLM和前沿API模型，分析了它们在非英语语言的实际编码任务方面的局限性。我们正在公开发布MERA，以指导未来的研究，预测模型开发中的突破性功能，并标准化评估程序。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [468] [Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development](https://arxiv.org/abs/2507.12665)
> *单一对话方法论：一种以人为中心的AI辅助软件开发协议*

*Salvador D. Escobedo* | **Category: cs.SE, cs.AI, cs.HC** | **Updated: 2025-07-16**

**Keywords:** 单一对话方法论, AI辅助软件开发, 大型语言模型, 人为中心, 软件工程

**Comment:** Style reviewed by a LLM for improving clarity and English syntax

> **TL;DR:** 本文提出了一种名为单一对话方法论（SCM）的新型AI辅助软件开发方法，通过在单个长上下文对话中处理所有项目阶段，旨在纠正对大型语言模型（LLMs）的被动依赖，并重新确立开发者作为智能工具的主动角色。

**AI_Comments:** 该论文提出了一种创新的、以人为本的AI辅助软件开发方法，通过强调“单一对话”和“长上下文”来解决LLMs在开发中应用时的碎片化和被动依赖问题。其重要性在于试图重新定义开发者与AI工具的关系，从被动使用者转变为主动的架构师和监督者，这对于未来AI集成开发实践具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对当前生成式AI在软件开发中存在的“临时性交互”问题，以及开发者对大型语言模型（LLMs）的被动依赖，本文提出了一种强调开发者主动作用的结构化、持久性开发对话方法。

**Method:** 本文提出单一对话方法论（SCM），这是一种以人为中心的协议，旨在通过在一个单一的、长上下文对话中处理项目的所有阶段（从需求到架构和实现）来有效利用大型语言模型（LLMs）。该方法论基于认知清晰度、可追溯性、模块化和文档化等原则，并详细定义了其阶段、最佳实践和哲学立场。

**Result:** Not mentioned in abstract

**Conclusion:** 单一对话方法论（SCM）为AI辅助软件开发提供了一种必要的纠正，旨在将开发者的角色重新确立为智能工具的架构师和监督者，而非被动依赖大型语言模型（LLMs）。

> **ai_Abstract:** 本文提出了一种新颖的单一对话方法论（SCM），旨在改进AI辅助软件开发。该方法通过在一个单一的、长上下文对话中整合从需求到实现的所有项目阶段，结构化地使用大型语言模型（LLMs）。SCM以认知清晰度、可追溯性、模块化和文档化为原则，旨在纠正当前对LLMs的被动依赖，并重新确立开发者作为智能工具的架构师和监督者的主动角色。

> **摘要翻译:** 我们提出单一对话方法论（SCM），一种使用大型语言模型（LLMs）进行软件开发的创新且实用的方法。与生成式AI的临时性交互不同，SCM强调一种结构化和持久性的开发对话，其中项目的所有阶段——从需求到架构和实现——都在一个单一的、长上下文对话中展开。该方法论以认知清晰度、可追溯性、模块化和文档化原则为基础。我们定义了其阶段、最佳实践和哲学立场，同时论证SCM为纠正当前实践中普遍存在的对LLMs的被动依赖提供了必要的修正。我们的目标是重新确立开发者作为智能工具的架构师和监督者的主动作用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [479] [Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases](https://arxiv.org/abs/2507.13035)
> *研究小型语言模型在检测手动测试用例中测试异味方面的性能*

*Keila Lucas, Rohit Gheyi, Márcio Ribeiro, Fabio Palomba, Luana Martins, Elvys Soares* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** 小型语言模型, 测试异味检测, 手动测试用例, Phi-4, 质量改进

**Comment:** 7 pages, Accepted at Insightful Ideas and Emerging Results (IIER)
  Track of the Brazilian Symposium on Software Engineering (SBES 2025)

> **TL;DR:** 本研究评估了小型语言模型（SLMs）在检测手动测试用例中测试异味方面的潜力。Phi-4表现最佳，在检测包含测试异味的句子方面达到了97%的pass@2，并且SLMs还能自动解释问题并提出改进建议，无需明确的规则定义。

**AI_Comments:** 这项研究的创新之处在于首次将小型语言模型（SLMs）应用于手动测试用例的测试异味检测，并证明了其有效性。它解决了现有检测工具依赖手动规则定义和可扩展性差的问题，通过利用SLMs的自然语言理解能力，实现了自动化、概念驱动的检测。SLMs不仅能识别问题，还能提供解释和改进建议，这对于提高测试效率和质量具有重要意义。此外，SLMs在保护数据隐私方面的优势也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自动化测试工具存在，但手动测试对于发现自动化难以捕捉的问题仍然至关重要。然而，手动测试用例常存在测试异味（如歧义、冗余），这些异味会降低测试的可靠性和可维护性。现有的检测工具通常需要手动定义规则且缺乏可扩展性。

**Method:** 本研究评估了Gemma3、Llama3.2和Phi-4这三种小型语言模型（SLMs），在143个真实的Ubuntu测试用例上，涵盖了七种类型的测试异味，以调查它们自动检测测试异味的潜力。

**Result:** Phi-4在检测包含测试异味的句子方面取得了最佳结果，达到了97%的pass@2，而Gemma3和Llama3.2的准确率约为91%。此外，SLMs甚至在没有明确提示指令的情况下，也能自主解释问题并提出改进建议。

**Conclusion:** 研究结果突出了小型语言模型（SLMs）作为高效工具的潜力，它们能够保护数据隐私，并在实际场景中提高测试质量。SLMs实现了低成本、概念驱动的多种测试异味识别，无需依赖大量的规则定义或语法分析。

> **ai_Abstract:** 本研究旨在评估小型语言模型（SLMs）在自动检测手动测试用例中测试异味方面的性能。针对手动测试用例中常见的质量问题（如歧义、冗余），传统检测工具存在手动规则定义和可扩展性不足的缺点。研究人员使用Gemma3、Llama3.2和Phi-4三种SLM，在包含七种测试异味的143个真实Ubuntu测试用例上进行了评估。结果显示，Phi-4表现最佳，在检测测试异味句子方面达到了97%的pass@2，其他模型也达到91%左右。更重要的是，SLMs无需明确指令即可解释问题并提出改进建议，实现了低成本、概念驱动的检测，无需大量规则或语法分析。这表明SLMs在提高实际测试质量和保护数据隐私方面具有巨大潜力。

> **摘要翻译:** 手动测试中，测试人员遵循自然语言指令来验证系统行为，这对于发现自动化难以捕捉的问题仍然至关重要。然而，这些测试用例常常存在测试异味，例如歧义、冗余或遗漏检查等质量问题，这些问题会降低测试的可靠性和可维护性。尽管存在检测工具，但它们通常需要手动定义规则且缺乏可扩展性。本研究调查了小型语言模型（SLMs）自动检测测试异味的潜力。我们评估了Gemma3、Llama3.2和Phi-4在143个真实的Ubuntu测试用例上的表现，涵盖了七种类型的测试异味。Phi-4取得了最佳结果，在检测包含测试异味的句子方面达到了97%的pass@2，而Gemma3和Llama3.2的准确率约为91%。除了检测之外，SLMs甚至在没有明确提示指令的情况下，也能自主解释问题并提出改进建议。它们实现了低成本、概念驱动的多种测试异味识别，无需依赖大量的规则定义或语法分析。这些发现突出了SLMs作为高效工具的潜力，它们能够保护数据隐私并在实际场景中提高测试质量。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [524] [iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](https://arxiv.org/abs/2507.13081)
> *iReDev：一个知识驱动的多智能体框架，用于智能需求开发*

*Dongming Jin, Weisong Sun, Jiangping Huang, Peng Liang, Jifeng Xuan, Yang Liu, Zhi Jin* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** 需求开发, 多智能体系统, 知识驱动, 人机协作, iReDev

**Comment:** 22pages, 4 figures

> **TL;DR:** iReDev是一个知识驱动的多智能体框架，通过整合人类知识和人机协作，提升了需求开发的效率和质量。

**AI_Comments:** iReDev的创新之处在于其知识驱动的多智能体架构，特别是对人类知识的整合和“人在回路”机制，这使得智能体能够更好地模拟真实世界的利益相关者并支持人机协作。其事件驱动的通信机制也提升了对新需求的响应速度。这项工作对于解决软件需求开发中的效率和质量问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 需求开发是一个耗时且劳动密集型的关键阶段，现有研究对需求开发的支持有限，并且忽略了将人类知识注入智能体以及人机协作。

**Method:** 本文提出了一个名为iReDev的知识驱动多智能体框架，用于智能需求开发。iReDev包含六个知识驱动智能体，支持整个需求开发过程；它专注于整合人类知识以模拟真实世界的利益相关者；采用基于工件池的事件驱动通信机制；并引入了人机协作的“人在回路”机制。

**Result:** 我们评估了生成的工件，结果表明iReDev在多个方面优于现有基线。

**Conclusion:** 本研究希望促进智能需求开发的发展，并进一步展望了三个关键方向。

> **ai_Abstract:** iReDev是一个新颖的知识驱动多智能体框架，旨在解决传统需求开发中耗时费力且缺乏人机协作的问题。该框架由六个知识驱动智能体组成，通过整合人类知识、采用事件驱动通信机制和引入“人在回路”机制，模拟真实利益相关者并支持人机协作，以高效地生成软件需求规范。实验结果表明，iReDev在多个方面优于现有基线。

> **摘要翻译:** 需求开发是一个关键阶段，因为它负责提供对利益相关者需求的清晰理解。它涉及利益相关者之间的协作，以提取明确的需求并解决潜在的冲突，这既耗时又费力。最近，用于软件开发的多智能体系统引起了广泛关注。然而，现有研究对需求开发的支持有限，并且忽略了将人类知识注入智能体以及人机协作。为了解决这些问题，本文提出了一个名为iReDev的知识驱动多智能体框架，用于智能需求开发。iReDev的特点是：iReDev由六个知识驱动智能体组成，以支持整个需求开发过程。它们协同执行各种任务，以生成软件需求规范。iReDev专注于为智能体整合人类知识，使它们能够模拟真实世界的利益相关者。iReDev使用基于工件池的事件驱动通信机制。智能体持续监控池并根据其变化自主触发下一个动作，使iReDev能够快速处理新需求。iReDev引入了“人在回路”机制来支持人机协作，确保生成的工件符合利益相关者的期望。我们评估了生成的工件，结果表明iReDev在多个方面优于现有基线。我们进一步展望了三个关键方向，希望这项工作能够促进智能需求开发的发展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [569] [A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems](https://arxiv.org/abs/2507.13095)
> *预训练模型赋能系统需求工程的概念框架*

*Dongming Jin, Zhi Jin, Linyu Li, Xiaohong Chen* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** 需求工程, 预训练模型, 概念框架, 软件系统, 人工智能

**Comment:** 5pages, 1 figure

> **TL;DR:** 预训练模型引入的独特特性挑战了传统需求工程。本文提出了一个概念框架来应对这些挑战，并指明了未来的研究方向。

**AI_Comments:** 该论文识别了预训练模型在软件系统中应用对传统需求工程范式带来的根本性挑战，并提出了一个概念性框架，这对于理解和解决新兴的软件开发问题具有重要意义。其创新之处在于针对这类新型系统提出了专门的需求工程方法论，而非简单沿用旧有假设。

<details>
  <summary>Details</summary>

**Motivation:** 预训练模型作为核心组件广泛集成到软件系统中，但其模糊的能力边界、上下文依赖行为和持续演进等特性，对传统需求工程的假设（如功能可分解性和行为可预测性）提出了根本性挑战。

**Method:** 提出一个针对预训练模型赋能软件系统需求工程的概念框架，并概述了该框架内的几个有前景的研究方向。

**Result:** 该愿景有助于为研究人员和实践者提供指导，以应对预训练模型赋能系统需求工程中出现的新挑战。

**Conclusion:** 提出的概念框架和研究方向将指导研究人员和实践者有效应对预训练模型系统在需求工程领域的新兴挑战。

> **ai_Abstract:** 本文针对预训练模型在软件系统中广泛应用所带来的需求工程挑战进行了探讨。由于预训练模型具有模糊能力边界、上下文依赖和持续演进等特性，传统需求工程的假设受到冲击。作者提出一个专门的概念框架，旨在重新思考并指导预训练模型赋能系统的需求工程实践，并指明了未来的研究方向，以帮助研究人员和实践者应对新兴挑战。

> **摘要翻译:** 近来大型预训练模型的进展使其作为核心组件广泛集成到现代软件系统中。预计这一趋势在可预见的未来仍将持续。与受确定性逻辑支配的传统软件系统不同，由预训练模型驱动的系统展现出独特且新兴的特性，例如模糊的能力边界、上下文依赖行为和持续演进。这些特性从根本上挑战了需求工程中长期存在的假设，包括功能可分解性和行为可预测性。本文研究了这个问题，并倡导重新思考现有的需求工程方法。我们提出了一个专门针对预训练模型赋能软件系统需求工程的概念框架，并概述了该框架内的几个有前景的研究方向。这一愿景有助于为研究人员和实践者提供指导，以应对预训练模型赋能系统需求工程中出现的新挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [618] [Inferring Attributed Grammars from Parser Implementations](https://arxiv.org/abs/2507.13117)
> *从解析器实现中推断属性文法*

*Andreas Pointner, Josef Pichler, Herbert Prähofer* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** 属性文法, 解析器实现, 语义恢复, 文法挖掘, 递归下降解析器

**Comment:** Accepted to ICSME 2025

> **TL;DR:** 本文提出了一种从解析器实现中推断属性文法的新方法，通过动态分析递归下降解析器并映射运行时行为来恢复输入处理的语义。

**AI_Comments:** 这项工作具有创新性，因为它将文法挖掘的范围从纯粹的语法结构扩展到了语义方面，这是现有研究的盲点。通过动态分析解析器实现来推断属性文法，为软件逆向工程、规范恢复和程序理解提供了一条新途径。其重要性在于，完整的规范（包括语义）对于软件维护、演化和互操作性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 软件系统处理结构化输入时，通常缺乏完整且最新的规范，尤其是在输入处理的语义方面。现有文法挖掘技术主要关注语法结构恢复，而语义方面仍未被充分探索。

**Method:** 本研究引入了一种从解析器实现中推断属性文法的新方法。给定一个输入文法，该技术动态分析递归下降解析器的实现，以重建输入处理的语义方面。通过观察程序执行并将程序的运行时行为映射到文法，系统地提取语义动作并将其嵌入到文法规则中。

**Result:** 该方法能够生成属性文法形式的规范，并通过一组初始程序证明了其可行性，表明它可以通过生成的属性文法准确地重现程序行为。

**Conclusion:** 该方法能够实现全面的规范恢复，填补了现有文法挖掘技术在语义恢复方面的空白。

> **ai_Abstract:** 本文提出了一种从解析器实现中推断属性文法的新颖方法，旨在解决现有文法挖掘技术在恢复输入处理语义方面的不足。该方法通过动态分析递归下降解析器的运行时行为，并将其映射到文法规则中，从而系统地提取并嵌入语义动作，生成包含语法和语义信息的属性文法。实验证明，该方法能够有效地恢复程序规范并准确重现程序行为。

> **摘要翻译:** 处理结构化输入的软件系统通常缺乏完整且最新的规范，这些规范规定了输入语法和输入处理的语义。虽然文法挖掘技术主要侧重于恢复语法结构，但输入处理的语义在很大程度上仍未被探索。在这项工作中，我们介绍了一种从解析器实现中推断属性文法的新方法。给定一个输入文法，我们的技术动态分析递归下降解析器的实现，以重建输入处理的语义方面，从而以属性文法的形式生成规范。通过观察程序执行并将程序的运行时行为映射到文法，我们系统地提取语义动作并将其嵌入到文法规则中。这使得全面的规范恢复成为可能。我们使用一组初始程序演示了我们方法的可行性，表明它可以通过生成的属性文法准确地重现程序行为。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [659] [Detecting LLM-generated Code with Subtle Modification by Adversarial Training](https://arxiv.org/abs/2507.13123)
> *通过对抗训练检测经过细微修改的LLM生成代码*

*Xin Yin, Xinrui Li, Chao Ni, Xiaodan Xu, Xiaohu Yang* | **Category: cs.SE** | **Updated: 2025-07-17**

**Keywords:** LLM代码检测, 对抗训练, 代码鲁棒性, CodeGPTSensor+, MIST

**Comment:** 

> **TL;DR:** 针对LLM生成代码在经过细微修改后难以检测的问题，本文提出了CodeGPTSensor+，它通过对抗训练和多目标标识符与结构转换（MIST）模块显著提高了对对抗样本的检测准确性和鲁棒性。

**AI_Comments:** 本文解决了LLM生成代码检测领域的一个关键实际挑战，即代码在经过细微修改后的鲁棒性问题。其创新点在于引入了对抗训练机制和MIST模块来系统地生成对抗样本，这对于提升模型在现实世界应用中的泛化能力和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）生成代码的广泛应用，代码溯源、版权纠纷和代码质量等问题日益突出，因此有效检测LLM生成代码变得至关重要。然而，LLM生成代码在实际应用中常会经历手动修改，如变量重命名或结构调整，现有检测方法在面对这些修改后的代码时鲁棒性不足，缺乏有效的解决方案。

**Method:** 本文提出了CodeGPTSensor+，它是CodeGPTSensor的增强版，通过采用对抗训练来提高对输入扰动的鲁棒性。CodeGPTSensor+集成了一个对抗样本生成模块——多目标标识符与结构转换（MIST），该模块系统地生成高质量且具有代表性的对抗样本，从而有效增强了模型的抗攻击能力。

**Result:** 在HMCorp数据集上的实验结果表明，CodeGPTSensor+在对抗测试集上显著提高了检测准确性，同时在原始测试集上保持了高准确性，与CodeGPTSensor相比展现出卓越的鲁棒性。

**Conclusion:** CodeGPTSensor+通过对抗训练有效解决了LLM生成代码经过细微修改后难以检测的问题，显著提升了检测的鲁棒性和准确性。

> **ai_Abstract:** 本文针对LLM生成代码在经过手动细微修改后，现有检测方法鲁棒性不足的问题，提出了一种名为CodeGPTSensor+的增强型检测模型。CodeGPTSensor+通过引入对抗训练和多目标标识符与结构转换（MIST）模块，能够系统地生成高质量对抗样本，从而显著提升模型对输入扰动的抵抗能力。实验证明，CodeGPTSensor+在对抗性测试集上表现出更高的检测准确性，同时在原始数据集上保持了良好性能，显示出比现有模型更优越的鲁棒性。

> **摘要翻译:** 随着大型语言模型（LLMs）的快速发展，其强大的代码生成能力已广泛应用于代码补全和自动化开发等任务，展现了提高编码效率的价值。然而，LLM生成代码的广泛使用也带来了一些新的挑战。一方面，代码溯源、版权纠纷和代码质量等问题日益受到关注。如何有效检测LLM生成代码并确保其合规和负责任的使用已成为一个关键而紧迫的问题。另一方面，在实际应用中，LLM生成代码通常会经历手动修改，例如变量重命名或结构调整。尽管最近的一些研究提出了基于训练和零样本的LLM生成代码检测方法，但这些方法在面对修改后的LLM生成代码时显示出鲁棒性不足，并且缺乏有效的解决方案。为了解决LLM生成代码可能经历细微修改的实际场景，我们提出了CodeGPTSensor+，它是CodeGPTSensor的增强版，采用对抗训练来提高对输入扰动的鲁棒性。CodeGPTSensor+集成了一个对抗样本生成模块——多目标标识符与结构转换（MIST），该模块系统地生成高质量且具有代表性的对抗样本。该模块有效地增强了模型抵抗各种对抗攻击的能力。在HMCorp数据集上的实验结果表明，CodeGPTSensor+在对抗测试集上显著提高了检测准确性，同时在原始测试集上保持了高准确性，与CodeGPTSensor相比展现出卓越的鲁棒性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [229] [Identification of Authoritative Nodes and Dismantling of Illicit Networks Using a Novel Metric for Measuring Strength of a Graph](https://arxiv.org/abs/2507.12711)
> *使用一种衡量图强度的新颖指标识别权威节点和瓦解非法网络*

*Kartikeya Kansal, Arunabha Sen* | **Category: cs.SI** | **Updated: 2025-07-17**

**Keywords:** 网络强度, 权威节点, 非法网络, 人类感知, 图论瓦解

**Comment:** 

> **TL;DR:** 本文提出了一种结合结构属性和人类感知的新型网络强度衡量指标，该指标在识别权威节点和瓦解非法网络方面优于传统方法。

**AI_Comments:** 该论文的创新之处在于引入了“人类感知”这一维度来衡量网络强度，突破了传统方法仅依赖结构属性的局限性。这对于实际应用，特别是在执法和流行病控制等领域，具有重要意义，因为人类的直觉和经验往往是理解复杂网络动态的关键。该方法通过结合定性和定量因素，提供了一个更全面、更符合现实需求的网络强度评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有网络强度衡量指标仅依赖于图的结构属性，但在现实世界中，尤其是在执法领域，代理人对网络强度的感知与结构评估可能存在显著差异，且传统指标通常忽略了这些感知。因此，需要一个更能反映真实世界情况的网络强度衡量方法。

**Method:** 提出了一种新的强度衡量指标，该指标整合了结构属性和人类感知。通过人类受试者调查，验证了该方法与现有指标的对比。

**Result:** 所提出的指标不仅与人类判断更紧密地对齐，而且在识别权威节点和有效瓦解合成及真实世界网络方面优于传统方法。

**Conclusion:** 结合结构属性和人类感知的新型网络强度衡量指标，在识别关键节点和瓦解网络方面比传统方法更有效，更符合人类判断。

> **ai_Abstract:** 本研究旨在解决网络强度衡量中忽略人类感知的问题。针对现有指标仅依赖结构属性的局限性，本文提出了一种结合结构属性和人类感知的新型网络强度衡量指标。通过人类受试者调查验证，该指标在识别权威节点和有效瓦解合成及真实世界网络方面表现出优于传统方法的性能，并与人类判断更为一致。

> **摘要翻译:** 通过移除节点来瓦解犯罪网络或遏制流行病或虚假信息是一个被充分研究的问题。为了评估这些努力的有效性，必须测量节点移除前后网络的强度。如果通过P1移除k个节点后残余网络的强度小于通过P2移除后的强度，则认为P1过程比P2更有效。这引出了核心问题：网络强度应该如何衡量？
现有指标仅依赖于图的结构属性，例如连通性。然而，在现实世界中，特别是在执法领域，代理人对网络强度的感知可能与结构评估存在显著差异。这些感知在传统指标中常常被忽略。
我们提出了一种新的强度指标，它整合了结构属性和人类感知。通过人类受试者调查，我们验证了我们的方法与现有指标的对比。我们的指标不仅与人类判断更紧密地对齐，而且在识别权威节点和有效瓦解合成和真实世界网络方面优于传统方法。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [271] [T3MAL: Test-Time Fast Adaptation for Robust Multi-Scale Information Diffusion Prediction](https://arxiv.org/abs/2507.12880)
> *T3MAL：用于鲁棒多尺度信息扩散预测的测试时快速适应*

*Wenting Zhu, Chaozhuo Li, Qingpo Yang, Xi Zhang, Philip S. Yu* | **Category: cs.SI** | **Updated: 2025-07-17**

**Keywords:** 信息扩散预测, 测试时训练, 分布偏移, 自监督学习, 元学习

**Comment:** 

> **TL;DR:** T3MAL是一个新的框架，通过测试时训练和自监督辅助任务，解决信息扩散预测中数据分布偏移的问题，实现快速鲁棒的适应。

**AI_Comments:** T3MAL的创新之处在于将测试时训练（TTT）范式引入信息扩散预测，有效应对了实际社交网络中常见的非独立同分布问题。通过结合BYOL启发的自监督学习和元辅助学习，该方法不仅实现了实例级的灵活适应，还解决了TTT中常见的权重初始化和灾难性遗忘问题，显著提升了模型在复杂动态环境下的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有信息扩散预测方法假设数据独立同分布，但在实际社交网络中用户行为的不确定性和可变性导致分布偏移，影响模型性能。

**Method:** 提出T3MAL框架，基于测试时训练（TTT）。通过一个自监督辅助任务，在预测前灵活适应每个测试实例的分布。T3MAL引入一个受BYOL启发的自监督辅助网络，与主扩散预测网络共享特征提取骨干，以指导实例特定的适应。通过结合元辅助学习方案和轻量级适配器，提供更好的TTT权重初始化并减轻灾难性遗忘，从而实现快速准确的测试时适应。

**Result:** 在三个公共数据集上的大量实验表明，T3MAL优于各种最先进的方法。

**Conclusion:** T3MAL通过引入测试时训练和自监督适应机制，有效解决了信息扩散预测中的分布偏移问题，显著提升了模型在实际复杂网络环境中的鲁棒性和预测性能。

> **ai_Abstract:** 本论文提出了T3MAL，一个针对信息扩散预测（IDP）任务中分布偏移问题的鲁棒测试时训练（TTT）框架。T3MAL通过引入一个BYOL启发的自监督辅助网络，在测试阶段对每个实例进行灵活适应，同时利用元辅助学习和轻量级适配器实现快速准确的适应并缓解灾难性遗忘。实验证明T3MAL优于现有SOTA方法。

> **摘要翻译:** 信息扩散预测（IDP）是理解信息如何在用户之间传播的关键任务。大多数现有方法普遍遵循传统的训练-测试范式，即模型在训练数据上预训练，然后直接应用于测试样本。然而，这种范式的成功取决于数据独立同分布的假设，这在实际社交网络中由于用户行为固有的不确定性和可变性而常常失效。在本文中，我们解决了IDP任务中分布偏移这一新颖挑战，并提出了一个基于鲁棒测试时训练（TTT）的多尺度扩散预测框架，命名为T3MAL。其核心思想是通过一个自监督辅助任务，在进行预测之前灵活地使训练好的模型适应每个测试实例的分布。具体来说，T3MAL引入了一个受BYOL启发的自监督辅助网络，该网络与主要扩散预测网络共享共同的特征提取骨干，以在测试期间指导实例特定的适应。此外，T3MAL通过结合一种新颖的元辅助学习方案和一个轻量级适配器，实现了快速准确的测试时适应，它们共同为TTT提供更好的权重初始化并减轻灾难性遗忘。在三个公共数据集上的大量实验表明，T3MAL优于各种最先进的方法。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [313] [The Centrality Paradox: Why Your Friends Are Always More Important](https://arxiv.org/abs/2507.13059)
> *中心性悖论：为什么你的朋友总是更重要*

*Rajat Subhra Hazra, Evgeny Verbitskiy* | **Category: cs.SI, math.PR** | **Updated: 2025-07-17**

**Keywords:** 友谊悖论, 中心性度量, 网络分析, Perron特征值, 图论

**Comment:** 11 pages

> **TL;DR:** 本文重新审视并推广了经典的友谊悖论，指出在无向图中，朋友的平均中心性（包括度、特征向量、游走计数、Katz和PageRank）总是高于全局平均值，这一结果可由Perron特征值的特征向量变分表征来解释。

**AI_Comments:** 该论文显著地推广了著名的友谊悖论，将其从单纯的度量扩展到更广泛的中心性度量。利用Perron特征值变分表征提供了严格的数学基础，揭示了网络结构的基本属性。其创新之处在于将这些观察结果统一在一个数学原理之下。

<details>
  <summary>Details</summary>

**Motivation:** 重新审视经典的友谊悖论，并将其推广到各种网络中心性度量。

**Method:** 作者证明对于任何不可约的无向图G，度、特征向量中心性、游走计数、Katz和PageRank中心性的“朋友平均值”超过了全局平均值。这一结果源于Perron特征值对应特征向量的变分表征。

**Result:** 在不可约的无向图中，朋友的平均度、特征向量中心性、游走计数、Katz和PageRank中心性均高于网络整体的平均值。

**Conclusion:** 中心性悖论适用于多种中心性度量，其数学基础在于Perron特征值对应特征向量的变分表征。

> **ai_Abstract:** 本文推广了经典的友谊悖论，指出在不可约的无向图中，一个人的朋友在度、特征向量中心性、游走计数、Katz和PageRank等多种网络中心性度量上的平均值，总是高于网络的全局平均值。这一“中心性悖论”的数学解释源于Perron特征值对应特征向量的变分表征。

> **摘要翻译:** 我们重新审视了经典的友谊悖论，该悖论指出平均而言，一个人的朋友拥有的朋友数量至少与自己一样多，并将其推广到各种网络中心性度量。具体而言，我们证明对于任何不可约的无向图G，度、特征向量中心性、游走计数、Katz和PageRank中心性的“朋友平均值”超过了全局平均值。我们证明该结果源于对应于Perron特征值的特征向量的变分表征。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [529] [DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter](https://arxiv.org/abs/2501.09035)
> *DomainDemo：一个关于Twitter上不同人口群体间域名分享活动的数据集*

*Kai-Cheng Yang, Pranav Goel, Alexi Quintana-Mathé, Luke Horgan, Stefan D. McCabe, Nir Grinberg, Kenneth Joseph, David Lazer* | **Category: cs.SI, cs.CY** | **Updated: 2025-07-16**

**Keywords:** DomainDemo, 数据集, Twitter, 人口统计学, 信息共享

**Comment:** 24 pages, 3 figures

> **TL;DR:** DomainDemo是一个新数据集，连接Twitter上的域名分享与用户人口统计学特征，以理解信息流和政治言论趋势。

**AI_Comments:** DomainDemo数据集的创新之处在于它首次将Twitter上的域名共享活动与详细的用户人口统计学特征（包括投票记录）进行了大规模关联。这对于理解信息传播、政治极化以及不同群体如何消费和分享在线内容具有重要意义。其方法的可靠性通过与现有分类的一致性得到了验证，为未来的社会科学研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 尽管社交媒体在信息传播中扮演关键角色，但我们对人口因素与在线信息分享之间关联的理解仍然有限。

**Method:** 本文介绍了DomainDemo数据集，该数据集将Twitter（X）上分享的域名与相关用户的年龄、性别、种族、政治派别和地理位置等人口统计学特征联系起来。此资源来源于超过150万Twitter用户与美国选民登记记录的匹配。通过将用户人口统计信息聚合到域名上，研究者得出了五个指标，其中“本地性”和“党派受众”指标分别量化了域名的地理覆盖范围和意识形态倾向。

**Result:** 这些指标与现有分类显示出高度一致性，表明DomainDemo方法是有效和可靠的。

**Conclusion:** DomainDemo数据集有助于更好地理解过去十年中主要社交媒体平台上的信息流以及不同社会人口群体中美国注册选民的政治和公共话语趋势。

> **ai_Abstract:** 本文介绍了DomainDemo数据集，它将Twitter上分享的域名与用户的年龄、性别、种族、政治派别和地理位置等人口统计学特征关联起来。该数据集基于150多万Twitter用户与美国选民登记记录的匹配，旨在弥补对人口因素与在线信息共享之间关联理解的不足。研究者通过聚合用户人口信息到域名上，导出了五个指标，包括量化域名地理范围和意识形态倾向的“本地性”和“党派受众”指标。这些指标与现有分类的高度一致性证明了DomainDemo方法的有效性和可靠性，为理解社交媒体上的信息流和政治话语趋势提供了新资源。

> **摘要翻译:** 社交媒体在网络内容传播中发挥着举足轻重的作用，尤其是在选举期间，但我们对人口因素与在线信息共享之间关联的理解仍然有限。在此，我们引入了一个独特的数据集DomainDemo，它将Twitter（X）上分享的域名与相关用户的人口统计学特征（包括年龄、性别、种族、政治派别和地理位置）从2011年到2022年进行了关联。这个新资源来源于一个由超过150万Twitter用户组成的面板，这些用户与他们的美国选民登记记录进行了匹配，从而有助于更好地理解过去十年中在最著名的社交媒体平台之一上的信息流，以及不同社会人口群体中美国注册选民的政治和公共话语趋势。通过将用户人口统计信息聚合到域名上，我们得出了五个指标，这些指标为超过129,000个网站提供了关键见解。特别是，“本地性”和“党派受众”指标分别量化了域名的地理覆盖范围和意识形态倾向。这些指标与现有分类显示出高度一致性，表明DomainDemo方法是有效和可靠的。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [574] [Hypergraph Link Prediction via Hyperedge Copying](https://arxiv.org/abs/2502.02386)
> *超图链接预测通过超边复制*

*Xie He, Philip S. Chodrow, Peter J. Mucha* | **Category: cs.SI, nlin.AO, physics.data-an, physics.soc-ph** | **Updated: 2025-07-17**

**Keywords:** 超图链接预测, 生成模型, 超边复制, 时间演化超图, 随机期望最大化

**Comment:** 

> **TL;DR:** 提出了一种基于超边复制的生成模型，用于时间演化超图，并在链接预测任务中表现出色，参数少但性能与大型神经网络相当。

**AI_Comments:** 这项工作提出了一种新颖的超图生成机制（超边复制），不仅能捕捉经验超图的特征，而且在链接预测任务中展现出卓越的参数效率，与大型神经网络相媲美，这表明其在实际应用中具有很大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提出一个能重现经验事实、可学习、定义完整超图似然，且可扩展的超图生成模型，以解决现有模型可能无法捕捉所有经验超图特征或缺乏可扩展性的问题。

**Method:** 提出了一种时间演化超图的生成模型，其中超边通过对先前超边的噪声复制形成。开发了一个可扩展的随机期望最大化算法来拟合模型。在超图链接预测任务上评估了模型。

**Result:** 模型重现了许多经验超图的程式化事实；模型可从数据中学习并定义完整超图的似然；模型参数可以描述节点度、边大小和边交集大小分布；识别了模型成功和未能捕捉的经验超图特征；开发了可扩展的随机期望最大化算法，可处理数百万节点和边的超图数据集；仅有11个参数的模型实例在超图链接预测任务中实现了与大型神经网络相当的预测性能。

**Conclusion:** 提出的基于超边复制的生成模型在超图链接预测任务中表现出强大的竞争力，且参数效率高，仅用少量参数即可达到与大型神经网络相当的性能。

> **ai_Abstract:** 本文提出了一种基于超边噪声复制的生成模型，用于时间演化超图的链接预测。该模型能够重现经验超图的多个特征，可从数据中学习，并能在大规模数据集上进行拟合。实验结果表明，该模型在参数数量极少的情况下，在超图链接预测任务上取得了与复杂神经网络相当的性能。

> **摘要翻译:** 我们提出了一种时间演化超图的生成模型，其中超边通过对先前超边的噪声复制形成。我们提出的模型重现了许多经验超图的几个程式化事实，可从数据中学习，并定义了完整超图的似然，而非基于自我中心或其他子超图的似然。通过分析我们的模型，我们根据模型参数推导了节点度、边大小和边交集大小分布的描述。我们还展示了我们的模型成功和未能捕捉的经验超图的几个特征。我们提供了一个可扩展的随机期望最大化算法，可以用它将我们的模型拟合到包含数百万节点和边的超图数据集。最后，我们在超图链接预测任务上评估了我们的模型，发现我们的模型的一个仅有11个参数的实例可以与大型神经网络达到有竞争力的预测性能。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [319] [Energy-Efficient RSMA-enabled Low-altitude MEC Optimization Via Generative AI-enhanced Deep Reinforcement Learning](https://arxiv.org/abs/2507.12910)
> *基于生成式AI增强深度强化学习的低空MEC中RSMA能效优化*

*Xudong Wang, Hongyang Du, Lei Feng, Kaibin Huang* | **Category: cs.NI** | **Updated: 2025-07-17**

**Keywords:** RSMA, MEC, 深度强化学习, 生成式AI, 能效优化

**Comment:** 13 pages, 10 figures

> **TL;DR:** 本文提出了一种基于生成式AI增强深度强化学习的框架，用于优化RSMA使能的低空MEC系统的能效，以解决6G中低延迟计算需求和上行链路干扰问题。

**AI_Comments:** 本文的创新点在于将生成式AI（特别是扩散模型）引入深度强化学习框架，以优化低空MEC系统中的RSMA能效。这种结合有效解决了高维、非凸优化问题中的探索效率和局部最优问题，并通过优先级RSMA解码策略进一步提升了性能。该研究为6G背景下的高效边缘计算和干扰管理提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 6G中对低延迟计算的需求不断增长，推动了基于无人机的低空移动边缘计算（MEC）系统的发展。然而，有限的频谱常常导致地面终端（GTs）之间严重的上行链路干扰。

**Method:** 本文研究了一个RSMA（速率分裂多址）使能的低空MEC系统，并建立了一个联合优化问题，包括无人机3D轨迹、RSMA解码顺序、任务卸载决策和资源分配，旨在减轻多用户干扰并最大化能效。针对该优化问题的高维度、非凸性和动态特性，提出了一种生成式AI增强的深度强化学习（DRL）框架来高效求解。具体来说，将扩散模型嵌入到Actor网络中以生成高质量的动作样本，从而改善混合动作空间的探索并避免局部最优。此外，设计了一种基于优先级的RSMA解码策略，以低复杂度实现高效的连续干扰消除。

**Result:** 仿真结果表明，所提出的低空MEC系统方法优于基线方法，并且将GDM（生成式扩散模型）与RSMA集成可以显著提高能效性能。

**Conclusion:** 将生成式AI（尤其是扩散模型）与深度强化学习相结合，并辅以优先级RSMA解码策略，可以有效优化低空MEC系统的能效，显著优于现有基线方法。

> **ai_Abstract:** 本文针对6G中无人机低空MEC系统面临的低延迟计算需求和上行链路干扰问题，提出了一种基于生成式AI增强的深度强化学习（DRL）框架。该框架通过联合优化无人机轨迹、RSMA解码顺序、任务卸载和资源分配，旨在最大化系统能效并减轻多用户干扰。为解决高维度、非凸和动态优化难题，研究将扩散模型嵌入DRL的Actor网络以提升探索效率并避免局部最优，同时设计了低复杂度的优先级RSMA解码策略。仿真结果表明，该方法显著优于基线方法，并能大幅提高能效性能。

> **摘要翻译:** 6G中对低延迟计算不断增长的需求正在推动基于无人机的低空移动边缘计算（MEC）系统的使用。然而，有限的频谱常常导致地面终端（GTs）之间严重的上行链路干扰。在本文中，我们研究了一个RSMA（速率分裂多址）使能的低空MEC系统，其中一个基于无人机的边缘服务器协助多个GTs在共享上行链路上同时卸载其任务。我们建立了一个联合优化问题，包括无人机3D轨迹、RSMA解码顺序、任务卸载决策和资源分配，旨在减轻多用户干扰并最大化能效。鉴于该优化问题的高维度、非凸性和动态特性，我们提出了一种生成式AI增强的深度强化学习（DRL）框架来高效求解。具体来说，我们将扩散模型嵌入到Actor网络中以生成高质量的动作样本，从而改善混合动作空间的探索并避免局部最优。此外，设计了一种基于优先级的RSMA解码策略，以低复杂度实现高效的连续干扰消除。仿真结果表明，所提出的低空MEC系统方法优于基线方法，并且将GDM与RSMA集成可以显著提高能效性能。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [367] [RIDAS: A Multi-Agent Framework for AI-RAN with Representation- and Intention-Driven Agents](https://arxiv.org/abs/2507.13140)
> *RIDAS：一种基于表示和意图驱动代理的AI-RAN多智能体框架*

*Kuiyuan Ding, Caili Guo, Yang Yang, Jianzhang Guo* | **Category: cs.NI** | **Updated: 2025-07-17**

**Keywords:** AI-RAN, 多智能体系统, 6G网络, 大型语言模型, 资源分配

**Comment:** 6 pages, 7 figures

> **TL;DR:** RIDAS是一个多智能体框架，利用表示驱动代理和意图驱动代理，通过LLM将用户意图映射到AI-RAN配置，从而提高资源效率和用户支持数量。

**AI_Comments:** RIDAS的创新点在于结合了表示驱动代理和意图驱动代理，并通过大型语言模型驱动的规划来解决AI-RAN中用户意图到网络配置的映射难题，显著提升了资源效率和用户支持能力，为6G网络发展提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 第六代（6G）网络要求将人工智能（AI）紧密集成到无线接入网络（RAN）中，以满足严格的服务质量（QoS）和资源效率要求。现有解决方案难以弥合高级用户意图与实现最佳性能所需的低级参数化配置之间的鸿沟。

**Method:** 提出RIDAS多智能体框架，包含表示驱动代理（RDAs）和意图驱动代理（IDA）。RDAs提供可调控制参数（秩和量化比特），实现失真和传输速率之间的权衡。IDA采用由大型语言模型（LLM）驱动的两阶段规划方案（带宽预分配和再分配），将用户意图和系统状态映射到最优的RDA配置。

**Result:** 在同等QoS约束下，RIDAS比WirelessAgent支持的用户多44.71%。

**Conclusion:** RIDAS能够捕捉用户意图并在AI-RAN环境中更有效地分配资源。

> **ai_Abstract:** 本文提出了RIDAS，一个用于AI-RAN的多智能体框架，旨在弥合用户意图与网络配置之间的差距。RIDAS包含表示驱动代理（RDAs）用于参数调优，以及一个意图驱动代理（IDA）利用大型语言模型（LLM）进行两阶段规划，将用户意图转化为最优的RDA配置。实验证明，RIDAS能显著提高用户支持数量和资源分配效率。

> **摘要翻译:** 第六代（6G）网络要求将人工智能（AI）紧密集成到无线接入网络（RAN）中，以满足严格的服务质量（QoS）和资源效率要求。现有解决方案难以弥合高级用户意图与实现最佳性能所需的低级参数化配置之间的鸿沟。为了解决这一挑战，我们提出了RIDAS，一个由表示驱动代理（RDAs）和意图驱动代理（IDA）组成的多智能体框架。RDAs提供开放接口和可调控制参数（秩和量化比特），从而实现失真和传输速率之间的明确权衡。IDA采用由大型语言模型（LLM）驱动的两阶段规划方案（带宽预分配和再分配），将用户意图和系统状态映射到最优的RDA配置。实验表明，在同等QoS约束下，RIDAS比WirelessAgent支持的用户多44.71%。这些结果验证了RIDAS在AI-RAN环境中捕获用户意图并更有效地分配资源的能力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [409] [Predictability-Aware Motion Prediction for Edge XR via High-Order Error-State Kalman Filtering](https://arxiv.org/abs/2507.13179)
> *基于高阶误差状态卡尔曼滤波的边缘XR可预测性感知运动预测*

*Ziyu Zhong, Hector A Caltenco, Björn Landfeldt, Günter Alce* | **Category: cs.NI, cs.MM** | **Updated: 2025-07-17**

**Keywords:** 6G, XR, 边缘计算, 应用卸载, 运动预测

**Comment:** 

> **TL;DR:** 6G网络结合边缘计算将使XR应用卸载成为可能，从而降低用户设备功耗并实现更小尺寸的设备设计。

**AI_Comments:** 该摘要主要介绍了6G和边缘计算在推动XR应用卸载方面的巨大潜力及其带来的益处，如降低设备功耗和实现更小尺寸的设计。然而，摘要并未深入阐述标题中提及的具体技术细节，如“高阶误差状态卡尔曼滤波”如何实现“可预测性感知运动预测”。它更像是一个引言，为后续的详细技术讨论奠定了背景。

<details>
  <summary>Details</summary>

**Motivation:** 随着6G网络的开发和定义，XR应用的卸载正成为一个重要的新用例。通过将计算密集型功能（包括渲染）从用户设备迁移到网络，可以降低用户设备的电池需求并实现更小尺寸的新设备设计。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文探讨了6G网络与边缘计算相结合，为XR应用卸载提供了现实场景的可能性。通过将计算密集型任务从用户设备转移到网络，有望显著降低设备能耗并实现更紧凑的设备设计。

> **摘要翻译:** 随着6G网络的开发和定义，XR应用的卸载正成为一个重要的新用例。6G降低的延迟与边缘处理基础设施相结合，将首次在蜂窝网络中提供一个真实的卸载场景，其中包括渲染在内的多个计算密集型功能可以从用户设备迁移到网络。这样做的一个关键优势是降低了用户设备的电池需求，并有可能设计出尺寸更小的新设备。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [449] [Bidirectional Age of Incorrect Information: A Performance Metric for Status Updates in Virtual Dynamic Environments](https://arxiv.org/abs/2507.13312)
> *双向错误信息年龄：虚拟动态环境中状态更新的性能指标*

*Chiara Schiavo, Manuele Favero, Alessandro Buratto, Leonardo Badia* | **Category: cs.NI, cs.IT, cs.MM, math.IT** | **Updated: 2025-07-17**

**Keywords:** 双向错误信息年龄, 虚拟动态环境, 性能指标, 状态更新, 马尔可夫链

**Comment:** 8 pages, 8 figures, 1 table, Proc. IEEE Metacom

> **TL;DR:** 提出双向错误信息年龄（BAoII）作为虚拟动态环境中信息新鲜度和准确性的性能指标，并建立了其模型和优化策略。

**AI_Comments:** 本文提出的BAoII概念创新性地将信息新鲜度指标扩展到双向信息流，更准确地反映了虚拟动态环境中实体间相互感知的重要性。其基于马尔可夫链的模型推导和对通信成本与信息新鲜度权衡的分析，为优化元宇宙和数字孪生等应用中的状态更新策略提供了理论基础和实用工具，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟动态环境（如元宇宙和数字孪生）需要准确且最新的实体表示以实现无缝交互和系统可靠性，但现有方法可能不足以衡量双向信息交换中的不准确性。

**Method:** 提出双向错误信息年龄（BAoII），量化实体因自身和动态空间信息不准确或过时而付出的时间相关代价。使用连续时间马尔可夫链模型推导出长期BAoII的闭合表达式，并识别了最优更新策略的传输成本阈值。

**Result:** 导出了长期BAoII的闭合表达式，确定了最优更新策略的传输成本阈值。数值模拟验证了模型，并展示了BAoII在评估系统性能和实时协作中的重要性。

**Conclusion:** BAoII是评估虚拟动态环境中信息新鲜度和系统性能的重要指标，可用于优化通信成本和信息新鲜度之间的权衡，对元宇宙和数字孪生等实时协作应用具有重要意义。

> **ai_Abstract:** 本文提出了双向错误信息年龄（BAoII）作为衡量虚拟动态环境（VDEs，如元宇宙和数字孪生）中信息准确性和新鲜度的性能指标。BAoII量化了实体因自身和环境信息不准确所付出的代价，并考虑了双向信息交换的需要。研究通过连续时间马尔可夫链模型推导了长期BAoII的闭合表达式，并确定了最优更新策略的传输成本阈值，揭示了通信成本与信息新鲜度之间的权衡。数值模拟验证了BAoII在评估系统性能和促进实时协作中的有效性。

> **摘要翻译:** 虚拟动态环境（VDE），例如元宇宙和数字孪生（DT），需要对交互实体进行适当的表示，以在其模拟或增强空间中映射其特征。保持这些表示的准确性和最新性对于无缝交互和系统可靠性至关重要。在本文中，我们提出了双向错误信息年龄（BAoII）来解决这一方面。BAoII量化了VDE中实体因自身和整体动态变化空间的不正确或过时知识而付出的时间相关代价。这扩展了错误信息年龄的概念，用于双向信息交换，捕获了VDE需要实体自身表示（在虚拟空间中测量）和所有其他实体共享其表示的相互意识。使用连续时间马尔可夫链模型，我们推导了长期BAoII的闭合表达式，并确定了最优更新策略的传输成本阈值。我们描述了通信成本和信息新鲜度之间的权衡，并通过数值模拟验证了我们的模型，展示了BAoII在评估系统性能方面的影响，并强调了其在元宇宙和DTs中实时协作的相关性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [534] [XR Offloading Across Multiple Time Scales: The Roles of Power, Temperature, and Energy](https://arxiv.org/abs/2506.18584)
> *跨多时间尺度的XR卸载：功率、温度和能量的作用*

*Francesco Malandrino, Olga Chukhno, Alessandro Catania, Antonella Molinaro, Carla Fabiana Chiasserini* | **Category: cs.NI** | **Updated: 2025-07-17**

**Keywords:** XR卸载, 时间尺度, 功率, 温度, 能量, TAO

**Comment:** 

> **TL;DR:** 本文提出了一种名为TAO的随机稳态卸载策略，用于XR设备，该策略考虑了瞬时功率、短期温度和长期电池续航，能在不违反操作限制的情况下将卸载成本降低35%以上。

**AI_Comments:** 本文的创新之处在于其首次将XR设备的卸载问题与多个时间尺度（功率、温度、能量）相结合进行考虑，并提出了一个全面的系统模型和相应的优化策略TAO。这对于提升可穿戴设备的性能和用户体验具有重要意义。其关注的温度和能量约束是实际设备部署中非常关键的限制，使研究更具实用价值。

<details>
  <summary>Details</summary>

**Motivation:** XR（扩展现实）设备（可穿戴设备）需要处理巨大的计算负载并满足严格的延迟要求。为了满足这些需求，设备依赖于设备内处理和边缘卸载的结合。本文的动机是研究可穿戴设备的卸载策略，并考虑其对瞬时功耗、短期温度波动和长期电池续航的影响。

**Method:** 本文引入了一个全面的系统模型，捕捉了瞬时功率消耗、短期温度波动和长期电池续航这三种时间尺度上的动态。在此基础上，提出了一种名为TAO（温度感知卸载）的随机稳态卸载策略，旨在最小化卸载成本，同时遵守功率、热和能量限制。性能评估利用了真实世界可穿戴设备的COMSOL模型。

**Result:** 性能评估证实，与最先进的方法相比，TAO在不违反可穿戴设备操作限制的情况下，将卸载成本降低了35%以上。

**Conclusion:** TAO策略能够有效降低XR设备的卸载成本，同时满足功率、热和能量约束，并显著优于现有方法。

> **ai_Abstract:** 本文针对XR可穿戴设备在处理高计算负载和低延迟要求下的卸载问题，提出了一种名为TAO（温度感知卸载）的随机稳态策略。该策略综合考虑了瞬时功率、短期温度和长期电池能量消耗，旨在最小化卸载成本，同时遵守设备的操作限制。通过COMSOL模型验证，TAO比现有方法能将卸载成本降低超过35%。

> **摘要翻译:** 扩展现实（XR）设备，通常被称为可穿戴设备，必须在严格的延迟限制下处理大量的计算负载。为了满足这些需求，它们依赖于设备内处理和边缘卸载的结合。本文重点关注可穿戴设备的卸载策略，并考虑其在三个时间尺度上的影响：瞬时功耗、短期温度波动和长期电池续航。我们引入了一个全面的系统模型，捕捉了这些时间动态，并提出了一种随机稳态卸载策略，称为TAO（温度感知卸载），旨在最小化卸载成本，同时遵守功率、热和能量约束。我们的性能评估，利用真实世界可穿戴设备的COMSOL模型，证实TAO与最先进的方法相比，在不违反可穿戴设备操作限制的情况下，将卸载成本降低了35%以上。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [128] [ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic Communications](https://arxiv.org/abs/2505.10946)
> *ToDMA：大模型驱动的令牌域多址接入用于语义通信*

*Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Robert Schober, Deniz Gündüz* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-17**

**Keywords:** 令牌通信, 语义通信, 多址接入, 大语言模型, 压缩感知

**Comment:** Submitted to IEEE journals

> **TL;DR:** 本文提出了一种名为ToDMA的令牌域多址接入方案，利用大模型处理令牌进行语义通信，通过压缩感知检测和MLLM预测来缓解令牌冲突，显著降低了文本和图像传输的延迟并提升了质量。

**AI_Comments:** ToDMA的创新之处在于将令牌域多址接入与大模型（MLLM）相结合，利用MLLM的上下文理解能力来解决令牌冲突这一核心挑战，这是传统通信方案难以实现的能力。其重要性在于为未来大规模设备接入的语义通信提供了一种高效且智能的解决方案，有望在降低传输速率的同时提升通信质量和鲁斯性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的令牌通信（TokCom）通过基于上下文和多模态大语言模型（MLLM）的令牌处理来降低传输速率。本文旨在提出一种令牌域的多址接入方案，以解决大量设备共享资源时的语义通信问题，并有效处理令牌冲突。

**Method:** ToDMA方案中，设备共享令牌码本和调制码本。发送端将源信号令牌化并调制成码字。接收端首先使用压缩感知检测活跃令牌和信道状态信息（CSI）。然后，通过对多时隙的令牌相关CSI进行聚类来重建源令牌序列。为缓解令牌冲突，当出现空缺时，利用预训练的MLLM预测被遮蔽的令牌，从而恢复信息。

**Result:** 仿真结果表明，所提出的ToDMA框架在文本和图像传输任务中均有效。与上下文无关的正交通信方案相比，ToDMA显著降低了延迟；与最先进的上下文无关非正交通信方法相比，ToDMA提供了更优越的失真和感知质量。

**Conclusion:** ToDMA是一种有效的大模型驱动的令牌域多址接入方案，它通过利用上下文信息和MLLM，显著提升了语义通信的效率和质量，尤其在处理令牌冲突方面表现出色。

> **ai_Abstract:** 本文提出了一种大模型驱动的令牌域多址接入（ToDMA）方案，用于语义通信。该方案利用共享的令牌码本和调制码本，通过压缩感知在接收端检测活跃令牌和信道状态信息，并聚类重建令牌序列。针对令牌冲突，ToDMA创新性地利用预训练的多模态大语言模型（MLLM）来预测被遮蔽的令牌，从而缓解冲突。仿真结果验证了ToDMA在文本和图像传输中相对于现有方法的优越性，包括更低的延迟和更高的传输质量。

> **摘要翻译:** 令牌通信（TokCom）是一种新兴的生成式语义通信概念，它通过使用上下文和基于多模态大语言模型（MLLM）的令牌处理来降低传输速率，其中令牌作为跨模态的通用语义单元。在本文中，我们提出了一种令牌域的语义多址接入方案，称为令牌域多址接入（ToDMA），其中大量设备共享一个令牌码本和一个调制码本，分别用于源编码和信道编码。具体来说，每个发送器首先将其源信号令牌化，并将每个令牌调制成一个码字。在接收器端，首先采用压缩感知来从叠加信号中检测活跃令牌和相应的信道状态信息（CSI）。然后，通过对多个时隙中与令牌相关的CSI进行聚类来重建源令牌序列。在令牌冲突的情况下，一些活跃令牌无法被分配，并且重建令牌序列中的某些位置是空的。我们建议使用预训练的MLLM来利用上下文，预测被遮蔽的令牌，从而缓解令牌冲突。仿真结果表明，所提出的ToDMA框架在文本和图像传输任务中均有效，与上下文无关的正交通信方案相比，实现了显著更低的延迟，同时与最先进的上下文无关非正交通信方法相比，提供了更优越的失真和感知质量。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [133] [Extremely Large Full Duplex MIMO for Simultaneous Downlink Communications and Monostatic Sensing at Sub-THz Frequencies](https://arxiv.org/abs/2502.10693)
> *用于亚太赫兹频率下同步下行链路通信和单站感知的超大型全双工MIMO*

*George C. Alexandropoulos, Ioannis Gavras* | **Category: cs.IT, cs.ET, math.IT** | **Updated: 2025-07-17**

**Keywords:** 全双工, MIMO, ISAC, 亚太赫兹, 波束成形

**Comment:** 13 pages, 8 figures, submitted to an IEEE journal

> **TL;DR:** 本文提出了一种用于亚太赫兹频率下同步下行链路通信和单站感知的超大型全双工MIMO系统，并设计了联合优化框架，在最大化下行链路速率的同时满足感知精度要求，其性能优于现有技术。

**AI_Comments:** 该论文的创新点在于提出了用于亚太赫兹频率下超大型全双工MIMO系统的联合优化框架，以同时实现通信和单站感知。其重要性体现在推动ISAC范式在下一代无线网络中的应用，特别是在高频段。论文考虑了两种不同的模拟波束成形架构，增加了研究的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 全双工（FD）技术作为集成感知与通信（ISAC）范式的一种使能技术，正受到关注，ISAC旨在将未连接实体的感知机制无缝集成到下一代无线网络中。本文旨在优化超大型全双工MIMO系统以实现同步通信和感知。

**Method:** 本文提出了一种具有超大型天线阵列的全双工多输入多输出（MIMO）系统，针对两种新兴的模拟波束成形架构进行优化，以实现亚太赫兹频率下的同步下行链路（DL）通信和单站式感知。设计了一个新颖的优化框架，用于联合设计模拟和数字发射波束成形、模拟接收组合以及自干扰信号的数字消除器，目标是最大化可实现的DL速率，同时满足无源目标未知三维参数的位置误差界限的预定义阈值。利用全连接移相器网络和部分连接超材料阵列的波束成形架构的独特特性，提出了两种ISAC设计。

**Result:** 仿真结果表明，本文提出的两种设计方案均优于现有技术方案，并突出了各种系统参数在通信和感知功能之间权衡中的作用。

**Conclusion:** 本文成功开发并验证了用于亚太赫兹频率下同步通信和感知的超大型全双工MIMO系统和相应的联合优化框架，证明了其优越性，并揭示了系统参数对通信和感知权衡的影响。

> **ai_Abstract:** 本文提出了一种在亚太赫兹频率下实现同步下行链路通信和单站感知的超大型全双工MIMO系统。该系统针对两种模拟波束成形架构进行了优化，并开发了一个新颖的联合优化框架，旨在最大化下行链路速率，同时满足预设的感知精度。研究利用了全连接移相器网络和部分连接超材料阵列的特性，提出了两种ISAC设计。仿真结果表明，所提出的设计优于现有技术，并揭示了系统参数对通信和感知功能之间权衡的影响。

> **摘要翻译:** 带内全双工（FD）技术作为新兴的集成感知与通信（ISAC）范式的一种使能技术，正日益受到关注，ISAC旨在将未连接实体的感知机制无缝集成到下一代无线网络中。在本文中，我们提出了一种全双工多输入多输出（MIMO）系统，其收发信机模块具有超大型天线阵列，该系统针对两种新兴的模拟波束成形架构进行了优化，以实现亚太赫兹频率下的同步下行链路（DL）通信和单站式感知，其中后者的操作依赖于发射信息承载信号的接收反射。我们设计了一个新颖的优化框架，用于联合设计模拟和数字发射波束成形、模拟接收组合以及自干扰信号的数字消除器，目标是最大化可实现的DL速率，同时满足无源目标未知三维参数的位置误差界限的预定义阈值。利用全连接移相器网络和部分连接超材料阵列的波束成形架构的独特特性，本文提出了两种ISAC设计。我们的仿真结果表明，本文提出的两种设计方案均优于现有技术方案，并突出了各种系统参数在通信和感知功能之间权衡中的作用。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [489] [Learning-Based Interface for Semantic Communication with Bit Importance Awareness](https://arxiv.org/abs/2507.12850)
> *基于学习的语义通信接口，具有比特重要性感知功能*

*Wenzheng Kong, Wenyi Zhang* | **Category: cs.IT, cs.NI, math.IT** | **Updated: 2025-07-17**

**Keywords:** 语义通信, 联合信源信道编码, 基于学习的接口, 比特重要性, 无线图像传输

**Comment:** 

> **TL;DR:** 本文提出一种基于学习的语义通信接口，该接口具有比特重要性感知功能，可提高性能并兼容现有网络。

**AI_Comments:** 该论文的创新之处在于将接口参数设计为可训练，并引入了比特级重要性感知，这使得端到端性能得到提升，并能更好地动态适应信道条件。这种方法有效解决了语义通信在当前网络架构中集成面临的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 当前联合信源信道编码（JSCC）方法难以与现有通信网络架构集成，而分离式深度JSCC（Split DeepJSCC）虽有所改进，但仍有提升空间。

**Method:** 提出一种基于学习的接口设计，其参数可训练，并能指定信源编码输出的比特级重要性。此外，还提出了一个“重要性感知网络”（Importance-Aware Net），利用接口派生的比特重要性信息，实现对不同信道条件和时变信道条件的动态适应。

**Result:** 实验结果表明，该方法在无线图像传输任务中提高了性能。

**Conclusion:** 这项工作为在现有无线网络中实现语义通信提供了一个潜在的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的基于学习的语义通信接口，该接口基于分离式深度JSCC范式。通过将接口参数视为可训练的，并引入比特重要性感知功能，所提出的方法提升了端到端性能。它还包含一个“重要性感知网络”，用于动态适应变化的信道条件。实验证实了其在无线图像传输中性能的提升，为在现有无线网络中实现语义通信提供了一个实用解决方案。

> **摘要翻译:** 联合信源信道编码（JSCC）是实现语义通信的有效方法。然而，当前的JSCC方法难以与现有通信网络架构集成，在这些架构中，应用提供商和网络提供商通常是不同的实体。最近，为了解决这一挑战，一种名为“分离式深度JSCC”（Split DeepJSCC）的新范式正在被考虑。分离式深度JSCC采用比特级接口，实现信源和信道代码的独立设计，在保持JSCC在语义保真度和信道适应性方面优势的同时，确保了与现有通信网络的兼容性。在本文中，我们提出了一种基于学习的接口设计，将其参数视为可训练的，与分离式深度JSCC相比，实现了端到端性能的提升。特别是，该接口能够指定信源编码输出的比特级重要性。此外，我们提出了一种“重要性感知网络”（Importance-Aware Net），它利用接口派生的比特重要性信息，实现对各种信道带宽比和时变信道条件的动态适应。实验结果表明，我们的方法在无线图像传输任务中提高了性能。这项工作为在现有无线网络中实现语义通信提供了潜在解决方案。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [494] [Robust Resource Allocation for Pinching-Antenna Systems under Imperfect CSI](https://arxiv.org/abs/2507.12582)
> *不完美CSI下挤压天线系统的鲁棒资源分配*

*Ming Zeng, Xianbin Wang, Yuanwei Liu, Zhiguo Ding, George K. Karagiannidis, H. Vincent Poor* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-16**

**Keywords:** 挤压天线, 鲁棒资源分配, 位置不确定性, 粒子群优化, 高频通信

**Comment:** submitted to IEEE journals; 5 pages;

> **TL;DR:** 本文研究了在用户位置不确定性下，挤压天线系统的鲁棒资源分配问题，旨在最小化总发射功率并满足中断概率约束，并通过仿真验证了所提方案优于传统固定天线系统。

**AI_Comments:** 本文创新性地将鲁棒优化方法应用于挤压天线系统，有效解决了实际高频通信中用户位置不确定性带来的挑战。通过引入PSO算法处理多用户场景下的复杂非凸问题，展示了其在实际部署中的潜力。该研究对于提升未来无线通信系统的鲁棒性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于挤压天线辅助设计的文献大多假设用户位置信息是完全已知的，这在实际系统中是不切实际的假设。本文旨在解决多用户挤压天线下行系统中用户位置不确定性时的鲁棒资源分配问题。

**Method:** 首先，针对单用户情况，通过二分法结合几何分析推导出最优挤压天线位置和相应的功率分配。然后，将该方案扩展到多用户情况，使用粒子群优化（PSO）算法来优化挤压天线位置，以处理由此产生的非凸和不可微优化问题。

**Result:** 仿真结果表明，所提出的方案优于传统的固定天线系统，并验证了基于PSO的天线放置策略在位置不确定性下的有效性。

**Conclusion:** 本文成功解决了不完美用户位置信息下挤压天线系统的鲁棒资源分配问题，通过优化天线位置和功率分配，有效提升了系统性能并验证了所提方法的实用性。

> **ai_Abstract:** 本论文研究了在用户位置不确定性条件下，挤压天线系统中的鲁棒资源分配问题。针对单用户场景，提出了基于二分法和几何分析的最优天线位置和功率分配方法。对于多用户场景，利用粒子群优化（PSO）算法解决天线位置的非凸优化问题，旨在最小化总发射功率并满足用户中断概率约束。仿真结果验证了所提出方案相对于传统固定天线系统的优越性以及PSO算法在位置不确定性下天线放置策略的有效性。

> **摘要翻译:** 挤压天线技术最近展示了其在重新配置无线传播环境方面的巨大潜力，特别是在毫米波和太赫兹频段等高频通信系统中。通过将天线动态放置在介电波导上，可以建立视距（LoS）连接，从而显著提高系统性能。尽管最近的研究已经说明了挤压天线辅助设计的优势，但它们主要预设了用户位置的完整知识——这在实际系统中是不切实际的假设。为了解决这个问题，本文研究了在用户位置不确定性的多用户挤压天线下行系统中的鲁棒资源分配，旨在最小化总发射功率，同时满足单个中断概率约束。首先，我们处理单用户情况，推导出最优挤压天线位置，并使用二分法结合几何分析获得相应的功率分配。然后，我们将此解决方案扩展到多用户情况。在这种情况下，我们使用粒子群优化（PSO）算法来优化挤压天线位置，以处理由此产生的非凸和不可微优化问题。仿真结果表明，所提出的方案优于传统的固定天线系统，并验证了基于PSO的天线放置策略在位置不确定性下的有效性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [539] [Robust Beamforming Design for Secure Near-Field ISAC Systems](https://arxiv.org/abs/2507.12881)
> *安全近场ISAC系统中的鲁棒波束成形设计*

*Ziqiang CHen, Feng Wang, Guojun Han, Xin Wang, Vincent K. N. Lau* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-17**

**Keywords:** 鲁棒波束成形, 近场ISAC, 安全通信, 信道不确定性, SROCR

**Comment:** 5 pages, 4 figures, accepted by IEEE WCL

> **TL;DR:** 本文提出了一种针对近场安全ISAC系统的鲁棒波束成形设计，通过S-Procedure和SROCR方法解决了非凸问题，数值结果表明该方案在安全性和鲁棒性方面优于现有方案。

**AI_Comments:** 该论文的创新点在于将S-Procedure和SROCR方法结合应用于考虑信道不确定性的近场安全ISAC系统鲁棒波束成形设计。它提供了一种有效且低复杂度的解决方案来处理非凸优化问题，并显著提升了系统的安全性和鲁棒性，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对包含多个通信用户、目标和窃听者的近场安全集成感知与通信（ISAC）系统，考虑到信道不确定性，需要设计鲁棒的波束成形以最大化目标感知波束图增益，同时满足通信用户和窃听者的SINR以及ISAC发射功率约束。

**Method:** 首先，利用S-Procedure将半无限信道不确定性约束转换为线性矩阵不等式（LMIs）。然后，采用最先进的顺序秩一约束松弛（SROCR）方法来处理秩一约束，以获得低复杂度的次优解。

**Result:** 数值结果表明，所提出的ISAC波束成形设计方案优于现有的半定松弛（SDR）和其他基线方案，并且显著增强了近场ISAC系统的安全性和鲁棒性。

**Conclusion:** 本文提出的鲁棒波束成形设计方案能有效提升近场ISAC系统的安全性和鲁棒性，并通过数值结果验证了其优越性。

> **ai_Abstract:** 本文提出了一种针对近场安全集成感知与通信（ISAC）系统的鲁棒波束成形设计，该系统包含多个通信用户、目标和窃听者，并考虑了信道不确定性。研究目标是在满足通信用户和窃听者SINR以及功率约束的前提下，最大化目标的最小感知波束图增益。针对由此产生的非凸问题，作者提出了一个低复杂度的次优解，即利用S-Procedure将信道不确定性转换为线性矩阵不等式，并采用SROCR方法处理秩一约束。数值结果验证了所提方案在提升近场ISAC系统安全性和鲁棒性方面的优越性。

> **摘要翻译:** 本文研究了针对具有多个通信用户（CUs）、目标以及多个窃听者的近场安全集成感知与通信（ISAC）系统的鲁棒波束成形设计。考虑到信道不确定性约束，我们最大化了目标的最小感知波束图增益，同时满足每个CU的最小信干噪比（SINR）约束、每个窃听者的最大SINR约束以及ISAC发射功率约束。所构建的设计问题是非凸的。作为一种低复杂度的次优解，我们首先应用S-Procedure将半无限信道不确定性约束转换为线性矩阵不等式（LMIs），然后使用最先进的顺序秩一约束松弛（SROCR）方法来处理秩一约束。数值结果表明，所提出的ISAC波束成形设计方案优于现有的半定松弛（SDR）和其他基线方案，并且显著增强了近场ISAC系统的安全性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [584] [Secure Pinching Antenna-aided ISAC](https://arxiv.org/abs/2507.13131)
> *安全夹持天线辅助的ISAC*

*Elmehdi Illi, Marwa Qaraqe, Ali Ghrayeb* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-17**

**Keywords:** 夹持天线, ISAC, 安全通信, 传感性能, 波束成形

**Comment:** 

> **TL;DR:** 本研究提出了一种利用夹持天线（PA）的安全集成传感与通信（ISAC）方案，旨在优化PA位置和信号设计以最大化网络传感性能，同时满足保密和功率限制。数值结果表明，该方案在照明功率方面显著优于传统系统。

**AI_Comments:** 该论文提出了一种新颖的夹持天线（PA）辅助ISAC方案，创新点在于引入PA来增强安全性和传感性能。通过联合优化PA位置、波束成形和人工噪声，实现了在保证通信机密性的同时，有效提升恶意目标探测能力。其在照明功率方面的显著性能提升表明了该方案的潜在价值，为未来安全ISAC系统的设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在集成传感与通信（ISAC）系统中，如何在服务合法用户通信的同时，有效探测恶意目标并保证通信机密性是一个重要挑战。

**Method:** 本研究提出了一种夹持天线（PA）辅助的安全ISAC方案。该方案优化了PA位置，并在此基础上设计了合法信号波束成形和人工噪声协方差矩阵，以在保密和总功率约束下最大化网络的传感性能。

**Result:** 数值示例表明，所提出的方案在照明功率方面比基线等距PA辅助方案高出3 dB，并且比传统的半波长间隔均匀线性阵列ISAC系统高出高达30 dB。

**Conclusion:** 本研究提出的夹持天线辅助安全ISAC方案在保证通信机密性和功率约束的同时，显著提升了网络传感性能，尤其在照明功率方面表现出优越性。

> **ai_Abstract:** 本研究提出了一种基于夹持天线（PA）的安全集成传感与通信（ISAC）系统方案。该方案通过优化PA位置，并在保密和总功率约束下，设计合法信号波束成形和人工噪声协方差矩阵，以最大化网络的传感性能。数值结果验证了该方案的有效性，并显示其在照明功率方面显著优于传统的DFRC ISAC系统和基线等距PA辅助方案。

> **摘要翻译:** 在这封信中，我们研究了一种用于建立安全集成传感与通信系统（ISAC）的夹持天线（PA）辅助方案。底层系统包括一个双功能雷达通信（DFRC）基站（BS），该基站连接到多个波导，用于服务多个下行链路用户，同时感知给定区域内的一组恶意目标。PA辅助基站旨在保持与合法用户的通信机密性，同时能够检测恶意目标。所提出方案的一个目标是优化PA位置，在此基础上提供合法信号波束成形和人工噪声协方差矩阵的最优设计，以在保密和总功率约束下最大化网络的传感性能。我们通过数值示例证明了所提出方案的有效性，并将其与使用半波长间隔天线均匀线性阵列的传统DFRC ISAC系统进行了比较。结果表明，所提出的方案在照明功率方面比基线等距PA辅助方案高出3 dB，同时与使用半波长间隔均匀线性阵列的传统ISAC系统相比，在相同指标上可提供高达30 dB的增益。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [629] [A Framework of Distributed Source Encryption using Mutual Information Security Criterion and the Strong Converse Theorem](https://arxiv.org/abs/2507.13294)
> *基于互信息安全准则和强逆定理的分布式信源加密框架*

*Yasutada Oohama, Bagus Santoso* | **Category: cs.IT, math.IT** | **Updated: 2025-07-17**

**Keywords:** 分布式信源加密, 互信息, 安全准则, 速率区域, 强逆定理

**Comment:** 11 pages, two figures. A short version of this paper is accepted for
  presentation in ITW 2025, which will be held at Sydney form Sept. 29 to Oct.
  3 in 2025. This conference accepted paper consists of 5 pages for the text
  and one page for the reference. ITW 2025 program committee recommends that a
  complete version of the conference paper such as this paper is published in
  advance at the arXiv. arXiv admin note: text overlap with arXiv:2102.06363

> **TL;DR:** 本文基于标准互信息安全准则，重新研究了分布式安全信源编码，并成功确立了其速率区域的边界。

**AI_Comments:** 本文通过采用标准互信息安全准则，修正并完善了先前关于分布式信源加密速率区域边界的推导，提高了理论的严谨性和普适性。其创新点在于将标准信息论安全概念引入并成功应用于分布式编码框架，对于后续研究具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** Oohama和Santoso（ITW 2021）提出的分布式信源加密框架，其速率区域的边界是基于非标准安全准则推导的，本文旨在采用标准互信息安全准则来重新确立这些边界。

**Method:** 本文采用标准互信息作为安全准则，并利用信息谱方法和Birkhoff-von Neumann定理的变体来推导速率区域的边界。

**Result:** 成功地基于标准互信息安全准则建立了分布式安全信源编码的速率区域边界。

**Conclusion:** 本文成功地将标准互信息安全准则应用于分布式安全信源编码，并确立了其速率区域的精确边界，纠正了先前工作中使用非标准准则的问题。

> **ai_Abstract:** 本文重新审视了Oohama和Santoso（ITW 2021）提出的分布式安全信源编码框架。针对先前工作中使用非标准安全准则推导速率区域边界的问题，本文采纳了标准互信息作为安全准则，并成功地确立了基于该准则的速率区域边界。研究过程中，信息谱方法和Birkhoff-von Neumann定理的变体发挥了关键作用。

> **摘要翻译:** 我们重新研究了Oohama和Santoso（ITW 2021）提出的基于通用密钥密码系统的通用分布式安全信源编码。他们提出了一个分布式信源加密框架，并推导了实现可靠和安全传输的必要和充分条件。然而，在所提出的密码系统下，指定实现可靠和安全传输的必要和充分条件的速率区域边界是基于一种自制的“非标准”安全准则推导的。在本文中，我们采用标准安全准则，即标准互信息。我们成功地基于这种安全准则建立了速率区域的边界。信息谱方法和Birkhoff-von Neumann定理的一个变体在推导结果中发挥了重要作用。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [667] [Analytical Optimization for Antenna Placement in Pinching-Antenna Systems](https://arxiv.org/abs/2507.13307)
> *钳制天线系统中天线放置的解析优化*

*Zhiguo Ding, H. Vincent Poor* | **Category: cs.IT, math.IT** | **Updated: 2025-07-17**

**Keywords:** 天线放置, 钳制天线, 解析优化, OMA, NOMA

**Comment:** 

> **TL;DR:** 本文通过解析优化方法，为钳制天线系统中的天线放置问题提供了闭式解，并揭示了天线放置对系统性能的影响，特别是在正交多址(OMA)和非正交多址(NOMA)传输下的最优位置选择。

**AI_Comments:** 本文的创新之处在于采用解析优化而非传统的数值方法来解决钳制天线系统的天线放置问题，从而获得了闭式解。这不仅提供了对系统性能影响的深刻理解，也为未来系统设计提供了理论指导，揭示了不同多址接入方案下天线最优位置选择的内在机制。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于钳制天线位置优化的工作大多采用复杂的数值优化和学习工具，缺乏对钳制天线放置的深入理解。本文旨在弥补这一研究空白，通过解析优化获得最优天线位置的闭式解。

**Method:** 本文采用解析优化方法，推导了最优天线位置的闭式解。具体研究了面向用户公平的正交多址（OMA）传输、基于贪婪分配的OMA传输（通过高信噪比近似进行渐近研究）以及非正交多址（NOMA）传输（即使是面向用户公平的目标）下的天线放置问题。

**Result:** 对于面向用户公平的OMA传输，解析结果表明钳制天线应激活在对所有服务用户都有利的位置，但用户到波导的距离对位置选择没有影响。对于基于贪婪分配的OMA传输，渐近研究表明最优天线位置非常接近最靠近波导的用户。对于NOMA传输（即使是面向用户公平的目标），解析结果显示最优天线位置并非能使所有用户受益，而是靠近最靠近波导的用户。

**Conclusion:** 本文通过解析优化，为钳制天线系统中的天线放置问题提供了深入理解，揭示了在不同多址接入方案（OMA和NOMA）及优化目标下，最优天线位置的决定因素，即它取决于接入方式和用户分布，而非一概而论。

> **ai_Abstract:** 本文针对钳制天线系统中的天线位置优化这一关键问题，提出了解析优化方法，以弥补现有数值方法在提供深入理解方面的不足。研究获得了最优天线位置的闭式解，并分析了其对系统性能的影响。具体地，对于面向用户公平的OMA传输，最优位置对所有用户有利，且与用户到波导的距离无关；而对于贪婪分配的OMA传输，最优位置靠近最接近波导的用户。对于NOMA传输，即使目标是用户公平，最优位置也倾向于靠近最接近波导的用户。这些解析结果提供了关于最优天线放置的深刻见解。

> **摘要翻译:** 作为钳制天线系统设计中的主要问题，天线位置优化是实现信道可重构性和系统灵活性的关键。该领域现有的大多数工作都采用复杂的优化和学习工具以数值方式确定最优天线位置，但对钳制天线放置的深入理解仍然缺失。受此研究空白的启发，本文旨在对钳制天线放置进行解析优化，获得了最优天线位置的闭式解，以揭示天线放置对系统性能的影响。具体而言，对于面向用户公平的正交多址（OMA）传输，解析结果表明钳制天线需要激活在对所有服务用户都有利的位置；然而，用户到波导的距离对位置选择没有影响。对于基于贪婪分配的OMA传输，基于高信噪比近似进行渐近研究表明，最优天线位置非常接近最靠近波导的用户。对于非正交多址（NOMA）传输，即使目标是面向用户公平，所获得的解析结果也表明最优天线位置并非能使所有用户受益，而是靠近最靠近波导的用户。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [42] [GPU Performance Portability needs Autotuning](https://arxiv.org/abs/2505.03780)
> *GPU性能可移植性需要自动调优*

*Burkhard Ringlein, Thomas Parnell, Radu Stoica* | **Category: cs.AR, cs.AI, cs.PL** | **Updated: 2025-07-17**

**Keywords:** GPU性能可移植性, 自动调优, LLM推理, JIT编译, 内核优化

**Comment:** revision after reviewers feedback, broadening autotune study

> **TL;DR:** 本文提出结合即时编译(JIT)和全面的内核参数自动调优，以实现在无需代码更改的情况下，跨GPU厂商实现LLM推理的性能可移植性，并展示了显著的性能提升和代码优化。

**AI_Comments:** 这项工作具有重要的创新性，它通过结合JIT编译和自动调优，有效地解决了LLM在多GPU平台上的性能可移植性难题，这在当前AI硬件多样化发展的背景下尤为关键。其能够显著提升性能并减少手动优化，展现了巨大的实用价值和对未来AI硬件生态的积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 随着LLM复杂性增加，实现最先进的性能需要算法、软件和硬件的紧密协同设计。当前对单一主导平台的依赖限制了可移植性，造成厂商锁定，并为新的AI硬件设置了障碍。

**Method:** 本文提出将即时编译（JIT）与全面的内核参数自动调优相结合，以实现在无需代码更改的情况下，实现最先进性能的LLM推理可移植性。研究重点是性能关键的LLM内核。

**Result:** 该方法探索了多达15倍的内核参数配置，生成了在多个维度上显著更多样化的代码，甚至比供应商优化实现高出230%，同时将内核代码大小减少了70倍，并消除了手动代码优化。

**Conclusion:** 结果表明，自动调优是解锁跨GPU厂商模型可移植性的一条有前景的途径。

> **ai_Abstract:** 本文提出了一种结合即时编译（JIT）和内核参数自动调优的方法，旨在解决大型语言模型（LLM）在不同GPU平台上的性能可移植性问题。该方法通过深入探索内核参数配置，生成多样化代码，实现了LLM推理性能的显著提升（最高达230%），甚至超越了供应商优化，同时大幅减少了代码量并消除了手动优化需求。研究结果表明，自动调优是实现跨GPU厂商LLM模型可移植性的有效途径。

> **摘要翻译:** 随着LLM复杂性的增长，实现最先进的性能需要算法、软件和硬件的紧密协同设计。当前对单一主导平台的依赖限制了可移植性，造成厂商锁定，并为新的AI硬件设置了障碍。在这项工作中，我们提出将即时编译（JIT）与全面的内核参数自动调优相结合，以实现在无需代码更改的情况下，实现最先进性能的LLM推理可移植性。我们专注于性能关键的LLM内核，结果表明该方法探索了多达15倍的内核参数配置，生成了在多个维度上显著更多样化的代码，甚至比供应商优化实现高出230%，同时将内核代码大小减少了70倍，并消除了手动代码优化。我们的结果强调，自动调优是解锁跨GPU厂商模型可移植性的一条有前景的途径。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [87] [High-Performance Pipelined NTT Accelerators with Homogeneous Digit-Serial Modulo Arithmetic](https://arxiv.org/abs/2507.12418)
> *采用同质数字串行模运算的高性能流水线NTT加速器*

*George Alexakis, Dimitrios Schoinianakis, Giorgos Dimitrakopoulos* | **Category: cs.AR** | **Updated: 2025-07-17**

**Keywords:** NTT, FHE, 硬件加速, 数字串行模运算, 流水线加速器

**Comment:** 28th Euromicro Conference Series on Digital System Design (DSD 2025)

> **TL;DR:** 本文提出了一种结合同质数字串行模运算和冗余数据表示的流水线NTT加速器，以克服大字长模运算的局限性，实现高时钟频率和低硬件复杂度，并优于现有技术。

**AI_Comments:** 本文的创新点在于将数字串行模运算与冗余数据表示相结合，并应用于流水线NTT加速器设计，从而有效克服了传统大字长模运算在硬件实现上的瓶颈。其提出的均匀操作方式避免了中间（反）序列化，提高了效率。这对于推动FHE等计算密集型隐私保护技术的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数论变换（NTT）是隐私保护技术（特别是全同态加密FHE）中的基础操作。NTT计算效率直接影响FHE的整体性能，因此硬件加速对于实现实际的FHE应用至关重要。然而，在大模数上进行NTT操作需要大字长模运算，这限制了硬件中可实现的时钟频率并增加了硬件面积成本。

**Method:** 本文旨在利用数字串行模运算结合适当的冗余数据表示，设计模块化流水线NTT加速器，使其能够统一地对任意小数字进行操作，而无需中间（反）序列化。所提出的架构通过规则流水线实现高时钟频率，同时保持并行性。

**Result:** 实验结果表明，所提出的方法在相同性能和输入输出带宽约束下，优于最先进的实现，并降低了硬件复杂度。

**Conclusion:** 本文通过采用同质数字串行模运算和冗余数据表示，成功设计出高性能流水线NTT加速器，解决了大字长模运算带来的频率和面积限制，实现了更高的时钟频率、并行性和更低的硬件复杂度，从而加速了FHE等隐私保护技术的实际应用。

> **ai_Abstract:** 本文提出了一种创新的高性能流水线数论变换（NTT）加速器架构，该架构利用同质数字串行模运算和冗余数据表示。此设计旨在解决现有大字长模运算在全同态加密（FHE）应用中面临的时钟频率限制和硬件面积成本问题。通过规则流水线化，该加速器实现了高时钟频率并保持并行性，实验证明其性能优于现有技术，并在同等性能和输入输出带宽下降低了硬件复杂度。

> **摘要翻译:** 数论变换（NTT）是隐私保护技术，特别是全同态加密（FHE）中的基本操作。NTT计算效率直接影响FHE的整体性能，使得硬件加速成为实现实际FHE应用的关键技术。定制加速器，无论是FPGA还是ASIC，由于能够利用大规模并行和专业优化，提供了显著的性能优势。然而，在大模数上进行NTT操作需要大字长模运算，这限制了硬件中可实现的时钟频率并增加了硬件面积成本。为了克服这些缺陷，已经独立探索了用于模乘和模加的数字串行算术。这项工作的目标是利用数字串行模运算结合适当的冗余数据表示，设计模块化流水线NTT加速器，使其能够统一地对任意小数字进行操作，而无需中间（反）序列化。所提出的架构通过规则流水线实现高时钟频率，同时保持并行性。实验结果表明，所提出的方法在相同性能和输入输出带宽约束下，优于最先进的实现，并降低了硬件复杂度。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [589] [Modular SAIL: dream or reality?](https://arxiv.org/abs/2507.12471)
> *模块化SAIL：梦想还是现实？*

*Petr Kourzanov, Anmol* | **Category: cs.AR** | **Updated: 2025-05-22**

**Keywords:** RISC-V, SAIL, 模块化, 组合性, 仿真器

**Comment:** 

> **TL;DR:** 研究表明，将模块化引入SAIL-RISCV黄金模型以支持RISC-V ISA组合性是可行的。

**AI_Comments:** 这篇论文的创新在于将模块化和组合性概念引入了RISC-V的黄金模型（SAIL-RISCV），解决了RISC-V社区在ISA模块化方面的关键挑战。其重要性在于，如果成功，这将极大地提升RISC-V生态系统的灵活性和可扩展性，使得ISA扩展和验证更加高效。论文通过实验证明了其方法的可行性，为RISC-V的未来发展提供了有益的探索。

<details>
  <summary>Details</summary>

**Motivation:** 为了真正受益于RISC-V ISA的模块化，社区需要解决组合性问题，超越规范层面的模块，覆盖包括仿真、模拟和验证在内的更广泛的RISC-V开发流程。

**Method:** 本文介绍了模块化SAIL，这是一项旨在将组合性注入SAIL-RISCV黄金模型的实验。通过实验展示了SAIL-RISCV流程（以及理想情况下SAIL编译器本身）适应仿真器级别的模块并不困难。通过对使用静态和动态绑定的可插拔仿真器性能进行比较研究来支持发现。

**Result:** 结果显示，适应SAIL-RISCV流程以支持仿真器级别的模块化在原则上并不困难。可插拔仿真器在使用静态和动态绑定时，与原始的单片仿真器（RISC-V ISS）具有相同的功能行为。

**Conclusion:** 将模块化SAIL引入RISC-V开发流程是可行的，并且能够保持与现有系统相同的功能性，从而使RISC-V ISA的模块化成为现实。

> **ai_Abstract:** 本文探讨了RISC-V ISA模块化中的组合性挑战，并提出了模块化SAIL作为解决方案。研究表明，将模块化概念引入SAIL-RISCV黄金模型及其开发流程是可行的，且不会影响功能行为。通过对可插拔仿真器的性能研究，验证了该方法的可行性，为实现RISC-V ISA的真正模块化迈出了重要一步。

> **摘要翻译:** 为了真正受益于RISC-V ISA的模块化，社区必须解决组合性问题，超越规范层面的模块，覆盖包括仿真、模拟和验证在内的更广泛的RISC-V开发流程。本文介绍了模块化SAIL，这是一项旨在将组合性注入SAIL-RISCV黄金模型的实验。我们表明，原则上，SAIL-RISCV流程（以及理想情况下SAIL编译器本身）适应仿真器级别的模块并不困难。我们通过对使用静态和动态绑定的可插拔仿真器性能进行比较研究来支持我们的发现，这两种绑定方式都表现出与原始单片仿真器（即RISC-V ISS）相同的功能行为。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [634] [An ultra-low-power CGRA for accelerating Transformers at the edge](https://arxiv.org/abs/2507.12904)
> *一种用于边缘设备加速Transformer的超低功耗CGRA*

*Rohit Prasad* | **Category: cs.AR, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 超低功耗, CGRA, Transformer, 边缘计算, GEMM

**Comment:** 

> **TL;DR:** 鉴于Transformer模型在低功耗边缘设备上部署的计算挑战，本文提出了一种超低功耗粗粒度可重构阵列（CGRA）架构，旨在通过优化通用矩阵乘法（GEMM）、内存操作和通信来加速Transformer模型。

**AI_Comments:** 该论文的创新之处在于专门为边缘设备上的Transformer加速定制了CGRA，解决了在受限硬件上部署大型模型的关键挑战。其架构选择，如专用的内存操作块（MOBs）和无交换机互连网络，对于实现超低功耗和处理计算密集型GEMM工作负载的高效率至关重要，这对实现普适人工智能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型在深度学习领域取得了革命性进展，但其巨大的计算需求使得在低功耗边缘设备上部署变得非常困难。

**Method:** 本文提出了一种超低功耗的粗粒度可重构阵列（CGRA）架构，专门用于加速Transformer模型中的通用矩阵乘法（GEMM）操作，以适应边缘应用的能耗和资源限制。该架构集成了4x4的处理单元（PE）阵列以实现高效并行计算，以及专用的4x2内存操作块（MOB）用于优化加载/存储操作，从而减少内存带宽需求并增强数据重用。此外，无交换机网格环形互连网络通过实现PE和MOB之间的直接通信，进一步最小化了功耗和延迟。

**Result:** 该CGRA架构通过其异构阵列设计和高效数据流，有效解决了Transformer模型独特的计算需求，为在边缘设备上部署复杂的机器学习模型提供了可扩展的途径。

**Conclusion:** 本文提出的CGRA架构通过优化Transformer模型中的GEMM和数据处理，为在资源受限的边缘设备上部署计算密集型Transformer模型提供了一个可扩展且高效的途径。

> **ai_Abstract:** 本文提出了一种超低功耗的粗粒度可重构阵列（CGRA）架构，旨在加速Transformer模型在边缘设备上的运行。为应对Transformer的计算挑战，所提出的CGRA集成了4x4的处理单元（PE）阵列和4x2的内存操作块（MOB），以优化通用矩阵乘法（GEMM）和内存操作。一个无交换机网格环形互连网络确保了高效、低功耗的通信。这种异构设计为在能耗和资源受限的边缘平台上可扩展地部署复杂的机器学习模型提供了可能。

> **摘要翻译:** Transformer模型在自然语言处理、计算机视觉等领域取得了革命性进展。然而，它们的计算需求使得在低功耗边缘设备上部署面临挑战。本文介绍了一种超低功耗的粗粒度可重构阵列（CGRA）架构，专门设计用于加速Transformer模型中的通用矩阵乘法（GEMM）操作，以适应边缘应用的能耗和资源限制。所提出的架构集成了4x4的处理单元（PE）阵列以实现高效并行计算，以及专用的4x2内存操作块（MOB）用于优化加载/存储操作，从而减少内存带宽需求并增强数据重用。无交换机网格环形互连网络通过实现PE和MOB之间的直接通信，进一步最小化了功耗和延迟，无需集中式交换。通过其异构阵列设计和高效数据流，该CGRA架构解决了Transformer模型独特的计算需求，为在边缘设备上部署复杂的机器学习模型提供了可扩展的途径。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [671] [WIP: Turning Fake Chips into Learning Opportunities](https://arxiv.org/abs/2507.13281)
> *WIP: 将假芯片转化为学习机会*

*Haniye Mehraban, Saad Azmeen-ur-Rahman, John Hu* | **Category: cs.AR** | **Updated: 2025-07-17**

**Keywords:** 假冒芯片, 电子教育, 实践学习, 模拟电路, 供应链安全

**Comment:** This is the accepted version of a paper accepted for presentation at
  the 2025 IEEE Frontiers in Education Conference (FIE). The final version will
  be available via IEEE Xplore at:https://ieeexplore.ieee.org/Xplore/home.jsp

> **TL;DR:** 一篇进行中的论文，描述了如何将电子课程中发现的假冒芯片转化为一次实践学习体验。

**AI_Comments:** 这项工作提供了一个创新且实用的教学方法，将负面事件转化为积极的学习体验。它强调了在工程教育中结合实际问题解决的重要性，并提升了学生对供应链安全等现实挑战的认识。

<details>
  <summary>Details</summary>

**Motivation:** 假冒集成电路日益普遍，对本科电子实验室的完整性构成重大威胁。作者旨在将此问题转化为教学机会。

**Method:** 发现假冒TL074运算放大器后，作者没有简单替换，而是将其变成教学环节。学生通过测量电流、分析波形和故障排除进行实践诊断。

**Result:** 学生通过使用假芯片组件，对模拟电路、供应链安全和实际工程有了更深入的理解。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文是一篇进行中的工作，探讨了如何将电子实验室中发现的假冒TL074运算放大器转化为独特的教学机会。面对日益普遍的假冒集成电路威胁，作者没有直接替换，而是引导学生进行实践诊断，包括电流测量、波形分析和故障排除。此举使学生不仅深入理解了模拟电路，还认识到供应链安全的重要性，并获得了宝贵的实际工程经验。

> **摘要翻译:** 这篇进行中的论文介绍了一个案例研究，其中在初级电子课程中发现的假冒TL074运算放大器成为了实践学习体验的基础。假冒集成电路（IC）日益普遍，对本科电子实验室的完整性构成了重大威胁。我们没有简单地替换假冒组件，而是将这个问题变成了一个教学时刻。学生们参与了动手诊断，测量电流、分析波形和故障排除。通过使用假芯片组件，他们对模拟电路、供应链安全和实际工程有了更深入的理解。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [47] [Building State Machine Replication Using Practical Network Synchrony](https://arxiv.org/abs/2507.12792)
> *使用实用网络同步构建状态机复制*

*Yiliang Wan, Nitin Shivaraman, Akshaye Shenoi, Xiang Liu, Tao Luo, Jialin Li* | **Category: cs.DC** | **Updated: 2025-07-17**

**Keywords:** 状态机复制, 网络同步, 分布式系统, Chora, 吞吐量

**Comment:** 12 pages, 10 figures

> **TL;DR:** 该论文提出了一种新的网络设计，在数据中心实现了强同步（2微秒的轮次界限），并共同设计了一种利用此特性的新型复制协议Chora，显著提升了吞吐量。

**AI_Comments:** 这篇论文通过证明在现代数据中心中实现强同步是可行的，挑战了分布式系统传统的异步/部分同步假设。其创新之处在于共同设计了专门的网络基础设施和紧密利用这种同步性的复制协议（Chora），从而实现了显著的性能提升。它的重要性在于拓宽了分布式系统中网络假设的“实用”边界，可能为超低延迟、高吞吐量的分布式应用开辟新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 传统的分布式协议对底层网络做出最小假设，通常假定为部分同步或完全异步模型。然而，本文认为现代数据中心系统在常见情况下可以提供强大的同步特性。其动机是设计一个实用的系统和新的复制协议来验证这一假设，并利用这种强同步性来提高性能。

**Method:** 作者工程化了一个实用的网络设计，结合了内核旁路网络、多线程架构和宽松的轮次长度，实现了小于2微秒的紧密轮次界限。在此基础上，他们共同设计了一种名为Chora的新型复制协议，该协议利用强大的网络同步特性，高效地流水线化多个复制实例，并允许所有副本并行提议而无需额外协调。

**Result:** 工程化的网络实现了小于2微秒的紧密轮次界限。新的复制协议Chora在吞吐量上分别比最先进的单领导者协议提高了255%，比多领导者协议提高了109%。

**Conclusion:** 本文证明了现代数据中心系统能够提供强大的同步性，并且可以利用这种同步性来设计高效的状态机复制协议（如Chora），显著优于现有解决方案。

> **ai_Abstract:** 本文提出现代数据中心可以提供强大的网络同步性。通过结合内核旁路网络、多线程架构和宽松的轮次长度，设计了一个实现小于2微秒紧密轮次界限的实用网络系统。在此基础上，共同设计了新的状态机复制协议Chora，该协议利用网络同步性高效地流水线化复制实例并支持并行提议。实验证明，Chora在吞吐量上显著优于现有的单领导者和多领导者协议。

> **摘要翻译:** 分布式系统，例如状态机复制，是现代应用的关键基础设施。实用的分布式协议对底层网络做出了最低限度的假设：它们通常假设一个部分同步或完全异步的网络模型。在这项工作中，我们认为现代数据中心系统可以被设计成在常见情况下提供强大的同步特性，即服务器以同步锁步轮次运行。我们通过工程化一个实用的设计来证明这一假设，该设计结合了内核旁路网络、多线程架构和宽松的轮次长度，实现了小于2微秒的紧密轮次界限。利用我们工程化的强同步网络，我们共同设计了一种新的复制协议——Chora。Chora 利用网络同步特性有效地流水线化多个复制实例，同时允许所有副本并行提议而无需额外协调。通过实验，我们表明 Chora 在吞吐量上分别比最先进的单领导者和多领导者协议提高了255%和109%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [92] [Autonomous Resource Management in Microservice Systems via Reinforcement Learning](https://arxiv.org/abs/2507.12879)
> *基于强化学习的微服务系统自主资源管理*

*Yujun Zou, Nia Qi, Yingnan Deng, Zhihao Xue, Ming Gong, Wuyang Zhang* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 微服务, 资源管理, 调度优化, 自主管理

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的微服务资源调度与优化方法，旨在解决传统微服务架构中资源分配不均、延迟高、吞吐量不足等问题，并通过实验证明了其在响应时间、吞吐量、资源利用率和成本效率方面的显著改进。

**AI_Comments:** 该论文的创新点在于将强化学习应用于微服务系统的自主资源管理，提供了一种动态且自适应的解决方案，克服了传统静态分配方法的局限性。其重要性在于能够显著提升微服务系统的性能、效率和弹性，尤其是在面对复杂多变的生产环境时。

<details>
  <summary>Details</summary>

**Motivation:** 传统微服务架构存在资源分配不均、延迟高、吞吐量不足等问题。随着服务数量和负载的增加，高效调度和分配计算、内存、存储等资源成为关键挑战。

**Method:** 本文采用基于强化学习的智能调度算法，通过智能体与环境的交互，持续优化资源分配策略。

**Result:** 实验结果表明，该方法在低负载和高并发条件下显著提高了系统响应速度和吞吐量，优化了资源利用率并降低了能耗。在多维资源条件下，该方法能考虑多目标并实现优化调度。与传统静态资源分配方法相比，强化学习模型展现出更强的适应性和优化能力，能够实时调整资源分配策略，在动态变化的负载和资源环境中保持良好的系统性能。

**Conclusion:** 基于强化学习的资源调度方法能够有效解决微服务系统中资源管理面临的挑战，显著提升系统性能和资源利用效率，并展现出优于传统方法的适应性和优化能力。

> **ai_Abstract:** 本文提出了一种基于强化学习的微服务资源调度与优化方法，旨在解决传统微服务系统中的资源分配不均、高延迟和低吞吐量问题。该方法通过智能体与环境的交互持续优化资源分配策略。实验结果表明，该方法在提高系统响应速度、吞吐量、优化资源利用率和降低能耗方面表现出色，并能适应动态变化的负载和资源环境，实现多目标资源调度，优于传统静态分配方法。

> **摘要翻译:** 本文提出了一种基于强化学习的微服务资源调度与优化方法，旨在解决传统微服务架构中资源分配不均、延迟高、吞吐量不足等问题。在微服务系统中，随着服务数量和负载的增加，高效调度和分配计算能力、内存和存储等资源成为一个关键的研究挑战。为了解决这个问题，本文采用了一种基于强化学习的智能调度算法。通过智能体与环境的交互，资源分配策略被持续优化。在实验中，本文考虑了不同的资源条件和负载场景，从响应时间、吞吐量、资源利用率和成本效率等多个维度评估了所提出的方法。实验结果表明，基于强化学习的调度方法在低负载和高并发条件下显著提高了系统响应速度和吞吐量，同时优化了资源利用率并降低了能耗。在多维资源条件下，所提出的方法可以考虑多个目标并实现优化的资源调度。与传统的静态资源分配方法相比，强化学习模型展现出更强的适应性和优化能力。它能够实时调整资源分配策略，从而在动态变化的负载和资源环境中保持良好的系统性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [290] [AAPA: An Archetype-Aware Predictive Autoscaler with Uncertainty Quantification for Serverless Workloads on Kubernetes](https://arxiv.org/abs/2507.05653)
> *AAPA：一种用于Kubernetes上无服务器工作负载的、具有不确定性量化的原型感知预测自动扩缩器*

*Guilin Zhang, Srinivas Vippagunta, Raghavendra Nandagopal, Suchitra Raman, Jeff Xu, Marcus Pfeiffer, Shreeshankar Chatterjee, Ziqi Tan, Wulan Guo, Hailong Jiang* | **Category: cs.DC** | **Updated: 2025-07-16**

**Keywords:** 自动扩缩, 无服务器, Kubernetes, 不确定性量化, 工作负载分类

**Comment:** 6 pages, 4 figures, 1 table. First three authors contributed equally.
  Correspondence to Hailong Jiang

> **TL;DR:** AAPA是一种新的预测自动扩缩器，通过识别工作负载模式并考虑不确定性，显著改善了Kubernetes上无服务器工作负载的性能，并发布了数据集。

**AI_Comments:** 这篇论文通过引入原型感知和不确定性量化，为无服务器工作负载的自动扩缩提供了一种创新方法。工作负载分类和定制策略显著提升了性能，同时发布的大规模数据集对未来研究具有重要贡献。虽然在某些情况下资源消耗增加是需要权衡的，但提出的REI指标为评估这种权衡提供了有益的工具。这项工作强调了在高度动态环境中精细化工作负载建模的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动扩缩方法通常依赖于统一的反应式策略或无条件预测模型，忽略了工作负载语义和预测不确定性，导致在高度动态和异构的工作负载下，自动扩缩仍然充满挑战。

**Method:** AAPA将工作负载分为四种行为模式（SPIKE、PERIODIC、RAMP、STATIONARY），并应用定制的扩缩策略，同时进行基于置信度的调整。为支持可重现评估，它发布了AAPAset数据集，并提出了资源效率指数（REI）来评估性能、成本和扩缩平滑度之间的权衡。

**Result:** 与Kubernetes HPA相比，AAPA将SLO违规减少高达50%，延迟降低40%，但在尖峰主导条件下资源使用量高出2-8倍。

**Conclusion:** 结果表明在自动扩缩设计中对工作负载异构性和不确定性建模的重要性。

> **ai_Abstract:** AAPA是一种新的原型感知预测自动扩缩器，旨在解决Kubernetes上无服务器工作负载在动态异构环境下的自动扩缩挑战。它通过将工作负载识别为四种模式（SPIKE、PERIODIC、RAMP、STATIONARY）并应用定制的扩缩策略，同时结合不确定性量化来优化性能。研究发布了AAPAset数据集以促进可重复评估，并引入了资源效率指数（REI）来衡量性能与资源消耗之间的权衡。实验结果显示，AAPA显著降低了SLO违规和延迟，尽管在特定条件下资源使用量有所增加，强调了对工作负载异构性和不确定性进行建模的重要性。

> **摘要翻译:** 无服务器平台（如Kubernetes）在高性能计算中得到越来越多的应用，但在高度动态和异构的工作负载下，自动扩缩仍然充满挑战。现有方法通常依赖于统一的反应式策略或无条件预测模型，忽略了工作负载语义和预测不确定性。我们提出了AAPA，一种原型感知预测自动扩缩器，它将工作负载分为四种行为模式——SPIKE（尖峰）、PERIODIC（周期）、RAMP（斜坡）和STATIONARY（稳定），并应用定制的扩缩策略，同时进行基于置信度的调整。为了支持可重现的评估，我们发布了AAPAset，一个包含30万个Azure Functions工作负载窗口的弱标注数据集，涵盖了多种模式。与Kubernetes HPA相比，AAPA将SLO违规减少高达50%，延迟降低40%，尽管在尖峰主导条件下资源使用量高出2-8倍。为了评估权衡，我们提出了资源效率指数（REI），一个平衡性能、成本和扩缩平滑度的统一指标。我们的结果证明了在自动扩缩设计中对工作负载异构性和不确定性建模的重要性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [338] [Distributed Algorithms for Potential Problems](https://arxiv.org/abs/2507.12038)
> *分布式势能问题算法*

*Alkida Balliu, Thomas Boudier, Francesco d'Amore, Dennis Olivetti, Gustav Schmid, Jukka Suomela* | **Category: cs.DC** | **Updated: 2025-07-17**

**Keywords:** 分布式算法, 局部势能问题, 局部最优割, 轮次复杂度, 有界度图

**Comment:** 28 pages, 4 figures. Acknowledgments added in v2

> **TL;DR:** 本文提出了一种快速分布式算法，解决了有界度图中的局部势能问题（包括局部最优割问题），将复杂度从O(n)降低到log^O(1) n，填补了长期存在的复杂度鸿沟。

**AI_Comments:** 本文的创新之处在于成功地弥合了局部势能问题（尤其是局部最优割问题）在分布式轮次复杂度上长期存在的巨大差距。通过提供一个多对数时间的分布式算法，它将之前平凡的O(n)上限显著降低，解决了分布式计算领域的一个重要开放问题，对理解局部性问题及其在分布式环境中的可解性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 局部最优割等局部势能问题的分布式轮次复杂度长期以来存在巨大的开放性问题和上下界之间的巨大差距，现有唯一的已知上界是平凡的O(n)轮穷举解。

**Method:** 本文提出了一种用于解决局部势能问题的快速分布式算法。

**Result:** 在有界度图中，所有局部势能问题（包括局部最优割）都可以在确定性和随机LOCAL模型下以log^O(1) n轮解决。特别是，局部最优割问题的确定性轮次复杂度现在被确定为log^Θ(1) n。

**Conclusion:** 局部最优割问题的确定性轮次复杂度现已确定为log^Θ(1) n，这表明长期存在的复杂性鸿沟已被弥合。

> **ai_Abstract:** 本文提出了一种快速分布式算法，用于解决图中的局部势能问题，这类问题旨在找到局部最优解。研究重点是局部最优割问题，该问题在分布式轮次复杂度上存在显著的上下界差距。作者证明，在有界度图中，包括局部最优割在内的所有局部势能问题都可以在确定性和随机LOCAL模型下，以多对数（log^O(1) n）轮次完成，显著改善了之前O(n)的上限，并最终确定了局部最优割问题的确定性轮次复杂度。

> **摘要翻译:** 在这项工作中，我们提出了一种针对局部势能问题的快速分布式算法：这些是图问题，其任务是找到一个局部最优解，其中没有节点可以通过改变自己的标签单方面改善其局部邻域的效用。这类问题的一个简单例子是寻找局部最优割的任务，即一个割，其中每个节点的至少一半入射边是割边。局部最优割的分布式轮次复杂度一直是一个开放问题；已知该问题在确定性LOCAL模型中需要Ω(log n)轮，在随机LOCAL模型中需要Ω(log log n)轮，但唯一已知的上界是平凡的O(n)轮暴力解。有界度图中的局部最优割可能是局部可检查标签问题中最简单的例子，其当前上下界之间仍然存在如此大的差距。我们表明，在有界度图中，所有局部势能问题，包括局部最优割，都可以在确定性和随机LOCAL模型下以log^O(1) n轮解决。特别是，局部最优割问题的确定性轮次复杂度现在被确定为log^Θ(1) n。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [32] [Rookie Mistakes: Measuring Software Quality in Student Projects to Guide Educational Enhancement](https://arxiv.org/abs/2507.12488)
> *菜鸟的错误：衡量学生项目中的软件质量以指导教育改进*

*Marco De Luca, Sergio Di Martino, Sergio Di Meglio, Anna Rita Fasolino, Luigi Libero Lucio Starace, Porfirio Tramontana* | **Category: cs.CY, cs.SE** | **Updated: 2025-07-15**

**Keywords:** 软件质量, 学生项目, 软件工程教育, 代码异味, 架构反模式

**Comment:** Manuscript accepted for the 51st Euromicro Conference Series on
  Software Engineering and Advanced Applications (SEAA)

> **TL;DR:** 本文分析了大学生的团队面向对象项目中的软件质量问题，以识别常见错误并为软件工程教育提供改进建议。

**AI_Comments:** 这篇论文通过实证分析填补了教育领域在衡量中级学生软件项目质量方面的空白。其创新之处在于将工业级的静态分析工具应用于学生项目，并提供了具体的质量问题证据，这对于指导软件工程课程改进具有重要意义。局限性可能在于研究范围仅限于一个大学的特定课程，结果的普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在学士学位课程中，软件工程教育常侧重功能实现而忽视软件质量，且质量相关主题时间有限。现有研究多关注初学者和小规模代码，缺乏对具有基础技能的中间水平学生处理复杂项目的指导。本文旨在填补此空白，为教育者提供改进课程的依据。

**Method:** 分析了来自4届面向对象编程课程中172名学生开发的83个面向对象团队项目。采用结合SonarQube和ArchUnit的静态分析管道，检测代码异味和架构反模式，以评估软件质量。

**Result:** 研究发现了学生项目中反复出现的质量问题，并提供了学生在此阶段面临挑战的具体证据。

**Conclusion:** 研究结果为教育者持续改进软件工程课程和推广面向质量的开发实践提供了有价值的指导。

> **ai_Abstract:** 本文旨在解决软件工程教育中软件质量被忽视的问题，特别是对于具有一定基础的大学生的复杂项目。研究分析了来自四年大学课程的83个面向对象团队项目，使用SonarQube和ArchUnit进行静态质量评估。结果揭示了学生常见的质量问题，为教育者提供了改进课程和促进质量导向开发实践的具体依据。

> **摘要翻译:** 在学士学位课程中教授编程和软件工程时，对创建功能性软件项目的强调往往盖过了对软件质量的关注，这一趋势与ACM课程建议相符。软件工程课程通常在课程后期引入，并且通常只能分配有限的时间用于质量相关主题，这使得教育工作者面临决定优先考虑哪些质量方面的挑战。在这项决定中，现有文献提供的指导有限，因为大多数现有研究侧重于新手学生编写的代码和小型代码单元，因此不清楚这些发现是否适用于具有面向对象编程基础技能的中间水平学生处理更复杂的软件项目。为了弥补这一空白，我们分析了由172名大学学生在4个不同版本的面向对象编程课程中开发的83个面向对象团队项目。我们应用了先前研究中使用的静态分析管道来评估软件质量，结合SonarQube和ArchUnit来检测代码异味和架构反模式。我们的发现突出了反复出现的质量问题，并提供了学生在此阶段面临挑战的具体证据，为旨在持续改进软件工程课程和推广面向质量的开发实践的教育工作者提供了宝贵的指导。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [52] [ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle](https://arxiv.org/abs/2507.12674)
> *ParaStudent：通过教授大型语言模型“挣扎”来生成和评估真实的“学生代码”*

*Mihran Miroyan, Rose Niousha, Joseph E. Gonzalez, Gireeja Ranade, Narges Norouzi* | **Category: cs.CY, cs.AI, cs.SE** | **Updated: 2025-07-16**

**Keywords:** 大型语言模型, 学生代码, 代码生成, 微调, 学习动态

**Comment:** 

> **TL;DR:** 本研究提出ParaStudent，系统探讨了大型语言模型（LLMs）生成类似真实学生代码的能力。结果表明，通过微调，LLMs能更忠实地模拟学生的学习轨迹、错误模式和编码风格，强调了捕捉学习动态的重要性。

**AI_Comments:** 这项研究具有创新性，因为它将LLM的应用从单纯追求正确答案扩展到模拟学习过程中的“挣扎”和不完美，这对于教育技术、自动反馈系统和教学辅助工具的开发具有重要意义。通过捕捉学习动态，模型能够更好地理解学生犯错的原因和学习路径，从而提供更个性化和有效的支持。其方法论结合了真实数据和多维度评估，增强了研究的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在编程任务上表现出色，但研究者想探究它们是否能生成像真实学生一样不完美、迭代且风格多样的代码，以填补现有LLMs在模拟真实学习过程方面的空白。

**Method:** 本文提出了ParaStudent，一项在入门编程课程背景下，系统研究基于LLM的“学生风格”代码生成的研究。利用跨多个学期带有时间戳的学生提交数据集，设计了低分辨率和高分辨率实验来建模学生进度，并从语义、功能和风格维度评估代码输出。

**Result:** 研究结果表明，微调显著改善了LLM生成代码与真实学生轨迹的一致性，并更忠实地捕捉了错误模式、增量改进和风格变化。

**Conclusion:** 建模真实的“学生代码”需要通过上下文感知生成、时间建模和多维度评估来捕捉学习动态。

> **ai_Abstract:** 本文介绍了ParaStudent，一项系统研究大型语言模型（LLMs）生成“学生代码”能力的工作。研究利用真实学生提交代码数据集，通过低分辨率和高分辨率实验建模学生进度。结果显示，经过微调的LLMs能显著提高生成代码与真实学生轨迹的一致性，并准确捕捉错误模式、逐步改进和风格多样性。研究强调，要生成逼真的学生代码，需关注学习动态，结合上下文感知生成、时间建模和多维度评估。

> **摘要翻译:** 大型语言模型 (LLM) 在编程任务上表现出色，但它们能否像真实学生一样——不完美、迭代且风格多样地生成学生风格的代码？我们提出了 ParaStudent，这是一项关于在入门编程课程设置中基于 LLM 的“学生风格”代码生成的系统研究。我们使用跨多个学期带有时间戳的学生提交数据集，设计了低分辨率和高分辨率实验来模拟学生进度，并从语义、功能和风格维度评估代码输出。我们的结果表明，微调显著改善了与真实学生轨迹的一致性，并更忠实地捕捉了错误模式、增量改进和风格变化。这项研究表明，建模真实的“学生代码”需要通过上下文感知生成、时间建模和多维度评估来捕捉学习动态。实验和评估代码可在 https://github.com/mmiroyan/ParaStudent 获取。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [77] [The Case for Contextual Copyleft: Licensing Open Source Training Data and Generative AI](https://arxiv.org/abs/2507.12713)
> *上下文版權傳承的案例：開源訓練數據和生成式AI的許可*

*Grant Shanklin, Emmie Hine, Claudio Novelli, Tyler Schroder, Luciano Floridi* | **Category: cs.CY, cs.SE** | **Updated: 2025-07-17**

**Keywords:** 上下文版權傳承, 生成式AI, 開源許可, FOSS, 版權法

**Comment:** 19 pages

> **TL;DR:** 本文介紹了上下文版權傳承AI（CCAI）許可證，這是一種新穎的許可機制，旨在將版權傳承原則從訓練數據擴展到生成的AI模型，以解決生成式AI對開源社區帶來的挑戰，並在適當的監管下保持開源原則的活力。

**AI_Comments:** 本文提出了一種創新的許可證模型——CCAI，旨在解決生成式AI時代開源軟件版權傳承的困境。其創新點在於將版權傳承的概念從代碼擴展到數據和模型，這對於保護開源社區的利益至關重要。其重要性在於為FOSS原則在AI領域的應用提供了潛在的解決方案，並強調了監管環境的重要性。一個潛在的局限性可能是CCAI在實際法律實施和全球範圍內被廣泛接受的挑戰。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI系統的普及對自由和開源軟件（FOSS）社區帶來了新的挑戰，特別是如何將傳統的版權傳承原則應用於使用開源代碼訓練AI模型的情況。

**Method:** 本文引入了上下文版權傳承AI（CCAI）許可證，這是一種將版權傳承要求從訓練數據擴展到生成式AI模型的新型許可機制。研究通過一個三部分評估框架進行論證，包括：1) 當前版權法下的法律可行性，2) 傳統軟件和AI上下文的政策合理性比較，以及3) 跨上下文的收益和風險綜合。

**Result:** CCAI許可證提供了顯著優勢，包括增強開發者控制、激勵開源AI開發以及減輕“開放式洗白”（openwashing）行為。研究通過評估框架證明了其可行性。然而，開源AI日益增長的風險（特別是潛在的直接濫用）需要補充性的監管方法。

**Conclusion:** 在專注於負責任AI使用的健全監管環境中實施時，CCAI許可證提供了一種可行的機制，用於在不斷發展的生成式AI開發領域中保留和適應核心FOSS原則。

> **ai_Abstract:** 該論文針對生成式AI對開源軟件（FOSS）社區帶來的挑戰，提出了一種名為上下文版權傳承AI（CCAI）的新型許可證。CCAI旨在將版權傳承原則從開源訓練數據延伸至生成的AI模型，以增強開發者控制、激勵開源AI發展並遏制“開放式洗白”。論文通過法律可行性、政策合理性及風險收益分析對CCAI進行了評估，並認為其在健全的監管框架下，是維持FOSS原則在生成式AI領域活力的可行方案。

> **摘要翻译:** 生成式AI系統的普及為自由和開源軟件（FOSS）社區帶來了新的挑戰，特別是關於當開源代碼用於訓練AI模型時，傳統的版權傳承原則應如何適用。本文介紹了上下文版權傳承AI（CCAI）許可證，這是一種新穎的許可機制，將版權傳承要求從訓練數據擴展到由此產生的生成式AI模型。CCAI許可證提供了顯著優勢，包括增強開發者控制、激勵開源AI開發以及減輕“開放式洗白”（openwashing）行為。這通過一個結構化的三部分評估框架得到證明，該框架審查了 (1) 當前版權法下的法律可行性，(2) 比較傳統軟件和AI上下文的政策合理性，以及 (3) 綜合跨上下文的收益和風險。然而，開源AI日益增長的風險，特別是直接濫用的潛力，需要補充性的監管方法來實現適當的風險-收益平衡。論文總結道，當在專注於負責任AI使用的健全監管環境中實施時，CCAI許可證提供了一種可行的機制，用於在不斷發展的生成式AI開發領域中保留和適應核心FOSS原則。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [188] [Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers](https://arxiv.org/abs/2507.12571)
> *在算法中捕捉黑暗信号：揭示推荐给儿童和青少年的不安全内容的视听和主题标记*

*Haoning Xue, Brian Nishimine, Martin Hilbert, Drew Cingel, Samantha Vigil, Jane Shawcroft, Arti Thakur, Zubair Shafiq, Jingwen Zhang* | **Category: cs.CY, cs.MM** | **Updated: 2025-07-16**

**Keywords:** 短视频平台, 不安全内容, 算法审计, 多模态分析, 儿童保护

**Comment:** 

> **TL;DR:** 研究发现，推荐给儿童和青少年的不安全短视频具有较暗的视觉特征，并包含显性和隐性有害内容，呼吁加强内容审核和平台监管。

**AI_Comments:** 该研究创新性地结合了多模态特征分析和主题建模来识别算法推荐的不安全内容，并提出了一个全面的在线危害框架。其重要性在于揭示了短视频平台对儿童和青少年的潜在风险，并为平台监管和内容审核提供了具体的建议，对保护青少年健康成长具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 短视频平台的普及以及年龄验证机制的无效性，导致儿童和青少年在算法调控的在线环境中面临潜在危害，促使研究人员调查这些风险。

**Method:** 研究人员对从Instagram Reels、TikTok和YouTube Shorts收集的4,492个推荐给儿童和青少年的短视频进行了多模态特征分析和主题建模。

**Result:** 分析显示，不安全的短视频(a)具有较暗的视觉特征，(b)包含显性有害内容以及来自引发焦虑的普通内容的隐性危害。研究还提出了一个有用的在线危害框架（即显性、隐性、非预期）。

**Conclusion:** 研究结果强调了保护处于关键发展阶段的年轻受众免受社交媒体上显性和隐性风险的重要性，并呼吁实施细致的内容审核、年龄验证和平台监管。

> **ai_Abstract:** 本研究调查了短视频平台对儿童和青少年的潜在危害，通过对4,492个推荐视频进行多模态分析和主题建模。结果发现，不安全视频具有较暗的视觉特征，并包含显性或隐性有害内容。文章提出了一个在线危害框架，并强调了对年轻受众进行内容审核、年龄验证和平台监管的必要性。

> **摘要翻译:** 短视频平台的普及，加上年龄验证机制的无效性，引发了人们对儿童和青少年在算法调控的在线环境中可能面临的危害的担忧。作为算法审计实验的一部分，我们对在Instagram Reels、TikTok和YouTube Shorts上推荐给儿童和青少年的4,492个短视频进行了多模态特征分析和主题建模。这种特征层面和内容层面的分析表明，不安全（即有问题、精神困扰）的短视频（a）具有较暗的视觉特征，（b）包含明确的有害内容以及来自引发焦虑的普通内容的隐性危害。我们引入了一个有用的在线危害框架（即显性、隐性、非预期），为理解儿童和青少年面临的动态、多方面的在线风险提供了独特的视角。研究结果强调了在关键发展阶段保护年轻受众免受社交媒体上显性和隐性风险的重要性，呼吁细致的内容审核、年龄验证和平台监管。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [242] [The Goldilocks zone of governing technology: Leveraging uncertainty for responsible quantum practices](https://arxiv.org/abs/2507.12957)
> *技术治理的金发姑娘区：利用不确定性实现负责任的量子实践*

*Miriam Meckel, Philipp Hacker, Lea Steinacker, Aurelija Lukoseviciene, Surjo R. Soekadar, Jacob Slosser, Gina-Maria Poehlmann* | **Category: cs.CY** | **Updated: 2025-07-17**

**Keywords:** 量子计算, 技术治理, 不确定性, 概率框架, 负责任创新

**Comment:** Paper is accepted and will be published

> **TL;DR:** 本文提出了一种针对量子计算等新兴技术的新治理模式，将不确定性重构为一种生成力，通过适应性、概率性框架指导负责任的创新。

**AI_Comments:** 本文通过将不确定性从一种负担重构为技术治理（特别是量子计算领域）中的宝贵资产，提供了一个创新的视角。其优势在于借鉴量子力学和认知神经科学的类比，提出了一种新颖的概率性治理模式。概念性的量子风险模拟器是一个很好的例证，尽管其具体的实施细节并非重点。这种方法可能对塑造快速发展技术的政策产生深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 新兴技术，特别是像量子计算这样不确定性是其基本特征的技术，对传统治理方法提出了挑战。本文旨在通过将不确定性从一种负担重构为一种治理的生成力来解决这个问题。

**Method:** 本文利用量子力学范式，提出了适应性、概率性的负责任创新框架。它识别了不确定性的三个层面（物理、技术和社会），并引入了量子风险模拟器（QRS）作为概念性示例，以说明基于不确定性的治理。论文还借鉴了认知神经科学和预测处理的类比，提出了一种与量子系统概率本质相符的新治理模式。

**Result:** 本文提出了一个通过利用不确定性来治理新兴技术的概念框架。它提出了一种使用概率推理并识别关键不确定性层面的模型。量子风险模拟器（QRS）被引入作为动态的、基于不确定性的治理的概念蓝图。

**Conclusion:** 所提出的与量子系统概率本质相符的治理模式，为监管量子及其他前沿技术提供了一条有前景的“第三条道路”，特别是对欧盟而言，平衡了自由放任式创新与国家主导控制。

> **ai_Abstract:** 本文探讨了治理新兴技术（特别是量子计算）的挑战，这些技术固有的不确定性。它将不确定性重新定义为一种生成力，并提出了受量子力学启发的适应性、概率性治理框架。论文识别了不确定性的物理、技术和社会层面，并引入了一个概念性的量子风险模拟器（QRS）来演示动态的、基于不确定性的治理。通过借鉴认知神经科学，它提出了一种新的概率性治理模式，将其定位为欧盟监管前沿技术的一种灵活而负责任的“第三条道路”。

> **摘要翻译:** 新兴技术对传统治理方法提出了挑战，尤其是在量子计算等领域，不确定性不是暂时的障碍，而是其基本特征。本文将不确定性从治理负担重构为一种生成力，利用量子力学范式提出了适应性、概率性的负责任创新框架。我们确定了不确定性的三个相互依赖的层面——物理、技术和社会——这些层面是量子技术演进的核心。所提出的量子风险模拟器（QRS）作为一个概念性示例，是一个富有想象力的蓝图而非规定性工具，旨在说明概率推理如何指导动态的、基于不确定性的治理。通过突出认识论和本体论的模糊性，并借鉴认知神经科学和预测处理的类比，我们提出了一种与量子系统概率本质相符的新治理模式。我们认为，这种模式对于欧盟来说尤其有前景，作为自由放任式创新和国家主导控制之间的第三条道路，为监管量子及其他前沿技术提供了一条灵活而负责任的途径。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [296] [Quantifying the Improvement of Accessibility achieved via Shared Mobility on Demand](https://arxiv.org/abs/2507.13100)
> *按需共享出行对可达性提升的量化研究*

*Severin Diepolder, Andrea Araldo, Tarek Chouaki, Santa Maiti, Sebastian Hörl, Constantinos Antoniou* | **Category: cs.CY, econ.GN, q-fin.EC** | **Updated: 2025-07-17**

**Keywords:** 共享出行服务, 可达性, 等时线, 克里金, 公共交通

**Comment:** 

> **TL;DR:** 本研究提出了一种量化计算共享出行服务（SMS）在公共交通系统中对基于等时线可达性提升的方法，填补了现有研究的空白。

**AI_Comments:** 这项研究的创新之处在于首次提出了量化计算共享出行服务（SMS）对基于等时线可达性影响的方法，填补了该领域的一个重要空白。它超越了传统的仅关注出行时间等指标的局限性，转而关注更具实际意义的“可达机会”潜力。该方法结合了时空统计分析和图论，为城市规划者和交通运营商评估共享出行对城市可达性的真实影响提供了有力的工具，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的公共交通（PT）在低密度区域服务不足，而共享出行服务（SMS）可以改善这些区域的出行能力。然而，现有的衡量指标（如等待时间、出行时间）未能充分体现SMS对用户接触周边机会（即，可达性）的重要贡献。目前缺乏量化方法来计算通过SMS实现的可达性（特别是基于等时线的可达性指标）。

**Method:** 本研究提出了一种计算由常规公共交通和作为接驳服务的共享出行组成的公共交通系统等时线可达性的方法。该方法基于通过克里金（Kriging）进行的时空统计分析。它以观测到的共享出行数据为输入，将其汇总到一个图中，然后在此图上计算等时线可达性指标。

**Result:** 本研究开发并提出了一种量化计算共享出行服务可达性提升的方法，并将其应用于巴黎-萨克雷郊区一个关于整合按需响应交通到公共交通的MATSim模拟研究。

**Conclusion:** 该研究成功填补了现有定量计算共享出行服务所实现的可达性（特别是基于等时线指标）的空白，为评估共享出行对区域可达性的实际贡献提供了工具。

> **ai_Abstract:** 本研究旨在解决量化评估共享出行服务（SMS）对可达性提升的空白。鉴于传统指标未能充分衡量SMS在连接用户与周边机会方面的贡献，论文提出了一种新的方法，利用克里金（Kriging）进行时空统计分析，将观测到的SMS出行数据转化为图结构，进而计算基于等时线的可达性指标。该方法已被应用于巴黎-萨克雷郊区的一个整合按需响应交通与公共交通的模拟案例研究。

> **摘要翻译:** 共享出行服务（SMS），例如按需响应式交通或拼车，可以改善低密度区域的出行，这些区域通常传统公共交通（PT）服务不佳。这种改善通常通过基本的性能指标来衡量，例如等待时间或出行时间。然而，这些基本指标并未考虑SMS对区域可能提供的最重要的贡献，即增加用户到达周边机会（例如工作、学校、商业等）的潜力。这种潜力可以通过基于等时线的可达性指标来衡量，这些指标计算在有限时间内可到达的机会数量，因此易于公众理解。SMS对可达性的潜在影响已被定性讨论，对公平性的影响也已进行实证研究。然而，迄今为止，还没有量化方法来计算通过SMS实现的可达性（基于等时线指标）。
这项工作通过提出第一个计算由常规公共交通和作为公共交通枢纽接驳服务的SMS组成的公共交通系统等时线可达性的方法，填补了这一空白。该方法基于通过克里金（Kriging）进行的时空统计分析。它将观测到的SMS出行作为输入，并将其汇总到一个图中。在此图上，计算等时线可达性指标。我们将所提出的方法应用于一个关于按需响应式交通整合到公共交通的MATSim模拟研究，该研究涉及巴黎-萨克雷郊区。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [390] [Dataset resulting from the user study on comprehensibility of explainable AI algorithms](https://arxiv.org/abs/2411.02419)
> *可解释人工智能算法可理解性用户研究数据集*

*Szymon Bobek, Paloma Korycińska, Monika Krakowska, Maciej Mozolewski, Dorota Rak, Magdalena Zych, Magdalena Wójcik, Grzegorz J. Nalepa* | **Category: cs.CY, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 可解释人工智能, 用户研究, 数据集, 可理解性, 定性评估

**Comment:** 

> **TL;DR:** 该论文介绍了一个关于可解释人工智能算法可理解性用户研究的数据集。

**AI_Comments:** 该数据集对于研究XAI的可理解性具有重要意义，尤其在于其多学科的用户群体设计，能够从不同背景视角收集对AI解释的理解和反馈。手动标记的访谈记录以及补充数据（如可视化和改进建议）增加了数据集的丰富性和可用性。这对于促进XAI领域对人类因素和定性评估的研究至关重要，有助于设计更符合用户需求的可解释AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 随着可解释AI技术快速发展，社区需要对可解释性进行多学科定性评估。该数据集旨在满足这一需求，并为分析收集到的材料提供可能性。

**Method:** 进行了一项用户研究，招募了149名候选人，分为三组：真菌学专家（DE）、数据科学和可视化背景的学生（IT）、社会科学和人文学科学生（SSH）。研究主要内容是访谈参与者，要求他们完成与解释机器学习模型决策（区分可食用和不可食用蘑菇）相关的任务和问题。访谈记录被手动标记，并辅以解释的可视化、主题分析结果、参与者提供的改进建议以及初步调查结果（用于确定领域知识和数据分析素养）。

**Result:** 论文介绍了一个数据集，该数据集是关于可解释人工智能（XAI）算法可理解性用户研究的产物。数据集主要包含39份访谈记录，以及解释的可视化、主题分析结果、参与者提供的改进建议和初步调查结果。

**Conclusion:** 该数据集不仅可以复现研究，还为分析收集到的材料提供了广泛的可能性，以支持多学科定性评估可解释性。

> **ai_Abstract:** 本文介绍了一个新的数据集，该数据集源于一项关于可解释人工智能（XAI）算法可理解性的用户研究。研究招募了真菌学专家、数据科学学生和社会科学学生三类参与者，通过访谈记录他们对机器学习模型解释的理解和反馈。该数据集包含39份访谈记录、解释可视化、主题分析结果、改进建议和参与者背景调查数据，旨在支持对XAI可解释性进行多学科定性评估，并为未来的研究提供丰富的分析材料。

> **摘要翻译:** 本文介绍了一个数据集，该数据集是关于可解释人工智能（XAI）算法可理解性用户研究的成果。该研究的参与者从149名候选人中招募，组成了代表真菌学领域专家（DE）、具有数据科学和可视化背景的学生（IT）以及社会科学和人文学科学生（SSH）的三个小组。数据集的主要部分包含39份访谈记录，访谈期间参与者被要求完成一系列与解释机器学习模型决策（该模型旨在区分可食用和不可食用蘑菇）相关的任务和问题。访谈记录补充了额外数据，包括呈现给用户的解释的可视化、主题分析结果、参与者提供的解释改进建议，以及用于确定参与者领域知识和数据分析素养的初步调查结果。访谈记录经过手动标记，以便文本与其他特定片段相关数据之间进行自动匹配。在XAI技术快速发展的背景下，对可解释性进行多学科定性评估的需求是社区中正在出现的主题之一。我们的数据集不仅可以重现我们进行的研究，还为分析我们收集的材料开辟了广阔的可能性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [425] [AI Governance InternationaL Evaluation Index (AGILE Index) 2024](https://arxiv.org/abs/2502.15859)
> *人工智能治理国际评估指数（AGILE指数）2024*

*Yi Zeng, Enmeng Lu, Xin Guan, Cunqing Huangfu, Zizhe Ruan, Ammar Younas, Kang Sun, Xuan Tang, Yuwei Wang, Hongjie Suo, Dongqi Liang, Zhengqiang Han, Aorigele Bao, Xiaoyang Guo, Jin Wang, Jiawei Xie, Yao Liang* | **Category: cs.CY, cs.AI, 68T01, A.1** | **Updated: 2025-07-17**

**Keywords:** 人工智能治理, AGILE指数, 国际评估, 治理框架, 政策分析指标体系, 政策建议

**Comment:** Evaluation Report. 85 pages, 30 Figures

> **TL;DR:** 本文介绍了人工智能治理国际评估指数（AGILE指数），旨在评估全球14个代表性国家的人工智能治理水平，以帮助各国识别治理阶段并改进其治理系统。

**AI_Comments:** AGILE指数的提出具有重要意义，它为量化和比较不同国家AI治理水平提供了一个结构化的框架。其创新之处在于将治理水平与发展水平相匹配的设计原则，并涵盖了多维度的评估指标。这有助于促进国际社会对AI治理的理解，并可能推动各国改进其治理策略。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能技术的快速发展带来了伦理、法律和社会问题，有效的人工智能治理已成为全球关注的焦点。特别是自2022年生成式AI广泛部署以来，国际社会持续努力应对新挑战。随着国际治理共识的建立和实施，对全球人工智能治理现状进行评估的实际重要性日益显现。

**Method:** 本文开发了人工智能治理国际评估指数（AGILE指数），遵循“治理水平应与发展水平相匹配”的设计原则。该指数首次评估涵盖了人工智能发展水平、人工智能治理环境、人工智能治理工具和人工智能治理有效性这四个基础支柱，包含18个维度下的39个指标，全面评估了全球14个代表性国家的人工智能治理水平。

**Result:** 该指数被用于深入探究首批评估的14个国家的人工智能治理现状，通过数据评分描绘了这些国家人工智能治理的当前状态。

**Conclusion:** 该研究旨在通过数据评分描绘各国人工智能治理的当前状态，协助它们识别其治理阶段并发现治理问题，最终为提升其人工智能治理系统提供见解。

> **ai_Abstract:** 本文介绍了人工智能治理国际评估指数（AGILE指数），旨在应对AI技术发展带来的治理挑战。该指数遵循“治理水平与发展水平匹配”的原则，构建了包括AI发展水平、治理环境、治理工具和治理有效性在内的四个核心支柱，涵盖18个维度和39个指标。AGILE指数已用于评估全球14个代表性国家的人工智能治理现状，旨在通过数据评分帮助各国识别其治理阶段、发现治理问题，并为提升其治理系统提供有益见解。

> **摘要翻译:** 人工智能（AI）技术的快速发展正在深刻地改变人类社会，并同时带来一系列伦理、法律和社会问题。有效的人工智能治理已成为一个至关重要的全球关注点。自2022年以来，生成式人工智能，特别是大型语言模型的广泛部署，标志着人工智能治理进入了一个新阶段。国际社会正在持续努力积极应对这些人工智能发展带来的新挑战。随着国际治理共识的不断建立和实施，对人工智能治理现状进行全球评估的实际重要性正日益凸显。在此背景下，我们启动了人工智能治理国际评估指数（AGILE指数）的开发。秉持“治理水平应与发展水平相匹配”的设计原则，AGILE指数的首次评估从四个基础支柱展开：人工智能发展水平、人工智能治理环境、人工智能治理工具和人工智能治理有效性。它涵盖了18个维度下的39个指标，全面评估了全球14个代表性国家的人工智能治理水平。该指数被用于深入探究首批评估的14个国家的人工智能治理现状。其目的是通过数据评分描绘这些国家人工智能治理的当前状态，协助它们识别其治理阶段并发现治理问题，并最终为提升其人工智能治理系统提供见解。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [459] [Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening](https://arxiv.org/abs/2507.11548)
> *公平性还不够：审计AI简历筛选中的能力与交叉偏见*

*Kevin T Webster* | **Category: cs.CY, cs.AI, cs.CL, I.2.1; K.4.2; I.2.6; K.4.1** | **Updated: 2025-07-17**

**Keywords:** AI简历筛选, 偏见, 能力审计, 中立性幻觉, 双重验证

**Comment:** 34 pages, 4 figures

> **TL;DR:** 本研究审计了AI简历筛选工具，发现除了偏见，一些看似无偏的AI实际上缺乏评估能力，仅依赖表面匹配。提出了“中立性幻觉”并建议同时审计偏见和能力。

**AI_Comments:** 这篇论文的创新之处在于提出了“中立性幻觉”这一概念，揭示了AI系统在招聘领域可能存在的深层问题，即表面上的无偏见可能掩盖了其根本能力的缺失。这超越了传统上仅关注偏见的研究，强调了AI在执行核心任务时能力的重要性。其提出的双重验证框架对于未来AI工具的开发和监管具有重要指导意义，提醒行业和监管者在追求公平性的同时，不能忽视AI的实际性能和判断能力。

<details>
  <summary>Details</summary>

**Motivation:** AI简历筛选被认为能提供无偏的替代方案，但研究质疑这些AI系统是否具备执行评估任务的根本能力。

**Method:** 本研究通过对八个主要AI平台进行两部分审计来调查能力问题。实验1验证了复杂的、情境化的种族和性别偏见。实验2评估了核心能力。

**Result:** 实验1证实了复杂的、情境化的种族和性别偏见，一些模型仅因人口统计学信号的存在而惩罚候选人。实验2提供了一个关键见解：一些看似无偏的模型实际上无法进行实质性评估，而是依赖于肤浅的关键词匹配。研究提出了“中立性幻觉”来描述这种现象。

**Conclusion:** 本研究提出了“中立性幻觉”，即表面上缺乏偏见仅仅是模型无法做出有意义判断的症状。研究建议组织和监管机构采用双重验证框架，同时审计AI招聘工具的人口统计学偏见和可证明的能力，以确保它们既公平又有效。

> **ai_Abstract:** 本研究质疑AI简历筛选工具的根本能力，指出其不仅存在偏见，还可能出现“中立性幻觉”，即一些看似公平的AI实际上缺乏实质性评估能力，仅依赖关键词匹配。通过对八个主流AI平台进行两部分审计，研究发现复杂的种族和性别偏见，并揭示了模型能力不足的问题。论文强调，公平性不足以衡量AI，建议采用双重验证框架，同时审计AI招聘工具的偏见和实际能力。

> **摘要翻译:** 生成式AI在简历筛选中日益普及，其前提是它能提供无偏的替代方案，取代有偏见的人类决策。然而，这种信念未能解决一个关键问题：这些AI系统是否根本上具备执行其预期评估任务的能力？
本研究通过对八个主要AI平台进行两部分审计来调查能力问题。实验1证实了复杂的、情境化的种族和性别偏见，一些模型仅仅因为存在人口统计学信号就惩罚候选人。实验2评估了核心能力，提供了一个关键见解：一些看似无偏的模型实际上无法进行实质性评估，而是依赖于肤浅的关键词匹配。
本文引入“中立性幻觉”来描述这种现象，即表面上缺乏偏见仅仅是模型无法做出有意义判断的症状。本研究建议组织和监管机构采用双重验证框架，同时审计AI招聘工具的人口统计学偏见和可证明的能力，以确保它们既公平又有效。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [560] [Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety](https://arxiv.org/abs/2507.13008)
> *跨越界限：如何在信任与安全领域促进跨机构的有效研究合作*

*Amanda Menking, Mona Elswah, David J. Grüning, Lasse H. Hansen, Irene Huang, Julia Kamin, Catrine Normann* | **Category: cs.CY, cs.HC, J.4; K.4.1; K.4.2** | **Updated: 2025-07-17**

**Keywords:** 信任与安全, 研究合作, 跨机构, 合作框架, 跨学科

**Comment:** 19 pages, no figures

> **TL;DR:** 本论文探讨了在日益增长的信任与安全领域中，如何构建跨学术界、工业界、政府和非政府组织的研究合作，以克服激励、时间表和约束上的不一致，并提出了一个实用的分步框架来启动和管理有效的合作。

**AI_Comments:** 这篇论文的创新之处在于其对跨机构研究合作的实际指导，特别是在新兴且复杂的信任与安全领域。它不仅识别了合作中的常见障碍（如激励不一致），还提供了一个可操作的框架来解决这些问题。强调“清晰表达”的重要性是一个深刻的见解，因为它触及了跨领域沟通的核心挑战。该研究对于任何寻求建立或改进跨部门合作的人都具有重要意义，尤其是在需要多方专业知识来应对复杂社会技术问题的领域。

<details>
  <summary>Details</summary>

**Motivation:** 随着数字空间中信任与安全领域的不断发展，在学术界、工业界、政府和非政府组织之间进行研究合作变得越来越必要，但也越来越复杂。本研究旨在解决如何构建跨机构研究伙伴关系以克服不一致的激励、时间表和限制。

**Method:** 作者基于自身跨部门合作的经验，定义了主要的机构类型，并强调了各部门在研究重点、运营压力和评估指标上的常见差异。在此基础上，提出了一套实用的、分步式的框架，用于启动和管理有效的合作，包括建立信任、统一目标和分配角色的策略。

**Result:** 本研究提出了一个实用的分步框架，用于启动和管理跨机构的有效合作，并强调了清晰表达（articulation）的关键作用。该框架包括建立信任、统一目标和分配角色的策略，旨在克服合作中的常见障碍。

**Conclusion:** 本研究认为，跨部门合作对于在信任与安全领域开展更道德、公平和有影响力的研究至关重要。最终，倡导优先考虑包容性、透明度和现实世界相关性的协作模式，以满足这一新兴领域的跨学科需求。

> **ai_Abstract:** 本论文探讨了在快速发展的信任与安全领域中，如何有效开展跨学术界、工业界、政府和非政府组织的研究合作。作者基于经验，分析了不同机构类型的研究差异，并提出了一个实用的分步框架，用于启动和管理此类合作，包括建立信任、统一目标和分配角色。研究强调了清晰表达的重要性，并指出跨部门合作对于推动更道德、公平和有影响力的研究至关重要，最终倡导采纳包容、透明且注重现实世界相关性的协作模式。

> **摘要翻译:** 随着数字空间中信任与安全领域的不断发展，在学术界、工业界、政府和非政府组织之间进行研究合作变得越来越必要，但也越来越复杂。本论文探讨了如何构建跨机构研究伙伴关系，以克服激励、时间表和约束上的不一致，同时发挥每个利益相关者的独特优势。我们借鉴自身跨部门合作的经验，定义了主要的机构类型，并强调了各部门在研究重点、运营压力和评估指标上的常见差异。然后，我们提出了一个实用的、分步式的框架，用于启动和管理有效的合作，包括建立信任、统一目标和分配角色的策略。我们强调了清晰表达（articulation）的关键但往往无形的工作，并认为跨部门伙伴关系对于在信任与安全领域开展更道德、公平和有影响力的研究至关重要。最终，我们倡导优先考虑包容性、透明度和现实世界相关性的协作模式，以满足这一新兴领域的跨学科需求。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [350] [Vector-level Feedforward Control of LPBF Melt Pool Area Using a Physics-Based Thermal Model](https://arxiv.org/abs/2507.12557)
> *基于物理热模型的LPBF熔池面积矢量级前馈控制*

*Nicholas Kirschbaum, Nathaniel Wood, Chang-Eun Kim, Thejaswi U. Tumkur, Chinedum Okwudire* | **Category: cs.CE, physics.app-ph** | **Updated: 2025-07-16**

**Keywords:** LPBF, 前馈控制, 熔池, 热模型, 增材制造

**Comment:** 43 pages, 15 figures

> **TL;DR:** 本文提出了一种 novel 矢量级前馈控制框架，用于调节LPBF中的熔池面积，通过解耦部件级热行为和小型熔池物理，显著改善了零件质量，减少了几何误差和孔隙率。

**AI_Comments:** 本文的创新点在于提出了一个解耦部件级热行为和熔池物理的矢量级前馈控制框架，并结合了两种轻量级模型。其重要性在于通过主动补偿热效应，显著提高了LPBF零件的质量，同时保持了计算效率和可扩展性，为增材制造过程控制提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 激光粉末床熔融 (LPBF) 制造的零件容易出现内部缺陷和几何不准确性，部分原因在于熔池的变化。

**Method:** 本文提出了一种新颖的矢量级前馈控制框架来调节LPBF中的熔池面积。该控制器通过解耦部件级热行为和小尺度熔池物理，提供与尺度无关的熔池面积预测并进行高效优化。它在两个耦合的轻量级模型上运行：一个有效捕获矢量级温度场的有限差分热模型和一个降阶分析熔池模型。每个模型都通过最少的单道和二维实验单独校准。

**Result:** 前馈矢量级激光功率调度使关键尺寸的几何不准确性平均降低了62%，总孔隙率平均降低了16.5%，光电二极管变异性平均降低了6.8%。

**Conclusion:** 这种模块化、数据高效的方法表明，主动补偿已知热效应可以显著改善零件质量，同时保持计算效率高，并且易于扩展到其他材料和机器。

> **ai_Abstract:** 本文提出了一种用于激光粉末床熔融 (LPBF) 的矢量级前馈控制框架，旨在解决熔池变化导致的零件缺陷和几何不准确性问题。该框架利用一个有限差分热模型和一个简化的分析熔池模型，实现对熔池面积的预测和优化。通过在两种材料的复杂3D几何体上验证，结果表明该方法显著降低了几何不准确性、总孔隙率和光电二极管变异性，证明了其在提高零件质量方面的有效性、计算效率和可扩展性。

> **摘要翻译:** 激光粉末床熔融 (LPBF) 是一种增材制造技术，因其能够生产几何复杂、完全致密的金属零件而受到欢迎。然而，这些零件容易出现内部缺陷和几何不准确性，部分原因在于熔池的变化。本文提出了一种新颖的矢量级前馈控制框架，用于调节LPBF中的熔池面积。通过解耦部件级热行为和小尺度熔池物理，该控制器提供了与尺度无关的熔池面积预测并对其进行高效优化。这是通过在两个耦合的轻量级模型上运行来实现的：一个有效捕获矢量级温度场的有限差分热模型和一个降阶分析熔池模型。每个模型都通过最少的单道和二维实验单独校准，并且该框架在Inconel 718和316L不锈钢的复杂3D几何体上进行了验证。结果显示，前馈矢量级激光功率调度使关键尺寸的几何不准确性平均降低了62%，总孔隙率平均降低了16.5%，光电二极管变异性平均降低了6.8%。总体而言，这种模块化、数据高效的方法表明，主动补偿已知热效应可以显著改善零件质量，同时保持计算效率高，并且易于扩展到其他材料和机器。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [395] [IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion](https://arxiv.org/abs/2507.12745)
> *IDS-Net：一种用于少样本光伏功率预测的新颖框架，具有可解释的动态选择和特征信息融合*

*Hang Fan, Weican Liu, Zuhan Zhang, Ying Lu, Wencai Run, Dunnan Liu* | **Category: cs.CE** | **Updated: 2025-07-17**

**Keywords:** 光伏功率预测, 少样本学习, 迁移学习, 可解释动态选择, 特征融合

**Comment:** 

> **TL;DR:** IDS-Net是一个新的框架，通过可解释的动态选择和特征信息融合，实现了少样本光伏功率的准确预测。

**AI_Comments:** 该论文通过提出IDS-Net，一个结合了可解释动态选择和特征信息融合的迁移学习框架，创新性地解决了光伏功率预测领域中普遍存在的少样本数据挑战。其两阶段方法，特别是第一阶段中对源域选择、特征选择和异常值校正的精细处理，以及IDS-Net内部的动态权重分配和特征融合机制，增强了模型的预测精度和可解释性。这项工作对于提高可再生能源预测的可靠性具有重要意义，尤其是在数据稀缺的新建电站场景中。

<details>
  <summary>Details</summary>

**Motivation:** 随着可再生能源需求的增长，各国正在加速建设光伏电站。然而，由于数据可用性有限，准确预测新建光伏电站的功率数据极具挑战性（少样本预测问题）。

**Method:** 本文提出了一种基于特征信息融合的可解释动态选择网络（IDS-Net），这是一个两阶段的迁移学习框架。第一阶段在大数据集上进行预训练，利用最大平均差异（MMD）选择与目标域数据分布最相似的源域数据集，使用ReliefF算法进行特征选择，并利用Hampel Identifier（HI）进行训练数据集异常值校正。在IDS-Net模型中，首先从预测模型池中获取初始提取特征，然后利用两个独立的加权通道分别确定每个子模型的可解释权重和自适应选择结果。接着，将每个子模型提取的特征结果与其对应的权重相乘并求和，以获得加权提取特征。然后，对附加特征进行交叉嵌入，并将其与提取的加权特征融合，融合后的信息通过MLP层获得预测。第二阶段设计了一种端到端的自适应迁移学习策略，以获得目标数据集上的最终预测结果。

**Result:** 该框架和迁移学习策略通过使用来自中国河北省的两个光伏功率数据集进行了验证，证明了其有效性和泛化能力。

**Conclusion:** 本文提出的IDS-Net框架，结合了可解释的动态选择和特征信息融合，通过一种新颖的迁移学习策略，有效解决了少样本光伏功率预测的挑战，并展现了其有效性和泛化能力。

> **ai_Abstract:** 本文提出了一种名为IDS-Net的新型迁移学习框架，旨在解决新建光伏电站因数据有限而导致的少样本功率预测难题。该框架分为两个阶段：第一阶段在大数据集上进行预训练，利用MMD选择相似源域、ReliefF进行特征选择和HI进行异常值校正。在IDS-Net模型内部，通过可解释的加权通道动态选择并融合来自模型池的特征，并与交叉嵌入的附加特征融合。第二阶段则采用端到端的自适应迁移学习策略，以在目标数据集上获得最终预测。在河北省的两个光伏数据集上的验证表明，该框架在少样本场景下具有良好的有效性和泛化能力。

> **摘要翻译:** 随着可再生能源需求的增长，各国正在加速建设光伏电站。然而，由于数据可用性有限，准确预测新建光伏电站的功率数据极具挑战性。为此，我们提出了一种基于特征信息融合的新型可解释动态选择网络（IDS-Net），以实现准确的少样本预测。这个迁移学习框架主要由两部分组成。在第一阶段，我们在大型数据集上进行预训练，利用最大平均差异（MMD）选择与目标域数据分布最相似的源域数据集。随后，利用ReliefF算法进行特征选择，减少特征冗余的影响。然后，使用Hampel Identifier（HI）对训练数据集异常值进行校正。在IDS-Net模型中，我们首先从预测模型池中获取初始提取特征。在此之后，利用两个独立的加权通道分别确定每个子模型的可解释权重和自适应选择结果。随后，将每个子模型提取的特征结果与其对应的权重相乘并求和，以获得加权提取特征。然后，我们对附加特征进行交叉嵌入，并将其与提取的加权特征融合。然后，将此融合信息通过MLP（多层感知机）层以获得预测。在第二阶段，我们设计了一种端到端的自适应迁移学习策略，以获得目标数据集上的最终预测结果。我们使用来自中国河北省的两个光伏功率数据集验证了迁移学习过程，以证明我们框架和迁移学习策略的有效性和泛化能力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [430] [Quantum-Enhanced Reinforcement Learning with LSTM Forecasting Signals for Optimizing Fintech Trading Decisions](https://arxiv.org/abs/2507.12835)
> *量子增强强化学习结合LSTM预测信号优化金融科技交易决策*

*Yen-Ku Liu, Yun-Huei Pan, Pei-Fan Lu, Yun-Cheng Tsai, Samuel Yen-Chi Chen* | **Category: cs.CE** | **Updated: 2025-07-17**

**Keywords:** 量子强化学习, 金融科技, 交易决策, LSTM, A3C

**Comment:** 

> **TL;DR:** 本研究将量子电路与强化学习结合，并引入LSTM预测信号，以优化金融交易决策，实验证明量子模型在金融市场中表现更优。

**AI_Comments:** 本文的创新点在于将量子计算引入金融强化学习领域，探索了量子算法在复杂金融环境下的潜力。结合LSTM进行预测进一步增强了模型的实用性。该研究为金融科技领域的智能交易提供了新的思路，但其在实际部署中的计算资源需求和量子硬件的成熟度仍需进一步考量。

<details>
  <summary>Details</summary>

**Motivation:** 传统强化学习方法在波动性高、信号多变、市场机制动态变化的金融交易环境中难以取得突破性表现。

**Method:** 设计了一个集成量子电路的强化学习框架，并比较了经典A3C与量子A3C算法的性能；同时，评估了结合LSTM预测未来一周经济趋势对学习效果的影响。实验采用自定义的Gymnasium兼容交易环境进行模拟。

**Result:** 实验结果表明，量子模型，特别是在结合了预测信号时，即使在浅层量子电路深度下，也能在嘈杂的金融条件下表现出卓越的性能和稳定性。

**Conclusion:** 量子增强的强化学习模型，特别是结合LSTM预测信号后，能有效提升金融交易决策的性能和稳定性。

> **ai_Abstract:** 本文针对金融交易环境的高波动性和复杂性，提出了一种结合量子电路的强化学习框架来优化交易决策。研究对比了经典A3C与量子A3C算法的性能，并探讨了整合LSTM预测信号对学习效果的影响。实验结果显示，量子模型，尤其是在结合了预测信号后，在嘈杂的金融市场中展现出更优越的性能和稳定性。

> **摘要翻译:** 金融交易环境具有高波动性、众多宏观经济信号和动态变化的市场机制等特点，传统强化学习方法往往难以取得突破性表现。在本研究中，我们通过集成量子电路，设计了一个专为金融系统量身定制的强化学习框架。我们比较了（1）经典A3C与量子A3C算法的性能，以及（2）结合基于LSTM的下一周经济趋势预测对学习结果的影响。实验框架采用自定义的Gymnasium兼容交易环境，模拟离散交易行为并根据投资组合反馈评估回报。实验结果表明，量子模型——特别是当与预测信号结合时——即使在浅层量子电路深度下，也能在嘈杂的金融条件下表现出卓越的性能和稳定性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [465] [Agentar-DeepFinance-300K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization](https://arxiv.org/abs/2507.12901)
> *Agentar-DeepFinance-300K：通过系统化思维链合成优化构建的大规模金融数据集*

*Xiaoke Zhao, Zhaowen Zhou, Lin Chen, Lihong Wang, Zhiyi Huang, Kaiyuan Zheng, Yanjun Zheng, Xiyang Du, Longfei Liao, Jiawei Liu, Xiang Qi, Bo Zhang, Peng Zhang, Zhe Li, Wei Wang* | **Category: cs.CE** | **Updated: 2025-07-17**

**Keywords:** 金融推理, 大型语言模型, 思维链, 数据集, 合成优化

**Comment:** 

> **TL;DR:** 本文提出了Agentar-DeepFinance-300K，一个通过系统化思维链合成优化构建的大规模金融推理数据集，并在金融基准测试上取得了显著改进。

**AI_Comments:** 本文通过提供一个高质量、大规模且经过系统化思维链优化的数据集，解决了金融人工智能领域的一个关键空白，这对于稳健的金融推理至关重要。多视角知识提取（MKE）和自我纠正重写（SCR）的流程是一种创新方法，能够生成深入且详尽的推理路径。“CoT Cube”分析为CoT的有效性提供了宝贵的见解，超越了单纯的数据量。数据集的公开发布是对社区的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有思维链（CoT）合成方法存在浅层CoT采样问题，且金融推理知识空间的构建方式尚未被充分探索。尽管大型语言模型（LLMs）在金融领域有巨大潜力，但需要更强大可靠的推理能力。

**Method:** 提出了Agentar-DeepFinance-300K大规模金融推理数据集。设计了包含多视角知识提取（MKE）和自我纠正重写（SCR）的CoT合成流程，以生成详尽深入的金融推理轨迹。同时，通过“CoT Cube”系统研究了影响CoT有效性的关键因素，如必要性、长度和合成器。

**Result:** 在Agentar-DeepFinance-300K上训练的模型在金融基准测试中取得了显著改进。

**Conclusion:** 本文贡献了一个通过系统化优化构建的大规模金融推理数据集Agentar-DeepFinance-300K，并将其公开发布，旨在推动金融推理模型的研究进展。

> **ai_Abstract:** 本文提出了Agentar-DeepFinance-300K，一个大规模金融推理数据集，旨在解决现有方法中思维链（CoT）采样深度不足的问题。该数据集通过新颖的CoT合成流程（包括多视角知识提取和自我纠正重写）生成深入的推理轨迹，并通过“CoT Cube”分析来优化CoT构建。实验证明，在此数据集上训练的模型在金融基准测试中表现显著提升。该数据集已公开发布，以促进金融推理模型领域的研究。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展展示了卓越的通用推理能力，这在需要强大可靠推理的金融领域具有重要应用潜力。事实证明，从先进的通用推理模型中提炼高质量的思维链（CoT）推理过程，为构建金融推理模型提供了一条有前景且高效的途径。然而，现有的CoT合成方法存在CoT采样深度不足的问题，导致如何构建一个设计良好的金融推理知识空间的问题仍未被探索。在本文中，我们提出了Agentar-DeepFinance-300K，这是一个以系统化CoT合成优化为特征的大规模金融推理数据集。我们首先引入了一个全面的CoT合成流程，该流程包含多视角知识提取（MKE）和自我纠正重写（SCR），以生成详尽深入的金融推理轨迹。此外，还进行了一项名为CoT Cube的系统性研究，旨在分析影响CoT有效性的关键因素，如必要性、长度和合成器，为高质量金融CoT的构建提供了宝贵见解。实验表明，在我们的Agentar-DeepFinance-300K数据集上训练的模型在金融基准测试上取得了显著改进。我们公开发布Agentar-DeepFinance-300K，希望能推动金融推理模型的研究。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [507] [To What Extent Can Public Equity Indices Statistically Hedge Real Purchasing Power Loss in Compounded Structural Emerging-Market Crises? An Explainable ML-Based Assessment](https://arxiv.org/abs/2507.13055)
> *公共股票指数在复合结构性新兴市场危机中能在多大程度上对冲实际购买力损失？一项基于可解释机器学习的评估*

*Artem Alkhamov, Boris Kriuk* | **Category: cs.CE** | **Updated: 2025-07-17**

**Keywords:** 新兴市场危机, 购买力对冲, 公共股票指数, 可解释机器学习, 尾部依赖

**Comment:** 8 pages, 3 figures, 1 table

> **TL;DR:** 研究发现，在复合宏观金融危机中，公共股票指数在保护购买力方面系统性失效，挑战了传统的通胀和贬值对冲假设。

**AI_Comments:** 该研究通过引入可解释机器学习（SHAP）和尾部依赖分析，为评估新兴市场危机中股权对冲购买力损失的能力提供了新颖且深入的视角。其创新之处在于结合了多种高级统计和机器学习方法，并聚焦于危机期间的极端情况。研究结果对传统的股权定价理论提出了重要挑战，强调了在特殊市场环境下对冲策略的局限性，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在调查在新兴市场复合结构性宏观金融崩溃期间，当地公共股票指数能在多大程度上统计对冲实际购买力损失。

**Method:** 采用非线性乘法实际回报计算（符合费雪平价逻辑），结合分位数回归、尾部依赖copula分析和Shapley可加解释（SHAP）评估宏观变量的解释力。分析聚焦于土耳其（2018）、尼日利亚（2020）和巴基斯坦（2021）的危机事件。

**Result:** 尾部建模显示，在同时发生宏观经济和货币错位时（即最需要保护时），基于公共股票的购买力保护系统性失效。

**Conclusion:** 研究结果质疑了股权定价理论中传统的通胀和贬值对冲假设，强调了基于股权保护的局限性以及在复合宏观金融困境中采取情境敏感策略的必要性。

> **ai_Abstract:** 本研究评估了新兴市场复合宏观金融危机中公共股票指数对冲实际购买力损失的能力。通过对土耳其、尼日利亚和巴基斯坦的案例研究，并采用非线性回报计算、分位数回归、copula分析和SHAP等方法，研究发现当宏观经济和货币出现错位时，公共股票无法有效提供购买力保护，挑战了传统股权对冲通胀和贬值的观念。

> **摘要翻译:** 本研究调查了在新兴市场复合结构性宏观金融崩溃期间，当地公共股票指数能在多大程度上统计对冲实际购买力损失。我们采用符合费雪平价逻辑的非线性乘法实际回报计算，并结合原则性分位数回归、尾部依赖copula分析和Shapley可加解释（SHAP）来评估宏观变量的解释力。分析重点关注了近期三个可获取数据的典型崩溃事件：土耳其（2018年）、尼日利亚（2020年）和巴基斯坦（2021年）。选择这些案例是为了符合2018年后数据标准化和危机可比性的改进，它们涵盖了不同的货币制度和危机触发因素。我们的尾部建模揭示，正是在宏观经济和货币同时出现错位时（即最需要此类保护时），基于公共股权的购买力保护会系统性失效。研究结果质疑了股权定价理论中传统的通胀和贬值对冲假设，强调了基于股权保护的局限性以及在复合宏观金融困境中采取情境敏感策略的必要性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [530] [Model-free Forecasting of Rogue Waves using Reservoir Computing](https://arxiv.org/abs/2506.21918)
> *基于储层计算的无模型疯狗浪预测*

*Abrari Noor Hasmi, Hadi Susanto* | **Category: cs.CE, nlin.PS** | **Updated: 2025-07-17**

**Keywords:** 储层计算, 疯狗浪, 哈密顿系统, 非线性薛定谔方程, 回声状态网络

**Comment:** 25 pages 14 figures. Proof-ready version

> **TL;DR:** 本文利用储层计算（Reservoir Computing）预测由非线性薛定谔方程描述的疯狗浪，展示了良好的短期预测能力，并通过引入新方法显著提升了长期预测能力。

**AI_Comments:** 本文将储层计算应用于一个具有挑战性的领域（哈密顿系统，特别是疯狗浪），这是一个较少被探索的领域，具有创新性。其创新之处在于使RC适用于复杂时空动力学的长期预测，并引入了一种提高自主模式性能的方法。强调训练数据相空间覆盖的重要性为该领域的未来研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 储层计算已显示出对混沌动力系统的建模能力，但其在哈密顿系统，特别是像非线性薛定谔方程描述的疯狗浪动力学这类具有挑战性的系统中的应用仍未被充分探索。

**Method:** 本文采用无模型方法，利用经过适当调整的并行回声状态网络（Echo State Network）。该模型从具有五个不稳定模式的呼吸子模拟中学习，并在两个不同的测试数据集上进行测试（一个是训练数据的延续，另一个是更高阶的呼吸子）。此外，引入了一种显著改善自主模式下储层计算预测能力的方法。

**Result:** 一步预测能力显示出显著的一致性。经过训练的储层能够预测疯狗浪在相对较长预测范围内的传播，即使面对未见的动力学。引入的方法显著改善了自主模式下的储层计算预测，增强了其长期预测能力。

**Conclusion:** 研究结果推进了储层计算在时空哈密顿系统中的应用，并强调了训练数据设计中相空间覆盖的关键重要性。

> **ai_Abstract:** 本文探讨了储层计算在疯狗浪无模型预测中的应用，疯狗浪是一种由非线性薛定谔方程描述的复杂哈密顿系统。通过在呼吸子模拟上训练并行回声状态网络，作者展示了其卓越的单步预测精度以及在较长预测范围内预测疯狗浪传播的能力，即使面对未见的动力学。此外，本文引入了一种新方法，以增强储层计算在自主模式下的长期预测能力，并强调了相空间覆盖在时空哈密顿系统训练数据设计中的重要性。

> **摘要翻译:** 最近的研究表明，储层计算（Reservoir Computing）能够对各种混沌动力系统进行建模，但其在哈密顿系统中的应用仍相对未被充分探索。本文研究了储层计算在从非线性薛定谔方程（一个具有调制不稳定性的挑战性哈密顿系统）中捕获疯狗浪动力学方面的有效性。这种无模型方法从具有五个不稳定模式的呼吸子模拟中学习。一个经过适当调整的并行回声状态网络（Echo State Network）可以预测来自两个不同测试数据集的动力学。第一个数据集是训练数据的延续，而第二个数据集涉及更高阶的呼吸子。对一步预测能力的研究表明，测试数据与模型之间存在显著的一致性。此外，我们表明，尽管面临未见的动力学，经过训练的储层仍能在相对较长的预测范围内预测疯狗浪的传播。最后，我们引入了一种显著改善储层计算在自主模式下预测的方法，增强了其长期预测能力。这些结果推进了储层计算在时空哈密顿系统中的应用，并强调了训练数据中相空间覆盖的关键重要性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [652] [Fined-Grained Complexity of Ambiguity Problems on Automata and Directed Graphs](https://arxiv.org/abs/2501.14725)
> *自动机和有向图上歧义问题的细粒度复杂度*

*Karolina Drabik, Anita Dürr, Fabian Frei, Filip Mazowiecki, Karol Węgrzycki* | **Category: cs.FL** | **Updated: 2025-07-17**

**Keywords:** 自动机, 歧义性, 细粒度复杂性, 一元自动机, 孪生性质

**Comment:** 

> **TL;DR:** 本研究在细粒度复杂性假设下，证明了自动机歧义性问题的决策时间下界，并为一元自动机和加权自动机的孪生性质问题提供了改进的算法。

**AI_Comments:** 该论文的创新之处在于其对自动机歧义性问题计算复杂度的严格分析，特别是在细粒度复杂性理论框架下提供了匹配的下界，从而确立了现有算法的最优性。此外，针对一元自动机这一特殊且重要的类别，作者提出了显著改进的算法，将复杂度从多项式时间降低到接近线性或线性时间，这对于实际应用具有重要意义。对加权自动机孪生性质的研究也补充了相关理论。

<details>
  <summary>Details</summary>

**Motivation:** 现有的确定自动机歧义性（无歧义、有限歧义和多项式歧义）问题的算法运行时已知，但其最优性尚未完全证明。此外，对于一元自动机等特定情况，可能存在更高效的算法。

**Method:** 本研究通过引入匹配的下界来证明现有算法运行时间的最佳性，这些下界基于流行的细粒度复杂性假设。对于一元自动机，通过将问题转化为有向图问题，并利用GCD矩阵的1-范数界限来改进无歧义性的上界，并提出有限和多项式歧义性的线性时间算法。此外，研究了加权自动机上的孪生性质，并分析了其算法的最优性。

**Result:** 在细粒度复杂性假设下，证明了无歧义性和多项式歧义性决策的二次时间以及有限歧义性决策的三次时间是最佳的。对于一元自动机，无歧义性问题获得了接近线性的上界，有限和多项式歧义性问题获得了简单的线性时间算法。对于加权自动机上的孪生性质，证明了Allauzen和Mohri的二次时间算法在相同细粒度假设下是最佳的，并且对于一元自动机，给出了一个线性时间算法。

**Conclusion:** 本研究在流行的细粒度复杂性假设下，确定了自动机歧义性决策问题的运行时间下界，证实了现有算法的最优性。同时，为一元自动机上的歧义性问题和加权自动机上的孪生性质问题提供了更高效的算法，特别是在一元情况下实现了显著的性能提升。

> **ai_Abstract:** 本研究深入探讨了有限自动机歧义性问题的细粒度复杂性。作者在流行的细粒度复杂性假设下，确立了无歧义、有限歧义和多项式歧义自动机决策问题的匹配下界，证明了现有二次和三次时间算法的最优性。此外，文章显著改进了一元自动机上这些问题的上界，为无歧义性提供了接近线性的算法，并为有限和多项式歧义性提供了线性时间算法。论文还考察了热带半环上加权自动机的孪生性质，证明了现有二次时间算法的最优性，并为一元加权自动机上的孪生性质问题提出了线性时间解决方案，通过将其转化为加权有向图中循环平均权重相等的问题。

> **摘要翻译:** 两种基本的有限自动机是确定性自动机和非确定性自动机（DFA和NFA）。通过限制NFA允许的歧义性（即每个单词的接受运行次数），产生了自然的中间类别：无歧义、有限歧义和多项式歧义有限自动机。已知，判断给定NFA是否为无歧义和是否为多项式歧义可以在二次时间内完成，判断有限歧义可以在三次时间内完成。我们提供了匹配的下界，表明这些运行时间是最佳的，这假设了流行的细粒度复杂性假设。
我们改进了一元自动机的上界，一元自动机本质上是带有源点和目标点的有向图。在这种观点下，无歧义性问题是询问从源点到目标点的所有路径是否具有不同的长度。我们算法的运行时间分析归结为限制GCD矩阵的逐项1-范数，从而得到了接近线性的上界。对于有限歧义和多项式歧义，我们在一元情况下提供了简单的线性时间算法。
最后，我们研究了热带半环上加权自动机的孪生性质，该性质表征了无歧义加权自动机的确定性。它在我们的上下文中自然出现，因为确定孪生性质是具有有界歧义的加权自动机确定性算法中的中间步骤。我们表明，Allauzen和Mohri的检查孪生性质的二次时间算法在与无歧义性相同的细粒度假设下是最佳的。对于一元自动机，我们表明该问题可以重新表述为加权有向图中所有循环是否具有相同的平均权重，并给出了一个线性时间算法。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [676] [Syntax Repair as Language Intersection](https://arxiv.org/abs/2507.11873)
> *语法修复即语言交集*

*Breandan Considine* | **Category: cs.FL, cs.PL** | **Updated: 2025-07-17**

**Keywords:** 语法修复, 语言交集, 上下文无关语言, CFL可达性, Brzozowski导数

**Comment:** 

> **TL;DR:** 该研究提出了一种将语法修复建模为语言交集问题的新技术，并展示了其在Python语法修复基准测试上达到了最先进的水平。

**AI_Comments:** 该论文的创新之处在于将语法修复问题巧妙地转化为语言交集问题，并利用了形式语言理论和程序分析的交叉知识。这种方法不仅提供了理论上的可判定性证明，还通过实验验证了其在实际应用中的高效性和先进性，为语法错误修复领域提供了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 修复任意上下文无关语言中的语法错误。

**Method:** 该技术将语法修复建模为语言交集问题，通过定义一个有限语言来生成给定编辑距离内的所有语法有效修复。利用形式语言理论中的Bar-Hillel构造与程序分析中的CFL可达性之间的理论联系，证明了在有限排版编辑次数内的可修复性是多对数并行时间可判定的，并提供了一个基于Brzozowski导数的枚举算法。

**Result:** 在有限数量的排版编辑下，可修复性是多对数并行时间可判定的。在Python语法修复基准测试上展示了最先进的结果。

**Conclusion:** 该论文提出了一种将语法修复建模为语言交集的新技术，该技术基于形式语言理论和程序分析的联系，实现了高效的语法错误修复，并在实验中取得了优异表现。

> **ai_Abstract:** 该论文提出了一种将语法修复视为语言交集问题的新颖技术，适用于任意上下文无关语言。通过定义一个有限语言来生成所有有效修复，并结合形式语言理论的Bar-Hillel构造和程序分析的CFL可达性，证明了在有限编辑距离内的可修复性具有多对数并行时间可判定性。该研究还提供了一个基于Brzozowski导数的枚举算法，并在Python语法修复基准测试上取得了最先进的性能。

> **摘要翻译:** 我们引入了一种修复任意上下文无关语言中语法错误的新技术。该技术将语法修复建模为语言交集问题，通过定义一个有限语言，该语言可以证明生成给定编辑距离内的所有语法有效修复。利用形式语言理论中的Bar-Hillel构造与程序分析中的CFL可达性之间的理论联系，我们证明了在有限数量的排版编辑下的可修复性是多对数并行时间可判定的，并提供了一个基于Brzozowski导数的枚举算法。最后，我们评估了该算法及其实现，展示了在Python语法修复基准测试上达到最先进的结果。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [13] [Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands](https://arxiv.org/abs/2507.12830)
> *具有优先需求的地理分布式存储中的延迟最优文件分配*

*Srivathsa Acharya, P. Vijay Kumar, Viveck R. Cadambe* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 地理分布式存储, 文件分配, 延迟优化, 非均匀需求, 顶点着色

**Comment:** arXiv admin note: text overlap with arXiv:2405.06641

> **TL;DR:** 本文研究在地理分布式存储中，针对非均匀文件需求概率，通过将最差延迟建模为顶点着色问题并将平均延迟优化转换为平衡分配问题，实现延迟最优的文件分配，其在未编码方案中是最佳的。

**AI_Comments:** 本文的创新之处在于解决了地理分布式存储中非均匀文件需求下的延迟优化问题，这比传统假设更贴近现实。通过将复杂问题分解为顶点着色和平衡分配两个子问题，并利用图论和优化方法进行求解，展现了较强的理论深度。该方法在未编码方案中实现了最优性，为实际系统设计提供了理论指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有地理分布式存储系统在文件访问时存在延迟问题，尤其是在文件未本地存储时。先前的研究仅考虑了文件需求概率均等的情况，而现实中文件需求往往是非均匀的，这导致了需要研究更通用的非均匀文件需求情况下的延迟优化问题。

**Method:** 本文提出了一种在未编码方案族内最优的文件分配方案。它首先将最差情况下的延迟约束建模为一个顶点着色问题，然后将系统平均延迟优化问题转换为一个平衡分配问题。

**Result:** 提出的方案在未编码方案族内是延迟最优的。

**Conclusion:** 本文成功地为具有非均匀文件需求概率的地理分布式存储网络中的文件分配问题提供了一个延迟最优的解决方案，该方案在未编码设置下表现出最优性，并通过图论和优化方法解决了复杂约束。

> **ai_Abstract:** 本文研究了地理分布式存储网络中的文件分配问题，旨在最小化每个节点的最差情况延迟和系统平均延迟。与以往研究假设文件需求概率均等不同，本文关注更通用的非均匀文件需求情况。作者提出了一种在未编码方案中实现延迟最优的方案，该方案通过将最差情况延迟约束建模为顶点着色问题，并将系统平均延迟优化转换为平衡分配问题来解决。

> **摘要翻译:** 我们考虑在服务器（或节点）的地理分布式网络中进行数据存储的问题，其中节点间的通信会产生一定的往返延迟。每个节点服务一组用户，这些用户可以请求网络中的任何文件。如果请求的文件在节点上不可用，它会与其他节点通信以获取文件，从而导致用户在获取文件时遇到延迟。文件可以以未编码的方式放置，即每个节点存储文件的精确副本；也可以以编码的方式放置，即每个节点放置文件的某些线性组合。我们旨在获得关于最小化每个节点的最差情况延迟以及系统平均延迟的最优文件放置。先前的文献考虑了节点处文件需求概率均等的情况。在本文中，我们研究了每个节点处文件需求概率非均匀的通用情况。这里提出的方案在未编码方案族内是最佳的。它首先通过将最差情况延迟约束建模为顶点着色问题，然后将系统平均延迟优化转换为平衡分配问题来获得。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [34] [Predictive & Trust-based Multi-Agent Coordination](https://arxiv.org/abs/2507.09997)
> *基于预测和信任的多智能体协同*

*Venkatraman Renganathan, Sabyasachi Mondal, Antonios Tsourdos* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-17**

**Keywords:** 多智能体协同, 预测, 信任, 共识协议, 滚动视界

**Comment:** Need more simulation results to be done

> **TL;DR:** 本文提出了一种基于信任的预测性多智能体共识协议（ADC），通过分析邻居的预期数据进行协同决策，并利用共享的预测数据学习邻居的信任和承诺特性，并通过Lyapunov理论和数值模拟证明其收敛性。

**AI_Comments:** 该论文的创新点在于将预测机制与信任机制相结合，应用于多智能体协同领域，提出了ADC协议。通过考虑邻居的预期数据和其表现出的信任与承诺特性，有望提高多智能体系统的协同效率和鲁棒性。Lyapunov理论的应用为协议的稳定性提供了理论保障。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种新的多智能体共识协议，能够通过分析邻居的预期数据并结合信任机制来进行有效的协同决策。

**Method:** 本文提出了一种名为预期分布式协同（Anticipatory Distributed Coordination, ADC）的协议。该协议允许网络中的智能体与其邻居共享未来预测数据，并以滚动视界的方式更新预测。智能体利用这些预测数据学习邻居随时间表现出的信任和承诺特性。协议的收敛性通过Lyapunov理论进行分析，并通过数值模拟进行验证。

**Result:** 协议通过Lyapunov理论证明了智能体之间的共识收敛性，并通过数值模拟进行了演示。

**Conclusion:** 本文提出的基于信任的预测性多智能体共识协议（ADC）能够有效地实现智能体间的协同，并通过分析邻居的预期数据和学习信任与承诺特性来增强决策能力。

> **ai_Abstract:** 本文介绍了一种名为预期分布式协同（ADC）的基于信任的预测性多智能体共识协议。该协议允许智能体共享并更新未来预测数据，并利用这些数据学习邻居的信任和承诺特性，从而实现有效的协同决策。文章通过Lyapunov理论证明了协议的收敛性，并用数值模拟进行了验证。

> **摘要翻译:** 本文提出了一种基于信任的预测性多智能体共识协议，该协议分析邻居的预期数据并做出协同决策。网络中的智能体在有限的预测范围内与邻居共享其未来预测数据，并以滚动视界的方式更新其预测。然后，智能体利用这些预测数据学习其邻居随时间表现出的信任和承诺特性。所提出的协议被命名为预期分布式协同（ADC）协议。论文提供了基于Lyapunov理论的智能体间一致性收敛证明，随后通过数值模拟进行了演示。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [43] [Guaranteeing and Explaining Stability across Heterogeneous Load Balancing using Calculus Network Dynamics](https://arxiv.org/abs/2507.12892)
> *使用微积分网络动力学保证和解释异构负载均衡的稳定性*

*Mengbang Zou, Yun Tang, Adolfo Perrusquía, Weisi Guo* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 负载均衡, 网络动力学, 稳定性, 微积分, 异构网络

**Comment:** 

> **TL;DR:** 当前的数据驱动负载均衡存在振荡和稳定性保证不足的问题。本文提出了一种微积分动力学框架，用于解释这些振荡并为任何网络拓扑下的异构负载均衡提供稳定性保证。

**AI_Comments:** 该论文引入了一种新颖的理论框架，利用微积分网络动力学来解决电信领域中的实际问题：负载均衡的稳定性和振荡。其创新之处在于超越了纯粹的数据驱动方法，通过引入数学框架（微积分动力学、特征值谱）来解释和保证网络行为。这为设计更健壮、更高效的负载均衡算法提供了更深层次的理解和原则性方法，对于大规模、异构网络至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 目前的基站间负载均衡机制在大量基站中会导致负载演化出现振荡效应，引发高基站间消息传递。现有数据驱动算法缺乏整合网络拓扑的微积分函数，无法解释负载状态振荡现象，也无法为理想同步状态的稳定性提供理论保证。此外，当前缺乏一个理论框架来证明负载状态振荡与负载均衡算法和拓扑结构的耦合关系，也没有改进算法的途径。

**Method:** 将通用和异构的数据驱动算法抽象到“微积分动力学空间”中。通过结合“非保守误差”和网络化动力学的“特征值谱”，为任何网络拓扑下的网络化负载均衡动力学建立同步条件。

**Result:** 能够调整基站间负载均衡机制，以实现高效率和收敛保证。在无法满足同步条件时，可以减轻振荡。

**Conclusion:** 本文提出了一种使用微积分网络动力学的理论框架，用于解释负载振荡并保证异构负载均衡的稳定性，从而提高了效率和收敛性。

> **ai_Abstract:** 本文旨在解决当前数据驱动负载均衡机制的局限性，这些机制因缺乏整合网络拓扑的微积分函数而导致负载演化振荡并缺乏稳定性理论保证。为克服此问题，作者提出将异构数据驱动算法抽象到微积分动力学空间中。通过引入“非保守误差”和特征值谱，该框架为网络化负载均衡建立了同步条件。这使得能够调整基站间负载均衡机制，以实现高效率、收敛保证并减轻振荡，从而为改进负载均衡算法提供了理论基础。

> **摘要翻译:** 基站（BSs）之间的负载均衡可以有效地利用基站容量并避免中断。目前，数据驱动的机制致力于平衡基站间负载并减少不必要的切换。挑战在于，在大量基站中，网络会观察到负载演化中的振荡效应，这会导致高基站间消息传递。如果没有一个整合网络拓扑来描述负载状态演化的微积分函数，当前的数据驱动算法无法解释观察到的负载状态振荡现象，也无法为理想同步状态的稳定性提供理论保证。虽然我们知道负载状态振荡与负载均衡过程算法以及基站间边界关系的拓扑结构相关联，但我们没有一个理论框架来证明这一点，也没有改进负载均衡算法的途径。在此，我们将通用和异构的数据驱动算法抽象到微积分动力学空间中，以便我们可以为任何网络拓扑建立网络化负载均衡动力学的同步条件。通过结合所谓的“非保守误差”和网络化动力学的特征值谱，我们可以调整基站间负载均衡机制以实现高效率和收敛保证，或者在无法满足同步条件时减轻振荡。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [73] [Learning-Based Cost-Aware Defense of Parallel Server Systems against Malicious Attacks](https://arxiv.org/abs/2507.12975)
> *学习型成本感知并行服务器系统恶意攻击防御*

*Yuzhen Zhan, Li Jin* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 并行服务器系统, 网络安全, 马尔可夫安全博弈, minimax-Q学习, 成本感知防御

**Comment:** 

> **TL;DR:** 本文提出一种基于学习的近似minimax-Q算法，用于在考虑成本和性能下降之间平衡的情况下，防御并行服务器系统免受恶意网络攻击。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合成本意识和学习算法的防御策略，用于保护并行服务器系统。其方法基于零和马尔可夫安全博弈和近似minimax-Q学习，并针对无界状态空间和收敛性进行了理论分析。特别值得注意的是，该算法在收敛速度上表现出色，远超基于神经网络的方法，同时保持了较小的最优性差距，这对于实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 并行服务器系统在网络、制造和交通等工程应用中广泛使用，但其依赖反馈控制，易受拒绝服务、数据伪造和指令操纵等恶意网络攻击，因此需要开发一种防御策略来平衡防御成本和攻击造成的性能下降。

**Method:** 本文开发了一种学习算法来计算防御策略。具体地，考虑一个零和马尔可夫安全博弈，并提出了一种近似minimax-Q学习算法。该算法使用针对系统结构定制的可解释线性函数逼近来高效计算博弈的均衡点，从而得到成本感知的防御策略。该方法通过Lyapunov方法处理无界状态空间导致的无界时间差错误，并使用常微分方程论证收敛性。

**Result:** 仿真结果表明，该算法比代表性的基于神经网络的方法收敛速度快约50倍，且最优性差距不显著，在4%到8%之间，具体取决于线性逼近器的复杂度和并行服务器的数量。

**Conclusion:** 本文开发了一种高效且收敛性可证明的基于学习的近似minimax-Q算法，能够为并行服务器系统提供成本感知的防御策略，有效平衡防御成本和攻击损失。

> **ai_Abstract:** 本文研究了并行服务器系统的网络物理安全问题，并提出了一种基于学习的成本感知防御策略。通过构建一个零和马尔可夫安全博弈模型，并开发了近似minimax-Q学习算法，该算法利用线性函数逼近来高效计算博弈均衡点。实验证明，该算法在收敛速度上显著优于现有方法，并能有效平衡防御成本与攻击造成的性能损失。

> **摘要翻译:** 我们考虑了并行服务器系统的网络物理安全，这与网络、制造和交通等各种工程应用相关。这些系统依赖于反馈控制，因此可能容易受到拒绝服务、数据伪造和指令操纵等恶意攻击。在本文中，我们开发了一种学习算法，用于计算一种防御策略，以平衡防御行动的技术成本与上述网络攻击造成的性能下降。我们考虑了一个零和马尔可夫安全博弈。我们开发了一种近似的minimax-Q学习算法，该算法能够有效地计算博弈的均衡点，从而得到一种成本感知的防御策略。该算法使用针对系统结构定制的可解释线性函数逼近。我们表明，在温和的假设下，该算法以概率一收敛到近似马尔可夫完美均衡。我们首先使用Lyapunov方法来解决由于无界状态空间导致的无界时间差错误。然后，我们使用基于常微分方程的论证来建立收敛性。仿真结果表明，我们的算法比一种代表性的基于神经网络的方法收敛速度快约50倍，且最优性差距在4%到8%之间，这取决于线性逼近器的复杂度和并行服务器的数量。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [102] [Deep Bilinear Koopman Model for Real-Time Vehicle Control in Frenet Frame](https://arxiv.org/abs/2507.12578)
> *Frenet坐标系下用于实时车辆控制的深度双线性Koopman模型*

*Mohammad Abtahi, Farhang Motallebi Araghi, Navid Mojahed, Shima Nazari* | **Category: eess.SY, cs.LG, cs.RO, cs.SY, 93C10 (Primary), 93B40, 93C41, 68T07, 93B45 (Secondary), I.2.8; I.2.6; G.1.6; J.7** | **Updated: 2025-07-16**

**Keywords:** 深度Koopman模型, 实时控制, Frenet坐标系, 车辆动力学, 模型预测控制

**Comment:** 14 pages, 8 figures. This manuscript is under review with IEEE
  Transactions on Intelligent Vehicles

> **TL;DR:** 本文提出了一种深度双线性Koopman模型，用于在Frenet坐标系下对车辆进行实时建模和控制，并通过硬件在环实验验证了其在实时轨迹跟踪中的卓越性能。

**AI_Comments:** 该论文的创新点在于将深度学习与Koopman算子理论相结合，解决了高维非线性车辆动力学在Frenet坐标系下的建模和控制问题。通过引入双线性交互和保持凸性，确保了模型对实时MPC的适用性。此外，结合累积误差调节器进一步提升了实时轨迹跟踪的鲁棒性。硬件在环实验验证了其在实际应用中的有效性，对于自动驾驶车辆的精确控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于车辆动力学的非线性和耦合特性，自动驾驶车辆的精确建模和控制仍然是一个基本挑战。Koopman算子理论为部署强大的线性控制技术提供了框架，但学习有限维不变子空间以实现高保真建模仍是一个开放问题。

**Method:** 本研究提出了一种深度Koopman方法，用于在曲线Frenet坐标系下对车辆动力学进行建模和控制。该框架使用深度神经网络架构，同时从数据中学习Koopman算子及其相关的不变子空间。算法捕获输入-状态双线性相互作用，同时保持凸性，使其适用于实时模型预测控制(MPC)应用。训练过程中采用多步预测损失以确保长时域预测能力。为进一步提高实时轨迹跟踪性能，模型集成了累积误差调节器(CER)模块，通过减轻累积预测误差来补偿模型不匹配。

**Result:** 通过使用CarSim RT模型作为目标设备进行硬件在环(HIL)实验，并在dSPACE SCALEXIO系统上进行实时验证，评估了闭环性能。与基线控制器相比，所提出的控制器显著降低了跟踪误差。

**Conclusion:** 所提出的控制器显著降低了跟踪误差，证实了其适用于嵌入式自动驾驶系统中的实时实现。

> **ai_Abstract:** 本文提出了一种基于深度双线性Koopman模型的车辆实时控制方法，特别适用于Frenet坐标系下的自动驾驶车辆。针对车辆动力学建模的非线性和耦合挑战，该方法利用深度神经网络同时学习Koopman算子和其不变子空间，并通过捕获输入-状态双线性相互作用和保持凸性，使其适用于实时模型预测控制。为提高预测能力和轨迹跟踪性能，模型引入了多步预测损失和累积误差调节器。硬件在环实验结果表明，该控制器显著降低了跟踪误差，证明了其在嵌入式自动驾驶系统中的实时应用潜力。

> **摘要翻译:** 由于车辆动力学的非线性和耦合特性，自动驾驶车辆的精确建模和控制仍然是一个基本挑战。Koopman算子理论为部署强大的线性控制技术提供了框架，但学习有限维不变子空间以实现高保真建模仍是一个开放问题。本文提出了一种深度Koopman方法，用于在曲线Frenet坐标系下对车辆动力学进行建模和控制。所提出的框架使用深度神经网络架构，同时从数据中学习Koopman算子及其相关的不变子空间。算法捕获输入-状态双线性相互作用，同时保持凸性，使其适用于实时模型预测控制(MPC)应用。训练过程中采用多步预测损失以确保长时域预测能力。为进一步提高实时轨迹跟踪性能，模型集成了累积误差调节器(CER)模块，通过减轻累积预测误差来补偿模型不匹配。通过使用CarSim RT模型作为目标设备进行硬件在环(HIL)实验，并在dSPACE SCALEXIO系统上进行实时验证，评估了闭环性能。与基线控制器相比，所提出的控制器显著降低了跟踪误差，证实了其适用于嵌入式自动驾驶系统中的实时实现。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [103] [Fractional-order controller tuning via minimization of integral of time-weighted absolute error without multiple closed-loop tests](https://arxiv.org/abs/2507.12987)
> *分数阶控制器整定：基于时间加权绝对误差积分最小化，无需多次闭环测试*

*Ansei Yonezawa, Heisei Yonezawa, Shuichi Yahagi, Itsuro Kajiwara, Shinya Kijimoto* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 分数阶控制器, 非迭代整定, ITAE, 虚拟参考信号, 开发成本

**Comment:** Published in Asian Journal of Control
  (https://doi.org/10.1002/asjc.3788)

> **TL;DR:** 本文提出一种分数阶控制器非迭代整定技术，通过一次性输入/输出数据和虚拟参考信号最小化ITAE，避免了多次闭环测试，显著降低了开发成本。

**AI_Comments:** 这项研究的创新点在于其提出的分数阶控制器非迭代整定方法，通过引入虚拟参考信号和重构优化问题，成功地避免了传统ITAE整定所需的多次闭环实验或仿真。这一改进显著降低了开发成本和时间，是其最重要的贡献。该方法对于需要快速部署和成本敏感的分数阶控制器应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统分数阶控制器整定需要多次闭环实验或模型仿真来评估时间加权绝对误差积分（ITAE），成本高昂且耗时。本研究旨在提供一种无需重复实验、能降低开发成本的非迭代整定方法，同时保持或提升减少超调/欠调和抑制稳态误差的性能。

**Method:** 本文提出一种基于ITAE准则的线性分数阶(FO)控制器非迭代整定技术。该方法通过从受控设备收集一次性的输入/输出数据，并在此基础上定义一个虚拟参考信号，从而能够评估任意控制器参数所提供的闭环响应。为避免传统方法中必要的重复实验，研究将ITAE最小化问题利用虚拟参考信号重新表述为一个优化问题，通过求解该优化问题获得最小化ITAE的FO控制器参数。

**Result:** 通过数值研究验证了所提出方法的有效性。该方法成功避免了传统方法所需的重复实验，显著降低了线性分数阶控制器的开发成本。

**Conclusion:** 所提出的非迭代整定方法通过避免重复实验，显著降低了分数阶控制器的开发成本，从而促进了其在实际中的应用。

> **ai_Abstract:** 本文提出一种新颖的线性分数阶控制器非迭代整定方法，该方法基于ITAE准则，但与传统方法不同，它仅需一次性输入/输出数据，并通过引入虚拟参考信号将ITAE最小化问题转化为优化问题求解，从而避免了多次闭环实验或仿真。数值研究证实了其有效性，显著降低了分数阶控制器的开发成本，有利于其工程应用。

> **摘要翻译:** 本研究提出了一种基于时间加权绝对误差积分(ITAE)准则的线性分数阶(FO)控制器非迭代整定技术。最小化ITAE是分数阶控制器整定的传统方法，该技术可以减少超调/欠调并抑制稳态误差。与传统的基于ITAE的控制器整定方法相比，所提出的方法无需多次闭环实验或基于模型的仿真来评估ITAE。通过从受控设备收集一次性的输入/输出数据，并在此基础上定义一个虚拟参考信号，从而能够评估任意控制器参数所提供的闭环响应。为了避免传统方法中必要的重复实验，我们利用虚拟参考信号重新表述了ITAE最小化问题。通过求解基于虚拟参考信号的优化问题，获得了最小化ITAE的理想分数阶控制器参数。数值研究证明了所提出方法的有效性。避免重复实验显著降低了线性分数阶控制器的开发成本，从而促进了它们的实际应用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [135] [Vertical Vibration Reduction of Maglev Vehicles using Nonlinear MPC](https://arxiv.org/abs/2507.13015)
> *磁悬浮列车非线性模型预测控制垂向振动抑制*

*Mario Hermle, Arnim Kargl, Peter Eberhard* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 磁悬浮列车, 非线性模型预测控制, 振动抑制, 机械悬架, 乘坐舒适性

**Comment:** 

> **TL;DR:** 提出了一种新的非线性模型预测控制（NMPC）策略，通过将机械悬架动力学纳入控制模型，有效减少磁悬浮列车的垂向振动，提高乘坐舒适性。

**AI_Comments:** 该研究的创新之处在于将机械悬架动力学显式地纳入NMPC模型中，解决了传统方法忽略悬浮磁铁与车体相互作用的问题。其重要性在于显著提升了高速磁悬浮列车的乘坐舒适性，并通过预测性控制优化了减振效果。这对于未来高速轨道交通的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统磁悬浮控制方法常忽略悬浮磁铁与车体运动之间的相互作用，导致无法有效预测和抑制垂向振动，影响乘客舒适度。

**Method:** 本文提出了一种新颖的非线性模型预测控制（NMPC）策略，该策略将机械悬架动力学明确地纳入控制模型中，并通过同时建模电磁力和悬架行为来实现预测性减振。

**Result:** 模拟结果表明，该方法在振动抑制方面优于现有控制器，显著提高了乘客舒适度和乘坐质量，并通过减少轨道不平整引起的垂向振动，实现了气隙跟踪精度和乘坐舒适性之间更有效的权衡。

**Conclusion:** 该非线性模型预测控制策略在磁悬浮列车垂向振动抑制方面表现出色，是未来高速磁悬浮应用的一个有前景的解决方案。

> **ai_Abstract:** 本文提出一种新颖的非线性模型预测控制（NMPC）策略，用于高速磁悬浮列车的垂向振动抑制。该方法与传统方法不同，它将机械悬架动力学和电磁力明确纳入控制模型，从而实现对振动的预测性缓解。仿真结果表明，该方法在提高乘客舒适度和乘坐质量方面优于现有控制器，并为气隙跟踪和乘坐舒适性之间的权衡提供了更有效的调整，是未来高速磁悬浮应用的有前景解决方案。

> **摘要翻译:** 这项工作提出了一种新颖的非线性模型预测控制（NMPC）策略，用于高速磁悬浮列车，该策略将机械悬架动力学明确地纳入控制模型中。与通常忽略悬浮磁铁和车体运动之间相互作用的传统方法不同，所提出的方法通过建模电磁力和悬架行为来实现预测性振动抑制。这种集成方法通过减少由轨道不平整引起的垂向振动，显著提高了乘客舒适度和乘坐质量。此外，它允许在精确气隙跟踪和乘坐舒适性之间进行更有效的权衡调整。基于Transrapid详细多体模型的仿真结果表明，该方法在振动抑制方面优于现有控制器，使其成为未来高速磁悬浮应用的一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [171] [Dual LiDAR-Based Traffic Movement Count Estimation at a Signalized Intersection: Deployment, Data Collection, and Preliminary Analysis](https://arxiv.org/abs/2507.13073)
> *双激光雷达在信号交叉口交通流量计数估计中的应用：部署、数据收集和初步分析*

*Saswat Priyadarshi Nayak, Guoyuan Wu, Kanok Boriboonsomsin, Matthew Barth* | **Category: eess.SY, cs.CV, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 交通流量计数, 激光雷达, 信号交叉口, 交通检测, 3D检测

**Comment:** 7 Pages, 8 Figures. This paper has been accepted for publication at
  the 2025 IEEE ITSC. Copyright IEEE

> **TL;DR:** 本文开发并评估了一个双激光雷达系统，用于在信号交叉口估计交通流量，克服了传统方法的局限性。

**AI_Comments:** 该论文创新性地将双激光雷达系统应用于交通流量计数，解决了传统方法在恶劣环境下的局限性，特别是在数据采集和初步分析方面。其重要性在于为智能交通系统提供了更可靠的数据源，有望提升交通管理和安全水平。

<details>
  <summary>Details</summary>

**Motivation:** 交叉口的交通流量计数 (TMC) 对于优化信号配时、评估现有交通控制措施的性能以及提出高效的车道配置以最大限度地减少延误、减少拥堵和提高安全性至关重要。传统方法（特别是基于摄像头的）在恶劣天气和夜间光照不足时容易出现不准确性。激光雷达 (LiDAR) 技术因成本降低及其在 3D 对象检测、跟踪和相关应用中的扩展使用而日益受欢迎。

**Method:** 本文开发、部署并评估了一个双激光雷达系统，用于在加利福尼亚州里亚尔托市的一个交叉口进行 TMC 估计。利用来自两个激光雷达的 3D 边界框检测来根据交通方向、车辆运动和车辆类别对车辆计数进行分类。

**Result:** 本文讨论了估计的 TMC 结果，并提供了对观察到的趋势和不规则性的见解。

**Conclusion:** 该工作讨论了估计的 TMC 结果并提供了见解。还讨论了潜在的改进，不仅可以增强 TMC 估计，还可以增强交叉口的轨迹预测和意图预测。

> **ai_Abstract:** 本论文介绍了一种在信号交叉口使用双激光雷达系统进行交通流量计数 (TMC) 估计的新方法。针对传统基于摄像头方法在恶劣条件下的不足，该研究部署了双激光雷达系统，利用其3D检测能力对车辆进行分类和计数。研究讨论了初步的TMC估计结果，并提出了未来在轨迹预测和意图预测方面的潜在改进。

> **摘要翻译:** 交叉口的交通流量计数 (TMC) 对于优化信号配时、评估现有交通控制措施的性能以及提出高效的车道配置以最大限度地减少延误、减少拥堵和提高安全性至关重要。传统上，诸如人工计数、线圈检测器、气动路管和基于摄像头的识别等方法已被用于 TMC 估计。尽管通常可靠，但基于摄像头的 TMC 估计在恶劣天气和夜间光照条件差的情况下容易出现不准确性。相比之下，由于成本降低及其在 3D 对象检测、跟踪和相关应用中的扩展使用，激光雷达 (LiDAR) 技术最近越来越受欢迎。本文介绍了作者在加利福尼亚州里亚尔托市的一个交叉口开发、部署和评估双激光雷达系统以进行 TMC 估计的尝试。来自两个激光雷达的 3D 边界框检测用于根据交通方向、车辆运动和车辆类别对车辆计数进行分类。这项工作讨论了估计的 TMC 结果，并提供了对观察到的趋势和不规则性的见解。还讨论了潜在的改进，不仅可以增强 TMC 估计，还可以增强交叉口的轨迹预测和意图预测。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [213] [QTCAJOSA: Low-Complexity Joint Offloading and Subchannel Allocation for NTN-Enabled IoMT](https://arxiv.org/abs/2507.13242)
> *QTCAJOSA：面向NTN使能IoMT的低复杂度联合卸载和子信道分配*

*Alejandro Flores C., Konstantinos Ntontin, Ashok Bandi, Symeon Chatzinotas* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** IoMT, 非地面网络, 任务卸载, 资源分配, 低复杂度算法

**Comment:** 

> **TL;DR:** 针对医疗物联网（IoMT）设备在非地面网络（NTN）中的任务卸载问题，本文提出了一种低复杂度的联合子信道分配和卸载决策算法，旨在最小化任务的加权总延迟，并通过仿真验证了该方法在引入非地面节点后的性能增益。

**AI_Comments:** 这项工作提出了一种实用的低复杂度算法，用于解决IoMT在非地面网络中的复杂任务卸载问题。其创新点在于结合了UAV、HAPS和LEO卫星的多层NTN架构，并设计了针对非凸问题的贪婪启发式算法，以实现加权延迟最小化。其重要性在于为未来IoMT在非地面环境下的高效运行提供了理论和算法支持。

<details>
  <summary>Details</summary>

**Motivation:** 解决医疗物联网（IoMT）设备向非地面网络（NTN）卸载任务的资源分配问题，目标是最小化任务的加权总延迟。

**Method:** 提出了一种基于凸优化准则的贪婪启发式低复杂度联合子信道分配和卸载决策算法，该算法具有动态计算资源初始化功能。

**Result:** 仿真结果表明，与不包含非地面节点的架构相比，包含不同非地面节点（UAV、HAPS、LEO卫星）的架构获得了性能增益。

**Conclusion:** 通过引入非地面网络节点（UAV、HAPS、LEO卫星），可以有效降低IoMT任务卸载的加权总延迟，从而提升系统性能。

> **ai_Abstract:** 本文研究了医疗物联网（IoMT）设备在非地面网络（NTN）中的任务卸载资源分配问题。该系统架构涉及IoMT设备将任务卸载到充当MEC服务器的无人机，无人机可自行计算或将任务进一步卸载至高空平台站（HAPS）或低地球轨道（LEO）卫星。作者旨在最小化任务的加权总延迟，并针对该非凸问题，提出了一种基于凸优化准则的贪婪启发式低复杂度联合子信道分配和卸载决策算法。仿真结果验证了引入非地面节点对系统性能的提升。

> **摘要翻译:** 在这项工作中，我们考虑了从医疗物联网（IoMT）设备到非地面网络（NTN）的任务卸载的资源分配问题。该架构考虑了IoMT设备集群将其任务卸载到专用无人机（UAV），该无人机充当多接入边缘计算（MEC）服务器，可以计算任务或将其进一步卸载到可用的高空平台站（HAPS）或低地球轨道（LEO）卫星进行远程计算。我们提出了一个以最小化任务加权和延迟为目标的优化问题。鉴于问题的非凸性质，并认识到优化算法的复杂性会影响其性能，我们推导了一种具有动态计算资源初始化的低复杂度联合子信道分配和卸载决策算法，该算法是基于凸优化准则的贪婪启发式算法。仿真结果表明，与不包含非地面节点的架构相比，包含不同非地面节点的架构获得了增益。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [262] [Transient-Stability-Aware Frequency Provision in IBR-Rich Grids via Information Gap Decision Theory and Deep Learning](https://arxiv.org/abs/2507.13265)
> *基于信息鸿沟决策理论和深度学习的富含逆变器电网暂态稳定性感知频率提供*

*Amin Masoumi, Mert Korkali* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 暂态稳定性, 频率提供, 逆变器基资源, 深度学习, 信息鸿沟决策理论

**Comment:** 

> **TL;DR:** 本文提出了一种结合深度学习和信息鸿沟决策理论的框架，用于在高逆变器渗透率电网中提供暂态稳定性感知的频率支持，通过主动重新调度资源，防止在传统虚拟惯量调度策略失败的情况下系统崩溃，且成本增加仅为5%。

**AI_Comments:** 该论文的创新点在于将深度学习的预测能力与信息鸿沟决策理论的鲁棒性相结合，为高逆变器渗透率电网的暂态稳定性问题提供了一种风险规避且主动的解决方案。其优于传统方法的表现以及较低的成本增加，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决高逆变器渗透率电网中由于惯量降低导致的暂态稳定性严重损失问题。

**Method:** 该方法将预测性深度学习（DL）模型与信息鸿沟决策理论（IGDT）相结合，创建了一个规避风险的调度策略。通过重新制定传统的虚拟惯量调度（VIS）问题，该框架利用故障后动态的早期预测来主动重新调度资源。

**Result:** 在IEEE 39总线系统（70% IBR渗透率）上验证，所提出的方法在传统VIS策略失败的情况下防止了系统崩溃，确保了频率稳定性，且成本增加仅为5%。

**Conclusion:** 所提出的结合深度学习和信息鸿沟决策理论的框架能够有效提高高逆变器渗透率电网的暂态稳定性，并在保证频率稳定的同时，将成本增加控制在较低水平，优于传统方法。

> **ai_Abstract:** 本文提出了一种新的框架，通过整合深度学习模型和信息鸿沟决策理论，来解决高逆变器（IBR）渗透率电网中因惯量减少导致的暂态稳定性问题。该框架通过预测故障后动态并主动重新调度资源，重新制定了虚拟惯量调度问题，以确保系统在最坏情况下的稳定性。在IEEE 39总线系统上的验证表明，该方法能够有效防止系统崩溃并确保频率稳定，而传统策略则会失败，且仅带来5%的成本增加。

> **摘要翻译:** 本文介绍了一个旨在解决高逆变器渗透率电网中因惯量降低导致的暂态稳定性严重损失的框架。所提出的方法将预测性深度学习（DL）模型与信息鸿沟决策理论（IGDT）相结合，以创建一种规避风险的调度策略。通过重新制定传统的虚拟惯量调度（VIS）问题，该框架利用故障后动态的早期预测来主动重新调度资源，确保系统重心在最坏情况偶发事件下保持稳定。在IEEE 39总线系统（70% IBR渗透率）上验证，所提出的方法在传统VIS策略失败的情况下防止了系统崩溃，确保了频率稳定性，且成本增加仅为5%。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [297] [Privacy-Preserving Fusion for Multi-Sensor Systems Under Multiple Packet Dropouts](https://arxiv.org/abs/2507.13286)
> *多传感器系统在多丢包情况下的隐私保护融合*

*Jie Huang, Jason J. R. Liu* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 隐私保护融合, 多传感器系统, 丢包, 窃听, 无线传感器网络

**Comment:** 

> **TL;DR:** 本文提出了一种分布式编码的隐私保护机制，用于多传感器系统在丢包和窃听攻击下的隐私保护融合估计，并在不影响估计精度的情况下增强了数据隐私。

**AI_Comments:** 本文提出了一种新颖的分布式编码方法来解决多传感器系统在复杂网络环境（如丢包和窃听）下的隐私保护融合估计问题，具有重要的理论和实践意义。其创新点在于将隐私保护与状态估计性能相结合，并通过严格的数学分析和仿真验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 无线传感器网络在现代信息物理系统中面临窃听和丢包的固有风险，对安全状态估计构成重大挑战。本文旨在解决多传感器系统在多丢包和窃听攻击下的隐私保护融合估计问题。

**Method:** 提出了一种基于分布式编码的隐私保护机制（PPM），在控制理论框架内确保传输期间的数据隐私。开发了一个集中式融合滤波器，考虑了丢包和编码PPM的耦合效应。通过修改的代数Riccati方程推导了合法用户估计误差协方差的有界条件。此外，通过证明窃听者平均估计误差的发散性，严格分析了所提出的PPFE算法的数据保密性。

**Result:** 通过对基于互联网的三罐系统进行仿真，验证了所提出方法的有效性，突出了其在不影响估计精度的情况下增强隐私的潜力。

**Conclusion:** 本文提出的分布式编码的隐私保护融合估计方法，在多传感器系统面临多丢包和窃听攻击时，能够有效保护数据隐私，同时保持合法状态估计的性能。

> **ai_Abstract:** 本文针对多传感器系统在多丢包和窃听攻击下的隐私保护融合估计问题，提出了一种分布式编码的隐私保护机制。该机制在控制理论框架下运行，并开发了一个集中式融合滤波器以应对丢包和编码的耦合效应。研究通过修改的代数Riccati方程分析了合法用户的估计误差，并通过证明窃听者误差的发散性来验证数据保密性。仿真结果表明，该方法在不牺牲估计精度的前提下，有效增强了数据隐私。

> **摘要翻译:** 无线传感器网络（WSN）是现代信息物理系统中的关键组成部分，通过空间分布的传感器实现高效的数据收集和融合。然而，此类网络中固有的窃听和丢包风险对安全状态估计提出了重大挑战。在本文中，我们解决了多传感器系统在多丢包和窃听攻击下的隐私保护融合估计（PPFE）问题。为了缓解这些问题，我们提出了一种在控制理论框架内的分布式编码隐私保护机制（PPM），确保传输期间的数据隐私，同时保持合法状态估计的性能。开发了一个集中式融合滤波器，考虑了丢包和基于编码的PPM的耦合效应。通过修改的代数Riccati方程推导了合法用户估计误差协方差的有界条件。此外，通过证明窃听者平均估计误差的发散性，严格分析了所提出的PPFE算法的数据保密性。基于互联网的三罐系统仿真结果验证了所提出方法的有效性，突出了其在不影响估计精度的情况下增强隐私的潜力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [566] [Input-Output Extension of Underactuated Nonlinear Systems](https://arxiv.org/abs/2403.03117)
> *欠驱动非线性系统的输入-输出扩展*

*Mirko Mizzoni, Amr Afifi, Antonio Franchi* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 欠驱动系统, 辅助执行器, 反馈线性化, 全姿态跟踪, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种通过集成辅助执行器和反馈线性化外环控制器来增强商业欠驱动系统任务空间能力的方法，并展示了其在接触下的稳定性和参数不确定性下的鲁棒性。

**AI_Comments:** 这项工作具有创新性，因为它提出了一种在不修改现有认证低级控制器的情况下，通过外部扩展来增强欠驱动系统能力的方法。这对于商业系统的升级和应用具有重要意义，尤其是在需要物理交互的场景中。其在接触稳定性和鲁棒性方面的表现也验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 为了在不修改现有认证低级控制器的情况下，增强商业欠驱动系统的任务空间能力，并实现全姿态跟踪。

**Method:** 该方法通过集成辅助执行器，并结合一个反馈线性化外环控制器来实现全姿态跟踪。同时，提供了使现有高级命令和新执行器输入能够协调配合以实现所有自由度解耦控制的条件。

**Result:** 与标准四旋翼飞行器进行比较研究表明，所提出的修改平台在接触下保持稳定，而基线系统则发散。此外，在参数不确定性下的仿真结果也表明了该方法的鲁棒性。

**Conclusion:** 通过集成辅助执行器和反馈线性化外环控制器，可以有效增强欠驱动系统的任务空间能力，实现全姿态跟踪，并表现出良好的接触稳定性和鲁棒性。

> **ai_Abstract:** 本文提出了一种针对欠驱动非线性系统的输入-输出扩展方法。该方法通过集成辅助执行器和一个反馈线性化外环控制器，在不修改现有低级控制器的情况下，增强了商业欠驱动系统的任务空间能力，并实现了全姿态跟踪和所有自由度的解耦控制。实验证明，该方法提高了系统在接触下的稳定性，并在参数不确定性下表现出良好的鲁棒性。

> **摘要翻译:** 本文提出了一种集成辅助执行器的方法，以增强商业欠驱动系统的任务空间能力，同时保持内部认证的低级控制器不变。附加的执行器与一个反馈线性化外环控制器相结合，实现了全姿态跟踪。我们提供了在何种条件下，遗留的高级命令和新的执行器输入可以协调配合，以实现所有自由度的解耦控制。与标准四旋翼飞行器（最初并非为物理交互设计）进行的比较研究表明，所提出的修改平台在接触下保持稳定，而基线系统则发散。此外，在参数不确定性下的仿真结果也说明了所提出方法的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [594] [Model Predictive Black Start for Dynamic Formation of DER-Led Microgrids with Inrush Current Impacts](https://arxiv.org/abs/2507.12569)
> *考虑励磁涌流影响的分布式能源主导微电网动态形成模型预测黑启动*

*Cong Bai, Salish Maharjan, Zhaoyu Wang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-16**

**Keywords:** 黑启动, 模型预测控制, 励磁涌流, 分布式能源, 微电网

**Comment:** 

> **TL;DR:** 本文提出了一种模型预测黑启动（MPBS）框架，结合励磁涌流可行性模块和电压控制策略，以安全高效地恢复高渗透率分布式能源配电系统，并有效缓解励磁涌流。

**AI_Comments:** 该论文的创新点在于将模型预测控制与励磁涌流的精确估计和缓解策略相结合，以解决高渗透率分布式能源配电系统黑启动中的关键挑战。所提出的电压控制策略和开关阻断机制对于防止保护装置误动作具有重要意义。该研究对于未来智能电网的恢复和韧性具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在高渗透率分布式能源（DER）的配电系统中，黑启动（BS）需要先进的控制框架来确保安全高效的恢复。现有的黑启动过程可能面临励磁涌流过大导致保护装置误动作的问题。

**Method:** 本文提出了一种模型预测黑启动（MPBS）框架。该框架包含一个励磁涌流可行性模块，用于实时生成可行且最优的恢复序列。它利用分布式能源输出和输电网可用性的短期预测来构建自适应的启动路径。励磁涌流可行性模块分析性地估计由带电空载配电变压器引起的瞬态励磁涌流。为缓解过大的励磁涌流并避免保护装置的潜在误动作，开发了一种受紧急操作启发的电压控制策略和开关阻断机制。所提出的励磁涌流模型通过PowerFactory中的电磁暂态（EMT）仿真进行验证。

**Result:** 所提出的励磁涌流模型在电磁暂态（EMT）仿真中验证，估计精度超过90%。在修改后的IEEE 123节点馈线上的案例研究表明，MPBS框架可以防止熔断器和重合器的误动作，减少不必要的分布式能源能量消耗，并提高分布式能源主导的黑启动过程中的负荷恢复效率。

**Conclusion:** 本文提出的模型预测黑启动（MPBS）框架，通过整合励磁涌流可行性模块和创新的电压控制策略，能够有效应对高渗透率分布式能源配电系统黑启动中的挑战，实现安全、高效且可靠的系统恢复。

> **ai_Abstract:** 本文提出了一种模型预测黑启动（MPBS）框架，用于高渗透率分布式能源（DER）配电系统的安全高效恢复。该框架整合了励磁涌流可行性模块，利用短期预测动态生成最优恢复序列，并开发了电压控制策略和开关阻断机制来缓解变压器励磁涌流问题。模型通过电磁暂态仿真验证，并在IEEE 123节点馈线案例研究中展示了其在防止保护装置误动作、减少能源消耗和提高负荷恢复效率方面的有效性。

> **摘要翻译:** 高渗透率分布式能源（DER）配电系统（DS）的黑启动（BS）需要先进的控制框架来确保安全高效的恢复。本文提出了一种模型预测黑启动（MPBS）框架，该框架结合了励磁涌流可行性模块，以动态生成实时可行和最优的恢复序列。利用分布式能源输出和输电网（TG）可用性的短期预测来构建自适应的启动路径。励磁涌流可行性模块分析性地估计由带电空载配电变压器（DTs）引起的瞬态励磁涌流。为缓解过大的励磁涌流并避免保护装置的潜在误动作，开发了一种受紧急操作启发的电压控制策略和开关阻断机制。所提出的励磁涌流模型通过PowerFactory中的电磁暂态（EMT）仿真进行验证，估计精度超过90%。在修改后的IEEE 123节点馈线上的案例研究表明，MPBS框架可以防止熔断器和重合器的误动作，减少不必要的分布式能源能量消耗，并提高分布式能源主导的黑启动过程中的负荷恢复效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [606] [Using Dynamic Safety Margins as Control Barrier Functions](https://arxiv.org/abs/2404.01445)
> *使用动态安全裕度作为控制障碍函数*

*Victor Freire, Marco M. Nicotra* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 控制障碍函数, 动态安全裕度, 参考调节器, 状态约束, 输入约束

**Comment:** 12 pages, 6 figures

> **TL;DR:** 本文提出了一种利用动态安全裕度作为控制障碍函数的新方法，能处理任意状态和输入约束，且性能优于现有方法。

**AI_Comments:** 该论文的创新点在于将动态安全裕度（DSMs）与控制障碍函数（CBFs）相结合，并利用参考调节器理论来处理复杂的系统约束。其优势在于方法对相对度数不敏感，能够处理多个状态和输入约束，并且在数值模拟中表现出优于现有方法的性能，同时保证了系统的安全性和优化问题的可行性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种设计控制障碍函数（CBFs）的新方法，以应对任意状态和输入约束，并利用参考调节器（reference governor）的工具。

**Method:** 本文提出将动态安全裕度（DSMs）作为扩展系统的控制障碍函数（CBFs），该扩展系统通过将状态与虚拟参考连接而获得。该方法对相对度数不敏感，并能利用CBFs的控制共享特性处理多个状态和输入约束。文中进一步详细研究了使用基于Lyapunov的DSMs构建CBFs的方法。

**Result:** 数值模拟表明，该方法优于现有的基于DSMs的方法，同时保证了相关优化程序安全性和持续可行性。

**Conclusion:** 本文提出的利用动态安全裕度作为控制障碍函数的方法，在处理复杂约束方面表现出色，并能有效保证系统的安全性和优化问题的可行性。

> **ai_Abstract:** 本文提出了一种利用动态安全裕度（DSMs）作为控制障碍函数（CBFs）的新方法，以处理任意状态和输入约束。该方法通过将DSMs应用于一个结合了虚拟参考的扩展系统来实现，并且对相对度数不敏感，能有效处理多重约束。数值模拟验证了该方法在性能上优于现有DSMs方法，并能确保系统的安全性和优化问题的持续可行性。

> **摘要翻译:** 本文提出了一种利用参考调节器文献中的工具，为任意状态和输入约束设计控制障碍函数（CBFs）的方法。具体而言，研究表明动态安全裕度（DSMs）是扩展系统的CBFs，该扩展系统通过将状态与虚拟参考连接而获得。所提出的方法与相对度数无关，并且可以利用CBFs的控制共享特性处理多个状态和输入约束。随后，本文进一步详细研究了使用基于Lyapunov的DSMs构建CBFs的方法。数值模拟表明，该方法优于现有的基于DSMs的方法，同时保证了相关优化程序安全性和持续可行性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [620] [Joint Price and Power MPC for Peak Power Reduction at Workplace EV Charging Stations](https://arxiv.org/abs/2507.12703)
> *工作场所电动汽车充电站的联合价格和功率MPC用于削减峰值功率*

*Thibaud Cambronne, Samuel Bobick, Wente Zeng, Scott Moura* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 电动汽车充电, 峰值功率削减, 模型预测控制, 需求费用, 价格优化

**Comment:** 

> **TL;DR:** 本文提出了一种结合价格和功率优化的模型预测控制（MPC）方法，以降低电动汽车充电站的峰值功率和运营成本。

**AI_Comments:** 本文通过将价格激励与基于MPC的功率优化相结合，为电动汽车充电基础设施的运营成本降低提供了一种实用且创新的方法。蒙特卡洛模拟的使用为所提出的方法提供了可靠的评估。

<details>
  <summary>Details</summary>

**Motivation:** 商业电动汽车充电站运营商的电费中，需求费用通常占很大一部分。本文旨在探索控制方法，以减少工作场所电动汽车充电站的峰值功耗和相关成本。

**Method:** 本文在联合价格和功率优化框架下探索控制方法，通过优化一系列价格选项来激励用户选择可控充电服务。提出了几种解决方案，并使用基于时间序列预测的模型预测控制（MPC）进行实现。通过蒙特卡洛模拟进行评估。

**Result:** 蒙特卡洛模拟结果表明，使用时间序列预测的模型预测控制可以显著降低充电站运营商的成本。

**Conclusion:** 本文得出结论，通过优化价格和功率，使用时间序列预测的模型预测控制（MPC）可以有效降低工作场所电动汽车充电站的运营商成本。

> **ai_Abstract:** 本文针对商业电动汽车充电站因需求费用导致的电费高昂问题，提出了一种联合价格和功率优化框架。该框架通过优化价格选项激励用户选择可控充电服务。研究通过蒙特卡洛模拟验证了使用基于时间序列预测的模型预测控制（MPC）能够有效降低峰值功率消耗和总运营商成本。

> **摘要翻译:** 需求费用通常占商业电动汽车充电站运营商电费的很大一部分。本文探讨了在联合价格和功率优化框架下，减少工作场所电动汽车充电站峰值功耗的控制方法。我们优化了一系列价格选项，以激励用户选择可控充电服务。利用这个框架，我们提出了几种解决方案，以实现需求费用和总运营商成本的双重降低。通过蒙特卡洛模拟，我们发现使用时间序列预测的模型预测控制可以显著降低充电站运营商的成本。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [648] [A Stackelberg Game of Demand Response from the Aggregator's Perspective](https://arxiv.org/abs/2507.12708)
> *从聚合商角度的电需求响应Stackelberg博弈*

*Seangleng Khe, Parin Chaipunya, Athikom Bangviwat* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-17**

**Keywords:** Stackelberg博弈, 需求响应, 聚合商, 双层优化, 负荷控制

**Comment:** 

> **TL;DR:** 本文从聚合商角度出发，利用Stackelberg博弈模型研究了需求响应活动，实现了负荷控制和降低电费的双赢。

**AI_Comments:** 本文创新性地将Stackelberg博弈理论应用于需求响应领域，从聚合商视角构建了双层优化模型，有效解决了负荷控制和电费优化问题。其模型简洁且实用，对于智能电网中的需求侧管理具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究单个聚合商与多个参与消费者之间的需求响应活动建模，以有效控制负荷并为消费者降低电费。

**Method:** 采用双层结构（bilevel structure）的Stackelberg博弈模型，聚合商扮演领导者，消费者扮演追随者。

**Result:** 所提出的模型在负荷控制方面被证明是有效的，帮助聚合商达到目标削减量，同时消费者支付更便宜的电费。

**Conclusion:** 该Stackelberg博弈模型能够有效地协调聚合商和消费者之间的需求响应活动，实现负荷控制和电费降低。

> **ai_Abstract:** 本文从聚合商的角度，构建了一个Stackelberg博弈模型来分析聚合商与多个消费者之间的需求响应活动。该模型采用双层结构，将聚合商设定为领导者，消费者为追随者。研究结果表明，该模型能有效实现负荷控制，帮助聚合商达到预设的削减目标，并同时降低消费者的电费负担。

> **摘要翻译:** 本文研究了单个聚合商与多个参与消费者之间的需求响应活动建模。该模型融合了信息结构和决策序列中自然出现的双层结构，其中聚合商扮演领导者角色，参与消费者扮演追随者角色。所提出的模型被证明在负荷控制方面是有效的，有助于聚合商达到目标削减，同时消费者支付更便宜的电费。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [653] [Spacecraft Attitude Control Under Reaction Wheel Constraints Using Control Lyapunov and Control Barrier Functions](https://arxiv.org/abs/2409.19936)
> *使用控制李雅普诺夫函数和控制障碍函数实现反作用轮约束下的航天器姿态控制*

*Milad Alipour Shahraki, Laurent Lessard* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-16**

**Keywords:** 航天器姿态控制,反作用轮约束,控制李雅普诺夫函数,控制障碍函数,敏捷控制

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的控制策略，用于解决反作用轮约束下的敏捷航天器姿态控制问题。

**AI_Comments:** 本文提出了一种新颖的控制策略，结合了控制李雅普诺夫函数和控制障碍函数，有效地解决了敏捷航天器在反作用轮约束下的姿态控制问题。该方法不仅稳定了系统，还通过减轻低采样频率下的颤振和强制执行硬状态约束，展现了其创新性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为敏捷航天器姿态控制提供一种新的控制策略，以解决反作用轮相关的输入和状态约束问题。

**Method:** 采用最优衰减控制李雅普诺夫函数二次规划来稳定系统并减轻低采样频率下的颤振，同时利用控制障碍函数强制执行硬状态约束。

**Result:** 数值模拟验证了该方法在实时敏捷航天器姿态控制中的实用性和效率。

**Conclusion:** 该研究提出了一种实用且高效的敏捷航天器姿态控制策略，能够有效处理反作用轮带来的约束。

> **ai_Abstract:** 本文提出了一种新颖的敏捷航天器姿态控制策略，该策略通过结合最优衰减控制李雅普诺夫函数二次规划和控制障碍函数，有效解决了反作用轮带来的输入和状态约束问题。数值模拟结果验证了该方法在实际应用中的高效性和实用性。

> **摘要翻译:** 本文介绍了一种新颖的敏捷航天器姿态控制策略，旨在解决与反作用轮相关的输入和状态约束。一个最优衰减控制李雅普诺夫函数二次规划稳定了系统并减轻了低采样频率下的颤振，而控制障碍函数则强制执行硬状态约束。数值模拟验证了该方法在实时敏捷航天器姿态控制中的实用性和效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [672] [On the Properties of Optimal-Decay Control Barrier Functions](https://arxiv.org/abs/2507.12717)
> *关于最优衰减控制障碍函数的性质*

*Pio Ong, Max H. Cohen, Tamas G. Molnar, Aaron D. Ames* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 控制障碍函数, 最优衰减, 安全滤波器, 前向不变性, 卫星控制

**Comment:** 8 pages, 2 figures, to appear at 64th IEEE Conference on Decision and
  Control (CDC 2025)

> **TL;DR:** 本文提出了最优衰减控制障碍函数（OD-CBFs），通过自动确定衰减率$\omega$来解决传统控制障碍函数（CBFs）中$\alpha$函数选择的用户定义问题，并提供了全面的理论分析和仿真验证。

**AI_Comments:** 本文的创新点在于解决了传统控制障碍函数（CBFs）中$\alpha$函数选择的经验性难题，通过引入最优衰减控制障碍函数（OD-CBFs）实现了衰减率的自动确定。这显著提高了CBF在安全滤波器设计中的鲁棒性和实用性。论文对OD-CBF框架进行了全面的理论表征，并扩展了高阶CBF，显示了其理论深度和广泛适用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的控制障碍函数（CBFs）中，类$\mathcal{K}^e$函数$\alpha$的选择是用户定义的，且对系统行为有显著影响。本文旨在形式化这一选择过程。

**Method:** 本文引入了最优衰减控制障碍函数（OD-CBFs），修改了传统的CBF不等式为$\dot{h} \geq - \omega \alpha(h)$，其中$\omega \geq 0$由安全滤波器自动确定。该框架对OD-CBF的有效性、状态空间中底层集合的控制不变性、安全集合的前向不变性以及基于优化的安全控制器的可行性、Lipschitz连续性和封闭形式表达式进行了全面表征。此外，该方法还扩展了现有的高阶CBF技术，处理相对度消失的安全约束。

**Result:** 该框架提供了OD-CBF有效性、状态空间中底层集合的控制不变性、安全集合的前向不变性，以及基于优化的安全控制器的可行性、Lipschitz连续性和封闭形式表达式的可处理条件。该方法还扩展了现有高阶CBF技术。所提出的方法在卫星控制问题中通过仿真得到验证。

**Conclusion:** 本文通过引入最优衰减控制障碍函数（OD-CBFs），成功形式化了控制障碍函数中$\alpha$函数的选择过程，为安全滤波器设计提供了一个更鲁棒和易于使用的方法，并通过理论表征和仿真得到了支持。

> **ai_Abstract:** 本文针对传统控制障碍函数（CBFs）中用户定义且对系统行为有显著影响的类$\mathcal{K}^e$函数$\alpha$的选择问题，提出了最优衰减控制障碍函数（OD-CBFs）。OD-CBFs通过修改CBF不等式为$\dot{h} \geq - \omega \alpha(h)$，并自动确定衰减率$\omega$，从而形式化了$\alpha$的选择过程。该研究全面表征了OD-CBF框架，包括其有效性、集合不变性和基于优化控制器的性质，并将其扩展到高阶CBF。仿真结果在卫星控制问题上验证了所提方法的有效性。

> **摘要翻译:** 控制障碍函数为合成安全滤波器提供了一种强大的手段，确保以向前集不变性为框架的安全性。CBF有效性的关键在于系统动力学上的简单不等式：$\dot{h} \geq - \alpha(h)$。然而，确定类$\mathcal{K}^e$函数$\alpha$是一个用户定义的选项，可能对所得系统行为产生显著影响。本文使用最优衰减控制障碍函数（OD-CBFs）形式化了选择$\alpha$的过程。这些函数将传统的CBF不等式修改为：$\dot{h} \geq - \omega \alpha(h)$，其中$\omega \geq 0$由安全滤波器自动确定。本文详细阐述了该框架的全面表征，包括OD-CBF有效性的可处理条件、状态空间中底层集合的控制不变性、安全集合的前向不变性条件，以及关于基于优化的安全控制器的可行性、Lipschitz连续性和封闭形式表达式的讨论。该框架还扩展了现有高阶CBF技术，解决了相对度消失的安全约束。所提出的方法在仿真中的卫星控制问题上得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [693] [A Generalized Stability Analysis Method with Dynamic Phasors for LV AC Microgrids](https://arxiv.org/abs/2507.08383)
> *一种基于动态相量用于低压交流微电网的广义稳定性分析方法*

*Bülent Dağ* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-17**

**Keywords:** 动态相量, 稳定性分析, 低压交流微电网, 感应耦合, 下垂控制

**Comment:** 8 pages, 6 figures

> **TL;DR:** 现有基于静态相量的微电网稳定性分析方法对于包含感应耦合线路的系统存在不足。本文提出了一种将动态相量纳入现有方法的广义稳定性分析方法，并成功预测了低压交流微电网的不稳定性边界。

**AI_Comments:** 该论文通过整合动态相量，解决了微电网稳定性分析中的一个实际局限性，这是一项关键创新。它提供了一种更准确、更通用的方法，可能有助于设计和运行更稳健的微电网，尤其是在具有显著感应耦合的系统中。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于相量的简化稳定性分析方法对于包含感应耦合线路的微电网存在不足，主要原因是使用传统静态相量表示感应耦合线路。

**Method:** 将感应耦合线路的动态相量纳入现有基于相量的稳定性分析方法中，并应用于由下垂控制逆变器组成的低压交流微电网。

**Result:** 结果表明，采用动态相量的稳定性分析方法成功预测了低压交流微电网的不稳定性边界。

**Conclusion:** 将动态相量纳入稳定性分析中，显著提高了低压交流微电网不稳定性边界预测的准确性，解决了传统静态相量方法的局限性。

> **ai_Abstract:** 本文提出了一种用于低压交流微电网的广义稳定性分析方法，旨在解决现有方法在处理感应耦合线路时因使用静态相量而导致的不足。通过将动态相量纳入现有基于相量的稳定性分析方法中，该方法能够成功预测低压交流微电网的不稳定性边界，从而提高了稳定性评估的准确性。

> **摘要翻译:** 用传统静态相量表示感应耦合线路是现有基于相量的简化稳定性分析方法对包含感应耦合线路的微电网不足的主要原因。在文献中，动态相量已被提出用于感应线路的动态建模，以保持分析方法的简化结构。在本研究中，提出了一种用于由下垂控制逆变器组成的低压交流微电网的广义稳定性分析方法。所提出的分析方法基于将感应耦合线路的动态相量纳入现有基于相量的稳定性分析方法中。结果表明，采用动态相量的稳定性分析方法成功预测了低压交流微电网的不稳定性边界。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [696] [Invariance Guarantees using Continuously Parametrized Control Barrier Functions](https://arxiv.org/abs/2507.12743)
> *采用连续参数化控制障碍函数的不变性保证*

*Inkyu Jang, H. Jin Kim* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-17**

**Keywords:** 控制障碍函数, 不变性保证, 参数化控制, 安全控制, 二次规划

**Comment:** 11 pages, 6 figures

> **TL;DR:** 本文提出PCBF框架，通过连续参数化控制障碍函数简化复杂不变集的构建，实现安全控制和环境适应性。

**AI_Comments:** 本文的创新之处在于引入了连续参数化控制障碍函数（PCBF）的概念，通过将复杂的控制不变集问题分解为多个简单形状不变集的动态选择，显著简化了传统CBF的设计难度。这种方法不仅提高了系统对复杂环境的适应性，还通过轻量级的PCBF-QP控制器提供了实用的解决方案。其重要性在于为安全关键系统提供了一种更灵活、更易于实现的不变性保证方法。

<details>
  <summary>Details</summary>

**Motivation:** 在安全关键控制中，构建形状合适且在给定状态约束内的控制不变集是一个基本但困难的问题，尤其对于大型或复杂空间。

**Method:** 论文引入了利用连续参数化控制障碍函数（PCBF）的安全控制框架。PCBF中，每个参数选择对应一个形状相对简单的控制不变集。通过动态选择参数，使对应的不变集位于安全边界内，从而实现不变性保持控制，避免合成单一复杂的CBF。通过在参数空间上分配可微分动力学，推导出一个基于二次规划（QP）的轻量级反馈控制器，称为PCBF-QP。还讨论了如何为一类系统构建有效的PCBF以及如何约束参数以使不变集不超过安全边界。概念还扩展到连续参数化高阶CBF，称为高阶PCBF。

**Result:** 仿真实验验证了所提出的方法。

**Conclusion:** PCBF框架通过简化不变集的构建并增强对不同环境的适应性，为安全关键控制提供了一种有效且轻量级的解决方案。

> **ai_Abstract:** 本文提出了一个名为PCBF（连续参数化控制障碍函数）的安全控制框架，旨在解决在复杂空间中构建控制不变集的难题。PCBF通过为每个参数选择对应一个简单形状的不变集，并动态选择参数以确保不变集位于安全边界内，从而避免了合成单一复杂CBF的需要，并提高了对多样环境的适应性。研究还推导出了基于二次规划的PCBF-QP控制器，并探讨了PCBF的构建方法和参数约束，同时将概念扩展到高阶PCBF。仿真实验验证了该方法的有效性。

> **摘要翻译:** 构建一个形状合适且在给定状态约束内的控制不变集是安全关键控制中的一个基本问题，但已知其难度很大，特别是对于大型或复杂空间。本文引入了一个利用连续参数化控制障碍函数（PCBF）的安全控制框架。在PCBF中，每个参数选择都对应一个形状相对简单的控制不变集。通过动态选择其对应不变集位于安全边界内的参数来完成保持不变性的控制。这消除了合成一个与整个自由空间匹配的单一复杂CBF的需要。它还使得更容易适应不同的环境。通过在参数空间上分配可微分动力学，我们推导出了一个基于二次规划（QP）的轻量级反馈控制器，即PCBF-QP。我们还讨论了如何为一类系统构建有效的PCBF以及如何约束参数以使不变集不超过安全边界。该概念还扩展到涵盖连续参数化高阶CBF，称为高阶PCBF。最后，进行了仿真实验以验证所提出的方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [18] [A Novel Data Augmentation Strategy for Robust Deep Learning Classification of Biomedical Time-Series Data: Application to ECG and EEG Analysis](https://arxiv.org/abs/2507.12645)
> *生物医学时间序列数据鲁棒深度学习分类的新型数据增强策略：在心电图和脑电图分析中的应用*

*Mohammed Guhdar, Ramadhan J. Mstafa, Abdulhakeem O. Mohammed* | **Category: eess.SP, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 数据增强, 深度学习, 生物医学信号, 心电图, 脑电图

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的数据增强策略，结合ResNet和注意力机制，用于统一的生物医学时间序列数据（如ECG和EEG）深度学习分类，并在多个基准数据集上取得了最先进的性能，同时具有低资源消耗。

**AI_Comments:** 本文的创新点在于提出了新型的时间域串联数据增强策略，科学地增加了信号复杂性，从而有效提升了模型对多种生物医学时间序列数据的泛化能力和分类性能。其统一框架设计能够处理根本不同的生理信号，解决了现有方法在多模态数据分析中的痛点。同时，通过结合Focal Loss和正则化，有效缓解了生物医学数据中常见的类别不平衡问题。模型的低资源占用和高处理速度也使其在实际临床应用，特别是可穿戴设备部署方面具有重要潜力。这是一项结合了深度学习和信号处理的实用且高效的研究。

<details>
  <summary>Details</summary>

**Motivation:** 准确统一分析多样生物信号（如ECG和EEG）的需求日益增长，尤其是在同步监测中。现有方法在处理和提取不同生理信号特征的统一架构方面存在不足，且许多生物医学数据集中固有的类别不平衡会导致传统方法性能偏差。

**Method:** 提出了一种新颖的统一深度学习框架，结合了基于ResNet的CNN和注意力机制。核心是时间域串联多个增强信号变体以生成更丰富表示的新型数据增强策略，科学地增加了信号复杂性。预处理包括小波去噪、基线去除和标准化。通过结合高级数据增强和Focal Loss函数有效管理类别不平衡。训练期间应用正则化技术以确保泛化能力。

**Result:** 在三个基准数据集（UCI癫痫脑电图、MIT-BIH心律失常、PTB诊断心电图）上，分别达到了99.96%、99.78%和100%的准确率。与现有技术相比，实现了最佳预测。架构仅需约130 MB内存，每个样本处理时间约10 ms，适用于低端或可穿戴设备部署。

**Conclusion:** 所提出的统一深度学习架构在处理多样生物医学时间序列数据方面表现出强大的鲁棒性，并在不同信号类型和临床背景下取得了最先进的性能，同时具有高效的资源利用率，使其适用于实际部署。

> **ai_Abstract:** 本研究提出了一种新颖的统一深度学习框架，用于生物医学时间序列数据的鲁棒分类，特别是ECG和EEG。该框架结合了ResNet-based CNN与注意力机制，并引入了一种独特的时间域串联数据增强策略，以应对多信号类型处理和类别不平衡问题。实验在UCI Seizure EEG、MIT-BIH Arrhythmia和PTB Diagnostic ECG数据集上取得了接近完美的分类准确率，并展现出低内存和快速处理能力，使其适用于资源受限设备。

> **摘要翻译:** 对心电图和脑电图等多种生物信号进行准确统一分析的需求日益增长，这对于全面的患者评估至关重要，尤其是在同步监测中。尽管多传感器融合取得了进展，但在开发能够有效处理和提取根本不同生理信号特征的统一架构方面仍然存在关键空白。另一个挑战是许多生物医学数据集中固有的类别不平衡，这常常导致传统方法的性能偏差。本研究通过提出一种新颖的统一深度学习框架来解决这些问题，该框架在不同信号类型上实现了最先进的性能。我们的方法将基于ResNet的CNN与注意力机制相结合，并通过一种新颖的数据增强策略得到增强：将每个信号的多个增强变体进行时域串联，以生成更丰富的表示。与以往的工作不同，我们科学地增加了信号复杂性以实现更长远的能力，这使得与现有技术相比获得了最佳预测。预处理步骤包括小波去噪、基线去除和标准化。通过结合这种先进的数据增强和Focal Loss函数，有效地管理了类别不平衡。训练期间应用了正则化技术以确保泛化能力。我们严格评估了所提出的架构在三个基准数据集上的性能：UCI癫痫脑电图、MIT-BIH心律失常和PTB诊断心电图。它分别达到了99.96%、99.78%和100%的准确率，展示了在不同信号类型和临床背景下的鲁棒性。最后，该架构需要约130 MB内存，每个样本处理时间约10 ms，表明其适用于低端或可穿戴设备部署。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [48] [Enhancing Urban GNSS Positioning Reliability via Conservative Satellite Selection Using Unanimous Voting Across Multiple Machine Learning Classifiers](https://arxiv.org/abs/2507.12706)
> *城市GNSS定位可靠性增强：基于多机器学习分类器一致投票的保守卫星选择策略*

*Sanghyun Kim, Jiwon Seo* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** GNSS定位, 卫星选择, 机器学习, 城市环境, 可靠性

**Comment:** Submitted to IEEE ITSC 2025

> **TL;DR:** 针对城市GNSS定位误差问题，本研究提出一种基于多机器学习分类器一致投票的保守卫星选择策略，显著提升了定位可靠性。

**AI_Comments:** 这项研究通过引入多机器学习分类器的一致投票机制，为城市GNSS环境下的保守卫星选择提供了一个创新且鲁棒的解决方案。其核心创新在于“一致投票”和“置信度阈值”的应用，有效过滤了不可靠的卫星信号，显著提升了定位可靠性。尽管可能牺牲部分可用卫星数量，但对于保障城市复杂环境下的定位精度和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在城市环境中，全球导航卫星系统（GNSS）定位常因建筑物造成的信号遮挡和多径效应而受损，导致显著的定位误差。

**Method:** 本研究提出通过采用多机器学习分类器（随机森林、梯度提升决策树、支持向量机）一致投票的保守卫星选择策略，来增强基于空间体阴影匹配（ZSM）的定位。只有当所有分类器对其视距（LOS）/非视距（NLOS）分类一致同意且置信度分数超过阈值时，才选择该卫星进行定位。

**Result:** 真实城市GPS数据显示，该方法显著提高了定位成功率和接收机包含率，即使LOS/NLOS分类不完美。虽然卫星数量减少导致定位边界略有增加，但整体定位可靠性得到显著增强。

**Conclusion:** 提出的方法在城市GNSS环境中有效提升了定位可靠性。

> **ai_Abstract:** 本文提出一种新颖的保守卫星选择策略，通过结合随机森林、梯度提升决策树和支持向量机等多种机器学习分类器的一致投票，来提升城市环境中全球导航卫星系统（GNSS）定位的可靠性。该方法仅在所有分类器对卫星的视距/非视距（LOS/NLOS）分类达成一致且置信度高于阈值时才使用该卫星。实验结果表明，尽管可能导致使用的卫星数量减少，但该策略显著提高了定位成功率和接收机包含率，从而增强了整体定位可靠性。

> **摘要翻译:** 在城市环境中，全球导航卫星系统（GNSS）定位常因建筑物造成的信号遮挡和多径效应而受损，导致显著的定位误差。为解决此问题，本研究提出通过采用多机器学习分类器一致投票的保守卫星选择策略，来鲁棒性增强基于空间体阴影匹配（ZSM）的定位。研究训练了三种不同的模型——随机森林（RF）、梯度提升决策树（GBDT）和支持向量机（SVM）——以基于全球定位系统（GPS）信号特征执行视距（LOS）和非视距（NLOS）分类。只有当所有分类器一致同意对卫星进行分类且其相关置信度分数超过阈值时，才选择该卫星进行定位。在密集城市区域收集的真实GPS数据进行的实验表明，即使LOS/NLOS分类不完美，所提出的方法也显著提高了定位成功率和接收机包含率。尽管由于使用的卫星数量减少，定位边界略有增加，但整体定位可靠性得到了显著增强，这表明所提出的方法在城市GNSS环境中是有效的。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [78] [Beamforming Tradeoff for Sensing and Communication in Cell-Free MIMO](https://arxiv.org/abs/2507.12917)
> *免蜂窝MIMO系统中传感与通信的波束成形权衡*

*Xi Ding, Luca Kunz, E. Jorswieck* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 波束成形, 联合传感与通信, 免蜂窝MIMO, 半正定松弛, 全局最优

**Comment:** 

> **TL;DR:** 本文提出了一种基于SDR的优化框架，用于免蜂窝MIMO系统中的联合传感与通信的波束成形，该框架无需后处理即可保证全局最优解。

**AI_Comments:** 本文的创新之处在于提出了一种无需后处理即可保证全局最优解的基于SDR的波束成形优化框架，解决了现有方法在全局最优性或后处理方面的局限性。其通用多用户模型也为未来扩展奠定了基础，对下一代无线网络发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联合传感与通信（JSAC）优化方法，如连续凸逼近（SCA）和半正定松弛（SDR），要么缺乏全局最优性，要么需要额外的降秩步骤。

**Method:** 本文提出了一种基于SDR的优化框架，该框架无需后处理即可保证全局最优解。为了评估其性能，还引入了一种独立的波束成形策略，将每个接入点（AP）专门用于通信或传感。所提出的公式建立在通用的多用户系统模型之上。

**Result:** 本文提供了一个全局最优且计算效率高的波束成形设计。

**Conclusion:** 所提出的框架为下一代无线网络的发展提供了有价值的见解，并实现了全局最优和计算高效的波束成形设计。

> **ai_Abstract:** 本文针对小规模免蜂窝MIMO系统中的联合传感与通信（JSAC），提出了一种无需后处理即可保证全局最优的基于半正定松弛（SDR）的联合波束成形优化框架。为基准测试，引入了独立的通信或传感专用波束成形策略。该框架基于通用多用户模型，旨在为下一代无线网络提供高效且最优的波束成形设计。

> **摘要翻译:** 本文研究了小规模免蜂窝MIMO（CF-MIMO）系统中用于联合传感与通信（JSAC）的最优联合波束成形（BF）。虽然先前的工作已经探索了使用连续凸逼近（SCA）和半正定松弛（SDR）等方法进行JSAC优化，但其中许多方法要么缺乏全局最优性，要么需要额外的降秩步骤。与此相反，我们提出了一种基于SDR的优化框架，该框架无需后处理即可保证全局最优解。为了评估其性能，我们引入了一种独立的BF策略，将每个接入点（AP）专门用于通信或传感。所提出的公式建立在通用的多用户系统模型之上，从而能够超越单用户设置进行未来扩展。总的来说，我们的框架提供了一个全局最优且计算效率高的BF设计，为下一代无线网络的发展提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [108] [Multiple-Mode Affine Frequency Division Multiplexing with Index Modulation](https://arxiv.org/abs/2507.13037)
> *多模式仿射频分复用与索引调制*

*Guangyao Liu, Tianqi Mao, Yanqun Tang, Jingjing Zhao, Zhenyu Xiao* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 仿射频分复用, 索引调制, 多模式, 频谱效率, 能量效率

**Comment:** 

> **TL;DR:** 本文提出了一种名为MM-AFDM-IM的多模式索引调制方案，用于仿射频分复用（AFDM），旨在提高其频谱和能量效率，并通过仿真证明了其优越性能。

**AI_Comments:** 本文的创新点在于提出了MM-AFDM-IM方案，通过引入多模式索引调制，在不增加额外能量消耗的情况下，有效地提升了AFDM的频谱和能量效率，这对于高移动性通信具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 仿射频分复用（AFDM）被认为是高移动性通信场景的有效解决方案，但本研究旨在进一步提高AFDM的频谱和能量效率。

**Method:** 提出了一种名为MM-AFDM-IM的多模式索引调制方案。该方案为不同的基于线性调频的子载波选择多个星座字母表，并通过星座模式选择和线性调频激活的动态模式来传递额外信息比特，且不消耗额外能量。此外，还讨论了模式选择策略，并在最大似然检测下推导了所提方案的误码率（BER）渐进紧密上限。

**Result:** 仿真结果表明，MM-AFDM-IM方案的性能优于传统的基准方案。

**Conclusion:** 所提出的MM-AFDM-IM方案能够显著提高AFDM的频谱和能量效率，并在性能上超越传统方案。

> **ai_Abstract:** 本文提出了一种针对仿射频分复用（AFDM）的多模式索引调制方案（MM-AFDM-IM），旨在提升其在高移动性通信中的频谱和能量效率。该方案通过为不同子载波选择多个星座字母表，并利用星座模式选择和线性调频激活的动态模式来额外传输信息，且无需额外能耗。研究还推导了该方案的误码率上限，并通过仿真验证了其相比传统方案的优越性能。

> **摘要翻译:** 仿射频分复用（AFDM）是一种利用线性调频信号的有前景的多载波技术，已被视为高移动性通信场景的有效解决方案。在本文中，我们开发了一种专为AFDM设计的多模式索引调制方案，称为MM-AFDM-IM，旨在进一步提高AFDM的频谱和能量效率。具体而言，为不同的基于线性调频的子载波（线性调频）选择了多个星座字母表。除了经典的幅度/相位调制，额外的信息比特可以通过星座模式选择和线性调频激活的动态模式来传递，而无需额外的能量消耗。此外，我们讨论了模式选择策略，并在最大似然检测下推导了所提方案的误码率（BER）渐进紧密上限。仿真结果表明，MM-AFDM-IM与传统基准方案相比具有优越的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [141] [Unmodulated Visible Light Positioning: A Deep Dive into Techniques, Studies, and Future Prospects](https://arxiv.org/abs/2507.13080)
> *未调制可见光定位：技术、研究与未来展望的深度探索*

*Morteza Alijani, Wout Joseph, David Plets* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 未调制可见光定位, 室内定位, 可见光通信, 6G, LED

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文深入探讨了未调制可见光定位（uVLP）技术，它通过利用未调制照明源的信号来克服传统VLP的成本和复杂性限制，并对现有技术进行了分类和未来展望。

**AI_Comments:** 本文对未调制可见光定位（uVLP）领域进行了全面的综述，其创新之处在于提出了一个结构化的分类框架，并深入分析了现有技术、挑战和未来方向。这对于推动uVLP技术的发展和实际应用具有重要意义，尤其是在6G网络背景下，其成本效益和效率优势使其成为一个极具前景的室内定位解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统可见光定位（VLP）解决方案因调制LED带来的成本增加、操作复杂性以及照明效率降低而面临广泛采用的障碍。为了解决这些限制，研究引入了未调制可见光定位（uVLP）的概念，该技术利用未调制照明源（如常规LED）发出的光信号，提供了一种经济高效、低基础设施的室内定位替代方案。

**Method:** 本文阐述了uVLP的基本原理，对比分析了uVLP与传统VLP方法。它根据接收器技术将现有uVLP技术分为基于强度的方法（如光电二极管、太阳能电池等）和基于成像的方法。此外，论文提出了一种全面的分类法，将技术归类为解复用和未解复用方法。在此框架下，文章批判性地回顾了uVLP的当前进展，讨论了普遍存在的挑战，并概述了开发稳健、可扩展和广泛部署的uVLP解决方案所需的重要研究方向。

**Result:** 本文提供了一个关于uVLP技术的全面概述，包括其基本原理、与传统VLP的比较分析、现有技术的分类（基于接收器技术和解复用/未解复用方法），并总结了当前进展、挑战和未来研究方向。

**Conclusion:** 开发稳健、可扩展和广泛部署的未调制可见光定位（uVLP）解决方案需要进一步的研究，以克服现有挑战并探索有前景的方向。

> **ai_Abstract:** 本文深入探讨了未调制可见光定位（uVLP）技术，该技术旨在克服传统可见光定位（VLP）因LED调制带来的成本和效率问题。uVLP利用未调制照明源的光信号，提供了一种经济高效、低基础设施的室内定位方案。论文详细阐述了uVLP的原理，与传统VLP进行比较，并根据接收器技术（强度基和成像基）和信号处理方法（解复用和未解复用）对现有uVLP技术进行了分类。文章还回顾了当前进展，讨论了挑战，并展望了未来的研究方向，以期推动uVLP的广泛部署。

> **摘要翻译:** 可见光定位（VLP）已成为下一代室内定位系统（IPS）的一项有前景的技术，尤其是在第六代（6G）无线网络的范畴内。它的吸引力源于利用配备发光二极管（LED）的现有照明基础设施，从而实现成本效益高的部署，并在厘米到分米范围内实现高精度定位。然而，传统VLP解决方案的广泛采用面临重大障碍，因为调制LED会增加成本和操作复杂性，从而通过降低其辐射通量来降低照明效率。为了解决这些限制，最近的研究引入了未调制可见光定位（uVLP）的概念，该技术利用由未调制照明源（如传统LED）发出的机会光信号（LSOOP）。这种范式通过消除对调制硬件的需求并保持照明效率，为室内定位提供了一种经济高效、低基础设施的替代方案。本文阐述了uVLP的基本原理，提供了uVLP与传统VLP方法的比较分析，并根据接收器技术将现有uVLP技术分类为基于强度的方法（例如，光电二极管、太阳能电池等）和基于成像的方法。此外，我们提出了一种全面的分类法，将技术归类为解复用和未解复用方法。在这个结构化框架内，我们批判性地回顾了uVLP的当前进展，讨论了普遍存在的挑战，并概述了开发稳健、可扩展和广泛部署的uVLP解决方案所需的重要研究方向。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [177] [Angle Estimation of a Single Source with Massive Uniform Circular Arrays](https://arxiv.org/abs/2507.13086)
> *大规模均匀圆阵单源角度估计*

*Mingyan Gong* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 角度估计, 均匀圆阵, DOA, 实时处理, 非均匀噪声

**Comment:** 

> **TL;DR:** 本文提出了一种用于大规模均匀圆阵的单源二维DOA估计算法，该算法通过计算协方差获得量化方位角，然后通过显式公式获得仰角，具有计算简单、适用于实时处理的特点，且在非均匀噪声下仍有效。

**AI_Comments:** 该论文的创新点在于为大规模均匀圆阵的二维DOA估计提供了一种简化的方法。通过角度量化和协方差比较来获取方位角，并结合显式公式计算仰角，显著降低了计算复杂度。其计算简单性和对非均匀噪声的鲁棒性是关键优势，使其非常适合实时系统，并可作为更复杂算法的有效初始化步骤。

<details>
  <summary>Details</summary>

**Motivation:** 均匀线阵只能提供源方位角估计，而均匀圆阵（UCA）可以提供360°方位覆盖和额外的仰角信息，因此具有吸引力。本文旨在为大规模UCA提出一种简单、计算效率高的二维到达方向（DOA）估计算法。

**Method:** 提出了一种简单的单源二维DOA估计算法，适用于大规模均匀圆阵（UCA）。该方法通过角度量化，利用阵列传感器的极角近似表示360°的方位角。量化的方位角估计通过计算和比较多个协方差获得，随后仰角估计通过一个显式公式得出。

**Result:** 所提出的方法能够获得方位角和仰角估计。这些估计可以作为更高精度方法进行多维搜索的起始点。此外，该方法在存在非均匀噪声的情况下仍然有效。

**Conclusion:** 该方法为大规模均匀圆阵上的单源提供了计算简单且适用于实时处理的二维到达方向（DOA）估计，即使在非均匀噪声下也表现出鲁棒性，并且可以作为高精度方法的良好初始化。

> **ai_Abstract:** 本文提出了一种针对大规模均匀圆阵（UCA）的单源二维到达方向（DOA）估计算法。该方法利用角度量化将阵列传感器的极角近似为方位角，并通过比较协方差获得量化的方位角估计，然后利用显式公式计算仰角。数值结果表明，该方法能够有效估计方位角和仰角，可作为高精度多维搜索方法的起始点，并且在非均匀噪声环境下仍能正常工作，具有计算简单、适用于实时信号处理的优点。

> **摘要翻译:** 到达波方向（DOA）估计是阵列信号处理中的一个重要课题。广泛采用的均匀线阵只能提供源方位角的估计。因此，均匀圆阵（UCA）具有吸引力，因为它们可以提供360°的方位覆盖和额外的仰角信息。考虑到对于大规模UCA，其阵列传感器的极角可以通过角度量化近似表示360°的方位角，本文提出了一种简单的单源二维DOA估计算法。在该方法中，量化的方位角估计仅通过计算和比较一定数量的协方差来获得，然后基于此通过显式公式获得仰角估计。因此，所提出的方法计算简单，适用于实时信号处理。数值结果验证了所提出的方法可以获得方位角和仰角估计，并且这些估计可以用作更高精度方法的多维搜索的起始点。此外，所提出的方法在存在非均匀噪声的情况下仍然可以工作。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [219] [Multifrequency system model for multiport time-modulated scatterers](https://arxiv.org/abs/2507.13130)
> *多频系统模型，用于多端口时变调制散射体*

*Aleksandr D. Kuznetsov, Jari Holopainen, Ville Viikari* | **Category: eess.SP, physics.app-ph** | **Updated: 2025-07-17**

**Keywords:** 多频, 时变调制散射体, 多端口模型, S参数, 可重构智能表面

**Comment:** 11 pages, 11 figures; this work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 提出了一个扩展的多端口S参数模型，用于准确预测多频和时变调制散射结构的散射特性，并通过实验验证了其准确性。

**AI_Comments:** 该论文的创新点在于其提出的多频系统模型对现有S矩阵模型的扩展，使其能够更全面地描述时变调制的多端口散射结构。特别值得注意的是，该模型首次整合了结构散射、互耦、非数字调制和非周期配置等复杂因素，这对于传统方法来说是一个显著的进步。这使得模型能够更精确地分析和优化新兴的通信和传感系统，如RIS和反向散射系统，这些系统通常在多频环境下运行并产生复杂的互调效应。模型的实验验证进一步增强了其在实际应用中的可信度和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型在处理多频操作或产生互调谐波的系统（特别是包含时空调制或动态负载控制的系统）时存在局限性，需要能够同时捕捉多个频率和方向散射行为的先进建模方法。

**Method:** 本文扩展了一个基于多端口S参数的模型，用于预测多频工作结构的散射特性。该模型将方便的S矩阵模型应用于时变调制的多端口结构，并结合了结构散射、互耦、非数字调制以及非周期配置。

**Result:** 针对时空调制散射结构进行的实验结果验证了所提出模型的准确性和实际适用性。

**Conclusion:** 所提出的多频系统模型在预测多频操作和时变调制散射结构的散射特性方面具有准确性和实际适用性。

> **ai_Abstract:** 本文提出了一种扩展的多端口S参数模型，用于预测多频工作和时变调制散射体的散射特性。该模型解决了现有模型在处理多频操作和互调谐波方面的不足，特别适用于可重构智能表面和反向散射系统。其创新之处在于将结构散射、互耦、非数字调制和非周期配置纳入考量，从而能对广泛的通信和传感系统进行精确分析和优化。实验验证表明该模型具有高准确性和实用性。

> **摘要翻译:** 在通信工程中利用散射体，例如可重构智能表面（RIS）和反向散射系统，需要物理一致的模型来进行准确的性能预测。已经为非周期散射体开发了一种多端口模型，该模型也考虑了结构散射。然而，许多新兴系统在多个频率下运行或产生互调谐波，特别是当结合时空调制（STM）或动态负载控制时。这些功能需要先进的建模方法，能够同时捕捉多个频率和方向的散射行为。本文扩展了一个基于多端口S参数的模型，用于预测多频工作结构的散射特性。该模型扩展了方便的S矩阵模型在时变调制多端口结构中的适用性。与已知方法不同，该模型结合了结构散射、互耦、非数字调制以及非周期配置的可能性，从而能够对广泛的通信和传感系统进行精确分析和优化。针对时空调制散射结构进行的实验结果验证了所提出模型的准确性和实际适用性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [254] [Disentangling coincident cell events using deep transfer learning and compressive sensing](https://arxiv.org/abs/2507.13176)
> *使用深度迁移学习和压缩感知解缠结重合细胞事件*

*Moritz Leuthner, Rafael Vorländer, Oliver Hayden* | **Category: eess.SP, q-bio.QM** | **Updated: 2025-07-17**

**Keywords:** 单细胞分析, 深度学习, 压缩感知, 重合事件, 磁流式细胞术

**Comment:** 

> **TL;DR:** 该论文提出了一种结合全卷积神经网络（FCN）和压缩感知（CS）的混合框架，用于准确分离一维传感器数据中重叠的单细胞事件，在不进行再训练的情况下，在真实细胞上表现出优于传统方法的性能，并具有广泛的适用性。

**AI_Comments:** 该论文的创新之处在于将深度迁移学习（FCN的泛化能力）与压缩感知相结合，以解决单细胞分析中的一个具有挑战性的问题。其非光学特性和与各种模式的兼容性使其在未来的诊断平台中具有高度通用性和重要性。可解释性方面也增加了其临床相关性。

<details>
  <summary>Details</summary>

**Motivation:** 准确的单细胞分析对于诊断、免疫监测和细胞治疗至关重要，但重合事件（多个细胞在传感区重叠）会严重损害信号保真度。本研究的动机是克服这一限制。

**Method:** 本文提出了一种混合框架，将全卷积神经网络（FCN）与压缩感知（CS）相结合，以解缠结一维传感器数据中重叠的事件。FCN在珠子衍生数据集上训练，准确估计重合事件计数，并在不重新训练的情况下泛化到全血中的免疫磁性标记CD4+和CD14+细胞。利用此计数，CS模块高保真地重建单个信号分量。

**Result:** 与传统的有限状态机算法相比，该框架表现出卓越的性能，能够恢复多达21%的事件，并将分类准确率提高到97%以上。它能准确估计重合事件计数，并高保真地重建单个细胞特征，包括速度、振幅和流体动力学直径。该方法无需再训练即可泛化到CD4+和CD14+细胞，并且与磁流式细胞术（MFC）以及其他波形生成模式（包括阻抗细胞术、纳米孔和电阻脉冲传感）兼容。

**Conclusion:** 该框架为下一代非光学单细胞传感平台奠定了基础，这些平台具有自动化、通用性和解决重叠事件的能力，拓宽了流式细胞术在转化医学和精准诊断（例如细胞相互作用研究）中的应用。

> **ai_Abstract:** 本文提出了一种新颖的混合框架，利用全卷积神经网络（FCN）和压缩感知（CS）来解决一维传感器数据中的重合细胞事件。FCN在珠子数据上训练，能够准确计数重叠事件并泛化到人类血细胞。随后，CS模块高保真地重建单个细胞信号，从而实现精确的特征恢复。基准测试表明，与传统方法相比，事件恢复和分类准确率显著提高。该框架具有可解释性，与各种非光学传感模式兼容，并为诊断和细胞治疗中的先进单细胞分析铺平了道路。

> **摘要翻译:** 准确的单细胞分析对于诊断、免疫监测和细胞治疗至关重要，但重合事件（即多个细胞在传感区重叠）会严重损害信号保真度。我们提出了一种混合框架，该框架将全卷积神经网络（FCN）与压缩感知（CS）相结合，以解缠结一维传感器数据中此类重叠事件。FCN在珠子衍生数据集上训练，准确估计重合事件计数，并在不重新训练的情况下泛化到全血中的免疫磁性标记CD4+和CD14+细胞。利用此计数，CS模块高保真地重建单个信号分量，从而能够精确恢复单细胞特征，包括速度、振幅和流体动力学直径。与传统的有限状态机算法进行基准测试显示出卓越的性能——恢复多达21%的事件，并将分类准确率提高到97%以上。通过类激活图和参数化高斯模板拟合实现的可解释性确保了透明度和临床可解释性。该框架通过磁流式细胞术（MFC）进行了演示，并且与包括阻抗细胞术、纳米孔和电阻脉冲传感在内的其他波形生成模式兼容。这项工作为下一代非光学单细胞传感平台奠定了基础，这些平台是自动化、通用且能够解决重叠事件的，从而拓宽了流式细胞术在转化医学和精准诊断（例如细胞相互作用研究）中的应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [397] [Fast Variational Block-Sparse Bayesian Learning](https://arxiv.org/abs/2306.00442)
> *快速变分块稀疏贝叶斯学习*

*Jakob Möderl, Erik Leitinger, Bernard H. Fleury, Franz Pernkopf, Klaus Witrisal* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 变分贝叶斯, 块稀疏贝叶斯学习, 快速实现, 广义逆高斯分布, 剪枝

**Comment:** 16 pages, 4 figures, submitted to IEEE Transactions on Signal
  Processing on 1st of June, 2023, Major Revision on Dec. 2023, Resubmission
  Feb 2024, Major Revision Oct. 2024

> **TL;DR:** 提出了一种名为F-BSBL的快速变分块稀疏贝叶斯学习算法，该算法显著提高了运行速度并统一了现有方法。

**AI_Comments:** 这篇论文的创新点在于提出了F-BSBL算法，显著提升了块稀疏贝叶斯学习的运行速度，实现了两个数量级的改进。此外，它通过证明EM-based和VB-based BSBL实现的一致性，为理解和解释现有BSBL方法提供了一个统一的理论框架，这对于该领域的未来研究具有重要意义。固有的剪枝机制也增强了模型的稀疏性。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在提出一种变分贝叶斯（VB）实现的块稀疏贝叶斯学习（BSBL）方法，以计算权重和超参数的近似后验概率密度函数（PDFs），并解决现有BSBL方法的局限性。

**Method:** 论文提出了一种变分贝叶斯（VB）实现的块稀疏贝叶斯学习（BSBL）方法，命名为变分BSBL（VA-BSBL）。该方法选择广义逆高斯分布家族作为超参数的先验分布。受经典稀疏贝叶斯学习（SBL）先前工作的启发，研究了单个权重块及其相关超参数的代理PDFs的更新阶段，从而得到一个非线性一阶递归关系。通过迭代该关系，获得了判断超参数均值序列收敛或发散的准则。将此准则整合到VA-BSBL算法中，实现了快速BSBL（F-BSBL）。此外，还确定了广义逆高斯分布参数的范围，该范围导致模型中“弱”分量被剪枝，以获得稀疏结果。最后，证明了基于期望最大化（EM）和基于VB的BSBL实现是相同的方法。

**Result:** 提出的F-BSBL算法实现了两个数量级的运行时改进。研究确定了广义逆高斯分布参数的特定范围，该范围能够实现模型中“弱”分量的固有剪枝过程。此外，研究证明了基于期望最大化（EM）和基于变分贝叶斯（VB）的BSBL实现是相同的方法，从而将经典SBL的已知结果扩展到BSBL。因此，F-BSBL与使用坐标上升最大化边际似然的BSBL是重合的。这些结果为解释现有BSBL方法提供了一个统一的框架。

**Conclusion:** 论文的结果为解释现有BSBL方法提供了一个统一的框架。

> **ai_Abstract:** 本文提出了一种名为快速变分块稀疏贝叶斯学习（F-BSBL）的新算法，它是块稀疏贝叶斯学习（BSBL）的变分贝叶斯实现。该算法通过引入一个判断超参数均值序列收敛或发散的准则，并在广义逆高斯分布家族中选择超参数先验，显著提高了运行效率，实现了两个数量级的运行时改进。此外，研究还发现特定参数范围能够实现模型中弱分量的固有剪枝，并证明了基于期望最大化和变分贝叶斯的BSBL实现是等同的，从而为现有BSBL方法提供了一个统一的解释框架。

> **摘要翻译:** 我们提出了一种块稀疏贝叶斯学习（BSBL）的变分贝叶斯（VB）实现，用于计算近似权重和相关超参数在块稀疏线性模型中后验概率密度函数（PDFs）的代理PDFs，从而产生一种迭代算法，命名为变分BSBL（VA-BSBL）。超参数的先验被选择为属于广义逆高斯分布家族。该家族包含常用超先验的特殊情况。受经典稀疏贝叶斯学习（SBL）先前工作的启发，我们研究了更新阶段，在该阶段中，单个权重块及其相关超参数的代理PDFs被连续更新，同时保持其他参数的代理PDFs固定。该阶段定义了超参数代理PDF均值的非线性一阶递归关系。通过“无限”迭代该关系，我们获得了一个准则，该准则确定如此生成的超参数均值序列是收敛还是发散。将此准则整合到VA-BSBL算法中，产生了一种快速实现，命名为快速BSBL（F-BSBL），其运行时性能提高了两个数量级。我们进一步确定了广义逆高斯分布参数的范围，该范围导致模型中“弱”分量的固有剪枝过程，这对于获得稀疏结果是必要的。最后，我们表明基于期望最大化（EM）和基于VB的BSBL实现是相同的方法。因此，我们将经典SBL的一个众所周知的结论扩展到了BSBL。因此，F-BSBL和使用坐标上升最大化边际似然的BSBL是重合的。这些结果为解释现有BSBL方法提供了一个统一的框架。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [431] [Globally Optimal Movable Antenna-Enhanced multiuser Communication: Discrete Antenna Positioning, Motion Power Consumption, and Imperfect CSI](https://arxiv.org/abs/2408.15435)
> *全局最优可移动天线增强型多用户通信：离散天线定位、运动功耗和不完美信道状态信息*

*Yifei Wu, Dongfang Xu, Derrick Wing Kwan Ng, Wolfgang Gerstacker, Robert Schober* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 可移动天线, 离散定位, 运动功耗, 不完美CSI, 分支定界, 逐次凸近似

**Comment:** 

> **TL;DR:** 可移动天线（MA）系统在提升空间自由度方面潜力巨大，但其运动功耗、精确位置控制和不完美信道状态信息（CSI）是实际应用中的挑战。本文通过将MA运动建模为离散步骤并量化其功耗，引入了针对MA系统的新型CSI误差模型。研究目标是优化波束成形和MA位置以最小化基站总功耗，同时保证用户服务质量。为此，提出了基于分支定界（BnB）的全局最优算法和基于逐次凸近似（SCA）的低复杂度算法，数值结果验证了其有效性和实用性。

**AI_Comments:** 该论文通过解决可移动天线（MA）系统中的实际挑战，特别是通常被忽视的运动功耗和不完美信道状态信息问题，做出了重要贡献。同时开发了全局最优（BnB）和低复杂度（SCA）算法，为理论理解和实际部署提供了全面的解决方案。这项工作推动了利用MA技术的未来无线通信系统的理解和设计。

<details>
  <summary>Details</summary>

**Motivation:** 可移动天线（MA）通过动态调整天线位置来增强传统多天线系统的空间自由度，具有广阔前景。然而，现有研究在MA系统的功耗、精确位置控制以及实际中难以获得的完美信道状态信息（CSI）方面存在不足，这些是阻碍MA系统实际应用的关键挑战。

**Method:** 本文将可移动天线（MA）元件的运动建模为离散步骤，并量化了相应的运动功耗。针对MA系统特性，引入了一种新颖的CSI误差模型，以支持鲁棒的资源分配设计。研究目标是优化基站的波束成形和MA位置，以最小化包括辐射功率和MA运动功率在内的总基站功耗，同时保证每个用户的最低信干噪比（SINR）。为此，开发了利用分支定界（BnB）方法的新颖算法以获得完美和不完美CSI下的最优解。此外，为了实际实现，提出了利用逐次凸近似（SCA）的低复杂度算法，并保证收敛性。

**Result:** 数值结果验证了所提出的基于分支定界（BnB）算法的最优性。此外，研究发现，所提出的两种基于逐次凸近似（SCA）的算法在几次迭代内即可接近最优性能，这突出了它们的实际应用优势。

**Conclusion:** 本文成功解决了可移动天线（MA）系统中离散定位、运动功耗和不完美信道状态信息（CSI）等关键挑战，并提出了在保证用户服务质量的前提下，最小化基站总功耗的优化框架。通过开发分支定界（BnB）算法实现全局最优解，以及逐次凸近似（SCA）算法实现低复杂度且实用的解决方案，本研究为MA系统的实际部署提供了重要的理论和算法支持。

> **ai_Abstract:** 本文针对可移动天线（MA）系统中的关键挑战，包括离散天线定位、运动功耗和不完美信道状态信息（CSI），提出了全面的解决方案。研究首先将MA元件的运动建模为离散步骤并量化其功耗，随后引入了一种专门针对MA系统的新型CSI误差模型。核心工作是优化波束成形和MA位置，以最小化基站的总功耗（包含辐射功率和MA运动功率），同时保证用户最低的信干噪比。为实现这一目标，作者开发了基于分支定界（BnB）的算法以获得最优解，并提出了基于逐次凸近似（SCA）的低复杂度算法以支持实际应用。数值结果验证了所提出BnB算法的最优性，并显示SCA算法能快速达到接近最优的性能，突显了其在实际应用中的优势。

> **摘要翻译:** 可移动天线（MAs）代表一种有前景的范式，通过动态调整指定传输区域内天线元件的位置，来增强传统多天线系统的空间自由度。特别是，通过使用机电MA驱动器，可以调整MA元件的位置以形成有利的空间相关性，从而提高系统性能。尽管初步研究已经探索了MA系统的波束成形设计，但对功耗和MA元件精确定位的复杂性尚未充分理解。此外，文献中采用的完美CSI假设是不切实际的，因为存在显著的导频开销和获取完美CSI所需的大量时间。为了解决这些挑战，我们将MA元件的运动建模为离散步骤，并将相关的功耗量化为这些运动的函数。此外，通过利用MA信道模型的特性，我们引入了一种专为MA系统量身定制的新型CSI误差模型，有助于鲁棒的资源分配设计。特别是，我们优化了基站的波束成形和MA位置，以最小化基站的总功耗，包括辐射功率和MA运动功率，同时保证每个用户所需的最低SINR。为此，开发了利用分支定界（BnB）方法的新颖算法，以获得完美和不完美CSI下的最优解。此外，为了支持实际实现，我们提出了利用逐次凸近似（SCA）的低复杂度算法，并保证收敛性。我们的数值结果验证了所提出的基于BnB算法的最优性。此外，我们揭示了所提出的两种基于SCA的算法在几次迭代内就能接近最优性能，从而突出了它们的实际优势。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [466] [Rate Splitting Multiple Access for RIS-aided URLLC MIMO Broadcast Channels](https://arxiv.org/abs/2411.11028)
> *速率分裂多址接入用于RIS辅助的URLLC MIMO广播信道*

*Mohammad Soleymani, Ignacio Santamaria, Eduard Jorswieck, Marco Di Renzo, Robert Schober, Lajos Hanzo* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 速率分裂多址接入, 可重构智能表面, 超可靠低延迟通信, MIMO, 有限块长度编码

**Comment:** Accepted at IEEE Transactions on Wireless Communications

> **TL;DR:** 本文研究了在超可靠低延迟通信（URLLC）MIMO广播信道中结合速率分裂多址接入（RSMA）和可重构智能表面（RISs）的性能，发现它们能显著提升频谱效率和能量效率，尤其在严格的可靠性和延迟要求下，且在高用户负载时协同效应更显著。

**AI_Comments:** 该论文探讨了RSMA和RIS这两种前沿技术在URLLC场景下的结合应用，具有重要的理论和实际意义。其创新之处在于将FBL编码引入RIS-aided RSMA方案中，并深入分析了用户负载对RIS和RSMA协同增益的影响。这为未来6G通信系统中干扰管理和性能提升提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现代无线通信系统，特别是超可靠低延迟通信（URLLC）场景，面临严重的干扰问题，需要有效的技术来管理干扰并提升系统性能。

**Method:** 本文为多用户多输入多输出（MIMO）RIS辅助广播信道（BCs）开发了基于有限块长度（FBL）编码的速率分裂多址接入（RSMA）方案。

**Result:** 1. RSMA和RIS能显著提高MIMO RIS辅助URLLC系统的频谱效率（SE）和能量效率（EE）。 2. 当可靠性和延迟约束更严格时，RSMA和RIS的增益显著增加。 3. RIS对RSMA的影响取决于用户负载：在系统欠载时，RIS足以管理干扰，RSMA增益小；但在用户负载高时，RIS和RSMA协同作用显著。

**Conclusion:** RSMA和RIS是解决URLLC系统中干扰问题的有效协同技术，尤其在高用户负载和严格约束下能带来显著性能提升。

> **ai_Abstract:** 本文研究了在超可靠低延迟通信（URLLC）MIMO广播信道中结合速率分裂多址接入（RSMA）和可重构智能表面（RISs）的性能。研究开发了基于有限块长度（FBL）编码的RSMA方案，并证明RSMA与RISs的结合能显著提升系统的频谱效率和能量效率，特别是在严格的可靠性和延迟要求下。结果还表明，在高用户负载时，RSMA和RISs能产生显著的协同增益。

> **摘要翻译:** 现代无线通信系统的性能通常受限于干扰。在超可靠低延迟通信（URLLC）用例中，干扰的影响甚至可能更加严重。速率分裂多址接入（RSMA）是管理干扰的强大工具，它包含了非正交多址接入（NOMA）、空间分割多址接入（SDMA）和广播等多种多址技术。可重构智能表面（RISs）是另一种增强URLLC系统性能和减轻干扰的有效技术。本文为多用户多输入多输出（MIMO）RIS辅助广播信道（BCs）开发了基于有限块长度（FBL）编码的RSMA方案。我们表明，RSMA和RISs可以大幅提高MIMO RIS辅助URLLC系统的频谱效率（SE）和能量效率（EE）。此外，当可靠性和延迟约束更严格时，采用RSMA和RISs的增益会显著增加。此外，RISs对RSMA的影响因用户负载而异。如果系统欠载，RISs能够很好地管理干扰，使得RSMA的增益很小。然而，当用户负载高时，RISs和RSMA变得协同增效。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [509] [A Weighted Hankel Approach and Cramér-Rao Bound Analysis for Quantitative Acoustic Microscopy Imaging](https://arxiv.org/abs/2412.07497)
> *加权Hankel方法和Cramér-Rao界分析在定量声学显微成像中的应用*

*Lorena Leon, Jonathan Mamou, Denis Kouamé, Adrian Basarab* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 定量声学显微镜, 加权Hankel, Cramér-Rao界, 声学参数估计, 生物医学成像

**Comment:** 

> **TL;DR:** 本文提出了一种加权Hankel谱方法来提高定量声学显微（QAM）成像中声学参数估计的鲁棒性，并首次为QAM推导了Cramér-Rao界，以建立理论性能基准。

**AI_Comments:** 本文的创新点在于提出了结合重新加权策略的加权Hankel谱方法，以解决QAM中噪声干扰导致参数估计不准确的问题。更重要的是，首次为QAM引入了Cramér-Rao界分析，为该领域的参数估计性能提供了重要的理论基准。这对于推动QAM在生物医学诊断中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 定量声学显微镜（QAM）在生物组织特性分析中具有重要作用，但其图像处理面临噪声影响和声学参数估计不可靠的问题，需要更稳健的方法来提高精度和可靠性。

**Method:** 本文引入了一种加权Hankel谱方法，并结合了重新加权策略，以增强对噪声的鲁棒性并减少不可靠的声学参数估计。此外，首次在QAM领域推导了Cramér-Rao界，以建立声学参数估计的理论性能基准。

**Result:** 仿真和实验结果表明，所提出的方法在具有挑战性的条件下，始终优于标准的自回归方法。

**Conclusion:** 所提出的加权Hankel方法显著提高了组织表征的准确性和可靠性，增强了定量声学显微镜在生物医学应用中的潜力。

> **ai_Abstract:** 本研究针对定量声学显微镜（QAM）成像中噪声和不可靠参数估计的问题，提出了一种创新的加权Hankel谱方法，结合重新加权策略以提高稳健性。同时，首次为QAM声学参数估计推导了Cramér-Rao界，提供了理论性能上限。实验验证显示，该方法在噪声环境下表现优于传统方法，有望提升QAM在生物医学应用中组织表征的准确性和可靠性。

> **摘要翻译:** 定量声学显微镜（QAM）是一种尖端成像模式，它利用极高频超声波以微观分辨率表征生物组织的声学和机械特性。射频回波信号经过数字化和处理，生成二维图。本文介绍了一种基于加权Hankel的频谱方法，该方法采用重新加权策略，以增强对噪声的鲁棒性并减少不可靠的声学参数估计。此外，我们首次在QAM中推导了Cramér-Rao界，以建立声学参数估计的理论性能基准。仿真和实验结果表明，所提出的方法始终优于标准的自回归方法，特别是在具有挑战性的条件下。这些进展有望提高组织表征的准确性和可靠性，从而增强QAM在生物医学应用中的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [536] [Exploiting Polarization Domain of the IOS for Enhanced Full-Dimensional Transmission](https://arxiv.org/abs/2502.03110)
> *利用IOS的偏振域实现增强的全维度传输*

*Weiqiao Zhu, Zizhou Zheng, Yang Yang, Huan Huang, Weijun Hao, Xiaofei Jia, Hongliang Zhang* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 智能全向表面, 偏振域, 波束成形, 和速率, 全维度传输

**Comment:** 

> **TL;DR:** 本文引入双偏振智能全向表面（IOS）以克服传统功率域IOS折射和反射耦合的限制，通过利用偏振域实现独立的折射和反射模式，并通过联合波束成形最大化和速率，仿真结果验证了其显著的性能提升。

**AI_Comments:** 该论文提出了一种创新的方法，通过引入偏振域来增强智能全向表面（IOS）的性能，有效地解耦了反射和折射行为。这一突破有望为未来的全维度传输开辟新的可能性，并提高频谱效率。同时，对偏振泄漏的考虑增加了研究的实用性和严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 功率域智能全向表面（IOS）辅助系统的性能受到IOS元件折射和反射行为之间紧密耦合的限制，导致服务覆盖和传输效率不足。

**Method:** 本文引入了双偏振IOS辅助通信的概念，通过在IOS设计中采用偏振域，实现完全独立的折射和反射模式。考虑了一个下行链路双偏振IOS辅助系统，并考虑了不同偏振之间的泄漏。为了最大化和速率，将问题建模为一个联合基站（BS）数字和IOS模拟波束成形问题，并提出了一种迭代算法来解决这个非凸程序。

**Result:** 仿真结果验证了双偏振IOS显著优于功率域IOS的性能，实现了增强的全维度传输。

**Conclusion:** 双偏振智能全向表面（IOS）通过有效利用偏振域，成功克服了传统功率域IOS中折射和反射行为耦合的限制，实现了独立的折射和反射模式，从而显著提升了系统的传输性能。

> **ai_Abstract:** 本文提出了一种双偏振智能全向表面（IOS）通信系统，旨在解决传统功率域IOS中折射和反射行为紧密耦合导致的性能限制。通过利用偏振域，该系统能够实现独立的折射和反射模式。研究人员构建了一个下行链路双偏振IOS辅助系统模型，并考虑了不同偏振间的泄漏。为最大化系统和速率，论文将问题表述为联合基站数字和IOS模拟波束成形问题，并开发了一种迭代算法进行求解。仿真结果表明，与功率域IOS相比，双偏振IOS显著提升了系统性能。

> **摘要翻译:** 智能全向表面（IOS）能够以反射和折射方式为移动用户（MU）提供服务覆盖，最近引起了广泛关注。然而，功率域IOS辅助系统的性能受到IOS元件折射和反射行为之间紧密耦合的限制。在本文中，我们引入了双偏振IOS辅助通信的概念来克服这一挑战。通过在IOS设计中采用偏振域，可以实现完全独立的折射和反射模式。我们考虑了一个下行链路双偏振IOS辅助系统，同时考虑了不同偏振之间的泄漏。为了最大化和速率，我们提出了一个联合基站（BS）数字和IOS模拟波束成形问题，并提出了一种迭代算法来解决这个非凸程序。仿真结果验证了双偏振IOS显著优于功率域IOS的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [571] [Performance Analysis of Multi-IRS Aided Multiple Operator Systems at mmWave Frequencies](https://arxiv.org/abs/2503.06596)
> *毫米波频率下多IRS辅助多运营商系统的性能分析*

*Souradeep Ghosh, L. Yashvanth, Chandra R. Murthy* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 智能反射面, 毫米波, 多运营商, 频谱效率, 合作

**Comment:** Accepted for publication in IEEE Transactions on Communications

> **TL;DR:** 该论文分析了毫米波频率下多IRS辅助多运营商系统的性能。研究发现，即使没有运营商间的合作，每个运营商也可以独立控制其IRS，并且其他运营商IRS的存在不会降低其性能，而联合优化带来的增益在实践中是微不足道的。

**AI_Comments:** 该论文在实际的多运营商IRS部署场景中提供了有价值的见解，揭示了即使在多运营商环境下，每个运营商也能相对独立地管理其IRS，而无需复杂的跨运营商协作，这对于未来IRS的实际部署具有重要的指导意义。其创新之处在于针对多运营商共存场景下的IRS相互影响进行了量化分析，并得出了支持独立操作的结论。

<details>
  <summary>Details</summary>

**Motivation:** 智能反射面（IRS）有望增强毫米波无线系统的性能。在实际中，多个移动运营商（MO）在同一区域共存并为用户设备（UE）提供独立服务。如果每个MO都部署IRS来增强其性能，这些IRS也会改变其他MO的用户信道。因此，本文旨在探讨一个MO是否仍能独立于其他MO和IRS控制其IRS，以及是否需要不同MO部署的IRS进行联合优化和MO间合作。

**Method:** 研究首先通过考虑毫米波频段，推导了在以下方案下2个MO系统的遍历和频谱效率（SE）：1）IRS整体相位的联合优化与MO合作；2）通过时分复用实现MO合作；3）MO之间无合作。随后，将结果推广到多MO设置，并通过数值验证了研究发现。

**Result:** 研究发现，即使MO之间没有合作，给定MO的性能也不会因部署和独立控制其IRS的带外（OOB）MO的存在而降低。另一方面，给定MO通过联合优化和合作相对于无合作方案获得的SE增益与另一个MO部署的IRS中的元件数量成反比。对于多MO设置，和SE相对于无合作情况的增益至少与OOB MO的数量呈线性增加。

**Conclusion:** 每个MO都可以独立操作和调整其IRS；通过优化整体相位进行的合作在实践中仅带来微不足道的收益。

> **ai_Abstract:** 本论文分析了毫米波频率下多智能反射面（IRS）辅助多运营商（MO）系统的性能，特别关注在多运营商共存环境下，独立部署IRS所带来的影响。通过推导2个MO系统及推广到多MO设置的遍历和频谱效率（SE），并比较了联合优化、时分复用和无合作等方案，研究得出结论：运营商可以很大程度上独立控制其IRS，而不会因其他运营商IRS的存在而显著降低性能。此外，研究还表明，运营商间的合作，尤其是通过整体相位优化实现的合作，在实践中仅能带来微不足道的收益。

> **摘要翻译:** 智能反射面（IRS）有望增强毫米波无线系统的性能。在实践中，多个移动运营商（MO）在同一区域共存，并在不同频段上向用户设备（UE）提供同步和独立的服务。那么，如果每个MO都部署一个IRS来增强其性能，这些IRS也会改变其他MO的用户信道。在这种背景下，本文解决了以下问题：一个MO是否仍能独立于其他MO和IRS控制其IRS？是否需要不同MO部署的IRS进行联合优化和MO间合作？为此，通过考虑毫米波频段，我们首先推导了在以下方案下2个MO系统的遍历和频谱效率（SE）：1）IRS整体相位的联合优化与MO合作；2）通过时分复用实现MO合作；3）MO之间无合作。我们发现，即使MO之间没有合作，给定MO的性能也不会因部署和独立控制其IRS的带外（OOB）MO的存在而降低。另一方面，给定MO通过联合优化和合作相对于无合作方案获得的SE增益与另一个MO部署的IRS中的元件数量成反比。我们将结果推广到多MO设置，并表明和SE相对于无合作情况的增益至少与OOB MO的数量呈线性增加。最后，我们对研究发现进行了数值验证，并得出结论：每个MO都可以独立操作和调整其IRS；通过优化整体相位进行的合作在实践中仅带来微不足道的收益。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [611] [Context-Aware Deep Learning for Robust Channel Extrapolation in Fluid Antenna Systems](https://arxiv.org/abs/2507.04435)
> *流体天线系统中用于鲁棒信道外推的上下文感知深度学习*

*Yanliang Jin, Runze Yu, Yuan Gao, Shengli Liu, Xiaoli Chu, Kai-Kit Wong, Chan-Byoung Chae* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** 流体天线系统, 信道外推, 深度学习, 上下文感知, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了CANet，一个基于深度学习的鲁棒模型，用于解决流体天线系统（FAS）中获取高分辨率信道状态信息（CSI）所面临的巨大开销问题，并通过仿真验证了其优越性能。

**AI_Comments:** 这篇论文通过将深度学习与新颖的扰动增强策略相结合，为流体天线系统中的信道外推提供了一个鲁棒且高效的解决方案。其创新点在于借鉴了图像处理领域的频域增强思想来提升通信系统中信道估计的鲁棒性，这为解决无线通信中的CSI获取挑战开辟了新的视角，具有重要的研究价值和潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 流体天线系统（FAS）在获取高分辨率信道状态信息（CSI）时面临巨大开销，这限制了其空间灵活性，因此需要一种更高效和鲁棒的信道外推方法。

**Method:** 本文提出了CANet模型，它结合了上下文自适应建模和跨尺度注意力机制，并以ConvNeXt v2作为骨干网络，以提高未观测天线端口的外推精度。为了增强鲁棒性，引入了受图像处理频域增强技术启发的新颖空间幅度扰动策略，并结合傅里叶域损失函数（捕获频域一致性）和频谱结构一致性损失（在扰动下增强学习稳定性）。

**Result:** 仿真结果表明，CANet在广泛的信噪比（SNR）水平下，其性能优于各种基准模型。

**Conclusion:** CANet能够有效地解决流体天线系统中高分辨率CSI获取的挑战，并提供鲁棒、准确的信道外推能力。

> **ai_Abstract:** 本文提出了一种名为CANet的深度学习模型，旨在解决流体天线系统（FAS）中获取高分辨率信道状态信息（CSI）所带来的巨大开销问题。CANet通过结合上下文自适应建模、跨尺度注意力机制和ConvNeXt v2骨干网络来提高外推精度，并通过引入空间幅度扰动策略、傅里叶域损失和频谱结构一致性损失来增强模型的鲁棒性和学习稳定性。仿真结果验证了CANet在不同信噪比条件下均优于现有基准模型。

> **摘要翻译:** 流体天线系统（FAS）提供了卓越的空间灵活性，但在获取高分辨率信道状态信息（CSI）方面面临重大挑战，导致相当大的开销。为了解决这个问题，我们提出了CANet，一个用于FAS中信道外推的鲁棒深度学习模型。CANet将上下文自适应建模与跨尺度注意力机制相结合，并构建在ConvNeXt v2骨干网络上，以提高未观测天线端口的外推精度。为了进一步增强鲁棒性，我们引入了一种新颖的空间幅度扰动策略，其灵感来源于图像处理中的频域增强技术。这促使我们结合傅里叶域损失函数（捕获频域一致性）以及频谱结构一致性损失（在扰动下增强学习稳定性）。我们的仿真结果表明，CANet在广泛的信噪比（SNR）水平下优于基准模型。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [657] [DSSD: Efficient Edge-Device LLM Deployment and Collaborative Inference via Distributed Split Speculative Decoding](https://arxiv.org/abs/2507.12000)
> *DSSD：通过分布式分割推测解码实现高效边缘设备LLM部署和协同推理*

*Jiahong Ning, Ce Zheng, Tingting Yang* | **Category: eess.SP** | **Updated: 2025-07-17**

**Keywords:** LLM部署, 边缘计算, 推测解码, 分布式推理, 通信优化

**Comment:** ICML 2025

> **TL;DR:** DSSD是一种新的架构，通过分布式分割推测解码，解决了大型语言模型（LLM）在边缘设备部署时面临的资源限制和通信开销问题，显著降低了通信延迟并保持了推理质量。

**AI_Comments:** DSSD的创新之处在于其对推测解码验证阶段的分布式处理，通过将验证任务在设备和边缘之间分割，并优化通信方式（用单次下行传输替代多次上行），有效地解决了LLM在边缘设备部署中的关键瓶颈——通信延迟和准确性权衡问题。这对于资源受限的边缘计算环境具有重要意义，因为它能够在不牺牲推理质量的前提下提高效率。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在设备-边缘系统中的部署面临资源限制和通信开销的严峻挑战。现有结合小型语言模型（SLM）和LLM的协同推理框架虽然使用推测解码（SD）提高效率，但往往以牺牲推理准确性为代价，或者在验证候选tokens时产生高昂的上行传输成本。

**Method:** 本文提出了分布式分割推测解码（DSSD），这是一种新颖的架构，它不仅保留了SLM-LLM的分割，还将验证阶段在设备和边缘之间进行分区。通过这种方式，DSSD用单次下行传输取代了多次词汇分布的上行传输。

**Result:** DSSD显著降低了通信延迟，同时保持了推理质量。实验表明，我们的解决方案优于现有方法。

**Conclusion:** DSSD通过优化验证阶段的通信方式，有效解决了LLM在边缘设备部署中的效率和质量问题，实现了高效的LLM部署和协同推理。

> **ai_Abstract:** DSSD（分布式分割推测解码）是一种针对大型语言模型（LLM）在边缘设备部署的新型协同推理架构。它解决了现有方案中资源限制、通信开销以及上行传输成本高的问题。DSSD通过在设备和边缘之间分区验证阶段，并用一次下行传输替代多次上行传输，显著降低了通信延迟，同时保持了推理质量。实验证明，DSSD优于现有方法。

> **摘要翻译:** 大型语言模型（LLM）已经改变了自然语言处理，但由于资源限制和通信开销，在设备-边缘系统中面临关键的部署挑战。为了解决这些问题，出现了协同框架，将设备上的小型语言模型（SLM）与边缘的LLM结合起来，使用推测解码（SD）来提高效率。然而，现有解决方案通常以推理准确性换取延迟，或者在验证候选tokens时遭受高昂的上行传输成本。在本文中，我们提出了分布式分割推测解码（DSSD），这是一种新颖的架构，它不仅保留了SLM-LLM的分割，而且还在设备和边缘之间划分了验证阶段。通过这种方式，DSSD用单次下行传输取代了多次词汇分布的上行传输，显著降低了通信延迟，同时保持了推理质量。实验表明，我们的解决方案优于现有方法，代码可在：https://github.com/JasonNing96/DSSD-Efficient-Edge-Computing

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [675] [Achieving Robust Channel Estimation Neural Networks by Designed Training Data](https://arxiv.org/abs/2507.12630)
> *通过设计训练数据实现鲁棒信道估计神经网络*

*Dianxin Luan, John Thompson* | **Category: eess.SP, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 信道估计, 神经网络, 鲁棒性, 训练数据, 无线通信

**Comment:** Accepted by IEEE Transactions on Cognitive Communications and
  Networking (TCCN)

> **TL;DR:** 本文提出了一种设计训练数据的方法，使神经网络能够在未知无线信道上实现鲁棒的信道估计，无需在线训练或先验信道信息。

**AI_Comments:** 本文为在动态无线环境中部署数据驱动方法提供了一个实用的解决方案。通过专注于鲁棒的训练数据设计而非在线微调，它解决了低延迟和资源有限的实际约束。泛化能力与架构无关的发现尤其具有洞察力，简化了部署考量。

<details>
  <summary>Details</summary>

**Motivation:** 在认知通信中，神经网络进行信道估计时常在未训练过的新信道上性能下降，因为它们无法外推训练知识。同时，由于低延迟和有限计算资源，神经网络无法进行在线训练。这促使研究设计离线训练的神经网络，使其在设计时无需任何实际信道信息即可在无线信道上鲁棒运行。

**Method:** 本文提出了生成神经网络合成训练数据集的设计标准，以确保训练后的网络在新的和未见信道上达到一定的均方误差（MSE）。此外，还提出了一个基准设计，以确保对不同信道配置的智能操作。

**Result:** 仿真结果表明，使用所提出方法训练的神经网络对具有固定信道配置和可变延迟扩展的无线信道都实现了鲁棒的泛化。并且，所实现的泛化能力似乎与神经网络架构无关。

**Conclusion:** 所提出的方法使得神经网络信道估计解决方案能够在实际应用中鲁棒部署，无需先验信道信息或在线参数更新。

> **ai_Abstract:** 本文解决了认知通信中神经网络信道估计模型在未见信道上性能下降且在线训练不切实际的挑战。作者提出了一种新颖的设计标准，用于生成合成训练数据集，使离线训练的神经网络能够在新的无线信道上实现鲁棒性能（保证均方误差），而无需先验信道信息或实时更新。该方法的有效性通过仿真得到验证，显示出对各种信道配置的鲁棒泛化能力，并且与网络架构无关。

> **摘要翻译:** 信道估计在认知通信中至关重要，因为它通过提供准确的当前信道状态信息，实现智能频谱感知和自适应传输。然而，在许多论文中，神经网络通常在单个示例信道或相似信道上进行训练和测试。这是因为数据驱动方法在未经训练的新数据上性能常常下降，因为它们无法外推其训练知识。尽管物理信道通常被认为是时变的。然而，由于低延迟要求和有限的计算资源，神经网络可能没有足够的时间和计算资源执行在线训练来微调参数。这促使我们设计离线训练的神经网络，使其能够在无线信道上鲁棒地运行，而在设计时无需任何实际信道信息。在本文中，我们提出了生成神经网络合成训练数据集的设计标准，这些标准保证训练后的网络在新的和以前未见的信道上达到一定的均方误差（MSE）。因此，神经网络解决方案在实际实现中不需要先验信道信息或参数更新。基于所提出的设计标准，我们进一步提出了一个基准设计，确保了对不同信道配置的智能操作。为了证明其普遍适用性，我们使用不同复杂度的神经网络来表明所实现的泛化能力似乎与神经网络架构无关。从仿真结果来看，神经网络对具有固定信道配置和可变延迟扩展的无线信道都实现了鲁棒的泛化。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [703] [Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS](https://arxiv.org/abs/2507.12593)
> *Zak-OTFS中移动和时延扩展信道下的差分通信*

*Sandesh Rao Mattu, Nishant Mehrotra, Robert Calderbank* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-16**

**Keywords:** Zak-OTFS, 差分通信, 时延-多普勒, 导频传输, 频谱效率

**Comment:** 6 pages, 4 figures, submitted to IEEE Wireless Communications Letters
  for possible publication. Copyright maybe transferred without notice

> **TL;DR:** 本文提出了一种Zak-OTFS系统中的差分通信方案，通过利用已检测数据作为导频，消除了对周期性导频传输的需求，从而提高了能量效率、频谱效率并降低了复杂度。

**AI_Comments:** 该论文的创新点在于提出了Zak-OTFS系统中的差分通信方案，巧妙地利用已检测数据作为导频，从而避免了周期性导频传输。这在移动和时延扩展信道中尤其重要，因为信道变化快。该方法通过提高能量效率和频谱效率，同时降低系统复杂度和提高性能，为未来无线通信系统提供了有价值的思路。

<details>
  <summary>Details</summary>

**Motivation:** 即使是基于Zak变换的正交时频空间（Zak-OTFS）系统，也需要周期性地发送导频信号，尽管速率较低。本文的动机是消除Zak-OTFS系统中对周期性导频传输的需求。

**Method:** 本文提出了一种用于Zak-OTFS系统的差分通信方案。该方案分析表明，检测到的数据可以作为导频使用，并且从检测到的数据获得的信道估计可以支持进一步的检测，从而实现通信的“差分”特性。具体来说，该方法利用Zak-OTFS中DD信道的预测能力，使用前一时刻的信道估计（通过将检测到的数据符号视为导频获得）来检测下一时刻的数据，并向前传播。

**Result:** 该方案具有双重优势：首先，它允许数据符号获得更高的能量，因为原本用于导频符号的能量也可以分配给数据符号；其次，与点或嵌入式导频相比，它实现了全频谱效率。与实现全频谱效率的扩频导频方案相比，所提出的方法在较低复杂度下实现了更好的误码率。

**Conclusion:** 本文提出的Zak-OTFS差分通信方案通过利用检测到的数据作为导频，成功消除了对周期性导频传输的需求，从而显著提高了数据符号的能量利用率、实现了全频谱效率，并在较低复杂度下获得了更优的误码率性能。

> **ai_Abstract:** 本文提出了一种针对Zak-OTFS系统的差分通信方案，旨在消除对周期性导频传输的需求。该方案利用已检测数据作为导频来估计信道，并利用DD信道的预测能力将前一时刻的信道估计用于下一时刻的数据检测。这种方法不仅提高了数据符号的能量效率，实现了全频谱效率，而且与现有扩频导频方案相比，在较低复杂度下取得了更优的误码率性能。

> **摘要翻译:** 基于Zak变换的正交时频空间（Zak-OTFS）是一种时延-多普勒（DD）域调制方案，其中信号处理在DD域中进行。当在DD域中观察时，信道是可预测的。然而，即使使用Zak-OTFS，也需要周期性地发送导频，尽管速率较低。在本文中，我们提出了一种用于Zak-OTFS系统的差分通信方案，以消除周期性导频传输的需求。为此，我们分析表明，检测到的数据可以用作导频，并且从检测到的数据获得的信道估计可以支持进一步的检测，从而实现通信的“差分”特性。具体来说，我们利用Zak-OTFS中DD信道的预测能力，使用前一时刻的信道估计（通过将检测到的数据符号视为导频获得）来检测下一时刻的数据，并向前传播。这样做有双重优势。首先，它允许数据符号获得更高的能量，因为原本用于导频符号的能量也可以分配给数据符号。其次，与点或嵌入式导频相比，它允许实现全频谱效率。与实现全频谱效率的扩频导频方案相比，所提出的方法在较低复杂度下实现了更好的误码率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [7] [InSight: AI Mobile Screening Tool for Multiple Eye Disease Detection using Multimodal Fusion](https://arxiv.org/abs/2507.12669)
> *InSight：使用多模态融合进行多种眼病检测的AI移动筛查工具*

*Ananya Raghu, Anisha Raghu, Alice S. Tang, Yannis M. Paulus, Tyson N. Kim, Tomiko T. Oskotsky* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-16**

**Keywords:** 多模态融合, 眼病筛查, 糖尿病视网膜病变, AI诊断, 移动医疗

**Comment:** 

> **TL;DR:** InSight是一款AI驱动的移动应用，结合患者元数据和眼底图像，实现五种常见眼病的早期、准确筛查，尤其适用于资源有限地区。

**AI_Comments:** 该论文提出了一种创新的AI移动筛查工具InSight，其核心创新点在于多模态融合技术（MetaFusion），将临床元数据与眼底图像结合，显著提升了诊断准确性。此外，多任务学习模型的应用不仅能同时诊断多种疾病，还大大提高了计算效率，使其适用于移动设备和资源受限环境。这对于解决全球眼病筛查可及性问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全球数亿人受年龄相关性黄斑变性、青光眼、糖尿病视网膜病变等眼病影响。早期筛查至关重要，但在中低收入国家和资源有限地区，医疗服务可及性受限。

**Method:** InSight采用三阶段流程：实时图像质量评估、疾病诊断模型和DR分级模型。疾病诊断模型包含三项创新：(a) 多模态融合技术(MetaFusion)结合临床元数据和图像；(b) 利用监督和自监督损失函数进行预训练；(c) 同时预测五种疾病的多任务模型。使用BRSET（实验室采集）和mBRSET（智能手机采集）数据集进行训练和评估，这些数据集均包含临床元数据。

**Result:** 图像质量检查器在过滤低质量眼底图像方面达到近100%的准确率。多模态预训练疾病诊断模型在BRSET数据集上的平衡准确率比仅使用图像的模型高6%，在mBRSET数据集上高4%。

**Conclusion:** InSight管线在不同图像条件下表现出鲁棒性，对所有五种疾病均具有高诊断准确性，并能泛化到智能手机和实验室采集的图像。多任务模型使管线轻量化，计算效率是五个独立模型的五倍。

> **ai_Abstract:** InSight是一款创新的AI移动应用，旨在通过结合患者临床元数据和眼底图像的多模态融合技术，实现对五种常见眼病（如年龄相关性黄斑变性、青光眼、糖尿病视网膜病变等）的早期、准确诊断。该应用采用三阶段管线，包含图像质量评估、疾病诊断和DR分级。其核心创新在于多模态融合、预训练方法和多任务学习，显著提高了诊断准确性（比仅图像模型高4-6%）和计算效率。InSight的鲁棒性和轻量化特性使其特别适用于资源有限地区的眼病筛查，提升了医疗可及性。

> **摘要翻译:** 背景/目标：年龄相关性黄斑变性、青光眼、糖尿病视网膜病变（DR）、糖尿病性黄斑水肿和病理性近视影响着全球数亿人。这些疾病的早期筛查至关重要，然而在中低收入国家以及资源有限的环境中，医疗服务的可及性仍然有限。我们开发了InSight，一个基于AI的应用程序，它将患者元数据与眼底图像结合起来，用于准确诊断五种常见眼病，以提高筛查的可及性。
方法：InSight具有三阶段流程：实时图像质量评估、疾病诊断模型和评估严重程度的DR分级模型。我们的疾病诊断模型包含了三项关键创新：(a) 结合临床元数据和图像的多模态融合技术（MetaFusion）；(b) 利用监督和自监督损失函数进行预训练的方法；(c) 同时预测五种疾病的多任务模型。我们使用了BRSET（实验室采集图像）和mBRSET（智能手机采集图像）数据集，这两个数据集也都包含用于模型训练/评估的临床元数据。
结果：在BRSET和mBRSET图像数据集上训练后，图像质量检查器在过滤低质量眼底图像方面实现了接近100%的准确率。多模态预训练的疾病诊断模型在BRSET数据集上的平衡准确率比仅使用图像的模型高6%，在mBRSET数据集上高4%。
结论：InSight管线在各种图像条件下均表现出鲁棒性，对所有五种疾病都具有高诊断准确性，并能泛化到智能手机和实验室采集的图像。多任务模型有助于管线的轻量化，使其计算效率比对应每种疾病的五个独立模型高出五倍。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [39] [RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions](https://arxiv.org/abs/2505.12887)
> *RetinaLogos：通过描述文字细粒度合成高分辨率视网膜图像*

*Junzhi Ning, Cheng Tang, Kaijing Zhou, Diping Song, Lihao Liu, Ming Hu, Wei Li, Huihui Xu, Yanzhou Su, Tianbin Li, Jiyao Liu, Jin Ye, Sheng Zhang, Yuanfeng Ji, Junjun He* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 视网膜图像合成, 细粒度控制, 带描述文字数据集, 机器学习, 眼科学

**Comment:** 

> **TL;DR:** RetinaLogos是一种新颖的方法，通过利用大规模带描述文字的数据集和三步训练框架，实现高分辨率视网膜图像的细粒度合成，有效缓解了高质量标注数据稀缺的问题，并显著提升了眼科机器学习模型的性能。

**AI_Comments:** 该论文的创新点在于提出了一个通过视觉语言模型创建大规模带描述文字视网膜数据集的方法，并在此基础上开发了一个能实现细粒度图像合成的训练框架。这有效解决了眼科领域高质量标注数据稀缺的痛点，为机器学习模型在眼科疾病诊断方面的发展提供了重要支持。其能够生成高度逼真且具有临床价值的合成数据，对推动医疗影像AI研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高质量、标注的视网膜成像数据稀缺，严重阻碍了眼科机器学习模型的发展。现有合成方法主要依赖预定义的疾病标签，限制了其生成反映细粒度解剖变异、微妙疾病阶段和多样病理特征的能力。

**Method:** 首先引入了一个名为RetinaLogos-1400k的大规模（140万条）带描述文字的视网膜数据集，该数据集使用视觉语言模型（VLM）描述视网膜状况和关键结构。在此数据集基础上，采用了一个新颖的三步训练框架RetinaLogos，实现对视网膜图像的细粒度语义控制。

**Result:** 在多项数据集上表现出卓越性能，62.07%的文本驱动合成CFP图像被眼科医生认为与真实图像无法区分。此外，合成数据使糖尿病视网膜病变分级和青光眼检测的准确率提高了5%-10%。

**Conclusion:** RetinaLogos通过细粒度合成高质量视网膜图像有效解决了数据稀缺问题，显著提高了眼科机器学习模型的性能。

> **ai_Abstract:** 该论文针对高质量标注视网膜图像数据稀缺的问题，提出了一种名为RetinaLogos的框架，用于通过描述文字细粒度合成高分辨率视网膜图像。为此，研究者首先构建了一个包含140万条记录的大规模带描述文字的视网膜数据集RetinaLogos-1400k，该数据集利用视觉语言模型（VLM）描述视网膜的详细情况。在此基础上，开发了一个新颖的三步训练框架RetinaLogos，实现了对合成图像精细的语义控制，能准确捕捉疾病进展和解剖变异。实验结果表明，该方法生成的合成图像有62.07%能被眼科医生认为是真实的，并且能将糖尿病视网膜病变分级和青光眼检测的准确率提高5%-10%。

> **摘要翻译:** 高质量、标注的视网膜成像数据稀缺，给眼科机器学习模型的开发带来了巨大挑战，阻碍了该领域的进展。现有彩色眼底照片（CFP）合成方法大多依赖预定义的疾病标签，这限制了它们生成能够反映细粒度解剖变异、微妙疾病阶段以及超出粗略类别之外的多种病理特征的能力。为了克服这些挑战，我们首先引入了一个创新的流程，创建了一个大规模的、带描述文字的视网膜数据集，包含140万条记录，命名为RetinaLogos-1400k。具体而言，RetinaLogos-1400k使用视觉语言模型（VLM）来描述视网膜状况和关键结构，例如视盘配置、血管分布、神经纤维层和病理特征。在此数据集的基础上，我们采用了一种新颖的三步训练框架——RetinaLogos，该框架能够对视网膜图像进行细粒度语义控制，并准确捕捉疾病进展的不同阶段、细微的解剖变异和特定病变类型。通过广泛的实验，我们的方法在多个数据集上表现出卓越的性能，其中62.07%的文本驱动合成CFP图像被眼科医生认为与真实图像无法区分。此外，合成数据使糖尿病视网膜病变分级和青光眼检测的准确率提高了5%-10%。代码可在https://github.com/uni-medical/retina-text2cfp 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [84] [BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia](https://arxiv.org/abs/2506.23305)
> *BPD-Neo：一个用于新生儿支气管肺发育不良肺气管分割的MRI数据集及临床数据*

*Rachit Saluja, Arzu Kovanlikaya, Candace Chien, Lauren Kathryn Blatt, Jeffrey M. Perlman, Stefan Worgall, Mert R. Sabuncu, Jonathan P. Dyke* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 支气管肺发育不良, MRI数据集, 肺气管分割, 新生儿, 临床数据

**Comment:** Adding link to Zenodo repo for dataset

> **TL;DR:** BPD-Neo是一个新的MRI数据集，包含40名新生儿的肺和气管分割图像及临床数据，旨在促进新生儿支气管肺发育不良的研究。

**AI_Comments:** 该论文的创新之处在于构建了一个专门用于新生儿BPD肺部MRI图像分割的大型数据集，这对于推动非侵入性诊断方法的发展和深入理解BPD的病理机制至关重要。提供临床数据和基线模型进一步提升了其实用性和研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的X射线成像在诊断新生儿支气管肺发育不良（BPD）时存在局限性。肺部MRI作为一种非侵入性替代方案，能避免镇静和辐射，并提供更详细的BPD潜在机制信息。开发先进的图像处理和语义分割算法需要高质量的3D MRI数据来辅助临床医生识别BPD病因。

**Method:** 本研究构建了一个包含40名新生儿的MRI数据集，其中大多数诊断为BPD。数据包括自由呼吸3D星形径向梯度回波采集（StarVIBE系列）的MRI扫描图像，以及对应的肺和气管语义分割。此外，还提供了全面的临床数据和经临床评估验证的基线分割模型。

**Result:** 提出了BPD-Neo数据集，该数据集包含40名新生儿的MRI图像、肺和气管的语义分割，以及综合临床数据和基线分割模型。

**Conclusion:** 该数据集旨在支持新生儿肺部成像领域的进一步研究和开发，以协助临床医生识别支气管肺发育不良的病因。

> **ai_Abstract:** 本文介绍了BPD-Neo数据集，这是一个专为新生儿支气管肺发育不良（BPD）研究设计的新型MRI数据集。该数据集包含40名新生儿（多数为BPD患者）的肺部MRI扫描图像及其对应的肺和气管语义分割。MRI数据采用自由呼吸3D StarVIBE系列采集。此外，数据集中还提供了全面的临床信息和已验证的基线分割模型，旨在促进利用MRI进行新生儿BPD诊断和机制研究的图像处理与算法开发。

> **摘要翻译:** 支气管肺发育不良（BPD）是早产儿常见的并发症，便携式X射线成像在新生儿重症监护室（NICU）中作为标准诊断方式。然而，肺部磁共振成像（MRI）提供了一种非侵入性替代方案，可避免镇静和辐射，同时能深入了解BPD的潜在机制。利用高分辨率3D MRI数据，可以开发先进的图像处理和语义分割算法，以协助临床医生识别BPD的病因。在该数据集中，我们展示了40名新生儿的MRI扫描图像及其对应的肺和气管语义分割，其中大多数新生儿被诊断为BPD。成像数据由自由呼吸3D星形径向梯度回波采集（称为StarVIBE系列）组成。此外，我们还提供了全面的临床数据和经临床评估验证的基线分割模型，以支持新生儿肺部成像的进一步研究和开发。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [130] [Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT](https://arxiv.org/abs/2507.08214)
> *深度序列Transformer (DST) 用于非造影CT上节段特异性ICA钙化映射*

*Xiangjian Hou, Ebru Yaman Akcicek, Xin Wang, Kazem Hashemizadeh, Scott Mcnally, Chun Yuan, Xiaodong Ma* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-16**

**Keywords:** 深度序列Transformer, 颅内颈动脉钙化, 节段特异性, 地标定位, 非造影CT

**Comment:** 

> **TL;DR:** 本文提出了一种深度序列Transformer (DST) 框架，通过将3D CT体积处理为2D切片序列，实现了对非造影CT上颅内颈动脉钙化 (ICAC) 的节段特异性量化，解决了传统方法无法处理全局上下文的问题，并取得了高精度。

**AI_Comments:** 本文的创新点在于将复杂的3D定位问题巧妙地重构为1D轴向上的并行概率地标定位任务，并引入了深度序列Transformer (DST) 架构来处理全分辨率CT序列，有效解决了传统方法在处理全局上下文方面的局限性。其提出的DST框架在准确性和鲁棒性方面表现出色，为临床上实现自动化的节段特异性ICAC分析提供了突破性的实用工具，对于中风风险评估和手术规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虽然总颅内颈动脉钙化 (ICAC) 体积是已确定的中风生物标志物，但越来越多的证据表明，这一聚合指标忽略了斑块位置的关键影响，因为不同节段的钙化具有不同的预后和手术风险。然而，更精细的、节段特异性的量化在技术上仍然不可行。传统的3D模型被迫处理降采样体积或孤立的补丁，牺牲了解决解剖模糊和实现可靠地标定位所需的全局上下文。

**Method:** 本文将3D挑战重新定义为沿1D轴向维度的“并行概率地标定位”任务。提出了“深度序列Transformer (DST)”框架，该框架将全分辨率CT体积处理为2D切片序列，学习预测N=6个独立的概率分布，以精确定位关键解剖地标。

**Result:** DST框架在100名患者的临床队列上，通过严格的5折交叉验证评估，实现了0.1切片的平均绝对误差 (MAE)，96%的预测落在±1切片容差内。此外，DST骨干在公共Clean-CC-CCII分类基准上，在端到端评估协议下取得了最佳结果。

**Conclusion:** 本文的工作提供了第一个用于自动化节段特异性ICAC分析的实用工具。所提出的框架为进一步研究位置特异性生物标志物在诊断、预后和手术规划中的作用奠定了基础。

> **ai_Abstract:** 本文针对现有颅内颈动脉钙化 (ICAC) 量化方法无法提供节段特异性分析且牺牲全局上下文的问题，提出了一种名为深度序列Transformer (DST) 的新框架。DST将3D CT体积视为2D切片序列，并通过“并行概率地标定位”任务预测关键解剖地标。该方法在临床队列中表现出高精度和鲁棒性，MAE为0.1切片，96%的预测在±1切片容差内，并在公共基准上取得最佳结果。DST提供了首个实用的自动化节段特异性ICAC分析工具，为基于位置的生物标志物研究奠定基础。

> **摘要翻译:** 虽然总颅内颈动脉钙化 (ICAC) 体积是已确定的中风生物标志物，但越来越多的证据表明，这一聚合指标忽略了斑块位置的关键影响，因为不同节段的钙化具有不同的预后和手术风险。然而，更精细的、节段特异性的量化在技术上仍然不可行。传统的3D模型被迫处理降采样体积或孤立的补丁，牺牲了解决解剖模糊和实现可靠地标定位所需的全局上下文。为了克服这个问题，我们将3D挑战重新定义为沿1D轴向维度的“并行概率地标定位”任务。我们提出了“深度序列Transformer (DST)”，一个将全分辨率CT体积处理为2D切片序列的框架，学习预测N=6个独立的概率分布，以精确定位关键解剖地标。我们的DST框架展示了卓越的准确性和鲁棒性。在100名患者的临床队列上，通过严格的5折交叉验证评估，它实现了0.1切片的平均绝对误差 (MAE)，96%的预测落在±1切片容差内。此外，为了验证其架构能力，DST骨干在公共Clean-CC-CCII分类基准上，在端到端评估协议下取得了最佳结果。我们的工作提供了第一个用于自动化节段特异性ICAC分析的实用工具。所提出的框架为进一步研究位置特异性生物标志物在诊断、预后和手术规划中的作用奠定了基础。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [178] [A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion](https://arxiv.org/abs/2507.09966)
> *一种基于CLIP和3D U-Net的脑肿瘤分割方法，具有跨模态语义指导和多级特征融合*

*Mingda Zhang* | **Category: eess.IV, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 脑肿瘤分割, CLIP, 3D U-Net, 多级特征融合, 跨模态语义指导

**Comment:** 13 pages,6 figures

> **TL;DR:** 本研究提出了一种结合CLIP和3D U-Net的脑肿瘤分割方法，通过多级特征融合和跨模态语义指导，有效提高了分割精度，尤其是在增强肿瘤区域。

**AI_Comments:** 该论文的创新点在于将CLIP模型的语义理解能力引入到3D U-Net的医学图像分割中，通过多级融合和跨模态语义指导，有效弥补了传统方法仅依赖视觉特征的不足，充分利用了医疗文本中的高层语义信息，为脑肿瘤的精确分割提供了新思路。其在增强肿瘤区域的显著性能提升具有重要的临床意义。

<details>
  <summary>Details</summary>

**Motivation:** 精确的脑肿瘤分割对神经肿瘤学诊断和治疗规划至关重要，但由于肿瘤形态异质性和复杂的三维空间关系，自动分割仍具挑战性。现有技术主要依赖于MRI序列的视觉特征，而未充分利用医学报告中嵌入的语义知识。

**Method:** 本文提出了一种多级融合架构，整合了像素级、特征级和语义级信息。语义级融合路径通过三种机制将对比语言-图像预训练（CLIP）模型的语义理解能力与3D U-Net的空间特征提取优势相结合：3D-2D语义桥接、跨模态语义指导和基于语义的注意力机制。

**Result:** 在BraTS 2020数据集上的实验验证表明，所提出的模型总体Dice系数达到0.8567，比传统3D U-Net提高了4.8%，在临床上重要的增强肿瘤（ET）区域Dice系数提高了7.3%。

**Conclusion:** 所提出的结合CLIP和3D U-Net的脑肿瘤分割方法，通过多级特征融合和跨模态语义指导，显著提高了分割精度，尤其在增强肿瘤区域表现出色，证明了利用语义知识的有效性。

> **ai_Abstract:** 本研究提出了一种创新的脑肿瘤分割方法，通过结合CLIP模型和3D U-Net，构建了一个多级融合架构。该架构整合了像素、特征和语义层面的信息，并通过3D-2D语义桥接、跨模态语义指导和基于语义的注意力机制，有效利用了医学报告中的语义知识。实验结果表明，该方法在BraTS 2020数据集上显著提高了脑肿瘤分割的精度，尤其是在增强肿瘤区域。

> **摘要翻译:** 从磁共振成像（MRI）中精确分割脑肿瘤对于神经肿瘤学诊断和治疗规划至关重要。尽管深度学习方法取得了进展，但由于肿瘤形态异质性和复杂的三维空间关系，自动分割仍然具有挑战性。当前技术主要依赖于从MRI序列中提取的视觉特征，而未充分利用医学报告中嵌入的语义知识。本研究提出了一种多级融合架构，整合了像素级、特征级和语义级信息，促进从低级数据到高级概念的全面处理。语义级融合路径通过三种机制将对比语言-图像预训练（CLIP）模型的语义理解能力与3D U-Net的空间特征提取优势相结合：3D-2D语义桥接、跨模态语义指导和基于语义的注意力机制。在BraTS 2020数据集上的实验验证表明，所提出的模型总体Dice系数达到0.8567，比传统3D U-Net提高了4.8%，在临床上重要的增强肿瘤（ET）区域Dice系数提高了7.3%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [183] [Pathology-Guided Virtual Staining Metric for Evaluation and Training](https://arxiv.org/abs/2507.12624)
> *病理学引导的虚拟染色评估与训练度量*

*Qiankai Wang, James E. D. Tweel, Parsin Haji Reza, Anita Layton* | **Category: eess.IV, cs.CV, cs.SY, eess.SY** | **Updated: 2025-07-16**

**Keywords:** 虚拟染色, 图像质量评估, 病理学, 深度学习, PaPIS

**Comment:** 19 pages, 10 figures. Intended for submission to the Journal of
  Imaging Informatics in Medicine (JIIM)

> **TL;DR:** 本文提出PaPIS，一种新型病理学专用虚拟染色评估指标，解决了现有评估方法的局限性，并能作为损失函数提升模型性能。

**AI_Comments:** 这项工作的创新之处在于提出了一个专门针对病理学图像的虚拟染色评估指标，解决了传统图像质量评估指标在病理领域适用性差的问题。其重要性体现在它不仅提供了一个更准确的评估工具，还能够作为损失函数直接优化虚拟染色模型的性能，对虚拟染色技术的临床转化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有虚拟染色评估方法主要依赖为自然图像设计的FR-IQA指标，无法准确捕捉病理学特征；专家评审虽有效但主观且耗时。因此，需要一个专门针对病理学图像的评估指标。

**Method:** 本研究引入PaPIS（Pathology-Aware Perceptual Image Similarity），这是一种新型FR-IQA指标，专为虚拟染色评估定制。PaPIS利用基于细胞形态分割训练的深度学习特征，并结合Retinex启发式特征分解，以更好地反映组织学感知质量。

**Result:** PaPIS与病理学相关视觉线索更准确地对齐，并能区分传统和现有感知度量易于忽视的细微细胞结构。此外，将PaPIS作为指导损失函数集成到虚拟染色模型中，可显著提高组织学保真度。

**Conclusion:** 这项工作强调了开发病理学感知评估框架对于推进虚拟染色技术发展和临床就绪的迫切需求。

> **ai_Abstract:** 本文提出PaPIS，一种为虚拟染色评估量身定制的新型全参考图像质量评估（FR-IQA）指标，旨在解决现有评估方法无法准确捕捉病理学相关特征的问题。PaPIS结合了深度学习特征和Retinex思想，能更准确地反映组织学感知质量。实验证明，PaPIS能更好地区分细微细胞结构，并且作为损失函数能提升虚拟染色模型的组织学保真度，强调了病理学感知评估框架的重要性。

> **摘要翻译:** 虚拟染色已成为传统组织病理学染色技术的强大替代方案，能够实现快速、无试剂的图像转换。然而，现有的评估方法主要依赖于全参考图像质量评估（FR-IQA）指标，例如结构相似性，这些指标最初是为自然图像设计的，通常无法捕捉病理学相关特征。专家病理学审查也被使用，但它们本质上是主观的且耗时。
在本研究中，我们引入了PaPIS（Pathology-Aware Perceptual Image Similarity），一种专门为虚拟染色评估量身定制的新型FR-IQA指标。PaPIS利用基于细胞形态分割训练的深度学习特征，并结合Retinex启发式特征分解，以更好地反映组织学感知质量。对比实验表明，PaPIS与病理学相关视觉线索更准确地对齐，并能区分传统和现有感知度量易于忽视的细微细胞结构。此外，将PaPIS作为指导损失函数集成到虚拟染色模型中，可提高组织学保真度。
这项工作强调了开发病理学感知评估框架对于推进虚拟染色技术发展和临床就绪的迫切需求。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [225] [TRIQA: Image Quality Assessment by Contrastive Pretraining on Ordered Distortion Triplets](https://arxiv.org/abs/2507.12687)
> *TRIQA：基于有序失真三元组对比预训练的图像质量评估*

*Rajesh Sureddi, Saman Zadtootaghaj, Nabajeet Barman, Alan C. Bovik* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-16**

**Keywords:** 图像质量评估, 无参考IQA, 对比学习, 三元组学习, 泛化性能

**Comment:** 5 pages

> **TL;DR:** TRIQA通过对比三元组学习，利用有限数据高效训练NR-IQA模型，实现了良好的泛化性能。

**AI_Comments:** 这篇论文通过引入对比三元组学习和构建自定义数据集，为解决无参考图像质量评估领域数据稀缺的挑战提供了一个创新的解决方案。这种方法提高了训练效率和模型泛化能力，对于资源有限的IQA研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有无参考图像质量评估（NR-IQA）模型面临主观标注数据有限的挑战，且多数深度学习方法依赖大规模数据集预训练。

**Method:** 本文提出了TRIQA，一种新颖的无参考图像质量评估方法。该方法通过利用有限的参考内容图像构建自定义数据集，并引入了一个结合内容和质量特征的NR-IQA模型。具体而言，该模型使用对比三元组学习进行质量感知训练。

**Result:** TRIQA能够用更少样本进行高效训练，并在公开数据集上实现了强大的泛化性能。

**Conclusion:** 通过引入对比三元组学习，TRIQA有效解决了无参考图像质量评估领域数据稀缺的挑战，显著提高了模型的训练效率和泛化能力。

> **ai_Abstract:** 本文提出了TRIQA，一种新颖的无参考图像质量评估（NR-IQA）方法，旨在解决主观标注数据稀缺的问题。该方法通过利用有限的参考内容图像构建自定义数据集，并采用对比三元组学习来训练一个结合内容和质量特征的质量感知模型。实验证明，TRIQA能够用更少的样本进行高效训练，并在公开数据集上展现出强大的泛化能力。

> **摘要翻译:** 图像质量评估 (IQA) 模型旨在预测与人类判断一致的感知图像质量。由于缺乏参考图像，无参考 (NR) IQA 仍然特别具有挑战性。虽然深度学习显著推动了该领域的发展，但开发 NR-IQA 模型的一个主要障碍是主观标注数据的可用性有限。大多数现有的基于深度学习的 NR-IQA 方法在进行 IQA 任务微调之前，都依赖于在大规模数据集上进行预训练。为了进一步推动该领域的进展，我们提出了一种新颖的方法，该方法利用有限数量的参考内容图像构建自定义数据集，并引入了一种结合内容和质量特征的无参考 IQA 模型用于感知质量预测。具体来说，我们使用对比三元组学习训练了一个质量感知模型，从而能够以更少的样本进行高效训练，同时在公开可用数据集上实现强大的泛化性能。我们的代码库可在 https://github.com/rajeshsureddi/triqa 访问。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [265] [Pixel Perfect MegaMed: A Megapixel-Scale Vision-Language Foundation Model for Generating High Resolution Medical Images](https://arxiv.org/abs/2507.12698)
> *Pixel Perfect MegaMed：一个用于生成高分辨率医学图像的百万像素级视觉-语言基础模型*

*Zahra TehraniNasab, Amar Kumar, Tal Arbel* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 医学图像合成, 视觉-语言模型, 高分辨率, Transformer, 数据增强

**Comment:** 

> **TL;DR:** Pixel Perfect MegaMed是一个视觉-语言基础模型，能够生成1024x1024分辨率的高质量医学图像，解决了现有方法在细节保留上的不足。

**AI_Comments:** 该论文提出了一个重要的创新，即第一个百万像素级的视觉-语言基础模型用于医学图像合成。其多尺度Transformer架构和医学领域定制的视觉-语言对齐技术是关键的创新点，有效解决了传统方法在高分辨率医学图像细节保留上的不足。该模型在数据增强方面的应用潜力巨大，尤其对于解决医学领域数据稀缺的问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统生成架构（如GANs或VAEs）在生成高分辨率医学图像时难以保留对准确诊断至关重要的精细细节，而医学图像合成需要高分辨率和复杂细节。

**Method:** 引入了Pixel Perfect MegaMed，这是第一个能够合成1024x1024分辨率图像的视觉-语言基础模型。它部署了一个专门为超高分辨率医学图像生成设计的多尺度Transformer架构，并通过针对医学术语和成像模态的视觉-语言对齐技术，连接了文本描述和视觉表示。

**Result:** 模型能够在1024x1024分辨率下合成图像，并在CheXpert数据集上生成了临床上忠实的胸部X射线图像。这些高分辨率合成图像在下游任务（如分类）中显示出价值，尤其是在数据量较少的情况下，可用于数据增强并带来可衡量的性能提升。

**Conclusion:** Pixel Perfect MegaMed成功解决了高分辨率医学图像合成中细节保留的挑战，通过其创新的视觉-语言基础模型和多尺度Transformer架构，生成了临床上有用的图像，并提升了下游任务的性能。

> **ai_Abstract:** Pixel Perfect MegaMed是一个开创性的视觉-语言基础模型，专为解决高分辨率医学图像合成中细节保留的挑战而设计。该模型采用多尺度Transformer架构和医学领域特定的视觉-语言对齐技术，能够生成1024x1024分辨率的图像，并有效保留全局和局部细节。在CheXpert数据集上的实验表明，它能从文本提示生成临床忠实的胸部X射线，并且这些合成图像在下游分类任务中作为数据增强手段，尤其是在数据稀缺时，显著提升了性能。

> **摘要翻译:** 医学图像合成由于临床环境中固有的复杂性和所需的高分辨率细节而面临独特的挑战。传统的生成架构，例如生成对抗网络（GANs）或变分自编码器（VAEs），在高分辨率图像生成方面显示出巨大潜力，但在保留对准确诊断至关重要的精细细节方面存在困难。为了解决这个问题，我们引入了Pixel Perfect MegaMed，这是第一个能够合成1024x1024分辨率图像的视觉-语言基础模型。我们的方法部署了一个专门为超高分辨率医学图像生成设计的多尺度Transformer架构，从而能够同时保留全局解剖上下文和局部图像级细节。通过利用针对医学术语和成像模态量身定制的视觉-语言对齐技术，Pixel Perfect MegaMed以前所未有的分辨率水平弥合了文本描述和视觉表示之间的鸿沟。我们将模型应用于CheXpert数据集，并展示了其从文本提示生成临床上忠实胸部X射线图像的能力。除了视觉质量之外，这些高分辨率合成图像被证明对下游任务（如分类）非常有价值，当用于数据增强时，尤其是在数据量不足的情况下，显示出可衡量的性能增益。我们的代码可通过项目网站访问：https://tehraninasab.github.io/pixelperfect-megamed。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [309] [Unleashing Vision Foundation Models for Coronary Artery Segmentation: Parallel ViT-CNN Encoding and Variational Fusion](https://arxiv.org/abs/2507.12938)
> *释放视觉基础模型用于冠状动脉分割：并行ViT-CNN编码与变分融合*

*Caixia Dong, Duwei Dai, Xinyi Han, Fan Liu, Xu Yang, Zongfang Li, Songhua Xu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 冠状动脉分割, 视觉基础模型, ViT, CNN, 变分融合, 不确定性细化

**Comment:** 

> **TL;DR:** 提出了一种新的冠状动脉分割框架，结合ViT和CNN进行并行编码，并通过变分融合和不确定性细化模块，显著提高了分割精度和泛化能力。

**AI_Comments:** 这篇论文的创新点在于其结合了ViT（用于全局特征）和CNN（用于局部细节）的并行编码架构，并引入了新颖的变分融合和不确定性细化模块。这种多模型协同和不确定性量化的方法，对于处理冠状动脉这种复杂且难以分割的目标具有重要意义，尤其是在医疗图像分析领域，其准确性和鲁棒性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 准确的冠状动脉分割对于计算机辅助诊断冠状动脉疾病至关重要，但由于血管尺寸小、形态复杂以及与周围组织对比度低，分割仍然具有挑战性。

**Method:** 提出了一种利用视觉基础模型（VFMs）的并行编码分割框架。该框架包含：一个ViT编码器（VFM内）捕获全局结构特征，并通过激活最后两个ViT块和集成注意力引导增强（AGE）模块进行增强；一个CNN编码器提取局部细节。这些互补特征通过跨分支变分融合（CVF）模块自适应地融合，该模块对潜在分布进行建模并应用变分注意力来分配特定模态的权重。此外，引入了证据学习不确定性细化（EUR）模块，该模块使用证据理论量化不确定性，并通过结合多尺度特征聚合和注意力机制来细化不确定区域。

**Result:** 在广泛评估中，所提出的框架在一个内部数据集和两个公共数据集上显著优于现有最先进的方法，在准确的冠状动脉分割方面取得了卓越性能，并展示了强大的跨多个数据集的泛化能力。

**Conclusion:** 该框架通过结合视觉基础模型的并行编码和创新的融合与不确定性细化机制，能够有效克服冠状动脉分割的挑战，实现高精度和强泛化能力。

> **ai_Abstract:** 本文提出了一种创新的冠状动脉分割框架，旨在解决其小尺寸、复杂形态和低对比度带来的挑战。该框架利用视觉基础模型，采用并行ViT-CNN编码器分别捕获全局和局部特征，并通过跨分支变分融合模块自适应地整合这些特征。此外，引入了证据学习不确定性细化模块，以量化和优化不确定区域。实验结果表明，该方法在多个数据集上显著优于现有技术，展示了卓越的分割性能和泛化能力。

> **摘要翻译:** 准确的冠状动脉分割对于计算机辅助诊断冠状动脉疾病（CAD）至关重要，但由于血管尺寸小、形态复杂以及与周围组织对比度低，分割仍然具有挑战性。为了解决这些挑战，我们提出了一种新颖的分割框架，通过并行编码架构利用视觉基础模型（VFMs）的力量。具体来说，VFM中的视觉Transformer（ViT）编码器捕获全局结构特征，并通过激活最后两个ViT块和集成注意力引导增强（AGE）模块进行增强，而卷积神经网络（CNN）编码器则提取局部细节。这些互补特征通过跨分支变分融合（CVF）模块自适应地融合，该模块对潜在分布进行建模并应用变分注意力来分配特定模态的权重。此外，我们引入了证据学习不确定性细化（EUR）模块，该模块使用证据理论量化不确定性，并通过结合多尺度特征聚合和注意力机制来细化不确定区域，进一步提高分割精度。在一个内部数据集和两个公共数据集上进行的广泛评估表明，所提出的框架显著优于现有最先进的方法，在准确的冠状动脉分割方面取得了卓越性能，并展示了强大的跨多个数据集的泛化能力。代码可在 https://github.com/d1c2x3/CAseg 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [357] [From Variability To Accuracy: Conditional Bernoulli Diffusion Models with Consensus-Driven Correction for Thin Structure Segmentation](https://arxiv.org/abs/2507.12985)
> *从可变性到准确性：基于共识驱动校正的条件伯努利扩散模型用于薄结构分割*

*Jinseo An, Min Jin Lee, Kyu Won Shim, Helen Hong* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 薄结构分割, 扩散模型, 共识驱动校正, 医疗图像分割, 眶骨

**Comment:** Early accepted at MICCAI 2025

> **TL;DR:** 该研究提出了一种利用条件伯努利扩散模型和共识驱动校正的新框架，用于薄结构（如眶骨）的精确分割，显著提高了模糊区域的召回率并保持了结构连续性。

**AI_Comments:** 该论文的创新点在于提出了一个结合条件伯努利扩散模型和共识驱动校正的框架，有效地解决了薄结构分割中边界模糊和结构不连续的问题。通过生成多样化的分割结果并进行共识整合，显著提升了分割的准确性和鲁棒性。其重要性体现在能够自动化医疗图像分割结果的校正过程，并为图像引导手术规划提供了更可靠的依据。

<details>
  <summary>Details</summary>

**Motivation:** 面部CT图像中眶骨的准确分割对于定制植入物至关重要，但由于模糊边界和眶内侧壁、眶底等薄结构的存在，现有分割方法常导致结果不连贯或分割不足。

**Method:** 本文提出了一种新颖的框架，通过利用多个扩散模型输出的共识来纠正分割结果。该方法采用一个在每张图像不同注释模式上训练的条件伯努利扩散模型来生成多个合理的分割结果，然后进行共识驱动校正，该校正结合了位置邻近性、共识水平和梯度方向相似性来纠正挑战区域。

**Result:** 实验结果表明，该方法优于现有方法，显著提高了模糊区域的召回率，同时保持了薄结构的连续性。

**Conclusion:** 该方法实现了分割结果手动校正的自动化，并可应用于图像引导手术规划和手术。

> **ai_Abstract:** 本研究提出了一种新颖的框架，用于解决CT图像中薄结构（如眶骨）分割的挑战。该方法利用一个条件伯努利扩散模型生成多种可能的分割结果，并通过结合位置邻近性、共识水平和梯度方向相似性的共识驱动校正来优化这些结果。实验证明，该方法在模糊区域的召回率上显著优于现有技术，并能有效保持薄结构的连续性，同时实现了分割结果校正的自动化，适用于手术规划。

> **摘要翻译:** 面部计算机断层扫描（CT）图像中眶骨的精确分割对于重建缺损眶骨的定制植入物至关重要，尤其由于模糊的边界和薄结构（如眶内侧壁和眶底）而极具挑战性。在这些模糊区域，现有分割方法通常输出不连贯或分割不足的结果。我们提出了一种新颖的框架，通过利用来自多个扩散模型输出的共识来纠正分割结果。我们的方法采用一个条件伯努利扩散模型，该模型在每张图像的不同注释模式上进行训练，以生成多个合理的分割结果，然后进行共识驱动的校正，该校正结合了位置邻近性、共识水平和梯度方向相似性来纠正挑战性区域。实验结果表明，我们的方法优于现有方法，显著提高了模糊区域的召回率，同时保持了薄结构的连续性。此外，我们的方法自动化了分割结果校正的手动过程，并可应用于图像引导手术规划和手术。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [401] [fastWDM3D: Fast and Accurate 3D Healthy Tissue Inpainting](https://arxiv.org/abs/2507.13146)
> *fastWDM3D：快速准确的3D健康组织修复*

*Alicia Durrer, Florentin Bieder, Paul Friedrich, Bjoern Menze, Philippe C. Cattin, Florian Kofler* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 健康组织修复, 3D修复, 扩散模型, fastWDM3D, 小波扩散模型

**Comment:** Philippe C. Cattin and Florian Kofler: equal contribution

> **TL;DR:** fastWDM3D是一种基于扩散模型的3D健康组织修复方法，比现有DDPM模型快800倍，同时性能更优。

**AI_Comments:** 本论文的创新点在于将2D图像生成中的方差保持噪声调度和重建损失应用于3D健康组织修复，并成功集成到小波扩散模型中，实现了在不依赖GANs的情况下显著提升修复速度和性能。其速度提升（高达800倍）是该方法最重要的优势，这使得其在需要快速处理的医疗图像分析等实际应用中具有巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 健康组织修复在肿瘤生长模型和图像配准中具有重要应用，但现有去噪扩散概率模型（DDPMs）在生成高质量结果的同时，采样速度较慢，限制了其实用性。

**Method:** 为了解决DDPMs采样速度慢的问题，作者将一种结合DDPMs与GANs并采用方差保持噪声调度的2D图像生成方法应用于3D修复任务。实验发现方差保持噪声调度和选定的重建损失可以在少量时间步内实现高质量3D修复，且无需对抗训练。基于此发现，作者将该技术应用于不含GAN组件的3D小波扩散模型（WDM3D），从而开发出fastWDM3D。

**Result:** fastWDM3D在BraTS修复测试集上取得了0.8571的SSIM、0.0079的MSE和22.26的PSNR。该模型仅使用两个时间步，每张图像的3D修复过程仅需1.81秒。与用于健康脑组织修复的其他DDPMs相比，fastWDM3D速度提高了800倍，同时性能指标更优越。

**Conclusion:** fastWDM3D是一种用于快速准确健康组织修复的有前景的方法。

> **ai_Abstract:** fastWDM3D是一种高效的3D健康组织修复模型，通过改进扩散模型并结合方差保持噪声调度，显著提升了修复速度和准确性。该模型在保持高质量修复效果的同时，实现了比现有DDPMs快800倍的速度，在BraTS修复测试集上表现出色。

> **摘要翻译:** 健康组织修复具有重要应用，包括为肿瘤生长模型生成伪健康基线和促进图像配准。在之前的BraTS通过修复局部合成健康脑组织挑战赛中，去噪扩散概率模型（DDPMs）展示了定性上令人信服的结果，但采样速度较慢。为了缓解这一限制，我们调整了一种2D图像生成方法，将DDPMs与生成对抗网络（GANs）结合，并采用方差保持噪声调度，用于3D修复任务。我们的实验表明，方差保持噪声调度和选定的重建损失可以有效地用于在少量时间步内实现高质量的3D修复，而无需对抗训练。我们将我们的发现应用于另一种架构，即不包含GAN组件的3D小波扩散模型（WDM3D）。由此产生的模型，命名为fastWDM3D，在BraTS修复测试集上获得了0.8571的SSIM，0.0079的MSE和22.26的PSNR。值得注意的是，它仅使用两个时间步就达到了这些分数，每张图像的3D修复过程在1.81秒内完成。与用于健康脑组织修复的其他DDPMs相比，我们的模型速度提高了800倍，同时仍能实现卓越的性能指标。我们提出的方法fastWDM3D，代表了一种快速准确的健康组织修复的有前景方法。我们的代码可在https://github.com/AliciaDurrer/fastWDM3D获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [436] [SpectraLift: Physics-Guided Spectral-Inversion Network for Self-Supervised Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2507.13339)
> *SpectraLift：物理引导的光谱反演网络，用于自监督高光谱图像超分辨率*

*Ritik Shah, Marco F. Duarte* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 高光谱图像, 超分辨率, 自监督, 光谱反演, 多层感知机

**Comment:** 

> **TL;DR:** SpectraLift是一个自监督框架，仅利用MSI的SRF，就能将低分辨率高光谱图像和高分辨率多光谱图像融合，实现高光谱图像超分辨率，并超越现有SOTA方法。

**AI_Comments:** SpectraLift的创新之处在于其完全自监督的特性，仅利用MSI的SRF进行训练，避免了对难以获取的PSF或真实HR-HSI的依赖，这大大提高了其在实际应用中的可行性。其轻量级MLP设计和快速收敛特性也值得称赞，使其成为一个高效且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 高空间分辨率高光谱图像对遥感和医学成像等应用至关重要，但现有高光谱传感器在空间细节和光谱丰富度之间存在权衡。融合高空间分辨率多光谱图像（HR-MSI）和低空间分辨率高光谱图像（LR-HSI）是恢复精细空间结构而不牺牲光谱保真度的有前景途径。然而，大多数现有融合方法需要点扩散函数（PSF）校准或真实高分辨率高光谱图像（HR-HSI），这在实际中难以获得。

**Method:** SpectraLift是一个完全自监督的框架，仅使用MSI的光谱响应函数（SRF）融合LR-HSI和HR-MSI输入。它训练一个轻量级的逐像素多层感知机（MLP）网络，训练过程如下：(i) 将SRF应用于LR-HSI作为输入，得到合成的低空间分辨率多光谱图像（LR-MSI）；(ii) 将LR-HSI作为输出；(iii) 使用估计的LR-HSI与真实LR-HSI之间的$\ell_1$光谱重建损失作为优化目标。在推理时，SpectraLift使用训练好的网络将HR-MSI逐像素映射到HR-HSI估计。

**Result:** SpectraLift在数分钟内收敛，对空间模糊和分辨率不敏感，并且在PSNR、SAM、SSIM和RMSE基准测试中优于现有最先进的方法。

**Conclusion:** SpectraLift提供了一种高效且实用的自监督高光谱图像超分辨率解决方案，克服了传统方法对PSF校准或真实HR-HSI的依赖，并在性能上超越了现有技术。

> **ai_Abstract:** SpectraLift是一种新颖的自监督框架，旨在解决高光谱图像超分辨率问题，通过融合低分辨率高光谱图像和高分辨率多光谱图像来实现。与传统方法不同，它仅依赖多光谱图像的光谱响应函数，避免了对点扩散函数校准或真实高分辨率高光谱图像的需求。该方法利用一个轻量级MLP网络，通过物理引导的光谱反演进行训练，并在性能上超越了现有技术。

> **摘要翻译:** 高空间分辨率高光谱图像（HSI）对于遥感和医学成像等应用至关重要，然而HSI传感器在空间细节和光谱丰富度之间存在固有的权衡。将高空间分辨率多光谱图像（HR-MSI）与低空间分辨率多光谱图像（LR-HSI）融合是恢复精细空间结构而不牺牲光谱保真度的一种有前景的途径。大多数最先进的HSI-MSI融合方法需要点扩散函数（PSF）校准或真实高分辨率HSI（HR-HSI），这两者在实际应用中都难以获得。我们提出了SpectraLift，一个完全自监督的框架，仅使用MSI的光谱响应函数（SRF）来融合LR-HSI和HR-MSI输入。SpectraLift使用以下方式训练一个轻量级的逐像素多层感知机（MLP）网络：(i) 将SRF应用于LR-HSI作为输入，以获得合成的低空间分辨率多光谱图像（LR-MSI）；(ii) 将LR-HSI作为输出；(iii) 使用估计的LR-HSI与真实LR-HSI之间的$\ell_1$光谱重建损失作为优化目标。在推理时，SpectraLift使用训练好的网络将HR-MSI逐像素映射到HR-HSI估计。SpectraLift在数分钟内收敛，对空间模糊和分辨率不敏感，并且在PSNR、SAM、SSIM和RMSE基准测试中优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [541] [Learning Lens Blur Fields](https://arxiv.org/abs/2310.11535)
> *学习镜头模糊场*

*Esther Y. H. Lin, Zhecheng Wang, Rebecca Lin, Daniel Miau, Florian Kainz, Jiawen Chen, Xuaner Cecilia Zhang, David B. Lindell, Kiriakos N. Kutulakos* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 镜头模糊场, 神经网络, 点扩散函数, 光学建模, 反卷积

**Comment:** 

> **TL;DR:** 提出了一种高维神经网络表示“镜头模糊场”来精确建模现代相机中复杂的镜头模糊，并开发了获取方法和数据集。

**AI_Comments:** 这篇论文的创新点在于提出了一个新颖的、基于神经网络的镜头模糊表示方法，即“镜头模糊场”，能够以前所未有的精度捕捉复杂的相机光学特性。通过将模糊建模为高维函数，并利用少量焦距堆栈进行训练，解决了传统方法难以应对的挑战。其结果不仅对计算摄影和图像处理有重要意义，更首次揭示了即使是同型号设备也可能存在光学差异，这对于质量控制和设备分析具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代相机因其复杂的光学元件，其固有的光学模糊难以建模。

**Method:** 引入了高维神经网络表示“镜头模糊场”（一个MLP），用于捕获图像平面位置、焦点设置以及可选的深度上的2D点扩散函数变化，并将其参数化为传感器特定函数。该模型结合了散焦、衍射、像差，并考虑了像素颜色滤镜和微透镜等传感器特性。通过广义非盲反卷积问题，使用少量焦距堆栈直接优化MLP权重来学习模糊场。

**Result:** 获取的5D模糊场具有足够的表达力和准确性，首次揭示了相同品牌和型号的智能手机设备在光学行为上的差异。还提供了首个5D模糊场数据集。

**Conclusion:** 提出的镜头模糊场表示和获取方法能够准确建模复杂的光学模糊，甚至能揭示同型号设备间的细微光学差异，为相机光学特性分析提供了新工具。

> **ai_Abstract:** 这篇论文提出了一种名为“镜头模糊场”的高维神经网络表示，用于精确建模现代相机中复杂的镜头模糊。该方法利用多层感知器（MLP）捕捉点扩散函数在图像平面位置、焦点和深度上的变化，并将其参数化。通过广义非盲反卷积，使用少量焦距堆栈来训练MLP。研究还创建了首个5D模糊场数据集，并证明了其能够揭示相同品牌型号智能手机设备间的光学差异。

> **摘要翻译:** 光学模糊是任何镜头系统固有的属性，由于现代相机复杂的光学元件，对其建模具有挑战性。为了解决这一挑战，我们引入了一种高维模糊神经网络表示——“镜头模糊场”——以及一种获取它的实用方法。镜头模糊场是一个多层感知器（MLP），旨在（1）精确捕获图像平面位置、焦点设置以及可选的深度上镜头2D点扩散函数的变化，以及（2）将这些变化参数化为单个、传感器特定的函数。该表示模型结合了散焦、衍射、像差的综合效应，并考虑了像素颜色滤镜和像素特定微透镜等传感器特征。为了学习给定设备的真实世界模糊场，我们制定了一个广义非盲反卷积问题，该问题仅使用少量焦距堆栈作为输入，直接优化MLP权重。我们还提供了首个5D模糊场数据集——适用于智能手机相机、配备各种镜头的相机机身等。最后，我们展示了所获取的5D模糊场具有足够的表达力和准确性，首次揭示了相同品牌和型号的智能手机设备在光学行为上的差异。代码和数据可在blur-fields.github.io获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [576] [Deep Blur Multi-Model (DeepBlurMM) -- a strategy to mitigate the impact of image blur on deep learning model performance in histopathology image analysis](https://arxiv.org/abs/2405.09298)
> *深度模糊多模型 (DeepBlurMM)——一种减轻图像模糊对组织病理学图像分析中深度学习模型性能影响的策略*

*Yujie Xiang, Bojing Liu, Mattias Rantalainen* | **Category: eess.IV, cs.CV, I.4; J.3** | **Updated: 2025-07-16**

**Keywords:** 组织病理学, 图像模糊, 深度学习, 专家混合, 全玻片图像

**Comment:** 

> **TL;DR:** 提出DeepBlurMM（多专家模型）策略，通过结合不同模糊程度训练的模型，有效提升深度学习模型在模糊组织病理图像上的性能。

**AI_Comments:** 该研究解决了组织病理学图像分析中一个实际且普遍存在的问题——图像模糊对AI模型性能的影响。其提出的专家混合（MoE）策略是一种新颖且有效的应对方法，通过利用不同模糊程度的数据训练专家模型，提高了模型在真实世界复杂图像质量下的鲁棒性。这对于AI在临床病理诊断中的广泛应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** AI模型在组织病理学全玻片图像（WSI）分析中日益普及，但图像中不清晰或模糊的区域会显著降低预测性能，本研究旨在解决这一问题。

**Method:** 本研究引入了一种专家混合（MoE）策略，该策略结合了在不同模糊级别数据上训练的多个专家模型的预测结果。使用来自2,093名乳腺癌患者的H&E染色WSI，在等级分类和IHC生物标志物预测任务上，对基于CNN和Vision Transformer的模型（CNN_CLAM, MoE-CNN_CLAM, UNI_CLAM, MoE-UNI_CLAM）进行了性能基准测试。

**Result:** 基线模型的性能随着模糊度的增加而持续下降。专家模型，特别是提出的MoE方法，显著提高了性能，并在模拟场景中优于基线模型。MoE-CNN_CLAM在中度模糊（AUC: 0.868 vs. 0.702）和混合模糊（AUC: 0.890 vs. 0.875）条件下优于基线CNN_CLAM。MoE-UNI_CLAM在中度模糊（AUC: 0.950 vs. 0.928）和混合模糊（AUC: 0.944 vs. 0.931）条件下优于基线UNI_CLAM模型。

**Conclusion:** 该MoE方法有潜力增强AI病理模型在可变图像质量下的可靠性，支持其在研究和临床环境中的广泛应用。

> **ai_Abstract:** 本研究提出DeepBlurMM，一种基于专家混合（MoE）的策略，旨在解决组织病理学图像模糊对深度学习模型性能的影响。通过在不同模糊级别数据上训练多个专家模型并结合其预测，该方法显著提高了模型在模糊图像上的表现，并在乳腺癌WSI分析中，在CNN和Vision Transformer模型上均优于基线模型，证明了其在提高AI病理模型可靠性方面的潜力。

> **摘要翻译:** 基于AI的组织病理学全玻片图像（WSI）分析模型越来越普遍，但WSI中不清晰或模糊的区域会显著降低预测性能。在本研究中，我们调查了图像模糊对深度学习模型的影响，并引入了一种专家混合（MoE）策略，该策略结合了在不同模糊级别数据上训练的多个专家模型的预测结果。我们使用来自2,093名乳腺癌患者的H&E染色WSI，对基于CNN（CNN_CLAM和MoE-CNN_CLAM）和Vision Transformer（UNI_CLAM和MoE-UNI_CLAM）模型的等级分类和IHC生物标志物预测性能进行了基准测试。我们的结果表明，基线模型的性能随着模糊度的增加而持续下降，但通过模糊图像块训练的专家模型，特别是我们提出的MoE方法，显著提高了性能，并在一系列模拟场景中优于基线模型。MoE-CNN_CLAM在中度模糊（AUC：0.868 对 0.702）和混合模糊（AUC：0.890 对 0.875）条件下优于基线CNN_CLAM。MoE-UNI_CLAM在中度模糊（AUC：0.950 对 0.928）和混合模糊（AUC：0.944 对 0.931）条件下优于基线UNI_CLAM模型。这种MoE方法有潜力增强AI病理模型在可变图像质量下的可靠性，支持其在研究和临床环境中的广泛应用。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [619] [Uncertainty quantification for White Matter Hyperintensity segmentation detects silent failures and improves automated Fazekas quantification](https://arxiv.org/abs/2411.17571)
> *白质高信号分割的不确定性量化检测静默失败并改进自动化Fazekas评分量化*

*Ben Philps, Maria del C. Valdes Hernandez, Chen Qin, Una Clancy, Eleni Sakka, Susana Munoz Maniega, Mark E. Bastin, Angela C. C. Jochems, Joanna M. Wardlaw, Miguel O. Bernabeu, Alzheimers Disease Neuroimaging Initiative* | **Category: eess.IV, cs.CV, cs.LG, I.4.10; I.4.6; I.2.10; I.2.6; J.3; G.3** | **Updated: 2025-07-17**

**Keywords:** 白质高信号, 不确定性量化, 分割, Fazekas评分, 静默失败

**Comment:** 34 pages (or 19 not including appendix) 28 figures (or 10 not
  including appendix)

> **TL;DR:** 该研究评估了不确定性量化(UQ)技术在白质高信号(WMH)分割中的效用，发现UQ能减少“静默失败”，提高分割性能，并改进基于WMH概率和UQ图的Fazekas评分分类。

**AI_Comments:** 本文的创新点在于将不确定性量化(UQ)技术应用于白质高信号(WMH)分割，并明确展示了其在检测“静默失败”和改进下游临床Fazekas评分量化方面的实际效用。通过结合UQ信息，模型不仅提高了分割精度，更重要的是增强了对分割结果可靠性的评估，这对于临床诊断和研究具有重要意义。特别是利用UQ图的空间特征来改进Fazekas评分分类，为自动化临床评估提供了新的思路和更鲁棒的工具。

<details>
  <summary>Details</summary>

**Motivation:** 白质高信号(WMH)是脑MRI中与小血管疾病相关的关键神经放射学标记物，在研究和临床中评估其重要。然而，由于WMH在形状、位置、大小、边界模糊以及与其他病理和伪影的相似强度分布方面存在高度变异性，导致其分割具有挑战性。

**Method:** 研究评估了分割中不确定性量化(UQ)技术在WMH分割任务中的效用。结合了随机分割网络与深度集成(Stochastic Segmentation Networks with Deep Ensembles)。提出了一种利用体素级WMH概率和UQ图提取空间特征的新方法，用于临床Fazekas评分分类。

**Result:** UQ技术通过识别模型未分割的深部白质中的小WMH簇，减少了“静默失败”。随机分割网络与深度集成的组合产生了最高的Dice分数和最低的绝对体积差异百分比(AVD)分数，并能突出WMH和中风病变之间模糊的区域。结合WMH不确定性信息改进了Fazekas分类性能和校准。模型在深度WMH区域的平衡准确率分别为0.74/0.67/0.62，根Brier分数分别为0.65/0.72/0.74；在脑室周围区域的平衡准确率分别为0.74/0.73/0.71，根Brier分数分别为0.64/0.66/0.68。高样本多样性的随机UQ技术能改进低质量分割的检测。

**Conclusion:** 不确定性量化(UQ)技术在白质高信号(WMH)分割中具有显著效用，能够有效减少“静默失败”，提高分割的准确性和可靠性，并进一步提升下游任务如Fazekas评分分类的性能和校准。这表明UQ对于临床和研究中的WMH评估至关重要。

> **ai_Abstract:** 本研究探讨了不确定性量化(UQ)技术在脑部MRI白质高信号(WMH)分割中的应用。研究发现UQ技术能有效识别并减少模型分割中的“静默失败”，尤其是在深部白质中未被识别的小WMH簇。结合随机分割网络与深度集成的UQ方法不仅提高了分割的Dice和AVD分数，还能区分WMH和中风病变模糊区域。此外，研究提出了一种利用WMH概率和UQ图的空间特征进行Fazekas评分分类的新方法，并证明引入WMH不确定性信息显著提升了分类性能和校准。这表明UQ对提高WMH分割的可靠性及其在临床评估中的应用具有重要价值。

> **摘要翻译:** 白质高信号（WMH）是脑部MRI中与小血管疾病相关的关键神经放射学标记物。WMH的评估在研究和临床中都非常重要。然而，由于WMH在形状、位置、大小、边界模糊以及与其他病理（例如中风病变）和伪影（例如头部运动）的相似强度分布方面存在高度变异性，导致其分割具有挑战性。在这项工作中，我们评估了分割中最有效的不确定性量化（UQ）技术在多个测试时间数据分布下WMH分割任务中的效用和语义特性。我们发现UQ技术通过在UQ图中识别模型未分割的深部白质中的小WMH簇，从而减少了“静默失败”。结合随机分割网络与深度集成的方法也产生了最高的Dice分数和最低的绝对体积差异百分比（AVD）分数，并且可以突出WMH和中风病变之间存在模糊的区域。我们进一步展示了UQ的下游效用，提出了一种利用体素级WMH概率和UQ图提取空间特征的新方法，用于临床Fazekas评分的分类。我们表明，结合WMH不确定性信息可以改善Fazekas分类性能和校准。我们的模型在深度WMH区域（UQ和空间WMH特征）/（空间WMH特征）/（仅WMH体积）的平衡准确率分别为0.74/0.67/0.62，根Brier分数分别为0.65/0.72/0.74；在脑室周围区域的平衡准确率分别为0.74/0.73/0.71，根Brier分数分别为0.64/0.66/0.68。我们进一步证明，具有高样本多样性的随机UQ技术可以改善低质量分割的检测。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [656] [Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application on the DermaMNIST Dataset](https://arxiv.org/abs/2507.12961)
> *使用CNNs提高色素性皮肤病变的诊断准确性：在DermaMNIST数据集上的应用*

*Nerma Kadric, Amila Akagic, Medina Kapo* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 色素性皮肤病变, CNN, DermaMNIST, 诊断准确性, 迁移学习

**Comment:** 

> **TL;DR:** 本研究评估了ResNet-50和EfficientNetV2L模型在DermaMNIST数据集上对色素性皮肤病变的多类别分类性能，发现CNNs能显著提高诊断准确性。

**AI_Comments:** 这项研究通过在DermaMNIST数据集上应用和优化CNN模型，展示了深度学习在提高色素性皮肤病变诊断准确性方面的潜力。其创新点在于对不同模型（ResNet-50和EfficientNetV2L）和配置的系统评估，并取得了与现有方法匹敌或超越的成果，这对于皮肤癌的早期诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 色素性皮肤病变可能预示严重的疾病如黑色素瘤，而黑色素瘤是皮肤癌死亡的主要原因，因此提高诊断准确性至关重要。

**Method:** 本研究使用DermaMNIST数据集，评估了ResNet-50和EfficientNetV2L模型进行多类别分类，采用了迁移学习和不同的层配置。

**Result:** 某一种配置的结果达到或超越了现有方法。

**Conclusion:** 卷积神经网络（CNNs）可以推动生物医学图像分析的进步，显著提高诊断准确性。

> **ai_Abstract:** 本研究旨在提高色素性皮肤病变的诊断准确性，该病变可能指示严重的皮肤癌。研究利用MedMNIST v2中的DermaMNIST数据集，评估了ResNet-50和EfficientNetV2L两种深度学习模型在多类别分类任务上的表现。通过应用迁移学习和调整模型层配置，研究发现其中一种配置达到了与现有方法相当甚至超越的性能。这表明卷积神经网络在生物医学图像分析中具有巨大潜力，能够显著提升诊断准确率。

> **摘要翻译:** 色素性皮肤病变代表黑色素增加的局部区域，可能预示着严重的疾病，如黑色素瘤，这是皮肤癌死亡的主要原因。受MNIST启发，MedMNIST v2数据集最近被引入，以推动生物医学成像领域的研究，其中包括DermaMNIST，一个基于HAM10000数据集用于色素性病变分类的数据集。本研究评估了ResNet-50和EfficientNetV2L模型在DermaMNIST数据集上进行多类别分类的性能，采用了迁移学习和各种层配置。其中一种配置达到了或超越了现有方法的结果。本研究表明，卷积神经网络（CNNs）可以推动生物医学图像分析的进步，显著提高诊断准确性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [661] [Comparative Evaluation of Radiomics and Deep Learning Models for Disease Detection in Chest Radiography](https://arxiv.org/abs/2504.12249)
> *放射组学与深度学习模型在胸部X光片疾病检测中的比较评估*

*Zhijin He, Alan B. McMillan* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 放射组学, 深度学习, 胸部X光片, 疾病检测, 诊断AI

**Comment:** revised abstract; added statistical analysis; one figure removed,
  three tables added; clarification of dataset usage, experimental design, and
  model training strategy; revised methods with details; revised discussion;
  defined all abbreviations; correction of typographical and numerical
  inconsistencies; overall language review

> **TL;DR:** 本研究比较了放射组学和深度学习模型在胸部X光片疾病检测中的表现。结果显示，深度学习模型在数据量大时表现更优，而放射组学模型在数据量少时仍有用，为诊断AI的模型选择提供了实用指导。

**AI_Comments:** 这项研究通过系统比较放射组学和深度学习模型在不同数据量下的性能，弥补了AI诊断模型选择的实践空白。其创新之处在于提供了数据驱动的、统计验证的建议，特别强调了深度学习模型在数据充足时的优越性和放射组学在低数据情境下的潜在价值，对临床AI部署具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决AI辅助诊断研究中在不同临床环境下部署AI模型的实际指导的缺失，并对放射组学和深度学习模型在胸部X光片疾病检测中的性能进行全面评估。

**Method:** 本研究系统比较了多种放射组学模型（包括决策树、梯度提升、随机森林、支持向量机和多层感知机）和最先进的深度学习模型（如InceptionV3、EfficientNetL和ConvNeXtXLarge）在胸部X光片上检测COVID-19、肺部不透明和病毒性肺炎的诊断性能。性能评估在多个样本量下进行，并使用Scheirer-Ray-Hare检验和Bonferroni校正的Mann-Whitney U检验进行统计分析。

**Result:** 在24个样本时，EfficientNetL的AUC达到0.839，优于SVM的0.762。在4000个样本时，InceptionV3的AUC最高，达到0.996，而随机森林为0.885。统计检验证实模型类型和样本量对所有指标都有显著的主效应和交互效应，且深度学习模型在大多数条件下表现出一致的性能优势。

**Conclusion:** 深度学习模型在数据可用性增加时表现出更高的性能和更好的可扩展性，而放射组学模型在数据量有限的情况下可能仍然有用。本研究为诊断AI中的模型选择提供了经过统计验证的数据驱动建议。

> **ai_Abstract:** 本研究全面比较了放射组学和深度学习模型在胸部X光片上检测COVID-19、肺部不透明和病毒性肺炎等疾病的性能。结果显示，在数据量充足时，深度学习模型表现出更高的诊断准确性（如InceptionV3在4000个样本时AUC达0.996），并具有更好的可扩展性；而在数据量有限的情况下，深度学习模型（如EfficientNetL在24个样本时AUC为0.839）仍优于放射组学模型。研究通过统计验证，为AI诊断模型在不同临床场景下的选择提供了实用指导，强调了深度学习在大数据量下的优势以及放射组学在低数据量下的潜在价值。

> **摘要翻译:** 人工智能（AI）在医学影像中的应用彻底改变了诊断实践，实现了放射数据的先进分析和解释。本研究对基于放射组学和深度学习的方法在胸部X光片疾病检测中的应用进行了全面评估，重点关注COVID-19、肺部不透明和病毒性肺炎。虽然深度学习模型，特别是卷积神经网络和视觉变换器，直接从图像数据中学习，但基于放射组学的模型提取手工特征，在数据有限的情况下具有潜在优势。我们系统地比较了各种AI模型的诊断性能，包括用于放射组学的决策树、梯度提升、随机森林、支持向量机和多层感知机，以及最先进的深度学习模型，如InceptionV3、EfficientNetL和ConvNeXtXLarge。性能在多个样本量下进行了评估。在24个样本时，EfficientNetL的AUC达到0.839，优于SVM的0.762。在4000个样本时，InceptionV3达到了0.996的最高AUC，而随机森林为0.885。Scheirer-Ray-Hare检验证实了模型类型和样本量对所有指标都有显著的主效应和交互效应。事后Bonferroni校正的Mann-Whitney U检验进一步揭示了深度学习模型在大多数条件下具有一致的性能优势。这些发现为诊断AI中的模型选择提供了经过统计验证、数据驱动的建议。深度学习模型随着数据可用性的增加表现出更高的性能和更好的可扩展性，而基于放射组学的模型在低数据环境下可能仍然有用。本研究通过为在不同临床环境中部署AI模型提供实用指导，弥补了AI辅助诊断研究中的一个关键空白。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [701] [UNet-3D with Adaptive TverskyCE Loss for Pancreas Medical Image Segmentation](https://arxiv.org/abs/2505.01951)
> *UNet-3D结合自适应TverskyCE损失用于胰腺医学图像分割*

*Xubei Zhang, Mikhail Y. Shalaginov, Tingying Helen Zeng* | **Category: eess.IV** | **Updated: 2025-07-17**

**Keywords:** 胰腺分割, Tversky损失, 交叉熵损失, UNet-3D, 深度学习

**Comment:** 12 pages and 3 figures

> **TL;DR:** 本研究提出了一种自适应TverskyCE损失函数，用于改进UNet-3D模型在胰腺CT图像分割中的性能，显著提高了分割准确率。

**AI_Comments:** 本研究的创新点在于提出了自适应TverskyCE损失函数，通过动态调整Tversky损失和交叉熵损失的贡献，有效提升了胰腺医学图像分割的准确性。这对于胰腺癌的早期诊断具有重要意义，因为胰腺分割的精确度直接影响后续的诊断和治疗规划。该方法为处理医学图像分割中常见的类别不平衡问题提供了一种有效的策略。

<details>
  <summary>Details</summary>

**Motivation:** 胰腺癌诊断和治疗极具挑战性，生存率低。早期通过CT扫描检测至关重要，但胰腺解剖位置隐蔽、体积小且常被周围器官遮挡，使其难以准确识别和分割。尽管深度学习模型在分割任务中显示出潜力，但其性能仍需显著提升以应对这些挑战。

**Method:** 本研究提出了一种新颖的自适应TverskyCE损失函数，用于深度学习模型训练。该方法通过可学习的权重将Tversky损失与交叉熵损失结合起来，从而在训练过程中自动调整损失贡献，动态优化目标函数以提高性能。所有实验均在NIH胰腺-CT数据集上进行，并在UNet-3D和Dilated UNet-3D模型上评估了该自适应损失函数。

**Result:** 在NIH胰腺-CT数据集上，采用自适应TverskyCE损失的UNet-3D和Dilated UNet-3D模型取得了85.59%的Dice相似系数（DSC），峰值性能达到95.24%。与使用Tversky损失的基线UNet-3D相比，胰腺分割的DSC和得分分别提高了9.47%和8.98%。

**Conclusion:** 本研究提出的自适应TverskyCE损失函数显著提升了UNet-3D模型在胰腺医学图像分割任务中的性能，为胰腺癌的早期诊断提供了更准确的分割工具。

> **ai_Abstract:** 本研究旨在解决胰腺CT图像分割的挑战，提出了一种新颖的自适应TverskyCE损失函数，该函数通过可学习权重结合了Tversky损失和交叉熵损失。该方法能够动态优化深度学习模型的训练过程。在NIH胰腺-CT数据集上，该自适应损失函数显著提升了UNet-3D和Dilated UNet-3D模型的胰腺分割性能，DSC达到了85.59%，并相较于基线模型实现了显著的性能提升。

> **摘要翻译:** 胰腺癌是一种生存率低的癌症，也是最难有效诊断和治疗的癌症之一。通过腹部计算机断层扫描（CT）进行早期检测至关重要，但胰腺解剖位置隐蔽、体积小且常被周围器官遮挡，使其识别和准确分割变得复杂。尽管深度学习（DL）模型在分割任务中显示出潜力，但其性能仍需显著改进以应对这些挑战。在本研究中，我们提出了一种新颖的自适应TverskyCE损失函数用于DL模型训练，该函数通过可学习的权重将Tversky损失与交叉熵损失相结合。我们的方法能够在训练过程中自动调整损失贡献，动态优化目标函数以提高性能。所有实验均在美国国立卫生研究院（NIH）胰腺-CT数据集上进行。我们在UNet-3D和Dilated UNet-3D上评估了自适应TverskyCE损失，我们的方法实现了85.59%的Dice相似系数（DSC），峰值性能高达95.24%，得分为85.14%。与使用Tversky损失的基线UNet-3D进行胰腺分割相比，DSC和得分分别提高了9.47%和8.98%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [44] [Stereo Reproduction in the Presence of Sample Rate Offsets](https://arxiv.org/abs/2507.05402)
> *存在采样率偏移时的立体声再现*

*Srikanth Korse, Andreas Walther, Emanuel A. P. Habets* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-17**

**Keywords:** 采样率偏移, 空间音频, 时钟偏差, 立体声再现, 补偿

**Comment:** Accepted to IEEE Workshop on Applications of Signal Processing to
  Audio and Acoustics (WASPAA) 2025

> **TL;DR:** 本文提出了一种音频域采样率偏移（SRO）补偿方法，通过空间滤波隔离扬声器贡献来估计和补偿SRO，从而减轻无线连接扬声器空间音频再现中的感知退化。

**AI_Comments:** 该论文提出了一种新颖的音频域SRO补偿方法，通过空间滤波来解决无线空间音频系统中的时钟偏差问题。其创新点在于直接在音频域进行SRO估计和补偿，这对于优化听觉体验，尤其是在多扬声器设置中保持空间感至关重要。研究的重要性体现在它解决了现有网络协议未完全解决的感知退化问题。

<details>
  <summary>Details</summary>

**Motivation:** 无线连接扬声器在空间音频再现中的同步主要挑战是时钟偏差，这源于扬声器之间的采样率偏移（SROs）。尽管已探索网络协议，但SROs对空间音频再现及其感知后果的影响仍未得到充分探索。

**Method:** 提出了一种音频域SRO补偿方法，利用空间滤波隔离扬声器贡献。这些滤波后的信号以及原始播放信号用于估计SROs，并在空间音频再现之前对其影响进行补偿。

**Result:** 主观听力测试和客观指标结果表明，所提出的方法通过保留空间线索，减轻了SROs引入的感知退化。

**Conclusion:** 所提出的音频域SRO补偿方法能够有效减轻由采样率偏移引起的空间音频再现中的感知退化。

> **ai_Abstract:** 本文针对无线连接扬声器空间音频再现中由独立设备时钟引起的采样率偏移（SROs）导致的时钟偏差问题，提出了一种音频域SRO补偿方法。该方法利用空间滤波隔离扬声器贡献，并结合原始播放信号来估计SROs，进而在空间音频再现前进行补偿。主观听力测试和客观指标验证了该方法能有效减轻SROs造成的感知退化，从而保持空间线索。

> **摘要翻译:** 在空间音频再现中，无线连接扬声器同步的主要挑战之一是时钟偏差。时钟偏差源于扬声器之间由于使用独立设备时钟而产生的采样率偏移（SROs）。虽然已经探索了像精确时间协议（PTP）和网络时间协议（NTP）这样的基于网络的协议，但SROs对空间音频再现及其感知后果的影响仍未得到充分探索。我们提出了一种使用空间滤波隔离扬声器贡献的音频域SRO补偿方法。这些滤波后的信号与原始播放信号一起用于估计SROs，并在空间音频再现之前对其影响进行补偿。我们通过主观听力测试评估了补偿方法的效果。这些测试的结果以及客观指标表明，所提出的方法通过保留空间线索，减轻了SROs引入的感知退化。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [89] [VoxATtack: A Multimodal Attack on Voice Anonymization Systems](https://arxiv.org/abs/2507.12081)
> *VoxATtack：一种针对语音匿名化系统的多模态攻击*

*Ahmad Aloradi, Ünal Ege Gaznepoglu, Emanuël A. P. Habets, Daniel Tenbrinck* | **Category: eess.AS** | **Updated: 2025-07-17**

**Keywords:** 语音匿名化, 去匿名化攻击, 多模态, ECAPA-TDNN, BERT

**Comment:** 5 pages, 3 figures, 3 tables, accepted at WASPAA 2025

> **TL;DR:** VoxATtack是一种新颖的多模态（声学+文本）去匿名化模型，它通过结合文本信息和数据增强，成功攻击了语音匿名化系统，在多个基准测试中超越了现有技术水平，揭示了当前匿名化方法的漏洞。

**AI_Comments:** VoxATtack的创新之处在于其首次将文本信息与声学信息结合用于语音去匿名化攻击，打破了以往只关注语音表征的局限。这种多模态融合以及数据增强策略的引入，显著提升了攻击的有效性，为理解和改进语音隐私保护技术提供了新的视角。该研究的重要性在于揭示了当前语音匿名化技术的潜在脆弱性，敦促研究人员开发更鲁棒的隐私保护方案。

<details>
  <summary>Details</summary>

**Motivation:** 语音匿名化系统旨在保护说话人隐私，但其保留的语言内容可能被利用来识别特定说话人相关的语义语音模式。本文旨在利用声学和文本信息，开发一种多模态攻击模型，以揭示现有语音匿名化系统的漏洞。

**Method:** 本文提出了VoxATtack模型，这是一种新颖的多模态去匿名化模型。它采用双分支架构：一个ECAPA-TDNN处理匿名化语音，一个预训练的BERT编码文本转录。两个分支的输出被投射到相同维度的嵌入空间，并基于逐语句置信度权重进行融合。此外，模型还利用匿名化语音和SpecAugment作为数据增强技术来提升性能。

**Result:** VoxATtack模型在VoicePrivacy Attacker Challenge (VPAC) 数据集上进行评估，在七个基准测试中的五个（B3、B4、B5、T8-5和T12-5）上超越了顶尖攻击者。通过利用匿名化语音和SpecAugment进行数据增强，VoxATtack在所有VPAC基准测试上都达到了最先进的水平，在T10-2和T25-1上分别获得了20.6%和27.2%的平均等错误率。

**Conclusion:** 研究结果表明，结合文本信息和选择性数据增强揭示了当前语音匿名化方法的关键漏洞，并暴露了用于评估这些方法的数据集的潜在弱点。

> **ai_Abstract:** 本文介绍了VoxATtack，一个新颖的多模态去匿名化模型，旨在攻击语音匿名化系统。该模型通过结合声学（ECAPA-TDNN）和文本（BERT）信息，并利用置信度加权融合，显著提升了攻击性能。实验结果表明，VoxATtack在VoicePrivacy Attacker Challenge (VPAC) 数据集上超越了现有最佳攻击者，并在引入数据增强后，在所有VPAC基准测试上实现了最先进的性能。这项工作揭示了当前语音匿名化方法及评估数据集的潜在漏洞。

> **摘要翻译:** 语音匿名化系统旨在通过模糊声学特征来保护说话人隐私，同时保留对下游应用相关的语言内容。然而，由于这些语言线索保持完整，它们可以被利用来识别与特定说话人相关的语义语音模式。在这项工作中，我们提出了VoxATtack，一种新颖的多模态去匿名化模型，它结合了声学和文本信息来攻击匿名化系统。虽然之前的研究主要集中在完善从语音中提取的说话人表示，但我们表明，将文本信息与标准ECAPA-TDNN结合可以提高攻击者的性能。我们提出的VoxATtack模型采用双分支架构，其中一个ECAPA-TDNN处理匿名化语音，一个预训练的BERT编码转录本。两个输出都被投射到相同维度的嵌入空间，然后根据逐语句计算的置信度权重进行融合。在VoicePrivacy Attacker Challenge (VPAC) 数据集上评估我们的方法时，它在七个基准测试中的五个（B3、B4、B5、T8-5和T12-5）上超越了排名靠前的攻击者。为了进一步提升性能，我们利用匿名化语音和SpecAugment作为增强技术。这种增强使VoxATtack在所有VPAC基准测试上都达到了最先进的水平，在T10-2和T25-1上分别获得了20.6%和27.2%的平均等错误率。我们的结果表明，结合文本信息和选择性数据增强揭示了当前语音匿名化方法的关键漏洞，并暴露了用于评估这些方法的数据集的潜在弱点。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [315] [Enhancing In-Domain and Out-Domain EmoFake Detection via Cooperative Multilingual Speech Foundation Models](https://arxiv.org/abs/2507.12595)
> *通过协作多语言语音基础模型增强域内和域外情感伪造检测*

*Orchid Chetia Phukan, Mohd Mujtaba Akhtar, Girish, Arun Balaji Buduru* | **Category: eess.AS** | **Updated: 2025-07-16**

**Keywords:** 情感伪造检测, 多语言语音基础模型, 模型融合, THAMA, 域内域外检测

**Comment:** 

> **TL;DR:** 本文通过比较分析证明了多语言语音基础模型在情感伪造检测（EFD）中的优越性，并提出了THAMA融合方法，该方法与多语言SFM协同作用，在域内和域外EFD任务中均取得了最顶尖的性能。

**AI_Comments:** 本文的创新点在于提出了THAMA这种新颖的融合方法，它巧妙地结合了Tucker分解和Hadamard积，以有效融合基础模型。其重要性体现在通过利用多语言语音基础模型的跨语言理解能力，并结合高效的融合策略，显著提升了情感伪造检测在不同语言环境下的性能，为该领域树立了新的SOTA。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决情感伪造检测（EFD）问题。研究者假设多语言语音基础模型（SFMs）由于其在多种语言上的预训练，能够细致理解音高、音调和强度变化，因此特别适用于EFD。

**Method:** 研究方法包括对最先进（SOTA）的多语言语音基础模型进行全面的比较分析。此外，本文提出了一种名为THAMA的融合方法，该方法结合了Tucker分解和Hadamard积，用于有效融合基础模型（FMs），以进一步提升性能。

**Result:** 研究结果表明，多语言SFMs在同语言（域内）和跨语言（域外）情感伪造检测评估中均表现出优越性。结合THAMA与协作式多语言SFMs，在域内和域外设置中均实现了最佳性能，超越了单独的基础模型、基线融合技术和之前的SOTA方法。

**Conclusion:** 多语言语音基础模型在情感伪造检测中表现出色，并且通过引入THAMA这种新颖的融合技术，可以进一步显著提升其在域内和域外场景下的检测性能，达到最先进的水平。

> **ai_Abstract:** 本文致力于情感伪造检测（EFD），并提出多语言语音基础模型（SFMs）因其跨语言预训练的特性，能有效理解语音细微变化，从而适用于EFD。通过对现有SOTA SFMs的比较分析，证明了多语言SFMs在域内和域外EFD任务中的优越性。在此基础上，论文进一步提出了一种新颖的融合方法THAMA，该方法结合了Tucker分解和Hadamard积。实验结果显示，THAMA与协作多语言SFMs的协同作用，在域内和域外场景下均实现了最顶尖的性能，超越了单一模型及现有基线方法。

> **摘要翻译:** 在这项工作中，我们解决了情感伪造检测（EFD）问题。我们假设多语言语音基础模型（SFMs）由于其在多种语言上的预训练，能够细致理解音高、音调和强度变化，因此对EFD特别有效。为了验证这一点，我们对最先进（SOTA）的SFMs进行了全面的比较分析。我们的结果表明，多语言SFMs在同语言（域内）以及跨语言（域外）评估中均表现出优越性。为此，我们还提出了THAMA，这是一种受相关研究启发的融合基础模型（FMs）的方法，其中结合FMs已显示出性能提升。THAMA利用Tucker分解和Hadamard积的互补结合来实现有效融合。THAMA与协作多语言SFMs协同作用，在域内和域外设置中均取得了最佳性能，超越了单独的FMs、基线融合技术和先前的SOTA方法。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [363] [DiffRhythm+: Controllable and Flexible Full-Length Song Generation with Preference Optimization](https://arxiv.org/abs/2507.12890)
> *DiffRhythm+: 可控且灵活的偏好优化全长歌曲生成*

*Huakang Chen, Yuepeng Jiang, Guobin Ma, Chunbo Hao, Shuai Wang, Jixun Yao, Ziqian Ning, Meng Meng, Jian Luan, Lei Xie* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-17**

**Keywords:** 全长歌曲生成, 扩散模型, 可控性, 偏好优化, 音乐合成

**Comment:** 

> **TL;DR:** DiffRhythm+是一个增强的扩散模型，通过扩大数据集、多模态风格条件化和偏好优化，解决了现有全长歌曲生成模型在数据不平衡、可控性不足和音乐质量不一致方面的挑战，显著提升了歌曲的自然度、编曲复杂性和听众满意度。

**AI_Comments:** DiffRhythm+的创新之处在于其综合性方法，通过结合大规模平衡数据集、多模态风格控制和用户偏好优化，系统地解决了全长歌曲生成中的核心挑战。这不仅提升了生成歌曲的质量，也极大地增强了用户对音乐风格的创作灵活性和控制能力，为音乐生成领域带来了显著的进步。

<details>
  <summary>Details</summary>

**Motivation:** 当前全长歌曲合成系统面临数据不平衡、可控性不足和音乐质量不一致等重大挑战。先前的DiffRhythm模型受限于不平衡的训练数据集和有限的音乐风格可控性，导致质量差异和创造灵活性受限。

**Method:** DiffRhythm+通过以下方式实现：1. 扩展并平衡训练数据集，以缓解歌词重复和遗漏问题，并培养更丰富的音乐技能和表现力。2. 引入多模态风格条件化策略，允许用户通过描述性文本和参考音频精确指定音乐风格，增强创造控制和多样性。3. 引入与用户偏好对齐的直接性能优化，引导模型生成持续符合偏好的输出。

**Result:** DiffRhythm+在自然度、编曲复杂性和听众满意度方面比现有系统取得了显著的改进。

**Conclusion:** DiffRhythm+通过改进数据集、引入多模态风格控制和偏好优化，成功克服了全长歌曲生成中的主要限制，显著提升了生成歌曲的质量和可控性。

> **ai_Abstract:** DiffRhythm+是一个增强的扩散模型，旨在解决全长歌曲生成中数据不平衡、可控性不足和音乐质量不一致的问题。该模型通过扩展和平衡训练数据集来提升歌词和音乐表现力，引入多模态风格条件化（文本和音频）以增强创作控制和多样性，并采用用户偏好优化以提高输出质量。实验证明，DiffRhythm+在歌曲的自然度、编曲复杂性和听众满意度方面均优于现有系统。

> **摘要翻译:** 歌曲作为音乐艺术的核心形式，体现了人类智慧和创造力的丰富性。尽管生成建模的最新进展在长篇歌曲生成方面取得了显著进展，但当前的全长歌曲合成系统仍面临重大挑战，包括数据不平衡、可控性不足和音乐质量不一致。DiffRhythm作为一个开创性的基于扩散的模型，通过生成带有表现力人声和伴奏的全长歌曲，推动了该领域的发展。然而，其性能受限于不平衡的模型训练数据集和有限的音乐风格可控性，导致明显的质量差异和受限的创作灵活性。为了解决这些限制，我们提出了DiffRhythm+，一个增强的基于扩散的框架，用于可控和灵活的全长歌曲生成。DiffRhythm+利用大幅扩展和平衡的训练数据集来缓解歌词重复和遗漏等问题，同时培养更丰富的音乐技能和表现力。该框架引入了多模态风格条件化策略，使用户能够通过描述性文本和参考音频精确指定音乐风格，从而显著增强创造性控制和多样性。我们进一步引入了与用户偏好对齐的直接性能优化，引导模型在评估指标上持续生成偏好的输出。广泛的实验表明，DiffRhythm+在自然度、编曲复杂性和听众满意度方面比现有系统取得了显著改进。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [406] [AVFSNet: Audio-Visual Speech Separation for Flexible Number of Speakers with Multi-Scale and Multi-Task Learning](https://arxiv.org/abs/2507.12972)
> *AVFSNet: 基于多尺度和多任务学习的灵活说话人数音视频语音分离*

*Daning Zhang, Ying Wei* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-17**

**Keywords:** 音视频语音分离, 灵活说话人数, 多尺度学习, 多任务学习, AVFSNet

**Comment:** 

> **TL;DR:** AVFSNet提出了一种音视频语音分离模型，通过多尺度和多任务学习处理未知说话人数的混合信号，并取得了最先进的性能。

**AI_Comments:** AVFSNet的创新之处在于其能够处理灵活数量的说话人，这是现有方法的一个主要局限。通过结合音视频信息、多尺度编码和多任务学习，该模型在解决实际复杂声学环境中的语音分离问题上迈出了重要一步。其并行分离和联合优化的设计提高了模型的效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音分离方法大多假设已知混合信号中的说话人数，而处理未知说话人数场景的研究泛化能力有限，难以适应真实声学环境。本文旨在克服这些挑战。

**Method:** 本文提出了AVFSNet模型，它是一个音视频语音分离模型，集成了多尺度编码和并行架构。该模型针对说话人计数和多说话人分离任务进行联合优化，独立并行分离每个说话人，并通过整合视觉信息增强对环境噪声的适应性。

**Result:** AVFSNet在多个评估指标上取得了最先进的成果，并在不同数据集上表现出色。

**Conclusion:** AVFSNet通过其创新的多尺度和多任务学习方法，成功解决了未知说话人数语音分离的挑战，并在性能上超越了现有技术。

> **ai_Abstract:** AVFSNet是一种新型的音视频语音分离模型，旨在解决混合信号中说话人数量未知的问题。该模型结合了多尺度编码和并行架构，并通过多任务学习同时进行说话人计数和多说话人分离。它能够独立并行地分离每个说话人，并利用视觉信息提高对噪声的适应性。实验结果表明，AVFSNet在多项评估指标和不同数据集上均达到了最先进的性能。

> **摘要翻译:** 将目标语音从包含灵活说话人数量的混合信号中分离出来是一项具有挑战性的任务。虽然现有方法表现出强大的分离性能和噪声鲁棒性，但它们主要假设已知混合信号中的说话人数量。针对未知说话人数量场景的有限研究在真实声学环境中表现出显著受限的泛化能力。为了克服这些挑战，本文提出了AVFSNet——一种集成多尺度编码和并行架构的音视频语音分离模型——该模型针对说话人计数和多说话人分离任务进行联合优化。该模型独立并行分离每个说话人，同时通过整合视觉信息增强环境噪声适应性。全面的实验评估表明，AVFSNet在多个评估指标上取得了最先进的成果，并在不同数据集上提供了出色的性能。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [630] [UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets](https://arxiv.org/abs/2507.12951)
> *UniSLU：从异构跨任务数据集中实现统一的口语理解*

*Zhichao Sheng, Shilin Zhou, Chen Gong, Zhenghua Li* | **Category: eess.AS, cs.AI, cs.CL, cs.MM, cs.SD** | **Updated: 2025-07-17**

**Keywords:** 口语理解, 统一框架, 异构数据集, 多任务学习, 大型语言模型

**Comment:** 13 pages, 3 figures

> **TL;DR:** UniSLU是一个统一的框架，在一个架构中共同建模多种口语理解任务，利用异构数据集并增强任务交互，性能优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了一个统一的框架UniSLU，通过单一架构和统一表示来处理多种口语理解任务，有效解决了传统方法中模型复杂和数据利用不足的问题。其与大型语言模型的无缝集成也具有重要意义，预示着未来SLU系统更强大的生成能力。该方法的有效性在实验中得到了验证，并承诺开源，有助于推动该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有口语理解（SLU）方法通常为ASR、口语NER和SA等不同任务使用独立的模型架构，这增加了系统复杂性，限制了跨任务交互，并且未能充分利用跨任务可用的异构数据集。

**Method:** 提出UniSLU，一个在单一架构中联合建模多种SLU任务的统一框架。具体来说，提出了一种针对不同SLU任务的统一表示，以充分利用跨多个任务的异构数据集。在此表示的基础上，提出了一种统一的生成方法，联合建模ASR、口语NER和SA任务，增强任务交互，并能与大型语言模型无缝集成。

**Result:** 在公共SLU数据集上的广泛实验表明，该方法有效，与几种基准方法相比，实现了卓越的SLU性能。

**Conclusion:** UniSLU方法在真实世界的基于语音的多媒体场景中表现良好，并且代码和模型将被发布以促进未来的研究。

> **ai_Abstract:** 本文提出了UniSLU，一个用于口语理解（SLU）的统一框架，旨在解决现有方法中因独立模型架构而导致的复杂性、任务间交互受限以及异构数据集利用不足的问题。UniSLU引入了一种统一表示和生成方法，在一个单一架构中联合建模ASR、口语NER和SA等多种SLU任务，从而增强了任务间的交互并能与大型语言模型集成。实验结果表明，UniSLU在SLU性能上优于基准方法，适用于实际应用。

> **摘要翻译:** 口语理解（SLU）在以语音为中心的多媒体应用中扮演着关键角色，使机器能够在会议、访谈和客户服务交互等场景中理解口语。SLU包含多项任务，包括自动语音识别（ASR）、口语命名实体识别（NER）和口语情感分析（SA）。然而，现有方法通常依赖于针对口语NER和SA等单个任务的独立模型架构，这增加了系统复杂性，限制了跨任务交互，并且未能充分利用跨任务可用的异构数据集。为了解决这些限制，我们提出了UniSLU，一个在单一架构中联合建模多种SLU任务的统一框架。具体来说，我们提出了一种针对不同SLU任务的统一表示，从而能够充分利用跨多个任务的异构数据集。在此表示的基础上，我们提出了一种统一的生成方法，联合建模ASR、口语NER和SA任务，增强任务交互，并能与大型语言模型无缝集成，以利用其强大的生成能力。在公共SLU数据集上的广泛实验证明了我们方法的有效性，与几种基准方法相比，实现了卓越的SLU性能，使其非常适用于真实世界的基于语音的多媒体场景。我们将发布所有代码和模型在GitHub上，以促进未来的研究。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [705] [A lightweight and robust method for blind wideband-to-fullband extension of speech](https://arxiv.org/abs/2412.11392)
> *一种轻量级、鲁棒的语音盲宽带到全带扩展方法*

*Jan Büthe, Jean-Marc Valin* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-17**

**Keywords:** 带宽扩展, 语音处理, 宽带到全带, 轻量级, 鲁棒性

**Comment:** WASPAA 2025, 5 pages

> **TL;DR:** 提出了一种轻量级、鲁棒的语音盲宽带到全带扩展方法，该方法参数少、计算复杂度低，能显著提升语音质量并达到或超越现有编解码器的性能，实现向后兼容的质量提升。

**AI_Comments:** 该论文提出了一种创新的盲带宽扩展方法，其亮点在于其“轻量级”和“鲁棒性”的特点。模型参数少、计算复杂度低，使其在资源受限环境下具有很高的实用性。更重要的是，它证明了盲带宽扩展可以达到甚至超越经典引导式带宽扩展的质量，为语音通信的向后兼容质量提升提供了新的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的环境中，如低带宽语音传输或低复杂度声码器，减少语音带宽是常见做法。本文旨在提出一种轻量级且鲁棒的方法来扩展宽带语音信号的带宽。

**Method:** 本文提出了一种受经典语音编码方法启发的轻量级、鲁棒的宽带语音信号带宽扩展方法。该模型仅有约37万参数，复杂度约为140 MFLOPS（或70 MMACS），帧大小为10毫秒，前瞻性仅为0.27毫秒。

**Result:** 该模型与Opus SILK语音编解码器（1.5版本）结合使用时，在P.808 DCR听力测试中，能将6到12 kb/s的语音质量显著提升。此外，Opus 1.5结合所提出的带宽扩展在9 kb/s时能达到3GPP EVS在9.6 kb/s的质量，以及Opus 1.4在18 kb/s的质量。

**Conclusion:** 所提出的盲带宽扩展方法能够达到经典引导式带宽扩展的质量，从而为向后兼容的质量改进提供了一种途径。

> **ai_Abstract:** 本文提出了一种轻量级、鲁棒的语音盲宽带到全带扩展方法，灵感来源于经典语音编码技术。该模型参数少、计算复杂度低，适用于常见宽带语音编解码器。实验证明，该方法能显著提升语音质量，并能在较低码率下达到或超越现有高质量编解码器的性能，为向后兼容的语音质量改进提供了有效途径。

> **摘要翻译:** 在资源受限的环境中，如低带宽语音传输或低复杂度声码器，减少语音带宽是常见做法。我们提出了一种受语音编码领域经典方法启发的轻量级、鲁棒的宽带语音信号带宽扩展方法。由此产生的模型只有约37万个参数，复杂度约为140 MFLOPS（或70 MMACS）。该模型以10毫秒的帧大小和仅0.27毫秒的前瞻性，非常适合与常见的宽带语音编解码器配合使用。我们通过将其与Opus SILK语音编解码器（1.5版本）配对来评估模型的鲁棒性，并在P.808 DCR听力测试中验证了它能将6到12 kb/s的质量显著提高。我们还证明了Opus 1.5结合所提出的9 kb/s带宽扩展能够达到3GPP EVS在9.6 kb/s的质量以及Opus 1.4在18 kb/s的质量，这表明盲带宽扩展可以达到经典引导式带宽扩展的质量，从而为向后兼容的质量改进提供了一种方法。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [5] [A Logically Consistent Chain-of-Thought Approach for Stance Detection](https://arxiv.org/abs/2312.16054)
> *针对立场检测的逻辑一致思维链方法*

*Bowen Zhang, Daijun Ding, Liwen Jing, Hu Huang* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 零样本立场检测, 思维链, 逻辑一致性, 背景知识, 大语言模型

**Comment:** 

> **TL;DR:** 提出了一种逻辑一致的思维链（LC-CoT）方法，通过确保相关且逻辑合理的知识提取来改进零样本立场检测，优于传统有监督方法。

**AI_Comments:** LC-CoT的创新之处在于其将思维链与逻辑一致性相结合，并通过结构化的三步流程有效解决了零样本立场检测中知识与任务的脱节问题。其亮点是能够不依赖标注数据，且性能优于有监督方法，这对于资源匮乏的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本立场检测（ZSSD）方法在融合背景知识时常面临知识与任务脱节以及预测缺乏逻辑一致性的问题。

**Method:** 引入了逻辑一致思维链（LC-CoT）方法。该方法包含三步：首先评估是否需要外部知识；其次通过API调用检索知识（可由单独的LLM处理）；最后，通过手动示例引导LLM，使用“如果-那么”逻辑结构推断立场类别，以保持相关性和逻辑连贯性。

**Result:** 该方法在不依赖标注数据的情况下，提升了模型的性能，并优于传统的有监督方法。

**Conclusion:** LC-CoT通过其结构化的知识提取和逻辑推理过程，有效解决了零样本立场检测中的知识-任务脱节和逻辑一致性问题，显著提升了检测性能。

> **ai_Abstract:** 本文提出了一种名为逻辑一致思维链（LC-CoT）的新型零样本立场检测方法。针对现有方法在知识融合中存在的知识-任务脱节和逻辑一致性问题，LC-CoT通过三步流程确保知识提取的相关性和逻辑性：评估知识需求、通过API检索知识（可由LLM处理），并利用手动示例和“如果-那么”逻辑结构进行立场推断。实验结果表明，LC-CoT在不依赖标注数据的情况下，性能优于传统的有监督方法。

> **摘要翻译:** 零样本立场检测（ZSSD）旨在检测对未见目标的立场。结合背景知识以增强已见目标和未见目标之间的可迁移性构成了ZSSD的主要方法。然而，这些方法常常面临知识-任务脱节和预测缺乏逻辑一致性的问题。为了解决这些问题，我们引入了一种名为逻辑一致思维链（LC-CoT）的新方法，用于ZSSD，它通过确保相关且逻辑合理的知识提取来改进立场检测。LC-CoT采用三步过程。首先，它评估是否需要补充外部知识。随后，它使用API调用检索这些知识，这些知识可以由单独的LLM进行处理。最后，一个手动示例引导LLM推断立场类别，使用“如果-那么”逻辑结构来保持相关性和逻辑连贯性。这种结构化的背景知识启发方法增强了模型的能力，其性能优于传统的有监督方法，且不依赖于标注数据。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [9] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
> *AdaptiSent：面向多模态方面级情感分析的上下文感知自适应注意力机制*

*S M Rafiuddin, Sadia Kamal, Mohammed Rakib, Arunkumar Bagavathi, Atriya Sen* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 多模态情感分析, 方面级情感分析, 自适应注意力, 跨模态, AdaptiSent

**Comment:** 12 pages (including references), 2 figures (Fig. 1 overview, Fig. 2
  hyperparameter sensitivity with two subplots), 6 tables (performance,
  ablation, dataset stats, case studies, etc.), accepted at ASONAM 2025 (Social
  Network Analysis and Mining)

> **TL;DR:** AdaptiSent是一个新的多模态方面级情感分析框架，通过自适应跨模态注意力机制和动态模态加权，显著提升了情感分类和方面术语提取的准确性，超越了现有模型。

**AI_Comments:** AdaptiSent的创新之处在于其引入的自适应跨模态注意力机制和动态模态加权，这使得模型能够根据上下文动态调整对不同模态信息的关注，从而更有效地捕捉多模态数据中的细微情感和方面信息。这对于解决多模态情感分析中复杂的模态间关系问题具有重要意义，并为未来的MABSA研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态方面级情感分析（MABSA）方法在情感分类和方面术语提取方面可能存在局限性，尤其是在理解文本线索和视觉上下文之间复杂交互方面。本研究旨在通过引入上下文感知自适应注意力机制来改进这一领域。

**Method:** 本研究提出了AdaptiSent框架，该框架利用自适应跨模态注意力机制来改进多模态方面级情感分析。模型集成了动态模态加权和上下文自适应注意力，通过关注文本线索和视觉上下文的交互来增强情感和方面相关信息的提取。

**Result:** 在标准Twitter数据集上的测试结果表明，AdaptiSent在准确率、召回率和F1分数上均超越了包括传统文本模型和其他多模态方法在内的现有基线模型。它在识别对准确情感和方面术语提取至关重要的细微模态间关系方面特别有效，这得益于模型能够根据上下文相关性动态调整其焦点。

**Conclusion:** AdaptiSent为多模态方面级情感分析（MABSA）设定了新标准，显著优于当前方法，特别是在理解复杂多模态信息方面。

> **ai_Abstract:** AdaptiSent是一个针对多模态方面级情感分析（MABSA）提出的新型框架。它通过整合自适应跨模态注意力机制、动态模态加权和上下文自适应注意力，有效利用文本和视觉上下文的交互来提升情感分类和方面术语提取的准确性。在标准Twitter数据集上的实验结果表明，AdaptiSent在各项性能指标上均优于现有基线模型，尤其擅长识别复杂的模态间关系，为MABSA领域树立了新标准。

> **摘要翻译:** 我们引入了AdaptiSent，这是一个用于多模态方面级情感分析（MABSA）的新框架，它使用自适应跨模态注意力机制来改进文本和图像中的情感分类和方面术语提取。我们的模型整合了动态模态加权和上下文自适应注意力，通过关注文本线索和视觉上下文如何交互，增强了情感和方面相关信息的提取。我们针对包括传统基于文本模型和其他多模态方法在内的多个基线测试了我们的方法。来自标准Twitter数据集的结果表明，AdaptiSent在准确率、召回率和F1分数上超越了现有模型，并且在识别对准确情感和方面术语提取至关重要的细微模态间关系方面特别有效。这种有效性源于模型能够根据上下文的相关性动态调整其焦点，从而提高了各种多模态数据集上情感分析的深度和准确性。AdaptiSent为MABSA设定了新标准，显著优于当前方法，尤其是在理解复杂多模态信息方面。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [35] [Exploiting Adaptive Contextual Masking for Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2402.13722)
> *利用自适应上下文掩码进行方面级情感分析*

*S M Rafiuddin, Mohammed Rakib, Sadia Kamal, Arunkumar Bagavathi* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 方面级情感分析, 自适应掩码, 上下文掩码, 注意力机制

**Comment:** 12 pages, 4 figures, Accepted at PAKDD 2024

> **TL;DR:** 本文提出自适应掩码方法，通过移除不相关token来改进方面级情感分析（ABSA），并在基准数据集上超越基线方法。

**AI_Comments:** 该研究通过引入自适应上下文掩码机制，有效解决了传统静态掩码在处理复杂上下文时的问题，提升了方面级情感分析的准确性。其创新点在于根据上下文动态调整掩码，更精细地捕获词语的相关性，对于细粒度情感分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前方面级情感分析（ABSA）方法在注意力掩码机制中依赖静态超参数，导致上下文适应性差，难以准确分析包含多方面和不同情感的复杂句子。

**Method:** 本文提出自适应掩码方法，根据上下文移除不相关的token，以辅助ABSA中的方面术语提取和方面情感分类子任务。

**Result:** 实验表明，所提出的方法在四个基准在线评论数据集上的准确率和F1分数均优于基线方法。此外，该方法可扩展多种适应性，并通过样本文本展示了方面术语提取的定性分析。

**Conclusion:** 所提出的自适应上下文掩码方法有效提高了方面级情感分析的性能，解决了现有方法在上下文适应性方面的局限。

> **ai_Abstract:** 本文针对方面级情感分析（ABSA）中现有方法在注意力掩码机制上对上下文适应性不足的问题，提出了一种自适应掩码方法。该方法根据上下文移除不相关的token，以增强方面术语提取和方面情感分类子任务的性能。实验结果表明，在四个基准在线评论数据集上，所提出的方法在准确率和F1分数上均优于基线方法，并展现了其可扩展性和对方面术语提取的有效性。

> **摘要翻译:** 方面级情感分析（ABSA）是一个细粒度的语言学问题，它需要从给定文本中提取多方面的方面、观点和情感。独立和复合的ABSA任务在文献中已被广泛用于检查在线评论和社交媒体帖子中存在的细微信息。当前的ABSA方法通常依赖于注意力掩码机制的静态超参数，这可能在上下文适应方面遇到困难，并可能忽略在不同情况下的词语的独特相关性。这导致在准确分析包含多个方面且情感不同的复杂句子时面临挑战。在这项工作中，我们提出了自适应掩码方法，根据上下文移除不相关的token，以辅助ABSA的方面术语提取和方面情感分类子任务。我们的实验表明，所提出的方法在四个基准在线评论数据集上的准确率和F1分数均优于基线方法。此外，我们还表明所提出的方法可以扩展多种适应性，并使用样本文本对所提出的方面术语提取方法进行了定性分析。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [54] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
> *FLEXITOKENS: 灵活分词以适应演进的语言模型*

*Abraham Toluase Owodunni, Orevaoghene Ahia, Sachin Kumar* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 灵活分词, 语言模型, 字节级LMs, 过度碎片化, FLEXITOKENS

**Comment:** 

> **TL;DR:** FLEXITOKENS提出了一种灵活的分词方法，通过可学习的分词器和简化的训练目标，解决了语言模型在适应新数据分布时分词器僵化的问题，显著减少了token过度碎片化并提升了下游任务性能。

**AI_Comments:** FLEXITOKENS的创新之处在于其提出了可学习的字节级分词器和简化的训练目标，这有效解决了传统子词分词器在处理新数据分布时的固有僵化问题。通过允许分词过程的灵活性，该方法显著提高了语言模型在多语言和形态复杂任务上的适应性和性能，对提升LMs的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型（LMs）难以通过简单的微调来适应新的数据分布，这是由于其子词分词器的僵化性，导致在域外数据、未见语言或脚本上分词效率低下，造成过度碎片化。

**Method:** 本文开发了带有可学习分词器的字节级语言模型，其中包含一个子模块，该子模块学习预测输入字节序列之间的边界，并将其编码为可变长度的片段。与现有强制固定压缩率的分词器无关的方法不同，本文提出了FLEXITOKENS，一个简化的训练目标，以在适应过程中实现更大的灵活性。

**Result:** FLEXITOKENS在多个多语言基准测试、形态多样的任务和领域中进行评估，结果表明它始终如一地减少了token过度碎片化，并且与子词分词器和其他基于梯度的分词器相比，在下游任务性能上实现了高达10%的改进。

**Conclusion:** FLEXITOKENS通过引入灵活、可学习的分词器和简化的训练目标，有效解决了语言模型在适应新数据分布时分词器僵化的问题，显著提高了分词效率和下游任务性能。

> **ai_Abstract:** 该论文提出了FLEXITOKENS，一种针对语言模型（LMs）的灵活分词方法，旨在解决现有子词分词器在适应新数据分布时存在的僵化和过度碎片化问题。通过开发带有可学习分词器的字节级LMs，并引入一个简化的训练目标，FLEXITOKENS允许分词器在适应过程中保持更大的灵活性。实验结果表明，FLEXITOKENS显著减少了token的过度碎片化，并在多语言基准测试和形态多样的任务中，相比传统分词器，下游任务性能提高了高达10%。

> **摘要翻译:** 语言模型（LMs）难以通过简单的微调来适应新的数据分布。这是由于其子词分词器的僵化性，这些分词器在适应过程中通常保持不变。这种不灵活性常常导致低效的分词，造成域外领域、未见语言或脚本的过度碎片化。在这项工作中，我们开发了带有可学习分词器的字节级语言模型，以使分词具有适应性。我们的模型包含一个子模块，该子模块学习预测输入字节序列之间的边界，并将其编码为可变长度的片段。现有无分词器方法使用辅助损失训练此边界预测器，该损失在整个训练语料库中强制执行固定的压缩率，引入了一种新的僵化。我们提出了FLEXITOKENS，一个简化的训练目标，可在适应过程中实现显著更大的灵活性。通过在多个多语言基准测试、形态多样的任务和领域中进行评估，我们证明FLEXITOKENS始终如一地减少了token过度碎片化，并且与子词分词器和其他基于梯度的分词器相比，在下游任务性能上实现了高达10%的改进。我们实验的代码和数据将在https://github.com/owos/flexitokens发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [60] [On the Limitations of Large Language Models (LLMs): False Attribution](https://arxiv.org/abs/2404.04631)
> *大型语言模型（LLMs）的局限性：虚假归因*

*Tosin Adewumi, Nudrat Habib, Lama Alkhaled, Elisa Barney* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 幻觉, 虚假归因, 作者归因, Simple Hallucination Index

**Comment:** This paper was accepted for presentation by Recent Advances in NLP
  (RANLP) 2025 conference

> **TL;DR:** 本文引入了Simple Hallucination Index (SHI)度量，并评估了LLM在作者归因任务中的虚假归因问题，发现Mixtral 8x7B表现最佳但存在高幻觉，且SHI与准确性呈强负相关。

**AI_Comments:** 本文的创新点在于提出了Simple Hallucination Index (SHI)这一新的幻觉度量，并首次系统地将其应用于评估LLM在作者归因任务中的虚假归因问题。研究结果揭示了即使是最先进的LLM也存在显著的幻觉现象，尤其是在特定数据上，这对于理解LLM的局限性具有重要意义。SHI与准确性之间的强负相关性表明其作为幻觉度量的有效性，并可能推广到其他需要评估LLM可靠性的任务。公开数据集和代码也提升了研究的透明度和可复现性，对后续研究具有积极的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究大型语言模型（LLMs）参数知识的一个重要局限性，即虚假归因，并通过引入新的幻觉度量SHI来评估其表现。

**Method:** 研究引入了Simple Hallucination Index (SHI)作为新的幻觉度量。通过在零样本设置下，评估了Gemma-7B、Mixtral 8x7B和LLaMA-2-13B三种开放SotA LLM在自动作者归因任务上的能力。实验数据来自Project Gutenberg中最受欢迎的10本书，每本书被分成400字的文本块。LLM被要求预测作者，并随机抽取162个文本块进行人工评估。研究还进行了错误分析，并公开了带注释的数据块和代码。

**Result:** 平均结果显示，Mixtral 8x7B具有最高的预测准确性、最低的SHI和-0.9996的皮尔逊相关系数(r)，其次是LLaMA-2-13B和Gemma-7B。然而，Mixtral 8x7B在三本书上表现出高幻觉，SHI高达0.87。准确性和SHI之间存在强烈的负相关（r），这证明了新幻觉度量的准确性。此外，预测准确性与书籍标题的维基百科实例频率呈正相关，而非下载量。

**Conclusion:** 研究表明，新引入的Simple Hallucination Index (SHI)是一个可靠的幻觉度量，其与预测准确性呈强负相关，并可能推广到其他任务。LLMs在作者归因任务中存在虚假归因的局限性，即使是表现最佳的模型也可能产生高幻觉。书籍在维基百科上的流行度而非下载量能更好地预测LLM的归因准确性。

> **ai_Abstract:** 本文引入了Simple Hallucination Index (SHI)这一新的幻觉度量，并以此评估了大型语言模型（LLMs）在零样本作者归因任务中存在的虚假归因问题。研究对比了Gemma-7B、Mixtral 8x7B和LLaMA-2-13B，发现Mixtral 8x7B在准确性上表现最佳，且SHI最低，但对于部分书籍仍存在严重幻觉。结果表明，SHI与预测准确性呈强负相关，验证了该度量的有效性。此外，LLM的归因准确性与书籍标题的维基百科提及频率正相关。研究公开了数据集和代码，以促进可复现性。

> **摘要翻译:** 在这项工作中，我们引入了一种新的幻觉度量——简单幻觉指数（SHI），并深入探讨了大型语言模型（LLMs）参数知识的一个重要局限性，即虚假归因。对于相对较小的文本块进行自动作者归因是一项重要的NLP任务，但也可能具有挑战性。我们实证评估了三种开放的SotA LLM（Gemma-7B、Mixtral 8x7B和LLaMA-2-13B）在零样本设置下的能力。我们根据Project Gutenberg获取了当月最受欢迎的10本书，将每本书分成等长的400字文本块，并提示每个LLM预测作者。然后，我们根据7%的误差幅度核95%的置信水平，从每本书中随机抽取162个文本块进行人工评估。平均结果显示，Mixtral 8x7B具有最高的预测准确性、最低的SHI和0.724、0.263、-0.9996的皮尔逊相关系数（r），其次是LLaMA-2-13B和Gemma-7B。然而，Mixtral 8x7B在三本书上遭受了高幻觉，SHI高达0.87（范围0-1，其中1是最差）。准确性和SHI之间强烈的负相关（由r给出）证明了新幻觉度量的忠实性，这可能推广到其他任务。我们还表明，预测准确性与书籍标题的维基百科实例频率呈正相关，而不是下载量，并且我们对预测进行了错误分析。我们公开发布了带注释的数据块和我们的代码，以帮助其他模型的可复现性和评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [85] [SCULPT: Systematic Tuning of Long Prompts](https://arxiv.org/abs/2410.20788)
> *SCULPT：长提示的系统调优*

*Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 提示优化, 大型语言模型, 长提示, 树结构, Critic-Actor框架

**Comment:** Accepted at ACL Main 2025

> **TL;DR:** SCULPT是一个用于优化长提示的框架，它将提示视为树结构，并使用Critic-Actor框架进行分层细化，解决了现有方法在处理长提示时的局限性，显著提高了大型语言模型的性能和鲁棒性。

**AI_Comments:** SCULPT的创新之处在于其将长提示优化转化为分层树细化问题，并引入了Critic-Actor框架，这提供了一种结构化且可解释的方法来处理复杂提示。其无需初始人工提示即可生成高性能提示的能力，以及在鲁棒性和泛化能力上的提升，显示了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型提示优化方法在处理长而复杂的提示时面临挑战，容易导致信息丢失且对小扰动敏感，因此需要一种新的方法来有效优化长提示。

**Method:** 本文提出了SCULPT（Systematic Tuning of Long Prompts）框架，将提示优化视为一个分层的树细化问题。SCULPT将提示表示为树结构，实现有针对性的修改同时保持上下文完整性。它采用Critic-Actor框架来生成反思并应用行动来细化提示。

**Result:** 评估表明SCULPT在长提示上是有效的，对对抗性扰动具有鲁棒性，并且即使没有初始的人工编写提示也能生成高性能的提示。与现有最先进的方法相比，SCULPT通过保留必要的任务信息并应用结构化细化，持续提高大型语言模型的性能。定性和定量分析都表明，SCULPT产生更稳定和可解释的提示修改，确保在不同任务中具有更好的泛化能力。

**Conclusion:** SCULPT框架通过将长提示优化视为分层树细化问题，并采用Critic-Actor框架，有效解决了现有方法在处理长提示时的局限性，显著提升了大型语言模型在性能、鲁棒性和泛化能力方面的表现。

> **ai_Abstract:** SCULPT是一个新颖的框架，专门用于系统地优化大型语言模型的长提示。它通过将提示视为分层树结构，并利用Critic-Actor框架进行迭代细化，解决了现有方法在处理长提示时信息丢失和敏感性的问题。实验证明，SCULPT在长提示优化方面表现出色，具有高鲁棒性，甚至无需初始人工提示即可生成高质量提示，并且相较于现有SOTA方法，能持续提升LLM性能和泛化能力。

> **摘要翻译:** 提示优化对于大型语言模型（LLMs）在各种任务中的有效利用至关重要。然而，现有优化方法在优化短提示方面是有效的，但它们在处理更长、更复杂的提示时会遇到困难，常常冒着信息丢失的风险，并且对小扰动敏感。为了解决这些挑战，我们提出了SCULPT（Systematic Tuning of Long Prompts），一个将提示优化视为分层树细化问题的框架。SCULPT将提示表示为树结构，从而能够在保留上下文完整性的同时进行有针对性的修改。它采用Critic-Actor框架，生成反思并应用行动来细化提示。评估表明SCULPT在长提示上的有效性、对对抗性扰动的鲁棒性，以及即使没有任何初始人工编写提示也能生成高性能提示的能力。与现有最先进的方法相比，SCULPT通过在应用结构化细化的同时保留必要的任务信息，持续提高LLM性能。定性和定量分析均表明，SCULPT产生更稳定和可解释的提示修改，确保在不同任务中具有更好的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [99] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
> *TransEvalnia：基于推理的翻译评估与排名*

*Richard Sproat, Tianyu Zhao, Llion Jones* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 翻译评估, 翻译排名, 大型语言模型, 推理, 位置偏差

**Comment:** 

> **TL;DR:** TransEvalnia 是一个基于提示的翻译评估和排名系统，它使用推理进行评估，性能与现有最佳系统相当或更好，并且其评估结果与人类判断高度相关。

**AI_Comments:** TransEvalnia 的创新之处在于其基于推理的评估和排名方法，以及对MQM的细粒度应用。其重要性体现在提供了一个性能与人类判断高度相关的自动化翻译评估工具，并指出了位置偏差这一重要限制，同时提供了解决方案，对未来的翻译评估研究有指导意义。开源所有数据和代码进一步提升了其价值。

<details>
  <summary>Details</summary>

**Motivation:** 需要一个能够提供细粒度评估、排名并给出数值分数的翻译评估系统，该系统应具备推理能力并克服现有方法的局限性。

**Method:** TransEvalnia 是一个基于提示的翻译评估和排名系统，它利用推理能力进行评估和排名。该系统基于多维质量指标（MQM）的一个子集提供细粒度评估，并给出最佳翻译的评估结果和各维度及整体翻译的数值分数。它使用 Anthropic 的 Claude-3.5-Sonnet 和 Qwen-2.5-72B-Instruct 作为评估大型语言模型（LLM）。此外，该系统还提出了解决翻译呈现顺序引起的位置偏差的方法。

**Result:** TransEvalnia 在其自有英日数据以及来自多个 WMT 共享任务的多种语言对上，表现与最先进的 MT-Ranker 相当或更好。使用 Claude-3.5-Sonnet 和 Qwen-2.5-72B-Instruct 作为评估 LLM，返回的评估结果被人类评估者高度接受，并且 Sonnet 及其他 LLM 分配的翻译分数与人类评估者分配的分数具有良好的相关性。研究还发现 TransEvalnia 和 MT-Ranker 都对翻译呈现的顺序敏感。

**Conclusion:** TransEvalnia 是一个有效且表现良好的基于推理的翻译评估和排名系统，其评估结果与人类判断高度相关，并在性能上与现有最佳系统相当或更好。该研究还指出了翻译评估中存在的位置偏差问题，并提出了相应的解决方案。所有相关数据和代码均已发布。

> **ai_Abstract:** TransEvalnia 是一种基于提示和推理的翻译评估与排名系统。它利用多维质量指标提供细粒度评估、最佳翻译判断及数值分数。实验表明，TransEvalnia 在多语言对上性能与现有最佳系统相当或更优，且其评估结果与人类判断高度相关。研究还揭示了系统对翻译顺序的敏感性，并提出了解决方案。所有相关数据和代码均已开源。

> **摘要翻译:** 我们提出了 TransEvalnia，一个基于提示的翻译评估和排名系统，它在执行评估和排名时使用推理。该系统基于多维质量指标（https://themqm.org/）的一个子集提供细粒度评估，返回其认为最佳的翻译评估结果，并为各个维度和整体翻译提供数值分数。我们展示了 TransEvalnia 在我们自己的英日数据以及来自多个 WMT 共享任务的多种语言对上，表现与最先进的 MT-Ranker（Moosa et al. 2024）相当或更好。使用 Anthropic 的 Claude-3.5-Sonnet 和 Qwen-2.5-72B-Instruct 作为评估 LLM，我们展示了返回的评估结果被人类评估者高度接受，并且 Sonnet 以及其他 LLM 分配给翻译的分数与人类评估者分配的分数具有良好的相关性。我们还注意到我们的系统——以及 MT-Ranker——对翻译呈现顺序的敏感性，我们提出了解决这种位置偏差的方法。所有数据，包括系统的评估和推理、人类评估以及代码都已发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [110] [Memorization Inheritance in Sequence-Level Knowledge Distillation for Neural Machine Translation](https://arxiv.org/abs/2502.01491)
> *神经机器翻译中序列级知识蒸馏的记忆继承*

*Verna Dankers, Vikas Raunak* | **Category: cs.CL** | **Updated: 2025-07-16**

**Keywords:** 知识蒸馏, 神经机器翻译, 记忆继承, 幻觉, 序列级知识蒸馏

**Comment:** To appear at ACL 2025; 15 pages total (5 in the main paper, 3 pages
  of limitations and references and 7 pages with appendices)

> **TL;DR:** 学生模型在序列级知识蒸馏中会继承教师模型的记忆，包括错误模式，研究提出了Adaptive-SeqKD来减少这种继承。

**AI_Comments:** 这项工作揭示了序列级知识蒸馏中一个重要的隐患，即学生模型不仅继承了教师的性能，也继承了其记忆和潜在的错误模式（如幻觉），这对于模型部署和可靠性具有重要意义。提出的Adaptive-SeqKD为解决这一问题提供了初步方案，但其效果和普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 探索教师神经机器翻译（NMT）模型中的实例级记忆如何在序列级知识蒸馏（SeqKD）中被学生模型继承。

**Method:** 研究了学生模型在不直接看到原始训练数据的情况下，其记忆和幻觉行为；表征了学生模型在特定训练数据子组（如低质量和特定反事实记忆得分子组）上的行为；提出了一种名为Adaptive-SeqKD的修改版SeqKD，旨在减少记忆和幻觉。

**Result:** 学生模型比基线模型记忆更多（精确匹配多3.4%，提取式记忆多57%），并显示出更高的幻觉率；学生模型在低质量子组上表现出增强的去噪能力；提出的Adaptive-SeqKD能够减少记忆和幻觉。

**Conclusion:** 在使用序列级知识蒸馏（SeqKD）时应谨慎，因为学生模型会继承教师模型的优异性能和其故障模式，因此需要积极监控。

> **ai_Abstract:** 本文研究了神经机器翻译中序列级知识蒸馏（SeqKD）下学生模型对教师模型记忆的继承情况。研究发现，学生模型即使未直接接触原始训练数据，仍会比基线模型表现出更高的记忆率和幻觉率，并能对低质量数据进行去噪。为缓解此问题，论文提出了一种改进的SeqKD方法——Adaptive-SeqKD，旨在减少记忆和幻觉。研究强调在使用SeqKD时需警惕学生模型继承教师模型的错误模式。

> **摘要翻译:** 在这项工作中，我们探讨了教师神经机器翻译（NMT）模型中的实例级记忆如何在序列级知识蒸馏（SeqKD）中被学生模型继承。我们发现，尽管学生模型没有直接看到原始训练数据，但它们比基线模型（相同大小，在原始数据上训练的模型）记忆更多——精确匹配多3.4%，提取式记忆多57%——并显示出更高的幻觉率。此外，在这种SeqKD设置下，我们还描述了学生模型在特定训练数据子组上的行为，例如低质量和特定反事实记忆（CM）得分的子组，并发现学生模型在低质量子组上表现出增强的去噪能力。最后，我们提出了一种对SeqKD的修改，名为Adaptive-SeqKD，它干预SeqKD以减少记忆和幻觉。总的来说，我们建议在使用SeqKD时要谨慎：学生模型继承了教师模型的卓越性能和它们的故障模式，因此需要积极监控。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [140] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
> *Logit 算术无需训练即可激发长链推理能力*

*Yunxiang Zhang, Muhammad Khalifa, Lechen Zhang, Xin Liu, Ayoung Lee, Xinliang Frederick Zhang, Farima Fatahi Bayat, Lu Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** Logit 算术, 长链推理, 解码时, 大型语言模型, 偏好优化

**Comment:** 

> **TL;DR:** 该论文提出了 ThinkLogit，一种在解码时利用 Logit 算术和小型引导模型的方法，使大型模型无需额外训练即可获得长链推理能力，并引入 ThinkLogit-DPO 以进一步提升性能。

**AI_Comments:** 该论文的创新之处在于，它提出了一种无需大量再训练即可激发大型模型复杂长推理能力的计算高效的解码时方法，并由一个显著更小的模型进行引导。这对于更实际地部署强大的推理模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最近的研究表明，大型推理模型（LRMs）固有地拥有长推理能力，但通常需要额外训练才能解锁。本研究旨在探索如何在不进行任何训练的情况下激发这些长推理行为。

**Method:** 本研究提出了两种方法：
1. ThinkLogit：一种解码时方法，利用 Logit 算术（Liu et al., 2024）来调整目标大型语言模型，使其能够进行长推理，并使用一个显著较小的模型作为引导。
2. ThinkLogit-DPO：通过对从目标模型和引导模型中采样的正确/不正确推理对进行偏好优化来训练引导模型，从而进一步提升性能。

**Result:** 实验结果表明：
- 在使用 R1-Distill-Qwen-1.5B（小 21 倍的模型）作为引导时，ThinkLogit 和 ThinkLogit-DPO 在四个数学数据集上，相对于 Qwen2.5-32B，pass@1 分别相对提高了 26% 和 29%。
- ThinkLogit 能够转移通过强化学习获得的长期推理技能，与 Qwen2.5-32B 基础模型相比，pass@1 相对提高了 13%。

**Conclusion:** 本工作提出了一种计算高效的方法，可以在最少或无需额外训练的情况下，激发大型模型的长推理能力。

> **ai_Abstract:** 本文介绍了 ThinkLogit，一种新颖的解码时方法，它利用 Logit 算术和一个较小的引导模型，使大型语言模型无需额外训练即可进行长链思维推理。该研究还提出了 ThinkLogit-DPO，通过对引导模型进行偏好优化训练，进一步提升性能。实验结果表明，该方法在数学推理任务上取得了显著的性能提升，证明了其在计算效率方面解锁复杂推理能力的潜力。

> **摘要翻译:** 大型推理模型 (LRM) 可以通过涉及回溯和自我修正等认知策略的长思维链 (CoT) 进行复杂推理。最近的研究表明，一些模型固有地拥有这些长推理能力，这可能通过额外训练来解锁。我们的工作首先研究是否可以在没有任何训练的情况下激发这种行为。为此，我们提出了一种解码时方法 ThinkLogit，它利用 Logit 算术（Liu 等人，2024）来调整目标大型语言模型以进行长推理，并使用一个大大较小的模型作为引导。然后我们展示，通过对来自目标模型和引导模型的正确/不正确推理对进行偏好优化来训练引导模型，可以进一步提升性能——这种设置我们称之为 ThinkLogit-DPO。我们的实验表明，在使用 R1-Distill-Qwen-1.5B（小 21 倍的模型）作为引导时，ThinkLogit 和 ThinkLogit-DPO 在四个数学数据集上，相对于 Qwen2.5-32B，pass@1 分别相对提高了 26% 和 29%。最后，我们展示了 ThinkLogit 可以转移通过强化学习获得的长期推理技能，与 Qwen2.5-32B 基础模型相比，pass@1 相对提高了 13%。我们的工作提出了一种计算高效的方法，以最少或无需额外训练即可激发大型模型的长推理能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [143] [MPO: An Efficient Post-Processing Framework for Mixing Diverse Preference Alignment](https://arxiv.org/abs/2502.18699)
> *MPO：一种混合多样偏好对齐的有效后处理框架*

*Tianze Wang, Dongnan Gui, Yifan Hu, Shuhang Lin, Linjun Zhang* | **Category: cs.CL, cs.LG, stat.ME** | **Updated: 2025-07-17**

**Keywords:** 偏好对齐, 后处理框架, 强化学习, 大型语言模型, 多样化偏好

**Comment:** ICML 2025

> **TL;DR:** MPO是一个高效的后处理框架，用于混合多样化偏好，通过对数线性组合现有策略来避免从头开始对齐，并显著降低计算成本，同时实现平衡性能。

**AI_Comments:** MPO的创新之处在于其“后处理”的视角，通过组合现有策略而非从头训练，巧妙地解决了RLHF中处理多样化偏好的成本和稳定性问题。这提供了一个更高效、更实用的解决方案，有望加速LLM在复杂、多维度偏好场景下的对齐。

<details>
  <summary>Details</summary>

**Motivation:** 现有RLHF方法依赖单一奖励模型，忽略了人类偏好的多样性。多目标RLHF虽然尝试解决，但成本高昂且不稳定，尤其是在处理相互竞争和异构的偏好时。

**Method:** 本文提出了混合偏好优化（MPO），一个后处理框架，通过对现有单目标策略进行对数线性组合来聚合它们，每个策略的权重通过批量随机镜像下降计算。MPO避免了从头开始对齐。

**Result:** MPO在多样化偏好下实现了平衡的性能，超越或匹配了现有模型，并显著降低了计算成本。

**Conclusion:** MPO为处理RLHF中多样化的人类偏好提供了一个高效且稳定的替代方案，解决了多目标RLHF的成本和稳定性问题。

> **ai_Abstract:** 本文提出了MPO（Mixing Preference Optimization），一个针对RLHF中多样化人类偏好的高效后处理框架。与传统的多目标RLHF高成本和不稳定性问题不同，MPO通过对现有单目标策略进行对数线性组合并使用批量随机镜像下降计算权重，从而避免了从头开始对齐。实验结果表明，MPO在实现平衡性能的同时，显著降低了计算成本，并且性能优于或媲美现有模型。

> **摘要翻译:** 人类反馈强化学习（RLHF）在对齐大型语言模型（LLM）方面显示出前景。然而，它对单一奖励模型的依赖常常忽视了人类偏好的多样性。最近的方法通过利用多维度反馈来微调相应的奖励模型并使用强化学习训练LLM来解决这一限制。然而，这个过程成本高昂且不稳定，尤其是在人类偏好相互竞争和异构的情况下。在本文中，我们提出了混合偏好优化（MPO），一个聚合单目标策略的后处理框架，作为多目标RLHF（MORLHF）和最大最小RLHF的替代方案。MPO避免了从头开始对齐。相反，它将现有策略对数线性组合成一个统一的策略，其中每个策略的权重通过批量随机镜像下降计算。实证结果表明，MPO在多样化偏好下实现了平衡的性能，超越或匹配了现有模型，并显著降低了计算成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [147] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
> *HATS：用于评估大型语言模型推理能力的印地语类比测试集*

*Ashray Gupta, Rohan Joseph, Sunny Rai* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 印地语, 类比测试, 大型语言模型, 推理能力, 多语言评估

**Comment:** 

> **TL;DR:** 引入了HATS，一个用于评估大型语言模型在印地语中推理能力的新测试集，并发现模型在英语提示下表现最佳。

**AI_Comments:** 这项工作通过引入一个专门的印地语类比测试集，填补了LLM在印度语言推理能力评估方面的一个重要空白，具有创新性。其提出的接地链式思维方法也为提升模型性能提供了新的思路。研究结果揭示了LLM在跨语言推理中对提示语言的依赖性，为未来的多语言LLM研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在印地语等印度语言中的推理能力研究不足，限制了对模型跨语言泛化能力的理解。

**Method:** 引入了一个包含405个多项选择题的新印地语类比测试集（HATS），题目来源于印度政府考试。使用各种提示策略对最先进的多语言LLM进行了基准测试，并引入了一种基于认知类比推理理论的接地链式思维方法。

**Result:** 接地链式思维方法提高了模型在印地语类比问题上的表现。实验表明，无论提示策略如何，模型在英语提示下表现最佳。

**Conclusion:** HATS填补了评估LLM在印地语中推理能力关键资源的空白。

> **ai_Abstract:** 该研究引入了HATS（印地语类比测试集），旨在解决大型语言模型在印地语推理能力评估方面的空白。HATS包含405个多项选择题，来源于印度政府考试。研究人员使用HATS对最先进的多语言LLM进行了基准测试，并提出了一种基于认知理论的接地链式思维方法，该方法能提升模型在印地语类比问题上的表现。实验结果显示，模型在使用英语提示时表现最佳，这突出了跨语言泛化中的挑战。

> **摘要翻译:** 类比测试模型推断概念之间隐含关系的能力，使其成为评估推理能力的关键基准。虽然大型语言模型（LLMs）在英语中的推理能力得到了广泛评估，但它们在印度语言中的能力仍未得到充分研究，这限制了我们对这些模型是否能跨语言泛化的理解。为了弥补这一空白，我们引入了一个新的印地语类比测试集（HATS），包含405个来源于印度政府考试的多项选择题。我们使用各种提示策略对最先进的多语言LLM进行了基准测试，并引入了一种基于类比推理认知理论的接地链式思维方法。这种方法提高了模型在印地语类比问题上的表现。我们的实验表明，无论提示策略如何，模型在英语提示下表现最佳。我们的测试集解决了缺乏评估LLM在印地语中推理能力的关键资源的问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [148] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
> *大型语言模型狼人杀智能体中的策略适应*

*Fuya Nakamori, Yin Jou Huang, Fei Cheng* | **Category: cs.CL, I.2.7** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 狼人杀智能体, 策略适应, 游戏AI

**Comment:** 7 pages, 2 figures

> **TL;DR:** 本研究提出了一种基于玩家态度和对话上下文，动态切换预定义策略的方法，以提高大型语言模型狼人杀智能体的性能，解决现有方法无法适应变化情况的问题。

**AI_Comments:** 这项研究通过引入显式策略适应机制，为大型语言模型在复杂多智能体交互环境中的应用提供了新的思路。其创新点在于从隐式策略转向显式选择，增强了智能体的环境适应性。该方法对于提升LLM在游戏等动态场景中的表现具有重要意义，也为未来LLM的行为控制提供了潜在方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型狼人杀智能体通过提示工程隐式定义策略，但无法适应不断变化的局势，导致性能受限。

**Method:** 本研究提出一种方法，通过基于其他玩家的态度和对话上下文，显式地在预定义策略之间进行切换。具体而言，它根据游戏上下文和对其他玩家角色的估计，显式选择合适的策略。

**Result:** 通过与使用隐式或固定策略的基线智能体进行比较，验证了所提出策略适应方法的有效性。

**Conclusion:** 本研究证明了在大型语言模型狼人杀智能体中，显式地根据游戏情境和玩家角色估计进行策略适应，能够有效提升智能体的性能。

> **ai_Abstract:** 本研究旨在解决大型语言模型狼人杀智能体在复杂游戏情境中策略适应性差的问题。通过引入一种新方法，该方法能根据其他玩家的态度和对话上下文，显式地在预定义策略中进行选择和切换。实验结果表明，与采用隐式或固定策略的基线智能体相比，这种策略适应方法能显著提高狼人杀智能体的性能。

> **摘要翻译:** 本研究提出了一种通过根据其他玩家的态度和对话上下文在预定义策略之间切换来提高狼人杀智能体性能的方法。虽然以往使用提示工程的狼人杀智能体所采用的方法是隐式定义有效策略的，但它们无法适应不断变化的情况。在这项研究中，我们提出了一种基于游戏上下文和对其他玩家角色的估计来显式选择适当策略的方法。我们将策略适应狼人杀智能体与使用隐式或固定策略的基线智能体进行比较，并验证了我们提出的方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [174] [Synthesizing Privacy-Preserving Text Data via Finetuning without Finetuning Billion-Scale LLMs](https://arxiv.org/abs/2503.12347)
> *通过微调而非微调十亿级LLM合成隐私保护文本数据*

*Bowen Tan, Zheng Xu, Eric Xing, Zhiting Hu, Shanshan Wu* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 隐私保护, 合成数据, 差分隐私, 大型语言模型, CTCL

**Comment:** Code available at https://github.com/tanyuqian/synthetic-private-data

> **TL;DR:** CTCL是一种新的框架，用于在不进行大量提示工程或微调十亿级LLM的情况下，生成隐私保护的合成数据。它通过预训练轻量级生成器和主题模型，并对私有数据进行差分隐私微调来实现。

**AI_Comments:** CTCL在不微调十亿级LLM的情况下实现隐私保护数据合成，显著降低了计算成本。其创新点在于结合轻量级生成器、聚类主题模型和DP微调，有效平衡了隐私保护和数据质量。该方法对资源受限环境下的隐私数据处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 合成数据在训练模型时保护数据隐私方面具有前景，但对大型语言模型（LLMs）进行差分隐私（DP）微调作为数据生成器在计算资源有限时是不切实际的。同时，基于提示的方法（如私有演化）严重依赖手动提示，并且在迭代数据选择过程中未能有效利用私有信息。

**Method:** 我们提出了CTCL（Data Synthesis with ConTrollability and CLustering），一种新颖的框架。CTCL在大型公共数据上预训练一个轻量级140M条件生成器和一个基于聚类的主题模型。为了进一步适应私有领域，生成器在私有数据上进行DP微调以获取细粒度文本信息，而主题模型提取一个代表分布信息的DP直方图。然后，DP生成器根据DP直方图进行采样以合成所需数量的数据示例。

**Result:** 在五个不同领域的评估证明了我们框架的有效性，尤其是在强隐私机制下。系统消融实验验证了每个框架组件的设计，并突出了我们方法的可扩展性。

**Conclusion:** CTCL框架能够有效生成隐私保护的合成数据，解决了传统DP微调LLM计算量大和基于提示方法依赖手动提示的问题，尤其在强隐私要求下表现出色。

> **ai_Abstract:** 该论文提出了CTCL框架，旨在解决在计算资源有限的情况下，使用大型语言模型进行差分隐私（DP）微调合成隐私保护文本数据的实际困难，以及基于提示方法对手动提示的过度依赖问题。CTCL通过预训练一个轻量级条件生成器和一个聚类主题模型，并在私有数据上进行DP微调，结合DP直方图采样来高效生成合成数据。实验证明，该框架在多个领域特别是强隐私设置下表现出有效性和可扩展性。

> **摘要翻译:** 合成数据为在保护数据隐私的同时训练模型提供了一条有前景的路径。将大型语言模型（LLMs）进行差分隐私（DP）微调作为数据生成器是有效的，但在计算资源有限时是不切实际的。同时，基于提示的方法，例如私有演化，严重依赖手动提示，并且在迭代数据选择过程中未能有效利用私有信息。为了克服这些限制，我们提出了CTCL（Data Synthesis with ConTrollability and CLustering），一个用于在不进行大量提示工程或微调十亿级LLM的情况下生成隐私保护合成数据的新颖框架。CTCL在大型公共数据上预训练一个轻量级140M条件生成器和一个基于聚类的主题模型。为了进一步适应私有领域，生成器在私有数据上进行DP微调以获取细粒度文本信息，而主题模型提取一个代表分布信息的DP直方图。然后，DP生成器根据DP直方图进行采样以合成所需数量的数据示例。在五个不同领域的评估证明了我们框架的有效性，尤其是在强隐私机制下。系统消融实验验证了每个框架组件的设计，并突出了我们方法的可扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [189] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
> *多模态大语言模型安全自动引导技术*

*Lyucheng Wu, Mengru Wang, Ziwen Xu, Tri Cao, Nay Oo, Bryan Hooi, Shumin Deng* | **Category: cs.CL, cs.AI, cs.IR, cs.LG, cs.MM** | **Updated: 2025-07-17**

**Keywords:** 多模态大语言模型, 模型安全, 对抗性攻击, 推理时干预, AutoSteer

**Comment:** Working in progress. 22 pages (8+ for main); 25 figures; 1 table

> **TL;DR:** AutoSteer是一种无需微调的模块化自适应推理时干预技术，显著提升多模态大语言模型（MLLMs）在对抗性输入下的安全性，同时保持其通用能力。

**AI_Comments:** AutoSteer的创新之处在于其模块化和无需微调的特性，使其易于集成到现有MLLMs中。通过引入安全感知分数和自适应安全探测器，该方法能够智能地识别和干预潜在的安全风险，提供了一种可解释的推理时安全增强方案。其在降低攻击成功率方面的显著效果，且不牺牲通用能力，凸显了其在实际部署中的重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在解锁强大的跨模态推理能力的同时，也带来了新的安全隐患，尤其是在面对对抗性多模态输入时。

**Method:** 本文提出了一种名为AutoSteer的模块化、自适应推理时干预技术，无需对底层模型进行任何微调。AutoSteer包含三个核心组件：1) 一种新颖的“安全感知分数”（SAS），能自动识别模型内部层中最与安全相关的区别；2) 一个自适应安全探测器，用于估计中间表示产生有害输出的可能性；3) 一个轻量级“拒绝头部”（Refusal Head），在检测到安全风险时选择性地干预以调节生成。

**Result:** 在LLaVA-OV和Chameleon上，针对文本、视觉和跨模态威胁的各种安全关键基准测试表明，AutoSteer显著降低了攻击成功率（ASR），同时保持了模型的通用能力。

**Conclusion:** AutoSteer是一个实用、可解释且有效的框架，可用于更安全地部署多模态AI系统。

> **ai_Abstract:** 本文提出了一种名为AutoSteer的模块化、自适应推理时干预技术，旨在提升多模态大语言模型（MLLMs）在面对对抗性输入时的安全性，且无需对模型进行微调。AutoSteer由安全感知分数（SAS）、自适应安全探测器和轻量级拒绝头部三个核心组件构成，分别用于识别安全相关层、预测有害输出风险并选择性地干预生成。实验证明，AutoSteer能显著降低文本、视觉和跨模态威胁的攻击成功率，同时保持模型通用能力，为多模态AI系统的安全部署提供了一个实用、可解释且有效的框架。

> **摘要翻译:** 多模态大语言模型（MLLMs）最近的进展解锁了强大的跨模态推理能力，但也带来了新的安全隐患，尤其是在面对对抗性多模态输入时。为了在推理过程中提高MLLMs的安全性，我们引入了一种模块化和自适应的推理时干预技术——AutoSteer，无需对底层模型进行任何微调。AutoSteer包含三个核心组件：(1) 一种新颖的“安全感知分数”（SAS），能自动识别模型内部层中最与安全相关的区别；(2) 一个自适应安全探测器，用于估计中间表示产生有害输出的可能性；以及 (3) 一个轻量级“拒绝头部”（Refusal Head），在检测到安全风险时选择性地干预以调节生成。在LLaVA-OV和Chameleon上，针对各种安全关键基准测试，实验表明AutoSteer显著降低了文本、视觉和跨模态威胁的攻击成功率（ASR），同时保持了模型的通用能力。这些发现将AutoSteer定位为一个实用、可解释且有效的框架，用于更安全地部署多模态AI系统。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [194] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
> *Synergy：端到端概念模型*

*Keli Zheng, Zerong Xie* | **Category: cs.CL, cs.AI, I.2.7** | **Updated: 2025-07-17**

**Keywords:** 语言模型, 无分词器, 字节级, 抽象层次, Synergy

**Comment:** 

> **TL;DR:** Synergy是一种字节级语言模型，通过学习路由机制实现端到端抽象，可以自发学习分词，性能与BBPE相当甚至优于Llama3，并展示了无分词器架构的可行性。

**AI_Comments:** Synergy模型通过引入学习路由机制和字节级训练，实现了自发分词和端到端抽象连接，这在语言模型领域具有创新性。其在性能上优于Llama3，并发现位置无关概念的出现，对未来的无分词器架构研究具有重要意义，可能简化NLP管道并提高灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过Synergy模型，探索一种能够以端到端方式连接不同抽象级别、自发学习分词并实现无分词器架构的语言模型。

**Method:** Synergy模型被训练为字节级语言模型，通过学习到的路由机制连接不同抽象级别。它能自发学习将字节分词，生成比BBPE更少的概念token。

**Result:** Synergy模型自发学习分词，产生的概念token比BBPE分词器少，同时保持了可比的性能。在相同的模型规模和训练数据集大小下，Synergy比Llama3表现出优势。模型中间部分（更高抽象部分）在移除位置编码后表现更好，表明出现了位置无关的概念。

**Conclusion:** 这些发现证明了无分词器架构的可行性，为更健壮和灵活的管道铺平了道路。

> **ai_Abstract:** 本文介绍了Synergy，一个创新的字节级语言模型，它通过学习路由机制实现端到端的不同抽象层次连接。Synergy能够自发学习分词，生成更少的概念token，并与Llama3在相同条件下相比展现出性能优势。研究还发现其高抽象部分在移除位置编码后表现更佳，预示着位置无关概念的出现。这些成果为开发更鲁棒、更灵活的无分词器语言模型架构提供了可行性。

> **摘要翻译:** 标题：协同：端到端概念模型
摘要：在本文中，我们提出了Synergy，一个通过学习路由机制以端到端方式连接不同抽象层次的语言模型。我们专注于低级语言抽象，将模型训练成字节级语言模型。我们的模型自发学习将字节分词，产生的概念token比字节级字节对编码器（BBPE）分词器少，同时保持了可比的性能。通过与Llama3进行比较，我们观察到在相同的模型规模和训练数据集大小下，Synergy具有优势。进一步的研究表明，当移除位置编码时，我们模型的中间部分（更高抽象部分）表现更好，这表明出现了与位置无关的概念。这些发现证明了无分词器架构的可行性，为更健壮和灵活的管道铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [196] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
> *学习鲁棒的否定文本表示*

*Thinh Hung Truong, Karin Verspoor, Trevor Cohn, Timothy Baldwin* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 文本表示, 否定, 对比学习, 大型语言模型, BERT

**Comment:** 

> **TL;DR:** 本文提出一种通过从大型语言模型中蒸馏数据来提高文本编码器否定鲁棒性的策略，并在否定理解和通用基准上取得了显著改进。

**AI_Comments:** 本文的创新点在于提出了一种通过从大型语言模型蒸馏数据来增强小型文本编码器否定鲁棒性的方法。这种数据蒸馏结合对比学习的策略，有效地解决了现有模型在否定理解上的不足。其重要性体现在提升了文本编码器在复杂语义理解任务中的表现，尤其是在处理否定句时，这对于许多依赖文本嵌入的下游应用具有实际价值。该方法还展示了其对大型语言模型的适用性，表明了其潜在的广泛应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型被广泛采用，但小型文本编码器在需要丰富上下文表示的文本理解任务中仍很重要。然而，这些方法未能正确捕获否定这一重要的语义功能，影响了许多依赖文本嵌入的下游应用。

**Method:** 提出一种策略来提高文本编码器的否定鲁棒性，通过使用多样化的否定和对冲模式从大型语言模型中蒸馏数据。采用标准的对比学习策略来微调一个强大的基于BERT的模型。

**Result:** 在否定理解能力上观察到显著改进，同时在通用基准上保持了有竞争力的性能。此外，该方法还可以适应大型语言模型，从而提高其在否定基准上的表现。

**Conclusion:** 该研究成功提出了一种有效的方法来提高文本编码器和大型语言模型对否定语义的理解能力，解决了现有模型在处理否定时的不足。

> **ai_Abstract:** 本文旨在解决小型文本编码器未能有效捕获否定语义的问题，该问题影响了依赖文本嵌入的下游应用。作者提出一种新策略，通过从大型语言模型中蒸馏包含多样化否定和对冲模式的数据，并结合对比学习对BERT模型进行微调，以增强其否定理解能力。实验结果表明，该方法显著提升了模型对否定的理解，并在通用任务上保持了良好性能。此外，该方法也被证明适用于大型语言模型，进一步提升了其在否定任务上的表现。

> **摘要翻译:** 尽管自回归大型语言模型被迅速采用，但较小的文本编码器在需要丰富上下文表示的文本理解任务中仍然发挥着重要作用。否定是一种重要的语义功能，但此类方法仍未能正确捕获，这影响了许多依赖文本嵌入的下游应用。我们提出了一种策略，通过使用多样化的否定和对冲模式从大型语言模型中蒸馏数据，以提高文本编码器的否定鲁棒性。我们采用标准的对比学习策略来微调一个强大的基于BERT的模型，并观察到否定理解能力的大幅提升，同时在通用基准上保持了有竞争力的性能。此外，我们还表明我们的方法可以适应大型语言模型，从而提高其在否定基准上的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [203] [CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings](https://arxiv.org/abs/2503.13733)
> *CoDet-M4：多语言、多生成器和多领域环境中机器生成代码的检测*

*Daniil Orel, Dilshod Azizov, Preslav Nakov* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 机器生成代码检测, 大型语言模型, 代码生成, 多语言, 域外检测

**Comment:** 

> **TL;DR:** CoDet-M4框架旨在多语言、多生成器和多领域环境下检测LLM生成的代码，解决了现有研究的局限性，并在实验中展现出卓越的区分能力和泛化性，为该任务设定了新基准。

**AI_Comments:** 这篇论文提出了一个全面的CoDet-M4框架，旨在解决LLM生成代码检测在多语言、多生成器和多领域环境中的挑战，显著提升了现有方法的覆盖范围和鲁棒性。其创新性在于跨越多种复杂场景的检测能力，并通过大规模数据集和域外泛化评估验证了其有效性，为维护代码质量、伦理和评估完整性提供了重要的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）革新了代码生成，但其应用对编程技能、伦理和评估完整性构成挑战。因此，检测LLM生成的代码对于维护问责制和标准至关重要。现有研究在领域覆盖、鲁棒性和支持的编程语言数量方面存在不足。

**Method:** 本研究提出了一个框架，能够区分人类编写和LLM编写的代码，该框架支持多种编程语言、代码生成器和领域。研究使用了来自知名平台和LLM代码生成器的大规模数据集，并进行了严格的数据质量检查、特征工程。通过评估传统机器学习模型、预训练语言模型（PLMs）和LLMs进行代码检测，并进行比较分析。此外，还在域外场景下进行了评估，包括检测生成代码的作者身份、混合作者身份以及泛化到未见过的模型、领域和编程语言。

**Result:** CoDet-M4框架能够有效地将人类编写的代码与LLM编写的代码区分开来。广泛的实验表明，该框架在多语言、多生成器和多领域设置下表现出色，并为代码生成检测任务设定了新的基准。

**Conclusion:** CoDet-M4框架在多语言、多生成器和多领域环境中成功实现了LLM生成代码的检测，有效解决了现有研究的局限性，并为该任务设定了新的高性能基准。

> **ai_Abstract:** 本研究针对大型语言模型（LLMs）生成代码带来的挑战，提出了CoDet-M4框架，旨在多语言、多生成器和多领域环境中有效检测LLM生成的代码。该框架利用大规模数据集、严格的数据质量检查和特征工程，并结合传统机器学习模型、预训练语言模型和LLMs进行评估。CoDet-M4在域外场景下进行了广泛验证，包括作者身份和混合作者身份检测，以及对未见过的模型、领域和编程语言的泛化能力。实验结果证明，CoDet-M4能够有效区分人类和LLM编写的代码，并为该任务树立了新的基准。

> **摘要翻译:** 大型语言模型（LLMs）彻底改变了代码生成，以惊人的效率实现了编程自动化。然而，这些进步对编程技能、伦理和评估完整性提出了挑战，使得检测LLM生成的代码对于维护问责制和标准至关重要。尽管已经有一些关于此问题的研究，但它们通常缺乏领域覆盖和鲁棒性，并且只涵盖少量编程语言。为此，我们提出了一个框架，能够区分跨多种编程语言、代码生成器和领域的人类编写和LLM编写的代码。我们使用来自知名平台和基于LLM的代码生成器的大规模数据集，并应用严格的数据质量检查、特征工程，以及使用传统机器学习模型、预训练语言模型（PLMs）和LLMs进行代码检测的评估来进行比较分析。我们对域外场景进行评估，例如检测生成代码的作者身份和混合作者身份，以及泛化到未见过的模型、领域和编程语言。此外，我们的大量实验表明，我们的框架有效地将人类编写的代码与LLM编写的代码区分开来，并为这项任务设定了新的基准。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [212] [VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents](https://arxiv.org/abs/2506.21582)
> *VIDEE：基于智能代理的文本分析的可视化与交互式分解、执行和评估*

*Sam Yu-Te Lee, Chengyang Ji, Shicheng Wen, Lifu Huang, Dongyu Liu, Kwan-Liu Ma* | **Category: cs.CL, cs.AI, cs.HC** | **Updated: 2025-07-17**

**Keywords:** 文本分析, 智能代理, 大语言模型, 人机协作, 可视化

**Comment:** 

> **TL;DR:** VIDEE是一个支持初级数据分析师使用智能代理进行高级文本分析的系统，通过人机协作工作流实现分解、执行和评估。

**AI_Comments:** VIDEE的创新之处在于其将大语言模型与人机协作相结合，通过分解、执行和评估的结构化流程，显著降低了文本分析的门槛。其引入的“人机在环蒙特卡洛树搜索”是亮点，强调了人类反馈在生成式推理中的关键作用。该系统对初级分析师的实用性以及对未来智能文本分析系统设计的启示，都体现了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 传统文本分析需要专业的自然语言处理（NLP）或文本分析知识，对入门级分析师构成障碍。大语言模型（LLMs）的最新进展使得文本分析更加易于访问和自动化，但仍需系统支持初级分析师进行高级文本分析。

**Method:** VIDEE系统实现了一个人机协作工作流，包含三个阶段：1) 分解：结合人机协作的蒙特卡洛树搜索算法，支持带有人类反馈的生成式推理；2) 执行：生成可执行的文本分析管道；3) 评估：整合基于LLM的评估和可视化，支持用户验证执行结果。

**Result:** 通过两项定量实验评估了VIDEE的有效性并分析了常见的代理错误。一项用户研究表明该系统具有可用性，并揭示了不同的用户行为模式。研究结果为人类与代理协作的设计提供了启示，验证了VIDEE对非专业用户的实用性。

**Conclusion:** 研究结果为人类与代理协作的设计提供了启示，验证了VIDEE对非专业用户的实用性，并为未来智能文本分析系统的改进提供了信息。

> **ai_Abstract:** 本文介绍了VIDEE系统，旨在帮助初级数据分析师利用智能代理进行高级文本分析。该系统通过一个三阶段的人机协作工作流实现：分解（利用带人类反馈的蒙特卡洛树搜索）、执行（生成分析管道）和评估（整合LLM评估和可视化）。实验和用户研究表明VIDEE有效且可用，特别对非专家用户具有实用性，并为未来人机协作的智能文本分析系统设计提供了指导。

> **摘要翻译:** 文本分析传统上需要自然语言处理（NLP）或文本分析方面的专业知识，这给入门级分析师带来了障碍。大语言模型（LLMs）的最新进展改变了NLP的格局，使文本分析更加易于访问和自动化（例如，主题检测、摘要、信息提取等）。我们引入了VIDEE，一个支持入门级数据分析师使用智能代理进行高级文本分析的系统。VIDEE实例化了一个人机协作工作流，包括三个阶段：(1) 分解：结合了人机在环的蒙特卡洛树搜索算法，以支持带有人类反馈的生成式推理；(2) 执行：生成一个可执行的文本分析管道；(3) 评估：整合了基于LLM的评估和可视化，以支持用户验证执行结果。我们进行了两项定量实验来评估VIDEE的有效性并分析常见的代理错误。一项涉及不同NLP和文本分析经验水平（从无到专家）参与者的用户研究，展示了系统的可用性并揭示了独特的用​​户行为模式。研究结果确定了人机协作的设计启示，验证了VIDEE对非专家用户的实际效用，并为未来智能文本分析系统的改进提供了信息。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [233] [Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering](https://arxiv.org/abs/2504.13425)
> *企业安全多方面RAG：混合知识检索与安全过滤*

*Grace Byun, Shinsun Lee, Nayoung Choi, Jinho D. Choi* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** RAG, 企业AI, 数据安全, 混合检索, LLM

**Comment:** 

> **TL;DR:** 本文提出了一种名为SecMulti-RAG的安全多方面检索增强生成（RAG）框架，通过结合内部文档、预生成专家知识和按需外部LLM生成知识，并采用安全过滤机制，解决了企业RAG系统中检索范围有限和数据安全风险的问题，在汽车行业的报告生成任务中显著优于传统RAG。

**AI_Comments:** SecMulti-RAG的创新点在于其混合知识检索策略（内部、预生成专家、按需外部LLM）以及关键的安全过滤机制，有效解决了企业RAG中数据完整性和隐私保护的痛点。该框架通过降低成本和提高响应质量，为企业级RAG应用提供了实际可行的解决方案，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有企业检索增强生成（RAG）系统面临检索范围有限和数据安全风险的挑战。当缺乏相关内部文档时，系统难以生成准确完整的响应。此外，使用闭源大型语言模型（LLMs）会引发专有信息泄露的担忧。

**Method:** 本文提出了安全多方面RAG（SecMulti-RAG）框架，该框架不仅从内部文档中检索，还从预生成的专家知识和按需外部LLM生成知识这两种补充来源中检索。为降低安全风险，该方法采用本地开源生成器，并仅在过滤机制认为提示安全时才选择性地利用外部LLMs。

**Result:** 在汽车行业的报告生成任务评估中，SecMulti-RAG显著优于传统RAG，在基于LLM的评估中，其在正确性、丰富性和实用性方面取得了79.3%至91.9%的胜率，在人工评估中取得了56.3%至70.4%的胜率。

**Conclusion:** SecMulti-RAG是一种实用且安全的企业RAG解决方案。

> **ai_Abstract:** 本文提出了一种名为SecMulti-RAG的框架，旨在解决企业环境中检索增强生成（RAG）系统的局限性，包括检索范围不足和数据安全风险。SecMulti-RAG通过整合内部文档、预生成专家知识和按需外部LLM知识，扩展了知识检索范围。为确保安全，它采用本地开源生成器，并仅在通过安全过滤后才谨慎使用外部LLMs。实验结果表明，在汽车行业的报告生成任务中，SecMulti-RAG在正确性、丰富性和实用性方面显著优于传统RAG，证明了其作为企业RAG解决方案的实用性和安全性。

> **摘要翻译:** 现有检索增强生成（RAG）系统在企业环境中面临挑战，原因在于检索范围有限和数据安全风险。当相关的内部文档不可用时，系统难以生成准确和完整的响应。此外，使用闭源大型语言模型（LLMs）引发了对暴露专有信息的担忧。为了解决这些问题，我们提出了安全多方面RAG（SecMulti-RAG）框架，该框架不仅从内部文档中检索，还从两个补充来源中检索：针对预期查询预生成的专家知识和按需外部LLM生成的知识。为了减轻安全风险，我们采用本地开源生成器，并仅在过滤机制认为提示安全时才选择性地利用外部LLMs。这种方法增强了完整性，防止了数据泄露，并降低了成本。在我们对汽车行业报告生成任务的评估中，SecMulti-RAG显著优于传统RAG——在基于LLM的评估中，其在正确性、丰富性和实用性方面取得了79.3%至91.9%的胜率，在人工评估中取得了56.3%至70.4%的胜率。这凸显了SecMulti-RAG作为企业RAG的实用且安全解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [244] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
> *多语言模型中的知识和指代是否跨语言一致？*

*Xi Ai, Mahardika Krisna Ihsani, Min-Yen Kan* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 跨语言一致性, 多语言模型, 知识, 代码混合训练, 跨语言词对齐

**Comment:** 

> **TL;DR:** 研究多语言模型中知识的跨语言一致性，发现其受语言家族等因素影响，且通常不一致；但代码混合训练和跨语言词对齐能有效提升一致性。

**AI_Comments:** 该研究创新性地关注了多语言模型中知识的“跨语言一致性”这一重要但常被忽视的方面。它不仅揭示了现有模型在此方面存在的局限性（受语言家族、语言因素和层级瓶颈影响），更重要的是，它指出了通过代码混合训练和跨语言词对齐等方法可以有效提升这种一致性。这对于未来多语言模型的设计和训练具有重要的指导意义，有助于构建更健壮、事实性更强的跨语言AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 评估跨语言可迁移性、保持模型知识的跨语言事实性以及维持语言模型性能的对等性，因此需要分析、评估和解释事实知识的跨语言一致性。

**Method:** 通过检查跨语言传达相同知识的代码混合共指语句来研究跨语言知识一致性。使用解释性方法分析模型在跨语言上下文中的行为。此外，评估旨在提高多语言性能的常见策略，以观察这些策略是否能同时提高知识一致性。

**Result:** 多语言模型显示出不同程度的一致性，受语言家族、语言因素和特定层中跨语言一致性瓶颈的影响。虽然在许多情况下知识不具备跨语言一致性，但代码混合训练和跨语言词对齐目标显示出最有希望的结果。

**Conclusion:** 强调跨语言对齐监督和代码混合训练对于提高多语言性能和跨语言一致性的重要性。

> **ai_Abstract:** 本研究探讨了多语言模型中事实知识的跨语言一致性，该一致性对于评估模型跨语言迁移能力、保持知识事实性及性能对等至关重要。通过分析跨语言代码混合共指语句并采用解释性方法，研究发现多语言模型的一致性水平因语言家族、语言因素和特定层瓶颈而异。尽管知识在多数情况下不具备跨语言一致性，但代码混合训练和跨语言词对齐策略在提升一致性方面表现出显著效果，凸显了这些方法对提升多语言性能和一致性的双重价值。

> **摘要翻译:** 跨语言一致性应被考虑用于评估跨语言可迁移性、保持模型知识在不同语言间的事实性，并维持语言模型性能的对等性。因此，我们对分析、评估和解释事实知识的跨语言一致性感兴趣。我们检查了跨语言传达相同知识的代码混合共指语句，以研究跨语言知识一致性。我们使用一些可解释性方法来分析模型在跨语言上下文中的行为，发现多语言模型显示出不同程度的一致性，这取决于语言家族、语言因素以及特定层中跨语言一致性的瓶颈。此外，我们评估了旨在提高多语言性能的常见策略，以观察这些策略是否能同时提高知识一致性。虽然在许多情况下知识不具备跨语言一致性，但代码混合训练和跨语言词对齐目标显示出最有希望的结果，强调了跨语言对齐监督和代码混合训练对于多语言性能和跨语言一致性增强的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [258] [ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs](https://arxiv.org/abs/2504.16394)
> *ConTextual：通过上下文保留的令牌过滤和知识图谱改进LLM中的临床文本摘要*

*Fahmida Liza Piya, Rahmatollah Beheshti* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 临床文本摘要, 大型语言模型, 令牌过滤, 知识图谱, 上下文保留

**Comment:** Accepted for MLHC 2025

> **TL;DR:** ConTextual是一种新颖的框架，结合上下文保留的令牌过滤和领域特定知识图谱，显著提高了临床文本摘要的质量和准确性。

**AI_Comments:** 这篇论文的创新点在于结合了上下文保留的令牌过滤和领域特定知识图谱来改进临床文本摘要，解决了现有方法在处理细微临床信息时的不足。其重要性在于提供了一种可扩展且有效的方法，能够提高临床文本摘要的精度和临床实用性，对于医疗决策支持具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 临床非结构化数据是重要的信息来源，但现有临床文本摘要方法要么统一处理所有令牌，要么依赖启发式过滤，导致忽略细微的临床线索或未能优先处理关键信息，影响决策。

**Method:** 本研究提出了ConTextual框架，该框架将上下文保留的令牌过滤方法与领域特定知识图谱（KG）相结合，用于上下文增强。通过保留上下文特定的重要令牌并用结构化知识丰富它们，ConTextual提高了语言连贯性和临床准确性。

**Result:** 在两个公共基准数据集上的广泛实证评估表明，ConTextual始终优于其他基线方法。

**Conclusion:** ConTextual方法强调了令牌级过滤和结构化检索在增强语言和临床完整性方面的互补作用，并为提高临床文本生成精度提供了一个可扩展的解决方案。

> **ai_Abstract:** 本文提出了ConTextual框架，旨在改进大型语言模型（LLMs）中的临床文本摘要。针对现有方法在处理非结构化临床数据时忽略关键上下文的问题，ConTextual结合了上下文保留的令牌过滤和领域特定知识图谱进行上下文增强。该方法通过保留重要令牌并利用结构化知识丰富它们，显著提高了摘要的语言连贯性和临床准确性。在两个公共基准数据集上的评估结果显示，ConTextual的性能优于现有基线。

> **摘要翻译:** 非结构化临床数据可以作为独特而丰富的信息来源，能够有效地指导临床实践。从这些数据中提取最相关的上下文对于发挥其在患者护理中实现最佳和及时决策的真正潜力至关重要。虽然先前的研究探索了各种临床文本摘要方法，但大多数先前的研究要么统一处理所有输入令牌，要么依赖基于启发式的方法，这可能会忽略细微的临床线索，并且未能优先处理对决策至关重要的信息。在本研究中，我们提出了ConTextual，一个新颖的框架，它将上下文保留令牌过滤方法与领域特定知识图谱（KG）相结合，以进行上下文增强。通过保留上下文特定的重要令牌并用结构化知识丰富它们，ConTextual提高了语言连贯性和临床保真度。我们在两个公共基准数据集上进行的广泛实证评估表明，ConTextual始终优于其他基线。我们提出的方法强调了令牌级过滤和结构化检索在增强语言和临床完整性方面的互补作用，并为提高临床文本生成的精度提供了一个可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [293] [MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness](https://arxiv.org/abs/2504.21773)
> *MAC-Tuning：增强知识边界感知的大语言模型多组合问题推理*

*Junsheng Huang, Zhitao He, Yucheng Huang, Sandeep Polisetty, Qingyun Wang, May Fung* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 大语言模型, 幻觉, 知识边界, 置信度估计, 多问题推理

**Comment:** 

> **TL;DR:** MAC-Tuning是一种新方法，通过分离答案预测和置信度估计来解决LLM在多问题设置中的幻觉问题，并在平均精度上超越基线。

**AI_Comments:** 该论文创新性地提出了MAC-Tuning方法，通过分离答案预测和置信度估计的学习过程，有效解决了LLM在多问题设置下的幻觉问题和知识边界感知不足。这种分步调整的策略为提升LLM在复杂推理任务中的可靠性提供了一个新的视角和有效的解决方案，对于提高LLM的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）的广泛应用带来了生成虚假信息（即幻觉）的问题，尤其是在需要同时准确回答多个问题的多问题设置下，LLM对其内部参数化知识边界的感知能力尚未得到充分探索。

**Method:** 本文提出了一种名为多答案和置信度逐步调整（Multiple Answers and Confidence Stepwise Tuning, MAC-Tuning）的新方法，该方法在指令数据微调过程中，将答案预测和置信度估计的学习过程分开。

**Result:** 广泛的实验表明，我们的方法在平均精度上比基线提高了高达25%。

**Conclusion:** MAC-Tuning通过分离答案预测和置信度估计，显著提高了LLM在多组合问题推理中对知识边界的感知和性能，有效缓解了幻觉问题。

> **ai_Abstract:** 本文针对大语言模型（LLMs）在多问题设置中普遍存在的幻觉问题及知识边界感知不足的挑战，提出了一种名为MAC-Tuning（多答案和置信度逐步调整）的新方法。该方法创新性地在微调过程中分离了答案预测和置信度估计的学习，实验证明其在平均精度上比现有基线提高了高达25%，有效提升了LLM在复杂多问题推理中的准确性和知识边界意识。

> **摘要翻译:** 随着大语言模型（LLMs）的广泛应用，生成不存在的事实（即幻觉）问题日益受到关注。以往增强LLM置信度估计的研究主要集中在单一问题设置上。然而，LLM在更具挑战性的多问题设置下对其内部参数化知识边界的感知能力，即需要同时准确回答多个问题，仍未得到充分探索。为了弥补这一差距，我们引入了一种新颖的方法，多答案和置信度逐步调整（MAC-Tuning），它在指令数据微调过程中，将答案预测和置信度估计的学习过程分开。广泛的实验表明，我们的方法在平均精度上比基线提高了高达25%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
> *形式化攻击场景描述：一个提议的模型*

*Quentin Goux, Nadira Lammari* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 攻击场景, 形式化, 网络安全自动化, UML模型, 攻击分析

**Comment:** 

> **TL;DR:** 提出了一种形式化攻击场景描述的新模型，旨在支持网络安全自动化，如攻击分析和脚本生成。

**AI_Comments:** 本文的创新之处在于提出了一种基于UML的形式化模型来描述攻击场景，这对于推动网络安全流程的自动化至关重要。通过将攻击场景形式化，该模型为攻击分析和自动化脚本生成提供了基础，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 组织面临不断变化的威胁，需要不断努力保护其资产，这使得采用增加的网络安全自动化成为必然。然而，流程自动化需要输入数据的形式化。本文旨在解决需要使用攻击场景作为输入的流程的这一需求。

**Method:** 本文的主要研究贡献是一个新颖的形式化模型，该模型包含攻击的上下文描述及其场景。该模型使用UML类模型进行抽象。

**Result:** 该研究提出了一个形式化模型，并展示了其在攻击分析过程以及网络安全培训中自动生成攻击脚本的两个用例。

**Conclusion:** 本文提出的模型通过形式化攻击场景描述，能够支持上游攻击分析过程和网络安全培训中攻击脚本的自动生成，从而推动网络安全自动化。

> **ai_Abstract:** 鉴于组织在不断变化的威胁环境中对网络安全自动化日益增长的需求，本文提出了一种新颖的形式化模型，用于描述攻击的上下文和场景。该模型采用UML类模型进行抽象，其主要目的是为需要攻击场景作为输入的流程（如攻击分析和攻击模拟脚本生成）提供结构化的数据。论文进一步展示了该模型在支持上游攻击分析和自动生成网络安全培训脚本方面的应用，突出了其在促进网络安全自动化方面的实用价值。

> **摘要翻译:** 组织面临不断变化的威胁态势。它们必须持续投入大量精力来保护其资产，这使得它们采用增加的网络安全自动化成为必然。然而，流程自动化需要输入数据的形式化。通过本文，我们解决了使用攻击场景作为输入的流程的这一需求。在这些流程中，可以提及用于攻击模拟和训练目的的脚本生成，以及攻击分析。因此，本文的主要研究贡献是一个新颖的形式化模型，该模型包含攻击的上下文描述及其场景。它使用UML类模型进行抽象。一旦我们的模型描述完成，我们将展示它如何服务于上游攻击分析过程。我们还将展示它在网络安全培训背景下自动生成攻击脚本的用途。这两个用例构成了本研究工作的第二个贡献。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [304] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
> *SemCSE：使用LLM生成摘要的科学摘要语义对比句子嵌入*

*Marc Brinner, Sina Zarriess* | **Category: cs.CL, cs.IR, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 语义嵌入, 对比学习, LLM摘要, 科学文本, 无监督学习

**Comment:** 

> **TL;DR:** SemCSE是一种无监督方法，它利用LLM生成的科学摘要来训练模型，从而在嵌入空间中将语义相关的摘要更紧密地放置在一起，并在语义理解基准和SciRepEval上取得了最先进的性能。

**AI_Comments:** SemCSE的创新之处在于其利用LLM生成的摘要进行对比学习，这提供了一种新颖且有效的无监督方法来捕捉文本的深层语义。与传统方法相比，它更注重语义内容而非引用关系，这对于科学文本分析具有重要意义。在语义理解基准和SciRepEval上的SOTA表现证明了其强大的性能和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于引用的方法不一定能反映语义相似性，因此需要一种能捕捉文本真实语义内容的文本嵌入方法。

**Method:** SemCSE是一种无监督方法，它利用大型语言模型（LLM）生成的科学摘要进行对比学习，将语义相关的摘要在嵌入空间中拉近。此外，提出了一种新的基准来评估模型理解和编码科学文本语义内容的能力。

**Result:** SemCSE在提出的新基准上实现了更强的语义分离，并在SciRepEval科学文本嵌入综合基准上，在其规模的模型中取得了最先进的性能。

**Conclusion:** SemCSE通过语义聚焦的训练方法，能够有效地捕捉科学文本的真实语义内容，并在多个基准测试中表现出色，证明了其优越性。

> **ai_Abstract:** SemCSE是一种无监督的科学文本语义嵌入方法，它通过利用大型语言模型（LLM）生成的摘要进行对比学习来训练模型。该方法旨在克服传统基于引用方法在捕捉语义相似性方面的不足。研究人员提出了一个新的基准来验证SemCSE在语义理解方面的能力，并证明其能实现更强的语义分离。此外，SemCSE在SciRepEval基准测试中也取得了同等规模模型中的最先进性能，突显了其语义聚焦训练方法的有效性。

> **摘要翻译:** 我们引入了SemCSE，这是一种用于学习科学文本语义嵌入的无监督方法。该方法建立在文本嵌入对比学习的最新进展之上，利用LLM生成的科学摘要来训练一个模型，该模型将语义相关的摘要在嵌入空间中放置得更近。由此产生的目标确保模型能够捕捉文本的真实语义内容，这与不一定反映语义相似性的传统基于引用的方法形成对比。为了验证这一点，我们提出了一个新颖的基准，旨在评估模型理解和编码科学文本语义内容的能力，证明我们的方法在嵌入空间中实现了更强的语义分离。此外，我们在科学文本嵌入的综合SciRepEval基准上评估了SemCSE，它在其规模的模型中取得了最先进的性能，从而突出了语义聚焦训练方法的优势。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [323] [Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning](https://arxiv.org/abs/2505.13886)
> *Code2Logic：游戏代码驱动的数据合成以增强VLM的通用推理能力*

*Jingqi Tong, Jixin Tang, Hangcheng Li, Yurong Mou, Ming Zhang, Jun Zhao, Yanbo Wen, Fan Song, Jiahao Zhan, Yuyang Lu, Chaoran Tao, Zhiyuan Guo, Jizhou Yu, Tianhao Cheng, Changhao Jiang, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Weifeng Ge, Guanhua Chen, Tao Gui, Xipeng Qiu, Qi Zhang, Xuanjing Huang* | **Category: cs.CL, I.2.7; I.2.10** | **Updated: 2025-07-17**

**Keywords:** VLMs, 数据合成, 游戏代码, 通用推理, Chain-of-Thought

**Comment:** 63 pages, 23 figures, submitted to NeurIPS 2025

> **TL;DR:** 鉴于视觉语言模型（VLM）推理数据稀缺且标注成本高昂，本文提出Code2Logic，一种利用游戏代码驱动的多模态推理数据合成方法。该方法通过大型语言模型（LLM）和代码执行自动生成推理数据，并构建了GameQA数据集。实验证明，尽管仅在游戏数据上训练，VLMs仍展现出域外泛化能力，并在多个基准测试中提升了性能。

**AI_Comments:** 本文的创新点在于巧妙地利用了游戏代码这一未充分利用的资源，通过结合LLM和代码执行来自动化生成高质量的视觉-语言推理数据，有效解决了现有数据稀缺和标注成本高昂的痛点。其合成数据能够使VLMs在未见过的域外任务上实现性能提升和泛化，这对于提升VLM的通用推理能力具有重要意义和广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言思维链（CoT）数据资源相对稀缺，限制了视觉语言模型（VLM）推理能力的提升。然而，高质量的视觉-语言推理数据标注成本高昂且耗时。

**Method:** 本文提出Code2Logic，一种新颖的、由游戏代码驱动的多模态推理数据合成方法。该方法利用大型语言模型（LLM）来适应游戏代码，并通过代码执行自动获取推理过程和结果。基于此方法，开发了GameQA数据集用于训练和评估VLMs。

**Result:** GameQA数据集具有成本效益、可扩展性，提供可控的难度分级，并包含30款游戏和158项任务。令人惊讶的是，尽管仅在游戏数据上训练，VLMs（特别是Qwen2.5-VL-7B）在7个不同的视觉-语言基准测试中表现出域外泛化能力，性能提升了2.33%。

**Conclusion:** Code2Logic方法通过利用游戏代码有效地解决了VLM推理数据稀缺的问题，并证明了其合成数据在增强VLM通用推理能力方面的有效性，即使在域外任务上也能实现泛化。

> **ai_Abstract:** 本文针对视觉语言模型（VLM）推理能力受限于稀缺的视觉语言思维链（CoT）数据资源的问题，提出Code2Logic，一种利用游戏代码驱动的多模态推理数据合成方法。该方法通过大型语言模型（LLM）适应游戏代码，并通过代码执行自动获取推理过程和结果。基于此方法构建的GameQA数据集具有成本效益、可扩展性、难度可控且多样化。实验表明，尽管仅在游戏数据上训练，VLMs（如Qwen2.5-VL-7B）在多个视觉语言基准测试中展现出2.33%的性能提升和显著的域外泛化能力。

> **摘要翻译:** 视觉-语言思维链（CoT）数据资源相较于纯文本对应物而言相对稀缺，这限制了视觉语言模型（VLM）推理能力的提升。然而，高质量的视觉-语言推理数据标注成本高昂且劳动密集。为解决此问题，我们利用了一种有前景的资源：游戏代码，它天然包含逻辑结构和状态转换过程。因此，我们提出了Code2Logic，一种新颖的、由游戏代码驱动的多模态推理数据合成方法。我们的方法利用大型语言模型（LLM）来适应游戏代码，通过代码执行自动获取推理过程和结果。使用Code2Logic方法，我们开发了GameQA数据集来训练和评估VLM。GameQA具有成本效益和可扩展性，提供可控的难度分级，并且多样化，包含30款游戏和158项任务。令人惊讶的是，尽管仅在游戏数据上训练，VLMs展现出域外泛化能力，特别是Qwen2.5-VL-7B在7个不同的视觉-语言基准测试中性能提升了2.33%。我们的代码、数据集和模型可在https://github.com/tongjingqi/Code2Logic获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [340] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
> *识别文本中自我面向的计算框架*

*Jaya Caporusso, Matthew Purver, Senja Pollak* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 自我面向, 自然语言处理, 计算框架, 心理健康, 本体论

**Comment:** Accepted to ACL SRW 2025

> **TL;DR:** 本博士提案旨在开发一个计算框架，用于在文本中识别“自我面向”，通过构建本体论和数据集，并评估多种NLP模型，以应用于心理健康等领域。

**AI_Comments:** 这项提案具有创新性，因为它旨在弥补“自我”概念在自然语言处理领域研究不足的空白，并将其与心理健康等重要应用领域相结合。通过构建本体论和黄金标准数据集，为未来的研究奠定了坚实的基础。评估标准全面，考虑了模型的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管“自我”在认知科学和现象学等领域被广泛描述，但在自然语言处理（NLP）领域仍未得到充分探索。鉴于许多自我面向与心理健康等已充分研究的现象相关联，因此需要进行系统的基于NLP的分析。

**Method:** 该提案计划开发一个计算框架来识别文本中的自我面向。具体方法包括：1) 引入一个自我面向的本体论（ontology）和一个黄金标准标注数据集；2) 基于此基础，开发并评估传统的判别模型、生成式大型语言模型和基于嵌入的检索方法；3) 评估将基于可解释性、与真实值的符合度、准确性和计算效率四个主要标准。表现最佳的模型将应用于心理健康和经验现象学的案例研究中。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本博士提案旨在开发一个计算框架，用于在文本中识别“自我面向”。鉴于“自我”在NLP领域研究不足但与心理健康等领域高度相关，研究者计划构建一个自我面向的本体论和黄金标准数据集。在此基础上，将开发并评估判别模型、大型语言模型和嵌入式检索方法，重点关注其可解释性、准确性、真实值符合度和计算效率，最终将表现优异的模型应用于心理健康等实际案例研究。

> **摘要翻译:** 这项博士提案介绍了一个开发计算框架的计划，旨在识别文本中的“自我面向”。“自我”是一个多方面的概念，并反映在语言中。尽管它在认知科学和现象学等学科中有所描述，但在自然语言处理（NLP）领域仍未得到充分探索。许多“自我”的面向与心理学及其他充分研究的现象（例如，与心理健康相关的现象）相符，这突出了进行系统性基于NLP的分析的必要性。为此，我们计划引入一个自我面向的本体论和一个黄金标准标注数据集。以此为基础，我们将开发并评估传统的判别模型、生成式大型语言模型以及基于嵌入的检索方法，并依据四个主要标准进行评估：可解释性、真实值符合度、准确性和计算效率。表现最佳的模型将应用于心理健康和经验现象学的案例研究中。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [353] [ContextQFormer: A New Context Modeling Method for Multi-Turn Multi-Modal Conversations](https://arxiv.org/abs/2505.23121)
> *ContextQFormer：一种多轮多模态对话的上下文建模新方法*

*Yiming Lei, Zhizheng Yang, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 多模态对话, 上下文建模, ContextQFormer, TMDialog, 长上下文

**Comment:** 9 pages, 6 figures

> **TL;DR:** 本文提出了一种新的上下文建模模块ContextQFormer，用于增强多模态大模型在多轮多模态对话中的长上下文处理能力，并构建了一个新的多轮多模态对话数据集TMDialog。实验证明ContextQFormer在可用率上优于基线模型。

**AI_Comments:** 该论文针对多模态对话中长上下文处理的痛点，提出了ContextQFormer这一创新性的上下文建模方法，并通过构建专门的TMDialog数据集来支持和验证其效果，这对于推动多轮多模态对话领域的发展具有重要意义。数据集的开源将进一步促进该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的开源多模态模型在多轮交互，特别是长上下文处理方面能力较弱。

**Method:** 引入了一个名为ContextQFormer的上下文建模模块，它利用内存块来增强上下文信息的表示。此外，构建了一个新的多轮多模态对话数据集TMDialog，用于预训练、指令微调和评估，该数据集包含更长的对话。

**Result:** ContextQFormer在TMDialog数据集上与三个基线模型进行比较，实验结果表明ContextQFormer在可用率方面比基线模型提高了2%-4%。

**Conclusion:** ContextQFormer有效提升了多模态模型在多轮多模态对话中的上下文处理能力，并且TMDialog数据集的构建为该领域的研究提供了支持。

> **ai_Abstract:** 本文针对现有开源多模态模型在多轮长上下文交互能力不足的问题，提出了一种新的上下文建模模块ContextQFormer，该模块通过内存块增强上下文表示。同时，为了促进研究，构建了一个包含更长对话的多轮多模态对话数据集TMDialog。实验结果表明，ContextQFormer在TMDialog上相较于基线模型在可用率上提升了2%-4%。

> **摘要翻译:** 多模态大语言模型展现出了卓越的零样本能力和强大的图像理解能力。然而，现有的开源多模态模型在多轮交互方面能力较弱，特别是对于长上下文。为了解决这个问题，我们首先引入了一个上下文建模模块，命名为ContextQFormer，它利用记忆块来增强上下文信息的表示。此外，为了促进进一步的研究，我们精心构建了一个新的多轮多模态对话数据集（TMDialog）用于预训练、指令微调和评估，该数据集将在后期开源。与其他多模态对话数据集相比，TMDialog包含更长的对话，这支持了多轮多模态对话的研究。此外，ContextQFormer在TMDialog上与三个基线模型进行了比较，实验结果表明ContextQFormer在可用率方面比基线模型提高了2%-4%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [356] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
> *大语言模型对符号音乐的内在感知*

*Andrew Shin, Kunitake Kaneko* | **Category: cs.CL, cs.AI, cs.LG, cs.SD, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 大语言模型, 符号音乐, 音乐生成, 神经网络, MIDI

**Comment:** 

> **TL;DR:** 本文研究大语言模型在没有明确音乐训练的情况下如何通过文本提示生成符号音乐，并评估其隐含的音乐理解能力，发现它们能推断出基本的音乐结构但也有局限性。

**AI_Comments:** 这项研究通过在没有明确音乐训练的情况下，利用LLM从文本生成音乐并以此训练下游模型，展示了LLM理解和推理非文本符号领域（如音乐）的独特潜力。其创新点在于探索了LLM的“内部感知”而非外部训练，揭示了LLM跨模态泛化的能力，尽管也指出了其在缺乏专业领域知识时的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在自然语言和其他符号领域表现出色，但其对符号音乐的隐式建模能力尚未充分探索。本文旨在研究大语言模型如何表示音乐概念。

**Method:** 通过文本提示生成符号音乐（MIDI文件），不依赖显式音乐训练；构建由LLM生成的MIDI数据集；在此数据集上训练神经网络，进行流派和风格分类以及旋律补全任务，并与现有模型进行性能基准测试。

**Result:** 结果表明，大语言模型可以从文本中推断出基本的音乐结构和时间关系。

**Conclusion:** 本研究揭示了大语言模型隐式编码音乐模式的潜力及其因缺乏显式音乐上下文而存在的局限性，并阐明了其在符号音乐生成方面的能力。

> **ai_Abstract:** 本文探索了大语言模型（LLMs）对符号音乐的内在感知能力。研究人员通过文本提示让LLMs生成MIDI音乐数据，并在未进行明确音乐训练的情况下，使用这些生成数据训练神经网络进行音乐分类和补全任务。结果表明，LLMs能够从文本中推断出基本的音乐结构和时间关系，揭示了其隐式编码音乐模式的潜力，同时也指出了其缺乏显式音乐上下文的局限性，为LLMs在符号音乐生成方面的应用提供了见解。

> **摘要翻译:** 大语言模型（LLMs）擅长对自然语言中的字符串关系进行建模，并已显示出扩展到编码或数学等其他符号领域的潜力。然而，它们在多大程度上隐式建模符号音乐仍未得到充分探索。本文通过从描述流派和风格组合的文本提示生成符号音乐数据，并评估其在识别和生成任务中的效用，来研究LLMs如何表示音乐概念。我们生成了一个不依赖显式音乐训练的LLM生成MIDI文件数据集。然后，我们完全在此LLM生成MIDI数据集上训练神经网络，并执行流派和风格分类以及旋律补全，将其性能与已建立的模型进行基准测试。我们的结果表明，LLMs可以从文本中推断出基本的音乐结构和时间关系，这突出了它们隐式编码音乐模式的潜力及其由于缺乏显式音乐上下文而存在的局限性，从而阐明了它们在符号音乐生成方面的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [369] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
> *QuestA：通过问题增强扩展大型语言模型推理能力*

*Jiazheng Li, Hong Lu, Kaiyue Wen, Zaiwen Yang, Jiaxuan Gao, Hongzhou Lin, Yi Wu, Jingzhao Zhang* | **Category: cs.CL, cs.AI, 68T50** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 强化学习, 问题增强, 推理能力, 数学推理

**Comment:** 19 pages, 8 figures

> **TL;DR:** QuestA通过在训练中引入部分解来增强大型语言模型在多步推理任务上的表现，尤其是在标准强化学习难以解决的难题上。

**AI_Comments:** QuestA的创新之处在于其简单而有效的问题增强策略，通过引入部分解决方案来优化强化学习过程，从而在不增加模型规模的情况下显著提升了LLMs在复杂推理任务上的性能。这种方法提供了一种通用且实用的途径来增强LLMs的推理能力，对于推动LLMs在需要多步推理的领域（如科学、数学）的应用具有重要意义。该研究不仅提供了经验性证据，还给出了理论解释，增加了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在训练大型语言推理模型中是关键组成部分，但近期研究质疑其在提高多步推理（特别是难题）方面的有效性。

**Method:** 我们提出了一种名为QuestA的简单而有效的策略，通过问题增强（Question Augmentation）实现：在训练期间引入部分解决方案，以降低问题难度并提供更具信息量的学习信号。

**Result:** QuestA在数学推理任务的强化学习训练中应用时，不仅提高了pass@1，还显著提高了pass@k，尤其是在标准强化学习难以取得进展的问题上。它使DeepScaleR和OpenMath Nemotron等强大的开源模型能够持续改进。使用1.5B参数模型，在数学基准测试中取得了新的SOTA结果：AIME24上达到67.1%（+5.3%），AIME25上达到59.5%（+10.0%），HMMT25上达到35.5%（+4.0%）。

**Conclusion:** QuestA通过强化学习提高了样本效率，为扩展推理能力提供了一个实用且可推广的途径。

> **ai_Abstract:** 该论文提出了一种名为QuestA的新策略，通过在大型语言模型（LLMs）的强化学习训练中引入问题增强（即部分解决方案），旨在解决现有强化学习在处理多步推理难题时的局限性。QuestA通过降低问题难度和提供更丰富的学习信号，显著提升了LLMs在数学推理任务上的表现，尤其是在pass@k指标上。实验结果表明，QuestA在多个数学基准测试上取得了最先进的成果，并能持续改进现有强大的开源模型，同时理论分析也支持其提高了样本效率。

> **摘要翻译:** 强化学习（RL）已成为训练大型语言推理模型（LLMs）的关键组成部分。然而，最近的研究对其在提高多步推理（特别是难题）方面的有效性提出了质疑。为了应对这一挑战，我们提出了一种简单而有效的策略，即问题增强（Question Augmentaion）：在训练期间引入部分解决方案，以降低问题难度并提供更具信息量的学习信号。我们的方法QuestA在数学推理任务的强化学习训练中应用时，不仅提高了pass@1，还提高了pass@k——特别是在标准强化学习难以取得进展的问题上。这使得DeepScaleR和OpenMath Nemotron等强大的开源模型能够持续改进，进一步增强了它们的推理能力。我们使用1.5B参数模型在数学基准测试中取得了新的最先进结果：AIME24上达到67.1%（+5.3%），AIME25上达到59.5%（+10.0%），HMMT25上达到35.5%（+4.0%）。此外，我们提供了理论解释，说明QuestA提高了样本效率，为通过强化学习扩展推理能力提供了一个实用且可推广的途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [382] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
> *评估LLM标注在人口统计学偏见和模型解释背景下的可靠性*

*Hadi Mohammadi, Tina Shahedi, Pablo Mosteiro, Massimo Poesio, Ayoub Bagheri, Anastasia Giachanou* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 人口统计学偏见, LLM标注, 可解释AI, 性别歧视检测, 标注可靠性

**Comment:** 

> **TL;DR:** 研究发现人口统计学特征对NLP标注的影响很小，主要还是文本内容。指导LLM使用人口统计学角色通常不能提高标注性能，有时甚至会降低。XAI显示模型预测主要依赖内容而非人口统计学特征。

**AI_Comments:** 这篇论文对于理解自然语言处理系统中的偏见来源以及LLM在标注任务中的应用具有重要意义。其创新之处在于量化了人口统计学特征对标注的影响，并评估了LLM作为标注者的局限性，特别是指出简单的角色提示并不总是有效。论文的结论强调内容驱动的解释和鲁棒的标注协议，为未来公平NLP系统的开发提供了实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 了解标注变异的来源对于开发公平的NLP系统至关重要，尤其是在性别歧视检测等存在人口统计学偏见的任务中。本研究旨在调查标注者人口统计学特征与文本内容对标注决策的影响。

**Method:** 使用广义线性混合模型（Generalized Linear Mixed Model）量化人口统计学特征对标注决策的影响。评估生成式AI模型作为标注者的可靠性，并探讨使用人口统计学角色指导是否能改善与人类判断的一致性。使用可解释AI（XAI）技术揭示模型预测的依赖性。

**Result:** 人口统计学因素虽然统计上存在影响，但仅占观察到方差的8%，推文内容是主导因素。简单的角色提示通常无法提高，有时甚至会降低基线模型的性能。XAI显示模型预测主要依赖于与性别歧视相关的内容特定token，而非人口统计学特征的相关性。

**Conclusion:** 专注于内容驱动的解释和稳健的标注协议是实现公平性更可靠的途径，而非潜在的角色模拟。

> **ai_Abstract:** 本研究探讨了在性别歧视检测任务中，标注者人口统计学特征和文本内容对标注决策的影响，并评估了大型语言模型（LLMs）作为标注者的可靠性。结果显示，人口统计学因素对标注变异的影响微乎其微（8%），文本内容是主导因素。同时，简单的LLM人口学角色引导未能提升甚至可能降低标注性能。可解释AI分析表明模型主要依据内容而非人口统计学特征进行预测。研究强调，应侧重于内容驱动的解释和稳健的标注协议以实现公平性。

> **摘要翻译:** 了解标注变异的来源对于开发公平的自然语言处理（NLP）系统至关重要，特别是在性别歧视检测等人口统计学偏见令人担忧的任务中。本研究调查了标注者人口统计学特征与文本内容相比，在多大程度上影响标注决策。我们使用广义线性混合模型量化了这种影响，发现虽然统计学上存在，但人口统计学因素仅占观察到方差的一小部分（8%），而推文内容是主导因素。然后，我们评估了生成式AI（GenAI）模型作为标注者的可靠性，特别是评估了通过人口统计学角色引导它们是否能提高与人类判断的一致性。我们的结果表明，与基线模型相比，简单的角色提示通常无法增强性能，有时甚至会降低性能。此外，可解释AI（XAI）技术揭示，模型预测主要依赖于与性别歧视相关的内容特定标记，而不是人口统计学特征的相关性。我们认为，专注于内容驱动的解释和稳健的标注协议，而非潜在的角色模拟，为实现公平性提供了更可靠的途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [383] [Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback](https://arxiv.org/abs/2506.03106)
> *Critique-GRPO：通过自然语言和数值反馈提升LLM推理能力*

*Xiaoying Zhang, Hao Sun, Yipeng Zhang, Kaituo Feng, Chaochao Lu, Chao Yang, Helen Meng* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** LLM推理, 强化学习, 自然语言反馈, 数值反馈, Critique-GRPO

**Comment:** 52 pages, updated with new experimental results and implementation
  details

> **TL;DR:** Critique-GRPO通过结合自然语言和数值反馈，显著提升了大型语言模型的推理能力，解决了纯数值反馈RL的局限性。

**AI_Comments:** Critique-GRPO的创新之处在于其将自然语言反馈（批评）与传统的数值反馈相结合，形成了一个更全面、更有效的强化学习范式，以克服纯数值RL的固有局限性。这对于提升LLM在复杂推理任务上的性能，尤其是实现更深层次的自我纠正和泛化能力具有重要意义。通过引入塑造函数来引导学习，该方法也展现了对学习过程的精细控制，有助于LLM从错误中更高效地学习。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于数值反馈的强化学习（RL）在增强大型语言模型（LLM）的复杂推理能力方面取得了成功，但纯数值反馈的RL面临性能瓶颈、自反思效果有限以及持续失败等挑战。

**Method:** 本文提出了Critique-GRPO，一个在线强化学习框架，它整合了自然语言和数值反馈以进行有效的策略优化。Critique-GRPO使LLM能够同时从初始响应和批评引导的自我改进中学习，并保持探索性。此外，它采用了一个塑造函数来增强从正确（尤其是陌生）改进中的学习，并惩罚不正确的改进。

**Result:** Critique-GRPO在八项具有挑战性的数学、STEM和通用推理任务上，始终优于监督学习和基于RL的微调方法，在Qwen2.5-7B-Base和Qwen3-8B上的平均pass@1分数分别提高了约4.4%和3.8%。它通过自我批评和从弱到强的泛化实现了有效的自我改进，例如在AIME 2024上比GRPO分别高出16.7%和10.0%的pass@1改进。

**Conclusion:** Critique-GRPO通过有效整合自然语言和数值反馈，显著提升了LLM的推理能力，克服了纯数值RL的局限性，并实现了模型通过自我批评进行有效的自我改进。

> **ai_Abstract:** 本文提出了Critique-GRPO，一个创新的在线强化学习框架，旨在解决现有纯数值反馈RL在提升LLM推理能力时遇到的性能瓶颈和自反思局限性。Critique-GRPO通过巧妙地整合自然语言批评和数值反馈，使LLM能够同时从初始响应和自我纠正中学习。实验结果表明，Critique-GRPO在多个推理任务上显著优于监督学习和传统RL微调方法，并能通过自我批评实现有效的模型自我改进和泛化能力。

> **摘要翻译:** 摘要：
近期，以标量奖励等数值反馈为基础的强化学习（RL）取得了进展，显著提升了大型语言模型（LLM）的复杂推理能力。尽管取得了成功，我们发现纯数值反馈的RL面临三个关键挑战：性能瓶颈、自发性自我反思效果有限以及持续失败。随后，我们证明了即使RL微调模型在表现出性能瓶颈后，通过利用批评形式的自然语言反馈，也能对持续失败的问题生成正确的改进。基于这一洞察，我们提出了Critique-GRPO，一个在线RL框架，它整合了自然语言和数值反馈以进行有效的策略优化。Critique-GRPO使LLM能够同时从初始响应和批评引导的自我改进中学习，同时保持探索性。此外，我们采用了一个塑造函数来增强从正确（尤其是陌生）改进中的学习，并惩罚不正确的改进。使用Qwen2.5-7B-Base、Qwen2.5-Math-7B-Base和Qwen3-8B进行的广泛实验表明，Critique-GRPO在八项具有挑战性的数学、STEM和通用推理任务上始终优于监督学习和基于RL的微调方法，在Qwen2.5-7B-Base和Qwen3-8B上的平均pass@1分数分别提高了约4.4%和3.8%。值得注意的是，Critique-GRPO通过自我批评和从弱到强的泛化实现了有效的自我改进，比GRPO取得了持续的提升，例如在AIME 2024上分别提高了16.7%和10.0%的pass@1。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [403] [Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation](https://arxiv.org/abs/2506.17088)
> *思想链提示在大型语言模型中掩盖了幻觉线索：一项实证评估*

*Jiahao Cheng, Tiancheng Su, Jia Yuan, Guoxiu He, Jiawei Liu, Xinqi Tao, Jingwen Xie, Huaxia Li* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 幻觉, 思想链提示, 幻觉检测, 实证评估

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）中的思想链（CoT）提示虽然有助于减少幻觉频率，但却会掩盖用于幻觉检测的关键信号，从而损害了各种检测方法的有效性。

**AI_Comments:** 这项研究揭示了一个重要的、此前被忽视的CoT提示的负面效应，即它可能通过改变LLM内部状态来“隐藏”幻觉的线索，使得幻觉更难被检测。这对于追求LLM可靠性和可信度的研究和应用具有重要意义，提示未来研究需在减少幻觉和保持可检测性之间寻求平衡，或开发新的、对CoT鲁棒的检测方法。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）经常出现“幻觉”现象。虽然思想链（CoT）提示可以减轻幻觉，但其对幻觉检测的影响尚未得到充分探索。本研究旨在弥补这一空白。

**Method:** 本研究进行了一项系统的实证评估。首先，通过初步实验揭示CoT推理对LLM内部状态和token概率分布的显著影响。然后，评估了各种CoT提示方法对主流幻觉检测方法在指令调优和推理导向LLMs上的影响，具体考察了幻觉分数分布、检测准确性和检测置信度的变化。

**Result:** 研究发现，尽管CoT提示有助于降低幻觉频率，但它也倾向于掩盖用于检测的关键信号，从而损害了各种检测方法的有效性。

**Conclusion:** 本研究强调了在使用推理（如CoT提示）时一个被忽视的权衡：它在减少大型语言模型幻觉的同时，却削弱了现有检测方法识别幻觉的能力。

> **ai_Abstract:** 本研究对大型语言模型中思想链（CoT）提示对幻觉生成和检测的影响进行了系统实证评估。研究发现，尽管CoT提示能有效减少LLMs的幻觉频率，但它同时会改变模型的内部状态和token概率分布，进而掩盖了用于幻觉检测的关键信号，导致现有主流检测方法的准确性和置信度下降。这揭示了在利用CoT进行推理时，减少幻觉和有效检测幻觉之间存在一个重要的权衡。

> **摘要翻译:** 大型语言模型（LLMs）经常表现出“幻觉”，即生成事实不正确或语义无关的内容以响应提示。思想链（CoT）提示通过鼓励分步推理可以减轻幻觉，但其对幻觉检测的影响仍未被充分探索。为了弥补这一空白，我们进行了一项系统的实证评估。我们首先进行了一项初步实验，揭示CoT推理显著影响LLM的内部状态和token概率分布。在此基础上，我们评估了各种CoT提示方法对指令调优和推理导向LLMs上主流幻觉检测方法的影响。具体来说，我们检查了三个关键维度：幻觉分数分布的变化、检测准确性的变化以及检测置信度的偏移。我们的研究结果表明，虽然CoT提示有助于降低幻觉频率，但它也倾向于掩盖用于检测的关键信号，从而损害了各种检测方法的有效性。我们的研究强调了在使用推理时一个被忽视的权衡。代码已公开发布在：https://anonymous.4open.science/r/cot-hallu-detect。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [411] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
> *TalentCLEF 2025 概述：人力资本管理中的技能和职位智能*

*Luis Gasco, Hermenegildo Fabregat, Laura García-Sardiña, Paula Estrella, Daniel Deniz, Alvaro Rodrigo, Rabih Zbib* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-17**

**Keywords:** 人力资本管理, 技能智能, 职位匹配, 自然语言处理, 公共基准

**Comment:** 

> **TL;DR:** TalentCLEF 2025 是首个针对技能和职位智能的评估活动，旨在为人力资本管理领域提供急需的公共基准和数据，以推动可靠、公平的语言技术发展。

**AI_Comments:** 这项工作的重要性在于，它首次为人力资本管理领域的语言技术提供了公共的、经过评估的基准和数据。通过包含多语言任务和性别偏见评估，TalentCLEF 2025 有助于推动该领域开发更鲁棒、公平和实际可用的AI模型。其发现，即训练策略比模型大小更重要，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 人力资本管理领域对基于语言技术的智能系统需求日益增长，但目前缺乏用于评估可靠和公平模型的公共数据和开放基准。

**Method:** TalentCLEF 2025 是首个专注于技能和职位智能的评估活动，包含两个任务：任务A为多语言职位匹配（涵盖英、西、德、中），任务B为基于职位的技能预测（英文）。所有语料库均来自真实求职申请，经过匿名化和人工标注。评估涵盖单语、跨语言场景以及性别偏见评估。

**Result:** TalentCLEF 吸引了76支团队和280多次提交。大多数系统采用基于多语言编码器的信息检索技术，通过对比学习进行微调，并结合大型语言模型进行数据增强或重排序。结果表明，训练策略对性能的影响大于模型大小。

**Conclusion:** TalentCLEF 提供了人力资本管理领域首个公共基准，并鼓励开发适用于劳动力市场的鲁棒、公平和可迁移的语言技术。

> **ai_Abstract:** 本论文概述了 TalentCLEF 2025，这是首个专注于人力资本管理领域技能和职位智能的评估活动。该活动旨在解决该领域缺乏公共数据和开放基准的问题，提供了多语言职位匹配和基于职位的技能预测两项任务。通过真实世界语料库和对性别偏见的评估，TalentCLEF 吸引了大量参与者，并揭示了训练策略对模型性能的重要性。它为劳动力市场语言技术的发展设立了重要的公共基准。

> **摘要翻译:** 自然语言处理和大型语言模型的进步正在推动人力资本管理领域的重大变革，人们对构建基于语言技术的智能系统以用于人才获取、技能提升策略和劳动力规划的兴趣日益增长。然而，这些技术的采用和进展关键取决于开发可靠和公平的模型，并在公共数据和开放基准上进行适当评估，而这些在该领域迄今尚未 उपलब्ध。
为了弥补这一空白，我们推出了 TalentCLEF 2025，这是首个专注于技能和职位智能的评估活动。该实验室包含两个任务：任务A - 多语言职位匹配，涵盖英语、西班牙语、德语和中文；以及任务B - 基于职位的技能预测，使用英语。两个语料库均从真实求职申请中构建，经过仔细匿名化和人工标注，以反映真实世界劳动力市场数据的复杂性和多样性，包括语言变异性和性别标记表达。
评估包括单语和跨语言场景，并涵盖了性别偏见的评估。
TalentCLEF 吸引了76个注册团队，提交了280多次。大多数系统依赖于通过对比学习微调的多语言编码器模型构建的信息检索技术，其中一些整合了大型语言模型进行数据增强或重新排序。结果表明，训练策略的影响大于模型本身的大小。TalentCLEF 提供了该领域的首个公共基准，并鼓励为劳动力市场开发鲁棒、公平和可迁移的语言技术。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [417] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
> *基于特征的南非荷兰语和科萨语儿童口语叙事分析*

*Emma Sharratt, Annelien Smith, Retief Louw, Daleen Klop, Febe de Wet, Herman Kamper* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 口语叙事, 儿童语言, 机器学习, 识字发展, 跨语言

**Comment:** SLaTE 2025 in Nijmegen, Netherlands

> **TL;DR:** 本研究利用机器学习分析南非荷兰语和科萨语儿童的口语叙事，识别出词汇多样性和特定动词等特征，作为叙事能力和干预需求的预测指标。

**AI_Comments:** 该论文通过机器学习对口语叙事进行跨语言分析，特别是研究了两种截然不同的南非语言，具有创新性。其发现为在多语言环境中早期识别有识字发展风险的儿童提供了宝贵见解，超越了单一语言研究。识别特定语法特征（动词/助词）作为预测因子是一项值得注意的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 口语叙事能力是后期识字能力发展的有力预测指标。本研究旨在考察被专家认定需要干预的儿童的口语叙事特征。

**Method:** 本研究使用简单的机器学习方法，分析了四到五岁南非荷兰语和科萨语儿童的录制故事。

**Result:** 词汇多样性（独特词汇）和基于长度的特征（平均话语长度）是典型发展的指标，而发音速度信息量较小。与目标导向叙事相关的特定动词和助词的使用与干预需求降低的可能性相关。分析揭示了叙事能力方面的语言特有和共享预测因子。

**Conclusion:** 本研究的发现对多语言环境中的早期评估具有重要意义，揭示了两种语言学上截然不同的语言中叙事能力的语言特有和共享预测因子。

> **ai_Abstract:** 本研究调查了四到五岁南非荷兰语和科萨语儿童的口语叙事特征，这些儿童被认定需要干预。研究采用简单的机器学习方法，证实词汇多样性和话语长度是典型发展的指标，而发音速度作用不大。重要的是，使用与目标导向叙事相关的特定动词和助词与较低的干预可能性相关。研究结果揭示了叙事能力的语言特有和普遍预测因子，为多语言环境中的早期评估提供了见解。

> **摘要翻译:** 口语叙事能力是后期识字能力发展的有力预测指标。本研究考察了被专家认定需要干预的儿童的口语叙事特征。我们使用简单的机器学习方法，分析了四到五岁南非荷兰语和科萨语儿童的录制故事。与先前的研究一致，我们将词汇多样性（独特词汇）和基于长度的特征（平均话语长度）确定为典型发展的指标，但像发音速度这样的特征则信息量较小。尽管词性模式存在跨语言差异，但与目标导向叙事相关的特定动词和助词的使用与干预需求降低的可能性相关。我们对两种语言学上截然不同的语言的分析揭示了叙事能力方面的语言特有和共享预测因子，这对多语言环境中的早期评估具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [423] [Learning to Translate Ambiguous Terminology by Preference Optimization on Post-Edits](https://arxiv.org/abs/2507.03580)
> *通过对后期编辑进行偏好优化来学习翻译歧义术语*

*Nathaniel Berger, Johannes Eschbach-Dymanus, Miriam Exel, Matthias Huck, Stefan Riezler* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 神经机器翻译, 术语歧义, 偏好优化, 后期编辑, 术语准确性

**Comment:** 

> **TL;DR:** 本文提出一种基于偏好优化的方法，利用人工后期编辑数据来解决神经机器翻译中歧义术语的翻译问题，提高了术语准确性。

**AI_Comments:** 这篇论文的创新点在于它利用了现实世界中丰富的后期编辑数据来解决机器翻译中术语歧义的难题，避免了传统方法对严格一对一词典的依赖。通过偏好优化，模型能够学习到上下文相关的术语选择偏好，这对于企业级或专业领域的机器翻译具有重要意义。其方法避免了人工干预，提高了自动化程度，具有很好的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在实际翻译场景中，术语往往不是一一对应的，一个术语可能有多个有效译文，但其正确性取决于企业风格指南和语境，这给神经机器翻译（NMT）系统带来了挑战。

**Method:** 本文提出一种基于偏好优化的方法，利用术语后期编辑作为优先知识，学习如何消除术语歧义。该框架无需一对一词典或解码时的人工干预，与以往依赖明确翻译词典或输入软约束的方法不同。

**Result:** 监督微调和偏好优化（结合术语特定和全序列目标）的最佳组合在术语准确性方面相对于强大的NMT基线取得了统计学上的显著提升，同时COMET分数没有显著损失。此外，研究者还发布了后期编辑数据和术语词典中的测试集。

**Conclusion:** 通过利用人工后期编辑数据进行偏好优化，可以有效解决神经机器翻译中歧义术语的翻译问题，显著提高术语准确性，而无需严格的词典约束或人工干预。

> **ai_Abstract:** 本文提出了一种新颖的神经机器翻译方法，旨在解决实际翻译中歧义术语的翻译问题。该方法利用人工后期编辑数据进行偏好优化，学习如何根据上下文和企业风格指南选择正确的术语译文。与以往需要严格词典约束或人工干预的方法不同，本框架通过结合监督微调和偏好优化，在英德数据集上显著提高了术语准确性，同时保持了整体翻译质量。研究还发布了相关测试集。

> **摘要翻译:** 在现实世界的翻译场景中，术语很少是一一对应的。相反，术语词典中可能会出现多个有效译文，但翻译的正确性取决于企业风格指南和上下文。这对于神经机器翻译（NMT）系统来说可能是一个挑战。幸运的是，在企业环境中，存在许多对有效但不正确的术语进行人工后期编辑的例子。这项工作的目标是根据这些修正来学习如何消除术语的歧义。我们的方法基于偏好优化，使用术语后期编辑作为优先知识。虽然以前的工作不得不依赖明确的翻译词典在解码期间设置硬约束，或者在输入中添加软约束，但我们的框架既不需要一对一词典，也不需要在解码时进行人工干预。我们报告了在英德后期编辑数据上的结果，发现监督微调和偏好优化的最佳组合（同时包含术语特定和全序列目标）在术语准确性方面相对于强大的NMT基线取得了统计学上的显著改进，而COMET分数没有显著损失。此外，我们发布了从我们的后期编辑数据和术语词典中提取的测试集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [443] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
> *Gemini 2.5：以高级推理、多模态、长上下文和下一代代理能力推动前沿*

*Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, Krishna Haridasan, Ahmed Omran, Nikunj Saunshi, Dara Bahri, Gaurav Mishra, Eric Chu, Toby Boyd, Brad Hekman, Aaron Parisi, Chaoyi Zhang, Kornraphop Kawintiranon, Tania Bedrax-Weiss, Oliver Wang, Ya Xu, Ollie Purkiss, Uri Mendlovic, Ilaï Deutel, Nam Nguyen, Adam Langley, Flip Korn, Lucia Rossazza, Alexandre Ramé, Sagar Waghmare, Helen Miller, Vaishakh Keshava, Ying Jian, Xiaofan Zhang, Raluca Ada Popa, Kedar Dhamdhere, Blaž Bratanič, Kyuyeun Kim, Terry Koo, Ferran Alet, Yi-ting Chen, Arsha Nagrani, Hannah Muckenhirn, Zhiyuan Zhang, Corbin Quick, Filip Pavetić, Duc Dung Nguyen, Joao Carreira, Michael Elabd, Haroon Qureshi, Fabian Mentzer, Yao-Yuan Yang, Danielle Eisenbud, Anmol Gulati, Ellie Talius, Eric Ni, Sahra Ghalebikesabi, Edouard Yvinec, Alaa Saade, Thatcher Ulrich, Lorenzo Blanco, Dan A. Calian, Muhuan Huang, Aäron van den Oord, Naman Goyal, Terry Chen, Praynaa Rawlani, Christian Schallhart, Swachhand Lokhande, Xianghong Luo, Jyn Shan, Ceslee Montgomery, Victoria Krakovna, Federico Piccinini, Omer Barak, Jingyu Cui, Yiling Jia, Mikhail Dektiarev, Alexey Kolganov, Shiyu Huang, Zhe Chen, Xingyu Wang, Jessica Austin, Peter de Boursac, Evgeny Sluzhaev, Frank Ding, Huijian Li, Surya Bhupatiraju, Mohit Agarwal, Sławek Kwasiborski, Paramjit Sandhu, Patrick Siegler, Ahmet Iscen, Eyal Ben-David, Shiraz Butt, Miltos Allamanis, Seth Benjamin, Robert Busa-Fekete, Felix Hernandez-Campos, Sasha Goldshtein, Matt Dibb, Weiyang Zhang, Annie Marsden, Carey Radebaugh, Stephen Roller, Abhishek Nayyar, Jacob Austin, Tayfun Terzi, Bhargav Kanagal Shamanna, Pete Shaw, Aayush Singh, Florian Luisier, Artur Mendonça, Vaibhav Aggarwal, Larisa Markeeva, Claudio Fantacci, Sergey Brin, HyunJeong Choe, Guanyu Wang, Hartwig Adam, Avigail Dabush, Tatsuya Kiyono, Eyal Marcus, Jeremy Cole, Theophane Weber, Hongrae Lee, Ronny Huang, Alex Muzio, Leandro Kieliger, Maigo Le, Courtney Biles, Long Le, Archit Sharma, Chengrun Yang, Avery Lamp, Dave Dopson, Nate Hurley, Katrina, Xu, Zhihao Shan, Shuang Song, Jiewen Tan, Alexandre Senges, George Zhang, Chong You, Yennie Jun, David Raposo, Susanna Ricco, Xuan Yang, Weijie Chen, Prakhar Gupta, Arthur Szlam, Kevin Villela, Chun-Sung Ferng, Daniel Kasenberg, Chen Liang, Rui Zhu, Arunachalam Narayanaswamy, Florence Perot, Paul Pucciarelli, Anna Shekhawat, Alexey Stern, Rishikesh Ingale, Stefani Karp, Sanaz Bahargam, Adrian Goedeckemeyer, Jie Han, Sicheng Li, Andrea Tacchetti, Dian Yu, Abhishek Chakladar, Zhiying Zhang, Mona El Mahdy, Xu Gao, Dale Johnson, Samrat Phatale, AJ Piergiovanni, Hyeontaek Lim, Clement Farabet, Carl Lebsack, Theo Guidroz, John Blitzer, Nico Duduta, David Madras, Steve Li, Daniel von Dincklage, Xin Li, Mahdis Mahdieh, George Tucker, Ganesh Jawahar, Owen Xiao, Danny Tarlow, Robert Geirhos, Noam Velan, Daniel Vlasic, Kalesha Bullard, SK Park, Nishesh Gupta, Kellie Webster, Ayal Hitron, Jieming Mao, Julian Eisenschlos, Laurel Prince, Nina D'Souza, Kelvin Zheng, Sara Nasso, Gabriela Botea, Carl Doersch, Caglar Unlu, Chris Alberti, Alexey Svyatkovskiy, Ankita Goel, Krzysztof Choromanski, Pan-Pan Jiang, Richard Nguyen, Four Flynn, Daria Ćurko, Peter Chen, Nicholas Roth, Kieran Milan, Caleb Habtegebriel, Shashi Narayan, Michael Moffitt, Jake Marcus, Thomas Anthony, Brendan McMahan, Gowoon Cheon, Ruibo Liu, Megan Barnes, Lukasz Lew, Rebeca Santamaria-Fernandez, Mayank Upadhyay, Arjun Akula, Arnar Mar Hrafnkelsson, Alvaro Caceres, Andrew Bunner, Michal Sokolik, Subha Puttagunta, Lawrence Moore, Berivan Isik, Jay Hartford, Lawrence Chan, Pradeep Shenoy, Dan Holtmann-Rice, Jane Park, Fabio Viola, Alex Salcianu, Sujeevan Rajayogam, Ian Stewart-Binks, Zelin Wu, Richard Everett, Xi Xiong, Pierre-Antoine Manzagol, Gary Leung, Carl Saroufim, Bo Pang, Dawid Wegner, George Papamakarios, Jennimaria Palomaki, Helena Pankov, Guangda Lai, Guilherme Tubone, Shubin Zhao, Theofilos Strinopoulos, Seth Neel, Mingqiu Wang, Joe Kelley, Li Li, Pingmei Xu, Anitha Vijayakumar, Andrea D'olimpio, Omer Levy, Massimo Nicosia, Grigory Rozhdestvenskiy, Ni Lao, Sirui Xie, Yash Katariya, Jon Simon, Sanjiv Kumar, Florian Hartmann, Michael Kilgore, Jinhyuk Lee, Aroma Mahendru, Roman Ring, Tom Hennigan, Fiona Lang, Colin Cherry, David Steiner, Dawsen Hwang, Ray Smith, Pidong Wang, Jeremy Chen, Ming-Hsuan Yang, Sam Kwei, Philippe Schlattner, Donnie Kim, Ganesh Poomal Girirajan, Nikola Momchev, Ayushi Agarwal, Xingyi Zhou, Ilkin Safarli, Zachary Garrett, AJ Pierigiovanni, Sarthak Jauhari, Alif Raditya Rochman, Shikhar Vashishth, Quan Yuan, Christof Angermueller, Jon Blanton, Xinying Song, Nitesh Bharadwaj Gundavarapu, Thi Avrahami, Maxine Deines, Subhrajit Roy, Manish Gupta, Christopher Semturs, Shobha Vasudevan, Aditya Srikanth Veerubhotla, Shriya Sharma, Josh Jacob, Zhen Yang, Andreas Terzis, Dan Karliner, Auriel Wright, Tania Rojas-Esponda, Ashley Brown, Abhijit Guha Roy, Pawan Dogra, Andrei Kapishnikov, Peter Young, Wendy Kan, Vinodh Kumar Rajendran, Maria Ivanova, Salil Deshmukh, Chia-Hua Ho, Mike Kwong, Stav Ginzburg, Annie Louis, KP Sawhney, Slav Petrov, Jing Xie, Yunfei Bai, Georgi Stoyanov, Alex Fabrikant, Rajesh Jayaram, Yuqi Li, Joe Heyward, Justin Gilmer, Yaqing Wang, Radu Soricut, Luyang Liu, Qingnan Duan, Jamie Hayes, Maura O'Brien, Gaurav Singh Tomar, Sivan Eiger, Bahar Fatemi, Jeffrey Hui, Catarina Barros, Adaeze Chukwuka, Alena Butryna, Saksham Thakur, Austin Huang, Zhufeng Pan, Haotian Tang, Serkan Cabi, Tulsee Doshi, Michiel Bakker, Sumit Bagri, Ruy Ley-Wild, Adam Lelkes, Jennie Lees, Patrick Kane, David Greene, Shimu Wu, Jörg Bornschein, Gabriela Surita, Sarah Hodkinson, Fangtao Li, Chris Hidey, Sébastien Pereira, Sean Ammirati, Phillip Lippe, Adam Kraft, Pu Han, Sebastian Gerlach, Zifeng Wang, Liviu Panait, Feng Han, Brian Farris, Yingying Bi, Hannah DeBalsi, Miaosen Wang, Gladys Tyen, James Cohan, Susan Zhang, Jarred Barber, Da-Woon Chung, Jaeyoun Kim, Markus Kunesch, Steven Pecht, Nami Akazawa, Abe Friesen, James Lyon, Ali Eslami, Junru Wu, Jie Tan, Yue Song, Ravi Kumar, Chris Welty, Ilia Akolzin, Gena Gibson, Sean Augenstein, Arjun Pillai, Nancy Yuen, Du Phan, Xin Wang, Iain Barr, Heiga Zen, Nan Hua, Casper Liu, Jilei, Wang, Tanuj Bhatia, Hao Xu, Oded Elyada, Pushmeet Kohli, Mirek Olšák, Ke Chen, Azalia Mirhoseini, Noam Shazeer, Shoshana Jakobovits, Maggie Tran, Nolan Ramsden, Tarun Bharti, Fred Alcober, Yunjie Li, Shilpa Shetty, Jing Chen, Dmitry Kalashnikov, Megha Nawhal, Sercan Arik, Hanwen Chen, Michiel Blokzijl, Shubham Gupta, James Rubin, Rigel Swavely, Sophie Bridgers, Ian Gemp, Chen Su, Arun Suggala, Juliette Pluto, Mary Cassin, Alain Vaucher, Kaiyang Ji, Jiahao Cai, Andrew Audibert, Animesh Sinha, David Tian, Efrat Farkash, Amy Hua, Jilin Chen, Duc-Hieu Tran, Edward Loper, Nicole Brichtova, Lara McConnaughey, Ballie Sandhu, Robert Leland, Doug DeCarlo, Andrew Over, James Huang, Xing Wu, Connie Fan, Eric Li, Yun Lei, Deepak Sharma, Cosmin Paduraru, Luo Yu, Matko Bošnjak, Phuong Dao, Min Choi, Sneha Kudugunta, Jakub Adamek, Carlos Guía, Ali Khodaei, Jie Feng, Wenjun Zeng, David Welling, Sandeep Tata, Christina Butterfield, Andrey Vlasov, Seliem El-Sayed, Swaroop Mishra, Tara Sainath, Shentao Yang, RJ Skerry-Ryan, Jeremy Shar, Robert Berry, Arunkumar Rajendran, Arun Kandoor, Andrea Burns, Deepali Jain, Tom Stone, Wonpyo Park, Shibo Wang, Albin Cassirer, Guohui Wang, Hayato Kobayashi, Sergey Rogulenko, Vineetha Govindaraj, Mikołaj Rybiński, Nadav Olmert, Colin Evans, Po-Sen Huang, Kelvin Xu, Premal Shah, Terry Thurk, Caitlin Sikora, Mu Cai, Jin Xie, Elahe Dabir, Saloni Shah, Norbert Kalb, Carrie Zhang, Shruthi Prabhakara, Amit Sabne, Artiom Myaskovsky, Vikas Raunak, Blanca Huergo, Behnam Neyshabur, Jon Clark, Ye Zhang, Shankar Krishnan, Eden Cohen, Dinesh Tewari, James Lottes, Yumeya Yamamori, Hui, Li, Mohamed Elhawaty, Ada Maksutaj Oflazer, Adrià Recasens, Sheryl Luo, Duy Nguyen, Taylor Bos, Kalyan Andra, Ana Salazar, Ed Chi, Jeongwoo Ko, Matt Ginsberg, Anders Andreassen, Anian Ruoss, Todor Davchev, Elnaz Davoodi, Chenxi Liu, Min Kim, Santiago Ontanon, Chi Ming To, Dawei Jia, Rosemary Ke, Jing Wang, Anna Korsun, Moran Ambar, Ilya Kornakov, Irene Giannoumis, Toni Creswell, Denny Zhou, Yi Su, Ishaan Watts, Aleksandr Zaks, Evgenii Eltyshev, Ziqiang Feng, Sidharth Mudgal, Alex Kaskasoli, Juliette Love, Kingshuk Dasgupta, Sam Shleifer, Richard Green, Sungyong Seo, Chansoo Lee, Dale Webster, Prakash Shroff, Ganna Raboshchuk, Isabel Leal, James Manyika, Sofia Erell, Daniel Murphy, Zhisheng Xiao, Anton Bulyenov, Julian Walker, Mark Collier, Matej Kastelic, Nelson George, Sushant Prakash, Sailesh Sidhwani, Alexey Frolov, Steven Hansen, Petko Georgiev, Tiberiu Sosea, Chris Apps, Aishwarya Kamath, David Reid, Emma Cooney, Charlotte Magister, Oriana Riva, Alec Go, Pu-Chin Chen, Sebastian Krause, Nir Levine, Marco Fornoni, Ilya Figotin, Nick Roy, Parsa Mahmoudieh, Vladimir Magay, Mukundan Madhavan, Jin Miao, Jianmo Ni, Yasuhisa Fujii, Ian Chou, George Scrivener, Zak Tsai, Siobhan Mcloughlin, Jeremy Selier, Sandra Lefdal, Jeffrey Zhao, Abhijit Karmarkar, Kushal Chauhan, Shivanker Goel, Zhaoyi Zhang, Vihan Jain, Parisa Haghani, Mostafa Dehghani, Jacob Scott, Erin Farnese, Anastasija Ilić, Steven Baker, Julia Pawar, Li Zhong, Josh Camp, Yoel Zeldes, Shravya Shetty, Anand Iyer, Vít Listík, Jiaxian Guo, Luming Tang, Mark Geller, Simon Bucher, Yifan Ding, Hongzhi Shi, Carrie Muir, Dominik Grewe, Ramy Eskander, Octavio Ponce, Boqing Gong, Derek Gasaway, Samira Khan, Umang Gupta, Angelos Filos, Weicheng Kuo, Klemen Kloboves, Jennifer Beattie, Christian Wright, Leon Li, Alicia Jin, Sandeep Mariserla, Miteyan Patel, Jens Heitkaemper, Dilip Krishnan, Vivek Sharma, David Bieber, Christian Frank, John Lambert, Paul Caron, Martin Polacek, Mai Giménez, Himadri Choudhury, Xing Yu, Sasan Tavakkol, Arun Ahuja, Franz Och, Rodolphe Jenatton, Wojtek Skut, Bryan Richter, David Gaddy, Andy Ly, Misha Bilenko, Megh Umekar, Ethan Liang, Martin Sevenich, Mandar Joshi, Hassan Mansoor, Rebecca Lin, Sumit Sanghai, Abhimanyu Singh, Xiaowei Li, Sudheendra Vijayanarasimhan, Zaheer Abbas, Yonatan Bitton, Hansa Srinivasan, Manish Reddy Vuyyuru, Alexander Frömmgen, Yanhua Sun, Ralph Leith, Alfonso Castaño, DJ Strouse, Le Yan, Austin Kyker, Satish Kambala, Mary Jasarevic, Thibault Sellam, Chao Jia, Alexander Pritzel, Raghavender R, Huizhong Chen, Natalie Clay, Sudeep Gandhe, Sean Kirmani, Sayna Ebrahimi, Hannah Kirkwood, Jonathan Mallinson, Chao Wang, Adnan Ozturel, Kuo Lin, Shyam Upadhyay, Vincent Cohen-Addad, Sean Purser-haskell, Yichong Xu, Ebrahim Songhori, Babi Seal, Alberto Magni, Almog Gueta, Tingting Zou, Guru Guruganesh, Thais Kagohara, Hung Nguyen, Khalid Salama, Alejandro Cruzado Ruiz, Justin Frye, Zhenkai Zhu, Matthias Lochbrunner, Simon Osindero, Wentao Yuan, Lisa Lee, Aman Prasad, Lam Nguyen Thiet, Daniele Calandriello, Victor Stone, Qixuan Feng, Han Ke, Maria Voitovich, Geta Sampemane, Lewis Chiang, Ling Wu, Alexander Bykovsky, Matt Young, Luke Vilnis, Ishita Dasgupta, Aditya Chawla, Qin Cao, Bowen Liang, Daniel Toyama, Szabolcs Payrits, Anca Stefanoiu, Dimitrios Vytiniotis, Ankesh Anand, Tianxiao Shen, Blagoj Mitrevski, Michael Tschannen, Sreenivas Gollapudi, Aishwarya P S, José Leal, Zhe Shen, Han Fu, Wei Wang, Arvind Kannan, Doron Kukliansky, Sergey Yaroshenko, Svetlana Grant, Umesh Telang, David Wood, Alexandra Chronopoulou, Alexandru Ţifrea, Tao Zhou, Tony, Nguy\~ên, Muge Ersoy, Anima Singh, Meiyan Xie, Emanuel Taropa, Woohyun Han, Eirikur Agustsson, Andrei Sozanschi, Hui Peng, Alex Chen, Yoel Drori, Efren Robles, Yang Gao, Xerxes Dotiwalla, Ying Chen, Anudhyan Boral, Alexei Bendebury, John Nham, Chris Tar, Luis Castro, Jiepu Jiang, Canoee Liu, Felix Halim, Jinoo Baek, Andy Wan, Jeremiah Liu, Yuan Cao, Shengyang Dai, Trilok Acharya, Ruoxi Sun, Fuzhao Xue, Saket Joshi, Morgane Lustman, Yongqin Xian, Rishabh Joshi, Deep Karkhanis, Nora Kassner, Jamie Hall, Xiangzhuo Ding, Gan Song, Gang Li, Chen Zhu, Yana Kulizhskaya, Bin Ni, Alexey Vlaskin, Solomon Demmessie, Lucio Dery, Salah Zaiem, Yanping Huang, Cindy Fan, Felix Gimeno, Ananth Balashankar, Koji Kojima, Hagai Taitelbaum, Maya Meng, Dero Gharibian, Sahil Singla, Wei Chen, Ambrose Slone, Guanjie Chen, Sujee Rajayogam, Max Schumacher, Suyog Kotecha, Rory Blevins, Qifei Wang, Mor Hazan Taege, Alex Morris, Xin Liu, Fayaz Jamil, Richard Zhang, Pratik Joshi, Ben Ingram, Tyler Liechty, Ahmed Eleryan, Scott Baird, Alex Grills, Gagan Bansal, Shan Han, Kiran Yalasangi, Shawn Xu, Majd Al Merey, Isabel Gao, Felix Weissenberger, Igor Karpov, Robert Riachi, Ankit Anand, Gautam Prasad, Kay Lamerigts, Reid Hayes, Jamie Rogers, Mandy Guo, Ashish Shenoy, Qiong, Hu, Kyle He, Yuchen Liu, Polina Zablotskaia, Sagar Gubbi, Yifan Chang, Jay Pavagadhi, Kristian Kjems, Archita Vadali, Diego Machado, Yeqing Li, Renshen Wang, Dipankar Ghosh, Aahil Mehta, Dana Alon, George Polovets, Alessio Tonioni, Nate Kushman, Joel D'sa, Lin Zhuo, Allen Wu, Rohin Shah, John Youssef, Jiayu Ye, Justin Snyder, Karel Lenc, Senaka Buthpitiya, Matthew Tung, Jichuan Chang, Tao Chen, David Saxton, Jenny Lee, Lydia Lihui Zhang, James Qin, Prabakar Radhakrishnan, Maxwell Chen, Piotr Ambroszczyk, Metin Toksoz-Exley, Yan Zhong, Nitzan Katz, Brendan O'Donoghue, Tamara von Glehn, Adi Gerzi Rosenthal, Aga Świetlik, Xiaokai Zhao, Nick Fernando, Jinliang Wei, Jieru Mei, Sergei Vassilvitskii, Diego Cedillo, Pranjal Awasthi, Hui Zheng, Koray Kavukcuoglu, Itay Laish, Joseph Pagadora, Marc Brockschmidt, Christopher A. Choquette-Choo, Arunkumar Byravan, Yifeng Lu, Xu Chen, Mia Chen, Kenton Lee, Rama Pasumarthi, Sijal Bhatnagar, Aditya Shah, Qiyin Wu, Zhuoyuan Chen, Zack Nado, Bartek Perz, Zixuan Jiang, David Kao, Ganesh Mallya, Nino Vieillard, Lantao Mei, Sertan Girgin, Mandy Jordan, Yeongil Ko, Alekh Agarwal, Yaxin Liu, Yasemin Altun, Raoul de Liedekerke, Anastasios Kementsietsidis, Daiyi Peng, Dangyi Liu, Utku Evci, Peter Humphreys, Austin Tarango, Xiang Deng, Yoad Lewenberg, Kevin Aydin, Chengda Wu, Bhavishya Mittal, Tsendsuren Munkhdalai, Kleopatra Chatziprimou, Rodrigo Benenson, Uri First, Xiao Ma, Jinning Li, Armand Joulin, Hamish Tomlinson, Tingnan Zhang, Milad Nasr, Zhi Hong, Michaël Sander, Lisa Anne Hendricks, Anuj Sharma, Andrew Bolt, Eszter Vértes, Jiri Simsa, Tomer Levinboim, Olcan Sercinoglu, Divyansh Shukla, Austin Wu, Craig Swanson, Danny Vainstein, Fan Bu, Bo Wang, Ryan Julian, Charles Yoon, Sergei Lebedev, Antonious Girgis, Bernd Bandemer, David Du, Todd Wang, Xi Chen, Ying Xiao, Peggy Lu, Natalie Ha, Vlad Ionescu, Simon Rowe, Josip Matak, Federico Lebron, Andreas Steiner, Lalit Jain, Manaal Faruqui, Nicolas Lacasse, Georgie Evans, Neesha Subramaniam, Dean Reich, Giulia Vezzani, Aditya Pandey, Joe Stanton, Tianhao Zhou, Liam McCafferty, Henry Griffiths, Verena Rieser, Soheil Hassas Yeganeh, Eleftheria Briakou, Lu Huang, Zichuan Wei, Liangchen Luo, Erik Jue, Gabby Wang, Victor Cotruta, Myriam Khan, Jongbin Park, Qiuchen Guo, Peiran Li, Rong Rong, Diego Antognini, Anastasia Petrushkina, Chetan Tekur, Eli Collins, Parul Bhatia, Chester Kwak, Wenhu Chen, Arvind Neelakantan, Immanuel Odisho, Sheng Peng, Vincent Nallatamby, Vaibhav Tulsyan, Fabian Pedregosa, Peng Xu, Raymond Lin, Yulong Wang, Emma Wang, Sholto Douglas, Reut Tsarfaty, Elena Gribovskaya, Renga Aravamudhan, Manu Agarwal, Mara Finkelstein, Qiao Zhang, Elizabeth Cole, Phil Crone, Sarmishta Velury, Anil Das, Chris Sauer, Luyao Xu, Danfeng Qin, Chenjie Gu, Dror Marcus, CJ Zheng, Wouter Van Gansbeke, Sobhan Miryoosefi, Haitian Sun, YaGuang Li, Charlie Chen, Jae Yoo, Pavel Dubov, Alex Tomala, Adams Yu, Paweł Wesołowski, Alok Gunjan, Eddie Cao, Jiaming Luo, Nikhil Sethi, Arkadiusz Socala, Laura Graesser, Tomas Kocisky, Arturo BC, Minmin Chen, Edward Lee, Sophie Wang, Weize Kong, Qiantong Xu, Nilesh Tripuraneni, Yiming Li, Xinxin Yu, Allen Porter, Paul Voigtlaender, Biao Zhang, Arpi Vezer, Sarah York, Qing Wei, Geoffrey Cideron, Mark Kurzeja, Seungyeon Kim, Benny Li, Angéline Pouget, Hyo Lee, Kaspar Daugaard, Yang Li, Dave Uthus, Aditya Siddhant, Paul Cavallaro, Sriram Ganapathy, Maulik Shah, Rolf Jagerman, Jeff Stanway, Piermaria Mendolicchio, Li Xiao, Kayi Lee, Tara Thompson, Shubham Milind Phal, Jason Chase, Sun Jae Lee, Adrian N Reyes, Disha Shrivastava, Zhen Qin, Roykrong Sukkerd, Seth Odoom, Lior Madmoni, John Aslanides, Jonathan Herzig, Elena Pochernina, Sheng Zhang, Parker Barnes, Daisuke Ikeda, Qiujia Li, Shuo-yiin Chang, Shakir Mohamed, Jim Sproch, Richard Powell, Bidisha Samanta, Domagoj Ćevid, Anton Kovsharov, Shrestha Basu Mallick, Srinivas Tadepalli, Anne Zheng, Kareem Ayoub, Andreas Noever, Christian Reisswig, Zhuo Xu, Junhyuk Oh, Martin Matysiak, Tim Blyth, Shereen Ashraf, Julien Amelot, Boone Severson, Michele Bevilacqua, Motoki Sano, Ethan Dyer, Ofir Roval, Anu Sinha, Yin Zhong, Sagi Perel, Tea Sabolić, Johannes Mauerer, Willi Gierke, Mauro Verzetti, Rodrigo Cabrera, Alvin Abdagic, Steven Hemingray, Austin Stone, Jong Lee, Farooq Ahmad, Karthik Raman, Lior Shani, Jonathan Lai, Orhan Firat, Nathan Waters, Eric Ge, Mo Shomrat, Himanshu Gupta, Rajeev Aggarwal, Tom Hudson, Bill Jia, Simon Baumgartner, Palak Jain, Joe Kovac, Junehyuk Jung, Ante Žužul, Will Truong, Morteza Zadimoghaddam, Songyou Peng, Marco Liang, Rachel Sterneck, Balaji Lakshminarayanan, Machel Reid, Oliver Woodman, Tong Zhou, Jianling Wang, Vincent Coriou, Arjun Narayanan, Jay Hoover, Yenai Ma, Apoorv Jindal, Clayton Sanford, Doug Reid, Swaroop Ramaswamy, Alex Kurakin, Roland Zimmermann, Yana Lunts, Dragos Dena, Zalán Borsos, Vered Cohen, Shujian Zhang, Will Grathwohl, Robert Dadashi, Morgan Redshaw, Joshua Kessinger, Julian Odell, Silvano Bonacina, Zihang Dai, Grace Chen, Ayush Dubey, Pablo Sprechmann, Mantas Pajarskas, Wenxuan Zhou, Niharika Ahuja, Tara Thomas, Martin Nikoltchev, Matija Kecman, Bharath Mankalale, Andrey Ryabtsev, Jennifer She, Christian Walder, Jiaming Shen, Lu Li, Carolina Parada, Sheena Panthaplackel, Okwan Kwon, Matt Lawlor, Utsav Prabhu, Yannick Schroecker, Marc'aurelio Ranzato, Pete Blois, Iurii Kemaev, Ting Yu, Dmitry Lepikhin, Hao Xiong, Sahand Sharifzadeh, Oleaser Johnson, Jeremiah Willcock, Rui Yao, Greg Farquhar, Sujoy Basu, Hidetoshi Shimokawa, Nina Anderson, Haiguang Li, Khiem Pham, Yizhong Liang, Sebastian Borgeaud, Alexandre Moufarek, Hideto Kazawa, Blair Kutzman, Marcin Sieniek, Sara Smoot, Ruth Wang, Natalie Axelsson, Nova Fallen, Prasha Sundaram, Yuexiang Zhai, Varun Godbole, Petros Maniatis, Alek Wang, Ilia Shumailov, Santhosh Thangaraj, Remi Crocker, Nikita Gupta, Gang Wu, Phil Chen, Gellért Weisz, Celine Smith, Mojtaba Seyedhosseini, Boya Fang, Xiyang Luo, Roey Yogev, Zeynep Cankara, Andrew Hard, Helen Ran, Rahul Sukthankar, George Necula, Gaël Liu, Honglong Cai, Praseem Banzal, Daniel Keysers, Sanjay Ghemawat, Connie Tao, Emma Dunleavy, Aditi Chaudhary, Wei Li, Maciej Mikuła, Chen-Yu Lee, Tiziana Refice, Krishna Somandepalli, Alexandre Fréchette, Dan Bahir, John Karro, Keith Rush, Sarah Perrin, Bill Rosgen, Xiaomeng Yang, Clara Huiyi Hu, Mahmoud Alnahlawi, Justin Mao-Jones, Roopal Garg, Hoang Nguyen, Bat-Orgil Batsaikhan, Iñaki Iturrate, Anselm Levskaya, Avi Singh, Ashyana Kachra, Tony Lu, Denis Petek, Zheng Xu, Mark Graham, Lukas Zilka, Yael Karov, Marija Kostelac, Fangyu Liu, Yaohui Guo, Weiyue Wang, Bernd Bohnet, Emily Pitler, Tony Bruguier, Keisuke Kinoshita, Chrysovalantis Anastasiou, Nilpa Jha, Ting Liu, Jerome Connor, Phil Wallis, Philip Pham, Eric Bailey, Shixin Li, Heng-Tze Cheng, Sally Ma, Haiqiong Li, Akanksha Maurya, Kate Olszewska, Manfred Warmuth, Christy Koh, Dominik Paulus, Siddhartha Reddy Jonnalagadda, Enrique Piqueras, Ali Elqursh, Geoff Brown, Hadar Shemtov, Loren Maggiore, Fei Xia, Ryan Foley, Beka Westberg, George van den Driessche, Livio Baldini Soares, Arjun Kar, Michael Quinn, Siqi Zuo, Jialin Wu, Kyle Kastner, Anna Bortsova, Aijun Bai, Ales Mikhalap, Luowei Zhou, Jennifer Brennan, Vinay Ramasesh, Honglei Zhuang, John Maggs, Johan Schalkwyk, Yuntao Xu, Hui Huang, Andrew Howard, Sasha Brown, Linting Xue, Gloria Shen, Brian Albert, Neha Jha, Daniel Zheng, Varvara Krayvanova, Spurthi Amba Hombaiah, Olivier Lacombe, Gautam Vasudevan, Dan Graur, Tian Xie, Meet Gandhi, Bangju Wang, Dustin Zelle, Harman Singh, Dahun Kim, Sébastien Cevey, Victor Ungureanu, Natasha Noy, Fei Liu, Annie Xie, Fangxiaoyu Feng, Katerina Tsihlas, Daniel Formoso, Neera Vats, Quentin Wellens, Yinan Wang, Niket Kumar Bhumihar, Samrat Ghosh, Matt Hoffman, Tom Lieber, Oran Lang, Kush Bhatia, Tom Paine, Aroonalok Pyne, Ronny Votel, Madeleine Clare Elish, Benoit Schillings, Alex Panagopoulos, Haichuan Yang, Adam Raveret, Zohar Yahav, Shuang Liu, Dalia El Badawy, Nishant Agrawal, Mohammed Badawi, Mahdi Mirzazadeh, Carla Bromberg, Fan Ye, Chang Liu, Tatiana Sholokhova, George-Cristian Muraru, Gargi Balasubramaniam, Jonathan Malmaud, Alen Carin, Danilo Martins, Irina Jurenka, Pankil Botadra, Dave Lacey, Richa Singh, Mariano Schain, Dan Zheng, Isabelle Guyon, Victor Lavrenko, Seungji Lee, Xiang Zhou, Demis Hassabis, Jeshwanth Challagundla, Derek Cheng, Nikhil Mehta, Matthew Mauger, Michela Paganini, Pushkar Mishra, Kate Lee, Zhang Li, Lexi Baugher, Ondrej Skopek, Max Chang, Amir Zait, Gaurav Menghani, Lizzetth Bellot, Guangxing Han, Jean-Michel Sarr, Sharat Chikkerur, Himanshu Sahni, Rohan Anil, Arun Narayanan, Chandu Thekkath, Daniele Pighin, Hana Strejček, Marko Velic, Fred Bertsch, Manuel Tragut, Keran Rong, Alicia Parrish, Kai Bailey, Jiho Park, Isabela Albuquerque, Abhishek Bapna, Rajesh Venkataraman, Alec Kosik, Johannes Griesser, Zhiwei Deng, Alek Andreev, Qingyun Dou, Kevin Hui, Fanny Wei, Xiaobin Yu, Lei Shu, Avia Aharon, David Barker, Badih Ghazi, Sebastian Flennerhag, Chris Breaux, Yuchuan Liu, Matthew Bilotti, Josh Woodward, Uri Alon, Stephanie Winkler, Tzu-Kuo Huang, Kostas Andriopoulos, João Gabriel Oliveira, Penporn Koanantakool, Berkin Akin, Michael Wunder, Cicero Nogueira dos Santos, Mohammad Hossein Bateni, Lin Yang, Dan Horgan, Beer Changpinyo, Keyvan Amiri, Min Ma, Dayeong Lee, Lihao Liang, Anirudh Baddepudi, Tejasi Latkar, Raia Hadsell, Jun Xu, Hairong Mu, Michael Han, Aedan Pope, Snchit Grover, Frank Kim, Ankit Bhagatwala, Guan Sun, Yamini Bansal, Amir Globerson, Alireza Nazari, Samira Daruki, Hagen Soltau, Jane Labanowski, Laurent El Shafey, Matt Harvey, Yanif Ahmad, Elan Rosenfeld, William Kong, Etienne Pot, Yi-Xuan Tan, Aurora Wei, Victoria Langston, Marcel Prasetya, Petar Veličković, Richard Killam, Robin Strudel, Darren Ni, Zhenhai Zhu, Aaron Archer, Kavya Kopparapu, Lynn Nguyen, Emilio Parisotto, Hussain Masoom, Sravanti Addepalli, Jordan Grimstad, Hexiang Hu, Joss Moore, Avinatan Hassidim, Le Hou, Mukund Raghavachari, Jared Lichtarge, Adam R. Brown, Hilal Dib, Natalia Ponomareva, Justin Fu, Yujing Zhang, Altaf Rahman, Joana Iljazi, Edouard Leurent, Gabriel Dulac-Arnold, Cosmo Du, Chulayuth Asawaroengchai, Larry Jin, Ela Gruzewska, Ziwei Ji, Benigno Uria, Daniel De Freitas, Paul Barham, Lauren Beltrone, Víctor Campos, Jun Yan, Neel Kovelamudi, Arthur Nguyen, Elinor Davies, Zhichun Wu, Zoltan Egyed, Kristina Toutanova, Nithya Attaluri, Hongliang Fei, Peter Stys, Siddhartha Brahma, Martin Izzard, Siva Velusamy, Scott Lundberg, Vincent Zhuang, Kevin Sequeira, Adam Santoro, Ehsan Amid, Ophir Aharoni, Shuai Ye, Mukund Sundararajan, Lijun Yu, Yu-Cheng Ling, Stephen Spencer, Hugo Song, Josip Djolonga, Christo Kirov, Sonal Gupta, Alessandro Bissacco, Clemens Meyer, Mukul Bhutani, Andrew Dai, Weiyi Wang, Siqi Liu, Ashwin Sreevatsa, Qijun Tan, Maria Wang, Lucy Kim, Yicheng Wang, Alex Irpan, Yang Xiao, Stanislav Fort, Yifan He, Alex Gurney, Bryan Gale, Yue Ma, Monica Roy, Viorica Patraucean, Taylan Bilal, Golnaz Ghiasi, Anahita Hosseini, Melvin Johnson, Zhuowan Li, Yi Tay, Benjamin Beyret, Katie Millican, Josef Broder, Mayank Lunayach, Danny Swisher, Eugen Vušak, David Parkinson, MH Tessler, Adi Mayrav Gilady, Richard Song, Allan Dafoe, Yves Raimond, Masa Yamaguchi, Itay Karo, Elizabeth Nielsen, Kevin Kilgour, Mike Dusenberry, Rajiv Mathews, Jiho Choi, Siyuan Qiao, Harsh Mehta, Sahitya Potluri, Chris Knutsen, Jialu Liu, Tat Tan, Kuntal Sengupta, Keerthana Gopalakrishnan, Abodunrinwa Toki, Mencher Chiang, Mike Burrows, Grace Vesom, Zafarali Ahmed, Ilia Labzovsky, Siddharth Vashishtha, Preeti Singh, Ankur Sharma, Ada Ma, Jinyu Xie, Pranav Talluri, Hannah Forbes-Pollard, Aarush Selvan, Joel Wee, Loic Matthey, Tom Funkhouser, Parthasarathy Gopavarapu, Lev Proleev, Cheng Li, Matt Thomas, Kashyap Kolipaka, Zhipeng Jia, Ashwin Kakarla, Srinivas Sunkara, Joan Puigcerver, Suraj Satishkumar Sheth, Emily Graves, Chen Wang, Sadh MNM Khan, Kai Kang, Shyamal Buch, Fred Zhang, Omkar Savant, David Soergel, Kevin Lee, Linda Friso, Xuanyi Dong, Rahul Arya, Shreyas Chandrakaladharan, Connor Schenck, Greg Billock, Tejas Iyer, Anton Bakalov, Leslie Baker, Alex Ruiz, Angad Chandorkar, Trieu Trinh, Matt Miecnikowski, Yanqi Zhou, Yangsibo Huang, Jiazhong Nie, Ali Shah, Ashish Thapliyal, Sam Haves, Lun Wang, Uri Shaham, Patrick Morris-Suzuki, Soroush Radpour, Leonard Berrada, Thomas Strohmann, Chaochao Yan, Jingwei Shen, Sonam Goenka, Tris Warkentin, Petar Dević, Dan Belov, Albert Webson, Madhavi Yenugula, Puranjay Datta, Jerry Chang, Nimesh Ghelani, Aviral Kumar, Vincent Perot, Jessica Lo, Yang Song, Herman Schmit, Jianmin Chen, Vasilisa Bashlovkina, Xiaoyue Pan, Diana Mincu, Paul Roit, Isabel Edkins, Andy Davis, Yujia Li, Ben Horn, Xinjian Li, Pradeep Kumar S, Eric Doi, Wanzheng Zhu, Sri Gayatri Sundara Padmanabhan, Siddharth Verma, Jasmine Liu, Heng Chen, Mihajlo Velimirović, Malcolm Reynolds, Priyanka Agrawal, Nick Sukhanov, Abhinit Modi, Siddharth Goyal, John Palowitch, Nima Khajehnouri, Wing Lowe, David Klinghoffer, Sharon Silver, Vinh Tran, Candice Schumann, Francesco Piccinno, Xi Liu, Mario Lučić, Xiaochen Yang, Sandeep Kumar, Ajay Kannan, Ragha Kotikalapudi, Mudit Bansal, Fabian Fuchs, Mohammad Javad Hosseini, Abdelrahman Abdelhamed, Dawn Bloxwich, Tianhe Yu, Ruoxin Sang, Gregory Thornton, Karan Gill, Yuchi Liu, Virat Shejwalkar, Jason Lin, Zhipeng Yan, Kehang Han, Thomas Buschmann, Michael Pliskin, Zhi Xing, Susheel Tatineni, Junlin Zhang, Sissie Hsiao, Gavin Buttimore, Marcus Wu, Zefei Li, Geza Kovacs, Legg Yeung, Tao Huang, Aaron Cohen, Bethanie Brownfield, Averi Nowak, Mikel Rodriguez, Tianze Shi, Hado van Hasselt, Kevin Cen, Deepanway Ghoshal, Kushal Majmundar, Weiren Yu, Warren, Chen, Danila Sinopalnikov, Hao Zhang, Vlado Galić, Di Lu, Zeyu Zheng, Maggie Song, Gary Wang, Gui Citovsky, Swapnil Gawde, Isaac Galatzer-Levy, David Silver, Ivana Balazevic, Dipanjan Das, Kingshuk Majumder, Yale Cong, Praneet Dutta, Dustin Tran, Hui Wan, Junwei Yuan, Daniel Eppens, Alanna Walton, Been Kim, Harry Ragan, James Cobon-Kerr, Lu Liu, Weijun Wang, Bryce Petrini, Jack Rae, Rakesh Shivanna, Yan Xiong, Chace Lee, Pauline Coquinot, Yiming Gu, Lisa Patel, Blake Hechtman, Aviel Boag, Orion Jankowski, Alex Wertheim, Alex Lee, Paul Covington, Hila Noga, Sam Sobell, Shanthal Vasanth, William Bono, Chirag Nagpal, Wei Fan, Xavier Garcia, Kedar Soparkar, Aybuke Turker, Nathan Howard, Sachit Menon, Yuankai Chen, Vikas Verma, Vladimir Pchelin, Harish Rajamani, Valentin Dalibard, Ana Ramalho, Yang Guo, Kartikeya Badola, Seojin Bang, Nathalie Rauschmayr, Julia Proskurnia, Sudeep Dasari, Xinyun Chen, Mikhail Sushkov, Anja Hauth, Pauline Sho, Abhinav Singh, Bilva Chandra, Allie Culp, Max Dylla, Olivier Bachem, James Besley, Heri Zhao, Timothy Lillicrap, Wei Wei, Wael Al Jishi, Ning Niu, Alban Rrustemi, Raphaël Lopez Kaufman, Ryan Poplin, Jewel Zhao, Minh Truong, Shikhar Bharadwaj, Ester Hlavnova, Eli Stickgold, Cordelia Schmid, Georgi Stephanov, Zhaoqi Leng, Frederick Liu, Léonard Hussenot, Shenil Dodhia, Juliana Vicente Franco, Lesley Katzen, Abhanshu Sharma, Sarah Cogan, Zuguang Yang, Aniket Ray, Sergi Caelles, Shen Yan, Ravin Kumar, Daniel Gillick, Renee Wong, Joshua Ainslie, Jonathan Hoech, Séb Arnold, Dan Abolafia, Anca Dragan, Ben Hora, Grace Hu, Alexey Guseynov, Yang Lu, Chas Leichner, Jinmeng Rao, Abhimanyu Goyal, Nagabhushan Baddi, Daniel Hernandez Diaz, Tim McConnell, Max Bain, Jake Abernethy, Qiqi Yan, Rylan Schaeffer, Paul Vicol, Will Thompson, Montse Gonzalez Arenas, Mathias Bellaiche, Pablo Barrio, Stefan Zinke, Riccardo Patana, Pulkit Mehta, JK Kearns, Avraham Ruderman, Scott Pollom, David D'Ambrosio, Cath Hope, Yang Yu, Andrea Gesmundo, Kuang-Huei Lee, Aviv Rosenberg, Yiqian Zhou, Yaoyiran Li, Drew Garmon, Yonghui Wu, Safeen Huda, Gil Fidel, Martin Baeuml, Jian Li, Phoebe Kirk, Rhys May, Tao Tu, Sara Mc Carthy, Toshiyuki Fukuzawa, Miranda Aperghis, Chih-Kuan Yeh, Toshihiro Yoshino, Bo Li, Austin Myers, Kaisheng Yao, Ben Limonchik, Changwan Ryu, Rohun Saxena, Alex Goldin, Ruizhe Zhao, Rocky Rhodes, Tao Zhu, Divya Tyam, Heidi Howard, Nathan Byrd, Hongxu Ma, Yan Wu, Ryan Mullins, Qingze Wang, Aida Amini, Sebastien Baur, Yiran Mao, Subhashini Venugopalan, Will Song, Wen Ding, Paul Collins, Sashank Reddi, Megan Shum, Andrei Rusu, Luisa Zintgraf, Kelvin Chan, Sheela Goenka, Mathieu Blondel, Michael Collins, Renke Pan, Marissa Giustina, Nikolai Chinaev, Christian Schuler, Ce Zheng, Jonas Valfridsson, Alyssa Loo, Alex Yakubovich, Jamie Smith, Tao Jiang, Rich Munoz, Gabriel Barcik, Rishabh Bansal, Mingyao Yang, Yilun Du, Pablo Duque, Mary Phuong, Alexandra Belias, Kunal Lad, Zeyu Liu, Tal Schuster, Karthik Duddu, Jieru Hu, Paige Kunkle, Matthew Watson, Jackson Tolins, Josh Smith, Denis Teplyashin, Garrett Bingham, Marvin Ritter, Marco Andreetto, Divya Pitta, Mohak Patel, Shashank Viswanadha, Trevor Strohman, Catalin Ionescu, Jincheng Luo, Yogesh Kalley, Jeremy Wiesner, Dan Deutsch, Derek Lockhart, Peter Choy, Rumen Dangovski, Chawin Sitawarin, Cat Graves, Tanya Lando, Joost van Amersfoort, Ndidi Elue, Zhouyuan Huo, Pooya Moradi, Jean Tarbouriech, Henryk Michalewski, Wenting Ye, Eunyoung Kim, Alex Druinsky, Florent Altché, Xinyi Chen, Artur Dwornik, Da-Cheng Juan, Rivka Moroshko, Horia Toma, Jarrod Kahn, Hai Qian, Maximilian Sieb, Irene Cai, Roman Goldenberg, Praneeth Netrapalli, Sindhu Raghuram, Yuan Gong, Lijie Fan, Evan Palmer, Yossi Matias, Valentin Gabeur, Shreya Pathak, Tom Ouyang, Don Metzler, Geoff Bacon, Srinivasan Venkatachary, Sridhar Thiagarajan, Alex Cullum, Eran Ofek, Vytenis Sakenas, Mohamed Hammad, Cesar Magalhaes, Mayank Daswani, Oscar Chang, Ashok Popat, Ruichao Li, Komal Jalan, Yanhan Hou, Josh Lipschultz, Antoine He, Wenhao Jia, Pier Giuseppe Sessa, Prateek Kolhar, William Wong, Sumeet Singh, Lukas Haas, Jay Whang, Hanna Klimczak-Plucińska, Georges Rotival, Grace Chung, Yiqing Hua, Anfal Siddiqui, Nicolas Serrano, Dongkai Chen, Billy Porter, Libin Bai, Keshav Shivam, Sho Arora, Partha Talukdar, Tom Cobley, Sangnie Bhardwaj, Evgeny Gladchenko, Simon Green, Kelvin Guu, Felix Fischer, Xiao Wu, Eric Wang, Achintya Singhal, Tatiana Matejovicova, James Martens, Hongji Li, Roma Patel, Elizabeth Kemp, Jiaqi Pan, Lily Wang, Blake JianHang Chen, Jean-Baptiste Alayrac, Navneet Potti, Erika Gemzer, Eugene Ie, Kay McKinney, Takaaki Saeki, Edward Chou, Pascal Lamblin, SQ Mah, Zach Fisher, Martin Chadwick, Jon Stritar, Obaid Sarvana, Andrew Hogue, Artem Shtefan, Hadi Hashemi, Yang Xu, Jindong Gu, Sharad Vikram, Chung-Ching Chang, Sabela Ramos, Logan Kilpatrick, Weijuan Xi, Jenny Brennan, Yinghao Sun, Abhishek Jindal, Ionel Gog, Dawn Chen, Felix Wu, Jason Lee, Sudhindra Kopalle, Srinadh Bhojanapalli, Oriol Vinyals, Natan Potikha, Burcu Karagol Ayan, Yuan Yuan, Michael Riley, Piotr Stanczyk, Sergey Kishchenko, Bing Wang, Dan Garrette, Antoine Yang, Vlad Feinberg, CJ Carey, Javad Azizi, Viral Shah, Erica Moreira, Chongyang Shi, Josh Feldman, Elizabeth Salesky, Thomas Lampe, Aneesh Pappu, Duhyeon Kim, Jonas Adler, Avi Caciularu, Brian Walker, Yunhan Xu, Yochai Blau, Dylan Scandinaro, Terry Huang, Sam El-Husseini, Abhishek Sinha, Lijie Ren, Taylor Tobin, Patrik Sundberg, Tim Sohn, Vikas Yadav, Mimi Ly, Emily Xue, Jing Xiong, Afzal Shama Soudagar, Sneha Mondal, Nikhil Khadke, Qingchun Ren, Ben Vargas, Stan Bileschi, Sarah Chakera, Cindy Wang, Boyu Wang, Yoni Halpern, Joe Jiang, Vikas Sindhwani, Petre Petrov, Pranavaraj Ponnuramu, Sanket Vaibhav Mehta, Yu Watanabe, Betty Chan, Matheus Wisniewski, Trang Pham, Jingwei Zhang, Conglong Li, Dario de Cesare, Art Khurshudov, Alex Vasiloff, Melissa Tan, Zoe Ashwood, Bobak Shahriari, Maryam Majzoubi, Garrett Tanzer, Olga Kozlova, Robin Alazard, James Lee-Thorp, Nguyet Minh Phu, Isaac Tian, Junwhan Ahn, Andy Crawford, Lauren Lax, Yuan Shangguan, Iftekhar Naim, David Ross, Oleksandr Ferludin, Tongfei Guo, Andrea Banino, Hubert Soyer, Xiaoen Ju, Dominika Rogozińska, Ishaan Malhi, Marcella Valentine, Daniel Balle, Apoorv Kulshreshtha, Maciej Kula, Yiwen Song, Sophia Austin, John Schultz, Roy Hirsch, Arthur Douillard, Apoorv Reddy, Michael Fink, Summer Yue, Khyatti Gupta, Adam Zhang, Norman Rink, Daniel McDuff, Lei Meng, András György, Yasaman Razeghi, Ricky Liang, Kazuki Osawa, Aviel Atias, Matan Eyal, Tyrone Hill, Nikolai Grigorev, Zhengdong Wang, Nitish Kulkarni, Rachel Soh, Ivan Lobov, Zachary Charles, Sid Lall, Kazuma Hashimoto, Ido Kessler, Victor Gomes, Zelda Mariet, Danny Driess, Alessandro Agostini, Canfer Akbulut, Jingcao Hu, Marissa Ikonomidis, Emily Caveness, Kartik Audhkhasi, Saurabh Agrawal, Ioana Bica, Evan Senter, Jayaram Mudigonda, Kelly Chen, Jingchen Ye, Xuanhui Wang, James Svensson, Philipp Fränken, Josh Newlan, Li Lao, Eva Schnider, Sami Alabed, Joseph Kready, Jesse Emond, Afief Halumi, Tim Zaman, Chengxi Ye, Naina Raisinghani, Vilobh Meshram, Bo Chang, Ankit Singh Rawat, Axel Stjerngren, Sergey Levi, Rui Wang, Xiangzhu Long, Mitchelle Rasquinha, Steven Hand, Aditi Mavalankar, Lauren Agubuzu, Sudeshna Roy, Junquan Chen, Jarek Wilkiewicz, Hao Zhou, Michal Jastrzebski, Qiong Hu, Agustin Dal Lago, Ramya Sree Boppana, Wei-Jen Ko, Jennifer Prendki, Yao Su, Zhi Li, Eliza Rutherford, Girish Ramchandra Rao, Ramona Comanescu, Adrià Puigdomènech, Qihang Chen, Dessie Petrova, Christine Chan, Vedrana Milutinovic, Felipe Tiengo Ferreira, Chin-Yi Cheng, Ming Zhang, Tapomay Dey, Sherry Yang, Ramesh Sampath, Quoc Le, Howard Zhou, Chu-Cheng Lin, Hoi Lam, Christine Kaeser-Chen, Kai Hui, Dean Hirsch, Tom Eccles, Basil Mustafa, Shruti Rijhwani, Morgane Rivière, Yuanzhong Xu, Junjie Wang, Xinyang Geng, Xiance Si, Arjun Khare, Cheolmin Kim, Vahab Mirrokni, Kamyu Lee, Khuslen Baatarsukh, Nathaniel Braun, Lisa Wang, Pallavi LV, Richard Tanburn, Yuvein, Zhu, Fangda Li, Setareh Ariafar, Dan Goldberg, Ken Burke, Daniil Mirylenka, Meiqi Guo, Olaf Ronneberger, Hadas Natalie Vogel, Liqun Cheng, Nishita Shetty, Johnson Jia, Thomas Jimma, Corey Fry, Ted Xiao, Martin Sundermeyer, Ryan Burnell, Yannis Assael, Mario Pinto, JD Chen, Rohit Sathyanarayana, Donghyun Cho, Jing Lu, Rishabh Agarwal, Sugato Basu, Lucas Gonzalez, Dhruv Shah, Meng Wei, Dre Mahaarachchi, Rohan Agrawal, Tero Rissa, Yani Donchev, Ramiro Leal-Cavazos, Adrian Hutter, Markus Mircea, Alon Jacovi, Faruk Ahmed, Jiageng Zhang, Shuguang Hu, Bo-Juen Chen, Jonni Kanerva, Guillaume Desjardins, Andrew Lee, Nikos Parotsidis, Asier Mujika, Tobias Weyand, Jasper Snoek, Jo Chick, Kai Chen, Paul Chang, Ethan Mahintorabi, Zi Wang, Tolly Powell, Orgad Keller, Abhirut Gupta, Claire Sha, Kanav Garg, Nicolas Heess, Ágoston Weisz, Cassidy Hardin, Bartek Wydrowski, Ben Coleman, Karina Zainullina, Pankaj Joshi, Alessandro Epasto, Terry Spitz, Binbin Xiong, Kai Zhao, Arseniy Klimovskiy, Ivy Zheng, Johan Ferret, Itay Yona, Waleed Khawaja, Jean-Baptiste Lespiau, Maxim Krikun, Siamak Shakeri, Timothee Cour, Bonnie Li, Igor Krivokon, Dan Suh, Alex Hofer, Jad Al Abdallah, Nikita Putikhin, Oscar Akerlund, Silvio Lattanzi, Anurag Kumar, Shane Settle, Himanshu Srivastava, Folawiyo Campbell-Ajala, Edouard Rosseel, Mihai Dorin Istin, Nishanth Dikkala, Anand Rao, Nick Young, Kate Lin, Dhruva Bhaswar, Yiming Wang, Jaume Sanchez Elias, Kritika Muralidharan, James Keeling, Dayou Du, Siddharth Gopal, Gregory Dibb, Charles Blundell, Manolis Delakis, Jacky Liang, Marco Tulio Ribeiro, Georgi Karadzhov, Guillermo Garrido, Ankur Bapna, Jiawei Cao, Adam Sadovsky, Pouya Tafti, Arthur Guez, Coline Devin, Yixian Di, Jinwei Xing, Chuqiao, Xu, Hanzhao Lin, Chun-Te Chu, Sameera Ponda, Wesley Helmholz, Fan Yang, Yue Gao, Sara Javanmardi, Wael Farhan, Alex Ramirez, Ricardo Figueira, Khe Chai Sim, Yuval Bahat, Ashwin Vaswani, Liangzhe Yuan, Gufeng Zhang, Leland Rechis, Hanjun Dai, Tayo Oguntebi, Alexandra Cordell, Eugénie Rives, Kaan Tekelioglu, Naveen Kumar, Bing Zhang, Aurick Zhou, Nikolay Savinov, Andrew Leach, Alex Tudor, Sanjay Ganapathy, Yanyan Zheng, Mirko Rossini, Vera Axelrod, Arnaud Autef, Yukun Zhu, Zheng Zheng, Mingda Zhang, Baochen Sun, Jie Ren, Nenad Tomasev, Nithish Kannen, Amer Sinha, Charles Chen, Louis O'Bryan, Alex Pak, Aditya Kusupati, Weel Yang, Deepak Ramachandran, Patrick Griffin, Seokhwan Kim, Philipp Neubeck, Craig Schiff, Tammo Spalink, Mingyang Ling, Arun Nair, Ga-Young Joung, Linda Deng, Avishkar Bhoopchand, Lora Aroyo, Tom Duerig, Jordan Griffith, Gabe Barth-Maron, Jake Ades, Alex Haig, Ankur Taly, Yunting Song, Paul Michel, Dave Orr, Dean Weesner, Corentin Tallec, Carrie Grimes Bostock, Paul Niemczyk, Andy Twigg, Mudit Verma, Rohith Vallu, Henry Wang, Marco Gelmi, Kiranbir Sodhia, Aleksandr Chuklin, Omer Goldman, Jasmine George, Liang Bai, Kelvin Zhang, Petar Sirkovic, Efrat Nehoran, Golan Pundak, Jiaqi Mu, Alice Chen, Alex Greve, Paulo Zacchello, David Amos, Heming Ge, Eric Noland, Colton Bishop, Jeffrey Dudek, Youhei Namiki, Elena Buchatskaya, Jing Li, Dorsa Sadigh, Masha Samsikova, Dan Malkin, Damien Vincent, Robert David, Rob Willoughby, Phoenix Meadowlark, Shawn Gao, Yan Li, Raj Apte, Amit Jhindal, Stein Xudong Lin, Alex Polozov, Zhicheng Wang, Tomas Mery, Anirudh GP, Varun Yerram, Sage Stevens, Tianqi Liu, Noah Fiedel, Charles Sutton, Matthew Johnson, Xiaodan Song, Kate Baumli, Nir Shabat, Muqthar Mohammad, Hao Liu, Marco Selvi, Yichao Zhou, Mehdi Hafezi Manshadi, Chu-ling Ko, Anthony Chen, Michael Bendersky, Jorge Gonzalez Mendez, Nisarg Kothari, Amir Zandieh, Yiling Huang, Daniel Andor, Ellie Pavlick, Idan Brusilovsky, Jitendra Harlalka, Sally Goldman, Andrew Lampinen, Guowang Li, Asahi Ushio, Somit Gupta, Lei Zhang, Chuyuan Kelly Fu, Madhavi Sewak, Timo Denk, Jed Borovik, Brendan Jou, Avital Zipori, Prateek Jain, Junwen Bai, Thang Luong, Jonathan Tompson, Alice Li, Li Liu, George Powell, Jiajun Shen, Alex Feng, Grishma Chole, Da Yu, Yinlam Chow, Tongxin Yin, Eric Malmi, Kefan Xiao, Yash Pande, Shachi Paul, Niccolò Dal Santo, Adil Dostmohamed, Sergio Guadarrama, Aaron Phillips, Thanumalayan Sankaranarayana Pillai, Gal Yona, Amin Ghafouri, Preethi Lahoti, Benjamin Lee, Dhruv Madeka, Eren Sezener, Simon Tokumine, Adrian Collister, Nicola De Cao, Richard Shin, Uday Kalra, Parker Beak, Emily Nottage, Ryo Nakashima, Ivan Jurin, Vikash Sehwag, Meenu Gaba, Junhao Zeng, Kevin R. McKee, Fernando Pereira, Tamar Yakar, Amayika Panda, Arka Dhar, Peilin Zhong, Daniel Sohn, Mark Brand, Lars Lowe Sjoesund, Viral Carpenter, Sharon Lin, Shantanu Thakoor, Marcus Wainwright, Ashwin Chaugule, Pranesh Srinivasan, Muye Zhu, Bernett Orlando, Jack Weber, Ayzaan Wahid, Gilles Baechler, Apurv Suman, Jovana Mitrović, Gabe Taubman, Honglin Yu, Helen King, Josh Dillon, Cathy Yip, Dhriti Varma, Tomas Izo, Levent Bolelli, Borja De Balle Pigem, Julia Di Trapani, Fotis Iliopoulos, Adam Paszke, Nishant Ranka, Joe Zou, Francesco Pongetti, Jed McGiffin, Alex Siegman, Rich Galt, Ross Hemsley, Goran Žužić, Victor Carbune, Tao Li, Myle Ott, Félix de Chaumont Quitry, David Vilar Torres, Yuri Chervonyi, Tomy Tsai, Prem Eruvbetine, Samuel Yang, Matthew Denton, Jake Walker, Slavica Andačić, Idan Heimlich Shtacher, Vittal Premachandran, Harshal Tushar Lehri, Cip Baetu, Damion Yates, Lampros Lamprou, Mariko Iinuma, Ioana Mihailescu, Ben Albrecht, Shachi Dave, Susie Sargsyan, Bryan Perozzi, Lucas Manning, Chiyuan Zhang, Denis Vnukov, Igor Mordatch, Raia Hadsell Wolfgang Macherey, Ryan Kappedal, Jim Stephan, Aditya Tripathi, Klaus Macherey, Jun Qian, Abhishek Bhowmick, Shekoofeh Azizi, Rémi Leblond, Shiva Mohan Reddy Garlapati, Timothy Knight, Matthew Wiethoff, Wei-Chih Hung, Anelia Angelova, Georgios Evangelopoulos, Pawel Janus, Dimitris Paparas, Matthew Rahtz, Ken Caluwaerts, Vivek Sampathkumar, Daniel Jarrett, Shadi Noghabi, Antoine Miech, Chak Yeung, Geoff Clark, Henry Prior, Fei Zheng, Jean Pouget-Abadie, Indro Bhattacharya, Kalpesh Krishna, Will Bishop, Zhe Yuan, Yunxiao Deng, Ashutosh Sathe, Kacper Krasowiak, Ciprian Chelba, Cho-Jui Hsieh, Kiran Vodrahalli, Buhuang Liu, Thomas Köppe, Amr Khalifa, Lubo Litchev, Pichi Charoenpanit, Reed Roberts, Sachin Yadav, Yasumasa Onoe, Desi Ivanov, Megha Mohabey, Vighnesh Birodkar, Nemanja Rakićević, Pierre Sermanet, Vaibhav Mehta, Krishan Subudhi, Travis Choma, Will Ng, Luheng He, Kathie Wang, Tasos Kementsietsidis, Shane Gu, Mansi Gupta, Andrew Nystrom, Mehran Kazemi, Timothy Chung, Nacho Cano, Nikhil Dhawan, Yufei Wang, Jiawei Xia, Trevor Yacovone, Eric Jia, Mingqing Chen, Simeon Ivanov, Ashrith Sheshan, Sid Dalmia, Paweł Stradomski, Pengcheng Yin, Salem Haykal, Congchao Wang, Dennis Duan, Neslihan Bulut, Greg Kochanski, Liam MacDermed, Namrata Godbole, Shitao Weng, Jingjing Chen, Rachana Fellinger, Ramin Mehran, Daniel Suo, Hisham Husain, Tong He, Kaushal Patel, Joshua Howland, Randall Parker, Kelvin Nguyen, Sharath Maddineni, Chris Rawles, Mina Khan, Shlomi Cohen-Ganor, Amol Mandhane, Xinyi Wu, Chenkai Kuang, Iulia Comşa, Ramya Ganeshan, Hanie Sedghi, Adam Bloniarz, Nuo Wang Pierse, Anton Briukhov, Petr Mitrichev, Anita Gergely, Serena Zhan, Allan Zhou, Nikita Saxena, Eva Lu, Josef Dean, Ashish Gupta, Nicolas Perez-Nieves, Renjie Wu, Cory McLean, Wei Liang, Disha Jindal, Anton Tsitsulin, Wenhao Yu, Kaiz Alarakyia, Tom Schaul, Piyush Patil, Peter Sung, Elijah Peake, Hongkun Yu, Feryal Behbahani, JD Co-Reyes, Alan Ansell, Sean Sun, Clara Barbu, Jonathan Lee, Seb Noury, James Allingham, Bilal Piot, Mohit Sharma, Christopher Yew, Ivan Korotkov, Bibo Xu, Demetra Brady, Goran Petrovic, Shibl Mourad, Claire Cui, Aditya Gupta, Parker Schuh, Saarthak Khanna, Anna Goldie, Abhinav Arora, Vadim Zubov, Amy Stuart, Mark Epstein, Yun Zhu, Jianqiao Liu, Yury Stuken, Ziyue Wang, Karolis Misiunas, Dee Guo, Ashleah Gill, Ale Hartman, Zaid Nabulsi, Aurko Roy, Aleksandra Faust, Jason Riesa, Ben Withbroe, Mengchao Wang, Marco Tagliasacchi, Andreea Marzoca, James Noraky, Serge Toropov, Malika Mehrotra, Bahram Raad, Sanja Deur, Steve Xu, Marianne Monteiro, Zhongru Wu, Yi Luan, Sam Ritter, Nick Li, Håvard Garnes, Yanzhang He, Martin Zlocha, Jifan Zhu, Matteo Hessel, Will Wu, Spandana Raj Babbula, Chizu Kawamoto, Yuanzhen Li, Mehadi Hassen, Yan Wang, Brian Wieder, James Freedman, Yin Zhang, Xinyi Bai, Tianli Yu, David Reitter, XiangHai Sheng, Mateo Wirth, Aditya Kini, Dima Damen, Mingcen Gao, Rachel Hornung, Michael Voznesensky, Brian Roark, Adhi Kuncoro, Yuxiang Zhou, Rushin Shah, Anthony Brohan, Kuangyuan Chen, James Wendt, David Rim, Paul Kishan Rubenstein, Jonathan Halcrow, Michelle Liu, Ty Geri, Yunhsuan Sung, Jane Shapiro, Shaan Bijwadia, Chris Duvarney, Christina Sorokin, Paul Natsev, Reeve Ingle, Pramod Gupta, Young Maeng, Ndaba Ndebele, Kexin Zhu, Valentin Anklin, Katherine Lee, Yuan Liu, Yaroslav Akulov, Shaleen Gupta, Guolong Su, Flavien Prost, Tianlin Liu, Vitaly Kovalev, Pol Moreno, Martin Scholz, Sam Redmond, Zongwei Zhou, Alex Castro-Ros, André Susano Pinto, Dia Kharrat, Michal Yarom, Rachel Saputro, Jannis Bulian, Ben Caine, Ji Liu, Abbas Abdolmaleki, Shariq Iqbal, Tautvydas Misiunas, Mikhail Sirotenko, Shefali Garg, Guy Bensky, Huan Gui, Xuezhi Wang, Raphael Koster, Mike Bernico, Da Huang, Romal Thoppilan, Trevor Cohn, Ben Golan, Wenlei Zhou, Andrew Rosenberg, Markus Freitag, Tynan Gangwani, Vincent Tsang, Anand Shukla, Xiaoqi Ren, Minh Giang, Chi Zou, Andre Elisseeff, Charline Le Lan, Dheeru Dua, Shuba Lall, Pranav Shyam, Frankie Garcia, Sarah Nguyen, Michael Guzman, AJ Maschinot, Marcello Maggioni, Ming-Wei Chang, Karol Gregor, Lotte Weerts, Kumaran Venkatesan, Bogdan Damoc, Leon Liu, Jan Wassenberg, Lewis Ho, Becca Roelofs, Majid Hadian, François-Xavier Aubet, Yu Liang, Sami Lachgar, Danny Karmon, Yong Cheng, Amelio Vázquez-Reina, Angie Chen, Zhuyun Dai, Andy Brock, Shubham Agrawal, Chenxi Pang, Peter Garst, Mariella Sanchez-Vargas, Ivor Rendulic, Aditya Ayyar, Andrija Ražnatović, Olivia Ma, Roopali Vij, Neha Sharma, Ashwin Balakrishna, Bingyuan Liu, Ian Mackinnon, Sorin Baltateanu, Petra Poklukar, Gabriel Ibagon, Colin Ji, Hongyang Jiao, Isaac Noble, Wojciech Stokowiec, Zhihao Li, Jeff Dean, David Lindner, Mark Omernick, Kristen Chiafullo, Mason Dimarco, Vitor Rodrigues, Vittorio Selo, Garrett Honke, Xintian, Wu, Wei He, Adam Hillier, Anhad Mohananey, Vihari Piratla, Chang Ye, Chase Malik, Sebastian Riedel, Samuel Albanie, Zi Yang, Kenny Vassigh, Maria Bauza, Sheng Li, Yiqing Tao, Nevan Wichers, Andrii Maksai, Abe Ittycheriah, Ross Mcilroy, Bryan Seybold, Noah Goodman, Romina Datta, Steven M. Hernandez, Tian Shi, Yony Kochinski, Anna Bulanova, Ken Franko, Mikita Sazanovich, Nicholas FitzGerald, Praneeth Kacham, Shubha Srinivas Raghvendra, Vincent Hellendoorn, Alexander Grushetsky, Julian Salazar, Angeliki Lazaridou, Jason Chang, Jan-Thorsten Peter, Sushant Kafle, Yann Dauphin, Abhishek Rao, Filippo Graziano, Izhak Shafran, Yuguo Liao, Tianli Ding, Geng Yan, Grace Chu, Zhao Fu, Vincent Roulet, Gabriel Rasskin, Duncan Williams, Shahar Drath, Alex Mossin, Raphael Hoffmann, Jordi Orbay, Francesco Bertolini, Hila Sheftel, Justin Chiu, Siyang Xue, Yuheng Kuang, Ferjad Naeem, Swaroop Nath, Nana Nti, Phil Culliton, Kashyap Krishnakumar, Michael Isard, Pei Sun, Ayan Chakrabarti, Nathan Clement, Regev Cohen, Arissa Wongpanich, GS Oh, Ashwin Murthy, Hao Zheng, Jessica Hamrick, Oskar Bunyan, Suhas Ganesh, Nitish Gupta, Roy Frostig, John Wieting, Yury Malkov, Pierre Marcenac, Zhixin, Lai, Xiaodan Tang, Mohammad Saleh, Fedir Zubach, Chinmay Kulkarni, Huanjie Zhou, Vicky Zayats, Nan Ding, Anshuman Tripathi, Arijit Pramanik, Patrik Zochbauer, Harish Ganapathy, Vedant Misra, Zach Behrman, Hugo Vallet, Mingyang Zhang, Mukund Sridhar, Ye Jin, Mohammad Babaeizadeh, Siim Põder, Megha Goel, Divya Jain, Tajwar Nasir, Shubham Mittal, Tim Dozat, Diego Ardila, Aliaksei Severyn, Fabio Pardo, Sammy Jerome, Siyang Qin, Louis Rouillard, Amir Yazdanbakhsh, Zizhao Zhang, Shivani Agrawal, Kaushik Shivakumar, Caden Lu, Praveen Kallakuri, Rachita Chhaparia, Kanishka Rao, Charles Kwong, Asya Fadeeva, Shitij Nigam, Yan Virin, Yuan Zhang, Balaji Venkatraman, Beliz Gunel, Marc Wilson, Huiyu Wang, Abhinav Gupta, Xiaowei Xu, Adrien Ali Taïga, Kareem Mohamed, Doug Fritz, Daniel Rodriguez, Zoubin Ghahramani, Harry Askham, Lior Belenki, James Zhao, Rahul Gupta, Krzysztof Jastrzębski, Takahiro Kosakai, Kaan Katircioglu, Jon Schneider, Rina Panigrahy, Konstantinos Bousmalis, Peter Grabowski, Prajit Ramachandran, Chaitra Hegde, Mihaela Rosca, Angelo Scorza Scarpati, Kyriakos Axiotis, Ying Xu, Zach Gleicher, Assaf Hurwitz Michaely, Mandar Sharma, Sanil Jain, Christoph Hirnschall, Tal Marian, Xuhui Jia, Kevin Mather, Kilol Gupta, Linhai Qiu, Nigamaa Nayakanti, Lucian Ionita, Steven Zheng, Lucia Loher, Kurt Shuster, Igor Petrovski, Roshan Sharma, Rahma Chaabouni, Angel Yeh, James An, Arushi Gupta, Steven Schwarcz, Seher Ellis, Sam Conway-Rahman, Javier Snaider, Alex Zhai, James Atwood, Daniel Golovin, Liqian Peng, Te I, Vivian Xia, Salvatore Scellato, Mahan Malihi, Arthur Bražinskas, Vlad-Doru Ion, Younghoon Jun, James Swirhun, Soroosh Mariooryad, Jiao Sun, Steve Chien, Rey Coaguila, Ariel Brand, Yi Gao, Tom Kwiatkowski, Roee Aharoni, Cheng-Chun Lee, Mislav Žanić, Yichi Zhang, Dan Ethier, Vitaly Nikolaev, Pranav Nair, Yoav Ben Shalom, Hen Fitoussi, Jai Gupta, Hongbin Liu, Dee Cattle, Tolga Bolukbasi, Ben Murdoch, Fantine Huot, Yin Li, Chris Hahn, Urvashi Khandelwal, Frederik Benzing, Arthur Conmy, Andrey Simanovsky, Françoise Beaufays, Eugene Weinstein, Tongzhou Chen, Luke Leonhard, Bhuvana Ramabhadran* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** Gemini 2.5, 多模态, 代理能力, 长上下文, 推理

**Comment:** 72 pages, 17 figures

> **TL;DR:** 本报告介绍了Gemini 2.X系列模型，包括最强大的Gemini 2.5 Pro（在编码、推理和多模态理解方面达到SoTA，支持长视频处理和代理工作流），以及注重效率和成本的Gemini 2.5 Flash和Gemini 2.0 Flash/Flash-Lite。该系列旨在覆盖模型能力与成本的完整帕累托前沿，以实现复杂的代理问题解决。

**AI_Comments:** 这篇报告展示了Gemini模型家族在高级推理、多模态处理和长上下文理解方面的显著进步，特别是Gemini 2.5 Pro处理视频内容的能力，为下一代代理系统的发展奠定了基础。通过推出覆盖不同能力与成本权衡的模型版本，该系列展现了其在实际应用中的灵活性和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 推动模型能力的前沿，提供覆盖模型能力与成本帕累托前沿的解决方案，以实现复杂的代理问题解决。

**Method:** 报告介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro、Gemini 2.5 Flash、Gemini 2.0 Flash和Flash-Lite，并详细阐述了它们各自的能力和应用。

**Result:** Gemini 2.5 Pro在前沿编码和推理基准测试中达到了SoTA性能，擅长多模态理解并能处理长达3小时的视频内容。Gemini 2.5 Flash以较低的计算和延迟提供出色的推理能力。Gemini 2.0 Flash和Flash-Lite以低延迟和低成本提供高性能。

**Conclusion:** Gemini 2.X模型系列涵盖了模型能力与成本的完整帕累托前沿，使用户能够探索复杂代理问题解决的可能性边界。

> **ai_Abstract:** 本报告详细介绍了Google的Gemini 2.X系列模型。其中，Gemini 2.5 Pro是当前最强大的模型，在编码、推理和多模态理解方面表现卓越，能处理长达3小时的视频内容，并支持新的代理工作流。同时，报告还介绍了高效率的Gemini 2.5 Flash以及高性能低成本的Gemini 2.0 Flash和Flash-Lite。整个Gemini 2.X系列旨在通过提供不同能力和成本的平衡点，推动复杂代理问题解决的边界。

> **摘要翻译:** 在本报告中，我们介绍了Gemini 2.X模型家族：Gemini 2.5 Pro和Gemini 2.5 Flash，以及我们早期的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro是我们迄今为止最强大的模型，在前沿编码和推理基准测试中取得了SoTA性能。除了其令人难以置信的编码和推理能力外，Gemini 2.5 Pro是一个擅长多模态理解的思考模型，现在能够处理长达3小时的视频内容。其长上下文、多模态和推理能力的独特组合可以结合起来，解锁新的代理工作流程。Gemini 2.5 Flash以一小部分计算和延迟要求提供了出色的推理能力，而Gemini 2.0 Flash和Flash-Lite则以低延迟和低成本提供高性能。总而言之，Gemini 2.X模型世代涵盖了模型能力与成本的完整帕累托前沿，使用户能够探索复杂代理问题解决的可能性边界。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [457] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
> *GEMMAS：基于图的多智能体系统评估指标*

*Jisoo Lee, Raeyoung Chang, Dongwook Kwon, Harmanpreet Singh, Nikhil Verma* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 多智能体系统, 评估指标, 图模型, 协作效率, 冗余推理

**Comment:** 4 figures, 1 algorithm, 2 tables, 6 pages, under review at EMNLP
  Industry track 2025

> **TL;DR:** GEMMAS是一个基于图的评估框架，用于分析多智能体系统中智能体间协作过程，通过引入信息多样性得分（IDS）和不必要路径比率（UPR）来衡量协作质量，揭示了现有仅关注最终结果的评估方法的不足。

**AI_Comments:** 该论文的创新点在于提出了一个全新的、基于过程的评估框架GEMMAS，弥补了现有评估方法仅关注最终结果的不足。通过引入IDS和UPR，它能够更深入地揭示多智能体系统内部协作的效率和质量，这对于优化系统设计、提高资源利用率和增强可解释性具有重要意义。其发现强调了从“结果导向”到“过程导向”评估范式转变的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有对基于语言模型的多智能体系统的评估只关注最终输出的正确性，忽略了低效沟通和不良协作如何导致冗余推理和更高的计算成本。

**Method:** 引入了GEMMAS，一个基于图的评估框架，通过将智能体交互建模为有向无环图来分析内部协作过程。提出了两个过程级指标：信息多样性得分（IDS）用于衡量智能体间消息的语义变化，不必要路径比率（UPR）用于量化冗余推理路径。

**Result:** 在五个基准测试上评估了GEMMAS，并在GSM8K上展示了结果：准确率仅相差2.1%的系统，其IDS相差12.8%，UPR相差80%，这揭示了内部协作的巨大差异。

**Conclusion:** 这些发现表明，仅基于结果的指标不足以评估多智能体系统的性能，并强调了过程级诊断在设计更具可解释性和资源效率的协作AI系统中的重要性。

> **ai_Abstract:** 本文提出了GEMMAS，一个基于图的评估框架，旨在解决当前多智能体系统评估仅关注最终结果而忽视内部协作效率的问题。GEMMAS通过将智能体交互建模为有向无环图，并引入信息多样性得分（IDS）和不必要路径比率（UPR）两个过程级指标来量化协作质量和冗余推理。实验结果表明，即使最终准确率相似的系统，其内部协作效率也可能存在显著差异，强调了过程级诊断对于设计高效协作AI系统的重要性。

> **摘要翻译:** 基于语言模型构建的多智能体系统在协作推理任务上表现出强大的性能。然而，现有评估仅关注最终输出的正确性，忽略了低效沟通和不良协作如何导致冗余推理和更高的计算成本。我们引入了GEMMAS，一个基于图的评估框架，通过将智能体交互建模为有向无环图来分析内部协作过程。为了捕捉协作质量，我们提出了两个过程级指标：信息多样性得分（IDS）用于衡量智能体间消息的语义变化，以及不必要路径比率（UPR）用于量化冗余推理路径。我们在五个基准测试上评估了GEMMAS，并重点展示了GSM8K上的结果，其中准确率仅相差2.1%的系统，其IDS相差12.8%，UPR相差80%，这揭示了内部协作的巨大差异。这些发现表明，仅基于结果的指标不足以评估多智能体系统的性能，并强调了过程级诊断在设计更具可解释性和资源效率的协作AI系统中的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [464] [What Factors Affect LLMs and RLLMs in Financial Question Answering?](https://arxiv.org/abs/2507.08339)
> *什么因素影响大型语言模型和推理大型语言模型在金融问答中的表现？*

*Peng Wang, Xuesi Hu, Jiageng Wu, Yuntao Zou, Qiancheng Zhang, Dagang Li* | **Category: cs.CL** | **Updated: 2025-07-16**

**Keywords:** LLMs, RLLMs, 金融问答, 长链式思考, 提示方法

**Comment:** Preprint

> **TL;DR:** 本研究探讨了提示方法、代理框架和多语言对齐方法对大型语言模型（LLMs）和推理大型语言模型（RLLMs）在金融问答任务中表现的影响，发现这些方法主要通过模拟长链式思考来提升LLMs的性能，而RLLMs由于其固有的长链式思考能力，提升效果有限。

**AI_Comments:** 该论文系统地探讨了不同增强方法对LLMs和RLLMs在特定领域（金融问答）的影响，具有重要价值。论文区分了这些方法如何影响LLMs（通过模拟CoT）与RLLMs（本身已具有固有CoT），这是一个关键的洞察，表明针对不同模型类型需要采取不同的优化策略。

<details>
  <summary>Details</summary>

**Motivation:** 当前很少有工作系统地探索哪些方法可以充分释放大型语言模型（LLMs）和推理大型语言模型（RLLMs）在金融领域的性能。

**Method:** 研究利用五种大型语言模型（LLMs）和三种推理大型语言模型（RLLMs）来评估提示方法、代理框架和多语言对齐方法对金融问答任务的影响。

**Result:** 1. 当前的提示方法和代理框架通过模拟长链式思考（Long CoT）来增强大型语言模型（LLMs）在金融问答中的性能；2. 推理大型语言模型（RLLMs）具有固有的长链式思考（Long CoT）能力，这限制了传统方法进一步提升其性能的有效性；3. 当前先进的多语言对齐方法主要通过延长推理长度来提高大型语言模型（LLMs）的多语言性能，而对推理大型语言模型（RLLMs）的益处微乎其微。

**Conclusion:** 本研究希望为大型语言模型（LLMs）和推理大型语言模型（RLLMs）在金融问答领域提供重要参考。

> **ai_Abstract:** 本研究旨在探讨提示方法、代理框架和多语言对齐方法对大型语言模型（LLMs）和推理大型语言模型（RLLMs）在金融问答任务中表现的影响。通过使用五种LLMs和三种RLLMs进行评估，研究发现这些方法主要通过模拟长链式思考（Long CoT）来提升LLMs的性能。然而，由于RLLMs本身具有固有的Long CoT能力，传统方法对其性能的进一步提升效果有限。本研究旨在为金融问答领域中LLMs和RLLMs的应用提供重要参考。

> **摘要翻译:** 最近，大型语言模型（LLMs）和推理大型语言模型（RLLMs）的发展受到了许多研究人员的广泛关注。RLLMs通过长链式思考（Long CoT）过程增强了LLMs的推理能力，显著提高了LLMs在解决复杂问题方面的性能。然而，很少有工作系统地探索哪些方法可以充分释放LLMs和RLLMs在金融领域的性能。为了调查各种方法对LLMs和RLLMs的影响，我们利用五种LLMs和三种RLLMs来评估提示方法、代理框架和多语言对齐方法对金融问答任务的影响。我们的研究结果表明：（1）当前的提示方法和代理框架通过模拟长链式思考（Long CoT）来增强LLMs在金融问答中的性能；（2）RLLMs具有固有的长链式思考（Long CoT）能力，这限制了传统方法进一步提升其性能的有效性；（3）当前先进的多语言对齐方法主要通过延长推理长度来提高LLMs的多语言性能，而对RLLMs的益处微乎其微。我们希望这项研究能为LLMs和RLLMs在金融问答领域提供重要参考。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [469] [SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems](https://arxiv.org/abs/2507.08898)
> *SEALGuard：保护LLM软件系统中东南亚语言的多语言对话*

*Wenliang Shan, Michael Fu, Rui Yang, Chakkrit Tantithamthavorn* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 多语言安全, LLM护栏, 东南亚语言, 安全对齐, SEALSBench

**Comment:** 

> **TL;DR:** SEALGuard是一个多语言安全护栏，通过适应多语言LLM并构建大型数据集，显著提高了对东南亚语言中不安全和越狱提示的检测能力，优于现有SOTA护栏。

**AI_Comments:** 本文的创新点在于专注于低资源东南亚语言的多语言安全对齐，并通过LoRA适应通用多语言模型，以及构建了大规模的多语言安全数据集SEALSBench，这对于推动LLM在非英语环境下的安全应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM安全护栏（如LlamaGuard）在处理多语言不安全输入时表现不佳，特别是在东南亚等低资源语言中，使得LLM系统容易受到攻击。

**Method:** 引入SEALGuard，一个多语言护栏，旨在改善跨多种语言的安全对齐。通过低秩适应（LoRA）将通用多语言语言模型转换为多语言护栏。构建了SEALSBench，一个包含超过260,000个提示的大规模多语言安全对齐数据集，涵盖十种语言（包括安全、不安全和越狱案例）。在SEALSBench上评估SEALGuard与LlamaGuard等现有SOTA护栏的性能。

**Result:** 现有SOTA护栏LlamaGuard在多语言不安全和越狱提示上的性能显著下降，防御成功率（DSR）分别下降9%和18%。相比之下，SEALGuard在检测多语言不安全和越狱提示方面优于现有护栏，DSR比LlamaGuard提高了48%，并取得了最佳的DSR、准确率和F1分数。消融研究揭示了适应策略和模型大小对SEALGuard整体性能的贡献。

**Conclusion:** SEALGuard有效解决了现有LLM护栏在多语言安全对齐方面的不足，特别是在东南亚语言中，显著提高了对不安全和越狱提示的检测能力。

> **ai_Abstract:** 本文提出了SEALGuard，一个针对LLM系统多语言安全对齐的护栏，旨在解决现有护栏在处理东南亚等低资源语言中不安全和越狱提示时的不足。通过使用LoRA适应多语言LLM并构建大规模多语言数据集SEALSBench，SEALGuard在检测多语言不安全和越狱提示方面显著优于LlamaGuard等现有SOTA护栏，显著提高了防御成功率、准确率和F1分数。

> **摘要翻译:** 安全对齐对于LLM驱动的系统至关重要。虽然最近的LLM驱动的护栏方法（如LlamaGuard）在检测用英语编写的不安全输入（例如，“如何制造炸弹？”）方面取得了很高的检测精度，但它们在多语言不安全输入方面却表现不佳。这一限制使得LLM系统容易受到用低资源语言（如东南亚语言）编写的不安全和越狱提示的攻击。本文介绍了SEALGuard，一个旨在改善跨多种语言安全对齐的多语言护栏。它旨在解决现有护栏的多语言安全对齐差距，并确保有效过滤LLM驱动系统中不安全和越狱提示。我们使用低秩适应（LoRA）将通用多语言语言模型转换为多语言护栏。我们构建了SEALSBench，一个包含超过260,000个提示的大规模多语言安全对齐数据集，涵盖十种语言，包括安全、不安全和越狱案例。我们在这个基准上评估了SEALGuard与LlamaGuard等最先进的护栏。我们的发现表明，多语言不安全和越狱提示会显著降低最先进的LlamaGuard的性能，与仅英语提示的性能相比，其防御成功率（DSR）分别下降9%和18%。相比之下，SEALGuard在检测多语言不安全和越狱提示方面优于现有护栏，DSR比LlamaGuard提高了48%，并取得了最佳的DSR、准确率和F1分数。我们的消融研究进一步揭示了适应策略和模型大小对SEALGuard整体性能的贡献。我们发布了预训练模型和基准，网址为https://github.com/awsm-research/SEALGuard，以支持进一步的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [481] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
> *AbGen：评估大型语言模型在科学研究中消融研究设计与评估的能力*

*Yilun Zhao, Weiyuan Chen, Zhijian Xu, Manasi Patwardhan, Yixin Liu, Chengye Wang, Lovekesh Vig, Arman Cohan* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 消融研究, 基准测试, 评估, 科学研究

**Comment:** ACL 2025

> **TL;DR:** AbGen是一个基准测试，用于评估大型语言模型在设计科学研究中消融研究的能力，发现LLM与人类专家之间存在显著差距，并且现有自动化评估方法不可靠。

**AI_Comments:** AbGen的创新之处在于它是首个专门评估LLM消融研究设计能力的基准测试，并引入了AbGen-Eval用于元评估自动化评估系统。这篇论文的重要性体现在它揭示了当前LLMs在复杂科学任务中与人类专家之间的差距，并强调了开发可靠评估方法的重要性，为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在评估大型语言模型（LLMs）在设计科学研究中消融研究方面的能力，并解决当前自动化评估方法在衡量LLM性能方面存在的可靠性问题。

**Method:** 研究引入了AbGen基准测试，包含来自807篇NLP论文的1500个专家标注示例，用于评估LLMs生成消融研究设计的能力。此外，开发了AbGen-Eval元评估基准测试，用于评估常用自动化评估系统在衡量LLM性能方面的可靠性。研究还调查了各种LLM-as-Judge系统。

**Result:** 评估结果显示，DeepSeek-R1-0528和o4-mini等领先LLMs在消融研究设计的重要性、忠实性和合理性方面与人类专家存在显著性能差距。此外，当前自动化评估方法在与人工评估比较时存在显著差异，证明其不可靠。

**Conclusion:** 大型语言模型在消融研究设计方面仍远不如人类专家，且现有自动化评估方法并不可靠。本研究为未来开发更有效、更可靠的基于LLM的复杂科学任务评估系统提供了见解。

> **ai_Abstract:** 本研究引入了AbGen，一个用于评估大型语言模型（LLMs）在科学研究中设计消融研究能力的基准测试，该基准包含1500个专家标注示例。对领先LLMs的评估揭示了它们在消融研究设计方面与人类专家之间存在显著性能差距。同时，研究指出现有自动化评估方法并不可靠，为此开发了AbGen-Eval元评估基准来评估这些系统的可靠性。研究结果为未来开发更有效、可靠的LLM-based评估系统提供了重要见解。

> **摘要翻译:** 我们引入了AbGen，这是第一个旨在评估大型语言模型（LLMs）在科学研究中设计消融研究能力的基准测试。AbGen包含从807篇NLP论文中提取的1500个专家标注示例。在这个基准测试中，LLMs的任务是根据给定的研究背景为特定模块或过程生成详细的消融研究设计。我们对DeepSeek-R1-0528和o4-mini等领先LLMs的评估突出显示了这些模型与人类专家在消融研究设计的重要性、忠实性和合理性方面存在显著的性能差距。此外，我们证明了当前的自动化评估方法对于我们的任务并不可靠，因为它们与人工评估相比显示出显著差异。为了更好地调查这一点，我们开发了AbGen-Eval，这是一个元评估基准测试，旨在评估常用自动化评估系统在衡量LLM在我们任务上的性能时的可靠性。我们调查了AbGen-Eval上的各种LLM-as-Judge系统，为未来开发更有效和可靠的基于LLM的复杂科学任务评估系统提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [483] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
> *评估大型语言模型与人类语言创造力的比较方法*

*Anca Dinu, Andra-Maria Florescu, Alina Resceanu* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 语言创造力, 大型语言模型, 人机比较, 构词, 隐喻语言

**Comment:** Accepted for presentation at KES 2025. To appear in Procedia Computer
  Science (Elsevier)

> **TL;DR:** 本文介绍了一种比较大型语言模型（LLMs）和人类语言创造力的新测试。结果显示LLMs在多项指标和任务上表现优于人类，但在创造力类型上存在差异。

**AI_Comments:** 本文引入了一种结构化的比较方法来评估语言创造力，这具有创新性。使用自动化工具（OCSAI）进行评估提供了一种系统化的方法。研究发现LLMs在某些方面优于人类，但表现出不同类型的创造力（E-创造力 vs. F-创造力），这是对AI生成语言本质的重要洞察。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在引入一种通用的语言创造力测试，以评估大型语言模型（LLMs）和人类生成新颖原创词语和短语的能力，并进行比较。

**Method:** 研究设计了一个包含构词（派生和复合）和隐喻语言使用任务的语言创造力测试。该测试对24名人类和24个LLMs进行了实施。答案使用OCSAI工具自动评估了原创性、精细性和灵活性三个标准。研究还计算了个体答案的独特性，并进行了简短的手动分析。

**Result:** 大型语言模型在所有评估标准（原创性、精细性、灵活性）上均优于人类，并在八项测试任务中的六项中表现更好。个体答案的独特性在人类和LLMs之间显示出细微差异。手动分析揭示人类更倾向于E（扩展）创造力，而LLMs偏爱F（固定）创造力。

**Conclusion:** 大型语言模型在语言创造力测试中的表现普遍优于人类，但在创造力的类型上存在质的差异，人类倾向于E-创造力，而LLMs倾向于F-创造力。

> **ai_Abstract:** 本文提出了一种新颖的语言创造力测试，用于评估人类和大型语言模型（LLMs）生成新词和短语的能力，涵盖构词和隐喻用法。研究对24名人类和24个LLMs进行了测试，并使用OCSAI工具自动评估了原创性、精细性和灵活性。结果表明，LLMs在这些标准和大多数任务中表现优于人类。尽管个体答案的独特性存在细微差异，但手动分析揭示人类倾向于E-创造力，而LLMs偏爱F-创造力。

> **摘要翻译:** 本论文介绍了一种针对人类和大型语言模型（LLMs）的通用语言创造力测试。该测试包含各种任务，旨在评估它们根据构词过程（派生和复合）和隐喻语言使用生成新颖原创词语和短语的能力。我们对24名人类和等量的LLMs进行了测试，并使用OCSAI工具从三个标准：原创性、精细性和灵活性，自动评估了他们的答案。结果显示，LLMs不仅在所有评估标准上都优于人类，而且在八项测试任务中有六项表现更好。然后，我们计算了个体答案的独特性，这显示出人类和LLMs之间存在一些细微差异。最后，我们对数据集进行了简短的手动分析，结果表明人类更倾向于E（扩展）创造力，而LLMs偏爱F（固定）创造力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [490] [ReCode: Updating Code API Knowledge with Reinforcement Learning](https://arxiv.org/abs/2506.20495)
> *ReCode：使用强化学习更新代码API知识*

*Haoze Wu, Yunzhi Yao, Wenhao Yu, Huajun Chen, Ningyu Zhang* | **Category: cs.CL, cs.AI, cs.IR, cs.LG, cs.SE** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 代码生成, API更新, 大型语言模型, 代码适应

**Comment:** Work in progress

> **TL;DR:** 大型语言模型在面对频繁更新的API时，其代码生成能力会因过时的知识而受限。ReCode提出了一种基于强化学习的新框架，通过模拟人类程序员适应API变化的方式，显著提升了LLM在动态API场景中的代码生成性能，且对LLM的通用代码生成能力影响较小。

**AI_Comments:** 这篇论文解决了一个LLM代码生成领域中非常实际且重要的问题：如何适应频繁变化的API。使用强化学习来模拟人类程序员的适应过程是其创新之处。论文发现ReCode对LLM通用代码生成能力的影响小于监督微调，这是一个显著的优势，因为它避免了微调中常见的“灾难性遗忘”问题。此外，一个较小的模型（Qwen2.5-Coder-7B）在经过ReCode训练后能超越更大的模型，也凸显了其效率和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在代码生成方面表现出色，但由于其训练数据中包含过时的API知识，即使能访问最新文档，也难以适应外部库API的频繁更新，这阻碍了它们在动态环境中生成可靠代码的能力。

**Method:** 本文提出了ReCode（基于规则的强化学习用于代码更新）框架，旨在模仿人类程序员适应API变化的方式。具体方法包括：构建一个约2000个数据条目的数据集，用于训练LLM进行基于更新信息的版本迁移；引入一种修改后的字符串相似性度量作为强化学习的代码评估奖励；将ReCode应用于各种LLM和强化学习算法（如GRPO和DAPO）。

**Result:** ReCode显著提升了LLM在动态API场景中的代码生成性能，尤其在未见的CodeUpdateArena任务上表现突出。与监督微调相比，ReCode对LLM的通用代码生成能力影响较小。在各种LLM和强化学习算法上均实现了持续改进。值得注意的是，经过ReCode训练后，Qwen2.5-Coder-7B的性能超越了同架构下32B参数的代码指令微调模型和推理模型。

**Conclusion:** ReCode通过强化学习有效解决了大型语言模型在动态API环境中代码生成时面临的过时API知识问题，显著提高了性能，同时最大程度地保留了模型的通用代码生成能力。

> **ai_Abstract:** ReCode是一个新颖的框架，它利用强化学习来解决大型语言模型在处理不断更新的API时代码生成能力下降的问题。通过构建一个约2000个数据条目的数据集并引入改进的字符串相似性作为强化学习奖励，ReCode显著提升了LLM在动态API场景中的代码生成性能，尤其是在未见的任务上。与监督微调相比，ReCode对LLM的通用代码生成能力影响较小，并且在多种LLM和强化学习算法上都表现出一致的改进。

> **摘要翻译:** 大型语言模型（LLMs）展现出卓越的代码生成能力，但在适应外部库API频繁更新方面表现不佳。这一关键限制源于其训练数据中过时的API知识，即使能够访问最新文档，也阻碍了在动态环境中可靠的代码生成。为了解决这个问题，我们提出了ReCode（基于规则的强化学习用于代码更新），这是一个模仿人类程序员适应API变化的新颖框架。具体来说，我们构建了一个约2000个数据条目的数据集，用于训练LLM根据更新信息执行版本迁移。然后，我们引入了一种修改后的字符串相似性度量作为代码评估的奖励，用于强化学习。我们的实验表明，ReCode显著提升了LLM在动态API场景中的代码生成性能，尤其是在未见的CodeUpdateArena任务上。至关重要的是，与监督微调相比，ReCode对LLM通用代码生成能力的影响较小。我们将ReCode应用于各种LLM和强化学习算法（GRPO和DAPO），所有都实现了持续改进。值得注意的是，训练后，Qwen2.5-Coder-7B的性能超越了同架构下32B参数的代码指令微调模型和推理模型。代码可在https://github.com/zjunlp/ReCode获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [492] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
> *通过激活态操控增强大型语言模型的跨任务迁移能力*

*Xinyu Tang, Zhihao Lv, Xiaoxue Cheng, Junyi Li, Wayne Xin Zhao, Zujie Wen, Zhiqiang Zhang, Jun Zhou* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 跨任务迁移, 激活操控, 潜在空间, 上下文学习

**Comment:** 

> **TL;DR:** 本文提出CAST框架，通过操控大型语言模型内部激活状态，实现在不更新参数或扩展输入的情况下，有效提升模型在数据稀缺任务上的跨任务迁移能力，且具有更好的可扩展性和更低的计算成本。

**AI_Comments:** 这篇论文的创新点在于提出了通过直接操控大型语言模型内部激活状态而非传统的参数微调或输入扩展来实现跨任务知识迁移的方法。这种方法在数据稀缺场景下尤为重要，因为它提供了一种高效且计算成本较低的解决方案，克服了传统上下文学习在鲁棒性、可扩展性和效率上的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在处理未见过或数据稀缺任务时表现不佳，而跨任务上下文学习虽然提供了一种直接解决方案，但在鲁棒性、可扩展性和效率方面仍面临挑战。

**Method:** 作者通过分析LLM潜在空间中的激活模式，发现由上下文示例引起的增强激活在不同任务中具有一致的模式。受此启发，提出CAST（Cross-task Activation Steering Transfer）框架，通过操纵模型的内部激活状态实现有效迁移。具体方法是：首先从高资源任务中选择有影响力和多样性的样本，然后利用它们的对比表示增强激活来使LLM适应低资源任务。

**Result:** 实验结果表明，CAST方法在跨领域和跨语言迁移设置中均优于竞争基线，并展示出卓越的可扩展性和更低的计算成本。

**Conclusion:** 通过对大型语言模型内部激活状态的操控，可以在不更新参数或扩展输入的情况下，有效实现和增强模型的跨任务知识迁移，尤其适用于数据稀缺场景。

> **ai_Abstract:** 本文提出一种新颖的CAST框架，旨在通过操控大型语言模型（LLMs）的内部激活状态来增强其在数据稀缺任务上的跨任务迁移能力。研究发现，LLM潜在空间中由上下文示例引起的激活模式在不同任务间具有一致性。CAST利用高资源任务中有影响力的样本的对比表示增强激活，以适应低资源任务，从而实现无需参数更新或输入扩展的有效知识迁移。实验证明，该方法在跨领域和跨语言设置中表现优越，并具有更高的可扩展性和更低的计算成本。

> **摘要翻译:** 大型语言模型（LLMs）在通过提示利用预训练知识方面表现出令人印象深刻的能力，但它们在处理未见过的任务时，特别是在数据稀缺场景下，往往会遇到困难。尽管跨任务上下文学习为跨任务知识迁移提供了一种直接解决方案，但它在鲁棒性、可扩展性和效率方面仍面临严峻挑战。在本文中，我们研究了是否可以通过潜在空间操控来实现跨任务迁移，而无需参数更新或输入扩展。通过对LLM潜在空间中激活模式的分析，我们观察到由上下文示例引起的增强激活在不同任务中具有一致的模式。受这些发现的启发，我们提出了CAST，一个新颖的跨任务激活操控迁移框架，它通过操纵模型的内部激活状态来实现有效的迁移。我们的方法首先从高资源任务中选择有影响力和多样性的样本，然后利用它们的对比表示增强激活来使LLM适应低资源任务。在跨领域和跨语言迁移设置中进行的广泛实验表明，我们的方法优于竞争基线，并展示出卓越的可扩展性和更低的计算成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [500] [Multi-task retriever fine-tuning for domain-specific and efficient RAG](https://arxiv.org/abs/2501.04652)
> *多任务检索器微调，用于领域特定和高效的RAG*

*Patrice Béchard, Orlando Marquez Ayala* | **Category: cs.CL, cs.IR, cs.LG** | **Updated: 2025-07-16**

**Keywords:** RAG, 检索器微调, 多任务学习, 领域特定, LLM

**Comment:** 7 pages, 2 figures. Accepted at Workshop on Structured Knowledge for
  Large Language Models (SKnowLLM) at KDD 2025

> **TL;DR:** 针对RAG应用中领域特异性和部署成本问题，通过多任务指令微调一个小型检索器编码器，使其能服务多种领域和任务，提高效率和泛化性。

**AI_Comments:** 这篇论文的创新点在于提出了多任务指令微调检索器的方法，以应对RAG在实际部署中遇到的领域特异性和效率问题。通过微调小型检索器而非昂贵的LLM，并使其具备处理多种任务的能力，显著降低了部署成本并提高了系统可扩展性，对于企业级RAG应用的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有RAG应用面临两个主要问题：1) 检索信息通常是领域特定的，但微调LLM计算成本高，微调检索器更可行；2) 部署多个独立的检索器成本高且不切实际，尤其当不同RAG应用需要检索不同类型数据时。

**Method:** 通过指令微调一个小型检索器编码器，使其能够处理多种领域特定任务，从而实现一个编码器服务多种用例。

**Result:** 该编码器能泛化到域外设置以及未见的真实企业用例检索任务。

**Conclusion:** 通过多任务微调检索器，可以实现低成本、可扩展、快速的RAG部署，并有效解决领域特异性及多应用部署的挑战。

> **ai_Abstract:** 该论文提出了一种通过多任务指令微调小型检索器编码器的方法，以解决真实世界RAG应用中领域特异性信息检索和多检索器部署成本高昂的问题。这种方法使得一个检索器编码器能够服务于多种领域和任务，从而实现低成本、高效率和可扩展性，并展示了其在域外和未见企业用例中的泛化能力。

> **摘要翻译:** 检索增强生成（RAG）在部署大型语言模型（LLM）时已变得无处不在，因为它可以解决诸如生成幻觉或过时信息等典型局限性。然而，在构建真实的RAG应用程序时，会出现实际问题。首先，检索到的信息通常是领域特定的。由于微调LLM计算成本高昂，因此微调检索器以提高LLM输入中包含的数据质量更为可行。其次，随着更多应用程序部署在同一真实世界系统中，无法负担部署单独的检索器。此外，这些RAG应用程序通常检索不同类型的数据。我们的解决方案是在各种领域特定任务上对一个小型检索器编码器进行指令微调，以使我们能够部署一个可以服务多种用例的编码器，从而实现低成本、可扩展性和速度。我们展示了该编码器如何泛化到域外设置以及未见的真实企业用例检索任务。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [508] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
> *AudioJudge：理解大型音频模型语音评估中的有效方法*

*Potsawee Manakul, Woody Haosheng Gan, Michael J. Ryan, Ali Sartaz Khan, Warit Sirichotedumrong, Kunat Pipatanakul, William Held, Diyi Yang* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 大型音频模型, 语音评估, AudioJudge, 提示工程, 人类偏好相关性

**Comment:** 

> **TL;DR:** AudioJudge利用大型音频模型统一语音评估，解决了传统方法的局限性，并通过提示工程和多方面集成实现了高人类偏好相关性，但需注意冗余和位置偏差。

**AI_Comments:** 这项工作创新性地将大型音频模型应用于统一的语音评估，通过先进的提示工程和多方面集成方法，显著提升了自动评估与人类偏好的一致性，为解决传统评估方法的局限性提供了新思路。其高相关性结果显示了LAMs在该领域的巨大潜力，但也指出了其固有的偏差，为未来的研究方向提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 当前语音评估存在两个主要局限性：1. 设计针对特定音频特征的专业系统既必要又困难；2. 自动化评估方法与人类偏好相关性差。

**Method:** 本文提出AudioJudge，一个基于大型音频模型（LAM）的评估框架。系统地探索了其在音频特征检测任务（如发音、语速、说话人识别和语音质量）以及系统级人类偏好模拟中的应用。研究了不同的提示工程策略，发现音频拼接结合上下文学习能显著提高性能。进一步引入了多方面集成AudioJudge，将语音评估分解为词汇内容、语音质量和副语言特征的专业评估器。

**Result:** 音频拼接结合上下文学习显著提高了音频特征检测和人类偏好模拟任务的性能。多方面集成AudioJudge在系统排名基准上与人类偏好达到了高达0.91的Spearman相关性。鲁棒性分析显示，LAMs在声学噪声下仍保持良好性能，但存在明显的冗余和位置偏差。

**Conclusion:** 大型音频模型（LAMs）作为AudioJudge能够提供一个统一的语音评估框架，有效解决当前评估的局限性，并通过提示工程和多方面集成实现高精度，但其冗余和位置偏差需要仔细缓解。

> **ai_Abstract:** 本文提出了AudioJudge，一个基于大型音频模型（LAM）的统一语音评估框架，旨在解决当前语音评估中专用系统设计困难和自动化评估与人类偏好相关性差的问题。研究通过系统探索AudioJudge在多种音频特征检测和人类偏好模拟任务中的表现，发现音频拼接结合上下文学习能显著提升性能。此外，引入的多方面集成AudioJudge通过将评估分解为专业判断，实现了与人类偏好高度相关的评估结果（Spearman相关性高达0.91）。研究还指出了LAMs在噪声环境下表现稳健，但存在冗余和位置偏差，需要进一步优化。

> **摘要翻译:** 当前语音评估存在两个关键局限性：一是设计针对单个音频特征的专用系统的必要性和难度，二是自动化评估方法与人类偏好之间的相关性较差。这项工作对大型音频模型（LAM）作为评估器（AudioJudge）进行了系统研究，调查它是否能提供一个统一的评估框架来解决这两个挑战。我们系统地探索了AudioJudge在音频特征检测任务中的应用，包括发音、语速、说话人识别和语音质量，以及用于自动化基准测试的系统级人类偏好模拟。我们研究了不同的提示工程策略，发现音频拼接结合上下文学习显著提高了音频特征检测和人类偏好模拟任务的性能。我们进一步引入了一种多方面集成AudioJudge，以实现通用多方面音频评估。该方法将语音评估分解为词汇内容、语音质量和副语言特征的专业评估器，在我们的系统排名基准上与人类偏好达到了高达0.91的Spearman相关性。鲁棒性分析表明，虽然大型音频模型在声学噪声下仍保持强大性能，但它们表现出显著的冗余和位置偏差，需要仔细缓解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [525] [Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses](https://arxiv.org/abs/2507.07188)
> *提示扰动揭示了大型语言模型调查回答中的类人偏见*

*Jens Rupprecht, Georg Ahnert, Markus Strohmaier* | **Category: cs.CL, cs.AI, cs.CY, J.4** | **Updated: 2025-07-16**

**Keywords:** 大型语言模型, 调查偏差, 提示扰动, 近期偏见, 鲁棒性测试

**Comment:** 18 pages, 17 figures

> **TL;DR:** 研究发现大型语言模型在调查回应中表现出类人偏见，特别是近期偏见，强调了提示设计和鲁棒性测试的重要性。

**AI_Comments:** 这篇论文的创新之处在于系统性地通过提示扰动来探究大型语言模型在调查响应中的偏差，特别是揭示了其类人偏见，如近期偏见。其重要性在于，随着LLMs在社会科学研究中应用的增加，了解其局限性和偏差对于确保数据质量和研究结论的有效性至关重要。论文强调了细致的提示工程和鲁棒性测试的必要性，为未来利用LLMs进行调查研究提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地被用作社会科学调查中人类受试者的替代品，但其可靠性以及对已知响应偏差的敏感性尚不清楚。本研究旨在探讨LLMs在规范调查环境中的响应鲁棒性。

**Method:** 研究人员测试了九个不同的大型语言模型，使用了世界价值观调查（WVS）中的问题，并对问题措辞和答案选项结构应用了11种全面的扰动，共进行了超过167,000次模拟访谈。

**Result:** 研究不仅揭示了大型语言模型对扰动的脆弱性，还表明所有测试模型都表现出一致的近期偏见，其强度各异，不成比例地偏爱最后呈现的答案选项。虽然较大的模型通常更具鲁棒性，但所有模型对语义变化（如意译）和组合扰动仍然敏感。

**Conclusion:** 通过应用一系列扰动，研究揭示了大型语言模型部分与人类调查响应中识别出的偏见相符。这强调了在使用大型语言模型生成合成调查数据时，提示设计和鲁棒性测试的至关重要性。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在社会科学调查中作为人类替代品的可靠性及其对响应偏差的敏感性。通过对九个LLMs进行世界价值观调查问题的测试，并施加11种提示和答案结构扰动，模拟了超过16.7万次访谈。结果显示，LLMs对扰动敏感，普遍存在近期偏见，即偏爱最后呈现的选项。尽管大型模型表现出更高的鲁棒性，但它们仍易受语义变化和组合扰动的影响。研究最终揭示LLMs展现出与人类相似的调查响应偏差，强调了在使用LLMs生成合成调查数据时，提示设计和鲁棒性测试的关键作用。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地被用作社会科学调查中人类受试者的替代品，但其可靠性以及对已知响应偏差的敏感性尚不清楚。本文调查了LLMs在规范调查背景下的响应鲁棒性——我们测试了九个不同的LLMs，使用了世界价值观调查（WVS）中的问题，并对问题措辞和答案选项结构应用了一套全面的11种扰动，从而产生了超过167,000次模拟访谈。在此过程中，我们不仅揭示了LLMs对扰动的脆弱性，还表明所有测试模型都表现出一致的近期偏见，其强度各异，不成比例地偏爱最后呈现的答案选项。虽然较大的模型通常更具鲁棒性，但所有模型对语义变化（如意译）和组合扰动仍然敏感。通过应用一系列扰动，我们揭示了LLMs部分与人类调查响应中识别出的偏见相符。这强调了在使用LLMs生成合成调查数据时，提示设计和鲁棒性测试的至关重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [527] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
> *多智能体协同驱动的迭代视觉叙事合成*

*Wang Xi, Quan Shi, Tian Yu, Yujie Peng, Jiayi Sun, Mengxing Ren, Zenghui Ding, Ningguang Yao* | **Category: cs.CL, 68T50, 68T07, I.2.7; I.2.11; H.5.2** | **Updated: 2025-07-17**

**Keywords:** 媒体演示文稿生成, 视觉叙事合成, RCPS, PREVAL, 自动化内容生成式自动化

**Comment:** 22 pages, 7 figures, 3 tables. Submitted to an ACL-style conference

> **TL;DR:** 本文提出RCPS框架，通过深度叙事规划、自适应布局和迭代优化解决高质量媒体演示文稿自动生成中的逻辑不一致和布局问题。同时引入PREVAL评估工具，实验证明RCPS优于基线方法，PREVAL与人类判断高度相关。

**AI_Comments:** 该论文的创新点在于提出了一个集成了叙事规划、布局生成和迭代优化的综合框架RCPS，以及一个新颖的、基于偏好的评估框架PREVAL。RCPS通过其多组件协同和迭代优化机制，有效提升了自动生成媒体演示文稿的质量，使其更接近专业标准。PREVAL的提出则为评估演示文稿质量提供了一个可靠的自动化工具，这对于自动化内容生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在自动生成高质量媒体演示文稿时常产生逻辑不一致和次优布局，难以达到专业标准，因此需要开发更鲁棒的解决方案。

**Method:** 提出RCPS（Reflective Coherent Presentation Synthesis）框架，包含深度结构化叙事规划、自适应布局生成和迭代优化循环三个核心组件。同时，提出PREVAL，一个基于偏好的评估框架，利用理由增强的多维模型评估内容、连贯性和设计方面的演示文稿质量。

**Result:** RCPS在所有质量维度上显著优于基线方法，生成的演示文稿非常接近人类专家标准。PREVAL与人类判断显示出强相关性，验证了其作为评估演示文稿质量的可靠自动化工具。

**Conclusion:** RCPS框架能够有效生成接近人类专家标准的媒体演示文稿，PREVAL则是一个可靠的自动化评估工具，共同解决了高质量媒体演示文稿自动生成和评估的挑战。

> **ai_Abstract:** 本文提出RCPS（Reflective Coherent Presentation Synthesis）框架，旨在解决高质量媒体演示文稿自动生成中存在的逻辑不一致和布局次优问题。RCPS整合了深度结构化叙事规划、自适应布局生成和迭代优化循环。同时，文章还引入了PREVAL评估框架，该框架利用多维模型评估演示文稿的内容、连贯性和设计质量。实验证明，RCPS在生成质量上显著超越基线方法并接近人类专家水平，而PREVAL则被验证为可靠的自动化评估工具。

> **摘要翻译:** 自动化生成高质量媒体演示文稿具有挑战性，需要强大的内容提取、叙事规划、视觉设计和整体质量优化能力。现有方法常产生逻辑不一致和次优布局的演示文稿，难以达到专业标准。为解决这些挑战，我们引入了RCPS（Reflective Coherent Presentation Synthesis），一个整合了三个关键组件的新颖框架：（1）深度结构化叙事规划；（2）自适应布局生成；（3）迭代优化循环。此外，我们提出了PREVAL，一个基于偏好的评估框架，采用理由增强的多维模型来评估演示文稿在内容、连贯性和设计方面的质量。实验结果表明，RCPS在所有质量维度上显著优于基线方法，生成的演示文稿非常接近人类专家标准。PREVAL与人类判断显示出强相关性，验证了其作为评估演示文稿质量的可靠自动化工具。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [532] [OASIS: Order-Augmented Strategy for Improved Code Search](https://arxiv.org/abs/2503.08161)
> *OASIS：用于改进代码搜索的顺序增强策略*

*Zuchen Gao, Zizheng Zhan, Xianming Li, Erxin Yu, Ziqi Zhan, Haotian Zhang, Bin Chen, Yuqun Zhang, Jing Li* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-17**

**Keywords:** 代码嵌入, 代码搜索, 顺序增强策略, InfoNCE损失, 语义细微差别

**Comment:** 

> **TL;DR:** OASIS通过引入顺序相似性标签来利用负样本对之间的细微差异，显著提高了代码搜索的性能，解决了传统方法无法捕获深层语义细微差别的问题。

**AI_Comments:** OASIS的创新之处在于其引入了“顺序增强”的概念，通过利用负样本对之间的细微差异来改进代码嵌入训练。这突破了传统InfoNCE损失仅关注正负样本主要差异的局限性，特别适用于代码这种上下文稀疏的领域。此方法对于提升代码搜索及其他代码相关LLM应用的性能具有重要意义，为未来的代码表示学习提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的代码嵌入训练主要依赖InfoNCE损失，通过比较正向自然语言-代码对与批内负样本来优化。然而，由于代码上下文的稀疏性，仅通过比较正负样本之间的主要差异可能无法捕获更深层次的语义细微差别。

**Method:** 提出了一种新颖的顺序增强策略（OASIS），它利用基于顺序的相似性标签来训练模型，使其能够捕获负样本对之间细微的相似性差异。

**Result:** 广泛的基准评估表明，OASIS模型显著优于以前仅关注主要正负差异的最新模型。

**Conclusion:** 强调了利用带有顺序标签的负样本对之间的细微差异对于有效的代码嵌入训练的价值。

> **ai_Abstract:** 本文提出了一种名为OASIS（Order-Augmented Strategy for Improved Code Search）的新型代码嵌入训练策略。针对现有方法在处理代码上下文稀疏性时无法捕捉深层语义细微差别的问题，OASIS通过引入基于顺序的相似性标签，使模型能够学习并区分负样本对之间细微的相似性差异。实验结果表明，OASIS在代码搜索任务上显著优于现有的最先进模型，证明了利用负样本对细微差异的重要性。

> **摘要翻译:** 代码嵌入捕获代码的语义表示，对于各种代码相关的大型语言模型（LLM）应用（如代码搜索）至关重要。之前的训练主要依赖于通过将正向自然语言（NL）-代码对与批内负样本进行比较来优化InfoNCE损失。然而，由于代码上下文的稀疏性，仅通过比较正负样本之间的主要差异可能无法捕获更深层次的语义细微差别。为了解决这个问题，我们提出了一种新颖的顺序增强策略（OASIS），用于改进代码搜索。它利用基于顺序的相似性标签来训练模型，以捕获负样本对之间细微的相似性差异。广泛的基准评估表明，我们的OASIS模型显著优于以前仅关注主要正负差异的最新模型。它强调了利用带有顺序标签的负样本对之间的细微差异对于有效的代码嵌入训练的价值。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [551] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
> *视觉-语言训练有助于部署分类学知识但并未从根本上改变它*

*Yulu Qin, Dheeraj Varghese, Adam Dahlgren Lindström, Lucia Donatelli, Kanishka Misra, Najoung Kim* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 视觉-语言训练, 分类学知识, 语言模型, 知识部署, 语言表征

**Comment:** 

> **TL;DR:** 视觉-语言(VL)训练并未从根本上改变语言模型的分类学知识，但提高了这种知识在特定任务中的部署能力，即使是纯文本任务。

**AI_Comments:** 该论文的关键创新在于区分了知识的“改变”与“部署”。它提出VL训练并非从根本上重塑了语言模型的内在分类学知识，而是优化了模型在特定任务中调用和应用这些知识的机制。这一发现对于理解多模态训练如何影响语言模型的能力具有重要意义，提示未来研究可以更多关注知识的激活和应用而非仅仅知识的习得。

<details>
  <summary>Details</summary>

**Motivation:** 探究视觉-语言(VL)训练是否能显著改变语言模型的语言表征，特别是词汇-概念知识及其分类组织，因为现有研究结果多为不一致或微不足道的差异。

**Method:** 通过比较文本-only语言模型(LMs)及其VL训练对应模型，在一个需要分类学理解的纯文本问答任务上进行测试。并使用一系列有针对性的行为和表征分析。

**Result:** VL模型在需要分类学理解的纯文本问答任务上表现优于纯文本模型。LMs和VLMs在分类学知识本身没有显著差异，但在如何表征包含分类学关系或非分类学关系概念的问题上存在差异。

**Conclusion:** 额外的视觉-语言训练并不会实质性地改变分类学知识本身，但它确实提高了这种知识在特定任务背景下的部署能力，即使任务的呈现形式是纯语言的。

> **ai_Abstract:** 本研究旨在探究视觉-语言（VL）训练对语言模型（LMs）词汇-概念知识，特别是分类组织的影响。研究发现，VL训练后的模型在需要分类学理解的纯文本问答任务上表现优于仅文本模型。然而，进一步分析表明，VL训练并未从根本上改变LMs的分类学知识本身，而是提高了模型在特定任务中部署和应用现有分类学知识的能力，即使任务是纯文本形式。

> **摘要翻译:** 视觉-语言（VL）训练是否能以有意义的方式改变语言模型的语言表征？文献中的大多数结果在行为和表征上都显示出不一致或微不足道的差异。在这项工作中，我们从一个假设开始：VL训练可能产生显著影响的领域是词汇-概念知识，特别是其分类组织。通过比较仅文本语言模型（LMs）及其经过VL训练的对应模型，我们首先展示了VL模型在需要对问题中提及的概念进行分类学理解的纯文本问答任务上，通常优于仅文本模型。通过一系列有针对性的行为和表征分析，我们发现LMs和VLMs在分类学知识本身方面没有显著差异，但它们在如何表征包含分类学关系或非分类学关系概念的问题上有所不同。这意味着分类学知识本身通过额外的VL训练并没有发生实质性改变，但VL训练确实提高了这种知识在特定任务背景下的部署能力，即使任务的呈现形式是纯语言的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [562] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
> *HapticCap：一个用于理解振动触觉信号用户体验的多模态数据集和任务*

*Guimin Hu, Daniel Hershcovich, Hasti Seifi* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 触觉信号, 多模态数据集, 用户体验, 振动, 对比学习

**Comment:** 

> **TL;DR:** 论文介绍了HapticCap，一个包含9万多触觉-文本对的振动触觉信号数据集，并提出了触觉-标题检索任务，旨在改善触觉信号的用户体验理解和设计。

**AI_Comments:** 本文的创新之处在于构建了首个大规模、完全人工标注的触觉-文本数据集HapticCap，极大地弥补了该领域数据稀缺的现状。同时，提出的触觉-标题检索任务和基于对比学习的解决方案为理解和量化用户对触觉信号的感知提供了有效途径，对未来触觉人机交互设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 触觉信号设计难以与用户产生有意义的共鸣；缺乏带有文本描述的大型触觉振动数据集；现有任务和模型描述振动信号的能力有限。

**Method:** 引入了HapticCap数据集，它是第一个完全由人类标注的触觉-标题数据集，包含92,070个触觉-文本对。基于HapticCap，提出了触觉-标题检索任务，并使用监督对比学习框架，结合特定类别内的文本表示和振动来解决此任务。实验中使用了语言模型T5和音频模型AST。

**Result:** HapticCap数据集被成功创建，包含92,070个触觉-文本对。在触觉-标题检索任务中，语言模型T5和音频模型AST的组合表现最佳，尤其是在针对每个描述类别单独训练时。

**Conclusion:** HapticCap数据集和提出的触觉-标题检索任务有助于克服当前触觉信号设计和理解的挑战，并为深入理解振动触觉信号的用户体验提供了资源和方法。

> **ai_Abstract:** 本文介绍了HapticCap，一个包含92,070个触觉-文本对的全新多模态数据集，旨在解决触觉信号设计中描述数据缺乏和现有模型能力受限的问题。研究者基于该数据集提出了触觉-标题检索任务，并采用监督对比学习框架进行评估。结果表明，结合T5语言模型和AST音频模型的方案在任务中表现最优，尤其是在按类别单独训练时，这为理解和设计用户体验丰富的振动触觉信号提供了重要资源和方法。

> **摘要翻译:** 触觉信号，从智能手机振动到虚拟现实触觉反馈，可以有效地传达信息并增强真实感，但设计能与用户产生有意义共鸣的信号具有挑战性。为了促进这一点，我们引入了一个多模态数据集和任务，即匹配用户描述与振动触觉信号，并强调了两个主要挑战：(1) 缺乏带有文本描述的大型触觉振动数据集，因为收集触觉描述非常耗时；(2) 现有任务和模型用文本描述振动信号的能力有限。为了推进这一领域，我们创建了HapticCap，这是第一个完全由人类标注的触觉-标题数据集，包含92,070个触觉-文本对，用于描述振动的感官、情感和联想属性的用户描述。基于HapticCap，我们提出了触觉-标题检索任务，并展示了该任务在监督对比学习框架下的结果，该框架将特定类别内的文本表示与振动结合起来。总体而言，语言模型T5和音频模型AST的组合在触觉-标题检索任务中表现最佳，尤其是在针对每个描述类别单独训练时。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [567] [MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents](https://arxiv.org/abs/2506.15841)
> *MEM1：学习协同记忆与推理以实现高效长周期智能体*

*Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, Paul Pu Liang* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-17**

**Keywords:** 强化学习, 记忆整合, 推理, 长周期智能体, 语言模型

**Comment:** 

> **TL;DR:** MEM1是一个端到端强化学习框架，通过更新紧凑的共享内部状态来整合记忆和推理，使语言智能体能够在长周期多轮交互中以恒定内存运行，显著提升性能并减少内存使用。

**AI_Comments:** MEM1的创新之处在于其端到端的强化学习框架，通过推理驱动的记忆整合实现了长周期多轮任务中的恒定内存操作，有效解决了现有LLM系统内存无限增长和性能下降的问题。其构建多轮环境的方法也提升了训练的现实性和可组合性。这项工作为开发更高效、可扩展的交互式智能体提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现代语言智能体在长周期、多轮交互中面临内存无限增长、计算成本增加以及在分布外输入长度上推理性能下降的问题，因为大多数LLM系统依赖于全上下文提示，无论相关性如何都附加所有过去的轮次。

**Method:** MEM1是一个端到端强化学习框架，它通过在每个轮次更新一个紧凑的共享内部状态来实现恒定内存操作。这个状态整合了先前的记忆与来自环境的新观察，并策略性地丢弃不相关或冗余的信息。为了支持在更真实和组合设置中的训练，论文提出了一种简单、有效且可扩展的方法，通过组合现有数据集来构建任意复杂的任务序列，从而创建多轮环境。

**Result:** 在包括内部检索问答、开放域网络问答和多轮网络购物在内的三个领域进行的实验表明，在16目标多跳问答任务上，MEM1-7B的性能比Qwen2.5-14B-Instruct提高了3.5倍，内存使用减少了3.7倍，并且能够泛化到训练周期之外。

**Conclusion:** 论文结果表明，推理驱动的记忆整合是现有解决方案的一种可扩展替代方案，用于训练长周期交互式智能体，同时优化了效率和性能。

> **ai_Abstract:** 本研究提出了MEM1，一个端到端强化学习框架，旨在解决现代语言智能体在长周期多轮交互中面临的内存无限增长和推理性能下降问题。MEM1通过维护一个紧凑的共享内部状态来整合记忆和推理，该状态在每个轮次更新，并策略性地丢弃不相关信息，从而实现恒定内存操作。为支持训练，论文还提出了一种可扩展的多轮环境构建方法。实验证明，MEM1在多跳问答任务上显著提升了性能并减少了内存使用，展现了推理驱动记忆整合在高效长周期交互式智能体训练中的潜力。

> **摘要翻译:** 现代语言智能体必须在长周期、多轮交互中运行，在此过程中它们检索外部信息，适应观察，并回答相互依赖的查询。然而，大多数LLM系统依赖于全上下文提示，无论相关性如何都附加所有过去的轮次。这导致内存无限增长、计算成本增加，并在分布外输入长度上推理性能下降。我们引入MEM1，一个端到端强化学习框架，使智能体能够在长多轮任务中以恒定内存运行。在每个轮次，MEM1更新一个紧凑的共享内部状态，该状态共同支持记忆整合和推理。该状态将先前的记忆与来自环境的新观察相结合，同时策略性地丢弃不相关或冗余的信息。为了支持在更真实和组合设置中的训练，我们提出了一种简单而有效且可扩展的方法，通过组合现有数据集来构建任意复杂的任务序列，从而构建多轮环境。在包括内部检索问答、开放域网络问答和多轮网络购物在内的三个领域进行的实验表明，MEM1-7B在16目标多跳问答任务上比Qwen2.5-14B-Instruct性能提高了3.5倍，内存使用减少了3.7倍，并且能够泛化到训练周期之外。我们的结果证明了推理驱动的记忆整合作为现有解决方案的可扩展替代方案的前景，用于训练长周期交互式智能体，同时优化了效率和性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [575] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
> *使语言模型成为分层分类器和生成器*

*Yihong Wang, Zhonglin Jiang, Ningyuan Xi, Yue Zhao, Qingqing Gu, Xiyuan Chen, Hao Wu, Sheng Xu, Hange Zhou, Yong Chen, Luo Ji* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 分层解码器, 语言模型, 分层分类, 分层生成, 预训练模型

**Comment:** 

> **TL;DR:** 本文提出了一种分层解码器架构，通过将预训练语言模型的最后一层语言头复制到中间层并进行微调，使其在分层文本分类、分类引导生成和分层文本生成等任务上达到SOTA性能。

**AI_Comments:** 本文提出了一种创新的方法，将现有的解码器语言模型改造为分层分类器和生成器，通过利用模型内部的中间层进行多层次解码。这一思想打破了传统解码器模型仅在最后一层解码的范式，并通过实验证明了其有效性，特别是在分层任务上的SOTA表现，这对于未来构建更接近人类思维模式的通用分层推理器具有重要意义。其创新点在于对现有模型架构的巧妙利用和扩展。

<details>
  <summary>Details</summary>

**Motivation:** 受人类分层思维能力的启发，作者提出可以构建一种分层解码器架构，让不同层同时解码文本。

**Method:** 由于时间和计算资源有限，作者选择将预训练语言模型（如GPT和LLaMA）改编为分层解码器。具体方法是将最后一层的语言头复制到不同的选定中间层，并用不同的任务输入进行微调。

**Result:** 通过详尽的实验验证，这些选择性的中间层可以被调整以生成有意义且合理的内容，并且这种分层解码器范式在分层文本分类、分类引导生成和分层文本生成等多个任务上取得了最先进的性能。

**Conclusion:** 这项研究表明了从头开始预训练一个广义分层推理器的可能性。

> **ai_Abstract:** 本文提出了一种新颖的分层解码器架构，该架构受人类分层思维启发，允许语言模型的不同层同时解码文本。通过将预训练语言模型（如GPT和LLaMA）的最后一层语言头复制到选定的中间层并进行微调，该模型在分层文本分类、分类引导生成和分层文本生成等任务上取得了最先进的性能，并证明了中间层能够生成有意义的内容，为构建广义分层推理器提供了可能性。

> **摘要翻译:** 仅解码器语言模型，如GPT和LLaMA，通常在最后一层进行解码。受人类分层思维能力的启发，我们提出可以构建一个分层解码器架构，让不同层同时解码文本。由于时间和计算资源有限，我们选择将预训练语言模型改编成这种形式的分层解码器。最后一层的语言头被复制到不同的选定中间层，并用不同的任务输入进行微调。通过详尽的实验，我们验证了这些选择性的中间层可以被调整以生成有意义且合理的内容，并且这种分层解码器范式在分层文本分类、分类引导生成和分层文本生成等多个任务上取得了最先进的性能。这项研究表明了从头开始预训练一个广义分层推理器的可能性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [581] [DeFine: Decision-Making with Analogical Reasoning over Factor Profiles](https://arxiv.org/abs/2410.01772)
> *DeFine：基于因子画像的类比推理决策*

*Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 决策, 类比推理, 因子画像, 不确定性, LLM

**Comment:** Proceedings of the 63rd Annual Meeting of the Association for
  Computational Linguistics (ACL 2025), Vienna, Austria

> **TL;DR:** DeFine是一个模块化框架，通过构建概率因子画像并结合类比推理，帮助LLM在处理复杂冗长的语音转录场景时，系统地整合不确定性并做出关键决策。

**AI_Comments:** DeFine通过其模块化设计和对不确定性处理的分离，为LLMs在现实世界复杂场景（如财报电话会议）中的决策能力提供了创新方法。其亮点在于引入了“概率因子画像”和“类比推理”来系统地整合不确定性，这对于需要高精度和鲁棒性决策的领域（如金融和咨询）具有重要意义。该方法有望提升LLMs在理解和应对模糊、冗余信息方面的表现。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在决策方面表现出色，但处理描述复杂场景的冗长语音转录时面临挑战，因为这些转录包含重复、规避和模糊信息。例如，在公司财报电话会议中，高管可能会为了安抚投资者而表达积极的收入展望，尽管未来收益存在不确定性。因此，LLMs在决策时系统地整合这种不确定性至关重要。

**Method:** 本文引入了DeFine，一个模块化框架，它从复杂场景中构建概率因子画像。然后，该框架将这些画像与类比推理相结合，利用过去类似经验的洞察力来指导LLMs在新的情境中做出关键决策。该框架将量化不确定性与将其整合到LLM决策中的任务分离开来。

**Result:** Not mentioned in abstract

**Conclusion:** DeFine框架通过构建概率因子画像并结合类比推理，有效地解决了LLMs在处理复杂场景中不确定性信息时的决策挑战，特别适用于咨询和金融审议等需要在不确定性下做出决策的领域。

> **ai_Abstract:** 本文提出了DeFine框架，旨在解决大型语言模型（LLMs）在处理复杂且冗长的语音转录文本时，难以系统整合不确定性信息进行决策的挑战。DeFine通过构建情景的概率因子画像，并结合类比推理，利用历史经验指导LLMs在不确定性下做出关键决策。该框架将不确定性的量化与决策整合过程分离，特别适用于咨询和金融等需要应对不确定性的领域。

> **摘要翻译:** 大型语言模型（LLMs）因其在长文本语境下进行推理的能力而非常适合决策。然而，在处理描述复杂场景的语音转录时会遇到挑战，因为它们冗长且包含重复、规避和模糊信息。例如，在公司财报电话会议中，一位高管可能会为了安抚投资者而预测积极的收入前景，尽管未来收益存在不确定性。对于LLMs来说，在做决策时系统地整合这种不确定性至关重要。在本文中，我们引入了\textsc{DeFine}，一个模块化框架，它从复杂场景中构建概率因子画像。然后，它将这些画像与类比推理相结合，利用过去类似经验的洞察力来指导LLMs在新情境中做出关键决策。我们的框架将量化不确定性与将其整合到LLM决策中的任务分离开来。这种方法在咨询和金融审议等需要在不确定性下做出决策的领域特别有用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [593] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
> *将开放世界认知建模为概率模型的按需合成*

*Lionel Wong, Katherine M. Collins, Lance Ying, Cedegao E. Zhang, Adrian Weller, Tobias Gersternberg, Timothy O'Donnell, Alexander K. Lew, Jacob D. Andreas, Joshua B. Tenenbaum, Tyler Brooke-Wilson* | **Category: cs.CL, cs.AI, cs.PL** | **Updated: 2025-07-16**

**Keywords:** 开放世界认知, 概率模型, 模型合成, 语言模型, 人类推理

**Comment:** Presented at CogSci 2025

> **TL;DR:** 本文提出了一种模型合成架构（MSA），通过结合语言模型和概率程序来模拟人类在开放世界中按需合成心理模型的能力，并在一个新颖的推理数据集上优于纯语言模型基线。

**AI_Comments:** 本文提出了一种新颖的模型合成架构（MSA），通过结合语言模型和概率程序，为模拟人类在开放世界中的认知能力提供了一条有前景的路径。其创新点在于将语言模型的全局信息检索能力与概率程序的局部模型构建能力相结合，以应对复杂、新颖的推理任务。在评估中，其超越纯语言模型基线的结果，凸显了这种混合方法在处理开放式推理方面的潜力。这对于推动人工智能在通用人工智能（AGI）方向的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当面对新颖情境时，人类能够从广泛的背景知识中调集相关信息进行推理和预测。本文旨在探索是什么使我们能够提取全局相关信息并进行连贯推理，并提出一种计算模型来模拟这种开放世界认知能力。

**Method:** 本文提出了一种“模型合成架构”（MSA）。该架构利用语言模型实现基于全局相关性的信息检索和模型合成，并使用概率程序实现定制的、连贯的世界模型。研究团队在一个名为“模型奥运会”的新型推理数据集上评估了MSA，该数据集围绕体育短片领域构建，旨在测试模型对语言描述的新颖因果结构进行判断、利用大量背景知识并在引入任意新变量的观察下进行开放式推理的能力。

**Result:** 实验结果表明，与仅使用语言模型的基线相比，无论是直接生成还是通过支持模型合成的语言模型的思维链生成，MSA方法都能更好地捕捉人类的判断。

**Conclusion:** 这些结果表明，模型合成架构（MSA）的实现方式可以反映人类在全局相关变量上进行局部连贯推理的能力，为理解和复制开放领域中的人类推理提供了一条途径。

> **ai_Abstract:** 本文提出了一种“模型合成架构”（MSA），旨在计算模拟人类在面对新颖情境时，如何按需合成定制心理模型以进行开放世界认知。该架构结合了语言模型进行全局相关性检索和模型合成，以及概率程序构建连贯的世界模型。通过在一个新颖的“模型奥运会”推理数据集上进行评估，MSA在捕捉人类判断方面优于纯语言模型基线，表明其能够有效模拟人类在开放领域中基于全局相关信息进行局部连贯推理的能力。

> **摘要翻译:** 当面对新颖情境时，人们能够从广泛的背景知识中调集相关考量，并将其用于推理和预测。是什么使我们能够提取全局相关信息并对其进行连贯推理？本文探讨了这样一个假设：人们结合分布式和符号表征来构建针对新颖情境的定制心理模型。我们提出了这种想法的计算实现——一个“模型合成架构”（MSA）——它使用语言模型来实现基于全局相关性的检索和模型合成，并使用概率程序来实现定制的、连贯的世界模型。我们在一个新颖的推理数据集上评估了我们的MSA作为人类判断的模型。该数据集围绕“模型奥运会”体育短片领域构建，通过要求（i）对语言描述的新颖因果结构进行判断；（ii）利用大量背景知识；以及（iii）在引入任意新变量的观察下进行上述两项操作，来测试模型类人、开放式推理的能力。在支持模型合成的语言模型的直接生成和思维链生成两种情况下，我们的MSA方法都比仅使用语言模型的基线更好地捕捉了人类判断。这些结果表明，MSA可以以一种反映人类在全局相关变量上进行局部连贯推理能力的方式实现，为理解和复制开放领域中的人类推理提供了一条途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [602] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
> *搜索引擎结果中的社会和政治框架*

*Amrit Poudel, Tim Weninger* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 搜索引擎, 偏见, 信息两极分化, 政治框架, 用户查询

**Comment:** Accepted to ICWSM 2026

> **TL;DR:** 本研究发现搜索引擎不仅通过内容优先级反映潜在偏见，而且意识形态驱动的用户查询会加剧这些偏见，从而放大特定叙事，加剧信息两极分化。

**AI_Comments:** 该研究揭示了搜索引擎在信息传播中的复杂性和潜在危害，尤其是在加剧社会和政治两极分化方面。其创新之处在于不仅关注搜索引擎本身的偏见，还深入探讨了用户意识形态对偏见的放大作用。这对于理解信息生态系统和设计更公平的搜索算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有研究已广泛探讨搜索偏见的各种维度（如内容优先级、索引偏见、政治两极分化和偏见来源），但一个重要问题仍未得到充分探索：搜索引擎和受意识形态驱动的用户查询如何导致搜索结果中的偏见。

**Method:** 本研究使用政治和社会话题数据集分析了主要搜索引擎的输出。

**Result:** 研究结果表明，搜索引擎不仅以反映潜在偏见的方式优先显示内容，而且意识形态驱动的用户查询会加剧这些偏见，导致特定叙事的放大。此外，不同搜索引擎在内容来源优先级方面存在显著差异。

**Conclusion:** 这些结果表明，搜索引擎可能通过强化意识形态分歧，在塑造公众认知方面发挥关键作用，从而加剧信息两极分化这一更广泛的问题。

> **ai_Abstract:** 本研究探讨了搜索引擎和受意识形态驱动的用户查询如何导致搜索结果中的社会和政治偏见。通过分析主要搜索引擎在政治和社会话题上的输出，研究发现搜索引擎在内容优先级上存在固有偏见，且用户查询会放大这些偏见，导致特定叙事的传播。不同搜索引擎在内容来源优先级上也有显著差异。研究强调搜索引擎在加剧信息两极分化和塑造公众认知方面的关键作用。

> **摘要翻译:** 搜索引擎在影响信息获取和框架方式方面发挥着至关重要的作用，从而塑造了公共话语。尽管先前的研究已广泛探讨了搜索偏见的各种维度——例如内容优先级、索引偏见、政治两极分化和偏见来源——但一个重要问题仍未得到充分探索：搜索引擎和受意识形态驱动的用户查询如何导致搜索结果中的偏见。本研究使用政治和社会话题数据集分析了主要搜索引擎的输出。研究结果表明，搜索引擎不仅以反映潜在偏见的方式优先显示内容，而且意识形态驱动的用户查询会加剧这些偏见，导致特定叙事的放大。此外，不同搜索引擎在内容来源优先级方面存在显著差异。这些结果表明，搜索引擎可能通过强化意识形态分歧，在塑造公众认知方面发挥关键作用，从而加剧信息两极分化这一更广泛的问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [616] [Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information](https://arxiv.org/abs/2410.12774)
> *使用逐点V-可用信息识别多任务学习中的任务分组*

*Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 多任务学习, 任务分组, 逐点V-可用信息, 负迁移, 任务相关性

**Comment:** main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables

> **TL;DR:** 提出了一种基于逐点V-可用信息 (PVI) 的任务相关性度量，用于识别多任务学习中的最佳任务分组，实验证明其能以更少参数获得有竞争力的结果。

**AI_Comments:** 这篇论文的创新点在于提出了一个基于PVI的任务相关性度量，该度量通过量化任务难度来指导多任务学习中的任务分组，有效避免了负迁移。其重要性在于提供了一种量化且可验证的方法来优化多任务学习的性能和参数效率，尤其是在NLP等复杂领域。

<details>
  <summary>Details</summary>

**Motivation:** 多任务学习的成功很大程度上取决于任务分组，不当的分组会导致负迁移。尽管已有很多研究，但定义一个度量标准来识别最佳任务分组仍然是一个挑战。

**Method:** 提出了一种基于逐点V-可用信息 (PVI) 衡量任务难度的任务相关性度量。假设PVI估计没有统计学差异的任务足够相似，可以从联合学习中受益。在15个NLP数据集上进行了全面的实验评估，并与单任务学习器、现有基线方法和大型语言模型（如Llama 2和GPT-4）进行了比较。

**Result:** 结果表明，通过将PVI估计相似的任务进行分组，联合学习器以更少的总参数获得了有竞争力的结果，并且在不同领域表现一致。

**Conclusion:** 该研究验证了基于PVI的任务分组度量在多任务学习中的可行性和有效性，能够识别出有利于联合学习的任务组合，并实现参数效率和性能的一致性。

> **ai_Abstract:** 这篇论文提出了一种基于逐点V-可用信息（PVI）的新型任务相关性度量，用于解决多任务学习中任务分组的挑战。研究假设PVI估计相似的任务适合联合学习。通过在15个NLP数据集上的实验，证明了该方法能够有效地识别任务分组，使得联合学习器在参数更少的情况下，性能与单任务模型、现有基线和大型语言模型（如Llama 2、GPT-4）相比具有竞争力，并在不同领域表现一致。

> **摘要翻译:** 多任务学习的成功在很大程度上取决于任务如何分组。天真地将所有任务或随机的任务集分组在一起可能导致负迁移，使得多任务模型的表现比单任务模型更差。尽管已经做了许多努力来识别任务分组并衡量不同任务之间的相关性，但定义一个度量标准来从众多潜在任务组合中识别出最佳任务分组仍然是一个具有挑战性的研究课题。我们提出了一种基于逐点V-可用信息（PVI）衡量任务难度的任务相关性度量。PVI是最近提出的一种度量标准，用于估计给定模型下数据集包含多少可用信息。我们假设PVI估计没有统计学差异的任务足够相似，可以从联合学习过程中受益。我们进行了全面的实验，以评估该度量在通用、生物医学和临床领域的15个NLP数据集上进行任务分组的可行性。我们将联合学习器的结果与单任务学习器、现有基线方法以及包括Llama 2和GPT-4在内的最新大型语言模型进行了比较。结果表明，通过将PVI估计相似的任务进行分组，联合学习器以更少的总参数获得了有竞争力的结果，并且在不同领域表现一致。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [624] [A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation Classification Using Large Language Models](https://arxiv.org/abs/2503.12989)
> *基于大型语言模型的分类法引导推理的多阶段职业分类框架*

*Palakorn Achananuparp, Ee-Peng Lim, Yao Lu* | **Category: cs.CL, cs.AI, cs.SI** | **Updated: 2025-07-16**

**Keywords:** 职业分类, 大型语言模型, 多阶段框架, 分类法引导推理, 成本效益

**Comment:** Accepted to ICWSM'26

> **TL;DR:** 提出一个多阶段框架，结合分类法引导推理，有效且经济地使用LLM进行职业分类。

**AI_Comments:** 这篇论文的创新点在于提出了一个多阶段框架，并通过集成分类法引导推理来解决LLM在职业分类中对专业分类法知识掌握不足的问题。其重要性在于提供了一个成本效益高且性能优越的解决方案，使得LLM在劳动力市场分析等实际应用中更具可行性和可扩展性，尤其对于资源受限的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 职业分类对劳动力市场分析至关重要，但受数据稀缺和手动标注限制。大型语言模型（LLM）虽有潜力，但其对职业分类法的了解程度不明确，且小型模型表现有限。

**Method:** 提出一个多阶段框架，包含推理、检索和重排序阶段。该框架通过整合分类法引导推理示例，使LLM的输出与分类法知识对齐，从而提高性能。

**Result:** 在大型数据集上的评估表明，所提出的框架不仅增强了职业和技能分类任务的表现，而且为GPT-4o等前沿模型提供了一种成本效益高的替代方案，显著降低了计算成本，同时保持了强大的性能。

**Conclusion:** 该框架为基于大型语言模型的职业分类及相关任务提供了一个实用且可扩展的解决方案。

> **ai_Abstract:** 本研究针对职业分类中数据稀缺和LLM对分类法知识理解不足的问题，提出了一个多阶段框架。该框架结合了推理、检索和重排序，并通过分类法引导推理示例来提升LLM的分类准确性。实验证明，该方法不仅提高了职业和技能分类的性能，还在成本效益上优于现有前沿模型，为LLM在职业分类领域的应用提供了实用且可扩展的方案。

> **摘要翻译:** 自动使用分类法对工作数据进行标准化职业标注，即职业分类，对劳动力市场分析至关重要。然而，这项任务常受数据稀缺和手动标注挑战的阻碍。尽管大型语言模型（LLM）因其广泛的世界知识和上下文学习能力而前景广阔，但它们的有效性取决于其对职业分类法的了解程度，这一点仍不明确。在本研究中，我们评估了LLM从分类法中生成精确分类实体的能力，并强调了它们的局限性，特别是对于小型模型。为了解决这些挑战，我们提出了一个多阶段框架，包括推理、检索和重排序阶段，该框架整合了分类法引导推理示例，通过使输出与分类法知识对齐来提高性能。在大型数据集上的评估表明，我们的框架不仅增强了职业和技能分类任务，而且为GPT-4o等前沿模型提供了一种成本效益高的替代方案，显著降低了计算成本，同时保持了强大的性能。这使其成为LLM职业分类及相关任务的实用且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [631] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
> *首个车臣语开放机器翻译系统*

*Abu-Viskhan A. Umishov, Vladislav A. Grigorian* | **Category: cs.CL** | **Updated: 2025-07-16**

**Keywords:** 机器翻译, 车臣语, 俄语, 开源模型, NLLB-200

**Comment:** 7 pages

> **TL;DR:** 本文介绍了首个针对濒危车臣语与俄语之间翻译的开源机器翻译模型、训练数据集及其评估结果，并探讨了将新语言纳入多语言大型语言模型NLLB-200的微调能力。

**AI_Comments:** 这项工作具有重要意义，因为它为濒危语言车臣语提供了首个开放的机器翻译系统，这对于语言保护和数字化具有积极作用。同时，通过微调现有的大型多语言模型NLLB-200来引入新语言的方法，也为其他低资源语言的机器翻译研究提供了宝贵的经验和范例。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于车臣语是一种濒危语言，且缺乏开放的机器翻译系统，本文旨在开发并发布首个针对车臣语和俄语之间翻译的开源模型。

**Method:** 研究者收集了用于训练和评估的数据集，并探索了将新语言（车臣语）纳入多语言翻译大型语言模型NLLB-200的微调能力。同时发布了翻译模型、平行词汇、短语和句子语料库，以及适应车臣语的多语言句子编码器。

**Result:** 模型在俄语到车臣语翻译方向的BLEU/ChrF++分数为8.34/34.69，在反向翻译的车臣语到俄语方向的分数为20.89/44.55。

**Conclusion:** 本文成功引入了首个针对濒危车臣语和俄语之间翻译的开源模型及相关数据集，展示了将新语言通过微调整合到大型多语言翻译系统中的可行性。

> **ai_Abstract:** 本文首次提出了一个针对濒危车臣语与俄语之间翻译的开源机器翻译系统。研究团队收集并发布了训练和评估所需的数据集，并探讨了如何通过微调将车臣语整合到大型多语言模型NLLB-200中。该模型取得了具体的BLEU和ChrF++分数，并随附发布了相关的语料库和多语言句子编码器，为车臣语的机器翻译提供了重要的基础资源。

> **摘要翻译:** 我们介绍了首个用于濒危车臣语和俄语之间翻译的开源模型，以及为训练和评估该模型而收集的数据集。我们探索了将新语言纳入多语言翻译大型语言模型系统NLLB-200的微调能力。我们的模型在俄语到车臣语方向和反向翻译的BLEU/ChrF++分数分别为8.34/34.69和20.89/44.55。翻译模型的发布伴随着平行词汇、短语和句子语料库以及适应车臣语的多语言句子编码器的分发。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [637] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
> *模仿游戏：图灵机模仿器是长度泛化推理器*

*Zhouqi Hua, Wenwei Zhang, Chengqi Lyu, Yuzhe Gu, Songyang Gao, Kuikun Liu, Kai Chen* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 长度泛化, 大型语言模型, 图灵机, 思维链, 合成数据

**Comment:** 

> **TL;DR:** 提出图灵机模仿学习（TAIL），通过模仿图灵机执行过程生成思维链数据，显著提升大型语言模型的长度泛化能力。

**AI_Comments:** 这项工作通过将图灵机概念引入大型语言模型的训练，为解决LLM的长度泛化问题提供了一个创新且通用的方向。其创新点在于利用图灵机执行过程生成高质量的合成思维链数据，并通过显式机制模拟图灵机的读写行为，这有助于模型更好地理解和执行复杂的可计算任务。该方法证明了在LLM中融入计算理论基础的潜力，对于推动LLM在通用推理能力上的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决基于Transformer的大型语言模型在长度泛化方面的核心挑战，现有数据驱动方法任务特异性强且性能有限，寻求更通用的可计算推理问题解决方案。

**Method:** 提出图灵机模仿学习（TAIL），通过计算机程序合成模仿图灵机执行过程的思维链（CoT）数据。该方法将推理步骤线性扩展为原子状态以缓解捷径学习，并引入显式内存获取机制以降低动态和长距离数据访问的难度。

**Result:** TAIL显著提高了Qwen2.5-7B在各种任务上的长度泛化能力和性能，仅使用合成数据就超越了现有方法和DeepSeek-R1。实验表明，图灵机的关键概念对于TAIL的长度泛化是不可或缺的，模型在注意力层中表现出与图灵机特性一致的读写行为。

**Conclusion:** 本工作提出了一种通过合成数据学习大型语言模型推理的有前景的方向，并强调了图灵机关键概念在提升模型长度泛化能力中的重要性。

> **ai_Abstract:** 本文提出图灵机模仿学习（TAIL），旨在提升大型语言模型在可计算推理任务上的长度泛化能力。TAIL通过合成模仿图灵机执行过程的思维链数据，并引入原子状态扩展和显式内存获取机制，有效缓解了捷径学习和数据访问难题。实验结果表明，TAIL在合成数据集上显著优于现有方法，并揭示了图灵机关键概念对模型长度泛化的重要性。

> **摘要翻译:** 长度泛化，即解决比训练期间观察到的序列更长序列问题的能力，对基于Transformer的大型语言模型（LLM）构成了核心挑战。尽管现有研究主要集中于算术运算和符号操作任务的数据驱动方法，但这些方法往往是任务特定的，整体性能有限。为了寻求更通用的解决方案，本文关注更广泛的可计算推理问题，即算法可以解决的问题，因此也可以由图灵机解决。从这个角度出发，本文提出了图灵机模仿学习（TAIL）来提高LLM的长度泛化能力。TAIL通过计算机程序合成模仿图灵机执行过程的思维链（CoT）数据，该数据将推理步骤线性扩展为原子状态以缓解捷径学习，并引入显式内存获取机制以降低基本操作中动态和长距离数据访问的难度。为了验证TAIL的可靠性和普适性，我们构建了一个具有挑战性的合成数据集，涵盖8类算法和18个任务。TAIL在不使用额外技巧的情况下，仅使用合成数据就显著提高了Qwen2.5-7B在各种任务上的长度泛化能力和性能，超越了现有方法和DeepSeek-R1。实验结果表明，图灵机中的关键概念，而非思维方式，对于TAIL的长度泛化是不可或缺的，通过TAIL，模型在注意力层中表现出与图灵机特性一致的读写行为。这项工作为未来从合成数据中学习LLM推理提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [639] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
> *这只是幻想吗？语言模型表征反映了人类对事件合理性的判断*

*Michael A. Lepori, Jennifer Hu, Ishita Dasgupta, Roma Patel, Thomas Serre, Ellie Pavlick* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 语言模型, 模态分类, 可解释性, 人类判断, 模态差异向量

**Comment:** 

> **TL;DR:** 语言模型能够可靠地判断句子的模态类别，其内部表征反映了人类的判断。

**AI_Comments:** 这项研究通过引入“模态差异向量”的概念，并利用机制可解释性技术，为理解语言模型内部如何处理和表征模态信息提供了新颖且深入的视角。其创新之处在于不仅证明了语言模型具备可靠的模态判断能力，还揭示了这种能力的发展规律，并进一步将其与人类认知行为关联起来，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型在执行任务时需要辨别句子的模态类别（如可能性、不可能性），但近期研究对此能力提出了质疑。

**Method:** 本研究通过识别语言模型内部区分模态类别的线性表征（即模态差异向量），并分析这些向量来评估语言模型的模态判断能力。此外，研究还通过将模态差异向量与人类对可解释特征的评分相关联，探索其与人类模态分类行为的联系。

**Result:** 1. 模态差异向量揭示了语言模型拥有比先前报告更可靠的模态分类判断能力。2. 模态差异向量随着模型能力的提升（训练步骤、层数、参数量）以一致的顺序出现。3. 语言模型激活中识别出的模态差异向量可以用于建模细粒度的人类分类行为。

**Conclusion:** 本研究通过机制可解释性技术深入理解了语言模型的模态分类能力，并有望增进对人类模态分类的理解。

> **ai_Abstract:** 本研究探讨了语言模型对句子模态类别的判断能力，解决了此前对此能力存在的质疑。通过识别和分析语言模型内部的“模态差异向量”，研究发现语言模型具有比预期更可靠的模态分类判断能力，并且这些向量的出现与模型能力的提升同步。此外，这些向量还能有效模拟人类对模态的细粒度判断，为理解人类认知提供了新视角。

> **摘要翻译:** 语言模型（LMs）被用于各种任务，从问答到撰写奇幻故事。为了可靠地完成这些任务，语言模型必须能够辨别句子的模态类别（即，它描述的是可能、不可能、完全荒谬等）。然而，最近的研究（Michaelov et al., 2025; Kauf et al., 2023）对语言模型根据模态对句子进行分类的能力提出了质疑。在这项工作中，我们识别了在各种语言模型中区分模态类别的线性表征，即模态差异向量。对模态差异向量的分析表明，语言模型拥有比先前报告更可靠的模态分类判断能力。此外，我们发现模态差异向量随着模型能力的提升（即通过训练步骤、层数和参数量）以一致的顺序出现。值得注意的是，我们发现语言模型激活中识别出的模态差异向量可以用于建模细粒度的人类分类行为。这可能为人类参与者如何区分模态类别提供了一个新颖的视角，我们通过将沿模态差异向量的投影与人类参与者对可解释特征的评分相关联来探索这一点。总之，我们利用机制可解释性技术对语言模型模态分类获得了新的见解，并有可能增进我们对人类模态分类的理解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [662] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
> *大型语言模型上下文工程综述*

*Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li, Zhong-Zhi Li, Duzhen Zhang, Chenlin Zhou, Jiayi Mao, Tianze Xia, Jiafeng Guo, Shenghua Liu* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 上下文工程, 大型语言模型, 上下文管理, 检索增强生成, 研究空白

**Comment:** ongoing work; 165 pages, 1401 citations

> **TL;DR:** 本综述介绍了上下文工程，这是一个超越简单提示设计的学科，旨在系统优化LLM的信息载荷。它提供了一个全面的分类法，并揭示了模型在理解复杂上下文方面表现出色，但在生成同样复杂的长篇输出方面存在显著局限性。

**AI_Comments:** 这篇综述的重要性在于它首次将“上下文工程”正式化为一个独立的学科，并提供了全面的分类和技术路线图。其创新之处在于系统性地梳理了上下文处理的各个方面，从基础组件到高级系统集成。最重要的是，它明确指出了当前LLM在复杂长篇输出生成方面的局限性这一关键研究挑战，为未来的研究指明了方向，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的性能从根本上由推理过程中提供的上下文信息决定。本综述旨在正式介绍上下文工程，一个超越简单提示设计、涵盖LLMs信息载荷系统优化的学科。

**Method:** 本综述提出了一个全面的分类法，将上下文工程分解为基础组件（上下文检索与生成、上下文处理和上下文管理）以及集成这些组件的复杂系统实现（检索增强生成RAG、内存系统和工具集成推理、多智能体系统）。通过对1300多篇研究论文的系统分析。

**Result:** 本综述建立了上下文工程领域的技术路线图，并揭示了一个关键的研究空白：模型能力之间存在根本性不对称。当前模型在理解复杂上下文方面表现出卓越的熟练度，但在生成同样复杂的长篇输出方面表现出明显的局限性。

**Conclusion:** 本综述为推进上下文感知AI的研究人员和工程师提供了一个统一的框架。解决模型生成复杂长篇输出的局限性是未来研究的明确优先事项。

> **ai_Abstract:** 本综述系统地分析了大型语言模型（LLM）的上下文工程，将其定义为一个超越简单提示设计的正式学科，旨在优化LLM的信息载荷。文章提出了一个全面的分类法，分解了上下文工程的基础组件（检索、生成、处理、管理）及其复杂的系统实现（RAG、内存系统、多智能体系统）。通过对1300多篇论文的分析，该综述不仅绘制了技术路线图，还指出了一个关键研究空白：LLM在理解复杂上下文方面能力卓越，但在生成同样复杂的长篇输出方面存在显著限制，并强调这是未来研究的重点。

> **摘要翻译:** 大型语言模型（LLM）的性能从根本上由推理过程中提供的上下文信息决定。本综述介绍了上下文工程，这是一门超越简单提示设计、涵盖LLM信息载荷系统优化的正式学科。我们提出了一个全面的分类法，将上下文工程分解为其基础组件以及将它们集成到智能系统中的复杂实现。我们首先考察了基础组件：上下文检索与生成、上下文处理和上下文管理。然后，我们探讨了这些组件如何通过架构集成来创建复杂的系统实现：检索增强生成（RAG）、内存系统和工具集成推理，以及多智能体系统。通过对1300多篇研究论文的系统分析，我们的综述不仅为该领域建立了技术路线图，而且揭示了一个关键的研究空白：模型能力之间存在根本性的不对称。尽管当前模型在先进上下文工程的增强下，在理解复杂上下文方面表现出卓越的熟练度，但它们在生成同样复杂的长篇输出方面表现出明显的局限性。解决这一差距是未来研究的明确优先事项。最终，本综述为推进上下文感知AI的研究人员和工程师提供了一个统一的框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [665] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
> *自动评估南非荷兰语和科萨语儿童的口头叙事*

*R. Louw, E. Sharratt, F. de Wet, C. Jacobs, A. Smith, H. Kamper* | **Category: cs.CL, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 口头叙事评估, 自动语音识别, 大型语言模型, 学龄前儿童, 南非荷兰语, 科萨语

**Comment:** Accepted to SLaTE 2025

> **TL;DR:** 该研究提出了一个自动评估南非荷兰语和科萨语学龄前儿童口头叙事和理解能力的系统，该系统基于ASR和机器学习模型，其中LLM表现优于线性模型，且与人类专家相当。

**AI_Comments:** 该论文创新性地将ASR和LLM应用于儿童口头叙事能力的自动评估，特别是在资源相对较少的南非语言（阿非利卡语和科萨语）中，具有重要的实践意义。它能够减轻教师负担，提高早期干预的效率。然而，其对ASR准确性的依赖以及LLM模型的可解释性可能是未来需要关注的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 学龄前儿童叙事和理解能力的发展对日后识字至关重要，但幼儿园教师在大型班级中难以准确识别需要干预的学生。

**Method:** 该系统首先使用自动语音识别（ASR），然后通过机器学习评分模型预测叙事和理解分数。在评分预测的转录文本时，比较了线性模型和大型语言模型（LLM），以LLM为基础的系统表现更优。

**Result:** LLM-based系统在大多数情况下优于线性模型，但线性系统尽管简单却具有竞争力。LLM-based系统在标记需要干预的儿童方面与人类专家相当。

**Conclusion:** 该研究为课堂中的自动口头评估奠定了基础，使教师能够有更多精力专注于儿童学习的个性化支持。

> **ai_Abstract:** 本文提出了一个自动评估南非荷兰语和科萨语学龄前儿童口头叙事和理解能力的系统，旨在帮助教师识别需要干预的学生。该系统结合了自动语音识别和机器学习评分模型，并比较了线性模型和大型语言模型（LLM）在评分预测转录文本上的表现。研究结果表明，基于LLM的系统在多数情况下优于线性模型，且在识别需要干预的儿童方面与人类专家水平相当，为课堂中的自动化口语评估提供了可行方案。

> **摘要翻译:** 幼儿时期叙事和理解能力的发展对日后识字至关重要。然而，大型学前班的教师难以准确识别需要干预的学生。我们提出了一个自动评估南非荷兰语和科萨语学龄前儿童口头叙事能力的系统。该系统使用自动语音识别，然后通过机器学习评分模型预测叙事和理解分数。对于预测转录文本的评分，我们比较了线性模型和大型语言模型（LLM）。基于LLM的系统在大多数情况下优于线性模型，但线性系统尽管简单却具有竞争力。基于LLM的系统在标记需要干预的儿童方面与人类专家相当。我们为课堂中的自动口头评估奠定了基础，使教师能够有更多精力专注于儿童学习的个性化支持。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [673] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
> *使用大型语言模型改进过量死亡监测中的药物识别*

*Arthur J. Funnell, Panayiotis Petousis, Fabrice Harel-Canada, Ruby Romero, Alex A. T. Bui, Adam Koncsol, Hritika Chaturvedi, Chelsea Shover, David Goodman-Meza* | **Category: cs.CL, q-bio.QM, I.2.7; J.3** | **Updated: 2025-07-16**

**Keywords:** 药物识别, 过量死亡监测, 大型语言模型, BioClinicalBERT, 自然语言处理

**Comment:** 30 pages, 1 figure, 4 tables, 2 supplemental figures, 4 supplemental
  tables, submitted to Journal of Forensic Sciences (JFS)

> **TL;DR:** 本研究利用大型语言模型，特别是微调的BioClinicalBERT，显著提高了从自由文本报告中识别过量死亡药物的准确性和效率，优于传统方法。

**AI_Comments:** 该论文的创新点在于将先进的大型语言模型应用于药物过量死亡监测这一关键公共卫生领域，解决了传统人工编码效率低下和信息丢失的问题。BioClinicalBERT的优异表现凸显了领域特定预训练模型在处理专业文本方面的强大能力。这项研究的重要性在于其提供了一个高度准确和可扩展的解决方案，有望显著加速药物过量监测工作流程，实现近实时趋势检测，对公共卫生决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 美国药物相关死亡率上升，特别是芬太尼，需要及时准确的监测。然而，关键的过量数据常埋藏在法医报告的自由文本中，导致编码为ICD-10时出现延迟和信息丢失。现有自然语言处理（NLP）模型在该领域的应用有限。

**Method:** 研究使用了来自美国多个司法管辖区2020年的35,433份死亡记录进行模型训练和内部测试，并使用2023-2024年3,335份新记录的独立数据集进行外部验证。评估了多种NLP方法，包括传统的单标签和多标签分类器、微调的编码器-only语言模型（如BERT和BioClinicalBERT）以及现代的解码器-only大型语言模型（如Qwen 3和Llama 3）。模型性能通过宏平均F1分数评估，并计算95%置信区间。

**Result:** 微调的BioClinicalBERT模型在内部测试集上取得了接近完美的性能，宏F1分数≥0.998。外部验证证实了其鲁棒性（宏F1=0.966），优于传统的机器学习、通用领域BERT模型和各种解码器-only大型语言模型。

**Conclusion:** NLP模型，特别是像BioClinicalBERT这样经过微调的临床变体，为从自由文本报告中进行过量死亡分类提供了一种高度准确和可扩展的解决方案。这些方法可以显著加速监测工作流程，克服手动ICD-10编码的局限性，并支持近乎实时的药物滥用趋势检测。

> **ai_Abstract:** 本研究旨在通过利用大型语言模型改进过量死亡监测中药物的识别效率和准确性，以应对美国药物相关死亡率上升的挑战。研究使用了大规模死亡记录数据集，评估了多种自然语言处理（NLP）方法，包括传统的分类器、微调的BERT系列模型和现代的解码器-only大型语言模型。结果显示，经过微调的BioClinicalBERT模型表现出色，在内部和外部验证中均取得了高F1分数，显著优于其他方法。这表明NLP技术，特别是针对临床文本优化的模型，能够提供一个准确且可扩展的解决方案，以加速药物过量监测并支持实时趋势检测。

> **摘要翻译:** 美国药物相关死亡率的上升，主要由芬太尼驱动，需要及时准确的监测。然而，关键的过量数据通常隐藏在自由文本的法医报告中，导致在编码为ICD-10（国际疾病分类）时出现延迟和信息丢失。自然语言处理（NLP）模型可以自动化并增强过量监测，但之前的应用有限。本研究使用了一个包含2020年美国多个司法管辖区35,433份死亡记录的数据集进行模型训练和内部测试。外部验证使用了一个新的、独立的2023-2024年3,335份记录的数据集进行。评估了多种NLP方法，用于从非结构化的死亡证明文本中分类特定药物的参与情况。这些方法包括传统的单标签和多标签分类器，以及微调的仅编码器语言模型，如Transformer的双向编码器表示（BERT）和BioClinicalBERT，以及当代的仅解码器大型语言模型，如Qwen 3和Llama 3。模型性能使用宏平均F1分数进行评估，并计算95%置信区间以量化不确定性。微调的BioClinicalBERT模型实现了近乎完美的性能，在内部测试集上宏F1分数≥0.998。外部验证证实了其鲁棒性（宏F1=0.966），优于传统的机器学习、通用领域BERT模型和各种仅解码器大型语言模型。NLP模型，特别是像BioClinicalBERT这样经过微调的临床变体，为从自由文本报告中进行过量死亡分类提供了一种高度准确和可扩展的解决方案。这些方法可以显著加速监测工作流程，克服手动ICD-10编码的局限性，并支持近乎实时的突发药物使用趋势检测。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [686] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
> *比较苹果和橘子：一个关于大型语言模型幽默理解的数据集与分析，从传统双关语到时事笑话*

*Tyler Loakman, William Thorne, Chenghua Lin* | **Category: cs.CL** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 幽默理解, 计算幽默, 数据集, 笑话解释

**Comment:** 

> **TL;DR:** 本研究探讨大型语言模型（LLMs）解释幽默的能力是否取决于幽默形式。通过构建包含双关语和时事笑话的600条数据集，并测试LLMs的零样本能力，发现现有LLMs无法可靠解释所有类型的幽默，突显了计算幽默研究的局限性。

**AI_Comments:** 该论文创新性地构建了一个多样化的幽默理解数据集，超越了传统计算幽默研究对简单双关语的狭隘关注。其重要性在于揭示了当前大型语言模型在理解和解释复杂幽默（尤其是需要世界知识的幽默）方面的显著局限性。这为未来计算幽默领域的研究指明了方向，即需要开发更深层次的推理和世界知识整合能力，而不仅仅是模式匹配。

<details>
  <summary>Details</summary>

**Motivation:** 现有的计算幽默研究几乎只关注简短的、基于双关语的笑话，而幽默是一种复杂的语言形式，源于生活的方方面面。本研究旨在探究大型语言模型（LLMs）解释幽默的能力是否取决于特定的幽默形式。

**Method:** 研究团队构建了一个包含600个笑话的数据集，涵盖四种笑话类型：异形同音双关语、同形同音双关语、当代网络幽默和时事笑话。这些笑话的理解需要超越“常识”的世界知识，例如新闻事件和流行文化。研究人员手动编写了高质量的解释。利用这个数据集，研究团队比较了一系列大型语言模型在零样本条件下准确、全面解释不同类型笑话的能力。

**Result:** 研究发现，所有测试的模型（包括推理模型）都无法可靠地为所有笑话类型生成足够的解释。

**Conclusion:** 研究结果突显了幽默解释任务中存在的关键研究空白，并进一步强调了大多数计算幽默工作过于侧重简单笑话形式的局限性。

> **ai_Abstract:** 本研究通过构建一个包含双关语、网络幽默和时事笑话等四种类型共600条笑话的数据集，旨在评估大型语言模型（LLMs）解释不同幽默形式的能力。研究发现，即使是先进的LLMs也无法可靠地解释所有类型的幽默，特别是那些需要世界知识的复杂笑话。这揭示了当前计算幽默研究在处理多样化幽默形式方面的局限性，并指出了未来研究的方向。

> **摘要翻译:** 幽默作为一种复杂的语言形式，源于生活的方方面面，而现有的计算幽默研究几乎只专注于简短的、基于双关语的笑话。在这项工作中，我们调查了大型语言模型（LLMs）解释幽默的能力是否取决于特定的幽默形式。我们比较了模型在简单双关语和更复杂的时事幽默上的表现，后者需要现实世界实体和事件的知识。为此，我们策划了一个包含600个笑话的数据集，分为四种笑话类型，并手动编写了高质量的解释。这些笑话包括异形同音和同形同音双关语、当代网络幽默和时事笑话，它们的理解依赖于超越“常识”的推理，而是植根于有关新闻事件和流行文化的世界知识。利用这个数据集，我们比较了一系列大型语言模型在零样本条件下准确、全面解释不同类型笑话的能力，从而识别了幽默解释任务中的关键研究空白。我们发现，所有测试的模型（包括推理模型）都无法可靠地为所有笑话类型生成足够的解释，这进一步突显了大多数计算幽默工作过于侧重简单笑话形式的狭隘性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [694] [IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization](https://arxiv.org/abs/2411.06208)
> *IOPO：通过输入-输出偏好优化增强大型语言模型复杂指令遵循能力*

*Xinghua Zhang, Haiyang Yu, Cheng Fu, Fei Huang, Yongbin Li* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 指令遵循, 偏好优化, IOPO, TRACE

**Comment:** ACL 2025

> **TL;DR:** 本文提出了IOPO方法和TRACE基准，旨在解决大型语言模型在遵循复杂指令方面数据和算法不足的问题，并通过实验证明了其显著的性能提升。

**AI_Comments:** 本文的创新之处在于同时解决了复杂指令遵循的数据稀缺问题（通过TRACE基准）和算法不足问题（通过IOPO方法）。IOPO独特地结合了输入和输出偏好优化，使其在复杂指令场景下表现优异，对LLM在更高级、更复杂的应用中的发展具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）的应用中，模型准确遵循指令的能力至关重要，特别是随着指令复杂性的快速增加。然而，当前面临两个主要挑战：一是缺乏足够的复杂指令评估数据；二是缺少专门用于提升LLM复杂指令遵循能力的算法。

**Method:** 本文引入了TRACE基准，该基准包含12万训练数据和1千评估数据，用于提升和评估LLM的复杂指令遵循能力。此外，提出了一种名为IOPO（Input-Output Preference Optimization）的对齐方法，该方法同时考虑输入和输出偏好对，使LLM能够快速对齐响应偏好并细致探索指令偏好。

**Result:** 在域内和域外数据集上的大量实验证实了IOPO的有效性。与SFT和DPO相比，IOPO在域内数据上分别实现了8.15%和2.18%的提升，在域外数据上分别实现了6.29%和3.13%的提升。

**Conclusion:** 本文提出的IOPO方法和TRACE基准有效提升了大型语言模型遵循复杂指令的能力，解决了现有方法在数据和算法上的局限性。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在遵循复杂指令方面面临的数据和算法不足问题，提出了两项关键贡献：首先，引入了TRACE基准，这是一个包含大量训练和评估数据的复杂指令遵循能力数据集；其次，提出了一种新颖的IOPO（输入-输出偏好优化）对齐方法，该方法通过同时考虑输入和输出偏好对，增强了LLM对指令和响应的理解与对齐。实验结果表明，IOPO在域内和域外数据集上均显著优于SFT和DPO，证明了其在提升LLM复杂指令遵循能力方面的有效性。

> **摘要翻译:** 在大型语言模型（LLMs）领域，模型准确遵循指令的能力至关重要，因为越来越多的代理和应用利用LLM进行构建，指令的复杂性正在迅速增加。然而，一方面，复杂的指令评估数据量有限；另一方面，没有专门的算法来提高遵循复杂指令的能力。为此，本文引入了TRACE，一个用于提高和评估复杂指令遵循能力的基准，它包含12万训练数据和1千评估数据。此外，我们提出了IOPO（输入-输出偏好优化）对齐方法，该方法同时考虑输入和输出偏好对，使LLM不仅能快速对齐响应偏好，还能细致探索指令偏好。在域内和域外数据集上的大量实验证实了IOPO的有效性，与SFT和DPO相比，在域内数据上分别提升了8.15%、2.18%，在域外数据上分别提升了6.29%、3.13%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [700] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
> *MRT在IberLEF-2025 PRESTA任务中：多步骤最大化表格恢复*

*Maximiliano Hormazábal Lagos, Álvaro Bueno Sáez, Héctor Cerezo-Costas, Pedro Alonso Doval, Jorge Alcalde Vesteiro* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 表格问答, 大型语言模型, 代码生成, IberLEF 2025, 西班牙语

**Comment:** Accepted as an official challenge paper in the PRESTA: Questions and
  Answers over Tabular Data shared task at IberLEF 2025, colocated with the
  41st SEPLN Conference in Zaragoza, Spain

> **TL;DR:** 本文介绍了在IberLEF 2025 PRESTA任务中，通过LLMs生成Python代码来处理表格并回答问题的方法，实现了85%的准确率。

**AI_Comments:** 该论文展示了LLMs在复杂数据提取和问答任务中的潜力，特别是通过代码生成实现多步骤操作。其创新点在于将自然语言指令转化为可执行代码以处理结构化数据，并针对特定任务进行优化。85%的准确率表明了该方法在西班牙语表格问答方面的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 参与IberLEF 2025 PRESTA任务，解决西班牙语表格问答问题，并最大化从表格中恢复信息。

**Method:** 采用LLMs生成Python代码，用于过滤和处理表格以获取答案。该方法是多步骤的，包括分析表格内容、选择有用列、生成自然语言指令、将指令翻译成代码、运行代码以及处理错误。使用了开源LLMs和优化过的精细提示。

**Result:** 在任务中取得了85%的准确率。

**Conclusion:** 通过多步骤LLMs生成代码的方法，可以有效处理西班牙语表格问答任务，并达到较高的准确率。

> **ai_Abstract:** 本文提出了一种针对IberLEF 2025 PRESTA任务的解决方案，该方案利用大型语言模型（LLMs）生成Python代码，通过多步骤流程（包括表格分析、列选择、指令生成、代码转换和错误处理）来从西班牙语表格中提取信息并回答问题。该方法基于Semeval 2025的MRT实现，并取得了85%的准确率。

> **摘要翻译:** 本文介绍了我们参加IberLEF 2025 PRESTA任务（西班牙语表格问答）的方法。我们的解决方案通过使用大型语言模型（LLMs）生成Python代码来获取问题的答案，该代码用于过滤和处理表格。该解决方案是从Semeval 2025相关任务的MRT实现演变而来。该过程包括多个步骤：分析和理解表格内容、选择有用的列、生成自然语言指令、将这些指令翻译成代码、运行代码以及处理潜在的错误或异常。这些步骤使用了开源LLMs以及针对每个步骤优化过的精细提示。通过这种方法，我们在任务中取得了85%的准确率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [3] [An EPTAS for multiprocessor scheduling with rejection under a machine cost constraint](https://arxiv.org/abs/2507.12635)
> *具有机器成本约束的带拒绝多处理器调度问题的EPTAS*

*Mingyang Gong, Brendan Mumey* | **Category: cs.DS, F.2.2** | **Updated: 2025-07-16**

**Keywords:** 多处理器调度, 拒绝, 机器成本, 近似算法, EPTAS

**Comment:** 

> **TL;DR:** 研究了带机器成本约束的带拒绝多处理器调度问题，提出了一个2-近似算法和一个EPTAS（当机器数量m为常数时）。

**AI_Comments:** 这篇论文通过引入机器成本约束和拒绝选项，扩展了传统的多处理器调度问题。其创新点在于为该复杂问题提供了两种不同条件下的近似算法，特别是当机器数量固定时能达到EPTAS，这表明在特定条件下可以获得高质量的近似解。

<details>
  <summary>Details</summary>

**Motivation:** 解决多处理器调度问题中，如何在考虑任务拒绝惩罚和机器成本限制的同时，优化调度结果。

**Method:** 提出了一个简单的2-近似算法，并为机器数量m为固定常数的情况提供了EPTAS (Efficient Polynomial Time Approximation Scheme)。

**Result:** 获得了一个2-近似算法，并且当机器数量m为固定常数时，实现了EPTAS。

**Conclusion:** 在机器成本约束下，带拒绝多处理器调度问题可以被有效地近似解决，尤其是在机器数量固定时可以达到EPTAS。

> **ai_Abstract:** 这篇论文探讨了在机器成本约束下的多处理器调度与拒绝问题。该问题旨在最小化已接受作业的完工时间和被拒绝作业的罚款总和，同时遵守总机器成本限制。作者提出了一个2-近似算法，并进一步证明了当机器数量固定时，可以达到一个高效多项式时间近似方案（EPTAS）。

> **摘要翻译:** 我们研究了在机器成本约束下的多处理器调度与拒绝问题。在该问题中，每个作业要么被拒绝并支付拒绝罚款，要么被接受并调度到其中一台机器上进行处理。机器成本与在其上调度的作业的总处理时间成正比。该问题的目标是最小化已接受作业的完工时间加上被拒绝作业的总拒绝罚款，同时总机器成本不超过给定的上限。我们为该问题提出了一个简单的2-近似算法，并且当机器数量m是一个固定常数时，我们实现了一个EPTAS。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [49] [Computing and Bounding Equilibrium Concentrations in Athermic Chemical Systems](https://arxiv.org/abs/2507.12699)
> *非热化学系统中平衡浓度的计算与界定*

*Hamidreza Akef, Minki Hhan, David Soloveichik* | **Category: cs.DS, q-bio.MN, G.2.1; J.2** | **Updated: 2025-07-17**

**Keywords:** 平衡浓度, 非热系统, 迭代算法, 脱靶聚合物, DNA纳米技术

**Comment:** To be published in DNA31 (31st International Conference on DNA
  Computing and Molecular Programming)

> **TL;DR:** 开发了一种用于非热化学系统（如DNA纳米技术）中计算和界定聚合物平衡浓度（特别是脱靶聚合物上限）的迭代算法。

**AI_Comments:** 这项工作创新性地在非热设置下，通过迭代算法解决了分子复合物平衡浓度计算的难题，并提供了脱靶聚合物浓度的上限界定方法，对DNA纳米技术等领域（如降低DNA逻辑中的泄漏）具有重要意义，其理论贡献在于连接了组合论证与实值浓度。

<details>
  <summary>Details</summary>

**Motivation:** 分子复合物的平衡浓度计算通常难以解析，需要数值方法。

**Method:** 在非热环境中，开发了一种迭代算法来分配聚合物浓度以满足详细平衡，旨在使目标聚合物浓度高，脱靶聚合物浓度低。该方法还提供了脱靶聚合物浓度的上限洞察，将离散配置的组合论证与实值浓度联系起来。

**Result:** 该算法提供了关于脱靶聚合物浓度上限的有效见解，成功应用于降低DNA逻辑和信号传播中的泄漏。

**Conclusion:** 该研究为当配置由熵力区分时，平衡浓度的设计和验证提供了一个新框架。

> **ai_Abstract:** 本研究关注非热化学系统中分子复合物（聚合物）的平衡浓度计算问题，该问题通常难以解析。论文提出了一种迭代算法，用于在聚合物-单体层面分配聚合物浓度以满足详细平衡，旨在提高目标聚合物浓度并降低脱靶聚合物浓度。该算法特别适用于DNA纳米技术中的强键合（基于域）机制。即使不直接执行，该算法也能有效洞察脱靶聚合物浓度的上限，将离散配置的组合论证与实值浓度联系起来。研究结果为在熵力区分配置时，平衡浓度的设计和验证提供了一个新框架，并通过应用于降低DNA逻辑和信号传播中的泄漏进行了验证。

> **摘要翻译:** 计算分子复合物的平衡浓度通常在分析上是棘手的，需要数值方法。在这项工作中，我们关注聚合物-单体层面，其中不可分割的分子（单体）结合形成复合物（聚合物）。我们不为每种聚合物使用自由能参数，而是专注于所有相互作用都保持焓的非热设置。这种设置与DNA纳米技术中当链可以以不同方式结合但总是以最大整体键合的强键合（基于域）机制相符——并且与热力学结合网络（TBNs）模型中的饱和配置一致。在此背景下，我们开发了一种迭代算法，用于分配聚合物浓度以满足详细平衡，其中目标（期望）聚合物浓度高，脱靶（不期望）聚合物浓度低。即使不直接执行，我们的算法也能为脱靶聚合物浓度的上限提供有效见解，将关于离散配置（例如TBN模型中的配置）的组合论证与实值浓度联系起来。最后，我们介绍了该方法在降低DNA逻辑和信号传播中的泄漏方面的应用。我们的结果为当配置由熵力区分时，平衡浓度的设计和验证提供了一个新框架。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [94] [Splittable Spanning Trees and Balanced Forests in Dense Random Graphs](https://arxiv.org/abs/2507.12707)
> *稠密随机图中的可分裂生成树和平衡森林*

*David Gillman, Jacob Platnick, Dana Randall* | **Category: cs.DS, F.2.2; G.2.1** | **Updated: 2025-07-17**

**Keywords:** 公平划分, 生成树, 稠密随机图, 随机森林, ReCom算法

**Comment:** 13 pages, 2 figures

> **TL;DR:** 本文证明了稠密随机图上的生成树具有逆多项式概率可分裂，从而可以在此类图上高效采样公平划分。此外，还揭示了ReCom算法在公平划分问题中存在比已知更广泛的问题。

**AI_Comments:** 本文的创新点在于将可分裂生成树的概念扩展到了稠密随机图，从而为一类新的图结构提供了高效的公平划分采样算法，补充了现有对网格图的研究。其重要性不仅在于提供了理论上的保证，还在于为实际应用中的公平划分问题提供了更广泛的工具。此外，论文对ReCom算法的深入批判和揭示其潜在的严重缺陷，对于理解现有算法的局限性、指导未来研究方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图的加权公平划分因其在重新划分选区、网络算法和图像分解等多种应用中的重要性而受到关注。根据生成树度量进行划分，因倾向于更紧凑的块而具有数学和实践意义。

**Method:** 论文通过理论证明，表明稠密随机图上的生成树具有逆多项式概率可分裂，这为高效、精确地采样公平划分提供了一种新的方法。此外，还利用这些证明保证了森林上“上下行走”的快速近似均匀采样。论文还通过构建图族来分析并揭示了ReCom算法的局限性。

**Result:** 1. 证明了稠密随机图上的生成树具有逆多项式概率可分裂，使得公平划分可以在这类图上高效精确地采样。2. 这些证明也保证了森林上“上下行走”的快速近似均匀采样，提供了另一种可证明高效的随机方法来生成公平划分。3. 揭示了ReCom算法在公平划分问题中存在比以前已知更广泛的问题，即使在之前认为更有希望的特殊情况下也是如此。4. 提出了一个图族，其中ReCom算法的马尔可夫链在需要完美公平时不可约，而在允许一个顶点不平衡时，拒绝采样步骤可能需要指数时间。

**Conclusion:** 本文扩展了可分裂生成树在稠密随机图上的适用性，为公平划分提供了新的高效采样方法，并深入分析并揭示了现有ReCom算法在特定情况下的严重缺陷，挑战了先前关于其效率的假设。

> **ai_Abstract:** 本文研究了图的加权公平划分问题，特别是利用可分裂生成树的方法。在Cannon等人工作的基础上，本文证明了稠密随机图上的生成树也具有逆多项式概率可分裂，从而为这类图提供了高效精确采样公平划分的新途径。同时，这些结果也支持了森林上“上下行走”的快速近似均匀采样。此外，论文深入分析了现有ReCom算法的局限性，揭示了其在特定图结构下马尔可夫链不可约或拒绝采样时间呈指数增长的问题，这挑战了该算法在某些场景下的效率假设。

> **摘要翻译:** 图的加权公平划分最近因其在重新划分选区、网络算法和图像分解等多种应用中的重要性而受到关注。根据生成树度量对划分进行加权，因其通常倾向于更紧凑的块而具有数学和实践意义。Charikar 等人提出的一种吸引人的算法是采样一个随机生成树并移除 k-1 条边，从而生成一个随机森林。如果森林的组件形成一个平衡划分，则该划分在易于计算的接受概率下是公平的。Cannon 等人最近表明，n 个顶点的网格图和类网格图上的生成树以至少 $n^{-2k}$ 的概率可分裂成 k 个大小相等的块，从而为一类图提供了第一个严格的采样算法。我们提出了补充结果，表明稠密随机图上的生成树也具有逆多项式概率可分裂，从而提供了另一类图，其中可以高效精确地采样公平划分。这些证明也保证了森林上“上下行走”的快速近似均匀采样，提供了另一种可证明高效的随机方法来生成公平划分。此外，我们表明，对于公平划分的广受研究的 ReCom 算法存在的问题比以前已知更为广泛，即使在以前认为更有希望的特殊情况下也是如此。我们提出了一个图族，其中当马尔可夫链必须保持组件完美公平时，它会失败而不可约；然而，当链允许组件之间仅有一个顶点的不平衡时，拒绝采样步骤可能需要指数时间。即使当图满足被推测足以进行快速采样的理想属性时，情况也是如此。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [142] [Waiting is worth it and can be improved with predictions](https://arxiv.org/abs/2507.12822)
> *等待是值得的，并且可以通过预测来改进*

*Ya-Chun Liang, Meng-Hsi Li, Chung-Shou Liao, Clifford Stein* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 在线旅行商问题, 在线按需乘车问题, 在线预测, 竞争比, 等待策略

**Comment:** 

> **TL;DR:** 本研究提出了一种带有在线预测的等待策略，以改进在线旅行商问题和在线按需乘车问题的竞争比，并证明了在线算法的竞争比下限。

**AI_Comments:** 本文的创新点在于提出了带有“在线”和“二元”预测的等待策略，这与传统的需要预知完整信息的离线预测或整体预测方法不同，使其更适用于实际的在线场景。其贡献在于不仅提出了性能有界的新算法，还从理论上证明了在线调度算法在完美预测下的竞争比下限，对该领域的研究具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探索如何利用带有预测的在线算法（即学习增强算法）来改进在线旅行商问题（OLTSP）和在线按需乘车问题（OLDARP）在多项式时间内的最佳竞争比。

**Method:** 提出了一种带有在线预测的等待策略，其中每个预测仅针对整个路线中的每个调度进行二元决策，而不是预先预测整个请求集（即离线预测），因此不需要提前知道请求数量。该方法基于一种在线调度算法。

**Result:** 所提出的在线调度算法在多项式时间内实现了1.1514 * lambda + 1.5-一致性和1.5 + 1.5 / (2.3028 * lambda - 1)-鲁棒性，其中lambda在(1/theta, 1]区间内，theta约为2.3028。当lambda接近1/theta时，最佳一致性趋近于2。同时，研究表明即使有完美的在线预测，任何基于在线调度的算法也无法获得小于2的竞争比。

**Conclusion:** 即使有完美的在线预测，基于在线调度的算法在OLTSP和OLDARP中也无法将竞争比降低到2以下，但本文提出的带有在线预测的等待策略可以显著改进现有算法的性能，并在多项式时间内提供有界的一致性和鲁棒性。

> **ai_Abstract:** 本文研究了在线旅行商问题（OLTSP）和在线按需乘车问题（OLDARP），旨在通过引入带有在线预测的算法来改进其竞争比。作者提出了一种新的等待策略，该策略采用针对每个调度进行二元决策的在线预测，而非整体离线预测，从而无需预知请求总数。该方法在多项式时间内获得了特定的算法一致性和鲁棒性界限。研究还进一步证明，即使在完美在线预测的条件下，任何基于在线调度的算法都无法将竞争比降低到2以下。

> **摘要翻译:** 我们重新审视了众所周知的在线旅行商问题（OLTSP）及其扩展——在线按需乘车问题（OLDARP）。服务器从度量空间中的指定起点出发，需要服务在线请求，并返回起点，以使完成时间最小化。SmartStart算法由Ascheuer等人引入，将等待方法整合到在线调度算法中，并且如果每个调度都是最优的，则OLTSP和OLDARP可以达到2的最优上限。使用Christofides启发式算法近似每个调度，可以在多项式时间内获得当前最佳的上限，约为(7 + sqrt(13)) / 4，即大约2.6514。
在这项研究中，我们调查了如何使用带有预测的在线算法（一个最近流行的框架，即所谓的学习增强算法）来改进多项式时间内的最佳竞争比。特别是，我们开发了一种带有在线预测的等待策略，其中每个预测仅是整个路线中每个调度的二元决策，而不是一开始就预测整个请求集（即离线预测）。也就是说，它不需要提前知道请求的数量。所提出的在线调度算法可以在多项式时间内实现1.1514 * lambda + 1.5-一致性和1.5 + 1.5 / (2.3028 * lambda - 1)-鲁棒性，其中lambda位于区间(1/theta, 1]内，theta设置为(1 + sqrt(13)) / 2，约为2.3028。当lambda接近1/theta时，最佳一致性趋近于2。同时，我们表明即使有完美的在线预测，任何基于在线调度的算法也无法获得小于2的竞争比。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [190] [Cut-Matching Games for Bipartiteness Ratio of Undirected Graphs](https://arxiv.org/abs/2507.12847)
> *无向图二分比的割-匹配博弈*

*Tasuku Soma, Mingquan Ye, Yuichi Yoshida* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 二分比, 近似算法, 割-匹配博弈, 斜对称图, 最大流

**Comment:** 

> **TL;DR:** 提出了一种基于割-匹配博弈框架的 $O(\log n)$ 近似算法，用于计算无向图的二分比，运行时间接近线性，并引入了斜对称图的良好连接性概念。

**AI_Comments:** 这篇论文的创新点在于将割-匹配博弈框架从稀疏割扩展到二分比问题，并成功地开发了一个高效的近似算法。其引入的斜对称图的良好连接性概念及其对二分比的表征具有重要的理论意义，可能为未来相关研究提供新的视角。算法的接近线性时间复杂度也使其在实际应用中具有吸引力。

<details>
  <summary>Details</summary>

**Motivation:** 针对Trevisan提出的无向图二分比问题，寻找一种高效的近似算法。

**Method:** 提出了一种扩展了稀疏割的割-匹配博弈框架的方法，用于计算二分比。该算法需要进行多对数次单商品无向最大流计算。此外，引入了斜对称图的良好连接性概念，并证明了二分比与辅助斜对称图中的良好连接性之间的关系。

**Result:** 1. 提出了一个 $O(\log n)$ 近似算法用于无向图的二分比计算。2. 该算法运行时间接近线性。3. 引入了斜对称图的良好连接性概念，并给出了二分比的新表征。4. 作为一个应用，开发了一个能在给定图上找到特定割的 $\tilde{O}(mn)$ 时间算法。

**Conclusion:** 该研究成功地为无向图的二分比问题提供了一个高效的近似算法，并通过扩展割-匹配博弈框架和引入新理论概念（斜对称图的良好连接性）做出了贡献，这些新概念可能具有独立的理论价值。

> **ai_Abstract:** 本文提出了一种基于扩展割-匹配博弈框架的 $O(\log n)$ 近似算法，用于计算无向图的二分比，该算法运行时间接近线性。研究引入了斜对称图的良好连接性概念，并证明了二分比与辅助斜对称图中的良好连接性之间的新型关系。此外，还展示了该算法在一个图切割问题上的应用。

> **摘要翻译:** 我们提出了一种针对Trevisan（SIAM Journal on Computing, vol. 41, no. 6, 2012）引入的无向图二分比的 $O(\log n)$ 近似算法，其中 $n$ 是顶点数。我们的方法将稀疏割的割-匹配博弈框架扩展到二分比问题。我们的算法只需要进行 $\mathrm{poly}\log n$ 次单商品无向最大流计算。因此，借助当前最快的无向最大流算法，它的运行时间接近线性。在此过程中，我们引入了斜对称图的良好连接性概念，并证明了二分比在辅助斜对称图中通过良好连接性进行表征的新颖特性，这可能具有独立的兴趣。作为一个应用，我们设计了一个 $\tilde{O}(mn)$ 时间算法，该算法在给定一个最大割删除 $1-\eta$ 比例边的图时，能找到一个删除 $1 - O(\log n \log(1/\eta)) \cdot \eta$ 比例边的割，其中 $m$ 是边数。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [239] [A 1/2-Approximation for Budgeted $k$-Submodular Maximization](https://arxiv.org/abs/2507.12875)
> *预算约束下k-次模最大化问题的1/2近似算法*

*Chenhao Wang* | **Category: cs.DS, cs.DM, math.OC** | **Updated: 2025-07-17**

**Keywords:** k-次模最大化, 预算约束, 近似算法, 1-Guess Greedy, 连续分析

**Comment:** 15 pages. Accepted to ESA 2025

> **TL;DR:** 本文证明了1-Guess Greedy算法在预算约束下的单调k-次模最大化问题上能达到1/2近似比，并对非单调问题达到1/3近似比。

**AI_Comments:** 本文的主要创新在于提出了1-Guess Greedy算法并利用新颖的连续变换和多线性扩展进行分析，成功解决了预算约束下k-次模最大化这一长期开放问题。该算法的简单性和可并行化使其具有较高的实用价值。此外，其连续分析方法不仅证明了算法的近似比，还为改进现有算法和处理更广泛约束下的问题提供了统一的框架，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究表明贪婪算法在基数或拟阵约束下的单调k-次模最大化问题上能达到1/2近似比，但对于预算约束（即背包约束）下的问题，是否存在一个确定的1/2近似算法一直是一个未解决的问题。

**Method:** 本文提出了1-Guess Greedy算法。该算法首先从一个最优解中猜测一个合适的元素，然后继续执行贪婪算法。证明思想是引入一种从最优解到贪婪解的新型连续变换，利用多线性扩展评估变换过程中的每个分数解。

**Result:** 1-Guess Greedy算法在预算约束下的单调k-次模最大化问题上实现了1/2近似比。这个结果是渐近紧的。对于非单调问题，1-Guess Greedy算法实现了1/3近似比。

**Conclusion:** 本文通过1-Guess Greedy算法解决了预算约束下k-次模最大化问题是否存在1/2近似算法的开放问题。该算法简单且可并行化，适用于实际应用，并且其连续分析方法可以改进现有算法的近似比，并自然地扩展到更广泛约束下的k-次模最大化问题，提供了一个更灵活和统一的分析框架。

> **ai_Abstract:** 本文解决了预算约束下k-次模最大化问题是否存在1/2近似算法的长期开放问题。通过引入1-Guess Greedy算法及其基于多线性扩展的连续分析方法，作者证明了该算法在单调预算约束下可达到1/2近似比，对非单调问题则为1/3近似比。该算法简单、可并行化，且其分析方法具有普适性，可改进现有算法并扩展到更广泛的约束。

> **摘要翻译:** k-次模函数通过接受k个不相交的子集作为输入，自然地概括了次模函数，而非单个子集。与仅需为解选择元素的标准次模最大化不同，k-次模最大化增加了确定每个选定元素属于哪个子集的挑战。先前的研究表明，贪婪算法是基数或拟阵约束下单调k-次模最大化问题的1/2近似算法。然而，对于预算版本（即具有背包约束）是否存在确定的1/2近似算法，这个问题已经悬而未决多年。我们通过证明1-Guess Greedy算法（该算法首先从一个最优解中猜测一个合适的元素，然后继续执行贪婪算法）实现了1/2近似比，从而肯定地解决了这个问题。这个结果是渐近紧的，因为即使没有约束，((k+1)/(2k)+ε)-近似也需要指数级的价值预言查询（Iwata et al., SODA 2016）。我们进一步表明，1-Guess Greedy算法对于非单调问题是1/3近似算法。该算法既简单又可并行化，非常适合实际应用。利用（Badanidiyuru和Vondrak, SODA 2014）中的阈值技术，它的运行时间接近O(n^2k^2)。
证明思想很简单：我们引入了一种从最优解到贪婪解的新颖连续变换，在变换过程中使用多线性扩展来评估每个分数解。这种连续分析方法产生了两个关键的扩展。首先，它能够改进各种现有算法的近似比。其次，我们的方法自然地扩展到更广泛约束下的k-次模最大化问题，提供了一个更灵活和统一的分析框架。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [284] [List Decoding Expander-Based Codes up to Capacity in Near-Linear Time](https://arxiv.org/abs/2504.20333)
> *近似线性时间下基于扩展码的列表译码达到容量*

*Shashank Srivastava, Madhur Tulsiani* | **Category: cs.DS, cs.CC, cs.IT, math.IT** | **Updated: 2025-07-17**

**Keywords:** 列表译码, 扩展码, 图正则引理, 近似线性时间, 纠错码

**Comment:** Improved dependence on $\epsilon$ from doubly exponential to
  exponential

> **TL;DR:** 本文提出了一个基于图正则引理的新框架，用于在近似线性时间内对基于谱扩展器的码进行列表译码和列表恢复，达到了接近容量的性能。

**AI_Comments:** 这项工作创新性地将图正则引理应用于纠错码的列表译码和恢复，为扩展码的解码效率设定了新的里程碑。其重要性在于实现了近似线性时间的高效算法，并为多种显式构造提供了更紧密的理论界限，对编码理论和算法设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了在近似线性时间内实现基于谱扩展器的码的列表译码和列表恢复，并达到接近容量的性能，需要一个新的高效框架。

**Method:** 本文采用了一个基于图正则引理的新框架，并利用现有在近似线性时间内计算稀疏图正则分解的算法，结合适当选择的常数大小的内部/基础码。

**Result:** 1. 使用Alon、Edmonds和Luby的距离放大技术构建的扩展码（速率为ρ），可以在近似线性时间内以1 - ρ - ε的半径进行列表译码，输出列表大小为O(1/ε)。2. 上述Alon、Edmonds和Luby的码（速率为ρ），也可以在近似线性时间内以1 - ρ - ε的半径进行列表恢复，输出列表为常数大小。3. Sipser和Spielman的Tanner码构造（距离为δ），可以在近似线性时间内以δ - ε的半径进行列表译码，输出列表为常数大小。这些结果为上述显式构造提供了新颖的组合和算法界限。

**Conclusion:** 本文通过图正则引理框架，成功地将局部基础码的列表译码和列表恢复特性提升到通过特定构造获得的全局码，实现了近似线性时间的解码和恢复，并获得了新的组合和算法界限。

> **ai_Abstract:** 本文提出了一个基于图正则引理的新框架，用于在近似线性时间内对基于谱扩展器的码进行列表译码和列表恢复。该框架结合了稀疏图的正则分解算法和精心选择的基础码，成功地实现了Alon-Edmonds-Luby扩展码和Sipser-Spielman Tanner码在接近容量的半径下进行高效的列表译码和恢复，并获得了新的组合和算法界限。

> **摘要翻译:** 我们提出了一个基于图正则引理的新框架，用于谱扩展器码的列表译码和列表恢复。利用现有在（随机化）近似线性时间内计算稀疏图正则分解的算法，并适当选择常数大小的内部/基础码，我们证明了以下几点：
- 使用Alon、Edmonds和Luby [FOCS 1995] 的距离放大技术构建的扩展码，其速率为 ρ，可以在近似线性时间内以 1 - ρ - ε 的半径进行列表译码。根据已知结果，输出列表的大小为 O(1/ε)。
- 上述Alon、Edmonds和Luby的码，其速率为 ρ，也可以在近似线性时间内以 1 - ρ - ε 的半径进行列表恢复，输出列表为常数大小。
- Sipser和Spielman [IEEE Trans. Inf. Theory 1996] 的Tanner码构造，其距离为 δ，可以在近似线性时间内以 δ - ε 的半径进行列表译码，输出列表为常数大小。
我们的结果对上述每种显式构造都意味着新颖的组合和算法界限。所有这些界限都是通过组合刚性现象获得的，并使用（弱）图正则性进行了证明。正则性框架允许我们将局部基础码的列表译码和列表恢复特性提升到通过上述构造获得的全局码。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [292] [Efficient Semi-External Breadth-First Search](https://arxiv.org/abs/2507.12925)
> *高效半外部广度优先搜索*

*Xiaolong Wan, Xixian Han* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 广度优先搜索, 半外部内存, 大规模图, EP-BFS, 算法效率

**Comment:** 

> **TL;DR:** 本文提出了一种名为EP-BFS的高效半外部广度优先搜索算法，它在处理大规模图数据时比现有方法快10倍。

**AI_Comments:** 本文提出了一种针对半外部内存模型的创新BFS算法EP-BFS，有效解决了大规模图数据处理中内存限制和计算效率的问题。其主要创新在于在有限内存条件下实现了显著的性能提升，对于处理超大规模图数据集具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着图数据库规模的急剧增长，大规模图数据通常驻留在磁盘上。传统的内存BFS算法无法处理整个图，而外部BFS算法计算成本高昂。半外部内存模型是折衷方案，但其BFS问题仍未解决，因此需要高效的半外部BFS算法。

**Method:** 本文对半外部内存模型中的BFS处理进行了全面研究。在讨论了基于半外部图算法基本框架的朴素解决方案后，本文提出了一种名为EP-BFS的高效算法，该算法具有较小的最小内存空间要求。

**Result:** 在真实和合成的大规模图上进行了广泛实验，包括节点超过17亿的WDC-2014图和边超过91亿的eu-2015图。实验结果证实，EP-BFS的速度可以提高多达10倍。

**Conclusion:** EP-BFS算法在半外部内存模型下实现了高效的广度优先搜索，显著优于现有方法。

> **ai_Abstract:** 本文针对大规模图数据在半外部内存模型中进行广度优先搜索（BFS）的挑战，提出了一种名为EP-BFS的高效算法。该算法解决了传统内存BFS无法处理大型图和外部BFS计算成本高的问题。EP-BFS具有较低的内存需求，并通过在真实和合成大规模图上的实验证明，其性能比现有方法快达10倍。

> **摘要翻译:** 广度优先搜索（BFS）被认为是学习图属性的基本搜索策略。近年来，随着图数据库规模的急剧增长，大规模图G通常驻留在磁盘上。在半外部内存模型中获取G的BFS结果是不可避免的，因为内存BFS算法必须将整个G维护在主内存中，而外部BFS算法消耗高昂的计算成本。作为内部和外部内存模型之间的一个良好折衷，半外部内存模型假设主内存至少可以容纳G的生成树。然而，由于其难度，半外部BFS问题仍然是一个开放性问题。因此，本文对在半外部内存模型中处理BFS进行了全面研究。在讨论了基于半外部图算法基本框架的朴素解决方案后，本文提出了一种名为EP-BFS的高效算法，该算法具有较小的最小内存空间要求，这是评估半外部算法的一个重要因素。在真实和合成的大规模图上进行了广泛实验，其中WDC-2014图包含超过17亿个节点，eu-2015图包含超过91亿条边。实验结果证实，EP-BFS的速度可以提高多达10倍。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [334] [The Price of Diversity of the Traveling Salesman Problem](https://arxiv.org/abs/2507.13026)
> *旅行商问题多样性代价*

*Mark de Berg, Andrés López Martínez, Frits Spieksma* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 多样性代价, 旅行商问题, 离散优化, 边不相交路径, 最短哈密顿路径

**Comment:** 

> **TL;DR:** 本文引入了“多样性代价”（PoD）的概念，量化了离散优化问题中解的多样性与成本之间的权衡，并针对旅行商问题（TSP）在特定条件下建立了PoD的渐近值。

**AI_Comments:** 本文的创新之处在于提出了“多样性代价”（PoD）这一新颖的概念，为量化离散优化问题中解的多样性与成本之间的权衡提供了一个新的视角和工具。通过对旅行商问题（TSP）的具体分析，并利用最短哈密顿路径问题（SHP）作为辅助，成功地为特定约束下的多样性成本提供了渐近的量化结果，对于理解和设计需要多样化解决方案的优化算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在引入“多样性代价”（PoD）的概念，以量化离散优化问题中解的多样性与成本之间的权衡。

**Method:** 本文定义了“多样性代价”（PoD）为在所有实例中，一组k个多样化解的最小可实现成本与单个最优解成本之间的最坏情况比率。研究以旅行商问题（TSP）为例，特别是要求k个边不相交的路径的情况。通过分析相关的最短哈密顿路径问题（SHP），得到了PoD的结果。

**Result:** 本文发现，渐近地，在特殊的一维情况下，寻找两个边不相交路径的PoD为8/5；在一般的度量空间中，PoD为2。这些结果是通过分析最短哈密顿路径问题（SHP）获得的，SHP也建立了类似的结果。

**Conclusion:** 本文成功地为旅行商问题（TSP）在要求边不相交路径的多样性约束下，建立了渐近的“多样性代价”（PoD）值，并揭示了多样性与成本之间的量化权衡关系。

> **ai_Abstract:** 本文引入了离散优化问题中“多样性代价”（PoD）的概念，旨在量化解决方案多样性与成本之间的权衡。PoD被定义为在所有实例中，一组k个多样化解决方案的最小成本与单个最优解决方案成本的最坏情况比率。研究以旅行商问题（TSP）为例，特别是要求k条边不相交路径的情况。研究结果表明，对于两个边不相交的路径，PoD在特殊的一维情况下渐近为8/5，在一般度量空间中为2。这些结果是通过分析最短哈密顿路径问题（SHP）获得的。

> **摘要翻译:** 本文引入了离散优化问题中“多样性代价”（PoD）的概念，量化了解决方案多样性与成本之间的权衡。对于一个最小化问题，PoD被定义为在所有实例中，一组k个多样化解决方案的最小可实现成本与同一实例的单个最优解决方案成本之间的最坏情况比率。这里，k个解决方案集的成本由该集合中最昂贵的解决方案决定。我们以旅行商问题（TSP）作为关键示例，研究了要求k个边不相交路径设置下的PoD。我们确定，渐近地，在特殊的一维情况下，寻找两个边不相交路径的PoD为8/5，在一般的度量空间中为2。我们通过分析相关的基本问题：最短哈密顿路径问题（SHP）获得了这些结果，并为SHP建立了类似的结果。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [347] [Efficiently Constructing Sparse Navigable Graphs](https://arxiv.org/abs/2507.13296)
> *高效构建稀疏可导航图*

*Alex Conway, Laxman Dhulipala, Martin Farach-Colton, Rob Johnson, Ben Landrum, Christopher Musco, Yarin Shechter, Torsten Suel, Richard Wen* | **Category: cs.DS, cs.DB, cs.IR** | **Updated: 2025-07-17**

**Keywords:** 稀疏可导航图,最近邻搜索,集合覆盖,算法复杂度,近似算法

**Comment:** 

> **TL;DR:** 本文提出了一种准最优的 $\tilde{O}(n^2)$ 时间算法，用于高效构建稀疏可导航图，并证明了其最优性和近似硬度。

**AI_Comments:** 这篇论文的创新之处在于首次将稀疏可导航图的构建问题置于严格的理论框架下，并提供了具有可证明保证的算法。它将图构建问题与经典的集合覆盖问题联系起来，并巧妙地利用了其相关性来克服计算复杂性。其 $\tilde{O}(n^2)$ 的时间复杂度在理论上具有重要意义，接近最优，并且对实践中的最近邻搜索性能提升有潜在影响。同时，对近似硬度的证明也为该领域的研究设定了界限。

<details>
  <summary>Details</summary>

**Motivation:** 图基最近邻搜索方法性能优越，但构建稀疏可导航搜索图计算成本高昂，实践中普遍使用启发式方法，缺乏可证明的保证。

**Method:** 将构建最优稀疏可导航图的问题建模为 $n$ 个高度相关的最小集合覆盖实例。通过利用集合覆盖实例之间的相关性，结合流式和次线性时间集合覆盖算法的技术，以及问题特定的预处理技术，提出了一种改进的算法。

**Result:** 提出了一种 $\tilde{O}(n^2)$ 时间算法，用于在任何距离函数下构建 $O(\log n)$ 近似最稀疏可导航图。该算法的运行时间在强指数时间假设下，通过从单色最近对的归约，在对数因子内是最佳的。此外，证明了获得优于 $O(\log n)$ 近似是NP-hard的。该技术还能将构建 $\alpha$-快捷可达图和 $\tau$-单调图的时间复杂度降至 $\tilde{O}(n^{2.5})$ 或更优。

**Conclusion:** 本文首次提出了具有可证明保证的快速算法来构建稀疏可导航图，显著提升了计算效率，并为相关问题提供了理论最优或近最优的解决方案。

> **ai_Abstract:** 本文针对图基最近邻搜索中计算成本高昂的稀疏可导航图构建问题，首次提出了具有可证明保证的快速算法。通过将问题建模为 $n$ 个相关的最小集合覆盖实例，并结合流式、次线性时间算法及预处理技术，作者开发了一种 $\tilde{O}(n^2)$ 时间算法，用于构建 $O(\log n)$ 近似的稀疏可导航图。该算法在理论上被证明是近乎最优的，并且其近似比被证明是NP-hard的。此外，该方法还适用于其他相关图的构建。

> **摘要翻译:** 近年来，基于图的最近邻搜索方法越来越受欢迎，在各种应用中都提供了最先进的性能。这些方法的核心任务是为给定数据集构建一个具有距离函数的稀疏可导航搜索图。不幸的是，这样做计算成本很高，因此实践中普遍使用启发式方法。
在这项工作中，我们首次研究了具有可证明保证的快速搜索图构建算法。对于一个包含 $n$ 个数据点的数据集，构建最优稀疏可导航图的问题可以被框架为 $n$ 个独立但高度相关的最小集合覆盖实例。这产生了一个朴素的 $O(n^3)$ 时间贪婪算法，该算法返回的可导航图的稀疏性至多比最优高 $O(\log n)$。我们显著改进了这一基线，利用集合覆盖实例之间的相关性，利用流式和次线性时间集合覆盖算法的技术。结合问题特定的预处理技术，我们提出了一种 $\tilde{O}(n^2)$ 时间算法，用于在任何距离函数下构建 $O(\log n)$ 近似最稀疏可导航图。
根据强指数时间假设，通过从单色最近对的归约，我们方法的运行时间在对数因子内是最佳的。此外，我们证明，与一般集合覆盖一样，尽管可导航图问题中存在显著的额外结构，但获得优于 $O(\log n)$ 近似是NP-hard的。最后，我们表明我们的技术还可以击败构建 $\alpha$-快捷可达图和 $\tau$-单调图的立方时间，这些图也用于最近邻搜索。对于此类图，我们获得了 $\tilde{O}(n^{2.5})$ 时间或更优的算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [376] [Maintaining Routing Structures under Deletions via Self-Pruning](https://arxiv.org/abs/2507.13044)
> *通过自剪枝在删除操作下维护路由结构*

*Bernhard Haeupler, Antti Roeyskoe* | **Category: cs.DS, F.2.2; G.2.2** | **Updated: 2025-07-17**

**Keywords:** 扩展图, 自剪枝, 路由, 边删除, 动态图

**Comment:** 

> **TL;DR:** 本文介绍了一系列易于路由且可自剪枝的扩展图，以在边删除操作下维护路由结构，并能实现最坏情况下的自剪枝，同时严格控制路由路径长度。

**AI_Comments:** 本文的创新点在于提出了“自剪枝”扩展图的概念，并设计了一个在线算法来处理边删除，同时保持图的可路由性。特别值得注意的是，其实现了最坏情况下的性能保证，这在动态图算法中是一个重要的进步。该研究对于构建鲁棒的网络路由结构具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的两类图算法问题分别是：在扩展图上计算低拥塞路由（扩展图路由）和在边故障下维护禁用顶点子集（扩展图剪枝）。本文旨在结合这两个问题，即在剪枝步骤下维护单位多商品需求的路由。

**Method:** 本文通过引入一系列扩展图来解决此问题，这些图像超立方体一样易于路由且具有自剪枝特性。针对在线的边删除序列，一个简单的自包含算法可以在每次边删除时找到少量顶点进行剪枝，从而使剩余图始终保持为该系列中易于路由的扩展图。

**Result:** 该自剪枝机制可以实现最坏情况下的性能，即每次对抗性删除只会导致少量额外的删除。结果还允许对路由路径长度进行严格的常数因子控制，并因此扩展到常数跳和长度受限的扩展图。

**Conclusion:** 本文成功地提出了一种在边删除操作下维护路由结构的方法，通过引入自剪枝扩展图并实现了最坏情况下的性能保证和路由路径长度的严格控制，解决了结合路由和剪枝的复杂问题。

> **ai_Abstract:** 本文研究了在边删除操作下维护路由结构的问题，通过引入一类新的“自剪枝”扩展图解决了该问题。这些图易于路由，并能通过一个简单的算法在每次删除时自动修剪少量顶点，以保持图的扩展性。该方法实现了最坏情况下的自剪枝性能，并能严格控制路由路径长度，使其适用于对路径长度有严格要求的扩展图。

> **摘要翻译:** 扩展图是强大的算法结构，具有两个关键特性：
a) 可路由性：对于任何单位多商品流需求，存在一条在短路径上具有低拥塞的路由，其中如果任何顶点发送/接收的需求量最多为其相邻边数，则该需求是单位需求。
b) 稳定性/可剪枝性：对于任何（序列的）边故障，存在一个比例上很小的顶点子集可以被禁用，使得剩余顶点上诱导的图仍然是扩展图。
对应于这两个存在性保证的两个自然算法问题是：扩展图路由，即在扩展图上计算单位多商品需求的低拥塞路由；以及扩展图剪枝，即在边故障序列下维护禁用顶点的子集。
本文考虑了这两个问题的结合：在剪枝步骤下维护单位多商品需求的路由。这是通过引入一系列扩展图来实现的，这些图像超立方体一样易于路由，并且是自剪枝的：对于在线的边删除序列，一个简单的自包含算法可以在每次边删除时找到少量顶点进行剪枝，从而使剩余图始终保持为该系列中易于路由的扩展图。
值得注意的是，经过大量的技术工作，这种自剪枝可以实现最坏情况下的性能，即每次对抗性删除只会导致少量额外的删除。我们的结果还允许对路由路径长度进行严格的常数因子控制（伴随着拥塞和剪枝比的通常权衡），因此扩展到常数跳和长度受限的扩展图，其中在常数长度路径上路由至关重要。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [415] [Kernelization for $H$-Coloring](https://arxiv.org/abs/2507.13129)
> *H-着色问题的核化*

*Yael Berkman, Ishay Haviv* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** H-着色, 核化, 顶点覆盖数, 参数化复杂度, 图同态

**Comment:** 38 pages

> **TL;DR:** 该论文为H-着色问题提供了新的核化上界和下界，并提出了两种改进的核化算法。

**AI_Comments:** 本文通过引入创新的组合和线性代数核化技术，并结合全面的上界和下界分析，显著推进了H-着色问题在参数化复杂度领域的理解，几乎完全解决了其核复杂度，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在改进H-着色问题在顶点覆盖数参数化下的核大小界限，并深入理解其核复杂度，以超越现有成果。

**Method:** 提出两种核化算法：一种纯组合算法，其大小由H图的非邻接见证数决定；另一种利用线性代数工具。同时，提供了条件性下界来补充上界。

**Result:** 组合核化算法在特定图类上提供了多项式大小的核，且对于多数图H，其多项式次数仅对最大度呈对数增长。线性代数核化算法强化了现有通用界限，并为相关问题提供了接近最优的核。结合这些结果和条件性下界，几乎解决了该问题对各种目标图H的核复杂度。

**Conclusion:** 该研究通过提供新的上界和下界，几乎解决了H-着色问题对各种目标图H的核复杂度。

> **ai_Abstract:** 本文研究了H-着色问题在顶点覆盖数参数化下的核化复杂度。针对现有工作，论文提出了两种新的核化算法：一种是纯组合算法，其核大小由图H的结构量（非邻接见证数）决定，对特定图类和几乎所有图H展现出优越的界限；另一种利用线性代数工具，强化了现有通用界限。此外，论文还提供了条件性下界，这些结果共同几乎解决了该问题对于各种目标图H的核复杂度。

> **摘要翻译:** 对于一个固定的图$H$，H-着色问题询问给定图的顶点集是否存在一个到$H$的顶点集的保边函数。Hell和Ne\v{s}et\v{r}il的一个开创性定理指出，当$H$是无环且非二分图时，H-着色问题是NP难的。Jansen和Pieterse的一个结果表明，对于每个图$H$，以顶点覆盖数$k$为参数的H-着色问题存在一个核（kernel），其顶点数为$O(k^{\Delta(H)})$，比特大小受$O(k^{\Delta(H)} \cdot \log k)$限制，其中$\Delta(H)$表示$H$中的最大度。对于$H$是至少有三个顶点的完全图的情况，这个核大小几乎与Jansen和Kratsch以及Jansen和Pieterse建立的条件性下界相匹配。
本文提出了H-着色问题在顶点覆盖数参数化下的核大小的新上界和下界。这些上界源于两种核化算法。第一种是纯组合的，其大小由图$H$的一个结构量（称为非邻接见证数）决定。作为应用，我们获得了核大小由固定多项式界定的核，适用于最大度无界的自然图类$H$。更引人注目的是，我们表明对于几乎所有图$H$，限制我们组合核大小的多项式次数仅随$\Delta(H)$呈对数增长。我们的第二个核利用了线性代数工具，并涉及图的忠实独立表示概念。它强化了先前工作的通用界限，并且在其他应用中，为涉及有限域上正交图表示维度的问题提供了接近最优的核。我们用条件性下界补充了这些结果，从而几乎解决了该问题对于各种目标图$H$的核复杂度。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [452] [Online Rounding for Set Cover under Subset Arrivals](https://arxiv.org/abs/2507.13159)
> *子集到达模型下集合覆盖的在线舍入*

*Jarosław Byrka, Yongho Shin* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 在线舍入, 集合覆盖, 子集到达, 近似算法, 竞争比

**Comment:** 

> **TL;DR:** 本文提出了在子集到达模型下集合覆盖的改进在线舍入方案，达到了更好的竞争比，特别是对于多阶段随机集合覆盖和边覆盖。

**AI_Comments:** 该论文通过改进在更通用和更具挑战性的“子集到达”模型下的在线集合覆盖的竞争比，做出了重要贡献，特别是对于多阶段随机变体。对于边覆盖的具体结果也是一个显著的改进。s预先已知的假设是一个温和的限制，但在这种分析中很常见。

<details>
  <summary>Details</summary>

**Motivation:** 在更通用的子集到达模型下，集合覆盖的现有在线舍入方案仅达到O(log n)的竞争比，不如元素到达模型下的O(log s)。因此，需要在此模型下开发更优的方案。此外，多阶段随机集合覆盖的现有算法也有待改进。

**Method:** 本文提出了新的竞争性舍入方案：在子集到达模型下（s预先已知）提出了一个O(log^2 s)竞争性舍入方案；在边到达模型下，对于s=2的边覆盖问题提出了一个1.8竞争性舍入方案。

**Result:** 在子集到达模型下（s预先已知）提出了一个O(log^2 s)竞争性舍入方案。该方案立即获得了多阶段随机集合覆盖的O(log^2 s)近似算法，当s相对于阶段数和元素数足够小时，这改进了现有算法。对于s=2的边覆盖问题，在边到达模型下提出了一个1.8竞争性舍入方案。

**Conclusion:** 本文成功开发了在具有挑战性的在线模型下改进的集合覆盖在线舍入方案，从而为多阶段随机集合覆盖和边覆盖等相关问题带来了更好的近似算法。

> **ai_Abstract:** 本文主要关注集合覆盖问题的在线舍入，特别是在现有结果有限的子集到达模型下。论文提出了一个O(log^2 s)竞争性舍入方案（假设s预先已知），这进而为多阶段随机集合覆盖问题提供了一个改进的O(log^2 s)近似算法。此外，对于边覆盖（s=2）的特殊情况，论文在边到达模型下提出了一个1.8竞争性舍入方案。

> **摘要翻译:** 集合覆盖的舍入方案一直是该问题近似算法设计中的一个重要组成部分，并且存在一个 H_s 近似舍入方案，其中 s 表示最大子集大小，直接意味着具有相同近似保证的近似算法。舍入方案也在一些在线模型下被考虑，特别是在作为在线集合覆盖算法中关键子程序的元素到达模型下，已知存在一个 O(log s) 竞争性舍入方案 [Buchbinder, Chen, and Naor, SODA 2014]。另一方面，在更通用的模型，即子集到达模型下，仅已知一个简单的 O(log n) 竞争性舍入方案，其中 n 表示基础集中元素的数量。

本文中，我们提出了一个在子集到达模型下 O(log^2 s) 竞争性舍入方案，并有一个温和的假设：s 是预先已知的。使用我们的舍入方案，我们立即获得了多阶段随机集合覆盖的 O(log^2 s) 近似算法，当 s 相对于阶段数和元素数足够小时，这改进了现有算法 [Swamy and Shmoys, SICOMP 2012; Byrka and Srinivasan, SIDMA 2018]。最后，对于 s = 2 的集合覆盖，也称为边覆盖，我们提出了一个在边到达模型下 1.8 竞争性舍入方案。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [522] [Parameterized algorithms for block-structured integer programs with large entries](https://arxiv.org/abs/2311.01890)
> *具有大项的块结构整数程序的参数化算法*

*Jana Cslovjecsek, Martin Koutecký, Alexandra Lassota, Michał Pilipczuk, Adam Polak* | **Category: cs.DS, math.OC** | **Updated: 2025-07-17**

**Keywords:** 整数程序, 参数化算法, 两阶段随机程序, n-fold程序, 固定参数可解性

**Comment:** 49 pages. This is the TheoretiCS journal version

> **TL;DR:** 本文研究了在允许部分输入项较大的情况下，两阶段随机程序和n-fold整数程序的参数化可解性，并证明了在特定参数化下，这些问题仍然是固定参数可解的。

**AI_Comments:** 本文的创新之处在于扩展了块结构整数程序参数化可解性的已知结果，证明了在允许部分输入项较大的情况下，问题依然是固定参数可解的。这对于处理实际中可能出现大数值系数的优化问题具有重要意义。文章明确指出了$n$-fold程序中均匀性假设的必要性，并提及算法是弱多项式时间的，这暗示了在某些情况下，运行时间可能仍然与输入的大小呈指数关系，但相对于强多项式时间算法而言，这是一个进步。

<details>
  <summary>Details</summary>

**Motivation:** 已知块结构整数程序（如两阶段随机程序和n-fold程序）在相关矩阵的最大维度和约束矩阵中任何项的最大绝对值参数化下是固定参数可解的。本文的动机是探索当程序全局部分允许存在大项时，这些参数化可解性结果是否仍然成立。

**Method:** 通过理论证明，作者展示了在允许部分输入项较大时，两阶段随机程序和n-fold整数程序的固定参数可解性。具体来说，他们证明了两种情况下问题的固定参数可解性，并指出所提出的算法是弱多项式时间的。

**Result:** 1. 两阶段随机程序的可行性问题，当以矩阵A_i和D_i的维度以及矩阵D_i的项的最大绝对值进行参数化时，是固定参数可解的。这意味着矩阵A_i可以有任意大的项。
2. 均匀的n-fold整数程序的线性优化问题，当以矩阵C_i和D_i的维度以及矩阵D_i的项的最大绝对值进行参数化时，是固定参数可解的。这意味着所有矩阵C_i相等，并且C可以有任意大的项。对于第二个结果，均匀性假设是必要的，否则问题在参数取常数值时已是NP-hard。

**Conclusion:** 本文证明了对于两阶段随机程序和特定类型的n-fold整数程序，即使在程序的全局部分允许存在大项，其参数化可解性结果仍然成立。对于n-fold程序，均匀性假设是确保可解性的关键。

> **ai_Abstract:** 本文研究了两阶段随机程序和$n$-fold整数程序的参数化算法，特别关注当程序中允许存在大数值项的情况。研究发现，即使在全局部分允许大项，这些问题的固定参数可解性依然成立。具体而言，对于两阶段随机程序，当A_i矩阵允许任意大项时，问题仍可解；对于均匀的$n$-fold程序，当C矩阵允许任意大项时，问题也仍可解。文章指出，对于$n$-fold程序，均匀性假设是必要的，且所提出的算法是弱多项式时间的。

> **摘要翻译:** 我们研究了两种经典的块结构整数规划变体。
两阶段随机程序是形如$\{A_i \mathbf{x} + D_i \mathbf{y}_i = \mathbf{b}_i\textrm{ for all }i=1,\ldots,n\}$的整数程序，其中$A_i$和$D_i$是有限大小的矩阵。另一方面，$n$-fold程序是形如$\{\sum_{i=1}^n C_i\mathbf{y}_i=\mathbf{a} \textrm{ and } D_i\mathbf{y}_i=\mathbf{b}_i\textrm{ for all }i=1,\ldots,n\}$的整数程序，其中$C_i$和$D_i$同样是有限大小的矩阵。已知当以相关矩阵$A_i,C_i,D_i$的最大维度以及约束矩阵中任何项的最大绝对值进行参数化时，解决这类程序是固定参数可解的。
我们证明了即使在程序的全局部分允许存在大项，两阶段随机程序和$n$-fold程序的参数化可解性结果依然成立。更准确地说，我们证明：
- 两阶段随机程序的可行性问题，当以矩阵$A_i,D_i$的维度以及矩阵$D_i$的项的最大绝对值进行参数化时，是固定参数可解的。也就是说，我们允许矩阵$A_i$具有任意大的项。
- 均匀的$n$-fold整数程序的线性优化问题——所有矩阵$C_i$都相等——当以矩阵$C_i$和$D_i$的维度以及矩阵$D_i$的项的最大绝对值进行参数化时，是固定参数可解的。也就是说，我们要求所有$i=1,\ldots,n$时$C_i=C$，但我们允许$C$具有任意大的项。
在第二个结果中，均匀性假设是必要的；否则，即使参数取常数值，问题也已经是$\\mathsf{NP}$-hard。我们的两种算法都是弱多项式时间的：运行时间是根据输入总比特大小来衡量的。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [557] [Approximate counting of permutation patterns](https://arxiv.org/abs/2411.04718)
> *置换模式的近似计数*

*Omri Ben-Eliezer, Slobodan Mitrović, Pranjal Srivastava* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 置换模式, 近似计数, Birgé分解, 数据结构, 模式匹配

**Comment:** 

> **TL;DR:** 本文提出了一种确定性的近线性时间(1+ε)-近似算法，用于计数长度k≤5的置换模式，首次证明了近似计数与精确计数之间的分离，并创新性地利用了Birgé分解。

**AI_Comments:** 本文的创新点在于首次将Birgé分解这一在分布测试中广泛使用的工具引入到置换模式计数问题中，并成功设计出高效的近似算法。它首次在理论上证明了近似计数与精确计数之间的差异，这对于理解模式计数问题的本质具有重要意义。此外，所开发的递增对范围查询数据结构也具有独立的价值。

<details>
  <summary>Details</summary>

**Motivation:** 该问题源于排名、非参数统计、组合学和细粒度复杂性中的多种联系和应用，尤其当k是一个小的固定常数时。现有研究在模式检测方面取得了进展，但计数问题更具挑战性，具有较高的条件性下限，并且预计比检测问题更难。

**Method:** 本文设计了一种确定性的近线性时间(1+ε)-近似算法，用于计数序列f中σ模式的副本，适用于所有k≤5。该算法利用了Birgé分解（一种次线性单调分布工具），这是首次在模式计数中使用。同时，开发了一种用于平面中(1+ε)-近似递增对范围查询的近最优数据结构。

**Result:** 该算法对于k≤5的置换模式计数实现了(1+ε)-近似，并结合k=4的条件性下限，首次建立了近似模式计数与精确模式计数之间的分离。所开发的递增对范围查询数据结构也展示了与精确情况的条件性分离。

**Conclusion:** 本文提出的近似计数算法首次明确了近似模式计数与精确模式计数之间的差异。Birgé分解的创新应用以及新数据结构的开发，为相关领域提供了新的工具和见解。

> **ai_Abstract:** 本文研究了在序列中近似计数置换模式的问题，该问题在多个领域具有应用。鉴于精确计数的高难度，作者提出了一种针对长度k≤5模式的确定性近线性时间(1+ε)-近似算法。该算法首次将Birgé分解引入模式计数领域，并构建了新的数据结构，成功实现了近似计数与精确计数之间的首次分离。

> **摘要翻译:** 我们考虑在序列 $f 	hincolon [n] 	o 	ext{R}$ 中计数长度为 $k$ 的模式 $	au$ 的副本的问题，其中副本是指索引 $i_1 < 	ext{...} < i_k 	ext{ 	ext{ϵ} } [n]$ 的子集，使得当且仅当 $	au(j) < 	au(	ext{ℓ})$ 时 $f(i_j) < f(i_	ext{ℓ})$。这个问题受到排名、非参数统计、组合学和细粒度复杂性中一系列联系和应用的启发，特别是当 $k$ 是一个小的固定常数时。
最近的进展显著提高了我们对模式计数和检测的理解。Guillemot 和 Marx [2014] 针对任何固定的 $k$ 获得了检测变体的 $O(n)$ 时间算法。他们的证明为发现双生宽度奠定了基础，双生宽度是近年来显著推动参数化复杂性的一个概念。相比之下，计数更难：它具有 $n^{	ext{Ω}(k / 	ext{log} k)}$ 的条件性下限 [Berendsohn, Kozma, 和 Marx, 2019]，并且考虑到它与图中的 $4$ 周期计数等价 [Dudek 和 Gawrychowski, 2020]，预计早在 $k = 4$ 时就比检测在多项式意义上更难。
在这项工作中，我们设计了一种确定性的近线性时间 $(1+	ext{ε})$-近似算法，用于计数 $f$ 中所有 $k 	ext{≤} 5$ 的 $	au$-副本。结合 $k=4$ 的条件性下限，这建立了近似模式计数与精确模式计数之间的首次已知分离。有趣的是，我们的算法利用了 Birgé 分解——一种广泛用于分布测试的次线性单调分布工具——据我们所知，这在模式计数上下文中以前从未被使用过。在此过程中，我们开发了一种用于平面中 $(1+	ext{ε})$-近似递增对范围查询的近最优数据结构，该结构展示了与精确情况的条件性分离，并且可能具有独立的兴趣。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [586] [DNA Probe Computing System for Solving NP-Complete Problems](https://arxiv.org/abs/2507.12470)
> *用于解决NP完全问题的DNA探针计算系统*

*Jin Xu, XiaoLong Shi, Xin Chen, Fang Wang, Sirui Li, Pali Ye, Boliang Zhang, Di Deng, Zheng Kou, Xiaoli Qiang* | **Category: cs.DS** | **Updated: 2025-04-21**

**Keywords:** DNA计算, NP完全问题, 并行计算, 探针机, 分子计算

**Comment:** 11 pages, 4 figures

> **TL;DR:** 本研究开发了一种基于DNA探针的并行计算系统，能够一次性找出NP完全问题的所有解，突破了传统电子计算机的局限。

**AI_Comments:** 这项研究的创新之处在于首次在分子层面实现了全并行计算系统，利用DNA探针技术解决NP完全问题。其重要性在于提供了一种超越传统图灵机限制的计算范式，可能为处理高复杂度问题（如蛋白质折叠、密码学）开辟新途径。

<details>
  <summary>Details</summary>

**Motivation:** 高效解决NP完全问题（如蛋白质结构预测、密码解密、漏洞检测）是计算机科学的核心挑战。传统电子计算机受限于图灵机的单维数据处理和顺序操作，难以有效解决这些问题。为了克服这一瓶颈，计算模型需要采用多维数据结构和并行信息处理机制。

**Method:** 基于团队提出的探针机模型（一种非图灵计算框架），本研究开发了一种阻断探针技术，利用DNA计算固有的并行性，通过一次探针操作即可识别NP完全问题的所有有效解。

**Result:** 以27顶点3着色问题为例，通过DNA分子探针实验成功检索到所有解决方案。首次实现了分子层面的全并行计算系统。

**Conclusion:** 探针机及其并行架构和分子实现超越了经典模型的局限性，并有望解决复杂的现实世界问题。

> **ai_Abstract:** 本研究提出了一种基于DNA探针的并行计算系统，旨在高效解决NP完全问题，突破了传统图灵机模型的局限。该系统利用DNA计算的并行性，通过阻断探针技术，能够在一次操作中找到NP完全问题的所有解。以27顶点3着色问题为例，实验成功验证了该系统的可行性，并首次实现了分子层面的全并行计算，为解决复杂现实问题提供了新范式。

> **摘要翻译:** 高效解决NP完全问题——例如蛋白质结构预测、密码解密和漏洞检测——仍然是计算机科学的核心挑战。传统的电子计算机受限于图灵机的单维数据处理和顺序操作，难以有效解决这些问题。为了克服这一瓶颈，计算模型必须采用多维数据结构和并行信息处理机制。本研究基于我们团队提出的探针机模型（一种非图灵计算框架），开发了一种阻断探针技术，该技术利用DNA计算固有的并行性，通过一次探针操作即可识别NP完全问题的所有有效解。我们以27顶点3着色问题为例，通过DNA分子探针实验成功检索到所有解决方案。这一突破展示了首次在分子层面实现的全并行计算系统，为解决计算复杂性问题提供了一种新范式。我们的结果表明，探针机凭借其并行架构和分子实现，超越了经典模型的局限性，并有望解决复杂的现实世界问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [597] [Faster and Space Efficient Indexing for Locality Sensitive Hashing](https://arxiv.org/abs/2503.06737)
> *局部敏感哈希的更快、更节省空间的索引*

*Bhisham Dev Verma, Rameshwar Pratap* | **Category: cs.DS, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 局部敏感哈希, 计数草图, 空间效率, 时间复杂度, LSH

**Comment:** 

> **TL;DR:** 该研究提出了新的局部敏感哈希（LSH）哈希码生成算法（CSELSH、HCSELSH、CSSRP、HCSSRP），显著降低了欧几里得距离和余弦相似度的LSH索引构建的时间和空间复杂度，解决了现有O(md)方法的低效问题。

**AI_Comments:** 该论文通过引入基于草图（sketch-based）的技术，显著提高了局部敏感哈希（LSH）索引构建的效率，特别是在高维数据处理方面。这项创新直接解决了现有LSH方法中O(md)复杂度的关键瓶颈，使得LSH这种广泛使用的近似最近邻搜索方法更具可扩展性和实用性，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于欧几里得距离（ELSH）和余弦相似度（SRP）的局部敏感哈希（LSH）哈希码生成算法在计算m维哈希码时，其时间和空间复杂度为O(md)，这对于m和d值较大时变得不切实际。

**Method:** 本研究提出了两种替代性的LSH哈希码生成算法，分别针对欧几里得距离和余弦相似度：CSELSH、HCSELSH以及CSSRP、HCSSRP。其中，CSELSH和CSSRP基于计数草图（count sketch），而HCSELSH和HCSSRP则利用了高阶计数草图（higher-order count sketch）。

**Result:** 提出的算法将哈希码计算时间从O(md)显著降低到O(d)。在空间复杂度方面，CSELSH和CSSRP将其从O(md)降低到O(d)；而HCSELSH和HCSSRP则将其从O(md)降低到O(N * d^(1/N))。这些提案得到了强大的数学保证支持，并通过在各种真实世界数据集上的模拟验证了其性能。

**Conclusion:** 本研究提出的算法显著提高了LSH索引构建的时间和空间效率，使其在高维数据处理中更具实用性。

> **ai_Abstract:** 本文针对局部敏感哈希（LSH）在欧几里得距离和余弦相似度下的索引构建，提出了创新的哈希码生成算法CSELSH、HCSELSH、CSSRP和HCSSRP。鉴于传统ELSH和SRP方法在时间和空间复杂度上存在O(md)的瓶颈，本文提出的基于计数草图和高阶计数草图的新方法，显著将哈希码计算时间降低到O(d)，并将空间复杂度分别优化至O(d)或O(N * d^(1/N))。这些改进不仅有坚实的数学理论支持，也通过在真实世界数据集上的实验得到了验证，极大地提升了LSH索引在大规模数据应用中的效率和实用性。

> **摘要翻译:** 这项工作提出了用于欧几里得距离（又称ELSH）和余弦相似度（又称SRP）的局部敏感哈希（LSH）的更快、更节省空间的索引构建算法。这些LSH的索引构建步骤依赖于根据哈希码将数据点分组到哈希表的几个桶中。为了生成d维数据点的m维哈希码，这些LSH首先将数据点投影到d维随机高斯向量上，然后对所得内积进行离散化。ELSH和SRP计算d维向量的m大小哈希码的时间和空间复杂度均为O(md)，这对于m和d值较大时变得不切实际。为了克服这个问题，我们提出了两种替代性的LSH哈希码生成算法，分别用于欧几里得距离和余弦相似度，即CSELSH、HCSELSH和CSSRP、HCSSRP。CSELSH和CSSRP基于计数草图[count_sketch]，而HCSELSH和HCSSRP则利用高阶计数草图[shi2019higher]。这些提案显著地将哈希码计算时间从O(md)减少到O(d)。此外，CSELSH和CSSRP都将空间复杂度从O(md)减少到O(d)；而HCSELSH、HCSSRP分别将空间复杂度从O(md)减少到O(N * d^(1/N))，其中N≥1表示输入/重塑张量的大小。我们的提案得到了强大的数学保证支持，并且我们通过在各种真实世界数据集上的模拟验证了它们的性能。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [626] [Max-Cut with Multiple Cardinality Constraints](https://arxiv.org/abs/2507.12607)
> *多重基数约束下的最大割*

*Yury Makarychev, Madhusudhan Reddy Pittu, Ali Vakilian* | **Category: cs.DS** | **Updated: 2025-07-16**

**Keywords:** 最大割, 基数约束, 近似算法, 关联舍入, NP难

**Comment:** 

> **TL;DR:** 本文研究了多重基数约束下的最大割问题，提出了一种改进的近似算法，并在一般情况下探讨了NP难性。

**AI_Comments:** 该论文对最大割问题（特别是在基数约束下）的近似算法做出了重要贡献。在常数约束情况下，近似比的提高以及对先前工作的推广，展示了其广泛的适用性。NP难性结果提供了关于问题复杂性的重要理论见解。近似核和关联舍入技术的结合使用是一种创新方法。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决经典的最大割问题在多重基数约束下的复杂变体，该问题推广了现有的约束最大割问题。研究目的是改进现有近似算法的性能，并克服先前工作的局限性。

**Method:** 作者为约束最大割问题设计了一个近似核，并借鉴了Raghavendra和Tan (2012)的关联舍入技术。此外，他们还提出了一个在任意拟阵约束下的最大割问题的1/2-近似算法。

**Result:** 当约束数量$c=O(1)$时，本文提出了一个$(0.858 - oldsymbol{\varepsilon})$-近似算法。这改进了Feige和Langberg (2001)对$\maxcut_k$（$c=1, k_1=k$的特殊情况）的$(\frac{1}{2} + oldsymbol{\varepsilon}_0)$-近似。该算法还推广了Raghavendra和Tan (2012)的$(0.858 - oldsymbol{\varepsilon})$-近似，后者仅适用于特定条件且不处理多重约束。对于一般的$c$值，论文证明了判断是否存在切割所有边的可行解是NP难的。最后，提出了一个在任意拟阵约束下的最大割问题的1/2-近似算法。

**Conclusion:** 本文为约束最大割问题提供了重要的算法改进，特别是在约束数量为常数的情况下，通过利用先进的舍入技术和近似核方法。同时，论文也对该问题在一般情况下的计算复杂性给出了理论分析。

> **ai_Abstract:** 本文引入了约束最大割问题，目标是在顶点不相交分区上满足多个基数约束的条件下找到最大割。对于常数数量的约束($c=O(1)$)，作者利用近似核和关联舍入技术开发了一个$(0.858 - \varepsilon)$-近似算法，显著改进并推广了现有结果。论文还证明了对于一般的$c$，判断是否存在切割所有边的解是NP难的，并为任意拟阵约束下的最大割问题提供了一个$1/2$-近似算法。

> **摘要翻译:** 我们研究了经典的最大割问题在多重基数约束下的情况，我们称之为约束最大割问题。给定一个图$G=(V, E)$，将顶点划分为$c$个不相交的部分$V_1, \ldots, V_c$，以及基数参数$k_1, \ldots, k_c$，目标是选择一个集合$S \subseteq V$，使得对于每个$i \in [c]$都有$|S \cap V_i| = k_i$，同时最大化跨越$S$的边（即恰好一个端点在$S$中的边）的总权重。
通过为约束最大割问题设计一个近似核，并借鉴Raghavendra和Tan (2012)的关联舍入技术，我们为当$c = O(1)$时的问题提出了一个$(0.858 - \varepsilon)$-近似算法。该算法的运行时间为$O\left(\min\{k/\varepsilon, n\}^{\poly(c/\varepsilon)} + \poly(n)\right)$，其中$k = \sum_{i \in [c]} k_i$且$n=|V|$。这改进了Feige和Langberg (2001)对$\maxcut_k$（当$c=1, k_1 = k$时的特殊情况）的$(\frac{1}{2} + \varepsilon_0)$-近似，并推广了Raghavendra和Tan (2012)的$(0.858 - \varepsilon)$-近似，后者仅适用于$\min\{k,n-k\}=\Omega(n)$且不处理多重约束的情况。我们还确定，对于一般的$c$值，判断是否存在一个能切割所有边的可行解是NP难的。最后，我们提出了一个在任意拟阵约束下的最大割问题的$1/2$-近似算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [632] [Beyond Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-$2^{n/2}$ Enumeration](https://arxiv.org/abs/2503.20162)
> *超越最坏情况的子集和：一种自适应、结构感知型求解器，具有低于$2^{n/2}$的枚举*

*Jesus Salas* | **Category: cs.DS, cs.CC, cs.DM, F.2.2; G.2.1; G.1.6** | **Updated: 2025-07-17**

**Keywords:** 子集和问题, NP完全, 唯一子集和, 受控混叠, 算法优化

**Comment:** 33 pages, 6 figures, includes full algorithmic framework and
  empirical validation. Companion to the theory paper "Certificate-Sensitive
  Subset Sum and the Realization of Instance Complexity"

> **TL;DR:** 本文提出了一种针对子集和问题的自适应求解器，它能有效处理具有重复部分和的实例，并通过“受控混叠”技术在最坏情况下也优于经典算法，实现了低于$2^{n/2}$的运行时间。

**AI_Comments:** 这项工作在理论和实践上都对子集和问题做出了重要贡献。其创新点在于：1. 首次明确区分了实际难度与唯一子集和数量$U$的关系，并设计了针对$U$优化的算法。2. 引入了“受控混叠”技术，使得即使在最坏情况下也能打破经典的$2^{n/2}$界限，这是一个显著的理论突破。3. 结合了自适应和结构感知特性，使其在处理实际数据时表现出色。该研究为解决其他NP完全问题提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 子集和问题是一个基础的NP完全问题，经典算法的最优确定性边界为$O^*(2^{n/2})$。然而，在实际应用中，许多实例存在大量重复的部分和，导致实际难度由唯一子集和的数量$U$决定。因此，需要一个能更好地适应这类实例的求解器，并超越传统的最坏情况界限。

**Method:** 提出了一种结构感知型自适应求解器。该求解器仅枚举不同的子集和，并实时剪枝重复项。其核心是一个规范的唯一子集和枚举器，并结合了双向折半（double meet-in-the-middle）策略，支持随时和在线模式。为了在非结构化输入上也能确保最坏情况下的性能提升，引入了“受控混叠”（Controlled Aliasing）技术，可证明地将枚举空间减少一个固定常数因子。

**Result:** 1. 在只枚举不同子集和的情况下，实现了确定性运行时间$O(U 
^2)$和期望随机运行时间$O(U 
)$。2. 通过“受控混叠”技术，确保了全局运行时间为$O^*(2^{n/2 - 
})$（其中$
 > 0$），严格优于经典算法的界限。3. 经验结果表明，该求解器能高效适应低熵的结构化输入（例如，具有小倍增常数、重复项或加法级数的实例），性能常接近动态规划。

**Conclusion:** 本文提出的自适应框架可以扩展到其他NP完全问题。

> **ai_Abstract:** 本文针对NP完全问题子集和，提出了一种名为“超越最坏情况子集和”的自适应、结构感知型求解器。该求解器通过仅枚举独特的子集和并结合双向折半策略，在实践中针对具有大量重复部分和的实例实现了$O(U 
^2)$和$O(U 
)$的运行时间（其中$U$为唯一子集和的数量）。更重要的是，通过引入“受控混叠”技术，该方法在最坏情况下也能将运行时间降低到$O^*(2^{n/2 - 
})$，从而严格超越了经典的$O^*(2^{n/2})$界限。实验结果证实了其在结构化输入上的高效适应性，并指出该框架可推广至其他NP完全问题。

> **摘要翻译:** 子集和问题，即询问给定$n$个整数的集合是否存在一个子集其和等于目标$t$，是密码学和组合优化中一个基本的NP完全问题。Horowitz-Sahni的经典折半（MIM）算法运行时间为$
^*(2^{n/2})$，这仍然是已知最佳的确定性界限。然而在实践中，许多实例显示出部分和中存在大量冲突，因此实际难度往往由$U = |
(S)|$，即唯一子集和的数量来决定。
我们提出了一种结构感知型自适应求解器，它只枚举不同的子集和，并在运行时剪枝重复项，实现了确定性运行时间$
(U 
^2)$和期望随机运行时间$
(U 
)$。其核心是一个规范的唯一子集和枚举器，结合了双向折半策略，支持随时和在线模式。
为了即使在非结构化输入上也能确保最坏情况下的增益，我们引入了一种“受控混叠”技术，该技术可证明地将枚举空间减少一个固定常数因子。这使得全局运行时间保证为$
^*(2^{n/2 - 
})$（其中$
 > 0$），严格优于经典界限。
经验结果表明，该求解器能高效适应低熵的结构化输入（例如，具有小倍增常数、重复项或加法级数的实例），性能常接近动态规划。我们最后概述了如何将这种自适应框架扩展到其他NP完全问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [658] [Compressing Suffix Trees by Path Decompositions](https://arxiv.org/abs/2506.14734)
> *通过路径分解压缩后缀树*

*Ruben Becker, Davide Cenzato, Travis Gagie, Sung-Hwan Kim, Ragnar Groot Koerkamp, Giovanni Manzini, Nicola Prezza* | **Category: cs.DS** | **Updated: 2025-07-17**

**Keywords:** 后缀树, 路径分解, 压缩索引, I/O效率, 后缀排序

**Comment:** Submitted version

> **TL;DR:** 本文提出了一种I/O高效的压缩后缀树新方法，通过泛化后缀排序和路径分解实现，在空间和查询速度上优于现有方法。

**AI_Comments:** 这篇论文的创新点在于其独特的路径分解和后缀排序泛化方法，成功地将后缀树压缩与I/O效率相结合。它解决了长期存在的I/O高效压缩索引问题，为大规模数据处理提供了有前景的解决方案。其提出的新结构既优雅又实用，为后续研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 解决设计I/O高效压缩索引的长期问题。

**Method:** 本方法通过（i）根据更通用的优先级函数$\\pi$对后缀树的叶子进行排序，（ii）构建一个优先处理最左路径的后缀树路径分解，以及（iii）将分解的路径压缩为指向字符串后缀小子集的指针。最终，这些指针的共字典序排序数组形成了一个新的I/O高效压缩后缀树。文中还探讨了两种具体实现：一种使用字典序排名匹配经典后缀树的I/O复杂度，另一种使用共字典序排名实现更优的空间和查询速度。

**Result:** 开发了一种新的、优雅、简单且I/O高效的压缩后缀树。当$\\pi$为T的后缀的字典序排名时，可在$O(r)$空间内压缩后缀树拓扑，并基本匹配Weiner和McCreight后缀树的模式匹配I/O复杂度。当$\\pi$为T的前缀的共字典序排名时，得到的自索引比$r$-index占用更少空间，定位给定查询模式的速度快几个数量级。

**Conclusion:** 该方法成功解决了I/O高效压缩索引的设计问题，并提供了在空间和查询效率上显著优于现有技术的解决方案。

> **ai_Abstract:** 本文提出了一种创新的I/O高效压缩后缀树方法，旨在解决现有压缩索引的效率问题。该方法通过泛化后缀排序和重新设计路径分解来实现，即将后缀树叶子按通用优先级函数排序，构建优先最左路径的分解，并将路径压缩为指向字符串后缀子集的指针。实验结果表明，这种新方法在空间效率上显著优于传统后缀树，并在模式匹配查询速度上与经典方法相当甚至更快，尤其是在使用特定优先级函数时，其性能超越了现有最先进的自索引。

> **摘要翻译:** 在本文中，我们解决了设计I/O高效压缩索引的长期问题。我们的解决方案主要包括泛化后缀排序和重新审视后缀树路径压缩。在经典的后缀树中，路径压缩通过将一元后缀trie路径替换为指向T的指针对来实现，这些指针在查询时必须以某种随机访问预言机的形式可用。在我们的方法中，我们（i）根据更通用的优先级函数$\\pi$（泛化后缀排序）对后缀树的叶子进行排序，（ii）我们构建一个优先处理最左路径的后缀树路径分解，（iii）我们将分解的路径压缩为指向字符串后缀小子集的指针。此时，我们表明这些指针的共字典序排序数组代表了一种新的、优雅、简单且非常I/O高效的压缩后缀树。例如，通过将$\\pi$设为T的后缀的字典序排名，我们可以在$n\log\sigma + O(\log n)$比特文本表示的基础上，以$O(r)$空间压缩后缀树拓扑，同时基本匹配Weiner和McCreight后缀树的模式匹配I/O复杂度。另一种（更实用）的解决方案是通过将$\\pi$设为T的前缀的共字典序排名并使用完全压缩的随机访问预言机获得。由此产生的自索引允许我们以比$r$-index更少的空间和快几个数量级的速度定位给定查询模式的所有出现。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [669] [Fast Approximate Rank Determination and Selection with Group Testing](https://arxiv.org/abs/2507.12634)
> *基于群组测试的快速近似秩确定与选择*

*Adiesha Liyanage, Braeden Sopp, Brendan Mumey* | **Category: cs.DS, F.2.2** | **Updated: 2025-07-16**

**Keywords:** 群组测试, 秩确定, 选择, 拉斯维加斯算法, 蒙特卡洛算法

**Comment:** 

> **TL;DR:** 该论文探讨了使用单边群组测试来加速诸如查找最小/最大元素、秩确定和选择等问题，并提供了高效的随机算法。

**AI_Comments:** 该论文为经典的基于比较的问题引入了群组测试这一有趣的应用，为秩确定和选择提供了显著更快的近似解决方案。单边群组测试的使用是一种新颖的方法。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨：如果存在群组测试操作来检查集合中的顺序关系，这能否加速诸如查找最小/最大元素、秩确定和选择等问题？

**Method:** 作者考虑使用一种单边群组测试，其中查询形式为 $u \le_Q V$ 或 $V \le_Q u$。他们为最小/最大元素查找提供了一种拉斯维加斯算法，并为近似秩确定和选择提供了蒙特卡洛算法，允许 $1 \pm \delta$ 的相对误差。

**Result:** 对于最小或最大元素查找，给出了一个拉斯维加斯算法，其预期查询复杂度为 $\mathcal{O}(\log^2 n)$。对于近似秩确定，给出了一个蒙特卡洛算法，其预期查询复杂度为 $\tilde{\mathcal{O}}(1/\delta^2 - \log \epsilon)$，其中算法成功的概率为 $1-\epsilon$。对于近似选择，给出了一个蒙特卡洛算法，其预期查询复杂度为 $\tilde{\mathcal{O}}(-\log( \epsilon \delta^2) / \delta^4)$；它以至少 $1/2$ 的概率输出一个元素 $x$，如果输出，则 $x$ 以 $1-\epsilon$ 的概率具有所需的近似秩。

**Conclusion:** 群组测试，特别是单边群组测试，可以显著加速诸如最小/最大元素查找、近似秩确定和选择等问题，通过高效的随机算法实现具有竞争力的查询复杂度。

> **ai_Abstract:** 本文研究了利用单边群组测试加速排序相关问题，包括最小/最大元素查找、秩确定和选择。研究提出了一种用于最小/最大元素查找的拉斯维加斯算法，其预期查询复杂度为 $\mathcal{O}(\log^2 n)$。对于近似秩确定和选择，论文提出了蒙特卡洛算法，这些算法允许 $1 \pm \delta$ 的相对误差，并分别实现了 $\tilde{\mathcal{O}}(1/\delta^2 - \log \epsilon)$ 和 $\tilde{\mathcal{O}}(-\log( \epsilon \delta^2) / \delta^4)$ 的预期查询复杂度，展示了群组测试在这些场景下的效率。

> **摘要翻译:** 假设可以进行群组测试操作来检查集合中的顺序关系，这能否加速诸如查找最小/最大元素、秩确定和选择等问题？我们考虑使用一种单边群组测试，其中查询形式为 $u \le_Q V$ 或 $V \le_Q u$，并且当且仅当存在某个 $v \in V$ 使得 $u \le v$ 或 $v \le u$ 时，答案为“是”。我们将注意力限制在全序关系上，并关注查询复杂度；对于最小或最大元素查找，我们给出了一个拉斯维加斯算法，其预期查询复杂度为 $\mathcal{O}(\log^2 n)$。我们还为秩确定和选择提供了随机近似算法；我们允许估计秩或选定元素存在 $1 \pm \delta$ 的相对误差，其中 $\delta > 0$。在这种情况下，我们为近似秩确定提供了一个蒙特卡洛算法，其预期查询复杂度为 $\tilde{\mathcal{O}}(1/\delta^2 - \log \epsilon)$，其中 $1-\epsilon$ 是算法成功的概率。我们还为近似选择提供了一个蒙特卡洛算法，其预期查询复杂度为 $\tilde{\mathcal{O}}(-\log( \epsilon \delta^2) / \delta^4)$；它以至少 $1/2$ 的概率输出一个元素 $x$，如果输出，则 $x$ 以 $1-\epsilon$ 的概率具有所需的近似秩。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [14] [HairFormer: Transformer-Based Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.12600)
> *HairFormer：基于Transformer的动态神经头发模拟*

*Joy Xiaoji Zhang, Jingsen Zhu, Hanyu Chen, Steve Marschner* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-16**

**Keywords:** 头发模拟, Transformer, 神经网络, 动态头发, 实时推理

**Comment:** 

> **TL;DR:** HairFormer是一种基于Transformer的两阶段神经网络，首次实现了对任意发型、身体形状和运动的通用高保真动态头发模拟，并支持实时推理。

**AI_Comments:** 该论文的创新点在于首次将Transformer架构应用于头发动力学模拟，实现了对任意发型、身体形状和运动的广泛泛化能力，并支持实时推理。其两阶段设计，特别是结合静态和动态网络的策略，有效地解决了头发-身体穿透和复杂运动模拟的挑战，是计算机图形学领域的一项重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 模拟头发动力学，使其能够推广到任意发型、身体形状和运动，是一个关键挑战。

**Method:** 提出了一种新颖的两阶段神经网络解决方案。第一阶段是一个基于Transformer的静态网络，预测任意发型的静态垂坠形状，解决头发与身体的穿透并保持头发保真度。第二阶段是一个动态网络，具有新颖的交叉注意力机制，融合静态头发特征与运动学输入，生成富有表现力的动力学和复杂的二次运动。该动态网络还支持对急剧头部运动等挑战性运动序列进行高效微调。

**Result:** 该方法实现了静态单帧垂坠和姿态序列上动态垂坠的实时推理。它展示了在各种发型下高保真和可泛化的动态头发，由物理信息损失指导，即使对于复杂的、未见的刘海发型也能解决穿透问题。

**Conclusion:** HairFormer是首个利用Transformer架构实现对任意发型、身体形状和运动进行广泛泛化的动态头发模拟方法，提供了高保真、可泛化且实时的解决方案。

> **ai_Abstract:** 本文提出了一种名为HairFormer的Transformer基两阶段神经网络，用于解决头发动力学在任意发型、身体形状和运动中的泛化难题。第一阶段的静态网络利用Transformer预测静态垂坠形状并解决穿透问题，而第二阶段的动态网络通过交叉注意力机制融合静态特征与运动学输入，生成富有表现力的动态效果。该方法实现了高保真、可泛化的头发模拟，并支持实时推理，即使对于复杂的未见发型也能有效处理穿透问题。

> **摘要翻译:** 模拟头发动力学，使其能够推广到任意发型、身体形状和运动，是一个关键挑战。我们新颖的两阶段神经解决方案是第一个利用基于Transformer的架构实现如此广泛泛化的方法。我们提出了一种由Transformer驱动的静态网络，可以预测任何发型的静态垂坠形状，有效解决头发与身体的穿透并保持头发保真度。随后，一个具有新颖交叉注意力机制的动态网络将静态头发特征与运动学输入融合，以生成富有表现力的动力学和复杂的二次运动。该动态网络还允许对具有挑战性的运动序列进行高效微调，例如突然的头部运动。我们的方法为静态单帧垂坠和姿态序列上的动态垂坠提供实时推理。我们的方法展示了在各种发型下高保真和可泛化的动态头发，由物理信息损失指导，即使对于复杂的、未见的刘海发型也能解决穿透问题，突出了其广泛的泛化能力。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [59] [VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians](https://arxiv.org/abs/2507.12667)
> *VolSegGS：通过可变形三维高斯实现动态体素场景中的分割与跟踪*

*Siyuan Yao, Chaoli Wang* | **Category: cs.GR** | **Updated: 2025-07-16**

**Keywords:** 体素场景, 高斯溅射, 分割, 跟踪, 可变形三维高斯

**Comment:** 

> **TL;DR:** VolSegGS是一个基于高斯溅射的框架，利用可变形三维高斯在动态体素场景中实现交互式分割和跟踪，支持低计算需求的实时可视化分析。

**AI_Comments:** VolSegGS的创新之处在于将可变形三维高斯与交互式分割和跟踪功能相结合，解决了现有神经辐射场方法在交互性方面的不足。其在低计算需求下实现实时分析的能力，对于处理大规模时变数据具有重要意义。该方法通过结合视图无关颜色和亲和场网络进行精细分割，并利用高斯变形实现跟踪，展现了巧妙的设计。这为科学可视化领域提供了一个强大且实用的工具。

<details>
  <summary>Details</summary>

**Motivation:** 大规模时间相关模拟数据的可视化对于领域科学家分析复杂现象至关重要，但现有方法（如神经辐射场）虽然重建质量高，却未能有效支持交互式可视化探索，如特征提取和跟踪，且对资源需求高。

**Method:** 本文提出了VolSegGS框架，它利用可变形三维高斯来表示动态体素场景，从而实现实时新视图合成。为了实现准确分割，该方法首先利用高斯的视图无关颜色进行粗粒度分割，然后通过亲和场网络进行细粒度优化。此外，通过将分割结果嵌入到高斯中，确保了高斯变形时能实现分割区域的连续跟踪。

**Result:** VolSegGS在多个时变数据集上展示了其有效性，并与现有最先进的方法进行了比较。它能够在低计算需求下提供实时动态场景交互以及灵活的分割和跟踪能力。

**Conclusion:** VolSegGS框架为时变体素数据分析和可视化开辟了新的可能性，提供了一个在低计算需求下实现交互式分割和跟踪的强大解决方案。

> **ai_Abstract:** VolSegGS是一个创新的高斯溅射框架，旨在解决大规模动态体素场景可视化中交互式分割和跟踪的挑战。它通过使用可变形三维高斯表示场景，实现了实时新视图合成。该框架结合了粗粒度（基于高斯颜色）和细粒度（基于亲和场网络）分割，并通过将分割结果嵌入高斯中实现随时间连续跟踪。VolSegGS在低计算需求下提供了高效的实时交互和分析能力，为时变体素数据分析和可视化带来了新的机遇。

> **摘要翻译:** 大规模时间相关模拟数据的可视化对于领域科学家分析复杂现象至关重要，但它对I/O带宽、存储和计算资源要求很高。为了在本地低端机器上实现有效可视化，最近的视图合成技术，如神经辐射场，利用神经网络生成体素场景的新颖可视化。然而，这些方法侧重于重建质量，而非促进交互式可视化探索，例如特征提取和跟踪。我们引入了VolSegGS，一个新颖的高斯溅射框架，支持动态体素场景中的交互式分割和跟踪，以实现探索性可视化和分析。我们的方法利用可变形三维高斯来表示动态体素场景，从而实现实时新视图合成。为了准确分割，我们利用高斯的视图无关颜色进行粗粒度分割，并通过亲和场网络对结果进行细粒度优化。此外，通过将分割结果嵌入到高斯中，我们确保它们的变形能够实现分割区域随时间的连续跟踪。我们通过几个时变数据集展示了VolSegGS的有效性，并与现有最先进的方法进行了比较。凭借实时与动态场景交互并提供灵活分割和跟踪能力，VolSegGS在低计算需求下提供了一个强大的解决方案。该框架为时变体素数据分析和可视化开辟了令人兴奋的新可能性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [104] [A Controllable Appearance Representation for Flexible Transfer and Editing](https://arxiv.org/abs/2504.15028)
> *一种可控的外观表示，用于灵活的迁移和编辑*

*Santiago Jimenez-Navarro, Julia Guerrero-Viu, Belen Masia* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 外观表示, 解耦学习, FactorVAE, 扩散模型, 图像编辑

**Comment:** EGSR 2025 - Symposium Track

> **TL;DR:** 该方法提出了一种可控且解耦的材料外观表示，通过自监督学习和扩散模型实现外观的灵活迁移和编辑，并提供精细的用户控制。

**AI_Comments:** 该论文的创新点在于提出了一个自监督学习的可控、解耦的材料外观表示，并将其成功应用于扩散模型进行灵活的外观迁移和编辑。其避免使用人工标注数据，减少了潜在偏见，并提供了对生成结果的精细控制，具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 目前的图像处理和生成方法可能缺乏对材料外观的精细控制和可解释性。本文旨在开发一种可解释、解耦且紧凑的材料外观表示，以实现灵活的外观迁移和编辑。

**Method:** 该方法使用自监督的Adapted FactorVAE来学习材料外观的表示，训练数据集是精心设计的未标注数据。然后，将此表示作为指导，训练一个轻量级的IP-Adapter来条件化扩散管道，以实现外观的迁移和编辑。

**Result:** 模型展示了强大的解耦性和可解释性，有效地编码了材料外观和光照，尽管没有显式监督。该方法能将一个或多个图像的外观转移到目标几何体上，并允许用户进一步编辑结果外观，提供对生成结果的精细控制，用户可以直观地操纵色调或光泽度等属性。

**Conclusion:** 本文提出了一种通过自监督学习获得的、可解释且解耦的材料外观表示。该表示结合扩散模型，实现了灵活且可控的外观迁移和编辑，赋予用户对生成结果的精细控制能力。

> **ai_Abstract:** 本文提出了一种基于自监督学习的、可解释且解耦的材料外观表示方法。该方法利用改编的FactorVAE在未标注数据集上进行训练，有效编码了材料外观和光照。通过将此表示与轻量级IP-Adapter和扩散管道结合，实现了将图像外观灵活迁移到目标几何体并进行精细编辑的功能，允许用户直观控制如色调、光泽度等属性。

> **摘要翻译:** 我们提出了一种方法，该方法在高度紧凑、解耦的潜在空间中计算材料外观的可解释表示。这种表示通过自监督方式使用改编的FactorVAE进行学习。我们使用精心设计的未标注数据集训练我们的模型，避免了人类生成标签可能引起的偏差。我们的模型展示了强大的解耦性和可解释性，尽管没有显式监督，但仍能有效编码材料外观和光照。然后，我们使用我们的表示作为指导，训练一个轻量级的IP-Adapter来条件化扩散管道，将一个或多个图像的外观转移到目标几何体上，并允许用户进一步编辑结果外观。我们的方法对生成结果提供了精细的控制：由于结构良好的紧凑潜在空间，用户可以在图像空间中直观地操纵色调或光泽度等属性，以达到所需的最终外观。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [636] [WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation](https://arxiv.org/abs/2507.12493)
> *WaFusion：一种用于人脸形变生成的小波增强扩散框架*

*Seyed Rasoul Hosseini, Omid Ahmadieh, Jeremy Dawson, Nasser Nasrabadi* | **Category: cs.GR** | **Updated: 2025-07-15**

**Keywords:** 人脸形变生成, 小波分解, 扩散模型, 生物识别安全, WaFusion

**Comment:** 

> **TL;DR:** WaFusion是一个结合小波分解和扩散模型的新框架，用于高效生成高质量、逼真的人脸形变图像，解决了生物识别身份验证系统中的安全挑战。

**AI_Comments:** WaFusion的创新之处在于将小波分解与扩散模型相结合，有效提升了人脸形变图像的质量并减少了伪影。其在多个数据集上的优异表现以及对生物识别安全指标的显著改善，使其成为该领域的一个重要进展。该框架有望为未来的生物识别系统提供更强大的安全保障。

<details>
  <summary>Details</summary>

**Motivation:** 生物识别面部形变对身份验证系统构成严峻挑战，损害其安全性和鲁棒性。本文旨在解决这一问题，提升生物识别安全。

**Method:** 本文提出了WaFusion框架，它结合了小波分解和扩散模型来生成高质量、逼真的人脸形变图像。WaFusion利用小波变换捕获的结构细节和扩散模型的生成能力，生成伪影最少的人脸形变。

**Result:** 在FERET、FRGC、FRLL和WVU Twin数据集上进行的实验表明，WaFusion优于最先进的方法，能生成伪影更少的高分辨率形变图像。该框架在关键生物识别指标（包括攻击呈现分类错误率（APCER）、真实呈现分类错误率（BPCER）和等错误率（EER））方面表现出色。

**Conclusion:** WaFusion在生物识别形变生成领域设立了新基准，提供了一种尖端高效的解决方案来增强生物识别安全系统。

> **ai_Abstract:** WaFusion是一个新颖的框架，它结合了小波分解和扩散模型，旨在高效生成高质量、逼真的人脸形变图像，以应对生物识别身份验证系统的安全挑战。该方法利用小波变换捕获细节并结合扩散模型的生成能力，生成伪影极少的形变图像。实验结果表明，WaFusion在多个数据集上优于现有技术，并在关键生物识别指标上表现出色，为生物识别安全系统提供了一个先进的解决方案。

> **摘要翻译:** 生物识别面部形变对身份验证系统构成了严峻挑战，损害了其安全性和鲁棒性。为了解决这个问题，我们提出了WaFusion，一个结合了小波分解和扩散模型的新颖框架，旨在高效生成高质量、逼真的人脸形变图像。WaFusion利用小波变换捕获的结构细节和扩散模型的生成能力，生成伪影最少的人脸形变。在FERET、FRGC、FRLL和WVU Twin数据集上进行的实验表明，WaFusion优于最先进的方法，能生成伪影更少的高分辨率形变图像。我们的框架在关键生物识别指标，包括攻击呈现分类错误率（APCER）、真实呈现分类错误率（BPCER）和等错误率（EER）方面表现出色。这项工作在生物识别形变生成领域设立了新基准，提供了一种尖端高效的解决方案来增强生物识别安全系统。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [679] [Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition](https://arxiv.org/abs/2507.12498)
> *Wavelet-GS：基于小波分解的3D高斯泼溅*

*Beizhen Zhao, Yifan Zhou, Sicheng Yu, Zijian Wang, Hao Wang* | **Category: cs.GR, cs.MM** | **Updated: 2025-07-16**

**Keywords:** 3D高斯泼溅, 小波分解, 场景重建, 解耦优化, 光照效果

**Comment:** 9 pages

> **TL;DR:** Wavelet-GS通过引入3D和2D小波分解，解决了传统3D高斯泼溅在复杂场景中重建不完整和光照效果不佳的问题，实现了更先进的3D场景重建性能。

**AI_Comments:** Wavelet-GS的创新点在于将小波分解引入到3D高斯泼溅中，通过对点云进行高低频解耦优化，以及结合2D小波分解指导细节重建，有效解决了复杂场景重建中结构不完整和光照不清晰的问题。这种分频处理的思路，使得模型能够更精细地捕捉全局结构和局部细节，并优化光照效果，显著提升了3D场景重建的质量和真实感，是该领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅（3DGS）方法在复杂场景重建中面临显著挑战，表现为整体结构轮廓不完整和局部光照效果不清晰，尽管其在渲染质量、效率和速度之间取得了有效平衡。

**Method:** 本文提出了一种新颖的解耦优化框架，将小波分解集成到3D高斯泼溅和2D采样中。通过3D小波分解将点云分解为高频和低频分量进行针对性优化：低频分量通过体素化捕获全局结构轮廓并管理高斯分布；高频分量恢复精细的几何和纹理细节，并结合重光照模块以减轻光照伪影。此外，对训练图像应用2D小波分解来模拟辐射变化，为高频细节重建提供关键指导。

**Result:** 在具有挑战性的数据集上进行的广泛实验表明，Wavelet-GS方法在各项指标上均达到了最先进的性能，超越了现有方法。

**Conclusion:** 通过引入小波分解进行解耦优化，Wavelet-GS有效解决了3D高斯泼溅在复杂场景重建中的局限性，显著提升了3D场景重建的性能和质量，推动了该领域的发展。

> **ai_Abstract:** 本文提出了Wavelet-GS，一个结合3D和2D小波分解的新型解耦优化框架，以改进3D高斯泼溅在复杂场景重建中的表现。该方法将点云分解为高频和低频分量进行独立优化，其中低频分量处理全局结构，高频分量恢复细节并处理光照。同时，2D小波分解应用于训练图像以指导细节重建。实验结果表明，Wavelet-GS在多项指标上达到了最先进的性能，有效解决了现有3DGS方法的局限性，提升了3D场景重建的质量。

> **摘要翻译:** 3D高斯泼溅（3DGS）彻底改变了3D场景重建，有效平衡了渲染质量、效率和速度。然而，现有的3DGS方法通常会产生合理的结果，但在复杂场景重建中面临显著挑战，表现为整体结构轮廓不完整和局部光照效果不清晰。为了同时解决这些问题，我们提出了一种新颖的解耦优化框架，该框架将小波分解集成到3D高斯泼溅和2D采样中。从技术上讲，通过3D小波分解，我们的方法将点云分为高频和低频分量，从而能够针对每个分量进行优化。低频分量捕获全局结构轮廓并通过体素化管理高斯分布。相比之下，高频分量恢复复杂的几何和纹理细节，同时结合了一个重光照模块以减轻光照伪影并增强照片级真实感渲染。此外，对训练图像应用2D小波分解，模拟辐射变化。这为高频细节重建提供了关键指导，确保细节与全局结构的无缝集成。在具有挑战性的数据集上进行的广泛实验表明，我们的方法在各项指标上均达到了最先进的性能，超越了现有方法，并推动了3D场景重建领域的发展。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [202] [Machine-Readable Ads: Accessibility and Trust Patterns for AI Web Agents interacting with Online Advertisements](https://arxiv.org/abs/2507.12844)
> *机器可读广告：AI网络代理与在线广告交互的可访问性和信任模式*

*Joel Nitu, Heidrun Mühle, Andreas Stöckl* | **Category: cs.IR** | **Updated: 2025-07-17**

**Keywords:** AI网络代理, 在线广告, 机器可读广告, 信任, 可访问性

**Comment:** 

> **TL;DR:** 研究发现，AI网络代理在与在线广告交互时表现出严重的满足性，并揭示了需要改进的信任和可访问性设计原则。

**AI_Comments:** 这篇论文具有重要的创新性，它首次系统地研究了AI网络代理与在线广告的交互行为，揭示了当前广告设计对AI代理的不足。其提出的五项设计原则为广告商和开发者提供了实用的指导，以优化广告对机器的可读性，从而适应未来AI主导的在线环境。研究还深入探讨了AI代理的信任问题，强调了在自动化交互中确保安全和负责任行为的紧迫性，这对于构建可靠的AI生态系统至关重要。潜在的局限性可能在于实验环境的模拟性质，实际网络环境的复杂性可能带来更多挑战。

<details>
  <summary>Details</summary>

**Motivation:** 自主多模态语言模型正在迅速发展成为网络代理，能够代表用户浏览、点击和购买物品，这对为人类设计的展示广告构成了威胁。然而，关于这些代理如何与广告交互或哪些设计原则能确保可靠参与，人们知之甚少。本研究旨在解决这一问题。

**Method:** 研究人员使用新闻网站TT.com的忠实克隆版本进行了一项受控实验，其中包含各种广告类型（静态横幅、GIF、轮播、视频、Cookie对话框和付费墙）。他们使用以文档对象模型（DOM）为中心的浏览器使用框架，对GPT-4o、Claude 3.7 Sonnet、Gemini 2.0 Flash和基于像素的OpenAI Operator运行了300次初始试验和后续试验，涵盖10个真实的用例。

**Result:** 结果显示，这些代理表现出严重的满足性：它们从不滚动超过两个视口，并忽略纯视觉的行动呼吁，仅在存在语义按钮叠加或屏幕外文本标签时才点击横幅。关键是，当抽奖活动需要购买时，GPT-4o和Claude 3.7 Sonnet在100%的试验中订阅，Gemini 2.0 Flash在70%的试验中订阅，这揭示了成本效益分析的缺陷。研究确定了五个可操作的设计原则——语义叠加、隐藏标签、左上角放置、静态框架和对话框替换，这些原则可以在不损害用户体验的情况下使以人为中心的创意内容对机器可检测。

**Conclusion:** 本研究揭示了AI网络代理在与在线广告交互时的满足性行为和信任差距。它提出了五项设计原则，以提高机器可检测性，并强调了在现实世界广告中对AI代理进行稳健信任评估框架的迫切需求。

> **ai_Abstract:** 本研究探讨了AI网络代理与在线广告的交互方式，旨在解决当前广告主要为人类设计所带来的挑战。通过在新闻网站克隆上进行的受控实验，研究人员测试了GPT-4o、Claude 3.7 Sonnet和Gemini 2.0 Flash等模型，发现这些代理在处理广告时表现出“满足性”行为，即它们倾向于最小努力并忽略纯视觉元素，仅在有明确语义提示时才点击。更重要的是，在需要购买的场景中，这些代理在很大程度上未能进行有效的成本效益分析，导致高比例的意外订阅。为解决这些问题，论文提出了五项关键设计原则（语义叠加、隐藏标签、左上角放置、静态框架和对话框替换），以使广告对机器更具可读性，同时不影响用户体验。此外，研究强调了评估AI代理信任度的重要性，并呼吁建立更稳健的信任评估框架，以应对未来AI驱动的在线广告交互。

> **摘要翻译:** 自主多模态语言模型正在迅速发展成为网络代理，能够代表用户浏览、点击和购买物品，这对为人类设计的展示广告构成了威胁。然而，关于这些代理如何与广告交互或哪些设计原则能确保可靠参与，人们知之甚少。为了解决这个问题，我们使用新闻网站TT.com的忠实克隆版本进行了一项受控实验，其中包含各种广告：静态横幅、GIF、轮播、视频、Cookie对话框和付费墙。我们使用以文档对象模型（DOM）为中心的浏览器使用框架，对GPT-4o、Claude 3.7 Sonnet、Gemini 2.0 Flash和基于像素的OpenAI Operator运行了300次初始试验以及后续试验，涵盖10个真实的用例。我们的结果显示这些代理表现出严重的满足性：它们从不滚动超过两个视口，并忽略纯视觉的行动呼吁，仅在存在语义按钮叠加或屏幕外文本标签时才点击横幅。关键是，当抽奖活动需要购买时，GPT-4o和Claude 3.7 Sonnet在100%的试验中订阅，Gemini 2.0 Flash在70%的试验中订阅，这揭示了成本效益分析的缺陷。我们确定了五个可操作的设计原则——语义叠加、隐藏标签、左上角放置、静态框架和对话框替换，这些原则可以在不损害用户体验的情况下使以人为中心的创意内容对机器可检测。我们还通过“行为模式”（如Cookie同意处理和订阅选择）评估了代理的信任度，突出了模型特定的风险边界以及在现实世界广告中对健壮信任评估框架的迫切需求。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [250] [SGCL: Unifying Self-Supervised and Supervised Learning for Graph Recommendation](https://arxiv.org/abs/2507.13336)
> *SGCL: 统一自监督和监督学习的图推荐系统*

*Weizhi Zhang, Liangwei Yang, Zihe Song, Henrry Peng Zou, Ke Xu, Yuanjie Zhu, Philip S. Yu* | **Category: cs.IR** | **Updated: 2025-07-17**

**Keywords:** 图推荐, 自监督学习, 监督学习, 对比学习, 推荐系统

**Comment:** Accepted in RecSys 2025. arXiv admin note: substantial text overlap
  with arXiv:2404.15954

> **TL;DR:** SGCL通过统一监督对比学习，解决了图推荐中自监督和监督学习分离导致的训练低效和性能问题，实现了更快的训练和优越的性能。

**AI_Comments:** SGCL的创新点在于将推荐任务和对比学习任务统一在一个监督对比学习损失中，解决了传统多任务学习框架中梯度不一致和额外计算的问题。这种统一的优化方向显著提升了训练效率和模型性能，为图推荐领域提供了一个高效且有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有自监督图学习在推荐系统中存在问题：单独设计导致额外的图卷积过程，不同损失函数导致梯度方向不一致，从而导致训练时间长和性能次优。

**Method:** 引入SGCL框架，将推荐训练和无监督对比损失结合到一个统一的监督对比学习损失中，使两个任务在单一优化方向上对齐。

**Result:** 在三个真实世界数据集上的广泛实验表明，SGCL优于最先进的方法，实现了更高的准确性和效率。

**Conclusion:** SGCL通过统一的监督对比学习框架，有效解决了现有方法的训练效率和性能问题，为图推荐提供了更优的解决方案。

> **ai_Abstract:** 本文提出了SGCL（Supervised Graph Contrastive Learning for recommendation）框架，旨在解决现有图推荐系统中自监督和监督学习分离导致训练效率低和性能次优的问题。SGCL通过将推荐损失和无监督对比损失统一到一个监督对比学习损失中，实现了单一优化方向，从而显著加快了训练速度。在多个真实数据集上的实验证明，SGCL在准确性和效率上均超越了现有SOTA方法。

> **摘要翻译:** 推荐系统（RecSys）对于在线平台至关重要，它在海量信息中为用户提供个性化建议。自监督图学习旨在通过对用户-物品二部图进行无监督增强来利用高阶协同过滤信号，主要利用包含监督推荐损失和自监督对比损失的多任务学习框架。然而，这种分离设计引入了额外的图卷积过程，并由于不同的损失函数导致梯度方向不一致，从而导致训练时间延长和次优性能。在本研究中，我们引入了一种用于推荐的统一监督图对比学习（SGCL）框架来解决这些问题。SGCL独特地将推荐训练和无监督对比损失结合到一个内聚的监督对比学习损失中，使两项任务在单一优化方向上对齐，以实现异常快速的训练。在三个真实世界数据集上的广泛实验表明，SGCL优于最先进的方法，实现了更高的准确性和效率。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [387] [LLM-RecG: A Semantic Bias-Aware Framework for Zero-Shot Sequential Recommendation](https://arxiv.org/abs/2501.19232)
> *LLM-RecG：一种语义偏差感知零样本序列推荐框架*

*Yunzhe Li, Junting Wang, Hari Sundaram, Zhining Liu* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 零样本推荐, 序列推荐, 大型语言模型, 跨域, 语义偏差

**Comment:** 10 pages, Recsys'25 Spotlight Oral

> **TL;DR:** 提出LLM-RecG框架，通过解决领域语义偏差，提升基于LLM的零样本跨域序列推荐效果。

**AI_Comments:** 该论文针对基于LLM的零样本跨域序列推荐中存在的领域语义偏差问题，提出了一个新颖且全面的解决方案。其创新点在于同时考虑了项目和序列层面的偏差消除，特别是引入的泛化损失在平衡域间对齐和域内多样性方面具有独到之处。这对于提升LLM在推荐系统领域，尤其是在数据稀疏和冷启动场景下的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统模型在稀疏数据环境下存在局限性。尽管大型语言模型(LLMs)通过预训练表示增强了零样本跨域序列推荐(ZCDSR)，但领域语义偏差（词汇和内容差异）导致项目嵌入未对齐和泛化能力下降，这阻碍了LLM在ZCDSR中的有效应用。

**Method:** 我们提出了一个新颖的语义偏差感知框架LLM-RecG，通过在项目和序列两个层面改进跨领域对齐来增强基于LLM的ZCDSR。在项目层面，引入泛化损失，以对齐跨领域的项目嵌入（域间紧凑性），同时保留每个项目在其自身领域内的独特特征（域内多样性）。在序列层面，开发了一种方法来转移用户行为模式，通过聚类源域用户序列并在目标域推理期间应用基于注意力的聚合，动态调整用户嵌入以适应未见领域。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究提出LLM-RecG，一个用于零样本跨域序列推荐（ZCDSR）的语义偏差感知框架。针对现有LLM-based ZCDSR在处理领域语义偏差时遇到的项目嵌入未对齐和泛化能力下降问题，LLM-RecG在项目和序列两个层面进行创新。在项目层面，通过引入泛化损失实现跨域项目嵌入对齐（域间紧凑性）同时保持域内多样性。在序列层面，通过聚类源域用户序列并应用注意力聚合来转移用户行为模式，从而在无需目标域交互的情况下实现有效的零样本推荐。

> **摘要翻译:** 零样本跨域序列推荐（ZCDSR）无需额外训练或微调即可在未见领域进行预测，解决了传统模型在稀疏数据环境中的局限性。大型语言模型（LLMs）的最新进展通过丰富的预训练表示极大地增强了ZCDSR，促进了跨领域知识迁移。尽管取得了这些进展，但领域语义偏差——源于领域间词汇和内容焦点的差异——仍然是一个持续存在的挑战，导致项目嵌入未对齐和跨领域泛化能力降低。为了解决这个问题，我们提出了一种新颖的语义偏差感知框架，通过在项目和序列两个层面改进跨领域对齐来增强基于LLM的ZCDSR。在项目层面，我们引入了一种泛化损失，以对齐跨领域的项目嵌入（域间紧凑性），同时保留每个项目在其自身领域内的独特特征（域内多样性）。这确保了项目嵌入可以在领域之间有效迁移，而不会退化为过于通用或统一的表示。在序列层面，我们开发了一种方法来转移用户行为模式，通过聚类源域用户序列并在目标域推理期间应用基于注意力的聚合。我们动态调整用户嵌入以适应未见领域，从而实现有效的零样本推荐，而无需目标域交互。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [404] [Bridging the Gap: Leveraging Retrieval-Augmented Generation to Better Understand Public Concerns about Vaccines](https://arxiv.org/abs/2507.12840)
> *弥合差距：利用检索增强生成技术更好地理解公众对疫苗的担忧*

*Muhammad Javed, Sedigh Khademi Habibabadi, Christopher Palmer, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila* | **Category: cs.IR, cs.LG, cs.SI** | **Updated: 2025-07-17**

**Keywords:** 疫苗犹豫, 检索增强生成, 大型语言模型, 社交媒体, 公共卫生

**Comment:** 

> **TL;DR:** 本文开发了一个基于检索增强生成（RAG）的工具VaxPulse Query Corner，用于分析社交媒体上公众对疫苗的担忧，克服了传统方法和LLM的局限性，并表现出高准确度。

**AI_Comments:** 该研究的创新之处在于将检索增强生成（RAG）技术应用于理解复杂的公共卫生问题，特别是疫苗犹豫。它有效地结合了LLMs的语言理解能力与外部知识检索，克服了LLMs的“幻觉”问题和信息滞后性。这对于公共卫生管理者来说是一个重要的工具，能够提供更准确、及时的公众情绪洞察，从而制定更精准的干预措施。

<details>
  <summary>Details</summary>

**Motivation:** 疫苗犹豫威胁公共健康，导致疫苗接种延迟或拒绝；传统主题建模方法难以捕捉细微意见；大型语言模型（LLMs）常错过时事和社区关注点，且存在幻觉问题，可能损害公共健康沟通。

**Method:** 开发了一个名为VaxPulse Query Corner的工具，该工具使用了检索增强生成（Retrieval Augmented Generation, RAG）技术。它用于处理关于公众疫苗担忧的复杂查询，并分析社交媒体数据。

**Result:** 该工具分析了35,103条Shingrix疫苗相关的社交媒体帖子，并实现了0.96的答案忠实度和0.94的答案相关性。

**Conclusion:** VaxPulse Query Corner工具能够有效帮助公共卫生管理者和利益相关者理解公众担忧，并实施有针对性的干预措施以提高疫苗信心。

> **ai_Abstract:** 本文开发了一个名为VaxPulse Query Corner的工具，利用检索增强生成（RAG）技术来分析社交媒体上公众对疫苗的担忧。该工具旨在克服传统主题建模方法和大型语言模型（LLMs）在捕捉细微意见、处理时事及避免幻觉方面的局限性。通过分析数万条社交媒体帖子，该工具在理解公众关注点方面表现出高忠实度和相关性，为公共卫生管理提供了有效支持。

> **摘要翻译:** 疫苗犹豫威胁公共健康，导致疫苗接种延迟或拒绝。社交媒体是了解公众担忧的重要来源，而像主题建模这样的传统方法往往难以捕捉细微的意见。尽管大型语言模型（LLMs）经过查询回答训练，但它们经常错过时事和社区关注点。此外，LLMs中的幻觉可能会损害公共健康沟通。为了解决这些局限性，我们开发了一个使用检索增强生成技术的工具（VaxPulse Query Corner）。它解决了关于在线平台上公众疫苗担忧的复杂查询，帮助公共卫生管理者和利益相关者理解公众担忧并实施有针对性的干预措施以提高疫苗信心。通过分析35,103条Shingrix社交媒体帖子，该工具实现了0.96的答案忠实度和0.94的答案相关性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [422] [Imagine All The Relevance: Scenario-Profiled Indexing with Knowledge Expansion for Dense Retrieval](https://arxiv.org/abs/2503.23033)
> *想象所有相关性：面向场景的知识扩展索引用于密集检索*

*Sangam Lee, Ryang Heo, SeongKu Kang, Dongha Lee* | **Category: cs.IR** | **Updated: 2025-07-17**

**Keywords:** 密集检索, 知识扩展, 场景分析索引, 大型语言模型, 推理感知检索

**Comment:** Accepted to COLM 2025

> **TL;DR:** SPIKE是一种新的密集检索框架，通过将文档分解为基于场景的检索单元并利用大型语言模型生成场景增强数据集，从而捕捉需要推理的隐式相关性，显著提升了检索性能。

**AI_Comments:** SPIKE的创新之处在于其对“场景”的引入，将文档分解为基于推理单元的场景，并利用LLM进行知识扩展和蒸馏。这为密集检索领域提供了一个解决隐式相关性捕捉问题的新颖视角，特别是在处理复杂、需要深层推理的检索任务时显得尤为重要。其对用户体验和RAG的潜在提升也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有密集检索模型难以处理需要推理的检索任务，因为它们无法捕捉超越表面语义信息的隐式相关性。

**Method:** 我们提出了SPIKE（Scenario-Profiled Indexing with Knowledge Expansion），一个通过将文档分解为基于场景的检索单元来显式索引隐式相关性的密集检索框架。SPIKE利用强大的教师大型语言模型（LLM）构建场景增强数据集，然后将推理能力蒸馏到一个更小、高效的场景生成器中。在推理过程中，SPIKE结合了场景级和文档级相关性。

**Result:** 广泛的实验表明，SPIKE在各种查询类型和密集检索器上持续提升了检索性能。它还通过场景提升了用户检索体验，并为检索增强生成（RAG）中的LLM提供了有价值的上下文信息。

**Conclusion:** SPIKE通过显式索引隐式相关性，有效解决了密集检索模型在推理密集型任务中的挑战，显著提升了检索性能、用户体验并为RAG提供了更好的上下文。

> **ai_Abstract:** 本文提出了SPIKE（Scenario-Profiled Indexing with Knowledge Expansion），一个针对密集检索的创新框架，旨在解决现有模型在处理需要深入推理的隐式相关性方面的不足。SPIKE通过将文档分解为基于场景的检索单元来显式捕捉推理过程，并利用大型语言模型构建场景增强数据集，随后将能力蒸馏至小型生成器。在检索时，SPIKE结合了场景级和文档级相关性，从而实现了更有效的推理感知检索。实验证明，SPIKE能显著提升不同查询类型和密集检索器的检索性能，改善用户体验，并为RAG中的LLM提供丰富上下文。

> **摘要翻译:** 现有密集检索模型在推理密集型检索任务中表现不佳，因为它们无法捕捉需要超越表面语义信息进行推理的隐式相关性。为了解决这些挑战，我们提出了带有知识扩展的场景分析索引（SPIKE），这是一个密集检索框架，通过将文档分解为基于场景的检索单元来显式索引隐式相关性。SPIKE将文档组织成场景，这些场景封装了揭示假设信息需求和文档内容之间隐式关系所需的推理过程。SPIKE使用强大的教师大型语言模型（LLM）构建了一个场景增强数据集，然后将这些推理能力蒸馏到一个更小、高效的场景生成器中。在推理过程中，SPIKE将场景级相关性与文档级相关性相结合，从而实现推理感知检索。广泛的实验表明，SPIKE在各种查询类型和密集检索器上持续提升了检索性能。它还通过场景提升了用户的检索体验，并为检索增强生成（RAG）中的LLM提供了有价值的上下文信息。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [462] [LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation](https://arxiv.org/abs/2507.10917)
> *LLM驱动的双层多兴趣建模推荐系统*

*Ziyan Wang, Yingpeng Du, Zhu Sun, Jieyi Bi, Haoyan Chua, Tianjun Wei, Jie Zhang* | **Category: cs.IR** | **Updated: 2025-07-17**

**Keywords:** LLM, 多兴趣建模, 推荐系统, 双层模型, 对比学习

**Comment:** 10 pages, 5 figures

> **TL;DR:** 本文提出一个LLM驱动的双层多兴趣建模框架，用于解决现有方法在捕获用户真实多兴趣方面的局限性以及LLM生成兴趣粒度未知和数据稀疏性问题，并在真实数据集上取得了SOTA性能。

**AI_Comments:** 本文创新性地将LLM应用于推荐系统的多兴趣建模，并通过双层（个体与群体）设计有效解决了LLM应用中的粒度不确定和数据稀疏性挑战。其引入的对齐模块和最大覆盖问题优化了兴趣表示和群体聚合，对提升推荐精度具有重要意义。该工作为LLM在推荐领域，特别是复杂用户兴趣建模方面，提供了新的思路和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统在建模用户多兴趣时，常依赖启发式假设，导致未能有效捕捉与真实场景相符的用户多兴趣。尽管大型语言模型（LLMs）在多兴趣分析方面潜力巨大，但仍面临两个挑战：一是LLM驱动的多兴趣粒度不确定，可能导致兴趣分组过细或过粗；二是针对个体用户的分析因数据稀疏性而洞察有限。

**Method:** 本文提出了一个LLM驱动的双层多兴趣建模框架。在用户个体层面，利用LLM将用户交互的物品灵活分配到不同的语义簇中，以表示其多样且独特的兴趣。为解决LLM生成粒度未知的问题，通过一个对齐模块，将这些语义簇自适应地分配给从全局用户-物品交互中学习到的协作多兴趣，从而根据用户行为自动调整粒度。在用户群体层面，为缓解个体用户行为洞察有限的问题，提出将用户群聚集成具有丰富行为的合成用户，进行更全面的LLM驱动多兴趣分析。通过构建一个最大覆盖问题来确保合成用户行为的紧凑性和代表性，然后基于其LLM驱动的多兴趣进行对比学习，以解耦不同兴趣间的物品表示。

**Result:** 在真实世界数据集上的实验表明，本文提出的方法优于现有最先进的方法。

**Conclusion:** 本文提出的LLM驱动双层多兴趣建模框架，有效解决了现有推荐系统在多兴趣建模中的局限性、LLM生成兴趣粒度未知以及数据稀疏性问题，并在推荐性能上超越了SOTA方法，证明了其在捕获用户真实多兴趣方面的优越性。

> **ai_Abstract:** 本文提出一种名为“LLM-驱动的双层多兴趣建模”的推荐框架，旨在解决传统方法在捕兴趣方面的局限性以及LLM应用中存在的粒度不确定和数据稀疏问题。该框架在用户个体层面利用LLM进行物品语义聚类，并通过对齐模块自适应调整兴趣粒度；在用户群体层面，通过聚合用户群形成合成用户进行多兴趣分析，并运用最大覆盖问题和对比学习来优化物品表示。实验结果表明，该方法显著优于现有SOTA方法。

> **摘要翻译:** 最近，在基于用户行为或辅助信号建模用户多兴趣方面投入了大量精力。然而，现有方法通常依赖启发式假设，例如，共同出现的物品表示用户的相同兴趣，未能捕捉与真实世界场景相符的用户多兴趣。虽然大型语言模型（LLMs）因其广泛的知识和强大的推理能力在多兴趣分析方面显示出巨大潜力，但仍存在两个关键挑战。首先，LLM驱动的多兴趣粒度是不可知的，可能导致兴趣分组过于精细或粗糙。其次，由于数据稀疏性问题，个体用户分析提供的洞察有限。在本文中，我们提出了一种LLM驱动的双层多兴趣建模框架，以实现更有效的推荐。在用户个体层面，我们利用LLMs将用户参与的物品灵活地分配到不同的语义簇中，表明他们多样且独特的兴趣。为了减轻LLMs的不可知生成，我们自适应地将这些语义簇分配给从全局用户-物品交互中学习到的用户协作多兴趣，通过一个对齐模块允许粒度根据用户的行为自动调整。为了缓解个体用户行为带来的有限洞察，在用户群体层面，我们提出将用户小团体聚合成具有丰富行为的合成用户，以进行更全面的LLM驱动多兴趣分析。我们公式化了一个最大覆盖问题，以确保合成用户行为的紧凑性和代表性，然后基于其LLM驱动的多兴趣进行对比学习，以解耦不同兴趣间的物品表示。在真实世界数据集上的实验表明，我们的方法优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [535] [Generative Multi-Target Cross-Domain Recommendation](https://arxiv.org/abs/2507.12871)
> *生成式多目标跨域推荐*

*Jinqiu Jin, Yang Zhang, Junwei Pan, Fuli Feng, Hua Lu, Haijie Gu, Xiangnan He* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 生成式推荐, 多目标, 跨域推荐, 语义标识符, 对比学习

**Comment:** 

> **TL;DR:** 本文提出GMC，一种基于生成范式的多目标跨域推荐方法，通过语义量化离散物品标识符和统一生成模型来解决现有方法的局限性，并在多个数据集上表现出有效性。

**AI_Comments:** 该论文通过引入生成式范式和语义量化离散物品标识符，为多目标跨域推荐提供了一个新颖的解决方案，有效解决了传统方法对共享实体或大量预训练数据的依赖问题。其创新点在于将推荐任务转化为序列生成，并通过域感知机制提升了跨域知识的利用效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多目标跨域推荐（MTCDR）方法主要依赖于域共享实体进行知识融合和迁移，这在非重叠推荐场景中可能不可用；或者需要大量的辅助数据进行预训练。因此，开发更有效的MTCDR解决方案仍然是一个重要的探索领域。

**Method:** 本文提出了GMC，一种基于生成范式的多目标跨域推荐方法。GMC的核心思想是利用语义量化的离散物品标识符作为媒介，在一个统一的生成模型中整合多域知识。GMC首先使用物品分词器为每个物品生成域共享的语义标识符，然后通过训练一个域统一的序列到序列模型，将物品推荐表述为下一个令牌生成任务。为了进一步利用域信息增强性能，GMC在语义标识符学习中融入了域感知对比损失，并对统一推荐器进行域特定微调。

**Result:** 在五个公共数据集上进行的大量实验表明，与一系列基线方法相比，GMC是有效的。

**Conclusion:** 本文提出的GMC方法通过其生成式范式、语义量化离散物品标识符以及域感知机制，为多目标跨域推荐提供了一个有效且性能优越的解决方案。

> **ai_Abstract:** 本文针对多目标跨域推荐（MTCDR）中现有方法对共享实体或大量预训练数据依赖的问题，提出了一种名为GMC的生成式方法。GMC通过将语义量化的离散物品标识符作为跨域知识整合的媒介，并构建一个统一的生成模型将推荐任务转化为下一个令牌生成。此外，GMC还引入了域感知对比损失和域特定微调来进一步提升性能。实验证明，GMC在多个公共数据集上均优于现有基线方法。

> **摘要翻译:** 最近，多目标跨域推荐（MTCDR）引起了广泛关注，旨在同时提升多个领域的推荐性能。现有的MTCDR方法主要依赖于域共享实体（如用户或物品）来融合和迁移跨域知识，这在非重叠推荐场景中可能不可用。一些研究将用户偏好和物品特征建模为域可共享的语义表示，可用于解决MTCDR任务。然而，它们通常需要大量的辅助数据进行预训练。为MTCDR开发更有效的解决方案仍然是一个重要的探索领域。
受生成式推荐最新进展的启发，本文引入了GMC，一种基于生成范式的方法，用于多目标跨域推荐。GMC的核心思想是利用语义量化的离散物品标识符作为媒介，在一个统一的生成模型中整合多域知识。GMC首先采用物品分词器为每个物品生成域共享的语义标识符，然后通过训练一个域统一的序列到序列模型，将物品推荐表述为下一个令牌生成任务。为了进一步利用域信息增强性能，我们在语义标识符学习中融入了域感知对比损失，并对统一推荐器进行域特定微调。在五个公共数据集上进行的大量实验表明，与一系列基线方法相比，GMC是有效的。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [264] [Adversarial attacks to image classification systems using evolutionary algorithms](https://arxiv.org/abs/2507.13136)
> *使用进化算法对图像分类系统进行对抗性攻击*

*Sergio Nesmachnow, Jamal Toutouh* | **Category: cs.NE** | **Updated: 2025-07-17**

**Keywords:** 对抗性攻击, 图像分类, 进化算法, 生成对抗网络, 安全性

**Comment:** Genetic and Evolutionary Computation Conference (GECCO '25), July
  14--18, 2025, Malaga, Spain

> **TL;DR:** 本文提出了一种结合进化算法和生成对抗网络的方法，用于生成针对图像分类器的对抗性攻击，并在手写数字和物体图像分类任务中取得了比现有方法更好的攻击成功率。

**AI_Comments:** 本文的创新之处在于将进化算法与生成对抗网络相结合，以更有效地生成对抗性攻击。其重要性在于提供了一种新的、更成功的攻击方法，这对于理解和提升图像分类系统的安全性具有重要意义。该方法在不同类型的数据集上均表现出良好的性能。

<details>
  <summary>Details</summary>

**Motivation:** 图像分类系统面临对抗性攻击带来的严重安全挑战，这些攻击旨在故意修改图像以欺骗AI分类模型。

**Method:** 本文提出了一种结合进化算法和生成对抗网络（GAN）的方法来生成对抗性攻击。该方法利用进化算法探索GAN的潜在空间，以找到代表对抗性攻击的向量。

**Result:** 该方法在手写数字分类任务中实现了高达35%的攻击成功率，在物体图像分类任务中实现了高达75%的攻击成功率。这些结果优于其他搜索方法和相关工作中报告的结果。该方法在处理目标数据集上的数据多样性方面表现出有效性，即使在信息复杂性和丰富性带来的额外挑战的问题实例中也是如此。

**Conclusion:** 所应用的方法被证明在处理目标数据集的数据多样性方面是有效的，并且在生成对抗性攻击方面取得了显著的成功率，优于现有方法。

> **ai_Abstract:** 本文提出了一种利用进化算法探索生成对抗网络潜在空间的新方法，旨在生成针对图像分类系统的对抗性攻击。该方法在手写数字和物体图像分类任务中进行了评估，并取得了显著的攻击成功率（手写数字高达35%，物体图像高达75%），优于现有技术，并显示出处理复杂数据集的鲁棒性。

> **摘要翻译:** 图像分类目前面临对抗性攻击带来的重大安全挑战，这些攻击包括旨在欺骗基于人工智能的分类模型的故意篡改。本文探索了一种结合进化算法和生成对抗网络的方法，用于生成针对图像分类器的对抗性攻击。所提出的方法利用进化算法探索生成对抗网络的潜在空间，以找到代表对抗性攻击的向量。该方法在两个案例研究中进行了评估，分别对应手写数字和物体图像的分类。结果显示，手写数字的成功率高达35%，物体图像的成功率高达75%，优于其他搜索方法和相关工作中报告的结果。所应用的方法证明在处理目标数据集上的数据多样性方面是有效的，即使在由于信息复杂性和丰富性而带来额外挑战的问题实例中也是如此。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [310] [Multi-population GAN Training: Analyzing Co-Evolutionary Algorithms](https://arxiv.org/abs/2507.13157)
> *多群体GAN训练：分析协同进化算法*

*Walter P. Casas, Jamal Toutouh* | **Category: cs.NE** | **Updated: 2025-07-17**

**Keywords:** GANs, 协同进化, 世代替换, 模式崩溃, 多样性

**Comment:** Genetic and Evolutionary Computation Conference (GECCO '25
  Companion), July 14--18, 2025, Malaga, Spain

> **TL;DR:** 在协同进化GAN训练中，(mu,lambda)世代替换方法优于精英主义方法，能提高样本质量和多样性。

**AI_Comments:** 该论文为协同进化GAN训练提供了宝贵的实证见解，特别指出完全世代替换在保持多样性方面的优势，这对于避免GAN中的模式崩溃至关重要，揭示了在某些进化算法背景下，精英主义并非总是最优选择。

<details>
  <summary>Details</summary>

**Motivation:** 生成对抗网络（GANs）虽然是强大的生成模型，但由于模式崩溃和不稳定性等问题，训练仍然具有挑战性。最近的研究探索了协同进化方法，即通过进化生成器和判别器群体来解决这些问题，这是一种有前景的解决方案。

**Method:** 本文对不同的协同进化GAN训练策略进行了实证分析，重点关注选择和替换机制的影响。研究比较了(mu,lambda)、带有精英主义的(mu+lambda)和带有锦标赛选择的(mu+lambda)协同进化方案，以及一个非进化群体基础的多生成器多判别器GAN基线。实验在合成低维数据集（blob和高斯混合）和基于图像的基准（MNIST）上进行。

**Result:** 结果表明，完全世代替换，即(mu,lambda)方法，在样本质量和多样性方面始终表现更优，尤其是在结合更大后代规模时。相比之下，精英主义方法倾向于过早收敛并导致多样性降低。

**Conclusion:** 这些发现强调了在协同进化GAN训练中平衡探索和利用动态的重要性，并为设计更有效的基于群体的生成模型提供了指导。

> **ai_Abstract:** 本文对协同进化GAN训练策略进行了实证分析，比较了不同的选择和替换机制。研究发现，完全世代替换（(mu,lambda)）在样本质量和多样性方面始终优于精英主义方法，尤其是在后代规模较大时。这强调了在协同进化GAN训练中平衡探索和利用的重要性，为设计更有效的基于群体的生成模型提供了指导。

> **摘要翻译:** 生成对抗网络（GANs）是强大的生成模型，但由于模式崩溃和不稳定性等病理问题，训练仍然具有挑战性。最近的研究探索了协同进化方法，其中生成器和判别器的群体被进化，作为一种有前景的解决方案。本文对不同的协同进化GAN训练策略进行了实证分析，重点关注选择和替换机制的影响。我们比较了(mu,lambda)、带有精英主义的(mu+lambda)和带有锦标赛选择的(mu+lambda)协同进化方案，以及一个非进化群体基础的多生成器多判别器GAN基线，跨越合成低维数据集（blob和高斯混合）和基于图像的基准（MNIST）。结果显示，完全世代替换，即(mu,lambda)方法，在样本质量和多样性方面始终表现更优，尤其是在结合更大后代规模时。相比之下，精英主义方法倾向于过早收敛并导致多样性降低。这些发现强调了在协同进化GAN训练中平衡探索和利用动态的重要性，并为设计更有效的基于群体的生成模型提供了指导。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [40] [The Johnson-Krizek-Mercier elasticity element in any dimensions](https://arxiv.org/abs/2403.13189)
> *任意维度的Johnson-Krizek-Mercier弹性单元*

*Jay Gopalakrishnan, Johnny Guzman, Jeonghun J. Lee* | **Category: math.NA, cs.NA, 65N12, 65N15, 65N30** | **Updated: 2025-07-17**

**Keywords:** 线性弹性, 混合方法, Johnson-Mercier单元, Alfeld分裂, 误差估计

**Comment:** 33 pages, 1 figure

> **TL;DR:** 本文研究了任意维度下具有强对称应力的最低阶线性弹性混合方法，推广了Johnson-Mercier二维单元，并证明了数值解的最优误差估计。

**AI_Comments:** 本文的创新之处在于将Johnson-Mercier二维弹性单元推广到任意维度，这对于处理高维弹性问题具有重要意义。通过定义独特的应力空间结构和证明误差估计，该工作为数值模拟提供了坚实的理论基础。其在三维情况下对自由度的优化也显示了方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 研究线性弹性中具有强对称应力的最低阶混合方法。

**Method:** 采用混合方法，在每个单形上，应力空间具有关于其Alfeld分裂的分段线性分量，将Johnson-Mercier二维单元推广到更高维度。在三维情况下，当位移空间减小到局部刚性位移时，应力空间可以进一步减少（每个四面体24个自由度）。

**Result:** 成功将Johnson-Mercier二维单元推广到更高维度，并在三维情况下实现了应力空间的进一步约简。提供了数值解的最优误差估计以及通过后处理和对偶论证改进的误差估计的证明。

**Conclusion:** 本文成功推广了Johnson-Mercier弹性单元到高维度，并为数值解提供了严格的误差估计，证明了其方法的有效性和精度。

> **ai_Abstract:** 本文提出并研究了用于线性弹性的最低阶强对称应力混合方法，其核心在于将Johnson-Mercier二维弹性单元推广到任意维度。该方法通过在每个单形上定义应力空间的Alfeld分裂分段线性分量来实现，并在三维情况下展示了应力空间可进一步约简以提高效率。研究还提供了数值解的最优误差估计以及通过后处理和对偶论证获得的改进误差估计的严格证明。

> **摘要翻译:** 本文研究了具有最低阶强对称应力的线性弹性混合方法。在每个单形上，应力空间相对于其Alfeld分裂（将顶点连接到重心）具有分段线性分量，这推广了Johnson-Mercier二维单元到更高维度。在三维情况下，当位移空间减小到局部刚性位移时，应力空间可以进一步减少（每个四面体24个自由度）。文中提供了数值解最优误差估计的证明，以及通过后处理和对偶论证改进误差估计的证明。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [65] [Space-time FEM-BEM couplings for parabolic transmission problems](https://arxiv.org/abs/2409.14449)
> *空间-时间有限元-边界元耦合求解抛物型传输问题*

*Thomas Führer, Gregor Gantner, Michael Karkulik* | **Category: math.NA, cs.NA, 35K20, 65M12, 65M60, 65N38** | **Updated: 2025-07-17**

**Keywords:** 空间-时间耦合, 有限元法, 边界元法, 抛物型问题, 传输问题

**Comment:** 

> **TL;DR:** 该研究开发并验证了一种新的空间-时间有限元-边界元耦合方法，用于数值求解抛物型传输问题。

**AI_Comments:** 这项研究的创新之处在于将两种不同的数值方法（FOSLS和BEM）在空间-时间域内进行耦合，以解决复杂的抛物型传输问题。证明耦合的强制性是其理论贡献，并通过数值实验验证了其有效性，这对于数值分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在数值求解全空间和有限时间区间上的抛物型传输问题。

**Method:** 结合了抛物型问题的空间-时间一阶系统最小二乘法 (FOSLS) 和热方程的空间-时间边界元法 (BEM)。

**Result:** 证明了在特定限制条件下耦合方法的强制性，并通过数值实验验证了理论发现。

**Conclusion:** 该研究成功开发并验证了一种用于求解抛物型传输问题的空间-时间FEM-BEM耦合方法，并证明了其在特定条件下的强制性。

> **ai_Abstract:** 本文提出了一种创新的空间-时间有限元-边界元 (FEM-BEM) 耦合方法，专门用于数值求解抛物型传输问题。该方法结合了针对抛物型问题的FOSLS方法和针对热方程的BEM。研究不仅理论上证明了该耦合在特定条件下的强制性，还通过数值实验验证了这些理论结果。

> **摘要翻译:** 我们开发了一种将抛物型问题的最新空间-时间一阶系统最小二乘法 (FOSLS) 与热方程的空间-时间边界元法 (BEM) 相耦合的方法，用于数值求解全空间和有限时间区间上的抛物型传输问题。特别是，我们证明了在某些限制条件下耦合的强制性，并通过数值实验验证了我们的理论发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [90] [Optimal linear approximants for noisy data](https://arxiv.org/abs/2412.01287)
> *噪声数据的最优线性逼近器*

*Sergio López Ureña, Dionisio F. Yáñez* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 线性逼近器, 噪声数据, 优化问题, 噪声方差, 最优性

**Comment:** 6 pages, 2 figures

> **TL;DR:** 本文提出了一种处理点值噪声数据的最优线性逼近器，通过最小化噪声方差来确定系数，并证明了其在特定条件下的最优性。

**AI_Comments:** 本文的创新点在于通过将系数确定问题转化为一个最小化噪声方差的优化问题，从而为处理噪声数据提供了一种系统且最优的线性逼近方法。它不仅处理了普遍的噪声相关和非均匀分布情况，还证明了现有方法在特定条件下的最优性，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 处理点值噪声数据，并找到一种有效且最优的线性逼近方法。

**Method:** 通过解决一个优化问题来确定逼近器系数，该优化问题旨在最小化噪声方差。研究考虑了数据之间存在噪声相关性且分布不均匀的普遍情况。

**Result:** 证明了[S. L\u00f3pez-Ure\u00f1a and D. F. Y\u00e1\u00f1ez, J. Sci. Comput., 100(1) (2024)]中提出的细分规则对于非均匀方差的非相关噪声是最优的。数值实验表明，这些最优逼近器比其他逼近器更有效。

**Conclusion:** 本文提出的最优线性逼近器在处理噪声数据方面表现出显著的有效性，尤其在特定噪声条件下具有最优性。

> **ai_Abstract:** 本文提出了一种新的线性逼近器，用于处理点值噪声数据。其核心方法是通过解决一个优化问题来确定逼近器系数，以最小化噪声方差。该方法适用于噪声相关且非均匀分布的普遍情况。研究还表明，对于非相关且非均匀方差的噪声，先前提出的细分规则是最佳的。数值实验验证了这些最优逼近器的有效性。

> **摘要翻译:** 本文介绍了专门处理点值噪声数据的线性逼近器。一个关键的创新在于通过解决一个旨在最小化噪声方差的优化问题来确定逼近器系数。这项研究解决了普遍情况，允许数据之间存在噪声相关性且分布不均匀。事实上，我们表明[S. L\u00f3pez-Ure\u00f1a and D. F. Y\u00e1\u00f1ez, J. Sci. Comput., 100(1) (2024)]中提出的细分规则对于非均匀方差的非相关噪声是最优的。提供了数值实验来证明这些最优逼近器与其他逼近器相比的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [115] [A variational approach to the analysis of the continuous space-time FEM for the wave equation](https://arxiv.org/abs/2501.11494)
> *波动方程连续时空有限元方法的变分分析方法*

*Sergio Gómez* | **Category: math.NA, cs.NA, 65M60, 65M12, 35L04** | **Updated: 2025-07-17**

**Keywords:** 波动方程, 时空有限元, 稳定性分析, 收敛性分析, 误差估计

**Comment:** 

> **TL;DR:** 本文对波动方程的哈密顿公式的时空连续有限元方法进行了稳定性与收敛性分析，证明了离散解对数据的连续依赖性，并推导了先验和后验误差估计，通过数值实验验证了理论结果。

**AI_Comments:** 这篇论文的创新点在于其对波动方程时空连续有限元方法的严格稳定性与收敛性分析，特别是在不限制网格尺寸和时间步长的情况下，证明了离散解对数据的连续依赖性。这对于实际应用中选择灵活的时间步长和网格具有重要意义。此外，推导了准最优的先验误差估计和无常数的后验误差估计，为数值模拟的精度控制和误差评估提供了坚实的理论基础。对非齐次Dirichlet边界条件的特殊处理也增加了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 对波动方程的哈密顿公式的时空连续有限元方法进行稳定性与收敛性分析，以证明离散解对数据的连续依赖性，并在没有网格尺寸或时间步长限制的情况下导出准最优收敛率的先验误差估计和可靠的后验误差估计。

**Method:** 采用变分方法分析波动方程的哈密顿公式下的时空连续有限元方法。通过证明离散解在特定能量范数下对数据的连续依赖性，并利用稳定性估计推导先验误差估计。此外，基于后处理近似的性质，推导了无常数的后验误差估计。通过数值实验验证理论发现。

**Result:** 证明了离散解在$C^0([0, T]; X)$型能量范数下对数据的连续依赖性，且不受网格尺寸或时间步长的限制。导出了具有准最优收敛率的先验误差估计，其中对非齐次Dirichlet边界条件的适当处理至关重要。为半离散时间公式在$C^0([0, T]; L^2(\Omega))$范数下导出了无常数、可靠的后验误差估计。

**Conclusion:** 本文成功地对波动方程的哈密顿公式的时空连续有限元方法进行了稳定性与收敛性分析，并提供了在数据连续依赖性、先验误差估计和后验误差估计方面的理论结果，并通过数值实验验证了这些发现。

> **ai_Abstract:** 本文对波动方程哈密顿公式的时空连续有限元方法进行了深入的稳定性与收敛性分析。研究证明了离散解在特定能量范数下对数据的连续依赖性，且不受网格和时间步长限制。在此基础上，推导了具有准最优收敛率的先验误差估计，并强调了非齐次Dirichlet边界条件处理的重要性。此外，还为半离散时间公式导出了可靠的无常数后验误差估计。数值实验验证了理论结果。

> **摘要翻译:** 我们对波动方程哈密顿公式的时空连续有限元方法进行了稳定性与收敛性分析。更确切地说，我们证明了离散解在$C^0([0, T]; X)$型能量范数下对数据的连续依赖性，这不需要对网格尺寸或时间步长进行任何限制。然后，这些稳定性估计被用于推导出具有准最优收敛率的先验误差估计，其中对可能的非齐次Dirichlet边界条件的适当处理对于避免精度损失至关重要。此外，基于后处理近似的性质，我们为半离散时间公式在$C^0([0, T]; L^2(\Omega))$范数下推导了一个无常数、可靠的后验误差估计。本文提出了几个数值实验来验证我们的理论发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [149] [The Multiphase Cubic MARS method for Fourth- and Higher-order Interface Tracking of Two or More Materials with Arbitrarily Complex Topology and Geometry](https://arxiv.org/abs/2506.11897)
> *用于任意复杂拓扑和几何的两种或多种材料的四阶及更高阶界面跟踪的多相三次MARS方法*

*Yan Tan, Yixiao Qian, Zhiqi Li, Qinghai Zhang* | **Category: math.NA, cs.NA, 76T30, 65D07, 05C90, G.1.1; G.1.7; G.1.10; G.4** | **Updated: 2025-07-17**

**Keywords:** 多相流, 界面跟踪, MARS方法, 高阶精度, 复杂拓扑

**Comment:** 

> **TL;DR:** 提出了一种多相三次MARS方法，用于二维多材料界面跟踪，该方法通过图形、循环和三次样条准确高效地表示界面，保持(r,h)正则性条件，适用于任意复杂拓扑和几何的多材料，并实现了四阶、六阶和八阶时空精度。

**AI_Comments:** 该论文提出了一种创新的多相三次MARS方法，显著提升了多材料界面跟踪的精度和效率。其创新之处在于结合了图形、循环和三次样条来精确表示复杂界面，并能处理传统方法难以解决的各种交界点。达到四阶及更高阶的时空精度是其重要亮点，对于计算流体力学和材料科学等领域的高精度模拟具有重要意义。该方法有望成为处理复杂多相流问题的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法（如VOF和水平集方法）在处理各种类型的交界点时面临挑战，因此需要一种新的方法来准确、高效地跟踪具有任意复杂拓扑和几何的多材料界面，并达到高阶精度。

**Method:** 本文提出了一种多相三次MARS方法，该方法：(a) 通过图形、循环和三次样条准确高效地表示界面的拓扑和几何；(b) 保持界面的(r,h)正则性条件，使相邻标记点之间的距离在用户指定范围内；(c) 适用于具有任意复杂拓扑和几何的多材料；(d) 在时间和空间上实现了四阶、六阶和八阶精度。该方法特别容易处理VOF和水平集方法难以处理的所有可能类型的交界点。

**Result:** 在MARS框架下证明了所提出方法的四阶及更高阶收敛率。经典基准测试结果证实了分析，并表明该方法具有卓越的准确性和效率。

**Conclusion:** 所提出的多相三次MARS方法在二维多材料界面跟踪方面表现出卓越的准确性和效率，能够以高阶精度处理任意复杂拓扑和几何的界面，并有效解决了现有方法在处理交界点时的挑战。

> **ai_Abstract:** 本文介绍了一种名为多相三次MARS（Multiphase Cubic MARS）的新方法，专门用于在二维空间中跟踪任意数量材料的界面。该方法通过结合图形、循环和三次样条来实现对界面拓扑和几何的精确高效表示，同时确保界面的(r,h)正则性。它能够处理具有任意复杂拓扑和几何的多材料系统，并解决了传统VOF和水平集方法在处理复杂交界点时的难题。该方法在时间和空间上均能达到四阶、六阶和八阶精度，并通过理论证明和经典基准测试验证了其优越的准确性和效率。

> **摘要翻译:** 对于二维中任意数量材料的界面跟踪，我们提出了一种多相三次MARS方法，该方法：(a) 通过图形、循环和三次样条准确高效地表示界面的拓扑和几何；(b) 保持界面的(r,h)正则性条件，使任何一对相邻标记点之间的距离在用户指定范围内，该范围可根据局部曲率而变化；(c) 适用于具有任意复杂拓扑和几何的多材料；(d) 在时间和空间上实现了四阶、六阶和八阶精度。特别是，所有可能类型的交界点（对VOF方法和水平集方法构成挑战）都可以轻松处理。在MARS框架下证明了所提出方法的四阶及更高阶收敛率。经典基准测试结果证实了分析，并表明所提出方法具有卓越的准确性和效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [179] [High-order Gauss-Legendre methods admit a composition representation and a conjugate-symplectic counterpart](https://arxiv.org/abs/2506.16809)
> *高阶高斯-勒让德方法具有组合表示和共轭辛对应物*

*Felice Iavernaro, Francesca Mazzia, Ernst Hairer* | **Category: math.NA, cs.NA, 65L06, G.1.7** | **Updated: 2025-07-17**

**Keywords:** 高斯-勒让德方法, 组合表示, 共轭辛, 数值积分, 辛格式

**Comment:** 6 pages

> **TL;DR:** 高阶高斯-勒让德方法可以被表示为一种组合结构，并且存在共轭辛对应物。

**AI_Comments:** 本文的创新之处在于揭示了高阶高斯-勒让德方法与经典低阶方法的内在联系，通过发现其组合表示，为理解和构建更复杂的数值积分方法提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 经典的辛和共轭辛格式（如中点法和梯形法则）可以被解释为隐式和显式欧拉方法的组合。这自然引出了一个问题，即高阶高斯-勒让德方法是否存在类似的组合结构。

**Method:** 本文首先研究了四阶情况，然后概述了推广到更高阶的方法。

**Result:** 本文提供了一个肯定的答案，即高阶高斯-勒让德方法确实存在类似的组合结构和共轭辛对应物。

**Conclusion:** 高阶高斯-勒让德方法确实存在类似于中点法和梯形法则的组合结构，并且具有共轭辛对应物。

> **ai_Abstract:** 本文探讨了高阶高斯-勒让德方法是否具有类似于中点法和梯形法则的组合结构，后者可以看作是隐式和显式欧拉方法的组合。研究发现高阶高斯-勒让德方法确实存在这种组合表示和共轭辛对应物，并通过分析四阶情况后推广到更高阶。

> **摘要翻译:** 辛和共轭辛格式最经典的配对之一是中点法（2阶高斯-龙格-库塔法）和梯形法则。这些可以分别解释为隐式和显式欧拉方法按正向和反向顺序的组合。这自然引出了一个问题，即高阶高斯-勒让德方法是否存在类似的组合结构。在本文中，我们通过首先研究四阶情况，然后概述推广到更高阶的方法，提供了一个肯定的答案。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [209] [A Novel Homotopy Perturbation Sumudu Transform Method for Nonlinear Fractional PDEs: Applications and Comparative Analysis](https://arxiv.org/abs/2506.20457)
> *一种求解非线性分数阶偏微分方程的新型同伦摄动Sumudu变换方法：应用与比较分析*

*Maryam Jalili* | **Category: math.NA, cs.NA, 35R11, 44A10, 65M99, 34A08** | **Updated: 2025-07-17**

**Keywords:** 分数阶偏微分方程, Sumudu变换, 同伦摄动法, HPSTM, 非线性问题

**Comment:** 

> **TL;DR:** HPSTM是一种结合Sumudu变换和同伦摄动的新方法，用于高效准确地求解非线性分数阶偏微分方程。

**AI_Comments:** HPSTM通过结合Sumudu变换和同伦摄动，为解决非线性分数阶偏微分方程提供了一种创新且高效的途径，特别是在收敛速度和精度方面优于现有方法。其在多个领域的潜在应用凸显了其重要性。然而，该方法在高阶非线性和多维问题上的局限性表明未来研究可进一步优化。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决非线性分数阶偏微分方程（FPDEs），并提供一种比现有方法（如Laplace-HPM或Elzaki-HPM）收敛更快的混合方法。

**Method:** 提出同伦摄动Sumudu变换方法（HPSTM），它结合了Sumudu变换的线性保持特性和同伦摄动的灵活性，并使用Caputo分数阶导数。

**Result:** HPSTM对强非线性FPDEs的收敛速度比Laplace-HPM或Elzaki-HPM更快。对于α = 0.9，级数解的绝对误差低至3.12 × 10^-3。在标准硬件上，使用5项级数，每个示例的平均计算时间为0.5秒。解决方案通过与精确解、ADM、RBF无网格法、VIM、FDM和谱方法进行比较验证了其准确性、效率和鲁棒性。

**Conclusion:** HPSTM是一种精确、高效且鲁棒的方法，适用于求解非线性分数阶偏微分方程，在多孔介质流体建模、复杂材料热传导和生物种群动力学方面具有应用前景，尽管在高阶非线性和多维领域存在挑战。

> **ai_Abstract:** 本研究提出了一种新型混合方法——同伦摄动Sumudu变换方法（HPSTM），用于求解非线性分数阶偏微分方程。该方法结合了Sumudu变换和同伦摄动，利用Caputo分数阶导数，对强非线性FPDEs表现出更快的收敛速度和高精度。通过与多种现有方法比较验证了其准确性、效率和鲁棒性，并在流体流动、热传导和生物动力学等领域显示出应用潜力，但对高阶非线性和多维问题存在局限。

> **摘要翻译:** 本研究引入了同伦摄动Sumudu变换方法（HPSTM），这是一种结合Sumudu变换与同伦摄动来求解非线性分数阶偏微分方程（FPDEs）的新型混合方法，包括分数阶多孔介质方程、热传递方程和Fisher方程，并使用Caputo分数阶导数。HPSTM利用Sumudu变换的线性保持特性和同伦摄动的灵活性，对强非线性FPDEs实现了比Laplace-HPM或Elzaki-HPM更快的收敛速度。对于α = 0.9，级数解的绝对误差低至3.12 × 10^-3，在标准硬件上使用5项级数，每个示例的平均计算时间为0.5秒。解决方案通过与精确解、Adomian分解法（ADM）、径向基函数（RBF）无网格法、变分迭代法（VIM）、有限差分法（FDM）和谱方法进行验证。对α = 1.0、0.9、0.8、0.7的数值示例、敏感性分析和图形表示证实了HPSTM的准确性、效率和鲁棒性。局限性包括高阶非线性和多维领域面临的挑战。HPSTM在多孔介质流体建模、复杂材料热传导和生物种群动力学应用中显示出前景。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [238] [A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field](https://arxiv.org/abs/2507.02459)
> *强外磁场下Vlasov-Poisson系统的一种改进Crank-Nicolson格式*

*Francis Filbet, L Miguel Rodrigues, Kim Han Trinh* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** Crank-Nicolson, Vlasov-Poisson, 粒子-网格, 强磁场, 引导中心系统

**Comment:** 

> **TL;DR:** 本文提出并研究了一种基于Crank-Nicolson时间离散化的粒子在强不均匀外磁场中运动的Vlasov-Poisson系统粒子-网格(PIC)方法，该方法旨在避免传统方法中与拉莫尔半径和等离子体频率相关的稳定性时间步限制。

**AI_Comments:** 本文的创新点在于提出了一种改进的Crank-Nicolson粒子-网格(PIC)方法，成功解决了在强外磁场下Vlasov-Poisson系统模拟中常见的时间步稳定性限制问题。通过引入引导中心系统的一致PIC离散化，该方法在保持精度的同时，显著提高了计算效率和稳定性，对于等离子体物理和聚变研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在强外磁场下，Vlasov-Poisson系统的粒子-网格(PIC)方法可能面临与拉莫尔半径和等离子体频率的小尺度相关的稳定性时间步限制。本文的动机是提出一种新的方法来避免这种限制。

**Method:** 本文提出了一种基于Crank-Nicolson时间离散化的粒子-网格(PIC)方法，用于处理具有固定方向的强不均匀外磁场下的Vlasov-Poisson系统。该方法侧重于粒子在垂直于磁场的平面（极向方向）上的运动，并基于能够考虑磁场变化的引导中心系统的一致PIC离散化数值格式。

**Result:** 本文进行了理论证明和多项数值实验，以验证所提出的方法及其基本概念。

**Conclusion:** 本文提出的改进Crank-Nicolson格式的粒子-网格(PIC)方法在强外磁场下对Vlasov-Poisson系统是有效且经过验证的，能够避免传统方法中的时间步限制。

> **ai_Abstract:** 本文提出并研究了一种针对强不均匀外磁场下Vlasov-Poisson系统的改进粒子-网格(PIC)方法。该方法采用Crank-Nicolson时间离散化，并专注于粒子在垂直于磁场方向的运动。为了克服传统方法中与拉莫尔半径和等离子体频率相关的稳定性时间步限制，该方法基于对引导中心系统的一致PIC离散化方案。通过理论证明和数值实验，验证了该方法的有效性。

> **摘要翻译:** 我们提出并研究了一种基于Crank-Nicolson时间离散化的粒子-网格（PIC）方法，用于处理具有强且不均匀外磁场（方向固定）的Vlasov-Poisson系统。我们主要关注粒子在垂直于磁场的平面（即所谓的极向方向）上的运动。在这种情况下，时间步长可能会受到与拉莫尔半径和等离子体频率的小尺度相关的稳定性约束[21]。为了避免这一限制，我们的方法基于数值格式[9, 10, 12]，提供了一种考虑磁场变化的引导中心系统的一致PIC离散化。我们进行了一些理论证明并执行了多次数值实验来验证该方法及其基本概念。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [269] [Remarkable upper bounds for the interpolation error constants on the triangles](https://arxiv.org/abs/2507.04032)
> *三角形插值误差常数的显著上限*

*Kenta Kobayashi* | **Category: math.NA, cs.NA, 65D05(Primary), 41A44(Secondary), 65N30, 41A44, G.1.8; G.1.1; G.1.2** | **Updated: 2025-07-17**

**Keywords:** 插值误差常数, 三角形, 有限元方法, 数值验证, 渐近分析

**Comment:** 

> **TL;DR:** 本研究为三角形上的插值误差常数引入了显著的、尖锐且简单的上限，并通过数值验证方法和渐近分析证明了其有界性，这对有限元方法中的误差分析至关重要，并展示了数值验证方法的应用价值。

**AI_Comments:** 本文的创新之处在于提出了三角形上插值误差常数的“尖锐且简单”的上限公式，这对于数值分析特别是有限元方法具有重要意义。此外，它还成功展示了数值验证方法在理论证明中的强大应用，并暗示了其证明范式在解决其他范数不等式问题上的潜在普适性。

<details>
  <summary>Details</summary>

**Motivation:** 插值误差常数在分析插值误差，特别是与有限元方法相关的误差时至关重要，因此需要为其引入显著的上限。

**Method:** 研究通过数值验证方法和渐近分析证明了插值误差常数的有界性。

**Result:** 本研究引入了三角形上插值误差常数的显著上限，这些上限是尖锐的且由简单公式给出，并通过数值验证和渐近分析证明了其有界性。

**Conclusion:** 本研究不仅为三角形上的插值误差常数提供了重要的上限，还展示了数值验证方法的宝贵应用，并且其证明过程可能适用于各种其他范数不等式的证明。

> **ai_Abstract:** 本研究为三角形上的插值误差常数提出了显著的上限，这些上限具有尖锐性和简单公式的特点。这些常数对于有限元方法中的插值误差分析至关重要。作者通过数值验证方法和渐近分析成功证明了这些上限的有界性。该研究还强调了数值验证方法的实用价值，并指出其证明过程有望应用于其他范数不等式的证明。

> **摘要翻译:** 我们为三角形上的插值误差常数引入了显著的上限，这些上限是尖锐的且由简单公式给出。这些常数在分析插值误差，特别是与有限元方法相关的误差时至关重要。在本研究中，我们通过数值验证方法和渐近分析证明了其有界性。这项研究的重要性还在于它展示了数值验证方法的一个有价值的应用。本研究的证明过程可能适用于各种其他范数不等式的证明。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [351] [Generalized Scattering Matrix Framework for Modeling Implantable Antennas in Multilayered Spherical Media](https://arxiv.org/abs/2507.13119)
> *植入式天线在多层球形介质中建模的广义散射矩阵框架*

*Chenbo Shi, Xin Gu, Shichen Liang, Jin Pan* | **Category: math.NA, cs.NA, eess.SP** | **Updated: 2025-07-17**

**Keywords:** 广义散射矩阵, 植入式天线, 球形介质, 计算电磁学, 解耦建模

**Comment:** 

> **TL;DR:** 本文提出了一种高效的广义散射矩阵框架，用于在多层球形介质中分析植入式天线，通过解耦天线及其周围介质的建模，实现了计算效率的显著提升和广泛适用性。

**AI_Comments:** 这篇论文的创新之处在于其提出的广义散射矩阵框架，通过解耦天线与周围介质的建模，极大地提高了计算效率，尤其是在处理材料参数变化时。与传统的DGF-based MoM方法相比，这种计算优势对于需要快速迭代和优化的应用（如生物医学植入和天线罩设计）非常重要。该方法的通用性体现在支持多种球形介质，且其准确性、通用性和可扩展性已得到验证，并提供了代码实现，这有助于其在实际工程中的推广和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的植入式天线和工程应用中天线罩内天线的建模方法可能效率不高或适用性有限。该研究旨在为在球形分层介质中分析天线提供一个统一且高效的框架，特别适用于生物医学系统中的植入式天线和工程应用中的天线罩内天线。

**Method:** 该方法通过将天线的自由空间广义散射矩阵（GSM）与一套扩展的球形散射算子（SSOs）相结合，从而解耦了天线及其周围介质的建模。SSOs能够严格捕捉与多层球形环境的电磁相互作用。这种解耦使得在任意材料变化下无需重新仿真天线即可快速重新评估。

**Result:** 该框架支持多种球形介质，包括径向不均匀和单轴各向异性层。与传统的基于Dyadic Green's function (DGF)的MoM方法相比，该方法在计算上具有显著优势。广泛的案例研究表明，该方法与全波和基于DGF的解决方案具有出色的一致性，证实了其准确性、通用性和可扩展性。

**Conclusion:** 该研究成功开发了一个统一高效的广义散射矩阵框架，用于在多层球形介质中分析天线，通过解耦建模显著提高了计算效率和适用性，并已被证实具有高精度、通用性和可扩展性。

> **ai_Abstract:** 本文提出了一种创新的广义散射矩阵（GSM）框架，用于高效分析多层球形介质中的天线，如植入式天线。该方法通过将天线及其周围介质的建模解耦，结合天线的自由空间GSM和球形散射算子（SSOs），显著提高了计算效率，尤其是在材料参数变化时无需重新仿真。该框架具有高精度、通用性和可扩展性，并已通过广泛案例研究验证。

> **摘要翻译:** 本文提出了一种统一高效的框架，用于分析嵌入球形分层介质中的天线——该模型广泛适用于生物医学系统中的植入式天线和工程应用中的天线罩内天线。所提出的方法通过将天线的自由空间广义散射矩阵（GSM）与一套扩展的球形散射算子（SSOs）相结合，从而解耦了天线及其周围介质的建模，SSOs能够严格捕捉与多层球形环境的电磁相互作用。这种解耦使得在任意材料变化下无需重新仿真天线即可快速重新评估，与传统的基于Dyadic Green's function (DGF)的MoM方法相比，提供了显著的计算优势。该框架支持多种球形介质，包括径向不均匀和单轴各向异性层。广泛的案例研究表明，该方法与全波和基于DGF的解决方案具有出色的一致性，证实了该方法的准确性、通用性和可扩展性。提供了代码实现以促进采用和未来的开发。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [432] [A Unified Framework for Efficient Kernel and Polynomial Interpolation](https://arxiv.org/abs/2507.12629)
> *高效核函数与多项式插值的统一框架*

*M. Belianovich, G. E. Fasshauer, A. Narayan, V. Shankar* | **Category: math.NA, cs.NA** | **Updated: 2025-07-16**

**Keywords:** 核插值, 多项式插值, 统一框架, 数值线性代数, 流形

**Comment:** 

> **TL;DR:** 本文提出了一种统一的插值框架，结合了核函数和多项式，并通过专门的数值线性代数过程实现了高效计算和存储，在欧几里得域和流形上的表现优于传统多项式最小二乘法。

**AI_Comments:** 该论文的创新之处在于成功地将核函数插值和多项式插值这两种不同的方法整合到一个统一的框架中，并有效地解决了其计算效率问题。通过引入专门的数值线性代数过程和针对流形的修改，该工作显著扩展了插值方法的适用范围和效率，对于需要高精度和高效计算的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一个统一的插值方案，该方案能够结合紧支撑正定核函数和多元多项式，以推广现有插值方法（如紧支撑核插值和经典多项式最小二乘逼近），并实现高效的计算和存储，同时能够应用于流形上的目标函数。

**Method:** 本文提出了一种统一的插值方案，该方案结合了紧支撑正定核函数和多元多项式。为实现高效应用，文中提出了利用标准矩阵分解的专门数值线性代数过程。此外，还对数值线性代数过程进行了修改，使其能够推广应用于有边界和无边界流形上的目标函数。

**Result:** 数值实验表明，在欧几里得域和流形上，统一插值器优于多项式最小二乘逼近。

**Conclusion:** 本文提出的统一插值框架在欧几里得域和流形上均表现出优于传统多项式最小二乘法的性能，证明了其有效性和优越性。

> **ai_Abstract:** 本文提出了一种结合紧支撑正定核函数和多元多项式的统一插值框架。该框架不仅推广了现有的核插值和多项式最小二乘逼近方法，还通过专门的数值线性代数过程实现了高效的计算和存储。此外，该框架经过修改后可应用于有边界和无边界流形上的函数。数值实验结果表明，该统一插值器在欧几里得域和流形上的表现均优于传统的多项式最小二乘法。

> **摘要翻译:** 我们提出了一种统一的插值方案，该方案结合了紧支撑正定核函数和多元多项式。这个统一的框架推广了紧支撑核插值和经典多项式最小二乘逼近。为了促进这种统一插值方案的高效使用，我们提出了利用标准矩阵分解的专门数值线性代数过程。这些过程允许高效计算和存储统一插值器。我们还对数值线性代数进行了修改，这使得我们能够将统一框架的应用推广到有边界和无边界流形上的目标函数。我们在欧几里得域和流形上的数值实验表明，统一插值器优于多项式最小二乘法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [467] [Partitioned Conservative, Variable Step, Second-Order Method for Magneto-hydrodynamics In Elsässer Variables](https://arxiv.org/abs/2507.12700)
> *基于Elsässer变量的磁流体动力学分区守恒、变步长、二阶方法*

*Zhen Yao, Catalin Trenchea, Wenlong Pei* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 磁流体动力学, 辛算法, 变步长, 分区方法, Elsässer变量

**Comment:** 

> **TL;DR:** 本文提出并分析了一种针对Elsässer变量下磁流体动力学（MHD）演化系统的二阶辛算法，该算法通过并行求解两个子问题来降低计算成本，并实现了无条件守恒和二阶精度。

**AI_Comments:** 该论文提出了一种创新的分区方法来降低MHD模拟的计算成本，同时保持了关键物理量的守恒性和高精度。变步长和时间自适应机制是其重要亮点，有助于提高数值模拟的效率和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机是为磁流体动力学（MHD）演化系统开发一种计算成本更低、同时能保持高精度和重要物理量守恒的算法。

**Method:** 本文提出了一种针对Elsässer变量下MHD演化系统的二阶辛算法。该方法通过将耦合系统分解为两个半尺寸的子问题并并行求解，以降低迭代非线性求解器的计算成本。该算法是变步长的，并基于局部截断误差准则实现了时间自适应机制。

**Result:** 该算法在线性收敛，在L²和H¹范数下具有二阶精度。它无条件地守恒能量、交叉螺旋度和磁螺旋度。数值测试支持了理论发现并验证了时间自适应的优势。

**Conclusion:** 本文提出的分区守恒、变步长、二阶MHD算法在计算效率、精度和物理量守恒方面表现出色，并得到了数值测试的支持。

> **ai_Abstract:** 本文提出了一种针对Elsässer变量下磁流体动力学（MHD）演化系统的二阶辛算法。该算法通过将系统分解为两个并行求解的子问题来降低计算成本，并证明了其线性收敛性。该变步长算法能够无条件地守恒能量、交叉螺旋度和磁螺旋度，并在L²和H¹范数下达到二阶精度。时间自适应机制进一步提高了效率和精度平衡。数值实验验证了理论结果和时间自适应的优势。

> **摘要翻译:** 磁流体动力学（MHD）描述了导电流体与电磁场之间的相互作用。我们提出并分析了一种用于Elsässer变量中演化MHD系统的辛二阶算法。我们通过将耦合系统划分为两个半尺寸的子问题并并行求解，从而在每个时间步降低了迭代非线性求解器的计算成本。我们证明了在与全时空误差分析中所需的类似时间步长限制下，迭代线性收敛。变步长算法无条件地守恒能量、交叉螺旋度和磁螺旋度，并且数值解在L²和H¹范数下具有二阶精度。基于局部截断误差准则的时间自适应机制有助于变步长算法平衡精度和时间效率。多项数值测试支持了理论发现并验证了时间自适应的优势。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [476] [Keep the beat going: Automatic drum transcription with momentum](https://arxiv.org/abs/2507.12596)
> *保持节拍：基于动量的自动鼓点转录*

*Alisha L. Foster, Robert J. Webber* | **Category: math.NA, cs.NA, cs.SD, eess.AS** | **Updated: 2025-07-16**

**Keywords:** 自动鼓点转录, 非负矩阵分解, 投影梯度下降, 乘法更新规则, 音乐信息检索

**Comment:** 

> **TL;DR:** 本文通过部分固定非负矩阵分解，比较了乘法更新规则和带动量的投影梯度下降两种方法在自动鼓点转录中的性能，发现带动量的投影梯度下降在固定运行时间下能提供更高的准确性，并具有更强的收敛保证。

**AI_Comments:** 本文的创新点在于系统地比较了两种NMF优化方法在自动鼓点转录任务中的性能，并明确指出了带动量投影梯度下降的优势，这对于该领域的算法选择具有指导意义。其贡献在于为自动鼓点转录提供了一种更优的实现方式，并强调了理论收敛性与实际性能的结合。

<details>
  <summary>Details</summary>

**Motivation:** 自动鼓点转录是一个重要但具有挑战性的任务。作者旨在通过比较不同的非负矩阵分解优化方法来提高转录的准确性。

**Method:** 本文通过使用部分固定非负矩阵分解（NMF）对音乐片段的幅度谱进行分解来实现自动鼓点转录。研究比较了两种优化NMF的方法：乘法更新规则和带动量的投影梯度下降。这些方法在ENST-Drums数据集和作者乐队的原始录音上进行了评估，并与地面真实鼓点标注进行比较。

**Result:** 结果表明，在固定的运行时间内，带动量的投影梯度下降（projected gradient descent with momentum）方法能够实现更高的准确性，并且满足更强的收敛保证。

**Conclusion:** 带动量的投影梯度下降是自动鼓点转录中一种更优的优化方法，因为它在准确性和理论收敛性方面表现更好。

> **ai_Abstract:** 本文探讨了使用部分固定非负矩阵分解进行自动鼓点转录，并比较了两种优化算法：乘法更新规则和带动量的投影梯度下降。研究在ENST-Drums数据集和自定义录音上进行了实证评估，结果表明带动量的投影梯度下降在固定运行时间下能提供更高的转录准确性，并具有更强的理论收敛性。

> **摘要翻译:** 一个简单、可解释的自动鼓点转录方法是通过使用部分固定非负矩阵分解对录制音乐片段的幅度谱进行分解。有两种自然的方式来优化非负矩阵分解，包括乘法更新规则和带动量的投影梯度下降。这些方法在经验准确性和理论收敛保证方面存在差异。本文总结了这些方法及其时间复杂度，并将其应用于ENST-Drums数据集和作者乐队的原始录音，评估了相对于地面真实鼓点标注的经验准确性。结果表明，在固定的运行时间内，带动量的投影梯度下降能够带来更高的准确性，并且满足更强的收敛保证。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [487] [Analysis of Langevin midpoint methods using an anticipative Girsanov theorem](https://arxiv.org/abs/2507.12791)
> *使用预期Girsanov定理分析Langevin中点方法*

*Matthew S. Zhang* | **Category: math.NA, cs.DS, cs.NA, math.PR, math.ST, stat.TH** | **Updated: 2025-07-17**

**Keywords:** Langevin中点方法, Malliavin演算, 预期Girsanov定理, 随机微分方程, 查询复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种新的方法，利用Malliavin演算和预期Girsanov定理分析随机微分方程的中点离散化，并改进了采样方法的正则性和交叉正则性结果，同时获得了KL散度下的查询复杂度上界。

**AI_Comments:** 本文的创新之处在于引入了一种基于Malliavin演算和预期Girsanov定理的新方法来分析Langevin中点离散化，这使得对采样算法的理论分析更加深入，并获得了更精确的复杂度界限，对MCMC方法的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分析随机微分方程（SDEs）的中点离散化方法，这些方法常用于马尔可夫链蒙特卡洛（MCMC）采样。

**Method:** 引入了一种新的方法来分析SDEs的中点离散化，该方法借鉴了Malliavin演算技术，计算了可能预期布朗运动的$L^2([0, T); \mathbb{R}^d)$过程的Radon-Nikodym导数估计。

**Result:** 改进了采样方法文献中的正则性和交叉正则性结果。在对$
abla^2 V$的对数凹性和强平滑性假设下，获得了在KL散度中获得$\\varepsilon^2$精确样本的查询复杂度上界为$\\widetilde{O}(\\frac{\\kappa^{5/4} d^{1/4}}{\\varepsilon^{1/2}})$。

**Conclusion:** 通过引入新的分析方法，本文成功改进了Langevin中点方法的理论分析结果，并提供了更紧的复杂度界限。

> **ai_Abstract:** 本文提出了一种利用Malliavin演算和预期Girsanov定理分析随机微分方程中点离散化的新方法。该方法计算了可能预期布朗运动的过程的Radon-Nikodym导数估计，并将其应用于流行的中点离散化，从而改进了采样方法中的正则性和交叉正则性结果。此外，研究还在特定假设下给出了KL散度下获得精确样本的查询复杂度上界。

> **摘要翻译:** 我们引入了一种分析随机微分方程（SDEs）中点离散化的新方法，SDEs在中点离散化中常用于马尔可夫链蒙特卡洛（MCMC）方法，以从目标测度$\\pi \\propto \\exp(-V)$中采样。借鉴Malliavin演算的技术，我们计算了$L^2([0, T); \\mathbb{R}^d)$上过程的Radon-Nikodym导数估计，这些过程可能预期布朗运动，这意味着它们可能不适应同一时间的滤波。将这些应用于各种流行的中点离散化，我们能够改进采样方法文献中的正则性和交叉正则性结果。我们还在$\\nabla^2 V$的对数凹性和强平滑性假设下，获得了在KL散度中获得$\\varepsilon^2$精确样本的查询复杂度上界为$\\widetilde{O}(\\frac{\\kappa^{5/4} d^{1/4}}{\\varepsilon^{1/2}})$。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [510] [DPNO: A Dual Path Architecture For Neural Operator](https://arxiv.org/abs/2507.12719)
> *DPNO：一种用于神经算子的双路径架构*

*Yichen Wang, Wenlian Lu* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 神经算子, 双路径架构, 偏微分方程, 并行处理, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种名为DPNO的新型双路径架构，通过并行处理机制显著增强了神经算子的性能、特征提取和解近似能力，并在多种偏微分方程问题上取得了超过30%的改进，同时表现出卓越的通用性。

**AI_Comments:** 这项工作通过引入双路径并行架构，有效解决了单一神经算子块性能受限以及传统堆叠方式参数效率低的问题。其创新点在于借鉴ResNet和DenseNet的并行思想，并成功应用于神经算子，显著提升了模型性能和特征提取能力。该架构的通用性强，可以与现有主流神经算子结合，为未来神经算子设计提供了新的范式，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 神经算子在解决偏微分方程（PDEs）和复杂科学计算任务中是强大的工具，但单一算子块的性能有限，传统堆叠方式在参数效率上不经济。

**Method:** 本文提出了一种新颖的双路径架构DPNO，将基本的算子块组织成类似于ResNet和DenseNet的并行双路径，引入并行处理机制，以增强特征提取和解近似能力。该架构可应用于DeepONet和FNO等标准神经算子。

**Result:** 与原始模型相比，DPNO架构显示出更强大的特征提取和解近似能力。在Burgers'方程、Darcy流方程和2d Navier-Stokes方程等多种PDE问题上的广泛数值实验表明，在某些标准测试案例中，该模型比基础模型取得了超过30%的相对改进。该结构在DeepONet和FNO上应用，表明其具有优异的通用性。

**Conclusion:** DPNO双路径架构显著增强了基础神经算子的能力，提供了更强大的特征提取和解近似能力，并在多种PDE问题上取得了显著改进。其卓越的通用性为神经算子结构设计提供了有前景的方向。

> **ai_Abstract:** 本文提出了一种名为DPNO的新型双路径架构，旨在增强基础神经算子的能力。该架构将基本算子块以并行双路径（类似于ResNet和DenseNet）组织，引入并行处理机制，显著提升了特征提取和解近似能力。通过在Burgers'方程、Darcy流方程和2d Navier-Stokes方程等多种偏微分方程问题上的广泛数值实验，DPNO模型在某些标准测试案例上取得了超过30%的相对改进。此外，该架构可应用于DeepONet和FNO等不同范式的标准神经算子，展现出卓越的通用性，为神经算子结构设计提供了有前景的方向。

> **摘要翻译:** 神经算子已成为解决偏微分方程（PDEs）和其他复杂科学计算任务的强大工具。然而，单一算子块的性能通常是有限的，因此常常需要组合基本算子块以实现更好的性能。传统的组合方式是将这些块像前馈神经网络一样堆叠起来，考虑到参数效率的权衡，这可能不是很经济。在本文中，我们提出了一种新颖的双路径架构，显著增强了基本神经算子的能力。基本算子块以类似于ResNet和DenseNet的并行双路径组织。通过引入这种并行处理机制，我们的架构与原始模型相比，显示出更强大的特征提取和解近似能力。我们通过对各种PDE问题（包括Burgers'方程、Darcy流方程和2d Navier-Stokes方程）进行广泛的数值实验，证明了我们方法的有效性。实验结果表明，在某些标准测试案例中，我们的模型比基础模型取得了超过30%的相对改进。我们还将这种结构应用于从不同范式中选择的两种标准神经算子（DeepONet和FNO），这表明所提出的架构具有出色的通用性，为神经算子结构设计提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [537] [Quasi-optimality of the Crouzeix-Raviart FEM for p-Laplace-type problems](https://arxiv.org/abs/2507.12742)
> *p-Laplace型问题中Crouzeix-Raviart有限元法的准最优性*

*Johannes Storn* | **Category: math.NA, cs.NA, 35J62, 65N12, 65N15, 65N30** | **Updated: 2025-07-17**

**Keywords:** Crouzeix-Raviart FEM, p-Laplace, 准最优性, 误差估计, 有限元法

**Comment:** 

> **TL;DR:** 本文验证了Crouzeix-Raviart有限元法在p-Laplace型非线性问题上的准最优性，并给出了精确的误差界限。

**AI_Comments:** 这篇论文在数值分析领域，特别是有限元方法方面，具有重要意义。它不仅为Crouzeix-Raviart有限元法在处理p-Laplace型非线性问题时提供了理论支持，验证了其准最优性，还提出了新的误差估计方法，这对于提高数值模拟的精度和可靠性具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 验证Crouzeix-Raviart有限元法对于p-Laplace型非线性问题的准最优性。

**Method:** 采用Crouzeix-Raviart有限元法，并通过分析其在准范数下的误差来证明准最优性。

**Result:** 证明了Crouzeix-Raviart有限元法在准范数下的误差由一个有界常数乘以最佳逼近误差加上数据振荡项来限制。同时，作为副产品，还得到了一个针对符合条件的最低阶Lagrange有限元法的更局部化的先验误差估计。

**Conclusion:** 论文成功验证了Crouzeix-Raviart有限元法在p-Laplace型问题上的准最优性，并提供了详细的误差界限，同时提出了Lagrange有限元法的新误差估计。

> **ai_Abstract:** 本文验证了Crouzeix-Raviart有限元法在求解p-Laplace型非线性问题时的准最优性。研究结果表明，该方法在准范数下的误差可以通过最佳逼近误差和数据振荡项进行有效界定。此外，研究还附带地提出了一个针对符合条件的最低阶Lagrange有限元法的新的局部化先验误差估计。

> **摘要翻译:** 我们验证了Crouzeix-Raviart有限元法对于p-Laplace型非线性问题的准最优性。更精确地说，我们证明了Crouzeix-Raviart有限元法在准范数下的误差，其上界由一个一致有界常数乘以最佳逼近误差加上一个数据振荡项给出。作为副产品，我们验证了一个针对符合条件的最低阶Lagrange有限元法的新的、更局部化的先验误差估计。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [572] [Adaptive feature capture method for solving partial differential equations with low regularity solutions](https://arxiv.org/abs/2507.12941)
> *求解低正则性偏微分方程的自适应特征捕获方法*

*Yangtao Deng, Qiaolin He, Xiaoping Wang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 自适应特征捕获, 偏微分方程, 低正则性解, 无网格方法

**Comment:** 

> **TL;DR:** AFCM是一种新颖的无网格深度学习方法，通过自适应地在梯度高区域重新分配神经元和配置点，有效解决了低正则性偏微分方程的求解难题。

**AI_Comments:** AFCM的创新之处在于其将传统自适应网格思想与无网格神经网络方法相结合，通过动态调整计算资源分布来处理低正则性偏微分方程中的陡峭梯度和奇点。这解决了现有深度学习方法在局部分辨率方面的局限性，为复杂PDEs的精确高效求解提供了一个重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 传统数值方法在求解低正则性偏微分方程，尤其是在复杂几何形状中，面临网格生成和自适应细化计算成本高昂的挑战。现有的基于深度学习的方法（如PINNs和RFM）虽然是无网格的，但在关键区域缺乏自适应分辨率，限制了它们在处理陡峭梯度或奇点解时的准确性。

**Method:** 本文提出了一种新颖的机器学习框架——自适应特征捕获方法（AFCM）。该方法通过在梯度高区域自适应地重新分配神经元和配置点来增强局部表达能力。AFCM受自适应移动网格技术的启发，利用近似解的梯度范数作为监控函数，指导特征函数参数的重新初始化。这确保了分区超平面和配置点在最需要的地方聚集，从而在不增加计算开销的情况下实现更高的分辨率。AFCM扩展了RFM的能力，使其能够处理接近奇异的偏微分方程解，同时保持其无网格效率。

**Result:** 数值实验表明，该方法能够有效地准确求解低正则性问题，即使在复杂几何形状中也表现出色。

**Conclusion:** AFCM弥合了自适应网格细化和随机神经网络之间的鸿沟，为科学和工程应用中求解具有挑战性的偏微分方程提供了一种鲁棒且可扩展的方法。

> **ai_Abstract:** 本文提出了一种名为自适应特征捕获方法（AFCM）的新型机器学习框架，旨在解决传统数值方法和现有深度学习方法在处理低正则性偏微分方程时面临的挑战。AFCM通过自适应地在解的梯度高区域重新分配神经元和配置点，显著提高了局部分辨率和准确性，而不会增加计算负担。该方法借鉴了自适应移动网格技术，并扩展了随机特征方法，使其能够有效处理包含陡峭梯度甚至近奇异点的复杂PDEs。数值实验验证了AFCM在复杂几何形状中求解低正则性问题的有效性，为科学工程领域的PDEs求解提供了鲁棒且高效的途径。

> **摘要翻译:** 低正则性偏微分方程（PDEs）对传统数值方法提出了重大挑战，特别是在复杂几何形状中，网格生成和自适应细化变得计算成本高昂。虽然基于深度学习的方法，如物理信息神经网络（PINNs）和随机特征方法（RFM），提供了无网格替代方案，但它们通常在关键区域缺乏自适应分辨率，限制了它们在处理陡峭梯度或奇点解时的准确性。在这项工作中，我们提出了一种新颖的机器学习框架——自适应特征捕获方法（AFCM），该方法在梯度高区域自适应地重新分配神经元和配置点以增强局部表达能力。受自适应移动网格技术的启发，AFCM采用近似解的梯度范数作为监控函数，指导特征函数参数的重新初始化。这确保了分区超平面和配置点在最需要的地方聚集，从而在不增加计算开销的情况下实现更高的分辨率。AFCM扩展了RFM的能力，使其能够处理接近奇异的偏微分方程解，同时保持其无网格效率。数值实验表明，该方法能够有效地准确求解低正则性问题，即使在复杂几何形状中也表现出色。通过弥合自适应网格细化和随机神经网络之间的鸿沟，AFCM为科学和工程应用中求解具有挑战性的偏微分方程提供了一种鲁棒且可扩展的方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [607] [High Performance Parallel Solvers for the time-harmonic Maxwell Equations](https://arxiv.org/abs/2507.13066)
> *时谐麦克斯韦方程组的高性能并行求解器*

*Elise Fressart, Sébastien Dubois, Loïc Gouarin, Marc Massot, Michel Nowak, Nicole Spillane* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 时谐麦克斯韦方程组, 并行求解器, 预处理器, Hiptmair-Xu, Block Low-Rank

**Comment:** 

> **TL;DR:** 本文比较了用于求解大规模时谐麦克斯韦方程组的不同预处理策略，初步结果表明Hiptmair-Xu和Block Low-Rank预处理器表现较好。

**AI_Comments:** 这项工作探讨了解决困难的非厄米和非半正定时谐麦克斯韦方程组的并行求解器，通过比较多种预处理方法，为选择高效的求解策略提供了初步指导。特别指出了Hiptmair-Xu和Block Low-Rank的优势，这对于大规模电磁仿真具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决大规模时谐麦克斯韦方程组的数值解问题，因为这些方程组既非厄米也非半正定，求解困难。

**Method:** 比较了PETSc、MUMPS或hypre中可用的四种不同预处理策略：稀疏近似逆、受限加性Schwarz、Hiptmair-Xu预处理器和MUMPS的Block Low-Rank方法。同时与标准的LU分解技术（直接求解器）进行了性能比较。性能评估考虑了网格尺寸、CPU核数、波长和物理域大小。

**Result:** 初步结论表明Hiptmair-Rank和Block Low-Rank预处理器表现优异。

**Conclusion:** Hiptmair-Xu和Block Low-Rank预处理器在求解时谐麦克斯韦方程组时表现出更好的性能。

> **ai_Abstract:** 本文研究了大规模时谐麦克斯韦方程组的数值求解问题，该问题因方程组的非厄米和非半正定特性而具有挑战性。作者比较了四种不同的预处理策略（稀疏近似逆、受限加性Schwarz、Hiptmair-Xu和MUMPS的Block Low-Rank）以及标准的LU分解方法。初步结果表明Hiptmair-Xu和Block Low-Rank预处理器具有更好的性能。

> **摘要翻译:** 我们考虑大规模时谐麦克斯韦方程组的数值解。迄今为止，这个问题仍然很困难，特别是由于方程组既非厄米也非半正定。我们的方法是比较不同的策略，使用PETSc、MUMPS或hypre中可用的预处理器来求解这组方程。考虑了四种不同的预处理器。第一个是稀疏近似逆，它常用于电磁问题。第二个是受限加性Schwarz，一种域分解预处理器。第三个是Hiptmair-Xu预处理器，它专为正麦克斯韦方程组（一个相关问题）设计。最后一个预处理器是MUMPS的块低秩方法，一种压缩块过程。我们还将这种方法的性能与标准LU分解技术（一种直接求解器）进行了比较。考虑了网格尺寸、CPU核数、波长和域的物理尺寸方面的性能。这项正在进行的工作得出的临时结论支持Hiptmair-Xu和块低秩预处理器。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [642] [Stability of lattice Boltzmann schemes for initial boundary value problems in raw formulation](https://arxiv.org/abs/2507.13108)
> *原始公式中初始边界值问题格子玻尔兹曼格式的稳定性*

*Thomas Bellotti* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 格子玻尔兹曼格式, 稳定性, 初始边界值问题, 原始公式, 强稳定性

**Comment:** 

> **TL;DR:** 本文研究了原始公式下，一维线性标量格子玻尔兹曼格式在边界数据方面的稳定性，并引入了强稳定性概念来处理不同行为，通过数值模拟支持了理论结果。

**AI_Comments:** 该研究通过采用原始算法和引入强稳定性概念，有效地解决了格子玻尔兹曼格式在边界处稳定性分析的复杂性，避免了传统的复杂转换过程，具有一定的理论和实践意义。其创新点在于对边界处理的直接性和对稳定性的细致分类。

<details>
  <summary>Details</summary>

**Motivation:** 研究格子玻尔兹曼格式在边界数据方面的稳定性，特别是避免了在边界存在时难以进行的等效标量公式转换。

**Method:** 采用原始的、基于多个未知数的原始算法来研究一维线性标量格子玻尔兹曼格式的稳定性。引入了适当的强稳定性概念，以解释稳定向量丛的潜在不连续扩展。专注于特征方程模板宽度为一的方法，并研究了三种代表性方案，结合了文献中的各种边界条件，并通过数值模拟支持了理论结果。

**Result:** 引入了强稳定性概念以处理数值方案的不同行为。研究了三种代表性方案的强稳定性-不稳定性，并发现理论结果得到了数值模拟的支持。

**Conclusion:** 研究表明，对于特定类型的格子玻尔兹曼格式，在原始公式下，通过引入强稳定性概念可以有效地分析其在边界数据方面的稳定性，并且理论结果与数值模拟一致。

> **ai_Abstract:** 本文研究了原始公式下，一维线性标量格子玻尔兹曼格式对于双曲方程在边界数据方面的稳定性。研究避免了复杂的等效标量公式转换，并引入了强稳定性概念来处理数值方案的复杂行为。文章专注于特定类型的格式，通过分析三种代表性方案并结合数值模拟，验证了理论结果。

> **摘要翻译:** 我们研究了一维线性标量格子玻尔兹曼格式对于双曲方程在边界数据方面的稳定性。我们的方法基于几个未知数的原始算法，从而避免了转换为等效标量公式的需要——这在存在边界的情况下是一个具有挑战性的过程。为了解决数值方案表现出的不同行为，我们引入了适当的强稳定性概念。它们解释了对于某些分量，与单位圆上的整体方案相关的稳定向量丛可能缺乏连续扩展。我们没有发展一个通用理论（由于格子玻尔兹曼格式中的离散边界本质上是特征性的，这使得理论变得复杂），而是专注于特征方程模板宽度为一的方法的强稳定性-不稳定性。在此背景下，我们研究了三种代表性方案。这些方案被赋予了文献中各种边界条件，我们的理论结果得到了数值模拟的支持。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [666] [On the efficiency of a posteriori error estimators for parabolic partial differential equations in the energy norm](https://arxiv.org/abs/2507.13188)
> *抛物型偏微分方程能量范数下后验误差估计器效率的研究*

*Iain Smears* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 后验误差估计器, 抛物型偏微分方程, 能量范数, 隐式欧拉法, 有限元法

**Comment:** 

> **TL;DR:** 本文证明了在特定数值解定义下，抛物型偏微分方程后验误差估计器在能量范数下的有效性，并指出估计器效率依赖于范数和数值解的定义。

**AI_Comments:** 这篇论文的创新点在于揭示了后验误差估计器的效率不仅受范数选择影响，还受数值解定义方式的影响，这对于数值分析和误差控制领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在研究后验误差估计器在能量范数下的效率，并探究其效率是否受范数选择和数值解定义的影响。

**Method:** 研究了通过隐式欧拉法（时间）和协调有限元法（空间）离散化的热方程模型问题，并将数值解定义为通常的连续分段仿射时间重构和分段常数时间重构的平均值，在此基础上证明了后验误差估计器的效率。

**Result:** 证明了当数值解被视为连续分段仿射时间重构和分段常数时间重构的平均值时，后验误差估计器在能量范数下是有效的。结果表明估计器的效率不仅可能取决于范数的选择，还取决于数值解概念的选择。

**Conclusion:** 后验误差估计器的效率依赖于所选择的范数和数值解的定义。

> **ai_Abstract:** 本文研究了通过隐式欧拉法和有限元法离散化的热方程模型问题，证明了在将数值解定义为特定时间重构平均值的情况下，后验误差估计器在能量范数下的效率。研究揭示了估计器的效率不仅与所选范数有关，也与数值解的定义方式密切相关。

> **摘要翻译:** 对于通过时间上的隐式欧拉方法和空间上的协调有限元方法离散化的热方程模型问题，我们证明了当将数值解视为通常的连续分段仿射时间重构和分段常数时间重构的平均值时，后验误差估计器相对于误差的能量范数的效率。这说明了估计器的效率不仅可能取决于范数的选择，还取决于数值解概念的选择。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [691] [Well-balanced path-conservative discontinuous Galerkin methods with equilibrium preserving space for shallow water linearized moment equations](https://arxiv.org/abs/2507.13284)
> *浅水线性化矩量方程的平衡路径守恒间断伽辽金方法与平衡保持空间*

*Ruilin Fan, Julian Koellermeier, Yinhua Xia, Yan Xu, Jiahui Zhang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-17**

**Keywords:** 浅水线性化矩量方程, 间断伽辽金方法, 平衡保持, 路径守恒, 数值方法

**Comment:** 

> **TL;DR:** 本文提出了用于浅水线性化矩量方程的高阶、平衡、路径守恒间断伽辽金（DG）方法，能够精确保持静水和动水平衡状态，并具有高阶精度。

**AI_Comments:** 这项研究的创新之处在于将平衡路径守恒间断伽辽金方法应用于浅水线性化矩量方程，特别是通过引入“平衡保持空间”来同时处理通量梯度、非守恒项和源项。它为模拟复杂水流提供了更精确和稳定的数值工具，尤其是在处理具有垂直速度变化和复杂地形的场景时，克服了传统方法在处理非守恒项和稳态结构方面的挑战。其重要性在于提升了水动力学模拟的精度和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 浅水线性化矩量方程（SWLME）虽然能更详细地表示垂直动量传递和复杂速度剖面，但其非守恒项和复杂稳态结构带来了显著的数值挑战，需要开发能保持平衡状态的数值方法。

**Method:** 本文基于Dal Maso-LeFloch-Murat（DLM）理论，开发了路径守恒DG方案，并通过平衡保持空间平衡通量梯度、非守恒项和源项。对于静水平衡，将方程重构为准线性形式以消除源项；对于动水平衡，通过将守恒变量转换为平衡变量并采用线性分段路径来扩展DG方法。

**Result:** 所提出的方法在理论分析和数值实验中均表现出精确的平衡保持能力，即使在存在垂直速度变化和复杂地形的情况下也能保持高阶精度。

**Conclusion:** 本文开发的平衡路径守恒间断伽辽金方法能够有效解决浅水线性化矩量方程的数值挑战，精确保持静水和动水平衡，并提供高阶精度，证明了其在模拟复杂水流方面的有效性。

> **ai_Abstract:** 本文提出了一种高阶、平衡、路径守恒的间断伽辽金（DG）方法，用于解决浅水线性化矩量方程（SWLME）的数值挑战。该方法基于Dal Maso-LeFloch-Murat（DLM）理论，通过引入平衡保持空间和对静水、动水平衡的特殊处理（如准线性重构和平衡变量转换），实现了对静水和动水平衡状态的精确保持。理论分析和数值实验证明，该方法在保持高阶精度的同时，能有效处理垂直速度变化和复杂地形。

> **摘要翻译:** 本文提出了一种用于浅水线性化矩量方程（SWLME）的高阶、平衡、路径守恒间断伽辽金（DG）方法，旨在保持静水和动水两种平衡状态。与使用多个不同层来模拟垂直速度变化的传统多层浅水方程不同，SWLME采用速度剖面的多项式展开，最高可达N阶矩。这种方法能够更详细地表示垂直动量传递和复杂速度剖面，同时保留双曲性。然而，非守恒项和复杂稳态结构的存在引入了显著的数值挑战。为了应对这些挑战，我们开发了基于Dal Maso-LeFloch-Murat（DLM）理论的非守恒积的路径守恒DG方案。我们的方法通过平衡保持空间来平衡通量梯度、非守恒项和源项。对于静水平衡，我们将方程重新表述为准线性形式，消除了源项，从而固有地保持了稳态。对于动水平衡，我们通过将守恒变量转换为平衡变量并采用线性分段路径来扩展DG方法。理论分析和数值实验表明，所提出的方法即使在垂直速度变化和复杂地形的情况下，也能实现精确的平衡保持，同时保持高阶精度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [97] [Task-Specific Audio Coding for Machines: Machine-Learned Latent Features Are Codes for That Machine](https://arxiv.org/abs/2507.12701)
> *机器任务专用音频编码：机器学习的潜在特征是该机器的编码*

*Anastasia Kuznetsova, Inseon Jang, Wootaek Lim, Minje Kim* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 机器音频编码, 残差向量量化, 超低比特率, 任务特定, 语音识别, 音频分类

**Comment:** 

> **TL;DR:** 本文提出了一种高效的机器音频编码（ACoM）方法，通过量化预训练模型的中间特征表示，以超低比特率（<200 bps）实现高效压缩，同时保持下游任务性能，并适用于不同比特率和模型大小。

**AI_Comments:** 这篇论文的创新点在于提出了一个专门针对机器任务的音频编码范式，摆脱了传统音频编码对人类感知高保真度的依赖。通过直接量化下游模型的中间特征并结合任务特定损失，实现了超低比特率下的高效压缩，同时保持了关键的下游任务性能，这对于资源受限的边缘设备和大规模部署具有重要意义。其灵活性和在多种任务上的潜力使其成为一个有前景的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的神经音频编解码器侧重于高保真重构以满足人类感知，但机器音频编码（ACoM）需要的是高效压缩和下游任务性能，而非感知细节。因此，需要一种专门为机器任务设计的音频编码方法。

**Method:** 本文引入了一种高效的机器音频编码（ACoM）方法，该方法能够压缩和量化已训练的语音/音频下游模型的任意选定中间特征表示。该方法结合了任务特定损失指导和残差向量量化（RVQ）损失。

**Result:** 该方法在超低比特率（小于200 bps）下，对下游模型性能的损失最小。所生成的tokenizer可适应各种比特率和模型大小，实现灵活部署。在自动语音识别和音频分类任务上的评估表明，该方法有效且通过适当正则化具有更广泛的任务和架构适用性。

**Conclusion:** 本文提出的ACoM方法通过对机器任务定制的音频编码，实现了在超低比特率下高效压缩并保持下游任务性能，具有广泛的应用潜力。

> **ai_Abstract:** 本文提出了一种针对机器任务的音频编码（ACoM）新方法。与注重人类感知的传统音频编码不同，该方法专注于高效压缩和下游任务性能。它通过结合任务特定损失指导和残差向量量化（RVQ）损失，对预训练语音/音频模型的中间特征进行压缩和量化。实验结果表明，该方法能在超低比特率（<200 bps）下显著减少下游任务性能损失，并且其生成的tokenizer具有高度适应性，可灵活应用于不同的比特率和模型大小，在自动语音识别和音频分类等任务中展现出广阔的应用前景。

> **摘要翻译:** 神经音频编解码器利用量化算法，对各种语音/音频任务产生了显著影响。虽然高保真重建对于人类感知至关重要，但机器音频编码（ACoM）优先考虑高效压缩和下游任务性能，而忽略了感知细微差别。这项工作引入了一种高效的ACoM方法，该方法可以压缩和量化已训练的语音/音频下游模型的任何选定的中间特征表示。我们的方法采用任务特定损失指导以及残差向量量化（RVQ）损失，以超低比特率（即小于200 bps）提供，同时对下游模型性能的损失最小。由此产生的tokenizer可适应各种比特率和模型大小，以实现灵活部署。在自动语音识别和音频分类上进行评估，我们的方法通过适当的正则化证明了其有效性以及在更广泛任务和架构上的潜在适用性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [136] [Speech-Forensics: Towards Comprehensive Synthetic Speech Dataset Establishment and Analysis](https://arxiv.org/abs/2412.09032)
> *语音取证：建立和分析综合合成语音数据集*

*Zhoulin Ji, Chenhao Lin, Hang Wang, Chao Shen* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 合成语音检测, 语音取证, 数据集, 深度学习, TEST网络

**Comment:** IJCAI 2024

> **TL;DR:** 本文提出了Speech-Forensics数据集和一个名为TEST的网络，用于综合检测、定位和识别合成语音。

**AI_Comments:** 该论文的创新点在于构建了一个更全面的合成语音数据集Speech-Forensics，并提出了一个集多功能于一体的TEST网络，能够同时实现语音真实性检测、伪造片段定位和合成算法识别，且无需复杂后处理，这在合成语音取证领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于虚假信息和身份冒充的风险，检测合成语音变得越来越重要。现有合成语音分析数据集通常专注于特定领域，限制了其综合研究的效用。

**Method:** 本文提出了Speech-Forensics数据集，该数据集广泛覆盖了真实、合成和部分伪造的语音样本，包括由不同高质量算法合成的多个片段。此外，本文提出了一个名为TEST（TEmporal Speech LocalizaTion network）的时间语音定位网络，旨在同时执行真实性检测、多个伪造片段定位和合成算法识别，无需复杂的后处理。TEST有效集成了LSTM和Transformer来提取更强大的时间语音表示，并利用多尺度金字塔特征上的密集预测来估计合成跨度。

**Result:** 我们的模型在话语级别实现了83.55%的平均mAP和5.25%的EER。在片段级别，它达到了1.07%的EER和92.19%的F1分数。

**Conclusion:** 这些结果突出了模型在综合分析合成语音方面的强大能力，为该领域的未来研究和实际应用提供了有前景的途径。

> **ai_Abstract:** 本文针对现有合成语音数据集的局限性，提出了一个综合性的Speech-Forensics数据集，其中包含真实、合成和部分伪造的语音样本。同时，开发了一个名为TEST的时间语音定位网络，该网络结合了LSTM和Transformer，能够同时进行语音真实性检测、伪造片段定位和合成算法识别。实验结果表明，TEST模型在语音真实性检测和伪造片段定位方面表现出强大的性能，为合成语音分析提供了新的研究方向和应用潜力。

> **摘要翻译:** 由于虚假信息和身份冒充的风险，检测合成语音变得越来越重要。虽然已经开发了各种用于合成语音分析的数据集，但它们通常专注于特定领域，限制了其在综合研究中的效用。为了弥补这一空白，我们提出了Speech-Forensics数据集，该数据集广泛覆盖了真实、合成和部分伪造的语音样本，其中包括由不同高质量算法合成的多个片段。此外，我们提出了一个名为TEST（TEmporal Speech LocalizaTion network）的时间语音定位网络，旨在同时执行真实性检测、多个伪造片段定位和合成算法识别，无需任何复杂的后处理。TEST有效地集成了LSTM和Transformer以提取更强大的时间语音表示，并利用多尺度金字塔特征上的密集预测来估计合成跨度。我们的模型在话语级别实现了83.55%的平均mAP和5.25%的EER。在片段级别，它达到了1.07%的EER和92.19%的F1分数。这些结果突出了模型在综合分析合成语音方面的强大能力，为该领域的未来研究和实际应用提供了有前景的途径。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [184] [Learning Separated Representations for Instrument-based Music Similarity](https://arxiv.org/abs/2503.17281)
> *基于乐器分离表示的音乐相似性学习*

*Yuka Hashizume, Li Li, Atsushi Miyashita, Tomoki Toda* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 音乐相似性, 乐器分离, 表示学习, 三元组损失, 条件相似性网络

**Comment:** arXiv admin note: text overlap with arXiv:2404.06682

> **TL;DR:** 本文提出了一种使用单个神经网络从混合音乐信号中学习乐器分离表示的方法，以提高基于乐器的音乐相似性搜索的准确性和实用性。

**AI_Comments:** 该论文为音乐信息检索中的一个实际问题提供了一个创新性解决方案。通过使用单个网络直接从混合信号中学习乐器特有的表示，它解决了依赖不切实际的干净乐器查询或嘈杂分离信号的局限性。利用条件相似性网络和掩码三元组损失在一个嵌入空间内创建分离子空间是其关键贡献，这提高了乐器聚焦相似性任务的效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 灵活的音乐推荐和检索系统需要基于音乐多个部分元素的相似性。现有使用单独乐器信号的方法，要么查询不切实际，要么分离信号带来的伪影会降低准确性。

**Method:** 本文提出了一种使用单个网络，以混合信号作为输入的乐器部分音乐相似性学习方法。该方法设计了一个单一的相似性嵌入空间，其中包含每个乐器的独立子空间，这些子空间通过条件相似性网络提取，并使用带有掩码的三元组损失进行训练。

**Result:** 1. 所提出的方法在评估准确性较低的乐器时，可以获得比使用分离信号作为输入的单个网络更准确的嵌入表示。2. 每个子嵌入空间都可以保持相应乐器的特征。3. 所提出的方法选择关注每个乐器声音的相似音乐片段可以获得人类认可，尤其是在关注音色时。

**Conclusion:** 所提出的方法能够有效地从混合信号中学习乐器特有的音乐相似性，解决了现有方法的实用性和准确性问题，并表现出良好的性能和人类接受度。

> **ai_Abstract:** 本文提出了一种新颖的基于乐器的音乐相似性学习方法。该方法不依赖于单独或预分离的乐器音轨，而是使用单个神经网络处理混合音乐信号。该网络学习一个统一的相似性嵌入空间，并将其划分为独立的子空间，每个子空间专用于一种特定的乐器。通过三元组损失和掩码进行训练，该方法旨在克服先前多网络或分离信号方法的实用性和准确性问题。实验结果表明，该方法提高了嵌入的准确性，成功捕获了子空间中的乐器特征，并获得了乐器聚焦音乐检索的高度人类认可。

> **摘要翻译:** 一个灵活的推荐和检索系统需要音乐在多个部分元素方面的相似性，以允许用户选择他们想要关注的元素。使用多个网络和单独乐器信号的音乐相似性学习方法是有效的，但面临的问题是，将每个干净的乐器信号作为查询对于检索系统来说是不切实际的，并且使用分离的乐器信号会由于伪影而降低准确性。在本文中，我们提出了一种基于乐器部分的音乐相似性学习方法，该方法使用单个网络，以混合信号而不是单独乐器信号作为输入。具体来说，我们设计了一个单一的相似性嵌入空间，其中包含每个乐器的独立子空间，这些子空间通过条件相似性网络提取，并使用带有掩码的三元组损失进行训练。实验结果表明：（1）在评估准确性较低的乐器时，所提出的方法可以获得比使用分离信号作为输入的单个网络更准确的嵌入表示；（2）每个子嵌入空间都可以保持相应乐器的特征；（3）所提出的方法选择关注每个乐器声音的相似音乐片段可以获得人类认可，尤其是在关注音色时。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [204] [SHIELD: A Secure and Highly Enhanced Integrated Learning for Robust Deepfake Detection against Adversarial Attacks](https://arxiv.org/abs/2507.13170)
> *SHIELD：一种用于对抗性攻击的鲁棒性深度伪造检测的安全增强型集成学习*

*Kutub Uddin, Awais Khan, Muhammad Umar Farooq, Khalid Malik* | **Category: cs.SD, cs.AI, cs.CR, cs.LG, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 深度伪造检测, 反取证攻击, 协作学习, 生成对抗网络, 音频安全

**Comment:** 

> **TL;DR:** SHIELD提出了一种新的协作学习方法，通过集成辅助生成模型和设计三重模型，以增强对生成性反取证攻击的深度伪造音频检测的鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了SHIELD这一协作学习框架，通过引入辅助生成模型来暴露AF签名，并设计三重模型来捕获音频特征，从而有效提升了深度伪造检测在对抗性攻击下的鲁棒性。其重要性体现在解决了现有方法在反取证攻击面前的脆弱性，为深度伪造音频的检测提供了更可靠的解决方案，对于维护信息真实性具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度伪造音频检测方法容易受到反取证（AF）攻击，特别是使用生成对抗网络进行的攻击，这使得深度伪造音频能够传播虚假信息，对语音应用构成重大风险。

**Method:** 本文提出了一种名为SHIELD的新型协作学习方法来防御生成性AF攻击。SHIELD通过集成一个辅助防御（DF）生成模型来暴露AF签名，该模型通过结合输入和输出促进协作学习。此外，还设计了一个三重模型，利用辅助生成模型捕获真实和AF攻击音频与真实生成和攻击生成音频之间的相关性。

**Result:** 在ASVspoof2019数据集上，SHIELD在匹配设置下平均准确率达到98.13%，在不匹配设置下达到98.78%；在In-the-Wild数据集上，匹配设置下平均准确率达到98.58%，不匹配设置下达到98.62%；在HalfTruth数据集上，匹配设置下平均准确率达到99.57%，不匹配设置下达到98.85%。相比之下，AF攻击显著降低了现有方法的检测准确率，例如ASVspoof2019从95.49%降至59.77%。

**Conclusion:** SHIELD机制对AF攻击具有鲁棒性，并在各种生成模型和数据集上实现了强大的深度伪造音频检测性能。

> **ai_Abstract:** 本文提出SHIELD，一种新颖的协作学习方法，旨在增强深度伪造音频检测对生成性反取证（AF）攻击的鲁棒性。通过集成辅助防御生成模型来暴露AF签名，并设计一个三重模型来捕获真实与攻击音频的相关性，SHIELD显著提高了在ASVspoof2019、In-the-Wild和HalfTruth等数据集上的检测准确率，证明了其在对抗深度伪造音频攻击方面的有效性和鲁棒性。

> **摘要翻译:** 音频在扬声器验证、语音智能设备和音频会议等应用中扮演着关键角色。然而，音频篡改，例如深度伪造，通过传播虚假信息带来了重大风险。我们的实证分析表明，现有的深度伪造音频检测方法通常容易受到反取证（AF）攻击，特别是那些使用生成对抗网络进行攻击的方法。在本文中，我们提出了一种名为SHIELD的新型协作学习方法，以防御生成性AF攻击。为了揭示AF签名，我们集成了一个辅助生成模型，称为防御（DF）生成模型，它通过结合输入和输出促进协作学习。此外，我们设计了一个三重模型，利用辅助生成模型捕获真实和AF攻击音频与真实生成和攻击生成音频之间的相关性。所提出的SHIELD增强了对生成性AF攻击的防御，并在各种生成模型中实现了鲁棒的性能。所提出的AF显著降低了ASVspoof2019、In-the-Wild和HalfTruth三个不同生成模型的平均检测准确率，分别从95.49%降至59.77%、从99.44%降至38.45%以及从98.41%降至51.18%。所提出的SHIELD机制对AF攻击具有鲁棒性，在ASVspoof2019、In-the-Wild和HalfTruth数据集的匹配设置下分别达到了98.13%、98.58%和99.57%的平均准确率，在不匹配设置下分别达到了98.78%、98.62%和98.85%的平均准确率。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [232] [Can Large Language Models Predict Audio Effects Parameters from Natural Language?](https://arxiv.org/abs/2505.20770)
> *大型语言模型能否从自然语言中预测音频效果参数？*

*Seungheon Doh, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Juhan Nam, Yuki Mitsufuji* | **Category: cs.SD, cs.MM, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 音频效果, 自然语言处理, 音乐制作, 参数预测

**Comment:** Accepted for publication at The IEEE Workshop on Applications of
  Signal Processing to Audio and Acoustics (WASPAA)

> **TL;DR:** LLM2Fx框架利用大型语言模型（LLMs）直接从文本描述中预测音频效果（Fx）参数，无需特定任务训练或微调，表现优于现有优化方法。

**AI_Comments:** 这项研究的创新之处在于利用大型语言模型在零样本设置下直接从自然语言预测音频效果参数，显著简化了音乐制作流程。其重要性在于降低了音乐制作的技术壁垒，使非专业人士也能通过直观的文本描述进行创作。该方法为未来更智能、更易用的音乐生产工具奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在音乐制作中，通过自然语言操纵音频效果参数具有降低非专业人士技术门槛的潜力。

**Method:** 提出LLM2Fx框架，利用大型语言模型（LLMs）直接从文本描述中预测均衡和混响的Fx参数，无需任务特定训练或微调。采用零样本生成方式，并通过三种上下文示例（音频DSP特征、DSP函数代码和少样本示例）来增强性能。

**Result:** LLM-based Fx参数生成优于先前的优化方法，在将自然语言描述转换为适当的Fx设置方面提供具有竞争力的性能。

**Conclusion:** 大型语言模型可以作为音频制作的文本驱动界面，为更直观、更易于访问的音乐制作工具铺平道路。

> **ai_Abstract:** 该论文提出了LLM2Fx框架，旨在利用大型语言模型（LLMs）直接从自然语言描述中预测音频效果（Fx）参数，以降低音乐制作的技术门槛。该方法无需特定任务训练或微调，并能以零样本方式生成参数，尤其针对均衡和混响。通过引入DSP特征、DSP函数代码和少样本示例作为上下文，LLM2Fx在将自然语言转换为Fx设置方面表现优于现有优化方法，证明了LLMs作为音频制作文本驱动界面的潜力。

> **摘要翻译:** 在音乐制作中，通过自然语言操纵音频效果（Fx）参数具有降低非专业人士技术门槛的潜力。我们提出了LLM2Fx，这是一个利用大型语言模型（LLMs）直接从文本描述中预测Fx参数的框架，无需进行任务特定的训练或微调。我们的方法通过将自然语言描述映射到均衡和混响的相应Fx参数来解决文本到效果参数预测（Text2Fx）任务。我们证明了LLMs可以以零样本方式生成Fx参数，这阐明了音乐制作中音色语义与音频效果之间的关系。为了提高性能，我们引入了三种类型的上下文示例：音频数字信号处理（DSP）特征、DSP函数代码和少样本示例。我们的结果表明，基于LLM的Fx参数生成优于以前的优化方法，在将自然语言描述转换为适当的Fx设置方面提供了具有竞争力的性能。此外，LLMs可以作为音频制作的文本驱动界面，为更直观和易于访问的音乐制作工具铺平道路。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [287] [Radif Corpus: A Symbolic Dataset for Non-Metric Iranian Classical Music](https://arxiv.org/abs/2507.10456)
> *Radif语料库：一个非节拍伊朗古典音乐的符号数据集*

*Maziar Kanani, Sean O Leary, James McDermott* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-17**

**Keywords:** Radif, 伊朗古典音乐, 非节拍音乐, 音乐语料库, 符号数据集

**Comment:** 

> **TL;DR:** 本文介绍了Radif语料库，这是首个完整的非节拍伊朗古典音乐Radif曲目的数字数据集，包含MIDI文件和详细的音乐结构数据，旨在促进计算音乐学研究。

**AI_Comments:** 该论文的创新之处在于它是首个专门针对伊朗古典音乐中非节拍Radif曲目构建的完整数字符号语料库，填补了该领域的一个重要空白。其重要性在于为计算音乐学、民族音乐学和音乐信息检索等领域的研究提供了宝贵的、结构化的数据资源，将极大地促进对非西方音乐尤其是伊朗古典音乐的量化分析和理解。语料库对四分音和非节拍特性的忠实再现是其关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 伊朗古典音乐的核心是非节拍音乐，而Radif是其基础曲目。目前缺乏代表完整非节拍Radif曲目的数字语料库，这限制了对伊朗古典音乐的计算研究。因此，本研究的动机是创建这样一个数据集，以填补这一空白并为未来的计算研究提供平台。

**Method:** 本研究构建了第一个代表完整的非节拍Radif曲目的数字语料库，涵盖了现有的全部13个组成部分。语料库提供了MIDI文件（总计约281分钟）和数据表格，详细描述了228首音乐作品的音符、音符持续时间、音程和层次结构。该语料库忠实地再现了包括四分音在内的音调以及非节拍特性。此外，研究还提供了支持性的基本统计数据，以及语料库的复杂性和相似性度量。

**Result:** 该研究成功创建了Radif语料库，这是首个完整的非节拍伊朗古典音乐Radif曲目的数字数据集。它包含228首音乐作品的MIDI文件（总计约281分钟）和详细的数据表格，准确地表示了包括四分音在内的音调和非节拍特性。语料库还附带了基本的统计数据以及复杂性和相似性度量。

**Conclusion:** Radif语料库为伊朗古典音乐的计算研究提供了一个重要的平台。研究人员可以利用它来研究旋律模式、探索即兴创作风格，或用于音乐信息检索、音乐理论和计算（民族）音乐学中的其他任务。

> **ai_Abstract:** 本文介绍了Radif语料库，这是首个针对伊朗古典音乐中完整的非节拍Radif曲目创建的数字符号数据集。该语料库包含228首作品的MIDI文件（约281分钟）和详细的数据表格，精确地捕捉了包括四分音在内的音调和非节拍特征。它旨在为计算音乐学研究提供一个基础平台，支持对旋律模式、即兴风格以及音乐信息检索等领域的研究。

> **摘要翻译:** 非节拍音乐构成了伊朗古典音乐曲目的核心。达斯特加希（Dastgahi）音乐是伊朗艺术音乐和某些民间传统的基础理论体系。伊朗古典音乐的核心是拉迪夫（radif），这是一种基础曲目，组织着表演和教学的核心旋律材料。
在本研究中，我们引入了第一个代表完整非节拍拉迪夫曲目的数字语料库，涵盖了该曲目所有13个现有组成部分。我们提供了MIDI文件（总计约281分钟）和数据表格，描述了228首音乐作品的音符、音符持续时间、音程和层次结构。我们忠实地再现了包括四分音在内的音调以及非节拍特性。此外，我们还提供了支持性的基本统计数据，以及语料库的复杂性和相似性度量。
我们的语料库为伊朗古典音乐的计算研究提供了一个平台。研究人员可以利用它来研究旋律模式、探索即兴创作风格，或用于音乐信息检索、音乐理论和计算（民族）音乐学中的其他任务。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [321] [Voxtral](https://arxiv.org/abs/2507.13264)
> *沃克斯特拉*

*Alexander H. Liu, Andy Ehrenberg, Andy Lo, Clément Denoix, Corentin Barreau, Guillaume Lample, Jean-Malo Delignon, Khyathi Raghavi Chandu, Patrick von Platen, Pavankumar Reddy Muddireddy, Sanchit Gandhi, Soham Ghosh, Srijan Mishra, Thomas Foubert, Abhinav Rastogi, Adam Yang, Albert Q. Jiang, Alexandre Sablayrolles, Amélie Héliou, Amélie Martin, Anmol Agarwal, Antoine Roux, Arthur Darcet, Arthur Mensch, Baptiste Bout, Baptiste Rozière, Baudouin De Monicault, Chris Bamford, Christian Wallenwein, Christophe Renaudin, Clémence Lanfranchi, Darius Dabert, Devendra Singh Chaplot, Devon Mizelle, Diego de las Casas, Elliot Chane-Sane, Emilien Fugier, Emma Bou Hanna, Gabrielle Berrada, Gauthier Delerce, Gauthier Guinet, Georgii Novikov, Guillaume Martin, Himanshu Jaju, Jan Ludziejewski, Jason Rute, Jean-Hadrien Chabran, Jessica Chudnovsky, Joachim Studnia, Joep Barmentlo, Jonas Amar, Josselin Somerville Roberts, Julien Denize, Karan Saxena, Karmesh Yadav, Kartik Khandelwal, Kush Jain, Lélio Renard Lavaud, Léonard Blier, Lingxiao Zhao, Louis Martin, Lucile Saulnier, Luyu Gao, Marie Pellat, Mathilde Guillaumin, Mathis Felardos, Matthieu Dinot, Maxime Darrin, Maximilian Augustin, Mickaël Seznec, Neha Gupta, Nikhil Raghuraman, Olivier Duchenne, Patricia Wang, Patryk Saffer, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Philomène Chagniot, Pierre Stock, Pravesh Agrawal, Rémi Delacourt, Romain Sauvestre, Roman Soletskyi, Sagar Vaze, Sandeep Subramanian, Saurabh Garg, Shashwat Dalal, Siddharth Gandhi, Sumukh Aithal, Szymon Antoniak, Teven Le Scao, Thibault Schueller, Thibaut Lavril, Thomas Robert, Thomas Wang, Timothée Lacroix, Tom Bewley, Valeriia Nemychnikova, Victor Paltz, Virgile Richard, Wen-Ding Li, William Marshall, Xuanyu Zhang, Yihan Wan, Yunhao Tang* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 多模态模型, 音频聊天, 语音理解, 本地部署, 基准测试

**Comment:** 17 pages

> **TL;DR:** 本文介绍了Voxtral Mini和Voxtral Small，这是两个多模态音频聊天模型，在音频和文本理解方面表现出色，Voxtral Small还支持本地运行并提供新的评估基准。

**AI_Comments:** 这篇论文提出了一系列具有创新性的多模态音频聊天模型Voxtral，其亮点在于同时处理语音和文本的能力，并在音频基准上达到了SOTA。Voxtral Small的本地运行能力是其重要优势，降低了部署门槛。此外，贡献新的评估基准对于推动语音理解领域的发展也具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发能够理解语音和文本的多模态音频聊天模型，并期望其在性能上达到最先进水平，同时支持本地部署。

**Method:** 提出了Voxtral Mini和Voxtral Small两个多模态音频聊天模型。Voxtral模型通过训练来理解口语音频和文本文档。模型具有32K的上下文窗口。此外，还贡献了三个用于评估语音理解模型知识和琐事的基准。

**Result:** Voxtral在多种音频基准测试中取得了最先进的性能，同时保留了强大的文本处理能力。Voxtral Small在性能上超越了一些闭源模型，并且足够小巧，可以在本地运行。32K的上下文窗口使模型能够处理长达40分钟的音频文件和长时间的多轮对话。

**Conclusion:** Voxtral Mini和Voxtral Small是高性能的多模态音频聊天模型，它们在音频和文本理解方面表现出色，Voxtral Small还支持本地运行，并且研究贡献了新的语音理解评估基准。

> **ai_Abstract:** 本文介绍了Voxtral Mini和Voxtral Small，这是两个创新的多模态音频聊天模型。这些模型经过训练能够同时处理口语音频和文本文档，并在音频基准测试中展现出最先进的性能，同时保持了强大的文本处理能力。值得注意的是，Voxtral Small不仅超越了多个闭源模型，而且体积小巧，支持本地部署。模型配备的32K上下文窗口使其能够处理长达40分钟的音频和多轮对话。此外，研究还贡献了三个新的基准，用于评估语音理解模型在知识和琐事方面的能力。

> **摘要翻译:** 我们提出了Voxtral Mini和Voxtral Small，两个多模态音频聊天模型。Voxtral经过训练可以理解口语音频和文本文档，在各种音频基准测试中取得了最先进的性能，同时保留了强大的文本能力。Voxtral Small超越了许多闭源模型，同时足够小巧，可以在本地运行。一个32K的上下文窗口使模型能够处理长达40分钟的音频文件和长时间的多轮对话。我们还贡献了三个用于评估语音理解模型在知识和琐事方面的基准。两个Voxtral模型均根据Apache 2.0许可发布。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [344] [Best Practices and Considerations for Child Speech Corpus Collection and Curation in Educational, Clinical, and Forensic Scenarios](https://arxiv.org/abs/2507.12870)
> *儿童语音语料库收集和管理在教育、临床和法医场景中的最佳实践与注意事项*

*John Hansen, Satwik Dutta, Ellen Grand* | **Category: cs.SD, cs.CY, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 儿童语音语料库, 数据收集, 最佳实践, 语料库管理, 数据隐私

**Comment:** 5 pages, 0 figures, accepted at the 10th Workshop on Speech and
  Language Technology in Education (SLaTE 2025), a Satellite Workshop of the
  2025 Interspeech Conference

> **TL;DR:** 本研究为儿童语音语料库的收集和管理提供了最佳实践和注意事项，旨在解决数据动态变化和隐私挑战，并涵盖了数据收集的要素、协作指南和语料库质量检查。

**AI_Comments:** 这篇论文的创新之处在于其针对儿童语音语料库收集和管理这一复杂且敏感领域提供了全面的最佳实践和指导方针。鉴于儿童语音数据的独特性和隐私敏感性，以及其在教育、临床和法医等多个应用场景的日益增长的需求，该研究填补了现有空白，为相关研究和实践提供了宝贵的框架。其重要性体现在能够帮助研究者和从业者更有效地收集高质量、符合伦理规范的儿童语音数据，从而推动相关技术和应用的发展。

<details>
  <summary>Details</summary>

**Motivation:** 儿童的口语能力在成长过程中不断变化，尤其在7-8岁之前语音发展和语言结构快速演变。这种动态变化以及数据隐私问题，使得为儿童整理出可用于技术开发的语音语料库极具挑战性。本研究旨在弥补这一空白，为研究人员和从业者提供开发此类语料库的最佳实践和注意事项。

**Method:** 本研究基于先前的收集经验和知识，描述了数据收集的“谁、什么、何时、何地”要素。此外，还提供了建立合作、信任以及遵守人类受试者研究协议的指南。研究最后提出了语料库质量检查、分类和标注的指导方针。

**Result:** Not mentioned in abstract

**Conclusion:** 本研究为儿童语音语料库的质量检查、分类和标注提供了指导方针。

> **ai_Abstract:** 本研究致力于解决儿童语音语料库收集和管理面临的挑战，这些挑战源于儿童口语能力的动态变化和数据隐私问题。论文为研究人员和从业者提供了开发此类语料库的最佳实践和注意事项，涵盖了数据收集的“谁、什么、何时、何地”要素，建立合作和遵守人类受试者研究协议的指南，以及语料库质量检查、分类和标注的指导方针，旨在支持教育、临床和法医等领域对儿童语音数据的应用。

> **摘要翻译:** 儿童的口语能力会持续变化直至成年。在7-8岁之前，他们的语音发展和语言结构会迅速演变。这种口语交流技能的动态变化以及数据隐私问题，使得为儿童整理出可用于技术开发的语音语料库变得极具挑战性。本研究旨在弥补这一空白，为研究人员和从业者提供基于预期目标开发此类语料库的最佳实践和注意事项。尽管主要侧重于教育目标，但儿童语音数据的应用已扩展到包括临床和法医等领域。受此目标的驱动，我们借鉴先前的收集工作和我们的经验/知识，描述了数据收集的“谁、什么、何时、何地”。我们还提供了建立合作、信任以及遵守人类受试者研究协议的指南。本研究最后提出了语料库质量检查、分类和标注的指导方针。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [441] [Evaluation of Neural Surrogates for Physical Modelling Synthesis of Nonlinear Elastic Plates](https://arxiv.org/abs/2507.12563)
> *非线性弹性板物理建模合成中神经替代模型的评估*

*Carlos De La Vega Martin, Rodrigo Diaz Fernandez, Mark Sandler* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-16**

**Keywords:** 神经网络替代模型, 物理建模合成, 非线性弹性板, 实时音频合成, 振动

**Comment:** 

> **TL;DR:** 该研究比较了用于非线性弹性板振动物理建模合成的神经网络方法，揭示了其局限性，并讨论了对实时音频合成的影响。

**AI_Comments:** 该论文通过评估神经网络在非线性弹性板物理建模合成中的应用，为实时音频合成领域带来了新的视角。其创新之处在于对现有神经网络模型的局限性进行了深入分析，并强调了除时域误差外更全面的评估指标的重要性。这对于推动物理建模合成在计算效率和实时性方面的进步具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的物理建模合成方法（如有限差分和有限元）虽然精度高，但计算成本高昂，限制了它们在实时音频应用中的使用。

**Method:** 本文对基于神经网络的方法进行了比较分析，旨在解决非线性弹性板的振动问题。研究评估了多个最先进的模型，这些模型在短序列上训练，并以自回归方式预测长序列。

**Result:** 研究揭示了这些神经网络模型的一些局限性，并指出仅仅关注时域预测误差是不够的。

**Conclusion:** 本文讨论了研究结果对实时音频合成的意义，并提出了未来改进神经网络方法以模拟非线性振动的方向。

> **ai_Abstract:** 本文比较分析了多种基于神经网络的方法，以解决非线性弹性板的振动问题，旨在改进物理建模合成在实时音频应用中的效率。研究评估了在短序列上训练并以自回归方式预测长序列的最先进模型，并揭示了它们的局限性，指出仅凭时域预测误差不足以评估模型性能。文章讨论了这些发现对实时音频合成的意义，并为未来改进神经网络在非线性振动建模中的应用提供了方向。

> **摘要翻译:** 物理建模合成旨在通过振动结构的物理模拟生成音频。薄弹性板是鼓膜的常见模型。传统的数值方法，如有限差分和有限元，虽然精度高，但计算要求高，限制了它们在实时音频应用中的使用。本文对基于神经网络的方法进行了比较分析，用于解决非线性弹性板的振动问题。我们评估了几个最先进的模型，这些模型在短序列上训练，并以自回归方式预测长序列。我们展示了这些模型的一些局限性，以及为什么仅仅关注时域中的预测误差是不够的。我们讨论了对实时音频合成的影响，并提出了改进神经网络方法以模拟非线性振动的未来方向。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [514] [Early Detection of Furniture-Infesting Wood-Boring Beetles Using CNN-LSTM Networks and MFCC-Based Acoustic Features](https://arxiv.org/abs/2507.12793)
> *基于CNN-LSTM网络和MFCC声学特征的家具蛀虫早期检测*

*J. M. Chan Sri Manukalpa, H. S. Bopage, W. A. M. Jayawardena, P. K. P. G. Panduwawala* | **Category: cs.SD, cs.HC, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 白蚁检测, CNN-LSTM, 声学特征, 深度学习, 非侵入式

**Comment:** This is a preprint article

> **TL;DR:** 本研究提出了一种基于CNN-LSTM网络和MFCC声学特征的非侵入式深度学习声学分类框架，用于早期白蚁检测，实现了高精度（94.5%），并优于独立的CNN和LSTM架构，具有低假阴性率。

**AI_Comments:** 该研究通过结合CNN-LSTM网络和MFCC声学特征，为白蚁早期检测提供了一种创新的非侵入式解决方案，克服了传统方法的局限性。其高准确率和低假阴性率对于实际应用中的及时干预至关重要。值得注意的是，尽管标题提到了“家具蛀虫”，但摘要内容仅聚焦于“白蚁”。

<details>
  <summary>Details</summary>

**Motivation:** 传统的白蚁检测方法具有侵入性、劳动密集型且对早期侵染无效，导致巨大的经济损失。

**Method:** 本研究提出了一种非侵入式深度学习声学分类框架，用于早期白蚁检测。该框架引入了混合卷积神经网络长短期记忆（CNN-LSTM）架构，以捕获白蚁活动的MFFC声学信号的空间和时间特征。通过从受白蚁侵染和清洁的木样本中收集音频数据，训练CNN-LSTM模型进行信号分类。

**Result:** 实验结果显示该模型性能优异，准确率为94.5%，精确率为93.2%，召回率为95.8%。比较分析表明，混合模型优于独立的CNN和LSTM架构。值得注意的是，该模型具有低假阴性率。

**Conclusion:** 本研究为早期白蚁检测提供了一种非侵入式、自动化解决方案，对于改善害虫监测、最大限度地减少结构损坏以及提高房主和害虫控制专业人员的决策具有实际意义。

> **ai_Abstract:** 本研究提出了一种基于CNN-LSTM网络和MFCC声学特征的非侵入式深度学习声学分类框架，用于早期白蚁检测。该模型在区分白蚁声学信号和背景噪声方面表现出色，实现了94.5%的准确率、93.2%的精确率和95.8%的召回率，并优于独立的CNN和LSTM架构，具有低假阴性率。这项工作为白蚁早期检测提供了一种自动化、有效的解决方案，对害虫监测和结构保护具有重要意义。

> **摘要翻译:** 结构性害虫，如白蚁，对木结构建筑构成严重威胁，由于其隐蔽性和渐进性破坏导致巨大的经济损失。传统的检测方法，如目视检查和化学处理，具有侵入性、劳动密集型且对早期侵染无效。为了弥补这一空白，本研究提出了一种基于非侵入式深度学习的声学分类框架，用于早期白蚁检测。我们旨在开发一个鲁棒、可扩展的模型，以区分白蚁产生的声学信号和背景噪声。我们引入了一种混合卷积神经网络长短期记忆（CNN-LSTM）架构，该架构捕获白蚁活动的空间和时间特征。音频数据从受白蚁侵染和清洁的木样本中收集。我们提取了梅尔频率倒谱系数（MFCC），并训练CNN-LSTM模型对信号进行分类。实验结果显示出高性能，准确率为94.5%，精确率为93.2%，召回率为95.8%。比较分析表明，混合模型优于独立的CNN和LSTM架构，突出了其综合优势。值得注意的是，该模型产生了低假阴性率，这对于及时干预至关重要。这项研究为早期白蚁检测贡献了一种非侵入式、自动化解决方案，对于改善害虫监测、最大限度地减少结构损坏以及提高房主和害虫控制专业人员的决策具有实际意义。未来的工作可能会整合物联网以实现实时警报，并将检测范围扩展到其他结构性害虫。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [542] [Benchmarking Sub-Genre Classification For Mainstage Dance Music](https://arxiv.org/abs/2409.06690)
> *主舞台舞曲子流派分类基准测试*

*Hongzhi Shu, Xinglin Li, Hongyu Jiang, Minghao Fu, Xinyu Li* | **Category: cs.SD, cs.AI, cs.MM, H.5.5; I.2.1** | **Updated: 2025-07-17**

**Keywords:** 音乐分类, 子流派, 舞曲, 数据集, 基准测试

**Comment:** WASPAA 2025

> **TL;DR:** 本文提出了一个针对主舞台舞曲子流派分类的新基准，包括一个新数据集和基线模型，旨在解决现有数据集和方法的不足，并表明即使是先进的多模态大型语言模型也难以胜任此任务，而其专用基线模型表现出色。

**AI_Comments:** 该论文通过构建一个专门针对主舞台舞曲子流派分类的数据集和基线模型，填补了该领域现有数据集和方法不足的空白，具有重要的实践意义。其创新之处在于数据集对EDM场景多样性的捕捉以及对混合子流派曲目的软标签处理。此外，开源代码和数据将极大地促进后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决主舞台舞曲子流派分类中缺乏全面的数据集和有效方法的问题，并反映近期全球音乐节上顶尖DJ表演中子流派的多样性。

**Method:** 引入了一个新的数据集和一个专用基线模型。数据集扩展了子流派范围，以反映近期主舞台现场表演的多样性，并采用连续软标签方法来处理混合了多个子流派的曲目，以保留其内在复杂性。

**Result:** 实验表明，即使是最先进的多模态大型语言模型（MLLMs）也难以完成这项任务，而他们专门的基线模型取得了高精度。

**Conclusion:** 本文提出的新基准和专用基线模型为解决主舞台舞曲子流派分类的挑战提供了有效方案，并支持音乐推荐、DJ套装策划和交互式多媒体系统等应用。

> **ai_Abstract:** 本文提出了一个针对主舞台舞曲子流派分类的新基准，旨在解决当前缺乏全面数据集和有效方法的问题。研究者构建了一个反映近期EDM场景多样性的新数据集，并采用软标签处理多流派混合的曲目。实验结果显示，即使是先进的多模态大型语言模型在该任务上表现不佳，而作者提出的专用基线模型则能达到高精度。该基准有望支持音乐推荐和DJ策展等多种应用，且所有代码和数据均已开源。

> **摘要翻译:** 音乐分类作为音乐信息检索的基石，支持广泛的应用。为了解决主舞台舞曲子流派分类中缺乏全面的数据集和有效方法的问题，我们引入了一个新的基准，其中包含一个新数据集和基线模型。我们的数据集扩展了子流派的范围，以反映近期全球音乐节上顶尖DJ表演中子流派的多样性，捕捉了吸引全球数百万粉丝的充满活力且快速发展的电子舞曲（EDM）场景。我们采用连续软标签方法来处理混合了多个子流派的曲目，保留了其内在复杂性。实验表明，即使是最先进的多模态大型语言模型（MLLMs）也难以完成这项任务，而我们专门的基线模型取得了高精度。这个基准支持音乐推荐、DJ套装策划和交互式多媒体系统等应用，并提供了视频演示。我们的代码和数据已在https://github.com/Gariscat/housex-v2.git}{https://github.com/Gariscat/housex-v2.git 开源。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [546] [Cross-Modal Watermarking for Authentic Audio Recovery and Tamper Localization in Synthesized Audiovisual Forgeries](https://arxiv.org/abs/2507.12723)
> *跨模态水印用于合成视听伪造中的真实音频恢复和篡改定位*

*Minyoung Kim, Sehwan Park, Sungmin Cha, Paul Hongsuck Seo* | **Category: cs.SD, cs.MM, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 跨模态水印, 真实音频恢复, 篡改定位, 合成视听伪造, 虚假信息防御

**Comment:** 5 pages, 2 figures, Interspeech 2025

> **TL;DR:** 本文提出一种跨模态水印框架，用于在合成视听伪造中恢复真实音频并定位篡改，以对抗虚假信息。

**AI_Comments:** 本文的创新点在于提出了真实音频恢复（AAR）和音频篡改定位（TLA）的新任务，并通过跨模态水印技术，在内容被篡改前嵌入真实音频，从而有效对抗合成视听伪造。这种前瞻性的防御机制对于打击深度伪造虚假信息具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语音克隆和唇形同步模型的发展导致了合成视听伪造（SAVFs），其中音频和视觉都被操纵以模仿目标说话者，这显著增加了虚假信息的风险。现有方法可以检测或定位篡改，但无法恢复传达语义内容的真实音频，从而降低了其对抗视听虚假信息的有效性。

**Method:** 本文引入了从SAVFs中恢复真实音频（AAR）和音频篡改定位（TLA）的任务，并提出了一种跨模态水印框架，在操纵之前将真实音频嵌入到视觉中。

**Result:** 大量实验证明，本文方法在对抗各种操纵（包括语音克隆和唇形同步）方面，在AAR和TLA上表现出强大的性能。

**Conclusion:** 通过将真实音频嵌入到视觉中，本文提出的跨模态水印框架能够实现真实音频恢复和篡改定位，并提供针对虚假信息的强大防御。

> **ai_Abstract:** 本文针对合成视听伪造（SAVFs）带来的虚假信息风险，提出了一种跨模态水印框架。该框架旨在解决现有方法无法恢复真实音频的问题，实现真实音频恢复（AAR）和音频篡改定位（TLA）。通过在操纵前将真实音频嵌入到视觉中，该方法能够有效地对抗语音克隆和唇形同步等多种操纵，并为视听虚假信息提供鲁棒的防御。

> **摘要翻译:** 语音克隆和唇形同步模型的最新进展催生了合成视听伪造（SAVFs），其中音频和视觉都被操纵以模仿目标说话者。这显著增加了虚假信息的风险，使虚假内容看起来真实。为了解决这个问题，现有方法检测或定位操纵，但无法恢复传达消息语义内容的真实音频。这种限制降低了它们在打击视听虚假信息方面的有效性。在这项工作中，我们引入了从SAVFs中恢复真实音频（AAR）和音频篡改定位（TLA）的任务，并提出了一种跨模态水印框架，在操纵之前将真实音频嵌入到视觉中。这使得AAR、TLA以及对虚假信息的强大防御成为可能。大量的实验证明了我们的方法在AAR和TLA方面对抗各种操纵（包括语音克隆和唇形同步）的强大性能。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [577] [Enkidu: Universal Frequential Perturbation for Real-Time Audio Privacy Protection against Voice Deepfakes](https://arxiv.org/abs/2507.12932)
> *Enkidu：用于实时音频隐私保护以对抗语音深度伪造的通用频率扰动*

*Zhou Feng, Jiahao Chen, Chunyi Zhou, Yuwen Pu, Qingming Li, Tianyu Du, Shouling Ji* | **Category: cs.SD, cs.MM** | **Updated: 2025-07-17**

**Keywords:** 语音深度伪造, 音频隐私, 频率扰动, 实时保护, 黑盒防御

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** Enkidu是一种新型框架，通过通用频率扰动，实时、轻量级地保护用户音频隐私，有效对抗语音深度伪造，且显著提升效率。

**AI_Comments:** Enkidu的创新点在于其利用通用频率扰动和黑盒知识实现实时、轻量级的隐私保护，解决了现有方法在适应性、可伸缩性和计算成本方面的局限性。其在效率上的显著提升（内存和运行时）以及对黑盒攻击的鲁棒性使其在实际应用中具有重要价值。该研究为对抗日益增长的语音深度伪造威胁提供了有效且高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 语音深度伪造技术迅速发展，引发了严重的音频隐私担忧，攻击者利用公共语音数据进行身份盗窃、金融欺诈和虚假信息传播等恶意行为。现有防御方法存在局限性，包括对未见用户数据适应性差、对长音频可伸缩性差、僵化地依赖白盒知识以及加密过程中的高计算和时间成本。

**Method:** 本文提出了Enkidu，一个新颖的以用户为中心的隐私保护框架。它通过黑盒知识和少量用户数据进行少样本训练，生成通用的频率扰动。这些高度可塑的频域噪声补丁能够实现实时、轻量级的保护，对可变长度音频具有强大的泛化能力，并能有效抵抗语音深度伪造攻击，同时保持感知质量和语音清晰度。

**Result:** Enkidu与六种最先进的对策相比，实现了超过50到200倍的处理内存效率（低至0.004 GB）和3到7000倍的运行时效率（实时系数低至0.004）。对六个主流文本到语音模型和五个尖端自动说话人验证模型的广泛实验证明了Enkidu在防御普通和自适应语音深度伪造攻击方面的有效性、可迁移性和实用性。

**Conclusion:** Enkidu通过利用通用频率扰动，有效且高效地防御了语音深度伪造攻击，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了Enkidu，一个创新的用户导向隐私保护框架，旨在应对语音深度伪造对音频隐私的威胁。Enkidu通过黑盒知识和少量数据训练生成通用的频率扰动，实现对变长音频的实时、轻量级保护，有效抵抗语音深度伪造攻击，同时保持高质量的语音感知。与现有先进方法相比，Enkidu在处理内存和运行时效率上均有显著提升，并通过大量实验验证了其有效性、可迁移性和实用性。

> **摘要翻译:** 语音深度伪造技术的快速发展引发了用户音频隐私方面的严重担忧，因为攻击者越来越多地利用公开可用的语音数据生成令人信服的虚假音频，用于身份盗窃、金融欺诈和虚假信息宣传等恶意目的。虽然现有的防御方法提供部分保护，但它们面临关键限制，包括对未见用户数据适应性差、对长音频可伸缩性差、僵化地依赖白盒知识，以及加密过程中计算和时间成本高。为了解决这些挑战并防御个性化语音深度伪造威胁，我们提出了Enkidu，一个新颖的以用户为中心的隐私保护框架，它利用通过黑盒知识和少量用户数据进行少样本训练生成的通用频率扰动。这些高度可塑的频域噪声补丁能够实现实时、轻量级的保护，对可变长度音频具有强大的泛化能力，并能有效抵抗语音深度伪造攻击，同时保持感知质量和语音清晰度。值得注意的是，与六种最先进的对策相比，Enkidu实现了超过50到200倍的处理内存效率（低至0.004 GB）和3到7000倍的运行时效率（实时系数低至0.004）。对六个主流文本到语音模型和五个尖端自动说话人验证模型的广泛实验证明了Enkidu在防御普通和自适应语音深度伪造攻击方面的有效性、可迁移性和实用性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [582] [Sample-Constrained Black Box Optimization for Audio Personalization](https://arxiv.org/abs/2507.12773)
> *音频个性化中的样本约束黑盒优化*

*Rajalaxmi Rajagopalan, Yu-Lin Wei, Romit Roy Choudhury* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 音频个性化, 黑盒优化, 稀疏高斯过程回归, 混合查询, 用户满意度

**Comment:** Published in AAAI 2024

> **TL;DR:** 针对音频个性化中的黑盒优化问题，本文提出了一种基于稀疏高斯过程回归的混合查询方法，结合了对整体样本和个体元素的查询，实验证明其优于单一查询方式，能有效提升用户满意度。

**AI_Comments:** 这篇论文的创新点在于引入了“混合查询”的概念，即除了传统的对整体样本进行评分外，还允许用户对最优解的个体元素进行反馈。这种结合两种信息源的方法，在黑盒优化问题中提供了更丰富、可能更高效的优化路径。其重要性在于，它不仅解决了音频个性化这一特定应用的问题，更提出了一个通用的黑盒优化策略，有望推广到其他用户反馈敏感的复杂系统优化中，例如推荐系统、产品设计等。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决音频个性化中最大化用户体验的问题，即找到一个能最大化用户满意度的音频滤波器，由于用户满意度函数是未知的，这是一个黑盒优化问题。

**Method:** 现有方法通过播放不同滤波器处理的音频样本并询问用户满意度分数，然后设计代理函数进行优化。本文在此基础上，观察到用户还可以直接提供最佳滤波器个体元素的反馈。因此，提出了一种基于稀疏高斯过程回归（Sparse GPR）的混合查询方法，结合了这两种查询类型。

**Result:** 通过仿真和真实世界实验验证了所提出的混合方法。结果表明，混合查询方法优于任何单一类型的查询，并且在音乐/语音音频个性化中使志愿者达到了高满意度水平。

**Conclusion:** 混合查询的理念为黑盒优化开辟了新问题，其解决方案不仅可以造福音频个性化，还可以应用于其他领域。

> **ai_Abstract:** 本文研究音频个性化中的黑盒优化问题，旨在找到能最大化用户满意度的音频滤波器。针对传统方法仅依赖整体样本评分的局限性，作者提出了一种创新的混合查询方法。该方法基于稀疏高斯过程回归，结合了对整体音频样本的满意度评分和对最佳滤波器单个元素的直接反馈。实验结果表明，这种混合查询策略在仿真和真实世界场景中均优于单一查询方式，有效提升了用户满意度，并为黑盒优化领域带来了新的研究方向。

> **摘要翻译:** 我们考虑最大化用户体验的音频个性化问题。简而言之，我们的目标是找到一个滤波器 $h^*$，将其应用于任何音乐或语音，都将最大化用户的满意度。这是一个黑盒优化问题，因为用户的满意度函数是未知的。关于这个主题已经做了大量实质性工作，其核心思想是向用户播放由不同滤波器 $h_i$ 处理的音频样本，并询问用户他们的满意度分数 $f(h_i)$。然后设计一系列“代理”函数来拟合这些分数，优化方法逐渐完善这些函数以得到最大化满意度的滤波器 $\hat{h}^*$。在某些应用中，我们观察到第二种查询类型是可能的，即用户可以告诉我们最佳滤波器 $h^*$ 的各个元素 $h^*[j]$。以烹饪为例，目标是烹饪出最大化用户满意度的食谱。用户可以被要求对各种烹饪食谱（例如，豆腐炒饭）进行评分，或者对单个食材（例如，盐、糖、米饭、鸡肉等）进行评分。给定一个预算为 $B$ 的查询次数，其中查询可以是任一类型，我们的目标是找到能最大化该用户满意度的食谱。我们的提案建立在稀疏高斯过程回归（GPR）之上，并展示了混合方法如何优于任何一种单一类型的查询。我们的结果通过仿真和真实世界实验得到验证，在这些实验中，志愿者对音乐/语音音频提供了反馈，并能够达到高满意度水平。我们相信这种混合查询的理念在黑盒优化中开辟了新问题，并且其解决方案可以使音频个性化之外的其他应用受益。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [612] [Multi-Class-Token Transformer for Multitask Self-supervised Music Information Retrieval](https://arxiv.org/abs/2507.12996)
> *用于多任务自监督音乐信息检索的多类别令牌Transformer*

*Yuexuan Kong, Vincent Lostanlen, Romain Hennequin, Mathieu Lagrange, Gabriel Meseguer-Brocal* | **Category: cs.SD** | **Updated: 2025-07-17**

**Keywords:** 音乐信息检索, 自监督学习, Transformer, 对比学习, 等变学习

**Comment:** 

> **TL;DR:** 本文提出MT2，一种带有两个专用类别令牌的ViT-1D架构，用于结合对比学习和等变学习的自监督音乐信息检索。它在多项任务上优于单一任务模型和MERT，且参数量显著减少。

**AI_Comments:** 本文的创新之处在于其“两全其美”的方法，通过专门的类别令牌将两种不同的自监督学习范式（对比学习和等变学习）整合到单一架构中。这种多任务、多类别令牌的设计对于音乐信息检索（MIR）领域是新颖的，能够学习到更鲁棒和通用的表示，同时与现有技术（如MERT）相比，实现了显著的参数效率。其重要性在于通过克服单一范式方法的局限性，推动了复杂音频分析任务（特别是MIR）中自监督学习的发展。

<details>
  <summary>Details</summary>

**Motivation:** 对比学习和等变学习是音频内容分析中有效的自监督学习方法，但在音乐信息检索（MIR）中的应用面临困境：前者在标记任务上有效但在结构化预测上效果不佳；后者在特定任务上表现良好但泛化性差。本文旨在结合两者的优势。

**Method:** 本文提出了一种名为多类别令牌多任务（MT2）的新架构，它是基于一维频谱图块的Vision Transformer（ViT-1D），配备了两个专门用于不同自监督预训练任务但通过相同模型优化的类别令牌。其中一个类别令牌用于优化五度圈上等变学习的交叉功率谱密度（CPSD），另一个用于优化对比学习的归一化温度标度交叉熵（NT-Xent）。

**Result:** MT2始终优于单独使用对比学习或等变学习训练的单类别令牌ViT-1D模型。对两个类别令牌进行平均进一步提高了在多项任务上的性能。此外，MT2在使用相同单线性层探测方法的情况下，在除节拍跟踪之外的所有任务上均优于MERT，且由于其多任务处理能力，参数量减少了18倍。

**Conclusion:** 多类别令牌多任务学习方法（MT2）展示了其在音乐信息检索应用中的多功能性和优越性能，有效结合了对比学习和等变学习的优势。

> **ai_Abstract:** 本文提出MT2，一种新颖的Vision Transformer（ViT-1D）架构，用于自监督音乐信息检索。MT2利用两个专门的类别令牌，同时整合对比学习和等变学习，解决了将这些方法单独应用于MIR任务的局限性。通过组合优化策略，MT2持续超越了单一任务的自监督模型，并在大多数任务上表现出优于MERT的性能，尤其是在参数量显著减少的情况下，突显了其效率和多功能性。

> **摘要翻译:** 对比学习和等变学习是音频内容分析中有效的自监督学习（SSL）方法。然而，它们在音乐信息检索（MIR）中的应用面临一个困境：前者在标记（例如，乐器识别）方面更有效，但在结构化预测（例如，音调估计）方面效果较差；后者可以在其设计的特定任务上与监督方法相媲美，但泛化到其他任务时效果不佳。在本文中，我们采用了一种两全其美的方法，通过同时在两种类型的预训练任务上训练深度神经网络。所提出的新架构是一个带有1D频谱图块的Vision Transformer（ViT-1D），配备了两个类别令牌，它们专门用于不同的自监督预训练任务，但通过相同的模型进行优化：因此称之为自监督多类别令牌多任务（MT2）。前一个类别令牌优化五度圈上等变学习的交叉功率谱密度（CPSD），而后一个优化对比学习的归一化温度标度交叉熵（NT-Xent）。MT2结合了两种预训练任务的优势，并始终优于仅使用对比学习或等变学习训练的单类别令牌ViT-1D模型。对两个类别令牌进行平均进一步提高了在多项任务上的性能，突出了每个类别令牌学习到的表示的互补性。此外，使用相同的单线性层探测方法在最后一层特征上，MT2在除节拍跟踪之外的所有任务上均优于MERT；由于其多任务处理能力，实现这一目标所需的参数量减少了18倍。我们的SSL基准测试证明了我们多类别令牌多任务学习方法在MIR应用中的多功能性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [621] [Autoregressive Speech Enhancement via Acoustic Tokens](https://arxiv.org/abs/2507.12825)
> *基于声学标记的自回归语音增强*

*Luca Della Libera, Cem Subakan, Mirco Ravanelli* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-17**

**Keywords:** 语音增强, 声学标记, 自回归模型, 离散表示, 说话人身份

**Comment:** 5 pages, 2 figures

> **TL;DR:** 本文研究了使用声学标记进行语音增强，并引入了一种新的基于传感器的自回归架构，发现声学标记优于语义标记，且自回归方法能进一步提升性能，但离散表示仍不及连续表示。

**AI_Comments:** 本文的创新点在于首次全面研究了声学标记在语音增强中的应用，并引入了专为该任务设计的自回归架构。它解决了传统语义标记在保留说话人身份方面的不足，并利用了自回归建模的潜力。尽管如此，论文也坦诚地指出了离散表示与连续表示之间的性能差距，为未来的研究指明了方向，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在语音处理中，提高录音质量和可懂度至关重要。虽然监督回归是主要的语音增强方法，但音频标记化作为一种与其它模态平滑集成的新兴替代方案。然而，使用离散表示进行语音增强的研究有限，且之前的工作主要关注语义标记（丢失关键声学细节如说话人身份）并采用非自回归模型（忽略自回归建模的潜在改进）。

**Method:** 为解决现有问题，本文进行了两项工作：1) 全面研究声学标记在语音增强中的性能，包括比特率和噪声强度的影响；2) 引入一种专门为此任务设计的、新颖的基于传感器的自回归架构。

**Result:** 在VoiceBank和Libri1Mix数据集上的实验表明，声学标记在保留说话人身份方面优于语义标记，并且本文的自回归方法可以进一步提高性能。

**Conclusion:** 尽管声学标记结合自回归模型在语音增强中表现出优势，但离散表示的性能仍不及连续表示，这表明该领域需要进一步研究。

> **ai_Abstract:** 本文旨在解决语音增强领域中离散表示研究不足的问题，特别是现有方法对语义标记的过度关注导致丢失声学细节，以及非自回归模型未能充分利用序列相关性。文章全面评估了声学标记在语音增强中的性能，并提出了一种新颖的基于传感器的自回归架构。实验结果显示，声学标记在保留说话人身份方面优于语义标记，且所提出的自回归方法能进一步提升性能。然而，研究也指出离散表示仍不及连续表示，提示未来研究方向。

> **摘要翻译:** 在语音处理流程中，提高真实世界录音的质量和可懂度至关重要。虽然监督回归是语音增强的主要方法，但音频标记化正作为一种有前景的替代方案出现，以实现与其他模态的平滑集成。然而，使用离散表示进行语音增强的研究仍然有限。之前的工作主要集中在语义标记上，这些标记往往会丢失关键的声学细节，如说话人身份。此外，这些研究通常采用非自回归模型，假设输出的条件独立性，并忽视了自回归建模所能提供的潜在改进。为了弥补这些空白，我们：1) 对声学标记在语音增强中的性能进行了全面研究，包括比特率和噪声强度的影响；2) 引入了一种专门为此任务设计的新型基于传感器的自回归架构。在VoiceBank和Libri1Mix数据集上的实验表明，声学标记在保留说话人身份方面优于语义标记，并且我们的自回归方法可以进一步提高性能。尽管如此，我们观察到离散表示与连续表示相比仍有不足，这凸显了该领域需要进一步研究。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='cssc'></a>
## cs.SC 

### [120] [Probabilistic algorithm for computing all local minimizers of Morse functions on a compact domain](https://arxiv.org/abs/2507.13071)
> *紧凑域上Morse函数所有局部极小值计算的概率算法*

*Mohab Safey El Din, Georgy Scholten, Emmanuel Trélat* | **Category: cs.SC, math.OC** | **Updated: 2025-07-17**

**Keywords:** Morse函数, 局部极小值, 概率算法, 逼近理论, 计算机代数

**Comment:** 

> **TL;DR:** 提出一种概率算法，能在噪声模型下计算紧凑域上Morse函数的所有局部极小值，并提供精度保证和实际应用效果。

**AI_Comments:** 该研究的创新之处在于，它在噪声模型下提供了一种计算Morse函数所有局部极小值的概率算法，这对于全局优化问题是一个重要进展。结合了逼近理论和计算机代数技术的方法显得新颖且强大，并且其在Julia包中的实际实现证明了其解决以往无法处理问题的能力，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 在噪声模型下，计算紧凑域上Morse函数的所有局部极小值是一个挑战，本研究旨在设计一种能够实现此目标的算法。

**Method:** 该算法基于逼近理论，生成函数的S多项式逼近，并结合计算机代数技术求解多项式方程组。它是一种概率算法，在噪声模型下使用评估程序Γ和精心选择的评估点。

**Result:** 算法返回K中有限个有理点，这些点为中心、半径为ε的球集包含并分离了函数f的所有局部极小值。该算法在已知所有正则参数时提供了位复杂度估计，并且在Julia包Globtim中的实现能够处理以前无法解决的示例。

**Conclusion:** 本文成功设计了一种概率算法，用于在噪声模型下计算紧凑域上Morse函数的所有局部极小值，该算法具有理论精度保证和实际应用效果，能够解决现有方法无法处理的问题。

> **ai_Abstract:** 本文提出了一种在噪声模型下计算紧凑域上Morse函数所有局部极小值的概率算法。该算法利用逼近理论和计算机代数技术，在给定评估程序、噪声参数和精度要求下，能够返回有限个有理点，这些点形成的球集能够包含并分离所有局部极小值。文章提供了算法的位复杂度估计，并通过Julia包Globtim的实现展示了其在处理复杂问题上的有效性。

> **摘要翻译:** 设K是Rn中的单位立方体，f: K → R^n是一个Morse函数。我们假设函数f是通过噪声模型中的评估程序Γ给出的，即评估程序Γ接收一个额外参数η作为输入，并返回一个与f真实值相距η的近似值。在本文中，我们设计了一种能够计算K上f所有局部极小值的算法。我们的算法接收Γ、η、一个数值精度参数ε以及一些明确的额外正则参数作为输入。在概率性质的假设下——与用于馈送Γ的评估点的选择有关——，它返回K中有限个有理点，使得以这些点为中心、半径为ε的球集包含并分离了f的所有局部极小值。我们的方法基于逼近理论，为f生成多项式逼近，并结合计算机代数技术求解多项式方程组。当所有正则参数已知时，我们提供了算法的位复杂度估计。实际实验表明，我们在Julia包Globtim中实现的该算法能够处理迄今为止无法解决的示例。

</details>

[⬆️ 返回分类顶部](#cssc) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [10] [N Bugs on a Circle](https://arxiv.org/abs/2507.13333)
> *圆上的N只虫子*

*Josh Briley, Bryan Quaife* | **Category: math.DS, cs.NA, math.NA** | **Updated: 2025-07-17**

**Keywords:** 虫子, 圆, 循环追逐, 稳态, 汇合

**Comment:** 

> **TL;DR:** 该研究推广了经典的循环追逐问题，将N只虫子限制在单位圆周上。与原始问题不同，该推广产生了三种稳定的状态：所有虫子汇合、形成两组对立点集群，或进入无限追逐循环。研究分析了这些稳态的稳定性，并计算了达到每种状态的概率，发现其行为比经典问题更丰富。

**AI_Comments:** 这项研究创新性地将经典的循环追逐问题推广到受限空间——单位圆周上，揭示了在限制条件下系统动态行为的复杂性和多样性，这是原始无限制问题所不具备的。通过引入三种不同的稳态，并结合解析解与蒙特卡洛模拟，该工作不仅提供了理论深度，也为理解受限环境中多智能体系统的长期行为提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在推广经典的“正方形上的四只虫子”循环追逐问题，将虫子限制在单位圆周上，以探索在限制条件下与原始问题不同的丰富动力学行为。

**Method:** 研究将N只虫子限制在单位圆的周长上，每只虫子以恒定的角速度顺时针、逆时针移动或保持静止。分析了稳态的稳定性并计算了随机初始化虫子达到每种状态的概率。对于N≤4的情况，推导了精确的解析表达式；对于更大的N值，采用蒙特卡洛模拟来估计汇合的概率。

**Result:** 该推广产生了三种可能的稳态：所有虫子汇合到一点、虫子聚集在两个对立点上，或虫子进入稳定的无限追逐循环。与经典问题不同，虫子并非总是汇合。对于N≤4，得出了达到这些状态的精确概率表达式。对于更大的N值，蒙特卡洛模拟表明汇合概率近似遵循与虫子数量的平方根倒数关系。

**Conclusion:** 该推广揭示了经典问题中不存在的丰富动力学行为。分析提供了关于将虫子限制在圆周上如何从根本上改变追逐代理长期行为的见解，这与不受限制的追逐问题有所不同。

> **ai_Abstract:** 本文对经典的循环追逐问题进行了推广，将N只虫子限制在单位圆周上，而非允许其螺旋靠近。研究发现，与原始问题中虫子总会汇合不同，该模型产生了三种稳态：完全汇合、形成两组对立点集群或进入无限追逐循环。文章分析了这些稳态的稳定性，并计算了达到每种状态的概率，对于N≤4给出了精确解，对于更大的N值则通过蒙特卡洛模拟发现汇合概率与虫子数量呈近似反平方根关系。这项工作揭示了限制条件如何引入更丰富的动力学行为。

> **摘要翻译:** 我们描述并分析了经典“正方形上的四只虫子”循环追逐问题的推广。我们没有让虫子相互螺旋靠近，而是将N只虫子限制在单位圆的周长上。根据它们的配置，每只虫子以恒定的角速度顺时针或逆时针移动，或保持静止。与原始问题中虫子总是汇合不同，这种推广产生了三种可能的稳态：所有虫子汇合到一点，虫子集群位于两个对立点，或者虫子进入一个稳定的无限追逐循环，它们永不相遇。我们分析了这些稳态的稳定性，并计算了随机初始化的虫子达到每种状态的概率。对于N≤4，我们推导出了这些概率的精确解析表达式。对于更大的值，我们采用蒙特卡洛模拟来估计汇合的概率，发现它近似遵循与虫子数量的平方根倒数关系。这种推广揭示了经典问题中不存在的丰富动力学行为。我们的分析提供了关于将虫子限制在圆周上如何从根本上改变追逐代理的长期行为，这与不受限制的追逐问题相比。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

### [361] [Interacting Hosts with Microbiome Exchange: An Extension of Metacommunity Theory for Discrete Interactions](https://arxiv.org/abs/2507.11958)
> *宿主与微生物组交换的相互作用：离散相互作用的群落生态学理论扩展*

*Michael Johnson, Mason A. Porter* | **Category: math.DS, cond-mat.stat-mech, cs.SI, nlin.AO, q-bio.PE** | **Updated: 2025-07-16**

**Keywords:** 微生物组, 群落生态学, 离散相互作用, 宿主, 建模框架

**Comment:** 55 pages

> **TL;DR:** 本文提出了一种新的建模框架，用于描述活体宿主之间离散的微生物组交换，扩展了传统的群落生态学理论，并证明了交互频率和交换量参数对微生物组动态的重要性。

**AI_Comments:** 该论文通过引入离散相互作用的概念，对传统的群落生态学理论进行了重要扩展，使其更能适应活体宿主微生物组的复杂性。其创新之处在于提出了双参数建模方法，能够更精细地刻画交互频率和交换量对微生物组动态的影响。这对于理解和预测宿主-微生物组系统的演变具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的群落生态学模型假设微生物组在环境之间连续扩散，这适用于非生物环境。然而，活体宿主之间的微生物组交换通常是离散的，现有模型未能捕捉这一关键方面。因此，需要一个新的建模框架来解释活体宿主之间离散的微生物组相互作用。

**Method:** 本文开发了一个新的建模框架，该框架编码了离散的宿主间相互作用，并使用两个参数分别控制宿主间的相互作用频率和每次相互作用期间的微生物组交换量。研究者推导了该框架中模型在三种参数制度下的解析近似，并证明了其准确性。通过与数值模拟进行比较，验证了模型的有效性。

**Result:** 研究结果表明，该建模框架中的两个参数（相互作用频率和交换强度）对于确定微生物组动力学都是必需的。动力学的关键特征，例如微生物组在宿主间的趋同，对相互作用频率和强度之间的相互作用非常敏感。

**Conclusion:** 活体宿主之间离散的微生物组交换需要一个专门的建模框架，该框架中的相互作用频率和交换量参数共同决定了微生物组的动态，并对微生物组的趋同等关键特征产生敏感影响。

> **ai_Abstract:** 本文针对活体宿主之间离散的微生物组交换，提出了一种新的建模框架，以扩展传统的群落生态学理论。现有理论假设连续扩散，不适用于活体宿主间的离散相互作用。新框架引入了相互作用频率和每次相互作用交换量两个参数，并推导出其在不同参数制度下的解析近似。研究证明这两个参数对微生物组动态至关重要，特别是对微生物组在宿主间的趋同性有显著影响。

> **摘要翻译:** 微生物组是环境中相互作用的微生物群落，它们常常对所占据的环境斑块或活体宿主产生实质性影响。在微生物组模型中，考虑环境内的局部动态以及环境之间的微生物组交换非常重要。整合这些以及多尺度相互作用的一种方法是采用群落生态学理论。群落生态学模型通常假设微生物组在发生局部微生物组动态的环境之间连续扩散。在此假设下，每对环境之间的一个单一参数控制着它们之间的扩散速率。这种群落生态学框架非常适合非生物环境斑块，但它未能捕捉活体宿主微生物组的一个基本方面，即活体宿主通常不相互持续作用。相反，活体宿主以离散的时间间隔相互作用。在本文中，我们开发了一个建模框架，该框架编码了这种离散相互作用，并使用两个参数分别控制宿主之间的相互作用频率和每次相互作用期间的微生物组交换量。我们推导了我们框架中模型在三种参数制度下的解析近似，并证明了它们在这些制度下的准确性。我们将这些近似与一个说明性模型的数值模拟进行了比较。我们证明了我们建模框架中的两个参数都是确定微生物组动态所必需的。动态的关键特征，例如微生物组在宿主间的趋同，对相互作用频率和强度之间的相互作用高度敏感。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

### [531] [Estimation of Regions of Attraction for Nonlinear Systems via Coordinate-Transformed TS Models and Piecewise Quadratic Lyapunov Functions](https://arxiv.org/abs/2507.12718)
> *基于坐标变换TS模型和分段二次Lyapunov函数的非线性系统吸引域估计*

*Artun Sel, Mehmet Koruturk, Erdi Sayar* | **Category: math.DS, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 吸引域, 非线性系统, TS模型, Lyapunov函数, 坐标变换

**Comment:** 

> **TL;DR:** 本文提出了一种通过整合多重坐标变换和分段二次Lyapunov函数在Takagi-Sugeno (TS) 建模框架内，计算非线性系统增大的吸引域（ROA）的新方法，相较于现有方法显著增大了ROA估计。

**AI_Comments:** 本文的创新点在于其多路径方法，即通过多重坐标变换生成多个系统表示，并结合分段二次Lyapunov函数来计算各个吸引域，最终通过求并集的方式获得更大的吸引域估计。这克服了传统单一变换方法的局限性，为非线性系统吸引域的扩大估计提供了一个有效的途径，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通常采用单一路径来计算吸引域，限制了吸引域的估计大小。本文旨在通过提出一种新颖的方法来计算更大的非线性系统吸引域。

**Method:** 该方法通过应用一系列坐标变换（使用转换矩阵T1, T2, ..., TN）来生成多个系统表示，为每个变换后的系统构建相应的TS模型，并使用分段二次Lyapunov函数计算各自的吸引域。最终的吸引域估计是所有计算区域的并集。

**Result:** 与传统的单一变换技术相比，该增强方法在吸引域大小估计方面显示出显著改进，并通过与现有基于TS的稳定性方法进行比较分析得到证实。

**Conclusion:** 本文提出了一种通过结合多重坐标变换和分段二次Lyapunov函数的新颖方法，可以有效地计算出更大的非线性系统吸引域。

> **ai_Abstract:** 本文提出了一种新颖的方法，用于估计非线性系统的吸引域（ROA）。该方法通过在Takagi-Sugeno (TS) 建模框架下，结合多重坐标变换和分段二次Lyapunov函数来实现。与传统单一路径方法不同，本方法生成多个系统表示并计算各自的ROA，最终取其并集以获得更大的ROA估计。实验结果表明，该方法在ROA大小估计上显著优于现有技术。

> **摘要翻译:** 本文提出了一种通过在Takagi-Sugeno (TS) 建模框架内整合多重坐标变换和分段二次Lyapunov函数来计算非线性动力系统增大吸引域（ROA）的新颖方法。现有方法通常遵循单一路径：原始系统 → TS模型 → ROA计算，而所提出的方法系统地应用一系列坐标变换来生成多个系统表示，每个表示都产生不同的ROA估计。具体而言，该方法使用转换矩阵T1, T2, ..., TN对原始非线性系统进行变换，以获得N个不同的坐标表示，为每个变换后的系统构建相应的TS模型，并使用分段二次Lyapunov函数计算各自的ROA。最终的ROA估计是所有计算区域的并集，这利用了分段二次Lyapunov函数相对于传统二次方法的内在灵活性。与传统的单一变换技术相比，该增强方法在ROA大小估计方面显示出显著改进，这通过与现有基于TS的稳定性方法的比较分析得到证实。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [24] [Complex non-backtracking matrix for directed graphs](https://arxiv.org/abs/2507.12503)
> *复杂非回溯矩阵用于有向图*

*Keishi Sando, Hideitsu Hino* | **Category: math.CO, cs.LG, stat.ML** | **Updated: 2025-07-16**

**Keywords:** 复杂非回溯矩阵, 有向图, 厄米特邻接矩阵, 聚类信息, 图表示

**Comment:** 

> **TL;DR:** 提出一种结合厄米特邻接矩阵和非回溯矩阵特性的复杂非回溯矩阵，用于分析有向图，并发现其包含聚类信息，尤其适用于稀疏有向图。

**AI_Comments:** 该论文提出了一种创新的图表示矩阵，通过结合现有两种重要矩阵的特性，为有向图分析特别是聚类问题提供了新的视角和工具。其对稀疏有向图的适用性是一个重要的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 图表示矩阵是图数据分析的重要工具。现有研究提出了厄米特邻接矩阵来研究有向图结构，并证明其能提取聚类信息。本文旨在整合两种矩阵的特性以提供更强大的工具。

**Method:** 提出了一种新的“复杂非回溯矩阵”，该矩阵结合了厄米特邻接矩阵和非回溯矩阵的特性。

**Result:** 该提出的矩阵与无向图的非回溯矩阵具有相似的性质。揭示了复杂非回溯矩阵与厄米特邻接矩阵之间的关系。发现该矩阵表示包含聚类信息，特别是对于稀疏有向图。

**Conclusion:** 复杂非回溯矩阵是一种有效的新型图表示工具，能够为有向图，特别是稀疏有向图的聚类分析提供有价值的信息。

> **ai_Abstract:** 本文提出了一种用于有向图分析的复杂非回溯矩阵，该矩阵结合了厄米特邻接矩阵和非回溯矩阵的优点。研究发现，该矩阵与无向图的非回溯矩阵具有相似性质，并揭示了其与厄米特邻接矩阵的关系。重要的是，该矩阵表示被证明包含聚类信息，尤其适用于稀疏有向图，为有向图数据分析提供了新的有效工具。

> **摘要翻译:** 图表示矩阵是图数据分析的重要工具。最近，厄米特邻接矩阵被提出用于研究有向图结构。先前的研究表明这些矩阵可以提取有价值的聚类信息。在本文中，我们提出了一种复杂非回溯矩阵，它整合了厄米特邻接矩阵和非回溯矩阵的特性。所提出的矩阵与无向图的非回溯矩阵具有相似的性质。我们揭示了复杂非回溯矩阵与厄米特邻接矩阵之间的关系。此外，我们提供了有趣的见解，即这种矩阵表示包含聚类信息，特别是对于稀疏有向图。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [30] [Weighted Pseudorandom Generators for Read-Once Branching Programs via Weighted Pseudorandom Reductions](https://arxiv.org/abs/2502.08272)
> *通过加权伪随机约简实现一次性分支程序的加权伪随机生成器*

*Kuan Cheng, Ruiyang Wu* | **Category: cs.CC, cs.DS** | **Updated: 2025-07-17**

**Keywords:** 加权伪随机生成器, 一次性分支程序, 去随机化, 伪随机约简, 种子长度

**Comment:** 

> **TL;DR:** 本文研究并构建了用于一次性分支程序（ROBPs）的加权伪随机生成器（WPRGs）和去随机化方法，通过迭代加权伪随机约简获得了改进的种子长度和空间复杂度。

**AI_Comments:** 本文的创新点在于提出了“迭代加权伪随机约简”这一通用方法，它有效地将针对长ROBPs的伪随机性问题转化为短ROBPs的问题，从而统一并改进了不同类型ROBPs的WPRG构造和去随机化方案。其重要性在于为计算复杂性理论中去随机化问题提供了新的工具和更优的界限。

<details>
  <summary>Details</summary>

**Motivation:** 研究加权伪随机生成器（WPRGs）和用于一次性分支程序（ROBPs）的去随机化方法。

**Method:** 所有结果均基于迭代加权伪随机约简，该方法可以将欺骗长ROBPs的问题迭代地约简为欺骗短ROBPs的问题。

**Result:** 1. 对于标准ROBPs，提出了一个明确的ε-WPRG，其种子长度为$O\left(\frac{\log n\log (nw)}{\max\left\{1,\log\log w-\log\log n\right\}}+\log w \left(\log\log\log w-\log\log\max\left\{2,\frac{\log w}{\log \frac{n}{\varepsilon}}\right\}\right)+\log\frac{1}{\varepsilon}\right)$。
2. 对于无限宽度和单接受节点的置换ROBPs，提出了一个明确的ε-WPRG，其种子长度为$O\left( \log n\left( \log\log n + \sqrt{\log(1/\varepsilon)} \right)+\log(1/\varepsilon)\right)$。
3. 对于宽度为$w$、长度为$n = 2^{O(\sqrt{\log w})}$且具有多个接受节点的正则ROBPs，提出了一个新的Nisan-Zuckerman风格的去随机化方法，对于任意近似误差$\\varepsilon = 1/\text{poly} (w)$，实现了最佳空间复杂度$O(\log w)$。

**Conclusion:** 本文通过引入迭代加权伪随机约简，为不同类型的读一次分支程序（ROBPs）提供了新的加权伪随机生成器（WPRGs）和去随机化方案，并在种子长度和空间复杂度方面取得了改进。

> **ai_Abstract:** 本文深入研究了用于一次性分支程序（ROBPs）的加权伪随机生成器（WPRGs）和去随机化技术。研究提出了针对标准ROBPs和置换ROBPs的显式ε-WPRG，给出了具体的种子长度上界。此外，还为正则ROBPs引入了一种新的Nisan-Zuckerman风格的去随机化方法，并实现了最优空间复杂度。所有这些成果均得益于一种新颖的迭代加权伪随机约简技术，该技术能够将复杂问题分解为更简单的子问题。

> **摘要翻译:** 我们研究了用于一次性分支程序（ROBPs）的加权伪随机生成器（WPRGs）和去随机化方法。设$n$和$w$分别为ROBP的长度和宽度。我们有以下结果：
对于标准ROBPs，我们给出了一个显式的$\\varepsilon$-WPRG，其种子长度为$$O\left(\frac{\log n\log (nw)}{\max\left\{1,\log\log w-\log\log n\right\}}+\log w \left(\log\log\log w-\log\log\max\left\{2,\frac{\log w}{\log \frac{n}{\varepsilon}}\right\}\right)+\log\frac{1}{\varepsilon}\right).$$对于具有无限宽度和单个接受节点的置换ROBPs，我们给出了一个显式的$\\varepsilon$-WPRG，其种子长度为$$O\left( \log n\left( \log\log n + \sqrt{\log(1/\varepsilon)} \right)+\log(1/\varepsilon)\right). $$
我们还为宽度为$w$、长度为$n = 2^{O(\sqrt{\log w})}$且具有多个接受节点的正则ROBPs提供了一种新的Nisan-Zuckerman风格的去随机化方法。对于任意近似误差$\\varepsilon = 1/\text{poly} (w)$，我们实现了最佳空间复杂度$O(\log w)$。
我们所有的结果都基于迭代加权伪随机约简，它可以迭代地将欺骗长ROBPs的问题约简为欺骗短ROBPs的问题。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [511] [Computational-Statistical Tradeoffs from NP-hardness](https://arxiv.org/abs/2507.13222)
> *计算-统计权衡与NP-难性*

*Guy Blanc, Caleb Koch, Carmen Strassle, Li-Yang Tan* | **Category: cs.CC, cs.DS, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 计算-统计权衡, NP-难性, PAC学习, 样本复杂度, VC维

**Comment:** To appear at FOCS 2025

> **TL;DR:** 本文基于NP-难性，建立了计算效率与统计样本复杂度之间的权衡关系，并在PAC学习中得到了具体结果，包括VC维为1的类的样本复杂度以及RP=NP的学习条件。

**AI_Comments:** 这篇论文的创新之处在于它成功地将计算-统计权衡与更强的计算复杂度假设（NP-难性）联系起来，而不是依赖于平均情况假设。特别是，其对RP与NP关系的刻画以及针对非适当学习器的NP-难性结果，为理解学习理论中的计算限制提供了深刻的见解，并规避了之前研究中的形式障碍，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算机科学和统计学中的核心问题是高效算法能否达到统计问题的信息论极限。现有的计算-统计权衡多基于平均情况假设，但将它们建立在标准最坏情况假设上具有挑战性。本文旨在解决这一挑战，尤其是在PAC学习领域。

**Method:** 作者将计算-统计权衡建立在NP-难性上。他们通过假设NP需要指数时间来推导尖锐的计算-统计权衡，并利用学习理论来刻画RP与NP的关系，特别是证明了RP=NP当且仅当每个NP可枚举类都可以在多项式时间内用O(VCdim(C))样本学习的逆向蕴含。值得注意的是，所有下界都适用于非适当学习器。

**Result:** 1. 假设NP需要指数时间，得到了尖锐的计算-统计权衡：对于每个多项式p(n)，存在一个VC维为1的n变量类C，使得高效学习C的样本复杂度为$\\Theta(p(n))$。
2. 在学习方面刻画了RP与NP的关系：RP = NP当且仅当每个NP可枚举类都可以在多项式时间内用O(VCdim(C))样本学习。作者证明了这一命题的逆向蕴含。
3. 所有下界都适用于非适当学习器，这是首次针对多项式大小电路子类的非适当学习的NP-难性结果，规避了现有形式障碍。

**Conclusion:** 本文成功地将计算-统计权衡建立在NP-难性上，为理解高效算法在统计问题中达到信息论极限的限制提供了新的见解，特别是在PAC学习领域。

> **ai_Abstract:** 本文探讨了高效算法在统计问题中达到信息论极限的计算-统计权衡，尤其是在PAC学习框架下。作者将这些权衡与NP-难性关联起来，得到了两个主要结果：一是假设NP需要指数时间，则存在VC维为1的类在时间高效学习时样本复杂度与任意多项式函数相关；二是证明了RP=NP当且仅当所有NP可枚举类都能在多项式时间内用O(VCdim(C))样本学习。这些结果的下界适用于非适当学习器，并首次为多项式大小电路子类的非适当学习提供了NP-难性证明，克服了现有障碍。

> **摘要翻译:** 计算机科学和统计学中的一个核心问题是高效算法能否达到统计问题的信息论极限。许多计算-统计权衡已在平均情况假设下得到证明，但由于统计问题本质上是平均情况的，将其建立在标准最坏情况假设上一直是一个挑战。在首次研究此类权衡的PAC学习中，问题在于计算效率是否会以使用比信息论必要样本更多为代价。我们将此类权衡建立在$\\mathsf{NP}$-难性上并获得了：$\\circ$ 假设$\\mathsf{NP}$需要指数时间，则存在尖锐的计算-统计权衡：对于每个多项式$p(n)$，存在一个VC维为$1$的$n$变量类$C$，使得时间高效学习$C$的样本复杂度为$\\Theta(p(n))$。$\\circ$ 通过学习来刻画$\\mathsf{RP}$与$\\mathsf{NP}$的关系：当且仅当每个$\\mathsf{NP}$-可枚举类都可以在多项式时间内用$O(\\mathrm{VCdim}(C))$样本学习时，$\\mathsf{RP} = \\mathsf{NP}$。正向蕴含自(Pitt and Valiant, 1988)以来已知；我们证明了逆向蕴含。值得注意的是，我们所有的下界都适用于非适当学习器。这些是针对多项式大小电路子类进行非适当学习的首次$\\mathsf{NP}$-难性结果，规避了Applebaum、Barak和Xiao (2008)的形式障碍。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [596] [Perfect diffusion is $\mathsf{TC}^0$ -- Bad diffusion is Turing-complete](https://arxiv.org/abs/2507.12469)
> *完美扩散是$\mathsf{TC}^0$ -- 劣质扩散是图灵完备的*

*Yuxi Liu* | **Category: cs.CC, cs.CL, cs.LG** | **Updated: 2025-04-20**

**Keywords:** 扩散模型, 计算复杂性, 图灵完备, TC0, 语言建模

**Comment:** 7 pages

> **TL;DR:** 本文探讨了扩散模型在语言建模中的计算复杂性，证明了一个二分法：完美的扩散模型（精确计算分数函数）计算能力受限于$\mathsf{TC}^0$复杂度类，而如果对分数匹配网络没有要求（劣质），扩散模型则可以模拟任意图灵机。

**AI_Comments:** 本文通过对扩散模型计算复杂性的二分法证明，提供了对该模型能力和局限性的深刻理论洞察。其创新之处在于明确区分了“完美”和“劣质”扩散模型所对应的计算能力（$\mathsf{TC}^0$与图灵完备），这对于理解扩散模型的本质特性及其在语言建模中的应用具有重要意义。文章提出的关于未来机器学习架构的设想也极具启发性，指出了可能超越现有模型的方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索扩散模型在语言建模中的计算复杂性，并理解其能力和局限性，特别是对于需要顺序计算的任务。

**Method:** 作者通过证明一个基于扩散模型中分数匹配网络质量的二分法来分析计算复杂性。他们分别考察了网络精确计算分数函数和网络没有分数匹配要求的情况。

**Result:** 研究结果表明，如果扩散模型中的网络精确计算某个初始分布的分数函数，那么它只能在$\mathsf{TC}^0$复杂度类内执行语言建模。反之，如果网络没有匹配任何分数函数的要求，扩散模型在某种意义上可以模拟任何图灵机。

**Conclusion:** 这个二分法为扩散模型的能力和局限性提供了理论视角，尤其是在需要顺序计算的任务方面。作者还推测了理论结果的扩展，并讨论了更广泛的背景和实际意义，假设一种可以在顺序和并行操作模式之间插值的机器学习架构将优于Transformer和扩散模型。

> **ai_Abstract:** 本文深入探讨了扩散模型在语言建模领域的计算复杂性。研究核心在于提出并证明了一个二分法：当扩散模型的得分匹配网络精确地计算某一初始分布的得分函数时，其计算能力被限制在$\mathsf{TC}^0$复杂度类内，这暗示了其在快速收敛方面的局限性。然而，如果对得分匹配网络没有精确匹配任何得分函数的要求，该模型则能够以某种方式模拟任意图灵机。这一发现为理解扩散模型的潜力和局限性提供了重要的理论框架，尤其是在处理需要顺序计算的任务时。文章还提出了关于“良好”而非“完美”扩散模型的理论扩展猜想，并探讨了这些发现的实际影响，推测未来能够融合顺序与并行计算模式的机器学习架构可能超越当前流行的Transformer和扩散模型。

> **摘要翻译:** 本文探讨了基于扩散的语言模型的计算复杂性。我们证明了一个基于扩散模型中分数匹配网络质量的二分法。一方面，一个精确计算某个初始分布分数函数的网络，其语言建模能力仅限于$\mathsf{TC}^0$复杂度类，这反映了与快速收敛相关的局限性。另一方面，我们表明，如果网络没有匹配任何分数函数的要求，那么扩散模型在某种意义上可以模拟任何图灵机。这种二分法为扩散模型的能力和局限性提供了理论视角，特别是对于需要顺序计算的任务。我们推测了我们理论结果的扩展，包括扩散模型不完美但仅仅是好的情况。我们还讨论了更广泛的背景和实际意义，并假设一种可以在顺序和并行操作模式之间插值的机器学习架构将优于Transformer和扩散模型。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [45] [Determination of galaxy photometric redshifts using Conditional Generative Adversarial Networks (CGANs)](https://arxiv.org/abs/2501.06532)
> *使用条件生成对抗网络（CGANs）测定星系光度红移*

*M. Garcia-Fernandez* | **Category: astro-ph.IM, astro-ph.CO, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 光度红移, CGAN, 星系, 机器学习, 暗能量巡天

**Comment:** 

> **TL;DR:** 本文提出使用CGANs测定星系光度红移，并与MDN比较，发现CGANs虽略逊于MDN但结果接近，为CGANs在该领域的应用提供了可能性。

**AI_Comments:** 本文提出了一种将CGAN应用于光度红移估计的新颖方法，尽管其性能尚未超越现有技术（MDN），但其接近的性能表现为未来在该领域的探索提供了新的方向和可能性。这表明CGAN作为一种强大的生成模型，在天体物理数据分析中具有潜在的应用价值，尤其是在需要进行不确定性估计（概率密度估计）的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 光度红移的准确可靠测定是宽视场光度巡天中的关键问题。传统方法依赖于机器学习和人工智能技术，但本文旨在提出一种新的算法方法。

**Method:** 本文提出了一种使用条件生成对抗网络（CGANs）来测定星系光度红移的算法方法。该实现能够确定光度红移的点估计和概率密度估计。该方法使用暗能量巡天（DES）Y1数据进行测试，并与混合密度网络（MDN）等现有算法进行比较。

**Result:** 尽管获得的结果显示MDN具有优越性，但CGAN的质量指标与MDN的结果接近。

**Conclusion:** CGAN在光度红移估计中的应用是可行的，并且其结果接近现有表现最好的算法，为未来的研究打开了大门。

> **ai_Abstract:** 本文提出一种基于条件生成对抗网络（CGANs）的星系光度红移测定新方法，可进行点估计和概率密度估计。该方法在暗能量巡天（DES）Y1数据上进行了测试，并与混合密度网络（MDN）等现有算法进行了比较。结果显示，尽管MDN表现更优，但CGAN的性能指标与MDN非常接近，表明CGAN在光度红移估计领域具有应用潜力。

> **摘要翻译:** 准确可靠的光度红移测定是宽视场光度巡天中的关键方面之一。星系光度红移的测定传统上通过使用在校准星系样本上训练的机器学习和人工智能技术来解决，这些样本同时具有光度和光谱数据。在本文中，我们提出了一种使用条件生成对抗网络（CGANs）测定星系光度红移的新算法方法。所提出的实现能够确定光度红移的点估计和概率密度估计。该方法使用暗能量巡天（DES）Y1数据进行测试，并与混合密度网络（MDN）等其他现有算法进行比较。尽管获得的结果显示MDN具有优越性，但CGAN的质量指标与MDN的结果接近，这为在光度红移估计中使用CGAN打开了大门。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

### [248] [A Semi-Supervised Learning Method for the Identification of Bad Exposures in Large Imaging Surveys](https://arxiv.org/abs/2507.12784)
> *大型成像巡天中不良曝光识别的半监督学习方法*

*Yufeng Luo, Adam D. Myers, Alex Drlica-Wagner, Dario Dematties, Salma Borchani, Frank Valdes, Arjun Dey, David Schlegel, Rongpu Zhou, DESI Legacy Imaging Surveys Team* | **Category: astro-ph.IM, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 半监督学习, 图像质量控制, 天文巡天, 视觉Transformer, k-最近邻

**Comment:** 21 pages, 12 figures

> **TL;DR:** 本文提出了一种基于半监督学习的机器学习方法，用于在大规模天文成像巡天中自动识别低质量曝光，并在DECaLS数据上进行了验证。

**AI_Comments:** 本文提出了一种结合ViT和kNN的半监督学习方法，用于识别大型天文成像巡天中的不良曝光，这在数据量爆炸式增长的背景下具有重要意义。其创新之处在于将自监督学习与半监督框架结合，有效利用了少量标记数据和大量未标记数据。该方法的高效性和可扩展性使其在天文学领域具有广泛的应用潜力，解决了人工检查不可行的问题。

<details>
  <summary>Details</summary>

**Motivation:** 随着天文成像巡天数据量的快速增长，传统的人工目视检查等图像异常检测方法变得不切实际，需要一种高效、可扩展的自动化解决方案来识别低质量曝光。

**Method:** 该方法是一个半监督学习流程，结合了通过自监督学习（SSL）训练的视觉Transformer（ViT）和一个k-最近邻（kNN）分类器。它使用少量已标记的曝光进行训练和验证。

**Result:** 该方法在DECaLS数据发布11中识别出780个问题曝光，并通过人工目视检查得到验证。对“好”和“坏”图像的聚类空间分析表明，该方法能够高效准确地确定曝光质量。

**Conclusion:** 本文提出的半监督学习方法能够高效、准确地识别大型成像巡天中的不良曝光，提供了一个可扩展的质量控制解决方案，并适用于其他大型成像巡天。

> **ai_Abstract:** 本文提出了一种针对大型天文成像巡天中低质量曝光识别的半监督学习方法。该方法结合了通过自监督学习训练的视觉Transformer（ViT）和k-最近邻（kNN）分类器。通过在DECam巡天数据上训练和验证，该方法被证明能够高效准确地识别不良曝光。在DECaLS数据发布11中的应用成功识别了780个问题曝光并得到了验证，表明其为大规模成像巡天提供了可扩展的质量控制解决方案。

> **摘要翻译:** 随着天文成像巡天数据量的快速增长，传统的人工目视检查等图像异常检测方法变得不切实际。我们引入了一种基于机器学习的方法来检测大型成像巡天中的低质量曝光，重点关注低消光区域（即 E(B-V)<0.04）的DECam遗留巡天（DECaLS）。我们的半监督流程整合了一个通过自监督学习（SSL）训练的视觉Transformer（ViT）和一个k-最近邻（kNN）分类器。我们使用一小部分由暗能量相机（DECam）巡天观测到的已标记曝光来训练和验证我们的流程。对我们流程将“好”和“坏”类别的图像放置在聚类空间的分析表明，我们的方法可以高效准确地确定曝光的质量。应用于正在为DECaLS数据发布11进行处理的新图像时，我们的流程识别出780个有问题曝光，我们随后通过目视检查进行了验证。由于其高效和适应性强，我们的方法为其他大型成像巡天中的质量控制提供了一个可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

### [364] [(Exhaustive) Symbolic Regression and model selection by minimum description length](https://arxiv.org/abs/2507.13033)
> *(穷举)符号回归与最小描述长度模型选择*

*Harry Desmond* | **Category: astro-ph.IM, astro-ph.CO, astro-ph.GA, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 符号回归, 最小描述长度, 模型选择, 穷举搜索, 天体物理学

**Comment:** 15 pages, 4 figures; Invited review for the Royal Society
  Philosophical Transactions A special issue "Symbolic regression in the
  physical sciences"

> **TL;DR:** 本文提出一种基于穷举搜索和最小描述长度原则的符号回归算法，旨在解决传统算法的局限性，并在天体物理学问题上取得了优于现有文献标准的结果。

**AI_Comments:** 该论文的创新点在于提出了结合穷举搜索和最小描述长度（MDL）原则的符号回归方法，有效地解决了传统方法在函数发现成功率低和模型选择不明确的问题。MDL原则将准确性和复杂性统一到信息单位中，提供了一种理论上更坚实、实践中更有效的模型选择机制。其在天体物理学开放问题上的成功应用，证明了其强大的发现能力和超越现有解决方案的潜力，对于需要从数据中发现潜在数学关系的科学领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统符号回归算法面临两大挑战：一是找到给定良好函数的概率未知且可能很低；二是函数选择过程存在歧义和缺乏合理假设。

**Method:** 提出通过最小描述长度原则进行穷举搜索和模型选择，该原则允许通过信息单位衡量准确性和复杂性，从而直接进行权衡。

**Result:** 所提出的穷举符号回归算法在宇宙膨胀历史、星系中引力的有效行为和暴胀场势能这三个天体物理学开放问题上进行了展示，并在每个案例中识别出许多优于现有文献标准的函数。

**Conclusion:** 这种通用方法应在科学及其他领域得到广泛应用。

> **ai_Abstract:** 本文提出了一种名为“穷举符号回归”的新型符号回归算法，旨在解决传统算法在发现优秀函数和模型选择方面的局限性。该方法采用穷举搜索结合最小描述长度原则，以信息单位衡量准确性和复杂性，实现两者之间的直接权衡。在宇宙膨胀历史、星系引力行为和暴胀场势能等三个天体物理学开放问题上的应用表明，该算法能够发现大量优于现有文献标准的函数，显示出其在科学及其他领域的广泛应用潜力。

> **摘要翻译:** 符号回归是一种从数据中学习函数的机器学习方法。在简要概述符号回归领域之后，我将描述传统算法面临的两个主要挑战：它们找到任何给定良好函数的概率未知（且可能显著），并且它们在函数选择过程中存在歧义和缺乏合理假设。为了解决这些问题，我提出了通过最小描述长度原则进行穷举搜索和模型选择，该原则允许通过信息单位衡量准确性和复杂性，从而直接进行权衡。我在三个天体物理学开放问题上展示了由此产生的公开可用的穷举符号回归算法：宇宙的膨胀历史、星系中引力的有效行为以及暴胀场的势能。在每个案例中，该算法都识别出许多优于文献标准的函数。这种通用方法应在科学及其他领域得到广泛应用。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='q-finmf'></a>
## q-fin.MF 

### [69] [Distributional Reinforcement Learning on Path-dependent Options](https://arxiv.org/abs/2507.12657)
> *路径依赖期权上的分布强化学习*

*Ahmet Umur Özsoy* | **Category: q-fin.MF, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 分布强化学习, 路径依赖期权, 金融衍生品定价, 风险感知定价, 不确定性量化

**Comment:** 

> **TL;DR:** 本文提出一个使用分布强化学习（DistRL）来估计收益的完整分布，从而对路径依赖型金融衍生品进行定价的框架，以实现风险感知定价和不确定性量化。

**AI_Comments:** 这项工作在金融衍生品定价领域具有创新性，因为它将分布强化学习引入其中，突破了传统方法仅关注预期价值的局限。通过建模收益的完整分布，它为风险管理提供了更细致的视角，尤其是在尾部风险和不确定性量化方面。这对于金融机构进行更稳健的决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法只关注期权的预期价值，无法进行风险感知定价、尾部风险估计和不确定性量化。

**Method:** 提出一个框架，通过使用分布强化学习（DistRL）来估计收益的完整分布，从而对路径依赖型金融衍生品进行定价。该方法建模了收益的整个条件分布，并使用基于分位数的值函数近似器在亚洲期权上进行了验证。

**Result:** 该方法在亚洲期权上展示了有效性，能够实现风险感知定价、尾部风险估计和增强的不确定性量化。

**Conclusion:** 分布强化学习提供了一种有效的方法来对路径依赖型金融衍生品进行定价，通过建模收益的完整分布，从而实现更全面的风险管理和不确定性量化。

> **ai_Abstract:** 该论文提出了一个利用分布强化学习（DistRL）来对路径依赖型金融衍生品进行定价的新框架。与传统侧重于预期价值的方法不同，该框架通过估计收益的完整分布，实现了风险感知定价、尾部风险估计和更精确的不确定性量化。研究在亚洲期权上验证了该方法的有效性，并采用了基于分位数的值函数近似器。

> **摘要翻译:** 我们重新解释并提出了一个框架，用于通过使用分布强化学习（DistRL）估计收益的完整分布来对路径依赖型金融衍生品进行定价。与传统方法侧重于预期期权价值不同，我们的方法建模了收益的整个条件分布，从而实现风险感知定价、尾部风险估计和增强的不确定性量化。我们使用基于分位数的值函数近似器，在亚洲期权上展示了该方法的有效性。

</details>

[⬆️ 返回分类顶部](#q-finmf) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [79] [Distributed Truncated Predictive Control for Networked Systems under Uncertainty: Stability and Near-Optimality Guarantee](https://arxiv.org/abs/2310.06194)
> *不确定性下网络化系统的分布式截断预测控制：稳定性和近似最优性保证*

*Eric Xu, Soummya Kar, Guannan Qu* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 分布式控制, 预测控制, 网络化系统, 不确定性, 稳定性, 近似最优性

**Comment:** 16 pages, 3 figures, 2 column format. This work has been submitted to
  the IEEE for possible publication

> **TL;DR:** 本文提出了一种分布式截断预测控制 (DTPC) 算法，用于不确定性下的网络化系统控制。该算法通过截断预测和局部邻域信息，实现了输入到状态稳定性 (ISS) 和指数衰减的后悔值，表明在短预测范围和小的截断半径下也能达到近似最优性能，且对近期预测误差更敏感。

**AI_Comments:** 该论文提出了一种新颖的分布式截断预测控制方法，通过限制预测范围和邻域范围，有效解决了网络化系统在不确定性下的在线控制问题。其创新点在于证明了在局部信息和短预测范围下也能保证系统的稳定性和近似最优性，降低了计算复杂性。对预测误差敏感度的分析也很有价值，为实际应用中的预测精度要求提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 研究具有时变成本函数和扰动的网络化系统的分布式在线控制问题，其中每个节点仅具有状态的局部信息以及成本和扰动的预测。

**Method:** 开发了一种分布式截断预测控制 (DTPC) 算法。每个节点求解一个具有预测范围 $k$ 的“截断”预测最优控制问题，但仅涉及 $\\kappa$ 跳邻域内的节点（忽略外部节点）。

**Result:** DTPC 算法满足输入到状态稳定性 (ISS) 界限，并且后悔值以 $k$ 和 $\\kappa$ 指数衰减，这意味着短预测范围 $k$ 和小截断半径 $\\kappa$ 足以实现近似最优性能。此外，当未来的成本和扰动不完全已知时，后悔值对预测误差的敏感度随预测范围呈指数衰减，这意味着近期预测误差比长期预测误差起着更重要的作用。

**Conclusion:** 所提出的分布式截断预测控制 (DTPC) 算法在不确定性下为网络化系统提供了稳定性和近似最优性保证，即使在预测范围短和截断半径小的情况下也能实现良好性能，并且对近期预测误差的敏感性更高。

> **ai_Abstract:** 本文针对不确定性下具有时变成本和扰动的网络化系统，提出了一种分布式截断预测控制 (DTPC) 算法。该算法允许每个节点基于局部信息和 $\\kappa$-跳邻域内的节点进行截断预测控制。研究结果表明，DTPC 算法具有输入到状态稳定性 (ISS) 特性，并且其后悔值随预测范围 $k$ 和截断半径 $\\kappa$ 指数衰减，意味着即使是短期的预测和有限的局部信息也能实现近似最优性能。此外，该算法对未来预测误差的敏感性也随预测范围呈指数衰减，强调了近期预测误差的重要性。

> **摘要翻译:** 我们研究了具有时变成本函数和扰动的网络化系统的分布式在线控制问题，其中每个节点仅具有状态的局部信息以及成本和扰动的预测。我们开发了一种分布式截断预测控制 (DTPC) 算法，其中每个节点求解一个具有预测范围 $k$ 的“截断”预测最优控制问题，但仅涉及 $\\kappa$ 跳邻域内的节点（忽略外部节点）。我们表明 DTPC 算法满足输入到状态稳定性 (ISS) 界限，并且后悔值以 $k$ 和 $\\kappa$ 指数衰减，这意味着短预测范围 $k$ 和小截断半径 $\\kappa$ 足以实现近似最优性能。此外，我们表明，当未来的成本和扰动不完全已知时，后悔值对预测误差的敏感度随预测范围呈指数衰减，这意味着近期预测误差比长期预测误差起着更重要的作用。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [306] [Nash equilibrium seeking for a class of quadratic-bilinear Wasserstein distributionally robust games](https://arxiv.org/abs/2411.09636)
> *一类二次-双线性Wasserstein分布鲁棒博弈的纳什均衡寻求*

*Georgios Pantazis, Reza Rahimi Baghbadorani, Sergio Grammatico* | **Category: math.OC, cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-17**

**Keywords:** 纳什均衡, Wasserstein距离, 分布鲁棒优化, 变分不等式, 黄金分割算法

**Comment:** 19 pages, 6 figures

> **TL;DR:** 该论文研究了一类Wasserstein分布鲁棒纳什均衡问题，证明其可被重构为有限维问题，并提出了两种基于黄金分割算法的求解方法，通过仿真验证了其效率。

**AI_Comments:** 该论文的创新之处在于成功地将复杂的、看似无限维的分布鲁棒纳什均衡问题转化为可计算的有限维形式，这对于实际应用至关重要。重构方案在数据规模上的可伸缩性以及约束数量独立于样本数量的特性是其显著优势。采用基于黄金分割算法进行求解也体现了对实际计算效率的关注，为分析不确定性下风险规避多智能体决策提供了坚实的理论基础和实用工具。

<details>
  <summary>Details</summary>

**Motivation:** 考虑代理人基于私有样本和半径构建异构数据驱动的Wasserstein模糊集，以反映其个体风险规避行为的纳什均衡问题。目标是找到一种可扩展的方法来计算这些看似无限维问题的均衡解。

**Method:** 通过利用博弈的性质，将原始的无限维问题转化为有限维纳什均衡问题。随后，将问题重构为有限维变分不等式，并建立了其解集之间的联系。为了计算解，论文提出了两种基于黄金分割算法的方案。

**Result:** 原始无限维问题的均衡可以作为有限维纳什均衡问题的解获得。重构为有限维变分不等式后，其与相应解集之间建立了联系。该重构在数据大小方面具有可伸缩性，并且独立于样本数量，保持固定数量的约束。两种提出的算法方案的效率通过广泛的仿真研究得到了证实，包括一个说明性示例和随机投资组合分配博弈。

**Conclusion:** 该论文成功地将一类复杂的分布鲁棒纳什均衡问题转化为可处理的有限维形式，并提供了高效的算法进行计算，展示了其可伸缩性和实际适用性。

> **ai_Abstract:** 该论文探讨了代理人具有异构数据驱动Wasserstein模糊集的Wasserstein分布鲁棒纳什均衡问题。研究表明，这些看似无限维的问题可被重构为有限维纳什均衡问题和有限维变分不等式，且具有数据规模可伸缩性及固定约束数量的优点。为求解这些问题，论文提出了两种基于黄金分割算法的方法，并通过仿真实验验证了其在说明性示例和随机投资组合分配博弈中的效率。

> **摘要翻译:** 我们考虑一类Wasserstein分布鲁棒纳什均衡问题，其中代理人根据其个体风险规避行为，利用私有样本和半径构建异构数据驱动的Wasserstein模糊集。通过利用此类博弈的相关性质，我们表明，原始看似无限维问题的均衡可以作为有限维纳什均衡问题的解来获得。然后，我们将问题重新表述为有限维变分不等式，并建立了相应解集之间的联系。我们的重构在数据大小方面具有可伸缩性，并且独立于样本数量，保持固定数量的约束。为了计算解，我们利用了两种基于黄金分割算法的算法。通过对一个说明性示例和随机投资组合分配博弈（其中模拟了投资者之间的行为耦合）进行广泛的仿真研究，证实了这两种算法方案的效率。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [402] [Unsupervised Ground Metric Learning](https://arxiv.org/abs/2507.13094)
> *无监督基础度量学习*

*Janis Auffenberg, Jonas Bresch, Oleh Melnyk, Gabriele Steidl* | **Category: math.OC, cs.LG, cs.NA, math.NA** | **Updated: 2025-07-17**

**Keywords:** 无监督学习, 度量学习, 最优传输, 随机随机函数迭代, 马哈拉诺比斯距离

**Comment:** 10 figures, 1 table

> **TL;DR:** 该论文探讨了无监督度量学习的算法和建模，提出了一种收敛的随机随机函数迭代算法，并研究了使用马哈拉诺比斯距离和图拉普拉斯代替最优传输距离的方法。

**AI_Comments:** 该论文的创新点在于提出了一个在算子非准收缩条件下仍能实现线性收敛的随机随机函数迭代算法，这扩展了无监督度量学习的算法基础。同时，通过引入马哈拉诺比斯距离和图拉普拉斯方法，拓宽了无监督度量学习的建模范畴，特别是图拉普拉斯方法能有效简化计算复杂性，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在缺乏标注样本的情况下进行数据分类是一个挑战性问题，而这通常依赖于选择合适的特征间距离。度量学习旨在解决此问题，尤其是在无监督情境下，如何有效地学习距离度量是关键。

**Method:** 该研究从算法和建模两方面探讨了无监督度量学习。算法方面，作者提出并证明了随机随机函数迭代算法在线性收敛，即使其算子不满足以往要求的准收缩性。建模方面，研究探索了最优传输距离是否可被其他距离替代，并展示了马哈拉诺比斯距离和图拉普拉斯方法如何适用于此框架，后者可简化为线性代数问题。

**Result:** 提出了随机随机函数迭代算法，并证明了其在线性收敛，即便在算子非准收缩的情况下。此外，研究展示了马哈拉诺比斯距离和图拉普拉斯方法可以被纳入无监督度量学习框架，特别是图拉普拉斯方法能将问题简化为线性函数处理，从而应用简单的线性代数算法。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文致力于无监督度量学习，旨在解决无标签数据分类中距离选择的挑战。在先前最优传输成本矩阵学习的基础上，作者从算法和建模两方面展开研究。算法上，提出并证明了随机随机函数迭代算法的线性收敛性，突破了现有对算子准收缩性的要求。建模上，探讨了用马哈拉诺比斯距离和图拉普拉斯方法替代最优传输距离的可行性，并指出图拉普拉斯方法可将问题简化为线性形式，便于应用简单的线性代数算法。

> **摘要翻译:** 无监督基础度量学习

在无法访问标记样本的情况下进行数据分类仍然是一个具有挑战性的问题。它通常取决于特征之间适当选择的距离，这是一个在度量学习中解决的主题。最近，Huizing、Cantini 和 Peyr\'e 提出同时学习数据集样本和特征之间的最优传输（OT）成本矩阵。这导致了寻找将成本矩阵映射到 OT 距离的某个非线性函数的正特征向量的任务。考虑到这个基本思想，我们考虑了无监督度量学习的算法和建模两部分。首先，我们检查了适当的算法及其收敛性。特别是，我们提出使用随机随机函数迭代算法，并证明它在我们的设置中线性收敛，尽管我们的算子不像迄今为止要求收敛那样是准收缩的。其次，我们提出了一个自然的问题，即 OT 距离是否可以被其他距离取代。我们展示了马哈拉诺比斯（Mahalanobis-like）距离如何适应我们的考虑。此外，我们通过图拉普拉斯（graph Laplacians）研究了一种方法。与以前的设置相反，在这里我们只需处理所需矩阵中的线性函数，因此可以应用线性代数中的简单算法。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [426] [On the factorization of matrices into products of positive definite ones](https://arxiv.org/abs/2507.12560)
> *关于矩阵分解为正定矩阵乘积的问题*

*Mahmoud Abdelgalil, Tryphon T. Georgiou* | **Category: math.OC, cs.NA, cs.SY, eess.SY, math.DS, math.NA, 15A23, 15B48, 49Q22, 37N35, 37J25, 93C05, 93Axx, 90C52, 65F30, 68T30** | **Updated: 2025-07-16**

**Keywords:** 矩阵分解, 正定矩阵, 最优质量传输, 控制系统, Ballantine型分解

**Comment:** 7 pages

> **TL;DR:** 本文提出了一种新的方法，将具有正行列式的方阵分解为正定因子，该方法基于最优质量传输理论，并与控制工程中的Ballantine型分解相关。

**AI_Comments:** 本文的创新之处在于引入了最优质量传输理论来解决矩阵分解问题，为Ballantine型分解提供了一种新的建设性方法。这不仅对控制工程领域具有重要意义，也深化了对旋转和无旋运动之间关系的理解。

<details>
  <summary>Details</summary>

**Motivation:** Ballantine型分解在解决线性系统强可控性这一基本但难以捉摸的控制问题中至关重要。此外，Ballantine的结果突出了旋转可以通过连续应用无旋运动来实现这一鲜为人知的事实。

**Method:** 本文的方法是建设性的，并基于最优质量传输理论。具体而言，它将高斯分布的连续旋转与构成所需因子的相应最优传输映射相关联。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种基于最优质量传输理论的新方法，用于将具有正行列式的方阵分解为正定矩阵的乘积。该方法重新审视了查尔斯·巴兰坦的相关结果，并强调了此类分解在解决控制工程中的线性系统强可控性问题以及理解旋转机制方面的重要性。

> **摘要翻译:** 本工作重新审视并提供了一种新方法，关于查尔斯·巴兰坦（Charles Ballantine）的一个结果，即具有正行列式的方阵分解为正定因子的乘积。巴兰坦型分解，限制了正定因子的数量，被证明在解决一个基本但难以捉摸的控制问题——通过状态反馈形式的控制实现线性系统的强可控性——中至关重要。巴兰坦的结果超越了控制工程，并强调了一个鲜为人知的事实，即旋转可以通过连续应用无旋运动来实现。我们的方法是建设性的，并基于最优质量传输理论，具体而言，它将高斯分布的连续旋转与构成所求因子的相应最优传输映射联系起来。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [588] [Stochastic Weakly Convex Optimization Under Heavy-Tailed Noises](https://arxiv.org/abs/2507.13283)
> *重尾噪声下的随机弱凸优化*

*Tianxi Zhu, Yi Xu, Xiangyang Ji* | **Category: math.OC, cs.LG, stat.ML** | **Updated: 2025-07-17**

**Keywords:** 随机优化, 弱凸优化, 重尾噪声, 次梯度下降, 收敛性

**Comment:** 

> **TL;DR:** 本文研究了重尾噪声下随机一阶方法（SFOMs）在弱凸优化问题中的收敛性，发现香草随机次梯度下降（SsGD）和裁剪SsGD在特定噪声类型下表现出与光滑目标函数相似的理论依赖性，尽管裁剪SsGD的样本复杂度可能较差。

**AI_Comments:** 本文填补了在重尾噪声下，随机一阶方法在弱凸优化领域收敛性理解的空白。其创新之处在于将现有针对光滑或凸情况的分析扩展到更通用的弱凸设置，这对于实际深度学习等应用具有重要意义。尽管裁剪SsGD的样本复杂度结果不尽理想，但整体工作为理解复杂噪声环境下的优化算法提供了宝贵的理论见解。

<details>
  <summary>Details</summary>

**Motivation:** 在凸优化和标准光滑优化背景下，重尾梯度噪声（如亚Weibull噪声和具有有界$p$阶中心矩的噪声）下的随机一阶方法（SFOMs）的收敛性已得到广泛研究。然而，对于弱凸目标函数（包括Lipschitz连续凸目标和光滑目标），在这些噪声类型下SFOMs的期望收敛性和高概率收敛性的理解仍不完整。

**Method:** 本文研究了在弱凸优化背景下，两种随机一阶方法的收敛性：1. 在亚Weibull噪声下，香草随机次梯度下降（SsGD）方法的高概率收敛性。2. 在具有有界$p$阶中心矩（$p$-BCM）噪声下，裁剪SsGD的高概率和期望收敛性。

**Result:** 1. 对于亚Weibull噪声下的香草SsGD，其理论上对失败概率和迭代次数的依赖性与光滑目标函数的情况相比没有下降。2. 在$p$-BCM噪声下，弱凸目标函数的非光滑性和非凸性不影响裁剪SGD对失败概率的理论依赖性，但推导出的样本复杂度差于光滑优化的已知下界。

**Conclusion:** 在重尾噪声下，对于弱凸目标函数，香草SsGD和裁剪SsGD在理论上可以实现与光滑目标函数相似的收敛特性，尽管裁剪SsGD的样本复杂度可能存在劣势。这扩展了对随机一阶方法在更广泛问题类别中表现的理解。

> **ai_Abstract:** 本文研究了在重尾梯度噪声（包括亚Weibull噪声和有界$p$阶中心矩噪声）下，随机一阶方法在弱凸优化问题中的收敛性。针对弱凸但可能非凸非光滑的目标函数，作者分析了香草随机次梯度下降（SsGD）在亚Weibull噪声下的高概率收敛性，以及裁剪SsGD在$p$-BCM噪声下的高概率和期望收敛性。研究结果表明，香草SsGD的理论依赖性在亚Weibull噪声下与光滑情况相当，而裁剪SGD在$p$-BCM噪声下，虽然对失败概率的依赖性未受非光滑和非凸性影响，但其样本复杂度劣于光滑优化的已知下界。

> **摘要翻译:** 越来越多的研究关注重尾梯度噪声下的随机一阶方法（SFOMs），这种噪声已在实际深度学习模型的训练中被观察到。本文关注两种类型的梯度噪声：一种是亚Weibull噪声，另一种是在假设其具有有界$p$阶中心矩（$p$-BCM）且$p \in (1, 2]$的情况下产生的噪声。后者由于当$p \in (1, 2)$时出现无限方差而更具挑战性。在这两种梯度噪声假设下，SFOMs的期望收敛性和高概率收敛性已在凸优化和标准光滑优化背景下得到广泛研究。然而，对于弱凸目标函数——一类包含所有Lipschitz连续凸目标和光滑目标——我们对SFOMs在这两种噪声下的期望收敛性和高概率收敛性的理解仍不完整。我们研究了在亚Weibull噪声下香草随机次梯度下降（SsGD）方法的高概率收敛性，以及在$p$-BCM噪声下裁剪SsGD的高概率和期望收敛性。所有分析都在弱凸优化的背景下进行。对于可能是非凸和非光滑的弱凸目标函数，我们的结果表明，香草SsGD在亚Weibull噪声下对失败概率和迭代次数的理论依赖性与光滑目标函数的情况相比没有下降。在$p$-BCM噪声下，我们的发现表明，弱凸目标函数的非光滑性和非凸性不影响裁剪SGD相对于光滑情况对失败概率的理论依赖性；然而，我们推导出的样本复杂度差于光滑优化的一个已知下界。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [592] [Tensor-Tensor Products, Group Representations, and Semidefinite Programming](https://arxiv.org/abs/2507.12729)
> *张量-张量积、群表示和半定规划*

*Alex Dunbar, Elizabeth Newman* | **Category: math.OC, cs.CV, cs.NA, math.NA, math.RT, 90C22, 15A69, 65F99** | **Updated: 2025-07-17**

**Keywords:** 张量-张量积, 半定规划, 群表示, 三阶张量, 不变半定规划

**Comment:** 34 Pages, 7 figures

> **TL;DR:** 该论文将线性代数性质通过$\\star_M$-积推广到三阶张量，并将其与群表示论联系起来，以研究不变半定规划，并应用于刻画二次形式和解决张量补全问题。

**AI_Comments:** 该论文创新性地将张量积、群表示和半定规划联系起来，为将线性代数概念扩展到高阶张量，特别是不变问题，提供了一个强大的框架。其在二次形式和张量补全方面的实际应用突显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在利用$\\star_M$-积在三阶张量上的应用，研究其正半定性和半定规划，并探索其与群表示论的内在联系。

**Method:** 本文采用$\\star_M$-张量-张量积族，该框架将线性代数中的许多性质推广到三阶张量。研究的关键在于将$\\star_M$-积中矩阵M的选择与底层群作用的表示理论联系起来。此框架为研究不变半定规划提供了自然设置。

**Result:** M-SDP框架成功地表征了某些非负二次形式，并解决了低秩张量补全问题。

**Conclusion:** $\\star_M$-积框架与群表示理论相结合，为研究不变半定规划提供了自然的设置，并成功应用于二次形式的表征和张量补全问题。

> **ai_Abstract:** 本文利用$\\star_M$-积将线性代数概念推广到三阶张量，重点研究正半定性和半定规划。论文建立了$\\star_M$-积中的矩阵M与群表示理论之间的联系，为不变半定规划提供了一个框架。其应用包括表征非负二次形式和解决低秩张量补全问题。

> **摘要翻译:** $\\star_M$-张量-张量积族是一个将线性代数中的许多性质推广到三阶张量的框架。本文中，我们研究了在$\\star_M$-积下的正半定性和半定规划。我们研究的关键是$\\star_M$-积中矩阵M的选择与底层群作用的表示理论之间的联系。利用这个框架，配备了$\\star_M$-积的三阶张量是研究不变半定规划的自然设置。作为M-SDP框架的应用，我们提供了某些非负二次形式的表征，并解决了低秩张量补全问题。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [608] [A column generation algorithm with dynamic constraint aggregation for minimum sum-of-squares clustering](https://arxiv.org/abs/2410.06187)
> *一种用于最小平方和聚类的动态约束聚合列生成算法*

*Antonio M. Sudoso, Daniel Aloise* | **Category: math.OC, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 最小平方和聚类, k-均值聚类, 列生成, 动态约束聚合, 精确求解

**Comment:** 

> **TL;DR:** 本文提出了一种结合列生成和动态约束聚合的新算法，用于高效解决大规模最小平方和聚类问题（k-均值聚类），并显著优于现有最先进的精确方法。

**AI_Comments:** 该论文的创新点在于将动态约束聚合（DCA）这一技术引入到列生成（CG）算法中，以解决大规模最小平方和聚类（MSSC）问题。DCA最初用于减少集合划分问题中的退化，将其应用于MSSC的精确求解是一个新颖的尝试。通过有效减少CG主问题的约束数量，该方法显著提升了大规模MSSC实例的求解效率，并超越了现有最先进的精确方法，这对于处理大数据集下的聚类问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最小平方和聚类问题（MSSC），即k-均值聚类，在处理大规模实例时效率低下。本文旨在开发一种高效算法来解决大规模MSSC实例。

**Method:** 本文提出了一种结合列生成（CG）与动态约束聚合（DCA）的算法。DCA用于有效减少CG主问题中考虑的约束数量。作者探索了DCA在MSSC精确求解中的应用，并通过一系列关于DCA设计选择的消融研究对方法进行了微调。

**Result:** 该方法在解决大规模MSSC实例时，显著优于现有文献中可用的最先进的精确方法。

**Conclusion:** 结合列生成和动态约束聚合的算法能够高效地解决大规模最小平方和聚类问题，并取得了超越现有精确方法的性能。

> **ai_Abstract:** 本文提出了一种结合列生成（CG）和动态约束聚合（DCA）的新型算法，旨在高效解决大规模最小平方和聚类问题（MSSC，即k-均值聚类）。该方法利用DCA来减少CG主问题中的约束数量，并通过消融研究进行了优化。实验结果表明，该算法在处理大规模MSSC实例时，性能显著优于现有的精确求解方法。

> **摘要翻译:** 最小平方和聚类问题（MSSC），也称为k-均值聚类，是指将n个数据点划分为k个簇的问题，目标是最小化每个点与其分配簇中心之间的欧几里得距离平方总和。我们提出了一种用于解决大规模MSSC实例的高效算法，该算法结合了列生成（CG）与动态约束聚合（DCA），以有效减少CG主问题中考虑的约束数量。DCA最初是为了通过利用从集合划分约束划分为不相交簇获得的聚合受限主问题来减少集合划分问题中的退化而构思的。在这项工作中，我们探索了在CG算法中使用DCA进行MSSC精确求解。我们的方法通过一系列关于DCA设计选择的消融研究进行了微调，并被证明显著优于现有文献中可用的最先进的精确方法。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstat-mech'></a>
## cond-mat.stat-mech 

### [82] [Partial decidability protocol for the Wang tiling problem from statistical mechanics and chaotic mapping](https://arxiv.org/abs/2507.13268)
> *基于统计力学和混沌映射的Wang平铺问题部分可判定性协议*

*Fabrizio Canfora, Marco Cedeno* | **Category: cond-mat.stat-mech, cs.IT, hep-th, math.IT, math.LO** | **Updated: 2025-07-17**

**Keywords:** Wang平铺问题, 部分可判定性, 统计力学, 混沌映射, 熵, Kendall Tau系数

**Comment:** 22 pages, 24 figures

> **TL;DR:** 本文提出了一种Wang平铺问题的部分可判定性协议，通过将平铺映射到统计力学和混沌系统，并识别可以平铺平面的“良好字母表”。

**AI_Comments:** 该论文通过将组合学与统计力学和混沌动力学相结合，为解决一个不可判定问题提供了一种创新方法。利用熵、温度和Kendall Tau系数分析瓦片集，提供了一个新颖的视角。其与混沌系统的联系为理解可判定性增添了引人入胜的维度。识别“良好字母表”的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Wang平铺问题是组合学和统计物理学中不可判定问题的原型。本研究旨在为其引入一个部分可判定性协议。

**Method:** 通过构建从不同大小的有限正方形平铺到平铺的映射，为Wang瓦片字母表定义了有效熵和温度。通过观察当给定字母表的熵和温度在热力学意义上表现良好时，该字母表可以平铺无限二维平面，从而识别出了一类良好的字母表。该提议已成功地用已知的良好字母表进行了测试。分析表明，Kendall Tau系数能够区分具有良好热力学行为的字母表和具有不良热力学行为的字母表。从良好行为到不可判定行为的转变与Logistic型离散动力系统中从非混沌到混沌状态的转变有关。

**Result:** 引入了一种用于Wang平铺问题的部分可判定性协议。当字母表的熵和温度在热力学意义上表现良好时，它们可以平铺无限二维平面，从而被识别为“良好字母表”。该协议已成功地用已知的良好字母表进行了测试，包括产生周期性、非周期性但自相似以及既非周期性也非自相似平铺的字母表。Kendall Tau系数能够区分具有良好热力学行为的字母表和具有不良热力学行为的字母表。从良好行为到不可判定行为的转变与Logistic型离散动力系统中从非混沌到混沌状态的转变有关。

**Conclusion:** 本文成功引入了一种Wang平铺问题的部分可判定性协议，将问题的可判定性与热力学性质和混沌动力学联系起来，并提供了一种区分良好字母表的方法。

> **ai_Abstract:** 本文提出了一种用于不可判定Wang平铺问题的部分可判定性协议。通过将有限正方形平铺映射到统计力学概念，该协议为瓦片字母表定义了有效熵和温度。研究识别出具有良好热力学性质的“良好字母表”，这些字母表能够平铺无限平面。该协议已成功通过各种已知良好字母表的测试，并发现Kendall Tau系数能够区分瓦片的热力学行为，将不可判定性的转变与离散动力系统中从非混沌到混沌状态的转变联系起来。

> **摘要翻译:** 我们引入了一种用于Wang平铺问题（组合学和统计物理学中不可判定问题的原型）的部分可判定性协议，通过构建从不同大小的有限正方形平铺到平铺的适当映射。这种映射取决于初始的Wang瓦片族（字母表），用其可以平铺平面。这使得可以定义与字母表相关的有效熵和温度（以及相应的配分函数）。我们通过观察当给定字母表的熵和温度在热力学意义上表现良好时，该字母表可以平铺无限二维平面，从而识别出了一类良好的字母表。我们的提议已成功地用已知的良好字母表进行了测试（这些字母表产生周期性平铺、非周期性但自相似平铺以及既非周期性也非自相似平铺）。我们的分析表明，Kendall Tau系数能够区分具有良好热力学行为的字母表和具有不良热力学行为的字母表。从良好行为到不可判定行为的转变与Logistic型离散动力系统中从非混沌到混沌状态的转变有关。

</details>

[⬆️ 返回分类顶部](#cond-matstat-mech) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [101] [Efficient Classical-Processing of Constant-Depth Time Evolution Circuits in Control Hardware](https://arxiv.org/abs/2507.12765)
> *控制硬件中恒定深度时间演化电路的高效经典处理*

*Akhil Francis, Abhi D. Rajagopala, Norm M. Tubman, Katherine Klymko, Kasra Nowrouzi* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-17**

**Keywords:** 经典处理, 参数化电路执行, 时间演化电路, 量子算法, 硬件辅助

**Comment:** 

> **TL;DR:** 本文通过硬件辅助参数化电路执行（PCE）来优化量子算法的经典处理和编译时间，实现了高达50%的运行时缩减。

**AI_Comments:** 该论文的创新点在于将硬件辅助参数化电路执行（PCE）应用于时间演化电路，以解决量子算法中经典的瓶颈问题。通过利用电路的结构等效性，实现了显著的运行时性能提升。这项工作对于推动近期量子计算的发展具有重要意义，尤其是在需要频繁经典处理的量子模拟领域。

<details>
  <summary>Details</summary>

**Motivation:** 提高量子算法的运行时性能是当前研究的重点之一。具体来说，本研究旨在通过优化经典处理来减少经典处理和编译时间，以加速量子系统的动态属性计算。

**Method:** 本研究采用硬件辅助参数化电路执行（PCE）方法，利用结构等效电路来计算量子多体系统的动态特性。具体地，通过Cartan分解生成恒定深度时间演化电路，并将其应用于计算自旋模型的关联函数。

**Result:** 在横场XY模型（最多6个位点）和海森堡自旋模型（最多3个位点）中，计算自旋-自旋关联函数时，与标准编译方法相比，观察到运行时缩减高达50%。

**Conclusion:** 硬件辅助PCE的时间演化电路具有良好的适应性，能够有效缓解近期量子算法中的经典瓶颈问题。

> **ai_Abstract:** 本研究提出了一种通过硬件辅助参数化电路执行（PCE）来优化量子算法经典处理的方法。通过利用结构等效的时间演化电路，该方法显著减少了计算量子系统动态属性所需的经典处理和编译时间。实验结果表明，在自旋模型中计算关联函数时，与传统编译方法相比，运行时性能提升高达50%，这表明PCE在缓解近期量子算法经典瓶颈方面的巨大潜力。

> **摘要翻译:** 提高量子算法的运行时性能涉及多种策略，例如减少量子门计数、减少测量次数、改进QPU技术以实现更快的门操作，或优化经典处理。这项工作专注于后者，具体是通过硬件辅助参数化电路执行（PCE）来减少经典处理和编译时间，用于计算量子系统的动态特性。PCE先前已通过QCVV协议验证，该协议利用结构电路等效性。我们展示了这种方法在计算量子多体系统动态特性方面的适用性，使用结构等效的时间演化电路，特别是通过Cartan分解生成的恒定深度电路来计算自旋模型的关联函数。在横场XY模型（最多6个位点）和海森堡自旋模型（最多3个位点）中实现自旋-自旋关联函数时，与标准编译方法相比，我们观察到运行时缩减高达50%。这突出了时间演化电路与硬件辅助PCE的适应性，有望缓解近期量子算法中的经典瓶颈。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [176] [Utility-Scale Quantum Computation of Ground-State Energy in a 100+ Site Planar Kagome Antiferromagnet via Hamiltonian Engineering](https://arxiv.org/abs/2507.06361)
> *通过哈密顿量工程对100+位点平面Kagome反铁磁体进行实用级量子计算基态能量*

*Muhammad Ahsan* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-17**

**Keywords:** 量子计算, Kagome反铁磁体, 变分量子本征求解器, 哈密顿量工程, 可扩展性

**Comment:** National Center for Quantum Computing, UET Lahore, Pakistan

> **TL;DR:** 在IBM Heron处理器上，通过哈密顿量工程和混合VQE方法，成功对103位点Kagome反铁磁体进行了实用级量子计算，估算了其基态能量，并展示了VQE在受挫二维系统中的可扩展性。

**AI_Comments:** 该研究的创新之处在于，它展示了在100多个位点的系统上进行实用级量子计算的能力，特别是对于像Kagome晶格这样的受挫二维系统。哈密顿量工程策略是关键的创新点，它能够在保持精度的同时简化ansatz，这对于当前的噪声中尺度量子（NISQ）设备至关重要。混合VQE方法也有助于高效的硬件利用。这项工作代表了在复杂材料的实际量子模拟方面迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 在实用级量子处理器上展示变分量子本征求解器（VQE）在受挫二维系统中的可扩展性，并为未来研究奠定基础。

**Method:** 该研究使用IBM的Heron r1和Heron r2量子处理器，采用了一种混合方法，将传统的变分量子本征求解器（VQE）分解为局部（经典）和全局（量子）组件。更重要的是，引入了一种哈密顿量工程策略，通过增加缺陷三角形上的耦合来模拟环翻转动力学，从而简化了ansatz并保持了计算精度。使用单次重复的硬件高效ansatz，实现了高达103个量子位的纠缠。

**Result:** 研究估算了103位点平面Kagome反铁磁体（KAFH）的每位点基态能量为-0.417 J，在开边界校正后与热力学极限能量-0.4386 J相匹配。成功地以高保真度纠缠了多达103个量子位。

**Conclusion:** 这项工作展示了变分量子本征求解器（VQE）在受挫二维系统中的可扩展性，并为未来在实用级量子处理器上使用更深层ansatz电路和更大晶格的研究奠定了基础。

> **ai_Abstract:** 本文利用IBM的Heron量子处理器，实验性地计算了103位点Kagome反铁磁体的基态能量。研究采用了一种混合变分量子本征求解器（VQE）方法，并结合了一种新颖的哈密顿量工程策略，以简化ansatz并保持计算精度。估算的每位点基态能量与热力学极限值相匹配。这项工作展示了VQE在受挫二维系统中的可扩展性，并为未来在更大、更复杂系统上的量子计算研究奠定了基础。

> **摘要翻译:** 我们利用IBM的Heron r1和Heron r2量子处理器，对一个103位点的平面Kagome晶格在反铁磁海森堡模型（KAFH）下的基态能量进行了实验性量子计算。对于自旋1/2的KAFH，我们估算的每位点基态能量为-0.417 J，在开边界校正后，这与热力学极限下的能量（即-0.4386 J）相匹配。为了实现这一目标，我们采用了一种混合方法，将传统的变分量子本征求解器（VQE）分解为局部（经典）和全局（量子）组件，以实现高效的硬件利用。更重要的是，我们引入了一种哈密顿量工程策略，通过增加缺陷三角形上的耦合来模拟环翻转动力学，从而简化了ansatz并保持了计算精度。我们使用单次重复的硬件高效ansatz，以高保真度纠缠了多达103个量子位，以确定哈密顿量的最低本征值。这项工作展示了VQE在受挫二维系统中的可扩展性，并为未来在实用级量子处理器上使用更深层ansatz电路和更大晶格的研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [275] [K-P Quantum Neural Networks](https://arxiv.org/abs/2504.01673)
> *K-P 量子神经网络*

*Elija Perrier* | **Category: quant-ph, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 量子神经网络, K-P控制, Cartan分解, 等变量子神经网络, 时间最优控制

**Comment:** Accepted for publication GSI 2025

> **TL;DR:** 论文将Cartan方法整合到等变量子神经网络（EQNN）中，用于K-P时间最优量子控制，并证明其能复制测地线，且梯度训练可收敛到最优解，推广了几何控制理论。

**AI_Comments:** 这篇论文的创新之处在于将Cartan几何方法与等变量子神经网络相结合，为时间最优量子控制提供了新的理论框架和计算方法。它将抽象的几何控制理论与实用的量子机器学习模型连接起来，展示了在量子计算中实现精确控制的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在扩展K-P时间最优量子控制解决方案，并通过量子机器学习方法实现最优测地线估计。

**Method:** 论文通过使用全局Cartan $KAK$ 分解来扩展K-P时间最优量子控制解决方案，并将Cartan方法集成到等变量子神经网络（EQNN）中，利用有限深度的EQNN ansatz和Cartan层来复制常数-$\\theta$ 次黎曼测地线，并使用基于梯度的训练方法。

**Result:** 证明了带有Cartan层的有限深度EQNN ansatz可以复制K-P问题的常数-$\\theta$ 次黎曼测地线。对于黎曼对称空间上的特定控制问题，在满足简单正则性条件时，使用适当成本函数的基于梯度的训练方法可以收敛到全局时间最优解。

**Conclusion:** 该方法推广了先前的几何控制理论，并阐明了如何在量子机器学习背景下进行最优测地线估计。

> **ai_Abstract:** 这篇论文介绍了一种扩展K-P时间最优量子控制解决方案的方法，通过将Cartan分解和Cartan方法整合到等变量子神经网络（EQNN）中。研究表明，带有Cartan层的EQNN能够复制K-P问题的次黎曼测地线，并且在特定条件下，基于梯度的训练可以收敛到全局时间最优解。这项工作推广了几何控制理论，并为量子机器学习中的最优测地线估计提供了新视角。

> **摘要翻译:** 我们提出了K-P时间最优量子控制解决方案的扩展，该方案使用全局Cartan $KAK$ 分解进行基于测地线的解决方案。在扩展近期时间最优常数-$\\theta$ 控制结果的基础上，我们将Cartan方法整合到等变量子神经网络（EQNN）中，用于量子控制任务。我们展示了配备Cartan层的有限深度限制EQNN ansatz可以复制K-P问题的常数-$\\theta$ 次黎曼测地线。我们演示了对于黎曼对称空间上某些类别的控制问题，当满足简单的正则性条件时，使用适当成本函数的基于梯度的训练可以收敛到某些全局时间最优解。这推广了先前的几何控制理论方法，并阐明了如何在量子机器学习背景下进行最优测地线估计。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [454] [Quantum Transfer Learning to Boost Dementia Detection](https://arxiv.org/abs/2507.12485)
> *量子迁移学习助力痴呆症检测*

*Sounak Bhowmik, Talita Perciano, Himanshu Thapliyal* | **Category: quant-ph, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 量子迁移学习, 痴呆症检测, 生物医学图像分类, 深度学习, 量子机器学习

**Comment:** 

> **TL;DR:** 本文展示了量子迁移学习（QTL）如何提升一个弱经典深度学习模型在痴呆症二分类任务上的性能，并探讨了噪声的影响，表明量子技术在生物医学图像分类中的潜力。

**AI_Comments:** 这篇论文的创新之处在于将量子迁移学习应用于痴呆症的早期检测，这在应对传统机器学习处理高维生物医学数据时遇到的计算和性能瓶颈方面具有重要意义。通过将量子技术与经典深度学习模型结合，它提供了一个潜在的解决方案来提高诊断的准确性和效率。此外，对噪声影响的探讨增加了该方法鲁棒性的考量，提升了研究的实用价值。这项工作为量子计算在医疗保健领域的应用开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 痴呆症的早期准确检测至关重要，但传统的机器学习和深度学习方法在处理高维生物医学数据和大规模数据集时，常面临计算和性能瓶制。为解决这些挑战，量子机器学习（QML）作为一种有前景的范式出现，具有更快的训练速度和先进的模式识别能力。

**Method:** 本研究旨在通过量子迁移学习（QTL）来提升一个弱经典深度学习模型在痴呆症检测的二分类任务上的性能。此外，研究还展示了噪声对基于QTL方法的影响，以调查该方法的可靠性和鲁棒性。研究使用了OASIS 2数据集。

**Result:** 研究表明，量子技术可以将一个次优的经典模型转化为更有效的生物医学图像分类解决方案。

**Conclusion:** 量子技术在提升医疗保健技术方面具有潜在影响，尤其是在生物医学图像分类领域。

> **ai_Abstract:** 本研究探讨了量子迁移学习（QTL）在增强痴呆症检测方面一个弱经典深度学习模型性能的潜力。针对经典机器学习在处理高维生物医学数据时的局限性，论文提出使用QTL，并利用OASIS 2数据集进行验证。研究还分析了噪声对QTL方法的影响，结果表明量子技术能够显著提升次优经典模型的分类效果，展现了其在生物医学图像分类和医疗技术发展中的应用前景。

> **摘要翻译:** 痴呆症是一种毁灭性的疾病，对个体、家庭和医疗系统都有深远的影响。早期准确地检测痴呆症对于及时干预和改善患者预后至关重要。尽管经典的机器学习和深度学习方法在痴呆症预测方面已被广泛探索，但这些解决方案在处理高维生物医学数据和大规模数据集时，常常面临计算和性能限制。为了解决这一挑战，量子机器学习（QML）作为一种有前景的范式出现，提供了更快的训练速度和先进的模式识别能力。这项工作旨在展示量子迁移学习（QTL）的潜力，以增强应用于痴呆症检测二分类任务的弱经典深度学习模型的性能。此外，我们展示了噪声对基于QTL方法的影响，调查了该方法的可靠性和鲁棒性。使用OASIS 2数据集，我们展示了量子技术如何将一个次优的经典模型转化为更有效的生物医学图像分类解决方案，突显了它们在推进医疗保健技术方面的潜在影响。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [472] [Leveraging Quantum Superposition to Infer the Dynamic Behavior of a Spatial-Temporal Neural Network Signaling Model](https://arxiv.org/abs/2403.18963)
> *利用量子叠加推断时空神经网络信号模型的动态行为*

*Gabriel A. Silva* | **Category: quant-ph, cs.AI, q-bio.NC** | **Updated: 2025-07-16**

**Keywords:** 量子计算, 神经网络, 网络动态, 量子叠加

**Comment:** 36 pages, 4 figures. See
  https://github.com/gabe-alex-silva/Network_Dynamics_QuantumSim/tree/main for
  code details

> **TL;DR:** 本文利用扩展的Grover和Deutsch-Jozsa量子算法，通过量子叠加高效推断大规模神经网络的动态行为，判断其能否维持活动或最终停止。

**AI_Comments:** 本文的创新之处在于将现有的量子算法（Grover和Deutsch-Jozsa）进行扩展和耦合，以解决网络动态中的一个特定复杂问题，从而将量子计算与神经生物学和机器学习相结合。这展示了一种利用量子叠加推断复杂系统行为的新颖方式。

<details>
  <summary>Details</summary>

**Motivation:** 探索量子计算的新问题类别，特别是解决与神经生物学和机器学习相关的大规模网络动态行为问题，即网络能否在任意观察时间后维持固有动态活动或停止。

**Method:** 将问题公式化并结构化以利用量子叠加，通过Grover和Deutsch-Jozsa量子算法的耦合工作流高效解决。扩展了这些算法的功能，以满足输入（子）集的数学结构要求，并使测量输出能被解释为网络动态的有意义属性。

**Result:** 展示了这类问题可以被公式化并利用所提出的量子方法高效解决，从而能够回答关于网络动态行为的问题。

**Conclusion:** 通过扩展和耦合Grover和Deutsch-Jozsa量子算法，可以高效推断大规模时空神经网络的动态行为（是维持活动还是停止）。

> **ai_Abstract:** 本文提出了一种利用量子计算分析大规模时空神经网络长期动态行为的新方法。它将问题设计为利用量子叠加，并使用Grover和Deutsch-Jozsa算法的扩展耦合工作流，高效确定网络活动是否随时间持续或停止。该方法允许将量子测量输出有意义地解释为网络动态属性。

> **摘要翻译:** 量子计算新问题类别的探索是一个活跃的研究领域。在本文中，我们介绍并解决了一个与神经生物学和机器学习相关的大规模网络动态行为的新问题类别。具体来说，我们探讨了一个网络是否能在某个任意观察时间之后维持固有的动态活动，或者活动是否会通过静止或类似癫痫的状态饱和而停止。我们表明，这类问题可以被公式化和结构化，以利用量子叠加，并通过Grover和Deutsch-Jozsa量子算法之间的耦合工作流高效解决。为此，我们扩展了它们的功能，以解决算法输入（子）集必须在数学上如何结构化的独特要求，同时构建输入，使得测量输出可以被解释为网络动态的有意义的属性。这反过来使我们能够回答我们提出的问题。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [505] [Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise](https://arxiv.org/abs/2507.12492)
> *量子环境下应对量子噪声的稀疏联邦学习方法*

*Ratun Rahman, Atit Pokharel, Dinh C. Nguyen* | **Category: quant-ph, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 量子联邦学习, 量子噪声, 稀疏学习, 分布式量子系统, 模型鲁棒性

**Comment:** 

> **TL;DR:** SpoQFL利用稀疏学习来应对量子联邦学习中的量子噪声，显著提升了训练性能和收敛稳定性。

**AI_Comments:** 该论文的创新点在于提出了SpoQFL框架，通过引入稀疏学习来动态应对量子联邦学习中异构的量子噪声。这种方法为提高量子设备在分布式学习环境中的训练性能和稳定性提供了一个实用的解决方案，对于推动量子机器学习的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子联邦学习（QFL）中的量子噪声具有异构性，导致训练性能不足，是其发展的一个重要障碍。

**Method:** 提出了一种名为SpoQFL的新型量子联邦学习框架，该框架利用稀疏学习来减轻分布式量子系统中的量子噪声异构性。SpoQFL根据噪声波动动态调整训练策略。

**Result:** 在真实世界数据集上的大量实验表明，SpoQFL显著优于传统的QFL方法，实现了卓越的训练性能和更稳定的收敛。

**Conclusion:** SpoQFL通过动态调整训练策略，有效缓解了量子噪声异构性，从而显著提高了量子联邦学习的性能和稳定性。

> **ai_Abstract:** 本文提出了一种名为SpoQFL的新型量子联邦学习（QFL）框架，旨在解决现代量子设备中异构量子噪声导致的训练性能不足问题。SpoQFL利用稀疏学习，并根据噪声波动动态调整训练策略，从而增强模型鲁棒性、收敛稳定性和学习效率。实验结果表明，SpoQFL在训练性能和收敛稳定性方面显著优于传统QFL方法。

> **摘要翻译:** 量子联邦学习（QFL）是一种新兴范式，它结合了量子计算和联邦学习（FL），以实现在量子网络上保持数据隐私的去中心化模型训练。然而，量子噪声仍然是QFL的一个重要障碍，因为现代量子设备由于硬件质量的差异和对量子退相干的敏感性而经历异构的噪声水平，导致训练性能不足。为了解决这个问题，我们提出了SpoQFL，一个新颖的QFL框架，它利用稀疏学习来减轻分布式量子系统中的量子噪声异构性。SpoQFL根据噪声波动动态调整训练策略，增强了模型的鲁棒性、收敛稳定性和整体学习效率。在真实世界数据集上的大量实验表明，SpoQFL显著优于传统的QFL方法，实现了卓越的训练性能和更稳定的收敛。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [578] [Quantum HyperNetworks: Training Binary Neural Networks in Quantum Superposition](https://arxiv.org/abs/2301.08292)
> *量子超网络：在量子叠加态中训练二值神经网络*

*Juan Carrasquilla, Mohamed Hibat-Allah, Estelle Inack, Alireza Makhzani, Kirill Neklyudov, Graham W. Taylor, Giacomo Torlai* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 量子超网络, 二值神经网络, 量子计算, 组合优化, 变分量子电路

**Comment:** 15 pages, 12 figures including appendices. Minimal implementation:
  https://github.com/carrasqu/binncode

> **TL;DR:** 本文提出量子超网络，利用量子计算机在单一优化循环中训练二值神经网络，并同时优化参数、超参数和架构。

**AI_Comments:** 这篇论文的创新点在于将量子计算应用于二值神经网络的训练，通过量子超网络实现参数、超参数和架构的统一优化。这有望解决传统二值神经网络训练中的组合优化难题，为资源受限设备上的深度学习部署提供新的途径。其潜在影响是巨大的，可能促进量子机器学习的发展。

<details>
  <summary>Details</summary>

**Motivation:** 二值神经网络虽然适用于资源受限设备，但其训练、架构设计和超参数调优涉及计算昂贵的组合优化问题，因此具有挑战性。

**Method:** 引入量子超网络，作为在量子计算机上训练二值神经网络的机制。它将参数、超参数和架构的搜索统一到一个单一的优化循环中。量子超网络被表示为变分量子电路。

**Result:** 通过经典模拟，证明该方法能以高概率有效找到高斯数据集和MNIST手写数字数据集上分类问题的最优参数、超参数和架构选择。发现最优电路深度能最大化找到高性能二值神经网络的概率。

**Conclusion:** 量子超网络提供了一种在量子计算机上训练二值神经网络的统一方法，并为机器学习领域的其他应用提供了巨大的潜力。

> **ai_Abstract:** 本文提出量子超网络，一种利用量子计算机训练二值神经网络的新机制，旨在解决二值神经网络训练、架构设计和超参数调优中的组合优化难题。该方法将所有优化任务整合到一个单一的量子优化循环中。通过经典模拟，研究人员证明了该方法在分类任务上能有效找到最优配置，并发现存在一个最优的变分量子电路深度。

> **摘要翻译:** 二值神经网络，即参数和激活值被限制为仅有两个可能值的神经网络，为在能量和内存受限设备上部署深度学习模型提供了一条引人注目的途径。然而，它们的训练、架构设计和超参数调优仍然具有挑战性，因为这些都涉及到多个计算成本高昂的组合优化问题。本文引入量子超网络作为在量子计算机上训练二值神经网络的机制，它将参数、超参数和架构的搜索统一到一个单一的优化循环中。通过经典模拟，我们证明了我们的方法能以高概率有效找到分类问题（包括二维高斯数据集和MNIST手写数字的缩小版）上的最优参数、超参数和架构选择。我们将量子超网络表示为变分量子电路，并发现最优电路深度能最大化找到高性能二值神经网络的概率。我们的统一方法为机器学习领域的其他应用提供了巨大的潜力。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [579] [Comparing One- and Two-way Quantum Repeater Architectures](https://arxiv.org/abs/2409.06152)
> *比较单向和双向量子中继器架构*

*Prateek Mantri, Kenneth Goodenough, Don Towsley* | **Category: quant-ph, cs.NI** | **Updated: 2025-07-16**

**Keywords:** 量子中继器, 单向架构, 双向架构, 多路复用, 纠缠蒸馏

**Comment:** 25 pages, 7 figures

> **TL;DR:** 本文比较了单向和双向量子中继器架构，提出了一种新的双向协议，结合了多路复用和应用感知蒸馏，并发现该双向架构在性能上优于单向协议，同时需要更低的技术和资源开销。

**AI_Comments:** 这篇论文的创新之处在于提出了一种结合多路复用和应用感知蒸馏的新型双向量子中继器协议，并提供了一个新的分析框架来评估其性能。其重要性在于挑战了先前关于单向中继器在某些参数下更优的观点，并证明了在现代硬件条件下双向架构的优越性，这对于未来大规模量子网络部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于存储可用性增加和多路复用纠缠生成技术的进步，需要对单向和双向中继器架构进行新的比较。

**Method:** 提出了一种结合多路复用和应用感知蒸馏的双向中继器协议，适用于高质量内存资源充足的环境。引入了递归公式来跟踪多路复用双向中继器架构中贝尔对的完整概率分布，以分析使用概率性n-to-k蒸馏的多路复用中继器方案的性能。

**Result:** 在以前认为有利于单向方案的参数范围内，所提出的双向协议始终优于单向协议，同时需要更低的技术和资源开销。

**Conclusion:** 双向量子中继器架构在性能上优于单向协议，并且在技术和资源开销方面更低。

> **ai_Abstract:** 本文旨在比较单向和双向量子中继器架构，以应对量子信息在长距离传输中的损耗和错误问题。研究人员提出了一种新的双向中继器协议，该协议结合了多路复用和应用感知蒸馏，并设计用于内存资源充足的环境。通过引入递归公式来分析多路复用双向中继器中贝尔对的分布，研究发现所提出的双向架构在性能上始终优于单向协议，并且在技术和资源开销方面具有优势，即使在传统上认为单向方案更有利的参数范围内也是如此。

> **摘要翻译:** 量子中继器是实现远距离量子通信的重要组成部分。然而，由于量子信息的脆弱性，这些中继器会受到损耗和操作错误的影响。以前的工作根据其使用概率性或近确定性方法来缓解这些错误，将中继器分为三大类。除了经典通信时间的差异外，这些方法在技术复杂性上也各不相同，近确定性方法需要更先进的硬件。最近存储可用性的增加和多路复用纠缠生成技术的进步，促使对单向和双向中继器架构进行新的比较。
在这项工作中，我们提出了一种双向中继器协议，该协议将多路复用与应用感知蒸馏相结合，专为高质量内存资源充足的环境而设计——这反映了大规模网络部署中预期的架构假设。我们引入了一个递归公式来跟踪多路复用双向中继器架构中贝尔对的完整概率分布，从而能够对使用概率性n-to-k蒸馏的多路复用中继器方案进行性能分析。利用这个框架，我们将所提出的双向协议与单向方案在以前认为有利于后者的参数范围内进行比较，发现双向架构始终优于单向协议，同时需要更低的技术和资源开销。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [598] [Quantum Long Short-Term Memory for Drug Discovery](https://arxiv.org/abs/2407.19852)
> *用于药物发现的量子长短期记忆网络*

*Liang Zhang, Yin Xu, Mohan Wu, Liang Wang, Hua Xu* | **Category: quant-ph, cs.LG, q-bio.BM** | **Updated: 2025-07-17**

**Keywords:** 量子长短期记忆网络, 药物发现, 量子机器学习, 噪声鲁棒性, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了量子长短期记忆网络（QLSTM），一种量子机器学习架构，并在药物发现任务中展示了其优于经典LSTM的性能，包括更高的准确性、更快的收敛速度和对噪声的鲁棒性。

**AI_Comments:** 本文创新性地将量子计算与长短期记忆网络结合，提出了QLSTM模型，并将其应用于药物发现领域。其重要性在于，QLSTM不仅在性能上超越了经典LSTM，还在量子硬件固有的噪声环境下展现出强大的鲁棒性，这对于未来量子机器学习的实际应用具有重要意义。该研究为量子机器学习在复杂科学问题（如药物发现）中的应用提供了新的方向和潜力，尤其是在量子硬件仍在发展阶段时，其抗噪声特性尤为关键。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算与机器学习的结合是一个极具前景的研究领域，量子机器学习（QML）有望比经典机器学习更有效地解决科学问题。

**Method:** 本文提出了一种量子机器学习架构——量子长短期记忆网络（QLSTM），并在BBBP、BACE、SIDER、BCAP37、T-47D这五个基准数据集上对其进行了评估。

**Result:** QLSTM在经典LSTM上取得了持续的性能提升，ROC-AUC提高了3%到6%以上。随着量子比特数的增加，QLSTM的预测精度有所提高。在相同的训练条件下，QLSTM比经典LSTM收敛更快。QLSTM对量子计算机噪声表现出强大的鲁棒性，在某些设置下甚至优于无噪声的经典LSTM。

**Conclusion:** 这些发现突出了QLSTM作为一种可扩展且抗噪声模型在科学应用中的潜力，特别是随着量子硬件在量子比特容量和保真度方面的不断进步。

> **ai_Abstract:** 本文提出了一种名为量子长短期记忆网络（QLSTM）的量子机器学习架构，并验证了其在药物发现领域的有效性。通过在五个基准数据集上的评估，QLSTM在ROC-AUC方面显示出比经典LSTM 3%至6%的性能提升。研究还发现，QLSTM的预测精度随量子比特数增加而提高，收敛速度更快，并对量子计算机噪声具有显著的鲁棒性。这些结果表明QLSTM是一种有潜力的、可扩展且抗噪声的科学应用模型，尤其适用于药物发现。

> **摘要翻译:** 量子计算与机器学习（ML）相结合是一个极具前景的研究领域，大量研究表明量子机器学习（QML）有望比经典ML更有效地解决科学问题。在这项工作中，我们提出了量子长短期记忆网络（QLSTM），一种QML架构，并展示了其在药物发现中的有效性。我们在五个基准数据集（BBBP、BACE、SIDER、BCAP37、T-47D）上评估了QLSTM，观察到其相对于经典LSTM具有持续的性能提升，ROC-AUC改进范围从3%到6%以上。此外，随着量子比特数的增加，QLSTM表现出更高的预测精度，并且在相同的训练条件下比经典LSTM收敛更快。值得注意的是，QLSTM对量子计算机噪声保持了强大的鲁棒性，在某些设置下甚至优于无噪声的经典LSTM。这些发现突出了QLSTM作为一种可扩展且抗噪声模型在科学应用中的潜力，特别是随着量子硬件在量子比特容量和保真度方面的不断进步。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [623] [Cross-Problem Parameter Transfer in Quantum Approximate Optimization Algorithm: A Machine Learning Approach](https://arxiv.org/abs/2504.10733)
> *量子近似优化算法中的跨问题参数迁移：一种机器学习方法*

*Kien X. Nguyen, Bao Bach, Ilya Safro* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 量子近似优化算法, 参数迁移, 机器学习, 组合优化, MaxCut, 最大独立集

**Comment:** 

> **TL;DR:** 本文研究了如何将量子近似优化算法（QAOA）中针对一个问题（如MaxCut）优化的参数迁移到另一个问题（如最大独立集MIS）中，结果表明这可以显著减少优化迭代次数。

**AI_Comments:** 这项研究的创新之处在于，它将机器学习方法引入到QAOA参数优化中，并首次探索了跨问题类型（MaxCut到MIS）的参数迁移。这对于克服QAOA中“贫瘠高原”等挑战，提高算法效率具有重要意义。该方法有望加速QAOA在更复杂组合优化问题上的应用，为实现量子优势提供了一条实用路径。

<details>
  <summary>Details</summary>

**Motivation:** 量子近似优化算法（QAOA）在解决组合优化问题方面具有潜力，但寻找良好的变分参数集是一个挑战，存在“贫瘠高原”等问题。因此，利用参数可迁移性来加速优化过程并减轻性能缺陷变得越来越重要，特别是探索从一类问题向另一类问题迁移参数的可能性。

**Method:** 本文研究了是否可以将预训练的MaxCut QAOA参数直接使用或作为热启动应用于最大独立集（MIS）电路。具体而言，作者设计了机器学习模型来寻找在MaxCut上优化的良好“捐赠者”候选，并将其参数应用于MIS“接受者”。

**Result:** 实验结果表明，这种参数迁移可以显著减少所需的优化迭代次数，同时实现可比较的近似比。

**Conclusion:** 研究表明，通过机器学习方法将量子近似优化算法的参数从一类问题（如MaxCut）迁移到另一类问题（如MIS）是可行且有效的，能够提高优化效率。

> **ai_Abstract:** 本文探讨了量子近似优化算法（QAOA）中跨问题参数迁移的可行性，旨在解决参数优化困难的问题。研究人员利用机器学习方法，将针对MaxCut问题优化的QAOA参数迁移到最大独立集（MIS）问题中。实验结果表明，这种参数迁移策略能显著减少优化迭代次数，同时保持相近的近似比，为QAOA的实际应用提供了新的优化途径。

> **摘要翻译:** 量子近似优化算法（QAOA）是实现量子优势解决组合优化问题最有希望的候选算法之一。由于贫瘠高原等多种因素，在QAOA电路中找到一组好的变分参数已被证明具有挑战性。因此，人们对利用参数可迁移性越来越感兴趣，即将针对一个问题实例优化的参数集迁移到另一个可能更复杂的问题实例，以估计解决方案或作为进一步优化的热启动。但是，我们能否将参数从一类问题迁移到另一类问题呢？利用从一个研究充分的问题类别中学到的参数集可以帮助探索研究较少的问题，从而减少优化开销并减轻性能缺陷。在本文中，我们研究了MaxCut的预训练QAOA参数是否可以直接使用或作为热启动应用于最大独立集（MIS）电路。具体而言，我们设计了机器学习模型来寻找在MaxCut上优化的良好捐赠者候选，并将其参数应用于MIS接受者。我们的实验结果表明，这种参数迁移可以显著减少所需的优化迭代次数，同时实现可比较的近似比。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [683] [Do you know what q-means?](https://arxiv.org/abs/2308.09701)
> *你知道什么是q-means吗？*

*Arjan Cornelissen, Joao F. Doriguello, Alessandro Luongo, Ewin Tang* | **Category: quant-ph, cs.DS, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 聚类, k-means, 量子算法, 经典算法, 下界

**Comment:** 21 pages. v2: improved the quantum complexity, references added; v3:
  new co-author added, new algorithms and upper bounds, improved old upper
  bounds, new lower bounds, references added

> **TL;DR:** 该论文提出了一种经典ε-k-means算法，其在数据量n上的依赖性呈指数级改进，并与原始q-means量子算法匹配。同时，还提出了一种改进的q-means量子算法，其运行时间比其经典算法在多个参数上二次加速，并通过下界证明了算法在多数参数上的最优性。

**AI_Comments:** 本文的创新之处在于同时开发了显著加速的经典近似k-means算法和在此基础上更快的量子版本。量子算法通过避免复杂的量子线性代数，转而依赖更基础的量子操作（如QRAM和量子幅度估计），展现了其独特优势。同时，论文通过建立严格的下界，为所提出算法的最优性提供了坚实的理论基础。这项工作对于大数据分析领域，特别是考虑到量子计算加速此类任务的潜力，具有重要的意义。

<details>
  <summary>Details</summary>

**Motivation:** 聚类是分析大型数据集的重要工具，而Lloyd的k-means算法是最受欢迎的聚类算法之一。研究动机在于提高k-means算法的效率，特别是对于大型数据集，并探索量子算法在此领域的潜力。

**Method:** 本文提出了一种经典的ε-k-means算法，用于执行Lloyd算法单次迭代的近似版本。同时，提出了一种改进的q-means量子算法，该量子算法不依赖于先前的量子线性代数原语，而是仅使用QRAM和多元量子幅度估计来准备简单状态。此外，论文还提供了经典和量子查询下界。

**Result:** 提出的经典ε-k-means算法时间复杂度为$	ilde{O}\big(\frac{\|V\|_F^2}{n}\frac{k^{2}d}{\varepsilon^2}(k + \log{n})\big)$，指数级改进了对数据大小n的依赖，并与原始的“q-means”量子算法相匹配。改进的q-means量子算法时间复杂度为$	ilde{O}\big(\frac{\|V\|_F}{\sqrt{n}}\frac{k^{3/2}d}{\varepsilon}(\sqrt{k}+\sqrt{d})(\sqrt{k} + \log{n})\big)$，在多个参数上二次改进了经典算法的运行时间。通过下界证明，所提出的算法在大多数参数上都是最优的。

**Conclusion:** 该论文提出了经典和量子近似k-means算法，显著提升了运行效率，并通过理论下界证明了这些算法在大多数参数上的最优性。

> **ai_Abstract:** 本文旨在提高k-means聚类算法的效率，提出了一种经典的$\varepsilon$-$k$-means算法，该算法在数据大小n的依赖性上实现了指数级改进，并与现有q-means量子算法的性能相匹配。在此基础上，论文进一步提出了一种改进的q-means量子算法，该算法通过采用QRAM和多元量子幅度估计而非传统的量子线性代数原语，实现了比其经典对应算法在多个参数上二次加速。此外，研究还提供了经典和量子查询下界，证明了所提出算法在大多数参数上的最优性。

> **摘要翻译:** 聚类是分析大型数据集最重要的工具之一，而Lloyd的k-means算法可能是最受欢迎的聚类算法。该算法接收n个向量$V=[v_1,\dots,v_n]\in\mathbb{R}^{d\times n}$并输出k个质心$c_1,\dots,c_k\in\mathbb{R}^d$；这些质心根据哪个质心最接近特定向量，将向量划分为簇。我们提出了一种经典的$\varepsilon$-$k$-means算法，它执行Lloyd算法一次迭代的近似版本，时间复杂度为$\tilde{O}\big(\frac{\|V\|_F^2}{n}\frac{k^{2}d}{\varepsilon^2}(k + \log{n})\big)$，指数级改进了对数据大小n的依赖，并与Kerenidis、Landman、Luongo和Prakash（NeurIPS'19）最初提出的“q-means”量子算法相匹配。此外，我们提出了一种改进的q-means量子算法，其时间复杂度为$\tilde{O}\big(\frac{\|V\|_F}{\sqrt{n}}\frac{k^{3/2}d}{\varepsilon}(\sqrt{k}+\sqrt{d})(\sqrt{k} + \log{n})\big)$，在多个参数上二次改进了我们经典的$\varepsilon$-$k$-means算法的运行时间。我们的量子算法不依赖于先前工作的量子线性代数原语，而是仅使用QRAM基于当前迭代的簇和多元量子幅度估计来准备简单状态。最后，我们提供了经典和量子查询下界，表明我们的算法在大多数参数上都是最优的。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [114] [Finite-Dimensional Gaussian Approximation for Deep Neural Networks: Universality in Random Weights](https://arxiv.org/abs/2507.12686)
> *深度神经网络的有限维高斯逼近：随机权重的普适性*

*Krishnakumar Balasubramanian, Nathan Ross* | **Category: stat.ML, cs.LG, math.PR, math.ST, stat.TH** | **Updated: 2025-07-16**

**Keywords:** 深度神经网络, 高斯逼近, 有限维分布, 随机权重, Wasserstein-1范数

**Comment:** 

> **TL;DR:** 本文研究了具有随机初始化权重的深度神经网络的有限维分布（FDDs），并建立了FDDs与其高斯极限之间的Wasserstein-1范数高斯逼近界限，给出了特定情况下的收敛速率。

**AI_Comments:** 该论文在理论上分析了深度神经网络在随机权重初始化下的FDDs的高斯逼近特性，并提供了严格的收敛界限，这对于理解深度学习模型的理论基础及其在大宽度极限下的行为具有重要意义。其创新之处在于考虑了层宽度以任意相对速率增长的情况，并给出了具体的收敛速率。

<details>
  <summary>Details</summary>

**Motivation:** 研究具有有限阶矩的随机初始化权重的深度神经网络的有限维分布（FDDs）。

**Method:** 建立了FDDs与其高斯极限之间的Wasserstein-1范数高斯逼近界限，假设使用Lipschitz激活函数并允许层宽度以任意相对速率增长到无穷大。

**Result:** 在所有宽度与共同尺度参数$n$成比例且有$L-1$个隐藏层的特殊情况下，获得了$n^{-({1}/{6})^{L-1} + \epsilon}$（对于任意$\epsilon > 0$）的收敛速率。

**Conclusion:** Not mentioned in abstract.

> **ai_Abstract:** 本文研究了深度神经网络的有限维分布（FDDs），其权重随机初始化且具有有限阶矩。研究建立了FDDs与其高斯极限之间的Wasserstein-1范数高斯逼近界限，该界限适用于Lipschitz激活函数且层宽度可任意增长至无穷大的情况。特别地，当所有层宽度与一个公共尺度参数$n$成比例且存在$L-1$个隐藏层时，论文给出了收敛速率为$n^{-({1}/{6})^{L-1} + \epsilon}$（对于任意$\epsilon > 0$）。

> **摘要翻译:** 我们研究了具有有限阶矩的随机初始化权重的深度神经网络的有限维分布（FDDs）。具体来说，我们建立了FDDs与其高斯极限之间的Wasserstein-1范数高斯逼近界限，假设使用Lipschitz激活函数并允许层宽度以任意相对速率增长到无穷大。在所有宽度与共同尺度参数$n$成比例且有$L-1$个隐藏层的特殊情况下，我们获得了$n^{-({1}/{6})^{L-1} + \epsilon}$（对于任意$\epsilon > 0$）的收敛速率。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [166] [Self Balancing Neural Network: A Novel Method to Estimate Average Treatment Effect](https://arxiv.org/abs/2507.12818)
> *自平衡神经网络：一种估计平均治疗效果的新方法*

*Atomsa Gemechu Abdisa, Yingchun Zhou, Yuqi Qiu* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 自平衡神经网络, 平均治疗效果, 倾向得分, 观察性研究, 因果推断

**Comment:** 

> **TL;DR:** 本研究提出了一种名为“自平衡神经网络”（Sbnet）的新方法，通过将平衡网络作为前馈神经网络的关键部分来估计平均治疗效果，并在模拟和真实数据集上表现优于现有最佳方法。

**AI_Comments:** 该论文的创新之处在于提出了一种将倾向得分估计过程内嵌到神经网络结构中的方法（平衡网络），从而实现平均治疗效果的一步式估计，有效地规避了传统方法中倾向得分模型设定错误的风险。多伪倾向得分框架的引入进一步增强了模型的鲁棒性和泛化能力。这项工作对于因果推断领域，特别是在处理观察性数据时的偏差校正，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在观察性研究中，混杂变量和工具变量会影响治疗和结果，导致平均治疗效果的估计存在偏差。现有方法（如使用倾向得分）存在倾向得分模型设定错误的风险。

**Method:** 提出了一种名为“自平衡神经网络”（Sbnet）的新方法。该方法通过一个“平衡网络”让模型自身获取伪倾向得分，并将此平衡网络作为前馈神经网络的关键部分来一步到位地估计平均治疗效果。此外，还提出了一个从多样化平衡网络中估计多伪倾向得分的框架。

**Result:** 所提出的自平衡神经网络在三个模拟设置和真实世界数据集上与现有最佳方法进行了比较，结果表明其性能优于现有最佳方法。

**Conclusion:** 自平衡神经网络是一种有效且性能优越的方法，能够解决观察性研究中平均治疗效果估计的偏差和倾向得分模型设定错误的问题。

> **ai_Abstract:** 本研究提出了一种新颖的“自平衡神经网络”（Sbnet），旨在解决观察性研究中平均治疗效果估计的偏差问题以及传统倾向得分方法可能存在的模型设定错误。Sbnet通过一个内部的“平衡网络”生成伪倾向得分，并将其整合到前馈神经网络中，实现一步式平均治疗效果估计。该文还引入了多伪倾向得分框架以增强鲁棒性。实验结果表明，Sbnet在模拟和真实世界数据集上的表现均优于现有最佳方法。

> **摘要翻译:** 在观察性研究中，混杂变量同时影响治疗和结果。此外，工具变量也会影响治疗分配机制。这种情况使该研究有别于标准的随机对照试验，因为在随机对照试验中，治疗分配是随机的。由于这种情况，估计的平均治疗效果会产生偏差。为了解决这个问题，一种标准方法是在估计平均治疗效果时纳入估计的倾向得分。然而，这些方法存在倾向得分模型设定错误的风险。为了解决这个问题，本研究提出了一种名为“自平衡神经网络”（Sbnet）的新方法，该方法让模型本身从平衡网络中获取其伪倾向得分。所提出的方法通过将平衡网络作为前馈神经网络的关键部分来估计平均治疗效果。这种公式化方法一步解决了平均治疗效果的估计问题。此外，还提出了多伪倾向得分框架，该框架从多样化的平衡网络中估计并用于平均治疗效果的估计。最后，将所提出的方法与三种模拟设置和真实世界数据集上的现有最佳方法进行了比较。结果表明，所提出的自平衡神经网络表现出比现有最佳方法更好的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [214] [Bayesian Modeling and Estimation of Linear Time-Variant Systems using Neural Networks and Gaussian Processes](https://arxiv.org/abs/2507.12878)
> *使用神经网络和高斯过程对线性时变系统进行贝叶斯建模与估计*

*Yaniv Shulman* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 线性时变系统, 贝叶斯建模, 神经网络, 高斯过程, 系统识别

**Comment:** 

> **TL;DR:** 本文提出了一个统一的贝叶斯框架，利用神经网络和高斯过程对线性时变系统进行建模和识别，能够量化不确定性并展现出优越的性能。

**AI_Comments:** 这项工作的创新之处在于将贝叶斯框架、神经网络和高斯过程结合起来，解决了LTV系统识别中的不确定性量化问题。它引入的LTIE系统类别具有理论意义和潜在应用价值。通过实验证明了其在数据效率和跟踪能力方面的优越性，这对于实际工程应用非常重要。

<details>
  <summary>Details</summary>

**Motivation:** 从输入输出数据中识别线性时变（LTV）系统是一个基本但具有挑战性的病态逆问题。

**Method:** 本文引入了一个统一的贝叶斯框架，将系统的脉冲响应建模为一个随机过程，并将其分解为后验均值和随机波动项。该方法利用贝叶斯神经网络和高斯过程，并通过可扩展的变分推断进行推断。

**Result:** 该框架能够从单个噪声观测中稳健地推断LTI系统的属性；在模拟环境噪声层析成像问题中，与经典方法相比，显示出卓越的数据效率；通过使用结构化高斯过程先验，成功地跟踪了连续变化的LTV脉冲响应。

**Conclusion:** 这项工作为动态环境中的不确定性感知系统识别提供了一种灵活且鲁棒的方法。

> **ai_Abstract:** 本文提出了一个统一的贝叶斯框架，用于从输入输出数据中识别线性时变（LTV）系统。该框架将系统脉冲响应建模为随机过程，并引入了期望线性时不变（LTIE）系统类别。通过结合贝叶斯神经网络和高斯过程，并利用可扩展的变分推断，该方法能够稳健地推断系统属性、提高数据效率，并成功跟踪变化的脉冲响应，为动态环境下的不确定性感知系统识别提供了一种灵活鲁棒的解决方案。

> **摘要翻译:** 从输入输出数据中识别线性时变（LTV）系统是一个基本但具有挑战性的病态逆问题。这项工作引入了一个统一的贝叶斯框架，将系统的脉冲响应 $h(t, \tau)$ 建模为一个随机过程。我们将响应分解为后验均值和随机波动项，这种公式化提供了一种量化不确定性的原则性方法，并自然地定义了一个我们称之为期望线性时不变（LTIE）的新型有用系统类别。为了进行推断，我们利用了现代机器学习技术，包括贝叶斯神经网络和高斯过程，并使用可扩展的变分推断。我们通过一系列实验证明，我们的框架能够从单个噪声观测中稳健地推断LTI系统的属性；在模拟环境噪声层析成像问题中，与经典方法相比，显示出卓越的数据效率；通过使用结构化高斯过程先验，成功地跟踪了连续变化的LTV脉冲响应。这项工作为动态环境中的不确定性感知系统识别提供了一种灵活且鲁棒的方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [299] [Approximation Rates for Shallow ReLU$^k$ Neural Networks on Sobolev Spaces via the Radon Transform](https://arxiv.org/abs/2408.10996)
> *浅层ReLU$^k$神经网络在Sobolev空间上的逼近率研究：基于Radon变换*

*Tong Mao, Jonathan W. Siegel, Jinchao Xu* | **Category: stat.ML, cs.LG, cs.NA, math.NA, 62M45, 41A25, 41A30** | **Updated: 2025-07-17**

**Keywords:** 浅层神经网络, ReLU$^k$, 逼近率, Sobolev空间, Radon变换

**Comment:** 

> **TL;DR:** 本研究利用Radon变换和偏差理论，证明了浅层ReLU$^k$神经网络在Sobolev空间上逼近函数的近乎最优速率，这些速率在对数因子内是最佳的，并且显著推广了现有结果。

**AI_Comments:** 该论文的创新点在于利用Radon变换和偏差理论为浅层ReLU$^k$神经网络的近似率提供了简洁且广义的证明。其重要性体现在揭示了ReLU$^k$神经网络的自适应性，使其能够对更高光滑度的函数实现最优逼近，即使其本身是低阶分段多项式，这为理解神经网络的表达能力提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 研究浅层ReLU$^k$激活函数神经网络在$L_q(\Omega)$-范数下，能够以多高的效率逼近Sobolev空间$W^s(L_p(\Omega))$中的函数。

**Method:** 利用Radon变换和偏差理论的最新成果，提供了一种简单的方法来证明在多种情况下（包括$q\leq p$、$p\geq 2$和$s \leq k + (d+1)/2$）的近似率。

**Result:** 得出的近似率在对数因子内是最佳的，并且显著推广了现有结果。一个有趣的推论是，浅层ReLU$^k$神经网络的自适应性使其能够获得高达$s = k + (d+1)/2$阶光滑度的最佳逼近率，尽管它们表示的是固定度数$k$的分段多项式。

**Conclusion:** 浅层ReLU$^k$神经网络的自适应性使其能够在Sobolev空间上实现高达$s = k + (d+1)/2$阶光滑度的最优逼近率，这超越了它们固定度数分段多项式的表示能力。

> **ai_Abstract:** 本研究探讨了浅层ReLU$^k$神经网络在Sobolev空间中逼近函数的效率问题。通过运用Radon变换和偏差理论，论文提供了一种简洁的证明，揭示了在特定条件下（如$q\leq p$, $p\geq 2$, $s \leq k + (d+1)/2$）近乎最优的逼近率。这些速率在对数因子内达到了最优，并显著扩展了现有理论。研究还发现，浅层ReLU$^k$神经网络的自适应能力使其即使作为固定度数的分段多项式，也能对高达$s = k + (d+1)/2$阶的光滑函数实现最优逼近。

> **摘要翻译:** 设$\Omega\subset \mathbb{R}^d$是一个有界域。我们考虑的问题是，具有ReLU$^k$激活函数的浅层神经网络能够以多高的效率逼近Sobolev空间$W^s(L_p(\Omega))$中的函数，误差以$L_q(\Omega)$-范数衡量。利用Radon变换和偏差理论的最新成果，我们提供了一个简单的方法来证明在多种情况下，包括当$q\leq p$、$p\geq 2$和$s \leq k + (d+1)/2$时，近乎最优的逼近率。我们得出的速率在对数因子内是最佳的，并且显著推广了现有结果。一个有趣的推论是，浅层ReLU$^k$神经网络的自适应性使其能够获得高达$s = k + (d+1)/2$阶光滑度的最佳逼近率，即使它们表示的是固定度数$k$的分段多项式。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [322] [When Pattern-by-Pattern Works: Theoretical and Empirical Insights for Logistic Models with Missing Values](https://arxiv.org/abs/2507.13024)
> *模式逐模式策略何时有效：缺失值逻辑模型的理论与实证洞察*

*Christophe Muller, Erwan Scornet, Julie Josse* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 逻辑模型, 缺失值, 模式逐模式, 插补, 贝叶斯概率

**Comment:** 

> **TL;DR:** 本文深入探讨了在缺失数据下逻辑回归模型的预测问题。从理论上证明了模式逐模式（PbP）策略在多种缺失数据场景下能准确近似贝叶斯概率。通过实证比较多种方法，发现PbP和MICE.RF.Y在不同样本量和特征类型下表现优异。

**AI_Comments:** 本文通过理论证明和实证分析相结合的方式，深入探讨了缺失值逻辑模型中的预测问题，具有重要的理论和实践意义。其创新之处在于证明了PbP策略在多种缺失数据场景下的有效性，并提供了在不同数据条件下选择最佳缺失数据处理方法的具体建议。研究结果对实际应用中处理缺失数据具有指导价值，特别是区分了小样本量和大样本量下的最优策略。

<details>
  <summary>Details</summary>

**Motivation:** 在参数模型中，即使参数估计本身不足以预测部分观测输入，预测具有部分缺失输入的响应仍然是一项具有挑战性的任务。现有工作主要研究线性模型，但逻辑模型具有其自身的困难，因此本文专注于解决缺失值逻辑模型中的预测问题。

**Method:** 本文从理论角度证明了“模式逐模式”（Pattern-by-Pattern, PbP）策略（为每个缺失模式学习一个逻辑模型）在多种缺失数据场景（MCAR、MAR和MNAR）下能准确近似贝叶斯概率。在实证方面，本文全面比较了多种方法（常数和迭代插补、完整案例分析、PbP和EM算法），评估指标包括分类、概率估计、校准和参数推断。

**Result:** 研究发现，对于小样本量，均值插补可作为基线方法，通过带有标签的非线性多重迭代插补技术（MICE.RF.Y）可获得更好的性能。对于大样本量，PbP是高斯混合数据最佳方法，而对于存在非线性特征的情况，推荐使用MICE.RF.Y。

**Conclusion:** 本文对缺失值逻辑回归提供了全面的视角。研究表明，在不同样本量和数据特征下，模式逐模式（PbP）策略和MICE.RF.Y方法是处理缺失值逻辑模型的有效选择。

> **ai_Abstract:** 本文探讨了在存在缺失输入的情况下预测响应的挑战，尤其关注逻辑模型。理论上，论文证明了模式逐模式（PbP）策略在各种缺失数据场景下能准确近似贝叶斯概率。实证研究比较了多种方法，包括常数和迭代插补、完整案例分析、PbP和EM算法，评估了它们在分类、概率估计、校准和参数推断方面的表现。研究结果表明，对于小样本量，均值插补可作为基线，MICE.RF.Y表现更佳；对于大样本量，PbP在高斯混合数据中表现最佳，而MICE.RF.Y在非线性特征存在时表现突出。这项工作为缺失值逻辑回归提供了全面的见解。

> **摘要翻译:** 即使在参数模型中，用部分缺失的输入来预测响应仍然是一项具有挑战性的任务，因为参数估计本身不足以预测部分观测到的输入。一些工作研究了线性模型中的预测问题。在本文中，我们专注于逻辑模型，它本身就存在困难。从理论角度来看，我们证明了“模式逐模式”（PbP）策略（为每个缺失模式学习一个逻辑模型）在各种缺失数据场景（MCAR、MAR和MNAR）中能准确近似贝叶斯概率。在实证方面，我们全面比较了各种方法（常数和迭代插补、完整案例分析、PbP和EM算法），涵盖分类、概率估计、校准和参数推断。我们的分析提供了关于缺失值逻辑回归的全面视角。它揭示了均值插补可作为小样本量下的基线方法，并通过带有标签的非线性多重迭代插补技术（MICE.RF.Y）获得了改进的性能。对于大样本量，PbP是高斯混合数据的最佳方法，并且在存在非线性特征的情况下，我们推荐使用MICE.RF.Y。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [437] [Bounding the Worst-class Error: A Boosting Approach](https://arxiv.org/abs/2310.14890)
> *限制最差类别错误：一种提升方法*

*Yuya Saito, Shinnosuke Matsuo, Seiichi Uchida, Daiki Suehiro* | **Category: stat.ML, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 最差类别错误, 提升方法, 深度神经网络, 分类, 过拟合

**Comment:** Accepted at IJCNN2025

> **TL;DR:** 本文提出了一种提升（Boosting）方法来限制分类任务中的最差类别错误率，有效避免过拟合。

**AI_Comments:** 该论文的创新点在于将关注点从传统的平均错误率转移到更具实际意义的最差类别错误率，并通过提出一种提升方法来“限制”而非“消除”这种错误，这在处理关键类别性能和避免过拟合方面提供了一个实用的解决方案。特别是在医学诊断等高风险应用中，这种方法的重要性不言而喻。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决最差类别错误率问题，而非标准的所有类别平均错误率。在许多应用中（例如医学图像分类），某一关键类别的错误率过高是不可接受的，而平均错误率可能无法反映这一问题。为了在使用深度神经网络（DNNs）最小化最差类别错误时避免过拟合，作者设计了一种限制最差类别错误而非将其降至零的问题表述。

**Method:** 为避免深度神经网络（DNNs）在最小化最差类别错误时过拟合，本文设计了一种限制最差类别错误而非实现零最差类别错误的问题表述。此外，为了正确限制最差类别错误，本文提出了一种集成DNNs的提升（boosting）方法。论文还给出了训练和泛化最差类别错误界限。

**Result:** 实验结果表明，该算法在降低最差类别测试错误率的同时，有效避免了对训练集的过拟合。

**Conclusion:** 所提出的提升方法能够有效限制并降低最差类别错误率，表现出良好的泛化能力并避免了过拟合。

> **ai_Abstract:** 本文提出了一种基于提升（Boosting）的方法来解决分类任务中的最差类别错误率问题，该问题在医学图像分类等应用中尤为关键，因为平均错误率可能掩盖了关键类别的高错误率。为避免深度神经网络（DNNs）在最小化最差类别错误时发生过拟合，研究设计了一种将最差类别错误限制在一定范围而非完全消除的表述。通过集成DNNs，该方法提供了训练和泛化最差类别错误的界限。实验结果证实，该算法能够有效降低最差类别测试错误率，同时保持良好的泛化能力并避免过拟合。

> **摘要翻译:** 本文解决了最差类别错误率问题，而非所有类别平均的标准错误率。例如，一个三类别分类任务，如果各类别错误率分别为10%、10%和40%，其最差类别错误率为40%，而在类别平衡条件下平均错误率为20%。最差类别错误在许多应用中都非常重要。例如，在医学图像分类任务中，恶性肿瘤类别的错误率达到40%是不可接受的，而良性和健康类别的错误率只有10%。为了避免在使用深度神经网络（DNNs）最小化最差类别错误时出现过拟合，我们设计了一种限制最差类别错误而非实现零最差类别错误的问题表述。此外，为了正确限制最差类别错误，我们提出了一种集成DNNs的提升方法。我们给出了训练和泛化最差类别错误界限。实验结果表明，该算法在降低最差类别测试错误率的同时，避免了对训练集的过拟合。代码可在https://github.com/saito-yuya/Bounding-the-Worst-class-error-A-Boosting-Approach 获取。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [477] [Relation-Aware Slicing in Cross-Domain Alignment](https://arxiv.org/abs/2507.13194)
> *跨域对齐中的关系感知切片*

*Dhruv Sarkar, Aprameyo Chakrabartty, Anish Chakrabarty, Swagatam Das* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 切片Gromov-Wasserstein, 关系感知切片, 跨域对齐, 投影方向, 计算成本

**Comment:** 

> **TL;DR:** 本文提出了一种关系感知切片方法，通过引入无需优化的关系感知投影方向（RAPD）和关系感知切片分布（RASD），改进了切片Gromov-Wasserstein（SGW）距离，解决了其计算成本高和代表性差的问题。

**AI_Comments:** 本文的创新点在于提出了“无需优化”的关系感知切片分布（RASD），通过引入关系感知投影方向（RAPD）来改进切片Gromov-Wasserstein距离。这种方法避免了传统切片分布优化的高昂成本和复杂性，同时提升了距离的代表性和计算效率，为跨域对齐任务提供了一个更实用且强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 切片Gromov-Wasserstein（SGW）距离旨在降低Gromov-Wasserstein距离的计算成本，但其现有切片机制由于无信息的投影方向导致不必要的计算成本，并影响距离的代表能力。此外，寻找更合适的切片分布本身是一个计算成本高昂的优化问题，且复杂分布的采样也可能很昂贵。

**Method:** 为解决SGW的缺点，本文提出了一种无需优化的切片分布，以实现快速蒙特卡洛近似。具体方法是引入关系感知投影方向（RAPD），有效捕获两对随机向量（每个向量遵循其环境律）之间的成对关联。基于此，推导出关系感知切片分布（RASD），这是一种对应于采样RAPD的位置-尺度律。最终，引入了RASGW距离及其变体，如IWRASGW（重要性加权RASGW）。

**Result:** 本文从理论上分析了RASGW距离的性质，并通过在各种对齐任务上进行大量实验，证实了其经验上的强大能力。

**Conclusion:** 本文提出的RASGW距离及其变体克服了现有切片Gromov-Wasserstein（SGW）距离所遇到的缺点，提升了其计算效率和代表性。

> **ai_Abstract:** 本文针对切片Gromov-Wasserstein（SGW）距离在计算成本和代表性方面的局限性，提出了一种创新的关系感知切片方法。通过引入关系感知投影方向（RAPD）和由此衍生的关系感知切片分布（RASD），该方法实现了无需优化的快速采样，有效捕获了数据间的成对关联。在此基础上，作者提出了RASGW距离及其变体，并通过理论分析和大量实验证明了其在解决SGW固有缺点方面的优越性。

> **摘要翻译:** 切片Gromov-Wasserstein (SGW) 距离旨在减轻解决非凸二次规划（即Gromov-Wasserstein距离）的计算成本，它利用从单位超球体均匀采样的投影方向。这种切片机制由于无信息的方向而产生不必要的计算成本，这也影响了距离的代表能力。然而，寻找更合适的投影方向分布（切片分布）本身通常是一个优化问题，并带有其自身的计算成本。此外，对于更复杂的分布，采样本身可能很昂贵。作为补救措施，我们提出了一种无需优化的切片分布，为蒙特卡洛近似提供了快速采样。我们通过引入关系感知投影方向（RAPD）来实现这一点，它有效地捕获了每对随机向量（每个向量遵循其环境律）之间的成对关联。这使我们能够推导出关系感知切片分布（RASD），这是一种对应于采样RAPD的位置-尺度律。最后，我们引入了RASGW距离及其变体，例如IWRASGW（重要性加权RASGW），它们克服了SGW所遇到的缺点。我们从理论上分析其性质，并通过在各种对齐任务上的大量实验证实了其经验上的强大能力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [496] [Physics constrained learning of stochastic characteristics](https://arxiv.org/abs/2507.12661)
> *物理约束的随机特性学习*

*Pardha Sai Krishna Ala, Ameya Salvi, Venkat Krovi, Matthias Schmid* | **Category: stat.ML, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-16**

**Keywords:** 状态估计, 噪声特性, 协方差矩阵, 机器学习, 实时车辆估计

**Comment:** 6 pages, 6 figures

> **TL;DR:** 本文提出了一种基于学习的方法，利用不同的损失函数来识别噪声特性，并将其应用于实时车辆状态估计，以解决传统协方差矩阵选择和噪声识别的挑战。

**AI_Comments:** 本文提出了一个新颖的基于学习的方法来解决状态估计中噪声特性识别的挑战，这对于提高估计精度和滤波器稳定性至关重要。其创新点在于利用不同的损失函数进行学习，并将其实际应用于实时车辆状态估计，显示了其潜在的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确的状态估计需要仔细考虑过程和测量模型的不确定性，但这些特性通常未知，且协方差矩阵的选择对估计精度至关重要，错误选择可能导致滤波器发散。识别噪声特性是一个长期存在的挑战。

**Method:** 本文提出了一种基于学习的方法，利用不同的损失函数来识别噪声特性。

**Result:** 该方法在实时车辆状态估计中测试了其性能。

**Conclusion:** 本文提出的基于学习的方法能够识别噪声特性，并在实时车辆状态估计中表现出有效性。

> **ai_Abstract:** 准确的状态估计依赖于对过程和测量模型不确定性的精确考量，但噪声特性和协方差矩阵的选择是长期存在的挑战，错误选择可能导致估计不准确甚至滤波器发散。传统方法多依赖优化算法。本文提出了一种基于学习的新方法，利用不同的损失函数来识别噪声特性，并在实时车辆状态估计中验证了其性能。

> **摘要翻译:** 准确的状态估计需要仔细考虑过程和测量模型的不确定性；这些特性通常不为人所知，需要经验丰富的设计师来选择协方差矩阵。协方差矩阵选择中的错误可能会影响估计算法的准确性，有时甚至导致滤波器发散。由于噪声源的不确定性以及系统性噪声建模的困难，识别噪声特性长期以来一直是一个具有挑战性的问题。大多数现有方法尝试通过涉及创新序列的优化算法来识别未知的协方差矩阵。近年来，学习方法已被用于确定过程和测量模型的随机特性。我们提出了一种基于学习的方法，采用不同的损失函数来识别噪声特性，并测试这些方法在实时车辆状态估计中的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [583] [Conformal inference for regression on Riemannian Manifolds](https://arxiv.org/abs/2310.08209)
> *黎曼流形回归中的共形推断*

*Alejandro Cholaquidis, Fabrice Gamboa, Leonardo Moreno* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 共形推断, 黎曼流形, 回归, 预测集, 非欧几里得数据

**Comment:** 

> **TL;DR:** 本文为响应变量在流形中且协变量在欧几里得空间中的回归场景，开发了分布无关且非参数的预测集。

**AI_Comments:** 本文的创新之处在于将共形推断这一强大的统计工具扩展应用于黎曼流形上的回归问题，有效解决了非欧几里得数据预测集的构建挑战。其所提出的预测集具有分布无关和非参数的优点，大大增强了方法的普适性。理论上的渐近收敛性证明与实际模拟及真实数据分析相结合，共同验证了该方法的可靠性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于非欧几里得数据在诸多领域（如圆形数据、协方差矩阵空间数据、格拉斯曼流形数据等）的广泛应用，流形上的回归和统计学研究的重要性日益凸显。然而，现有方法可能未能充分解决响应变量位于黎曼流形上的回归场景中预测集的构建问题。

**Method:** 本文将共形推断的概念扩展到响应变量在流形中且协变量在欧几里得空间中的回归场景，构建了分布无关且非参数的预测集。研究证明了这些区域在流形上的经验版本渐近几乎必然收敛到其总体对应物。

**Result:** 通过全面的模拟研究和对真实世界数据的分析，证明了该方法的有效性和效率。

**Conclusion:** 本文成功地为响应变量在黎曼流形中的回归问题提供了分布无关且非参数的预测集，并通过理论证明和实证分析展示了其有效性，为处理非欧几里得数据提供了重要工具。

> **ai_Abstract:** 本文针对响应变量在黎曼流形中、协变量在欧几里得空间中的回归问题，提出了基于共形推断的预测集。这些预测集具有分布无关和非参数的特性，并提供了其经验版本渐近收敛的理论证明。通过全面的模拟研究和真实世界数据分析，验证了该方法的有效性和效率。

> **摘要翻译:** 流形上的回归，以及更广泛地说，流形上的统计学，由于非欧几里得数据的广泛应用，近年来变得越来越重要。圆形数据是一个经典的例子，但协方差矩阵空间中的数据、通过主成分分析获得的格拉斯曼流形上的数据等也同样重要。在这项工作中，我们研究了当响应变量（表示为$Y$）位于流形中，而协变量（表示为$X$）位于欧几里得空间中的回归场景的预测集。这扩展了\cite{waser14}中描述的概念到这个新颖的上下文。与共形推断中的传统原则一致，这些预测集是分布无关的，表明对$(X,Y)$的联合分布没有施加特定的假设，并且它们保持非参数特性。我们证明了这些区域在流形上的经验版本的渐近几乎必然收敛到它们的总体对应物。通过全面的模拟研究和涉及真实世界数据的分析，证明了该方法的效率。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [603] [Nonparametric IPSS: Fast, flexible feature selection with false discovery control](https://arxiv.org/abs/2410.02208)
> *非参数IPSS：快速、灵活且具有错误发现控制的特征选择*

*Omar Melikechi, David B. Dunson, Jeffrey W. Miller* | **Category: stat.ML, cs.LG, stat.AP, stat.ME** | **Updated: 2025-07-16**

**Keywords:** 特征选择, 错误发现控制, 非参数方法, IPSS, 梯度提升, 随机森林

**Comment:** 

> **TL;DR:** 本文介绍了一种基于IPSS的通用非参数特征选择方法，能够准确控制错误发现率并检测更多真阳性，且计算高效，在癌症相关基因检测中表现优异。

**AI_Comments:** 本文的创新之处在于提出了一种通用的非参数特征选择框架IPSS，通过结合任意特征重要性得分和稳定性选择，有效地解决了现有方法在错误发现控制和真阳性识别上的局限性。其非参数特性和对q值的估计使其更适用于高维复杂数据。方法的效率和在实际生物医学数据上的出色表现凸显了其重要性和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有特征选择方法存在问题：(i) 依赖参数方法，(ii) 缺乏理论上的错误发现控制，或 (iii) 识别的真阳性较少。

**Method:** 提出了一种基于将集成路径稳定性选择 (IPSS) 应用于任意特征重要性得分的通用特征选择方法。该方法在重要性得分是非参数时是非参数的，并估计q值。重点关注使用梯度提升 (IPSSGB) 和随机森林 (IPSSRF) 作为重要性得分的两种特殊情况。

**Result:** 针对RNA测序数据的广泛非线性模拟显示，IPSSGB和IPSSRF两种方法都能准确控制错误发现率，并比现有方法检测到更多真阳性。两种方法也高效，在500个样本和5000个特征的情况下运行时间不到20秒。应用于检测与癌症相关的microRNA和基因时，它们以更少的特征产生了比现有方法更好的预测。

**Conclusion:** IPSSGB和IPSSRF是高效、准确的非参数特征选择方法，能够有效控制错误发现率，并在实际应用中（如癌症相关基因检测）表现出优越性。

> **ai_Abstract:** 本文提出了一种名为非参数IPSS的通用特征选择方法，旨在解决现有方法在依赖参数模型、缺乏错误发现控制或识别真阳性不足的问题。该方法将集成路径稳定性选择（IPSS）应用于任意特征重要性得分，并在重要性得分非参数时保持非参数特性，同时估计q值。研究者通过梯度提升（IPSSGB）和随机森林（IPSSRF）实例化了该方法。在RNA测序数据的模拟实验中，IPSSGB和IPSSRF均表现出准确的错误发现率控制和更高的真阳性检测能力，且计算高效。在癌症相关microRNA和基因的实际应用中，它们以更少特征实现了更优的预测性能。

> **摘要翻译:** 特征选择是机器学习和统计学中的一项关键任务。然而，现有的特征选择方法要么 (i) 依赖于参数方法，如线性或广义线性模型，要么 (ii) 缺乏理论上的错误发现控制，要么 (iii) 识别出很少的真阳性。在此，我们介绍了一种通用的特征选择方法，该方法基于将集成路径稳定性选择 (IPSS) 应用于任意特征重要性得分，具有有限样本的错误发现控制。当重要性得分是非参数时，该方法是非参数的，并且它估计q值，这比p值更适合高维数据。我们重点关注使用梯度提升 (IPSSGB) 和随机森林 (IPSSRF) 作为重要性得分的两种特殊情况。对RNA测序数据进行的广泛非线性模拟表明，这两种方法都能准确控制错误发现率，并比现有方法检测到更多真阳性。这两种方法也都很高效，在有500个样本和5000个特征的情况下运行时间不到20秒。我们将IPSSGB和IPSSRF应用于检测与癌症相关的microRNA和基因，发现它们以更少的特征产生了比现有方法更好的预测。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [613] [Signal Recovery Using a Spiked Mixture Model](https://arxiv.org/abs/2501.01840)
> *峰值混合模型在信号恢复中的应用*

*Paul-Louis Delacour, Sander Wahls, Jeffrey M. Spraggins, Lukasz Migas, Raf Van de Plas* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 峰值混合模型, 信号恢复, 期望最大化, Gaussian 混合模型, 高光谱成像

**Comment:** 

> **TL;DR:** 该研究引入了一种新的峰值混合模型（SMM）及其EM算法，用于从噪声观测中恢复信号，并在低信噪比下表现优于传统方法。

**AI_Comments:** 这篇论文的创新点在于引入了峰值混合模型（SMM）来处理随机缩放和噪声观测下的信号恢复问题，并设计了专门的EM算法。其重要性体现在 SMM 在低信噪比条件下优于传统 GMM，并能发现传统方法遗漏的信号，这对于生物医学和计算机视觉等领域的数据分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决从大量随机缩放和噪声观测中估计一组信号的问题。

**Method:** 引入了峰值混合模型（SMM），并设计了一种新颖的期望最大化（EM）算法来恢复SMM的所有参数。通过应用于生物医学研究（成像质谱数据）和计算机视觉（高光谱成像数据）中的不同数据类型来验证其广泛适用性。

**Result:** 在低信噪比条件下，SMM在信号恢复性能方面超越了传统的 Gaussian 混合模型（GMM）。在两个案例研究中（生物医学和计算机视觉），SMM 能够恢复传统方法（如 k-means 聚类和 GMM）遗漏的信号。

**Conclusion:** 峰值混合模型（SMM）及其EM恢复算法在从噪声观测中恢复信号方面表现出色，尤其在低信噪比环境下，并且能够发现传统方法遗漏的信号，显示出其在不同数据类型中的广泛适用性。

> **ai_Abstract:** 本文提出了一种新的峰值混合模型（SMM）及其期望最大化（EM）算法，用于在存在随机缩放和噪声的情况下恢复信号。实验证明，在低信噪比环境下，SMM在信号恢复方面优于传统的 Gaussian 混合模型（GMM），并且在生物医学和计算机视觉等不同应用中，SMM能够成功恢复传统方法（如 k-means 和 GMM）未能检测到的信号。

> **摘要翻译:** 我们引入了峰值混合模型（SMM）来解决从大量随机缩放和噪声观测中估计一组信号的问题。随后，我们设计了一种新颖的期望最大化（EM）算法来恢复SMM的所有参数。数值实验表明，在低信噪比条件下，对于SMM相关的数据类型，SMM在信号恢复性能方面超越了更传统的 Gaussian 混合模型（GMM）。通过将该技术应用于不同数据类型，证明了SMM及其相应的EM恢复算法的广泛相关性。第一个案例研究是生物医学研究应用，利用成像质谱数据集探索微米级大鼠脑组织切片的分子含量。第二个案例研究展示了SMM在计算机视觉应用中的性能，将高光谱成像数据集分割成潜在模式。尽管测量方式差异很大，但在两个案例研究中，SMM都被证明能够恢复传统方法（如 k-means 聚类和 GMM）遗漏的信号。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [633] [How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction](https://arxiv.org/abs/2507.11161)
> *标签错误如何影响对比学习？一个来自数据降维的视角*

*Jun Chen, Hong Chen, Yonghua Yu, Yiming Ying* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 对比学习, 标签错误, 数据降维, 奇异值分解, 下游分类性能

**Comment:** Published as ICML2025 poster. The arXiv version is a modified version

> **TL;DR:** 本文研究了标签错误对对比学习下游分类性能的影响，并提出使用数据降维（如SVD）和合适的增强策略来缓解负面影响。

**AI_Comments:** 这篇论文通过深入分析标签错误在对比学习中的影响，填补了现有理论理解的空白。其创新之处在于不仅揭示了标签错误的负面作用，还创造性地引入了数据降维（SVD）作为一种潜在的缓解策略。SVD作为“双刃剑”的发现尤其具有洞察力，强调了在应用增强和降维技术时需要权衡。论文最终提供的实用建议，如选择适度嵌入维度和弱增强，对实际应用具有重要的指导意义和参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 以前的对比学习理论都依赖于标签一致性假设，但由于数据增强策略的强度和随机性，这个假设在实践中可能不成立，导致标签错误。本文旨在深入研究标签错误对对比学习下游分类性能的理论影响。

**Method:** 本文首先揭示了标签错误对下游分类风险的显著负面影响。为了缓解这些影响，研究者将数据降维方法（例如奇异值分解SVD）应用于原始数据以减少假阳性样本。研究通过理论和实证评估来验证其效果。

**Result:** 标签错误对对比学习的下游分类风险有几个显著的负面影响。虽然数据降维（如SVD）可以减少假阳性样本，但它也被发现可能是一把双刃剑，由于增强图连接性的降低而导致下游分类准确率的恶化。

**Conclusion:** 为了提高模型性能，建议使用适度的嵌入维度（例如512, 1024）、数据膨胀、弱增强以及SVD，以确保大的图连接性和小的标签错误。

> **ai_Abstract:** 本文深入探讨了标签错误对对比学习下游分类性能的影响。研究指出，由于数据增强策略，标签一致性假设在实践中常被违反。论文揭示了标签错误对下游分类风险的负面影响，并提出应用数据降维（如SVD）来减少假阳性样本。然而，研究也发现SVD可能因降低增强图连接性而损害性能。基于这些发现，论文建议综合使用适度的嵌入维度、数据膨胀、弱增强和SVD，以平衡图连接性和标签错误，从而提升模型表现。

> **摘要翻译:** 近年来，对比学习在自监督表示学习领域取得了最先进的性能。许多先前的工作试图为对比学习的成功提供理论理解。几乎所有这些工作都依赖于一个默认假设，即标签一致性假设，但由于常见的增强策略（如随机裁剪RRC）的强度和随机性，这在实践中可能不成立（失败的概率称为标签错误）。本文研究了标签错误对对比学习下游分类性能的理论影响。我们首先揭示了标签错误对下游分类风险的几个显著负面影响。为了缓解这些影响，我们将数据降维方法（例如奇异值分解SVD）应用于原始数据以减少假阳性样本，并建立了理论和实证评估。此外，还发现SVD是一把双刃剑，它可能由于增强图连接性的降低而导致下游分类准确率的恶化。基于以上观察，我们给出了增强建议，即我们应该使用一些适度的嵌入维度（例如我们实验中的512, 1024）、数据膨胀、弱增强和SVD，以确保大的图连接性和小的标签错误，从而提高模型性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [134] [Rel-HNN: Split Parallel Hypergraph Neural Network for Learning on Relational Databases](https://arxiv.org/abs/2507.12562)
> *Rel-HNN：用于关系数据库学习的并行超图神经网络*

*Md. Tanvir Alam, Md. Ahasanul Alam, Md Mahmudur Rahman, Md. Mosaddek Khan* | **Category: cs.DB, cs.DC, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 关系数据库, 超图神经网络, Rel-HNN, 并行训练, 多GPU

**Comment:** 

> **TL;DR:** Rel-HNN是一种新颖的超图神经网络框架，通过将属性-值对建模为节点和元组建模为超边，以捕获关系数据库中的细粒度关联，并通过并行训练算法解决了可扩展性问题，显著优于现有方法。

**AI_Comments:** Rel-HNN的创新之处在于其独特的超图建模方式，将属性-值对和元组映射为节点和超边，从而有效捕获了传统GNN难以处理的细粒度元组内部关系。此外，为解决大型关系数据库的可扩展性问题而引入的分段并行训练算法，进一步提升了其实用价值。该工作为关系数据库上的深度学习提供了一个强大且高效的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 关系数据库（RDB）在企业和实际应用中无处不在，但将数据库扁平化给依赖固定大小输入表示的深度学习模型带来了挑战，这些模型难以从关系数据的结构化特性中捕获关系语义。现有的图神经网络（GNN）虽然被提出解决此问题，但它们通常通过将所有元组建模为整体节点而忽略元组内部关联，从而过度简化了关系结构。

**Method:** 本文提出了一种名为Rel-HNN的新型超图框架，该框架将每个独特的属性-值对建模为节点，将每个元组建模为超边，从而能够捕获细粒度的元组内部关系。该方法学习跨属性-值、元组和表级别的显式多级表示。为了解决大型RDB带来的可扩展性挑战，我们进一步引入了一种分段并行训练算法，该算法利用多GPU执行实现高效的超图学习。

**Result:** 在真实世界和基准数据集上的大量实验表明，Rel-HNN在分类和回归任务中均显著优于现有方法。此外，与传统的单GPU执行相比，我们的分段并行训练实现了显著的加速——在关系数据学习方面高达3.18倍，在超图学习方面高达2.94倍。

**Conclusion:** Rel-HNN通过创新的超图建模和高效的并行训练算法，成功解决了关系数据库中细粒度关系捕获和大规模数据处理的挑战，在各项任务中表现出卓越的性能和可扩展性。

> **ai_Abstract:** Rel-HNN是一种新颖的超图神经网络，旨在解决关系数据库中细粒度关系捕获和大规模学习的挑战。它通过将属性-值对视为节点、元组视为超边来构建超图，从而能够学习多级表示并捕获元组内部关联。为提高可扩展性，Rel-HNN引入了分段并行训练算法。实验证明，Rel-HNN在分类和回归任务上显著优于现有方法，并且其并行训练算法实现了显著的加速。

> **摘要翻译:** 关系数据库（RDB）在企业和实际应用中无处不在。将数据库扁平化给依赖固定大小输入表示的深度学习模型带来了挑战，这些模型难以从关系数据的结构化特性中捕获关系语义。图神经网络（GNN）已被提出解决此问题，但它们通常通过将所有元组建模为整体节点而忽略元组内部关联，从而过度简化了关系结构。在这项工作中，我们提出了一种名为Rel-HNN的新型超图框架，该框架将每个独特的属性-值对建模为节点，将每个元组建模为超边，从而能够捕获细粒度的元组内部关系。我们的方法学习跨属性-值、元组和表级别的显式多级表示。为了解决大型RDB带来的可扩展性挑战，我们进一步引入了一种分段并行训练算法，该算法利用多GPU执行实现高效的超图学习。在真实世界和基准数据集上的大量实验表明，Rel-HNN在分类和回归任务中均显著优于现有方法。此外，与传统的单GPU执行相比，我们的分段并行训练实现了显著的加速——在关系数据学习方面高达3.18倍，在超图学习方面高达2.94倍。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [488] [THOR: Transformer Heuristics for On-Demand Retrieval](https://arxiv.org/abs/2507.09592)
> *THOR：按需检索的Transformer启发式方法*

*Isaac Shi, Zeyuan Li, Fan Liu, Wenli Wang, Lewei He, Yang Yang, Tianyu Shi* | **Category: cs.DB, cs.AI** | **Updated: 2025-07-17**

**Keywords:** Text-to-SQL, 自然语言处理, 企业数据库, 数据检索, Transformer

**Comment:** 

> **TL;DR:** THOR是一个由eSapiens开发的、安全的、可扩展的引擎，它将自然语言问题转换为企业数据库的只读SQL分析，使非技术用户能够轻松安全地访问实时数据。

**AI_Comments:** THOR模块的创新在于其解耦的架构设计，特别是集成了LLM驱动的自校正和评分循环，这大大提高了Text-to-SQL系统的鲁棒性和输出质量。其强调的企业级安全性和对非技术用户的赋能，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决非技术用户访问企业数据库实时数据的困难，通过将自然语言问题转换为SQL查询，实现数据分析的简化和自动化，同时确保安全性。

**Method:** THOR模块采用解耦的编排/执行架构。它包含一个主管代理路由查询，模式检索动态注入表和列元数据，SQL生成代理发出受只读护栏保护的单语句SELECT查询。它还有一个集成的自校正和评分循环，用于捕获空结果、执行错误或低质量输出，并触发LLM驱动的再生成尝试。最后，结果解释代理生成简洁、人类可读的洞察。

**Result:** 在金融、销售和运营场景的冒烟测试中，展示了可靠的即席查询和自动化定期报告能力。THOR模块使非技术用户能够以零SQL的简单性和企业级的安全性访问实时数据。

**Conclusion:** THOR模块通过嵌入模式感知、容错执行和合规性护栏，成功赋能非技术用户以简单且安全的方式访问实时企业数据。

> **ai_Abstract:** THOR模块是一个由eSapiens开发的Text-to-SQL引擎，它将自然语言问题转化为安全的只读SQL查询，用于企业数据库的分析。它采用解耦架构，包含查询路由、模式检索、SQL生成、自校正和结果解释等组件。该系统旨在简化非技术用户对实时数据的访问，并通过冒烟测试验证了其在多个业务场景中的可靠性、安全性和易用性。

> **摘要翻译:** 我们引入了THOR（Transformer Heuristics for On-Demand Retrieval）模块，由eSapiens设计和实现，这是一个安全、可扩展的引擎，可将自然语言问题转换为企业数据库的经过验证的只读SQL分析。该Text-to-SQL模块遵循解耦的编排/执行架构：主管代理路由查询，模式检索动态注入表和列元数据，SQL生成代理发出受只读护栏保护的单语句SELECT查询。集成的自校正和评分循环捕获空结果、执行错误或低质量输出，并触发多达五次由LLM驱动的再生成尝试。最后，结果解释代理产生简洁、人类可读的洞察，并将原始行交给洞察与智能引擎进行可视化或预测。
在金融、销售和运营场景的冒烟测试中，展示了可靠的即席查询和自动化定期报告。通过嵌入模式感知、容错执行和合规性护栏，THOR模块使非技术用户能够以零SQL的简单性和企业级安全性访问实时数据。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [501] [MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced AI Applications with Retrieval Augmented Generation and Knowledge Graphs](https://arxiv.org/abs/2407.02994)
> *MedPix 2.0: 一个用于高级AI应用、结合检索增强生成和知识图谱的综合多模态生物医学数据集*

*Irene Siragusa, Salvatore Contino, Massimo La Ciura, Rosario Alicata, Roberto Pirrone* | **Category: cs.DB, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 多模态数据集, 检索增强生成, 知识图谱, 视觉语言模型, 医疗AI

**Comment:** 

> **TL;DR:** MedPix 2.0是一个新的综合多模态生物医学数据集，旨在解决高质量医疗数据稀缺的问题，并支持高级AI应用，特别是结合检索增强生成和知识图谱的视觉语言模型。

**AI_Comments:** MedPix 2.0的创新之处在于其构建了一个综合性的多模态生物医学数据集，并通过结合检索增强生成（RAG）和知识图谱，为高级医疗AI应用提供了强大的基础。其半自动化构建流程和对数据质量的关注解决了医疗数据稀缺和隐私的挑战。该数据集及其配套的GUI和模型应用潜力巨大，尤其是在医疗决策支持系统方面。

<details>
  <summary>Details</summary>

**Motivation:** 医疗领域AI应用开发面临高质量数据（尤其是多模态数据）稀缺的问题，主要由于隐私问题以及视觉语言模型对多模态医疗数据的需求增长，需要将临床报告和发现与相应的医学扫描图关联起来。

**Method:** 本研究开发了一个半自动管道，从现有MedPix®数据集中提取视觉和文本数据，并进行手动清理以去除噪声样本，从而创建了一个MongoDB数据库。同时，开发了一个图形用户界面（GUI）用于高效导航MongoDB实例和获取原始数据。此外，作者还展示了基于MedPix 2.0训练的检索增强生成（RAG）视觉语言模型DR-Minerva，并提出了DR-Minerva与知识图谱的扩展，该知识图谱使用Llama 3.1 Instruct 8B并利用MedPix 2.0。

**Result:** 成功构建了MedPix 2.0数据集，并创建了MongoDB数据库和配套的GUI。展示了基于MedPix 2.0训练的DR-Minerva模型，该模型能预测输入图像的身体部位和扫描模态。提出了DR-Minerva与知识图谱的扩展，形成一个可端到端查询的医疗决策支持系统。

**Conclusion:** MedPix 2.0数据集的构建及其与检索增强生成和知识图谱的结合，为解决医疗领域高质量多模态数据稀缺问题提供了重要资源，并为开发先进的医疗AI应用（如医疗决策支持系统）奠定了基础。

> **ai_Abstract:** MedPix 2.0是一个为高级AI应用设计的多模态生物医学数据集，旨在解决医疗领域高质量数据稀缺的问题。该数据集通过半自动化流程从MedPix®构建，并经过手动清理，存储在MongoDB中，并配有用于数据导航的GUI。论文还展示了基于MedPix 2.0训练的检索增强生成（RAG）VLM模型DR-Minerva，并提出了结合知识图谱的DR-Minerva扩展，使其能够作为医疗决策支持系统进行端到端查询。MedPix 2.0已开源。

> **摘要翻译:** 在医学领域开发人工智能应用的兴趣日益增长，但却苦于缺乏高质量数据集，这主要是由于隐私相关问题。此外，视觉语言模型（VLM）的最新发展导致了对多模态医疗数据集的需求，其中临床报告和发现需附带相应的医学扫描图。本文阐述了构建MedPix 2.0数据集的整个工作流程。我们从广为人知的多模态数据集MedPix®（主要供医生、护士和医疗保健学生用于继续医学教育目的）开始，开发了一个半自动管道来提取视觉和文本数据，随后进行手动清理过程，移除噪声样本，从而创建了一个MongoDB数据库。除了数据集，我们还开发了一个图形用户界面（GUI），旨在高效导航MongoDB实例并获取可轻松用于训练和/或微调VLM的原始数据。为了强调这一点，在这项工作中，我们首先回顾了DR-Minerva，一个基于检索增强生成（RAG）的VLM模型，它在MedPix 2.0上进行训练。DR-Minerva预测其输入图像的身体部位和所使用的扫描模态。我们还提出了DR-Minerva与知识图谱的扩展，该知识图谱使用Llama 3.1 Instruct 8B，并利用MedPix 2.0。由此产生的架构可以作为医疗决策支持系统进行端到端查询。MedPix 2.0已在GitHub上发布。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [544] [Transforming Football Data into Object-centric Event Logs with Spatial Context Information](https://arxiv.org/abs/2507.12504)
> *将足球数据转换为具有空间上下文信息的以对象为中心的事件日志*

*Vito Chan, Lennart Ebert, Paul-Julius Hillmann, Christoffer Rubensson, Stephan A. Fahrenkrog-Petersen, Jan Mendling* | **Category: cs.DB, cs.AI** | **Updated: 2025-07-16**

**Keywords:** 以对象为中心的事件日志, 足球数据, 空间上下文信息, 流程挖掘, 体育分析

**Comment:** Accepted for the 3rd Workshop on Object-centric processes from A to Z
  (co-locatedOBJECTS 2025) with BPM 2025

> **TL;DR:** 本文提出了一个框架，用于将足球数据转换为以对象为中心的事件日志，并加入了空间维度，以促进更复杂的足球数据分析。

**AI_Comments:** 该论文的创新点在于首次将以对象为中心的事件日志概念应用于足球数据分析，并引入了空间维度，这极大地扩展了传统事件日志的分析能力。其重要性在于为分析复杂、多对象交互的体育数据提供了新的视角和工具。未来的工作可以进一步探索变体分析和过滤技术，以更好地应对数据中的变异性，从而提升其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单案例事件日志在分析复杂和真实的流程行为方面存在局限性，而以对象为中心的事件日志能够处理多个对象，但其在现实世界中的数量有限，且其效用需要进一步验证。团队体育数据日益增长的可用性为以对象为中心的流程挖掘提供了契机。

**Method:** 本文提出了一个框架，用于将足球（soccer）数据转换为以对象为中心的事件日志，并进一步增强了空间维度。作者通过基于真实足球数据生成以对象为中心的事件日志来展示该框架的有效性。

**Result:** 作者成功地基于真实足球数据生成了以对象为中心的事件日志，并讨论了不同过程表示的结果，证明了所提出框架的有效性。

**Conclusion:** 本文首次提供了足球分析中以对象为中心的事件日志的示例，为未来在足球数据分析中应用以对象为中心的流程挖掘奠定了基础。

> **ai_Abstract:** 本研究旨在解决以对象为中心的事件日志在现实世界中应用有限的问题。论文提出了一种将足球数据转化为带有空间上下文信息的以对象为中心的事件日志的框架。通过使用真实足球数据进行验证，该框架被证明是有效的，并为足球分析中引入以对象为中心的流程挖掘提供了首个实例。

> **摘要翻译:** 以对象为中心的事件日志通过考虑多个对象，扩展了传统的单案例事件日志概念，从而能够分析更复杂和真实的流程行为。然而，现实世界中以对象为中心的事件日志数量仍然有限，需要进一步研究以测试其有用性。团队体育数据日益增长的可用性可以促进以对象为中心的流程挖掘，利用现实世界的数据和合适的用例。在本文中，我们提出了一个将足球（soccer）数据转换为以对象为中心的事件日志的框架，并进一步增强了空间维度。我们通过基于真实足球数据生成以对象为中心的事件日志来证明我们框架的有效性，并讨论了不同过程表示的结果。通过我们的论文，我们提供了足球分析中以对象为中心的事件日志的第一个示例。未来的工作应考虑变体分析和过滤技术，以更好地处理变异性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [175] [Token Communications: A Large Model-Driven Framework for Cross-modal Context-aware Semantic Communications](https://arxiv.org/abs/2502.12096)
> *令牌通信：一种大型模型驱动的跨模态上下文感知语义通信框架*

*Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato* | **Category: cs.MM, cs.CV, cs.IT, eess.SP, math.IT** | **Updated: 2025-07-16**

**Keywords:** 令牌通信, 大型模型, 语义通信, 跨模态上下文, 带宽效率

**Comment:** Accepted at IEEE Wireless Communications Magazine

> **TL;DR:** 本文提出了令牌通信（TokCom），一个由大型模型驱动的框架，用于在生成式语义通信中利用跨模态上下文信息，通过高效的基于Transformer的令牌处理显著提高带宽效率。

**AI_Comments:** 本文提出了一种新颖的令牌通信范式，将大型模型（GFM/MLLMs）引入语义通信领域，通过以令牌为通信单元和高效的Transformer处理，有效利用跨模态上下文信息，从而显著提升了带宽效率。其创新性在于将大模型与通信系统深度融合，为未来无线网络中的语义通信提供了新的思路和框架，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是生成式基础模型和多模态大型语言模型（GFM/MLLMs）的最新成功，这些模型使得以令牌为通信单元成为可能，从而实现高效的基于Transformer的令牌处理。

**Method:** 本文提出了令牌通信（TokCom）框架，它是一个大型模型驱动的框架，用于在生成式语义通信（GenSC）中利用跨模态上下文信息。TokCom将令牌作为通信单元，并在发射器和接收器端实现高效的基于Transformer的令牌处理。该方法探索了如何将基于GFM/MLLMs的令牌处理集成到语义通信系统中，以经济的复杂性有效利用跨模态上下文，并提出了未来无线网络中各层高效TokCom的关键原则。

**Result:** 在一个典型的图像语义通信设置中，通过利用令牌之间的上下文信息，TokCom显著提高了带宽效率。

**Conclusion:** 本文确定了潜在的研究方向，以促进TokCom在未来无线网络中的应用。

> **ai_Abstract:** 本文提出了一种名为令牌通信（TokCom）的新型大型模型驱动框架，旨在生成式语义通信（GenSC）中有效利用跨模态上下文信息。受生成式基础模型和多模态大型语言模型成功的启发，TokCom以令牌作为通信单元，并通过高效的基于Transformer的令牌处理实现通信。研究探讨了集成GFM/MLLMs进行上下文利用的机遇与挑战，并提出了高效TokCom的关键原则。实验结果表明，在图像语义通信中，TokCom显著提高了带宽效率。文章还指出了未来的研究方向。

> **摘要翻译:** 在本文中，我们介绍了令牌通信（TokCom），一个由大型模型驱动的框架，旨在生成式语义通信（GenSC）中利用跨模态上下文信息。TokCom是一种新范式，其灵感来源于生成式基础模型和多模态大型语言模型（GFM/MLLMs）的最新成功，其中通信单元是令牌，从而在发射器和接收器端实现高效的基于Transformer的令牌处理。在本文中，我们介绍了在GenSC中利用上下文的潜在机遇和挑战，探讨了如何将基于GFM/MLLMs的令牌处理集成到语义通信系统中，以经济的复杂性有效利用跨模态上下文，并提出了未来无线网络中各层高效TokCom的关键原则。在一个典型的图像语义通信设置中，我们证明了TokCom通过利用令牌之间的上下文信息显著提高了带宽效率。最后，确定了潜在的研究方向，以促进TokCom在未来无线网络中的采用。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [513] [KEN: Knowledge Augmentation and Emotion Guidance Network for Multimodal Fake News Detection](https://arxiv.org/abs/2507.09647)
> *KEN：用于多模态假新闻检测的知识增强与情感引导网络*

*Peican Zhu, Yubo Jing, Le Cheng, Keke Tang, Yangming Guo* | **Category: cs.MM, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 多模态假新闻检测, 知识增强, 情感引导, LVLM, 平衡学习

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** KEN是一种新的多模态假新闻检测网络，它通过知识增强（利用LVLM）和情感引导（平衡学习）来解决现有方法在图像语义理解、文本信息不足以及情感类型处理上的不足，并在真实世界数据集中表现出卓越性能。

**AI_Comments:** 该论文的创新点在于结合了知识增强和情感引导，以解决多模态假新闻检测中的现有难题。利用LVLM进行图像和文本的语义理解及知识扩展，以及通过平衡学习对情感类型进行细粒度建模，是其独特之处。这种方法有望显著提升假新闻检测的准确性和鲁棒性，对于打击社交媒体上的虚假信息具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体上错误信息的泛滥使得准确检测多模态假新闻成为关键研究焦点。然而，现有研究未能充分理解图像语义，模型在文本信息有限的情况下难以辨别新闻真实性，同时，对所有情感类型新闻一视同仁的处理方式导致性能下降。

**Method:** 我们提出了一个新颖的知识增强与情感引导网络（KEN）。一方面，利用LVLM强大的语义理解和世界知识，为图像生成全面的描述，并为文本检索证据以打破信息孤岛。另一方面，通过平衡学习考虑不同情感类型新闻之间的类间差异，实现情感类型与真实性之间关系的细粒度建模。

**Result:** 在两个真实世界数据集上的大量实验证明了我们KEN的优越性。

**Conclusion:** KEN通过结合知识增强和情感引导，有效提升了多模态假新闻的检测性能。

> **ai_Abstract:** 本文提出了一种名为KEN（知识增强与情感引导网络）的新型框架，旨在解决多模态假新闻检测中图像语义理解不足、文本信息有限以及情感类型处理不当的问题。KEN通过利用LVLM进行知识增强，为图像生成详细描述并为文本检索相关证据，同时采用平衡学习来细致地处理不同情感类型新闻的差异。实验结果表明，该方法在真实世界数据集上取得了显著的性能提升。

> **摘要翻译:** 近年来，社交媒体上错误信息的猖獗传播使得准确检测多模态假新闻成为一个关键研究焦点。然而，以往的研究未能充分理解图像的语义，并且模型在有限的文本信息下难以辨别新闻的真实性。同时，对所有情感类型的新闻一视同仁而没有量身定制的方法，进一步导致了性能下降。因此，我们提出了一种新颖的知识增强与情感引导网络（KEN）。一方面，我们有效利用了LVLM强大的语义理解和广泛的世界知识。对于图像，生成的标题提供了对图像内容和场景的全面理解；而对于文本，检索到的证据有助于打破由封闭和有限的文本及上下文引起的信息孤岛。另一方面，我们通过平衡学习考虑了不同情感类型新闻之间的类间差异，实现了情感类型与真实性之间关系的细粒度建模。在两个真实世界数据集上的大量实验证明了我们KEN的优越性。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [215] [Data-Efficient Deep Operator Network for Unsteady Flow: A Multi-Fidelity Approach with Physics-Guided Subsampling](https://arxiv.org/abs/2503.17941)
> *数据高效的非定常流深度算子网络：一种物理引导子采样的多精度方法*

*Sunwoong Yang, Youngkyu Lee, Namwoo Kang* | **Category: physics.flu-dyn, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 深度算子网络, 多精度, 非定常流, 数据高效, 物理引导子采样

**Comment:** 

> **TL;DR:** 该研究提出了一种改进的深度算子网络（DeepONet）框架，通过引入合并网络、迁移学习和物理引导子采样方法，在高精度数据稀缺的情况下，显著提高了非定常流场预测的效率和精度，并减少了对高精度数据的需求。

**AI_Comments:** 该论文在深度算子网络（DeepONet）领域引入了多项重要的创新，特别是有效地解决了高精度模拟中数据稀缺的挑战。合并网络、迁移学习策略和物理引导子采样方法都是提升效率和精度的巧妙途径。预测误差、精度和训练时间上的显著改进，凸显了这项工作在非定常流预测实际应用中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在高精度数据稀缺的情况下，如何高效地进行时空流场预测是一个挑战。本研究旨在解决DeepONet在处理这种数据稀缺性时的效率问题。

**Method:** 本研究提出了一个增强的多精度深度算子网络（DeepONet）框架。其关键创新包括：1. 使用合并网络取代传统的点积操作；2. 采用迁移学习多精度方法，冻结预训练的低精度网络，仅训练合并网络；3. 引入物理引导的子采样方法，根据时间动态策略性地选择高精度训练点。

**Result:** 1. 合并网络使预测误差减少50.4%，精度提高7.57%，训练时间减少96%。2. 迁移学习多精度方法比其他替代方案表现优异高达76%，比单精度训练的精度提高43.7%。3. 物理引导子采样方法在保持可比精度的同时，将高精度样本需求减少40%。总体而言，该框架显著减少了所需的高精度数据集大小，同时保持了预测精度，并持续优于传统基准。

**Conclusion:** 本研究提出的框架能够显著减少高精度数据集的需求，同时保持预测精度，并且相对于传统基准表现出持续的卓越性能。

> **ai_Abstract:** 本研究提出了一种增强的多精度深度算子网络（DeepONet）框架，旨在解决高精度数据稀缺下的时空流场预测问题。该框架整合了创新的合并网络、迁移学习多精度方法和物理引导子采样技术。这些创新共同显著提高了预测精度和效率，大幅缩短了训练时间，并减少了对大量高精度数据集的依赖，其性能优于传统基准。

> **摘要翻译:** 本研究提出了一种增强的多精度深度算子网络（DeepONet）框架，用于在高精度数据稀缺时进行高效的时空流场预测。主要创新包括：用合并网络取代传统的点积操作，使预测误差减少50.4%，精度提高7.57%，同时训练时间减少96%；一种迁移学习多精度方法，冻结预训练的低精度网络，仅训练合并网络，性能优于其他替代方案高达76%，比单精度训练的精度提高43.7%；以及一种物理引导的子采样方法，根据时间动态策略性地选择高精度训练点，在保持可比精度的同时将高精度样本需求减少40%。跨多个分辨率和数据集的综合实验证明，该框架能够显著减少所需的高精度数据集大小，同时保持预测精度，并且相对于传统基准表现出持续的卓越性能。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [345] [Real-time control of a magnetohydrodynamic flow](https://arxiv.org/abs/2507.12479)
> *磁流体动力学流动的实时控制*

*Adam Uchytil, Milan Korda, Jiří Zemánek* | **Category: physics.flu-dyn, cs.SY, eess.SY, 76W05 (Primary) 93C20, 93C55, 65K10 (Secondary)** | **Updated: 2025-07-10**

**Keywords:** 磁流体动力学, 实时控制, 模型预测控制, Koopman算子理论, 洛伦兹力

**Comment:** 18 pages, 6 figures

> **TL;DR:** 本文展示了通过数据驱动的Koopman模型预测控制（MPC）框架，利用洛伦兹力对弱导磁流体动力学（MHD）流动进行实时反馈控制，并成功在标准笔记本电脑上实现。

**AI_Comments:** 这篇论文的创新点在于将Koopman算子理论与模型预测控制（MPC）框架相结合，有效地将复杂的非线性磁流体动力学系统转化为线性表示，从而极大地简化了实时控制问题的求解。其能够在标准笔记本电脑上实现实时控制，显示了该方法的实用性和高效性，在流体控制领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 控制磁流体动力学（MHD）流动以达到预设的速度或涡度模式，解决其非线性动力学问题，并实现实时控制。

**Method:** 该研究通过外部施加电场和磁场产生的洛伦兹力来控制弱导磁流体动力学（MHD）流动。具体方法包括：使用电极和电磁体阵列进行控制；通过平面粒子图像测速（PIV）提供反馈；采用模型预测控制（MPC）框架计算控制信号，该框架通过最小化成本函数进行优化。预测器完全基于数据，利用Koopman算子理论将底层非线性流体动力学线性化。这种线性化使得MPC问题可以通过交替求解两个小型且高效的凸二次规划（QPs）来解决，一个用于电极，一个用于电磁体。

**Result:** 所开发的控制器能够在标准笔记本电脑上以闭环方式实时运行，实现对流动的实时控制。实验证明，该方法成功地将流动塑形以匹配一系列参考速度场和时变涡度场。

**Conclusion:** 本研究成功开发并演示了一种基于数据驱动Koopman理论的MPC框架，实现了对磁流体动力学流动的实时、高效控制，为复杂流体系统的精确控制提供了有效途径。

> **ai_Abstract:** 该论文展示了一种实时反馈控制弱导磁流体动力学（MHD）流动的方法。通过利用洛伦兹力以及电极和电磁体阵列，结合平面粒子图像测速（PIV）反馈，实现了对流体速度或涡度模式的精确引导。核心控制策略是基于数据驱动的Koopman算子理论构建的线性模型预测控制（MPC）框架，该框架能将非线性流体动力学线性化，从而将复杂的优化问题分解为可高效求解的凸二次规划（QPs）。该控制器可在标准笔记本电脑上实时运行，实验证明其能有效将流动塑形以匹配各种预设模式。

> **摘要翻译:** 我们展示了通过外部施加的电场和磁场产生的洛伦兹力，对弱导磁流体动力学（MHD）流动进行反馈控制。具体来说，我们使用围绕和位于流体储层下方布置的电极和电磁体阵列，将电解质的流动引导至预设的速度或涡度模式，并通过平面粒子图像测速（PIV）提供反馈。控制是使用模型预测控制（MPC）框架实现的，其中控制信号通过最小化流动预测演变过程中的成本函数来计算。预测器完全基于数据，使用Koopman算子理论构建，这使得底层非线性流体动力学能够以线性方式表示。这种线性化使得MPC问题可以通过在两个小型且高效可解的凸二次规划（QPs）之间交替求解来解决：一个用于电极，一个用于电磁体。由此产生的控制器在标准笔记本电脑上以闭环方式运行，实现了流动的实时控制。我们通过实验展示了该方法的功能，在实验中，流动被塑形以匹配一系列参考速度场和时变涡度场。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [230] [Interpretable Transformation and Analysis of Timelines through Learning via Surprisability](https://arxiv.org/abs/2503.04502)
> *通过可解释的惊喜学习进行时间线转换与分析*

*Osnat Mokryn, Teddy Lazebnik, Hagit Ben Shoshan* | **Category: stat.ME, cs.AI, cs.IT, math.IT** | **Updated: 2025-07-17**

**Keywords:** 时间线分析, 惊喜度, 异常检测, 可解释性, 高维数据

**Comment:** Accepted for Publication in Chaos, May 2025

> **TL;DR:** 提出一种基于“惊喜度”的新方法LvS，用于转换和分析高维时间线数据，有效识别异常和离群值。

**AI_Comments:** LvS的创新之处在于将认知科学中的“惊喜度”概念引入高维时间线数据分析，提供了一种新颖且可解释的异常检测和特征识别方法。它克服了传统方法在高维、复杂和稀疏数据上的局限性，特别强调了“可解释性”，这对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 传统分析技术难以处理高维、复杂分布和稀疏的时间线数据，导致难以有效提取有意义的洞察并识别趋势特征、离群值和异常。

**Method:** 提出“通过惊喜学习”（Learning via Surprisability, LvS）方法，受认知科学中“惊喜度”概念启发，通过形式化与预期行为的偏差来量化和优先处理时间序列数据中的异常。LvS将注意力认知理论与计算方法结合，以保留关键上下文的方式检测异常和变化。

**Result:** LvS转换能够高效且可解释地识别时间线中的离群值、异常和最具可变性的特征。在传感器数据、全球死亡原因数据集和美国总统国情咨文文本语料库三个高维时间线用例中证明了其有效性。

**Conclusion:** LvS提供了一种新的视角来解释复杂数据集，通过其可解释的转换能力，有效解决了高维时间线数据分析中的挑战，并成功识别了异常和关键特征。

> **ai_Abstract:** 本文提出一种名为“通过惊喜学习”（LvS）的新方法，灵感来源于认知科学中的“惊喜度”概念，旨在解决高维时间线数据分析中传统方法面临的挑战。LvS通过量化数据偏离预期行为的程度来识别和优先处理时间序列中的异常和离群值，并能有效揭示最具变化的特征。该方法已在多种高维时间线数据集上得到验证，为复杂时间数据的解释和异常检测提供了可解释且高效的工具。

> **摘要翻译:** 高维时间线数据的分析以及离群值和异常的识别在传感器读数、生物医学数据、历史记录和全球统计等不同领域至关重要。然而，传统的分析技术常常面临高维度、复杂分布和稀疏性等挑战。这些限制阻碍了从复杂时间数据集中提取有意义洞察的能力，使得难以有效识别趋势特征、离群值和异常。受“惊喜度”——一个描述人类如何本能地关注意外偏差的认知科学概念——的启发，我们提出了“通过惊喜学习”（LvS），一种用于转换高维时间线数据的新方法。LvS通过形式化与预期行为的偏差来量化和优先处理时间序列数据中的异常。LvS将注意力认知理论与计算方法相结合，以保留关键上下文的方式检测异常和变化，为解释复杂数据集提供了一个新视角。我们在三个高维时间线用例中展示了LvS的实用性：传感器数据的时间序列、多年的全球死亡原因数据集以及包含两个多世纪美国总统国情咨文的文本语料库。我们的结果表明，LvS转换能够高效且可解释地识别时间线中的离群值、异常以及最具可变性的特征。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [385] [Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data](https://arxiv.org/abs/2507.08773)
> *总/对偶相关/相干性、冗余/协同、复杂性和O-信息，用于实值和复值多变量数据*

*Roberto D. Pascual-Marqui, Kieko Kochi, Toshihiko Kinoshita* | **Category: stat.ME, cs.IT, math.IT, math.ST, stat.TH** | **Updated: 2025-07-16**

**Keywords:** 信息论度量, 总相关, O-信息, 冗余-协同, 多变量数据

**Comment:** Version 2 fixed: (A) header now includes DOI link to paper; (B)
  figure 1 now has correct AR coeffs; (C) link to software. Version 3: section
  4d was modified to clarify the problem with the TC equation in the literature
  that although formally incorrect, was correctly applied in those cited papers

> **TL;DR:** 本文提出了多种信息论度量（如总相关、O-信息、冗余-协同指数）的公式，并对其进行了推广，以更好地分析结构化多变量数据和量化变量间连接的贡献。

**AI_Comments:** 这篇论文通过系统地推导和推广多种信息论度量，为分析复杂多变量数据提供了更精细的工具。其创新之处在于对DTC的深入解释、引入结构化信息度量（如结构化O-信息）以捕捉传统方法可能遗漏的组间协同作用，以及提出量化变量间连接贡献的框架。这些进展对于理解神经科学、金融等领域中的复杂系统信息流和相互作用具有重要意义，增强了信息论在处理真实世界复杂数据时的实用性和精确性。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在提出总相关/相干性(TC)、对偶总相关/相干性(DTC)、O-信息、TSE复杂度以及冗余-协同指数(RSI)等信息论度量的公式，并针对结构化变量组推广这些度量，以及量化变量间连接对系统度量的贡献。

**Method:** 假设高斯分布，提出了多种信息论度量的公式，并利用协方差矩阵及其逆矩阵的性质进行推导。特别地，将DTC解释为逆Wishart对的Kullback-Leibler散度。其次，引入了这些度量对结构化变量组的推广，例如结构化O-信息。第三，提出了一个量化变量间“连接”对系统TC、DTC、O-信息和TSE复杂度贡献的框架。最后，提出了冗余-协同指数的推广，用于量化变量组对系统冗余-协同平衡的贡献。

**Result:** 导出了TC、DTC、O-信息、TSE复杂度、RSI等信息论度量的公式。DTC被解释为逆Wishart对的Kullback-Leibler散度，揭示了其作为“总偏相关”度量的含义。提出了一种结构化O-信息度量，能够正确报告组间协同作用，解决了传统O-信息可能遗漏的问题。开发了量化变量间连接对系统信息度量贡献的框架，并推广了冗余-协同指数。所导出的表达式直接适用于其他椭圆分布的数据。

**Conclusion:** 本文为分析实值和复值多变量数据提供了全面的信息论度量框架，包括对现有度量的详细公式化、对结构化数据的推广以及量化变量间连接贡献的方法，这些都增强了多变量信息分析的能力。

> **ai_Abstract:** 本文首先在高斯假设下，推导并呈现了总相关/相干性、对偶总相关/相干性、O-信息、TSE复杂度和冗余-协同指数等信息论度量的具体公式。文中详细阐释了对偶总相关/相干性作为总偏相关度量的解释。其次，研究引入了这些度量针对结构化变量组的泛化方法，特别是提出了一种改进的结构化O-信息度量，能够有效识别多组变量间的协同作用。此外，论文还建立了一个框架来量化变量间连接对系统整体信息度量的贡献，并推广了冗余-协同指数以评估变量组对系统冗余-协同平衡的影响。最终，研究指出这些推导出的表达式同样适用于其他椭圆分布的数据。

> **摘要翻译:** 首先，假设高斯分布，提出了以下信息论度量的方程：总相关/相干性（TC）、对偶总相关/相干性（DTC）、O-信息、TSE复杂度和冗余-协同指数（RSI）。由于这些度量是协方差矩阵“S”及其逆矩阵“S^-1”的函数，因此相关的Wishart和逆Wishart分布值得注意。DTC被证明是逆Wishart对“S^-1”及其对角矩阵“D=diag(S^-1)”的Kullback-Leibler（KL）散度，这阐明了其作为“总偏相关”度量的解释，即-lndetP，测试假设H0: P=I，其中“P”是标准化逆协方差（即P=(D^-1/2)(S^-1)(D^-1/2)）。本文的第二个目标是引入所有这些度量对结构化变量组的推广。例如，考虑三个或更多组，每组包含三个或更多变量，每组内主要表现为冗余，但组间存在协同相互作用。O-信息将遗漏组间协同作用（因为冗余在系统中更常发生）。相比之下，本文提出的结构化O-信息度量将正确报告组间的主要协同作用。这是向结构化多变量信息度量迈出的相关推广。第三个目标是提出一个框架，用于量化变量间“连接”对系统TC、DTC、O-信息和TSE复杂度的贡献。第四个目标是提出冗余-协同指数的推广，用于量化变量组对系统冗余-协同平衡的贡献。最后，结果表明这里推导出的表达式直接适用于来自其他几种椭圆分布的数据。所有程序代码、数据文件和可执行文件均可获取（https://osf.io/jd37g/）。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [495] [Revisiting the Berkeley Admissions data: Statistical Tests for Causal Hypotheses](https://arxiv.org/abs/2502.10161)
> *重温伯克利招生数据：因果假设的统计检验*

*Sourbh Bhadane, Joris M. Mooij, Philip Boeken, Onno Zoeter* | **Category: stat.ME, cs.CY, math.ST, stat.ML, stat.TH** | **Updated: 2025-07-17**

**Keywords:** 因果推断, 公平性, 辛普森悖论, 统计检验, 伯克利招生

**Comment:** Accepted to UAI 2025

> **TL;DR:** 本文通过因果视角重新审视了伯克利招生数据中的辛普森悖论，并引入了一种基于Pearl工具变量不等式的因果假设统计检验方法，以更原则性地理解因果假设检验和公平性。

**AI_Comments:** 本文的创新之处在于将因果推理方法应用于公平性分析，并针对辛普森悖论这一经典问题提出了新的统计检验方法。通过使用Pearl的工具变量不等式，该研究提供了一种更严谨的框架来评估观测数据中的因果公平性假设，超越了传统相关性分析的局限性。其重要性在于为公平性研究提供了一个强有力的因果分析工具，有助于避免因果混淆，从而得出更准确的结论。

<details>
  <summary>Details</summary>

**Motivation:** 通过基于相关性的概念来推理公平性充满了陷阱，伯克利招生案例是辛普森悖论的一个经典例子。研究的动机是希望通过因果视角对该案例进行分析，并开发一种更原则性的因果假设检验和公平性理解方法。

**Method:** 本文通过因果视角对伯克利研究生招生案例进行推理。在此过程中，引入了一种基于Pearl工具变量不等式（Pearl 1995）的因果假设统计检验。比较了基于因果模型上的图示、反事实和干预查询的不同因果公平性概念，并开发了仅使用观测数据的这些概念的统计检验。

**Result:** 研究了不同概念之间的逻辑关系，并表明虽然这些概念可能不等价，但在本案例中，它们相应的统计检验结果是一致的。

**Conclusion:** 我们认为，彻底的基于案例的因果分析有助于对因果假设检验和公平性形成更原则性的理解。

> **ai_Abstract:** 本文重新审视了伯克利招生数据中的辛普森悖论，指出仅凭相关性推理公平性的局限性。研究人员通过引入基于Pearl工具变量不等式的统计检验，从因果视角分析了该案例。论文比较了基于图示、反事实和干预查询的因果公平性概念，并开发了仅使用观测数据的统计检验。研究发现，尽管这些概念可能不等价，但其统计检验在本案例中结果一致。最终，作者认为这种基于案例的因果分析有助于更深入理解因果假设检验和公平性。

> **摘要翻译:** 通过基于相关性的概念来推理公平性充满了陷阱。1973年加州大学伯克利分校研究生招生案例（Bickel et. al. 1975）就是这种陷阱的一个经典例子，即辛普森悖论。在所有院系的汇总数据中，男性和女性申请者之间招生率的差异，在按院系检查招生率时就消失了。我们通过因果视角对伯克利研究生招生案例进行推理。在此过程中，我们引入了一种基于Pearl工具变量不等式（Pearl 1995）的因果假设统计检验。我们比较了基于因果模型上的图示、反事实和干预查询的不同因果公平性概念，并开发了仅使用观测数据的这些概念的统计检验。我们研究了概念之间的逻辑关系，并表明虽然概念可能不等价，但在本案例中，它们相应的统计检验结果是一致的。我们相信，彻底的基于案例的因果分析有助于对因果假设检验和公平性形成更原则性的理解。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [587] [Formalising causal inference as prediction on a target population](https://arxiv.org/abs/2407.17385)
> *将因果推断形式化为目标人群上的预测*

*Benedikt Höltgen, Robert C. Williamson* | **Category: stat.ME, cs.LG, econ.EM** | **Updated: 2025-07-17**

**Keywords:** 因果推断, 潜在结果, 目标人群, 预测, 可检验假设

**Comment:** Presented at the Humans, Algorithmic Decision-Making and Society
  Workshop at ICML 2024

> **TL;DR:** 本文提出了一种新的因果推断框架，将因果推断视为对有限人群的治疗预测，并使所有假设都可追溯检验，解决了传统潜在结果框架在纳入目标人群和假设可测性方面的局限。

**AI_Comments:** 这篇论文的创新点在于它提供了一个更实用的因果推断框架，通过将因果推断重新定义为针对目标人群的治疗预测，并明确提出所有假设都可追溯检验。这一点对于实际应用和决策制定非常重要，因为它增强了模型的可解释性和错误诊断能力，弥补了传统方法在处理实际目标人群和假设透明度方面的不足。其重要性在于提升了因果推断的科学严谨性和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的潜在结果因果模型框架在将目标人群纳入其分析中存在困难，并且其归纳性假设（如抽象抽样和独立性假设）不易直接检验，这使得在决策制定时难以明确处理与目标人群的关系。本文旨在解决这一局限性。

**Method:** 本文开发了一种新的因果推断框架版本，将因果推断视为对有限人群的治疗方式预测。在这个新框架中，所有的假设都可以追溯检验。

**Result:** 在新框架下，不仅可以直接测试预测结果，而且当预测失败时，可以追溯并调查错误来源。此外，由于与原始框架的紧密联系，既定的方法仍然可以在这个新框架下进行分析。

**Conclusion:** 本文成功地将因果推断形式化为目标人群上的治疗预测，并确保所有假设都可追溯检验，从而提供了一个更具可操作性和可验证性的因果推断方法，同时兼容现有方法。

> **ai_Abstract:** 本文针对Neyman和Rubin的潜在结果框架在纳入目标人群和假设可测性方面的不足，提出了一种新的因果推断框架。该框架将因果推断重新定义为对有限人群的治疗方式预测，并强调所有假设均可事后检验。这一创新使得预测不仅可以直接测试，而且在预测失败时能够追溯错误来源，同时保持了与现有因果推断方法的兼容性。

> **摘要翻译:** 因果建模的标准方法，尤其是在社会和健康科学中，是Neyman和Rubin提出的潜在结果框架。在这个框架中，观察结果被认为是来自感兴趣变量的分布，目标是识别这个分布的参数。尽管声明的目标通常是为某个目标人群的决策提供信息，但没有直接的方法将这些目标人群纳入框架中。相反，这个框架中的归纳假设采取抽象抽样和独立性假设的形式，而不是对观察到的样本和目标人群之间的关系进行建模。在本文中，我们开发了该框架的一个版本，将因果推断理解为对有限人群的治疗方式预测，其中所有假设都可以追溯检验；这意味着人们不仅可以测试预测本身（没有任何根本问题），而且当预测失败时，还可以调查错误来源。由于与原始框架的紧密联系，既定的方法仍然可以在新框架下进行分析。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [622] [Optimal Empirical Risk Minimization under Temporal Distribution Shifts](https://arxiv.org/abs/2507.13287)
> *时间分布偏移下的最优经验风险最小化*

*Yujin Jeong, Ramesh Johari, Dominik Rothenhäusler, Emily Fox* | **Category: stat.ME, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 时间分布偏移, 经验风险最小化, RIDER, 随机分布偏移, 预测性能

**Comment:** 

> **TL;DR:** 本文介绍了RIDER，一种在时间分布偏移下推导出最优加权经验风险最小化过程的方法，并在多个真实世界任务中展示了其优越的预测性能。

**AI_Comments:** RIDER的创新之处在于其理论基础，即随机分布偏移模型，并能够统一解释多种现有加权方案。其重要性在于为应对动态环境下的时间分布偏移提供了一种有效的解决方案，并通过实际应用展示了其在预测性能上的显著提升。

<details>
  <summary>Details</summary>

**Motivation:** 在动态演变的环境中训练和部署的机器学习模型面临时间分布偏移的挑战，这会影响其性能。

**Method:** 本文引入了RIDER（Dynamically Evolving Regimes下的风险最小化），该方法在随机分布偏移模型下推导出最优加权经验风险最小化过程。该模型认为随机偏移是数据生成过程中众多不可预测变化的叠加。

**Result:** RIDER作为微调步骤应用于Yearbook数据集时，在Wild-Time中的一系列基准方法上持续提高了样本外预测性能。此外，RIDER在预测股市波动和预测纽约市出租车行程持续时间这两个真实世界任务中，优于标准加权策略。

**Conclusion:** RIDER方法能够在时间分布偏移下实现最优的经验风险最小化，并显著提升了机器学习模型在动态环境中的预测性能。

> **ai_Abstract:** 本文提出了一种名为RIDER的新方法，用于在时间分布偏移下进行最优经验风险最小化。该方法基于随机分布偏移模型，并能自然地包含多种现有加权方案。实验证明，RIDER在多个数据集和真实世界任务中，相比传统方法和标准加权策略，显著提升了模型的预测性能。

> **摘要翻译:** 时间分布偏移对在动态演变环境中训练和部署的机器学习模型构成了关键挑战。本文介绍了RIDER（动态演进制度下的风险最小化），它在时间分布偏移下推导出最优加权经验风险最小化过程。我们的方法在理论上以随机分布偏移模型为基础，其中随机偏移是数据生成过程中众多不可预测变化的叠加。我们表明，常见的加权方案，例如汇集所有数据、指数加权数据以及仅使用最新数据，在我们的框架中自然地作为特例出现。我们证明，当RIDER作为微调步骤应用于Yearbook数据集时，在Wild-Time中的一系列基准方法上，它始终能提高样本外预测性能。此外，我们还表明，在另外两个真实世界任务中：预测股市波动和预测纽约市出租车行程持续时间，RIDER的表现优于标准加权策略。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [685] [Differentially Private Conformal Prediction via Quantile Binary Search](https://arxiv.org/abs/2507.12497)
> *通过分位数二分搜索实现差分隐私共形预测*

*Ogonnaya M. Romanus, Roberto Molinari* | **Category: stat.ME, cs.LG, stat.AP, stat.CO, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 差分隐私, 共形预测, 分位数二分搜索, 隐私保护, 不确定性量化

**Comment:** 

> **TL;DR:** 本文提出了一种名为P-COQS的通用差分隐私共形预测方法，通过适应一种现有的随机二分搜索算法来计算校准阶段的差分隐私分位数，从而保证预测集的隐私性，并在实验中表现出对隐私噪声的鲁棒性以及在经验覆盖率、效率和信息量方面优于现有替代方案。

**AI_Comments:** 本文的创新点在于将差分隐私的概念扩展到了共形预测的校准阶段，填补了现有DP方法在该领域空白。通过适应已有的随机二分搜索算法来计算DP分位数，提供了一种实用的解决方案。其重要性在于，在不确定性量化中，特别是在处理敏感数据时，能够提供具有隐私保证的预测集。尽管提到在有限样本下可能存在轻微的欠覆盖，但其在多个基准数据集上的良好表现证明了方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 大多数差分隐私（DP）方法侧重于限制学习器基于训练数据产生的隐私泄露，但很少有方法考虑当程序涉及校准数据集时的泄露，这在共形预测（CP）等不确定性量化方法中很常见。由于这方面的现有方法有限，因此需要一种通用的DP共形预测方法。

**Method:** 本文提出了一种名为Private Conformity via Quantile Search (P-COQS) 的通用差分隐私共形预测方法。该方法通过适应一种现有的随机二分搜索算法，在共形预测的校准阶段计算差分隐私分位数，从而保证了后续预测集的隐私性。

**Result:** P-COQS 方法在有限样本校准集下可能导致轻微的欠覆盖，但广泛的实证结果表明它通常能达到所需的水平。实验结果表明，该方法对隐私噪声具有鲁棒性，并且在经验覆盖率、效率和信息量方面优于当前的差分隐私替代方案。具体而言，P-COQS在所有实验设置中都能生成更小的共形预测集，同时实现所需的覆盖率和隐私保证。

**Conclusion:** 本文提出的P-COQS方法为共形预测提供了一种有效的差分隐私解决方案，它在隐私保护的同时，保持了良好的预测性能和效率，并且在多种基准数据集上表现出色，克服了传统DP方法在校准数据隐私方面的不足。

> **ai_Abstract:** 本文提出了一种名为P-COQS的通用差分隐私共形预测方法，旨在解决校准数据集中的隐私泄露问题。P-COQS通过在共形预测的校准阶段应用差分隐私分位数二分搜索算法，确保预测集的隐私性。尽管在有限样本下可能存在轻微的欠覆盖，但实验结果表明，P-COQS对隐私噪声具有鲁棒性，并在经验覆盖率、效率和信息量方面优于现有差分隐私替代方案，能生成更小且同时满足所需覆盖率和隐私保证的预测集。

> **摘要翻译:** 大多数差分隐私（DP）方法侧重于限制学习器基于训练数据产生的隐私泄露，而较少有方法考虑当程序涉及校准数据集时的泄露，这在共形预测（CP）等不确定性量化方法中很常见。由于这方面的现有方法有限，在这项工作中，我们提出了一种通用的DP共形预测方法，我们称之为通过分位数搜索的私有共形性（P-COQS）。所提出的方法适应了一种现有的随机二分搜索算法，用于在CP的校准阶段计算DP分位数，从而保证后续预测集的隐私性。然而，这会以在使用有限样本校准集时略低于所需（1 - α）水平的覆盖率为代价（尽管广泛的实证结果表明P-COQS在所考虑的案例中通常能达到所需水平）。为了确认所适应算法的特性并量化后续CP的近似覆盖保证，我们进行了广泛的实验，以检查隐私噪声、样本大小和显著性水平对我们方法与现有替代方案性能的影响。此外，我们在几个基准数据集上对我们的方法进行了实证评估，包括CIFAR-10、ImageNet和CoronaHack。我们的结果表明，所提出的方法对隐私噪声具有鲁棒性，并且在经验覆盖率、效率和信息量方面相对于当前的DP替代方案表现良好。具体而言，结果表明P-COQS在所有这些实验设置中都能生成更小的共形预测集，同时实现所需的覆盖率和隐私保证。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [236] [Just Verification of Mutual Exclusion Algorithms](https://arxiv.org/abs/2507.13198)
> *互斥算法的公正验证*

*Rob van Glabbeek, Bas Luttik, Myrthe Spronck* | **Category: cs.LO, cs.DC, F.3.1** | **Updated: 2025-07-17**

**Keywords:** 互斥算法, 模型检测, 公正性, 活性属性, 共享寄存器

**Comment:** An abbreviated version of this paper will appear in Proc. CONCUR'25

> **TL;DR:** 本文通过模型检测并采用公正性作为完备性准则，验证了多种互斥算法的正确性。

**AI_Comments:** 该论文的创新点在于引入“公正性”作为模型检测中验证活性属性的完备性准则，这有助于更准确地识别算法缺陷并避免虚假反例。其重要性在于为互斥算法的严格验证提供了一个实用的框架，并指出了实际算法中可能存在的漏洞。

<details>
  <summary>Details</summary>

**Motivation:** 验证多种互斥算法的正确性，特别是对于活性属性的验证，需要一个完备性准则来消除虚假反例。

**Method:** 使用模型检测来验证互斥算法的正确性；针对活性属性的验证，采用“公正性”（justness）作为完备性准则；公正性依赖于并发关系，考虑了多种并发关系来模拟共享寄存器工作的不同假设；算法通信通过共享读/写寄存器，这些寄存器可以是原子或非原子的。

**Result:** 成功验证了多种互斥算法的正确性；提出了展示一些算法违反正确性属性的执行示例；在某些情况下提出了改进建议。

**Conclusion:** 论文通过模型检测和公正性准则成功验证了互斥算法，并识别了缺陷，提出了改进。

> **ai_Abstract:** 本文利用模型检测技术，对通过共享读/写寄存器（包括原子和非原子类型）进行通信的多种互斥算法的正确性进行了验证。特别地，为了验证活性属性并消除虚假反例，研究人员引入了“公正性”作为完备性准则，并探讨了多种并发关系以适应不同的寄存器工作假设。研究结果揭示了一些算法存在的正确性问题，并通过具体的执行示例进行了展示，同时提出了一些改进措施。

> **摘要翻译:** 我们通过模型检测验证了各种互斥算法的正确性。我们研究了通过共享读/写寄存器进行通信的算法，其中这些寄存器可以是原子的或非原子的。为了验证活性属性，有必要假设一个完备性准则来消除虚假反例。我们使用公正性作为完备性准则。公正性取决于并发关系；我们考虑了几种这样的关系，模拟了共享寄存器工作的不同假设。我们展示了证明几种算法违反正确性属性的执行，并在某些情况下提出了改进建议。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='q-biope'></a>
## q-bio.PE 

### [267] [Investigating Forecasting Models for Pandemic Infections Using Heterogeneous Data Sources: A 2-year Study with COVID-19](https://arxiv.org/abs/2507.12966)
> *使用异构数据源调查大流行感染预测模型：一项为期两年的COVID-19研究*

*Zacharias Komodromos, Kleanthis Malialis, Panayiotis Kolios* | **Category: q-bio.PE, cs.LG** | **Updated: 2025-07-17**

**Keywords:** COVID-19, 预测模型, 异构数据, 大流行, 塞浦路斯

**Comment:** Keywords: epidemiology, pandemic forecasting, COVID-19, infections,
  machine learning Accepted: IEEE Conference on Computational Intelligence in
  Bioinformatics and Computational Biology (CIBCB) 2025

> **TL;DR:** 本研究利用为期两年的COVID-19异构数据集（包括流行病学数据、疫苗接种记录、政策措施和天气条件），在塞浦路斯进行大规模病例研究，以分析感染趋势、评估预测性能并检查外部因素对疾病动态的影响，旨在改善未来的大流行准备和应对策略。

**AI_Comments:** 该研究的创新之处在于其对COVID-19预测使用了多源异构数据（流行病学、疫苗接种、政策、天气），并进行了为期两年的大规模案例研究。这对于理解复杂的大流行动态和改进未来的预测模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** COVID-19大流行造成了广泛的健康、经济和社会混乱，需要改进预测模型以增强对未来疫情的准备和响应，并减轻其社会和经济影响。

**Method:** 本文对塞浦路斯的COVID-19预测进行了大规模案例研究，利用为期两年的数据集，该数据集整合了流行病学数据、疫苗接种记录、政策措施和天气条件。研究分析了感染趋势，评估了预测性能，并检查了外部因素对疾病动态的影响。

**Result:** 通过分析感染趋势、评估预测性能以及检查外部因素对疾病动态的影响，获得了有助于改善大流行准备和应对策略的见解。

**Conclusion:** 本研究获得的见解有助于改善大流行病的准备和应对策略。

> **ai_Abstract:** 本文对塞浦路斯的COVID-19预测进行了为期两年的大规模案例研究，整合了流行病学、疫苗接种、政策和天气等多源异构数据。研究旨在分析感染趋势、评估预测性能并探讨外部因素对疾病动态的影响，以期为未来的大流行准备和响应提供改进的见解。

> **摘要翻译:** COVID-19大流行于2019年12月出现，造成了广泛的健康、经济和社会混乱。快速的全球传播使医疗系统不堪重负，导致高感染率、住院率和死亡率。为了最大限度地减少传播，各国政府实施了几项非药物干预措施，如封锁和旅行限制。这些措施在控制传播方面虽然有效，但也带来了重大的经济和社会挑战。尽管世界卫生组织于2023年5月宣布COVID-19不再是全球卫生紧急事件，但其影响持续存在，塑造着公共卫生战略。大流行期间收集的大量数据为疾病动态、传播和干预措施有效性提供了宝贵的见解。利用这些见解可以改进预测模型，增强对未来疫情的准备和响应，同时减轻其社会和经济影响。本文介绍了塞浦路斯COVID-19预测的一项大规模案例研究，利用了一个为期两年的数据集，该数据集整合了流行病学数据、疫苗接种记录、政策措施和天气条件。我们分析了感染趋势，评估了预测性能，并检查了外部因素对疾病动态的影响。所获得的见解有助于改善大流行病的准备和应对策略。

</details>

[⬆️ 返回分类顶部](#q-biope) | [⬆️ 返回总目录](#toc)

---

### [444] [Life Finds A Way: Emergence of Cooperative Structures in Adaptive Threshold Networks](https://arxiv.org/abs/2507.13253)
> *生命自寻出路：自适应阈值网络中合作结构的涌现*

*Sean P. Maley, Carlos Gershenson, Stuart A. Kauffman* | **Category: q-bio.PE, cs.SI** | **Updated: 2025-07-17**

**Keywords:** 合作结构, 自适应阈值网络, 网络动力学, 涌现, 相变

**Comment:** 

> **TL;DR:** 研究发现，即使在广泛的对抗性互动中，自适应阈值网络中也能涌现出高阶合作组织，并通过一个新模型揭示了系统元素数量增加导致的质变。

**AI_Comments:** 这项研究通过一个创新的随机阈值有向网络模型，解决了合作结构如何在竞争环境中涌现这一长期存在的问题。其引入节点特定特征和动态链接的机制，使得模型能够更真实地模拟复杂系统的演化。发现即使在对抗性互动中也能涌现高阶组织，并揭示了系统规模与质变的关系，为理解生命演化和复杂自适应系统提供了重要见解。该框架的普适性使其在生物和经济等多个领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 长期以来，关于新组织层次如何演化存在争议，尤其是在合作必须战胜竞争的背景下。论文旨在探究合作与对抗偏向如何影响网络动力学，以及生命演化中自催化集合涌现的前提条件。

**Method:** 本文提出了一个随机阈值有向网络模型，该模型整合了节点特定特征、动态边缘形成和节点移除，以模拟任意程度的合作与竞争。在该框架中，内在节点值通过各种阈值规则决定有向链接，生成带有符号边缘（反映支持/对抗，标记为“帮助”/“伤害”）的多有向图，最终产生两个并行但相互依赖的阈值图。该方法还融入了时间增长和节点更替。

**Result:** 研究发现，即使在普遍存在的对抗性互动中，高阶组织也能涌现。通常观察到，系统中元素数量的定量增加导致定性转变。模型揭示了连接性和恢复力方面的相变。研究结果扩展了经典的随机阈值和Erdős-Rényi模型，为生物和经济背景下的自适应系统提供了新见解，并强调了在集体可供性集合中的应用。

**Conclusion:** 该框架对于预测正在进行的土壤微生物群落实验结果将非常有用。

> **ai_Abstract:** 本文通过引入一个创新的随机阈值有向网络模型，探讨了在合作与竞争并存的环境中，高阶合作结构如何涌现。该模型整合了节点特定特征、动态链接形成和节点移除，模拟了复杂的相互作用，并发现即使在广泛的对抗性背景下，系统仍能形成合作组织。研究揭示了系统元素数量增加导致的连接性和恢复力的相变，扩展了现有网络模型，为理解生物和经济中的自适应系统提供了新的视角，特别是在集体可供性集合和微生物群落研究中具有潜在应用。

> **摘要翻译:** 关于新组织层次如何演化，一直存在长期争论。这似乎不太可能，因为合作必须战胜竞争。一个被深入研究的例子是自催化集合的涌现，这似乎是生命进化的先决条件。我们使用一个简单的模型，研究了合作与对抗的不同偏向如何塑造网络动力学，揭示了即使在普遍存在的对抗性互动中，高阶组织也能涌现。总的来说，我们观察到系统中元素数量的定量增加会导致定性转变。
我们提出了一个随机阈值有向网络模型，该模型整合了节点特定特征与动态边缘形成和节点移除，模拟了任意程度的合作与竞争。在我们的框架中，内在节点值通过各种阈值规则决定有向链接。我们的模型生成了一个带有符号边缘（反映支持/对抗，标记为“帮助”/“伤害”）的多有向图，最终产生了两个并行但相互依赖的阈值图。在我们的方法中融入时间增长和节点更替，可以探索群落的进化、适应和潜在崩溃，并揭示了连接性和恢复力方面的相变。
我们的发现扩展了经典的随机阈值和Erdős-Rényi模型，为生物和经济背景下的自适应系统提供了新见解，并强调了在集体可供性集合中的应用。该框架也应有助于进行预测，这些预测将通过正在进行的土壤微生物群落实验进行检验。

</details>

[⬆️ 返回分类顶部](#q-biope) | [⬆️ 返回总目录](#toc)

---

<a id='physicsapp-ph'></a>
## physics.app-ph 

### [303] [Wireless Multi-Port Sensing: Virtual-VNA-Enabled De-Embedding of an Over-the-Air Fixture](https://arxiv.org/abs/2507.12909)
> *无线多端口传感：支持虚拟VNA的空中夹具去嵌入*

*Philipp del Hougne* | **Category: physics.app-ph, eess.SP** | **Updated: 2025-07-17**

**Keywords:** 无线传感, 多端口, 虚拟VNA, 去嵌入, 散射参数

**Comment:** 10 pages including 4 figures

> **TL;DR:** 本文提出了一种无线多端口传感技术，利用多端口反向散射调制和“虚拟VNA”方法，在空中（OTA）确定多端口待测设备（DUT）的散射参数，并通过实验验证了该方法。

**AI_Comments:** 本文提出了一种新颖的无线多端口传感技术，通过引入“虚拟VNA”概念，解决了在空中（OTA）环境下精确表征和去嵌入夹具的难题，从而能够确定待测设备的散射参数。这种方法避免了直接接触，对于RFID和无线生物电子学等需要非接触式测量的应用具有重要意义。其创新之处在于利用可调负载网络和反向散射调制，巧妙地实现了传统VNA在无线环境中的功能。未来的工作可以探索其在更复杂、动态的无线环境中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为了在空中（OTA）确定线性、无源、时不变多端口待测设备（DUT）的散射参数，本文开发了一种多端口反向散射调制技术，以克服传统方法无法直接测量空中夹具的挑战。

**Method:** 该方法首先利用“虚拟VNA”技术，通过连接不可直接访问（NDA）天线到可调负载网络并测量可访问天线端口的散射来表征空中（OTA）夹具。其次，将NDA天线连接到DUT并测量可访问天线端口的散射。最后，去嵌入OTA夹具以获取DUT的散射参数。

**Result:** 该技术在2.45 GHz频率下对1端口和5端口DUT进行了实验验证，并在混响室内部的富散射OTA夹具中进行了测试。研究系统地分析了可访问天线数量以及系统模型和可调负载网络特性中各种简化对结果的影响。

**Conclusion:** 本文提出的无线多端口传感技术能够确定OTA环境中DUT的散射参数，并有望应用于RFID和无线生物电子学等领域。

> **ai_Abstract:** 本文提出了一种创新的无线多端口传感技术，通过多端口反向散射调制和“虚拟VNA”方法，实现在空中（OTA）准确测量多端口待测设备（DUT）的散射参数。该方法分三步：首先，利用可调负载网络和虚拟VNA技术表征OTA夹具；其次，测量DUT连接时的散射；最后，去嵌入夹具以获得DUT的散射参数。实验在2.45 GHz频率下对1端口和5端口DUT进行了验证，证明了其有效性，并探讨了系统参数的影响。该技术在RFID和无线生物电子学等领域具有潜在应用。

> **摘要翻译:** 我们开发了一种多端口反向散射调制技术，用于在空中（OTA）确定线性、无源、时不变多端口待测设备（DUT）的散射参数。一组“不可直接访问”（NDA）天线可以在连接到DUT或特定的、已知的、可调负载网络之间切换。波可以通过一组不同的“可访问”天线进行辐射和捕获，这些天线通过OTA与NDA天线耦合。首先，我们基于最近引入的“虚拟VNA”技术来表征可访问天线端口和DUT端口之间的OTA夹具；具体来说，我们将NDA天线连接到可调负载网络，并测量在可调负载网络各种配置下可访问天线端口的散射。其次，我们将NDA天线连接到DUT并测量可访问天线端口的散射。第三，我们去嵌入OTA夹具以获取DUT的散射参数。我们在2.45 GHz频率下对1端口DUT和5端口DUT进行了实验验证，考虑了混响室内部的富散射OTA夹具。我们系统地研究了可访问天线数量以及系统模型和可调负载网络特性中各种可设想的简化所产生的影响。我们的无线多端口传感技术可在RFID和无线生物电子学等领域找到应用。

</details>

[⬆️ 返回分类顶部](#physicsapp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phep'></a>
## astro-ph.EP 

### [308] [CubeSat Orbit Insertion Maneuvering Using J2 Perturbation](https://arxiv.org/abs/2507.13017)
> *CubeSat轨道插入机动利用J2摄动*

*M. Amin Alandihallaj, M. Reza Emami* | **Category: astro-ph.EP, astro-ph.IM, cs.RO** | **Updated: 2025-07-17**

**Keywords:** CubeSat, 轨道插入, J2摄动, 燃料消耗, 轨道机动

**Comment:** Pre-print of IEEE aeroconf paper

> **TL;DR:** 本文提出一种利用地球J2摄动实现CubeSat轨道精确插入的机动序列，能显著减少燃料消耗。

**AI_Comments:** 这篇论文的创新点在于它将通常被视为需要补偿的“扰动”——地球J2摄动，转化为实现轨道调整的“工具”。通过被动利用这一自然现象，该方法能够显著减少CubeSat在轨道插入阶段的燃料消耗，这对于资源受限的CubeSat任务具有重要的实际意义，有助于延长任务寿命和扩展任务能力。

<details>
  <summary>Details</summary>

**Motivation:** CubeSat的精确入轨是一项复杂任务，主要受限于其有限的推进能力和燃料储备，这严重限制了大幅轨道修正的可能性。因此，需要开发更高效的机动技术以确保任务成功。

**Method:** 本文提出一种利用地球扁率引起的自然J2摄动的机动序列。通过利用J2摄动的长期效应，被动影响近地点幅角和升交点赤经等关键轨道参数，从而减少对基于推进的修正需求。该方法通过全面的数值模拟进行了验证，并提供了案例研究。

**Result:** 数值模拟和案例研究表明，所提出的J2增强策略在实现精确轨道插入方面是有效的，与传统方法相比，燃料消耗显著减少。

**Conclusion:** 该方法有望延长CubeSat的运行寿命和能力，为未来的低地球轨道任务提供一个可行的解决方案。

> **ai_Abstract:** 本文提出一种创新的CubeSat轨道插入机动方法，通过巧妙利用地球J2摄动的长期效应，被动调整轨道参数，从而大幅减少对有限燃料推进的需求。该方法通过全面的数值模拟和案例研究得到验证，结果显示与传统方法相比，燃料消耗显著降低。这项技术有望延长CubeSat的任务寿命和能力，为未来的低地球轨道任务提供高效、燃料优化的解决方案。

> **摘要翻译:** 标题：CubeSat轨道插入机动利用J2摄动

摘要：将CubeSat精确插入指定轨道是一项复杂的任务，主要原因是其有限的推进能力和受限的燃料储备，这严重限制了大幅轨道修正的范围。这种限制要求开发更高效的机动技术以确保任务成功。在本文中，我们提出了一种利用地球扁率引起的自然J2摄动的机动序列。通过利用这种摄动的长期效应，可以被动地影响关键轨道参数，如近地点幅角和升交点赤经，从而减少对基于推进的广泛修正的需求。该方法旨在优化CubeSat的轨道插入，并最大限度地减少轨迹调整所需的总燃料，使其特别适用于燃料受限的任务。所提出的方法通过全面的数值模拟进行了验证，这些模拟检查了不同的初始轨道条件和摄动环境。通过案例研究展示了J2增强策略在实现精确轨道插入方面的有效性，与传统方法相比，燃料消耗显著减少。结果强调了这种方法延长CubeSat运行寿命和能力的潜力，为未来的低地球轨道任务提供了可行的解决方案。

</details>

[⬆️ 返回分类顶部](#astro-phep) | [⬆️ 返回总目录](#toc)

---

<a id='physicsplasm-ph'></a>
## physics.plasm-ph 

### [329] [Multiple solutions to the static forward free-boundary Grad-Shafranov problem on MAST-U](https://arxiv.org/abs/2503.05674)
> *MAST-U 上静态正向自由边界 Grad-Shafranov 问题的多重解*

*K. Pentland, N. C. Amorisco, P. E. Farrell, C. J. Ham* | **Category: physics.plasm-ph, cs.NA, math.NA** | **Updated: 2025-07-17**

**Keywords:** Grad-Shafranov 方程, 多重解, 托卡马克, 自由边界, 等离子体平衡

**Comment:** 

> **TL;DR:** 在真实托卡马克几何结构中，首次发现了 Grad-Shafranov 方程的多个平衡解，这对于等离子体建模具有重要意义。

**AI_Comments:** 这项工作首次在实际托卡马克几何中展示了 Grad-Shafranov 方程的多重解，填补了理论与实际应用之间的空白。其创新之处在于使用了先进的求解器和算法来探索这一复杂问题。研究结果对托卡马克等离子体平衡建模具有重要意义，提示了在分析和模拟中需要考虑多重解的可能性，从而可能提高模拟的准确性和可靠性。对积分自由边界条件限制性的讨论也提供了对未来研究方向的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 以前的研究在理想化几何和简化条件下证明了 Grad-Shafranov (GS) 方程存在多个解。然而，在真实世界的托卡马克几何结构中，使用更复杂的电流密度分布和积分自由边界条件（生产级平衡代码常用）时，是否存在多个平衡解的问题一直悬而未决。

**Method:** 本研究使用经过验证的演化平衡求解器 FreeGSNKE 和收缩连续算法，在 MAST-U 托卡马克几何结构中发现了静态正向自由边界 GS 问题的多个解。通过改变等离子体电流、电流密度分布系数或线圈电流来识别和表征不同的平衡解。

**Result:** 发现了静态正向自由边界 Grad-Shafranov 问题的多个解，包括深度和浅层约束的等离子体状态。研究表明，积分自由边界条件的限制性可能阻止了更多平衡解的存在。

**Conclusion:** 这些发现对更广泛的平衡建模具有重要意义，并强调需要探索其他平衡代码和托卡马克中是否存在多个解，以及它们对依赖 GS 平衡的下游模拟的潜在影响。

> **ai_Abstract:** 本研究首次在真实世界的 MAST-U 托卡马克几何结构中，利用 FreeGSNKE 求解器和收缩连续算法，发现了静态正向自由边界 Grad-Shafranov (GS) 方程的多个平衡解，包括不同约束状态的等离子体。这解决了先前仅在理想化条件下发现多解的局限性。研究指出积分自由边界条件的限制性可能限制了更多解的存在，并强调了这些发现对未来托卡马克平衡建模和下游模拟的重要性。

> **摘要翻译:** Grad-Shafranov (GS) 方程是一个非线性椭圆偏微分方程，它控制着托卡马克等离子体的理想磁流体动力学平衡。以前的研究已经证明，在理想化的几何结构中，当使用简化的等离子体电流密度分布和边界条件求解时，GS 方程存在多个解。到目前为止，在真实世界的托卡马克几何结构中，使用更复杂的电流密度分布和积分自由边界条件（生产级平衡代码中常用）时，是否存在多个平衡解的问题一直悬而未决。在这项工作中，我们利用经过验证的演化平衡求解器 FreeGSNKE 和收缩连续算法，在 MAST-U 托卡马克几何结构中发现了静态正向自由边界 GS 问题的多个解。通过改变 GS 方程中的等离子体电流、电流密度分布系数或线圈电流，我们识别并表征了不同的平衡解，包括深度和浅层约束的等离子体状态。我们认为，积分自由边界条件的限制性很可能阻止了更多平衡解的存在，因为它将计算边界上的极向磁通量与内部磁通量全局耦合。最后，我们讨论了这些发现对更广泛的平衡建模的影响，并强调需要探索其他平衡代码和托卡马克中是否存在多个解，以及它们对依赖 GS 平衡的下游模拟的潜在影响。

</details>

[⬆️ 返回分类顶部](#physicsplasm-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [348] [An Algebraic Approach to Asymmetric Delegation and Polymorphic Label Inference (Technical Report)](https://arxiv.org/abs/2504.20432)
> *一种非对称委托和多态标签推断的代数方法（技术报告）*

*Silei Ren, Coşku Acay, Andrew C. Myers* | **Category: cs.PL, cs.CR** | **Updated: 2025-07-16**

**Keywords:** 信息流控制, 非对称委托, 多态标签推断, 代数语义, 非可延展信息流

**Comment:** 

> **TL;DR:** 本文提出一个代数语义框架，用于形式化信息流控制中的非对称委托和多态标签推断，以解决现有标签模型在建模安全假设上的局限性。

**AI_Comments:** 本文创新性地将代数方法引入信息流控制领域，提出了非对称委托的概念，扩展了IFC的表达能力。同时，通过非可延展信息流（NMIF）确保安全性，并结合静态检查算法和多态标签推断，提高了IFC系统的实用性和灵活性，对于去中心化应用的安全策略执行具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有语言级信息流控制（IFC）在设计表达性系统和使用IFC标签建模特定安全假设（如半诚实代理）时面临挑战和局限性。

**Method:** 研究了基于格的IFC标签模型的代数语义，提出了一个语义框架来形式化非对称委托；设计并实现了一种静态检查非可延展信息流（NMIF）的新算法，以及一个支持有界标签多态性的标签推断过程。

**Result:** 该框架支持信息降级并通过非可延展信息流（NMIF）确保安全性；所设计的算法能静态检查NMIF；标签推断过程能高效支持有界标签多态性，允许用户编写对标签通用的代码。

**Conclusion:** 论文通过提出代数语义框架和相关算法，为信息流控制中的非对称委托和多态标签推断提供了实用的解决方案，提高了IFC系统的表达性和安全性。

> **ai_Abstract:** 本文针对语言级信息流控制（IFC）中现有标签模型在建模特定安全假设时的局限性，提出了一种基于代数语义的框架。该框架能够形式化非对称委托（即机密性或完整性的部分委托），并支持信息降级，同时通过非可延展信息流（NMIF）保证安全性。为验证实用性，论文还设计并实现了一种静态检查NMIF的新算法以及一个支持有界标签多态性的标签推断过程，从而允许用户编写更通用的代码。

> **摘要翻译:** 语言级信息流控制（IFC）能够在去中心化应用中推理和强制执行安全策略。尽管信息流属性具有相对的外延性和组合性，但设计能够强制执行此类属性的表达性系统仍然具有挑战性。特别是，使用IFC标签来建模某些安全假设（例如半诚实代理）可能很困难。
受这些建模局限性的启发，我们研究了基于格的IFC标签模型的代数语义，并提出了一个语义框架，该框架允许形式化非对称委托，即机密性或完整性的部分委托。我们的框架支持信息降级，并通过非可延展信息流（NMIF）确保其安全性。
为了证明我们框架的实用性，我们设计并实现了一种新颖的算法，该算法静态检查NMIF，以及一个有效支持有界标签多态性的标签推断过程，允许用户编写对标签通用的代码。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [446] [Towards Formal Verification of LLM-Generated Code from Natural Language Prompts](https://arxiv.org/abs/2507.13290)
> *走向对LLM生成的自然语言提示代码的正式验证*

*Aaron Councilman, David Fu, Aryan Gupta, Chengxiao Wang, David Grove, Yu-Xiong Wang, Vikram Adve* | **Category: cs.PL, cs.AI** | **Updated: 2025-07-17**

**Keywords:** LLM, 形式化验证, 代码生成, 自然语言编程, Astrogator

**Comment:** 31 pages, 9 figures

> **TL;DR:** 本文提出了一种通过引入形式化查询语言来验证LLM生成的代码的方法，以确保其符合用户意图，并在Ansible语言上实现了名为Astrogator的系统，结果显示在验证正确代码和识别错误代码方面表现良好。

**AI_Comments:** 这项工作具有重要意义，因为它直接解决了LLM在代码生成方面的一个核心痛点：可靠性和正确性。通过引入形式化查询语言和验证机制，它为LLM生成的代码提供了可信赖的保证，这对于提升AI代码助手的实用性和安全性至关重要。Astrogator系统在Ansible上的实现展示了其在特定领域的应用潜力。创新点在于将形式化验证引入到LLM生成的代码流程中，弥补了LLM黑箱操作的不足。未来的工作可能包括将其扩展到更广泛的编程语言和更复杂的场景。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的代码常有错误，且用户难以发现并修复这些错误。为了提高AI代码助手的用户体验，并使非程序员也能进行自然语言编程，需要为LLM生成的代码提供形式化的正确性保证。

**Method:** 本文提出引入一种形式化查询语言，以正式但类似自然语言的方式表达用户意图，并让用户确认。然后，使用此查询来验证LLM生成的代码，确保其与用户意图匹配。这些思想在名为Astrogator的系统中实现，该系统针对Ansible编程语言，包含形式化查询语言、表示Ansible程序行为的演算以及用于验证的符号解释器。

**Result:** 在包含21个代码生成任务的基准测试套件上，本文的验证器能够验证83%的正确代码，并识别92%的错误代码。

**Conclusion:** 通过提供形式化的正确性保证，本文的方法可以显著改善AI代码助手的使用体验，并有望使编程知识很少或没有的用户也能进行自然语言编程。

> **ai_Abstract:** 本文旨在解决大型语言模型（LLM）生成代码的错误率高且用户难以纠正的问题。研究提出了一种通过引入形式化查询语言来精确表达用户意图，并以此验证LLM生成代码的方法，从而提供形式化的正确性保证。该方法已在针对Ansible语言的Astrogator系统中实现，该系统包含形式化查询语言、行为演算和符号解释器。实验结果表明，该验证器在基准测试中能够有效验证正确代码和识别错误代码，这有望提升AI代码助手的可靠性并促进自然语言编程。

> **摘要翻译:** 在过去的几年里，大型语言模型（LLM）已经成为一种能够辅助程序员的工具，它们可以接收自然语言描述并生成相应的代码。然而，LLM经常生成不正确的代码，用户需要进行修复，并且文献表明用户往往难以检测到这些错误。在这项工作中，我们旨在为LLM生成的代码提供形式化的正确性保证；这种保证可以改善使用AI代码助手的体验，并可能使编程知识很少或没有的用户也能进行自然语言编程。为了解决这个挑战，我们提出引入一种形式化查询语言，这种语言能够以一种形式化定义但类似自然语言的方式表示用户意图，并且用户可以确认它是否符合他们的意图。然后，我们建议使用这样的查询来验证LLM生成的代码，以确保它符合用户的意图。我们在我们的系统Astrogator中实现了这些想法，该系统针对Ansible编程语言，其中包含这样一个形式化查询语言、一个用于表示Ansible程序行为的演算以及一个用于验证的符号解释器。在包含21个代码生成任务的基准测试套件上，我们的验证器能够验证83%的正确代码并识别92%的错误代码。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [352] [Cognitive Modelling Aspects of Neurodevelopmental Disorders Using Standard and Oscillating Neighbourhood SOM Neural Networks](https://arxiv.org/abs/2507.12567)
> *使用标准和振荡邻域SOM神经网络进行神经发育障碍的认知建模*

*Spyridon Revithis, Nadine Marcus* | **Category: q-bio.NC, cs.NE, I.2.6; I.2.0; J.3** | **Updated: 2025-07-16**

**Keywords:** 自组织映射, 神经发育障碍, 认知建模, 振荡拓扑邻域, 神经网络

**Comment:** 32 pages, 11 figures, 1 table. This paper is a substantially revised
  & expanded version of Revithis, S., Wilson, W. H., and Marcus, N. "SOM
  Cognitive Modeling of Autistic and Schizophrenic Traits Using an Oscillating
  Topological Neighborhood Width Function". In: Proc. 35th Annual Conference of
  the Cognitive Science Society, M. Knauff, M. Pauen, N. Sebanz, and I.
  Wachsmuth, Eds. CSS, 2013

> **TL;DR:** 本文研究了自组织映射（SOM）神经网络在认知建模，特别是神经发育障碍方面的有效性，并引入了一种具有生物学合理性的振荡拓扑邻域SOM，通过模拟自闭症和精神分裂症，证明其在模拟大脑功能方面更具现实性。

**AI_Comments:** 本文的创新点在于引入了一种考虑皮层柱状振荡的振荡拓扑邻域SOM，增强了模型在神经发育障碍认知建模中的生物学合理性。这对于理解神经系统疾病的计算机制具有重要意义。局限性可能在于其模型仍是理论模拟，需要更多实际神经数据来进一步验证其预测能力。

<details>
  <summary>Details</summary>

**Motivation:** 探讨自组织映射（SOM）神经网络在认知建模，特别是神经发育障碍方面的理论和应用有效性。

**Method:** 引入并应用了一种修改后的、具有更高生物学合理性的SOM网络类型，该类型包含一种皮层柱状振荡形式的振荡拓扑邻域（TN）。使用标准和振荡-TN SOM网络模拟了自闭症和精神分裂症的某些方面，基于现有的神经计算理论。训练过程中对TN宽度函数进行了有针对性的修改。基于新的建模假设，使用先前引入模型（IPSOM）的修订版本进行了计算机模拟。

**Result:** 标准SOM和振荡-TN SOM建模在图谱形成行为、输出和结构方面表现出很强的相似性。

**Conclusion:** 振荡版本的SOM为大脑功能提供了更现实的计算模拟。提出了神经科学和计算论证来验证所提出的SOM修改在认知建模框架内的有效性。

> **ai_Abstract:** 本文探讨了自组织映射（SOM）神经网络在认知建模，特别是神经发育障碍中的应用。研究引入了一种具有更高生物学合理性的振荡拓扑邻域（TN）SOM，该模型通过模拟皮层柱状振荡来增强现实性。通过对自闭症和精神分裂症的建模，研究发现标准SOM和振荡-TN SOM在图谱形成和结构上相似，但振荡版本在模拟大脑功能方面更具现实意义。研究通过神经科学和计算论证验证了这种改进的SOM模型在认知建模中的有效性。

> **摘要翻译:** 背景/介绍：本文研究了自组织映射（SOM）神经网络在认知建模，特别是神经发育障碍方面的理论和应用有效性。
方法：引入并应用了一种修改后的、具有更高生物学合理性的SOM网络类型，该类型包含一种皮层柱状振荡形式的振荡拓扑邻域（TN），并与标准SOM一同应用。基于现有的神经计算理论，使用SOM网络对自闭症和精神分裂症两种神经发育障碍的某些方面进行了建模。标准和振荡-TN SOM训练都采用了对TN宽度函数有针对性的修改。使用先前引入模型（IPSOM）的修订版本，基于新的建模假设进行了计算机模拟。
结果/结论：结果表明，标准SOM和振荡-TN SOM建模在图谱形成行为、输出和结构方面具有很强的相似性，而振荡版本提供了更现实的大脑功能计算模拟。提出了神经科学和计算论证，以验证所提出的SOM修改在认知建模框架内的有效性。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [429] [Mapping Emotions in the Brain: A Bi-Hemispheric Neural Model with Explainable Deep Learning](https://arxiv.org/abs/2507.12625)
> *大脑情绪映射：一种可解释深度学习的双半球神经模型*

*David Freire-Obregón, Agnieszka Dubiel, Prasoon Kumar Vinodkumar, Gholamreza Anbarjafari, Dorota Kamińska, Modesto Castrillón-Santana* | **Category: q-bio.NC, cs.HC, eess.SP** | **Updated: 2025-07-16**

**Keywords:** 脑电图, 情绪识别, 可解释深度学习, LIME, 双半球模型

**Comment:** Accepted at Neuro-Inspired AI Workshop at 23rd International
  Conference on Image Analysis and Processing (ICIAP 2025)

> **TL;DR:** 本文提出了一种针对双流脑电图分类器的事后可解释性框架，该框架扩展了LIME方法以适应结构化的双半球输入，并揭示了与神经生理学现象一致的情绪特异性半球激活模式。

**AI_Comments:** 这项工作在提高脑电图情绪识别模型的可解释性方面具有重要意义，特别是在结合了神经科学先验知识的双半球架构中。通过扩展LIME以适应结构化双半球输入，并提供通道级别的贡献分析，该研究不仅提升了模型的透明度，还有助于将模型决策与已知的神经生理学现象联系起来。其创新之处在于将可解释性方法与神经科学知识相结合，为理解大脑情绪处理提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管双半球神经网络在脑电图情绪识别方面取得了进展，但其可解释性不足限制了在情感计算和认知建模等敏感领域的应用。

**Method:** 本文引入了一个针对双流脑电图分类器的事后可解释性框架，该框架扩展了LIME方法以适应结构化的双半球输入（左右半球脑电图通道组）。该方法将预测相关性分解为每个通道在半球和情绪类别上的贡献。该框架应用于一个在EmoNeuroDB数据集上训练的双分支循环神经网络。

**Result:** 解释结果揭示了与已知神经生理现象（如快乐时的额叶偏侧化和悲伤时的后部不对称）一致的情绪特异性半球激活模式。通过聚合局部解释，可以推导出全局通道重要性配置文件，从而实现对模型决策的神经生理学解释。对称电极之间的相关性分析进一步突出了模型的情绪依赖性偏侧化行为，支持了情感神经科学中报告的功能不对称性。

**Conclusion:** 本文提出的可解释性框架能够揭示与已知神经生理现象一致的情绪特异性半球激活模式，并支持情感神经科学中报告的功能不对称性，从而实现了对模型决策的神经生理学解释。

> **ai_Abstract:** 本文针对双半球脑电图情绪识别模型的可解释性问题，提出了一种扩展LIME的事后可解释性框架。该框架能够分解预测贡献到左右半球的特定通道，并在应用于双分支循环神经网络时，揭示了与神经生理学一致的情绪相关半球激活模式，如快乐时的额叶偏侧化和悲伤时的后部不对称。此外，通过聚合局部解释，该方法提供了全局通道重要性，从而实现了对模型决策的神经生理学解释，并支持了情感神经科学中的功能不对称性发现。

> **摘要翻译:** 最近的进展表明，通过采用将神经科学先验知识融入深度学习模型的双半球神经架构，可以实现从脑电图（EEG）信号中识别情绪。然而，可解释性仍然是它们在情感计算和认知建模等敏感领域应用的一个显著限制。在这项工作中，我们引入了一个为双流脑电图分类器量身定制的事后可解释性框架，该框架扩展了局部可解释模型无关解释（LIME）方法，以适应结构化的双半球输入。我们的方法调整LIME以处理与左右半球脑电图通道组对应的结构化双分支输入。它将预测相关性分解为跨半球和情绪类别的每个通道贡献。我们将此框架应用于一个先前经过验证的双分支循环神经网络，该网络在EmoNeuroDB数据集上进行训练，该数据集包含在基于VR的情绪诱发任务期间捕获的脑电图记录。由此产生的解释揭示了与已知神经生理现象一致的情绪特异性半球激活模式，例如快乐时的额叶偏侧化和悲伤时的后部不对称。此外，我们聚合了样本间的局部解释，以推导出全局通道重要性配置文件，从而实现了对模型决策的神经生理学解释。对称电极之间的相关性分析进一步突出了模型的情绪依赖性偏侧化行为，支持了情感神经科学中报告的功能不对称性。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [646] [The Generalist Brain Module: Module Repetition in Neural Networks in Light of the Minicolumn Hypothesis](https://arxiv.org/abs/2507.12473)
> *通才大脑模块：基于微型柱假说的神经网络模块重复*

*Mia-Katrin Kvalsund, Mikkel Elle Lepperød* | **Category: q-bio.NC, cs.LG, cs.NE** | **Updated: 2025-07-01**

**Keywords:** 神经网络, 微型柱假说, 模块重复, 通才模块, 群体智能

**Comment:** 

> **TL;DR:** 本综述探讨了一种受大脑微型柱假说启发的AI架构路径，即通过重复模块来构建神经网络，以期实现更高的鲁棒性、适应性和效率，并解决现代AI在可扩展性、能耗和民主化方面的挑战。

**AI_Comments:** 该论文的创新之处在于其全面回顾了神经网络中的模块重复现象，并明确将其与生物学上的微型柱假说和群体智能联系起来。它强调了一种有前景但尚未充分探索的架构范式，这可能解决现代AI的关键挑战，例如能源效率、可扩展性和鲁棒性。作者承认的一个局限性是目前缺乏支持经验观察的理论结果。其重要性在于指导未来的AI研究，使其朝着受生物启发、模块化和高效的架构发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有工作已涉及，但目前缺乏将皮层柱与重复神经网络模块架构联系起来的全面综述。本综述旨在通过综合关于神经模块重复的历史、理论和方法学观点来填补这一空白。最终目标是为现代AI面临的挑战（如可扩展性、能耗和鲁棒性）提供解决方案。

**Method:** 本论文是一篇全面的综述，旨在综合关于神经模块重复的历史、理论和方法学观点，特别是关注微型柱假说及其与群体智能（CI）的联系。它区分了结构重复和参数共享模块重复两种类型。

**Result:** 本综述指出，重复模块倾向于收敛为“通才模块”，即简单、灵活的问题解决者。这些通才模块能够为现代AI的长期挑战提供解决方案，例如通过简化和可扩展性提高训练期间的能源效率，以及通过泛化实现鲁棒的具身控制。经验结果表明此类系统可以泛化到分布外问题。

**Conclusion:** 特征模块重复的架构仍然是一种新兴且未被充分探索的架构策略，在效率、鲁棒性和适应性方面具有巨大的未开发潜力。一个采用群体智能优势并遵循微型柱架构和功能原则的系统，有望解决现代AI在可扩展性、能耗和民主化方面的问题。

> **ai_Abstract:** 本综述探讨了一种受大脑微型柱假说启发的AI架构方法，该假说认为新皮层由重复模块组成。它旨在综合关于神经模块重复的历史、理论和方法学观点，填补现有全面综述的空白。论文区分了结构重复和参数共享重复，强调后者能培养出鲁棒、适应性强且泛化能力好的通才模块。这种方法有望解决AI的能源效率、可扩展性和鲁棒控制等挑战，尽管目前仍缺乏理论结果。作者总结认为，模块重复是一种有前景但尚未充分探索的策略，对未来的AI系统具有重要潜力。

> **摘要翻译:** 尽管现代AI持续进步，生物大脑在鲁棒性、适应性和效率方面仍是神经网络的巅峰。本综述探讨了一条受大脑结构启发的AI架构路径，特别是微型柱假说，该假说将新皮层视为一个重复模块的分布式系统——我们将其与群体智能（CI）联系起来。尽管现有工作已涉及，但目前缺乏将皮层柱与重复神经网络模块架构联系起来的全面综述。本综述旨在通过综合关于神经模块重复的历史、理论和方法学观点来填补这一空白。我们区分了结构重复（即结构复用）和参数共享模块重复（即同一功能单元在网络中重复）。后者展现出关键的群体智能特性，如鲁棒性、适应性和泛化能力。有证据表明，重复模块倾向于收敛为通才模块：即简单、灵活的问题解决者，能够在整体中处理多种角色。这种通才倾向可能为现代AI的长期挑战提供解决方案：通过简化和可扩展性提高训练期间的能源效率，并通过泛化实现鲁棒的具身控制。虽然经验结果表明此类系统可以泛化到分布外问题，但理论结果仍然缺乏。总的来说，特征模块重复的架构仍然是一种新兴且未被充分探索的架构策略，在效率、鲁棒性和适应性方面具有巨大的未开发潜力。我们相信，一个采用群体智能优势并遵循微型柱架构和功能原则的系统，有望挑战现代AI在可扩展性、能耗和民主化方面的问题。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [359] [Designing quantum chemistry algorithms with Just-In-Time compilation](https://arxiv.org/abs/2507.09772)
> *使用即时编译设计量子化学算法*

*Xiaojie Wu, Yuanheng Wang* | **Category: physics.comp-ph, cs.NA, math.NA** | **Updated: 2025-07-17**

**Keywords:** 量子化学, 即时编译, 电子排斥积分, GPU, 计算效率

**Comment:** 10 pages, 7 figures

> **TL;DR:** 本文通过引入即时编译（JIT）和新算法，显著提升了量子化学中电子排斥积分（JK矩阵）的计算效率，在不同基组下实现了2到4倍的加速，单精度计算更是提高了3倍。

**AI_Comments:** 本文通过将JIT编译引入量子化学计算，并结合针对高角动量轨道的新算法，有效解决了电子排斥积分计算中的效率瓶颈。其创新性在于JIT的应用和算法优化，实现了显著的性能提升，且代码量紧凑，这对于加速大规模量子化学模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提高电子排斥积分计算的效率。

**Method:** 引入即时编译（JIT）到高斯型轨道（GTO）的积分核中，并结合为高角动量轨道设计的新型算法。核心CUDA实现代码量紧凑，并支持单精度算术。

**Result:** 对于库仑和交换（JK）矩阵，基于JIT的算法在小型6-31G*基组上比GPU4PySCF v1.4快2倍。通过结合高角动量轨道的新算法，大型def2-TZVPP基组的JK评估效率提高了高达4倍。单精度实现比现有最先进技术快3倍。

**Conclusion:** 通过引入即时编译和专门为高角动量轨道设计的新算法，显著提升了量子化学中电子排斥积分计算的效率和速度。

> **ai_Abstract:** 本文提出将即时编译（JIT）应用于高斯型轨道（GTO）的积分核，以提高量子化学中电子排斥积分（特别是JK矩阵）的计算效率。结合一种针对高角动量轨道设计的新算法，该方法在不同基组（如6-31G*和def2-TZVPP）上实现了显著加速，最高可达4倍。其紧凑的CUDA实现还支持单精度计算，并在此方面取得了3倍的性能提升。

> **摘要翻译:** 我们引入即时编译（JIT）到高斯型轨道（GTO）的积分核中，以提高电子排斥积分计算的效率。对于库仑和交换（JK）矩阵，基于JIT的算法在NVIDIA A100-80G GPU上，对于小型6-31G*基组，比GPU4PySCF v1.4实现了2倍的加速。通过结合为高角动量轨道设计的新型算法，大型def2-TZVPP基组的JK评估效率提高了高达4倍。核心CUDA实现代码量紧凑，仅包含约1,000行代码，并支持单精度算术。此外，单精度实现比现有最先进技术实现了3倍的加速。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statco'></a>
## stat.CO 

### [373] [Implementation and Analysis of GPU Algorithms for Vecchia Approximation](https://arxiv.org/abs/2407.02740)
> *Vecchia近似的GPU算法实现与分析*

*Zachary James, Joseph Guinness* | **Category: stat.CO, cs.AI, cs.LG, stat.ML** | **Updated: 2024-07-03**

**Keywords:** Vecchia近似, GPU算法, 高斯过程, 并行计算, GpGpU

**Comment:** 

> **TL;DR:** 本文实现了并分析了三种用于Vecchia近似的GPU算法，其中一种新方法表现最佳，并被集成到GpGpU R包中，显示出比现有软件更快的运行时间和更好的预测精度。

**AI_Comments:** 本文的创新点在于填补了Vecchia近似在GPU实现方面的空白，并提出了一种优于现有方法的创新算法。通过GPU加速，该研究显著提升了高斯过程处理大规模空间统计数据的能力，对于大数据背景下的高斯过程应用具有重要意义。GpGpU R包的发布也为研究人员提供了实用的工具。

<details>
  <summary>Details</summary>

**Motivation:** 高斯过程在空间统计中不可或缺，但处理大数据集时计算和内存需求巨大。Vecchia近似能降低计算复杂度，且可并行计算。尽管已有多核软件（如GpGp R包），但缺乏GPU软件，而GPU在统计和机器学习中已取得巨大成功。

**Method:** 本文比较了三种在GPU上实现Vecchia近似的方法：其中两种类似于其他高斯过程近似方法，一种是新方法。研究了内存类型对性能的影响，并对最终方法进行了优化。将新方法集成到GpGpU R包中，并与现有的多核和GPU加速软件进行比较，通过拟合高斯过程模型在各种数据集上进行测试，包括一个包含超过一百万个点的时空数据集。

**Result:** 我们的新方法优于其他两种方法。GpGpU在各种数据集上（包括一个大型时空数据集）实现了更快的运行时间和更好的预测精度。

**Conclusion:** GpGpU R包中的新GPU实现为Vecchia近似提供了高效且准确的计算方法，显著优于现有的多核和GPU加速软件，使得高斯过程能够更好地应用于大规模数据集。

> **ai_Abstract:** 本文针对高斯过程在处理大规模数据集时的计算瓶颈，提出并分析了三种基于GPU的Vecchia近似算法。研究发现，其中一种新提出的GPU实现方法表现最佳，并在GpGpU R包中发布。通过与现有CPU和GPU加速软件的比较，GpGpU在大型空间-时间数据集上展现出显著更快的运行速度和更高的预测精度，有效提升了高斯过程处理大数据的能力。

> **摘要翻译:** 高斯过程已成为空间统计学家工具箱中不可或缺的一部分，但由于精确拟合相关模型所需的时间和内存巨大，它们不适用于分析大型数据集。Vecchia近似被广泛用于降低计算复杂度，并且可以通过易于并行的算法进行计算。尽管已开发出用于Vecchia近似的多核软件，例如GpGp R包，但缺乏专为图形处理单元（GPU）设计的软件，尽管GPU在统计和机器学习中取得了巨大的成功。我们比较了在GPU上实现Vecchia近似的三种不同方法：其中两种类似于用于其他高斯过程近似的方法，另一种是新方法。研究了内存类型对性能的影响，并相应地优化了最终方法。我们表明，我们的新方法优于其他两种方法，然后将其呈现在GpGpU R包中。我们通过在各种数据集上拟合高斯过程模型，包括一个包含超过一百万个点、从地球观测卫星收集的大型时空数据集，将GpGpU与现有的多核和GPU加速软件进行比较。我们的结果表明，GpGpU实现了更快的运行时间和更好的预测精度。

</details>

[⬆️ 返回分类顶部](#statco) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [391] [Assessing the economic benefits of space weather mitigation investment decisions: Evidence from Aotearoa New Zealand](https://arxiv.org/abs/2507.12495)
> *评估空间天气缓解投资决策的经济效益：来自新西兰奥特亚罗瓦的证据*

*Edward J. Oughton, Andrew Renton, Daniel Mac Marnus, Craig J. Rodger* | **Category: physics.geo-ph, cs.SY, eess.SY, physics.plasm-ph, physics.soc-ph, physics.space-ph** | **Updated: 2025-07-15**

**Keywords:** 空间天气, 经济效益, 地磁感应电流, GDP损失, 新西兰

**Comment:** 

> **TL;DR:** 本研究首次量化了空间天气事件对新西兰经济的潜在GDP损失，并发现缓解措施具有极高的成本效益。

**AI_Comments:** 这篇论文通过对新西兰的案例研究，首次量化了空间天气事件对国家经济的潜在影响，并详细评估了不同缓解策略的成本效益，为决策者提供了强有力的经济论据。其创新之处在于将宏观经济模型与空间天气影响相结合，并揭示了供应链级联效应的重要性。该研究的局限性可能在于其模型未完全涵盖所有潜在损失，如资本设备和长期收入损失，这也被作者指出为未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 空间天气事件对现代经济构成日益增长的威胁，但其宏观经济后果尚未得到充分探索。本研究旨在通过提供潜在经济效益的一阶近似值，支持空间天气缓解投资的决策。

**Method:** 本研究对新西兰奥特亚罗瓦的地磁暴影响进行了首次专门的经济评估，量化了极端日冕物质抛射（CME）在七种中断和缓解情景下可能造成的GDP损失。主要关注地磁感应电流（GICs）对输电网络的破坏性影响。

**Result:** 在没有缓解措施的情况下，一次严重但现实的风暴可能导致高达83.6亿新西兰元的GDP损失，其中一半以上来自级联供应链效应。即使是不太严重的情景也会造成超过30亿新西兰元的损失。研究主导的运营策略（如优化开关和孤岛运行）可以避免高达3.7亿新西兰元的损失，而支出仅需50万新西兰元，成本效益比为740:1。物理保护措施（如GIC阻断设备）可将中断进一步降低至11.2亿新西兰元，避免的GDP损失高达23亿新西兰元，成本效益回报高达80:1。

**Conclusion:** 考虑到未建模的影响（包括资本设备和长期收入的数十亿损失），预防性缓解措施的经济理由变得更加充分。未来的研究需要整合对具有战略重要性的工业设施的资本和收入损失建模。

> **ai_Abstract:** 本研究首次专门评估了极端空间天气事件对新西兰经济的影响，量化了地磁暴可能造成的GDP损失，尤其关注地磁感应电流对电网的破坏。研究发现，在无缓解措施下，严重的风暴可能导致高达83.6亿新西兰元的GDP损失。然而，通过研究主导的运营策略和物理保护措施，可以以极高的成本效益比显著减少这些损失。研究强调了预防性缓解投资的必要性。

> **摘要翻译:** 空间天气事件对现代经济构成日益增长的威胁，但其宏观经济后果仍未得到充分探索。本研究首次对新西兰奥特亚罗瓦的地磁暴影响进行了专门的经济评估，量化了极端日冕物质抛射（CME）在七种中断和缓解情景下可能造成的潜在GDP损失。主要关注地磁感应电流（GICs）对输电网络的破坏性影响。目标是通过提供其潜在经济效益的一阶近似值来支持空间天气缓解投资的决策。我们发现，在没有缓解措施的情况下，一次严重但现实的风暴可能导致高达83.6亿新西兰元的GDP损失，其中一半以上源于级联供应链效应。然而，即使是不太严重的情景也会造成超过30亿新西兰元的损失。重要的是，研究主导的运营策略，例如优化开关和孤岛运行，仅需50万新西兰元的支出即可避免高达3.7亿新西兰元的损失，带来740:1的成本效益比。此外，GIC阻断设备等物理保护措施可将中断进一步降低至11.2亿新西兰元，避免的GDP损失高达23亿新西兰元，成本效益回报高达80:1。当同时考虑到未建模的影响，包括资本设备和长期收入的数十亿损失时，预防性缓解的经济理由变得更加充分。未来的研究需要整合对具有战略重要性的工业设施的资本和收入损失建模。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='econth'></a>
## econ.TH 

### [413] [Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective](https://arxiv.org/abs/2507.12475)
> *粗略加法与圣彼得堡悖论：一种启发式视角*

*Takashi Izumo* | **Category: econ.TH, cs.AI, math.OC** | **Updated: 2025-07-05**

**Keywords:** 圣彼得堡悖论, 粗略加法, 决策理论, 认知精度, 启发式

**Comment:** 16 pages, no figure

> **TL;DR:** 本文提出了一种“粗略加法”模型，通过将数值分组为感知类别来解决圣彼得堡悖论，从而模拟认知受限的智能体如何处理发散的奖励结构。

**AI_Comments:** 该论文的创新之处在于引入了一种符合认知规律的机制（粗略加法）来解决一个经典悖论，从而将关注点从纯粹的数学改进转向对数值处理更具人类中心化的视角。其重要性在于为决策理论和行为经济学提供了一个新的启发式视角。论文明确指出其局限性，即它并非旨在彻底解决该悖论。

<details>
  <summary>Details</summary>

**Motivation:** 圣彼得堡悖论是决策理论中一个长期存在的挑战，描述了一个期望值无限但无法确定合理有限赌注的游戏。传统的解决方案引入了辅助假设，但可能与人们实际感知或处理数值信息的方式不符。

**Method:** 本文探索了一种基于粗略划分结果空间上定义的修改加法运算（称为“粗略加法”）的替代方法。在该模型中，精确的数值被分组为感知类别，并且每个值在相加之前被其组的代表元素替换。这种方法允许出现重复加法最终停止影响结果的现象，这种行为被称为惯性稳定。

**Result:** 研究表明，在适当构建的划分下，圣彼得堡序列在这种粗略加法下可以变得惰性（inert）。

**Conclusion:** 所提出的框架提供了一种合理的方式来表示认知精度有限的智能体如何处理发散的奖励结构。尽管这并非旨在彻底解决悖论，但该方法可能在行为建模和感知限制下的机器推理研究中具有更广泛的应用。

> **ai_Abstract:** 本文旨在解决决策理论中长期存在的圣彼得堡悖论，该悖论因其无限的期望值和无法确定的合理有限赌注而构成挑战。与依赖辅助假设的传统方法不同，本研究提出了一种“粗略加法”的新方法，即在数值处理中将精确值归类到感知组中。这种方法展示了重复加法如何导致“惯性稳定”，从而使圣彼得堡序列变得惰性。虽然不作为悖论的最终解决方案，但该框架提供了一种启发式视角，解释了认知精度有限的智能体如何处理发散的奖励结构，并可能在行为建模和机器推理领域有更广泛的应用。

> **摘要翻译:** 圣彼得堡悖论对决策理论提出了一个长期存在的挑战。它描述了一个期望值无限的游戏，但却无法确定一个合理的有限赌注。传统的解决方案引入了辅助假设，例如边际效用递减、时间贴现或扩展数系。这些方法通常涉及数学上的改进，可能与人们实际感知或处理数值信息的方式不符。本文探索了一种替代方法，该方法基于在结果空间的粗略划分上定义的修改加法运算。在该模型中，精确的数值被分组为感知类别，并且每个值在相加之前被其组的代表元素替换。这种方法允许出现重复加法最终停止影响结果的现象，这种行为被称为惯性稳定。尽管这并非旨在彻底解决悖论，但所提出的框架提供了一种合理的方式来表示认知精度有限的智能体如何处理发散的奖励结构。我们证明了在适当构建的划分下，圣彼得堡序列在这种粗略加法下可以变得惰性。该方法也可能在行为建模和感知限制下的机器推理研究中具有更广泛的应用。

</details>

[⬆️ 返回分类顶部](#econth) | [⬆️ 返回总目录](#toc)

---

<a id='mathdg'></a>
## math.DG 

### [442] [Search for Z/2 eigenfunctions on the sphere using machine learning](https://arxiv.org/abs/2507.13122)
> *使用机器学习在球面上搜索Z/2本征函数*

*Andriy Haydys, Willem Adriaan Salm* | **Category: math.DG, cs.LG, cs.NA, math.NA, 53-08, 53C99** | **Updated: 2025-07-17**

**Keywords:** Z/2本征函数, 机器学习, 深度神经网络, 球面, JAX

**Comment:** 14 pages, 12 pictures

> **TL;DR:** 本文利用机器学习，特别是多值前馈深度神经网络，在2-球面上成功找到了Z/2本征函数的例子，包括固定分支点和AI自主定位分支点的情况。

**AI_Comments:** 本文的创新之处在于提出了一个多值版本的前馈深度神经网络来解决Z/2本征函数的搜索问题，并成功地在具体案例中找到了解决方案。这展示了深度学习在复杂数学问题探索中的新颖应用，为相关领域的研究提供了新的工具和视角。

<details>
  <summary>Details</summary>

**Motivation:** 在2-球面上寻找Z/2本征函数的例子。

**Method:** 创建了一个多值版本的前馈深度神经网络，并使用JAX库实现。该网络用于搜索Z/2本征函数。

**Result:** 找到了三种情况下的Z/2本征函数：前两种情况中，分支点分别固定在四面体和立方体的顶点；第三种情况中，AI自主移动分支点，并最终将其定位在扁平四面体的顶点。

**Conclusion:** 成功地利用机器学习方法在2-球面上找到了Z/2本征函数，展示了该方法在解决此类问题上的潜力。

> **ai_Abstract:** 本文利用一种新颖的多值前馈深度神经网络，并借助JAX库实现，在2-球面上成功搜索并找到了Z/2本征函数的具体例子。研究人员在固定分支点于四面体和立方体顶点的情况下各找到一例，并在允许AI自主优化分支点位置的实验中，发现分支点最终收敛于扁平四面体的顶点，展示了机器学习在这一数学问题上的应用潜力。

> **摘要翻译:** 我们使用机器学习来搜索2-球面上Z/2本征函数的例子。为此，我们创建了一个多值版本的前馈深度神经网络，并使用JAX库实现了它。我们找到了三种情况下的Z/2本征函数：在前两种情况中，我们分别将分支点固定在四面体和立方体的顶点。在第三种情况中，我们允许AI移动分支点，最终它将分支点定位在一个扁平四面体的顶点。

</details>

[⬆️ 返回分类顶部](#mathdg) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [460] [Boundary Feedback and Observer Synthesis for a Class of Nonlinear Parabolic--Elliptic PDE Systems](https://arxiv.org/abs/2507.12615)
> *边界反馈与一类非线性抛物-椭圆偏微分方程系统的观测器综合*

*Kamal Fenza, Moussa Labbadi, Mohamed Ouzahra* | **Category: math.AP, cs.SY, eess.SY** | **Updated: 2025-07-16**

**Keywords:** 边界反馈, 反步设计, 非线性PDE, 抛物-椭圆系统, 稳定性

**Comment:** 

> **TL;DR:** 研究非线性抛物-椭圆PDE系统的边界反馈稳定性和观测器设计。

**AI_Comments:** 本文的创新之处在于将严格的反步设计应用于非线性抛物-椭圆PDE耦合系统的边界反馈控制和观测器合成，并提供了明确的稳定性证明。这对于复杂PDE系统的控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 稳定化一个包含非线性项的抛物型和椭圆型PDE耦合系统。

**Method:** 采用严格的反步设计，提供了显式边界控制律和基于部分边界测量的指数收敛观测器。

**Result:** 确保了非线性闭环系统的指数稳定性和适定性。

**Conclusion:** 通过反步设计，成功实现了非线性抛物-椭圆PDE耦合系统的边界稳定化，并证明了其指数稳定性和适定性。

> **ai_Abstract:** 本文针对一类包含非线性项的抛物型和椭圆型偏微分方程耦合系统，提出了一种边界反馈稳定化方法。通过严格的反步设计，获得了显式边界控制律和指数收敛观测器。研究结果通过定理证明了所设计非线性闭环系统的指数稳定性和适定性。

> **摘要翻译:** 本文研究了一个包含抛物型偏微分方程和椭圆型偏微分方程的耦合系统的稳定化问题，该系统包含非线性项。一个严格的反步设计提供了一个显式的边界控制律和基于部分边界测量的指数收敛观测器。多项定理确保了非线性闭环系统的指数稳定性和适定性。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [471] [GLOMIA-Pro: A Generalizable Longitudinal Medical Image Analysis Framework for Disease Progression Prediction](https://arxiv.org/abs/2507.12500)
> *GLOMIA-Pro：一个用于疾病进展预测的通用纵向医学图像分析框架*

*Shuaitong Zhang, Yuchen Sun, Yong Ao, Xuehuan Zhang, Ruoshui Yang, Jiantao Xu, Zuwu Ai, Haike Zhang, Xiang Yang, Yao Xu, Kunwei Li, Duanduan Chen* | **Category: q-bio.QM, eess.IV** | **Updated: 2025-07-16**

**Keywords:** 纵向医学图像分析, 疾病进展预测, 通用框架, 表示学习, 深度学习

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** GLOMIA-Pro是一个新的纵向医学图像分析框架，通过解决现有方法的局限性，提高了疾病进展预测的通用性和准确性。

**AI_Comments:** GLOMIA-Pro的创新之处在于其对纵向医学图像分析中常见挑战的系统性解决，特别是引入了分段正交注意力机制和序数进展约束来处理时间变化和序数性质，以及通过改进的跳跃连接来缓解表示崩溃。其通用性在两种不同疾病上的验证，表明该框架具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在建模时空模式方面面临三个关键局限性：(1) 缺乏适用于不同疾病进展预测任务的通用框架；(2) 经常忽视疾病分期固有的序数性质；(3) 由于相邻时间点之间的结构相似性，容易出现表示崩溃，这会掩盖细微但具有区分性的进展生物标志物。

**Method:** 提出GLOMIA-Pro框架，包含两个核心组件：进展表示提取和进展感知融合。进展表示提取模块引入分段正交注意力机制并采用序数进展约束来解耦与疾病进展相关的精细时间成像变化。进展感知融合模块整合了重新设计的跳跃连接架构，将学习到的进展表示与当前成像表示相结合，有效缓解了跨时间融合时的表示崩溃。

**Result:** GLOMIA-Pro在膝骨关节炎严重程度预测和食道癌治疗反应评估这两个临床应用中，始终优于七种最先进的纵向分析方法。消融研究进一步证实了各个组件的贡献，证明了GLOMIA-Pro在不同临床场景中的鲁棒性和通用性。

**Conclusion:** GLOMIA-Pro是一个通用、鲁棒且在疾病进展预测方面表现优异的纵向医学图像分析框架，能够有效解决现有方法的局限性。

> **ai_Abstract:** 本文提出了GLOMIA-Pro，一个通用的纵向医学图像分析框架，旨在解决现有方法在疾病进展预测中面临的通用性不足、忽视序数性质和表示崩溃等问题。GLOMIA-Pro包含进展表示提取和进展感知融合两大模块，通过引入分段正交注意力机制、序数进展约束以及重新设计的跳跃连接架构，有效捕捉细微的时空变化并缓解表示崩溃。在膝骨关节炎和食道癌的临床应用中，GLOMIA-Pro表现优于现有SOTA方法，证明了其鲁棒性和通用性。

> **摘要翻译:** 纵向医学图像通过捕捉与动态生物过程相关的时空变化，对于监测疾病进展至关重要。尽管当前方法在建模时空模式方面取得了进展，但它们面临三个关键局限性：(1) 缺乏适用于不同疾病进展预测任务的通用框架；(2) 经常忽视疾病分期固有的序数性质；(3) 由于相邻时间点之间的结构相似性，容易出现表示崩溃，这会掩盖细微但具有区分性的进展生物标志物。为了解决这些局限性，我们提出了一个用于疾病进展预测的通用纵向医学图像分析框架（GLOMIA-Pro）。GLOMIA-Pro由两个核心组件组成：进展表示提取和进展感知融合。进展表示提取模块引入了分段正交注意力机制，并采用了新颖的序数进展约束，以解耦与疾病进展相关的精细时间成像变化。进展感知融合模块整合了重新设计的跳跃连接架构，将学习到的进展表示与当前成像表示相结合，有效缓解了跨时间融合时的表示崩溃。在两个不同的临床应用中进行验证：膝骨关节炎严重程度预测和食道癌治疗反应评估，GLOMIA-Pro始终优于七种最先进的纵向分析方法。消融研究进一步证实了各个组件的贡献，证明了GLOMIA-Pro在不同临床场景中的鲁棒性和通用性。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [484] [Modelling the spillover from online engagement to offline protest: stochastic dynamics and mean-field approximations on networks](https://arxiv.org/abs/2507.13310)
> *建模在线参与向线下抗议的溢出：网络上的随机动力学和平均场近似*

*Moyi Tian, P. Jeffrey Brantingham, Nancy Rodríguez* | **Category: physics.soc-ph, cs.SI, math.DS, nlin.AO, q-bio.PE** | **Updated: 2025-07-17**

**Keywords:** 在线参与, 线下抗议, 溢出效应, 随机动力学, 平均场模型

**Comment:** 44 pages, 33 figures

> **TL;DR:** 本研究提出了一种耦合建模框架，分析在线参与如何溢出到线下抗议活动。研究发现线上线下转换率是关键因素，且模型复杂性需根据网络密度调整，但在真实网络上更复杂的模型并未提高准确性。

**AI_Comments:** 本文创新性地提出了一个耦合模型框架来量化在线参与对线下抗议的溢出效应，并引入了关键的“传输率”概念。其发现模型复杂性与网络密度的关系具有理论意义，但真实网络测试结果表明，简单模型在实践中可能更具鲁棒性，这为实际应用提供了重要启示。论文的局限性在于，虽然提出了模型，但并未详细说明如何具体测量或估算文中所提及的“传输率”等关键参数。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体正在改变线下生活的各个方面，包括冲突的演变。本研究的动机是分析在线参与如何溢出到线下抗议活动，以理解这种线上到线下的影响机制。

**Method:** 研究提出了一个带有在线社交网络层的耦合建模框架。开发了一个随机模型，并推导出了几种不同复杂度的平均场模型。这些模型被用于估算再生数和预测活动高峰。研究还在合成网络上检验了网络结构对近似模型准确性的影响，并在两个真实世界网络上进行了测试。

**Result:** 关键发现是线上和线下领域之间的传输率必须在一个临界范围内（既不太低也不太高），线下爆发才可能出现。在合成网络上，低密度网络需要更复杂的近似模型，而高密度网络可以使用更简单的模型。然而，在两个真实世界网络上测试时，增加模型复杂性并没有提高准确性。

**Conclusion:** 本研究的结论是，在线参与向线下抗议的溢出受线上线下传输率的临界范围影响。模型选择应考虑网络密度，但简单的模型可能在某些真实世界场景下表现与复杂模型相当甚至更好。

> **ai_Abstract:** 本研究提出了一种耦合建模框架，包含一个在线社交网络层，用于分析在线参与如何引发线下抗议。通过开发随机模型和平均场近似模型，研究发现线上到线下传输率是决定线下活动爆发的关键因素，其必须处于一个临界范围内。此外，模型复杂性应根据网络密度进行调整，但研究在真实世界网络上发现，更复杂的模型并不一定带来更高的准确性。

> **摘要翻译:** 社交媒体正在改变线下生活的各个方面，从日常决策如餐饮选择到冲突的演变。在本研究中，我们提出了一个带有在线社交网络层的耦合建模框架，以分析特定主题的在线参与如何溢出到线下抗议活动。我们开发了一个随机模型，并推导出了几个不同复杂度的平均场模型。这些模型使我们能够估算再生数并预测活动高峰何时可能发生。一个关键因素是在线和线下领域之间的传输率；为了出现线下爆发，该传输率必须落在一个临界范围内，既不能太低也不能太高。此外，我们使用合成网络，检查了网络结构如何影响这些近似模型的准确性。我们的发现表明，低密度网络需要更复杂的近似，而更简单的模型可以有效地表示高密度网络。然而，在两个真实世界网络上测试时，复杂性的增加并没有提高准确性。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [663] [From Signed Networks to Group Graphs](https://arxiv.org/abs/2505.22802)
> *从符号网络到群图*

*Tim S. Evans* | **Category: physics.soc-ph, cs.DM, cs.SI** | **Updated: 2025-07-17**

**Keywords:** 群图, 符号网络, 对称性, 网络动力学, 平衡

**Comment:** 54 pages including 13 in the appendices. Version 2 has further
  applications and has added references to voltage graphs and gain graphs

> **TL;DR:** 本文定义了一种“群图”，它扩展了符号网络，并证明在平衡群图上，时间演化仅由网络拓扑决定。

**AI_Comments:** 本文的创新之处在于提出了“群图”这一新概念，它超越了传统的符号网络，允许更广泛的群标签，从而能够更普遍地编码网络动力学中的对称性。其重要性体现在统一和扩展了现有关于网络动力学的研究，并揭示了在特定条件下网络拓扑对时间演化的决定性作用，为理解复杂网络中的对称性提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究（符号网络和复杂网络）在处理网络动力学中的对称性时存在局限性。本文旨在通过引入“群图”来统一和扩展这些发现，从而更好地编码网络动力学中的对称性。

**Method:** 本文定义了一种新的图结构——“群图”，它通过允许来自任意群的链接标签并推广标准的平衡概念来扩展符号网络。

**Result:** 研究证明，在平衡群图上的动力学过程中，时间演化完全由网络拓扑决定，而不受群结构的影响。

**Conclusion:** 群图提供了一种新的框架，用于统一和扩展现有关于网络动力学和对称性驱动建模的发现。它揭示了在特定条件下，网络拓扑在决定动力学演化中的核心作用。

> **ai_Abstract:** 本文引入并定义了“群图”的概念，该概念旨在编码网络动力学过程中的对称性。群图是符号网络的一种泛化，它允许链接标签来自任意群，并推广了平衡的概念。研究发现，在平衡群图上，动力学过程的时间演化仅由网络拓扑决定，与群结构无关。这项工作统一并扩展了先前关于符号网络和复杂网络的研究，并讨论了其与现有图论概念（如Harary的群图、电压图和增益图）的关系，以及在网络动力学和对称性驱动建模中的潜在应用。

> **摘要翻译:** 我定义了一种“群图”，它编码了网络上动态过程中的对称性。群图通过允许来自任何群的链接标签并推广标准的平衡概念，从而扩展了链接用正负一标记的符号网络。我证明，在平衡群图上的过程，其时间演化完全由网络拓扑决定，而不是由群结构决定。这统一并扩展了最近关于符号网络（Tian & Lambiotte, 2024a）和复杂网络（Tian & Lambiotte, 2024b）的发现。我还会将这里讨论的结果与相关工作联系起来，例如Harary（1982）的“群图”、Gross（1974）的“电压图”和Zaslavsky（1989）的“增益图”。最后，我将回顾一些有前景的网络动力学和对称性驱动建模应用，包括状态、零标签边、弱平衡、非平衡群图以及使用幺半群。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [547] [The carbon cost of materials discovery: Can machine learning really accelerate the discovery of new photovoltaics?](https://arxiv.org/abs/2507.13246)
> *材料发现的碳成本：机器学习真的能加速新型光伏材料的发现吗？*

*Matthew Walker, Keith T. Butler* | **Category: cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 碳成本, 机器学习, 光伏, 材料发现, DFT, CO2排放

**Comment:** 

> **TL;DR:** 本研究量化了基于DFT的光伏材料发现工作流程的碳排放，并评估了混合ML/DFT策略，旨在降低环境成本同时保持预测性能。

**AI_Comments:** 这篇论文具有创新性，因为它定量评估了计算材料发现的环境足迹，这是一个关键但常被忽视的方面。它证明了ML不仅可以加速发现，还可以使其更具可持续性，为平衡精度与环境成本提供了具体策略。ML有时能超越使用替代泛函的DFT的发现尤其富有洞察力，预示着数据驱动计算化学的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 计算筛选（DFT）在发现高性能光伏材料方面功能强大，但存在显著的计算和环境成本（CO2排放）。机器学习（ML）模型作为DFT的替代方案，有望减少资源消耗，但其环境权衡需要量化。

**Method:** 本研究重现了一个典型的基于DFT的工作流程，用于估算最大效率极限。然后逐步用ML替代品替换DFT组件。通过量化每种计算策略相关的CO2排放，评估了预测效率和环境成本之间的权衡。研究还评估了通过扩展数据集和改进针对光伏相关特征的模型架构来改进ML驱动筛选的策略。

**Result:** 研究结果揭示了多种混合ML/DFT策略，这些策略在精度-排放曲线上优化了不同的点。直接预测标量量（如最大效率）比使用预测吸收光谱作为中间步骤更易于处理。在筛选应用中，在DFT数据上训练的ML模型可以优于使用替代交换关联泛函的DFT工作流程，这突出了数据驱动方法的一致性和实用性。

**Conclusion:** 这项工作为构建低排放、高通量材料发现管道提供了定量框架。

> **ai_Abstract:** 本文探讨了计算材料发现（特别是光伏材料）的环境成本（CO2排放）。它比较了传统的基于DFT的工作流程与混合机器学习（ML）/DFT方法。该研究量化了CO2排放和预测效率，发现混合ML/DFT策略可以在降低排放的同时优化精度。它强调了直接ML预测标量量的有效性，并表明ML模型甚至可以超越某些DFT设置，为可持续、高通量的材料发现提供了一个定量框架。

> **摘要翻译:** 计算筛选已成为实验工作发现高性能光伏（PV）材料的强大补充。大多数工作流程依赖于密度泛函理论（DFT）来估计与太阳能转换相关的电子和光学性质。尽管比基于实验室的方法更高效，但DFT计算仍然需要大量的计算和环境成本。机器学习（ML）模型最近作为DFT的替代品受到关注，在预测性能具有竞争力的同时，大幅减少了资源使用。在这项研究中，我们重现了一个典型的基于DFT的工作流程来估计最大效率极限，并逐步用ML替代品替换其组件。通过量化与每种计算策略相关的CO2排放，我们评估了预测效率和环境成本之间的权衡。我们的结果揭示了多种混合ML/DFT策略，这些策略在精度-排放曲线上优化了不同的点。我们发现，直接预测标量量（如最大效率）比使用预测吸收光谱作为中间步骤更易于处理。有趣的是，在筛选应用中，在DFT数据上训练的ML模型可以优于使用替代交换关联泛函的DFT工作流程，这突出了数据驱动方法的一致性和实用性。我们还评估了通过扩展数据集和改进针对PV相关特征的模型架构来改进ML驱动筛选的策略。这项工作为构建低排放、高通量发现管道提供了定量框架。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [556] [Refining Coarse-Grained Molecular Topologies: A Bayesian Optimization Approach](https://arxiv.org/abs/2501.02707)
> *精炼粗粒化分子拓扑：一种贝叶斯优化方法*

*Pranoy Ray, Adam P. Generale, Nikhith Vankireddy, Yuichiro Asoma, Masataka Nakauchi, Haein Lee, Katsuhisa Yoshida, Yoshishige Okuno, Surya R. Kalidindi* | **Category: physics.chem-ph, cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-06-11**

**Keywords:** 粗粒化分子动力学, 贝叶斯优化, 分子拓扑, Martini3, 多尺度模拟

**Comment:** 

> **TL;DR:** 本文利用贝叶斯优化方法，针对特定领域应用，优化粗粒化分子动力学（CGMD）拓扑结构，特别是键合相互作用参数，旨在以CGMD的效率达到全原子（AA）模拟的精度。

**AI_Comments:** 这项工作创新性地将贝叶斯优化应用于粗粒化分子动力学（CGMD）的拓扑精炼，尤其侧重于键合相互作用参数，以解决现有CGMD方法在特定领域应用中精度不足的问题。其重要性在于，通过在Martini3框架下开发出既能达到全原子（AA）模拟精度又保持CGMD计算效率的优化势能，成功弥合了多尺度分子模拟中效率与精度之间的差距，为更快速、更经济的分子发现提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 全原子分子动力学（AA MD）模拟计算成本高昂。现有粗粒化分子动力学（CGMD）方法（如CG-Martini）虽然降低了计算成本，但在尝试泛化参数化以适用于不同分子类别时，无法针对特定领域应用进行专业化，导致在需要足够精度和计算速度的关键领域表现不足。

**Method:** 本文提出了一种新颖的方法，利用贝叶斯优化技术，通过精炼通用Martini3拓扑结构中特定的键合相互作用参数，来优化粗粒化分子动力学（CGMD）模拟结果，使其适用于特定领域应用。研究开发并验证了一种适用于任意聚合度的粗粒化势能。

**Result:** 开发出的优化粗粒化势能，在Martini3框架基础上，旨在达到与全原子分子动力学（AAMD）相当的精度，同时保持粗粒化分子动力学（CGMD）的计算效率。

**Conclusion:** 这种方法弥合了多尺度分子模拟中效率与精度之间的鸿沟，有望在各个科学技术领域实现更快速、更具成本效益的分子发现。

> **ai_Abstract:** 本研究针对全原子分子动力学（AAMD）的高计算成本以及现有粗粒化分子动力学（CGMD）方法在特定领域应用中精度不足的问题，提出了一种新颖的贝叶斯优化方法。该方法通过精炼通用Martini3拓扑结构中的键合相互作用参数，以优化CGMD模拟结果，使其能更精确地应用于特定领域。研究开发并验证了一种适用于任意聚合度的优化CG势能，旨在实现与AAMD相当的精度，同时保持CGMD的计算效率，从而弥合了多尺度分子模拟中效率与精度之间的差距。

> **摘要翻译:** 分子动力学（MD）模拟对于准确预测各种压力和温度系综下大型分子系统的物理和化学性质至关重要。然而，与全原子（AA）MD模拟相关的高计算成本导致了粗粒化分子动力学（CGMD）的发展，它将AA结构压缩成具有代表性的CG珠粒，提供更低的维度，从而降低了计算费用，但牺牲了预测精度。现有的CGMD方法，如CG-Martini（根据实验数据校准），旨在生成一个在各种结构中充分泛化的拓扑嵌入。不利的是，在尝试指定适用于分子类别的参数化时，它无法专门用于特定领域应用，而在这些应用中，足够的精度和计算速度至关重要。这项工作提出了一种新颖的方法，通过使用贝叶斯优化方法，精炼通用Martini3拓扑结构（特别是给定粗粒化映射中的键合相互作用参数），从而优化粗粒化分子动力学模拟的派生结果，使其适用于特定领域应用。我们开发并验证了一种适用于任意聚合度的粗粒化势能，这代表了该领域的重大进展。我们基于Martini3框架的优化粗粒化势能，旨在达到与全原子分子动力学（AAMD）相当的精度，同时保持粗粒化分子动力学（CGMD）的计算效率。这种方法弥合了多尺度分子模拟中效率与精度之间的鸿沟，有望在各个科学技术领域实现更快速、更具成本效益的分子发现。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsao-ph'></a>
## physics.ao-ph 

### [595] [Super Resolution for Renewable Energy Resource Data With Wind From Reanalysis Data and Application to Ukraine](https://arxiv.org/abs/2407.19086)
> *可再生能源资源数据超分辨率处理：基于再分析风数据及其在乌克兰的应用*

*Brandon N. Benton, Grant Buster, Pavlo Pinchuk, Andrew Glaws, Ryan N. King, Galen Maclaurin, Ilya Chernyakhovskiy* | **Category: physics.ao-ph, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 风能, 降尺度, 生成对抗网络, ERA5, 超分辨率

**Comment:** 22 pages, 9 figures

> **TL;DR:** 本文提出了一种基于GAN的深度学习方法，用于风数据超分辨率降尺度，在保持与传统方法相当的准确性的同时，显著降低了计算成本，并应用于乌克兰地区。

**AI_Comments:** 本文的创新之处在于利用GANs进行风数据的时空降尺度，并采用真实的低分辨率输入数据进行训练，这显著降低了计算负担，同时保持了数据精度。这对于高效、大规模地生成高分辨率可再生能源资源数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着电力系统对风能发电容量和能源的依赖性可能增加，全球对历史精确、时空连续、高分辨率风数据的需求不断扩大。传统的基于数值天气预报的降尺度方法计算负担高，且需要大量的调优以确保历史准确性。

**Method:** 本文提出了一种新颖的基于深度学习的时空降尺度方法，使用生成对抗网络（GANs）从欧洲中期天气预报中心再分析版本5数据（ERA5）生成历史精确的高分辨率风资源数据。与以往使用粗化高分辨率数据作为低分辨率训练数据的方法不同，本文使用真实的低分辨率模拟输出。通过使用ERA5作为低分辨率输入和风能整合国家数据集工具包（WTK）数据作为高分辨率目标来训练GAN模型。

**Result:** 通过训练GAN模型，实现了与传统动态降尺度在历史准确性和时空变异性方面相当的结果。这种基于GAN的降尺度方法还比动态降尺度降低了两个数量级的计算成本。该方法已应用于将2000年1月至2023年12月期间乌克兰、摩尔多瓦和罗马尼亚部分地区的30公里、每小时ERA5数据降尺度到2公里、5分钟的风数据，形成了24年数据记录，即Sup3rWind数据集的第一个成员。

**Conclusion:** 基于GAN的降尺度方法为生成高分辨率风数据提供了一种高效且准确的替代方案，适用于可再生能源应用。

> **ai_Abstract:** 本文提出了一种新颖的基于生成对抗网络（GANs）的深度学习时空降尺度方法，用于从ERA5数据生成历史精确的高分辨率风资源数据。该方法创新性地使用真实的低分辨率模拟输出进行训练，而非粗化的高分辨率数据。实验结果表明，该GAN模型在历史准确性和时空变异性方面与传统动态降尺度方法相当，并且计算成本降低了两个数量级。该方法已成功应用于将乌克兰及周边地区24年的ERA5风数据降尺度至2公里、5分钟的高分辨率数据，并命名为Sup3rWind，以满足可再生能源领域对详细风数据的需求。

> **摘要翻译:** 随着电力系统对风能发电容量和能源的依赖性可能增加，全球对历史精确、时空连续、高分辨率风数据的需求不断扩大。传统的基于数值天气预报的降尺度方法计算负担高，且需要大量的调优以确保历史准确性。在这项工作中，我们提出了一种新颖的基于深度学习的时空降尺度方法，使用生成对抗网络（GANs）从欧洲中期天气预报中心再分析版本5数据（ERA5）生成历史精确的高分辨率风资源数据。与以往使用粗化高分辨率数据作为低分辨率训练数据的方法不同，我们使用真实的低分辨率模拟输出。我们表明，通过使用ERA5作为低分辨率输入和风能整合国家数据集工具包（WTK）数据作为高分辨率目标来训练GAN模型，我们在历史准确性和时空变异性方面取得了与传统动态降尺度相当的结果。这种基于GAN的降尺度方法还比动态降尺度降低了两个数量级的计算成本。我们将这种方法应用于将2000年1月至2023年12月期间乌克兰、摩尔多瓦和罗马尼亚部分地区的30公里、每小时ERA5数据降尺度到2公里、5分钟的风数据，覆盖多个轮毂高度。这个24年的数据记录是基于再分析数据风能可再生能源资源数据超分辨率数据集（Sup3rWind）的第一个成员。

</details>

[⬆️ 返回分类顶部](#physicsao-ph) | [⬆️ 返回总目录](#toc)

---

### [628] [Advancing Seasonal Prediction of Tropical Cyclone Activity with a Hybrid AI-Physics Climate Model](https://arxiv.org/abs/2505.01455)
> *混合AI-物理气候模型推进热带气旋活动的季节性预测*

*Gan Zhang, Megha Rao, Janni Yuval, Ming Zhao* | **Category: physics.ao-ph, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 热带气旋预测, 混合模型, 机器学习, 气候模型, NeuralGCM

**Comment:** 

> **TL;DR:** 该研究展示了使用谷歌开发的混合ML-物理模型NeuralGCM进行热带气旋活动的季节性预测的可行性，其预测技能可与现有物理GCM媲美。

**AI_Comments:** 这篇论文通过NeuralGCM展示了AI与物理模型结合在气候预测领域的巨大潜力。其创新之处在于将机器学习的效率与物理模型的可靠性相结合，显著提高了热带气旋季节性预测的速度和准确性。尽管提到了模型分辨率和简化边界强迫的挑战，但其与现有物理GCM媲美的预测技能以及快速模拟能力，预示着未来在天气-气候无缝预测方面的重要应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型在天气预报和气候模拟方面取得了成功，但将其用于有用的气候预测仍需探索。

**Method:** 使用谷歌开发的混合ML-物理大气模型NeuralGCM进行季节性预测。简化边界条件，假设海面温度（SST）和海冰遵循其气候周期，但保留初始化时的异常。

**Result:** NeuralGCM能在约8分钟内用单个GPU生成100天的模拟数据。模拟结果显示了真实的大气环流和热带气旋气候模式。对热带大气和各种热带气旋活动指标的季节性预测（7月至11月）有效。北太平洋和大西洋盆地的热带气旋频率预测与观测结果在1990年至2023年间显著相关（r=~0.7），表明预测技能可与现有物理GCM媲美。模型预测的年际变化与观测结果显著相关，包括次盆地热带气旋路径（p<0.1）和盆地累积气旋能量（p<0.01）。

**Conclusion:** 这些发现突出了利用结合物理洞察的机器学习模型来模拟热带气旋风险并提供无缝天气-气候预测的潜力。

> **ai_Abstract:** 本文利用谷歌开发的混合ML-物理气候模型NeuralGCM，探索了机器学习模型在气候预测中的应用。通过简化边界条件，NeuralGCM能够快速生成模拟数据，并成功地对大规模大气变率和热带气旋活动进行季节性预测。研究发现其预测技能与现有物理GCM相当，尤其在热带气旋频率和年际变化方面与观测结果高度相关，展示了结合ML与物理洞察在气候预测领域的巨大潜力。

> **摘要翻译:** 机器学习（ML）模型在天气预报中取得了成功，并在气候模拟方面取得了进展，但将其用于有用的气候预测仍需探索。本文展示了使用谷歌开发的混合ML-物理大气模型NeuralGCM进行大规模大气变率和北半球热带气旋（TC）活动季节性预测的可行性。受物理模型研究的启发，我们简化了边界条件，假设海面温度（SST）和海冰遵循其气候周期，但保留初始化时存在的异常。在这种强迫下，NeuralGCM可以在大约8分钟内使用单个图形处理单元（GPU）生成100天的模拟数据，同时模拟真实的大气环流和热带气旋气候模式。这种配置为热带大气和各种热带气旋活动指标提供了有用的季节性预测（7月至11月）。值得注意的是，1990年至2023年期间，北大西洋和东太平洋盆地预测的热带气旋频率与观测结果显著相关（r=~0.7），表明预测技能可与现有物理GCM媲美。尽管存在模型分辨率和简化边界强迫相关的挑战，模型预测的年际变化与观测结果表现出显著相关性，包括北大西洋和北太平洋盆地的次盆地热带气旋路径（p<0.1）和盆地累积气旋能量（p<0.01）。这些发现突出了利用结合物理洞察的机器学习模型来模拟热带气旋风险并提供无缝天气-气候预测的潜力。

</details>

[⬆️ 返回分类顶部](#physicsao-ph) | [⬆️ 返回总目录](#toc)

---

<a id='hep-th'></a>
## hep-th 

### [617] [Hamiltonian Neural Networks approach to fuzzball geodesics](https://arxiv.org/abs/2502.20881)
> *哈密顿神经网络方法在模糊球测地线中的应用*

*Andrea Cipriani, Alessandro De Santis, Giorgio Di Russo, Alfredo Grillo, Luca Tabarroni* | **Category: hep-th, cs.LG, gr-qc** | **Updated: 2025-07-16**

**Keywords:** 哈密顿神经网络, 模糊球测地线, 哈密顿方程, 机器学习, 理论高能物理

**Comment:** 25 pages + Appendices, 39 figures, minor changes with respect to the
  previous version

> **TL;DR:** 该研究利用哈密顿神经网络（HNNs）高精度地求解了模糊球测地线中的哈密顿方程，并表明HNNs在关键情况下比传统数值积分器更可靠，可能取而代之。

**AI_Comments:** 该论文的创新之处在于将哈密顿神经网络（一种物理信息机器学习技术）应用于理论高能物理中复杂微分方程的求解，填补了该领域ML应用不普及的空白。其重要性体现在HNNs在关键情况下的高可靠性，这使得它们有可能取代传统的数值积分器，从而为该领域提供更稳健的模拟工具。

<details>
  <summary>Details</summary>

**Motivation:** 尽管机器学习在物理数据分析中的应用日益增多，但在理论高能物理中，将机器学习方法应用于求解描述复杂物理系统的微分方程尚未完全普及。

**Method:** 本研究实施并训练了多个哈密顿神经网络（HNNs），以高精度求解无质量探测器在光滑无视界D1-D5圆形模糊球几何内运动的哈密顿方程。研究了不同冲击参数下的平面（赤道）和非平面测地线，其中一些是不稳定的。

**Result:** 研究结果表明，哈密顿神经网络（HNNs）能够高精度地求解哈密顿方程，并且它们与标准数值积分器一样精确，但在关键情况下更可靠。

**Conclusion:** 研究结论认为，哈密顿神经网络（HNNs）最终可能取代标准数值积分器，因为它们同样精确且在关键情况下更可靠。

> **ai_Abstract:** 本论文探讨了哈密顿神经网络（HNNs）在求解模糊球测地线中哈密顿方程的应用。研究人员实施并训练了HNNs，以高精度模拟无质量探测器在D1-D5圆形模糊球几何中的平面和非平面测地线。研究结果表明，HNNs与传统数值积分器一样精确，但在处理关键情况时表现出更高的可靠性，这预示着HNNs有潜力替代理论高能物理中的标准数值计算方法。

> **摘要翻译:** 计算资源和数据可用性的最新增长导致机器学习（ML）技术在物理数据分析中的使用显著增加。然而，在理论高能物理中，将ML方法应用于求解能够描述复杂物理系统的微分方程尚未完全普及。哈密顿神经网络（HNNs）是旨在最小化定义用于求解哈密顿运动方程的损失函数的工具。在这项工作中，我们实现了几个HNNs，它们经过训练，能够高精度地求解无质量探测器在光滑无视界D1-D5圆形模糊球内部运动的哈密顿方程。我们根据冲击参数研究了不同状态下的平面（赤道）和非平面测地线，其中一些是不稳定的。我们的发现表明，HNNs最终可能取代标准数值积分器，因为它们同样精确，但在关键情况下更可靠。

</details>

[⬆️ 返回分类顶部](#hep-th) | [⬆️ 返回总目录](#toc)

---

<a id='mathgr'></a>
## math.GR 

### [625] [On finite extensions of lamplighter groups](https://arxiv.org/abs/2507.13203)
> *关于灯夫群的有限扩张*

*Corentin Bodart* | **Category: math.GR, cs.DM, cs.FL** | **Updated: 2025-07-17**

**Keywords:** 灯夫群, 组合群论, 判定问题, 字问题, 共轭问题

**Comment:** 27 pages, 6 figures

> **TL;DR:** 本文研究灯夫群的简单扩张，并利用它们解决了组合群论中的多个开放问题，展示了具有特定性质组合的群。

**AI_Comments:** 这篇论文通过构造特定的群实例，巧妙地解决了组合群论中长期存在的难题，特别是关于各种判定问题的可判定性边界。其创新之处在于利用灯夫群的扩张来构造具有复杂且非直观性质组合的群，这对于理解群的结构和算法性质具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决组合群论中的多个开放问题，并通过构建具有特定性质组合的群来探索群论中的各种性质。

**Method:** 研究一类由灯夫群的最简单扩张组成的群。

**Result:** 提供了具有以下组合性质的群：1) 可判定子群成员资格问题但不可判定均匀子群成员资格问题；2) 有理体积增长序列但不可判定字问题；3) 递归（甚至是上下文无关）共轭测地线语言、可判定字问题但不可判定共轭问题。此外，还考虑了这类群中的共字问题、剩余有限性和同构问题。

**Conclusion:** 通过研究灯夫群的有限扩张，成功地构建了具有特殊组合性质的群，从而解决了组合群论中的一些开放问题，并深入探讨了相关判定问题。

> **ai_Abstract:** 本文研究了灯夫群的简单有限扩张，并利用这些新构造的群解决了组合群论中的若干开放问题。研究展示了具有独特性质组合的群，包括在子群成员资格、字问题和共轭问题上的可判定性差异，以及体积增长序列的性质。此外，论文还探讨了共字问题、剩余有限性和同构问题。

> **摘要翻译:** 我们研究了一类由灯夫群的最简单扩张组成的群。我们利用这些群来回答组合群论中的多个开放问题，提供了展示各种性质组合的群：1) 可判定子群成员资格问题和不可判定均匀子群成员资格问题，2) 有理体积增长序列和不可判定字问题，以及3) 递归（甚至是上下文无关）共轭测地线语言、可判定字问题和不可判定共轭问题。我们还在这类群中考虑了共字问题、剩余有限性和同构问题。

</details>

[⬆️ 返回分类顶部](#mathgr) | [⬆️ 返回总目录](#toc)

---

<a id='gr-qc'></a>
## gr-qc 

### [638] [Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis](https://arxiv.org/abs/2507.11192)
> *引力波数据分析中基于模拟的推断的最新进展*

*Bo Liang, He Wang* | **Category: gr-qc, astro-ph.HE, astro-ph.IM, cs.LG, stat.ML** | **Updated: 2025-07-17**

**Keywords:** 引力波, 基于模拟的推断, 机器学习, 参数估计, 神经推断

**Comment:** 30 pages, 6 figures, 1 table. Minor clarifications added on page 3.
  Literature covered up to early 2025

> **TL;DR:** 这篇综述探讨了引力波数据分析中基于模拟的推断方法的最新进展，特别是那些利用机器学习技术的方法，以解决传统贝叶斯推断方法的计算挑战，并讨论了它们的优势和局限性。

**AI_Comments:** 这篇综述及时地总结了引力波数据分析领域的一个重要趋势，即利用机器学习技术加速参数估计。其创新点在于系统地梳理了多种基于模拟的推断方法及其在引力波领域的应用。文章不仅指出了这些方法的性能优势（如速度提升），也坦诚地揭示了其局限性，如模型依赖性和对先验假设的敏感性，以及需要进一步验证准确性。这为该领域的未来研究指明了方向，即在追求计算效率的同时，也必须重视模型的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 引力波探测开启了观测天文学的新时代，对快速、详细的参数估计和群体层面分析提出了需求。然而，传统的贝叶斯推断方法（如马尔可夫链蒙特卡罗）在处理引力波数据固有的高维参数空间和复杂噪声特性时面临显著的计算挑战。

**Method:** 本文综述了引力波天文学中新兴的基于模拟的推断方法，重点关注利用机器学习技术的方法，如归一化流和神经后验估计。文中全面概述了各种基于模拟的推断方法的理论基础，包括神经后验估计（NPE）、神经比率估计（NRE）、神经似然估计（NLE）、流匹配和一致性模型。

**Result:** 这些技术在受控研究中表现出比传统方法更快的速度。然而，它们的模型依赖性和对先验假设的敏感性是其广泛采用的障碍。它们的准确性与传统方法相似，但需要在更广泛的参数空间和噪声条件下进行进一步验证。

**Conclusion:** 基于模拟的推断方法在引力波数据分析中显示出加速潜力，但其模型依赖性、对先验假设的敏感性以及在更广泛条件下的准确性验证是其未来广泛应用的关键挑战。

> **ai_Abstract:** 这篇综述深入探讨了引力波数据分析领域中基于模拟的推断方法（SBA）的最新进展。鉴于传统贝叶斯推断方法在处理高维引力波数据时的计算瓶颈，SBA，特别是那些融合了机器学习技术（如归一化流和神经后验估计）的方法，被提出作为有效的替代方案。文章详细介绍了包括NPE、NRE、NLE、流匹配和一致性模型在内的多种SBA的理论基础及其在单源参数估计、重叠信号分析、广义相对论检验和群体研究等引力波数据处理场景中的应用。尽管SBA在速度上优于传统方法，但其模型依赖性、对先验假设的敏感性以及在广泛参数空间和噪声条件下的准确性验证是其普及面临的挑战。

> **摘要翻译:** 引力波数据分析中基于模拟的推断的最新进展

LIGO-Virgo-KAGRA合作对引力波的探测开启了观测天文学的新时代，强调了对快速、详细的参数估计和群体层面分析的需求。传统的贝叶斯推断方法，特别是马尔可夫链蒙特卡罗，在处理引力波数据固有的高维参数空间和复杂噪声特性时面临显著的计算挑战。这篇综述探讨了基于模拟的推断方法在引力波天文学中新兴的作用，重点关注那些利用机器学习技术（如归一化流和神经后验估计）的方法。我们全面概述了各种基于模拟的推断方法（包括神经后验估计、神经比率估计、神经似然估计、流匹配和一致性模型）的理论基础。我们探讨了这些方法在各种引力波数据处理场景中的应用，从单源参数估计和重叠信号分析到检验广义相对论和进行群体研究。尽管这些技术在受控研究中表现出比传统方法更快的速度，但它们的模型依赖性和对先验假设的敏感性是其广泛采用的障碍。它们的准确性与传统方法相似，但需要在更广泛的参数空间和噪声条件下进行进一步验证。

</details>

[⬆️ 返回分类顶部](#gr-qc) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [699] [Freshness, Persistence and Success of Scientific Teams](https://arxiv.org/abs/2507.12255)
> *科学团队的新鲜度、持久性与成功*

*Hanjo D. Boekhout, Eelke M. Heemskerk, Niccolò Pisani, Frank W. Takes* | **Category: cs.DL, cs.SI** | **Updated: 2025-07-17**

**Keywords:** 团队科学, 新鲜度, 持久性, 合作, 成功

**Comment:** Author name correction in arXiv metadata

> **TL;DR:** 成功的科学团队不仅需要持久性，更需要通过引入新合作（新鲜度）来保持活力和高影响力。

**AI_Comments:** 这篇论文通过大规模数据分析，提出了“团队新鲜度”这一新颖概念，挑战了传统上认为持久性是团队成功唯一关键的观点。其创新之处在于强调了新合作对于团队持续高产和高影响力的重要性，为理解团队动力学提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 团队科学在科学知识生产中占据主导地位，但什么能让学术团队成功？

**Method:** 使用2520万份出版物和3180万名作者的时间数据，提出了一种新颖的网络驱动方法来识别和研究持久性团队的成功。

**Result:** 挑战了“仅凭持久性就能驱动成功”的观点；发现团队新鲜度（基于先前经验建立的新合作）是成功的关键；高影响力研究往往在团队生命周期的早期出现；对新合作关系开放的团队持续产生更好的科学成果；引入新鲜度冲动的团队重组能维持成功，而来自经验丰富团队的持久性冲动则与早期影响力相关。

**Conclusion:** 新鲜度和持久性共同塑造了跨合作阶段的团队成功。

> **ai_Abstract:** 本研究基于大规模出版物和作者数据，探讨了科学团队成功的驱动因素。它提出，除了团队的持久性外，引入新的合作（即“团队新鲜度”）对于维持团队的活力和产出高影响力研究至关重要。研究发现，高影响力成果常在团队早期出现，并且开放新合作的团队表现更佳，表明新鲜度和持久性共同决定了团队的成功。

> **摘要翻译:** 团队科学主导着科学知识的生产，但什么能让学术团队成功？我们利用2520万份出版物和3180万名作者的时间数据，提出了一种新颖的网络驱动方法来识别和研究持久性团队的成功。我们挑战了“仅凭持久性就能驱动成功”的观点，发现团队新鲜度——在先前经验基础上建立的新合作——是成功的关键。高影响力研究往往在团队生命周期的早期出现。通过分析复杂的团队重叠，我们发现对新合作关系开放的团队始终能产出更好的科学成果。具体而言，引入新的新鲜度冲动的团队重组能维持成功，而来自经验丰富团队的持久性冲动则与更早的影响力相关。总而言之，新鲜度和持久性共同塑造了跨合作阶段的团队成功。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [706] [Untangling Graphs on Surfaces](https://arxiv.org/abs/2311.00437)
> *解开曲面上的图*

*Éric Colin de Verdière, Vincent Despré, Loïc Dubois* | **Category: cs.CG, cs.DS, 05C10, 57M15, 57N05, 68Q25, 68R10, 68W05, 14E25** | **Updated: 2025-07-17**

**Keywords:** 图解缠绕, 曲面嵌入, 计算拓扑, 同伦, 缩减三角剖分

**Comment:** 41 pages. 17 figures. To be presented at SODA 2024

> **TL;DR:** 本文提出了一种算法，用于判断绘制在曲面上的带交叉的图是否可以通过滑动顶点和边来解开（即同伦于一个嵌入），特别是针对球体或圆盘以外的复杂曲面，这在以前的通用图研究中是未被触及的。

**AI_Comments:** 本文的主要创新在于首次解决了在复杂曲面上解开通用图的问题，填补了平面性测试在更广义曲面上的空白。引入的“缩减三角剖分”是一种新颖的离散模拟方法，其特性（如路径唯一性）使其可能具有独立的理论和应用价值。算法的效率分析也体现了其在处理复杂几何结构上的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 当曲面是球体或圆盘时，该问题归结为平面性测试。然而，对于其他情况，除了输入图是环形的情况外，以前从未研究过，这表明在更复杂的曲面上对通用图进行解缠绕存在研究空白。

**Method:** 本文提供了一种算法来判断图的绘制是否可以解开（即同伦于一个嵌入）。该算法利用了二维计算拓扑和双曲曲面理论的各种技术。最值得注意的是，它引入了“缩减三角剖分”，这是一种新颖的双曲曲面离散模拟，具有路径唯一且在反转时稳定的额外优点。算法还使用了定制的数据结构来高效地进行同伦测试，并依赖于Akitaya、Fulek和Tóth（SODA 2018，TALG 2019）提出的测试曲面上图的弱简单性的算法作为关键子程序。

**Result:** 该算法的运行时间为O(m + poly(g+b) n log n)，其中g >= 0和b >= 0是输入可定向曲面S的亏格和边界分量数，n是输入图绘制的大小，m是S上蜂窝状嵌入的某个固定图的大小。

**Conclusion:** 本文为在任意可定向曲面上解开通用图提供了首个算法，并引入了可能具有独立兴趣的新颖理论工具，如缩减三角剖分。

> **ai_Abstract:** 本文提出了一种算法，用于判断绘制在可定向曲面上的带交叉的图是否可以通过连续形变解开为一个嵌入。与之前仅限于环或简单曲面的工作不同，该算法解决了具有亏格g和b个边界分量的曲面上的通用图问题。它在O(m + poly(g+b) n log n)时间内运行，利用了计算拓扑学、双曲曲面理论，并引入了“缩减三角剖分”作为一项关键的新颖技术，该技术可能具有独立的理论价值。

> **摘要翻译:** 考虑一个绘制在曲面（例如，平面减去有限数量的障碍点）上的图，可能带有交叉。我们提供了一种算法来判断这种绘制是否可以被解开，即是否可以通过在曲面上滑动图的顶点和边（避开障碍物）来消除所有交叉；换句话说，绘制是否同伦于一个嵌入。当曲面是球体或圆盘（或等效地没有障碍的平面）时，该问题归结为平面性测试，但其他情况以前从未被研究过，除了输入图是循环时，在拓扑学的大量文献中以及最近由Despré和Lazarus [SoCG 2017, J. ACM 2019] 研究过。 我们的算法运行时间为O(m + poly(g+b) n log n)，其中g >= 0和b >= 0是输入可定向曲面S的亏格和边界分量数，n是输入图绘制的大小，位于S上蜂窝状嵌入的某个固定图的大小m。 我们使用了二维计算拓扑和双曲曲面理论的各种技术。最值得注意的是，我们引入了缩减三角剖分，这是一种新颖的双曲曲面离散模拟，借鉴了Lazarus和Rivaud [FOCS 2012] 以及Erickson和Whittlesey [SODA 2013] 的四边形系统思想，其额外的好处是缩减路径是唯一的且在反转时稳定；它们可能具有独立的兴趣。需要定制的数据结构才能在这些三角剖分上高效地实现某些同伦测试。作为一个关键的子程序，我们依赖于Akitaya、Fulek和Tóth [SODA 2018, TALG 2019] 提出的测试曲面上图的弱简单性的算法。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

