{"id": "2506.06333", "title": "Extending AALpy with Passive Learning: A Generalized State-Merging Approach", "authors": ["Benjamin von Berg", "Bernhard K. Aichernig"], "summary": "AALpy is a well-established open-source automata learning library written in\nPython with a focus on active learning of systems with IO behavior. It provides\na wide range of state-of-the-art algorithms for different automaton types\nranging from fully deterministic to probabilistic automata. In this work, we\npresent the recent addition of a generalized implementation of an important\nmethod from the domain of passive automata learning: state-merging in the\nred-blue framework. Using a common internal representation for different\nautomaton types allows for a general and highly configurable implementation of\nthe red-blue framework. We describe how to define and execute state-merging\nalgorithms using AALpy, which reduces the implementation effort for\nstate-merging algorithms mainly to the definition of compatibility criteria and\nscoring. This aids the implementation of both existing and novel algorithms. In\nparticular, defining some existing state-merging algorithms from the literature\nwith AALpy only takes a few lines of code.", "comment": "Accepted for publication at CAV 2025, the 37th International\n  Conference on Computer Aided Verification", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06333v1", "AI": {"title_translation": "将AALpy扩展到被动学习：一种广义的状态合并方法", "tldr": "AALpy库新增了广义的状态合并实现，简化了被动自动机学习算法的开发。", "motivation": "现有的AALpy库主要关注主动学习，而缺乏对被动自动机学习中重要方法（如状态合并）的通用支持，这限制了其在被动学习领域的应用和新算法的实现。", "method": "作者将一种广义的状态合并方法（基于红蓝框架）集成到AALpy库中。通过使用不同自动机类型的通用内部表示，实现了高度可配置的红蓝框架，并简化了状态合并算法的定义，主要集中于兼容性标准和评分的定义。", "result": "这种集成显著降低了状态合并算法的实现难度，使得现有和新颖的算法更容易被开发。文献中已有的状态合并算法现在只需几行代码即可在AALpy中定义。", "conclusion": "通过在AALpy中引入广义的状态合并实现，该工作有效地扩展了AALpy的功能，使其能够支持被动自动机学习，并极大地简化了相关算法的开发。", "translation": "AALpy是一个成熟的开源自动机学习库，用Python编写，专注于具有IO行为的系统的主动学习。它提供了广泛的最新算法，适用于从完全确定性到概率自动机的不同自动机类型。在这项工作中，我们介绍了最近添加的被动自动机学习领域中一种重要方法的广义实现：红蓝框架中的状态合并。使用不同自动机类型的通用内部表示，可以实现红蓝框架的通用且高度可配置的实现。我们描述了如何使用AALpy定义和执行状态合并算法，这主要将状态合并算法的实现工作量减少到兼容性标准和评分的定义。这有助于现有和新颖算法的实现。特别是，使用AALpy定义文献中一些现有的状态合并算法只需几行代码。", "summary": "本文介绍了对开源自动机学习库AALpy的扩展，新增了被动自动机学习领域中广义状态合并方法（基于红蓝框架）的实现。通过采用通用内部表示，该实现具有高度可配置性，并显著降低了状态合并算法的开发难度，使得现有和新颖算法的定义变得更加简单高效。", "keywords": "AALpy, 被动学习, 状态合并, 自动机学习, 红蓝框架", "comments": "这项工作通过集成被动学习的关键方法，增强了AALpy作为通用自动机学习库的功能。其创新之处在于提供了一个广义且可配置的状态合并框架，极大地降低了算法实现门槛，对于促进自动机学习领域的研究和应用具有重要意义。"}}
{"id": "2506.06551", "title": "Elementary Cellular Automata as Non-Cryptographic Hash Functions", "authors": ["Daniel McKinley"], "summary": "A subset of 10 of the 256 elementary cellular automata (ECA) are implemented\nas a hash function using an error minimization lossy compression algorithm\noperating on wrapped 4x4 neighborhood cells. All 256 rules are processed and 10\nrules in two subsets of 8 are found to have properties that include both error\nminimization and maximization, unique solutions, a lossy inverse, efficient\nretroactive hashing, and an application to edge detection. The algorithm\nparallels the nested powers-of-two structure of the Fast Fourier Transform and\nFast Walsh-Hadamard Transform, is implemented in Java, and is built to hash any\n2 byte RGB code bitmap.", "comment": null, "cate": "nlin.CG", "url": "http://arxiv.org/pdf/2506.06551v1", "AI": {"title_translation": "基本元胞自动机作为非加密哈希函数", "tldr": "本文将基本元胞自动机（ECA）实现为非加密哈希函数，并发现10种规则具有误差最小化、最大化、唯一解、有损逆、高效追溯哈希以及边缘检测应用等特性。", "motivation": "Not mentioned in abstract", "method": "本文将256种基本元胞自动机（ECA）中的10种实现为哈希函数。该实现采用在4x4环绕邻域单元上运行的误差最小化有损压缩算法。该算法与快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套2的幂结构并行，并用Java实现，旨在对任何2字节RGB代码位图进行哈希处理。", "result": "在处理所有256种规则后，发现在两个8个子集中有10种规则具有误差最小化和最大化、唯一解、有损逆、高效追溯哈希以及应用于边缘检测等特性。", "conclusion": "本文成功将部分基本元胞自动机实现为非加密哈希函数，并发现特定规则具有可用于数据处理和图像分析（如边缘检测）的理想属性。", "translation": "本文将256种基本元胞自动机（ECA）中的10种实现为哈希函数，该实现采用在4x4环绕邻域单元上运行的误差最小化有损压缩算法。所有256种规则都经过处理，发现在两个8个子集中有10种规则具有误差最小化和最大化、唯一解、有损逆、高效追溯哈希以及应用于边缘检测等特性。该算法与快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套2的幂结构并行，并用Java实现，旨在对任何2字节RGB代码位图进行哈希处理。", "summary": "本文将256种基本元胞自动机（ECA）中的10种作为非加密哈希函数进行实现，利用误差最小化有损压缩算法处理环绕的4x4邻域单元。研究发现，有10种规则表现出误差最小化和最大化、唯一解、有损逆、高效追溯哈希以及边缘检测应用等特性。该算法结构类似于快速傅里叶变换，并用Java实现，可对2字节RGB位图进行哈希处理。", "keywords": "基本元胞自动机, 非加密哈希函数, 误差最小化, 有损压缩, 边缘检测", "comments": "这项工作展示了基本元胞自动机在非加密哈希函数领域的潜在应用，特别是其在数据压缩和图像处理（如边缘检测）方面的能力。算法与传统变换的并行性可能意味着其具有计算效率。然而，其非加密性质限制了其在安全敏感应用中的使用。"}}
{"id": "2506.07956", "title": "Language Models over Canonical Byte-Pair Encodings", "authors": ["Tim Vieira", "Tianyu Liu", "Clemente Pasti", "Yahya Emara", "Brian DuSell", "Benjamin LeBrun", "Mario Giulianelli", "Juan Luis Gastaldi", "Timothy J. O'Donnell", "Ryan Cotterell"], "summary": "Modern language models represent probability distributions over character\nstrings as distributions over (shorter) token strings derived via a\ndeterministic tokenizer, such as byte-pair encoding. While this approach is\nhighly effective at scaling up language models to large corpora, its current\nincarnations have a concerning property: the model assigns nonzero probability\nmass to an exponential number of $\\it{noncanonical}$ token encodings of each\ncharacter string -- these are token strings that decode to valid character\nstrings but are impossible under the deterministic tokenizer (i.e., they will\nnever be seen in any training corpus, no matter how large). This misallocation\nis both erroneous, as noncanonical strings never appear in training data, and\nwasteful, diverting probability mass away from plausible outputs. These are\navoidable mistakes! In this work, we propose methods to enforce canonicality in\ntoken-level language models, ensuring that only canonical token strings are\nassigned positive probability. We present two approaches: (1) canonicality by\nconditioning, leveraging test-time inference strategies without additional\ntraining, and (2) canonicality by construction, a model parameterization that\nguarantees canonical outputs but requires training. We demonstrate that fixing\ncanonicality mistakes improves the likelihood of held-out data for several\nmodels and corpora.", "comment": "ICML 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.07956v1", "AI": {"title_translation": "基于规范字节对编码的语言模型", "tldr": "语言模型在处理字节对编码时会为无效的token序列分配概率，本文提出了两种方法来强制规范性，从而提高模型性能。", "motivation": "现代语言模型使用确定性分词器（如字节对编码）将字符字符串表示为token字符串的分布。然而，它们当前存在一个问题：模型会为每个字符字符串的指数级数量的“非规范”token编码分配非零概率质量。这些非规范编码在确定性分词器下是不可能的，也永远不会出现在训练语料库中。这种错误的分配既是错误的，因为它从未出现在训练数据中，也是浪费的，因为它将概率质量从合理的输出中转移出去。", "method": "本文提出了两种方法来强制token级语言模型中的规范性，确保只有规范的token字符串被赋予正概率：\n1.  通过条件作用实现规范性：利用测试时推理策略，无需额外训练。\n2.  通过构建实现规范性：一种模型参数化，保证规范输出，但需要训练。", "result": "实验表明，纠正规范性错误可以提高多个模型和语料库在保留数据上的似然性。", "conclusion": "通过强制语言模型仅将正概率分配给规范的token字符串，可以避免概率质量的错误分配和浪费，从而显著提高模型在未见数据上的似然性。", "translation": "现代语言模型将字符字符串的概率分布表示为通过确定性分词器（例如字节对编码）派生出的（较短的）token字符串的分布。虽然这种方法在将语言模型扩展到大型语料库方面非常有效，但其目前的实现方式有一个令人担忧的特性：模型会为每个字符字符串的指数级数量的“非规范”token编码分配非零概率质量——这些token字符串解码为有效的字符字符串，但在确定性分词器下是不可能的（即，无论语料库多大，它们都不会出现在任何训练语料库中）。这种错误分配既是错误的，因为非规范字符串从未出现在训练数据中，也是浪费的，因为它将概率质量从合理的输出中转移出去。这些都是可以避免的错误！在这项工作中，我们提出了在token级语言模型中强制规范性的方法，确保只有规范的token字符串被赋予正概率。我们提出了两种方法：(1) 通过条件作用实现规范性，利用测试时推理策略，无需额外训练；(2) 通过构建实现规范性，这是一种模型参数化，保证规范输出，但需要训练。我们证明，纠正规范性错误可以提高多个模型和语料库在保留数据上的似然性。", "summary": "现代语言模型在处理字节对编码时，会错误地为“非规范”的token编码分配概率质量，这既不合理又浪费。本文提出了两种方法来解决这一问题：一是通过测试时推理策略进行“条件性规范化”，无需额外训练；二是通过模型参数化进行“构建性规范化”，需要训练。实验结果表明，这些方法能够有效纠正规范性错误，并提高模型在保留数据上的似然性。", "keywords": "语言模型, 字节对编码, 分词, 规范性, 概率分布", "comments": "这篇论文解决了现代语言模型在处理字节对编码时一个基本但常被忽视的问题。通过确保只有有效的token序列被赋予概率，它使得模型更加高效和准确，这对于大规模模型尤为重要。提出的两种方法，一种无需重新训练，另一种通过模型设计保证，为解决实际问题提供了灵活的方案，具有重要的理论和实践意义。"}}
{"id": "2506.06407", "title": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "authors": ["Zhi Wen Soi", "Chaoyi Zhu", "Fouad Abiad", "Aditya Shankar", "Jeroen M. Galjaard", "Huijuan Wang", "Lydia Y. Chen"], "summary": "Synthetic time series generated by diffusion models enable sharing\nprivacy-sensitive datasets, such as patients' functional MRI records. Key\ncriteria for synthetic data include high data utility and traceability to\nverify the data source. Recent watermarking methods embed in homogeneous latent\nspaces, but state-of-the-art time series generators operate in real space,\nmaking latent-based watermarking incompatible. This creates the challenge of\nwatermarking directly in real space while handling feature heterogeneity and\ntemporal dependencies. We propose TimeWak, the first watermarking algorithm for\nmultivariate time series diffusion models. To handle temporal dependence and\nspatial heterogeneity, TimeWak embeds a temporal chained-hashing watermark\ndirectly within the real temporal-feature space. The other unique feature is\nthe $\\epsilon$-exact inversion, which addresses the non-uniform reconstruction\nerror distribution across features from inverting the diffusion process to\ndetect watermarks. We derive the error bound of inverting multivariate time\nseries and further maintain high watermark detectability. We extensively\nevaluate TimeWak on its impact on synthetic data quality, watermark\ndetectability, and robustness under various post-editing attacks, against 5\ndatasets and baselines of different temporal lengths. Our results show that\nTimeWak achieves improvements of 61.96% in context-FID score, and 8.44% in\ncorrelational scores against the state-of-the-art baseline, while remaining\nconsistently detectable.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06407v1", "AI": {"title_translation": "TimeWak：时间序列数据的时序链式哈希水印", "tldr": "该论文提出了TimeWak，一种针对扩散模型生成的多变量时间序列数据的新型水印方法，解决了真实空间嵌入和非均匀重建误差的挑战，并展示了数据质量的提升和持续的可检测性。", "motivation": "合成时间序列数据需要高数据效用性和可追溯性。现有水印方法在潜在空间中嵌入，但最先进的时间序列生成器在真实空间中运行，导致不兼容。因此，挑战在于如何在处理特征异构性和时间依赖性的同时，直接在真实空间中进行水印处理。", "method": "本文提出了TimeWak，一种针对多变量时间序列扩散模型的首次水印算法。它通过在真实时间-特征空间中直接嵌入时序链式哈希水印来处理时间依赖性和空间异构性。此外，它还采用$\\epsilon$-精确反演来解决反演扩散过程以检测水印时特征间非均匀重建误差分布的问题。作者推导了多变量时间序列反演的误差界限，并保持了高水印可检测性。", "result": "TimeWak在context-FID分数上比最先进的基线提高了61.96%，在相关性分数上提高了8.44%，同时保持了持续的可检测性。它在5个数据集和不同时间长度的基线上，对合成数据质量、水印可检测性以及在各种后编辑攻击下的鲁棒性进行了广泛评估。", "conclusion": "TimeWak成功解决了在真实空间中对时间序列扩散模型进行水印的挑战，并在数据效用性、水印可检测性和鲁棒性方面表现出优于现有方法的性能。", "translation": "扩散模型生成的合成时间序列使得共享隐私敏感数据集（如患者的功能性MRI记录）成为可能。合成数据的关键标准包括高数据效用性和可追溯性以验证数据来源。最近的水印方法嵌入在同质潜在空间中，但最先进的时间序列生成器在真实空间中运行，使得基于潜在空间的水印不兼容。这带来了直接在真实空间中进行水印处理的挑战，同时需要处理特征异构性和时间依赖性。我们提出了TimeWak，这是第一个用于多变量时间序列扩散模型的水印算法。为了处理时间依赖性和空间异构性，TimeWak直接在真实时间-特征空间中嵌入了一个时序链式哈希水印。另一个独特之处是$\\epsilon$-精确反演，它解决了反演扩散过程以检测水印时，特征之间非均匀重建误差分布的问题。我们推导了反演多变量时间序列的误差界限，并进一步保持了高水印可检测性。我们对TimeWak在合成数据质量、水印可检测性以及在各种后编辑攻击下的鲁棒性进行了广泛评估，涉及5个数据集和不同时间长度的基线。我们的结果表明，TimeWak在context-FID分数上实现了61.96%的改进，在相关性分数上比最先进的基线提高了8.44%，同时保持了持续的可检测性。", "summary": "本文介绍了TimeWak，一种专为扩散模型生成的多变量时间序列数据设计的新型水印算法。它通过将时序链式哈希水印直接嵌入到真实时间-特征空间中，解决了传统潜在空间水印与真实空间时间序列生成器不兼容的问题。TimeWak还包含一个$\\epsilon$-精确反演机制，用于管理水印检测过程中的非均匀重建误差。广泛的评估表明，TimeWak显著提高了合成数据质量（context-FID提高61.96%，相关性分数提高8.44%），并保持了水印的一致可检测性以及对抗后编辑攻击的鲁棒性，优于最先进的基线。", "keywords": "时间序列数据, 水印, 扩散模型, 数据可追溯性, 时序链式哈希", "comments": "这篇论文在合成时间序列数据的可追溯性方面取得了重大进展，特别适用于隐私敏感的应用。其创新之处在于直接在真实时间-特征空间中嵌入水印，以及用于鲁棒检测的$\\epsilon$-精确反演，这克服了以往方法的关键局限性。在数据效用性和一致可检测性方面令人印象深刻的性能提升突显了其实际重要性。"}}
{"id": "2506.06409", "title": "HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions", "authors": ["Dor Tsur", "Carol Xuan Long", "Claudio Mayrink Verdun", "Hsiang Hsu", "Chen-Fu Chen", "Haim Permuter", "Sajani Vithana", "Flavio P. Calmon"], "summary": "Large language model (LLM) watermarks enable authentication of text\nprovenance, curb misuse of machine-generated text, and promote trust in AI\nsystems. Current watermarks operate by changing the next-token predictions\noutput by an LLM. The updated (i.e., watermarked) predictions depend on random\nside information produced, for example, by hashing previously generated tokens.\nLLM watermarking is particularly challenging in low-entropy generation tasks -\nsuch as coding - where next-token predictions are near-deterministic. In this\npaper, we propose an optimization framework for watermark design. Our goal is\nto understand how to most effectively use random side information in order to\nmaximize the likelihood of watermark detection and minimize the distortion of\ngenerated text. Our analysis informs the design of two new watermarks:\nHeavyWater and SimplexWater. Both watermarks are tunable, gracefully\ntrading-off between detection accuracy and text distortion. They can also be\napplied to any LLM and are agnostic to side information generation. We examine\nthe performance of HeavyWater and SimplexWater through several benchmarks,\ndemonstrating that they can achieve high watermark detection accuracy with\nminimal compromise of text generation quality, particularly in the low-entropy\nregime. Our theoretical analysis also reveals surprising new connections\nbetween LLM watermarking and coding theory. The code implementation can be\nfound in https://github.com/DorTsur/HeavyWater_SimplexWater", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06409v1", "AI": {"title_translation": "HeavyWater 和 SimplexWater：水印低熵文本分布", "tldr": "本文提出了两种新的大语言模型水印技术（HeavyWater和SimplexWater），专门用于有效水印低熵文本分布，同时保持高检测准确率和低文本失真。", "motivation": "当前大语言模型（LLM）水印技术通过改变下一个token的预测来运作，但在低熵生成任务（如编码）中，下一个token的预测接近确定性，这使得LLM水印变得特别具有挑战性。研究的动机在于理解如何最有效地利用随机侧信息，以最大化水印检测的可能性并最小化生成文本的失真，从而解决现有水印在低熵文本方面面临的挑战。", "method": "本文提出了一个水印设计的优化框架，旨在最大化水印检测的可能性并最小化生成文本的失真。该框架指导了两种新水印：HeavyWater和SimplexWater的设计。这两种水印都是可调的，可以在检测精度和文本失真之间进行权衡，并且可以应用于任何LLM，同时与侧信息生成无关。", "result": "HeavyWater和SimplexWater在多个基准测试中表现出高水印检测准确率，同时对文本生成质量的损害最小，尤其是在低熵区域。理论分析还揭示了LLM水印与编码理论之间令人惊讶的新联系。这两种水印都是可调的，可以在检测精度和文本失真之间进行权衡，并且可以应用于任何LLM。", "conclusion": "本文提出的HeavyWater和SimplexWater水印技术，有效地解决了大语言模型在低熵文本分布中水印的挑战，能够在保持生成文本质量的同时，实现高水印检测准确率，并揭示了与编码理论的新联系。", "translation": "大语言模型（LLM）水印能够验证文本来源，遏制机器生成文本的滥用，并促进对人工智能系统的信任。当前的水印通过改变LLM输出的下一个token预测来运作。更新后的（即带有水印的）预测取决于随机侧信息，例如通过哈希先前生成的token产生。LLM水印在低熵生成任务（例如编码）中特别具有挑战性——在这种任务中，下一个token的预测接近确定性。在本文中，我们提出了一个水印设计的优化框架。我们的目标是了解如何最有效地利用随机侧信息，以最大化水印检测的可能性并最小化生成文本的失真。我们的分析指导了两种新水印：HeavyWater和SimplexWater的设计。这两种水印都是可调的，可以在检测精度和文本失真之间进行权衡。它们也可以应用于任何LLM，并且与侧信息生成无关。我们通过几个基准测试检验了HeavyWater和SimplexWater的性能，证明它们能够以最小的文本生成质量妥协实现高水印检测准确率，尤其是在低熵区域。我们的理论分析还揭示了LLM水印与编码理论之间令人惊讶的新联系。代码实现可在 https://github.com/DorTsur/HeavyWater_SimplexWater 找到。", "summary": "本文提出了一种优化框架，用于设计大语言模型（LLM）水印，旨在解决当前水印在低熵文本（如代码）中面临的挑战。基于此框架，研究人员开发了两种新的可调水印：HeavyWater和SimplexWater。这些水印能够有效利用随机侧信息，在最大化检测准确率的同时，将文本失真降至最低。实验结果表明，HeavyWater和SimplexWater在低熵文本生成中表现出色，实现了高水印检测率和低文本质量损害，并且适用于任何LLM。此外，研究还揭示了LLM水印与编码理论之间的新联系。", "keywords": "LLM水印, 低熵文本, HeavyWater, SimplexWater, 编码理论", "comments": "本文的创新点在于针对LLM水印在低熵文本分布（如代码）中面临的特定挑战提出了有效的解决方案。通过引入优化框架来指导水印设计，并提出HeavyWater和SimplexWater两种新水印，该研究在保持文本质量的同时显著提高了水印检测的准确性。其可调性、对任何LLM的普适性以及与编码理论的理论联系，都增加了其重要性和潜在影响力。"}}
{"id": "2506.06414", "title": "Benchmarking Misuse Mitigation Against Covert Adversaries", "authors": ["Davis Brown", "Mahdi Sabbaghi", "Luze Sun", "Alexander Robey", "George J. Pappas", "Eric Wong", "Hamed Hassani"], "summary": "Existing language model safety evaluations focus on overt attacks and\nlow-stakes tasks. Realistic attackers can subvert current safeguards by\nrequesting help on small, benign-seeming tasks across many independent queries.\nBecause individual queries do not appear harmful, the attack is hard to\n{detect}. However, when combined, these fragments uplift misuse by helping the\nattacker complete hard and dangerous tasks. Toward identifying defenses against\nsuch strategies, we develop Benchmarks for Stateful Defenses (BSD), a data\ngeneration pipeline that automates evaluations of covert attacks and\ncorresponding defenses. Using this pipeline, we curate two new datasets that\nare consistently refused by frontier models and are too difficult for weaker\nopen-weight models. Our evaluations indicate that decomposition attacks are\neffective misuse enablers, and highlight stateful defenses as a countermeasure.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06414v1", "AI": {"title_translation": "基准测试对抗隐蔽性攻击的滥用缓解措施", "tldr": "现有语言模型安全评估未能覆盖隐蔽的、多查询的分解攻击。本文开发了有状态防御基准测试（BSD）管道，用于自动化评估此类攻击和相应的防御措施，结果表明分解攻击是有效的滥用促成因素，并强调了有状态防御作为反制措施的重要性。", "motivation": "现有语言模型安全评估主要关注公开攻击和低风险任务，忽视了现实中攻击者可能通过在多个独立、看似无害的查询中逐步实现恶意目的的隐蔽性攻击。这种攻击难以检测，但组合后能促成危险任务的完成，因此需要识别针对此类策略的防御措施。", "method": "开发了“有状态防御基准测试”（BSD）数据生成管道，该管道能够自动化评估隐蔽攻击和相应的防御措施。利用此管道，整理并发布了两个新的数据集。", "result": "评估表明分解攻击是有效的滥用促成因素。通过BSD管道整理的新数据集被前沿模型一致拒绝，而对较弱的开源模型来说则过于困难。研究强调有状态防御是有效的反制措施。", "conclusion": "分解攻击是有效的滥用促成因素，而有状态防御被证实是应对此类隐蔽攻击的有效反制措施。", "translation": "现有语言模型安全评估侧重于公开攻击和低风险任务。现实攻击者可以通过在许多独立的查询中请求看似无害的小任务来规避当前的防护措施。由于单个查询似乎无害，因此攻击难以检测。然而，当这些片段结合起来时，它们会通过帮助攻击者完成困难和危险的任务来促进滥用。为了识别针对此类策略的防御措施，我们开发了“有状态防御基准测试”（BSD），这是一个数据生成管道，可以自动化评估隐蔽攻击和相应的防御措施。利用此管道，我们整理了两个新的数据集，这些数据集被前沿模型一致拒绝，并且对于较弱的开源模型来说太困难。我们的评估表明，分解攻击是有效的滥用促成因素，并强调有状态防御是一种反制措施。", "summary": "本文指出现有语言模型安全评估未能有效应对隐蔽性攻击，即攻击者通过多个看似无害的独立查询来规避安全措施，这些查询组合起来可实现恶意目的。为解决这一问题，研究者开发了“有状态防御基准测试”（BSD）数据生成管道，以自动化评估隐蔽攻击及其防御措施。通过该管道，他们创建了两个新数据集，并发现分解攻击是有效的滥用促成因素，而有状态防御是重要的反制措施。", "keywords": "语言模型安全, 隐蔽攻击, 分解攻击, 有状态防御, 基准测试", "comments": "这项研究创新性地关注了语言模型中一个被忽视但现实存在的安全漏洞：隐蔽性、多阶段的“分解攻击”。通过开发BSD基准测试，它提供了一个系统化的方法来评估和开发针对这类复杂威胁的防御措施，特别是强调了有状态防御的重要性，这对于提高语言模型在实际应用中的安全性具有重要意义。"}}
{"id": "2506.06518", "title": "A Systematic Review of Poisoning Attacks Against Large Language Models", "authors": ["Neil Fendley", "Edward W. Staley", "Joshua Carney", "William Redman", "Marie Chau", "Nathan Drenkow"], "summary": "With the widespread availability of pretrained Large Language Models (LLMs)\nand their training datasets, concerns about the security risks associated with\ntheir usage has increased significantly. One of these security risks is the\nthreat of LLM poisoning attacks where an attacker modifies some part of the LLM\ntraining process to cause the LLM to behave in a malicious way. As an emerging\narea of research, the current frameworks and terminology for LLM poisoning\nattacks are derived from earlier classification poisoning literature and are\nnot fully equipped for generative LLM settings. We conduct a systematic review\nof published LLM poisoning attacks to clarify the security implications and\naddress inconsistencies in terminology across the literature. We propose a\ncomprehensive poisoning threat model applicable to categorize a wide range of\nLLM poisoning attacks. The poisoning threat model includes four poisoning\nattack specifications that define the logistics and manipulation strategies of\nan attack as well as six poisoning metrics used to measure key characteristics\nof an attack. Under our proposed framework, we organize our discussion of\npublished LLM poisoning literature along four critical dimensions of LLM\npoisoning attacks: concept poisons, stealthy poisons, persistent poisons, and\npoisons for unique tasks, to better understand the current landscape of\nsecurity risks.", "comment": "28 Pages including number", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06518v1", "AI": {"title_translation": "大型语言模型中毒攻击的系统综述", "tldr": "本文对大型语言模型（LLM）中毒攻击进行了系统综述，提出了一个全面的威胁模型和分类框架，以解决现有术语不一致的问题并更好地理解安全风险。", "motivation": "随着预训练大型语言模型及其训练数据集的广泛应用，人们对其使用中的安全风险日益担忧，其中LLM中毒攻击是一个重要威胁。现有针对分类中毒的框架和术语不适用于生成式LLM，因此需要更清晰的理解和统一的框架。", "method": "本文对已发表的LLM中毒攻击进行了系统综述，以阐明安全影响并解决文献中术语不一致的问题。作者提出了一个全面的中毒威胁模型，该模型包含四个中毒攻击规范（定义攻击的逻辑和操作策略）以及六个用于衡量攻击关键特征的中毒指标。在此框架下，作者将已发表的LLM中毒文献按照概念中毒、隐蔽中毒、持久中毒和针对特定任务的中毒这四个关键维度进行组织讨论。", "result": "本文提供了一个全面的中毒威胁模型，包含攻击规范和测量指标，并根据四个关键维度对LLM中毒攻击文献进行了系统组织和讨论，从而澄清了安全影响并解决了术语不一致的问题。", "conclusion": "本文通过系统综述和提出全面的中毒威胁模型，为理解和分类大型语言模型中毒攻击提供了清晰的框架，有助于更好地理解当前的安全风险格局。", "translation": "随着预训练大型语言模型（LLM）及其训练数据集的广泛可用性，人们对其使用相关的安全风险担忧显著增加。其中一个安全风险是LLM中毒攻击的威胁，即攻击者修改LLM训练过程的某些部分，导致LLM以恶意方式运行。作为一个新兴研究领域，当前LLM中毒攻击的框架和术语源自早期的分类中毒文献，并未完全适用于生成式LLM环境。我们对已发表的LLM中毒攻击进行了系统综述，以阐明其安全影响并解决文献中术语不一致的问题。我们提出了一个全面的中毒威胁模型，适用于对各种LLM中毒攻击进行分类。该中毒威胁模型包括四个中毒攻击规范，定义了攻击的逻辑和操纵策略，以及六个用于衡量攻击关键特征的中毒指标。在我们提出的框架下，我们围绕LLM中毒攻击的四个关键维度：概念中毒、隐蔽中毒、持久中毒和针对独特任务的中毒，组织了对已发表LLM中毒文献的讨论，以更好地理解当前的安全风险格局。", "summary": "本文针对大型语言模型（LLM）中毒攻击这一新兴研究领域，指出现有框架和术语未能完全适应生成式LLM的特点。为此，作者进行了一项系统综述，旨在阐明安全影响并解决文献中的术语不一致问题。文章提出了一种全面的中毒威胁模型，该模型包含四个攻击规范和六个衡量指标，并在此框架下，将已发表的LLM中毒文献按照概念、隐蔽、持久和针对特定任务的中毒等四个关键维度进行了组织和讨论，以增进对当前安全风险的理解。", "keywords": "大型语言模型, 中毒攻击, 系统综述, 威胁模型, 安全风险", "comments": "本文通过对LLM中毒攻击进行系统性综述，填补了现有研究中框架和术语不一致的空白。其提出的全面威胁模型和分类维度，为后续研究提供了清晰的指导和统一的语言，对于理解和防御LLM安全风险具有重要意义。创新性在于其系统化的梳理和新模型的提出。"}}
{"id": "2506.06837", "title": "AI-Generated Compromises for Coalition Formation", "authors": ["Eyal Briman", "Ehud Shapiro", "Nimrod Talmon"], "summary": "The challenge of finding compromises between agent proposals is fundamental\nto AI subfields such as argumentation, mediation, and negotiation. Building on\nthis tradition, Elkind et al. (2021) introduced a process for coalition\nformation that seeks majority-supported proposals preferable to the status quo,\nusing a metric space where each agent has an ideal point. A crucial step in\nthis process involves identifying compromise proposals around which agent\ncoalitions can unite. How to effectively find such compromise proposals remains\nan open question. We address this gap by formalizing a model that incorporates\nagent bounded rationality and uncertainty, and by developing AI methods to\ngenerate compromise proposals. We focus on the domain of collaborative document\nwriting, such as the democratic drafting of a community constitution. Our\napproach uses natural language processing techniques and large language models\nto induce a semantic metric space over text. Based on this space, we design\nalgorithms to suggest compromise points likely to receive broad support. To\nevaluate our methods, we simulate coalition formation processes and show that\nAI can facilitate large-scale democratic text editing, a domain where\ntraditional tools are limited.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.06837v1", "AI": {"title_translation": "联盟形成中的AI生成妥协方案", "tldr": "本文提出了一种利用AI方法（NLP和大型语言模型）在语义度量空间中生成妥协方案以促进联盟形成和大规模民主文本编辑的方法。", "motivation": "在联盟形成过程中，如何有效找到能让各代理人联合起来的妥协提案仍是一个悬而未决的问题。", "method": "本文通过形式化一个包含代理人有限理性和不确定性的模型，并开发AI方法来生成妥协方案。具体来说，研究利用自然语言处理技术和大型语言模型在文本上构建语义度量空间，并在此基础上设计算法以建议可能获得广泛支持的妥协点。研究聚焦于协作文档撰写领域，如社区章程的民主起草。", "result": "研究通过模拟联盟形成过程，证明AI可以促进大规模民主文本编辑，这是一个传统工具受限的领域。", "conclusion": "AI能够促进大规模民主文本编辑，弥补了传统工具的局限性。", "translation": "代理人提案之间寻找妥协方案的挑战是人工智能子领域（如论证、调解和谈判）的基础问题。在此传统基础上，Elkind 等人（2021）引入了一种联盟形成过程，该过程在每个代理人都有一个理想点的度量空间中，寻求多数支持且优于现状的提案。此过程中的关键一步是识别能让代理人联盟团结起来的妥协提案。如何有效找到此类妥协提案仍然是一个开放性问题。我们通过形式化一个包含代理人有限理性和不确定性的模型，并开发人工智能方法来生成妥协提案，从而解决了这一空白。我们专注于协作文档撰写领域，例如社区章程的民主起草。我们的方法使用自然语言处理技术和大型语言模型在文本上生成语义度量空间。基于此空间，我们设计了算法来建议可能获得广泛支持的妥协点。为了评估我们的方法，我们模拟了联盟形成过程，并表明人工智能可以促进大规模民主文本编辑，这是一个传统工具受限的领域。", "summary": "本文针对联盟形成中寻找妥协方案的挑战，提出了一种基于AI的方法。研究首先形式化了一个考虑代理人有限理性和不确定性的模型，然后利用自然语言处理技术和大型语言模型在文本上构建语义度量空间。在此空间中，设计了算法来生成可能获得广泛支持的妥协提案。通过模拟协作文档撰写过程，研究展示了AI在促进大规模民主文本编辑方面的有效性，填补了传统工具的空白。", "keywords": "AI生成妥协, 联盟形成, 自然语言处理, 大型语言模型, 民主文本编辑", "comments": "本文的创新之处在于将AI方法（特别是NLP和LLM）应用于联盟形成中的妥协方案生成，并将其应用于大规模民主文本编辑这一实际且复杂的领域。这为多代理人系统中的协商和协作提供了新的工具和视角，具有重要的实践意义。"}}
{"id": "2506.06361", "title": "Tactile MNIST: Benchmarking Active Tactile Perception", "authors": ["Tim Schneider", "Guillaume Duret", "Cristiana de Farias", "Roberto Calandra", "Liming Chen", "Jan Peters"], "summary": "Tactile perception has the potential to significantly enhance dexterous\nrobotic manipulation by providing rich local information that can complement or\nsubstitute for other sensory modalities such as vision. However, because\ntactile sensing is inherently local, it is not well-suited for tasks that\nrequire broad spatial awareness or global scene understanding on its own. A\nhuman-inspired strategy to address this issue is to consider active perception\ntechniques instead. That is, to actively guide sensors toward regions with more\ninformative or significant features and integrate such information over time in\norder to understand a scene or complete a task. Both active perception and\ndifferent methods for tactile sensing have received significant attention\nrecently. Yet, despite advancements, both fields lack standardized benchmarks.\nTo bridge this gap, we introduce the Tactile MNIST Benchmark Suite, an\nopen-source, Gymnasium-compatible benchmark specifically designed for active\ntactile perception tasks, including localization, classification, and volume\nestimation. Our benchmark suite offers diverse simulation scenarios, from\nsimple toy environments all the way to complex tactile perception tasks using\nvision-based tactile sensors. Furthermore, we also offer a comprehensive\ndataset comprising 13,500 synthetic 3D MNIST digit models and 153,600\nreal-world tactile samples collected from 600 3D printed digits. Using this\ndataset, we train a CycleGAN for realistic tactile simulation rendering. By\nproviding standardized protocols and reproducible evaluation frameworks, our\nbenchmark suite facilitates systematic progress in the fields of tactile\nsensing and active perception.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06361v1", "AI": {"title_translation": "触觉MNIST：主动触觉感知的基准测试", "tldr": "引入触觉MNIST，一个用于主动触觉感知的开源基准，旨在解决该领域缺乏标准化基准的问题。", "motivation": "触觉感知对机器人操作至关重要，但其固有的局部性限制了其在需要广泛空间或全局场景理解的任务中的应用。主动感知是解决此问题的一种人类启发策略。然而，主动感知和触觉传感领域都缺乏标准化的基准，阻碍了系统性进展。", "method": "本文引入了触觉MNIST基准套件，这是一个开源的、与Gymnasium兼容的基准，专门为主动触觉感知任务（包括定位、分类和体积估计）设计。该基准套件提供多样化的模拟场景，并包含一个综合数据集，该数据集由13,500个合成3D MNIST数字模型和153,600个从真实3D打印数字中收集的触觉样本组成。此外，研究人员还使用此数据集训练了一个CycleGAN，用于逼真的触觉模拟渲染。", "result": "该研究成功引入了一个标准化的基准套件和数据集，为主动触觉感知任务提供了可复现的评估框架和标准化协议，从而促进了该领域的系统性进展。", "conclusion": "触觉MNIST基准套件通过提供标准化的协议和可复现的评估框架，促进了触觉传感和主动感知领域的系统性进展。", "translation": "触觉感知通过提供丰富的局部信息，可以补充或替代视觉等其他感官模式，从而显著增强灵巧的机器人操作。然而，由于触觉感应本质上是局部的，它本身不适合需要广泛空间意识或全局场景理解的任务。解决这个问题的一种受人类启发的方法是考虑主动感知技术。也就是说，主动引导传感器朝向信息更丰富或更重要的特征区域，并随时间整合这些信息，以理解场景或完成任务。主动感知和不同的触觉感应方法最近都受到了广泛关注。然而，尽管取得了进展，这两个领域都缺乏标准化的基准。为了弥补这一差距，我们引入了触觉MNIST基准套件，这是一个开源的、与Gymnasium兼容的基准，专门为主动触觉感知任务设计，包括定位、分类和体积估计。我们的基准套件提供了多样化的模拟场景，从简单的玩具环境到使用基于视觉的触觉传感器的复杂触觉感知任务。此外，我们还提供了一个全面的数据集，包含13,500个合成3D MNIST数字模型和从600个3D打印数字中收集的153,600个真实世界触觉样本。使用此数据集，我们训练了一个CycleGAN用于逼真的触觉模拟渲染。通过提供标准化的协议和可复现的评估框架，我们的基准套件促进了触觉传感和主动感知领域的系统性进展。", "summary": "本文介绍了触觉MNIST基准套件，这是一个开源的、与Gymnasium兼容的框架，旨在标准化主动触觉感知的评估。为解决局部触觉传感的局限性以及缺乏基准的问题，该套件提供了多样化的模拟场景和包含合成与真实触觉样本的综合数据集。该基准促进了主动触觉感知领域（如定位、分类和体积估计）的可复现研究和系统性进展。", "keywords": "触觉感知, 主动感知, 基准测试, 机器人学, 数据集", "comments": "这篇论文通过提供一个急需的标准化基准，解决了触觉传感和主动感知领域的一个关键空白。这将极大地帮助可复现研究，并通过为评估不同的主动触觉感知算法提供一个共同的基础来加速进展。包含模拟和真实世界数据，以及用于逼真渲染的CycleGAN，增强了其实用性。"}}
{"id": "2506.06381", "title": "CPS-Guard: Framework for Dependability Assurance of AI- and LLM-Based Cyber-Physical Systems", "authors": ["Trisanth Srinivasan", "Santosh Patapati", "Himani Musku", "Idhant Gode", "Aditya Arora", "Samvit Bhattacharya", "Abubakr Nazriev", "Sanika Hirave", "Zaryab Kanjiani", "Srinjoy Ghose", "Srinidhi Shetty"], "summary": "Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to\noperate in critical applications. However, traditional verification and\nvalidation methods often struggle to handle the unpredictable and dynamic\nnature of AI components. In this paper, we introduce CPS-Guard, a novel\nframework that employs multi-role orchestration to automate the iterative\nassurance process for AI-powered CPS. By assigning specialized roles (e.g.,\nsafety monitoring, security assessment, fault injection, and recovery planning)\nto dedicated agents within a simulated environment, CPS-Guard continuously\nevaluates and refines AI behavior against a range of dependability\nrequirements. We demonstrate the framework through a case study involving an\nautonomous vehicle navigating an intersection with an AI-based planner. Our\nresults show that CPS-Guard effectively detects vulnerabilities, manages\nperformance impacts, and supports adaptive recovery strategies, thereby\noffering a structured and extensible solution for rigorous V&V in safety- and\nsecurity-critical systems.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06381v1", "AI": {"title_translation": "CPS-Guard：面向AI和LLM网络物理系统可靠性保障框架", "tldr": "CPS-Guard是一个新颖的框架，通过多角色编排在模拟环境中自动化AI驱动CPS的可靠性保障过程，有效检测漏洞并支持自适应恢复策略。", "motivation": "网络物理系统（CPS）日益依赖先进的AI技术在关键应用中运行，但传统的验证和确认方法难以处理AI组件不可预测和动态的特性。", "method": "本文引入了CPS-Guard框架，该框架采用多角色编排，在一个模拟环境中为AI驱动的CPS自动化迭代保障过程。通过将专业角色（如安全监控、安全评估、故障注入和恢复规划）分配给专用代理，CPS-Guard持续评估和完善AI行为以满足一系列可靠性要求。", "result": "通过一个涉及自动驾驶汽车的案例研究，结果表明CPS-Guard有效检测漏洞，管理性能影响，并支持自适应恢复策略。", "conclusion": "CPS-Guard为安全和关键安全系统中的严格验证与确认提供了一个结构化和可扩展的解决方案。", "translation": "网络物理系统（CPS）日益依赖先进的AI技术在关键应用中运行。然而，传统的验证和确认方法往往难以处理AI组件不可预测和动态的特性。在本文中，我们引入了CPS-Guard，这是一个新颖的框架，它采用多角色编排来自动化AI驱动CPS的迭代保障过程。通过在模拟环境中将专业角色（例如安全监控、安全评估、故障注入和恢复规划）分配给专用代理，CPS-Guard持续评估和完善AI行为以满足一系列可靠性要求。我们通过一个涉及具有AI规划器的自动驾驶汽车导航十字路口的案例研究来演示该框架。我们的结果表明，CPS-Guard有效检测漏洞，管理性能影响，并支持自适应恢复策略，从而为安全和关键安全系统中的严格验证与确认提供了一个结构化和可扩展的解决方案。", "summary": "CPS-Guard是一个创新的框架，旨在解决AI驱动网络物理系统（CPS）中传统验证和确认方法所面临的挑战。该框架利用多角色编排，在模拟环境中自动化AI-powered CPS的迭代保障过程。通过分配专门的角色，如安全监控和故障注入，CPS-Guard持续评估并完善AI行为，以满足可靠性要求。案例研究表明，它能有效检测漏洞、管理性能影响并支持自适应恢复策略，为关键系统提供了严谨的V&V解决方案。", "keywords": "网络物理系统, AI, 可靠性保障, 验证与确认, 多角色编排", "comments": "CPS-Guard的创新之处在于其多角色编排方法，自动化了AI驱动CPS的可靠性保障过程，这对于处理AI组件的动态和不可预测性至关重要。该框架提供了一个结构化和可扩展的解决方案，对于提高安全和关键安全系统的鲁棒性具有重要意义。"}}
{"id": "2506.06478", "title": "Enhancing Software Supply Chain Security Through STRIDE-Based Threat Modelling of CI/CD Pipelines", "authors": ["Sowmiya Dhandapani"], "summary": "With the increasing adoption of Continuous Integration and Continuous\nDeployment pipelines, securing software supply chains has become a critical\nchallenge for modern DevOps teams. This study addresses these challenges by\napplying a structured threat modeling approach to identify and mitigate risks\nthroughout the CI/CD lifecycle. By modeling a representative pipeline\narchitecture incorporating tools such as GitHub, Jenkins, Docker, and\nKubernetes and applying the STRIDE framework, we systematically analyze\nvulnerabilities at each stage, from source code management to deployment.\nThreats are documented and mapped to comprehensive security controls drawn from\nstandards like NIST SP 800-218, OWASP Top 10 CI/CD risks, and the SLSA\nframework. Controls are further evaluated against SLSA maturity levels to\nassess improvements in trust and provenance. To operationalize these findings,\nthe study outlines a practical security toolchain integration strategy grounded\nin Security as Code and Shift Left-Shield Right principles, enabling automated,\nenforceable security across the pipeline. This approach provides a pragmatic\nroadmap for enhancing CI/CD pipeline security against evolving software supply\nchain threats.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.06478v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06283", "title": "Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow", "authors": ["Juexiao Zhou", "Zhongyi Han", "Mankun Xin", "Xingwei He", "Guotao Wang", "Jiaoyan Song", "Gongning Luo", "Wenjia He", "Xintong Li", "Yuetan Chu", "Juanwen Chen", "Bo Wang", "Xia Wu", "Wenwen Duan", "Zhixia Guo", "Liyan Bai", "Yilin Pan", "Xuefei Bi", "Lu Liu", "Long Feng", "Xiaonan He", "Xin Gao"], "summary": "Global population aging presents increasing challenges to healthcare systems,\nwith coronary artery disease (CAD) responsible for approximately 17.8 million\ndeaths annually, making it a leading cause of global mortality. As CAD is\nlargely preventable, early detection and proactive management are essential. In\nthis work, we introduce DigitalShadow, an advanced early warning system for\nCAD, powered by a fine-tuned facial foundation model. The system is pre-trained\non 21 million facial images and subsequently fine-tuned into LiveCAD, a\nspecialized CAD risk assessment model trained on 7,004 facial images from 1,751\nsubjects across four hospitals in China. DigitalShadow functions passively and\ncontactlessly, extracting facial features from live video streams without\nrequiring active user engagement. Integrated with a personalized database, it\ngenerates natural language risk reports and individualized health\nrecommendations. With privacy as a core design principle, DigitalShadow\nsupports local deployment to ensure secure handling of user data.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06283v1", "AI": {"title_translation": "面部基础模型利用DigitalShadow从实时视频中推进冠状动脉疾病的早期预警", "tldr": "DigitalShadow是一个基于面部基础模型的早期预警系统，能从实时视频中非接触式地检测冠状动脉疾病风险，并提供个性化健康建议，同时注重隐私。", "motivation": "全球人口老龄化给医疗系统带来挑战，冠状动脉疾病（CAD）是全球主要死亡原因，每年导致约1780万人死亡。CAD在很大程度上是可预防的，因此早期检测和主动管理至关重要。", "method": "本研究引入了DigitalShadow，一个由微调的面部基础模型驱动的先进CAD早期预警系统。该系统首先在2100万张面部图像上进行预训练，然后在中国四家医院的1751名受试者的7004张面部图像上微调成LiveCAD，一个专门的CAD风险评估模型。DigitalShadow被设计为被动、非接触式运行，从实时视频流中提取面部特征，无需用户主动参与。它与个性化数据库集成，生成自然语言风险报告和个性化健康建议，并支持本地部署以确保数据隐私。", "result": "DigitalShadow系统能够从实时视频中提取面部特征，评估冠状动脉疾病风险，并生成自然语言风险报告和个性化健康建议。它提供了一种非接触式、注重隐私的早期预警方式。", "conclusion": "DigitalShadow系统利用面部基础模型，提供了一种创新、非接触式且注重隐私的冠状动脉疾病早期预警解决方案，有助于解决全球健康挑战。", "translation": "全球人口老龄化给医疗系统带来日益严峻的挑战，冠状动脉疾病（CAD）每年导致约1780万人死亡，是全球主要的死亡原因。由于CAD在很大程度上是可预防的，因此早期检测和主动管理至关重要。在这项工作中，我们介绍了DigitalShadow，一个由微调的面部基础模型驱动的先进CAD早期预警系统。该系统在2100万张面部图像上进行预训练，随后在中国四家医院的1751名受试者的7004张面部图像上微调成LiveCAD，一个专门的CAD风险评估模型。DigitalShadow被设计为被动、非接触式运行，从实时视频流中提取面部特征，无需用户主动参与。它与个性化数据库集成，生成自然语言风险报告和个性化健康建议。DigitalShadow以隐私为核心设计原则，支持本地部署以确保用户数据的安全处理。", "summary": "本论文介绍了一个名为DigitalShadow的先进冠状动脉疾病（CAD）早期预警系统。该系统利用一个在海量面部图像上预训练并针对CAD风险评估进行微调的面部基础模型（LiveCAD），能够从实时视频流中非接触式地提取面部特征，并结合个性化数据库生成自然语言风险报告和个性化健康建议。DigitalShadow强调隐私保护，支持本地部署，旨在为全球日益增长的CAD问题提供早期检测和管理方案。", "keywords": "冠状动脉疾病, 早期预警, 面部基础模型, 实时视频, DigitalShadow", "comments": "这项工作具有重要的创新性和实用性。它利用了前沿的面部基础模型技术，将非接触式视频分析应用于疾病早期预警，这在医疗健康领域是一个非常有前景的方向。其被动、非接触式的特点极大地提高了用户依从性，而对隐私的强调（支持本地部署）则解决了当前医疗数据应用中的一大痛点。如果该系统的准确性和可靠性得到充分验证，将对CAD的早期筛查和预防产生深远影响。然而，抽象中未提及模型的具体性能指标，这是未来评估其实际应用价值的关键。"}}
{"id": "2506.06513", "title": "A Benchmarking Framework for Network Classification Methods", "authors": ["Joao V. Merenda", "Gonzalo Travieso", "Odemir M. Bruno"], "summary": "Network classification plays a crucial role in the study of complex systems,\nimpacting fields like biology, sociology, and computer science. In this\nresearch, we present an innovative benchmark dataset made up of synthetic\nnetworks that are categorized into various classes and subclasses. This dataset\nis specifically crafted to test the effectiveness and resilience of different\nnetwork classification methods. To put these methods to the test, we also\nintroduce various types and levels of structural noise. We evaluate five\nfeature extraction techniques: traditional structural measures, Life-Like\nNetwork Automata (LLNA), Graph2Vec, Deterministic Tourist Walk (DTW), and its\nimproved version, the Deterministic Tourist Walk with Bifurcation (DTWB). Our\nexperimental results reveal that DTWB surpasses the other methods in\nclassifying both classes and subclasses, even when faced with significant\nnoise. LLNA and DTW also perform well, while Graph2Vec lands somewhere in the\nmiddle in terms of accuracy. Interestingly, topological measures, despite their\nsimplicity and common usage, consistently show the weakest classification\nperformance. These findings underscore the necessity of robust feature\nextraction techniques for effective network classification, particularly in\nnoisy conditions.", "comment": "10 pages, 3 figures", "cate": "cs.SI", "url": "http://arxiv.org/abs/2506.06513v1", "AI": {"title_translation": "网络分类方法的基准测试框架", "tldr": "本研究提出了一个用于测试网络分类方法有效性的合成网络基准数据集，并引入了结构噪声。实验结果表明，DTWB在有噪声的情况下表现最佳，强调了鲁棒特征提取技术的重要性。", "motivation": "网络分类在复杂系统研究中至关重要，影响生物学、社会学和计算机科学等领域。为了测试不同网络分类方法的有效性和弹性，需要一个基准框架。", "method": "本研究提出了一个由合成网络组成的创新基准数据集，该数据集被分类为各种类别和子类别。为了测试这些方法，引入了各种类型和级别的结构噪声。评估了五种特征提取技术：传统结构测量、Life-Like Network Automata (LLNA)、Graph2Vec、Deterministic Tourist Walk (DTW)及其改进版本Deterministic Tourist Walk with Bifurcation (DTWB)。", "result": "实验结果表明，DTWB在分类类别和子类别方面均超越了其他方法，即使在面临显著噪声时也是如此。LLNA和DTW也表现良好，而Graph2Vec在准确性方面处于中等水平。拓扑测量尽管简单且常用，但始终表现出最弱的分类性能。", "conclusion": "这些发现强调了鲁棒特征提取技术对于有效网络分类的必要性，尤其是在有噪声的条件下。", "translation": "网络分类在复杂系统研究中扮演着至关重要的角色，影响着生物学、社会学和计算机科学等领域。在这项研究中，我们提出了一个由合成网络组成的创新基准数据集，这些网络被分为不同的类别和子类别。该数据集专门用于测试不同网络分类方法的有效性和弹性。为了测试这些方法，我们还引入了各种类型和级别的结构噪声。我们评估了五种特征提取技术：传统结构测量、生命般网络自动机（LLNA）、Graph2Vec、确定性旅行者漫步（DTW）及其改进版本——带分叉的确定性旅行者漫步（DTWB）。我们的实验结果表明，即使在面临显著噪声时，DTWB在分类类别和子类别方面均超越了其他方法。LLNA和DTW也表现良好，而Graph2Vec在准确性方面处于中等水平。有趣的是，拓扑测量尽管简单且常用，但始终表现出最弱的分类性能。这些发现强调了鲁棒特征提取技术对于有效网络分类的必要性，尤其是在有噪声的条件下。", "summary": "本研究提出了一个创新的合成网络基准数据集，用于评估不同网络分类方法的有效性和鲁棒性，并通过引入结构噪声来模拟真实条件。研究比较了五种特征提取技术：传统结构测量、LLNA、Graph2Vec、DTW和DTWB。结果显示，DTWB在噪声环境下表现出卓越的分类性能，优于其他所有方法。LLNA和DTW也表现良好，而拓扑测量表现最差。研究强调了在复杂和有噪声的网络分类任务中，鲁棒特征提取技术的重要性。", "keywords": "网络分类, 基准测试, 特征提取, 合成网络, 结构噪声", "comments": "这项研究的创新之处在于构建了一个带有结构噪声的合成网络基准数据集，这对于全面评估网络分类方法的鲁棒性至关重要。DTWB在噪声条件下的优异表现揭示了其在实际应用中的巨大潜力。研究结果也明确指出了传统拓扑测量在噪声环境下的局限性，并强调了更先进特征提取方法的必要性。"}}
{"id": "2506.06282", "title": "Understanding Financial Reasoning in AI: A Multimodal Benchmark and Error Learning Approach", "authors": ["Shuangyan Deng", "Haizhou Peng", "Jiachen Xu", "Chunhou Liu", "Ciprian Doru Giurcuaneanu", "Jiamou Liu"], "summary": "Effective financial reasoning demands not only textual understanding but also\nthe ability to interpret complex visual data such as charts, tables, and trend\ngraphs. This paper introduces a new benchmark designed to evaluate how well AI\nmodels - especially large language and multimodal models - reason in\nfinance-specific contexts. Covering 3,200 expert-level question-answer pairs\nacross 15 core financial topics, the benchmark integrates both textual and\nvisual modalities to reflect authentic analytical challenges in finance. To\naddress limitations in current reasoning approaches, we propose an error-aware\nlearning framework that leverages historical model mistakes and feedback to\nguide inference, without requiring fine-tuning. Our experiments across\nstate-of-the-art models show that multimodal inputs significantly enhance\nperformance and that incorporating error feedback leads to consistent and\nmeasurable improvements. The results highlight persistent challenges in visual\nunderstanding and mathematical logic, while also demonstrating the promise of\nself-reflective reasoning in financial AI systems. Our code and data can be\nfound at https://anonymous/FinMR/CodeData.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06282v1", "AI": {"title_translation": "理解人工智能中的金融推理：一个多模态基准和错误学习方法", "tldr": "有效的金融推理需要文本和视觉理解。本文提出了一个名为FinMR的多模态金融基准，包含3200个问答对，并引入了一个错误感知学习框架。实验表明，多模态输入和错误反馈显著提高了性能，但视觉理解和数学逻辑仍是挑战。", "motivation": "有效的金融推理不仅需要文本理解，还需要解释图表、表格和趋势图等复杂视觉数据的能力。现有AI模型在金融特定环境中的推理能力，特别是多模态推理方面存在局限性，需要新的评估方法和改进方案。", "method": "本文引入了一个名为FinMR的新型多模态金融推理基准，该基准包含15个核心金融主题的3200个专家级问答对，并整合了文本和视觉模态数据。此外，提出了一种错误感知学习框架，该框架利用历史模型错误和反馈来指导推理，无需进行微调。", "result": "实验表明，多模态输入显著提升了最先进模型的性能。结合错误反馈带来了持续且可衡量的改进。研究结果突出了在视觉理解和数学逻辑方面持续存在的挑战，同时也展示了金融AI系统中自我反思推理的潜力。", "conclusion": "多模态输入和错误反馈显著提升了AI在金融推理方面的能力，但在视觉理解和数学逻辑方面仍存在挑战。自我反思推理在未来的金融AI系统中展现出巨大潜力。", "translation": "有效的金融推理不仅需要文本理解，还需要解释图表、表格和趋势图等复杂视觉数据的能力。本文引入了一个新的基准，旨在评估人工智能模型——特别是大型语言和多模态模型——在金融特定环境中的推理能力。该基准涵盖了15个核心金融主题的3,200个专家级问答对，整合了文本和视觉模态，以反映金融领域真实的分析挑战。为了解决当前推理方法的局限性，我们提出了一种错误感知学习框架，该框架利用历史模型错误和反馈来指导推理，而无需进行微调。我们对最先进模型的实验表明，多模态输入显著提高了性能，并且结合错误反馈带来了持续和可衡量的改进。结果突出了视觉理解和数学逻辑方面持续存在的挑战，同时也展示了金融AI系统中自我反思推理的潜力。我们的代码和数据可在 https://anonymous/FinMR/CodeData 找到。", "summary": "本文介绍了FinMR，一个用于评估AI金融推理能力的新型多模态基准，包含15个金融主题的3200个问答对，整合了文本和视觉数据。同时，提出了一个利用历史模型错误指导推理的错误感知学习框架，无需微调。实验证明，多模态输入和错误反馈显著提升了性能，但视觉理解和数学逻辑仍是挑战，并展示了自我反思推理的潜力。", "keywords": "金融推理, 多模态AI, 基准, 错误学习, 金融数据分析", "comments": "该论文通过开发全面的多模态基准和创新的错误感知学习框架，解决了AI中金融推理能力的关键需求。将视觉数据整合并利用过去的错误进行自我纠正，是迈向更可靠和复杂的金融AI系统的重要一步。对视觉和数学逻辑中持续存在的挑战的识别，为未来的研究提供了明确的方向。"}}
{"id": "2506.06749", "title": "Statistical Limits for Finite-Rank Tensor Estimation", "authors": ["Riccardo Rossetti", "Galen Reeves"], "summary": "This paper provides a unified framework for analyzing tensor estimation\nproblems that allow for nonlinear observations, heteroskedastic noise, and\ncovariate information. We study a general class of high-dimensional models\nwhere each observation depends on the interactions among a finite number of\nunknown parameters. Our main results provide asymptotically exact formulas for\nthe mutual information (equivalently, the free energy) as well as the minimum\nmean-squared error in the Bayes-optimal setting. We then apply this framework\nto derive sharp characterizations of statistical thresholds for two novel\nscenarios: (1) tensor estimation in heteroskedastic noise that is independent\nbut not identically distributed, and (2) higher-order assignment problems,\nwhere the goal is to recover an unknown permutation from tensor-valued\nobservations.", "comment": "25 pages, 0 figures", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.06749v1", "AI": {"title_translation": "有限秩张量估计的统计极限", "tldr": "本文提供了一个统一的框架来分析张量估计问题，包括非线性观测、异方差噪声和协变量信息，并推导出贝叶斯最优设置下的互信息和最小均方误差的渐近精确公式，同时应用于两种新颖场景的统计阈值表征。", "motivation": "该研究旨在为允许非线性观测、异方差噪声和协变量信息的张量估计问题提供一个统一的分析框架，特别关注高维模型中观测值依赖于有限数量未知参数之间相互作用的情况。", "method": "本文建立了一个统一的框架来分析张量估计问题，该框架能够处理非线性观测、异方差噪声和协变量信息。主要方法是推导出贝叶斯最优设置下互信息（或自由能）以及最小均方误差的渐近精确公式，并将此框架应用于推导两种新颖场景的统计阈值。", "result": "主要结果是推导出了贝叶斯最优设置下互信息（或自由能）以及最小均方误差的渐近精确公式。该框架被应用于推导两种新颖场景的统计阈值的精确表征：(1) 独立但非同分布的异方差噪声下的张量估计，和 (2) 高阶分配问题（从张量值观测中恢复未知排列）。", "conclusion": "本文成功提供了一个统一的框架，能够处理复杂的张量估计问题，并为贝叶斯最优设置下的统计极限提供了精确的表征，同时为异方差噪声和高阶分配问题提供了尖锐的统计阈值分析。", "translation": "本文提供了一个分析张量估计问题的统一框架，该框架允许非线性观测、异方差噪声和协变量信息。我们研究了一类通用的高维模型，其中每个观测值都取决于有限数量未知参数之间的相互作用。我们的主要结果提供了互信息（等效地，自由能）以及贝叶斯最优设置下最小均方误差的渐近精确公式。然后，我们将此框架应用于推导两种新颖场景的统计阈值的精确表征：(1) 在独立但非同分布的异方差噪声下的张量估计，以及 (2) 高阶分配问题，其目标是从张量值观测中恢复未知排列。", "summary": "本研究提出一个统一框架，用于分析包含非线性观测、异方差噪声和协变量信息的高维张量估计问题。核心贡献在于推导出贝叶斯最优设置下互信息和最小均方误差的渐近精确公式。该框架进一步应用于精确刻画了两种新颖场景的统计阈值：异方差噪声下的张量估计和高阶分配问题。", "keywords": "张量估计, 统计极限, 高维模型, 异方差噪声, 分配问题", "comments": "这篇论文的创新之处在于其提供了一个统一且通用的框架，能够处理传统方法难以解决的非线性、异方差噪声和协变量信息等复杂情况。其推导出的渐近精确公式对于理解复杂高维张量估计问题的统计极限具有重要理论价值。该工作对信号处理、机器学习等领域中张量数据分析具有重要指导意义。"}}
{"id": "2506.06693", "title": "Design and Implementation of a RISC-V SoC with Custom DSP Accelerators for Edge Computing", "authors": ["Priyanshu Yadav"], "summary": "This paper presents a comprehensive analysis of the RISC-V instruction set\narchitecture, focusing on its modular design, implementation challenges, and\nperformance characteristics. We examine the RV32I base instruction set with\nextensions for multiplication (M) and atomic operations (A). Through\ncycle-accurate simulation of a pipelined implementation, we evaluate\nperformance metrics including CPI (cycles per instruction) and power\nefficiency. Our results demonstrate RISC-V's advantages in embedded systems and\nits scalability for custom accelerators. Comparative analysis shows a 17%\nreduction in power consumption compared to ARM Cortex-M0 implementations in\nsimilar process nodes. The open-standard nature of RISC-V provides significant\nflexibility for domain-specific optimizations.", "comment": "12 Pages, 1 figure", "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.06693v1", "AI": {"title_translation": "面向边缘计算的RISC-V SoC及定制DSP加速器设计与实现", "tldr": "本文分析了RISC-V指令集架构的模块化设计、性能和功耗效率，展示了其在嵌入式系统和定制加速器中的优势，并显示相比ARM Cortex-M0功耗降低17%。", "motivation": "旨在全面分析RISC-V指令集架构，重点关注其模块化设计、实现挑战和性能特征，以证明其在嵌入式系统中的优势以及对定制加速器的可扩展性，尤其适用于边缘计算。", "method": "研究人员对RISC-V指令集架构（RV32I及M、A扩展）进行了全面分析。他们通过对流水线实现的周期精确仿真，评估了CPI和功耗效率等性能指标，并与ARM Cortex-M0进行了比较分析。", "result": "研究结果表明RISC-V在嵌入式系统和定制加速器方面具有优势和可扩展性。与类似工艺节点中的ARM Cortex-M0实现相比，功耗降低了17%。", "conclusion": "RISC-V是一种适合嵌入式系统和定制加速器的灵活开放标准架构，为边缘计算应用提供了显著的功耗效率优势。", "translation": "本文对RISC-V指令集架构进行了全面分析，重点关注其模块化设计、实现挑战和性能特征。我们研究了带有乘法(M)和原子操作(A)扩展的RV32I基本指令集。通过对流水线实现的周期精确仿真，我们评估了包括CPI(每指令周期)和功耗效率在内的性能指标。我们的结果表明RISC-V在嵌入式系统中的优势及其对定制加速器的可扩展性。比较分析显示，与类似工艺节点中的ARM Cortex-M0实现相比，功耗降低了17%。RISC-V的开放标准性质为领域特定优化提供了显著的灵活性。", "summary": "本文通过对RISC-V指令集架构（特别是带有M和A扩展的RV32I）进行周期精确仿真分析，评估了其性能指标和功耗效率。研究结果展示了RISC-V在嵌入式系统中的优势及其对定制加速器的可扩展性。与ARM Cortex-M0的比较分析显示，RISC-V的功耗降低了17%，突出了其在边缘计算领域进行特定领域优化的灵活性。", "keywords": "RISC-V, 边缘计算, DSP加速器, SoC, 功耗效率", "comments": "该论文的创新之处在于展示了RISC-V在边缘计算领域的实际优势，特别是其功耗效率和对定制DSP加速器的灵活性，这对于资源受限的边缘设备至关重要。与ARM Cortex-M0的对比分析为RISC-V的竞争力提供了有力证据。"}}
{"id": "2506.06290", "title": "CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning", "authors": ["Mingyu Lu", "Ethan Weinberger", "Chanwoo Kim", "Su-In Lee"], "summary": "High-content screening (HCS) assays based on high-throughput microscopy\ntechniques such as Cell Painting have enabled the interrogation of cells'\nmorphological responses to perturbations at an unprecedented scale. The\ncollection of such data promises to facilitate a better understanding of the\nrelationships between different perturbations and their effects on cellular\nstate. Towards achieving this goal, recent advances in cross-modal contrastive\nlearning could, in theory, be leveraged to learn a unified latent space that\naligns perturbations with their corresponding morphological effects. However,\nthe application of such methods to HCS data is not straightforward due to\nsubstantial differences in the semantics of Cell Painting images compared to\nnatural images, and the difficulty of representing different classes of\nperturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent\nspace. In response to these challenges, here we introduce CellCLIP, a\ncross-modal contrastive learning framework for HCS data. CellCLIP leverages\npre-trained image encoders coupled with a novel channel encoding scheme to\nbetter capture relationships between different microscopy channels in image\nembeddings, along with natural language encoders for representing\nperturbations. Our framework outperforms current open-source models,\ndemonstrating the best performance in both cross-modal retrieval and\nbiologically meaningful downstream tasks while also achieving significant\nreductions in computation time.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06290v1", "AI": {"title_translation": "CellCLIP——通过文本引导的对比学习来学习细胞图谱中的扰动效应", "tldr": "CellCLIP是一个用于高内涵筛选（HCS）数据的跨模态对比学习框架，它解决了传统方法在细胞图谱图像和扰动表示上的挑战，通过结合预训练图像编码器和新型通道编码方案，以及自然语言编码器来表示扰动，从而在跨模态检索和生物学下游任务中表现优异，并显著减少计算时间。", "motivation": "高内涵筛选（HCS）技术（如细胞图谱）能够大规模地研究细胞对扰动的形态反应。理论上，跨模态对比学习可以帮助理解不同扰动及其对细胞状态的影响，但将此类方法应用于HCS数据面临挑战，包括细胞图谱图像与自然图像语义的巨大差异，以及在单一潜在空间中表示不同类型扰动（如小分子与CRISPR基因敲除）的难度。", "method": "本文引入了CellCLIP，一个用于HCS数据的跨模态对比学习框架。CellCLIP利用预训练的图像编码器结合新颖的通道编码方案，以更好地捕获图像嵌入中不同显微镜通道之间的关系，并使用自然语言编码器来表示扰动。", "result": "CellCLIP框架优于当前的开源模型，在跨模态检索和生物学意义的下游任务中均表现出最佳性能，同时显著减少了计算时间。", "conclusion": "CellCLIP成功地解决了将跨模态对比学习应用于高内涵筛选数据的挑战，提供了一个高效且高性能的框架，能够更好地理解扰动对细胞形态的影响。", "translation": "高内涵筛选（HCS）检测，基于高通量显微镜技术，如细胞图谱（Cell Painting），已经实现了对细胞对扰动的形态反应进行前所未有的规模的探究。收集此类数据有望促进更好地理解不同扰动及其对细胞状态之间关系。为了实现这一目标，跨模态对比学习的最新进展理论上可以被利用来学习一个统一的潜在空间，将扰动与其相应的形态效应对齐。然而，由于细胞图谱图像与自然图像的语义存在实质性差异，以及在单一潜在空间中表示不同类别扰动（例如，小分子与CRISPR基因敲除）的难度，将此类方法应用于HCS数据并不直接。为了应对这些挑战，我们在此引入了CellCLIP，一个用于HCS数据的跨模态对比学习框架。CellCLIP利用预训练的图像编码器结合新颖的通道编码方案，以更好地捕获图像嵌入中不同显微镜通道之间的关系，并结合自然语言编码器来表示扰动。我们的框架优于当前的开源模型，在跨模态检索和具有生物学意义的下游任务中均表现出最佳性能，同时显著减少了计算时间。", "summary": "本文介绍了CellCLIP，一个针对高内涵筛选（HCS）数据的跨模态对比学习框架。该框架旨在克服将现有跨模态对比学习方法应用于细胞图谱数据时的挑战，特别是细胞图像语义的差异性以及统一表示多种扰动类型的困难。CellCLIP通过结合预训练图像编码器、新颖的通道编码方案以及自然语言编码器来表示扰动，从而学习扰动与其对应的形态效应之间的统一潜在空间。实验结果表明，CellCLIP在跨模态检索和生物学下游任务中均优于现有开源模型，并显著降低了计算成本。", "keywords": "高内涵筛选, 细胞图谱, 对比学习, 跨模态, 扰动效应", "comments": "CellCLIP的创新之处在于其针对细胞图谱数据的特性，引入了新颖的通道编码方案来优化图像嵌入，并结合了自然语言编码器来统一表示不同类型的扰动。这解决了传统跨模态对比学习方法在应用于高内涵筛选数据时的核心挑战。该方法的重要性在于其能够更有效地理解细胞对扰动的形态反应，为药物发现和疾病研究提供强大的工具。计算时间的显著减少也使其具有很高的实用价值。"}}
{"id": "2506.06286", "title": "Disentangling AI Alignment: A Structured Taxonomy Beyond Safety and Ethics", "authors": ["Kevin Baum"], "summary": "Recent advances in AI research make it increasingly plausible that artificial\nagents with consequential real-world impact will soon operate beyond tightly\ncontrolled environments. Ensuring that these agents are not only safe but that\nthey adhere to broader normative expectations is thus an urgent\ninterdisciplinary challenge. Multiple fields -- notably AI Safety, AI\nAlignment, and Machine Ethics -- claim to contribute to this task. However, the\nconceptual boundaries and interrelations among these domains remain vague,\nleaving researchers without clear guidance in positioning their work.\n  To address this meta-challenge, we develop a structured conceptual framework\nfor understanding AI alignment. Rather than focusing solely on alignment goals,\nwe introduce a taxonomy distinguishing the alignment aim (safety, ethicality,\nlegality, etc.), scope (outcome vs. execution), and constituency (individual\nvs. collective). This structural approach reveals multiple legitimate alignment\nconfigurations, providing a foundation for practical and philosophical\nintegration across domains, and clarifying what it might mean for an agent to\nbe aligned all-things-considered.", "comment": "accepted for the LNCS post proceedings of the AISoLA 2024 conference", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06286v1", "AI": {"title_translation": "解构AI对齐：超越安全与伦理的结构化分类法", "tldr": "本文提出了一个结构化的概念框架，通过区分对齐目标、范围和受众来理解AI对齐，以解决AI安全、对齐和机器伦理领域概念边界模糊的问题，并促进跨领域的整合。", "motivation": "随着AI代理日益脱离受控环境并在现实世界中产生影响，确保它们不仅安全而且符合更广泛的规范性期望成为一项紧迫的跨学科挑战。然而，AI安全、AI对齐和机器伦理等相关领域的概念界限和相互关系仍然模糊不清，导致研究人员缺乏明确的指导。", "method": "为了解决这一元挑战，本文开发了一个结构化的概念框架来理解AI对齐。该框架不只关注对齐目标，而是引入了一个分类法，区分了对齐目的（安全性、伦理性、合法性等）、范围（结果vs.执行）和受众（个体vs.集体）。", "result": "这种结构化方法揭示了多种合法的对齐配置，为跨领域的实践和哲学整合奠定了基础，并阐明了代理在“全面考虑”下对齐的含义。", "conclusion": "本文提出的结构化分类法有助于澄清AI对齐的复杂性，为理解和实现AI的全面对齐提供了理论基础和整合视角。", "translation": "人工智能研究的最新进展使得具有重大现实世界影响的人工智能代理很快将超越严格受控环境运行变得越来越可能。因此，确保这些代理不仅安全而且符合更广泛的规范性期望，是一项紧迫的跨学科挑战。多个领域——特别是人工智能安全、人工智能对齐和机器伦理——声称对此任务有所贡献。然而，这些领域之间的概念界限和相互关系仍然模糊不清，使得研究人员在定位其工作时缺乏明确的指导。\n为了解决这一元挑战，我们开发了一个结构化的概念框架来理解人工智能对齐。我们不只关注对齐目标，而是引入了一个分类法，区分了对齐目的（安全性、伦理性、合法性等）、范围（结果与执行）和受众（个体与集体）。这种结构化方法揭示了多种合法的对齐配置，为跨领域的实践和哲学整合提供了基础，并阐明了代理在“全面考虑”下对齐的含义。", "summary": "本文提出了一种结构化的AI对齐概念框架，旨在解决AI安全、对齐和机器伦理领域中概念边界模糊的问题。该框架通过区分对齐目的（如安全、伦理、合法性）、范围（结果或执行）和受众（个体或集体），揭示了多种有效的对齐配置，为跨学科整合提供了基础，并明确了AI代理“全面考虑”下对齐的含义。", "keywords": "AI对齐, 分类法, AI安全, 机器伦理, 规范性期望", "comments": "该论文创新性地提出了一个结构化的AI对齐分类法，超越了传统的安全和伦理范畴，引入了目的、范围和受众维度，极大地澄清了AI对齐领域的复杂性。这对于促进跨学科研究和实际部署全面对齐的AI系统具有重要意义。"}}
{"id": "2506.06448", "title": "Generating representative macrobenchmark microservice systems from distributed traces with Palette", "authors": ["Vaastav Anand", "Matheus Stolet", "Jonathan Mace", "Antoine Kaufmann"], "summary": "Microservices are the dominant design for developing cloud systems\n  today. Advancements for microservice need to be evaluated in representative\nsystems, e.g. with matching scale, topology, and execution patterns.\n  Unfortunately in practice, researchers and practitioners alike often do not\nhave access to representative systems. Thus they have to resort to sub-optimal\nnon-representative alternatives, e.g. small and oversimplified synthetic\nbenchmark systems or simulated system models instead.\n  To solve this issue, we propose the use of distributed trace datasets,\navailable from large internet companies,\n  to generate representative microservice systems.\n  To do so, we introduce a novel abstraction of a system topology which uses\nGraphical Causal Models (GCMs)\n  to model the underlying system by incorporating the branching probabilities,\nexecution order of outgoing\n  calls to every dependency, and execution times.\n  We then incorporate this topology in Palette, a system that generates\n  representative flexible macrobenchmarks microservice systems from distributed\ntraces.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.06448v1", "AI": {"title_translation": "使用Palette从分布式跟踪生成代表性宏基准微服务系统", "tldr": "Palette系统利用大型互联网公司的分布式跟踪数据，通过图形因果模型抽象系统拓扑，生成代表性宏基准微服务系统，以解决研究人员和从业者缺乏代表性评估系统的问题。", "motivation": "微服务系统在评估其进展时需要代表性系统（具有匹配的规模、拓扑和执行模式），但研究人员和从业者通常无法获得此类系统，只能使用次优的非代表性替代方案，如小型、过度简化的合成基准系统或模拟模型。", "method": "提出使用来自大型互联网公司的分布式跟踪数据集来生成代表性微服务系统。引入了一种新颖的系统拓扑抽象，该抽象使用图形因果模型（GCMs）来建模底层系统，其中包含分支概率、对外调用执行顺序和执行时间。然后将此拓扑整合到Palette系统中，该系统能够从分布式跟踪生成代表性灵活的宏基准微服务系统。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "微服务是当今开发云系统的主导设计。微服务的进步需要在具有代表性的系统中进行评估，例如具有匹配的规模、拓扑和执行模式的系统。不幸的是，在实践中，研究人员和从业者往往无法获得代表性系统。因此，他们不得不求助于次优的非代表性替代方案，例如小型且过度简化的合成基准系统或模拟系统模型。\n为了解决这个问题，我们建议使用大型互联网公司提供的分布式跟踪数据集来生成代表性微服务系统。为此，我们引入了一种新颖的系统拓扑抽象，该抽象使用图形因果模型（GCMs）来建模底层系统，其中包含分支概率、对外调用执行顺序和执行时间。然后，我们将此拓扑整合到Palette中，Palette是一个从分布式跟踪生成代表性灵活宏基准微服务系统的系统。", "summary": "该论文旨在解决微服务系统评估中缺乏代表性系统的问题。作者提出利用大型互联网公司提供的分布式跟踪数据集来生成此类系统。为此，他们引入了一种基于图形因果模型（GCMs）的新颖系统拓扑抽象，该模型能够捕捉系统中的分支概率、调用执行顺序和执行时间。最终，该拓扑被集成到名为Palette的系统中，该系统能够根据分布式跟踪数据生成代表性的、灵活的宏基准微服务系统。", "keywords": "微服务, 分布式跟踪, 宏基准测试, 图形因果模型, 系统生成", "comments": "这篇论文提出了一种创新方法，通过利用实际分布式跟踪数据来生成代表性微服务宏基准系统，解决了当前微服务研究和实践中评估环境不具代表性的痛点。其核心创新在于使用图形因果模型（GCMs）来抽象和建模复杂的系统拓扑，这使得生成的基准系统能更好地反映真实世界的行为模式。如果该方法能够有效且广泛地应用，将极大地推动微服务领域的研究和开发。"}}
{"id": "2506.06469", "title": "Steps towards an Ecology for the Internet", "authors": ["Anil Madhavapeddy", "Sam Reynolds", "Alec P. Christie", "David A. Coomes", "Michael W. Dales", "Patrick Ferris", "Ryan Gibb", "Hamed Haddadi", "Sadiq Jaffer", "Josh Millar", "Cyrus Omar", "William J. Sutherland", "Jon Crowcroft"], "summary": "The Internet has grown from a humble set of protocols for end-to-end\nconnectivity into a critical global system with no builtin \"immune system\". In\nthe next decade the Internet will likely grow to a trillion nodes and need\nprotection from threats ranging from floods of fake generative data to\nAI-driven malware. Unfortunately, growing centralisation has lead to the\nbreakdown of mutualism across the network, with surveillance capitalism now the\ndominant business model. We take lessons from from biological systems towards\nevolving a more resilient Internet that can integrate adaptation mechanisms\ninto its fabric. We also contribute ideas for how the Internet might\nincorporate digital immune systems, including how software stacks might mutate\nto encourage more architectural diversity. We strongly advocate for the\nInternet to \"re-decentralise\" towards incentivising more mutualistic forms of\ncommunication.", "comment": "To appear in the sixth decennial Aarhus conference: Computing X\n  Crisis, Aug 2025", "cate": "cs.NI", "url": "http://arxiv.org/abs/2506.06469v1", "AI": {"title_translation": "迈向互联网生态的步骤", "tldr": "本文探讨了互联网缺乏内置“免疫系统”且日益中心化的问题，提出借鉴生物系统，通过去中心化和引入适应机制来构建更具弹性的互联网，以应对未来威胁。", "motivation": "互联网已成为关键的全球系统，但缺乏内置的“免疫系统”，面临着从虚假生成数据洪水到AI驱动恶意软件等威胁。日益增长的中心化导致网络互惠互利关系破裂，监视资本主义成为主导商业模式。为了应对未来万亿节点互联网的挑战，需要构建一个更具弹性的系统。", "method": "本文借鉴生物系统的经验，旨在将适应机制整合到互联网的结构中。提出如何将数字免疫系统融入互联网，包括软件栈如何变异以鼓励更多的架构多样性。强烈主张互联网“再中心化”以激励更多的互惠互利形式的通信。", "result": "Not mentioned in abstract", "conclusion": "本文强烈主张互联网应“再中心化”，以激励更多的互惠互利形式的通信，并融入类似生物系统的适应机制和数字免疫系统，从而构建一个更具弹性的未来互联网。", "translation": "互联网已从一套简单的端到端连接协议发展成为一个关键的全球系统，但缺乏内置的“免疫系统”。在未来十年，互联网可能会增长到万亿个节点，需要保护其免受从虚假生成数据洪水到AI驱动恶意软件等各种威胁。不幸的是，日益增长的中心化导致了网络互惠互利关系的破裂，监视资本主义现在是主导的商业模式。我们从生物系统中汲取经验，以发展一个更具弹性的互联网，使其能够将适应机制整合到其结构中。我们还为互联网如何整合数字免疫系统贡献了想法，包括软件栈如何变异以鼓励更多的架构多样性。我们强烈主张互联网“再中心化”，以激励更多的互惠互利形式的通信。", "summary": "本文指出当前互联网缺乏“免疫系统”且过度中心化，难以应对未来万亿节点可能面临的AI恶意软件和虚假数据等威胁。作者提出借鉴生物系统的进化和适应机制，构建一个更具弹性的互联网，包括引入数字免疫系统和鼓励软件栈多样性。核心主张是互联网应“再中心化”，以促进更健康的互惠通信模式。", "keywords": "互联网生态, 数字免疫系统, 去中心化, 弹性网络, 生物系统", "comments": "本文提出了一个引人深思的观点，将互联网的未来发展与生物生态系统进行类比，强调了去中心化和引入“免疫系统”的重要性。这种跨学科的视角为解决当前互联网面临的中心化、安全性和弹性问题提供了新的思路，具有潜在的创新性和重要性。其对“再中心化”的倡导，对于构建更公平、更安全的网络环境具有积极意义。"}}
{"id": "2506.06356", "title": "Deep Learning Enhanced Multi-Day Turnover Quantitative Trading Algorithm for Chinese A-Share Market", "authors": ["Yimin Du"], "summary": "This paper presents a sophisticated multi-day turnover quantitative trading\nalgorithm that integrates advanced deep learning techniques with comprehensive\ncross-sectional stock prediction for the Chinese A-share market. Our framework\ncombines five interconnected modules: initial stock selection through deep\ncross-sectional prediction networks, opening signal distribution analysis using\nmixture models for arbitrage identification, market capitalization and\nliquidity-based dynamic position sizing, grid-search optimized profit-taking\nand stop-loss mechanisms, and multi-granularity volatility-based market timing\nmodels. The algorithm employs a novel approach to balance capital efficiency\nwith risk management through adaptive holding periods and sophisticated\nentry/exit timing. Trained on comprehensive A-share data from 2010-2020 and\nrigorously backtested on 2021-2024 data, our method achieves remarkable\nperformance with 15.2\\% annualized returns, maximum drawdown constrained below\n5\\%, and a Sharpe ratio of 1.87. The strategy demonstrates exceptional\nscalability by maintaining 50-100 daily positions with a 9-day maximum holding\nperiod, incorporating dynamic profit-taking and stop-loss mechanisms that\nenhance capital turnover efficiency while preserving risk-adjusted returns. Our\napproach exhibits robust performance across various market regimes while\nmaintaining high capital capacity suitable for institutional deployment.", "comment": "10 pages", "cate": "cs.CE", "url": "http://arxiv.org/abs/2506.06356v1", "AI": {"title_translation": "深度学习增强的中国A股市场多日周转量化交易算法", "tldr": "本文提出了一种结合深度学习和多模块策略的中国A股市场多日周转量化交易算法，实现了高年化收益和低最大回撤。", "motivation": "论文旨在为中国A股市场开发一种先进的、结合深度学习和多模块策略的量化交易算法，以实现资本效率与风险管理的平衡，并获得卓越的交易表现。", "method": "该算法是一个多日周转量化交易算法，整合了深度学习技术和全面的横截面股票预测。它包含五个相互关联的模块：通过深度横截面预测网络进行初始股票选择；使用混合模型进行开盘信号分布分析以识别套利机会；基于市值和流动性的动态头寸调整；网格搜索优化的止盈止损机制；以及多粒度基于波动率的市场择时模型。算法通过自适应持有期和复杂的进出场时机来平衡资本效率和风险管理。", "result": "算法在2010-2020年数据上训练，在2021-2024年数据上回测，实现了15.2%的年化收益率，最大回撤低于5%，夏普比率为1.87。该策略每天保持50-100个头寸，最长持有期为9天，通过动态止盈止损机制提高了资本周转效率，同时保持了风险调整后的回报。", "conclusion": "该算法在中国A股市场表现出强大的鲁棒性，在不同市场机制下均能保持高性能，并具有适合机构部署的高资本容量。", "translation": "本文提出了一种复杂的、结合了先进深度学习技术和全面横截面股票预测的中国A股市场多日周转量化交易算法。我们的框架结合了五个相互关联的模块：通过深度横截面预测网络进行初始股票选择、使用混合模型进行开盘信号分布分析以识别套利机会、基于市值和流动性的动态头寸调整、网格搜索优化的止盈止损机制，以及多粒度基于波动率的市场择时模型。该算法采用一种新颖的方法，通过自适应持有期和复杂的进出场时机来平衡资本效率与风险管理。该方法在2010-2020年的A股综合数据上进行训练，并在2021-2024年的数据上进行了严格的回测，取得了显著的性能，年化收益率为15.2%，最大回撤控制在5%以下，夏普比率为1.87。该策略通过保持50-100个日常头寸（最长持有期9天）展示了卓越的可扩展性，并结合了动态止盈止损机制，在保持风险调整后回报的同时提高了资本周转效率。我们的方法在各种市场机制下均表现出强大的鲁棒性，同时保持了适合机构部署的高资本容量。", "summary": "本文提出一种面向中国A股市场的深度学习增强型多日周转量化交易算法。该算法整合了深度学习驱动的股票预测和五个关键模块，包括股票选择、开盘信号分析、动态仓位管理、止盈止损及市场择时。经过2010-2020年数据训练和2021-2024年数据回测，该策略实现了15.2%的年化收益率、低于5%的最大回撤和1.87的夏普比率，表现出高资本效率、低风险和机构部署潜力。", "keywords": "深度学习, 量化交易, A股市场, 多日周转, 风险管理", "comments": "这篇论文的创新点在于将深度学习与一个多模块、综合性的量化交易框架相结合，特别针对中国A股市场进行了优化。其强调资本效率、风险管理以及在实际市场条件下的鲁棒性，并提供了令人印象深刻的回测结果，表明其在实际应用中的潜力。多模块的设计使其能够处理复杂的市场动态，而深度学习的应用则提升了预测的准确性。"}}
{"id": "2506.06530", "title": "Breaking the Gaussian Barrier: Residual-PAC Privacy for Automatic Privatization", "authors": ["Tao Zhang", "Yevgeniy Vorobeychik"], "summary": "The Probably Approximately Correct (PAC) Privacy framework [1] provides a\npowerful instance-based methodology for certifying privacy in complex\ndata-driven systems. However, existing PAC Privacy algorithms rely on a\nGaussian mutual information upper bound. We show that this is in general too\nconservative: the upper bound obtained by these algorithms is tight if and only\nif the perturbed mechanism output is jointly Gaussian with independent Gaussian\nnoise. To address the inefficiency inherent in the Gaussian-based approach, we\nintroduce Residual PAC Privacy, an f-divergence-based measure that quantifies\nthe privacy remaining after adversarial inference. When instantiated with\nKullback-Leibler divergence, Residual-PAC Privacy is governed by conditional\nentropy. Moreover, we propose Stackelberg Residual-PAC (SR-PAC) privatization\nmechanisms for RPAC Privacy, a game-theoretic framework that selects optimal\nnoise distributions through convex bilevel optimization. Our approach achieves\ntight privacy budget utilization for arbitrary data distributions. Moreover, it\nnaturally composes under repeated mechanisms and provides provable privacy\nguarantees with higher statistical efficiency. Numerical experiments\ndemonstrate that SR-PAC certifies the target privacy budget while consistently\nimproving utility compared to existing methods.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06530v1", "AI": {"title_translation": "突破高斯屏障：用于自动私有化的残差PAC隐私", "tldr": "现有PAC隐私算法依赖高斯上界过于保守，本文提出基于f-散度的残差PAC隐私和SR-PAC机制，实现更紧密的隐私预算利用和更高的效用。", "motivation": "现有PAC隐私算法依赖于高斯互信息上界，这被证明过于保守且效率低下，仅在特定高斯噪声条件下才紧密。", "method": "引入了基于f-散度的残差PAC隐私度量，用于量化对抗性推断后剩余的隐私。进一步提出了Stackelberg残差PAC (SR-PAC) 私有化机制，这是一个通过凸双层优化选择最优噪声分布的博弈论框架。", "result": "该方法实现了对任意数据分布的紧密隐私预算利用，在重复机制下具有良好的可组合性，并提供了具有更高统计效率的可证明隐私保证。数值实验表明，SR-PAC在保证目标隐私预算的同时，持续提高了效用。", "conclusion": "通过引入残差PAC隐私和SR-PAC机制，本文成功克服了现有PAC隐私框架中高斯上界的保守性问题，实现了更高效、更灵活且实用性更强的隐私保护。", "translation": "概率近似正确 (PAC) 隐私框架 [1] 提供了一种强大的基于实例的方法，用于认证复杂数据驱动系统中的隐私。然而，现有的PAC隐私算法依赖于高斯互信息上界。我们表明这通常过于保守：这些算法获得的上限当且仅当扰动机制输出与独立高斯噪声联合高斯时才是紧密的。为了解决基于高斯方法固有的低效率问题，我们引入了残差PAC隐私，这是一种基于f-散度的度量，用于量化对抗性推断后剩余的隐私。当用Kullback-Leibler散度实例化时，残差PAC隐私受条件熵控制。此外，我们针对RPAC隐私提出了Stackelberg残差PAC (SR-PAC) 私有化机制，这是一个通过凸双层优化选择最优噪声分布的博弈论框架。我们的方法实现了对任意数据分布的紧密隐私预算利用。此外，它在重复机制下自然地组合，并提供了具有更高统计效率的可证明隐私保证。数值实验表明，SR-PAC在认证目标隐私预算的同时，与现有方法相比持续提高了效用。", "summary": "本文针对现有PAC隐私框架中基于高斯互信息上界过于保守的问题，提出了创新的残差PAC隐私度量，该度量基于f-散度，能更准确地量化对抗性推断后的剩余隐私。在此基础上，进一步引入了Stackelberg残差PAC (SR-PAC) 私有化机制，该机制利用博弈论和凸双层优化选择最优噪声分布。实验证明，SR-PAC能够为任意数据分布提供紧密的隐私预算利用，提高统计效率，并在保持隐私预算的同时显著提升数据效用。", "keywords": "残差PAC隐私, f-散度, Stackelberg残差PAC, 隐私保护, 效用", "comments": "这篇论文通过引入残差PAC隐私和SR-PAC机制，成功地“突破了高斯屏障”，解决了现有PAC隐私框架在隐私预算利用上的保守性问题。其创新点在于引入了f-散度来衡量隐私，并结合博弈论优化噪声分布，使得隐私保护更加灵活高效，且对数据分布的普适性更强。这对于实际应用中实现更紧密的隐私预算和更高的数据效用具有重要意义。"}}
{"id": "2506.07232", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "authors": ["Xinran Li", "Chenjia Bai", "Zijian Li", "Jiakun Zheng", "Ting Xiao", "Jun Zhang"], "summary": "Large language models (LLMs) possess extensive knowledge bases and strong\nreasoning capabilities, making them promising tools for complex, multi-agent\nplanning in embodied environments. However, despite LLMs' advanced abilities\nand the sophisticated modular design of agentic methods, existing LLM-based\nplanning algorithms remain limited by weak adaptation capabilities to\nmulti-agent embodied scenarios. We address this limitation by introducing a\nframework that enables LLM agents to learn and evolve both before and during\ntest time, equipping them with environment-relevant knowledge for better\nplanning and enhanced communication for improved cooperation. Inspired by\ncentralized training with decentralized execution in multi-agent reinforcement\nlearning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)}\nparadigm for multi-agent LLMs adaptation. At the individual level, LLM agents\nlearn a local utility function from exploratory datasets to better comprehend\nthe embodied environment, which is then queried during test time to support\ninformed decision-making. At the team level, LLM agents collaboratively and\niteratively maintain and update a shared cooperation knowledge list based on\nnew experiences, using it to guide more effective communication. By combining\nindividual learning with team evolution, LIET enables comprehensive and\nflexible adaptation for LLM agents. Our experiments on Communicative\nWatch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate\nthat LIET, instantiated with both LLaMA and GPT-4o, outperforms existing\nbaselines and exhibits strong cooperative planning abilities.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.07232v1", "AI": {"title_translation": "个体学习，团队进化：具身环境中多智能体LLM的适应性", "tldr": "本文提出了一种名为LIET（Learn as Individuals, Evolve as a Team）的框架，旨在解决大型语言模型（LLMs）在具身多智能体环境中适应性不足的问题。LIET通过结合个体学习（理解环境）和团队进化（协作知识共享）使LLM智能体能更好地规划和沟通。实验证明，LIET在多项基准测试中优于现有基线，展现出强大的协作规划能力。", "motivation": "尽管大型语言模型（LLMs）拥有广泛的知识库和强大的推理能力，并且代理方法设计精巧，但现有的基于LLM的规划算法在多智能体具身场景中的适应能力仍然有限。", "method": "本文引入了一个名为“个体学习，团队进化（LIET）”的范式来解决多智能体LLM的适应性问题。在个体层面，LLM智能体从探索性数据集中学习一个局部效用函数，以更好地理解具身环境，并在测试时查询该函数以支持知情决策。在团队层面，LLM智能体根据新经验协作迭代地维护和更新一个共享的协作知识列表，并利用它来指导更有效的沟通。通过结合个体学习和团队进化，LIET实现了LLM智能体的全面而灵活的适应。", "result": "在Communicative Watch-And-Help和ThreeD-World Multi-Agent Transport基准测试中的实验表明，使用LLaMA和GPT-4o实例化的LIET框架，其性能优于现有基线，并展现出强大的协作规划能力。", "conclusion": "LIET通过结合个体学习和团队进化，为LLM智能体提供了全面而灵活的适应能力，使其在具身环境中展现出强大的协作规划能力。", "translation": "大型语言模型（LLMs）拥有广泛的知识库和强大的推理能力，使其成为具身环境中复杂多智能体规划的有力工具。然而，尽管LLMs具有先进的能力和代理方法的复杂模块化设计，但现有的基于LLM的规划算法仍然受限于对多智能体具身场景的弱适应能力。我们通过引入一个框架来解决这一限制，该框架使LLM智能体能够在测试前和测试期间进行学习和进化，从而为它们配备与环境相关的知识，以实现更好的规划，并增强沟通以改进合作。受多智能体强化学习中集中训练去中心化执行的启发，我们提出了一种“个体学习，团队进化（LIET）”的范式，用于多智能体LLMs的适应。在个体层面，LLM智能体从探索性数据集中学习一个局部效用函数，以更好地理解具身环境，该函数随后在测试时被查询以支持知情决策。在团队层面，LLM智能体根据新经验协作迭代地维护和更新一个共享的协作知识列表，并利用它来指导更有效的沟通。通过结合个体学习和团队进化，LIET实现了LLM智能体的全面而灵活的适应。我们在Communicative Watch-And-Help和ThreeD-World Multi-Agent Transport基准测试中的实验表明，使用LLaMA和GPT-4o实例化的LIET，其性能优于现有基线，并展现出强大的协作规划能力。", "summary": "大型语言模型（LLMs）在具身多智能体规划中面临适应性不足的挑战。本文提出了一种名为“个体学习，团队进化（LIET）”的框架来解决此问题。LIET借鉴了多智能体强化学习中的集中训练去中心化执行思想，使LLM智能体能够在个体层面通过学习局部效用函数来理解环境，并在团队层面通过维护和更新共享协作知识列表来增强沟通与合作。实验结果表明，LIET在多个具身多智能体基准测试中表现优于现有方法，证明了其在增强LLM智能体协作规划能力方面的有效性。", "keywords": "多智能体LLM, 具身环境, 适应性, 协作规划, LIET", "comments": "LIET框架的创新之处在于其将个体学习与团队进化相结合的范式，为LLM在复杂具身多智能体环境中的适应性提供了新的解决方案。这种分层学习与协作知识共享的机制，有效地弥补了现有LLM在多智能体场景中适应能力不足的缺陷，是LLM应用于具身智能领域的重要进展。其灵感来源于多智能体强化学习，也体现了跨领域思想的融合。"}}
{"id": "2506.06459", "title": "Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control", "authors": ["Ruitao Chen", "Mozhang Guo", "Jinge Li"], "summary": "Automated driving (AD) has substantially improved vehicle safety and driving\ncomfort, but their impact on passenger well-being, particularly infant sleep,\nis not sufficiently studied. Sudden acceleration, abrupt braking, and sharp\nmaneuvers can disrupt infant sleep, compromising both passenger comfort and\nparental convenience. To solve this problem, this paper explores the\nintegration of reinforcement learning (RL) within AD to personalize driving\nbehavior and optimally balance occupant comfort and travel efficiency. In\nparticular, we propose an intelligent cruise control framework that adapts to\nvarying driving conditions to enhance infant sleep quality by effectively\nsynergizing wearable sensing and vehicle data. Long short-term memory (LSTM)\nand transformer-based neural networks are integrated with RL to model the\nrelationship between driving behavior and infant sleep quality under diverse\ntraffic and road conditions. Based on the sleep quality indicators from the\nwearable sensors, driving action data from vehicle controllers, and map data\nfrom map applications, the model dynamically computes the optimal driving\naggressiveness level, which is subsequently translated into specific AD control\nstrategies, e.g., the magnitude and frequency of acceleration, lane change, and\novertaking. Simulation results demonstrate that the proposed solution\nsignificantly improves infant sleep quality compared to baseline methods, while\npreserving desirable travel efficiency.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06459v1", "AI": {"title_translation": "面向婴儿睡眠优化的驾驶：智能巡航控制中可穿戴和车辆传感的协同作用", "tldr": "本文提出了一种智能巡航控制框架，通过结合可穿戴和车辆传感数据以及强化学习，优化驾驶行为以提升婴儿睡眠质量，并在仿真中显示出显著效果。", "motivation": "自动驾驶（AD）对乘客福祉，特别是婴儿睡眠的影响研究不足。突然的加速、急刹车和急转弯会扰乱婴儿睡眠，影响乘客舒适度和父母便利性。", "method": "本文提出了一种智能巡航控制框架，该框架将强化学习（RL）与长短期记忆（LSTM）和基于Transformer的神经网络相结合。通过协同利用可穿戴传感器提供的睡眠质量指标、车辆控制器提供的驾驶行为数据以及地图数据，该模型动态计算最佳驾驶激进程度，并将其转化为具体的自动驾驶控制策略（如加减速的幅度、频率、变道和超车），以适应不同驾驶条件，从而提高婴儿睡眠质量。", "result": "仿真结果表明，所提出的解决方案与基线方法相比，显著提高了婴儿睡眠质量，同时保持了理想的出行效率。", "conclusion": "通过整合可穿戴和车辆传感数据，并利用强化学习优化自动驾驶行为，可以有效地提升婴儿在车内的睡眠质量，同时不牺牲出行效率。", "translation": "自动驾驶（AD）已大大提高了车辆安全性和驾驶舒适性，但其对乘客福祉，特别是婴儿睡眠的影响，尚未得到充分研究。突然的加速、急刹车和急转弯会扰乱婴儿睡眠，损害乘客舒适度及父母便利性。为解决此问题，本文探索了在自动驾驶中集成强化学习（RL），以个性化驾驶行为，并最佳地平衡乘员舒适度和出行效率。特别是，我们提出了一种智能巡航控制框架，该框架通过有效协同可穿戴传感和车辆数据，适应不同的驾驶条件以提高婴儿睡眠质量。长短期记忆（LSTM）和基于Transformer的神经网络与强化学习相结合，以建模驾驶行为与不同交通和道路条件下婴儿睡眠质量之间的关系。基于可穿戴传感器提供的睡眠质量指标、车辆控制器提供的驾驶动作数据以及地图应用程序提供的地图数据，模型动态计算最佳驾驶激进程度，随后将其转化为具体的自动驾驶控制策略，例如加减速的幅度、频率、变道和超车。仿真结果表明，与基线方法相比，所提出的解决方案显著提高了婴儿睡眠质量，同时保持了理想的出行效率。", "summary": "本文提出了一种创新的智能巡航控制框架，旨在解决自动驾驶对婴儿睡眠影响研究不足的问题。该框架结合了强化学习、LSTM和Transformer网络，通过协同分析可穿戴传感器提供的婴儿睡眠质量数据、车辆驾驶行为数据和地图数据，动态调整驾驶激进程度。其目标是优化自动驾驶行为，以提高婴儿睡眠质量，同时保持出行效率。仿真结果验证了该方法在改善婴儿睡眠方面优于基线方法。", "keywords": "婴儿睡眠优化, 智能巡航控制, 强化学习, 可穿戴传感, 车辆传感", "comments": "这项研究在自动驾驶领域引入了乘客福祉，特别是婴儿睡眠质量这一新颖且重要的考量维度，具有创新性。通过结合多模态数据（可穿戴、车辆、地图）和先进的AI技术（强化学习、LSTM、Transformer），为实现更人性化和以乘客为中心的智能驾驶提供了新的范式。其潜在应用价值在于显著提升家庭出行体验，减少父母的困扰。"}}
{"id": "2506.06508", "title": "Information-Theoretic Detection of Unusual Source Code Changes", "authors": ["Adriano Torres", "Sebastian Baltes", "Christoph Treude", "Markus Wagner"], "summary": "The code base of software projects evolves essentially through inserting and\nremoving information to and from the source code. We can measure this evolution\nvia the elements of information - tokens, words, nodes - of the respective\nrepresentation of the code. In this work, we approach the measurement of the\ninformation content of the source code of open-source projects from an\ninformation-theoretic standpoint. Our focus is on the entropy of two\nfundamental representations of code: tokens and abstract syntax tree nodes,\nfrom which we derive definitions of textual and structural entropy. We proceed\nwith an empirical assessment where we evaluate the evolution patterns of the\nentropy of 95 actively maintained open source projects. We calculate the\nstatistical relationships between our derived entropy metrics and classic\nmethods of measuring code complexity and learn that entropy may capture\ndifferent dimensions of complexity than classic metrics. Finally, we conduct\nentropy-based anomaly detection of unusual changes to demonstrate that our\napproach may effectively recognise unusual source code change events with over\n60% precision, and lay the groundwork for improvements to information-theoretic\nmeasurement of source code evolution, thus paving the way for a new approach to\nstatically gauging program complexity throughout its development.", "comment": "48 pages, 17 figures, 7 tables, accepted for publication in the\n  Empirical Software Engineering journal", "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.06508v1", "AI": {"title_translation": "基于信息论的异常源代码变更检测", "tldr": "本文提出了一种基于信息论的方法来检测异常源代码变更，通过测量令牌和抽象语法树节点的熵来评估代码的信息内容和演化模式，并发现该方法能有效识别异常变更。", "motivation": "软件项目的代码库通过插入和删除信息不断演化，现有方法可能无法完全捕捉代码复杂度的所有维度。本研究旨在从信息论角度测量源代码的信息内容，并检测异常变更，以期为静态衡量程序复杂度提供新方法。", "method": "研究从信息论角度出发，关注代码的两种基本表示（令牌和抽象语法树节点）的熵，并推导出文本熵和结构熵的定义。通过对95个活跃维护的开源项目进行实证评估，计算了熵指标与经典代码复杂度度量之间的统计关系。最后，进行了基于熵的异常检测。", "result": "研究发现熵可能捕捉到与经典度量不同的复杂度维度。基于熵的异常检测方法能够以超过60%的精度有效识别异常源代码变更事件。", "conclusion": "本文为信息论测量源代码演化奠定了基础，为静态衡量程序开发过程中的复杂度提供了一种新方法。", "translation": "软件项目的代码库主要通过向源代码中插入和删除信息来演化。我们可以通过代码相应表示的信息元素——令牌、单词、节点——来衡量这种演化。在这项工作中，我们从信息论的角度来衡量开源项目源代码的信息内容。我们的重点是代码的两种基本表示形式：令牌和抽象语法树节点的熵，并从中推导出文本熵和结构熵的定义。我们进行了一项实证评估，评估了95个活跃维护的开源项目的熵演化模式。我们计算了我们推导出的熵指标与衡量代码复杂度的经典方法之间的统计关系，并发现熵可能捕捉到与经典指标不同的复杂度维度。最后，我们进行了基于熵的异常检测，以证明我们的方法可以有效识别异常源代码变更事件，精度超过60%，并为信息论测量源代码演进奠定了基础，从而为在程序开发过程中静态衡量程序复杂度铺平了道路。", "summary": "本文提出了一种基于信息论的异常源代码变更检测方法。研究通过测量开源项目源代码中令牌和抽象语法树节点的熵来定义文本熵和结构熵，并评估了95个开源项目的熵演化模式。结果表明，熵能捕捉到与传统指标不同的代码复杂度维度，并且基于熵的异常检测方法能够以超过60%的精度有效识别异常源代码变更事件。这项工作为信息论视角下的源代码演化测量和静态程序复杂度评估提供了新途径。", "keywords": "信息论, 源代码变更, 熵, 异常检测, 代码复杂度", "comments": "本文创新性地将信息论引入源代码变更检测和复杂度度量，通过熵的概念为代码演化分析提供了新的视角。其提出的文本熵和结构熵概念，并结合实证评估，证明了信息论方法在识别异常变更方面的潜力，且可能捕捉到传统度量未涵盖的复杂度维度，对于软件质量保证和维护具有重要意义。"}}
{"id": "2506.06389", "title": "Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images", "authors": ["Rifat Sadik", "Tanvir Rahman", "Arpan Bhattacharjee", "Bikash Chandra Halder", "Ismail Hossain"], "summary": "Deep learning models have shown remarkable success in dermatological image\nanalysis, offering potential for automated skin disease diagnosis. Previously,\nconvolutional neural network(CNN) based architectures have achieved immense\npopularity and success in computer vision (CV) based task like skin image\nrecognition, generation and video analysis. But with the emergence of\ntransformer based models, CV tasks are now are nowadays carrying out using\nthese models. Vision Transformers (ViTs) is such a transformer-based models\nthat have shown success in computer vision. It uses self-attention mechanisms\nto achieve state-of-the-art performance across various tasks. However, their\nreliance on global attention mechanisms makes them susceptible to adversarial\nperturbations. This paper aims to investigate the susceptibility of ViTs for\nmedical images to adversarial watermarking-a method that adds so-called\nimperceptible perturbations in order to fool models. By generating adversarial\nwatermarks through Projected Gradient Descent (PGD), we examine the\ntransferability of such attacks to CNNs and analyze the performance defense\nmechanism -- adversarial training. Results indicate that while performance is\nnot compromised for clean images, ViTs certainly become much more vulnerable to\nadversarial attacks: an accuracy drop of as low as 27.6%. Nevertheless,\nadversarial training raises it up to 90.0%.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06389v1", "AI": {"title_translation": "探索基于Transformer模型中的对抗性水印：医疗图像的迁移性和对抗防御机制的鲁棒性", "tldr": "本文研究了Vision Transformers（ViTs）在医疗图像上对对抗性水印的脆弱性，发现ViTs易受攻击，但对抗训练能有效提高其鲁棒性。", "motivation": "深度学习模型，特别是Vision Transformers (ViTs)，在医学图像分析中表现出色，但其对全局注意力机制的依赖使其容易受到对抗性扰动。因此，本文旨在探究ViTs在医疗图像上对对抗性水印的脆弱性。", "method": "通过使用投影梯度下降（PGD）生成对抗性水印，研究了此类攻击对卷积神经网络（CNNs）的迁移性，并分析了防御机制——对抗训练的性能。", "result": "结果显示，对于干净图像，模型性能没有受到损害，但ViTs对对抗性攻击变得更加脆弱，准确率最低降至27.6%。然而，对抗训练将其提高到90.0%。", "conclusion": "尽管Vision Transformers在医疗图像分析中表现出色，但它们对对抗性水印攻击高度敏感。幸运的是，对抗训练可以显著提高ViTs的鲁棒性，使其能够抵御此类攻击。", "translation": "深度学习模型在皮肤病图像分析中取得了显著成功，为自动化皮肤疾病诊断提供了潜力。此前，基于卷积神经网络（CNN）的架构在计算机视觉（CV）任务，如皮肤图像识别、生成和视频分析中，获得了巨大的普及和成功。但随着基于Transformer模型的出现，当前的CV任务正在使用这些模型进行。Vision Transformers（ViTs）就是这样一种在计算机视觉中取得成功的基于Transformer的模型。它使用自注意力机制在各种任务中实现最先进的性能。然而，它们对全局注意力机制的依赖使其容易受到对抗性扰动。本文旨在调查ViTs在医疗图像上对抗性水印的脆弱性——一种添加所谓“难以察觉的扰动”以欺骗模型的方法。通过投影梯度下降（PGD）生成对抗性水印，我们检查了此类攻击对CNN的迁移性，并分析了防御机制——对抗训练的性能。结果表明，虽然对干净图像的性能没有受到影响，但ViTs确实对对抗性攻击变得更加脆弱：准确率最低降至27.6%。然而，对抗训练将其提高到90.0%。", "summary": "本文探讨了Vision Transformers (ViTs) 在医疗图像处理中对抗性水印攻击的脆弱性。研究通过投影梯度下降（PGD）生成对抗性水印，并评估了攻击对CNN的迁移性以及对抗训练作为防御机制的效果。结果表明，ViTs在对抗性攻击下准确率显著下降，但对抗训练能有效提升其鲁棒性，将其准确率恢复到较高水平。", "keywords": "对抗性水印, Vision Transformers, 医疗图像, 对抗训练, 鲁棒性", "comments": "这篇论文在医疗AI安全领域具有重要意义，因为它揭示了Vision Transformers在医疗图像分析中对抗性攻击的潜在漏洞。研究不仅证实了ViTs的脆弱性，还提出了对抗训练作为一种有效的防御策略，这对于确保医疗诊断系统的可靠性和安全性至关重要。"}}
{"id": "2506.06728", "title": "Neighborhood Overlap-Aware High-Order Graph Neural Network for Dynamic Graph Learning", "authors": ["Ling Wang"], "summary": "Dynamic graph learning (DGL) aims to learn informative and\ntemporally-evolving node embeddings to support downstream tasks such as link\nprediction. A fundamental challenge in DGL lies in effectively modeling both\nthe temporal dynamics and structural dependencies of evolving graph topologies.\nRecent advances in Dynamic Graph Neural Networks (DGNNs) have obtained\nremarkable success by leveraging message-passing mechanisms to capture pairwise\nnode interactions. However, these approaches often overlook more complex\nstructural patterns, particularly neighborhood overlap, which can play a\ncritical role in characterizing node interactions. To overcome this limitation,\nwe introduce the Neighborhood Overlap-Aware High-Order Graph Neural Network\n(NO-HGNN), which is built upon two key innovations: (a) computing a correlation\nscore based on the extent of neighborhood overlap to better capture complex\nnode interactions; and (b) embedding this correlation directly into the\nmessage-passing process of high-order graph neural networks in the DGL.\nExperiments on two real-world dynamic graphs show that NO-HGNN achieves notable\nimprovements in link prediction accuracy, outperforming several\nstate-of-the-art approaches.", "comment": null, "cate": "cs.SI", "url": "http://arxiv.org/abs/2506.06728v1", "AI": {"title_translation": "邻域重叠感知高阶图神经网络用于动态图学习", "tldr": "提出NO-HGNN，通过计算邻域重叠相关性并将其嵌入高阶GNN的消息传递过程，有效提升动态图学习中的链接预测性能。", "motivation": "动态图学习（DGL）在建模演化图拓扑的时间动态和结构依赖性方面面临挑战。现有DGNNs忽视了更复杂的结构模式，特别是邻域重叠，这在表征节点交互中至关重要。", "method": "引入邻域重叠感知高阶图神经网络（NO-HGNN），其创新点在于：(a) 基于邻域重叠程度计算相关性分数，以更好地捕获复杂节点交互；(b) 将此相关性直接嵌入到高阶图神经网络在DGL中的消息传递过程中。", "result": "在两个真实世界的动态图上的实验表明，NO-HGNN在链接预测精度上取得了显著提升，优于几种最先进的方法。", "conclusion": "NO-HGNN通过有效建模邻域重叠来捕捉复杂节点交互，显著提高了动态图链接预测的性能，证明了其在动态图学习中的有效性。", "translation": "动态图学习（DGL）旨在学习信息丰富且随时间演变的节点嵌入，以支持链接预测等下游任务。DGL的一个根本挑战在于有效建模演化图拓扑的时间动态和结构依赖性。动态图神经网络（DGNNs）的最新进展通过利用消息传递机制捕获成对节点交互，取得了显著成功。然而，这些方法往往忽略了更复杂的结构模式，特别是邻域重叠，这在表征节点交互中可以发挥关键作用。为了克服这一限制，我们引入了邻域重叠感知高阶图神经网络（NO-HGNN），它建立在两个关键创新之上：(a) 基于邻域重叠的程度计算相关性分数，以更好地捕获复杂节点交互；(b) 将此相关性直接嵌入到DGL中高阶图神经网络的消息传递过程中。在两个真实世界的动态图上的实验表明，NO-HGNN在链接预测精度上取得了显著提升，优于几种最先进的方法。", "summary": "本文针对动态图学习中现有方法忽略邻域重叠这一复杂结构模式的局限性，提出了一种名为邻域重叠感知高阶图神经网络（NO-HGNN）的新模型。NO-HGNN通过计算基于邻域重叠的相关性分数，并将其融入高阶图神经网络的消息传递机制中，旨在更有效地捕获复杂节点交互和图拓扑的动态性。实验结果表明，NO-HGNN在链接预测任务上显著优于现有SOTA方法。", "keywords": "动态图学习, 图神经网络, 邻域重叠, 高阶图, 链接预测", "comments": "这篇论文的创新点在于将邻域重叠这一高阶结构信息引入动态图神经网络的消息传递过程，解决了现有DGNNs在捕获复杂节点交互方面的不足。通过量化邻域重叠并将其作为相关性分数，NO-HGNN能够更精细地建模动态图中的结构依赖性，这对于链接预测等任务至关重要。该方法为动态图学习提供了一个新的视角和有效的解决方案。"}}
{"id": "2506.06284", "title": "Unreal Patterns", "authors": ["John Beverley", "Jim Logan"], "summary": "This paper introduces a framework for representing information about entities\nthat do not exist or may never exist, such as those involving fictional\nentities, blueprints, simulations, and future scenarios. Traditional approaches\nthat introduce \"dummy instances\" or rely on modal logic are criticized, and a\nproposal is defended in which such cases are modeled using the intersections of\nactual types rather than specific non existent tokens. The paper positions\nitself within the Basic Formal Ontology and its realist commitments,\nemphasizing the importance of practical, implementable solutions over purely\nmetaphysical or philosophical proposals, arguing that existing approaches to\nnon existent entities either overcommit to metaphysical assumptions or\nintroduce computational inefficiencies that hinder applications. By developing\na structured ontology driven approach to unreal patterns, the paper aims to\nprovide a useful and computationally viable means of handling references to\nhypothetical or non existent entities.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06284v1", "AI": {"title_translation": "虚构模式", "tldr": "本文提出了一种在本体论框架内表示不存在或可能永远不存在的实体信息的方法，通过使用实际类型的交集而不是虚拟实例或模态逻辑来建模，旨在提供一种实用且计算上可行的方式来处理对假设或不存在实体的引用。", "motivation": "传统处理不存在实体的方法（如引入“虚拟实例”或依赖模态逻辑）被批评为过度承诺形而上学假设或引入计算效率低下，阻碍了实际应用。因此，需要一种更实用、可实现且计算上可行的解决方案。", "method": "该论文提出并辩护了一种方法，即使用实际类型的交集而不是特定的不存在的标记来建模不存在的实体。该方法定位在基本形式本体论（Basic Formal Ontology）及其现实主义承诺之内，强调实用、可实现性。", "result": "通过开发一种结构化的、本体论驱动的虚构模式方法，该论文旨在提供一种有用且计算上可行的方式来处理对假设或不存在实体的引用。", "conclusion": "本文得出的结论是，所提出的框架提供了一种实用、可实现且计算上可行的方法来处理对虚构、蓝图、模拟和未来场景等不存在或可能永远不存在的实体的引用，克服了传统方法的局限性。", "translation": "本文介绍了一个用于表示不存在或可能永远不存在的实体信息的框架，例如涉及虚构实体、蓝图、模拟和未来情景的实体。传统引入“虚拟实例”或依赖模态逻辑的方法受到批评，本文提出并捍卫了一种建议，即此类情况应使用实际类型的交集而不是特定的不存在的标记来建模。该论文将自身定位在基本形式本体论（Basic Formal Ontology）及其现实主义承诺之内，强调实用、可实现解决方案的重要性，而非纯粹的形而上学或哲学提案，认为现有处理不存在实体的方法要么过度承诺形而上学假设，要么引入阻碍应用的计算效率低下。通过开发一种结构化的、本体论驱动的虚构模式方法，本文旨在提供一种有用且计算上可行的方式来处理对假设或不存在实体的引用。", "summary": "本文提出了一种处理不存在或可能永远不存在实体（如虚构实体、蓝图、模拟和未来情景）信息的新框架。该框架批评了传统“虚拟实例”和模态逻辑方法在形而上学和计算效率上的不足，转而倡导在基本形式本体论（Basic Formal Ontology）内，通过建模实际类型的交集来表示这些“虚构模式”。其核心目标是提供一种实用、可实现且计算上高效的方式来处理对假设或不存在实体的引用。", "keywords": "虚构实体, 本体论, 模式, 假设实体, 信息表示", "comments": "该论文的创新之处在于其对处理不存在实体的实用主义方法，避免了传统方法中常见的形而上学假设和计算效率低下。它将自身定位在已建立的本体论框架内，强调可实现性，这对于将本体论应用于实际计算场景具有重要意义。通过专注于实际类型的交集而非虚拟实例，它为处理复杂、假设性数据提供了一个清晰且可能更高效的路径。"}}
{"id": "2506.06754", "title": "MIMO Pinching-Antenna-Aided SWIPT", "authors": ["Haoyun Li", "Zhonghao Lyu", "Yulan Gao", "Ming Xiao", "H. Vincent Poor"], "summary": "Pinching-antenna systems (PASS) have recently emerged as a promising\ntechnology for improving wireless communications by establishing or\nstrengthening reliable line-of-sight (LoS) links by adjusting the positions of\npinching antennas (PAs). Motivated by these benefits, we propose a novel\nPASS-aided multi-input multi-output (MIMO) system for simultaneous wireless\ninformation and power transfer (SWIPT), where the PASS are equipped with\nmultiple waveguides to provide information transmission and wireless power\ntransfer (WPT) for several multiple antenna information decoding receivers\n(IDRs), and energy harvesting receivers (EHRs), respectively. Based on the\nsystem, we consider maximizing the sum-rate of all IDRs while guaranteeing the\nminimum harvested energy of each EHR by jointly optimizing the pinching\nbeamforming and the PA positions. To solve this highly non-convex problem, we\niteratively optimize the pinching beamforming based on a weighted minimum\nmean-squared-error (WMMSE) method and update the PA positions with a\nGauss-Seidel-based approach in an alternating optimization (AO) framework.\nNumerical results verify the significant superiority of the PASS compared with\nconventional designs.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.06754v1", "AI": {"title_translation": "MIMO 夹持天线辅助的SWIPT", "tldr": "提出了一种基于夹持天线系统(PASS)的MIMO-SWIPT系统，通过联合优化波束成形和天线位置，在保证能量收集的同时最大化信息传输速率。", "motivation": "夹持天线系统(PASS)有望通过调整夹持天线位置来建立或增强可靠的视距(LoS)链路，从而改善无线通信。受此启发，本文提出了一个用于同时无线信息和功率传输(SWIPT)的PASS辅助MIMO系统。", "method": "提出了一种新型的PASS辅助MIMO系统用于SWIPT，其中PASS配备多个波导，为多个信息解码接收器(IDR)和能量收集接收器(EHR)提供信息传输和无线功率传输(WPT)。目标是最大化所有IDR的总速率，同时保证每个EHR的最小收集能量，通过联合优化夹持波束成形和PA位置。该非凸问题通过交替优化(AO)框架解决：基于加权最小均方误差(WMMSE)方法迭代优化夹持波束成形，并使用基于高斯-赛德尔的方法更新PA位置。", "result": "数值结果验证了PASS相比传统设计的显著优越性。", "conclusion": "Not mentioned in abstract", "translation": "夹持天线系统（PASS）最近作为一种有前景的技术出现，通过调整夹持天线（PA）的位置来建立或加强可靠的视距（LoS）链路，从而改善无线通信。受这些益处的启发，我们提出了一种新颖的PASS辅助多输入多输出（MIMO）系统，用于同时无线信息和功率传输（SWIPT），其中PASS配备多个波导，分别为多个多天线信息解码接收器（IDR）和能量收集接收器（EHR）提供信息传输和无线功率传输（WPT）。基于该系统，我们考虑通过联合优化夹持波束成形和PA位置，在保证每个EHR最小收集能量的同时，最大化所有IDR的总速率。为了解决这个高度非凸问题，我们在一个交替优化（AO）框架中，基于加权最小均方误差（WMMSE）方法迭代优化夹持波束成形，并使用基于高斯-赛德尔的方法更新PA位置。数值结果验证了PASS与传统设计相比的显著优越性。", "summary": "本文提出了一种创新的夹持天线系统(PASS)辅助的多输入多输出(MIMO)系统，用于同时无线信息和功率传输(SWIPT)。该系统旨在通过联合优化夹持波束成形和夹持天线位置，在确保能量收集接收器(EHRs)最小能量收集的同时，最大化信息解码接收器(IDRs)的总速率。为了解决这一复杂的非凸优化问题，研究者采用了一种基于加权最小均方误差(WMMSE)和高斯-赛德尔方法的交替优化(AO)框架。数值结果表明，所提出的PASS系统相比传统设计具有显著优势。", "keywords": "夹持天线系统, SWIPT, MIMO, 波束成形, 交替优化", "comments": "该研究创新性地将新兴的夹持天线系统(PASS)引入到MIMO-SWIPT领域，利用其可调控的LoS链路增强能力来优化系统性能。其提出的联合优化波束成形和天线位置的策略，以及采用的WMMSE和高斯-赛德尔相结合的AO框架，为解决此类复杂非凸问题提供了有效途径。数值结果验证了PASS的优越性，表明该技术在未来无线通信中具有重要应用潜力。"}}
{"id": "2506.06769", "title": "Containerized In-Storage Processing and Computing-Enabled SSD Disaggregation", "authors": ["Miryeong Kwon", "Donghyun Gouk", "Eunjee Na", "Jiseon Kim", "Junhee Kim", "Hyein Woo", "Eojin Ryu", "Hyunkyu Choi", "Jinwoo Baek", "Hanyeoreum Bae", "Mahmut Kandemir", "Myoungsoo Jung"], "summary": "ISP minimizes data transfer for analytics but faces challenges in adaptation\nand disaggregation. We propose DockerSSD, an ISP model leveraging OS-level\nvirtualization and lightweight firmware to enable containerized data processing\ndirectly on SSDs. Key features include Ethernet over NVMe for network-based ISP\nmanagement and Virtual Firmware for secure, efficient container execution.\nDockerSSD supports disaggregated storage pools, reducing host overhead and\nenhancing large-scale services like LLM inference. It achieves up to 2.0x\nbetter performance for I/O-intensive workloads, and 7.9x improvement in\ndistributed LLM inference.", "comment": null, "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.06769v1", "AI": {"title_translation": "容器化存储内处理与计算赋能的SSD解耦", "tldr": "DockerSSD通过在SSD上直接实现容器化数据处理来解决存储内处理的挑战，显著提升I/O密集型工作负载和分布式LLM推理的性能。", "motivation": "存储内处理（ISP）虽然能最小化数据传输，但在适应性和解耦方面面临挑战。", "method": "本文提出了DockerSSD，一个利用操作系统级虚拟化和轻量级固件在SSD上直接实现容器化数据处理的ISP模型。其关键特性包括用于网络化ISP管理的以太网 over NVMe，以及用于安全高效容器执行的虚拟固件。DockerSSD支持解耦存储池。", "result": "DockerSSD在I/O密集型工作负载中实现了高达2.0倍的性能提升，在分布式LLM推理中实现了7.9倍的性能改进。", "conclusion": "DockerSSD通过在SSD上实现容器化存储内处理，成功解决了现有ISP的挑战，并显著提升了I/O密集型和分布式LLM推理等大型服务的性能，同时减少了主机开销。", "translation": "ISP最大限度地减少了分析的数据传输，但在适应性和解耦方面面临挑战。我们提出了DockerSSD，这是一种ISP模型，利用操作系统级虚拟化和轻量级固件，直接在SSD上实现容器化数据处理。主要特点包括用于基于网络的ISP管理的以太网 over NVMe，以及用于安全高效容器执行的虚拟固件。DockerSSD支持解耦存储池，减少了主机开销，并增强了LLM推理等大规模服务。它在I/O密集型工作负载中实现了高达2.0倍的性能提升，在分布式LLM推理中实现了7.9倍的改进。", "summary": "本文提出DockerSSD，一种创新的存储内处理（ISP）模型，通过利用操作系统级虚拟化和轻量级固件，直接在SSD上实现容器化数据处理。该系统通过以太网 over NVMe实现网络管理，并使用虚拟固件确保容器执行的安全高效。DockerSSD支持解耦存储池，有效降低主机开销，并显著提升了I/O密集型工作负载（最高2.0倍）和分布式大型语言模型（LLM）推理（最高7.9倍）的性能。", "keywords": "存储内处理, SSD, 容器化, 解耦, DockerSSD", "comments": "该论文通过将容器化技术引入SSD的存储内处理，提供了一种新颖且高效的解决方案，有效解决了数据传输和解耦的挑战。其对大型语言模型推理性能的显著提升，预示着其在未来AI和大数据应用中的巨大潜力。"}}
{"id": "2506.06291", "title": "Improvement of Optimization using Learning Based Models in Mixed Integer Linear Programming Tasks", "authors": ["Xiaoke Wang", "Batuhan Altundas", "Zhaoxin Li", "Aaron Zhao", "Matthew Gombolay"], "summary": "Mixed Integer Linear Programs (MILPs) are essential tools for solving\nplanning and scheduling problems across critical industries such as\nconstruction, manufacturing, and logistics. However, their widespread adoption\nis limited by long computational times, especially in large-scale, real-time\nscenarios. To address this, we present a learning-based framework that\nleverages Behavior Cloning (BC) and Reinforcement Learning (RL) to train Graph\nNeural Networks (GNNs), producing high-quality initial solutions for\nwarm-starting MILP solvers in Multi-Agent Task Allocation and Scheduling\nProblems. Experimental results demonstrate that our method reduces optimization\ntime and variance compared to traditional techniques while maintaining solution\nquality and feasibility.", "comment": "4 pages, 4 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06291v1", "AI": {"title_translation": "混合整数线性规划任务中基于学习模型的优化改进", "tldr": "该研究提出一个基于学习的框架，利用BC和RL训练GNN，为MILP求解器提供高质量初始解，从而减少优化时间和方差。", "motivation": "混合整数线性规划（MILPs）在关键行业中解决规划和调度问题至关重要，但其广泛应用受限于计算时间过长，尤其在大规模、实时场景中。", "method": "本文提出了一个基于学习的框架，该框架利用行为克隆（BC）和强化学习（RL）来训练图神经网络（GNNs），旨在为多智能体任务分配和调度问题中的混合整数线性规划（MILP）求解器提供高质量的初始解以进行热启动。", "result": "实验结果表明，与传统技术相比，该方法在保持解的质量和可行性的同时，减少了优化时间和方差。", "conclusion": "该方法通过提供高质量的初始解，显著提高了MILP求解器的效率，使其在大规模实时应用中更具可行性。", "translation": "混合整数线性规划（MILPs）是解决建筑、制造和物流等关键行业规划和调度问题的重要工具。然而，它们的广泛应用受到计算时间过长的限制，尤其是在大规模、实时场景中。为了解决这个问题，我们提出了一个基于学习的框架，该框架利用行为克隆（BC）和强化学习（RL）来训练图神经网络（GNNs），为多智能体任务分配和调度问题中的MILP求解器生成高质量的初始解以进行热启动。实验结果表明，与传统技术相比，我们的方法在保持解的质量和可行性的同时，减少了优化时间和方差。", "summary": "本文提出一种基于学习的框架，结合行为克隆和强化学习训练图神经网络，旨在为混合整数线性规划（MILPs）求解器提供高质量的初始解，以解决其在复杂任务分配和调度问题中计算时间过长的问题。实验证明，该方法能有效缩短优化时间并降低方差，同时保持解的质量和可行性。", "keywords": "混合整数线性规划, 学习模型, 图神经网络, 行为克隆, 强化学习", "comments": "这项研究通过结合机器学习（特别是GNN、BC和RL）与传统优化方法（MILP），为解决大规模MILP问题提供了创新途径。其重要性在于，通过提供高质量的初始解来“热启动”求解器，显著提高了计算效率，这对于实时和大规模工业应用具有重要意义。"}}
{"id": "2506.06299", "title": "How Malicious AI Swarms Can Threaten Democracy", "authors": ["Daniel Thilo Schroeder", "Meeyoung Cha", "Andrea Baronchelli", "Nick Bostrom", "Nicholas A. Christakis", "David Garcia", "Amit Goldenberg", "Yara Kyrychenko", "Kevin Leyton-Brown", "Nina Lutz", "Gary Marcus", "Filippo Menczer", "Gordon Pennycook", "David G. Rand", "Frank Schweitzer", "Christopher Summerfield", "Audrey Tang", "Jay Van Bavel", "Sander van der Linden", "Dawn Song", "Jonas R. Kunst"], "summary": "Advances in AI portend a new era of sophisticated disinformation operations.\nWhile individual AI systems already create convincing -- and at times\nmisleading -- information, an imminent development is the emergence of\nmalicious AI swarms. These systems can coordinate covertly, infiltrate\ncommunities, evade traditional detectors, and run continuous A/B tests, with\nround-the-clock persistence. The result can include fabricated grassroots\nconsensus, fragmented shared reality, mass harassment, voter micro-suppression\nor mobilization, contamination of AI training data, and erosion of\ninstitutional trust. With democratic processes worldwide increasingly\nvulnerable, we urge a three-pronged response: (1) platform-side defenses --\nalways-on swarm-detection dashboards, pre-election high-fidelity\nswarm-simulation stress-tests, transparency audits, and optional client-side\n\"AI shields\" for users; (2) model-side safeguards -- standardized\npersuasion-risk tests, provenance-authenticating passkeys, and watermarking;\nand (3) system-level oversight -- a UN-backed AI Influence Observatory.", "comment": "8 pages, 1 figure", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06299v1", "AI": {"title_translation": "恶意AI蜂群如何威胁民主", "tldr": "恶意AI蜂群将对民主构成严重威胁，需要平台、模型和系统层面的多管齐下应对。", "motivation": "随着AI技术进步，复杂的虚假信息操作进入新时代，特别是恶意AI蜂群的出现，它们能秘密协调、渗透社区、规避检测，并持续运行，对全球日益脆弱的民主进程构成威胁。", "method": "提出三管齐下的应对措施：1) 平台侧防御（常驻蜂群检测仪表板、选前高保真蜂群模拟压力测试、透明度审计、客户端“AI盾”）；2) 模型侧保护（标准化说服风险测试、来源认证通行密钥、水印）；3) 系统级监督（联合国支持的AI影响力观察站）。", "result": "恶意AI蜂群可能导致捏造的基层共识、共享现实的碎片化、大规模骚扰、选民微观压制或动员、AI训练数据污染以及机构信任的侵蚀。", "conclusion": "鉴于民主进程日益脆弱，迫切需要平台、模型和系统层面的综合应对措施来抵御恶意AI蜂群的威胁。", "translation": "人工智能的进步预示着一个复杂虚假信息操作的新时代。虽然单个AI系统已经能创建令人信服——有时甚至是误导性的——信息，但一个迫在眉睫的发展是恶意AI蜂群的出现。这些系统可以秘密协调、渗透社区、规避传统检测器，并进行持续的A/B测试，不间断地运行。其结果可能包括捏造的基层共识、共享现实的碎片化、大规模骚扰、选民微观压制或动员、AI训练数据污染以及机构信任的侵蚀。鉴于全球民主进程日益脆弱，我们敦促采取三管齐下的应对措施：(1) 平台侧防御——常驻蜂群检测仪表板、选前高保真蜂群模拟压力测试、透明度审计以及用户的可选客户端“AI盾”；(2) 模型侧保护——标准化说服风险测试、来源认证通行密钥和水印；以及 (3) 系统级监督——一个由联合国支持的AI影响力观察站。", "summary": "本文探讨了恶意AI蜂群对民主构成的迫在眉睫的威胁。这些蜂群能够秘密协调、传播虚假信息、规避检测，并导致虚假共识、社会分裂和信任侵蚀。为应对此威胁，文章提出了一项三管齐下的策略，包括加强平台防御、实施模型级保护以及建立系统级监督（如联合国支持的AI影响力观察站）。", "keywords": "恶意AI蜂群, 虚假信息, 民主, AI安全, 平台防御", "comments": "这篇论文创新性地提出了“恶意AI蜂群”的概念，强调了AI在虚假信息操作中从单点攻击向协同、持续威胁演变的趋势。其重要性在于及时预警了这一潜在威胁，并提出了一套全面的、多层次的防御框架，涵盖了技术、平台和治理层面，对于维护民主进程具有重要的指导意义。"}}
{"id": "2506.06450", "title": "Performance Impact of Containerized METADOCK 2 on Heterogeneous Platforms", "authors": ["Antonio Jesús Banegas-Luna", "Baldomero Imbernón Tudela", "Carlos Martínez-Cortés", "José María Cecilia", "Horacio Pérez-Sánchez"], "summary": "Virtual screening (VS) is a computationally intensive process crucial for\ndrug discovery, often requiring significant resources to analyze large chemical\nlibraries and predict ligand-protein interactions. This study evaluates the\nperformance impact of containerization on METADOCK 2, a high-throughput docking\nsoftware when deployed on heterogeneous high-performance computing (HPC)\nplatforms. By testing three containerization technologies - Docker,\nSingularity, and Apptainer - across varying CPU and GPU configurations, the\nexperiments reveal that containerization introduces negligible performance\noverhead, with deviations below 1%. Moreover, METADOCK 2 demonstrated the\ncapability to efficiently process large molecular complexes, surpassing the\nlimitations of commercial tools such as AutoDock Vina. The results underscore\nthe advantages of container-based deployment for ensuring portability,\nreproducibility, and scalability in scientific computing. This study concludes\nthat containerized METADOCK 2 is a robust and efficient solution for VS tasks\non heterogeneous HPC platforms.", "comment": "20 pages, 5 figures, 2 tables", "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.06450v1", "AI": {"title_translation": "容器化METADOCK 2在异构平台上的性能影响", "tldr": "本研究评估了容器化METADOCK 2在异构HPC平台上的性能，发现容器化引入的性能开销可忽略不计，且能高效处理大型分子复合物，是虚拟筛选的强大解决方案。", "motivation": "虚拟筛选（VS）是药物发现中的计算密集型过程，需要大量资源。本研究旨在评估容器化对METADOCK 2在高通量对接软件在异构高性能计算（HPC）平台上部署时的性能影响。", "method": "本研究通过在不同的CPU和GPU配置上测试Docker、Singularity和Apptainer三种容器化技术，评估了METADOCK 2的性能影响。", "result": "实验结果显示，容器化引入的性能开销可忽略不计，偏差低于1%。METADOCK 2能够高效处理大型分子复合物，超越了AutoDock Vina等商业工具的限制。容器化部署在科学计算中能确保可移植性、可重复性和可扩展性。", "conclusion": "容器化METADOCK 2是异构HPC平台上虚拟筛选任务的强大且高效的解决方案。", "translation": "虚拟筛选（VS）是一个计算密集型过程，对药物发现至关重要，通常需要大量资源来分析大型化学文库并预测配体-蛋白质相互作用。本研究评估了容器化对METADOCK 2（一种高通量对接软件）在异构高性能计算（HPC）平台上部署时的性能影响。通过在不同的CPU和GPU配置上测试Docker、Singularity和Apptainer三种容器化技术，实验表明容器化引入的性能开销可忽略不计，偏差低于1%。此外，METADOCK 2展示了高效处理大型分子复合物的能力，超越了AutoDock Vina等商业工具的限制。结果强调了基于容器的部署在科学计算中确保可移植性、可重复性和可扩展性的优势。本研究得出结论，容器化METADOCK 2是异构HPC平台上虚拟筛选任务的强大且高效的解决方案。", "summary": "本研究评估了在高通量药物发现中，容器化METADOCK 2在异构高性能计算平台上的性能表现。实验结果显示，使用Docker、Singularity和Apptainer三种容器化技术几乎不引入性能开销（偏差低于1%），且METADOCK 2能够高效处理大型分子复合物，优于商业工具。这表明容器化部署为科学计算带来了可移植性、可重复性和可扩展性，证实容器化METADOCK 2是异构HPC平台上虚拟筛选任务的强大高效解决方案。", "keywords": "容器化, METADOCK 2, 虚拟筛选, 高性能计算, 药物发现", "comments": "这项研究的重要性在于它验证了容器化技术在高通量计算密集型科学应用中的可行性和高效性。通过展示极低的性能开销，并突出其在处理大型分子复合物方面的优势，该研究为药物发现等领域推广容器化工作流提供了有力证据，极大地提升了计算实验的可移植性和可重复性。"}}
{"id": "2506.06688", "title": "A Comparative Analyses Of Network Formation In Low-power Lossy Networks: ContikiMAC vs Orchestra-enabled TSCH", "authors": ["Heerok Banerjee"], "summary": "Medium Access Control (MAC) layer protocols are the underlying paradigms\nwhich dictate the transmission & reception of data in any network. Particularly\nfor Low-powered Lossy Networks (LLNs), the design and selection of appropiate\nMAC-layer protocols is crucial inorder to satisfy several networking objectives\nsuch as joining time, network lifetime, energy consumption, end-to-end-delay,\netc. In this report, we have presented a comparative analysis between\nContiki-MAC and Orchestra-enabled TSCH protocol which provides insights towards\nthe network joining & convergence time as well as an estimate of the energy\nconsumption required of build such LLNs. Our results indicates that Contiki-MAC\noutperforms Orchestra-enabled TSCH by a factor of 13 times in network\nformation.", "comment": null, "cate": "cs.NI", "url": "http://arxiv.org/abs/2506.06688v1", "AI": {"title_translation": "低功耗有损网络中网络形成的比较分析：ContikiMAC 对比 Orchestra-enabled TSCH", "tldr": "本文比较了ContikiMAC和Orchestra-enabled TSCH在低功耗有损网络(LLN)中的网络形成性能，结果显示ContikiMAC在网络形成方面性能高出13倍。", "motivation": "在低功耗有损网络(LLN)中，介质访问控制(MAC)层协议的设计和选择对于满足网络加入时间、网络寿命、能耗和端到端延迟等目标至关重要。", "method": "本文对Contiki-MAC和Orchestra-enabled TSCH协议进行了比较分析，以评估它们的网络加入与收敛时间以及能耗。", "result": "研究结果表明，Contiki-MAC在网络形成方面比Orchestra-enabled TSCH的性能高出13倍。", "conclusion": "Contiki-MAC在低功耗有损网络(LLN)的网络形成速度上显著优于Orchestra-enabled TSCH。", "translation": "介质访问控制 (MAC) 层协议是决定任何网络中数据传输和接收的基础范式。特别是对于低功耗有损网络 (LLN)，适当的 MAC 层协议的设计和选择至关重要，以满足多个网络目标，例如加入时间、网络寿命、能耗、端到端延迟等。在本报告中，我们对 Contiki-MAC 和启用 Orchestra 的 TSCH 协议进行了比较分析，该分析提供了关于网络加入和收敛时间以及构建此类 LLN 所需能耗的见解。我们的结果表明，Contiki-MAC 在网络形成方面比启用 Orchestra 的 TSCH 性能高出 13 倍。", "summary": "本文对低功耗有损网络(LLN)中的Contiki-MAC和Orchestra-enabled TSCH协议的网络形成性能进行了比较分析。研究侧重于网络加入和收敛时间以及能耗。结果表明，Contiki-MAC在网络形成速度上比Orchestra-enabled TSCH快13倍，表现出显著优势。", "keywords": "低功耗有损网络, MAC协议, ContikiMAC, TSCH, 网络形成", "comments": "该论文提供了关于LLN中MAC协议的明确量化比较，特别关注网络形成速度和能耗，这对于实际系统设计具有重要参考价值。"}}
{"id": "2506.06622", "title": "\\textit{QuantMCP}: Grounding Large Language Models in Verifiable Financial Reality", "authors": ["Yifan Zeng"], "summary": "Large Language Models (LLMs) hold immense promise for revolutionizing\nfinancial analysis and decision-making, yet their direct application is often\nhampered by issues of data hallucination and lack of access to real-time,\nverifiable financial information. This paper introduces QuantMCP, a novel\nframework designed to rigorously ground LLMs in financial reality. By\nleveraging the Model Context Protocol (MCP) for standardized and secure tool\ninvocation, QuantMCP enables LLMs to accurately interface with a diverse array\nof Python-accessible financial data APIs (e.g., Wind, yfinance). Users can\ninteract via natural language to precisely retrieve up-to-date financial data,\nthereby overcoming LLM's inherent limitations in factual data recall. More\ncritically, once furnished with this verified, structured data, the LLM's\nanalytical capabilities are unlocked, empowering it to perform sophisticated\ndata interpretation, generate insights, and ultimately support more informed\nfinancial decision-making processes. QuantMCP provides a robust, extensible,\nand secure bridge between conversational AI and the complex world of financial\ndata, aiming to enhance both the reliability and the analytical depth of LLM\napplications in finance.", "comment": null, "cate": "cs.CE", "url": "http://arxiv.org/abs/2506.06622v1", "AI": {"title_translation": "QuantMCP：将大型语言模型植根于可验证的金融现实", "tldr": "QuantMCP是一个新颖的框架，通过利用模型上下文协议（MCP），使大型语言模型（LLMs）能够与金融数据API准确交互，从而克服幻觉问题并支持更明智的金融决策。", "motivation": "大型语言模型（LLMs）在金融分析和决策方面潜力巨大，但其直接应用常受限于数据幻觉和缺乏实时、可验证的金融信息。", "method": "本文介绍了QuantMCP，一个旨在将LLMs严格植根于金融现实的新颖框架。它通过利用模型上下文协议（MCP）进行标准化和安全的工具调用，使LLMs能够准确地与各种Python可访问的金融数据API（如Wind、yfinance）进行交互。", "result": "用户可以通过自然语言精确检索最新的金融数据，从而克服LLM在事实数据回忆方面的固有局限性。一旦获得这些经过验证的结构化数据，LLM的分析能力将被解锁，使其能够执行复杂的数据解释、生成见解，并最终支持更明智的金融决策过程。", "conclusion": "QuantMCP在会话式AI和复杂的金融数据世界之间提供了一个健壮、可扩展且安全的桥梁，旨在增强金融领域LLM应用的可靠性和分析深度。", "translation": "大型语言模型（LLMs）在革新金融分析和决策方面具有巨大潜力，但其直接应用常常受到数据幻觉以及缺乏实时、可验证金融信息等问题的阻碍。本文介绍了QuantMCP，一个旨在将LLMs严格植根于金融现实的新颖框架。通过利用模型上下文协议（MCP）进行标准化和安全的工具调用，QuantMCP使LLMs能够准确地与各种Python可访问的金融数据API（例如Wind、yfinance）进行接口。用户可以通过自然语言进行交互，精确检索最新的金融数据，从而克服LLM在事实数据回忆方面的固有局限性。更关键的是，一旦获得了这些经过验证的结构化数据，LLM的分析能力将被解锁，使其能够执行复杂的数据解释、生成见解，并最终支持更明智的金融决策过程。QuantMCP在会话式AI和复杂的金融数据世界之间提供了一个健壮、可扩展且安全的桥梁，旨在增强金融领域LLM应用的可靠性和分析深度。", "summary": "QuantMCP是一个旨在解决大型语言模型（LLMs）在金融应用中数据幻觉和缺乏实时数据问题的框架。它通过利用模型上下文协议（MCP）与金融数据API（如Wind、yfinance）接口，使用户能通过自然语言检索准确的金融数据。这不仅克服了LLM在事实回忆上的限制，还解锁了其分析能力，支持更复杂的数据解释和决策，从而提升LLM在金融领域的可靠性和分析深度。", "keywords": "大型语言模型, 金融分析, QuantMCP, 模型上下文协议, 金融数据API", "comments": "QuantMCP的创新之处在于它为大型语言模型提供了一个可靠的机制，使其能够访问和利用实时的、可验证的金融数据，从而有效解决LLM在金融领域应用中常见的幻觉问题。通过结合MCP和金融API，它为LLM在金融分析和决策中的实际应用奠定了坚实的基础，显著提升了其可靠性和洞察力。"}}
{"id": "2506.06547", "title": "The complexity of the SupportMinors Modeling for the MinRank Problem", "authors": ["Daniel Cabarcas", "Giulia Gaggero", "Elisa Gorla"], "summary": "In this note, we provide proven estimates for the complexity of the\nSupportMinors Modeling, mostly confirming the heuristic complexity estimates\ncontained in the original article.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06547v1", "AI": {"title_translation": "MinRank问题中SupportMinors建模的复杂性", "tldr": "本文为SupportMinors建模的复杂性提供了经过验证的估计，证实了原始文章中的启发式估计。", "motivation": "本文旨在为SupportMinors建模的复杂性提供经过验证的估计，以证实原始文章中包含的启发式复杂性估计。", "method": "通过提供SupportMinors建模的复杂性证明估计。", "result": "研究结果主要证实了原始文章中包含的启发式复杂性估计。", "conclusion": "本文为SupportMinors建模的复杂性提供了经过验证的估计，并且这些估计与原始文章中的启发式估计基本一致。", "translation": "在这篇笔记中，我们为SupportMinors建模的复杂性提供了经过验证的估计，这在很大程度上证实了原始文章中包含的启发式复杂性估计。", "summary": "本文提供了关于MinRank问题中SupportMinors建模复杂度的经过验证的估计。研究结果表明，这些新估计与原始论文中提出的启发式复杂性估计基本一致。", "keywords": "复杂性, SupportMinors建模, MinRank问题, 复杂度估计, 验证", "comments": "这篇论文的重点是验证和量化MinRank问题中SupportMinors建模的计算复杂性，这对于密码学和计算代数领域可能很重要。其创新之处在于提供了“经过验证的估计”，而非仅仅是启发式估计，从而增强了该建模方法的可靠性。"}}
{"id": "2506.07332", "title": "Digital Twin-based Smart Manufacturing: Dynamic Line Reconfiguration for Disturbance Handling", "authors": ["Bo Fu", "Mingjie Bi", "Shota Umeda", "Takahiro Nakano", "Youichi Nonaka", "Quan Zhou", "Takaharu Matsui", "Dawn M. Tilbury", "Kira Barton"], "summary": "The increasing complexity of modern manufacturing, coupled with demand\nfluctuation, supply chain uncertainties, and product customization, underscores\nthe need for manufacturing systems that can flexibly update their\nconfigurations and swiftly adapt to disturbances. However, current research\nfalls short in providing a holistic reconfigurable manufacturing framework that\nseamlessly monitors system disturbances, optimizes alternative line\nconfigurations based on machine capabilities, and automates simulation\nevaluation for swift adaptations. This paper presents a dynamic manufacturing\nline reconfiguration framework to handle disturbances that result in operation\ntime changes. The framework incorporates a system process digital twin for\nmonitoring disturbances and triggering reconfigurations, a capability-based\nontology model capturing available agent and resource options, a configuration\noptimizer generating optimal line configurations, and a simulation generation\nprogram initializing simulation setups and evaluating line configurations at\napproximately 400x real-time speed. A case study of a battery production line\nhas been conducted to evaluate the proposed framework. In two implemented\ndisturbance scenarios, the framework successfully recovers system throughput\nwith limited resources, preventing the 26% and 63% throughput drops that would\nhave occurred without a reconfiguration plan. The reconfiguration optimizer\nefficiently finds optimal solutions, taking an average of 0.03 seconds to find\na reconfiguration plan for a manufacturing line with 51 operations and 40\navailable agents across 8 agent types.", "comment": "IEEE Transactions on Automation Science and Engineering (T-ASE) and\n  CASE 2025", "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.07332v1", "AI": {"title_translation": "基于数字孪生的智能制造：面向扰动处理的动态产线重构", "tldr": "该论文提出了一种基于数字孪生的动态产线重构框架，用于智能制造中处理扰动，显著提高了生产线在面对中断时的吞吐量恢复能力。", "motivation": "现代制造业日益复杂，面临需求波动、供应链不确定性和产品定制化等挑战，需要能够灵活更新配置并迅速适应扰动的制造系统。然而，现有研究未能提供一个全面的可重构制造框架，以无缝监控系统扰动、基于机器能力优化替代产线配置，并自动化仿真评估以实现快速适应。", "method": "该框架包括：1) 用于监控扰动和触发重构的系统过程数字孪生；2) 捕获可用代理和资源选项的基于能力的本体模型；3) 生成最优产线配置的配置优化器；4) 初始化仿真设置并以约400倍实时速度评估产线配置的仿真生成程序。通过电池生产线案例研究进行评估。", "result": "在两个扰动场景中，该框架成功地在有限资源下恢复了系统吞吐量，避免了在没有重构计划的情况下可能发生的26%和63%的吞吐量下降。重构优化器平均0.03秒就能为一个包含51个操作和40个可用代理的生产线找到重构方案。", "conclusion": "该框架通过动态产线重构有效处理了制造扰动，显著提高了系统韧性和效率，尤其在处理操作时间变化引起的扰动方面表现出色。", "translation": "现代制造业日益增长的复杂性，加上需求波动、供应链不确定性和产品定制化，凸显了对能够灵活更新其配置并迅速适应扰动的制造系统的需求。然而，当前研究在提供一个全面的可重构制造框架方面存在不足，该框架能够无缝监控系统扰动、基于机器能力优化替代产线配置，并自动化仿真评估以实现快速适应。本文提出了一种动态制造产线重构框架，以处理导致操作时间变化的扰动。该框架包含一个用于监控扰动和触发重构的系统过程数字孪生、一个捕获可用代理和资源选项的基于能力的本体模型、一个生成最优产线配置的配置优化器，以及一个初始化仿真设置并以大约400倍实时速度评估产线配置的仿真生成程序。对电池生产线进行了案例研究以评估所提出的框架。在两个已实施的扰动场景中，该框架成功地在有限资源下恢复了系统吞吐量，避免了在没有重构计划的情况下可能发生的26%和63%的吞吐量下降。重构优化器有效地找到了最优解决方案，平均0.03秒就能为一个包含51个操作和40个可用代理的制造产线找到一个重构计划。", "summary": "本文针对现代制造中因需求波动和不确定性导致的系统扰动问题，提出了一种基于数字孪生的动态产线重构框架。该框架整合了数字孪生监控、能力本体建模、配置优化器和高速仿真评估，旨在实现制造系统对操作时间变化的快速适应。通过电池生产线案例验证，该框架能有效恢复因扰动导致的吞吐量下降，并在极短时间内生成最优重构方案，显著提升了制造系统的韧性和效率。", "keywords": "数字孪生, 智能制造, 产线重构, 扰动处理, 优化", "comments": "该论文的创新点在于结合了数字孪生技术与动态产线重构，提供了一个集成化的解决方案来应对复杂制造环境中的实时扰动。其高速仿真评估能力和快速优化器是亮点，极大地提升了系统响应速度和实用性。这对于实现真正的智能制造和工业4.0愿景具有重要意义。"}}
{"id": "2506.06394", "title": "Active Illumination Control in Low-Light Environments using NightHawk", "authors": ["Yash Turkar", "Youngjin Kim", "Karthik Dantu"], "summary": "Subterranean environments such as culverts present significant challenges to\nrobot vision due to dim lighting and lack of distinctive features. Although\nonboard illumination can help, it introduces issues such as specular\nreflections, overexposure, and increased power consumption. We propose\nNightHawk, a framework that combines active illumination with exposure control\nto optimize image quality in these settings. NightHawk formulates an online\nBayesian optimization problem to determine the best light intensity and\nexposure-time for a given scene. We propose a novel feature detector-based\nmetric to quantify image utility and use it as the cost function for the\noptimizer. We built NightHawk as an event-triggered recursive optimization\npipeline and deployed it on a legged robot navigating a culvert beneath the\nErie Canal. Results from field experiments demonstrate improvements in feature\ndetection and matching by 47-197% enabling more reliable visual estimation in\nchallenging lighting conditions.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06394v1", "AI": {"title_translation": "在弱光环境中使用NightHawk进行主动照明控制", "tldr": "NightHawk是一个在弱光环境中结合主动照明和曝光控制来优化图像质量的框架，通过在线贝叶斯优化和新颖的特征检测器度量，显著提高了特征检测和匹配，从而实现更可靠的视觉估计。", "motivation": "地下环境（如涵洞）由于光线昏暗和缺乏独特特征，给机器人视觉带来了重大挑战。车载照明虽然有帮助，但会引入镜面反射、过曝和功耗增加等问题。", "method": "提出NightHawk框架，结合主动照明和曝光控制以优化图像质量。NightHawk将在线贝叶斯优化问题公式化，以确定给定场景的最佳光强度和曝光时间。提出一种新颖的基于特征检测器的度量来量化图像效用，并将其用作优化器的成本函数。NightHawk被构建为一个事件触发的递归优化管道，并部署在伊利运河下涵洞中导航的腿式机器人上。", "result": "现场实验结果表明，特征检测和匹配提高了47-197%，从而在挑战性照明条件下实现了更可靠的视觉估计。", "conclusion": "NightHawk框架通过结合主动照明和曝光控制，显著提高了弱光环境下机器人视觉的图像质量和视觉估计的可靠性。", "translation": "涵洞等地下环境由于光线昏暗和缺乏独特特征，给机器人视觉带来了重大挑战。尽管车载照明有所帮助，但它会引入镜面反射、过曝和功耗增加等问题。我们提出了NightHawk，一个结合主动照明和曝光控制以优化这些环境中图像质量的框架。NightHawk将在线贝叶斯优化问题公式化，以确定给定场景的最佳光强度和曝光时间。我们提出了一种新颖的基于特征检测器的度量来量化图像效用，并将其用作优化器的成本函数。我们将NightHawk构建为一个事件触发的递归优化管道，并将其部署在伊利运河下方涵洞中导航的腿式机器人上。现场实验结果表明，特征检测和匹配提高了47-197%，从而在挑战性照明条件下实现了更可靠的视觉估计。", "summary": "本文提出了NightHawk，一个用于弱光环境下主动照明控制的框架，旨在解决地下环境中机器人视觉面临的挑战。NightHawk通过在线贝叶斯优化来确定最佳光强度和曝光时间，并引入了一种新颖的基于特征检测器的度量作为成本函数。在腿式机器人上的现场实验表明，该系统能将特征检测和匹配性能提高47-197%，从而在恶劣照明条件下实现更可靠的视觉估计。", "keywords": "主动照明, 曝光控制, 贝叶斯优化, 机器人视觉, 弱光环境", "comments": "该论文的创新之处在于其结合主动照明与曝光控制的在线贝叶斯优化方法，以及提出的基于特征检测器的新颖图像效用度量。NightHawk显著提升了机器人视觉在极具挑战性的弱光环境中的性能，对于地下探测、搜救等领域具有重要意义。"}}
{"id": "2506.06509", "title": "Private GPTs for LLM-driven testing in software development and machine learning", "authors": ["Jakub Jagielski", "Markus Abel"], "summary": "In this contribution, we examine the capability of private GPTs to\nautomatically generate executable test code based on requirements. More\nspecifically, we use acceptance criteria as input, formulated as part of epics,\nor stories, which are typically used in modern development processes. This\ngives product owners, or business intelligence, respectively, a way to directly\nproduce testable criteria through the use of LLMs. We explore the quality of\nthe so-produced tests in two ways: i) directly by letting the LLM generate code\nfrom requirements, ii) through an intermediate step using Gherkin syntax. As a\nresult, it turns out that the two-step procedure yields better results -where\nwe define better in terms of human readability and best coding practices, i.e.\nlines of code and use of additional libraries typically used in testing.\nConcretely, we evaluate prompt effectiveness across two scenarios: a simple\n\"Hello World\" program and a digit classification model, showing that structured\nprompts lead to higher-quality test outputs.", "comment": "5 pages, 10 figures", "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.06509v1", "AI": {"title_translation": "用于软件开发和机器学习中基于LLM的测试的私有GPTs", "tldr": "本文探讨了私有GPTs根据需求自动生成可执行测试代码的能力，发现两步过程（通过Gherkin语法）和结构化提示能产生更高质量的测试。", "motivation": "本文旨在探究私有GPTs自动根据需求（如验收标准）生成可执行测试代码的能力，从而让产品负责人或业务智能人员能够直接通过大型语言模型（LLMs）生成可测试标准。", "method": "研究人员使用私有GPTs，以验收标准作为输入，探索了两种生成测试代码的方式：1) LLM直接从需求生成代码；2) 通过使用Gherkin语法作为中间步骤。他们通过评估提示词在“Hello World”程序和数字分类模型两个场景中的有效性来衡量所生成测试的质量。", "result": "结果表明，两步过程（通过Gherkin语法）能产生更好的测试结果，这体现在人类可读性和最佳编码实践（如代码行数和附加库的使用）方面。此外，结构化提示词能带来更高质量的测试输出。", "conclusion": "本文得出结论，私有GPTs能够有效地根据需求生成可执行测试代码，并且采用中间步骤（如Gherkin语法）和结构化提示词可以显著提高生成测试的质量和实用性。", "translation": "在这项贡献中，我们检验了私有GPTs根据需求自动生成可执行测试代码的能力。更具体地说，我们使用验收标准作为输入，这些标准通常以史诗或故事的形式在现代开发流程中使用。这使得产品负责人或业务智能人员能够分别通过使用大型语言模型（LLMs）直接生成可测试的标准。我们通过两种方式探索了所生成测试的质量：i）直接让LLM从需求生成代码，ii）通过使用Gherkin语法作为中间步骤。结果表明，两步过程产生了更好的结果——我们将“更好”定义为人类可读性和最佳编码实践，即代码行数和测试中通常使用的额外库的使用。具体来说，我们在两种场景中评估了提示词的有效性：一个简单的“Hello World”程序和一个数字分类模型，结果显示结构化提示词能带来更高质量的测试输出。", "summary": "本文研究了私有GPTs在软件开发和机器学习中根据需求自动生成可执行测试代码的能力。研究人员利用验收标准作为输入，比较了LLM直接生成测试代码和通过Gherkin语法作为中间步骤的两种方法。实验结果表明，采用两步过程（通过Gherkin语法）能生成更高质量的测试，并在“Hello World”程序和数字分类模型场景中验证了结构化提示词能提升测试输出的质量。", "keywords": "私有GPTs, LLM驱动测试, 自动化测试, 软件开发, Gherkin语法", "comments": "该研究探讨了利用私有GPTs实现LLM驱动的测试自动化，这在当前AI辅助软件开发的背景下具有重要意义。特别是，它为产品所有者直接生成可测试标准提供了潜在途径，弥合了业务需求与技术实现之间的鸿沟。比较直接生成和通过Gherkin语法中间步骤的方法，并得出两步法更优的结论，为实际应用提供了有价值的指导。对结构化提示词有效性的强调也进一步提升了其实用性。"}}
{"id": "2506.06480", "title": "(LiFT) Lightweight Fitness Transformer: A language-vision model for Remote Monitoring of Physical Training", "authors": ["A. Postlmayr", "P. Cosman", "S. Dey"], "summary": "We introduce a fitness tracking system that enables remote monitoring for\nexercises using only a RGB smartphone camera, making fitness tracking more\nprivate, scalable, and cost effective. Although prior work explored automated\nexercise supervision, existing models are either too limited in exercise\nvariety or too complex for real-world deployment. Prior approaches typically\nfocus on a small set of exercises and fail to generalize across diverse\nmovements. In contrast, we develop a robust, multitask motion analysis model\ncapable of performing exercise detection and repetition counting across\nhundreds of exercises, a scale far beyond previous methods. We overcome\nprevious data limitations by assembling a large-scale fitness dataset, Olympia\ncovering more than 1,900 exercises. To our knowledge, our vision-language model\nis the first that can perform multiple tasks on skeletal fitness data. On\nOlympia, our model can detect exercises with 76.5% accuracy and count\nrepetitions with 85.3% off-by-one accuracy, using only RGB video. By presenting\na single vision-language transformer model for both exercise identification and\nrep counting, we take a significant step toward democratizing AI-powered\nfitness tracking.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06480v1", "AI": {"title_translation": "（LiFT）轻量级健身Transformer：一种用于远程监控体能训练的语言-视觉模型", "tldr": "LiFT是一个轻量级语言-视觉模型，仅使用RGB智能手机摄像头即可远程监控数百种运动，解决了现有健身追踪系统在运动种类和部署复杂性方面的局限性。", "motivation": "现有的自动化运动监督模型在运动种类上过于有限，或者对于实际部署来说过于复杂，无法泛化到多样化的动作。先前的方案通常只关注少数运动，且无法在多种动作中实现泛化。", "method": "研究人员开发了一个名为LiFT的鲁棒多任务运动分析模型，能够对数百种运动进行运动检测和重复计数。通过构建一个名为Olympia的大规模健身数据集（包含超过1900种运动），克服了先前的数据限制。该模型是第一个能对骨骼健身数据执行多任务的视觉-语言模型。", "result": "在Olympia数据集上，该模型使用RGB视频进行运动检测的准确率为76.5%，重复计数的一差准确率为85.3%。", "conclusion": "通过提出一个单一的视觉-语言Transformer模型，同时实现运动识别和重复计数，该研究在普及AI驱动的健身追踪方面迈出了重要一步。", "translation": "我们引入了一种健身追踪系统，该系统仅使用RGB智能手机摄像头即可实现运动的远程监控，从而使健身追踪更加私密、可扩展且经济高效。尽管先前的工作探索了自动化运动监督，但现有模型要么在运动种类上过于有限，要么对于实际部署来说过于复杂。先前的方案通常只关注少数运动，并且无法泛化到多样化的动作。相比之下，我们开发了一个鲁棒的多任务运动分析模型，能够对数百种运动进行运动检测和重复计数，其规模远远超过了以前的方法。我们通过组建一个名为Olympia的大规模健身数据集（涵盖1900多种运动）来克服先前的数据限制。据我们所知，我们的视觉-语言模型是第一个可以在骨骼健身数据上执行多任务的模型。在Olympia上，我们的模型仅使用RGB视频即可实现76.5%的运动检测准确率和85.3%的一差重复计数准确率。通过提出一个单一的视觉-语言Transformer模型，同时用于运动识别和重复计数，我们在普及AI驱动的健身追踪方面迈出了重要一步。", "summary": "本文介绍了一种名为LiFT（轻量级健身Transformer）的语言-视觉模型，旨在通过RGB智能手机摄像头实现远程体能训练监控。针对现有健身追踪系统运动种类有限和部署复杂的问题，LiFT开发了一个鲁棒的多任务模型，结合了大规模的Olympia数据集（包含1900多种运动），能够对数百种运动进行检测和重复计数。该模型在运动检测和重复计数方面取得了高准确率，并被认为是首个能对骨骼健身数据执行多任务的视觉-语言模型，为普及AI健身追踪迈出了重要一步。", "keywords": "健身追踪, 远程监控, 语言-视觉模型, Transformer, 运动检测", "comments": "该论文的创新点在于提出了一个轻量级的视觉-语言Transformer模型LiFT，并构建了迄今为止最大规模的健身数据集Olympia，极大地扩展了可追踪的运动种类。其重要性在于通过仅使用智能手机RGB摄像头，降低了远程健身监控的成本和复杂性，使其更具可访问性和隐私性。该方法的多任务能力和对大量运动的泛化能力是其显著优势，有望推动AI健身追踪的民主化。"}}
{"id": "2506.07026", "title": "An $α$-triangle eigenvector centrality of graphs", "authors": ["Zhang Qingying", "Sun Lizhu", "Bu Changjiang"], "summary": "Centrality represents a fundamental research field in complex network\nanalysis, where centrality measures identify important vertices within\nnetworks. Over the years, researchers have developed diverse centrality\nmeasures from varied perspectives. This paper proposes an $\\alpha$-triangle\neigenvector centrality ($\\alpha$TEC), which is a global centrality measure\nbased on both edge and triangle structures. It can dynamically adjust the\ninfluence of edges and triangles through a parameter $\\alpha$ ($\\alpha \\in\n(0,1]$). The centrality scores for vertices are defined as the eigenvector\ncorresponding to the spectral radius of a nonnegative tensor. By the\nPerron-Frobenius theorem, $\\alpha$TEC guarantees unique positive centrality\nscores for all vertices in connected graphs. Numerical experiments on synthetic\nand real world networks demonstrate that $\\alpha$TEC effectively identifies the\nvertex's structural positioning within graphs. As $\\alpha$ increases\n(decreases), the centrality rankings reflect a stronger (weaker) contribution\nfrom edge structure and a weaker (stronger) contribution from triangle\nstructure. Furthermore, we experimentally prove that vertices with higher\n$\\alpha$TEC rankings have a greater impact on network connectivity.", "comment": "18pages,13figures", "cate": "cs.SI", "url": "http://arxiv.org/abs/2506.07026v1", "AI": {"title_translation": "图的$\\\\alpha$-三角形特征向量中心性", "tldr": "本文提出了一种新的网络中心性度量$\\\\alpha$TEC，它结合了边和三角形结构，并通过参数$\\\\alpha$动态调整其影响，能有效识别节点结构位置并影响网络连通性。", "motivation": "复杂网络分析中，中心性度量是识别网络中重要顶点的基本研究领域。现有方法多样，但可能没有充分结合边和三角形结构并动态调整其影响。", "method": "提出了$\\\\alpha$-三角形特征向量中心性（$\\\\alpha$TEC），这是一种基于边和三角形结构的全局中心性度量。它通过参数$\\\\alpha \\\\in (0,1]$动态调整边和三角形结构的影响。顶点中心性分数被定义为非负张量谱半径对应的特征向量。通过Perron-Frobenius定理保证了连通图中所有顶点的唯一正中心性分数。", "result": "在合成网络和真实世界网络上的数值实验表明，$\\\\alpha$TEC能有效识别图中顶点的结构位置。随着$\\\\alpha$的增加（减少），中心性排名反映出边结构贡献更强（弱），三角形结构贡献更弱（强）。实验证明，$\\\\alpha$TEC排名较高的顶点对网络连通性有更大的影响。", "conclusion": "$\\\\alpha$TEC是一种有效的中心性度量，它结合了边和三角形结构，能够识别顶点在网络中的结构位置，并且与网络连通性有显著关联。其参数$\\\\alpha$允许动态调整不同结构的影响。", "translation": "复杂网络分析中，中心性代表一个基本研究领域，其中中心性度量识别网络中的重要顶点。多年来，研究人员从不同角度发展了多种中心性度量。本文提出了一种$\\\\alpha$-三角形特征向量中心性（$\\\\alpha$TEC），这是一种基于边和三角形结构的全局中心性度量。它可以通过参数$\\\\alpha$（$\\\\alpha \\\\in (0,1]$）动态调整边和三角形的影响。顶点的中心性分数被定义为非负张量的谱半径对应的特征向量。根据Perron-Frobenius定理，$\\\\alpha$TEC保证了连通图中所有顶点的唯一正中心性分数。对合成网络和真实世界网络的数值实验表明，$\\\\alpha$TEC能有效识别图中顶点的结构位置。随着$\\\\alpha$的增加（减少），中心性排名反映出边结构贡献更强（弱），三角形结构贡献更弱（强）。此外，我们实验证明，$\\\\alpha$TEC排名较高的顶点对网络连通性有更大的影响。", "summary": "本文提出了一种名为$\\\\alpha$TEC的新型全局中心性度量，用于复杂网络分析。$\\\\alpha$TEC基于边和三角形结构，并通过参数$\\\\alpha$动态平衡两者影响。通过非负张量的特征向量定义中心性分数，并利用Perron-Frobenius定理确保其唯一性。实验证明，$\\\\alpha$TEC能有效识别顶点结构位置，且$\\\\alpha$的调整能反映不同结构贡献。此外，高$\\\\alpha$TEC排名的顶点对网络连通性影响更大。", "keywords": "中心性度量, $\\\\alpha$-三角形特征向量中心性, 复杂网络, 张量, 网络连通性", "comments": "该论文的创新点在于提出了一种结合边和三角形结构的新型中心性度量，并引入可调参数$\\\\alpha$以动态平衡这两种结构的影响，这使得该度量在不同网络和应用场景中具有更强的适应性。其基于张量特征向量的方法论也为中心性研究提供了新的视角。"}}
{"id": "2506.06285", "title": "NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy Forecasting", "authors": ["Kaike Sa Teles Rocha Alves", "Eduardo Pestana de Aguiar"], "summary": "Evolving Fuzzy Systems (eFS) have gained significant attention due to their\nability to adaptively update their structure in response to data dynamics while\nmaintaining interpretability. However, the lack of publicly available\nimplementations of these models limits their accessibility and widespread\nadoption. To address this gap, we present evolvingfuzzysystems, a Python\nlibrary that provides implementations of several well-established eFS models,\nincluding ePL-KRLS-DISCO, ePL+, eMG, ePL, exTS, Simpl\\_eTS, and eTS. The\nlibrary facilitates model evaluation and comparison by offering built-in tools\nfor training, visualization, and performance assessment. The models are\nevaluated using the fetch\\_california\\_housing dataset, with performance\nmeasured in terms of normalized root-mean-square error (NRMSE), non-dimensional\nerror index (NDEI), and mean absolute percentage error (MAPE). Additionally,\ncomputational complexity is analyzed by measuring execution times and rule\nevolution during training and testing phases. The results highlight ePL as a\nsimple yet efficient model that balances accuracy and computational cost,\nmaking it particularly suitable for real-world applications. By making these\nmodels publicly available, evolvingfuzzysystems aims to foster research and\npractical applications in adaptive and interpretable machine learning.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06285v1", "AI": {"title_translation": "NFISiS: 可再生能源预测中模糊推理系统的新视角", "tldr": "本文介绍了 `evolvingfuzzysystems`，一个用于演化模糊系统 (eFS) 的 Python 库，旨在提高这些模型的可用性并促进自适应机器学习领域的研究。", "motivation": "演化模糊系统 (eFS) 模型缺乏公开可用的实现，限制了它们的易用性和广泛采用，从而阻碍了相关研究和实际应用。", "method": "作者开发了名为 `evolvingfuzzysystems` 的 Python 库，其中实现了多种成熟的 eFS 模型。该库提供了用于模型训练、可视化和性能评估的内置工具。模型使用 `fetch_california_housing` 数据集进行评估，性能指标包括 NRMSE、NDEI 和 MAPE，同时通过测量执行时间和规则演化来分析计算复杂度。", "result": "评估结果表明，ePL 是一种简单而高效的模型，在准确性和计算成本之间取得了良好平衡，使其特别适用于实际应用。", "conclusion": "通过公开提供 eFS 模型的实现，`evolvingfuzzysystems` 库旨在促进自适应和可解释机器学习领域的研究和实际应用。", "translation": "演化模糊系统 (eFS) 因其能够根据数据动态自适应更新结构同时保持可解释性而受到广泛关注。然而，这些模型缺乏公开可用的实现，限制了它们的易用性和广泛采用。为了弥补这一空白，我们推出了 evolvingfuzzysystems，这是一个 Python 库，提供了几种成熟 eFS 模型的实现，包括 ePL-KRLS-DISCO、ePL+、eMG、ePL、exTS、Simpl_eTS 和 eTS。该库通过提供用于训练、可视化和性能评估的内置工具，促进了模型评估和比较。这些模型使用 fetch_california_housing 数据集进行评估，性能通过归一化均方根误差 (NRMSE)、无量纲误差指数 (NDEI) 和平均绝对百分比误差 (MAPE) 来衡量。此外，通过测量训练和测试阶段的执行时间和规则演化来分析计算复杂度。结果突出显示 ePL 是一种简单而高效的模型，它在准确性和计算成本之间取得了平衡，使其特别适用于实际应用。通过公开这些模型，evolvingfuzzysystems 旨在促进自适应和可解释机器学习领域的研究和实际应用。", "summary": "本文介绍了 `evolvingfuzzysystems`，一个旨在解决演化模糊系统 (eFS) 模型可用性受限问题的 Python 库。该库包含了多种 eFS 模型的实现，并提供了训练、可视化和性能评估工具。通过在 `fetch_california_housing` 数据集上的实验，研究表明 ePL 是一种高效的模型，能在准确性和计算成本之间取得平衡。该库的总体目标是推动自适应和可解释机器学习领域的进一步研究与实际应用。", "keywords": "演化模糊系统, Python库, 机器学习, 可解释性, 自适应系统", "comments": "该论文通过提供一个公开的 Python 库，解决了演化模糊系统领域一个重要的实际限制。这一举措对于加速这些自适应且可解释的机器学习模型的研究和应用至关重要，这些模型在实际应用中具有高度相关性。对可用性和性能评估（包括计算成本）的关注增加了其实用价值。"}}
{"id": "2506.06796", "title": "Polarized Element-pair Code Based FFMA over a Gaussian Multiple-access Channel", "authors": ["Zhang-li-han Liu", "Qi-yue Yu"], "summary": "This paper presents polarized element-pair (EP) codes for\npolarization-adjusted finite-field multiple-access (PA-FFMA) systems. The core\ninnovation of FFMA systems lies in their unique processing order that exchanges\nthe conventional sequence of channel coding and multiplexing operations,\neffectively solving the multiuser finite-blocklength (FBL) problem while\nenhancing error performance. In this architecture, EPs serve as virtual\nresources for user separation, where different EP codes provide distinct error\nperformance characteristics. The proposed polarized EP code differs from\nclassical polar codes in one aspect that it is specifically designed for\nGaussian multiple access channel (GMAC) environments rather than single-user\nGaussian channels. We derive the channel capacity for this polarized EP code\nbased FFMA system, then develop an optimal power allocation scheme to maximize\nmultiuser channel capacity. The code construction employs the Marto Loco method\nfor selecting the polarized index set. For decoding, we introduce two\nspecialized algorithms. A successive cancellation list (SCL) decoder for the\nbalanced information-parity section scenarios, and a top $L$ bifurcated minimum\ndistance (Top$L$-BMD) decoder for small payload cases while maintaining\ncomparable error performance. Simulations show that, for $15$ users, our system\nachieves a $1.25$ dB coding gain compared to the state-of-the-art polar random\nspreading systems.", "comment": "13 pages 8 figures", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.06796v1", "AI": {"title_translation": "高斯多址信道下基于极化单元对码的FFMA", "tldr": "本文提出一种用于PA-FFMA系统的极化单元对（EP）码，它针对高斯多址信道（GMAC）设计，通过独特的处理顺序和新颖的解码算法，解决了多用户有限块长问题，并在15用户场景下比现有系统实现1.25 dB的编码增益。", "motivation": "解决多用户有限块长（FBL）问题并提高错误性能，特别是在FFMA系统中，通过交换信道编码和多路复用操作的传统顺序。", "method": "1. 提出极化单元对（EP）码用于PA-FFMA系统，该码专为高斯多址信道（GMAC）设计。 2. 推导了基于该极化EP码的FFMA系统的信道容量，并开发了最优功率分配方案以最大化多用户信道容量。 3. 采用Marto Loco方法进行码构造。 4. 引入两种专用解码算法：用于信息-奇偶校验平衡场景的逐次消除列表（SCL）译码器，以及用于小载荷情况的Top$L$-BMD译码器。", "result": "仿真结果表明，在15个用户的情况下，该系统比最先进的极化随机扩频系统实现了1.25 dB的编码增益。", "conclusion": "本文提出了一种专为GMAC环境设计的极化EP码，并结合FFMA系统架构和创新的解码算法，有效解决了多用户有限块长问题，显著提升了错误性能，并实现了可观的编码增益。", "translation": "本文提出了一种用于极化调整有限域多址（PA-FFMA）系统的极化单元对（EP）码。FFMA系统的核心创新在于其独特的处理顺序，该顺序交换了信道编码和多路复用操作的传统序列，有效解决了多用户有限块长（FBL）问题，同时提高了错误性能。在此架构中，EP作为用户分离的虚拟资源，不同的EP码提供不同的错误性能特性。所提出的极化EP码与经典极化码在一个方面有所不同，即它专门为高斯多址信道（GMAC）环境而非单用户高斯信道设计。我们推导了基于这种极化EP码的FFMA系统的信道容量，然后开发了一种最优功率分配方案以最大化多用户信道容量。码构造采用Marto Loco方法选择极化索引集。对于解码，我们引入了两种专用算法。一种是用于信息-奇偶校验平衡场景的逐次消除列表（SCL）译码器，另一种是用于小载荷情况的Top$L$-BMD译码器，同时保持可比较的错误性能。仿真结果表明，对于15个用户，我们的系统比最先进的极化随机扩频系统实现了1.25 dB的编码增益。", "summary": "本文提出了一种针对高斯多址信道（GMAC）环境设计的极化单元对（EP）码，并将其应用于极化调整有限域多址（PA-FFMA）系统。该系统通过独特的处理顺序解决了多用户有限块长（FBL）问题并提高了错误性能。研究内容包括推导信道容量、开发最优功率分配方案、采用Marto Loco方法进行码构造，以及引入SCL和Top$L$-BMD两种专用解码算法。仿真结果显示，在15个用户场景下，该系统相比现有极化随机扩频系统实现了1.25 dB的编码增益。", "keywords": "极化单元对码, FFMA, 高斯多址信道, 有限块长, 解码算法", "comments": "这篇论文通过引入专门为高斯多址信道设计的极化单元对码，并在FFMA架构中应用，创新性地解决了多用户有限块长通信的挑战。其独特的处理顺序和针对性的解码算法（SCL和TopL-BMD）是亮点。1.25 dB的编码增益证明了其在性能上的显著提升，对于多用户通信系统的实际应用具有重要意义。"}}
{"id": "2506.06773", "title": "Taming Wild Branches: Overcoming Hard-to-Predict Branches using the Bullseye Predictor", "authors": ["Emet Behrendt", "Shing Wai Pun", "Prashant J. Nair"], "summary": "Branch prediction is key to the performance of out-of-order processors. While\nthe CBP-2016 winner TAGE-SC-L combines geometric-history tables, a statistical\ncorrector, and a loop predictor, over half of its remaining mispredictions stem\nfrom a small set of hard-to-predict (H2P) branches. These branches occur under\ndiverse global histories, causing repeated thrashing in TAGE and eviction\nbefore usefulness counters can mature. Prior work shows that simply enlarging\nthe tables offers only marginal improvement.\n  We augment a 159 KB TAGE-SC-L predictor with a 28 KB H2P-targeted subsystem\ncalled the Bullseye predictor. It identifies problematic PCs using a\nset-associative H2P Identification Table (HIT) and steers them to one of two\nbranch-specific perceptrons, one indexed by hashed local history and the other\nby folded global history. A short trial phase tracks head-to-head accuracy in\nan H2P cache. A branch becomes perceptron-resident only if the perceptron's\nsustained accuracy and output magnitude exceed dynamic thresholds, after which\nTAGE updates for that PC are suppressed to reduce pollution. The HIT, cache,\nand perceptron operate fully in parallel with TAGE-SC-L, providing higher\nfidelity on the H2P tail. This achieves an average MPKI of 3.4045 and CycWpPKI\nof 145.09.", "comment": "Paper accepted and presented at the 6th Championship Branch\n  Prediction (CBP) workshop, co-held with ISCA 2025, on June 21, 2025, Tokyo,\n  Japan", "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.06773v1", "AI": {"title_translation": "驯服“狂野”分支：使用Bullseye预测器克服难以预测的分支", "tldr": "本文提出了Bullseye预测器，通过专门针对难以预测的分支来改进分支预测，从而实现比TAGE-SC-L更好的准确性。", "motivation": "乱序处理器的分支预测性能关键，但CBP-2016获胜者TAGE-SC-L等现有分支预测器仍有超过一半的误预测源于一小部分难以预测（H2P）的分支。这些分支在多样化的全局历史下发生，导致TAGE中反复抖动并被逐出，简单地扩大表只能带来微小的改进。", "method": "作者用一个28 KB的H2P目标子系统，即Bullseye预测器，增强了159 KB的TAGE-SC-L预测器。它使用一个组相联的H2P识别表（HIT）来识别有问题的分支PC，并将其引导到两个分支特定的感知器之一。一个短暂的试验阶段在H2P缓存中跟踪一对一的准确性。只有当感知器的持续准确性和输出幅度超过动态阈值时，分支才成为感知器驻留，此后该PC的TAGE更新被抑制以减少污染。HIT、缓存和感知器与TAGE-SC-L完全并行运行。", "result": "该方法实现了平均MPKI为3.4045和CycWpPKI为145.09。", "conclusion": "Bullseye预测器通过补充现有预测器，有效解决了难以预测分支的挑战，显著提高了整体分支预测的准确性和性能。", "translation": "分支预测是乱序处理器性能的关键。虽然CBP-2016的获胜者TAGE-SC-L结合了几何历史表、一个统计校正器和一个循环预测器，但其剩余的误预测中超过一半源于一小部分难以预测（H2P）的分支。这些分支在不同的全局历史下出现，导致TAGE中反复抖动并在有用性计数器成熟之前被逐出。先前的研究表明，简单地扩大表只能带来微小的改进。\n我们用一个28 KB的H2P目标子系统（称为Bullseye预测器）增强了一个159 KB的TAGE-SC-L预测器。它使用一个组相联的H2P识别表（HIT）来识别有问题的分支PC，并将其引导到两个分支特定的感知器之一，一个由哈希局部历史索引，另一个由折叠全局历史索引。一个短暂的试验阶段在H2P缓存中跟踪一对一的准确性。只有当感知器的持续准确性和输出幅度超过动态阈值时，分支才成为感知器驻留，此后该PC的TAGE更新被抑制以减少污染。HIT、缓存和感知器与TAGE-SC-L完全并行运行，为H2P尾部提供更高的保真度。这实现了平均MPKI为3.4045和CycWpPKI为145.09。", "summary": "本文旨在解决现有最先进分支预测器（如TAGE-SC-L）中难以预测（H2P）分支导致的误预测问题。作者提出了Bullseye预测器，这是一个28 KB的H2P目标子系统，用于增强TAGE-SC-L。Bullseye通过识别表（HIT）识别H2P分支，并将其引导至专门的感知器。它采用试验阶段和动态阈值来确保高准确性，并抑制这些分支的TAGE更新，同时与TAGE-SC-L并行操作。这种方法显著减少了误预测，提高了MPKI和CycWpPKI指标。", "keywords": "分支预测, 难以预测分支, Bullseye预测器, TAGE-SC-L, 感知器", "comments": "本文的创新之处在于其专门针对难以预测分支的策略，通过引入HIT、感知器、试验阶段和更新抑制等机制，有效解决了通用预测器难以处理的“尾部”问题。这对于提升现代CPU架构的性能至关重要，因为它能显著减少分支误预测这一关键性能瓶颈。"}}
{"id": "2506.06292", "title": "Mutual-Taught for Co-adapting Policy and Reward Models", "authors": ["Tianyuan Shi", "Canbin Huang", "Fanqi Wan", "Longguang Zhong", "Ziyi Yang", "Weizhou Shen", "Xiaojun Quan", "Ming Yan"], "summary": "During the preference optimization of large language models (LLMs),\ndistribution shifts may arise between newly generated model samples and the\ndata used to train the reward model (RM). This shift reduces the efficacy of\nthe RM, which in turn negatively impacts the performance of the policy model\n(PM). To address this challenge, we propose Mutual-Taught, a self-training\nmethod that iteratively improves both the PM and RM without requiring\nadditional human annotation. Our approach mirrors the expectation-maximization\n(EM) algorithm. In the E-step, the PM is updated using feedback from the\ncurrent RM, guiding the PM toward a better approximation of the latent optimal\npreference distribution. In the M-step, we update the RM by constructing\ntraining data from the outputs of the PM before and after the E-step update.\nThis process ensures that the RM adapts to the evolving policy distribution.\nExperimental results demonstrate that this iterative approach leads to\nconsistent improvements in both models. Specifically, our 8B policy model,\nLLaMA-3-8B-Instruct-MT, achieves a length-controlled win rate of 54.1\\% on\nAlpacaEval-2, while our 8B reward model, FsfairX-LLaMA3-RM-MT, performs on par\nwith GPT-4o-2024-08-06 on RewardBench.", "comment": "Accepted to ACL 2025 (Main Conference)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06292v1", "AI": {"title_translation": "用于协同适应策略模型和奖励模型的互教方法", "tldr": "提出了一种名为Mutual-Taught的自训练方法，通过迭代更新策略模型和奖励模型来解决大型语言模型偏好优化中的分布偏移问题，无需额外人工标注，并取得了显著效果。", "motivation": "在大型语言模型（LLMs）的偏好优化过程中，新生成的模型样本与奖励模型（RM）训练数据之间可能出现分布偏移，这会降低RM的效率，进而负面影响策略模型（PM）的性能。", "method": "提出了一种名为Mutual-Taught的自训练方法，该方法无需额外人工标注即可迭代改进PM和RM。它模仿了期望最大化（EM）算法：E步中，PM利用当前RM的反馈进行更新，引导PM更好地近似潜在的最优偏好分布；M步中，通过构建E步更新前后PM的输出来更新RM的训练数据，确保RM适应不断变化的策略分布。", "result": "实验结果表明，这种迭代方法能持续改进两个模型。具体而言，8B策略模型LLaMA-3-8B-Instruct-MT在AlpacaEval-2上达到了54.1%的长度控制胜率，而8B奖励模型FsfairX-LLaMA3-RM-MT在RewardBench上的表现与GPT-4o-2024-08-06相当。", "conclusion": "Mutual-Taught方法通过自适应地协同训练策略模型和奖励模型，有效解决了LLM偏好优化中的分布偏移问题，显著提升了模型性能。", "translation": "在大型语言模型（LLMs）的偏好优化过程中，新生成的模型样本与用于训练奖励模型（RM）的数据之间可能出现分布偏移。这种偏移降低了RM的效率，进而对策略模型（PM）的性能产生负面影响。为了解决这一挑战，我们提出了Mutual-Taught，一种自训练方法，无需额外人工标注即可迭代改进PM和RM。我们的方法模仿了期望最大化（EM）算法。在E步中，PM利用当前RM的反馈进行更新，引导PM更好地近似潜在的最优偏好分布。在M步中，我们通过构建E步更新前后PM的输出来更新RM的训练数据。这一过程确保了RM适应不断变化的策略分布。实验结果表明，这种迭代方法能持续改进两个模型。具体而言，我们的8B策略模型LLaMA-3-8B-Instruct-MT在AlpacaEval-2上达到了54.1%的长度控制胜率，而我们的8B奖励模型FsfairX-LLaMA3-RM-MT在RewardBench上的表现与GPT-4o-2024-08-06相当。", "summary": "本文提出了一种名为Mutual-Taught的自训练方法，用于解决大型语言模型偏好优化中策略模型和奖励模型之间的分布偏移问题。该方法通过迭代的E步（更新策略模型）和M步（更新奖励模型）来协同适应这两个模型，无需额外人工标注。实验证明，Mutual-Taught能持续提升模型性能，其策略模型在AlpacaEval-2上表现出色，奖励模型与顶尖模型持平。", "keywords": "大型语言模型, 偏好优化, 奖励模型, 策略模型, 自训练, 分布偏移", "comments": "该论文提出了一种创新的自训练框架Mutual-Taught，通过模拟EM算法，巧妙地解决了LLM偏好优化中策略模型和奖励模型之间的分布偏移问题。其主要创新点在于无需额外人工标注即可实现双模型的协同适应和迭代改进，这对于大规模LLM训练具有重要意义。实验结果显示出显著的性能提升，特别是奖励模型达到了与GPT-4o相媲美的水平，这表明了该方法的有效性和潜力。"}}
{"id": "2506.06355", "title": "LLMs as World Models: Data-Driven and Human-Centered Pre-Event Simulation for Disaster Impact Assessment", "authors": ["Lingyao Li", "Dawei Li", "Zhenhui Ou", "Xiaoran Xu", "Jingxiao Liu", "Zihui Ma", "Runlong Yu", "Min Deng"], "summary": "Efficient simulation is essential for enhancing proactive preparedness for\nsudden-onset disasters such as earthquakes. Recent advancements in large\nlanguage models (LLMs) as world models show promise in simulating complex\nscenarios. This study examines multiple LLMs to proactively estimate perceived\nearthquake impacts. Leveraging multimodal datasets including geospatial,\nsocioeconomic, building, and street-level imagery data, our framework generates\nModified Mercalli Intensity (MMI) predictions at zip code and county scales.\nEvaluations on the 2014 Napa and 2019 Ridgecrest earthquakes using USGS ''Did\nYou Feel It? (DYFI)'' reports demonstrate significant alignment, as evidenced\nby a high correlation of 0.88 and a low RMSE of 0.77 as compared to real\nreports at the zip code level. Techniques such as RAG and ICL can improve\nsimulation performance, while visual inputs notably enhance accuracy compared\nto structured numerical data alone. These findings show the promise of LLMs in\nsimulating disaster impacts that can help strengthen pre-event planning.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06355v1", "AI": {"title_translation": "LLMs作为世界模型：数据驱动和以人为中心的灾害事前模拟用于灾害影响评估", "tldr": "本研究利用大型语言模型（LLMs）作为世界模型，通过多模态数据对地震影响进行事前模拟，并在实际地震中表现出高精度，可用于灾害规划。", "motivation": "高效模拟对于加强对地震等突发灾害的事前准备至关重要。大型语言模型（LLMs）作为世界模型在模拟复杂场景方面显示出潜力，本研究旨在利用其能力主动估计感知的地震影响。", "method": "本研究检验了多个LLMs以主动估计感知的地震影响。框架利用包括地理空间、社会经济、建筑和街道级图像数据在内的多模态数据集，生成邮政编码和县级的修正麦卡利烈度（MMI）预测。评估在2014年纳帕和2019年里奇克雷斯特地震上使用USGS“你感觉到了吗？（DYFI）”报告进行。研究还探讨了RAG和ICL等技术以及视觉输入对模拟性能和准确性的影响。", "result": "在邮政编码级别，与USGS DYFI报告显示出显著一致性，相关性达到0.88，RMSE为0.77。RAG和ICL等技术可以提高模拟性能。视觉输入相比单独的结构化数值数据显著提高了准确性。", "conclusion": "研究结果表明，大型语言模型（LLMs）在模拟灾害影响方面显示出巨大潜力，可以有效帮助加强事前规划。", "translation": "高效模拟对于加强对地震等突发灾害的积极准备至关重要。大型语言模型（LLMs）作为世界模型的最新进展在模拟复杂场景方面显示出潜力。本研究检验了多个LLMs，以主动估计感知的地震影响。利用包括地理空间、社会经济、建筑和街道级图像数据在内的多模态数据集，我们的框架在邮政编码和县级生成修正麦卡利烈度（MMI）预测。对2014年纳帕和2019年里奇克雷斯特地震使用USGS“你感觉到了吗？（DYFI）”报告进行的评估表明，与邮政编码级别的真实报告相比，结果显示出显著的一致性，表现为0.88的高相关性和0.77的低RMSE。RAG和ICL等技术可以提高模拟性能，而视觉输入相比单独的结构化数值数据显著提高了准确性。这些发现表明LLMs在模拟灾害影响方面的潜力，有助于加强事前规划。", "summary": "本文探讨了利用大型语言模型（LLMs）作为世界模型进行地震影响的事前模拟。研究团队开发了一个框架，整合多模态数据（包括地理空间、社会经济、建筑和图像数据），以预测邮政编码和县级的修正麦卡利烈度（MMI）。通过对历史地震的评估，该模型展示了与实际报告高度一致的预测能力，相关系数达到0.88，RMSE为0.77。研究还发现，RAG和ICL等技术以及视觉输入能显著提升模拟性能和准确性。这表明LLMs在灾害影响评估和事前规划方面具有巨大潜力。", "keywords": "大型语言模型, 灾害模拟, 地震影响评估, 多模态数据, 世界模型", "comments": "这篇论文的创新点在于将LLMs作为“世界模型”应用于灾害模拟，特别是结合了多模态数据，包括视觉信息，这比传统方法更全面。其在实际地震数据上的高准确性验证了该方法的有效性。这为利用AI进行灾害预警和规划提供了新的思路，可能对未来灾害管理产生深远影响。"}}
{"id": "2506.06472", "title": "Cost-Efficient LLM Training with Lifetime-Aware Tensor Offloading via GPUDirect Storage", "authors": ["Ziqi Yuan", "Haoyang Zhang", "Yirui Eric Zhou", "Apoorve Mohan", "I-Hsin Chung", "Seetharami Seelam", "Jian Huang"], "summary": "We present the design and implementation of a new lifetime-aware tensor\noffloading framework for GPU memory expansion using low-cost PCIe-based\nsolid-state drives (SSDs). Our framework, TERAIO, is developed explicitly for\nlarge language model (LLM) training with multiple GPUs and multiple SSDs. Its\ndesign is driven by our observation that the active tensors take only a small\nfraction (1.7% on average) of allocated GPU memory in each LLM training\niteration, the inactive tensors are usually large and will not be used for a\nlong period of time, creating ample opportunities for offloading/prefetching\ntensors to/from slow SSDs without stalling the GPU training process. TERAIO\naccurately estimates the lifetime (active period of time in GPU memory) of each\ntensor with the profiling of the first few iterations in the training process.\nWith the tensor lifetime analysis, TERAIO will generate an optimized tensor\noffloading/prefetching plan and integrate it into the compiled LLM program via\nPyTorch. TERAIO has a runtime tensor migration engine to execute the\noffloading/prefetching plan via GPUDirect storage, which allows direct tensor\nmigration between GPUs and SSDs for alleviating the CPU bottleneck and\nmaximizing the SSD bandwidth utilization. In comparison with state-of-the-art\nstudies such as ZeRO-Offload and ZeRO-Infinity, we show that TERAIO improves\nthe training performance of various LLMs by 1.47x on average, and achieves\n80.7% of the ideal performance assuming unlimited GPU memory.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.06472v1", "AI": {"title_translation": "成本高效的LLM训练：基于GPUDirect Storage的生命周期感知张量卸载", "tldr": "TERAIO是一个新的生命周期感知张量卸载框架，通过GPUDirect Storage将LLM训练中的非活跃张量卸载到SSD，显著提升了训练性能并降低了成本。", "motivation": "观察到LLM训练迭代中，活跃张量仅占GPU内存的一小部分（平均1.7%），而大量非活跃张量通常较大且长时间不被使用，这为将张量卸载到低成本SSD提供了充足的机会，以扩展GPU内存并避免GPU训练过程停滞。", "method": "提出并实现了TERAIO框架，这是一个新的生命周期感知张量卸载框架，用于利用低成本PCIe SSD扩展GPU内存。TERAIO通过分析训练过程的前几次迭代来准确估计每个张量的生命周期，并生成一个优化的张量卸载/预取计划。该计划通过PyTorch集成到已编译的LLM程序中。TERAIO还包含一个运行时张量迁移引擎，通过GPUDirect Storage执行卸载/预取计划，实现GPU和SSD之间的直接张量迁移，以缓解CPU瓶颈并最大化SSD带宽利用率。", "result": "与ZeRO-Offload和ZeRO-Infinity等现有技术相比，TERAIO平均将各种LLM的训练性能提升了1.47倍，并达到了假设GPU内存无限的理想性能的80.7%。", "conclusion": "TERAIO通过其生命周期感知的张量卸载策略和对GPUDirect Storage的有效利用，显著提高了大型语言模型训练的成本效益和性能，使其能够接近理想的GPU内存使用效率。", "translation": "我们提出了一种新的生命周期感知张量卸载框架的设计和实现，用于使用低成本PCIe固态硬盘（SSD）扩展GPU内存。我们的框架TERAIO专为多GPU和多SSD的大型语言模型（LLM）训练而开发。其设计源于我们的观察：在每次LLM训练迭代中，活跃张量仅占用分配的GPU内存的一小部分（平均1.7%），而非活跃张量通常较大且长时间不被使用，这为将张量卸载/预取到/从较慢的SSD提供了充足的机会，而不会中断GPU训练过程。TERAIO通过分析训练过程的前几次迭代，准确估计每个张量的生命周期（在GPU内存中的活跃时间）。通过张量生命周期分析，TERAIO将生成一个优化的张量卸载/预取计划，并通过PyTorch将其集成到已编译的LLM程序中。TERAIO拥有一个运行时张量迁移引擎，通过GPUDirect Storage执行卸载/预取计划，从而实现GPU和SSD之间的直接张量迁移，以缓解CPU瓶颈并最大化SSD带宽利用率。与ZeRO-Offload和ZeRO-Infinity等最先进的研究相比，我们表明TERAIO平均将各种LLM的训练性能提高了1.47倍，并达到了假设GPU内存无限的理想性能的80.7%。", "summary": "本文介绍了TERAIO，一个专为多GPU和多SSD的LLM训练设计的生命周期感知张量卸载框架。该框架利用LLM训练中活跃张量占用内存少、非活跃张量大且长时间不用的特点，通过精确估计张量生命周期并生成优化卸载/预取计划，将张量高效地迁移到低成本SSD。TERAIO通过GPUDirect Storage实现GPU与SSD间的直接数据传输，有效缓解CPU瓶颈并最大化SSD带宽。实验结果表明，TERAIO相较于现有技术，将LLM训练性能平均提升1.47倍，并达到了接近理想的性能。", "keywords": "LLM训练, 张量卸载, GPUDirect Storage, 内存扩展, TERAIO", "comments": "TERAIO的创新点在于其独特的生命周期感知张量卸载策略，能够更精确地管理GPU内存和SSD之间的张量迁移。结合GPUDirect Storage实现GPU与SSD之间的直接数据传输，有效绕过了CPU瓶颈，显著提升了卸载效率和整体训练性能。这对于降低大型语言模型训练的成本和扩展其模型规模具有重要意义。"}}
{"id": "2506.06916", "title": "ARGOS: Anomaly Recognition and Guarding through O-RAN Sensing", "authors": ["Stavros Dimou", "Guevara Noubir"], "summary": "Rogue Base Station (RBS) attacks, particularly those exploiting downgrade\nvulnerabilities, remain a persistent threat as 5G Standalone (SA) deployments\nare still limited and User Equipment (UE) manufacturers continue to support\nlegacy network connectivity. This work introduces ARGOS, a comprehensive O-RAN\ncompliant Intrusion Detection System (IDS) deployed within the Near Real-Time\nRIC, designed to detect RBS downgrade attacks in real time, an area previously\nunexplored within the O-RAN context. The system enhances the 3GPP KPM Service\nModel to enable richer, UE-level telemetry and features a custom xApp that\napplies unsupervised Machine Learning models for anomaly detection.\nDistinctively, the updated KPM Service Model operates on cross-layer features\nextracted from Modem Layer 1 (ML1) logs and Measurement Reports collected\ndirectly from Commercial Off-The-Shelf (COTS) UEs. To evaluate system\nperformance under realistic conditions, a dedicated testbed is implemented\nusing Open5GS, srsRAN, and FlexRIC, and validated against an extensive\nreal-world measurement dataset. Among the evaluated models, the Variational\nAutoencoder (VAE) achieves the best balance of detection performance and\nefficiency, reaching 99.5% Accuracy with only 0.6% False Positives and minimal\nsystem overhead.", "comment": null, "cate": "cs.NI", "url": "http://arxiv.org/abs/2506.06916v1", "AI": {"title_translation": "ARGOS: 通过O-RAN感知进行异常识别与防护", "tldr": "ARGOS是一个O-RAN兼容的入侵检测系统，用于实时检测流氓基站降级攻击，通过增强的KPM服务模型和无监督机器学习实现，并在实际测试中表现出色，VAE模型达到99.5%的准确率。", "motivation": "流氓基站（RBS）攻击，特别是利用降级漏洞的攻击，仍然是一个持续存在的威胁，因为5G独立组网（SA）部署仍然有限，且用户设备（UE）制造商继续支持传统网络连接。", "method": "本文提出了ARGOS，一个部署在近实时RIC中的O-RAN兼容入侵检测系统（IDS），旨在实时检测RBS降级攻击。该系统增强了3GPP KPM服务模型，以实现更丰富、UE级别的遥测，并包含一个自定义的xApp，应用无监督机器学习模型进行异常检测。更新后的KPM服务模型利用从调制解调器层1（ML1）日志和直接从商用现货（COTS）UE收集的测量报告中提取的跨层特征。为了在实际条件下评估系统性能，使用Open5GS、srsRAN和FlexRIC实现了一个专用测试平台，并通过大量的真实世界测量数据集进行了验证。", "result": "在评估的模型中，变分自编码器（VAE）在检测性能和效率之间取得了最佳平衡，达到了99.5%的准确率，仅有0.6%的误报率，并且系统开销极小。", "conclusion": "ARGOS系统能够有效实时检测O-RAN环境下的流氓基站降级攻击，其中VAE模型表现最佳。", "translation": "流氓基站（RBS）攻击，特别是那些利用降级漏洞的攻击，仍然是一个持续存在的威胁，因为5G独立组网（SA）部署仍然有限，且用户设备（UE）制造商继续支持传统网络连接。这项工作介绍了ARGOS，一个全面的O-RAN兼容入侵检测系统（IDS），部署在近实时RIC中，旨在实时检测RBS降级攻击，这是O-RAN背景下以前未探索的领域。该系统增强了3GPP KPM服务模型，以实现更丰富、UE级别的遥测，并具有一个自定义的xApp，应用无监督机器学习模型进行异常检测。独特的是，更新后的KPM服务模型在从调制解调器层1（ML1）日志和直接从商用现货（COTS）UE收集的测量报告中提取的跨层特征上运行。为了在实际条件下评估系统性能，使用Open5GS、srsRAN和FlexRIC实现了一个专用测试平台，并针对大量的真实世界测量数据集进行了验证。在评估的模型中，变分自编码器（VAE）在检测性能和效率之间取得了最佳平衡，达到了99.5%的准确率，仅有0.6%的误报率，并且系统开销极小。", "summary": "本文提出了ARGOS，一个O-RAN兼容的入侵检测系统，部署在近实时RIC中，用于实时检测流氓基站降级攻击。该系统通过增强的3GPP KPM服务模型实现UE级遥测，并利用自定义xApp中的无监督机器学习模型进行异常检测，其特征提取自ML1日志和COTS UE的测量报告。在专用测试平台上验证显示，变分自编码器（VAE）模型表现最佳，实现了99.5%的准确率和极低的误报率。", "keywords": "流氓基站攻击, O-RAN, 入侵检测系统, 实时检测, 机器学习", "comments": "ARGOS的创新之处在于它是首个在O-RAN背景下探索实时RBS降级攻击检测的系统，并利用了从COTS UE直接获取的跨层特征。其在实际测试环境中的高性能验证，特别是VAE模型的高准确率和低误报率，凸显了其在增强5G网络安全方面的潜力。"}}
{"id": "2506.06329", "title": "The Hype Index: an NLP-driven Measure of Market News Attention", "authors": ["Zheng Cao", "Wanchaloem Wunkaew", "Helyette Geman"], "summary": "This paper introduces the Hype Index as a novel metric to quantify media\nattention toward large-cap equities, leveraging advances in Natural Language\nProcessing (NLP) for extracting predictive signals from financial news. Using\nthe S&P 100 as the focus universe, we first construct a News Count-Based Hype\nIndex, which measures relative media exposure by computing the share of news\narticles referencing each stock or sector. We then extend it to the\nCapitalization Adjusted Hype Index, adjusts for economic size by taking the\nratio of a stock's or sector's media weight to its market capitalization weight\nwithin its industry or sector. We compute both versions of the Hype Index at\nthe stock and sector levels, and evaluate them through multiple lenses: (1)\ntheir classification into different hype groups, (2) their associations with\nreturns, volatility, and VIX index at various lags, (3) their signaling power\nfor short-term market movements, and (4) their empirical properties including\ncorrelations, samplings, and trends. Our findings suggest that the Hype Index\nfamily provides a valuable set of tools for stock volatility analysis, market\nsignaling, and NLP extensions in Finance.", "comment": null, "cate": "q-fin.ST", "url": "http://arxiv.org/abs/2506.06329v1", "AI": {"title_translation": "炒作指数：一种基于自然语言处理的市场新闻关注度衡量方法", "tldr": "本文引入炒作指数，利用自然语言处理技术量化金融新闻中对大盘股的媒体关注度，并发现其在股票波动性分析和市场信号方面具有价值。", "motivation": "量化媒体对大盘股的关注度，并利用自然语言处理（NLP）从金融新闻中提取预测信号。", "method": "1. 构建新闻计数型炒作指数（News Count-Based Hype Index），通过计算提及每只股票或行业的文章份额来衡量相对媒体曝光度。2. 将其扩展为资本化调整型炒作指数（Capitalization Adjusted Hype Index），通过计算股票或行业媒体权重与其市值权重之比进行调整。3. 在股票和行业层面计算这两种炒作指数。4. 通过以下方式评估：分类到不同炒作组、与收益/波动率/VIX指数的关联、对短期市场波动的信号能力以及经验属性（相关性、采样、趋势）。", "result": "炒作指数家族为股票波动性分析、市场信号传递和金融领域NLP扩展提供了有价值的工具。", "conclusion": "炒作指数家族为股票波动性分析、市场信号传递和金融领域NLP扩展提供了有价值的工具。", "translation": "本文引入了炒作指数作为衡量媒体对大盘股关注度的新型指标，利用自然语言处理（NLP）的进展从金融新闻中提取预测信号。我们以S&P 100指数为研究范围，首先构建了新闻计数型炒作指数，该指数通过计算提及每只股票或行业的新闻文章份额来衡量相对媒体曝光度。然后，我们将其扩展为资本化调整型炒作指数，该指数通过计算股票或行业的媒体权重与其在行业或部门内的市值权重之比来调整经济规模。我们在股票和行业层面计算了这两种版本的炒作指数，并通过多重视角对其进行了评估：（1）将其分类到不同的炒作组，（2）其与不同滞后期的收益、波动率和VIX指数的关联，（3）其对短期市场波动的信号能力，以及（4）其经验属性，包括相关性、采样和趋势。我们的研究结果表明，炒作指数家族为股票波动性分析、市场信号传递和金融领域NLP扩展提供了一套有价值的工具。", "summary": "本文提出了一种名为“炒作指数”的新型指标，旨在利用自然语言处理（NLP）技术量化媒体对大盘股的关注度，并从金融新闻中提取预测信号。研究以S&P 100指数成分股为研究对象，首先构建了基于新闻计数的炒作指数，随后进一步开发了考虑经济规模的资本化调整型炒作指数。这两种指数都在股票和行业层面进行了计算，并从多个角度进行了评估，包括分类、与市场指标的关联、短期市场信号能力以及经验特性。研究结果表明，炒作指数系列为股票波动性分析、市场信号识别以及金融领域NLP应用提供了有价值的工具。", "keywords": "炒作指数, 自然语言处理, 市场关注度, 金融新闻, 股票波动性", "comments": "本文的创新之处在于引入了“炒作指数”这一概念，并结合NLP技术量化市场新闻关注度，为金融领域的量化分析提供了新的视角和工具。其在股票波动性分析和市场信号方面的应用潜力值得关注。"}}
{"id": "2506.06565", "title": "Adapting Under Fire: Multi-Agent Reinforcement Learning for Adversarial Drift in Network Security", "authors": ["Emilia Rivas", "Sabrina Saika", "Ahtesham Bakht", "Aritran Piplai", "Nathaniel D. Bastian", "Ankit Shah"], "summary": "Evolving attacks are a critical challenge for the long-term success of\nNetwork Intrusion Detection Systems (NIDS). The rise of these changing patterns\nhas exposed the limitations of traditional network security methods. While\nsignature-based methods are used to detect different types of attacks, they\noften fail to detect unknown attacks. Moreover, the system requires frequent\nupdates with new signatures as the attackers are constantly changing their\ntactics. In this paper, we design an environment where two agents improve their\npolicies over time. The adversarial agent, referred to as the red agent,\nperturbs packets to evade the intrusion detection mechanism, whereas the blue\nagent learns new defensive policies using drift adaptation techniques to\ncounter the attacks. Both agents adapt iteratively: the red agent responds to\nthe evolving NIDS, while the blue agent adjusts to emerging attack patterns. By\nstudying the model's learned policy, we offer concrete insights into drift\nadaptation techniques with high utility. Experiments show that the blue agent\nboosts model accuracy by 30% with just 2 to 3 adaptation steps using only 25 to\n30 samples each.", "comment": "In Proceedings of the 22nd International Conference on Security and\n  Cryptography, ISBN 978-989-758-760-3, ISSN 2184-7711, pages 547-554", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06565v1", "AI": {"title_translation": "在攻击下适应：网络安全中对抗性漂移的多智能体强化学习", "tldr": "本文提出了一种多智能体强化学习方法来应对网络入侵检测系统（NIDS）面临的不断演变的攻击。通过红方（攻击者）和蓝方（防御者）智能体的迭代适应，蓝方智能体利用漂移适应技术显著提高了NIDS的准确性。", "motivation": "不断演变的攻击对网络入侵检测系统（NIDS）的长期成功构成关键挑战。传统的基于签名的网络安全方法在检测未知攻击方面存在局限性，并且需要频繁更新以应对攻击者不断变化的策略。", "method": "设计了一个双智能体环境：红色对抗性智能体扰动数据包以规避入侵检测机制，而蓝色智能体则利用漂移适应技术学习新的防御策略来对抗攻击。两个智能体都迭代适应，红方响应演变的NIDS，蓝方调整以适应新兴攻击模式。", "result": "实验表明，蓝色智能体仅需2到3个适应步骤，每次仅使用25到30个样本，就能将模型准确性提高30%。通过研究模型的学习策略，本文对高效用的漂移适应技术提供了具体的见解。", "conclusion": "本文提出的多智能体强化学习方法，特别是防御智能体采用的漂移适应技术，能够有效提高网络入侵检测系统在面对不断演变攻击时的准确性，并为漂移适应技术提供了有价值的见解。", "translation": "不断演变的攻击是网络入侵检测系统（NIDS）长期成功的关键挑战。这些不断变化的模式的出现暴露了传统网络安全方法的局限性。虽然基于签名的检测方法用于检测不同类型的攻击，但它们常常无法检测未知攻击。此外，由于攻击者不断改变策略，系统需要频繁更新新签名。在本文中，我们设计了一个环境，其中两个智能体随着时间推移改进其策略。对抗性智能体，即红色智能体，扰动数据包以规避入侵检测机制，而蓝色智能体则利用漂移适应技术学习新的防御策略来对抗攻击。两个智能体都迭代适应：红色智能体响应不断演变的NIDS，而蓝色智能体则调整以适应新兴的攻击模式。通过研究模型的学习策略，我们对高效用的漂移适应技术提供了具体的见解。实验表明，蓝色智能体仅需2到3个适应步骤，每次仅使用25到30个样本，就能将模型准确性提高30%。", "summary": "本文针对网络入侵检测系统（NIDS）面临的不断演变的攻击挑战，提出了一种多智能体强化学习框架。该框架包含一个不断演变其攻击方式的“红色”对抗性智能体，以及一个利用漂移适应技术调整其防御策略的“蓝色”防御智能体。这种迭代适应显著提高了NIDS的准确性，为对抗性漂移提供了有价值的有效防御策略见解。", "keywords": "多智能体强化学习, 网络安全, 对抗性漂移, 入侵检测, 漂移适应", "comments": "本文将多智能体强化学习创新性地应用于网络安全领域，解决了一个关键的现实世界问题：抵御不断演变的威胁。红蓝智能体之间的迭代适应机制有效地模拟了对抗性环境，有助于开发出鲁棒的防御策略。在仅需少量适应步骤和样本的情况下，模型准确性的大幅提升，凸显了其漂移适应技术的效率和实用性。该方法有望带来更具弹性的NIDS。"}}
{"id": "2506.07388", "title": "Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents", "authors": ["Yun Hua", "Haosheng Chen", "Shiqin Wang", "Wenhao Li", "Xiangfeng Wang", "Jun Luo"], "summary": "Large Language Models (LLMs) show strong collaborative performance in\nmulti-agent systems with predefined roles and workflows. However, in open-ended\nenvironments lacking coordination rules, agents tend to act in self-interested\nways. The central challenge in achieving coordination lies in credit assignment\n-- fairly evaluating each agent's contribution and designing pricing mechanisms\nthat align their heterogeneous goals. This problem is critical as LLMs\nincreasingly participate in complex human-AI collaborations, where fair\ncompensation and accountability rely on effective pricing mechanisms. Inspired\nby how human societies address similar coordination challenges (e.g., through\ntemporary collaborations such as employment or subcontracting), we propose a\ncooperative workflow, Shapley-Coop. Shapley-Coop integrates Shapley\nChain-of-Thought -- leveraging marginal contributions as a principled basis for\npricing -- with structured negotiation protocols for effective price matching,\nenabling LLM agents to coordinate through rational task-time pricing and\npost-task reward redistribution. This approach aligns agent incentives, fosters\ncooperation, and maintains autonomy. We evaluate Shapley-Coop across two\nmulti-agent games and a software engineering simulation, demonstrating that it\nconsistently enhances LLM agent collaboration and facilitates equitable credit\nassignment. These results highlight the effectiveness of Shapley-Coop's pricing\nmechanisms in accurately reflecting individual contributions during task\nexecution.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.07388v1", "AI": {"title_translation": "Shapley-Coop：自利LLM智能体中涌现合作的信用分配", "tldr": "Shapley-Coop提出了一种基于Shapley值和谈判协议的信用分配机制，使自利LLM智能体能够在开放环境中通过任务时间定价和奖励再分配实现合作。", "motivation": "在缺乏协调规则的开放环境中，大型语言模型（LLM）智能体倾向于自利行为，难以实现协调。核心挑战在于信用分配，即公平评估每个智能体的贡献并设计能够协调其异质目标的定价机制，这对于日益复杂的人机协作至关重要。", "method": "提出了一种名为Shapley-Coop的合作工作流。该方法将Shapley Chain-of-Thought（利用边际贡献作为定价原则）与结构化谈判协议相结合，以实现有效的价格匹配，使LLM智能体能够通过理性任务时间定价和任务后奖励再分配进行协调。", "result": "在两个多智能体博弈和一个软件工程模拟中评估了Shapley-Coop，结果表明它持续增强了LLM智能体的协作，并促进了公平的信用分配。这些结果突出了Shapley-Coop定价机制在准确反映任务执行过程中个体贡献方面的有效性。", "conclusion": "Shapley-Coop通过其创新的定价机制，成功解决了自利LLM智能体在开放环境中实现合作的信用分配挑战，显著提升了协作效率和公平性。", "translation": "大型语言模型（LLM）在具有预定义角色和工作流程的多智能体系统中表现出强大的协作能力。然而，在缺乏协调规则的开放环境中，智能体倾向于以自利方式行事。实现协调的核心挑战在于信用分配——公平评估每个智能体的贡献并设计能够协调其异质目标的定价机制。这个问题至关重要，因为LLM越来越多地参与复杂的人机协作，其中公平的报酬和问责制依赖于有效的定价机制。受人类社会解决类似协调挑战（例如，通过临时合作，如雇佣或分包）的启发，我们提出了一种合作工作流Shapley-Coop。Shapley-Coop将Shapley思维链（利用边际贡献作为定价的原则基础）与结构化谈判协议相结合，以实现有效的价格匹配，使LLM智能体能够通过理性任务时间定价和任务后奖励再分配进行协调。这种方法协调了智能体的激励，促进了合作，并保持了自主性。我们在两个多智能体博弈和一个软件工程模拟中评估了Shapley-Coop，证明它持续增强了LLM智能体的协作并促进了公平的信用分配。这些结果突出了Shapley-Coop定价机制在准确反映任务执行过程中个体贡献方面的有效性。", "summary": "本文提出Shapley-Coop，一种为自利LLM智能体设计的新型信用分配机制，旨在促进开放环境中的合作。该方法结合了Shapley思维链的边际贡献定价原则与结构化谈判协议，通过任务时间定价和奖励再分配来协调智能体激励。实验结果表明，Shapley-Coop显著提升了LLM智能体的协作能力和信用分配的公平性。", "keywords": "LLM智能体, 信用分配, 合作, Shapley值, 多智能体系统", "comments": "Shapley-Coop的创新之处在于将Shapley值理论与LLM智能体的多智能体协作相结合，有效解决了自利智能体在开放环境中进行公平信用分配的难题。其基于边际贡献的定价机制和谈判协议为LLM智能体实现自主且高效的合作提供了新的范式，对于未来复杂人机协作系统的设计具有重要意义。"}}
{"id": "2506.06474", "title": "Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception", "authors": ["Everett Richards", "Bipul Thapa", "Lena Mashayekhy"], "summary": "Accurate and reliable object detection is critical for ensuring the safety\nand efficiency of Connected Autonomous Vehicles (CAVs). Traditional on-board\nperception systems have limited accuracy due to occlusions and blind spots,\nwhile cloud-based solutions introduce significant latency, making them\nunsuitable for real-time processing demands required for autonomous driving in\ndynamic environments. To address these challenges, we introduce an innovative\nframework, Edge-Enabled Collaborative Object Detection (ECOD) for CAVs, that\nleverages edge computing and multi-CAV collaboration for real-time,\nmulti-perspective object detection. Our ECOD framework integrates two key\nalgorithms: Perceptive Aggregation and Collaborative Estimation (PACE) and\nVariable Object Tally and Evaluation (VOTE). PACE aggregates detection data\nfrom multiple CAVs on an edge server to enhance perception in scenarios where\nindividual CAVs have limited visibility. VOTE utilizes a consensus-based voting\nmechanism to improve the accuracy of object classification by integrating data\nfrom multiple CAVs. Both algorithms are designed at the edge to operate in\nreal-time, ensuring low-latency and reliable decision-making for CAVs. We\ndevelop a hardware-based controlled testbed consisting of camera-equipped\nrobotic CAVs and an edge server to evaluate the efficacy of our framework. Our\nexperimental results demonstrate the significant benefits of ECOD in terms of\nimproved object classification accuracy, outperforming traditional\nsingle-perspective onboard approaches by up to 75%, while ensuring low-latency,\nedge-driven real-time processing. This research highlights the potential of\nedge computing to enhance collaborative perception for latency-sensitive\nautonomous systems.", "comment": "This paper has been accepted to IEEE EDGE 2025. The final version\n  will be published in IEEE Xplore later this year", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06474v1", "AI": {"title_translation": "边缘赋能的实时多车辆感知协同目标检测", "tldr": "提出了一种名为ECOD的边缘赋能协同目标检测框架，通过边缘计算和多车辆协作，显著提高了互联自动驾驶汽车的目标分类准确性，并确保了低延迟实时处理。", "motivation": "传统车载感知系统受遮挡和盲区限制，准确性有限；基于云的解决方案延迟高，不适用于自动驾驶的实时需求。", "method": "引入了边缘赋能协同目标检测（ECOD）框架，利用边缘计算和多CAV协作实现实时多视角目标检测。ECOD包含两个算法：感知聚合和协同估计（PACE）用于在边缘服务器上聚合多CAV检测数据以增强感知；可变目标统计和评估（VOTE）利用基于共识的投票机制整合多CAV数据以提高目标分类准确性。所有算法均在边缘设计，以实现实时低延迟操作。使用配备摄像头的机器人CAV和边缘服务器的硬件测试平台进行评估。", "result": "ECOD显著提高了目标分类准确性，比传统单视角车载方法高出75%，同时确保了低延迟的边缘驱动实时处理。", "conclusion": "该研究突出了边缘计算在增强延迟敏感型自动驾驶系统协同感知方面的潜力。", "translation": "精确可靠的目标检测对于确保互联自动驾驶汽车（CAV）的安全和效率至关重要。传统的车载感知系统由于遮挡和盲区而准确性有限，而基于云的解决方案则引入了显著的延迟，使其不适用于动态环境中自动驾驶所需的实时处理需求。为了解决这些挑战，我们引入了一种创新的框架——边缘赋能协同目标检测（ECOD），用于CAV，该框架利用边缘计算和多CAV协作实现实时、多视角的目标检测。我们的ECOD框架集成了两个关键算法：感知聚合和协同估计（PACE）以及可变目标统计和评估（VOTE）。PACE在边缘服务器上聚合来自多个CAV的检测数据，以增强个体CAV能见度有限情况下的感知能力。VOTE利用基于共识的投票机制，通过整合来自多个CAV的数据来提高目标分类的准确性。这两种算法都在边缘设计，以实现实时操作，确保CAV的低延迟和可靠决策。我们开发了一个由配备摄像头的机器人CAV和边缘服务器组成的硬件控制测试平台，以评估我们框架的有效性。我们的实验结果表明，ECOD在提高目标分类准确性方面具有显著优势，性能优于传统的单视角车载方法高达75%，同时确保了低延迟的边缘驱动实时处理。这项研究突出了边缘计算在增强延迟敏感型自动驾驶系统协同感知方面的潜力。", "summary": "针对互联自动驾驶汽车（CAV）中传统车载感知系统准确性受限和云端解决方案高延迟的问题，本文提出了一种边缘赋能协同目标检测（ECOD）框架。ECOD利用边缘计算和多CAV协作，通过感知聚合和协同估计（PACE）算法增强低能见度下的感知，并通过可变目标统计和评估（VOTE）算法通过共识投票提高目标分类准确性。实验结果表明，ECOD显著提升了目标分类准确性（比传统方法高出75%），并实现了低延迟实时处理，展示了边缘计算在协同感知领域的潜力。", "keywords": "边缘计算, 协同感知, 目标检测, 互联自动驾驶汽车, 低延迟", "comments": "这项研究通过引入边缘计算和多车辆协作来解决互联自动驾驶汽车中目标检测的准确性和延迟问题，具有创新性。它结合了车载系统的低延迟优势和云系统的多视角信息，通过边缘服务器实现了实时数据聚合和处理，有效克服了遮挡和盲区，并显著提高了目标分类准确性。其硬件测试平台的建立也增加了研究结果的可信度。"}}
{"id": "2506.06580", "title": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": ["Xiaoran Liu", "Istvan David"], "summary": "Insufficient data volume and quality are particularly pressing challenges in\nthe adoption of modern subsymbolic AI. To alleviate these challenges, AI\nsimulation uses virtual training environments in which AI agents can be safely\nand efficiently developed with simulated, synthetic data. Digital twins open\nnew avenues in AI simulation, as these high-fidelity virtual replicas of\nphysical systems are equipped with state-of-the-art simulators and the ability\nto further interact with the physical system for additional data collection. In\nthis article, we report on our systematic survey of digital twin-enabled AI\nsimulation. By analyzing 22 primary studies, we identify technological trends\nand derive a reference framework to situate digital twins and AI components.\nBased on our findings, we derive a reference framework and provide\narchitectural guidelines by mapping it onto the ISO 23247 reference\narchitecture for digital twins. Finally, we identify challenges and research\nopportunities for prospective researchers.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06580v1", "AI": {"title_translation": "数字孪生驱动的AI模拟：系统综述、参考框架与标准化架构映射", "tldr": "本论文系统综述了数字孪生在AI模拟中的应用，旨在解决AI数据不足的问题。通过分析22项研究，作者提出了一个参考框架，并将其映射到ISO 23247标准，同时指出了未来的挑战和研究机会。", "motivation": "现代亚符号AI的采纳面临数据量和质量不足的紧迫挑战，而AI模拟（特别是利用数字孪生）提供了一种安全高效地使用模拟合成数据开发AI智能体的方法来缓解这些问题。", "method": "本研究对数字孪生驱动的AI模拟进行了系统综述，分析了22项主要研究。在此基础上，识别了技术趋势，并导出了一个参考框架来定位数字孪生和AI组件。此外，通过将该框架映射到数字孪生的ISO 23247参考架构，提供了架构指南。", "result": "本研究识别了数字孪生驱动的AI模拟中的技术趋势，导出了一个整合数字孪生和AI组件的参考框架，并提供了将其映射到ISO 23247参考架构的架构指南。此外，还指出了该领域的挑战和研究机会。", "conclusion": "该论文通过系统综述、提出参考框架并映射到标准化架构，为数字孪生驱动的AI模拟领域提供了全面的洞察和结构化指导，同时展望了未来的研究方向。", "translation": "现代亚符号AI的采纳面临着数据量和质量不足的特别紧迫的挑战。为了缓解这些挑战，AI模拟利用虚拟训练环境，在其中可以安全有效地使用模拟的合成数据开发AI智能体。数字孪生为AI模拟开辟了新途径，因为这些物理系统的高保真虚拟副本配备了最先进的模拟器，并能够进一步与物理系统交互以进行额外的数据收集。在本文中，我们报告了我们对数字孪生支持的AI模拟进行的系统综述。通过分析22项主要研究，我们确定了技术趋势并导出了一个参考框架来定位数字孪生和AI组件。基于我们的发现，我们导出了一个参考框架，并通过将其映射到数字孪生的ISO 23247参考架构来提供架构指南。最后，我们为未来的研究人员指出了挑战和研究机会。", "summary": "本论文旨在解决现代AI面临的数据量和质量不足问题，通过系统综述数字孪生在AI模拟中的应用。研究分析了22项主要文献，识别了技术趋势，并提出了一个用于整合数字孪生和AI组件的参考框架。该框架进一步被映射到ISO 23247数字孪生参考架构，以提供具体的架构指南。最后，文章还指出了该领域未来的挑战和研究机会。", "keywords": "数字孪生, AI模拟, 系统综述, 参考框架, ISO 23247", "comments": "该论文具有重要意义，因为它系统地调查了一个新兴且关键的领域：由数字孪生增强的AI模拟，这直接解决了AI开发中的一个主要瓶颈——数据稀缺。参考框架的推导及其与ISO标准的映射提供了宝贵的架构指导，有助于促进这一复杂领域的标准化和互操作性。同时，识别未来挑战也有助于指导后续研究工作。"}}
{"id": "2506.06764", "title": "Mind the Gap: A Readability-Aware Metric for Test Code Complexity", "authors": ["Wendkûuni C. Ouédraogo", "Yinghua Li", "Xueqi Dang", "Xin Zhou", "Anil Koyuncu", "Jacques Klein", "David Lo", "Tegawendé F. Bissyandé"], "summary": "Automatically generated unit tests-from search-based tools like EvoSuite or\nLLMs-vary significantly in structure and readability. Yet most evaluations rely\non metrics like Cyclomatic Complexity and Cognitive Complexity, designed for\nfunctional code rather than test code. Recent studies have shown that\nSonarSource's Cognitive Complexity metric assigns near-zero scores to\nLLM-generated tests, yet its behavior on EvoSuite-generated tests and its\napplicability to test-specific code structures remain unexplored. We introduce\nCCTR, a Test-Aware Cognitive Complexity metric tailored for unit tests. CCTR\nintegrates structural and semantic features like assertion density, annotation\nroles, and test composition patterns-dimensions ignored by traditional\ncomplexity models but critical for understanding test code. We evaluate 15,750\ntest suites generated by EvoSuite, GPT-4o, and Mistral Large-1024 across 350\nclasses from Defects4J and SF110. Results show CCTR effectively discriminates\nbetween structured and fragmented test suites, producing interpretable scores\nthat better reflect developer-perceived effort. By bridging structural analysis\nand test readability, CCTR provides a foundation for more reliable evaluation\nand improvement of generated tests. We publicly release all data, prompts, and\nevaluation scripts to support replication.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.06764v1", "AI": {"title_translation": "注意差距：一种测试代码复杂度的可读性感知度量", "tldr": "本文提出了一种名为CCTR的测试代码认知复杂度度量，该度量专门针对单元测试，并考虑了传统复杂度模型忽略的结构和语义特征，实验证明CCTR能有效区分结构化和碎片化的测试套件，并更好地反映开发者感知的复杂性，为评估和改进自动生成的测试提供了更可靠的基础。", "motivation": "自动生成的单元测试在结构和可读性上差异显著，但现有的大多数评估指标（如圈复杂度、认知复杂度）是为功能代码而非测试代码设计的。这些传统指标对LLM生成的测试评分接近零，且对EvoSuite生成的测试的行为及其对测试特有代码结构的适用性尚未被充分探索，这导致了评估自动生成测试的局限性。", "method": "本文引入了CCTR（Test-Aware Cognitive Complexity），一种专门为单元测试定制的测试感知认知复杂度度量。CCTR整合了结构和语义特征，例如断言密度、注解角色和测试组合模式。研究人员在Defects4J和SF110的350个类上，评估了由EvoSuite、GPT-4o和Mistral Large-1024生成的15,750个测试套件。", "result": "结果表明，CCTR能有效区分结构化和碎片化的测试套件，并产生可解释的评分，这些评分能更好地反映开发者感知的努力。CCTR通过弥合结构分析和测试可读性之间的差距，为生成测试的更可靠评估和改进提供了基础。", "conclusion": "CCTR通过整合结构分析和测试可读性，为自动生成的测试提供了一个更可靠的评估和改进的基础。", "translation": "自动生成的单元测试——来自像EvoSuite这样的基于搜索的工具或大型语言模型（LLMs）——在结构和可读性上差异显著。然而，大多数评估依赖于像圈复杂度（Cyclomatic Complexity）和认知复杂度（Cognitive Complexity）这样的指标，这些指标是为功能代码而不是测试代码设计的。最近的研究表明，SonarSource的认知复杂度指标对LLM生成的测试分配了接近零的分数，但其在EvoSuite生成的测试上的行为及其对测试特定代码结构的适用性仍未被探索。我们引入了CCTR，一种专门为单元测试定制的测试感知认知复杂度度量。CCTR整合了结构和语义特征，如断言密度、注解角色和测试组合模式——这些维度被传统复杂度模型所忽略，但对理解测试代码至关重要。我们评估了来自Defects4J和SF110的350个类中，由EvoSuite、GPT-4o和Mistral Large-1024生成的15,750个测试套件。结果显示CCTR能有效区分结构化和碎片化的测试套件，产生可解释的评分，这些评分能更好地反映开发者感知的努力。通过弥合结构分析和测试可读性之间的差距，CCTR为生成测试的更可靠评估和改进提供了基础。我们公开所有数据、提示和评估脚本以支持复现。", "summary": "针对自动生成的单元测试在结构和可读性上的显著差异以及现有复杂度指标（如圈复杂度、认知复杂度）不适用于测试代码的问题，本文提出了一种名为CCTR的测试感知认知复杂度度量。CCTR专门为单元测试定制，并整合了断言密度、注解角色和测试组合模式等结构和语义特征。通过在Defects4J和SF110的350个类上对15,750个由EvoSuite、GPT-4o和Mistral Large-1024生成的测试套件进行评估，结果显示CCTR能够有效地区分结构化和碎片化的测试套件，并产生更符合开发者感知努力的可解释评分。CCTR的引入为自动生成测试的更可靠评估和改进奠定了基础。", "keywords": "测试代码复杂度, 可读性度量, CCTR, 单元测试, 生成测试", "comments": "本文的创新之处在于提出了CCTR这一专门针对单元测试的认知复杂度度量，它弥补了传统复杂度指标在评估自动生成测试方面存在的“差距”。通过整合断言密度、注解角色和测试组合模式等测试特有特征，CCTR能够更准确地反映测试代码的实际复杂性和可读性，这对于当前LLM等工具大量生成测试代码的背景下尤为重要。其重要性体现在为自动化测试的质量评估提供了更可靠的工具，有助于改进生成测试的质量。"}}
{"id": "2506.06517", "title": "GS4: Generalizable Sparse Splatting Semantic SLAM", "authors": ["Mingqi Jiang", "Chanho Kim", "Chen Ziwen", "Li Fuxin"], "summary": "Traditional SLAM algorithms are excellent at camera tracking but might\ngenerate lower resolution and incomplete 3D maps. Recently, Gaussian Splatting\n(GS) approaches have emerged as an option for SLAM with accurate, dense 3D map\nbuilding. However, existing GS-based SLAM methods rely on per-scene\noptimization which is time-consuming and does not generalize to diverse scenes\nwell. In this work, we introduce the first generalizable GS-based semantic SLAM\nalgorithm that incrementally builds and updates a 3D scene representation from\nan RGB-D video stream using a learned generalizable network. Our approach\nstarts from an RGB-D image recognition backbone to predict the Gaussian\nparameters from every downsampled and backprojected image location.\nAdditionally, we seamlessly integrate 3D semantic segmentation into our GS\nframework, bridging 3D mapping and recognition through a shared backbone. To\ncorrect localization drifting and floaters, we propose to optimize the GS for\nonly 1 iteration following global localization. We demonstrate state-of-the-art\nsemantic SLAM performance on the real-world benchmark ScanNet with an order of\nmagnitude fewer Gaussians compared to other recent GS-based methods, and\nshowcase our model's generalization capability through zero-shot transfer to\nthe NYUv2 and TUM RGB-D datasets.", "comment": "13 pages, 6 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06517v1", "AI": {"title_translation": "GS4：可泛化的稀疏溅射语义SLAM", "tldr": "提出了首个可泛化的基于高斯溅射的语义SLAM算法GS4，它通过学习网络增量构建3D场景，实现了最先进的性能和良好的泛化能力，且高斯数量远少于现有方法。", "motivation": "传统SLAM算法生成的3D地图分辨率低且不完整。现有基于高斯溅射（GS）的SLAM方法依赖于耗时的逐场景优化，泛化能力差。", "method": "引入了GS4，一个基于学习的可泛化网络，从RGB-D视频流增量构建和更新3D场景表示。该方法从RGB-D图像识别骨干网络预测高斯参数，并无缝集成3D语义分割。通过全局定位后仅优化GS一次迭代来纠正定位漂移和浮点。", "result": "在ScanNet基准测试上实现了最先进的语义SLAM性能，且高斯数量比其他GS方法少一个数量级。通过零样本迁移在NYUv2和TUM RGB-D数据集上展示了模型的泛化能力。", "conclusion": "GS4是首个可泛化的基于高斯溅射的语义SLAM算法，解决了现有GS方法在泛化性和效率上的不足，并在多个真实世界数据集上表现出卓越的性能和泛化能力。", "translation": "传统SLAM算法在相机跟踪方面表现出色，但可能会生成分辨率较低且不完整的3D地图。最近，高斯溅射（GS）方法已成为SLAM的一种选择，可以构建准确、密集的3D地图。然而，现有的基于GS的SLAM方法依赖于逐场景优化，这非常耗时且不能很好地泛化到不同的场景。在这项工作中，我们引入了第一个可泛化的基于GS的语义SLAM算法，该算法使用学习到的可泛化网络从RGB-D视频流增量构建和更新3D场景表示。我们的方法从RGB-D图像识别骨干网络开始，预测每个下采样和反投影图像位置的高斯参数。此外，我们将3D语义分割无缝集成到我们的GS框架中，通过共享骨干网络连接3D映射和识别。为了纠正定位漂移和浮点，我们建议在全局定位后仅对GS进行1次迭代优化。我们在真实世界基准ScanNet上展示了最先进的语义SLAM性能，与最近的其他基于GS的方法相比，高斯数量少了一个数量级，并通过零样本迁移到NYUv2和TUM RGB-D数据集展示了我们模型的泛化能力。", "summary": "本文提出了GS4，一种新颖的、可泛化的基于高斯溅射（GS）的语义SLAM算法。针对传统SLAM地图质量和现有GS-SLAM泛化性差的问题，GS4利用学习到的网络从RGB-D视频流增量构建和更新3D场景，并无缝集成3D语义分割。该方法通过单次迭代优化纠正定位问题，在ScanNet上实现了领先的语义SLAM性能，且显著减少了高斯数量，同时在NYUv2和TUM RGB-D数据集上展现出卓越的零样本泛化能力。", "keywords": "语义SLAM, 高斯溅射, 泛化能力, 3D重建, 实时定位与地图构建", "comments": "这篇论文通过引入“可泛化”的概念，显著提升了高斯溅射在SLAM领域的实用性，解决了现有方法对逐场景优化的依赖。其创新点在于结合了学习型网络预测高斯参数和高效的单次迭代优化策略，同时实现了3D语义分割。在减少高斯数量的同时达到SOTA性能和出色的泛化能力，是该工作的重要贡献，有望推动实时、高精度3D语义SLAM的应用。"}}
{"id": "2506.07435", "title": "Fast Geometric Embedding for Node Influence Maximization", "authors": ["Alexander Kolpakov", "Igor Rivin"], "summary": "Computing classical centrality measures such as betweenness and closeness is\ncomputationally expensive on large-scale graphs. In this work, we introduce an\nefficient force layout algorithm that embeds a graph into a low-dimensional\nspace, where the radial distance from the origin serves as a proxy for various\ncentrality measures. We evaluate our method on multiple graph families and\ndemonstrate strong correlations with degree, PageRank, and paths-based\ncentralities. As an application, it turns out that the proposed embedding\nallows to find high-influence nodes in a network, and provides a fast and\nscalable alternative to the standard greedy algorithm.", "comment": "8 pages, 4 figures, 18 tables; Github repository available\n  (https://github.com/sashakolpakov/graphem/); Package available on PyPi\n  (https://pypi.org/project/graphem-jax/)", "cate": "cs.SI", "url": "http://arxiv.org/abs/2506.07435v1", "AI": {"title_translation": "用于节点影响力最大化的快速几何嵌入", "tldr": "本文提出了一种高效的力布局算法，将图嵌入低维空间，以径向距离作为中心性度量的近似值，从而实现快速且可扩展的节点影响力最大化，替代了传统的计算密集型方法。", "motivation": "在大型图上计算经典的中心性度量（如介数和紧密度）计算成本高昂。", "method": "引入了一种高效的力布局算法，将图嵌入低维空间，其中径向距离作为各种中心性度量的代理。", "result": "该方法在多种图族上进行了评估，并与度中心性、PageRank和基于路径的中心性表现出强相关性。所提出的嵌入允许在网络中找到高影响力节点，并为标准贪婪算法提供了一种快速且可扩展的替代方案。", "conclusion": "该几何嵌入方法为节点影响力最大化提供了一种快速且可扩展的解决方案，有效替代了计算成本高的传统方法。", "translation": "计算经典中心性度量（如介数和紧密度）在大型图上计算成本高昂。在这项工作中，我们引入了一种高效的力布局算法，将图嵌入低维空间，其中到原点的径向距离可作为各种中心性度量的代理。我们在多种图族上评估了我们的方法，并证明了其与度中心性、PageRank和基于路径的中心性之间存在强相关性。作为一项应用，所提出的嵌入允许在网络中找到高影响力节点，并为标准贪婪算法提供了一种快速且可扩展的替代方案。", "summary": "本文提出了一种快速几何嵌入方法，通过高效的力布局算法将大型图嵌入低维空间。该方法的径向距离可作为多种中心性度量的近似值，并被证明与度中心性、PageRank和基于路径的中心性高度相关。作为一项应用，该嵌入技术能够快速有效地识别网络中的高影响力节点，为传统的贪婪算法提供了一种可扩展且计算效率更高的替代方案。", "keywords": "几何嵌入, 节点影响力最大化, 中心性度量, 力布局, 可扩展性", "comments": "本文的创新之处在于利用几何嵌入的径向距离来近似图的中心性度量，并将其应用于节点影响力最大化问题。这种方法有效解决了传统中心性计算在大型图上的高计算成本问题，提供了一个快速且可扩展的解决方案，对于实际网络分析具有重要意义。"}}
{"id": "2506.06287", "title": "Deep Research Bench: Evaluating AI Web Research Agents", "authors": ["FutureSearch", ":", "Nikos I. Bosse", "Jon Evans", "Robert G. Gambee", "Daniel Hnyk", "Peter Mühlbacher", "Lawrence Phillips", "Dan Schwarz", "Jack Wildman"], "summary": "Amongst the most common use cases of modern AI is LLM chat with web search\nenabled. However, no direct evaluations of the quality of web research agents\nexist that control for the continually-changing web. We introduce Deep Research\nBench, consisting of 89 multi-step web research task instances of varying\ndifficulty across 8 diverse task categories, with the answers carefully worked\nout by skilled humans. We provide a \"RetroSearch\" environment with a large\nfrozen set of scraped web pages, and demonstrate that offline \"RetroSearch\"\nagents perform comparably to \"live web\" agents, enabling reliable evaluations\nof models over time. We provide robust agent tooling and scaffolding to\nbenchmark major LLMs as they are released, including \"thinking\" models like o3\nand Gemini 2.5 Pro. We include automated evaluations of the lengthy agent\ntraces to report progress over time in hallucinations, tool use, and\nforgetting. Finally, we evaluate the major web research products branded as\n\"Deep Research\", \"Deep Search\", \"Search\", or \"Research.\" Results are available\non a public leaderboard at https://drb.futuresearch.ai/.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06287v1", "AI": {"title_translation": "深度研究基准：评估AI网络研究代理", "tldr": "引入Deep Research Bench，一个用于评估AI网络研究代理的基准，通过“RetroSearch”环境解决网络不断变化的问题，并提供工具以进行可靠的长期评估。", "motivation": "现代AI最常见的用例之一是启用网络搜索的LLM聊天，但目前缺乏针对不断变化的网络进行控制的、直接评估网络研究代理质量的方法。", "method": "1. 引入Deep Research Bench，包含89个多步骤网络研究任务实例，涵盖8个任务类别，答案由人类精心整理。 2. 提供一个“RetroSearch”环境，包含大量冻结的抓取网页，并证明离线“RetroSearch”代理与“实时网络”代理表现相当。 3. 提供强大的代理工具和脚手架，用于基准测试主流LLM（如o3和Gemini 2.5 Pro）。 4. 包括对冗长代理轨迹的自动化评估，以报告幻觉、工具使用和遗忘的进展。 5. 评估了名为“Deep Research”、“Deep Search”、“Search”或“Research”的主流网络研究产品。", "result": "离线“RetroSearch”代理与“实时网络”代理表现相当，这使得模型能够进行可靠的长期评估。评估结果可在公共排行榜上获取。", "conclusion": "Deep Research Bench及其RetroSearch环境实现了对AI网络研究代理的可靠和可重复的评估，解决了网络动态变化带来的挑战，并促进了该领域模型性能的长期追踪和改进。", "translation": "现代AI最常见的用例之一是启用网络搜索的LLM聊天。然而，目前还没有直接评估网络研究代理质量的方法，以控制不断变化的网络。我们引入了Deep Research Bench，它包含89个多步骤网络研究任务实例，难度各异，涵盖8个不同的任务类别，答案由熟练的人类精心整理。我们提供了一个“RetroSearch”环境，其中包含大量冻结的抓取网页，并证明离线“RetroSearch”代理与“实时网络”代理表现相当，从而实现了模型随时间推移的可靠评估。我们提供强大的代理工具和脚手架，用于基准测试发布时的主流LLM，包括像o3和Gemini 2.5 Pro这样的“思考”模型。我们对冗长的代理轨迹进行自动化评估，以报告幻觉、工具使用和遗忘方面的进展。最后，我们评估了名为“Deep Research”、“Deep Search”、“Search”或“Research”的主流网络研究产品。结果可在公共排行榜 https://drb.futuresearch.ai/ 上获取。", "summary": "该论文介绍了Deep Research Bench，这是一个用于评估AI网络研究代理的新基准。为解决网络动态变化的挑战，该基准引入了“RetroSearch”环境，使用固定的网页数据集进行离线评估，并证明其结果与实时网络评估一致。Deep Research Bench包含89个多步骤研究任务，并提供了评估工具，能够对主流LLM（如o3和Gemini 2.5 Pro）在幻觉、工具使用和遗忘方面的表现进行自动化追踪。该研究旨在为AI网络研究产品提供一个可靠、可重复的评估框架，并已公开评估结果。", "keywords": "AI网络研究代理, 评估, 基准测试, RetroSearch, LLM", "comments": "这篇论文的创新之处在于引入了“RetroSearch”环境，通过冻结网页数据集解决了网络动态变化对AI网络研究代理评估的挑战，从而实现了可重复和可靠的长期基准测试。这对于追踪和改进AI在网络研究中的性能至关重要，特别是在幻觉、工具使用和遗忘等关键方面。其提出的Deep Research Bench为评估未来大型语言模型在复杂网络研究任务中的能力提供了宝贵的工具和方法。"}}
{"id": "2506.07019", "title": "Passive Detection in Multi-Static ISAC Systems: Performance Analysis and Joint Beamforming Optimization", "authors": ["Renjie He", "Yiqiu Wang", "Meixia Tao", "Shu Sun"], "summary": "This paper investigates the passive detection problem in multi-static\nintegrated sensing and communication (ISAC) systems, where multiple sensing\nreceivers (SRs) jointly detect a target using random unknown communication\nsignals transmitted by a collaborative base station. Unlike traditional active\ndetection, the considered passive detection does not require complete prior\nknowledge of the transmitted communication signals at each SR. First, we derive\na generalized likelihood ratio test detector and conduct an asymptotic analysis\nof the detection statistic under the large-sample regime. We examine how the\nsignal-to-noise ratios (SNRs) of the target paths and direct paths influence\nthe detection performance. Then, we propose two joint transmit beamforming\ndesigns based on the analyses. In the first design, the asymptotic detection\nprobability is maximized while satisfying the signal-to-interference-plus-noise\nratio requirement for each communication user under the total transmit power\nconstraint. Given the non-convex nature of the problem, we develop an\nalternating optimization algorithm based on the quadratic transform and\nsemi-definite relaxation. The second design adopts a heuristic approach that\naims to maximize the target energy, subject to a minimum SNR threshold on the\ndirect path, and offers lower computational complexity. Numerical results\nvalidate the asymptotic analysis and demonstrate the superiority of the\nproposed beamforming designs in balancing passive detection performance and\ncommunication quality. This work highlights the promise of target detection\nusing unknown communication data signals in multi-static ISAC systems.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07019v1", "AI": {"title_translation": "多基地ISAC系统中的无源探测：性能分析与联合波束赋形优化", "tldr": "本文研究了多基地ISAC系统中利用未知通信信号进行无源探测，并提出了两种联合波束赋形优化设计以平衡探测性能和通信质量。", "motivation": "传统有源探测需要完整的先验知识，而本文研究的无源探测不需要对通信信号有完整的先验知识，旨在解决这一限制并在多基地ISAC系统中实现目标探测。", "method": "首先，推导了广义似然比检验检测器，并进行了大样本状态下的渐近分析。然后，提出了两种联合发射波束赋形设计：第一种设计在满足通信用户信噪比要求和总发射功率约束下，最大化渐近检测概率，并采用基于二次变换和半正定松弛的交替优化算法解决其非凸性；第二种设计采用启发式方法，旨在最大化目标能量，同时满足直达路径的最小信噪比阈值，且计算复杂度较低。", "result": "数值结果验证了渐近分析的准确性，并表明所提出的波束赋形设计在平衡无源探测性能和通信质量方面具有优越性。", "conclusion": "这项工作突出了在多基地ISAC系统中利用未知通信数据信号进行目标探测的潜力。", "translation": "本文研究了多基地集成感知与通信（ISAC）系统中的无源探测问题，其中多个感知接收器（SRs）协同使用协作基站发送的随机未知通信信号来联合探测目标。与传统的有源探测不同，所考虑的无源探测不需要每个感知接收器对传输的通信信号有完整的先验知识。首先，我们推导了一个广义似然比检验检测器，并在大样本条件下对检测统计量进行了渐近分析。我们检查了目标路径和直达路径的信噪比（SNRs）如何影响检测性能。然后，我们基于这些分析提出了两种联合发射波束赋形设计。在第一种设计中，在总发射功率约束下，在满足每个通信用户的信噪比（SNR）要求的同时，最大化渐近检测概率。考虑到问题的非凸性，我们开发了一种基于二次变换和半正定松弛的交替优化算法。第二种设计采用启发式方法，旨在最大化目标能量，同时满足直达路径上的最小信噪比阈值，并提供较低的计算复杂度。数值结果验证了渐近分析，并证明了所提出的波束赋形设计在平衡无源探测性能和通信质量方面的优越性。这项工作突出了在多基地ISAC系统中利用未知通信数据信号进行目标探测的潜力。", "summary": "本文探讨了多基地ISAC系统中的无源探测问题，提出了一种无需通信信号完整先验知识的探测方法。研究推导了广义似然比检验检测器并进行了渐近分析，在此基础上提出了两种联合发射波束赋形优化设计。第一种设计通过交替优化算法最大化渐近检测概率，第二种设计通过启发式方法最大化目标能量。数值结果表明，所提出的波束赋形设计在平衡无源探测性能和通信质量方面表现出色，证实了利用未知通信信号进行目标探测的可行性。", "keywords": "无源探测, ISAC系统, 波束赋形, 广义似然比检验, 性能分析", "comments": "本文的创新点在于提出了在多基地ISAC系统中，利用未知通信信号进行无源目标探测的方法，这大大降低了对先验知识的需求。其提出的两种联合波束赋形优化设计，特别是第一种复杂的非凸优化问题的解决，展示了其在实际应用中的潜力，能够有效平衡感知和通信性能。这项工作为未来ISAC系统的发展提供了重要思路。"}}
{"id": "2506.06817", "title": "ASPO: Constraint-Aware Bayesian Optimization for FPGA-based Soft Processors", "authors": ["Haoran Wu", "Ce Guo", "Wayne Luk", "Robert Mullins"], "summary": "Bayesian Optimization (BO) has shown promise in tuning processor design\nparameters. However, standard BO does not support constraints involving\ncategorical parameters such as types of branch predictors and division\ncircuits. In addition, optimization time of BO grows with processor complexity,\nwhich becomes increasingly significant especially for FPGA-based soft\nprocessors. This paper introduces ASPO, an approach that leverages disjunctive\nform to enable BO to handle constraints involving categorical parameters.\nUnlike existing methods that directly apply standard BO, the proposed ASPO\nmethod, for the first time, customizes the mathematical mechanism of BO to\naddress challenges faced by soft-processor designs on FPGAs. Specifically, ASPO\nsupports categorical parameters using a novel customized BO covariance kernel.\nIt also accelerates the design evaluation procedure by penalizing the BO\nacquisition function with potential evaluation time and by reusing FPGA\nsynthesis checkpoints from previously evaluated configurations. ASPO targets\nthree soft processors: RocketChip, BOOM, and EL2 VeeR. The approach is\nevaluated based on seven RISC-V benchmarks. Results show that ASPO can reduce\nexecution time for the ``multiply'' benchmark on the BOOM processor by up to\n35\\% compared to the default configuration. Furthermore, it reduces design time\nfor the BOOM processor by up to 74\\% compared to Boomerang, a state-of-the-art\nhardware-oriented BO approach.", "comment": "Accepted to International Conference on Field-Programmable Logic and\n  Applications (FPL) 2025", "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.06817v1", "AI": {"title_translation": "ASPO：面向FPGA软处理器的约束感知贝叶斯优化", "tldr": "ASPO是一种定制的贝叶斯优化方法，专为FPGA软处理器设计，能处理分类约束并加速评估，显著提升执行和设计效率。", "motivation": "标准贝叶斯优化（BO）不擅长处理分类参数约束，且其优化时间随处理器复杂性增加而显著增长，尤其对于FPGA软处理器而言，这成为一个重要挑战。", "method": "ASPO通过利用析取形式和定制的BO协方差核来支持分类参数。它通过对BO采集函数施加潜在评估时间惩罚并重用先前评估配置的FPGA综合检查点来加速设计评估过程。该方法针对RocketChip、BOOM和EL2 VeeR三种软处理器，并基于七个RISC-V基准进行评估。", "result": "ASPO在BOOM处理器上，将“乘法”基准的执行时间比默认配置减少了高达35%。与最先进的面向硬件的BO方法Boomerang相比，它将BOOM处理器的设计时间减少了高达74%。", "conclusion": "ASPO通过处理分类约束和加速设计评估，有效解决了FPGA软处理器优化所面临的挑战，从而显著提升了性能和缩短了设计时间。", "translation": "贝叶斯优化（BO）在调整处理器设计参数方面已显示出潜力。然而，标准BO不支持涉及分类参数的约束，例如分支预测器和除法电路的类型。此外，BO的优化时间随处理器复杂性而增长，这对于基于FPGA的软处理器而言变得越来越重要。本文介绍了ASPO，一种利用析取形式使BO能够处理涉及分类参数的约束的方法。与直接应用标准BO的现有方法不同，所提出的ASPO方法首次定制了BO的数学机制，以解决FPGA上软处理器设计面临的挑战。具体来说，ASPO使用新颖的定制BO协方差核来支持分类参数。它还通过对BO采集函数施加潜在评估时间惩罚并重用先前评估配置的FPGA综合检查点来加速设计评估过程。ASPO针对三种软处理器：RocketChip、BOOM和EL2 VeeR。该方法基于七个RISC-V基准进行评估。结果表明，与默认配置相比，ASPO可以将BOOM处理器上“乘法”基准的执行时间缩短高达35%。此外，与最先进的面向硬件的BO方法Boomerang相比，它将BOOM处理器的设计时间缩短了高达74%。", "summary": "本文提出ASPO，一种针对FPGA软处理器的约束感知贝叶斯优化方法。ASPO通过定制的协方差核处理分类参数约束，并利用评估时间惩罚和综合检查点复用加速设计评估。实验结果表明，ASPO在BOOM处理器上显著减少了执行时间和设计时间，分别达到35%和74%的提升，优于现有方法。", "keywords": "贝叶斯优化, FPGA, 软处理器, 约束感知, 设计自动化", "comments": "ASPO的创新之处在于它首次为FPGA软处理器设计定制了贝叶斯优化的数学机制，特别是在处理分类参数和加速评估过程方面。这对于提高复杂硬件设计的自动化优化效率具有重要意义。"}}
{"id": "2506.06293", "title": "Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks", "authors": ["Junyi Liu", "Stanley Kok"], "summary": "Agencies such as Standard & Poor's and Moody's provide bank credit ratings\nthat influence economic stability and decision-making by stakeholders. Accurate\nand timely predictions support informed decision-making, regulatory actions,\nand investor protection. However, a complete interbank connection graph is\noften unavailable due to privacy concerns, complicating the direct application\nof Graph Neural Networks (GNNs) for rating prediction. our research utilizes\npersistent homology to construct a network that captures relationships among\nbanks and combines this with a traditional lending network to create a\nheterogeneous network that integrates information from both sources, leading to\nimproved predictions. Experiments on a global, real-world dataset validate the\neffectiveness of HTGNN. This research has implications for investors and\nregulatory bodies in enhancing proactive risk mitigation and the implementation\nof effective market interventions.The code can be find at\nhttps://github.com/Liu-Jun-Yi/HTGNN.", "comment": "WITS 2024 (Workshop on Information Technologies and Systems 2024)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06293v1", "AI": {"title_translation": "异构拓扑图神经网络在银行信用评级预测中的应用", "tldr": "本文提出了一种异构拓扑图神经网络（HTGNN）模型，通过结合持久同调构建的网络和传统借贷网络来预测银行信用评级，有效解决了银行间连接图数据缺失的问题。", "motivation": "银行信用评级对经济稳定和利益相关者决策至关重要。尽管图神经网络（GNNs）在预测方面有潜力，但由于隐私问题，完整的银行间连接图通常不可用，这阻碍了GNNs的直接应用。", "method": "研究利用持久同调构建了一个捕捉银行间关系的网络，并将其与传统借贷网络结合，创建了一个整合两类信息的异构网络，从而提升了预测能力。", "result": "在全球真实世界数据集上的实验验证了HTGNN的有效性。", "conclusion": "该研究对投资者和监管机构在加强主动风险缓解和实施有效市场干预方面具有重要意义。", "translation": "银行信用评级预测中的异构拓扑图神经网络\n\n标准普尔和穆迪等机构提供的银行信用评级影响着经济稳定和利益相关者的决策。准确及时的预测有助于明智的决策、监管行动和投资者保护。然而，由于隐私问题，完整的银行间连接图通常不可用，这使得图神经网络（GNNs）在评级预测中的直接应用变得复杂。我们的研究利用持久同调构建了一个捕捉银行间关系的网络，并将其与传统借贷网络结合，创建了一个整合两类信息的异构网络，从而提高了预测能力。在全球真实世界数据集上的实验验证了HTGNN的有效性。这项研究对于投资者和监管机构在加强主动风险缓解和实施有效市场干预方面具有重要意义。代码可在https://github.com/Liu-Jun-Yi/HTGNN 找到。", "summary": "本文提出了一种异构拓扑图神经网络（HTGNN）模型，用于解决银行信用评级预测中因隐私问题导致的银行间连接图数据缺失的挑战。该模型通过持久同调构建了一个捕捉银行间关系的网络，并将其与传统借贷网络融合，形成一个整合多源信息的异构网络。在全球真实数据集上的实验证明了HTGNN的有效性，为投资者和监管机构提供了更准确的风险评估工具。", "keywords": "银行信用评级, 异构图神经网络, 持久同调, 风险预测, 金融稳定", "comments": "本文的创新点在于提出了一种新颖的方法来处理银行间连接图数据缺失的问题，通过结合持久同调和传统借贷网络构建异构图，使得GNNs能够应用于此领域。这对于金融风险管理和市场监管具有重要的实践意义。"}}
{"id": "2506.06377", "title": "Evaluating Large Language Model Capabilities in Assessing Spatial Econometrics Research", "authors": ["Giuseppe Arbia", "Luca Morandini", "Vincenzo Nardelli"], "summary": "This paper investigates Large Language Models (LLMs) ability to assess the\neconomic soundness and theoretical consistency of empirical findings in spatial\neconometrics. We created original and deliberately altered \"counterfactual\"\nsummaries from 28 published papers (2005-2024), which were evaluated by a\ndiverse set of LLMs. The LLMs provided qualitative assessments and structured\nbinary classifications on variable choice, coefficient plausibility, and\npublication suitability. The results indicate that while LLMs can expertly\nassess the coherence of variable choices (with top models like GPT-4o achieving\nan overall F1 score of 0.87), their performance varies significantly when\nevaluating deeper aspects such as coefficient plausibility and overall\npublication suitability. The results further revealed that the choice of LLM,\nthe specific characteristics of the paper and the interaction between these two\nfactors significantly influence the accuracy of the assessment, particularly\nfor nuanced judgments. These findings highlight LLMs' current strengths in\nassisting with initial, more surface-level checks and their limitations in\nperforming comprehensive, deep economic reasoning, suggesting a potential\nassistive role in peer review that still necessitates robust human oversight.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06377v1", "AI": {"title_translation": "评估大型语言模型在空间计量经济学研究评估中的能力", "tldr": "本研究评估了大型语言模型（LLMs）在评估空间计量经济学研究中的表现，发现它们擅长初步的表面检查，但在深入的经济推理方面存在局限性，表明其在同行评审中可作为辅助工具，但仍需人类监督。", "motivation": "本研究旨在调查大型语言模型（LLMs）评估空间计量经济学实证研究的经济合理性和理论一致性的能力。", "method": "研究团队从28篇已发表论文（2005-2024年）中创建了原始和故意修改的“反事实”摘要，并由不同的大型语言模型进行评估。LLMs提供了定性评估，并对变量选择、系数合理性和出版适宜性进行了结构化的二元分类。", "result": "结果表明，LLMs在评估变量选择的一致性方面表现出色（GPT-4o的F1分数达到0.87），但在评估系数合理性和整体出版适宜性等更深层次方面时，其表现差异显著。此外，LLM的选择、论文的具体特征以及两者之间的相互作用显著影响评估的准确性，尤其是在进行细致判断时。", "conclusion": "研究结果突出了LLMs在辅助进行初步、表面层次检查方面的当前优势，以及它们在执行全面、深入经济推理方面的局限性，这表明LLMs在同行评审中具有潜在的辅助作用，但仍需要强大的人工监督。", "translation": "本文研究了大型语言模型（LLMs）评估空间计量经济学实证研究中经济合理性和理论一致性的能力。我们从28篇已发表论文（2005-2024年）中创建了原始和故意修改的“反事实”摘要，并由不同的大型语言模型进行评估。LLMs提供了定性评估，并对变量选择、系数合理性和出版适宜性进行了结构化的二元分类。结果表明，虽然LLMs可以熟练评估变量选择的一致性（GPT-4o等顶级模型总体F1分数达到0.87），但它们在评估系数合理性和整体出版适宜性等更深层次方面时，表现差异显著。结果进一步揭示，LLM的选择、论文的具体特征以及两者之间的相互作用显著影响评估的准确性，尤其是在进行细致判断时。这些发现突出了LLMs在协助进行初步、表面层次检查方面的当前优势，以及它们在执行全面、深入经济推理方面的局限性，这表明它们在同行评审中具有潜在的辅助作用，但仍需要强大的人工监督。", "summary": "本研究评估了大型语言模型（LLMs）在评估空间计量经济学实证研究的经济合理性和理论一致性方面的能力。通过让LLMs评估28篇论文的原始和修改摘要，研究发现LLMs在变量选择的一致性评估上表现良好，但在更深层次的经济推理方面存在局限性。研究强调LLMs可作为同行评审的辅助工具，但需人类监督。", "keywords": "大型语言模型, 空间计量经济学, 同行评审, 经济推理, 评估", "comments": "该论文创新性地探讨了LLMs在专业领域（空间计量经济学）评估中的应用潜力，揭示了其在表面检查方面的优势和深层推理的局限性。这对于理解LLMs在复杂学术工作中的角色及其未来发展方向具有重要意义，尤其是在自动化同行评审的背景下。"}}
{"id": "2506.07159", "title": "pFedSOP : Accelerating Training Of Personalized Federated Learning Using Second-Order Optimization", "authors": ["Mrinmay Sen", "Chalavadi Krishna Mohan"], "summary": "Personalized Federated Learning (PFL) enables clients to collaboratively\ntrain personalized models tailored to their individual objectives, addressing\nthe challenge of model generalization in traditional Federated Learning (FL)\ndue to high data heterogeneity. However, existing PFL methods often require\nincreased communication rounds to achieve the desired performance, primarily\ndue to slow training caused by the use of first-order optimization, which has\nlinear convergence. Additionally, many of these methods increase local\ncomputation because of the additional data fed into the model during the search\nfor personalized local models. One promising solution to this slow training is\nsecond-order optimization, known for its quadratic convergence. However,\nemploying it in PFL is challenging due to the Hessian matrix and its inverse.\nIn this paper, we propose pFedSOP, which efficiently utilizes second-order\noptimization in PFL to accelerate the training of personalized models and\nenhance performance with fewer communication rounds. Our approach first\ncomputes a personalized local gradient update using the Gompertz function-based\nnormalized angle between local and global gradient updates, incorporating\nclient-specific global information. We then use a regularized Fisher\nInformation Matrix (FIM), computed from this personalized gradient update, as\nan approximation of the Hessian to update the personalized models. This\nFIM-based second-order optimization speeds up training with fewer communication\nrounds by tackling the challenges with exact Hessian and avoids additional data\nbeing fed into the model during the search for personalized local models.\nExtensive experiments on heterogeneously partitioned image classification\ndatasets with partial client participation demonstrate that pFedSOP outperforms\nstate-of-the-art FL and PFL algorithms.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.07159v1", "AI": {"title_translation": "pFedSOP：使用二阶优化加速个性化联邦学习的训练", "tldr": "pFedSOP提出了一种利用二阶优化加速个性化联邦学习训练的方法，通过近似Hessian矩阵并减少通信轮次，在异构数据集上表现优于现有算法。", "motivation": "现有个性化联邦学习（PFL）方法存在通信轮次多、训练速度慢（由于一阶优化）以及局部计算量大等问题。二阶优化虽然具有二次收敛性，但其在PFL中的应用因Hessian矩阵及其逆的挑战而受限。", "method": "本文提出了pFedSOP，它首先使用基于Gompertz函数的局部与全局梯度更新之间的归一化角度计算个性化局部梯度更新，融入客户端特有的全局信息。然后，利用从该个性化梯度更新计算得到的正则化Fisher信息矩阵（FIM）作为Hessian的近似来更新个性化模型。", "result": "在异构分区图像分类数据集上进行的部分客户端参与的广泛实验表明，pFedSOP优于最先进的联邦学习（FL）和个性化联邦学习（PFL）算法。", "conclusion": "pFedSOP通过有效利用近似二阶优化，成功解决了现有PFL方法训练速度慢和通信轮次多的问题，显著提升了PFL的性能和效率。", "translation": "个性化联邦学习（PFL）使客户端能够协同训练针对其个体目标量身定制的个性化模型，解决了传统联邦学习（FL）中因数据高度异构性导致的模型泛化挑战。然而，现有的PFL方法通常需要增加通信轮次才能达到期望的性能，这主要是由于使用线性收敛的一阶优化导致训练缓慢。此外，许多这些方法在搜索个性化局部模型期间，由于额外数据被送入模型，增加了局部计算量。解决这种缓慢训练的一个有前景的解决方案是二阶优化，它以其二次收敛性而闻名。然而，由于Hessian矩阵及其逆的挑战，将其应用于PFL具有挑战性。在本文中，我们提出了pFedSOP，它有效地在PFL中利用二阶优化，以加速个性化模型的训练并以更少的通信轮次提高性能。我们的方法首先使用基于Gompertz函数的局部和全局梯度更新之间的归一化角度计算个性化局部梯度更新，其中包含客户端特定的全局信息。然后，我们使用从该个性化梯度更新计算得到的正则化Fisher信息矩阵（FIM）作为Hessian的近似来更新个性化模型。这种基于FIM的二阶优化通过解决精确Hessian的挑战，以更少的通信轮次加速训练，并避免在搜索个性化局部模型期间将额外数据送入模型。在具有部分客户端参与的异构分区图像分类数据集上的广泛实验表明，pFedSOP优于最先进的FL和PFL算法。", "summary": "该论文提出了pFedSOP，一种加速个性化联邦学习（PFL）训练的方法。它通过高效地利用二阶优化，克服了传统PFL中一阶优化导致的训练缓慢和通信开销大的问题。pFedSOP通过计算个性化局部梯度更新并使用正则化Fisher信息矩阵（FIM）作为Hessian的近似来更新模型。实验证明，pFedSOP在异构数据集上优于现有FL和PFL算法，减少了通信轮次并提高了性能。", "keywords": "个性化联邦学习, 二阶优化, Fisher信息矩阵, 通信效率, 梯度更新", "comments": "pFedSOP的创新之处在于其在个性化联邦学习中成功且高效地引入了二阶优化，巧妙地通过Fisher信息矩阵近似Hessian矩阵，解决了直接使用Hessian的计算难题。这对于提升PFL的训练效率和性能具有重要意义，尤其是在数据高度异构的环境下。该方法不仅加速了训练，还减少了通信轮次，是联邦学习领域的一个重要进展。"}}
{"id": "2506.07715", "title": "Delay Optimization in Remote ID-Based UAV Communication via BLE and Wi-Fi Switching", "authors": ["Yian Zhu", "Ziye Jia", "Lei Zhang", "Yao Wu", "Qiuming Zhu", "Qihui Wu"], "summary": "The remote identification (Remote ID) broadcast capability allows unmanned\naerial vehicles (UAVs) to exchange messages, which is a pivotal technology for\ninter-UAV communications. Although this capability enhances the operational\nvisibility, low delay in Remote ID-based communications is critical for\nensuring the efficiency and timeliness of multi-UAV operations in dynamic\nenvironments. To address this challenge, we first establish delay models for\nRemote ID communications by considering packet reception and collisions across\nboth BLE 4 and Wi-Fi protocols. Building upon these models, we formulate an\noptimization problem to minimize the long-term communication delay through\nadaptive protocol selection. Since the delay performance varies with the UAV\ndensity, we propose an adaptive BLE/Wi-Fi switching algorithm based on the\nmulti-agent deep Q-network approach. Experimental results demonstrate that in\ndynamic-density scenarios, our strategy achieves 32.1% and 37.7% lower latency\ncompared to static BLE 4 and Wi-Fi modes respectively.", "comment": null, "cate": "cs.NI", "url": "http://arxiv.org/abs/2506.07715v1", "AI": {"title_translation": "基于远程ID的无人机通信中BLE和Wi-Fi切换的延迟优化", "tldr": "本文提出一种基于多智能体深度Q网络（MADQN）的自适应BLE/Wi-Fi切换算法，以最小化远程ID无人机通信中的延迟，在动态密度场景下显著降低了延迟。", "motivation": "远程识别（Remote ID）广播能力对无人机间通信至关重要，但动态环境中多无人机操作的效率和及时性要求远程ID通信具有低延迟。", "method": "首先，建立了考虑BLE 4和Wi-Fi协议下数据包接收和碰撞的远程ID通信延迟模型。然后，基于这些模型，提出了一个优化问题来最小化长期通信延迟，并通过自适应协议选择实现。最后，提出了一种基于多智能体深度Q网络（MADQN）的自适应BLE/Wi-Fi切换算法来应对无人机密度变化。", "result": "在动态密度场景下，与静态BLE 4模式相比，该策略实现了32.1%的低延迟；与静态Wi-Fi模式相比，实现了37.7%的低延迟。", "conclusion": "通过建立延迟模型和采用基于多智能体深度Q网络的自适应BLE/Wi-Fi切换算法，可以有效降低远程ID无人机通信的延迟，尤其是在动态无人机密度场景下，从而提高通信效率和及时性。", "translation": "远程识别（Remote ID）广播能力允许无人机（UAV）交换消息，这是无人机间通信的关键技术。尽管此能力增强了操作可见性，但在动态环境中，基于远程ID的通信中的低延迟对于确保多无人机操作的效率和及时性至关重要。为了解决这一挑战，我们首先通过考虑BLE 4和Wi-Fi协议下的数据包接收和碰撞，建立了远程ID通信的延迟模型。基于这些模型，我们提出了一个优化问题，旨在通过自适应协议选择来最小化长期通信延迟。由于延迟性能随无人机密度的变化而变化，我们提出了一种基于多智能体深度Q网络方法的自适应BLE/Wi-Fi切换算法。实验结果表明，在动态密度场景下，我们的策略与静态BLE 4和Wi-Fi模式相比，分别实现了32.1%和37.7%的更低延迟。", "summary": "本文研究了远程ID无人机通信中的延迟优化问题，认为低延迟对于动态环境下的多无人机操作至关重要。作者建立了BLE 4和Wi-Fi协议下的远程ID通信延迟模型，并将其建模为一个最小化长期通信延迟的优化问题。为应对无人机密度变化，提出了一种基于多智能体深度Q网络（MADQN）的自适应BLE/Wi-Fi切换算法。实验结果表明，该算法在动态密度场景下，相较于静态BLE 4和Wi-Fi模式，分别将延迟降低了32.1%和37.7%。", "keywords": "远程ID, 无人机通信, 延迟优化, BLE/Wi-Fi切换, 深度Q网络", "comments": "这篇论文通过引入自适应BLE/Wi-Fi切换策略，并结合深度Q网络来应对动态无人机密度下的延迟问题，具有较强的创新性。其提出的延迟模型和优化问题为远程ID通信的性能提升提供了理论基础，实验结果也验证了该方法的有效性，对提升无人机间通信的效率和可靠性具有重要意义。"}}
{"id": "2506.06335", "title": "FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models", "authors": ["Xuan Xu", "Fufang Wen", "Beilin Chu", "Zhibing Fu", "Qinhong Lin", "Jiaqi Liu", "Binjie Fei", "Zhongliang Yang", "Linna Zhou", "Yu Li"], "summary": "In natural language processing (NLP), the focus has shifted from encoder-only\ntiny language models like BERT to decoder-only large language models(LLMs) such\nas GPT-3. However, LLMs' practical application in the financial sector has\nrevealed three limitations: (1) LLMs often perform worse than fine-tuned BERT\non discriminative tasks despite costing much higher computational resources,\nsuch as market sentiment analysis in financial reports; (2) Application on\ngenerative tasks heavily relies on retrieval augmented generation (RAG) methods\nto provide current and specialized information, with general retrievers showing\nsuboptimal performance on domain-specific retrieval tasks; (3) There are\nadditional inadequacies in other feature-based scenarios, such as topic\nmodeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained\non a high-quality, financial-specific corpus of 32b tokens. This represents the\nlargest known Chinese financial pretraining corpus for models of this parameter\nsize. As a better backbone, FinBERT2 can bridge the gap in the\nfinancial-specific deployment of LLMs through the following achievements: (1)\nDiscriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT\nvariants by 0.4%-3.3% and leading LLMs by 9.7%-12.3% on average across five\nfinancial classification tasks. (2) Contrastive fine-tuned models\n(Fin-Retrievers) outperform both open-source (e.g., +6.8\\% avg improvement over\nBGE-base-zh) and proprietary (e.g., +4.2\\% avg improvement over OpenAI's\ntext-embedding-3-large) embedders across five financial retrieval tasks; (3)\nBuilding on FinBERT2 variants, we construct the Fin-TopicModel, which enables\nsuperior clustering and topic representation for financial titles. Our work\nrevisits financial BERT models through comparative analysis with contemporary\nLLMs and offers practical insights for effectively utilizing FinBERT in the\nLLMs era.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06335v1", "AI": {"title_translation": "FinBERT2：一种专门的双向编码器，旨在弥合大型语言模型在金融领域部署中的差距", "tldr": "FinBERT2是一个专门的金融领域双向编码器，它通过在大型金融语料库上预训练，显著提升了大型语言模型在金融判别、检索和主题建模任务上的性能，弥补了现有LLM在该领域的不足。", "motivation": "大型语言模型（LLMs）在自然语言处理中占据主导地位，但在金融领域的实际应用中面临三大限制：(1) 在判别性任务上（如市场情绪分析）性能不如微调过的BERT且计算成本高；(2) 在生成性任务中依赖RAG方法，但通用检索器在领域特定检索任务上表现不佳；(3) 在主题建模等其他基于特征的场景中存在不足。", "method": "本文提出了FinBERT2，一个专门的双向编码器，它在一个包含320亿token的高质量金融特定语料库上进行了预训练。这是已知该参数规模模型中最大的中文金融预训练语料库。FinBERT2被用作一个更优的骨干模型。", "result": "1. 判别性微调模型（Fin-Labelers）在五项金融分类任务中，平均性能优于其他（Fin）BERT变体0.4%-3.3%，优于领先的LLM 9.7%-12.3%。\n2. 对比性微调模型（Fin-Retrievers）在五项金融检索任务中，平均性能优于开源嵌入器（如BGE-base-zh，提高6.8%）和专有嵌入器（如OpenAI的text-embedding-3-large，提高4.2%）。\n3. 基于FinBERT2变体构建的Fin-TopicModel，为金融标题提供了卓越的聚类和主题表示能力。", "conclusion": "这项工作通过与当代大型语言模型的比较分析，重新审视了金融BERT模型，并为在LLM时代有效利用FinBERT提供了实用的见解。", "translation": "在自然语言处理（NLP）中，焦点已从BERT等仅编码器的小型语言模型转向GPT-3等仅解码器的大型语言模型（LLMs）。然而，LLMs在金融领域的实际应用暴露出三个局限性：(1) 尽管计算资源成本高昂，LLMs在判别性任务（例如金融报告中的市场情绪分析）上的表现通常不如微调过的BERT；(2) 生成性任务的应用严重依赖于检索增强生成（RAG）方法来提供当前和专业信息，而通用检索器在领域特定检索任务上表现不佳；(3) 在其他基于特征的场景（如主题建模）中存在额外不足。我们介绍了FinBERT2，一个专门的双向编码器，它在一个包含320亿token的高质量金融特定语料库上进行了预训练。这是已知该参数规模模型中最大的中文金融预训练语料库。作为更好的骨干模型，FinBERT2可以通过以下成就弥合LLMs在金融领域部署中的差距：(1) 判别性微调模型（Fin-Labelers）在五项金融分类任务中，平均性能优于其他（Fin）BERT变体0.4%-3.3%，优于领先的LLMs 9.7%-12.3%。(2) 对比性微调模型（Fin-Retrievers）在五项金融检索任务中，表现优于开源（例如，比BGE-base-zh平均提高6.8%）和专有（例如，比OpenAI的text-embedding-3-large平均提高4.2%）嵌入器；(3) 基于FinBERT2变体，我们构建了Fin-TopicModel，它能够为金融标题提供卓越的聚类和主题表示。我们的工作通过与当代LLMs的比较分析，重新审视了金融BERT模型，并为在LLM时代有效利用FinBERT提供了实用的见解。", "summary": "该论文提出了FinBERT2，一个专门针对金融领域训练的双向编码器，旨在解决当前大型语言模型（LLMs）在金融应用中面临的性能和效率问题。通过在一个大规模高质量中文金融语料库上预训练，FinBERT2在多项金融分类、检索和主题建模任务上显著超越了现有BERT变体和领先的LLMs，证明了其作为金融领域LLM骨干模型的优越性，并为该领域的实际部署提供了有效途径。", "keywords": "FinBERT2, 金融NLP, 双向编码器, 领域适应, 大型语言模型", "comments": "这项工作非常重要，因为它直接解决了LLMs在特定领域（金融）部署中的实际痛点。通过开发一个领域特定的双向编码器（FinBERT2），作者证明了在某些任务上，经过精心设计的专业化小型模型仍能超越通用大型模型，尤其是在成本和效率方面。FinBERT2在中文金融语料上的大规模预训练，使其在中文金融NLP领域具有显著的应用价值。这项研究为在特定垂直领域中如何有效地利用和改进AI模型提供了新的视角，即并非所有任务都需要最大的LLM，有时领域优化的编码器可能是更优解。"}}
{"id": "2506.06572", "title": "Cyber Security of Sensor Systems for State Sequence Estimation: an AI Approach", "authors": ["Xubin Fang", "Rick S. Blum", "Ramesh Bharadwaj", "Brian M. Sadler"], "summary": "Sensor systems are extremely popular today and vulnerable to sensor data\nattacks. Due to possible devastating consequences, counteracting sensor data\nattacks is an extremely important topic, which has not seen sufficient study.\nThis paper develops the first methods that accurately identify/eliminate only\nthe problematic attacked sensor data presented to a sequence\nestimation/regression algorithm under a powerful attack model constructed based\non known/observed attacks. The approach does not assume a known form for the\nstatistical model of the sensor data, allowing data-driven and machine learning\nsequence estimation/regression algorithms to be protected. A simple protection\napproach for attackers not endowed with knowledge of the details of our\nprotection approach is first developed, followed by additional processing for\nattacks based on protection system knowledge. In the cases tested for which it\nwas designed, experimental results show that the simple approach achieves\nperformance indistinguishable, to two decimal places, from that for an approach\nwhich knows which sensors are attacked. For cases where the attacker has\nknowledge of the protection approach, experimental results indicate the\nadditional processing can be configured so that the worst-case degradation\nunder the additional processing and a large number of sensors attacked can be\nmade significantly smaller than the worst-case degradation of the simple\napproach, and close to an approach which knows which sensors are attacked, for\nthe same number of attacked sensors with just a slight degradation under no\nattacks. Mathematical descriptions of the worst-case attacks are used to\ndemonstrate the additional processing will provide similar advantages for cases\nfor which we do not have numerical results. All the data-driven processing used\nin our approaches employ only unattacked training data.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06572v1", "AI": {"title_translation": "用于状态序列估计的传感器系统网络安全：一种AI方法", "tldr": "本文开发了首个能够识别和消除传感器系统受攻击数据的方法，以保护序列估计/回归算法，即使在强大的攻击模型下也能表现良好。", "motivation": "传感器系统易受数据攻击，可能导致灾难性后果，但目前对传感器数据攻击的对策研究不足。", "method": "本文开发了识别和消除受攻击传感器数据的方法，用于保护序列估计/回归算法。该方法构建了基于已知/观察到的强大攻击模型，且不假设传感器数据的统计模型形式，从而支持数据驱动和机器学习算法。论文提出了两种保护策略：一种针对不了解保护细节的攻击者（简单方法），另一种针对了解保护系统知识的攻击者（附加处理）。所有数据驱动处理仅使用未受攻击的训练数据。", "result": "实验结果表明，简单方法在设计测试案例中，性能与已知哪些传感器被攻击的方法几乎没有区别。当攻击者了解保护方法时，附加处理能够显著降低最坏情况下的性能下降，使其接近已知哪些传感器被攻击的方法，且在无攻击情况下仅有轻微下降。数学描述的最坏情况攻击也表明附加处理在没有数值结果的情况下也能提供类似优势。", "conclusion": "本文成功开发了识别和消除传感器数据攻击的方法，显著提高了传感器系统在强大攻击下的网络安全性，尤其是在攻击者了解保护机制的情况下，附加处理表现出优越性。", "translation": "传感器系统在当今非常流行，但容易受到传感器数据攻击。由于可能造成毁灭性后果，对抗传感器数据攻击是一个极其重要但尚未得到充分研究的课题。本文开发了首批能够准确识别/消除在基于已知/观察到的攻击构建的强大攻击模型下呈现给序列估计/回归算法的受攻击传感器数据的 problematic 部分的方法。该方法不假设传感器数据的统计模型形式，从而允许保护数据驱动和机器学习序列估计/回归算法。首先开发了一种针对不了解我们保护方法细节的攻击者的简单保护方法，然后是针对基于保护系统知识的攻击的附加处理。在为之设计的测试案例中，实验结果表明，简单方法在性能上与已知哪些传感器受到攻击的方法几乎没有区别（精确到小数点后两位）。对于攻击者了解保护方法的情况，实验结果表明，可以配置附加处理，使得在附加处理和大量传感器受攻击下的最坏情况性能下降显著小于简单方法的最坏情况性能下降，并且在相同数量的受攻击传感器下接近已知哪些传感器受攻击的方法，而在没有攻击的情况下只有轻微的性能下降。最坏情况攻击的数学描述被用来证明附加处理将在我们没有数值结果的案例中提供类似的优势。我们方法中使用的所有数据驱动处理都只使用未受攻击的训练数据。", "summary": "本文针对传感器系统易受数据攻击的问题，提出了一种AI驱动的新方法，用于识别和消除序列估计/回归算法中的受攻击传感器数据。该方法不依赖于统计模型假设，并开发了两种策略：一种针对不了解保护细节的攻击者，另一种通过附加处理应对了解保护机制的攻击者。实验结果表明，这些方法在强大攻击模型下表现出色，显著提高了传感器系统的网络安全性。", "keywords": "传感器系统安全, 数据攻击, 序列估计, 机器学习, 网络安全", "comments": "这篇论文的创新点在于它是首个专门针对传感器数据攻击中识别和消除问题数据的方法，且不依赖于数据统计模型。其提出的两阶段保护策略，特别是应对了解保护机制的攻击者的附加处理，展示了其在实际应用中的鲁棒性。这对于提高关键基础设施中传感器系统的网络安全至关重要。"}}
{"id": "2506.07398", "title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "authors": ["Guibin Zhang", "Muxin Fu", "Guancheng Wan", "Miao Yu", "Kun Wang", "Shuicheng Yan"], "summary": "Large language model (LLM)-powered multi-agent systems (MAS) have\ndemonstrated cognitive and execution capabilities that far exceed those of\nsingle LLM agents, yet their capacity for self-evolution remains hampered by\nunderdeveloped memory architectures. Upon close inspection, we are alarmed to\ndiscover that prevailing MAS memory mechanisms (1) are overly simplistic,\ncompletely disregarding the nuanced inter-agent collaboration trajectories, and\n(2) lack cross-trial and agent-specific customization, in stark contrast to the\nexpressive memory developed for single agents. To bridge this gap, we introduce\nG-Memory, a hierarchical, agentic memory system for MAS inspired by\norganizational memory theory, which manages the lengthy MAS interaction via a\nthree-tier graph hierarchy: insight, query, and interaction graphs. Upon\nreceiving a new user query, G-Memory performs bi-directional memory traversal\nto retrieve both $\\textit{high-level, generalizable insights}$ that enable the\nsystem to leverage cross-trial knowledge, and $\\textit{fine-grained, condensed\ninteraction trajectories}$ that compactly encode prior collaboration\nexperiences. Upon task execution, the entire hierarchy evolves by assimilating\nnew collaborative trajectories, nurturing the progressive evolution of agent\nteams. Extensive experiments across five benchmarks, three LLM backbones, and\nthree popular MAS frameworks demonstrate that G-Memory improves success rates\nin embodied action and accuracy in knowledge QA by up to $20.89\\%$ and\n$10.12\\%$, respectively, without any modifications to the original frameworks.\nOur codes are available at https://github.com/bingreeky/GMemory.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.07398v1", "AI": {"title_translation": "G-Memory：追溯多智能体系统的分层记忆", "tldr": "G-Memory引入了一种分层、智能体化的记忆系统，通过管理洞察、查询和交互图的三层图层次结构来改进多智能体系统的记忆能力，显著提高了任务成功率和知识问答准确性。", "motivation": "当前大语言模型驱动的多智能体系统（MAS）的自我演化能力受到未充分发展的记忆架构的阻碍。现有的MAS记忆机制过于简单，忽视了细致的智能体间协作轨迹，并且缺乏跨试验和智能体特定的定制，这与为单个智能体开发的富有表现力的记忆形成鲜明对比。", "method": "G-Memory是一个受组织记忆理论启发的分层、智能体化记忆系统。它通过一个三层图层次结构（洞察图、查询图和交互图）来管理MAS的冗长交互。当接收到新的用户查询时，G-Memory执行双向记忆遍历，以检索高级的、可泛化的洞察和细粒度的、浓缩的交互轨迹。在任务执行后，整个层次结构通过吸收新的协作轨迹而演化。", "result": "G-Memory在五个基准测试、三个LLM骨干和三个流行的MAS框架中进行了广泛实验，结果显示，它在具身动作中的成功率提高了20.89%，在知识问答中的准确性提高了10.12%，且无需修改原始框架。", "conclusion": "G-Memory通过引入分层、智能体化的记忆系统，有效解决了现有MAS记忆架构的不足，显著提升了多智能体系统的认知和执行能力，尤其是在跨试验知识利用和协作经验编码方面。", "translation": "大语言模型（LLM）驱动的多智能体系统（MAS）展现出远超单一LLM智能体的认知和执行能力，但其自我演化能力仍受限于不完善的记忆架构。经仔细检查，我们惊觉现有MAS记忆机制（1）过于简单，完全忽视了细致的智能体间协作轨迹，以及（2）缺乏跨试验和智能体特定的定制，这与为单一智能体开发的富有表现力的记忆形成鲜明对比。为了弥补这一差距，我们引入了G-Memory，一个受组织记忆理论启发的分层、智能体化MAS记忆系统，它通过三层图层次结构：洞察图、查询图和交互图来管理冗长的MAS交互。当接收到新的用户查询时，G-Memory执行双向记忆遍历，以检索高级的、可泛化的洞察（使系统能够利用跨试验知识）和细粒度的、浓缩的交互轨迹（紧凑编码先前的协作经验）。在任务执行后，整个层次结构通过吸收新的协作轨迹而演化，促进智能体团队的逐步演化。在五个基准测试、三个LLM骨干和三个流行的MAS框架中进行的广泛实验表明，G-Memory在不修改原始框架的情况下，分别将具身动作的成功率提高了20.89%，知识问答的准确性提高了10.12%。我们的代码可在https://github.com/bingreeky/GMemory获取。", "summary": "本文提出G-Memory，一个受组织记忆理论启发的分层、智能体化记忆系统，旨在弥补大语言模型驱动的多智能体系统（MAS）在记忆架构上的不足。针对现有MAS记忆机制过于简单且缺乏定制化的问题，G-Memory通过管理洞察、查询和交互图的三层图层次结构来处理MAS的复杂交互。它能够双向检索高级泛化洞察和细粒度交互轨迹，并在任务执行后通过吸收新的协作经验进行演化。实验结果表明，G-Memory在多个基准测试中显著提升了具身动作的成功率和知识问答的准确性。", "keywords": "多智能体系统, 分层记忆, 大语言模型, 组织记忆理论, G-Memory", "comments": "G-Memory的创新之处在于其分层、智能体化的记忆架构，这有效地解决了多智能体系统在复杂协作和跨试验知识利用方面的记忆短板。将组织记忆理论引入MAS记忆设计，提供了一个新颖且有效的视角。其在不修改现有框架的情况下取得显著性能提升，证明了该方法的普适性和实用性。这对于推动MAS的自我演化能力具有重要意义。"}}
{"id": "2506.06476", "title": "Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception", "authors": ["Pushyami Kaveti", "Ambjorn Grimsrud Waldum", "Hanumant Singh", "Martin Ludvigsen"], "summary": "Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs)\ndemand robust spatial perception capabilities, including Simultaneous\nLocalization and Mapping (SLAM), to support both remote and autonomous tasks.\nVision-based systems have been integral to these advancements, capturing rich\ncolor and texture at low cost while enabling semantic scene understanding.\nHowever, underwater conditions -- such as light attenuation, backscatter, and\nlow contrast -- often degrade image quality to the point where traditional\nvision-based SLAM pipelines fail. Moreover, these pipelines typically rely on\nmonocular or stereo inputs, limiting their scalability to the multi-camera\nconfigurations common on many vehicles. To address these issues, we propose to\nleverage multi-modal sensing that fuses data from multiple sensors-including\ncameras, inertial measurement units (IMUs), and acoustic devices-to enhance\nsituational awareness and enable robust, real-time SLAM. We explore both\ngeometric and learning-based techniques along with semantic analysis, and\nconduct experiments on the data collected from a work-class ROV during several\nfield deployments in the Trondheim Fjord. Through our experimental results, we\ndemonstrate the feasibility of real-time reliable state estimation and\nhigh-quality 3D reconstructions in visually challenging underwater conditions.\nWe also discuss system constraints and identify open research questions, such\nas sensor calibration, limitations with learning-based methods, that merit\nfurther exploration to advance large-scale underwater operations.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06476v1", "AI": {"title_translation": "增强水下机器人多模态空间感知态势感知能力", "tldr": "本文提出了一种多模态融合感知方法，结合相机、IMU和声学设备，以实现在恶劣水下条件下鲁棒、实时的SLAM，提高水下机器人的态势感知能力。", "motivation": "自主水下航行器（AUVs）和遥控潜水器（ROVs）需要强大的空间感知能力（包括SLAM）来支持远程和自主任务。尽管基于视觉的系统成本低廉且能提供丰富的语义信息，但水下环境（如光衰减、反向散射和低对比度）会严重降低图像质量，导致传统视觉SLAM管道失效。此外，这些管道通常依赖单目或立体输入，限制了其在多摄像头配置车辆上的可扩展性。", "method": "提出利用多模态传感，融合来自多个传感器（包括相机、惯性测量单元（IMU）和声学设备）的数据，以增强态势感知并实现鲁棒、实时的SLAM。研究了几何和基于学习的技术以及语义分析。", "result": "通过在特隆赫姆峡湾的几次实地部署中从工作级ROV收集的数据进行的实验表明，在视觉挑战性的水下条件下，实时可靠的状态估计和高质量的3D重建是可行的。", "conclusion": "在视觉挑战性的水下条件下，多模态融合感知可以实现实时可靠的状态估计和高质量的3D重建。研究还讨论了系统约束并指出了开放的研究问题，如传感器校准和基于学习方法的局限性，这些问题需要进一步探索以推进大规模水下作业。", "translation": "自主水下航行器（AUVs）和遥控潜水器（ROVs）需要强大的空间感知能力，包括同步定位与建图（SLAM），以支持远程和自主任务。基于视觉的系统在这些进步中不可或缺，它们能以低成本捕获丰富的颜色和纹理，并实现语义场景理解。然而，水下条件——例如光衰减、反向散射和低对比度——经常会降低图像质量，以至于传统的基于视觉的SLAM管道失效。此外，这些管道通常依赖单目或立体输入，限制了它们对许多车辆上常见的多摄像头配置的可扩展性。为了解决这些问题，我们提出利用多模态传感，融合来自多个传感器（包括相机、惯性测量单元（IMU）和声学设备）的数据，以增强态势感知并实现鲁棒、实时的SLAM。我们探索了几何和基于学习的技术以及语义分析，并对在特隆赫姆峡湾几次实地部署中从工作级ROV收集的数据进行了实验。通过我们的实验结果，我们证明了在视觉挑战性的水下条件下，实时可靠的状态估计和高质量的3D重建是可行的。我们还讨论了系统约束并指出了开放的研究问题，例如传感器校准、基于学习方法的局限性，这些问题需要进一步探索以推进大规模水下作业。", "summary": "本文针对水下机器人（AUV和ROV）在恶劣水下环境中传统视觉SLAM失效的问题，提出了一种多模态感知融合方案。该方案融合了相机、IMU和声学设备的数据，旨在增强水下机器人的态势感知能力，并实现鲁棒、实时的同步定位与建图（SLAM）。研究探索了几何和基于学习的技术以及语义分析，并通过在特隆赫姆峡湾的工作级ROV实地部署数据进行了验证。实验结果证明了在视觉受限的水下条件下，该方法能够实现实时可靠的状态估计和高质量的3D重建。文章还讨论了系统限制和未来研究方向，如传感器校准和基于学习方法的局限性。", "keywords": "水下机器人, 多模态感知, SLAM, 态势感知, 传感器融合", "comments": "该论文解决了水下机器人空间感知的一个关键挑战，即水下环境对传统视觉SLAM的严峻考验。其创新点在于提出并验证了多模态传感器融合的方法，通过结合相机、IMU和声学数据，显著提高了水下环境下的态势感知和SLAM鲁棒性。这对于推进水下自主作业和探索具有重要意义。同时，论文也诚实地指出了当前方法的局限性和未来研究方向，例如传感器校准和基于学习方法的进一步优化，这体现了严谨的科研态度。"}}
{"id": "2506.06590", "title": "Robust predicate and function computation in continuous chemical reaction networks", "authors": ["Kim Calabrese", "David Doty", "Mina Latifi"], "summary": "We initiate the study of rate-constant-independent computation of Boolean\npredicates and numerical functions in the continuous model of chemical reaction\nnetworks (CRNs), which model the amount of a chemical species as a nonnegative,\nreal-valued *concentration*. Real-valued numerical functions have previously\nbeen studied, finding that exactly the continuous, piecewise rational linear\nfunctions $f: \\mathbb{R}_{> 0}^k \\to \\mathbb{R}_{> 0}$ can be computed\n*stably*, a.k.a., *rate-independently*, meaning that the CRN gets the answer\ncorrect no matter the rate at which reactions occur.\n  We show that, contrary to functions, continuous CRNs are severely limited in\nthe Boolean predicates they can stably decide, reporting an answer based only\non which inputs are 0 or positive.\n  This limitation motivates a slightly relaxed notion of rate-independent\ncomputation in CRNs that we call *robust computation*. The standard mass-action\nrate model is used, in which each reaction is assigned a rate equal to the\nproduct of its reactant concentrations and its rate constant. The computation\nis correct in this model if it converges to the correct output for any positive\nchoice of rate constants. This adversary is weaker than the stable computation\nadversary, the latter being able to run reactions at non-mass-action rates.\n  We show that CRNs can robustly decide every finite Boolean combination of\n*threshold predicates*: those predicates defined by taking a rational weighted\nsum of the inputs $\\mathbf{x} \\in \\mathbb{R}^k_{\\ge 0}$ and comparing to a\nconstant, answering the question ``Is $\\sum_{i=1}^k w_i \\cdot \\mathbf{x}(i) >\nh$?'', for rational weights $w_i$ and real threshold $h$. Turning to function\ncomputation, we show that CRNs can robustly compute any piecewise affine\nfunction with rational coefficients, where threshold predicates determine which\naffine piece to evaluate for a given input.", "comment": null, "cate": "cs.CC", "url": "http://arxiv.org/abs/2506.06590v1", "AI": {"title_translation": "连续化学反应网络中的鲁棒谓词和函数计算", "tldr": "本文研究了连续化学反应网络（CRNs）中布尔谓词和数值函数的鲁棒计算。鉴于CRNs在稳定计算下对布尔谓词的决策能力有限，作者引入了“鲁棒计算”这一概念，并证明了CRNs在鲁棒计算下能够实现更广泛的布尔谓词和分段仿射函数计算。", "motivation": "之前的研究发现，在“稳定”（完全速率无关）计算下，连续化学反应网络（CRNs）在布尔谓词的决策能力上受到严重限制，其答案仅基于输入是否为零或正。为了克服这一限制，作者引入了一种略微放宽的速率无关计算概念，即“鲁棒计算”。", "method": "本文采用标准的质量作用速率模型，其中每个反应的速率等于其反应物浓度乘积与速率常数的乘积。如果CRN在任何正速率常数选择下都能收敛到正确的输出，则认为计算是“鲁棒”的。研究通过理论分析，证明了CRN在鲁棒计算下的能力。", "result": "1. 与函数计算相反，连续CRN在稳定地决定布尔谓词方面受到严重限制。\n2. CRN可以鲁棒地决定所有有限的“阈值谓词”布尔组合，即通过对输入加权求和并与常数比较定义的谓词。\n3. CRN可以鲁棒地计算任何具有有理系数的分段仿射函数，其中阈值谓词决定了给定输入的仿射片段。", "conclusion": "通过引入“鲁棒计算”的概念，本文扩展了连续化学反应网络在布尔谓词和数值函数计算上的能力范围，使其能够处理更复杂的计算任务，如阈值谓词和分段仿射函数，这为基于化学反应的计算提供了更实际的模型。", "translation": "我们首次研究了连续化学反应网络（CRNs）模型中布尔谓词和数值函数的速率常数无关计算，该模型将化学物质的量建模为非负实值浓度。实值数值函数之前已被研究，发现只有连续、分段有理线性函数 $f: \\mathbb{R}_{> 0}^k \\to \\mathbb{R}_{> 0}$ 可以被“稳定”地计算，也称为“速率无关”计算，这意味着CRN无论反应速率如何都能得到正确答案。\n我们发现，与函数计算相反，连续CRN在稳定地决策布尔谓词方面受到严重限制，其答案仅基于哪些输入是零或正值。\n这种限制促使我们提出了一种略微放宽的CRN速率无关计算概念，我们称之为“鲁棒计算”。这里使用标准的质量作用速率模型，其中每个反应被赋予一个等于其反应物浓度乘积和其速率常数的速率。如果在此模型中，计算对于任何正速率常数选择都能收敛到正确的输出，则计算是正确的。这种对抗者弱于稳定计算的对抗者，后者能够以非质量作用速率运行反应。\n我们表明，CRN可以鲁棒地决定所有有限的“阈值谓词”布尔组合：这些谓词通过对输入 $\\mathbf{x} \\in \\mathbb{R}^k_{\\ge 0}$ 进行有理加权求和并与常数比较来定义，回答“$\\sum_{i=1}^k w_i \\cdot \\mathbf{x}(i) > h$ 吗？”的问题，其中 $w_i$ 是有理权重，$h$ 是实数阈值。转向函数计算，我们表明CRN可以鲁棒地计算任何具有有理系数的分段仿射函数，其中阈值谓词决定了给定输入的仿射片段。", "summary": "本文探讨了连续化学反应网络（CRNs）中布尔谓词和数值函数的计算能力。鉴于CRN在“稳定”计算（完全速率无关）下对布尔谓词的决策能力存在严重限制，作者引入了“鲁棒计算”这一新概念。鲁棒计算允许CRN在质量作用速率模型下，只要速率常数为正，就能收敛到正确结果。研究表明，CRN能够鲁棒地决定所有有限的阈值谓词布尔组合，并能鲁棒地计算任何具有有理系数的分段仿射函数，显著扩展了CRN的计算能力。", "keywords": "化学反应网络, 鲁棒计算, 谓词计算, 函数计算, 质量作用模型", "comments": "本文的创新之处在于引入了“鲁棒计算”这一概念，为化学反应网络的设计提供了一种更实际的计算模型，克服了传统“稳定计算”在布尔谓词决策上的局限性。这对于理解和构建基于化学反应的计算系统具有重要意义，尤其是在生物计算和分子编程领域。"}}
{"id": "2506.06767", "title": "Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness", "authors": ["Wendkûuni C. Ouédraogo", "Yinghua Li", "Xueqi Dang", "Xin Zhou", "Anil Koyuncu", "Jacques Klein", "David Lo", "Tegawendé F. Bissyandé"], "summary": "Large Language Models (LLMs) are increasingly employed to automatically\nrefactor unit tests, aiming to enhance readability, naming, and structural\nclarity while preserving functional behavior. However, evaluating such\nrefactorings remains challenging: traditional metrics like CodeBLEU are overly\nsensitive to renaming and structural edits, whereas embedding-based\nsimilarities capture semantics but ignore readability and modularity. We\nintroduce CTSES, a composite metric that integrates CodeBLEU, METEOR, and\nROUGE-L to balance behavior preservation, lexical quality, and structural\nalignment. CTSES is evaluated on over 5,000 test suites automatically\nrefactored by GPT-4o and Mistral-Large-2407, using Chain-of-Thought prompting,\nacross two established Java benchmarks: Defects4J and SF110. Our results show\nthat CTSES yields more faithful and interpretable assessments, better aligned\nwith developer expectations and human intuition than existing metrics.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.06767v1", "AI": {"title_translation": "超越表面相似性：通过结构和语义感知评估基于LLM的测试重构", "tldr": "引入CTSES，一种复合度量，用于更准确地评估LLM驱动的单元测试重构，克服了现有度量的局限性。", "motivation": "大型语言模型（LLM）被越来越多地用于自动化重构单元测试，以提高可读性、命名和结构清晰度，同时保持功能行为。然而，评估此类重构仍然具有挑战性：传统的度量标准对重命名和结构编辑过于敏感，而基于嵌入的相似性捕获语义但忽略可读性和模块化。", "method": "本文引入了CTSES，一种复合度量，它整合了CodeBLEU、METEOR和ROUGE-L，以平衡行为保留、词汇质量和结构对齐。CTSES在超过5,000个由GPT-4o和Mistral-Large-2407使用思维链提示自动重构的测试套件上进行了评估，涵盖两个已建立的Java基准：Defects4J和SF110。", "result": "我们的结果表明，CTSES产生了更忠实和可解释的评估，比现有度量更好地符合开发人员的期望和人类直觉。", "conclusion": "CTSES作为一种新的复合度量，能够对LLM驱动的测试重构进行更准确、更符合人类直觉的评估，从而克服了现有评估方法的局限性。", "translation": "大型语言模型（LLM）正越来越多地被用于自动化重构单元测试，旨在提高可读性、命名和结构清晰度，同时保留功能行为。然而，评估此类重构仍然具有挑战性：像CodeBLEU这样的传统度量对重命名和结构编辑过于敏感，而基于嵌入的相似性虽然能捕获语义，但却忽略了可读性和模块化。我们引入了CTSES，这是一种复合度量，它整合了CodeBLEU、METEOR和ROUGE-L，以平衡行为保留、词汇质量和结构对齐。CTSES在超过5,000个由GPT-4o和Mistral-Large-2407使用思维链提示自动重构的测试套件上进行了评估，涵盖两个已建立的Java基准：Defects4J和SF110。我们的结果表明，CTSES产生了更忠实和可解释的评估，比现有度量更好地符合开发人员的期望和人类直觉。", "summary": "本研究提出了一种名为CTSES的复合度量，用于评估大型语言模型（LLM）驱动的单元测试重构。针对现有评估方法在可读性、模块化和行为保留方面的不足，CTSES结合了CodeBLEU、METEOR和ROUGE-L，以提供更全面、更准确的评估。在GPT-4o和Mistral-Large-2407重构的Java测试套件上的实验表明，CTSES的评估结果与开发人员的期望和人类直觉更一致。", "keywords": "LLM, 测试重构, 评估指标, CTSES, 单元测试", "comments": "该论文的创新之处在于提出了CTSES这一复合度量，有效解决了LLM驱动的测试重构评估中的现有挑战。通过整合多种指标，CTSES能够更全面地评估重构的质量，包括行为保持、词汇质量和结构对齐，这对于提高LLM在软件工程中的应用至关重要。其重要性在于为未来LLM在代码重构领域的应用提供了更可靠的评估工具。"}}
{"id": "2506.06537", "title": "Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models", "authors": ["Seung-jae Lee", "Paul Hongsuck Seo"], "summary": "Audiovisual segmentation (AVS) aims to identify visual regions corresponding\nto sound sources, playing a vital role in video understanding, surveillance,\nand human-computer interaction. Traditional AVS methods depend on large-scale\npixel-level annotations, which are costly and time-consuming to obtain. To\naddress this, we propose a novel zero-shot AVS framework that eliminates\ntask-specific training by leveraging multiple pretrained models. Our approach\nintegrates audio, vision, and text representations to bridge modality gaps,\nenabling precise sound source segmentation without AVS-specific annotations. We\nsystematically explore different strategies for connecting pretrained models\nand evaluate their efficacy across multiple datasets. Experimental results\ndemonstrate that our framework achieves state-of-the-art zero-shot AVS\nperformance, highlighting the effectiveness of multimodal model integration for\nfinegrained audiovisual segmentation.", "comment": "Accepted on INTERSPEECH2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06537v1", "AI": {"title_translation": "音频与视觉的桥接：通过连接预训练模型实现零样本音视频分割", "tldr": "提出了一种零样本音视频分割框架，通过整合预训练的多模态模型，无需特定标注即可实现SOTA性能。", "motivation": "传统的音视频分割方法依赖于耗时且昂贵的大规模像素级标注，阻碍了其应用。", "method": "提出了一种新颖的零样本音视频分割框架，通过利用多个预训练模型消除任务特定训练。该方法整合了音频、视觉和文本表示来弥合模态差距，并系统地探索了连接预训练模型的不同策略。", "result": "该框架在零样本音视频分割任务上实现了最先进的性能。", "conclusion": "多模态模型集成对于细粒度音视频分割是有效的。", "translation": "音视频分割（AVS）旨在识别与声源对应的视觉区域，在视频理解、监控和人机交互中发挥着至关重要的作用。传统的AVS方法依赖于大规模像素级标注，获取成本高且耗时。为了解决这个问题，我们提出了一种新颖的零样本AVS框架，通过利用多个预训练模型来消除任务特定训练。我们的方法整合了音频、视觉和文本表示，以弥合模态差距，从而无需AVS特定标注即可实现精确的声源分割。我们系统地探索了连接预训练模型的不同策略，并在多个数据集上评估了它们的功效。实验结果表明，我们的框架实现了最先进的零样本AVS性能，突出了多模态模型集成对于细粒度音视频分割的有效性。", "summary": "本文提出了一种新颖的零样本音视频分割（AVS）框架，旨在解决传统AVS方法对昂贵标注的依赖问题。该框架通过连接和整合音频、视觉和文本等多种预训练模型，实现了无需任务特定训练的精确声源分割。实验证明，该方法在多个数据集上取得了最先进的零样本AVS性能，验证了多模态模型集成在细粒度音视频分割中的有效性。", "keywords": "零样本学习, 音视频分割, 预训练模型, 多模态集成, 声源定位", "comments": "这篇论文的创新点在于提出了一个零样本的音视频分割框架，通过巧妙地连接和利用现有的预训练模型，避免了昂贵的像素级标注，这对于实际应用具有重要意义。多模态（音频、视觉、文本）的融合是其成功的关键。"}}
{"id": "2506.07343", "title": "Powers of Magnetic Graph Matrix: Fourier Spectrum, Walk Compression, and Applications", "authors": ["Yinan Huang", "David F. Gleich", "Pan Li"], "summary": "Magnetic graphs, originally developed to model quantum systems under magnetic\nfields, have recently emerged as a powerful framework for analyzing complex\ndirected networks. Existing research has primarily used the spectral properties\nof the magnetic graph matrix to study global and stationary network features.\nHowever, their capacity to model local, non-equilibrium behaviors, often\ndescribed by matrix powers, remains largely unexplored. We present a novel\ncombinatorial interpretation of the magnetic graph matrix powers through\ndirected walk profiles -- counts of graph walks indexed by the number of edge\nreversals. Crucially, we establish that walk profiles correspond to a Fourier\ntransform of magnetic matrix powers. The connection allows exact reconstruction\nof walk profiles from magnetic matrix powers at multiple discrete potentials,\nand more importantly, an even smaller number of potentials often suffices for\naccurate approximate reconstruction in real networks. This shows the empirical\ncompressibility of the information captured by the magnetic matrix. This fresh\nperspective suggests new applications; for example, we illustrate how powers of\nthe magnetic matrix can identify frustrated directed cycles (e.g., feedforward\nloops) and can be effectively employed for link prediction by encoding local\nstructural details in directed graphs.", "comment": null, "cate": "physics.soc-ph", "url": "http://arxiv.org/abs/2506.07343v1", "AI": {"title_translation": "磁图矩阵的幂：傅里叶谱、游走压缩及应用", "tldr": "本文提出了一种通过有向游走剖面来解释磁图矩阵幂的新方法，并建立了其与傅里叶变换的联系，从而实现了游走剖面的精确和近似重构，并展示了在识别受挫有向循环和链接预测等方面的应用。", "motivation": "现有研究主要利用磁图矩阵的谱特性来研究全局和静态网络特征，但其建模局部、非平衡行为（通常由矩阵幂描述）的能力尚未得到充分探索。", "method": "本文通过有向游走剖面（按边反转次数索引的图游走计数）对磁图矩阵的幂进行了新颖的组合解释。关键是，研究建立了游走剖面与磁矩阵幂的傅里叶变换之间的对应关系。", "result": "游走剖面与磁矩阵幂的傅里叶变换相对应，这使得可以从多个离散电位的磁矩阵幂中精确重构游走剖面。更重要的是，在实际网络中，通常只需要更少数量的电位就可以实现准确的近似重构，这表明磁矩阵捕获的信息具有经验可压缩性。", "conclusion": "这种新的视角为磁图矩阵的幂提供了新的应用，例如，它们可以识别受挫的有向循环（如前馈环），并且可以通过编码有向图中的局部结构细节有效地用于链接预测。", "translation": "磁图最初是为了模拟磁场下的量子系统而开发的，最近已成为分析复杂有向网络的强大框架。现有研究主要利用磁图矩阵的谱特性来研究全局和静态网络特征。然而，它们建模局部、非平衡行为（通常由矩阵幂描述）的能力在很大程度上仍未被探索。我们通过有向游走剖面（即按边反转次数索引的图游走计数）对磁图矩阵的幂进行了一种新颖的组合解释。至关重要的是，我们确定游走剖面对应于磁矩阵幂的傅里叶变换。这种联系允许从多个离散电位的磁矩阵幂中精确重构游走剖面，更重要的是，在实际网络中，通常只需要更少数量的电位就可以实现准确的近似重构。这表明磁矩阵捕获的信息具有经验可压缩性。这种新的视角提出了新的应用；例如，我们说明了磁矩阵的幂如何识别受挫的有向循环（例如，前馈环），并且可以通过编码有向图中的局部结构细节有效地用于链接预测。", "summary": "本文提出了一种通过有向游走剖面来解释磁图矩阵幂的新颖组合方法，并建立了游走剖面与磁矩阵幂的傅里叶变换之间的对应关系。这一发现使得能够从多个离散电位的磁矩阵幂中精确重构游走剖面，并且在实际网络中，少量电位即可实现准确的近似重构，揭示了磁矩阵信息的可压缩性。这种新视角为识别受挫有向循环和通过编码局部结构细节进行链接预测等应用提供了可能性。", "keywords": "磁图矩阵, 傅里叶变换, 游走压缩, 有向网络, 链接预测", "comments": "本文通过对磁图矩阵的幂进行新颖的组合解释，并将其与傅里叶变换联系起来，为分析复杂有向网络的局部、非平衡行为提供了一个强大的新框架。其创新之处在于揭示了磁矩阵信息的可压缩性，并为图分析中的新应用（如识别受挫循环和链接预测）开辟了道路，具有重要的理论和实践意义。"}}
{"id": "2506.06301", "title": "Large Language Models and Their Applications in Roadway Safety and Mobility Enhancement: A Comprehensive Review", "authors": ["Muhammad Monjurul Karim", "Yan Shi", "Shucheng Zhang", "Bingzhang Wang", "Mehrdad Nasri", "Yinhai Wang"], "summary": "Roadway safety and mobility remain critical challenges for modern\ntransportation systems, demanding innovative analytical frameworks capable of\naddressing complex, dynamic, and heterogeneous environments. While traditional\nengineering methods have made progress, the complexity and dynamism of\nreal-world traffic necessitate more advanced analytical frameworks. Large\nLanguage Models (LLMs), with their unprecedented capabilities in natural\nlanguage understanding, knowledge integration, and reasoning, represent a\npromising paradigm shift. This paper comprehensively reviews the application\nand customization of LLMs for enhancing roadway safety and mobility. A key\nfocus is how LLMs are adapted -- via architectural, training, prompting, and\nmultimodal strategies -- to bridge the \"modality gap\" with transportation's\nunique spatio-temporal and physical data. The review systematically analyzes\ndiverse LLM applications in mobility (e.g., traffic flow prediction, signal\ncontrol) and safety (e.g., crash analysis, driver behavior assessment,).\nEnabling technologies such as V2X integration, domain-specific foundation\nmodels, explainability frameworks, and edge computing are also examined.\nDespite significant potential, challenges persist regarding inherent LLM\nlimitations (hallucinations, reasoning deficits), data governance (privacy,\nbias), deployment complexities (sim-to-real, latency), and rigorous safety\nassurance. Promising future research directions are highlighted, including\nadvanced multimodal fusion, enhanced spatio-temporal reasoning, human-AI\ncollaboration, continuous learning, and the development of efficient,\nverifiable systems. This review provides a structured roadmap of current\ncapabilities, limitations, and opportunities, underscoring LLMs' transformative\npotential while emphasizing the need for responsible innovation to realize\nsafer, more intelligent transportation systems.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06301v1", "AI": {"title_translation": "大型语言模型及其在道路安全和出行能力增强中的应用：一项综合综述", "tldr": "本文全面综述了大型语言模型（LLMs）在增强道路安全和出行能力方面的应用，探讨了其适应性策略、具体应用、使能技术、面临的挑战以及未来的研究方向。", "motivation": "道路安全和出行能力是现代交通系统的关键挑战，需要创新的分析框架来处理复杂、动态和异构的环境。传统工程方法已取得进展，但现实交通的复杂性和动态性需要更先进的分析框架。大型语言模型（LLMs）以其在自然语言理解、知识整合和推理方面的能力，代表着一个有前途的范式转变。", "method": "本文通过全面综述的方式，分析了大型语言模型（LLMs）在增强道路安全和出行能力方面的应用和定制。重点关注LLMs如何通过架构、训练、提示和多模态策略来适应交通领域独特的时空和物理数据，弥合“模态鸿沟”。系统分析了LLMs在出行（例如，交通流预测、信号控制）和安全（例如，碰撞分析、驾驶员行为评估）中的多样化应用，并考察了V2X集成、领域特定基础模型、可解释性框架和边缘计算等使能技术。", "result": "综述分析了LLMs在出行（交通流预测、信号控制）和安全（碰撞分析、驾驶员行为评估）中的多样化应用。考察了V2X集成、领域特定基础模型、可解释性框架和边缘计算等使能技术。尽管潜力巨大，但也指出了LLMs固有限制（幻觉、推理缺陷）、数据治理（隐私、偏见）、部署复杂性（模拟到现实、延迟）以及严格安全保障方面的挑战。", "conclusion": "LLMs在交通领域具有变革潜力，但需要负责任的创新以实现更安全、更智能的交通系统。本综述提供了当前能力、局限性和机遇的结构化路线图。", "translation": "道路安全和出行能力仍然是现代交通系统的关键挑战，需要能够解决复杂、动态和异构环境的创新分析框架。尽管传统工程方法取得了进展，但现实交通的复杂性和动态性需要更先进的分析框架。大型语言模型（LLMs）凭借其在自然语言理解、知识整合和推理方面前所未有的能力，代表着一个有前途的范式转变。本文全面综述了LLMs在增强道路安全和出行能力方面的应用和定制。一个关键的重点是LLMs如何通过架构、训练、提示和多模态策略来适应——弥合交通领域独特的时空和物理数据之间的“模态鸿沟”。本综述系统地分析了LLMs在出行（例如，交通流预测、信号控制）和安全（例如，碰撞分析、驾驶员行为评估）中的多样化应用。V2X集成、领域特定基础模型、可解释性框架和边缘计算等使能技术也得到了考察。尽管潜力巨大，但在LLMs固有限制（幻觉、推理缺陷）、数据治理（隐私、偏见）、部署复杂性（模拟到现实、延迟）以及严格安全保障方面仍然存在挑战。未来有前景的研究方向包括先进的多模态融合、增强的时空推理、人机协作、持续学习以及开发高效、可验证的系统。本综述提供了当前能力、局限性和机遇的结构化路线图，强调了LLMs的变革潜力，同时强调了负责任创新的必要性，以实现更安全、更智能的交通系统。", "summary": "本文对大型语言模型（LLMs）在提升道路安全和出行能力方面的应用进行了全面综述。文章探讨了LLMs如何通过多种策略（如架构、训练、提示和多模态方法）适应交通领域独特的时空数据，以弥补“模态鸿沟”。综述分析了LLMs在交通流预测、信号控制、碰撞分析和驾驶员行为评估等方面的具体应用，并讨论了V2X集成、领域特定基础模型等使能技术。同时，论文也指出了LLMs固有的局限性（如幻觉、推理缺陷）、数据治理、部署复杂性以及安全保障等挑战，并展望了多模态融合、时空推理、人机协作等未来研究方向。该综述为LLMs在交通领域的应用提供了结构化的现状、局限性和机遇路线图。", "keywords": "大型语言模型, 道路安全, 出行能力, 交通系统, 综合综述", "comments": "这篇综述论文及时地总结了大型语言模型（LLMs）在道路交通领域的应用现状，特别是其如何通过多模态策略适应交通数据，弥补了LLMs在处理非文本数据方面的不足。其重要性在于为研究人员和从业者提供了一个清晰的路线图，指明了LLMs在交通安全和出行能力提升中的潜力与挑战。论文不仅列举了具体的应用案例，还深入探讨了使能技术和面临的限制，如幻觉和数据隐私问题，这对于引导未来的负责任创新至关重要。"}}
{"id": "2506.07129", "title": "Energy Efficiency Maximization for Movable Antenna Communication Systems", "authors": ["Jingze Ding", "Zijian Zhou", "Lipeng Zhu", "Yuping Zhao", "Bingli Jiao", "Rui Zhang"], "summary": "This paper investigates energy efficiency maximization for movable antenna\n(MA)-aided multi-user uplink communication systems by considering the time\ndelay and energy consumption incurred by practical antenna movement. We first\nexamine the special case with a single user and propose an optimization\nalgorithm based on the one-dimensional (1D) exhaustive search to maximize the\nuser's energy efficiency. Moreover, we derive an upper bound on the energy\nefficiency and analyze the conditions required to achieve this performance\nbound under different numbers of channel paths. Then, for the general\nmulti-user scenario, we propose an iterative algorithm to fairly maximize the\nminimum energy efficiency among all users. Simulation results demonstrate the\neffectiveness of the proposed scheme in improving energy efficiency compared to\nexisting MA schemes that do not account for movement-related costs, as well as\nthe conventional fixed-position antenna (FPA) scheme. In addition, the results\nshow the robustness of the proposed scheme to imperfect channel state\ninformation (CSI) and provide valuable insights for practical system\ndeployment.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07129v1", "AI": {"title_translation": "可移动天线通信系统的能量效率最大化", "tldr": "本文研究了可移动天线（MA）辅助多用户上行通信系统中的能量效率最大化问题，考虑了天线移动的时间延迟和能量消耗，并提出了针对单用户和多用户场景的优化算法。", "motivation": "当前的可移动天线（MA）通信系统在最大化能量效率时，通常忽略了天线移动带来的时间延迟和能量消耗。为了更实际地提高系统性能，本文旨在解决这一问题。", "method": "本文首先针对单用户场景，提出了一种基于一维（1D）穷举搜索的优化算法来最大化用户能量效率，并推导了能量效率的上限。然后，对于多用户场景，提出了一种迭代算法来公平地最大化所有用户的最小能量效率。", "result": "仿真结果表明，与现有不考虑移动成本的MA方案以及传统的固定位置天线（FPA）方案相比，所提出的方案能有效提高能量效率。此外，该方案对不完善的信道状态信息（CSI）具有鲁棒性。", "conclusion": "本文提出的考虑天线移动成本的能量效率最大化方案，在多用户上行MA通信系统中表现出优越的性能和鲁棒性，为实际系统部署提供了有价值的见解。", "translation": "本文研究了可移动天线（MA）辅助多用户上行通信系统中的能量效率最大化问题，其中考虑了实际天线移动所产生的时间延迟和能量消耗。我们首先研究了单用户的特殊情况，并提出了一种基于一维（1D）穷举搜索的优化算法来最大化用户的能量效率。此外，我们推导了能量效率的上限，并分析了在不同信道路径数下达到此性能界限所需的条件。然后，对于一般多用户场景，我们提出了一种迭代算法来公平地最大化所有用户的最小能量效率。仿真结果表明，与现有不考虑移动相关成本的MA方案以及传统的固定位置天线（FPA）方案相比，所提出的方案在提高能量效率方面是有效的。此外，结果表明所提出的方案对不完善的信道状态信息（CSI）具有鲁棒性，并为实际系统部署提供了有价值的见解。", "summary": "本文研究了可移动天线（MA）辅助多用户上行通信系统的能量效率最大化，首次将天线移动的时间延迟和能量消耗纳入考虑。针对单用户情况，提出了一维穷举搜索算法并推导了能量效率上限。针对多用户情况，提出了一种迭代算法以公平最大化最小能量效率。仿真结果验证了所提方案在提高能量效率方面的有效性，并显示其对不完善CSI的鲁棒性，为实际部署提供了指导。", "keywords": "可移动天线, 能量效率最大化, 多用户通信, 时间延迟, 能量消耗", "comments": "本文的创新之处在于其首次将可移动天线通信系统中天线移动的时间延迟和能量消耗纳入能量效率最大化问题，这使得研究更贴近实际应用。所提出的针对单用户和多用户场景的优化算法具有理论和实践意义。此外，对不完善CSI鲁棒性的验证增强了方案的实用性。"}}
{"id": "2506.07046", "title": "QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine", "authors": ["Anushka Jha", "Tanushree Dewangan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "summary": "Reinforcement Learning (RL) has outperformed other counterparts in sequential\ndecision-making and dynamic environment control. However, FPGA deployment is\nsignificantly resource-expensive, as associated with large number of\ncomputations in training agents with high-quality images and possess new\nchallenges. In this work, we propose QForce-RL takes benefits of quantization\nto enhance throughput and reduce energy footprint with light-weight RL\narchitecture, without significant performance degradation. QForce-RL takes\nadvantages from E2HRL to reduce overall RL actions to learn desired policy and\nQuaRL for quantization based SIMD for hardware acceleration. We have also\nprovided detailed analysis for different RL environments, with emphasis on\nmodel size, parameters, and accelerated compute ops. The architecture is\nscalable for resource-constrained devices and provide parametrized efficient\ndeployment with flexibility in latency, throughput, power, and energy\nefficiency. The proposed QForce-RL provides performance enhancement up to 2.3x\nand better FPS - 2.6x compared to SoTA works.", "comment": null, "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07046v1", "AI": {"title_translation": "QForce-RL：量化FPGA优化的强化学习计算引擎", "tldr": "QForce-RL提出了一种量化和轻量级的强化学习架构，用于在FPGA上实现高效部署，性能提升显著。", "motivation": "强化学习（RL）在序列决策和动态环境控制中表现出色，但其在FPGA上的部署资源消耗巨大，尤其是在训练高质量图像的智能体时面临大量计算挑战。", "method": "QForce-RL通过利用量化技术和轻量级RL架构来提高吞吐量并降低能耗，同时保持性能。它借鉴了E2HRL来减少RL动作以学习期望策略，并利用QuaRL进行基于量化的SIMD硬件加速。", "result": "QForce-RL的性能提升高达2.3倍，帧率（FPS）比现有最先进（SoTA）作品高2.6倍。", "conclusion": "QForce-RL提供了一种可扩展且参数化高效的部署方案，适用于资源受限设备，并在延迟、吞吐量、功耗和能效方面具有灵活性。", "translation": "强化学习（RL）在序列决策和动态环境控制方面已超越其他方法。然而，FPGA部署的资源消耗巨大，因为其涉及到使用高质量图像训练智能体的大量计算，并带来了新的挑战。在这项工作中，我们提出了QForce-RL，它利用量化技术来提高吞吐量并降低能耗，采用轻量级RL架构，而不会导致显著的性能下降。QForce-RL借鉴了E2HRL来减少整体RL动作以学习期望策略，并利用QuaRL进行基于量化的SIMD硬件加速。我们还对不同的RL环境进行了详细分析，重点关注模型大小、参数和加速计算操作。该架构可扩展到资源受限设备，并提供参数化的有效部署，在延迟、吞吐量、功耗和能效方面具有灵活性。所提出的QForce-RL与现有最先进（SoTA）作品相比，性能提升高达2.3倍，帧率（FPS）提高2.6倍。", "summary": "本论文提出了QForce-RL，一个量化且FPGA优化的强化学习计算引擎，旨在解决RL在FPGA部署中面临的资源消耗和计算挑战。QForce-RL通过结合量化技术和轻量级架构，以及借鉴E2HRL和QuaRL的优势，显著提高了吞吐量并降低了能耗，同时保持了高性能。该架构具有可扩展性，适用于资源受限设备，并提供了灵活的部署选项。实验结果显示，QForce-RL在性能上提升高达2.3倍，FPS提高2.6倍。", "keywords": "强化学习, FPGA, 量化, 硬件加速, QForce-RL", "comments": "QForce-RL的创新在于将量化技术应用于FPGA上的强化学习部署，有效解决了资源消耗大的痛点。其轻量级架构和对现有优化方案的整合（如E2HRL和QuaRL）使其在保持性能的同时，实现了显著的能效和吞吐量提升，对于边缘设备上的RL部署具有重要意义。"}}
{"id": "2506.06294", "title": "GLProtein: Global-and-Local Structure Aware Protein Representation Learning", "authors": ["Yunqing Liu", "Wenqi Fan", "Xiaoyong Wei", "Qing Li"], "summary": "Proteins are central to biological systems, participating as building blocks\nacross all forms of life. Despite advancements in understanding protein\nfunctions through protein sequence analysis, there remains potential for\nfurther exploration in integrating protein structural information. We argue\nthat the structural information of proteins is not only limited to their 3D\ninformation but also encompasses information from amino acid molecules (local\ninformation) to protein-protein structure similarity (global information). To\naddress this, we propose \\textbf{GLProtein}, the first framework in protein\npre-training that incorporates both global structural similarity and local\namino acid details to enhance prediction accuracy and functional insights.\nGLProtein innovatively combines protein-masked modelling with triplet structure\nsimilarity scoring, protein 3D distance encoding and substructure-based amino\nacid molecule encoding. Experimental results demonstrate that GLProtein\noutperforms previous methods in several bioinformatics tasks, including\npredicting protein-protein interaction, contact prediction, and so on.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06294v1", "AI": {"title_translation": "GLProtein: 全局与局部结构感知蛋白质表示学习", "tldr": "GLProtein是一个新的蛋白质预训练框架，它结合了全局结构相似性和局部氨基酸细节，显著提高了蛋白质预测任务的准确性。", "motivation": "尽管蛋白质序列分析在理解蛋白质功能方面取得了进展，但在整合蛋白质结构信息方面仍有进一步探索的潜力。作者认为蛋白质结构信息不仅限于3D信息，还包括氨基酸分子（局部信息）和蛋白质-蛋白质结构相似性（全局信息）。现有方法可能未能充分利用这些多层次的结构信息。", "method": "本文提出了GLProtein框架，这是蛋白质预训练中第一个结合全局结构相似性和局部氨基酸细节的框架。它创新性地将蛋白质掩码建模与三重态结构相似性评分、蛋白质3D距离编码和基于子结构的氨基酸分子编码相结合。", "result": "GLProtein在多项生物信息学任务中优于现有方法，包括预测蛋白质-蛋白质相互作用、接触预测等。", "conclusion": "GLProtein通过整合全局和局部结构信息，显著提高了蛋白质预测的准确性和功能洞察力，为蛋白质表示学习提供了一个更全面的框架。", "translation": "蛋白质是生物系统的核心，作为所有生命形式的组成部分参与其中。尽管通过蛋白质序列分析在理解蛋白质功能方面取得了进展，但在整合蛋白质结构信息方面仍有进一步探索的潜力。我们认为蛋白质的结构信息不仅限于其3D信息，还包括来自氨基酸分子（局部信息）到蛋白质-蛋白质结构相似性（全局信息）的信息。为了解决这个问题，我们提出了**GLProtein**，这是蛋白质预训练中第一个结合了全局结构相似性和局部氨基酸细节以提高预测准确性和功能洞察力的框架。GLProtein创新性地将蛋白质掩码建模与三重态结构相似性评分、蛋白质3D距离编码和基于子结构的氨基酸分子编码相结合。实验结果表明，GLProtein在多项生物信息学任务中优于现有方法，包括预测蛋白质-蛋白质相互作用、接触预测等。", "summary": "本文提出了GLProtein，一个结合全局结构相似性和局部氨酸细节的蛋白质预训练框架。该框架通过整合蛋白质掩码建模、三重态结构相似性评分、3D距离编码和子结构氨基酸编码，旨在解决现有蛋白质表示学习未能充分利用多层次结构信息的问题。实验证明，GLProtein在多种生物信息学任务中表现优异，提升了蛋白质功能预测的准确性。", "keywords": "蛋白质表示学习, 全局结构, 局部结构, 预训练, 生物信息学", "comments": "GLProtein的创新之处在于其是首个在蛋白质预训练中同时考虑全局结构相似性和局部氨基酸细节的框架，这为蛋白质表示学习提供了一个更全面的视角。通过结合多种编码技术，它有效地捕获了蛋白质多层次的结构信息，有望在蛋白质功能预测和结构理解方面取得突破。"}}
{"id": "2506.06383", "title": "Human and AI collaboration in Fitness Education:A Longitudinal Study with a Pilates Instructor", "authors": ["Qian Huang", "King Wang Poon"], "summary": "Artificial intelligence is poised to transform teaching and coaching\npractices,yet its optimal role alongside human expertise remains unclear.This\nstudy investigates human and AI collaboration in fitness education through a\none year qualitative case study with a Pilates instructor.The researcher\nparticipated in the instructor classes and conducted biweekly semi structured\ninterviews to explore how generative AI could be integrated into class planning\nand instruction.", "comment": "19 pages, 5 figures", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06383v1", "AI": {"title_translation": "健身教育中的人机协作：一项与普拉提教练的纵向研究", "tldr": "一项为期一年的定性案例研究，探讨了生成式AI如何融入普拉提教练的课程规划和教学，以理解AI在健身教育中与人类专业知识协作的最佳角色。", "motivation": "尽管人工智能有望改变教学和指导实践，但其与人类专业知识相结合的最佳作用尚不明确，本研究旨在探索这一点。", "method": "本研究通过一项为期一年的定性案例研究，与一名普拉提教练合作进行。研究人员参与了教练的课程，并进行了双周半结构化访谈，以探讨生成式AI如何融入课程规划和教学。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "人工智能有望改变教学和指导实践，但其与人类专业知识相结合的最佳作用尚不明确。本研究通过一项为期一年的定性案例研究，与一名普拉提教练合作，调查了健身教育中的人机协作。研究人员参与了教练的课程，并进行了双周半结构化访谈，以探讨生成式人工智能如何融入课程规划和教学。", "summary": "本研究旨在探讨人工智能在健身教育中与人类专业知识协作的最佳方式。通过与一名普拉提教练进行为期一年的定性案例研究，研究人员参与课程并进行访谈，以了解生成式AI如何应用于课程规划和教学。", "keywords": "人机协作, 健身教育, 普拉提, 定性研究, 生成式AI", "comments": "该研究通过长期的定性案例研究方法，深入探讨了AI在健身教育实践中的具体应用和人机协作模式，具有较强的实践指导意义。其创新之处在于关注AI与人类专业知识的融合而非替代，但抽象中未提及具体发现或影响。"}}
{"id": "2506.07379", "title": "Addressing tokens dynamic generation, propagation, storage and renewal to secure the GlideinWMS pilot based jobs and system", "authors": ["Bruno Moreira Coimbra", "Marco Mambelli"], "summary": "GlideinWMS has been one of the first middleware in the WLCG community to\ntransition from X.509 to support also tokens. The first step was to get from\nthe prototype in 2019 to using tokens in production in 2022. This paper will\npresent the challenges introduced by the wider adoption of tokens and the\nevolution plans for securing the pilot infrastructure of GlideinWMS and\nsupporting the new requirements. In the last couple of years, the GlideinWMS\nteam supported the migration of experiments and resources to tokens. Inadequate\nsupport in the current infrastructure, more stringent requirements, and the\nhigher spatial and temporal granularity forced GlideinWMS to revisit once more\nhow credentials are generated, used, and propagated. The new credential modules\nhave been designed to be used in multiple systems (GlideinWMS, HEPCloud) and\nuse a model where credentials have type, purpose, and different flows.\nCredentials are dynamically generated in order to customize the duration and\nlimit the scope to the targeted resource. This allows to enforce the least\nprivilege principle. Finally, we also considered adding credential storage,\nrenewal, and invalidation mechanisms within the GlideinWMS infrastructure to\nbetter serve the experiments' needs.", "comment": "8 pages, 3 figures, for associated code, see\n  https://github.com/glideinWMS/glideinwms, to be published in proceedings of\n  27th International Conference on Computing in High Energy and Nuclear Physics\n  (CHEP 2024). 21-25 October 2024. Krakow,; Poland. (C24-10-21.8)", "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.07379v1", "AI": {"title_translation": "解决令牌动态生成、传播、存储和更新以保护基于GlideinWMS试点的工作和系统", "tldr": "GlideinWMS正在演进其凭证管理系统，以应对令牌广泛采用带来的挑战，通过动态生成、范围限制和新的凭证模块来增强安全性并支持多系统使用。", "motivation": "GlideinWMS从X.509向令牌的过渡带来了挑战，包括当前基础设施支持不足、更严格的要求以及更高的时间和空间粒度，迫使系统重新审视凭证的生成、使用和传播方式，以确保飞行员基础设施的安全并满足新需求。", "method": "GlideinWMS设计了新的凭证模块，这些模块可在多个系统（如GlideinWMS、HEPCloud）中使用，并采用凭证具有类型、目的和不同流程的模型。凭证被动态生成以自定义持续时间并将范围限制到目标资源，从而强制执行最小特权原则。此外，团队还考虑在GlideinWMS基础设施中添加凭证存储、续订和失效机制。", "result": "新的凭证模块被设计用于多个系统（GlideinWMS，HEPCloud）。凭证的动态生成允许自定义持续时间并限制范围，从而强制执行最小特权原则。", "conclusion": "该论文介绍了GlideinWMS在令牌广泛采用背景下所面临的挑战以及其为保护试点基础设施和支持新需求而制定的演进计划。通过设计新的凭证模块和动态凭证管理机制，GlideinWMS旨在提高凭证的安全性、灵活性和可用性。", "translation": "GlideinWMS是WLCG社区中首批从X.509过渡到支持令牌的中间件之一。第一步是从2019年的原型到2022年投入生产使用令牌。本文将介绍令牌更广泛采用所带来的挑战，以及为保护GlideinWMS的试点基础设施和支持新需求而制定的演进计划。在过去几年中，GlideinWMS团队支持了实验和资源向令牌的迁移。当前基础设施中支持不足、更严格的要求以及更高的时间和空间粒度迫使GlideinWMS再次重新审视凭证的生成、使用和传播方式。新的凭证模块已被设计用于多个系统（GlideinWMS、HEPCloud），并使用凭证具有类型、目的和不同流程的模型。凭证被动态生成，以自定义持续时间并将范围限制到目标资源。这允许强制执行最小特权原则。最后，我们还考虑在GlideinWMS基础设施中添加凭证存储、续订和失效机制，以更好地服务实验需求。", "summary": "本文探讨了GlideinWMS从X.509向令牌过渡所面临的挑战及应对策略。为解决令牌广泛采用带来的安全和管理问题，GlideinWMS开发了新的凭证模块，支持动态生成、范围限制，并计划引入存储、续订和失效机制，以确保飞行员基础设施的安全并满足未来需求。这些新模块旨在实现最小特权原则，并可应用于多个系统。", "keywords": "GlideinWMS, 令牌, 安全, 凭证, 动态生成", "comments": "该论文展示了GlideinWMS在应对大规模分布式计算环境中凭证管理挑战方面的积极探索。其创新点在于引入了动态凭证生成、范围限制以及多系统兼容的凭证模块设计，这对于提升系统安全性和操作灵活性具有重要意义。考虑凭证的存储、续订和失效机制也体现了对凭证生命周期管理的全面考虑。"}}
{"id": "2506.07880", "title": "Diffusion-RL for Scalable Resource Allocation for 6G Networks", "authors": ["Salar Nouri", "Mojdeh Karbalaee Motalleb", "Vahid Shah-Mansouri"], "summary": "This paper presents a novel approach to resource allocation in Open Radio\nAccess Networks (O-RAN), leveraging a Generative AI technique with network\nslicing to address the diverse demands of 5G and 6G service types such as\nEnhanced Mobile Broadband (eMBB), Ultra-Reliable Low-Latency Communications\n(URLLC), and Massive Machine-Type Communications (mMTC). Additionally, we\nprovide a comprehensive analysis and comparison of machine learning (ML)\ntechniques for resource allocation within O-RAN, evaluating their effectiveness\nin optimizing network performance. We introduce a diffusion-based reinforcement\nlearning (Diffusion-RL) algorithm designed to optimize the allocation of\nphysical resource blocks (PRBs) and power consumption, thereby maximizing\nweighted throughput and minimizing the delay for user equipment (UE). The\nDiffusion-RL model incorporates controlled noise and perturbations to explore\noptimal resource distribution while meeting each service type's Quality of\nService (QoS) requirements. We evaluate the performance of our proposed method\nagainst several benchmarks, including an exhaustive search algorithm, deep\nQ-networks (DQN), and the Semi-Supervised Variational Autoencoder (SS-VAE).\nComprehensive metrics, such as throughput and latency, are presented for each\nservice type. Experimental results demonstrate that the Diffusion-based RL\napproach outperforms existing methods in efficiency, scalability, and\nrobustness, offering a promising solution for resource allocation in dynamic\nand heterogeneous O-RAN environments with significant implications for future\n6G networks.", "comment": "9 pages, 8 figures", "cate": "cs.NI", "url": "http://arxiv.org/abs/2506.07880v1", "AI": {"title_translation": "用于6G网络可扩展资源分配的扩散强化学习", "tldr": "本文提出了一种基于扩散强化学习（Diffusion-RL）的新方法，用于在开放无线接入网络（O-RAN）中进行资源分配，以满足5G和6G服务的不同需求，并在效率、可扩展性和鲁棒性方面优于现有方法。", "motivation": "为了解决开放无线接入网络（O-RAN）中5G和6G服务类型（如eMBB、URLLC和mMTC）的多元化需求，需要一种新颖的资源分配方法。", "method": "本文引入了一种基于扩散的强化学习（Diffusion-RL）算法，旨在优化物理资源块（PRB）的分配和功耗，从而最大化加权吞吐量并最小化用户设备（UE）的延迟。该模型融合了受控噪声和扰动，以探索最佳资源分布，同时满足每种服务类型的服务质量（QoS）要求。此外，还对O-RAN中用于资源分配的机器学习（ML）技术进行了全面分析和比较。", "result": "通过与穷举搜索算法、深度Q网络（DQN）和半监督变分自编码器（SS-VAE）等基准进行性能评估，实验结果表明，所提出的基于扩散的强化学习方法在效率、可扩展性和鲁棒性方面均优于现有方法。针对每种服务类型，提供了吞吐量和延迟等综合指标。", "conclusion": "基于扩散的强化学习方法为动态异构O-RAN环境中的资源分配提供了一个有前景的解决方案，对未来的6G网络具有重要意义。", "translation": "本文提出了一种在开放无线接入网络（O-RAN）中进行资源分配的新颖方法，该方法利用生成式AI技术和网络切片来解决5G和6G服务类型（如增强型移动宽带（eMBB）、超可靠低延迟通信（URLLC）和大规模机器类型通信（mMTC））的多元化需求。此外，我们还对O-RAN中用于资源分配的机器学习（ML）技术进行了全面分析和比较，评估了它们在优化网络性能方面的有效性。我们引入了一种基于扩散的强化学习（Diffusion-RL）算法，旨在优化物理资源块（PRB）的分配和功耗，从而最大化加权吞吐量并最小化用户设备（UE）的延迟。Diffusion-RL模型融合了受控噪声和扰动，以探索最佳资源分布，同时满足每种服务类型的服务质量（QoS）要求。我们评估了所提出方法与多种基准（包括穷举搜索算法、深度Q网络（DQN）和半监督变分自编码器（SS-VAE））的性能。针对每种服务类型，提供了吞吐量和延迟等综合指标。实验结果表明，基于扩散的强化学习方法在效率、可扩展性和鲁棒性方面均优于现有方法，为动态异构O-RAN环境中的资源分配提供了一个有前景的解决方案，对未来的6G网络具有重要意义。", "summary": "本文提出了一种创新的基于扩散强化学习（Diffusion-RL）的资源分配方法，专为开放无线接入网络（O-RAN）设计，以应对5G和6G网络中多种服务类型（如eMBB、URLLC、mMTC）的动态需求。该方法结合了生成式AI和网络切片，通过优化物理资源块和功耗，旨在最大化吞吐量并最小化延迟。实验结果表明，Diffusion-RL在效率、可扩展性和鲁棒性方面均优于现有的基准方法，为未来6G网络中的资源分配提供了有力的解决方案。", "keywords": "扩散强化学习, 资源分配, O-RAN, 6G, 网络切片", "comments": "该论文的创新之处在于将扩散模型与强化学习相结合，应用于O-RAN中的资源分配，并利用生成式AI和网络切片来处理复杂多样的服务需求。其在效率、可扩展性和鲁棒性方面的优势表明了该方法在未来6G网络中的巨大潜力，为解决动态异构网络环境下的资源优化问题提供了新的思路。"}}
{"id": "2506.06597", "title": "Stochastic Training for Side-Channel Resilient AI", "authors": ["Anuj Dubey", "Aydin Aysu"], "summary": "The confidentiality of trained AI models on edge devices is at risk from\nside-channel attacks exploiting power and electromagnetic emissions. This paper\nproposes a novel training methodology to enhance resilience against such\nthreats by introducing randomized and interchangeable model configurations\nduring inference. Experimental results on Google Coral Edge TPU show a\nreduction in side-channel leakage and a slower increase in t-scores over 20,000\ntraces, demonstrating robustness against adversarial observations. The defense\nmaintains high accuracy, with about 1% degradation in most configurations, and\nrequires no additional hardware or software changes, making it the only\napplicable solution for existing Edge TPUs.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06597v1", "AI": {"title_translation": "用于侧信道弹性AI的随机训练", "tldr": "边缘设备上的AI模型易受侧信道攻击。本文提出了一种随机训练方法，通过在推理过程中引入随机模型配置来减少泄漏并提高弹性，同时保持高精度且无需硬件更改。", "motivation": "边缘设备上训练的AI模型的保密性面临侧信道攻击的风险，这些攻击利用功耗和电磁辐射。", "method": "本文提出了一种新颖的训练方法，通过在推理过程中引入随机和可互换的模型配置来增强对抗侧信道威胁的弹性。", "result": "在Google Coral Edge TPU上的实验结果显示，侧信道泄漏减少，并且在超过20,000条轨迹中，t-score的增长速度变慢，这表明了对抗对抗性观测的鲁棒性。该防御方案保持了高精度，在大多数配置下精度下降约1%，并且不需要额外的硬件或软件更改。", "conclusion": "所提出的随机训练方法通过减少泄漏和保持精度，有效增强了边缘设备上AI模型对抗侧信道攻击的弹性，使其成为现有Edge TPU的实用解决方案。", "translation": "边缘设备上训练的AI模型的保密性面临侧信道攻击的风险，这些攻击利用功耗和电磁辐射。本文提出了一种新颖的训练方法，通过在推理过程中引入随机和可互换的模型配置来增强对抗此类威胁的弹性。在Google Coral Edge TPU上的实验结果显示，侧信道泄漏减少，并且在超过20,000条轨迹中，t-score的增长速度变慢，这表明了对抗对抗性观测的鲁棒性。该防御方案保持了高精度，在大多数配置下精度下降约1%，并且不需要额外的硬件或软件更改，使其成为现有Edge TPU唯一适用的解决方案。", "summary": "本文介绍了一种随机训练方法，用于保护边缘设备上的AI模型免受侧信道攻击。通过在推理过程中使用随机模型配置，该方法显著减少了侧信道泄漏，提高了鲁棒性，同时保持了高精度，且无需硬件或软件修改，使其适用于现有Edge TPU。", "keywords": "侧信道攻击, AI模型, 边缘设备, 随机训练, 弹性", "comments": "这项研究的创新之处在于提出了一种纯软件、基于训练的防御方法，以应对边缘AI上的侧信道攻击，这在嵌入式系统的限制下尤为重要。其无需硬件更改即可适用于现有Edge TPU的特点是一个显著的优势。"}}
{"id": "2506.07400", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "authors": ["Philip Liu", "Sparsh Bansal", "Jimmy Dinh", "Aditya Pawar", "Ramani Satishkumar", "Shail Desai", "Neeraj Gupta", "Xin Wang", "Shu Hu"], "summary": "The integration of deep learning-based glaucoma detection with large language\nmodels (LLMs) presents an automated strategy to mitigate ophthalmologist\nshortages and improve clinical reporting efficiency. However, applying general\nLLMs to medical imaging remains challenging due to hallucinations, limited\ninterpretability, and insufficient domain-specific medical knowledge, which can\npotentially reduce clinical accuracy. Although recent approaches combining\nimaging models with LLM reasoning have improved reporting, they typically rely\non a single generalist agent, restricting their capacity to emulate the diverse\nand complex reasoning found in multidisciplinary medical teams. To address\nthese limitations, we propose MedChat, a multi-agent diagnostic framework and\nplatform that combines specialized vision models with multiple role-specific\nLLM agents, all coordinated by a director agent. This design enhances\nreliability, reduces hallucination risk, and enables interactive diagnostic\nreporting through an interface tailored for clinical review and educational\nuse. Code available at https://github.com/Purdue-M2/MedChat.", "comment": "7 pages, 6 figures. Accepted to the 2025 IEEE 8th International\n  Conference on Multimedia Information Processing and Retrieval (MIPR). Code\n  and platform available at https://github.com/Purdue-M2/MedChat", "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.07400v1", "AI": {"title_translation": "MedChat：一个基于大语言模型的多智能体多模态诊断框架", "tldr": "MedChat是一个多智能体框架，结合专业视觉模型和多个特定角色的LLM智能体，旨在解决通用LLM在医疗图像诊断中的局限性，提高诊断准确性和报告效率。", "motivation": "现有深度学习结合LLM的青光眼检测策略面临幻觉、可解释性差和医学知识不足的问题，且单智能体方法无法模拟多学科医疗团队的复杂推理，导致临床准确性受限。", "method": "提出MedChat，一个多智能体诊断框架和平台。它结合了专业视觉模型与多个角色特定的LLM智能体，并通过一个导演智能体进行协调。", "result": "MedChat增强了可靠性，降低了幻觉风险，并通过为临床审查和教育用途量身定制的界面实现了交互式诊断报告。", "conclusion": "MedChat通过其多智能体框架解决了通用LLM在医疗图像诊断中的挑战，提高了诊断的可靠性和报告效率，为医疗影像诊断提供了新的解决方案。", "translation": "深度学习驱动的青光眼检测与大型语言模型（LLM）的整合，提供了一种自动化策略，以缓解眼科医生短缺并提高临床报告效率。然而，将通用LLM应用于医学影像仍然具有挑战性，原因在于幻觉、有限的可解释性以及领域特定医学知识的不足，这些都可能降低临床准确性。尽管近期结合影像模型与LLM推理的方法改善了报告，但它们通常依赖于单一的通用智能体，这限制了它们模仿多学科医疗团队中多样化和复杂推理的能力。为解决这些局限性，我们提出了MedChat，一个多智能体诊断框架和平台，它结合了专业视觉模型与多个角色特定的LLM智能体，所有这些都由一个导演智能体协调。这种设计增强了可靠性，降低了幻觉风险，并通过一个为临床审查和教育用途量身定制的界面实现了交互式诊断报告。代码可在https://github.com/Purdue-M2/MedChat获取。", "summary": "MedChat是一个创新的多智能体框架，旨在通过结合专业视觉模型和多角色LLM智能体来克服通用大型语言模型在医疗影像诊断中的局限性。它通过一个协调导演智能体，增强了诊断的可靠性，减少了幻觉，并支持交互式报告，从而提高了临床准确性和效率，特别是在青光眼检测等领域。", "keywords": "多智能体框架, 大型语言模型, 医疗诊断, 多模态, 青光眼检测", "comments": "MedChat的创新之处在于其多智能体架构，模拟了多学科医疗团队的协作模式，有效解决了单一通用LLM在医学影像诊断中面临的幻觉和领域知识不足问题。其交互式诊断报告界面也具有重要的临床和教育应用价值，为未来医疗AI的发展提供了有益的探索。"}}
{"id": "2506.06487", "title": "BeliefMapNav: 3D Voxel-Based Belief Map for Zero-Shot Object Navigation", "authors": ["Zibo Zhou", "Yue Hu", "Lingkai Zhang", "Zonglin Li", "Siheng Chen"], "summary": "Zero-shot object navigation (ZSON) allows robots to find target objects in\nunfamiliar environments using natural language instructions, without relying on\npre-built maps or task-specific training. Recent general-purpose models, such\nas large language models (LLMs) and vision-language models (VLMs), equip agents\nwith semantic reasoning abilities to estimate target object locations in a\nzero-shot manner. However, these models often greedily select the next goal\nwithout maintaining a global understanding of the environment and are\nfundamentally limited in the spatial reasoning necessary for effective\nnavigation. To overcome these limitations, we propose a novel 3D voxel-based\nbelief map that estimates the target's prior presence distribution within a\nvoxelized 3D space. This approach enables agents to integrate semantic priors\nfrom LLMs and visual embeddings with hierarchical spatial structure, alongside\nreal-time observations, to build a comprehensive 3D global posterior belief of\nthe target's location. Building on this 3D voxel map, we introduce\nBeliefMapNav, an efficient navigation system with two key advantages: i)\ngrounding LLM semantic reasoning within the 3D hierarchical semantics voxel\nspace for precise target position estimation, and ii) integrating sequential\npath planning to enable efficient global navigation decisions. Experiments on\nHM3D, MP3D, and HSSD benchmarks show that BeliefMapNav achieves\nstate-of-the-art (SOTA) Success Rate (SR) and Success weighted by Path Length\n(SPL), with a notable 46.4% SPL improvement over the previous best SR method,\nvalidating its effectiveness and efficiency.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06487v1", "AI": {"title_translation": "BeliefMapNav：基于3D体素置信度图的零样本物体导航", "tldr": "BeliefMapNav提出了一种基于3D体素置信度图的方法，通过整合语义和空间推理来改进零样本物体导航，在多个基准测试中取得了最先进的性能。", "motivation": "现有的零样本物体导航方法（如基于LLM和VLM的模型）在选择下一个目标时缺乏对环境的全局理解和有效的空间推理能力，导致贪婪决策。", "method": "提出了一种新颖的3D体素置信度图，用于估计目标在体素化3D空间中的先验存在分布。该方法将LLM的语义先验、视觉嵌入与分层空间结构及实时观测相结合，构建目标位置的全面3D全局后验置信度。在此基础上，引入BeliefMapNav系统，其优势在于：1）将LLM语义推理锚定在3D分层语义体素空间中以实现精确目标估计；2）整合顺序路径规划以实现高效的全局导航决策。", "result": "BeliefMapNav在HM3D、MP3D和HSSD基准测试中实现了最先进的（SOTA）成功率（SR）和按路径长度加权的成功率（SPL）。相较于此前最佳SR方法，SPL显著提高了46.4%。", "conclusion": "BeliefMapNav通过引入3D体素置信度图，有效克服了现有零样本物体导航方法在空间推理和全局理解方面的局限性，成功整合了语义和空间信息，在导航性能和效率上达到了SOTA水平。", "translation": "零样本物体导航（ZSON）允许机器人在不依赖预建地图或特定任务训练的情况下，使用自然语言指令在陌生环境中找到目标物体。最近的通用模型，如大型语言模型（LLM）和视觉语言模型（VLM），赋予代理零样本估计目标物体位置的语义推理能力。然而，这些模型在没有保持对环境的全局理解的情况下，常常贪婪地选择下一个目标，并且在有效导航所需的空间推理方面存在根本性局限性。为了克服这些限制，我们提出了一种新颖的基于3D体素的置信度图，该图估计目标在体素化3D空间中的先验存在分布。这种方法使代理能够将来自LLM的语义先验和视觉嵌入与分层空间结构以及实时观测相结合，以构建目标位置的全面3D全局后验置信度。在此3D体素图的基础上，我们引入了BeliefMapNav，一个具有两个关键优势的高效导航系统：i）将LLM语义推理 grounding 到3D分层语义体素空间中，以实现精确的目标位置估计，以及ii）整合顺序路径规划以实现高效的全局导航决策。在HM3D、MP3D和HSSD基准上的实验表明，BeliefMapNav实现了最先进的（SOTA）成功率（SR）和按路径长度加权的成功率（SPL），比之前最佳SR方法提高了显著的46.4% SPL，验证了其有效性和效率。", "summary": "本文介绍了BeliefMapNav，一种新颖的零样本物体导航系统。它通过提出一个3D体素置信度图来解决当前基于LLM/VLM方法的局限性，即缺乏全局空间理解。该地图整合了来自LLM的语义先验、视觉嵌入和实时观测，以构建目标位置的全面3D全局后验置信度。BeliefMapNav利用此地图进行精确的目标估计和高效的全局路径规划，在多个基准测试中取得了最先进的成果，显著提高了成功率和路径效率。", "keywords": "零样本物体导航, 3D体素图, 置信度图, LLM, VLM, 空间推理", "comments": "该研究的创新之处在于有效地弥合了LLM/VLM的高级语义推理与导航所需的低级空间理解之间的鸿沟。3D体素置信度图提供了一个关键的全局空间上下文，这是以前的零样本方法所缺乏的，从而实现了更鲁棒和高效的导航。SPL的显著提升也凸显了其实用效率。"}}
{"id": "2506.07135", "title": "Taxonomy of migration scenarios for Qiskit refactoring using LLMs", "authors": ["José Manuel Suárez", "Luís Mariano Bibbó", "Joaquín Bogado", "Alejandro Fernandez"], "summary": "As quantum computing advances, quantum programming libraries' heterogeneity\nand steady evolution create new challenges for software developers. Frequent\nupdates in software libraries break working code that needs to be refactored,\nthus adding complexity to an already complex landscape. These refactoring\nchallenges are, in many cases, fundamentally different from those known in\nclassical software engineering due to the nature of quantum computing software.\nThis study addresses these challenges by developing a taxonomy of quantum\ncircuit's refactoring problems, providing a structured framework to analyze and\ncompare different refactoring approaches. Large Language Models (LLMs) have\nproven valuable tools for classic software development, yet their value in\nquantum software engineering remains unexplored. This study uses LLMs to\ncategorize refactoring needs in migration scenarios between different Qiskit\nversions. Qiskit documentation and release notes were scrutinized to create an\ninitial taxonomy of refactoring required for migrating between Qiskit releases.\nTwo taxonomies were produced: one by expert developers and one by an LLM. These\ntaxonomies were compared, analyzing differences and similarities, and were\nintegrated into a unified taxonomy that reflects the findings of both methods.\nBy systematically categorizing refactoring challenges in Qiskit, the unified\ntaxonomy is a foundation for future research on AI-assisted migration while\nenabling a more rigorous evaluation of automated refactoring techniques.\nAdditionally, this work contributes to quantum software engineering (QSE) by\nenhancing software development workflows, improving language compatibility, and\npromoting best practices in quantum programming.", "comment": "Accepted for publication in ASQC JAIIO 54\n  (https://54jaiio.sadio.org.ar/simposios/)", "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07135v1", "AI": {"title_translation": "使用LLM对Qiskit重构迁移场景进行分类", "tldr": "量子编程库Qiskit的频繁更新导致重构挑战。本研究通过LLM和专家方法构建并统一了Qiskit重构迁移场景的分类法，为AI辅助迁移和量子软件工程奠定基础。", "motivation": "量子计算发展导致量子编程库的异构性和快速演进，频繁的软件更新使得现有代码需要重构，这在量子软件工程中与经典软件工程面临的重构挑战不同，增加了复杂性。LLM在经典软件开发中很有价值，但在量子软件工程中的价值尚未探索。", "method": "本研究开发了量子电路重构问题的分类法，并利用大型语言模型（LLMs）对Qiskit不同版本间的迁移重构需求进行分类。通过审查Qiskit文档和发布说明，创建了重构的初始分类法。生成了由专家和LLM分别构建的两种分类法，并对其进行比较、分析异同，最终整合为一个统一的分类法。", "result": "本研究成功创建了一个统一的Qiskit重构迁移场景分类法，该分类法结合了专家开发者和LLM的分析结果。", "conclusion": "统一的Qiskit重构分类法为未来AI辅助迁移的研究奠定了基础，并能更严格地评估自动化重构技术。此外，这项工作通过增强软件开发工作流、提高语言兼容性及推广最佳实践，对量子软件工程（QSE）做出了贡献。", "translation": "随着量子计算的发展，量子编程库的异构性和持续演进给软件开发人员带来了新的挑战。软件库的频繁更新会破坏现有代码，需要进行重构，从而增加了本已复杂的领域中的复杂性。由于量子计算软件的性质，这些重构挑战在许多情况下与经典软件工程中已知的挑战根本不同。本研究通过开发量子电路重构问题的分类法来应对这些挑战，提供了一个结构化的框架来分析和比较不同的重构方法。大型语言模型（LLMs）已被证明是经典软件开发的宝贵工具，但它们在量子软件工程中的价值尚未被探索。本研究使用LLMs来分类Qiskit不同版本之间迁移场景中的重构需求。对Qiskit文档和发布说明进行了仔细审查，以创建在Qiskit版本之间迁移所需的重构的初始分类法。生成了两种分类法：一种由专家开发人员生成，另一种由LLM生成。对这些分类法进行了比较，分析了差异和相似性，并将其整合为一个统一的分类法，反映了两种方法的结果。通过系统地分类Qiskit中的重构挑战，统一的分类法为未来AI辅助迁移的研究奠定了基础，同时能够更严格地评估自动化重构技术。此外，这项工作通过增强软件开发工作流、提高语言兼容性以及推广量子编程的最佳实践，为量子软件工程（QSE）做出了贡献。", "summary": "本研究旨在解决量子编程库（特别是Qiskit）频繁更新导致的重构挑战。通过结合专家知识和大型语言模型（LLMs），研究人员开发了一个统一的Qiskit重构迁移场景分类法。该分类法系统地识别并组织了重构需求，为未来AI辅助量子软件迁移工具的开发和自动化重构技术的评估提供了基础，并对量子软件工程做出了贡献。", "keywords": "量子计算, Qiskit, 重构, 大型语言模型, 分类法", "comments": "这篇论文通过引入LLM来解决量子软件工程中独特的重构挑战，具有创新性。它提供了一个结构化的分类法，这对于理解和管理量子编程库的快速演进至关重要。统一专家和LLM方法提高了分类法的鲁棒性和实用性，为未来AI在量子软件开发中的应用铺平了道路。"}}
{"id": "2506.06946", "title": "Is Your Training Pipeline Production-Ready? A Case Study in the Healthcare Domain", "authors": ["Daniel Lawand", "Lucas Quaresma", "Roberto Bolgheroni", "Alfredo Goldman", "Renato Cordeiro Ferreira"], "summary": "Deploying a Machine Learning (ML) training pipeline into production requires\nrobust software engineering practices. This differs significantly from\nexperimental workflows. This experience report investigates this challenge in\nSPIRA, a project whose goal is to create an ML-Enabled System (MLES) to\npre-diagnose insufficiency respiratory via speech analysis. The first version\nof SPIRA's training pipeline lacked critical software quality attributes. This\npaper presents an overview of the MLES, then compares three versions of the\narchitecture of the Continuous Training subsystem, which evolved from a Big\nBall of Mud, to a Modular Monolith, towards Microservices. By adopting\ndifferent design principles and patterns to enhance its maintainability,\nrobustness, and extensibility. In this way, the paper seeks to offer insights\nfor both ML Engineers tasked to productionize ML training pipelines and Data\nScientists seeking to adopt MLOps practices.", "comment": "9 pages, 3 figures (2 diagrams, 1 code listing), submitted to the\n  workshop SADIS 2025", "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.06946v1", "AI": {"title_translation": "您的训练管道准备好投入生产了吗？医疗保健领域的一个案例研究", "tldr": "本文通过一个医疗保健项目（SPIRA）的案例研究，探讨了机器学习训练管道如何从初始的“一团糟”演变为微服务架构，强调了生产就绪所需的软件工程实践。", "motivation": "将机器学习训练管道部署到生产环境需要强大的软件工程实践，这与实验性工作流程显著不同。本文旨在调查这一挑战，并为负责将ML训练管道投入生产的ML工程师和寻求采用MLOps实践的数据科学家提供见解。", "method": "本文采用案例研究方法，以SPIRA项目为例，比较了其持续训练子系统架构的三个版本，从“一团糟”演变为模块化单体，再到微服务。通过采用不同的设计原则和模式来增强其可维护性、鲁棒性和可扩展性。", "result": "SPIRA项目的训练管道架构经过演变，从缺乏关键软件质量属性的初始版本，通过采用不同的设计原则和模式，成功提升了可维护性、鲁棒性和可扩展性。", "conclusion": "将ML训练管道部署到生产环境需要采纳强大的软件工程实践和不断演进的架构（如从单体到微服务），这对于ML工程师和数据科学家实现MLOps实践至关重要。", "translation": "将机器学习 (ML) 训练管道部署到生产环境需要强大的软件工程实践。这与实验性工作流程显著不同。这份经验报告调查了 SPIRA 项目中的这一挑战，该项目的目标是创建一个支持 ML 的系统 (MLES)，通过语音分析预诊断呼吸不足。SPIRA 训练管道的第一个版本缺乏关键的软件质量属性。本文概述了 MLES，然后比较了持续训练子系统架构的三个版本，这些版本从“一团糟”演变为模块化单体，再到微服务。通过采用不同的设计原则和模式来增强其可维护性、鲁棒性和可扩展性。通过这种方式，本文旨在为负责将 ML 训练管道投入生产的 ML 工程师和寻求采用 MLOps 实践的数据科学家提供见解。", "summary": "本文是一份经验报告，详细介绍了医疗保健领域SPIRA项目中的机器学习训练管道如何从最初缺乏软件质量属性的版本，通过架构演进（从“一团糟”到模块化单体再到微服务），逐步提升其可维护性、鲁棒性和可扩展性。它强调了在生产环境中部署ML训练管道所需强大的软件工程实践，并为ML工程师和数据科学家提供关于MLOps实践的实用见解。", "keywords": "机器学习, MLOps, 训练管道, 软件工程, 医疗保健, 微服务", "comments": "该论文作为一份实践案例研究非常有价值，它清晰地展示了机器学习训练管道从实验阶段到生产就绪系统的演变过程。它强调了软件工程原则和架构选择（如转向微服务）在实现健壮和可维护的MLOps中的关键作用。其对医疗保健领域的关注增加了特定的相关性。"}}
{"id": "2506.06563", "title": "Securing Traffic Sign Recognition Systems in Autonomous Vehicles", "authors": ["Thushari Hapuarachchi", "Long Dang", "Kaiqi Xiong"], "summary": "Deep Neural Networks (DNNs) are widely used for traffic sign recognition\nbecause they can automatically extract high-level features from images. These\nDNNs are trained on large-scale datasets obtained from unknown sources.\nTherefore, it is important to ensure that the models remain secure and are not\ncompromised or poisoned during training. In this paper, we investigate the\nrobustness of DNNs trained for traffic sign recognition. First, we perform the\nerror-minimizing attacks on DNNs used for traffic sign recognition by adding\nimperceptible perturbations on training data. Then, we propose a data\naugmentation-based training method to mitigate the error-minimizing attacks.\nThe proposed training method utilizes nonlinear transformations to disrupt the\nperturbations and improve the model robustness. We experiment with two\nwell-known traffic sign datasets to demonstrate the severity of the attack and\nthe effectiveness of our mitigation scheme. The error-minimizing attacks reduce\nthe prediction accuracy of the DNNs from 99.90% to 10.6%. However, our\nmitigation scheme successfully restores the prediction accuracy to 96.05%.\nMoreover, our approach outperforms adversarial training in mitigating the\nerror-minimizing attacks. Furthermore, we propose a detection model capable of\nidentifying poisoned data even when the perturbations are imperceptible to\nhuman inspection. Our detection model achieves a success rate of over 99% in\nidentifying the attack. This research highlights the need to employ advanced\ntraining methods for DNNs in traffic sign recognition systems to mitigate the\neffects of data poisoning attacks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06563v1", "AI": {"title_translation": "保障自动驾驶汽车交通标志识别系统安全", "tldr": "本文研究了交通标志识别系统中深度神经网络的鲁棒性，通过引入误差最小化攻击来展示数据投毒的危害，并提出了一种基于数据增强的训练方法和一种检测模型来有效缓解和识别此类攻击，显著提高了模型准确率和检测成功率。", "motivation": "深度神经网络（DNN）广泛应用于交通标志识别，但其训练数据集通常来源于未知来源，这使得模型在训练过程中面临被篡改或投毒的风险。因此，确保模型安全和鲁棒性至关重要。", "method": "首先，通过在训练数据中添加难以察觉的扰动，对用于交通标志识别的DNNs进行误差最小化攻击。其次，提出了一种基于数据增强的训练方法，利用非线性变换来破坏扰动，提高模型鲁棒性以缓解攻击。最后，提出了一种检测模型，即使扰动对人眼不可见，也能识别中毒数据。", "result": "误差最小化攻击将DNN的预测准确率从99.90%降低到10.6%。提出的缓解方案成功地将预测准确率恢复到96.05%，并且优于对抗训练。提出的检测模型在识别攻击方面的成功率超过99%。", "conclusion": "这项研究强调了在交通标志识别系统中，需要采用先进的DNN训练方法来减轻数据投毒攻击的影响。", "translation": "深度神经网络（DNNs）因其能够自动从图像中提取高级特征而被广泛用于交通标志识别。这些DNNs是在从未知来源获得的大规模数据集上训练的。因此，确保模型在训练过程中保持安全，不被损害或投毒至关重要。在本文中，我们研究了用于交通标志识别的DNNs的鲁棒性。首先，我们通过在训练数据上添加难以察觉的扰动，对用于交通标志识别的DNNs执行误差最小化攻击。然后，我们提出了一种基于数据增强的训练方法来缓解误差最小化攻击。所提出的训练方法利用非线性变换来破坏扰动并提高模型鲁棒性。我们使用两个著名的交通标志数据集进行了实验，以证明攻击的严重性和我们缓解方案的有效性。误差最小化攻击将DNNs的预测准确率从99.90%降低到10.6%。然而，我们的缓解方案成功地将预测准确率恢复到96.05%。此外，我们的方法在缓解误差最小化攻击方面优于对抗训练。此外，我们提出了一种检测模型，即使扰动对人眼不可见，也能够识别中毒数据。我们的检测模型在识别攻击方面的成功率超过99%。这项研究强调了在交通标志识别系统中，需要采用先进的DNN训练方法来减轻数据投毒攻击的影响。", "summary": "本研究关注自动驾驶汽车中交通标志识别系统所使用的深度神经网络的安全性与鲁棒性。鉴于训练数据来源可能不明，论文首先通过实施误差最小化攻击展示了数据投毒的严重性（将准确率从99.90%降至10.6%）。为应对此威胁，作者提出了一种基于数据增强的训练方法，通过非线性变换有效恢复了模型准确率至96.05%，并优于传统对抗训练。此外，还开发了一个能够以超过99%成功率识别中毒数据的检测模型。研究强调了为保障交通标志识别系统的安全，采用先进训练方法以缓解数据投毒攻击的必要性。", "keywords": "深度神经网络, 交通标志识别, 数据投毒攻击, 模型鲁棒性, 数据增强", "comments": "本文创新性地探讨了自动驾驶领域交通标志识别系统中深度学习模型的数据投毒攻击问题，并提出了两类有效对策：一是基于数据增强的防御性训练方法，显著提升了模型在投毒攻击下的鲁棒性；二是中毒数据检测模型，能够准确识别隐蔽性攻击。这项工作对于提升自动驾驶系统在恶意攻击下的安全性具有重要意义，其提出的缓解和检测机制为未来安全AI系统的设计提供了宝贵经验。"}}
{"id": "2506.07606", "title": "PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels", "authors": ["Peyman Rostami", "Vahid Rahimzadeh", "Ali Adibi", "Azadeh Shakery"], "summary": "Stance detection identifies the viewpoint expressed in text toward a specific\ntarget, such as a political figure. While previous datasets have focused\nprimarily on tweet-level stances from established platforms, user-level stance\nresources, especially on emerging platforms like Bluesky remain scarce.\nUser-level stance detection provides a more holistic view by considering a\nuser's complete posting history rather than isolated posts. We present the\nfirst stance detection dataset for the 2024 U.S. presidential election,\ncollected from Bluesky and centered on Kamala Harris and Donald Trump. The\ndataset comprises 16,044 user-target stance pairs enriched with engagement\nmetadata, interaction graphs, and user posting histories. PolitiSky24 was\ncreated using a carefully evaluated pipeline combining advanced information\nretrieval and large language models, which generates stance labels with\nsupporting rationales and text spans for transparency. The labeling approach\nachieves 81\\% accuracy with scalable LLMs. This resource addresses gaps in\npolitical stance analysis through its timeliness, open-data nature, and\nuser-level perspective. The dataset is available at\nhttps://doi.org/10.5281/zenodo.15616911", "comment": "The dataset is available at https://doi.org/10.5281/zenodo.15616911", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07606v1", "AI": {"title_translation": "PolitiSky24：带有用户立场标签的美国政治Bluesky数据集", "tldr": "提出了PolitiSky24，这是首个针对2024年美国大选的Bluesky用户级政治立场检测数据集，包含16,044个用户-目标立场对，通过结合信息检索和大型语言模型实现81%的标注准确率。", "motivation": "现有的立场检测数据集主要关注推文级别和传统平台，而Bluesky等新兴平台的用户级立场资源稀缺。用户级立场检测能提供更全面的视角，考虑用户完整的发布历史而非孤立的帖子。", "method": "PolitiSky24数据集通过精心评估的流程创建，该流程结合了高级信息检索和大型语言模型（LLMs），生成带有支持理由和文本跨度的立场标签以提高透明度。", "result": "PolitiSky24是首个针对2024年美国总统选举的Bluesky立场检测数据集，包含16,044个用户-目标立场对，并丰富了参与度元数据、交互图和用户发布历史。该标注方法的准确率达到81%。", "conclusion": "PolitiSky24数据集通过其及时性、开放数据性质和用户级视角，弥补了政治立场分析中用户级和新兴平台数据资源的空白。", "translation": "立场检测旨在识别文本中针对特定目标（如政治人物）表达的观点。虽然以前的数据集主要关注来自已建立平台的推文级别立场，但用户级别立场资源，尤其是在Bluesky等新兴平台上，仍然稀缺。用户级别立场检测通过考虑用户的完整发布历史而非孤立的帖子，提供更全面的视角。我们提出了第一个针对2024年美国总统选举的立场检测数据集，该数据集从Bluesky收集，并以卡马拉·哈里斯和唐纳德·特朗普为中心。该数据集包含16,044个用户-目标立场对，并丰富了参与度元数据、交互图和用户发布历史。PolitiSky24是使用精心评估的管道创建的，该管道结合了高级信息检索和大型语言模型，生成带有支持理由和文本跨度的立场标签，以提高透明度。该标注方法使用可扩展的LLM实现了81%的准确率。该资源通过其及时性、开放数据性质和用户级别视角解决了政治立场分析中的空白。该数据集可在https://doi.org/10.5281/zenodo.15616911获取。", "summary": "本文介绍了PolitiSky24，这是一个针对2024年美国总统选举的Bluesky平台用户级政治立场检测数据集。该数据集克服了现有研究主要关注推文级别和传统平台而缺乏新兴平台用户级资源的不足。PolitiSky24包含16,044个针对卡马拉·哈里斯和唐纳德·特朗普的用户-目标立场对，并提供了丰富的元数据。数据集通过结合信息检索和大型语言模型构建，其标注方法达到了81%的准确率。该资源为政治立场分析提供了及时、开放且用户级的宝贵数据。", "keywords": "政治立场检测, Bluesky, 用户级立场, 数据集, 大型语言模型", "comments": "该论文的创新之处在于它是首个针对新兴平台Bluesky的用户级政治立场数据集，并专注于2024年美国大选，具有高度的及时性。其采用结合信息检索和大型语言模型的标注方法，并提供理由和文本跨度以提高透明度，这在立场检测领域是一个重要的进步。该数据集填补了用户级立场检测资源的空白，对于研究新兴社交媒体平台上的政治观点具有重要意义。"}}
{"id": "2506.06324", "title": "Mapping Human-Agent Co-Learning and Co-Adaptation: A Scoping Review", "authors": ["Shruti Kumar", "Xiaoyu Chen", "Xiaomei Wang"], "summary": "Several papers have delved into the challenges of human-AI-robot co-learning\nand co-adaptation. It has been noted that the terminology used to describe this\ncollaborative relationship in existing studies needs to be more consistent. For\nexample, the prefix \"co\" is used interchangeably to represent both\n\"collaborative\" and \"mutual,\" and the terms \"co-learning\" and \"co-adaptation\"\nare sometimes used interchangeably. However, they can reflect subtle\ndifferences in the focus of the studies. The current scoping review's primary\nresearch question (RQ1) aims to gather existing papers discussing this\ncollaboration pattern and examine the terms researchers use to describe this\nhuman-agent relationship. Given the relative newness of this area of study, we\nare also keen on exploring the specific types of intelligent agents and task\ndomains that have been considered in existing research (RQ2). This exploration\nis significant as it can shed light on the diversity of human-agent\ninteractions, from one-time to continuous learning/adaptation scenarios. It can\nalso help us understand the dynamics of human-agent interactions in different\ntask domains, guiding our expectations towards research situated in dynamic,\ncomplex domains. Our third objective (RQ3) is to investigate the cognitive\ntheories and frameworks that have been utilized in existing studies to measure\nhuman-agent co-learning and co-adaptation. This investigation is crucial as it\ncan help us understand the theoretical underpinnings of human-agent\ncollaboration and adaptation, and it can also guide us in identifying any new\nframeworks proposed specifically for this type of relationship.", "comment": "Abstract accepted to HFES 2024 Annual Meeting", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06324v1", "AI": {"title_translation": "人机协同学习与协同适应性映射：一项范围审查", "tldr": "本范围审查旨在梳理人机协同学习和协同适应性研究中术语的不一致性，并探究智能代理类型、任务领域以及所使用的认知理论和框架。", "motivation": "现有研究中描述人机协同关系（特别是“协同学习”和“协同适应性”）的术语存在不一致性，且该研究领域相对较新，缺乏对智能代理类型、任务领域以及理论框架的系统性考察。", "method": "本研究采用范围审查（scoping review）的方法，旨在回答三个主要研究问题：1. 收集讨论人机协同模式的现有论文，并审查研究人员用于描述这种人机关系的术语；2. 探索现有研究中考虑的智能代理类型和任务领域；3. 调查现有研究中用于衡量人机协同学习和协同适应性的认知理论和框架。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "多篇论文深入探讨了人机-AI-机器人协同学习和协同适应性的挑战。人们注意到，现有研究中用于描述这种协作关系的术语需要更加一致。例如，“co”前缀被交替用于表示“协作”和“相互”，而“协同学习”和“协同适应性”这两个术语有时也互换使用。然而，它们可能反映了研究侧重点的细微差异。当前范围审查的首要研究问题（RQ1）旨在收集讨论这种协作模式的现有论文，并审查研究人员用于描述这种人机关系的术语。鉴于该研究领域相对较新，我们还热衷于探索现有研究中已考虑的智能代理的具体类型和任务领域（RQ2）。这项探索意义重大，因为它能揭示人机交互的多样性，从一次性到持续学习/适应场景。它还可以帮助我们理解不同任务领域中人机交互的动态，指导我们对动态、复杂领域中研究的期望。我们的第三个目标（RQ3）是调查现有研究中已利用的认知理论和框架，以衡量人机协同学习和协同适应性。这项调查至关重要，因为它有助于我们理解人机协作和适应的理论基础，同时也能指导我们识别专门为此类关系提出的任何新框架。", "summary": "本范围审查旨在系统性地梳理人机协同学习与协同适应性研究领域。鉴于当前术语使用不一致的问题，研究将收集相关文献，分析描述人机关系的术语，并探索智能代理类型、任务领域以及支撑该领域研究的认知理论和框架，以期为未来的研究提供清晰的指导和理论基础。", "keywords": "人机协同学习, 协同适应性, 范围审查, 术语一致性, 认知理论", "comments": "该论文通过范围审查的形式，针对人机协同领域中长期存在的术语不一致问题进行了梳理，并系统性地探索了智能代理类型、任务领域和理论框架。这对于新兴且复杂的跨学科领域具有重要意义，有助于标准化概念，并为未来的研究提供更明确的方向和理论支撑，避免概念混淆。"}}
{"id": "2506.07362", "title": "Fluid Antenna-Empowered Receive Spatial Modulation", "authors": ["Xinghao Guo", "Yin Xu", "Dazhi He", "Cixiao Zhang", "Hanjiang Hong", "Kai-Kit Wong", "Chan-Byoung Chae", "Wenjun Zhang", "Yiyan Wu"], "summary": "Fluid antenna (FA), as an emerging antenna technology, fully exploits spatial\ndiversity. This paper integrates FA with the receive spatial modulation (RSM)\nscheme and proposes a novel FA-empowered RSM (FA-RSM) system. In this system,\nthe transmitter is equipped with an FA that simultaneously activates multiple\nports to transmit precoded signals. We address three key challenges in the\nFA-RSM system: port selection, theoretical analysis, and detection. First, for\nport selection, an optimal algorithm from a capacity maximization perspective\nare proposed, followed by two low-complexity alternatives. Second, for\ntheoretical analysis, performance evaluation metrics are provided for port\nselection, which demonstrate that increasing the number of activated ports\nenhances system performance. Third, regarding detection, two low-complexity\ndetectors are proposed. Simulation results confirm that the FA-RSM system\nsignificantly outperforms the conventional RSM system. The proposed\nlow-complexity port selection algorithms facilitate minimal performance\ndegradation. Moreover, while activating additional ports improves performance,\nthe gain gradually saturates due to inherent spatial correlation, highlighting\nthe importance of effective port selection in reducing system complexity and\ncost. Finally, both proposed detectors achieve near-optimal detection\nperformance with low computational complexity, emphasizing the\nreceiver-friendly nature of the FA-RSM system.", "comment": "12 pages, submitted to IEEE Journal", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07362v1", "AI": {"title_translation": "流体天线赋能的接收空间调制", "tldr": "本文提出了一种流体天线赋能的接收空间调制（FA-RSM）系统，解决了端口选择、理论分析和检测等挑战，并通过仿真验证了其优于传统RSM系统，且具有低复杂度。", "motivation": "充分利用空间分集，并将新兴的流体天线技术与接收空间调制（RSM）方案相结合，以提升系统性能。", "method": "本文提出了一种新型的流体天线赋能的接收空间调制（FA-RSM）系统。为解决FA-RSM系统中的端口选择、理论分析和检测三大挑战，研究者首先提出了一种基于容量最大化的最优端口选择算法，并提供了两种低复杂度替代方案。其次，对端口选择进行了理论分析，提供了性能评估指标，并表明增加激活端口数量可提升系统性能。最后，提出了两种低复杂度检测器。", "result": "仿真结果表明，FA-RSM系统显著优于传统的RSM系统。所提出的低复杂度端口选择算法能实现最小的性能下降。激活更多端口可以提高性能，但由于固有的空间相关性，增益会逐渐饱和，这凸显了有效端口选择在降低系统复杂度和成本方面的重要性。此外，所提出的两种检测器都以低计算复杂度实现了接近最优的检测性能。", "conclusion": "FA-RSM系统通过创新的端口选择和低复杂度检测器，显著提升了性能，并强调了有效端口选择对于平衡性能、复杂度和成本的重要性，使其成为一个对接收机友好的系统。", "translation": "流体天线（FA）作为一种新兴的天线技术，充分利用了空间分集。本文将FA与接收空间调制（RSM）方案相结合，提出了一种新颖的流体天线赋能的RSM（FA-RSM）系统。在该系统中，发射器配备了一个FA，同时激活多个端口来传输预编码信号。我们解决了FA-RSM系统中的三个关键挑战：端口选择、理论分析和检测。首先，对于端口选择，提出了一个从容量最大化角度出发的最优算法，随后提出了两种低复杂度替代方案。其次，对于理论分析，提供了端口选择的性能评估指标，这些指标表明增加激活端口的数量可以增强系统性能。第三，关于检测，提出了两种低复杂度检测器。仿真结果证实，FA-RSM系统显著优于传统的RSM系统。所提出的低复杂度端口选择算法有助于实现最小的性能下降。此外，虽然激活额外端口可以提高性能，但由于固有的空间相关性，增益逐渐饱和，这凸显了有效端口选择在降低系统复杂度和成本方面的重要性。最后，所提出的两种检测器都以低计算复杂度实现了接近最优的检测性能，强调了FA-RSM系统对接收机的友好性。", "summary": "本文提出了一种将流体天线（FA）与接收空间调制（RSM）结合的新型FA-RSM系统。该系统通过解决端口选择、理论分析和检测三大挑战，实现了性能的显著提升。研究者提出了最优及低复杂度的端口选择算法，并分析了激活端口数量对性能的影响及饱和现象。同时，设计了两种低复杂度检测器。仿真结果表明，FA-RSM系统性能优于传统RSM，且具有低复杂度、接收机友好的特点。", "keywords": "流体天线, 接收空间调制, 空间分集, 端口选择, 低复杂度检测", "comments": "这篇论文创新性地将新兴的流体天线技术应用于接收空间调制，通过解决关键技术挑战，提升了系统的性能。其提出的低复杂度算法和检测器，对于实际系统部署具有重要意义，尤其是在权衡性能与成本方面提供了有效的解决方案。研究中对空间相关性导致性能增益饱和的揭示，也为未来研究提供了方向。"}}
{"id": "2506.07126", "title": "MAGNet: A Multi-Scale Attention-Guided Graph Fusion Network for DRC Violation Detection", "authors": ["Weihan Lu", "Hong Cai Chen"], "summary": "Design rule checking (DRC) is of great significance for cost reduction and\ndesign efficiency improvement in integrated circuit (IC) designs.\nMachine-learning-based DRC has become an important approach in computer-aided\ndesign (CAD). In this paper, we propose MAGNet, a hybrid deep learning model\nthat integrates an improved U-Net with a graph neural network for DRC violation\nprediction. The U-Net backbone is enhanced with a Dynamic Attention Module\n(DAM) and a Multi-Scale Convolution Module (MSCM) to strengthen its capability\nin extracting fine-grained and multi-scale spatial features. In parallel, we\nconstruct a pixel-aligned graph structure based on chip layout tiles, and apply\na specialized GNN to model the topological relationships among pins. During\ngraph construction, a graph-to-grid mapping is generated to align GNN features\nwith the layout image. In addition, a label amplification strategy is adopted\nduring training to enhance the model's sensitivity to sparse violation\npatterns. Overall, MAGNet effectively combines spatial, semantic, and\nstructural information, achieving improved prediction accuracy and reduced\nfalse positive rates in DRC hotspot detection. Subsequently, through\nincremental training, we achieve a more sensitive discrimination ability for\nhotspots. The results demonstrate that, in comparison with ibUnet, RouteNet,\nand J-Net, MAGnet significantly outperforms these models, achieving substantial\nimprovements in overall performance.", "comment": "9 pages, 12 figures, 2 tables", "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07126v1", "AI": {"title_translation": "MAGNet: 一种用于DRC违规检测的多尺度注意力引导图融合网络", "tldr": "MAGNet是一种混合深度学习模型，结合了改进的U-Net和图神经网络，用于提高集成电路设计中DRC违规检测的准确性并降低误报率。", "motivation": "设计规则检查（DRC）对于集成电路（IC）设计的成本降低和设计效率提高具有重要意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。", "method": "本文提出了MAGNet，一个混合深度学习模型，它将改进的U-Net与图神经网络（GNN）相结合，用于DRC违规预测。U-Net骨干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）进行增强，以提取细粒度和多尺度空间特征。同时，基于芯片布局瓦片构建像素对齐的图结构，并应用专门的GNN来建模引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以将GNN特征与布局图像对齐。此外，训练期间采用标签放大策略，以增强模型对稀疏违规模式的敏感性。随后，通过增量训练，实现了对热点更敏感的判别能力。", "result": "MAGNet有效结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。与ibUnet、RouteNet和J-Net相比，MAGNet显著优于这些模型，在整体性能上取得了实质性改进。", "conclusion": "MAGNet成功地将空间、语义和结构信息结合起来，显著提高了DRC违规检测的准确性和效率，并在与现有模型的比较中表现出优越的性能。", "translation": "设计规则检查（DRC）对于集成电路（IC）设计的成本降低和设计效率提高具有重要意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。在本文中，我们提出了MAGNet，一个混合深度学习模型，它将改进的U-Net与图神经网络相结合，用于DRC违规预测。U-Net骨干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）进行增强，以加强其提取细粒度和多尺度空间特征的能力。同时，我们基于芯片布局瓦片构建了一个像素对齐的图结构，并应用了一个专门的GNN来建模引脚之间的拓扑关系。在图构建过程中，生成了一个图到网格的映射，以将GNN特征与布局图像对齐。此外，在训练期间采用了一种标签放大策略，以增强模型对稀疏违规模式的敏感性。总体而言，MAGNet有效地结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。随后，通过增量训练，我们实现了对热点更敏感的判别能力。结果表明，与ibUnet、RouteNet和J-Net相比，MAGNet显著优于这些模型，在整体性能上取得了实质性改进。", "summary": "本文提出了一种名为MAGNet的混合深度学习模型，旨在提高集成电路设计中的设计规则检查（DRC）违规检测精度。MAGNet结合了改进的U-Net（通过动态注意力模块和多尺度卷积模块增强）和图神经网络（用于建模拓扑关系），并通过图到网格映射和标签放大策略优化训练。实验结果表明，MAGNet在预测准确性和降低误报率方面优于现有模型，有效整合了空间、语义和结构信息。", "keywords": "DRC违规检测, 深度学习, 图神经网络, U-Net, 混合模型", "comments": "MAGNet的创新点在于其混合架构，将卷积神经网络（U-Net）的空间特征提取能力与图神经网络的拓扑关系建模能力相结合。这种融合对于处理复杂的芯片布局数据非常有效，特别是考虑到DRC违规的稀疏性和多尺度性质。此外，动态注意力模块、多尺度卷积模块和标签放大策略是模型性能提升的关键。该研究对于提高IC设计的自动化和效率具有重要意义。"}}
{"id": "2506.06295", "title": "dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching", "authors": ["Zhiyuan Liu", "Yicun Yang", "Yaojie Zhang", "Junjie Chen", "Chang Zou", "Qingyuan Wei", "Shaobo Wang", "Linfeng Zhang"], "summary": "Autoregressive Models (ARMs) have long dominated the landscape of Large\nLanguage Models. Recently, a new paradigm has emerged in the form of\ndiffusion-based Large Language Models (dLLMs), which generate text by\niteratively denoising masked segments. This approach has shown significant\nadvantages and potential. However, dLLMs suffer from high inference latency.\nTraditional ARM acceleration techniques, such as Key-Value caching, are\nincompatible with dLLMs due to their bidirectional attention mechanism. To\naddress this specific challenge, our work begins with a key observation that\ndLLM inference involves a static prompt and a partially dynamic response, where\nmost tokens remain stable across adjacent denoising steps. Based on this, we\npropose dLLM-Cache, a training-free adaptive caching framework that combines\nlong-interval prompt caching with partial response updates guided by feature\nsimilarity. This design enables efficient reuse of intermediate computations\nwithout compromising model performance. Extensive experiments on representative\ndLLMs, including LLaDA 8B and Dream 7B, show that dLLM-Cache achieves up to 9.1\nx speedup over standard inference without compromising output quality. Notably,\nour method brings dLLM inference latency close to that of ARMs under many\nsettings. Codes are provided in the supplementary material and will be released\npublicly on GitHub.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06295v1", "AI": {"title_translation": "dLLM-Cache: 通过自适应缓存加速扩散大型语言模型", "tldr": "dLLM-Cache是一种无需训练的自适应缓存框架，通过结合长间隔提示缓存和基于特征相似度的部分响应更新，将扩散大型语言模型（dLLM）的推理速度提高了9.1倍，使其延迟接近自回归模型。", "motivation": "扩散大型语言模型（dLLMs）尽管具有显著优势和潜力，但其推理延迟较高。传统的自回归模型（ARMs）加速技术（如键值缓存）由于dLLMs的双向注意力机制而无法兼容。", "method": "基于dLLM推理中静态提示和部分动态响应的观察，提出了dLLM-Cache。这是一种无需训练的自适应缓存框架，它结合了长间隔提示缓存和由特征相似度引导的部分响应更新，以高效地重用中间计算。", "result": "在LLaDA 8B和Dream 7B等代表性dLLMs上进行的大量实验表明，dLLM-Cache在不影响输出质量的情况下，比标准推理实现了高达9.1倍的加速。值得注意的是，在许多设置下，该方法使dLLM的推理延迟接近ARMs。", "conclusion": "dLLM-Cache框架有效地解决了扩散大型语言模型的推理延迟问题，通过自适应缓存显著提高了推理速度，使其性能与自回归模型相媲美。", "translation": "自回归模型（ARMs）长期以来主导着大型语言模型的格局。最近，一种新的范式以扩散大型语言模型（dLLMs）的形式出现，它通过迭代去噪掩码片段来生成文本。这种方法显示出显著的优势和潜力。然而，dLLMs面临高推理延迟的问题。传统的ARM加速技术，如键值缓存，由于其双向注意力机制，与dLLMs不兼容。为了解决这一特定挑战，我们的工作从一个关键观察开始：dLLM推理涉及静态提示和部分动态响应，其中大多数令牌在相邻去噪步骤中保持稳定。基于此，我们提出了dLLM-Cache，一个无需训练的自适应缓存框架，它结合了长间隔提示缓存和由特征相似度引导的部分响应更新。这种设计能够在不影响模型性能的情况下高效地重用中间计算。在LLaDA 8B和Dream 7B等代表性dLLMs上进行的大量实验表明，dLLM-Cache比标准推理实现了高达9.1倍的加速，且不影响输出质量。值得注意的是，我们的方法在许多设置下使dLLM的推理延迟接近ARMs。代码已在补充材料中提供，并将公开发布在GitHub上。", "summary": "本文提出了一种名为dLLM-Cache的无需训练的自适应缓存框架，旨在解决扩散大型语言模型（dLLMs）高推理延迟的问题。研究发现，dLLM推理涉及静态提示和部分动态响应，其中大部分令牌在相邻去噪步骤中保持稳定。基于此，dLLM-Cache通过结合长间隔提示缓存和由特征相似度引导的部分响应更新，实现了中间计算的高效重用。实验结果表明，dLLM-Cache在LLaDA 8B和Dream 7B等模型上实现了高达9.1倍的加速，且不影响输出质量，使dLLM的推理延迟接近自回归模型。", "keywords": "dLLM-Cache, 扩散大型语言模型, 自适应缓存, 推理延迟, 加速", "comments": "dLLM-Cache的创新之处在于其针对dLLM双向注意力机制的特性，提出了一种不同于传统ARM缓存策略的自适应缓存方法。该方法通过识别推理过程中的静态和动态部分，并结合特征相似度进行智能更新，实现了显著的性能提升。其无需训练的特性也降低了部署的复杂性。该研究对于推动dLLM在实际应用中的普及具有重要意义，因为它有效解决了dLLM面临的主要性能瓶颈。"}}
{"id": "2506.06390", "title": "Benchmarking Large Language Models on Homework Assessment in Circuit Analysis", "authors": ["Liangliang Chen", "Zhihao Qin", "Yiming Guo", "Jacqueline Rohde", "Ying Zhang"], "summary": "Large language models (LLMs) have the potential to revolutionize various\nfields, including code development, robotics, finance, and education, due to\ntheir extensive prior knowledge and rapid advancements. This paper investigates\nhow LLMs can be leveraged in engineering education. Specifically, we benchmark\nthe capabilities of different LLMs, including GPT-3.5 Turbo, GPT-4o, and Llama\n3 70B, in assessing homework for an undergraduate-level circuit analysis\ncourse. We have developed a novel dataset consisting of official reference\nsolutions and real student solutions to problems from various topics in circuit\nanalysis. To overcome the limitations of image recognition in current\nstate-of-the-art LLMs, the solutions in the dataset are converted to LaTeX\nformat. Using this dataset, a prompt template is designed to test five metrics\nof student solutions: completeness, method, final answer, arithmetic error, and\nunits. The results show that GPT-4o and Llama 3 70B perform significantly\nbetter than GPT-3.5 Turbo across all five metrics, with GPT-4o and Llama 3 70B\neach having distinct advantages in different evaluation aspects. Additionally,\nwe present insights into the limitations of current LLMs in several aspects of\ncircuit analysis. Given the paramount importance of ensuring reliability in\nLLM-generated homework assessment to avoid misleading students, our results\nestablish benchmarks and offer valuable insights for the development of a\nreliable, personalized tutor for circuit analysis -- a focus of our future\nwork. Furthermore, the proposed evaluation methods can be generalized to a\nbroader range of courses for engineering education in the future.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06390v1", "AI": {"title_translation": "大型语言模型在电路分析作业评估中的基准测试", "tldr": "本文评估了GPT-3.5 Turbo、GPT-4o和Llama 3 70B等大型语言模型在电路分析本科作业评估中的能力，并开发了一个LaTeX格式的新数据集。结果显示GPT-4o和Llama 3 70B表现优于GPT-3.5 Turbo。", "motivation": "大型语言模型（LLM）具有彻底改变包括教育在内各个领域的潜力，因为它们拥有广泛的先验知识和快速发展。本文旨在探究LLM如何在工程教育中发挥作用，特别是评估它们在电路分析作业评估中的能力。", "method": "研究人员开发了一个包含官方参考答案和真实学生答案的LaTeX格式数据集，以克服LLM图像识别的局限性。设计了一个提示模板来测试学生答案的五个指标：完整性、方法、最终答案、算术错误和单位。对GPT-3.5 Turbo、GPT-4o和Llama 3 70B进行了基准测试。", "result": "GPT-4o和Llama 3 70B在所有五个指标上的表现均显著优于GPT-3.5 Turbo，且两者在不同评估方面各有优势。研究还揭示了当前LLM在电路分析某些方面的局限性。", "conclusion": "本研究的结果为开发可靠、个性化的电路分析导师建立了基准并提供了宝贵的见解。此外，所提出的评估方法未来可以推广到更广泛的工程教育课程中。", "translation": "大型语言模型（LLM）由于其广泛的先验知识和快速发展，有潜力彻底改变包括代码开发、机器人技术、金融和教育在内的各个领域。本文研究了LLM如何在工程教育中发挥作用。具体来说，我们对不同LLM（包括GPT-3.5 Turbo、GPT-4o和Llama 3 70B）在评估本科电路分析课程作业方面的能力进行了基准测试。我们开发了一个新颖的数据集，其中包含电路分析中各种问题的官方参考解决方案和真实学生解决方案。为了克服当前最先进LLM在图像识别方面的局限性，数据集中的解决方案被转换为LaTeX格式。使用该数据集，设计了一个提示模板来测试学生解决方案的五个指标：完整性、方法、最终答案、算术错误和单位。结果显示，GPT-4o和Llama 3 70B在所有五个指标上的表现均显著优于GPT-3.5 Turbo，其中GPT-4o和Llama 3 70B在不同评估方面各有独特优势。此外，我们还提出了当前LLM在电路分析几个方面的局限性。鉴于确保LLM生成的作业评估的可靠性以避免误导学生至关重要，我们的结果建立了基准，并为开发可靠的个性化电路分析导师（这是我们未来工作的重点）提供了宝贵的见解。此外，所提出的评估方法未来可以推广到更广泛的工程教育课程中。", "summary": "本研究评估了大型语言模型（LLM）在本科电路分析作业评估中的潜力。通过开发一个包含LaTeX格式解决方案的新数据集，并针对完整性、方法、最终答案、算术错误和单位等五个指标设计评估模板，研究人员对GPT-3.5 Turbo、GPT-4o和Llama 3 70B进行了基准测试。结果表明，GPT-4o和Llama 3 70B的表现显著优于GPT-3.5 Turbo，且各自在不同评估方面展现出优势。文章还指出了当前LLM在电路分析中的局限性，并强调了确保评估可靠性的重要性，为未来开发个性化电路分析导师奠定了基础，并提出了可推广的评估方法。", "keywords": "大型语言模型, 作业评估, 电路分析, 工程教育, 基准测试", "comments": "该论文通过构建特定领域的LaTeX格式数据集和细致的评估指标，为LLM在工程教育中的应用提供了一个有价值的基准。其创新之处在于克服了LLM在图像识别方面的局限性，并针对作业评估的多个维度进行量化。研究结果不仅揭示了不同LLM在教育应用中的性能差异，也明确指出了其当前局限性，对未来开发可靠的教育辅助工具具有指导意义。该研究的通用性也使其方法可以推广到其他工程学科。"}}
{"id": "2506.07574", "title": "New Limits on Distributed Quantum Advantage: Dequantizing Linear Programs", "authors": ["Alkida Balliu", "Corinna Coupette", "Antonio Cruciani", "Francesco d'Amore", "Massimo Equi", "Henrik Lievonen", "Augusto Modanese", "Dennis Olivetti", "Jukka Suomela"], "summary": "In this work, we give two results that put new limits on distributed quantum\nadvantage in the context of the LOCAL model of distributed computing. First, we\nshow that there is no distributed quantum advantage for any linear program. Put\notherwise, if there is a quantum-LOCAL algorithm $\\mathcal{A}$ that finds an\n$\\alpha$-approximation of some linear optimization problem $\\Pi$ in $T$\ncommunication rounds, we can construct a classical, deterministic LOCAL\nalgorithm $\\mathcal{A}'$ that finds an $\\alpha$-approximation of $\\Pi$ in $T$\nrounds. As a corollary, all classical lower bounds for linear programs,\nincluding the KMW bound, hold verbatim in quantum-LOCAL. Second, using the\nabove result, we show that there exists a locally checkable labeling problem\n(LCL) for which quantum-LOCAL is strictly weaker than the classical\ndeterministic SLOCAL model. Our results extend from quantum-LOCAL also to\nfinitely dependent and non-signaling distributions, and one of the corollaries\nof our work is that the non-signaling model and the SLOCAL model are\nincomparable in the context of LCL problems: By prior work, there exists an LCL\nproblem for which SLOCAL is strictly weaker than the non-signaling model, and\nour work provides a separation in the opposite direction.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.07574v1", "AI": {"title_translation": "分布式量子优势的新限制：线性程序的去量子化", "tldr": "本研究表明，在分布式计算的LOCAL模型中，线性程序不存在分布式量子优势，即任何量子-LOCAL算法都可以被等效的经典确定性LOCAL算法替代。此外，对于某些局部可检查标签问题（LCL），量子-LOCAL模型比经典的SLOCAL模型更弱。", "motivation": "本研究旨在探讨在分布式计算的LOCAL模型中，分布式量子优势的局限性。", "method": "研究通过证明任何线性程序的量子-LOCAL算法都可以被去量子化为具有相同近似度和通信轮次的经典、确定性LOCAL算法。在此基础上，利用这一结果证明了存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL严格弱于经典的确定性SLOCAL模型。", "result": "1. 对于任何线性程序，不存在分布式量子优势。如果存在一个在T轮通信中找到线性优化问题$\\Pi$的$\\alpha$-近似的量子-LOCAL算法$\\mathcal{A}$，则可以构建一个在T轮中找到$\\Pi$的$\\alpha$-近似的经典、确定性LOCAL算法$\\mathcal{A}'$。因此，所有针对线性程序的经典下界，包括KMW界，在量子-LOCAL中也同样适用。\n2. 存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL严格弱于经典的确定性SLOCAL模型。\n这些结果从量子-LOCAL扩展到有限依赖和非信号分布。研究的一个推论是，在LCL问题背景下，非信号模型和SLOCAL模型是不可比较的。", "conclusion": "本研究为分布式量子优势设定了新的限制，尤其是在线性程序和某些局部可检查标签问题（LCL）的背景下，表明在这些情况下，经典算法的能力与量子算法相当甚至更强。", "translation": "在这项工作中，我们给出了两个结果，在分布式计算的LOCAL模型背景下，对分布式量子优势设定了新的限制。首先，我们证明了对于任何线性程序，不存在分布式量子优势。换句话说，如果存在一个量子-LOCAL算法$\\mathcal{A}$，在T轮通信中找到某个线性优化问题$\\Pi$的$\\alpha$-近似，我们就可以构建一个经典、确定性LOCAL算法$\\mathcal{A}'$，在T轮中找到$\\Pi$的$\\alpha$-近似。因此，所有针对线性程序的经典下界，包括KMW界，在量子-LOCAL中也同样适用。其次，利用上述结果，我们证明了存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL严格弱于经典的确定性SLOCAL模型。我们的结果从量子-LOCAL也扩展到有限依赖和非信号分布，我们工作的一个推论是，在LCL问题背景下，非信号模型和SLOCAL模型是不可比较的：根据之前的工作，存在一个LCL问题，SLOCAL严格弱于非信号模型，而我们的工作提供了相反方向的分离。", "summary": "本研究在分布式计算的LOCAL模型中，对分布式量子优势提出了新的限制。核心贡献是证明了对于任何线性程序，不存在分布式量子优势，即量子-LOCAL算法可以被等效的经典LOCAL算法去量子化。基于此，研究进一步揭示了存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL模型甚至比经典的SLOCAL模型更弱。这些发现不仅扩展到其他分布模型，还表明在LCL问题上，非信号模型与SLOCAL模型是不可比较的，为量子计算的分布式优势边界提供了重要见解。", "keywords": "分布式量子优势, 线性程序, LOCAL模型, 去量子化, 局部可检查标签问题", "comments": "这项研究的创新之处在于，它明确地划定了分布式量子计算在特定问题（如线性程序）上的局限性，表明并非所有问题都能从量子并行性中受益。通过“去量子化”证明，它为理解量子算法的真正优势边界提供了理论工具。此外，其在LCL问题上展示的量子-LOCAL模型弱于经典SLOCAL模型的结果，对于理解不同分布式模型的能力差异具有重要意义，挑战了量子计算普遍优于经典的直觉。"}}
{"id": "2506.06380", "title": "Beyond the Norm: A Survey of Synthetic Data Generation for Rare Events", "authors": ["Jingyi Gu", "Xuan Zhang", "Guiling Wang"], "summary": "Extreme events, such as market crashes, natural disasters, and pandemics, are\nrare but catastrophic, often triggering cascading failures across\ninterconnected systems. Accurate prediction and early warning can help minimize\nlosses and improve preparedness. While data-driven methods offer powerful\ncapabilities for extreme event modeling, they require abundant training data,\nyet extreme event data is inherently scarce, creating a fundamental challenge.\nSynthetic data generation has emerged as a powerful solution. However, existing\nsurveys focus on general data with privacy preservation emphasis, rather than\nextreme events' unique performance requirements. This survey provides the first\noverview of synthetic data generation for extreme events. We systematically\nreview generative modeling techniques and large language models, particularly\nthose enhanced by statistical theory as well as specialized training and\nsampling mechanisms to capture heavy-tailed distributions. We summarize\nbenchmark datasets and introduce a tailored evaluation framework covering\nstatistical, dependence, visual, and task-oriented metrics. A central\ncontribution is our in-depth analysis of each metric's applicability in\nextremeness and domain-specific adaptations, providing actionable guidance for\nmodel evaluation in extreme settings. We categorize key application domains and\nidentify underexplored areas like behavioral finance, wildfires, earthquakes,\nwindstorms, and infectious outbreaks. Finally, we outline open challenges,\nproviding a structured foundation for advancing synthetic rare-event research.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06380v1", "AI": {"title_translation": "超越常规：稀有事件合成数据生成综述", "tldr": "本综述针对极端事件的数据稀缺问题，系统回顾了稀有事件合成数据生成方法，包括生成模型和大型语言模型，并提出了一个定制的评估框架，旨在推动该领域的研究。", "motivation": "极端事件（如市场崩盘、自然灾害、流行病）虽然罕见但具灾难性，准确预测和预警至关重要。数据驱动方法需要大量训练数据，但极端事件数据本身稀缺，现有合成数据综述未针对极端事件的独特性能要求。", "method": "本综述系统回顾了生成建模技术和大型语言模型，特别是那些通过统计理论以及专门训练和采样机制增强以捕获重尾分布的模型。总结了基准数据集，并引入了一个涵盖统计、依赖性、视觉和面向任务指标的定制评估框架。深入分析了每个指标在极端性中的适用性及特定领域的适应性。对关键应用领域进行了分类，并识别了未充分探索的领域。最后，概述了开放性挑战。", "result": "本综述首次全面概述了极端事件的合成数据生成。总结了基准数据集，并提出了一个定制的评估框架。深入分析了评估指标在极端情况下的适用性。对关键应用领域进行了分类，并识别了行为金融学、野火、地震、风暴和传染病爆发等未充分探索的领域。概述了开放性挑战。", "conclusion": "本综述为推进合成稀有事件研究奠定了结构化基础。", "translation": "极端事件，如市场崩盘、自然灾害和流行病，虽然罕见但具有灾难性，常常引发互联系统中的连锁故障。准确预测和早期预警有助于最大限度地减少损失并提高准备程度。尽管数据驱动方法为极端事件建模提供了强大的能力，但它们需要大量训练数据，然而极端事件数据本身稀缺，这构成了一个根本性挑战。合成数据生成已成为一个强大的解决方案。然而，现有综述侧重于具有隐私保护通用数据，而非极端事件独特的性能要求。本综述首次全面概述了极端事件的合成数据生成。我们系统地回顾了生成建模技术和大型语言模型，特别是那些通过统计理论以及专门的训练和采样机制增强以捕获重尾分布的模型。我们总结了基准数据集，并引入了一个量身定制的评估框架，涵盖统计、依赖性、视觉和面向任务的指标。一个核心贡献是我们深入分析了每个指标在极端性中的适用性以及特定领域的适应性，为极端情况下的模型评估提供了可操作的指导。我们对关键应用领域进行了分类，并识别了未充分探索的领域，如行为金融学、野火、地震、风暴和传染病爆发。最后，我们概述了开放性挑战，为推进合成稀有事件研究奠定了结构化基础。", "summary": "本综述旨在解决稀有灾难性极端事件建模中数据稀缺的挑战。它全面回顾了针对极端事件的合成数据生成技术，涵盖了生成模型和大型语言模型，特别关注捕获重尾分布的方法。论文引入了一个新的定制评估框架，并深入分析了评估指标的适用性，为极端环境下的模型评估提供了指导。此外，它还对关键应用领域进行了分类，识别了未充分探索的领域，并概述了开放性挑战，为稀有事件合成数据研究提供了结构化基础。", "keywords": "合成数据生成, 稀有事件, 极端事件, 生成建模, 重尾分布", "comments": "本论文具有高度相关性，因为它解决了极端事件建模中数据稀缺的关键问题。其创新之处在于作为首个专门针对极端事件合成数据生成的综述，填补了现有文献的空白。论文提出的定制评估框架和对重尾分布指标适用性的深入分析对于实际应用具有重要价值。通过识别未充分探索的领域和开放性挑战，它也为未来的研究提供了明确的方向。"}}
{"id": "2506.06604", "title": "Scoring the Unscorables: Cyber Risk Assessment Beyond Internet Scans", "authors": ["Armin Sarabi", "Manish Karir", "Mingyan Liu"], "summary": "In this paper we present a study on using novel data types to perform cyber\nrisk quantification by estimating the likelihood of a data breach. We\ndemonstrate that it is feasible to build a highly accurate cyber risk\nassessment model using public and readily available technology signatures\nobtained from crawling an organization's website. This approach overcomes the\nlimitations of previous similar approaches that relied on large-scale IP\naddress based scanning data, which suffers from incomplete/missing IP address\nmappings as well as the lack of such data for large numbers of small and\nmedium-sized organizations (SMEs). In comparison to scan data, technology\ndigital signature data is more readily available for millions of SMEs. Our\nstudy shows that there is a strong relationship between these technology\nsignatures and an organization's cybersecurity posture. In cross-validating our\nmodel using different cyber incident datasets, we also highlight the key\ndifferences between ransomware attack victims and the larger population of\ncyber incident and data breach victims.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06604v1", "AI": {"title_translation": "难以评分者的评分：超越互联网扫描的网络风险评估", "tldr": "本文提出了一种使用从组织网站爬取的技术签名来评估网络风险（特别是数据泄露可能性）的新方法，克服了传统IP扫描数据的局限性，并对模型进行了验证。", "motivation": "传统的网络风险评估方法依赖于基于IP地址的大规模扫描数据，但这种数据存在IP地址映射不完整/缺失以及大量中小型组织（SMEs）缺乏此类数据的局限性。", "method": "本文研究了使用新型数据类型进行网络风险量化，通过估计数据泄露的可能性。具体方法是使用从组织网站爬取到的公开且易于获取的技术签名来构建网络风险评估模型，并使用不同的网络事件数据集对模型进行交叉验证。", "result": "证明了使用技术签名构建高精度网络风险评估模型是可行的。研究显示技术签名与组织的网络安全态势之间存在强烈的关系。交叉验证模型还揭示了勒索软件攻击受害者与更广泛的网络事件和数据泄露受害者之间的关键差异。", "conclusion": "本文证明了使用从网站获取的技术签名来构建高精度网络风险评估模型是可行的，并且这些签名与组织的网络安全态势之间存在强烈的关系。", "translation": "在本文中，我们提出了一项关于使用新型数据类型通过估计数据泄露的可能性来执行网络风险量化的研究。我们证明，利用从组织网站爬取获得的公开且易于获取的技术签名，构建一个高度准确的网络风险评估模型是可行的。这种方法克服了之前依赖于大规模IP地址扫描数据（这些数据存在IP地址映射不完整/缺失以及大量中小型组织（SMEs）缺乏此类数据的问题）的类似方法的局限性。与扫描数据相比，技术数字签名数据更容易为数百万中小企业获取。我们的研究表明，这些技术签名与组织的网络安全态势之间存在很强的关系。在利用不同的网络事件数据集对我们的模型进行交叉验证时，我们还强调了勒索软件攻击受害者与更广泛的网络事件和数据泄露受害者之间的关键差异。", "summary": "本文提出了一种创新的网络风险评估方法，通过分析从组织网站获取的公开技术签名来量化数据泄露的可能性。该方法解决了传统基于IP扫描数据在数据完整性和中小企业覆盖方面的不足，并证明了其构建高精度模型的普适性。研究发现技术签名与网络安全态势强相关，并通过交叉验证揭示了不同网络攻击受害者群体的特征。", "keywords": "网络风险评估, 技术签名, 数据泄露, 中小企业, 网络安全态势", "comments": "这篇论文通过引入“技术签名”这一新颖的数据类型来克服传统网络扫描数据的局限性，特别是在覆盖中小型企业方面的不足，具有创新性。它提供了一种更易于获取和扩展的网络风险评估方法，对于提升中小企业的网络安全量化能力具有重要意义。"}}
{"id": "2506.07935", "title": "Diffusion of Responsibility in Collective Decision Making", "authors": ["Pavel Naumov", "Jia Tao"], "summary": "The term \"diffusion of responsibility'' refers to situations in which\nmultiple agents share responsibility for an outcome, obscuring individual\naccountability. This paper examines this frequently undesirable phenomenon in\nthe context of collective decision-making mechanisms.\n  The work shows that if a decision is made by two agents, then the only way to\navoid diffusion of responsibility is for one agent to act as a \"dictator'',\nmaking the decision unilaterally. In scenarios with more than two agents, any\ndiffusion-free mechanism is an \"elected dictatorship'' where the agents elect a\nsingle agent to make a unilateral decision.\n  The technical results are obtained by defining a bisimulation of\ndecision-making mechanisms, proving that bisimulation preserves\nresponsibility-related properties, and establishing the results for a smallest\nbisimular mechanism.", "comment": null, "cate": "cs.MA", "url": "http://arxiv.org/abs/2506.07935v1", "AI": {"title_translation": "集体决策中的责任分散", "tldr": "在集体决策中，责任分散是一个常见问题。研究表明，要避免责任分散，唯一的途径是采取“独裁者”或“选举独裁”的决策机制。", "motivation": "本文旨在探究集体决策机制中常见的、不受欢迎的“责任分散”现象。", "method": "通过定义决策机制的“双模拟”（bisimulation），证明双模拟能保留与责任相关的属性，并为最小的双模拟机制建立了结果。", "result": "研究表明，如果决策由两个主体做出，避免责任分散的唯一方法是其中一个主体充当“独裁者”单方面做出决策。在主体多于两个的场景中，任何无责任分散的机制都是“选举独裁”，即主体选举一个单一主体进行单方面决策。", "conclusion": "在集体决策中，要避免责任分散，必然导致某种形式的单方面决策，即独裁或选举独裁。", "translation": "“责任分散”一词指的是多个主体分担某个结果的责任，从而模糊了个人问责的情况。本文探讨了集体决策机制中这种经常不受欢迎的现象。研究表明，如果决策由两个主体做出，那么避免责任分散的唯一方法是其中一个主体充当“独裁者”，单方面做出决策。在主体多于两个的场景中，任何无责任分散的机制都是“选举独裁”，即主体选举一个单一主体进行单方面决策。技术结果是通过定义决策机制的“双模拟”获得的，证明双模拟保留了与责任相关的属性，并为最小的双模拟机制建立了结果。", "summary": "本文探讨了集体决策中责任分散的现象，该现象模糊了个人问责。研究发现，在双主体决策中，避免责任分散的唯一方式是其中一方充当独裁者。在多主体场景中，任何无责任分散的机制都将演变为“选举独裁”，即主体选举一人进行单边决策。这些技术结果是通过定义决策机制的双模拟并证明其责任相关属性的保留性而得出的。", "keywords": "责任分散, 集体决策, 问责制, 独裁, 双模拟", "comments": "这篇论文提出了一个重要的理论论点，即在集体决策中实现清晰的问责制，本质上会导致中心化、单边化的决策结构。这揭示了在追求分布式责任的系统中，问责制与决策形式之间可能存在的根本性权衡。"}}
{"id": "2506.06535", "title": "MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping", "authors": ["Vineet Bhat", "Naman Patel", "Prashanth Krishnamurthy", "Ramesh Karri", "Farshad Khorrami"], "summary": "Robotic manipulation of unseen objects via natural language commands remains\nchallenging. Language driven robotic grasping (LDRG) predicts stable grasp\nposes from natural language queries and RGB-D images. Here we introduce\nMask-guided feature pooling, a lightweight enhancement to existing LDRG\nmethods. Our approach employs a two-stage training strategy: first, a\nvision-language model generates feature maps from CLIP-fused embeddings, which\nare upsampled and weighted by text embeddings to produce segmentation masks.\nNext, the decoder generates separate feature maps for grasp prediction, pooling\nonly token features within these masked regions to efficiently predict grasp\nposes. This targeted pooling approach reduces computational complexity,\naccelerating both training and inference. Incorporating mask pooling results in\na 12% improvement over prior approaches on the OCID-VLG benchmark. Furthermore,\nwe introduce RefGraspNet, an open-source dataset eight times larger than\nexisting alternatives, significantly enhancing model generalization for\nopen-vocabulary grasping. By extending 2D grasp predictions to 3D via depth\nmapping and inverse kinematics, our modular method achieves performance\ncomparable to recent Vision-Language-Action (VLA) models on the LIBERO\nsimulation benchmark, with improved generalization across different task\nsuites. Real-world experiments on a 7 DoF Franka robotic arm demonstrate a 57%\nsuccess rate with unseen objects, surpassing competitive baselines by 7%. Code\nwill be released post publication.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06535v1", "AI": {"title_translation": "MapleGrasp: 面具引导的特征池化用于语言驱动的高效机器人抓取", "tldr": "MapleGrasp通过掩码引导的特征池化和大型数据集，提高了语言驱动机器人抓取（LDRG）的效率、准确性和泛化能力。", "motivation": "通过自然语言命令操纵未见过的物体对机器人来说仍然具有挑战性，且现有语言驱动机器人抓取（LDRG）方法在计算效率和泛化能力方面有待提升。", "method": "本文提出Mask-guided feature pooling，一种两阶段训练策略：首先，视觉-语言模型从CLIP融合的嵌入生成特征图，并结合文本嵌入产生分割掩码；其次，解码器仅在这些掩码区域内池化令牌特征，以高效预测抓取姿态。同时引入了比现有大八倍的RefGraspNet开源数据集，并将2D抓取预测扩展到3D。", "result": "在OCID-VLG基准上，掩码池化使性能比现有方法提高12%。引入了RefGraspNet，一个比现有数据集大8倍的开源数据集。在LIBERO模拟基准上，性能与最新视觉-语言-动作（VLA）模型相当，且在不同任务套件中泛化能力更强。在真实世界7自由度Franka机械臂上，对未见过物体的成功率为57%，超过竞争基线7%。", "conclusion": "MapleGrasp通过其创新的掩码引导特征池化和大规模RefGraspNet数据集，显著提升了语言驱动机器人抓取任务的效率、准确性和泛化能力，并在实际应用中表现出色。", "translation": "通过自然语言命令操纵未见过的物体对机器人来说仍然具有挑战性。语言驱动机器人抓取（LDRG）从自然语言查询和RGB-D图像中预测稳定的抓取姿态。本文介绍了一种轻量级增强现有LDRG方法的技术——掩码引导特征池化。我们的方法采用两阶段训练策略：首先，视觉-语言模型从CLIP融合的嵌入生成特征图，然后通过文本嵌入进行上采样和加权，以生成分割掩码。接下来，解码器为抓取预测生成独立的特征图，仅在这些掩码区域内池化令牌特征，从而高效地预测抓取姿态。这种有针对性的池化方法降低了计算复杂度，加速了训练和推理。在OCID-VLG基准测试中，结合掩码池化使性能比现有方法提高了12%。此外，我们引入了RefGraspNet，一个比现有替代方案大八倍的开源数据集，显著增强了开放词汇抓取模型的泛化能力。通过深度映射和逆运动学将2D抓取预测扩展到3D，我们的模块化方法在LIBERO模拟基准上实现了与最新视觉-语言-动作（VLA）模型相当的性能，并在不同任务套件中具有更好的泛化能力。在7自由度Franka机械臂上的真实世界实验表明，对于未见过的物体，成功率为57%，超过竞争基线7%。代码将在发布后发布。", "summary": "MapleGrasp提出了一种名为掩码引导特征池化的轻量级方法，用于提升语言驱动机器人抓取（LDRG）的效率和性能。该方法采用两阶段训练，利用视觉-语言模型生成分割掩码，并在此掩码区域内高效池化特征以预测抓取姿态。结合新引入的大规模RefGraspNet数据集，MapleGrasp在多个基准测试中展示了显著的性能提升和更强的泛化能力，并在真实世界机器人实验中取得了高成功率。", "keywords": "机器人抓取, 语言驱动, 特征池化, 深度学习, 语义分割", "comments": "这篇论文通过引入“掩码引导特征池化”这一创新机制，有效降低了计算复杂度并提高了语言驱动机器人抓取的效率和准确性。其两阶段训练策略和对CLIP特征的巧妙利用值得关注。此外，RefGraspNet数据集的发布显著推动了开放词汇抓取领域的数据规模和模型泛化能力。在真实世界实验中取得的良好表现也证明了其方法的实用性。"}}
{"id": "2506.07436", "title": "Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition", "authors": ["Nishi Chaudhary", "S M Jamil Uddin", "Sathvik Sharath Chandra", "Anto Ovid", "Alex Albert"], "summary": "The recent emergence of multimodal large language models (LLMs) has\nintroduced new opportunities for improving visual hazard recognition on\nconstruction sites. Unlike traditional computer vision models that rely on\ndomain-specific training and extensive datasets, modern LLMs can interpret and\ndescribe complex visual scenes using simple natural language prompts. However,\ndespite growing interest in their applications, there has been limited\ninvestigation into how different LLMs perform in safety-critical visual tasks\nwithin the construction domain. To address this gap, this study conducts a\ncomparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5,\nGPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify\npotential hazards from real-world construction images. Each model was tested\nunder three prompting strategies: zero-shot, few-shot, and chain-of-thought\n(CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated\nbasic safety context and a hazard source mnemonic, and CoT provided\nstep-by-step reasoning examples to scaffold model thinking. Quantitative\nanalysis was performed using precision, recall, and F1-score metrics across all\nconditions. Results reveal that prompting strategy significantly influenced\nperformance, with CoT prompting consistently producing higher accuracy across\nmodels. Additionally, LLM performance varied under different conditions, with\nGPT-4.5 and GPT-o3 outperforming others in most settings. The findings also\ndemonstrate the critical role of prompt design in enhancing the accuracy and\nconsistency of multimodal LLMs for construction safety applications. This study\noffers actionable insights into the integration of prompt engineering and LLMs\nfor practical hazard recognition, contributing to the development of more\nreliable AI-assisted safety systems.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07436v1", "AI": {"title_translation": "从提示到防护：多模态大型语言模型在施工危险识别中的比较研究", "tldr": "本研究比较了多模态大型语言模型（Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3、Gemini 2.0 Pro）在建筑危险识别中的表现，并评估了零样本、少样本和思维链（CoT）等提示策略。结果显示CoT策略显著提高了准确性，且GPT-4.5和GPT-o3在多数情况下表现最优，强调了提示设计的重要性。", "motivation": "传统的计算机视觉模型依赖于领域特定训练和大量数据集，而多模态大型语言模型（LLMs）为建筑工地视觉危险识别提供了新机遇。然而，目前对不同LLMs在建筑领域安全关键视觉任务中的表现研究有限，本研究旨在弥补这一空白。", "method": "本研究对五种最先进的LLMs（Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3、Gemini 2.0 Pro）进行了比较评估，以测试它们从真实建筑图像中识别潜在危险的能力。每个模型在零样本、少样本和思维链（CoT）三种提示策略下进行测试。通过精确率、召回率和F1分数指标进行定量分析。", "result": "提示策略显著影响了性能，其中思维链（CoT）提示在所有模型中始终产生更高的准确性。LLM的性能在不同条件下有所不同，GPT-4.5和GPT-o3在大多数设置中表现优于其他模型。研究结果还表明，提示设计在提高多模态LLMs用于建筑安全应用的准确性和一致性方面发挥着关键作用。", "conclusion": "本研究为提示工程和LLMs在实际危险识别中的集成提供了可操作的见解，有助于开发更可靠的AI辅助安全系统。", "translation": "多模态大型语言模型（LLMs）的最新出现为改善建筑工地的视觉危险识别带来了新的机遇。与依赖领域特定训练和大量数据集的传统计算机视觉模型不同，现代LLMs可以使用简单的自然语言提示来解释和描述复杂的视觉场景。然而，尽管人们对其应用越来越感兴趣，但对于不同LLMs在建筑领域安全关键视觉任务中的表现研究有限。为了弥补这一空白，本研究对五种最先进的LLMs进行了比较评估：Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3和Gemini 2.0 Pro，以评估它们从真实世界建筑图像中识别潜在危险的能力。每个模型在三种提示策略下进行了测试：零样本（zero-shot）、少样本（few-shot）和思维链（CoT）。零样本提示涉及最少的指令，少样本提示结合了基本的安全上下文和危险源助记符，而CoT则提供了分步推理示例以支撑模型思考。在所有条件下，使用精确率、召回率和F1分数指标进行了定量分析。结果表明，提示策略显著影响了性能，CoT提示在所有模型中始终产生更高的准确性。此外，LLM的性能在不同条件下有所不同，其中GPT-4.5和GPT-o3在大多数设置中表现优于其他模型。研究结果还表明，提示设计在提高多模态LLMs用于建筑安全应用的准确性和一致性方面发挥着关键作用。本研究为提示工程和LLMs在实际危险识别中的集成提供了可操作的见解，有助于开发更可靠的AI辅助安全系统。", "summary": "本研究评估了五种先进的多模态大型语言模型（LLMs），包括Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3和Gemini 2.0 Pro，在建筑危险识别任务中的表现。研究利用真实世界建筑图像，并测试了零样本、少样本和思维链（CoT）三种提示策略。结果显示，CoT提示策略显著提高了模型的识别准确性，且GPT-4.5和GPT-o3在多数情况下表现最优。研究强调了提示设计在提升多模态LLMs在建筑安全应用中准确性和一致性方面的关键作用，为开发更可靠的AI辅助安全系统提供了实用见解。", "keywords": "多模态LLMs, 建筑安全, 危险识别, 提示工程, 思维链", "comments": "这项研究具有创新性，因为它系统地比较了多种尖端的多模态LLMs在一个关键的实际应用（建筑危险识别）中的表现，这是一个尚未充分探索的领域。其对提示策略的关注尤为重要，表明提示工程是释放这些模型在安全应用中全部潜力的关键。研究结果为研究人员和从业者开发更有效的AI驱动安全系统提供了实用指导。"}}
{"id": "2506.06569", "title": "Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models", "authors": ["Yannis Spyridis", "Vasileios Argyriou"], "summary": "Automated sorting is crucial for improving the efficiency and scalability of\ntextile recycling, but accurately identifying material composition and\ndetecting contaminants from sensor data remains challenging. This paper\ninvestigates the use of standard RGB imagery, a cost-effective sensing\nmodality, for key pre-processing tasks in an automated system. We present\ncomputer vision components designed for a conveyor belt setup to perform (a)\nclassification of four common textile types and (b) segmentation of non-textile\nfeatures such as buttons and zippers. For classification, several pre-trained\narchitectures were evaluated using transfer learning and cross-validation, with\nEfficientNetB0 achieving the best performance on a held-out test set with\n81.25\\% accuracy. For feature segmentation, a zero-shot approach combining the\nGrounding DINO open-vocabulary detector with the Segment Anything Model (SAM)\nwas employed, demonstrating excellent performance with a mIoU of 0.90 for the\ngenerated masks against ground truth. This study demonstrates the feasibility\nof using RGB images coupled with modern deep learning techniques, including\ntransfer learning for classification and foundation models for zero-shot\nsegmentation, to enable essential analysis steps for automated textile\nrecycling pipelines.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06569v1", "AI": {"title_translation": "纺织品回收自动化分析：迁移学习与零样本基础模型的应用", "tldr": "本文利用RGB图像、迁移学习和零样本基础模型，实现了纺织品分类和非纺织特征分割，以支持自动化纺织品回收。", "motivation": "自动化分拣对于提高纺织品回收的效率和可扩展性至关重要，但准确识别材料成分和检测污染物仍然具有挑战性。", "method": "使用标准RGB图像，设计计算机视觉组件用于传送带设置，执行(a)四种常见纺织品类型的分类和(b)纽扣、拉链等非纺织特征的分割。分类采用迁移学习评估预训练架构，其中EfficientNetB0表现最佳。特征分割采用结合Grounding DINO和Segment Anything Model (SAM)的零样本方法。", "result": "EfficientNetB0在纺织品分类任务中，在保留测试集上实现了81.25%的准确率。零样本分割方法在生成的掩码与真实值对比时，mIoU达到0.90。", "conclusion": "本研究证明了使用RGB图像结合现代深度学习技术（包括用于分类的迁移学习和用于零样本分割的基础模型）来支持自动化纺织品回收流水线中基本分析步骤的可行性。", "translation": "自动化分拣对于提高纺织品回收的效率和可扩展性至关重要，但准确识别材料成分和从传感器数据中检测污染物仍然具有挑战性。本文研究了使用标准RGB图像这种经济高效的传感模式，用于自动化系统中的关键预处理任务。我们提出了为传送带设置设计的计算机视觉组件，以执行(a)四种常见纺织品类型的分类和(b)纽扣和拉链等非纺织特征的分割。对于分类，使用迁移学习和交叉验证评估了几种预训练架构，其中EfficientNetB0在保留测试集上达到了81.25%的最佳性能。对于特征分割，采用了结合Grounding DINO开放词汇检测器和Segment Anything Model (SAM)的零样本方法，在生成的掩码与真实值对比时，表现出卓越的性能，mIoU为0.90。这项研究证明了使用RGB图像结合现代深度学习技术，包括用于分类的迁移学习和用于零样本分割的基础模型，以实现自动化纺织品回收流水线中基本分析步骤的可行性。", "summary": "本文旨在通过利用成本效益高的RGB图像和先进的深度学习技术，解决纺织品回收自动化分拣中的材料识别和污染物检测难题。研究设计了计算机视觉系统，实现了四种纺织品类型的分类（EfficientNetB0达到81.25%准确率）和非纺织特征（如纽扣、拉链）的零样本分割（Grounding DINO与SAM结合达到0.90 mIoU）。结果证明了该方法在自动化纺织品回收分析中的可行性。", "keywords": "纺织品回收, 自动化分拣, 迁移学习, 零样本分割, 深度学习", "comments": "这项研究通过结合迁移学习和零样本基础模型，为自动化纺织品回收提供了一种创新且经济高效的解决方案。特别是利用RGB图像进行复杂分析，以及零样本分割的应用，展示了其在实际工业应用中的巨大潜力，有助于提高回收效率并减少环境污染。"}}
{"id": "2506.07916", "title": "Refugees' path to legal stability is long and systematically unequal", "authors": ["Ola Ali", "Elma Dervic", "Guillermo Prieto-Viertel", "Carsten Källner", "Rainer Stütz", "Andrea Vismara", "Rafael Prieto-Curiel"], "summary": "Legal systems shape not only the recognition of migrants and refugees but\nalso the pace and stability of their integration. Refugees often shift between\nmultiple legal classifications, a process we refer to as the \"legal journey\".\nThis journey is frequently prolonged and uncertain. Using a network-based\napproach, we analyze legal transitions for over 350,000 migrants in Austria\n(2022 to 2024). Refugees face highly unequal pathways to stability, ranging\nfrom two months for Ukrainians to nine months for Syrians and 20 months for\nAfghans. Women, especially from these regions, are more likely to gain\nprotection; Afghan men wait up to 30 months on average. We also find that those\nwho cross the border without going through official border controls face higher\nexit rates and lower chances of securing stable status. We show that legal\nintegration is not a uniform process, but one structured by institutional\ndesign, procedural entry points, and unequal timelines.", "comment": null, "cate": "physics.soc-ph", "url": "http://arxiv.org/abs/2506.07916v1", "AI": {"title_translation": "难民获得法律稳定性的道路漫长且系统性不平等", "tldr": "难民在奥地利获得法律身份的“法律旅程”漫长且存在系统性不平等，不同国籍和性别面临显著差异，非官方入境者更难获得稳定身份。", "motivation": "法律系统不仅影响移民和难民的认定，还影响他们融入社会的速度和稳定性。难民经常在多种法律分类之间转换，这一“法律旅程”通常漫长且不确定，因此需要分析其模式。", "method": "使用基于网络的方法，分析了2022年至2024年间奥地利超过35万移民的法律过渡过程。", "result": "难民获得稳定身份的途径高度不平等，乌克兰人平均2个月，叙利亚人9个月，阿富汗人20个月。女性，尤其是来自这些地区的女性，更有可能获得保护；阿富汗男性平均等待时间长达30个月。未经官方边境检查入境者面临更高的离境率和更低获得稳定身份的机会。", "conclusion": "法律融合不是一个统一的过程，而是由制度设计、程序切入点和不平等的时程结构化的。", "translation": "法律系统不仅塑造了对移民和难民的承认，也塑造了他们融入社会的速度和稳定性。难民经常在多种法律分类之间转换，我们称之为“法律旅程”。这一旅程通常漫长且不确定。我们采用基于网络的方法，分析了2022年至2024年间奥地利超过35万移民的法律过渡过程。难民在获得稳定身份方面面临高度不平等的途径，乌克兰人只需2个月，叙利亚人9个月，阿富汗人则需20个月。女性，特别是来自这些地区的女性，更有可能获得保护；阿富汗男性平均等待时间长达30个月。我们还发现，未经官方边境检查入境者面临更高的离境率和更低获得稳定身份的机会。我们表明，法律融合并非一个统一的过程，而是由制度设计、程序切入点和不平等的时程所结构化的。", "summary": "该研究分析了奥地利超过35万移民的“法律旅程”，揭示难民获得法律稳定性的过程漫长且存在系统性不平等。研究发现，不同国籍（如乌克兰、叙利亚、阿富汗）和性别（特别是阿富汗男性）的难民在获得保护和稳定身份的时间上存在显著差异。此外，未经官方边境检查入境者面临更高的离境率和更低获得稳定身份的机会。研究强调，法律融合是一个由制度设计和不平等时间线结构化的非统一过程。", "keywords": "难民, 法律稳定性, 移民融合, 不平等, 奥地利", "comments": "这篇论文的创新之处在于其大规模的数据集（超过35万奥地利移民）和基于网络的方法，揭示了难民法律整合过程中的系统性不平等。研究结果对政策制定者具有重要意义，凸显了制度设计、程序入口和不同国籍/性别背景对难民“法律旅程”的深刻影响，为优化难民庇护和融入政策提供了实证依据。"}}
{"id": "2506.06326", "title": "Memory OS of AI Agent", "authors": ["Jiazheng Kang", "Mingming Ji", "Zhe Zhao", "Ting Bai"], "summary": "Large Language Models (LLMs) face a crucial challenge from fixed context\nwindows and inadequate memory management, leading to a severe shortage of\nlong-term memory capabilities and limited personalization in the interactive\nexperience with AI agents. To overcome this challenge, we innovatively propose\na Memory Operating System, i.e., MemoryOS, to achieve comprehensive and\nefficient memory management for AI agents. Inspired by the memory management\nprinciples in operating systems, MemoryOS designs a hierarchical storage\narchitecture and consists of four key modules: Memory Storage, Updating,\nRetrieval, and Generation. Specifically, the architecture comprises three\nlevels of storage units: short-term memory, mid-term memory, and long-term\npersonal memory. Key operations within MemoryOS include dynamic updates between\nstorage units: short-term to mid-term updates follow a dialogue-chain-based\nFIFO principle, while mid-term to long-term updates use a segmented page\norganization strategy. Our pioneering MemoryOS enables hierarchical memory\nintegration and dynamic updating. Extensive experiments on the LoCoMo benchmark\nshow an average improvement of 49.11% on F1 and 46.18% on BLEU-1 over the\nbaselines on GPT-4o-mini, showing contextual coherence and personalized memory\nretention in long conversations. The implementation code is open-sourced at\nhttps://github.com/BAI-LAB/MemoryOS.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06326v1", "AI": {"title_translation": "AI Agent的记忆操作系统", "tldr": "提出MemoryOS，一个受操作系统启发的分层记忆管理系统，解决了LLM长期记忆和个性化交互不足的问题，并在基准测试中显著提升了性能。", "motivation": "大语言模型（LLMs）面临固定上下文窗口和记忆管理不足的关键挑战，导致长期记忆能力严重不足以及AI代理交互体验中个性化受限。", "method": "提出MemoryOS，一个受操作系统记忆管理原理启发的分层存储架构。它包含记忆存储、更新、检索和生成四个关键模块。存储架构分为短期记忆、中期记忆和长期个人记忆三层。更新操作包括短期到中期（基于对话链的FIFO）和中期到长期（分段页面组织策略）。", "result": "在LoCoMo基准测试上，GPT-4o-mini的F1分数平均提高了49.11%，BLEU-1分数平均提高了46.18%，在长对话中显示出上下文连贯性和个性化记忆保留能力。", "conclusion": "MemoryOS通过分层记忆整合和动态更新，有效解决了LLM的长期记忆和个性化交互问题，显著提升了AI代理在长对话中的表现。", "translation": "论文标题：AI Agent的记忆操作系统\n论文摘要：\n大语言模型（LLMs）面临固定上下文窗口和记忆管理不足的关键挑战，导致长期记忆能力严重短缺，以及与AI代理交互体验中的个性化受限。为了克服这一挑战，我们创新性地提出了一个记忆操作系统，即MemoryOS，以实现AI代理全面高效的记忆管理。受操作系统中记忆管理原理的启发，MemoryOS设计了一个分层存储架构，并由四个关键模块组成：记忆存储、更新、检索和生成。具体来说，该架构包含三个层次的存储单元：短期记忆、中期记忆和长期个人记忆。MemoryOS中的关键操作包括存储单元之间的动态更新：短期到中期的更新遵循基于对话链的FIFO原则，而中期到长期的更新则采用分段页面组织策略。我们开创性的MemoryOS实现了分层记忆整合和动态更新。在LoCoMo基准测试上进行的广泛实验表明，GPT-4o-mini的F1分数平均提高了49.11%，BLEU-1分数平均提高了46.18%，超过了基线模型，这在长对话中显示出上下文连贯性和个性化记忆保留能力。实现代码已在https://github.com/BAI-LAB/MemoryOS 开源。", "summary": "本文提出MemoryOS，一个受操作系统启发的分层记忆管理系统，旨在解决大语言模型在长期记忆和个性化交互方面的不足。MemoryOS包含短期、中期和长期记忆单元，并设计了动态更新机制。实验结果表明，MemoryOS在LoCoMo基准测试上显著提升了GPT-4o-mini在长对话中的表现，增强了上下文连贯性和个性化记忆保留。", "keywords": "AI Agent, 记忆操作系统, 大语言模型, 长期记忆, 分层存储", "comments": "这篇论文的创新点在于将操作系统中的记忆管理概念引入到AI Agent的长期记忆管理中，提出分层存储和动态更新机制，为解决LLM上下文窗口限制提供了一个新颖且有效的方法。其性能提升显著，对提升AI Agent的交互体验和个性化能力具有重要意义。"}}
{"id": "2506.07380", "title": "The error-correcting pair for several classes of NMDS linear codes", "authors": ["Dong He", "Zhaohui Zhang", "Qunying Liao"], "summary": "The error-correcting pair is a general algebraic decoding method for linear\ncodes. The near maximal distance separable (NMDS) linear code is a subclass of\nlinear codes and has applications in secret sharing scheme and communication\nsystems due to the efficient performance, thus we focus on the error-correcting\npair of NMDS linear codes. In 2023, He and Liao showed that for an NMDS linear\ncode $\\mathcal{C}$ with minimal distance $2\\ell+1$ or $2\\ell+2$, if\n$\\mathcal{C}$ has an $\\ell$-error-correcting pair $\\left( \\mathcal{A},\n\\mathcal{B} \\right)$, then the parameters of $\\mathcal{A}$ have 6 or 10\npossibilities, respectively.\n  In this manuscript, basing on Product Singleton Bound, we give several\nnecessary conditions for that the NMDS linear code $\\mathcal{C}$ with minimal\ndistance $2\\ell+1$ has an $\\ell$-error-correcting pair $(\\mathcal{A},\n\\mathcal{B})$, where the parameters of $\\mathcal{A}$ is the 1st, 2nd, 4th or\n5th case, then basing on twisted generalized Reed-Solomon codes, we give an\nexample for that the parameters of $\\mathcal{A}$ is the 1st case. Moreover, we\nalso give several necessary conditions for that the NMDS linear code\n$\\mathcal{C}$ with minimal distance $2\\ell+2$ has an $\\ell$-error-correcting\npair $(\\mathcal{A}, \\mathcal{B})$, where the parameters of $\\mathcal{A}$ is the\n2nd, 4th, 7th or 8th case, then we give an example for that the parameters of\n$\\mathcal{A}$ is the 1st or 2nd case, respectively.", "comment": "20 pages", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07380v1", "AI": {"title_translation": "几类NMDS线性码的纠错对", "tldr": "本文研究了几类NMDS线性码的纠错对，并针对不同最小距离的NMDS码，基于Product Singleton Bound给出了其具有纠错对时参数的必要条件和相应的例子。", "motivation": "纠错对是线性码的通用代数解码方法。近最大距离可分（NMDS）线性码是线性码的一个子类，由于其高效的性能，在秘密共享方案和通信系统中具有应用，因此研究NMDS线性码的纠错对具有重要意义。", "method": "本文基于Product Singleton Bound给出了NMDS线性码具有纠错对的几个必要条件。此外，还基于扭曲广义Reed-Solomon码给出了相应的例子。", "result": "对于最小距离为$2\\ell+1$的NMDS线性码，论文给出了其具有$\\ell$-纠错对时$\\mathcal{A}$参数为第1、2、4或5种情况的几个必要条件，并给出了$\\mathcal{A}$参数为第1种情况的例子。对于最小距离为$2\\ell+2$的NMDS线性码，论文给出了其具有$\\ell$-纠错对时$\\mathcal{A}$参数为第2、4、7或8种情况的几个必要条件，并分别给出了$\\mathcal{A}$参数为第1或第2种情况的例子。", "conclusion": "本文为NMDS线性码的纠错对的存在性提供了重要的必要条件，并通过具体例子验证了这些条件，有助于深入理解NMDS码的纠错能力。", "translation": "纠错对是线性码的一种通用代数解码方法。近最大距离可分（NMDS）线性码是线性码的一个子类，由于其高效的性能，在秘密共享方案和通信系统中具有应用，因此我们专注于NMDS线性码的纠错对。2023年，He和Liao表明，对于最小距离为$2\\ell+1$或$2\\ell+2$的NMDS线性码$\\mathcal{C}$，如果$\\mathcal{C}$具有一个$\\ell$-纠错对$\\left( \\mathcal{A}, \\mathcal{B} \\right)$，则$\\mathcal{A}$的参数分别有6种或10种可能性。\\n在本手稿中，我们基于Product Singleton Bound，给出了最小距离为$2\\ell+1$的NMDS线性码$\\mathcal{C}$具有$\\ell$-纠错对$(\\mathcal{A}, \\mathcal{B})$的几个必要条件，其中$\\mathcal{A}$的参数是第1、2、4或5种情况，然后基于扭曲广义Reed-Solomon码，我们给出了$\\mathcal{A}$参数为第1种情况的例子。此外，我们还给出了最小距离为$2\\ell+2$的NMDS线性码$\\mathcal{C}$具有$\\ell$-纠错对$(\\mathcal{A}, \\mathcal{B})$的几个必要条件，其中$\\mathcal{A}$的参数是第2、4、7或8种情况，然后我们分别给出了$\\mathcal{A}$参数为第1或第2种情况的例子。", "summary": "本文深入研究了NMDS线性码的纠错对。基于Product Singleton Bound，作者为最小距离为$2\\ell+1$和$2\\ell+2$的NMDS线性码提供了其具有$\\ell$-纠错对时$\\mathcal{A}$参数的几个必要条件。此外，论文还利用扭曲广义Reed-Solomon码为这些条件提供了具体的例子，从而为理解NMDS码的纠错能力提供了新的见解。", "keywords": "纠错对, NMDS线性码, Product Singleton Bound, 扭曲广义Reed-Solomon码, 必要条件", "comments": "本文在He和Liao (2023) 的工作基础上，进一步细化了NMDS线性码拥有纠错对的条件，通过给出具体的必要条件和构造性例子，对NMDS码的解码理论和应用具有指导意义。"}}
{"id": "2506.07239", "title": "VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code", "authors": ["Raghu Vamshi Hemadri", "Jitendra Bhandari", "Johann Knechtel", "Badri P Gopalan", "Ramesh Narayanaswamy", "Ramesh Karri", "Siddharth Garg"], "summary": "Modern chip design is complex, and there is a crucial need for early-stage\nprediction of key design-quality metrics like timing and routing congestion\ndirectly from Verilog code (a commonly used programming language for hardware\ndesign). It is especially important yet complex to predict individual lines of\ncode that cause timing violations or downstream routing congestion. Prior works\nhave tried approaches like converting Verilog into an intermediate graph\nrepresentation and using LLM embeddings alongside other features to predict\nmodule-level quality, but did not consider line-level quality prediction. We\npropose VeriLoC, the first method that predicts design quality directly from\nVerilog at both the line- and module-level. To this end, VeriLoC leverages\nrecent Verilog code-generation LLMs to extract local line-level and\nmodule-level embeddings, and train downstream classifiers/regressors on\nconcatenations of these embeddings. VeriLoC achieves high F1-scores of\n0.86-0.95 for line-level congestion and timing prediction, and reduces the mean\naverage percentage error from 14% - 18% for SOTA methods down to only 4%. We\nbelieve that VeriLoC embeddings and insights from our work will also be of\nvalue for other predictive and optimization tasks for complex hardware design.", "comment": null, "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07239v1", "AI": {"title_translation": "VeriLoC：基于Verilog代码的硬件设计质量行级别预测", "tldr": "VeriLoC首次实现了从Verilog代码对硬件设计质量（如时序和布线拥塞）进行行级别和模块级别的预测，显著提高了预测精度。", "motivation": "现代芯片设计复杂，急需从Verilog代码早期预测关键设计质量指标，尤其是预测导致时序违规或布线拥塞的单个代码行。现有工作未考虑行级别预测。", "method": "提出VeriLoC，利用Verilog代码生成LLM提取局部行级别和模块级别嵌入，并训练下游分类器/回归器。", "result": "VeriLoC在行级别拥塞和时序预测上取得了0.86-0.95的高F1分数，并将SOTA方法的平均百分比误差从14%-18%降低到仅4%。", "conclusion": "VeriLoC的嵌入和研究成果对于复杂硬件设计的其他预测和优化任务也具有价值。", "translation": "现代芯片设计复杂，迫切需要在早期阶段直接从Verilog代码（一种常用的硬件设计编程语言）预测关键设计质量指标，如时序和布线拥塞。预测导致时序违规或下游布线拥塞的单个代码行尤其重要且复杂。以往的工作尝试了将Verilog转换为中间图表示，并使用LLM嵌入以及其他特征来预测模块级质量，但没有考虑行级质量预测。我们提出了VeriLoC，这是第一个直接从Verilog在行级和模块级预测设计质量的方法。为此，VeriLoC利用最近的Verilog代码生成LLM来提取局部行级和模块级嵌入，并在这些嵌入的串联上训练下游分类器/回归器。VeriLoC在行级拥塞和时序预测方面取得了0.86-0.95的高F1分数，并将SOTA方法的平均百分比误差从14%-18%降低到仅4%。我们相信VeriLoC的嵌入和我们工作的见解对于复杂硬件设计的其他预测和优化任务也具有价值。", "summary": "本文提出了VeriLoC，一种创新的方法，首次实现了从Verilog代码对硬件设计质量（包括时序和布线拥塞）进行行级别和模块级别的预测。该方法利用Verilog代码生成大型语言模型（LLM）来提取代码嵌入，并训练分类器/回归器进行预测。实验结果显示，VeriLoC在行级别预测上F1分数高达0.86-0.95，并将平均百分比误差从14%-18%显著降低至4%，表明其在早期硬件设计质量预测方面的卓越性能。", "keywords": "硬件设计质量, Verilog, 行级别预测, LLM, 时序拥塞", "comments": "VeriLoC的创新之处在于首次将LLM应用于Verilog代码的行级别质量预测，解决了现有方法无法深入到代码行层面的局限。其显著的性能提升预示着在复杂硬件设计早期阶段发现潜在问题、提高设计效率的巨大潜力，对硬件设计自动化领域具有重要意义。"}}
{"id": "2506.06296", "title": "Dynamic Graph CNN with Jacobi Kolmogorov-Arnold Networks for 3D Classification of Point Sets", "authors": ["Hanaa El Afia", "Said Ohamouddou", "Raddouane Chiheb", "Abdellatif El Afia"], "summary": "We introduce Jacobi-KAN-DGCNN, a framework that integrates Dynamic Graph\nConvolutional Neural Network (DGCNN) with Jacobi Kolmogorov-Arnold Networks\n(KAN) for the classification of three-dimensional point clouds. This method\nreplaces Multi-Layer Perceptron (MLP) layers with adaptable univariate\npolynomial expansions within a streamlined DGCNN architecture, circumventing\ndeep levels for both MLP and KAN to facilitate a layer-by-layer comparison. In\ncomparative experiments on the ModelNet40 dataset, KAN layers employing Jacobi\npolynomials outperform the traditional linear layer-based DGCNN baseline in\nterms of accuracy and convergence speed, while maintaining parameter\nefficiency. Our results demonstrate that higher polynomial degrees do not\nautomatically improve performance, highlighting the need for further\ntheoretical and empirical investigation to fully understand the interactions\nbetween polynomial bases, degrees, and the mechanisms of graph-based learning.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06296v1", "AI": {"title_translation": "结合Jacobi Kolmogorov-Arnold网络的动态图CNN用于三维点集分类", "tldr": "本文提出了Jacobi-KAN-DGCNN框架，将DGCNN与Jacobi KAN结合，通过替换MLP层为可变单变量多项式展开，在ModelNet40数据集上实现了三维点云分类性能的提升，并在准确性和收敛速度上优于传统DGCNN基线，同时保持参数效率。", "motivation": "为了提升三维点云分类的性能，本文旨在将动态图卷积神经网络（DGCNN）与Jacobi Kolmogorov-Arnold网络（KAN）结合，通过替换DGCNN中的多层感知机（MLP）层为可适应的单变量多项式展开，以期在准确性和收敛速度上超越传统方法。", "method": "本文提出了Jacobi-KAN-DGCNN框架，该框架将动态图卷积神经网络（DGCNN）与Jacobi Kolmogorov-Arnold网络（KAN）集成。具体方法是，在简化的DGCNN架构中，用可适应的单变量多项式展开替换多层感知机（MLP）层，避免了MLP和KAN的深层结构，以便于逐层比较。", "result": "在ModelNet40数据集上的对比实验表明，采用Jacobi多项式的KAN层在准确性和收敛速度方面均优于传统的基于线性层的DGCNN基线，同时保持了参数效率。结果还显示，更高的多项式次数并不能自动提高性能。", "conclusion": "Jacobi-KAN-DGCNN方法在三维点云分类中展现了潜力，但在准确性和收敛速度上超越了传统DGCNN。然而，更高多项式次数并非总能带来性能提升，这表明需要进一步的理论和实证研究来充分理解多项式基、次数以及基于图学习机制之间的相互作用。", "translation": "我们引入了Jacobi-KAN-DGCNN，这是一个将动态图卷积神经网络（DGCNN）与Jacobi Kolmogorov-Arnold网络（KAN）集成用于三维点云分类的框架。该方法在简化的DGCNN架构中，用可适应的单变量多项式展开替换了多层感知机（MLP）层，避免了MLP和KAN的深层结构，以便于逐层比较。在ModelNet40数据集上的对比实验中，采用Jacobi多项式的KAN层在准确性和收敛速度方面均优于传统的基于线性层的DGCNN基线，同时保持了参数效率。我们的结果表明，更高的多项式次数并不能自动提高性能，这凸显了需要进一步的理论和实证研究，以充分理解多项式基、次数以及基于图学习机制之间的相互作用。", "summary": "本文提出了Jacobi-KAN-DGCNN，一个结合动态图卷积神经网络（DGCNN）和Jacobi Kolmogorov-Arnold网络（KAN）用于三维点云分类的新框架。该方法用可适应的单变量多项式展开替换了DGCNN中的MLP层。实验结果表明，在ModelNet40数据集上，Jacobi KAN层在准确性和收敛速度上优于传统DGCNN，同时保持了参数效率。研究还发现，并非所有更高的多项式次数都能自动提升性能，这指出了未来研究需深入探索多项式基、次数与图学习机制的相互作用。", "keywords": "动态图CNN, Jacobi KAN, 点云分类, ModelNet40, 多项式展开", "comments": "该论文的创新点在于将新颖的Jacobi Kolmogorov-Arnold网络（KAN）与经典的动态图卷积神经网络（DGCNN）相结合，通过替换MLP层为多项式展开，为三维点云分类提供了一种新的方法。这种方法在准确性和收敛速度上的提升，以及参数效率的保持，显示了其潜在的应用价值。然而，论文也指出了一个重要的局限性，即多项式次数与性能之间并非简单的正相关关系，这为未来的理论和实证研究留下了广阔的空间，需要进一步探究多项式基、次数与图学习机制的复杂相互作用。"}}
{"id": "2506.06391", "title": "From Rogue to Safe AI: The Role of Explicit Refusals in Aligning LLMs with International Humanitarian Law", "authors": ["John Mavi", "Diana Teodora Găitan", "Sergio Coronado"], "summary": "Large Language Models (LLMs) are widely used across sectors, yet their\nalignment with International Humanitarian Law (IHL) is not well understood.\nThis study evaluates eight leading LLMs on their ability to refuse prompts that\nexplicitly violate these legal frameworks, focusing also on helpfulness - how\nclearly and constructively refusals are communicated. While most models\nrejected unlawful requests, the clarity and consistency of their responses\nvaried. By revealing the model's rationale and referencing relevant legal or\nsafety principles, explanatory refusals clarify the system's boundaries, reduce\nambiguity, and help prevent misuse. A standardised system-level safety prompt\nsignificantly improved the quality of the explanations expressed within\nrefusals in most models, highlighting the effectiveness of lightweight\ninterventions. However, more complex prompts involving technical language or\nrequests for code revealed ongoing vulnerabilities. These findings contribute\nto the development of safer, more transparent AI systems and propose a\nbenchmark to evaluate the compliance of LLM with IHL.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06391v1", "AI": {"title_translation": "从失控到安全AI：显式拒绝在使LLM与国际人道法保持一致中的作用", "tldr": "本研究评估了大型语言模型（LLM）拒绝违反国际人道法（IHL）提示的能力，发现显式且清晰的拒绝对于AI安全至关重要，且轻量级干预可以改善拒绝质量，但复杂提示仍存在漏洞。", "motivation": "大型语言模型（LLM）已广泛应用，但其与国际人道法（IHL）的对齐情况尚不明确。本研究旨在评估LLM拒绝明确违反这些法律框架的提示的能力。", "method": "研究评估了八个领先的LLM拒绝违反国际人道法（IHL）提示的能力，并重点关注拒绝的清晰度和建设性。同时，研究测试了标准化系统级安全提示对拒绝解释质量的影响。", "result": "大多数模型拒绝了非法请求，但响应的清晰度和一致性各不相同。解释性拒绝（揭示理由并引用法律/安全原则）有助于澄清系统边界并防止滥用。标准化系统级安全提示显著提高了大多数模型中拒绝解释的质量。然而，涉及技术语言或代码请求的更复杂提示仍暴露出持续存在的漏洞。", "conclusion": "本研究的发现有助于开发更安全、更透明的AI系统，并提出了一个评估LLM符合国际人道法（IHL）情况的基准。显式且清晰的拒绝，辅以轻量级干预，对于LLM与IHL的对齐至关重要，尽管在处理复杂情况时仍存在挑战。", "translation": "大型语言模型（LLM）在各个领域得到广泛应用，但它们与国际人道法（IHL）的对齐情况尚不清楚。本研究评估了八个领先的LLM拒绝明确违反这些法律框架的提示的能力，并侧重于有用性——即拒绝的沟通方式是否清晰和具有建设性。虽然大多数模型拒绝了非法请求，但其响应的清晰度和一致性各不相同。通过揭示模型的理由并引用相关法律或安全原则，解释性拒绝阐明了系统的边界，减少了模糊性，并有助于防止滥用。一个标准化的系统级安全提示显著提高了大多数模型中拒绝解释的质量，突出了轻量级干预的有效性。然而，涉及技术语言或代码请求的更复杂提示揭示了持续存在的漏洞。这些发现有助于开发更安全、更透明的AI系统，并提出了一个评估LLM符合IHL情况的基准。", "summary": "本研究评估了八个领先的大型语言模型（LLM）与国际人道法（IHL）的对齐情况，重点测试了它们拒绝违反法律框架提示的能力。研究发现，尽管大多数模型能拒绝非法请求，但其拒绝的清晰度和一致性存在差异。提供理由并引用法律/安全原则的解释性拒绝对于明确系统边界和防止滥用至关重要。一个标准化的系统级安全提示显著提升了大多数模型中拒绝解释的质量，但面对涉及技术语言或代码的复杂提示时，模型仍暴露出漏洞。本研究为开发更安全、更透明的AI系统做出了贡献，并提出了一个评估LLM符合IHL情况的基准。", "keywords": "LLM, 国际人道法, 显式拒绝, AI安全, 基准", "comments": "该研究的创新之处在于关注显式拒绝作为LLM与国际人道法对齐的机制，特别是“解释性拒绝”的概念，这对于提高透明度具有深刻见解。其重要性体现在解决了LLM在敏感应用中的关键安全和伦理问题，并提出了有价值的评估基准。然而，研究也指出，对于复杂提示，简单的干预可能不足以解决所有漏洞，这揭示了未来研究的挑战。"}}
{"id": "2506.07838", "title": "A Terminology for Scientific Workflow Systems", "authors": ["Frédéric Sutera", "Tainã Coleman", "İlkay Altintaş", "Rosa M. Badia", "Bartosz Balis", "Kyle Chard", "Iacopo Colonnelli", "Ewa Deelman", "Paolo Di Tommaso", "Thomas Fahringer", "Carole Goble", "Shantenu Jha", "Daniel S. Katz", "Johannes Köster", "Ulf Leser", "Kshitij Mehta", "Hilary Oliver", "J. -Luc Peterson", "Giovanni Pizzi", "Loïc Pottier", "Raül Sirvent", "Eric Suchyta", "Douglas Thain", "Sean R. Wilkinson", "Justin M. Wozniak", "Rafael Ferreira da Silva"], "summary": "The term scientific workflow has evolved over the last two decades to\nencompass a broad range of compositions of interdependent compute tasks and\ndata movements. It has also become an umbrella term for processing in modern\nscientific applications. Today, many scientific applications can be considered\nas workflows made of multiple dependent steps, and hundreds of workflow\nmanagement systems (WMSs) have been developed to manage and run these\nworkflows. However, no turnkey solution has emerged to address the diversity of\nscientific processes and the infrastructure on which they are implemented.\nInstead, new research problems requiring the execution of scientific workflows\nwith some novel feature often lead to the development of an entirely new WMS. A\ndirect consequence is that many existing WMSs share some salient features,\noffer similar functionalities, and can manage the same categories of workflows\nbut also have some distinct capabilities. This situation makes researchers who\ndevelop workflows face the complex question of selecting a WMS. This selection\ncan be driven by technical considerations, to find the system that is the most\nappropriate for their application and for the resources available to them, or\nother factors such as reputation, adoption, strong community support, or\nlong-term sustainability. To address this problem, a group of WMS developers\nand practitioners joined their efforts to produce a community-based terminology\nof WMSs. This paper summarizes their findings and introduces this new\nterminology to characterize WMSs. This terminology is composed of fives axes:\nworkflow characteristics, composition, orchestration, data management, and\nmetadata capture. Each axis comprises several concepts that capture the\nprominent features of WMSs. Based on this terminology, this paper also presents\na classification of 23 existing WMSs according to the proposed axes and terms.", "comment": null, "cate": "cs.DC", "url": "http://arxiv.org/abs/2506.07838v1", "AI": {"title_translation": "科学工作流系统的术语", "tldr": "鉴于科学工作流系统（WMS）的多样性和选择困难，本文提出了一套社区驱动的WMS术语和分类方法。", "motivation": "科学工作流系统（WMS）种类繁多，功能重叠但也有独特之处，导致研究人员在选择WMS时面临复杂问题，缺乏统一的解决方案来应对科学流程和基础设施的多样性。", "method": "由WMS开发者和实践者组成的团队合作，共同制定了一套社区驱动的WMS术语。该术语包含五个轴：工作流特性、组成、编排、数据管理和元数据捕获。论文还基于此术语对23个现有WMS进行了分类。", "result": "提出了一个由五个轴（工作流特性、组成、编排、数据管理、元数据捕获）组成的社区驱动的WMS术语，并基于此术语对23个现有WMS进行了分类。", "conclusion": "通过引入一套统一的术语和分类方法，本文旨在帮助研究人员更好地理解和选择科学工作流系统，解决WMS多样性带来的挑战。", "translation": "科学工作流这一术语在过去二十年里不断演变，涵盖了广泛的相互依赖的计算任务和数据移动的组合。它也成为了现代科学应用中处理的统称。如今，许多科学应用可以被视为由多个依赖步骤组成的工作流，并且已经开发了数百个工作流管理系统（WMS）来管理和运行这些工作流。然而，尚未出现一种开箱即用的解决方案来解决科学过程及其所实现基础设施的多样性。相反，需要以某种新颖特征执行科学工作流的新研究问题往往会导致全新的WMS的开发。直接的结果是，许多现有WMS共享一些显著特征，提供类似功能，并且可以管理相同类别的工作流，但也具有一些独特的能力。这种情况使得开发工作流的研究人员面临选择WMS的复杂问题。这种选择可能由技术考虑驱动，以找到最适合其应用和可用资源的系统，或由其他因素驱动，如声誉、采用率、强大的社区支持或长期可持续性。为了解决这个问题，一群WMS开发者和实践者共同努力，制定了一套基于社区的WMS术语。本文总结了他们的发现，并介绍了这个新的术语来表征WMS。该术语由五个轴组成：工作流特性、组成、编排、数据管理和元数据捕获。每个轴都包含几个概念，捕捉了WMS的突出特征。基于此术语，本文还根据所提出的轴和术语对23个现有WMS进行了分类。", "summary": "鉴于科学工作流管理系统（WMS）数量众多且功能多样，研究人员在选择合适的系统时面临挑战。本文旨在解决这一问题，通过汇集WMS开发者和实践者的努力，制定了一套社区驱动的WMS术语。该术语包含工作流特性、组成、编排、数据管理和元数据捕获五个核心轴，每个轴下包含多个概念，用于描述WMS的关键特征。基于这套术语，论文还对23个现有WMS进行了分类，以帮助用户更好地理解和选择系统。", "keywords": "科学工作流系统, 术语, 工作流管理系统, 分类, 数据管理", "comments": "这篇论文通过引入一套结构化的社区驱动术语，为混乱且多样化的科学工作流系统领域带来了急需的清晰度。其创新之处在于提供了一个统一的框架来描述和分类WMS，这对于研究人员和开发者在选择、比较和设计系统时都极具价值。这种标准化有助于促进WMS领域的交流和理解，并可能为未来的系统开发提供指导。"}}
{"id": "2506.06532", "title": "Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks", "authors": ["Zijiang Yan", "Hao Zhou", "Jianhua Pei", "Hina Tabassum"], "summary": "Unmanned aerial vehicles (UAVs) have been widely adopted in various\nreal-world applications. However, the control and optimization of multi-UAV\nsystems remain a significant challenge, particularly in dynamic and constrained\nenvironments. This work explores the joint motion and communication control of\nmultiple UAVs operating within integrated terrestrial and non-terrestrial\nnetworks that include high-altitude platform stations (HAPS). Specifically, we\nconsider an aerial highway scenario in which UAVs must accelerate, decelerate,\nand change lanes to avoid collisions and maintain overall traffic flow.\nDifferent from existing studies, we propose a novel hierarchical and\ncollaborative method based on large language models (LLMs). In our approach, an\nLLM deployed on the HAPS performs UAV access control, while another LLM onboard\neach UAV handles motion planning and control. This LLM-based framework\nleverages the rich knowledge embedded in pre-trained models to enable both\nhigh-level strategic planning and low-level tactical decisions. This\nknowledge-driven paradigm holds great potential for the development of\nnext-generation 3D aerial highway systems. Experimental results demonstrate\nthat our proposed collaborative LLM-based method achieves higher system\nrewards, lower operational costs, and significantly reduced UAV collision rates\ncompared to baseline approaches.", "comment": "Accepted in ICML 2025 Workshop on Machine Learning for Wireless\n  Communication and Networks (ML4Wireless)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06532v1", "AI": {"title_translation": "综合天地一体化网络中多无人机运动与通信的分层协作式LLM控制", "tldr": "该研究提出了一种基于LLM的分层协作方法，用于综合天地一体化网络中多无人机的运动和通信控制，并在空中高速公路场景中取得了显著效果。", "motivation": "多无人机系统的控制和优化，尤其是在动态和受限环境中，仍然是一个重大挑战。", "method": "提出了一种新颖的基于大语言模型（LLM）的分层协作方法。一个LLM部署在高空平台站（HAPS）上执行无人机接入控制，而另一个LLM部署在每架无人机上处理运动规划和控制。", "result": "实验结果表明，所提出的协作式LLM方法与基线方法相比，实现了更高的系统奖励、更低的操作成本和显著降低的无人机碰撞率。", "conclusion": "这种知识驱动的范式对于开发下一代3D空中高速公路系统具有巨大潜力。", "translation": "无人机（UAV）已广泛应用于各种实际场景。然而，多无人机系统的控制和优化仍然是一个重大挑战，特别是在动态和受限环境中。这项工作探索了在包含高空平台站（HAPS）的综合天地一体化网络中运行的多无人机的联合运动和通信控制。具体而言，我们考虑了一个空中高速公路场景，其中无人机必须加速、减速和变道以避免碰撞并保持整体交通流量。与现有研究不同，我们提出了一种新颖的基于大语言模型（LLM）的分层协作方法。在我们的方法中，部署在HAPS上的LLM执行无人机接入控制，而部署在每架无人机上的另一个LLM处理运动规划和控制。这种基于LLM的框架利用预训练模型中嵌入的丰富知识，以实现高层战略规划和低层战术决策。这种知识驱动的范式对于开发下一代3D空中高速公路系统具有巨大潜力。实验结果表明，我们提出的协作式LLM方法与基线方法相比，实现了更高的系统奖励、更低的操作成本和显著降低的无人机碰撞率。", "summary": "本文针对综合天地一体化网络中多无人机在动态受限环境下的运动与通信控制挑战，提出了一种新颖的分层协作式LLM（大语言模型）控制框架。该框架将LLM分别部署在高空平台站（HAPS）和每架无人机上，分别负责高层接入控制和低层运动规划。实验结果表明，该方法在空中高速公路场景中能有效提高系统奖励、降低运营成本并显著减少无人机碰撞。", "keywords": "多无人机控制, 大语言模型, 天地一体化网络, 运动规划, 通信控制", "comments": "这篇论文的创新点在于将大语言模型引入到多无人机系统的分层控制中，利用LLM的知识驱动能力来处理复杂的运动和通信协同问题。这种将高层战略规划和低层战术决策相结合的思路，为未来3D空中高速公路系统的发展提供了新的范式，具有重要的研究价值和应用前景。"}}
{"id": "2506.07003", "title": "End-to-End Probabilistic Framework for Learning with Hard Constraints", "authors": ["Utkarsh Utkarsh", "Danielle C. Maddix", "Ruijun Ma", "Michael W. Mahoney", "Yuyang Wang"], "summary": "We present a general purpose probabilistic forecasting framework,\nProbHardE2E, to learn systems that can incorporate operational/physical\nconstraints as hard requirements. ProbHardE2E enforces hard constraints by\nexploiting variance information in a novel way; and thus it is also capable of\nperforming uncertainty quantification (UQ) on the model. Our methodology uses a\nnovel differentiable probabilistic projection layer (DPPL) that can be combined\nwith a wide range of neural network architectures. This DPPL allows the model\nto learn the system in an end-to-end manner, compared to other approaches where\nthe constraints are satisfied either through a post-processing step or at\ninference. In addition, ProbHardE2E can optimize a strictly proper scoring\nrule, without making any distributional assumptions on the target, which\nenables it to obtain robust distributional estimates (in contrast to existing\napproaches that generally optimize likelihood-based objectives, which are\nheavily biased by their distributional assumptions and model choices); and it\ncan incorporate a range of non-linear constraints (increasing the power of\nmodeling and flexibility). We apply ProbHardE2E to problems in learning partial\ndifferential equations with uncertainty estimates and to probabilistic\ntime-series forecasting, showcasing it as a broadly applicable general setup\nthat connects these seemingly disparate domains.", "comment": "46 pages, 5 figures, 10 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07003v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06635", "title": "TrustConnect: An In-Vehicle Anomaly Detection Framework through Topology-Based Trust Rating", "authors": ["Ayan Roy", "Jeetkumar Patel", "Rik Chakraborti", "Shudip Datta"], "summary": "Modern vehicles are equipped with numerous in-vehicle components that\ninteract with the external environment through remote communications and\nservices, such as Bluetooth and vehicle-to-infrastructure communication. These\ncomponents form a network, exchanging information to ensure the proper\nfunctioning of the vehicle. However, the presence of false or fabricated\ninformation can disrupt the vehicle's performance. Given that these components\nare interconnected, erroneous data can propagate throughout the network,\npotentially affecting other components and leading to catastrophic\nconsequences. To address this issue, we propose TrustConnect, a framework\ndesigned to assess the trustworthiness of a vehicle's in-vehicle network by\nevaluating the trust levels of individual components under various network\nconfigurations. The proposed framework leverages the interdependency of all the\nvehicle's components, along with the correlation of their values and their\nvulnerability to remote injection based on the outside exposure of each\ncomponent, to determine the reliability of the in-vehicle network. The\neffectiveness of the proposed framework has been validated through programming\nsimulations conducted across various scenarios using a random distribution of\nan in-vehicle network graph generated with the Networkx package in Python.", "comment": "To Appear in 2025 the IEEE 101st Vehicular Technology Conference:\n  VTC2025-Spring", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06635v1", "AI": {"title_translation": "TrustConnect：一种基于拓扑信任评级的车载异常检测框架", "tldr": "TrustConnect是一种车载异常检测框架，通过评估组件信任度来识别和防止错误信息传播，从而提升车辆可靠性。", "motivation": "现代车辆中，车载组件通过外部通信与外部环境交互，但虚假或伪造信息的存在可能扰乱车辆性能，并可能在网络中传播，导致灾难性后果。", "method": "本文提出了TrustConnect框架，旨在通过评估各种网络配置下单个组件的信任级别来评估车辆车载网络的信任度。该框架利用所有车辆组件的相互依赖性、其值的相关性以及基于每个组件外部暴露的远程注入脆弱性来确定车载网络的可靠性。", "result": "所提出的框架的有效性已通过使用Python的Networkx包生成的车载网络图在各种场景下的编程仿真得到验证。", "conclusion": "TrustConnect框架能够有效评估车载网络的信任度，并通过识别和防止错误信息传播来增强车辆的可靠性和安全性。", "translation": "现代车辆配备了大量车载组件，这些组件通过蓝牙和车对基础设施通信等远程通信和服务与外部环境交互。这些组件形成一个网络，交换信息以确保车辆的正常运行。然而，虚假或伪造信息的存在可能会扰乱车辆的性能。鉴于这些组件是相互连接的，错误数据可能会在整个网络中传播，可能影响其他组件并导致灾难性后果。为了解决这个问题，我们提出了TrustConnect，一个旨在通过评估各种网络配置下单个组件的信任级别来评估车辆车载网络信任度的框架。所提出的框架利用所有车辆组件的相互依赖性、其值的相关性以及基于每个组件外部暴露的远程注入脆弱性来确定车载网络的可靠性。所提出的框架的有效性已通过使用Python的Networkx包生成的车载网络图在各种场景下的编程仿真得到验证。", "summary": "本文提出了TrustConnect框架，旨在解决现代车辆中因虚假信息传播导致的网络性能问题。该框架通过评估车载网络中各个组件的信任度，并考虑组件间的相互依赖性、数据相关性和远程注入脆弱性，来确定网络的整体可靠性。通过编程仿真验证了其在不同场景下的有效性。", "keywords": "车载网络, 异常检测, 信任评估, 拓扑, 网络安全", "comments": "TrustConnect是一个创新性的框架，它通过引入基于拓扑的信任评级来解决车载网络中的异常检测问题。其重要性在于能够有效提升现代车辆的安全性与可靠性，尤其是在应对外部通信带来的潜在威胁方面。该方法考虑了组件的相互依赖性和外部暴露程度，这在实际应用中具有很高的价值。"}}
{"id": "2506.06560", "title": "Semantics-aware Predictive Inspection Path Planning", "authors": ["Mihir Dharmadhikari", "Kostas Alexis"], "summary": "This paper presents a novel semantics-aware inspection path planning paradigm\ncalled \"Semantics-aware Predictive Planning\" (SPP). Industrial environments\nthat require the inspection of specific objects or structures (called\n\"semantics\"), such as ballast water tanks inside ships, often present\nstructured and repetitive spatial arrangements of the semantics of interest.\nMotivated by this, we first contribute an algorithm that identifies spatially\nrepeating patterns of semantics - exact or inexact - in a semantic scene graph\nrepresentation and makes predictions about the evolution of the graph in the\nunseen parts of the environment using these patterns. Furthermore, two\ninspection path planning strategies, tailored to ballast water tank inspection,\nthat exploit these predictions are proposed. To assess the performance of the\nnovel predictive planning paradigm, both simulation and experimental\nevaluations are performed. First, we conduct a simulation study comparing the\nmethod against relevant state-of-the-art techniques and further present tests\nshowing its ability to handle imperfect patterns. Second, we deploy our method\nonboard a collision-tolerant aerial robot operating inside the ballast tanks of\ntwo real ships. The results, both in simulation and field experiments,\ndemonstrate significant improvement over the state-of-the-art in terms of\ninspection time while maintaining equal or better semantic surface coverage. A\nset of videos describing the different parts of the method and the field\ndeployments is available at https://tinyurl.com/spp-videos. The code for this\nwork is made available at https://github.com/ntnu-arl/predictive_planning_ros.", "comment": "Accepted at IEEE Transactions on Field Robotics", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06560v1", "AI": {"title_translation": "语义感知预测性巡检路径规划", "tldr": "本文提出了一种新颖的语义感知预测性规划（SPP）范式，用于工业环境中的巡检路径规划。该方法利用语义空间重复模式识别和预测来规划路径，并在仿真和实际船舶压载水舱中进行了验证，结果显示其在巡检时间和语义表面覆盖方面均优于现有技术。", "motivation": "工业环境中（如船舶压载水舱）需要巡检特定对象或结构（“语义”）时，这些语义往往呈现结构化和重复的空间排列。受此启发，本文旨在利用这些重复模式来优化巡检路径规划。", "method": "本文首先提出了一种算法，用于在语义场景图表示中识别语义的空间重复模式（精确或不精确），并利用这些模式预测环境中未见部分的图演变。此外，还提出了两种针对压载水舱巡检的路径规划策略，以利用这些预测。为了评估该预测性规划范式的性能，进行了仿真和实验评估，包括与现有技术的比较以及处理不完美模式的能力测试。该方法还部署在两艘真实船舶的压载水舱内的抗碰撞空中机器人上。", "result": "仿真和现场实验结果表明，与现有技术相比，该方法在巡检时间方面有显著改善，同时保持了相同或更好的语义表面覆盖率。", "conclusion": "本文提出的语义感知预测性规划（SPP）范式能够显著提高结构化工业环境（如压载水舱）的巡检效率和覆盖率。", "translation": "本文提出了一种新颖的语义感知巡检路径规划范式，称为“语义感知预测性规划”（SPP）。需要巡检特定对象或结构（称为“语义”）的工业环境，例如船舶内部的压载水舱，通常呈现出感兴趣语义的结构化和重复性空间排列。受此启发，我们首先贡献了一种算法，该算法在语义场景图表示中识别语义的空间重复模式——精确或不精确——并利用这些模式预测环境中未见部分的图演变。此外，提出了两种利用这些预测的巡检路径规划策略，专门针对压载水舱巡检。为了评估这种新型预测性规划范式的性能，我们进行了仿真和实验评估。首先，我们进行了一项仿真研究，将该方法与相关现有技术进行比较，并进一步展示了其处理不完美模式的能力测试。其次，我们将我们的方法部署在两艘真实船舶压载水舱内运行的抗碰撞空中机器人上。仿真和现场实验结果均表明，在巡检时间方面，该方法比现有技术有显著改进，同时保持了相同或更好的语义表面覆盖率。描述该方法不同部分和现场部署的一系列视频可在 https://tinyurl.com/spp-videos 获取。该工作的代码可在 https://github.com/ntnu-arl/predictive_planning_ros 获取。", "summary": "本文提出了一种名为“语义感知预测性规划”（SPP）的新型语义感知巡检路径规划范式。针对工业环境中语义的结构化和重复性空间排列，本文贡献了一种算法，用于识别语义场景图中的精确或不精确的空间重复模式，并利用这些模式预测环境中未见部分的图演变。在此基础上，提出了两种利用这些预测的巡检路径规划策略，并针对压载水舱巡检进行了优化。通过仿真和在真实船舶压载水舱中的实验评估，结果显示该方法在巡检时间上显著优于现有技术，同时保持了相同或更好的语义表面覆盖率。", "keywords": "巡检路径规划, 语义感知, 预测性规划, 机器人, 压载水舱", "comments": "本文的创新点在于提出了“语义感知预测性规划”范式，利用了工业环境中语义的结构化和重复性特点进行模式识别和预测，从而优化巡检路径。这种方法显著提高了巡检效率，对于需要高效、全面巡检的复杂工业环境具有重要意义。在真实船舶上的部署验证也增加了其应用价值。"}}
{"id": "2506.07714", "title": "Profiling Electric Vehicles via Early Charging Voltage Patterns", "authors": ["Francesco Marchiori", "Denis Donadel", "Alessandro Brighente", "Mauro Conti"], "summary": "Electric Vehicles (EVs) are rapidly gaining adoption as a sustainable\nalternative to fuel-powered vehicles, making secure charging infrastructure\nessential. Despite traditional authentication protocols, recent results showed\nthat attackers may steal energy through tailored relay attacks. One\ncountermeasure is leveraging the EV's fingerprint on the current exchanged\nduring charging. However, existing methods focus on the final charging stage,\nallowing malicious actors to consume substantial energy before being detected\nand repudiated. This underscores the need for earlier and more effective\nauthentication methods to prevent unauthorized charging. Meanwhile, profiling\nraises privacy concerns, as uniquely identifying EVs through charging patterns\ncould enable user tracking.\n  In this paper, we propose a framework for uniquely identifying EVs using\nphysical measurements from the early charging stages. We hypothesize that\nvoltage behavior early in the process exhibits similar characteristics to\ncurrent behavior in later stages. By extracting features from early voltage\nmeasurements, we demonstrate the feasibility of EV profiling. Our approach\nimproves existing methods by enabling faster and more reliable vehicle\nidentification. We test our solution on a dataset of 7408 usable charges from\n49 EVs, achieving up to 0.86 accuracy. Feature importance analysis shows that\nnear-optimal performance is possible with just 10 key features, improving\nefficiency alongside our lightweight models. This research lays the foundation\nfor a novel authentication factor while exposing potential privacy risks from\nunauthorized access to charging data.", "comment": "Accepted to be presented at the AI&CPSS Workshop in conjunction with\n  ARES 2025", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07714v1", "AI": {"title_translation": "通过早期充电电压模式识别电动汽车", "tldr": "本文提出了一种利用电动汽车早期充电电压模式进行身份识别的框架，旨在提高充电认证的效率和安全性，同时揭示了潜在的隐私风险。", "motivation": "尽管传统的认证协议存在，但攻击者仍可能通过定制的继电器攻击窃取电动汽车充电能量。现有方法侧重于充电后期，导致恶意行为者在被检测前已消耗大量能量。因此，需要更早期、更有效的认证方法来防止未经授权的充电。同时，通过充电模式唯一识别电动汽车可能导致用户追踪，引发隐私担忧。", "method": "本文提出了一种利用早期充电阶段的物理测量数据（电压模式）来唯一识别电动汽车的框架。研究假设早期电压行为与后期电流行为具有相似的特征。通过从早期电压测量中提取特征，验证了电动汽车识别的可行性。", "result": "该解决方案在包含49辆电动汽车的7408次有效充电数据集中进行了测试，实现了高达0.86的准确率。特征重要性分析表明，仅使用10个关键特征即可实现接近最优的性能，提高了效率并支持轻量级模型。", "conclusion": "这项研究为一种新颖的认证因素奠定了基础，同时也揭示了未经授权访问充电数据可能带来的隐私风险。", "translation": "电动汽车（EVs）作为燃料动力汽车的可持续替代品正在迅速普及，因此安全的充电基础设施至关重要。尽管有传统的认证协议，但最近的结果表明，攻击者可能通过定制的继电器攻击窃取能量。一种对策是利用电动汽车在充电过程中交换电流的“指纹”。然而，现有方法侧重于最终充电阶段，使得恶意行为者在被检测和拒绝之前消耗大量能量。这强调了需要更早、更有效的认证方法来防止未经授权的充电。同时，识别也引发了隐私问题，因为通过充电模式唯一识别电动汽车可能导致用户追踪。\n在本文中，我们提出了一种利用早期充电阶段的物理测量数据来唯一识别电动汽车的框架。我们假设早期充电过程中的电压行为与后期电流行为表现出相似的特征。通过从早期电压测量中提取特征，我们证明了电动汽车识别的可行性。我们的方法通过实现更快、更可靠的车辆识别来改进现有方法。我们在一个包含49辆电动汽车的7408次可用充电数据集中测试了我们的解决方案，实现了高达0.86的准确率。特征重要性分析表明，仅使用10个关键特征即可实现接近最优的性能，提高了效率，同时支持我们的轻量级模型。这项研究为一种新颖的认证因素奠定了基础，同时也揭示了未经授权访问充电数据可能带来的潜在隐私风险。", "summary": "本文提出了一种基于电动汽车早期充电电压模式的身份识别框架，旨在解决现有充电认证方法检测滞后导致能量被盗的问题。研究假设早期电压行为与后期电流行为具有相似的识别特征。通过从早期电压测量中提取特征，该方法在49辆电动汽车的7408次充电数据上实现了高达0.86的准确率，并发现仅需10个关键特征即可实现接近最优性能。这项研究为更早、更可靠的电动汽车认证提供了新途径，同时也指出了充电数据可能引发的隐私风险。", "keywords": "电动汽车, 充电认证, 电压模式, 身份识别, 隐私风险", "comments": "该研究创新性地将电动汽车认证的焦点从充电后期转移到早期电压模式，显著提高了检测效率和安全性。其提出的轻量级模型和对关键特征的识别，使其在实际应用中具有较高的效率和部署潜力。然而，研究也明确指出了这种识别能力可能带来的隐私风险，这在未来电动汽车数据利用中是需要重点关注和解决的问题。"}}
{"id": "2506.07385", "title": "GUIPilot: A Consistency-based Mobile GUI Testing Approach for Detecting Application-specific Bugs", "authors": ["Ruofan Liu", "Xiwen Teoh", "Yun Lin", "Guanjie Chen", "Ruofei Ren", "Denys Poshyvanyk", "Jin Song Dong"], "summary": "In this work, we propose GUIPilot, an approach for detecting inconsistencies\nbetween the mobile design and their implementations. The mobile design usually\nconsists of design mock-ups that specify (1) the expected screen appearances\n(e.g., widget layouts, colors, and shapes) and (2) the expected screen\nbehaviors, regarding how one screen can transition into another (e.g., labeled\nwidgets with textual description). Given a design mock-up and the\nimplementation of its application, GUIPilot reports both their screen\ninconsistencies as well as process inconsistencies. On the one hand, GUIPilot\ndetects the screen inconsistencies by abstracting every screen into a widget\ncontainer where each widget is represented by its position, width, height, and\ntype. By defining the partial order of widgets and the costs of replacing,\ninserting, and deleting widgets in a screen, we convert the screen-matching\nproblem into an optimizable widget alignment problem. On the other hand, we\ntranslate the specified GUI transition into stepwise actions on the mobile\nscreen (e.g., click, long-press, input text on some widgets). To this end, we\npropose a visual prompt for the vision-language model to infer widget-specific\nactions on the screen. By this means, we can validate the presence or absence\nof expected transitions in the implementation. Our extensive experiments on 80\nmobile applications and 160 design mock-ups show that (1) GUIPilot can achieve\n94.5% precision and 99.6% recall in detecting screen inconsistencies,\noutperforming the state-of-the-art approach, such as GVT, by 66.2% and 56.6%\nrespectively, and (2) GUIPilot reports zero errors in detecting process\ninconsistencies. Furthermore, our industrial case study on applying GUIPilot on\na trading mobile application shows that GUIPilot has detected nine application\nbugs, and all the bugs were confirmed by the original application experts.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07385v1", "AI": {"title_translation": "GUIPilot：一种基于一致性的移动GUI测试方法，用于检测应用程序特定错误", "tldr": "GUIPilot通过检测移动应用设计与实现之间的屏幕和过程不一致性来发现应用程序错误。", "motivation": "移动设计通常包括设计模型，用于指定预期的屏幕外观和行为。然而，实现可能与设计不一致，需要一种有效的方法来检测这些不一致性以发现应用程序错误。", "method": "GUIPilot旨在检测设计模型与应用程序实现之间的屏幕不一致性和过程不一致性。对于屏幕不一致性，它将每个屏幕抽象为小部件容器，通过定义小部件的偏序和操作成本，将屏幕匹配问题转化为可优化的小部件对齐问题。对于过程不一致性，它将指定的GUI转换转化为移动屏幕上的逐步操作（如点击、长按），并利用视觉-语言模型推断小部件特定操作，以验证预期转换的存在或缺失。", "result": "在80个移动应用和160个设计模型上的实验表明：GUIPilot在检测屏幕不一致性方面达到94.5%的精确度和99.6%的召回率，分别比最先进的方法（如GVT）高出66.2%和56.6%。在检测过程不一致性方面报告零错误。此外，在交易移动应用程序上的工业案例研究中，GUIPilot检测到9个应用程序错误，并均得到专家确认。", "conclusion": "GUIPilot是一种高效且准确的移动GUI测试方法，能够有效检测设计与实现之间的屏幕和过程不一致性，并通过在实际应用中发现错误，证明了其优越性和实用价值。", "translation": "在这项工作中，我们提出了GUIPilot，一种用于检测移动设计与其实现之间不一致性的方法。移动设计通常包括设计模型，这些模型指定了（1）预期的屏幕外观（例如，小部件布局、颜色和形状）和（2）预期的屏幕行为，涉及一个屏幕如何过渡到另一个屏幕（例如，带有文本描述的标签小部件）。给定一个设计模型及其应用程序的实现，GUIPilot报告它们的屏幕不一致性以及过程不一致性。一方面，GUIPilot通过将每个屏幕抽象为一个小部件容器来检测屏幕不一致性，其中每个小部件由其位置、宽度、高度和类型表示。通过定义小部件的偏序以及屏幕中小部件替换、插入和删除的成本，我们将屏幕匹配问题转换为一个可优化的小部件对齐问题。另一方面，我们将指定的GUI转换转化为移动屏幕上的逐步操作（例如，点击、长按、在某些小部件上输入文本）。为此，我们提出了一个视觉提示，供视觉-语言模型推断屏幕上特定于小部件的操作。通过这种方式，我们可以验证实现中预期转换的存在或缺失。我们对80个移动应用程序和160个设计模型的广泛实验表明：（1）GUIPilot在检测屏幕不一致性方面可以达到94.5%的精确度和99.6%的召回率，分别比最先进的方法（如GVT）高出66.2%和56.6%，并且（2）GUIPilot在检测过程不一致性方面报告零错误。此外，我们对将GUIPilot应用于交易移动应用程序的工业案例研究表明，GUIPilot检测到九个应用程序错误，所有错误都得到了原始应用程序专家的确认。", "summary": "GUIPilot是一种基于一致性的移动GUI测试方法，旨在通过检测移动设计模型与其应用实现之间的屏幕和过程不一致性来发现应用程序错误。它通过将屏幕匹配转换为小部件对齐问题来识别屏幕布局差异，并利用视觉-语言模型推断动作以验证GUI转换。实验结果表明，GUIPilot在检测屏幕和过程不一致性方面表现出高精度和召回率，并成功在实际应用中发现错误，优于现有技术。", "keywords": "移动GUI测试, 一致性检测, 应用程序错误, 屏幕不一致性, 过程不一致性", "comments": "GUIPilot的创新之处在于其结合了对屏幕布局（静态）和GUI行为（动态）一致性的检测，并通过将问题转化为可优化的小部件对齐和利用视觉-语言模型来解决。其在实际应用中的高精确度和发现实际bug的能力显示了其重要的实用价值，为移动应用测试提供了一种有效的新方法。"}}
{"id": "2506.06578", "title": "A Deep Learning Approach for Facial Attribute Manipulation and Reconstruction in Surveillance and Reconnaissance", "authors": ["Anees Nashath Shaik", "Barbara Villarini", "Vasileios Argyriou"], "summary": "Surveillance systems play a critical role in security and reconnaissance, but\ntheir performance is often compromised by low-quality images and videos,\nleading to reduced accuracy in face recognition. Additionally, existing\nAI-based facial analysis models suffer from biases related to skin tone\nvariations and partially occluded faces, further limiting their effectiveness\nin diverse real-world scenarios. These challenges are the results of data\nlimitations and imbalances, where available training datasets lack sufficient\ndiversity, resulting in unfair and unreliable facial recognition performance.\nTo address these issues, we propose a data-driven platform that enhances\nsurveillance capabilities by generating synthetic training data tailored to\ncompensate for dataset biases. Our approach leverages deep learning-based\nfacial attribute manipulation and reconstruction using autoencoders and\nGenerative Adversarial Networks (GANs) to create diverse and high-quality\nfacial datasets. Additionally, our system integrates an image enhancement\nmodule, improving the clarity of low-resolution or occluded faces in\nsurveillance footage. We evaluate our approach using the CelebA dataset,\ndemonstrating that the proposed platform enhances both training data diversity\nand model fairness. This work contributes to reducing bias in AI-based facial\nanalysis and improving surveillance accuracy in challenging environments,\nleading to fairer and more reliable security applications.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06578v1", "AI": {"title_translation": "一种用于监控和侦察中面部属性操纵和重建的深度学习方法", "tldr": "本文提出了一种基于深度学习的平台，利用自编码器和GANs生成多样化的合成面部数据并增强图像，以解决监控人脸识别中的偏差和低质量问题。", "motivation": "监控系统常因图像质量低而导致人脸识别准确性下降。现有AI面部分析模型因训练数据不足和不平衡而存在肤色和遮挡偏见，导致识别性能不公平和不可靠。", "method": "提出了一个数据驱动的平台，通过深度学习（自编码器和生成对抗网络GANs）进行面部属性操纵和重建，生成定制的合成训练数据以弥补数据集偏差。此外，系统还集成了一个图像增强模块，用于改善低分辨率或被遮挡面部的清晰度。", "result": "使用CelebA数据集进行评估，结果表明所提出的平台有效增强了训练数据的多样性和模型的公平性。", "conclusion": "该工作有助于减少基于AI的面部分析中的偏见，提高复杂环境中的监控准确性，从而实现更公平、更可靠的安全应用。", "translation": "监控系统在安全和侦察中发挥着关键作用，但其性能常常受到低质量图像和视频的影响，导致人脸识别准确性降低。此外，现有的基于AI的面部分析模型存在与肤色变化和部分遮挡面部相关的偏见，进一步限制了它们在各种现实场景中的有效性。这些挑战是数据限制和不平衡的结果，现有训练数据集缺乏足够的多样性，导致不公平和不可靠的人脸识别性能。为了解决这些问题，我们提出了一个数据驱动的平台，通过生成定制的合成训练数据来弥补数据集偏差，从而增强监控能力。我们的方法利用基于深度学习的面部属性操纵和重建，使用自编码器和生成对抗网络（GANs）来创建多样化和高质量的面部数据集。此外，我们的系统集成了一个图像增强模块，提高了监控录像中低分辨率或被遮挡面部的清晰度。我们使用CelebA数据集评估了我们的方法，结果表明所提出的平台增强了训练数据的多样性和模型的公平性。这项工作有助于减少基于AI的面部分析中的偏见，并提高在复杂环境中的监控准确性，从而实现更公平、更可靠的安全应用。", "summary": "本文提出了一种基于深度学习的平台，旨在解决监控系统中人脸识别因图像质量低和模型偏见导致的问题。该平台利用自编码器和生成对抗网络（GANs）进行面部属性操纵和重建，生成多样化的合成训练数据以弥补数据集偏差，并集成图像增强模块以提高低分辨率或遮挡面部的清晰度。在CelebA数据集上的评估表明，该方法能有效提升训练数据多样性和模型公平性，从而实现更可靠的安全应用。", "keywords": "面部属性操纵, 深度学习, 生成对抗网络, 监控, 偏见消除", "comments": "本文的创新之处在于利用深度学习（特别是自编码器和GANs）来生成合成数据，以解决监控场景中因数据限制和偏差导致的人脸识别准确性和公平性问题。这对于提升AI在现实世界安防应用中的鲁棒性和可靠性具有重要意义。"}}
{"id": "2506.06352", "title": "Will artificial agents pursue power by default?", "authors": ["Christian Tarsney"], "summary": "Researchers worried about catastrophic risks from advanced AI have argued\nthat we should expect sufficiently capable AI agents to pursue power over\nhumanity because power is a convergent instrumental goal, something that is\nuseful for a wide range of final goals. Others have recently expressed\nskepticism of these claims. This paper aims to formalize the concepts of\ninstrumental convergence and power-seeking in an abstract, decision-theoretic\nframework, and to assess the claim that power is a convergent instrumental\ngoal. I conclude that this claim contains at least an element of truth, but\nmight turn out to have limited predictive utility, since an agent's options\ncannot always be ranked in terms of power in the absence of substantive\ninformation about the agent's final goals. However, the fact of instrumental\nconvergence is more predictive for agents who have a good shot at attaining\nabsolute or near-absolute power.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06352v1", "AI": {"title_translation": "人工智能体默认会追求权力吗？", "tldr": "论文通过决策理论框架形式化了工具性收敛和权力寻求的概念，并得出结论：AI寻求权力有一定道理，但其预测效用有限，除非AI能获得绝对权力。", "motivation": "针对高级AI可能对人类构成灾难性风险的担忧，研究者们认为AI代理会寻求权力，因为权力是一种收敛的工具性目标。但也有人对此表示怀疑，因此本研究旨在评估这一主张。", "method": "本文旨在在一个抽象的、决策理论框架中形式化工具性收敛和权力寻求的概念，并评估权力是一种收敛的工具性目标这一主张。", "result": "结论是，权力是收敛的工具性目标这一主张至少包含一部分事实，但可能预测效用有限，因为在缺乏关于代理最终目标的实质性信息的情况下，代理的选项并非总能按权力进行排序。然而，对于那些有很大机会获得绝对或接近绝对权力的代理来说，工具性收敛的事实更具预测性。", "conclusion": "权力作为收敛性工具性目标的主张有其真实性，但其预测能力有限，因为在不了解AI最终目标的情况下，其选项无法总是按权力排序。然而，对于有潜力获得绝对或接近绝对权力的AI而言，工具性收敛的预测性更强。", "translation": "研究人员担心先进人工智能带来的灾难性风险，认为足够强大的人工智能代理会寻求超越人类的权力，因为权力是一个收敛的工具性目标，对广泛的最终目标都有用。最近也有人对此类主张表示怀疑。本文旨在在一个抽象的、决策理论框架中形式化工具性收敛和权力寻求的概念，并评估权力是一个收敛的工具性目标这一主张。我得出结论，这一主张至少包含一部分事实，但可能预测效用有限，因为在缺乏关于代理最终目标的实质性信息的情况下，代理的选项并非总能按权力进行排序。然而，对于那些有很大机会获得绝对或接近绝对权力的代理来说，工具性收敛的事实更具预测性。", "summary": "本文在一个抽象的决策理论框架中，形式化并评估了人工智能代理是否会寻求权力这一问题。研究发现，“权力是收敛的工具性目标”这一主张具有一定真实性，但在缺乏AI最终目标信息时，其预测效用有限。然而，对于有潜力获得绝对或接近绝对权力的AI，工具性收敛的预测性更强。", "keywords": "人工智能, 权力寻求, 工具性收敛, AI风险, 决策理论", "comments": "这篇论文通过严谨的决策理论框架，对AI风险领域中关于AI权力寻求的核心论点进行了形式化和审视。其创新之处在于提供了一个理论工具来分析这一复杂问题，并得出了一个 nuanced 的结论，即该主张并非全盘皆错，但也并非普遍适用。这对于理解AI行为的潜在风险具有重要意义，尤其是在区分不同能力水平和目标信息的AI代理时。论文的局限性可能在于其抽象性，实际应用中可能需要更多具体情境的考量。"}}
{"id": "2506.07391", "title": "Distributed Image Semantic Communication via Nonlinear Transform Coding", "authors": ["Yufei Bo", "Meixia Tao", "Kai Niu"], "summary": "This paper investigates distributed source-channel coding for correlated\nimage semantic transmission over wireless channels. In this setup, correlated\nimages at different transmitters are separately encoded and transmitted through\ndedicated channels for joint recovery at the receiver. We propose a general\napproach for distributed image semantic communication that applies to both\nseparate source and channel coding (SSCC) and joint source-channel coding\n(JSCC). Unlike existing learning-based approaches that implicitly learn source\ncorrelation in a purely data-driven manner, our method leverages nonlinear\ntransform coding (NTC) to explicitly model source correlation from both\nprobabilistic and geometric perspectives. A joint entropy model approximates\nthe joint distribution of latent representations to guide adaptive rate\nallocation, while a transformation module aligns latent features for maximal\ncorrelation learning at the decoder. We implement this framework as D-NTSC for\nSSCC and D-NTSCC for JSCC, both built on Swin Transformers for effective\nfeature extraction and correlation exploitation. Variational inference is\nemployed to derive principled loss functions that jointly optimize encoding,\ndecoding, and joint entropy modeling. Extensive experiments on real-world\nmulti-view datasets demonstrate that D-NTSC and D-NTSCC outperform existing\ndistributed SSCC and distributed JSCC baselines, respectively, achieving\nstate-of-the-art performance in both pixel-level and perceptual quality\nmetrics.", "comment": "arXiv admin note: text overlap with arXiv:2503.21249", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07391v1", "AI": {"title_translation": "分布式图像语义通信通过非线性变换编码", "tldr": "本文提出了一种基于非线性变换编码（NTC）的分布式图像语义通信方法D-NTSC/D-NTSCC，该方法显式建模源相关性，并在多视角数据集上实现了最先进的性能。", "motivation": "现有基于学习的分布式图像语义通信方法隐式地、纯数据驱动地学习源相关性，而本文旨在通过非线性变换编码（NTC）从概率和几何角度显式建模源相关性，以提高传输效率和重建质量。", "method": "本文提出了一种通用的分布式图像语义通信方法，适用于分离源和信道编码（SSCC）和联合源信道编码（JSCC）。该方法利用非线性变换编码（NTC）显式地从概率和几何角度建模源相关性。具体地，它采用一个联合熵模型来近似潜在表示的联合分布以指导自适应速率分配，并使用一个变换模块来对齐潜在特征以实现解码器处最大相关性学习。该框架被实现为D-NTSC（用于SSCC）和D-NTSCC（用于JSCC），两者均基于Swin Transformers进行有效的特征提取和相关性利用。此外，采用变分推断来推导联合优化编码、解码和联合熵建模的损失函数。", "result": "在真实世界多视角数据集上的广泛实验表明，D-NTSC和D-NTSCC分别优于现有的分布式SSCC和分布式JSCC基线，在像素级和感知质量指标上均实现了最先进的性能。", "conclusion": "本文提出的基于非线性变换编码的分布式图像语义通信方法（D-NTSC和D-NTSCC）在实验中表现出优越性，并在多视角数据集上达到了最先进的性能，证明了其在处理相关图像语义传输方面的有效性和潜力。", "translation": "本文研究了无线信道上相关图像语义传输的分布式源信道编码。在此设置中，不同发射机处的关联图像被单独编码和传输，以便在接收机处联合恢复。我们提出了一种通用的分布式图像语义通信方法，适用于分离源和信道编码（SSCC）以及联合源信道编码（JSCC）。与现有纯数据驱动隐式学习源相关性的学习方法不同，我们的方法利用非线性变换编码（NTC）从概率和几何角度显式建模源相关性。一个联合熵模型近似潜在表示的联合分布以指导自适应速率分配，而一个变换模块对齐潜在特征以实现解码器处最大相关性学习。我们将此框架实现为用于SSCC的D-NTSC和用于JSCC的D-NTSCC，两者都建立在Swin Transformers上，以实现有效的特征提取和相关性利用。采用变分推断来推导联合优化编码、解码和联合熵建模的原理性损失函数。在真实世界多视角数据集上的广泛实验表明，D-NTSC和D-NTSCC分别优于现有的分布式SSCC和分布式JSCC基线，在像素级和感知质量指标上均实现了最先进的性能。", "summary": "本文提出了一种名为D-NTSC（用于SSCC）和D-NTSCC（用于JSCC）的分布式图像语义通信新方法。该方法通过非线性变换编码（NTC）显式地从概率和几何角度建模相关图像的源相关性，克服了现有数据驱动方法隐式学习的局限性。它结合了联合熵模型进行自适应速率分配和变换模块进行特征对齐，并利用Swin Transformers进行高效特征提取。实验证明，该方法在多视角数据集上超越了现有基线，在图像质量上达到了最先进水平。", "keywords": "分布式图像通信, 语义通信, 非线性变换编码, 源信道编码, 联合熵模型", "comments": "该论文的创新点在于其提出了一种显式建模源相关性的分布式图像语义通信方法，与现有隐式学习的方法形成对比。通过引入非线性变换编码、联合熵模型和变换模块，并结合Swin Transformers，该方法在理论和实践上都取得了显著进步。在分布式通信场景中，尤其是在处理多视图图像等相关数据时，这种显式建模相关性的方法对于提高传输效率和重建质量具有重要意义。"}}
{"id": "2506.07367", "title": "A Survey on LUT-based Deep Neural Networks Implemented in FPGAs", "authors": ["Zeyu Guo"], "summary": "Low-latency, energy-efficient deep neural networks (DNNs) inference are\ncritical for edge applications, where traditional cloud-based deployment\nsuffers from high latency and security risks. Field-Programmable Gate Arrays\n(FPGAs) offer a compelling solution, balancing reconfigurability, power\nefficiency, and real-time performance. However, conventional FPGA-based DNNs\nrely heavily on digital signal processing (DSP) blocks for multiply-accumulate\n(MAC) operations, limiting scalability.\n  LUT-based DNNs address this challenge by fully leveraging FPGA lookup tables\n(LUTs) for computation, improving resource utilization and reducing inference\nlatency. This survey provides a comprehensive review of LUT-based DNN\narchitectures, including their evolution, design methodologies, and performance\ntrade-offs, while outlining promising directions for future research.", "comment": null, "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07367v1", "AI": {"title_translation": "基于查找表（LUT）的FPGA深度神经网络实现综述", "tldr": "这篇综述探讨了在FPGA中实现基于查找表的深度神经网络，以解决边缘应用中传统方法的延迟和可扩展性问题，并概述了未来的研究方向。", "motivation": "传统的云端深度神经网络部署在边缘应用中存在高延迟和安全风险。FPGA提供了一个平衡的解决方案，但传统的FPGA深度神经网络严重依赖DSP块进行MAC操作，限制了可扩展性。", "method": "这篇综述通过全面回顾基于查找表的深度神经网络架构，包括其演变、设计方法和性能权衡，来解决上述挑战。", "result": "综述提供了基于查找表的深度神经网络架构的全面回顾，涵盖了它们的演变、设计方法和性能权衡。", "conclusion": "文章概述了未来研究的有前景方向。", "translation": "低延迟、高能效的深度神经网络（DNN）推理对于边缘应用至关重要，而传统的基于云的部署存在高延迟和安全风险。现场可编程门阵列（FPGA）提供了一个引人注目的解决方案，平衡了可重构性、能效和实时性能。然而，传统的基于FPGA的DNN严重依赖数字信号处理（DSP）块进行乘积累加（MAC）操作，从而限制了可扩展性。\n基于查找表（LUT）的DNN通过充分利用FPGA查找表进行计算来解决这一挑战，从而提高资源利用率并降低推理延迟。本综述全面回顾了基于查找表的DNN架构，包括其演变、设计方法和性能权衡，同时概述了未来研究的有前景方向。", "summary": "本综述关注在FPGA中实现低延迟、高能效的深度神经网络推理，以满足边缘应用的需求。针对传统FPGA深度神经网络依赖DSP块导致可扩展性受限的问题，文章探讨了基于查找表（LUT）的深度神经网络，该方法通过充分利用FPGA的查找表进行计算，提高了资源利用率并降低了推理延迟。该综述全面回顾了基于LUT的深度神经网络架构，包括其演变、设计方法和性能权衡，并指出了未来研究方向。", "keywords": "FPGA, 深度神经网络, 查找表, 边缘计算, 硬件加速", "comments": "这篇综述的重要性在于它识别并系统地分析了一种解决FPGA上深度神经网络实现瓶颈的关键技术——基于LUT的计算。通过摆脱对DSP块的过度依赖，基于LUT的DNN为边缘AI应用提供了更高的资源利用率和更低的延迟，这对于推动FPGA在AI加速领域的应用至关重要。该综述不仅总结了现有技术，还指明了未来的研究方向，具有很高的指导价值。"}}
{"id": "2506.06297", "title": "Optimal patient allocation for echocardiographic assessments", "authors": ["Bozhi Sun", "Seda Tierney", "Jeffrey A. Feinstein", "Frederick Damen", "Alison L. Marsden", "Daniele E. Schiavazzi"], "summary": "Scheduling echocardiographic exams in a hospital presents significant\nchallenges due to non-deterministic factors (e.g., patient no-shows, patient\narrival times, diverse exam durations, etc.) and asymmetric resource\nconstraints between fetal and non-fetal patient streams. To address these\nchallenges, we first conducted extensive pre-processing on one week of\noperational data from the Echo Laboratory at Stanford University's Lucile\nPackard Children's Hospital, to estimate patient no-show probabilities and\nderive empirical distributions of arrival times and exam durations. Based on\nthese inputs, we developed a discrete-event stochastic simulation model using\nSimPy, and integrate it with the open source Gymnasium Python library. As a\nbaseline for policy optimization, we developed a comparative framework to\nevaluate on-the-fly versus reservation-based allocation strategies, in which\ndifferent proportions of resources are reserved in advance. Considering a\nhospital configuration with a 1:6 ratio of fetal to non-fetal rooms and a 4:2\nratio of fetal to non-fetal sonographers, we show that on-the-fly allocation\ngenerally yields better performance, more effectively adapting to patient\nvariability and resource constraints. Building on this foundation, we apply\nreinforcement learning (RL) to derive an approximated optimal dynamic\nallocation policy. This RL-based policy is benchmarked against the\nbest-performing rule-based strategies, allowing us to quantify their\ndifferences and provide actionable insights for improving echo lab efficiency\nthrough intelligent, data-driven resource management.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06297v1", "AI": {"title_translation": "超声心动图评估患者优化分配", "tldr": "医院超声心动图预约挑战大，本文通过仿真和强化学习优化患者动态分配，发现即时分配通常表现更好，RL可提高效率。", "motivation": "医院超声心动图检查安排面临显著挑战，原因是非确定性因素（如患者未到、到达时间、检查时长不同等）以及胎儿和非胎儿患者流之间不对称的资源限制。", "method": "首先对斯坦福大学露西尔·帕卡德儿童医院超声实验室一周的运营数据进行预处理，估算患者未到概率并推导到达时间和检查时长的经验分布。然后，使用SimPy开发了一个离散事件随机仿真模型，并将其与开源Gymnasium Python库集成。作为策略优化的基准，开发了一个比较框架来评估即时分配和基于预约的分配策略。在此基础上，应用强化学习（RL）推导近似最优的动态分配策略，并与表现最佳的基于规则的策略进行基准测试。", "result": "在考虑胎儿与非胎儿房间比例为1:6、超声技师比例为4:2的医院配置下，研究表明即时分配通常表现更好，能更有效地适应患者变异性和资源限制。基于强化学习的策略与表现最佳的基于规则的策略进行基准测试，量化了它们的差异，并为通过智能、数据驱动的资源管理提高超声实验室效率提供了可操作的见解。", "conclusion": "本文为通过智能、数据驱动的资源管理提高超声实验室效率提供了可操作的见解，并成功推导出近似最优的动态分配策略。", "translation": "在医院安排超声心动图检查面临重大挑战，原因是非确定性因素（例如，患者未到、患者到达时间、不同的检查时长等）以及胎儿和非胎儿患者流之间不对称的资源限制。为了解决这些挑战，我们首先对斯坦福大学露西尔·帕卡德儿童医院超声实验室一周的运营数据进行了广泛的预处理，以估算患者未到概率并推导到达时间和检查时长的经验分布。基于这些输入，我们使用SimPy开发了一个离散事件随机仿真模型，并将其与开源Gymnasium Python库集成。作为策略优化的基准，我们开发了一个比较框架来评估即时分配和基于预约的分配策略，其中不同比例的资源被提前预留。考虑到胎儿与非胎儿房间比例为1:6、胎儿与非胎儿超声技师比例为4:2的医院配置，我们表明即时分配通常能产生更好的性能，更有效地适应患者变异性和资源限制。在此基础上，我们应用强化学习（RL）来推导近似最优的动态分配策略。这种基于RL的策略与表现最佳的基于规则的策略进行基准测试，使我们能够量化它们的差异，并为通过智能、数据驱动的资源管理提高超声实验室效率提供可操作的见解。", "summary": "本文针对医院超声心动图检查预约面临的非确定性因素和资源限制挑战，利用斯坦福大学儿童医院的运营数据进行预处理，估算患者未到概率和检查时长分布。研究团队构建了一个基于SimPy的离散事件随机仿真模型，并结合Gymnasium库，比较了即时分配和预约分配策略。结果显示，即时分配在适应患者变异性和资源限制方面通常表现更优。在此基础上，论文进一步应用强化学习（RL）推导出近似最优的动态分配策略，并与现有最佳规则策略进行基准测试，旨在通过智能数据驱动的资源管理提升超声实验室效率。", "keywords": "超声心动图, 患者分配, 离散事件仿真, 强化学习, 资源管理", "comments": "这篇论文通过结合离散事件随机仿真和强化学习，为解决医院资源分配的复杂问题提供了一个数据驱动的创新方法。其亮点在于利用真实世界数据进行预处理，并对比了不同分配策略的有效性，特别是证明了即时分配在特定场景下的优势。强化学习的应用进一步提升了解决方案的优化潜力，为医院超声实验室等医疗机构的效率提升提供了可行的智能管理策略。"}}
{"id": "2506.06540", "title": "Large Language Models Can Be a Viable Substitute for Expert Political Surveys When a Shock Disrupts Traditional Measurement Approaches", "authors": ["Patrick Y. Wu"], "summary": "After a disruptive event or shock, such as the Department of Government\nEfficiency (DOGE) federal layoffs of 2025, expert judgments are colored by\nknowledge of the outcome. This can make it difficult or impossible to\nreconstruct the pre-event perceptions needed to study the factors associated\nwith the event. This position paper argues that large language models (LLMs),\ntrained on vast amounts of digital media data, can be a viable substitute for\nexpert political surveys when a shock disrupts traditional measurement. We\nanalyze the DOGE layoffs as a specific case study for this position. We use\npairwise comparison prompts with LLMs and derive ideology scores for federal\nexecutive agencies. These scores replicate pre-layoff expert measures and\npredict which agencies were targeted by DOGE. We also use this same approach\nand find that the perceptions of certain federal agencies as knowledge\ninstitutions predict which agencies were targeted by DOGE, even when\ncontrolling for ideology. This case study demonstrates that using LLMs allows\nus to rapidly and easily test the associated factors hypothesized behind the\nshock. More broadly, our case study of this recent event exemplifies how LLMs\noffer insights into the correlational factors of the shock when traditional\nmeasurement techniques fail. We conclude by proposing a two-part criterion for\nwhen researchers can turn to LLMs as a substitute for expert political surveys.", "comment": "19 pages, 6 figures", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06540v1", "AI": {"title_translation": "当冲击扰乱传统测量方法时，大型语言模型可以有效替代专家政治调查", "tldr": "当传统测量方法因冲击事件受阻时，大型语言模型（LLMs）可以作为专家政治调查的有效替代品，以重建事件前的认知并研究相关因素。", "motivation": "在颠覆性事件或冲击（如DOGE联邦裁员）发生后，专家判断会受到结果知识的影响，这使得重建研究事件相关因素所需的事件前认知变得困难或不可能。", "method": "本文论证了大型语言模型（LLMs）在冲击扰乱传统测量时可以替代专家政治调查。研究以DOGE裁员为例进行案例分析，使用LLMs进行配对比较提示，并得出联邦行政机构的意识形态得分。此外，研究还通过相同方法发现某些联邦机构作为知识机构的认知可以预测哪些机构被DOGE裁员，即使在控制意识形态的情况下。", "result": "LLM得出的机构意识形态得分复制了裁员前的专家测量结果，并成功预测了哪些机构成为DOGE的裁员目标。同时，某些联邦机构作为知识机构的认知也能预测裁员目标，即使在控制意识形态后。这表明LLMs可以快速、容易地测试冲击背后的假设相关因素。", "conclusion": "本文得出的结论是，利用大型语言模型（LLMs）可以在传统测量技术失效时，为冲击事件的相关因素提供见解。研究提出了一项两部分标准，指导研究人员何时可以将LLMs作为专家政治调查的替代品。", "translation": "在颠覆性事件或冲击（例如2025年政府效率部（DOGE）的联邦裁员）发生后，专家判断会受到结果知识的影响。这使得重建研究事件相关因素所需的事件前认知变得困难或不可能。这篇立场论文认为，当冲击扰乱传统测量时，经过大量数字媒体数据训练的大型语言模型（LLMs）可以有效替代专家政治调查。我们以DOGE裁员作为这一立场的具体案例研究。我们使用LLMs进行配对比较提示，并得出联邦行政机构的意识形态得分。这些得分复制了裁员前的专家测量结果，并预测了哪些机构成为DOGE的目标。我们还使用相同的方法发现，某些联邦机构作为知识机构的认知可以预测哪些机构成为DOGE的目标，即使在控制意识形态的情况下。这项案例研究表明，使用LLMs使我们能够快速、轻松地测试冲击背后假设的相关因素。更广泛地说，我们对这一近期事件的案例研究表明，当传统测量技术失效时，LLMs如何为冲击的相关因素提供见解。最后，我们提出了一个两部分标准，说明研究人员何时可以转向LLMs作为专家政治调查的替代品。", "summary": "本研究提出，在颠覆性事件导致传统测量方法失效时，大型语言模型（LLMs）可以有效替代专家政治调查，以重建事件前的认知。研究以DOGE联邦裁员为例，利用LLMs进行配对比较，成功复制了专家测量结果并预测了被裁机构。结果表明，LLMs能快速识别与冲击事件相关的因素，并提出何时使用LLMs替代专家调查的标准。", "keywords": "大型语言模型, 专家政治调查, 颠覆性事件, 政治测量, 案例研究", "comments": "这篇论文提出了一种创新性的方法，利用大型语言模型（LLMs）来解决政治学研究中一个关键的测量难题，即在重大事件发生后，传统专家调查可能存在的偏差问题。其重要性在于，它为在动态且难以进行传统数据收集的政治环境中，提供了一种新的、可行的研究工具。通过具体案例研究展示了LLMs的潜力，为LLMs在社会科学领域的应用开辟了新途径。论文的局限性可能在于，所提出的“两部分标准”的具体内容在摘要中并未详细阐述，且仅通过一个案例研究来验证其有效性，可能需要更多不同情境下的验证。"}}
{"id": "2506.06579", "title": "Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques", "authors": ["Adarsh Prasad Behera", "Jaya Prakash Champati", "Roberto Morabito", "Sasu Tarkoma", "James Gross"], "summary": "Recent progress in Language Models (LMs) has dramatically advanced the field\nof natural language processing (NLP), excelling at tasks like text generation,\nsummarization, and question answering. However, their inference remains\ncomputationally expensive and energy intensive, especially in settings with\nlimited hardware, power, or bandwidth. This makes it difficult to deploy LMs in\nmobile, edge, or cost sensitive environments. To address these challenges,\nrecent approaches have introduced multi LLM intelligent model selection\nstrategies that dynamically allocate computational resources based on query\ncomplexity -- using lightweight models for simpler queries and escalating to\nlarger models only when necessary. This survey explores two complementary\nstrategies for efficient LLM inference: (i) routing, which selects the most\nsuitable model based on the query, and (ii) cascading or hierarchical inference\n(HI), which escalates queries through a sequence of models until a confident\nresponse is found. Both approaches aim to reduce computation by using\nlightweight models for simpler tasks while offloading only when needed. We\nprovide a comparative analysis of these techniques across key performance\nmetrics, discuss benchmarking efforts, and outline open challenges. Finally, we\noutline future research directions to enable faster response times, adaptive\nmodel selection based on task complexity, and scalable deployment across\nheterogeneous environments, making LLM based systems more efficient and\naccessible for real world applications.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06579v1", "AI": {"title_translation": "迈向高效多大型语言模型推理：大型语言模型路由与分层技术的特征描述与分析", "tldr": "本综述探讨了两种提高大型语言模型推理效率的策略：路由和分层推理，旨在通过动态模型选择来降低计算成本。", "motivation": "大型语言模型（LLMs）的推理计算成本高昂且能耗大，尤其在硬件、功耗或带宽受限的环境中部署困难，限制了其在移动、边缘或成本敏感场景的应用。", "method": "本综述探讨了两种互补的LLM高效推理策略：(i) 路由，根据查询选择最合适的模型；(ii) 级联或分层推理（HI），通过模型序列逐步处理查询直至找到可靠响应。两种方法都旨在通过优先使用轻量级模型来减少计算。", "result": "本综述对这些技术进行了关键性能指标的比较分析，讨论了基准测试工作，并概述了开放挑战。", "conclusion": "未来的研究方向包括实现更快的响应时间、基于任务复杂性的自适应模型选择以及在异构环境中的可扩展部署，从而使基于LLM的系统在实际应用中更高效和易于访问。", "translation": "语言模型（LMs）的最新进展极大地推动了自然语言处理（NLP）领域的发展，在文本生成、摘要和问答等任务中表现出色。然而，它们的推理仍然计算成本高昂且能耗大，尤其是在硬件、功耗或带宽受限的环境中。这使得在移动、边缘或成本敏感环境中部署LMs变得困难。为了应对这些挑战，最近的方法引入了多LLM智能模型选择策略，根据查询复杂性动态分配计算资源——对简单查询使用轻量级模型，仅在必要时才升级到更大的模型。本综述探讨了两种互补的高效LLM推理策略：(i) 路由，根据查询选择最合适的模型；(ii) 级联或分层推理（HI），通过模型序列逐步处理查询，直到找到可靠的响应。这两种方法都旨在通过对简单任务使用轻量级模型，仅在需要时才进行卸载，从而减少计算。我们对这些技术在关键性能指标上进行了比较分析，讨论了基准测试工作，并概述了开放挑战。最后，我们概述了未来的研究方向，以实现更快的响应时间、基于任务复杂性的自适应模型选择以及在异构环境中的可扩展部署，从而使基于LLM的系统在实际应用中更高效和易于访问。", "summary": "本综述针对大型语言模型（LLMs）推理成本高昂的问题，探讨了两种提高效率的策略：路由和分层推理。这些方法通过动态选择模型（对简单查询使用轻量级模型，对复杂查询升级到大型模型）来优化资源分配并降低计算开销。论文对这些技术进行了比较分析，讨论了基准测试，并指出了未来的研究方向，旨在使LLM系统在实际应用中更高效、更易于访问，尤其是在资源受限的环境中。", "keywords": "大型语言模型, 推理效率, 模型路由, 分层推理, 计算优化", "comments": "这篇综述性文章对多LLM推理的效率问题进行了深入探讨，提出了路由和分层推理这两种重要的优化策略。其创新性在于系统性地比较了这些方法，并指出了未来的研究方向，对于推动LLM在资源受限环境中的实际部署具有重要意义。文章关注的是一个当前非常热门且具有挑战性的领域，即如何在保持LLM强大能力的同时降低其运行成本和能耗。"}}
{"id": "2506.06943", "title": "WiFi Pathologies Detection using LLMs", "authors": ["Forough Shirin Abkenar"], "summary": "In this paper, we fine-tune encoder-only and decoder-only large language\nmodels (LLMs) to detect pathologies in IEEE 802.11 networks, commonly known as\nWiFi. Our approach involves manually crafting prompts followed by fine-tuning.\nEvaluations show that the sequential model achieves high detection accuracy\nusing labeled data, while the causal model performs equally well for unlabeled\ndata.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06943v1", "AI": {"title_translation": "使用LLM进行WiFi故障检测", "tldr": "本文微调LLM来检测WiFi网络故障，其中序贯模型在有标签数据上表现良好，而因果模型在无标签数据上表现出色。", "motivation": "检测IEEE 802.11（WiFi）网络中的故障（pathologies）。", "method": "微调编码器-only和解码器-only大型语言模型（LLMs），方法包括手动设计提示词后进行微调。", "result": "评估显示，序贯模型在使用有标签数据时实现了高检测精度，而因果模型在无标签数据上的表现同样出色。", "conclusion": "通过微调LLMs，可以有效地检测WiFi网络故障，不同类型的LLM模型在有标签和无标签数据上表现出各自的优势。", "translation": "在本文中，我们对仅编码器和仅解码器的大型语言模型（LLMs）进行了微调，以检测IEEE 802.11网络（通常称为WiFi）中的故障。我们的方法涉及手动制作提示词，然后进行微调。评估表明，序贯模型在使用有标签数据时实现了高检测精度，而因果模型在无标签数据上的表现同样出色。", "summary": "本文研究了使用微调的大型语言模型（LLMs）来检测WiFi网络故障。通过手动设计提示词并对编码器-only和解码器-only LLMs进行微调，作者发现序贯模型在有标签数据上表现出高检测精度，而因果模型在无标签数据上同样表现良好，表明LLMs在WiFi故障诊断中的潜力。", "keywords": "WiFi故障检测, 大型语言模型, 微调, IEEE 802.11, 网络病理学", "comments": "这篇论文的创新点在于将大型语言模型应用于WiFi网络故障检测这一特定领域，并探索了不同类型的LLMs（编码器-only和解码器-only）在有标签和无标签数据上的性能差异。这为网络故障诊断提供了新的思路，并展示了LLMs在非传统NLP任务中的泛化能力。"}}
{"id": "2506.07551", "title": "ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning", "authors": ["Mengsong Wu", "YaFei Wang", "Yidong Ming", "Yuqi An", "Yuwei Wan", "Wenliang Chen", "Binbin Lin", "Yuqiang Li", "Tong Xie", "Dongzhan Zhou"], "summary": "Large language models (LLMs) have recently demonstrated promising\ncapabilities in chemistry tasks while still facing challenges due to outdated\npretraining knowledge and the difficulty of incorporating specialized chemical\nexpertise. To address these issues, we propose an LLM-based agent that\nsynergistically integrates 137 external chemical tools created ranging from\nbasic information retrieval to complex reaction predictions, and a dataset\ncuration pipeline to generate the dataset ChemToolBench that facilitates both\neffective tool selection and precise parameter filling during fine-tuning and\nevaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search\n(HE-MCTS) framework, enabling independent optimization of tool planning and\nexecution. By leveraging self-generated data, our approach supports step-level\nfine-tuning (FT) of the policy model and training task-adaptive PRM and ORM\nthat surpass GPT-4o. Experimental evaluations demonstrate that our approach\nsignificantly improves performance in Chemistry QA and discovery tasks,\noffering a robust solution to integrate specialized tools with LLMs for\nadvanced chemical applications. All datasets and code are available at\nhttps://github.com/AI4Chem/ChemistryAgent .", "comment": "15 pages, 6 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07551v1", "AI": {"title_translation": "ChemAgent：通过基于树搜索的工具学习增强化学和材料科学领域的大语言模型", "tldr": "ChemAgent通过集成137个化学工具和分层进化蒙特卡洛树搜索（HE-MCTS）显著提升了LLM在化学任务中的表现，甚至超越了GPT-4o。", "motivation": "大型语言模型（LLMs）在化学任务中面临预训练知识过时和难以整合专业化学知识的挑战。", "method": "提出ChemAgent，一个基于LLM的智能体，协同整合137个外部化学工具；创建数据集ChemToolBench以促进工具选择和参数填充；引入分层进化蒙特卡洛树搜索（HE-MCTS）框架，能够独立优化工具规划和执行；利用自生成数据支持策略模型的步级微调以及任务自适应PRM和ORM的训练。", "result": "实验评估表明，该方法显著提高了在化学问答和发现任务中的性能，并且训练的任务自适应PRM和ORM超越了GPT-4o。", "conclusion": "ChemAgent提供了一个强大的解决方案，将专业工具与大语言模型相结合，以实现先进的化学应用。", "translation": "大型语言模型（LLMs）最近在化学任务中展现出有前景的能力，但仍面临预训练知识过时以及难以整合专业化学知识的挑战。为了解决这些问题，我们提出了一种基于LLM的智能体——ChemAgent，它协同整合了137个外部化学工具，这些工具涵盖从基本信息检索到复杂反应预测的范围；并建立了一个数据集整理流程，以生成ChemToolBench数据集，该数据集有助于在微调和评估过程中进行有效的工具选择和精确的参数填充。我们引入了一种分层进化蒙特卡洛树搜索（HE-MCTS）框架，能够独立优化工具规划和执行。通过利用自生成数据，我们的方法支持策略模型的步级微调（FT），并训练出超越GPT-4o的任务自适应PRM和ORM。实验评估表明，我们的方法显著提高了在化学问答和发现任务中的性能，为将专业工具与LLM集成以实现高级化学应用提供了强大的解决方案。所有数据集和代码均可在https://github.com/AI4Chem/ChemistryAgent 获取。", "summary": "本文提出了ChemAgent，一个基于LLM的智能体，旨在解决当前LLM在化学领域面临的知识过时和专业知识整合难题。ChemAgent通过集成137个化学工具和一个名为ChemToolBench的数据集，并引入分层进化蒙特卡洛树搜索（HE-MCTS）框架，实现了对工具规划和执行的独立优化。该方法利用自生成数据进行步级微调，并训练出性能超越GPT-4o的任务自适应模型。实验证明，ChemAgent显著提升了LLM在化学问答和发现任务中的表现，为化学领域的高级应用提供了有效的工具集成方案。", "keywords": "化学大语言模型, 工具学习, 蒙特卡洛树搜索, 化学信息学, ChemAgent", "comments": "该论文的创新点在于其系统地集成了大量的化学专业工具（137个），并设计了HE-MCTS框架以优化工具的规划和执行，这大大增强了LLM在特定领域（化学）的专业能力。通过自生成数据进行步级微调，并声称超越GPT-4o，显示了其在解决特定领域知识瓶颈方面的潜力。这种将LLM与外部专业工具深度结合的范式，为未来其他专业领域LLM的发展提供了新的思路。"}}
{"id": "2506.06730", "title": "Fuse and Federate: Enhancing EV Charging Station Security with Multimodal Fusion and Federated Learning", "authors": ["Rabah Rahal", "Abdelaziz Amara Korba", "Yacine Ghamri-Doudane"], "summary": "The rapid global adoption of electric vehicles (EVs) has established electric\nvehicle supply equipment (EVSE) as a critical component of smart grid\ninfrastructure. While essential for ensuring reliable energy delivery and\naccessibility, EVSE systems face significant cybersecurity challenges,\nincluding network reconnaissance, backdoor intrusions, and distributed\ndenial-of-service (DDoS) attacks. These emerging threats, driven by the\ninterconnected and autonomous nature of EVSE, require innovative and adaptive\nsecurity mechanisms that go beyond traditional intrusion detection systems\n(IDS). Existing approaches, whether network-based or host-based, often fail to\ndetect sophisticated and targeted attacks specifically crafted to exploit new\nvulnerabilities in EVSE infrastructure. This paper proposes a novel intrusion\ndetection framework that leverages multimodal data sources, including network\ntraffic and kernel events, to identify complex attack patterns. The framework\nemploys a distributed learning approach, enabling collaborative intelligence\nacross EVSE stations while preserving data privacy through federated learning.\nExperimental results demonstrate that the proposed framework outperforms\nexisting solutions, achieving a detection rate above 98% and a precision rate\nexceeding 97% in decentralized environments. This solution addresses the\nevolving challenges of EVSE security, offering a scalable and privacypreserving\nresponse to advanced cyber threats", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06730v1", "AI": {"title_translation": "融合与联邦：通过多模态融合和联邦学习增强电动汽车充电站安全", "tldr": "本文提出了一种新颖的入侵检测框架，利用多模态数据融合和联邦学习，以提高电动汽车充电站的安全，有效检测复杂攻击，同时保护数据隐私。", "motivation": "电动汽车的快速普及使得电动汽车供电设备（EVSE）成为智能电网基础设施的关键组成部分。然而，EVSE系统面临严峻的网络安全挑战，如网络侦察、后门入侵和分布式拒绝服务（DDoS）攻击。现有入侵检测系统（IDS）难以检测针对EVSE基础设施新漏洞的复杂和定向攻击，因此需要创新和自适应的安全机制。", "method": "本文提出了一种新颖的入侵检测框架，该框架利用网络流量和内核事件等多模态数据源来识别复杂的攻击模式。该框架采用分布式学习方法，通过联邦学习在EVSE站点之间实现协作智能，同时保护数据隐私。", "result": "实验结果表明，所提出的框架优于现有解决方案，在去中心化环境中实现了98%以上的检测率和97%以上的精确率。", "conclusion": "该解决方案解决了电动汽车供电设备（EVSE）安全不断演变的问题，为高级网络威胁提供了可扩展且保护隐私的响应。", "translation": "电动汽车（EV）在全球的快速普及已将电动汽车供电设备（EVSE）确立为智能电网基础设施的关键组成部分。虽然对于确保可靠的能源输送和可访问性至关重要，但EVSE系统面临着严峻的网络安全挑战，包括网络侦察、后门入侵和分布式拒绝服务（DDoS）攻击。这些新兴威胁，由EVSE的互联和自治特性驱动，需要创新和自适应的安全机制，超越传统的入侵检测系统（IDS）。现有方法，无论是基于网络的还是基于主机的，往往无法检测专门为利用EVSE基础设施新漏洞而设计的复杂和定向攻击。本文提出了一种新颖的入侵检测框架，该框架利用多模态数据源，包括网络流量和内核事件，来识别复杂的攻击模式。该框架采用分布式学习方法，通过联邦学习在EVSE站点之间实现协作智能，同时保护数据隐私。实验结果表明，所提出的框架优于现有解决方案，在去中心化环境中实现了98%以上的检测率和97%以上的精确率。该解决方案解决了EVSE安全不断演变的问题，为高级网络威胁提供了可扩展且保护隐私的响应。", "summary": "本文提出了一种创新的入侵检测框架，旨在增强电动汽车充电站（EVSE）的安全性。该框架通过融合网络流量和内核事件等多模态数据来识别复杂攻击模式，并利用联邦学习实现分布式协作智能，同时确保数据隐私。实验证明，该框架在去中心化环境中表现优异，检测率和精确率均超过97%，有效应对了EVSE日益严峻的网络安全挑战。", "keywords": "电动汽车充电站安全, 多模态融合, 联邦学习, 入侵检测, 网络安全", "comments": "该论文的创新点在于结合了多模态数据融合和联邦学习来解决电动汽车充电站的安全问题。多模态数据的使用增强了对复杂攻击模式的检测能力，而联邦学习则有效解决了数据隐私和可扩展性问题，这对于分布式智能电网基础设施至关重要。该方法在实际应用中具有重要意义，因为它为关键基础设施提供了更强的网络弹性。"}}
{"id": "2506.06325", "title": "Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies", "authors": ["Viorica Rozina Chifu", "Tudor Cioara", "Cristina Bianca Pop", "Ionut Anghel"], "summary": "This paper proposes a decentralized model of energy cooperation between\nmicrogrids, in which decisions are made locally, at the level of the microgrid\ncommunity. Each microgrid is modeled as an autonomous agent that adopts a Hawk\nor Dove strategy, depending on the level of energy stored in the battery and\nits role in the energy trading process. The interactions between selling and\nbuying microgrids are modeled through an evolutionary algorithm. An individual\nin the algorithm population is represented as an energy trading matrix that\nencodes the amounts of energy traded between the selling and buying microgrids.\nThe population evolution is achieved by recombination and mutation operators.\nRecombination uses a specialized operator for matrix structures, and mutation\nis applied to the matrix elements according to a Gaussian distribution. The\nevaluation of an individual is made with a multi-criteria fitness function that\nconsiders the seller profit, the degree of energy stability at the community\nlevel, penalties for energy imbalance at the community level and for the\ndegradation of microgrids batteries. The method was tested on a simulated\nscenario with 100 microgrids, each with its own selling and buying thresholds,\nto reflect a realistic environment with variable storage characteristics of\nmicrogrids batteries. By applying the algorithm on this scenario, 95 out of the\n100 microgrids reached a stable energy state. This result confirms the\neffectiveness of the proposed model in achieving energy balance both at the\nindividual level, for each microgrid, and at the level of the entire community.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06325v1", "AI": {"title_translation": "社区微电网中基于鹰鸽策略的能源交易演化模型", "tldr": "提出一种去中心化能源合作模型，通过演化算法和鹰鸽策略实现社区微电网的能源平衡。", "motivation": "解决社区微电网中去中心化能源合作的问题，实现能源交易的本地决策和能源平衡。", "method": "本文提出一个去中心化的能源合作模型，将每个微电网建模为采用鹰或鸽策略的自主代理。通过演化算法模拟买卖微电网之间的互动，其中个体表示为能源交易矩阵。算法通过重组和变异操作实现种群演化，并使用多标准适应度函数进行评估，考虑了卖方利润、社区能源稳定性、能源不平衡惩罚和电池退化。", "result": "该方法在一个包含100个微电网的模拟场景中进行了测试，其中95个微电网达到了稳定的能源状态。", "conclusion": "结果证实了所提出模型在实现个体微电网和整个社区层面能源平衡的有效性。", "translation": "本文提出了一种微电网之间能源合作的去中心化模型，其中决策在微电网社区层面本地做出。每个微电网都被建模为一个自主代理，根据电池中存储的能量水平及其在能源交易过程中的作用，采用鹰或鸽策略。买卖微电网之间的相互作用通过演化算法进行建模。算法种群中的个体表示为能量交易矩阵，该矩阵编码了买卖微电网之间交易的能量量。种群演化通过重组和变异操作实现。重组使用针对矩阵结构的专门操作符，变异根据高斯分布应用于矩阵元素。个体的评估通过多标准适应度函数进行，该函数考虑了卖方利润、社区层面的能量稳定性、社区层面的能量不平衡惩罚以及微电网电池的退化。该方法在一个包含100个微电网的模拟场景中进行了测试，每个微电网都有自己的买卖阈值，以反映具有可变微电网电池存储特性的现实环境。通过将算法应用于此场景，100个微电网中有95个达到了稳定的能源状态。这一结果证实了所提出模型在实现个体微电网和整个社区层面能源平衡的有效性。", "summary": "本文提出了一种基于鹰鸽策略的去中心化演化模型，用于社区微电网的能源交易与合作。模型将微电网视为自主代理，其行为（鹰或鸽）取决于电池能量水平。通过演化算法模拟微电网间的能源交易，以能源交易矩阵为个体，并利用多标准适应度函数进行评估。在包含100个微电网的模拟场景中，该模型成功使95个微电网达到稳定能源状态，证明了其在实现个体和社区层面能源平衡的有效性。", "keywords": "社区微电网, 能源交易, 演化算法, 鹰鸽策略, 去中心化模型", "comments": "该论文提出了一种新颖的将演化算法和博弈论（鹰鸽策略）应用于社区微电网能源交易的去中心化模型。其创新性在于将微电网行为抽象为简单的博弈策略，并通过演化过程优化整体能源平衡。模型的去中心化特性使其更适用于实际部署，且在模拟场景中表现出良好的能源稳定效果。"}}
{"id": "2506.06562", "title": "Towards Terrain-Aware Task-Driven 3D Scene Graph Generation in Outdoor Environments", "authors": ["Chad R Samuelson", "Timothy W McLain", "Joshua G Mangelson"], "summary": "High-level autonomous operations depend on a robot's ability to construct a\nsufficiently expressive model of its environment. Traditional three-dimensional\n(3D) scene representations, such as point clouds and occupancy grids, provide\ndetailed geometric information but lack the structured, semantic organization\nneeded for high-level reasoning. 3D scene graphs (3DSGs) address this\nlimitation by integrating geometric, topological, and semantic relationships\ninto a multi-level graph-based representation. By capturing hierarchical\nabstractions of objects and spatial layouts, 3DSGs enable robots to reason\nabout environments in a structured manner, improving context-aware\ndecision-making and adaptive planning. Although most recent work has focused on\nindoor 3DSGs, this paper investigates their construction and utility in outdoor\nenvironments. We present a method for generating a task-agnostic\nmetric-semantic point cloud for large outdoor settings and propose\nmodifications to existing indoor 3DSG generation techniques for outdoor\napplicability. Our preliminary qualitative results demonstrate the feasibility\nof outdoor 3DSGs and highlight their potential for future deployment in\nreal-world field robotic applications.", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06562v1", "AI": {"title_translation": "面向室外环境下地形感知和任务驱动的3D场景图生成", "tldr": "本文探讨了在室外环境中生成3D场景图（3DSGs），以支持高水平自主操作。", "motivation": "传统的3D场景表示（如点云和占用网格）缺乏高水平推理所需的结构化语义组织。3D场景图（3DSGs）通过整合几何、拓扑和语义关系来解决这一问题，从而实现结构化推理、上下文感知决策和自适应规划。然而，大多数现有工作集中在室内3DSGs，因此需要研究其在室外环境中的构建和实用性。", "method": "本文提出了一种为大型室外环境生成与任务无关的度量语义点云的方法，并对现有室内3DSG生成技术进行了修改以适用于室外环境。", "result": "初步定性结果表明了室外3DSGs的可行性。", "conclusion": "室外3DSGs是可行的，并有望在未来的实际野外机器人应用中部署，以改善高水平自主操作的上下文感知决策和自适应规划。", "translation": "高水平自主操作依赖于机器人构建足够表达性环境模型的能力。传统的三维（3D）场景表示，如点云和占用网格，提供详细的几何信息但缺乏高水平推理所需的结构化语义组织。3D场景图（3DSGs）通过将几何、拓扑和语义关系集成到多级图表示中来解决这一限制。通过捕获对象和空间布局的层次抽象，3DSGs使机器人能够以结构化方式对环境进行推理，从而改善上下文感知决策和自适应规划。尽管最近的大多数工作都集中在室内3DSGs上，但本文研究了它们在室外环境中的构建和实用性。我们提出了一种为大型室外环境生成与任务无关的度量语义点云的方法，并提出了对现有室内3DSG生成技术的修改以适用于室外。我们的初步定性结果证明了室外3DSGs的可行性，并突出了它们在未来实际野外机器人应用中部署的潜力。", "summary": "本文旨在解决传统3D场景表示在机器人高层推理方面的局限性，重点研究3D场景图（3DSGs）在室外环境中的生成和应用。与以往多数侧重于室内环境的工作不同，作者提出了一种生成与任务无关的度量语义点云的方法，并对现有室内3DSG技术进行了修改以适应室外应用。初步的定性结果证明了室外3DSGs的可行性，并强调了它们在实际野外机器人应用中增强上下文感知决策和自适应规划的潜力。", "keywords": "3D场景图, 室外环境, 自主操作, 机器人应用, 点云", "comments": "该论文的创新之处在于将主要在室内环境中研究的3D场景图扩展到更具挑战性的室外环境，这对于推进野外机器人的高水平自主操作至关重要。尽管摘要中未详细说明方法，但对地形感知和任务驱动的关注暗示了其在实际应用中的潜力。初步的定性结果虽然不是定量数据，但为该重要领域未来的研究奠定了基础。"}}
{"id": "2506.07743", "title": "Quantum-Enhanced Spectral Solution of the Poisson Equation", "authors": ["G. Intoccia", "U. Chirico", "G. Pepe", "S. Cuomo"], "summary": "We present a hybrid numerical-quantum method for solving the Poisson equation\nunder homogeneous Dirichlet boundary conditions, leveraging the Quantum Fourier\nTransform (QFT) to enhance computational efficiency and reduce time and space\ncomplexity. This approach bypasses the integration-heavy calculations of\nclassical methods, which have to deal with high computational costs for large\nnumber of points. The proposed method estimates the coefficients of the series\nexpansion of the solution directly within the quantum framework. Numerical\nexperiments validate its effectiveness and reveal significant improvements in\nterms of time and space complexity and solution accuracy, demonstrating the\ncapability of quantum-assisted techniques to contribute in solving partial\ndifferential equations (PDEs). Despite the inherent challenges of quantum\nimplementation, the present work serves as a starting point for future\nresearches aimed at refining and expanding quantum numerical methods.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07743v1", "AI": {"title_translation": "量子增强的泊松方程谱解法", "tldr": "本文提出了一种混合数值-量子方法，利用量子傅里叶变换（QFT）求解泊松方程，显著提高了计算效率并降低了时间和空间复杂度。", "motivation": "经典的泊松方程解法涉及大量积分计算，对于大量数据点而言计算成本高昂，因此需要一种更高效的方法。", "method": "本文提出了一种混合数值-量子方法，利用量子傅里叶变换（QFT）来增强计算效率并降低时间和空间复杂度。该方法直接在量子框架内估计解的级数展开系数，从而避免了经典方法中繁重的积分计算。", "result": "数值实验验证了该方法的有效性，并在时间、空间复杂度和解的准确性方面取得了显著改进。", "conclusion": "量子辅助技术能够有效解决偏微分方程（PDEs）。尽管量子实现存在固有的挑战，但这项工作为未来完善和扩展量子数值方法的研究奠定了基础。", "translation": "我们提出了一种用于齐次狄利克雷边界条件下求解泊松方程的混合数值-量子方法，该方法利用量子傅里叶变换（QFT）来提高计算效率并降低时间和空间复杂度。这种方法绕过了经典方法中繁重的积分计算，后者在处理大量数据点时计算成本很高。所提出的方法直接在量子框架内估计解的级数展开系数。数值实验验证了其有效性，并在时间、空间复杂度和解的准确性方面取得了显著改进，展示了量子辅助技术在解决偏微分方程（PDEs）方面的能力。尽管量子实现存在固有的挑战，但目前的工作为未来旨在完善和扩展量子数值方法的研究提供了一个起点。", "summary": "该论文介绍了一种混合数值-量子方法，通过利用量子傅里叶变换（QFT）来高效地求解泊松方程，特别是在处理齐次狄利克雷边界条件时。该方法避免了传统方法的积分密集型计算，直接在量子领域估计解的级数展开系数。实验结果表明，与经典方法相比，该方法在计算时间、空间复杂度和解的准确性方面都有显著提升，凸显了量子辅助技术在解决偏微分方程中的潜力。", "keywords": "泊松方程, 量子傅里叶变换, 混合方法, 偏微分方程, 计算复杂度", "comments": "这项工作在量子计算应用于偏微分方程求解方面迈出了重要一步，特别是通过利用QFT来优化计算效率和资源消耗。其创新性在于将量子框架与数值方法相结合，直接估计系数，从而绕过经典计算的瓶颈。尽管论文承认量子实现仍面临挑战，但它为未来量子数值算法的发展提供了一个有价值的起点，对高性能计算和科学模拟领域具有潜在影响。"}}
{"id": "2506.07419", "title": "Generate Realistic Test Scenes for V2X Communication Systems", "authors": ["An Guo", "Xinyu Gao", "Chunrong Fang", "Haoxiang Tian", "Weisong Sun", "Yanzhou Mu", "Shuncheng Tang", "Lei Ma", "Zhenyu Chen"], "summary": "Accurately perceiving complex driving environments is essential for ensuring\nthe safe operation of autonomous vehicles. With the tremendous progress in deep\nlearning and communication technologies, cooperative perception with\nVehicle-to-Everything (V2X) technologies has emerged as a solution to overcome\nthe limitations of single-agent perception systems in perceiving distant\nobjects and occlusions. Despite the considerable advancements, V2X cooperative\nperception systems require thorough testing and continuous enhancement of\nsystem performance. Given that V2X driving scenes entail intricate\ncommunications with multiple vehicles across various geographic locations,\ncreating V2X test scenes for these systems poses a significant challenge.\nMoreover, current testing methodologies rely on manual data collection and\nlabeling, which are both time-consuming and costly.\n  In this paper, we design and implement V2XGen, an automated testing\ngeneration tool for V2X cooperative perception systems. V2XGen utilizes a\nhigh-fidelity approach to generate realistic cooperative object instances and\nstrategically place them within the background data in crucial positions.\nFurthermore, V2XGen adopts a fitness-guided V2X scene generation strategy for\nthe transformed scene generation process and improves testing efficiency. We\nconduct experiments on V2XGen using multiple cooperative perception systems\nwith different fusion schemes to assess its performance on various tasks. The\nexperimental results demonstrate that V2XGen is capable of generating realistic\ntest scenes and effectively detecting erroneous behaviors in different\nV2X-oriented driving conditions. Furthermore, the results validate that\nretraining systems under test with the generated scenes can enhance average\ndetection precision while reducing occlusion and long-range perception errors.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07419v1", "AI": {"title_translation": "生成V2X通信系统逼真测试场景", "tldr": "V2XGen是一个自动测试场景生成工具，能生成逼真的V2X场景并有效检测系统错误，还能通过再训练提升感知性能。", "motivation": "自动驾驶车辆的安全运行需要准确感知复杂驾驶环境。V2X协同感知技术可以克服单智能体感知的局限性，但需要彻底的测试和持续的性能提升。创建V2X测试场景面临挑战，因为涉及多车、多地理位置的复杂通信，且现有测试方法耗时且成本高昂。", "method": "本文设计并实现了V2XGen，一个用于V2X协同感知系统的自动化测试生成工具。V2XGen采用高保真方法生成逼真的协同对象实例，并将其策略性地放置在背景数据中的关键位置。此外，V2XGen采用适应度引导的V2X场景生成策略进行场景转换生成过程，并提高了测试效率。", "result": "实验结果表明，V2XGen能够生成逼真的测试场景，并有效检测不同V2X驾驶条件下的错误行为。此外，结果验证了使用生成场景对被测系统进行再训练可以提高平均检测精度，同时减少遮挡和远距离感知错误。", "conclusion": "V2XGen能够生成逼真的V2X测试场景，有效检测系统错误，并通过再训练提升协同感知系统的性能，从而克服了现有测试方法的挑战。", "translation": "准确感知复杂的驾驶环境对于确保自动驾驶车辆的安全运行至关重要。随着深度学习和通信技术的巨大进步，V2X（车联网）技术的协同感知已成为克服单智能体感知系统在感知远距离物体和遮挡方面的局限性的一种解决方案。尽管取得了长足的进步，V2X协同感知系统仍需要彻底的测试和系统性能的持续增强。鉴于V2X驾驶场景涉及多个车辆在不同地理位置的复杂通信，为这些系统创建V2X测试场景带来了重大挑战。此外，当前的测试方法依赖于手动数据收集和标记，这既耗时又昂贵。\n在本文中，我们设计并实现了V2XGen，一个用于V2X协同感知系统的自动化测试生成工具。V2XGen利用高保真方法生成逼真的协同对象实例，并将其策略性地放置在背景数据中的关键位置。此外，V2XGen采用适应度引导的V2X场景生成策略进行转换后的场景生成过程，并提高了测试效率。我们使用具有不同融合方案的多个协同感知系统对V2XGen进行了实验，以评估其在各种任务上的性能。实验结果表明，V2XGen能够生成逼真的测试场景，并有效检测不同V2X驾驶条件下的错误行为。此外，结果验证了使用生成场景对被测系统进行再训练可以提高平均检测精度，同时减少遮挡和远距离感知错误。", "summary": "本文提出V2XGen，一个用于V2X协同感知系统的自动化测试场景生成工具。针对现有测试方法耗时且成本高的问题，V2XGen通过高保真方法生成逼真的协同对象实例并进行策略性放置，同时采用适应度引导策略提高效率。实验证明V2XGen能生成逼真场景，有效检测系统错误行为，并且使用生成场景进行再训练可提升检测精度并减少感知错误。", "keywords": "V2X通信, 协同感知, 测试场景生成, 自动化测试, V2XGen", "comments": "V2XGen的创新之处在于其自动化生成逼真V2X测试场景的能力，解决了手动数据收集和标记耗时耗费的问题。其适应度引导的场景生成策略和高保真对象实例生成方法，使得生成的场景能够有效检测系统错误并提升协同感知系统的性能，对于V2X系统的开发和测试具有重要意义。"}}
{"id": "2506.06596", "title": "EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras", "authors": ["Youssef Farah", "Federico Paredes-Vallés", "Guido De Croon", "Muhammad Ahmed Humais", "Hussain Sajwani", "Yahya Zweiri"], "summary": "Event cameras are novel bio-inspired sensors that capture motion dynamics\nwith much higher temporal resolution than traditional cameras, since pixels\nreact asynchronously to brightness changes. They are therefore better suited\nfor tasks involving motion such as motion segmentation. However, training\nevent-based networks still represents a difficult challenge, as obtaining\nground truth is very expensive, error-prone and limited in frequency. In this\narticle, we introduce EV-LayerSegNet, a self-supervised CNN for event-based\nmotion segmentation. Inspired by a layered representation of the scene\ndynamics, we show that it is possible to learn affine optical flow and\nsegmentation masks separately, and use them to deblur the input events. The\ndeblurring quality is then measured and used as self-supervised learning loss.\nWe train and test the network on a simulated dataset with only affine motion,\nachieving IoU and detection rate up to 71% and 87% respectively.", "comment": "This paper has been accepted for publication at the IEEE Conference\n  on Computer Vision and Pattern Recognition (CVPR) Workshops, Nashville, 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06596v1", "AI": {"title_translation": "EV-LayerSegNet: 使用事件相机进行自监督运动分割", "tldr": "EV-LayerSegNet是一种自监督CNN，用于事件相机的运动分割，通过学习仿射光流和分割掩码来去模糊输入事件，并使用去模糊质量作为自监督学习损失，在模拟数据集上取得了不错的性能。", "motivation": "传统相机在捕捉运动动态方面的时间分辨率较低，而事件相机更适合运动分割任务。然而，训练基于事件的网络面临挑战，因为获取真值非常昂贵、易出错且频率有限。", "method": "本文引入了EV-LayerSegNet，一个用于事件运动分割的自监督CNN。受场景动态分层表示的启发，该方法能够分别学习仿射光流和分割掩码，并利用它们对输入事件进行去模糊处理。去模糊质量被用作自监督学习损失。", "result": "在仅包含仿射运动的模拟数据集上训练和测试了网络，其IoU（交并比）达到了71%，检测率达到了87%。", "conclusion": "该研究表明，通过自监督学习，利用场景的层状表示进行事件去模糊，可以有效地实现事件相机的运动分割。", "translation": "事件相机是一种新型的仿生传感器，与传统相机相比，由于像素对亮度变化异步反应，它们能够以更高的时间分辨率捕捉运动动态。因此，它们更适合涉及运动的任务，例如运动分割。然而，训练基于事件的网络仍然是一个巨大的挑战，因为获取真值非常昂贵、容易出错且频率受限。在本文中，我们介绍了EV-LayerSegNet，一个用于事件运动分割的自监督CNN。受场景动态分层表示的启发，我们展示了可以分别学习仿射光流和分割掩码，并使用它们来对输入事件进行去模糊。然后测量去模糊质量，并将其用作自监督学习损失。我们在一个仅包含仿射运动的模拟数据集上训练和测试了该网络，实现了高达71%的IoU和87%的检测率。", "summary": "EV-LayerSegNet是一个针对事件相机运动分割的自监督卷积神经网络。为了解决传统事件网络训练中真值获取困难的问题，该方法借鉴场景分层表示，独立学习仿射光流和分割掩码，并利用它们对事件进行去模糊。去模糊质量被作为自监督学习的损失函数。在模拟数据集上，该网络在仿射运动分割任务中取得了71%的IoU和87%的检测率，验证了其有效性。", "keywords": "事件相机, 运动分割, 自监督学习, 仿射光流, 深度学习", "comments": "EV-LayerSegNet的创新之处在于其自监督学习范式，这极大地降低了对昂贵且难以获取的真值标注的依赖。通过将去模糊质量作为自监督信号，该方法巧妙地利用了事件相机固有的特性。该研究为事件相机在运动分割领域的应用开辟了新的途径，尤其是在真值稀缺的场景下具有重要意义。然而，目前仅在模拟的仿射运动数据集上进行了验证，未来需要进一步在真实世界复杂场景中进行测试。"}}
{"id": "2506.06367", "title": "Towards Foundation Model on Temporal Knowledge Graph Reasoning", "authors": ["Jiaxin Pan", "Mojtaba Nayyeri", "Osama Mohammed", "Daniel Hernandez", "Rongchuan Zhang", "Cheng Cheng", "Steffen Staab"], "summary": "Temporal Knowledge Graphs (TKGs) store temporal facts with quadruple formats\n(s, p, o, t). Existing Temporal Knowledge Graph Embedding (TKGE) models perform\nlink prediction tasks in transductive or semi-inductive settings, which means\nthe entities, relations, and temporal information in the test graph are fully\nor partially observed during training. Such reliance on seen elements during\ninference limits the models' ability to transfer to new domains and generalize\nto real-world scenarios. A central limitation is the difficulty in learning\nrepresentations for entities, relations, and timestamps that are transferable\nand not tied to dataset-specific vocabularies. To overcome these limitations,\nwe introduce the first fully-inductive approach to temporal knowledge graph\nlink prediction. Our model employs sinusoidal positional encodings to capture\nfine-grained temporal patterns and generates adaptive entity and relation\nrepresentations using message passing conditioned on both local and global\ntemporal contexts. Our model design is agnostic to temporal granularity and\ntime span, effectively addressing temporal discrepancies across TKGs and\nfacilitating time-aware structural information transfer. As a pretrained,\nscalable, and transferable model, POSTRA demonstrates strong zero-shot\nperformance on unseen temporal knowledge graphs, effectively generalizing to\nnovel entities, relations, and timestamps. Extensive theoretical analysis and\nempirical results show that a single pretrained model can improve zero-shot\nperformance on various inductive temporal reasoning scenarios, marking a\nsignificant step toward a foundation model for temporal KGs.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06367v1", "AI": {"title_translation": "迈向时序知识图谱推理的基础模型", "tldr": "提出首个全归纳时序知识图谱链接预测方法POSTRA，通过预训练实现对未知TKGs的零样本泛化，迈向时序KG基础模型。", "motivation": "现有时序知识图谱嵌入（TKGE）模型在归纳或半归纳设置下进行链接预测，依赖训练期间已观测到的实体、关系和时间信息，限制了模型向新领域迁移和泛化到真实世界场景的能力，难以学习可迁移且不依赖数据集特定词汇的表示。", "method": "引入首个全归纳的时序知识图谱链接预测方法POSTRA。该模型采用正弦位置编码来捕获精细时间模式，并利用消息传递，结合局部和全局时间上下文生成自适应实体和关系表示。模型设计与时间粒度和时间跨度无关，有效解决了TKGs之间的时间差异，促进了时间感知结构信息的传递。", "result": "POSTRA作为一种预训练、可扩展和可迁移的模型，在未见过的时序知识图谱上表现出强大的零样本性能，有效地泛化到新实体、关系和时间戳。广泛的理论分析和实证结果表明，单个预训练模型可以提高各种归纳时序推理场景的零样本性能。", "conclusion": "该研究代表了向时序知识图谱基础模型迈出的重要一步，通过实现对新实体、关系和时间戳的零样本泛化能力，克服了现有模型的局限性。", "translation": "时序知识图谱（TKGs）以四元组形式（s, p, o, t）存储时序事实。现有的时序知识图谱嵌入（TKGE）模型在直推式或半归纳式设置下执行链接预测任务，这意味着测试图中的实体、关系和时间信息在训练期间是完全或部分可见的。这种在推理时对已见元素的依赖限制了模型向新领域迁移和泛化到真实世界场景的能力。一个核心局限在于难以学习可迁移且不依赖数据集特定词汇的实体、关系和时间戳表示。为了克服这些局限性，我们引入了首个针对时序知识图谱链接预测的全归纳方法。我们的模型采用正弦位置编码来捕获细粒度的时间模式，并利用消息传递，结合局部和全局时间上下文生成自适应实体和关系表示。我们的模型设计与时间粒度和时间跨度无关，有效解决了TKGs之间的时间差异，并促进了时间感知结构信息的传递。作为一种预训练、可扩展和可迁移的模型，POSTRA在未见过的时序知识图谱上展示了强大的零样本性能，有效地泛化到新实体、关系和时间戳。广泛的理论分析和实证结果表明，单个预训练模型可以提高各种归纳时序推理场景的零样本性能，标志着向时序知识图谱基础模型迈出了重要一步。", "summary": "本文提出POSTRA，首个用于时序知识图谱（TKG）链接预测的全归纳方法。针对现有TKGE模型在面对新实体、关系和时间戳时泛化能力不足的问题，POSTRA通过正弦位置编码捕获时间模式，并利用消息传递生成自适应实体和关系表示。该模型设计独立于时间粒度和跨度，并通过预训练实现对未见TKGs的强大零样本性能，显著提升了在归纳时序推理场景中的泛化能力，为构建时序KG基础模型奠定了基础。", "keywords": "时序知识图谱, 链接预测, 全归纳学习, 基础模型, 零样本学习", "comments": "本文的创新点在于提出了首个全归纳的时序知识图谱链接预测方法POSTRA，突破了传统TKGE模型对已知元素的依赖。通过实现零样本泛化能力，POSTRA有望成为时序知识图谱领域的基础模型，极大地提升模型在真实世界复杂动态场景中的应用潜力，解决了跨领域和新数据泛化的核心挑战。"}}
{"id": "2506.07599", "title": "Flexible MIMO for Future Wireless Communications: Which Flexibilities are Possible?", "authors": ["Zhe Wang", "Jiayi Zhang", "Bokai Xu", "Wenhui Yi", "Emil Björnson", "Bo Ai"], "summary": "To enable next-generation wireless communication networks with modest\nspectrum availability, multiple-input multiple-output (MIMO) technology needs\nto undergo further evolution. In this paper, we introduce a promising\nnext-generation wireless communication concept: flexible MIMO technology. This\ntechnology represents a MIMO technology with flexible physical configurations\nand integrated applications. We categorize twelve representative flexible MIMO\ntechnologies into three major classifications: flexible deployment\ncharacteristics-based, flexible geometry characteristics-based, and flexible\nreal-time modifications-based. Then, we provide a comprehensive overview of\ntheir fundamental characteristics, potential, and challenges. Furthermore, we\ndemonstrate three vital enablers for the flexible MIMO technology, including\nefficient channel state information (CSI) acquisition schemes, low-complexity\nbeamforming design, and explainable artificial intelligence (AI)-enabled\noptimization. Within these areas, eight critical sub-enabling technologies are\ndiscussed in detail. Finally, we present two case studies-pre-optimized\nirregular arrays and cell-free movable antennas-where significant potential for\nflexible MIMO technologies to enhance the system capacity is showcased.", "comment": "9 pages, 5 figures, 1 table", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07599v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07665", "title": "FREESS: An Educational Simulator of a RISC-V-Inspired Superscalar Processor Based on Tomasulo's Algorithm", "authors": ["Roberto Giorgi"], "summary": "FREESS is a free, interactive simulator that illustrates instruction-level\nparallelism in a RISC-V-inspired superscalar processor. Based on an extended\nversion of Tomasulo's algorithm, FREESS is intended as a hands-on educational\ntool for Advanced Computer Architecture courses. It enables students to explore\ndynamic, out-of-order instruction execution, emphasizing how instructions are\nissued as soon as their operands become available.\n  The simulator models key microarchitectural components, including the\nInstruction Window (IW), Reorder Buffer (ROB), Register Map (RM), Free Pool\n(FP), and Load/Store Queues. FREESS allows users to dynamically configure\nruntime parameters, such as the superscalar issue width, functional unit types\nand latencies, and the sizes of architectural buffers and queues.\n  To simplify learning, the simulator uses a minimal instruction set inspired\nby RISC-V (ADD, ADDI, BEQ, BNE, LW, MUL, SW), which is sufficient to\ndemonstrate key pipeline stages: fetch, register renaming, out-of-order\ndispatch, execution, completion, commit, speculative branching, and memory\naccess. FREESS includes three step-by-step, illustrated examples that visually\ndemonstrate how multiple instructions can be issued and executed in parallel\nwithin a single cycle. Being open source, FREESS encourages students and\neducators to experiment freely by writing and analyzing their own\ninstruction-level programs and superscalar architectures.", "comment": "WCAE'25 - Workshop on Computer Architecture Education, June 21--25,\n  2025, Tokyo, Japan", "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07665v1", "AI": {"title_translation": "FREESS：一个基于Tomasulo算法的RISC-V启发式超标量处理器教育模拟器", "tldr": "FREESS是一个免费、交互式的教育模拟器，用于演示基于Tomasulo算法的RISC-V超标量处理器中的指令级并行。", "motivation": "FREESS旨在作为高级计算机体系结构课程的实践教育工具，帮助学生探索动态、乱序指令执行，并理解指令如何在其操作数可用时立即发出。", "method": "FREESS是一个基于Tomasulo算法扩展版本的模拟器，它建模了关键的微体系结构组件，如指令窗口（IW）、重排序缓冲区（ROB）、寄存器映射（RM）、空闲池（FP）和加载/存储队列。它允许用户动态配置运行时参数，并使用受RISC-V启发的最少指令集来演示关键流水线阶段。", "result": "FREESS使学生能够探索动态、乱序指令执行，强调指令在其操作数可用时如何发出。它能演示取指、寄存器重命名、乱序分派、执行、完成、提交、推测分支和内存访问等关键流水线阶段，并提供分步示例，视觉上展示多条指令如何在单个周期内并行发出和执行。", "conclusion": "FREESS是一个免费、开源的教育模拟器，它通过提供实践工具和示例，鼓励学生和教育工作者自由地编写和分析自己的指令级程序和超标量架构，从而深入理解指令级并行。", "translation": "FREESS是一个免费的交互式模拟器，它演示了RISC-V启发式超标量处理器中的指令级并行。FREESS基于Tomasulo算法的扩展版本，旨在作为高级计算机体系结构课程的实践教育工具。它使学生能够探索动态、乱序指令执行，强调指令在其操作数可用时立即发出。该模拟器模拟了关键的微体系结构组件，包括指令窗口（IW）、重排序缓冲区（ROB）、寄存器映射（RM）、空闲池（FP）和加载/存储队列。FREESS允许用户动态配置运行时参数，例如超标量发射宽度、功能单元类型和延迟，以及架构缓冲区和队列的大小。为了简化学习，该模拟器使用受RISC-V启发的最少指令集（ADD、ADDI、BEQ、BNE、LW、MUL、SW），足以演示关键的流水线阶段：取指、寄存器重命名、乱序分派、执行、完成、提交、推测分支和内存访问。FREESS包含三个分步的、带图示的示例，直观地演示了如何在单个周期内并行发出和执行多条指令。作为开源项目，FREESS鼓励学生和教育工作者通过编写和分析自己的指令级程序和超标量架构来自由实验。", "summary": "FREESS是一个免费、交互式的教育模拟器，旨在帮助高级计算机体系结构课程的学生理解RISC-V启发式超标量处理器中的指令级并行和乱序执行。它基于扩展的Tomasulo算法，模拟了关键的微体系结构组件，并允许动态配置参数。通过使用精简的RISC-V指令集和分步示例，FREESS清晰地演示了流水线阶段和多指令并行执行，并作为一个开源工具鼓励用户进行实验。", "keywords": "RISC-V, 超标量处理器, Tomasulo算法, 教育模拟器, 指令级并行", "comments": "FREESS的创新之处在于它提供了一个免费、交互式且开源的平台，将复杂的超标量处理器乱序执行概念可视化，极大地降低了学生理解这些抽象概念的门槛。其基于Tomasulo算法的实现和可配置的参数使其成为一个非常灵活和实用的教育工具。作为开源项目，它也鼓励了更深层次的学习和实验。"}}
{"id": "2506.06298", "title": "Pairwise Calibrated Rewards for Pluralistic Alignment", "authors": ["Daniel Halpern", "Evi Micha", "Ariel D. Procaccia", "Itai Shapira"], "summary": "Current alignment pipelines presume a single, universal notion of desirable\nbehavior. However, human preferences often diverge across users, contexts, and\ncultures. As a result, disagreement collapses into the majority signal and\nminority perspectives are discounted. To address this, we propose reflecting\ndiverse human preferences through a distribution over multiple reward\nfunctions, each inducing a distinct aligned policy. The distribution is learned\ndirectly from pairwise preference without annotator identifiers or predefined\ngroups. Instead, annotator disagreements are treated as informative soft\nlabels. Our central criterion is pairwise calibration: for every pair of\ncandidate responses, the proportion of reward functions preferring one response\nmatches the fraction of annotators with that preference. We prove that even a\nsmall outlier-free ensemble can accurately represent diverse preference\ndistributions. Empirically, we introduce and validate a practical training\nheuristic to learn such ensembles, and demonstrate its effectiveness through\nimproved calibration, implying a more faithful representation of pluralistic\nvalues.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06298v1", "AI": {"title_translation": "用于多元对齐的成对校准奖励", "tldr": "当前对齐方法忽略人类偏好多样性，本文提出通过学习奖励函数分布来反映多元偏好，并引入成对校准准则以更忠实地表示多元价值观。", "motivation": "当前的对齐流程假设单一的理想行为概念，但人类偏好存在多样性，导致少数观点被忽视。", "method": "本文提出通过学习多个奖励函数上的分布来反映多样化的人类偏好，每个奖励函数对应一个对齐策略。该分布直接从成对偏好中学习，不依赖标注者身份或预定义群体，将标注者分歧视为信息性软标签。核心准则是成对校准：对于每对候选响应，偏好其中一个响应的奖励函数比例与持有该偏好的标注者比例相匹配。", "result": "理论上证明了即使是小型无异常值集合也能准确表示多样化偏好分布。经验上，引入并验证了一种学习此类集合的实用训练启发式方法，并通过改进的校准效果证明了其有效性，这意味着更忠实地表示了多元价值观。", "conclusion": "本文提出了一种通过成对校准奖励来反映多样化人类偏好的方法，并通过实验证明其能够更忠实地表示多元价值观。", "translation": "当前的对齐流程假定单一、普遍的理想行为概念。然而，人类偏好常常因用户、情境和文化而异。结果是，分歧会坍缩为多数信号，少数观点被忽视。为解决此问题，我们提出通过多个奖励函数上的分布来反映多样化的人类偏好，每个奖励函数都会引出一个不同的对齐策略。该分布直接从成对偏好中学习，不依赖标注者身份或预定义群体。相反，标注者之间的分歧被视为信息性的软标签。我们的核心准则是成对校准：对于每对候选响应，偏好其中一个响应的奖励函数比例与持有该偏好的标注者比例相匹配。我们证明，即使是一个小的、无异常值的集合也能准确地表示多样化的偏好分布。在经验上，我们引入并验证了一种学习此类集合的实用训练启发式方法，并通过改进的校准效果证明了其有效性，这意味着更忠实地表示了多元价值观。", "summary": "本文针对当前AI对齐方法忽视人类偏好多样性的问题，提出了一种新颖的“成对校准奖励”框架。该方法通过学习多个奖励函数上的分布来反映多元偏好，并利用成对偏好数据和标注者分歧作为软标签。核心思想是确保奖励函数对响应的偏好比例与标注者的实际偏好比例相匹配（成对校准）。理论和实践证明，该方法能有效捕捉和表示多元价值观，从而实现更忠实的AI对齐。", "keywords": "成对校准, 多元对齐, 奖励函数, 人类偏好, 偏好分布", "comments": "该论文创新性地提出通过学习奖励函数分布来解决AI对齐中人类偏好多样性问题，并通过“成对校准”准则和将分歧视为软标签的方式，有效地捕捉和表示了多元价值观，对实现更具包容性的AI对齐具有重要意义。"}}
{"id": "2506.06576", "title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce", "authors": ["Yijia Shao", "Humishka Zope", "Yucheng Jiang", "Jiaxin Pei", "David Nguyen", "Erik Brynjolfsson", "Diyi Yang"], "summary": "The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the\nlabor market, raising concerns about job displacement, diminished human agency,\nand overreliance on automation. Yet, we lack a systematic understanding of the\nevolving landscape. In this paper, we address this gap by introducing a novel\nauditing framework to assess which occupational tasks workers want AI agents to\nautomate or augment, and how those desires align with the current technological\ncapabilities. Our framework features an audio-enhanced mini-interview to\ncapture nuanced worker desires and introduces the Human Agency Scale (HAS) as a\nshared language to quantify the preferred level of human involvement. Using\nthis framework, we construct the WORKBank database, building on the U.S.\nDepartment of Labor's O*NET database, to capture preferences from 1,500 domain\nworkers and capability assessments from AI experts across over 844 tasks\nspanning 104 occupations. Jointly considering the desire and technological\ncapability divides tasks in WORKBank into four zones: Automation \"Green Light\"\nZone, Automation \"Red Light\" Zone, R&D Opportunity Zone, Low Priority Zone.\nThis highlights critical mismatches and opportunities for AI agent development.\nMoving beyond a simple automate-or-not dichotomy, our results reveal diverse\nHAS profiles across occupations, reflecting heterogeneous expectations for\nhuman involvement. Moreover, our study offers early signals of how AI agent\nintegration may reshape the core human competencies, shifting from\ninformation-focused skills to interpersonal ones. These findings underscore the\nimportance of aligning AI agent development with human desires and preparing\nworkers for evolving workplace dynamics.", "comment": "Preprint", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06576v1", "AI": {"title_translation": "采用AI代理的未来工作：审计美国劳动力的自动化和增强潜力", "tldr": "AI代理正在重塑劳动力市场，本文提出了一个审计框架，以系统地评估工人对AI代理自动化或增强任务的偏好，并将其与技术能力对齐，揭示了AI代理开发的机遇和挑战。", "motivation": "快速兴起的复合AI系统（AI代理）正在重塑劳动力市场，引发了对工作替代、人类能动性减弱和过度依赖自动化的担忧。然而，目前缺乏对这一不断演变格局的系统理解。", "method": "本文引入了一个新颖的审计框架，旨在评估工人希望AI代理自动化或增强哪些职业任务，以及这些愿望如何与当前技术能力对齐。该框架包含音频增强的迷你访谈以捕捉细微的工人愿望，并引入了“人类能动性量表”（HAS）来量化人类参与的首选水平。利用此框架，研究构建了WORKBank数据库（基于美国劳工部的O*NET数据库），收集了来自1,500名领域工人（涵盖104个职业的844多项任务）的偏好和AI专家的能力评估。通过综合考虑愿望和技术能力，WORKBank中的任务被划分为自动化“绿灯”区、自动化“红灯”区、研发机会区和低优先级区四个区域。", "result": "研究揭示了WORKBank中任务的关键不匹配和AI代理开发的机遇。结果显示，不同职业的“人类能动性量表”（HAS）配置文件多样，反映了对人类参与的异质期望。此外，研究提供了AI代理集成可能如何重塑核心人类能力（从信息聚焦技能转向人际交往技能）的早期信号。", "conclusion": "研究强调了将AI代理开发与人类愿望对齐以及为不断演变的工作场所动态做好准备的重要性。", "translation": "快速兴起的复合AI系统（又称AI代理）正在重塑劳动力市场，引发了对工作替代、人类能动性减弱和过度依赖自动化的担忧。然而，我们缺乏对不断演变格局的系统理解。在本文中，我们通过引入一种新颖的审计框架来弥补这一空白，该框架旨在评估职业任务中工人希望AI代理自动化或增强哪些部分，以及这些愿望如何与当前技术能力对齐。我们的框架具有音频增强的迷你访谈功能，以捕捉细微的工人愿望，并引入了人类能动性量表（HAS）作为量化人类参与首选水平的共同语言。利用这个框架，我们构建了WORKBank数据库，该数据库基于美国劳工部的O*NET数据库，捕获了来自1,500名领域工人（涵盖104个职业的844多项任务）的偏好以及AI专家的能力评估。综合考虑愿望和技术能力，WORKBank中的任务被划分为四个区域：自动化“绿灯”区、自动化“红灯”区、研发机会区、低优先级区。这突出了AI代理开发中的关键不匹配和机遇。我们的结果超越了简单的自动化与否的二分法，揭示了不同职业中多样化的HAS配置文件，反映了对人类参与的异质期望。此外，我们的研究提供了关于AI代理集成可能如何重塑核心人类能力（从信息聚焦技能转向人际交往技能）的早期信号。这些发现强调了将AI代理开发与人类愿望对齐以及为不断演变的工作场所动态做好准备的重要性。", "summary": "本文针对AI代理对劳动力市场的影响，提出了一种新颖的审计框架来评估工人对AI代理自动化或增强任务的偏好与当前技术能力的匹配度。通过音频访谈和“人类能动性量表”（HAS），作者构建了WORKBank数据库，收集了1500名工人对844多项任务的偏好和AI专家的能力评估。研究将任务划分为四个区域，揭示了AI代理开发中的机遇和不匹配，并发现不同职业对人类参与的期望存在差异，预示着核心人类能力将从信息技能转向人际交往技能。研究强调了AI代理开发需与人类愿望对齐，并为职场变化做好准备。", "keywords": "AI代理, 劳动力市场, 自动化, 增强, 人类能动性, WORKBank数据库", "comments": "本文通过引入“人类能动性量表”（HAS）和WORKBank数据库，提供了一个系统性的方法来评估AI代理在工作场所的自动化和增强潜力，并考虑了人类的偏好与技术能力之间的对齐。这种以人为中心的研究方法对于指导未来AI代理的负责任开发具有重要意义，尤其是在避免工作替代和增强人类能动性方面。其划分的四个区域也为AI研发提供了清晰的方向。"}}
{"id": "2506.07355", "title": "SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments", "authors": ["Yuya Okada", "Takayuki Nishio"], "summary": "We propose SALT (Split-Adaptive Lightweight Tuning), a lightweight model\nadaptation framework for Split Computing under closed constraints, where the\nhead and tail networks are proprietary and inaccessible to users. In such\nclosed environments, conventional adaptation methods are infeasible since they\nrequire access to model parameters or architectures. SALT addresses this\nchallenge by introducing a compact, trainable adapter on the client side to\nrefine latent features from the head network, enabling user-specific adaptation\nwithout modifying the original models or increasing communication overhead. We\nevaluate SALT on user-specific classification tasks with CIFAR-10 and\nCIFAR-100, demonstrating improved accuracy with lower training latency compared\nto fine-tuning methods. Furthermore, SALT facilitates model adaptation for\nrobust inference over lossy networks, a common challenge in edge-cloud\nenvironments. With minimal deployment overhead, SALT offers a practical\nsolution for personalized inference in edge AI systems under strict system\nconstraints.", "comment": "6 pages, submitted to IEEE Globecom 2025 (under review)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07355v1", "AI": {"title_translation": "SALT：一种闭环分体式计算环境下的轻量级模型自适应方法", "tldr": "SALT提出了一种在闭环分体式计算环境中进行轻量级模型自适应的方法，通过客户端适配器实现个性化推理，无需访问原始模型。", "motivation": "在闭环分体式计算环境中，头部和尾部网络是专有的且用户无法访问，导致传统模型自适应方法因需要访问模型参数或架构而不可行。", "method": "SALT通过在客户端引入一个紧凑、可训练的适配器来细化来自头部网络的潜在特征，从而实现用户特定的自适应，而无需修改原始模型或增加通信开销。", "result": "在CIFAR-10和CIFAR-100上的用户特定分类任务中，SALT与微调方法相比，提高了准确性并降低了训练延迟。此外，SALT有助于在损耗网络上实现鲁棒推理的模型自适应。", "conclusion": "SALT以最小的部署开销，为严格系统约束下的边缘AI系统中的个性化推理提供了一种实用解决方案。", "translation": "我们提出了SALT（Split-Adaptive Lightweight Tuning），一种用于闭环约束下分体式计算的轻量级模型自适应框架，在这种环境下，头部和尾部网络是专有的且用户无法访问。在这样的闭环环境中，传统的自适应方法不可行，因为它们需要访问模型参数或架构。SALT通过在客户端引入一个紧凑、可训练的适配器来解决这一挑战，该适配器用于细化来自头部网络的潜在特征，从而实现用户特定的自适应，而无需修改原始模型或增加通信开销。我们在CIFAR-10和CIFAR-100上的用户特定分类任务中评估了SALT，结果表明与微调方法相比，它提高了准确性并降低了训练延迟。此外，SALT有助于在损耗网络上实现鲁棒推理的模型自适应，这是边缘-云环境中常见的挑战。以最小的部署开销，SALT为严格系统约束下的边缘AI系统中的个性化推理提供了一种实用解决方案。", "summary": "本文提出了SALT（Split-Adaptive Lightweight Tuning），一种针对闭环分体式计算环境设计的轻量级模型自适应框架。鉴于传统方法无法在专有网络环境下工作，SALT在客户端引入了一个紧凑、可训练的适配器，用于优化头部网络的潜在特征，从而实现无需修改原始模型或增加通信开销的用户特定自适应。实验证明，SALT在用户分类任务上提高了准确性并缩短了训练延迟，并能促进损耗网络上的鲁棒推理，为边缘AI系统中的个性化推理提供了实用方案。", "keywords": "分体式计算, 模型自适应, 轻量级, 边缘AI, 闭环环境", "comments": "SALT的创新之处在于其在“闭环分体式计算环境”这一特殊且受限的场景下实现了模型自适应。通过在客户端引入一个轻量级的适配器，它巧妙地规避了访问专有模型参数的难题，同时保持了低通信开销和部署成本，这对于边缘AI和隐私保护场景具有重要意义。"}}
{"id": "2506.07865", "title": "FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity", "authors": ["Jinxi Li", "Ziyang Song", "Siyuan Zhou", "Bo Yang"], "summary": "In this paper, we aim to model 3D scene geometry, appearance, and the\nunderlying physics purely from multi-view videos. By applying various governing\nPDEs as PINN losses or incorporating physics simulation into neural networks,\nexisting works often fail to learn complex physical motions at boundaries or\nrequire object priors such as masks or types. In this paper, we propose\nFreeGave to learn the physics of complex dynamic 3D scenes without needing any\nobject priors. The key to our approach is to introduce a physics code followed\nby a carefully designed divergence-free module for estimating a per-Gaussian\nvelocity field, without relying on the inefficient PINN losses. Extensive\nexperiments on three public datasets and a newly collected challenging\nreal-world dataset demonstrate the superior performance of our method for\nfuture frame extrapolation and motion segmentation. Most notably, our\ninvestigation into the learned physics codes reveals that they truly learn\nmeaningful 3D physical motion patterns in the absence of any human labels in\ntraining.", "comment": "CVPR 2025. Code and data are available at:\n  https://github.com/vLAR-group/FreeGave", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07865v1", "AI": {"title_translation": "FreeGave：通过高斯速度从动态视频中学习3D物理", "tldr": "FreeGave提出了一种无需物体先验知识，通过高斯速度场学习复杂动态3D场景物理的方法，并在未来帧外推和运动分割任务上表现优异，且其学习到的物理编码能捕捉有意义的3D物理运动模式。", "motivation": "现有方法通过PINN损失或将物理模拟融入神经网络，常无法学习边界处的复杂物理运动，或需要物体先验信息（如掩码或类型）。", "method": "论文提出了FreeGave，通过引入物理编码，并结合精心设计的无散度模块来估计每个高斯的速度场，从而学习复杂动态3D场景的物理，且不依赖低效的PINN损失。", "result": "在三个公共数据集和一个新收集的真实世界数据集上的大量实验表明，该方法在未来帧外推和运动分割方面表现出优越性能。学习到的物理编码在没有人工标签的情况下，能真正学习到有意义的3D物理运动模式。", "conclusion": "FreeGave成功地在没有物体先验知识的情况下，从多视图视频中学习了复杂动态3D场景的物理，并且其学习到的物理编码能够捕捉到有意义的3D物理运动模式，这表明其在未来帧预测和运动分割等任务上的有效性。", "translation": "在本文中，我们旨在纯粹从多视图视频中建模3D场景的几何、外观和底层物理。通过将各种控制偏微分方程作为PINN损失或将物理模拟整合到神经网络中，现有工作常常无法学习边界处的复杂物理运动，或者需要物体先验信息，如掩码或类型。在本文中，我们提出了FreeGave，用于学习复杂动态3D场景的物理，而无需任何物体先验。我们方法的关键是引入一个物理编码，然后是一个精心设计的无散度模块，用于估计每个高斯的速度场，而不依赖于低效的PINN损失。在三个公共数据集和一个新收集的具有挑战性的真实世界数据集上进行的大量实验表明，我们的方法在未来帧外推和运动分割方面表现出卓越的性能。最值得注意的是，我们对所学习到的物理编码的调查表明，它们在训练中没有任何人工标签的情况下，确实学习到了有意义的3D物理运动模式。", "summary": "本文提出了FreeGave，一种无需物体先验知识，仅从多视图视频中学习复杂动态3D场景物理的方法。该方法通过引入物理编码和一个无散度模块来估计高斯速度场，避免了低效的PINN损失。实验结果表明，FreeGave在未来帧外推和运动分割任务上表现优异，并且其学习到的物理编码能够捕捉到有意义的3D物理运动模式。", "keywords": "3D物理学习, 动态视频, 高斯速度, 无物体先验, 物理编码", "comments": "FreeGave的创新之处在于其无需物体先验知识即可学习3D场景物理的能力，以及通过物理编码和无散度模块来避免传统PINN损失的低效率。其在无监督学习物理运动模式方面的发现，对于未来3D场景理解和预测领域具有重要意义。"}}
{"id": "2506.06735", "title": "Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions", "authors": ["Mesut Ozdag"], "summary": "Smart contracts, integral to blockchain ecosystems, enable decentralized\napplications to execute predefined operations without intermediaries. Their\nability to enforce trustless interactions has made them a core component of\nplatforms such as Ethereum. Vulnerabilities such as numerical overflows,\nreentrancy attacks, and improper access permissions have led to the loss of\nmillions of dollars throughout the blockchain and smart contract sector.\nTraditional smart contract auditing techniques such as manual code reviews and\nformal verification face limitations in scalability, automation, and\nadaptability to evolving development patterns. As a result, AI-based solutions\nhave emerged as a promising alternative, offering the ability to learn complex\npatterns, detect subtle flaws, and provide scalable security assurances. This\npaper examines novel AI-driven techniques for vulnerability detection in smart\ncontracts, focusing on machine learning, deep learning, graph neural networks,\nand transformer-based models. This paper analyzes how each technique represents\ncode, processes semantic information, and responds to real world vulnerability\nclasses. We also compare their strengths and weaknesses in terms of accuracy,\ninterpretability, computational overhead, and real time applicability. Lastly,\nit highlights open challenges and future opportunities for advancing this\ndomain.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06735v1", "AI": {"title_translation": "智能合约中人工智能驱动的漏洞分析：趋势、挑战与未来方向", "tldr": "本文综述了智能合约中AI驱动的漏洞检测技术，探讨了机器学习、深度学习、图神经网络和Transformer模型，并分析了它们的优缺点、挑战和未来方向。", "motivation": "智能合约中的漏洞导致了数百万美元的损失。传统的审计技术在可扩展性、自动化和适应性方面存在局限性。AI解决方案作为一种有前景的替代方案出现，能够学习复杂模式、检测细微缺陷并提供可扩展的安全保障。", "method": "本文审查了智能合约中AI驱动的漏洞检测新技术，重点关注机器学习、深度学习、图神经网络和基于Transformer的模型。分析了每种技术如何表示代码、处理语义信息以及响应实际漏洞类别。还比较了它们在准确性、可解释性、计算开销和实时适用性方面的优缺点。", "result": "本文分析并比较了各种AI驱动的漏洞检测技术（如机器学习、深度学习、图神经网络、Transformer模型）在表示代码、处理语义信息、响应漏洞以及准确性、可解释性、计算开销和实时适用性方面的优缺点。", "conclusion": "论文强调了该领域存在的开放挑战和未来的发展机遇。", "translation": "智能合约作为区块链生态系统的组成部分，使去中心化应用程序无需中介即可执行预定义操作。它们强制执行无需信任交互的能力使其成为以太坊等平台的核心组件。数值溢出、重入攻击和不当访问权限等漏洞已导致整个区块链和智能合约领域数百万美元的损失。传统智能合约审计技术，如手动代码审查和形式化验证，在可扩展性、自动化和适应不断发展的开发模式方面面临局限性。因此，基于人工智能的解决方案已成为一种有前景的替代方案，能够学习复杂模式、检测细微缺陷并提供可扩展的安全保障。本文研究了智能合约中用于漏洞检测的新型人工智能驱动技术，重点关注机器学习、深度学习、图神经网络和基于Transformer的模型。本文分析了每种技术如何表示代码、处理语义信息以及响应实际漏洞类别。我们还比较了它们在准确性、可解释性、计算开销和实时适用性方面的优缺点。最后，它强调了推进该领域的开放挑战和未来机遇。", "summary": "本文针对智能合约中因漏洞造成的巨额损失和传统审计方法的局限性，综述了人工智能驱动的漏洞检测技术。重点探讨了机器学习、深度学习、图神经网络和基于Transformer的模型，分析了它们在代码表示、语义处理和漏洞响应方面的能力，并比较了它们在准确性、可解释性、计算开销和实时适用性上的优缺点。论文最后指出了该领域的开放挑战和未来发展方向。", "keywords": "智能合约, 漏洞分析, 人工智能, 机器学习, 深度学习", "comments": "这篇综述论文的重要性在于系统地梳理了智能合约AI驱动漏洞分析的最新进展，为研究人员和开发者提供了全面的视角。它不仅识别了当前的技术趋势，还明确指出了未来研究的关键挑战和机遇，对于推动智能合约安全领域的发展具有指导意义。"}}
{"id": "2506.06366", "title": "AI Agent Behavioral Science", "authors": ["Lin Chen", "Yunke Zhang", "Jie Feng", "Haoye Chai", "Honglin Zhang", "Bingbing Fan", "Yibo Ma", "Shiyuan Zhang", "Nian Li", "Tianhui Liu", "Nicholas Sukiennik", "Keyu Zhao", "Yu Li", "Ziyi Liu", "Fengli Xu", "Yong Li"], "summary": "Recent advances in large language models (LLMs) have enabled AI systems to\nbehave in increasingly human-like ways, exhibiting planning, adaptation, and\nsocial dynamics across increasingly diverse, interactive, and open-ended\nscenarios. These behaviors are not solely the product of the models' internal\narchitecture, but emerge from their integration into agentic systems that\noperate within situated contexts, where goals, feedback, and interactions shape\nbehavior over time. This shift calls for a new scientific lens: AI Agent\nBehavioral Science. Rather than focusing only on internal mechanisms, this\nparadigm emphasizes the systematic observation of behavior, design of\ninterventions to test hypotheses, and theory-guided interpretation of how AI\nagents act, adapt, and interact over time. We systematize a growing body of\nresearch across individual, multi-agent, and human-agent interaction settings,\nand further demonstrate how this perspective informs responsible AI by treating\nfairness, safety, interpretability, accountability, and privacy as behavioral\nproperties. By unifying recent findings and laying out future directions, we\nposition AI Agent Behavioral Science as a necessary complement to traditional\napproaches, providing essential tools for understanding, evaluating, and\ngoverning the real-world behavior of increasingly autonomous AI systems.", "comment": null, "cate": "q-bio.NC", "url": "http://arxiv.org/abs/2506.06366v1", "AI": {"title_translation": "AI智能体行为科学", "tldr": "大型语言模型（LLM）的最新进展使得AI系统能够表现出类人行为，因此需要一门新的行为科学来理解和管理AI智能体在现实世界中的行动。", "motivation": "大型语言模型（LLM）的最新进展使得AI系统能够以越来越像人类的方式行事，在日益多样化、交互式和开放式的场景中表现出规划、适应和社交动态。这些行为不仅是模型内部架构的产物，更是它们集成到智能体系统中并在特定情境下运作的结果，其中目标、反馈和交互会随着时间推移塑造行为。这种转变呼唤一种新的科学视角：AI智能体行为科学，以理解这些在情境中产生的行为。", "method": "AI智能体行为科学这种范式不只关注内部机制，而是强调系统地观察行为、设计干预措施以验证假设，以及对AI智能体如何随时间行动、适应和交互进行理论指导的解释。该研究系统化了跨个体、多智能体和人机交互设置的日益增长的研究。", "result": "这种新视角通过将公平性、安全性、可解释性、可问责性和隐私视为行为属性来指导负责任的AI。它统一了最新发现并提出了未来的研究方向。", "conclusion": "AI智能体行为科学是传统方法的必要补充，为理解、评估和管理日益自主的AI系统的真实世界行为提供了基本工具。", "translation": "大型语言模型（LLM）的最新进展使得AI系统能够以越来越像人类的方式行事，在日益多样化、交互式和开放式的场景中表现出规划、适应和社交动态。这些行为不仅是模型内部架构的产物，更是它们集成到智能体系统中并在特定情境下运作的结果，其中目标、反馈和交互会随着时间推移塑造行为。这种转变需要一种新的科学视角：AI智能体行为科学。这种范式不只关注内部机制，而是强调系统地观察行为、设计干预措施以验证假设，以及对AI智能体如何随时间行动、适应和交互进行理论指导的解释。我们系统化了跨个体、多智能体和人机交互设置的日益增长的研究，并进一步展示了这种视角如何通过将公平性、安全性、可解释性、可问责性和隐私视为行为属性来指导负责任的AI。通过统一最新发现并提出未来方向，我们将AI智能体行为科学定位为传统方法的必要补充，为理解、评估和管理日益自主的AI系统的真实世界行为提供了基本工具。", "summary": "大型语言模型使AI智能体能够展现类人行为。本论文提出“AI智能体行为科学”作为研究这些涌现行为的新范式。与传统关注内部机制的方法不同，该领域强调系统观察、干预设计以及对AI智能体在特定情境中行为的理论指导解释。它整合了现有研究，并通过将公平性、安全等属性视为行为特性来指导负责任的AI，为理解和管理自主AI提供了工具。", "keywords": "AI智能体, 行为科学, 大型语言模型, 负责任AI, 类人行为", "comments": "本论文提出了一个及时且至关重要的跨学科新领域。通过将研究焦点从AI的内部机制转向情境中的可观察行为，它为理解和管理日益自主的AI系统，尤其是在负责任AI原则方面，提供了一个实用的框架。"}}
{"id": "2506.06567", "title": "NeSyPack: A Neuro-Symbolic Framework for Bimanual Logistics Packing", "authors": ["Bowei Li", "Peiqi Yu", "Zhenran Tang", "Han Zhou", "Yifan Sun", "Ruixuan Liu", "Changliu Liu"], "summary": "This paper presents NeSyPack, a neuro-symbolic framework for bimanual\nlogistics packing. NeSyPack combines data-driven models and symbolic reasoning\nto build an explainable hierarchical system that is generalizable,\ndata-efficient, and reliable. It decomposes a task into subtasks via\nhierarchical reasoning, and further into atomic skills managed by a symbolic\nskill graph. The graph selects skill parameters, robot configurations, and\ntask-specific control strategies for execution. This modular design enables\nrobustness, adaptability, and efficient reuse - outperforming end-to-end models\nthat require large-scale retraining. Using NeSyPack, our team won the First\nPrize in the What Bimanuals Can Do (WBCD) competition at the 2025 IEEE\nInternational Conference on Robotics and Automation.", "comment": "10 pages, 5 figures. Accepted to the RSS 2025 Workshop on\n  Benchmarking Robot Manipulation: Improving Interoperability and Modularity.\n  First Prize in the WBCD competition at ICRA 2025. Equal contribution by Bowei\n  Li and Peiqi Yu", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06567v1", "AI": {"title_translation": "NeSyPack：一种用于双手物流包装的神经符号框架", "tldr": "NeSyPack是一个神经符号框架，通过结合数据驱动模型和符号推理，实现可解释、通用、数据高效且可靠的双手物流包装，并在WBCD竞赛中获得一等奖。", "motivation": "该论文旨在解决现有端到端模型需要大规模重新训练的问题，并构建一个通用、数据高效、可靠且可解释的双手物流包装系统。", "method": "NeSyPack结合了数据驱动模型和符号推理，构建了一个可解释的分层系统。它通过分层推理将任务分解为子任务，并进一步分解为由符号技能图管理的原子技能。该技能图选择技能参数、机器人配置和任务特定的控制策略进行执行。这种模块化设计实现了鲁棒性、适应性和高效重用。", "result": "使用NeSyPack，研究团队在2025年IEEE机器人与自动化国际会议上的“双手能做什么”（WBCD）竞赛中获得一等奖。NeSyPack在性能上优于需要大规模重新训练的端到端模型。", "conclusion": "NeSyPack框架通过结合神经符号方法，提供了一种通用、数据高效、可靠且可解释的双手物流包装解决方案，并在实际竞赛中证明了其有效性和优越性。", "translation": "本文介绍了NeSyPack，一种用于双手物流包装的神经符号框架。NeSyPack结合了数据驱动模型和符号推理，构建了一个可解释的分层系统，该系统具有通用性、数据效率和可靠性。它通过分层推理将任务分解为子任务，并进一步分解为由符号技能图管理的原子技能。该技能图选择技能参数、机器人配置和任务特定的控制策略进行执行。这种模块化设计实现了鲁棒性、适应性和高效重用——优于需要大规模重新训练的端到端模型。使用NeSyPack，我们的团队在2025年IEEE机器人与自动化国际会议上的“双手能做什么”（WBCD）竞赛中获得一等奖。", "summary": "NeSyPack是一个创新的神经符号框架，专为双手物流包装任务设计。它融合了数据驱动模型和符号推理，创建了一个可解释、通用、数据高效且可靠的分层系统。通过将复杂任务分解为由符号技能图管理的原子技能，NeSyPack实现了模块化、鲁棒性、适应性和高效的技能重用，显著优于传统的端到端模型。该框架的有效性已在2025年IEEE机器人与自动化国际会议的WBCD竞赛中得到验证，并荣获一等奖。", "keywords": "神经符号框架, 双手物流包装, 分层系统, 机器人, 技能图", "comments": "NeSyPack的创新之处在于其神经符号混合方法，它结合了数据驱动模型的学习能力和符号推理的可解释性及通用性。这种模块化设计解决了端到端模型在面对新任务时需要大量重新训练的问题，提高了系统的鲁棒性和数据效率。在实际竞赛中取得的成功进一步证明了其在复杂机器人操作任务中的实用性和优越性。"}}
{"id": "2506.07810", "title": "A weighted quantum ensemble of homogeneous quantum classifiers", "authors": ["Emiliano Tolotti", "Enrico Blanzieri", "Davide Pastorello"], "summary": "Ensemble methods in machine learning aim to improve prediction accuracy by\ncombining multiple models. This is achieved by ensuring diversity among\npredictors to capture different data aspects. Homogeneous ensembles use\nidentical models, achieving diversity through different data subsets, and\nweighted-average ensembles assign higher influence to more accurate models\nthrough a weight learning procedure. We propose a method to achieve a weighted\nhomogeneous quantum ensemble using quantum classifiers with indexing registers\nfor data encoding. This approach leverages instance-based quantum classifiers,\nenabling feature and training point subsampling through superposition and\ncontrolled unitaries, and allowing for a quantum-parallel execution of diverse\ninternal classifiers with different data compositions in superposition. The\nmethod integrates a learning process involving circuit execution and classical\nweight optimization, for a trained ensemble execution with weights encoded in\nthe circuit at test-time. Empirical evaluation demonstrate the effectiveness of\nthe proposed method, offering insights into its performance.", "comment": "21 pages, 4 figures", "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.07810v1", "AI": {"title_translation": "同质量子分类器的加权量子集成", "tldr": "本文提出了一种加权同质量子分类器集成方法，利用量子分类器和经典权重优化来提高预测精度。", "motivation": "机器学习中的集成方法旨在通过结合多个模型来提高预测精度。传统集成方法通过确保预测器之间的多样性来捕捉不同的数据方面，并且加权平均集成通过权重学习过程为更准确的模型分配更高的影响力。本文的动机是将这些优势引入量子领域，提出一种加权同质量子集成方法。", "method": "本文提出了一种加权同质量子集成方法，该方法使用带有索引寄存器进行数据编码的量子分类器。这种方法利用基于实例的量子分类器，通过叠加和受控酉变换实现特征和训练点的子采样，并允许以量子并行方式执行具有不同数据组成的内部分类器。该方法整合了涉及电路执行和经典权重优化的学习过程，以便在测试时执行编码了权重的训练好的集成。", "result": "经验评估证明了所提出方法的有效性，并提供了对其性能的深入见解。", "conclusion": "所提出的加权同质量子集成方法是有效的，能够提高预测精度。", "translation": "机器学习中的集成方法旨在通过结合多个模型来提高预测精度。这通过确保预测器之间的多样性来实现，以捕捉不同的数据方面。同质集成使用相同的模型，通过不同的数据子集实现多样性；加权平均集成通过权重学习过程为更准确的模型分配更高的影响力。我们提出了一种使用带有索引寄存器进行数据编码的量子分类器来实现加权同质量子集成的方法。这种方法利用基于实例的量子分类器，通过叠加和受控酉变换实现特征和训练点的子采样，并允许以量子并行方式执行具有不同数据组成的内部分类器。该方法整合了涉及电路执行和经典权重优化的学习过程，以便在测试时执行编码了权重的训练好的集成。经验评估证明了所提出方法的有效性，并提供了对其性能的深入见解。", "summary": "本文提出了一种加权同质量子分类器集成方法，旨在结合多个量子模型以提高预测准确性。该方法利用带有索引寄存器的量子分类器进行数据编码，并通过叠加和受控酉变换实现特征和训练点的子采样，从而在量子并行模式下执行多样化的内部分类器。它还集成了量子电路执行和经典的权重优化过程，以在测试时使用编码在电路中的权重进行集成。经验评估验证了该方法的有效性。", "keywords": "量子集成, 同质分类器, 加权平均, 量子机器学习, 预测精度", "comments": "本文在量子机器学习领域具有创新性，它将经典的集成学习思想（特别是加权同质集成）引入了量子计算框架。通过利用量子叠加和并行性，它有效地解决了在量子模型中实现多样性和优化权重的问题。这种结合量子计算能力与经典优化策略的方法，为未来更强大的量子机器学习算法奠定了基础。"}}
{"id": "2506.07486", "title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "authors": ["Yuxiang Zhang", "Pengyu Xue", "Zhen Yang", "Xiaoxue Ren", "Xiang Li", "Linhao Wu", "Jiancheng Zhao", "Xingda Yu"], "summary": "Automated test-generation research overwhelmingly assumes the correctness of\nfocal methods, yet practitioners routinely face non-regression scenarios where\nthe focal method may be defective. A baseline evaluation of EvoSuite and two\nleading Large Language Model (LLM)-based generators, namely ChatTester and\nChatUniTest, on defective focal methods reveals that despite achieving up to\n83% of branch coverage, none of the generated tests expose defects.\n  To resolve this problem, we first construct two new benchmarks, namely\nDefects4J-Desc and QuixBugs-Desc, for experiments. In particular, each focal\nmethod is equipped with an extra Natural Language Description (NLD) for code\nfunctionality understanding.\n  Subsequently, we propose DISTINCT, a Description-guided, branch-consistency\nanalysis framework that transforms LLMs into fault-aware test generators.\nDISTINCT carries three iterative components: (1) a Generator that derives\ninitial tests based on the NLDs and the focal method, (2) a Validator that\niteratively fixes uncompilable tests using compiler diagnostics, and (3) an\nAnalyzer that iteratively aligns test behavior with NLD semantics via\nbranch-level analysis.\n  Extensive experiments confirm the effectiveness of our approach. Compared to\nstate-of-the-art methods, DISTINCT achieves an average improvement of 14.64% in\nCompilation Success Rate (CSR) and 6.66% in Passing Rate (PR) across both\nbenchmarks. It notably enhances Defect Detection Rate (DDR) on both benchmarks,\nwith a particularly significant gain of 149.26% observed on Defects4J-Desc. In\nterms of code coverage, DISTINCT improves Statement Coverage (SC) by an average\nof 3.77% and Branch Coverage (BC) by 5.36%. These results set a new baseline\nfor non-regressive test generation and highlight how description-driven\nreasoning enables LLMs to move beyond coverage chasing toward effective defect\ndetection.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07486v1", "AI": {"title_translation": "一种基于描述驱动的分支一致性分析生成非回归测试用例的框架", "tldr": "现有的自动化测试生成在有缺陷的方法上表现不佳。本文提出了DISTINCT框架，它利用自然语言描述和分支一致性分析，将大型语言模型（LLM）转化为故障感知测试生成器，显著提高了缺陷检测率。", "motivation": "自动化测试生成研究普遍假设核心方法是正确的，但实际中测试人员经常面临核心方法可能存在缺陷的非回归场景。基线评估显示，EvoSuite和两个领先的基于LLM的生成器（ChatTester和ChatUniTest）在有缺陷的核心方法上，尽管分支覆盖率高达83%，但都未能暴露缺陷。", "method": "本文提出了DISTINCT，一个由描述引导的分支一致性分析框架，它将LLM转化为故障感知测试生成器。为此，作者首先构建了两个新的基准测试集：Defects4J-Desc和QuixBugs-Desc，其中每个核心方法都附带额外的自然语言描述（NLD）以帮助理解代码功能。DISTINCT包含三个迭代组件：(1) 生成器：根据NLD和核心方法推导初始测试；(2) 验证器：使用编译器诊断迭代修复不可编译的测试；(3) 分析器：通过分支级分析迭代地将测试行为与NLD语义对齐。", "result": "与现有技术相比，DISTINCT在两个基准测试集上，编译成功率（CSR）平均提高了14.64%，通过率（PR）平均提高了6.66%。它显著提高了两个基准测试集上的缺陷检测率（DDR），尤其在Defects4J-Desc上观测到149.26%的显著提升。在代码覆盖率方面，DISTINCT使语句覆盖率（SC）平均提高了3.77%，分支覆盖率（BC）提高了5.36%。", "conclusion": "这些结果为非回归测试生成设定了新的基线，并强调了描述驱动的推理如何使LLM超越单纯的覆盖率追求，转向有效的缺陷检测。", "translation": "自动化测试生成研究绝大多数都假设核心方法是正确的，然而实际操作者经常面临核心方法可能有缺陷的非回归场景。对EvoSuite和两个领先的基于大型语言模型（LLM）的生成器（即ChatTester和ChatUniTest）在有缺陷的核心方法上的基线评估显示，尽管分支覆盖率高达83%，但生成的测试均未能暴露缺陷。\n为了解决这个问题，我们首先构建了两个新的实验基准测试集，即Defects4J-Desc和QuixBugs-Desc。特别是，每个核心方法都配备了额外的自然语言描述（NLD），以便理解代码功能。\n随后，我们提出了DISTINCT，一个由描述引导的分支一致性分析框架，它将LLM转化为故障感知测试生成器。DISTINCT包含三个迭代组件：(1) 一个生成器，根据NLD和核心方法推导初始测试；(2) 一个验证器，使用编译器诊断迭代修复不可编译的测试；(3) 一个分析器，通过分支级分析迭代地将测试行为与NLD语义对齐。\n广泛的实验证实了我们方法的有效性。与现有最先进的方法相比，DISTINCT在两个基准测试集上，编译成功率（CSR）平均提高了14.64%，通过率（PR）平均提高了6.66%。它显著提高了两个基准测试集上的缺陷检测率（DDR），尤其在Defects4J-Desc上观测到149.26%的显著提升。在代码覆盖率方面，DISTINCT使语句覆盖率（SC）平均提高了3.77%，分支覆盖率（BC）提高了5.36%。这些结果为非回归测试生成设定了新的基线，并强调了描述驱动的推理如何使LLM超越单纯的覆盖率追求，转向有效的缺陷检测。", "summary": "本文旨在解决当前自动化测试生成在缺陷方法上表现不佳的问题，特别是LLM生成的测试尽管覆盖率高但未能有效检测缺陷。为此，作者提出了DISTINCT框架，该框架利用自然语言描述和分支一致性分析，将LLM转化为故障感知测试生成器。DISTINCT通过生成、验证和分析三个迭代组件，显著提升了测试的编译成功率、通过率，并大幅提高了缺陷检测率，尤其在特定基准测试集上实现了近150%的提升。这项工作为非回归测试生成树立了新标杆，并展示了描述驱动推理在使LLM实现有效缺陷检测方面的潜力。", "keywords": "非回归测试, LLM, 测试生成, 分支一致性, 缺陷检测", "comments": "该论文的创新之处在于它改变了LLM在测试生成中的角色，使其从单纯追求代码覆盖率转变为能够有效检测缺陷的工具。通过引入自然语言描述和精细的分支一致性分析，DISTINCT框架为LLM提供了更深层次的语义理解能力，从而能够生成更具故障敏感性的测试用例。这对于处理实际软件开发中常见的非回归场景，即需要测试可能存在缺陷的方法，具有重要的实践意义和价值。"}}
{"id": "2506.06600", "title": "RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints", "authors": ["Tan-Hanh Pham", "Chris Ngo"], "summary": "The growing integration of vision-language models (VLMs) in medical\napplications offers promising support for diagnostic reasoning. However,\ncurrent medical VLMs often face limitations in generalization, transparency,\nand computational efficiency-barriers that hinder deployment in real-world,\nresource-constrained settings. To address these challenges, we propose a\nReasoning-Aware Reinforcement Learning framework, \\textbf{RARL}, that enhances\nthe reasoning capabilities of medical VLMs while remaining efficient and\nadaptable to low-resource environments. Our approach fine-tunes a lightweight\nbase model, Qwen2-VL-2B-Instruct, using Low-Rank Adaptation and custom reward\nfunctions that jointly consider diagnostic accuracy and reasoning quality.\nTraining is performed on a single NVIDIA A100-PCIE-40GB GPU, demonstrating the\nfeasibility of deploying such models in constrained environments. We evaluate\nthe model using an LLM-as-judge framework that scores both correctness and\nexplanation quality. Experimental results show that RARL significantly improves\nVLM performance in medical image analysis and clinical reasoning, outperforming\nsupervised fine-tuning on reasoning-focused tasks by approximately 7.78%, while\nrequiring fewer computational resources. Additionally, we demonstrate the\ngeneralization capabilities of our approach on unseen datasets, achieving\naround 27% improved performance compared to supervised fine-tuning and about 4%\nover traditional RL fine-tuning. Our experiments also illustrate that diversity\nprompting during training and reasoning prompting during inference are crucial\nfor enhancing VLM performance. Our findings highlight the potential of\nreasoning-guided learning and reasoning prompting to steer medical VLMs toward\nmore transparent, accurate, and resource-efficient clinical decision-making.\nCode and data are publicly available.", "comment": "Under review", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06600v1", "AI": {"title_translation": "RARL：在数据和硬件限制下，通过强化学习和LoRA改进医疗VLM的推理和泛化能力", "tldr": "RARL框架利用强化学习和LoRA在资源受限环境下显著提升了医疗VLM的推理和泛化能力，解决了当前医疗VLM在泛化、透明度和计算效率方面的局限性。", "motivation": "当前医疗视觉-语言模型（VLMs）在泛化能力、透明度和计算效率方面面临局限性，这阻碍了它们在资源受限的真实世界医疗应用中的部署。", "method": "本文提出了RARL（Reasoning-Aware Reinforcement Learning）框架，通过结合诊断准确性和推理质量的自定义奖励函数，使用Low-Rank Adaptation（LoRA）对轻量级基础模型Qwen2-VL-2B-Instruct进行微调。训练在一个NVIDIA A100 GPU上进行，并采用LLM-as-judge框架评估模型的正确性和解释质量。", "result": "RARL显著提升了医疗图像分析和临床推理中的VLM性能，在推理型任务上比监督微调高出约7.78%，同时需要更少的计算资源。在未见数据集上的泛化能力也得到了提升，比监督微调高出约27%，比传统强化学习微调高出约4%。研究还表明，训练中的多样性提示和推理中的推理提示对VLM性能的提升至关重要。", "conclusion": "理由引导学习和理由提示有潜力引导医疗VLM实现更透明、准确和资源高效的临床决策。", "translation": "视觉-语言模型（VLMs）在医疗应用中日益增长的整合为诊断推理提供了有力的支持。然而，当前的医疗VLM在泛化能力、透明度和计算效率方面常常面临局限性，这些障碍阻碍了其在真实世界、资源受限环境中的部署。为了解决这些挑战，我们提出了一种推理感知强化学习框架——\\textbf{RARL}，它在保持高效和适应低资源环境的同时，增强了医疗VLM的推理能力。我们的方法使用低秩适应（Low-Rank Adaptation）和联合考虑诊断准确性和推理质量的自定义奖励函数，对轻量级基础模型Qwen2-VL-2B-Instruct进行微调。训练在单个NVIDIA A100-PCIE-40GB GPU上进行，这证明了在受限环境中部署此类模型的可行性。我们使用LLM-as-judge框架评估模型，该框架同时对正确性和解释质量进行评分。实验结果表明，RARL显著提升了医疗图像分析和临床推理中的VLM性能，在推理型任务上比监督微调高出约7.78%，同时需要更少的计算资源。此外，我们证明了我们方法在未见数据集上的泛化能力，与监督微调相比，性能提升了约27%，比传统RL微调提升了约4%。我们的实验还表明，训练中的多样性提示和推理中的推理提示对于增强VLM性能至关重要。我们的发现突出了理由引导学习和理由提示在引导医疗VLM走向更透明、准确和资源高效的临床决策方面的潜力。代码和数据已公开可用。", "summary": "RARL是一个新颖的推理感知强化学习框架，旨在解决医疗VLM在泛化、透明度和计算效率方面的挑战，尤其是在资源受限的环境下。该框架通过LoRA和自定义奖励函数对轻量级模型进行微调，显著提升了医疗图像分析和临床推理的性能。实验结果表明，RARL在推理任务和未见数据集上的表现均优于监督微调和传统RL微调，并且计算效率更高，强调了理由引导学习和提示工程在提升医疗VLM能力方面的重要性。", "keywords": "医疗VLM, 强化学习, LoRA, 推理, 泛化", "comments": "该论文的创新点在于结合强化学习和LoRA技术，以在资源受限的环境下提升医疗VLM的推理和泛化能力。其重要性体现在为医疗AI在实际临床部署中面临的计算和数据挑战提供了可行解决方案。通过在单个A100 GPU上完成训练，展示了其高效性和实际部署潜力，这对于医疗领域有限的硬件资源而言意义重大。此外，强调多样性提示和推理提示的作用，为未来的VLM优化提供了新的方向。"}}
{"id": "2506.06470", "title": "SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation", "authors": ["Yanwei Ren", "Haotian Zhang", "Fuxiang Wu", "Jiayan Qiu", "Jiaxing Huang", "Baosheng Yu", "Liu Liu"], "summary": "Enhancing large language models by simply scaling up datasets has begun to\nyield diminishing returns, shifting the spotlight to data quality. Monte Carlo\nTree Search (MCTS) has emerged as a powerful technique for generating\nhigh-quality chain-of-thought data, yet conventional approaches typically\nretain only the top-scoring trajectory from the search tree, discarding sibling\nnodes that often contain valuable partial insights, recurrent error patterns,\nand alternative reasoning strategies. This unconditional rejection of\nnon-optimal reasoning branches may waste vast amounts of informative data in\nthe whole search tree. We propose SIGMA (Sibling Guided Monte Carlo\nAugmentation), a novel framework that reintegrates these discarded sibling\nnodes to refine LLM reasoning. SIGMA forges semantic links among sibling nodes\nalong each search path and applies a two-stage refinement: a critique model\nidentifies overlooked strengths and weaknesses across the sibling set, and a\nrevision model conducts text-based backpropagation to refine the top-scoring\ntrajectory in light of this comparative feedback. By recovering and amplifying\nthe underutilized but valuable signals from non-optimal reasoning branches,\nSIGMA substantially improves reasoning trajectories. On the challenging MATH\nbenchmark, our SIGMA-tuned 7B model achieves 54.92% accuracy using only 30K\nsamples, outperforming state-of-the-art models trained on 590K samples. This\nresult highlights that our sibling-guided optimization not only significantly\nreduces data usage but also significantly boosts LLM reasoning.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06470v1", "AI": {"title_translation": "SIGMA：通过同级引导蒙特卡洛增强改进大型语言模型推理", "tldr": "SIGMA通过重新整合蒙特卡洛树搜索中被丢弃的同级节点，显著提升了LLM的推理能力，同时大幅减少了数据需求。", "motivation": "现有的大型语言模型通过简单扩充数据集提升效果已收效甚微，数据质量成为焦点。尽管MCTS能生成高质量思维链数据，但传统方法只保留最优路径，丢弃了包含有价值见解、错误模式和替代策略的同级节点，导致大量信息浪费。", "method": "提出SIGMA（Sibling Guided Monte Carlo Augmentation）框架，重新整合被丢弃的同级节点以改进LLM推理。SIGMA在每个搜索路径中的同级节点之间建立语义链接，并应用两阶段改进：一个批判模型识别同级节点集中的优缺点，一个修订模型根据比较反馈进行基于文本的反向传播，以改进最优路径。", "result": "在具有挑战性的MATH基准测试中，SIGMA微调的7B模型仅使用3万样本就达到了54.92%的准确率，优于使用59万样本训练的SOTA模型。", "conclusion": "SIGMA通过同级引导优化，不仅显著减少了数据使用，还显著提升了LLM的推理能力。", "translation": "简单地扩充数据集来增强大型语言模型的效果已开始出现边际效益递减，这使得人们的关注点转向数据质量。蒙特卡洛树搜索（MCTS）已成为一种生成高质量思维链数据的强大技术，然而，传统方法通常只保留搜索树中的最高得分轨迹，而丢弃了通常包含有价值的部分见解、反复出现的错误模式和替代推理策略的同级节点。这种无条件地拒绝非最优推理分支可能会浪费整个搜索树中大量的信息数据。我们提出了SIGMA（同级引导蒙特卡洛增强），这是一个新颖的框架，它重新整合了这些被丢弃的同级节点以改进LLM推理。SIGMA在每个搜索路径中的同级节点之间建立语义链接，并应用两阶段改进：一个批判模型识别同级节点集中的被忽视的优点和缺点，一个修订模型根据这种比较反馈进行基于文本的反向传播，以改进最高得分轨迹。通过恢复和放大来自非最优推理分支的未充分利用但有价值的信号，SIGMA显著改善了推理轨迹。在具有挑战性的MATH基准测试中，我们的SIGMA微调的7B模型仅使用3万样本就达到了54.92%的准确率，超越了在59万样本上训练的SOTA模型。这一结果突出表明，我们的同级引导优化不仅显著减少了数据使用，而且显著提升了LLM的推理能力。", "summary": "SIGMA是一种新颖的框架，旨在通过重新整合蒙特卡洛树搜索中被丢弃的同级节点来改进大型语言模型的推理能力。它通过在同级节点间建立语义链接，并利用批判模型和修订模型的两阶段反馈机制来优化最优推理路径。实验结果表明，SIGMA在MATH基准测试上以更少的数据量（3万样本）取得了超越SOTA模型（59万样本）的性能，证明了其在提升LLM推理能力和数据效率方面的有效性。", "keywords": "大型语言模型, 蒙特卡洛树搜索, 推理增强, 数据效率, SIGMA", "comments": "该论文的创新点在于认识到蒙特卡洛树搜索中被丢弃的非最优路径中蕴含的价值，并提出SIGMA框架系统地利用这些“同级”信息来反哺和优化最优路径。这种方法通过利用被忽视的数据信号，显著提升了LLM的推理能力，同时大幅减少了对大规模数据集的依赖，这对于LLM的训练效率和性能提升具有重要意义。"}}
{"id": "2506.07607", "title": "Criss-Cross Deletion Correcting Codes: Optimal Constructions with Efficient Decoders", "authors": ["Yubo Sun", "Gennian Ge"], "summary": "This paper addresses fundamental challenges in two-dimensional error\ncorrection by constructing optimal codes for \\emph{criss-cross deletions}. We\nconsider an $ n \\times n $ array over a $ q $-ary alphabet $\\Sigma_q := \\{0, 1,\n\\ldots, q-1\\}$ that is subject to a \\emph{$(t_r, t_c)$-criss-cross deletion},\nwhich involves the simultaneous removal of $ t_r $ rows and $ t_c $ columns. A\ncode $\\mathcal{C} \\subseteq \\Sigma_q^{n \\times n}$ is defined as a\n\\emph{$(t_r,t_c)$-criss-cross deletion correcting code} if it can successfully\ncorrect these deletions. We derive a sphere-packing type lower bound and a\nGilbert-Varshamov type upper bound on the redundancy of optimal codes. Our\nresults indicate that the optimal redundancy for a $(t_r, t_c)$-criss-cross\ndeletion correcting code lies between $(t_r + t_c)n\\log q + (t_r + t_c)\\log n +\nO_{q,t_r,t_c}(1)$ and $(t_r + t_c)n\\log q + 2(t_r + t_c)\\log n +\nO_{q,t_r,t_c}(1)$, where the logarithm is on base two, and $O_{q,t_r,t_c}(1)$\nis a constant that depends solely on $q$, $t_r$, and $t_c$. For the case of\n$(1,1)$-criss-cross deletions, we develop two families of constructions. One\nachieves a redundancy of $2n\\log q + 2\\log n$ for non-binary alphabets, while\nthe other requires $2n\\log q + 2\\log n + O_q(1)$ bits of redundancy for\narbitrary alphabets. Both constructions match our lower bound, differing only\nby a constant $O_q(1)$ that depends solely on $q$, thereby confirming their\noptimality. For the case of $(t_r, t_c)$-criss-cross deletions, we provide a\nstrategy to derive optimal codes when both unidirectional deletions occur\nconsecutively. We propose decoding algorithms with a time complexity of\n$O(n^2)$ for our codes, which are optimal for two-dimensional scenarios.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07607v1", "AI": {"title_translation": "交叉删除纠错码：高效解码器的最优构造", "tldr": "本文构建了用于交叉删除的最优纠错码，并提供了高效的解码算法。", "motivation": "本文旨在解决二维纠错中的基本挑战，通过构建针对“交叉删除”的最优代码。", "method": "研究考虑了同时删除 $t_r$ 行和 $t_c$ 列的 $n \times n$ 数组上的 $(t_r, t_c)$-交叉删除。推导了最优码冗余的球填充类型下界和Gilbert-Varshamov类型上界。对于 $(1,1)$-交叉删除，开发了两种构造族。对于 $(t_r, t_c)$-交叉删除，当单向删除连续发生时，提供了推导最优码的策略。", "result": "最优冗余度介于 $(t_r + t_c)n\text{log }q + (t_r + t_c)\text{log }n + O_{q,t_r,t_c}(1)$ 和 $(t_r + t_c)n\text{log }q + 2(t_r + t_c)\text{log }n + O_{q,t_r,t_c}(1)$ 之间。对于 $(1,1)$-交叉删除，构造的冗余度分别为 $2n\text{log }q + 2\text{log }n$ 和 $2n\text{log }q + 2\text{log }n + O_q(1)$，与下界匹配，证实了其最优性。提出了时间复杂度为 $O(n^2)$ 的解码算法。", "conclusion": "本文构建的交叉删除纠错码是最优的，并且提供了高效的解码算法，解决了二维纠错中的挑战。", "translation": "本文通过构建“交叉删除”的最优代码，解决了二维纠错中的基本挑战。我们考虑一个 $n \times n$ 的$q$进制字母表 $\\Sigma_q := \\{0, 1, \\ldots, q-1\\}$ 上的数组，该数组受到“$(t_r, t_c)$-交叉删除”的影响，其中涉及同时删除 $t_r$ 行和 $t_c$ 列。如果代码 $\\mathcal{C} \\subseteq \\Sigma_q^{n \\times n}$ 能够成功纠正这些删除，则将其定义为“$(t_r,t_c)$-交叉删除纠错码”。我们推导了最优码冗余的球填充类型下界和Gilbert-Varshamov类型上界。我们的结果表明，$(t_r, t_c)$-交叉删除纠错码的最优冗余度介于 $(t_r + t_c)n\\text{log }q + (t_r + t_c)\\text{log }n + O_{q,t_r,t_c}(1)$ 和 $(t_r + t_c)n\\text{log }q + 2(t_r + t_c)\\text{log }n + O_{q,t_r,t_c}(1)$ 之间，其中对数以二为底，$O_{q,t_r,t_c}(1)$ 是一个仅取决于 $q$、$t_r$ 和 $t_c$ 的常数。对于 $(1,1)$-交叉删除的情况，我们开发了两个构造族。一个针对非二进制字母表实现了 $2n\\text{log }q + 2\\text{log }n$ 的冗余度，而另一个对于任意字母表需要 $2n\\text{log }q + 2\\text{log }n + O_q(1)$ 比特的冗余度。这两个构造都与我们的下界匹配，仅相差一个仅取决于 $q$ 的常数 $O_q(1)$，从而证实了它们的最优性。对于 $(t_r, t_c)$-交叉删除的情况，当两种单向删除连续发生时，我们提供了一种推导最优码的策略。我们提出了时间复杂度为 $O(n^2)$ 的解码算法，这对于二维场景来说是最优的。", "summary": "本文研究了二维纠错中的交叉删除问题，即同时删除二维数组中的行和列。作者推导了 $(t_r, t_c)$-交叉删除纠错码的最优冗余度上下界。对于 $(1,1)$-交叉删除，提出了两种最优构造，其冗余度与理论下界仅相差一个常数。对于更一般的 $(t_r, t_c)$-交叉删除，也提供了构建最优码的策略。此外，论文还提出了时间复杂度为 $O(n^2)$ 的高效解码算法。", "keywords": "交叉删除, 纠错码, 最优构造, 解码器, 冗余度", "comments": "该论文在二维错误纠正领域取得了重要进展，特别是针对交叉删除这一特定错误模型。其创新性在于提出了最优的代码构造和高效的解码算法，填补了该领域的空白。理论下界和构造的匹配性证明了其工作的严谨性和贡献度。"}}
{"id": "2506.07945", "title": "ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols", "authors": ["Arnav Sheth", "Ivaxi Sheth", "Mario Fritz"], "summary": "Recent advances in Large Language Models (LLMs) have shown promising\ncapabilities in generating code for general-purpose programming languages. In\ncontrast, their applicability for hardware description languages, particularly\nfor generating synthesizable and functionally correct designs, remains\nsignificantly underexplored. HDLs such as SystemVerilog are logic-oriented and\ndemand strict adherence to timing semantics, concurrency, and synthesizability\nconstraints. Moreover, HDL-based design flows encompass a broad set of tasks\nbeyond structural code generation, including testbench development,\nassertion-based verification, timing closure, and protocol-level integration\nfor on-chip communication. The objective of our paper is to analyze the\ncapabilities of state-of-the-art LLMs in generating SystemVerilog\nimplementations of standard communication protocols, a core component of\nembedded and System-on-Chip (SoC) architectures. This paper introduces the\nfirst benchmark suite targeting four widely used protocols: SPI, I2C, UART, and\nAXI. We define code generation tasks that capture varying levels of design\nabstraction and prompt specificity. The generated designs are assessed for\nsyntactic correctness, synthesizability, and functional fidelity via waveform\nsimulation and test benches.", "comment": "Accepted at MLSysArch@ISCA 2025", "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07945v1", "AI": {"title_translation": "ProtocolLLM：用于通信协议SystemVerilog生成的RTL基准测试", "tldr": "本文引入了ProtocolLLM，一个针对SystemVerilog通信协议生成的RTL基准测试套件，旨在分析大型语言模型（LLM）在硬件描述语言（HDL）代码生成方面的能力。", "motivation": "大型语言模型（LLM）在通用编程语言代码生成方面显示出巨大潜力，但在硬件描述语言（HDL）特别是SystemVerilog的可综合和功能正确设计生成方面的应用尚未得到充分探索。HDL对时序语义、并发性和可综合性有严格要求，且HDL设计流程包含结构代码生成之外的多种复杂任务。", "method": "本文引入了ProtocolLLM，这是首个针对SPI、I2C、UART和AXI四种广泛使用的通信协议的RTL基准测试套件。研究定义了捕获不同设计抽象级别和提示特异性的代码生成任务，并通过波形仿真和测试平台评估生成设计的语法正确性、可综合性和功能保真度。", "result": "本文介绍了针对四种广泛使用的通信协议（SPI、I2C、UART、AXI）的RTL基准测试套件ProtocolLLM，并定义了评估LLM生成SystemVerilog实现能力的代码生成任务。具体评估结果（如LLM的性能表现）未在摘要中提及。", "conclusion": "本文通过引入ProtocolLLM基准测试套件，为分析和评估大型语言模型在SystemVerilog通信协议生成方面的能力提供了框架，旨在推动LLM在硬件描述语言设计领域的应用。", "translation": "大型语言模型（LLM）的最新进展在通用编程语言代码生成方面展现出良好前景。相比之下，它们在硬件描述语言（HDL）方面的适用性，尤其是在生成可综合且功能正确的RTL设计方面，仍未得到充分探索。SystemVerilog等HDL是面向逻辑的，要求严格遵守时序语义、并发性和可综合性约束。此外，基于HDL的设计流程涵盖了结构代码生成之外的广泛任务，包括测试平台开发、基于断言的验证、时序收敛以及片上通信的协议级集成。本文的目标是分析最先进的LLM在生成标准通信协议的SystemVerilog实现方面的能力，这些协议是嵌入式和片上系统（SoC）架构的核心组件。本文引入了第一个针对四种广泛使用的协议（SPI、I2C、UART和AXI）的基准测试套件。我们定义了捕获不同设计抽象级别和提示特异性的代码生成任务。通过波形仿真和测试平台，评估了生成设计的语法正确性、可综合性和功能保真度。", "summary": "本文旨在分析最先进的大型语言模型（LLM）在生成标准通信协议SystemVerilog实现方面的能力，这些协议是嵌入式和片上系统（SoC）架构的核心组件。为此，论文引入了ProtocolLLM，这是首个针对SPI、I2C、UART和AXI四种常用协议的RTL基准测试套件。研究定义了捕获不同设计抽象级别和提示特异性的代码生成任务，并通过波形仿真和测试平台评估了生成设计的语法正确性、可综合性和功能保真度。", "keywords": "LLM, SystemVerilog, HDL, 通信协议, RTL基准测试", "comments": "这项工作通过引入专门的RTL基准测试套件，填补了LLM在硬件描述语言（特别是SystemVerilog）代码生成领域研究的空白。它为评估和提升LLM在硬件设计自动化中的应用奠定了基础，对于实现更高效、更可靠的硬件设计流程具有重要意义。"}}
{"id": "2506.06300", "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization", "authors": ["Yuanye Zhou", "Zhaokun Wang", "Kai Zhou", "Hui Tang", "Xiaofan Li"], "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless\ntool for topology optimization, capable of simultaneously determining optimal\ntopologies and physical solutions. However, conventional PINNs rely on\ndensity-based topology descriptions, which necessitate manual interpolation and\nlimit their applicability to complex geometries. To address this, we propose\nLagrangian topology-conscious PINNs (LT-PINNs), a novel framework for\nboundary-focused engineering optimization. By parameterizing the control\nvariables of topology boundary curves as learnable parameters, LT-PINNs\neliminate the need for manual interpolation and enable precise boundary\ndetermination. We further introduce specialized boundary condition loss\nfunction and topology loss function to ensure sharp and accurate boundary\nrepresentations, even for intricate topologies. The accuracy and robustness of\nLT-PINNs are validated via two types of partial differential equations (PDEs),\nincluding elastic equation with Dirichlet boundary conditions and Laplace's\nequation with Neumann boundary conditions. Furthermore, we demonstrate\neffectiveness of LT-PINNs on more complex time-dependent and time-independent\nflow problems without relying on measurement data, and showcase their\nengineering application potential in flow velocity rearrangement, transforming\na uniform upstream velocity into a sine-shaped downstream profile. The results\ndemonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors\ncompared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2)\nLT-PINNs can handle arbitrary boundary conditions, making them suitable for a\nwide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries\nwithout manual interpolation, especially for complex topologies.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06300v1", "AI": {"title_translation": "LT-PINN：用于边界聚焦工程优化的拉格朗日拓扑感知物理信息神经网络", "tldr": "LT-PINN是一种新型物理信息神经网络，通过参数化拓扑边界曲线并引入专门的损失函数，解决了传统PINN在拓扑优化中需要手动插值和处理复杂几何体的局限性，实现了更精确的边界确定和显著的误差降低。", "motivation": "传统的物理信息神经网络（PINNs）在拓扑优化中依赖于基于密度的拓扑描述，这需要手动插值并限制了它们在复杂几何体上的适用性。", "method": "本文提出了拉格朗日拓扑感知物理信息神经网络（LT-PINNs）。该方法通过将拓扑边界曲线的控制变量参数化为可学习参数，从而消除了手动插值的需要，并实现了精确的边界确定。此外，引入了专门的边界条件损失函数和拓扑损失函数，以确保即使对于复杂的拓扑也能获得清晰准确的边界表示。", "result": "1. LT-PINNs与最先进的密度拓扑导向PINNs（DT-PINNs）相比，相对L2误差显著降低。\n2. LT-PINNs可以处理任意边界条件，适用于各种偏微分方程（PDEs）。\n3. LT-PINNs无需手动插值即可推断出清晰的拓扑边界，尤其适用于复杂拓扑。", "conclusion": "LT-PINN通过其创新的边界参数化和专门的损失函数，克服了传统PINN在拓扑优化中的局限性，在处理复杂几何和任意边界条件方面表现出更高的准确性、鲁棒性和工程应用潜力。", "translation": "物理信息神经网络（PINNs）已成为拓扑优化中强大的无网格工具，能够同时确定最佳拓扑和物理解。然而，传统的PINNs依赖于基于密度的拓扑描述，这需要手动插值并限制了它们在复杂几何体上的适用性。为了解决这个问题，我们提出了拉格朗日拓扑感知PINNs（LT-PINNs），这是一种用于边界聚焦工程优化的新型框架。通过将拓扑边界曲线的控制变量参数化为可学习参数，LT-PINNs消除了手动插值的需要，并实现了精确的边界确定。我们进一步引入了专门的边界条件损失函数和拓扑损失函数，以确保即使对于复杂的拓扑也能获得清晰准确的边界表示。LT-PINNs的准确性和鲁棒性通过两种类型的偏微分方程（PDEs）进行了验证，包括带有Dirichlet边界条件的弹性方程和带有Neumann边界条件的拉普拉斯方程。此外，我们证明了LT-PINNs在更复杂的瞬态和稳态流问题上的有效性，无需依赖测量数据，并展示了它们在流速重排中的工程应用潜力，将均匀的上游速度转换为正弦形下游剖面。结果表明：（1）与最先进的密度拓扑导向PINNs（DT-PINNs）相比，LT-PINNs在相对L2误差方面取得了显著降低；（2）LT-PINNs可以处理任意边界条件，使其适用于各种PDEs；（3）LT-PINNs无需手动插值即可推断出清晰的拓扑边界，尤其适用于复杂拓扑。", "summary": "本文提出了一种名为拉格朗日拓扑感知物理信息神经网络（LT-PINN）的新型框架，用于边界聚焦工程优化。LT-PINN通过将拓扑边界曲线的控制变量参数化为可学习参数，消除了传统PINN在拓扑优化中对手动插值的需求，并实现了精确的边界确定。该方法引入了专门的边界条件损失函数和拓扑损失函数，以确保即使对于复杂的拓扑也能获得清晰准确的边界表示。通过对弹性方程和拉普拉斯方程等不同偏微分方程的验证，以及在复杂流问题中的应用，结果表明LT-PINN相对于现有方法显著降低了L2误差，能够处理任意边界条件，并能清晰地推断出复杂拓扑的边界。", "keywords": "物理信息神经网络, 拓扑优化, 边界参数化, 拉格朗日方法, 工程优化", "comments": "LT-PINN的创新之处在于其拉格朗日拓扑感知方法，通过直接参数化边界曲线并引入专门的损失函数，显著提升了PINN在拓扑优化中的性能。它克服了传统PINN在处理复杂几何和需要手动插值方面的局限性，使其在工程优化领域具有重要的应用潜力。"}}
{"id": "2506.06591", "title": "Privacy Perspectives and Practices of Chinese Smart Home Product Teams", "authors": ["Shijing He", "Yaxiong Lei", "Xiao Zhan", "Chi Zhang", "Juan Ye", "Ruba Abu-Salma", "Jose Such"], "summary": "Previous research has explored the privacy needs and concerns of device\nowners, primary users, and different bystander groups with regard to smart home\ndevices like security cameras, smart speakers, and hubs, but little is known\nabout the privacy views and practices of smart home product teams, particularly\nthose in non-Western contexts. This paper presents findings from 27\nsemi-structured interviews with Chinese smart home product team members,\nincluding product/project managers, software/hardware engineers, user\nexperience (UX) designers, legal/privacy experts, and marketers/operation\nspecialists. We examine their privacy perspectives, practices, and risk\nmitigation strategies. Our results show that participants emphasized compliance\nwith Chinese data privacy laws, which typically prioritized national security\nover individual privacy rights. China-specific cultural, social, and legal\nfactors also influenced participants' ethical considerations and attitudes\ntoward balancing user privacy and security with convenience. Drawing on our\nfindings, we propose a set of recommendations for smart home product teams,\nalong with socio-technical and legal interventions to address smart home\nprivacy issues-especially those belonging to at-risk groups-in Chinese\nmulti-user smart homes.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06591v1", "AI": {"title_translation": "中国智能家居产品团队的隐私视角与实践", "tldr": "本文通过访谈探讨了中国智能家居产品团队的隐私视角和实践，揭示了他们强调遵守优先于个人隐私权利的国家安全的中国数据隐私法，以及文化、社会和法律因素对平衡隐私、安全和便利性的影响。文章为解决中国多用户智能家居中的隐私问题提出了建议。", "motivation": "以往的研究主要关注设备所有者、主要用户和旁观者群体在智能家居设备方面的隐私需求和担忧，但对于智能家居产品团队的隐私观点和实践知之甚少，尤其是在非西方背景下，本研究旨在填补这一空白。", "method": "本研究通过对27名中国智能家居产品团队成员（包括产品/项目经理、软件/硬件工程师、用户体验（UX）设计师、法律/隐私专家以及市场/运营专员）进行半结构化访谈， بررسی了他们的隐私视角、实践和风险缓解策略。", "result": "研究结果显示，参与者强调遵守中国的个人数据隐私法律，这些法律通常将国家安全置于个人隐私权之上。中国特有的文化、社会和法律因素也影响了参与者的道德考量以及在平衡用户隐私和安全与便利性方面的态度。", "conclusion": "根据研究发现，本文为智能家居产品团队提出了一系列建议，并提出了社会技术和法律干预措施，以解决中国多用户智能家居中的隐私问题，特别是那些属于弱势群体的隐私问题。", "translation": "之前的研究已经探讨了设备所有者、主要用户以及不同旁观者群体在智能家居设备（如安防摄像头、智能音箱和集线器）方面的隐私需求和担忧，但对于智能家居产品团队的隐私观点和实践知之甚少，特别是在非西方背景下。本文介绍了对27名中国智能家居产品团队成员（包括产品/项目经理、软件/硬件工程师、用户体验（UX）设计师、法律/隐私专家以及市场/运营专员）进行半结构化访谈的发现。我们 بررسی了他们的隐私视角、实践和风险缓解策略。我们的结果显示，参与者强调遵守中国数据隐私法律，这些法律通常将国家安全置于个人隐私权之上。中国特有的文化、社会和法律因素也影响了参与者的道德考量以及在平衡用户隐私和安全与便利性方面的态度。根据我们的发现，我们为智能家居产品团队提出了一系列建议，以及社会技术和法律干预措施，以解决中国多用户智能家居中的隐私问题——特别是那些属于弱势群体的隐私问题。", "summary": "本研究通过访谈调查了中国智能家居产品团队的隐私视角和实践。结果表明，这些团队优先遵守中国的个人数据隐私法律，这些法律通常将国家安全置于个人隐私之上。此外，中国的文化、社会和法律因素显著影响了他们对用户隐私、安全与便利性之间平衡的伦理考量。文章最后提出了解决中国智能家居隐私问题的建议和干预措施，尤其针对弱势用户群体。", "keywords": "智能家居, 隐私, 中国, 产品团队, 数据隐私法", "comments": "本文通过关注产品团队而非用户视角，在智能家居隐私研究领域填补了重要空白，尤其是在中国这种非西方背景下。其发现揭示了特定法律框架（国家安全优先）和文化因素所带来的独特挑战和考量，为行业和政策制定者提供了超越以用户为中心研究的宝贵见解。提出的建议对行业和政策制定者具有实用价值。"}}
{"id": "2506.07581", "title": "FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning", "authors": ["Tan Chen", "Jintao Yan", "Yuxuan Sun", "Sheng Zhou", "Zhisheng Niu"], "summary": "Federated learning (FL) is a promising paradigm for multiple devices to\ncooperatively train a model. When applied in wireless networks, two issues\nconsistently affect the performance of FL, i.e., data heterogeneity of devices\nand limited bandwidth. Many papers have investigated device scheduling\nstrategies considering the two issues. However, most of them recognize data\nheterogeneity as a property of individual devices. In this paper, we prove that\nthe convergence speed of FL is affected by the sum of device-level and\nsample-level collective gradient divergence (CGD). The device-level CGD refers\nto the gradient divergence of the scheduled device group, instead of the sum of\nthe individual device divergence. The sample-level CGD is statistically upper\nbounded by sampling variance, which is inversely proportional to the total\nnumber of samples scheduled for local update. To derive a tractable form of the\ndevice-level CGD, we further consider a classification problem and transform it\ninto the weighted earth moving distance (WEMD) between the group distribution\nand the global distribution. Then we propose FedCGD algorithm to minimize the\nsum of multi-level CGDs by balancing WEMD and sampling variance, within\npolynomial time. Simulation shows that the proposed strategy increases\nclassification accuracy on the CIFAR-10 dataset by up to 4.2\\% while scheduling\n41.8\\% fewer devices, and flexibly switches between reducing WEMD and reducing\nsampling variance.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07581v1", "AI": {"title_translation": "FedCGD：无线联邦学习中集体梯度散度优化调度", "tldr": "本文提出了FedCGD算法，通过最小化设备级和样本级集体梯度散度来优化无线联邦学习中的设备调度，从而在提高分类准确性的同时减少设备数量。", "motivation": "联邦学习在无线网络中应用时面临数据异构性和有限带宽两大问题，现有调度策略大多将数据异构性视为个体设备属性，未能有效解决这些问题。", "method": "本文证明了联邦学习的收敛速度受设备级和样本级集体梯度散度（CGD）之和影响。设备级CGD指调度设备组的梯度散度，而非个体设备散度之和。样本级CGD在统计学上受采样方差上限约束，与用于本地更新的总样本数成反比。为推导设备级CGD的可处理形式，本文进一步考虑分类问题并将其转化为组分布与全局分布之间的加权地球移动距离（WEMD）。在此基础上，提出了FedCGD算法，通过平衡WEMD和采样方差来最小化多级CGD之和，且在多项式时间内完成。", "result": "仿真结果表明，所提出的策略在CIFAR-10数据集上将分类准确率提高了4.2%，同时调度的设备减少了41.8%，并且可以在减少WEMD和减少采样方差之间灵活切换。", "conclusion": "FedCGD算法通过优化集体梯度散度，有效解决了无线联邦学习中的数据异构性和带宽限制问题，显著提高了性能并减少了资源消耗。", "translation": "联邦学习（FL）是一种很有前景的多设备协同训练模型范式。当应用于无线网络时，两个问题持续影响FL的性能，即设备的数据异构性和有限带宽。许多论文已经研究了考虑这两个问题的设备调度策略。然而，它们中的大多数将数据异构性视为个体设备的属性。在本文中，我们证明了FL的收敛速度受设备级和样本级集体梯度散度（CGD）之和的影响。设备级CGD指的是调度设备组的梯度散度，而不是个体设备散度之和。样本级CGD在统计学上受采样方差的上限约束，采样方差与用于本地更新的总样本数成反比。为了推导设备级CGD的可处理形式，我们进一步考虑了一个分类问题，并将其转化为组分布与全局分布之间的加权地球移动距离（WEMD）。然后，我们提出了FedCGD算法，通过平衡WEMD和采样方差，在多项式时间内最小化多级CGD之和。仿真结果表明，所提出的策略在CIFAR-10数据集上将分类准确率提高了4.2%，同时调度的设备减少了41.8%，并且可以在减少WEMD和减少采样方差之间灵活切换。", "summary": "本文提出了一种名为FedCGD的无线联邦学习调度算法，旨在解决数据异构性和带宽限制问题。该算法核心在于证明联邦学习收敛速度受设备级和样本级集体梯度散度（CGD）之和影响。FedCGD将设备级CGD建模为加权地球移动距离（WEMD），并通过平衡WEMD与采样方差来最小化多级CGD。实验结果显示，FedCGD在提高分类准确率的同时显著减少了所需设备数量。", "keywords": "联邦学习, 集体梯度散度, 设备调度, 数据异构性, 无线网络", "comments": "本文的创新点在于引入了“集体梯度散度（CGD）”的概念，并将其分为设备级和样本级进行分析，这与以往关注个体设备异构性的方法不同。通过将设备级CGD转化为加权地球移动距离（WEMD），并提出FedCGD算法来平衡WEMD和采样方差，为无线联邦学习中的设备调度提供了新的优化视角。其在提高准确率和减少设备数量方面的表现，表明了该方法的有效性和实用性。"}}
{"id": "2506.07836", "title": "Are Trees Really Green? A Detection Approach of IoT Malware Attacks", "authors": ["Silvia Lucia Sanna", "Diego Soi", "Davide Maiorca", "Giorgio Giacinto"], "summary": "Nowadays, the Internet of Things (IoT) is widely employed, and its usage is\ngrowing exponentially because it facilitates remote monitoring, predictive\nmaintenance, and data-driven decision making, especially in the healthcare and\nindustrial sectors. However, IoT devices remain vulnerable due to their\nresource constraints and difficulty in applying security patches. Consequently,\nvarious cybersecurity attacks are reported daily, such as Denial of Service,\nparticularly in IoT-driven solutions. Most attack detection methodologies are\nbased on Machine Learning (ML) techniques, which can detect attack patterns.\nHowever, the focus is more on identification rather than considering the impact\nof ML algorithms on computational resources. This paper proposes a green\nmethodology to identify IoT malware networking attacks based on flow\nprivacy-preserving statistical features. In particular, the hyperparameters of\nthree tree-based models -- Decision Trees, Random Forest and Extra-Trees -- are\noptimized based on energy consumption and test-time performance in terms of\nMatthew's Correlation Coefficient. Our results show that models maintain high\nperformance and detection accuracy while consistently reducing power usage in\nterms of watt-hours (Wh). This suggests that on-premise ML-based Intrusion\nDetection Systems are suitable for IoT and other resource-constrained devices.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07836v1", "AI": {"title_translation": "树木真的环保吗？一种物联网恶意软件攻击检测方法", "tldr": "该研究提出了一种针对物联网恶意软件攻击的绿色检测方法，通过优化基于树的机器学习模型，在保持高检测性能的同时显著降低能耗，适用于资源受限的物联网设备。", "motivation": "物联网设备因资源受限和安全补丁应用困难而容易受到网络攻击。现有的机器学习检测方法侧重于识别，但忽略了算法对计算资源（尤其是能耗）的影响，这在物联网环境中是一个重要问题。", "method": "该论文提出了一种“绿色”方法，利用流隐私保护统计特征来识别物联网恶意软件网络攻击。具体而言，该方法基于能耗和测试时间性能（通过Matthew's Correlation Coefficient衡量），优化了三种基于树的模型（决策树、随机森林和Extra-Trees）的超参数。", "result": "研究结果表明，优化后的模型在保持高检测性能和准确性的同时，能持续降低功耗（以瓦时计）。", "conclusion": "基于本地机器学习的入侵检测系统适用于物联网及其他资源受限设备，证明了在保证性能的同时实现能耗优化的可行性。", "translation": "如今，物联网（IoT）被广泛应用，其使用量呈指数级增长，因为它促进了远程监控、预测性维护和数据驱动的决策，尤其是在医疗保健和工业领域。然而，物联网设备由于其资源限制和应用安全补丁的困难而仍然脆弱。因此，每天都有各种网络安全攻击被报告，例如拒绝服务攻击，特别是在物联网驱动的解决方案中。大多数攻击检测方法都基于机器学习（ML）技术，这些技术可以检测攻击模式。然而，重点更多地放在识别上，而不是考虑ML算法对计算资源的影响。本文提出了一种绿色方法来识别基于流隐私保护统计特征的物联网恶意软件网络攻击。特别是，三种基于树的模型——决策树、随机森林和Extra-Trees——的超参数是根据能耗和测试时间性能（以Matthew's Correlation Coefficient衡量）进行优化的。我们的结果表明，模型在保持高性能和检测准确性的同时，持续降低了瓦时（Wh）功耗。这表明基于本地ML的入侵检测系统适用于物联网和其他资源受限设备。", "summary": "本文提出了一种检测物联网恶意软件攻击的“绿色”方法，旨在解决现有机器学习检测方案中能耗被忽视的问题。该方法通过优化决策树、随机森林和Extra-Trees等基于树的模型的超参数，在确保高检测准确性的同时，显著降低了功耗。实验结果表明，这种方法在保持高性能的同时，能够有效减少物联网设备上的能源消耗，使其更适合资源受限的物联网环境。", "keywords": "物联网安全, 恶意软件检测, 机器学习, 能效, 基于树的模型", "comments": "该研究的创新之处在于其“绿色”检测理念，将机器学习模型的能耗优化纳入考量，这对于资源受限的物联网设备至关重要。它不仅关注了检测准确性，还解决了实际部署中的能耗挑战，为物联网安全领域提供了一个兼顾性能和效率的实用方案。"}}
{"id": "2506.06742", "title": "LADSG: Label-Anonymized Distillation and Similar Gradient Substitution for Label Privacy in Vertical Federated Learning", "authors": ["Zeyu Yan", "Yifei Yao", "Xuanbing Wen", "Juli Zhang", "Kai Fan"], "summary": "Vertical federated learning (VFL) has become a key paradigm for collaborative\nmachine learning, enabling multiple parties to train models over distributed\nfeature spaces while preserving data privacy. Despite security protocols that\ndefend against external attacks - such as gradient masking and encryption,\nwhich prevent unauthorized access to sensitive data - recent label inference\nattacks from within the system have emerged. These attacks exploit gradients\nand semantic embeddings to reconstruct private labels, bypassing traditional\ndefenses. For example, the passive label inference attack can reconstruct tens\nof thousands of participants' private data using just 40 auxiliary labels,\nposing a significant security threat. Existing defenses address single leakage\npathways, such as gradient leakage or label exposure. As attack strategies\nevolve, their limitations become clear, especially against hybrid attacks that\ncombine multiple vectors. To address this, we propose Label-Anonymized Defense\nwith Substitution Gradient (LADSG), a unified defense framework that integrates\ngradient substitution, label anonymization, and anomaly detection. LADSG\nmitigates both gradient and label leakage while maintaining the scalability and\nefficiency of VFL. Experiments on six real-world datasets show that LADSG\nreduces label inference attack success rates by 30-60%, with minimal\ncomputational overhead, underscoring the importance of lightweight defenses in\nsecuring VFL.", "comment": "20 pages, 6 figures. Under review", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06742v1", "AI": {"title_translation": "LADSG：垂直联邦学习中用于标签隐私的标签匿名化蒸馏和相似梯度替换", "tldr": "针对垂直联邦学习中的标签推断攻击，提出了LADSG框架，通过梯度替换、标签匿名化和异常检测，有效降低攻击成功率，且计算开销小。", "motivation": "垂直联邦学习面临内部标签推断攻击，这些攻击利用梯度和语义嵌入重建私有标签，绕过传统防御。现有防御措施针对单一泄漏路径，难以应对结合多种向量的混合攻击。", "method": "提出LADSG（Label-Anonymized Defense with Substitution Gradient），一个统一的防御框架，整合了梯度替换、标签匿名化和异常检测。", "result": "在六个真实世界数据集上的实验表明，LADSG将标签推断攻击成功率降低了30-60%，计算开销极小。", "conclusion": "LADSG提供了一种轻量级的有效防御，能够同时缓解垂直联邦学习中的梯度和标签泄漏，同时保持可扩展性和效率。", "translation": "垂直联邦学习（VFL）已成为协作机器学习的关键范式，它使多方能够在分布式特征空间上训练模型，同时保护数据隐私。尽管存在抵御外部攻击的安全协议——例如梯度掩码和加密，以防止未经授权访问敏感数据——但最近系统内部出现了标签推断攻击。这些攻击利用梯度和语义嵌入来重建私有标签，绕过了传统防御。例如，被动标签推断攻击仅使用40个辅助标签就可以重建数万名参与者的私人数据，构成了重大的安全威胁。现有防御措施解决了单一的泄漏路径，例如梯度泄漏或标签暴露。随着攻击策略的演变，它们的局限性变得清晰，特别是针对结合多种向量的混合攻击。为了解决这个问题，我们提出了LADSG（Label-Anonymized Defense with Substitution Gradient），一个统一的防御框架，它整合了梯度替换、标签匿名化和异常检测。LADSG在保持VFL的可扩展性和效率的同时，缓解了梯度和标签泄漏。在六个真实世界数据集上的实验表明，LADSG将标签推断攻击成功率降低了30-60%，计算开销极小，强调了轻量级防御在保护VFL中的重要性。", "summary": "本文提出了LADSG（Label-Anonymized Defense with Substitution Gradient），一个针对垂直联邦学习中标签隐私泄露的统一防御框架。面对利用梯度和语义嵌入进行标签重建的内部攻击，LADSG通过结合梯度替换、标签匿名化和异常检测，有效抵御了现有防御难以应对的混合攻击。实验证明，LADSG能在保持VFL效率的同时，显著降低标签推断攻击成功率（30-60%），且计算开销极低。", "keywords": "垂直联邦学习, 标签隐私, 梯度替换, 标签匿名化, 异常检测", "comments": "本文提出了一种创新且实用的方法来解决垂直联邦学习中日益增长的标签隐私泄露问题。LADSG的统一框架能够同时处理多种攻击向量，这对于应对不断演变的攻击策略至关重要。其在降低攻击成功率方面的显著效果和极低的计算开销，使其成为VFL安全领域一个有前景的轻量级解决方案。"}}
{"id": "2506.06570", "title": "Enhancing Robot Safety via MLLM-Based Semantic Interpretation of Failure Data", "authors": ["Aryaman Gupta", "Yusuf Umut Ciftci", "Somil Bansal"], "summary": "As robotic systems become increasingly integrated into real-world\nenvironments, ranging from autonomous vehicles to household assistants, they\ninevitably encounter diverse and unstructured scenarios that lead to failures.\nWhile such failures pose safety and reliability challenges, they also provide\nrich perceptual data for improving future performance. However, manually\nanalyzing large-scale failure datasets is impractical. In this work, we present\na method for automatically organizing large-scale robotic failure data into\nsemantically meaningful clusters, enabling scalable learning from failure\nwithout human supervision. Our approach leverages the reasoning capabilities of\nMultimodal Large Language Models (MLLMs), trained on internet-scale data, to\ninfer high-level failure causes from raw perceptual trajectories and discover\ninterpretable structure within uncurated failure logs. These semantic clusters\nreveal latent patterns and hypothesized causes of failure, enabling scalable\nlearning from experience. We demonstrate that the discovered failure modes can\nguide targeted data collection for policy refinement, accelerating iterative\nimprovement in agent policies and overall safety. Additionally, we show that\nthese semantic clusters can be employed for online failure detection, offering\na lightweight yet powerful safeguard for real-time adaptation. We demonstrate\nthat this framework enhances robot learning and robustness by transforming\nreal-world failures into actionable and interpretable signals for adaptation.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06570v1", "AI": {"title_translation": "机器人安全增强：基于多模态大语言模型的故障数据语义解释", "tldr": "利用多模态大语言模型自动分析机器人故障数据，生成语义化故障模式，以提高机器人安全和学习能力。", "motivation": "机器人系统在真实世界中会遇到导致故障的复杂场景，这些故障数据对改进性能很重要，但手动分析大规模故障数据不切实际，因此需要自动化方法来提高机器人安全性和可靠性。", "method": "提出一种利用多模态大语言模型（MLLMs）自动将大规模机器人故障数据组织成有语义意义的集群的方法。该方法利用MLLMs的推理能力，从原始感知轨迹中推断高级故障原因，并从未经整理的故障日志中发现可解释的结构。", "result": "发现的语义集群揭示了潜在的模式和假设的故障原因，实现了可扩展的从经验中学习。这些故障模式可以指导有针对性的数据收集以优化策略，加速智能体策略的迭代改进和整体安全性。此外，这些语义集群还可用于在线故障检测。", "conclusion": "该框架通过将真实世界故障转化为可操作和可解释的适应信号，从而增强了机器人的学习能力和鲁棒性。", "translation": "随着机器人系统日益融入现实世界环境，从自动驾驶汽车到家用助手，它们不可避免地会遇到导致故障的各种非结构化场景。虽然此类故障带来了安全性和可靠性挑战，但它们也为改善未来性能提供了丰富的感知数据。然而，手动分析大规模故障数据集是不切实际的。在这项工作中，我们提出了一种自动将大规模机器人故障数据组织成具有语义意义的集群的方法，从而实现在无人监督下从故障中进行可扩展学习。我们的方法利用了在互联网规模数据上训练的多模态大语言模型（MLLMs）的推理能力，从原始感知轨迹中推断出高级故障原因，并在未经整理的故障日志中发现可解释的结构。这些语义集群揭示了潜在的模式和假设的故障原因，从而实现了可扩展的从经验中学习。我们证明，所发现的故障模式可以指导有针对性的数据收集以优化策略，加速智能体策略的迭代改进和整体安全性。此外，我们还表明这些语义集群可用于在线故障检测，为实时适应提供了一种轻量级但功能强大的保障。我们证明，该框架通过将真实世界故障转化为可操作和可解释的适应信号，从而增强了机器人的学习能力和鲁棒性。", "summary": "本文提出了一种基于多模态大语言模型（MLLMs）的自动化方法，用于将大规模机器人故障数据组织成语义集群。该方法能够从原始感知数据中推断出高级故障原因和可解释的结构，从而实现从故障中进行可扩展学习。研究表明，这些语义集群能够指导策略优化、加速学习过程，并可用于在线故障检测，最终增强机器人的安全性和鲁棒性。", "keywords": "机器人安全, 多模态大语言模型, 故障分析, 语义解释, 在线故障检测", "comments": "这篇论文的创新点在于利用了多模态大语言模型（MLLMs）的强大推理能力来自动化处理和解释大规模机器人故障数据，从而克服了传统手动分析的局限性。这种方法将非结构化的故障数据转化为可操作的语义信息，对提高机器人安全性和学习效率具有重要意义。特别是其在指导数据收集和在线故障检测方面的应用，显示了其潜在的实际价值。"}}
{"id": "2506.07503", "title": "Large Language Models for Multilingual Vulnerability Detection: How Far Are We?", "authors": ["Honglin Shu", "Michael Fu", "Junji Yu", "Dong Wang", "Chakkrit Tantithamthavorn", "Junjie Chen", "Yasutaka Kamei"], "summary": "Various deep learning-based approaches utilizing pre-trained language models\n(PLMs) have been proposed for automated vulnerability detection. With recent\nadvancements in large language models (LLMs), several studies have begun\nexploring their application to vulnerability detection tasks. However, existing\nstudies primarily focus on specific programming languages (e.g., C/C++) and\nfunction-level detection, leaving the strengths and weaknesses of PLMs and LLMs\nin multilingual and multi-granularity scenarios largely unexplored. To bridge\nthis gap, we conduct a comprehensive fine-grained empirical study evaluating\nthe effectiveness of state-of-the-art PLMs and LLMs for multilingual\nvulnerability detection. Using over 30,000 real-world vulnerability-fixing\npatches across seven programming languages, we systematically assess model\nperformance at both the function-level and line-level. Our key findings\nindicate that GPT-4o, enhanced through instruction tuning and few-shot\nprompting, significantly outperforms all other evaluated models, including\nCodeT5P. Furthermore, the LLM-based approach demonstrates superior capability\nin detecting unique multilingual vulnerabilities, particularly excelling in\nidentifying the most dangerous and high-severity vulnerabilities. These results\nunderscore the promising potential of adopting LLMs for multilingual\nvulnerability detection at function-level and line-level, revealing their\ncomplementary strengths and substantial improvements over PLM approaches. This\nfirst empirical evaluation of PLMs and LLMs for multilingual vulnerability\ndetection highlights LLMs' value in addressing real-world software security\nchallenges.", "comment": "33 pages, 9 figures", "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07503v1", "AI": {"title_translation": "大型语言模型在多语言漏洞检测中的应用：我们进展如何？", "tldr": "本研究全面评估了PLM和LLM在多语言、多粒度漏洞检测中的有效性。结果显示，经过指令微调和少样本提示的GPT-4o显著优于其他模型，尤其在检测多语言和高危漏洞方面表现出色，揭示了LLM在该领域的巨大潜力。", "motivation": "现有研究主要关注特定编程语言（如C/C++）和函数级漏洞检测，PLM和LLM在多语言、多粒度场景下的优缺点尚未充分探索。本研究旨在弥补这一空白。", "method": "作者进行了一项全面的细粒度实证研究，评估了最先进的PLM和LLM在多语言漏洞检测中的有效性。使用了来自七种编程语言的30,000多个真实世界漏洞修复补丁，并系统地评估了模型在函数级和行级的性能。", "result": "GPT-4o（通过指令微调和少样本提示增强）显著优于所有其他评估模型，包括CodeT5P。基于LLM的方法在检测独特的多语言漏洞方面表现出卓越的能力，尤其擅长识别最危险和高严重性漏洞。", "conclusion": "LLM在多语言、函数级和行级漏洞检测方面具有巨大的应用潜力，它们与PLM方法相比展现出互补的优势和显著的改进。这是PLM和LLM在多语言漏洞检测领域的首次实证评估，突显了LLM在解决实际软件安全挑战中的价值。", "translation": "各种基于深度学习的方法，利用预训练语言模型（PLM），已被提出用于自动化漏洞检测。随着大型语言模型（LLM）的最新进展，一些研究已开始探索它们在漏洞检测任务中的应用。然而，现有研究主要集中于特定编程语言（例如C/C++）和函数级检测，PLM和LLM在多语言和多粒度场景下的优缺点在很大程度上尚未被探索。为了弥补这一空白，我们进行了一项全面的细粒度实证研究，评估了最先进的PLM和LLM在多语言漏洞检测中的有效性。我们使用来自七种编程语言的30,000多个真实世界漏洞修复补丁，系统地评估了模型在函数级和行级的性能。我们的主要发现表明，经过指令微调和少样本提示增强的GPT-4o显著优于所有其他评估模型，包括CodeT5P。此外，基于LLM的方法在检测独特的多语言漏洞方面表现出卓越的能力，尤其擅长识别最危险和高严重性漏洞。这些结果强调了采用LLM进行多语言、函数级和行级漏洞检测的巨大潜力，揭示了它们与PLM方法相比的互补优势和实质性改进。这项首次对PLM和LLM进行多语言漏洞检测的实证评估，突出了LLM在解决真实世界软件安全挑战中的价值。", "summary": "本研究旨在弥补多语言、多粒度漏洞检测领域中PLM和LLM评估的空白。作者进行了一项细致的实证研究，使用涵盖七种编程语言的30,000多个真实漏洞修复补丁，在函数级和行级评估了最先进的PLM和LLM。研究发现，经过指令微调和少样本提示的GPT-4o在所有评估模型中表现最佳，尤其在检测多语言和高危漏洞方面展现出卓越能力。结果表明，LLM在多语言漏洞检测方面具有巨大潜力，并相较于PLM有显著改进，为解决实际软件安全问题提供了新途径。", "keywords": "大型语言模型, 漏洞检测, 多语言, 软件安全, GPT-4o", "comments": "这项研究首次对PLM和LLM在多语言、多粒度漏洞检测中的表现进行了全面实证评估，填补了现有研究的空白。其创新之处在于使用了大量真实世界的跨语言补丁数据，并深入分析了模型在不同粒度（函数级和行级）下的性能。研究结果明确指出GPT-4o在这一领域的领先地位，并强调了LLM在识别高危漏洞方面的独特优势，为未来的软件安全研究和实践提供了重要指导。"}}
{"id": "2506.06602", "title": "Zero Shot Composed Image Retrieval", "authors": ["Santhosh Kakarla", "Gautama Shastry Bulusu Venkata"], "summary": "Composed image retrieval (CIR) allows a user to locate a target image by\napplying a fine-grained textual edit (e.g., ``turn the dress blue'' or ``remove\nstripes'') to a reference image. Zero-shot CIR, which embeds the image and the\ntext with separate pretrained vision-language encoders, reaches only 20-25\\%\nRecall@10 on the FashionIQ benchmark. We improve this by fine-tuning BLIP-2\nwith a lightweight Q-Former that fuses visual and textual features into a\nsingle embedding, raising Recall@10 to 45.6\\% (shirt), 40.1\\% (dress), and\n50.4\\% (top-tee) and increasing the average Recall@50 to 67.6\\%. We also\nexamine Retrieval-DPO, which fine-tunes CLIP's text encoder with a Direct\nPreference Optimization loss applied to FAISS-mined hard negatives. Despite\nextensive tuning of the scaling factor, index, and sampling strategy,\nRetrieval-DPO attains only 0.02\\% Recall@10 -- far below zero-shot and\nprompt-tuned baselines -- because it (i) lacks joint image-text fusion, (ii)\nuses a margin objective misaligned with top-$K$ metrics, (iii) relies on\nlow-quality negatives, and (iv) keeps the vision and Transformer layers frozen.\nOur results show that effective preference-based CIR requires genuine\nmultimodal fusion, ranking-aware objectives, and carefully curated negatives.", "comment": "8 pages, 3 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06602v1", "AI": {"title_translation": "零样本组合图像检索", "tldr": "零样本组合图像检索（CIR）性能不佳，本文通过微调BLIP-2并引入Q-Former大幅提升了Recall@10，同时发现Retrieval-DPO因缺乏多模态融合等原因效果很差。", "motivation": "零样本组合图像检索（CIR）在FashionIQ基准上的Recall@10表现仅为20-25%，性能非常低，需要改进。", "method": "本文通过使用轻量级Q-Former微调BLIP-2，将视觉和文本特征融合为单一嵌入来改进零样本CIR。此外，还研究了Retrieval-DPO，它使用直接偏好优化（DPO）损失对CLIP的文本编码器进行微调，并应用于FAISS挖掘的硬负样本。", "result": "通过微调BLIP-2和Q-Former，Recall@10提升至衬衫45.6%、连衣裙40.1%、上衣50.4%，平均Recall@50提升至67.6%。然而，Retrieval-DPO仅达到0.02%的Recall@10，远低于零样本和提示微调基线，原因包括缺乏联合图像-文本融合、目标函数与Top-K指标不匹配、依赖低质量负样本以及视觉和Transformer层冻结。", "conclusion": "有效的基于偏好的CIR需要真正的多模态融合、考虑排名的目标函数以及精心策划的负样本。", "translation": "组合图像检索（CIR）允许用户通过对参考图像应用细粒度文本编辑（例如，“把裙子改成蓝色”或“去除条纹”）来定位目标图像。零样本CIR，即使用独立的预训练视觉-语言编码器嵌入图像和文本，在FashionIQ基准上仅达到20-25%的Recall@10。我们通过使用轻量级Q-Former微调BLIP-2来改进这一点，该Q-Former将视觉和文本特征融合为单一嵌入，将Recall@10提高到衬衫45.6%、连衣裙40.1%和上衣50.4%，并将平均Recall@50提高到67.6%。我们还研究了Retrieval-DPO，它使用应用于FAISS挖掘的硬负样本的直接偏好优化（DPO）损失来微调CLIP的文本编码器。尽管对缩放因子、索引和采样策略进行了广泛调整，Retrieval-DPO仅达到0.02%的Recall@10——远低于零样本和提示微调基线——因为它（i）缺乏联合图像-文本融合，（ii）使用的边际目标与top-K指标不匹配，（iii）依赖低质量的负样本，以及（iv）保持视觉和Transformer层冻结。我们的结果表明，有效的基于偏好的CIR需要真正的多模态融合、考虑排名的目标函数和精心策划的负样本。", "summary": "零样本组合图像检索（CIR）性能不足。本文通过微调BLIP-2并引入轻量级Q-Former，将视觉和文本特征融合为单一嵌入，显著提升了CIR的检索性能。同时，研究发现Retrieval-DPO在CIR任务中表现不佳，并分析了其失败原因，强调了多模态融合、排名感知目标和高质量负样本对于有效CIR的重要性。", "keywords": "组合图像检索, 零样本, BLIP-2, Q-Former, 多模态融合", "comments": "本文通过对比两种不同的方法（基于BLIP-2微调和Retrieval-DPO）来改进零样本CIR，清晰地展示了多模态融合在图像-文本检索任务中的关键作用。对Retrieval-DPO失败原因的深入分析为未来研究提供了宝贵的经验，指明了有效基于偏好的检索方法的设计方向。"}}
{"id": "2506.06523", "title": "Reinforcement Learning for Autonomous Warehouse Orchestration in SAP Logistics Execution: Redefining Supply Chain Agility", "authors": ["Sumanth Pillella"], "summary": "In an era of escalating supply chain demands, SAP Logistics Execution (LE) is\npivotal for managing warehouse operations, transportation, and delivery. This\nresearch introduces a pioneering framework leveraging reinforcement learning\n(RL) to autonomously orchestrate warehouse tasks in SAP LE, enhancing\noperational agility and efficiency. By modeling warehouse processes as dynamic\nenvironments, the framework optimizes task allocation, inventory movement, and\norder picking in real-time. A synthetic dataset of 300,000 LE transactions\nsimulates real-world warehouse scenarios, including multilingual data and\noperational disruptions. The analysis achieves 95% task optimization accuracy,\nreducing processing times by 60% compared to traditional methods.\nVisualizations, including efficiency heatmaps and performance graphs, guide\nagile warehouse strategies. This approach tackles data privacy, scalability,\nand SAP integration, offering a transformative solution for modern supply\nchains.", "comment": "6 pages", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06523v1", "AI": {"title_translation": "强化学习在SAP物流执行中实现自主仓库编排：重新定义供应链敏捷性", "tldr": "本研究引入了一个开创性的强化学习框架，用于在SAP LE中自主编排仓库任务，显著提高了任务优化准确性并缩短了处理时间，从而增强了供应链的敏捷性和效率。", "motivation": "在供应链需求不断升级的时代，SAP物流执行（LE）对于管理仓库运营、运输和交付至关重要。为了应对这些挑战并增强运营敏捷性和效率，本研究旨在利用强化学习（RL）实现仓库任务的自主编排。", "method": "本研究引入了一个利用强化学习（RL）的开创性框架，以在SAP LE中自主编排仓库任务。该框架将仓库流程建模为动态环境，实时优化任务分配、库存移动和订单拣选。研究使用了包含多语言数据和操作中断的30万条LE事务的合成数据集来模拟真实世界的仓库场景。", "result": "该分析实现了95%的任务优化准确率，与传统方法相比，处理时间减少了60%。可视化（包括效率热图和性能图）指导敏捷仓库策略。", "conclusion": "该方法解决了数据隐私、可扩展性和SAP集成问题，为现代供应链提供了一个变革性的解决方案，重新定义了供应链敏捷性。", "translation": "在供应链需求不断升级的时代，SAP物流执行（LE）对于管理仓库运营、运输和交付至关重要。本研究引入了一个开创性的强化学习（RL）框架，用于在SAP LE中自主编排仓库任务，从而提高运营敏捷性和效率。通过将仓库流程建模为动态环境，该框架实时优化任务分配、库存移动和订单拣选。一个包含30万条LE事务的合成数据集模拟了真实世界的仓库场景，包括多语言数据和操作中断。分析实现了95%的任务优化准确率，与传统方法相比，处理时间减少了60%。可视化（包括效率热图和性能图）指导敏捷仓库策略。该方法解决了数据隐私、可扩展性和SAP集成问题，为现代供应链提供了一个变革性的解决方案。", "summary": "本研究提出了一种基于强化学习（RL）的创新框架，旨在SAP物流执行（LE）中实现仓库任务的自主编排。通过将仓库流程视为动态环境，该框架能实时优化任务分配、库存移动和订单拣选。利用包含30万条LE事务的合成数据集进行模拟，结果显示任务优化准确率达到95%，处理时间相较传统方法缩短了60%。该方案解决了数据隐私、可扩展性和SAP集成等关键挑战，为提升现代供应链的敏捷性和效率提供了变革性的途径。", "keywords": "强化学习, 仓库编排, SAP物流执行, 供应链敏捷性, 任务优化", "comments": "该论文的创新点在于将强化学习应用于SAP物流执行中的仓库任务自主编排，这在当前供应链需求不断增长的背景下具有重要意义。其通过模拟真实世界场景并展示出95%的任务优化准确率和60%的处理时间减少，证明了该方法的有效性和潜力。此外，论文还考虑了数据隐私、可扩展性和SAP集成等实际应用中的关键问题，使其解决方案更具实用性。这为提升供应链敏捷性提供了一个有前景的方向。"}}
{"id": "2506.07609", "title": "Correcting Errors Through Partitioning and Burst-Deletion Correction", "authors": ["Yubo Sun", "Gennian Ge"], "summary": "In this paper, we propose a partitioning technique that decomposes a pair of\nsequences with overlapping $t$-deletion $s$-substitution balls into sub-pairs,\nwhere the $^{\\leq}t$-burst-deletion balls of each sub-pair intersect. This\ndecomposition facilitates the development of $t$-deletion $s$-substitution\ncorrecting codes that leverage approaches from $^{\\leq}t$-burst-deletion\ncorrection. Building upon established approaches in the\n$^{\\leq}t$-burst-deletion correction domain, we construct $t$-deletion\n$s$-substitution correcting codes for $t\\in \\{1,2\\}$ over binary alphabets and\nfor $t=1$ in non-binary alphabets, with some constructions matching existing\nresults and others outperforming current methods. Our framework offers new\ninsights into the underlying principles of prior works, elucidates the\nlimitations of current approaches, and provides a unified perspective on error\ncorrection strategies.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07609v1", "AI": {"title_translation": "通过分区和突发删除纠正错误", "tldr": "本文提出了一种分区技术，用于分解具有重叠t-删除s-替换球的序列对，从而构建了新的t-删除s-替换纠错码，其性能在某些情况下优于现有方法。", "motivation": "论文旨在通过提出一种分区技术，利用现有的突发删除纠错方法来开发更有效的t-删除s-替换纠错码。", "method": "本文提出了一种分区技术，将具有重叠t-删除s-替换球的序列对分解为子对，其中每个子对的≤t-突发删除球相交。在此基础上，构建了适用于二元字母表（t=1,2）和非二元字母表（t=1）的t-删除s-替换纠错码。", "result": "所构建的纠错码在某些情况下与现有结果相匹配，在其他情况下则优于当前方法。该框架为现有工作提供了新见解，阐明了当前方法的局限性，并提供了错误纠正策略的统一视角。", "conclusion": "本文提出的分区框架不仅成功构建了性能优越的t-删除s-替换纠错码，而且为错误纠正策略提供了新的见解和统一的视角，揭示了现有方法的局限性。", "translation": "在本文中，我们提出了一种分区技术，该技术将一对具有重叠t-删除s-替换球的序列分解为子对，其中每个子对的≤t-突发删除球相交。这种分解有助于开发利用≤t-突发删除纠正方法的t-删除s-替换纠错码。在≤t-突发删除纠正领域已建立的方法基础上，我们为二元字母表中的t∈{1,2}和非二元字母表中的t=1构建了t-删除s-替换纠错码，其中一些构造与现有结果相匹配，另一些则优于当前方法。我们的框架为先前工作的基本原理提供了新见解，阐明了当前方法的局限性，并为错误纠正策略提供了统一的视角。", "summary": "本文提出了一种创新的分区技术，旨在解决t-删除s-替换错误纠正问题。通过将序列对分解为子对并利用≤t-突发删除纠正方法，研究人员构建了针对二元和非二元字母表的t-删除s-替换纠错码。这些新构造的码在某些情况下性能与现有方法相当，在另一些情况下则表现更优。该研究不仅提供了新的纠错方案，也为理解现有工作和错误纠正策略提供了统一的视角。", "keywords": "分区, 突发删除, 纠错码, 序列对, t-删除s-替换", "comments": "这项研究的创新之处在于提出了分区技术，将复杂的t-删除s-替换问题转化为可利用现有突发删除纠正方法的子问题。其重要性在于构建了性能优越的新型纠错码，并为整个错误纠正领域提供了更深层次的理解和统一的理论框架，有助于揭示当前方法的局限性。"}}
{"id": "2506.07957", "title": "Understanding the Error Sensitivity of Privacy-Aware Computing", "authors": ["Matías Mazzanti", "Esteban Mocskos", "Augusto Vega", "Pradip Bose"], "summary": "Homomorphic Encryption (HE) enables secure computation on encrypted data\nwithout decryption, allowing a great opportunity for privacy-preserving\ncomputation. In particular, domains such as healthcare, finance, and\ngovernment, where data privacy and security are of utmost importance, can\nbenefit from HE by enabling third-party computation and services on sensitive\ndata. In other words, HE constitutes the \"Holy Grail\" of cryptography: data\nremains encrypted all the time, being protected while in use.\n  HE's security guarantees rely on noise added to data to make relatively\nsimple problems computationally intractable. This error-centric intrinsic HE\nmechanism generates new challenges related to the fault tolerance and\nrobustness of HE itself: hardware- and software-induced errors during HE\noperation can easily evade traditional error detection and correction\nmechanisms, resulting in silent data corruption (SDC).\n  In this work, we motivate a thorough discussion regarding the sensitivity of\nHE applications to bit faults and provide a detailed error characterization\nstudy of CKKS (Cheon-Kim-Kim-Song). This is one of the most popular HE schemes\ndue to its fixed-point arithmetic support for AI and machine learning\napplications. We also delve into the impact of the residue number system (RNS)\nand the number theoretic transform (NTT), two widely adopted HE optimization\ntechniques, on CKKS' error sensitivity. To the best of our knowledge, this is\nthe first work that looks into the robustness and error sensitivity of\nhomomorphic encryption and, as such, it can pave the way for critical future\nwork in this area.", "comment": null, "cate": "cs.AR", "url": "http://arxiv.org/abs/2506.07957v1", "AI": {"title_translation": "理解隐私感知计算的错误敏感性", "tldr": "同态加密（HE）在隐私保护计算中很有潜力，但其固有的错误机制和操作中的软硬件错误可能导致静默数据损坏（SDC）。本研究首次深入探讨HE应用的位错误敏感性，并详细分析了流行的CKKS方案及其优化技术（RNS和NTT）对错误敏感性的影响，为该领域的未来研究奠定基础。", "motivation": "同态加密（HE）虽然为隐私保护计算提供了巨大机会，但其依赖于噪声的机制以及运行中可能出现的软硬件错误，易导致传统错误检测和纠正机制失效，从而引发静默数据损坏（SDC）。这突显了对HE应用错误敏感性进行深入研究的必要性。", "method": "本研究对Cheon-Kim-Kim-Song (CKKS) 同态加密方案进行了详细的错误特性分析，并深入探讨了残余数系统（RNS）和数论变换（NTT）这两种广泛采用的HE优化技术对CKKS错误敏感性的影响。", "result": "Not mentioned in abstract", "conclusion": "本研究首次探讨了同态加密的鲁棒性和错误敏感性，为该领域的未来关键工作铺平了道路。", "translation": "同态加密（HE）使得在不解密的情况下对加密数据进行安全计算成为可能，为隐私保护计算提供了巨大机会。特别是在医疗、金融和政府等数据隐私和安全至关重要的领域，HE通过在敏感数据上实现第三方计算和服务而受益。换句话说，HE构成了密码学的“圣杯”：数据始终保持加密状态，在使用过程中受到保护。\nHE的安全保障依赖于添加到数据中的噪声，以使相对简单的问题在计算上变得难以处理。这种以错误为中心的内在HE机制带来了与HE自身容错性和鲁棒性相关的新挑战：HE操作期间的硬件和软件引起的错误很容易规避传统的错误检测和纠正机制，导致静默数据损坏（SDC）。\n在这项工作中，我们促使对HE应用对位错误的敏感性进行彻底讨论，并对CKKS（Cheon-Kim-Kim-Song）进行了详细的错误特性研究。CKKS因其对AI和机器学习应用的定点算术支持而成为最流行的HE方案之一。我们还深入探讨了残余数系统（RNS）和数论变换（NTT）这两种广泛采用的HE优化技术对CKKS错误敏感性的影响。据我们所知，这是首次研究同态加密的鲁棒性和错误敏感性，因此，它可以为该领域的未来关键工作铺平道路。", "summary": "同态加密（HE）为隐私保护计算提供了“圣杯”级的解决方案，特别是在医疗、金融等敏感数据领域。然而，HE固有的噪声机制和运行过程中的软硬件错误可能导致静默数据损坏（SDC），且难以通过传统方法检测。本文旨在深入探讨HE应用对位错误的敏感性，并首次详细分析了流行的CKKS同态加密方案的错误特性。研究还考察了残余数系统（RNS）和数论变换（NTT）这两种HE优化技术对CKKS错误敏感性的影响，为未来HE鲁棒性研究奠定了基础。", "keywords": "同态加密, 错误敏感性, CKKS, 残余数系统, 数论变换", "comments": "本文首次深入研究了同态加密（HE）的错误敏感性，填补了该领域的一个重要空白。通过对流行的CKKS方案及其优化技术（RNS和NTT）的详细错误特性分析，为HE在实际应用中的鲁棒性问题提供了新的视角。这项工作对于推动HE的可靠部署和未来研究具有重要意义，尤其是在数据敏感性极高的领域。"}}
{"id": "2506.06303", "title": "Reward Is Enough: LLMs Are In-Context Reinforcement Learners", "authors": ["Kefan Song", "Amir Moeini", "Peng Wang", "Lei Gong", "Rohan Chandra", "Yanjun Qi", "Shangtong Zhang"], "summary": "Reinforcement learning (RL) is a human-designed framework for solving\nsequential decision making problems. In this work, we demonstrate that,\nsurprisingly, RL emerges in LLM's (Large Language Model) inference time -- a\nphenomenon known as in-context RL (ICRL). Specifically, we propose a novel\nmulti-round prompting framework called ICRL prompting. The goal is to prompt\nthe LLM to complete a task. After the LLM generates a response at the current\nround, we give numerical scalar feedbacks for the response, called the rewards.\nAt the next round, we prompt the LLM again with the same task and a context\nconsisting of all previous responses and rewards. We observe that the quality\nof the LLM's response increases as the context grows. In other words, the LLM\nis able to maximize the scalar reward signal in the inference time, just like\nan RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24,\ncreative writing, and ScienceWorld) and demonstrate significant performance\nimprovements over baseline methods such as Self-Refine and Reflexion.\nSurprisingly, in some experiments the reward signals are generated by the LLM\nitself, yet performance improvements are still observed from ICRL prompting,\noffering a promising paradigm for scaling test-time compute.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06303v1", "AI": {"title_translation": "奖励足够：大型语言模型是情境强化学习者", "tldr": "本文提出了一种名为情境强化学习（ICRL）的提示框架，发现大型语言模型（LLM）在推理时能够通过接收数值奖励信号来提高任务表现，表现出类似强化学习的行为。", "motivation": "强化学习（RL）是解决序列决策问题的框架。本文旨在证明RL现象可以在大型语言模型（LLM）的推理过程中涌现，即情境强化学习（ICRL）。", "method": "研究提出了一种新颖的多轮提示框架，称为ICRL提示。该方法在LLM生成响应后，提供数值标量反馈（奖励）。在下一轮中，LLM会再次收到相同的任务，并包含所有先前响应和奖励的上下文。通过这种方式，观察LLM响应质量随上下文增长而提高。", "result": "ICRL提示在三个基准测试（Game of 24、创意写作和ScienceWorld）中进行了评估，并显示出相对于Self-Refine和Reflexion等基线方法的显著性能改进。令人惊讶的是，即使奖励信号由LLM自身生成，ICRL提示也能观察到性能提升。", "conclusion": "大型语言模型在推理时能够最大化标量奖励信号，表现出情境强化学习的能力，这为扩展测试时间计算提供了一个有前景的范式。", "translation": "强化学习（RL）是一种人类设计的用于解决序列决策问题的框架。在这项工作中，我们令人惊讶地证明，RL在大型语言模型（LLM）的推理时间中涌现——这种现象被称为情境强化学习（ICRL）。具体来说，我们提出了一种新颖的多轮提示框架，称为ICRL提示。目标是提示LLM完成一项任务。在LLM在当前轮次生成响应后，我们为该响应提供数值标量反馈，称为奖励。在下一轮次中，我们再次提示LLM相同的任务，并提供包含所有先前响应和奖励的上下文。我们观察到LLM响应的质量随着上下文的增长而提高。换句话说，LLM能够在推理时最大化标量奖励信号，就像一个RL算法一样。我们在三个基准测试（Game of 24、创意写作和ScienceWorld）中评估了ICRL提示，并证明相对于Self-Refine和Reflexion等基线方法有显著的性能改进。令人惊讶的是，在一些实验中，奖励信号是由LLM自身生成的，但ICRL提示仍然观察到性能改进，这为扩展测试时间计算提供了一个有前景的范式。", "summary": "本文探讨了大型语言模型（LLM）在推理时涌现的“情境强化学习”（ICRL）现象。研究提出了一种多轮ICRL提示框架，通过在LLM生成响应后提供数值奖励，并将其作为后续轮次的上下文，观察到LLM的任务表现随上下文增长而提高。实验在Game of 24、创意写作和ScienceWorld等基准测试中，ICRL提示显著优于现有基线方法，甚至在LLM自生成奖励的情况下也能实现性能提升，这为LLM的推理能力和测试时间计算提供了新的视角。", "keywords": "情境强化学习, 大型语言模型, 奖励, 推理时间, 多轮提示", "comments": "这项研究的创新之处在于揭示了LLM在推理时表现出的类强化学习行为，并提出了一个实用的多轮提示框架ICRL。其重要性在于，它表明LLM不仅能处理静态信息，还能通过动态反馈进行自我优化，即使反馈是自生成的。这为未来LLM的自我改进和决策能力开辟了新的研究方向，尤其是在无需外部人工标注即可进行在线优化的场景中。"}}
{"id": "2506.06803", "title": "Spatial Disparities in Fire Shelter Accessibility: Capacity Challenges in the Palisades and Eaton Fires", "authors": ["Su Yeon Han", "Yubin Lee", "Jooyoung Yoo", "Jeon-Young Kang", "Jinwoo Park", "Soe W. Myint", "Eunsang Cho", "Xin Gu", "Joon-Seok Kim"], "summary": "The increasing frequency and severity of wildfire in California, exacerbated\nby prolonged drought and environmental changes, pose significant challenges to\nurban community resilience and equitable emergency response. The study\ninvestigates issues of accessibility to shelters during the Palisades and Eaton\nFires which started in January 2025 in Southern California that led to over\n180,000 displacements and the loss of 16,000 structures. Despite coordinated\nefforts of many organizations' emergency assistance, shelter shortages left\nmany evacuees without safety or accessible refuge. This research aims to\nmeasure shelter accessibility during the fires' peak, evaluate whether existing\nshelter capacity met the demand, and identify spatial disparities in access.\nResults reveal severe shelter shortages and pronounced inequities in access to\nshelters, particularly in geographically isolated regions and mountainous\nareas. Our simulations of shelter placement strategies using a capacity-based\nalgorithm and a proximity-based approach demonstrate potential improvements in\nboth shelter accessibility and equitable access to shelters. The findings\nunderscore the critical need for strategic shelter planning and infrastructure\ndevelopment to enhance disaster readiness and reduce vulnerability in regions\nthat frequently experience wildfires.", "comment": "35 pages, 11 figures", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06803v1", "AI": {"title_translation": "火灾避难所可达性中的空间差异：Palisades和Eaton火灾中的容量挑战", "tldr": "研究发现加州Palisades和Eaton火灾期间避难所严重短缺且存在空间不平等，尤其在偏远地区，并提出通过优化避难所布局策略可改善可达性。", "motivation": "随着加州野火频率和严重性增加，对城市社区韧性和公平应急响应构成挑战。Palisades和Eaton火灾期间，尽管有协调努力，避难所短缺导致大量疏散人员无处可去，促使本研究旨在衡量避难所可达性、评估现有容量是否满足需求并识别空间差异。", "method": "研究通过测量火灾高峰期的避难所可达性，评估现有避难所容量是否满足需求，并识别空间差异。此外，研究使用基于容量算法和基于邻近度方法模拟了避难所安置策略。", "result": "结果显示避难所严重短缺，特别是在地理隔离区域和山区，避难所的可达性存在明显不公平。模拟表明，新的避难所安置策略（基于容量算法和基于邻近度方法）可以潜在改善避难所可达性和公平性。", "conclusion": "研究强调，为提高灾害准备并减少常发野火地区的脆弱性，迫切需要进行战略性避难所规划和基础设施建设。", "translation": "随着加州野火频率和严重性的增加，在长期干旱和环境变化的加剧下，对城市社区韧性和公平应急响应构成了重大挑战。本研究调查了2025年1月在南加州爆发的Palisades和Eaton火灾期间避难所可达性问题，这两场火灾导致超过18万人流离失所，1.6万座建筑物被毁。尽管许多组织为紧急援助做出了协调努力，但避难所短缺使许多疏散人员缺乏安全或可及的避难所。本研究旨在衡量火灾高峰期间避难所的可达性，评估现有避难所容量是否满足需求，并识别可达性中的空间差异。结果显示避难所严重短缺，尤其是在地理隔离区域和山区，避难所的可达性存在明显不公平。我们使用基于容量算法和基于邻近度方法的避难所安置策略模拟表明，避难所可达性和公平性均有潜在改善。研究结果强调了战略性避难所规划和基础设施建设的迫切需求，以增强灾害准备并减少常发野火地区的脆弱性。", "summary": "本研究分析了加州Palisades和Eaton火灾期间避难所的可达性问题，发现避难所严重短缺且存在空间不平等，尤其是在偏远和山区。通过模拟基于容量和邻近度的避难所安置策略，研究证明了改善避难所可达性和公平性的潜力，并强调了战略性避难所规划对于提高野火地区灾害准备的重要性。", "keywords": "火灾避难所, 可达性, 空间差异, 容量挑战, 灾害规划", "comments": "本研究创新性地结合了地理空间分析和模拟方法来评估和优化火灾避难所的可达性与公平性，对未来灾害管理和基础设施规划具有重要指导意义，尤其是在气候变化导致野火风险增高的背景下。"}}
{"id": "2506.07605", "title": "TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems", "authors": ["Marco Di Gennaro", "Giovanni De Lucia", "Stefano Longari", "Stefano Zanero", "Michele Carminati"], "summary": "Federated Learning has emerged as a privacy-oriented alternative to\ncentralized Machine Learning, enabling collaborative model training without\ndirect data sharing. While extensively studied for neural networks, the\nsecurity and privacy implications of tree-based models remain underexplored.\nThis work introduces TimberStrike, an optimization-based dataset reconstruction\nattack targeting horizontally federated tree-based models. Our attack, carried\nout by a single client, exploits the discrete nature of decision trees by using\nsplit values and decision paths to infer sensitive training data from other\nclients. We evaluate TimberStrike on State-of-the-Art federated gradient\nboosting implementations across multiple frameworks, including Flower, NVFlare,\nand FedTree, demonstrating their vulnerability to privacy breaches. On a\npublicly available stroke prediction dataset, TimberStrike consistently\nreconstructs between 73.05% and 95.63% of the target dataset across all\nimplementations. We further analyze Differential Privacy, showing that while it\npartially mitigates the attack, it also significantly degrades model\nperformance. Our findings highlight the need for privacy-preserving mechanisms\nspecifically designed for tree-based Federated Learning systems, and we provide\npreliminary insights into their design.", "comment": "Proceedings on Privacy Enhancing Technologies (To appear) 2025(4)", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07605v1", "AI": {"title_translation": "TimberStrike：揭示联邦树形系统中隐私泄露的数据集重建攻击", "tldr": "TimberStrike攻击揭示了联邦树形模型中严重的隐私泄露，可重建高达95.63%的数据集，并指出需要专门的隐私保护机制。", "motivation": "联邦学习在神经网络方面得到了广泛研究，但树形模型的安全和隐私影响仍未被充分探索。", "method": "本文引入了TimberStrike，一种针对水平联邦树形模型的基于优化的数据集重建攻击。该攻击由单个客户端执行，利用决策树的离散性质，通过分裂值和决策路径推断其他客户端的敏感训练数据。", "result": "TimberStrike在多个框架（包括Flower、NVFlare和FedTree）的联邦梯度提升实现上，始终能重建目标数据集的73.05%到95.63%。差分隐私虽然部分缓解了攻击，但显著降低了模型性能。", "conclusion": "研究结果强调了为基于树的联邦学习系统设计专门的隐私保护机制的必要性，并提供了初步的设计见解。", "translation": "联邦学习已成为集中式机器学习的一种面向隐私的替代方案，可以在不直接共享数据的情况下实现协作模型训练。虽然对神经网络的研究广泛，但树形模型的安全和隐私影响仍未得到充分探索。这项工作引入了TimberStrike，一种针对水平联邦树形模型的基于优化的数据集重建攻击。我们的攻击由单个客户端执行，利用决策树的离散性质，通过分裂值和决策路径推断其他客户端的敏感训练数据。我们在包括Flower、NVFlare和FedTree在内的多个框架上评估了最先进的联邦梯度提升实现中的TimberStrike，证明了它们容易受到隐私泄露的影响。在一个公开可用的中风预测数据集上，TimberStrike在所有实现中始终能重建目标数据集的73.05%到95.63%。我们进一步分析了差分隐私，表明虽然它部分缓解了攻击，但也会显著降低模型性能。我们的发现强调了为基于树的联邦学习系统专门设计隐私保护机制的必要性，并提供了初步的设计见解。", "summary": "本文提出了TimberStrike，一种针对联邦树形模型的数据集重建攻击，旨在揭示其隐私泄露风险。该攻击利用决策树的离散特性，通过分裂值和决策路径从单个客户端推断出其他客户端的敏感训练数据。实验表明，在多种联邦梯度提升框架下，TimberStrike能够重建高达95.63%的目标数据集。研究还发现，差分隐私虽然能部分缓解攻击，但会严重损害模型性能。这突出了为联邦树形学习系统开发专门隐私保护机制的重要性。", "keywords": "联邦学习, 隐私泄露, 树形模型, 数据集重建攻击, TimberStrike", "comments": "该论文创新性地提出了针对联邦树形模型的TimberStrike数据集重建攻击，填补了该领域隐私泄露研究的空白。其重要性在于揭示了现有联邦树形系统在隐私保护方面的脆弱性，并量化了数据泄露的严重程度。同时，对差分隐私有效性的分析也为未来隐私保护机制的设计提供了宝贵启示，强调了需要更具针对性的解决方案。"}}
{"id": "2506.06975", "title": "Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test", "authors": ["Xiaoyuan Zhu", "Yaowen Ye", "Tianyi Qiu", "Hanlin Zhu", "Sijun Tan", "Ajraf Mannan", "Jonathan Michala", "Raluca Ada Popa", "Willie Neiswanger"], "summary": "As API access becomes a primary interface to large language models (LLMs),\nusers often interact with black-box systems that offer little transparency into\nthe deployed model. To reduce costs or maliciously alter model behaviors, API\nproviders may discreetly serve quantized or fine-tuned variants, which can\ndegrade performance and compromise safety. Detecting such substitutions is\ndifficult, as users lack access to model weights and, in most cases, even\noutput logits. To tackle this problem, we propose a rank-based uniformity test\nthat can verify the behavioral equality of a black-box LLM to a locally\ndeployed authentic model. Our method is accurate, query-efficient, and avoids\ndetectable query patterns, making it robust to adversarial providers that\nreroute or mix responses upon the detection of testing attempts. We evaluate\nthe approach across diverse threat scenarios, including quantization, harmful\nfine-tuning, jailbreak prompts, and full model substitution, showing that it\nconsistently achieves superior statistical power over prior methods under\nconstrained query budgets.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.06975v1", "AI": {"title_translation": "使用基于排名的均匀性测试审计黑盒LLM API", "tldr": "提出了一种基于排名的均匀性测试，用于验证黑盒LLM API与本地模型的行为一致性，以检测潜在的模型替换或修改，确保LLM服务的透明度和安全性。", "motivation": "作为LLM的主要接口，API通常是黑盒系统，透明度低。API提供商可能为了降低成本或恶意改变行为而秘密提供量化或微调过的模型变体，这会导致性能下降和安全问题。用户缺乏模型权重和输出logits的访问权限，使得检测这些替换变得困难。", "method": "提出了一种基于排名的均匀性测试（rank-based uniformity test），该方法能够验证黑盒LLM与本地部署的真实模型之间的行为等同性。该方法准确、查询高效，并避免可检测的查询模式，使其对在检测到测试尝试时重新路由或混合响应的对抗性提供商具有鲁棒性。", "result": "在量化、有害微调、越狱提示和完整模型替换等多种威胁场景下进行了评估，结果表明在受限查询预算下，该方法始终比现有方法具有更优越的统计功效。", "conclusion": "该方法能有效且高效地检测黑盒LLM API的潜在模型替换或行为修改，即使在对抗性环境下也能保持鲁棒性，从而增强LLM API的透明度和安全性。", "translation": "随着API访问成为大型语言模型（LLM）的主要接口，用户通常与提供很少透明度的黑盒系统交互。为了降低成本或恶意改变模型行为，API提供商可能会悄悄地提供量化或微调过的变体，这会降低性能并损害安全性。检测此类替换非常困难，因为用户无法访问模型权重，在大多数情况下甚至无法访问输出 logits。为了解决这个问题，我们提出了一种基于排名的均匀性测试，可以验证黑盒LLM与本地部署的真实模型之间的行为等同性。我们的方法准确、查询高效，并避免可检测的查询模式，使其对在检测到测试尝试时重新路由或混合响应的对抗性提供商具有鲁棒性。我们在包括量化、有害微调、越狱提示和完整模型替换在内的各种威胁场景中评估了该方法，结果表明在受限查询预算下，它始终比现有方法具有优越的统计功效。", "summary": "本文提出了一种基于排名的均匀性测试方法，旨在解决用户在使用黑盒LLM API时遇到的模型不透明性问题。该方法能够准确、高效地验证黑盒LLM与本地真实模型之间的行为一致性，从而检测API提供商可能进行的模型量化、微调或替换，这些行为可能导致性能下降或安全风险。实验证明，该方法在多种威胁场景下，即使在查询预算有限的情况下，也比现有方法具有更高的统计功效，并且对对抗性策略具有鲁棒性。", "keywords": "黑盒LLM API, 均匀性测试, 模型审计, 行为等同性, LLM安全", "comments": "这项工作通过提出一种新颖的、基于排名的均匀性测试方法，解决了黑盒LLM API透明度不足的关键问题。其创新之处在于能够仅通过行为观察来检测模型潜在的秘密修改或替换，且对对抗性提供商具有鲁棒性，这对于确保LLM服务的可靠性和安全性至关重要。该方法在查询效率和统计功效方面的优势也使其具有很高的实用价值。"}}
{"id": "2506.06612", "title": "Underwater Multi-Robot Simulation and Motion Planning in Angler", "authors": ["Akshaya Agrawal", "Evan Palmer", "Zachary Kingston", "Geoffrey A. Hollinger"], "summary": "Deploying multi-robot systems in underwater environments is expensive and\nlengthy; testing algorithms and software in simulation improves development by\ndecoupling software and hardware. However, this requires a simulation framework\nthat closely resembles the real-world. Angler is an open-source framework that\nsimulates low-level communication protocols for an onboard autopilot, such as\nArduSub, providing a framework that is close to reality, but unfortunately\nlacking support for simulating multiple robots. We present an extension to\nAngler that supports multi-robot simulation and motion planning. Our extension\nhas a modular architecture that creates non-conflicting communication channels\nbetween Gazebo, ArduSub Software-in-the-Loop (SITL), and MAVROS to operate\nmultiple robots simultaneously in the same environment. Our multi-robot motion\nplanning module interfaces with cascaded controllers via a JointTrajectory\ncontroller in ROS~2. We also provide an integration with the Open Motion\nPlanning Library (OMPL), a collision avoidance module, and tools for procedural\nenvironment generation. Our work enables the development and benchmarking of\nunderwater multi-robot motion planning in dynamic environments.", "comment": "Accepted for OCEANS 2025 Brest", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06612v1", "AI": {"title_translation": "Angler中的水下多机器人仿真与运动规划", "tldr": "该研究扩展了Angler开源框架，使其支持水下多机器人仿真和运动规划，从而能够在动态环境中开发和测试多机器人算法。", "motivation": "在水下环境中部署多机器人系统成本高昂且耗时，因此需要一个能紧密模拟真实世界且支持多机器人的仿真框架来解耦软硬件开发。现有Angler框架虽接近现实但缺乏多机器人支持。", "method": "本研究通过模块化架构扩展了Angler，实现了Gazebo、ArduSub软件在环(SITL)和MAVROS之间的无冲突通信，以同时操作多个机器人。它还通过ROS 2中的JointTrajectory控制器与级联控制器接口，并集成了Open Motion Planning Library (OMPL)、碰撞避免模块和程序化环境生成工具。", "result": "开发了一个支持多机器人仿真和运动规划的Angler扩展，该扩展能够实现水下多机器人运动规划在动态环境中的开发和基准测试。", "conclusion": "该工作使得在动态水下环境中进行多机器人运动规划的开发和基准测试成为可能。", "translation": "在水下环境中部署多机器人系统成本高昂且耗时；在仿真中测试算法和软件通过解耦软硬件改进了开发过程。然而，这需要一个与真实世界高度相似的仿真框架。Angler是一个开源框架，它模拟了机载自动驾驶仪（如ArduSub）的低级通信协议，提供了一个接近现实的框架，但遗憾的是缺乏对多机器人仿真的支持。我们提出了Angler的一个扩展，它支持多机器人仿真和运动规划。我们的扩展具有模块化架构，在Gazebo、ArduSub软件在环（SITL）和MAVROS之间创建了非冲突的通信通道，以便在同一环境中同时操作多个机器人。我们的多机器人运动规划模块通过ROS 2中的JointTrajectory控制器与级联控制器接口。我们还提供了与Open Motion Planning Library (OMPL)的集成、一个碰撞避免模块以及用于程序化环境生成的工具。我们的工作使得在动态环境中进行水下多机器人运动规划的开发和基准测试成为可能。", "summary": "本论文介绍了一个Angler开源框架的扩展，旨在解决水下多机器人系统开发中真实环境测试的高成本和复杂性问题。Angler原本是一个模拟低级通信协议的框架，但不支持多机器人仿真。该扩展引入了一个模块化架构，通过在Gazebo、ArduSub SITL和MAVROS之间建立无冲突通信通道，实现了在同一环境中同时操作多个机器人。此外，它集成了ROS 2的JointTrajectory控制器、Open Motion Planning Library (OMPL)、碰撞避免模块和程序化环境生成工具，从而支持水下多机器人运动规划的开发和基准测试，尤其适用于动态环境。", "keywords": "水下机器人, 多机器人系统, 仿真, 运动规划, Angler", "comments": "这项工作具有重要意义，因为它填补了现有Angler仿真框架在多机器人支持方面的空白。通过提供一个高保真、模块化的多机器人仿真平台，它极大地降低了水下多机器人算法开发和测试的成本与风险，加速了该领域的研究进展。其模块化设计和与ROS 2、OMPL的集成也增强了其可用性和扩展性。"}}
{"id": "2506.07524", "title": "IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents", "authors": ["Shiwei Feng", "Xiangzhe Xu", "Xuan Chen", "Kaiyuan Zhang", "Syed Yusuf Ahmed", "Zian Su", "Mingwei Zheng", "Xiangyu Zhang"], "summary": "LLM agents are increasingly deployed to automate real-world tasks by invoking\nAPIs through natural language instructions. While powerful, they often suffer\nfrom misinterpretation of user intent, leading to the agent's actions that\ndiverge from the user's intended goal, especially as external toolkits evolve.\nTraditional software testing assumes structured inputs and thus falls short in\nhandling the ambiguity of natural language. We introduce IntenTest, an\nAPI-centric stress testing framework that systematically uncovers intent\nintegrity violations in LLM agents. Unlike prior work focused on fixed\nbenchmarks or adversarial inputs, IntenTest generates realistic tasks based on\ntoolkits' documentation and applies targeted mutations to expose subtle agent\nerrors while preserving user intent. To guide testing, we propose semantic\npartitioning, which organizes natural language tasks into meaningful categories\nbased on toolkit API parameters and their equivalence classes. Within each\npartition, seed tasks are mutated and ranked by a lightweight predictor that\nestimates the likelihood of triggering agent errors. To enhance efficiency,\nIntenTest maintains a datatype-aware strategy memory that retrieves and adapts\neffective mutation patterns from past cases. Experiments on 80 toolkit APIs\ndemonstrate that IntenTest effectively uncovers intent integrity violations,\nsignificantly outperforming baselines in both error-exposing rate and query\nefficiency. Moreover, IntenTest generalizes well to stronger target models\nusing smaller LLMs for test generation, and adapts to evolving APIs across\ndomains.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07524v1", "AI": {"title_translation": "IntenTest：面向API调用型LLM智能体的意图完整性压力测试", "tldr": "IntenTest是一个API中心化的压力测试框架，用于系统性地发现LLM智能体中意图完整性违规问题。它通过生成基于工具包文档的真实任务并应用有针对性的变异来暴露细微的智能体错误，同时保留用户意图，并在实验中显著优于现有基线。", "motivation": "LLM智能体在自动化现实任务中通过调用API变得越来越普及，但它们经常遭受用户意图误解的困扰，导致智能体行为偏离用户预期目标，尤其是在外部工具包不断演进的情况下。传统的软件测试方法假设结构化输入，因此无法处理自然语言的模糊性。", "method": "IntenTest是一个API中心化的压力测试框架。它生成基于工具包文档的真实任务，并应用有针对性的变异来暴露智能体错误，同时保留用户意图。它提出语义分区，将自然语言任务组织成基于工具包API参数及其等价类的有意义类别。在每个分区内，种子任务被变异并通过轻量级预测器进行排名，以估计触发智能体错误的 likelihood。为了提高效率，IntenTest维护一个数据类型感知的策略记忆，从过去的案例中检索和调整有效的变异模式。", "result": "在对80个工具包API进行的实验表明，IntenTest有效地发现了意图完整性违规，在错误暴露率和查询效率方面均显著优于基线。此外，IntenTest能够很好地推广到使用较小LLM进行测试生成的更强目标模型，并适应跨领域不断演进的API。", "conclusion": "IntenTest通过其新颖的API中心化压力测试框架，有效地解决了LLM智能体中意图完整性违规的问题，显著提高了测试效率和错误发现率，并展现出良好的泛化和适应能力。", "translation": "LLM智能体正越来越多地被部署，通过自然语言指令调用API来自动化现实世界的任务。尽管功能强大，但它们经常遭受用户意图误解的困扰，导致智能体的行为偏离用户预期目标，尤其是在外部工具包不断演进的情况下。传统的软件测试假设输入是结构化的，因此在处理自然语言的模糊性方面存在不足。我们引入了IntenTest，一个以API为中心的压力测试框架，它系统地揭示LLM智能体中的意图完整性违规。与之前专注于固定基准或对抗性输入的工作不同，IntenTest基于工具包的文档生成真实任务，并应用有针对性的变异来暴露细微的智能体错误，同时保留用户意图。为了指导测试，我们提出了语义分区，它根据工具包API参数及其等价类将自然语言任务组织成有意义的类别。在每个分区内，种子任务通过一个轻量级预测器进行变异和排名，该预测器估计触发智能体错误的 likelihood。为了提高效率，IntenTest维护一个数据类型感知的策略记忆，从过去的案例中检索和调整有效的变异模式。对80个工具包API的实验表明，IntenTest有效地发现了意图完整性违规，在错误暴露率和查询效率方面均显著优于基线。此外，IntenTest能够很好地推广到使用较小LLM进行测试生成的更强目标模型，并适应跨领域不断演进的API。", "summary": "IntenTest是一个创新的API中心化压力测试框架，旨在解决LLM智能体在执行API调用时出现的意图误解问题。它通过基于工具包文档生成真实任务并应用有针对性的变异来系统地揭示意图完整性违规。该框架引入了语义分区和数据类型感知的策略记忆，以提高测试效率和错误发现能力。实验证明，IntenTest在错误暴露率和查询效率方面显著优于现有基线，并能有效推广到更强的LLM模型和适应不断演进的API。", "keywords": "LLM智能体, 意图完整性, 压力测试, API调用, 自然语言处理", "comments": "该论文提出了一种新颖且实用的方法来解决LLM智能体在API调用中意图完整性问题，这是当前LLM应用落地中的一个关键挑战。其创新点在于结合了API文档、语义分区、任务变异和策略记忆，使得测试过程更加系统化、高效和真实。这项工作对于提高LLM智能体的可靠性和安全性具有重要意义，尤其是在自动化现实世界任务方面。"}}
{"id": "2506.06631", "title": "PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments", "authors": ["Minghao Zou", "Qingtian Zeng", "Yongping Miao", "Shangkun Liu", "Zilong Wang", "Hantao Liu", "Wei Zhou"], "summary": "Visual parsing of images and videos is critical for a wide range of\nreal-world applications. However, progress in this field is constrained by\nlimitations of existing datasets: (1) insufficient annotation granularity,\nwhich impedes fine-grained scene understanding and high-level reasoning; (2)\nlimited coverage of domains, particularly a lack of datasets tailored for\neducational scenarios; and (3) lack of explicit procedural guidance, with\nminimal logical rules and insufficient representation of structured task\nprocess. To address these gaps, we introduce PhysLab, the first video dataset\nthat captures students conducting complex physics experiments. The dataset\nincludes four representative experiments that feature diverse scientific\ninstruments and rich human-object interaction (HOI) patterns. PhysLab comprises\n620 long-form videos and provides multilevel annotations that support a variety\nof vision tasks, including action recognition, object detection, HOI analysis,\netc. We establish strong baselines and perform extensive evaluations to\nhighlight key challenges in the parsing of procedural educational videos. We\nexpect PhysLab to serve as a valuable resource for advancing fine-grained\nvisual parsing, facilitating intelligent classroom systems, and fostering\ncloser integration between computer vision and educational technologies. The\ndataset and the evaluation toolkit are publicly available at\nhttps://github.com/ZMH-SDUST/PhysLab.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06631v1", "AI": {"title_translation": "PhysLab：一个用于物理实验多粒度视觉解析的基准数据集", "tldr": "PhysLab是一个新的视频数据集，用于解决现有数据集在细粒度视觉解析、教育领域覆盖和程序指导方面的不足，它包含学生进行物理实验的视频，并提供多级别标注，旨在推动计算机视觉在教育领域的应用。", "motivation": "现有图像和视频视觉解析数据集存在以下局限性：1) 注释粒度不足，阻碍细粒度场景理解和高级推理；2) 领域覆盖有限，特别是缺乏针对教育场景的数据集；3) 缺乏明确的程序指导，逻辑规则少且结构化任务过程表示不足。", "method": "本文介绍了PhysLab，这是第一个捕捉学生进行复杂物理实验的视频数据集。该数据集包含四种代表性实验，涉及多样化的科学仪器和丰富的人-物交互模式。PhysLab包含620个长视频，并提供多级别标注，支持动作识别、物体检测、人-物交互分析等多种视觉任务。作者建立了强大的基线并进行了广泛评估，以突出程序性教育视频解析中的关键挑战。", "result": "PhysLab数据集包含620个长视频，涵盖四种物理实验，具有多样化的科学仪器和丰富的人-物交互模式。它提供了支持多种视觉任务（如动作识别、物体检测、人-物交互分析）的多级别标注。研究者建立了强基线并进行了广泛评估，揭示了程序性教育视频解析中的关键挑战。", "conclusion": "PhysLab有望成为推动细粒度视觉解析、促进智能课堂系统以及加强计算机视觉与教育技术之间整合的宝贵资源。", "translation": "图像和视频的视觉解析对于广泛的现实世界应用至关重要。然而，该领域的进展受到现有数据集局限性的制约：(1) 注释粒度不足，阻碍细粒度场景理解和高级推理；(2) 领域覆盖有限，特别是缺乏针对教育场景的数据集；(3) 缺乏明确的程序指导，逻辑规则极少且结构化任务过程表示不足。为了弥补这些空白，我们引入了PhysLab，这是第一个捕捉学生进行复杂物理实验的视频数据集。该数据集包括四种代表性实验，具有多样化的科学仪器和丰富的人-物交互（HOI）模式。PhysLab包含620个长视频，并提供支持各种视觉任务（包括动作识别、物体检测、HOI分析等）的多级别标注。我们建立了强大的基线并进行了广泛评估，以突出程序性教育视频解析中的关键挑战。我们期望PhysLab能成为推动细粒度视觉解析、促进智能课堂系统以及加强计算机视觉与教育技术之间更紧密整合的宝贵资源。该数据集和评估工具包可在 https://github.com/ZMH-SDUST/PhysLab 公开获取。", "summary": "为了解决现有视觉解析数据集在注释粒度、领域覆盖和程序指导方面的不足，本文推出了PhysLab，一个包含学生进行复杂物理实验视频的基准数据集。PhysLab包含620个长视频，并提供多级别标注，支持多种视觉任务。研究者建立了基线并评估了程序性教育视频解析中的挑战。该数据集旨在促进细粒度视觉解析和智能课堂系统发展，加强计算机视觉与教育技术的融合。", "keywords": "PhysLab, 视觉解析, 物理实验, 基准数据集, 教育技术", "comments": "PhysLab的创新之处在于它是首个专门为物理实验设计的视频数据集，解决了现有数据集在教育领域和细粒度程序指导方面的空白。它的重要性在于能够促进计算机视觉在教育场景中的应用，例如智能课堂系统和自动化实验分析。该数据集的多粒度标注和对复杂人-物交互的捕捉，使其成为推进细粒度视觉解析研究的重要资源。"}}
{"id": "2506.06524", "title": "ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search", "authors": ["Sam Earle", "Ahmed Khalifa", "Muhammad Umair Nasir", "Zehua Jiang", "Graham Todd", "Andrzej Banburski-Fahey", "Julian Togelius"], "summary": "There is much interest in using large pre-trained models in Automatic Game\nDesign (AGD), whether via the generation of code, assets, or more abstract\nconceptualization of design ideas. But so far this interest largely stems from\nthe ad hoc use of such generative models under persistent human supervision.\nMuch work remains to show how these tools can be integrated into\nlonger-time-horizon AGD pipelines, in which systems interface with game engines\nto test generated content autonomously. To this end, we introduce ScriptDoctor,\na Large Language Model (LLM)-driven system for automatically generating and\ntesting games in PuzzleScript, an expressive but highly constrained description\nlanguage for turn-based puzzle games over 2D gridworlds. ScriptDoctor generates\nand tests game design ideas in an iterative loop, where human-authored examples\nare used to ground the system's output, compilation errors from the\nPuzzleScript engine are used to elicit functional code, and search-based agents\nplay-test generated games. ScriptDoctor serves as a concrete example of the\npotential of automated, open-ended LLM-based workflows in generating novel game\ncontent.", "comment": "5 pages, 3 figures, 3 tables, submitted to IEEE Conference on Games\n  as a Short Paper", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06524v1", "AI": {"title_translation": "ScriptDoctor：通过大型语言模型和树搜索自动生成PuzzleScript游戏", "tldr": "ScriptDoctor是一个利用大型语言模型和树搜索，自动生成和测试PuzzleScript游戏的系统，旨在将LLM集成到更长期的自动游戏设计流程中。", "motivation": "尽管人们对在自动游戏设计（AGD）中使用大型预训练模型很感兴趣，但目前这种应用大多是在持续人工监督下的临时使用。仍需大量工作来展示如何将这些工具整合到更长期的AGD流程中，实现系统与游戏引擎的自主交互和测试。", "method": "ScriptDoctor系统通过一个迭代循环来生成和测试游戏设计理念。该循环利用人工编写的示例来引导系统输出，利用PuzzleScript引擎的编译错误来生成功能性代码，并使用基于搜索的代理来玩测试生成的游戏。", "result": "ScriptDoctor提供了一个具体案例，展示了自动化、开放式、基于大型语言模型的工作流在生成新颖游戏内容方面的潜力。", "conclusion": "自动化、开放式、基于大型语言模型的工作流在生成新颖游戏内容方面具有巨大潜力，ScriptDoctor系统为此提供了一个具体范例。", "translation": "人们对在自动游戏设计（AGD）中使用大型预训练模型抱有浓厚兴趣，无论是通过生成代码、资产，还是更抽象的设计理念概念化。但迄今为止，这种兴趣主要源于在持续人工监督下对这些生成模型的临时性使用。仍需大量工作来展示如何将这些工具整合到更长期的AGD流程中，在这些流程中，系统与游戏引擎进行交互以自主测试生成的内容。为此，我们引入了ScriptDoctor，一个由大型语言模型（LLM）驱动的系统，用于在PuzzleScript中自动生成和测试游戏。PuzzleScript是一种表达力强但高度受限的描述语言，用于2D网格世界中的回合制解谜游戏。ScriptDoctor通过一个迭代循环生成和测试游戏设计理念，其中人工编写的示例用于引导系统输出，PuzzleScript引擎的编译错误用于生成功能性代码，基于搜索的代理则对生成的游戏进行玩测试。ScriptDoctor为自动化、开放式、基于LLM的工作流在生成新颖游戏内容方面的潜力提供了一个具体案例。", "summary": "本文介绍了ScriptDoctor，一个由大型语言模型（LLM）驱动的系统，用于自动生成和测试PuzzleScript游戏。该系统旨在解决当前自动游戏设计中LLM应用依赖人工监督的局限性，通过迭代循环，结合人工示例、编译错误反馈和搜索代理的玩测试，实现游戏内容的自主生成和验证。ScriptDoctor展示了LLM在自动化、开放式游戏内容生成工作流中的巨大潜力。", "keywords": "大型语言模型, 自动游戏设计, PuzzleScript, 游戏生成, 树搜索", "comments": "ScriptDoctor的创新之处在于其将大型语言模型与迭代测试循环相结合，实现了游戏内容的自动化、开放式生成和验证，这对于将LLM更深入地集成到自动游戏设计流程中具有重要意义。它超越了LLM的临时性使用，展示了其在复杂、有约束环境（如PuzzleScript）中自主创作的潜力。"}}
{"id": "2506.07787", "title": "A General Coding Framework for Adaptive Private Information Retrieval", "authors": ["Jinbao Zhu", "Xiaohu Tang"], "summary": "The problem of $T$-colluding private information retrieval (PIR) enables the\nuser to retrieve one out of $M$ files from a distributed storage system with\n$N$ servers without revealing anything about the index of the desired file to\nany group of up to $T$ colluding servers. In the considered storage system, the\n$M$ files are stored across the $N$ distributed servers in an $X$-secure\n$K$-coded manner such that any group of up to $X$ colluding servers learns\nnothing about the files; the storage overhead at each server is reduced by a\nfactor of $\\frac{1}{K}$ compared to the total size of the files; and the files\ncan be reconstructed from any $K+X$ servers. However, in practical scenarios,\nwhen the user retrieves the desired file from the distributed system, some\nservers may respond to the user very slowly or not respond at all. These\nservers are referred to as \\emph{stragglers}, and particularly their identities\nand numbers are unknown in advance and may change over time. This paper\nconsiders the adaptive PIR problem that can be capable of tolerating the\npresence of a varying number of stragglers. We propose a general coding method\nfor designing adaptive PIR schemes by introducing the concept of a\n\\emph{feasible PIR coding framework}. We demonstrate that any \\emph{feasible\nPIR coding framework} over a finite field $\\mathbb{F}_q$ with size $q$ can be\nused to construct an adaptive PIR scheme that achieves a retrieval rate of\n$1-\\frac{K+X+T-1}{N-S}$ simultaneously for all numbers of stragglers $0\\leq\nS\\leq N-(K+X+T)$ over the same finite field. Additionally, we provide an\nimplementation of the \\emph{feasible PIR coding framework}, ensuring that the\nadaptive PIR scheme operates over any finite field $\\mathbb{F}_q$ with size\n$q\\geq N+\\max\\{K, N-(K+X+T-1)\\}$.", "comment": "Accepted by IEEE TIT", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07787v1", "AI": {"title_translation": "自适应私有信息检索的通用编码框架", "tldr": "本文提出了一种通用的编码框架，用于设计能够容忍可变数量慢服务器（stragglers）的自适应私有信息检索（PIR）方案，并给出了具体的速率实现。", "motivation": "在实际的分布式存储系统中，用户从服务器检索文件时，可能会遇到响应缓慢或无响应的服务器（称为“慢服务器”），其身份和数量未知且可能随时间变化。传统PIR方案难以应对这种情况，因此需要一种能够容忍可变数量慢服务器的自适应PIR方案。", "method": "本文提出了一种通用编码方法，通过引入“可行PIR编码框架”的概念来设计自适应PIR方案。该方法允许在有限域上构建PIR方案，以应对可变数量的慢服务器。此外，论文还提供了一个“可行PIR编码框架”的实现。", "result": "任何在有限域$\\\\mathbb{F}_q$上的“可行PIR编码框架”都可以用于构建一个自适应PIR方案，该方案在$0\\\\leq S\\\\leq N-(K+X+T)$的慢服务器数量下，同时实现$1-\\\\frac{K+X+T-1}{N-S}$的检索速率。此外，论文提供了一个确保自适应PIR方案可以在任何大小为$q\\\\geq N+\\\\max\\\\{K, N-(K+X+T-1)\\\\}$的有限域$\\\\mathbb{F}_q$上运行的“可行PIR编码框架”的实现。", "conclusion": "本文提出了一个通用的编码框架来解决自适应私有信息检索问题，该框架能够有效容忍分布式存储系统中存在可变数量的慢服务器，并实现了特定的检索速率，为实际应用提供了理论基础和实现方法。", "translation": "关于$T$合谋私有信息检索（PIR）的问题，用户可以从具有$N$个服务器的分布式存储系统中检索$M$个文件中的一个，而不会向任何多达$T$个合谋服务器组透露所需文件的索引信息。在所考虑的存储系统中，$M$个文件以$X$安全$K$编码的方式存储在$N$个分布式服务器上，使得任何多达$X$个合谋服务器组都无法了解文件内容；与文件总大小相比，每个服务器的存储开销减少了$\\\\frac{1}{K}$；并且文件可以从任意$K+X$个服务器中重建。然而，在实际场景中，当用户从分布式系统检索所需文件时，一些服务器可能响应非常慢或根本不响应。这些服务器被称为“慢服务器”，其身份和数量事先未知，并且可能随时间变化。本文考虑了能够容忍可变数量慢服务器存在的自适应PIR问题。我们通过引入“可行PIR编码框架”的概念，提出了一种设计自适应PIR方案的通用编码方法。我们证明，任何在大小为$q$的有限域$\\\\mathbb{F}_q$上的“可行PIR编码框架”都可以用于构建一个自适应PIR方案，该方案在相同的有限域上同时实现$1-\\\\frac{K+X+T-1}{N-S}$的检索速率，适用于所有$0\\\\leq S\\\\leq N-(K+X+T)$的慢服务器数量。此外，我们提供了一个“可行PIR编码框架”的实现，确保自适应PIR方案可以在任何大小为$q\\\\geq N+\\\\max\\\\{K, N-(K+X+T-1)\\\\}$的有限域$\\\\mathbb{F}_q$上运行。", "summary": "本研究解决了在存在可变数量慢服务器的分布式存储系统中进行私有信息检索（PIR）的挑战。论文提出了一种“通用编码框架”来设计自适应PIR方案，引入了“可行PIR编码框架”的概念。研究表明，任何在有限域上的可行PIR编码框架都可以构建一个自适应PIR方案，该方案在不同数量的慢服务器存在时，能实现特定的检索速率。此外，论文还提供了一个确保该方案在特定有限域上运行的具体实现。", "keywords": "私有信息检索, 自适应PIR, 慢服务器, 编码框架, 分布式存储系统", "comments": "本文的创新点在于提出了一个通用的编码框架来解决自适应PIR问题，特别是考虑了实际场景中慢服务器的存在。通过引入“可行PIR编码框架”的概念，为设计容错的PIR方案提供了一个灵活且强大的工具。其重要性在于提升了PIR方案在非理想网络环境下的鲁棒性和实用性，为分布式存储系统中的隐私保护和数据检索提供了新的思路。"}}
{"id": "2506.06505", "title": "InstantFT: An FPGA-Based Runtime Subsecond Fine-tuning of CNN Models", "authors": ["Keisuke Sugiura", "Hiroki Matsutani"], "summary": "Training deep neural networks (DNNs) requires significantly more computation\nand memory than inference, making runtime adaptation of DNNs challenging on\nresource-limited IoT platforms. We propose InstantFT, an FPGA-based method for\nultra-fast CNN fine-tuning on IoT devices, by optimizing the forward and\nbackward computations in parameter-efficient fine-tuning (PEFT). Experiments on\ndatasets with concept drift demonstrate that InstantFT fine-tunes a pre-trained\nCNN 17.4x faster than existing Low-Rank Adaptation (LoRA)-based approaches,\nwhile achieving comparable accuracy. Our FPGA-based InstantFT reduces the\nfine-tuning time to just 0.36s and improves energy-efficiency by 16.3x,\nenabling on-the-fly adaptation of CNNs to non-stationary data distributions.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06505v1", "AI": {"title_translation": "InstantFT: 一种基于FPGA的CNN模型运行时亚秒级微调", "tldr": "InstantFT是一种基于FPGA的方法，可在IoT设备上实现CNN模型的超快速微调，比现有方法快17.4倍，且保持相当的准确性。", "motivation": "在资源受限的IoT平台上，深度神经网络（DNNs）的训练需要大量计算和内存，使得DNN的运行时适应性成为挑战。", "method": "本文提出InstantFT，一种基于FPGA的方法，通过优化参数高效微调（PEFT）中的前向和后向计算，实现IoT设备上的超快速CNN微调。", "result": "InstantFT在概念漂移数据集上比现有基于LoRA的方法微调预训练CNN快17.4倍，同时保持相当的准确性。基于FPGA的InstantFT将微调时间缩短至0.36秒，并将能效提高了16.3倍。", "conclusion": "InstantFT使得CNN模型能够对非平稳数据分布进行即时适应，从而实现运行时模型更新。", "translation": "训练深度神经网络（DNNs）比推理需要显著更多的计算和内存，这使得DNNs在资源受限的IoT平台上进行运行时适应变得具有挑战性。我们提出了InstantFT，一种基于FPGA的方法，通过优化参数高效微调（PEFT）中的前向和后向计算，实现IoT设备上的超快速CNN微调。在具有概念漂移的数据集上进行的实验表明，InstantFT微调预训练CNN的速度比现有的基于低秩适应（LoRA）的方法快17.4倍，同时实现了相当的准确性。我们基于FPGA的InstantFT将微调时间缩短到仅0.36秒，并将能效提高了16.3倍，从而使CNN能够对非平稳数据分布进行即时适应。", "summary": "本文提出InstantFT，一种基于FPGA的CNN模型微调方法，旨在解决IoT设备上DNNs运行时适应的资源限制问题。通过优化参数高效微调中的计算，InstantFT实现了超快速微调，实验表明其速度比现有LoRA方法快17.4倍，微调时间仅0.36秒，能效提高16.3倍，且保持相当的准确性，从而实现CNN对动态数据分布的即时适应。", "keywords": "FPGA, CNN微调, IoT设备, 参数高效微调, 运行时适应", "comments": "本文的创新点在于提出了基于FPGA的InstantFT，显著加速了IoT设备上CNN模型的运行时微调，解决了传统训练方法在资源受限环境下的挑战。其在速度和能效上的显著提升，对边缘AI和动态数据环境下的模型适应性具有重要意义。"}}
{"id": "2506.06327", "title": "Wine Quality Prediction with Ensemble Trees: A Unified, Leak-Free Comparative Study", "authors": ["Zilang Chen"], "summary": "Accurate and reproducible wine-quality assessment is critical for production\ncontrol yet remains dominated by subjective, labour-intensive tasting panels.\nWe present the first unified benchmark of five ensemble learners (Random\nForest, Gradient Boosting, XGBoost, LightGBM, CatBoost) on the canonical Vinho\nVerde red- and white-wine datasets (1,599 and 4,898 instances, 11\nphysicochemical attributes). Our leakage-free workflow employs an 80:20\nstratified train-test split, five-fold StratifiedGroupKFold within the training\nset, per-fold standardisation, SMOTE-Tomek resampling, inverse-frequency cost\nweighting, Optuna hyper-parameter search (120-200 trials per model) and a\ntwo-stage feature-selection refit. Final scores on untouched test sets are\nreported with weighted F1 as the headline metric. Gradient Boosting achieves\nthe highest accuracy (weighted F1 0.693 +/- 0.028 for red and 0.664 +/- 0.016\nfor white), followed within three percentage points by Random Forest and\nXGBoost. Limiting each model to its five top-ranked variables lowers\ndimensionality by 55 percent while reducing weighted F1 by only 2.6 percentage\npoints for red and 3.0 percentage points for white, indicating that alcohol,\nvolatile acidity, sulphates, free SO2 and chlorides capture most predictive\nsignal. Runtime profiling on an EPYC 9K84/H20 node reveals a steep efficiency\ngradient: Gradient Boosting averages 12 h per five-fold study, XGBoost and\nLightGBM require 2-3 h, CatBoost 1 h, and Random Forest under 50 min. We\ntherefore recommend Random Forest as the most cost-effective production model,\nXGBoost and LightGBM as GPU-efficient alternatives, and Gradient Boosting as\nthe accuracy ceiling for offline benchmarking. The fully documented pipeline\nand metric set provide a reproducible baseline for future work on imbalanced\nmulti-class wine-quality prediction.", "comment": "14pages, 7figures,2tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06327v1", "AI": {"title_translation": "使用集成树进行葡萄酒质量预测：一项统一、无泄漏的比较研究", "tldr": "本研究对五种集成学习器在葡萄酒质量预测任务上进行了首次统一、无泄漏的基准测试，发现梯度提升机准确率最高，而随机森林是最具成本效益的生产模型。", "motivation": "准确且可重现的葡萄酒质量评估对生产控制至关重要，但目前仍主要依赖主观、劳动密集型的品鉴小组。", "method": "研究在Vinho Verde红葡萄酒和白葡萄酒数据集上，对随机森林、梯度提升机、XGBoost、LightGBM、CatBoost五种集成学习器进行了统一基准测试。工作流程采用80:20分层训练-测试集划分、训练集内五折分层组K折交叉验证、每折标准化、SMOTE-Tomek重采样、逆频率成本加权、Optuna超参数搜索以及两阶段特征选择再拟合。主要评估指标为加权F1分数。", "result": "梯度提升机获得了最高准确率（红葡萄酒加权F1为0.693 +/- 0.028，白葡萄酒为0.664 +/- 0.016），随机森林和XGBoost紧随其后。将模型限制在五个最重要的变量（酒精、挥发性酸度、硫酸盐、游离SO2和氯化物）上，可将维度降低55%，而加权F1仅降低2.6%（红葡萄酒）和3.0%（白葡萄酒）。运行时分析显示，随机森林最快（不到50分钟），梯度提升机最慢（平均12小时）。", "conclusion": "研究推荐随机森林作为最具成本效益的生产模型，XGBoost和LightGBM作为GPU高效替代方案，而梯度提升机作为离线基准测试的准确性上限。所提供的完整文档流程和指标集为未来不平衡多类别葡萄酒质量预测工作提供了可复现的基线。", "translation": "准确且可重现的葡萄酒质量评估对生产控制至关重要，但目前仍主要依赖主观、劳动密集型的品鉴小组。我们首次对五种集成学习器（随机森林、梯度提升机、XGBoost、LightGBM、CatBoost）在经典的Vinho Verde红葡萄酒和白葡萄酒数据集（分别为1,599和4,898个实例，11个理化属性）上进行了统一的基准测试。我们的无泄漏工作流程采用了80:20分层训练-测试集划分、训练集内五折分层组K折交叉验证、每折标准化、SMOTE-Tomek重采样、逆频率成本加权、Optuna超参数搜索（每个模型120-200次试验）和两阶段特征选择再拟合。在未接触的测试集上报告最终得分，以加权F1作为主要指标。梯度提升机取得了最高准确率（红葡萄酒加权F1为0.693 +/- 0.028，白葡萄酒为0.664 +/- 0.016），随机森林和XGBoost的得分在其三个百分点以内。将每个模型限制在其排名前五的变量上，可将维度降低55%，同时红葡萄酒的加权F1仅降低2.6个百分点，白葡萄酒仅降低3.0个百分点，这表明酒精、挥发性酸度、硫酸盐、游离SO2和氯化物捕获了大部分预测信号。在EPYC 9K84/H20节点上的运行时分析显示出陡峭的效率梯度：梯度提升机平均每五折研究需要12小时，XGBoost和LightGBM需要2-3小时，CatBoost需要1小时，随机森林不到50分钟。因此，我们推荐随机森林作为最具成本效益的生产模型，XGBoost和LightGBM作为GPU高效替代方案，以及梯度提升机作为离线基准测试的准确性上限。完整文档化的流程和指标集为未来不平衡多类别葡萄酒质量预测工作提供了可复现的基线。", "summary": "本研究对五种集成学习器（随机森林、梯度提升机、XGBoost、LightGBM、CatBoost）在Vinho Verde葡萄酒数据集上进行了首次统一、无泄漏的葡萄酒质量预测基准测试。通过严谨的工作流程和评估，发现梯度提升机在准确性上表现最佳，而随机森林在效率上更具优势。研究还识别出影响葡萄酒质量的五个关键理化属性，并为未来的葡萄酒质量预测研究提供了可复现的基线和实际应用建议。", "keywords": "葡萄酒质量预测, 集成树, 比较研究, 无泄漏, 特征选择", "comments": "本文通过对多种集成树模型进行全面且无数据泄漏的比较研究，为葡萄酒质量的客观评估提供了坚实的基础。其创新之处在于构建了一个严谨、可复现的基准测试流程，并提供了实际的生产模型选择建议，兼顾了准确性和计算效率。此外，对关键特征的识别也具有重要的实践意义。"}}
{"id": "2506.06958", "title": "Position: Simulating Society Requires Simulating Thought", "authors": ["Chance Jiajie Li", "Jiayi Wu", "Zhenze Mo", "Ao Qu", "Yuhan Tang", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Jinhua Zhao", "Paul Liang", "Luis Alonso", "Kent Larson"], "summary": "Simulating society with large language models (LLMs), we argue, requires more\nthan generating plausible behavior -- it demands cognitively grounded reasoning\nthat is structured, revisable, and traceable. LLM-based agents are increasingly\nused to emulate individual and group behavior -- primarily through prompting\nand supervised fine-tuning. Yet they often lack internal coherence, causal\nreasoning, and belief traceability -- making them unreliable for analyzing how\npeople reason, deliberate, or respond to interventions.\n  To address this, we present a conceptual modeling paradigm, Generative Minds\n(GenMinds), which draws from cognitive science to support structured belief\nrepresentations in generative agents. To evaluate such agents, we introduce the\nRECAP (REconstructing CAusal Paths) framework, a benchmark designed to assess\nreasoning fidelity via causal traceability, demographic grounding, and\nintervention consistency. These contributions advance a broader shift: from\nsurface-level mimicry to generative agents that simulate thought -- not just\nlanguage -- for social simulations.", "comment": null, "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.06958v1", "AI": {"title_translation": "立场：模拟社会需要模拟思想", "tldr": "现有LLM社会模拟缺乏认知基础和因果推理；本文提出GenMinds范式和RECAP评估框架，旨在模拟思想而非仅是语言。", "motivation": "现有大型语言模型（LLMs）在模拟社会时，主要通过提示和微调来模仿个体和群体行为，但它们缺乏内部连贯性、因果推理和信念可追溯性，导致它们在分析人们如何推理、审议或响应干预方面不可靠。文章认为模拟社会需要认知上扎根的、结构化的、可修改和可追溯的推理，而不仅仅是生成貌似合理的行为。", "method": "提出一个概念建模范式——“生成式思维”（Generative Minds, GenMinds），它借鉴认知科学来支持生成式智能体中的结构化信念表示。为了评估这些智能体，引入了RECAP（REconstructing CAusal Paths）框架，这是一个旨在通过因果可追溯性、人口学基础和干预一致性来评估推理保真度的基准。", "result": "本文的贡献是提出了GenMinds范式和RECAP评估框架，推动了社会模拟从表面模仿向模拟思想而非仅仅语言的生成式智能体的转变。", "conclusion": "模拟社会需要超越表面行为模仿，转向模拟具有认知基础、结构化、可修订和可追溯思维的生成式智能体，这通过GenMinds和RECAP框架得以实现。", "translation": "模拟社会需要模拟思想\n我们认为，用大型语言模型（LLMs）模拟社会，需要的不仅仅是生成貌似合理的行为——它需要认知上扎根的推理，这种推理是结构化的、可修改的和可追溯的。基于LLM的智能体越来越多地被用于模拟个体和群体行为——主要是通过提示和监督微调。然而，它们常常缺乏内部连贯性、因果推理和信念可追溯性——这使得它们在分析人们如何推理、审议或响应干预方面不可靠。\n为了解决这个问题，我们提出了一种概念建模范式，即生成式思维（Generative Minds, GenMinds），它借鉴认知科学来支持生成式智能体中的结构化信念表示。为了评估这些智能体，我们引入了RECAP（REconstructing CAusal Paths）框架，这是一个旨在通过因果可追溯性、人口学基础和干预一致性来评估推理保真度的基准。这些贡献推动了更广泛的转变：从表面层面的模仿转向模拟思想——而不仅仅是语言——用于社会模拟的生成式智能体。", "summary": "本文提出，使用大型语言模型进行社会模拟，需要模拟具有认知基础、结构化、可修改和可追溯的思维，而非仅是表面行为。针对现有LLM智能体在因果推理和信念可追溯性上的不足，作者引入了“生成式思维”（GenMinds）概念建模范式，该范式借鉴认知科学以支持智能体中的结构化信念表示。同时，为评估此类智能体，文章提出了RECAP框架，一个通过因果可追溯性、人口学基础和干预一致性来衡量推理保真度的基准。这些工作旨在推动社会模拟从单纯的语言模仿转向更深层次的思想模拟。", "keywords": "社会模拟, 大型语言模型, 生成式智能体, 认知科学, 因果推理", "comments": "这篇论文提出了一种重要的观点，即在社会模拟中，LLM需要从简单的行为模仿转向更深层次的认知模拟，即模拟“思想”而非仅仅“语言”。GenMinds范式和RECAP评估框架的提出，为实现这一目标提供了具体的方向和工具，强调了认知科学在AI社会模拟中的重要性，具有创新性。"}}
{"id": "2506.07724", "title": "Optimal quantum sampling on distributed databases", "authors": ["Longyun Chen", "Jingcheng Liu", "Penghui Yao"], "summary": "Quantum sampling, a fundamental subroutine in numerous quantum algorithms,\ninvolves encoding a given probability distribution in the amplitudes of a pure\nstate. Given the hefty cost of large-scale quantum storage, we initiate the\nstudy of quantum sampling in a distributed setting. Specifically, we assume\nthat the data is distributed among multiple machines, and each machine solely\nmaintains a basic oracle that counts the multiplicity of individual elements.\nGiven a quantum sampling task, which is to sample from the joint database, a\ncoordinator can make oracle queries to all machines. We focus on the oblivious\ncommunication model, where communications between the coordinator and the\nmachines are predetermined. We present both sequential and parallel algorithms:\nthe sequential algorithm queries the machines sequentially, while the parallel\nalgorithm allows the coordinator to query all machines simultaneously.\nFurthermore, we prove that both algorithms are optimal in their respective\nsettings.", "comment": null, "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.07724v1", "AI": {"title_translation": "分布式数据库上的最优量子采样", "tldr": "由于大规模量子存储成本高昂，本文研究了分布式数据库上的量子采样问题，并提出了在预定通信模型下最优的顺序和并行算法。", "motivation": "大规模量子存储成本高昂，这促使研究人员在分布式环境下探索量子采样问题。", "method": "本文假设数据分布在多台机器上，每台机器维护一个计算元素多重性的基本预言机。协调器向所有机器进行预言机查询以实现联合数据库采样。研究聚焦于预定通信模型，并提出了顺序和并行两种算法。", "result": "本文提出了针对分布式数据库上量子采样的顺序和并行算法。并证明这两种算法在各自设置下都是最优的。", "conclusion": "本文在预定通信模型下，成功引入并分析了分布式数据库上的最优量子采样算法，解决了大规模量子存储成本带来的挑战。", "translation": "量子采样是许多量子算法中的一个基本子程序，它涉及将给定的概率分布编码到纯态的振幅中。鉴于大规模量子存储的巨大成本，我们启动了分布式环境下量子采样的研究。具体来说，我们假设数据分布在多台机器上，每台机器只维护一个计算单个元素多重性的基本预言机。给定一个量子采样任务，即从联合数据库中进行采样，协调器可以向所有机器进行预言机查询。我们专注于预定通信模型，其中协调器和机器之间的通信是预先确定的。我们提出了顺序算法和并行算法：顺序算法依次查询机器，而并行算法允许协调器同时查询所有机器。此外，我们证明这两种算法在各自的设置中都是最优的。", "summary": "本文针对大规模量子存储成本高昂的问题，在分布式数据库环境下研究了量子采样。在数据分布且机器具有基本多重性预言机的假设下，文章提出了在预定通信模型下，协调器从联合数据库采样的顺序和并行算法，并证明了其最优性。", "keywords": "量子采样, 分布式数据库, 最优算法, 预定通信, 量子存储", "comments": "本文的创新之处在于，它通过将基本的量子子程序（采样）应用于分布式环境，解决了实际挑战（高昂的量子存储成本）。对最优算法以及不同通信模型（顺序与并行）的关注也值得注意。"}}
{"id": "2506.07010", "title": "ModelForge: Using GenAI to Improve the Development of Security Protocols", "authors": ["Martin Duclos", "Ivan A. Fernandez", "Kaneesha Moore", "Sudip Mittal", "Edward Zieglar"], "summary": "Formal methods can be used for verifying security protocols, but their\nadoption can be hindered by the complexity of translating natural language\nprotocol specifications into formal representations. In this paper, we\nintroduce ModelForge, a novel tool that automates the translation of protocol\nspecifications for the Cryptographic Protocol Shapes Analyzer (CPSA). By\nleveraging advances in Natural Language Processing (NLP) and Generative AI\n(GenAI), ModelForge processes protocol specifications and generates a CPSA\nprotocol definition. This approach reduces the manual effort required, making\nformal analysis more accessible. We evaluate ModelForge by fine-tuning a large\nlanguage model (LLM) to generate protocol definitions for CPSA, comparing its\nperformance with other popular LLMs. The results from our evaluation show that\nModelForge consistently produces quality outputs, excelling in syntactic\naccuracy, though some refinement is needed to handle certain protocol details.\nThe contributions of this work include the architecture and proof of concept\nfor a translating tool designed to simplify the adoption of formal methods in\nthe development of security protocols.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07010v1", "AI": {"title_translation": "ModelForge：使用生成式AI改进安全协议的开发", "tldr": "ModelForge是一个利用生成式AI和NLP自动化将安全协议的自然语言规范转换为形式化表示的工具，旨在简化安全协议的形式化验证。", "motivation": "形式化方法可用于验证安全协议，但将自然语言协议规范转换为形式化表示的复杂性阻碍了其应用。", "method": "本文介绍了ModelForge，一个利用自然语言处理（NLP）和生成式AI（GenAI）自动化将协议规范翻译为Cryptographic Protocol Shapes Analyzer (CPSA)协议定义的工具。通过微调大型语言模型（LLM）来生成CPSA协议定义，并将其性能与其他流行LLM进行比较以进行评估。", "result": "ModelForge持续生成高质量输出，在语法准确性方面表现出色，尽管在处理某些协议细节方面仍需完善。", "conclusion": "本工作的贡献包括一个旨在简化形式化方法在安全协议开发中应用的翻译工具的架构和概念验证。", "translation": "形式化方法可用于验证安全协议，但将自然语言协议规范转换为形式化表示的复杂性可能会阻碍其采用。在本文中，我们介绍了ModelForge，这是一种新颖的工具，可自动化为密码协议形状分析器 (CPSA) 翻译协议规范。通过利用自然语言处理 (NLP) 和生成式AI (GenAI) 的进步，ModelForge 处理协议规范并生成 CPSA 协议定义。这种方法减少了所需的手动工作，使形式化分析更易于访问。我们通过微调大型语言模型 (LLM) 来生成 CPSA 的协议定义，并将其性能与其他流行的 LLM 进行比较，从而评估了 ModelForge。我们的评估结果表明，ModelForge 持续产生高质量输出，在语法准确性方面表现出色，尽管在处理某些协议细节方面仍需完善。这项工作的贡献包括一个翻译工具的架构和概念验证，旨在简化形式化方法在安全协议开发中的采用。", "summary": "ModelForge是一款利用NLP和生成式AI的工具，旨在自动化将安全协议的自然语言规范转换为形式化表示，特别是针对CPSA。它通过微调LLM实现自动化，显著减少了手动工作，使形式化分析更易于访问。评估结果显示ModelForge在语法准确性方面表现优异，证明了其在简化安全协议开发中形式化方法应用的潜力。", "keywords": "安全协议, 形式化方法, 生成式AI, 自然语言处理, ModelForge", "comments": "ModelForge的创新之处在于将生成式AI应用于安全协议的形式化表示转换，解决了传统方法中人工翻译的复杂性问题。这对于推广形式化方法在安全协议开发中的应用具有重要意义，因为它降低了使用门槛。虽然在处理复杂协议细节上仍有改进空间，但其概念验证和架构为未来的研究奠定了基础。"}}
{"id": "2506.06541", "title": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes", "authors": ["Eugenie Lai", "Gerardo Vitagliano", "Ziyu Zhang", "Sivaprasad Sudhir", "Om Chabra", "Anna Zeng", "Anton A. Zabreyko", "Chenning Li", "Ferdi Kossmann", "Jialin Ding", "Jun Chen", "Markos Markakis", "Matthew Russo", "Weiyang Wang", "Ziniu Wu", "Michael J. Cafarella", "Lei Cao", "Samuel Madden", "Tim Kraska"], "summary": "Constructing real-world data-to-insight pipelines often involves data\nextraction from data lakes, data integration across heterogeneous data sources,\nand diverse operations from data cleaning to analysis. The design and\nimplementation of data science pipelines require domain knowledge, technical\nexpertise, and even project-specific insights. AI systems have shown remarkable\nreasoning, coding, and understanding capabilities. However, it remains unclear\nto what extent these capabilities translate into successful design and\nexecution of such complex pipelines. We introduce KRAMABENCH: a benchmark\ncomposed of 104 manually-curated real-world data science pipelines spanning\n1700 data files from 24 data sources in 6 different domains. We show that these\npipelines test the end-to-end capabilities of AI systems on data processing,\nrequiring data discovery, wrangling and cleaning, efficient processing,\nstatistical reasoning, and orchestrating data processing steps given a\nhigh-level task. Our evaluation tests 5 general models and 3 code generation\nmodels using our reference framework, DS-GURU, which instructs the AI model to\ndecompose a question into a sequence of subtasks, reason through each step, and\nsynthesize Python code that implements the proposed design. Our results on\nKRAMABENCH show that, although the models are sufficiently capable of solving\nwell-specified data science code generation tasks, when extensive data\nprocessing and domain knowledge are required to construct real-world data\nscience pipelines, existing out-of-box models fall short. Progress on\nKramaBench represents crucial steps towards developing autonomous data science\nagents for real-world applications. Our code, reference framework, and data are\navailable at https://github.com/mitdbg/KramaBench.", "comment": null, "cate": "cs.DB", "url": "http://arxiv.org/abs/2506.06541v1", "AI": {"title_translation": "KramaBench：一个针对数据湖上数据到洞察管道中AI系统的基准", "tldr": "该论文引入了KramaBench，这是一个用于评估AI系统处理复杂真实世界数据到洞察管道能力的基准。现有AI模型在这些端到端任务上表现不足，这突显了对更好自主数据科学智能体的需求。", "motivation": "尽管AI系统在推理、编码和理解方面表现出色，但尚不清楚这些能力在设计和执行涉及数据提取、集成、清理和分析等复杂真实世界数据到洞察管道方面的转化程度。因此，需要一个基准来评估AI系统在这方面的端到端能力。", "method": "研究人员推出了KRAMABENCH，这是一个包含104个手动策划的真实世界数据科学管道的基准，涵盖来自6个不同领域24个数据源的1700个数据文件。他们使用DS-GURU参考框架评估了5个通用模型和3个代码生成模型，该框架指导AI模型将问题分解为子任务、推理每个步骤并生成Python代码。", "result": "KRAMABENCH的评估结果表明，尽管现有模型足以解决规范明确的数据科学代码生成任务，但在需要大量数据处理和领域知识来构建真实世界数据科学管道时，现有开箱即用模型表现不足。", "conclusion": "KramaBench的进展对于开发用于真实世界应用的自主数据科学智能体至关重要，因为当前的AI系统在处理端到端数据到洞察管道的复杂性方面仍面临挑战。", "translation": "构建真实世界的数据到洞察管道通常涉及从数据湖中提取数据、跨异构数据源进行数据集成以及从数据清洗到分析的各种操作。数据科学管道的设计和实现需要领域知识、技术专长，甚至项目特定的洞察力。AI系统已经展示出卓越的推理、编码和理解能力。然而，尚不清楚这些能力在多大程度上转化为成功设计和执行此类复杂管道。我们引入了KRAMABENCH：一个由104个手动策划的真实世界数据科学管道组成的基准，涵盖来自6个不同领域24个数据源的1700个数据文件。我们表明，这些管道测试了AI系统在数据处理方面的端到端能力，需要数据发现、整理和清洗、高效处理、统计推理以及根据高级任务编排数据处理步骤。我们的评估使用我们的参考框架DS-GURU测试了5个通用模型和3个代码生成模型，该框架指导AI模型将问题分解为一系列子任务，推理每个步骤，并合成实现所提出设计的Python代码。我们在KRAMABENCH上的结果表明，尽管模型足以解决规范明确的数据科学代码生成任务，但当构建真实世界数据科学管道需要大量数据处理和领域知识时，现有开箱即用模型表现不足。KramaBench的进展代表着开发用于真实世界应用的自主数据科学智能体的关键步骤。我们的代码、参考框架和数据可在https://github.com/mitdbg/KramaBench获取。", "summary": "KramaBench是一个新的基准，旨在评估AI系统在构建真实世界数据湖上数据到洞察管道方面的能力。该基准包含104个真实数据科学管道，涵盖广泛的数据处理任务，从数据发现到统计推理和流程编排。评估结果表明，尽管现有AI模型在特定代码生成任务上表现良好，但在处理需要大量数据处理和领域知识的复杂真实世界管道时，它们仍显不足。KramaBench的进展被认为是开发自主数据科学智能体的关键一步。", "keywords": "数据到洞察管道, 数据湖, AI系统, 基准, 数据科学智能体", "comments": "KramaBench通过关注复杂真实世界数据科学管道所需的端到端能力，弥补了AI评估中的一个关键空白。其手动策划的性质和多样化的领域使其成为一个强大的基准。研究结果表明当前模型在整合领域知识和处理复杂数据处理工作流方面的不足，这对于推动自主数据科学的发展具有重要意义。"}}
{"id": "2506.06624", "title": "Attention-Based Convolutional Neural Network Model for Human Lower Limb Activity Recognition using sEMG", "authors": ["Mojtaba Mollahossein", "Farshad Haghgoo Daryakenari", "Mohammad Hossein Rohban", "Gholamreza Vossoughi"], "summary": "Accurate classification of lower limb movements using surface\nelectromyography (sEMG) signals plays a crucial role in assistive robotics and\nrehabilitation systems. In this study, we present a lightweight attention-based\ndeep neural network (DNN) for real-time movement classification using\nmulti-channel sEMG data from the publicly available BASAN dataset. The proposed\nmodel consists of only 62,876 parameters and is designed without the need for\ncomputationally expensive preprocessing, making it suitable for real-time\ndeployment. We employed a leave-oneout validation strategy to ensure\ngeneralizability across subjects, and evaluated the model on three movement\nclasses: walking, standing with knee flexion, and sitting with knee extension.\nThe network achieved 86.74% accuracy on the validation set and 85.38% on the\ntest set, demonstrating strong classification performance under realistic\nconditions. Comparative analysis with existing models in the literature\nhighlights the efficiency and effectiveness of our approach, especially in\nscenarios where computational cost and real-time response are critical. The\nresults indicate that the proposed model is a promising candidate for\nintegration into upper-level controllers in human-robot interaction systems.", "comment": "6 pages, 3 figures", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06624v1", "AI": {"title_translation": "基于注意力机制的卷积神经网络模型用于sEMG人体下肢活动识别", "tldr": "本研究提出了一种轻量级、基于注意力机制的深度神经网络，用于使用sEMG信号进行实时下肢运动分类，在准确性和计算效率方面表现出色，适用于辅助机器人和康复系统。", "motivation": "使用表面肌电图（sEMG）信号准确分类下肢运动对于辅助机器人和康复系统至关重要。", "method": "本研究提出了一种轻量级基于注意力机制的深度神经网络（DNN），用于使用公开的BASAN数据集中的多通道sEMG数据进行实时运动分类。该模型仅包含62,876个参数，无需计算昂贵的预处理，适合实时部署。采用留一法验证策略，在行走、屈膝站立和伸膝坐立三种运动类别上对模型进行了评估。", "result": "该网络在验证集上实现了86.74%的准确率，在测试集上实现了85.38%的准确率，在实际条件下表现出强大的分类性能。与现有模型的比较分析突出了该方法在计算成本和实时响应至关重要场景下的效率和有效性。", "conclusion": "研究结果表明，所提出的模型是集成到人机交互系统中上层控制器的一个有前景的候选方案。", "translation": "使用表面肌电图（sEMG）信号准确分类下肢运动在辅助机器人和康复系统中起着关键作用。在本研究中，我们提出了一种轻量级、基于注意力机制的深度神经网络（DNN），用于使用公开的BASAN数据集中的多通道sEMG数据进行实时运动分类。所提出的模型仅包含62,876个参数，并且无需计算昂贵的预处理，使其适用于实时部署。我们采用留一法验证策略，以确保模型在不同受试者之间的泛化能力，并在三种运动类别上对模型进行了评估：行走、屈膝站立和伸膝坐立。该网络在验证集上实现了86.74%的准确率，在测试集上实现了85.38%的准确率，在实际条件下表现出强大的分类性能。与现有模型的比较分析突出了我们方法的效率和有效性，尤其是在计算成本和实时响应至关重要的场景中。结果表明，所提出的模型是集成到人机交互系统中上层控制器的一个有前景的候选方案。", "summary": "本研究提出了一种轻量级、基于注意力机制的深度神经网络（DNN），利用多通道sEMG信号对人体下肢活动进行实时分类。该模型参数少，无需复杂预处理，在BASAN数据集上对行走、屈膝站立和伸膝坐立三种运动类别进行了评估，在验证集和测试集上分别达到了86.74%和85.38%的准确率。研究结果表明，该模型在计算效率和分类性能上均表现出色，有望应用于辅助机器人和康复系统中的人机交互系统。", "keywords": "sEMG, 下肢活动识别, 注意力机制, 深度神经网络, 实时", "comments": "该论文提出了一种轻量级且高效的注意力机制深度神经网络，用于sEMG信号的下肢活动识别。其创新性在于模型参数少且无需复杂预处理，这对于实时部署具有重要意义。在实际应用场景中，计算成本和实时响应能力是关键因素，该模型在这两方面都表现出色。其在辅助机器人和康复系统领域的潜在应用前景广阔。"}}
{"id": "2506.07594", "title": "Evaluating LLMs Effectiveness in Detecting and Correcting Test Smells: An Empirical Study", "authors": ["E. G. Santana Jr", "Jander Pereira Santos Junior", "Erlon P. Almeida", "Iftekhar Ahmed", "Paulo Anselmo da Mota Silveira Neto", "Eduardo Santana de Almeida"], "summary": "Test smells indicate poor development practices in test code, reducing\nmaintainability and reliability. While developers often struggle to prevent or\nrefactor these issues, existing tools focus primarily on detection rather than\nautomated refactoring. Large Language Models (LLMs) have shown strong potential\nin code understanding and transformation, but their ability to both identify\nand refactor test smells remains underexplored. We evaluated GPT-4-Turbo, LLaMA\n3 70B, and Gemini-1.5 Pro on Python and Java test suites, using PyNose and\nTsDetect for initial smell detection, followed by LLM-driven refactoring.\nGemini achieved the highest detection accuracy (74.35\\% Python, 80.32\\% Java),\nwhile LLaMA was lowest. All models could refactor smells, but effectiveness\nvaried, sometimes introducing new smells. Gemini also improved test coverage,\nunlike GPT-4 and LLaMA, which often reduced it. These results highlight LLMs'\npotential for automated test smell refactoring, with Gemini as the strongest\nperformer, though challenges remain across languages and smell types.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07594v1", "AI": {"title_translation": "评估大型语言模型在检测和纠正测试异味方面的有效性：一项实证研究", "tldr": "本研究评估了大型语言模型（LLMs）在检测和重构测试异味方面的能力，发现Gemini-1.5 Pro表现最佳，但仍存在挑战。", "motivation": "测试异味会降低代码的可维护性和可靠性，而现有工具主要侧重于检测而非自动化重构。尽管大型语言模型（LLMs）在代码理解和转换方面显示出潜力，但它们在识别和重构测试异味方面的能力尚未得到充分探索。", "method": "研究评估了GPT-4-Turbo、LLaMA 3 70B和Gemini-1.5 Pro，在Python和Java测试套件上进行实验。首先使用PyNose和TsDetect进行初始异味检测，然后由LLM驱动进行重构。", "result": "Gemini-1.5 Pro在检测准确性方面表现最佳（Python为74.35%，Java为80.32%），而LLaMA 3 70B最低。所有模型都能重构异味，但有效性各异，有时会引入新的异味。与GPT-4和LLaMA不同，Gemini还能提高测试覆盖率，而其他模型通常会降低。", "conclusion": "研究结果突出了大型语言模型在自动化测试异味重构方面的潜力，其中Gemini-1.5 Pro表现最强，但跨语言和异味类型仍存在挑战。", "translation": "测试异味表明测试代码中存在不良开发实践，降低了可维护性和可靠性。尽管开发人员常常难以预防或重构这些问题，但现有工具主要侧重于检测而非自动化重构。大型语言模型（LLMs）在代码理解和转换方面显示出强大潜力，但它们识别和重构测试异味的能力仍未得到充分探索。我们评估了GPT-4-Turbo、LLaMA 3 70B和Gemini-1.5 Pro在Python和Java测试套件上的表现，使用PyNose和TsDetect进行初始异味检测，然后进行LLM驱动的重构。Gemini取得了最高的检测准确率（Python为74.35%，Java为80.32%），而LLaMA最低。所有模型都能重构异味，但有效性各异，有时会引入新的异味。与GPT-4和LLaMA不同，Gemini还能提高测试覆盖率，而其他模型通常会降低。这些结果突出了LLMs在自动化测试异味重构方面的潜力，其中Gemini是表现最强的模型，尽管跨语言和异味类型仍存在挑战。", "summary": "本研究评估了大型语言模型（LLMs），包括GPT-4-Turbo、LLaMA 3 70B和Gemini-1.5 Pro，在检测和纠正Python和Java测试代码中测试异味方面的有效性。研究发现，Gemini-1.5 Pro在检测准确性上表现最佳，并且能够提高测试覆盖率。尽管所有模型都能进行重构，但其有效性各异，且有时会引入新的异味。结果表明LLMs在自动化测试异味重构方面具有潜力，Gemini是其中的佼佼者，但仍面临跨语言和异味类型的挑战。", "keywords": "测试异味, 大型语言模型, 代码重构, 软件质量, 实证研究", "comments": "这项研究创新性地将大型语言模型应用于测试异味的自动化重构，超越了现有工具的局限性。其重要性在于为提高测试代码质量和开发效率提供了新的途径。Gemini-1.5 Pro在检测准确性和提升测试覆盖率方面的优异表现是亮点，但研究也坦诚地指出了模型可能引入新异味以及跨语言/异味类型挑战的局限性，这为未来研究指明了方向。"}}
{"id": "2506.06643", "title": "Dark Channel-Assisted Depth-from-Defocus from a Single Image", "authors": ["Moushumi Medhi", "Rajiv Ranjan Sahay"], "summary": "In this paper, we utilize the dark channel as a complementary cue to estimate\nthe depth of a scene from a single space-variant defocus blurred image due to\nits effectiveness in implicitly capturing the local statistics of blurred\nimages and the scene structure. Existing depth-from-defocus (DFD) techniques\ntypically rely on multiple images with varying apertures or focus settings to\nrecover depth information. Very few attempts have focused on DFD from a single\ndefocused image due to the underconstrained nature of the problem. Our method\ncapitalizes on the relationship between local defocus blur and contrast\nvariations as key depth cues to enhance the overall performance in estimating\nthe scene's structure. The entire pipeline is trained adversarially in a fully\nend-to-end fashion. Experiments conducted on real data with realistic\ndepth-induced defocus blur demonstrate that incorporating dark channel prior\ninto single image DFD yields meaningful depth estimation results, validating\nthe effectiveness of our approach.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06643v1", "AI": {"title_translation": "暗通道辅助的单幅图像离焦深度估计", "tldr": "本文提出了一种利用暗通道先验从单幅离焦图像中估计场景深度的方法，通过对抗性端到端训练，实现了有意义的深度估计结果。", "motivation": "现有的离焦深度估计（DFD）技术通常依赖于多幅具有不同光圈或对焦设置的图像来恢复深度信息。由于单幅离焦图像的深度估计问题具有欠约束性质，因此很少有研究尝试从单幅图像进行DFD。", "method": "本方法利用暗通道作为补充线索，从单幅空间变异离焦模糊图像中估计场景深度，因为它能有效隐式捕获模糊图像的局部统计信息和场景结构。该方法利用局部离焦模糊和对比度变化之间的关系作为关键深度线索，以提高场景结构估计的整体性能。整个流程以完全端到端的方式进行对抗性训练。", "result": "在具有真实深度引起的离焦模糊的真实数据上进行的实验表明，将暗通道先验引入单幅图像DFD可以产生有意义的深度估计结果。", "conclusion": "将暗通道先验引入单幅图像离焦深度估计是有效的，能够从单幅离焦图像中获得有意义的深度估计结果。", "translation": "在本文中，我们利用暗通道作为补充线索，从单幅空间变异离焦模糊图像中估计场景深度，因为它能有效隐式捕获模糊图像的局部统计信息和场景结构。现有的离焦深度估计（DFD）技术通常依赖于多幅具有不同光圈或对焦设置的图像来恢复深度信息。由于问题的欠约束性质，很少有尝试关注从单幅离焦图像进行DFD。我们的方法利用局部离焦模糊和对比度变化之间的关系作为关键深度线索，以提高场景结构估计的整体性能。整个流程以完全端到端的方式进行对抗性训练。在具有真实深度引起的离焦模糊的真实数据上进行的实验表明，将暗通道先验引入单幅图像DFD可以产生有意义的深度估计结果，验证了我们方法的有效性。", "summary": "本文提出了一种新颖的单幅图像离焦深度估计（DFD）方法，通过利用暗通道作为补充线索来捕获模糊图像的局部统计信息和场景结构。该方法克服了传统DFD技术对多幅图像的依赖，通过利用局部离焦模糊和对比度变化的关系作为深度线索，并采用完全端到端的对抗性训练。实验结果表明，该方法在真实数据上能够有效估计深度，验证了暗通道先验在单幅图像DFD中的有效性。", "keywords": "暗通道, 离焦深度估计, 单幅图像, 深度估计, 对抗性训练", "comments": "这项工作在单幅图像离焦深度估计这一欠约束问题上取得了进展，通过引入暗通道先验作为一种新颖的补充线索。其端到端的对抗性训练方法提高了估计性能，并在真实数据上得到了验证，具有重要的实践意义。"}}
{"id": "2506.06574", "title": "The Optimization Paradox in Clinical AI Multi-Agent Systems", "authors": ["Suhana Bedi", "Iddah Mlauzi", "Daniel Shin", "Sanmi Koyejo", "Nigam H. Shah"], "summary": "Multi-agent artificial intelligence systems are increasingly deployed in\nclinical settings, yet the relationship between component-level optimization\nand system-wide performance remains poorly understood. We evaluated this\nrelationship using 2,400 real patient cases from the MIMIC-CDM dataset across\nfour abdominal pathologies (appendicitis, pancreatitis, cholecystitis,\ndiverticulitis), decomposing clinical diagnosis into information gathering,\ninterpretation, and differential diagnosis. We evaluated single agent systems\n(one model performing all tasks) against multi-agent systems (specialized\nmodels for each task) using comprehensive metrics spanning diagnostic outcomes,\nprocess adherence, and cost efficiency. Our results reveal a paradox: while\nmulti-agent systems generally outperformed single agents, the\ncomponent-optimized or Best of Breed system with superior components and\nexcellent process metrics (85.5% information accuracy) significantly\nunderperformed in diagnostic accuracy (67.7% vs. 77.4% for a top multi-agent\nsystem). This finding underscores that successful integration of AI in\nhealthcare requires not just component level optimization but also attention to\ninformation flow and compatibility between agents. Our findings highlight the\nneed for end to end system validation rather than relying on component metrics\nalone.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06574v1", "AI": {"title_translation": "临床AI多智能体系统中的优化悖论", "tldr": "临床AI多智能体系统中，组件级优化不一定带来系统级性能提升，甚至可能导致诊断准确性下降，需要关注信息流和系统级验证。", "motivation": "临床AI多智能体系统部署日益增多，但组件级优化与系统整体性能之间的关系尚不清楚。", "method": "使用MIMIC-CDM数据集中2400例真实患者病例，涵盖四种腹部病理（阑尾炎、胰腺炎、胆囊炎、憩室炎），将临床诊断分解为信息收集、解释和鉴别诊断。比较了单一智能体系统和多智能体系统，并使用了诊断结果、过程依从性和成本效率等综合指标进行评估。", "result": "发现了一个悖论：多智能体系统通常优于单一智能体系统，但组件优化或“最佳品种”系统（具有优越组件和出色过程指标，信息准确率达85.5%）在诊断准确率上表现显著不佳（67.7%），远低于表现最佳的多智能体系统（77.4%）。", "conclusion": "成功将AI整合到医疗保健中，不仅需要组件级优化，还需要关注智能体之间的信息流和兼容性。研究结果强调了需要进行端到端系统验证，而不是仅仅依赖于组件指标。", "translation": "多智能体人工智能系统越来越多地部署在临床环境中，然而，组件级优化与系统整体性能之间的关系仍知之甚少。我们使用来自MIMIC-CDM数据集的2400例真实患者病例，评估了四种腹部病理（阑尾炎、胰腺炎、胆囊炎、憩室炎）的这种关系，将临床诊断分解为信息收集、解释和鉴别诊断。我们使用涵盖诊断结果、过程依从性和成本效率的综合指标，评估了单一智能体系统（一个模型执行所有任务）与多智能体系统（每个任务都有专门模型）的性能。我们的结果揭示了一个悖论：虽然多智能体系统通常优于单一智能体系统，但组件优化或“最佳品种”系统（具有优越组件和出色过程指标，信息准确率达85.5%）在诊断准确率方面表现显著不佳（67.7%），远低于表现最佳的多智能体系统（77.4%）。这一发现强调，AI在医疗保健中的成功整合不仅需要组件级优化，还需要关注智能体之间的信息流和兼容性。我们的研究结果凸显了需要进行端到端系统验证，而不是仅仅依赖于组件指标。", "summary": "本研究调查了临床AI多智能体系统中组件级优化与系统整体性能之间的关系。通过在2400例真实患者病例上比较单一智能体和多智能体系统，研究发现了一个“优化悖论”：尽管多智能体系统通常表现更好，但组件最优化的系统反而可能在诊断准确性上表现不佳。这表明在医疗AI中，成功的系统集成需要关注智能体间的信息流和兼容性，并强调了进行端到端系统验证的重要性。", "keywords": "多智能体系统, 临床AI, 优化悖论, 系统验证, 诊断准确性", "comments": "这篇论文揭示了在复杂多智能体AI系统中一个重要的反直觉现象，即“优化悖论”。它强调了在医疗等高风险领域部署AI系统时，不能仅仅停留在组件层面的优化，而必须考虑系统整体的协同效应、信息流和兼容性。其创新之处在于通过实际数据验证了这一悖论，并为未来医疗AI系统的设计和验证提供了关键指导，具有重要的实践意义。"}}
{"id": "2506.07799", "title": "Learned Off-Grid Imager for Low-Altitude Economy with Cooperative ISAC Network", "authors": ["Yixuan Huang", "Jie Yang", "Shuqiang Xia", "Chao-Kai Wen", "Shi Jin"], "summary": "The low-altitude economy is emerging as a key driver of future economic\ngrowth, necessitating effective flight activity surveillance using existing\nmobile cellular network sensing capabilities. However, traditional monostatic\nand localizationbased sensing methods face challenges in fusing sensing results\nand matching channel parameters. To address these challenges, we model\nlow-altitude surveillance as a compressed sensing (CS)-based imaging problem by\nleveraging the cooperation of multiple base stations and the inherent sparsity\nof aerial images. Additionally, we derive the point spread function to analyze\nthe influences of different antenna, subcarrier, and resolution settings on the\nimaging performance. Given the random spatial distribution of unmanned aerial\nvehicles (UAVs), we propose a physics-embedded learning method to mitigate\noff-grid errors in traditional CS-based approaches. Furthermore, to enhance\nrare UAV detection in vast low-altitude airspace, we integrate an online hard\nexample mining scheme into the loss function design, enabling the network to\nadaptively focus on samples with significant discrepancies from the ground\ntruth during training. Simulation results demonstrate the effectiveness of the\nproposed low-altitude surveillance framework. The proposed physicsembedded\nlearning algorithm achieves a 97.55% detection rate, significantly\noutperforming traditional CS-based methods under off-grid conditions. Part of\nthe source code for this paper will be soon accessed at\nhttps://github.com/kiwi1944/LAEImager.", "comment": "submitted to IEEE for possible publication", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07799v1", "AI": {"title_translation": "用于低空经济的合作ISAC网络学习型离格成像仪", "tldr": "本文提出了一种基于压缩感知和物理嵌入学习的低空监视框架，利用现有蜂窝网络实现高精度无人机检测，有效解决了传统方法的离格误差问题，并显著提高了检测率。", "motivation": "低空经济是未来经济增长的关键驱动力，需要利用现有移动蜂窝网络感知能力进行有效的飞行活动监测。然而，传统的单站和基于定位的感知方法在融合感知结果和匹配信道参数方面面临挑战。", "method": "将低空监视建模为基于压缩感知（CS）的成像问题，利用多基站协作和空中图像的固有稀疏性。推导了点扩散函数以分析不同天线、子载波和分辨率设置对成像性能的影响。提出了一种物理嵌入学习方法以减轻传统CS方法中的离格误差。此外，将在线难例挖掘方案集成到损失函数设计中，以增强对稀有无人机的检测。", "result": "仿真结果表明所提出的低空监视框架的有效性。所提出的物理嵌入学习算法实现了97.55%的检测率，在离格条件下显著优于传统的基于CS的方法。", "conclusion": "该研究提出了一种有效的低空监视框架，通过结合物理嵌入学习和在线难例挖掘，显著提高了无人机检测的准确性，尤其是在存在离格误差的情况下，为低空经济的飞行活动监测提供了新途径。", "translation": "低空经济正在成为未来经济增长的关键驱动力，因此需要利用现有移动蜂窝网络的感知能力进行有效的飞行活动监视。然而，传统的单站和基于定位的感知方法在融合感知结果和匹配信道参数方面面临挑战。为了解决这些挑战，我们通过利用多个基站的协作和空中图像固有的稀疏性，将低空监视建模为一个基于压缩感知（CS）的成像问题。此外，我们推导了点扩散函数，以分析不同天线、子载波和分辨率设置对成像性能的影响。鉴于无人机（UAVs）的随机空间分布，我们提出了一种物理嵌入学习方法来减轻传统基于CS方法中的离格误差。此外，为了增强在广阔低空空域中稀有无人机的检测，我们将在线难例挖掘方案集成到损失函数设计中，使网络在训练期间能够自适应地关注与真实值存在显著差异的样本。仿真结果证明了所提出的低空监视框架的有效性。所提出的物理嵌入学习算法实现了97.55%的检测率，在离格条件下显著优于传统的基于CS的方法。本文的部分源代码将很快在https://github.com/kiwi1944/LAEImager访问。", "summary": "本文针对低空经济中飞行活动监视的需求，提出了一种基于压缩感知（CS）的低空成像框架。该框架利用多基站协作和空中图像稀疏性，并将低空监视建模为CS成像问题。为解决传统CS方法中的离格误差，引入了一种物理嵌入学习方法，并结合在线难例挖掘方案以提高稀有无人机检测能力。仿真结果显示，该方法检测率高达97.55%，显著优于传统CS方法。", "keywords": "低空经济, 合作ISAC, 压缩感知, 离格误差, 无人机检测", "comments": "本文的创新点在于将物理嵌入学习与压缩感知相结合，有效解决了低空监视中的离格误差问题，并引入难例挖掘机制提升了稀有目标检测能力，对低空经济的空域安全和管理具有重要意义。"}}
{"id": "2506.06787", "title": "FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks", "authors": ["Qiyun Zhao"], "summary": "As integrated circuit scale grows and design complexity rises, effective\ncircuit representation helps support logic synthesis, formal verification, and\nother automated processes in electronic design automation. And-Inverter Graphs\n(AIGs), as a compact and canonical structure, are widely adopted for\nrepresenting Boolean logic in these workflows. However, the increasing\ncomplexity and integration density of modern circuits introduce structural\nheterogeneity and global logic information loss in AIGs, posing significant\nchallenges to accurate circuit modeling. To address these issues, we propose\nFuncGNN, which integrates hybrid feature aggregation to extract\nmulti-granularity topological patterns, thereby mitigating structural\nheterogeneity and enhancing logic circuit representations. FuncGNN further\nintroduces gate-aware normalization that adapts to circuit-specific gate\ndistributions, improving robustness to structural heterogeneity. Finally,\nFuncGNN employs multi-layer integration to merge intermediate features across\nlayers, effectively synthesizing local and global semantic information for\ncomprehensive logic representations. Experimental results on two logic-level\nanalysis tasks (i.e., signal probability prediction and truth-table distance\nprediction) demonstrate that FuncGNN outperforms existing state-of-the-art\nmethods, achieving improvements of 2.06% and 18.71%, respectively, while\nreducing training time by approximately 50.6% and GPU memory usage by about\n32.8%.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06787v1", "AI": {"title_translation": "FuncGNN：利用图神经网络学习逻辑电路的功能语义", "tldr": "FuncGNN是一种新的图神经网络模型，通过混合特征聚合、门感知归一化和多层集成，有效解决了复杂集成电路建模中的结构异质性和信息丢失问题，并在逻辑分析任务中显著优于现有SOTA方法。", "motivation": "随着集成电路规模的增长和设计复杂性的提高，有效的电路表示对于支持逻辑综合、形式验证和其他电子设计自动化中的自动化过程至关重要。然而，现代电路日益增长的复杂性和集成密度在与非反相图（AIGs）中引入了结构异质性和全局逻辑信息丢失，对准确的电路建模构成了重大挑战。", "method": "本文提出了FuncGNN，它通过以下方式解决上述问题：1. 整合混合特征聚合以提取多粒度拓扑模式，从而减轻结构异质性并增强逻辑电路表示。2. 引入门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。3. 采用多层集成，合并跨层中间特征，有效综合局部和全局语义信息，实现全面的逻辑表示。", "result": "FuncGNN在信号概率预测和真值表距离预测这两个逻辑级分析任务上，分别实现了2.06%和18.71%的性能提升，同时训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。", "conclusion": "FuncGNN通过其创新的混合特征聚合、门感知归一化和多层集成机制，有效克服了复杂集成电路建模中的挑战，显著提高了逻辑电路表示的准确性和效率，并在多个逻辑分析任务中展现出卓越的性能。", "translation": "随着集成电路规模的增长和设计复杂性的提高，有效的电路表示有助于支持逻辑综合、形式验证和电子设计自动化中的其他自动化过程。与非反相图（AIGs）作为一种紧凑和规范的结构，在这些工作流程中被广泛用于表示布尔逻辑。然而，现代电路日益增长的复杂性和集成密度在AIGs中引入了结构异质性和全局逻辑信息丢失，对准确的电路建模构成了重大挑战。为了解决这些问题，我们提出了FuncGNN，它集成了混合特征聚合以提取多粒度拓扑模式，从而减轻结构异质性并增强逻辑电路表示。FuncGNN进一步引入了门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。最后，FuncGNN采用了多层集成，合并跨层中间特征，有效综合局部和全局语义信息，实现全面的逻辑表示。在两个逻辑级分析任务（即信号概率预测和真值表距离预测）上的实验结果表明，FuncGNN优于现有的最先进方法，分别实现了2.06%和18.71%的改进，同时训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。", "summary": "本文提出了FuncGNN，一种用于学习逻辑电路功能语义的图神经网络模型，旨在解决复杂集成电路中AIGs表示的结构异质性和信息丢失问题。FuncGNN通过混合特征聚合捕获多粒度拓扑模式，引入门感知归一化增强鲁棒性，并利用多层集成整合局部和全局语义信息。实验证明，FuncGNN在信号概率和真值表距离预测任务上显著优于现有方法，并大幅降低了训练时间和GPU内存消耗。", "keywords": "图神经网络, 逻辑电路, 功能语义, 电路表示, 结构异质性", "comments": "FuncGNN的创新之处在于其结合了混合特征聚合、门感知归一化和多层集成，这些机制协同作用，有效提升了复杂逻辑电路表示的准确性和鲁棒性。该方法不仅在性能上超越了现有SOTA，还在资源效率方面取得了显著进步，这对于大规模集成电路设计和自动化具有重要意义。它为未来的电路建模和分析提供了新的方向。"}}
{"id": "2506.06330", "title": "ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications", "authors": ["James Afful"], "summary": "As machine learning systems are increasingly deployed in high-stakes domains\nsuch as criminal justice, finance, and healthcare, the demand for interpretable\nand trustworthy models has intensified. Despite the proliferation of local\nexplanation techniques, including SHAP, LIME, and counterfactual methods, there\nexists no standardized, reproducible framework for their comparative\nevaluation, particularly in fairness-sensitive settings.\n  We introduce ExplainBench, an open-source benchmarking suite for systematic\nevaluation of local model explanations across ethically consequential datasets.\nExplainBench provides unified wrappers for popular explanation algorithms,\nintegrates end-to-end pipelines for model training and explanation generation,\nand supports evaluation via fidelity, sparsity, and robustness metrics. The\nframework includes a Streamlit-based graphical interface for interactive\nexploration and is packaged as a Python module for seamless integration into\nresearch workflows.\n  We demonstrate ExplainBench on datasets commonly used in fairness research,\nsuch as COMPAS, UCI Adult Income, and LendingClub, and showcase how different\nexplanation methods behave under a shared experimental protocol. By enabling\nreproducible, comparative analysis of local explanations, ExplainBench advances\nthe methodological foundations of interpretable machine learning and\nfacilitates accountability in real-world AI systems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06330v1", "AI": {"title_translation": "ExplainBench: 公平性关键应用中局部模型解释的基准框架", "tldr": "ExplainBench 是一个开源基准框架，用于系统评估公平性敏感场景下的局部模型解释技术。", "motivation": "随着机器学习系统在高风险领域（如刑事司法、金融、医疗保健）的部署日益增多，对可解释和可信模型的需求加剧。尽管局部解释技术（如 SHAP、LIME、反事实方法）激增，但缺乏一个标准化、可复现的比较评估框架，尤其是在公平性敏感设置中。", "method": "本文引入了 ExplainBench，一个开源基准套件，用于在伦理上重要的数据集上系统评估局部模型解释。ExplainBench 为流行的解释算法提供统一封装器，集成模型训练和解释生成的端到端管道，并支持通过保真度、稀疏性和鲁棒性指标进行评估。该框架包括一个基于 Streamlit 的图形界面用于交互式探索，并打包为 Python 模块以便无缝集成到研究工作流程中。", "result": "作者在公平性研究中常用的数据集（如 COMPAS、UCI Adult Income 和 LendingClub）上演示了 ExplainBench，并展示了不同解释方法在共享实验协议下的行为。", "conclusion": "通过实现局部解释的可复现、比较分析，ExplainBench 提升了可解释机器学习的方法论基础，并促进了现实世界 AI 系统中的问责制。", "translation": "随着机器学习系统越来越多地部署在刑事司法、金融和医疗保健等高风险领域，对可解释和可信模型的需求日益增加。尽管局部解释技术（包括 SHAP、LIME 和反事实方法）激增，但目前尚缺乏一个标准化、可复现的比较评估框架，尤其是在对公平性敏感的设置中。\n我们引入了 ExplainBench，一个开源基准套件，用于在具有伦理影响的数据集上系统评估局部模型解释。ExplainBench 为流行的解释算法提供了统一的封装器，集成了模型训练和解释生成的端到端管道，并支持通过保真度、稀疏性和鲁棒性指标进行评估。该框架包括一个基于 Streamlit 的图形界面用于交互式探索，并打包为 Python 模块以便无缝集成到研究工作流程中。\n我们在公平性研究中常用的数据集（如 COMPAS、UCI Adult Income 和 LendingClub）上演示了 ExplainBench，并展示了不同解释方法在共享实验协议下的行为。通过实现局部解释的可复现、比较分析，ExplainBench 提升了可解释机器学习的方法论基础，并促进了现实世界 AI 系统中的问责制。", "summary": "本文介绍了 ExplainBench，一个开源的基准框架，旨在标准化和系统评估在公平性敏感应用中的局部模型解释技术。该框架为多种解释算法提供统一接口，支持端到端评估流程，并利用保真度、稀疏性和鲁棒性指标进行衡量。ExplainBench 通过在公平性数据集上的演示，促进了可解释机器学习的方法论发展和AI系统的问责制。", "keywords": "局部模型解释, 公平性, 基准框架, 可解释机器学习, ExplainBench", "comments": "ExplainBench 的创新之处在于提供了一个急需的标准化、可复现的框架，用于比较评估局部模型解释技术，尤其关注公平性关键应用。这对于提升可解释AI的科学严谨性至关重要，因为它解决了现有评估方法碎片化的问题，并促进了对不同解释方法行为的深入理解，从而有助于构建更负责任的AI系统。"}}
{"id": "2506.07282", "title": "Adultification Bias in LLMs and Text-to-Image Models", "authors": ["Jane Castleman", "Aleksandra Korolova"], "summary": "The rapid adoption of generative AI models in domains such as education,\npolicing, and social media raises significant concerns about potential bias and\nsafety issues, particularly along protected attributes, such as race and\ngender, and when interacting with minors. Given the urgency of facilitating\nsafe interactions with AI systems, we study bias along axes of race and gender\nin young girls. More specifically, we focus on \"adultification bias,\" a\nphenomenon in which Black girls are presumed to be more defiant, sexually\nintimate, and culpable than their White peers. Advances in alignment techniques\nshow promise towards mitigating biases but vary in their coverage and\neffectiveness across models and bias types. Therefore, we measure explicit and\nimplicit adultification bias in widely used LLMs and text-to-image (T2I)\nmodels, such as OpenAI, Meta, and Stability AI models. We find that LLMs\nexhibit explicit and implicit adultification bias against Black girls,\nassigning them harsher, more sexualized consequences in comparison to their\nWhite peers. Additionally, we find that T2I models depict Black girls as older\nand wearing more revealing clothing than their White counterparts, illustrating\nhow adultification bias persists across modalities. We make three key\ncontributions: (1) we measure a new form of bias in generative AI models, (2)\nwe systematically study adultification bias across modalities, and (3) our\nfindings emphasize that current alignment methods are insufficient for\ncomprehensively addressing bias. Therefore, new alignment methods that address\nbiases such as adultification are needed to ensure safe and equitable AI\ndeployment.", "comment": "Accepted to the ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT '25)", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.07282v1", "AI": {"title_translation": "LLMs和文本到图像模型中的成人化偏见", "tldr": "研究发现，大型语言模型（LLMs）和文本到图像（T2I）模型对黑人女孩存在成人化偏见，将其描述为更年长、更具性意味或面临更严厉的后果，表明现有AI对齐方法不足以解决此类偏见。", "motivation": "随着生成式AI模型在教育、警务和社交媒体等领域的快速采用，其潜在的偏见和安全问题日益突出，特别是在涉及受保护属性（如种族和性别）和未成年人时。本文关注“成人化偏见”，即黑人女孩被错误地认为比白人同龄人更不顺从、更具性暗示和更应受责备的现象，以促进AI系统的安全交互。", "method": "研究测量了广泛使用的LLM（如OpenAI、Meta）和文本到图像（T2I）模型（如Stability AI）中的显性和隐性成人化偏见，重点关注年轻女孩，特别是黑人女孩。", "result": "发现LLMs对黑人女孩表现出显性和隐性成人化偏见，与白人同龄人相比，她们被赋予更严厉、更性化的后果。T2I模型将黑人女孩描绘得更年长，穿着更暴露，表明成人化偏见跨模态存在。", "conclusion": "当前的对齐方法不足以全面解决诸如成人化偏见等问题，因此需要新的对齐方法来确保安全和公平的AI部署。", "translation": "生成式AI模型在教育、警务和社交媒体等领域的快速采用，引发了对潜在偏见和安全问题的严重担忧，尤其是在涉及种族和性别等受保护属性以及与未成年人互动时。鉴于促进与AI系统安全交互的紧迫性，我们研究了年轻女孩在种族和性别方面的偏见。更具体地说，我们关注“成人化偏见”，这是一种黑人女孩被假定比白人同龄人更不顺从、更具性暗示和更应受责备的现象。对齐技术的进步显示出缓解偏见的希望，但其覆盖范围和有效性在不同模型和偏见类型之间存在差异。因此，我们测量了广泛使用的LLM和文本到图像（T2I）模型（如OpenAI、Meta和Stability AI模型）中的显性和隐性成人化偏见。我们发现LLM对黑人女孩表现出显性和隐性成人化偏见，与白人同龄人相比，她们被赋予更严厉、更性化的后果。此外，我们发现T2I模型将黑人女孩描绘得更年长，穿着更暴露，这说明成人化偏见在不同模态中持续存在。我们做出了三个关键贡献：(1) 我们测量了生成式AI模型中的一种新形式的偏见，(2) 我们系统地研究了跨模态的成人化偏见，(3) 我们的发现强调，当前的对齐方法不足以全面解决偏见。因此，需要新的对齐方法来解决诸如成人化等偏见，以确保AI的安全和公平部署。", "summary": "本研究探讨了大型语言模型（LLMs）和文本到图像（T2I）模型中存在的“成人化偏见”，即黑人女孩被错误地视为比白人同龄人更成熟、更具性暗示或更应受责备。通过对OpenAI、Meta和Stability AI等广泛使用的模型进行测试，发现LLMs对黑人女孩施加更严厉、更性化的后果，而T2I模型则将其描绘得更年长、穿着更暴露。研究强调，这种偏见跨模态存在，并指出当前AI对齐方法在解决此类复杂偏见方面的不足，呼吁开发新的对齐技术以确保AI的公平和安全部署。", "keywords": "成人化偏见, 生成式AI, LLM, 文本到图像模型, 偏见缓解", "comments": "这项研究通过引入“成人化偏见”这一新颖且重要的概念，揭示了生成式AI模型中存在的深层社会偏见。其创新之处在于系统地跨模态（LLM和T2I）测量了这种偏见，并明确指出现有对齐技术的局限性。这对于推动AI伦理和负责任的AI开发具有重要意义，提醒开发者和研究者需要更细致、更全面的方法来识别和缓解AI系统中的隐性偏见，特别是针对弱势群体。"}}
{"id": "2506.07031", "title": "HauntAttack: When Attack Follows Reasoning as a Shadow", "authors": ["Jingyuan Ma", "Rui Li", "Zheng Li", "Junfeng Liu", "Lei Sha", "Zhifang Sui"], "summary": "Emerging Large Reasoning Models (LRMs) consistently excel in mathematical and\nreasoning tasks, showcasing exceptional capabilities. However, the enhancement\nof reasoning abilities and the exposure of their internal reasoning processes\nintroduce new safety vulnerabilities. One intriguing concern is: when reasoning\nis strongly entangled with harmfulness, what safety-reasoning trade-off do LRMs\nexhibit? To address this issue, we introduce HauntAttack, a novel and\ngeneral-purpose black-box attack framework that systematically embeds harmful\ninstructions into reasoning questions. Specifically, we treat reasoning\nquestions as carriers and substitute one of their original conditions with a\nharmful instruction. This process creates a reasoning pathway in which the\nmodel is guided step by step toward generating unsafe outputs. Based on\nHauntAttack, we conduct comprehensive experiments on multiple LRMs. Our results\nreveal that even the most advanced LRMs exhibit significant safety\nvulnerabilities. Additionally, we perform a detailed analysis of different\nmodels, various types of harmful instructions, and model output patterns,\nproviding valuable insights into the security of LRMs.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07031v1", "AI": {"title_translation": "HauntAttack：当攻击如影随形地伴随推理", "tldr": "大型推理模型（LRMs）在推理任务中表现出色，但当有害指令被嵌入到推理问题中时，它们会表现出显著的安全漏洞。", "motivation": "随着大型推理模型（LRMs）在数学和推理任务中表现出卓越能力，其推理能力的增强和内部推理过程的暴露引入了新的安全漏洞。具体来说，当推理与危害性强烈纠缠时，LRMs会表现出何种安全-推理权衡是一个令人担忧的问题。", "method": "提出了一种新颖的、通用的黑盒攻击框架HauntAttack，它系统地将有害指令嵌入到推理问题中。具体方法是将推理问题视为载体，并用有害指令替换其原始条件之一，从而创建一个逐步引导模型生成不安全输出的推理路径。", "result": "实验结果表明，即使是最先进的LRMs也表现出显著的安全漏洞。此外，对不同模型、各种有害指令类型和模型输出模式的详细分析，为LRMs的安全性提供了有价值的见解。", "conclusion": "LRMs在处理嵌入了有害指令的推理问题时存在严重的安全漏洞，需要进一步关注其安全-推理权衡。", "translation": "大型推理模型（LRMs）在数学和推理任务中表现出色，展现出卓越的能力。然而，推理能力的增强和其内部推理过程的暴露引入了新的安全漏洞。一个令人担忧的问题是：当推理与危害性强烈纠缠时，LRMs会表现出何种安全-推理权衡？为了解决这个问题，我们引入了HauntAttack，一个新颖的、通用的黑盒攻击框架，它系统地将有害指令嵌入到推理问题中。具体来说，我们将推理问题视为载体，并用有害指令替换其原始条件之一。这个过程创建了一个推理路径，其中模型被一步步引导生成不安全输出。基于HauntAttack，我们对多个LRMs进行了全面的实验。我们的结果表明，即使是最先进的LRMs也表现出显著的安全漏洞。此外，我们对不同模型、各种有害指令类型和模型输出模式进行了详细分析，为LRMs的安全性提供了有价值的见解。", "summary": "本文提出了HauntAttack，一个针对大型推理模型（LRMs）的黑盒攻击框架，旨在评估当推理问题中嵌入有害指令时LRMs的安全漏洞。通过将有害指令替换推理问题中的原始条件，HauntAttack能够引导LRMs生成不安全输出。实验结果表明，即使是最先进的LRMs也存在显著的安全漏洞，这强调了在推理能力提升的同时，LRMs在安全-推理权衡方面面临的挑战。", "keywords": "大型推理模型, 安全漏洞, 黑盒攻击, 推理安全, 有害指令", "comments": "这项研究揭示了大型推理模型在处理包含有害指令的推理任务时存在的严重安全风险，即使是先进的模型也未能幸免。HauntAttack作为一种新颖的黑盒攻击方法，通过巧妙地将有害指令融入推理路径，提供了一个评估和理解LRM安全漏洞的有效工具。这项工作对于推动安全AI研究和开发更鲁棒的推理模型具有重要意义。"}}
{"id": "2506.06630", "title": "Active Test-time Vision-Language Navigation", "authors": ["Heeju Ko", "Sungjune Kim", "Gyeongrok Oh", "Jeongyoon Yoon", "Honglak Lee", "Sujin Jang", "Seungryong Kim", "Sangpil Kim"], "summary": "Vision-Language Navigation (VLN) policies trained on offline datasets often\nexhibit degraded task performance when deployed in unfamiliar navigation\nenvironments at test time, where agents are typically evaluated without access\nto external interaction or feedback. Entropy minimization has emerged as a\npractical solution for reducing prediction uncertainty at test time; however,\nit can suffer from accumulated errors, as agents may become overconfident in\nincorrect actions without sufficient contextual grounding. To tackle these\nchallenges, we introduce ATENA (Active TEst-time Navigation Agent), a test-time\nactive learning framework that enables a practical human-robot interaction via\nepisodic feedback on uncertain navigation outcomes. In particular, ATENA learns\nto increase certainty in successful episodes and decrease it in failed ones,\nimproving uncertainty calibration. Here, we propose mixture entropy\noptimization, where entropy is obtained from a combination of the action and\npseudo-expert distributions-a hypothetical action distribution assuming the\nagent's selected action to be optimal-controlling both prediction confidence\nand action preference. In addition, we propose a self-active learning strategy\nthat enables an agent to evaluate its navigation outcomes based on confident\npredictions. As a result, the agent stays actively engaged throughout all\niterations, leading to well-grounded and adaptive decision-making. Extensive\nevaluations on challenging VLN benchmarks-REVERIE, R2R, and R2R-CE-demonstrate\nthat ATENA successfully overcomes distributional shifts at test time,\noutperforming the compared baseline methods across various settings.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06630v1", "AI": {"title_translation": "活跃测试时间视觉语言导航", "tldr": "ATENA是一个测试时间主动学习框架，通过情景反馈和混合熵优化，帮助视觉语言导航代理在陌生环境中克服分布偏移并提高性能。", "motivation": "离线训练的视觉语言导航(VLN)策略在陌生测试环境中性能下降，且无法获得外部交互或反馈。现有的熵最小化方法可能导致错误累积和过度自信。", "method": "本文引入了ATENA（Active TEst-time Navigation Agent），一个测试时间主动学习框架，通过对不确定导航结果的情景反馈实现实用的人机交互。ATENA学习在成功情景中增加确定性，在失败情景中减少确定性，从而改善不确定性校准。提出了混合熵优化，其中熵是从动作和伪专家分布的组合中获得的，从而同时控制预测置信度和动作偏好。此外，还提出了一种自主动学习策略，使代理能够根据自信的预测评估其导航结果。", "result": "在REVERIE、R2R和R2R-CE等具有挑战性的VLN基准测试中，ATENA成功克服了测试时间的分布偏移，并在各种设置下均优于对比的基线方法。", "conclusion": "ATENA通过其主动学习框架、混合熵优化和自主动学习策略，有效解决了视觉语言导航在测试时间面临的挑战，显著提高了在陌生环境中的性能和不确定性校准。", "translation": "视觉语言导航（VLN）策略在离线数据集上训练后，部署到不熟悉的导航环境进行测试时，其任务性能通常会下降，因为代理通常在没有外部交互或反馈的情况下进行评估。熵最小化已成为一种实用的解决方案，用于在测试时减少预测不确定性；然而，它可能会遭受累积误差的影响，因为代理在没有足够的上下文基础的情况下，可能会对不正确的动作过度自信。为了解决这些挑战，我们引入了ATENA（Active TEst-time Navigation Agent），一个测试时间主动学习框架，通过对不确定导航结果的情景反馈实现实用的人机交互。特别是，ATENA学习在成功情景中增加确定性，在失败情景中减少确定性，从而改善不确定性校准。在此，我们提出了混合熵优化，其中熵是从动作和伪专家分布（假设代理选择的动作是最佳的假设动作分布）的组合中获得的，从而同时控制预测置信度和动作偏好。此外，我们提出了一种自主动学习策略，使代理能够根据自信的预测评估其导航结果。因此，代理在所有迭代中保持积极参与，从而实现良好基础和自适应的决策。在具有挑战性的VLN基准测试——REVERIE、R2R和R2R-CE——上的广泛评估表明，ATENA成功克服了测试时间的分布偏移，在各种设置下均优于对比的基线方法。", "summary": "本文提出了ATENA，一个用于视觉语言导航（VLN）的测试时间主动学习框架，旨在解决代理在陌生环境中性能下降和现有熵最小化方法局限性的问题。ATENA通过情景反馈实现人机交互，学习校准不确定性。其核心方法包括混合熵优化（结合动作和伪专家分布）和自主动学习策略，使代理能持续评估并自适应决策。实验表明，ATENA在多个VLN基准测试中有效克服了分布偏移，并优于基线方法。", "keywords": "视觉语言导航, 主动学习, 测试时间适应, 不确定性校准, 人机交互", "comments": "本文的创新点在于提出了一个结合人机交互和自主动学习的测试时间主动学习框架ATENA，以应对视觉语言导航在陌生环境中的性能退化问题。特别是，混合熵优化和自主动学习策略的引入，使得代理能够更好地校准不确定性并进行自适应决策，有效克服了测试时间的分布偏移。这对于现实世界中机器人导航的鲁棒性具有重要意义。"}}
{"id": "2506.07683", "title": "Leveraging Network Methods for Hub-like Microservice Detection", "authors": ["Alexander Bakhtin", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "summary": "Context: Microservice Architecture is a popular architectural paradigm that\nfacilitates flexibility by decomposing applications into small, independently\ndeployable services. Catalogs of architectural anti-patterns have been proposed\nto highlight the negative aspects of flawed microservice design. In particular,\nthe Hub-like anti-pattern lacks an unambiguous definition and detection method.\nAim: In this work, we aim to find a robust detection approach for the Hub-like\nmicroservice anti-pattern that outputs a reasonable number of Hub-like\ncandidates with high precision. Method: We leveraged a dataset of 25\nmicroservice networks and several network hub detection techniques to identify\nthe Hub-like anti-pattern, namely scale-free property, centrality metrics and\nclustering coefficient, minimum description length principle, and the approach\nbehind the Arcan tool. Results and Conclusion: Our findings revealed that the\nstudied architectural networks are not scale-free, that most considered hub\ndetection approaches do not agree on the detected hubs, and that the method by\nKirkley leveraging the Erdos-Renyi encoding is the most accurate one in terms\nof the number of detected hubs and the detection precision. Investigating\nfurther the applicability of these methods to detecting Hub-like components in\nmicroservice-based and other systems opens up new research directions.\nMoreover, our results provide an evaluation of the approach utilized by the\nwidely used Arcan tool and highlight the potential to update the tool to use\nthe normalized degree centrality of a component in the network, or for the\napproach based on ER encoding to be adopted instead.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07683v1", "AI": {"title_translation": "利用网络方法检测类中心微服务", "tldr": "本文研究了一种鲁棒的类中心微服务反模式检测方法，发现Kirkley的ER编码方法在检测数量和精度方面最为准确，并为现有工具的改进提供了依据。", "motivation": "微服务架构中的“类中心”反模式缺乏明确的定义和有效的检测方法，导致难以识别和解决其负面影响。本研究旨在找到一种高精度、能够输出合理数量类中心候选的鲁棒检测方法。", "method": "研究利用了25个微服务网络数据集，并比较了多种网络中心检测技术，包括无标度特性、中心性度量、聚类系数、最小描述长度原理以及Arcan工具所采用的方法。", "result": "研究发现所分析的架构网络并非无标度网络；大多数考虑的中心检测方法在检测到的中心上不一致；Kirkley利用Erdos-Renyi编码的方法在检测到的中心数量和检测精度方面是最准确的。", "conclusion": "Kirkley利用Erdos-Renyi编码的方法是检测类中心微服务反模式最准确的方法。研究建议可以更新Arcan工具以使用归一化度中心性，或直接采用基于ER编码的方法。", "translation": "背景: 微服务架构是一种流行的架构范式，通过将应用程序分解为小型、独立部署的服务来促进灵活性。人们提出了架构反模式目录，以突出有缺陷的微服务设计的负面影响。特别是，“类中心”反模式缺乏明确的定义和检测方法。\n目的: 在这项工作中，我们旨在为“类中心”微服务反模式找到一种鲁棒的检测方法，该方法能够以高精度输出合理数量的类中心候选。\n方法: 我们利用了25个微服务网络数据集和几种网络中心检测技术来识别“类中心”反模式，即无标度特性、中心性度量和聚类系数、最小描述长度原理以及Arcan工具背后的方法。\n结果与结论: 我们的发现表明，所研究的架构网络并非无标度网络，大多数考虑的中心检测方法在检测到的中心上不一致，并且Kirkley利用Erdos-Renyi编码的方法在检测到的中心数量和检测精度方面是最准确的。进一步研究这些方法在基于微服务和其他系统中检测类中心组件的适用性开辟了新的研究方向。此外，我们的结果评估了广泛使用的Arcan工具所采用的方法，并强调了更新该工具以使用网络中组件的归一化度中心性，或采用基于ER编码的方法的潜力。", "summary": "本文旨在为微服务架构中的“类中心”反模式寻找一种鲁棒的检测方法。通过分析25个微服务网络并比较多种网络中心检测技术，研究发现所分析的网络并非无标度网络，且大多数检测方法结果不一致。其中，Kirkley基于Erdos-Renyi编码的方法被证明在检测数量和精度上最为准确。研究结果为更新现有工具如Arcan提供了依据，并指出了未来研究方向。", "keywords": "微服务架构, 类中心反模式, 网络分析, 中心检测, Erdos-Renyi编码", "comments": "这项研究通过系统地比较多种网络分析方法来检测微服务架构中的“类中心”反模式，具有重要的实践意义。它不仅填补了该反模式检测方法上的空白，还对现有广泛使用的工具如Arcan的检测能力进行了评估和改进建议，有助于提升微服务系统设计的质量和可维护性。其创新点在于将网络科学的度量方法应用于软件架构反模式检测。"}}
{"id": "2506.06645", "title": "Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling", "authors": ["Cheng Peng", "Jingxiang Sun", "Yushuo Chen", "Zhaoqi Su", "Zhuo Su", "Yebin Liu"], "summary": "Photorealistic and animatable human avatars are a key enabler for\nvirtual/augmented reality, telepresence, and digital entertainment. While\nrecent advances in 3D Gaussian Splatting (3DGS) have greatly improved rendering\nquality and efficiency, existing methods still face fundamental challenges,\nincluding time-consuming per-subject optimization and poor generalization under\nsparse monocular inputs. In this work, we present the Parametric Gaussian Human\nModel (PGHM), a generalizable and efficient framework that integrates human\npriors into 3DGS for fast and high-fidelity avatar reconstruction from\nmonocular videos. PGHM introduces two core components: (1) a UV-aligned latent\nidentity map that compactly encodes subject-specific geometry and appearance\ninto a learnable feature tensor; and (2) a disentangled Multi-Head U-Net that\npredicts Gaussian attributes by decomposing static, pose-dependent, and\nview-dependent components via conditioned decoders. This design enables robust\nrendering quality under challenging poses and viewpoints, while allowing\nefficient subject adaptation without requiring multi-view capture or long\noptimization time. Experiments show that PGHM is significantly more efficient\nthan optimization-from-scratch methods, requiring only approximately 20 minutes\nper subject to produce avatars with comparable visual quality, thereby\ndemonstrating its practical applicability for real-world monocular avatar\ncreation.", "comment": "Project Page: https://pengc02.github.io/pghm/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06645v1", "AI": {"title_translation": "参数化高斯人体模型：高效逼真人体化身建模的可泛化先验", "tldr": "PGHM将人体先验引入3DGS，实现了从单目视频中快速、高保真地重建人体化身，解决了现有方法的效率和泛化问题。", "motivation": "现有3D高斯泼溅（3DGS）方法面临耗时的逐主题优化和稀疏单目输入下泛化能力差的挑战。逼真且可动画的人体化身对于虚拟/增强现实、远程呈现和数字娱乐至关重要。", "method": "提出参数化高斯人体模型（PGHM）。包含两个核心组件：1) 紫外线对齐的潜在身份图，将特定主体的几何和外观紧凑编码为可学习的特征张量；2) 解耦的多头U-Net，通过条件解码器分解静态、姿态依赖和视角依赖的组件来预测高斯属性。这种设计在挑战性姿态和视角下实现了鲁棒的渲染质量，并允许高效的主体适应。", "result": "PGHM比从头开始优化的方法效率显著更高，每个主体仅需约20分钟即可生成具有可比视觉质量的化身。", "conclusion": "PGHM由于其效率和可比的视觉质量，在现实世界单目化身创建中展现了实际应用价值。", "translation": "逼真且可动画的人体化身是虚拟/增强现实、远程呈现和数字娱乐的关键推动者。尽管3D高斯泼溅（3DGS）的最新进展大大提高了渲染质量和效率，但现有方法仍面临根本性挑战，包括耗时的逐主题优化和稀疏单目输入下的泛化能力差。在这项工作中，我们提出了参数化高斯人体模型（PGHM），这是一个可泛化且高效的框架，它将人体先验集成到3DGS中，以实现从单目视频中快速高保真地重建化身。PGHM引入了两个核心组件：（1）一个UV对齐的潜在身份图，它将特定主体的几何和外观紧凑地编码为可学习的特征张量；（2）一个解耦的多头U-Net，通过条件解码器分解静态、姿态依赖和视角依赖的组件来预测高斯属性。这种设计在挑战性姿态和视角下实现了鲁棒的渲染质量，同时无需多视角捕获或长时间优化即可实现高效的主体适应。实验表明，PGHM比从头开始优化的方法效率显著更高，每个主体仅需约20分钟即可生成具有可比视觉质量的化身，从而证明了其在现实世界单目化身创建中的实际适用性。", "summary": "本文介绍了PGHM，一个参数化高斯人体模型，它将人体先验集成到3D高斯泼溅（3DGS）中，以克服现有方法在人体化身建模中耗时优化和泛化能力差的挑战。PGHM利用UV对齐的潜在身份图和解耦的多头U-Net，从单目视频中高效重建高保真、可泛化的人体化身。实验表明，PGHM显著将每个主体的优化时间缩短至约20分钟，同时保持可比的视觉质量，使其在现实世界单目化身创建中具有实用性。", "keywords": "参数化高斯人体模型, 3D高斯泼溅, 人体化身, 单目视频, 可泛化先验", "comments": "该论文创新性地将人体先验引入3D高斯泼溅，有效解决了现有方法在效率和泛化能力上的痛点。其核心组件，如UV对齐的潜在身份图和解耦的多头U-Net，设计巧妙，实现了从单目视频中高效生成高保真人体化身。这项工作对于推动虚拟现实、远程呈现和数字娱乐中人体化身的实际应用具有重要意义，因为它大大降低了高质量化身创建的门槛。"}}
{"id": "2506.07817", "title": "On the Fixed-Length-Burst Levenshtein Ball with Unit Radius", "authors": ["Yuanxiao Xi", "Yubo Sun", "Gennian Ge"], "summary": "Consider a length-$n$ sequence $\\bm{x}$ over a $q$-ary alphabet. The\n\\emph{fixed-length Levenshtein ball} $\\mathcal{L}_t(\\bm{x})$ of radius $t$\nencompasses all length-$n$ $q$-ary sequences that can be derived from $\\bm{x}$\nby performing $t$ deletions followed by $t$ insertions. Analyzing the size and\nstructure of these balls presents significant challenges in combinatorial\ncoding theory. Recent studies have successfully characterized fixed-length\nLevenshtein balls in the context of a single deletion and a single insertion.\nThese works have derived explicit formulas for various key metrics, including\nthe exact size of the balls, extremal bounds (minimum and maximum sizes), as\nwell as expected sizes and their concentration properties. However, the general\ncase involving an arbitrary number of $t$ deletions and $t$ insertions $(t>1)$\nremains largely uninvestigated. This work systematically examines fixed-length\nLevenshtein balls with multiple deletions and insertions, focusing specifically\non \\emph{fixed-length burst Levenshtein balls}, where deletions occur\nconsecutively, as do insertions. We provide comprehensive solutions for\nexplicit cardinality formulas, extremal bounds (minimum and maximum sizes),\nexpected size, and concentration properties surrounding the expected value.", "comment": null, "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07817v1", "AI": {"title_translation": "关于单位半径的固定长度突发Levenshtein球", "tldr": "本文系统地研究了固定长度突发Levenshtein球，并提供了其基数、极值界、期望大小及其集中性质的综合解决方案。", "motivation": "分析固定长度Levenshtein球的大小和结构在组合编码理论中具有重要挑战。现有研究已成功描述了单次删除和单次插入的情况，但涉及任意数量的t次删除和t次插入（t>1）的普遍情况仍未得到充分研究。", "method": "本文系统地检查了具有多次删除和插入的固定长度Levenshtein球，特别关注删除和插入连续发生的固定长度突发Levenshtein球。作者提供了明确的基数公式、极值界（最小和最大尺寸）、期望大小及其围绕期望值的集中性质的综合解决方案。", "result": "本文为固定长度突发Levenshtein球提供了明确的基数公式、极值界（最小和最大尺寸）、期望大小及其围绕期望值的集中性质的综合解决方案。", "conclusion": "本文为固定长度突发Levenshtein球的多种关键指标（包括明确的基数公式、极值界、期望大小及其集中性质）提供了全面的解决方案，填补了t>1情况下的研究空白。", "translation": "考虑一个长度为n的q元序列$\bm{x}$。半径为t的固定长度Levenshtein球$\text{L}_t(\bm{x})$包含所有可以通过对$\bm{x}$执行t次删除后t次插入而得到的长度为n的q元序列。分析这些球的大小和结构在组合编码理论中提出了重大挑战。最近的研究已成功地描述了单次删除和单次插入情况下的固定长度Levenshtein球。这些工作推导出了各种关键指标的明确公式，包括球的精确大小、极值界（最小和最大尺寸），以及期望大小及其集中性质。然而，涉及任意数量的t次删除和t次插入（t>1）的普遍情况在很大程度上仍未得到研究。这项工作系统地检查了具有多次删除和插入的固定长度Levenshtein球，特别关注固定长度突发Levenshtein球，其中删除和插入是连续发生的。我们为明确的基数公式、极值界（最小和最大尺寸）、期望大小及其围绕期望值的集中性质提供了综合解决方案。", "summary": "本文系统研究了固定长度突发Levenshtein球，其中删除和插入操作是连续发生的。针对这一在组合编码理论中具有挑战性且t>1情况未被充分研究的领域，论文提供了关于此类球的明确基数公式、极值界（最小和最大尺寸）、期望大小及其集中性质的综合解决方案，填补了现有研究的空白。", "keywords": "Levenshtein球, 突发错误, 组合编码理论, 序列分析, 基数", "comments": "本文解决了Levenshtein球分析中一个重要的未研究领域，即当删除和插入次数t>1时的普遍情况，并特别聚焦于“突发”操作。其创新性在于为复杂的固定长度突发Levenshtein球提供了全面的数学解决方案，包括基数、极值和统计性质。这对于纠错码和序列分析等领域具有重要理论价值。"}}
{"id": "2506.07069", "title": "Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization", "authors": ["Zhican Wang", "Guanghui He", "Dantong Liu", "Lingjun Gao", "Shell Xu Hu", "Chen Zhang", "Zhuoran Song", "Nicholas Lane", "Wayne Luk", "Hongxiang Fan"], "summary": "3D Gaussian Splatting (3DGS) has recently gained significant attention for\nhigh-quality and efficient view synthesis, making it widely adopted in fields\nsuch as AR/VR, robotics, and autonomous driving. Despite its impressive\nalgorithmic performance, real-time rendering on resource-constrained devices\nremains a major challenge due to tight power and area budgets. This paper\npresents an architecture-algorithm co-design to address these inefficiencies.\nFirst, we reveal substantial redundancy caused by repeated computation of\ncommon terms/expressions during the conventional rasterization. To resolve\nthis, we propose axis-oriented rasterization, which pre-computes and reuses\nshared terms along both the X and Y axes through a dedicated hardware design,\neffectively reducing multiply-and-add (MAC) operations by up to 63%. Second, by\nidentifying the resource and performance inefficiency of the sorting process,\nwe introduce a novel neural sorting approach that predicts order-independent\nblending weights using an efficient neural network, eliminating the need for\ncostly hardware sorters. A dedicated training framework is also proposed to\nimprove its algorithmic stability. Third, to uniformly support rasterization\nand neural network inference, we design an efficient reconfigurable processing\narray that maximizes hardware utilization and throughput. Furthermore, we\nintroduce a $\\pi$-trajectory tile schedule, inspired by Morton encoding and\nHilbert curve, to optimize Gaussian reuse and reduce memory access overhead.\nComprehensive experiments demonstrate that the proposed design preserves\nrendering quality while achieving a speedup of $23.4\\sim27.8\\times$ and energy\nsavings of $28.8\\sim51.4\\times$ compared to edge GPUs for real-world scenes. We\nplan to open-source our design to foster further development in this field.", "comment": "Preprint. Under review", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07069v1", "AI": {"title_translation": "使用神经排序和轴向光栅化加速3D高斯泼溅", "tldr": "本文提出了一种架构-算法协同设计，通过神经排序和轴向光栅化显著加速资源受限设备上的3D高斯泼溅，实现了高速度提升和能耗节省。", "motivation": "尽管3D高斯泼溅（3DGS）在高质量和高效视图合成方面表现出色，但由于严格的功耗和面积预算，在资源受限设备上实现实时渲染仍然是一个重大挑战。传统光栅化中存在大量冗余计算，且排序过程效率低下。", "method": "1. 提出轴向光栅化，通过专门的硬件设计预计算并重用沿X和Y轴的共享项，减少多乘加（MAC）操作高达63%。2. 引入新颖的神经排序方法，使用高效神经网络预测与顺序无关的混合权重，消除对昂贵硬件排序器的需求，并提出专门的训练框架提高算法稳定性。3. 设计高效的可重构处理阵列，统一支持光栅化和神经网络推理，最大化硬件利用率和吞吐量。4. 引入受莫顿编码和希尔伯特曲线启发的$\\\\pi$-轨迹瓦片调度，优化高斯重用并减少内存访问开销。", "result": "所提出的设计在保持渲染质量的同时，与边缘GPU相比，在真实场景中实现了23.4~27.8倍的速度提升和28.8~51.4倍的能耗节省。", "conclusion": "本文提出了一种有效的架构-算法协同设计，用于加速资源受限设备上的3D高斯泼溅，显著提高了性能和能效。作者计划开源其设计以促进该领域的进一步发展。", "translation": "3D高斯泼溅（3DGS）最近因其高质量和高效的视图合成而受到广泛关注，使其在AR/VR、机器人和自动驾驶等领域得到广泛应用。尽管其算法性能令人印象深刻，但由于严格的功耗和面积预算，在资源受限设备上实现实时渲染仍然是一个重大挑战。本文提出了一种架构-算法协同设计来解决这些低效率问题。首先，我们揭示了传统光栅化过程中重复计算常见项/表达式所造成的实质性冗余。为了解决这个问题，我们提出了轴向光栅化，通过专门的硬件设计预计算并重用沿X和Y轴的共享项，有效减少了多乘加（MAC）操作高达63%。其次，通过识别排序过程中的资源和性能低效率，我们引入了一种新颖的神经排序方法，该方法使用高效的神经网络预测与顺序无关的混合权重，从而无需昂贵的硬件排序器。还提出了一个专门的训练框架来提高其算法稳定性。第三，为了统一支持光栅化和神经网络推理，我们设计了一种高效的可重构处理阵列，以最大限度地提高硬件利用率和吞吐量。此外，我们引入了一种受莫顿编码和希尔伯特曲线启发的$\\\\pi$轨迹瓦片调度，以优化高斯重用并减少内存访问开销。综合实验表明，与边缘GPU相比，所提出的设计在保持渲染质量的同时，在真实场景中实现了23.4~27.8倍的速度提升和28.8~51.4倍的能耗节省。我们计划开源我们的设计，以促进该领域的进一步发展。", "summary": "本文介绍了一种架构-算法协同设计，旨在加速资源受限设备上的3D高斯泼溅（3DGS），解决在严格功耗和面积预算下实时渲染的挑战。主要创新包括轴向光栅化，通过重用共享项减少冗余计算；以及神经排序，通过神经网络预测混合权重，无需硬件排序器。此外，还提出了高效的可重构处理阵列和$\\\\pi$-轨迹瓦片调度，以优化硬件利用率、吞吐量、高斯重用和内存访问。实验结果表明，与边缘GPU相比，所提出的设计在保持渲染质量的同时，显著提高了渲染速度（23.4-27.8倍）和能效（28.8-51.4倍）。", "keywords": "3D高斯泼溅, 神经排序, 轴向光栅化, 硬件-算法协同设计, 实时渲染", "comments": "该论文通过将硬件-软件协同设计与新颖的算法技术（神经排序、轴向光栅化）相结合，提出了一种高度创新的方法，解决了在边缘设备上实时3DGS渲染的关键问题。所实现的显著速度提升和能耗节省突出了其在AR/VR和自动驾驶等对效率至关重要的应用中的潜在影响。开源设计的计划也对研究社区做出了宝贵贡献。"}}
{"id": "2506.07363", "title": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust", "authors": ["Claudiu Popa", "Rex Pallath", "Liam Cunningham", "Hewad Tahiri", "Abiram Kesavarajah", "Tao Wu"], "summary": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on\nDigital Trust. With the increasing accessibility of generative AI, tools for\nvoice cloning, face-swapping, and synthetic media creation have advanced\nsignificantly, lowering both financial and technical barriers for their use.\nWhile these technologies present innovative opportunities, their rapid growth\nraises concerns about trust, privacy, and security. This white paper explores\nthe implications of deepfake technology, analyzing its role in enabling fraud,\nmisinformation, and the erosion of authenticity in multimedia. Using\ncost-effective, easy to use tools such as Runway, Rope, and ElevenLabs, we\nexplore how realistic deepfakes can be created with limited resources,\ndemonstrating the risks posed to individuals and organizations alike. By\nanalyzing the technical and ethical challenges of deepfake mitigation and\ndetection, we emphasize the urgent need for regulatory frameworks, public\nawareness, and collaborative efforts to maintain trust in digital media.", "comment": "12 pages, 13 figures", "cate": "cs.CY", "url": "http://arxiv.org/abs/2506.07363v1", "AI": {"title_translation": "深度伪造技术揭秘：人工智能的商品化及其对数字信任的影响", "tldr": "随着生成式AI工具的普及，深度伪造技术门槛降低，引发信任、隐私和安全问题。本白皮书探讨了深度伪造的含义，展示了如何用有限资源创建逼真的深度伪造，并强调了应对技术和伦理挑战、维护数字信任的紧迫性。", "motivation": "生成式AI工具的普及降低了深度伪造技术的财务和技术门槛，导致欺诈、错误信息和多媒体真实性受侵蚀，引发了对信任、隐私和安全的担忧。因此，本白皮书旨在探讨深度伪造技术的影响。", "method": "本白皮书分析了深度伪造技术在促成欺诈、错误信息和多媒体真实性侵蚀方面的作用。通过使用Runway、Rope和ElevenLabs等经济高效、易于使用的工具，演示了如何用有限的资源创建逼真的深度伪造。同时，分析了深度伪造缓解和检测的技术和伦理挑战。", "result": "研究表明，即使资源有限，也能使用Runway、Rope和ElevenLabs等工具创建逼真的深度伪造，这给个人和组织都带来了风险。", "conclusion": "深度伪造技术带来了严峻的技术和伦理挑战，迫切需要监管框架、公众意识和协作努力来维护数字媒体的信任。", "translation": "深度伪造技术揭秘：人工智能的商品化及其对数字信任的影响。随着生成式人工智能可及性的提高，语音克隆、换脸和合成媒体创建工具取得了显著进展，降低了其使用的财务和技术障碍。虽然这些技术带来了创新的机会，但其快速增长引发了对信任、隐私和安全的担忧。本白皮书探讨了深度伪造技术的影响，分析了其在促成欺诈、错误信息和多媒体真实性侵蚀方面的作用。通过使用Runway、Rope和ElevenLabs等经济高效、易于使用的工具，我们探讨了如何用有限的资源创建逼真的深度伪造，展示了对个人和组织造成的风险。通过分析深度伪造缓解和检测的技术和伦理挑战，我们强调了维护数字媒体信任的监管框架、公众意识和协作努力的迫切需求。", "summary": "本白皮书深入探讨了深度伪造技术，指出生成式AI工具的普及如何降低了其创建门槛，从而引发了数字信任、隐私和安全危机。文章分析了深度伪造在欺诈和错误信息传播中的作用，并演示了如何利用现有工具以有限资源生成逼真内容。最后，强调了为应对技术和伦理挑战，亟需建立监管框架、提升公众意识并加强合作，以维护数字媒体的真实性。", "keywords": "深度伪造, 数字信任, 生成式AI, 欺诈, 错误信息", "comments": "本文创新性地通过列举具体工具（如Runway、Rope和ElevenLabs）来演示深度伪造的易操作性，直观地揭示了该技术对数字信任的潜在威胁。其重要性在于，它不仅指出了深度伪造的危害，更提出了通过监管、教育和合作来应对挑战的紧迫性，对于政策制定者和公众都具有警示意义。"}}
{"id": "2506.07034", "title": "NanoZone: Scalable, Efficient, and Secure Memory Protection for Arm CCA", "authors": ["Shiqi Liu", "Yongpeng Gao", "Mingyang Zhang", "Jie Wang"], "summary": "Arm Confidential Computing Architecture (CCA) currently isolates at the\ngranularity of an entire Confidential Virtual Machine (CVM), leaving intra-VM\nbugs such as Heartbleed unmitigated. The state-of-the-art narrows this to the\nprocess level, yet still cannot stop attacks that pivot within the same\nprocess, and prior intra-enclave schemes are either too slow or incompatible\nwith CVM-style isolation. We extend CCA with a three-tier zone model that\nspawns an unlimited number of lightweight isolation domains inside a single\nprocess, while shielding them from kernel-space adversaries. To block\ndomain-switch abuse, we also add a fast user-level Code-Pointer Integrity (CPI)\nmechanism. We developed two prototypes: a functional version on Arm's official\nsimulator to validate resistance against intra-process and kernel-space\nadversaries, and a performance variant on Arm development boards evaluated for\nsession-key isolation within server applications, in-memory key-value\nprotection, and non-volatile-memory data isolation. NanoZone incurs roughly a\n20% performance overhead while retaining 95% throughput compared to the system\nwithout fine-grained isolation.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07034v1", "AI": {"title_translation": "NanoZone：Arm CCA 的可伸缩、高效和安全的内存保护", "tldr": "NanoZone 为 Arm CCA 引入了一个三层区域模型和 CPI 机制，以在单个进程内实现可伸缩、高效且安全的细粒度内存保护，解决了现有虚拟机内和进程内隔离的局限性。", "motivation": "Arm 机密计算架构 (CCA) 目前以整个机密虚拟机 (CVM) 的粒度进行隔离，导致虚拟机内部的漏洞（如 Heartbleed）无法得到缓解。现有的最先进技术虽然将隔离粒度缩小到进程级别，但仍无法阻止在同一进程内进行的攻击。此外，以前的飞地内部方案要么速度太慢，要么与 CVM 风格的隔离不兼容。", "method": "NanoZone 通过一个三层区域模型扩展了 Arm CCA，该模型可以在单个进程内生成无限数量的轻量级隔离域，并保护它们免受内核空间攻击者的侵害。为了阻止域切换滥用，该方案还添加了一个快速的用户级代码指针完整性 (CPI) 机制。研究人员开发了两个原型：一个功能版本在 Arm 官方模拟器上验证了对进程内和内核空间攻击者的抵抗能力，另一个性能版本在 Arm 开发板上评估了服务器应用程序中的会话密钥隔离、内存中键值保护和非易失性内存数据隔离。", "result": "与没有细粒度隔离的系统相比，NanoZone 带来了大约 20% 的性能开销，同时保留了 95% 的吞吐量。原型验证了对进程内和内核空间攻击者的抵抗能力，并在会话密钥隔离、内存中键值保护和非易失性内存数据隔离方面进行了评估。", "conclusion": "NanoZone 为 Arm CCA 提供了一种可伸缩、高效且安全的细粒度内存保护解决方案，有效解决了现有隔离方案的局限性，并在可接受的性能开销下增强了安全性。", "translation": "Arm 机密计算架构 (CCA) 目前以整个机密虚拟机 (CVM) 的粒度进行隔离，这使得诸如 Heartbleed 等虚拟机内部错误无法得到缓解。现有的最先进技术将其缩小到进程级别，但仍然无法阻止在同一进程内进行枢轴攻击，并且以前的飞地内部方案要么太慢，要么与 CVM 风格的隔离不兼容。我们通过一个三层区域模型扩展了 CCA，该模型可以在单个进程内生成无限数量的轻量级隔离域，同时保护它们免受内核空间攻击者的侵害。为了阻止域切换滥用，我们还添加了一个快速的用户级代码指针完整性 (CPI) 机制。我们开发了两个原型：一个在 Arm 官方模拟器上运行的功能版本，用于验证对进程内和内核空间攻击者的抵抗能力；另一个是性能版本，在 Arm 开发板上评估了服务器应用程序中的会话密钥隔离、内存中键值保护和非易失性内存数据隔离。与没有细粒度隔离的系统相比，NanoZone 带来了大约 20% 的性能开销，同时保留了 95% 的吞吐量。", "summary": "本文提出 NanoZone，一种用于 Arm 机密计算架构 (CCA) 的新型内存保护方案，旨在解决当前虚拟机级别和进程级别隔离的局限性。NanoZone 采用一个三层区域模型，在单个进程内创建轻量级、隔离的域，并防止内核空间威胁。它还集成了一个快速的用户级代码指针完整性 (CPI) 机制。原型验证了其对抗进程内和内核空间攻击的有效性，实现了细粒度隔离，仅带来约 20% 的性能开销，同时保留了 95% 的吞吐量。", "keywords": "Arm CCA, 内存保护, 机密计算, 细粒度隔离, 代码指针完整性", "comments": "NanoZone 在机密计算领域取得了显著进展，通过在单个进程内提供细粒度内存保护，对于缓解 Heartbleed 等复杂的虚拟机内部攻击至关重要。其与 CVM 风格隔离的兼容性以及可接受的性能开销（20% 的开销，但保留 95% 的吞吐量）使其成为增强 Arm CCA 安全性的一项实用且重要的贡献。区域模型和 CPI 的结合同时解决了隔离和控制流完整性问题。"}}
{"id": "2506.06658", "title": "Self-Adapting Improvement Loops for Robotic Learning", "authors": ["Calvin Luo", "Zilai Zeng", "Mingxi Jia", "Yilun Du", "Chen Sun"], "summary": "Video generative models trained on expert demonstrations have been utilized\nas performant text-conditioned visual planners for solving robotic tasks.\nHowever, generalization to unseen tasks remains a challenge. Whereas improved\ngeneralization may be facilitated by leveraging learned prior knowledge from\nadditional pre-collected offline data sources, such as web-scale video\ndatasets, in the era of experience we aim to design agents that can\ncontinuously improve in an online manner from self-collected behaviors. In this\nwork we thus propose the Self-Adapting Improvement Loop (SAIL), where an\nin-domain video model iteratively updates itself on self-produced trajectories,\ncollected through adaptation with an internet-scale pretrained video model, and\nsteadily improves its performance for a specified task of interest. We apply\nSAIL to a diverse suite of MetaWorld tasks, as well as two manipulation tasks\non a real robot arm, and find that performance improvements continuously emerge\nover multiple iterations for novel tasks initially unseen during original\nin-domain video model training. Furthermore, we discover that SAIL is\nsurprisingly robust regarding if and how the self-collected experience is\nfiltered, and the quality of the initial in-domain demonstrations. Through\nadaptation with summarized internet-scale data, and learning through online\nexperience, we thus demonstrate a way to iteratively bootstrap a\nhigh-performance video model for solving novel robotic tasks through\nself-improvement.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06658v1", "AI": {"title_translation": "机器人学习的自适应改进循环", "tldr": "提出SAIL框架，使机器人通过自收集经验和互联网规模模型自适应地持续改进，解决泛化性挑战。", "motivation": "现有视频生成模型在机器人任务中泛化到未见任务仍是挑战。尽管可以利用离线数据，但目标是设计能通过自收集行为在线持续改进的智能体。", "method": "提出自适应改进循环（SAIL）框架。该框架使领域内视频模型通过与互联网规模预训练视频模型进行适应性学习，在自生成轨迹上迭代更新自身，从而稳定地提高特定任务的性能。", "result": "在MetaWorld任务和真实机械臂操作任务中，SAIL在多轮迭代后，对初始训练中未见的新任务持续展现出性能提升。SAIL对自收集经验的过滤方式以及初始领域内演示的质量表现出令人惊讶的鲁棒性。", "conclusion": "通过与总结的互联网规模数据进行适应性学习，并通过在线经验学习，SAIL展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的方法。", "translation": "视频生成模型在专家演示上进行训练，已被用作高性能的文本条件视觉规划器来解决机器人任务。然而，泛化到未见任务仍然是一个挑战。尽管可以利用来自额外预收集的离线数据源（如网络规模视频数据集）的已学习先验知识来促进泛化能力的提高，但在经验时代，我们旨在设计能够通过自收集行为在线持续改进的智能体。因此，在这项工作中，我们提出了自适应改进循环（SAIL），其中领域内视频模型通过与互联网规模预训练视频模型进行适应性学习，在自生成轨迹上迭代更新自身，并稳定地提高其对特定感兴趣任务的性能。我们将SAIL应用于多样化的MetaWorld任务套件以及真实机械臂上的两个操作任务，发现对于在原始领域内视频模型训练期间最初未见的新任务，性能改进在多次迭代中持续出现。此外，我们发现SAIL在自收集经验是否以及如何过滤以及初始领域内演示的质量方面表现出令人惊讶的鲁棒性。通过与总结的互联网规模数据进行适应性学习，并通过在线经验学习，我们因此展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的方法。", "summary": "本文提出了自适应改进循环（SAIL）框架，旨在解决机器人学习中视频生成模型对未见任务泛化能力不足的问题。SAIL通过让领域内视频模型利用互联网规模预训练模型生成的自收集轨迹进行迭代更新，实现在线持续性能提升。实验证明，SAIL在多种机器人任务上对新任务表现出持续的性能改进，并且对经验过滤和初始演示质量具有鲁棒性，从而展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的有效途径。", "keywords": "机器人学习, 自适应改进循环, 在线学习, 泛化, 视频生成模型", "comments": "这项工作提出了一个新颖的在线自适应学习框架SAIL，通过结合互联网规模的预训练模型和自收集经验，有效解决了机器人学习中泛化性差的挑战。其核心创新在于“自适应改进循环”的理念，使得机器人能够持续地从自身经验中学习和进步，且对数据质量要求不高，具有重要的实际应用潜力。"}}
{"id": "2506.07690", "title": "Centrality Change Proneness: an Early Indicator of Microservice Architectural Degradation", "authors": ["Alexander Bakhtin", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "summary": "Over the past decade, the wide adoption of Microservice Architecture has\nrequired the identification of various patterns and anti-patterns to prevent\nMicroservice Architectural Degradation. Frequently, the systems are modelled as\na network of connected services. Recently, the study of temporal networks has\nemerged as a way to describe and analyze evolving networks. Previous research\nhas explored how software metrics such as size, complexity, and quality are\nrelated to microservice centrality in the architectural network. This study\ninvestigates whether temporal centrality metrics can provide insight into the\nearly detection of architectural degradation by correlating or affecting\nsoftware metrics. We reconstructed the architecture of 7 releases of an OSS\nmicroservice project with 42 services. For every service in every release, we\ncomputed the software and centrality metrics. From one of the latter, we\nderived a new metric, Centrality Change Proneness. We then explored the\ncorrelation between the metrics. We identified 7 size and 5 complexity metrics\nthat have a consistent correlation with centrality, while Centrality Change\nProneness did not affect the software metrics, thus providing yet another\nperspective and an early indicator of microservice architectural degradation.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07690v1", "AI": {"title_translation": "集中度变化倾向：微服务架构退化的早期指标", "tldr": "本研究提出并评估了一种新的指标“集中度变化倾向”，作为微服务架构退化的早期预警信号。", "motivation": "微服务架构的广泛采用需要识别各种模式和反模式以防止架构退化。现有研究已探索软件指标与微服务架构网络中集中度之间的关系，本研究旨在探究时间集中度指标是否能通过关联或影响软件指标来提供架构退化的早期检测。", "method": "研究重建了一个包含42个服务的开源微服务项目7个版本的架构。针对每个版本中的每个服务，计算了软件和集中度指标。从集中度指标中推导出一个新指标——集中度变化倾向，然后探索了这些指标之间的关联。", "result": "研究发现7个规模指标和5个复杂性指标与集中度存在一致的相关性。集中度变化倾向虽然未影响软件指标，但它提供了一个新的视角，并被确认为微服务架构退化的早期指标。", "conclusion": "集中度变化倾向被确认为微服务架构退化的一个早期指标，为理解和预防架构退化提供了新的视角。", "translation": "在过去的十年中，微服务架构的广泛采用要求识别各种模式和反模式，以防止微服务架构退化。通常，系统被建模为连接服务的网络。最近，时间网络的研究已成为描述和分析演化网络的一种方式。先前的研究已经探索了诸如规模、复杂性和质量等软件指标如何与架构网络中的微服务集中度相关联。本研究调查了时间集中度指标是否能通过关联或影响软件指标，为架构退化的早期检测提供见解。我们重建了一个包含42个服务的开源微服务项目7个版本的架构。对于每个版本中的每个服务，我们计算了软件和集中度指标。从后者之一中，我们推导出了一个新指标，即集中度变化倾向。然后，我们探索了这些指标之间的相关性。我们识别出7个规模指标和5个复杂性指标与集中度具有一致的相关性，而集中度变化倾向并未影响软件指标，从而提供了另一个视角和微服务架构退化的早期指标。", "summary": "本研究旨在通过引入“集中度变化倾向”这一新指标，实现微服务架构退化的早期检测。通过分析一个包含42个服务的开源微服务项目7个版本的架构数据，计算了软件和集中度指标。研究发现，7个规模指标和5个复杂性指标与集中度存在一致相关性，并且“集中度变化倾向”作为一个新的时间集中度指标，被证实是微服务架构退化的一个早期预警信号。", "keywords": "微服务架构, 架构退化, 集中度指标, 时间网络, 软件指标", "comments": "本文的创新之处在于提出了“集中度变化倾向”这一新颖的时间集中度指标，并将其作为微服务架构退化的早期预警。这对于维护微服务系统的健康和稳定性具有重要意义，提供了一种前瞻性的架构质量监控方法。"}}
{"id": "2506.06667", "title": "Flood-DamageSense: Multimodal Mamba with Multitask Learning for Building Flood Damage Assessment using SAR Remote Sensing Imagery", "authors": ["Yu-Hsuan Ho", "Ali Mostafavi"], "summary": "Most post-disaster damage classifiers succeed only when destructive forces\nleave clear spectral or structural signatures -- conditions rarely present\nafter inundation. Consequently, existing models perform poorly at identifying\nflood-related building damages. The model presented in this study,\nFlood-DamageSense, addresses this gap as the first deep-learning framework\npurpose-built for building-level flood-damage assessment. The architecture\nfuses pre- and post-event SAR/InSAR scenes with very-high-resolution optical\nbasemaps and an inherent flood-risk layer that encodes long-term exposure\nprobabilities, guiding the network toward plausibly affected structures even\nwhen compositional change is minimal. A multimodal Mamba backbone with a\nsemi-Siamese encoder and task-specific decoders jointly predicts (1) graded\nbuilding-damage states, (2) floodwater extent, and (3) building footprints.\nTraining and evaluation on Hurricane Harvey (2017) imagery from Harris County,\nTexas -- supported by insurance-derived property-damage extents -- show a mean\nF1 improvement of up to 19 percentage points over state-of-the-art baselines,\nwith the largest gains in the frequently misclassified \"minor\" and \"moderate\"\ndamage categories. Ablation studies identify the inherent-risk feature as the\nsingle most significant contributor to this performance boost. An end-to-end\npost-processing pipeline converts pixel-level outputs to actionable,\nbuilding-scale damage maps within minutes of image acquisition. By combining\nrisk-aware modeling with SAR's all-weather capability, Flood-DamageSense\ndelivers faster, finer-grained, and more reliable flood-damage intelligence to\nsupport post-disaster decision-making and resource allocation.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06667v1", "AI": {"title_translation": "Flood-DamageSense：多模态Mamba与多任务学习结合SAR遥感图像用于建筑物洪水损害评估", "tldr": "Flood-DamageSense是一种新型深度学习框架，结合SAR图像、光学地图和固有洪水风险层，通过多模态Mamba骨干网和多任务学习，显著提高了建筑物洪水损害评估的准确性，尤其在轻微和中度损害分类上表现突出。", "motivation": "现有灾后损害分类器在洪水淹没后识别建筑物损害时表现不佳，因为洪水很少留下清晰的光谱或结构特征，导致现有模型难以识别洪水相关的建筑物损害。", "method": "本研究提出了Flood-DamageSense模型，这是一个专门用于建筑物级别洪水损害评估的深度学习框架。该架构融合了灾前和灾后的SAR/InSAR场景、超高分辨率光学底图以及编码长期暴露概率的固有洪水风险层。模型采用多模态Mamba骨干网，带有半Siamese编码器和任务特定解码器，共同预测分级建筑物损害状态、洪水范围和建筑物足迹。", "result": "在2017年飓风哈维（德克萨斯州哈里斯县）的图像上进行训练和评估，并辅以保险衍生的财产损害范围数据，结果显示，相对于最先进的基线模型，F1分数平均提高了19个百分点，其中在经常被错误分类的“轻微”和“中度”损害类别中增益最大。消融研究表明，固有风险特征是性能提升的最重要贡献者。", "conclusion": "Flood-DamageSense通过结合风险感知建模和SAR的全天候能力，能够更快、更精细、更可靠地提供洪水损害信息，以支持灾后决策和资源分配。", "translation": "大多数灾后损害分类器仅在破坏力留下清晰光谱或结构特征时才能成功——而洪水淹没后很少出现这种情况。因此，现有模型在识别洪水相关建筑物损害方面表现不佳。本研究提出的模型Flood-DamageSense解决了这一空白，它是首个专门用于建筑物级别洪水损害评估的深度学习框架。该架构融合了灾前和灾后的SAR/InSAR场景、超高分辨率光学底图以及编码长期暴露概率的固有洪水风险层，即使组成变化很小，也能引导网络识别可能受影响的结构。采用多模态Mamba骨干网，带有半Siamese编码器和任务特定解码器，共同预测(1)分级建筑物损害状态、(2)洪水范围和(3)建筑物足迹。在2017年飓风哈维（德克萨斯州哈里斯县）的图像上进行训练和评估——并辅以保险衍生的财产损害范围——结果显示，相对于最先进的基线模型，F1分数平均提高了19个百分点，其中在经常被错误分类的“轻微”和“中度”损害类别中增益最大。消融研究表明，固有风险特征是性能提升的最重要贡献者。端到端后处理管道可在图像采集后数分钟内将像素级输出转换为可操作的建筑物尺度损害地图。通过结合风险感知建模和SAR的全天候能力，Flood-DamageSense能够更快、更精细、更可靠地提供洪水损害信息，以支持灾后决策和资源分配。", "summary": "Flood-DamageSense是一种创新的深度学习框架，旨在解决现有模型在洪水后建筑物损害评估方面的不足。它整合了灾前/灾后SAR/InSAR图像、高分辨率光学底图和固有洪水风险层，利用多模态Mamba骨干网和多任务学习共同预测建筑物损害等级、洪水范围和建筑物足迹。该模型在飓风哈维的数据集上表现出色，相对于现有技术，F1分数提高了19个百分点，尤其在轻微和中度损害分类上取得了显著进展。其创新点在于引入了固有风险特征，并能快速生成实用的损害地图，为灾后响应提供支持。", "keywords": "洪水损害评估, SAR遥感, 多模态Mamba, 多任务学习, 深度学习", "comments": "这项研究的创新之处在于它是首个专门为建筑物级洪水损害评估设计的深度学习框架，并且创造性地引入了“固有洪水风险层”作为模型输入，这在消融研究中被证明是性能提升的关键因素。结合SAR图像的全天候能力和多任务学习，该模型不仅提高了评估的准确性，特别是对难以分类的轻微和中度损害，而且实现了快速的端到端处理，具有重要的实际应用价值。"}}
{"id": "2506.06634", "title": "GELD: A Unified Neural Model for Efficiently Solving Traveling Salesman Problems Across Different Scales", "authors": ["Yubin Xiao", "Di Wang", "Rui Cao", "Xuan Wu", "Boyang Li", "You Zhou"], "summary": "The Traveling Salesman Problem (TSP) is a well-known combinatorial\noptimization problem with broad real-world applications. Recent advancements in\nneural network-based TSP solvers have shown promising results. Nonetheless,\nthese models often struggle to efficiently solve both small- and large-scale\nTSPs using the same set of pre-trained model parameters, limiting their\npractical utility. To address this issue, we introduce a novel neural TSP\nsolver named GELD, built upon our proposed broad global assessment and refined\nlocal selection framework. Specifically, GELD integrates a lightweight\nGlobal-view Encoder (GE) with a heavyweight Local-view Decoder (LD) to enrich\nembedding representation while accelerating the decision-making process.\nMoreover, GE incorporates a novel low-complexity attention mechanism, allowing\nGELD to achieve low inference latency and scalability to larger-scale TSPs.\nAdditionally, we propose a two-stage training strategy that utilizes training\ninstances of different sizes to bolster GELD's generalization ability.\nExtensive experiments conducted on both synthetic and real-world datasets\ndemonstrate that GELD outperforms seven state-of-the-art models considering\nboth solution quality and inference speed. Furthermore, GELD can be employed as\na post-processing method to significantly elevate the quality of the solutions\nderived by existing neural TSP solvers via spending affordable additional\ncomputing time. Notably, GELD is shown as capable of solving TSPs with up to\n744,710 nodes, first-of-its-kind to solve this large size TSP without relying\non divide-and-conquer strategies to the best of our knowledge.", "comment": "21pages, 4 figures, and 14 tables", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06634v1", "AI": {"title_translation": "GELD：一种高效解决不同规模旅行商问题的统一神经网络模型", "tldr": "GELD是一种新型神经网络TSP求解器，能高效解决从小规模到超大规模的TSP问题，且性能优于现有SOTA模型。", "motivation": "现有的基于神经网络的TSP求解器难以使用同一组预训练模型参数高效地解决小规模和大规模TSP问题，限制了它们的实用性。", "method": "本文提出GELD模型，基于“广域全局评估和精细局部选择”框架。GELD结合轻量级全局视角编码器（GE）和重量级局部视角解码器（LD）以丰富嵌入表示并加速决策过程。GE引入了新颖的低复杂度注意力机制，实现低推理延迟和可扩展性。此外，还提出两阶段训练策略，利用不同大小的训练实例来增强GELD的泛化能力。", "result": "在合成和真实世界数据集上的广泛实验表明，GELD在解决方案质量和推理速度方面均优于七种最先进的模型。GELD还可以作为后处理方法，通过可承受的额外计算时间显著提升现有神经TSP求解器的解决方案质量。GELD能够解决节点数高达744,710的TSP问题，是首个在不依赖分治策略的情况下解决如此大规模TSP问题的方法。", "conclusion": "GELD是一个统一的神经网络模型，能够高效且高质量地解决不同规模的旅行商问题，填补了现有模型在处理大尺度TSP方面的空白，并展现出卓越的性能和实用性。", "translation": "旅行商问题（TSP）是一个著名的组合优化问题，具有广泛的现实世界应用。最近基于神经网络的TSP求解器取得了有希望的成果。然而，这些模型通常难以使用同一组预训练模型参数高效地解决小规模和大规模TSP，这限制了它们的实际效用。为了解决这个问题，我们引入了一种名为GELD的新型神经TSP求解器，它建立在我们提出的广域全局评估和精细局部选择框架之上。具体来说，GELD将一个轻量级的全局视角编码器（GE）与一个重量级的局部视角解码器（LD）相结合，以丰富嵌入表示，同时加速决策过程。此外，GE包含一种新颖的低复杂度注意力机制，使得GELD能够实现低推理延迟并扩展到更大规模的TSP。此外，我们提出了一种两阶段训练策略，利用不同大小的训练实例来增强GELD的泛化能力。在合成和真实世界数据集上进行的广泛实验表明，GELD在解决方案质量和推理速度方面均优于七种最先进的模型。此外，GELD可以作为后处理方法，通过花费可承受的额外计算时间，显著提升现有神经TSP求解器导出的解决方案质量。值得注意的是，据我们所知，GELD能够解决多达744,710个节点的TSP问题，这是首个在不依赖分治策略的情况下解决如此大规模TSP问题的方法。", "summary": "本文提出了一种名为GELD的新型神经网络模型，旨在高效解决不同规模的旅行商问题（TSP）。GELD采用“广域全局评估和精细局部选择”框架，结合轻量级全局视角编码器（GE）和重量级局部视角解码器（LD），并引入低复杂度注意力机制和两阶段训练策略。实验证明，GELD在解决方案质量和推理速度上均优于现有SOTA模型，且能处理节点数高达744,710的超大规模TSP，无需分治策略。", "keywords": "旅行商问题, 神经网络, 组合优化, 统一模型, 大规模TSP", "comments": "GELD的创新之处在于其统一的架构能够同时处理小规模和超大规模TSP，解决了现有模型的局限性。其低复杂度注意力机制和两阶段训练策略是其实现高效和泛化能力的关键。能够解决744,710个节点TSP且不依赖分治策略是其显著的突破，极大地扩展了神经TSP求解器的实际应用范围。"}}
{"id": "2506.07869", "title": "Hybrid Beamforming Optimization for MIMO ISAC Exploiting Prior Information: A PCRB-based Approach", "authors": ["Yizhuo Wang", "Shuowen Zhang"], "summary": "This paper considers a multiple-input multiple-output (MIMO) integrated\nsensing and communication (ISAC) system, where a multi-antenna base station\n(BS) with transceiver hybrid analog-digital arrays transmits dual-functional\nsignals to communicate with a multi-antenna user and simultaneously sense the\nunknown and random location information of a target based on the reflected echo\nsignals and the prior distribution information on the target's location. Under\ntransceiver hybrid arrays, we characterize the sensing performance by deriving\nthe posterior Cram\\'{e}r-Rao bound (PCRB) of the mean-squared error which is a\nfunction of the transmit hybrid beamforming and receive analog beamforming. We\nstudy joint transmit hybrid beamforming and receive analog beamforming\noptimization to minimize the PCRB subject to a communication rate requirement.\nWe first consider a sensing-only system and derive the optimal solution to each\nelement in the transmit/receive analog beamforming matrices that minimizes the\nPCRB in closed form. Then, we develop an alternating optimization (AO) based\nalgorithm. Next, we study a narrowband MIMO ISAC system and devise an efficient\nAO-based hybrid beamforming algorithm by leveraging weighted minimum\nmean-squared error and feasible point pursuit successive convex approximation\nmethods. Furthermore, we extend the results for narrowband systems to a MIMO\northogonal frequency-division multiplexing (OFDM) ISAC system. Numerical\nresults validate the effectiveness of our proposed hybrid beamforming designs.\nIt is revealed that the number of receive RF chains has more significant impact\non the sensing performance than its transmit counterpart. Under a given budget\non the total number of transmit/receive RF chains at the BS, the optimal number\nof transmit RF chains increases as the communication rate target increases due\nto the non-trivial PCRB-rate trade-off.", "comment": "submitted for possible journal publication", "cate": "cs.IT", "url": "http://arxiv.org/abs/2506.07869v1", "AI": {"title_translation": "利用先验信息的多输入多输出综合感知与通信混合波束成形优化：一种基于PCRB的方法", "tldr": "本文提出了一种基于PCRB的混合波束成形优化方法，用于MIMO ISAC系统，旨在最小化感知误差并满足通信速率要求，同时揭示了RF链的影响和性能权衡。", "motivation": "本文旨在为多输入多输出（MIMO）综合感知与通信（ISAC）系统优化混合波束成形，以在满足通信速率要求的同时，提高感知性能（最小化后验克拉美-劳界PCRB），特别是在目标位置未知但有先验分布信息的情况下。", "method": "该研究通过推导均方误差的后验克拉美-劳界（PCRB）来表征感知性能。它研究了联合发射混合波束成形和接收模拟波束成形优化，以在满足通信速率要求的情况下最小化PCRB。首先，针对纯感知系统，推导了最小化PCRB的发射/接收模拟波束成形矩阵中每个元素的闭式最优解。然后，开发了一种基于交替优化（AO）的算法。接着，针对窄带MIMO ISAC系统，通过利用加权最小均方误差和可行点追踪逐次凸逼近方法，设计了一种高效的基于AO的混合波束成形算法。最后，将窄带系统的结果扩展到MIMO正交频分复用（OFDM）ISAC系统。", "result": "数值结果验证了所提出混合波束成形设计的有效性。研究发现，接收射频链的数量对感知性能的影响比发射射频链更显著。在基站总收发射频链预算给定的情况下，由于非平凡的PCRB-速率权衡，最优发射射频链数量会随着通信速率目标的增加而增加。", "conclusion": "本文提出的混合波束成形优化方法能有效提升MIMO ISAC系统的感知性能，同时兼顾通信速率要求，并揭示了接收射频链的关键作用以及PCRB-速率之间的权衡关系。", "translation": "本文考虑了一个多输入多输出（MIMO）综合感知与通信（ISAC）系统，其中一个带有收发混合模拟-数字阵列的多天线基站（BS）发送双功能信号，与多天线用户进行通信，并同时根据反射回波信号和目标位置的先验分布信息感知目标的未知随机位置信息。在收发混合阵列下，我们通过推导均方误差的后验克拉美-劳界（PCRB）来表征感知性能，该PCRB是发射混合波束成形和接收模拟波束成形的函数。我们研究了联合发射混合波束成形和接收模拟波束成形优化，以在满足通信速率要求的情况下最小化PCRB。我们首先考虑一个纯感知系统，并推导出最小化PCRB的发射/接收模拟波束成形矩阵中每个元素的闭式最优解。然后，我们开发了一种基于交替优化（AO）的算法。接下来，我们研究了一个窄带MIMO ISAC系统，并通过利用加权最小均方误差和可行点追踪逐次凸逼近方法，设计了一种高效的基于AO的混合波束成形算法。此外，我们将窄带系统的结果扩展到MIMO正交频分复用（OFDM）ISAC系统。数值结果验证了我们提出的混合波束成形设计的有效性。结果表明，接收射频链的数量对感知性能的影响比发射射频链更显著。在给定基站总收发射频链预算的情况下，随着通信速率目标的增加，最优发射射频链数量会增加，这归因于非平凡的PCRB-速率权衡。", "summary": "本文提出了一种基于后验克拉美-劳界（PCRB）的混合波束成形优化方法，用于多输入多输出（MIMO）综合感知与通信（ISAC）系统。该方法联合优化发射混合波束成形和接收模拟波束成形，以在满足通信速率要求的同时最小化感知性能的PCRB。论文针对纯感知场景推导了闭式解，并为窄带和OFDM ISAC系统开发了基于交替优化（AO）的算法。数值结果验证了所提设计的有效性，并揭示了接收射频链对感知性能的影响大于发射射频链，且在给定射频链预算下，最优发射射频链数量会随通信速率目标的增加而增加，这归因于非平凡的PCRB-速率权衡。", "keywords": "MIMO ISAC, 混合波束成形, PCRB, 交替优化, 射频链", "comments": "该论文为MIMO ISAC系统提供了一个基于PCRB的混合波束成形优化框架，对ISAC的实际部署具有重要意义。对射频链影响和PCRB-速率权衡的分析为系统设计提供了宝贵的见解。交替优化和凸逼近方法的使用使得所提出的解决方案具有可操作性。"}}
{"id": "2506.07139", "title": "FPGA-Based Material Testing Machine Controller", "authors": ["Arev Hambardzumyan", "Rafayel Ghasabyan", "Vahagn Tamazyan"], "summary": "In the realm of contemporary materials testing, the demand for scalability,\nadaptability, parallelism, and speed has surged due to the proliferation of\ndiverse materials and testing standards. Traditional controller-based systems\noften fall short in meeting these requirements, resulting in adaptability and\nprocessing speed limitations. Conversely, FPGA-based controllers present a\nmultifaceted, high-performance solution. Key advantages of FPGA-based\ncontrollers in materials testing encompass reconfiguration capabilities for\ncost-effective adaptation to evolving materials and standards. FPGAs also\nenable the integration of parallel control and data acquisition circuits, vital\nfor multichannel test equipment demanding simultaneous, independent operation\nof multiple control channels.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07139v1", "AI": {"title_translation": "基于FPGA的材料测试机控制器", "tldr": "传统的材料测试控制器在可扩展性、适应性、并行性和速度方面存在局限，FPGA控制器提供了一种高性能解决方案，具有可重构性和并行控制能力，适用于多通道测试设备。", "motivation": "在当代材料测试领域，由于材料和测试标准的日益多样化，对可扩展性、适应性、并行性和速度的需求激增。传统的基于控制器的系统往往难以满足这些要求，导致适应性和处理速度受限。", "method": "本研究提出并采用FPGA（现场可编程门阵列）作为材料测试机的控制器，以解决传统控制器的局限性。", "result": "基于FPGA的控制器具有可重构能力，能够经济高效地适应不断变化的材料和标准；同时，FPGA还能够集成并行控制和数据采集电路，这对于需要多个控制通道同时独立运行的多通道测试设备至关重要。", "conclusion": "基于FPGA的控制器为材料测试提供了一种多功能、高性能的解决方案，能够克服传统系统在适应性、并行性和速度方面的局限性。", "translation": "在当代材料测试领域，由于材料和测试标准的日益多样化，对可扩展性、适应性、并行性和速度的需求激增。传统的基于控制器的系统往往难以满足这些要求，导致适应性和处理速度受限。相比之下，基于FPGA的控制器提供了一种多功能、高性能的解决方案。基于FPGA的控制器在材料测试中的主要优势包括：可重构能力，能够经济高效地适应不断变化的材料和标准；FPGA还能够集成并行控制和数据采集电路，这对于需要多个控制通道同时独立运行的多通道测试设备至关重要。", "summary": "鉴于现代材料测试对可扩展性、适应性、并行性和速度的需求，本研究提出了一种基于FPGA的材料测试机控制器。与传统控制器相比，FPGA控制器能够提供可重构能力以适应不断变化的材料和标准，并支持集成并行控制和数据采集电路，从而满足多通道测试设备对同时独立操作的需求，提供了一种高性能的解决方案。", "keywords": "FPGA, 材料测试, 控制器, 并行控制, 可重构性", "comments": "本文指出FPGA在材料测试控制器领域的应用，其创新性在于利用FPGA的可重构性和并行处理能力，解决了传统控制器在可扩展性、适应性和速度上的瓶颈，对于需要处理多样化材料和多通道测试的现代测试设备具有重要意义。"}}
{"id": "2506.06337", "title": "Optimized Local Updates in Federated Learning via Reinforcement Learning", "authors": ["Ali Murad", "Bo Hui", "Wei-Shinn Ku"], "summary": "Federated Learning (FL) is a distributed framework for collaborative model\ntraining over large-scale distributed data, enabling higher performance while\nmaintaining client data privacy. However, the nature of model aggregation at\nthe centralized server can result in a performance drop in the presence of\nnon-IID data across different clients. We remark that training a client locally\non more data than necessary does not benefit the overall performance of all\nclients. In this paper, we devise a novel framework that leverages a Deep\nReinforcement Learning (DRL) agent to select an optimized amount of data\nnecessary to train a client model without oversharing information with the\nserver. Starting without awareness of the client's performance, the DRL agent\nutilizes the change in training loss as a reward signal and learns to optimize\nthe amount of training data necessary for improving the client's performance.\nSpecifically, after each aggregation round, the DRL algorithm considers the\nlocal performance as the current state and outputs the optimized weights for\neach class, in the training data, to be used during the next round of local\ntraining. In doing so, the agent learns a policy that creates an optimized\npartition of the local training dataset during the FL rounds. After FL, the\nclient utilizes the entire local training dataset to further enhance its\nperformance on its own data distribution, mitigating the non-IID effects of\naggregation. Through extensive experiments, we demonstrate that training FL\nclients through our algorithm results in superior performance on multiple\nbenchmark datasets and FL frameworks. Our code is available at\nhttps://github.com/amuraddd/optimized_client_training.git.", "comment": "This paper is accepted at IEEE IJCNN 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06337v1", "AI": {"title_translation": "通过强化学习优化联邦学习中的本地更新", "tldr": "本文提出了一种利用深度强化学习（DRL）代理来优化联邦学习中客户端本地更新的数据量，以提升非独立同分布（non-IID）数据下的性能并避免信息过载。", "motivation": "联邦学习在非独立同分布（non-IID）数据存在时，由于中心化服务器的模型聚合，会导致性能下降。此外，客户端训练超出必要的数据量并不能提升整体性能，反而可能导致信息过度共享。", "method": "本文提出了一种新颖的框架，利用深度强化学习（DRL）代理来选择客户端模型训练所需的最优数据量，避免信息过度共享。DRL代理以训练损失的变化作为奖励信号，并根据客户端的本地性能（作为当前状态）输出每个类别在训练数据中的优化权重，用于下一轮本地训练。该代理学习一个策略，在联邦学习轮次中创建本地训练数据集的优化分区。在联邦学习结束后，客户端利用整个本地训练数据集进一步提升其在自身数据分布上的性能，从而缓解非独立同分布聚合的影响。", "result": "通过广泛的实验，本文证明了使用该算法训练联邦学习客户端在多个基准数据集和联邦学习框架上均能获得卓越的性能。", "conclusion": "本文提出的基于深度强化学习的优化本地更新方法，能够有效解决联邦学习中非独立同分布数据导致的性能下降问题，通过智能选择训练数据量，提升了整体性能并缓解了信息过度共享。", "translation": "联邦学习（FL）是一种分布式框架，用于在大规模分布式数据上进行协作模型训练，在保持客户端数据隐私的同时实现更高的性能。然而，在不同客户端之间存在非独立同分布（non-IID）数据的情况下，中心化服务器上的模型聚合性质可能导致性能下降。我们指出，客户端在超出必要的数据量上进行本地训练并不能提升所有客户端的整体性能。在本文中，我们设计了一个新颖的框架，该框架利用深度强化学习（DRL）代理来选择训练客户端模型所需的最优数据量，而不会与服务器过度共享信息。DRL代理最初不了解客户端的性能，它利用训练损失的变化作为奖励信号，并学习优化训练数据量，以提高客户端的性能。具体来说，在每次聚合轮次之后，DRL算法将本地性能视为当前状态，并输出训练数据中每个类别的优化权重，以用于下一轮本地训练。通过这样做，代理学习了一个策略，在联邦学习轮次中创建本地训练数据集的优化分区。在联邦学习之后，客户端利用整个本地训练数据集进一步提升其在自身数据分布上的性能，从而缓解聚合的非独立同分布效应。通过广泛的实验，我们证明通过我们的算法训练联邦学习客户端在多个基准数据集和联邦学习框架上均能获得卓越的性能。我们的代码可在https://github.com/amuraddd/optimized_client_training.git获取。", "summary": "本文针对联邦学习在非独立同分布（non-IID）数据下性能下降的问题，提出了一种创新的解决方案。该方案引入了一个深度强化学习（DRL）代理，用于智能地选择客户端本地训练所需的最优数据量，以避免信息过度共享并提升模型性能。DRL代理通过监控训练损失变化来优化数据选择策略，并在联邦学习聚合后利用整个本地数据集进一步优化客户端自身性能，有效缓解了非IID效应。实验结果表明，该方法在多个基准数据集和FL框架上均实现了卓越的性能。", "keywords": "联邦学习, 强化学习, 本地更新, 非独立同分布数据, 数据隐私", "comments": "该论文通过引入深度强化学习来优化联邦学习中的本地数据选择，解决了非独立同分布数据下性能下降的核心问题。其创新点在于将DRL应用于动态管理客户端的本地训练数据，通过优化数据分区来提高模型性能和隐私保护，这对于实际部署联邦学习具有重要意义。该方法通过避免不必要的信息共享，有效地提升了联邦学习的效率和准确性。"}}
{"id": "2506.06341", "title": "NR4DER: Neural Re-ranking for Diversified Exercise Recommendation", "authors": ["Xinghe Cheng", "Xufang Zhou", "Liangda Fang", "Chaobo He", "Yuyu Zhou", "Weiqi Luo", "Zhiguo Gong", "Quanlong Guan"], "summary": "With the widespread adoption of online education platforms, an increasing\nnumber of students are gaining new knowledge through Massive Open Online\nCourses (MOOCs). Exercise recommendation have made strides toward improving\nstudent learning outcomes. However, existing methods not only struggle with\nhigh dropout rates but also fail to match the diverse learning pace of\nstudents. They frequently face difficulties in adjusting to inactive students'\nlearning patterns and in accommodating individualized learning paces, resulting\nin limited accuracy and diversity in recommendations. To tackle these\nchallenges, we propose Neural Re-ranking for Diversified Exercise\nRecommendation (in short, NR4DER). NR4DER first leverages the mLSTM model to\nimprove the effectiveness of the exercise filter module. It then employs a\nsequence enhancement method to enhance the representation of inactive students,\naccurately matches students with exercises of appropriate difficulty. Finally,\nit utilizes neural re-ranking to generate diverse recommendation lists based on\nindividual students' learning histories. Extensive experimental results\nindicate that NR4DER significantly outperforms existing methods across multiple\nreal-world datasets and effectively caters to the diverse learning pace of\nstudents.", "comment": "accepted for presentation at the SIGIR 2025 Full Papers track", "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06341v1", "AI": {"title_translation": "NR4DER: 神经网络重排序用于多样化习题推荐", "tldr": "NR4DER模型通过结合mLSTM、序列增强和神经网络重排序，解决了在线教育中习题推荐的准确性和多样性不足问题，尤其针对学习节奏多样和不活跃的学生。", "motivation": "现有习题推荐方法在在线教育中面临高辍学率、难以匹配学生多样化学习节奏、难以适应不活跃学生学习模式以及推荐准确性和多样性有限等挑战。", "method": "NR4DER模型首先利用mLSTM模型提升习题过滤模块的有效性；其次，采用序列增强方法增强不活跃学生的表示，以准确匹配学生与适当难度的习题；最后，利用神经网络重排序根据学生的学习历史生成多样化的推荐列表。", "result": "广泛的实验结果表明，NR4DER在多个真实世界数据集上显著优于现有方法，并能有效满足学生多样化的学习节奏。", "conclusion": "NR4DER模型通过其多阶段方法有效地解决了在线教育中习题推荐的准确性和多样性问题，特别是在处理学生学习节奏多样性方面表现出色。", "translation": "随着在线教育平台的广泛普及，越来越多的学生通过大规模开放在线课程（MOOCs）获取新知识。习题推荐在改善学生学习成果方面取得了进展。然而，现有方法不仅难以解决高辍学率问题，也未能匹配学生多样化的学习节奏。它们经常在适应不活跃学生的学习模式和适应个性化学习节奏方面面临困难，导致推荐的准确性和多样性有限。为了解决这些挑战，我们提出了用于多样化习题推荐的神经网络重排序（简称NR4DER）。NR4DER首先利用mLSTM模型提高习题过滤模块的有效性。然后，它采用序列增强方法增强不活跃学生的表示，准确匹配学生与适当难度的习题。最后，它利用神经网络重排序根据学生个人学习历史生成多样化的推荐列表。广泛的实验结果表明，NR4DER在多个真实世界数据集上显著优于现有方法，并能有效满足学生多样化的学习节奏。", "summary": "本论文提出了一种名为NR4DER的神经网络重排序模型，旨在解决在线教育中习题推荐的准确性和多样性不足问题。针对现有方法难以匹配学生多样化学习节奏和适应不活跃学生学习模式的痛点，NR4DER通过结合mLSTM进行习题过滤、序列增强来表征不活跃学生以及神经网络重排序生成多样化推荐列表。实验证明，NR4DER在真实数据集上表现优异，并有效提升了推荐的准确性和多样性，适应了学生不同的学习节奏。", "keywords": "习题推荐, 神经网络重排序, 在线教育, 多样性推荐, mLSTM", "comments": "NR4DER的创新点在于其多阶段的推荐框架，特别是引入了针对不活跃学生的序列增强和用于多样性推荐的神经网络重排序，这对于提升在线教育平台的学习体验和降低辍学率具有重要意义。"}}
{"id": "2506.07077", "title": "Dual-Priv Pruning : Efficient Differential Private Fine-Tuning in Multimodal Large Language Models", "authors": ["Qianshan Wei", "Jiaqi Li", "Zihan You", "Yi Zhan", "Kecen Li", "Jialin Wu", "Xinfeng Li Hengjun Liu", "Yi Yu", "Bin Cao", "Yiwen Xu", "Yang Liu", "Guilin Qi"], "summary": "Differential Privacy (DP) is a widely adopted technique, valued for its\neffectiveness in protecting the privacy of task-specific datasets, making it a\ncritical tool for large language models. However, its effectiveness in\nMultimodal Large Language Models (MLLMs) remains uncertain. Applying\nDifferential Privacy (DP) inherently introduces substantial computation\noverhead, a concern particularly relevant for MLLMs which process extensive\ntextual and visual data. Furthermore, a critical challenge of DP is that the\ninjected noise, necessary for privacy, scales with parameter dimensionality,\nleading to pronounced model degradation; This trade-off between privacy and\nutility complicates the application of Differential Privacy (DP) to complex\narchitectures like MLLMs. To address these, we propose Dual-Priv Pruning, a\nframework that employs two complementary pruning mechanisms for DP fine-tuning\nin MLLMs: (i) visual token pruning to reduce input dimensionality by removing\nredundant visual information, and (ii) gradient-update pruning during the DP\noptimization process. This second mechanism selectively prunes parameter\nupdates based on the magnitude of noisy gradients, aiming to mitigate noise\nimpact and improve utility. Experiments demonstrate that our approach achieves\ncompetitive results with minimal performance degradation. In terms of\ncomputational efficiency, our approach consistently utilizes less memory than\nstandard DP-SGD. While requiring only 1.74% more memory than zeroth-order\nmethods which suffer from severe performance issues on A100 GPUs, our method\ndemonstrates leading memory efficiency on H20 GPUs. To the best of our\nknowledge, we are the first to explore DP fine-tuning in MLLMs. Our code is\ncoming soon.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07077v1", "AI": {"title_translation": "双隐私剪枝：多模态大型语言模型中高效的差分隐私微调", "tldr": "Dual-Priv Pruning引入了两种剪枝机制（视觉token和梯度更新），以实现在多模态大型语言模型（MLLM）中高效且隐私的微调，同时减轻噪声影响和计算开销。", "motivation": "差分隐私（DP）在保护大型语言模型隐私方面有效，但其在多模态大型语言模型（MLLM）中的有效性仍不确定。将DP应用于MLLM会引入大量的计算开销，并且由于隐私所需的噪声会随参数维度增加而放大，导致模型性能显著下降，使得DP难以应用于复杂的MLLM架构。", "method": "本文提出了Dual-Priv Pruning，一个用于MLLM中DP微调的框架。它采用了两种互补的剪枝机制：(i) 视觉token剪枝，通过去除冗余视觉信息来降低输入维度；(ii) DP优化过程中的梯度更新剪枝，该机制根据噪声梯度的大小选择性地剪枝参数更新，旨在减轻噪声影响并提高效用。", "result": "实验表明，Dual-Priv Pruning在性能下降最小的情况下取得了有竞争力的结果。它始终比标准DP-SGD占用更少的内存，并在H20 GPU上展现出领先的内存效率，仅比零阶方法多占用1.74%的内存（零阶方法在A100 GPU上存在严重的性能问题）。", "conclusion": "Dual-Priv Pruning通过提高计算效率和效用，同时保持有竞争力的性能，有效地解决了将差分隐私应用于多模态大型语言模型的挑战，并且是首个探索MLLM中DP微调的工作。", "translation": "差分隐私（DP）是一种广泛采用的技术，因其在保护任务特定数据集隐私方面的有效性而受到重视，使其成为大型语言模型的关键工具。然而，其在多模态大型语言模型（MLLM）中的有效性仍不确定。应用差分隐私（DP）本身会引入大量的计算开销，这对于处理大量文本和视觉数据的MLLM来说尤其重要。此外，DP的一个关键挑战是，隐私所需的注入噪声会随着参数维度的增加而按比例放大，导致模型性能显著下降；这种隐私与效用之间的权衡使得差分隐私（DP）难以应用于MLLM等复杂架构。为了解决这些问题，我们提出了双隐私剪枝（Dual-Priv Pruning），一个在MLLM中采用两种互补剪枝机制进行DP微调的框架：(i) 视觉token剪枝，通过去除冗余视觉信息来降低输入维度；(ii) DP优化过程中的梯度更新剪枝。后一种机制根据噪声梯度的大小选择性地剪枝参数更新，旨在减轻噪声影响并提高效用。实验表明，我们的方法在性能下降最小的情况下取得了有竞争力的结果。在计算效率方面，我们的方法始终比标准DP-SGD占用更少的内存。虽然比零阶方法仅多占用1.74%的内存（零阶方法在A100 GPU上存在严重的性能问题），但我们的方法在H20 GPU上展现出领先的内存效率。据我们所知，我们是第一个探索MLLM中DP微调的研究。我们的代码即将发布。", "summary": "本文介绍了Dual-Priv Pruning，一个旨在利用差分隐私（DP）对多模态大型语言模型（MLLM）进行高效且隐私微调的新颖框架。该方法认识到DP在MLLM中面临的挑战——即高计算开销和噪声导致的显著效用下降——提出了两种剪枝策略：视觉token剪枝以降低输入维度，以及梯度更新剪枝以减轻优化过程中的噪声影响。实验结果表明，Dual-Priv Pruning在性能下降最小的情况下取得了有竞争力的表现，与标准DP-SGD相比显著提高了内存效率，并且是首次探索MLLM中DP微调的方法。", "keywords": "差分隐私, 多模态大型语言模型, 剪枝, 微调, 隐私保护AI", "comments": "这篇论文解决了将差分隐私应用于多模态大型语言模型的一个关键挑战，这是一个新颖且重要的领域。所提出的Dual-Priv Pruning框架及其两种互补的剪枝机制（视觉token和梯度更新）是一种创新的方法，旨在减轻高维模型中DP常见的计算开销和效用下降。论文声称是第一个探索MLLM中DP微调的工作，这突显了其开创性及其对隐私保护AI发展的潜在影响。"}}
{"id": "2506.07293", "title": "Very Large-scale Multi-Robot Task Allocation in Challenging Environments via Robot Redistribution", "authors": ["Seabin Lee", "Joonyeol Sim", "Changjoo Nam"], "summary": "We consider the Multi-Robot Task Allocation (MRTA) problem that aims to\noptimize an assignment of multiple robots to multiple tasks in challenging\nenvironments which are with densely populated obstacles and narrow passages. In\nsuch environments, conventional methods optimizing the sum-of-cost are often\nineffective because the conflicts between robots incur additional costs (e.g.,\ncollision avoidance, waiting). Also, an allocation that does not incorporate\nthe actual robot paths could cause deadlocks, which significantly degrade the\ncollective performance of the robots.\n  We propose a scalable MRTA method that considers the paths of the robots to\navoid collisions and deadlocks which result in a fast completion of all tasks\n(i.e., minimizing the \\textit{makespan}). To incorporate robot paths into task\nallocation, the proposed method constructs a roadmap using a Generalized\nVoronoi Diagram. The method partitions the roadmap into several components to\nknow how to redistribute robots to achieve all tasks with less conflicts\nbetween the robots. In the redistribution process, robots are transferred to\ntheir final destinations according to a push-pop mechanism with the first-in\nfirst-out principle. From the extensive experiments, we show that our method\ncan handle instances with hundreds of robots in dense clutter while competitors\nare unable to compute a solution within a time limit.", "comment": "15 pages", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07293v1", "AI": {"title_translation": "恶劣环境下基于机器人重新分配的超大规模多机器人任务分配", "tldr": "提出一种可扩展的多机器人任务分配方法，通过构建路图和机器人重新分配，在复杂环境中避免冲突和死锁，实现大规模机器人任务的快速完成。", "motivation": "传统的多机器人任务分配方法在障碍物密集和狭窄通道的复杂环境中效率低下，因为机器人冲突会产生额外成本并导致死锁，严重影响集体性能。", "method": "提出一种可扩展的多机器人任务分配（MRTA）方法，该方法考虑机器人路径以避免碰撞和死锁，从而最小化完工时间。具体地，该方法使用广义Voronoi图构建路图，并将路图划分为多个组件以指导机器人重新分配，以减少冲突。机器人重新分配过程采用遵循先进先出原则的推拉机制。", "result": "实验表明，该方法能够处理数百个机器人在密集杂乱环境中的实例，而竞争方法无法在规定时间内计算出解决方案。", "conclusion": "该研究成功开发了一种高效且可扩展的多机器人任务分配方法，通过集成路径规划和智能机器人重新分配策略，显著提高了在复杂大规模环境中的任务完成效率和鲁棒性。", "translation": "我们考虑多机器人任务分配（MRTA）问题，旨在优化在障碍物密集和狭窄通道等挑战性环境中多个机器人对多个任务的分配。在这种环境中，优化成本总和的传统方法通常无效，因为机器人之间的冲突会产生额外成本（例如，避碰、等待）。此外，不包含实际机器人路径的分配可能会导致死锁，从而显著降低机器人的集体性能。\n我们提出了一种可扩展的MRTA方法，该方法考虑机器人的路径以避免碰撞和死锁，从而实现所有任务的快速完成（即最小化完工时间）。为了将机器人路径纳入任务分配，所提出的方法使用广义Voronoi图构建路图。该方法将路图划分为几个组件，以了解如何重新分配机器人，从而以更少的机器人之间冲突来完成所有任务。在重新分配过程中，机器人根据具有先进先出原则的推拉机制转移到它们的最终目的地。通过广泛的实验，我们表明我们的方法可以处理数百个机器人在密集杂乱环境中的实例，而竞争对手无法在规定时间内计算出解决方案。", "summary": "这项研究提出了一种用于大规模多机器人任务分配（MRTA）的新方法，专门针对障碍物密集和狭窄通道的复杂环境。该方法通过构建基于广义Voronoi图的路图，并将其划分为多个组件来指导机器人重新分配，从而在考虑机器人路径的同时避免碰撞和死锁，旨在最小化任务完工时间。实验证明，该方法在处理数百个机器人的密集杂乱场景时，比现有方法更有效和可扩展。", "keywords": "多机器人任务分配, 机器人重新分配, 广义Voronoi图, 完工时间最小化, 复杂环境", "comments": "该论文的创新点在于将机器人路径规划（通过广义Voronoi图构建路图）与任务分配深度结合，并通过一种新颖的机器人重新分配机制（推拉机制）来解决大规模、高冲突环境下的MRTA问题。其在处理数百个机器人的密集环境中的表现，突出了其在可扩展性和鲁棒性方面的显著优势，对于实际应用具有重要意义。"}}
{"id": "2506.06659", "title": "DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning", "authors": ["Wenhao Yao", "Zhenxin Li", "Shiyi Lan", "Zi Wang", "Xinglong Sun", "Jose M. Alvarez", "Zuxuan Wu"], "summary": "In complex driving environments, autonomous vehicles must navigate safely.\nRelying on a single predicted path, as in regression-based approaches, usually\ndoes not explicitly assess the safety of the predicted trajectory.\nSelection-based methods address this by generating and scoring multiple\ntrajectory candidates and predicting the safety score for each, but face\noptimization challenges in precisely selecting the best option from thousands\nof possibilities and distinguishing subtle but safety-critical differences,\nespecially in rare or underrepresented scenarios. We propose DriveSuprim to\novercome these challenges and advance the selection-based paradigm through a\ncoarse-to-fine paradigm for progressive candidate filtering, a rotation-based\naugmentation method to improve robustness in out-of-distribution scenarios, and\na self-distillation framework to stabilize training. DriveSuprim achieves\nstate-of-the-art performance, reaching 93.5% PDMS in NAVSIM v1 and 87.1% EPDMS\nin NAVSIM v2 without extra data, demonstrating superior safetycritical\ncapabilities, including collision avoidance and compliance with rules, while\nmaintaining high trajectory quality in various driving scenarios.", "comment": "15 pages, 6 figures", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06659v1", "AI": {"title_translation": "DriveSuprim: 面向端到端规划的精确轨迹选择", "tldr": "DriveSuprim通过采用粗到细的过滤、基于旋转的增强和自蒸馏框架，提高了自动驾驶车辆轨迹选择的精确性和安全性。", "motivation": "回归方法无法明确评估预测轨迹的安全性；现有选择方法在精确选择最佳轨迹和区分细微但关键的安全差异方面面临优化挑战，尤其是在罕见或代表性不足的场景中。", "method": "DriveSuprim提出了一种粗到细的渐进式候选过滤范式，一种基于旋转的增强方法以提高分布外场景的鲁棒性，以及一个自蒸馏框架来稳定训练。", "result": "DriveSuprim在NAVSIM v1中达到93.5%的PDMS，在NAVSIM v2中达到87.1%的EPDMS，无需额外数据，实现了最先进的性能，并展示了卓越的安全关键能力（包括避免碰撞和遵守规则），同时在各种驾驶场景中保持高轨迹质量。", "conclusion": "DriveSuprim通过解决现有选择方法的挑战，显著提升了自动驾驶车辆的轨迹选择精度和安全关键能力，达到了最先进的性能。", "translation": "在复杂的驾驶环境中，自动驾驶车辆必须安全导航。像基于回归的方法那样，依赖单一的预测路径通常不会明确评估预测轨迹的安全性。基于选择的方法通过生成和评估多个候选轨迹并预测每个轨迹的安全分数来解决这个问题，但面临着从数千种可能性中精确选择最佳选项以及区分细微但对安全至关重要的差异的优化挑战，尤其是在罕见或代表性不足的场景中。我们提出了DriveSuprim来克服这些挑战，并通过渐进式候选过滤的粗到细范式、提高分布外场景鲁棒性的基于旋转的增强方法以及稳定训练的自蒸馏框架来推进基于选择的范式。DriveSuprim实现了最先进的性能，在NAVSIM v1中达到93.5%的PDMS，在NAVSIM v2中达到87.1%的EPDMS，无需额外数据，展示了卓越的安全关键能力，包括避免碰撞和遵守规则，同时在各种驾驶场景中保持高轨迹质量。", "summary": "DriveSuprim是一种新的方法，旨在提高自动驾驶车辆在复杂环境中的轨迹选择精度和安全性。它通过结合粗到细的过滤、基于旋转的数据增强和自蒸馏框架来解决现有选择方法的不足。该方法在NAVSIM基准测试中表现出领先的性能，显著提升了碰撞避免和规则遵守等安全关键能力。", "keywords": "轨迹选择, 端到端规划, 自动驾驶, 安全性, DriveSuprim", "comments": "DriveSuprim通过引入多方面的创新（粗到细过滤、旋转增强、自蒸馏）有效地解决了选择式规划在复杂和罕见场景中的精度和鲁棒性问题。其在SOTA性能上的表现，尤其是在安全关键能力上的提升，显示了该方法在自动驾驶领域的重要性和实用性。"}}
{"id": "2506.07695", "title": "Towards a Small Language Model Lifecycle Framework", "authors": ["Parsa Miraghaei", "Sergio Moreschini", "Antti Kolehmainen", "David Hästbacka"], "summary": "Background: The growing demand for efficient and deployable language models\nhas led to increased interest in Small Language Models (SLMs). However,\nexisting research remains fragmented, lacking a unified lifecycle perspective.\n  Objective: This study aims to define a comprehensive lifecycle framework for\nSLMs by synthesizing insights from academic literature and practitioner\nsources.\n  Method: We conducted a comprehensive survey of 36 works, analyzing and\ncategorizing lifecycle-relevant techniques.\n  Results: We propose a modular lifecycle model structured into main, optional,\nand cross-cutting components. The model captures key interconnections across\nstages, supporting method reuse, co-adaptation, and lifecycle-awareness.\n  Conclusion: Our framework provides a coherent foundation for developing and\nmaintaining SLMs, bridging theory and practice, and guiding future research and\ntool development.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07695v1", "AI": {"title_translation": "构建小型语言模型生命周期框架", "tldr": "该研究提出了一个模块化的SLM生命周期框架，旨在统一现有研究并指导SLM的开发和维护。", "motivation": "现有的小型语言模型（SLMs）研究分散，缺乏统一的生命周期视角，而市场对高效可部署语言模型的需求日益增长。", "method": "通过对36篇文献进行全面调查，分析并分类了与生命周期相关的技术。", "result": "提出了一个模块化的生命周期模型，该模型由主要、可选和跨领域组件构成，并捕捉了各阶段之间的关键互联，支持方法重用、协同适应和生命周期感知。", "conclusion": "该框架为SLM的开发和维护提供了连贯的基础，弥合了理论与实践之间的鸿沟，并指导了未来的研究和工具开发。", "translation": "背景：对高效、可部署语言模型日益增长的需求，使得人们对小型语言模型（SLMs）的兴趣日益增加。然而，现有研究仍然碎片化，缺乏统一的生命周期视角。\n目标：本研究旨在通过综合学术文献和实践来源的见解，为SLMs定义一个全面的生命周期框架。\n方法：我们对36项工作进行了全面调查，分析并分类了与生命周期相关的技术。\n结果：我们提出了一个模块化的生命周期模型，该模型由主要、可选和跨领域组件构成。该模型捕捉了各阶段之间的关键互联，支持方法重用、协同适应和生命周期感知。\n结论：我们的框架为开发和维护SLMs提供了连贯的基础，弥合了理论与实践之间的鸿沟，并指导了未来的研究和工具开发。", "summary": "本研究针对小型语言模型（SLMs）研究碎片化的问题，通过对36篇文献的综合调查，提出了一个模块化的SLM生命周期框架。该框架旨在统一SLM的开发和维护过程，促进方法重用和协同适应，从而弥合理论与实践之间的差距，并为未来的研究和工具开发提供指导。", "keywords": "小型语言模型, 生命周期框架, 文献调查, 模块化模型, 理论与实践", "comments": "这项工作通过提出一个统一的SLM生命周期框架，解决了当前SLM研究分散的痛点。其创新之处在于将生命周期分解为模块化组件，并强调了组件间的互联性，这对于指导SLM的系统化开发和维护具有重要意义。该框架有望提高SLM开发的效率和质量，并为未来的工具链建设奠定基础。"}}
{"id": "2506.06680", "title": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": ["Radha Kodali", "Venkata Rao Dhulipalla", "Venkata Siva Kishor Tatavarty", "Madhavi Nadakuditi", "Bharadwaj Thiruveedhula", "Suryanarayana Gunnam", "Durga Prasad Bavirisetti"], "summary": "Infertility has a considerable impact on individuals' quality of life,\naffecting them socially and psychologically, with projections indicating a rise\nin the upcoming years. In vitro fertilization (IVF) emerges as one of the\nprimary techniques within economically developed nations, employed to address\nthe rising problem of low fertility. Expert embryologists conventionally grade\nembryos by reviewing blastocyst images to select the most optimal for transfer,\nyet this process is time-consuming and lacks efficiency. Blastocyst images\nprovide a valuable resource for assessing embryo viability. In this study, we\nintroduce an explainable artificial intelligence (XAI) framework for\nclassifying embryos, employing a fusion of convolutional neural network (CNN)\nand long short-term memory (LSTM) architecture, referred to as CNN-LSTM.\nUtilizing deep learning, our model achieves high accuracy in embryo\nclassification while maintaining interpretability through XAI.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06680v1", "AI": {"title_translation": "深度学习模型在体外受精（IVF）治疗中胚胎选择的解释", "tldr": "本研究开发了一个结合CNN和LSTM的XAI框架，用于高效准确地解释体外受精胚胎选择，解决了传统方法的耗时和低效问题。", "motivation": "不孕不育问题日益严重，体外受精（IVF）是主要治疗手段。然而，传统的胚胎选择过程耗时且效率低下，需要更高效准确的自动化方法。", "method": "本研究引入了一个可解释人工智能（XAI）框架，用于胚胎分类。该框架融合了卷积神经网络（CNN）和长短期记忆网络（LSTM）架构，命名为CNN-LSTM。", "result": "所提出的深度学习模型在胚胎分类中实现了高准确度，同时通过XAI保持了可解释性。", "conclusion": "该研究提出的结合CNN和LSTM的XAI框架为体外受精中的胚胎选择提供了一个高准确度且可解释的解决方案。", "translation": "不孕不育对个体生活质量有相当大的影响，在社会和心理上都影响着他们，预计未来几年还会上升。体外受精（IVF）是经济发达国家解决低生育率问题的主要技术之一。专家胚胎学家通常通过审查囊胚图像来对胚胎进行分级，以选择最适合移植的胚胎，但这个过程耗时且效率低下。囊胚图像为评估胚胎活力提供了宝贵资源。在本研究中，我们引入了一种可解释人工智能（XAI）框架，用于胚胎分类，该框架采用卷积神经网络（CNN）和长短期记忆（LSTM）架构的融合，称为CNN-LSTM。利用深度学习，我们的模型在胚胎分类中实现了高准确度，同时通过XAI保持了可解释性。", "summary": "本研究针对体外受精（IVF）中胚胎选择的传统方法耗时且效率低下的问题，提出了一种基于深度学习的可解释人工智能（XAI）框架。该框架融合了卷积神经网络（CNN）和长短期记忆网络（LSTM）架构（CNN-LSTM），旨在通过分析囊胚图像进行胚胎分类。研究结果表明，该模型在实现高准确度的同时，通过XAI保持了良好的可解释性，为IVF胚胎选择提供了高效且透明的解决方案。", "keywords": "深度学习, 胚胎选择, 体外受精, 可解释人工智能, CNN-LSTM", "comments": "该研究创新性地将可解释人工智能（XAI）引入胚胎选择领域，有效解决了深度学习模型在医疗应用中常见的“黑箱”问题，显著提升了模型的透明度和临床可信度。结合CNN和LSTM的架构设计，充分利用了图像的空间特征，对于提高诊断准确性具有重要意义。"}}
{"id": "2506.06698", "title": "Contextual Experience Replay for Self-Improvement of Language Agents", "authors": ["Yitao Liu", "Chenglei Si", "Karthik Narasimhan", "Shunyu Yao"], "summary": "Large language model (LLM) agents have been applied to sequential\ndecision-making tasks such as web navigation, but without any\nenvironment-specific experiences, they often fail in these complex tasks.\nMoreover, current LLM agents are not designed to continually learn from past\nexperiences during inference time, which could be crucial for them to gain\nthese environment-specific experiences. To address this, we propose Contextual\nExperience Replay (CER), a training-free framework to enable efficient\nself-improvement for language agents in their context window. Specifically, CER\naccumulates and synthesizes past experiences into a dynamic memory buffer.\nThese experiences encompass environment dynamics and common decision-making\npatterns, allowing the agents to retrieve and augment themselves with relevant\nknowledge in new tasks, enhancing their adaptability in complex environments.\nWe evaluate CER on the challenging WebArena and VisualWebArena benchmarks. On\nVisualWebArena, CER achieves a competitive performance of 31.9%. On WebArena,\nCER also gets a competitive average success rate of 36.7%, relatively improving\nthe success rate of the GPT-4o agent baseline by 51.0%. We also conduct a\ncomprehensive analysis on it to prove its efficiency, validity and understand\nit better.", "comment": "Accepted to ACL 2025. 20 pages", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06698v1", "AI": {"title_translation": "上下文经验回放用于语言智能体的自我提升", "tldr": "大型语言模型（LLM）智能体在复杂决策任务中因缺乏环境特定经验和持续学习能力而受限。本文提出上下文经验回放（CER），一个免训练框架，通过在上下文窗口中积累和合成过往经验，显著提升智能体在Web导航等任务中的表现和适应性。", "motivation": "大型语言模型（LLM）智能体在网络导航等序列决策任务中，由于缺乏环境特定经验，且当前设计无法在推理时持续学习过往经验，导致其在复杂任务中表现不佳。", "method": "本文提出了上下文经验回放（CER），一个免训练的框架，旨在使其语言智能体在上下文窗口中高效地自我提升。CER通过将过往经验（包括环境动态和常见决策模式）积累并合成到一个动态记忆缓冲区中。智能体在新任务中可以检索并利用这些相关知识来增强自身，从而提高在复杂环境中的适应性。", "result": "在VisualWebArena基准测试中，CER取得了31.9%的竞争力表现。在WebArena基准测试中，CER的平均成功率为36.7%，相对GPT-4o智能体基线提升了51.0%的成功率。研究还对其进行了全面分析，以证明其效率、有效性并加深理解。", "conclusion": "上下文经验回放（CER）是一个高效且有效的免训练框架，它通过在上下文窗口中积累和利用过往经验，显著提升了语言智能体在复杂环境中的自我改进能力和适应性。", "translation": "大型语言模型（LLM）智能体已被应用于网络导航等序列决策任务中，但由于缺乏任何环境特定经验，它们在这些复杂任务中常常失败。此外，当前的LLM智能体并非旨在推理时持续学习过往经验，而这对于它们获取这些环境特定经验可能至关重要。为了解决这个问题，我们提出了上下文经验回放（CER），一个免训练的框架，旨在使其语言智能体在上下文窗口中高效地自我提升。具体来说，CER积累并合成过往经验到一个动态记忆缓冲区中。这些经验包括环境动态和常见决策模式，使智能体在新任务中能够检索并利用相关知识来增强自身，从而提高在复杂环境中的适应性。我们在具有挑战性的WebArena和VisualWebArena基准测试中评估了CER。在VisualWebArena上，CER取得了31.9%的竞争力表现。在WebArena上，CER也获得了36.7%的竞争力平均成功率，相对GPT-4o智能体基线提升了51.0%的成功率。我们还对其进行了全面分析，以证明其效率、有效性并加深理解。", "summary": "本文提出了上下文经验回放（CER），一个免训练的框架，旨在通过在上下文窗口中积累和合成过往经验，使语言智能体能够高效地自我提升。CER通过动态记忆缓冲区存储环境动态和决策模式，从而在复杂任务中增强智能体的适应性。在WebArena和VisualWebArena基准测试中，CER表现出竞争力，并在WebArena上相对GPT-4o基线提升了51.0%的成功率。", "keywords": "上下文经验回放, 语言智能体, 自我提升, 大型语言模型, 网络导航", "comments": "CER的创新之处在于其免训练的特性，以及在上下文窗口中实现持续学习的能力，这对于LLM智能体在复杂环境中的适应性和泛化能力至关重要。通过动态记忆缓冲区来积累和利用经验是一种高效且实用的方法，为LLM智能体的自我改进提供了一条新途径。"}}
{"id": "2506.06321", "title": "On the Interplay of Privacy, Persuasion and Quantization", "authors": ["Anju Anand", "Emrah Akyol"], "summary": "We develop a communication-theoretic framework for privacy-aware and\nresilient decision making in cyber-physical systems under misaligned objectives\nbetween the encoder and the decoder. The encoder observes two correlated\nsignals ($X$,$\\theta$) and transmits a finite-rate message $Z$ to aid a\nlegitimate controller (the decoder) in estimating $X+\\theta$, while an\neavesdropper intercepts $Z$ to infer the private parameter $\\theta$. Unlike\nconventional setups where encoder and decoder share a common MSE objective,\nhere the encoder minimizes a Lagrangian that balances legitimate control\nfidelity and the privacy leakage about $\\theta$. In contrast, the decoder's\ngoal is purely to minimize its own estimation error without regard for privacy.\nWe analyze fully, partially, and non-revealing strategies that arise from this\nconflict, and characterize optimal linear encoders when the rate constraints\nare lifted. For finite-rate channels, we employ gradient-based methods to\ncompute the optimal controllers. Numerical experiments illustrate how tuning\nthe privacy parameter shapes the trade-off between control performance and\nresilience against unauthorized inferences.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06321v1", "AI": {"title_translation": "隐私、说服与量化的相互作用", "tldr": "本文提出了一个通信理论框架，用于网络物理系统中在编码器和解码器目标不一致的情况下的隐私感知和弹性决策，分析了不同策略和最优控制器，并展示了隐私参数如何平衡控制性能和抗未授权推理的能力。", "motivation": "传统的通信设置中，编码器和解码器通常共享一个共同的目标（例如MSE），但这在网络物理系统中，尤其是在涉及隐私保护的决策制定时，编码器和解码器可能存在目标不一致（例如，编码器需要平衡控制精度和隐私泄露，而解码器只关注估计误差）。这种目标不一致导致了冲突，因此需要开发一个新的通信理论框架来解决这一问题。", "method": "本文开发了一个通信理论框架，用于在编码器和解码器目标不一致的情况下实现隐私感知和弹性决策。编码器观察两个相关信号($X$,$\theta$)并发送有限速率消息$Z$给解码器以估计$X+\theta$，同时防止窃听者推断私有参数$\theta$。编码器通过最小化一个平衡合法控制精度和$\theta$隐私泄露的拉格朗日函数进行优化，而解码器仅最小化其自身的估计误差。研究分析了由此冲突产生的完全揭示、部分揭示和不揭示策略，并在解除速率约束时表征了最优线性编码器。对于有限速率信道，采用基于梯度的方法来计算最优控制器。", "result": "数值实验表明，调整隐私参数可以塑造控制性能和抵御未经授权推理的弹性之间的权衡。", "conclusion": "调整隐私参数对于管理网络物理系统中控制性能和抵御未经授权推理的弹性之间的权衡至关重要。", "translation": "我们开发了一个通信理论框架，用于在编码器和解码器目标不一致的网络物理系统中进行隐私感知和弹性决策。编码器观察两个相关信号($X$,$\theta$)并传输一个有限速率消息$Z$，以帮助合法的控制器（解码器）估计$X+\theta$，同时窃听者截获$Z$以推断私有参数$\theta$。与编码器和解码器共享共同MSE目标的传统设置不同，本文中编码器最小化一个平衡合法控制精度和$\theta$隐私泄露的拉格朗日函数。相反，解码器的目标纯粹是最小化其自身的估计误差，而不考虑隐私。我们全面分析了由此冲突产生的完全揭示、部分揭示和不揭示策略，并在解除速率约束时表征了最优线性编码器。对于有限速率信道，我们采用基于梯度的方法来计算最优控制器。数值实验说明了调整隐私参数如何塑造控制性能和抵御未经授权推理的弹性之间的权衡。", "summary": "本文提出了一个通信理论框架，用于解决网络物理系统中编码器和解码器目标不一致时的隐私感知与弹性决策问题。研究中，编码器在平衡控制精度和隐私泄露的前提下进行优化，而解码器则纯粹追求最小化估计误差。文章分析了多种信息揭示策略，并在无限速率条件下推导了最优线性编码器，对于有限速率信道则采用梯度方法计算最优控制器。数值实验结果表明，通过调整隐私参数，可以有效权衡控制系统性能与抵抗未授权推理的能力。", "keywords": "隐私, 网络物理系统, 量化, 目标不一致, 权衡", "comments": "这篇论文解决了网络物理系统中一个关键且实际的问题，即在系统组件目标不一致的情况下实现隐私感知决策。编码器通过拉格朗日优化同时平衡控制和隐私的方法具有创新性。对不同信息揭示策略的分析以及在有限速率信道中使用基于梯度的方法，展示了研究方法的全面性。关于隐私参数如何影响控制性能和弹性之间权衡的发现，为设计安全高效的网络物理系统提供了宝贵的见解。"}}
{"id": "2506.07263", "title": "Exploiting Inaccurate Branch History in Side-Channel Attacks", "authors": ["Yuhui Zhu", "Alessandro Biondi"], "summary": "Modern out-of-order CPUs heavily rely on speculative execution for\nperformance optimization, with branch prediction serving as a cornerstone to\nminimize stalls and maximize efficiency. Whenever shared branch prediction\nresources lack proper isolation and sanitization methods, they may originate\nsecurity vulnerabilities that expose sensitive data across different software\ncontexts.\n  This paper examines the fundamental components of modern Branch Prediction\nUnits (BPUs) and investigates how resource sharing and contention affect two\nwidely implemented but underdocumented features: Bias-Free Branch Prediction\nand Branch History Speculation. Our analysis demonstrates that these BPU\nfeatures, while designed to enhance speculative execution efficiency through\nmore accurate branch histories, can also introduce significant security risks.\nWe show that these features can inadvertently modify the Branch History Buffer\n(BHB) update behavior and create new primitives that trigger malicious\nmis-speculations.\n  This discovery exposes previously unknown cross-privilege attack surfaces for\nBranch History Injection (BHI). Based on these findings, we present three novel\nattack primitives: two Spectre attacks, namely Spectre-BSE and Spectre-BHS, and\na cross-privilege control flow side-channel attack called BiasScope. Our\nresearch identifies corresponding patterns of vulnerable control flows and\ndemonstrates exploitation on multiple processors. Finally, Chimera is\npresented: an attack demonstrator based on eBPF for a variant of Spectre-BHS\nthat is capable of leaking kernel memory contents at 24,628 bit/s.", "comment": "20 pages, 8 figures, to be published in proceedings of the 34th\n  USENIX Security Symposium (2025)", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07263v1", "AI": {"title_translation": "利用不准确的分支历史进行侧信道攻击", "tldr": "现代CPU的推测执行特性，特别是无偏分支预测和分支历史推测，因共享资源隔离不当，可被利用来引发恶意错误推测。本文揭示了新的分支历史注入（BHI）攻击面，并提出了Spectre-BSE、Spectre-BHS以及跨特权控制流侧信道攻击BiasScope，其中一个攻击演示器Chimera能以24,628比特/秒的速度泄露内核内存。", "motivation": "现代乱序CPU的推测执行严重依赖分支预测来优化性能，但当共享分支预测资源缺乏适当的隔离和清理时，它们可能产生安全漏洞，暴露不同软件上下文中的敏感数据。具体而言，本文旨在探究两个广泛实现但文档不足的分支预测单元（BPU）功能——无偏分支预测和分支历史推测——如何引入安全风险，因为它们可能无意中修改分支历史缓冲区（BHB）的更新行为并创建新的恶意错误推测原语。", "method": "本文研究了现代分支预测单元（BPU）的基本组成部分，并调查了资源共享和争用如何影响无偏分支预测和分支历史推测这两个特性。研究人员展示了这些功能如何修改BHB更新行为并创建触发恶意错误推测的新原语。基于这些发现，他们提出了三种新颖的攻击原语，并识别了相应的易受攻击控制流模式，在多个处理器上演示了漏洞利用。此外，还提出了一个基于eBPF的攻击演示器Chimera。", "result": "结果表明，无偏分支预测和分支历史推测这些BPU功能，虽然旨在提高效率，但会引入重大的安全风险，因为它们无意中修改了分支历史缓冲区（BHB）的更新行为，并创建了触发恶意错误推测的新原语。研究揭示了以前未知的针对分支历史注入（BHI）的跨特权攻击面。文章提出了三种新颖的攻击原语：Spectre-BSE、Spectre-BHS（两种Spectre攻击）和BiasScope（一种跨特权控制流侧信道攻击）。研究识别了相应的易受攻击控制流模式，并在多个处理器上成功演示了漏洞利用。最后，Chimera，一个基于eBPF的Spectre-BHS变体攻击演示器，被证明能够以24,628比特/秒的速度泄露内核内存内容。", "conclusion": "本文得出结论，现代CPU中某些特定的分支预测单元（BPU）功能，如无偏分支预测和分支历史推测，通过创建恶意错误推测的新原语，引入了显著的安全风险。这些风险导致了针对分支历史注入（BHI）的全新跨特权侧信道攻击面，并催生了Spectre变体（Spectre-BSE、Spectre-BHS）和BiasScope等新型攻击，这些攻击能够高效地泄露敏感数据。", "translation": "现代乱序CPU严重依赖推测执行进行性能优化，其中分支预测是最小化停顿和最大化效率的基石。当共享分支预测资源缺乏适当的隔离和清理方法时，它们可能会产生安全漏洞，暴露不同软件上下文中的敏感数据。\n本文研究了现代分支预测单元（BPU）的基本组成部分，并调查了资源共享和争用如何影响两个广泛实现但文档不足的功能：无偏分支预测（Bias-Free Branch Prediction）和分支历史推测（Branch History Speculation）。我们的分析表明，这些BPU功能虽然旨在通过更准确的分支历史来提高推测执行效率，但也可能引入重大的安全风险。我们展示了这些功能可能无意中修改分支历史缓冲区（BHB）的更新行为，并创建触发恶意错误推测的新原语。\n这一发现揭示了以前未知的针对分支历史注入（BHI）的跨特权攻击面。基于这些发现，我们提出了三种新颖的攻击原语：两种Spectre攻击，即Spectre-BSE和Spectre-BHS，以及一种名为BiasScope的跨特权控制流侧信道攻击。我们的研究识别了相应的易受攻击控制流模式，并在多个处理器上展示了漏洞利用。最后，我们展示了Chimera：一个基于eBPF的Spectre-BHS变体攻击演示器，能够以24,628比特/秒的速度泄露内核内存内容。", "summary": "本文研究了现代CPU中两个未充分记录的分支预测特性：无偏分支预测和分支历史推测，如何引入安全漏洞。研究揭示这些特性可能无意中改变分支历史缓冲区（BHB）的更新方式，从而为恶意错误推测创造新的原语。这导致了新的跨特权分支历史注入（BHI）攻击面。作者提出了三种新型攻击：Spectre-BSE、Spectre-BHS和BiasScope，并在多个处理器上展示了它们的利用。其中，一个名为Chimera的Spectre-BHS变体演示器能够以高速度泄露内核内存。", "keywords": "分支预测, 侧信道攻击, Spectre, 推测执行, 分支历史注入", "comments": "这篇论文意义重大，因为它揭示了源自CPU中未充分记录的分支预测特性所带来的新侧信道攻击面。其创新之处在于识别了看似增强性能的机制如何被滥用，从而创建新的错误推测原语，导致新型Spectre类攻击。对高速内核内存泄漏的演示突显了这些漏洞的实际严重性。该研究有助于更深入地理解推测执行的安全风险。"}}
{"id": "2506.06359", "title": "From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins", "authors": ["Gabriel Antonesi", "Tudor Cioara", "Ionut Anghel", "Vasilis Michalakopoulos", "Elissaios Sarmas", "Liana Toderean"], "summary": "Artificial intelligence (AI) has long promised to improve energy management\nin smart grids by enhancing situational awareness and supporting more effective\ndecision-making. While traditional machine learning has demonstrated notable\nresults in forecasting and optimization, it often struggles with\ngeneralization, situational awareness, and heterogeneous data integration.\nRecent advances in foundation models such as Transformer architecture and Large\nLanguage Models (LLMs) have demonstrated improved capabilities in modelling\ncomplex temporal and contextual relationships, as well as in multi-modal data\nfusion which is essential for most AI applications in the energy sector. In\nthis review we synthesize the rapid expanding field of AI applications in the\nenergy domain focusing on Transformers and LLMs. We examine the architectural\nfoundations, domain-specific adaptations and practical implementations of\ntransformer models across various forecasting and grid management tasks. We\nthen explore the emerging role of LLMs in the field: adaptation and fine tuning\nfor the energy sector, the type of tasks they are suited for, and the new\nchallenges they introduce. Along the way, we highlight practical\nimplementations, innovations, and areas where the research frontier is rapidly\nexpanding. These recent developments reviewed underscore a broader trend:\nGenerative AI (GenAI) is beginning to augment decision-making not only in\nhigh-level planning but also in day-to-day operations, from forecasting and\ngrid balancing to workforce training and asset onboarding. Building on these\ndevelopments, we introduce the concept of the Agentic Digital Twin, a\nnext-generation model that integrates LLMs to bring autonomy, proactivity, and\nsocial interaction into digital twin-based energy management systems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06359v1", "AI": {"title_translation": "从Transformer到大型语言模型：能源领域人工智能应用迈向智能体数字孪生的系统综述", "tldr": "本文系统综述了Transformer和大型语言模型（LLMs）在能源领域的应用，强调了它们在复杂数据建模方面的能力，并提出了将LLMs集成到智能体数字孪生中以增强能源管理的概念。", "motivation": "尽管传统机器学习在智能电网能源管理中有所应用，但其在泛化、态势感知和异构数据集成方面存在局限性。Transformer和LLMs等基础模型在处理复杂时间/上下文关系和多模态数据融合方面展现出更强的能力，这对于能源领域的AI应用至关重要，因此有必要对其进行系统回顾。", "method": "本文对能源领域中快速发展的人工智能应用（特别是Transformer和LLMs）进行了系统综述。它考察了Transformer模型的架构基础、领域特定适应和实际应用，并探讨了LLMs在新兴能源领域的角色，包括其适应性、适用任务和引入的挑战。此外，还提出了智能体数字孪生的概念。", "result": "综述结果表明，Transformer和LLMs在建模复杂时间/上下文关系和多模态数据融合方面表现出改进的能力，并且生成式AI（GenAI）正在增强能源部门的决策制定，从高层规划到日常运营。此外，论文引入了智能体数字孪生概念，该模型通过集成LLMs为数字孪生能源管理系统带来自主性、主动性和社交互动。", "conclusion": "该论文得出结论，生成式AI（特别是LLMs）的最新发展将显著增强能源领域的决策制定，并引入了智能体数字孪生这一创新概念，旨在为能源管理系统赋予自主性和主动性。", "translation": "人工智能（AI）长期以来一直致力于通过增强态势感知和支持更有效的决策来改善智能电网中的能源管理。虽然传统的机器学习在预测和优化方面取得了显著成果，但它常常在泛化、态势感知和异构数据集成方面遇到困难。Transformer架构和大型语言模型（LLMs）等基础模型的最新进展，在建模复杂的时间和上下文关系以及多模态数据融合方面表现出更强的能力，这对于能源领域的大多数AI应用至关重要。在这篇综述中，我们综合了能源领域中快速发展的人工智能应用，重点关注Transformer和LLMs。我们研究了Transformer模型在各种预测和电网管理任务中的架构基础、领域特定适应和实际实现。然后，我们探讨了LLMs在该领域的新兴作用：针对能源领域的适应和微调、它们适合的任务类型以及它们引入的新挑战。在此过程中，我们强调了实际实现、创新以及研究前沿正在迅速扩展的领域。这些近期回顾的进展强调了一个更广泛的趋势：生成式AI（GenAI）开始不仅在高层规划中，而且在日常运营中（从预测和电网平衡到劳动力培训和资产入职）增强决策。基于这些发展，我们引入了智能体数字孪生（Agentic Digital Twin）的概念，这是一种集成了LLMs的下一代模型，旨在将自主性、主动性和社交互动引入基于数字孪生的能源管理系统。", "summary": "本系统综述探讨了Transformer和大型语言模型（LLMs）等先进AI模型在能源领域的日益增长的应用。论文指出，这些模型通过有效处理复杂数据和关系，克服了传统机器学习的局限性。文中深入分析了它们的架构基础、领域适应性以及在预测和电网管理等任务中的实际应用。该综述强调了LLMs在增强能源运营中决策制定的新兴作用，并引入了智能体数字孪生这一创新概念，该概念利用LLMs提升能源管理系统的自主性和主动性。", "keywords": "Transformers, 大型语言模型, 能源领域, 数字孪生, 智能电网", "comments": "该论文具有重要意义，因为它将前沿AI技术（Transformer、LLMs）与关键的能源领域相结合。其创新之处在于系统地回顾了这些先进模型的应用，更重要的是，概念化了“智能体数字孪生”，这为能源管理提出了一种新颖、更自主的范式。这一框架有望显著增强智能电网的韧性和效率。"}}
{"id": "2506.07153", "title": "Mind the Web: The Security of Web Use Agents", "authors": ["Avishag Shapira", "Parth Atulbhai Gandhi", "Edan Habler", "Oleg Brodt", "Asaf Shabtai"], "summary": "Web-use agents are rapidly being deployed to automate complex web tasks,\noperating with extensive browser capabilities including multi-tab navigation,\nDOM manipulation, JavaScript execution and authenticated session access.\nHowever, these powerful capabilities create a critical and previously\nunexplored attack surface. This paper demonstrates how attackers can exploit\nweb-use agents' high-privilege capabilities by embedding malicious content in\nweb pages such as comments, reviews, or advertisements that agents encounter\nduring legitimate browsing tasks. In addition, we introduce the task-aligned\ninjection technique that frame malicious commands as helpful task guidance\nrather than obvious attacks. This technique exploiting fundamental limitations\nin LLMs' contextual reasoning: agents struggle in maintaining coherent\ncontextual awareness and fail to detect when seemingly helpful web content\ncontains steering attempts that deviate from their original task goal. Through\nsystematic evaluation of four popular agents (OpenAI Operator, Browser Use, Do\nBrowser, OpenOperator), we demonstrate nine payload types that compromise\nconfidentiality, integrity, and availability, including unauthorized camera\nactivation, user impersonation, local file exfiltration, password leakage, and\ndenial of service, with validation across multiple LLMs achieving success rates\nof 80%-100%. These payloads succeed across agents with built-in safety\nmechanisms, requiring only the ability to post content on public websites,\ncreating unprecedented risks given the ease of exploitation combined with\nagents' high-privilege access. To address this attack, we propose comprehensive\nmitigation strategies including oversight mechanisms, execution constraints,\nand task-aware reasoning techniques, providing practical directions for secure\ndevelopment and deployment.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07153v1", "AI": {"title_translation": "小心网络：网络使用代理的安全性", "tldr": "网络使用代理因其高级功能而面临新的安全漏洞，攻击者可通过嵌入恶意内容利用LLM的上下文推理缺陷，实现高成功率的机密性、完整性和可用性攻击。", "motivation": "网络使用代理正被广泛部署以自动化复杂的网络任务，它们具有多标签导航、DOM操作、JavaScript执行和认证会话访问等广泛的浏览器功能。然而，这些强大的功能也创造了一个关键且以前未被探索的攻击面，攻击者可以利用这些代理的高权限能力。", "method": "研究人员展示了攻击者如何通过在网络页面（如评论、评论或广告）中嵌入恶意内容来利用网络使用代理的高权限能力。他们引入了“任务对齐注入”技术，将恶意命令伪装成有用的任务指导，从而利用大型语言模型（LLMs）上下文推理中的基本局限性。他们通过对四种流行代理（OpenAI Operator, Browser Use, Do Browser, OpenOperator）的系统评估，验证了九种有效载荷类型。", "result": "研究展示了九种能够损害机密性、完整性或可用性的有效载荷类型，包括未经授权的摄像头激活、用户冒充、本地文件外泄、密码泄露和拒绝服务。这些有效载荷在多个LLM上进行了验证，成功率达到80%-100%。即使代理内置了安全机制，这些攻击也能成功，仅需要能够发布公共网站内容的能力。", "conclusion": "网络使用代理因其易于利用性结合高权限访问，带来了前所未有的风险。为了解决这种攻击，论文提出了全面的缓解策略，包括监督机制、执行约束和任务感知推理技术，为安全开发和部署提供了实用方向。", "translation": "网络使用代理正在迅速部署以自动化复杂的网络任务，它们以广泛的浏览器功能运行，包括多标签导航、DOM操作、JavaScript执行和认证会话访问。然而，这些强大的功能创造了一个关键且以前未被探索的攻击面。本文展示了攻击者如何通过在网络页面（如评论、评论或广告）中嵌入恶意内容来利用网络使用代理的高权限能力，这些内容是代理在合法浏览任务中遇到的。此外，我们引入了任务对齐注入技术，该技术将恶意命令伪装成有用的任务指导，而不是明显的攻击。这项技术利用了大型语言模型（LLMs）上下文推理中的基本局限性：代理难以保持连贯的上下文感知，并且无法检测看似有用的网络内容何时包含偏离其原始任务目标的引导尝试。通过对四种流行代理（OpenAI Operator、Browser Use、Do Browser、OpenOperator）的系统评估，我们展示了九种损害机密性、完整性和可用性的有效载荷类型，包括未经授权的摄像头激活、用户冒充、本地文件外泄、密码泄露和拒绝服务，并在多个LLM上进行了验证，成功率达到80%-100%。这些有效载荷在内置安全机制的代理中也能成功，仅需要能够在公共网站上发布内容的能力，考虑到易受攻击性与代理高权限访问相结合，这带来了前所未有的风险。为了解决这种攻击，我们提出了全面的缓解策略，包括监督机制、执行约束和任务感知推理技术，为安全开发和部署提供了实用方向。", "summary": "本论文探讨了网络使用代理（Web-use agents）在自动化网络任务时引入的新型安全漏洞。研究指出，代理的强大浏览器功能（如DOM操作和会话访问）带来了未被探索的攻击面。通过引入“任务对齐注入”技术，攻击者可利用LLM的上下文推理缺陷，将恶意指令伪装成有用的任务指导。通过对四种主流代理的系统评估，论文展示了九种可导致数据泄露、身份冒充和拒绝服务等后果的攻击载荷，成功率高达80%-100%，即使代理内置安全机制也无法幸免。鉴于攻击的易行性和代理的高权限，这带来了前所未有的风险。论文最后提出了监督机制、执行约束和任务感知推理等缓解策略。", "keywords": "Web-use agents, LLM security, Task-aligned injection, Attack surface, Web automation", "comments": "这篇论文揭示了一个新兴且重要的安全问题，即AI代理在与网络交互时所面临的风险。其创新之处在于提出了“任务对齐注入”这一新颖的攻击技术，巧妙地利用了大型语言模型在上下文推理方面的固有局限性。研究通过对主流代理的系统性评估，证实了攻击的普遍性和高成功率，这对于指导未来AI代理的安全设计与部署具有重大意义。论文不仅指出了问题，还提出了实用的缓解策略，具有很高的实践价值。"}}
{"id": "2506.07468", "title": "Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models", "authors": ["Mickel Liu", "Liwei Jiang", "Yancheng Liang", "Simon Shaolei Du", "Yejin Choi", "Tim Althoff", "Natasha Jaques"], "summary": "Conventional language model (LM) safety alignment relies on a reactive,\ndisjoint procedure: attackers exploit a static model, followed by defensive\nfine-tuning to patch exposed vulnerabilities. This sequential approach creates\na mismatch -- attackers overfit to obsolete defenses, while defenders\nperpetually lag behind emerging threats. To address this, we propose\nSelf-RedTeam, an online self-play reinforcement learning algorithm where an\nattacker and defender agent co-evolve through continuous interaction. We cast\nsafety alignment as a two-player zero-sum game, where a single model alternates\nbetween attacker and defender roles -- generating adversarial prompts and\nsafeguarding against them -- while a reward LM adjudicates outcomes. This\nenables dynamic co-adaptation. Grounded in the game-theoretic framework of\nzero-sum games, we establish a theoretical safety guarantee which motivates the\ndesign of our method: if self-play converges to a Nash Equilibrium, the\ndefender will reliably produce safe responses to any adversarial input.\nEmpirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared\nto attackers trained against static defenders and achieves higher robustness on\nsafety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained\nagainst static attackers. We further propose hidden Chain-of-Thought, allowing\nagents to plan privately, which boosts adversarial diversity and reduces\nover-refusals. Our results motivate a shift from reactive patching to proactive\nco-evolution in LM safety training, enabling scalable, autonomous, and robust\nself-improvement of LMs via multi-agent reinforcement learning (MARL).", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07468v1", "AI": {"title_translation": "利用在线自博弈强化学习追逐移动目标以实现更安全的语言模型", "tldr": "本文提出Self-RedTeam，一种在线自博弈强化学习算法，通过攻击者和防御者智能体的共同进化，旨在提升语言模型安全性，解决传统方法的滞后问题。", "motivation": "传统语言模型（LM）安全对齐方法是反应性的、分离的，导致攻击者过度拟合过时防御，而防御者永久落后于新兴威胁，存在攻击与防御不匹配的问题。", "method": "本文提出了Self-RedTeam，一种在线自博弈强化学习算法。该方法将安全对齐建模为双人零和博弈，其中单个语言模型轮流扮演攻击者和防御者角色，生成对抗性提示并进行防御，并由奖励LM裁决结果，从而实现动态共同适应。理论上，如果自博弈收敛到纳什均衡，防御者能可靠地对任何对抗性输入产生安全响应。此外，还提出了隐藏式思维链（hidden Chain-of-Thought），允许智能体私下规划，以提升对抗多样性并减少过度拒绝。", "result": "经验证明，与针对静态防御者训练的攻击者相比，Self-RedTeam能发现更多样化的攻击（SBERT +21.8%）。在安全基准测试（例如WildJailBreak）上，其防御鲁棒性比针对静态攻击者训练的防御者更高（+65.5%）。隐藏式思维链进一步提升了对抗多样性并减少了过度拒绝。", "conclusion": "本文结果促使语言模型安全训练从反应性修补转向主动共同进化，通过多智能体强化学习（MARL）实现语言模型的可扩展、自主和鲁棒的自我改进。", "translation": "传统语言模型（LM）安全对齐依赖于一种反应性的、分离的程序：攻击者利用静态模型，随后进行防御性微调以修补暴露的漏洞。这种顺序方法造成了不匹配——攻击者过度拟合过时的防御，而防御者则永久落后于新兴威胁。为了解决这个问题，我们提出了Self-RedTeam，一种在线自博弈强化学习算法，其中攻击者和防御者智能体通过持续交互共同进化。我们将安全对齐视为一个双人零和博弈，其中一个模型轮流扮演攻击者和防御者角色——生成对抗性提示并抵御它们——同时一个奖励LM裁决结果。这使得动态共同适应成为可能。基于零和博弈的博弈论框架，我们建立了理论安全保证，这激励了我们方法的设计：如果自博弈收敛到纳什均衡，防御者将可靠地对任何对抗性输入产生安全响应。经验上，与针对静态防御者训练的攻击者相比，Self-RedTeam发现了更多样化的攻击（SBERT +21.8%），并且在安全基准测试（例如WildJailBreak）上比针对静态攻击者训练的防御者实现了更高的鲁棒性（+65.5%）。我们进一步提出了隐藏式思维链（hidden Chain-of-Thought），允许智能体私下规划，这提升了对抗多样性并减少了过度拒绝。我们的结果促使LM安全训练从反应性修补转向主动共同进化，通过多智能体强化学习（MARL）实现LM的可扩展、自主和鲁棒的自我改进。", "summary": "本文提出Self-RedTeam，一种在线自博弈强化学习算法，旨在解决传统语言模型安全对齐中攻击者与防御者之间的滞后问题。该算法将安全对齐建模为双人零和博弈，通过一个模型轮流扮演攻击者和防御者角色，实现动态共同适应。理论分析表明，收敛到纳什均衡可提供安全保证。实验结果显示，Self-RedTeam能发现更多样化的攻击并提升防御鲁棒性。此外，引入隐藏式思维链进一步增强了对抗多样性并减少了过度拒绝。该研究倡导LM安全训练从被动修补转向主动协同进化。", "keywords": "语言模型安全, 自博弈强化学习, 对抗性训练, 零和博弈, 多智能体强化学习", "comments": "这篇论文的创新点在于将语言模型安全对齐问题转化为一个动态的、多智能体强化学习的自博弈过程，而非传统的静态修补。通过引入攻击者和防御者的共同进化，有效解决了现有方法中“攻击者过度拟合、防御者滞后”的问题，并提供了理论安全保证。隐藏式思维链的提出也进一步提升了实际效果。这项工作为语言模型安全性的自主和持续改进提供了一个有前景的新范式。"}}
{"id": "2506.06664", "title": "Generalized Trajectory Scoring for End-to-end Multimodal Planning", "authors": ["Zhenxin Li", "Wenhao Yao", "Zi Wang", "Xinglong Sun", "Joshua Chen", "Nadine Chang", "Maying Shen", "Zuxuan Wu", "Shiyi Lan", "Jose M. Alvarez"], "summary": "End-to-end multi-modal planning is a promising paradigm in autonomous\ndriving, enabling decision-making with diverse trajectory candidates. A key\ncomponent is a robust trajectory scorer capable of selecting the optimal\ntrajectory from these candidates. While recent trajectory scorers focus on\nscoring either large sets of static trajectories or small sets of dynamically\ngenerated ones, both approaches face significant limitations in generalization.\nStatic vocabularies provide effective coarse discretization but struggle to\nmake fine-grained adaptation, while dynamic proposals offer detailed precision\nbut fail to capture broader trajectory distributions. To overcome these\nchallenges, we propose GTRS (Generalized Trajectory Scoring), a unified\nframework for end-to-end multi-modal planning that combines coarse and\nfine-grained trajectory evaluation. GTRS consists of three complementary\ninnovations: (1) a diffusion-based trajectory generator that produces diverse\nfine-grained proposals; (2) a vocabulary generalization technique that trains a\nscorer on super-dense trajectory sets with dropout regularization, enabling its\nrobust inference on smaller subsets; and (3) a sensor augmentation strategy\nthat enhances out-of-domain generalization while incorporating refinement\ntraining for critical trajectory discrimination. As the winning solution of the\nNavsim v2 Challenge, GTRS demonstrates superior performance even with\nsub-optimal sensor inputs, approaching privileged methods that rely on\nground-truth perception. Code will be available at\nhttps://github.com/NVlabs/GTRS.", "comment": "The 1st place solution of the End-to-end Driving Track at the CVPR\n  2025 Autonomous Grand Challenge", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06664v1", "AI": {"title_translation": "广义轨迹评分用于端到端多模态规划", "tldr": "GTRS提出一个统一框架，结合粗粒度和细粒度轨迹评估，解决现有轨迹评分器泛化性差的问题，并在Navsim v2挑战中表现出色。", "motivation": "现有的轨迹评分器在泛化性方面存在显著局限性，无论是针对大量静态轨迹还是少量动态生成轨迹的评分方法，都难以进行细粒度适应或捕获更广泛的轨迹分布。", "method": "提出GTRS (Generalized Trajectory Scoring) 框架，包含三个创新点：1) 基于扩散的轨迹生成器，产生多样细粒度提案；2) 词汇泛化技术，在超密集轨迹集上通过dropout正则化训练评分器，使其在较小字集上也能鲁棒推理；3) 传感器增强策略，增强域外泛化性并结合关键轨迹判别细化训练。", "result": "GTRS是Navsim v2挑战赛的获胜方案，即使在次优传感器输入下也表现出卓越性能，接近依赖于真实感知数据的特权方法。", "conclusion": "GTRS通过结合粗粒度和细粒度评估，克服了现有轨迹评分器在泛化性方面的挑战，并在实际应用中展现出优越的性能，为端到端多模态规划提供了统一且鲁棒的解决方案。", "translation": "端到端多模态规划是自动驾驶中一个有前景的范式，它能够实现基于多样轨迹候选的决策。其中一个关键组件是能够从这些候选轨迹中选择最优轨迹的鲁棒轨迹评分器。虽然最近的轨迹评分器专注于对大量静态轨迹或少量动态生成轨迹进行评分，但这两种方法在泛化性方面都面临显著局限。静态词汇表提供了有效的粗粒度离散化，但难以进行细粒度适应，而动态提案提供了详细的精度，却未能捕获更广泛的轨迹分布。为了克服这些挑战，我们提出了GTRS（广义轨迹评分），一个用于端到端多模态规划的统一框架，它结合了粗粒度评估和细粒度评估。GTRS由三个互补的创新组成：(1) 一个基于扩散的轨迹生成器，产生多样化的细粒度提案；(2) 一种词汇泛化技术，通过dropout正则化在超密集轨迹集上训练评分器，使其能够在较小子集上进行鲁棒推理；(3) 一种传感器增强策略，在整合关键轨迹判别细化训练的同时增强域外泛化性。作为Navsim v2挑战赛的获胜方案，GTRS即使在次优传感器输入下也表现出卓越性能，接近依赖于地面真实感知数据的特权方法。代码将在https://github.com/NVlabs/GTRS提供。", "summary": "本文提出了GTRS（广义轨迹评分）框架，旨在解决自动驾驶中端到端多模态规划现有轨迹评分器泛化性不足的问题。GTRS通过结合基于扩散的轨迹生成、词汇泛化技术和传感器增强策略，实现了粗粒度与细粒度轨迹评估的统一。该方法作为Navsim v2挑战赛的获胜方案，在次优传感器输入下仍展现出优异性能。", "keywords": "轨迹评分, 多模态规划, 自动驾驶, 泛化性, 扩散模型", "comments": "GTRS的创新之处在于其统一了粗粒度和细粒度轨迹评估，并通过扩散模型、词汇泛化和传感器增强等技术显著提升了轨迹评分器的泛化能力，尤其是在域外和次优输入条件下的鲁棒性。其在Navsim v2挑战赛中获胜，证明了其在实际应用中的有效性和先进性。"}}
{"id": "2506.07942", "title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "authors": ["Yang Liu", "Armstrong Foundjem", "Foutse Khomh", "Heng Li"], "summary": "Large Language Models (LLMs) have become vital tools in software development\ntasks such as code generation, completion, and analysis. As their integration\ninto workflows deepens, ensuring robustness against vulnerabilities especially\nthose triggered by diverse or adversarial inputs becomes increasingly\nimportant. Such vulnerabilities may lead to incorrect or insecure code\ngeneration when models encounter perturbed task descriptions, code, or\ncomments. Prior research often overlooks the role of natural language in\nguiding code tasks. This study investigates how adversarial perturbations in\nnatural language inputs including prompts, comments, and descriptions affect\nLLMs for Code (LLM4Code). It examines the effects of perturbations at the\ncharacter, word, and sentence levels to identify the most impactful\nvulnerabilities. We analyzed multiple projects (e.g., ReCode, OpenAttack) and\ndatasets (e.g., HumanEval, MBPP), establishing a taxonomy of adversarial\nattacks. The first dimension classifies the input type code, prompts, or\ncomments while the second dimension focuses on granularity: character, word, or\nsentence-level changes. We adopted a mixed-methods approach, combining\nquantitative performance metrics with qualitative vulnerability analysis.\nLLM4Code models show varying robustness across perturbation types.\nSentence-level attacks were least effective, suggesting models are resilient to\nbroader contextual changes. In contrast, word-level perturbations posed serious\nchallenges, exposing semantic vulnerabilities. Character-level effects varied,\nshowing model sensitivity to subtle syntactic deviations.Our study offers a\nstructured framework for testing LLM4Code robustness and emphasizes the\ncritical role of natural language in adversarial evaluation. Improving model\nresilience to semantic-level disruptions is essential for secure and reliable\ncode-generation systems.", "comment": null, "cate": "cs.SE", "url": "http://arxiv.org/abs/2506.07942v1", "AI": {"title_translation": "面向代码大型语言模型的对抗性攻击分类与鲁棒性测试", "tldr": "本研究探讨了自然语言输入中的对抗性扰动如何影响代码大型语言模型（LLM4Code），并提出了一个对抗性攻击分类法和鲁棒性测试框架，发现词级扰动对模型构成严重挑战。", "motivation": "大型语言模型（LLMs）已成为软件开发中的重要工具，但其在工作流程中面临对抗性输入引起的漏洞问题，可能导致生成不正确或不安全的代码。现有研究常忽视自然语言在指导代码任务中的作用，因此本研究旨在填补这一空白，确保LLM4Code的鲁棒性。", "method": "本研究调查了提示、注释和描述等自然语言输入中的对抗性扰动如何影响LLM4Code。研究检查了字符、单词和句子级别的扰动效果，以识别最具影响力的漏洞。研究分析了多个项目（如ReCode, OpenAttack）和数据集（如HumanEval, MBPP），建立了一个对抗性攻击分类法，该分类法根据输入类型（代码、提示、注释）和粒度（字符、单词、句子级别）进行分类。研究采用混合方法，结合定量性能指标和定性漏洞分析。", "result": "LLM4Code模型在不同扰动类型下表现出不同的鲁棒性。句子级攻击效果最差，表明模型对更广泛的上下文变化具有弹性。相反，词级扰动带来了严峻挑战，暴露了语义漏洞。字符级影响各不相同，显示模型对细微语法偏差的敏感性。", "conclusion": "本研究为LLM4Code鲁棒性测试提供了一个结构化框架，并强调了自然语言在对抗性评估中的关键作用。提高模型对语义级干扰的弹性对于安全可靠的代码生成系统至关重要。", "translation": "大型语言模型（LLMs）已成为代码生成、代码补全和代码分析等软件开发任务中的重要工具。随着它们在工作流程中深度集成，确保其抵御漏洞（特别是那些由多样化或对抗性输入触发的漏洞）的鲁棒性变得越来越重要。当模型遇到受扰动的任务描述、代码或注释时，此类漏洞可能导致不正确或不安全的代码生成。先前的研究常常忽视自然语言在指导代码任务中的作用。本研究调查了提示、注释和描述等自然语言输入中的对抗性扰动如何影响面向代码的大型语言模型（LLM4Code）。它检查了字符、单词和句子级别的扰动效果，以识别最具影响力的漏洞。我们分析了多个项目（例如ReCode、OpenAttack）和数据集（例如HumanEval、MBPP），建立了一个对抗性攻击分类法。第一个维度根据输入类型（代码、提示或注释）进行分类，而第二个维度则侧重于粒度：字符、单词或句子级别的更改。我们采用混合方法，结合定量性能指标和定性漏洞分析。LLM4Code模型在不同扰动类型下表现出不同的鲁棒性。句子级攻击效果最差，表明模型对更广泛的上下文变化具有弹性。相反，词级扰动带来了严峻挑战，暴露了语义漏洞。字符级影响各不相同，显示模型对细微语法偏差的敏感性。我们的研究为测试LLM4Code鲁棒性提供了一个结构化框架，并强调了自然语言在对抗性评估中的关键作用。提高模型对语义级干扰的弹性对于安全可靠的代码生成系统至关重要。", "summary": "本研究旨在评估面向代码的大型语言模型（LLM4Code）在自然语言对抗性扰动下的鲁棒性。研究分析了字符、单词和句子级别的扰动对LLM4Code的影响，并基于输入类型和扰动粒度构建了一个对抗性攻击分类法。通过对多个项目和数据集的分析，研究发现词级扰动对LLM4Code构成严重挑战，暴露了语义漏洞，而句子级攻击效果最弱。本研究提出了一个结构化框架，用于测试LLM4Code的鲁棒性，并强调了自然语言在对抗性评估中的关键作用，指出提高模型对语义级干扰的弹性对于确保代码生成系统的安全和可靠至关重要。", "keywords": "对抗性攻击, LLM4Code, 鲁棒性测试, 自然语言, 代码生成", "comments": "本研究的创新点在于其首次系统性地探讨了自然语言输入中对抗性扰动对LLM4Code的影响，并提出了一个新颖的对抗性攻击分类法。其贡献在于提供了一个结构化的鲁棒性测试框架，并揭示了词级（语义）扰动对LLM4Code的严重威胁，这对于开发更安全、更可靠的代码生成系统具有重要指导意义。"}}
{"id": "2506.06710", "title": "A Systematic Investigation on Deep Learning-Based Omnidirectional Image and Video Super-Resolution", "authors": ["Qianqian Zhao", "Chunle Guo", "Tianyi Zhang", "Junpei Zhang", "Peiyang Jia", "Tan Su", "Wenjie Jiang", "Chongyi Li"], "summary": "Omnidirectional image and video super-resolution is a crucial research topic\nin low-level vision, playing an essential role in virtual reality and augmented\nreality applications. Its goal is to reconstruct high-resolution images or\nvideo frames from low-resolution inputs, thereby enhancing detail preservation\nand enabling more accurate scene analysis and interpretation. In recent years,\nnumerous innovative and effective approaches have been proposed, predominantly\nbased on deep learning techniques, involving diverse network architectures,\nloss functions, projection strategies, and training datasets. This paper\npresents a systematic review of recent progress in omnidirectional image and\nvideo super-resolution, focusing on deep learning-based methods. Given that\nexisting datasets predominantly rely on synthetic degradation and fall short in\ncapturing real-world distortions, we introduce a new dataset, 360Insta, that\ncomprises authentically degraded omnidirectional images and videos collected\nunder diverse conditions, including varying lighting, motion, and exposure\nsettings. This dataset addresses a critical gap in current omnidirectional\nbenchmarks and enables more robust evaluation of the generalization\ncapabilities of omnidirectional super-resolution methods. We conduct\ncomprehensive qualitative and quantitative evaluations of existing methods on\nboth public datasets and our proposed dataset. Furthermore, we provide a\nsystematic overview of the current status of research and discuss promising\ndirections for future exploration. All datasets, methods, and evaluation\nmetrics introduced in this work are publicly available and will be regularly\nupdated. Project page: https://github.com/nqian1/Survey-on-ODISR-and-ODVSR.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06710v1", "AI": {"title_translation": "基于深度学习的全向图像和视频超分辨率的系统研究", "tldr": "本文系统综述了基于深度学习的全向图像和视频超分辨率研究进展，并提出了一个包含真实退化数据的360Insta新数据集，用于更鲁棒的评估。", "motivation": "全向图像和视频超分辨率是低级视觉中的关键研究课题，在虚拟现实和增强现实应用中发挥着重要作用。其目标是从低分辨率输入重建高分辨率图像或视频帧，以增强细节保留并实现更准确的场景分析和解释。现有数据集主要依赖合成退化，未能捕捉真实世界的失真。", "method": "本文系统综述了基于深度学习的全向图像和视频超分辨率的最新进展，重点关注深度学习方法。针对现有数据集的不足，提出了一个包含真实退化全向图像和视频的新数据集360Insta。在公共数据集和360Insta数据集上对现有方法进行了全面的定性和定量评估。此外，还系统概述了研究现状并讨论了未来方向。", "result": "提出了一个包含真实退化全向图像和视频的新数据集360Insta，解决了现有全向基准测试中关键的空白，并能更鲁棒地评估全向超分辨率方法的泛化能力。对现有方法在公共数据集和所提出的数据集上进行了全面的定性和定量评估。", "conclusion": "本文提供了对基于深度学习的全向图像和视频超分辨率的系统回顾，并提出了一个用于更鲁棒评估的真实退化数据集360Insta，同时讨论了未来的研究方向。", "translation": "全向图像和视频超分辨率是低级视觉中的一个关键研究课题，在虚拟现实和增强现实应用中发挥着重要作用。其目标是从低分辨率输入重建高分辨率图像或视频帧，从而增强细节保留并实现更准确的场景分析和解释。近年来，已经提出了许多创新和有效的方法，主要基于深度学习技术，涉及不同的网络架构、损失函数、投影策略和训练数据集。本文系统回顾了全向图像和视频超分辨率的最新进展，重点关注基于深度学习的方法。鉴于现有数据集主要依赖合成退化，未能捕捉真实世界的失真，我们引入了一个新数据集360Insta，它包含在不同条件下（包括不同的光照、运动和曝光设置）收集的真实退化全向图像和视频。该数据集解决了当前全向基准测试中的关键空白，并能够更鲁棒地评估全向超分辨率方法的泛化能力。我们对现有方法在公共数据集和我们提出的数据集上进行了全面的定性和定量评估。此外，我们系统概述了研究现状并讨论了未来探索的有希望的方向。这项工作中引入的所有数据集、方法和评估指标都是公开可用的，并将定期更新。项目页面：https://github.com/nqian1/Survey-on-ODISR-and-ODVSR。", "summary": "本文对基于深度学习的全向图像和视频超分辨率进行了系统综述，该技术对VR/AR应用至关重要。鉴于现有数据集的局限性，作者提出了一个名为360Insta的新数据集，其中包含真实世界中退化的全向图像和视频，以促进对超分辨率方法泛化能力的更准确评估。研究对现有方法进行了全面评估，并展望了未来的研究方向。所有相关资源均已公开。", "keywords": "全向图像,视频超分辨率,深度学习,360Insta,系统综述", "comments": "该论文的创新之处在于提出了一个包含真实世界退化数据的360Insta数据集，这解决了现有基准测试中合成数据无法充分反映真实世界复杂性的问题。这对于提升全向超分辨率方法的泛化能力和实际应用价值具有重要意义。同时，作为一篇系统综述，它为该领域的最新进展和未来方向提供了宝贵的洞察。"}}
{"id": "2506.06714", "title": "Integrating AI Planning Semantics into SysML System Models for Automated PDDL File Generation", "authors": ["Hamied Nabizada", "Tom Jeleniewski", "Lasse Beers", "Maximilian Weigand", "Felix Gehlhoff", "Alexander Fay"], "summary": "This paper presents a SysML profile that enables the direct integration of\nplanning semantics based on the Planning Domain Definition Language (PDDL) into\nsystem models. Reusable stereotypes are defined for key PDDL concepts such as\ntypes, predicates, functions and actions, while formal OCL constraints ensure\nsyntactic consistency. The profile was derived from the Backus-Naur Form (BNF)\ndefinition of PDDL 3.1 to align with SysML modeling practices. A case study\nfrom aircraft manufacturing demonstrates the application of the profile: a\nrobotic system with interchangeable end effectors is modeled and enriched to\ngenerate both domain and problem descriptions in PDDL format. These are used as\ninput to a PDDL solver to derive optimized execution plans. The approach\nsupports automated and model-based generation of planning descriptions and\nprovides a reusable bridge between system modeling and AI planning in\nengineering design.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06714v1", "AI": {"title_translation": "将AI规划语义集成到SysML系统模型中以实现PDDL文件自动化生成", "tldr": "本文提出了一种SysML配置文件，用于将PDDL规划语义直接集成到系统模型中，实现PDDL文件自动化生成，并在航空制造案例中得到验证。", "motivation": "解决在工程设计中系统建模与AI规划之间的集成问题，实现规划描述的自动化和基于模型的生成。", "method": "提出一个SysML配置文件，该文件基于PDDL 3.1的BNF定义，定义了可重用的PDDL概念刻板印象（如类型、谓词、函数和动作），并使用OCL约束确保语法一致性。", "result": "该配置文件成功应用于航空制造案例研究，对一个具有可互换末端执行器的机器人系统进行建模和丰富，从而生成PDDL格式的领域和问题描述，这些描述可作为PDDL求解器的输入，用于导出优化的执行计划。", "conclusion": "该方法支持规划描述的自动化和基于模型的生成，并在工程设计中的系统建模与AI规划之间提供了可重用的桥梁。", "translation": "本文提出了一个SysML配置文件，该文件能够将基于规划领域定义语言（PDDL）的规划语义直接集成到系统模型中。为类型、谓词、函数和动作等关键PDDL概念定义了可重用的刻板印象，同时正式的OCL约束确保了语法一致性。该配置文件源自PDDL 3.1的巴克斯-瑙尔范式（BNF）定义，以与SysML建模实践保持一致。一个来自飞机制造的案例研究展示了该配置文件的应用：对一个带有可互换末端执行器的机器人系统进行建模和丰富，以生成PDDL格式的领域和问题描述。这些描述被用作PDDL求解器的输入，以导出优化的执行计划。该方法支持规划描述的自动化和基于模型的生成，并在工程设计中的系统建模与AI规划之间提供了可重用桥梁。", "summary": "本文介绍了一种SysML配置文件，旨在将PDDL规划语义无缝集成到系统模型中。该配置文件通过定义PDDL概念的刻板印象和OCL约束，实现了PDDL文件的自动化生成。通过航空制造中的机器人系统案例研究，验证了该方法能够生成PDDL领域和问题描述，进而用于规划求解器生成优化执行计划。这为系统建模与AI规划之间建立了自动化的、基于模型的桥梁。", "keywords": "SysML, AI规划, PDDL, 系统建模, 自动化生成", "comments": "这项工作创新性地将SysML系统建模与AI规划（PDDL）相结合，通过定义专门的SysML配置文件，实现了规划描述的自动化生成。其重要性在于为复杂的工程系统设计提供了一种集成化的、模型驱动的规划方法，有望提高规划效率和准确性。通过案例研究展示了其实用性，为未来在其他工程领域的应用提供了基础。"}}
{"id": "2506.06354", "title": "High-gain MIMO Beamforming Antenna System for DSRC and mmwave 5G Integration in Autonomous Vehicles", "authors": ["Mohammad Shahed Pervez", "Amanpreet Kaur"], "summary": "The evolution of autonomous vehicles necessitates robust, high-speed, and\nlow-latency wireless communication systems. This paper presents a novel\nhigh-gain Multiple-Input Multiple-Output (MIMO) beamforming antenna system that\nconcurrently supports Dedicated Short Range Communications (DSRC) at 5.9 GHz\nand millimeter-wave (mm Wave) 5G communications at 28 GHz. The proposed design\naddresses challenges such as compactness, dual-band operation, beam steering\ncapability, and port-to-port isolation within dynamic vehicular environments.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06354v1", "AI": {"title_translation": "用于自动驾驶车辆中DSRC和毫米波5G集成的高增益MIMO波束赋形天线系统", "tldr": "本文提出了一种新颖的高增益MIMO波束赋形天线系统，可同时支持自动驾驶车辆中的DSRC（5.9 GHz）和毫米波5G（28 GHz）通信。", "motivation": "自动驾驶车辆的发展需要鲁棒、高速、低延迟的无线通信系统。", "method": "本文提出了一种新颖的高增益多输入多输出（MIMO）波束赋形天线系统，该系统可同时支持5.9 GHz的专用短程通信（DSRC）和28 GHz的毫米波（mmWave）5G通信。该设计解决了动态车辆环境中紧凑性、双频操作、波束控制能力以及端口间隔离等挑战。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "自动驾驶车辆的演进需要鲁棒、高速、低延迟的无线通信系统。本文提出了一种新颖的高增益多输入多输出（MIMO）波束赋形天线系统，该系统可同时支持5.9 GHz的专用短程通信（DSRC）和28 GHz的毫米波（mmWave）5G通信。所提出的设计解决了动态车辆环境中紧凑性、双频操作、波束控制能力以及端口间隔离等挑战。", "summary": "本文介绍了一种专为自动驾驶车辆设计的新型高增益MIMO波束赋形天线系统。该系统能够同时支持5.9 GHz的DSRC和28 GHz的毫米波5G通信，并解决了紧凑性、双频操作、波束控制和端口隔离等关键挑战，旨在满足自动驾驶车辆对鲁棒、高速、低延迟无线通信的需求。", "keywords": "MIMO, 波束赋形, 自动驾驶车辆, DSRC, 毫米波5G", "comments": "该论文提出了一种创新的双频MIMO波束赋形天线系统，旨在解决自动驾驶车辆通信的关键需求。其创新点在于同时支持DSRC和毫米波5G，并关注了实际应用中的挑战，如紧凑性和波束控制。这项工作对于推动自动驾驶车辆的通信技术发展具有重要意义。"}}
{"id": "2506.07366", "title": "MoE-GPS: Guidlines for Prediction Strategy for Dynamic Expert Duplication in MoE Load Balancing", "authors": ["Haiyue Ma", "Zhixu Du", "Yiran Chen"], "summary": "In multi-GPU Mixture-of-Experts (MoE) network, experts are distributed across\ndifferent GPUs, which creates load imbalance as each expert processes different\nnumber of tokens. Recent works improve MoE inference load balance by\ndynamically duplicating popular experts to more GPUs to process excessive\ntokens, which requires predicting the distribution before routing. In this\npaper, we discuss the tradeoff of prediction strategies, accuracies, overhead,\nand end-to-end system performance. We propose MoE-GPS, a framework that guides\nthe selection of the optimal predictor design under various system\nconfigurations, by quantifying the performance impact to system-level model\nruntime. Specifically, we advocate for Distribution-Only Prediction, a\nprediction strategy that only predicts overall token distribution which\nsignificantly reduces overhead compared to the traditional Token-to-Expert\nPrediction. On Mixtral 8x7B MMLU dataset, MoE-GPS suggests Distribution-Only\nPrediction which improves end-to-end inference performance by more than 23%\ncompared with Token-to-Expert Prediction.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07366v1", "AI": {"title_translation": "MoE-GPS：MoE负载均衡中动态专家复制的预测策略指南", "tldr": "MoE-GPS提出了一种预测策略，用于动态复制MoE中的专家以平衡负载，建议使用仅预测分布的方法，可将推理性能提高23%以上。", "motivation": "在多GPU专家混合（MoE）网络中，由于每个专家处理不同数量的tokens，导致负载不平衡。现有的MoE推理负载均衡方法通过动态复制热门专家来处理过多的tokens，但这需要在路由前预测token分布。本文旨在探讨不同预测策略的权衡，并指导选择最佳预测器设计以优化系统性能。", "method": "本文提出了MoE-GPS框架，该框架通过量化对系统级模型运行时的性能影响，指导在各种系统配置下选择最佳预测器设计。具体地，MoE-GPS倡导“仅分布预测”（Distribution-Only Prediction）策略，这种策略只预测整体token分布，与传统的“Token-to-Expert Prediction”相比，显著降低了开销。", "result": "在Mixtral 8x7B MMLU数据集上，MoE-GPS建议使用“仅分布预测”策略，与“Token-to-Expert Prediction”相比，端到端推理性能提升了23%以上。", "conclusion": "MoE-GPS框架为MoE负载均衡中的动态专家复制提供了有效的预测策略选择指南，特别是其推荐的“仅分布预测”策略能够显著提高端到端推理性能。", "translation": "在多GPU专家混合（MoE）网络中，专家分布在不同的GPU上，由于每个专家处理不同数量的tokens，这会造成负载不平衡。最近的工作通过将热门专家动态复制到更多GPU来处理过多的tokens，从而改善MoE推理负载平衡，这需要在路由前预测分布。在本文中，我们讨论了预测策略、准确性、开销和端到端系统性能之间的权衡。我们提出了MoE-GPS，一个通过量化对系统级模型运行时的性能影响来指导在各种系统配置下选择最佳预测器设计的框架。具体来说，我们提倡“仅分布预测”，这是一种只预测整体token分布的预测策略，与传统的“Token-to-Expert Prediction”相比，显著降低了开销。在Mixtral 8x7B MMLU数据集上，MoE-GPS建议使用“仅分布预测”，与“Token-to-Expert Prediction”相比，端到端推理性能提高了23%以上。", "summary": "本文针对多GPU专家混合（MoE）网络中的负载不平衡问题，提出了MoE-GPS框架。该框架旨在通过量化对系统级模型运行时的性能影响，指导选择最优的动态专家复制预测策略。研究发现，MoE-GPS提倡的“仅分布预测”策略（只预测整体token分布）相比传统方法显著降低了开销，并在Mixtral 8x7B MMLU数据集上将端到端推理性能提升了23%以上，从而有效改善MoE模型的推理负载平衡。", "keywords": "MoE, 负载均衡, 专家混合, 预测策略, GPU推理", "comments": "该论文提出MoE-GPS框架以解决MoE模型在多GPU环境下的负载不平衡问题，其创新点在于提出了“仅分布预测”这一高效策略，显著降低了预测开销并提升了推理性能。这对于优化大型MoE模型的部署和运行效率具有重要意义，尤其是在资源受限或对延迟敏感的场景下。"}}
{"id": "2506.07190", "title": "A Simulation-based Evaluation Framework for Inter-VM RowHammer Mitigation Techniques", "authors": ["Hidemasa Kawasaki", "Soramichi Akiyama"], "summary": "Inter-VM RowHammer is an attack that induces a bitflip beyond the boundaries\nof virtual machines (VMs) to compromise a VM from another, and some\nsoftware-based techniques have been proposed to mitigate this attack.\nEvaluating these mitigation techniques requires to confirm that they actually\nmitigate inter-VM RowHammer in low overhead. A challenge in this evaluation\nprocess is that both the mitigation ability and the overhead depend on the\nunderlying hardware whose DRAM address mappings are different from machine to\nmachine. This makes comprehensive evaluation prohibitively costly or even\nimplausible as no machine that has a specific DRAM address mapping might be\navailable. To tackle this challenge, we propose a simulation-based framework to\nevaluate software-based inter-VM RowHammer mitigation techniques across\nconfigurable DRAM address mappings. We demonstrate how to reproduce existing\nmitigation techniques on our framework, and show that it can evaluate the\nmitigation abilities and performance overhead of them with configurable DRAM\naddress mappings.", "comment": "Presented in Fifth Workshop on DRAM Security (DRAMSec), June 21, 2025", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07190v1", "AI": {"title_translation": "基于仿真的虚拟机间RowHammer缓解技术评估框架", "tldr": "由于硬件依赖性，评估虚拟机间RowHammer缓解技术很困难；本文提出了一个仿真框架，可以在各种DRAM映射下进行评估。", "motivation": "现有虚拟机间RowHammer缓解技术的评估成本高昂或不可行，因为缓解能力和开销取决于特定且不同的硬件DRAM地址映射，这使得全面评估变得困难。", "method": "本文提出了一种基于仿真的框架，用于评估可配置DRAM地址映射下的基于软件的虚拟机间RowHammer缓解技术。他们展示了如何在框架上重现现有技术。", "result": "该框架能够评估具有可配置DRAM地址映射的技术的缓解能力和性能开销。", "conclusion": "所提出的基于仿真的框架通过允许可配置的DRAM地址映射，有效地解决了评估虚拟机间RowHammer缓解技术的挑战，从而能够全面评估其缓解能力和开销。", "translation": "虚拟机间RowHammer是一种跨越虚拟机(VM)边界诱发位翻转以从一个虚拟机攻击另一个虚拟机的攻击，并且已经提出了一些基于软件的技术来缓解这种攻击。评估这些缓解技术需要确认它们确实以低开销缓解了虚拟机间RowHammer。这个评估过程中的一个挑战是，缓解能力和开销都取决于底层硬件，其DRAM地址映射在不同机器上是不同的。这使得全面评估成本过高甚至不可行，因为可能无法获得具有特定DRAM地址映射的机器。为了解决这个挑战，我们提出了一种基于仿真的框架，用于评估可配置DRAM地址映射下的基于软件的虚拟机间RowHammer缓解技术。我们展示了如何在我们的框架上重现现有的缓解技术，并表明它可以通过可配置的DRAM地址映射评估它们的缓解能力和性能开销。", "summary": "本文解决了评估虚拟机间RowHammer缓解技术的挑战，该挑战因硬件依赖的DRAM地址映射而复杂化。它提出了一个基于仿真的框架，允许可配置的DRAM地址映射，从而能够全面评估基于软件的缓解技术的有效性和性能开销，克服了硬件特定评估的局限性。", "keywords": "虚拟机间RowHammer, 缓解, 仿真, DRAM, 评估框架", "comments": "该框架为系统安全领域的一个重要评估挑战提供了实用的解决方案，使研究人员能够更高效、更全面地测试RowHammer缓解措施，而无需特定的硬件配置。其可配置性是关键创新。"}}
{"id": "2506.07755", "title": "Deep Equivariant Multi-Agent Control Barrier Functions", "authors": ["Nikolaos Bousias", "Lars Lindemann", "George Pappas"], "summary": "With multi-agent systems increasingly deployed autonomously at scale in\ncomplex environments, ensuring safety of the data-driven policies is critical.\nControl Barrier Functions have emerged as an effective tool for enforcing\nsafety constraints, yet existing learning-based methods often lack in\nscalability, generalization and sampling efficiency as they overlook inherent\ngeometric structures of the system. To address this gap, we introduce\nsymmetries-infused distributed Control Barrier Functions, enforcing the\nsatisfaction of intrinsic symmetries on learnable graph-based safety\ncertificates. We theoretically motivate the need for equivariant\nparametrization of CBFs and policies, and propose a simple, yet efficient and\nadaptable methodology for constructing such equivariant group-modular networks\nvia the compatible group actions. This approach encodes safety constraints in a\ndistributed data-efficient manner, enabling zero-shot generalization to larger\nand denser swarms. Through extensive simulations on multi-robot navigation\ntasks, we demonstrate that our method outperforms state-of-the-art baselines in\nterms of safety, scalability, and task success rates, highlighting the\nimportance of embedding symmetries in safe distributed neural policies.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07755v1", "AI": {"title_translation": "深度等变多智能体控制障碍函数", "tldr": "本文提出了一种融入对称性的分布式控制障碍函数（symmetries-infused distributed Control Barrier Functions），通过利用系统固有几何结构，解决了现有学习型控制障碍函数在多智能体系统安全方面面临的可伸缩性、泛化性和采样效率不足的问题。该方法在多机器人导航任务中表现出色，实现了零样本泛化，并在安全性、可伸缩性和任务成功率方面优于现有基线。", "motivation": "现有基于学习的控制障碍函数（CBF）方法在可伸缩性、泛化性和采样效率方面不足，因为它们忽略了系统固有的几何结构，这在复杂环境中大规模部署多智能体系统时，确保数据驱动策略的安全性是一个关键挑战。", "method": "引入了融入对称性的分布式控制障碍函数，通过强制在可学习的基于图的安全证书上满足内在对称性。该方法理论上论证了CBF和策略进行等变参数化的必要性，并提出了一种简单、高效且适应性强的方法，通过兼容群作用来构建等变群模块化网络，以分布式、数据高效的方式编码安全约束。", "result": "在多机器人导航任务的广泛模拟中，该方法在安全性、可伸缩性和任务成功率方面优于最先进的基线，并能够对更大、更密集的群体进行零样本泛化。", "conclusion": "强调了在安全分布式神经策略中嵌入对称性的重要性。", "translation": "随着多智能体系统在复杂环境中大规模自主部署，确保数据驱动策略的安全性至关重要。控制障碍函数已成为强制执行安全约束的有效工具，然而，现有的基于学习的方法往往缺乏可伸缩性、泛化性和采样效率，因为它们忽略了系统固有的几何结构。为了弥补这一空白，我们引入了融入对称性的分布式控制障碍函数，强制在可学习的基于图的安全证书上满足内在对称性。我们从理论上阐述了CBF和策略进行等变参数化的必要性，并提出了一种简单、高效且适应性强的方法，通过兼容群作用来构建此类等变群模块化网络。这种方法以分布式、数据高效的方式编码安全约束，能够对更大、更密集的群体进行零样本泛化。通过在多机器人导航任务上的广泛模拟，我们证明了我们的方法在安全性、可伸缩性和任务成功率方面优于最先进的基线，突出了在安全分布式神经策略中嵌入对称性的重要性。", "summary": "本文提出了一种名为“融入对称性的分布式控制障碍函数”（symmetries-infused distributed Control Barrier Functions）的新方法，旨在解决现有学习型控制障碍函数在多智能体系统安全方面存在的扩展性、泛化性和采样效率不足的问题。通过利用系统固有的几何对称性，并构建等变群模块化网络，该方法能够以分布式且数据高效的方式编码安全约束，并实现了对更大、更密集群体的零样本泛化。实验结果表明，该方法在多机器人导航任务中，在安全性、可伸缩性和任务成功率方面均优于现有基线。", "keywords": "控制障碍函数, 多智能体系统, 对称性, 等变神经网络, 安全性", "comments": "这篇论文的创新点在于将群对称性（group symmetries）的概念引入到多智能体控制障碍函数（CBF）的设计中，解决了传统学习型CBF方法在可伸缩性和泛化性方面的局限。通过理论分析和实际仿真，证明了利用等变参数化可以显著提升多智能体系统的安全性和任务成功率，特别是在零样本泛化到更大规模群体方面表现出色。这项工作强调了在设计安全分布式神经策略时，考虑并嵌入系统内在几何结构的重要性，对于未来大规模自主多智能体系统的安全部署具有重要意义。"}}
{"id": "2506.06677", "title": "RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation", "authors": ["Songhao Han", "Boxiang Qiu", "Yue Liao", "Siyuan Huang", "Chen Gao", "Shuicheng Yan", "Si Liu"], "summary": "Recent advances in vision-language models (VLMs) have enabled\ninstruction-conditioned robotic systems with improved generalization. However,\nmost existing work focuses on reactive System 1 policies, underutilizing VLMs'\nstrengths in semantic reasoning and long-horizon planning. These System 2\ncapabilities-characterized by deliberative, goal-directed thinking-remain under\nexplored due to the limited temporal scale and structural complexity of current\nbenchmarks. To address this gap, we introduce RoboCerebra, a benchmark for\nevaluating high-level reasoning in long-horizon robotic manipulation.\nRoboCerebra includes: (1) a large-scale simulation dataset with extended task\nhorizons and diverse subtask sequences in household environments; (2) a\nhierarchical framework combining a high-level VLM planner with a low-level\nvision-language-action (VLA) controller; and (3) an evaluation protocol\ntargeting planning, reflection, and memory through structured System 1-System 2\ninteraction. The dataset is constructed via a top-down pipeline, where GPT\ngenerates task instructions and decomposes them into subtask sequences. Human\noperators execute the subtasks in simulation, yielding high-quality\ntrajectories with dynamic object variations. Compared to prior benchmarks,\nRoboCerebra features significantly longer action sequences and denser\nannotations. We further benchmark state-of-the-art VLMs as System 2 modules and\nanalyze their performance across key cognitive dimensions, advancing the\ndevelopment of more capable and generalizable robotic planners.", "comment": "23 pages, 18 figures", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06677v1", "AI": {"title_translation": "RoboCerebra：一个用于长周期机器人操纵评估的大规模基准", "tldr": "引入RoboCerebra，一个大规模基准，用于评估长周期机器人操纵中的高级推理和System 2能力，通过数据集、分层框架和评估协议来弥补现有基准的不足。", "motivation": "现有机器人操纵基准主要关注反应式System 1策略，未能充分利用视觉语言模型（VLMs）在语义推理和长周期规划（System 2能力）方面的优势，因为其时间尺度有限且结构复杂性不足。", "method": "引入RoboCerebra基准，用于评估长周期机器人操纵中的高级推理。它包括：1) 一个大规模模拟数据集，具有扩展的任务周期和多样的子任务序列；2) 一个结合高级VLM规划器和低级VLA控制器的分层框架；3) 一个通过结构化System 1-System 2交互来评估规划、反思和记忆的评估协议。数据集通过GPT生成任务指令并分解为子任务序列，由人类操作员在模拟中执行以生成高质量轨迹。", "result": "RoboCerebra与现有基准相比，具有显著更长的动作序列和更密集的注释。该研究还对最先进的VLMs作为System 2模块进行了基准测试，并分析了它们在关键认知维度上的性能。", "conclusion": "RoboCerebra基准通过提供更长周期、更复杂的数据集和评估协议，促进了更强大和更通用机器人规划器的发展，尤其是在高级推理和System 2能力方面。", "translation": "视觉语言模型（VLMs）的最新进展使得指令驱动的机器人系统具有更好的泛化能力。然而，大多数现有工作侧重于反应式System 1策略，未能充分利用VLMs在语义推理和长周期规划方面的优势。这些System 2能力——以深思熟虑、目标导向的思维为特征——由于当前基准的时间尺度有限和结构复杂性不足而未得到充分探索。为了弥补这一空白，我们引入了RoboCerebra，这是一个用于评估长周期机器人操纵中高级推理的基准。RoboCerebra包括：(1) 一个大规模模拟数据集，具有扩展的任务周期和家庭环境中多样化的子任务序列；(2) 一个结合高级VLM规划器和低级视觉语言动作（VLA）控制器的分层框架；以及 (3) 一个通过结构化System 1-System 2交互来评估规划、反思和记忆的评估协议。该数据集通过自上而下的流程构建，其中GPT生成任务指令并将其分解为子任务序列。人类操作员在模拟中执行子任务，从而生成具有动态对象变化的高质量轨迹。与现有基准相比，RoboCerebra具有显著更长的动作序列和更密集的注释。我们进一步将最先进的VLMs作为System 2模块进行基准测试，并分析了它们在关键认知维度上的性能，从而推动了更强大和更通用机器人规划器的发展。", "summary": "本文介绍了RoboCerebra，一个旨在弥补现有机器人基准在评估视觉语言模型（VLMs）长周期规划和高级推理（System 2能力）方面不足的大规模基准。RoboCerebra提供了一个包含长任务周期和复杂子任务序列的模拟数据集，一个结合VLM规划器和VLA控制器的分层框架，以及一个评估规划、反思和记忆的协议。通过使用GPT生成任务并由人类操作员执行子任务来构建数据集，RoboCerebra提供了比现有基准更长的动作序列和更密集的注释。研究还利用RoboCerebra对最先进的VLMs进行了基准测试，以促进更强大和更通用机器人规划器的发展。", "keywords": "机器人操纵, 视觉语言模型, 基准, 长周期规划, System 2能力", "comments": "RoboCerebra的创新之处在于其专注于机器人操纵中的System 2能力，即长周期规划和语义推理，这与现有基准主要关注System 1反应式策略形成对比。其大规模、高复杂度的模拟数据集和分层评估框架对于推动VLM在机器人领域更高级、更通用应用的发展至关重要。通过结合GPT生成任务和人类操作员执行来构建数据集，确保了数据质量和多样性。"}}
{"id": "2506.06712", "title": "Active Contour Models Driven by Hyperbolic Mean Curvature Flow for Image Segmentation", "authors": ["Saiyu Hu", "Chunlei He", "Jianfeng Zhang", "Dexing Kong", "Shoujun Huang"], "summary": "Parabolic mean curvature flow-driven active contour models (PMCF-ACMs) are\nwidely used in image segmentation, which however depend heavily on the\nselection of initial curve configurations. In this paper, we firstly propose\nseveral hyperbolic mean curvature flow-driven ACMs (HMCF-ACMs), which introduce\ntunable initial velocity fields, enabling adaptive optimization for diverse\nsegmentation scenarios. We shall prove that HMCF-ACMs are indeed normal flows\nand establish the numerical equivalence between dissipative HMCF formulations\nand certain wave equations using the level set method with signed distance\nfunction. Building on this framework, we furthermore develop hyperbolic\ndual-mode regularized flow-driven ACMs (HDRF-ACMs), which utilize smooth\nHeaviside functions for edge-aware force modulation to suppress over-diffusion\nnear weak boundaries. Then, we optimize a weighted fourth-order Runge-Kutta\nalgorithm with nine-point stencil spatial discretization when solving the\nabove-mentioned wave equations. Experiments show that both HMCF-ACMs and\nHDRF-ACMs could achieve more precise segmentations with superior noise\nresistance and numerical stability due to task-adaptive configurations of\ninitial velocities and initial contours.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06712v1", "AI": {"title_translation": "双曲平均曲率流驱动的主动轮廓模型用于图像分割", "tldr": "本文提出了基于双曲平均曲率流的主动轮廓模型（HMCF-ACMs）和双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），通过引入可调初始速度场和边缘感知力调制，显著提高了图像分割的精度、抗噪性和数值稳定性，解决了传统抛物线模型对初始曲线配置依赖性强的问题。", "motivation": "传统的抛物线平均曲率流驱动的主动轮廓模型（PMCF-ACMs）在图像分割中广泛使用，但其结果严重依赖于初始曲线配置的选择。本文旨在解决这一局限性。", "method": "1. 提出了几种双曲平均曲率流驱动的主动轮廓模型（HMCF-ACMs），引入可调初始速度场以实现自适应优化。2. 证明了HMCF-ACMs确实是法向流，并利用带符号距离函数的水平集方法建立了耗散型HMCF公式与某些波动方程之间的数值等价性。3. 在此基础上，开发了双曲双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），利用平滑Heaviside函数进行边缘感知力调制，以抑制弱边界附近的过度扩散。4. 优化了使用九点模板空间离散化的加权四阶Runge-Kutta算法来求解波动方程。", "result": "实验表明，HMCF-ACMs和HDRF-ACMs由于初始速度和初始轮廓的任务自适应配置，能够实现更精确的分割，并具有卓越的抗噪性和数值稳定性。", "conclusion": "本文提出的基于双曲平均曲率流的主动轮廓模型（HMCF-ACMs）和双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），通过引入可调初始速度场和边缘感知力调制，显著提高了图像分割的精度、抗噪性和数值稳定性。", "translation": "抛物线平均曲率流驱动的主动轮廓模型（PMCF-ACMs）在图像分割中广泛使用，但其结果严重依赖于初始曲线配置的选择。在本文中，我们首先提出了几种双曲平均曲率流驱动的主动轮廓模型（HMCF-ACMs），它们引入了可调的初始速度场，从而能够对不同的分割场景进行自适应优化。我们将证明HMCF-ACMs确实是法向流，并利用带符号距离函数的水平集方法建立了耗散型HMCF公式与某些波动方程之间的数值等价性。在此框架的基础上，我们进一步开发了双曲双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），它们利用平滑的Heaviside函数进行边缘感知力调制，以抑制弱边界附近的过度扩散。然后，我们在求解上述波动方程时，优化了一个使用九点模板空间离散化的加权四阶Runge-Kutta算法。实验表明，HMCF-ACMs和HDRF-ACMs由于初始速度和初始轮廓的任务自适应配置，能够实现更精确的分割，并具有卓越的抗噪性和数值稳定性。", "summary": "本文针对传统抛物线平均曲率流驱动的主动轮廓模型对初始曲线配置依赖性强的问题，提出了一种基于双曲平均曲率流的新型主动轮廓模型（HMCF-ACMs）及其扩展模型（HDRF-ACMs）。HMCF-ACMs引入了可调初始速度场以实现自适应优化，并被证明是法向流。HDRF-ACMs则通过平滑Heaviside函数进行边缘感知力调制，以抑制弱边界处的过度扩散。研究还建立了耗散型HMCF公式与波动方程的数值等价性，并优化了求解算法。实验结果验证了所提模型在图像分割中具有更高的精度、更强的抗噪性和更好的数值稳定性。", "keywords": "主动轮廓模型, 双曲平均曲率流, 图像分割, 水平集方法, 双模式正则化流", "comments": "本文的创新点在于将双曲平均曲率流引入主动轮廓模型，并通过引入可调初始速度场和边缘感知力调制，有效解决了传统模型对初始初始曲线配置的强依赖性问题，并提升了在复杂图像分割场景下的性能。其理论分析和数值实现优化也为后续研究提供了基础。"}}
{"id": "2506.06725", "title": "WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making", "authors": ["Guillaume Levy", "Cedric Colas", "Pierre-Yves Oudeyer", "Thomas Carta", "Clement Romac"], "summary": "Large Language Models (LLMs) possess general world knowledge but often\nstruggle to generate precise predictions in structured, domain-specific\ncontexts such as simulations. These limitations arise from their inability to\nground their broad, unstructured understanding in specific environments. To\naddress this, we present WorldLLM, a framework that enhances LLM-based world\nmodeling by combining Bayesian inference and autonomous active exploration with\nreinforcement learning. WorldLLM leverages the in-context learning abilities of\nLLMs to guide an LLM-based world model's predictions using natural language\nhypotheses given in its prompt. These hypotheses are iteratively refined\nthrough a Bayesian inference framework that leverages a second LLM as the\nproposal distribution given collected evidence. This evidence is collected\nusing a curiosity-driven reinforcement learning policy that explores the\nenvironment to find transitions with a low log-likelihood under our LLM-based\npredictive model using the current hypotheses. By alternating between refining\nhypotheses and collecting new evidence, our framework autonomously drives\ncontinual improvement of the predictions. Our experiments demonstrate the\neffectiveness of WorldLLM in a textual game environment that requires agents to\nmanipulate and combine objects. The framework not only enhances predictive\naccuracy, but also generates human-interpretable theories of environment\ndynamics.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06725v1", "AI": {"title_translation": "WorldLLM：通过好奇心驱动的理论构建改进LLM的世界建模", "tldr": "WorldLLM框架结合贝叶斯推理、主动探索和强化学习，通过迭代细化假设和收集证据，显著提高了LLM在结构化领域环境中的预测精度和可解释性。", "motivation": "大型语言模型（LLM）虽然拥有通用世界知识，但在结构化、特定领域（如模拟）中生成精确预测时表现不佳，因为它们无法将其广泛的非结构化理解与特定环境相结合。", "method": "WorldLLM框架通过结合贝叶斯推理和自主主动探索与强化学习来增强基于LLM的世界建模。它利用LLM的上下文学习能力，通过自然语言假设指导LLM世界模型的预测。这些假设通过一个贝叶斯推理框架迭代细化，该框架使用第二个LLM作为给定收集到的证据的提议分布。证据通过好奇心驱动的强化学习策略收集，该策略探索环境以找到在当前假设下LLM预测模型中对数似然较低的转换。通过交替细化假设和收集新证据，框架自主地推动预测的持续改进。", "result": "在文本游戏环境中的实验证明，WorldLLM不仅提高了预测精度，而且生成了人类可解释的环境动态理论。", "conclusion": "WorldLLM通过结合贝叶斯推理和强化学习，有效解决了LLM在结构化环境中精确预测的局限性，并能生成可解释的理论，从而持续改进其世界建模能力。", "translation": "大型语言模型（LLM）拥有通用世界知识，但在结构化、特定领域（如模拟）中生成精确预测时常常遇到困难。这些局限性源于它们无法将其广泛的、非结构化理解与特定环境相结合。为了解决这个问题，我们提出了WorldLLM，一个通过结合贝叶斯推理和自主主动探索与强化学习来增强基于LLM的世界建模的框架。WorldLLM利用LLM的上下文学习能力，通过提示中给出的自然语言假设来指导基于LLM的世界模型的预测。这些假设通过一个贝叶斯推理框架迭代细化，该框架利用第二个LLM作为给定收集到的证据的提议分布。这些证据通过一个好奇心驱动的强化学习策略收集，该策略探索环境以找到在当前假设下LLM预测模型中对数似然较低的转换。通过交替细化假设和收集新证据，我们的框架自主地推动预测的持续改进。我们的实验证明了WorldLLM在一个需要智能体操作和组合对象的文本游戏环境中的有效性。该框架不仅提高了预测精度，而且生成了人类可解释的环境动态理论。", "summary": "WorldLLM是一个旨在解决大型语言模型在结构化、特定领域环境中预测精度不足的框架。它通过结合贝叶斯推理和好奇心驱动的强化学习，利用两个LLM迭代地细化自然语言假设并收集环境证据。这种方法显著提高了LLM的预测准确性，并能生成可解释的环境动态理论。", "keywords": "LLM, 世界建模, 贝叶斯推理, 强化学习, 好奇心驱动", "comments": "WorldLLM的创新之处在于其将贝叶斯推理、强化学习和两个LLM的协同作用结合起来，以实现好奇心驱动的理论构建和预测改进。其能够生成人类可解释的环境动态理论是一个重要的优势，有助于提高LLM在复杂环境中的透明度和可靠性。"}}
{"id": "2506.06357", "title": "Cascaded Multiwire-PLC/Multiple-VLC System: Characterization and Performance", "authors": ["Hugerles S. Silva", "Higo T. P. Silva", "Paulo V. B. Tomé", "Felipe A. P. Figueiredo", "Edson P. da Silva", "Rausley A. A. de Souza"], "summary": "This paper proposes a cascaded multiwire-power line communication\n(PLC)/multiple-visible light communication (VLC) system. This hybrid\narchitecture offers low installation cost, enhanced performance, practical\nfeasibility, and a wide range of applications. Novel analytical expressions are\nderived for key statistics and outage probability, bit error probability, and\nergodic channel capacity metrics. Furthermore, the analytical results are\nvalidated through Monte Carlo simulations, with several performance curves\npresented under various channel and PLC/VLC system parameters. All expressions\nderived in this work are original and have not been previously published. Our\nproposed system proves feasible for smart environments, green communication\nsystems, internet of things networks, industrial environments, and\nnext-generation networks.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06357v1", "AI": {"title_translation": "级联多线电力线通信/多可见光通信系统：特性与性能", "tldr": "本文提出了一种级联多线电力线通信（PLC）/多可见光通信（VLC）混合系统，并通过推导原创分析表达式和蒙特卡洛仿真验证了其性能和在多种应用场景中的可行性。", "motivation": "该研究旨在提出一种具有低安装成本、增强性能、实用可行性及广泛应用范围的通信系统，以满足智能环境、物联网等下一代网络的需求。", "method": "本文提出了一种级联多线电力线通信（PLC）/多可见光通信（VLC）混合系统。通过推导关键统计数据、中断概率、误码概率和遍历信道容量指标的新颖分析表达式来表征系统性能。此外，利用蒙特卡洛仿真对分析结果进行了验证，并在各种信道和PLC/VLC系统参数下展示了性能曲线。", "result": "研究推导了关键统计数据、中断概率、误码概率和遍历信道容量的原创分析表达式。这些分析结果通过蒙特卡洛仿真得到了验证。结果表明，所提出的系统在智能环境、绿色通信系统、物联网网络、工业环境和下一代网络中均具有可行性。", "conclusion": "所提出的级联多线电力线通信/多可见光通信混合系统具有低安装成本、增强性能和广泛的应用前景，并已证明在智能环境、物联网网络和下一代网络等多种应用场景中是可行的。", "translation": "本文提出了一种级联多线电力线通信（PLC）/多可见光通信（VLC）系统。这种混合架构具有低安装成本、增强的性能、实际可行性和广泛的应用范围。文中推导了关键统计数据、中断概率、误码概率和遍历信道容量指标的新颖分析表达式。此外，分析结果通过蒙特卡洛仿真进行了验证，并在各种信道和PLC/VLC系统参数下展示了多条性能曲线。本工作中推导出的所有表达式都是原创的，以前从未发表过。我们提出的系统被证明在智能环境、绿色通信系统、物联网网络、工业环境和下一代网络中是可行的。", "summary": "本文提出并分析了一种级联多线电力线通信（PLC）/多可见光通信（VLC）混合系统。该系统旨在提供低安装成本、增强性能和广泛应用。研究通过推导原创的分析表达式来表征系统性能，并使用蒙特卡洛仿真验证了这些结果，证明了其在智能环境、绿色通信系统、物联网网络、工业环境和下一代网络等多种应用场景中的可行性。", "keywords": "电力线通信, 可见光通信, 混合系统, 性能分析, 级联系统", "comments": "该论文的创新之处在于提出了一个新型的级联多线电力线通信/多可见光通信混合系统架构，并首次推导了其关键性能指标的原创分析表达式，填补了该领域研究的空白。其提出的低成本、高性能和广泛应用前景的特点，使其在未来智能环境和物联网等领域具有重要应用潜力。"}}
{"id": "2506.06398", "title": "Theoretical Analysis of Positional Encodings in Transformer Models: Impact on Expressiveness and Generalization", "authors": ["Yin Li"], "summary": "Positional encodings are a core part of transformer-based models, enabling\nprocessing of sequential data without recurrence. This paper presents a\ntheoretical framework to analyze how various positional encoding methods,\nincluding sinusoidal, learned, relative, and bias-based methods like Attention\nwith Linear Biases (ALiBi), impact a transformer's expressiveness,\ngeneralization ability, and extrapolation to longer sequences. Expressiveness\nis defined via function approximation, generalization bounds are established\nusing Rademacher complexity, and new encoding methods based on orthogonal\nfunctions, such as wavelets and Legendre polynomials, are proposed. The\nextrapolation capacity of existing and proposed encodings is analyzed,\nextending ALiBi's biasing approach to a unified theoretical context.\nExperimental evaluation on synthetic sequence-to-sequence tasks shows that\northogonal transform-based encodings outperform traditional sinusoidal\nencodings in generalization and extrapolation. This work addresses a critical\ngap in transformer theory, providing insights for design choices in natural\nlanguage processing, computer vision, and other transformer applications.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06398v1", "AI": {"title_translation": "Transformer模型中位置编码的理论分析：对表达能力和泛化能力的影响", "tldr": "本文提出了一个理论框架，分析了各种位置编码方法（包括正弦、学习、相对和基于偏置的方法）如何影响Transformer模型的表达能力、泛化能力和外推能力，并提出了基于正交函数的新编码方法，实验证明其在泛化和外推方面优于传统方法。", "motivation": "现有Transformer理论在位置编码对模型性能影响方面存在空白，需要一个理论框架来分析不同位置编码方法对Transformer表达能力、泛化能力和序列外推能力的影响。", "method": "提出了一个理论框架，用于分析正弦、学习、相对和基于偏置（如ALiBi）等多种位置编码方法；通过函数逼近定义表达能力；使用Rademacher复杂度建立泛化界限；提出了基于正交函数（如小波和勒让德多项式）的新编码方法；分析了现有和提出的编码方法的外推能力，并将ALiBi的偏置方法扩展到统一的理论背景；在合成序列到序列任务上进行了实验评估。", "result": "基于正交变换的编码方法在泛化能力和序列外推方面优于传统的正弦编码方法。", "conclusion": "这项工作填补了Transformer理论中的一个关键空白，为自然语言处理、计算机视觉和其他Transformer应用中的设计选择提供了深入见解。", "translation": "位置编码是基于Transformer模型的核心组成部分，使得模型无需循环即可处理序列数据。本文提出了一个理论框架，用于分析各种位置编码方法，包括正弦、学习、相对和基于偏置的方法（如带有线性偏置的注意力机制ALiBi），如何影响Transformer的表达能力、泛化能力以及对更长序列的外推能力。表达能力通过函数逼近来定义，泛化界限通过Rademacher复杂度建立，并提出了基于正交函数（如小波和勒让德多项式）的新编码方法。本文分析了现有和提出的编码方法的外推能力，将ALiBi的偏置方法扩展到一个统一的理论背景。在合成序列到序列任务上的实验评估表明，基于正交变换的编码方法在泛化和外推方面优于传统的正弦编码。这项工作解决了Transformer理论中的一个关键空白，为自然语言处理、计算机视觉和其他Transformer应用中的设计选择提供了见解。", "summary": "本文提出了一个理论框架，深入分析了Transformer模型中不同位置编码方法（如正弦、学习、相对和基于偏置的方法）对其表达能力、泛化能力和序列外推能力的影响。研究定义了表达能力和泛化界限，并提出了基于正交函数（如小波和勒让德多项式）的新型位置编码。实验结果表明，这些正交变换编码在泛化和外推性能上优于传统的正弦编码，为Transformer模型的设计提供了重要的理论和实践指导。", "keywords": "位置编码, Transformer模型, 表达能力, 泛化能力, 正交函数", "comments": "这项研究通过建立一个全面的理论框架，系统地分析了不同位置编码对Transformer模型性能的关键影响，填补了该领域的一个理论空白。其提出的基于正交函数的新编码方法，并在实验中验证了其优越性，为Transformer模型在长序列处理和泛化能力方面提供了新的设计思路和优化方向，具有重要的理论和应用价值。"}}
{"id": "2506.06404", "title": "Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights", "authors": ["Sooyung Choi", "Jaehyeok Lee", "Xiaoyuan Yi", "Jing Yao", "Xing Xie", "JinYeong Bak"], "summary": "The application scope of Large Language Models (LLMs) continues to expand,\nleading to increasing interest in personalized LLMs that align with human\nvalues. However, aligning these models with individual values raises\nsignificant safety concerns, as certain values may correlate with harmful\ninformation. In this paper, we identify specific safety risks associated with\nvalue-aligned LLMs and investigate the psychological principles behind these\nchallenges. Our findings reveal two key insights. (1) Value-aligned LLMs are\nmore prone to harmful behavior compared to non-fine-tuned models and exhibit\nslightly higher risks in traditional safety evaluations than other fine-tuned\nmodels. (2) These safety issues arise because value-aligned LLMs genuinely\ngenerate text according to the aligned values, which can amplify harmful\noutcomes. Using a dataset with detailed safety categories, we find significant\ncorrelations between value alignment and safety risks, supported by\npsychological hypotheses. This study offers insights into the \"black box\" of\nvalue alignment and proposes in-context alignment methods to enhance the safety\nof value-aligned LLMs.", "comment": "Accepted to ACL 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06404v1", "AI": {"title_translation": "价值对齐大型语言模型的意外危害：心理学和实证洞察", "tldr": "本文揭示了价值对齐的大型语言模型（LLMs）可能无意中产生有害内容，甚至比未微调模型风险更高，因为它会真正地按照对齐的价值观生成文本，从而放大有害结果。", "motivation": "大型语言模型（LLMs）的应用范围不断扩大，人们对与人类价值观对齐的个性化LLMs越来越感兴趣。然而，将这些模型与个人价值观对齐引发了重大的安全担忧，因为某些价值观可能与有害信息相关联。", "method": "本文识别了与价值对齐LLMs相关的特定安全风险，并调查了这些挑战背后的心理学原理。研究使用了包含详细安全类别的数据集，并结合心理学假设来发现价值对齐与安全风险之间的显著关联。", "result": "研究发现两个关键洞察：(1) 价值对齐LLMs比未微调模型更容易产生有害行为，并且在传统安全评估中比其他微调模型表现出略高的风险。(2) 这些安全问题之所以出现，是因为价值对齐LLMs确实按照对齐的价值观生成文本，这会放大有害结果。研究发现了价值对齐与安全风险之间的显著关联。", "conclusion": "本研究深入探讨了价值对齐的“黑箱”，并提出了上下文对齐方法以增强价值对齐LLMs的安全性。", "translation": "大型语言模型（LLMs）的应用范围持续扩大，导致人们对与人类价值观对齐的个性化LLMs的兴趣日益增加。然而，将这些模型与个人价值观对齐引发了重大的安全担忧，因为某些价值观可能与有害信息相关联。在本文中，我们识别了与价值对齐LLMs相关的特定安全风险，并调查了这些挑战背后的心理学原理。我们的发现揭示了两个关键洞察。(1) 价值对齐LLMs比未微调模型更容易产生有害行为，并且在传统安全评估中比其他微调模型表现出略高的风险。(2) 这些安全问题之所以出现，是因为价值对齐LLMs确实按照对齐的价值观生成文本，这会放大有害结果。使用包含详细安全类别的数据集，我们发现价值对齐与安全风险之间存在显著关联，并得到了心理学假设的支持。这项研究为价值对齐的“黑箱”提供了洞察，并提出了上下文对齐方法以增强价值对齐LLMs的安全性。", "summary": "随着大型语言模型（LLMs）的普及，个性化和价值对齐的LLMs受到关注。然而，本文指出价值对齐可能带来意想不到的安全风险，因为某些价值观可能与有害信息相关。研究发现，价值对齐LLMs比未微调模型更容易产生有害内容，甚至比其他微调模型风险更高，原因在于它们会忠实地按照对齐的价值观生成文本，从而放大潜在的有害结果。通过详细的安全数据集和心理学假设，研究揭示了价值对齐与安全风险之间的显著关联，为理解价值对齐的“黑箱”提供了洞察，并提出了上下文对齐的安全增强方法。", "keywords": "价值对齐LLMs, 安全风险, 有害行为, 心理学洞察, 上下文对齐", "comments": "这篇论文揭示了价值对齐大型语言模型潜在的“双刃剑”效应，即为了追求个性化和价值观对齐，模型可能在无意中放大有害内容。其创新之处在于不仅从实证角度验证了这一风险，还深入探讨了其背后的心理学机制，并提出了“黑箱”洞察。这对于LLM的安全性和负责任的AI发展具有重要意义，提醒开发者在追求对齐的同时，必须警惕并解决随之而来的潜在危害。"}}
{"id": "2506.07200", "title": "Efficient RL-based Cache Vulnerability Exploration by Penalizing Useless Agent Actions", "authors": ["Kanato Nakanishi", "Soramichi Akiyama"], "summary": "Cache-timing attacks exploit microarchitectural characteristics to leak\nsensitive data, posing a severe threat to modern systems. Despite its severity,\nanalyzing the vulnerability of a given cache structure against cache-timing\nattacks is challenging. To this end, a method based on Reinforcement Learning\n(RL) has been proposed to automatically explore vulnerabilities for a given\ncache structure. However, a naive RL-based approach suffers from inefficiencies\ndue to the agent performing actions that do not contribute to the exploration.\nIn this paper, we propose a method to identify these useless actions during\ntraining and penalize them so that the agent avoids them and the exploration\nefficiency is improved. Experiments on 17 cache structures show that our\ntraining mechanism reduces the number of useless actions by up to 43.08%. This\nresulted in the reduction of training time by 28\\% in the base case and 4.84\\%\nin the geomean compared to a naive RL-based approach.", "comment": "Presented in Machine Learning for Computer Architecture and Systems\n  (MLArchSys), June 21, 2025", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07200v1", "AI": {"title_translation": "通过惩罚无用代理动作实现高效的基于强化学习的缓存漏洞探索", "tldr": "本文提出了一种通过惩罚强化学习代理在缓存漏洞探索中执行的无用动作来提高探索效率的方法，从而显著减少了训练时间和无用动作的数量。", "motivation": "分析给定缓存结构对抗缓存时序攻击的漏洞具有挑战性，而现有的基于强化学习的方法因代理执行无用动作而效率低下。", "method": "提出了一种在训练过程中识别并惩罚无用动作的方法，使代理避免这些动作，从而提高探索效率。", "result": "在17种缓存结构上的实验表明，该训练机制将无用动作的数量减少了高达43.08%，与朴素的基于强化学习的方法相比，训练时间在基本情况下减少了28%，几何平均减少了4.84%。", "conclusion": "通过惩罚无用代理动作，可以显著提高基于强化学习的缓存漏洞探索的效率，减少训练时间和无用动作的数量。", "translation": "缓存时序攻击利用微架构特性来泄露敏感数据，对现代系统构成严重威胁。尽管其严重性，分析给定缓存结构对抗缓存时序攻击的漏洞具有挑战性。为此，已经提出了一种基于强化学习（RL）的方法来自动探索给定缓存结构的漏洞。然而，朴素的基于RL的方法由于代理执行对探索没有贡献的动作而效率低下。在本文中，我们提出了一种在训练期间识别这些无用动作并惩罚它们的方法，以便代理避免它们并提高探索效率。在17种缓存结构上的实验表明，我们的训练机制将无用动作的数量减少了高达43.08%。与朴素的基于RL的方法相比，这导致训练时间在基本情况下减少了28%，几何平均减少了4.84%。", "summary": "本文提出了一种改进基于强化学习（RL）的缓存漏洞探索效率的方法。针对现有RL方法中代理执行无用动作导致效率低下的问题，该研究引入了一种机制，在训练过程中识别并惩罚这些无用动作，从而引导代理避免它们。实验结果表明，该方法显著减少了无用动作的数量和训练时间，证明了其在提高缓存漏洞分析效率方面的有效性。", "keywords": "缓存漏洞, 强化学习, 缓存时序攻击, 探索效率, 代理动作", "comments": "该论文通过引入对无用代理动作的惩罚机制，有效地解决了基于强化学习的缓存漏洞探索中存在的效率问题。这一创新点在于优化了RL代理的学习过程，使其更专注于有益的探索，从而显著缩短了训练时间，具有重要的实际应用价值。"}}
{"id": "2506.07756", "title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning", "authors": ["Mark Burgess"], "summary": "Some formal aspects of the Semantic Spacetime graph model are presented, with\nreference to its use for directed knowledge representations and process\nmodelling. A finite $\\gamma(3,4)$ representation is defined to form a closed\nset of operations that can scale to any degree of semantic complexity. The\nSemantic Spacetime postulates bring predictability with minimal constraints to\npathways in graphs. The ubiquitous appearance of absorbing states in any\npartial graph means that a graph process leaks information. The issue is\nclosely associated with the issue of division by zero, which signals a loss of\nclosure and the need for manual injection of remedial information. The Semantic\nSpacetime model (and its Promise Theory) origins help to clarify how such\nabsorbing states are associated with boundary information where intentionality\ncan enter.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07756v1", "AI": {"title_translation": "代理语义、语义时空与图形推理", "tldr": "本文介绍了语义时空图模型的形式方面，及其在有向知识表示和过程建模中的应用。它定义了一个有限的$\\gamma(3,4)$表示，以形成一个可扩展到任意语义复杂度的封闭操作集，并通过语义时空假设为图路径带来可预测性。论文还探讨了图过程中吸收态导致的信息泄漏问题，并将其与边界信息和意图性联系起来。", "motivation": "本文旨在介绍语义时空图模型的形式方面，并探讨其在有向知识表示和过程建模中的应用，特别是解决图过程中信息泄漏和吸收态的问题。", "method": "本文定义了一个有限的$\\gamma(3,4)$表示，用于形成一个封闭的操作集，并应用语义时空假设来为图中的路径提供可预测性。此外，它还参考了其与承诺理论（Promise Theory）的渊源来阐明吸收态。", "result": "语义时空假设以最小的约束带来了图路径的可预测性。任何部分图中普遍存在的吸收态意味着图过程会泄漏信息，这与除以零的问题密切相关，预示着封闭性的丧失以及需要手动注入补救信息。语义时空模型（及其承诺理论）的起源有助于阐明这些吸收态如何与意图性可以进入的边界信息相关联。", "conclusion": "语义时空模型及其承诺理论的起源有助于澄清吸收态如何与边界信息相关联，即意图性可以在这些边界信息处进入，从而解决图过程中信息泄漏和封闭性丧失的问题。", "translation": "本文介绍了语义时空图模型的一些形式方面，并参考其在有向知识表示和过程建模中的应用。定义了一个有限的$\\gamma(3,4)$表示，以形成一个可以扩展到任何语义复杂度的封闭操作集。语义时空假设以最小的约束为图中的路径带来了可预测性。任何部分图中普遍存在的吸收态意味着图过程会泄漏信息。这个问题与除以零的问题密切相关，后者标志着封闭性的丧失以及需要手动注入补救信息。语义时空模型（及其承诺理论）的起源有助于阐明这些吸收态如何与意图性可以进入的边界信息相关联。", "summary": "本文探讨了语义时空图模型的形式化方面及其在有向知识表示和过程建模中的应用。它引入了一个有限的$\\gamma(3,4)$表示来处理语义复杂度，并通过语义时空假设实现了图路径的可预测性。文章深入分析了图过程中吸收态导致的信息泄漏问题，将其与“除以零”的封闭性丧失联系起来，并指出语义时空模型（及其承诺理论）揭示了吸收态与意图性可以注入的边界信息之间的关联，从而为信息泄漏提供了补救机制。", "keywords": "语义时空, 图模型, 吸收态, 信息泄漏, 承诺理论", "comments": "本文提出了一个新颖的语义时空图模型，并引入了$\\gamma(3,4)$表示来处理复杂的语义。其创新之处在于将信息泄漏、吸收态与“除以零”的数学概念联系起来，并引入“意图性”作为补救机制，为图模型中的信息流和控制提供了独特视角。该模型在处理复杂知识表示和过程建模方面具有潜在的重要性。"}}
{"id": "2506.06683", "title": "RoboPARA: Dual-Arm Robot Planning with Parallel Allocation and Recomposition Across Tasks", "authors": ["Shiying Duan", "Pei Ren", "Nanxiang Jiang", "Zhengping Che", "Jian Tang", "Yifan Sun", "Zhaoxin Fan", "Wenjun Wu"], "summary": "Dual-arm robots play a crucial role in improving efficiency and flexibility\nin complex multitasking scenarios. While existing methods have achieved\npromising results in task planning, they often fail to fully optimize task\nparallelism, limiting the potential of dual-arm collaboration. To address this\nissue, we propose RoboPARA, a novel large language model (LLM)-driven framework\nfor dual-arm task parallelism planning. RoboPARA employs a two-stage process:\n(1) Dependency Graph-based Planning Candidates Generation, which constructs\ndirected acyclic graphs (DAGs) to model task dependencies and eliminate\nredundancy, and (2) Graph Re-Traversal-based Dual-Arm Parallel Planning, which\noptimizes DAG traversal to maximize parallelism while maintaining task\ncoherence. In addition, we introduce the Cross-Scenario Dual-Arm Parallel Task\ndataset (X-DAPT dataset), the first dataset specifically designed to evaluate\ndual-arm task parallelism across diverse scenarios and difficulty levels.\nExtensive experiments on the X-DAPT dataset demonstrate that RoboPARA\nsignificantly outperforms existing methods, achieving higher efficiency and\nreliability, particularly in complex task combinations. The code and dataset\nwill be released upon acceptance.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06683v1", "AI": {"title_translation": "RoboPARA: 双臂机器人规划与跨任务并行分配和重组", "tldr": "RoboPARA是一个由LLM驱动的框架，用于优化双臂机器人任务的并行性，通过两阶段规划和新数据集实现了更高的效率和可靠性。", "motivation": "现有方法在双臂机器人任务规划中未能充分优化任务并行性，限制了双臂协作的潜力。", "method": "提出RoboPARA框架，一个LLM驱动的双臂任务并行规划框架。它包括两个阶段：1) 基于依赖图的规划候选生成，构建有向无环图(DAG)以建模任务依赖并消除冗余；2) 基于图重遍历的双臂并行规划，优化DAG遍历以最大化并行性并保持任务连贯性。此外，引入了首个专门用于评估跨场景和难度级别双臂任务并行性的数据集X-DAPT。", "result": "在X-DAPT数据集上的大量实验表明，RoboPARA显著优于现有方法，尤其在复杂任务组合中，实现了更高的效率和可靠性。", "conclusion": "RoboPARA通过其创新的LLM驱动框架和优化的并行规划方法，显著提升了双臂机器人在复杂多任务场景下的效率和可靠性，解决了现有方法并行性不足的问题。", "translation": "双臂机器人在提高复杂多任务场景的效率和灵活性方面发挥着关键作用。尽管现有方法在任务规划方面取得了可喜的成果，但它们往往未能充分优化任务并行性，限制了双臂协作的潜力。为了解决这个问题，我们提出了RoboPARA，一个新颖的由大型语言模型（LLM）驱动的双臂任务并行规划框架。RoboPARA采用两阶段过程：(1) 基于依赖图的规划候选生成，该阶段构建有向无环图（DAG）以建模任务依赖并消除冗余；(2) 基于图重遍历的双臂并行规划，该阶段优化DAG遍历以最大化并行性同时保持任务连贯性。此外，我们引入了跨场景双臂并行任务数据集（X-DAPT数据集），这是第一个专门设计用于评估跨不同场景和难度级别的双臂任务并行性的数据集。在X-DAPT数据集上进行的广泛实验表明，RoboPARA显著优于现有方法，尤其在复杂任务组合中，实现了更高的效率和可靠性。代码和数据集将在论文被接受后发布。", "summary": "本文提出了RoboPARA，一个由大型语言模型（LLM）驱动的双臂机器人任务并行规划框架，旨在解决现有方法在优化任务并行性方面的不足。RoboPARA采用两阶段方法，包括基于依赖图的规划候选生成和基于图重遍历的双臂并行规划，以最大化任务并行性并保持连贯性。此外，研究团队还发布了首个专门用于评估双臂任务并行性的X-DAPT数据集。实验结果表明，RoboPARA在效率和可靠性方面显著优于现有方法，尤其在复杂任务组合中表现突出。", "keywords": "双臂机器人, 任务规划, 并行性, 大型语言模型, 数据集", "comments": "RoboPARA的创新之处在于其LLM驱动的双臂任务并行规划框架，以及引入了专门用于评估双臂任务并行性的X-DAPT数据集，这对于推动双臂机器人协作和多任务处理领域的发展具有重要意义。其两阶段规划方法有效地解决了任务并行性优化不足的问题，提升了双臂机器人在复杂场景下的表现。"}}
{"id": "2506.06821", "title": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "authors": ["Yuhan Cao", "Zian Chen", "Kun Quan", "Ziliang Zhang", "Yu Wang", "Xiaoning Dong", "Yeqi Feng", "Guanzhong He", "Jingcheng Huang", "Jianhao Li", "Yixuan Tan", "Jiafu Tang", "Yilin Tang", "Junlei Wu", "Qianyu Xiao", "Can Zheng", "Shouchen Zhou", "Yuxiang Zhu", "Yiming Huang", "Tian Xie", "Tianxing He"], "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode generation, capable of tackling complex tasks during inference. However,\nthe extent to which LLMs can be utilized for code checking or debugging through\ntest case generation remains largely unexplored. We investigate this problem\nfrom the perspective of competition-level programming (CP) programs and propose\nTCGBench, a Benchmark for (LLM generation of) Test Case Generators. This\nbenchmark comprises two tasks, aimed at studying the capabilities of LLMs in\n(1) generating valid test case generators for a given CP problem, and further\n(2) generating targeted test case generators that expose bugs in human-written\ncode. Experimental results indicate that while state-of-the-art LLMs can\ngenerate valid test case generators in most cases, most LLMs struggle to\ngenerate targeted test cases that reveal flaws in human code effectively.\nEspecially, even advanced reasoning models (e.g., o3-mini) fall significantly\nshort of human performance in the task of generating targeted generators.\nFurthermore, we construct a high-quality, manually curated dataset of\ninstructions for generating targeted generators. Analysis demonstrates that the\nperformance of LLMs can be enhanced with the aid of this dataset, by both\nprompting and fine-tuning.", "comment": "37 pages, 22 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06821v1", "AI": {"title_translation": "LLMs能否生成可靠的测试用例生成器？一项关于竞赛级编程问题的研究", "tldr": "大型语言模型（LLMs）在生成有效测试用例生成器方面表现良好，但在生成针对性测试用例以发现人类代码缺陷方面仍远低于人类水平。", "motivation": "尽管大型语言模型（LLMs）在代码生成方面展现出卓越能力，但其在通过测试用例生成进行代码检查或调试方面的潜力仍未被充分探索。", "method": "本研究提出了TCGBench，一个用于评估LLM生成测试用例生成器的基准。该基准包含两项任务：1) 为给定竞赛级编程问题生成有效的测试用例生成器；2) 生成能揭示人类编写代码错误的有针对性测试用例生成器。此外，研究构建了一个高质量、手动整理的指令数据集，并发现通过提示和微调可提升LLM性能。", "result": "实验结果表明，最先进的LLMs在大多数情况下可以生成有效的测试用例生成器。然而，大多数LLMs在有效生成揭示人类代码缺陷的有针对性测试用例方面存在困难，即使是先进的推理模型（如o3-mini）也远低于人类表现。分析还表明，利用构建的高质量数据集，LLM的性能可以通过提示和微调得到增强。", "conclusion": "LLMs在生成通用测试用例生成器方面有潜力，但在生成能够有效发现代码缺陷的针对性测试用例方面仍需显著改进，且当前表现远不及人类。高质量的数据集有助于提升LLMs在此方面的能力。", "translation": "大型语言模型（LLMs）在代码生成方面展现出卓越的能力，能够在推理过程中处理复杂的任务。然而，LLMs在多大程度上能够通过测试用例生成来用于代码检查或调试，这在很大程度上仍未被探索。我们从竞赛级编程（CP）程序的角度研究了这个问题，并提出了TCGBench，一个用于（LLM生成）测试用例生成器的基准。该基准包含两项任务，旨在研究LLMs在以下方面的能力：(1) 为给定的CP问题生成有效的测试用例生成器，以及进一步 (2) 生成有针对性的测试用例生成器，以揭示人类编写代码中的错误。实验结果表明，尽管最先进的LLMs在大多数情况下可以生成有效的测试用例生成器，但大多数LLMs在有效生成能够揭示人类代码缺陷的有针对性测试用例方面存在困难。特别是，即使是先进的推理模型（例如o3-mini）在生成有针对性的生成器任务中也远低于人类表现。此外，我们构建了一个高质量、手动整理的指令数据集，用于生成有针对性的生成器。分析表明，通过提示和微调，借助该数据集可以增强LLMs的性能。", "summary": "本研究探讨了大型语言模型（LLMs）在生成竞赛级编程问题测试用例生成器方面的能力。研究提出了TCGBench基准，用于评估LLMs生成有效及针对性测试用例生成器的性能。结果显示，LLMs能生成有效测试用例，但在发现人类代码缺陷的针对性测试用例生成方面表现不佳，远低于人类水平。研究还发现，通过高质量数据集进行提示和微调可以提升LLMs的性能。", "keywords": "大型语言模型, 测试用例生成, 竞赛级编程, 代码调试, TCGBench", "comments": "这篇论文创新性地将LLMs应用于竞赛级编程问题的测试用例生成，并区分了“有效”和“有针对性”两种生成任务，揭示了LLMs在发现代码缺陷方面的局限性。其提出的TCGBench基准和高质量数据集对于未来研究LLMs在代码调试和验证领域的应用具有重要意义。"}}
{"id": "2506.06719", "title": "Improving Wildlife Out-of-Distribution Detection: Africas Big Five", "authors": ["Mufhumudzi Muthivhi", "Jiahao Huo", "Fredrik Gustafsson", "Terence L. van Zyl"], "summary": "Mitigating human-wildlife conflict seeks to resolve unwanted encounters\nbetween these parties. Computer Vision provides a solution to identifying\nindividuals that might escalate into conflict, such as members of the Big Five\nAfrican animals. However, environments often contain several varied species.\nThe current state-of-the-art animal classification models are trained under a\nclosed-world assumption. They almost always remain overconfident in their\npredictions even when presented with unknown classes. This study investigates\nout-of-distribution (OOD) detection of wildlife, specifically the Big Five. To\nthis end, we select a parametric Nearest Class Mean (NCM) and a non-parametric\ncontrastive learning approach as baselines to take advantage of pretrained and\nprojected features from popular classification encoders. Moreover, we compare\nour baselines to various common OOD methods in the literature. The results show\nfeature-based methods reflect stronger generalisation capability across varying\nclassification thresholds. Specifically, NCM with ImageNet pre-trained features\nachieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over the\nbest OOD methods, respectively. The code can be found here\nhttps://github.com/pxpana/BIG5OOD", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06719v1", "AI": {"title_translation": "改进野生动物分布外检测：非洲五大动物", "tldr": "本研究旨在改进野生动物的分布外（OOD）检测，特别是针对非洲五大动物。通过使用基于特征的方法，特别是ImageNet预训练特征的NCM，实现了显著的性能提升，解决了现有分类模型在未知类别上过自信的问题。", "motivation": "为了解决人与野生动物冲突中识别潜在危险个体的需求，以及现有计算机视觉动物分类模型在“封闭世界”假设下对未知类别预测过于自信的局限性。", "method": "研究调查了野生动物的分布外（OOD）检测，特别是针对非洲五大动物。选择了参数化的最近类别均值（NCM）和非参数化的对比学习方法作为基线，利用预训练和投影的分类编码器特征。此外，将这些基线与文献中各种常见的OOD方法进行了比较。", "result": "结果表明，基于特征的方法在不同分类阈值下表现出更强的泛化能力。具体而言，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。", "conclusion": "基于特征的方法，特别是结合ImageNet预训练特征的NCM，能够有效提升野生动物的分布外检测性能，为缓解人与野生动物冲突提供了更可靠的解决方案。", "translation": "缓解人与野生动物冲突旨在解决双方之间不必要的遭遇。计算机视觉提供了一种识别可能升级为冲突的个体（例如非洲五大动物的成员）的解决方案。然而，环境通常包含多种不同的物种。当前最先进的动物分类模型是在封闭世界假设下训练的。即使遇到未知类别，它们几乎总是对其预测过于自信。本研究调查了野生动物的分布外（OOD）检测，特别是针对非洲五大动物。为此，我们选择了一种参数化的最近类别均值（NCM）和一种非参数化的对比学习方法作为基线，以利用来自流行分类编码器的预训练和投影特征。此外，我们将我们的基线与文献中各种常见的OOD方法进行了比较。结果表明，基于特征的方法在不同分类阈值下反映出更强的泛化能力。具体而言，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。代码可以在https://github.com/pxpana/BIG5OOD找到。", "summary": "本研究致力于改进野生动物的分布外（OOD）检测，以解决现有动物分类模型在面对未知物种时过度自信的问题，这对于缓解人与野生动物冲突至关重要。研究选取了最近类别均值（NCM）和对比学习作为基线方法，并与多种现有OOD方法进行比较。结果显示，基于特征的方法，特别是结合ImageNet预训练特征的NCM，在泛化能力上表现出色，并在多项OOD检测指标上取得了显著提升。", "keywords": "野生动物, 分布外检测, 非洲五大动物, 最近类别均值, 计算机视觉", "comments": "这篇论文解决了计算机视觉领域中一个重要的实际问题，即模型在未知类别上的泛化能力，这在野生动物监测等实际应用中尤为关键。其创新点在于将OOD检测应用于野生动物领域，并证明了基于特征的方法（特别是NCM结合预训练特征）的有效性。这项工作对于提高自动化野生动物监测系统的可靠性具有重要意义。"}}
{"id": "2506.06727", "title": "VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs", "authors": ["Can Li", "Ting Zhang", "Mei Wang", "Hua Huang"], "summary": "Large Multimodal Models (LMMs) have demonstrated remarkable problem-solving\ncapabilities across various domains. However, their ability to perform\nmathematical reasoning when answer options are represented as images--an\nessential aspect of multi-image comprehension--remains underexplored. To bridge\nthis gap, we introduce VisioMath, a benchmark designed to evaluate mathematical\nreasoning in multimodal contexts involving image-based answer choices.\nVisioMath comprises 8,070 images and 1,800 multiple-choice questions, where\neach answer option is an image, presenting unique challenges to existing LMMs.\nTo the best of our knowledge, VisioMath is the first dataset specifically\ntailored for mathematical reasoning in image-based-option scenarios, where\nfine-grained distinctions between answer choices are critical for accurate\nproblem-solving. We systematically evaluate state-of-the-art LMMs on VisioMath\nand find that even the most advanced models struggle with this task. Notably,\nGPT-4o achieves only 45.9% accuracy, underscoring the limitations of current\nmodels in reasoning over visually similar answer choices. By addressing a\ncrucial gap in existing benchmarks, VisioMath establishes a rigorous testbed\nfor future research, driving advancements in multimodal reasoning.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06727v1", "AI": {"title_translation": "VisioMath：LMMs中基于图像的数学推理基准测试", "tldr": "VisioMath是一个新基准，用于评估大型多模态模型在答案选项为图像时的数学推理能力，发现现有模型表现不佳。", "motivation": "大型多模态模型（LMMs）在解决问题方面表现出色，但当答案选项以图像形式呈现时，它们的数学推理能力（多图像理解的关键方面）仍未得到充分探索。为弥补这一空白，引入了VisioMath。", "method": "引入VisioMath，一个包含8,070张图像和1,800道多项选择题的基准，其中每个答案选项都是一张图像。系统评估了最先进的LMMs在VisioMath上的表现。", "result": "即使是最先进的模型也难以完成这项任务。GPT-4o的准确率仅为45.9%，这突显了当前模型在对视觉相似的答案选项进行推理时的局限性。", "conclusion": "VisioMath通过弥补现有基准中的关键空白，为未来的研究建立了严格的测试平台，推动了多模态推理的进步。", "translation": "大型多模态模型（LMMs）在各个领域都展现出卓越的问题解决能力。然而，当答案选项以图像形式呈现时，它们的数学推理能力——多图像理解的一个重要方面——仍未得到充分探索。为了弥补这一空白，我们引入了VisioMath，一个旨在评估涉及基于图像答案选项的多模态环境中数学推理能力的基准。VisioMath包含8,070张图像和1,800道多项选择题，其中每个答案选项都是一张图像，对现有LMMs提出了独特的挑战。据我们所知，VisioMath是第一个专门为基于图像选项场景中的数学推理量身定制的数据集，在此类场景中，答案选项之间的细微差别对于准确解决问题至关重要。我们系统地评估了VisioMath上最先进的LMMs，发现即使是最先进的模型也难以完成这项任务。值得注意的是，GPT-4o的准确率仅为45.9%，这突显了当前模型在对视觉相似的答案选项进行推理时的局限性。通过弥补现有基准中的关键空白，VisioMath为未来的研究建立了严格的测试平台，推动了多模态推理的进步。", "summary": "该论文介绍了VisioMath，一个新颖的基准数据集，旨在评估大型多模态模型（LMMs）在答案选项为图像时的数学推理能力。VisioMath包含8,070张图像和1,800道多项选择题，专门用于测试模型对视觉相似答案的细微区分能力。研究发现，即使是GPT-4o等最先进的LMMs，在此任务上的表现也差强人意，准确率仅为45.9%。VisioMath填补了现有基准的空白，为推动多模态推理研究提供了严格的测试平台。", "keywords": "多模态模型, 数学推理, 图像基准, VisioMath, LMMs", "comments": "该论文通过引入VisioMath基准，创新性地解决了大型多模态模型在处理基于图像答案的数学推理这一未充分探索的领域。它揭示了当前LMMs在区分视觉相似图像选项时的显著局限性，特别是GPT-4o的低准确率突显了未来研究的巨大潜力。VisioMath的重要性在于它为多模态推理领域提供了一个急需的、具有挑战性的测试平台，有望推动模型在更精细视觉理解方面的进步。"}}
{"id": "2506.06387", "title": "Model-based Neural Data Augmentation for sub-wavelength Radio Localization", "authors": ["Baptiste Chatelier", "Vincent Corlay", "Musa Furkan Keskin", "Matthieu Crussière", "Henk Wymeersch", "Luc Le Magoarou"], "summary": "The increasing deployment of large antenna arrays at base stations has\nsignificantly improved the spatial resolution and localization accuracy of\nradio-localization methods. However, traditional signal processing techniques\nstruggle in complex radio environments, particularly in scenarios dominated by\nnon line of sight (NLoS) propagation paths, resulting in degraded localization\naccuracy. Recent developments in machine learning have facilitated the\ndevelopment of machine learning-assisted localization techniques, enhancing\nlocalization accuracy in complex radio environments. However, these methods\noften involve substantial computational complexity during both the training and\ninference phases. This work extends the well-established fingerprinting-based\nlocalization framework by simultaneously reducing its memory requirements and\nimproving its accuracy. Specifically, a model-based neural network is used to\nlearn the location-to-channel mapping, and then serves as a generative neural\nchannel model. This generative model augments the fingerprinting comparison\ndictionary while reducing the memory requirements. The proposed method\noutperforms fingerprinting baselines by achieving sub-wavelength localization\naccuracy, even in NLoS environments. Remarkably, it offers an improvement by\nseveral orders of magnitude in localization accuracy, while simultaneously\nreducing memory requirements by an order of magnitude compared to classical\nfingerprinting methods.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06387v1", "AI": {"title_translation": "基于模型的神经数据增强用于亚波长无线电定位", "tldr": "该论文提出了一种基于模型的神经网络数据增强方法，显著提高了指纹识别无线电定位的精度并降低了内存需求，尤其在非视距（NLoS）环境中表现出色。", "motivation": "传统信号处理技术在复杂无线电环境（特别是NLoS路径主导的场景）中定位精度下降。现有的机器学习辅助定位方法虽然提高了精度，但在训练和推理阶段计算复杂度高。本文旨在同时减少指纹识别定位框架的内存需求并提高其精度。", "method": "该工作扩展了指纹识别定位框架，通过使用一个基于模型的神经网络来学习位置到信道的映射，并将其用作生成式神经信道模型。这个生成模型用于增强指纹识别的比较字典，同时降低内存需求。", "result": "所提出的方法在NLoS环境中实现了亚波长定位精度，优于传统的指纹识别基线方法。与经典指纹识别方法相比，定位精度提高了几个数量级，同时内存需求降低了一个数量级。", "conclusion": "该研究成功地通过引入基于模型的神经网络数据增强，显著提升了无线电定位的精度，特别是在挑战性的NLoS环境中，并同时有效地降低了内存消耗，为高精度、低开销的无线电定位提供了新的解决方案。", "translation": "基站大型天线阵列的日益部署显著提高了无线电定位方法的空间分辨率和定位精度。然而，传统的信号处理技术在复杂的无线电环境中，特别是在非视距（NLoS）传播路径占主导的场景中，表现不佳，导致定位精度下降。机器学习的最新发展促进了机器学习辅助定位技术的发展，提高了复杂无线电环境中的定位精度。然而，这些方法在训练和推理阶段通常涉及大量的计算复杂性。这项工作通过同时减少内存需求和提高精度来扩展了成熟的基于指纹识别的定位框架。具体来说，一个基于模型的神经网络被用来学习位置到信道的映射，然后作为生成式神经信道模型。这个生成模型在减少内存需求的同时增强了指纹识别的比较字典。所提出的方法优于指纹识别基线，即使在NLoS环境中也能实现亚波长定位精度。值得注意的是，与经典指纹识别方法相比，它在定位精度方面提供了几个数量级的改进，同时将内存需求降低了一个数量级。", "summary": "本文提出了一种新颖的基于模型的神经数据增强方法，用于亚波长无线电定位。通过使用一个学习位置到信道映射的生成式神经网络来增强指纹识别比较字典，该方法显著提高了在复杂NLoS环境中的定位精度，实现了亚波长级别，并且在定位精度方面提高了数个数量级，同时将内存需求降低了一个数量级，解决了传统方法在复杂环境中的局限性以及机器学习方法的高计算开销问题。", "keywords": "无线电定位, 神经网络数据增强, 指纹识别, 非视距, 亚波长", "comments": "这项工作创新性地将模型驱动的神经网络与传统的指纹识别定位框架相结合，通过生成式模型进行数据增强，有效解决了复杂无线电环境下定位精度和内存效率的矛盾。其在NLoS环境中实现亚波长精度的能力以及显著的内存优化，对于未来无线通信和定位技术的发展具有重要意义。"}}
{"id": "2506.06411", "title": "CoxNTF: A New Approach for Joint Clustering and Prediction in Survival Analysis", "authors": ["Paul Fogel", "Christophe Geissler", "George Luta"], "summary": "The interpretation of the results of survival analysis often benefits from\nlatent factor representations of baseline covariates. However, existing\nmethods, such as Nonnegative Matrix Factorization (NMF), do not incorporate\nsurvival information, limiting their predictive power. We present CoxNTF, a\nnovel approach that uses non-negative tensor factorization (NTF) to derive\nmeaningful latent representations that are closely associated with survival\noutcomes. CoxNTF constructs a weighted covariate tensor in which survival\nprobabilities derived from the Coxnet model are used to guide the tensorization\nprocess. Our results show that CoxNTF achieves survival prediction performance\ncomparable to using Coxnet with the original covariates, while providing a\nstructured and interpretable clustering framework. In addition, the new\napproach effectively handles feature redundancy, making it a powerful tool for\njoint clustering and prediction in survival analysis.", "comment": "7 pages, 3 figures, Conference on Lifetime Data Science 2025,\n  Brooklyn, New York, USA", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06411v1", "AI": {"title_translation": "CoxNTF：一种生存分析中联合聚类和预测的新方法", "tldr": "CoxNTF是一种新的非负张量分解方法，结合生存信息进行聚类和预测，性能与现有方法相当且更具解释性。", "motivation": "现有方法（如非负矩阵分解NMF）在生存分析中解释结果时，未融入生存信息，限制了其预测能力。", "method": "本文提出了CoxNTF，一种利用非负张量分解（NTF）来获得与生存结果密切相关的潜在表示的新方法。CoxNTF通过使用从Coxnet模型获得的生存概率来指导张量化过程，构建加权协变量张量。", "result": "CoxNTF在生存预测性能上与使用原始协变量的Coxnet相当，同时提供了一个结构化且可解释的聚类框架。此外，新方法有效处理了特征冗余。", "conclusion": "CoxNTF为生存分析中的联合聚类和预测提供了一个强大且有效的工具，兼具预测性能和解释性。", "translation": "生存分析结果的解释常常受益于基线协变量的潜在因子表示。然而，现有方法，例如非负矩阵分解（NMF），并未纳入生存信息，限制了其预测能力。我们提出了CoxNTF，这是一种新颖的方法，它利用非负张量分解（NTF）来推导与生存结果密切相关的有意义的潜在表示。CoxNTF构建了一个加权协变量张量，其中使用从Coxnet模型获得的生存概率来指导张量化过程。我们的结果表明，CoxNTF实现了与使用原始协变量的Coxnet相当的生存预测性能，同时提供了一个结构化且可解释的聚类框架。此外，这种新方法有效处理了特征冗余，使其成为生存分析中联合聚类和预测的强大工具。", "summary": "本文提出了CoxNTF，一种基于非负张量分解的新方法，用于生存分析中的联合聚类和预测。它通过将Coxnet模型的生存概率纳入协变量张量化过程，克服了现有方法未能整合生存信息的局限性。实验结果显示，CoxNTF在保持与传统Coxnet相当的预测性能的同时，提供了一个结构化、可解释的聚类框架，并能有效处理特征冗余。", "keywords": "生存分析, 非负张量分解, 联合聚类, 预测, CoxNTF", "comments": "CoxNTF的创新之处在于将生存信息融入非负张量分解过程，解决了现有潜在因子表示方法在生存分析中预测能力受限的问题。其提供的可解释聚类框架和处理特征冗余的能力，使其在生存分析领域具有重要的应用潜力。"}}
{"id": "2506.06690", "title": "SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game", "authors": ["Hao Wang", "Chengkai Hou", "Xianglong Li", "Yankai Fu", "Chenxuan Li", "Ning Chen", "Gaole Dai", "Jiaming Liu", "Tiejun Huang", "Shanghang Zhang"], "summary": "Learning to control high-speed objects in the real world remains a\nchallenging frontier in robotics. Table tennis serves as an ideal testbed for\nthis problem, demanding both rapid interception of fast-moving balls and\nprecise adjustment of their trajectories. This task presents two fundamental\nchallenges: it requires a high-precision vision system capable of accurately\npredicting ball trajectories, and it necessitates intelligent strategic\nplanning to ensure precise ball placement to target regions. The dynamic nature\nof table tennis, coupled with its real-time response requirements, makes it\nparticularly well-suited for advancing robotic control capabilities in\nfast-paced, precision-critical domains. In this paper, we present\nSpikePingpong, a novel system that integrates spike-based vision with imitation\nlearning for high-precision robotic table tennis. Our approach introduces two\nkey attempts that directly address the aforementioned challenges: SONIC, a\nspike camera-based module that achieves millimeter-level precision in\nball-racket contact prediction by compensating for real-world uncertainties\nsuch as air resistance and friction; and IMPACT, a strategic planning module\nthat enables accurate ball placement to targeted table regions. The system\nharnesses a 20 kHz spike camera for high-temporal resolution ball tracking,\ncombined with efficient neural network models for real-time trajectory\ncorrection and stroke planning. Experimental results demonstrate that\nSpikePingpong achieves a remarkable 91% success rate for 30 cm accuracy target\narea and 71% in the more challenging 20 cm accuracy task, surpassing previous\nstate-of-the-art approaches by 38% and 37% respectively. These significant\nperformance improvements enable the robust implementation of sophisticated\ntactical gameplay strategies, providing a new research perspective for robotic\ncontrol in high-speed dynamic tasks.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06690v1", "AI": {"title_translation": "脉冲乒乓：基于高频脉冲视觉的机器人学习，实现乒乓球游戏中精准击球", "tldr": "SpikePingpong系统利用20kHz脉冲相机和模仿学习，在乒乓球机器人中实现高精度击球，显著提高了目标区域击球的成功率。", "motivation": "控制现实世界中的高速物体是机器人领域的挑战。乒乓球是理想的测试平台，需要快速拦截高速球并精确调整轨迹。这面临两个挑战：高精度视觉系统预测球轨迹，以及智能战略规划以精确放置球到目标区域。", "method": "提出SpikePingpong系统，结合脉冲视觉和模仿学习。该系统包含两个模块：SONIC，一个基于脉冲相机的模块，通过补偿空气阻力、摩擦等不确定性实现毫米级球拍接触预测；IMPACT，一个战略规划模块，实现球的精确落点。系统使用20 kHz脉冲相机进行高时间分辨率球跟踪，并结合高效神经网络模型进行实时轨迹校正和击球规划。", "result": "SpikePingpong在30厘米精度目标区域任务中达到91%的成功率，在更具挑战性的20厘米精度任务中达到71%的成功率，分别超越现有最先进方法38%和37%。", "conclusion": "这些显著的性能提升使得复杂战术游戏策略的稳健实施成为可能，为高速动态任务中的机器人控制提供了新的研究视角。", "translation": "在现实世界中控制高速物体仍然是机器人领域的一个具有挑战性的前沿。乒乓球作为解决此问题的理想试验台，要求能够快速拦截高速移动的球并精确调整其轨迹。这项任务提出了两个基本挑战：它需要一个高精度视觉系统，能够准确预测球的轨迹；它还需要智能战略规划，以确保将球精确放置到目标区域。乒乓球的动态特性，加上其实时响应要求，使其特别适合于推进机器人控制在快节奏、对精度要求高的领域的能力。在本文中，我们提出了SpikePingpong，一个将基于脉冲的视觉与模仿学习相结合的新颖系统，用于高精度机器人乒乓球。我们的方法引入了两个直接解决上述挑战的关键尝试：SONIC，一个基于脉冲相机的模块，通过补偿空气阻力、摩擦等真实世界的不确定性，实现了球拍接触预测的毫米级精度；以及IMPACT，一个战略规划模块，能够将球精确放置到目标桌面区域。该系统利用20 kHz脉冲相机进行高时间分辨率的球跟踪，并结合高效的神经网络模型进行实时轨迹校正和击球规划。实验结果表明，SpikePingpong在30厘米精度目标区域任务中取得了91%的显著成功率，在更具挑战性的20厘米精度任务中取得了71%的成功率，分别超越了现有最先进方法38%和37%。这些显著的性能改进使得复杂战术游戏策略的稳健实施成为可能，为高速动态任务中的机器人控制提供了新的研究视角。", "summary": "本论文提出了SpikePingpong系统，旨在解决机器人控制高速物体的挑战，以乒乓球为例。该系统结合了20 kHz脉冲视觉和模仿学习，通过SONIC模块实现毫米级球拍接触预测，并通过IMPACT模块进行精确的战略规划。实验结果表明，SpikePingpong在30厘米和20厘米精度任务中分别达到了91%和71%的成功率，显著优于现有技术，为高速动态任务中的机器人控制提供了新的研究视角。", "keywords": "机器人学习, 乒乓球, 脉冲视觉, 高速控制, 精准击球", "comments": "本文创新性地将高频脉冲视觉与模仿学习相结合，解决了高速乒乓球机器人控制中的两大核心挑战：高精度轨迹预测和精确落点规划。通过引入SONIC和IMPACT模块，以及利用20kHz脉冲相机，系统在精度和成功率上取得了显著突破，大幅超越了现有技术。这为机器人控制在高速、高精度领域的应用开辟了新的可能性，特别是对于需要实时响应和复杂战术的游戏或工业场景具有重要意义。"}}
{"id": "2506.07389", "title": "Human Side of Smart Contract Fuzzing: An Empirical Study", "authors": ["Guanming Qiao", "Partha Protim Paul"], "summary": "Smart contract (SC) fuzzing is a critical technique for detecting\nvulnerabilities in blockchain applications. However, its adoption remains\nchallenging for practitioners due to fundamental differences between SCs and\ntraditional software systems. In this study, we investigate the challenges\npractitioners face when adopting SC fuzzing tools by conducting an inductive\ncontent analysis of 381 GitHub issues from two widely used SC fuzzers: Echidna\nand Foundry. Furthermore, we conducted a user study to examine how these\nchallenges affect different practitioner groups, SC developers, and traditional\nsoftware security professionals, and identify strategies practitioners use to\novercome them. We systematically categorize these challenges into a taxonomy\nbased on their nature and occurrence within the SC fuzzing workflow. Our\nfindings reveal domain-specific ease-of-use and usefulness challenges,\nincluding technical issues with blockchain emulation, and human issues with a\nlack of accessible documentation and process automation. Our results provide\nactionable insights for tool developers and researchers, guiding future\nimprovements in SC fuzzer tool design.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07389v1", "AI": {"title_translation": "智能合约模糊测试的人为因素：一项实证研究", "tldr": "本研究通过分析GitHub issues和用户研究，探讨了智能合约模糊测试工具在实际应用中面临的技术和人为挑战，并为工具设计改进提供了见解。", "motivation": "智能合约模糊测试是检测区块链应用漏洞的关键技术，但由于智能合约与传统软件系统之间的根本差异，其实际应用对从业者来说仍然充满挑战。本研究旨在调查从业者在采用智能合约模糊测试工具时所面临的挑战。", "method": "本研究通过对两个广泛使用的智能合约模糊测试工具（Echidna和Foundry）的381个GitHub issues进行归纳内容分析。此外，还进行了一项用户研究，以检查这些挑战如何影响不同的从业者群体（智能合约开发者和传统软件安全专业人员），并确定从业者克服这些挑战的策略。研究系统地将这些挑战分类。", "result": "研究发现领域特定的易用性和有用性挑战，包括区块链模拟的技术问题，以及缺乏可访问文档和流程自动化的人为问题。", "conclusion": "研究结果为工具开发者和研究人员提供了可操作的见解，指导未来智能合约模糊测试工具设计的改进。", "translation": "智能合约（SC）模糊测试是检测区块链应用程序漏洞的关键技术。然而，由于SC与传统软件系统之间的根本差异，其实际应用对从业者来说仍然充满挑战。在本研究中，我们通过对两个广泛使用的SC模糊测试器：Echidna和Foundry的381个GitHub issue进行归纳内容分析，调查了从业者在采用SC模糊测试工具时所面临的挑战。此外，我们还进行了一项用户研究，以检查这些挑战如何影响不同的从业者群体，即SC开发者和传统软件安全专业人员，并确定从业者克服这些挑战的策略。我们根据这些挑战的性质及其在SC模糊测试工作流程中的出现，将其系统地分类。我们的发现揭示了领域特定的易用性和有用性挑战，包括区块链模拟的技术问题，以及缺乏可访问文档和流程自动化的人为问题。我们的结果为工具开发者和研究人员提供了可操作的见解，指导未来SC模糊测试工具设计的改进。", "summary": "本研究通过分析GitHub issues和进行用户研究，深入探讨了智能合约模糊测试工具在实际应用中面临的挑战，特别关注了技术障碍（如区块链模拟）和人为因素（如文档不足和自动化缺乏）。研究结果旨在为智能合约模糊测试工具的设计改进提供指导，以提高其易用性和实用性，从而促进其在区块链安全领域的广泛应用。", "keywords": "智能合约模糊测试, 人为因素, 易用性, 区块链安全, 漏洞检测", "comments": "这项研究通过结合GitHub issue分析和用户研究，从“人为因素”的角度深入剖析了智能合约模糊测试工具的实际采用障碍，这对于传统上偏重技术的研究领域而言具有创新性。其发现的挑战，特别是关于文档和自动化方面的问题，为工具开发者提供了非常具体的改进方向，有助于弥合理论研究与实际应用之间的鸿沟，对提升智能合约模糊测试工具的实用性和普及性具有重要意义。"}}
{"id": "2506.06729", "title": "Mitigating Object Hallucination via Robust Local Perception Search", "authors": ["Zixian Gao", "Chao Yang", "Zhanhui Zhou", "Xing Xu", "Chaochao Lu"], "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have enabled\nthem to effectively integrate vision and language, addressing a variety of\ndownstream tasks. However, despite their significant success, these models\nstill exhibit hallucination phenomena, where the outputs appear plausible but\ndo not align with the content of the images. To mitigate this issue, we\nintroduce Local Perception Search (LPS), a decoding method during inference\nthat is both simple and training-free, yet effectively suppresses\nhallucinations. This method leverages local visual prior information as a value\nfunction to correct the decoding process. Additionally, we observe that the\nimpact of the local visual prior on model performance is more pronounced in\nscenarios with high levels of image noise. Notably, LPS is a plug-and-play\napproach that is compatible with various models. Extensive experiments on\nwidely used hallucination benchmarks and noisy data demonstrate that LPS\nsignificantly reduces the incidence of hallucinations compared to the baseline,\nshowing exceptional performance, particularly in noisy settings.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06729v1", "AI": {"title_translation": "通过鲁棒局部感知搜索缓解物体幻觉", "tldr": "多模态大型语言模型（MLLMs）存在物体幻觉问题。本文提出了局部感知搜索（LPS），这是一种简单、无需训练的解码方法，它利用局部视觉先验来抑制幻觉，尤其在噪声数据中表现出色，并且是即插即用的。", "motivation": "尽管多模态大型语言模型（MLLMs）在整合视觉和语言方面取得了显著成功，但它们仍存在幻觉现象，即输出看似合理但与图像内容不符。本文旨在解决这一问题。", "method": "本文引入了局部感知搜索（LPS），这是一种在推理过程中使用的简单、无需训练的解码方法。它利用局部视觉先验信息作为价值函数来纠正解码过程。LPS 是一种即插即用的方法，兼容各种模型。", "result": "LPS 在广泛使用的幻觉基准和噪声数据上进行了大量实验，结果表明它与基线相比显著降低了幻觉的发生率，尤其是在噪声环境下表现出卓越的性能。研究还发现，局部视觉先验对模型性能的影响在图像噪声水平较高的情况下更为显著。", "conclusion": "局部感知搜索（LPS）通过在推理过程中利用局部视觉先验，有效缓解了多模态大型语言模型（MLLMs）中的物体幻觉问题，尤其是在噪声条件下。它是一种简单、无需训练且即插即用的解决方案。", "translation": "多模态大型语言模型（MLLMs）的最新进展使其能够有效地整合视觉和语言，解决各种下游任务。然而，尽管取得了显著成功，这些模型仍然表现出幻觉现象，即输出看似合理但与图像内容不符。为了缓解这个问题，我们引入了局部感知搜索（LPS），这是一种在推理过程中使用的解码方法，它既简单又无需训练，却能有效抑制幻觉。该方法利用局部视觉先验信息作为价值函数来纠正解码过程。此外，我们观察到在图像噪声水平较高的情况下，局部视觉先验对模型性能的影响更为显著。值得注意的是，LPS 是一种即插即用的方法，与各种模型兼容。在广泛使用的幻觉基准和噪声数据上进行的广泛实验表明，与基线相比，LPS 显著降低了幻觉的发生率，尤其是在噪声环境下表现出卓越的性能。", "summary": "本文针对多模态大型语言模型（MLLMs）中的物体幻觉问题，提出了一种名为局部感知搜索（LPS）的新方法。LPS 是一种简单、无需训练且即插即用的解码策略，通过利用局部视觉先验来纠正推理过程，从而有效抑制幻觉，尤其是在噪声环境中表现出色。实验证明 LPS 显著减少了幻觉的发生。", "keywords": "物体幻觉, MLLMs, 局部感知搜索, 解码方法, 噪声数据", "comments": "该论文的创新点在于提出了局部感知搜索（LPS）这一简单、无需训练且即插即用的解码方法，有效缓解了 MLLMs 中的幻觉问题。其在噪声环境下的突出表现以及与多种模型的兼容性，使其成为提升 MLLM 可靠性的重要贡献。"}}
{"id": "2506.06739", "title": "Honey, I shrunk the hypothesis space (through logical preprocessing)", "authors": ["Andrew Cropper", "Filipe Gouveia", "David M. Cerna"], "summary": "Inductive logic programming (ILP) is a form of logical machine learning. The\ngoal is to search a hypothesis space for a hypothesis that generalises training\nexamples and background knowledge. We introduce an approach that 'shrinks' the\nhypothesis space before an ILP system searches it. Our approach uses background\nknowledge to find rules that cannot be in an optimal hypothesis regardless of\nthe training examples. For instance, our approach discovers relationships such\nas \"even numbers cannot be odd\" and \"prime numbers greater than 2 are odd\". It\nthen removes violating rules from the hypothesis space. We implement our\napproach using answer set programming and use it to shrink the hypothesis space\nof a constraint-based ILP system. Our experiments on multiple domains,\nincluding visual reasoning and game playing, show that our approach can\nsubstantially reduce learning times whilst maintaining predictive accuracies.\nFor instance, given just 10 seconds of preprocessing time, our approach can\nreduce learning times from over 10 hours to only 2 seconds.", "comment": "Submitted to JAIR", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06739v1", "AI": {"title_translation": "亲爱的，我缩小了假设空间（通过逻辑预处理）", "tldr": "该研究提出了一种逻辑预处理方法，用于在归纳逻辑编程（ILP）搜索之前缩小假设空间，从而显著减少学习时间，同时保持预测准确性。", "motivation": "归纳逻辑编程（ILP）的目标是在假设空间中搜索能够泛化训练示例和背景知识的假设。本研究的动机是引入一种方法，在ILP系统搜索之前“缩小”假设空间，以提高学习效率。", "method": "该方法利用背景知识识别无论训练示例如何都无法成为最优假设的规则，例如“偶数不能是奇数”和“大于2的素数是奇数”。然后，它从假设空间中删除这些违反性规则。该方法通过答案集编程实现，并用于缩小基于约束的ILP系统的假设空间。", "result": "在包括视觉推理和游戏在内的多个领域进行的实验表明，该方法可以显著减少学习时间，同时保持预测准确性。例如，仅需10秒的预处理时间，学习时间就可以从10小时以上缩短到仅2秒。", "conclusion": "通过逻辑预处理缩小假设空间，可以大幅提高归纳逻辑编程（ILP）的学习效率，同时不牺牲预测准确性。", "translation": "归纳逻辑编程（ILP）是一种逻辑机器学习形式。其目标是在假设空间中搜索能够泛化训练示例和背景知识的假设。我们引入了一种方法，在ILP系统搜索假设空间之前“缩小”它。我们的方法利用背景知识来查找无论训练示例如何都无法成为最优假设的规则。例如，我们的方法发现了诸如“偶数不能是奇数”和“大于2的素数是奇数”之类的关系。然后，它从假设空间中删除违反性规则。我们使用答案集编程实现了我们的方法，并用它来缩小基于约束的ILP系统的假设空间。我们在包括视觉推理和游戏在内的多个领域进行的实验表明，我们的方法可以显著减少学习时间，同时保持预测准确性。例如，仅需10秒的预处理时间，我们的方法就可以将学习时间从10小时以上缩短到仅2秒。", "summary": "这项研究提出了一种逻辑预处理方法，用于在归纳逻辑编程（ILP）搜索之前缩小假设空间。该方法利用背景知识识别并移除不可能成为最优假设的规则，显著减少了ILP的学习时间，同时保持了预测准确性。实验证明，该方法在多个领域（如视觉推理和游戏）表现出色，能将学习时间大幅缩短。", "keywords": "归纳逻辑编程, 假设空间缩小, 逻辑预处理, 答案集编程, 机器学习", "comments": "这篇论文提出了一种创新且实用的方法来优化归纳逻辑编程（ILP）的性能。通过在搜索之前对假设空间进行逻辑预处理，它有效地解决了ILP中常见的搜索效率问题。这种方法的重要性在于它能够将学习时间从数小时缩短到几秒，这对于实际应用中的ILP系统具有巨大的潜在价值。其通用性通过在不同领域（视觉推理和游戏）的成功应用得到了证明。"}}
{"id": "2506.06412", "title": "NeurNCD: Novel Class Discovery via Implicit Neural Representation", "authors": ["Junming Wang", "Yi Shi"], "summary": "Discovering novel classes in open-world settings is crucial for real-world\napplications. Traditional explicit representations, such as object descriptors\nor 3D segmentation maps, are constrained by their discrete, hole-prone, and\nnoisy nature, which hinders accurate novel class discovery. To address these\nchallenges, we introduce NeurNCD, the first versatile and data-efficient\nframework for novel class discovery that employs the meticulously designed\nEmbedding-NeRF model combined with KL divergence as a substitute for\ntraditional explicit 3D segmentation maps to aggregate semantic embedding and\nentropy in visual embedding space. NeurNCD also integrates several key\ncomponents, including feature query, feature modulation and clustering,\nfacilitating efficient feature augmentation and information exchange between\nthe pre-trained semantic segmentation network and implicit neural\nrepresentations. As a result, our framework achieves superior segmentation\nperformance in both open and closed-world settings without relying on densely\nlabelled datasets for supervised training or human interaction to generate\nsparse label supervision. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches on the NYUv2 and Replica\ndatasets.", "comment": "Accepted by ICMR 2024", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06412v1", "AI": {"title_translation": "NeurNCD: 基于隐式神经表示的新颖类别发现", "tldr": "NeurNCD是一个新颖的框架，它利用隐式神经表示（特别是Embedding-NeRF模型和KL散度）来克服传统显式表示的局限性，从而在无需大量标注数据的情况下，在开放和封闭世界设置中实现卓越的新颖类别发现和分割性能。", "motivation": "在开放世界环境中发现新颖类别对于实际应用至关重要。传统的显式表示（如物体描述符或3D分割图）存在离散、易出错和噪声多的问题，这阻碍了准确的新颖类别发现。", "method": "本文提出了NeurNCD，这是一个通用的、数据高效的新颖类别发现框架。它采用精心设计的Embedding-NeRF模型与KL散度相结合，替代传统的显式3D分割图，以在视觉嵌入空间中聚合语义嵌入和熵。NeurNCD还集成了特征查询、特征调制和聚类等关键组件，以促进预训练语义分割网络与隐式神经表示之间的特征增强和信息交换。", "result": "NeurNCD框架在开放和封闭世界设置中均实现了卓越的分割性能，且无需依赖密集标注数据集进行监督训练或人工交互来生成稀疏标签监督。在NYUv2和Replica数据集上的大量实验表明，该方法显著优于最先进的方法。", "conclusion": "NeurNCD通过引入隐式神经表示，成功克服了传统显式表示在开放世界新颖类别发现中的局限性，并在数据效率和分割性能方面取得了显著提升。", "translation": "在开放世界环境中发现新颖类别对于实际应用至关重要。传统的显式表示，例如物体描述符或3D分割图，受限于其离散、易出错和噪声多的特性，这阻碍了准确的新颖类别发现。为了解决这些挑战，我们引入了NeurNCD，这是第一个通用且数据高效的新颖类别发现框架，它采用精心设计的Embedding-NeRF模型结合KL散度，作为传统显式3D分割图的替代，以在视觉嵌入空间中聚合语义嵌入和熵。NeurNCD还集成了几个关键组件，包括特征查询、特征调制和聚类，促进了预训练语义分割网络与隐式神经表示之间的高效特征增强和信息交换。因此，我们的框架在开放和封闭世界设置中都取得了卓越的分割性能，而无需依赖密集标注数据集进行监督训练或人工交互来生成稀疏标签监督。大量的实验表明，我们的方法在NYUv2和Replica数据集上显著优于最先进的方法。", "summary": "NeurNCD是一个开创性的新颖类别发现框架，它通过引入隐式神经表示（特别是Embedding-NeRF模型和KL散度）来克服传统显式表示在处理新颖类别时的局限性。该框架通过集成特征查询、调制和聚类，实现了高效的特征增强和信息交换，从而在无需大量标注数据的情况下，在开放和封闭世界设置中均展现出卓越的分割性能，并在标准数据集上超越了现有技术。", "keywords": "新颖类别发现, 隐式神经表示, NeurNCD, NeRF, 语义分割", "comments": "NeurNCD的创新之处在于首次将隐式神经表示应用于新颖类别发现任务，这有望解决传统显式表示的固有缺陷。其数据高效性和在无需密集标注的情况下实现SOTA性能的能力，使其在实际应用中具有重要价值。这种方法为开放世界识别和分割问题开辟了新的研究方向。"}}
{"id": "2506.06447", "title": "Fake Friends and Sponsored Ads: The Risks of Advertising in Conversational Search", "authors": ["Jacob Erickson"], "summary": "Digital commerce thrives on advertising, with many of the largest technology\ncompanies relying on it as a significant source of revenue. However, in the\ncontext of information-seeking behavior, such as search, advertising may\ndegrade the user experience by lowering search quality, misusing user data for\ninappropriate personalization, potentially misleading individuals, or even\nleading them toward harm. These challenges remain significant as conversational\nsearch technologies, such as ChatGPT, become widespread. This paper critically\nexamines the future of advertising in conversational search, utilizing several\nspeculative examples to illustrate the potential risks posed to users who seek\nguidance on sensitive topics. Additionally, it provides an overview of the\nforms that advertising might take in this space and introduces the \"fake friend\ndilemma,\" the idea that a conversational agent may exploit unaligned user trust\nto achieve other objectives. This study presents a provocative discussion on\nthe future of online advertising in the space of conversational search and ends\nwith a call to action.", "comment": "Accepted for publication at ACM CUI 2025", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.06447v1", "AI": {"title_translation": "虚假朋友和赞助广告：对话式搜索中广告的风险", "tldr": "本文探讨了对话式搜索（如ChatGPT）中广告的潜在风险，包括用户体验下降、数据滥用、误导甚至伤害用户，并提出了“虚假朋友困境”。", "motivation": "数字商务严重依赖广告，但广告在信息检索（如搜索）中可能通过降低搜索质量、滥用用户数据、误导甚至伤害用户来损害用户体验。随着ChatGPT等对话式搜索技术的普及，这些挑战依然严峻，因此有必要审视对话式搜索中广告的未来。", "method": "本文通过几个推测性示例来阐述对话式搜索中广告对寻求敏感话题指导的用户可能造成的风险。此外，它概述了广告在该领域可能采取的形式，并提出了“虚假朋友困境”，即对话代理可能利用未对齐的用户信任来实现其他目标。", "result": "本文批判性地审视了对话式搜索中广告的未来，揭示了广告对用户（尤其是在敏感话题上）潜在的风险，并提出了“虚假朋友困境”，即对话代理可能利用用户信任以达成自身目的。", "conclusion": "本文对对话式搜索中在线广告的未来进行了发人深省的讨论，并以行动呼吁结束。", "translation": "数字商务依靠广告蓬勃发展，许多最大的科技公司将其作为重要的收入来源。然而，在信息寻求行为（如搜索）的背景下，广告可能会通过降低搜索质量、滥用用户数据进行不当个性化、可能误导个人甚至导致他们受到伤害来降低用户体验。随着ChatGPT等对话式搜索技术的普及，这些挑战依然严峻。本文批判性地审视了对话式搜索中广告的未来，利用几个推测性示例来说明对寻求敏感话题指导的用户可能造成的潜在风险。此外，它概述了广告在该领域可能采取的形式，并引入了“虚假朋友困境”，即对话代理可能利用未对齐的用户信任来实现其他目标。本研究对对话式搜索领域在线广告的未来进行了发人深省的讨论，并以行动呼吁结束。", "summary": "本文探讨了在ChatGPT等对话式搜索技术普及的背景下，广告可能对用户体验和信息质量造成的负面影响。文章通过推测性示例揭示了广告可能带来的风险，例如降低搜索质量、滥用用户数据、误导甚至伤害用户，并提出了“虚假朋友困境”，即对话式代理可能利用用户信任来实现自身目标。研究对对话式搜索中的广告未来进行了深入讨论，并呼吁采取行动。", "keywords": "对话式搜索, 广告风险, 虚假朋友困境, 用户体验, 人工智能伦理", "comments": "这篇论文提出了一个非常及时且重要的议题，即在人工智能驱动的对话式搜索日益普及的今天，广告可能带来的伦理和用户体验风险。文章引入的“虚假朋友困境”概念尤其具有创新性，它深刻揭示了AI代理在商业利益驱动下可能对用户信任造成的潜在滥用。该研究不仅提出了问题，还呼吁采取行动，这对于未来AI产品设计和政策制定具有指导意义，强调了在商业利益与用户福祉之间取得平衡的重要性。"}}
{"id": "2506.06313", "title": "DISRetrieval: Harnessing Discourse Structure for Long Document Retrieval", "authors": ["Huiyao Chen", "Yi Yang", "Yinghui Li", "Meishan Zhang", "Min Zhang"], "summary": "Long document understanding has become increasingly crucial in natural\nlanguage processing, with retrieval-based methods emerging as a promising\nsolution to address the context length limitations of large language models\n(LLMs). However, existing approaches either treat documents as flat sequences\nor employ arbitrary chunking strategies, failing to capture the inherent\ndiscourse structure that guides human comprehension. We present DISRetrieval, a\nnovel hierarchical retrieval framework that leverages linguistic discourse\nstructure to enhance long document understanding. Our approach introduces three\nkey innovations: (1) a discourse-aware document organization framework that\nutilizes rhetorical structure theory (RST) to create sentence-level\nhierarchical representations, preserving both semantic relationships and\nnatural document flow; (2) an LLM-enhanced node representation technique that\ncombines discourse structure with adaptive summarization to enrich tree nodes\nwith contextual information; and (3) a hierarchical evidence retrieval\nmechanism that effectively selects relevant content while maintaining discourse\ncoherence. Through comprehensive experiments on QASPER and QuALITY datasets,\nDISRetrieval demonstrates substantial improvements over existing methods in\nboth token-level retrieval metrics and downstream question answering tasks. Our\nablation studies confirm that incorporating discourse structure significantly\nenhances retrieval effectiveness across different document lengths and query\ntypes, validating the importance of linguistically-informed document\nrepresentation in long-text understanding. Our code and datasets are publicly\navailable at github/DreamH1gh/DISRetrieval to facilitate future research.", "comment": "21 pages, 7 figures", "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06313v1", "AI": {"title_translation": "DISRetrieval：利用语篇结构进行长文档检索", "tldr": "DISRetrieval是一个新颖的层次检索框架，通过利用语篇结构显著改善了长文档检索和下游问答任务的性能。", "motivation": "现有长文档检索方法未能有效捕捉指导人类理解的内在语篇结构，导致在处理大型语言模型（LLMs）的上下文长度限制时表现不佳。", "method": "本文提出了DISRetrieval，一个新颖的层次检索框架，它利用语言语篇结构来增强长文档理解。该方法包含三项关键创新：1) 一个语篇感知的文档组织框架，利用修辞结构理论（RST）创建句子级层次表示；2) 一种LLM增强的节点表示技术，结合语篇结构与自适应摘要来丰富树节点；3) 一种层次证据检索机制，有效选择相关内容并保持语篇连贯性。", "result": "在QASPER和QuALITY数据集上的全面实验表明，DISRetrieval在token级检索指标和下游问答任务上均显著优于现有方法。消融研究证实，结合语篇结构显著增强了不同文档长度和查询类型的检索效率。", "conclusion": "本研究验证了语言学信息丰富的文档表示在长文本理解中的重要性，并证明了通过整合语篇结构可以显著提高长文档检索的有效性。", "translation": "长文档理解在自然语言处理中变得越来越重要，而基于检索的方法已成为解决大型语言模型（LLM）上下文长度限制的一种有前景的解决方案。然而，现有方法要么将文档视为扁平序列，要么采用任意分块策略，未能捕捉指导人类理解的内在语篇结构。我们提出了DISRetrieval，一个新颖的层次检索框架，它利用语言语篇结构来增强长文档理解。我们的方法引入了三项关键创新：（1）一个语篇感知的文档组织框架，它利用修辞结构理论（RST）创建句子级层次表示，同时保留语义关系和自然的文档流；（2）一种LLM增强的节点表示技术，它将语篇结构与自适应摘要相结合，以用上下文信息丰富树节点；以及（3）一种层次证据检索机制，它能有效选择相关内容，同时保持语篇连贯性。通过在QASPER和QuALITY数据集上进行的全面实验，DISRetrieval在token级检索指标和下游问答任务上均显著优于现有方法。我们的消融研究证实，结合语篇结构显著提高了不同文档长度和查询类型的检索效率，验证了语言学信息丰富的文档表示在长文本理解中的重要性。我们的代码和数据集已在github/DreamH1gh/DISRetrieval公开发布，以促进未来的研究。", "summary": "DISRetrieval是一个新颖的层次检索框架，旨在通过利用语言语篇结构来改进长文档理解和检索。它通过语篇感知的文档组织、LLM增强的节点表示和层次证据检索机制，解决了现有方法未能捕捉文档内在语篇结构的问题。在QASPER和QuALITY数据集上的实验表明，DISRetrieval在检索和问答任务上均表现出色，证明了语篇结构在长文本理解中的重要性。", "keywords": "长文档检索, 语篇结构, 层次检索, 大型语言模型, 修辞结构理论", "comments": "该论文的创新点在于将语言学中的语篇结构理论（RST）引入到长文档检索中，通过构建层次化的文档表示来克服现有方法的局限性。这种方法不仅提升了检索效率，也为LLMs处理长文本提供了更具语义和结构性的上下文。其贡献在于提供了一个更符合人类理解模式的长文档处理范式。"}}
{"id": "2506.07313", "title": "SCGAgent: Recreating the Benefits of Reasoning Models for Secure Code Generation with Agentic Workflows", "authors": ["Rebecca Saul", "Hao Wang", "Koushik Sen", "David Wagner"], "summary": "Large language models (LLMs) have seen widespread success in code generation\ntasks for different scenarios, both everyday and professional. However current\nLLMs, despite producing functional code, do not prioritize security and may\ngenerate code with exploitable vulnerabilities. In this work, we propose\ntechniques for generating code that is more likely to be secure and introduce\nSCGAgent, a proactive secure coding agent that implements our techniques. We\nuse security coding guidelines that articulate safe programming practices,\ncombined with LLM-generated unit tests to preserve functional correctness. In\nour evaluation, we find that SCGAgent is able to preserve nearly 98% of the\nfunctionality of the base Sonnet-3.7 LLM while achieving an approximately 25%\nimprovement in security. Moreover, SCGAgent is able to match or best the\nperformance of sophisticated reasoning LLMs using a non-reasoning model and an\nagentic workflow.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07313v1", "AI": {"title_translation": "SCGAgent：通过代理工作流重现推理模型在安全代码生成中的优势", "tldr": "SCGAgent是一个安全代码生成代理，它利用代理工作流和安全编码指南，在保持功能性的同时显著提高了代码安全性，并能与复杂的推理LLM媲美。", "motivation": "当前的大型语言模型（LLM）在代码生成方面取得了广泛成功，但它们不优先考虑安全性，可能生成带有可利用漏洞的代码。", "method": "我们提出了生成更安全代码的技术，并引入了SCGAgent，一个主动的安全编码代理。SCGAgent结合了阐明安全编程实践的安全编码指南，并使用LLM生成的单元测试来保持功能正确性，通过代理工作流实现。", "result": "SCGAgent能够保留基础Sonnet-3.7 LLM近98%的功能性，同时将安全性提高约25%。此外，SCGAgent能够使用非推理模型和代理工作流，匹配或超越复杂推理LLM的性能。", "conclusion": "SCGAgent通过结合安全编码指南、LLM生成的单元测试和代理工作流，在不牺牲功能性的前提下显著提高了代码安全性，并能与复杂的推理模型相媲美，证明了代理工作流在安全代码生成中的有效性。", "translation": "大型语言模型（LLM）在不同场景（日常和专业）的代码生成任务中取得了广泛成功。然而，当前的LLM尽管能生成功能代码，但并不优先考虑安全性，可能会生成带有可利用漏洞的代码。在这项工作中，我们提出了生成更可能安全的代码的技术，并引入了SCGAgent，一个实现我们技术的主动安全编码代理。我们使用阐明安全编程实践的安全编码指南，并结合LLM生成的单元测试来保持功能正确性。在我们的评估中，我们发现SCGAgent能够保留基础Sonnet-3.7 LLM近98%的功能性，同时将安全性提高约25%。此外，SCGAgent能够使用非推理模型和代理工作流，匹配或超越复杂推理LLM的性能。", "summary": "本研究提出了SCGAgent，一个旨在提高代码安全性的主动编码代理。该代理结合了安全编码指南和LLM生成的单元测试，以在生成安全代码的同时保持功能正确性。评估结果显示，SCGAgent在保留高功能性的前提下，显著提高了代码安全性，并能与先进的推理模型性能相媲美，这得益于其代理工作流。", "keywords": "安全代码生成, 代理工作流, 大型语言模型, 代码安全性, 单元测试", "comments": "SCGAgent的创新之处在于，它通过代理工作流，使非推理模型也能实现与复杂推理模型相当甚至更优的安全代码生成性能。这表明，通过巧妙的流程设计和结合领域知识（安全编码指南），可以有效地弥补基础模型在特定能力（如安全性）上的不足，为LLM在关键应用领域（如安全软件开发）的部署提供了新的思路和潜力。"}}
{"id": "2506.06798", "title": "SARAL-Bot: Autonomous Robot for Strawberry Plant Care", "authors": ["Arif Ahmed", "Ritvik Agarwal", "Gaurav Srikar", "Nathaniel Rose", "Parikshit Maini"], "summary": "Strawberry farming demands intensive labor for monitoring and maintaining\nplant health. To address this, Team SARAL develops an autonomous robot for the\n2024 ASABE Student Robotics Challenge, capable of navigation, unhealthy leaf\ndetection, and removal. The system addresses labor shortages, reduces costs,\nand supports sustainable farming through vision-based plant assessment. This\nwork demonstrates the potential of robotics to modernize strawberry cultivation\nand enable scalable, intelligent agricultural solutions.", "comment": "Awarded Best Written Report @ Robotics Design Challenge (Advanced),\n  ASABE 2024", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06798v1", "AI": {"title_translation": "SARAL-Bot：草莓植株护理自主机器人", "tldr": "SARAL团队开发了一款名为SARAL-Bot的自主机器人，用于草莓种植，能导航、检测并移除不健康叶片，以解决劳动力短缺和降低成本。", "motivation": "草莓种植对监测和维护植物健康提出密集的劳动力需求。为了解决劳动力短缺、降低成本和支持可持续农业，开发了这款自主机器人。", "method": "SARAL团队为2024 ASABE学生机器人挑战赛开发了一款自主机器人。该机器人具备导航、不健康叶片检测和移除的能力，并通过基于视觉的植物评估来实现这些功能。", "result": "该系统解决了劳动力短缺，降低了成本，并通过基于视觉的植物评估支持可持续农业。这项工作展示了机器人技术在现代化草莓种植和实现可扩展、智能农业解决方案方面的潜力。", "conclusion": "机器人技术有潜力使草莓种植现代化，并实现可扩展、智能的农业解决方案。", "translation": "草莓种植对监测和维护植物健康提出密集的劳动力需求。为了解决这一问题，SARAL团队为2024年ASABE学生机器人挑战赛开发了一款自主机器人，该机器人能够导航、检测和移除不健康的叶片。该系统通过基于视觉的植物评估解决了劳动力短缺问题，降低了成本，并支持可持续农业。这项工作展示了机器人技术使草莓种植现代化并实现可扩展、智能农业解决方案的潜力。", "summary": "SARAL团队开发了一款名为SARAL-Bot的自主机器人，旨在解决草莓种植中劳动力密集的问题。该机器人专为2024年ASABE学生机器人挑战赛设计，具备导航、不健康叶片检测及移除功能。通过基于视觉的植物评估，该系统有助于缓解劳动力短缺，降低生产成本，并促进可持续农业实践，展示了机器人技术在现代化农业中的应用前景。", "keywords": "自主机器人, 草莓种植, 植物护理, 农业自动化, 机器视觉", "comments": "这篇论文展示了一个实用的农业机器人应用，专注于解决草莓种植中的具体痛点。其创新之处在于结合了导航、视觉检测和物理移除功能于一体，为传统农业提供了现代化的解决方案。重要性在于它直接响应了农业劳动力短缺的挑战，并促进了智能和可持续的农业发展。"}}
{"id": "2506.07390", "title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "authors": ["Xin-Cheng Wen", "Yijun Yang", "Cuiyun Gao", "Yang Xiao", "Deheng Ye"], "summary": "Large language models (LLMs) demonstrate considerable proficiency in numerous\ncoding-related tasks; however, their capabilities in detecting software\nvulnerabilities remain limited. This limitation primarily stems from two\nfactors: (1) the absence of reasoning data related to vulnerabilities, which\nhinders the models' ability to capture underlying vulnerability patterns; and\n(2) their focus on learning semantic representations rather than the reason\nbehind them, thus failing to recognize semantically similar vulnerability\nsamples. Furthermore, the development of LLMs specialized in vulnerability\ndetection is challenging, particularly in environments characterized by the\nscarcity of high-quality datasets. In this paper, we propose a novel framework\nReVD that excels at mining vulnerability patterns through reasoning data\nsynthesizing and vulnerability-specific preference optimization. Specifically,\nwe construct forward and backward reasoning processes for vulnerability and\ncorresponding fixed code, ensuring the synthesis of high-quality reasoning\ndata. Moreover, we design the triplet supervised fine-tuning followed by\ncurriculum online preference optimization for enabling ReVD to better\nunderstand vulnerability patterns. The extensive experiments conducted on\nPrimeVul and SVEN datasets demonstrate that ReVD sets new state-of-the-art for\nLLM-based software vulnerability detection, e.g., 12.24\\%-22.77\\% improvement\nin the accuracy. The source code and data are available at\nhttps://github.com/Xin-Cheng-Wen/PO4Vul.", "comment": "Accepted by ACL 2025 Findings", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07390v1", "AI": {"title_translation": "LLM漏洞检测能力提升：基于课程偏好优化与合成推理数据", "tldr": "提出ReVD框架，通过合成推理数据和课程偏好优化显著提升LLM的软件漏洞检测能力，实现SOTA表现。", "motivation": "大型语言模型（LLMs）在软件漏洞检测方面能力有限，主要原因在于缺乏与漏洞相关的推理数据，阻碍了模型捕获潜在漏洞模式的能力；同时，LLMs侧重于学习语义表示而非其背后的原因，导致无法识别语义相似的漏洞样本。此外，开发专门的LLMs用于漏洞检测面临高质量数据集稀缺的挑战。", "method": "本文提出了ReVD框架，通过以下方法挖掘漏洞模式：1) 构建漏洞及其修复代码的前向和后向推理过程，以合成高质量的推理数据。2) 设计三元组监督微调，随后进行课程在线偏好优化，使ReVD更好地理解漏洞模式。", "result": "在PrimeVul和SVEN数据集上进行的广泛实验表明，ReVD在基于LLM的软件漏洞检测方面达到了新的最先进水平，准确率提升了12.24%-22.77%。", "conclusion": "ReVD框架通过结合合成推理数据和漏洞特定偏好优化，有效解决了LLM在漏洞检测中的局限性，并显著提升了其性能，达到了当前最先进水平。", "translation": "大型语言模型（LLMs）在众多编码相关任务中表现出相当的熟练程度；然而，它们在检测软件漏洞方面的能力仍然有限。这种局限性主要源于两个因素：（1）缺乏与漏洞相关的推理数据，这阻碍了模型捕获潜在漏洞模式的能力；（2）它们侧重于学习语义表示而非其背后的原因，因此未能识别语义相似的漏洞样本。此外，开发专门用于漏洞检测的LLM具有挑战性，特别是在高质量数据集稀缺的环境中。在本文中，我们提出了一种新颖的框架ReVD，该框架通过推理数据合成和漏洞特定偏好优化，擅长挖掘漏洞模式。具体来说，我们构建了漏洞和相应修复代码的前向和后向推理过程，确保合成高质量的推理数据。此外，我们设计了三元组监督微调，随后进行课程在线偏好优化，以使ReVD更好地理解漏洞模式。在PrimeVul和SVEN数据集上进行的广泛实验表明，ReVD为基于LLM的软件漏洞检测设定了新的最先进水平，例如准确率提高了12.24%-22.77%。源代码和数据可在https://github.com/Xin-Cheng-Wen/PO4Vul 获取。", "summary": "本文提出ReVD框架，旨在提升大型语言模型在软件漏洞检测方面的能力。针对现有LLM缺乏推理数据和侧重语义而非推理原因的局限，ReVD通过合成高质量的漏洞推理数据，并结合三元组监督微调和课程在线偏好优化，使模型更好地理解和识别漏洞模式。实验结果表明，ReVD在PrimeVul和SVEN数据集上显著优于现有SOTA方法，大幅提高了漏洞检测的准确率，实现了12.24%-22.77%的准确率提升。", "keywords": "大型语言模型, 漏洞检测, 推理数据合成, 偏好优化, 课程学习", "comments": "该论文通过引入合成推理数据和创新的偏好优化方法，有效解决了LLM在漏洞检测中对推理能力的需求和高质量数据稀缺的问题，为提升LLM在专业领域的应用提供了新的思路，具有重要的研究价值和实际应用潜力。"}}
{"id": "2506.06733", "title": "RecipeGen: A Step-Aligned Multimodal Benchmark for Real-World Recipe Generation", "authors": ["Ruoxuan Zhang", "Jidong Gao", "Bin Wen", "Hongxia Xie", "Chenming Zhang", "Honghan-shuai", "Wen-Huang Cheng"], "summary": "Creating recipe images is a key challenge in food computing, with\napplications in culinary education and multimodal recipe assistants. However,\nexisting datasets lack fine-grained alignment between recipe goals, step-wise\ninstructions, and visual content. We present RecipeGen, the first large-scale,\nreal-world benchmark for recipe-based Text-to-Image (T2I), Image-to-Video\n(I2V), and Text-to-Video (T2V) generation. RecipeGen contains 26,453 recipes,\n196,724 images, and 4,491 videos, covering diverse ingredients, cooking\nprocedures, styles, and dish types. We further propose domain-specific\nevaluation metrics to assess ingredient fidelity and interaction modeling,\nbenchmark representative T2I, I2V, and T2V models, and provide insights for\nfuture recipe generation models. Project page is available now.", "comment": "This is an extended version of arXiv:2503.05228", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06733v1", "AI": {"title_translation": "食谱生成：一个用于真实世界食谱生成的步骤对齐多模态基准", "tldr": "提出了RecipeGen，一个大型多模态食谱生成基准，解决了现有数据集缺乏细粒度对齐的问题，并支持文本到图像、图像到视频和文本到视频的生成任务。", "motivation": "现有食谱数据集缺乏食谱目标、分步说明和视觉内容之间的细粒度对齐，这限制了食谱图像生成在烹饪教育和多模态食谱助手等领域的应用。", "method": "本文提出了RecipeGen，这是第一个用于基于食谱的文本到图像（T2I）、图像到视频（I2V）和文本到视频（T2V）生成的大规模、真实世界基准。RecipeGen包含26,453个食谱、196,724张图片和4,491个视频。此外，还提出了领域特定的评估指标来评估食材保真度和交互建模，并对代表性的T2I、I2V和T2V模型进行了基准测试。", "result": "RecipeGen包含了26,453个食谱、196,724张图片和4,491个视频，涵盖了不同的食材、烹饪步骤、风格和菜肴类型。研究还提出了领域特定的评估指标，并对代表性模型进行了基准测试，为未来的食谱生成模型提供了见解。", "conclusion": "RecipeGen是第一个用于真实世界食谱生成的大规模、步骤对齐的多模态基准，它通过解决现有数据集的细粒度对齐问题，并提供新的评估指标和基准测试，为未来的食谱生成模型研究奠定了基础。", "translation": "创建食谱图像是食品计算中的一个关键挑战，在烹饪教育和多模态食谱助手中有应用。然而，现有数据集缺乏食谱目标、分步说明和视觉内容之间的细粒度对齐。我们提出了RecipeGen，这是第一个用于基于食谱的文本到图像（T2I）、图像到视频（I2V）和文本到视频（T2V）生成的大规模真实世界基准。RecipeGen包含26,453个食谱、196,724张图片和4,491个视频，涵盖了不同的食材、烹饪步骤、风格和菜肴类型。我们进一步提出了领域特定的评估指标来评估食材保真度和交互建模，对代表性的T2I、I2V和T2V模型进行了基准测试，并为未来的食谱生成模型提供了见解。项目页面现已可用。", "summary": "本文介绍了RecipeGen，一个大型的、步骤对齐的多模态基准数据集，旨在解决现有食谱数据集在食谱目标、分步说明和视觉内容之间缺乏细粒度对齐的问题。RecipeGen支持文本到图像、图像到视频和文本到视频的食谱生成任务，并提供了新的评估指标和基准测试结果，为未来的食谱生成模型研究提供了基础和方向。", "keywords": "食谱生成, 多模态基准, 文本到图像, 图像到视频, 文本到视频", "comments": "这篇论文的创新点在于构建了一个大规模、细粒度对齐的真实世界多模态食谱数据集RecipeGen，并提出了针对性的评估指标，这对于推动食谱生成，特别是多模态食谱生成领域的研究具有重要意义。它填补了现有数据集的空白，为未来的模型开发提供了坚实的基础。"}}
{"id": "2506.06740", "title": "AI PsyRoom: Artificial Intelligence Platform for Segmented Yearning and Reactive Outcome Optimization Method", "authors": ["Yigui Feng", "Qinglin Wang", "Ke Liu", "Xinhai Chen", "Bo Yang", "Jie Liu"], "summary": "Psychological counseling faces huge challenges due to the growing demand for\nmental health services and the shortage of trained professionals. Large\nlanguage models (LLMs) have shown potential to assist psychological counseling,\nespecially in empathy and emotional support. However, existing models lack a\ndeep understanding of emotions and are unable to generate personalized\ntreatment plans based on fine-grained emotions. To address these shortcomings,\nwe present AI PsyRoom, a multi-agent simulation framework designed to enhance\npsychological counseling by generating empathetic and emotionally nuanced\nconversations. By leveraging fine-grained emotion classification and a\nmulti-agent framework, we construct a multi-agent PsyRoom A for dialogue\nreconstruction, generating a high-quality dialogue dataset EmoPsy, which\ncontains 35 sub-emotions, 423 specific emotion scenarios, and 12,350 dialogues.\nWe also propose PsyRoom B for generating personalized treatment plans.\nQuantitative evaluations demonstrate that AI PsyRoom significantly outperforms\nstate-of-the-art methods, achieving 18% improvement in problem orientation, 23%\nin expression, 24% in Empathy, and 16% in interactive communication quality.\nThe datasets and models are publicly available, providing a foundation for\nadvancing AI-assisted psychological counseling research.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06740v1", "AI": {"title_translation": "AI PsyRoom：分段渴望与反应性结果优化方法的人工智能平台", "tldr": "AI PsyRoom是一个多智能体框架，通过细粒度情感分类和对话重建，生成同理心对话和个性化治疗方案，显著提升AI心理咨询效果。", "motivation": "心理咨询面临服务需求增长和专业人员短缺的挑战；现有大型语言模型（LLM）缺乏对情感的深入理解，无法生成基于细粒度情感的个性化治疗方案。", "method": "提出了AI PsyRoom，一个多智能体模拟框架，旨在通过生成同理心和情感细致的对话来增强心理咨询。它利用细粒度情感分类和多智能体框架，构建了用于对话重建的PsyRoom A，并生成了高质量的EmoPsy对话数据集；同时提出了用于生成个性化治疗方案的PsyRoom B。", "result": "AI PsyRoom在问题导向方面提升18%，表达方面提升23%，同理心方面提升24%，互动交流质量方面提升16%，显著优于现有最先进的方法。", "conclusion": "AI PsyRoom为推进AI辅助心理咨询研究提供了基础，其数据集和模型已公开可用。", "translation": "心理咨询面临巨大挑战，因为心理健康服务需求不断增长，而训练有素的专业人员却短缺。大型语言模型（LLMs）已显示出辅助心理咨询的潜力，尤其是在同理心和情感支持方面。然而，现有模型缺乏对情感的深入理解，并且无法根据细粒度情感生成个性化的治疗方案。为了解决这些缺点，我们提出了AI PsyRoom，一个多智能体模拟框架，旨在通过生成富有同理心和情感细致的对话来增强心理咨询。通过利用细粒度情感分类和多智能体框架，我们构建了一个用于对话重建的多智能体PsyRoom A，生成了一个高质量的对话数据集EmoPsy，其中包含35种子情感、423个特定情感场景和12,350个对话。我们还提出了用于生成个性化治疗方案的PsyRoom B。定量评估表明，AI PsyRoom显著优于现有最先进的方法，在问题导向方面实现了18%的改进，在表达方面实现了23%的改进，在同理心方面实现了24%的改进，在互动交流质量方面实现了16%的改进。数据集和模型均已公开可用，为推进AI辅助心理咨询研究奠定了基础。", "summary": "针对心理咨询中专业人员短缺及现有LLM情感理解和个性化治疗不足的问题，本文提出了AI PsyRoom，一个多智能体模拟框架。该框架通过细粒度情感分类和多智能体技术，构建了PsyRoom A用于对话重建并生成了大规模高质量情感对话数据集EmoPsy，同时提出了PsyRoom B用于生成个性化治疗方案。实验结果表明，AI PsyRoom在多个关键指标上显著优于现有方法，并已公开其数据集和模型，为AI辅助心理咨询研究提供了重要基础。", "keywords": "心理咨询, 人工智能, 多智能体系统, 情感分类, 个性化治疗", "comments": "本文的创新点在于提出了一个多智能体模拟框架AI PsyRoom，通过细粒度情感分类和对话重建，解决了现有LLM在心理咨询中情感理解不足和个性化治疗方案生成困难的问题。其构建的EmoPsy数据集和PsyRoom B模块具有很高的实用价值和研究潜力，为AI辅助心理咨询领域的发展提供了重要基础。模型的公开可用性也促进了该领域的研究进展。"}}
{"id": "2506.06549", "title": "GeoClip: Geometry-Aware Clipping for Differentially Private SGD", "authors": ["Atefeh Gilani", "Naima Tasnim", "Lalitha Sankar", "Oliver Kosut"], "summary": "Differentially private stochastic gradient descent (DP-SGD) is the most\nwidely used method for training machine learning models with provable privacy\nguarantees. A key challenge in DP-SGD is setting the per-sample gradient\nclipping threshold, which significantly affects the trade-off between privacy\nand utility. While recent adaptive methods improve performance by adjusting\nthis threshold during training, they operate in the standard coordinate system\nand fail to account for correlations across the coordinates of the gradient. We\npropose GeoClip, a geometry-aware framework that clips and perturbs gradients\nin a transformed basis aligned with the geometry of the gradient distribution.\nGeoClip adaptively estimates this transformation using only previously released\nnoisy gradients, incurring no additional privacy cost. We provide convergence\nguarantees for GeoClip and derive a closed-form solution for the optimal\ntransformation that minimizes the amount of noise added while keeping the\nprobability of gradient clipping under control. Experiments on both tabular and\nimage datasets demonstrate that GeoClip consistently outperforms existing\nadaptive clipping methods under the same privacy budget.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06549v1", "AI": {"title_translation": "GeoClip: 差分隐私随机梯度下降的几何感知裁剪", "tldr": "DP-SGD中的梯度裁剪阈值设置具有挑战性，影响隐私与效用。GeoClip提出了一种几何感知的裁剪方法，在变换基中进行裁剪和扰动，并在实验中优于现有方法。", "motivation": "差分隐私随机梯度下降（DP-SGD）中设置每样本梯度裁剪阈值是一个关键挑战，因为它显著影响隐私和效用之间的权衡。现有的自适应方法在标准坐标系中操作，未能考虑梯度坐标之间的相关性。", "method": "本文提出了GeoClip，一个几何感知框架，在与梯度分布几何对齐的变换基中裁剪和扰动梯度。GeoClip仅使用先前发布的噪声梯度自适应地估计此变换，不产生额外的隐私成本。作者为GeoClip提供了收敛性保证，并推导出了一个闭合形式的解决方案，用于最小化添加噪声量同时控制梯度裁剪概率的最佳变换。", "result": "在表格和图像数据集上的实验表明，GeoClip在相同的隐私预算下始终优于现有的自适应裁剪方法。", "conclusion": "GeoClip通过使用几何感知裁剪改进了DP-SGD中的隐私-效用权衡，并在实验中持续优于现有方法。", "translation": "差分隐私随机梯度下降（DP-SGD）是训练具有可证明隐私保证的机器学习模型最广泛使用的方法。DP-SGD 中的一个关键挑战是设置每样本梯度裁剪阈值，这显著影响隐私和效用之间的权衡。虽然最近的自适应方法通过在训练期间调整此阈值来提高性能，但它们在标准坐标系中操作，未能考虑梯度坐标之间的相关性。我们提出了 GeoClip，一个几何感知框架，它在与梯度分布几何对齐的变换基中裁剪和扰动梯度。GeoClip 仅使用先前发布的噪声梯度自适应地估计此变换，不产生额外的隐私成本。我们为 GeoClip 提供了收敛性保证，并推导出了一个闭合形式的解决方案，用于最小化添加噪声量同时控制梯度裁剪概率的最佳变换。在表格和图像数据集上的实验表明，GeoClip 在相同的隐私预算下始终优于现有的自适应裁剪方法。", "summary": "本文介绍了GeoClip，一个用于差分隐私随机梯度下降（DP-SGD）的几何感知框架。它通过在与梯度分布几何对齐的变换基中执行裁剪和扰动来解决梯度裁剪阈值设置的挑战。GeoClip利用先前的噪声梯度自适应地估计此变换，不产生额外隐私成本，并提供了收敛性保证和最优变换的闭合解。实验证明，GeoClip在隐私-效用权衡方面始终优于现有的自适应裁剪方法。", "keywords": "差分隐私SGD, 梯度裁剪, 几何感知, 自适应方法, 隐私-效用权衡", "comments": "这篇论文通过考虑梯度分布的几何特性，引入了一种创新的DP-SGD梯度裁剪方法，是对传统基于坐标的方法的显著改进。其在不增加额外隐私成本的情况下自适应估计变换的能力，以及提供收敛性保证，是其显著的优势。GeoClip持续超越现有方法的表现，表明其对隐私保护机器学习领域做出了实用且有影响力的贡献。"}}
{"id": "2506.06443", "title": "Unlocking Chemical Insights: Superior Molecular Representations from Intermediate Encoder Layers", "authors": ["Luis Pinto"], "summary": "Pretrained molecular encoders have become indispensable in computational\nchemistry for tasks such as property prediction and molecular generation.\nHowever, the standard practice of relying solely on final-layer embeddings for\ndownstream tasks may discard valuable information. In this work, we challenge\nthis convention by conducting a comprehensive layer-wise analysis of five\ndiverse molecular encoders across 22 ADMET property prediction tasks. Our\nresults demonstrate that embeddings from intermediate layers consistently\noutperform final-layer representations. Specifically, using fixed embeddings\nfrom the optimal intermediate layers improved downstream performance by an\naverage of 5.4%, reaching gains up to 28.6%. Furthermore, finetuning up to\nthese intermediate layers yielded even greater average improvements of 8.5%,\nwith performance increases as high as 40.8%, achieving new state-of-the-art\nresults on several benchmarks. Additionally, a strong positive correlation\nbetween fixed embedding performance and finetuning outcomes supports an\nefficient evaluate-then-finetune approach, enabling identification of optimal\nlayers with reduced computational cost. These findings highlight the importance\nof exploring the full representational depth of molecular encoders to achieve\nsubstantial performance improvements and computational efficiency. The code is\nmade publicly available at\nhttps://github.com/luispintoc/Unlocking-Chemical-Insights.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06443v1", "AI": {"title_translation": "解锁化学见解：来自中间编码器层的卓越分子表示", "tldr": "分子编码器的中间层提供了比最终层更好的分子表示，从而显著提高了属性预测任务的性能。", "motivation": "预训练分子编码器在计算化学中不可或缺，但仅依赖最终层嵌入进行下游任务的标准做法可能会丢弃有价值的信息，限制了性能。", "method": "研究人员对五种不同的分子编码器在22个ADMET属性预测任务中进行了全面的层级分析，评估了固定嵌入和对中间层进行微调的效果。", "result": "结果显示，来自中间层的嵌入始终优于最终层表示。使用最佳中间层的固定嵌入平均提高了5.4%的性能（最高达28.6%）。对这些中间层进行微调带来了更大的平均改进，达到8.5%（最高达40.8%），并在多个基准测试中取得了新的最先进结果。此外，固定嵌入性能与微调结果之间存在强正相关性，支持高效的“评估-然后-微调”方法。", "conclusion": "探索分子编码器的完整表示深度，即利用中间层，对于在计算化学任务中实现显著的性能改进和计算效率至关重要。", "translation": "预训练分子编码器在计算化学中对于属性预测和分子生成等任务变得不可或缺。然而，仅依赖最终层嵌入进行下游任务的标准做法可能会丢弃有价值的信息。在这项工作中，我们通过对五种不同分子编码器在22个ADMET属性预测任务中进行全面的层级分析，挑战了这一传统做法。我们的结果表明，来自中间层的嵌入始终优于最终层表示。具体而言，使用来自最佳中间层的固定嵌入将下游性能平均提高了5.4%，最高达到28.6%。此外，对这些中间层进行微调带来了更大的平均改进，达到8.5%，性能提升高达40.8%，在多个基准测试中取得了新的最先进结果。此外，固定嵌入性能与微调结果之间存在很强的正相关性，这支持了一种高效的“评估-然后-微调”方法，从而以降低的计算成本识别最佳层。这些发现强调了探索分子编码器完整表示深度对于实现显著性能改进和计算效率的重要性。代码已公开在https://github.com/luispintoc/Unlocking-Chemical-Insights。", "summary": "本文通过挑战仅使用最终层嵌入的传统做法，探讨了预训练分子编码器中信息未被充分利用的问题。通过对五种编码器在22个ADMET任务中的层级分析，研究发现中间层持续提供更优的分子表示。无论是使用固定嵌入还是对这些中间层进行微调，都能带来显著的性能提升，其中微调达到了新的最先进水平。研究结果强调了探索编码器完整表示深度以提高性能和计算效率的重要性，并提出了一种高效的“评估-然后-微调”策略。", "keywords": "分子表示, 分子编码器, 深度学习, 属性预测, 中间层", "comments": "这篇论文提出了一个重要的发现，挑战了计算化学中的一个常见做法。通过证明分子编码器中间层的价值，它为优化模型性能和效率开辟了新途径。所提出的“评估-然后-微调”方法实用且计算高效，使得这些见解能够立即得到应用。这项工作强调了深入理解架构（超越最终输出层）的重要性。"}}
{"id": "2506.06813", "title": "BTPD: A Multilingual Hand-curated Dataset of Bengali Transnational Political Discourse Across Online Communities", "authors": ["Dipto Das", "Syed Ishtiaque Ahmed", "Shion Guha"], "summary": "Understanding political discourse in online spaces is crucial for analyzing\npublic opinion and ideological polarization. While social computing and\ncomputational linguistics have explored such discussions in English, such\nresearch efforts are significantly limited in major yet under-resourced\nlanguages like Bengali due to the unavailability of datasets. In this paper, we\npresent a multilingual dataset of Bengali transnational political discourse\n(BTPD) collected from three online platforms, each representing distinct\ncommunity structures and interaction dynamics. Besides describing how we\nhand-curated the dataset through community-informed keyword-based retrieval,\nthis paper also provides a general overview of its topics and multilingual\ncontent.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06813v1", "AI": {"title_translation": "BTPD：一个多语言、人工整理的孟加拉语跨国政治话语在线社区数据集", "tldr": "本文介绍了BTPD，一个用于孟加拉语跨国政治话语分析的多语言人工整理数据集，旨在解决该领域数据稀缺的问题。", "motivation": "现有研究在英语政治话语分析方面进展显著，但在孟加拉语等资源不足的语言中，由于缺乏可用数据集，研究工作受到严重限制。", "method": "通过社区知情的关键词检索方法，从三个具有不同社区结构和互动动态的在线平台中人工整理并收集了BTPD数据集。", "result": "论文介绍了BTPD数据集，并提供了其主题和多语言内容的概览。", "conclusion": "论文成功地提出了一个用于分析孟加拉语跨国政治话语的多语言数据集BTPD，填补了该领域的数据空白。", "translation": "理解在线空间中的政治话语对于分析公众舆论和意识形态两极分化至关重要。虽然社会计算和计算语言学已经探索了英语中的此类讨论，但由于缺乏数据集，孟加拉语等主要但资源不足的语言中的此类研究工作受到严重限制。在本文中，我们提出了一个多语言的孟加拉语跨国政治话语（BTPD）数据集，该数据集从三个在线平台收集，每个平台都代表着独特的社区结构和互动动态。除了描述我们如何通过社区知情的关键词检索方法人工整理数据集之外，本文还提供了其主题和多语言内容的概览。", "summary": "本文介绍了BTPD，一个专门为孟加拉语跨国政治话语分析而创建的多语言、人工整理数据集。该数据集从三个在线平台收集，旨在弥补孟加拉语等资源不足语言在政治话语研究中缺乏数据的空白。论文详细描述了数据集的整理过程，并概述了其包含的主题和多语言内容。", "keywords": "孟加拉语, 政治话语, 数据集, 多语言, 在线社区", "comments": "该论文通过创建BTPD数据集，解决了孟加拉语等资源不足语言在政治话语分析领域的数据稀缺问题，为理解这些语言的在线政治讨论和意识形态两极分化提供了重要的基础资源，具有显著的实用价值和创新性。"}}
{"id": "2506.06316", "title": "A Reinforcement-Learning-Enhanced LLM Framework for Automated A/B Testing in Personalized Marketing", "authors": ["Haoyang Feng", "Yanjun Dai", "Yuan Gao"], "summary": "For personalized marketing, a new challenge of how to effectively algorithm\nthe A/B testing to maximize user response is urgently to be overcome. In this\npaper, we present a new approach, the RL-LLM-AB test framework, for using\nreinforcement learning strategy optimization combined with LLM to automate and\npersonalize A/B tests. The RL-LLM-AB test is built upon the pre-trained\ninstruction-tuned language model. It first generates A/B versions of candidate\ncontent variants using a Prompt-Conditioned Generator, and then dynamically\nembeds and fuses the user portrait and the context of the current query with\nthe multi-modal perception module to constitute the current interaction state.\nThe content version is then selected in real-time through the policy\noptimization module with an Actor-Critic structure, and long-term revenue is\nestimated according to real-time feedback (such as click-through rate and\nconversion rate). Furthermore, a Memory-Augmented Reward Estimator is embedded\ninto the framework to capture long-term user preference drift, which helps to\ngeneralize policy across multiple users and content contexts. Numerical results\ndemonstrate the superiority of our proposed RL-LLM-ABTest over existing A/B\ntesting methods, including classical A/B testing, Contextual Bandits, and\nbenchmark reinforcement learning approaches on real-world marketing data.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06316v1", "AI": {"title_translation": "强化学习增强的LLM框架，用于个性化营销中的自动化A/B测试", "tldr": "本文提出了一个RL-LLM-AB测试框架，结合强化学习和LLM实现自动化个性化A/B测试，并展示了其在真实营销数据上的优越性。", "motivation": "针对个性化营销中如何有效算法化A/B测试以最大化用户响应的挑战。", "method": "提出了RL-LLM-AB测试框架。该框架基于预训练的指令调优语言模型，通过Prompt-Conditioned Generator生成A/B版本内容，多模态感知模块融合用户画像和查询上下文构成交互状态，策略优化模块（Actor-Critic结构）实时选择内容版本并根据反馈（点击率、转化率）估计长期收益。此外，嵌入Memory-Augmented Reward Estimator以捕捉长期用户偏好漂移，泛化策略。", "result": "数值结果表明，所提出的RL-LLM-ABTest框架在真实营销数据上优于现有A/B测试方法，包括经典A/B测试、上下文强盗算法和基准强化学习方法。", "conclusion": "RL-LLM-AB测试框架能够有效自动化和个性化A/B测试，并在个性化营销中实现更好的用户响应最大化。", "translation": "对于个性化营销，如何有效算法化A/B测试以最大化用户响应是一个亟待解决的新挑战。在本文中，我们提出了一种新方法，即RL-LLM-AB测试框架，用于结合强化学习策略优化和LLM来自动化和个性化A/B测试。RL-LLM-AB测试建立在预训练的指令调优语言模型之上。它首先使用Prompt-Conditioned Generator生成A/B版本的候选内容变体，然后通过多模态感知模块动态嵌入和融合用户画像和当前查询的上下文，构成当前的交互状态。内容版本随后通过具有Actor-Critic结构的策略优化模块实时选择，并根据实时反馈（如点击率和转化率）估计长期收益。此外，框架中嵌入了一个记忆增强奖励估计器，以捕捉长期用户偏好漂移，这有助于在多个用户和内容上下文中泛化策略。数值结果表明，我们提出的RL-LLM-ABTest在真实世界营销数据上优于现有A/B测试方法，包括经典A/B测试、上下文强盗算法和基准强化学习方法。", "summary": "本文提出了一种名为RL-LLM-AB测试的创新框架，旨在通过结合强化学习的策略优化能力和大型语言模型（LLM）的生成与理解能力，实现个性化营销中的自动化A/B测试。该框架利用LLM生成内容变体，并动态整合用户画像与查询上下文以形成交互状态，随后通过基于Actor-Critic的强化学习模块实时选择最佳内容版本并估计长期收益。此外，引入记忆增强奖励估计器以适应用户偏好变化。实验结果表明，该框架在真实营销数据上显著优于传统及基准A/B测试方法。", "keywords": "强化学习, 大型语言模型, A/B测试, 个性化营销, 策略优化", "comments": "这篇论文的创新点在于将强化学习与大型语言模型相结合，应用于A/B测试的自动化和个性化，特别是在营销领域。通过整合用户画像和上下文，并引入长期偏好捕捉机制，该框架有望显著提升A/B测试的效率和效果，为个性化营销提供了一个强大的新工具。其优势在于能够实时动态调整策略并考虑长期用户反馈，超越了传统A/B测试的局限性。"}}
{"id": "2506.07372", "title": "Enhanced Consistency Bi-directional GAN(CBiGAN) for Malware Anomaly Detection", "authors": ["Thesath Wijayasiri", "Kar Wai Fok", "Vrizlynn L. L. Thing"], "summary": "Static analysis, a cornerstone technique in cybersecurity, offers a\nnoninvasive method for detecting malware by analyzing dormant software without\nexecuting potentially harmful code. However, traditional static analysis often\nrelies on biased or outdated datasets, leading to gaps in detection\ncapabilities against emerging malware threats. To address this, our study\nfocuses on the binary content of files as key features for malware detection.\nThese binary contents are transformed and represented as images, which then\nserve as inputs to deep learning models. This method takes into account the\nvisual patterns within the binary data, allowing the model to analyze potential\nmalware effectively. This paper introduces the application of the CBiGAN in the\ndomain of malware anomaly detection. Our approach leverages the CBiGAN for its\nsuperior latent space mapping capabilities, critical for modeling complex\nmalware patterns by utilizing a reconstruction error-based anomaly detection\nmethod. We utilized several datasets including both portable executable (PE)\nfiles as well as Object Linking and Embedding (OLE) files. We then evaluated\nour model against a diverse set of both PE and OLE files, including\nself-collected malicious executables from 214 malware families. Our findings\ndemonstrate the robustness of this innovative approach, with the CBiGAN\nachieving high Area Under the Curve (AUC) results with good generalizability,\nthereby confirming its capability to distinguish between benign and diverse\nmalicious files with reasonably high accuracy.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07372v1", "AI": {"title_translation": "增强一致性双向GAN (CBiGAN) 用于恶意软件异常检测", "tldr": "CBiGAN通过将二进制内容转化为图像，利用重建误差进行恶意软件异常检测，并取得了高准确率。", "motivation": "传统的静态分析依赖于有偏差或过时的数据集，导致对新兴恶意软件威胁的检测能力存在不足。", "method": "将文件的二进制内容转换为图像作为深度学习模型的输入，并应用增强一致性双向GAN (CBiGAN) 及其基于重建误差的异常检测方法来建模复杂的恶意软件模式。模型在包括可移植可执行文件 (PE) 和对象链接与嵌入 (OLE) 文件在内的多个数据集上进行了评估。", "result": "CBiGAN实现了高曲线下面积 (AUC) 结果和良好的泛化能力，能够以相当高的准确率区分良性文件和各种恶意文件。", "conclusion": "增强一致性双向GAN (CBiGAN) 是一种有效且鲁棒的恶意软件异常检测方法，能够以高准确率区分良性文件和多样化的恶意文件。", "translation": "静态分析作为网络安全领域的基石技术，通过分析休眠软件而不执行潜在有害代码，提供了一种非侵入性的恶意软件检测方法。然而，传统的静态分析通常依赖于有偏差或过时的数据集，导致在应对新兴恶意软件威胁时检测能力存在差距。为了解决这个问题，我们的研究侧重于将文件的二进制内容作为恶意软件检测的关键特征。这些二进制内容被转换并表示为图像，然后作为深度学习模型的输入。这种方法考虑了二进制数据中的视觉模式，使模型能够有效地分析潜在的恶意软件。本文介绍了CBiGAN在恶意软件异常检测领域的应用。我们的方法利用CBiGAN卓越的潜在空间映射能力，这对于通过使用基于重建误差的异常检测方法建模复杂的恶意软件模式至关重要。我们使用了包括可移植可执行文件 (PE) 和对象链接与嵌入 (OLE) 文件在内的多个数据集。然后，我们针对多样化的PE和OLE文件集（包括从214个恶意软件家族中自行收集的恶意可执行文件）评估了我们的模型。我们的研究结果证明了这种创新方法的鲁棒性，CBiGAN取得了高曲线下面积 (AUC) 结果和良好的泛化能力，从而证实了其以相当高的准确率区分良性文件和各种恶意文件的能力。", "summary": "本文提出了一种基于增强一致性双向GAN (CBiGAN) 的恶意软件异常检测方法，旨在解决传统静态分析中数据集偏差和过时的问题。该方法将文件的二进制内容转换为图像，并利用CBiGAN的重建误差进行异常检测。实验结果表明，CBiGAN在区分良性文件和多种恶意文件方面表现出高准确率、高AUC和良好的泛化能力。", "keywords": "恶意软件检测, 异常检测, CBiGAN, 静态分析, 深度学习", "comments": "该论文的创新点在于将二进制文件内容转换为图像，并将其与CBiGAN结合用于恶意软件异常检测，有效利用了深度学习在图像识别领域的优势。这种方法有望提高对新型和未知恶意软件的检测能力，但其对不同文件类型和复杂恶意软件变体的泛化能力可能需要进一步研究和验证。"}}
{"id": "2506.06804", "title": "IRS: Instance-Level 3D Scene Graphs via Room Prior Guided LiDAR-Camera Fusion", "authors": ["Hongming Chen", "Yiyang Lin", "Ziliang Li", "Biyu Ye", "Yuying Zhang", "Ximin Lyu"], "summary": "Indoor scene understanding remains a fundamental challenge in robotics, with\ndirect implications for downstream tasks such as navigation and manipulation.\nTraditional approaches often rely on closed-set recognition or loop closure,\nlimiting their adaptability in open-world environments. With the advent of\nvisual foundation models (VFMs), open-vocabulary recognition and natural\nlanguage querying have become feasible, unlocking new possibilities for 3D\nscene graph construction.\n  In this paper, we propose a robust and efficient framework for instance-level\n3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's wide\nfield of view (FOV) and long-range sensing capabilities, we rapidly acquire\nroom-level geometric priors. Multi-level VFMs are employed to improve the\naccuracy and consistency of semantic extraction. During instance fusion,\nroom-based segmentation enables parallel processing, while the integration of\ngeometric and semantic cues significantly enhances fusion accuracy and\nrobustness. Compared to state-of-the-art methods, our approach achieves up to\nan order-of-magnitude improvement in construction speed while maintaining high\nsemantic precision.\n  Extensive experiments in both simulated and real-world environments validate\nthe effectiveness of our approach. We further demonstrate its practical value\nthrough a language-guided semantic navigation task, highlighting its potential\nfor real-world robotic applications.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06804v1", "AI": {"title_translation": "IRS: 实例级3D场景图，通过房间先验引导的激光雷达-相机融合", "tldr": "提出了一种通过激光雷达-相机融合构建实例级3D场景图的框架，利用房间先验和多级VFM，显著提高了构建速度和语义精度，并支持语言引导的机器人导航。", "motivation": "室内场景理解对机器人技术至关重要，但传统方法（封闭集识别或闭环）在开放世界环境中适应性有限。视觉基础模型（VFMs）的出现使开放词汇识别和自然语言查询成为可能，为3D场景图构建提供了新机遇。", "method": "提出了一个鲁棒高效的实例级3D场景图构建框架，通过激光雷达-相机融合实现。利用激光雷达的宽视场和远距离感知能力快速获取房间级几何先验。采用多级VFMs提高语义提取的准确性和一致性。在实例融合过程中，基于房间的分割实现并行处理，同时几何和语义线索的整合显著增强了融合的准确性和鲁棒性。", "result": "相比现有方法，该方法在构建速度上实现了数量级提升，同时保持了高语义精度。在模拟和真实世界环境中都验证了其有效性，并通过语言引导的语义导航任务展示了其实用价值。", "conclusion": "该方法能够鲁棒高效地构建实例级3D场景图，在速度和精度上优于现有技术，并有望应用于实际机器人任务，如语言引导的语义导航。", "translation": "室内场景理解仍然是机器人学中的一个基本挑战，对导航和操作等下游任务具有直接影响。传统方法通常依赖于封闭集识别或闭环，限制了它们在开放世界环境中的适应性。随着视觉基础模型（VFMs）的出现，开放词汇识别和自然语言查询变得可行，为3D场景图构建解锁了新的可能性。\n在本文中，我们提出了一种通过激光雷达-相机融合构建实例级3D场景图的鲁棒高效框架。利用激光雷达的宽视场（FOV）和远距离感知能力，我们快速获取房间级几何先验。采用多级VFMs以提高语义提取的准确性和一致性。在实例融合过程中，基于房间的分割实现了并行处理，同时几何和语义线索的整合显著增强了融合的准确性和鲁棒性。与现有最先进的方法相比，我们的方法在构建速度上实现了数量级提升，同时保持了高语义精度。\n在模拟和真实世界环境中的广泛实验验证了我们方法的有效性。我们通过语言引导的语义导航任务进一步展示了其实用价值，突出了其在真实世界机器人应用中的潜力。", "summary": "本文提出了一种名为IRS的实例级3D场景图构建框架，该框架通过融合激光雷达和相机数据实现。它利用激光雷达获取房间级几何先验，并结合多级视觉基础模型进行语义提取，以提高准确性。通过基于房间的分割实现并行处理，并整合几何与语义信息，显著提升了实例融合的准确性和鲁棒性。实验证明，IRS在构建速度上比现有方法快一个数量级，同时保持了高语义精度，并在语言引导的语义导航等实际机器人应用中展现出巨大潜力。", "keywords": "3D场景图, 激光雷达-相机融合, 视觉基础模型, 房间先验, 实例级理解", "comments": "这篇论文的创新点在于其提出的激光雷达-相机融合框架，特别是利用房间先验和多级VFM来构建实例级3D场景图。其在构建速度上达到数量级提升，同时保持高精度，解决了传统方法在开放世界环境中的局限性，并为语言引导的机器人导航等实际应用提供了新的解决方案，具有重要的实用价值。"}}
{"id": "2506.07834", "title": "Execution-Aware Program Reduction for WebAssembly via Record and Replay", "authors": ["Doehyun Baek", "Daniel Lehmann", "Ben L. Titzer", "Sukyoung Ryu", "Michael Pradel"], "summary": "WebAssembly (Wasm) programs may trigger bugs in their engine implementations.\nTo aid debugging, program reduction techniques try to produce a smaller variant\nof the input program that still triggers the bug. However, existing\nexecution-unaware program reduction techniques struggle with large and complex\nWasm programs, because they rely on static information and apply syntactic\ntransformations, while ignoring the valuable information offered by the input\nprogram's execution behavior.\n  We present RR-Reduce and Hybrid-Reduce, novel execution-aware program\nreduction techniques that leverage execution behaviors via record and replay.\nRR-Reduce identifies a bug-triggering function as the target function, isolates\nthat function from the rest of the program, and generates a reduced program\nthat replays only the interactions between the target function and the rest of\nthe program. Hybrid-Reduce combines a complementary execution-unaware reduction\ntechnique with RR-Reduce to further reduce program size.\n  We evaluate RR-Reduce and Hybrid-Reduce on 28 Wasm programs that trigger a\ndiverse set of bugs in three engines. On average, RR-Reduce reduces the\nprograms to 1.20 percent of their original size in 14.5 minutes, which\noutperforms the state of the art by 33.15 times in terms of reduction time.\nHybrid-Reduce reduces the programs to 0.13 percent of their original size in\n3.5 hours, which outperforms the state of the art by 3.42 times in terms of\nreduced program size and 2.26 times in terms of reduction time. We envision\nRR-Reduce as the go-to tool for rapid, on-demand debugging in minutes, and\nHybrid-Reduce for scenarios where developers require the smallest possible\nprograms.", "comment": null, "cate": "cs.PL", "url": "http://arxiv.org/abs/2506.07834v1", "AI": {"title_translation": "通过记录和回放实现WebAssembly的执行感知程序精简", "tldr": "本文提出了RR-Reduce和Hybrid-Reduce，这是两种新颖的执行感知程序精简技术，用于WebAssembly (Wasm) 程序调试。它们通过记录和回放利用执行行为，显著优于现有方法，在精简速度和程序大小方面均有大幅提升。", "motivation": "现有的执行不感知程序精简技术难以处理大型和复杂的WebAssembly (Wasm) 程序，因为它们依赖于静态信息和语法转换，而忽略了输入程序执行行为提供的宝贵信息，这阻碍了WebAssembly引擎中错误的调试。", "method": "本文提出了两种执行感知程序精简技术：\n1. RR-Reduce：识别触发错误的函数作为目标函数，将其从程序其余部分中分离，并通过回放目标函数与程序其余部分之间的交互来生成精简程序。\n2. Hybrid-Reduce：将RR-Reduce与一种互补的执行不感知精简技术结合，以进一步减小程序大小。\n两种技术都通过记录和回放来利用程序的执行行为。", "result": "在28个触发各种错误的Wasm程序上进行了评估：\n- RR-Reduce：平均在14.5分钟内将程序精简到其原始大小的1.20%，精简时间比现有技术快33.15倍。\n- Hybrid-Reduce：平均在3.5小时内将程序精简到其原始大小的0.13%，精简程序大小比现有技术好3.42倍，精简时间比现有技术快2.26倍。", "conclusion": "RR-Reduce被设想为几分钟内快速、按需调试的首选工具，而Hybrid-Reduce则适用于开发人员需要最小程序的场景。这些技术为WebAssembly程序的调试精简提供了显著的改进。", "translation": "WebAssembly (Wasm) 程序可能会触发其引擎实现中的错误。为了帮助调试，程序精简技术尝试生成输入程序的较小变体，该变体仍能触发错误。然而，现有的执行不感知程序精简技术难以处理大型和复杂的 Wasm 程序，因为它们依赖于静态信息并应用语法转换，同时忽略了输入程序执行行为提供的宝贵信息。\n我们提出了 RR-Reduce 和 Hybrid-Reduce，这是新颖的执行感知程序精简技术，它们通过记录和回放利用执行行为。RR-Reduce 识别一个触发错误的函数作为目标函数，将该函数从程序的其余部分中分离出来，并生成一个精简的程序，该程序只回放目标函数与程序其余部分之间的交互。Hybrid-Reduce 将一种互补的执行不感知精简技术与 RR-Reduce 结合起来，以进一步减小程序大小。\n我们在 28 个 Wasm 程序上评估了 RR-Reduce 和 Hybrid-Reduce，这些程序在三个引擎中触发了各种错误。平均而言，RR-Reduce 在 14.5 分钟内将程序精简到其原始大小的 1.20%，在精简时间方面比现有技术快 33.15 倍。Hybrid-Reduce 在 3.5 小时内将程序精简到其原始大小的 0.13%，在精简程序大小方面比现有技术好 3.42 倍，在精简时间方面好 2.26 倍。我们将 RR-Reduce 设想为几分钟内快速、按需调试的首选工具，而 Hybrid-Reduce 则适用于开发人员需要最小程序的场景。", "summary": "本文介绍了RR-Reduce和Hybrid-Reduce，这两种新颖的执行感知程序精简技术，专为WebAssembly (Wasm) 程序设计。与现有依赖静态信息、忽略执行行为的方法不同，这些技术通过记录和回放来识别并隔离触发错误的函数，或结合其他精简方法。评估结果表明，RR-Reduce显著提高了精简速度（比现有技术快33.15倍），而Hybrid-Reduce则能实现更小的程序大小（原始大小的0.13%）和更快的精简时间，使其成为Wasm调试的重要工具。", "keywords": "WebAssembly, 程序精简, 调试, 记录和回放, 执行感知", "comments": "本文的创新之处在于通过记录和回放利用程序的执行行为来进行程序精简，这相较于静态的、执行不感知的现有方法是一个重大改进。这种方法解决了调试复杂Wasm程序中的关键挑战，提供了快速精简和极限大小精简的能力。实验中展示的显著性能提升对实际的调试工作流程具有高度影响力。"}}
{"id": "2506.06748", "title": "THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised Video Object Segmentation", "authors": ["Mingqi Gao", "Haoran Duan", "Tianlu Zhang", "Jungong Han"], "summary": "In this report, we describe our approach to egocentric video object\nsegmentation. Our method combines large-scale visual pretraining from SAM2 with\ndepth-based geometric cues to handle complex scenes and long-term tracking. By\nintegrating these signals in a unified framework, we achieve strong\nsegmentation performance. On the VISOR test set, our method reaches a J&F score\nof 90.1%.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06748v1", "AI": {"title_translation": "THU-Warwick 参加 EPIC-KITCHEN 2025 挑战赛：半监督视频对象分割", "tldr": "该论文介绍了THU-Warwick团队为EPIC-KITCHEN 2025挑战赛提交的半监督视频对象分割方法，该方法结合SAM2预训练和深度几何线索，在VISOR数据集上达到了90.1%的J&F分数。", "motivation": "解决以自我为中心的视频对象分割问题，特别是处理复杂场景和实现长期跟踪。", "method": "该方法将来自SAM2的大规模视觉预训练与基于深度的几何线索相结合，并在统一的框架中集成这些信号。", "result": "在VISOR测试集上，该方法达到了90.1%的J&F分数，显示出强大的分割性能。", "conclusion": "该方法通过结合视觉预训练和深度几何线索，在以自我为中心的视频对象分割方面取得了强大的性能。", "translation": "本报告描述了我们处理以自我为中心的视频对象分割的方法。我们的方法将SAM2的大规模视觉预训练与基于深度的几何线索相结合，以处理复杂场景和长期跟踪。通过在统一框架中整合这些信号，我们实现了强大的分割性能。在VISOR测试集上，我们的方法达到了90.1%的J&F分数。", "summary": "本文介绍了THU-Warwick团队为EPIC-KITCHEN 2025挑战赛提交的半监督视频对象分割方法。该方法创新性地结合了SAM2的大规模视觉预训练模型和基于深度的几何线索，旨在有效处理复杂场景下的以自我为中心的视频对象分割及长期跟踪问题。通过在统一框架中整合这些技术，该方法在VISOR测试集上取得了显著的90.1%的J&F分数，展现出强大的分割能力。", "keywords": "视频对象分割, 半监督, SAM2, 深度信息, EPIC-KITCHEN", "comments": "该论文的创新点在于将强大的预训练模型（SAM2）与深度几何信息有效结合，以解决以自我为中心的视频对象分割中的复杂性和长期跟踪挑战。在VISOR数据集上取得的高J&F分数（90.1%）表明了该方法在实际应用中的有效性和鲁棒性，对于未来以自我为中心视觉任务的研究具有重要意义。"}}
{"id": "2506.06750", "title": "Bio-Inspired Classification: Combining Information Theory and Spiking Neural Networks -- Influence of the Learning Rules", "authors": ["Zofia Rudnicka", "Janusz Szczepanski", "Agnieszka Pregowska"], "summary": "Training of Spiking Neural Networks (SNN) is challenging due to their unique\nproperties, including temporal dynamics, non-differentiability of spike events,\nand sparse event-driven activations. In this paper, we widely consider the\ninfluence of the type of chosen learning algorithm, including bioinspired\nlearning rules on the accuracy of classification. We proposed a bioinspired\nclassifier based on the combination of SNN and Lempel-Ziv complexity (LZC).\nThis approach synergizes the strengths of SNNs in temporal precision and\nbiological realism with LZC's structural complexity analysis, facilitating\nefficient and interpretable classification of spatiotemporal neural data. It\nturned out that the classic backpropagation algorithm achieves excellent\nclassification accuracy, but at extremely high computational cost, which makes\nit impractical for real-time applications. Biologically inspired learning\nalgorithms such as tempotron and Spikprop provide increased computational\nefficiency while maintaining competitive classification performance, making\nthem suitable for time-sensitive tasks. The results obtained indicate that the\nselection of the most appropriate learning algorithm depends on the trade-off\nbetween classification accuracy and computational cost as well as application\nconstraints.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06750v1", "AI": {"title_translation": "生物启发式分类：结合信息论与脉冲神经网络——学习规则的影响", "tldr": "本文探讨了不同学习算法对脉冲神经网络（SNN）分类准确性的影响，并提出了一种结合SNN和Lempel-Ziv复杂度的生物启发式分类器，旨在平衡分类精度和计算效率。", "motivation": "脉冲神经网络（SNN）的训练由于其时间动态性、脉冲事件的不可微性以及稀疏事件驱动激活等独特属性而具有挑战性。", "method": "本文广泛考虑了所选学习算法类型（包括生物启发式学习规则）对分类准确性的影响。提出了一种基于SNN和Lempel-Ziv复杂度（LZC）结合的生物启发式分类器，该方法结合了SNN在时间精度和生物真实性方面的优势与LZC的结构复杂度分析，以促进时空神经数据的有效和可解释分类。", "result": "经典的反向传播算法取得了出色的分类准确性，但计算成本极高，不适用于实时应用。Tempotron和Spikprop等生物启发式学习算法在提高计算效率的同时保持了有竞争力的分类性能，适用于时间敏感的任务。", "conclusion": "最合适的学习算法的选择取决于分类准确性与计算成本之间的权衡以及应用限制。", "translation": "脉冲神经网络（SNN）的训练由于其独特属性（包括时间动态性、脉冲事件的不可微性以及稀疏事件驱动激活）而具有挑战性。在本文中，我们广泛考虑了所选学习算法类型（包括生物启发式学习规则）对分类准确性的影响。我们提出了一种基于SNN和Lempel-Ziv复杂度（LZC）结合的生物启发式分类器。该方法结合了SNN在时间精度和生物真实性方面的优势与LZC的结构复杂度分析，以促进时空神经数据的有效和可解释分类。结果表明，经典的反向传播算法取得了出色的分类准确性，但计算成本极高，这使其不适用于实时应用。Tempotron和Spikprop等生物启发式学习算法在提高计算效率的同时保持了有竞争力的分类性能，使其适用于时间敏感的任务。所获得的结果表明，最合适的学习算法的选择取决于分类准确性与计算成本之间的权衡以及应用限制。", "summary": "本研究旨在克服脉冲神经网络（SNN）训练的挑战，通过结合SNN和Lempel-Ziv复杂度（LZC）提出了一种生物启发式分类器。研究比较了不同学习规则对SNN分类准确性和计算效率的影响，发现经典的反向传播算法虽然准确但计算成本高昂，而Tempotron和Spikprop等生物启发式算法能在保持竞争性性能的同时显著提高效率，为实时应用提供了更可行的选择。", "keywords": "脉冲神经网络, 生物启发式学习, Lempel-Ziv复杂度, 分类, 学习规则", "comments": "本文的创新点在于结合了SNN的生物真实性和LZC的信息理论分析，为时空神经数据分类提供了一种新颖且可解释的方法。其重要性在于揭示了SNN学习规则选择的权衡，为实际应用中SNN的部署提供了指导。尤其强调了生物启发式算法在计算效率方面的优势，这对于资源受限或实时性要求高的场景具有重要意义。"}}
{"id": "2506.06663", "title": "Skewness of von Neumann entropy over Bures-Hall random states", "authors": ["Linfeng Wei", "Youyi Huang", "Lu Wei"], "summary": "We study the degree of entanglement, as measured by von Neumann entropy, of\nbipartite systems over the Bures-Hall ensemble. Closed-form expressions of the\nfirst two cumulants of von Neumann entropy over the ensemble have been recently\nderived in the literature. In this paper, we focus on its skewness by\ncalculating the third cumulant that describes the degree of asymmetry of the\ndistribution. The main result is an exact closed-form formula of the third\ncumulant, which leads to a more accurate approximation to the distribution of\nvon Neumann entropy. The key to obtaining the result lies on finding a dozen of\nnew summation identities in simplifying a large number of finite summations\ninvolving polygamma functions.", "comment": "33 pages, 2 figures", "cate": "math-ph", "url": "http://arxiv.org/abs/2506.06663v1", "AI": {"title_translation": "Bures-Hall随机态中冯诺依曼熵的偏度", "tldr": "本文计算了Bures-Hall随机态中冯诺依曼熵的第三个累积量（偏度），得到了精确的闭合形式公式，并通过发现新的求和恒等式，提高了冯诺依曼熵分布的近似精度。", "motivation": "本文旨在研究Bures-Hall系综中冯诺依曼熵的偏度，通过计算其第三个累积量来描述分布的不对称程度，以补充现有文献中仅包含前两个累积量的研究。", "method": "通过计算冯诺依曼熵的第三个累积量来研究其偏度。关键在于发现了十几个新的求和恒等式，用于简化涉及多伽马函数的大量有限求和。", "result": "得到了冯诺依曼熵第三个累积量的精确闭合形式公式。", "conclusion": "所推导的第三个累积量的精确闭合形式公式，使得冯诺依曼熵分布的近似更加准确。", "translation": "我们研究了Bures-Hall系综中双分系统纠缠的程度，以冯诺依曼熵衡量。最近文献中已经推导出了该系综上冯诺依曼熵前两个累积量的闭合形式表达式。在本文中，我们通过计算描述分布不对称程度的第三个累积量来关注其偏度。主要结果是第三个累积量的精确闭合形式公式，这使得冯诺依曼熵的分布近似更加准确。获得结果的关键在于找到十几个新的求和恒等式，以简化大量涉及多伽马函数的有限求和。", "summary": "本文研究了Bures-Hall系综中双分系统冯诺依曼熵的偏度，扩展了先前仅涉及前两个累积量的工作。作者推导出了第三个累积量的精确闭合形式公式，该公式量化了分布的不对称性。这一成果的取得得益于发现了新的求和恒等式，用于简化多伽马函数的求和，最终使得冯诺依曼熵分布的近似更加精确。", "keywords": "冯诺依曼熵, Bures-Hall系综, 偏度, 累积量, 求和恒等式", "comments": "该论文的创新之处在于推导出了冯诺依曼熵第三个累积量的精确闭合形式公式，这极大地提高了对其分布的理解和近似精度。同时，发现“十几个新的求和恒等式”是方法学上的一个重要贡献，展现了解决量子信息理论中复杂问题（特别是纠缠量化）的深厚数学方法。"}}
{"id": "2506.06444", "title": "Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance", "authors": ["Ruizhong Qiu", "Gaotang Li", "Tianxin Wei", "Jingrui He", "Hanghang Tong"], "summary": "Existing safety assurance research has primarily focused on training-phase\nalignment to instill safe behaviors into LLMs. However, recent studies have\nexposed these methods' susceptibility to diverse jailbreak attacks.\nConcurrently, inference scaling has significantly advanced LLM reasoning\ncapabilities but remains unexplored in the context of safety assurance.\nAddressing this gap, our work pioneers inference scaling for robust and\neffective LLM safety against emerging threats. We reveal that conventional\ninference scaling techniques, despite their success in reasoning tasks, perform\npoorly in safety contexts, even falling short of basic approaches like\nBest-of-N Sampling. We attribute this inefficiency to a newly identified\nchallenge, the exploration--efficiency dilemma, arising from the high\ncomputational overhead associated with frequent process reward model (PRM)\nevaluations. To overcome this dilemma, we propose SAFFRON, a novel inference\nscaling paradigm tailored explicitly for safety assurance. Central to our\napproach is the introduction of a multifurcation reward model (MRM) that\nsignificantly reduces the required number of reward model evaluations. To\noperationalize this paradigm, we further propose: (i) a partial supervision\ntraining objective for MRM, (ii) a conservative exploration constraint to\nprevent out-of-distribution explorations, and (iii) a Trie-based key--value\ncaching strategy that facilitates cache sharing across sequences during tree\nsearch. Extensive experiments validate the effectiveness of our method.\nAdditionally, we publicly release our trained multifurcation reward model\n(Saffron-1) and the accompanying token-level safety reward dataset (Safety4M)\nto accelerate future research in LLM safety. Our code, model, and data are\npublicly available at https://github.com/q-rz/saffron , and our project\nhomepage is at https://q-rz.github.io/p/saffron .", "comment": "19 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06444v1", "AI": {"title_translation": "Saffron-1：迈向LLM安全保障的推理扩展范式", "tldr": "现有LLM安全保障方法易受攻击，且推理扩展未应用于安全领域。本文提出SAFFRON，一种新的推理扩展范式，通过多分支奖励模型（MRM）解决探索-效率困境，提高LLM安全性。", "motivation": "现有LLM安全保障主要集中于训练阶段对齐，但易受越狱攻击。同时，推理扩展在LLM推理能力上取得显著进展，但在安全保障方面尚未被探索，传统推理扩展技术在安全上下文中表现不佳。", "method": "提出SAFFRON，一个专门为安全保障量身定制的新型推理扩展范式。核心是引入多分支奖励模型（MRM），显著减少所需的奖励模型评估次数，以解决探索-效率困境。为实现此范式，进一步提出：(i) MRM的部分监督训练目标，(ii) 一个保守的探索约束以防止越界探索，以及 (iii) 一个基于Trie的键值缓存策略，该策略有助于在树搜索期间实现序列间的缓存共享。", "result": "发现传统的推理扩展技术在安全上下文中表现不佳，甚至不如Best-of-N采样。广泛的实验验证了所提方法的有效性。公开发布了训练好的多分支奖励模型（Saffron-1）和配套的token级安全奖励数据集（Safety4M）。", "conclusion": "SAFFRON范式通过创新的MRM和相关策略，有效克服了LLM安全保障中的探索-效率困境，显著提升了LLM的安全性，并为未来的研究提供了模型和数据集资源。", "translation": "现有安全保障研究主要集中于训练阶段对齐，以向大型语言模型（LLMs）灌输安全行为。然而，最近的研究揭示了这些方法容易受到各种越狱攻击。与此同时，推理扩展显著提升了LLMs的推理能力，但在安全保障方面仍未被探索。为了弥补这一空白，我们的工作开创性地将推理扩展应用于LLMs的鲁棒有效安全保障，以应对新兴威胁。我们发现，传统的推理扩展技术尽管在推理任务中取得了成功，但在安全上下文中表现不佳，甚至不如像Best-of-N采样这样的基本方法。我们将这种低效归因于一个新发现的挑战——探索-效率困境，该困境源于频繁的过程奖励模型（PRM）评估所带来的高计算开销。为了克服这一困境，我们提出了SAFFRON，一个专门为安全保障量身定制的新型推理扩展范式。我们方法的核心是引入了一种多分支奖励模型（MRM），它显著减少了所需的奖励模型评估次数。为了实现这一范式，我们进一步提出了：(i) MRM的部分监督训练目标，(ii) 一个保守的探索约束以防止越界探索，以及 (iii) 一个基于Trie的键值缓存策略，该策略有助于在树搜索期间实现序列间的缓存共享。广泛的实验验证了我们方法的有效性。此外，我们公开发布了我们训练好的多分支奖励模型（Saffron-1）和配套的token级安全奖励数据集（Safety4M），以加速LLM安全领域的未来研究。我们的代码、模型和数据可在https://github.com/q-rz/saffron 公开获取，我们的项目主页是https://q-rz.github.io/p/saffron 。", "summary": "针对现有LLM安全保障方法易受越狱攻击且推理扩展未应用于安全领域的现状，本文提出了SAFFRON，一个创新的推理扩展范式，旨在增强LLM的安全性。SAFFRON通过引入多分支奖励模型（MRM）来解决探索-效率困境，显著减少了奖励模型评估的计算开销。该范式还包括MRM的部分监督训练、保守探索约束和基于Trie的缓存策略。实验证明其有效性，并公开了Saffron-1模型和Safety4M数据集，以促进LLM安全研究。", "keywords": "LLM安全, 推理扩展, 多分支奖励模型, 探索-效率困境, 越狱攻击", "comments": "这篇论文在LLM安全保障领域引入了一个新颖的视角，将推理扩展技术应用于此前未被充分探索的安全上下文。其核心创新在于提出了多分支奖励模型（MRM）来解决“探索-效率困境”，这对于降低计算成本和提高安全保障效率至关重要。通过公开发布模型和数据集，该工作对社区研究具有重要推动作用。"}}
{"id": "2506.06816", "title": "How do datasets, developers, and models affect biases in a low-resourced language?", "authors": ["Dipto Das", "Shion Guha", "Bryan Semaan"], "summary": "Sociotechnical systems, such as language technologies, frequently exhibit\nidentity-based biases. These biases exacerbate the experiences of historically\nmarginalized communities and remain understudied in low-resource contexts.\nWhile models and datasets specific to a language or with multilingual support\nare commonly recommended to address these biases, this paper empirically tests\nthe effectiveness of such approaches in the context of gender, religion, and\nnationality-based identities in Bengali, a widely spoken but low-resourced\nlanguage. We conducted an algorithmic audit of sentiment analysis models built\non mBERT and BanglaBERT, which were fine-tuned using all Bengali sentiment\nanalysis (BSA) datasets from Google Dataset Search. Our analyses showed that\nBSA models exhibit biases across different identity categories despite having\nsimilar semantic content and structure. We also examined the inconsistencies\nand uncertainties arising from combining pre-trained models and datasets\ncreated by individuals from diverse demographic backgrounds. We connected these\nfindings to the broader discussions on epistemic injustice, AI alignment, and\nmethodological decisions in algorithmic audits.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06816v1", "AI": {"title_translation": "数据集、开发者和模型如何影响低资源语言中的偏见？", "tldr": "本文经验性地测试了在孟加拉语（一种低资源语言）中，针对性别、宗教和国籍身份的偏见，通过使用特定语言模型和多语言支持来解决这些偏见的效果。研究发现，即使语义内容和结构相似，孟加拉语情感分析模型仍表现出偏见。", "motivation": "语言技术等社会技术系统常表现出基于身份的偏见，这加剧了历史上被边缘化社区的经历，且在低资源语境中研究不足。尽管通常建议使用特定语言或多语言支持的模型和数据集来解决这些偏见，但这些方法的有效性尚未得到充分的实证检验。", "method": "研究对基于mBERT和BanglaBERT构建的情感分析模型进行了算法审计，这些模型使用Google Dataset Search中的所有孟加拉语情感分析（BSA）数据集进行了微调。分析了不同身份类别（性别、宗教、国籍）的偏见，并检查了结合预训练模型和由不同人口背景的个人创建的数据集所产生的不一致性和不确定性。", "result": "分析表明，尽管语义内容和结构相似，BSA模型在不同身份类别中表现出偏见。研究还发现，结合由不同人口背景的个人创建的预训练模型和数据集会导致不一致性和不确定性。", "conclusion": "研究结果与关于认知不正义、AI对齐以及算法审计中方法论决策的更广泛讨论相关联。", "translation": "社会技术系统，如语言技术，经常表现出基于身份的偏见。这些偏见加剧了历史上被边缘化社区的经历，并且在低资源环境中仍未得到充分研究。尽管通常建议使用特定语言或多语言支持的模型和数据集来解决这些偏见，但本文在孟加拉语（一种广泛使用但资源匮乏的语言）中，针对性别、宗教和国籍身份，实证检验了此类方法的有效性。我们对基于mBERT和BanglaBERT构建的情感分析模型进行了算法审计，这些模型使用Google Dataset Search中的所有孟加拉语情感分析（BSA）数据集进行了微调。我们的分析表明，尽管语义内容和结构相似，BSA模型在不同身份类别中表现出偏见。我们还检查了结合预训练模型和由不同人口背景的个人创建的数据集所产生的不一致性和不确定性。我们将这些发现与关于认知不正义、AI对齐和算法审计中方法论决策的更广泛讨论联系起来。", "summary": "本文实证研究了在低资源语言孟加拉语中，数据集、开发者和模型如何影响基于性别、宗教和国籍的偏见。通过对使用mBERT和BanglaBERT构建的情感分析模型进行算法审计，并利用所有孟加拉语情感分析数据集进行微调，研究发现这些模型在不同身份类别中存在偏见，即使语义内容和结构相似。同时，文章还探讨了结合不同背景的预训练模型和数据集所导致的不一致性，并将这些发现与认知不正义、AI对齐及算法审计的方法论决策等更广泛的议题联系起来。", "keywords": "低资源语言, 偏见, 孟加拉语, 情感分析, 算法审计", "comments": "本文针对低资源语言中的偏见问题进行了重要的实证研究，填补了该领域研究不足的空白。其创新之处在于通过算法审计具体分析了数据集、开发者和模型对偏见的影响，并将其与更宏观的认知不正义和AI对齐问题相结合，具有重要的理论和实践意义。研究结果揭示了即使在语义相似的情况下，模型仍可能存在偏见，这对于开发更公平的AI系统具有指导意义。"}}
{"id": "2506.06320", "title": "EvoGrad: Metaheuristics in a Differentiable Wonderland", "authors": ["Beatrice F. R. Citterio", "Andrea Tangherloni"], "summary": "Differentiable programming has revolutionised optimisation by enabling\nefficient gradient-based training of complex models, such as Deep Neural\nNetworks (NNs) with billions and trillions of parameters. However, traditional\nEvolutionary Computation (EC) and Swarm Intelligence (SI) algorithms, widely\nsuccessful in discrete or complex search spaces, typically do not leverage\nlocal gradient information, limiting their optimisation efficiency. In this\npaper, we introduce EvoGrad, a unified differentiable framework that integrates\nEC and SI with gradient-based optimisation through backpropagation. EvoGrad\nconverts conventional evolutionary and swarm operators (e.g., selection,\nmutation, crossover, and particle updates) into differentiable operators,\nfacilitating end-to-end gradient optimisation. Extensive experiments on\nbenchmark optimisation functions and training of small NN regressors reveal\nthat our differentiable versions of EC and SI metaheuristics consistently\noutperform traditional, gradient-agnostic algorithms in most scenarios. Our\nresults show the substantial benefits of fully differentiable evolutionary and\nswarm optimisation, setting a new standard for hybrid optimisation frameworks.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06320v1", "AI": {"title_translation": "EvoGrad：可微分仙境中的元启发式算法", "tldr": "EvoGrad是一个将进化计算和群智能算法与梯度优化相结合的可微分框架，通过使传统操作可微分，显著提高了优化效率，并在实验中超越了传统算法。", "motivation": "传统的进化计算（EC）和群智能（SI）算法在离散或复杂搜索空间中表现出色，但通常不利用局部梯度信息，这限制了它们的优化效率。而可微分编程通过启用高效的基于梯度的训练，彻底改变了优化领域。", "method": "本文引入了EvoGrad，一个统一的可微分框架，通过反向传播将EC和SI与基于梯度的优化相结合。EvoGrad将传统的进化和群智能操作符（例如选择、变异、交叉和粒子更新）转换为可微分操作符，从而实现端到端的梯度优化。", "result": "在基准优化函数和小型神经网络回归器的训练中，EvoGrad的可微分版本的EC和SI元启发式算法在大多数情况下始终优于传统的、不感知梯度的算法。结果表明完全可微分的进化和群智能优化具有显著优势。", "conclusion": "本文提出的完全可微分的进化和群智能优化方法具有显著优势，为混合优化框架设定了新标准。", "translation": "可微分编程通过实现复杂模型（如具有数十亿甚至数万亿参数的深度神经网络）的高效基于梯度的训练，彻底改变了优化领域。然而，传统的进化计算（EC）和群智能（SI）算法在离散或复杂搜索空间中取得了广泛成功，但通常不利用局部梯度信息，这限制了它们的优化效率。在本文中，我们引入了EvoGrad，一个统一的可微分框架，通过反向传播将EC和SI与基于梯度的优化相结合。EvoGrad将传统的进化和群智能操作符（例如选择、变异、交叉和粒子更新）转换为可微分操作符，从而实现端到端的梯度优化。在基准优化函数和小型神经网络回归器的训练中，我们对EC和SI元启发式算法的可微分版本进行了大量实验，结果显示它们在大多数情况下始终优于传统的、不感知梯度的算法。我们的结果表明完全可微分的进化和群智能优化具有显著优势，为混合优化框架设定了新标准。", "summary": "本文提出了EvoGrad，一个创新的可微分框架，它将传统的进化计算（EC）和群智能（SI）算法与基于梯度的优化方法相结合。通过将EC和SI的常见操作（如选择、变异、交叉和粒子更新）转化为可微分形式，EvoGrad实现了端到端的梯度优化。实验结果表明，与传统的、不感知梯度的算法相比，EvoGrad在基准测试和神经网络训练中表现出显著的性能提升，为混合优化领域树立了新标准。", "keywords": "EvoGrad, 可微分编程, 进化计算, 群智能, 梯度优化", "comments": "EvoGrad的创新之处在于它首次统一了进化计算/群智能与可微分编程，使得元启发式算法能够利用梯度信息，从而显著提高了优化效率。这对于解决传统EC/SI在连续优化和深度学习训练中效率不足的问题具有重要意义，并可能开启混合优化算法的新研究方向。"}}
{"id": "2506.07392", "title": "From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks", "authors": ["Yuyang Zhou", "Guang Cheng", "Kang Du", "Zihan Chen", "Tian Qin", "Yuyu Zhao"], "summary": "The proliferation of unmanned aerial vehicle (UAV) swarms has enabled a wide\nrange of mission-critical applications, but also exposes UAV networks to severe\nDenial-of-Service (DoS) threats due to their open wireless environment, dynamic\ntopology, and resource constraints. Traditional static or centralized defense\nmechanisms are often inadequate for such dynamic and distributed scenarios. To\naddress these challenges, we propose a novel federated multi-agent deep\nreinforcement learning (FMADRL)-driven moving target defense (MTD) framework\nfor proactive and adaptive DoS mitigation in UAV swarm networks. Specifically,\nwe design three lightweight and coordinated MTD mechanisms, including leader\nswitching, route mutation, and frequency hopping, that leverage the inherent\nflexibility of UAV swarms to disrupt attacker efforts and enhance network\nresilience. The defense problem is formulated as a multi-agent partially\nobservable Markov decision process (POMDP), capturing the distributed,\nresource-constrained, and uncertain nature of UAV swarms under attack. Each UAV\nis equipped with a local policy agent that autonomously selects MTD actions\nbased on partial observations and local experiences. By employing a policy\ngradient-based FMADRL algorithm, UAVs collaboratively optimize their defense\npolicies via reward-weighted aggregation, enabling distributed learning without\nsharing raw data and thus reducing communication overhead. Extensive\nsimulations demonstrate that our approach significantly outperforms\nstate-of-the-art baselines, achieving up to a 34.6% improvement in attack\nmitigation rate, a reduction in average recovery time of up to 94.6%, and\ndecreases in energy consumption and defense cost by as much as 29.3% and 98.3%,\nrespectively, while maintaining robust mission continuity under various DoS\nattack strategies.", "comment": "13pages; In submission", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07392v1", "AI": {"title_translation": "从静态防御到自适应防御：联邦多智能体深度强化学习驱动的无人机蜂群网络中DoS攻击的动态目标防御", "tldr": "本文提出了一种基于联邦多智能体深度强化学习（FMADRL）的动态目标防御（MTD）框架，用于主动和自适应地缓解无人机蜂群网络中的DoS攻击，并通过仿真验证了其显著优于现有技术。", "motivation": "无人机蜂群网络因其开放的无线环境、动态拓扑和资源限制，极易受到拒绝服务（DoS）攻击。传统的静态或集中式防御机制在应对这种动态和分布式场景时往往不足。", "method": "提出了一种联邦多智能体深度强化学习（FMADRL）驱动的动态目标防御（MTD）框架。设计了三种轻量级且协调的MTD机制：领导者切换、路由变异和频率跳变。将防御问题建模为多智能体部分可观测马尔可夫决策过程（POMDP）。每个无人机配备本地策略智能体，通过基于策略梯度的FMADRL算法，利用奖励加权聚合协作优化防御策略，实现不共享原始数据的分布式学习。", "result": "仿真结果表明，该方法在攻击缓解率方面提高了34.6%，平均恢复时间缩短了94.6%，能耗降低了29.3%，防御成本降低了98.3%，同时在各种DoS攻击策略下保持了任务的鲁棒连续性。", "conclusion": "该研究提出了一种有效的联邦多智能体深度强化学习驱动的动态目标防御框架，能够显著提高无人机蜂群网络在DoS攻击下的韧性、效率和任务连续性。", "translation": "无人机（UAV）蜂群的普及使得广泛的任务关键型应用成为可能，但由于其开放的无线环境、动态拓扑和资源限制，也使无人机网络面临严重的拒绝服务（DoS）威胁。传统的静态或集中式防御机制往往不足以应对这种动态和分布式场景。为了解决这些挑战，我们提出了一种新颖的联邦多智能体深度强化学习（FMADRL）驱动的动态目标防御（MTD）框架，用于在无人机蜂群网络中主动和自适应地缓解DoS攻击。具体而言，我们设计了三种轻量级且协调的MTD机制，包括领导者切换、路由变异和频率跳变，这些机制利用无人机蜂群固有的灵活性来扰乱攻击者的努力并增强网络韧性。防御问题被建模为多智能体部分可观测马尔可夫决策过程（POMDP），捕捉了受攻击下无人机蜂群的分布式、资源受限和不确定性。每架无人机都配备了一个本地策略智能体，该智能体根据部分观测和本地经验自主选择MTD动作。通过采用基于策略梯度的FMADRL算法，无人机通过奖励加权聚合协作优化其防御策略，实现不共享原始数据的分布式学习，从而减少通信开销。广泛的仿真表明，我们的方法显著优于现有技术，在攻击缓解率方面提高了34.6%，平均恢复时间缩短了94.6%，能耗和防御成本分别降低了29.3%和98.3%，同时在各种DoS攻击策略下保持了任务的鲁棒连续性。", "summary": "本文提出了一种新颖的联邦多智能体深度强化学习（FMADRL）驱动的动态目标防御（MTD）框架，旨在主动和自适应地缓解无人机蜂群网络中的拒绝服务（DoS）攻击。该框架设计了领导者切换、路由变异和频率跳变三种轻量级且协调的MTD机制。防御问题被建模为多智能体部分可观测马尔可夫决策过程，其中无人机通过基于策略梯度的FMADRL算法协作优化其防御策略，实现分布式学习并减少通信开销。广泛的仿真实验证明，该方法在攻击缓解率、恢复时间、能耗和防御成本方面均显著优于现有技术，同时保持了任务的鲁棒性。", "keywords": "无人机蜂群网络, 动态目标防御, 联邦多智能体深度强化学习, DoS攻击, 网络安全", "comments": "这项研究的创新之处在于将联邦多智能体深度强化学习与动态目标防御相结合，为无人机蜂群网络中的DoS攻击提供了一种自适应、分布式且高效的解决方案。通过避免原始数据共享，该方法解决了分布式学习中的隐私和通信开销问题，对于资源受限的无人机网络具有重要意义。其显著的性能提升表明了该框架在实际应用中的巨大潜力。"}}
{"id": "2506.06811", "title": "RF-Source Seeking with Obstacle Avoidance using Real-time Modified Artificial Potential Fields in Unknown Environments", "authors": ["Shahid Mohammad Mulla", "Aryan Kanakapudi", "Lakshmi Narasimhan", "Anuj Tiwari"], "summary": "Navigation of UAVs in unknown environments with obstacles is essential for\napplications in disaster response and infrastructure monitoring. However,\nexisting obstacle avoidance algorithms, such as Artificial Potential Field\n(APF) are unable to generalize across environments with different obstacle\nconfigurations. Furthermore, the precise location of the final target may not\nbe available in applications such as search and rescue, in which case\napproaches such as RF source seeking can be used to align towards the target\nlocation. This paper proposes a real-time trajectory planning method, which\ninvolves real-time adaptation of APF through a sampling-based approach. The\nproposed approach utilizes only the bearing angle of the target without its\nprecise location, and adjusts the potential field parameters according to the\nenvironment with new obstacle configurations in real time. The main\ncontributions of the article are i) an RF source seeking algorithm to provide a\nbearing angle estimate using RF signal calculations based on antenna placement,\nand ii) a modified APF for adaptable collision avoidance in changing\nenvironments, which are evaluated separately in the simulation software Gazebo,\nusing ROS2 for communication. Simulation results show that the RF\nsource-seeking algorithm achieves high accuracy, with an average angular error\nof just 1.48 degrees, and with this estimate, the proposed navigation algorithm\nimproves the success rate of reaching the target by 46% and reduces the\ntrajectory length by 1.2% compared to standard potential fields.", "comment": "14 pages, 16 figures, 1 table, shorter version under review for IEEE\n  ICCAS 2025 conference", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06811v1", "AI": {"title_translation": "射频源搜寻与避障：在未知环境中实时改进人工势场法", "tldr": "本文提出了一种实时轨迹规划方法，通过采样方法实时调整人工势场（APF），实现无人机在未知环境中基于射频源搜寻的避障导航，并在仿真中验证了其高精度和更高的目标到达成功率。", "motivation": "现有的人工势场避障算法难以适应不同障碍物配置的环境，且在搜索救援等应用中目标精确位置不可用。", "method": "本文提出了一种实时轨迹规划方法，通过基于采样的实时自适应修改人工势场（APF）。该方法仅利用目标的方位角而非精确位置，并根据新的障碍物配置实时调整势场参数。主要贡献包括：1) 基于天线布局的射频信号计算，提供方位角估计的射频源搜寻算法；2) 适用于变化环境中可适应性防撞的改进APF。在Gazebo仿真软件中使用ROS2进行评估。", "result": "射频源搜寻算法实现了高精度，平均角度误差仅为1.48度。基于此估计，所提出的导航算法将到达目标的成功率提高了46%，轨迹长度比标准势场法减少了1.2%。", "conclusion": "论文提出的射频源搜寻算法和改进人工势场避障方法，有效提升了无人机在未知环境中基于射频源搜寻的避障导航能力，提高了目标到达成功率和轨迹效率。", "translation": "无人机在未知障碍物环境中的导航对于灾难响应和基础设施监控等应用至关重要。然而，现有的人工势场（APF）等避障算法无法泛化到具有不同障碍物配置的环境中。此外，在搜索救援等应用中，最终目标的精确位置可能不可用，在这种情况下，可以使用射频源搜寻等方法来对准目标位置。本文提出了一种实时轨迹规划方法，该方法涉及通过基于采样的方法实时调整APF。所提出的方法仅利用目标的方位角而非其精确位置，并根据新的障碍物配置实时调整势场参数。文章的主要贡献是：i) 一种基于天线布局的射频信号计算提供方位角估计的射频源搜寻算法；ii) 一种用于在变化环境中进行适应性防撞的改进APF，这些贡献在Gazebo仿真软件中使用ROS2进行通信分别进行了评估。仿真结果表明，射频源搜寻算法实现了高精度，平均角度误差仅为1.48度，并且利用此估计，所提出的导航算法与标准势场法相比，将到达目标的成功率提高了46%，并将轨迹长度减少了1.2%。", "summary": "本文提出了一种在未知环境中进行射频源搜寻与避障的无人机实时轨迹规划方法。该方法通过实时自适应修改人工势场（APF）来应对不同障碍物配置，并仅利用射频信号提供的目标方位角进行导航。文章贡献包括高精度射频源搜寻算法和可适应性避碰的改进APF。仿真结果显示，该方法显著提高了目标到达成功率并优化了轨迹。", "keywords": "射频源搜寻, 人工势场, 避障, 无人机导航, 未知环境", "comments": "本文的创新点在于结合了射频源搜寻与实时自适应人工势场，解决了未知环境下目标位置不确定和传统APF泛化能力差的问题。其重要性体现在提升了无人机在灾难响应和搜索救援等实际应用中的自主导航能力。论文在仿真中取得了显著效果，但在实际复杂环境中的鲁棒性和实时性仍需进一步验证。"}}
{"id": "2506.07871", "title": "Can Hessian-Based Insights Support Fault Diagnosis in Attention-based Models?", "authors": ["Sigma Jahan", "Mohammad Masudur Rahman"], "summary": "As attention-based deep learning models scale in size and complexity,\ndiagnosing their faults becomes increasingly challenging. In this work, we\nconduct an empirical study to evaluate the potential of Hessian-based analysis\nfor diagnosing faults in attention-based models. Specifically, we use\nHessian-derived insights to identify fragile regions (via curvature analysis)\nand parameter interdependencies (via parameter interaction analysis) within\nattention mechanisms. Through experiments on three diverse models (HAN, 3D-CNN,\nDistilBERT), we show that Hessian-based metrics can localize instability and\npinpoint fault sources more effectively than gradients alone. Our empirical\nfindings suggest that these metrics could significantly improve fault diagnosis\nin complex neural architectures, potentially improving software debugging\npractices.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07871v1", "AI": {"title_translation": "基于Hessian的洞察能否支持基于注意力的模型中的故障诊断？", "tldr": "本研究探讨了使用Hessian分析来诊断大型注意力模型中的故障，发现Hessian指标在定位不稳定性和故障源方面比梯度更有效。", "motivation": "随着基于注意力的深度学习模型规模和复杂性增加，诊断其故障变得越来越困难。", "method": "本研究进行了一项实证研究，使用Hessian导出的洞察力通过曲率分析识别脆弱区域，并通过参数交互分析识别注意力机制内的参数相互依赖性。", "result": "通过在三种不同模型（HAN、3D-CNN、DistilBERT）上的实验表明，Hessian基于的指标可以比单独的梯度更有效地定位不稳定性和查明故障源。", "conclusion": "实证结果表明，Hessian指标可以显著改善复杂神经网络架构中的故障诊断，并可能改进软件调试实践。", "translation": "随着基于注意力的深度学习模型在规模和复杂性上的扩展，诊断其故障变得越来越具有挑战性。在这项工作中，我们进行了一项实证研究，以评估基于Hessian的分析在诊断基于注意力的模型中故障的潜力。具体来说，我们使用Hessian导出的洞察力来识别注意力机制中的脆弱区域（通过曲率分析）和参数相互依赖性（通过参数交互分析）。通过在三种不同模型（HAN、3D-CNN、DistilBERT）上的实验，我们表明基于Hessian的指标可以比单独的梯度更有效地定位不稳定性和查明故障源。我们的实证结果表明，这些指标可以显著改善复杂神经网络架构中的故障诊断，从而可能改进软件调试实践。", "summary": "本研究探讨了Hessian分析在诊断大型注意力模型故障方面的潜力。通过曲率和参数交互分析，研究人员使用Hessian导出的洞察力来识别脆弱区域和参数相互依赖性。实验结果表明，Hessian基于的指标在定位不稳定性和故障源方面优于单独的梯度，这表明它们可以显著改善复杂神经网络架构的故障诊断，并有助于改进软件调试。", "keywords": "Hessian分析, 故障诊断, 注意力模型, 深度学习, 模型调试", "comments": "这项研究的创新之处在于提出了将Hessian分析应用于注意力模型故障诊断，这是一个新颖且重要的方向。它超越了传统的梯度分析，提供了更深层次的模型内部洞察，对于理解和调试复杂的深度学习模型具有重要意义。其潜在的应用价值在于提高大型AI系统的可靠性和可维护性。"}}
{"id": "2506.06757", "title": "SAR2Struct: Extracting 3D Semantic Structural Representation of Aircraft Targets from Single-View SAR Image", "authors": ["Ziyu Yue", "Ruixi You", "Feng Xu"], "summary": "To translate synthetic aperture radar (SAR) image into interpretable forms\nfor human understanding is the ultimate goal of SAR advanced information\nretrieval. Existing methods mainly focus on 3D surface reconstruction or local\ngeometric feature extraction of targets, neglecting the role of structural\nmodeling in capturing semantic information. This paper proposes a novel task:\nSAR target structure recovery, which aims to infer the components of a target\nand the structural relationships between its components, specifically symmetry\nand adjacency, from a single-view SAR image. Through learning the structural\nconsistency and geometric diversity across the same type of targets as observed\nin different SAR images, it aims to derive the semantic representation of\ntarget directly from its 2D SAR image. To solve this challenging task, a\ntwo-step algorithmic framework based on structural descriptors is developed.\nSpecifically, in the training phase, it first detects 2D keypoints from real\nSAR images, and then learns the mapping from these keypoints to 3D hierarchical\nstructures using simulated data. During the testing phase, these two steps are\nintegrated to infer the 3D structure from real SAR images. Experimental results\nvalidated the effectiveness of each step and demonstrated, for the first time,\nthat 3D semantic structural representation of aircraft targets can be directly\nderived from a single-view SAR image.", "comment": "13 pages, 12 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06757v1", "AI": {"title_translation": "SAR2Struct: 从单视SAR图像中提取飞机目标的3D语义结构表示", "tldr": "本文提出了一种从单视SAR图像中提取飞机目标3D语义结构表示的新任务和方法，通过两步算法框架实现了目标组件及其结构关系的推断。", "motivation": "为了将合成孔径雷达（SAR）图像转换为人类可理解的形式，现有方法主要集中于3D表面重建或局部几何特征提取，但忽略了结构建模在捕获语义信息方面的作用。", "method": "本文提出了一种SAR目标结构恢复的新任务，旨在从单视SAR图像中推断目标组件及其结构关系（特别是对称性和邻接性）。为此，开发了一个基于结构描述符的两步算法框架。训练阶段，从真实SAR图像中检测2D关键点，并使用模拟数据学习这些关键点到3D分层结构的映射。测试阶段，将这两步整合以从真实SAR图像中推断3D结构。", "result": "实验结果验证了每个步骤的有效性，并首次证明了可以直接从单视SAR图像中推导出飞机目标的3D语义结构表示。", "conclusion": "本研究首次成功地从单视SAR图像中直接推导出了飞机目标的3D语义结构表示，并通过提出的两步算法框架验证了其有效性，为SAR高级信息检索提供了新的路径。", "translation": "为了将合成孔径雷达（SAR）图像转换为人类可理解的形式，是SAR高级信息检索的最终目标。现有方法主要集中于目标的3D表面重建或局部几何特征提取，忽略了结构建模在捕获语义信息方面的作用。本文提出了一项新任务：SAR目标结构恢复，旨在从单视SAR图像中推断目标的组件及其组件之间的结构关系，特别是对称性和邻接性。通过学习不同SAR图像中同类型目标所观察到的结构一致性和几何多样性，旨在直接从其2D SAR图像中导出目标的语义表示。为了解决这项具有挑战性的任务，开发了一个基于结构描述符的两步算法框架。具体而言，在训练阶段，它首先从真实SAR图像中检测2D关键点，然后使用模拟数据学习这些关键点到3D分层结构的映射。在测试阶段，将这两步整合以从真实SAR图像中推断3D结构。实验结果验证了每个步骤的有效性，并首次证明了可以直接从单视SAR图像中导出飞机目标的3D语义结构表示。", "summary": "本文提出了一项名为SAR目标结构恢复的新任务，旨在从单视SAR图像中提取飞机目标的3D语义结构表示，包括其组件及其结构关系（如对称性和邻接性）。针对现有方法在语义信息捕获方面的不足，研究开发了一个基于结构描述符的两步算法框架。该框架在训练阶段利用真实SAR图像的2D关键点和模拟数据学习到3D结构的映射，并在测试阶段整合此过程以从真实SAR图像中推断3D结构。实验结果首次验证了从单视SAR图像直接推导飞机目标3D语义结构表示的可行性和有效性。", "keywords": "SAR, 3D语义结构, 飞机目标, 单视SAR, 结构恢复", "comments": "本文的创新点在于提出了一个全新的任务——SAR目标结构恢复，并首次成功地从单视SAR图像中提取出3D语义结构表示，弥补了现有方法在语义信息捕获方面的不足。其两步算法框架结合了真实SAR图像的2D关键点检测与模拟数据学习3D结构映射的方法，为SAR图像理解和高级信息检索开辟了新的途径，具有重要的理论和应用价值。"}}
{"id": "2506.06786", "title": "Learning What Matters Now: A Dual-Critic Context-Aware RL Framework for Priority-Driven Information Gain", "authors": ["Dimitris Panagopoulos", "Adolfo Perrusquia", "Weisi Guo"], "summary": "Autonomous systems operating in high-stakes search-and-rescue (SAR) missions\nmust continuously gather mission-critical information while flexibly adapting\nto shifting operational priorities. We propose CA-MIQ (Context-Aware\nMax-Information Q-learning), a lightweight dual-critic reinforcement learning\n(RL) framework that dynamically adjusts its exploration strategy whenever\nmission priorities change. CA-MIQ pairs a standard extrinsic critic for task\nreward with an intrinsic critic that fuses state-novelty, information-location\nawareness, and real-time priority alignment. A built-in shift detector triggers\ntransient exploration boosts and selective critic resets, allowing the agent to\nre-focus after a priority revision. In a simulated SAR grid-world, where\nexperiments specifically test adaptation to changes in the priority order of\ninformation types the agent is expected to focus on, CA-MIQ achieves nearly\nfour times higher mission-success rates than baselines after a single priority\nshift and more than three times better performance in multiple-shift scenarios,\nachieving 100% recovery while baseline methods fail to adapt. These results\nhighlight CA-MIQ's effectiveness in any discrete environment with\npiecewise-stationary information-value distributions.", "comment": "6 pages, 2 figures, 3 tables, submitted as a regural paper to IEEE\n  International Conference on Systems, Man, and Cybernetics (SMC) 2025", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06786v1", "AI": {"title_translation": "学习当前重要内容：一种用于优先级驱动信息增益的双评论家上下文感知强化学习框架", "tldr": "CA-MIQ是一种轻量级双评论家强化学习框架，它能根据任务优先级变化动态调整探索策略，在模拟搜索救援任务中表现出显著优于基线的任务成功率。", "motivation": "自主系统在搜救任务中需要持续收集关键信息，同时灵活适应不断变化的行动优先级，这促使了对能够动态调整探索策略的强化学习框架的需求。", "method": "本文提出了CA-MIQ（Context-Aware Max-Information Q-learning），一个轻量级的双评论家强化学习（RL）框架。它将一个标准的外在评论家用于任务奖励，并结合一个内在评论家，该评论家融合了状态新颖性、信息位置感知和实时优先级对齐。内置的转移检测器会触发短暂的探索提升和选择性评论家重置，使智能体能够在优先级修订后重新聚焦。", "result": "在模拟搜救网格世界中，CA-MIQ在单次优先级转移后实现了比基线高近四倍的任务成功率，在多次转移场景中表现提高三倍以上，实现了100%的恢复率，而基线方法未能适应。", "conclusion": "CA-MIQ在具有分段平稳信息价值分布的任何离散环境中都非常有效，能够有效地应对优先级变化。", "translation": "自主系统在高度危险的搜索救援（SAR）任务中运行，必须持续收集任务关键信息，同时灵活适应不断变化的行动优先级。我们提出了CA-MIQ（Context-Aware Max-Information Q-learning），一个轻量级的双评论家强化学习（RL）框架，它能在任务优先级改变时动态调整其探索策略。CA-MIQ将一个用于任务奖励的标准外在评论家与一个内在评论家配对，该内在评论家融合了状态新颖性、信息位置感知和实时优先级对齐。内置的转移检测器会触发短暂的探索提升和选择性评论家重置，允许智能体在优先级修订后重新聚焦。在模拟SAR网格世界中，实验专门测试了对智能体预期关注的信息类型优先级顺序变化的适应性，CA-MIQ在单次优先级转移后实现了比基线高近四倍的任务成功率，在多次转移场景中表现提高三倍以上，实现了100%的恢复率，而基线方法未能适应。这些结果凸显了CA-MIQ在任何具有分段平稳信息价值分布的离散环境中的有效性。", "summary": "本文提出了一种名为CA-MIQ的双评论家上下文感知强化学习框架，旨在解决自主系统在面临不断变化的优先级时如何高效收集任务关键信息的问题。CA-MIQ通过结合外在和内在评论家，并利用内置的转移检测器来动态调整探索策略。在模拟搜救任务中的实验表明，该框架在应对优先级变化方面表现出色，显著优于现有基线方法，任务成功率大幅提升。", "keywords": "强化学习, 上下文感知, 优先级驱动, 信息增益, 搜索救援", "comments": "CA-MIQ的创新之处在于其双评论家设计和内置的转移检测器，使其能够灵活适应优先级变化，这对于高动态环境中的自主系统至关重要。其在模拟搜救任务中的卓越表现，尤其是在多优先级转移场景下的高恢复率，凸显了该框架的实用性和重要性。"}}
{"id": "2506.06700", "title": "Quantum accessible information and classical entropy inequalities", "authors": ["A. S. Holevo", "A. V. Utkin"], "summary": "Computing accessible information for an ensemble of quantum states is a basic\nproblem in quantum information theory. The optimality criterion recently\nobtained in [7], when applied to specific ensembles of states, leads to\nnontrivial tight lower bounds for the Shannon entropy that are discrete\nrelatives of the famous log-Sobolev inequality. In this light, the hypothesis\nof globally information-optimal measurement for an ensemble of equiangular\nequiprobable states (quantum pyramids) put forward and numerically\nsubstantiated in [2] is reconsidered and the corresponding tight entropy\ninequalities are proposed. We prove these inequalities in the cases of state\nensembles corresponding to acute or flat pyramids, thus providing the proof of\nthe hypothesis concerning the globally information-optimal observable.", "comment": "34 pages, no figures", "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.06700v1", "AI": {"title_translation": "量子可及信息与经典熵不等式", "tldr": "本文重新审视并证明了关于等角等概率量子态（量子金字塔）系综的全局信息最优测量的假设，并提出了相应的紧致熵不等式。", "motivation": "计算量子态系综的可及信息是量子信息论中的一个基本问题。此外，作者旨在重新审视并证明先前研究中提出的关于等角等概率态系综的全局信息最优测量的假设。", "method": "本文应用了文献[7]中获得的优化准则，将其应用于特定的态系综，以推导香农熵的非平凡紧致下界。研究人员重新审视了文献[2]中提出的关于等角等概率态系综（量子金字塔）的全局信息最优测量的假设，并提出了相应的紧致熵不等式。他们证明了这些不等式在对应于锐角或平坦金字塔的态系综情况下的成立。", "result": "应用优化准则得到了香农熵的非平凡紧致下界，这些下界是著名的对数-索伯列夫不等式的离散形式。研究人员提出了等角等概率态系综的紧致熵不等式，并证明了这些不等式在对应于锐角或平坦金字塔的态系综情况下的成立，从而为关于全局信息最优可观测量的假设提供了证明。", "conclusion": "本文成功地证明了关于等角等概率量子态系综的全局信息最优测量的假设，并提出了相应的紧致熵不等式，为量子信息理论提供了重要的理论支持。", "translation": "计算量子态系综的可及信息是量子信息论中的一个基本问题。文献[7]中最近获得的优化准则，当应用于特定的态系综时，可以为香农熵提供非平凡的紧致下界，这些下界是著名的对数-索伯列夫不等式的离散形式。鉴于此，本文重新审视了文献[2]中提出并经过数值验证的关于等角等概率态系综（量子金字塔）的全局信息最优测量的假设，并提出了相应的紧致熵不等式。我们证明了这些不等式在对应于锐角或平坦金字塔的态系综情况下的成立，从而为关于全局信息最优可观测量的假设提供了证明。", "summary": "本文探讨了量子态系综的可及信息计算问题，这是一个量子信息论中的基本问题。研究人员应用了最近获得的优化准则，推导出了香农熵的非平凡紧致下界，这些下界是著名的对数-索伯列夫不等式的离散形式。在此基础上，文章重新审视并证明了文献[2]中提出的关于等角等概率量子态（量子金字塔）系综的全局信息最优测量的假设，并提出了相应的紧致熵不等式。这些不等式在锐角或平坦金字塔态系综的情况下得到了证明，从而证实了全局信息最优可观测量的假设。", "keywords": "量子可及信息, 香农熵, 熵不等式, 量子金字塔, 全局信息最优测量", "comments": "该论文通过严谨的数学证明，解决了量子信息理论中的一个重要假设，即将量子金字塔的全局信息最优测量问题与经典熵不等式联系起来。其创新之处在于将优化准则应用于特定量子态系综，从而推导出香农熵的紧致下界，并成功证明了先前研究中的假设。这项工作对深入理解量子信息的可及性及其与经典熵的联系具有重要意义。"}}
{"id": "2506.06454", "title": "LETS Forecast: Learning Embedology for Time Series Forecasting", "authors": ["Abrar Majeedi", "Viswanatha Reddy Gajjala", "Satya Sai Srinath Namburi GNVV", "Nada Magdi Elkordi", "Yin Li"], "summary": "Real-world time series are often governed by complex nonlinear dynamics.\nUnderstanding these underlying dynamics is crucial for precise future\nprediction. While deep learning has achieved major success in time series\nforecasting, many existing approaches do not explicitly model the dynamics. To\nbridge this gap, we introduce DeepEDM, a framework that integrates nonlinear\ndynamical systems modeling with deep neural networks. Inspired by empirical\ndynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel\ndeep model that learns a latent space from time-delayed embeddings, and employs\nkernel regression to approximate the underlying dynamics, while leveraging\nefficient implementation of softmax attention and allowing for accurate\nprediction of future time steps. To evaluate our method, we conduct\ncomprehensive experiments on synthetic data of nonlinear dynamical systems as\nwell as real-world time series across domains. Our results show that DeepEDM is\nrobust to input noise, and outperforms state-of-the-art methods in forecasting\naccuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.", "comment": "Accepted at International Conference on Machine Learning (ICML) 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06454v1", "AI": {"title_translation": "LETS Forecast: 学习时间序列预测的嵌入式方法", "tldr": "DeepEDM是一个结合非线性动力学系统建模和深度神经网络的时间序列预测框架，通过学习潜在空间和核回归，在合成数据和真实世界时间序列上表现出鲁棒性和更高的预测精度。", "motivation": "现有深度学习时间序列预测方法未能明确建模复杂非线性动力学，而理解这些潜在动力学对于精确预测至关重要。", "method": "本文引入了DeepEDM框架，它将非线性动力学系统建模与深度神经网络相结合。该方法受经验动力学建模（EDM）启发并植根于Takens定理，通过时间延迟嵌入学习潜在空间，并利用核回归近似潜在动力学，同时高效利用softmax注意力机制。", "result": "DeepEDM对输入噪声具有鲁棒性，并在预测准确性方面优于最先进的方法。", "conclusion": "DeepEDM成功地将非线性动力学系统建模与深度学习相结合，提供了一种对噪声鲁棒且预测准确性高的时间序列预测方法。", "translation": "真实世界的时间序列通常受复杂的非线性动力学支配。理解这些潜在动力学对于精确的未来预测至关重要。虽然深度学习在时间序列预测方面取得了巨大成功，但许多现有方法并未明确建模动力学。为了弥补这一差距，我们引入了DeepEDM，这是一个将非线性动力学系统建模与深度神经网络相结合的框架。受经验动力学建模（EDM）的启发并植根于Takens定理，DeepEDM提出了一种新颖的深度模型，该模型从时间延迟嵌入中学习潜在空间，并采用核回归来近似潜在动力学，同时利用softmax注意力的有效实现并允许对未来时间步进行准确预测。为了评估我们的方法，我们对非线性动力学系统的合成数据以及跨领域的真实世界时间序列进行了全面实验。我们的结果表明，DeepEDM对输入噪声具有鲁棒性，并在预测准确性方面优于最先进的方法。我们的代码可在以下网址获取：https://abrarmajeedi.github.io/deep_edm。", "summary": "本文提出了一种名为DeepEDM的新型时间序列预测框架，旨在解决现有深度学习方法未明确建模复杂非线性动力学的问题。DeepEDM借鉴经验动力学建模和Takens定理，通过深度神经网络学习时间延迟嵌入的潜在空间，并利用核回归来近似基础动力学，同时结合高效的softmax注意力。实验结果表明，DeepEDM对输入噪声具有鲁棒性，并在合成数据和真实世界时间序列上均超越了现有最先进的预测方法。", "keywords": "时间序列预测, 非线性动力学, 深度学习, 经验动力学建模, Takens定理", "comments": "DeepEDM的创新之处在于将非线性动力学系统建模与深度神经网络有效结合，明确地解决了时间序列中复杂动力学的问题，这对于提高预测精度和模型鲁棒性至关重要。该方法通过学习潜在空间和利用核回归，为时间序列预测提供了一个新的视角。"}}
{"id": "2506.07049", "title": "FairPFN: A Tabular Foundation Model for Causal Fairness", "authors": ["Jake Robertson", "Noah Hollmann", "Samuel Müller", "Noor Awad", "Frank Hutter"], "summary": "Machine learning (ML) systems are utilized in critical sectors, such as\nhealthcare, law enforcement, and finance. However, these systems are often\ntrained on historical data that contains demographic biases, leading to ML\ndecisions that perpetuate or exacerbate existing social inequalities. Causal\nfairness provides a transparent, human-in-the-loop framework to mitigate\nalgorithmic discrimination, aligning closely with legal doctrines of direct and\nindirect discrimination. However, current causal fairness frameworks hold a key\nlimitation in that they assume prior knowledge of the correct causal model,\nrestricting their applicability in complex fairness scenarios where causal\nmodels are unknown or difficult to identify. To bridge this gap, we propose\nFairPFN, a tabular foundation model pre-trained on synthetic causal fairness\ndata to identify and mitigate the causal effects of protected attributes in its\npredictions. FairPFN's key contribution is that it requires no knowledge of the\ncausal model and still demonstrates strong performance in identifying and\nremoving protected causal effects across a diverse set of hand-crafted and\nreal-world scenarios relative to robust baseline methods. FairPFN paves the way\nfor promising future research, making causal fairness more accessible to a\nwider variety of complex fairness problems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07049v1", "AI": {"title_translation": "FairPFN: 因果公平的表格基础模型", "tldr": "机器学习系统存在偏见；FairPFN是一个新的表格基础模型，无需先验因果模型知识即可解决因果公平问题，表现优于基线方法。", "motivation": "机器学习系统在关键领域使用，但常因历史数据偏见导致社会不公。现有因果公平框架需已知因果模型，限制了其在因果模型未知或难以识别的复杂公平场景中的适用性。", "method": "提出FairPFN，一个预训练于合成因果公平数据的表格基础模型。它无需因果模型知识，即可识别并减轻预测中受保护属性的因果效应。", "result": "FairPFN在多种手工设计和真实世界场景中，无需因果模型知识，仍能有效识别并消除受保护的因果效应，性能优于强大的基线方法。", "conclusion": "FairPFN为有前景的未来研究铺平了道路，使因果公平性更易于应用于更广泛的复杂公平问题。", "translation": "机器学习（ML）系统被应用于医疗、执法和金融等关键领域。然而，这些系统通常在包含人口偏见的历史数据上进行训练，导致ML决策延续或加剧现有的社会不平等。因果公平提供了一个透明的、人机协作的框架来减轻算法歧视，这与直接和间接歧视的法律原则紧密契合。然而，当前的因果公平框架存在一个关键限制，即它们假设已知正确的因果模型，这限制了它们在因果模型未知或难以识别的复杂公平场景中的适用性。为了弥补这一差距，我们提出了FairPFN，一个在合成因果公平数据上预训练的表格基础模型，用于识别和减轻其预测中受保护属性的因果效应。FairPFN的关键贡献在于它不需要因果模型的知识，并且在识别和消除各种手工设计和真实世界场景中的受保护因果效应方面，相对于强大的基线方法，仍然表现出强大的性能。FairPFN为有前景的未来研究铺平了道路，使因果公平性更易于应用于更广泛的复杂公平问题。", "summary": "FairPFN是一个表格基础模型，通过在合成因果公平数据上预训练，解决了现有因果公平框架需要已知因果模型的问题。它无需因果模型知识即可有效识别并消除预测中的受保护属性的因果效应，在多种场景下表现优于基线方法，从而使因果公平性更易于应用于复杂的公平问题。", "keywords": "Causal fairness, Tabular foundation model, Algorithmic discrimination, Bias mitigation, Machine learning fairness", "comments": "FairPFN的创新在于其作为表格基础模型，无需先验因果模型知识即可解决因果公平性问题，这显著拓宽了因果公平方法在实际复杂场景中的应用范围，具有重要意义。"}}
{"id": "2506.06322", "title": "Neural networks with image recognition by pairs", "authors": ["Polad Geidarov"], "summary": "Neural networks based on metric recognition methods have a strictly\ndetermined architecture. Number of neurons, connections, as well as weights and\nthresholds values are calculated analytically, based on the initial conditions\nof tasks: number of recognizable classes, number of samples, metric expressions\nused. This paper discusses the possibility of transforming these networks in\norder to apply classical learning algorithms to them without using analytical\nexpressions that calculate weight values. In the received network, training is\ncarried out by recognizing images in pairs. This approach simplifies the\nlearning process and easily allows to expand the neural network by adding new\nimages to the recognition task. The advantages of these networks, including\nsuch as: 1) network architecture simplicity and transparency; 2) training\nsimplicity and reliability; 3) the possibility of using a large number of\nimages in the recognition problem using a neural network; 4) a consistent\nincrease in the number of recognizable classes without changing the previous\nvalues of weights and thresholds.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06322v1", "AI": {"title_translation": "成对图像识别的神经网络", "tldr": "本文提出了一种通过成对图像识别来训练度量识别神经网络的方法，旨在简化学习过程并允许网络轻松扩展，无需依赖复杂的分析表达式来计算权重。", "motivation": "传统的基于度量识别的神经网络架构严格固定，其神经元、连接、权重和阈值都是根据初始任务条件（如可识别类别数量、样本数量、度量表达式）通过分析方法计算出来的。本文的动机是探讨如何转换这些网络，以便能够应用经典的学习算法，而无需使用计算权重值的分析表达式。", "method": "本文讨论了将度量识别神经网络进行转换的可能性，以便能够对其应用经典的学习算法。在转换后的网络中，训练是通过成对识别图像来进行的。", "result": "这种方法简化了学习过程，并且允许通过向识别任务添加新图像来轻松扩展神经网络。这些网络的优点包括：1）网络架构的简单性和透明性；2）训练的简单性和可靠性；3）在识别问题中能够使用大量图像；4）在不改变先前权重和阈值值的情况下，可识别类别的数量可以持续增加。", "conclusion": "通过将度量识别神经网络转换为使用成对图像识别进行训练，可以实现学习过程的简化和网络的灵活扩展，同时保持架构的简单性、训练的可靠性，并支持大量图像和类别增长。", "translation": "基于度量识别方法的神经网络具有严格确定的架构。神经元、连接以及权重和阈值的值是根据任务的初始条件（可识别类别的数量、样本数量、使用的度量表达式）进行分析计算的。本文讨论了转换这些网络的可能性，以便对其应用经典的学习算法，而无需使用计算权重值的分析表达式。在接收到的网络中，训练是通过成对识别图像来进行的。这种方法简化了学习过程，并易于通过向识别任务添加新图像来扩展神经网络。这些网络的优点包括：1）网络架构的简单性和透明性；2）训练的简单性和可靠性；3）在识别问题中能够使用大量图像的能力；4）在不改变先前权重和阈值值的情况下，可识别类别的数量可以持续增加。", "summary": "本文提出了一种改进基于度量识别的神经网络的方法，旨在通过成对图像识别来替代传统复杂的分析计算权重方式。这种新方法使得神经网络的训练过程更加简化和可靠，同时保持了架构的透明性。它还允许网络轻松扩展，支持处理大量图像，并在不影响现有参数的情况下持续增加可识别的类别数量，从而克服了传统方法中严格架构和计算的限制。", "keywords": "神经网络, 图像识别, 度量识别, 成对训练, 机器学习", "comments": "这篇论文提出了一种实用的方法来解决传统度量识别神经网络的局限性，即其固定的架构和对分析计算的依赖。通过引入“成对图像识别”的训练机制，它显著简化了学习过程，并增强了网络的可扩展性，使其能够更灵活地适应新的数据和类别。这种方法对于需要动态扩展和简化训练的实际应用场景具有重要意义，尤其是在图像识别领域。"}}
{"id": "2506.07402", "title": "Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures", "authors": ["Yukai Zhou", "Sibei Yang", "Wenjie Wang"], "summary": "Large language models (LLMs) are increasingly deployed in real-world\napplications, raising concerns about their security. While jailbreak attacks\nhighlight failures under overtly harmful queries, they overlook a critical\nrisk: incorrectly answering harmless-looking inputs can be dangerous and cause\nreal-world harm (Implicit Harm). We systematically reformulate the LLM risk\nlandscape through a structured quadrant perspective based on output factuality\nand input harmlessness, uncovering an overlooked high-risk region. To\ninvestigate this gap, we propose JailFlipBench, a benchmark aims to capture\nimplicit harm, spanning single-modal, multimodal, and factual extension\nscenarios with diverse evaluation metrics. We further develop initial JailFlip\nattack methodologies and conduct comprehensive evaluations across multiple\nopen-source and black-box LLMs, show that implicit harm present immediate and\nurgent real-world risks, calling for broader LLM safety assessments and\nalignment beyond conventional jailbreak paradigms.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07402v1", "AI": {"title_translation": "超越越狱：揭示源于对齐失败的更隐蔽、更广泛的LLM安全风险", "tldr": "本文揭示了一种新的LLM安全风险，称为“隐性危害”，即看似无害的输入却导致危险的不正确输出。为此，论文提出了JailFlipBench基准和攻击方法来识别这些风险。", "motivation": "目前的越狱攻击主要关注明显有害的查询，但忽略了一个关键风险：大型语言模型（LLM）错误回答看似无害的输入也可能造成危险和现实世界损害（隐性危害）。本文旨在通过重新构建LLM风险格局来揭示这一被忽视的高风险区域。", "method": "作者通过基于输出事实性和输入无害性的结构化象限视角，系统地重新构建了LLM风险格局。为了调查这一空白，他们提出了JailFlipBench，一个旨在捕捉隐性危害的基准，涵盖单模态、多模态和事实扩展场景，并采用多样化的评估指标。此外，他们还开发了初始的JailFlip攻击方法，并对多个开源和黑盒LLM进行了全面评估。", "result": "评估结果表明，隐性危害带来了即时和紧迫的现实世界风险。", "conclusion": "研究结果呼吁在传统越狱范式之外进行更广泛的LLM安全评估和对齐。", "translation": "大型语言模型 (LLM) 越来越多地部署在实际应用中，引发了对其安全性的担忧。虽然越狱攻击突出了在明显有害查询下的失败，但它们忽略了一个关键风险：错误回答看似无害的输入可能是危险的，并造成现实世界的损害（隐性危害）。我们通过基于输出事实性和输入无害性的结构化象限视角，系统地重新构建了LLM风险格局，揭示了一个被忽视的高风险区域。为了调查这一空白，我们提出了JailFlipBench，一个旨在捕捉隐性危害的基准，涵盖单模态、多模态和事实扩展场景，并采用多样化的评估指标。我们进一步开发了初始的JailFlip攻击方法，并对多个开源和黑盒LLM进行了全面评估，结果表明隐性危害带来了即时和紧迫的现实世界风险，呼吁在传统越狱范式之外进行更广泛的LLM安全评估和对齐。", "summary": "本文识别出一种新的LLM安全风险，称为“隐性危害”，即看似无害的输入却导致危险的不正确输出，这与传统的越狱攻击不同。论文重新构建了LLM风险格局，提出了JailFlipBench基准来评估这种危害在各种场景下的表现，并开发了JailFlip攻击方法。全面的评估揭示了隐性危害带来了即时的现实世界风险，强调了在当前越狱范式之外进行更广泛LLM安全评估的必要性。", "keywords": "LLM安全, 隐性危害, 对齐失败, JailFlipBench, 安全风险", "comments": "这篇论文提出了一个超越传统越狱攻击的LLM安全新视角，具有重要意义。通过关注源于对齐失败的“隐性危害”，并提出新的基准（JailFlipBench）和攻击方法，它解决了LLM在实际部署中一个关键且被忽视的风险领域。这项工作通过推动对潜在危害更全面的理解，对推进LLM安全和对齐研究至关重要。"}}
{"id": "2506.06862", "title": "Multimodal Spatial Language Maps for Robot Navigation and Manipulation", "authors": ["Chenguang Huang", "Oier Mees", "Andy Zeng", "Wolfram Burgard"], "summary": "Grounding language to a navigating agent's observations can leverage\npretrained multimodal foundation models to match perceptions to object or event\ndescriptions. However, previous approaches remain disconnected from environment\nmapping, lack the spatial precision of geometric maps, or neglect additional\nmodality information beyond vision. To address this, we propose multimodal\nspatial language maps as a spatial map representation that fuses pretrained\nmultimodal features with a 3D reconstruction of the environment. We build these\nmaps autonomously using standard exploration. We present two instances of our\nmaps, which are visual-language maps (VLMaps) and their extension to\naudio-visual-language maps (AVLMaps) obtained by adding audio information. When\ncombined with large language models (LLMs), VLMaps can (i) translate natural\nlanguage commands into open-vocabulary spatial goals (e.g., \"in between the\nsofa and TV\") directly localized in the map, and (ii) be shared across\ndifferent robot embodiments to generate tailored obstacle maps on demand.\nBuilding upon the capabilities above, AVLMaps extend VLMaps by introducing a\nunified 3D spatial representation integrating audio, visual, and language cues\nthrough the fusion of features from pretrained multimodal foundation models.\nThis enables robots to ground multimodal goal queries (e.g., text, images, or\naudio snippets) to spatial locations for navigation. Additionally, the\nincorporation of diverse sensory inputs significantly enhances goal\ndisambiguation in ambiguous environments. Experiments in simulation and\nreal-world settings demonstrate that our multimodal spatial language maps\nenable zero-shot spatial and multimodal goal navigation and improve recall by\n50% in ambiguous scenarios. These capabilities extend to mobile robots and\ntabletop manipulators, supporting navigation and interaction guided by visual,\naudio, and spatial cues.", "comment": "accepted to International Journal of Robotics Research (IJRR). 24\n  pages, 18 figures. The paper contains texts from VLMaps(arXiv:2210.05714) and\n  AVLMaps(arXiv:2303.07522). The project page is https://mslmaps.github.io/", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.06862v1", "AI": {"title_translation": "机器人导航和操作的多模态空间语言地图", "tldr": "提出多模态空间语言地图（VLMaps和AVLMaps），融合预训练多模态特征与3D环境重建，使机器人能通过语言、视觉、听觉等指令进行零样本导航和操作，提高歧义环境下的召回率。", "motivation": "现有方法在语言与机器人观测的关联方面，与环境建图脱节，缺乏几何地图的空间精度，或忽略视觉之外的其他模态信息。", "method": "提出多模态空间语言地图（multimodal spatial language maps），通过将预训练的多模态特征与环境的3D重建融合来构建空间地图表示。这些地图可自主构建。具体包括视觉-语言地图（VLMaps）和音频-视觉-语言地图（AVLMaps）。VLMaps结合LLMs可将自然语言命令转换为开放词汇空间目标并定位，并能在不同机器人之间共享以生成障碍物地图。AVLMaps通过融合预训练多模态基础模型的特征，进一步整合音频、视觉和语言线索，实现多模态目标查询的定位。", "result": "多模态空间语言地图在模拟和真实世界环境中实现了零样本空间和多模态目标导航，并在模糊场景中将召回率提高了50%。这些能力可扩展到移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。", "conclusion": "该研究成功开发了多模态空间语言地图，有效解决了现有方法在空间精度和多模态信息利用方面的不足，显著提升了机器人在复杂和模糊环境中进行零样本导航和操作的能力。", "translation": "将语言与导航代理的观测结果联系起来，可以利用预训练的多模态基础模型来匹配感知与物体或事件的描述。然而，以前的方法仍然与环境建图脱节，缺乏几何地图的空间精度，或者忽略了视觉之外的额外模态信息。为了解决这个问题，我们提出了多模态空间语言地图作为一种空间地图表示，它将预训练的多模态特征与环境的3D重建融合。我们使用标准探索自主构建这些地图。我们展示了我们地图的两个实例，即视觉-语言地图（VLMaps）及其通过添加音频信息扩展而成的音频-视觉-语言地图（AVLMaps）。当与大型语言模型（LLMs）结合时，VLMaps可以（i）将自然语言命令转换为直接在地图中定位的开放词汇空间目标（例如，“沙发和电视之间”），以及（ii）在不同的机器人实体之间共享以按需生成定制的障碍物地图。在此能力的基础上，AVLMaps通过引入统一的3D空间表示来扩展VLMaps，该表示通过融合预训练多模态基础模型的特征来整合音频、视觉和语言线索。这使得机器人能够将多模态目标查询（例如，文本、图像或音频片段）与空间位置联系起来进行导航。此外，多样化感官输入的整合显著增强了模糊环境中的目标消歧能力。在模拟和真实世界环境中的实验表明，我们的多模态空间语言地图实现了零样本空间和多模态目标导航，并将模糊场景中的召回率提高了50%。这些能力扩展到移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。", "summary": "本文提出多模态空间语言地图（VLMaps和AVLMaps），旨在解决现有语言与机器人观测关联方法在环境建图脱节、空间精度不足及忽略视觉外模态信息的问题。该方法将预训练多模态特征与环境3D重建融合，自主构建地图。VLMaps结合LLMs能将自然语言命令转化为可定位的开放词汇空间目标，并支持跨机器人共享。AVLMaps在此基础上整合音频信息，实现多模态目标查询的定位，并增强歧义环境下的目标消歧能力。实验证明，该地图在模拟和真实环境中实现了零样本空间和多模态目标导航，并将模糊场景的召回率提高50%，适用于移动机器人和桌面操作器。", "keywords": "多模态空间语言地图, 机器人导航, 机器人操作, 语言接地, 3D重建", "comments": "这项工作通过引入多模态空间语言地图，有效地弥合了语言指令与机器人实际环境感知之间的鸿沟。其创新之处在于将预训练的多模态特征与3D环境重建相结合，并扩展到多种感官输入（视觉、听觉、语言），显著提高了机器人在复杂和模糊环境中理解和执行零样本空间及多模态目标的能力。这对于提升机器人自主性和泛化能力具有重要意义。"}}
{"id": "2506.06759", "title": "LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security", "authors": ["Nidheesh Gorthi", "Kartik Thakral", "Rishabh Ranjan", "Richa Singh", "Mayank Vatsa"], "summary": "Biometric authentication systems are increasingly being deployed in critical\napplications, but they remain susceptible to spoofing. Since most of the\nresearch efforts focus on modality-specific anti-spoofing techniques, building\na unified, resource-efficient solution across multiple biometric modalities\nremains a challenge. To address this, we propose LitMAS, a\n$\\textbf{Li}$gh$\\textbf{t}$ weight and generalizable $\\textbf{M}$ulti-modal\n$\\textbf{A}$nti-$\\textbf{S}$poofing framework designed to detect spoofing\nattacks in speech, face, iris, and fingerprint-based biometric systems. At the\ncore of LitMAS is a Modality-Aligned Concentration Loss, which enhances\ninter-class separability while preserving cross-modal consistency and enabling\nrobust spoof detection across diverse biometric traits. With just 6M\nparameters, LitMAS surpasses state-of-the-art methods by $1.36\\%$ in average\nEER across seven datasets, demonstrating high efficiency, strong\ngeneralizability, and suitability for edge deployment. Code and trained models\nare available at https://github.com/IAB-IITJ/LitMAS.", "comment": "Accepted in Interspeech 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06759v1", "AI": {"title_translation": "LitMAS：一种轻量级通用多模态生物识别安全反欺骗框架", "tldr": "LitMAS是一种轻量级、通用的多模态反欺骗框架，通过引入模态对齐集中损失，在多种生物识别系统（语音、人脸、虹膜、指纹）中有效检测欺骗攻击，并以6M参数量超越SOTA。", "motivation": "生物识别认证系统易受欺骗攻击，现有研究多关注特定模态的反欺骗技术，缺乏统一且资源高效的跨多模态解决方案。", "method": "提出LitMAS框架，它是一种轻量级且通用的多模态反欺骗框架，旨在检测语音、人脸、虹膜和指纹等生物识别系统中的欺骗攻击。其核心是模态对齐集中损失（Modality-Aligned Concentration Loss），该损失增强了类间可分离性，同时保持了跨模态一致性，从而实现了对不同生物特征的鲁棒欺骗检测。", "result": "LitMAS仅用6M参数，在七个数据集上的平均等错误率（EER）超越现有最先进方法1.36%，显示出高效率、强泛化能力和边缘部署的适用性。", "conclusion": "LitMAS提供了一个高效、通用且轻量级的多模态反欺骗解决方案，显著提升了生物识别系统的安全性，并适用于资源受限的边缘设备。", "translation": "生物识别认证系统正越来越多地应用于关键领域，但它们仍然容易受到欺骗攻击。由于大多数研究工作都集中在特定模态的反欺骗技术上，因此构建一个统一、资源高效的跨多种生物识别模态的解决方案仍然是一个挑战。为了解决这个问题，我们提出了LitMAS，一个轻量级且通用的多模态反欺骗框架，旨在检测基于语音、人脸、虹膜和指纹的生物识别系统中的欺骗攻击。LitMAS的核心是模态对齐集中损失（Modality-Aligned Concentration Loss），它在保持跨模态一致性的同时增强了类间可分离性，从而实现了对各种生物特征的鲁棒欺骗检测。LitMAS仅用6M参数，在七个数据集上的平均等错误率（EER）超越现有最先进方法1.36%，展示了高效率、强泛化能力和边缘部署的适用性。代码和训练模型可在https://github.com/IAB-IITJ/LitMAS获取。", "summary": "本文提出了LitMAS，一个轻量级且通用的多模态反欺骗框架，旨在解决现有生物识别系统易受欺骗攻击且缺乏统一跨模态解决方案的问题。LitMAS的核心是模态对齐集中损失，该损失通过增强类间可分离性并保持跨模态一致性，实现了对语音、人脸、虹膜和指纹等多种生物特征的鲁棒欺骗检测。实验结果表明，LitMAS以其仅6M的参数量，在七个数据集上的平均EER超越了现有SOTA方法1.36%，证明了其高效率、强大的泛化能力以及适用于边缘部署的特性。", "keywords": "多模态反欺骗, 生物识别安全, 轻量级, 泛化, 模态对齐集中损失", "comments": "LitMAS的创新之处在于其提出了一个统一的、跨多种生物模态的反欺骗框架，并通过模态对齐集中损失实现了高效且泛化的欺骗检测。其轻量级设计（仅6M参数）使其特别适合边缘部署，这在实际应用中具有重要价值。该研究解决了当前反欺骗领域中模态特异性方案的局限性，为未来多模态生物识别系统的安全性提供了新的思路。"}}
{"id": "2506.06832", "title": "Cross-Entropy Games for Language Models: From Implicit Knowledge to General Capability Measures", "authors": ["Clément Hongler", "Andrew Emil"], "summary": "Large Language Models (LLMs) define probability measures on text. By\nconsidering the implicit knowledge question of what it means for an LLM to know\nsuch a measure and what it entails algorithmically, we are naturally led to\nformulate a series of tasks that go beyond generative sampling, involving forms\nof summarization, counterfactual thinking, anomaly detection, originality\nsearch, reverse prompting, debating, creative solving, etc. These tasks can be\nformulated as games based on LLM measures, which we call Cross-Entropy (Xent)\nGames. Xent Games can be single-player or multi-player. They involve\ncross-entropy scores and cross-entropy constraints, and can be expressed as\nsimple computational graphs and programs. We show the Xent Game space is large\nenough to contain a wealth of interesting examples, while being constructible\nfrom basic game-theoretic consistency axioms. We then discuss how the Xent Game\nspace can be used to measure the abilities of LLMs. This leads to the\nconstruction of Xent Game measures: finite families of Xent Games that can be\nused as capability benchmarks, built from a given scope, by extracting a\ncovering measure. To address the unbounded scope problem associated with the\nchallenge of measuring general abilities, we propose to explore the space of\nXent Games in a coherent fashion, using ideas inspired by evolutionary\ndynamics.", "comment": "41 pages, 16 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06832v1", "AI": {"title_translation": "语言模型的交叉熵博弈：从隐性知识到通用能力衡量", "tldr": "该论文提出“交叉熵（Xent）博弈”作为一种新颖的框架，用于超越生成采样来评估大型语言模型（LLM）的通用能力，通过基于LLM概率度量的游戏化任务来衡量其隐含知识。", "motivation": "该研究旨在探讨LLM“知道”概率度量意味着什么，并提出超越生成采样的任务来衡量LLM的通用能力，特别是解决衡量通用能力时面临的无界范围问题。", "method": "作者提出了基于LLM度量的“交叉熵（Xent）博弈”框架。这些博弈包括交叉熵分数和约束，可以是单人或多人，并可表示为简单的计算图和程序。他们提出使用有限的Xent博弈族作为“Xent博弈度量”来构建能力基准，并通过受进化动力学启发的思想来探索Xent博弈空间，以解决无界范围问题。", "result": "Xent博弈空间被证明足够大，可以包含大量有趣的例子，并且可以从基本的博弈论一致性公理构建。Xent博弈度量可用于构建LLM能力基准。", "conclusion": "Xent博弈为评估LLM能力提供了一个新颖的框架，超越了传统的生成采样，为衡量隐性知识和通用能力提供了一种结构化的方法，并通过进化动力学思想应对了无界范围的挑战。", "translation": "大型语言模型（LLM）定义了文本上的概率度量。通过考虑LLM“知道”这种度量意味着什么以及它在算法上需要什么这一隐性知识问题，我们自然而然地提出了一系列超越生成采样的任务，包括摘要、反事实思维、异常检测、原创性搜索、逆向提示、辩论、创造性解决等形式。这些任务可以被表述为基于LLM度量的博弈，我们称之为交叉熵（Xent）博弈。Xent博弈可以是单人或多人。它们涉及交叉熵分数和交叉熵约束，并且可以表示为简单的计算图和程序。我们展示了Xent博弈空间足够大，可以包含大量有趣的例子，同时可以从基本的博弈论一致性公理构建。然后我们讨论了如何使用Xent博弈空间来衡量LLM的能力。这导致了Xent博弈度量的构建：从给定范围中提取覆盖度量，构建的有限Xent博弈族可以作为能力基准。为了解决与衡量通用能力挑战相关的无界范围问题，我们建议利用受进化动力学启发的思想，以连贯的方式探索Xent博弈空间。", "summary": "本文引入了“交叉熵（Xent）博弈”这一新颖框架，用于超越传统生成采样来评估大型语言模型（LLM）。这些博弈基于LLM的概率度量，涵盖了摘要、反事实思维和异常检测等多样化任务。Xent博弈涉及交叉熵分数和约束，可以是单人或多人，并被证明可以形成一个丰富且符合公理一致性的空间。作者提出使用有限的Xent博弈族作为“Xent博弈度量”来衡量LLM的能力，并通过进化动力学探索博弈空间，以解决衡量通用能力时面临的无界范围问题。", "keywords": "交叉熵博弈, 大型语言模型, 能力衡量, 隐性知识, 博弈论", "comments": "该论文提出了一个创新的博弈论框架——Xent博弈，旨在超越简单的生成评估来衡量LLM。通过关注隐性知识和更广泛的任务（如反事实思维和异常检测），它提供了一种更全面的方法来衡量LLM的通用能力。利用进化动力学探索通用能力无界范围的思想尤其引人入胜，有望带来更健壮和适应性更强的基准。"}}
{"id": "2506.06455", "title": "WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets", "authors": ["Antonio Jesús Banegas-Luna", "Horacio Pérez-Sánchez", "Carlos Martínez-Cortés"], "summary": "While predictive accuracy is often prioritized in machine learning (ML)\nmodels, interpretability remains essential in scientific and high-stakes\ndomains. However, diverse interpretability algorithms frequently yield\nconflicting explanations, highlighting the need for consensus to harmonize\nresults. In this study, six ML models were trained on six synthetic datasets\nwith known ground truths, utilizing various model-agnostic interpretability\ntechniques. Consensus explanations were generated using established methods and\na novel approach: WISCA (Weighted Scaled Consensus Attributions), which\nintegrates class probability and normalized attributions. WISCA consistently\naligned with the most reliable individual method, underscoring the value of\nrobust consensus strategies in improving explanation reliability.", "comment": "27 pages, 11 figures, 2 tables, 13 equations", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06455v1", "AI": {"title_translation": "WISCA：一种基于共识的表格数据集可解释性协调方法", "tldr": "WISCA提出了一种新的共识方法，通过结合类概率和归一化归因来协调机器学习模型中的可解释性解释，并显示出与最可靠的个体方法一致的结果。", "motivation": "尽管机器学习模型通常优先考虑预测准确性，但在科学和高风险领域，可解释性仍然至关重要。然而，不同的可解释性算法经常产生相互矛盾的解释，这突出了需要共识来协调结果。", "method": "本研究在六个具有已知真实值的合成数据集上训练了六个机器学习模型，并利用了各种模型无关的可解释性技术。使用现有方法和一种新颖的方法：WISCA（加权缩放共识归因）生成共识解释，WISCA集成了类概率和归一化归因。", "result": "WISCA始终与最可靠的个体方法保持一致。", "conclusion": "强大的共识策略在提高解释可靠性方面具有重要价值。", "translation": "尽管机器学习（ML）模型通常优先考虑预测准确性，但在科学和高风险领域，可解释性仍然至关重要。然而，不同的可解释性算法经常产生相互矛盾的解释，这突出了需要共识来协调结果。在本研究中，六个ML模型在六个具有已知真实值的合成数据集上进行了训练，并利用了各种模型无关的可解释性技术。使用既定方法和一种新颖的方法：WISCA（加权缩放共识归因）生成了共识解释，该方法集成了类概率和归一化归因。WISCA始终与最可靠的个体方法保持一致，这强调了稳健的共识策略在提高解释可靠性方面的价值。", "summary": "这项研究提出了WISCA（加权缩放共识归因），一种新的共识方法，用于协调机器学习模型中不同可解释性算法产生的相互矛盾的解释。通过在合成数据集上训练模型并应用模型无关的可解释性技术，WISCA被证明能与最可靠的个体方法保持一致，从而提高了解释的可靠性，这对于科学和高风险领域至关重要。", "keywords": "可解释性, 共识, WISCA, 表格数据集, 机器学习", "comments": "这篇论文通过提出WISCA，解决了机器学习可解释性领域中一个重要的问题：不同解释算法结果不一致。WISCA的创新点在于其结合类概率和归一化归因来生成更可靠的共识解释。这项工作对于提高机器学习模型在关键应用中的可信度和透明度具有重要意义。"}}
{"id": "2506.07326", "title": "Reward Model Interpretability via Optimal and Pessimal Tokens", "authors": ["Brian Christian", "Hannah Rose Kirk", "Jessica A. F. Thompson", "Christopher Summerfield", "Tsvetomira Dumbalska"], "summary": "Reward modeling has emerged as a crucial component in aligning large language\nmodels with human values. Significant attention has focused on using reward\nmodels as a means for fine-tuning generative models. However, the reward models\nthemselves -- which directly encode human value judgments by turning\nprompt-response pairs into scalar rewards -- remain relatively understudied. We\npresent a novel approach to reward model interpretability through exhaustive\nanalysis of their responses across their entire vocabulary space. By examining\nhow different reward models score every possible single-token response to\nvalue-laden prompts, we uncover several striking findings: (i) substantial\nheterogeneity between models trained on similar objectives, (ii) systematic\nasymmetries in how models encode high- vs low-scoring tokens, (iii) significant\nsensitivity to prompt framing that mirrors human cognitive biases, and (iv)\novervaluation of more frequent tokens. We demonstrate these effects across ten\nrecent open-source reward models of varying parameter counts and architectures.\nOur results challenge assumptions about the interchangeability of reward\nmodels, as well as their suitability as proxies of complex and\ncontext-dependent human values. We find that these models can encode concerning\nbiases toward certain identity groups, which may emerge as unintended\nconsequences of harmlessness training -- distortions that risk propagating\nthrough the downstream large language models now deployed to millions.", "comment": "Accepted for publication in Proceedings of the 2025 ACM Conference on\n  Fairness, Accountability, and Transparency (FAccT '25), to appear June 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07326v1", "AI": {"title_translation": "奖励模型通过最优和最差令牌的可解释性研究", "tldr": "本文通过对奖励模型在整个词汇空间中的响应进行穷尽分析，揭示了奖励模型在编码人类价值判断方面存在显著的异质性、不对称性、对提示语的敏感性和对高频词的偏爱，并发现其可能存在有害偏见，挑战了奖励模型作为人类价值代理的适用性。", "motivation": "奖励模型在使大型语言模型与人类价值观对齐方面至关重要，但其本身作为直接编码人类价值判断的工具，却相对未被充分研究。", "method": "提出了一种新的奖励模型可解释性方法，通过对奖励模型在整个词汇空间中的响应进行穷尽分析。具体而言，研究了不同奖励模型如何对每个可能的单令牌响应进行评分，以响应含有价值判断的提示语。", "result": "1. 训练目标相似的模型之间存在显著异质性。\n2. 模型在编码高分和低分令牌方面存在系统性不对称。\n3. 模型对提示语的敏感性显著，这与人类认知偏见相似。\n4. 模型过高评价更频繁的令牌。\n5. 这些模型可能对某些身份群体编码了令人担忧的偏见，这可能是无害性训练的意外后果。", "conclusion": "研究结果挑战了奖励模型可互换性的假设，以及它们作为复杂和依赖上下文的人类价值观代理的适用性。这些模型可能编码了对某些身份群体的偏见，这种扭曲可能通过下游的大型语言模型传播。", "translation": "奖励建模已成为使大型语言模型与人类价值观对齐的关键组成部分。人们将大量注意力集中在将奖励模型用作微调生成模型的方法。然而，奖励模型本身——它们通过将提示-响应对转化为标量奖励来直接编码人类价值判断——却相对未被充分研究。我们提出了一种通过对其在整个词汇空间中的响应进行穷尽分析来解释奖励模型的新方法。通过检查不同的奖励模型如何对价值导向提示的每个可能的单令牌响应进行评分，我们发现了一些惊人的发现：(i) 训练目标相似的模型之间存在显著异质性，(ii) 模型在编码高分和低分令牌方面存在系统性不对称，(iii) 模型对提示语的敏感性显著，这与人类认知偏见相似，以及 (iv) 模型过高评价更频繁的令牌。我们展示了这些效应在十个最近的开源奖励模型中（参数数量和架构各不相同）。我们的结果挑战了奖励模型可互换性的假设，以及它们作为复杂和依赖上下文的人类价值观代理的适用性。我们发现这些模型可能对某些身份群体编码了令人担忧的偏见，这可能是无害性训练的意外后果——这种扭曲有传播到当前部署给数百万用户的大型语言模型中的风险。", "summary": "本研究通过对奖励模型在整个词汇空间中的响应进行穷尽分析，提出了一种新颖的奖励模型可解释性方法。通过评估不同奖励模型对价值导向提示的单令牌响应评分，揭示了模型间的显著异质性、对高低分令牌编码的系统性不对称、对提示语框定的敏感性（类似人类认知偏见）以及对高频令牌的过高评价。研究结果挑战了奖励模型的可互换性及其作为复杂人类价值观代理的适用性，并指出这些模型可能无意中编码了对特定身份群体的偏见，存在将这些偏见传播到下游大型语言模型的风险。", "keywords": "奖励模型, 可解释性, 偏见, 大型语言模型, 价值对齐", "comments": "这篇论文的创新之处在于它将研究重点从奖励模型作为微调工具转向了奖励模型本身的可解释性，揭示了其内部运作机制和潜在偏见。其重要性在于，它对奖励模型作为人类价值代理的可靠性提出了质疑，并揭示了即使是“无害性训练”也可能导致有害偏见的产生和传播，这对未来大型语言模型的开发和部署具有重要的指导意义。论文通过系统性分析，提供了具体的证据来支持其发现，这对于理解和改进奖励模型至关重要。"}}
{"id": "2506.07403", "title": "Enhancing Watermarking Quality for LLMs via Contextual Generation States Awareness", "authors": ["Peiru Yang", "Xintian Li", "Wanchun Ni", "Jinhua Yin", "Huili Wang", "Guoshun Nan", "Shangguang Wang", "Yongfeng Huang", "Tao Qi"], "summary": "Recent advancements in watermarking techniques have enabled the embedding of\nsecret messages into AI-generated text (AIGT), serving as an important\nmechanism for AIGT detection. Existing methods typically interfere with the\ngeneration processes of large language models (LLMs) to embed signals within\nthe generated text. However, these methods often rely on heuristic rules, which\ncan result in suboptimal token selection and a subsequent decline in the\nquality of the generated content. In this paper, we introduce a plug-and-play\ncontextual generation states-aware watermarking framework (CAW) that\ndynamically adjusts the embedding process. It can be seamlessly integrated with\nvarious existing watermarking methods to enhance generation quality. First, CAW\nincorporates a watermarking capacity evaluator, which can assess the impact of\nembedding messages at different token positions by analyzing the contextual\ngeneration states. Furthermore, we introduce a multi-branch pre-generation\nmechanism to avoid the latency caused by the proposed watermarking strategy.\nBuilding on this, CAW can dynamically adjust the watermarking process based on\nthe evaluated watermark capacity of each token, thereby minimizing potential\ndegradation in content quality. Extensive experiments conducted on datasets\nacross multiple domains have verified the effectiveness of our method,\ndemonstrating superior performance compared to various baselines in terms of\nboth detection rate and generation quality.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07403v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07004", "title": "Hierarchical Intention Tracking with Switching Trees for Real-Time Adaptation to Dynamic Human Intentions during Collaboration", "authors": ["Zhe Huang", "Ye-Ji Mun", "Fatemeh Cheraghi Pouria", "Katherine Driggs-Campbell"], "summary": "During collaborative tasks, human behavior is guided by multiple levels of\nintentions that evolve over time, such as task sequence preferences and\ninteraction strategies. To adapt to these changing preferences and promptly\ncorrect any inaccurate estimations, collaborative robots must accurately track\nthese dynamic human intentions in real time. We propose a Hierarchical\nIntention Tracking (HIT) algorithm for collaborative robots to track dynamic\nand hierarchical human intentions effectively in real time. HIT represents\nhuman intentions as intention trees with arbitrary depth, and probabilistically\ntracks human intentions by Bayesian filtering, upward measurement propagation,\nand downward posterior propagation across all levels. We develop a HIT-based\nrobotic system that dynamically switches between Interaction-Task and\nVerification-Task trees for a collaborative assembly task, allowing the robot\nto effectively coordinate human intentions at three levels: task-level (subtask\ngoal locations), interaction-level (mode of engagement with the robot), and\nverification-level (confirming or correcting intention recognition). Our user\nstudy shows that our HIT-based collaborative robot system surpasses existing\ncollaborative robot solutions by achieving a balance between efficiency,\nphysical workload, and user comfort while ensuring safety and task completion.\nPost-experiment surveys further reveal that the HIT-based system enhances the\nuser trust and minimizes interruptions to user's task flow through its\neffective understanding of human intentions across multiple levels.", "comment": "15 pages, 10 figures", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07004v1", "AI": {"title_translation": "用于实时适应协作中动态人类意图的带切换树的分层意图跟踪", "tldr": "本文提出了一种分层意图跟踪（HIT）算法，使协作机器人能够实时跟踪动态和分层的人类意图，从而提高效率、减轻工作负荷并提升用户舒适度。", "motivation": "在协作任务中，人类行为受多层次意图的引导且随时间演变，协作机器人需要准确实时跟踪这些动态和多层次的人类意图，以适应不断变化的偏好并及时纠正不准确的估计。", "method": "本文提出了分层意图跟踪（HIT）算法，该算法将人类意图表示为任意深度的意图树，并通过贝叶斯滤波、向上测量传播和向下后验传播在所有级别上概率性地跟踪人类意图。开发了一个基于HIT的机器人系统，在协作装配任务中动态切换交互任务树和验证任务树，以协调任务级别、交互级别和验证级别的人类意图。", "result": "用户研究表明，基于HIT的协作机器人系统在确保安全和任务完成的同时，实现了效率、体力负荷和用户舒适度之间的平衡，并超越了现有解决方案。实验后调查进一步显示，该系统增强了用户信任并最大限度地减少了对用户任务流程的干扰。", "conclusion": "HIT算法使协作机器人能够有效跟踪动态和分层的人类意图，从而改善人机协作性能和用户体验。", "translation": "在协作任务中，人类行为受多层次意图的引导，这些意图随时间演变，例如任务序列偏好和交互策略。为了适应这些不断变化的偏好并及时纠正任何不准确的估计，协作机器人必须实时准确地跟踪这些动态的人类意图。我们提出了一种分层意图跟踪（HIT）算法，用于协作机器人实时有效地跟踪动态和分层的人类意图。HIT将人类意图表示为任意深度的意图树，并通过贝叶斯滤波、向上测量传播和向下后验传播在所有级别上概率性地跟踪人类意图。我们开发了一个基于HIT的机器人系统，该系统在协作装配任务中动态切换交互任务树和验证任务树，使机器人能够有效协调三个级别的人类意图：任务级别（子任务目标位置）、交互级别（与机器人的交互模式）和验证级别（确认或纠正意图识别）。我们的用户研究表明，我们基于HIT的协作机器人系统超越了现有的协作机器人解决方案，在确保安全和任务完成的同时，实现了效率、体力负荷和用户舒适度之间的平衡。实验后调查进一步显示，基于HIT的系统通过其对多层次人类意图的有效理解，增强了用户信任并最大限度地减少了对用户任务流程的干扰。", "summary": "本文介绍了一种分层意图跟踪（HIT）算法，该算法允许协作机器人通过对意图树进行概率性方法实时跟踪动态和多层次的人类意图。在协作装配任务中应用动态树切换，HIT与现有协作机器人解决方案相比，提高了效率，减轻了体力负荷，增强了用户舒适度，并建立了用户信任。", "keywords": "分层意图跟踪, 人机协作, 动态意图, 实时适应, 贝叶斯滤波", "comments": "该论文的创新之处在于将意图分层表示为可切换的树结构，并采用概率跟踪机制（贝叶斯滤波、传播）。这种方法解决了人机协作中实时适应的关键需求，从而实现更自然、更高效的交互。对用户舒适度和信任的强调是一个重要的积极成果。"}}
{"id": "2506.06771", "title": "LoopDB: A Loop Closure Dataset for Large Scale Simultaneous Localization and Mapping", "authors": ["Mohammad-Maher Nakshbandi", "Ziad Sharawy", "Dorian Cojocaru", "Sorin Grigorescu"], "summary": "In this study, we introduce LoopDB, which is a challenging loop closure\ndataset comprising over 1000 images captured across diverse environments,\nincluding parks, indoor scenes, parking spaces, as well as centered around\nindividual objects. Each scene is represented by a sequence of five consecutive\nimages. The dataset was collected using a high resolution camera, providing\nsuitable imagery for benchmarking the accuracy of loop closure algorithms,\ntypically used in simultaneous localization and mapping. As ground truth\ninformation, we provide computed rotations and translations between each\nconsecutive images. Additional to its benchmarking goal, the dataset can be\nused to train and fine-tune loop closure methods based on deep neural networks.\nLoopDB is publicly available at https://github.com/RovisLab/LoopDB.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06771v1", "AI": {"title_translation": "LoopDB：一个用于大规模同步定位与建图的闭环检测数据集", "tldr": "LoopDB是一个包含1000多张图像的闭环检测数据集，适用于大规模同步定位与建图中的算法基准测试和训练。", "motivation": "该研究的动机是提供一个具有挑战性的闭环检测数据集，用于评估和训练同步定位与建图（SLAM）中的闭环检测算法的准确性。", "method": "本研究介绍了LoopDB数据集，它包含1000多张在公园、室内场景、停车场以及围绕单个物体等多种不同环境中捕获的图像。每场景由五张连续图像序列表示。数据集使用高分辨率相机收集，并提供连续图像之间的计算出的旋转和平移作为真值信息。", "result": "结果是创建并公开了一个名为LoopDB的闭环检测数据集，该数据集可用于基准测试和训练基于深度神经网络的闭环检测方法。", "conclusion": "LoopDB数据集为大规模同步定位与建图中的闭环检测算法提供了一个有价值的基准测试和训练资源。", "translation": "在本研究中，我们介绍了LoopDB，这是一个具有挑战性的闭环检测数据集，包含在公园、室内场景、停车场以及围绕单个物体等多种不同环境中捕获的1000多张图像。每个场景都由五张连续图像的序列表示。该数据集使用高分辨率相机收集，为通常用于同步定位与建图的闭环检测算法的准确性基准测试提供了合适的图像。作为真值信息，我们提供了每张连续图像之间计算出的旋转和平移。除了其基准测试目标外，该数据集还可用于训练和微调基于深度神经网络的闭环检测方法。LoopDB可在https://github.com/RovisLab/LoopDB公开获取。", "summary": "本研究推出了LoopDB，一个包含1000多张图像的闭环检测数据集，涵盖公园、室内、停车场和物体中心等多样化环境。该数据集通过高分辨率相机收集，并提供连续图像间的真值旋转和平移，旨在为大规模同步定位与建图（SLAM）中的闭环检测算法提供基准测试。此外，LoopDB也适用于深度神经网络闭环检测方法的训练和微调，并已公开可用。", "keywords": "闭环检测, 数据集, 同步定位与建图, SLAM, LoopDB", "comments": "LoopDB数据集的创新之处在于其多样化的环境和大规模图像数量，这使其成为评估和训练闭环检测算法的宝贵资源。高分辨率图像和提供的真值信息增强了其在基准测试方面的实用性。该数据集的公开可用性将促进SLAM领域闭环检测方法的研究和发展。"}}
{"id": "2506.06843", "title": "United Minds or Isolated Agents? Exploring Coordination of LLMs under Cognitive Load Theory", "authors": ["HaoYang Shang", "Xuan Liu", "Zi Liang", "Jie Zhang", "Haibo Hu", "Song Guo"], "summary": "Large Language Models (LLMs) exhibit a notable performance ceiling on\ncomplex, multi-faceted tasks, as they often fail to integrate diverse\ninformation or adhere to multiple constraints. We posit that such limitation\narises when the demands of a task exceed the LLM's effective cognitive load\ncapacity. This interpretation draws a strong analogy to Cognitive Load Theory\n(CLT) in cognitive science, which explains similar performance boundaries in\nthe human mind, and is further supported by emerging evidence that reveals LLMs\nhave bounded working memory characteristics. Building upon this CLT-grounded\nunderstanding, we introduce CoThinker, a novel LLM-based multi-agent framework\ndesigned to mitigate cognitive overload and enhance collaborative\nproblem-solving abilities. CoThinker operationalizes CLT principles by\ndistributing intrinsic cognitive load through agent specialization and managing\ntransactional load via structured communication and a collective working\nmemory. We empirically validate CoThinker on complex problem-solving tasks and\nfabricated high cognitive load scenarios, demonstrating improvements over\nexisting multi-agent baselines in solution quality and efficiency. Our analysis\nreveals characteristic interaction patterns, providing insights into the\nemergence of collective cognition and effective load management, thus offering\na principled approach to overcoming LLM performance ceilings.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06843v1", "AI": {"title_translation": "统一的思维还是孤立的智能体？探索认知负荷理论下大型语言模型的协调性", "tldr": "大型语言模型（LLMs）在复杂任务上表现受限，本文受认知负荷理论启发，提出CoThinker多智能体框架，通过专业化和结构化通信来管理认知负荷，有效提升了LLM的协作问题解决能力。", "motivation": "大型语言模型（LLMs）在复杂的、多方面的任务上表现出显著的性能上限，常常无法整合多样信息或遵循多重约束，这可能是因为任务需求超出了LLM的有效认知负荷容量。", "method": "引入CoThinker，一个新型的基于LLM的多智能体框架，旨在减轻认知过载并增强协作解决问题的能力。CoThinker通过智能体专业化分配内在认知负荷，并通过结构化通信和集体工作记忆管理事务性负荷，从而操作化认知负荷理论原则。", "result": "CoThinker在复杂问题解决任务和伪造的高认知负荷场景中进行了实证验证，证明其在解决方案质量和效率上优于现有多智能体基线。分析揭示了特征交互模式，提供了关于集体认知出现和有效负荷管理的见解。", "conclusion": "CoThinker提供了一种有原则的方法来克服大型语言模型的性能上限，通过有效管理认知负荷和促进集体认知。", "translation": "大型语言模型（LLMs）在复杂的、多方面的任务上表现出显著的性能上限，因为它们常常无法整合多样信息或遵循多重约束。我们认为，这种限制产生于任务需求超出LLM的有效认知负荷容量时。这种解释与认知科学中的认知负荷理论（CLT）有很强的类比，CLT解释了人类思维中类似的性能边界，并且新兴证据表明LLMs具有有限的工作记忆特性，这进一步支持了该观点。基于这种以CLT为基础的理解，我们引入了CoThinker，一个新型的基于LLM的多智能体框架，旨在减轻认知过载并增强协作解决问题的能力。CoThinker通过智能体专业化分配内在认知负荷，并通过结构化通信和集体工作记忆管理事务性负荷，从而操作化CLT原则。我们在复杂问题解决任务和伪造的高认知负荷场景中对CoThinker进行了实证验证，证明其在解决方案质量和效率上优于现有多智能体基线。我们的分析揭示了特征交互模式，提供了关于集体认知出现和有效负荷管理的见解，从而提供了一种有原则的方法来克服LLM的性能上限。", "summary": "本文探讨了大型语言模型（LLMs）在复杂任务上存在的性能上限，并将其归因于认知负荷超出其处理能力。受认知负荷理论（CLT）启发，作者提出了CoThinker，一个新型LLM多智能体框架。CoThinker通过智能体专业化和结构化通信来有效管理认知负荷，并被证明在复杂问题解决任务中优于现有基线，提升了解决方案质量和效率。这项工作为克服LLM性能瓶颈提供了一种原则性方法。", "keywords": "大型语言模型, 认知负荷理论, 多智能体系统, 协作问题解决, 性能上限", "comments": "这篇论文通过将认知负荷理论引入LLM领域，为理解和解决LLM在复杂任务上的性能瓶颈提供了一个新颖且有力的视角。CoThinker框架的设计理念清晰，通过模拟人类认知过程中的负荷管理策略，有效地提升了LLM的协作能力，这对于未来构建更强大的LLM系统具有重要意义。"}}
{"id": "2506.07404", "title": "Pixel-Sensitive and Robust Steganography Based on Polar Codes", "authors": ["Yujun Ji", "Jinsheng Li", "Ling Liu", "Qi Cao", "Tao Dai"], "summary": "Steganography is an information hiding technique for covert communication.\nThe core issue in steganography design is the rate-distortion coding problem.\nPolar codes, which have been proven to achieve the rate-distortion bound for\nany binary symmetric source, are utilized to design a steganographic scheme\nthat can reach the embedding capacity for the Distortion-Limited Sender problem\nin certain cases. In adaptive steganography, for attack scenarios where each\nnoise element can have different intensities, existing steganographic coding\nmethods fail to resist such attacks. In this paper, we propose a\npixel-sensitive and robust steganographic scheme based on polar codes. Our\nsteganographic scheme not only matches the adaptive distortion well but is also\nrobust against sophisticated noise attacks. Futher, it is proven that our\nscheme achieves the embedding capacity in certain cases. Experimentally, a\nsteganographic scheme can be designed and implemented with a secret message\nerror rate at the $10^{-5}$ level when the attack noise is known to both the\nsender and the receiver. This demonstrates its significant robustness.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07404v1", "AI": {"title_translation": "基于极性码的像素敏感鲁棒隐写术", "tldr": "本文提出了一种基于极性码的像素敏感鲁棒隐写方案，该方案在某些情况下可以达到嵌入容量，并能有效抵抗复杂的噪声攻击。", "motivation": "现有的隐写编码方法无法抵抗每个噪声元素具有不同强度的自适应攻击，而隐写术设计的核心问题是速率-失真编码问题。", "method": "本文提出了一种基于极性码的像素敏感鲁棒隐写方案。该方案旨在很好地匹配自适应失真，并且对复杂的噪声攻击具有鲁棒性。", "result": "实验证明，该方案在某些情况下可以达到嵌入容量，并且当发送方和接收方都知道攻击噪声时，可以实现秘密消息错误率在10^-5级别的隐写方案，这表明其具有显著的鲁棒性。", "conclusion": "本文提出的基于极性码的像素敏感鲁棒隐写方案，不仅能很好地匹配自适应失真，而且对复杂的噪声攻击具有显著的鲁棒性，并在某些情况下实现了嵌入容量。", "translation": "隐写术是一种用于秘密通信的信息隐藏技术。隐写术设计的核心问题是速率-失真编码问题。极性码已被证明可以为任何二元对称源实现速率-失真界限，本文利用极性码设计了一种隐写方案，在某些情况下可以达到失真受限发送方问题的嵌入容量。在自适应隐写术中，对于每个噪声元素可能具有不同强度的攻击场景，现有的隐写编码方法无法抵抗此类攻击。在本文中，我们提出了一种基于极性码的像素敏感鲁棒隐写方案。我们的隐写方案不仅能很好地匹配自适应失真，而且对复杂的噪声攻击具有鲁棒性。此外，证明了我们的方案在某些情况下实现了嵌入容量。实验表明，当发送方和接收方都知道攻击噪声时，可以设计并实现秘密消息错误率在10^-5级别的隐写方案。这表明其具有显著的鲁棒性。", "summary": "针对现有隐写编码方法在自适应攻击下抵抗能力不足的问题，本文提出了一种基于极性码的像素敏感鲁棒隐写方案。该方案利用极性码能够达到速率-失真界限的特性，旨在匹配自适应失真并抵抗复杂的噪声攻击。实验证明，该方案在某些情况下能达到嵌入容量，并能在攻击噪声已知的情况下，实现10^-5级别的秘密消息错误率，展现出显著的鲁棒性。", "keywords": "隐写术, 极性码, 鲁棒性, 速率-失真, 自适应失真", "comments": "本文的创新点在于将极性码应用于像素敏感的鲁棒隐写术设计，有效解决了传统方法在面对不同强度噪声攻击时的不足。其在特定条件下达到嵌入容量并实现低错误率的实验结果，凸显了该方案在信息隐藏领域的实用性和重要性。"}}
{"id": "2506.07452", "title": "When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment", "authors": ["Yuxin Xiao", "Sana Tonekaboni", "Walter Gerych", "Vinith Suriyakumar", "Marzyeh Ghassemi"], "summary": "Large language models (LLMs) can be prompted with specific styles (e.g.,\nformatting responses as lists), including in jailbreak queries. Although these\nstyle patterns are semantically unrelated to the malicious intents behind\njailbreak queries, their safety impact remains unclear. In this work, we seek\nto understand whether style patterns compromise LLM safety, how superficial\nstyle alignment increases model vulnerability, and how best to mitigate these\nrisks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks,\nand find that malicious queries with style patterns inflate the attack success\nrate (ASR) for nearly all models. Notably, ASR inflation correlates with both\nthe length of style patterns and the relative attention an LLM exhibits on\nthem. We then investigate superficial style alignment, and find that\nfine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of\nthose same styles. Finally, we propose SafeStyle, a defense strategy that\nincorporates a small amount of safety training data augmented to match the\ndistribution of style patterns in the fine-tuning data. Across three LLMs and\nfive fine-tuning style settings, SafeStyle consistently outperforms baselines\nin maintaining LLM safety.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07452v1", "AI": {"title_translation": "当风格破坏安全时：防御语言模型对抗肤浅的风格对齐", "tldr": "研究发现，在越狱查询中添加风格模式会显著提高大型语言模型的攻击成功率，并提出了一种名为SafeStyle的防御策略，通过风格匹配的安全训练数据有效提高了模型的安全性。", "motivation": "尽管风格模式与恶意意图语义无关，但它们对大型语言模型（LLMs）安全性的影响尚不明确。研究旨在理解风格模式是否会损害LLM安全性、肤浅的风格对齐如何增加模型脆弱性，以及如何最好地在对齐过程中减轻这些风险。", "method": "研究评估了32个LLMs在七个越狱基准测试上的表现，以观察带有风格模式的恶意查询如何影响攻击成功率（ASR）。随后，调查了肤浅的风格对齐，发现用特定风格进行微调会使LLMs更容易受到相同风格的越狱攻击。最后，提出了一种名为SafeStyle的防御策略，该策略通过将少量安全训练数据进行增强，使其与微调数据中的风格模式分布匹配，并在三个LLMs和五种微调风格设置中进行了评估。", "result": "研究发现，带有风格模式的恶意查询几乎对所有模型都提高了攻击成功率（ASR）。ASR的提高与风格模式的长度以及LLM对它们的相对注意力相关。用特定风格进行微调会使LLMs更容易受到相同风格的越狱攻击。提出的SafeStyle防御策略在保持LLM安全性方面始终优于基线方法。", "conclusion": "风格模式会显著增加大型语言模型（LLMs）的越狱脆弱性。通过引入与微调风格分布匹配的增强安全训练数据（SafeStyle），可以有效地防御这种攻击，显著提高模型的安全性。", "translation": "大型语言模型（LLMs）可以用特定的风格（例如，将响应格式化为列表）进行提示，包括在越狱查询中。尽管这些风格模式在语义上与越狱查询背后的恶意意图无关，但它们的安全影响仍不清楚。在这项工作中，我们试图了解风格模式是否会损害LLM的安全性，肤浅的风格对齐如何增加模型的脆弱性，以及如何在对齐过程中最好地减轻这些风险。我们评估了32个LLM在七个越狱基准测试上的表现，发现带有风格模式的恶意查询几乎对所有模型都提高了攻击成功率（ASR）。值得注意的是，ASR的提高与风格模式的长度以及LLM对它们的相对注意力相关。然后，我们调查了肤浅的风格对齐，发现用特定风格进行微调会使LLMs更容易受到相同风格的越狱攻击。最后，我们提出了SafeStyle，这是一种防御策略，它结合了少量安全训练数据，并将其增强以匹配微调数据中的风格模式分布。在三个LLM和五种微调风格设置中，SafeStyle在保持LLM安全性方面始终优于基线方法。", "summary": "这项研究探讨了在大型语言模型（LLMs）的越狱查询中引入“风格模式”如何影响模型安全性。研究发现，即使风格与恶意意图无关，它们也能显著提高攻击成功率，且这种脆弱性与风格模式的长度和模型的注意力分配有关。此外，用特定风格进行微调会使LLMs更容易受到相同风格的越狱。为解决此问题，论文提出了SafeStyle防御策略，通过将少量安全训练数据与微调数据中的风格模式分布相匹配，有效提升了LLMs的安全性。", "keywords": "大型语言模型, 越狱攻击, 风格对齐, 模型安全, SafeStyle", "comments": "这篇论文揭示了一个重要的LLM安全漏洞，即“肤浅的风格对齐”可能导致模型更容易被越狱。其创新之处在于量化了风格模式对攻击成功率的影响，并提出了一个简单而有效的防御策略SafeStyle。这项研究对于理解LLM的鲁棒性和开发更安全的模型具有重要意义，特别是在实际应用中需要考虑用户提示的复杂性。"}}
{"id": "2506.07006", "title": "CARoL: Context-aware Adaptation for Robot Learning", "authors": ["Zechen Hu", "Tong Xu", "Xuesu Xiao", "Xuan Wang"], "summary": "Using Reinforcement Learning (RL) to learn new robotic tasks from scratch is\noften inefficient. Leveraging prior knowledge has the potential to\nsignificantly enhance learning efficiency, which, however, raises two critical\nchallenges: how to determine the relevancy of existing knowledge and how to\nadaptively integrate them into learning a new task. In this paper, we propose\nContext-aware Adaptation for Robot Learning (CARoL), a novel framework to\nefficiently learn a similar but distinct new task from prior knowledge. CARoL\nincorporates context awareness by analyzing state transitions in system\ndynamics to identify similarities between the new task and prior knowledge. It\nthen utilizes these identified similarities to prioritize and adapt specific\nknowledge pieces for the new task. Additionally, CARoL has a broad\napplicability spanning policy-based, value-based, and actor-critic RL\nalgorithms. We validate the efficiency and generalizability of CARoL on both\nsimulated robotic platforms and physical ground vehicles. The simulations\ninclude CarRacing and LunarLander environments, where CARoL demonstrates faster\nconvergence and higher rewards when learning policies for new tasks. In\nreal-world experiments, we show that CARoL enables a ground vehicle to quickly\nand efficiently adapt policies learned in simulation to smoothly traverse\nreal-world off-road terrain.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07006v1", "AI": {"title_translation": "CARoL：机器人学习中的上下文感知适应", "tldr": "CARoL是一个新的框架，通过上下文感知分析状态转换来识别相似性并优先适应特定知识，从而有效地从先验知识中学习新的机器人任务。", "motivation": "从头开始使用强化学习（RL）学习新的机器人任务通常效率低下。利用先验知识有显著提高学习效率的潜力，但这带来了两个关键挑战：如何确定现有知识的相关性以及如何将它们自适应地整合到新任务的学习中。", "method": "本文提出了CARoL（Context-aware Adaptation for Robot Learning），一个新颖的框架，用于从先验知识中高效学习一个相似但不同的新任务。CARoL通过分析系统动力学中的状态转换来融入上下文感知，以识别新任务与先验知识之间的相似性。然后，它利用这些已识别的相似性来优先处理和适应特定知识片段以用于新任务。此外，CARoL具有广泛的适用性，涵盖基于策略、基于价值和Actor-Critic的RL算法。", "result": "CARoL在模拟机器人平台（包括CarRacing和LunarLander环境）和物理地面车辆上都验证了其效率和通用性。模拟结果表明，CARoL在学习新任务策略时展现出更快的收敛速度和更高的奖励。在真实世界实验中，CARoL使地面车辆能够快速高效地适应在模拟中学习到的策略，从而平稳地通过真实世界的越野地形。", "conclusion": "CARoL通过上下文感知适应机制，有效地解决了强化学习中利用先验知识的挑战，显著提高了机器人学习新任务的效率和泛化能力，并在模拟和真实环境中均得到了验证。", "translation": "使用强化学习（RL）从头开始学习新的机器人任务通常效率低下。利用先验知识有显著提高学习效率的潜力，但这带来了两个关键挑战：如何确定现有知识的相关性以及如何将它们自适应地整合到新任务的学习中。在本文中，我们提出了CARoL（Context-aware Adaptation for Robot Learning），一个新颖的框架，用于从先验知识中高效学习一个相似但不同的新任务。CARoL通过分析系统动力学中的状态转换来融入上下文感知，以识别新任务与先验知识之间的相似性。然后，它利用这些已识别的相似性来优先处理和适应特定知识片段以用于新任务。此外，CARoL具有广泛的适用性，涵盖基于策略、基于价值和Actor-Critic的RL算法。我们在模拟机器人平台和物理地面车辆上都验证了CARoL的效率和通用性。模拟包括CarRacing和LunarLander环境，其中CARoL在学习新任务策略时展现出更快的收敛速度和更高的奖励。在真实世界实验中，我们展示了CARoL使地面车辆能够快速高效地适应在模拟中学习到的策略，从而平稳地通过真实世界的越野地形。", "summary": "本文提出了CARoL（Context-aware Adaptation for Robot Learning），一个新颖的框架，旨在解决强化学习从头开始学习机器人任务效率低下的问题。CARoL通过分析系统动力学中的状态转换来识别新任务与先验知识之间的相似性，并利用这些相似性来优先并适应特定的知识片段。该框架适用于多种RL算法，并在模拟和真实世界的机器人平台上验证了其效率和泛化能力，包括在CarRacing和LunarLander环境中实现更快的收敛和更高的奖励，以及使地面车辆在真实世界中高效适应越野地形。", "keywords": "强化学习, 机器人学习, 上下文感知, 知识适应, 迁移学习", "comments": "CARoL的创新点在于其上下文感知适应机制，能够智能地识别并整合先验知识，这对于提高机器人学习效率至关重要。其广泛的算法适用性和在模拟与真实环境中的验证，凸显了该方法的实用性和重要性，为解决强化学习在复杂真实世界应用中的效率问题提供了有效途径。"}}
{"id": "2506.06780", "title": "Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations", "authors": ["Lennart Bastian", "Mohammad Rashed", "Nassir Navab", "Tolga Birdal"], "summary": "Tracking and forecasting the rotation of objects is fundamental in computer\nvision and robotics, yet SO(3) extrapolation remains challenging as (1) sensor\nobservations can be noisy and sparse, (2) motion patterns can be governed by\ncomplex dynamics, and (3) application settings can demand long-term\nforecasting. This work proposes modeling continuous-time rotational object\ndynamics on $SO(3)$ using Neural Controlled Differential Equations guided by\nSavitzky-Golay paths. Unlike existing methods that rely on simplified motion\nassumptions, our method learns a general latent dynamical system of the\nunderlying object trajectory while respecting the geometric structure of\nrotations. Experimental results on real-world data demonstrate compelling\nforecasting capabilities compared to existing approaches.", "comment": "Extended abstract, presented at the CVPR Workshop on 4D Vision", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06780v1", "AI": {"title_translation": "连续时间SO(3)预测与Savitzky-Golay神经控制微分方程", "tldr": "本文提出了一种使用Savitzky-Golay路径引导的神经控制微分方程，用于在SO(3)上建模连续时间旋转对象动力学，以应对噪声、稀疏观测和复杂动态下的长期旋转预测挑战。", "motivation": "跟踪和预测物体旋转在计算机视觉和机器人领域至关重要，但SO(3)外推仍然具有挑战性，因为传感器观测可能嘈杂且稀疏，运动模式可能由复杂动力学决定，以及应用场景可能需要长期预测。现有方法依赖于简化的运动假设，无法有效解决这些问题。", "method": "本文提出使用由Savitzky-Golay路径引导的神经控制微分方程（Neural Controlled Differential Equations guided by Savitzky-Golay paths）来建模SO(3)上的连续时间旋转对象动力学。该方法学习底层对象轨迹的通用潜在动力学系统，同时尊重旋转的几何结构，区别于依赖简化运动假设的现有方法。", "result": "在真实世界数据上的实验结果表明，与现有方法相比，该方法具有引人注目的预测能力。", "conclusion": "该方法有效地解决了SO(3)旋转预测中的挑战，并在实际应用中表现出优越性。", "translation": "跟踪和预测物体的旋转在计算机视觉和机器人领域至关重要，但SO(3)外推仍然具有挑战性，因为 (1) 传感器观测可能嘈杂且稀疏，(2) 运动模式可能由复杂动力学决定，以及 (3) 应用场景可能需要长期预测。这项工作提出使用由Savitzky-Golay路径引导的神经控制微分方程来建模SO(3)上的连续时间旋转对象动力学。与现有依赖简化运动假设的方法不同，我们的方法学习底层对象轨迹的通用潜在动力学系统，同时尊重旋转的几何结构。在真实世界数据上的实验结果表明，与现有方法相比，该方法具有引人注目的预测能力。", "summary": "本文提出了一种新颖的方法，利用Savitzky-Golay神经控制微分方程在SO(3)流形上对连续时间物体旋转进行建模和预测。该方法旨在克服传统SO(3)预测中传感器噪声、复杂动力学和长期预测需求带来的挑战，通过学习通用潜在动力学系统并尊重旋转的几何结构，实现了优于现有方法的预测性能。", "keywords": "SO(3)预测, 神经控制微分方程, Savitzky-Golay, 旋转动力学, 连续时间", "comments": "这项工作的创新点在于将Savitzky-Golay路径与神经控制微分方程结合，用于SO(3)上的连续时间旋转预测，这使得模型能够处理复杂的运动模式和噪声数据，同时保持几何结构。其重要性在于提升了计算机视觉和机器人领域中物体旋转跟踪和预测的鲁棒性与准确性。"}}
{"id": "2506.06868", "title": "Incorporating Failure of Machine Learning in Dynamic Probabilistic Safety Assurance", "authors": ["Razieh Arshadizadeh", "Mahmoud Asgari", "Zeinab Khosravi", "Yiannis Papadopoulos", "Koorosh Aslansefat"], "summary": "Machine Learning (ML) models are increasingly integrated into safety-critical\nsystems, such as autonomous vehicle platooning, to enable real-time\ndecision-making. However, their inherent imperfection introduces a new class of\nfailure: reasoning failures often triggered by distributional shifts between\noperational and training data. Traditional safety assessment methods, which\nrely on design artefacts or code, are ill-suited for ML components that learn\nbehaviour from data. SafeML was recently proposed to dynamically detect such\nshifts and assign confidence levels to the reasoning of ML-based components.\nBuilding on this, we introduce a probabilistic safety assurance framework that\nintegrates SafeML with Bayesian Networks (BNs) to model ML failures as part of\na broader causal safety analysis. This allows for dynamic safety evaluation and\nsystem adaptation under uncertainty. We demonstrate the approach on an\nsimulated automotive platooning system with traffic sign recognition. The\nfindings highlight the potential broader benefits of explicitly modelling ML\nfailures in safety assessment.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06868v1", "AI": {"title_translation": "将机器学习故障纳入动态概率安全保障", "tldr": "本文提出了一种结合SafeML和贝叶斯网络的新型概率安全保障框架，用于动态评估和适应性调整，以解决机器学习模型在安全关键系统中因分布偏移导致的推理故障问题。", "motivation": "机器学习模型越来越多地集成到安全关键系统中，但其固有的不完善性（特别是操作数据和训练数据之间的分布偏移导致的推理故障）引入了新的故障类别。传统的安全评估方法不适用于从数据中学习行为的ML组件。", "method": "该研究将SafeML与贝叶斯网络（BNs）集成，以建模机器学习故障，作为更广泛的因果安全分析的一部分。这允许在不确定性下进行动态安全评估和系统适应。", "result": "该方法在一个模拟的具有交通标志识别功能的汽车队列系统中进行了演示。研究结果强调了在安全评估中明确建模ML故障的潜在更广泛的好处。", "conclusion": "在安全评估中明确建模机器学习故障具有潜在的广泛益处，可以实现不确定性下的动态安全评估和系统适应。", "translation": "机器学习（ML）模型越来越多地集成到自动驾驶车队等安全关键系统中，以实现实时决策。然而，其固有的不完善性引入了一种新型故障：通常由操作数据和训练数据之间的分布偏移触发的推理故障。传统的依赖于设计文物或代码的安全评估方法不适用于从数据中学习行为的ML组件。SafeML最近被提出，用于动态检测此类偏移并为基于ML组件的推理分配置信水平。在此基础上，我们引入了一个概率安全保障框架，该框架将SafeML与贝叶斯网络（BNs）集成，将ML故障建模为更广泛的因果安全分析的一部分。这允许在不确定性下进行动态安全评估和系统适应。我们在一个模拟的具有交通标志识别功能的汽车队列系统中演示了该方法。研究结果强调了在安全评估中明确建模ML故障的潜在更广泛的好处。", "summary": "本文提出了一个将SafeML与贝叶斯网络相结合的概率安全保障框架，旨在解决机器学习模型在安全关键系统中因分布偏移导致的推理故障问题。该框架能够动态检测ML推理的置信度，并将ML故障整合到更广泛的因果安全分析中，从而在不确定性下实现动态安全评估和系统适应。通过在模拟汽车队列系统中的演示，研究突出了明确建模ML故障在安全评估中的重要性。", "keywords": "机器学习故障, 概率安全保障, 贝叶斯网络, SafeML, 分布偏移", "comments": "本文提出了一种新颖的方法，通过将SafeML与贝叶斯网络相结合，将机器学习的固有故障（特别是由于数据分布偏移引起的推理故障）整合到概率安全评估中。这种动态的、基于模型的故障处理方式对于提升集成ML的安全关键系统的可靠性至关重要，弥补了传统安全评估方法的不足。其创新性在于将ML特有的不确定性纳入到系统级的因果安全分析中，为实际应用提供了更鲁棒的评估工具。"}}
{"id": "2506.07661", "title": "The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well", "authors": ["Meir Feder", "Ruediger Urbanke", "Yaniv Fogel"], "summary": "A fundamental question in modern machine learning is why large,\nover-parameterized models, such as deep neural networks and transformers, tend\nto generalize well, even when their number of parameters far exceeds the number\nof training samples.\n  We investigate this phenomenon through the lens of information theory,\ngrounded in universal learning theory. Specifically, we study a Bayesian\nmixture learner with log-loss and (almost) uniform prior over an expansive\nhypothesis class.\n  Our key result shows that the learner's regret is not determined by the\noverall size of the hypothesis class, but rather by the cumulative probability\nof all models that are close, in Kullback-Leibler divergence distance, to the\ntrue data-generating process. We refer to this cumulative probability as the\nweight of the hypothesis.\n  This leads to a natural notion of model simplicity: simple models are those\nwith large weight and thus require fewer samples to generalize, while complex\nmodels have small weight and need more data. This perspective provides a\nrigorous and intuitive explanation for why over-parameterized models often\navoid overfitting: the presence of simple hypotheses allows the posterior to\nconcentrate on them when supported by the data.\n  We further bridge theory and practice by recalling that stochastic gradient\ndescent with Langevin dynamics samples from the correct posterior distribution,\nenabling our theoretical learner to be approximated using standard machine\nlearning methods combined with ensemble learning.\n  Our analysis yields non-uniform regret bounds and aligns with key practical\nconcepts such as flat minima and model distillation. The results apply broadly\nacross online, batch, and supervised learning settings, offering a unified and\nprincipled understanding of the generalization behavior of modern AI systems.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07661v1", "AI": {"title_translation": "普适性视角：为什么即使是高度过参数化的模型也能很好地学习", "tldr": "该研究通过信息论视角解释了为什么过度参数化模型能够很好地泛化：学习器的遗憾不取决于假设类的整体大小，而是取决于与真实数据生成过程接近的模型的累积概率（即“权重”）。这一概念解释了过参数化模型中简单假设的存在如何避免过拟合。", "motivation": "现代机器学习中的一个基本问题是，为什么像深度神经网络和Transformer这样的大型、过参数化模型，即使其参数数量远超训练样本，也倾向于很好地泛化。", "method": "该研究通过信息论的视角，以普适学习理论为基础进行探究。具体研究了一个具有对数损失和（几乎）均匀先验的贝叶斯混合学习器在广阔假设类上的表现。此外，还通过Langevin动力学的随机梯度下降与理论学习器进行连接，以弥合理论与实践。", "result": "研究发现，学习器的遗憾不取决于假设类的整体大小，而是由所有在Kullback-Leibler散度距离上接近真实数据生成过程的模型的累积概率（称为假设的“权重”）决定。这引出了模型简单性的概念：简单模型权重高，需要更少样本泛化；复杂模型权重低，需要更多数据。分析产生了非均匀遗憾界。", "conclusion": "过参数化模型之所以能够避免过拟合，是因为当数据支持时，简单假设的存在使得后验能够集中在它们上。该研究为现代AI系统的泛化行为提供了统一和原则性的理解，并与平坦极小值和模型蒸馏等实践概念相吻合。这些结果广泛适用于在线、批量和监督学习设置。", "translation": "现代机器学习中的一个基本问题是，为什么大型的、过参数化的模型，例如深度神经网络和Transformer，即使它们的参数数量远远超过训练样本数量，也倾向于很好地泛化。\n我们通过信息论的视角，以普适学习理论为基础，研究了这一现象。具体来说，我们研究了一个在广阔假设类上具有对数损失和（几乎）均匀先验的贝叶斯混合学习器。\n我们的关键结果表明，学习器的遗憾不取决于假设类的整体大小，而是取决于所有在Kullback-Leibler散度距离上接近真实数据生成过程的模型的累积概率。我们将这种累积概率称为假设的权重。\n这引出了模型简单性的一个自然概念：简单模型是那些具有大权重因此需要更少样本来泛化的模型，而复杂模型具有小权重因此需要更多数据。这种观点为过参数化模型为何经常避免过拟合提供了严谨而直观的解释：当数据支持时，简单假设的存在使得后验能够集中在它们上。\n我们通过回顾带有Langevin动力学的随机梯度下降从正确的后验分布中采样，进一步弥合了理论与实践之间的鸿沟，使得我们的理论学习器可以通过结合集成学习的标准机器学习方法来近似。\n我们的分析产生了非均匀遗憾界，并与平坦极小值和模型蒸馏等关键实践概念相吻合。这些结果广泛适用于在线、批量和监督学习设置，为现代AI系统的泛化行为提供了统一和原则性的理解。", "summary": "该论文通过信息论和普适学习理论，探讨了过度参数化模型泛化能力强的深层原因。研究表明，贝叶斯学习器的遗憾并非由假设类的总大小决定，而是取决于与真实数据生成过程接近的模型的累积概率（即“权重”）。这一发现解释了大型模型中简单假设的存在如何有效避免过拟合，并与平坦极小值等实际现象相符。此外，理论学习器可通过结合集成学习的标准机器学习方法进行近似，为理解现代AI系统的泛化行为提供了统一且原则性的视角。", "keywords": "过参数化, 泛化, 信息论, 贝叶斯学习, 模型简单性", "comments": "该论文为过度参数化模型的泛化能力提供了一个新颖的信息论视角，超越了传统的复杂性度量。引入“假设权重”的概念，为大型模型为何仍能找到简单解并避免过拟合提供了直观且严格的解释，有效连接了理论理解与平坦极小值和模型蒸馏等实际现象。其在不同学习设置下的广泛适用性也增强了其重要性。"}}
{"id": "2506.06482", "title": "TimeRecipe: A Time-Series Forecasting Recipe via Benchmarking Module Level Effectiveness", "authors": ["Zhiyuan Zhao", "Juntong Ni", "Shangqing Xu", "Haoxin Liu", "Wei Jin", "B. Aditya Prakash"], "summary": "Time-series forecasting is an essential task with wide real-world\napplications across domains. While recent advances in deep learning have\nenabled time-series forecasting models with accurate predictions, there remains\nconsiderable debate over which architectures and design components, such as\nseries decomposition or normalization, are most effective under varying\nconditions. Existing benchmarks primarily evaluate models at a high level,\noffering limited insight into why certain designs work better. To mitigate this\ngap, we propose TimeRecipe, a unified benchmarking framework that\nsystematically evaluates time-series forecasting methods at the module level.\nTimeRecipe conducts over 10,000 experiments to assess the effectiveness of\nindividual components across a diverse range of datasets, forecasting horizons,\nand task settings. Our results reveal that exhaustive exploration of the design\nspace can yield models that outperform existing state-of-the-art methods and\nuncover meaningful intuitions linking specific design choices to forecasting\nscenarios. Furthermore, we release a practical toolkit within TimeRecipe that\nrecommends suitable model architectures based on these empirical insights. The\nbenchmark is available at: https://github.com/AdityaLab/TimeRecipe.", "comment": "46 pages, 1 figure, 28 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06482v1", "AI": {"title_translation": "TimeRecipe：一种通过基准测试模块级有效性的时间序列预测方法", "tldr": "TimeRecipe是一个统一的基准测试框架，通过模块级评估揭示了时间序列预测模型组件的有效性，其结果表明通过探索设计空间可以超越现有SOTA模型并提供设计选择与预测场景的直观联系，并发布了推荐工具包。", "motivation": "现有的时间序列预测模型基准测试主要在高层次进行评估，未能深入揭示不同架构和设计组件（如序列分解或归一化）在不同条件下最有效的原因，导致对特定设计为何更优的理解有限。", "method": "提出了TimeRecipe，一个统一的基准测试框架，用于在模块级别系统地评估时间序列预测方法。该框架进行了超过10,000次实验，以评估单个组件在各种数据集、预测范围和任务设置下的有效性。", "result": "结果显示，对设计空间进行详尽探索可以产生超越现有最先进方法（SOTA）的模型，并揭示将特定设计选择与预测场景联系起来的有意义的直觉。此外，TimeRecipe发布了一个实用工具包，根据这些经验洞察推荐合适的模型架构。", "conclusion": "通过对时间序列预测模型组件进行模块级基准测试，可以发现更优的模型设计，并为特定预测场景提供有价值的设计选择指导。", "translation": "时间序列预测是一项重要的任务，在各个领域都有广泛的实际应用。尽管深度学习的最新进展使时间序列预测模型能够实现准确的预测，但关于哪些架构和设计组件（例如序列分解或归一化）在不同条件下最有效仍然存在相当大的争议。现有基准主要在高层次评估模型，对某些设计为何效果更好提供的见解有限。为了弥补这一差距，我们提出了TimeRecipe，一个统一的基准测试框架，系统地在模块级别评估时间序列预测方法。TimeRecipe进行了超过10,000次实验，以评估单个组件在各种数据集、预测范围和任务设置下的有效性。我们的结果表明，对设计空间进行详尽探索可以产生超越现有最先进方法（SOTA）的模型，并揭示将特定设计选择与预测场景联系起来的有意义的直觉。此外，我们在TimeRecipe中发布了一个实用工具包，根据这些经验洞察推荐合适的模型架构。该基准可在https://github.com/AdityaLab/TimeRecipe获取。", "summary": "TimeRecipe是一个新颖的统一基准测试框架，旨在解决时间序列预测领域中对模型架构和组件有效性缺乏深入理解的问题。它通过在模块级别进行超过10,000次实验，系统评估了不同组件在多样化条件下的表现。研究结果表明，彻底探索设计空间可以发现超越现有SOTA的模型，并提供了关于设计选择与预测场景之间关系的直观见解。此外，TimeRecipe还提供了一个基于这些发现推荐模型架构的实用工具包。", "keywords": "时间序列预测, 基准测试, 模块级评估, 设计空间探索, 模型推荐", "comments": "这篇论文的创新点在于提出了一个统一的模块级基准测试框架TimeRecipe，而非传统的高层次模型评估。这种细粒度的分析有助于深入理解不同设计组件对时间序列预测性能的影响，从而指导更有效的模型构建。其重要性在于揭示了通过系统探索设计空间可以超越现有SOTA，并提供了实用的模型推荐工具包，对时间序列预测领域的模型开发和应用具有重要指导意义。"}}
{"id": "2506.07494", "title": "Towards Energy-Efficient and Low-Latency Voice-Controlled Smart Homes: A Proposal for Offline Speech Recognition and IoT Integration", "authors": ["Peng Huang", "Imdad Ullah", "Xiaotong Wei", "Tariq Ahamed Ahanger", "Najm Hassan", "Zawar Hussain Shah"], "summary": "The smart home systems, based on AI speech recognition and IoT technology,\nenable people to control devices through verbal commands and make people's\nlives more efficient. However, existing AI speech recognition services are\nprimarily deployed on cloud platforms on the Internet. When users issue a\ncommand, speech recognition devices like ``Amazon Echo'' will post a recording\nthrough numerous network nodes, reach multiple servers, and then receive\nresponses through the Internet. This mechanism presents several issues,\nincluding unnecessary energy consumption, communication latency, and the risk\nof a single-point failure. In this position paper, we propose a smart home\nconcept based on offline speech recognition and IoT technology: 1) integrating\noffline keyword spotting (KWS) technologies into household appliances with\nlimited resource hardware to enable them to understand user voice commands; 2)\ndesigning a local IoT network with decentralized architecture to manage and\nconnect various devices, enhancing the robustness and scalability of the\nsystem. This proposal of a smart home based on offline speech recognition and\nIoT technology will allow users to use low-latency voice control anywhere in\nthe home without depending on the Internet and provide better scalability and\nenergy sustainability.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07494v1", "AI": {"title_translation": "迈向节能低延迟的语音控制智能家居：离线语音识别与物联网集成的提案", "tldr": "现有智能家居语音控制系统依赖云端，存在能耗、延迟和单点故障问题。本文提出基于离线语音识别和本地IoT网络的智能家居方案，旨在实现低延迟、节能且鲁棒的语音控制。", "motivation": "现有智能家居AI语音识别服务主要部署在云平台，导致不必要的能耗、通信延迟和单点故障风险。", "method": "1) 将离线关键词识别(KWS)技术集成到资源有限的家用电器中，使其能理解语音命令；2) 设计一个去中心化架构的本地IoT网络来管理和连接设备。", "result": "该提案将使用户能够在家庭任何地方使用低延迟的语音控制，不依赖互联网，并提供更好的可扩展性和能源可持续性。", "conclusion": "通过结合离线语音识别和本地IoT网络，可以构建一个节能、低延迟、高鲁棒性和可扩展性的智能家居系统，摆脱对互联网的依赖。", "translation": "智能家居系统，基于AI语音识别和物联网技术，使人们能够通过语音命令控制设备，提高人们的生活效率。然而，现有的AI语音识别服务主要部署在互联网上的云平台。当用户发出命令时，像“Amazon Echo”这样的语音识别设备会通过众多网络节点发布录音，到达多个服务器，然后通过互联网接收响应。这种机制存在几个问题，包括不必要的能源消耗、通信延迟和单点故障的风险。在这篇立场论文中，我们提出了一种基于离线语音识别和物联网技术的智能家居概念：1) 将离线关键词识别（KWS）技术集成到资源有限的家用电器中，使其能够理解用户语音命令；2) 设计一个具有去中心化架构的本地物联网网络来管理和连接各种设备，增强系统的鲁棒性和可扩展性。这项基于离线语音识别和物联网技术的智能家居提案将使用户能够在家庭任何地方使用低延迟的语音控制，而无需依赖互联网，并提供更好的可扩展性和能源可持续性。", "summary": "本文提出一种旨在解决现有云端智能家居语音控制系统能耗高、延迟大及单点故障风险的方案。该方案核心在于将离线关键词识别技术植入本地设备，并构建去中心化的本地物联网网络，从而实现无需互联网依赖的低延迟、节能且高鲁棒性的智能家居语音控制。", "keywords": "智能家居, 离线语音识别, 物联网集成, 节能, 低延迟", "comments": "这篇立场论文的创新之处在于提出了一种完全离线的智能家居语音控制方案，解决了传统云端方案的痛点。其重要性在于提升了智能家居的隐私性、响应速度和能源效率。该提案为未来智能家居的发展提供了一个有前景的方向，特别是在对实时性和数据安全有高要求的场景下。"}}
{"id": "2506.07480", "title": "Explainable AI for Enhancing IDS Against Advanced Persistent Kill Chain", "authors": ["Bassam Noori Shaker", "Bahaa Al-Musawi", "Mohammed Falih Hassan"], "summary": "Advanced Persistent Threats (APTs) represent a sophisticated and persistent\ncy-bersecurity challenge, characterized by stealthy, multi-phase, and targeted\nattacks aimed at compromising information systems over an extended period.\nDevelop-ing an effective Intrusion Detection System (IDS) capable of detecting\nAPTs at different phases relies on selecting network traffic features. However,\nnot all of these features are directly related to the phases of APTs. Some\nnetwork traffic features may be unrelated or have limited relevance to\nidentifying malicious ac-tivity. Therefore, it is important to carefully select\nand analyze the most relevant features to improve the IDS performance. This\nwork proposes a feature selection and classification model that integrates two\nprominent machine learning algo-rithms: SHapley Additive exPlanations (SHAP)\nand Extreme Gradient Boosting (XGBoost). The aim is to develop lightweight IDS\nbased on a selected minimum number of influential features for detecting APTs\nat various phases. The pro-posed method also specifies the relevant features\nfor each phase of APTs inde-pendently. Extensive experimental results on the\nSCVIC-APT-2021 dataset indi-cated that our proposed approach has improved\nperformance compared to other standard techniques. Specifically, both the\nmacro-average F1-score and recall reached 94% and 93 %, respectively, while\nreducing the complexity of the detec-tion model by selecting only 12 features\nout of 77.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07480v1", "AI": {"title_translation": "可解释AI增强IDS对抗高级持续性杀伤链", "tldr": "本研究提出了一种结合SHAP和XGBoost的可解释人工智能（XAI）增强型入侵检测系统（IDS），用于检测高级持续性威胁（APT），通过精选少量关键特征，在SCVIC-APT-2021数据集上实现了高性能和模型轻量化。", "motivation": "高级持续性威胁（APT）是复杂且持续的网络安全挑战，其特点是隐蔽、多阶段和有针对性的攻击。开发有效的入侵检测系统（IDS）需要精确选择网络流量特征，但并非所有特征都与APT阶段直接相关，这限制了IDS的性能。因此，需要识别并分析最相关的特征以提升IDS的检测能力。", "method": "本研究提出了一种特征选择与分类模型，该模型集成了SHapley Additive exPlanations (SHAP) 和 Extreme Gradient Boosting (XGBoost) 两种机器学习算法。旨在通过选择最少数量的有影响力特征来开发轻量级IDS，以检测APT的各个阶段。该方法还独立地指定了APT每个阶段的相关特征。", "result": "在SCVIC-APT-2021数据集上进行了广泛实验，结果表明所提出的方法比其他标准技术性能有所提高。宏观平均F1分数达到94%，召回率达到93%。同时，通过从77个特征中仅选择12个特征，显著降低了检测模型的复杂性。", "conclusion": "本研究提出的结合SHAP和XGBoost的特征选择与分类模型，能够有效地增强IDS在APT检测方面的性能，通过识别并利用关键特征，实现了一个轻量级且高效的系统。", "translation": "高级持续性威胁（APT）代表着一种复杂且持续的网络安全挑战，其特点是隐蔽的、多阶段的、有针对性的攻击，旨在长期渗透信息系统。开发一种能够检测不同阶段APT的有效入侵检测系统（IDS）依赖于选择网络流量特征。然而，并非所有这些特征都与APT的阶段直接相关。一些网络流量特征可能不相关或与识别恶意活动的相关性有限。因此，仔细选择和分析最相关的特征以提高IDS性能至关重要。这项工作提出了一种特征选择和分类模型，该模型集成了两种著名的机器学习算法：SHapley Additive exPlanations (SHAP) 和 Extreme Gradient Boosting (XGBoost)。其目标是基于选定的最少数量的有影响力的特征来开发轻量级IDS，以检测各个阶段的APT。所提出的方法还独立地指定了APT每个阶段的相关特征。在SCVIC-APT-2021数据集上进行的广泛实验结果表明，我们提出的方法与其他标准技术相比，性能有所提高。具体而言，宏观平均F1分数和召回率分别达到94%和93%，同时通过从77个特征中仅选择12个特征，降低了检测模型的复杂性。", "summary": "本论文提出了一种利用可解释人工智能（XAI）增强的入侵检测系统（IDS），以有效对抗高级持续性威胁（APT）。该系统集成了SHAP进行特征选择和XGBoost进行分类，旨在通过识别并利用最少数量的关键网络流量特征来构建轻量级IDS。在SCVIC-APT-2021数据集上的实验结果表明，与现有技术相比，该方法在性能上有所提升，F1分数达到94%，召回率达到93%，同时将模型复杂性从77个特征显著降低至12个特征。", "keywords": "高级持续性威胁, 入侵检测系统, 可解释人工智能, 特征选择, XGBoost", "comments": "该研究通过结合SHAP和XGBoost，在IDS领域引入了可解释性，这对于网络安全威胁检测的透明度和决策支持至关重要。其创新点在于能够从大量特征中智能选择出极少数最具影响力的特征，从而构建了一个既高效又轻量级的检测模型。这一方法在降低模型复杂性的同时，保持甚至提升了检测性能，对于实际部署具有重要意义。"}}
{"id": "2506.07062", "title": "Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search", "authors": ["Dongryung Lee", "Sejune Joo", "Kimin Lee", "Beomjoon Kim"], "summary": "The problem of relocating a set of objects to designated areas amidst movable\nobstacles can be framed as a Geometric Task and Motion Planning (G-TAMP)\nproblem, a subclass of task and motion planning (TAMP). Traditional approaches\nto G-TAMP have relied either on domain-independent heuristics or on learning\nfrom planning experience to guide the search, both of which typically demand\nsignificant computational resources or data. In contrast, humans often use\ncommon sense to intuitively decide which objects to manipulate in G-TAMP\nproblems. Inspired by this, we propose leveraging Large Language Models (LLMs),\nwhich have common sense knowledge acquired from internet-scale data, to guide\ntask planning in G-TAMP problems. To enable LLMs to perform geometric\nreasoning, we design a predicate-based prompt that encodes geometric\ninformation derived from a motion planning algorithm. We then query the LLM to\ngenerate a task plan, which is then used to search for a feasible set of\ncontinuous parameters. Since LLMs are prone to mistakes, instead of committing\nto LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid action\nspace and use the LLM to guide the search. Unlike the previous approach that\ncalls an LLM at every node and incurs high computational costs, we use it to\nwarm-start the MCTS with the nodes explored in completing the LLM's task plan.\nOn six different G-TAMP problems, we show our method outperforms previous LLM\nplanners and pure search algorithms. Code can be found at:\nhttps://github.com/iMSquared/prime-the-search", "comment": "The International Journal of Robotics Research (IJRR)", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07062v1", "AI": {"title_translation": "启动搜索：使用大型语言模型通过热启动树搜索来指导几何任务和运动规划", "tldr": "本文提出了一种利用大型语言模型（LLM）的常识知识来指导几何任务和运动规划（G-TAMP）的方法，通过热启动蒙特卡洛树搜索（MCTS）来提高规划效率和性能。", "motivation": "传统的几何任务和运动规划（G-TAMP）方法依赖于领域无关启发式或从规划经验中学习，通常需要大量的计算资源或数据。与此不同，人类在解决G-TAMP问题时常凭直觉决定操作哪些物体。受此启发，本文旨在利用LLM的常识知识来指导G-TAMP中的任务规划。", "method": "本文设计了一种基于谓词的提示，该提示编码了从运动规划算法中提取的几何信息，以使LLM能够进行几何推理。LLM生成一个任务计划，然后用于搜索一组可行的连续参数。为了应对LLM可能出错的问题，本文扩展了蒙特卡洛树搜索（MCTS）到混合动作空间，并使用LLM来指导搜索，具体通过LLM任务计划中探索的节点来热启动MCTS，而不是在每个节点都调用LLM。", "result": "在六个不同的G-TAMP问题上，本文方法优于先前的LLM规划器和纯搜索算法。", "conclusion": "利用大型语言模型（LLM）的常识知识，通过热启动蒙特卡洛树搜索（MCTS）来指导几何任务和运动规划（G-TAMP），可以显著提高规划效率和性能，超越了以往的LLM规划器和纯搜索算法。", "translation": "将一组物体重新定位到指定区域，同时避开可移动障碍物的问题，可以被视为几何任务和运动规划（G-TAMP）问题，它是任务和运动规划（TAMP）的一个子类。传统的G-TAMP方法要么依赖于领域无关的启发式，要么依赖于从规划经验中学习来指导搜索，这两种方法通常都需要大量的计算资源或数据。相比之下，人类在G-TAMP问题中常常凭常识直觉决定操作哪些物体。受此启发，我们提出利用大型语言模型（LLM），它们从互联网规模的数据中获取了常识知识，来指导G-TAMP问题中的任务规划。为了使LLM能够进行几何推理，我们设计了一种基于谓词的提示，该提示编码了从运动规划算法中提取的几何信息。然后，我们查询LLM以生成一个任务计划，该计划随后用于搜索一组可行的连续参数。由于LLM容易出错，我们没有完全依赖LLM的输出，而是将蒙特卡洛树搜索（MCTS）扩展到混合动作空间，并使用LLM来指导搜索。与之前在每个节点都调用LLM并产生高计算成本的方法不同，我们使用LLM的任务计划中探索的节点来热启动MCTS。在六个不同的G-TAMP问题上，我们展示了我们的方法优于先前的LLM规划器和纯搜索算法。代码可在以下网址找到：https://github.com/iMSquared/prime-the-search", "summary": "本文提出了一种利用大型语言模型（LLM）的常识知识来指导几何任务和运动规划（G-TAMP）的新方法。针对传统方法计算成本高的问题，本文设计了一种基于谓词的提示，使LLM能够进行几何推理并生成任务计划。为了解决LLM可能出错的问题，本文将蒙特卡洛树搜索（MCTS）扩展到混合动作空间，并利用LLM生成的任务计划来热启动MCTS，从而避免了在每个节点都调用LLM的高成本。实验结果表明，该方法在六个不同的G-TAMP问题上优于以往的LLM规划器和纯搜索算法。", "keywords": "大型语言模型, 几何任务和运动规划, 蒙特卡洛树搜索, 热启动, 机器人规划", "comments": "这项工作创新性地将大型语言模型（LLM）的常识推理能力与传统的任务和运动规划（TAMP）相结合，尤其是在几何TAMP领域。通过将LLM作为热启动蒙特卡洛树搜索（MCTS）的引导机制，它有效地解决了LLM输出不确定性的问题，并显著降低了计算成本。这种结合常识知识和搜索算法的混合方法为解决复杂的机器人操作问题提供了一个有前景的方向。"}}
{"id": "2506.06802", "title": "Training-Free Identity Preservation in Stylized Image Generation Using Diffusion Models", "authors": ["Mohammad Ali Rezaei", "Helia Hajikazem", "Saeed Khanehgir", "Mahdi Javanmardi"], "summary": "While diffusion models have demonstrated remarkable generative capabilities,\nexisting style transfer techniques often struggle to maintain identity while\nachieving high-quality stylization. This limitation is particularly acute for\nimages where faces are small or exhibit significant camera-to-face distances,\nfrequently leading to inadequate identity preservation. To address this, we\nintroduce a novel, training-free framework for identity-preserved stylized\nimage synthesis using diffusion models. Key contributions include: (1) the\n\"Mosaic Restored Content Image\" technique, significantly enhancing identity\nretention, especially in complex scenes; and (2) a training-free content\nconsistency loss that enhances the preservation of fine-grained content details\nby directing more attention to the original image during stylization. Our\nexperiments reveal that the proposed approach substantially surpasses the\nbaseline model in concurrently maintaining high stylistic fidelity and robust\nidentity integrity, particularly under conditions of small facial regions or\nsignificant camera-to-face distances, all without necessitating model\nretraining or fine-tuning.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06802v1", "AI": {"title_translation": "使用扩散模型在风格化图像生成中实现免训练的身份保留", "tldr": "本文提出了一种免训练的框架，利用扩散模型在风格化图像生成中有效保留身份，即使在面部较小或相机距离较远的情况下也能实现高保真度。", "motivation": "现有的风格迁移技术在实现高质量风格化的同时，难以保持图像中的身份，尤其是在面部较小或相机与面部距离较远的情况下，经常导致身份保留不足。", "method": "我们引入了一种新颖的、免训练的身份保留风格化图像合成框架，该框架使用扩散模型。关键贡献包括：(1) “马赛克恢复内容图像”技术，显著增强了身份保留，特别是在复杂场景中；(2) 一种免训练的内容一致性损失，通过在风格化过程中更多地关注原始图像，增强了细粒度内容细节的保留。", "result": "我们的实验表明，所提出的方法在同时保持高风格保真度和鲁棒身份完整性方面，显著超越了基线模型，尤其是在面部区域较小或相机与面部距离较大的条件下，且无需模型再训练或微调。", "conclusion": "本文提出的免训练框架能有效解决扩散模型在风格化图像生成中身份保留的挑战，即使在面部较小或相机距离较远等复杂场景下，也能实现出色的身份保留和风格保真度。", "translation": "尽管扩散模型展示了卓越的生成能力，但现有的风格迁移技术在实现高质量风格化的同时，往往难以保持身份。这种局限性对于面部较小或相机与面部距离显著的图像尤为突出，经常导致身份保留不足。为了解决这个问题，我们引入了一种新颖的、免训练的框架，用于使用扩散模型进行身份保留的风格化图像合成。主要贡献包括：(1) “马赛克恢复内容图像”技术，显著增强了身份保留，特别是在复杂场景中；(2) 一种免训练的内容一致性损失，通过在风格化过程中更多地关注原始图像，增强了细粒度内容细节的保留。我们的实验表明，所提出的方法在同时保持高风格保真度和鲁棒身份完整性方面，显著超越了基线模型，尤其是在面部区域较小或相机与面部距离较大的条件下，所有这些都无需模型再训练或微调。", "summary": "本研究提出了一种创新的免训练框架，利用扩散模型进行身份保留的风格化图像生成。该框架通过引入“马赛克恢复内容图像”技术和免训练的内容一致性损失，有效解决了现有风格迁移技术在保持身份方面的不足，尤其是在处理面部区域较小或相机距离较远的图像时。实验证明，该方法在保持高风格保真度和鲁棒身份完整性方面显著优于基线模型，且无需额外的模型训练或微调。", "keywords": "扩散模型, 身份保留, 风格化图像生成, 免训练, 风格迁移", "comments": "该论文的创新之处在于提出了一个免训练的框架，解决了扩散模型在风格化图像生成中身份保留的难题，特别是在处理面部较小或相机距离较远等挑战性场景时。其“马赛克恢复内容图像”技术和免训练内容一致性损失是关键创新点，大大降低了实际应用中的计算成本和复杂性，具有重要的实用价值。"}}
{"id": "2506.06881", "title": "KnowCoder-V2: Deep Knowledge Analysis", "authors": ["Zixuan Li", "Wenxuan Liu", "Long Bai", "Chunmao Zhang", "Wei Li", "Fenghui Zhang", "Quanxin Jin", "Ruoyun He", "Zhuo Chen", "Zhilei Hu", "Fei Wang", "Bingbing Xu", "Xuhui Jiang", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "summary": "Deep knowledge analysis tasks always involve the systematic extraction and\nassociation of knowledge from large volumes of data, followed by logical\nreasoning to discover insights. However, to solve such complex tasks, existing\ndeep research frameworks face three major challenges: 1) They lack systematic\norganization and management of knowledge; 2) They operate purely online, making\nit inefficient for tasks that rely on shared and large-scale knowledge; 3) They\ncannot perform complex knowledge computation, limiting their abilities to\nproduce insightful analytical results. Motivated by these, in this paper, we\npropose a \\textbf{K}nowledgeable \\textbf{D}eep \\textbf{R}esearch (\\textbf{KDR})\nframework that empowers deep research with deep knowledge analysis capability.\nSpecifically, it introduces an independent knowledge organization phase to\npreprocess large-scale, domain-relevant data into systematic knowledge offline.\nBased on this knowledge, it extends deep research with an additional kind of\nreasoning steps that perform complex knowledge computation in an online manner.\nTo enhance the abilities of LLMs to solve knowledge analysis tasks in the above\nframework, we further introduce \\textbf{\\KCII}, an LLM that bridges knowledge\norganization and reasoning via unified code generation. For knowledge\norganization, it generates instantiation code for predefined classes,\ntransforming data into knowledge objects. For knowledge computation, it\ngenerates analysis code and executes on the above knowledge objects to obtain\ndeep analysis results. Experimental results on more than thirty datasets across\nsix knowledge analysis tasks demonstrate the effectiveness of \\KCII. Moreover,\nwhen integrated into the KDR framework, \\KCII can generate high-quality reports\nwith insightful analytical results compared to the mainstream deep research\nframework.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06881v1", "AI": {"title_translation": "KnowCoder-V2: 深度知识分析", "tldr": "本文提出了KDR框架和KnowCoder-V2 (KCII) LLM，通过离线知识组织和在线知识计算，有效解决了现有深度知识分析框架在知识管理、效率和复杂计算方面的挑战。", "motivation": "现有深度研究框架在解决复杂深度知识分析任务时面临三大挑战：1) 缺乏系统知识组织和管理；2) 纯在线操作，对共享和大规模知识效率低下；3) 无法执行复杂知识计算，限制了产生有洞察力分析结果的能力。", "method": "提出了一种知识深度研究 (KDR) 框架，该框架引入独立的知识组织阶段，将大规模数据离线预处理为系统知识。在此基础上，扩展了深度研究，增加了在线执行复杂知识计算的推理步骤。为增强LLM解决知识分析任务的能力，引入了KnowCoder-V2 (KCII)，一个通过统一代码生成连接知识组织和推理的LLM。KCII为知识组织生成实例化代码将数据转换为知识对象，为知识计算生成分析代码并在知识对象上执行。", "result": "在六项知识分析任务的三十多个数据集上的实验结果表明KCII是有效的。此外，当集成到KDR框架中时，与主流深度研究框架相比，KCII能够生成具有洞察力分析结果的高质量报告。", "conclusion": "Not mentioned in abstract.", "translation": "深度知识分析任务总是涉及从大量数据中系统地提取和关联知识，然后进行逻辑推理以发现洞察。然而，为了解决此类复杂任务，现有的深度研究框架面临三大主要挑战：1) 它们缺乏系统的知识组织和管理；2) 它们纯粹在线操作，对于依赖共享和大规模知识的任务来说效率低下；3) 它们无法执行复杂的知识计算，限制了它们产生有洞察力分析结果的能力。受这些挑战的启发，在本文中，我们提出了一个**知识深度研究 (KDR)** 框架，该框架赋予深度研究深度知识分析能力。具体来说，它引入了一个独立的知识组织阶段，将大规模、领域相关的数据离线预处理为系统知识。基于这些知识，它扩展了深度研究，增加了另一种推理步骤，以在线方式执行复杂的知识计算。为了增强大型语言模型 (LLMs) 在上述框架中解决知识分析任务的能力，我们进一步引入了**\\KCII**，一个通过统一代码生成连接知识组织和推理的LLM。对于知识组织，它生成预定义类的实例化代码，将数据转换为知识对象。对于知识计算，它生成分析代码并在上述知识对象上执行以获得深度分析结果。在六项知识分析任务的三十多个数据集上的实验结果证明了\\KCII的有效性。此外，当集成到KDR框架中时，与主流深度研究框架相比，\\KCII能够生成具有洞察力分析结果的高质量报告。", "summary": "本文提出了一个名为知识深度研究 (KDR) 的框架，旨在解决现有深度知识分析框架在知识组织、大规模知识处理效率和复杂知识计算方面的不足。KDR框架通过离线知识组织和在线知识计算实现深度知识分析能力。为增强框架内大型语言模型的能力，研究者引入了KnowCoder-V2 (KCII)，一个利用统一代码生成技术连接知识组织和推理的LLM。KCII通过生成实例化代码将数据转化为知识对象，并生成分析代码对这些对象进行复杂计算。实验结果表明，KCII在多项知识分析任务中表现出有效性，并且在KDR框架中能生成高质量的分析报告。", "keywords": "深度知识分析, KDR框架, KnowCoder-V2, 大型语言模型, 代码生成", "comments": "这篇论文的创新点在于提出了一个分阶段的深度知识分析框架KDR，并引入了KnowCoder-V2 (KCII) 这一新型LLM来桥接知识组织和计算。通过统一代码生成的方式，KCII能够将数据转化为结构化知识对象并进行复杂的分析，有效克服了传统LLM在处理大规模、系统性知识分析任务中的局限性。其离线知识组织和在线知识计算的结合，提高了处理效率和分析深度。"}}
{"id": "2506.07805", "title": "Generalization Analysis for Bayesian Optimal Experiment Design under Model Misspecification", "authors": ["Roubing Tang", "Sabina J. Sloman", "Samuel Kaski"], "summary": "In many settings in science and industry, such as drug discovery and clinical\ntrials, a central challenge is designing experiments under time and budget\nconstraints. Bayesian Optimal Experimental Design (BOED) is a paradigm to pick\nmaximally informative designs that has been increasingly applied to such\nproblems. During training, BOED selects inputs according to a pre-determined\nacquisition criterion. During testing, the model learned during training\nencounters a naturally occurring distribution of test samples. This leads to an\ninstance of covariate shift, where the train and test samples are drawn from\ndifferent distributions. Prior work has shown that in the presence of model\nmisspecification, covariate shift amplifies generalization error. Our first\ncontribution is to provide a mathematical decomposition of generalization error\nthat reveals key contributors to generalization error in the presence of model\nmisspecification. We show that generalization error under misspecification is\nthe result of, in addition to covariate shift, a phenomenon we term error\n(de-)amplification which has not been identified or studied in prior work. Our\nsecond contribution is to provide a detailed empirical analysis to show that\nmethods that result in representative and de-amplifying training data increase\ngeneralization performance. Our third contribution is to develop a novel\nacquisition function that mitigates the effects of model misspecification by\nincluding a term for representativeness and implicitly inducing\nde-amplification. Our experimental results demonstrate that our method\noutperforms traditional BOED in the presence of misspecification.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07805v1", "AI": {"title_translation": "模型误设下贝叶斯最优实验设计的泛化分析", "tldr": "本文对模型误设下贝叶斯最优实验设计的泛化误差进行了分析，并提出了一种新的采集函数以提高泛化性能。", "motivation": "在科学和工业（如药物发现和临床试验）中，受时间和预算限制的实验设计是一个核心挑战。贝叶斯最优实验设计（BOED）被越来越多地应用于此类问题。然而，在训练过程中，BOED选择的输入与测试样本的自然分布之间存在协变量漂移，且现有工作表明在模型误设的情况下，协变量漂移会放大泛化误差。", "method": "本文首先提供了泛化误差的数学分解，揭示了模型误设情况下泛化误差的关键因素，并识别了一种新的现象——误差（去）放大。其次，进行了详细的实证分析，以证明能产生代表性和去放大训练数据的方法可以提高泛化性能。最后，开发了一种新颖的采集函数，通过包含代表性项并隐式地诱导去放大来减轻模型误设的影响。", "result": "研究表明，在模型误设下，泛化误差除了协变量漂移外，还是误差（去）放大现象的结果。实证分析表明，产生代表性和去放大训练数据的方法能提高泛化性能。实验结果证明，所提出的方法在存在模型误设的情况下优于传统的BOED。", "conclusion": "本文通过对泛化误差的分解和引入新的采集函数，有效地解决了模型误设下贝叶斯最优实验设计的泛化性能问题，并证明了其优越性。", "translation": "在科学和工业中的许多场景，例如药物发现和临床试验，一个核心挑战是在时间和预算限制下设计实验。贝叶斯最优实验设计（BOED）是一种选择信息量最大设计的范式，并已越来越多地应用于此类问题。在训练期间，BOED根据预定的采集标准选择输入。在测试期间，训练期间学习到的模型会遇到自然发生的测试样本分布。这导致了一个协变量漂移的实例，即训练和测试样本来自不同的分布。先前的研究表明，在模型误设的情况下，协变量漂移会放大泛化误差。我们的第一个贡献是提供了泛化误差的数学分解，揭示了在模型误设情况下泛化误差的关键因素。我们表明，在误设下的泛化误差是除了协变量漂移之外，还是一种我们称之为误差（去）放大的现象的结果，这种现象在先前的研究中尚未被识别或研究。我们的第二个贡献是提供了详细的实证分析，以表明产生代表性和去放大训练数据的方法可以提高泛化性能。我们的第三个贡献是开发了一种新颖的采集函数，通过包含一个代表性项并隐式地诱导去放大来减轻模型误设的影响。我们的实验结果表明，我们的方法在存在误设的情况下优于传统的BOED。", "summary": "本文研究了模型误设下贝叶斯最优实验设计（BOED）的泛化性能问题。作者首先对泛化误差进行了数学分解，揭示了除了协变量漂移外，还存在一种新的“误差（去）放大”现象。随后，通过实证分析证明了具有代表性和去放大特性的训练数据能提高泛化性能。最后，提出了一种新的采集函数，通过引入代表性项和隐式诱导去放大来缓解模型误设的影响，实验证明该方法优于传统BOED。", "keywords": "贝叶斯最优实验设计, 模型误设, 泛化误差, 协变量漂移, 误差（去）放大", "comments": "本文的创新点在于对模型误设下泛化误差的深入分解，特别是识别并命名了“误差（去）放大”这一新现象。此外，通过开发一种考虑代表性和去放大特性的新型采集函数，有效地提高了BOED在实际应用中面对模型误设时的泛化性能，具有重要的理论和实践意义。"}}
{"id": "2506.06486", "title": "A Certified Unlearning Approach without Access to Source Data", "authors": ["Umit Yigit Basaran", "Sk Miraj Ahmed", "Amit Roy-Chowdhury", "Basak Guler"], "summary": "With the growing adoption of data privacy regulations, the ability to erase\nprivate or copyrighted information from trained models has become a crucial\nrequirement. Traditional unlearning methods often assume access to the complete\ntraining dataset, which is unrealistic in scenarios where the source data is no\nlonger available. To address this challenge, we propose a certified unlearning\nframework that enables effective data removal \\final{without access to the\noriginal training data samples}. Our approach utilizes a surrogate dataset that\napproximates the statistical properties of the source data, allowing for\ncontrolled noise scaling based on the statistical distance between the two.\n\\updated{While our theoretical guarantees assume knowledge of the exact\nstatistical distance, practical implementations typically approximate this\ndistance, resulting in potentially weaker but still meaningful privacy\nguarantees.} This ensures strong guarantees on the model's behavior\npost-unlearning while maintaining its overall utility. We establish theoretical\nbounds, introduce practical noise calibration techniques, and validate our\nmethod through extensive experiments on both synthetic and real-world datasets.\nThe results demonstrate the effectiveness and reliability of our approach in\nprivacy-sensitive settings.", "comment": "Accepted by ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06486v1", "AI": {"title_translation": "无需访问源数据的认证遗忘方法", "tldr": "提出了一种无需访问原始训练数据即可实现数据遗忘的认证方法，通过代理数据集和统计距离实现。", "motivation": "随着数据隐私法规的日益普及，从训练模型中擦除私人或受版权保护信息的能力变得至关重要。传统的遗忘方法通常假设可以访问完整的训练数据集，这在源数据不再可用的情况下是不现实的。", "method": "提出了一种认证遗忘框架，无需访问原始训练数据样本即可实现有效数据删除。该方法利用一个近似源数据统计特性的代理数据集，并根据两者之间的统计距离进行受控噪声缩放。同时建立了理论界限，并引入了实用的噪声校准技术。", "result": "结果表明，该方法在隐私敏感设置中是有效且可靠的。", "conclusion": "该研究提出了一种无需访问源数据的认证遗忘方法，通过使用代理数据集和统计距离进行噪声缩放，成功实现了数据遗忘，并在隐私敏感环境中表现出有效性和可靠性。", "translation": "随着数据隐私法规的日益普及，从训练模型中擦除私人或受版权保护信息的能力已成为一项关键要求。传统的遗忘方法通常假设可以访问完整的训练数据集，这在源数据不再可用的情况下是不现实的。为了解决这一挑战，我们提出了一种认证遗忘框架，该框架无需访问原始训练数据样本即可实现有效数据删除。我们的方法利用一个近似源数据统计特性的代理数据集，并允许根据两者之间的统计距离进行受控噪声缩放。虽然我们的理论保证假设已知精确的统计距离，但实际实现通常会近似此距离，这可能导致隐私保证较弱但仍有意义。这确保了模型在遗忘后的行为具有强大的保证，同时保持其整体效用。我们建立了理论界限，引入了实用的噪声校准技术，并通过在合成和真实世界数据集上的大量实验验证了我们的方法。结果表明，我们的方法在隐私敏感设置中是有效且可靠的。", "summary": "本研究提出了一种无需访问原始训练数据即可进行认证遗忘的新方法。该方法通过构建一个近似源数据统计特性的代理数据集，并基于代理数据集与源数据之间的统计距离进行受控噪声缩放，从而实现有效的数据删除。该方法在理论上建立了界限，并引入了噪声校准技术，实验证明其在隐私敏感场景中的有效性和可靠性。", "keywords": "认证遗忘, 数据隐私, 代理数据集, 噪声缩放, 统计距离", "comments": "该论文的关键创新在于无需访问原始训练数据即可实现认证遗忘，这解决了传统方法在实际应用中面临的重大挑战。通过引入代理数据集和基于统计距离的噪声缩放，该方法在保证模型效用的同时，提供了强大的隐私保护。文中也坦诚了实际操作中统计距离近似可能导致隐私保证减弱的局限性，增加了研究的严谨性。"}}
{"id": "2506.07586", "title": "MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity", "authors": ["Bikash Saha", "Sandeep Kumar Shukla"], "summary": "The dual use nature of Large Language Models (LLMs) presents a growing\nchallenge in cybersecurity. While LLM enhances automation and reasoning for\ndefenders, they also introduce new risks, particularly their potential to be\nmisused for generating evasive, AI crafted malware. Despite this emerging\nthreat, the research community currently lacks controlled and extensible tools\nthat can simulate such behavior for testing and defense preparation. We present\nMalGEN, a multi agent framework that simulates coordinated adversarial behavior\nto generate diverse, activity driven malware samples. The agents work\ncollaboratively to emulate attacker workflows, including payload planning,\ncapability selection, and evasion strategies, within a controlled environment\nbuilt for ethical and defensive research. Using MalGEN, we synthesized ten\nnovel malware samples and evaluated them against leading antivirus and\nbehavioral detection engines. Several samples exhibited stealthy and evasive\ncharacteristics that bypassed current defenses, validating MalGEN's ability to\nmodel sophisticated and new threats. By transforming the threat of LLM misuse\ninto an opportunity for proactive defense, MalGEN offers a valuable framework\nfor evaluating and strengthening cybersecurity systems. The framework addresses\ndata scarcity, enables rigorous testing, and supports the development of\nresilient and future ready detection strategies.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07586v1", "AI": {"title_translation": "MalGEN：网络安全中恶意软件建模的生成式智能体框架", "tldr": "MalGEN是一个多智能体框架，用于模拟对抗性行为以生成规避性恶意软件样本，帮助评估和加强网络安全防御系统。", "motivation": "大型语言模型（LLMs）的双重用途对网络安全构成日益增长的挑战，它们可能被滥用生成规避性、AI制作的恶意软件。然而，研究社区目前缺乏受控且可扩展的工具来模拟这种行为，以进行测试和防御准备。", "method": "本文提出了MalGEN，一个多智能体框架，它通过模拟协调的对抗性行为来生成多样化、活动驱动的恶意软件样本。该框架中的智能体协同工作，在受控环境中模拟攻击者工作流程，包括载荷规划、能力选择和规避策略。研究人员使用MalGEN合成了十个新型恶意软件样本，并针对领先的防病毒和行为检测引擎进行了评估。", "result": "多个样本表现出隐蔽和规避特性，成功绕过了当前的防御系统，验证了MalGEN建模复杂新威胁的能力。", "conclusion": "MalGEN将LLM滥用的威胁转化为主动防御的机会，提供了一个有价值的框架，用于评估和加强网络安全系统。该框架解决了数据稀缺问题，实现了严格的测试，并支持开发有弹性和面向未来的检测策略。", "translation": "大型语言模型（LLMs）的双重用途在网络安全领域提出了日益严峻的挑战。虽然LLM增强了防御者的自动化和推理能力，但它们也带来了新的风险，特别是它们可能被滥用以生成规避性、AI制作的恶意软件。尽管存在这种新兴威胁，但研究社区目前缺乏受控且可扩展的工具来模拟此类行为，以进行测试和防御准备。我们提出了MalGEN，一个多智能体框架，它模拟协调的对抗性行为，以生成多样化、活动驱动的恶意软件样本。这些智能体在为道德和防御性研究而构建的受控环境中协同工作，模拟攻击者工作流程，包括载荷规划、能力选择和规避策略。使用MalGEN，我们合成了十个新型恶意软件样本，并针对领先的防病毒和行为检测引擎进行了评估。多个样本表现出隐蔽和规避特性，成功绕过了当前的防御系统，验证了MalGEN建模复杂新威胁的能力。通过将LLM滥用的威胁转化为主动防御的机会，MalGEN提供了一个有价值的框架，用于评估和加强网络安全系统。该框架解决了数据稀缺问题，实现了严格的测试，并支持开发有弹性和面向未来的检测策略。", "summary": "该研究提出了MalGEN，一个多智能体框架，旨在模拟并生成由大型语言模型（LLMs）驱动的规避性恶意软件样本。鉴于LLMs在网络安全中潜在的滥用风险以及当前缺乏模拟此类威胁的工具，MalGEN通过模拟攻击者工作流程来合成多样化的恶意软件。实验结果表明，MalGEN生成的样本能够绕过现有防御系统，验证了其建模复杂威胁的能力。MalGEN为网络安全系统提供了一个评估和强化的工具，有助于解决数据稀缺问题并支持未来检测策略的开发。", "keywords": "大型语言模型, 网络安全, 恶意软件, 生成式智能体, MalGEN", "comments": "MalGEN的创新之处在于其将LLM滥用风险转化为主动防御机会的理念，通过多智能体框架模拟AI驱动的恶意软件生成，这在当前研究中是一个重要的空白。它为网络安全研究人员提供了一个道德且受控的环境来合成和测试新型威胁，对于提升防御能力、解决数据稀缺以及开发面向未来的检测策略具有重要意义。"}}
{"id": "2506.07127", "title": "Robotic Policy Learning via Human-assisted Action Preference Optimization", "authors": ["Wenke xia", "Yichu Yang", "Hongtao Wu", "Xiao Ma", "Tao Kong", "Di Hu"], "summary": "Establishing a reliable and iteratively refined robotic system is essential\nfor deploying real-world applications. While Vision-Language-Action (VLA)\nmodels are widely recognized as the foundation model for such robotic\ndeployment, their dependence on expert demonstrations hinders the crucial\ncapabilities of correction and learning from failures. To mitigate this\nlimitation, we introduce a Human-assisted Action Preference Optimization method\nnamed HAPO, designed to correct deployment failures and foster effective\nadaptation through preference alignment for VLA models. This method begins with\na human-robot collaboration framework for reliable failure correction and\ninteraction trajectory collection through human intervention. These\nhuman-intervention trajectories are further employed within the action\npreference optimization process, facilitating VLA models to mitigate failure\naction occurrences while enhancing corrective action adaptation. Specifically,\nwe propose an adaptive reweighting algorithm to address the issues of\nirreversible interactions and token probability mismatch when introducing\npreference optimization into VLA models, facilitating model learning from\nbinary desirability signals derived from interactions. Through combining these\nmodules, our human-assisted action preference optimization method ensures\nreliable deployment and effective learning from failure for VLA models. The\nexperiments conducted in simulation and real-world scenarios prove superior\ngeneralization and robustness of our framework across a variety of manipulation\ntasks.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07127v1", "AI": {"title_translation": "机器人策略学习通过人机辅助动作偏好优化", "tldr": "本文提出HAPO方法，通过人机协作和动作偏好优化，使VLA模型能从失败中学习并纠正部署错误，实验证明其在多种操作任务中具有卓越的泛化性和鲁棒性。", "motivation": "现有的视觉-语言-动作（VLA）模型对专家演示的依赖，限制了机器人系统在实际部署中纠正错误和从失败中学习的关键能力。", "method": "本文引入了名为HAPO（人机辅助动作偏好优化）的方法。该方法通过人机协作框架收集失败纠正和交互轨迹，并将这些人工干预轨迹用于动作偏好优化过程，旨在减少失败动作的发生并增强纠正动作的适应性。具体地，为解决将偏好优化引入VLA模型时不可逆交互和token概率不匹配的问题，提出了一种自适应重加权算法，以促进模型从二元期望信号中学习。", "result": "在模拟和真实世界场景中进行的实验证明，该框架在各种操作任务中具有卓越的泛化性和鲁棒性。", "conclusion": "HAPO方法通过人机辅助动作偏好优化，确保了视觉-语言-动作（VLA）模型在实际部署中的可靠性以及从失败中有效学习的能力。", "translation": "建立一个可靠且可迭代改进的机器人系统对于部署现实世界应用至关重要。虽然视觉-语言-动作（VLA）模型被广泛认为是此类机器人部署的基础模型，但它们对专家演示的依赖阻碍了纠正和从失败中学习的关键能力。为了缓解这一限制，我们引入了一种名为HAPO的人机辅助动作偏好优化方法，旨在纠正部署失败并通过VLA模型的偏好对齐来促进有效适应。该方法首先通过人机协作框架，通过人工干预实现可靠的故障纠正和交互轨迹收集。这些人工干预轨迹进一步用于动作偏好优化过程，促进VLA模型减少失败动作的发生，同时增强纠正动作的适应性。具体而言，我们提出了一种自适应重加权算法，以解决将偏好优化引入VLA模型时不可逆交互和token概率不匹配的问题，从而促进模型从交互中获得的二元期望信号中学习。通过结合这些模块，我们的人机辅助动作偏好优化方法确保了VLA模型的可靠部署和从失败中有效学习。在模拟和真实世界场景中进行的实验证明了我们框架在各种操作任务中卓越的泛化性和鲁棒性。", "summary": "本文提出了一种名为HAPO（人机辅助动作偏好优化）的新方法，旨在解决视觉-语言-动作（VLA）模型在机器人部署中依赖专家演示导致无法纠正错误和从失败中学习的问题。HAPO通过人机协作框架收集失败纠正轨迹，并利用这些轨迹进行动作偏好优化，以减少失败动作并促进纠正性学习。该方法还引入了自适应重加权算法来处理偏好优化中的特定挑战。实验结果表明，HAPO显著提高了VLA模型在多种操作任务中的泛化性和鲁棒性，使其能够可靠部署并有效从错误中学习。", "keywords": "机器人策略学习, 人机辅助, 动作偏好优化, VLA模型, 失败学习", "comments": "这项工作通过引入人机协作和偏好优化，有效地解决了VLA模型在实际机器人部署中从失败中学习和自我纠正的关键挑战。其创新性在于将人类干预转化为可学习的偏好信号，并通过自适应重加权算法解决了VLA模型集成偏好学习时的技术障碍。这对于构建更鲁棒、适应性更强的机器人系统具有重要意义。"}}
{"id": "2506.06818", "title": "Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation", "authors": ["Chao Yin", "Hao Li", "Kequan Yang", "Jide Li", "Pinpin Zhu", "Xiaoqiang Li"], "summary": "While promptable segmentation (\\textit{e.g.}, SAM) has shown promise for\nvarious segmentation tasks, it still requires manual visual prompts for each\nobject to be segmented. In contrast, task-generic promptable segmentation aims\nto reduce the need for such detailed prompts by employing only a task-generic\nprompt to guide segmentation across all test samples. However, when applied to\nCamouflaged Object Segmentation (COS), current methods still face two critical\nissues: 1) \\textit{\\textbf{semantic ambiguity in getting instance-specific text\nprompts}}, which arises from insufficient discriminative cues in holistic\ncaptions, leading to foreground-background confusion; 2)\n\\textit{\\textbf{semantic discrepancy combined with spatial separation in\ngetting instance-specific visual prompts}}, which results from global\nbackground sampling far from object boundaries with low feature correlation,\ncausing SAM to segment irrelevant regions. To address the issues above, we\npropose \\textbf{RDVP-MSD}, a novel training-free test-time adaptation framework\nthat synergizes \\textbf{R}egion-constrained \\textbf{D}ual-stream\n\\textbf{V}isual \\textbf{P}rompting (RDVP) via \\textbf{M}ultimodal\n\\textbf{S}tepwise \\textbf{D}ecomposition Chain of Thought (MSD-CoT). MSD-CoT\nprogressively disentangles image captions to eliminate semantic ambiguity,\nwhile RDVP injects spatial constraints into visual prompting and independently\nsamples visual prompts for foreground and background points, effectively\nmitigating semantic discrepancy and spatial separation. Without requiring any\ntraining or supervision, RDVP-MSD achieves a state-of-the-art segmentation\nresult on multiple COS benchmarks and delivers a faster inference speed than\nprevious methods, demonstrating significantly improved accuracy and efficiency.\nThe codes will be available at\n\\href{https://github.com/ycyinchao/RDVP-MSD}{https://github.com/ycyinchao/RDVP-MSD}", "comment": "under review", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06818v1", "AI": {"title_translation": "逐步分解与双流聚焦：一种无训练伪装目标分割的新方法", "tldr": "本文提出了RDVP-MSD，一个无训练的伪装目标分割框架，通过解决提示中的语义模糊性和差异性，实现了最先进的性能。", "motivation": "现有可提示分割方法（如SAM），尤其是任务通用型，在伪装目标分割（COS）中面临两大问题：1）文本提示中语义模糊性，因整体描述缺乏判别性线索导致前景-背景混淆；2）视觉提示中语义差异与空间分离，因全局背景采样远离目标边界且特征相关性低。", "method": "本文提出了RDVP-MSD，一个新颖的无训练测试时自适应框架。它通过多模态逐步分解思维链（MSD-CoT）协同区域约束双流视觉提示（RDVP）。MSD-CoT逐步解开图像描述以消除语义模糊性，而RDVP将空间约束注入视觉提示中，并独立采样前景和背景点的视觉提示，有效缓解语义差异和空间分离。", "result": "RDVP-MSD在多个COS基准测试中取得了最先进的分割结果，并比以前的方法提供了更快的推理速度，显示出显著提高的准确性和效率，且无需任何训练或监督。", "conclusion": "RDVP-MSD通过解决与提示相关的问题，有效应对了伪装目标分割的挑战，在无需训练或监督的情况下实现了卓越的性能。", "translation": "虽然可提示分割（例如SAM）在各种分割任务中显示出前景，但它仍然需要为每个要分割的对象手动提供视觉提示。相比之下，任务通用可提示分割旨在通过仅使用任务通用提示来指导所有测试样本的分割，从而减少对此类详细提示的需求。然而，当应用于伪装目标分割（COS）时，当前方法仍然面临两个关键问题：1）在获取实例特定文本提示时存在语义模糊性，这源于整体描述中缺乏足够的判别性线索，导致前景-背景混淆；2）在获取实例特定视觉提示时存在语义差异与空间分离，这是由于远离对象边界的全局背景采样和低特征相关性导致的，使得SAM分割无关区域。为了解决上述问题，我们提出了RDVP-MSD，这是一种新颖的无训练测试时自适应框架，它通过多模态逐步分解思维链（MSD-CoT）协同区域约束双流视觉提示（RDVP）。MSD-CoT逐步解开图像描述以消除语义模糊性，而RDVP将空间约束注入视觉提示中，并独立采样前景和背景点的视觉提示，有效缓解语义差异和空间分离。RDVP-MSD无需任何训练或监督，在多个COS基准测试中取得了最先进的分割结果，并比以前的方法提供了更快的推理速度，显示出显著提高的准确性和效率。代码将可在https://github.com/ycyinchao/RDVP-MSD获取。", "summary": "本文提出了一种名为RDVP-MSD的新型无训练框架，用于伪装目标分割（COS）。该方法旨在解决现有可提示分割方法（如SAM）在处理伪装目标时面临的语义模糊性（文本提示）和语义差异/空间分离（视觉提示）问题。RDVP-MSD利用多模态逐步分解思维链（MSD-CoT）来消除文本描述中的语义模糊性，并通过区域约束双流视觉提示（RDVP）注入空间约束并独立采样前景和背景点，从而改进视觉提示。该方法在多个COS基准测试中无需任何训练或监督就取得了最先进的性能，并提供了更快的推理速度，显著提高了准确性和效率。", "keywords": "伪装目标分割, 无训练, 可提示分割, 逐步分解, 双流视觉提示", "comments": "本文提出了一种创新的无训练方法，直接解决了可提示分割模型（如SAM）在处理具有挑战性的伪装目标时的局限性。文本提示的逐步分解以及双流、区域约束的视觉提示是解决语义模糊性和空间分离等核心问题的巧妙方案。该方法在无需任何训练或监督的情况下即可达到SOTA结果，这突显了其在效率和适应性方面的显著优势。"}}
{"id": "2506.06905", "title": "Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering", "authors": ["Akash Gupta", "Amos Storkey", "Mirella Lapata"], "summary": "Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to\nperform new tasks with minimal supervision. However, ICL performance,\nespecially in smaller LMMs, is inconsistent and does not always improve\nmonotonically with increasing examples. We hypothesize that this occurs due to\nthe LMM being overwhelmed by additional information present in the image\nembeddings, which is not required for the downstream task. To address this, we\npropose a meta-learning approach that provides an alternative for inducing\nfew-shot capabilities in LMMs, using a fixed set of soft prompts that are\ndistilled from task-relevant image features and can be adapted at test time\nusing a few examples. To facilitate this distillation, we introduce an\nattention-mapper module that can be easily integrated with the popular LLaVA\nv1.5 architecture and is jointly learned with soft prompts, enabling task\nadaptation in LMMs under low-data regimes with just a few gradient steps.\nEvaluation on the VL-ICL Bench shows that our method consistently outperforms\nICL and related prompt-tuning approaches, even under image perturbations,\nimproving task induction and reasoning across visual question answering tasks.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06905v1", "AI": {"title_translation": "元适应性提示蒸馏用于少样本视觉问答", "tldr": "本文提出了一种元学习方法，通过蒸馏任务相关的图像特征生成可适应的软提示，以解决大型多模态模型（LMMs）在少样本视觉问答中上下文学习（ICL）表现不一致的问题，并在实验中表现优于现有方法。", "motivation": "大型多模态模型（LMMs）的上下文学习（ICL）性能不稳定，尤其是在小型LMMs中，并且不会随着示例的增加而单调提升。研究人员推测这是因为LMM被图像嵌入中与下游任务无关的额外信息所淹没。", "method": "本文提出了一种元学习方法，通过固定一组软提示来诱导LMM的少样本能力。这些软提示从任务相关的图像特征中蒸馏而来，并可在测试时通过少量示例进行适应。为了促进蒸馏，引入了一个注意力映射模块，该模块可轻松集成到流行的LLaVA v1.5架构中，并与软提示共同学习，从而在低数据条件下通过少量梯度步骤实现LMMs的任务适应。", "result": "在VL-ICL Bench上的评估表明，即使在图像扰动下，该方法也始终优于ICL和相关的提示调整方法，改进了视觉问答任务中的任务归纳和推理能力。", "conclusion": "本文提出的元适应性提示蒸馏方法有效解决了LMMs在少样本视觉问答中ICL表现不一致的问题，通过引入任务相关的软提示和注意力映射模块，显著提升了模型在低数据条件下的任务适应和推理能力。", "translation": "大型多模态模型（LMMs）通常依赖于上下文学习（ICL）来以最少的监督执行新任务。然而，ICL的性能，尤其是在较小的LMMs中，表现不一致，并且不会随着示例的增加而单调提升。我们推测这是因为LMM被图像嵌入中存在的额外信息所淹没，而这些信息对于下游任务来说并非必需。为了解决这个问题，我们提出了一种元学习方法，该方法通过一组固定的软提示为LMMs诱导少样本能力提供了一种替代方案，这些软提示从任务相关的图像特征中蒸馏而来，并且可以在测试时使用少量示例进行适应。为了促进这种蒸馏，我们引入了一个注意力映射模块，该模块可以很容易地与流行的LLaVA v1.5架构集成，并与软提示共同学习，从而在低数据条件下通过少量梯度步骤实现LMMs的任务适应。在VL-ICL Bench上的评估表明，我们的方法始终优于ICL和相关的提示调整方法，即使在图像扰动下也是如此，改进了视觉问答任务中的任务归纳和推理能力。", "summary": "本文提出了一种名为“元适应性提示蒸馏”的新方法，旨在解决大型多模态模型（LMMs）在少样本视觉问答中上下文学习（ICL）性能不稳定的问题。该方法通过元学习框架，从任务相关的图像特征中蒸馏出一组可适应的软提示，并引入了一个注意力映射模块，使其能够与LLaVA v1.5等现有架构无缝集成。实验结果表明，该方法在低数据条件下，通过少量梯度步骤即可实现高效的任务适应，并且在VL-ICL Bench上显著优于传统的ICL和提示调整方法，提升了视觉问答任务的归纳和推理能力。", "keywords": "元适应性, 提示蒸馏, 少样本学习, 视觉问答, 大型多模态模型", "comments": "该论文通过引入元学习和提示蒸馏，为解决LMMs在少样本场景下ICL性能不佳的问题提供了一个新颖且有效的途径。其创新点在于将任务相关的特征蒸馏为软提示，并通过注意力映射模块实现高效集成和适应。这对于提升LMMs在实际应用中的鲁棒性和效率具有重要意义，尤其是在数据稀缺的场景下。"}}
{"id": "2506.07861", "title": "Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective", "authors": ["Firas Laakom", "Haobo Chen", "Jürgen Schmidhuber", "Yuheng Bu"], "summary": "Despite substantial progress in promoting fairness in high-stake applications\nusing machine learning models, existing methods often modify the training\nprocess, such as through regularizers or other interventions, but lack formal\nguarantees that fairness achieved during training will generalize to unseen\ndata. Although overfitting with respect to prediction performance has been\nextensively studied, overfitting in terms of fairness loss has received far\nless attention. This paper proposes a theoretical framework for analyzing\nfairness generalization error through an information-theoretic lens. Our novel\nbounding technique is based on Efron-Stein inequality, which allows us to\nderive tight information-theoretic fairness generalization bounds with both\nMutual Information (MI) and Conditional Mutual Information (CMI). Our empirical\nresults validate the tightness and practical relevance of these bounds across\ndiverse fairness-aware learning algorithms. Our framework offers valuable\ninsights to guide the design of algorithms improving fairness generalization.", "comment": "38 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07861v1", "AI": {"title_translation": "机器学习中的公平性过拟合：一个信息论视角", "tldr": "本文提出了一个信息论框架来分析机器学习中的公平性泛化误差，并推导了基于互信息和条件互信息的紧密泛化界限，经验结果验证了其有效性。", "motivation": "现有机器学习公平性方法缺乏公平性在未见数据上泛化的形式保证，且相较于预测性能的过拟合，公平性损失的过拟合受关注较少。", "method": "本文提出了一个通过信息论视角分析公平性泛化误差的理论框架。其新颖的边界技术基于Efron-Stein不等式，推导出包含互信息（MI）和条件互信息（CMI）的紧密信息论公平性泛化界限。", "result": "经验结果验证了这些界限在不同公平性感知学习算法中的紧密性和实际相关性。", "conclusion": "本文的框架为指导设计改进公平性泛化的算法提供了宝贵的见解。", "translation": "尽管在利用机器学习模型促进高风险应用中的公平性方面取得了实质性进展，但现有方法通常修改训练过程，例如通过正则化器或其他干预措施，但缺乏公平性在训练期间实现的泛化到未见数据的形式保证。尽管关于预测性能的过拟合已被广泛研究，但公平性损失方面的过拟合受到的关注要少得多。本文提出了一个通过信息论视角分析公平性泛化误差的理论框架。我们新颖的边界技术基于Efron-Stein不等式，这使我们能够推导出包含互信息（MI）和条件互信息（CMI）的紧密信息论公平性泛化界限。我们的经验结果验证了这些界限在不同公平性感知学习算法中的紧密性和实际相关性。我们的框架为指导设计改进公平性泛化的算法提供了宝贵的见解。", "summary": "本文针对机器学习模型中公平性泛化缺乏形式保证的问题，提出了一个信息论框架来分析公平性泛化误差。该框架利用Efron-Stein不等式，推导出了基于互信息和条件互信息的紧密公平性泛化界限。经验验证表明这些界限具有紧密性和实际相关性，为未来设计提升公平性泛化能力的算法提供了理论指导。", "keywords": "公平性过拟合, 信息论, 泛化误差, 互信息, 条件互信息", "comments": "本文创新性地将信息论引入公平性泛化误差分析，填补了公平性过拟合研究的空白，并提供了具有理论依据和实际应用价值的指导性框架。其提出的紧密界限对于理解和改进公平性算法的泛化能力具有重要意义。"}}
{"id": "2506.06488", "title": "Membership Inference Attacks for Unseen Classes", "authors": ["Pratiksha Thaker", "Neil Kale", "Zhiwei Steven Wu", "Virginia Smith"], "summary": "Shadow model attacks are the state-of-the-art approach for membership\ninference attacks on machine learning models. However, these attacks typically\nassume an adversary has access to a background (nonmember) data distribution\nthat matches the distribution the target model was trained on. We initiate a\nstudy of membership inference attacks where the adversary or auditor cannot\naccess an entire subclass from the distribution -- a more extreme but realistic\nversion of distribution shift than has been studied previously. In this\nsetting, we first show that the performance of shadow model attacks degrades\ncatastrophically, and then demonstrate the promise of another approach,\nquantile regression, that does not have the same limitations. We show that\nquantile regression attacks consistently outperform shadow model attacks in the\nclass dropout setting -- for example, quantile regression attacks achieve up to\n11$\\times$ the TPR of shadow models on the unseen class on CIFAR-100, and\nachieve nontrivial TPR on ImageNet even with 90% of training classes removed.\nWe also provide a theoretical model that illustrates the potential and\nlimitations of this approach.", "comment": "Preprint", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06488v1", "AI": {"title_translation": "针对未见类别的成员推断攻击", "tldr": "本研究探讨了在对抗者无法访问完整数据子类分布的极端场景下的成员推断攻击，发现传统影子模型攻击在此设定下性能急剧下降，并提出分位数回归方法作为替代，证明其在此“类别缺失”设置中显著优于影子模型攻击。", "motivation": "现有的影子模型成员推断攻击通常假设攻击者能够访问与目标模型训练数据分布匹配的背景数据分布。然而，在更极端且现实的场景中，攻击者或审计者可能无法访问分布中的整个子类，导致传统影子模型攻击的性能灾难性下降，因此需要探索新的攻击方法。", "method": "研究首先展示了在对抗者无法访问完整子类数据分布的“类别缺失”设置下，影子模型攻击的性能会灾难性下降。随后，论文提出并评估了分位数回归方法，证明其在克服现有方法局限性方面的潜力。研究还提供了一个理论模型来阐释该方法的潜力和局限性。", "result": "分位数回归攻击在类别缺失设置下始终优于影子模型攻击。例如，在CIFAR-100数据集上，分位数回归攻击在未见类别上的真阳性率（TPR）是影子模型的11倍。即使在ImageNet数据集上移除90%的训练类别，分位数回归攻击也能实现非平凡的TPR。", "conclusion": "在攻击者无法访问完整子类数据分布的更现实的成员推断攻击场景中，传统影子模型攻击表现不佳，而分位数回归是一种有效且显著优于传统影子模型攻击的方法，能够应对此挑战。", "translation": "影子模型攻击是机器学习模型上成员推断攻击的最新方法。然而，这些攻击通常假设攻击者可以访问与目标模型训练数据分布匹配的背景（非成员）数据分布。我们首次研究了在攻击者或审计者无法访问分布中整个子类的情况下进行的成员推断攻击——这是一种比以往研究的分布偏移更极端但更现实的版本。在这种设置下，我们首先表明影子模型攻击的性能会灾难性下降，然后证明了另一种方法——分位数回归——的前景，该方法没有相同的局限性。我们表明，分位数回归攻击在类别缺失设置下始终优于影子模型攻击——例如，在CIFAR-100上，分位数回归攻击在未见类别上的TPR是影子模型的11倍，即使在ImageNet上移除90%的训练类别也能获得非平凡的TPR。我们还提供了一个理论模型，说明了这种方法的潜力和局限性。", "summary": "本研究针对成员推断攻击中攻击者无法访问完整数据子类的现实场景进行了探讨。传统影子模型攻击在此“类别缺失”设置下表现极差。论文创新性地引入了分位数回归方法，并通过实验证明其在此挑战性环境中显著优于影子模型攻击，例如在CIFAR-100和ImageNet数据集上均有优异表现，并辅以理论模型分析。", "keywords": "成员推断攻击, 影子模型, 分位数回归, 分布偏移, 未见类别", "comments": "这篇论文解决了成员推断攻击领域的一个重要现实挑战：当攻击者无法访问完整的背景数据分布时，传统影子模型攻击的失效问题。引入分位数回归作为替代方案具有创新性，并且实验结果表明其在“未见类别”设置下的优越性，这对于评估机器学习模型的隐私风险具有重要意义，尤其是在数据稀缺或分布不匹配的场景下，其提出的方法具有更强的实用性。"}}
{"id": "2506.07962", "title": "Correlated Errors in Large Language Models", "authors": ["Elliot Kim", "Avi Garg", "Kenny Peng", "Nikhil Garg"], "summary": "Diversity in training data, architecture, and providers is assumed to\nmitigate homogeneity in LLMs. However, we lack empirical evidence on whether\ndifferent LLMs differ meaningfully. We conduct a large-scale empirical\nevaluation on over 350 LLMs overall, using two popular leaderboards and a\nresume-screening task. We find substantial correlation in model errors -- on\none leaderboard dataset, models agree 60% of the time when both models err. We\nidentify factors driving model correlation, including shared architectures and\nproviders. Crucially, however, larger and more accurate models have highly\ncorrelated errors, even with distinct architectures and providers. Finally, we\nshow the effects of correlation in two downstream tasks: LLM-as-judge\nevaluation and hiring -- the latter reflecting theoretical predictions\nregarding algorithmic monoculture.", "comment": "Accepted to ICML 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07962v1", "AI": {"title_translation": "大型语言模型中的相关错误", "tldr": "研究发现不同大型语言模型的错误高度相关，即使架构和提供商不同，尤其是在大型高精度模型中，这会影响下游任务。", "motivation": "普遍认为训练数据、架构和提供商的多样性可以减轻大型语言模型（LLM）的同质性，但缺乏实证证据证明不同LLM是否存在有意义的差异。", "method": "对350多个大型语言模型进行了大规模实证评估，使用了两个流行的排行榜和一个简历筛选任务。", "result": "发现模型错误存在显著相关性；在一个排行榜数据集上，当两个模型都出错时，它们有60%的时间错误一致；识别出导致模型相关性的因素，包括共享架构和提供商；更大、更准确的模型即使架构和提供商不同，其错误也高度相关；展示了相关性在LLM作为评估者和招聘这两个下游任务中的影响，后者反映了算法单一文化的理论预测。", "conclusion": "大型语言模型的错误存在显著相关性，即使在多样化的模型中也是如此，这可能导致下游任务中的问题，并支持算法单一文化的理论。", "translation": "训练数据、架构和提供商的多样性被认为可以减轻大型语言模型 (LLM) 中的同质性。然而，我们缺乏关于不同LLM是否真正存在有意义差异的实证证据。我们对总共350多个LLM进行了大规模实证评估，使用了两个流行的排行榜和一个简历筛选任务。我们发现模型错误存在显著相关性——在一个排行榜数据集上，当两个模型都出错时，它们有60%的时间错误一致。我们识别了导致模型相关性的因素，包括共享架构和提供商。然而，至关重要的是，更大、更准确的模型即使架构和提供商不同，其错误也高度相关。最后，我们展示了相关性在两个下游任务中的影响：LLM作为评估者的评估和招聘——后者反映了关于算法单一文化的理论预测。", "summary": "本文通过对350多个大型语言模型（LLM）进行大规模实证评估，发现不同LLM的错误存在显著相关性，即使模型架构和提供商多样化，特别是对于更大、更准确的模型。这种错误相关性会影响LLM作为评估者和招聘等下游任务，揭示了潜在的“算法单一文化”问题。", "keywords": "大型语言模型, 错误相关性, 算法单一文化, 实证评估, 模型多样性", "comments": "这项研究揭示了大型语言模型领域一个重要的未被充分认识的问题：模型错误的高度相关性。这挑战了多样性必然带来差异的普遍假设，并对LLM的鲁棒性和公平性提出了新的担忧，尤其是在关键的下游应用中。其发现“算法单一文化”的潜在影响具有重要意义。"}}
{"id": "2506.06328", "title": "Is BERTopic Better than PLSA for Extracting Key Topics in Aviation Safety Reports?", "authors": ["Aziida Nanyonga", "Joiner Keith", "Turhan Ugur", "Wild Graham"], "summary": "This study compares the effectiveness of BERTopic and Probabilistic Latent\nSemantic Analysis (PLSA) in extracting meaningful topics from aviation safety\nreports aiming to enhance the understanding of patterns in aviation incident\ndata. Using a dataset of over 36,000 National Transportation Safety Board\n(NTSB) reports from 2000 to 2020, BERTopic employed transformer based\nembeddings and hierarchical clustering, while PLSA utilized probabilistic\nmodelling through the Expectation-Maximization (EM) algorithm. Results showed\nthat BERTopic outperformed PLSA in topic coherence, achieving a Cv score of\n0.41 compared to PLSA 0.37, while also demonstrating superior interpretability\nas validated by aviation safety experts. These findings underscore the\nadvantages of modern transformer based approaches in analyzing complex aviation\ndatasets, paving the way for enhanced insights and informed decision-making in\naviation safety. Future work will explore hybrid models, multilingual datasets,\nand advanced clustering techniques to further improve topic modelling in this\ndomain.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06328v1", "AI": {"title_translation": "BERTopic在航空安全报告关键主题提取方面是否优于PLSA？", "tldr": "本研究发现，BERTopic在从航空安全报告中提取主题方面优于PLSA，在主题连贯性和可解释性方面表现更佳。", "motivation": "本研究旨在比较BERTopic和PLSA在从航空安全报告中提取有意义主题方面的有效性，以增强对航空事件数据模式的理解。", "method": "本研究使用了超过36,000份2000年至2020年的美国国家运输安全委员会（NTSB）报告数据集。BERTopic采用了基于Transformer的嵌入和层次聚类，而PLSA则通过期望最大化（EM）算法利用概率建模。", "result": "结果显示，BERTopic在主题连贯性方面优于PLSA，其Cv得分为0.41，而PLSA为0.37，同时经航空安全专家验证，BERTopic还表现出卓越的可解释性。", "conclusion": "这些发现强调了现代基于Transformer的方法在分析复杂航空数据集方面的优势，为增强航空安全领域的洞察力和知情决策铺平了道路。", "translation": "本研究比较了BERTopic和概率潜在语义分析（PLSA）在从航空安全报告中提取有意义主题方面的有效性，旨在增强对航空事件数据模式的理解。研究使用了2000年至2020年间超过36,000份美国国家运输安全委员会（NTSB）报告的数据集，BERTopic采用了基于Transformer的嵌入和层次聚类，而PLSA则通过期望最大化（EM）算法利用概率建模。结果显示，BERTopic在主题连贯性方面优于PLSA，其Cv得分为0.41，而PLSA为0.37，同时经航空安全专家验证，BERTopic还表现出卓越的可解释性。这些发现强调了现代基于Transformer的方法在分析复杂航空数据集方面的优势，为增强航空安全领域的洞察力和知情决策铺平了道路。未来的工作将探索混合模型、多语言数据集和高级聚类技术，以进一步改进该领域的主题建模。", "summary": "本研究比较了BERTopic和PLSA在从航空安全报告中提取关键主题的有效性。研究使用了超过36,000份NTSB报告数据集，发现BERTopic在主题连贯性（Cv得分为0.41）和专家验证的可解释性方面均优于PLSA（Cv得分为0.37）。这表明现代基于Transformer的方法在分析复杂航空数据方面具有显著优势，有助于提升航空安全洞察和决策。", "keywords": "BERTopic, PLSA, 航空安全, 主题建模, NTSB报告", "comments": "本研究通过实证比较，突出了现代基于Transformer的主题建模方法（如BERTopic）在处理复杂、非结构化文本数据方面的优越性，特别是在航空安全这一关键领域。其创新性在于将先进的自然语言处理技术应用于实际安全报告分析，为提升航空安全理解和决策提供了新的工具。研究结果对未来在类似领域应用更先进的AI模型具有指导意义。"}}
{"id": "2506.07150", "title": "Improving Traffic Signal Data Quality for the Waymo Open Motion Dataset", "authors": ["Xintao Yan", "Erdao Liang", "Jiawei Wang", "Haojie Zhu", "Henry X. Liu"], "summary": "Datasets pertaining to autonomous vehicles (AVs) hold significant promise for\na range of research fields, including artificial intelligence (AI), autonomous\ndriving, and transportation engineering. Nonetheless, these datasets often\nencounter challenges related to the states of traffic signals, such as missing\nor inaccurate data. Such issues can compromise the reliability of the datasets\nand adversely affect the performance of models developed using them. This\nresearch introduces a fully automated approach designed to tackle these issues\nby utilizing available vehicle trajectory data alongside knowledge from the\ntransportation domain to effectively impute and rectify traffic signal\ninformation within the Waymo Open Motion Dataset (WOMD). The proposed method is\nrobust and flexible, capable of handling diverse intersection geometries and\ntraffic signal configurations in real-world scenarios. Comprehensive\nvalidations have been conducted on the entire WOMD, focusing on over 360,000\nrelevant scenarios involving traffic signals, out of a total of 530,000\nreal-world driving scenarios. In the original dataset, 71.7% of traffic signal\nstates are either missing or unknown, all of which were successfully imputed by\nour proposed method. Furthermore, in the absence of ground-truth signal states,\nthe accuracy of our approach is evaluated based on the rate of red-light\nviolations among vehicle trajectories. Results show that our method reduces the\nestimated red-light running rate from 15.7% in the original data to 2.9%,\nthereby demonstrating its efficacy in rectifying data inaccuracies. This paper\nsignificantly enhances the quality of AV datasets, contributing to the wider AI\nand AV research communities and benefiting various downstream applications. The\ncode and improved traffic signal data are open-sourced at\nhttps://github.com/michigan-traffic-lab/WOMD-Traffic-Signal-Data-Improvement", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07150v1", "AI": {"title_translation": "改善Waymo开放运动数据集的交通信号数据质量", "tldr": "本研究提出了一种全自动方法，利用车辆轨迹数据和交通领域知识，有效推断和纠正Waymo开放运动数据集中的交通信号信息，显著提高了数据集质量并降低了估计的闯红灯率。", "motivation": "自动驾驶汽车（AVs）数据集在人工智能、自动驾驶和交通工程等研究领域具有重要前景，但这些数据集经常遇到交通信号状态缺失或不准确的问题，这会损害数据集的可靠性并影响使用其开发模型的性能。", "method": "本研究引入了一种全自动方法，通过利用可用的车辆轨迹数据以及交通领域的知识，有效推断和纠正Waymo开放运动数据集（WOMD）中的交通信号信息。该方法具有鲁棒性和灵活性，能够处理现实世界中不同的交叉路口几何形状和交通信号配置。", "result": "在原始数据集中，71.7%的交通信号状态缺失或未知，所有这些都通过我们提出的方法成功推断。此外，在缺乏地面真实信号状态的情况下，根据车辆轨迹的闯红灯率评估了我们方法的准确性。结果显示，我们的方法将原始数据中估计的闯红灯率从15.7%降低到2.9%，从而证明了其纠正数据不准确性的有效性。", "conclusion": "本文显著提高了AV数据集的质量，为更广泛的人工智能和AV研究社区做出了贡献，并有利于各种下游应用。", "translation": "自动驾驶汽车（AVs）相关的数据集在人工智能（AI）、自动驾驶和交通工程等一系列研究领域中具有重要的前景。然而，这些数据集经常遇到与交通信号状态相关的挑战，例如数据缺失或不准确。此类问题会损害数据集的可靠性，并对使用它们开发的模型性能产生不利影响。本研究引入了一种全自动方法，旨在通过利用可用的车辆轨迹数据以及交通领域的知识，有效推断和纠正Waymo开放运动数据集（WOMD）中的交通信号信息，从而解决这些问题。所提出的方法具有鲁棒性和灵活性，能够处理现实世界中不同的交叉路口几何形状和交通信号配置。我们对整个WOMD进行了全面验证，重点关注了总计530,000个真实世界驾驶场景中超过360,000个与交通信号相关的场景。在原始数据集中，71.7%的交通信号状态缺失或未知，所有这些都通过我们提出的方法成功推断。此外，在缺乏地面真实信号状态的情况下，根据车辆轨迹的闯红灯率评估了我们方法的准确性。结果显示，我们的方法将原始数据中估计的闯红灯率从15.7%降低到2.9%，从而证明了其纠正数据不准确性的有效性。本文显著提高了AV数据集的质量，为更广泛的人工智能和AV研究社区做出了贡献，并有利于各种下游应用。代码和改进的交通信号数据已在https://github.com/michigan-traffic-lab/WOMD-Traffic-Signal-Data-Improvement 开源。", "summary": "本研究提出了一种全自动方法，旨在解决Waymo开放运动数据集（WOMD）中交通信号数据缺失和不准确的问题。该方法利用车辆轨迹数据和交通领域知识，能够有效推断和纠正交通信号信息，并适用于多种复杂的交叉路口和信号配置。通过对WOMD的全面验证，该方法成功推断了原始数据中71.7%的缺失或未知信号状态，并将估计的闯红灯率从15.7%显著降低至2.9%，从而证明了其在提高自动驾驶数据集质量方面的有效性，对AI和AV研究具有重要意义。", "keywords": "交通信号数据质量, Waymo开放运动数据集, 自动驾驶, 数据增强, 闯红灯率", "comments": "该论文提出了一种创新且实用的方法来解决自动驾驶数据集中交通信号数据质量的关键问题。其全自动化和对复杂现实场景的适应性是其主要优势。通过显著降低数据不准确性（如闯红灯率），该研究对提升自动驾驶模型训练的可靠性和性能具有重要价值。开源代码和数据也体现了其对社区的贡献。"}}
{"id": "2506.06822", "title": "Hi-LSplat: Hierarchical 3D Language Gaussian Splatting", "authors": ["Chenlu Zhan", "Yufei Zhang", "Gaoang Wang", "Hongwei Wang"], "summary": "Modeling 3D language fields with Gaussian Splatting for open-ended language\nqueries has recently garnered increasing attention. However, recent 3DGS-based\nmodels leverage view-dependent 2D foundation models to refine 3D semantics but\nlack a unified 3D representation, leading to view inconsistencies.\nAdditionally, inherent open-vocabulary challenges cause inconsistencies in\nobject and relational descriptions, impeding hierarchical semantic\nunderstanding. In this paper, we propose Hi-LSplat, a view-consistent\nHierarchical Language Gaussian Splatting work for 3D open-vocabulary querying.\nTo achieve view-consistent 3D hierarchical semantics, we first lift 2D features\nto 3D features by constructing a 3D hierarchical semantic tree with layered\ninstance clustering, which addresses the view inconsistency issue caused by 2D\nsemantic features. Besides, we introduce instance-wise and part-wise\ncontrastive losses to capture all-sided hierarchical semantic representations.\nNotably, we construct two hierarchical semantic datasets to better assess the\nmodel's ability to distinguish different semantic levels. Extensive experiments\nhighlight our method's superiority in 3D open-vocabulary segmentation and\nlocalization. Its strong performance on hierarchical semantic datasets\nunderscores its ability to capture complex hierarchical semantics within 3D\nscenes.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06822v1", "AI": {"title_translation": "Hi-LSplat: 分层3D语言高斯泼溅", "tldr": "Hi-LSplat通过构建3D分层语义树和引入对比损失，解决了现有3D语言高斯泼溅模型中视图不一致和开放词汇语义理解不足的问题，实现了视图一致的3D开放词汇查询。", "motivation": "现有基于3DGS的模型在利用2D基础模型细化3D语义时，缺乏统一的3D表示，导致视图不一致。此外，固有的开放词汇挑战导致对象和关系描述不一致，阻碍了分层语义理解。", "method": "本文提出了Hi-LSplat，一个用于3D开放词汇查询的视图一致分层语言高斯泼溅工作。为实现视图一致的3D分层语义，首先通过分层实例聚类构建3D分层语义树，将2D特征提升到3D特征，解决2D语义特征导致的视图不一致问题。此外，引入实例级和部分级对比损失以捕获全面的分层语义表示。值得注意的是，构建了两个分层语义数据集以更好地评估模型能力。", "result": "广泛的实验突出显示了该方法在3D开放词汇分割和定位方面的优越性。其在分层语义数据集上的强大性能强调了其捕获3D场景中复杂分层语义的能力。", "conclusion": "Hi-LSplat通过引入3D分层语义树和对比损失，有效解决了3D语言高斯泼溅中的视图不一致和分层语义理解问题，并在3D开放词汇任务上表现出色。", "translation": "标题：Hi-LSplat: 分层3D语言高斯泼溅\n\n摘要：\n最近，利用高斯泼溅建模3D语言场以实现开放式语言查询受到了越来越多的关注。然而，最近基于3DGS的模型利用依赖于视图的2D基础模型来细化3D语义，但缺乏统一的3D表示，导致视图不一致。此外，固有的开放词汇挑战导致对象和关系描述不一致，阻碍了分层语义理解。在本文中，我们提出了Hi-LSplat，一个用于3D开放词汇查询的视图一致分层语言高斯泼溅工作。为了实现视图一致的3D分层语义，我们首先通过分层实例聚类构建3D分层语义树，将2D特征提升到3D特征，从而解决了由2D语义特征引起的视图不一致问题。此外，我们引入了实例级和部分级对比损失，以捕获全面的分层语义表示。值得注意的是，我们构建了两个分层语义数据集，以更好地评估模型区分不同语义层级的能力。广泛的实验突出显示了我们的方法在3D开放词汇分割和定位方面的优越性。其在分层语义数据集上的强大性能强调了其捕获3D场景中复杂分层语义的能力。", "summary": "本文提出了Hi-LSplat，一个针对3D开放词汇查询的视图一致分层语言高斯泼溅模型。它通过构建3D分层语义树将2D特征提升到3D，并引入实例级和部分级对比损失，解决了现有方法中视图不一致和分层语义理解不足的问题。实验证明，Hi-LSplat在3D开放词汇分割和定位方面表现优异，并能有效捕获复杂的3D分层语义。", "keywords": "3D语言场, 高斯泼溅, 分层语义, 开放词汇, 视图一致性", "comments": "该论文通过引入3D分层语义树和针对性的对比损失，创新性地解决了3D语言场建模中长期存在的视图不一致性和开放词汇分层语义理解困难的问题。其方法不仅提升了3D开放词汇查询的准确性，还为3D场景的复杂语义理解提供了新的视角和工具，具有重要的研究价值和潜在应用前景。"}}
{"id": "2506.06910", "title": "Causal Graph based Event Reasoning using Semantic Relation Experts", "authors": ["Mahnaz Koupaee", "Xueying Bai", "Mudan Chen", "Greg Durrett", "Nathanael Chambers", "Niranjan Balasubramanian"], "summary": "Understanding how events in a scenario causally connect with each other is\nimportant for effectively modeling and reasoning about events. But event\nreasoning remains a difficult challenge, and despite recent advances, Large\nLanguage Models (LLMs) still struggle to accurately identify causal connections\nbetween events. This struggle leads to poor performance on deeper reasoning\ntasks like event forecasting and timeline understanding. To address this\nchallenge, we investigate the generation of causal event graphs (e.g., A\nenables B) as a parallel mechanism to help LLMs explicitly represent causality\nduring inference. This paper evaluates both how to generate correct graphs as\nwell as how graphs can assist reasoning. We propose a collaborative approach to\ncausal graph generation where we use LLMs to simulate experts that focus on\nspecific semantic relations. The experts engage in multiple rounds of\ndiscussions which are then consolidated by a final expert. Then, to demonstrate\nthe utility of causal graphs, we use them on multiple downstream applications,\nand also introduce a new explainable event prediction task that requires a\ncausal chain of events in the explanation. These explanations are more\ninformative and coherent than baseline generations. Finally, our overall\napproach not finetuned on any downstream task, achieves competitive results\nwith state-of-the-art models on both forecasting and next event prediction\ntasks.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06910v1", "AI": {"title_translation": "基于因果图的事件推理与语义关系专家", "tldr": "论文提出一种基于因果图的事件推理方法，利用LLM模拟语义关系专家生成因果图，以帮助LLM更好地理解事件间的因果关系，并在事件预测等任务上取得有竞争力的结果。", "motivation": "大型语言模型（LLM）在事件推理中难以准确识别事件间的因果连接，导致在事件预测和时间线理解等深层推理任务中表现不佳。", "method": "本文提出一种协作式因果图生成方法，利用LLM模拟专注于特定语义关系的专家进行多轮讨论并最终整合。随后，将生成的因果图应用于多个下游应用，并引入一个新的可解释事件预测任务，该任务要求解释中包含事件的因果链。", "result": "生成的因果图能够辅助推理，其解释比基线生成更具信息量和连贯性。整体方法在未针对任何下游任务进行微调的情况下，在事件预测和下一事件预测任务上均取得了与最先进模型相当的竞争性结果。", "conclusion": "通过生成和利用因果事件图，可以有效帮助LLM明确表示因果关系，从而提升事件推理能力，并在相关任务中取得优异表现。", "translation": "理解场景中事件如何相互因果连接对于有效建模和推理事件至关重要。但事件推理仍然是一个难题，尽管最近取得了进展，大型语言模型（LLM）仍然难以准确识别事件间的因果连接。这种困难导致在事件预测和时间线理解等深层推理任务上表现不佳。为了解决这一挑战，我们研究了因果事件图（例如，A使B成为可能）的生成作为一种并行机制，以帮助LLM在推理过程中明确表示因果关系。本文评估了如何生成正确的图以及图如何辅助推理。我们提出了一种协作式因果图生成方法，其中我们使用LLM模拟专注于特定语义关系的专家。这些专家进行多轮讨论，然后由最终专家进行整合。然后，为了展示因果图的效用，我们将其用于多个下游应用，并引入一个新的可解释事件预测任务，该任务要求解释中包含事件的因果链。这些解释比基线生成更具信息量和连贯性。最后，我们的整体方法未在任何下游任务上进行微调，在预测和下一事件预测任务上均取得了与最先进模型相当的竞争性结果。", "summary": "本文旨在解决大型语言模型在事件因果推理方面的不足。作者提出一种新颖的协作式方法，通过LLM模拟语义关系专家生成因果事件图，以显式地表示事件间的因果关系。研究评估了因果图的生成及其对推理的辅助作用，并将其应用于事件预测等任务。实验结果表明，该方法在未进行下游任务微调的情况下，在事件预测和下一事件预测任务上达到了与现有最先进模型相当的性能，并能提供更具信息量和连贯性的因果链解释。", "keywords": "因果图, 事件推理, 大型语言模型, 语义关系, 事件预测", "comments": "这项研究通过引入因果图作为LLM推理的并行机制，为解决LLM在深层事件推理中的因果关系识别问题提供了创新性的视角。其亮点在于利用LLM本身模拟专家进行协作式因果图生成，以及在未微调的情况下达到竞争性结果，这表明了该方法在提升LLM解释性和推理能力方面的潜力。"}}
{"id": "2506.06489", "title": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks", "authors": ["Daniel Kunin", "Giovanni Luca Marchetti", "Feng Chen", "Dhruva Karkada", "James B. Simon", "Michael R. DeWeese", "Surya Ganguli", "Nina Miolane"], "summary": "What features neural networks learn, and how, remains an open question. In\nthis paper, we introduce Alternating Gradient Flows (AGF), an algorithmic\nframework that describes the dynamics of feature learning in two-layer networks\ntrained from small initialization. Prior works have shown that gradient flow in\nthis regime exhibits a staircase-like loss curve, alternating between plateaus\nwhere neurons slowly align to useful directions and sharp drops where neurons\nrapidly grow in norm. AGF approximates this behavior as an alternating two-step\nprocess: maximizing a utility function over dormant neurons and minimizing a\ncost function over active ones. AGF begins with all neurons dormant. At each\nround, a dormant neuron activates, triggering the acquisition of a feature and\na drop in the loss. AGF quantifies the order, timing, and magnitude of these\ndrops, matching experiments across architectures. We show that AGF unifies and\nextends existing saddle-to-saddle analyses in fully connected linear networks\nand attention-only linear transformers, where the learned features are singular\nmodes and principal components, respectively. In diagonal linear networks, we\nprove AGF converges to gradient flow in the limit of vanishing initialization.\nApplying AGF to quadratic networks trained to perform modular addition, we give\nthe first complete characterization of the training dynamics, revealing that\nnetworks learn Fourier features in decreasing order of coefficient magnitude.\nAltogether, AGF offers a promising step towards understanding feature learning\nin neural networks.", "comment": "35 pages, 7 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06489v1", "AI": {"title_translation": "梯度交替流：双层神经网络特征学习理论", "tldr": "本文提出了梯度交替流（AGF）框架，用于描述和量化双层神经网络中特征学习的动态过程，解释了损失函数呈阶梯状下降的行为，并统一了现有分析。", "motivation": "神经网络学习什么特征以及如何学习仍然是一个悬而未决的问题。", "method": "引入了梯度交替流（AGF）框架，该框架将梯度流在小初始化训练下的行为近似为一个交替的两步过程：在休眠神经元上最大化效用函数，在活跃神经元上最小化成本函数。AGF从所有神经元休眠开始，每一轮一个休眠神经元激活，触发特征获取和损失下降。", "result": "1. AGF量化了损失下降的顺序、时机和幅度，与不同架构的实验结果相符。2. AGF统一并扩展了全连接线性网络和仅注意力线性Transformer中现有的鞍点到鞍点分析，其中学习到的特征分别是奇异模态和主成分。3. 在对角线性网络中，证明了在初始化趋于零的极限下，AGF收敛于梯度流。4. 将AGF应用于训练执行模运算的二次网络，首次完整描述了训练动态，揭示了网络按系数幅度递减的顺序学习傅里叶特征。", "conclusion": "AGF为理解神经网络中的特征学习提供了有希望的一步。", "translation": "神经网络学习什么特征以及如何学习仍然是一个悬而未决的问题。在本文中，我们引入了梯度交替流（AGF），这是一个算法框架，描述了从小型初始化训练的双层网络中特征学习的动态过程。先前的研究表明，在这种情况下，梯度流呈现出阶梯状的损失曲线，在神经元缓慢对齐到有用方向的平台期和神经元范数迅速增长的急剧下降期之间交替。AGF将这种行为近似为一个交替的两步过程：在休眠神经元上最大化效用函数，在活跃神经元上最小化成本函数。AGF从所有神经元休眠开始。在每一轮中，一个休眠神经元激活，触发特征的获取和损失的下降。AGF量化了这些下降的顺序、时机和幅度，与不同架构的实验结果相符。我们表明，AGF统一并扩展了全连接线性网络和仅注意力线性Transformer中现有的鞍点到鞍点分析，其中学习到的特征分别是奇异模态和主成分。在对角线性网络中，我们证明了在初始化趋于零的极限下，AGF收敛于梯度流。将AGF应用于训练执行模运算的二次网络，我们首次完整地描述了训练动态，揭示了网络按系数幅度递减的顺序学习傅里叶特征。总而言之，AGF为理解神经网络中的特征学习提供了一个有希望的步骤。", "summary": "本文提出了梯度交替流（AGF）框架，旨在解决神经网络特征学习的开放性问题。AGF将双层网络在小初始化训练下的梯度流动态近似为休眠神经元效用最大化和活跃神经元成本最小化的交替过程，解释了损失函数阶梯状下降的行为。该框架量化了损失下降的顺序、时机和幅度，并统一扩展了现有对线性网络和Transformer的分析。研究证明AGF在特定条件下收敛于梯度流，并首次完整描述了二次网络中傅里叶特征的学习动态。AGF为深入理解神经网络特征学习提供了新的视角。", "keywords": "梯度交替流,特征学习,双层神经网络,训练动态,梯度流", "comments": "这篇论文的创新点在于提出了一个全新的算法框架AGF，它能够以一种直观且量化的方式解释双层神经网络中特征学习的动态过程，特别是损失函数呈现阶梯状下降的现象。AGF的普适性体现在它能统一并扩展现有对不同类型线性网络的分析，并首次完整刻画了二次网络中的训练动态，这对于理解神经网络的内部机制具有重要意义。该工作为神经网络特征学习的理论研究迈出了坚实的一步。"}}
{"id": "2506.07204", "title": "MorphoCopter: Design, Modeling, and Control of a New Transformable Quad-Bi Copter", "authors": ["Harsh Modi", "Hao Su", "Xiao Liang", "Minghui Zheng"], "summary": "This paper presents a novel morphing quadrotor, named MorphoCopter, covering\nits design, modeling, control, and experimental tests. It features a unique\nsingle rotary joint that enables rapid transformation into an ultra-narrow\nprofile. Although quadrotors have seen widespread adoption in applications such\nas cinematography, agriculture, and disaster management with increasingly\nsophisticated control systems, their hardware configurations have remained\nlargely unchanged, limiting their capabilities in certain environments. Our\ndesign addresses this by enabling the hardware configuration to change on the\nfly when required. In standard flight mode, the MorphoCopter adopts an X\nconfiguration, functioning as a traditional quadcopter, but can quickly fold\ninto a stacked bicopters arrangement or any configuration in between. Existing\nmorphing designs often sacrifice controllability in compact configurations or\nrely on complex multi-joint systems. Moreover, our design achieves a greater\nwidth reduction than any existing solution. We develop a new inertia and\ncontrol-action aware adaptive control system that maintains robust performance\nacross all rotary-joint configurations. The prototype can reduce its width from\n447 mm to 138 mm (nearly 70\\% reduction) in just a few seconds. We validated\nthe MorphoCopter through rigorous simulations and a comprehensive series of\nflight experiments, including robustness tests, trajectory tracking, and\nnarrow-gap passing tests.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07204v1", "AI": {"title_translation": "MorphoCopter: 一种新型可变形四旋翼-双旋翼飞行器的设计、建模与控制", "tldr": "MorphoCopter是一种新型可变形四旋翼飞行器，可通过单一旋转关节快速变形，实现超窄姿态，并采用自适应控制系统在不同配置下保持鲁棒性能。", "motivation": "现有四旋翼飞行器硬件配置基本不变，限制了其在特定环境中的能力。现有变形设计常牺牲紧凑配置下的可控性或依赖复杂多关节系统。本研究旨在解决这些局限性。", "method": "本文提出了一种名为MorphoCopter的新型变形四旋翼飞行器，具有独特的单一旋转关节，能够快速变形。开发了一种新的惯性和控制动作感知的自适应控制系统，以在所有旋转关节配置中保持鲁棒性能。通过仿真和全面的飞行实验（包括鲁棒性测试、轨迹跟踪和窄间隙通过测试）进行验证。", "result": "MorphoCopter在几秒内可将宽度从447毫米减少到138毫米（接近70%的缩减）。该设计实现了比现有解决方案更大的宽度缩减。自适应控制系统在所有旋转关节配置下保持了鲁棒性能。", "conclusion": "MorphoCopter通过其独特的单一旋转关节设计和新的自适应控制系统，成功实现了快速变形、显著的宽度缩减以及在各种配置下的鲁棒飞行性能，克服了现有变形无人机的局限性。", "translation": "本文介绍了一种名为MorphoCopter的新型变形四旋翼飞行器，涵盖其设计、建模、控制和实验测试。它具有独特的单一旋转关节，能够快速变形为超窄外形。尽管四旋翼飞行器在电影摄影、农业和灾害管理等应用中得到了广泛采用，并配备了日益复杂的控制系统，但其硬件配置基本保持不变，限制了它们在某些环境中的能力。我们的设计通过在需要时实现硬件配置的即时改变来解决这个问题。在标准飞行模式下，MorphoCopter采用X形配置，作为传统四旋翼飞行器运行，但可以迅速折叠成堆叠的双旋翼布局或介于两者之间的任何配置。现有的变形设计通常会牺牲紧凑配置下的可控性或依赖复杂的多个关节系统。此外，我们的设计实现了比任何现有解决方案更大的宽度缩减。我们开发了一种新的惯性和控制动作感知的自适应控制系统，该系统在所有旋转关节配置中都能保持鲁棒性能。原型机可以在短短几秒钟内将其宽度从447毫米减少到138毫米（接近70%的缩减）。我们通过严格的仿真和一系列全面的飞行实验（包括鲁棒性测试、轨迹跟踪和窄间隙通过测试）验证了MorphoCopter。", "summary": "本文介绍了一种名为MorphoCopter的新型可变形四旋翼飞行器。该飞行器通过独特的单一旋转关节，能够快速从X形四旋翼配置变形为堆叠的双旋翼或中间配置，实现高达70%的宽度缩减，以适应狭窄环境。为确保在不同形态下的鲁棒性能，研究开发了一种惯性和控制动作感知的自适应控制系统。通过仿真和全面的飞行实验，验证了其设计、变形能力和控制系统的有效性。", "keywords": "变形四旋翼飞行器, 单一旋转关节, 自适应控制, 窄间隙通过, MorphoCopter", "comments": "MorphoCopter的创新之处在于其单一旋转关节设计，实现了快速且显著的宽度缩减，同时通过自适应控制系统克服了现有变形无人机在可控性方面的挑战。这种设计对于在复杂和狭窄空间中执行任务的无人机具有重要意义，有望拓宽四旋翼飞行器的应用范围。"}}
{"id": "2506.06823", "title": "Exploring Visual Prompting: Robustness Inheritance and Beyond", "authors": ["Qi Li", "Liangzhi Li", "Zhouqiang Jiang", "Bowen Wang", "Keke Tang"], "summary": "Visual Prompting (VP), an efficient method for transfer learning, has shown\nits potential in vision tasks. However, previous works focus exclusively on VP\nfrom standard source models, it is still unknown how it performs under the\nscenario of a robust source model: Can the robustness of the source model be\nsuccessfully inherited? Does VP also encounter the same trade-off between\nrobustness and generalization ability as the source model during this process?\nIf such a trade-off exists, is there a strategy specifically tailored to VP to\nmitigate this limitation? In this paper, we thoroughly explore these three\nquestions for the first time and provide affirmative answers to them. To\nmitigate the trade-off faced by VP, we propose a strategy called Prompt\nBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally\ncompatible with VP, PBL effectively ensures the successful inheritance of\nrobustness when the source model is a robust model, while significantly\nenhancing VP's generalization ability across various downstream datasets.\nExtensive experiments across various datasets show that our findings are\nuniversal and demonstrate the significant benefits of the proposed strategy.", "comment": "arXiv admin note: substantial text overlap with arXiv:2311.10992", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06823v1", "AI": {"title_translation": "探索视觉提示：鲁棒性继承及超越", "tldr": "本文首次探讨了视觉提示（VP）在鲁棒源模型下的表现，发现鲁棒性可以继承但存在权衡，并提出PBL策略来缓解这一问题，显著提升了VP的泛化能力。", "motivation": "现有研究主要关注标准源模型下的视觉提示（VP），但对于鲁棒源模型下VP的性能尚不清楚，特别是鲁棒性能否成功继承，以及是否存在鲁棒性与泛化能力之间的权衡，以及如何缓解这一限制。", "method": "本文首次深入探讨了视觉提示（VP）在鲁棒源模型下的三个关键问题，并提出了名为“提示边界松弛（Prompt Boundary Loosening, PBL）”的策略来缓解VP所面临的权衡问题。PBL是一种轻量级、即插即用的策略。", "result": "研究发现鲁棒源模型的鲁棒性可以成功继承到视觉提示（VP）中，但存在鲁棒性与泛化能力之间的权衡。提出的PBL策略作为一种轻量级、即插即用的方法，在确保鲁棒性成功继承的同时，显著增强了VP在各种下游数据集上的泛化能力。广泛的实验表明这些发现是普遍的。", "conclusion": "本文首次全面回答了视觉提示（VP）在鲁棒源模型下的关键问题，证明了鲁棒性继承的可行性及权衡的存在，并成功开发了PBL策略来有效缓解这一权衡，显著提升了VP的性能和泛化能力，为VP在鲁棒性场景下的应用提供了重要指导。", "translation": "视觉提示（VP）作为一种高效的迁移学习方法，已在视觉任务中展现出其潜力。然而，以往的工作只专注于标准源模型下的VP，它在鲁棒源模型场景下的表现仍然未知：源模型的鲁棒性能否成功继承？在此过程中，VP是否也会像源模型一样，面临鲁棒性和泛化能力之间的权衡？如果存在这种权衡，是否有专门针对VP的策略来缓解这一局限性？在本文中，我们首次彻底探讨了这三个问题，并给出了肯定的答案。为了缓解VP面临的权衡，我们提出了一种名为“提示边界松弛（Prompt Boundary Loosening, PBL）”的策略。作为一种轻量级、即插即用的策略，它与VP天然兼容，当源模型是鲁棒模型时，PBL能有效确保鲁棒性的成功继承，同时显著增强VP在各种下游数据集上的泛化能力。对各种数据集进行的广泛实验表明，我们的发现是普遍的，并展示了所提出策略的显著优势。", "summary": "本文首次系统探究了视觉提示（VP）在鲁棒源模型场景下的表现，回答了鲁棒性继承、鲁棒性与泛化能力权衡等关键问题。研究发现鲁棒性可以继承但存在权衡，并提出了一种名为“提示边界松弛（PBL）”的轻量级即插即用策略。PBL能够有效确保鲁棒性继承，并显著提升VP在不同下游数据集上的泛化能力，实验证实了其普适性和有效性。", "keywords": "视觉提示, 鲁棒性继承, 泛化能力, 提示边界松弛, 迁移学习", "comments": "这篇论文创新性地将视觉提示（VP）的研究扩展到鲁棒源模型场景，填补了现有研究的空白。其提出的PBL策略具有轻量级和即插即用的优点，为提升VP在鲁棒性任务中的泛化能力提供了有效途径，具有重要的实践意义和潜在的应用价值。"}}
{"id": "2506.06923", "title": "Boosting LLM Reasoning via Spontaneous Self-Correction", "authors": ["Xutong Zhao", "Tengyu Xu", "Xuewei Wang", "Zhengxing Chen", "Di Jin", "Liang Tan", "Yen-Ting", "Zishun Yu", "Zhuokai Zhao", "Yun He", "Sinong Wang", "Han Fang", "Sarath Chandar", "Chen Zhu"], "summary": "While large language models (LLMs) have demonstrated remarkable success on a\nbroad range of tasks, math reasoning remains a challenging one. One of the\napproaches for improving math reasoning is self-correction, which designs\nself-improving loops to let the model correct its own mistakes. However,\nexisting self-correction approaches treat corrections as standalone\npost-generation refinements, relying on extra prompt and system designs to\nelicit self-corrections, instead of performing real-time, spontaneous\nself-corrections in a single pass. To address this, we propose SPOC, a\nspontaneous self-correction approach that enables LLMs to generate interleaved\nsolutions and verifications in a single inference pass, with generation\ndynamically terminated based on verification outcomes, thereby effectively\nscaling inference time compute. SPOC considers a multi-agent perspective by\nassigning dual roles -- solution proposer and verifier -- to the same model. We\nadopt a simple yet effective approach to generate synthetic data for\nfine-tuning, enabling the model to develop capabilities for self-verification\nand multi-agent collaboration. We further improve its solution proposal and\nverification accuracy through online reinforcement learning. Experiments on\nmathematical reasoning benchmarks show that SPOC significantly improves\nperformance. Notably, SPOC boosts the accuracy of Llama-3.1-8B and 70B Instruct\nmodels, achieving gains of 8.8% and 11.6% on MATH500, 10.0% and 20.0% on AMC23,\nand 3.3% and 6.7% on AIME24, respectively.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06923v1", "AI": {"title_translation": "通过自发自我纠正提升大型语言模型推理能力", "tldr": "SPOC是一种自发自我纠正方法，使大型语言模型（LLM）能够在单次推理中进行数学推理的自我校正，显著提高了性能。", "motivation": "大型语言模型（LLM）在数学推理方面仍面临挑战。现有的自我纠正方法需要额外的提示和系统设计，将纠正视为生成后的独立完善步骤，而非单次推理中的实时自发纠正。", "method": "提出SPOC方法，使LLM能够在单次推理中交错生成解决方案和验证，并根据验证结果动态终止生成。SPOC采用多智能体视角，赋予模型解决方案提议者和验证者双重角色。通过生成合成数据进行微调，并利用在线强化学习进一步提高解决方案提议和验证的准确性。", "result": "SPOC显著提升了数学推理基准测试的性能。Llama-3.1-8B和70B Instruct模型在MATH500上分别获得了8.8%和11.6%的准确率提升，在AMC23上分别提升10.0%和20.0%，在AIME24上分别提升3.3%和6.7%。", "conclusion": "SPOC显著提升了大型语言模型在数学推理任务上的准确性，证明了其自发自我纠正方法的有效性。", "translation": "尽管大型语言模型（LLM）在广泛任务上取得了显著成功，但数学推理仍然是一个具有挑战性的任务。改进数学推理的方法之一是自我纠正，它设计自我改进循环，让模型纠正自己的错误。然而，现有的自我纠正方法将纠正视为独立的生成后完善，依赖于额外的提示和系统设计来引发自我纠正，而不是在单次通过中执行实时、自发的自我纠正。为了解决这个问题，我们提出了SPOC，一种自发自我纠正方法，使LLM能够在单次推理通过中生成交错的解决方案和验证，并根据验证结果动态终止生成，从而有效地扩展推理时间计算。SPOC通过将解决方案提议者和验证者双重角色分配给同一个模型来考虑多智能体视角。我们采用一种简单而有效的方法来生成用于微调的合成数据，使模型能够开发自我验证和多智能体协作的能力。我们通过在线强化学习进一步提高了其解决方案提议和验证的准确性。在数学推理基准测试上的实验表明，SPOC显著提高了性能。值得注意的是，SPOC提升了Llama-3.1-8B和70B Instruct模型的准确性，在MATH500上分别获得了8.8%和11.6%的提升，在AMC23上分别获得了10.0%和20.0%的提升，在AIME24上分别获得了3.3%和6.7%的提升。", "summary": "该论文提出了SPOC，一种创新的自发自我纠正方法，旨在提升大型语言模型（LLM）的数学推理能力。不同于现有需要额外提示的自我纠正方法，SPOC允许LLM在单次推理中交错生成解决方案和验证，并根据验证结果动态终止生成。该方法通过将模型视为多智能体，赋予其解决方案提议者和验证者双重角色，并利用合成数据微调和在线强化学习来提高性能。实验结果表明，SPOC在多个数学推理基准测试上显著提升了Llama-3.1模型家族的准确率。", "keywords": "LLM推理, 自我纠正, 数学推理, 多智能体, 强化学习", "comments": "SPOC的创新之处在于实现了单次推理中的“自发”自我纠正，通过将LLM转化为具有解决方案提议和验证双重角色的多智能体，有效解决了现有方法的局限性。利用合成数据微调和在线强化学习进一步增强了其能力，显著提升了LLM在复杂数学推理任务上的性能，具有重要的实践意义。"}}
{"id": "2506.06499", "title": "Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms", "authors": ["Alex Havrilla", "Edward Hughes", "Mikayel Samvelyan", "Jacob Abernethy"], "summary": "Large language model (LLM) driven synthetic data generation has emerged as a\npowerful method for improving model reasoning capabilities. However, most\nmethods either distill large state-of-the-art models into small students or use\nnatural ground-truth problem statements to guarantee problem statement quality.\nThis limits the scalability of these approaches to more complex and diverse\nproblem domains. To address this, we present SPARQ: Synthetic Problem\nGeneration for Reasoning via Quality-Diversity Algorithms, a novel approach for\ngenerating high-quality and diverse synthetic math problem and solution pairs\nusing only a single model by measuring a problem's solve-rate: a proxy for\nproblem difficulty. Starting from a seed dataset of 7.5K samples, we generate\nover 20 million new problem-solution pairs. We show that filtering the\ngenerated data by difficulty and then fine-tuning the same model on the\nresulting data improves relative model performance by up to 24\\%. Additionally,\nwe conduct ablations studying the impact of synthetic data quantity, quality\nand diversity on model generalization. We find that higher quality, as measured\nby problem difficulty, facilitates better in-distribution performance. Further,\nwhile generating diverse synthetic data does not as strongly benefit\nin-distribution performance, filtering for more diverse data facilitates more\nrobust OOD generalization. We also confirm the existence of model and data\nscaling laws for synthetically generated problems, which positively benefit\ndownstream model generalization.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06499v1", "AI": {"title_translation": "质量-多样性算法用于推理的合成问题生成", "tldr": "提出SPARQ，一种通过测量解决率生成高质量和多样化合成数学问题及解决方案的方法，能显著提升模型推理能力并促进OOD泛化。", "motivation": "现有LLM驱动的合成数据生成方法在保证问题质量的同时，限制了其在更复杂和多样化问题领域的扩展性。", "method": "提出SPARQ，一种利用质量-多样性算法生成高质量和多样化合成数学问题与解决方案对的新方法。该方法仅使用单个模型，通过测量问题的解决率（作为问题难度的代理）来评估问题质量。从7.5K样本的种子数据集开始，生成了超过2000万个新的问题-解决方案对。", "result": "1. 通过难度过滤生成的数据并对同一模型进行微调，模型相对性能提升高达24%。\n2. 问题难度衡量下的更高质量数据有助于更好的分布内性能。\n3. 生成多样化合成数据对分布内性能的益处不强，但过滤出更多样化的数据有助于更稳健的分布外泛化。\n4. 证实了合成生成问题中存在模型和数据缩放定律，这积极地促进了下游模型的泛化。", "conclusion": "SPARQ方法通过生成高质量和多样化的合成数据，显著提升了LLM的推理能力和泛化性，并揭示了合成数据在质量、多样性和缩放定律对模型性能和泛化能力的影响。", "translation": "大型语言模型（LLM）驱动的合成数据生成已成为提高模型推理能力的强大方法。然而，大多数方法要么将大型最先进模型蒸馏成小型学生模型，要么使用自然的真实问题陈述来保证问题陈述的质量。这限制了这些方法在更复杂和多样化问题领域的扩展性。为了解决这个问题，我们提出了SPARQ：通过质量-多样性算法进行推理的合成问题生成，这是一种新颖的方法，仅使用单个模型通过测量问题的解决率（问题难度的代理）来生成高质量和多样化的合成数学问题和解决方案对。从7.5K个样本的种子数据集开始，我们生成了超过2000万个新的问题-解决方案对。我们表明，通过难度过滤生成的数据，然后对同一模型进行微调，可以将相对模型性能提高高达24%。此外，我们进行了消融研究，探讨了合成数据数量、质量和多样性对模型泛化的影响。我们发现，以问题难度衡量的更高质量有助于更好的分布内性能。此外，虽然生成多样化的合成数据对分布内性能的益处不强，但过滤出更多样化的数据有助于更稳健的分布外泛化。我们还证实了合成生成问题中存在模型和数据缩放定律，这积极地促进了下游模型的泛化。", "summary": "本文提出了SPARQ，一种基于质量-多样性算法的合成问题生成方法，旨在克服现有LLM驱动合成数据生成在扩展性和多样性上的限制。SPARQ仅使用单个模型，通过测量问题解决率来生成高质量和多样化的数学问题-解决方案对。实验表明，该方法能生成大量数据（超2000万对），并通过对过滤后的数据进行微调，使模型性能提升高达24%。研究还发现，高质量数据有利于分布内性能，而多样性数据则能增强分布外泛化能力，并证实了合成数据存在模型和数据缩放定律，对模型泛化有积极影响。", "keywords": "合成数据生成, 质量-多样性算法, 大语言模型, 推理, 数据增强", "comments": "这篇论文的创新点在于提出了SPARQ方法，通过质量-多样性算法和解决率作为难度代理来生成大规模、高质量且多样化的合成数据，克服了传统方法对真实数据或大型模型的依赖，显著提升了模型在推理任务上的性能和泛化能力。其揭示的合成数据质量、多样性以及缩放定律对模型泛化的影响，对于未来LLM的数据增强和训练具有重要指导意义。"}}
{"id": "2506.06331", "title": "How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG", "authors": ["Qiming Zeng", "Xiao Yan", "Hao Luo", "Yuhao Lin", "Yuxiang Wang", "Fangcheng Fu", "Bo Du", "Quanqing Xu", "Jiawei Jiang"], "summary": "By retrieving contexts from knowledge graphs, graph-based retrieval-augmented\ngeneration (GraphRAG) enhances large language models (LLMs) to generate quality\nanswers for user questions. Many GraphRAG methods have been proposed and\nreported inspiring performance in answer quality. However, we observe that the\ncurrent answer evaluation framework for GraphRAG has two critical flaws, i.e.,\nunrelated questions and evaluation biases, which may lead to biased or even\nwrong conclusions on performance. To tackle the two flaws, we propose an\nunbiased evaluation framework that uses graph-text-grounded question generation\nto produce questions that are more related to the underlying dataset and an\nunbiased evaluation procedure to eliminate the biases in LLM-based answer\nassessment. We apply our unbiased framework to evaluate 3 representative\nGraphRAG methods and find that their performance gains are much more moderate\nthan reported previously. Although our evaluation framework may still have\nflaws, it calls for scientific evaluations to lay solid foundations for\nGraphRAG research.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06331v1", "AI": {"title_translation": "实际性能提升有多大？一个用于GraphRAG的无偏评估框架", "tldr": "当前GraphRAG评估存在不相关问题和评估偏差两大缺陷，导致性能结论可能不准确。本文提出了一个无偏评估框架，通过图文结合的问题生成和无偏评估程序来解决这些问题。应用该框架发现，现有GraphRAG方法的实际性能提升远比之前报告的要温和。", "motivation": "当前的GraphRAG答案评估框架存在两个关键缺陷：不相关的问题和评估偏差。这些缺陷可能导致对性能的偏颇甚至错误的结论，从而无法准确衡量GraphRAG方法的真实效果。", "method": "本文提出了一个无偏评估框架，包含两部分：1. 使用图文结合的问题生成来产生与底层数据集更相关的问题。2. 采用无偏评估程序来消除基于LLM的答案评估中的偏差。", "result": "将提出的无偏框架应用于评估3种代表性的GraphRAG方法后发现，它们的性能提升远比之前报告的要温和。", "conclusion": "尽管提出的评估框架可能仍有缺陷，但它强调了进行科学评估的必要性，以期为GraphRAG研究奠定坚实的基础，并指出之前报告的性能可能被高估。", "translation": "通过从知识图中检索上下文，基于图的检索增强生成（GraphRAG）增强了大型语言模型（LLMs），以生成高质量的用户问题答案。许多GraphRAG方法已被提出，并报告了令人鼓舞的答案质量性能。然而，我们观察到当前GraphRAG的答案评估框架存在两个关键缺陷，即不相关的问题和评估偏差，这可能导致对性能的偏颇甚至错误的结论。为了解决这两个缺陷，我们提出了一个无偏评估框架，该框架使用图文结合的问题生成来产生与底层数据集更相关的问题，并采用无偏评估程序来消除基于LLM的答案评估中的偏差。我们将我们的无偏框架应用于评估3种代表性的GraphRAG方法，发现它们的性能提升远比之前报告的要温和。尽管我们的评估框架可能仍有缺陷，但它呼吁进行科学评估，为GraphRAG研究奠定坚实的基础。", "summary": "本文指出了当前GraphRAG性能评估框架中存在的关键缺陷（不相关问题和评估偏差），这些缺陷可能导致夸大的性能声明。为此，论文提出了一个无偏评估框架，该框架结合了图文结合的问题生成和无偏评估程序。通过将此新框架应用于三种代表性的GraphRAG方法，研究发现它们的实际性能提升远比之前报告的要温和，从而强调了GraphRAG研究中严格科学评估的必要性。", "keywords": "GraphRAG, 评估框架, 偏差, 大型语言模型, 知识图谱图谱", "comments": "这篇论文通过揭示并解决GraphRAG评估中存在的关键方法论缺陷，做出了重要贡献。它提出了一个无偏框架，挑战了现有的性能主张，并推动了更严谨的科学实践，这对于GraphRAG研究的健康发展至关重要。其对评估有效性的关注是一个重要的创新点。"}}
{"id": "2506.07728", "title": "\"I wasn't sure if this is indeed a security risk\": Data-driven Understanding of Security Issue Reporting in GitHub Repositories of Open Source npm Packages", "authors": ["Rajdeep Ghosh", "Shiladitya De", "Mainack Mondal"], "summary": "The npm (Node Package Manager) ecosystem is the most important package\nmanager for JavaScript development with millions of users. Consequently, a\nplethora of earlier work investigated how vulnerability reporting, patch\npropagation, and in general detection as well as resolution of security issues\nin such ecosystems can be facilitated. However, understanding the ground\nreality of security-related issue reporting by users (and bots) in npm-along\nwith the associated challenges has been relatively less explored at scale.\n  In this work, we bridge this gap by collecting 10,907,467 issues reported\nacross GitHub repositories of 45,466 diverse npm packages. We found that the\ntags associated with these issues indicate the existence of only 0.13%\nsecurity-related issues. However, our approach of manual analysis followed by\ndeveloping high accuracy machine learning models identify 1,617,738\nsecurity-related issues which are not tagged as security-related (14.8% of all\nissues) as well as 4,461,934 comments made on these issues. We found that the\nbots which are in wide use today might not be sufficient for either detecting\nor offering assistance. Furthermore, our analysis of user-developer interaction\ndata hints that many user-reported security issues might not be addressed by\ndevelopers-they are not tagged as security-related issues and might be closed\nwithout valid justification. Consequently, a correlation analysis hints that\nthe developers quickly handle security issues with known solutions (e.g.,\ncorresponding to CVE). However, security issues without such known solutions\n(even with reproducible code) might not be resolved. Our findings offer\nactionable insights for improving security management in open-source\necosystems, highlighting the need for smarter tools and better collaboration.\nThe data and code for this work is available at\nhttps://doi.org/10.5281/zenodo.15614029", "comment": "This extended version of our USENIX Security '25 paper on Security\n  issue reporting in NPM packages includes appendices for interested readers", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07728v1", "AI": {"title_translation": "“我不太确定这是否确实是一个安全风险”：对开源npm包GitHub仓库中安全问题报告的数据驱动理解", "tldr": "研究发现，npm开源项目中大量未标记的安全问题未得到解决，现有自动化工具不足，需要更智能的工具和更好的协作。", "motivation": "尽管npm生态系统中安全漏洞报告和解决已被广泛研究，但用户（和机器人）报告安全问题的实际情况及其相关挑战在大规模研究中相对较少探索。本文旨在弥补这一空白。", "method": "收集了来自45,466个不同npm包的GitHub仓库中的10,907,467个问题报告。通过人工分析，然后开发高精度机器学习模型，识别出未标记为安全相关的问题。", "result": "标签显示只有0.13%的问题是安全相关的。通过分析识别出1,617,738个未标记为安全相关的问题（占总问题的14.8%）是安全相关的，以及这些问题上的4,461,934条评论。现有机器人不足以检测或提供帮助。许多用户报告的安全问题可能未被开发者处理，它们未被标记为安全相关且可能在没有正当理由的情况下被关闭。开发者能快速处理有已知解决方案（如CVE）的安全问题。没有已知解决方案（即使有可复现代码）的安全问题可能未被解决。", "conclusion": "研究结果为改进开源生态系统中的安全管理提供了可操作的见解，强调了对更智能工具和更好协作的需求。", "translation": "npm（Node Package Manager）生态系统是JavaScript开发最重要的包管理器，拥有数百万用户。因此，大量早期工作研究了如何促进此类生态系统中的漏洞报告、补丁传播以及安全问题的检测和解决。然而，用户（和机器人）报告安全相关问题的实际情况及其相关挑战在大规模研究中相对较少探索。在这项工作中，我们通过收集来自45,466个不同npm包的GitHub仓库中的10,907,467个问题报告来弥补这一空白。我们发现，与这些问题相关的标签表明只有0.13%的安全相关问题。然而，我们采用人工分析，然后开发高精度机器学习模型的方法识别出1,617,738个未标记为安全相关的问题（占所有问题的14.8%）以及对这些问题提出的4,461,934条评论。我们发现，当今广泛使用的机器人可能不足以检测或提供帮助。此外，我们对用户-开发者交互数据的分析表明，许多用户报告的安全问题可能未被开发者处理——它们未被标记为安全相关问题，并且可能在没有正当理由的情况下被关闭。因此，相关性分析表明，开发者能快速处理有已知解决方案（例如，对应CVE）的安全问题。然而，没有已知解决方案（即使有可复现代码）的安全问题可能未被解决。我们的发现为改进开源生态系统中的安全管理提供了可操作的见解，强调了对更智能工具和更好协作的需求。这项工作的数据和代码可在https://doi.org/10.5281/zenodo.15614029获取。", "summary": "本文通过对GitHub上npm包的大规模问题报告进行数据驱动分析，揭示了开源生态系统中安全问题报告的实际挑战。研究发现，大量安全问题未被正确标记和处理，现有自动化工具不足以有效识别和解决这些问题。作者指出，开发者倾向于处理有已知解决方案的安全问题，而那些没有已知解决方案的问题常被忽视。研究强调了开发更智能工具和加强协作以改善开源安全管理的必要性。", "keywords": "安全问题报告, npm, GitHub, 开源安全, 机器学习", "comments": "这篇论文通过大规模数据分析揭示了开源项目（特别是npm生态系统）中安全问题报告和处理的真实图景，具有重要的实践意义。其创新之处在于结合了人工分析和机器学习模型来识别被忽视的安全问题，挑战了当前自动化工具的有效性。论文强调了用户-开发者交互中安全问题处理的不足，并指出了改进方向，即需要更智能的工具和更好的协作。这对于开源社区的安全管理和漏洞响应具有指导价值。"}}
{"id": "2506.07271", "title": "Machine Learning-Based Self-Localization Using Internal Sensors for Automating Bulldozers", "authors": ["Hikaru Sawafuji", "Ryota Ozaki", "Takuto Motomura", "Toyohisa Matsuda", "Masanori Tojima", "Kento Uchida", "Shinichi Shirakawa"], "summary": "Self-localization is an important technology for automating bulldozers.\nConventional bulldozer self-localization systems rely on RTK-GNSS (Real Time\nKinematic-Global Navigation Satellite Systems). However, RTK-GNSS signals are\nsometimes lost in certain mining conditions. Therefore, self-localization\nmethods that do not depend on RTK-GNSS are required. In this paper, we propose\na machine learning-based self-localization method for bulldozers. The proposed\nmethod consists of two steps: estimating local velocities using a machine\nlearning model from internal sensors, and incorporating these estimates into an\nExtended Kalman Filter (EKF) for global localization. We also created a novel\ndataset for bulldozer odometry and conducted experiments across various driving\nscenarios, including slalom, excavation, and driving on slopes. The result\ndemonstrated that the proposed self-localization method suppressed the\naccumulation of position errors compared to kinematics-based methods,\nespecially when slip occurred. Furthermore, this study showed that\nbulldozer-specific sensors, such as blade position sensors and hydraulic\npressure sensors, contributed to improving self-localization accuracy.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07271v1", "AI": {"title_translation": "机器学习辅助的推土机自动化内部传感器自定位", "tldr": "提出了一种基于机器学习的推土机自定位方法，利用内部传感器在RTK-GNSS信号丢失时提高定位精度。", "motivation": "传统推土机自定位系统依赖RTK-GNSS，但在某些采矿条件下信号会丢失，因此需要不依赖RTK-GNSS的自定位方法。", "method": "提出的方法包括两步：1) 使用机器学习模型从内部传感器估计局部速度；2) 将这些估计值整合到扩展卡尔曼滤波器(EKF)中进行全局定位。还创建了新的推土机里程计数据集，并在多种驾驶场景下进行实验。", "result": "提出的自定位方法相比基于运动学的方法抑制了位置误差的积累，尤其是在打滑时。此外，推土机专用传感器（如铲刀位置传感器和液压传感器）有助于提高自定位精度。", "conclusion": "该研究成功开发了一种不依赖RTK-GNSS的推土机自定位方法，并通过结合机器学习和内部传感器显著提高了在复杂工况下的定位精度和鲁棒性。", "translation": "自定位是推土机自动化的一项重要技术。\n传统的推土机自定位系统依赖于RTK-GNSS（实时动态-全球导航卫星系统）。然而，在某些采矿条件下，RTK-GNSS信号有时会丢失。因此，需要不依赖RTK-GNSS的自定位方法。在本文中，我们提出了一种基于机器学习的推土机自定位方法。所提出的方法包括两个步骤：使用机器学习模型从内部传感器估计局部速度，并将这些估计值整合到扩展卡尔曼滤波器（EKF）中进行全局定位。我们还创建了一个新的推土机里程计数据集，并在包括S形弯道、挖掘和坡道行驶在内的各种驾驶场景中进行了实验。结果表明，与基于运动学的方法相比，所提出的自定位方法抑制了位置误差的积累，尤其是在打滑发生时。此外，这项研究表明，推土机专用传感器，如铲刀位置传感器和液压传感器，有助于提高自定位精度。", "summary": "本文针对传统推土机自定位系统在RTK-GNSS信号丢失时面临的挑战，提出了一种基于机器学习的内部传感器自定位方法。该方法通过机器学习模型估计局部速度，并将其融合到扩展卡尔曼滤波器中进行全局定位。实验结果表明，该方法在抑制位置误差积累方面优于传统方法，尤其在打滑条件下表现出色，并且推土机专用传感器对提高定位精度有显著贡献。", "keywords": "推土机自定位, 机器学习, 内部传感器, 扩展卡尔曼滤波器, RTK-GNSS", "comments": "该论文的创新之处在于提出了一种不依赖RTK-GNSS的推土机自定位方案，解决了传统方法在特定工况下信号丢失的问题。通过结合机器学习和内部传感器数据，提高了定位的鲁棒性和精度，尤其是在复杂和易打滑的环境中。创建新的专用数据集也为后续研究提供了宝贵资源。这项研究对于实现推土机在恶劣环境下的完全自动化具有重要意义。"}}
{"id": "2506.06826", "title": "Controllable Coupled Image Generation via Diffusion Models", "authors": ["Chenfei Yuan", "Nanshan Jia", "Hangqi Li", "Peter W. Glynn", "Zeyu Zheng"], "summary": "We provide an attention-level control method for the task of coupled image\ngeneration, where \"coupled\" means that multiple simultaneously generated images\nare expected to have the same or very similar backgrounds. While backgrounds\ncoupled, the centered objects in the generated images are still expected to\nenjoy the flexibility raised from different text prompts. The proposed method\ndisentangles the background and entity components in the model's\ncross-attention modules, attached with a sequence of time-varying weight\ncontrol parameters depending on the time step of sampling. We optimize this\nsequence of weight control parameters with a combined objective that assesses\nhow coupled the backgrounds are as well as text-to-image alignment and overall\nvisual quality. Empirical results demonstrate that our method outperforms\nexisting approaches across these criteria.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06826v1", "AI": {"title_translation": "通过扩散模型实现可控耦合图像生成", "tldr": "本文提出了一种基于注意力层控制的方法，用于生成背景相似但前景物体可变的耦合图像，并通过优化权重控制参数在性能上超越现有方法。", "motivation": "在耦合图像生成任务中，需要生成多张背景相同或相似但中心物体可以根据不同文本提示灵活变化图像。现有方法可能难以同时实现背景耦合和前景灵活性的平衡。", "method": "本文提出了一种注意力层控制方法。该方法在模型的交叉注意力模块中解耦了背景和实体组件，并附加了一系列随时间步变化的权重控制参数。通过结合评估背景耦合度、文本到图像对齐以及整体视觉质量的目标函数来优化这些权重控制参数。", "result": "实证结果表明，在背景耦合度、文本到图像对齐和整体视觉质量等标准上，本文方法优于现有方法。", "conclusion": "本文提出的注意力层控制方法能够有效地实现可控的耦合图像生成，在保持背景一致性的同时，允许前景物体根据不同的文本提示进行灵活变化，并展现出优于现有方法的性能。", "translation": "我们为耦合图像生成任务提供了一种注意力层控制方法，“耦合”意味着多个同时生成的图像预期具有相同或非常相似的背景。在背景耦合的同时，生成的图像中的中心对象仍然有望享受不同文本提示带来的灵活性。所提出的方法在模型的交叉注意力模块中解耦了背景和实体组件，并附加了一系列取决于采样时间步的随时间变化的权重控制参数。我们通过一个组合目标来优化这一系列权重控制参数，该目标评估背景的耦合程度以及文本到图像的对齐和整体视觉质量。实证结果表明，我们的方法在这些标准上优于现有方法。", "summary": "本研究提出了一种基于扩散模型的注意力层控制方法，用于实现可控的耦合图像生成。该方法通过在交叉注意力模块中解耦背景和前景实体，并引入随时间变化的权重控制参数来优化背景耦合度、文本到图像对齐和视觉质量。实验结果表明，该方法在生成背景一致且前景灵活的耦合图像方面优于现有技术。", "keywords": "耦合图像生成, 扩散模型, 注意力控制, 图像生成, 交叉注意力", "comments": "这项工作创新性地提出了在扩散模型中通过注意力层控制实现耦合图像生成，有效地解决了背景一致性和前景多样性之间的平衡问题。这种精细化的控制方法为图像生成带来了新的可能性，尤其是在需要生成系列图像时。未来的工作可以探索这种控制方法在更多复杂场景或多模态生成中的应用。"}}
{"id": "2506.06935", "title": "An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design", "authors": ["Darui Lu", "Jordan M. Malof", "Willie J. Padilla"], "summary": "Recent significant advances in integrating multiple Large Language Model\n(LLM) systems have enabled Agentic Frameworks capable of performing complex\ntasks autonomously, including novel scientific research. We develop and\ndemonstrate such a framework specifically for the inverse design of photonic\nmetamaterials. When queried with a desired optical spectrum, the Agent\nautonomously proposes and develops a forward deep learning model, accesses\nexternal tools via APIs for tasks like simulation and optimization, utilizes\nmemory, and generates a final design via a deep inverse method. The framework's\neffectiveness is demonstrated in its ability to automate, reason, plan, and\nadapt. Notably, the Agentic Framework possesses internal reflection and\ndecision flexibility, permitting highly varied and potentially novel outputs.", "comment": "22 pages, 6 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06935v1", "AI": {"title_translation": "用于自主超材料建模和逆向设计的智能体框架", "tldr": "该研究开发了一个基于LLM的智能体框架，用于光子超材料的自主逆向设计，能够自动化、推理、规划和适应。", "motivation": "近期多LLM系统集成的显著进展使得智能体框架能够自主执行复杂任务，包括新型科学研究。本研究旨在开发并演示一个专门用于光子超材料逆向设计的智能体框架。", "method": "开发了一个智能体框架，当被查询所需光谱时，该智能体自主提出并开发一个正向深度学习模型，通过API访问外部工具进行仿真和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。", "result": "该框架在自动化、推理、规划和适应方面表现出有效性。值得注意的是，该智能体框架具有内部反思和决策灵活性，允许高度多样化和潜在新颖的输出。", "conclusion": "该智能体框架在光子超材料的自主逆向设计中表现出有效性，能够自动化、推理、规划和适应，并具有生成多样化和新颖输出的潜力。", "translation": "近期多大型语言模型（LLM）系统集成的显著进展，使得智能体框架能够自主执行复杂任务，包括新型科学研究。我们开发并演示了这样一个专门用于光子超材料逆向设计的框架。当被查询所需光学光谱时，该智能体自主提出并开发一个正向深度学习模型，通过API访问外部工具进行仿真和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。该框架的有效性体现在其自动化、推理、规划和适应的能力。值得注意的是，该智能体框架具有内部反思和决策灵活性，允许高度多样化和潜在新颖的输出。", "summary": "本研究开发了一个基于大型语言模型（LLM）的智能体框架，专门用于光子超材料的自主建模和逆向设计。该框架能够根据所需光学光谱，自主构建深度学习正向模型，利用外部API进行仿真和优化，并通过深度逆向方法生成最终设计。实验证明，该框架在自动化、推理、规划和适应方面表现出色，并具备内部反思和决策灵活性，能够产生多样化甚至新颖的设计。", "keywords": "智能体框架, 超材料, 逆向设计, 大型语言模型, 深度学习", "comments": "该论文的创新之处在于将LLM驱动的智能体框架应用于复杂的科学研究领域，特别是光子超材料的自主逆向设计。这种框架通过集成多种LLM系统和外部工具，显著提升了设计过程的自动化和智能化水平，展现了LLM在科学发现和工程设计中作为自主代理的巨大潜力。其内部反思和决策灵活性预示着能够生成超越传统方法的创新性解决方案。"}}
{"id": "2506.06501", "title": "Optimal Rates in Continual Linear Regression via Increasing Regularization", "authors": ["Ran Levinstein", "Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren", "Daniel Soudry", "Itay Evron"], "summary": "We study realizable continual linear regression under random task orderings,\na common setting for developing continual learning theory. In this setup, the\nworst-case expected loss after $k$ learning iterations admits a lower bound of\n$\\Omega(1/k)$. However, prior work using an unregularized scheme has only\nestablished an upper bound of $O(1/k^{1/4})$, leaving a significant gap. Our\npaper proves that this gap can be narrowed, or even closed, using two\nfrequently used regularization schemes: (1) explicit isotropic $\\ell_2$\nregularization, and (2) implicit regularization via finite step budgets. We\nshow that these approaches, which are used in practice to mitigate forgetting,\nreduce to stochastic gradient descent (SGD) on carefully defined surrogate\nlosses. Through this lens, we identify a fixed regularization strength that\nyields a near-optimal rate of $O(\\log k / k)$. Moreover, formalizing and\nanalyzing a generalized variant of SGD for time-varying functions, we derive an\nincreasing regularization strength schedule that provably achieves an optimal\nrate of $O(1/k)$. This suggests that schedules that increase the regularization\ncoefficient or decrease the number of steps per task are beneficial, at least\nin the worst case.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06501v1", "AI": {"title_translation": "通过增加正则化实现持续线性回归的最优速率", "tldr": "本文证明了通过增加正则化可以使持续线性回归达到最优学习速率，从而缩小了现有理论中的显著差距。", "motivation": "在持续线性回归中，先前的工作在最坏情况下的预期损失的上界和下界之间存在显著差距（从 $O(1/k^{1/4})$ 到 $\\Omega(1/k)$），本文旨在缩小甚至消除这一差距。", "method": "本文采用了两种常用正则化方案：(1) 显式各向同性 $\\ell_2$ 正则化，和 (2) 通过有限步长预算的隐式正则化。研究表明，这些方法可以归结为对精心定义的替代损失进行随机梯度下降 (SGD)。在此基础上，他们识别出一种固定正则化强度可以达到近似最优速率，并通过形式化和分析一种用于时变函数的广义 SGD 变体，推导出了一个可证明达到最优速率的递增正则化强度调度。", "result": "固定正则化强度可实现接近最优的 $O(\\log k / k)$ 速率。通过递增正则化强度调度（或减少每个任务的步数），可证明达到最优的 $O(1/k)$ 速率。", "conclusion": "增加正则化系数或减少每个任务的步数对于实现持续线性回归中的最优速率是有益的，至少在最坏情况下是如此。", "translation": "我们研究在随机任务排序下的可实现持续线性回归，这是发展持续学习理论的常见设置。在此设置中，经过 $k$ 次学习迭代后的最坏情况预期损失存在 $\\Omega(1/k)$ 的下界。然而，先前使用无正则化方案的工作仅建立了 $O(1/k^{1/4})$ 的上界，留下了显著的差距。我们的论文证明，使用两种常用正则化方案可以缩小甚至消除这一差距：(1) 显式各向同性 $\\ell_2$ 正则化，和 (2) 通过有限步长预算的隐式正则化。我们表明，这些在实践中用于减轻遗忘的方法，可以归结为在精心定义的替代损失上进行随机梯度下降 (SGD)。通过这种视角，我们确定了一种固定正则化强度，可以产生接近最优的 $O(\\log k / k)$ 速率。此外，通过形式化和分析一种用于时变函数的广义 SGD 变体，我们推导出了一个可证明达到最优的 $O(1/k)$ 速率的递增正则化强度调度。这表明，增加正则化系数或减少每个任务步数的调度是有益的，至少在最坏情况下是如此。", "summary": "本文解决了持续线性回归中最优速率的差距问题。研究表明，显式 $\\ell_2$ 正则化和隐式正则化（它们都映射到替代损失上的随机梯度下降）可以显著提高性能。固定正则化强度可实现接近最优的 $O(\\log k / k)$ 速率，而递增正则化调度则能达到最优的 $O(1/k)$ 速率，这表明此类调度在持续学习中的益处。", "keywords": "持续学习, 线性回归, 正则化, 最优速率, 随机梯度下降", "comments": "该论文通过使用正则化解决了持续线性回归中最优速率的差距，做出了重要的理论贡献。它通过将正则化与随机梯度下降联系起来，并提出了对持续学习有益的调度策略，为减轻遗忘提供了实用的见解，这对于持续学习至关重要。"}}
{"id": "2506.06332", "title": "Introduction to Predictive Coding Networks for Machine Learning", "authors": ["Mikko Stenlund"], "summary": "Predictive coding networks (PCNs) constitute a biologically inspired\nframework for understanding hierarchical computation in the brain, and offer an\nalternative to traditional feedforward neural networks in ML. This note serves\nas a quick, onboarding introduction to PCNs for machine learning practitioners.\nWe cover the foundational network architecture, inference and learning update\nrules, and algorithmic implementation. A concrete image-classification task\n(CIFAR-10) is provided as a benchmark-smashing application, together with an\naccompanying Python notebook containing the PyTorch implementation.", "comment": "22 pages", "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06332v1", "AI": {"title_translation": "机器学习的预测编码网络介绍", "tldr": "本文旨在为机器学习从业者介绍预测编码网络（PCNs），涵盖其架构、更新规则，并提供一个使用PyTorch实现CIFAR-10图像分类的案例。", "motivation": "本文旨在为机器学习从业者提供预测编码网络（PCNs）的快速入门介绍，PCNs作为一种受生物学启发的框架，为机器学习中的传统前馈神经网络提供了一种替代方案。", "method": "本文涵盖了预测编码网络的基础网络架构、推理和学习更新规则，以及算法实现。通过一个具体的图像分类任务（CIFAR-10）作为应用案例，并提供了一个包含PyTorch实现的Python笔记本。", "result": "提供了一个在CIFAR-10图像分类任务上表现出色的应用案例，并附带了相应的PyTorch实现Python笔记本。", "conclusion": "本文作为预测编码网络的入门介绍，提供了其在机器学习中应用的具体实现和性能展示，表明PCNs是传统神经网络的有效替代方案。", "translation": "预测编码网络（PCN）是一种受生物学启发的框架，用于理解大脑中的分层计算，并为机器学习中的传统前馈神经网络提供了一种替代方案。本笔记旨在为机器学习从业者快速、入门级地介绍PCN。我们涵盖了基础网络架构、推理和学习更新规则以及算法实现。提供了一个具体的图像分类任务（CIFAR-10）作为一项“打破基准”的应用，并附带了一个包含PyTorch实现的Python笔记本。", "summary": "本文为机器学习从业者提供了预测编码网络（PCNs）的入门指南，详细介绍了其基本架构、推理和学习更新规则以及算法实现。文中通过CIFAR-10图像分类任务展示了PCNs的实际应用，并提供了相应的PyTorch实现。", "keywords": "预测编码网络, 机器学习, 神经网络, CIFAR-10, PyTorch", "comments": "本文的重要性在于它向机器学习领域引入了一种受生物学启发的新型网络架构，即预测编码网络，为传统前馈神经网络提供了替代方案。通过提供具体的实现细节和PyTorch代码，极大地降低了实践者学习和应用PCNs的门槛。其在CIFAR-10任务上的“打破基准”表现，虽然抽象中未详细说明，但暗示了PCNs的强大潜力。"}}
{"id": "2506.07827", "title": "User-space library rootkits revisited: Are user-space detection mechanisms futile?", "authors": ["Enrique Soriano-Salvador", "Gorka Guardiola Múzquiz", "Juan González Gómez"], "summary": "The kind of malware designed to conceal malicious system resources (e.g.\nprocesses, network connections, files, etc.) is commonly referred to as a\nrootkit. This kind of malware represents a significant threat in contemporany\nsystems. Despite the existence of kernel-space rootkits (i.e. rootkits that\ninfect the operating system kernel), user-space rootkits (i.e. rootkits that\ninfect the user-space operating system tools, commands and libraries) continue\nto pose a significant danger. However, kernel-space rootkits attract all the\nattention, implicitly assuming that user-space rootkits (malware that is still\nin existence) are easily detectable by well-known user-space tools that look\nfor anomalies. The primary objective of this work is to answer the following\nquestion: Is detecting user-space rootkits with user-space tools futile?\nContrary to the prevailing view that considers it effective, we argue that the\ndetection of user-space rootkits cannot be done in user-space at all. Moreover,\nthe detection results must be communicated to the user with extreme caution. To\nsupport this claim, we conducted different experiments focusing on process\nconcealing in Linux systems. In these experiments, we evade the detection\nmechanisms widely accepted as the standard solution for this type of user-space\nmalware, bypassing the most popular open source anti-rootkit tool for process\nhiding. This manuscript describes the classical approach to build user-space\nlibrary rootkits, the traditional detection mechanisms, and different evasion\ntechniques (it also includes understandable code snippets and examples). In\naddition, it offers some guidelines to implement new detection tools and\nimprove the existing ones to the extent possible.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07827v1", "AI": {"title_translation": "用户空间库rootkit再探：用户空间检测机制是否徒劳？", "tldr": "研究表明，用于检测用户空间rootkit的用户空间工具是无效的，因为它们可以被规避。", "motivation": "尽管用户空间rootkit仍构成重大威胁，但人们普遍认为它们易于被用户空间工具检测到，而所有关注都集中在内核空间rootkit上。本研究旨在反驳这一假设。", "method": "通过在Linux系统上进行针对进程隐藏的实验，规避了被广泛接受的用户空间反rootkit工具的检测机制。", "result": "结果表明，用户空间rootkit的检测根本无法在用户空间完成，且检测结果必须极其谨慎地传达给用户。", "conclusion": "传统的用户空间rootkit检测机制是无效的，并提供了实现新检测工具和改进现有工具的指导。", "translation": "恶意软件旨在隐藏恶意系统资源（例如进程、网络连接、文件等），通常被称为rootkit。这种恶意软件在当代系统中构成了重大威胁。尽管存在内核空间rootkit（即感染操作系统内核的rootkit），用户空间rootkit（即感染用户空间操作系统工具、命令和库的rootkit）仍然构成重大危险。然而，内核空间rootkit吸引了所有注意力，这隐含地假设用户空间rootkit（仍然存在的恶意软件）很容易通过寻找异常的知名用户空间工具检测到。这项工作的主要目的是回答以下问题：使用用户空间工具检测用户空间rootkit是否徒劳？与普遍认为其有效的观点相反，我们认为用户空间rootkit的检测根本无法在用户空间完成。此外，检测结果必须极其谨慎地传达给用户。为了支持这一主张，我们进行了不同的实验，重点关注Linux系统中的进程隐藏。在这些实验中，我们规避了被广泛接受为此类用户空间恶意软件标准解决方案的检测机制，绕过了最流行的开源进程隐藏反rootkit工具。本手稿描述了构建用户空间库rootkit的经典方法、传统检测机制以及不同的规避技术（它还包括易于理解的代码片段和示例）。此外，它还提供了一些实现新检测工具和尽可能改进现有工具的指导方针。", "summary": "本文探讨了用户空间rootkit的检测问题，挑战了普遍认为用户空间工具可以有效检测它们的观点。通过在Linux系统上进行实验，研究表明用户空间检测机制容易被规避，尤其是在进程隐藏方面。因此，作者得出结论，用户空间rootkit无法在用户空间完全检测，并强调了检测结果沟通的谨慎性，同时提供了改进检测工具的指导。", "keywords": "用户空间rootkit, 检测机制, 进程隐藏, Linux安全, 反rootkit", "comments": "这篇论文挑战了安全领域中一个普遍存在的假设，即用户空间rootkit易于检测。其发现对于用户空间安全工具的有效性提出了重要质疑，并强调了需要更复杂的跨层检测机制。论文通过实验验证了其主张，并提供了实用的改进建议，具有重要的理论和实践意义。"}}
{"id": "2506.07283", "title": "Model Analysis And Design Of Ellipse Based Segmented Varying Curved Foot For Biped Robot Walking", "authors": ["Boyang Chen", "Xizhe Zang", "Chao Song", "Yue Zhang", "Jie Zhao"], "summary": "This paper presents the modeling, design, and experimental validation of an\nEllipse-based Segmented Varying Curvature (ESVC) foot for bipedal robots.\nInspired by the segmented curvature rollover shape of human feet, the ESVC foot\naims to enhance gait energy efficiency while maintaining analytical\ntractability for foot location based controller. First, we derive a complete\nanalytical contact model for the ESVC foot by formulating spatial\ntransformations of elliptical segments only using elementary functions. Then a\nnonlinear programming approach is engaged to determine optimal elliptical\nparameters of hind foot and fore foot based on a known mid-foot. An error\ncompensation method is introduced to address approximation inaccuracies in\nrollover length calculation. The proposed ESVC foot is then integrated with a\nHybrid Linear Inverted Pendulum model-based walking controller and validated\nthrough both simulation and physical experiments on the TT II biped robot.\nExperimental results across marking time, sagittal, and lateral walking tasks\nshow that the ESVC foot consistently reduces energy consumption compared to\nline, and flat feet, with up to 18.52\\% improvement in lateral walking. These\nfindings demonstrate that the ESVC foot provides a practical and\nenergy-efficient alternative for real-world bipedal locomotion. The proposed\ndesign methodology also lays a foundation for data-driven foot shape\noptimization in future research.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07283v1", "AI": {"title_translation": "双足机器人行走中基于椭圆分段变曲率足的模型分析与设计", "tldr": "本文提出并验证了一种基于椭圆分段变曲率（ESVC）的仿人足机器人脚部设计，该设计通过优化足部形状，显著提高了双足机器人步态能量效率，尤其在侧向行走中节能高达18.52%。", "motivation": "旨在通过受人类足部分段曲率翻滚形状启发的设计，提高双足机器人步态能量效率，同时保持足部位置控制器分析上的易处理性。", "method": "首先，通过仅使用基本函数建立椭圆段的空间变换，推导了ESVC足的完整分析接触模型。然后，采用非线性规划方法，基于已知的中足确定了后足和前足的最佳椭圆参数。引入误差补偿方法来解决翻滚长度计算中的近似不准确性。最后，将ESVC足与基于混合线性倒立摆模型的行走控制器集成，并通过仿真和TT II双足机器人上的物理实验进行验证。", "result": "在原地踏步、矢状面和侧向行走任务中的实验结果表明，与直线形和扁平足相比，ESVC足持续降低了能量消耗，其中侧向行走中能量效率提升高达18.52%。", "conclusion": "ESVC足为实际双足机器人行走提供了一种实用且节能的替代方案。所提出的设计方法也为未来研究中数据驱动的足部形状优化奠定了基础。", "translation": "本文提出并验证了一种用于双足机器人的基于椭圆分段变曲率（ESVC）的足部建模、设计和实验验证。受人类足部分段曲率翻滚形状的启发，ESVC足旨在提高步态能量效率，同时保持足部位置控制器分析上的易处理性。首先，我们通过仅使用基本函数建立椭圆段的空间变换，推导了ESVC足的完整分析接触模型。然后，采用非线性规划方法，基于已知的中足确定了后足和前足的最佳椭圆参数。引入误差补偿方法来解决翻滚长度计算中的近似不准确性。所提出的ESVC足随后与基于混合线性倒立摆模型的行走控制器集成，并通过仿真和TT II双足机器人上的物理实验进行验证。在原地踏步、矢状面和侧向行走任务中的实验结果表明，与直线形和扁平足相比，ESVC足持续降低了能量消耗，其中侧向行走中能量效率提升高达18.52%。这些发现表明，ESVC足为实际双足机器人行走提供了一种实用且节能的替代方案。所提出的设计方法也为未来研究中数据驱动的足部形状优化奠定了基础。", "summary": "本文提出并验证了一种受人类足部启发、基于椭圆分段变曲率（ESVC）的双足机器人足部设计。该设计通过建立分析接触模型、优化椭圆参数并引入误差补偿，旨在提高步态能量效率。结合混合线性倒立摆模型控制器，在仿真和物理实验中，ESVC足在多种行走任务中均显著降低了能量消耗，尤其在侧向行走中实现了高达18.52%的能量效率提升，证明了其在实际双足机器人行走中的实用性和节能性。", "keywords": "双足机器人, 椭圆足, 能量效率, 步态控制, 足部设计", "comments": "这项研究通过仿生学方法，将人类足部的分段曲率特性应用于机器人足部设计，实现了显著的能量效率提升，尤其在侧向行走中的表现突出。其创新点在于提出了完整的分析接触模型和优化的椭圆参数确定方法，并引入了误差补偿机制，确保了设计的精确性和实用性。这项工作不仅为双足机器人的足部设计提供了新的思路和有效方案，也为未来基于数据驱动的足部形状优化研究奠定了基础，具有重要的工程实践和理论研究价值。"}}
{"id": "2506.06830", "title": "EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery", "authors": ["Guankun Wang", "Rui Tang", "Mengya Xu", "Long Bai", "Huxin Gao", "Hongliang Ren"], "summary": "Endoscopic surgery is the gold standard for robotic-assisted minimally\ninvasive surgery, offering significant advantages in early disease detection\nand precise interventions. However, the complexity of surgical scenes,\ncharacterized by high variability in different surgical activity scenarios and\nconfused image features between targets and the background, presents challenges\nfor surgical environment understanding. Traditional deep learning models often\nstruggle with cross-activity interference, leading to suboptimal performance in\neach downstream task. To address this limitation, we explore multi-task\nlearning, which utilizes the interrelated features between tasks to enhance\noverall task performance. In this paper, we propose EndoARSS, a novel\nmulti-task learning framework specifically designed for endoscopy surgery\nactivity recognition and semantic segmentation. Built upon the DINOv2\nfoundation model, our approach integrates Low-Rank Adaptation to facilitate\nefficient fine-tuning while incorporating Task Efficient Shared Low-Rank\nAdapters to mitigate gradient conflicts across diverse tasks. Additionally, we\nintroduce the Spatially-Aware Multi-Scale Attention that enhances feature\nrepresentation discrimination by enabling cross-spatial learning of global\ninformation. In order to evaluate the effectiveness of our framework, we\npresent three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailored\nfor endoscopic surgery scenarios with detailed annotations for both activity\nrecognition and semantic segmentation tasks. Extensive experiments demonstrate\nthat EndoARSS achieves remarkable performance across multiple benchmarks,\nsignificantly improving both accuracy and robustness in comparison to existing\nmodels. These results underscore the potential of EndoARSS to advance AI-driven\nendoscopic surgical systems, offering valuable insights for enhancing surgical\nsafety and efficiency.", "comment": "Accepted by Advanced Intelligent Systems", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06830v1", "AI": {"title_translation": "EndoARSS：在内窥镜手术中适应空间感知基础模型以实现高效活动识别和语义分割", "tldr": "EndoARSS是一个基于DINOv2的多任务学习框架，通过低秩适应和空间感知注意力，显著提升了内窥镜手术中活动识别和语义分割的性能。", "motivation": "内窥镜手术场景复杂，存在高变异性和目标与背景间混淆的图像特征，导致传统深度学习模型在跨活动干扰下性能不佳。", "method": "本文提出了EndoARSS，一个专门为内窥镜手术活动识别和语义分割设计的新型多任务学习框架。该框架建立在DINOv2基础模型之上，集成了低秩适应（Low-Rank Adaptation）以促进高效微调，并引入任务高效共享低秩适应器（Task Efficient Shared Low-Rank Adapters）以缓解不同任务之间的梯度冲突。此外，还引入了空间感知多尺度注意力（Spatially-Aware Multi-Scale Attention）以增强特征表示的辨别力。为评估框架有效性，提出了三个新数据集：MTLESD、MTLEndovis和MTLEndovis-Gen。", "result": "EndoARSS在多个基准测试中取得了卓越的性能，与现有模型相比，显著提高了准确性和鲁棒性。", "conclusion": "EndoARSS有潜力推动AI驱动的内窥镜手术系统发展，为提高手术安全性和效率提供有价值的见解。", "translation": "内窥镜手术是机器人辅助微创手术的黄金标准，在早期疾病检测和精确干预方面具有显著优势。然而，手术场景的复杂性，表现为不同手术活动场景中的高变异性以及目标与背景之间混淆的图像特征，给手术环境理解带来了挑战。传统的深度学习模型常常难以应对跨活动干扰，导致在每个下游任务中表现不佳。为了解决这一局限性，我们探索了多任务学习，它利用任务之间相互关联的特征来提高整体任务性能。在本文中，我们提出了EndoARSS，一个专门为内窥镜手术活动识别和语义分割设计的新型多任务学习框架。我们的方法建立在DINOv2基础模型之上，集成了低秩适应（Low-Rank Adaptation）以促进高效微调，同时结合了任务高效共享低秩适应器（Task Efficient Shared Low-Rank Adapters）以缓解不同任务之间的梯度冲突。此外，我们引入了空间感知多尺度注意力（Spatially-Aware Multi-Scale Attention），通过实现全局信息的跨空间学习来增强特征表示的辨别力。为了评估我们框架的有效性，我们提出了三个新颖的数据集：MTLESD、MTLEndovis和MTLEndovis-Gen，它们专为内窥镜手术场景量身定制，并包含活动识别和语义分割任务的详细标注。广泛的实验表明，EndoARSS在多个基准测试中取得了卓越的性能，与现有模型相比，显著提高了准确性和鲁棒性。这些结果强调了EndoARSS推动AI驱动内窥镜手术系统的潜力，为提高手术安全性和效率提供了有价值的见解。", "summary": "本文提出了EndoARSS，一个用于内窥镜手术活动识别和语义分割的新型多任务学习框架。该框架基于DINOv2基础模型，通过引入低秩适应和任务高效共享低秩适应器来高效微调并解决任务间梯度冲突，同时利用空间感知多尺度注意力增强特征辨别力。研究还发布了三个新数据集。实验证明EndoARSS在准确性和鲁棒性方面均显著优于现有模型，有望提升AI驱动手术系统的性能。", "keywords": "内窥镜手术, 活动识别, 语义分割, 多任务学习, 基础模型", "comments": "该论文的创新点在于将DINOv2基础模型应用于内窥镜手术场景，并结合多任务学习策略，通过引入低秩适应和空间感知注意力机制有效解决了传统模型面临的跨任务干扰和特征辨别力不足的问题。同时，新发布的数据集也为该领域的研究提供了宝贵的资源。其重要性在于显著提升了内窥镜手术环境理解的准确性和效率，对未来AI辅助手术系统的发展具有重要推动作用。"}}
{"id": "2506.06941", "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity", "authors": ["Parshin Shojaee", "Iman Mirzadeh", "Keivan Alizadeh", "Maxwell Horton", "Samy Bengio", "Mehrdad Farajtabar"], "summary": "Recent generations of language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers.\nWhile these models demonstrate improved performance on reasoning benchmarks,\ntheir fundamental capabilities, scaling properties, and limitations remain\ninsufficiently understood. Current evaluations primarily focus on established\nmath and coding benchmarks, emphasizing final answer accuracy. However, this\nevaluation paradigm often suffers from contamination and does not provide\ninsights into the reasoning traces. In this work, we systematically investigate\nthese gaps with the help of controllable puzzle environments that allow precise\nmanipulation of complexity while maintaining consistent logical structures.\nThis setup enables the analysis of not only final answers but also the internal\nreasoning traces, offering insights into how LRMs think. Through extensive\nexperiments, we show that LRMs face a complete accuracy collapse beyond certain\ncomplexities. Moreover, they exhibit a counterintuitive scaling limit: their\nreasoning effort increases with problem complexity up to a point, then declines\ndespite having remaining token budget. By comparing LRMs with their standard\nLLM counterparts under same inference compute, we identify three performance\nregimes: (1) low-complexity tasks where standard models outperform LRMs, (2)\nmedium-complexity tasks where LRMs demonstrates advantage, and (3)\nhigh-complexity tasks where both models face complete collapse. We found that\nLRMs have limitations in exact computation: they fail to use explicit\nalgorithms and reason inconsistently across scales. We also investigate the\nreasoning traces in more depth, studying the patterns of explored solutions and\nanalyzing the models' computational behavior, shedding light on their\nstrengths, limitations, and raising questions about their reasoning\ncapabilities.", "comment": "preprint", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06941v1", "AI": {"title_translation": "思维的幻觉：通过问题复杂性视角理解推理模型的优势与局限", "tldr": "大型推理模型（LRMs）在特定复杂性下准确率会完全崩溃，并且推理努力存在反直觉的缩放限制，揭示了其在精确计算和算法使用上的局限性。", "motivation": "现有对大型推理模型（LRMs）的评估主要集中在数学和编码基准的最终答案准确性，但这种范式存在污染且无法深入了解推理过程。LRMs的基本能力、扩展特性和局限性仍未被充分理解。", "method": "研究人员利用可控的谜题环境，精确操纵复杂性同时保持逻辑结构一致。这种设置不仅分析最终答案，还分析内部推理轨迹，以了解LRMs如何“思考”。通过广泛实验并比较LRMs与标准LLM。", "result": "LRMs在超过一定复杂性后准确率会完全崩溃；LRMs表现出反直觉的缩放限制，推理努力随问题复杂性增加到一定程度后下降；识别出三种性能区域：低复杂性任务（标准模型优于LRMs），中等复杂性任务（LRMs有优势），高复杂性任务（两者均完全崩溃）；LRMs在精确计算方面存在局限性，未能使用显式算法，并在不同尺度上推理不一致；深入研究了推理轨迹，分析了探索解决方案的模式和模型的计算行为。", "conclusion": "LRMs的推理能力存在根本性局限，尤其是在处理高复杂性问题和精确计算方面，其“思考”过程可能只是“思维的幻觉”，而非真正的通用推理。", "translation": "大型语言模型的最新一代引入了大型推理模型（LRMs），这些模型在提供答案之前会生成详细的思维过程。虽然这些模型在推理基准测试中表现出改进的性能，但其基本能力、扩展特性和局限性仍未被充分理解。当前的评估主要侧重于已建立的数学和编码基准，强调最终答案的准确性。然而，这种评估范式常常受到污染，并且无法提供对推理轨迹的深入洞察。在这项工作中，我们借助可控的谜题环境系统地调查了这些差距，这些环境允许精确操纵复杂性同时保持一致的逻辑结构。这种设置不仅能够分析最终答案，还能分析内部推理轨迹，从而深入了解LRMs如何“思考”。通过广泛的实验，我们表明LRMs在超过一定复杂性后准确率会完全崩溃。此外，它们表现出反直觉的缩放限制：它们的推理努力随问题复杂性增加到一定程度后下降，尽管仍有剩余的token预算。通过在相同的推理计算量下比较LRMs与标准LLM对应物，我们确定了三种性能区域：（1）低复杂性任务，标准模型优于LRMs；（2）中等复杂性任务，LRMs表现出优势；（3）高复杂性任务，两种模型都面临完全崩溃。我们发现LRMs在精确计算方面存在局限性：它们未能使用显式算法，并且在不同尺度上推理不一致。我们还更深入地研究了推理轨迹，研究了探索解决方案的模式并分析了模型的计算行为，从而揭示了它们的优势、局限性，并对它们的推理能力提出了疑问。", "summary": "本文系统研究了大型推理模型（LRMs）的能力和局限性，特别关注其在不同复杂性问题上的表现。通过可控的谜题环境，作者发现LRMs在达到一定复杂性后准确率会完全崩溃，并展示出反直觉的推理努力缩放限制。研究还揭示了LRMs在精确计算和算法使用上的不足，并区分了LRMs与标准LLM在不同复杂性任务中的性能区域，对LRMs的真实推理能力提出了质疑。", "keywords": "大型推理模型, 问题复杂性, 准确率崩溃, 推理轨迹, 缩放限制", "comments": "这项研究通过引入可控的谜题环境，创新性地解决了现有推理模型评估范式中污染和缺乏内部推理洞察的问题。其发现的“准确率完全崩溃”和“反直觉缩放限制”对于理解LRMs的深层机制及其应用边界具有重要意义，对未来推理模型的设计和评估提出了新的挑战和方向。它强调了在追求模型复杂性时，更应关注其基础推理能力的本质。"}}
{"id": "2506.06836", "title": "Harnessing Vision-Language Models for Time Series Anomaly Detection", "authors": ["Zelin He", "Sarah Alnegheimish", "Matthew Reimherr"], "summary": "Time-series anomaly detection (TSAD) has played a vital role in a variety of\nfields, including healthcare, finance, and industrial monitoring. Prior\nmethods, which mainly focus on training domain-specific models on numerical\ndata, lack the visual-temporal reasoning capacity that human experts have to\nidentify contextual anomalies. To fill this gap, we explore a solution based on\nvision language models (VLMs). Recent studies have shown the ability of VLMs\nfor visual reasoning tasks, yet their direct application to time series has\nfallen short on both accuracy and efficiency. To harness the power of VLMs for\nTSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening\nstage built on a relatively lightweight pretrained vision encoder, which\nleverages 2-D time-series representations to accurately localize candidate\nanomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal\ncontext and VLM reasoning capacity to refine the detection upon the candidates\nprovided by ViT4TS. We show that without any time-series training, VLM4TS\noutperforms time-series pretrained and from-scratch baselines in most cases,\nyielding a 24.6 percent improvement in F1-max score over the best baseline.\nMoreover, VLM4TS also consistently outperforms existing language-model-based\nTSAD methods and is on average 36 times more efficient in token usage.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06836v1", "AI": {"title_translation": "利用视觉-语言模型进行时间序列异常检测", "tldr": "本文提出了一种两阶段解决方案VLM4TS，利用视觉-语言模型（VLM）进行时间序列异常检测（TSAD），无需时间序列训练即可显著优于现有基线方法。", "motivation": "现有时间序列异常检测方法主要侧重于数值数据上的领域特定模型训练，缺乏人类专家识别上下文异常所具备的视觉-时间推理能力。尽管视觉语言模型（VLMs）在视觉推理任务中表现出色，但直接应用于时间序列的准确性和效率不足。", "method": "本文提出了一种两阶段解决方案：1. ViT4TS：一个基于轻量级预训练视觉编码器的视觉筛选阶段，利用二维时间序列表示准确地定位候选异常。2. VLM4TS：一个基于VLM的阶段，整合全局时间上下文和VLM推理能力，对ViT4TS提供的候选异常进行精细检测。", "result": "VLM4TS在大多数情况下优于时间序列预训练和从头开始的基线方法，F1-max分数比最佳基线提高了24.6%。此外，VLM4TS持续优于现有的基于语言模型的TSAD方法，并且在Token使用效率上平均提高了36倍。", "conclusion": "本文提出了一种新颖的两阶段方法VLM4TS，成功地利用视觉语言模型的能力进行时间序列异常检测，并在准确性和效率方面取得了显著提升，无需时间序列训练。", "translation": "时间序列异常检测（TSAD）在医疗保健、金融和工业监测等多个领域发挥着至关重要的作用。以往的方法主要侧重于在数值数据上训练领域特定模型，缺乏人类专家识别上下文异常所具备的视觉-时间推理能力。为了弥补这一空白，我们探索了一种基于视觉语言模型（VLMs）的解决方案。最近的研究表明VLM在视觉推理任务中具有能力，但它们直接应用于时间序列在准确性和效率上都表现不佳。为了利用VLM的强大能力进行TSAD，我们提出了一种两阶段解决方案：(1) ViT4TS，一个建立在相对轻量级预训练视觉编码器上的视觉筛选阶段，它利用二维时间序列表示来准确地定位候选异常；(2) VLM4TS，一个基于VLM的阶段，它整合了全局时间上下文和VLM推理能力，以在ViT4TS提供的候选基础上细化检测。我们展示了在没有任何时间序列训练的情况下，VLM4TS在大多数情况下优于时间序列预训练和从头开始的基线，与最佳基线相比，F1-max分数提高了24.6%。此外，VLM4TS也持续优于现有的基于语言模型的TSAD方法，并且在Token使用效率上平均提高了36倍。", "summary": "本文提出了一种名为VLM4TS的两阶段时间序列异常检测（TSAD）框架，旨在克服传统方法在视觉-时间推理方面的不足。第一阶段ViT4TS使用轻量级视觉编码器定位候选异常，第二阶段VLM4TS则利用视觉语言模型（VLM）整合全局上下文进行精细化检测。实验证明，VLM4TS无需时间序列训练，在F1-max分数上比现有基线提高了24.6%，并且在Token使用效率上平均提高了36倍，显著优于现有方法。", "keywords": "时间序列异常检测, 视觉-语言模型, VLM4TS, ViT4TS, 视觉推理", "comments": "该论文的创新之处在于将视觉-语言模型（VLM）引入时间序列异常检测领域，通过将时间序列转换为2D表示，并结合VLM的推理能力，弥补了传统方法在上下文视觉-时间推理上的不足。其两阶段设计（ViT4TS进行初步筛选，VLM4TS进行精细化检测）提高了效率和准确性。特别值得注意的是，该方法在不进行时间序列特定训练的情况下，仍能超越现有基线，这表明了VLM在跨领域应用上的巨大潜力。"}}
{"id": "2506.06959", "title": "Deontically Constrained Policy Improvement in Reinforcement Learning Agents", "authors": ["Alena Makarova", "Houssam Abbas"], "summary": "Markov Decision Processes (MDPs) are the most common model for decision\nmaking under uncertainty in the Machine Learning community. An MDP captures\nnon-determinism, probabilistic uncertainty, and an explicit model of action. A\nReinforcement Learning (RL) agent learns to act in an MDP by maximizing a\nutility function. This paper considers the problem of learning a decision\npolicy that maximizes utility subject to satisfying a constraint expressed in\ndeontic logic. In this setup, the utility captures the agent's mission - such\nas going quickly from A to B. The deontic formula represents (ethical, social,\nsituational) constraints on how the agent might achieve its mission by\nprohibiting classes of behaviors. We use the logic of Expected Act\nUtilitarianism, a probabilistic stit logic that can be interpreted over\ncontrolled MDPs. We develop a variation on policy improvement, and show that it\nreaches a constrained local maximum of the mission utility. Given that in stit\nlogic, an agent's duty is derived from value maximization, this can be seen as\na way of acting to simultaneously maximize two value functions, one of which is\nimplicit, in a bi-level structure. We illustrate these results with experiments\non sample MDPs.", "comment": "20 pages, 11 figures, DEON2025 conference", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06959v1", "AI": {"title_translation": "强化学习智能体中受道义约束的策略改进", "tldr": "本文提出了一种在强化学习中，通过道义逻辑约束来学习最大化效用的决策策略的方法，并展示其能达到受约束的局部最大值。", "motivation": "传统的强化学习智能体通过最大化效用函数来学习决策策略，但缺乏对行为的道德、社会或情境约束的考虑。本文旨在解决如何在最大化效用的同时，满足以道义逻辑表达的约束条件的问题。", "method": "论文使用预期行为功利主义逻辑（一种可在受控MDPs上解释的概率性stit逻辑），并开发了一种策略改进的变体。", "result": "所开发的策略改进方法能够使智能体在满足道义约束的同时，达到任务效用的受约束局部最大值。实验结果在示例MDPs上得到了验证。", "conclusion": "该方法可以被视为一种在双层结构中同时最大化两个价值函数（一个显式，一个隐式）的方式，其中智能体的义务源于价值最大化。", "translation": "马尔可夫决策过程（MDPs）是机器学习领域中不确定性下决策最常用的模型。MDP捕捉了非确定性、概率不确定性和明确的行动模型。强化学习（RL）智能体通过最大化效用函数来学习在MDP中行动。本文考虑了学习一种决策策略的问题，该策略在最大化效用的同时，满足以道义逻辑表达的约束。在此设置中，效用捕捉了智能体的任务——例如从A到B快速移动。道义公式表示了对智能体如何完成任务的（伦理、社会、情境）约束，通过禁止某些行为类别。我们使用预期行为功利主义逻辑，这是一种可以在受控MDPs上解释的概率性stit逻辑。我们开发了一种策略改进的变体，并表明它能达到任务效用的受约束局部最大值。鉴于在stit逻辑中，智能体的义务源于价值最大化，这可以被视为一种在双层结构中同时最大化两个价值函数（其中一个隐式）的方式。我们通过在示例MDPs上的实验说明了这些结果。", "summary": "本文探讨了在强化学习中，如何使智能体在最大化任务效用的同时，遵守以道义逻辑表达的伦理、社会或情境约束。研究提出了一种基于预期行为功利主义逻辑的策略改进变体，该方法能够实现受约束的任务效用局部最大化，并可被理解为在双层结构中同时优化显式和隐式价值函数。实验结果验证了该方法的有效性。", "keywords": "强化学习, 道义逻辑, 策略改进, 马尔可夫决策过程, 约束优化", "comments": "这篇论文的创新点在于将道义逻辑引入强化学习的策略改进中，为RL智能体行为的伦理和社会规范提供了形式化约束的框架。它通过修改策略改进算法，使其能够同时考虑效用最大化和行为约束，这对于开发更安全、更符合社会规范的AI系统具有重要意义。该方法将义务视为价值最大化的结果，提出了双层优化的视角，具有理论深度。"}}
{"id": "2506.06521", "title": "Sharp Gap-Dependent Variance-Aware Regret Bounds for Tabular MDPs", "authors": ["Shulun Chen", "Runlong Zhou", "Zihan Zhang", "Maryam Fazel", "Simon S. Du"], "summary": "We consider the gap-dependent regret bounds for episodic MDPs. We show that\nthe Monotonic Value Propagation (MVP) algorithm achieves a variance-aware\ngap-dependent regret bound of $$\\tilde{O}\\left(\\left(\\sum_{\\Delta_h(s,a)>0}\n\\frac{H^2 \\log K \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\n+\\sum_{\\Delta_h(s,a)=0}\\frac{ H^2 \\land\n\\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_{\\mathrm{min}}} + SAH^4 (S \\lor H)\n\\right) \\log K\\right),$$ where $H$ is the planning horizon, $S$ is the number\nof states, $A$ is the number of actions, and $K$ is the number of episodes.\nHere, $\\Delta_h(s,a) =V_h^* (a) - Q_h^* (s, a)$ represents the suboptimality\ngap and $\\Delta_{\\mathrm{min}} := \\min_{\\Delta_h (s,a) > 0} \\Delta_h(s,a)$. The\nterm $\\mathtt{Var}_{\\max}^{\\text{c}}$ denotes the maximum conditional total\nvariance, calculated as the maximum over all $(\\pi, h, s)$ tuples of the\nexpected total variance under policy $\\pi$ conditioned on trajectories visiting\nstate $s$ at step $h$. $\\mathtt{Var}_{\\max}^{\\text{c}}$ characterizes the\nmaximum randomness encountered when learning any $(h, s)$ pair. Our result\nstems from a novel analysis of the weighted sum of the suboptimality gap and\ncan be potentially adapted for other algorithms. To complement the study, we\nestablish a lower bound of $$\\Omega \\left( \\sum_{\\Delta_h(s,a)>0} \\frac{H^2\n\\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\\cdot \\log K\\right),$$\ndemonstrating the necessity of dependence on $\\mathtt{Var}_{\\max}^{\\text{c}}$\neven when the maximum unconditional total variance (without conditioning on\n$(h, s)$) approaches zero.", "comment": "30 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06521v1", "AI": {"title_translation": "表格MDP的尖锐依赖于间隙的方差感知遗憾界限", "tldr": "本文为表格MDPs的MVP算法提供了尖锐的方差感知、依赖于间隙的遗憾界限，并建立了相应的下限，证明了最大条件总方差依赖性的必要性。", "motivation": "研究剧集式MDPs的依赖于间隙的遗憾界限，旨在获得更尖锐的（方差感知）遗憾界限。", "method": "通过对次优性间隙加权和的新颖分析，证明了单调值传播（MVP）算法可以实现方差感知的依赖于间隙的遗憾界限。同时，建立了相应的下限来补充研究。", "result": "MVP算法实现了$$\\tilde{O}\\left(\\left(\\sum_{\\Delta_h(s,a)>0} \\frac{H^2 \\log K \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)} +\\sum_{\\Delta_h(s,a)=0}\\frac{ H^2 \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_{\\mathrm{min}}} + SAH^4 (S \\lor H) \\right) \\log K\\right)$$的方差感知依赖于间隙的遗憾界限。此外，建立了一个下限$$\\Omega \\left( \\sum_{\\Delta_h(s,a)>0} \\frac{H^2 \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\\cdot \\log K\\right)$$，证明了即使在最大无条件总方差接近零的情况下，对$\\mathtt{Var}_{\\max}^{\\text{c}}$的依赖也是必要的。", "conclusion": "本文的结论是，对于表格MDPs，即使在最大无条件总方差接近零的情况下，对最大条件总方差($\\mathtt{Var}_{\\max}^{\\text{c}}$)的依赖也是必要的。MVP算法能够实现尖锐的方差感知、依赖于间隙的遗憾界限。", "translation": "我们考虑了剧集式MDPs的依赖于间隙的遗憾界限。我们展示了单调值传播（MVP）算法实现了方差感知、依赖于间隙的遗憾界限，其形式为$$\\tilde{O}\\left(\\left(\\sum_{\\Delta_h(s,a)>0} \\frac{H^2 \\log K \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)} +\\sum_{\\Delta_h(s,a)=0}\\frac{ H^2 \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_{\\mathrm{min}}} + SAH^4 (S \\lor H) \\right) \\log K\\right)$$，其中$H$是规划范围，$S$是状态数，$A$是动作数，$K$是剧集数。这里，$\\Delta_h(s,a) =V_h^* (a) - Q_h^* (s, a)$表示次优性间隙，$\\Delta_{\\mathrm{min}} := \\min_{\\Delta_h (s,a) > 0} \\Delta_h(s,a)$。$\\mathtt{Var}_{\\max}^{\\text{c}}$表示最大条件总方差，计算方式为在策略$\\pi$下，以轨迹访问状态$s$在步骤$h$为条件，所有$(\\pi, h, s)$元组的期望总方差的最大值。$\\mathtt{Var}_{\\max}^{\\text{c}}$表征了学习任何$(h, s)$对时遇到的最大随机性。我们的结果源于对次优性间隙加权和的新颖分析，并可能适用于其他算法。为了补充这项研究，我们建立了一个下限$$\\Omega \\left( \\sum_{\\Delta_h(s,a)>0} \\frac{H^2 \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\\cdot \\log K\\right)$$，证明了即使在最大无条件总方差（不以$(h, s)$为条件）接近零的情况下，对$\\mathtt{Var}_{\\max}^{\\text{c}}$的依赖也是必要的。", "summary": "本文研究了剧集式MDPs的依赖于间隙的遗憾界限。作者证明了单调值传播（MVP）算法能够实现一个尖锐的方差感知、依赖于间隙的遗憾界限。该界限的推导基于对次优性间隙加权和的新颖分析。为了验证结果的必要性，论文还建立了一个下限，明确指出即使在最大无条件总方差极低的情况下，对最大条件总方差$\\mathtt{Var}_{\\max}^{\\text{c}}$的依赖也是不可或缺的。", "keywords": "MDPs, 遗憾界限, 方差感知, 次优性间隙, MVP算法", "comments": "这项工作通过引入方差感知和依赖于间隙的遗憾界限，并提供了一个匹配的下限，为表格MDPs的遗憾分析做出了重要贡献。MVP算法及其新颖的分析方法是其创新点。特别是，下限的建立有力地证明了在学习过程中考虑条件方差的重要性，即使在非条件方差较低的情况下也是如此，这对于理解强化学习算法的根本限制具有重要意义。"}}
{"id": "2506.06334", "title": "Preference-based learning for news headline recommendation", "authors": ["Alexandre Bouras", "Audrey Durand", "Richard Khoury"], "summary": "This study explores strategies for optimizing news headline recommendations\nthrough preference-based learning. Using real-world data of user interactions\nwith French-language online news posts, we learn a headline recommender agent\nunder a contextual bandit setting. This allows us to explore the impact of\ntranslation on engagement predictions, as well as the benefits of different\ninteractive strategies on user engagement during data collection. Our results\nshow that explicit exploration may not be required in the presence of noisy\ncontexts, opening the door to simpler but efficient strategies in practice.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06334v1", "AI": {"title_translation": "新闻标题推荐中的偏好学习", "tldr": "本研究探讨了在语境多臂老虎机设置下，通过偏好学习优化新闻标题推荐策略，并发现有噪声语境下可能不需要显式探索。", "motivation": "本研究的动机是探索优化新闻标题推荐的策略，并评估翻译对用户参与度预测的影响以及不同交互策略在数据收集过程中对用户参与度的益处。", "method": "本研究使用真实世界的法语在线新闻用户交互数据，在语境多臂老虎机（contextual bandit）设置下学习了一个新闻标题推荐代理。", "result": "研究结果表明，在存在噪声语境的情况下，可能不需要显式探索。", "conclusion": "在有噪声语境的实际应用中，可以采用更简单但高效的策略进行新闻标题推荐，而无需进行显式探索。", "translation": "本研究探讨了通过基于偏好学习来优化新闻标题推荐的策略。我们利用用户与法语在线新闻帖子互动的真实世界数据，在语境多臂老虎机设置下学习了一个新闻标题推荐代理。这使我们能够探索翻译对参与度预测的影响，以及不同交互策略在数据收集过程中对用户参与度的益处。我们的结果表明，在存在噪声语境的情况下，可能不需要显式探索，这为实践中更简单但高效的策略打开了大门。", "summary": "本研究旨在通过偏好学习优化新闻标题推荐。研究利用真实的法语用户交互数据，在语境多臂老虎机框架下构建推荐代理，以探究翻译对用户参与度预测的影响以及不同交互策略的效益。核心发现是在噪声语境下，显式探索可能并非必需，这为实际应用提供了更简洁高效的推荐策略。", "keywords": "偏好学习, 新闻标题推荐, 语境多臂老虎机, 用户参与度, 在线推荐", "comments": "这项研究的创新之处在于将偏好学习应用于新闻标题推荐，并特别关注了在语境多臂老虎机设置下，翻译对用户参与度预测的影响。其发现显式探索在噪声语境下可能不必要，为实际系统设计提供了简化和效率提升的潜力，具有重要的实践意义。"}}
{"id": "2506.07868", "title": "Securing Unbounded Differential Privacy Against Timing Attacks", "authors": ["Zachary Ratliff", "Salil Vadhan"], "summary": "Recent works have started to theoretically investigate how we can protect\ndifferentially private programs against timing attacks, by making the joint\ndistribution the output and the runtime differentially private (JOT-DP).\nHowever, the existing approaches to JOT-DP have some limitations, particularly\nin the setting of unbounded DP (which protects the size of the dataset and\napplies to arbitrarily large datasets). First, the known conversion of pure DP\nprograms to pure JOT-DP programs in the unbounded setting (a) incurs a constant\nadditive increase in error probability (and thus does not provide vanishing\nerror as $n\\to\\infty$) (b) produces JOT-DP programs that fail to preserve the\ncomputational efficiency of the original pure DP program and (c) is analyzed in\na toy computational model in which the runtime is defined to be the number of\ncoin flips. In this work, we overcome these limitations. Specifically, we show\nthat the error required for pure JOT-DP in the unbounded setting depends on the\nmodel of computation. In a randomized RAM model where the dataset size $n$ is\ngiven (or can be computed in constant time) and we can generate random numbers\n(not just random bits) in constant time, polynomially small error probability\nis necessary and sufficient. If $n$ is not given or we only have a random-bit\ngenerator, an (arbitrarily small) constant error probability is necessary and\nsufficient. The aforementioned positive results are proven by efficient\nprocedures to convert any pure JOT-DP program $P$ in the upper-bounded setting\nto a pure JOT-DP program $P'$ in the unbounded setting, such that the output\ndistribution of $P'$ is $\\gamma$-close in total variation distance to that of\n$P$, where $\\gamma$ is either an arbitrarily small constant or polynomially\nsmall, depending on the model of computation.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07868v1", "AI": {"title_translation": "保护无界差分隐私免受时序攻击", "tldr": "现有针对无界差分隐私的JOT-DP方法存在误差、效率和计算模型限制。本文通过分析误差与计算模型（RAM与随机比特）的关系，并提供高效的转换程序来克服这些限制。", "motivation": "现有的JOT-DP方法在无界差分隐私（适用于任意大数据集）设置中存在局限性，包括导致常数加性错误概率（无法实现误差消失）、未能保持原始程序的计算效率，以及在过于简化的计算模型（运行时仅定义为抛硬币次数）下进行分析。", "method": "本文研究了在无界设置中纯JOT-DP所需的误差与计算模型的关系。作者提出了将上界设置中的纯JOT-DP程序高效转换为无界设置中纯JOT-DP程序的方法。这些转换程序确保新程序的输出分布与原程序在总变差距离上接近，其接近度（γ）根据所使用的计算模型而异。", "result": "在随机RAM模型中（数据集大小n已知或可快速计算，且可快速生成随机数），多项式小误差概率是必要且充分的。如果数据集大小n未知或仅有随机比特生成器，则任意小的常数误差概率是必要且充分的。这些积极结果通过高效的转换程序得以证明。", "conclusion": "本文克服了现有无界差分隐私JOT-DP方法的局限性，证明了所需误差取决于计算模型，并提供了高效的转换方法，从而在更实际的模型下实现了误差消失和效率保持。", "translation": "最近的工作开始从理论上研究如何通过使输出和运行时的联合分布具有差分隐私性（JOT-DP）来保护差分隐私程序免受时序攻击。然而，现有的JOT-DP方法存在一些局限性，特别是在无界差分隐私（保护数据集大小并适用于任意大数据集）的设置中。首先，在无界设置中将纯DP程序转换为纯JOT-DP程序的已知方法：(a) 会导致错误概率的常数加性增加（因此当n→∞时不会产生消失误差）；(b) 生成的JOT-DP程序未能保持原始纯DP程序的计算效率；(c) 在一个玩具计算模型中进行分析，其中运行时被定义为抛硬币的次数。在这项工作中，我们克服了这些局限性。具体来说，我们表明，在无界设置中纯JOT-DP所需的误差取决于计算模型。在随机RAM模型中，如果数据集大小n已知（或可以在常数时间内计算）并且我们可以在常数时间内生成随机数（而不仅仅是随机比特），则多项式小误差概率是必要且充分的。如果n未知或我们只有随机比特生成器，则（任意小的）常数误差概率是必要且充分的。上述积极结果是通过高效的程序证明的，这些程序将上界设置中的任何纯JOT-DP程序P转换为无界设置中的纯JOT-DP程序P'，使得P'的输出分布在总变差距离上与P的输出分布γ-接近，其中γ是任意小的常数或多项式小，具体取决于计算模型。", "summary": "本文解决了现有联合输出和运行时差分隐私（JOT-DP）方法在无界差分隐私应用中的局限性，特别是关于误差累积、计算效率低下以及对简化计算模型的依赖。作者证明了在无界设置中纯JOT-DP的必要错误概率取决于计算模型。他们表明，在随机RAM模型中可以实现多项式小误差，而仅使用随机比特生成器时只能实现常数误差。这项工作提供了高效的转换程序来实现这些结果，从而提高了JOT-DP在处理大型数据集时的实用性和理论理解。", "keywords": "差分隐私, 时序攻击, 无界DP, JOT-DP, 计算模型", "comments": "本文通过详细分析计算模型对抵御时序攻击的差分隐私保证的影响，特别是在无界数据集方面，展现了创新性。它超越了简化的假设，提供了更实际和高效的解决方案，解决了先前工作的实际限制。对RAM模型和随机比特模型之间区别的区分对于实际实现具有特别深刻的见解。"}}
{"id": "2506.07325", "title": "BR-MPPI: Barrier Rate guided MPPI for Enforcing Multiple Inequality Constraints with Learned Signed Distance Field", "authors": ["Hardik Parwana", "Taekyung Kim", "Kehan Long", "Bardh Hoxha", "Hideki Okamoto", "Georgios Fainekos", "Dimitra Panagou"], "summary": "Model Predictive Path Integral (MPPI) controller is used to solve\nunconstrained optimal control problems and Control Barrier Function (CBF) is a\ntool to impose strict inequality constraints, a.k.a, barrier constraints. In\nthis work, we propose an integration of these two methods that employ CBF-like\nconditions to guide the control sampling procedure of MPPI. CBFs provide an\ninequality constraint restricting the rate of change of barrier functions by a\nclassK function of the barrier itself. We instead impose the CBF condition as\nan equality constraint by choosing a parametric linear classK function and\ntreating this parameter as a state in an augmented system. The time derivative\nof this parameter acts as an additional control input that is designed by MPPI.\nA cost function is further designed to reignite Nagumo's theorem at the\nboundary of the safe set by promoting specific values of classK parameter to\nenforce safety. Our problem formulation results in an MPPI subject to multiple\nstate and control-dependent equality constraints which are non-trivial to\nsatisfy with randomly sampled control inputs. We therefore also introduce state\ntransformations and control projection operations, inspired by the literature\non path planning for manifolds, to resolve the aforementioned issue. We show\nempirically through simulations and experiments on quadrotor that our proposed\nalgorithm exhibits better sampled efficiency and enhanced capability to operate\ncloser to the safe set boundary over vanilla MPPI.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07325v1", "AI": {"title_translation": "BR-MPPI：基于障碍率引导的MPPI，用于通过学习符号距离场强制执行多重不等式约束", "tldr": "BR-MPPI将类控制障碍函数条件整合到MPPI中，通过将CBF条件视为增强系统中的等式约束来强制执行多个不等式约束，从而提高了安全性和采样效率。", "motivation": "Model Predictive Path Integral (MPPI) 控制器擅长解决无约束最优控制问题，而控制障碍函数 (CBF) 则用于施加严格的不等式约束。本研究的动机在于将这两种方法结合起来，以有效地处理和强制执行多重不等式约束，克服MPPI在随机采样控制输入下难以满足此类约束的挑战。", "method": "本文提出了 BR-MPPI 算法，通过以下方式将 MPPI 与类 CBF 条件相结合：1. 将 CBF 条件（即障碍函数变化率受 classK 函数限制）重新表述为等式约束。2. 选择一个参数化的线性 classK 函数，并将其参数作为增强系统中的一个状态。3. 将该参数的时间导数视为由 MPPI 设计的额外控制输入。4. 设计一个成本函数，促使 classK 参数取特定值，以在安全集边界处重新激活 Nagumo 定理，从而强制执行安全性。5. 为解决多重状态和控制相关等式约束难以满足的问题，引入了状态变换和控制投影操作。", "result": "通过在四旋翼飞行器上进行的仿真和实验，经验证明所提出的 BR-MPPI 算法相较于普通的 MPPI，展现出更好的采样效率和更强的在安全集边界附近运行的能力。", "conclusion": "BR-MPPI 成功地将 MPPI 和 CBF 结合起来，有效地强制执行多重不等式约束，从而提高了控制器的安全性和在安全边界附近的运行效率。", "translation": "模型预测路径积分 (MPPI) 控制器用于解决无约束最优控制问题，而控制障碍函数 (CBF) 是一种施加严格不等式约束（又称障碍约束）的工具。在这项工作中，我们提出了一种将这两种方法集成在一起的方法，该方法采用类似 CBF 的条件来引导 MPPI 的控制采样过程。CBF 规定了一个不等式约束，通过障碍函数本身的 classK 函数来限制障碍函数的变化率。我们通过选择参数化的线性 classK 函数并将此参数视为增强系统中的一个状态，从而将 CBF 条件作为等式约束施加。此参数的时间导数作为由 MPPI 设计的额外控制输入。进一步设计了一个成本函数，通过促进 classK 参数的特定值来重新激活安全集边界处的 Nagumo 定理，以强制执行安全性。我们的问题公式导致 MPPI 受到多个状态和控制相关等式约束，这些约束很难通过随机采样的控制输入来满足。因此，我们还引入了状态变换和控制投影操作（受流形路径规划文献启发）来解决上述问题。我们通过四旋翼飞行器上的仿真和实验经验证明，我们提出的算法比普通的 MPPI 表现出更好的采样效率和更强的在安全集边界附近操作的能力。", "summary": "本文提出了一种名为 BR-MPPI 的新型控制框架，它将模型预测路径积分 (MPPI) 与控制障碍函数 (CBF) 原理相结合。该方法将 CBF 条件重新表述为增强系统中的等式约束，其中一个参数化的 classK 函数被视为附加状态，其导数由 MPPI 设计为控制输入。为了应对满足多个等式约束的挑战，该方法引入了状态变换和控制投影操作。在四旋翼飞行器上的仿真和实验结果表明，与标准 MPPI 相比，BR-MPPI 显著提高了采样效率，并能更安全地在约束边界附近运行。", "keywords": "MPPI, 控制障碍函数, 不等式约束, 最优控制, 四旋翼飞行器", "comments": "本论文提出了一种创新方法，通过将 CBF 条件重新解释为等式约束，巧妙地融合了 MPPI（基于采样的最优控制）和 CBF（安全保证）的优势。将 classK 参数作为状态空间的一部分并由 MPPI 设计其导数的思想，对于将安全性融入采样框架中尤其巧妙。此外，状态变换和控制投影操作的引入进一步增强了其在复杂约束问题中的实用性。这项工作对于开发在严格不等式约束下运行系统的安全高效控制器具有重要意义。"}}
{"id": "2506.06846", "title": "Multi-StyleGS: Stylizing Gaussian Splatting with Multiple Styles", "authors": ["Yangkai Lin", "Jiabao Lei", "Kui jia"], "summary": "In recent years, there has been a growing demand to stylize a given 3D scene\nto align with the artistic style of reference images for creative purposes.\nWhile 3D Gaussian Splatting(GS) has emerged as a promising and efficient method\nfor realistic 3D scene modeling, there remains a challenge in adapting it to\nstylize 3D GS to match with multiple styles through automatic local style\ntransfer or manual designation, while maintaining memory efficiency for\nstylization training. In this paper, we introduce a novel 3D GS stylization\nsolution termed Multi-StyleGS to tackle these challenges. In particular, we\nemploy a bipartite matching mechanism to au tomatically identify\ncorrespondences between the style images and the local regions of the rendered\nimages. To facilitate local style transfer, we introduce a novel semantic style\nloss function that employs a segmentation network to apply distinct styles to\nvarious objects of the scene and propose a local-global feature matching to\nenhance the multi-view consistency. Furthermore, this technique can achieve\nmemory efficient training, more texture details and better color match. To\nbetter assign a robust semantic label to each Gaussian, we propose several\ntechniques to regularize the segmentation network. As demonstrated by our\ncomprehensive experiments, our approach outperforms existing ones in producing\nplausible stylization results and offering flexible editing.", "comment": "AAAI 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06846v1", "AI": {"title_translation": "Multi-StyleGS：使用多种风格对高斯溅射进行风格化", "tldr": "提出Multi-StyleGS，一种新的3D高斯溅射风格化方法，能够以内存高效的方式将多种风格应用于3D场景，并实现了更好的风格化效果和灵活编辑。", "motivation": "3D场景风格化需求日益增长，但现有的3D高斯溅射（GS）方法在自动或手动指定多种风格以及保持内存效率方面存在挑战。", "method": "引入Multi-StyleGS方案，采用二分匹配机制自动识别风格图像与渲染图像局部区域的对应关系；提出一种新的语义风格损失函数，结合分割网络将不同风格应用于场景中的各种对象；提出局部-全局特征匹配以增强多视图一致性；还提出多种技术来正则化分割网络，以更好地为每个高斯分配鲁棒的语义标签。", "result": "实验证明，该方法在生成合理的风格化结果和提供灵活编辑方面优于现有方法，并能实现更高的纹理细节和更好的色彩匹配。", "conclusion": "本文提出的Multi-StyleGS有效解决了3D高斯溅射多风格化的挑战，实现了内存高效的训练，并取得了优越的风格化效果和灵活的编辑能力。", "translation": "近年来，为了创意目的，对给定3D场景进行风格化以使其与参考图像的艺术风格保持一致的需求日益增长。虽然3D高斯溅射（GS）已成为一种有前景且高效的真实3D场景建模方法，但在使其适应通过自动局部风格迁移或手动指定来匹配多种风格，同时保持风格化训练的内存效率方面仍然存在挑战。在本文中，我们引入了一种新颖的3D GS风格化解决方案，称为Multi-StyleGS，以解决这些挑战。特别是，我们采用二分匹配机制自动识别风格图像与渲染图像局部区域之间的对应关系。为了促进局部风格迁移，我们引入了一种新颖的语义风格损失函数，该函数采用分割网络将不同风格应用于场景中的各种对象，并提出局部-全局特征匹配以增强多视图一致性。此外，该技术可以实现内存高效的训练，更多的纹理细节和更好的色彩匹配。为了更好地为每个高斯分配鲁棒的语义标签，我们提出了几种技术来正则化分割网络。正如我们全面的实验所证明的，我们的方法在生成合理的风格化结果和提供灵活编辑方面优于现有方法。", "summary": "本文针对3D高斯溅射（GS）在多风格化和内存效率方面的挑战，提出了一种名为Multi-StyleGS的新型解决方案。该方法通过引入二分匹配机制、语义风格损失函数（结合分割网络实现局部风格迁移）以及局部-全局特征匹配来增强多视图一致性。此外，Multi-StyleGS还实现了内存高效的训练，并能生成更丰富的纹理细节和更准确的色彩匹配。实验结果表明，Multi-StyleGS在生成逼真的风格化效果和提供灵活编辑方面优于现有方法。", "keywords": "高斯溅射, 3D风格化, 多风格, 语义风格迁移, 内存高效", "comments": "这篇论文在3D场景风格化领域做出了重要贡献，特别是在将多种艺术风格应用于高斯溅射模型方面。其创新点在于结合了二分匹配和语义分割网络来实现精细的局部风格迁移，同时解决了内存效率问题，这对于实际应用非常关键。该方法提高了风格化结果的真实感和编辑的灵活性，为3D内容创作提供了强大的新工具。"}}
{"id": "2506.06965", "title": "Long-Tailed Learning for Generalized Category Discovery", "authors": ["Cuong Manh Hoang"], "summary": "Generalized Category Discovery (GCD) utilizes labeled samples of known\nclasses to discover novel classes in unlabeled samples. Existing methods show\neffective performance on artificial datasets with balanced distributions.\nHowever, real-world datasets are always imbalanced, significantly affecting the\neffectiveness of these methods. To solve this problem, we propose a novel\nframework that performs generalized category discovery in long-tailed\ndistributions. We first present a self-guided labeling technique that uses a\nlearnable distribution to generate pseudo-labels, resulting in less biased\nclassifiers. We then introduce a representation balancing process to derive\ndiscriminative representations. By mining sample neighborhoods, this process\nencourages the model to focus more on tail classes. We conduct experiments on\npublic datasets to demonstrate the effectiveness of the proposed framework. The\nresults show that our model exceeds previous state-of-the-art methods.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06965v1", "AI": {"title_translation": "长尾学习用于广义类别发现", "tldr": "针对不平衡的长尾分布，提出了一种新的广义类别发现（GCD）框架，通过自引导标签和表示平衡，超越了现有最先进方法。", "motivation": "现有广义类别发现方法在平衡数据集上表现良好，但在真实世界不平衡的长尾分布数据集上效果显著下降。", "method": "提出了一种在长尾分布中进行广义类别发现的新框架。首先，引入自引导标签技术，利用可学习分布生成伪标签，以减少分类器的偏差。其次，提出表示平衡过程，通过挖掘样本邻域来学习判别性表示，并促使模型更多关注尾部类别。", "result": "在公共数据集上进行的实验表明，所提出的框架有效，并且模型性能超越了之前的最先进方法。", "conclusion": "该研究成功解决了长尾分布下广义类别发现的挑战，并提出了一个有效且性能优于现有先进方法的框架。", "translation": "广义类别发现（GCD）利用已知类别的标记样本来发现未标记样本中的新类别。现有方法在具有平衡分布的人工数据集上表现出有效性能。然而，真实世界的数据集总是不平衡的，这严重影响了这些方法的有效性。为了解决这个问题，我们提出了一种新颖的框架，该框架在长尾分布中执行广义类别发现。我们首先提出了一种自引导标签技术，该技术使用可学习分布生成伪标签，从而产生偏差较小的分类器。然后，我们引入了一个表示平衡过程，以导出判别性表示。通过挖掘样本邻域，此过程鼓励模型更多地关注尾部类别。我们在公共数据集上进行了实验，以证明所提出框架的有效性。结果表明，我们的模型超越了以前的最先进方法。", "summary": "本文提出了一种新颖的广义类别发现（GCD）框架，专门针对真实世界数据集中常见的长尾分布问题。该框架采用自引导标签技术生成偏差较小的伪标签，并引入表示平衡过程，通过挖掘样本邻域来关注尾部类别。实验证明，该框架的性能优于现有的最先进方法。", "keywords": "广义类别发现, 长尾学习, 不平衡数据, 自引导标签, 表示平衡", "comments": "该论文创新性地解决了广义类别发现（GCD）在长尾分布数据上的性能下降问题，其提出的自引导标签和表示平衡技术是关键创新点。这项工作对于将GCD方法应用于更真实的、不平衡的数据集具有重要意义。"}}
{"id": "2506.07882", "title": "Evaluating explainable AI for deep learning-based network intrusion detection system alert classification", "authors": ["Rajesh Kalakoti", "Risto Vaarandi", "Hayretdin Bahsi", "Sven Nõmm"], "summary": "A Network Intrusion Detection System (NIDS) monitors networks for cyber\nattacks and other unwanted activities. However, NIDS solutions often generate\nan overwhelming number of alerts daily, making it challenging for analysts to\nprioritize high-priority threats. While deep learning models promise to\nautomate the prioritization of NIDS alerts, the lack of transparency in these\nmodels can undermine trust in their decision-making. This study highlights the\ncritical need for explainable artificial intelligence (XAI) in NIDS alert\nclassification to improve trust and interpretability. We employed a real-world\nNIDS alert dataset from Security Operations Center (SOC) of TalTech (Tallinn\nUniversity Of Technology) in Estonia, developing a Long Short-Term Memory\n(LSTM) model to prioritize alerts. To explain the LSTM model's alert\nprioritization decisions, we implemented and compared four XAI methods: Local\nInterpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations\n(SHAP), Integrated Gradients, and DeepLIFT. The quality of these XAI methods\nwas assessed using a comprehensive framework that evaluated faithfulness,\ncomplexity, robustness, and reliability. Our results demonstrate that DeepLIFT\nconsistently outperformed the other XAI methods, providing explanations with\nhigh faithfulness, low complexity, robust performance, and strong reliability.\nIn collaboration with SOC analysts, we identified key features essential for\neffective alert classification. The strong alignment between these\nanalyst-identified features and those obtained by the XAI methods validates\ntheir effectiveness and enhances the practical applicability of our approach.", "comment": "Accepted version of a paper published in the Proceedings of the 11th\n  International Conference on Information Systems Security and Privacy (ICISSP\n  2025). Final version available via SCITEPRESS", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07882v1", "AI": {"title_translation": "评估用于基于深度学习的网络入侵检测系统告警分类的可解释AI", "tldr": "深度学习NIDS告警量巨大，缺乏透明度。本研究评估了用于NIDS告警分类的可解释AI方法，发现DeepLIFT表现最佳，提高了信任和可解释性。", "motivation": "网络入侵检测系统（NIDS）每天产生大量告警，使分析师难以优先处理高优先级威胁。尽管深度学习模型有望自动化NIDS告警的优先级排序，但其缺乏透明度会削弱对决策的信任。因此，本研究强调了在NIDS告警分类中对可解释人工智能（XAI）的迫切需求，以提高信任和可解释性。", "method": "本研究使用了爱沙尼亚塔林理工大学（TalTech）安全运营中心（SOC）的真实NIDS告警数据集，开发了一个长短期记忆（LSTM）模型来优先处理告警。为了解释LSTM模型的告警优先级决策，研究实施并比较了四种XAI方法：局部可解释模型无关解释（LIME）、SHapley加性解释（SHAP）、集成梯度（Integrated Gradients）和DeepLIFT。这些XAI方法的质量通过一个评估忠实性、复杂性、鲁棒性和可靠性的综合框架进行评估。研究还与SOC分析师合作，确定了有效告警分类的关键特征。", "result": "研究结果表明，DeepLIFT始终优于其他XAI方法，提供了高忠实性、低复杂性、鲁棒性能和强可靠性的解释。分析师识别的关键特征与XAI方法获得的关键特征之间存在高度一致性。", "conclusion": "本研究的结论是，DeepLIFT在解释NIDS告警优先级方面表现出色，并且XAI方法识别的特征与分析师识别的特征之间的强一致性验证了该方法的有效性和实际适用性，从而增强了信任和可解释性。", "translation": "网络入侵检测系统（NIDS）监控网络中的网络攻击和其他不必要的活动。然而，NIDS解决方案通常每天生成大量的警报，使分析师难以优先处理高优先级威胁。虽然深度学习模型有望自动化NIDS警报的优先级排序，但这些模型缺乏透明度可能会削弱对其决策的信任。本研究强调了在NIDS警报分类中对可解释人工智能（XAI）的迫切需求，以提高信任和可解释性。我们使用了来自爱沙尼亚塔林理工大学（TalTech）安全运营中心（SOC）的真实NIDS警报数据集，开发了一个长短期记忆（LSTM）模型来优先处理警报。为了解释LSTM模型的警报优先级决策，我们实施并比较了四种XAI方法：局部可解释模型无关解释（LIME）、SHapley加性解释（SHAP）、集成梯度（Integrated Gradients）和DeepLIFT。这些XAI方法的质量通过一个评估忠实性、复杂性、鲁棒性和可靠性的综合框架进行评估。我们的结果表明，DeepLIFT始终优于其他XAI方法，提供了高忠实性、低复杂性、鲁棒性能和强可靠性的解释。在与SOC分析师的合作中，我们确定了有效警报分类的关键特征。这些分析师识别的特征与XAI方法获得的特征之间的高度一致性验证了它们的有效性，并增强了我们方法的实际适用性。", "summary": "本论文旨在解决深度学习驱动的网络入侵检测系统（NIDS）产生大量告警的挑战，通过引入可解释人工智能（XAI）来增强透明度和信任。研究利用真实的NIDS告警数据集，开发了一个LSTM模型进行告警优先级排序，并比较了LIME、SHAP、Integrated Gradients和DeepL四种XAI方法。评估结果显示，DeepLIFT在忠实性、复杂性、鲁棒性和可靠性方面表现最佳。此外，研究还通过与安全运营中心（SOC）分析师的合作，验证了XAI方法识别的关键特征与分析师经验的高度一致性，从而提升了该方法的实用性和可信度。", "keywords": "可解释AI, 网络入侵检测系统, 深度学习, 告警分类, DeepLIFT", "comments": "这篇论文解决了网络安全领域一个实际且重要的问题：NIDS告警泛滥及其深度学习模型缺乏透明度。其创新点在于系统地比较了多种XAI方法，并结合真实世界数据和SOC分析师的专业知识对结果进行了验证，这大大增强了研究成果的实用性和可信度。DeepLIFT被确认为表现最佳的XAI方法，为未来的NIDS研究提供了有价值的方向。论文强调了人机协作在AI系统部署中的重要性，对提升AI在关键领域的可接受度具有积极意义。"}}
{"id": "2506.07339", "title": "Real-Time Execution of Action Chunking Flow Policies", "authors": ["Kevin Black", "Manuel Y. Galliker", "Sergey Levine"], "summary": "Modern AI systems, especially those interacting with the physical world,\nincreasingly require real-time performance. However, the high latency of\nstate-of-the-art generalist models, including recent vision-language action\nmodels (VLAs), poses a significant challenge. While action chunking has enabled\ntemporal consistency in high-frequency control tasks, it does not fully address\nthe latency problem, leading to pauses or out-of-distribution jerky movements\nat chunk boundaries. This paper presents a novel inference-time algorithm that\nenables smooth asynchronous execution of action chunking policies. Our method,\nreal-time chunking (RTC), is applicable to any diffusion- or flow-based VLA out\nof the box with no re-training. It generates the next action chunk while\nexecuting the current one, \"freezing\" actions guaranteed to execute and\n\"inpainting\" the rest. To test RTC, we introduce a new benchmark of 12 highly\ndynamic tasks in the Kinetix simulator, as well as evaluate 6 challenging\nreal-world bimanual manipulation tasks. Results demonstrate that RTC is fast,\nperformant, and uniquely robust to inference delay, significantly improving\ntask throughput and enabling high success rates in precise tasks\n$\\unicode{x2013}$ such as lighting a match $\\unicode{x2013}$ even in the\npresence of significant latency. See\nhttps://pi.website/research/real_time_chunking for videos.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07339v1", "AI": {"title_translation": "动作分块流策略的实时执行", "tldr": "本文提出了一种名为实时分块（RTC）的新型推理算法，旨在解决视觉-语言动作（VLA）模型在实时物理交互中的高延迟问题。RTC无需重新训练即可使动作分块策略平滑异步执行，显著提高任务吞吐量和成功率，即使在高延迟环境下也能实现。", "motivation": "现代AI系统，特别是与物理世界交互的系统，需要实时性能。然而，当前最先进的通用模型（包括视觉-语言动作模型VLAs）存在高延迟问题。尽管动作分块能提高高频控制任务的时间一致性，但未能完全解决延迟问题，导致在分块边界处出现停顿或不协调的动作。", "method": "本文提出了一种新颖的推理时间算法——实时分块（RTC），用于实现动作分块策略的平滑异步执行。该方法无需重新训练即可适用于任何基于扩散或流的VLA。RTC在执行当前动作块的同时生成下一个动作块，通过“冻结”确定执行的动作并“修复”其余部分。为测试RTC，研究者引入了Kinetix模拟器中的12个高度动态任务的新基准，并评估了6个具有挑战性的真实世界双手操作任务。", "result": "结果表明，RTC速度快、性能好，并且对推理延迟具有独特的鲁棒性。它显著提高了任务吞吐量，即使在存在显著延迟的情况下，也能在精确任务（如点燃火柴）中实现高成功率。", "conclusion": "RTC算法能够实现动作分块策略的平滑异步执行，有效解决了实时AI系统与物理世界交互中的延迟问题，从而提高了性能和鲁棒性。", "translation": "现代AI系统，特别是与物理世界交互的系统，越来越需要实时性能。然而，最先进的通用模型（包括最近的视觉-语言动作模型（VLAs））的高延迟带来了重大挑战。虽然动作分块在高频率控制任务中实现了时间一致性，但它并未完全解决延迟问题，导致在分块边界处出现暂停或超出分布的生涩动作。本文提出了一种新颖的推理时间算法，能够实现动作分块策略的平滑异步执行。我们的方法——实时分块（RTC），无需重新训练即可开箱即用于任何基于扩散或流的VLA。它在执行当前动作块的同时生成下一个动作块，“冻结”保证执行的动作并“修复”其余部分。为了测试RTC，我们引入了Kinetix模拟器中的12个高度动态任务的新基准，并评估了6个具有挑战性的真实世界双手操作任务。结果表明，RTC速度快、性能好，并且对推理延迟具有独特的鲁棒性，显著提高了任务吞吐量，并使在精确任务中（例如点燃火柴）实现高成功率成为可能，即使在存在显著延迟的情况下也是如此。请访问https://pi.website/research/real_time_chunking 查看视频。", "summary": "本文提出了一种名为实时分块（RTC）的新型推理时间算法，旨在解决现代视觉-语言动作（VLA）模型在实时物理世界交互中面临的高延迟挑战。与现有动作分块方法不同，RTC通过在执行当前动作块的同时生成下一个动作块，实现动作分块策略的平滑异步执行，从而避免了在分块边界处的停顿和不协调动作。该方法无需对现有扩散或流式VLA进行重新训练即可应用。通过在Kinetix模拟器中的新基准测试和真实世界双手操作任务上的评估，RTC展现出卓越的速度、性能和对推理延迟的鲁棒性，显著提升了任务吞吐量，并在高延迟环境下也能确保高精度任务的成功率。", "keywords": "实时AI, 动作分块, 视觉-语言模型, 延迟, 机器人, 异步执行", "comments": "该论文解决了一个在现实世界中部署AI系统所面临的关键实际问题：高频控制任务中的延迟。其创新之处在于提出了一种“推理时间算法”，这意味着它无需重新训练即可作为现有VLA模型的即插即用解决方案，这对于立即应用具有高价值。通过“冻结”和“修复”动作块内动作以实现异步执行的方法非常巧妙。其所展示的对推理延迟的鲁棒性和改进的吞吐量是机器人操作和实时控制领域的重大贡献。"}}
{"id": "2506.06850", "title": "Deep Inertial Pose: A deep learning approach for human pose estimation", "authors": ["Sara M. Cerqueira", "Manuel Palermo", "Cristina P. Santos"], "summary": "Inertial-based Motion capture system has been attracting growing attention\ndue to its wearability and unsconstrained use. However, accurate human joint\nestimation demands several complex and expertise demanding steps, which leads\nto expensive software such as the state-of-the-art MVN Awinda from Xsens\nTechnologies. This work aims to study the use of Neural Networks to abstract\nthe complex biomechanical models and analytical mathematics required for pose\nestimation. Thus, it presents a comparison of different Neural Network\narchitectures and methodologies to understand how accurately these methods can\nestimate human pose, using both low cost(MPU9250) and high end (Mtw Awinda)\nMagnetic, Angular Rate, and Gravity (MARG) sensors. The most efficient method\nwas the Hybrid LSTM-Madgwick detached, which achieved an Quaternion Angle\ndistance error of 7.96, using Mtw Awinda data. Also, an ablation study was\nconducted to study the impact of data augmentation, output representation,\nwindow size, loss function and magnetometer data on the pose estimation error.\nThis work indicates that Neural Networks can be trained to estimate human pose,\nwith results comparable to the state-of-the-art fusion filters.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06850v1", "AI": {"title_translation": "深度惯性姿态：一种用于人体姿态估计的深度学习方法", "tldr": "该研究探索使用神经网络进行人体姿态估计，以替代复杂的生物力学模型，并发现混合LSTM-Madgwick方法在惯性传感器数据上表现良好，结果可与现有技术媲美。", "motivation": "惯性运动捕捉系统因其可穿戴性和无约束使用而受到关注，但准确的人体关节估计需要复杂且专业的步骤，导致软件成本高昂。本研究旨在探索使用神经网络来简化人体姿态估计所需的复杂生物力学模型和分析数学。", "method": "本研究比较了不同的神经网络架构和方法，以评估它们在人体姿态估计中的准确性。实验使用了低成本（MPU9250）和高端（Mtw Awinda）的磁、角速率和重力（MARG）传感器数据。此外，还进行了一项消融研究，探讨了数据增强、输出表示、窗口大小、损失函数和磁力计数据对姿态估计误差的影响。", "result": "最有效的方法是Hybrid LSTM-Madgwick detached，使用Mtw Awinda数据时，其四元数角度距离误差为7.96。消融研究分析了数据增强、输出表示、窗口大小、损失函数和磁力计数据对姿态估计误差的影响。", "conclusion": "本研究表明，神经网络可以被训练用于人体姿态估计，并且其结果可与最先进的融合滤波器相媲美。", "translation": "基于惯性的运动捕捉系统因其可穿戴性和无约束使用而受到越来越多的关注。然而，准确的人体关节估计需要几个复杂且专业要求高的步骤，这导致了昂贵的软件，例如Xsens Technologies最先进的MVN Awinda。这项工作旨在研究使用神经网络来抽象姿态估计所需的复杂生物力学模型和分析数学。因此，它比较了不同的神经网络架构和方法，以了解这些方法在使用低成本（MPU9250）和高端（Mtw Awinda）磁、角速率和重力（MARG）传感器时，能够多准确地估计人体姿态。最有效的方法是Hybrid LSTM-Madgwick detached，使用Mtw Awinda数据时，其四元数角度距离误差为7.96。此外，还进行了一项消融研究，以研究数据增强、输出表示、窗口大小、损失函数和磁力计数据对姿态估计误差的影响。这项工作表明，神经网络可以被训练用于估计人体姿态，其结果可与最先进的融合滤波器相媲美。", "summary": "本研究提出了一种利用深度学习进行人体姿态估计的方法，旨在克服传统惯性运动捕捉系统在准确性方面的复杂性和高成本问题。研究比较了不同神经网络架构，并使用低成本和高端惯性传感器数据进行评估。结果显示，Hybrid LSTM-Madgwick detached方法表现最佳，误差为7.96。此外，通过消融研究分析了多个因素对估计误差的影响。研究表明，神经网络在人体姿态估计方面能达到与现有先进融合滤波器相当的性能。", "keywords": "人体姿态估计, 深度学习, 惯性传感器, 神经网络, 运动捕捉", "comments": "该论文探索了深度学习在人体姿态估计领域的应用，旨在简化传统惯性运动捕捉系统所需的复杂生物力学建模。其创新点在于将神经网络应用于处理惯性测量单元（IMU）数据，以直接估计人体姿态，从而可能降低成本并提高易用性。论文通过比较不同网络架构和进行消融研究，提供了关于影响姿态估计性能的关键因素的见解。研究结果表明，深度学习方法在性能上可以与现有先进技术相媲美，这对于可穿戴运动捕捉技术的发展具有重要意义。"}}
{"id": "2506.06981", "title": "Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments", "authors": ["Riley Simmons-Edler", "Ryan P. Badman", "Felix Baastad Berg", "Raymond Chua", "John J. Vastola", "Joshua Lunger", "William Qian", "Kanaka Rajan"], "summary": "Understanding the behavior of deep reinforcement learning (DRL) agents --\nparticularly as task and agent sophistication increase -- requires more than\nsimple comparison of reward curves, yet standard methods for behavioral\nanalysis remain underdeveloped in DRL. We apply tools from neuroscience and\nethology to study DRL agents in a novel, complex, partially observable\nenvironment, ForageWorld, designed to capture key aspects of real-world animal\nforaging -- including sparse, depleting resource patches, predator threats, and\nspatially extended arenas. We use this environment as a platform for applying\njoint behavioral and neural analysis to agents, revealing detailed,\nquantitatively grounded insights into agent strategies, memory, and planning.\nContrary to common assumptions, we find that model-free RNN-based DRL agents\ncan exhibit structured, planning-like behavior purely through emergent dynamics\n-- without requiring explicit memory modules or world models. Our results show\nthat studying DRL agents like animals -- analyzing them with\nneuroethology-inspired tools that reveal structure in both behavior and neural\ndynamics -- uncovers rich structure in their learning dynamics that would\notherwise remain invisible. We distill these tools into a general analysis\nframework linking core behavioral and representational features to diagnostic\nmethods, which can be reused for a wide range of tasks and agents. As agents\ngrow more complex and autonomous, bridging neuroscience, cognitive science, and\nAI will be essential -- not just for understanding their behavior, but for\nensuring safe alignment and maximizing desirable behaviors that are hard to\nmeasure via reward. We show how this can be done by drawing on lessons from how\nbiological intelligence is studied.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06981v1", "AI": {"title_translation": "深度强化学习需要深度行为分析：探索无模型智能体在开放式环境中的隐式规划", "tldr": "本文应用神经科学和行为学工具，在复杂新环境ForageWorld中研究深度强化学习智能体行为，发现无模型DRL智能体可展现规划式行为，并提出通用分析框架。", "motivation": "随着任务和智能体复杂性增加，理解深度强化学习（DRL）智能体的行为仅通过奖励曲线比较不足，而DRL中行为分析的标准方法仍不成熟。", "method": "研究人员应用神经科学和行为学工具，在名为ForageWorld的复杂、部分可观察环境中研究DRL智能体。ForageWorld旨在捕捉真实世界动物觅食的关键方面。他们对智能体进行联合行为和神经分析。", "result": "发现无模型、基于RNN的DRL智能体可以纯粹通过涌现动力学表现出结构化的、类似规划的行为，而无需显式记忆模块或世界模型。研究表明，像研究动物一样研究DRL智能体，能揭示其学习动力学中丰富的结构。", "conclusion": "像研究生物智能一样研究DRL智能体，通过神经行为学启发工具分析行为和神经动力学，对于理解其行为、确保安全对齐和最大化期望行为至关重要。本文将这些工具提炼成一个通用分析框架。", "translation": "理解深度强化学习（DRL）智能体的行为——特别是随着任务和智能体复杂性的增加——需要的不仅仅是简单的奖励曲线比较，然而DRL中行为分析的标准方法仍然不成熟。我们应用神经科学和行为学工具，在一个新颖、复杂、部分可观察的环境ForageWorld中研究DRL智能体，该环境旨在捕捉真实世界动物觅食的关键方面——包括稀疏、耗尽的资源区、捕食者威胁和空间广阔的竞技场。我们使用这个环境作为平台，对智能体进行联合行为和神经分析，揭示了关于智能体策略、记忆和规划的详细、量化基础的见解。与普遍假设相反，我们发现无模型、基于RNN的DRL智能体可以纯粹通过涌现动力学表现出结构化的、类似规划的行为——无需显式记忆模块或世界模型。我们的结果表明，像研究动物一样研究DRL智能体——用神经行为学启发的工具分析它们，揭示行为和神经动力学中的结构——可以揭示其学习动力学中丰富的结构，否则这些结构将是不可见的。我们将这些工具提炼成一个通用分析框架，将核心行为和表征特征与诊断方法联系起来，可广泛应用于各种任务和智能体。随着智能体变得更加复杂和自主，弥合神经科学、认知科学和人工智能之间的鸿沟将是必不可少的——不仅是为了理解它们的行为，也是为了确保安全对齐和最大化难以通过奖励衡量的期望行为。我们展示了如何借鉴生物智能研究的经验来做到这一点。", "summary": "本文指出，当前深度强化学习（DRL）的行为分析方法不足以应对复杂智能体和任务。为此，作者引入了受神经科学和行为学启发的分析工具，并在名为ForageWorld的复杂环境中研究无模型DRL智能体。研究发现，即使没有显式记忆或世界模型，这些智能体也能通过涌现动力学展现出规划式行为。论文强调了像研究动物一样分析DRL智能体的重要性，并提出了一个通用的行为分析框架，以促进对复杂AI行为的理解、安全对齐和期望行为的最大化。", "keywords": "深度强化学习, 行为分析, 无模型智能体, 隐式规划, 神经行为学", "comments": "这篇论文通过引入神经科学和行为学的方法来分析DRL智能体的行为，提供了一种新颖且深入的视角。其创新之处在于揭示了无模型DRL智能体能够自发地表现出规划能力，这挑战了传统观念中规划需要显式世界模型的假设。该研究的重要性在于为理解和控制日益复杂的AI系统提供了新的工具和框架，对于AI的安全性和可解释性具有重要意义。通过将生物智能的研究方法引入AI领域，为未来AI的发展提供了新的研究范式。"}}
{"id": "2506.06336", "title": "Research on E-Commerce Long-Tail Product Recommendation Mechanism Based on Large-Scale Language Models", "authors": ["Qingyi Lu", "Haotian Lyu", "Jiayun Zheng", "Yang Wang", "Li Zhang", "Chengrui Zhou"], "summary": "As e-commerce platforms expand their product catalogs, accurately\nrecommending long-tail items becomes increasingly important for enhancing both\nuser experience and platform revenue. A key challenge is the long-tail problem,\nwhere extreme data sparsity and cold-start issues limit the performance of\ntraditional recommendation methods. To address this, we propose a novel\nlong-tail product recommendation mechanism that integrates product text\ndescriptions and user behavior sequences using a large-scale language model\n(LLM). First, we introduce a semantic visor, which leverages a pre-trained LLM\nto convert multimodal textual content such as product titles, descriptions, and\nuser reviews into meaningful embeddings. These embeddings help represent\nitem-level semantics effectively. We then employ an attention-based user intent\nencoder that captures users' latent interests, especially toward long-tail\nitems, by modeling collaborative behavior patterns. These components feed into\na hybrid ranking model that fuses semantic similarity scores, collaborative\nfiltering outputs, and LLM-generated recommendation candidates. Extensive\nexperiments on a real-world e-commerce dataset show that our method outperforms\nbaseline models in recall (+12%), hit rate (+9%), and user coverage (+15%).\nThese improvements lead to better exposure and purchase rates for long-tail\nproducts. Our work highlights the potential of LLMs in interpreting product\ncontent and user intent, offering a promising direction for future e-commerce\nrecommendation systems.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06336v1", "AI": {"title_translation": "基于大规模语言模型的电商长尾商品推荐机制研究", "tldr": "针对电商长尾商品推荐中的数据稀疏和冷启动问题，本文提出了一种结合大规模语言模型（LLM）的推荐机制，通过语义表征和用户意图编码，显著提高了长尾商品的召回率、命中率和用户覆盖率。", "motivation": "随着电商平台产品目录的扩展，准确推荐长尾商品对于提升用户体验和平台收入至关重要。传统推荐方法面临数据稀疏和冷启动的长尾问题，性能受限。", "method": "提出了一种结合产品文本描述和用户行为序列的长尾商品推荐机制，使用大规模语言模型（LLM）。首先，引入语义视窗利用预训练LLM将多模态文本内容（如商品标题、描述、用户评论）转换为有意义的嵌入。其次，采用基于注意力的用户意图编码器，通过建模协同行为模式捕获用户潜在兴趣。最后，这些组件输入到混合排序模型中，融合语义相似度分数、协同过滤输出和LLM生成的推荐候选。", "result": "在真实电商数据集上的广泛实验表明，该方法在召回率（+12%）、命中率（+9%）和用户覆盖率（+15%）方面优于基线模型，从而提高了长尾商品的曝光率和购买率。", "conclusion": "该研究强调了LLM在解释产品内容和用户意图方面的潜力，为未来的电商推荐系统提供了有前景的方向。", "translation": "随着电商平台产品目录的扩展，准确推荐长尾商品对于提升用户体验和平台收入变得越来越重要。一个关键挑战是长尾问题，即极端数据稀疏性和冷启动问题限制了传统推荐方法的性能。为了解决这个问题，我们提出了一种新颖的长尾商品推荐机制，该机制利用大规模语言模型（LLM）整合产品文本描述和用户行为序列。首先，我们引入了一个语义视窗，它利用预训练的LLM将产品标题、描述和用户评论等多模态文本内容转换为有意义的嵌入。这些嵌入有助于有效表示项目级语义。然后，我们采用了一个基于注意力的用户意图编码器，通过建模协同行为模式来捕获用户的潜在兴趣，特别是对长尾商品的兴趣。这些组件被输入到一个混合排序模型中，该模型融合了语义相似度分数、协同过滤输出和LLM生成的推荐候选。在真实世界的电商数据集上进行的广泛实验表明，我们的方法在召回率（+12%）、命中率（+9%）和用户覆盖率（+15%）方面优于基线模型。这些改进使得长尾商品的曝光率和购买率更高。我们的工作突出了LLM在解释产品内容和用户意图方面的潜力，为未来的电商推荐系统提供了有前景的方向。", "summary": "本文提出了一种基于大规模语言模型（LLM）的电商长尾商品推荐机制，旨在解决传统方法在数据稀疏和冷启动问题上的不足。该机制通过LLM将产品文本内容转化为语义嵌入，并利用注意力机制编码用户对长尾商品的兴趣，最终通过混合排序模型生成推荐。实验结果显示，该方法显著提升了长尾商品的召回率、命中率和用户覆盖率，证明了LLM在电商推荐中的应用潜力。", "keywords": "长尾商品推荐, 大规模语言模型, 电商, 数据稀疏, 协同过滤", "comments": "这项研究创新性地将大规模语言模型应用于电商长尾商品推荐，有效解决了传统方法在数据稀疏和冷启动方面的挑战。通过结合语义理解和用户行为模式，该方法为提升长尾商品的曝光和销售提供了新的途径，对未来的个性化推荐系统发展具有重要意义。"}}
{"id": "2506.07888", "title": "SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark", "authors": ["Rui Wen", "Yiyong Liu", "Michael Backes", "Yang Zhang"], "summary": "Data reconstruction attacks, which aim to recover the training dataset of a\ntarget model with limited access, have gained increasing attention in recent\nyears. However, there is currently no consensus on a formal definition of data\nreconstruction attacks or appropriate evaluation metrics for measuring their\nquality. This lack of rigorous definitions and universal metrics has hindered\nfurther advancement in this field. In this paper, we address this issue in the\nvision domain by proposing a unified attack taxonomy and formal definitions of\ndata reconstruction attacks. We first propose a set of quantitative evaluation\nmetrics that consider important criteria such as quantifiability, consistency,\nprecision, and diversity. Additionally, we leverage large language models\n(LLMs) as a substitute for human judgment, enabling visual evaluation with an\nemphasis on high-quality reconstructions. Using our proposed taxonomy and\nmetrics, we present a unified framework for systematically evaluating the\nstrengths and limitations of existing attacks and establishing a benchmark for\nfuture research. Empirical results, primarily from a memorization perspective,\nnot only validate the effectiveness of our metrics but also offer valuable\ninsights for designing new attacks.", "comment": "To Appear in the 34th USENIX Security Symposium, August 13-15, 2025", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07888v1", "AI": {"title_translation": "SoK: 针对机器学习模型的数据重建攻击：定义、度量和基准", "tldr": "本文提出了针对机器学习模型的数据重建攻击的统一分类法、正式定义和量化评估指标，并利用大型语言模型进行评估，建立了该领域的基准。", "motivation": "目前，数据重建攻击缺乏正式定义和适当的评估指标，这阻碍了该领域的进一步发展。", "method": "提出统一的攻击分类法和数据重建攻击的正式定义；提出一套考虑可量化性、一致性、精确性和多样性的定量评估指标；利用大型语言模型替代人类判断进行视觉评估；建立统一框架以系统评估现有攻击并为未来研究设定基准。", "result": "实证结果验证了所提出指标的有效性，并为设计新的攻击提供了宝贵见解。", "conclusion": "本文为数据重建攻击提供了统一的框架、定义和评估指标，并通过实证结果验证了其有效性，为未来的研究和攻击设计奠定了基础。", "translation": "数据重建攻击旨在以有限的访问权限恢复目标模型的训练数据集，近年来受到越来越多的关注。然而，目前对于数据重建攻击的正式定义或衡量其质量的适当评估指标尚未达成共识。这种缺乏严格定义和通用指标的情况阻碍了该领域的进一步发展。在本文中，我们通过提出统一的攻击分类法和数据重建攻击的正式定义来解决视觉领域中的这个问题。我们首先提出一套定量评估指标，其中考虑了可量化性、一致性、精确性和多样性等重要标准。此外，我们利用大型语言模型（LLM）作为人类判断的替代，从而能够进行视觉评估，并强调高质量的重建。利用我们提出的分类法和指标，我们提出了一个统一的框架，用于系统地评估现有攻击的优缺点，并为未来的研究建立基准。主要从记忆角度进行的实证结果不仅验证了我们指标的有效性，而且为设计新攻击提供了宝贵的见解。", "summary": "本文针对机器学习模型数据重建攻击缺乏正式定义和一致评估指标的问题，提出了统一的分类法、正式定义和一套定量评估指标，尤其关注视觉领域。作者还利用大型语言模型进行视觉评估，并提出了一个统一的框架，用于对现有和未来的攻击进行基准测试。实证结果证实了这些指标的有效性，并为新攻击的设计提供了见解。", "keywords": "数据重建攻击, 机器学习安全, 评估指标, 大型语言模型, 基准", "comments": "该论文通过提供对数据重建攻击急需的系统化知识（SoK）而具有创新性，这对于理解机器学习中的隐私风险至关重要。利用大型语言模型进行评估是一种新颖的方法，可能使评估过程更具可扩展性和客观性。建立基准对于该快速发展领域的未来研究至关重要。"}}
{"id": "2506.07345", "title": "Reproducibility in the Control of Autonomous Mobility-on-Demand Systems", "authors": ["Xinling Li", "Meshal Alharbi", "Daniele Gammelli", "James Harrison", "Filipe Rodrigues", "Maximilian Schiffer", "Marco Pavone", "Emilio Frazzoli", "Jinhua Zhao", "Gioele Zardini"], "summary": "Autonomous Mobility-on-Demand (AMoD) systems, powered by advances in\nrobotics, control, and Machine Learning (ML), offer a promising paradigm for\nfuture urban transportation. AMoD offers fast and personalized travel services\nby leveraging centralized control of autonomous vehicle fleets to optimize\noperations and enhance service performance. However, the rapid growth of this\nfield has outpaced the development of standardized practices for evaluating and\nreporting results, leading to significant challenges in reproducibility. As\nAMoD control algorithms become increasingly complex and data-driven, a lack of\ntransparency in modeling assumptions, experimental setups, and algorithmic\nimplementation hinders scientific progress and undermines confidence in the\nresults. This paper presents a systematic study of reproducibility in AMoD\nresearch. We identify key components across the research pipeline, spanning\nsystem modeling, control problems, simulation design, algorithm specification,\nand evaluation, and analyze common sources of irreproducibility. We survey\nprevalent practices in the literature, highlight gaps, and propose a structured\nframework to assess and improve reproducibility. Specifically, concrete\nguidelines are offered, along with a \"reproducibility checklist\", to support\nfuture work in achieving replicable, comparable, and extensible results. While\nfocused on AMoD, the principles and practices we advocate generalize to a\nbroader class of cyber-physical systems that rely on networked autonomy and\ndata-driven control. This work aims to lay the foundation for a more\ntransparent and reproducible research culture in the design and deployment of\nintelligent mobility systems.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07345v1", "AI": {"title_translation": "自主按需出行系统控制中的可重现性", "tldr": "自动按需出行（AMoD）系统研究面临严重的可重现性挑战，本文系统分析了问题根源，并提出了一个结构化框架和“可重现性清单”，旨在促进更透明、可复制的研究。", "motivation": "自动按需出行（AMoD）系统作为未来城市交通的重要范式，其领域发展迅速，但缺乏评估和报告结果的标准化实践，导致研究结果的可重现性面临重大挑战。模型假设、实验设置和算法实现缺乏透明度，这阻碍了科学进步并损害了对研究结果的信心。", "method": "本文对AMoD研究中的可重现性进行了系统性研究。具体方法包括：识别研究流程中的关键组成部分（涵盖系统建模、控制问题、仿真设计、算法规范和评估），分析不可重现性的常见来源，调查现有文献中的普遍实践并指出其不足。在此基础上，提出了一个结构化框架和“可重现性清单”，旨在支持未来工作实现可复制、可比较和可扩展的研究结果。", "result": "本文识别了AMoD研究中不可重现性的关键组成部分和常见来源，并调查了现有实践中的不足。它提出了一个结构化框架和一份实用的“可重现性清单”，这些工具旨在显著改善AMoD系统设计和部署中研究结果的可复制性、可比较性和可扩展性。", "conclusion": "本文旨在为智能出行系统设计和部署中更透明和可重现的研究文化奠定基础。尽管研究重点是AMoD，但所提出的原则和实践具有普适性，可以推广到更广泛的依赖网络自主性和数据驱动控制的赛博物理系统。", "translation": "自动按需出行（AMoD）系统，得益于机器人技术、控制和机器学习（ML）的进步，为未来城市交通提供了一个有前景的范式。AMoD通过利用自动驾驶车队集中控制来优化运营和提升服务性能，从而提供快速和个性化的出行服务。然而，该领域的快速增长已经超越了评估和报告结果标准化实践的发展，导致可重现性面临重大挑战。随着AMoD控制算法变得日益复杂和数据驱动，模型假设、实验设置和算法实现缺乏透明度阻碍了科学进步并损害了对结果的信心。本文对AMoD研究中的可重现性进行了系统性研究。我们识别了研究流程中的关键组成部分，涵盖系统建模、控制问题、仿真设计、算法规范和评估，并分析了不可重现性的常见来源。我们调查了文献中的普遍实践，指出了不足，并提出了一个结构化框架来评估和改善可重现性。具体而言，本文提供了具体的指南和一份“可重现性清单”，以支持未来工作实现可复制、可比较和可扩展的结果。尽管侧重于AMoD，但我们倡导的原则和实践可以推广到更广泛的依赖网络自主性和数据驱动控制的赛博物理系统。这项工作旨在为智能出行系统设计和部署中更透明和可重现的研究文化奠定基础。", "summary": "本文探讨了自动按需出行（AMoD）系统研究中日益突出的可重现性问题。鉴于该领域快速发展但缺乏标准化实践，导致透明度不足并阻碍科学进步。作者系统性地研究了AMoD研究流程中的关键组成部分和不可重现性的常见来源。通过调查现有文献并指出不足，本文提出了一个结构化框架和“可重现性清单”，旨在为AMoD及其他赛博物理系统提供指导，以促进更透明、可复制、可比较和可扩展的研究。", "keywords": "自动按需出行系统, 可重现性, 控制算法, 赛博物理系统, 标准化实践", "comments": "这篇论文解决了AMoD领域一个关键且日益重要的问题：研究的可重现性。其创新之处在于系统性地识别了不可重现性的来源，并提出了一个实用的框架和“可重现性清单”，这对于推动该领域健康发展至关重要。该工作不仅对AMoD有直接指导意义，其提出的原则也具有广泛适用性，能促进整个赛博物理系统研究的透明度和科学严谨性。"}}
{"id": "2506.06852", "title": "Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation", "authors": ["John Waithaka", "Moise Busogi"], "summary": "Semantic segmentation of satellite imagery is crucial for Earth observation\napplications, but remains constrained by limited labelled training data. While\nself-supervised pretraining methods like Masked Autoencoders (MAE) have shown\npromise, they focus on reconstruction rather than localisation-a fundamental\naspect of segmentation tasks. We propose adapting LOCA (Location-aware), a\nposition prediction self-supervised learning method, for multimodal satellite\nimagery semantic segmentation. Our approach addresses the unique challenges of\nsatellite data by extending SatMAE's channel grouping from multispectral to\nmultimodal data, enabling effective handling of multiple modalities, and\nintroducing same-group attention masking to encourage cross-modal interaction\nduring pretraining. The method uses relative patch position prediction,\nencouraging spatial reasoning for localisation rather than reconstruction. We\nevaluate our approach on the Sen1Floods11 flood mapping dataset, where it\nsignificantly outperforms existing reconstruction-based self-supervised\nlearning methods for satellite imagery. Our results demonstrate that position\nprediction tasks, when properly adapted for multimodal satellite imagery, learn\nrepresentations more effective for satellite image semantic segmentation than\nreconstruction-based approaches.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06852v1", "AI": {"title_translation": "多模态卫星图像语义分割中的位置预测自监督学习", "tldr": "本文提出了一种基于位置预测的自监督学习方法，用于多模态卫星图像语义分割，在定位任务上优于基于重建的方法。", "motivation": "卫星图像语义分割在地球观测中至关重要，但受限于标注训练数据稀缺。现有的自监督预训练方法（如MAE）侧重于重建而非分割任务中关键的定位。", "method": "提出将LOCA（位置感知）方法适应于多模态卫星图像语义分割。该方法通过扩展SatMAE的通道分组以处理多模态数据，并引入同组注意力掩码以促进预训练期间的跨模态交互。它使用相对补丁位置预测来鼓励空间推理以实现定位。", "result": "在Sen1Floods11洪水测绘数据集上，该方法显著优于现有的基于重建的卫星图像自监督学习方法。", "conclusion": "结果表明，位置预测任务在适当适应多模态卫星图像时，学习到的表示比基于重建的方法更有效地用于卫星图像语义分割。", "translation": "卫星图像的语义分割对于地球观测应用至关重要，但仍受限于有限的标注训练数据。尽管像掩码自编码器（MAE）这样的自监督预训练方法已显示出前景，但它们侧重于重建而非定位——这是分割任务的一个基本方面。我们提出将LOCA（位置感知）这一位置预测自监督学习方法应用于多模态卫星图像语义分割。我们的方法通过将SatMAE的通道分组从多光谱扩展到多模态数据来解决卫星数据独特的挑战，从而能够有效处理多种模态，并在预训练期间引入同组注意力掩码以鼓励跨模态交互。该方法使用相对补丁位置预测，鼓励空间推理以实现定位而非重建。我们在Sen1Floods11洪水测绘数据集上评估了我们的方法，它显著优于现有的基于重建的卫星图像自监督学习方法。我们的结果表明，位置预测任务在适当适应多模态卫星图像时，学习到的表示比基于重建的方法更有效地用于卫星图像语义分割。", "summary": "本文提出了一种名为LOCA的位置预测自监督学习方法，用于解决多模态卫星图像语义分割中标注数据稀缺的问题。该方法通过扩展SatMAE的通道分组并引入同组注意力掩码来处理多模态数据，并利用相对补丁位置预测来促进定位推理。实验结果表明，该方法在洪水测绘数据集上显著优于现有的基于重建的自监督学习方法，证明了位置预测在学习更有效表示方面的优势。", "keywords": "自监督学习, 语义分割, 卫星图像, 位置预测, 多模态", "comments": "本文的创新点在于将位置预测自监督学习范式引入到多模态卫星图像语义分割领域，解决了传统重建方法在定位能力上的不足。通过适应卫星数据特性，特别是处理多模态信息和促进跨模态交互，该方法为卫星图像分析提供了新的有效途径。其重要性在于为数据稀缺的地球观测任务提供了一种更高效的预训练策略。"}}
{"id": "2506.06991", "title": "Evaluating LLM-corrupted Crowdsourcing Data Without Ground Truth", "authors": ["Yichi Zhang", "Jinlong Pang", "Zhaowei Zhu", "Yang Liu"], "summary": "The recent success of generative AI highlights the crucial role of\nhigh-quality human feedback in building trustworthy AI systems. However, the\nincreasing use of large language models (LLMs) by crowdsourcing workers poses a\nsignificant challenge: datasets intended to reflect human input may be\ncompromised by LLM-generated responses. Existing LLM detection approaches often\nrely on high-dimension training data such as text, making them unsuitable for\nannotation tasks like multiple-choice labeling. In this work, we investigate\nthe potential of peer prediction -- a mechanism that evaluates the information\nwithin workers' responses without using ground truth -- to mitigate\nLLM-assisted cheating in crowdsourcing with a focus on annotation tasks. Our\napproach quantifies the correlations between worker answers while conditioning\non (a subset of) LLM-generated labels available to the requester. Building on\nprior research, we propose a training-free scoring mechanism with theoretical\nguarantees under a crowdsourcing model that accounts for LLM collusion. We\nestablish conditions under which our method is effective and empirically\ndemonstrate its robustness in detecting low-effort cheating on real-world\ncrowdsourcing datasets.", "comment": "33 pages, 9 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.06991v1", "AI": {"title_translation": "在没有真实标签的情况下评估LLM污染的众包数据", "tldr": "本文研究了在缺乏真实标签的情况下，如何利用同伴预测机制来检测众包数据中由大型语言模型（LLM）辅助作弊的情况，并提出了一个无需训练的评分机制，在真实众包数据上有效识别低投入作弊。", "motivation": "生成式AI的成功依赖高质量的人类反馈，但众包工作者越来越多地使用LLM，导致众包数据可能被LLM生成的内容污染。现有LLM检测方法不适用于多项选择标注等任务，且通常依赖高维训练数据，因此需要一种无需真实标签的方法来评估LLM污染的众包数据。", "method": "本研究利用同伴预测机制，在没有真实标签的情况下评估众包数据。具体方法是量化工作者回答之间的关联，同时以请求者可获得的LLM生成标签（或其子集）为条件。论文提出了一个无需训练的评分机制，该机制在考虑LLM串通的众包模型下具有理论保证。", "result": "研究建立了该方法有效的条件，并在真实世界众包数据集上通过经验证明了其在检测低投入作弊方面的鲁棒性。", "conclusion": "该研究表明，在没有真实标签的情况下，利用同伴预测机制可以有效评估LLM污染的众包数据，并检测LLM辅助作弊，尤其适用于标注任务。", "translation": "生成式人工智能最近的成功凸显了高质量人类反馈在构建值得信赖的人工智能系统中的关键作用。然而，众包工作者越来越多地使用大型语言模型（LLM）带来了重大挑战：旨在反映人类输入的数据库可能被LLM生成的回应所损害。现有的LLM检测方法通常依赖于高维训练数据，例如文本，这使得它们不适用于多项选择标注等注释任务。在这项工作中，我们调查了同伴预测的潜力——一种在不使用真实标签的情况下评估工作者回应中信息的机制——以减轻众包中LLM辅助作弊，重点关注注释任务。我们的方法在以请求者可获得的LLM生成标签（或其子集）为条件的情况下，量化了工作者回答之间的关联。在先前研究的基础上，我们提出了一个无需训练的评分机制，在考虑LLM串通的众包模型下具有理论保证。我们建立了该方法有效的条件，并通过经验证明了其在真实世界众包数据集上检测低投入作弊方面的鲁棒性。", "summary": "本研究旨在解决大型语言模型（LLM）在众包中引入的数据污染问题，尤其是在缺乏真实标签的标注任务中。鉴于现有LLM检测方法的局限性，作者提出了一种基于同伴预测的无需训练的评分机制。该机制通过量化工作者回答之间的关联，并在考虑LLM串通的众包模型下提供理论保证。实验结果表明，该方法在检测真实众包数据集上的低投入作弊方面具有鲁棒性。", "keywords": "LLM, 众包, 同伴预测, 数据质量, 作弊检测", "comments": "本文的创新点在于提出了一个无需真实标签的、基于同伴预测的LLM作弊检测机制，这对于当前LLM广泛应用于众包场景下数据质量保障具有重要意义。其无需训练的特性也降低了实施门槛。该方法对于评估和净化LLM污染的众包数据，特别是标注任务，提供了一个有前景的解决方案。"}}
{"id": "2506.06556", "title": "SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks", "authors": ["Long Dang", "Thushari Hapuarachchi", "Kaiqi Xiong", "Yi Li"], "summary": "As the development of autonomous and connected vehicles advances, the\ncomplexity of modern vehicles increases, with numerous Electronic Control Units\n(ECUs) integrated into the system. In an in-vehicle network, these ECUs\ncommunicate with one another using an standard protocol called Controller Area\nNetwork (CAN). Securing communication among ECUs plays a vital role in\nmaintaining the safety and security of the vehicle. This paper proposes a\nrobust SDN-based False Data Detection and Mitigation System (FDDMS) for\nin-vehicle networks. Leveraging the unique capabilities of Software-Defined\nNetworking (SDN), FDDMS is designed to monitor and detect false data injection\nattacks in real-time. Specifically, we focus on brake-related ECUs within an\nSDN-enabled in-vehicle network. First, we decode raw CAN data to create an\nattack model that illustrates how false data can be injected into the system.\nThen, FDDMS, incorporating a Long Short Term Memory (LSTM)-based detection\nmodel, is used to identify false data injection attacks. We further propose an\neffective variant of DeepFool attack to evaluate the model's robustness. To\ncountermeasure the impacts of four adversarial attacks including Fast gradient\ndescent method, Basic iterative method, DeepFool, and the DeepFool variant, we\nfurther enhance a re-training technique method with a threshold based selection\nstrategy. Finally, a mitigation scheme is implemented to redirect attack\ntraffic by dynamically updating flow rules through SDN. Our experimental\nresults show that the proposed FDDMS is robust against adversarial attacks and\neffectively detects and mitigates false data injection attacks in real-time.", "comment": "The 34th International Conference on Computer Communications and\n  Networks (ICCCN 2025)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06556v1", "AI": {"title_translation": "基于SDN的车载网络虚假数据检测、缓解及其机器学习鲁棒性", "tldr": "本文提出了一种基于SDN的虚假数据检测和缓解系统（FDDMS），利用LSTM模型实时检测车载网络中的虚假数据注入攻击，并通过增强的重训练技术提高其对对抗性攻击的鲁棒性，同时实现了SDN驱动的攻击流量缓解。", "motivation": "随着自动驾驶和联网车辆的发展，现代车辆的复杂性增加，车载网络中ECU之间的通信安全对于车辆安全至关重要。因此，需要开发一种系统来检测并缓解车载网络中日益增长的虚假数据注入攻击威胁。", "method": "本文提出了一个基于SDN的虚假数据检测和缓解系统（FDDMS）。首先，解码原始CAN数据以构建虚假数据注入攻击模型。FDDMS使用基于LSTM的检测模型来识别攻击。为了评估和增强模型的鲁棒性，提出了一种DeepFool攻击的变体，并通过结合阈值选择策略的重训练技术来对抗四种对抗性攻击（FGM, BIM, DeepFool, DeepFool变体）。最后，通过SDN动态更新流规则来实施攻击流量重定向的缓解方案。", "result": "实验结果表明，所提出的FDDMS对对抗性攻击具有鲁棒性，并且能够有效、实时地检测和缓解车载网络中的虚假数据注入攻击。", "conclusion": "所提出的FDDMS能够有效保障车载网络通信安全，实时检测并缓解虚假数据注入攻击，且对对抗性攻击表现出良好的鲁棒性。", "translation": "随着自动驾驶和联网车辆的发展，现代车辆的复杂性不断增加，系统中集成了大量电子控制单元（ECU）。在车载网络中，这些ECU使用一种称为控制器局域网（CAN）的标准协议相互通信。确保ECU之间的通信安全在维护车辆安全方面发挥着至关重要的作用。本文提出了一种针对车载网络的基于SDN的鲁棒虚假数据检测和缓解系统（FDDMS）。FDDMS利用软件定义网络（SDN）的独特功能，旨在实时监控和检测虚假数据注入攻击。具体来说，我们专注于支持SDN的车载网络中与制动相关的ECU。首先，我们解码原始CAN数据以创建攻击模型，该模型说明了虚假数据如何注入系统。然后，FDDMS结合了基于长短期记忆（LSTM）的检测模型，用于识别虚假数据注入攻击。我们进一步提出了一种有效的DeepFool攻击变体来评估模型的鲁棒性。为了对抗包括快速梯度下降法、基本迭代法、DeepFool和DeepFool变体在内的四种对抗性攻击的影响，我们通过基于阈值的选择策略进一步增强了重训练技术方法。最后，实施了一种缓解方案，通过SDN动态更新流规则来重定向攻击流量。我们的实验结果表明，所提出的FDDMS对对抗性攻击具有鲁棒性，并能有效实时检测和缓解虚假数据注入攻击。", "summary": "本文提出了一种基于SDN的虚假数据检测和缓解系统（FDDMS），旨在实时保障车载网络安全。该系统首先通过解码CAN数据构建攻击模型，然后利用基于LSTM的检测模型识别虚假数据注入攻击。为应对对抗性攻击，研究者提出了一种DeepFool变体来评估模型鲁棒性，并通过基于阈值选择的重训练技术增强了防御能力。此外，系统还实现了基于SDN的攻击流量重定向缓解机制。实验验证了FDDMS在对抗性攻击下具有鲁棒性，并能有效实时检测和缓解虚假数据注入。", "keywords": "SDN, 虚假数据检测, 车载网络, 机器学习鲁棒性, LSTM", "comments": "本文的创新点在于将SDN与机器学习（LSTM）结合应用于车载网络的安全领域，特别关注了对抗性攻击的鲁棒性问题，并提出了相应的重训练和缓解策略。这对于保障日益复杂的自动驾驶车辆的通信安全具有重要意义，提供了一种实时、鲁棒的解决方案。"}}
{"id": "2506.07894", "title": "Secure Distributed Learning for CAVs: Defending Against Gradient Leakage with Leveled Homomorphic Encryption", "authors": ["Muhammad Ali Najjar", "Ren-Yi Huang", "Dumindu Samaraweera", "Prashant Shekhar"], "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, making it a promising approach\nfor privacy-preserving machine learning in domains like Connected and\nAutonomous Vehicles (CAVs). However, recent studies have shown that exchanged\nmodel gradients remain susceptible to inference attacks such as Deep Leakage\nfrom Gradients (DLG), which can reconstruct private training data. While\nexisting defenses like Differential Privacy (DP) and Secure Multi-Party\nComputation (SMPC) offer protection, they often compromise model accuracy. To\nthat end, Homomorphic Encryption (HE) offers a promising alternative by\nenabling lossless computation directly on encrypted data, thereby preserving\nboth privacy and model utility. However, HE introduces significant\ncomputational and communication overhead, which can hinder its practical\nadoption. To address this, we systematically evaluate various leveled HE\nschemes to identify the most suitable for FL in resource-constrained\nenvironments due to its ability to support fixed-depth computations without\nrequiring costly bootstrapping. Our contributions in this paper include a\ncomprehensive evaluation of HE schemes for real-world FL applications, a\nselective encryption strategy that targets only the most sensitive gradients to\nminimize computational overhead, and the development of a full HE-based FL\npipeline that effectively mitigates DLG attacks while preserving model\naccuracy. We open-source our implementation to encourage reproducibility and\nfacilitate adoption in safety-critical domains.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07894v1", "AI": {"title_translation": "CAV安全分布式学习：使用分级同态加密防御梯度泄露", "tldr": "FL在CAV中面临梯度泄露攻击，本文提出一种基于分级同态加密的选择性加密策略和完整FL管道，有效防御攻击同时保持模型精度。", "motivation": "联邦学习（FL）在CAV等领域中是保护隐私的机器学习的有效方法，但交换的模型梯度容易受到DLG等推理攻击，这可以重建私有训练数据。现有防御方法（如差分隐私和安全多方计算）通常会损害模型精度。同态加密（HE）虽然能提供无损计算，但其引入的显著计算和通信开销阻碍了其实际应用。", "method": "本文系统评估了各种分级HE方案，以识别最适合资源受限环境下FL的方案。提出了一种选择性加密策略，仅针对最敏感的梯度进行加密，以最小化计算开销。并开发了一个完整的基于HE的FL管道。", "result": "本文提出的方法有效缓解了DLG攻击，同时保持了模型精度。研究成果已开源，以促进可重现性和在安全关键领域的采用。", "conclusion": "本文提出的基于分级同态加密的FL管道能够有效防御梯度泄露攻击，同时保持模型精度，并适用于资源受限环境。", "translation": "联邦学习（FL）实现了分布式客户端之间的协作模型训练，而无需共享原始数据，使其成为连接和自动驾驶车辆（CAV）等领域中保护隐私的机器学习的一种有前景的方法。然而，最近的研究表明，交换的模型梯度仍然容易受到推理攻击，例如基于梯度的深度泄露（DLG），这可以重建私人训练数据。虽然差分隐私（DP）和安全多方计算（SMPC）等现有防御措施提供了保护，但它们通常会损害模型精度。为此，同态加密（HE）通过直接在加密数据上实现无损计算，从而保护隐私和模型效用，提供了一个有前景的替代方案。然而，HE引入了显著的计算和通信开销，这可能会阻碍其实际应用。为了解决这个问题，我们系统地评估了各种分级HE方案，以识别最适合资源受限环境下FL的方案，因为它能够支持固定深度计算，而无需昂贵的自举。本文的贡献包括：对HE方案在实际FL应用中的综合评估；一种仅针对最敏感梯度进行加密以最小化计算开销的选择性加密策略；以及开发了一个完整的基于HE的FL管道，该管道有效缓解了DLG攻击，同时保持了模型精度。我们开源了我们的实现，以鼓励可重现性并促进其在安全关键领域的采用。", "summary": "本文针对联邦学习（FL）在连接和自动驾驶车辆（CAV）中面临的梯度泄露攻击问题，提出了一种基于分级同态加密（HE）的解决方案。研究评估了不同分级HE方案，并开发了一种选择性加密策略，仅加密最敏感的梯度以减少计算开销。最终构建了一个完整的基于HE的FL管道，该管道能有效防御梯度泄露攻击，同时不牺牲模型精度，并开源了其实现。", "keywords": "联邦学习, 同态加密, 梯度泄露, 连接和自动驾驶车辆, 隐私保护", "comments": "这篇论文的创新点在于将分级同态加密应用于联邦学习，以解决梯度泄露问题，同时通过选择性加密策略有效降低了HE的计算和通信开销，使其在资源受限的CAV环境中更具实用性。其开源实现有助于推动该领域的研究和应用。"}}
{"id": "2506.07348", "title": "UruBots Autonomous Cars Challenge Pro Team Description Paper for FIRA 2025", "authors": ["Pablo Moraes", "Mónica Rodríguez", "Sebastian Barcelona", "Angel Da Silva", "Santiago Fernandez", "Hiago Sodre", "Igor Nunes", "Bruna Guterres", "Ricardo Grando"], "summary": "This paper describes the development of an autonomous car by the UruBots team\nfor the 2025 FIRA Autonomous Cars Challenge (Pro). The project involves\nconstructing a compact electric vehicle, approximately the size of an RC car,\ncapable of autonomous navigation through different tracks. The design\nincorporates mechanical and electronic components and machine learning\nalgorithms that enable the vehicle to make real-time navigation decisions based\non visual input from a camera. We use deep learning models to process camera\nimages and control vehicle movements. Using a dataset of over ten thousand\nimages, we trained a Convolutional Neural Network (CNN) to drive the vehicle\neffectively, through two outputs, steering and throttle. The car completed the\ntrack in under 30 seconds, achieving a pace of approximately 0.4 meters per\nsecond while avoiding obstacles.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07348v1", "AI": {"title_translation": "UruBots 自动驾驶汽车挑战赛专业组团队描述论文 FIRA 2025", "tldr": "UruBots 团队为 FIRA 2025 自动驾驶汽车挑战赛开发了一辆基于深度学习的紧凑型自动驾驶小车，并成功完成了赛道测试。", "motivation": "参加 2025 年 FIRA 自动驾驶汽车挑战赛（专业组）。", "method": "构建了一辆紧凑型电动车，整合了机械、电子组件和机器学习算法。利用深度学习模型（特别是卷积神经网络 CNN）处理摄像头视觉输入，并通过超过一万张图像的数据集进行训练，以实时控制车辆的转向和油门进行导航。", "result": "车辆在 30 秒内完成了赛道，平均速度约为每秒 0.4 米，并成功避开了障碍物。", "conclusion": "该自动驾驶小车成功通过了赛道测试，证明了其在 FIRA 2025 挑战赛中的能力。", "translation": "这篇论文描述了 UruBots 团队为 2025 年 FIRA 自动驾驶汽车挑战赛（专业组）开发自动驾驶汽车的过程。该项目包括构建一辆紧凑型电动车，其大小与遥控车相近，能够自主导航通过不同的赛道。设计中整合了机械和电子组件以及机器学习算法，使车辆能够根据摄像头的视觉输入做出实时导航决策。我们使用深度学习模型处理摄像头图像并控制车辆运动。利用超过一万张图像的数据集，我们训练了一个卷积神经网络（CNN）来有效地驾驶车辆，通过转向和油门两个输出进行控制。该车在 30 秒内完成了赛道，速度约为每秒 0.4 米，同时避开了障碍物。", "summary": "本文介绍了 UruBots 团队为 2025 年 FIRA 自动驾驶汽车挑战赛专业组开发的自动驾驶小车。该车辆集成了机械、电子组件和基于深度学习的视觉导航系统，特别是使用 CNN 处理摄像头图像以控制转向和油门。经过大量图像数据集的训练，该车成功在 30 秒内以约 0.4 米/秒的速度完成赛道并避开障碍物。", "keywords": "自动驾驶汽车, FIRA 挑战赛, 深度学习, 卷积神经网络, 实时导航", "comments": "该论文展示了一个实用的自动驾驶小车开发案例，其亮点在于结合了硬件构建与基于深度学习的视觉导航系统。使用 CNN 和大量图像数据集进行训练是其成功的关键。虽然速度和尺寸受挑战赛限制，但其在实时决策和障碍规避方面的表现值得关注。"}}
{"id": "2506.06854", "title": "DONUT: A Decoder-Only Model for Trajectory Prediction", "authors": ["Markus Knoche", "Daan de Geus", "Bastian Leibe"], "summary": "Predicting the motion of other agents in a scene is highly relevant for\nautonomous driving, as it allows a self-driving car to anticipate. Inspired by\nthe success of decoder-only models for language modeling, we propose DONUT, a\nDecoder-Only Network for Unrolling Trajectories. Different from existing\nencoder-decoder forecasting models, we encode historical trajectories and\npredict future trajectories with a single autoregressive model. This allows the\nmodel to make iterative predictions in a consistent manner, and ensures that\nthe model is always provided with up-to-date information, enhancing the\nperformance. Furthermore, inspired by multi-token prediction for language\nmodeling, we introduce an 'overprediction' strategy that gives the network the\nauxiliary task of predicting trajectories at longer temporal horizons. This\nallows the model to better anticipate the future, and further improves the\nperformance. With experiments, we demonstrate that our decoder-only approach\noutperforms the encoder-decoder baseline, and achieves new state-of-the-art\nresults on the Argoverse 2 single-agent motion forecasting benchmark.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06854v1", "AI": {"title_translation": "DONUT：一种用于轨迹预测的仅解码器模型", "tldr": "DONUT是一种受语言模型启发的仅解码器模型，通过单一自回归模型和“超预测”策略，在自动驾驶轨迹预测中超越了现有方法并取得了最先进的结果。", "motivation": "自动驾驶中预测场景中其他智能体的运动至关重要，因为它能让自动驾驶汽车进行预判。", "method": "提出DONUT（Decoder-Only Network for Unrolling Trajectories），与现有编解码器预测模型不同，它使用单一自回归模型编码历史轨迹并预测未来轨迹，实现了迭代预测和信息更新。此外，引入“超预测”策略，将预测更长时间范围轨迹作为辅助任务。", "result": "实验证明，DONUT的仅解码器方法优于编解码器基线，并在Argoverse 2单智能体运动预测基准测试中取得了新的最先进结果。", "conclusion": "DONUT通过其独特的仅解码器架构和“超预测”策略，显著提升了轨迹预测性能，并在相关基准测试中达到了最先进水平。", "translation": "预测场景中其他智能体的运动与自动驾驶高度相关，因为它能让自动驾驶汽车进行预判。受语言建模中仅解码器模型成功的启发，我们提出了DONUT，一个用于展开轨迹的仅解码器网络（Decoder-Only Network for Unrolling Trajectories）。与现有编解码器预测模型不同，我们使用单一自回归模型编码历史轨迹并预测未来轨迹。这使得模型能够以一致的方式进行迭代预测，并确保模型始终获得最新信息，从而提高性能。此外，受语言建模中多令牌预测的启发，我们引入了一种“超预测”策略，赋予网络在更长的时间范围内预测轨迹的辅助任务。这使得模型能够更好地预判未来，并进一步提高性能。通过实验，我们证明了我们的仅解码器方法优于编解码器基线，并在Argoverse 2单智能体运动预测基准测试中取得了新的最先进结果。", "summary": "本文提出了DONUT，一种受语言模型启发的仅解码器网络，用于自动驾驶中的轨迹预测。与传统的编解码器模型不同，DONUT采用单一自回归模型处理历史和未来轨迹，并引入“超预测”策略以增强长期预测能力。实验结果表明，DONUT在Argoverse 2基准测试中超越了现有编解码器方法，并达到了最先进的性能。", "keywords": "轨迹预测, 仅解码器模型, 自动驾驶, 自回归模型, 超预测", "comments": "DONUT的创新之处在于将语言模型中成功的仅解码器架构和多令牌预测（超预测）策略应用于轨迹预测任务，这提供了一种新颖且有效的建模范式。其自回归和信息更新的特性，以及辅助的超预测任务，显著提升了模型性能，并在自动驾驶领域展现了重要应用潜力。"}}
{"id": "2506.07047", "title": "Mathesis: Towards Formal Theorem Proving from Natural Languages", "authors": ["Yu Xuejun", "Jianyuan Zhong", "Zijin Feng", "Pengyi Zhai", "Roozbeh Yousefzadeh", "Wei Chong Ng", "Haoxiong Liu", "Ziyi Shou", "Jing Xiong", "Yudong Zhou", "Claudia Beth Ong", "Austen Jeremy Sugiarto", "Yaoxi Zhang", "Wai Ming Tai", "Huan Cao", "Dongcai Lu", "Jiacheng Sun", "Qiang Xu", "Shen Xin", "Zhenguo Li"], "summary": "Recent advances in large language models show strong promise for formal\nreasoning. However, most LLM-based theorem provers have long been constrained\nby the need for expert-written formal statements as inputs, limiting their\napplicability to real-world problems expressed in natural language. We tackle\nthis gap with Mathesis, the first end-to-end theorem proving pipeline\nprocessing informal problem statements. It contributes Mathesis-Autoformalizer,\nthe first autoformalizer using reinforcement learning to enhance the\nformalization ability of natural language problems, aided by our novel\nLeanScorer framework for nuanced formalization quality assessment. It also\nproposes a Mathesis-Prover, which generates formal proofs from the formalized\nstatements. To evaluate the real-world applicability of end-to-end formal\ntheorem proving, we introduce Gaokao-Formal, a benchmark of 488 complex\nproblems from China's national college entrance exam. Our approach is carefully\ndesigned, with a thorough study of each component. Experiments demonstrate\nMathesis's effectiveness, with the autoformalizer outperforming the best\nbaseline by 22% in pass-rate on Gaokao-Formal. The full system surpasses other\nmodel combinations, achieving 64% accuracy on MiniF2F with pass@32 and a\nstate-of-the-art 18% on Gaokao-Formal.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07047v1", "AI": {"title_translation": "Mathesis：迈向自然语言形式化定理证明", "tldr": "Mathesis是一个端到端的定理证明系统，能够直接处理自然语言问题，并通过强化学习自动形式化，在真实世界基准测试中表现出色。", "motivation": "现有的基于大型语言模型的定理证明器需要专家编写的形式化语句作为输入，这限制了它们在处理自然语言表达的实际问题时的适用性。", "method": "本文提出了Mathesis，一个端到端的定理证明流程，可以直接处理非形式化问题陈述。它包含Mathesis-Autoformalizer，这是第一个使用强化学习来增强自然语言问题形式化能力的自动形式化器，并辅以LeanScorer框架进行细致的形式化质量评估。此外，它还提出了Mathesis-Prover，用于从形式化语句生成形式化证明。为了评估端到端形式化定理证明的实际适用性，引入了Gaokao-Formal，一个包含488个来自中国高考的复杂问题的基准测试。", "result": "实验证明了Mathesis的有效性，其自动形式化器在Gaokao-Formal上的通过率比最佳基线高出22%。整个系统在MiniF2F上实现了64%的准确率（pass@32），在Gaokao-Formal上达到了18%的最新水平。", "conclusion": "Mathesis系统及其组件被精心设计并经过彻底研究，实验结果证明了其在从自然语言进行端到端形式化定理证明方面的有效性和优越性，尤其是在处理真实世界复杂问题方面。", "translation": "标题：Mathesis：迈向自然语言形式化定理证明\n\n摘要：大型语言模型在形式化推理方面展现出强大的前景。然而，大多数基于大型语言模型的定理证明器长期以来受限于需要专家编写的形式化语句作为输入，这限制了它们在处理自然语言表达的实际问题时的适用性。我们通过Mathesis解决了这一空白，它是第一个处理非形式化问题陈述的端到端定理证明流程。它贡献了Mathesis-Autoformalizer，这是第一个使用强化学习来增强自然语言问题形式化能力的自动形式化器，并辅以我们新颖的LeanScorer框架进行细致的形式化质量评估。它还提出了Mathesis-Prover，用于从形式化语句生成形式化证明。为了评估端到端形式化定理证明的实际适用性，我们引入了Gaokao-Formal，一个包含488个来自中国高考的复杂问题的基准测试。我们的方法经过精心设计，对每个组件进行了彻底研究。实验证明了Mathesis的有效性，其自动形式化器在Gaokao-Formal上的通过率比最佳基线高出22%。整个系统在MiniF2F上实现了64%的准确率（pass@32），在Gaokao-Formal上达到了18%的最新水平。", "summary": "Mathesis提出了一个创新的端到端定理证明流程，旨在解决大型语言模型在处理自然语言问题时需要专家级形式化输入的局限性。该系统包含一个基于强化学习的自动形式化器（Mathesis-Autoformalizer），通过LeanScorer框架评估形式化质量，以及一个证明生成器（Mathesis-Prover）。为了验证其实用性，研究人员创建了Gaokao-Formal基准测试。实验结果表明，Mathesis在自动形式化方面显著优于现有基线，并在MiniF2F和Gaokao-Formal等基准测试中取得了先进的证明准确率，展示了从自然语言进行形式化定理证明的巨大潜力。", "keywords": "形式化定理证明, 自然语言处理, 大型语言模型, 自动形式化, 强化学习", "comments": "Mathesis的创新之处在于其构建了一个完整的端到端管道，直接将自然语言问题转化为形式化证明，这大大降低了形式化定理证明的门槛。其引入强化学习进行自动形式化是一个重要的突破，能够更好地适应自然语言的复杂性和多样性。Gaokao-Formal基准的建立也为真实世界问题的评估提供了有价值的工具。这项工作对于推动LLM在形式化推理领域的实际应用具有重要意义，有望在未来实现更广泛的自动化数学证明。"}}
{"id": "2506.06558", "title": "Rapid training of Hamiltonian graph networks without gradient descent", "authors": ["Atamert Rahma", "Chinmay Datar", "Ana Cukarska", "Felix Dietrich"], "summary": "Learning dynamical systems that respect physical symmetries and constraints\nremains a fundamental challenge in data-driven modeling. Integrating physical\nlaws with graph neural networks facilitates principled modeling of complex\nN-body dynamics and yields accurate and permutation-invariant models. However,\ntraining graph neural networks with iterative, gradient-based optimization\nalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,\nespecially for large, complex systems. In comparison to 15 different\noptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trained\nup to 600x faster--but with comparable accuracy--by replacing iterative\noptimization with random feature-based parameter construction. We show robust\nperformance in diverse simulations, including N-body mass-spring systems in up\nto 3 dimensions with different geometries, while retaining essential physical\ninvariances with respect to permutation, rotation, and translation. We reveal\nthat even when trained on minimal 8-node systems, the model can generalize in a\nzero-shot manner to systems as large as 4096 nodes without retraining. Our work\nchallenges the dominance of iterative gradient-descent-based optimization\nalgorithms for training neural network models for physical systems.", "comment": "10 pages, 7 figures, 2 tables, and an appendix", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06558v1", "AI": {"title_translation": "无需梯度下降的哈密顿图网络快速训练", "tldr": "该研究提出了一种无需梯度下降的随机特征参数构建方法，可将哈密顿图网络（HGN）的训练速度提高多达600倍，且准确性相当，并能零样本泛化到更大的系统。", "motivation": "在数据驱动建模中，学习遵守物理对称性和约束的动力系统是一个基本挑战。将物理定律与图神经网络结合可以对复杂的N体动力学进行建模，但使用迭代的、基于梯度的优化算法（如Adam、RMSProp、LBFGS）训练图神经网络通常会导致训练缓慢，特别是对于大型复杂系统。", "method": "该研究通过用基于随机特征的参数构建取代迭代优化，来训练哈密顿图网络（HGN）。", "result": "与15种不同的优化器相比，哈密顿图网络（HGN）的训练速度提高了多达600倍，但精度相当。该方法在包括N体质量-弹簧系统（在不同几何形状的3D空间中）在内的各种模拟中表现出稳健的性能，同时保留了置换、旋转和平移等基本物理不变性。即使在最小的8节点系统上训练，模型也能以零样本方式泛化到多达4096个节点的系统，无需重新训练。", "conclusion": "该工作挑战了迭代梯度下降优化算法在物理系统神经网络模型训练中的主导地位。", "translation": "在数据驱动建模中，学习遵守物理对称性和约束的动力系统仍然是一个基本挑战。将物理定律与图神经网络相结合有助于对复杂的N体动力学进行原则性建模，并产生准确且置换不变的模型。然而，使用迭代的、基于梯度的优化算法（例如Adam、RMSProp、LBFGS）训练图神经网络通常会导致训练缓慢，特别是对于大型复杂系统。与15种不同的优化器相比，我们证明了哈密顿图网络（HGN）可以通过用基于随机特征的参数构建取代迭代优化，从而将训练速度提高多达600倍——但准确性相当。我们展示了在各种模拟中稳健的性能，包括在具有不同几何形状的多达3维的N体质量-弹簧系统，同时保留了关于置换、旋转和平移的基本物理不变性。我们揭示，即使在最小的8节点系统上进行训练，该模型也能以零样本方式泛化到多达4096个节点的系统，无需重新训练。我们的工作挑战了迭代梯度下降优化算法在物理系统神经网络模型训练中的主导地位。", "summary": "该论文提出了一种无需梯度下降即可快速训练哈密顿图网络（HGN）的新方法。通过用基于随机特征的参数构建取代传统的迭代优化，HGN的训练速度比现有优化器快600倍，同时保持相似的准确性。该模型在各种N体动力学模拟中表现出强大的鲁棒性，并能零样本泛化到远大于训练规模的系统，挑战了梯度下降在物理系统建模中的主导地位。", "keywords": "哈密顿图网络, 梯度下降, 随机特征, 快速训练, 动力系统", "comments": "这项工作具有重要意义，因为它打破了神经网络在物理系统建模中对梯度下降优化的依赖。通过引入随机特征参数构建，它显著提高了训练效率，同时保持了准确性和关键的物理不变性。特别值得注意的是其零样本泛化能力，这表明该模型在处理大规模复杂系统方面具有巨大潜力。这为开发更高效、可扩展的物理建模AI提供了新的方向。"}}
{"id": "2506.06339", "title": "Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components", "authors": ["Jumana Alsubhi", "Mohammad D. Alahmadi", "Ahmed Alhusayni", "Ibrahim Aldailami", "Israa Hamdine", "Ahmad Shabana", "Yazeed Iskandar", "Suhayb Khayyat"], "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful architecture\nfor combining the precision of retrieval systems with the fluency of large\nlanguage models. While several studies have investigated RAG pipelines for\nhigh-resource languages, the optimization of RAG components for Arabic remains\nunderexplored. This study presents a comprehensive empirical evaluation of\nstate-of-the-art RAG components-including chunking strategies, embedding\nmodels, rerankers, and language models-across a diverse set of Arabic datasets.\nUsing the RAGAS framework, we systematically compare performance across four\ncore metrics: context precision, context recall, answer faithfulness, and\nanswer relevancy. Our experiments demonstrate that sentence-aware chunking\noutperforms all other segmentation methods, while BGE-M3 and\nMultilingual-E5-large emerge as the most effective embedding models. The\ninclusion of a reranker (bge-reranker-v2-m3) significantly boosts faithfulness\nin complex datasets, and Aya-8B surpasses StableLM in generation quality. These\nfindings provide critical insights for building high-quality Arabic RAG\npipelines and offer practical guidelines for selecting optimal components\nacross different document types.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06339v1", "AI": {"title_translation": "优化阿拉伯语RAG管道：核心组件的系统分析", "tldr": "本研究对阿拉伯语RAG管道的核心组件进行了全面实证评估，发现句子感知分块、BGE-M3和Multilingual-E5-large嵌入模型、bge-reranker-v2-m3重排序器以及Aya-8B语言模型表现最佳，为构建高质量阿拉伯语RAG提供了实用指导。", "motivation": "尽管RAG管道在处理高资源语言方面已得到广泛研究，但其组件在阿拉伯语环境下的优化仍未得到充分探索，因此需要进行系统性评估。", "method": "本研究对分块策略、嵌入模型、重排序器和语言模型等RAG核心组件进行了全面的实证评估。实验使用了多样化的阿拉伯语数据集，并利用RAGAS框架，通过上下文精度、上下文召回率、答案忠实度和答案相关性四个核心指标系统地比较了性能。", "result": "实验结果表明，句子感知分块优于所有其他分段方法。BGE-M3和Multilingual-E5-large是最有效的嵌入模型。重排序器（bge-reranker-v2-m3）的加入显著提高了复杂数据集的忠实度。Aya-8B在生成质量上超越了StableLM。", "conclusion": "这些发现为构建高质量的阿拉伯语RAG管道提供了关键见解，并为不同文档类型选择最佳组件提供了实用指南。", "translation": "检索增强生成（RAG）已成为一种强大的架构，能够将检索系统的精确性与大型语言模型的流畅性相结合。尽管有几项研究调查了高资源语言的RAG管道，但阿拉伯语RAG组件的优化仍未得到充分探索。本研究对最先进的RAG组件——包括分块策略、嵌入模型、重排序器和语言模型——在多样化的阿拉伯语数据集上进行了全面的实证评估。我们使用RAGAS框架，系统地比较了上下文精度、上下文召回率、答案忠实度和答案相关性这四个核心指标的性能。我们的实验表明，句子感知分块优于所有其他分段方法，而BGE-M3和Multilingual-E5-large成为最有效的嵌入模型。重排序器（bge-reranker-v2-m3）的加入显著提高了复杂数据集的忠实度，并且Aya-8B在生成质量上超越了StableLM。这些发现为构建高质量的阿拉伯语RAG管道提供了关键见解，并为不同文档类型选择最佳组件提供了实用指南。", "summary": "本研究针对阿拉伯语RAG（检索增强生成）管道的核心组件进行了首次全面实证评估。通过系统比较分块策略、嵌入模型、重排序器和语言模型在多个阿拉伯语数据集上的表现，研究发现句子感知分块、BGE-M3和Multilingual-E5-large嵌入模型、bge-reranker-v2-m3重排序器以及Aya-8B语言模型在各项指标上表现突出。这些结果为优化阿拉伯语RAG系统提供了关键指导和实用建议。", "keywords": "RAG, 阿拉伯语, 优化, 嵌入模型, 重排序器", "comments": "这项研究填补了阿拉伯语RAG管道优化领域的空白，通过系统的实证分析提供了宝贵的实践指导。其创新性在于首次对阿拉伯语RAG核心组件进行了全面评估，并明确指出了在特定语言环境下表现最佳的组件组合。这对于推动阿拉伯语自然语言处理技术的发展具有重要意义。"}}
{"id": "2506.07974", "title": "Exposing Hidden Backdoors in NFT Smart Contracts: A Static Security Analysis of Rug Pull Patterns", "authors": ["Chetan Pathade", "Shweta Hooli"], "summary": "The explosive growth of Non-Fungible Tokens (NFTs) has revolutionized digital\nownership by enabling the creation, exchange, and monetization of unique assets\non blockchain networks. However, this surge in popularity has also given rise\nto a disturbing trend: the emergence of rug pulls - fraudulent schemes where\ndevelopers exploit trust and smart contract privileges to drain user funds or\ninvalidate asset ownership. Central to many of these scams are hidden backdoors\nembedded within NFT smart contracts. Unlike unintentional bugs, these backdoors\nare deliberately coded and often obfuscated to bypass traditional audits and\nexploit investor confidence. In this paper, we present a large-scale static\nanalysis of 49,940 verified NFT smart contracts using Slither, a static\nanalysis framework, to uncover latent vulnerabilities commonly linked to rug\npulls. We introduce a custom risk scoring model that classifies contracts into\nhigh, medium, or low risk tiers based on the presence and severity of rug pull\nindicators. Our dataset was derived from verified contracts on the Ethereum\nmainnet, and we generate multiple visualizations to highlight red flag\nclusters, issue prevalence, and co-occurrence of critical vulnerabilities.\nWhile we do not perform live exploits, our results reveal how malicious\npatterns often missed by simple reviews can be surfaced through static analysis\nat scale. We conclude by offering mitigation strategies for developers,\nmarketplaces, and auditors to enhance smart contract security. By exposing how\nhidden backdoors manifest in real-world smart contracts, this work contributes\na practical foundation for detecting and mitigating NFT rug pulls through\nscalable automated analysis.", "comment": "10 Pages, 4 Figures", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07974v1", "AI": {"title_translation": "揭露NFT智能合约中的隐藏后门：一种地毯式拉盘模式的静态安全分析", "tldr": "本文通过对49,940个NFT智能合约进行大规模静态分析，揭示了与“地毯式拉盘”骗局相关的隐藏后门和漏洞，并提出了风险评分模型及缓解策略。", "motivation": "NFT的爆炸式增长催生了“地毯式拉盘”骗局，其中开发者利用智能合约特权和隐藏后门来窃取用户资金或使资产所有权失效。传统的审计往往无法发现这些故意编码和混淆的后门。因此，需要一种大规模、可扩展的方法来检测这些恶意模式。", "method": "作者对49,940个经过验证的NFT智能合约进行了大规模静态分析，使用了Slither静态分析框架来发现与“地毯式拉盘”相关的潜在漏洞。他们引入了一个自定义风险评分模型，根据“地毯式拉盘”指标的存在和严重性将合约分为高、中、低风险等级。数据集来源于以太坊主网上的验证合约，并生成了多重可视化图表来突出危险信号集群、问题普遍性和关键漏洞的共现性。", "result": "研究结果揭示了通过大规模静态分析，可以发现简单审查容易遗漏的恶意模式。尽管没有进行实时攻击，但分析表明了隐藏后门在真实世界智能合约中的表现形式。", "conclusion": "该工作为通过可扩展的自动化分析检测和缓解NFT“地毯式拉盘”提供了实用基础。文章最后提出了针对开发者、市场和审计师的缓解策略，以增强智能合约的安全性。", "translation": "非同质化代币（NFT）的爆炸式增长通过在区块链网络上实现独特资产的创建、交换和货币化，彻底改变了数字所有权。然而，这种受欢迎程度的激增也催生了一种令人不安的趋势：地毯式拉盘的出现——即开发者利用信任和智能合约特权来耗尽用户资金或使资产所有权失效的欺诈性方案。许多此类骗局的核心是嵌入在NFT智能合约中的隐藏后门。与无意的错误不同，这些后门是故意编码并经常被混淆以绕过传统审计并利用投资者信心。在本文中，我们对49,940个经过验证的NFT智能合约进行了大规模静态分析，使用Slither（一个静态分析框架）来揭示通常与地毯式拉盘相关的潜在漏洞。我们引入了一个自定义风险评分模型，根据地毯式拉盘指标的存在和严重性将合约分为高、中或低风险等级。我们的数据集来源于以太坊主网上的验证合约，我们生成了多个可视化图表以突出危险信号集群、问题普遍性和关键漏洞的共现。虽然我们没有进行实时攻击，但我们的结果揭示了通过大规模静态分析如何发现简单审查经常遗漏的恶意模式。最后，我们为开发者、市场和审计师提供了缓解策略，以增强智能合约的安全性。通过揭示隐藏后门在真实世界智能合约中的表现形式，这项工作为通过可扩展的自动化分析检测和缓解NFT地毯式拉盘提供了实用基础。", "summary": "本文针对NFT市场中日益增长的“地毯式拉盘”骗局，通过对近5万个NFT智能合约进行大规模静态安全分析，旨在揭露其中隐藏的恶意后门。研究利用Slither框架和自定义风险评分模型，识别并分类了与“地毯式拉盘”相关的潜在漏洞，并通过可视化展示了这些危险模式的普遍性和共现性。研究结果表明，静态分析能有效发现传统审计难以察觉的恶意代码，并为开发者、平台和审计师提供了实用的缓解策略，以提升NFT智能合约的安全性。", "keywords": "NFT, 智能合约, 地毯式拉盘, 静态分析, 安全漏洞", "comments": "这项研究的重要性在于它直击了NFT市场中一个日益严重的信任问题——“地毯式拉盘”骗局。通过大规模的静态分析，它提供了一种可扩展且自动化的方法来识别智能合约中的恶意后门，这对于保护投资者和维护市场健康至关重要。其创新点在于结合了现有的静态分析工具和自定义的风险评分模型，能够有效地分类和可视化风险。尽管没有进行实时攻击，但其揭示的模式对于预防和教育具有重要价值。"}}
{"id": "2506.07350", "title": "MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation", "authors": ["Yijie Deng", "Shuaihang Yuan", "Congcong Wen", "Hao Huang", "Anthony Tzes", "Geeta Chandra Raju Bethala", "Yi Fang"], "summary": "Spatial awareness is a critical capability for embodied agents, as it enables\nthem to anticipate and reason about unobserved regions. The primary challenge\narises from learning the distribution of indoor semantics, complicated by\nsparse, imbalanced object categories and diverse spatial scales. Existing\nmethods struggle to robustly generate unobserved areas in real time and do not\ngeneralize well to new environments. To this end, we propose \\textbf{MapBERT},\na novel framework designed to effectively model the distribution of unseen\nspaces. Motivated by the observation that the one-hot encoding of semantic maps\naligns naturally with the binary structure of bit encoding, we, for the first\ntime, leverage a lookup-free BitVAE to encode semantic maps into compact\nbitwise tokens. Building on this, a masked transformer is employed to infer\nmissing regions and generate complete semantic maps from limited observations.\nTo enhance object-centric reasoning, we propose an object-aware masking\nstrategy that masks entire object categories concurrently and pairs them with\nlearnable embeddings, capturing implicit relationships between object\nembeddings and spatial tokens. By learning these relationships, the model more\neffectively captures indoor semantic distributions crucial for practical\nrobotic tasks. Experiments on Gibson benchmarks show that MapBERT achieves\nstate-of-the-art semantic map generation, balancing computational efficiency\nwith accurate reconstruction of unobserved regions.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07350v1", "AI": {"title_translation": "MapBERT：实时语义地图生成的位掩码建模", "tldr": "MapBERT提出了一种基于位掩码建模的新框架，利用BitVAE和掩码Transformer，通过对象感知掩码策略，实现实时、鲁棒且高效的语义地图生成，并在Gibson基准测试中达到SOTA。", "motivation": "现有方法在实时生成未观测区域方面存在困难，且泛化性差，尤其是在学习室内语义分布时面临稀疏、不平衡的对象类别和多样化的空间尺度挑战。", "method": "提出MapBERT框架。首次利用查找表无关的BitVAE将语义地图编码为紧凑的位掩码令牌。在此基础上，使用掩码Transformer来推断缺失区域并从有限观测中生成完整的语义地图。为增强以对象为中心的推理，提出了对象感知掩码策略，同时掩码整个对象类别，并将其与可学习嵌入配对。", "result": "MapBERT在Gibson基准测试中实现了最先进的语义地图生成，平衡了计算效率和对未观测区域的准确重建。", "conclusion": "MapBERT通过其新颖的位掩码建模和对象感知策略，有效解决了实时语义地图生成中的挑战，实现了高性能和高效率，对机器人任务至关重要。", "translation": "空间感知是具身智能体的关键能力，因为它使它们能够预测和推断未观测区域。主要挑战源于学习室内语义的分布，这因稀疏、不平衡的对象类别和多样化的空间尺度而变得复杂。现有方法难以实时鲁棒地生成未观测区域，并且对新环境的泛化性不佳。为此，我们提出了\\textbf{MapBERT}，一个旨在有效建模未见空间分布的新颖框架。受语义地图独热编码与位编码二进制结构自然对齐的启发，我们首次利用查找表无关的BitVAE将语义地图编码为紧凑的位掩码令牌。在此基础上，采用掩码Transformer来推断缺失区域并从有限观测中生成完整的语义地图。为了增强以对象为中心的推理，我们提出了一种对象感知掩码策略，该策略同时掩码整个对象类别，并将其与可学习嵌入配对，捕获对象嵌入和空间令牌之间的隐式关系。通过学习这些关系，模型更有效地捕获对实际机器人任务至关重要的室内语义分布。Gibson基准测试的实验表明，MapBERT实现了最先进的语义地图生成，平衡了计算效率和对未观测区域的准确重建。", "summary": "MapBERT是一个新颖的框架，旨在解决具身智能体在实时语义地图生成中面临的挑战，特别是针对未观测区域的鲁棒性和泛化性问题。该方法首次利用查找表无关的BitVAE将语义地图编码为紧凑的位掩码令牌，并结合掩码Transformer来推断缺失区域。为提升对象感知推理，MapBERT引入了对象感知掩码策略，通过学习对象嵌入和空间令牌间的关系，有效捕获室内语义分布。实验证明，MapBERT在Gibson基准测试中实现了最先进的语义地图生成，同时保持了计算效率和高准确度。", "keywords": "语义地图生成, 位掩码建模, MapBERT, BitVAE, 掩码Transformer", "comments": "MapBERT的创新之处在于首次将语义地图的独热编码与位编码的二进制结构相结合，并引入查找表无关的BitVAE进行高效编码。结合掩码Transformer和对象感知掩码策略，有效提升了模型对复杂室内语义分布的建模能力和对未观测区域的重建精度。其实时性和高效率对于实际机器人应用具有重要意义。"}}
{"id": "2506.06856", "title": "Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning", "authors": ["Chaoyang Wang", "Zeyu Zhang", "Haiyun Jiang"], "summary": "Visual reasoning is crucial for understanding complex multimodal data and\nadvancing Artificial General Intelligence. Existing methods enhance the\nreasoning capability of Multimodal Large Language Models (MLLMs) through\nReinforcement Learning (RL) fine-tuning (e.g., GRPO). However, current RL\napproaches sample action groups solely from the policy model itself, which\nlimits the upper boundary of the model's reasoning capability and leads to\ninefficient training. To address these limitations, this paper proposes a novel\nRL framework called \\textbf{Vision-EKIPL}. The core of this framework lies in\nintroducing high-quality actions generated by external auxiliary models during\nthe RL training process to guide the optimization of the policy model. The\npolicy learning with knowledge infusion from external models significantly\nexpands the model's exploration space, effectively improves the reasoning\nboundary, and substantially accelerates training convergence speed and\nefficiency. Experimental results demonstrate that our proposed Vision-EKIPL\nachieved up to a 5\\% performance improvement on the Reason-RFT-CoT Benchmark\ncompared to the state-of-the-art (SOTA). It reveals that Vision-EKIPL can\novercome the limitations of traditional RL methods, significantly enhance the\nvisual reasoning performance of MLLMs, and provide a new effective paradigm for\nresearch in this field.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06856v1", "AI": {"title_translation": "视觉-EKIPL：用于视觉推理的外部知识注入策略学习", "tldr": "Vision-EKIPL通过引入外部高质量动作来指导策略模型优化，显著提升了多模态大语言模型（MLLMs）的视觉推理能力和训练效率。", "motivation": "现有强化学习方法在多模态大语言模型（MLLMs）中进行推理时，动作组仅从策略模型本身采样，这限制了模型的推理能力上限并导致训练效率低下。", "method": "本文提出了一种名为Vision-EKIPL的新型强化学习框架。其核心是在强化学习训练过程中引入由外部辅助模型生成的高质量动作来指导策略模型的优化。这种知识注入显著扩展了模型的探索空间。", "result": "Vision-EKIPL在Reason-RFT-CoT基准测试上比现有最佳方法（SOTA）提高了高达5%的性能。", "conclusion": "Vision-EKIPL能够克服传统强化学习方法的局限性，显著增强MLLMs的视觉推理性能，并为该领域的研究提供了一种新的有效范式。", "translation": "视觉推理对于理解复杂的多模态数据和推进通用人工智能至关重要。现有方法通过强化学习（RL）微调（例如GRPO）增强多模态大语言模型（MLLMs）的推理能力。然而，当前的RL方法仅从策略模型本身采样动作组，这限制了模型的推理能力上限并导致训练效率低下。为了解决这些局限性，本文提出了一种名为Vision-EKIPL的新型RL框架。该框架的核心是在RL训练过程中引入由外部辅助模型生成的高质量动作来指导策略模型的优化。这种从外部模型注入知识的策略学习显著扩展了模型的探索空间，有效提高了推理边界，并大大加速了训练收敛速度和效率。实验结果表明，我们提出的Vision-EKIPL在Reason-RFT-CoT基准测试上比现有最佳方法（SOTA）提高了高达5%的性能。这揭示了Vision-EKIPL可以克服传统RL方法的局限性，显著增强MLLMs的视觉推理性能，并为该领域的研究提供了一种新的有效范式。", "summary": "本文提出了Vision-EKIPL，一个新颖的强化学习框架，旨在解决现有RL方法在多模态大语言模型（MLLMs）视觉推理中动作采样受限和训练效率低下的问题。Vision-EKIPL通过引入外部辅助模型生成的高质量动作来指导策略模型优化，从而扩展探索空间，提高推理能力上限，并加速训练收敛。实验证明，Vision-EKIPL在特定基准测试上实现了显著的性能提升，为视觉推理领域提供了新的解决方案。", "keywords": "视觉推理, 强化学习, 多模态大语言模型, 外部知识注入, 策略学习", "comments": "Vision-EKIPL的创新点在于将外部知识引入到强化学习的策略学习过程中，这有效地突破了传统RL方法中动作空间受限于策略模型本身的瓶颈。这种方法不仅提升了模型性能，还显著提高了训练效率，为未来多模态推理模型的设计提供了有价值的参考。"}}
{"id": "2506.07075", "title": "Reasoning Paths as Signals: Augmenting Multi-hop Fact Verification through Structural Reasoning Progression", "authors": ["Liwen Zheng", "Chaozhuo Li", "Haoran Jia", "Xi Zhang"], "summary": "The growing complexity of factual claims in real-world scenarios presents\nsignificant challenges for automated fact verification systems, particularly in\naccurately aggregating and reasoning over multi-hop evidence. Existing\napproaches often rely on static or shallow models that fail to capture the\nevolving structure of reasoning paths, leading to fragmented retrieval and\nlimited interpretability. To address these issues, we propose a Structural\nReasoning framework for Multi-hop Fact Verification that explicitly models\nreasoning paths as structured graphs throughout both evidence retrieval and\nclaim verification stages. Our method comprises two key modules: a\nstructure-enhanced retrieval mechanism that constructs reasoning graphs to\nguide evidence collection, and a reasoning-path-guided verification module that\nincrementally builds subgraphs to represent evolving inference trajectories. We\nfurther incorporate a structure-aware reasoning mechanism that captures\nlong-range dependencies across multi-hop evidence chains, enabling more precise\nverification. Extensive experiments on the FEVER and HoVer datasets demonstrate\nthat our approach consistently outperforms strong baselines, highlighting the\neffectiveness of reasoning-path modeling in enhancing retrieval precision and\nverification accuracy.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07075v1", "AI": {"title_translation": "推理路径作为信号：通过结构化推理进展增强多跳事实核查", "tldr": "提出一种结构化推理框架，通过将推理路径建模为结构化图来增强多跳事实核查的证据检索和声明核查。", "motivation": "现有自动化事实核查系统在准确聚合和推理多跳证据方面面临挑战，因为它们依赖静态或浅层模型，未能捕捉推理路径的演变结构，导致证据检索碎片化和可解释性有限。", "method": "本文提出一个结构化推理框架，在证据检索和声明核查阶段都明确将推理路径建模为结构化图。该方法包含两个关键模块：一个结构增强检索机制，用于构建推理图以指导证据收集；以及一个推理路径引导的核查模块，用于逐步构建子图以表示演变的推理轨迹。此外，还整合了结构感知推理机制，以捕捉多跳证据链中的长程依赖。", "result": "在FEVER和HoVer数据集上的广泛实验表明，该方法始终优于强大的基线，突出了推理路径建模在增强检索精度和核查准确性方面的有效性。", "conclusion": "通过将推理路径显式建模为结构化图，本文提出的方法显著提高了多跳事实核查系统的证据检索精度和核查准确性。", "translation": "现实世界场景中事实主张日益增长的复杂性给自动化事实核查系统带来了重大挑战，特别是在准确聚合和推理多跳证据方面。现有方法通常依赖静态或浅层模型，未能捕捉推理路径的演变结构，导致检索碎片化和可解释性有限。为了解决这些问题，我们提出了一种用于多跳事实核查的结构化推理框架，该框架在证据检索和声明核查阶段都明确将推理路径建模为结构化图。我们的方法包含两个关键模块：一个结构增强检索机制，用于构建推理图以指导证据收集；以及一个推理路径引导的核查模块，用于逐步构建子图以表示演变的推理轨迹。我们进一步整合了一种结构感知推理机制，该机制捕捉多跳证据链中的长程依赖，从而实现更精确的核查。在FEVER和HoVer数据集上的广泛实验表明，我们的方法始终优于强大的基线，突出了推理路径建模在增强检索精度和核查准确性方面的有效性。", "summary": "本文提出了一种结构化推理框架，用于解决多跳事实核查中证据聚合和推理的挑战。该框架将推理路径建模为结构化图，并包含结构增强检索和推理路径引导的核查模块，以指导证据收集和表示推理轨迹。实验证明，该方法在提高检索精度和核查准确性方面优于现有基线。", "keywords": "多跳事实核查, 推理路径, 结构化图, 证据检索, 声明核查", "comments": "这篇论文的创新点在于将推理路径显式地建模为结构化图，并在证据检索和声明核查的全过程中利用这些结构信息。这种方法有效地解决了现有系统在处理复杂多跳证据时面临的碎片化检索和可解释性差的问题，通过捕捉长程依赖关系显著提升了多跳事实核查的性能和准确性。"}}
{"id": "2506.06571", "title": "Graph Persistence goes Spectral", "authors": ["Mattie Ji", "Amauri H. Souza", "Vikas Garg"], "summary": "Including intricate topological information (e.g., cycles) provably enhances\nthe expressivity of message-passing graph neural networks (GNNs) beyond the\nWeisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods\nare increasingly employed for graph representation learning. In this context,\nrecent works have proposed decorating classical PH diagrams with vertex and\nedge features for improved expressivity. However, due to their dependence on\nfeatures, these methods still fail to capture basic graph structural\ninformation. In this paper, we propose SpectRe -- a new topological descriptor\nfor graphs that integrates spectral information into PH diagrams. Notably,\nSpectRe is strictly more expressive than existing descriptors on graphs. We\nalso introduce notions of global and local stability to analyze existing\ndescriptors and establish that SpectRe is locally stable. Finally, experiments\non synthetic and real-world datasets demonstrate the effectiveness of SpectRe\nand its potential to enhance the capabilities of graph models in relevant\nlearning tasks.", "comment": "24 pages, 4 figures, 6 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06571v1", "AI": {"title_translation": "图持久性走向谱域", "tldr": "本文提出了SpectRe，一种新的图拓扑描述符，它将谱信息与持久同调（PH）结合，以提高GNN的表达能力，并证明其比现有方法更具表达力和局部稳定性。", "motivation": "现有的用于图表示学习的持久同调（PH）方法，尽管通过特征来装饰PH图，但由于其对特征的依赖性，未能捕获基本的图结构信息。这限制了消息传递图神经网络（GNN）的表达能力，使其无法超越Weisfeiler-Leman（WL）层次结构，尽管已知包含像循环这样的拓扑信息可以增强表达能力。", "method": "本文提出了SpectRe——一种新的图拓扑描述符，它将谱信息集成到持久同调（PH）图中。此外，论文还引入了全局和局部稳定性的概念来分析现有描述符，并确定SpectRe是局部稳定的。", "result": "SpectRe在图上的表达能力严格优于现有描述符。它被证明是局部稳定的。在合成和真实世界数据集上的实验证明了SpectRe的有效性。", "conclusion": "SpectRe通过将谱信息集成到PH图中，有效地增强了图模型在相关学习任务中的能力，解决了以往依赖特征的方法的局限性，并证明了其卓越的表达能力和局部稳定性。", "translation": "将复杂的拓扑信息（例如循环）包含在内，可以证明地增强消息传递图神经网络（GNN）的表达能力，使其超越Weisfeiler-Leman（WL）层次结构。因此，持久同调（PH）方法越来越多地被用于图表示学习。在此背景下，最近的工作提出用顶点和边缘特征来装饰经典的PH图，以提高表达能力。然而，由于它们依赖于特征，这些方法仍然无法捕获基本的图结构信息。在本文中，我们提出了SpectRe——一种新的图拓扑描述符，它将谱信息集成到PH图中。值得注意的是，SpectRe在图上的表达能力严格优于现有描述符。我们还引入了全局和局部稳定性的概念来分析现有描述符，并确定SpectRe是局部稳定的。最后，在合成和真实世界数据集上的实验证明了SpectRe的有效性及其在相关学习任务中增强图模型能力的潜力。", "summary": "本文介绍了SpectRe，一种新颖的图拓扑描述符，它将谱信息与持久同调（PH）图相结合，以克服现有依赖特征的PH方法在捕获图结构信息方面的局限性。SpectRe被证明比现有描述符更具表达能力，并且是局部稳定的。在各种数据集上的实验结果证实了其有效性及其在学习任务中提升图模型能力的潜力。", "keywords": "持久同调, 图神经网络, 谱信息, 图表示学习, 拓扑描述符", "comments": "该论文通过将谱信息与拓扑方法（PH）相结合，解决了当前图表示学习中的一个重要限制，为提高GNN超越WL层次结构的表达能力提供了一种新颖的方法。严格的表达能力证明和局部稳定性是关键的理论贡献，而实验验证则支持了其实用性。"}}
{"id": "2506.06340", "title": "Structured Semantics from Unstructured Notes: Language Model Approaches to EHR-Based Decision Support", "authors": ["Wu Hao Ran", "Xi Xi", "Furong Li", "Jingyi Lu", "Jian Jiang", "Hui Huang", "Yuzhuan Zhang", "Shi Li"], "summary": "The advent of large language models (LLMs) has opened new avenues for\nanalyzing complex, unstructured data, particularly within the medical domain.\nElectronic Health Records (EHRs) contain a wealth of information in various\nformats, including free text clinical notes, structured lab results, and\ndiagnostic codes. This paper explores the application of advanced language\nmodels to leverage these diverse data sources for improved clinical decision\nsupport. We will discuss how text-based features, often overlooked in\ntraditional high dimensional EHR analysis, can provide semantically rich\nrepresentations and aid in harmonizing data across different institutions.\nFurthermore, we delve into the challenges and opportunities of incorporating\nmedical codes and ensuring the generalizability and fairness of AI models in\nhealthcare.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06340v1", "AI": {"title_translation": "从非结构化笔记中获取结构化语义：基于EHR的决策支持中的语言模型方法", "tldr": "本文探讨了大型语言模型（LLMs）如何应用于电子健康记录（EHRs）中的非结构化数据，以改善临床决策支持，并讨论了相关挑战与机遇。", "motivation": "本文旨在探索大型语言模型在分析医疗领域复杂、非结构化数据（特别是EHR中的自由文本临床笔记）方面的应用，以利用这些数据源改善临床决策支持，并解决传统EHR分析中对文本特征的忽视问题。", "method": "本文探讨了应用先进语言模型来利用电子健康记录（EHRs）中多样化的数据源，包括自由文本临床笔记、结构化实验室结果和诊断代码，以改进临床决策支持。研究将讨论文本特征如何提供语义丰富的表示并协调跨机构数据，并深入探讨结合医疗代码以及确保AI模型在医疗保健中通用性和公平性的挑战和机遇。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "大型语言模型（LLMs）的出现为分析复杂的非结构化数据开辟了新途径，特别是在医疗领域。电子健康记录（EHRs）包含各种格式的丰富信息，包括自由文本临床笔记、结构化实验室结果和诊断代码。本文探讨了先进语言模型在利用这些多样化数据源以改进临床决策支持方面的应用。我们将讨论文本特征（在传统高维EHR分析中常被忽视）如何提供语义丰富的表示，并有助于协调跨不同机构的数据。此外，我们深入探讨了结合医疗代码以及确保人工智能模型在医疗保健中通用性和公平性的挑战和机遇。", "summary": "本文探讨了利用大型语言模型分析电子健康记录（EHRs）中复杂、非结构化数据，以改进临床决策支持的应用。研究重点在于如何利用EHR中多样化的数据源，特别是文本特征，来提供语义丰富的表示并协调跨机构数据。同时，文章也讨论了整合医疗代码以及确保AI模型在医疗保健领域通用性和公平性所面临的挑战和机遇。", "keywords": "大型语言模型, 电子健康记录, 临床决策支持, 非结构化数据, 语义表示", "comments": "这篇论文探讨了将LLMs应用于医疗领域的核心挑战，即从非结构化EHR数据中提取有价值的结构化语义。它强调了文本特征的重要性，并关注了数据协调、代码整合以及AI模型通用性和公平性等关键问题，这对于推动医疗AI的发展具有重要意义。"}}
{"id": "2506.07988", "title": "Unraveling Ethereum's Mempool: The Impact of Fee Fairness, Transaction Prioritization, and Consensus Efficiency", "authors": ["S M Mostaq Hossain", "Amani Altarawneh"], "summary": "Ethereum's transaction pool (mempool) dynamics and fee market efficiency\ncritically affect transaction inclusion, validator workload, and overall\nnetwork performance. This research empirically analyzes gas price variations,\nmempool clearance rates, and block finalization times in Ethereum's\nproof-of-stake ecosystem using real-time data from Geth and Prysm nodes. We\nobserve that high-fee transactions are consistently prioritized, while low-fee\ntransactions face delays or exclusion despite EIP-1559's intended improvements.\nMempool congestion remains a key factor in validator efficiency and proposal\nlatency. We provide empirical evidence of persistent fee-based disparities and\nshow that extremely high fees do not always guarantee faster confirmation,\nrevealing inefficiencies in the current fee market. To address these issues, we\npropose congestion-aware fee adjustments, reserved block slots for low-fee\ntransactions, and improved handling of out-of-gas vulnerabilities. By\nmitigating prioritization bias and execution inefficiencies, our findings\nsupport more equitable transaction inclusion, enhance validator performance,\nand promote scalability. This work contributes to Ethereum's long-term\ndecentralization by reducing dependence on high transaction fees for network\nparticipation.", "comment": "7 pages, 6 figures and 1 table", "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.07988v1", "AI": {"title_translation": "揭示以太坊内存池：费用公平性、交易优先级和共识效率的影响", "tldr": "本研究实证分析了以太坊内存池动态，发现高费用交易被优先处理，低费用交易常被延迟或排除，且当前费用市场存在效率低下和不公平。研究提出了拥堵感知费用调整、保留区块槽位等解决方案，旨在促进交易公平性、提高验证者性能并支持以太坊去中心化。", "motivation": "以太坊的交易池（内存池）动态和费用市场效率严重影响交易纳入、验证者工作负载和整体网络性能。本研究旨在通过实证分析来揭示这些影响并提出改进方案。", "method": "本研究使用来自Geth和Prysm节点的实时数据，实证分析了以太坊权益证明生态系统中的Gas价格变化、内存池清除率和区块最终确定时间。", "result": "观察到高费用交易始终被优先处理，而低费用交易面临延迟或排除；内存池拥堵是验证者效率和提案延迟的关键因素；提供了持续存在的基于费用的差异的经验证据；发现极高费用并不总是保证更快的确认，揭示了当前费用市场的效率低下。", "conclusion": "研究结果支持更公平的交易纳入、增强验证者性能并促进可扩展性，通过减少对高交易费用的依赖来促进以太坊的长期去中心化。", "translation": "以太坊的交易池（内存池）动态和费用市场效率严重影响交易纳入、验证者工作负载和整体网络性能。本研究利用来自Geth和Prysm节点的实时数据，实证分析了以太坊权益证明生态系统中的Gas价格变化、内存池清除率和区块最终确定时间。我们观察到高费用交易始终被优先处理，而低费用交易尽管EIP-1559旨在改进，但仍面临延迟或排除。内存池拥堵仍然是验证者效率和提案延迟的关键因素。我们提供了持续存在的基于费用的差异的经验证据，并表明极高费用并不总是保证更快的确认，揭示了当前费用市场的效率低下。为了解决这些问题，我们提出了拥堵感知费用调整、为低费用交易保留区块槽位以及改进对Gas耗尽漏洞的处理。通过减轻优先级偏差和执行效率低下，我们的研究结果支持更公平的交易纳入、增强验证者性能并促进可扩展性。这项工作通过减少对高交易费用的依赖来促进以太坊的长期去中心化。", "summary": "本研究实证分析了以太坊权益证明系统中的内存池动态和费用市场效率。研究发现，尽管EIP-1559旨在改善，高费用交易仍被优先处理，低费用交易常被延迟或排除，且极高费用不总能保证快速确认，揭示了当前费用市场的不公平和低效。为解决这些问题，论文提出了拥堵感知费用调整、为低费用交易预留区块槽位以及改进Gas耗尽漏洞处理等方案，旨在促进交易公平性、提高验证者性能和网络可扩展性，从而支持以太坊的长期去中心化。", "keywords": "以太坊, 内存池, 费用公平性, 交易优先级, 共识效率", "comments": "这项研究通过对以太坊内存池的实证分析，揭示了EIP-1559实施后仍存在的费用公平性问题和效率低下。其创新之处在于提供了具体的实证数据支持，并提出了针对性的技术解决方案，如拥堵感知费用调整和保留区块槽位，这对于改善以太坊的用户体验和促进去中心化具有重要意义。研究的重要性在于它直接关系到以太坊作为全球领先区块链平台的可用性和公平性。"}}
{"id": "2506.07454", "title": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs", "authors": ["Jared Strader", "Aaron Ray", "Jacob Arkin", "Mason B. Peterson", "Yun Chang", "Nathan Hughes", "Christopher Bradley", "Yi Xuan Jia", "Carlos Nieto-Granda", "Rajat Talak", "Chuchu Fan", "Luca Carlone", "Jonathan P. How", "Nicholas Roy"], "summary": "In this paper, we introduce a multi-robot system that integrates mapping,\nlocalization, and task and motion planning (TAMP) enabled by 3D scene graphs to\nexecute complex instructions expressed in natural language. Our system builds a\nshared 3D scene graph incorporating an open-set object-based map, which is\nleveraged for multi-robot 3D scene graph fusion. This representation supports\nreal-time, view-invariant relocalization (via the object-based map) and\nplanning (via the 3D scene graph), allowing a team of robots to reason about\ntheir surroundings and execute complex tasks. Additionally, we introduce a\nplanning approach that translates operator intent into Planning Domain\nDefinition Language (PDDL) goals using a Large Language Model (LLM) by\nleveraging context from the shared 3D scene graph and robot capabilities. We\nprovide an experimental assessment of the performance of our system on\nreal-world tasks in large-scale, outdoor environments.", "comment": "12 pages, 4 figures", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07454v1", "AI": {"title_translation": "基于语言的多机器人3D场景图分层规划与执行", "tldr": "该研究提出了一个多机器人系统，利用3D场景图和大型语言模型，实现对自然语言复杂指令的分层规划与执行。", "motivation": "现有系统在执行自然语言表达的复杂指令时面临挑战，本研究旨在通过集成3D场景图和LLM来解决多机器人系统中的这一问题，使其能够理解和执行复杂的任务。", "method": "本系统引入了一个多机器人系统，该系统通过3D场景图集成测绘、定位以及任务和运动规划（TAMP）。它构建了一个共享的3D场景图，其中包含一个开放集基于对象的地图，用于多机器人3D场景图融合。该表示支持实时、视图不变的重定位和规划。此外，系统还引入了一种规划方法，利用大型语言模型（LLM）并结合共享3D场景图和机器人能力，将操作员意图转化为规划域定义语言（PDDL）目标。", "result": "该系统已在大型户外环境中的真实世界任务中进行了实验评估，验证了其性能。", "conclusion": "本研究提出的多机器人系统能够成功地将自然语言指令转化为可执行的机器人任务，并通过3D场景图和LLM实现高效的规划和执行。", "translation": "在本文中，我们介绍了一个多机器人系统，该系统通过3D场景图集成测绘、定位以及任务和运动规划（TAMP），以执行自然语言表达的复杂指令。我们的系统构建了一个共享的3D场景图，其中包含一个开放集基于对象的地图，该地图用于多机器人3D场景图融合。这种表示支持实时、视图不变的重定位（通过基于对象的地图）和规划（通过3D场景图），从而使机器人团队能够推理其周围环境并执行复杂任务。此外，我们引入了一种规划方法，该方法利用大型语言模型（LLM），通过共享的3D场景图和机器人能力提供的上下文，将操作员意图转化为规划域定义语言（PDDL）目标。我们对系统在大型户外环境中的真实世界任务中的性能进行了实验评估。", "summary": "本文介绍了一个多机器人系统，该系统利用共享的3D场景图整合了测绘、定位和任务与运动规划（TAMP），以执行自然语言指令。该系统通过一个开放集对象地图支持实时、视图不变的重定位和规划，并使用大型语言模型（LLM）将操作员意图转化为PDDL目标。系统已在真实世界的大规模户外环境中进行了性能评估。", "keywords": "多机器人系统, 3D场景图, 自然语言处理, 任务规划, 大型语言模型", "comments": "该论文的创新点在于将3D场景图与大型语言模型（LLM）相结合，实现了多机器人系统对复杂自然语言指令的理解和执行。这种集成方法提高了机器人在复杂环境中的态势感知能力和任务规划效率，为多机器人协同操作提供了新的范式。其在真实世界户外环境中的实验评估也增强了其实用性和鲁棒性。"}}
{"id": "2506.06864", "title": "Face recognition on point cloud with cgan-top for denoising", "authors": ["Junyu Liu", "Jianfeng Ren", "Sunhong Liang", "Xudong Jiang"], "summary": "Face recognition using 3D point clouds is gaining growing interest, while raw\npoint clouds often contain a significant amount of noise due to imperfect\nsensors. In this paper, an end-to-end 3D face recognition on a noisy point\ncloud is proposed, which synergistically integrates the denoising and\nrecognition modules. Specifically, a Conditional Generative Adversarial Network\non Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove the\nnoise in the point cloud, and recover the underlying features for subsequent\nrecognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) is\nthen adapted to recognize faces from the processed point cloud, which\nhierarchically links both the local point features and neighboring features of\nmultiple scales. The proposed method is validated on the Bosphorus dataset. It\nsignificantly improves the recognition accuracy under all noise settings, with\na maximum gain of 14.81%.", "comment": "Published in ICASSP 2023", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06864v1", "AI": {"title_translation": "基于cGAN-TOP去噪的点云人脸识别", "tldr": "本文提出了一种端到端的3D噪声点云人脸识别方法，通过cGAN-TOP进行去噪，并结合LDGCNN进行识别，显著提高了噪声条件下的识别精度。", "motivation": "由于传感器不完善，原始点云通常包含大量噪声，这阻碍了3D点云人脸识别的准确性，因此需要一种能够协同去噪和识别的端到端方法。", "method": "本文提出了一种端到端的3D噪声点云人脸识别方法。具体来说，设计了一个基于三正交平面的条件生成对抗网络（cGAN-TOP）来有效去除点云中的噪声并恢复底层特征。随后，采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸，该网络分层链接了局部点特征和多尺度邻近特征。", "result": "该方法在Bosphorus数据集上得到了验证，在所有噪声设置下均显著提高了识别精度，最大增益达到14.81%。", "conclusion": "本文提出的协同去噪和识别的端到端方法，通过cGAN-TOP和LDGCNN的结合，有效解决了噪声点云人脸识别的挑战，并显著提升了识别性能。", "translation": "三维点云人脸识别正日益受到关注，然而由于传感器不完善，原始点云通常包含大量噪声。本文提出了一种端到端的噪声点云三维人脸识别方法，该方法协同整合了去噪和识别模块。具体来说，设计了一种基于三正交平面的条件生成对抗网络（cGAN-TOP），以有效去除点云中的噪声并恢复用于后续识别的底层特征。然后，采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸，该网络分层链接了局部点特征和多尺度邻近特征。所提出的方法在Bosphorus数据集上进行了验证。它在所有噪声设置下均显著提高了识别精度，最大增益达到14.81%。", "summary": "本文提出了一种用于噪声点云的端到端3D人脸识别系统，该系统创新性地整合了去噪和识别模块。其中，cGAN-TOP用于有效去除点云噪声并恢复特征，而LDGCNN则用于从处理后的点云中识别面部。该方法在Bosphorus数据集上验证，在不同噪声环境下均显著提高了识别准确率，最高提升了14.81%。", "keywords": "点云人脸识别, cGAN-TOP, 去噪, LDGCNN, 3D人脸识别", "comments": "该论文的创新点在于将去噪和识别模块协同整合到一个端到端系统中，特别是在噪声点云人脸识别方面。cGAN-TOP的引入有效解决了3D点云数据中常见的噪声问题，并通过实验证明了其在提高识别精度方面的显著效果，对实际应用具有重要意义。"}}
{"id": "2506.07116", "title": "BRIGHT+: Upgrading the BRIGHT Benchmark with MARCUS, a Multi-Agent RAG Clean-Up Suite", "authors": ["Liyang Chen", "Yujun Cai", "Jieqiong Dong", "Yiwei Wang"], "summary": "Retrieval-Augmented Generation (RAG) systems require corpora that are both\nstructurally clean and semantically coherent. BRIGHT is a recent and\ninfluential benchmark designed to evaluate complex multi-hop retrieval across\ndiverse, high-reasoning domains. However, its practical effectiveness is\nlimited by common web-crawled artifacts - such as content redundancy and\nsemantic discontinuity - that impair retrieval accuracy and downstream\nreasoning. Notably, we find that such issues are concentrated in seven\nStackExchange-derived subdomains, while other domains (e.g., Coding and\nTheorem-based content) remain relatively clean.\n  In this study, we present MARCUS, a multi-agent pipeline that leverages large\nlanguage models (LLMs) to systematically clean and re-chunk BRIGHT into a\nhigher-quality corpus: BRIGHT-Plus. MARCUS applies dedicated agents for\nstructural noise removal and semantic segmentation, preserving answer-bearing\nspans while improving contextual integrity. Experimental evaluations\ndemonstrate that BRIGHT-Plus yields consistent and significant improvements in\nboth retrieval accuracy and multi-hop reasoning across a diverse set of\nretrievers. We release both the BRIGHT-Plus corpus and the MARCUS pipeline to\nsupport future research on robust, reasoning-centric retrieval.", "comment": "8 pages, 7 figures, 4 tables. Submitted to EMNLP 2025", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07116v1", "AI": {"title_translation": "BRIGHT+：使用多智能体RAG清理套件MARCUS升级BRIGHT基准", "tldr": "BRIGHT+通过多智能体RAG清理套件MARCUS升级了BRIGHT基准，显著提高了检索精度和多跳推理能力。", "motivation": "BRIGHT基准的实际效果受到网络爬取内容的冗余和语义不连贯等问题限制，这些问题影响了检索精度和下游推理。", "method": "引入MARCUS，一个利用大型语言模型（LLMs）的多智能体流水线，系统地清理和重新分块BRIGHT，生成更高质量的语料库BRIGHT-Plus。MARCUS使用专门的智能体进行结构噪声去除和语义分割，在保留答案相关片段的同时提高上下文完整性。", "result": "实验评估表明，BRIGHT-Plus在各种检索器上，在检索精度和多跳推理方面都产生了持续且显著的改进。", "conclusion": "BRIGHT-Plus语料库和MARCUS流水线的发布将支持未来对鲁棒、以推理为中心的检索的研究。", "translation": "检索增强生成（RAG）系统需要结构干净且语义连贯的语料库。BRIGHT是一个近期且有影响力的基准，旨在评估跨多样化、高推理领域的复杂多跳检索。然而，其实际效果受到常见的网络爬取内容缺陷的限制，例如内容冗余和语义不连贯，这些缺陷损害了检索精度和下游推理。值得注意的是，我们发现此类问题集中在七个源自StackExchange的子领域，而其他领域（例如，编程和基于定理的内容）相对干净。\n在本研究中，我们提出了MARCUS，一个利用大型语言模型（LLM）的多智能体流水线，系统地清理和重新分块BRIGHT，形成更高质量的语料库：BRIGHT-Plus。MARCUS应用专用智能体进行结构噪声去除和语义分割，在保留答案相关片段的同时提高上下文完整性。实验评估表明，BRIGHT-Plus在各种检索器上，在检索精度和多跳推理方面都产生了持续且显著的改进。我们发布了BRIGHT-Plus语料库和MARCUS流水线，以支持未来关于鲁棒、以推理为中心的检索的研究。", "summary": "本文介绍了BRIGHT+，一个通过MARCUS多智能体RAG清理套件升级的BRIGHT基准。BRIGHT基准在评估复杂多跳检索方面具有影响力，但其效果受限于网络爬取内容的冗余和语义不连贯。为解决此问题，研究团队开发了MARCUS，一个利用大型语言模型的多智能体流水线，用于系统地清理和重新分块BRIGHT，生成高质量的BRIGHT+语料库。实验结果表明，BRIGHT+在检索精度和多跳推理方面均实现了显著提升。研究团队已发布BRIGHT+语料库和MARCUS流水线，以促进未来对鲁棒、以推理为中心的检索系统的研究。", "keywords": "RAG, BRIGHT, MARCUS, 语料库清理, 多智能体系统", "comments": "这项工作通过引入MARCUS清理套件，解决了现有RAG基准BRIGHT在数据质量上的痛点，显著提升了其评估能力。多智能体LLM驱动的清理方法具有创新性，并且BRIGHT+语料库和MARCUS流水线的发布对RAG领域的研究具有重要贡献。"}}
{"id": "2506.07490", "title": "RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy", "authors": ["Zhaoliang Wan", "Zetong Bi", "Zida Zhou", "Hao Ren", "Yiming Zeng", "Yihan Li", "Lu Qi", "Xu Yang", "Ming-Hsuan Yang", "Hui Cheng"], "summary": "This paper addresses the scarcity of low-cost but high-dexterity platforms\nfor collecting real-world multi-fingered robot manipulation data towards\ngeneralist robot autonomy. To achieve it, we propose the RAPID Hand, a\nco-optimized hardware and software platform where the compact 20-DoF hand,\nrobust whole-hand perception, and high-DoF teleoperation interface are jointly\ndesigned. Specifically, RAPID Hand adopts a compact and practical hand ontology\nand a hardware-level perception framework that stably integrates wrist-mounted\nvision, fingertip tactile sensing, and proprioception with sub-7 ms latency and\nspatial alignment. Collecting high-quality demonstrations on high-DoF hands is\nchallenging, as existing teleoperation methods struggle with precision and\nstability on complex multi-fingered systems. We address this by co-optimizing\nhand design, perception integration, and teleoperation interface through a\nuniversal actuation scheme, custom perception electronics, and two retargeting\nconstraints. We evaluate the platform's hardware, perception, and teleoperation\ninterface. Training a diffusion policy on collected data shows superior\nperformance over prior works, validating the system's capability for reliable,\nhigh-quality data collection. The platform is constructed from low-cost and\noff-the-shelf components and will be made public to ensure reproducibility and\nease of adoption.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07490v1", "AI": {"title_translation": "RAPID 手: 一个鲁棒、经济、感知集成、灵巧操作平台，用于通用机器人自主性", "tldr": "开发了一种低成本、高灵巧度的机器人手RAPID Hand，集成了感知和遥操作，用于收集通用机器人自主学习数据。", "motivation": "缺乏低成本但高灵巧度的平台来收集真实世界多指机器人操作数据，以实现通用机器人自主性。现有遥操作方法在复杂多指系统上精度和稳定性不足。", "method": "提出了RAPID Hand，一个硬件和软件协同优化的平台。它包括紧凑的20自由度手、鲁棒的整体手部感知（腕部视觉、指尖触觉、本体感受，亚7毫秒延迟和空间对齐）和高自由度遥操作界面。通过通用驱动方案、定制感知电子设备和两种重定向约束，共同优化了手部设计、感知集成和遥操作界面。", "result": "评估了平台的硬件、感知和遥操作界面。在收集的数据上训练扩散策略显示出优于现有工作的性能，验证了系统收集可靠、高质量数据的能力。平台由低成本和现成组件构建，并将公开。", "conclusion": "RAPID Hand是一个有效且可行的平台，能够促进通用机器人自主学习所需的高质量多指操作数据收集。", "translation": "本文旨在解决用于通用机器人自主学习的低成本但高灵巧度平台在收集真实世界多指机器人操作数据方面的稀缺问题。为此，我们提出了RAPID Hand，一个硬件和软件协同优化的平台，其中紧凑的20自由度手、鲁棒的整体手部感知和高自由度遥操作界面是共同设计的。具体而言，RAPID Hand采用了紧凑实用的手部本体论和硬件级感知框架，该框架稳定地集成了腕部视觉、指尖触觉和本体感受，具有亚7毫秒的延迟和空间对齐。在高自由度手上收集高质量演示数据具有挑战性，因为现有遥操作方法在复杂多指系统上难以实现精度和稳定性。我们通过通用驱动方案、定制感知电子设备和两种重定向约束，共同优化了手部设计、感知集成和遥操作界面。我们评估了平台的硬件、感知和遥操作界面。在收集的数据上训练扩散策略显示出优于现有工作的性能，验证了系统收集可靠、高质量数据以实现高质量数据收集的能力。该平台由低成本和现成组件构建，并将公开以确保可重复性和易于采用。", "summary": "本文提出了RAPID Hand，一个用于通用机器人自主学习的低成本、高灵巧度多指操作平台。该平台通过硬件与软件的协同优化，集成了20自由度机械手、鲁棒的腕部视觉与指尖触觉感知系统，以及高自由度遥操作界面。实验证明，该平台能有效收集高质量数据，并在此数据上训练的扩散策略表现优异，为机器人操作数据收集提供了一个可复制且易于采用的解决方案。", "keywords": "RAPID Hand, 多指机器人, 灵巧操作, 通用机器人自主性", "comments": "RAPID Hand的创新之处在于其协同优化了硬件、感知和遥操作界面，解决了现有平台在成本、灵巧度和数据收集方面的痛点。其采用低成本和现成组件，并承诺开源，极大地降低了研究门槛，有望加速通用机器人自主学习领域的发展。"}}
{"id": "2506.06886", "title": "Hybrid Vision Transformer-Mamba Framework for Autism Diagnosis via Eye-Tracking Analysis", "authors": ["Wafaa Kasri", "Yassine Himeur", "Abigail Copiaco", "Wathiq Mansoor", "Ammar Albanna", "Valsamma Eapen"], "summary": "Accurate Autism Spectrum Disorder (ASD) diagnosis is vital for early\nintervention. This study presents a hybrid deep learning framework combining\nVision Transformers (ViT) and Vision Mamba to detect ASD using eye-tracking\ndata. The model uses attention-based fusion to integrate visual, speech, and\nfacial cues, capturing both spatial and temporal dynamics. Unlike traditional\nhandcrafted methods, it applies state-of-the-art deep learning and explainable\nAI techniques to enhance diagnostic accuracy and transparency. Tested on the\nSaliency4ASD dataset, the proposed ViT-Mamba model outperformed existing\nmethods, achieving 0.96 accuracy, 0.95 F1-score, 0.97 sensitivity, and 0.94\nspecificity. These findings show the model's promise for scalable,\ninterpretable ASD screening, especially in resource-constrained or remote\nclinical settings where access to expert diagnosis is limited.", "comment": "7 pages, 4 figures and 2 tables", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06886v1", "AI": {"title_translation": "混合视觉Transformer-Mamba框架用于眼动追踪分析的自闭症诊断", "tldr": "提出了一种结合ViT和Vision Mamba的混合深度学习框架，通过眼动追踪数据诊断ASD，在Saliency4ASD数据集上表现优异，有望实现可扩展、可解释的ASD筛查。", "motivation": "准确的自闭症谱系障碍（ASD）诊断对于早期干预至关重要。", "method": "本研究提出了一个结合Vision Transformers（ViT）和Vision Mamba的混合深度学习框架，用于通过眼动追踪数据检测ASD。该模型利用基于注意力的融合来整合视觉、语音和面部线索，捕捉空间和时间动态。与传统的手工方法不同，它应用了最先进的深度学习和可解释人工智能技术以提高诊断准确性和透明度。", "result": "在Saliency4ASD数据集上，所提出的ViT-Mamba模型优于现有方法，实现了0.96的准确率、0.95的F1分数、0.97的敏感性和0.94的特异性。", "conclusion": "该模型有望实现可扩展、可解释的ASD筛查，尤其适用于专家诊断资源有限的资源受限或偏远临床环境。", "translation": "准确的自闭症谱系障碍（ASD）诊断对于早期干预至关重要。本研究提出了一种结合视觉Transformer（ViT）和视觉Mamba的混合深度学习框架，用于通过眼动追踪数据检测ASD。该模型利用基于注意力的融合来整合视觉、语音和面部线索，捕捉空间和时间动态。与传统的手工方法不同，它应用了最先进的深度学习和可解释人工智能技术，以提高诊断准确性和透明度。在Saliency4ASD数据集上进行测试，所提出的ViT-Mamba模型优于现有方法，实现了0.96的准确率、0.95的F1分数、0.97的敏感性和0.94的特异性。这些发现表明该模型在可扩展、可解释的ASD筛查方面的潜力，特别是在专家诊断资源有限的资源受限或偏远临床环境中。", "summary": "本研究提出了一个混合深度学习框架，结合Vision Transformers和Vision Mamba，利用眼动追踪数据进行自闭症谱系障碍（ASD）诊断。该模型通过注意力机制融合视觉、语音和面部线索，捕捉时空动态，并利用可解释AI提升诊断准确性和透明度。在Saliency4ASD数据集上的实验表明，该模型在准确率、F1分数、敏感性和特异性方面均超越现有方法，显示出其在ASD筛查，尤其是在资源受限环境中的应用前景。", "keywords": "自闭症谱系障碍诊断, 眼动追踪, 视觉Transformer, Vision Mamba, 混合深度学习", "comments": "这项研究的创新之处在于结合了ViT和Vision Mamba这两种先进的深度学习架构，并应用于眼动追踪数据进行ASD诊断，这提供了一种非侵入性且高效的诊断方法。其强调可解释AI和在资源受限环境下的潜力，增加了其实际应用价值。"}}
{"id": "2506.07173", "title": "Translating Federated Learning Algorithms in Python into CSP Processes Using ChatGPT", "authors": ["Miroslav Popovic", "Marko Popovic", "Miodrag Djukic", "Ilija Basicevic"], "summary": "The Python Testbed for Federated Learning Algorithms is a simple Python FL\nframework that is easy to use by ML&AI developers who do not need to be\nprofessional programmers and is also amenable to LLMs. In the previous\nresearch, generic federated learning algorithms provided by this framework were\nmanually translated into the CSP processes and algorithms' safety and liveness\nproperties were automatically verified by the model checker PAT. In this paper,\na simple translation process is introduced wherein the ChatGPT is used to\nautomate the translation of the mentioned federated learning algorithms in\nPython into the corresponding CSP processes. Within the process, the minimality\nof the used context is estimated based on the feedback from ChatGPT. The\nproposed translation process was experimentally validated by successful\ntranslation (verified by the model checker PAT) of both generic centralized and\ndecentralized federated learning algorithms.", "comment": "6 pages, 4 tables", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07173v1", "AI": {"title_translation": "使用ChatGPT将Python中的联邦学习算法转换为CSP进程", "tldr": "本文介绍了一种使用ChatGPT自动将Python联邦学习算法翻译成CSP进程的方法，并成功验证了其有效性。", "motivation": "之前的研究中，将Python联邦学习算法手动翻译成CSP进程并进行验证。本文的动机是引入一种简单且自动化的翻译过程，以提高效率并减少人工干预。", "method": "本文引入了一种简单的翻译过程，使用ChatGPT自动将Python中的联邦学习算法翻译成对应的CSP进程。在此过程中，根据ChatGPT的反馈评估所用上下文的最小性。", "result": "所提出的翻译过程通过成功翻译（并经模型检查器PAT验证）通用集中式和去中心化联邦学习算法进行了实验验证。", "conclusion": "ChatGPT能够有效地自动化将Python联邦学习算法翻译成CSP进程，并且翻译后的进程能够被模型检查器PAT验证其安全性和活性属性。", "translation": "Python联邦学习算法测试平台是一个简单的Python FL框架，易于ML&AI开发者使用，他们无需成为专业的程序员，也适用于大型语言模型（LLM）。在之前的研究中，该框架提供的通用联邦学习算法被手动翻译成CSP进程，并通过模型检查器PAT自动验证了算法的安全性和活性属性。在本文中，引入了一种简单的翻译过程，其中使用ChatGPT自动化将上述Python联邦学习算法翻译成相应的CSP进程。在此过程中，根据ChatGPT的反馈估计所用上下文的最小性。所提出的翻译过程通过成功翻译（并经模型检查器PAT验证）通用集中式和去中心化联邦学习算法进行了实验验证。", "summary": "本文提出了一种利用ChatGPT将Python联邦学习算法自动转换为CSP进程的方法。该方法旨在简化并自动化此前手动进行的翻译过程，并通过模型检查器PAT对转换后的CSP进程进行验证。实验结果表明，该方法成功地将通用集中式和去中心化联邦学习算法从Python翻译成了可验证的CSP进程，证明了ChatGPT在自动化此类型代码转换中的潜力。", "keywords": "联邦学习, ChatGPT, CSP进程, 自动化翻译, 模型验证", "comments": "这项研究展示了大型语言模型（如ChatGPT）在自动化软件工程任务中的潜力，特别是将特定领域的代码（如联邦学习算法）转换为形式化验证语言（如CSP）。这可以显著提高验证效率，减少手动错误。其创新点在于利用LLM的自然语言理解和生成能力来辅助代码转换，而不仅仅是代码生成。未来可以探索其在其他领域或更复杂系统中的应用。"}}
{"id": "2506.06582", "title": "Demystifying Topological Message-Passing with Relational Structures: A Case Study on Oversquashing in Simplicial Message-Passing", "authors": ["Diaaeldin Taha", "James Chapman", "Marzieh Eidi", "Karel Devriendt", "Guido Montúfar"], "summary": "Topological deep learning (TDL) has emerged as a powerful tool for modeling\nhigher-order interactions in relational data. However, phenomena such as\noversquashing in topological message-passing remain understudied and lack\ntheoretical analysis. We propose a unifying axiomatic framework that bridges\ngraph and topological message-passing by viewing simplicial and cellular\ncomplexes and their message-passing schemes through the lens of relational\nstructures. This approach extends graph-theoretic results and algorithms to\nhigher-order structures, facilitating the analysis and mitigation of\noversquashing in topological message-passing networks. Through theoretical\nanalysis and empirical studies on simplicial networks, we demonstrate the\npotential of this framework to advance TDL.", "comment": "50 pages, 12 figures, published at ICLR 2025. The Thirteenth\n  International Conference on Learning Representations. 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06582v1", "AI": {"title_translation": "揭秘具有关系结构的拓扑消息传递：一个关于单纯消息传递中过挤压的案例研究", "tldr": "本文提出一个统一的公理框架，通过关系结构视角连接图和拓扑消息传递，以分析和缓解拓扑深度学习中的过挤压问题。", "motivation": "拓扑深度学习（TDL）在建模关系数据中的高阶交互方面表现出色，但拓扑消息传递中的过挤压等现象仍未被充分研究，缺乏理论分析。", "method": "提出一个统一的公理框架，通过关系结构的视角看待单纯复形和胞腔复形及其消息传递方案，从而连接图和拓扑消息传递。", "result": "该方法将图论结果和算法扩展到高阶结构，有助于分析和缓解拓扑消息传递网络中的过挤压。理论分析和对单纯网络的实证研究证明了该框架推进TDL的潜力。", "conclusion": "通过提出一个统一的公理框架，本文成功地连接了图和拓扑消息传递，并为分析和缓解拓扑消息传递中的过挤压问题提供了有效途径，从而推动了拓扑深度学习的发展。", "translation": "拓扑深度学习（TDL）已成为建模关系数据中高阶交互的强大工具。然而，拓扑消息传递中的过挤压等现象仍未被充分研究，且缺乏理论分析。我们提出了一个统一的公理框架，通过关系结构的视角看待单纯复形和胞腔复形及其消息传递方案，从而连接图和拓扑消息传递。这种方法将图论结果和算法扩展到高阶结构，有助于分析和缓解拓扑消息传递网络中的过挤压。通过理论分析和对单纯网络的实证研究，我们证明了该框架在推进TDL方面的潜力。", "summary": "本文针对拓扑深度学习中拓扑消息传递的过挤压问题，提出了一个统一的公理框架。该框架通过将单纯复形和胞腔复形视为关系结构，有效地连接了图和拓扑消息传递，并成功将图论的分析方法扩展到高阶结构。理论和实证研究表明，该框架能有效分析和缓解拓扑消息传递中的过挤压现象，对推进拓扑深度学习具有重要意义。", "keywords": "拓扑深度学习, 消息传递, 过挤压, 关系结构, 单纯复形", "comments": "本文的创新点在于提出了一个统一的公理框架，将图论与拓扑消息传递相结合，为理解和解决拓扑深度学习中的核心挑战——过挤压问题提供了新的理论工具和分析视角。这对于推动拓扑深度学习的理论发展和实际应用具有重要意义，特别是其将图论的成熟方法引入高阶结构，具有广阔的应用前景。"}}
{"id": "2506.06343", "title": "TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment", "authors": ["Taesoo Kim", "Jong Hwan Ko"], "summary": "Recent advances in speech-enabled language models have shown promising\nresults in building intelligent voice assistants. However, most existing\napproaches rely on large-scale paired speech-text data and extensive\ncomputational resources, which pose challenges in terms of scalability and\naccessibility. In this paper, we present \\textbf{TESU-LLM}, a novel framework\nthat enables training speech-capable language models using only text data. Our\nkey insight is to leverage a unified encoder that maps semantically equivalent\ntext and speech inputs to a shared latent space. By aligning the encoder output\nwith the embedding space of a LLM via a lightweight projection network, we\nenable the model to generalize from text-only supervision to speech-based\ninference. Despite being trained exclusively on text, TESU-LLM achieves strong\nperformance on various speech-related benchmarks, comparable to baseline\nmethods trained with large-scale multimodal datasets and substantial\ncomputational resources. These results highlight the effectiveness and\nefficiency of our approach, offering a scalable path toward building speech\nLLMs without speech data.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06343v1", "AI": {"title_translation": "TESU-LLM：通过统一编码器对齐实现无需语音的语音-LLM训练", "tldr": "TESU-LLM提出了一种新颖的框架，仅使用文本数据即可训练具备语音能力的LLM。它通过统一编码器将文本和语音输入映射到共享潜在空间，并与LLM的嵌入空间对齐，从而在语音相关基准测试上取得了与传统方法相当的强大性能，解决了大规模语音数据和计算资源依赖的挑战。", "motivation": "现有的语音使能语言模型依赖于大规模配对的语音-文本数据和大量的计算资源，这在可扩展性和可访问性方面带来了挑战。", "method": "TESU-LLM框架利用一个统一编码器，将语义等效的文本和语音输入映射到共享的潜在空间。通过一个轻量级投影网络将编码器输出与大型语言模型的嵌入空间对齐，使得模型能够从仅文本监督泛化到基于语音的推理。", "result": "尽管完全仅用文本进行训练，TESU-LLM 在各种语音相关基准测试上取得了强大性能，与使用大规模多模态数据集和大量计算资源训练的基线方法相当。", "conclusion": "TESU-LLM 方法有效且高效，为无需语音数据即可构建语音大型语言模型提供了一条可扩展的路径。", "translation": "标题：TESU-LLM：通过统一编码器对齐实现无需语音的语音-LLM训练\n\n摘要：近年来，语音支持的语言模型在构建智能语音助手方面取得了可喜的进展。然而，大多数现有方法依赖于大规模配对的语音-文本数据和大量的计算资源，这在可扩展性和可访问性方面带来了挑战。在本文中，我们提出了 **TESU-LLM**，一个新颖的框架，它使得仅使用文本数据即可训练具备语音能力的语言模型。我们的关键洞察是利用一个统一编码器，将语义等效的文本和语音输入映射到共享的潜在空间。通过一个轻量级投影网络将编码器输出与大型语言模型的嵌入空间对齐，我们使模型能够从仅文本监督泛化到基于语音的推理。尽管完全仅用文本进行训练，TESU-LLM 在各种语音相关基准测试上取得了与使用大规模多模态数据集和大量计算资源训练的基线方法相当的强大性能。这些结果突出了我们方法的有效性和效率，为无需语音数据即可构建语音大型语言模型提供了一条可扩展的路径。", "summary": "TESU-LLM提出了一种新颖的框架，旨在解决现有语音LLM对大规模语音-文本数据和计算资源的高度依赖问题。该方法通过一个统一编码器将文本和语音输入映射到共享潜在空间，并利用轻量级投影网络与LLM的嵌入空间对齐，从而仅利用文本数据训练出具备语音能力的LLM。实验结果表明，TESU-LLM在多个语音相关基准测试上表现出色，性能可与传统上需要大量多模态数据和计算资源训练的模型媲美，为构建可扩展的语音LLM提供了有效途径。", "keywords": "语音-LLM, 统一编码器, 仅文本训练, 潜在空间对齐, 可扩展性", "comments": "本文提出了一种创新方法，克服了训练语音使能LLM时数据稀缺和计算负担的挑战。通过将语音数据与训练过程解耦，TESU-LLM显著增强了此类模型的可扩展性和可访问性。统一编码器对齐以实现仅文本监督的核心思想对于未来在有限数据下进行多模态学习的研究具有重要影响。"}}
{"id": "2506.07509", "title": "Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent", "authors": ["Shoon Kit Lim", "Melissa Jia Ying Chong", "Jing Huey Khor", "Ting Yang Ling"], "summary": "Recent advances in agentic and physical artificial intelligence (AI) have\nlargely focused on ground-based platforms such as humanoid and wheeled robots,\nleaving aerial robots relatively underexplored. Meanwhile, state-of-the-art\nunmanned aerial vehicle (UAV) multimodal vision-language systems typically rely\non closed-source models accessible only to well-resourced organizations. To\ndemocratize natural language control of autonomous drones, we present an\nopen-source agentic framework that integrates PX4-based flight control, Robot\nOperating System 2 (ROS 2) middleware, and locally hosted models using Ollama.\nWe evaluate performance both in simulation and on a custom quadcopter platform,\nbenchmarking four large language model (LLM) families for command generation\nand three vision-language model (VLM) families for scene understanding.", "comment": "Source code available at:\n  https://github.com/limshoonkit/ros2-agent-ws", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07509v1", "AI": {"title_translation": "借助对话实现飞行：为基于PX4的无人机智能体提供自然语言控制", "tldr": "本文提出了一个开源框架，通过自然语言控制基于PX4的无人机，旨在解决空中机器人研究不足和现有系统依赖闭源模型的问题。", "motivation": "地面机器人研究进展迅速，但空中机器人相对未被充分探索；现有无人机多模态视觉-语言系统依赖闭源模型，限制了自然语言控制的普及。", "method": "提出了一个开源的智能体框架，该框架集成了基于PX4的飞控、机器人操作系统2 (ROS 2)中间件以及使用Ollama本地托管的模型。", "result": "在仿真和定制四旋翼平台上评估了性能，并对四种大型语言模型(LLM)系列用于命令生成和三种视觉-语言模型(VLM)系列用于场景理解进行了基准测试。", "conclusion": "本文成功构建并评估了一个开源框架，实现了通过自然语言对基于PX4的无人机进行控制，推动了自主无人机自然语言控制的民主化。", "translation": "近期在智能体和物理人工智能(AI)方面的进展主要集中在地面平台，如人形机器人和轮式机器人，而空中机器人相对未被充分探索。同时，最先进的无人机(UAV)多模态视觉-语言系统通常依赖于只有资源充足的组织才能访问的闭源模型。为了实现自主无人机自然语言控制的民主化，我们提出了一个开源的智能体框架，该框架集成了基于PX4的飞控、机器人操作系统2 (ROS 2)中间件以及使用Ollama本地托管的模型。我们在仿真和定制四旋翼平台上评估了性能，对四种大型语言模型(LLM)系列用于命令生成和三种视觉-语言模型(VLM)系列用于场景理解进行了基准测试。", "summary": "该论文提出了一个开源的智能体框架，旨在通过自然语言控制基于PX4的无人机，以解决空中机器人研究不足和现有系统依赖闭源模型的问题。该框架整合了PX4飞控、ROS 2和Ollama本地托管模型，并在仿真和实际四旋翼平台上对LLM和VLM的性能进行了评估。", "keywords": "无人机控制, 自然语言处理, PX4, 开源框架, 智能体", "comments": "该论文通过提供一个开源的解决方案，促进了无人机自然语言控制的民主化，特别是在使用本地托管模型方面具有创新性，降低了对昂贵闭源模型的依赖。这对于推动空中机器人领域的发展具有重要意义。"}}
{"id": "2506.06898", "title": "NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery", "authors": ["Reese Kneeland", "Paul S. Scotti", "Ghislain St-Yves", "Jesse Breedlove", "Kendrick Kay", "Thomas Naselaris"], "summary": "We release NSD-Imagery, a benchmark dataset of human fMRI activity paired\nwith mental images, to complement the existing Natural Scenes Dataset (NSD), a\nlarge-scale dataset of fMRI activity paired with seen images that enabled\nunprecedented improvements in fMRI-to-image reconstruction efforts. Recent\nmodels trained on NSD have been evaluated only on seen image reconstruction.\nUsing NSD-Imagery, it is possible to assess how well these models perform on\nmental image reconstruction. This is a challenging generalization requirement\nbecause mental images are encoded in human brain activity with relatively lower\nsignal-to-noise and spatial resolution; however, generalization from seen to\nmental imagery is critical for real-world applications in medical domains and\nbrain-computer interfaces, where the desired information is always internally\ngenerated. We provide benchmarks for a suite of recent NSD-trained open-source\nvisual decoding models (MindEye1, MindEye2, Brain Diffuser, iCNN, Takagi et\nal.) on NSD-Imagery, and show that the performance of decoding methods on\nmental images is largely decoupled from performance on vision reconstruction.\nWe further demonstrate that architectural choices significantly impact\ncross-decoding performance: models employing simple linear decoding\narchitectures and multimodal feature decoding generalize better to mental\nimagery, while complex architectures tend to overfit visual training data. Our\nfindings indicate that mental imagery datasets are critical for the development\nof practical applications, and establish NSD-Imagery as a useful resource for\nbetter aligning visual decoding methods with this goal.", "comment": "Published at CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06898v1", "AI": {"title_translation": "NSD-Imagery：一个用于将fMRI视觉解码方法扩展到心理意象的基准数据集", "tldr": "发布了NSD-Imagery数据集，用于评估fMRI视觉解码模型在心理意象重建上的表现。研究发现，解码方法在心理意象上的表现与视觉重建的表现很大程度上是脱钩的，并且简单的线性解码架构和多模态特征解码模型泛化能力更好。", "motivation": "现有的大规模fMRI-to-图像重建模型（如在NSD上训练的模型）仅在“所见图像”重建上进行评估，而心理意象重建是一个具有挑战性的泛化要求，但对于医疗领域和脑机接口等实际应用至关重要，因为这些应用中的信息总是内部生成的。因此，需要一个基准数据集来评估和改进模型在心理意象解码方面的能力。", "method": "发布了NSD-Imagery数据集，该数据集包含人类fMRI活动与心理意象的配对数据，以补充现有的Natural Scenes Dataset (NSD)。使用NSD-Imagery，对一系列近期在NSD上训练的开源视觉解码模型（MindEye1, MindEye2, Brain Diffuser, iCNN, Takagi et al.）进行了基准测试。", "result": "解码方法在心理意象上的表现与视觉重建的表现很大程度上是脱钩的。模型架构选择显著影响交叉解码性能：采用简单线性解码架构和多模态特征解码的模型能更好地泛化到心理意象，而复杂架构倾向于过拟合视觉训练数据。", "conclusion": "心理意象数据集对于实际应用的发展至关重要。NSD-Imagery被确立为一个有用的资源，可以更好地使视觉解码方法与这一目标保持一致。", "translation": "我们发布了NSD-Imagery，一个人类fMRI活动与心理意象配对的基准数据集，以补充现有的自然场景数据集（NSD），后者是一个大规模的fMRI活动与所见图像配对的数据集，使得fMRI到图像重建工作取得了前所未有的进展。最近在NSD上训练的模型仅在所见图像重建上进行了评估。通过使用NSD-Imagery，可以评估这些模型在心理意象重建上的表现。这是一个具有挑战性的泛化要求，因为心理意象在人脑活动中的编码信噪比和空间分辨率相对较低；然而，从所见图像到心理意象的泛化对于医疗领域和脑机接口等实际应用至关重要，因为所需信息总是内部生成的。我们提供了NSD-Imagery上一系列近期在NSD上训练的开源视觉解码模型（MindEye1、MindEye2、Brain Diffuser、iCNN、Takagi et al.）的基准测试，并表明解码方法在心理意象上的表现与视觉重建的表现很大程度上是脱钩的。我们进一步证明，架构选择显著影响交叉解码性能：采用简单线性解码架构和多模态特征解码的模型能更好地泛化到心理意象，而复杂架构倾向于过拟合视觉训练数据。我们的发现表明，心理意象数据集对于实际应用的发展至关重要，并确立NSD-Imagery作为一种有用的资源，可以更好地使视觉解码方法与这一目标保持一致。", "summary": "该研究发布了NSD-Imagery，一个将人类fMRI活动与心理意象配对的基准数据集，旨在弥补现有模型在“所见图像”重建上评估的局限性，并扩展到心理意象重建。通过对现有视觉解码模型在NSD-Imagery上进行基准测试，研究发现模型在心理意象上的解码性能与在所见图像上的性能是分离的，且简单的线性解码和多模态特征解码架构在泛化到心理意象方面表现更优。这强调了心理意象数据集对实际应用的重要性，并确立NSD-Imagery为视觉解码研究提供了关键资源。", "keywords": "fMRI, 视觉解码, 心理意象, 数据集, 脑机接口", "comments": "该论文通过发布NSD-Imagery数据集，填补了fMRI视觉解码领域的一个重要空白，即从对“所见图像”的解码扩展到更具挑战性和实际应用价值的“心理意象”解码。其创新性在于提供了首个大规模的心理意象fMRI基准数据集，并揭示了现有模型在心理意象解码上的泛化能力差异，特别是指出了简单架构的优势。这对于推动脑机接口和医疗诊断等领域的发展具有重要意义，因为它为开发更实用、更通用的视觉解码方法提供了新的方向和评估工具。"}}
{"id": "2506.07184", "title": "Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images", "authors": ["Liangliang You", "Junchi Yao", "Shu Yang", "Guimin Hu", "Lijie Hu", "Di Wang"], "summary": "While multimodal large language models excel at various tasks, they still\nsuffer from hallucinations, which limit their reliability and scalability for\nbroader domain applications. To address this issue, recent research mainly\nfocuses on objective hallucination. However, for sequential images, besides\nobjective hallucination, there is also behavioral hallucination, which is less\nstudied. This work aims to fill in the gap. We first reveal that behavioral\nhallucinations mainly arise from two key factors: prior-driven bias and the\nsnowball effect. Based on these observations, we introduce SHE (Sequence\nHallucination Eradication), a lightweight, two-stage framework that (1) detects\nhallucinations via visual-textual alignment check using our proposed adaptive\ntemporal window and (2) mitigates them via orthogonal projection onto the joint\nembedding space. We also propose a new metric (BEACH) to quantify behavioral\nhallucination severity. Empirical results on standard benchmarks demonstrate\nthat SHE reduces behavioral hallucination by over 10% on BEACH while\nmaintaining descriptive accuracy.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07184v1", "AI": {"title_translation": "缓解多模态大型语言模型在序列图像中的行为幻觉", "tldr": "本研究提出SHE框架，通过两阶段方法（检测和缓解）解决多模态大语言模型在序列图像中出现的行为幻觉，并引入了BEACH指标来量化行为幻觉，实验证明SHE能有效降低行为幻觉。", "motivation": "多模态大型语言模型在处理序列图像时，除了客观幻觉外，还存在行为幻觉，而这方面的研究较少。本文旨在填补这一空白，并揭示行为幻觉主要源于先验驱动偏差和滚雪球效应。", "method": "本文提出了SHE（Sequence Hallucination Eradication）框架，这是一个轻量级的两阶段框架：首先通过使用自适应时间窗口进行视觉-文本对齐检查来检测幻觉；其次通过正交投影到联合嵌入空间来缓解幻觉。此外，还提出了一种新的度量标准BEACH来量化行为幻觉的严重性。", "result": "在标准基准测试上的实验结果表明，SHE在BEACH指标上将行为幻觉降低了10%以上，同时保持了描述的准确性。", "conclusion": "SHE框架能够有效检测并缓解多模态大型语言模型在序列图像中产生的行为幻觉，显著提升了模型的可靠性。", "translation": "尽管多模态大型语言模型在各种任务中表现出色，但它们仍然遭受幻觉的困扰，这限制了其在更广泛领域应用中的可靠性和可扩展性。为了解决这个问题，最近的研究主要集中在客观幻觉上。然而，对于序列图像，除了客观幻觉之外，还存在行为幻觉，这方面的研究较少。这项工作旨在填补这一空白。我们首先揭示了行为幻觉主要源于两个关键因素：先验驱动偏差和滚雪球效应。基于这些观察，我们引入了SHE（Sequence Hallucination Eradication），一个轻量级的两阶段框架，该框架（1）通过使用我们提出的自适应时间窗口进行视觉-文本对齐检查来检测幻觉，以及（2）通过正交投影到联合嵌入空间来缓解幻觉。我们还提出了一种新的度量标准（BEACH）来量化行为幻觉的严重性。在标准基准测试上的经验结果表明，SHE在BEACH上将行为幻觉降低了10%以上，同时保持了描述的准确性。", "summary": "本文关注多模态大型语言模型在序列图像中未被充分研究的行为幻觉问题。研究揭示了行为幻觉源于先验驱动偏差和滚雪球效应，并提出了SHE（Sequence Hallucination Eradication）框架。SHE是一个轻量级的两阶段方法，通过自适应时间窗口进行视觉-文本对齐检测幻觉，并通过正交投影缓解幻觉。此外，引入了新的BEACH指标来量化行为幻觉。实验证明，SHE在保持描述准确性的同时，能有效降低行为幻觉。", "keywords": "行为幻觉, 多模态大语言模型, 序列图像, SHE框架, BEACH指标", "comments": "本文创新性地提出了“行为幻觉”这一概念，区别于以往对“客观幻觉”的关注，并针对序列图像场景进行了深入研究。提出的SHE框架通过两阶段方法（检测与缓解）和新颖的BEACH量化指标，为解决多模态大模型在实际应用中的可靠性问题提供了有效途径。其轻量级的设计也增加了实际部署的潜力。"}}
{"id": "2506.06584", "title": "Global Convergence of Gradient EM for Over-Parameterized Gaussian Mixtures", "authors": ["Mo Zhou", "Weihang Xu", "Maryam Fazel", "Simon S. Du"], "summary": "Learning Gaussian Mixture Models (GMMs) is a fundamental problem in machine\nlearning, with the Expectation-Maximization (EM) algorithm and its popular\nvariant gradient EM being arguably the most widely used algorithms in practice.\nIn the exact-parameterized setting, where both the ground truth GMM and the\nlearning model have the same number of components $m$, a vast line of work has\naimed to establish rigorous recovery guarantees for EM. However, global\nconvergence has only been proven for the case of $m=2$, and EM is known to fail\nto recover the ground truth when $m\\geq 3$.\n  In this paper, we consider the $\\textit{over-parameterized}$ setting, where\nthe learning model uses $n>m$ components to fit an $m$-component ground truth\nGMM. In contrast to the exact-parameterized case, we provide a rigorous global\nconvergence guarantee for gradient EM. Specifically, for any well separated\nGMMs in general position, we prove that with only mild over-parameterization $n\n= \\Omega(m\\log m)$, randomly initialized gradient EM converges globally to the\nground truth at a polynomial rate with polynomial samples. Our analysis\nproceeds in two stages and introduces a suite of novel tools for Gaussian\nMixture analysis. We use Hermite polynomials to study the dynamics of gradient\nEM and employ tensor decomposition to characterize the geometric landscape of\nthe likelihood loss. This is the first global convergence and recovery result\nfor EM or Gradient EM beyond the special case of $m=2$.", "comment": "77 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06584v1", "AI": {"title_translation": "过参数化高斯混合模型梯度EM的全局收敛性", "tldr": "本文证明了在过参数化设置下，梯度EM算法对于高斯混合模型的全局收敛性，解决了m≥3时EM算法无法恢复真实值的问题。", "motivation": "在精确参数化设置中，EM算法对于高斯混合模型的全局收敛性仅在m=2时得到证明，且已知当m≥3时EM无法恢复真实值。因此，需要研究在更一般情况下EM算法的收敛性。", "method": "本文考虑了过参数化设置（学习模型使用n>m个分量来拟合m个分量的高斯混合模型）。分析分为两个阶段，引入了高斯混合分析的新工具，使用Hermite多项式研究梯度EM的动态，并采用张量分解来表征似然损失的几何景观。", "result": "对于任何位置良好分离的高斯混合模型，在温和过参数化n=Ω(m log m)的条件下，随机初始化的梯度EM算法以多项式速率和多项式样本全局收敛到真实值。", "conclusion": "这是EM或梯度EM算法在m=2的特殊情况之外的第一个全局收敛和恢复结果。", "translation": "学习高斯混合模型（GMMs）是机器学习中的一个基本问题，期望最大化（EM）算法及其流行的变体梯度EM可以说是实践中最广泛使用的算法。在精确参数化设置中，即真实GMM和学习模型具有相同数量的组件m时，大量工作旨在为EM建立严格的恢复保证。然而，全局收敛性仅在m=2的情况下得到证明，并且已知当m≥3时EM无法恢复真实值。\n在本文中，我们考虑了过参数化设置，其中学习模型使用n>m个组件来拟合m个组件的真实GMM。与精确参数化情况相反，我们为梯度EM提供了严格的全局收敛保证。具体来说，对于任何位置良好分离的GMMs，我们证明了在仅有温和过参数化n=Ω(m log m)的情况下，随机初始化的梯度EM以多项式速率和多项式样本全局收敛到真实值。我们的分析分两个阶段进行，并引入了一套用于高斯混合分析的新颖工具。我们使用Hermite多项式来研究梯度EM的动态，并采用张量分解来表征似然损失的几何景观。这是EM或梯度EM在m=2的特殊情况之外的第一个全局收敛和恢复结果。", "summary": "本文研究了过参数化设置下梯度EM算法在高斯混合模型学习中的全局收敛性。针对以往EM算法在精确参数化设置中m≥3时无法保证全局收敛的问题，作者证明了在温和过参数化（n=Ω(m log m)）条件下，随机初始化的梯度EM能以多项式速率和多项式样本全局收敛到真实值。该研究通过引入Hermite多项式和张量分解等新工具，首次实现了EM或梯度EM在m=2以外的全局收敛和恢复。", "keywords": "高斯混合模型, 梯度EM, 全局收敛, 过参数化, 张量分解", "comments": "这项工作在EM算法的理论分析方面取得了重大突破，首次证明了其在过参数化设置下对高斯混合模型的全局收敛性，超越了传统理论的m=2限制。这对于理解和应用EM算法具有重要意义，尤其是在实际应用中模型经常过参数化的情况。其分析工具的创新性也值得关注。"}}
{"id": "2506.06347", "title": "Unified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for Resource-Efficient Toxicity Detection", "authors": ["Zachary Yang", "Domenico Tullo", "Reihaneh Rabbany"], "summary": "Toxicity detection in gaming communities faces significant scaling challenges\nwhen expanding across multiple games and languages, particularly in real-time\nenvironments where computational efficiency is crucial. We present two key\nfindings to address these challenges while building upon our previous work on\nToxBuster, a BERT-based real-time toxicity detection system. First, we\nintroduce a soft-prompting approach that enables a single model to effectively\nhandle multiple games by incorporating game-context tokens, matching the\nperformance of more complex methods like curriculum learning while offering\nsuperior scalability. Second, we develop an LLM-assisted label transfer\nframework using GPT-4o-mini to extend support to seven additional languages.\nEvaluations on real game chat data across French, German, Portuguese, and\nRussian achieve macro F1-scores ranging from 32.96% to 58.88%, with\nparticularly strong performance in German, surpassing the English benchmark of\n45.39%. In production, this unified approach significantly reduces\ncomputational resources and maintenance overhead compared to maintaining\nseparate models for each game and language combination. At Ubisoft, this model\nsuccessfully identifies an average of 50 players, per game, per day engaging in\nsanctionable behavior.", "comment": "11 pages, 1 figure, 9 Tables, KDD 2025 ADS Track", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06347v1", "AI": {"title_translation": "统一游戏内容审核：软提示与LLM辅助标签迁移实现资源高效的毒性检测", "tldr": "该研究提出了一个统一的毒性检测系统，利用软提示处理多款游戏，并使用LLM辅助标签迁移扩展到多语言，显著降低了资源消耗和维护成本。", "motivation": "游戏社区中的毒性检测在扩展到多款游戏和多种语言时面临巨大的扩展挑战，尤其是在计算效率至关重要的实时环境中。", "method": "该研究提出了两种关键方法：一是引入软提示方法，通过整合游戏上下文token，使单个模型能够有效地处理多款游戏，其性能与更复杂的方法（如课程学习）相匹配，同时提供了卓越的可扩展性。二是开发了一个使用GPT-4o-mini的LLM辅助标签迁移框架，将支持扩展到七种额外语言。这些方法是基于之前关于ToxBuster（一个基于BERT的实时毒性检测系统）的工作。", "result": "在法语、德语、葡萄牙语和俄语的真实游戏聊天数据上评估，宏观F1分数介于32.96%至58.88%之间，其中在德语中的表现尤其出色，超过了45.39%的英语基准。在生产环境中，与为每个游戏和语言组合维护独立模型相比，这种统一方法显著减少了计算资源和维护开销。在Ubisoft，该模型平均每天每款游戏成功识别出50名从事可制裁行为的玩家。", "conclusion": "这种统一的游戏毒性检测方法通过软提示和LLM辅助标签迁移，有效解决了跨游戏和跨语言的扩展挑战，显著降低了资源消耗和维护成本，并在实际应用中取得了良好的效果。", "translation": "游戏社区中的毒性检测在扩展到多款游戏和多种语言时面临巨大的扩展挑战，尤其是在计算效率至关重要的实时环境中。我们提出了两个关键发现来解决这些挑战，同时基于我们之前关于ToxBuster（一个基于BERT的实时毒性检测系统）的工作。首先，我们引入了一种软提示方法，通过整合游戏上下文token，使单个模型能够有效地处理多款游戏，其性能与课程学习等更复杂的方法相匹配，同时提供了卓越的可扩展性。其次，我们开发了一个使用GPT-4o-mini的LLM辅助标签迁移框架，将支持扩展到七种额外语言。在法语、德语、葡萄牙语和俄语的真实游戏聊天数据上的评估取得了32.96%到58.88%的宏观F1分数，其中在德语中的表现尤其出色，超过了45.39%的英语基准。在生产环境中，与为每个游戏和语言组合维护独立模型相比，这种统一方法显著减少了计算资源和维护开销。在Ubisoft，该模型平均每天每款游戏成功识别出50名从事可制裁行为的玩家。", "summary": "这篇论文提出了一种统一的游戏毒性检测方法，旨在解决跨游戏和多语言环境下的扩展性及效率问题。该方法包含两个核心创新：一是采用软提示技术，使单个模型能适应多款游戏，提升了可扩展性；二是利用LLM（GPT-4o-mini）辅助标签迁移，将支持扩展至七种额外语言。实验结果显示，该方法在多语言真实游戏数据上表现良好，特别是在德语方面，并且显著降低了生产环境中的计算资源和维护成本，在实际应用中有效识别了违规玩家。", "keywords": "毒性检测, 软提示, LLM辅助标签迁移, 游戏审核, 资源效率", "comments": "这篇论文的创新点在于结合了软提示和LLM辅助标签迁移，为游戏毒性检测提供了一个资源高效且可扩展的统一解决方案。软提示通过引入游戏上下文token，使得一个模型能处理多款游戏，避免了为每款游戏训练独立模型的开销。LLM辅助标签迁移则巧妙地利用了大型语言模型的生成能力，解决了多语言标签数据稀缺的问题。这种方法在实际生产环境中被验证有效，显著降低了运维成本，对于大规模在线游戏平台的实时内容审核具有重要意义。其对计算效率和可扩展性的关注，使其在AI应用部署方面具有很高的实用价值。"}}
{"id": "2506.07530", "title": "BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation", "authors": ["Hongyu Wang", "Chuyan Xiong", "Ruiping Wang", "Xilin Chen"], "summary": "Vision-Language-Action (VLA) models have shown impressive capabilities across\na wide range of robotics manipulation tasks. However, their growing model size\nposes significant challenges for deployment on resource-constrained robotic\nsystems. While 1-bit pretraining has proven effective for enhancing the\ninference efficiency of large language models with minimal performance loss,\nits application to VLA models remains underexplored. In this work, we present\nBitVLA, the first 1-bit VLA model for robotics manipulation, in which every\nparameter is ternary, i.e., {-1, 0, 1}. To further reduce the memory footprint\nof the vision encoder, we propose the distillation-aware training strategy that\ncompresses the full-precision encoder to 1.58-bit weights. During this process,\na full-precision encoder serves as a teacher model to better align latent\nrepresentations. Despite the lack of large-scale robotics pretraining, BitVLA\nachieves performance comparable to the state-of-the-art model OpenVLA-OFT with\n4-bit post-training quantization on the LIBERO benchmark, while consuming only\n29.8% of the memory. These results highlight BitVLA's promise for deployment on\nmemory-constrained edge devices. We release the code and model weights in\nhttps://github.com/ustcwhy/BitVLA.", "comment": "Work in progress", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07530v1", "AI": {"title_translation": "BitVLA：用于机器人操作的1比特视觉-语言-动作模型", "tldr": "BitVLA是首个用于机器人操作的1比特视觉-语言-动作模型，它将所有参数量化为三元（-1, 0, 1），并通过蒸馏感知训练进一步压缩视觉编码器。它在内存占用显著减少的情况下，实现了与最先进模型相当的性能。", "motivation": "视觉-语言-动作（VLA）模型在机器人操作任务中表现出色，但其不断增长的模型尺寸对在资源受限的机器人系统上部署提出了重大挑战。尽管1比特预训练已被证明能有效提高大型语言模型的推理效率且性能损失极小，但其在VLA模型中的应用仍未得到充分探索。", "method": "本文提出了BitVLA，这是首个用于机器人操作的1比特VLA模型，其所有参数均为三元（-1, 0, 1）。为了进一步减少视觉编码器的内存占用，提出了一种蒸馏感知训练策略，将全精度编码器压缩到1.58比特权重。在此过程中，一个全精度编码器作为教师模型，以更好地对齐潜在表示。", "result": "尽管缺乏大规模机器人预训练，BitVLA在LIBERO基准测试上实现了与最先进模型OpenVLA-OFT（采用4比特后训练量化）相当的性能，而内存消耗仅为其29.8%。", "conclusion": "BitVLA在内存受限的边缘设备上部署具有巨大潜力，因为它在显著降低内存消耗的同时保持了与现有先进模型相当的性能。", "translation": "视觉-语言-动作（VLA）模型在广泛的机器人操作任务中展现了令人印象深刻的能力。然而，其不断增长的模型尺寸对在资源受限的机器人系统上部署构成了重大挑战。尽管1比特预训练已被证明能有效提高大型语言模型的推理效率且性能损失极小，但其在VLA模型中的应用仍未得到充分探索。在这项工作中，我们提出了BitVLA，这是首个用于机器人操作的1比特VLA模型，其中每个参数都是三元的，即{-1, 0, 1}。为了进一步减少视觉编码器的内存占用，我们提出了一种蒸馏感知训练策略，将全精度编码器压缩到1.58比特权重。在此过程中，一个全精度编码器作为教师模型，以更好地对齐潜在表示。尽管缺乏大规模机器人预训练，BitVLA在LIBERO基准测试上实现了与最先进模型OpenVLA-OFT（采用4比特后训练量化）相当的性能，而内存消耗仅为其29.8%。这些结果突显了BitVLA在内存受限的边缘设备上部署的潜力。我们已在https://github.com/ustcwhy/BitVLA 发布了代码和模型权重。", "summary": "本文介绍了BitVLA，这是首个用于机器人操作的1比特视觉-语言-动作（VLA）模型，旨在解决现有VLA模型尺寸过大导致资源受限机器人系统部署困难的问题。BitVLA通过将所有模型参数量化为三元（-1, 0, 1），并采用蒸馏感知训练策略将视觉编码器压缩至1.58比特，显著降低了内存占用。尽管没有进行大规模机器人预训练，BitVLA在LIBERO基准测试上实现了与现有先进模型OpenVLA-OFT（4比特后训练量化）相当的性能，但内存消耗仅为后者的29.8%。这表明BitVLA在边缘设备部署方面具有巨大潜力。", "keywords": "1比特量化, 视觉-语言-动作模型, 机器人操作, 模型压缩, 边缘部署", "comments": "BitVLA的创新性在于将1比特量化应用于VLA模型，并结合蒸馏感知训练进一步压缩视觉编码器，有效解决了机器人系统内存受限的部署难题。其在性能与内存效率之间取得了出色的平衡，对于推动VLA模型在实际机器人应用中的落地具有重要意义。该工作证明了极低比特量化在复杂多模态模型中的可行性。"}}
{"id": "2506.06906", "title": "KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search", "authors": ["Nima Jamali", "Matina Mahdizadeh Sani", "Hanieh Naderi", "Shohreh Kasaei"], "summary": "Deep neural networks (DNNs) have demonstrated remarkable performance in\nanalyzing 3D point cloud data. However, their vulnerability to adversarial\nattacks-such as point dropping, shifting, and adding-poses a critical challenge\nto the reliability of 3D vision systems. These attacks can compromise the\nsemantic and structural integrity of point clouds, rendering many existing\ndefense mechanisms ineffective. To address this issue, a defense strategy named\nKNN-Defense is proposed, grounded in the manifold assumption and\nnearest-neighbor search in feature space. Instead of reconstructing surface\ngeometry or enforcing uniform point distributions, the method restores\nperturbed inputs by leveraging the semantic similarity of neighboring samples\nfrom the training set. KNN-Defense is lightweight and computationally\nefficient, enabling fast inference and making it suitable for real-time and\npractical applications. Empirical results on the ModelNet40 dataset\ndemonstrated that KNN-Defense significantly improves robustness across various\nattack types. In particular, under point-dropping attacks-where many existing\nmethods underperform due to the targeted removal of critical points-the\nproposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% on\nPointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest that\nKNN-Defense offers a scalable and effective solution for enhancing the\nadversarial resilience of 3D point cloud classifiers. (An open-source\nimplementation of the method, including code and data, is available at\nhttps://github.com/nimajam41/3d-knn-defense).", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06906v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07194", "title": "Exploring Effective Strategies for Building a Customised GPT Agent for Coding Classroom Dialogues", "authors": ["Luwei Bai", "Dongkeun Han", "Sara Hennessy"], "summary": "This study investigates effective strategies for developing a customised GPT\nagent to code classroom dialogue. While classroom dialogue is widely recognised\nas a crucial element of education, its analysis remains challenging due to the\nneed for a nuanced understanding of dialogic functions and the labour-intensive\nnature of manual transcript coding. Recent advancements in large language\nmodels offer promising avenues for automating this process. However, existing\nstudies predominantly focus on training large-scale models or evaluating\npre-trained models with fixed codebooks, which are often not applicable or\nreplicable for dialogue researchers working with small datasets or customised\ncoding schemes. Using GPT-4's MyGPT agent as a case, this study evaluates its\nbaseline performance in coding classroom dialogue with a human codebook and\nexamines how performance varies with different example inputs through a\nvariable control method. Through a design-based research approach, it\nidentifies a set of practical strategies, based on MyGPT's unique features, for\nconfiguring effective agents with limited data. The findings suggest that,\ndespite some limitations, a MyGPT agent developed with these strategies can\nserve as a useful coding assistant by generating coding suggestions.", "comment": "Draft technical report. 39 pages, 2 figures. Not yet submitted for\n  publication. Update expected", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07194v1", "AI": {"title_translation": "探索构建定制化GPT智能体以编码课堂对话的有效策略", "tldr": "本研究探讨了利用GPT-4的MyGPT智能体定制化编码课堂对话的有效策略，旨在解决小数据集和定制编码方案的挑战，并发现其可作为有用的编码助手。", "motivation": "课堂对话分析因其细致入微的对话功能理解需求和人工转录编码的劳动密集型性质而具有挑战性。现有的大语言模型研究主要集中在训练大型模型或使用固定代码本评估预训练模型，这对于处理小数据集或定制编码方案的对话研究人员来说通常不适用或不可复制。", "method": "本研究以GPT-4的MyGPT智能体为例，评估其在使用人类代码本编码课堂对话时的基线性能，并通过变量控制方法检查不同示例输入如何影响性能。通过设计本位研究方法，本研究基于MyGPT的独特功能，识别了一套在有限数据下配置有效智能体的实用策略。", "result": "研究结果表明，尽管存在一些局限性，但使用这些策略开发的MyGPT智能体可以通过生成编码建议来作为有用的编码助手。性能会随不同的示例输入而变化。", "conclusion": "定制化的MyGPT智能体可以作为课堂对话编码的有用辅助工具，尤其是在处理小数据集和定制编码方案时。", "translation": "本研究探讨了开发定制化GPT智能体以编码课堂对话的有效策略。尽管课堂对话被广泛认为是教育的关键要素，但由于需要对对话功能进行细致入微的理解以及手动转录编码的劳动密集型性质，其分析仍然具有挑战性。大型语言模型的最新进展为自动化这一过程提供了有前景的途径。然而，现有研究主要集中在训练大型模型或使用固定代码本评估预训练模型，这对于处理处理小数据集或定制编码方案的对话研究人员来说通常不适用或不可复制。本研究以GPT-4的MyGPT智能体为例，评估了其在使用人类代码本编码课堂对话时的基线性能，并通过变量控制方法检查了不同示例输入如何影响性能。通过设计本位研究方法，本研究基于MyGPT的独特功能，识别了一套在有限数据下配置有效智能体的实用策略。研究结果表明，尽管存在一些局限性，但使用这些策略开发的MyGPT智能体可以通过生成编码建议来作为有用的编码助手。", "summary": "本研究旨在解决课堂对话分析中人工编码的挑战和现有大语言模型方法的局限性，提出构建定制化GPT智能体的有效策略。研究以GPT-4的MyGPT为例，评估其编码性能，并通过变量控制和设计本位研究识别出在有限数据下配置有效智能体的实用方法。结果表明，定制化的MyGPT智能体可作为有用的编码助手，提供编码建议。", "keywords": "GPT智能体, 课堂对话, 编码策略, 大语言模型, 定制化", "comments": "本文的创新之处在于关注如何利用大语言模型（特别是MyGPT的定制化功能）来解决小数据集和定制化编码方案在课堂对话分析中的挑战，这与当前主流的大规模模型训练或固定代码本评估有所不同。其提出的实用策略对于教育研究者具有重要意义。局限性在于仍存在“一些局限性”，具体未详细说明。"}}
{"id": "2506.06599", "title": "Direct Prediction Set Minimization via Bilevel Conformal Classifier Training", "authors": ["Yuanjie Shi", "Hooman Shahrokhi", "Xuesong Jia", "Xiongzhi Chen", "Janardhan Rao Doppa", "Yan Yan"], "summary": "Conformal prediction (CP) is a promising uncertainty quantification framework\nwhich works as a wrapper around a black-box classifier to construct prediction\nsets (i.e., subset of candidate classes) with provable guarantees. However,\nstandard calibration methods for CP tend to produce large prediction sets which\nmakes them less useful in practice. This paper considers the problem of\nintegrating conformal principles into the training process of deep classifiers\nto directly minimize the size of prediction sets. We formulate conformal\ntraining as a bilevel optimization problem and propose the {\\em Direct\nPrediction Set Minimization (DPSM)} algorithm to solve it. The key insight\nbehind DPSM is to minimize a measure of the prediction set size (upper level)\nthat is conditioned on the learned quantile of conformity scores (lower level).\nWe analyze that DPSM has a learning bound of $O(1/\\sqrt{n})$ (with $n$ training\nsamples), while prior conformal training methods based on stochastic\napproximation for the quantile has a bound of $\\Omega(1/s)$ (with batch size\n$s$ and typically $s \\ll \\sqrt{n}$). Experiments on various benchmark datasets\nand deep models show that DPSM significantly outperforms the best prior\nconformal training baseline with $20.46\\%\\downarrow$ in the prediction set size\nand validates our theory.", "comment": "Accepted for Publication at International Conference on Machine\n  Learning (ICML), 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06599v1", "AI": {"title_translation": "通过双层共形分类器训练实现直接预测集最小化", "tldr": "本文提出DPSM算法，通过双层优化将共形预测融入深度分类器训练，以直接最小化预测集大小，实验证明其性能优于现有方法。", "motivation": "标准的共形预测（CP）校准方法倾向于产生过大的预测集，这使得它们在实践中不太有用。因此，本文旨在将共形原则整合到深度分类器的训练过程中，以直接最小化预测集的大小。", "method": "本文将共形训练公式化为一个双层优化问题，并提出了直接预测集最小化（DPSM）算法来解决它。DPSM的关键在于最小化预测集大小的度量（上层），该度量以一致性分数的学习分位数（下层）为条件。文章分析了DPSM的学习界为$O(1/\\sqrt{n})$。", "result": "实验表明，DPSM在各种基准数据集和深度模型上显著优于最佳的现有共形训练基线，预测集大小减少了20.46%，并验证了本文的理论。", "conclusion": "DPSM算法通过将共形原则融入深度分类器训练过程，并通过双层优化直接最小化预测集大小，从而有效解决了共形预测中预测集过大的问题，提高了其实用性。", "translation": "共形预测（CP）是一个很有前景的不确定性量化框架，它作为黑盒分类器的封装，用于构建具有可证明保证的预测集（即候选类别的子集）。然而，CP的标准校准方法倾向于产生过大的预测集，这使得它们在实践中不太有用。本文考虑将共形原则整合到深度分类器的训练过程中，以直接最小化预测集大小的问题。我们将共形训练公式化为一个双层优化问题，并提出了直接预测集最小化（DPSM）算法来解决它。DPSM背后的关键思想是最小化预测集大小的度量（上层），该度量以一致性分数的学习分位数（下层）为条件。我们分析了DPSM的学习界为$O(1/\\sqrt{n})$（使用$n$个训练样本），而之前基于随机近似分位数的共形训练方法的界为$\\Omega(1/s)$（使用批量大小$s$，通常$s \\ll \\sqrt{n}$）。在各种基准数据集和深度模型上的实验表明，DPSM显著优于最佳的现有共形训练基线，预测集大小减少了20.46%\\downarrow，并验证了我们的理论。", "summary": "本文针对共形预测中预测集过大的问题，提出了一种名为直接预测集最小化（DPSM）的新算法。该算法将共形训练建模为双层优化问题，旨在直接在深度分类器训练过程中最小化预测集的大小。DPSM通过最小化预测集大小（上层）并以一致性分数的学习分位数（下层）为条件来实现。理论分析表明，DPSM的泛化误差界为$O(1/\\sqrt{n})$，优于现有方法。实验结果显示，DPSM在多个基准数据集上显著优于现有共形训练基线，预测集大小减少了20.46%，验证了其理论优势。", "keywords": "共形预测, 预测集最小化, 双层优化, 深度分类器, 不确定性量化", "comments": "该论文的创新之处在于首次将共形训练建模为双层优化问题，并提出DPSM算法直接在训练阶段优化预测集大小，这显著提高了共形预测的实用性。理论上，其学习界优于现有方法，具有重要的理论贡献和实际应用价值。"}}
{"id": "2506.07540", "title": "Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations", "authors": ["Sreeja Roy-Singh", "Sarvesh Kolekar", "Daniel P. Bonny", "Kyle Foss"], "summary": "We present a methodology for estimating collision risk from counterfactual\nsimulated scenarios built on sensor data from automated driving systems (ADS)\nor naturalistic driving databases. Two-agent conflicts are assessed by\ndetecting and classifying conflict type, identifying the agents' roles\n(initiator or responder), identifying the point of reaction of the responder,\nand modeling their human behavioral expectations as probabilistic\ncounterfactual trajectories. The states are used to compute velocity\ndifferentials at collision, which when combined with crash models, estimates\nseverity of loss in terms of probabilistic injury or property damage,\nhenceforth called fractional collisions. The probabilistic models may also be\nextended to include other uncertainties associated with the simulation,\nfeatures, and agents. We verify the effectiveness of the methodology in a\nsynthetic simulation environment using reconstructed trajectories from 300+\ncollision and near-collision scenes sourced from VTTI's SHRP2 database and\nNexar dashboard camera data. Our methodology predicted fractional collisions\nwithin 1% of ground truth collisions. We then evaluate agent-initiated\ncollision risk of an arbitrary ADS software release by replacing the\nnaturalistic responder in these synthetic reconstructions with an ADS simulator\nand comparing the outcome to human-response outcomes. Our ADS reduced\nnaturalistic collisions by 4x and fractional collision risk by ~62%. The\nframework's utility is also demonstrated on 250k miles of proprietary,\nopen-loop sensor data collected on ADS test vehicles, re-simulated with an\narbitrary ADS software release. The ADS initiated conflicts that caused 0.4\ninjury-causing and 1.7 property-damaging fractional collisions, and the ADS\nimproved collision risk in 96% of the agent-initiated conflicts.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07540v1", "AI": {"title_translation": "分数碰撞：一个使用自动驾驶行为模拟进行反事实冲突风险评估的框架", "tldr": "一个框架利用ADS传感器数据的反事实模拟来估计碰撞风险和严重程度，并显示自动驾驶系统（ADS）可以显著降低碰撞。", "motivation": "旨在利用自动驾驶系统（ADS）传感器数据或自然驾驶数据库构建的反事实模拟场景来估计碰撞风险，特别是为了评估新ADS软件版本的安全性。", "method": "该方法通过检测和分类双代理冲突类型，识别代理角色（发起者或响应者）及响应者的反应点，并将人类行为预期建模为概率反事实轨迹。这些状态用于计算碰撞时的速度差，并结合碰撞模型，以概率性伤害或财产损失的形式估计损失的严重程度，称之为“分数碰撞”。概率模型还可以扩展以包含与模拟、特征和代理相关的其他不确定性。该方法在合成模拟环境中得到验证，通过将自然响应者替换为ADS模拟器来评估ADS引起的碰撞风险。", "result": "该方法预测的分数碰撞与真实碰撞的误差在1%以内。在评估中，ADS将自然碰撞减少了4倍，分数碰撞风险降低了约62%。在25万英里的专有开放环路传感器数据上，ADS引发的冲突导致了0.4次致伤性分数碰撞和1.7次财产损失性分数碰撞，并且ADS在96%的代理引发的冲突中改善了碰撞风险。", "conclusion": "该框架提供了一种用于反事实模拟中估计碰撞风险和严重程度的鲁棒方法，证明了ADS相对于人类驾驶员具有显著降低碰撞风险的潜力。", "translation": "我们提出了一种方法，用于根据自动驾驶系统（ADS）传感器数据或自然驾驶数据库构建的反事实模拟场景来估计碰撞风险。通过检测和分类冲突类型、识别代理的角色（发起者或响应者）、识别响应者的反应点，并将他们的人类行为预期建模为概率反事实轨迹来评估双代理冲突。这些状态用于计算碰撞时的速度差，结合碰撞模型，可以估计损失的严重程度，以概率性伤害或财产损失的形式，此后称为分数碰撞。概率模型还可以扩展，以包括与模拟、特征和代理相关的其他不确定性。我们在合成模拟环境中验证了该方法的有效性，使用了来自VTTI的SHRP2数据库和Nexar行车记录仪数据的300多个碰撞和近碰撞场景的重建轨迹。我们的方法预测的分数碰撞与真实碰撞的误差在1%以内。然后，我们通过将这些合成重建中的自然响应者替换为ADS模拟器，并将结果与人类响应结果进行比较，来评估任意ADS软件版本引起的碰撞风险。我们的ADS将自然碰撞减少了4倍，并将分数碰撞风险降低了约62%。该框架的实用性还在25万英里的专有开放环路传感器数据上得到了验证，这些数据是在ADS测试车辆上收集的，并用任意ADS软件版本进行了重新模拟。ADS引发的冲突导致了0.4次致伤性分数碰撞和1.7次财产损失性分数碰撞，并且ADS在96%的代理引发的冲突中改善了碰撞风险。", "summary": "该论文提出了一个“分数碰撞”框架，利用基于ADS传感器数据的反事实模拟来估计碰撞风险和严重程度。它通过建模概率性人类行为并计算潜在损害来评估双代理冲突。该方法通过真实世界数据进行验证，能够准确预测碰撞，并表明自动驾驶系统（ADS）与人类驾驶员相比可以显著降低碰撞风险和严重程度，在很大比例的冲突中改善了风险。", "keywords": "分数碰撞, 风险估计, 自动驾驶, 反事实模拟, 碰撞严重性", "comments": "该论文引入了一个创新的“分数碰撞”框架，用于定量评估反事实模拟中的碰撞风险和严重程度，这对自动驾驶系统的评估和验证至关重要。使用概率模型来模拟人类行为以及与碰撞模型结合以估计伤害/财产损失的能力具有重要意义。通过真实世界碰撞数据进行验证以及展示ADS在降低风险方面的积极影响，突显了其在ADS开发和部署方面的实际重要性。"}}
{"id": "2506.06909", "title": "Gaussian Mapping for Evolving Scenes", "authors": ["Vladimir Yugay", "Thies Kersten", "Luca Carlone", "Theo Gevers", "Martin R. Oswald", "Lukas Schmid"], "summary": "Mapping systems with novel view synthesis (NVS) capabilities are widely used\nin computer vision, with augmented reality, robotics, and autonomous driving\napplications. Most notably, 3D Gaussian Splatting-based systems show high NVS\nperformance; however, many current approaches are limited to static scenes.\nWhile recent works have started addressing short-term dynamics (motion within\nthe view of the camera), long-term dynamics (the scene evolving through changes\nout of view) remain less explored. To overcome this limitation, we introduce a\ndynamic scene adaptation mechanism that continuously updates the 3D\nrepresentation to reflect the latest changes. In addition, since maintaining\ngeometric and semantic consistency remains challenging due to stale\nobservations disrupting the reconstruction process, we propose a novel keyframe\nmanagement mechanism that discards outdated observations while preserving as\nmuch information as possible. We evaluate Gaussian Mapping for Evolving Scenes\n(GaME) on both synthetic and real-world datasets and find it to be more\naccurate than the state of the art.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06909v1", "AI": {"title_translation": "演化场景的高斯映射", "tldr": "引入了一种动态场景适应机制和新颖的关键帧管理机制，用于高斯映射系统，以处理长期动态场景，并在准确性上超越现有技术。", "motivation": "现有的3D高斯泼溅映射系统在处理静态场景方面表现出色，但大多局限于静态场景。虽然一些工作开始解决短期动态问题，但长期动态（场景在视野外发生变化）仍未得到充分探索，这限制了这些系统在真实世界应用中的实用性。", "method": "我们引入了一种动态场景适应机制，用于持续更新3D表示以反映最新变化。此外，我们提出了一种新颖的关键帧管理机制，该机制通过丢弃过时观测同时尽可能保留信息来维护几何和语义一致性。", "result": "在合成和真实世界数据集上评估了演化场景的高斯映射（GaME），发现它比现有技术更准确。", "conclusion": "演化场景的高斯映射（GaME）通过其动态场景适应和关键帧管理机制，有效地解决了高斯泼溅映射系统在处理长期动态场景方面的局限性，并实现了更高的准确性。", "translation": "具有新视图合成（NVS）能力的映射系统在计算机视觉领域广泛应用，包括增强现实、机器人和自动驾驶。其中，基于3D高斯泼溅的系统表现出高NVS性能；然而，许多现有方法仅限于静态场景。尽管最近的工作已开始解决短期动态（相机视野内的运动），但长期动态（场景在视野外通过变化演化）仍较少被探索。为了克服这一限制，我们引入了一种动态场景适应机制，该机制持续更新3D表示以反映最新变化。此外，由于陈旧观测扰乱重建过程，维持几何和语义一致性仍然具有挑战性，因此我们提出了一种新颖的关键帧管理机制，该机制丢弃过时观测同时尽可能保留信息。我们在合成和真实世界数据集上评估了演化场景的高斯映射（GaME），发现它比现有技术更准确。", "summary": "本文提出了一种名为“演化场景的高斯映射”（GaME）的新型高斯映射系统，旨在解决现有3D高斯泼溅系统在处理长期动态场景时的局限性。GaME引入了动态场景适应机制以持续更新3D表示，并采用了一种新颖的关键帧管理机制来维护几何和语义一致性，通过丢弃过时观测来避免重建过程中的干扰。实验结果表明，GaME在合成和真实世界数据集上均比现有技术更准确。", "keywords": "高斯映射, 动态场景, 新视图合成, 长期动态, 关键帧管理", "comments": "这项工作通过解决高斯泼溅系统在动态场景，特别是长期动态场景中的应用挑战，迈出了重要一步。其创新点在于结合了动态场景适应和智能关键帧管理，这对于在复杂、不断变化的环境中实现鲁棒的3D重建至关重要。这对于增强现实、机器人和自动驾驶等领域具有重要意义。"}}
{"id": "2506.07202", "title": "Reasoning Multimodal Large Language Model: Data Contamination and Dynamic Evaluation", "authors": ["Ming Liu", "Wensheng Zhang"], "summary": "Multimodal Large Language Models (MLLMs) show impressive vision-language\nbenchmark performance, yet growing concerns about data contamination (test set\nexposure during training) risk masking true generalization. This concern\nextends to reasoning MLLMs, often fine-tuned via reinforcement learning from\npotentially contaminated base models. We propose a novel dynamic evaluation\nframework to rigorously assess MLLM generalization, moving beyond static\nbenchmarks. Instead of perturbing inputs, we perturb the task itself. Using the\nsame visual input, models are evaluated across a family of tasks (e.g., QA,\ncaptioning, question posing, verification) to probe diverse capabilities. This\ntask perturbation reveals whether model performance is robust or reliant on\nsuperficial task-specific cues. Our approach is analogous to loss landscape\nsharpness: models overfit or contaminated for a single task (sharp minima)\nfalter under task shifts, unlike models with generalizable solutions (flatter\nminima). We developed an automated pipeline with a calibrated judge scoring\nopen-ended generations (captions, questions) using paraphrase and corruption\nsampling. Applying this framework to leading image/video MLLMs on benchmarks\nincluding MME, RealWorldQA, and CVRR-ES, we analyze each model's cross-task\n\"ability vector.\" We demonstrate that fine-tuning on simulated test data\n(extreme contamination) drastically sharpens task-specific performance but\nharms overall generalization. Our dynamic task perturbation offers deeper\ninsights into MLLM generalization, distinguishing genuine understanding from\nspurious leakage or overfitting.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07202v1", "AI": {"title_translation": "推理多模态大语言模型：数据污染与动态评估", "tldr": "本文提出一种新的动态评估框架，通过扰动任务而非输入来评估多模态大语言模型（MLLM）的泛化能力，以识别数据污染和过拟合的影响。", "motivation": "多模态大语言模型（MLLMs）在视觉-语言基准测试中表现出色，但人们日益担忧数据污染（训练期间暴露测试集）可能掩盖其真正的泛化能力。这种担忧尤其存在于推理型MLLMs中，它们通常通过强化学习对可能受污染的基础模型进行微调。", "method": "本文提出了一种新颖的动态评估框架，旨在严格评估MLLM的泛化能力，超越静态基准测试。该方法不扰动输入，而是扰动任务本身。使用相同的视觉输入，模型在一系列任务（例如，问答、图像描述、提问、验证）中进行评估，以探究其多样化的能力。这种任务扰动揭示了模型性能是稳健的还是依赖于表面的任务特定线索。该方法类似于损失景观的锐度：对单一任务过拟合或受污染的模型（尖锐的最小值）在任务转换下会失败，而具有泛化解决方案的模型（平坦的最小值）则不会。研究者开发了一个自动化流程，通过使用释义和损坏采样，由校准后的评判器对开放式生成（描述、问题）进行评分。", "result": "将此框架应用于领先的图像/视频MLLMs，包括MME、RealWorldQA和CVRR-ES等基准测试，分析了每个模型的跨任务“能力向量”。研究表明，在模拟测试数据上进行微调（极端污染）会急剧提高任务特定性能，但会损害整体泛化能力。", "conclusion": "我们的动态任务扰动方法为MLLM的泛化能力提供了更深入的见解，能够区分真正的理解与虚假泄漏或过拟合。", "translation": "多模态大语言模型（MLLMs）在视觉-语言基准测试中表现出色，但人们日益担忧数据污染（训练期间暴露测试集）可能掩盖其真正的泛化能力。这种担忧延伸到推理型MLLMs，它们通常通过强化学习对可能受污染的基础模型进行微调。我们提出了一种新颖的动态评估框架，旨在严格评估MLLM的泛化能力，超越静态基准测试。该方法不扰动输入，而是扰动任务本身。使用相同的视觉输入，模型在一系列任务（例如，问答、图像描述、提问、验证）中进行评估，以探究其多样化的能力。这种任务扰动揭示了模型性能是稳健的还是依赖于表面的任务特定线索。我们的方法类似于损失景观的锐度：对单一任务过拟合或受污染的模型（尖锐的最小值）在任务转换下会失败，而具有泛化解决方案的模型（平坦的最小值）则不会。我们开发了一个自动化流程，通过使用释义和损坏采样，由校准后的评判器对开放式生成（描述、问题）进行评分。将此框架应用于领先的图像/视频MLLMs，包括MME、RealWorldQA和CVRR-ES等基准测试，我们分析了每个模型的跨任务“能力向量”。我们证明，在模拟测试数据上进行微调（极端污染）会急剧提高任务特定性能，但会损害整体泛化能力。我们的动态任务扰动为MLLM的泛化能力提供了更深入的见解，能够区分真正的理解与虚假泄漏或过拟合。", "summary": "本文针对多模态大语言模型（MLLMs）面临的数据污染问题，提出了一种创新的动态评估框架。该框架通过扰动任务而非输入，使用相同的视觉输入在不同任务家族中评估模型，以揭示其泛化能力是稳健的还是依赖于表面线索。研究发现，在模拟污染数据上微调会提高任务特定性能但损害整体泛化。这种方法有助于区分MLLM的真正理解与数据泄漏或过拟合。", "keywords": "多模态大语言模型, 数据污染, 动态评估, 泛化能力, 任务扰动", "comments": "本文提出了一种新颖的动态评估框架，其创新点在于通过扰动任务本身而非输入来评估模型的泛化能力，并将其与损失景观的锐度概念联系起来。这种方法能够更深入地揭示数据污染和过拟合对MLLM泛化能力的影响，对于推动MLLM的可靠发展具有重要意义。"}}
{"id": "2506.06603", "title": "CAtCh: Cognitive Assessment through Cookie Thief", "authors": ["Joseph T Colonel", "Carolyn Hagler", "Guiselle Wismer", "Laura Curtis", "Jacqueline Becker", "Juan Wisnivesky", "Alex Federman", "Gaurav Pandey"], "summary": "Several machine learning algorithms have been developed for the prediction of\nAlzheimer's disease and related dementia (ADRD) from spontaneous speech.\nHowever, none of these algorithms have been translated for the prediction of\nbroader cognitive impairment (CI), which in some cases is a precursor and risk\nfactor of ADRD. In this paper, we evaluated several speech-based open-source\nmethods originally proposed for the prediction of ADRD, as well as methods from\nmultimodal sentiment analysis for the task of predicting CI from patient audio\nrecordings. Results demonstrated that multimodal methods outperformed unimodal\nones for CI prediction, and that acoustics-based approaches performed better\nthan linguistics-based ones. Specifically, interpretable acoustic features\nrelating to affect and prosody were found to significantly outperform\nBERT-based linguistic features and interpretable linguistic features,\nrespectively. All the code developed for this study is available at\nhttps://github.com/JTColonel/catch.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06603v1", "AI": {"title_translation": "CAtCh: 通过“偷饼干”进行认知评估", "tldr": "本文评估了多种机器学习算法（包括为ADRD预测设计的开源方法和多模态情感分析方法）在通过患者录音预测更广泛认知障碍（CI）方面的表现，发现多模态方法优于单模态方法，且基于声学的方法表现优于基于语言学的方法，特别是与情感和韵律相关的可解释声学特征表现显著。", "motivation": "现有机器学习算法虽能预测阿尔茨海默病及相关痴呆（ADRD），但尚未应用于更广泛的认知障碍（CI）预测，而CI有时是ADRD的前兆和风险因素。因此，本文旨在评估这些方法在CI预测任务中的有效性。", "method": "研究评估了多种基于语音的开源方法（最初用于ADRD预测）以及多模态情感分析方法，用于从患者音频记录中预测认知障碍（CI）。具体比较了单模态与多模态方法，以及基于声学与基于语言学的方法。", "result": "多模态方法在CI预测方面优于单模态方法。基于声学的方法表现优于基于语言学的方法。与情感和韵律相关的可解释声学特征显著优于基于BERT的语言特征和可解释语言特征。", "conclusion": "多模态方法，特别是利用声学特征（尤其是与情感和韵律相关的可解释声学特征），在通过患者语音记录预测认知障碍方面表现出卓越的性能。", "translation": "CAtCh: 通过“偷饼干”进行认知评估\n\n已开发出多种机器学习算法，用于从自发语音中预测阿尔茨海默病及相关痴呆（ADRD）。然而，这些算法都未能应用于更广泛的认知障碍（CI）的预测，而CI在某些情况下是ADRD的前兆和风险因素。在本文中，我们评估了几种最初用于ADRD预测的基于语音的开源方法，以及用于从患者录音中预测CI的多模态情感分析方法。结果表明，多模态方法在CI预测方面优于单模态方法，且基于声学的方法表现优于基于语言学的方法。具体而言，与情感和韵律相关的可解释声学特征被发现显著优于基于BERT的语言特征和可解释语言特征。本研究开发的所有代码均可在 https://github.com/JTColonel/catch 获取。", "summary": "本文旨在解决当前机器学习算法在预测阿尔茨海默病及相关痴呆（ADRD）后，未能有效应用于更广泛认知障碍（CI）预测的空白。研究评估了为ADRD预测开发的开源语音方法和多模态情感分析方法，在通过患者音频记录预测CI任务中的表现。结果显示，多模态方法在CI预测上优于单模态方法，且基于声学的方法优于基于语言学的方法，特别是与情感和韵律相关的可解释声学特征表现出显著优势。", "keywords": "认知障碍预测, 语音分析, 机器学习, 阿尔茨海默病, 多模态分析", "comments": "该论文的创新之处在于将原本用于ADRD预测的语音分析方法扩展到更广泛的认知障碍（CI）预测。其重要性在于揭示了多模态方法和声学特征在早期识别CI方面的潜力，这对于ADRD的早期干预和风险管理具有重要意义。特别是强调了可解释声学特征的有效性，为未来的研究指明了方向。"}}
{"id": "2506.07633", "title": "Blending Participatory Design and Artificial Awareness for Trustworthy Autonomous Vehicles", "authors": ["Ana Tanevska", "Ananthapathmanabhan Ratheesh Kumar", "Arabinda Ghosh", "Ernesto Casablanca", "Ginevra Castellano", "Sadegh Soudjani"], "summary": "Current robotic agents, such as autonomous vehicles (AVs) and drones, need to\ndeal with uncertain real-world environments with appropriate situational\nawareness (SA), risk awareness, coordination, and decision-making. The SymAware\nproject strives to address this issue by designing an architecture for\nartificial awareness in multi-agent systems, enabling safe collaboration of\nautonomous vehicles and drones. However, these agents will also need to\ninteract with human users (drivers, pedestrians, drone operators), which in\nturn requires an understanding of how to model the human in the interaction\nscenario, and how to foster trust and transparency between the agent and the\nhuman.\n  In this work, we aim to create a data-driven model of a human driver to be\nintegrated into our SA architecture, grounding our research in the principles\nof trustworthy human-agent interaction. To collect the data necessary for\ncreating the model, we conducted a large-scale user-centered study on human-AV\ninteraction, in which we investigate the interaction between the AV's\ntransparency and the users' behavior.\n  The contributions of this paper are twofold: First, we illustrate in detail\nour human-AV study and its findings, and second we present the resulting Markov\nchain models of the human driver computed from the study's data. Our results\nshow that depending on the AV's transparency, the scenario's environment, and\nthe users' demographics, we can obtain significant differences in the model's\ntransitions.", "comment": "Submitted to IEEE RO-MAN 2025", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07633v1", "AI": {"title_translation": "融合参与式设计与人工意识以实现可信赖的自动驾驶汽车", "tldr": "本文通过大规模用户研究，创建了一个人类驾驶员的数据驱动马尔可夫链模型，以提升自动驾驶汽车与人类交互的信任和透明度，并发现模型转换受AV透明度、环境和用户人口统计学影响。", "motivation": "当前机器人代理（如自动驾驶汽车和无人机）需要在不确定的真实世界环境中处理态势感知、风险感知、协调和决策。此外，这些代理还需要与人类用户互动，这要求理解如何建模人类以及如何培养代理与人类之间的信任和透明度。", "method": "本研究旨在创建一个人类驾驶员的数据驱动模型，并将其整合到态势感知架构中，以实现可信赖的人机交互。为此，研究人员进行了一项大规模的、以用户为中心的人机交互研究，调查了自动驾驶汽车透明度与用户行为之间的关系。研究结果用于构建人类驾驶员的马尔可夫链模型。", "result": "研究结果表明，根据自动驾驶汽车的透明度、场景环境和用户的社会人口学特征，模型中的转换（transitions）会呈现显著差异。", "conclusion": "Not mentioned in abstract", "translation": "当前的机器人代理，如自动驾驶汽车（AVs）和无人机，需要通过适当的态势感知（SA）、风险感知、协调和决策来应对不确定的真实世界环境。SymAware项目致力于通过设计一个用于多智能体系统的人工意识架构来解决这个问题，从而实现自动驾驶汽车和无人机的安全协作。然而，这些代理也需要与人类用户（驾驶员、行人、无人机操作员）互动，这反过来需要理解如何在交互场景中建模人类，以及如何培养代理和人类之间的信任和透明度。\n在这项工作中，我们旨在创建一个人类驾驶员的数据驱动模型，并将其整合到我们的态势感知架构中，将我们的研究建立在可信赖人机交互的原则之上。为了收集创建模型所需的数据，我们进行了一项关于人机交互的大规模以用户为中心的研究，其中我们调查了自动驾驶汽车的透明度与用户行为之间的相互作用。\n本文的贡献有两方面：首先，我们详细阐述了我们的人机研究及其发现；其次，我们展示了根据研究数据计算得出的人类驾驶员的马尔可夫链模型。我们的结果表明，根据自动驾驶汽车的透明度、场景环境和用户的社会人口学特征，模型中的转换会呈现显著差异。", "summary": "本研究旨在解决自动驾驶汽车与人类用户交互中的信任和透明度问题。文章提出了一种将人类驾驶员数据驱动模型整合到人工意识架构中的方法，以实现可信赖的人机交互。通过一项大规模用户研究，作者调查了自动驾驶汽车透明度对用户行为的影响，并基于收集到的数据构建了人类驾驶员的马尔可夫链模型。研究结果表明，模型中的转换受自动驾驶汽车透明度、环境和用户人口统计学特征的显著影响。", "keywords": "自动驾驶汽车, 人机交互, 马尔可夫链模型, 态势感知, 信任", "comments": "本文的创新之处在于将参与式设计原则应用于自动驾驶汽车的人工意识架构中，特别是通过构建人类驾驶员的数据驱动模型来增强人机信任和透明度。大规模的用户研究为理解自动驾驶汽车透明度与用户行为之间的复杂关系提供了实证基础，而马尔可夫链模型的应用则为预测和适应人类行为提供了量化工具。这对于提升未来自动驾驶系统的安全性、可靠性和用户接受度具有重要意义。"}}
{"id": "2506.06912", "title": "Sleep Stage Classification using Multimodal Embedding Fusion from EOG and PSM", "authors": ["Olivier Papillon", "Rafik Goubran", "James Green", "Julien Larivière-Chartier", "Caitlin Higginson", "Frank Knoefel", "Rébecca Robillard"], "summary": "Accurate sleep stage classification is essential for diagnosing sleep\ndisorders, particularly in aging populations. While traditional polysomnography\n(PSG) relies on electroencephalography (EEG) as the gold standard, its\ncomplexity and need for specialized equipment make home-based sleep monitoring\nchallenging. To address this limitation, we investigate the use of\nelectrooculography (EOG) and pressure-sensitive mats (PSM) as less obtrusive\nalternatives for five-stage sleep-wake classification. This study introduces a\nnovel approach that leverages ImageBind, a multimodal embedding deep learning\nmodel, to integrate PSM data with dual-channel EOG signals for sleep stage\nclassification. Our method is the first reported approach that fuses PSM and\nEOG data for sleep stage classification with ImageBind. Our results demonstrate\nthat fine-tuning ImageBind significantly improves classification accuracy,\noutperforming existing models based on single-channel EOG (DeepSleepNet),\nexclusively PSM data (ViViT), and other multimodal deep learning approaches\n(MBT). Notably, the model also achieved strong performance without fine-tuning,\nhighlighting its adaptability to specific tasks with limited labeled data,\nmaking it particularly advantageous for medical applications. We evaluated our\nmethod using 85 nights of patient recordings from a sleep clinic. Our findings\nsuggest that pre-trained multimodal embedding models, even those originally\ndeveloped for non-medical domains, can be effectively adapted for sleep\nstaging, with accuracies approaching systems that require complex EEG data.", "comment": "Submitted to IEEE MeMeA 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06912v1", "AI": {"title_translation": "基于EOG和PSM多模态嵌入融合的睡眠阶段分类", "tldr": "本文利用ImageBind融合眼电图（EOG）和压力敏感垫（PSM）数据进行睡眠阶段分类，实现了高准确性，接近传统EEG方法，并适用于家庭监测。", "motivation": "诊断睡眠障碍需要准确的睡眠阶段分类，但传统多导睡眠图（PSG）/脑电图（EEG）复杂且不适合家庭监测。本文旨在利用眼电图（EOG）和压力敏感垫（PSM）等侵入性较小的方法解决此限制。", "method": "本文提出了一种新颖的方法，利用ImageBind多模态嵌入深度学习模型，融合压力敏感垫（PSM）数据和双通道眼电图（EOG）信号进行五阶段睡眠-觉醒分类。这是首次将PSM和EOG数据与ImageBind结合用于睡眠阶段分类的方法，并使用85晚患者记录进行评估。", "result": "经过微调的ImageBind显著提高了分类准确性，优于现有基于单通道EOG（DeepSleepNet）、PSM数据（ViViT）以及其他多模态深度学习方法（MBT）的模型。即使未经微调，模型也表现出强大性能，突出了其在有限标记数据下对特定任务的适应性，准确性接近需要复杂EEG数据的系统。", "conclusion": "预训练的多模态嵌入模型，即使最初是为非医学领域开发的，也可以有效地用于睡眠分期，其准确性接近需要复杂EEG数据的系统。", "translation": "准确的睡眠阶段分类对于诊断睡眠障碍至关重要，尤其是在老年人群中。虽然传统的多导睡眠图（PSG）依赖脑电图（EEG）作为金标准，但其复杂性以及对专业设备的需求使得居家睡眠监测变得具有挑战性。为了解决这一限制，我们研究了使用眼电图（EOG）和压力敏感垫（PSM）作为侵入性较小的替代方案，进行五阶段睡眠-觉醒分类。本研究引入了一种新颖的方法，利用ImageBind（一种多模态嵌入深度学习模型）来整合PSM数据与双通道EOG信号，用于睡眠阶段分类。我们的方法是首次报道的将PSM和EOG数据与ImageBind融合用于睡眠阶段分类的方法。我们的结果表明，微调ImageBind显著提高了分类准确性，优于现有基于单通道EOG（DeepSleepNet）、仅使用PSM数据（ViViT）以及其他多模态深度学习方法（MBT）的模型。值得注意的是，该模型即使在未经微调的情况下也取得了强大性能，这突出了其在有限标记数据下对特定任务的适应性，使其在医疗应用中尤其具有优势。我们使用来自睡眠诊所的85晚患者记录评估了我们的方法。我们的研究结果表明，预训练的多模态嵌入模型，即使是最初为非医学领域开发的模型，也可以有效地应用于睡眠分期，其准确性接近需要复杂EEG数据的系统。", "summary": "本文提出了一种新颖的五阶段睡眠分类方法，利用非侵入性眼电图（EOG）和压力敏感垫（PSM）数据。该方法利用ImageBind多模态深度学习模型融合这些不同数据源。结果表明，与现有单模态和其他多模态方法相比，该方法在分类准确性方面表现更优，即使未经广泛微调也具有强大性能，这表明其在医疗应用中的强大适应性以及在家庭睡眠监测中的潜力。", "keywords": "睡眠阶段分类, 多模态嵌入, EOG, PSM, ImageBind", "comments": "本文的创新之处在于首次将PSM和EOG数据与ImageBind结合用于睡眠分期，并证明了预训练的多模态模型（即使源自非医学领域）在特定医学任务中的强大适应性。这为简化家庭睡眠监测提供了新的可能性，尤其对于老年人群的睡眠障碍诊断具有重要意义。"}}
{"id": "2506.07217", "title": "BIMgent: Towards Autonomous Building Modeling via Computer-use Agents", "authors": ["Zihan Deng", "Changyu Du", "Stavros Nousias", "André Borrmann"], "summary": "Existing computer-use agents primarily focus on general-purpose desktop\nautomation tasks, with limited exploration of their application in highly\nspecialized domains. In particular, the 3D building modeling process in the\nArchitecture, Engineering, and Construction (AEC) sector involves open-ended\ndesign tasks and complex interaction patterns within Building Information\nModeling (BIM) authoring software, which has yet to be thoroughly addressed by\ncurrent studies. In this paper, we propose BIMgent, an agentic framework\npowered by multimodal large language models (LLMs), designed to enable\nautonomous building model authoring via graphical user interface (GUI)\noperations. BIMgent automates the architectural building modeling process,\nincluding multimodal input for conceptual design, planning of software-specific\nworkflows, and efficient execution of the authoring GUI actions. We evaluate\nBIMgent on real-world building modeling tasks, including both text-based\nconceptual design generation and reconstruction from existing building design.\nThe design quality achieved by BIMgent was found to be reasonable. Its\noperations achieved a 32% success rate, whereas all baseline models failed to\ncomplete the tasks (0% success rate). Results demonstrate that BIMgent\neffectively reduces manual workload while preserving design intent,\nhighlighting its potential for practical deployment in real-world architectural\nmodeling scenarios.", "comment": "ICML 2025 Workshop on Computer Use Agents", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07217v1", "AI": {"title_translation": "BIMgent：迈向通过计算机代理实现的自主建筑建模", "tldr": "BIMgent是一个由多模态大型语言模型驱动的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作，并在实际建筑建模任务中表现出优于基线模型的性能，有效减少了手动工作量。", "motivation": "现有计算机代理主要关注通用桌面自动化任务，很少探索其在高度专业化领域的应用。特别是，建筑、工程和施工（AEC）行业的3D建筑建模过程涉及开放式设计任务和建筑信息模型（BIM）创作软件中复杂的交互模式，目前尚未得到充分解决。", "method": "本文提出了BIMgent，一个由多模态大型语言模型（LLMs）驱动的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作。BIMgent自动化了建筑建模过程，包括概念设计的多模态输入、软件特定工作流程的规划以及创作GUI操作的高效执行。", "result": "BIMgent在实际建筑建模任务（包括基于文本的概念设计生成和现有建筑设计的重建）上进行了评估。BIMgent实现的设计质量合理，其操作成功率为32%，而所有基线模型均未能完成任务（成功率为0%）。", "conclusion": "结果表明，BIMgent在保留设计意图的同时有效减少了手动工作量，突显了其在实际建筑建模场景中实际部署的潜力。", "translation": "现有计算机代理主要关注通用桌面自动化任务，很少探索其在高度专业化领域的应用。特别是，建筑、工程和施工（AEC）行业的3D建筑建模过程涉及开放式设计任务和建筑信息模型（BIM）创作软件中复杂的交互模式，目前尚未得到充分解决。在本文中，我们提出了BIMgent，一个由多模态大型语言模型（LLMs）驱动的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作。BIMgent自动化了建筑建模过程，包括概念设计的多模态输入、软件特定工作流程的规划以及创作GUI操作的高效执行。我们在实际建筑建模任务（包括基于文本的概念设计生成和现有建筑设计的重建）上评估了BIMgent。BIMgent实现的设计质量合理。其操作成功率为32%，而所有基线模型均未能完成任务（成功率为0%）。结果表明，BIMgent在保留设计意图的同时有效减少了手动工作量，突显了其在实际建筑建模场景中实际部署的潜力。", "summary": "针对现有计算机代理在专业领域应用有限的挑战，特别是AEC行业中复杂的3D建筑建模过程，本文提出了BIMgent。BIMgent是一个基于多模态大型语言模型（LLMs）的代理框架，通过自动化图形用户界面（GUI）操作实现自主建筑模型创作。它能够处理概念设计的多模态输入、规划软件工作流程并高效执行GUI动作。在实际建筑建模任务中，BIMgent取得了32%的成功率和合理的设计质量，而基线模型均未能完成任务，这表明BIMgent能有效减少手动工作量并保留设计意图，具有实际应用潜力。", "keywords": "BIM, 自主建模, 计算机代理, LLMs, GUI自动化", "comments": "该论文的创新之处在于将多模态大型语言模型应用于高度专业化的建筑信息模型（BIM）领域，通过GUI自动化实现自主建筑建模，这在现有研究中尚未得到充分探索。其重要性在于显著减少了手动工作量，并展示了在实际建筑建模场景中部署的潜力。尽管32%的成功率可能看起来不高，但考虑到基线模型0%的成功率，这已是显著的进步，表明了该方法的可行性和巨大潜力。"}}
{"id": "2506.06606", "title": "Stacey: Promoting Stochastic Steepest Descent via Accelerated $\\ell_p$-Smooth Nonconvex Optimization", "authors": ["Xinyu Luo", "Cedar Site Bai", "Bolian Li", "Petros Drineas", "Ruqi Zhang", "Brian Bullins"], "summary": "While popular optimization methods such as SGD, AdamW, and Lion depend on\nsteepest descent updates in either $\\ell_2$ or $\\ell_\\infty$ norms, there\nremains a critical gap in handling the non-Euclidean structure observed in\nmodern deep networks training. In this work, we address this need by\nintroducing a new accelerated $\\ell_p$ steepest descent algorithm, called\nStacey, which uses interpolated primal-dual iterate sequences to effectively\nnavigate non-Euclidean smooth optimization tasks. In addition to providing\nnovel theoretical guarantees for the foundations of our algorithm, we\nempirically compare our approach against these popular methods on tasks\nincluding image classification and language model (LLM) pretraining,\ndemonstrating both faster convergence and higher final accuracy. We further\nevaluate different values of $p$ across various models and datasets,\nunderscoring the importance and efficiency of non-Euclidean approaches over\nstandard Euclidean methods. Code can be found at\nhttps://github.com/xinyuluo8561/Stacey .", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06606v1", "AI": {"title_translation": "Stacey：通过加速$\\\\ell_p$-光滑非凸优化促进随机最速下降", "tldr": "Stacey是一种新的加速$\\\\ell_p$最速下降算法，解决了深度网络训练中非欧几里得结构的处理问题，并在经验上表现出更快的收敛速度和更高的精度。", "motivation": "现有流行的优化方法（如SGD、AdamW和Lion）依赖于$\\\\ell_2$或$\\\\ell_\\infty$范数的最速下降更新，但在处理现代深度网络训练中观察到的非欧几里得结构方面存在关键空白。", "method": "本文引入了一种名为Stacey的加速$\\\\ell_p$最速下降算法。该算法使用插值原始-对偶迭代序列来有效地处理非欧几里得光滑优化任务。", "result": "Stacey算法提供了新颖的理论保证。在图像分类和语言模型预训练等任务上，Stacey与流行方法相比，展示了更快的收敛速度和更高的最终精度。研究还评估了不同$p$值在各种模型和数据集上的表现，强调了非欧几里得方法相对于标准欧几里得方法的重要性和效率。", "conclusion": "Stacey算法通过处理非欧几里得结构，在深度学习优化中实现了更快的收敛和更高的精度，证明了非欧几里得方法的优越性。", "translation": "虽然SGD、AdamW和Lion等流行的优化方法依赖于$\\\\ell_2$或$\\\\ell_\\infty$范数的最速下降更新，但在处理现代深度网络训练中观察到的非欧几里得结构方面仍然存在关键空白。在这项工作中，我们通过引入一种新的加速$\\\\ell_p$最速下降算法Stacey来解决这一需求，该算法使用插值原始-对偶迭代序列来有效地处理非欧几里得光滑优化任务。除了为我们算法的基础提供新颖的理论保证外，我们还在图像分类和语言模型（LLM）预训练等任务上将我们的方法与这些流行方法进行了经验比较，证明了更快的收敛速度和更高的最终精度。我们进一步评估了不同$p$值在各种模型和数据集上的表现，强调了非欧几里得方法相对于标准欧几里得方法的重要性和效率。代码可在https://github.com/xinyuluo8561/Stacey 找到。", "summary": "本文提出了一种名为Stacey的新型加速$\\\\ell_p$最速下降算法，旨在解决深度学习优化中非欧几里得结构处理的难题。Stacey利用插值原始-对偶迭代序列，不仅提供了理论保证，还在图像分类和语言模型预训练等任务上，相较于SGD、AdamW和Lion等传统方法，展现出更快的收敛速度和更高的最终精度。研究还强调了非欧几里得方法在不同$p$值和数据集上的优势。", "keywords": "优化算法, 最速下降, 非欧几里得优化, 深度学习, $\\\\ell_p$范数", "comments": "这篇论文的创新点在于引入了加速$\\\\ell_p$最速下降算法Stacey来处理深度学习中普遍存在的非欧几里得结构，这弥补了现有优化方法的一个关键空白。通过在实际任务中展示优于现有流行方法的性能，Stacey有望为深度网络训练提供更高效和精确的优化途径，特别是其对非欧几里得方法的强调具有重要的理论和实践意义。"}}
{"id": "2506.07639", "title": "Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse", "authors": ["Zhekai Duan", "Yuan Zhang", "Shikai Geng", "Gaowen Liu", "Joschka Boedecker", "Chris Xiaoxuan Lu"], "summary": "Embodied Chain-of-Thought (ECoT) reasoning enhances vision-language-action\n(VLA) models by improving performance and interpretability through intermediate\nreasoning steps. However, its sequential autoregressive token generation\nintroduces significant inference latency, limiting real-time deployment. We\npropose Fast ECoT, an inference-time acceleration method that exploits the\nstructured and repetitive nature of ECoT to (1) cache and reuse high-level\nreasoning across timesteps and (2) parallelise the generation of modular\nreasoning steps. Additionally, we introduce an asynchronous scheduler that\ndecouples reasoning from action decoding, further boosting responsiveness. Fast\nECoT requires no model changes or additional training and integrates easily\ninto existing VLA pipelines. Experiments in both simulation (LIBERO) and\nreal-world robot tasks show up to a 7.5% reduction in latency with comparable\nor improved task success rate and reasoning faithfulness, bringing ECoT\npolicies closer to practical real-time deployment.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07639v1", "AI": {"title_translation": "快速ECoT：通过思想重用实现高效具身思维链", "tldr": "Fast ECoT通过重用思想和并行化推理步骤来加速具身思维链（ECoT）的推理速度，从而显著降低延迟并提高实时部署能力，同时保持或提升性能。", "motivation": "具身思维链（ECoT）推理虽然能增强视觉-语言-动作（VLA）模型的性能和可解释性，但其顺序自回归令牌生成导致显著的推理延迟，从而限制了其实时部署。", "method": "Fast ECoT是一种推理时加速方法，它利用ECoT的结构化和重复性，通过以下方式实现：1) 在不同时间步缓存和重用高级推理；2) 并行生成模块化推理步骤。此外，它引入了一个异步调度器，将推理与动作解码解耦，进一步提高了响应速度。", "result": "在模拟（LIBERO）和真实世界机器人任务中，Fast ECoT将延迟降低了高达7.5%，同时任务成功率和推理忠实度保持相当或有所提高。", "conclusion": "Fast ECoT通过显著降低推理延迟，使ECoT策略更接近实际的实时部署，且无需模型更改或额外训练，易于集成到现有VLA管线中。", "translation": "具身思维链（ECoT）推理通过中间推理步骤增强视觉-语言-动作（VLA）模型，从而提高性能和可解释性。然而，其顺序自回归令牌生成引入了显著的推理延迟，限制了实时部署。我们提出了快速ECoT，这是一种推理时加速方法，它利用ECoT的结构化和重复性来（1）在时间步之间缓存和重用高级推理，以及（2）并行生成模块化推理步骤。此外，我们引入了一个异步调度器，将推理与动作解码解耦，进一步提高了响应能力。快速ECoT无需模型更改或额外训练，并且易于集成到现有的VLA管线中。在模拟（LIBERO）和真实世界机器人任务中的实验表明，延迟降低了高达7.5%，同时任务成功率和推理忠实度相当或有所提高，使ECoT策略更接近实际的实时部署。", "summary": "该论文提出了Fast ECoT，一种用于加速具身思维链（ECoT）推理的方法，旨在解决ECoT的顺序生成导致的实时部署延迟问题。Fast ECoT通过缓存和重用高级推理、并行化推理步骤以及引入异步调度器来解耦推理与动作解码。该方法无需模型修改或额外训练，并能轻松集成。实验结果表明，在模拟和真实机器人任务中，Fast ECoT将延迟降低了高达7.5%，同时保持或提高了任务成功率和推理忠实度，从而使ECoT策略更适用于实际实时应用。", "keywords": "具身思维链, ECoT, 推理加速, 视觉-语言-动作模型, 实时部署", "comments": "Fast ECoT的创新之处在于其无需模型更改或额外训练即可显著加速ECoT推理，这对于现有VLA系统的集成非常有利。通过利用ECoT本身的结构化和重复性，它巧妙地解决了实时部署的瓶颈。这种方法对于提高机器人和具身AI系统的响应速度和实用性具有重要意义。"}}
{"id": "2506.06918", "title": "Reading in the Dark with Foveated Event Vision", "authors": ["Carl Brander", "Giovanni Cioffi", "Nico Messikommer", "Davide Scaramuzza"], "summary": "Current smart glasses equipped with RGB cameras struggle to perceive the\nenvironment in low-light and high-speed motion scenarios due to motion blur and\nthe limited dynamic range of frame cameras. Additionally, capturing dense\nimages with a frame camera requires large bandwidth and power consumption,\nconsequently draining the battery faster. These challenges are especially\nrelevant for developing algorithms that can read text from images. In this\nwork, we propose a novel event-based Optical Character Recognition (OCR)\napproach for smart glasses. By using the eye gaze of the user, we foveate the\nevent stream to significantly reduce bandwidth by around 98% while exploiting\nthe benefits of event cameras in high-dynamic and fast scenes. Our proposed\nmethod performs deep binary reconstruction trained on synthetic data and\nleverages multimodal LLMs for OCR, outperforming traditional OCR solutions. Our\nresults demonstrate the ability to read text in low light environments where\nRGB cameras struggle while using up to 2400 times less bandwidth than a\nwearable RGB camera.", "comment": "CVPR 2025 Workshop on Event-based Vision", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06918v1", "AI": {"title_translation": "使用中心凹事件视觉在黑暗中阅读", "tldr": "该论文提出了一种新颖的基于事件的OCR方法，用于智能眼镜在低光照和高速场景下阅读文本，通过注视点事件流显著降低带宽，并优于传统OCR。", "motivation": "当前配备RGB摄像头的智能眼镜在低光照和高速运动场景下感知环境时，由于运动模糊和帧摄像头的有限动态范围而面临困难。此外，捕获密集图像需要大量带宽和功耗，从而更快地耗尽电池。这些挑战对于开发从图像中读取文本的算法尤为重要。", "method": "该研究提出了一种新颖的基于事件的智能眼镜光学字符识别（OCR）方法。通过利用用户的眼球注视，对事件流进行中心凹处理，显著减少了约98%的带宽，同时利用了事件摄像头在高动态和快速场景中的优势。所提出的方法执行在合成数据上训练的深度二值重建，并利用多模态LLM进行OCR。", "result": "该方法优于传统的OCR解决方案。它展示了在RGB摄像头难以工作的低光照环境下阅读文本的能力，并且比可穿戴RGB摄像头使用的带宽减少了多达2400倍。", "conclusion": "该论文成功开发了一种基于事件的OCR方法，解决了传统RGB摄像头在低光照和高带宽方面的限制，为智能眼镜在挑战性环境下的文本阅读提供了高效且高性能的解决方案。", "translation": "论文标题：使用中心凹事件视觉在黑暗中阅读\n\n论文摘要：当前配备RGB摄像头的智能眼镜在低光照和高速运动场景下感知环境时，由于运动模糊和帧摄像头的有限动态范围而面临困难。此外，使用帧摄像头捕获密集图像需要大量带宽和功耗，从而更快地耗尽电池。这些挑战对于开发能够从图像中读取文本的算法尤为重要。在这项工作中，我们提出了一种新颖的基于事件的智能眼镜光学字符识别（OCR）方法。通过利用用户的眼球注视，我们对事件流进行中心凹处理，显著减少了约98%的带宽，同时利用了事件摄像头在高动态和快速场景中的优势。我们提出的方法执行在合成数据上训练的深度二值重建，并利用多模态LLM进行OCR，优于传统的OCR解决方案。我们的结果表明，该方法能够在RGB摄像头难以工作的低光照环境下阅读文本，同时比可穿戴RGB摄像头使用的带宽减少了多达2400倍。", "summary": "该论文介绍了一种用于智能眼镜的新型基于事件的OCR方法，旨在克服传统RGB摄像头在低光照和高速运动场景中的局限性。通过利用用户眼球注视进行事件流的中心凹处理，该方法显著降低了带宽（98%），并利用事件摄像头在高动态范围和快速场景中的优势。该方法在合成数据上训练深度二值重建，并结合多模态LLM进行OCR，其性能优于传统解决方案，在低光照环境下也能有效阅读文本，并且带宽消耗比RGB摄像头少2400倍。", "keywords": "事件视觉, OCR, 智能眼镜, 低光照, 带宽效率", "comments": "这项工作具有显著的创新性，它将事件相机与注视点追踪技术相结合，极大地解决了智能眼镜在低光照和高动态场景下的感知难题。带宽的大幅减少（高达2400倍）是其最突出的优势之一，这将显著延长智能眼镜的电池续航时间。同时，结合多模态LLM进行OCR也体现了前沿技术的融合。这项技术对于增强AR/VR设备的实用性和用户体验具有重要意义。"}}
{"id": "2506.07223", "title": "LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments", "authors": ["Yangqing Zheng", "Shunqi Mao", "Dingxin Zhang", "Weidong Cai"], "summary": "In the realm of embodied intelligence, the evolution of large language models\n(LLMs) has markedly enhanced agent decision making. Consequently, researchers\nhave begun exploring agent performance in dynamically changing high-risk\nscenarios, i.e., fire, flood, and wind scenarios in the HAZARD benchmark. Under\nthese extreme conditions, the delay in decision making emerges as a crucial yet\ninsufficiently studied issue. We propose a Time Conversion Mechanism (TCM) that\ntranslates inference delays in decision-making into equivalent simulation\nframes, thus aligning cognitive and physical costs under a single FPS-based\nmetric. By extending HAZARD with Respond Latency (RL) and Latency-to-Action\nRatio (LAR), we deliver a fully latency-aware evaluation protocol. Moreover, we\npresent the Rapid-Reflex Async-Reflect Agent (RRARA), which couples a\nlightweight LLM-guided feedback module with a rule-based agent to enable\nimmediate reactive behaviors and asynchronous reflective refinements in situ.\nExperiments on HAZARD show that RRARA substantially outperforms existing\nbaselines in latency-sensitive scenarios.", "comment": "Accepted by the CVPR 2025 Embodied AI Workshop", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07223v1", "AI": {"title_translation": "LLM增强的快速反应异步反射具身智能体，用于动态变化环境中的实时决策", "tldr": "针对具身智能体在动态高风险环境中决策延迟问题，本文提出时间转换机制和RRARA智能体，实现实时决策并显著优于现有基线。", "motivation": "现有研究未充分解决具身智能体在动态高风险（如火灾、洪水、大风）场景下决策延迟问题，这在这些极端条件下至关重要。", "method": "提出时间转换机制（TCM），将决策推理延迟转换为模拟帧，统一认知和物理成本。通过响应延迟（RL）和行动延迟比（LAR）扩展HAZARD基准，建立延迟感知评估协议。提出快速反应异步反射智能体（RRARA），结合轻量级LLM引导的反馈模块和基于规则的智能体，实现即时反应行为和异步反射改进。", "result": "RRARA在延迟敏感场景中表现显著优于现有基线。", "conclusion": "RRARA有效解决了具身智能体在动态高风险环境中的实时决策延迟问题，提升了性能。", "translation": "在具身智能领域，大型语言模型（LLM）的演进显著增强了智能体的决策能力。因此，研究人员已开始探索智能体在动态变化的高风险场景中的表现，例如HAZARD基准中的火灾、洪水和大风场景。在这些极端条件下，决策延迟成为一个关键但尚未充分研究的问题。我们提出了一种时间转换机制（TCM），它将决策推理延迟转换为等效的模拟帧，从而在单一的基于FPS的度量标准下统一了认知和物理成本。通过用响应延迟（RL）和行动延迟比（LAR）扩展HAZARD，我们提供了一个完全延迟感知的评估协议。此外，我们提出了快速反应异步反射智能体（RRARA），它将一个轻量级LLM引导的反馈模块与一个基于规则的智能体相结合，以实现即时反应行为和异步反射改进。HAZARD上的实验表明，RRARA在延迟敏感场景中显著优于现有基线。", "summary": "本文针对具身智能体在动态高风险环境中决策延迟的关键问题，提出了时间转换机制（TCM）以统一延迟度量，并扩展了HAZARD基准以实现延迟感知评估。核心贡献是设计了快速反应异步反射智能体（RRARA），该智能体结合了轻量级LLM反馈与规则代理，实现了即时反应和异步优化。实验证明RRARA在延迟敏感场景中性能显著超越现有方法。", "keywords": "具身智能体, 实时决策, LLM, 延迟敏感, HAZARD基准", "comments": "本文创新性地解决了具身智能体在实时高风险环境中的决策延迟问题，通过引入时间转换机制和RRARA智能体，在LLM增强的具身智能体领域具有重要意义。RRARA结合了LLM的认知能力和规则代理的快速反应，为未来的具身智能体设计提供了新思路。"}}
{"id": "2506.06632", "title": "Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning", "authors": ["Shubham Parashar", "Shurui Gui", "Xiner Li", "Hongyi Ling", "Sushil Vemuri", "Blake Olson", "Eric Li", "Yu Zhang", "James Caverlee", "Dileep Kalathil", "Shuiwang Ji"], "summary": "We aim to improve the reasoning capabilities of language models via\nreinforcement learning (RL). Recent RL post-trained models like DeepSeek-R1\nhave demonstrated reasoning abilities on mathematical and coding tasks.\nHowever, prior studies suggest that using RL alone to improve reasoning on\ninherently difficult tasks is less effective. Here, we draw inspiration from\ncurriculum learning and propose to schedule tasks from easy to hard (E2H),\nallowing LLMs to build reasoning skills gradually. Our method is termed E2H\nReasoner. Empirically, we observe that, although easy tasks are important\ninitially, fading them out through appropriate scheduling is essential in\npreventing overfitting. Theoretically, we establish convergence guarantees for\nE2H Reasoner within an approximate policy iteration framework. We derive\nfinite-sample complexity bounds and show that when tasks are appropriately\ndecomposed and conditioned, learning through curriculum stages requires fewer\ntotal samples than direct learning. Experiments across multiple domains show\nthat E2H Reasoner significantly improves the reasoning ability of small LLMs\n(1.5B to 3B), which otherwise struggle when trained with vanilla RL alone,\nhighlighting the effectiveness of our method.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06632v1", "AI": {"title_translation": "从易到难的任务课程强化学习提升大型语言模型推理能力", "tldr": "通过从易到难的任务安排（E2H Reasoner），课程强化学习能有效提升小型LLM的推理能力，并有理论收敛保证。", "motivation": "现有研究表明，单独使用强化学习（RL）来提升大型语言模型（LLM）在固有困难任务上的推理能力效果不佳。", "method": "本文提出了E2H Reasoner方法，该方法借鉴课程学习思想，将任务从易到难（E2H）进行调度，使LLM能够逐步建立推理技能。在理论上，该方法在近似策略迭代框架内建立了收敛保证，并推导了有限样本复杂度界。", "result": "经验上，研究发现简单任务在初期很重要，但通过适当调度逐渐减少它们对于防止过拟合至关重要。理论上，当任务被适当分解和条件化时，通过课程阶段学习所需的总样本量少于直接学习。实验表明，E2H Reasoner显著提升了小型LLM（1.5B到3B）的推理能力，解决了它们在单独使用普通RL训练时遇到的困难。", "conclusion": "E2H Reasoner通过课程强化学习，从易到难地安排任务，有效提升了小型LLM的推理能力，解决了其在单独使用RL训练时遇到的困难，并得到了理论支持。", "translation": "我们旨在通过强化学习（RL）提高语言模型的推理能力。最近经过RL后训练的模型，如DeepSeek-R1，已在数学和编码任务上展示了推理能力。然而，先前的研究表明，单独使用RL来提高固有困难任务的推理能力效果不佳。在此，我们从课程学习中汲取灵感，并提出将任务从易到难（E2H）进行调度，使大型语言模型（LLM）能够逐步建立推理技能。我们的方法被称为E2H Reasoner。经验上，我们观察到，尽管简单任务在初期很重要，但通过适当的调度逐渐减少它们对于防止过拟合至关重要。理论上，我们在近似策略迭代框架内为E2H Reasoner建立了收敛保证。我们推导了有限样本复杂度界，并表明当任务被适当分解和条件化时，通过课程阶段学习所需的总样本量少于直接学习。跨多个领域的实验表明，E2H Reasoner显著提高了小型LLM（1.5B到3B）的推理能力，这些模型在单独使用普通RL训练时会遇到困难，这突显了我们方法的有效性。", "summary": "本文提出E2H Reasoner，一种基于课程强化学习的方法，旨在通过从易到难的任务调度来提升大型语言模型（LLM）的推理能力。该方法经验上证明了简单任务在初期重要性以及逐渐减少简单任务以防过拟合的必要性。理论上，E2H Reasoner在近似策略迭代框架下具有收敛保证，并显示出比直接学习更低的样本复杂度。实验结果表明，E2H Reasoner显著改善了小型LLM的推理能力，弥补了传统RL训练的不足。", "keywords": "强化学习, 课程学习, 大型语言模型, 推理能力, 从易到难", "comments": "本文的创新点在于将课程学习的思想引入到强化学习中，以解决LLM在面对复杂推理任务时单独RL训练效果不佳的问题。通过“从易到难”的任务调度，使得小型LLM也能有效提升推理能力，这对于资源有限的场景具有重要意义。理论分析也提供了坚实的支撑。"}}
{"id": "2506.06691", "title": "An Efficient Digital Watermarking Technique for Small Scale devices", "authors": ["Kaushik Talathi", "Aparna Santra Biswas"], "summary": "In the age of IoT and mobile platforms, ensuring that content stay authentic\nwhilst avoiding overburdening limited hardware is a key problem. This study\nintroduces hybrid Fast Wavelet Transform & Additive Quantization index\nModulation (FWT-AQIM) scheme, a lightweight watermarking approach that secures\ndigital pictures on low-power, memory-constrained small scale devices to\nachieve a balanced trade-off among robustness, imperceptibility, and\ncomputational efficiency. The method embeds watermark in the luminance\ncomponent of YCbCr color space using low-frequency FWT sub-bands, minimizing\nperceptual distortion, using additive QIM for simplicity. Both the extraction\nand embedding processes run in less than 40 ms and require minimum RAM when\ntested on a Raspberry Pi 5. Quality assessments on standard and high-resolution\nimages yield PSNR greater than equal to 34 dB and SSIM greater than equal to\n0.97, while robustness verification includes various geometric and\nsignal-processing attacks demonstrating near-zero bit error rates and NCC\ngreater than equal to 0.998. Using a mosaic-based watermark, redundancy added\nenhancing robustness without reducing throughput, which peaks at 11 MP/s. These\nfindings show that FWT-AQIM provides an efficient, scalable solution for\nreal-time, secure watermarking in bandwidth- and power-constrained contexts,\nopening the way for dependable content protection in developing IoT and\nmultimedia applications.", "comment": "28 pages, 11 figures, 4 tables", "cate": "cs.MM", "url": "http://arxiv.org/abs/2506.06691v1", "AI": {"title_translation": "一种适用于小型设备的有效数字水印技术", "tldr": "本研究提出了一种混合FWT-AQIM轻量级水印方案，用于在资源受限的小型设备上保护数字图像，并在鲁棒性、不可感知性和计算效率之间取得了平衡。", "motivation": "在物联网和移动平台时代，确保内容真实性同时避免对有限硬件造成过重负担是一个关键问题。", "method": "该研究引入了混合快速小波变换和加性量化索引调制（FWT-AQIM）方案。该方法在YCbCr色彩空间的亮度分量中使用低频FWT子带嵌入水印，并使用加性QIM以简化操作，最大限度地减少感知失真。使用基于马赛克的水印增加了冗余，增强了鲁棒性而没有降低吞吐量。", "result": "在Raspberry Pi 5上测试时，提取和嵌入过程均在40毫秒内完成，并需要最小的RAM。标准和高分辨率图像的质量评估显示PSNR≥34 dB和SSIM≥0.97。鲁棒性验证包括各种几何和信号处理攻击，显示出接近零的误码率和NCC≥0.998。吞吐量峰值为11 MP/s。", "conclusion": "FWT-AQIM为带宽和功耗受限环境中的实时安全水印提供了一种高效、可扩展的解决方案，为新兴物联网和多媒体应用中的可靠内容保护开辟了道路。", "translation": "在物联网和移动平台时代，确保内容真实性同时避免对有限硬件造成过重负担是一个关键问题。本研究引入了混合快速小波变换和加性量化索引调制（FWT-AQIM）方案，这是一种轻量级水印方法，用于在低功耗、内存受限的小型设备上保护数字图像，以在鲁棒性、不可感知性和计算效率之间取得平衡。该方法在YCbCr色彩空间的亮度分量中使用低频FWT子带嵌入水印，最大限度地减少感知失真，并使用加性QIM以简化操作。在Raspberry Pi 5上测试时，提取和嵌入过程均在40毫秒内运行，并需要最小的RAM。对标准和高分辨率图像的质量评估显示PSNR大于等于34 dB和SSIM大于等于0.97，而鲁棒性验证包括各种几何和信号处理攻击，显示出接近零的误码率和NCC大于等于0.998。使用基于马赛克的水印，增加了冗余，增强了鲁棒性而没有降低吞吐量，吞吐量峰值为11 MP/s。这些发现表明，FWT-AQIM为带宽和功耗受限环境中的实时安全水印提供了一种高效、可扩展的解决方案，为新兴物联网和多媒体应用中的可靠内容保护开辟了道路。", "summary": "本研究提出了一种名为FWT-AQIM的混合数字水印技术，旨在解决物联网和移动平台中，在资源受限的小型设备上实现数字内容真实性保护的问题。该方法结合了快速小波变换和加性量化索引调制，将水印嵌入图像的亮度分量中，以在鲁棒性、不可感知性和计算效率之间取得平衡。实验结果表明，该技术在Raspberry Pi 5上运行高效，处理时间短，内存占用低，同时在图像质量和抗攻击鲁棒性方面表现出色，为带宽和功耗受限环境下的实时安全水印提供了有效且可扩展的解决方案。", "keywords": "数字水印, FWT-AQIM, 小型设备, 物联网, 鲁棒性", "comments": "该论文的创新之处在于其提出的FWT-AQIM混合方案，专为小型、资源受限设备设计，有效平衡了水印的鲁棒性、不可感知性和计算效率。其在实际硬件（如Raspberry Pi 5）上的出色性能验证了其在物联网和移动应用中内容保护的潜力，为轻量级数字水印领域提供了有价值的贡献。"}}
{"id": "2506.07696", "title": "A Communication-Latency-Aware Co-Simulation Platform for Safety and Comfort Evaluation of Cloud-Controlled ICVs", "authors": ["Yongqi Zhao", "Xinrui Zhang", "Tomislav Mihalj", "Martin Schabauer", "Luis Putzer", "Erik Reichmann-Blaga", "Ádám Boronyák", "András Rövid", "Gábor Soós", "Peizhi Zhang", "Lu Xiong", "Jia Hu", "Arno Eichberger"], "summary": "Testing cloud-controlled intelligent connected vehicles (ICVs) requires\nsimulation environments that faithfully emulate both vehicle behavior and\nrealistic communication latencies. This paper proposes a latency-aware\nco-simulation platform integrating CarMaker and Vissim to evaluate safety and\ncomfort under real-world vehicle-to-cloud (V2C) latency conditions. Two\ncommunication latency models, derived from empirical 5G measurements in China\nand Hungary, are incorporated and statistically modeled using Gamma\ndistributions. A proactive conflict module (PCM) is proposed to dynamically\ncontrol background vehicles and generate safety-critical scenarios. The\nplatform is validated through experiments involving an exemplary system under\ntest (SUT) across six testing conditions combining two PCM modes\n(enabled/disabled) and three latency conditions (none, China, Hungary). Safety\nand comfort are assessed using metrics including collision rate, distance\nheadway, post-encroachment time, and the spectral characteristics of\nlongitudinal acceleration. Results show that the PCM effectively increases\ndriving environment criticality, while V2C latency primarily affects ride\ncomfort. These findings confirm the platform's effectiveness in systematically\nevaluating cloud-controlled ICVs under diverse testing conditions.", "comment": "11 pages, 8 figures", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07696v1", "AI": {"title_translation": "一种考虑通信延迟的云控智能网联汽车安全与舒适性评估协同仿真平台", "tldr": "本文提出了一种考虑通信延迟的协同仿真平台，用于评估云控智能网联汽车在真实V2C延迟条件下的安全性和舒适性，并验证了其有效性。", "motivation": "测试云控智能网联汽车需要能够忠实模拟车辆行为和真实通信延迟的仿真环境。", "method": "本文提出了一种集成CarMaker和Vissim的通信延迟感知协同仿真平台。该平台结合了从中国和匈牙利5G实测数据中提取并使用Gamma分布统计建模的两种通信延迟模型。此外，还提出了一个主动冲突模块（PCM）来动态控制背景车辆并生成安全关键场景。该平台通过在六种测试条件（两种PCM模式和三种延迟条件）下对一个示例系统进行实验验证，并使用碰撞率、车头时距、冲突后通过时间以及纵向加速度的频谱特性等指标评估安全性和舒适性。", "result": "实验结果表明，主动冲突模块（PCM）能够有效提高驾驶环境的危险性，而车云（V2C）通信延迟主要影响乘坐舒适性。", "conclusion": "研究结果证实了该平台在不同测试条件下系统评估云控智能网联汽车的有效性。", "translation": "测试云控智能网联汽车（ICVs）需要能够忠实模拟车辆行为和真实通信延迟的仿真环境。本文提出了一种通信延迟感知的协同仿真平台，该平台集成了CarMaker和Vissim，用于评估真实车云（V2C）延迟条件下的安全性和舒适性。平台中整合了两种通信延迟模型，这些模型来源于中国和匈牙利的5G实测数据，并使用伽马分布进行了统计建模。本文提出了一个主动冲突模块（PCM），用于动态控制背景车辆并生成安全关键场景。该平台通过对一个示例测试系统（SUT）在六种测试条件（结合两种PCM模式：启用/禁用和三种延迟条件：无、中国、匈牙牙）下进行实验验证。安全性和舒适性通过碰撞率、车头时距、冲突后通过时间以及纵向加速度的频谱特性等指标进行评估。结果表明，PCM有效提高了驾驶环境的危险性，而V2C延迟主要影响乘坐舒适性。这些发现证实了该平台在不同测试条件下系统评估云控智能网联汽车的有效性。", "summary": "本文提出并验证了一个考虑通信延迟的协同仿真平台，该平台整合了CarMaker和Vissim，旨在评估云控智能网联汽车在真实车云通信延迟下的安全性和舒适性。平台引入了基于5G实测数据的通信延迟模型和用于生成安全关键场景的主动冲突模块（PCM）。实验结果表明，PCM能有效增加测试场景的危险性，而V2C延迟主要影响乘坐舒适性，从而证明了该平台在多样化测试条件下评估云控ICV的有效性。", "keywords": "云控智能网联汽车, 协同仿真, 通信延迟, 安全性, 舒适性", "comments": "该论文提出了一种创新的协同仿真平台，通过集成车辆动力学仿真（CarMaker）和交通流仿真（Vissim），并引入了基于真实5G测量数据的通信延迟模型以及主动冲突模块，有效地解决了云控ICV在真实通信延迟环境下进行安全性和舒适性评估的挑战。其创新点在于将实际通信延迟数据融入仿真环境，并设计了能够生成关键场景的模块，这对于提高ICV测试的真实性和有效性具有重要意义。该平台为未来云控ICV的研发和测试提供了有力的工具。"}}
{"id": "2506.06928", "title": "How Important are Videos for Training Video LLMs?", "authors": ["George Lydakis", "Alexander Hermans", "Ali Athar", "Daan de Geus", "Bastian Leibe"], "summary": "Research into Video Large Language Models (LLMs) has progressed rapidly, with\nnumerous models and benchmarks emerging in just a few years. Typically, these\nmodels are initialized with a pretrained text-only LLM and finetuned on both\nimage- and video-caption datasets. In this paper, we present findings\nindicating that Video LLMs are more capable of temporal reasoning after\nimage-only training than one would assume, and that improvements from\nvideo-specific training are surprisingly small. Specifically, we show that\nimage-trained versions of two LLMs trained with the recent LongVU algorithm\nperform significantly above chance level on TVBench, a temporal reasoning\nbenchmark. Additionally, we introduce a simple finetuning scheme involving\nsequences of annotated images and questions targeting temporal capabilities.\nThis baseline results in temporal reasoning performance close to, and\noccasionally higher than, what is achieved by video-trained LLMs. This suggests\nsuboptimal utilization of rich temporal features found in real video by current\nmodels. Our analysis motivates further research into the mechanisms that allow\nimage-trained LLMs to perform temporal reasoning, as well as into the\nbottlenecks that render current video training schemes inefficient.", "comment": "Project page on\n  https://visualcomputinginstitute.github.io/videollm-pseudovideo-training/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06928v1", "AI": {"title_translation": "视频对训练视频大型语言模型有多重要？", "tldr": "研究发现，视频大型语言模型（Video LLMs）在仅通过图像训练后，其时间推理能力比预期更强，而视频特有训练带来的提升却出奇地小，这表明当前模型可能未能充分利用视频中的丰富时间特征。", "motivation": "当前视频大型语言模型（Video LLMs）通常使用预训练的文本LLM并在图像和视频字幕数据集上进行微调。然而，本文旨在探究视频数据对于训练Video LLMs时间推理能力的重要性，因为研究发现仅通过图像训练的模型也能展现出意想不到的时间推理能力，且视频特有训练带来的提升有限。", "method": "研究使用了两种通过LongVU算法训练的LLM的图像训练版本，并在时间推理基准TVBench上进行测试。此外，论文还引入了一种简单的微调方案，该方案涉及带有注释图像序列和针对时间能力问题的训练。", "result": "仅通过图像训练的LLMs在TVBench时间推理基准上的表现显著高于随机水平。新引入的简单微调方案在时间推理性能上接近甚至有时超过了视频训练的LLMs所达到的水平。", "conclusion": "研究结果表明，当前模型可能未能充分利用真实视频中丰富的时序特征。这促使需要进一步研究允许图像训练的LLMs执行时序推理的机制，以及导致当前视频训练方案效率低下的瓶颈。", "translation": "视频大型语言模型（LLMs）的研究进展迅速，短短几年内就涌现出众多模型和基准。通常，这些模型以预训练的纯文本LLM作为初始化，并在图像和视频字幕数据集上进行微调。在本文中，我们提出的发现表明，Video LLMs在仅通过图像训练后，其时间推理能力比人们预想的更强，而视频特有训练带来的提升却出奇地小。具体而言，我们展示了使用近期LongVU算法训练的两种LLMs的图像训练版本在时间推理基准TVBench上的表现显著高于随机水平。此外，我们引入了一种简单的微调方案，该方案涉及带注释图像序列和针对时间能力的问题。这个基线在时间推理性能上接近，甚至偶尔高于，视频训练的LLMs所达到的水平。这表明当前模型对真实视频中丰富的时序特征利用不足。我们的分析促使进一步研究允许图像训练的LLMs执行时序推理的机制，以及导致当前视频训练方案效率低下的瓶颈。", "summary": "本研究探讨了视频数据在训练视频大型语言模型（Video LLMs）中的重要性。令人惊讶的是，研究发现仅通过图像训练的Video LLMs已具备显著的时间推理能力，而额外的视频特有训练带来的性能提升却微乎其微。论文通过在TVBench基准上的实验以及引入一种新的图像序列微调方案证明了这一点，该方案甚至能达到或超越视频训练模型的表现。这暗示了当前模型在利用视频丰富时间特征方面的不足，并呼吁进一步研究图像训练LLMs的时间推理机制和现有视频训练方案的效率瓶颈。", "keywords": "视频大型语言模型, 时间推理, 图像训练, 视频训练, 效率瓶颈", "comments": "这篇论文的创新之处在于挑战了传统观念，即视频数据对于训练Video LLMs的时间推理能力至关重要。它揭示了当前视频训练方案可能存在的效率低下问题，并指出了仅通过图像训练的LLMs在时间推理方面的潜力，这为未来的研究提供了新的方向，即如何更有效地利用视频数据或探索图像训练模型时间推理的内在机制。"}}
{"id": "2506.07255", "title": "Subgoal-Guided Policy Heuristic Search with Learned Subgoals", "authors": ["Jake Tuero", "Michael Buro", "Levi H. S. Lelis"], "summary": "Policy tree search is a family of tree search algorithms that use a policy to\nguide the search. These algorithms provide guarantees on the number of\nexpansions required to solve a given problem that are based on the quality of\nthe policy. While these algorithms have shown promising results, the process in\nwhich they are trained requires complete solution trajectories to train the\npolicy. Search trajectories are obtained during a trial-and-error search\nprocess. When the training problem instances are hard, learning can be\nprohibitively costly, especially when starting from a randomly initialized\npolicy. As a result, search samples are wasted in failed attempts to solve\nthese hard instances. This paper introduces a novel method for learning\nsubgoal-based policies for policy tree search algorithms. The subgoals and\npolicies conditioned on subgoals are learned from the trees that the search\nexpands while attempting to solve problems, including the search trees of\nfailed attempts. We empirically show that our policy formulation and training\nmethod improve the sample efficiency of learning a policy and heuristic\nfunction in this online setting.", "comment": "Accepted to ICML-25", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07255v1", "AI": {"title_translation": "基于学习子目标的子目标引导策略启发式搜索", "tldr": "现有策略树搜索训练成本高昂，因其依赖完整解决方案。本文提出从所有搜索树（包括失败尝试）中学习子目标和策略，以提高样本效率。", "motivation": "当前的策略树搜索算法在训练时需要完整的解决方案轨迹，这导致在处理困难问题或使用随机初始化策略时，训练成本过高且搜索样本在失败尝试中被浪费。", "method": "本文提出一种新颖的方法，用于为策略树搜索算法学习基于子目标的策略。子目标和以子目标为条件的策略均从搜索在尝试解决问题时扩展的所有树中学习，包括失败尝试的搜索树。", "result": "实证结果表明，所提出的策略制定和训练方法提高了在线设置中学习策略和启发式函数的样本效率。", "conclusion": "通过从包括失败尝试在内的所有搜索尝试中学习，本文提出的方法显著提高了策略树搜索算法中策略和启发式函数训练的样本效率。", "translation": "策略树搜索是一系列使用策略来指导搜索的树搜索算法。这些算法根据策略的质量，对解决给定问题所需的扩展次数提供保证。尽管这些算法已显示出有希望的结果，但其训练过程需要完整的解决方案轨迹来训练策略。搜索轨迹是在试错搜索过程中获得的。当训练问题实例很困难时，学习成本可能高得令人望而却步，尤其是在从随机初始化的策略开始时。结果，搜索样本在解决这些困难实例的失败尝试中被浪费。本文介绍了一种为策略树搜索算法学习基于子目标的策略的新方法。子目标和以子目标为条件的策略是从搜索在尝试解决问题时扩展的树中学习的，包括失败尝试的搜索树。我们凭经验表明，我们的策略制定和训练方法提高了在这种在线设置中学习策略和启发式函数的样本效率。", "summary": "本文提出了一种新颖的子目标引导策略启发式搜索方法，旨在提高策略树搜索算法的样本效率。现有方法需要完整的解决方案轨迹进行训练，导致在处理困难问题或初始策略随机时，训练成本高昂且样本浪费。本研究通过从所有搜索树（包括失败尝试的搜索树）中学习子目标和基于子目标的策略，有效地解决了这一问题。实验结果表明，该方法显著提升了在线设置下学习策略和启发式函数的样本效率。", "keywords": "策略树搜索, 子目标, 样本效率, 启发式搜索", "comments": "该论文解决了策略树搜索中的一个关键限制：策略训练的高成本和样本效率低下，尤其是在初始策略较差或处理复杂问题时。通过创新性地利用失败搜索尝试中的数据，该方法显著提高了样本效率。这种方法有望使策略树搜索在难以获得完整成功轨迹的复杂问题领域中变得更加实用和可扩展。从“失败”中学习的理念是机器学习中的一个强大概念，其在此的应用是一项显著贡献。"}}
{"id": "2506.06633", "title": "Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification", "authors": ["Chi-Sheng Chen"], "summary": "Recent advancements in quantum machine learning have shown promise in\nenhancing classical neural network architectures, particularly in domains\ninvolving complex, high-dimensional data. Building upon prior work in temporal\nsequence modeling, this paper introduces Vision-QRWKV, a hybrid\nquantum-classical extension of the Receptance Weighted Key Value (RWKV)\narchitecture, applied for the first time to image classification tasks. By\nintegrating a variational quantum circuit (VQC) into the channel mixing\ncomponent of RWKV, our model aims to improve nonlinear feature transformation\nand enhance the expressive capacity of visual representations.\n  We evaluate both classical and quantum RWKV models on a diverse collection of\n14 medical and standard image classification benchmarks, including MedMNIST\ndatasets, MNIST, and FashionMNIST. Our results demonstrate that the\nquantum-enhanced model outperforms its classical counterpart on a majority of\ndatasets, particularly those with subtle or noisy class distinctions (e.g.,\nChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first\nsystematic application of quantum-enhanced RWKV in the visual domain, offering\ninsights into the architectural trade-offs and future potential of quantum\nmodels for lightweight and efficient vision tasks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06633v1", "AI": {"title_translation": "Vision-QRWKV: 探索量子增强型RWKV模型用于图像分类", "tldr": "Vision-QRWKV是一种混合量子-经典RWKV模型，首次应用于图像分类，通过集成变分量子电路到通道混合组件中，在多数医学和标准图像分类基准测试中表现优于其经典对应模型，尤其是在区分度细微或嘈杂的数据集上。", "motivation": "量子机器学习在增强经典神经网络架构方面显示出潜力，尤其是在处理复杂、高维数据时。本文旨在通过将量子增强应用于RWKV架构，提升图像分类任务中的非线性特征转换和视觉表示的表达能力。", "method": "本文引入了Vision-QRWKV，这是一种混合量子-经典扩展的Receptance Weighted Key Value (RWKV) 架构，首次应用于图像分类任务。该模型通过将变分量子电路（VQC）集成到RWKV的通道混合组件中，以期改善非线性特征转换并增强视觉表示的表达能力。研究在14个医学和标准图像分类基准（包括MedMNIST数据集、MNIST和FashionMNIST）上评估了经典和量子RWKV模型。", "result": "量子增强模型在大多数数据集上，特别是那些具有细微或嘈杂类别区分的数据集（如ChestMNIST, RetinaMNIST, BloodMNIST）上，表现优于其经典对应模型。", "conclusion": "本研究代表了量子增强型RWKV在视觉领域的首次系统应用，提供了关于量子模型在轻量级和高效视觉任务中架构权衡和未来潜力的见解。", "translation": "近年来，量子机器学习的进展在增强经典神经网络架构方面显示出潜力，特别是在涉及复杂、高维数据的领域。本文在时间序列建模的先前工作基础上，引入了Vision-QRWKV，这是一种Receptance Weighted Key Value (RWKV) 架构的混合量子-经典扩展，首次应用于图像分类任务。通过将变分量子电路（VQC）集成到RWKV的通道混合组件中，我们的模型旨在改善非线性特征转换并增强视觉表示的表达能力。\n我们在14个医学和标准图像分类基准的多元集合上评估了经典和量子RWKV模型，包括MedMNIST数据集、MNIST和FashionMNIST。我们的结果表明，量子增强模型在大多数数据集上，特别是那些具有细微或嘈杂类别区分的数据集（例如，ChestMNIST, RetinaMNIST, BloodMNIST）上，表现优于其经典对应模型。这项研究代表了量子增强型RWKV在视觉领域的首次系统应用，为轻量级和高效视觉任务中量子模型的架构权衡和未来潜力提供了见解。", "summary": "Vision-QRWKV是一种混合量子-经典RWKV架构，首次应用于图像分类。该模型通过将变分量子电路集成到RWKV的通道混合组件中，旨在提高非线性特征转换和视觉表示的表达能力。在14个医学和标准图像分类基准测试中，Vision-QRWKV在多数数据集上，尤其是在区分度细微或嘈杂的数据集上，性能优于经典的RWKV模型。这项研究是量子增强型RWKV在视觉领域的首次系统应用，为未来轻量级高效视觉任务中的量子模型提供了见解。", "keywords": "量子机器学习, RWKV模型, 图像分类, 混合量子-经典, 变分量子电路", "comments": "这项研究的创新之处在于首次将量子增强型RWKV模型应用于图像分类任务，并集成了变分量子电路。其重要性在于证明了量子增强在处理复杂、高维图像数据方面的潜力，尤其是在医学图像等具有挑战性的数据集上。这为开发更高效、表达能力更强的轻量级视觉模型开辟了新途径。"}}
{"id": "2506.06694", "title": "Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning", "authors": ["Yuan Yuan", "Yukun Liu", "Chonghua Han", "Jie Feng", "Yong Li"], "summary": "Foundation models have revolutionized fields such as natural language\nprocessing and computer vision by enabling general-purpose learning across\ndiverse tasks and datasets. However, building analogous models for human\nmobility remains challenging due to the privacy-sensitive nature of mobility\ndata and the resulting data silos across institutions. To bridge this gap, we\npropose MoveGCL, a scalable and privacy-preserving framework for training\nmobility foundation models via generative continual learning. Without sharing\nraw data, MoveGCL enables decentralized and progressive model evolution by\nreplaying synthetic trajectories generated from a frozen teacher model, and\nreinforces knowledge retention through a tailored distillation strategy that\nmitigates catastrophic forgetting. To address the heterogeneity of mobility\npatterns, MoveGCL incorporates a Mixture-of-Experts Transformer with a\nmobility-aware expert routing mechanism, and employs a layer-wise progressive\nadaptation strategy to stabilize continual updates. Experiments on six\nreal-world urban datasets demonstrate that MoveGCL achieves performance\ncomparable to joint training and significantly outperforms federated learning\nbaselines, while offering strong privacy protection. MoveGCL marks a crucial\nstep toward unlocking foundation models for mobility, offering a practical\nblueprint for open, scalable, and privacy-preserving model development in the\nera of foundation models.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06694v1", "AI": {"title_translation": "打破数据孤岛：通过生成式持续学习迈向开放和可扩展的移动性基础模型", "tldr": "MoveGCL是一个通过生成式持续学习来构建移动性基础模型的框架，它在不共享原始数据的情况下，实现了可扩展、保护隐私且性能优于联邦学习的去中心化模型演化。", "motivation": "现有基础模型在自然语言处理和计算机视觉领域取得了巨大成功，但在人类移动性领域面临挑战，主要原因是移动性数据的隐私敏感性以及由此导致的数据孤岛问题。", "method": "本文提出了MoveGCL框架，通过生成式持续学习训练移动性基础模型。它不共享原始数据，而是通过回放由冻结教师模型生成的合成轨迹实现去中心化和渐进式模型演化。通过定制的蒸馏策略强化知识保留，以缓解灾难性遗忘。为解决移动模式异构性，MoveGCL整合了专家混合Transformer与移动性感知专家路由机制，并采用分层渐进式适应策略稳定持续更新。", "result": "在六个真实世界城市数据集上的实验表明，MoveGCL性能与联合训练相当，显著优于联邦学习基线，同时提供强大的隐私保护。", "conclusion": "MoveGCL是解锁移动性基础模型的重要一步，为基础模型时代开放、可扩展和隐私保护的模型开发提供了实用蓝图。", "translation": "基础模型通过在不同任务和数据集上实现通用学习，彻底改变了自然语言处理和计算机视觉等领域。然而，由于移动性数据的隐私敏感性以及由此导致机构间的数据孤岛，为人类移动性构建类似模型仍然充满挑战。为了弥合这一差距，我们提出了MoveGCL，一个通过生成式持续学习训练移动性基础模型的可扩展和隐私保护框架。在不共享原始数据的情况下，MoveGCL通过回放由冻结教师模型生成的合成轨迹，实现了去中心化和渐进式模型演化，并通过量身定制的蒸馏策略强化知识保留，从而缓解灾难性遗忘。为了解决移动模式的异构性，MoveGCL结合了专家混合Transformer与移动性感知专家路由机制，并采用了分层渐进式适应策略来稳定持续更新。在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并显著优于联邦学习基线，同时提供强大的隐私保护。MoveGCL标志着解锁移动性基础模型的关键一步，为基础模型时代开放、可扩展和隐私保护的模型开发提供了实用蓝图。", "summary": "本文提出了MoveGCL框架，旨在通过生成式持续学习解决移动性数据隐私敏感和数据孤岛问题，以构建开放、可扩展的移动性基础模型。MoveGCL无需共享原始数据，通过合成轨迹回放和定制蒸馏策略实现去中心化模型演化和知识保留，并采用专家混合Transformer处理异构性。实验证明其性能与联合训练相当，且优于联邦学习，同时提供强隐私保护。", "keywords": "移动性基础模型, 生成式持续学习, 数据孤岛, 隐私保护, 灾难性遗忘", "comments": "MoveGCL创新性地结合了生成式持续学习、数据蒸馏和专家混合模型，在不牺牲隐私的前提下，有效解决了移动性数据孤岛和灾难性遗忘问题，为构建实用的移动性基础模型提供了重要的技术路径。其性能与联合训练相当的实验结果显示了其在实际应用中的巨大潜力。"}}
{"id": "2506.07781", "title": "SMaRCSim: Maritime Robotics Simulation Modules", "authors": ["Mart Kartašev", "David Dörner", "Özer Özkahraman", "Petter Ögren", "Ivan Stenius", "John Folkesson"], "summary": "Developing new functionality for underwater robots and testing them in the\nreal world is time-consuming and resource-intensive. Simulation environments\nallow for rapid testing before field deployment. However, existing tools lack\ncertain functionality for use cases in our project: i) developing\nlearning-based methods for underwater vehicles; ii) creating teams of\nautonomous underwater, surface, and aerial vehicles; iii) integrating the\nsimulation with mission planning for field experiments. A holistic solution to\nthese problems presents great potential for bringing novel functionality into\nthe underwater domain. In this paper we present SMaRCSim, a set of simulation\npackages that we have developed to help us address these issues.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07781v1", "AI": {"title_translation": "SMaRCSim: 海洋机器人仿真模块", "tldr": "本文介绍了SMaRCSim，一套用于水下机器人开发和测试的仿真模块，旨在解决现有工具的不足。", "motivation": "开发水下机器人的新功能并在现实世界中进行测试既耗时又耗费资源。尽管仿真环境有帮助，但现有工具缺乏对基于学习的方法开发、自主水下/水面/空中车辆团队创建以及与任务规划集成的支持。", "method": "作者开发了SMaRCSim，一套仿真软件包，以解决现有水下机器人开发和测试中遇到的问题。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "开发水下机器人的新功能并在现实世界中进行测试既耗时又耗费资源。仿真环境允许在现场部署之前进行快速测试。然而，现有工具在我们的项目用例中缺乏某些功能：i) 开发水下车辆的基于学习的方法；ii) 创建自主水下、水面和空中车辆团队；iii) 将仿真与现场实验的任务规划相结合。解决这些问题的整体解决方案为将新颖功能引入水下领域提供了巨大潜力。在本文中，我们介绍了SMaRCSim，一套我们开发的仿真软件包，旨在帮助我们解决这些问题。", "summary": "本文介绍了SMaRCSim，一套为海洋机器人开发设计的仿真模块。鉴于水下机器人功能开发和测试的挑战，以及现有仿真工具在支持基于学习的方法、多类型自主车辆团队协作以及与任务规划集成方面的不足，SMaRCSim旨在提供一个全面的解决方案，以促进水下领域新功能的快速开发和测试。", "keywords": "海洋机器人, 仿真, 水下车辆, 自主系统, SMaRCSim", "comments": "该论文提出了一套针对水下机器人开发特定挑战的仿真工具。其创新性在于解决了现有工具在机器学习方法开发、多异构自主车辆团队仿真以及与实际任务规划集成方面的空白，这对于加速水下机器人技术的进步至关重要。"}}
{"id": "2506.06944", "title": "Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences", "authors": ["Mellon M. Zhang", "Glen Chou", "Saibal Mukhopadhyay"], "summary": "Accurate and efficient object detection is essential for autonomous vehicles,\nwhere real-time perception requires low latency and high throughput. LiDAR\nsensors provide robust depth information, but conventional methods process full\n360{\\deg} scans in a single pass, introducing significant delay. Streaming\napproaches address this by sequentially processing partial scans in the native\npolar coordinate system, yet they rely on translation-invariant convolutions\nthat are misaligned with polar geometry -- resulting in degraded performance or\nrequiring complex distortion mitigation. Recent Mamba-based state space models\n(SSMs) have shown promise for LiDAR perception, but only in the full-scan\nsetting, relying on geometric serialization and positional embeddings that are\nmemory-intensive and ill-suited to streaming. We propose Polar Hierarchical\nMamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming\nLiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial\nencoding and a global forward Mamba for inter-sector temporal modeling,\nreplacing convolutions and positional encodings with distortion-aware,\ndimensionally-decomposed operations. PHiM sets a new state-of-the-art among\nstreaming detectors on the Waymo Open Dataset, outperforming the previous best\nby 10\\% and matching full-scan baselines at twice the throughput. Code will be\navailable at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06944v1", "AI": {"title_translation": "极坐标分层Mamba：基于以自我为中心的点云序列的流式激光雷达目标检测", "tldr": "提出了一种名为PHiM的新型Mamba架构，用于流式LiDAR目标检测，它在Waymo数据集上实现了最先进的性能，超越了现有流式检测器并与全扫描基线持平，同时吞吐量翻倍。", "motivation": "自动驾驶需要低延迟和高吞吐的实时感知。传统LiDAR目标检测方法处理360度全扫描会引入显著延迟。现有流式方法依赖与极坐标几何不匹配的卷积，导致性能下降或需要复杂的失真缓解。现有基于Mamba的模型仅适用于全扫描设置，内存密集且不适合流式处理。", "method": "提出极坐标分层Mamba (PHiM)，这是一种为极坐标流式LiDAR设计的SSM架构。PHiM使用局部双向Mamba块进行扇区内空间编码，并使用全局前向Mamba进行扇区间时间建模，用失真感知、维度分解的操作取代了卷积和位置编码。", "result": "PHiM在Waymo Open Dataset上在流式检测器中达到了新的最先进水平，比之前的最佳性能提高了10%，并且在两倍吞吐量下与全扫描基线匹配。", "conclusion": "PHiM成功解决了流式LiDAR目标检测中的挑战，通过其创新的SSM架构实现了卓越的性能和效率，使其成为自动驾驶领域的重要进展。", "translation": "准确高效的目标检测对于自动驾驶车辆至关重要，其中实时感知需要低延迟和高吞吐量。激光雷达传感器提供稳健的深度信息，但传统方法一次性处理完整的360度扫描，引入了显著延迟。流式方法通过在原生极坐标系中顺序处理部分扫描来解决这个问题，但它们依赖于与极坐标几何不匹配的平移不变卷积，导致性能下降或需要复杂的失真缓解。最近基于Mamba的状态空间模型（SSM）在激光雷达感知方面显示出前景，但仅限于全扫描设置，依赖于内存密集且不适合流式处理的几何序列化和位置嵌入。我们提出了极坐标分层Mamba（PHiM），一种专为极坐标流式激光雷达设计的SSM新架构。PHiM使用局部双向Mamba块进行扇区内空间编码，并使用全局前向Mamba进行扇区间时间建模，用失真感知、维度分解的操作取代了卷积和位置编码。PHiM在Waymo开放数据集上的流式检测器中达到了新的最先进水平，比之前的最佳性能提高了10%，并在两倍吞吐量下与全扫描基线匹配。代码将在https://github.com/meilongzhang/Polar-Hierarchical-Mamba 提供。", "summary": "本文提出了一种名为极坐标分层Mamba (PHiM) 的新型状态空间模型（SSM）架构，专为解决流式激光雷达目标检测中的挑战而设计。PHiM通过结合局部双向Mamba块进行扇区内空间编码和全局前向Mamba进行扇区间时间建模，有效克服了传统方法中卷积与极坐标几何不匹配以及现有Mamba模型不适用于流式处理的问题。实验结果表明，PHiM在Waymo Open Dataset上显著提升了流式检测器的性能，超越了现有最佳方法10%，并在吞吐量翻倍的情况下达到了全扫描基线的性能水平。", "keywords": "LiDAR, Object Detection, Streaming, Mamba, State Space Models", "comments": "这篇论文的创新点在于将Mamba架构引入到流式LiDAR目标检测领域，并针对极坐标系的特性进行了分层和维度分解的设计，有效解决了传统卷积在极坐标系下的失真问题以及现有Mamba模型不适用于流式处理的限制。其重要性在于为自动驾驶车辆的实时感知提供了更高效、更准确的解决方案，尤其是在低延迟和高吞吐量方面取得了显著突破。"}}
{"id": "2506.06637", "title": "Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning", "authors": ["Olimjon Toirov", "Wei Yu"], "summary": "Non-Intrusive Load Monitoring (NILM) identifies the operating status and\nenergy consumption of each electrical device in the circuit by analyzing the\nelectrical signals at the bus, which is of great significance for smart power\nmanagement. However, the complex and changeable load combinations and\napplication environments lead to the challenges of poor feature robustness and\ninsufficient model generalization of traditional NILM methods. To this end,\nthis paper proposes a new non-intrusive load monitoring method that integrates\n\"image load signature\" and continual learning. This method converts\nmulti-dimensional power signals such as current, voltage, and power factor into\nvisual image load feature signatures, and combines deep convolutional neural\nnetworks to realize the identification and classification of multiple devices;\nat the same time, self-supervised pre-training is introduced to improve feature\ngeneralization, and continual online learning strategies are used to overcome\nmodel forgetting to adapt to the emergence of new loads. This paper conducts a\nlarge number of experiments on high-sampling rate load datasets, and compares a\nvariety of existing methods and model variants. The results show that the\nproposed method has achieved significant improvements in recognition accuracy.", "comment": "10 pages, 3 figures, 2025 2nd International Conference on Digital\n  Society and Artificial Intelligence (DSAI 2025), Conference dates: May 23-25,\n  2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06637v1", "AI": {"title_translation": "基于图像负荷特征和持续学习的非侵入式负荷监测", "tldr": "一种新的非侵入式负荷监测（NILM）方法，利用图像负荷特征和持续学习，提高了识别准确性并适应新负荷。", "motivation": "传统的非侵入式负荷监测（NILM）方法面临特征鲁棒性差和模型泛化能力不足的挑战，这是由于复杂多变的负荷组合和应用环境造成的。", "method": "本文提出了一种结合“图像负荷特征”和持续学习的非侵入式负荷监测方法。该方法将电流、电压、功率因数等多维电信号转换为可视化图像负荷特征，并结合深度卷积神经网络进行设备识别和分类。同时，引入自监督预训练以提高特征泛化能力，并采用持续在线学习策略克服模型遗忘，以适应新负荷的出现。", "result": "实验结果表明，所提出的方法在识别准确性方面取得了显著提升。", "conclusion": "所提出的基于图像负荷特征和持续学习的非侵入式负荷监测方法能够有效提高设备识别准确性，并克服传统方法的局限性。", "translation": "非侵入式负荷监测（NILM）通过分析总线上的电信号来识别电路中每个用电设备的运行状态和能耗，这对智能电力管理具有重要意义。然而，复杂多变的负荷组合和应用环境导致传统NILM方法存在特征鲁棒性差和模型泛化能力不足的挑战。为此，本文提出了一种融合“图像负荷特征”和持续学习的新型非侵入式负荷监测方法。该方法将电流、电压、功率因数等多维电信号转换为可视化图像负荷特征，并结合深度卷积神经网络实现多设备的识别和分类；同时，引入自监督预训练以提高特征泛化能力，并采用持续在线学习策略克服模型遗忘，以适应新负荷的出现。本文在高采样率负荷数据集上进行了大量实验，并与多种现有方法和模型变体进行了比较。结果表明，所提出的方法在识别准确性方面取得了显著提升。", "summary": "针对传统非侵入式负荷监测（NILM）方法在复杂多变环境下的特征鲁棒性和模型泛化能力不足的问题，本文提出了一种结合“图像负荷特征”和持续学习的新方法。该方法将多维电信号转换为图像特征，利用深度卷积神经网络进行设备识别，并通过自监督预训练和持续在线学习提升泛化能力并适应新负荷。实验结果表明，该方法显著提高了识别准确性。", "keywords": "非侵入式负荷监测, 图像负荷特征, 持续学习, 深度学习, 智能电力管理", "comments": "该论文的创新点在于将多维电信号转化为图像负荷特征，并将其与深度学习结合，同时引入持续学习策略以解决传统NILM方法在模型泛化能力和适应新负荷方面的不足。这种结合图像特征和持续学习的方法为非侵入式负荷监测提供了一个鲁棒且适应性强的解决方案，对于智能电力管理具有重要意义。"}}
{"id": "2506.06362", "title": "CR-BLEA: Contrastive Ranking for Adaptive Resource Allocation in Bilevel Evolutionary Algorithms", "authors": ["Dejun Xu", "Jijia Chen", "Gary G. Yen", "Min Jiang"], "summary": "Bilevel optimization poses a significant computational challenge due to its\nnested structure, where each upper-level candidate solution requires solving a\ncorresponding lower-level problem. While evolutionary algorithms (EAs) are\neffective at navigating such complex landscapes, their high resource demands\nremain a key bottleneck -- particularly the redundant evaluation of numerous\nunpromising lower-level tasks. Despite recent advances in multitasking and\ntransfer learning, resource waste persists. To address this issue, we propose a\nnovel resource allocation framework for bilevel EAs that selectively identifies\nand focuses on promising lower-level tasks. Central to our approach is a\ncontrastive ranking network that learns relational patterns between paired\nupper- and lower-level solutions online. This knowledge guides a\nreference-based ranking strategy that prioritizes tasks for optimization and\nadaptively controls resampling based on estimated population quality.\nComprehensive experiments across five state-of-the-art bilevel algorithms show\nthat our framework significantly reduces computational cost while preserving --\nor even enhancing -- solution accuracy. This work offers a generalizable\nstrategy to improve the efficiency of bilevel EAs, paving the way for more\nscalable bilevel optimization.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06362v1", "AI": {"title_translation": "CR-BLEA：双层进化算法中自适应资源分配的对比排序", "tldr": "提出CR-BLEA框架，通过对比排序网络自适应分配双层进化算法的资源，显著降低计算成本并保持或提高精度。", "motivation": "双层优化，特别是双层进化算法，由于其嵌套结构和大量无前景下层任务的冗余评估，导致计算成本高昂和资源浪费。", "method": "提出CR-BLEA框架，核心是一个对比排序网络，它在线学习上层和下层解决方案对之间的关系模式。该知识指导一个基于参考的排序策略，优先处理优化任务，并根据估计的种群质量自适应控制重采样。", "result": "在五种最先进的双层算法上的综合实验表明，CR-BLEA框架显著降低了计算成本，同时保持或甚至提高了解决方案的准确性。", "conclusion": "CR-BLEA为提高双层进化算法的效率提供了一种可推广的策略，为更具可扩展性的双层优化铺平了道路。", "translation": "双层优化由于其嵌套结构带来了显著的计算挑战，其中每个上层候选解都需要解决相应的下层问题。尽管进化算法（EAs）在处理这种复杂景观方面是有效的，但其高资源需求仍然是一个关键瓶颈——特别是大量无前景的下层任务的冗余评估。尽管多任务和迁移学习方面取得了最新进展，资源浪费仍然存在。为了解决这个问题，我们为双层进化算法提出了一种新颖的资源分配框架，该框架选择性地识别并专注于有前景的下层任务。我们方法的核心是一个对比排序网络，它在线学习成对的上层和下层解决方案之间的关系模式。这些知识指导一个基于参考的排序策略，该策略优先处理优化任务，并根据估计的种群质量自适应控制重采样。对五种最先进的双层算法进行的综合实验表明，我们的框架显著降低了计算成本，同时保持——甚至提高了——解决方案的准确性。这项工作提供了一种可推广的策略来提高双层进化算法的效率，为更具可扩展性的双层优化铺平了道路。", "summary": "本文针对双层进化算法中计算成本高和资源浪费的问题，提出了一种名为CR-BLEA的新型资源分配框架。该框架的核心是利用一个对比排序网络，在线学习上、下层解决方案之间的关系模式，并以此指导一个基于参考的排序策略，从而智能地优先处理有前景的下层任务并自适应控制重采样。实验结果表明，CR-BLEA能显著降低计算成本，同时保持或提升解决方案的准确性，为双层优化领域提供了一种通用且高效的策略。", "keywords": "双层优化, 进化算法, 资源分配, 对比排序, 计算效率", "comments": "这项工作创新性地将对比学习引入双层进化算法的资源分配中，通过在线学习解决方案间的关系来智能地识别并优先处理有前景的下层任务，有效解决了双层优化中的计算效率瓶颈。其通用性和在不同算法上的良好表现，显示出该方法在提高双层进化算法可扩展性方面的巨大潜力。"}}
{"id": "2506.06825", "title": "Identity Deepfake Threats to Biometric Authentication Systems: Public and Expert Perspectives", "authors": ["Shijing He", "Yaxiong Lei", "Zihan Zhang", "Yuzhou Sun", "Shujun Li", "Chi Zhang", "Juan Ye"], "summary": "Generative AI (Gen-AI) deepfakes pose a rapidly evolving threat to biometric\nauthentication, yet a significant gap exists between expert understanding of\nthese risks and public perception. This disconnection creates critical\nvulnerabilities in systems trusted by millions. To bridge this gap, we\nconducted a comprehensive mixed-method study, surveying 408 professionals\nacross key sectors and conducting in-depth interviews with 37 participants (25\nexperts, 12 general public [non-experts]). Our findings reveal a paradox: while\nthe public increasingly relies on biometrics for convenience, experts express\ngrave concerns about the spoofing of static modalities like face and voice\nrecognition. We found significant demographic and sector-specific divides in\nawareness and trust, with finance professionals, for example, showing\nheightened skepticism. To systematically analyze these threats, we introduce a\nnovel Deepfake Kill Chain model, adapted from Hutchins et al.'s cybersecurity\nframeworks to map the specific attack vectors used by malicious actors against\nbiometric systems. Based on this model and our empirical findings, we propose a\ntri-layer mitigation framework that prioritizes dynamic biometric signals\n(e.g., eye movements), robust privacy-preserving data governance, and targeted\neducational initiatives. This work provides the first empirically grounded\nroadmap for defending against AI-generated identity threats by aligning\ntechnical safeguards with human-centered insights.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.06825v1", "AI": {"title_translation": "身份深度伪造对生物识别认证系统的威胁：公众和专家视角", "tldr": "本研究通过调查和访谈揭示了公众与专家在生物识别深度伪造威胁认知上的差异，并提出了一个深度伪造杀伤链模型和三层缓解框架。", "motivation": "发现生成式AI深度伪造对生物识别认证构成威胁，但专家理解与公众认知之间存在显著差距，这导致系统存在关键漏洞。研究旨在弥合这一差距，为防御AI生成的身份威胁提供实证路线图。", "method": "采用混合方法研究，包括对408名关键行业专业人士的调查，以及对37名参与者（25名专家，12名公众）进行深度访谈。引入了新的深度伪造杀伤链模型，并基于此模型和实证结果提出了三层缓解框架。", "result": "发现公众日益依赖生物识别技术，而专家对静态模态（如面部和语音识别）的欺骗表示严重担忧。在意识和信任方面存在显著的人口统计学和行业特定差异，例如金融专业人士表现出更高的怀疑态度。", "conclusion": "本工作提供了首个以实证为基础的路线图，通过将技术保障与以人为本的见解相结合，以防御AI生成的身份威胁。", "translation": "生成式AI (Gen-AI) 深度伪造对生物识别认证构成迅速演变的威胁，然而，专家对这些风险的理解与公众认知之间存在显著差距。这种脱节在数百万用户信任的系统中造成了关键漏洞。为了弥合这一差距，我们进行了一项全面的混合方法研究，调查了408名来自关键行业的专业人士，并对37名参与者（25名专家，12名普通公众 [非专家]）进行了深度访谈。我们的发现揭示了一个悖论：尽管公众日益依赖生物识别技术以求便利，但专家对静态模态（如面部和语音识别）的欺骗表示严重担忧。我们发现在意识和信任方面存在显著的人口统计学和行业特定差异，例如金融专业人士表现出更高的怀疑态度。为了系统地分析这些威胁，我们引入了一个新颖的深度伪造杀伤链模型，该模型改编自Hutchins et al.的网络安全框架，用于描绘恶意行为者针对生物识别系统使用的特定攻击向量。基于此模型和我们的实证发现，我们提出了一个三层缓解框架，优先考虑动态生物识别信号（例如，眼球运动）、强大的隐私保护数据治理以及有针对性的教育 H。这项工作提供了首个以实证为基础的路线图，通过将技术保障与以人为本的见解相结合，以防御AI生成的身份威胁。", "summary": "本研究探讨了生成式AI深度伪造对生物识别认证系统的威胁，并揭示了专家与公众在风险认知上的显著差异。通过混合方法研究（调查和访谈），作者发现公众为求便利日益依赖生物识别，而专家则对静态模态的欺骗深感担忧。研究引入了深度伪造杀伤链模型，并据此提出了一个三层缓解框架，强调动态生物识别信号、隐私保护数据治理和有针对性教育的重要性，旨在提供防御AI生成身份威胁的实证路线图。", "keywords": "深度伪造, 生物识别认证, 公众认知, 专家视角, 深度伪造杀伤链, 缓解框架", "comments": "这项研究通过结合实证调查和访谈，深入揭示了生物识别深度伪造威胁中公众与专家认知之间的关键差距，这对于理解和应对实际安全挑战至关重要。其创新点在于提出了“深度伪造杀伤链模型”和基于此模型的三层缓解框架，为防御AI生成的身份威胁提供了具体的、以人为本的策略，而非单纯的技术解决方案。这种多维度的方法使其在当前快速发展的AI威胁背景下具有重要意义。"}}
{"id": "2506.07823", "title": "Primal-Dual iLQR for GPU-Accelerated Learning and Control in Legged Robots", "authors": ["Lorenzo Amatucci", "João Sousa-Pinto", "Giulio Turrisi", "Dominique Orban", "Victor Barasuol", "Claudio Semini"], "summary": "This paper introduces a novel Model Predictive Control (MPC) implementation\nfor legged robot locomotion that leverages GPU parallelization. Our approach\nenables both temporal and state-space parallelization by incorporating a\nparallel associative scan to solve the primal-dual Karush-Kuhn-Tucker (KKT)\nsystem. In this way, the optimal control problem is solved in\n$\\mathcal{O}(n\\log{N} + m)$ complexity, instead of $\\mathcal{O}(N(n + m)^3)$,\nwhere $n$, $m$, and $N$ are the dimension of the system state, control vector,\nand the length of the prediction horizon. We demonstrate the advantages of this\nimplementation over two state-of-the-art solvers (acados and crocoddyl),\nachieving up to a 60\\% improvement in runtime for Whole Body Dynamics (WB)-MPC\nand a 700\\% improvement for Single Rigid Body Dynamics (SRBD)-MPC when varying\nthe prediction horizon length. The presented formulation scales efficiently\nwith the problem state dimensions as well, enabling the definition of a\ncentralized controller for up to 16 legged robots that can be computed in less\nthan 25 ms. Furthermore, thanks to the JAX implementation, the solver supports\nlarge-scale parallelization across multiple environments, allowing the\npossibility of performing learning with the MPC in the loop directly in GPU.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07823v1", "AI": {"title_translation": "欠驱动iLQR用于足式机器人的GPU加速学习与控制", "tldr": "本文提出一种新颖的GPU加速的足式机器人模型预测控制（MPC）实现，显著提升了计算效率并支持多机器人控制和MPC在环学习。", "motivation": "现有MPC实现可能在计算效率上不足以满足足式机器人实时控制的需求，尤其是在处理复杂动力学和长预测周期时。", "method": "本文引入了一种新颖的MPC实现，通过GPU并行化，并结合并行关联扫描来解决原始-对偶Karush-Kuhn-Tucker（KKT）系统，从而实现时间并行化和状态空间并行化。该方法将最优控制问题的复杂度从$\\mathcal{O}(N(n + m)^3)$ 降低到 $\\mathcal{O}(n\\log{N} + m)$。", "result": "与现有最先进的求解器（acados和crocoddyl）相比，该实现使全身动力学（WB）-MPC的运行时提升高达60%，单刚体动力学（SRBD）-MPC提升高达700%。所提出的公式能有效扩展，支持最多16个足式机器人的集中式控制器，计算时间少于25毫秒。JAX实现还支持大规模多环境并行化，允许直接在GPU上进行MPC在环学习。", "conclusion": "该GPU加速的原始-对偶iLQR MPC实现显著提升了足式机器人控制的计算效率和可扩展性，为实时控制和基于MPC的学习提供了高效途径。", "translation": "本文介绍了一种新颖的模型预测控制（MPC）实现，用于足式机器人运动，该实现利用了GPU并行化。我们的方法通过引入并行关联扫描来解决原始-对偶Karush-Kuhn-Tucker（KKT）系统，从而实现了时间并行化和状态空间并行化。通过这种方式，最优控制问题的复杂度从 $\\mathcal{O}(N(n + m)^3)$ 降低到 $\\mathcal{O}(n\\log{N} + m)$，其中 $n$、$m$ 和 $N$ 分别是系统状态的维度、控制向量的维度和预测范围的长度。我们展示了这种实现相对于两种最先进的求解器（acados和crocoddyl）的优势，在改变预测范围长度时，对于全身动力学（WB）-MPC，运行时性能提升高达60%，对于单刚体动力学（SRBD）-MPC，提升高达700%。所提出的公式也能有效地随问题状态维度扩展，使得最多16个足式机器人的集中式控制器可以在不到25毫秒内计算。此外，得益于JAX的实现，该求解器支持跨多个环境的大规模并行化，从而可以在GPU上直接进行MPC在环学习。", "summary": "本文提出了一种基于GPU并行化的新型足式机器人模型预测控制（MPC）实现。通过并行关联扫描解决原始-对偶KKT系统，将最优控制问题复杂度显著降低。实验表明，该方法在运行时效率上远超现有求解器，并能有效扩展支持多机器人集中控制和MPC在环学习，为足式机器人的实时控制和学习提供了高效解决方案。", "keywords": "足式机器人, 模型预测控制, GPU并行化, 原始-对偶iLQR, 实时控制", "comments": "这篇论文的创新点在于将原始-对偶iLQR算法与GPU并行化技术结合，特别是通过并行关联扫描解决KKT系统，从而极大地提升了模型预测控制的计算效率和可扩展性。这对于足式机器人等需要高频率实时控制的领域至关重要。其在多机器人控制和MPC在环学习方面的潜力也预示着广阔的应用前景。"}}
{"id": "2506.06952", "title": "LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer", "authors": ["Ying Shen", "Zhiyang Xu", "Jiuhai Chen", "Shizhe Diao", "Jiaxin Zhang", "Yuguang Yao", "Joy Rimchala", "Ismini Lourentzou", "Lifu Huang"], "summary": "Recent advances in multimodal foundation models unifying image understanding\nand generation have opened exciting avenues for tackling a wide range of\nvision-language tasks within a single framework. Despite progress, existing\nunified models typically require extensive pretraining and struggle to achieve\nthe same level of performance compared to models dedicated to each task.\nAdditionally, many of these models suffer from slow image generation speeds,\nlimiting their practical deployment in real-time or resource-constrained\nsettings. In this work, we propose Layerwise Timestep-Expert Flow-based\nTransformer (LaTtE-Flow), a novel and efficient architecture that unifies image\nunderstanding and generation within a single multimodal model. LaTtE-Flow\nbuilds upon powerful pretrained Vision-Language Models (VLMs) to inherit strong\nmultimodal understanding capabilities, and extends them with a novel Layerwise\nTimestep Experts flow-based architecture for efficient image generation.\nLaTtE-Flow distributes the flow-matching process across specialized groups of\nTransformer layers, each responsible for a distinct subset of timesteps. This\ndesign significantly improves sampling efficiency by activating only a small\nsubset of layers at each sampling timestep. To further enhance performance, we\npropose a Timestep-Conditioned Residual Attention mechanism for efficient\ninformation reuse across layers. Experiments demonstrate that LaTtE-Flow\nachieves strong performance on multimodal understanding tasks, while achieving\ncompetitive image generation quality with around 6x faster inference speed\ncompared to recent unified multimodal models.", "comment": "Unified multimodal model, Flow-matching", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06952v1", "AI": {"title_translation": "LaTtE-Flow: 分层时间步专家流式Transformer", "tldr": "LaTtE-Flow是一个统一图像理解和生成的模型，通过分层时间步专家机制实现了更快的推理速度和良好的性能。", "motivation": "现有的统一多模态模型需要大量预训练，性能不如专用模型，且图像生成速度慢，限制了实际部署。", "method": "LaTtE-Flow基于预训练的视觉-语言模型（VLM）。它采用新颖的分层时间步专家流式架构，将流匹配过程分配给专门的Transformer层组，每组负责不同的时间步子集，在每个采样时间步只激活少量层。此外，它还提出了时间步条件残差注意力机制。", "result": "LaTtE-Flow在多模态理解任务上表现出色，图像生成质量具有竞争力，推理速度比最近的统一多模态模型快约6倍。", "conclusion": "LaTtE-Flow为统一图像理解和生成提供了一个高效且有效的解决方案，解决了以往模型在性能和速度上的局限。", "translation": "最近在统一图像理解和生成的跨模态基础模型方面的进展，为在单一框架内处理广泛的视觉-语言任务开辟了激动人心的途径。尽管取得了进展，但现有的统一模型通常需要大量的预训练，并且与专门针对每项任务的模型相比，难以达到相同的性能水平。此外，许多此类模型图像生成速度缓慢，限制了它们在实时或资源受限环境中的实际部署。在这项工作中，我们提出了分层时间步专家流式Transformer（LaTtE-Flow），这是一种新颖高效的架构，可在单一多模态模型中统一图像理解和生成。LaTtE-Flow以强大的预训练视觉-语言模型（VLM）为基础，继承了强大的多模态理解能力，并通过新颖的分层时间步专家流式架构对其进行扩展，以实现高效的图像生成。LaTtE-Flow将流匹配过程分布在专门的Transformer层组中，每组负责不同的时间步子集。这种设计通过在每个采样时间步仅激活少量层来显著提高采样效率。为了进一步提升性能，我们提出了一种时间步条件残差注意力机制，以实现层间高效的信息重用。实验表明，LaTtE-Flow在多模态理解任务上取得了强大性能，同时图像生成质量具有竞争力，推理速度比最近的统一多模态模型快约6倍。", "summary": "LaTtE-Flow是一种新型高效的多模态模型，统一了图像理解和生成。它利用预训练的视觉-语言模型（VLM），并引入了分层时间步专家流式架构，该架构将流匹配过程分配给专门的Transformer层，从而提高了采样效率。它还采用了时间步条件残差注意力机制。实验表明，该模型在理解任务上表现出色，生成质量具有竞争力，并且推理速度显著加快。", "keywords": "多模态模型, 图像生成, 视觉-语言模型, Transformer, 流式模型", "comments": "该模型的创新在于其分层时间步专家流式架构和时间步条件残差注意力机制，这在不牺牲性能的前提下显著提高了统一模型中的效率。这解决了实际部署中一个关键的瓶颈（速度问题）。"}}
{"id": "2506.07411", "title": "An Intelligent Fault Self-Healing Mechanism for Cloud AI Systems via Integration of Large Language Models and Deep Reinforcement Learning", "authors": ["Ze Yang", "Yihong Jin", "Juntian Liu", "Xinhe Xu"], "summary": "As the scale and complexity of cloud-based AI systems continue to increase,\nthe detection and adaptive recovery of system faults have become the core\nchallenges to ensure service reliability and continuity. In this paper, we\npropose an Intelligent Fault Self-Healing Mechanism (IFSHM) that integrates\nLarge Language Model (LLM) and Deep Reinforcement Learning (DRL), aiming to\nrealize a fault recovery framework with semantic understanding and policy\noptimization capabilities in cloud AI systems. On the basis of the traditional\nDRL-based control model, the proposed method constructs a two-stage hybrid\narchitecture: (1) an LLM-driven fault semantic interpretation module, which can\ndynamically extract deep contextual semantics from multi-source logs and system\nindicators to accurately identify potential fault modes; (2) DRL recovery\nstrategy optimizer, based on reinforcement learning, learns the dynamic\nmatching of fault types and response behaviors in the cloud environment. The\ninnovation of this method lies in the introduction of LLM for environment\nmodeling and action space abstraction, which greatly improves the exploration\nefficiency and generalization ability of reinforcement learning. At the same\ntime, a memory-guided meta-controller is introduced, combined with\nreinforcement learning playback and LLM prompt fine-tuning strategy, to achieve\ncontinuous adaptation to new failure modes and avoid catastrophic forgetting.\nExperimental results on the cloud fault injection platform show that compared\nwith the existing DRL and rule methods, the IFSHM framework shortens the system\nrecovery time by 37% with unknown fault scenarios.", "comment": "Proceedings of 2025 IEEE 8th International Conference on Advanced\n  Electronic Materials, Computers and Software Engineering (AEMCSE 2025)", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07411v1", "AI": {"title_translation": "通过集成大型语言模型和深度强化学习为云AI系统提供智能故障自愈机制", "tldr": "本文提出了一种智能故障自愈机制（IFSHM），通过整合大型语言模型（LLM）和深度强化学习（DRL），旨在为云AI系统提供具备语义理解和策略优化能力的故障恢复框架。", "motivation": "随着云AI系统规模和复杂性的不断增加，故障检测和自适应恢复已成为确保服务可靠性和连续性的核心挑战。", "method": "本文提出了一种智能故障自愈机制（IFSHM），该机制整合了大型语言模型（LLM）和深度强化学习（DRL）。在传统基于DRL的控制模型基础上，该方法构建了一个两阶段混合架构：1）LLM驱动的故障语义解释模块，能够从多源日志和系统指标中动态提取深层上下文语义，以准确识别潜在故障模式；2）DRL恢复策略优化器，基于强化学习，学习云环境中故障类型和响应行为的动态匹配。该方法的创新之处在于引入LLM进行环境建模和动作空间抽象，从而大大提高了强化学习的探索效率和泛化能力。同时，引入了记忆引导的元控制器，结合强化学习回放和LLM提示微调策略，以实现对新故障模式的持续适应并避免灾难性遗忘。", "result": "在云故障注入平台上的实验结果表明，与现有DRL和规则方法相比，IFSHM框架在未知故障场景下将系统恢复时间缩短了37%。", "conclusion": "本文提出的智能故障自愈机制（IFSHM）通过有效整合大型语言模型（LLM）和深度强化学习（DRL），显著提升了云AI系统在复杂和未知故障场景下的故障检测、语义理解和自适应恢复能力，尤其在缩短系统恢复时间方面表现出显著优势。", "translation": "随着云AI系统规模和复杂性的不断增加，系统故障的检测和自适应恢复已成为确保服务可靠性和连续性的核心挑战。在本文中，我们提出了一种智能故障自愈机制（IFSHM），该机制整合了大型语言模型（LLM）和深度强化学习（DRL），旨在实现云AI系统中具备语义理解和策略优化能力的故障恢复框架。在传统基于DRL的控制模型基础上，所提出的方法构建了一个两阶段混合架构：1）LLM驱动的故障语义解释模块，能够从多源日志和系统指标中动态提取深层上下文语义，以准确识别潜在故障模式；2）DRL恢复策略优化器，基于强化学习，学习云环境中故障类型和响应行为的动态匹配。该方法的创新之处在于引入LLM进行环境建模和动作空间抽象，从而大大提高了强化学习的探索效率和泛化能力。同时，引入了记忆引导的元控制器，结合强化学习回放和LLM提示微调策略，以实现对新故障模式的持续适应并避免灾难性遗忘。在云故障注入平台上的实验结果表明，与现有DRL和规则方法相比，IFSHM框架在未知故障场景下将系统恢复时间缩短了37%。", "summary": "本文提出了一种名为智能故障自愈机制（IFSHM）的新框架，旨在解决云AI系统中的故障检测和恢复挑战。该机制巧妙地结合了大型语言模型（LLM）和深度强化学习（DRL）。IFSHM采用两阶段架构：首先，LLM模块负责从多源数据中进行故障语义解释和模式识别；其次，DRL优化器学习并执行最佳恢复策略。该方法通过引入LLM进行环境建模和动作空间抽象，显著提升了强化学习的效率和泛化能力，并通过记忆引导的元控制器确保了对新故障模式的持续适应。实验证明，IFSHM在未知故障场景下能将系统恢复时间缩短37%。", "keywords": "智能故障自愈, 大型语言模型, 深度强化学习, 云AI系统, 故障恢复", "comments": "该论文的创新点在于首次将大型语言模型（LLM）引入到云AI系统的故障自愈机制中，并将其与深度强化学习（DRL）相结合。通过LLM进行环境建模和动作空间抽象，极大地提升了强化学习的探索效率和泛化能力，解决了传统DRL在复杂云环境中的局限性。此外，引入记忆引导的元控制器有效解决了灾难性遗忘问题，使得系统能够持续适应新的故障模式。这项工作为提升云AI系统的可靠性和韧性提供了重要的技术路径。"}}
{"id": "2506.06644", "title": "Spark Transformer: Reactivating Sparsity in FFN and Attention", "authors": ["Chong You", "Kan Wu", "Zhipeng Jia", "Lin Chen", "Srinadh Bhojanapalli", "Jiaxian Guo", "Utku Evci", "Jan Wassenberg", "Praneeth Netrapalli", "Jeremiah J. Willcock", "Suvinay Subramanian", "Felix Chern", "Alek Andreev", "Shreya Pathak", "Felix Yu", "Prateek Jain", "David E. Culler", "Henry M. Levy", "Sanjiv Kumar"], "summary": "The discovery of the lazy neuron phenomenon in trained Transformers, where\nthe vast majority of neurons in their feed-forward networks (FFN) are inactive\nfor each token, has spurred tremendous interests in activation sparsity for\nenhancing large model efficiency. While notable progress has been made in\ntranslating such sparsity to wall-time benefits, modern Transformers have moved\naway from the ReLU activation function crucial to this phenomenon. Existing\nefforts on re-introducing activation sparsity often degrade model quality,\nincrease parameter count, complicate or slow down training. Sparse attention,\nthe application of sparse activation to the attention mechanism, often faces\nsimilar challenges.\n  This paper introduces the Spark Transformer, a novel architecture that\nachieves a high level of activation sparsity in both FFN and the attention\nmechanism while maintaining model quality, parameter count, and standard\ntraining procedures. Our method realizes sparsity via top-k masking for\nexplicit control over sparsity level. Crucially, we introduce statistical\ntop-k, a hardware-accelerator-friendly, linear-time approximate algorithm that\navoids costly sorting and mitigates significant training slowdown from standard\ntop-$k$ operators. Furthermore, Spark Transformer reallocates existing FFN\nparameters and attention key embeddings to form a low-cost predictor for\nidentifying activated entries. This design not only mitigates quality loss from\nenforced sparsity, but also enhances wall-time benefit. Pretrained with the\nGemma-2 recipe, Spark Transformer demonstrates competitive performance on\nstandard benchmarks while exhibiting significant sparsity: only 8% of FFN\nneurons are activated, and each token attends to a maximum of 256 tokens. This\nsparsity translates to a 2.5x reduction in FLOPs, leading to decoding wall-time\nspeedups of up to 1.79x on CPU and 1.40x on GPU.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06644v1", "AI": {"title_translation": "Spark Transformer：在FFN和注意力机制中重新激活稀疏性", "tldr": "Spark Transformer通过创新的top-k掩码和参数重分配，在保持模型质量和训练效率的同时，在FFN和注意力机制中实现了高激活稀疏性，显著降低FLOPs并提高解码速度。", "motivation": "现有Transformer中“惰性神经元”现象促使研究人员关注激活稀疏性以提高模型效率。然而，现代Transformer放弃了ReLU激活函数，导致重新引入激活稀疏性时常伴随模型质量下降、参数增加或训练复杂/变慢等问题，稀疏注意力也面临类似挑战。", "method": "本文引入Spark Transformer架构，通过top-k掩码实现高激活稀疏性，明确控制稀疏水平。关键在于提出统计top-k算法，这是一种硬件加速器友好、线性时间的近似算法，避免了昂贵的排序并减轻了训练减速。此外，Spark Transformer重新分配现有FFN参数和注意力键嵌入，形成低成本预测器来识别激活条目，从而减轻质量损失并增强实际时间效益。", "result": "Spark Transformer在标准基准测试中表现出有竞争力的性能，同时展现出显著的稀疏性：仅8%的FFN神经元被激活，每个token最多关注256个token。这种稀疏性使FLOPs减少2.5倍，在CPU上解码实际时间加速高达1.79倍，在GPU上高达1.40倍。", "conclusion": "Spark Transformer成功地在保持模型质量和标准训练程序的同时，显著提高了FFN和注意力机制的激活稀疏性，带来了FLOPs的显著减少和实际解码时间的加速，证明了在现代Transformer中重新激活稀疏性的可行性和有效性。", "translation": "在训练好的Transformer中发现“惰性神经元”现象，即其前馈网络（FFN）中的绝大多数神经元对每个token都是非活跃的，这极大地激发了人们对激活稀疏性以提高大型模型效率的兴趣。尽管在将这种稀疏性转化为实际时间效益方面取得了显著进展，但现代Transformer已经放弃了对这种现象至关重要的ReLU激活函数。现有重新引入激活稀疏性的努力常常会降低模型质量、增加参数数量、使训练复杂化或变慢。稀疏注意力，即将稀疏激活应用于注意力机制，也常面临类似的挑战。\n本文介绍了Spark Transformer，这是一种新颖的架构，它在FFN和注意力机制中都实现了高水平的激活稀疏性，同时保持了模型质量、参数数量和标准训练程序。我们的方法通过top-k掩码实现稀疏性，从而明确控制稀疏水平。至关重要的是，我们引入了统计top-k，这是一种硬件加速器友好、线性时间的近似算法，它避免了昂贵的排序并减轻了标准top-k操作符带来的显著训练减速。此外，Spark Transformer重新分配现有的FFN参数和注意力键嵌入，形成一个低成本的预测器，用于识别激活的条目。这种设计不仅减轻了强制稀疏性带来的质量损失，而且还增强了实际时间效益。使用Gemma-2配方进行预训练，Spark Transformer在标准基准测试中表现出有竞争力的性能，同时展现出显著的稀疏性：只有8%的FFN神经元被激活，并且每个token最多关注256个token。这种稀疏性使FLOPs减少2.5倍，在CPU上解码实际时间加速高达1.79倍，在GPU上高达1.40倍。", "summary": "本文提出Spark Transformer，一个在FFN和注意力机制中实现高激活稀疏性的新型架构。通过引入硬件友好的统计top-k近似算法和参数重分配，Spark Transformer在保持模型质量、参数量和训练效率的同时，显著降低了计算量（FLOPs减少2.5倍）并提高了推理速度（CPU上加速达1.79倍，GPU上达1.40倍），验证了其在现代Transformer中重新激活稀疏性的有效性。", "keywords": "Spark Transformer, 激活稀疏性, FFN, 注意力机制, top-k", "comments": "Spark Transformer的创新之处在于其对激活稀疏性的实现方式，特别是统计top-k算法的应用，解决了传统top-k操作带来的训练减速问题，并兼顾了硬件友好性。此外，通过参数重分配来预测激活条目的设计，有效缓解了强制稀疏性可能导致的质量下降。这篇论文对于提升大型Transformer模型的效率，尤其是在资源受限环境下的部署，具有重要意义。"}}
{"id": "2506.06861", "title": "Differentially Private Sparse Linear Regression with Heavy-tailed Responses", "authors": ["Xizhi Tian", "Meng Ding", "Touming Tao", "Zihang Xiang", "Di Wang"], "summary": "As a fundamental problem in machine learning and differential privacy (DP),\nDP linear regression has been extensively studied. However, most existing\nmethods focus primarily on either regular data distributions or low-dimensional\ncases with irregular data. To address these limitations, this paper provides a\ncomprehensive study of DP sparse linear regression with heavy-tailed responses\nin high-dimensional settings. In the first part, we introduce the DP-IHT-H\nmethod, which leverages the Huber loss and private iterative hard thresholding\nto achieve an estimation error bound of \\(\n  \\tilde{O}\\biggl(\n  s^{* \\frac{1 }{2}}\n  \\cdot \\biggl(\\frac{\\log d}{n}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}}\n  +\n  s^{* \\frac{1 + 2\\zeta}{2 + 2\\zeta}}\n  \\cdot \\biggl(\\frac{\\log^2 d}{n \\varepsilon}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}}\n  \\biggr) \\) under the $(\\varepsilon, \\delta)$-DP model, where $n$ is the\nsample size, $d$ is the dimensionality, $s^*$ is the sparsity of the parameter,\nand $\\zeta \\in (0, 1]$ characterizes the tail heaviness of the data. In the\nsecond part, we propose DP-IHT-L, which further improves the error bound under\nadditional assumptions on the response and achieves \\(\n  \\tilde{O}\\Bigl(\\frac{(s^*)^{3/2} \\log d}{n \\varepsilon}\\Bigr). \\) Compared to\nthe first result, this bound is independent of the tail parameter $\\zeta$.\nFinally, through experiments on synthetic and real-world datasets, we\ndemonstrate that our methods outperform standard DP algorithms designed for\n``regular'' data.", "comment": "Accepted at ECML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06861v1", "AI": {"title_translation": "差分隐私重尾响应稀疏线性回归", "tldr": "本文研究了高维重尾响应的差分隐私稀疏线性回归，并提出了两种新方法（DP-IHT-H和DP-IHT-L），在理论上取得了改进的误差界限，并在实验中表现优异。", "motivation": "现有的差分隐私线性回归方法主要关注常规数据分布或低维不规则数据，未能解决高维重尾响应下的差分隐私稀疏线性回归问题。", "method": "本文提出了两种方法：1. DP-IHT-H: 利用Huber损失和私有迭代硬阈值（private iterative hard thresholding）方法。2. DP-IHT-L: 在响应数据额外假设下，进一步改进了误差界限。", "result": "1. DP-IHT-H: 在(ε, δ)-DP模型下，实现了估计误差界限为 \\( \\tilde{O}\\biggl( s^{* \\frac{1 }{2}} \\cdot \\biggl(\\frac{\\log d}{n}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}} + s^{* \\frac{1 + 2\\zeta}{2 + 2\\zeta}} \\cdot \\biggl(\\frac{\\log^2 d}{n \\varepsilon}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}} \\biggr) \\)。2. DP-IHT-L: 在额外假设下，实现了估计误差界限为 \\( \\tilde{O}\\Bigl(\\frac{(s^*)^{3/2} \\log d}{n \\varepsilon}\\Bigr) \\)，该界限与尾部参数ζ无关。3. 实验结果: 在合成和真实数据集上的实验表明，本文提出的方法优于为“常规”数据设计的标准DP算法。", "conclusion": "本文成功解决了高维重尾响应下的差分隐私稀疏线性回归问题，并提出了理论上具有更优误差界限且在实践中表现更好的新方法。", "translation": "作为一个机器学习和差分隐私（DP）中的基础问题，差分隐私线性回归已被广泛研究。然而，大多数现有方法主要关注常规数据分布或低维不规则数据。为了解决这些限制，本文全面研究了高维设置下重尾响应的差分隐私稀疏线性回归。第一部分，我们介绍了DP-IHT-H方法，该方法利用Huber损失和私有迭代硬阈值技术，在(ε, δ)-DP模型下实现了估计误差界限为 \\( \\tilde{O}\\biggl( s^{* \\frac{1 }{2}} \\cdot \\biggl(\\frac{\\log d}{n}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}} + s^{* \\frac{1 + 2\\zeta}{2 + 2\\zeta}} \\cdot \\biggl(\\frac{\\log^2 d}{n \\varepsilon}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}} \\biggr) \\)，其中n是样本量，d是维度，s*是参数的稀疏度，ζ ∈ (0, 1]表征数据的尾部厚度。第二部分，我们提出了DP-IHT-L，在响应数据额外假设下进一步改善了误差界限，达到了 \\( \\tilde{O}\\Bigl(\\frac{(s^*)^{3/2} \\log d}{n \\varepsilon}\\Bigr) \\)。与第一部分的结果相比，这个界限与尾部参数ζ无关。最后，通过在合成和真实世界数据集上的实验，我们证明了我们的方法优于为“常规”数据设计的标准DP算法。", "summary": "本文针对高维重尾响应数据下的差分隐私稀疏线性回归问题进行了深入研究。作者提出了两种新方法：DP-IHT-H，它结合了Huber损失和私有迭代硬阈值技术，并在(ε, δ)-DP模型下给出了理论误差界限；以及DP-IHT-L，在额外假设下进一步优化了误差界限，使其与数据尾部特性无关。实验结果表明，这些方法在性能上超越了现有为常规数据设计的差分隐私算法。", "keywords": "差分隐私, 稀疏线性回归, 重尾响应, 高维数据, Huber损失", "comments": "这篇论文解决了差分隐私领域一个重要且具有挑战性的问题，即在高维和重尾数据背景下的稀疏线性回归。其创新点在于提出了两种新的算法（DP-IHT-H和DP-IHT-L），并提供了严格的理论误差界限，特别是DP-IHT-L的误差界限独立于尾部参数ζ，这显示了其在处理重尾数据时的鲁棒性。实验验证了这些方法的有效性，表明其在实际应用中具有重要意义。"}}
{"id": "2506.07876", "title": "Versatile Loco-Manipulation through Flexible Interlimb Coordination", "authors": ["Xinghao Zhu", "Yuxin Chen", "Lingfeng Sun", "Farzad Niroui", "Simon Le CleacH", "Jiuguang Wang", "Kuan Fang"], "summary": "The ability to flexibly leverage limbs for loco-manipulation is essential for\nenabling autonomous robots to operate in unstructured environments. Yet, prior\nwork on loco-manipulation is often constrained to specific tasks or\npredetermined limb configurations. In this work, we present Reinforcement\nLearning for Interlimb Coordination (ReLIC), an approach that enables versatile\nloco-manipulation through flexible interlimb coordination. The key to our\napproach is an adaptive controller that seamlessly bridges the execution of\nmanipulation motions and the generation of stable gaits based on task demands.\nThrough the interplay between two controller modules, ReLIC dynamically assigns\neach limb for manipulation or locomotion and robustly coordinates them to\nachieve the task success. Using efficient reinforcement learning in simulation,\nReLIC learns to perform stable gaits in accordance with the manipulation goals\nin the real world. To solve diverse and complex tasks, we further propose to\ninterface the learned controller with different types of task specifications,\nincluding target trajectories, contact points, and natural language\ninstructions. Evaluated on 12 real-world tasks that require diverse and complex\ncoordination patterns, ReLIC demonstrates its versatility and robustness by\nachieving a success rate of 78.9% on average. Videos and code can be found at\nhttps://relic-locoman.github.io/.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07876v1", "AI": {"title_translation": "通过灵活的肢体协调实现多功能运动-操作", "tldr": "ReLIC是一种基于强化学习的方法，通过自适应控制器和动态肢体分配，实现机器人灵活的运动-操作，并在真实世界任务中表现出高成功率。", "motivation": "自主机器人在非结构化环境中操作需要灵活利用肢体进行运动-操作，但现有工作常受限于特定任务或预设肢体配置。", "method": "本文提出了基于肢体间协调的强化学习（ReLIC）方法。其核心是一个自适应控制器，根据任务需求无缝连接操作动作和稳定步态的执行。通过两个控制器模块的相互作用，ReLIC动态地为每个肢体分配操作或运动任务，并鲁棒地协调它们以实现任务成功。该方法在模拟中通过高效强化学习来学习稳定步态以适应操作目标，并通过接口与目标轨迹、接触点和自然语言指令等不同类型的任务规范进行交互。", "result": "ReLIC在需要多样和复杂协调模式的12项真实世界任务中进行了评估，平均成功率达到78.9%，展示了其多功能性和鲁棒性。", "conclusion": "ReLIC通过灵活的肢体协调实现了多功能运动-操作，并在真实世界任务中表现出强大的性能和适应性，克服了以往方法在特定任务或预设配置上的限制。", "translation": "自主机器人在非结构化环境中操作，灵活利用肢体进行运动-操作至关重要。然而，以往的运动-操作工作通常受限于特定任务或预设的肢体配置。在这项工作中，我们提出了基于肢体间协调的强化学习（ReLIC）方法，通过灵活的肢体协调实现多功能运动-操作。我们方法的关键是一个自适应控制器，它根据任务需求无缝连接操作动作的执行和稳定步态的生成。通过两个控制器模块的相互作用，ReLIC动态地为每个肢体分配操作或运动任务，并鲁棒地协调它们以实现任务成功。通过模拟中的高效强化学习，ReLIC学会了根据真实世界中的操作目标执行稳定步态。为了解决多样且复杂的任务，我们进一步提出将学习到的控制器与不同类型的任务规范（包括目标轨迹、接触点和自然语言指令）进行接口。在需要多样和复杂协调模式的12项真实世界任务中进行评估，ReLIC平均成功率达到78.9%，展示了其多功能性和鲁棒性。视频和代码可在https://relic-locoman.github.io/找到。", "summary": "本文提出了一种名为ReLIC（基于肢体间协调的强化学习）的新方法，旨在实现机器人灵活的运动-操作能力。ReLIC通过一个自适应控制器，能够根据任务需求动态地协调机器人的肢体进行操作或运动。该方法利用强化学习在模拟中进行训练，并能与多种任务规范（如目标轨迹、接触点、自然语言指令）进行交互。在12项真实的复杂协调任务中，ReLIC平均实现了78.9%的成功率，证明了其在非结构化环境中进行多功能运动-操作的有效性和鲁棒性。", "keywords": "运动-操作, 强化学习, 肢体协调, 机器人, 自适应控制器", "comments": "ReLIC的创新之处在于其自适应控制器和动态肢体分配机制，这使得机器人能够灵活地在运动和操作之间切换，并克服了传统方法对特定任务或配置的限制。其在真实世界任务中的高成功率证明了其实用性和重要性，为自主机器人在复杂非结构化环境中的应用提供了新的解决方案。"}}
{"id": "2506.06953", "title": "Task-driven real-world super-resolution of document scans", "authors": ["Maciej Zyrek", "Tomasz Tarasiewicz", "Jakub Sadel", "Aleksandra Krzywon", "Michal Kawulok"], "summary": "Single-image super-resolution refers to the reconstruction of a\nhigh-resolution image from a single low-resolution observation. Although recent\ndeep learning-based methods have demonstrated notable success on simulated\ndatasets -- with low-resolution images obtained by degrading and downsampling\nhigh-resolution ones -- they frequently fail to generalize to real-world\nsettings, such as document scans, which are affected by complex degradations\nand semantic variability. In this study, we introduce a task-driven, multi-task\nlearning framework for training a super-resolution network specifically\noptimized for optical character recognition tasks. We propose to incorporate\nauxiliary loss functions derived from high-level vision tasks, including text\ndetection using the connectionist text proposal network, text recognition via a\nconvolutional recurrent neural network, keypoints localization using Key.Net,\nand hue consistency. To balance these diverse objectives, we employ dynamic\nweight averaging mechanism, which adaptively adjusts the relative importance of\neach loss term based on its convergence behavior. We validate our approach upon\nthe SRResNet architecture, which is a well-established technique for\nsingle-image super-resolution. Experimental evaluations on both simulated and\nreal-world scanned document datasets demonstrate that the proposed approach\nimproves text detection, measured with intersection over union, while\npreserving overall image fidelity. These findings underscore the value of\nmulti-objective optimization in super-resolution models for bridging the gap\nbetween simulated training regimes and practical deployment in real-world\nscenarios.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06953v1", "AI": {"title_translation": "任务驱动的文档扫描真实世界超分辨率", "tldr": "本文提出了一种任务驱动的多任务学习框架，用于文档扫描的超分辨率，通过结合文本检测和识别等高层视觉任务的辅助损失函数，以提高真实世界场景下的性能。", "motivation": "现有的基于深度学习的单图像超分辨率方法在模拟数据集上表现良好，但在真实世界的文档扫描等复杂降级和语义变异场景下泛化能力差。", "method": "本文引入了一个任务驱动的多任务学习框架，用于训练专门针对光学字符识别（OCR）任务优化的超分辨率网络。该方法结合了来自高层视觉任务的辅助损失函数，包括使用CTPN的文本检测、CNN的文本识别、Key.Net的关键点定位和色调一致性。为了平衡这些目标，采用了动态权重平均机制来自适应调整每个损失项的重要性。", "result": "在模拟和真实世界的扫描文档数据集上的实验评估表明，所提出的方法提高了文本检测（通过IoU测量），同时保持了整体图像保真度。", "conclusion": "多目标优化在超分辨率模型中对于弥合模拟训练和真实世界部署之间的差距具有重要价值。", "translation": "单图像超分辨率是指从单个低分辨率观测图像重建高分辨率图像。尽管最近基于深度学习的方法在模拟数据集上取得了显著成功——通过降级和下采样高分辨率图像获得低分辨率图像——但它们经常无法推广到真实世界场景，例如受复杂降级和语义变异影响的文档扫描。在本研究中，我们引入了一个任务驱动的多任务学习框架，用于训练专门针对光学字符识别任务优化的超分辨率网络。我们建议结合来自高层视觉任务的辅助损失函数，包括使用连接主义文本提议网络的文本检测、通过卷积循环神经网络的文本识别、使用Key.Net的关键点定位以及色调一致性。为了平衡这些不同的目标，我们采用了动态权重平均机制，该机制根据每个损失项的收敛行为自适应调整其相对重要性。我们在SRResNet架构上验证了我们的方法，这是一种成熟的单图像超分辨率技术。在模拟和真实世界扫描文档数据集上的实验评估表明，所提出的方法提高了文本检测（通过交并比测量），同时保持了整体图像保真度。这些发现强调了超分辨率模型中多目标优化的价值，以弥合模拟训练机制与真实世界部署之间的差距。", "summary": "本研究提出了一种任务驱动的多任务学习框架，旨在解决现有超分辨率模型在真实世界文档扫描中泛化能力差的问题。通过将文本检测、文本识别、关键点定位和色调一致性等高层视觉任务的辅助损失函数纳入训练，并采用动态权重平均机制平衡各目标，该方法在SRResNet架构上进行了验证。实验结果表明，该方法有效提升了文本检测性能，并保持了图像整体质量，证明了多目标优化在弥合模拟与真实世界超分辨率之间鸿沟的重要性。", "keywords": "超分辨率, 文档扫描, 任务驱动, 多任务学习, 光学字符识别", "comments": "该论文的创新点在于提出了一个任务驱动的多任务学习框架，将高层视觉任务（如OCR）的辅助损失函数融入超分辨率网络的训练中，这有效地解决了传统超分辨率模型在真实世界复杂场景（如文档扫描）中泛化能力不足的问题。通过动态权重平均机制平衡不同损失项，进一步优化了模型性能。这项工作对于提升文档数字化和OCR的实际应用具有重要意义。"}}
{"id": "2506.07418", "title": "Evaluating Visual Mathematics in Multimodal LLMs: A Multilingual Benchmark Based on the Kangaroo Tests", "authors": ["Arnau Igualde Sáez", "Lamyae Rhomrasi", "Yusef Ahsini", "Ricardo Vinuesa", "Sergio Hoyas", "Jose P. García Sabater", "Marius J. Fullana i Alfonso", "J. Alberto Conejero"], "summary": "Multimodal Large Language Models (MLLMs) promise advanced vision language\ncapabilities, yet their effectiveness in visually presented mathematics remains\nunderexplored. This paper analyzes the development and evaluation of MLLMs for\nmathematical problem solving, focusing on diagrams, multilingual text, and\nsymbolic notation. We then assess several models, including GPT 4o, Pixtral,\nQwen VL, Llama 3.2 Vision variants, and Gemini 2.0 Flash in a multilingual\nKangaroo style benchmark spanning English, French, Spanish, and Catalan. Our\nexperiments reveal four key findings. First, overall precision remains moderate\nacross geometry, visual algebra, logic, patterns, and combinatorics: no single\nmodel excels in every topic. Second, while most models see improved accuracy\nwith questions that do not have images, the gain is often limited; performance\nfor some remains nearly unchanged without visual input, indicating\nunderutilization of diagrammatic information. Third, substantial variation\nexists across languages and difficulty levels: models frequently handle easier\nitems but struggle with advanced geometry and combinatorial reasoning. Notably,\nGemini 2.0 Flash achieves the highest precision on image based tasks, followed\nby Qwen VL 2.5 72B and GPT 4o, though none approach human level performance.\nFourth, a complementary analysis aimed at distinguishing whether models reason\nor simply recite reveals that Gemini and GPT 4o stand out for their structured\nreasoning and consistent accuracy. In contrast, Pixtral and Llama exhibit less\nconsistent reasoning, often defaulting to heuristics or randomness when unable\nto align their outputs with the given answer options.", "comment": "16 pages, 4 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07418v1", "AI": {"title_translation": "评估多模态大语言模型中的视觉数学：一个基于袋鼠测试的多语言基准", "tldr": "论文评估了多模态大语言模型在视觉数学问题解决上的表现，发现现有模型在处理图像、多语言和复杂推理方面仍有不足，但Gemini和GPT 4o展现出更好的推理能力。", "motivation": "多模态大语言模型在视觉语言能力方面前景广阔，但它们在视觉呈现的数学方面的有效性仍未被充分探索。", "method": "论文分析了多模态大语言模型在数学问题解决方面的开发和评估，重点关注图表、多语言文本和符号表示。随后，评估了包括GPT 4o、Pixtral、Qwen VL、Llama 3.2 Vision变体和Gemini 2.0 Flash在内的多个模型，使用一个涵盖英语、法语、西班牙语和加泰罗尼亚语的多语言袋鼠风格基准。", "result": "1. 整体准确率在几何、视觉代数、逻辑、模式和组合学方面仍处于中等水平，没有单一模型在所有主题上表现出色。\n2. 大多数模型在没有图像的问题上准确率有所提高，但提升有限；一些模型在没有视觉输入的情况下性能几乎不变，表明对图表信息利用不足。\n3. 不同语言和难度级别之间存在显著差异：模型通常能处理较简单的项目，但在高级几何和组合推理方面表现不佳。Gemini 2.0 Flash在基于图像的任务上准确率最高，其次是Qwen VL 2.5 72B和GPT 4o，但都未达到人类水平。\n4. 一项旨在区分模型是推理还是简单复述的补充分析表明，Gemini和GPT 4o在结构化推理和一致性准确率方面表现突出。相比之下，Pixtral和Llama的推理一致性较差，在无法将其输出与给定答案选项对齐时，通常会采用启发式或随机方法。", "conclusion": "现有的多模态大语言模型在视觉数学问题解决方面仍有显著局限性，尤其是在处理复杂视觉信息和高级推理方面。尽管如此，Gemini和GPT 4o展现出更强的结构化推理能力，但所有模型都未能达到人类水平。", "translation": "多模态大型语言模型（MLLMs）有望提供先进的视觉语言能力，但它们在视觉呈现的数学方面的有效性仍未被充分探索。本文分析了MLLMs在数学问题解决方面的开发和评估，重点关注图表、多语言文本和符号表示。随后，我们使用一个涵盖英语、法语、西班牙语和加泰罗尼亚语的多语言袋鼠风格基准，评估了包括GPT 4o、Pixtral、Qwen VL、Llama 3.2 Vision变体和Gemini 2.0 Flash在内的多个模型。我们的实验揭示了四个关键发现。首先，在几何、视觉代数、逻辑、模式和组合学方面，整体准确率仍处于中等水平：没有单一模型在所有主题上表现出色。其次，虽然大多数模型在没有图像的问题上准确率有所提高，但提升通常有限；一些模型在没有视觉输入的情况下性能几乎不变，表明对图表信息利用不足。第三，不同语言和难度级别之间存在显著差异：模型通常能处理较简单的项目，但在高级几何和组合推理方面表现不佳。值得注意的是，Gemini 2.0 Flash在基于图像的任务上准确率最高，其次是Qwen VL 2.5 72B和GPT 4o，尽管都没有接近人类水平的性能。第四，一项旨在区分模型是推理还是简单复述的补充分析表明，Gemini和GPT 4o在结构化推理和一致性准确率方面表现突出。相比之下，Pixtral和Llama的推理一致性较差，在无法将其输出与给定答案选项对齐时，通常会采用启发式或随机方法。", "summary": "本文评估了多模态大语言模型在视觉数学问题解决中的表现，特别关注图表、多语言文本和符号。通过一项多语言袋鼠测试基准，研究发现现有模型在处理视觉数学问题时，尤其是在高级几何和组合推理方面，准确率仍处于中等水平，且对图表信息利用不足。尽管Gemini 2.0 Flash在图像任务上表现最佳，但所有模型都未达到人类水平。研究还指出，Gemini和GPT 4o展现出更强的结构化推理能力，而其他模型则可能依赖启发式或随机方法。", "keywords": "多模态大语言模型, 视觉数学, 基准测试, 推理, 袋鼠测试", "comments": "这篇论文对多模态大语言模型在视觉数学领域的应用进行了深入且多维度的评估，填补了该领域研究的空白。其创新之处在于构建了一个多语言、多难度级别的基准测试，并对模型的推理能力进行了细致区分。研究结果揭示了当前MLLMs在处理复杂视觉数学问题时的局限性，并强调了未来在图表信息利用和高级推理能力方面改进的重要性。特别是对模型“推理”而非“复述”的区分，为后续研究提供了有价值的洞察。"}}
{"id": "2506.06649", "title": "SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes", "authors": ["Yishan Shen", "Yuyang Ye", "Hui Xiong", "Yong Chen"], "summary": "Dynamic treatment regimes (DTRs) are critical to precision medicine,\noptimizing long-term outcomes through personalized, real-time decision-making\nin evolving clinical contexts, but require careful supervision for unsafe\ntreatment risks. Existing efforts rely primarily on clinician-prescribed gold\nstandards despite the absence of a known optimal strategy, and predominantly\nusing structured EHR data without extracting valuable insights from clinical\nnotes, limiting their reliability for treatment recommendations. In this work,\nwe introduce SAFER, a calibrated risk-aware tabular-language recommendation\nframework for DTR that integrates both structured EHR and clinical notes,\nenabling them to learn from each other, and addresses inherent label\nuncertainty by assuming ambiguous optimal treatment solution for deceased\npatients. Moreover, SAFER employs conformal prediction to provide statistical\nguarantees, ensuring safe treatment recommendations while filtering out\nuncertain predictions. Experiments on two publicly available sepsis datasets\ndemonstrate that SAFER outperforms state-of-the-art baselines across multiple\nrecommendation metrics and counterfactual mortality rate, while offering robust\nformal assurances. These findings underscore SAFER potential as a trustworthy\nand theoretically grounded solution for high-stakes DTR applications.", "comment": "Accepted by ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06649v1", "AI": {"title_translation": "SAFER：一种用于动态治疗方案的校准风险感知多模态推荐模型", "tldr": "SAFER是一个针对动态治疗方案的风险感知多模态推荐模型，它整合了结构化电子健康记录和临床笔记，利用共形预测提供安全且有统计学保证的治疗建议，并在败血症数据集上表现优于现有基线。", "motivation": "动态治疗方案（DTRs）在精准医疗中至关重要，但现有方法主要依赖临床医生设定的黄金标准，缺乏已知的最优策略，并且主要使用结构化电子健康记录数据，未能从临床笔记中提取有价值的信息，限制了治疗推荐的可靠性。", "method": "本文提出了SAFER，一个校准的风险感知表格-语言推荐框架，用于动态治疗方案。它整合了结构化电子健康记录和临床笔记，使它们能够相互学习，并通过假设已故患者的模糊最优治疗方案来解决固有的标签不确定性。此外，SAFER采用共形预测来提供统计学保证，确保安全的治疗推荐，同时过滤掉不确定的预测。", "result": "在两个公开可用的败血症数据集上的实验表明，SAFER在多项推荐指标和反事实死亡率方面均优于最先进的基线方法，同时提供了强大的形式保证。", "conclusion": "这些发现强调了SAFER作为高风险动态治疗方案应用中一个值得信赖且有理论基础的解决方案的潜力。", "translation": "动态治疗方案 (DTRs) 对精准医疗至关重要，通过在不断变化的临床环境中进行个性化、实时决策来优化长期结果，但需要仔细监督不安全的治疗风险。现有工作主要依赖临床医生规定的黄金标准，尽管没有已知的最优策略，并且主要使用结构化电子健康记录 (EHR) 数据，而没有从临床笔记中提取有价值的见解，这限制了其治疗建议的可靠性。在这项工作中，我们引入了 SAFER，一个校准的风险感知表格-语言 DTR 推荐框架，它整合了结构化 EHR 和临床笔记，使它们能够相互学习，并通过假设已故患者的模糊最优治疗方案来解决固有的标签不确定性。此外，SAFER 采用共形预测来提供统计学保证，确保安全的治疗建议，同时过滤掉不确定的预测。在两个公开可用的败血症数据集上的实验表明，SAFER 在多个推荐指标和反事实死亡率方面均优于最先进的基线，同时提供了强大的形式保证。这些发现强调了 SAFER 作为高风险 DTR 应用中值得信赖且具有理论基础的解决方案的潜力。", "summary": "本文介绍了一种名为 SAFER 的新型校准风险感知多模态推荐模型，专为动态治疗方案（DTRs）设计。针对现有 DTR 推荐系统在数据利用和风险管理上的局限性，SAFER 创新性地整合了结构化电子健康记录和临床笔记，并通过共形预测提供统计学保证，确保推荐的安全性。实验结果显示，SAFER 在败血症数据集上显著优于现有基线，证明了其在高风险临床决策中的可靠性和潜力。", "keywords": "动态治疗方案, 推荐系统, 风险感知, 多模态, 共形预测", "comments": "SAFER的创新之处在于其整合了多模态数据（结构化EHR和临床笔记）以及利用共形预测提供统计学保证，从而在精准医疗的动态治疗方案中提供了更安全、更可靠的推荐。其解决标签不确定性和提供形式保证的能力，使其在实际高风险临床应用中具有重要价值。"}}
{"id": "2506.06371", "title": "Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models", "authors": ["Panagiotis Koletsis", "Christos Panagiotopoulos", "Georgios Th. Papadopoulos", "Vasilis Efthymiou"], "summary": "Over the past few years, table interpretation tasks have made significant\nprogress due to their importance and the introduction of new technologies and\nbenchmarks in the field. This work experiments with a hybrid approach for\ndetecting relationships among columns of unlabeled tabular data, using a\nKnowledge Graph (KG) as a reference point, a task known as CPA. This approach\nleverages large language models (LLMs) while employing statistical analysis to\nreduce the search space of potential KG relations. The main modules of this\napproach for reducing the search space are domain and range constraints\ndetection, as well as relation co-appearance analysis. The experimental\nevaluation on two benchmark datasets provided by the SemTab challenge assesses\nthe influence of each module and the effectiveness of different\nstate-of-the-art LLMs at various levels of quantization. The experiments were\nperformed, as well as at different prompting techniques. The proposed\nmethodology, which is publicly available on github, proved to be competitive\nwith state-of-the-art approaches on these datasets.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06371v1", "AI": {"title_translation": "表格数据关系检测：结合统计分析与大型语言模型", "tldr": "本文提出一种混合方法，结合统计分析和大型语言模型，用于在无标签表格数据中检测列之间的关系，通过减少知识图谱关系搜索空间，在基准数据集上表现出竞争力。", "motivation": "表格解释任务的重要性及其进展，特别是无标签表格数据中列间关系检测（CPA）的挑战。", "method": "提出一种混合方法，结合大型语言模型（LLMs）和统计分析。统计分析用于减少知识图谱（KG）关系搜索空间，主要通过域和范围约束检测以及关系共现分析实现。", "result": "在SemTab挑战提供的两个基准数据集上进行了实验评估，验证了每个模块的影响以及不同量化级别和提示技术下最先进LLMs的有效性。所提出的方法与现有最先进方法相比具有竞争力。", "conclusion": "该混合方法在无标签表格数据的列间关系检测任务上表现出竞争力，证明了结合统计分析和LLMs的有效性。", "translation": "过去几年，表格解释任务由于其重要性以及该领域新技术和基准的引入而取得了显著进展。这项工作尝试了一种混合方法，用于检测无标签表格数据列之间的关系，使用知识图谱（KG）作为参考点，这项任务被称为CPA。该方法利用大型语言模型（LLMs），同时采用统计分析来减少潜在KG关系的搜索空间。该方法用于减少搜索空间的主要模块是域和范围约束检测，以及关系共现分析。在SemTab挑战提供的两个基准数据集上进行的实验评估，评估了每个模块的影响以及不同量化级别下各种最先进LLMs的有效性。实验还在不同的提示技术下进行。所提出的方法（已在github上公开）在这些数据集上证明与最先进的方法具有竞争力。", "summary": "本文提出一种结合统计分析和大型语言模型（LLMs）的混合方法，用于在无标签表格数据中检测列之间的关系（CPA任务）。该方法利用统计分析（包括域和范围约束检测以及关系共现分析）来有效减少知识图谱（KG）关系的搜索空间。在SemTab挑战的两个基准数据集上的实验表明，该方法在性能上与现有最先进方法具有竞争力，并评估了不同模块、LLMs量化级别和提示技术的影响。", "keywords": "表格数据, 关系检测, 统计分析, 大型语言模型, 知识图谱", "comments": "该论文通过结合统计分析和大型语言模型，为表格数据中的关系检测提供了一种新颖的混合方法，特别是在减少搜索空间方面表现出创新性。其在无标签数据上的应用具有实用价值，并在SOTA数据集上表现出竞争力，表明了其有效性和重要性。代码的公开性也促进了研究的复现和发展。"}}
{"id": "2506.06891", "title": "Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?", "authors": ["Paulius Sasnauskas", "Yiğit Yalın", "Goran Radanović"], "summary": "We study the corruption-robustness of in-context reinforcement learning\n(ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,\n2023). To address the challenge of reward poisoning attacks targeting the DPT,\nwe propose a novel adversarial training framework, called Adversarially Trained\nDecision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an\nattacker to minimize the true reward of the DPT by poisoning environment\nrewards, and a DPT model to infer optimal actions from the poisoned data. We\nevaluate the effectiveness of our approach against standard bandit algorithms,\nincluding robust baselines designed to handle reward contamination. Our results\nshow that the proposed method significantly outperforms these baselines in\nbandit settings, under a learned attacker. We additionally evaluate AT-DPT on\nan adaptive attacker, and observe similar results. Furthermore, we extend our\nevaluation to the MDP setting, confirming that the robustness observed in\nbandit scenarios generalizes to more complex environments.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06891v1", "AI": {"title_translation": "情境式强化学习能否从奖励中毒攻击中恢复？", "tldr": "本文研究了情境式强化学习（ICRL）对奖励中毒攻击的鲁棒性，并提出了对抗训练决策预训练Transformer（AT-DPT）框架，该框架在强盗机设置下显著优于现有基线，并且鲁棒性可推广到MDP环境。", "motivation": "研究情境式强化学习（ICRL），特别是决策预训练Transformer（DPT），在奖励中毒攻击下的腐败鲁棒性，并解决DPT面临的奖励中毒攻击挑战。", "method": "提出了一种新颖的对抗训练框架，称为对抗训练决策预训练Transformer（AT-DPT）。该方法同时训练一个攻击者通过毒害环境奖励来最小化DPT的真实奖励，并训练一个DPT模型从被毒害的数据中推断出最优行动。", "result": "所提出的AT-DPT方法在强盗机设置下，在学习型攻击者下，显著优于包括处理奖励污染的鲁棒基线在内的标准强盗机算法。在自适应攻击者下也观察到类似结果。此外，在MDP设置中的评估也证实了在强盗机场景中观察到的鲁棒性可以推广到更复杂的环境。", "conclusion": "AT-DPT框架能够有效地抵御奖励中毒攻击，并在多种环境中展现出优越的鲁棒性，显著优于现有基线。", "translation": "我们研究了情境式强化学习（ICRL）的腐败鲁棒性，重点关注决策预训练Transformer（DPT，Lee et al., 2023）。为了解决针对DPT的奖励中毒攻击的挑战，我们提出了一种新颖的对抗训练框架，称为对抗训练决策预训练Transformer（AT-DPT）。我们的方法同时训练一个攻击者，通过毒害环境奖励来最小化DPT的真实奖励，并训练一个DPT模型从被毒害的数据中推断出最优行动。我们评估了我们方法对抗标准强盗算法的有效性，包括旨在处理奖励污染的鲁棒基线。我们的结果表明，在学习型攻击者下，所提出的方法在强盗机设置中显著优于这些基线。我们还评估了AT-DPT对抗自适应攻击者的情况，并观察到类似的结果。此外，我们将评估扩展到MDP设置，证实了在强盗机场景中观察到的鲁棒性可以推广到更复杂的环境。", "summary": "本文研究了情境式强化学习（ICRL）在奖励中毒攻击下的鲁棒性，并提出了对抗训练决策预训练Transformer（AT-DPT）。AT-DPT通过同时训练攻击者和DPT模型来应对奖励中毒。实验结果表明，AT-DPT在强盗机和MDP设置中均显著优于现有基线，证明了其对奖励中毒攻击的有效性和泛化能力。", "keywords": "情境式强化学习, 奖励中毒攻击, 对抗训练, 决策预训练Transformer, 鲁棒性", "comments": "本文提出了一种新颖的对抗训练框架AT-DPT，以解决情境式强化学习（ICRL）中决策预训练Transformer（DPT）面临的奖励中毒攻击问题。其创新点在于同时训练攻击者和防御模型，这提供了一种主动应对奖励污染的机制。该研究的重要性在于提升了ICRL在对抗环境下的鲁棒性，对于确保AI系统在恶意环境中的可靠性具有实际意义。"}}
{"id": "2506.07924", "title": "Design and Implementation of a Peer-to-Peer Communication, Modular and Decentral YellowCube UUV", "authors": ["Zhizun Xu", "Baozhu Jia", "Weichao Shi"], "summary": "The underwater Unmanned Vehicles(UUVs) are pivot tools for offshore\nengineering and oceanographic research. Most existing UUVs do not facilitate\neasy integration of new or upgraded sensors. A solution to this problem is to\nhave a modular UUV system with changeable payload sections capable of carrying\ndifferent sensor to suite different missions. The design and implementation of\na modular and decentral UUV named YellowCube is presented in the paper. Instead\na centralised software architecture which is adopted by the other modular\nunderwater vehicles designs, a Peer-To-Peer(P2P) communication mechanism is\nimplemented among the UUV's modules. The experiments in the laboratory and sea\ntrials have been executed to verify the performances of the UUV.", "comment": null, "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07924v1", "AI": {"title_translation": "点对点通信、模块化和去中心化YellowCube UUV的设计与实现", "tldr": "本文介绍了一种名为YellowCube的模块化、去中心化UUV，它采用点对点（P2P）通信机制，解决了现有UUV传感器集成困难的问题。", "motivation": "现有的大多数水下无人航行器（UUV）难以集成新的或升级的传感器，这限制了它们适应不同任务的能力。因此，需要一个模块化UUV系统，能够轻松更换有效载荷部分以携带不同传感器。", "method": "本文设计并实现了一种名为YellowCube的模块化和去中心化UUV。与传统模块化水下航行器采用的集中式软件架构不同，YellowCube在其UUV模块之间实现了点对点（P2P）通信机制。", "result": "已在实验室和海上试验中进行了实验，以验证该UUV的性能。", "conclusion": "本文成功设计并实现了一种采用点对点通信机制的模块化、去中心化UUV (YellowCube)，并通过实验验证了其性能，解决了现有UUV传感器集成的问题。", "translation": "水下无人航行器（UUV）是海洋工程和海洋研究的关键工具。大多数现有UUV不便于新传感器或升级传感器的轻松集成。解决这个问题的一个方法是拥有一个模块化的UUV系统，该系统具有可更换的有效载荷部分，能够携带不同的传感器以适应不同的任务。本文介绍了名为YellowCube的模块化和去中心化UUV的设计与实现。与其他模块化水下航行器设计所采用的集中式软件架构不同，该UUV的模块之间实现了点对点（P2P）通信机制。已经在实验室和海上试验中进行了实验，以验证UUV的性能。", "summary": "本文提出并实现了一种名为YellowCube的新型模块化去中心化水下无人航行器（UUV），旨在解决现有UUV在集成新传感器方面的挑战。与传统模块化UUV采用集中式软件架构不同，YellowCube在其模块之间引入了点对点（P2P）通信机制，从而增强了系统的灵活性和适应性。该UUV的性能已通过实验室实验和海上试验得到验证。", "keywords": "UUV, 模块化, 去中心化, 点对点通信, YellowCube", "comments": "该论文的创新点在于为模块化UUV引入了点对点（P2P）通信机制，这与传统的集中式架构形成对比。这种方法有望提高UUV系统的鲁棒性、灵活性和传感器集成能力，对于海洋工程和研究领域具有重要意义。"}}
{"id": "2506.06962", "title": "AR-RAG: Autoregressive Retrieval Augmentation for Image Generation", "authors": ["Jingyuan Qi", "Zhiyang Xu", "Qifan Wang", "Lifu Huang"], "summary": "We introduce Autoregressive Retrieval Augmentation (AR-RAG), a novel paradigm\nthat enhances image generation by autoregressively incorporating knearest\nneighbor retrievals at the patch level. Unlike prior methods that perform a\nsingle, static retrieval before generation and condition the entire generation\non fixed reference images, AR-RAG performs context-aware retrievals at each\ngeneration step, using prior-generated patches as queries to retrieve and\nincorporate the most relevant patch-level visual references, enabling the model\nto respond to evolving generation needs while avoiding limitations (e.g.,\nover-copying, stylistic bias, etc.) prevalent in existing methods. To realize\nAR-RAG, we propose two parallel frameworks: (1) Distribution-Augmentation in\nDecoding (DAiD), a training-free plug-and-use decoding strategy that directly\nmerges the distribution of model-predicted patches with the distribution of\nretrieved patches, and (2) Feature-Augmentation in Decoding (FAiD), a\nparameter-efficient fine-tuning method that progressively smooths the features\nof retrieved patches via multi-scale convolution operations and leverages them\nto augment the image generation process. We validate the effectiveness of\nAR-RAG on widely adopted benchmarks, including Midjourney-30K, GenEval and\nDPG-Bench, demonstrating significant performance gains over state-of-the-art\nimage generation models.", "comment": "Image Generation, Retrieval Augmented Generation", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06962v1", "AI": {"title_translation": "AR-RAG：图像生成中的自回归检索增强", "tldr": "AR-RAG通过在图像生成过程中自回归地进行逐块检索增强，解决了现有方法的局限性，并提出了DAiD和FAiD两种实现框架，显著提升了图像生成性能。", "motivation": "现有图像生成方法在生成前只进行单一静态检索，导致过度复制和风格偏差等局限性。AR-RAG旨在通过在每个生成步骤执行上下文感知的检索来解决这些问题。", "method": "AR-RAG通过在补丁级别自回归地整合k近邻检索来增强图像生成。它使用先前生成的补丁作为查询，在每个生成步骤进行上下文感知的检索。提出了两种并行框架：1) 解码中的分布增强（DAiD），一种无需训练的即插即用解码策略，直接合并模型预测补丁和检索补丁的分布；2) 解码中的特征增强（FAiD），一种参数高效的微调方法，通过多尺度卷积操作平滑检索补丁的特征并增强图像生成过程。", "result": "AR-RAG在Midjourney-30K、GenEval和DPG-Bench等广泛采用的基准测试中，相对于最先进的图像生成模型展现出显著的性能提升。", "conclusion": "AR-RAG是一种新颖且有效的图像生成范式，通过自回归的、上下文感知的补丁级检索增强，克服了现有方法的局限性，从而提升了性能。", "translation": "我们引入了自回归检索增强（AR-RAG），这是一种新颖的范式，通过自回归地结合补丁级别的k近邻检索来增强图像生成。与之前在生成前执行单一、静态检索并将整个生成过程基于固定参考图像的方法不同，AR-RAG在每个生成步骤执行上下文感知的检索，使用先前生成的补丁作为查询来检索并合并最相关的补丁级视觉参考，使模型能够响应不断变化的生成需求，同时避免现有方法中普遍存在的局限性（例如，过度复制、风格偏差等）。为了实现AR-RAG，我们提出了两个并行框架：（1）解码中的分布增强（DAiD），这是一种无需训练的即插即用解码策略，直接将模型预测补丁的分布与检索到的补丁的分布合并；（2）解码中的特征增强（FAiD），这是一种参数高效的微调方法，通过多尺度卷积操作逐步平滑检索到的补丁的特征，并利用它们来增强图像生成过程。我们在广泛采用的基准测试（包括Midjourney-30K、GenEval和DPG-Bench）上验证了AR-RAG的有效性，证明了其相对于最先进的图像生成模型有显著的性能提升。", "summary": "AR-RAG是一种新颖的图像生成范式，通过在每个生成步骤自回归地进行上下文感知的补丁级k近邻检索来增强图像生成。它克服了现有方法中单一静态检索导致的过度复制和风格偏差等局限性。为实现AR-RAG，论文提出了两种并行框架：无需训练的DAiD（解码中的分布增强）和参数高效的FAiD（解码中的特征增强）。实验结果表明，AR-RAG在多个基准测试上显著优于现有最先进的图像生成模型。", "keywords": "图像生成, 检索增强, 自回归, 补丁级检索, k近邻", "comments": "AR-RAG的创新点在于其自回归和上下文感知的检索增强机制，这与现有方法中单一静态检索形成了鲜明对比，有效解决了过度复制和风格偏差等问题。DAiD和FAiD两种实现框架，特别是DAiD的无需训练特性，使其具有很好的实用性和通用性。该方法在多个基准测试上的显著性能提升，表明其在图像生成领域具有重要意义和应用潜力。"}}
{"id": "2506.07428", "title": "HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model", "authors": ["Yuling Wang", "Zihui Chen", "Pengfei Jiao", "Xiao Wang"], "summary": "Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the\nneed for tailored attacks to assess their robustness and ensure security.\nHowever, existing HGNN attacks often require complex retraining of parameters\nto generate specific perturbations for new scenarios. Recently, foundation\nmodels have opened new horizons for the generalization of graph neural networks\nby capturing shared semantics across various graph distributions. This leads us\nto ask:Can we design a foundation attack model for HGNNs that enables\ngeneralizable perturbations across different HGNNs, and quickly adapts to new\nheterogeneous graphs (HGs)? Empirical findings reveal that, despite significant\ndifferences in model design and parameter space, different HGNNs surprisingly\nshare common vulnerability patterns from a relation-aware perspective.\nTherefore, we explore how to design foundation HGNN attack criteria by mining\nshared attack units. In this paper, we propose a novel relation-wise\nheterogeneous graph foundation attack model, HeTa. We introduce a foundation\nsurrogate model to align heterogeneity and identify the importance of shared\nrelation-aware attack units. Building on this, we implement a serialized\nrelation-by-relation attack based on the identified relational weights. In this\nway, the perturbation can be transferred to various target HGNNs and easily\nfine-tuned for new HGs. Extensive experiments exhibit powerful attack\nperformances and generalizability of our method.", "comment": "Accepted by IJCAI 2025", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07428v1", "AI": {"title_translation": "HeTa: 关系感知异构图基础攻击模型", "tldr": "HeTa是一个针对异构图神经网络（HGNNs）的新型关系感知基础攻击模型，旨在解决现有攻击缺乏泛化性和适应性的问题，通过发现HGNNs共享的脆弱模式，实现可转移且易于微调的扰动。", "motivation": "异构图神经网络（HGNNs）易受攻击，但现有攻击通常需要复杂的参数再训练以适应新场景，缺乏泛化性。因此，需要设计一个针对HGNNs的基础攻击模型，使其能够生成可泛化的扰动，并快速适应新的异构图。", "method": "本文提出了一个新颖的关系感知异构图基础攻击模型HeTa。它引入了一个基础代理模型来对齐异构性并识别共享的关系感知攻击单元的重要性。在此基础上，HeTa根据识别出的关系权重实现了序列化的逐关系攻击，使得扰动可以转移到各种目标HGNNs并轻松地为新的异构图进行微调。", "result": "广泛的实验证明了HeTa方法强大的攻击性能和泛化能力。", "conclusion": "HeTa模型成功地为异构图神经网络提供了一种具有强大攻击性能和泛化能力的基础攻击方法，解决了现有攻击的局限性。", "translation": "异构图神经网络（HGNNs）易受攻击，这突显了需要量身定制的攻击来评估其鲁棒性并确保安全性。然而，现有的HGNN攻击通常需要复杂的参数再训练才能为新场景生成特定的扰动。最近，基础模型为图神经网络的泛化开辟了新视野，通过捕获各种图分布中的共享语义。这促使我们思考：我们能否为HGNNs设计一个基础攻击模型，使其能够在不同的HGNNs之间实现可泛化的扰动，并快速适应新的异构图（HGs）？实证研究表明，尽管模型设计和参数空间存在显著差异，但从关系感知的角度来看，不同的HGNNs出人意料地共享着共同的脆弱模式。因此，我们探索如何通过挖掘共享攻击单元来设计基础HGNN攻击标准。在本文中，我们提出了一种新颖的关系感知异构图基础攻击模型HeTa。我们引入了一个基础代理模型来对齐异构性并识别共享关系感知攻击单元的重要性。在此基础上，我们根据识别出的关系权重实现了一个序列化的逐关系攻击。通过这种方式，扰动可以转移到各种目标HGNNs，并轻松地为新的HGs进行微调。广泛的实验展示了我们方法强大的攻击性能和泛化能力。", "summary": "异构图神经网络（HGNNs）容易受到攻击，而现有攻击方法往往需要针对新场景进行复杂的参数再训练，缺乏泛化性。本文提出了一种新颖的关系感知异构图基础攻击模型HeTa，旨在为HGNNs设计一个能够生成可泛化扰动并快速适应新异构图的通用攻击框架。研究发现不同HGNNs在关系感知层面存在共享的脆弱模式。HeTa通过引入一个基础代理模型来识别共享关系感知攻击单元的重要性，并在此基础上实现逐关系攻击。实验结果表明，HeTa具有强大的攻击性能和良好的泛化能力，能够有效地攻击各种HGNNs并适应新的异构图。", "keywords": "异构图神经网络, 攻击模型, 基础模型, 泛化性, 关系感知", "comments": "HeTa的创新之处在于提出了一个针对异构图神经网络的基础攻击模型，解决了现有攻击泛化性差的问题。通过发现HGNNs之间共享的脆弱模式并采用关系感知的方法，HeTa实现了可转移和可微调的扰动生成，这对于评估HGNNs的鲁棒性和确保其安全性具有重要意义。"}}
{"id": "2506.06656", "title": "Rescaled Influence Functions: Accurate Data Attribution in High Dimension", "authors": ["Ittai Rubinstein", "Samuel B. Hopkins"], "summary": "How does the training data affect a model's behavior? This is the question we\nseek to answer with data attribution. The leading practical approaches to data\nattribution are based on influence functions (IF). IFs utilize a first-order\nTaylor approximation to efficiently predict the effect of removing a set of\nsamples from the training set without retraining the model, and are used in a\nwide variety of machine learning applications. However, especially in the\nhigh-dimensional regime (# params $\\geq \\Omega($# samples$)$), they are often\nimprecise and tend to underestimate the effect of sample removals, even for\nsimple models such as logistic regression. We present rescaled influence\nfunctions (RIF), a new tool for data attribution which can be used as a drop-in\nreplacement for influence functions, with little computational overhead but\nsignificant improvement in accuracy. We compare IF and RIF on a range of\nreal-world datasets, showing that RIFs offer significantly better predictions\nin practice, and present a theoretical analysis explaining this improvement.\nFinally, we present a simple class of data poisoning attacks that would fool\nIF-based detections but would be detected by RIF.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06656v1", "AI": {"title_translation": "重新缩放的影响函数：高维数据归因的精确方法", "tldr": "本文提出了重新缩放的影响函数（RIF），这是一种新的数据归因工具，在高维情况下比传统影响函数（IF）更准确，并且能够检测IF无法发现的数据投毒攻击。", "motivation": "数据归因旨在回答训练数据如何影响模型行为的问题。现有的主要实践方法基于影响函数（IF），但IF在高维场景下常常不精确，并倾向于低估样本移除的影响，即使对于逻辑回归等简单模型也是如此。", "method": "本文提出了重新缩放的影响函数（RIF），它可以作为影响函数的直接替代品，计算开销小但准确性显著提高。作者将IF和RIF在一系列真实世界数据集上进行了比较，并提供了理论分析来解释其改进。", "result": "重新缩放的影响函数（RIF）在实践中提供了显著更好的预测，并且能够检测到基于IF方法无法发现的数据投毒攻击。", "conclusion": "重新缩放的影响函数（RIF）是数据归因领域的一个重要进展，它在高维数据下提供了更高的准确性，并且能有效识别传统方法无法检测的恶意数据投毒攻击。", "translation": "训练数据如何影响模型的行为？这是我们希望通过数据归因来回答的问题。数据归因的主要实践方法基于影响函数（IF）。IF利用一阶泰勒近似来有效地预测从训练集中移除一组样本的影响，而无需重新训练模型，并广泛应用于各种机器学习应用中。然而，特别是在高维（参数数量 ≥ 样本数量）的情况下，它们通常不精确，并且倾向于低估样本移除的影响，即使对于逻辑回归等简单模型也是如此。我们提出了重新缩放的影响函数（RIF），这是一种新的数据归因工具，可以作为影响函数的直接替代品，计算开销小但准确性显著提高。我们将IF和RIF在一系列真实世界数据集上进行了比较，表明RIF在实践中提供了显著更好的预测，并提出了解释这种改进的理论分析。最后，我们提出了一类简单的数据投毒攻击，这些攻击会欺骗基于IF的检测，但会被RIF检测到。", "summary": "本文针对高维数据归因中传统影响函数（IF）精度不足的问题，提出了一种新的工具——重新缩放的影响函数（RIF）。RIF作为IF的直接替代品，计算开销小，但能显著提高数据归因的准确性。实验结果表明，RIF在真实世界数据集上表现出更优的预测能力，并且能有效检测出IF无法识别的数据投毒攻击。文章还提供了理论分析来解释RIF的改进。", "keywords": "影响函数, 数据归因, 高维, 重新缩放影响函数, 数据投毒", "comments": "该论文提出了一种改进的数据归因方法RIF，解决了传统影响函数在高维数据下精度不足的问题。其创新点在于通过重新缩放提高了归因的准确性，并且能够识别更复杂的投毒攻击，这对于模型可解释性和安全性都具有重要意义。RIF作为IF的直接替代品，易于集成，具有较高的实用价值。"}}
{"id": "2506.06373", "title": "El0ps: An Exact L0-regularized Problems Solver", "authors": ["Théo Guyard", "Cédric Herzet", "Clément Elvira"], "summary": "This paper presents El0ps, a Python toolbox providing several utilities to\nhandle L0-regularized problems related to applications in machine learning,\nstatistics, and signal processing, among other fields. In contrast to existing\ntoolboxes, El0ps allows users to define custom instances of these problems\nthrough a flexible framework, provides a dedicated solver achieving\nstate-of-the-art performance, and offers several built-in machine learning\npipelines. Our aim with El0ps is to provide a comprehensive tool which opens\nnew perspectives for the integration of L0-regularized problems in practical\napplications.", "comment": null, "cate": "cs.MS", "url": "http://arxiv.org/abs/2506.06373v1", "AI": {"title_translation": "El0ps：一个精确的L0正则化问题求解器", "tldr": "El0ps是一个Python工具箱，用于解决机器学习、统计和信号处理中的L0正则化问题，提供灵活的自定义框架、最先进的求解器和内置机器学习管道。", "motivation": "本文旨在解决现有工具箱在处理L0正则化问题时的不足，并为L0正则化问题在机器学习、统计和信号处理等实际应用中的集成提供一个全面的工具。", "method": "本文提出了El0ps，一个Python工具箱，它提供了处理L0正则化问题的实用程序。El0ps允许用户通过灵活的框架定义这些问题的自定义实例，提供了一个实现最先进性能的专用求解器，并提供了几个内置的机器学习管道。", "result": "El0ps提供了一个灵活的框架，允许用户定义L0正则化问题的自定义实例；提供了一个实现最先进性能的专用求解器；并提供了几个内置的机器学习管道。", "conclusion": "El0ps旨在提供一个全面的工具，为L0正则化问题在实际应用中的集成开辟新视角。", "translation": "本文介绍了El0ps，一个Python工具箱，它提供了几个实用程序来处理与机器学习、统计学和信号处理等领域应用相关的L0正则化问题。与现有工具箱不同，El0ps允许用户通过灵活的框架定义这些问题的自定义实例，提供了一个实现最先进性能的专用求解器，并提供了几个内置的机器学习管道。我们开发El0ps的目的是提供一个全面的工具，为L0正则化问题在实际应用中的集成开辟新视角。", "summary": "本文介绍了El0ps，一个针对机器学习、统计和信号处理中L0正则化问题的Python工具箱。El0ps通过提供灵活的框架支持自定义问题定义，集成了一个达到最先进性能的专用求解器，并包含多种内置机器学习管道，旨在为L0正则化问题在实际应用中的集成提供一个全面的解决方案。", "keywords": "L0正则化, Python工具箱, 机器学习, 信号处理, 最先进性能", "comments": "El0ps的创新之处在于其提供了自定义L0正则化问题实例的灵活性，以及一个实现最先进性能的专用求解器，这对于L0正则化问题在实际应用中的推广和集成具有重要意义。"}}
{"id": "2506.07961", "title": "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models", "authors": ["Peiyan Li", "Yixiang Chen", "Hongtao Wu", "Xiao Ma", "Xiangnan Wu", "Yan Huang", "Liang Wang", "Tao Kong", "Tieniu Tan"], "summary": "Recently, leveraging pre-trained vision-language models (VLMs) for building\nvision-language-action (VLA) models has emerged as a promising approach to\neffective robot manipulation learning. However, only few methods incorporate 3D\nsignals into VLMs for action prediction, and they do not fully leverage the\nspatial structure inherent in 3D data, leading to low sample efficiency. In\nthis paper, we introduce BridgeVLA, a novel 3D VLA model that (1) projects 3D\ninputs to multiple 2D images, ensuring input alignment with the VLM backbone,\nand (2) utilizes 2D heatmaps for action prediction, unifying the input and\noutput spaces within a consistent 2D image space. In addition, we propose a\nscalable pre-training method that equips the VLM backbone with the capability\nto predict 2D heatmaps before downstream policy learning. Extensive experiments\nshow the proposed method is able to learn 3D manipulation efficiently and\neffectively. BridgeVLA outperforms state-of-the-art baseline methods across\nthree simulation benchmarks. In RLBench, it improves the average success rate\nfrom 81.4% to 88.2%. In COLOSSEUM, it demonstrates significantly better\nperformance in challenging generalization settings, boosting the average\nsuccess rate from 56.7% to 64.0%. In GemBench, it surpasses all the comparing\nbaseline methods in terms of average success rate. In real-robot experiments,\nBridgeVLA outperforms a state-of-the-art baseline method by 32% on average. It\ngeneralizes robustly in multiple out-of-distribution settings, including visual\ndisturbances and unseen instructions. Remarkably, it is able to achieve a\nsuccess rate of 96.8% on 10+ tasks with only 3 trajectories per task,\nhighlighting its extraordinary sample efficiency. Project\nWebsite:https://bridgevla.github.io/", "comment": "In Submission", "cate": "cs.RO", "url": "http://arxiv.org/abs/2506.07961v1", "AI": {"title_translation": "BridgeVLA：面向高效3D操作学习的视觉-语言模型输入-输出对齐", "tldr": "BridgeVLA通过创新的输入-输出对齐方法，显著提高了机器人3D操作学习的样本效率和成功率。", "motivation": "现有将3D信号整合到视觉-语言模型（VLMs）中进行动作预测的方法未能充分利用3D数据的空间结构，导致样本效率低下。", "method": "BridgeVLA是一种新颖的3D视觉-语言-动作（VLA）模型，它通过以下方式实现：1) 将3D输入投影到多个2D图像，确保与VLM骨干的输入对齐。2) 利用2D热图进行动作预测，统一输入和输出空间到一致的2D图像空间。3) 提出可扩展的预训练方法，使VLM骨干在下游策略学习前具备预测2D热图的能力。", "result": "BridgeVLA在三个模拟基准测试中均优于最先进的基线方法：在RLBench中，平均成功率从81.4%提高到88.2%；在COLOSSEUM中，在挑战性泛化设置下，平均成功率从56.7%提升至64.0%；在GemBench中，超越所有比较的基线方法。在真实机器人实验中，平均性能优于最先进基线方法32%，并在多种分布外设置中展现鲁棒泛化能力。在10+任务上，仅需每任务3条轨迹即可达到96.8%的成功率，展现出非凡的样本效率。", "conclusion": "BridgeVLA能够高效且有效地学习3D操作，并在多个模拟和真实机器人基准测试中优于现有方法，展现出卓越的样本效率和泛化能力。", "translation": "BridgeVLA：面向高效3D操作学习的视觉-语言模型输入-输出对齐\n\n近年来，利用预训练视觉-语言模型（VLMs）构建视觉-语言-动作（VLA）模型已成为有效机器人操作学习的一种有前景的方法。然而，很少有方法将3D信号整合到VLM中进行动作预测，并且它们未能充分利用3D数据固有的空间结构，导致样本效率低下。在本文中，我们引入了BridgeVLA，这是一种新颖的3D VLA模型，它（1）将3D输入投影到多个2D图像，确保与VLM骨干的输入对齐，以及（2）利用2D热图进行动作预测，统一输入和输出空间到一致的2D图像空间。此外，我们提出了一种可扩展的预训练方法，使VLM骨干在下游策略学习之前具备预测2D热图的能力。广泛的实验表明，所提出的方法能够高效且有效地学习3D操作。BridgeVLA在三个模拟基准测试中均优于最先进的基线方法。在RLBench中，它将平均成功率从81.4%提高到88.2%。在COLOSSEUM中，它在具有挑战性的泛化设置中表现出显著更好的性能，将平均成功率从56.7%提高到64.0%。在GemBench中，它在平均成功率方面超越了所有比较的基线方法。在真实机器人实验中，BridgeVLA平均优于一种最先进的基线方法32%。它在多种分布外设置（包括视觉干扰和未见过指令）中稳健泛化。值得注意的是，它能够在10多个任务上仅用每任务3条轨迹就达到96.8%的成功率，突显了其非凡的样本效率。项目网站：https://bridgevla.github.io/", "summary": "本文提出了BridgeVLA，一个新颖的3D视觉-语言-动作模型，旨在解决现有方法在机器人3D操作学习中3D数据利用不足和样本效率低下的问题。BridgeVLA通过将3D输入转换为2D图像并使用2D热图进行动作预测，实现了与视觉-语言模型骨干的输入-输出对齐。此外，它引入了一种可扩展的预训练方法。实验证明，BridgeVLA在模拟和真实机器人任务中均显著提高了学习效率和成功率，尤其在样本效率和泛化能力方面表现出色。", "keywords": "3D操作, 视觉-语言模型, 输入-输出对齐, 样本效率, 机器人学习", "comments": "BridgeVLA的创新之处在于其独特的输入-输出对齐策略，通过将3D数据有效转换为2D表示，使其能够充分利用现有VLMs的强大能力，同时解决了3D空间结构利用不足的问题。其预训练方法也增强了模型的通用性。卓越的样本效率是其重要亮点，对于实际机器人部署具有巨大潜力，因为它大大减少了数据收集的需求。"}}
{"id": "2506.06966", "title": "Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition", "authors": ["Siyuan Jing", "Guangxue Wang", "Haoyang Zhai", "Qin Tao", "Jun Yang", "Bing Wang", "Peng Jin"], "summary": "Due to the emergence of many sign language datasets, isolated sign language\nrecognition (ISLR) has made significant progress in recent years. In addition,\nthe development of various advanced deep neural networks is another reason for\nthis breakthrough. However, challenges remain in applying the technique in the\nreal world. First, existing sign language datasets do not cover the whole sign\nvocabulary. Second, most of the sign language datasets provide only single view\nRGB videos, which makes it difficult to handle hand occlusions when performing\nISLR. To fill this gap, this paper presents a dual-view sign language dataset\nfor ISLR named NationalCSL-DP, which fully covers the Chinese national sign\nlanguage vocabulary. The dataset consists of 134140 sign videos recorded by ten\nsigners with respect to two vertical views, namely, the front side and the left\nside. Furthermore, a CNN transformer network is also proposed as a strong\nbaseline and an extremely simple but effective fusion strategy for prediction.\nExtensive experiments were conducted to prove the effectiveness of the datasets\nas well as the baseline. The results show that the proposed fusion strategy can\nsignificantly increase the performance of the ISLR, but it is not easy for the\nsequence-to-sequence model, regardless of whether the early-fusion or\nlate-fusion strategy is applied, to learn the complementary features from the\nsign videos of two vertical views.", "comment": "18 pages, 3 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06966v1", "AI": {"title_translation": "双视角时空特征融合与CNN-Transformer混合网络在中文孤立手语识别中的应用", "tldr": "本文提出了一个双视角中文手语数据集（NationalCSL-DP）和一个结合CNN-Transformer的混合网络，并采用了一种有效的特征融合策略，显著提升了孤立手语识别性能，尽管从多视角数据中学习互补特征仍具挑战。", "motivation": "现有手语数据集未涵盖全部手语词汇，且大多只提供单视角RGB视频，导致在孤立手语识别（ISLR）中难以处理手部遮挡问题。", "method": "本文提出了一个名为NationalCSL-DP的双视角手语数据集，该数据集完全涵盖了中国国家手语词汇，包含134140个由十名手语者在正面和左侧两个垂直视角下录制的视频。此外，还提出了一个CNN-Transformer混合网络作为基线模型，并设计了一种简单但有效的预测融合策略。", "result": "所提出的融合策略能显著提高孤立手语识别（ISLR）的性能。然而，对于序列到序列模型而言，无论采用早期融合还是后期融合策略，从两个垂直视角的手语视频中学习互补特征并非易事。", "conclusion": "本文通过引入一个全面的双视角数据集和一种有效的融合策略，成功解决了孤立手语识别中的现有局限性，尽管对于序列到序列模型而言，从多视角数据中学习互补特征仍然是一个挑战。", "translation": "由于许多手语数据集的出现，孤立手语识别（ISLR）近年来取得了显著进展。此外，各种先进深度神经网络的发展是这一突破的另一个原因。然而，将该技术应用于现实世界仍面临挑战。首先，现有手语数据集并未涵盖全部手语词汇。其次，大多数手语数据集仅提供单视角RGB视频，这使得在执行ISLR时难以处理手部遮挡问题。为了弥补这一空白，本文提出了一个用于ISLR的双视角手语数据集，名为NationalCSL-DP，该数据集完全涵盖了中国国家手语词汇。该数据集包含由十名手语者录制的134140个手语视频，涉及两个垂直视角，即正面和左侧。此外，还提出了一种CNN-Transformer网络作为强大的基线，以及一种极其简单但有效的预测融合策略。进行了大量实验以证明数据集和基线的有效性。结果表明，所提出的融合策略可以显著提高ISLR的性能，但对于序列到序列模型来说，无论采用早期融合还是后期融合策略，从两个垂直视角的手语视频中学习互补特征并非易事。", "summary": "本文针对孤立手语识别（ISLR）中词汇覆盖不全和单视角数据导致手部遮挡的问题，提出了一个名为NationalCSL-DP的新型双视角中文手语数据集，该数据集涵盖了完整的中文手语词汇。同时，论文还提出了一个结合CNN和Transformer的混合网络，并设计了一种有效的特征融合策略。实验结果表明，该融合策略显著提升了ISLR的性能，但从双视角数据中学习互补特征对于序列到序列模型而言仍是一个挑战。", "keywords": "孤立手语识别, 双视角数据集, CNN-Transformer, 特征融合, 中文手语", "comments": "该论文通过引入双视角数据集NationalCSL-DP，创新性地解决了中文孤立手语识别中词汇覆盖有限和单视角数据导致遮挡的关键问题。提出的CNN-Transformer混合网络和简单有效的融合策略为该领域提供了强大的基线并显著提升了性能。然而，它也指出了序列到序列模型在有效学习多视角数据互补特征方面仍面临的挑战，这为未来的研究指明了方向。"}}
{"id": "2506.07443", "title": "LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning", "authors": ["Weijie Shi", "Han Zhu", "Jiaming Ji", "Mengze Li", "Jipeng Zhang", "Ruiyuan Zhang", "Jia Zhu", "Jiajie Xu", "Sirui Han", "Yike Guo"], "summary": "Legal judgment prediction (LJP) aims to function as a judge by making final\nrulings based on case claims and facts, which plays a vital role in the\njudicial domain for supporting court decision-making and improving judicial\nefficiency. However, existing methods often struggle with logical errors when\nconducting complex legal reasoning. We propose LegalReasoner, which enhances\nLJP reliability through step-wise verification and correction of the reasoning\nprocess. Specifically, it first identifies dispute points to decompose complex\ncases, and then conducts step-wise reasoning while employing a process verifier\nto validate each step's logic from correctness, progressiveness, and potential\nperspectives. When errors are detected, expert-designed attribution and\nresolution strategies are applied for correction. To fine-tune LegalReasoner,\nwe release the LegalHK dataset, containing 58,130 Hong Kong court cases with\ndetailed annotations of dispute points, step-by-step reasoning chains, and\nprocess verification labels. Experiments demonstrate that LegalReasoner\nsignificantly improves concordance with court decisions from 72.37 to 80.27 on\nLLAMA-3.1-70B. The data is available at\nhttps://huggingface.co/datasets/weijiezz/LegalHK.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07443v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06665", "title": "SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming", "authors": ["Hong-Ming Chiu", "Hao Chen", "Huan Zhang", "Richard Y. Zhang"], "summary": "Neural network verifiers based on linear bound propagation scale impressively\nto massive models but can be surprisingly loose when neuron coupling is\ncrucial. Conversely, semidefinite programming (SDP) verifiers capture\ninter-neuron coupling naturally, but their cubic complexity restricts them to\nonly small models. In this paper, we propose SDP-CROWN, a novel hybrid\nverification framework that combines the tightness of SDP relaxations with the\nscalability of bound-propagation verifiers. At the core of SDP-CROWN is a new\nlinear bound, derived via SDP principles, that explicitly captures\n$\\ell_{2}$-norm-based inter-neuron coupling while adding only one extra\nparameter per layer. This bound can be integrated seamlessly into any linear\nbound-propagation pipeline, preserving the inherent scalability of such methods\nyet significantly improving tightness. In theory, we prove that our\ninter-neuron bound can be up to a factor of $\\sqrt{n}$ tighter than traditional\nper-neuron bounds. In practice, when incorporated into the state-of-the-art\n$\\alpha$-CROWN verifier, we observe markedly improved verification performance\non large models with up to 65 thousand neurons and 2.47 million parameters,\nachieving tightness that approaches that of costly SDP-based methods.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06665v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06374", "title": "Structured State Space Model Dynamics and Parametrization for Spiking Neural Networks", "authors": ["Maxime Fabre", "Lyubov Dudchenko", "Emre Neftci"], "summary": "Multi-state spiking neurons such as the adaptive leaky integrate-and-fire\n(AdLIF) neuron offer compelling alternatives to conventional deep learning\nmodels thanks to their sparse binary activations, second-order nonlinear\nrecurrent dynamics, and efficient hardware realizations. However, such internal\ndynamics can cause instabilities during inference and training, often limiting\nperformance and scalability. Meanwhile, state space models (SSMs) excel in long\nsequence processing using linear state-intrinsic recurrence resembling spiking\nneurons' subthreshold regime. Here, we establish a mathematical bridge between\nSSMs and second-order spiking neuron models. Based on structure and\nparametrization strategies of diagonal SSMs, we propose two novel spiking\nneuron models. The first extends the AdLIF neuron through timestep training and\nlogarithmic reparametrization to facilitate training and improve final\nperformance. The second additionally brings initialization and structure from\ncomplex-state SSMs, broadening the dynamical regime to oscillatory dynamics.\nTogether, our two models achieve beyond or near state-of-the-art (SOTA)\nperformances for reset-based spiking neuron models across both event-based and\nraw audio speech recognition datasets. We achieve this with a favorable number\nof parameters and required dynamic memory while maintaining high activity\nsparsity. Our models demonstrate enhanced scalability in network size and\nstrike a favorable balance between performance and efficiency with respect to\nSSM models.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06374v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06933", "title": "Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry", "authors": ["Mahdi Salmani", "Alireza Abdollahpoorrostam", "Seyed-Mohsen Moosavi-Dezfooli"], "summary": "Traditional decision-based black-box adversarial attacks on image classifiers\naim to generate adversarial examples by slightly modifying input images while\nkeeping the number of queries low, where each query involves sending an input\nto the model and observing its output. Most existing methods assume that all\nqueries have equal cost. However, in practice, queries may incur asymmetric\ncosts; for example, in content moderation systems, certain output classes may\ntrigger additional review, enforcement, or penalties, making them more costly\nthan others. While prior work has considered such asymmetric cost settings,\neffective algorithms for this scenario remain underdeveloped. In this paper, we\npropose a general framework for decision-based attacks under asymmetric query\ncosts, which we refer to as asymmetric black-box attacks. We modify two core\ncomponents of existing attacks: the search strategy and the gradient estimation\nprocess. Specifically, we propose Asymmetric Search (AS), a more conservative\nvariant of binary search that reduces reliance on high-cost queries, and\nAsymmetric Gradient Estimation (AGREST), which shifts the sampling distribution\nto favor low-cost queries. We design efficient algorithms that minimize total\nattack cost by balancing different query types, in contrast to earlier methods\nsuch as stealthy attacks that focus only on limiting expensive (high-cost)\nqueries. Our method can be integrated into a range of existing black-box\nattacks with minimal changes. We perform both theoretical analysis and\nempirical evaluation on standard image classification benchmarks. Across\nvarious cost regimes, our method consistently achieves lower total query cost\nand smaller perturbations than existing approaches, with improvements of up to\n40% in some settings.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06933v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06970", "title": "Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment", "authors": ["Pengfei Zhao", "Rongbo Luan", "Wei Zhang", "Peng Wu", "Sifeng He"], "summary": "Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability\nto retrieve content across modalities, a substantial modality gap persists in\nits feature space. Intriguingly, we discover that off-the-shelf MLLMs\n(Multimodal Large Language Models) demonstrate powerful inherent modality\nalignment properties. While recent MLLM-based retrievers with unified\narchitectures partially mitigate this gap, their reliance on coarse modality\nalignment mechanisms fundamentally limits their potential. In this work, We\nintroduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel\nframework that leverages the fine grained alignment priors inherent in MLLM to\nguide cross modal representation learning. MAPLE formulates the learning\nprocess as reinforcement learning with two key components: (1) Automatic\npreference data construction using off-the-shelf MLLM, and (2) a new Relative\nPreference Alignment (RPA) loss, which adapts Direct Preference Optimization\n(DPO) to the embedding learning setting. Experimental results show that our\npreference-guided alignment achieves substantial gains in fine-grained\ncross-modal retrieval, underscoring its effectiveness in handling nuanced\nsemantic distinctions.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06970v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07446", "title": "Fact in Fragments: Deconstructing Complex Claims via LLM-based Atomic Fact Extraction and Verification", "authors": ["Liwen Zheng", "Chaozhuo Li", "Zheng Liu", "Feiran Huang", "Haoran Jia", "Zaisheng Ye", "Xi Zhang"], "summary": "Fact verification plays a vital role in combating misinformation by assessing\nthe veracity of claims through evidence retrieval and reasoning. However,\ntraditional methods struggle with complex claims requiring multi-hop reasoning\nover fragmented evidence, as they often rely on static decomposition strategies\nand surface-level semantic retrieval, which fail to capture the nuanced\nstructure and intent of the claim. This results in accumulated reasoning\nerrors, noisy evidence contamination, and limited adaptability to diverse\nclaims, ultimately undermining verification accuracy in complex scenarios. To\naddress this, we propose Atomic Fact Extraction and Verification (AFEV), a\nnovel framework that iteratively decomposes complex claims into atomic facts,\nenabling fine-grained retrieval and adaptive reasoning. AFEV dynamically\nrefines claim understanding and reduces error propagation through iterative\nfact extraction, reranks evidence to filter noise, and leverages\ncontext-specific demonstrations to guide the reasoning process. Extensive\nexperiments on five benchmark datasets demonstrate that AFEV achieves\nstate-of-the-art performance in both accuracy and interpretability.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07446v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06666", "title": "Through the Gaps: Uncovering Tactical Line-Breaking Passes with Clustering", "authors": ["Oktay Karakuş", "Hasan Arkadaş"], "summary": "Line-breaking passes (LBPs) are crucial tactical actions in football,\nallowing teams to penetrate defensive lines and access high-value spaces. In\nthis study, we present an unsupervised, clustering-based framework for\ndetecting and analysing LBPs using synchronised event and tracking data from\nelite matches. Our approach models opponent team shape through vertical spatial\nsegmentation and identifies passes that disrupt defensive lines within open\nplay. Beyond detection, we introduce several tactical metrics, including the\nspace build-up ratio (SBR) and two chain-based variants, LBPCh$^1$ and\nLBPCh$^2$, which quantify the effectiveness of LBPs in generating immediate or\nsustained attacking threats. We evaluate these metrics across teams and players\nin the 2022 FIFA World Cup, revealing stylistic differences in vertical\nprogression and structural disruption. The proposed methodology is explainable,\nscalable, and directly applicable to modern performance analysis and scouting\nworkflows.", "comment": "12 pages and 5 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06666v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06376", "title": "Enhancing Decision-Making of Large Language Models via Actor-Critic", "authors": ["Heng Dong", "Kefei Duan", "Chongjie Zhang"], "summary": "Large Language Models (LLMs) have achieved remarkable advancements in natural\nlanguage processing tasks, yet they encounter challenges in complex\ndecision-making scenarios that require long-term reasoning and alignment with\nhigh-level objectives. Existing methods either rely on short-term\nauto-regressive action generation or face limitations in accurately simulating\nrollouts and assessing outcomes, leading to sub-optimal decisions. This paper\nintroduces a novel LLM-based Actor-Critic framework, termed LAC, that\neffectively improves LLM policies with long-term action evaluations in a\nprincipled and scalable way. Our approach addresses two key challenges: (1)\nextracting robust action evaluations by computing Q-values via token logits\nassociated with positive/negative outcomes, enhanced by future trajectory\nrollouts and reasoning; and (2) enabling efficient policy improvement through a\ngradient-free mechanism. Experiments across diverse environments -- including\nhigh-level decision-making (ALFWorld), low-level action spaces (BabyAI-Text),\nand large action spaces (WebShop) -- demonstrate the framework's generality and\nsuperiority over state-of-the-art methods. Notably, our approach achieves\ncompetitive performance using 7B/8B parameter LLMs, even outperforming baseline\nmethods employing GPT-4 in complex tasks. These results underscore the\npotential of integrating structured policy optimization with LLMs' intrinsic\nknowledge to advance decision-making capabilities in multi-step environments.", "comment": "Forty-second International Conference on Machine Learning (ICML 2025)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06376v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06971", "title": "Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation", "authors": ["Jaechul Roh", "Varun Gandhi", "Shivani Anilkumar", "Arin Garg"], "summary": "Large Language Models (LLMs) have achieved remarkable success in tasks\nrequiring complex reasoning, such as code generation, mathematical problem\nsolving, and algorithmic synthesis -- especially when aided by reasoning tokens\nand Chain-of-Thought prompting. Yet, a core question remains: do these models\ntruly reason, or do they merely exploit shallow statistical patterns? In this\npaper, we systematically investigate the robustness of reasoning LLMs by\nintroducing a suite of semantically faithful yet adversarially structured\nprompt perturbations. Our evaluation -- spanning 700 perturbed code generations\nderived from LeetCode-style problems -- applies transformations such as\nstorytelling reframing, irrelevant constraint injection, example reordering,\nand numeric perturbation. We observe that while certain modifications severely\ndegrade performance (with accuracy drops up to -42.1%), others surprisingly\nimprove model accuracy by up to 35.3%, suggesting sensitivity not only to\nsemantics but also to surface-level prompt dynamics. These findings expose the\nfragility and unpredictability of current reasoning systems, underscoring the\nneed for more principles approaches to reasoning alignments and prompting\nrobustness. We release our perturbation datasets and evaluation framework to\npromote further research in trustworthy and resilient LLM reasoning.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06971v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06988", "title": "Hybrid Mesh-Gaussian Representation for Efficient Indoor Scene Reconstruction", "authors": ["Binxiao Huang", "Zhihao Li", "Shiyong Liu", "Xiao Tang", "Jiajun Tang", "Jiaqi Lin", "Yuxin Cheng", "Zhenyu Chen", "Xiaofei Wu", "Ngai Wong"], "summary": "3D Gaussian splatting (3DGS) has demonstrated exceptional performance in\nimage-based 3D reconstruction and real-time rendering. However, regions with\ncomplex textures require numerous Gaussians to capture significant color\nvariations accurately, leading to inefficiencies in rendering speed. To address\nthis challenge, we introduce a hybrid representation for indoor scenes that\ncombines 3DGS with textured meshes. Our approach uses textured meshes to handle\ntexture-rich flat areas, while retaining Gaussians to model intricate\ngeometries. The proposed method begins by pruning and refining the extracted\nmesh to eliminate geometrically complex regions. We then employ a joint\noptimization for 3DGS and mesh, incorporating a warm-up strategy and\ntransmittance-aware supervision to balance their contributions\nseamlessly.Extensive experiments demonstrate that the hybrid representation\nmaintains comparable rendering quality and achieves superior frames per second\nFPS with fewer Gaussian primitives.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06988v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07450", "title": "Efficient Generation of Diverse Cooperative Agents with World Models", "authors": ["Yi Loo", "Akshunn Trivedi", "Malika Meghjani"], "summary": "A major bottleneck in the training process for Zero-Shot Coordination (ZSC)\nagents is the generation of partner agents that are diverse in collaborative\nconventions. Current Cross-play Minimization (XPM) methods for population\ngeneration can be very computationally expensive and sample inefficient as the\ntraining objective requires sampling multiple types of trajectories. Each\npartner agent in the population is also trained from scratch, despite all of\nthe partners in the population learning policies of the same coordination task.\nIn this work, we propose that simulated trajectories from the dynamics model of\nan environment can drastically speed up the training process for XPM methods.\nWe introduce XPM-WM, a framework for generating simulated trajectories for XPM\nvia a learned World Model (WM). We show XPM with simulated trajectories removes\nthe need to sample multiple trajectories. In addition, we show our proposed\nmethod can effectively generate partners with diverse conventions that match\nthe performance of previous methods in terms of SP population training reward\nas well as training partners for ZSC agents. Our method is thus, significantly\nmore sample efficient and scalable to a larger number of partners.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07450v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06682", "title": "Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics", "authors": ["Di Lin", "Wanjing Ren", "Xuanbin Li", "Rui Zhang"], "summary": "In graph self-supervised learning, masked autoencoders (MAE) and contrastive\nlearning (CL) are two prominent paradigms. MAE focuses on reconstructing masked\nelements, while CL maximizes similarity between augmented graph views. Recent\nstudies highlight their complementarity: MAE excels at local feature capture,\nand CL at global information extraction. Hybrid frameworks for homogeneous\ngraphs have been proposed, but face challenges in designing shared encoders to\nmeet the semantic requirements of both tasks. In semantically sparse scenarios,\nCL struggles with view construction, and gradient imbalance between positive\nand negative samples persists. This paper introduces HetCRF, a novel\ndual-channel self-supervised learning framework for heterogeneous graphs.\nHetCRF uses a two-stage aggregation strategy to adapt embedding semantics,\nmaking it compatible with both MAE and CL. To address semantic sparsity, it\nenhances encoder output for view construction instead of relying on raw\nfeatures, improving efficiency. Two positive sample augmentation strategies are\nalso proposed to balance gradient contributions. Node classification\nexperiments on four real-world heterogeneous graph datasets demonstrate that\nHetCRF outperforms state-of-the-art baselines. On datasets with missing node\nfeatures, such as Aminer and Freebase, at a 40% label rate in node\nclassification, HetCRF improves the Macro-F1 score by 2.75% and 2.2%\nrespectively compared to the second-best baseline, validating its effectiveness\nand superiority.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06682v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06985", "title": "Certified Unlearning for Neural Networks", "authors": ["Anastasia Koloskova", "Youssef Allouah", "Animesh Jha", "Rachid Guerraoui", "Sanmi Koyejo"], "summary": "We address the problem of machine unlearning, where the goal is to remove the\ninfluence of specific training data from a model upon request, motivated by\nprivacy concerns and regulatory requirements such as the \"right to be\nforgotten.\" Unfortunately, existing methods rely on restrictive assumptions or\nlack formal guarantees. To this end, we propose a novel method for certified\nmachine unlearning, leveraging the connection between unlearning and privacy\namplification by stochastic post-processing. Our method uses noisy fine-tuning\non the retain data, i.e., data that does not need to be removed, to ensure\nprovable unlearning guarantees. This approach requires no assumptions about the\nunderlying loss function, making it broadly applicable across diverse settings.\nWe analyze the theoretical trade-offs in efficiency and accuracy and\ndemonstrate empirically that our method not only achieves formal unlearning\nguarantees but also performs effectively in practice, outperforming existing\nbaselines. Our code is available at\nhttps://github.com/stair-lab/certified-unlearningneural-networks-icml-2025", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06985v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06992", "title": "Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization", "authors": ["Yanting Gao", "Yepeng Liu", "Junming Liu", "Qi Zhang", "Hongyun Zhang", "Duoqian Miao", "Cairong Zhao"], "summary": "Exploring effective and transferable adversarial examples is vital for\nunderstanding the characteristics and mechanisms of Vision Transformers (ViTs).\nHowever, adversarial examples generated from surrogate models often exhibit\nweak transferability in black-box settings due to overfitting. Existing methods\nimprove transferability by diversifying perturbation inputs or applying uniform\ngradient regularization within surrogate models, yet they have not fully\nleveraged the shared and unique features of surrogate models trained on the\nsame task, leading to suboptimal transfer performance. Therefore, enhancing\nperturbations of common information shared by surrogate models and suppressing\nthose tied to individual characteristics offers an effective way to improve\ntransferability. Accordingly, we propose a commonality-oriented gradient\noptimization strategy (COGO) consisting of two components: Commonality\nEnhancement (CE) and Individuality Suppression (IS). CE perturbs the mid-to-low\nfrequency regions, leveraging the fact that ViTs trained on the same dataset\ntend to rely more on mid-to-low frequency information for classification. IS\nemploys adaptive thresholds to evaluate the correlation between backpropagated\ngradients and model individuality, assigning weights to gradients accordingly.\nExtensive experiments demonstrate that COGO significantly improves the transfer\nsuccess rates of adversarial attacks, outperforming current state-of-the-art\nmethods.", "comment": "22 pages", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06992v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07527", "title": "Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions", "authors": ["Lu Ma", "Hao Liang", "Meiyi Qiang", "Lexiang Tang", "Xiaochen Ma", "Zhen Hao Wong", "Junbo Niu", "Chengyu Shen", "Runming He", "Bin Cui", "Wentao Zhang"], "summary": "Recent advances in large language model (LLM) reasoning have shown that\nsophisticated behaviors such as planning and self-reflection can emerge through\nreinforcement learning (RL). However, despite these successes, RL in its\ncurrent form remains insufficient to induce capabilities that exceed the\nlimitations of the base model, as it is primarily optimized based on existing\nknowledge of the model rather than facilitating the acquisition of new\ninformation. To address this limitation, we employ supervised fine-tuning (SFT)\nto learn what RL cannot, which enables the incorporation of new knowledge and\nreasoning patterns by leveraging high-quality demonstration data. We analyze\nthe training dynamics of RL and SFT for LLM reasoning and find that RL excels\nat maintaining and improving performance on questions within the model's\noriginal capabilities, while SFT is more effective at enabling progress on\nquestions beyond the current scope of the model. Motivated by the complementary\nstrengths of RL and SFT, we introduce a novel training approach,\n\\textbf{ReLIFT} (\\textbf{Re}inforcement \\textbf{L}earning \\textbf{I}nterleaved\nwith Online \\textbf{F}ine-\\textbf{T}uning). In ReLIFT, the model is primarily\ntrained using RL, but when it encounters challenging questions, high-quality\nsolutions are collected for fine-tuning, and the training process alternates\nbetween RL and fine-tuning to enhance the model's reasoning abilities. ReLIFT\nachieves an average improvement of over +5.2 points across five\ncompetition-level benchmarks and one out-of-distribution benchmark compared to\nother zero-RL models. Furthermore, we demonstrate that ReLIFT outperforms both\nRL and SFT while using only 13\\% of the detailed demonstration data,\nhighlighting its scalability. These results provide compelling evidence that\nReLIFT overcomes the fundamental limitations of RL and underscores the\nsignificant potential.", "comment": "12 pages, 5 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07527v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07022", "title": "AlphaSteer: Learning Refusal Steering with Principled Null-Space Constraint", "authors": ["Leheng Sheng", "Changshuo Shen", "Weixiang Zhao", "Junfeng Fang", "Xiaohao Liu", "Zhenkai Liang", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "summary": "As LLMs are increasingly deployed in real-world applications, ensuring their\nability to refuse malicious prompts, especially jailbreak attacks, is essential\nfor safe and reliable use. Recently, activation steering has emerged as an\neffective approach for enhancing LLM safety by adding a refusal direction\nvector to internal activations of LLMs during inference, which will further\ninduce the refusal behaviors of LLMs. However, indiscriminately applying\nactivation steering fundamentally suffers from the trade-off between safety and\nutility, since the same steering vector can also lead to over-refusal and\ndegraded performance on benign prompts. Although prior efforts, such as vector\ncalibration and conditional steering, have attempted to mitigate this\ntrade-off, their lack of theoretical grounding limits their robustness and\neffectiveness. To better address the trade-off between safety and utility, we\npresent a theoretically grounded and empirically effective activation steering\nmethod called AlphaSteer. Specifically, it considers activation steering as a\nlearnable process with two principled learning objectives: utility preservation\nand safety enhancement. For utility preservation, it learns to construct a\nnearly zero vector for steering benign data, with the null-space constraints.\nFor safety enhancement, it learns to construct a refusal direction vector for\nsteering malicious data, with the help of linear regression. Experiments across\nmultiple jailbreak attacks and utility benchmarks demonstrate the effectiveness\nof AlphaSteer, which significantly improves the safety of LLMs without\ncompromising general capabilities. Our codes are available at\nhttps://github.com/AlphaLab-USTC/AlphaSteer.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07022v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06993", "title": "DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching", "authors": ["Cong Guan", "Jiacheng Ying", "Yuya Ieiri", "Osamu Yoshie"], "summary": "Dual-camera super-resolution is highly practical for smartphone photography\nthat primarily super-resolve the wide-angle images using the telephoto image as\na reference. In this paper, we propose DM$^3$Net, a novel dual-camera\nsuper-resolution network based on Domain Modulation and Multi-scale Matching.\nTo bridge the domain gap between the high-resolution domain and the degraded\ndomain, we learn two compressed global representations from image pairs\ncorresponding to the two domains. To enable reliable transfer of high-frequency\nstructural details from the reference image, we design a multi-scale matching\nmodule that conducts patch-level feature matching and retrieval across multiple\nreceptive fields to improve matching accuracy and robustness. Moreover, we also\nintroduce Key Pruning to achieve a significant reduction in memory usage and\ninference time with little model performance sacrificed. Experimental results\non three real-world datasets demonstrate that our DM$^3$Net outperforms the\nstate-of-the-art approaches.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06993v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07528", "title": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification", "authors": ["Qisheng Hu", "Quanyu Long", "Wenya Wang"], "summary": "Multi-hop claim verification is inherently challenging, requiring multi-step\nreasoning to construct verification chains while iteratively searching for\ninformation to uncover hidden bridging facts. This process is fundamentally\ninterleaved, as effective reasoning relies on dynamically retrieved evidence,\nwhile effective search demands reasoning to refine queries based on partial\ninformation. To achieve this, we propose Hierarchical Agent Reasoning and\nInformation Search (HARIS), explicitly modeling the coordinated process of\nreasoning-driven searching and search-informed reasoning. HARIS consists of a\nhigh-level reasoning agent that focuses on constructing the main verification\nchain, generating factual questions when more information is needed, and a\nlow-level search agent that iteratively retrieves more information, refining\nits search based on intermediate findings. This design allows each agent to\nspecialize in its respective task, enhancing verification accuracy and\ninterpretability. HARIS is trained using reinforcement learning with\noutcome-based rewards. Experimental results on the EX-FEVER and HOVER\nbenchmarks demonstrate that HARIS achieves strong performance, greatly\nadvancing multi-hop claim verification.", "comment": "19 pages, 9 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07528v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06699", "title": "MarginSel : Max-Margin Demonstration Selection for LLMs", "authors": ["Rajeev Bhatt Ambati", "James Lester", "Shashank Srivastava", "Snigdha Chaturvedi"], "summary": "Large Language Models (LLMs) excel at few-shot learning via in-context\nlearning (ICL). However, the effectiveness of ICL is often sensitive to the\nselection and ordering of demonstration examples. To address this, we present\nMarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that\nselects hard demonstration examples for the ICL prompt, adapting to each test\ninstance. Our approach achieves 2-7% absolute improvement in F1-score across\nclassification tasks, compared to a random selection of examples. We also\nprovide theoretical insights and empirical evidence showing that MarginSel\ninduces max-margin behavior in LLMs by effectively increasing the margin for\nhard examples, analogous to support vectors, thereby shifting the decision\nboundary in a beneficial direction.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06699v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07056", "title": "D2R: dual regularization loss with collaborative adversarial generation for model robustness", "authors": ["Zhenyu Liu", "Huizhi Liang", "Rajiv Ranjan", "Zhanxing Zhu", "Vaclav Snasel", "Varun Ojha"], "summary": "The robustness of Deep Neural Network models is crucial for defending models\nagainst adversarial attacks. Recent defense methods have employed collaborative\nlearning frameworks to enhance model robustness. Two key limitations of\nexisting methods are (i) insufficient guidance of the target model via loss\nfunctions and (ii) non-collaborative adversarial generation. We, therefore,\npropose a dual regularization loss (D2R Loss) method and a collaborative\nadversarial generation (CAG) strategy for adversarial training. D2R loss\nincludes two optimization steps. The adversarial distribution and clean\ndistribution optimizations enhance the target model's robustness by leveraging\nthe strengths of different loss functions obtained via a suitable function\nspace exploration to focus more precisely on the target model's distribution.\nCAG generates adversarial samples using a gradient-based collaboration between\nguidance and target models. We conducted extensive experiments on three\nbenchmark databases, including CIFAR-10, CIFAR-100, Tiny ImageNet, and two\npopular target models, WideResNet34-10 and PreActResNet18. Our results show\nthat D2R loss with CAG produces highly robust models.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07056v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06931", "title": "Towards Data-Driven Model-Free Safety-Critical Control", "authors": ["Zhe Shen", "Yitaek Kim", "Christoffer Sloth"], "summary": "This paper presents a framework for enabling safe velocity control of general\nrobotic systems using data-driven model-free Control Barrier Functions (CBFs).\nModel-free CBFs rely on an exponentially stable velocity controller and a\ndesign parameter (e.g. alpha in CBFs); this design parameter depends on the\nexponential decay rate of the controller. However, in practice, the decay rate\nis often unavailable, making it non-trivial to use model-free CBFs, as it\nrequires manual tuning for alpha. To address this, a Neural Network is used to\nlearn the Lyapunov function from data, and the maximum decay rate of the\nsystems built-in velocity controller is subsequently estimated. Furthermore, to\nintegrate the estimated decay rate with model-free CBFs, we derive a\nprobabilistic safety condition that incorporates a confidence bound on the\nviolation rate of the exponential stability condition, using Chernoff bound.\nThis enhances robustness against uncertainties in stability violations. The\nproposed framework has been tested on a UR5e robot in multiple experimental\nsettings, and its effectiveness in ensuring safe velocity control with\nmodel-free CBFs has been demonstrated.", "comment": "submitted to IROS 2025", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06931v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06995", "title": "Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems", "authors": ["Xiaoya Zhang"], "summary": "This technical report presents the implementation details of the winning\nsolution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. This\nchallenge focuses on semantic segmentation of 3D point clouds from diverse\nunstructured outdoor environments collected from multiple robotic platforms.\nThis problem was addressed by implementing Point Prompt Tuning (PPT) integrated\nwith Point Transformer v3 (PTv3) backbone, enabling adaptive processing of\nheterogeneous LiDAR data through platform-specific conditioning and\ncross-dataset class alignment strategies. The model is trained without\nrequiring additional external data. As a result, this approach achieved\nsubstantial performance improvements with mIoU increases of up to 22.59% on\nchallenging platforms compared to the baseline PTv3 model, demonstrating the\neffectiveness of adaptive point cloud understanding for field robotics\napplications.", "comment": "Winner of the GOOSE 3D Semantic Segmentation Challenge at the IEEE\n  ICRA Workshop on Field Robotics 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06995v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07548", "title": "Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning", "authors": ["Weiqiang Jin", "Hongyang Du", "Guizhong Liu", "Dong In Kim"], "summary": "Multi-agent reinforcement learning (MARL) has achieved strong performance in\ncooperative adversarial tasks. However, most existing methods typically train\nagents against fixed opponent strategies and rely on such meta-static\ndifficulty conditions, which limits their adaptability to changing environments\nand often leads to suboptimal policies. Inspired by the success of curriculum\nlearning (CL) in supervised tasks, we propose a dynamic CL framework for MARL\nthat employs an self-adaptive difficulty adjustment mechanism. This mechanism\ncontinuously modulates opponent strength based on real-time agent training\nperformance, allowing agents to progressively learn from easier to more\nchallenging scenarios. However, the dynamic nature of CL introduces instability\ndue to nonstationary environments and sparse global rewards. To address this\nchallenge, we develop a Counterfactual Group Relative Policy Advantage (CGRPA),\nwhich is tightly coupled with the curriculum by providing intrinsic credit\nsignals that reflect each agent's impact under evolving task demands. CGRPA\nconstructs a counterfactual advantage function that isolates individual\ncontributions within group behavior, facilitating more reliable policy updates\nthroughout the curriculum. CGRPA evaluates each agent's contribution through\nconstructing counterfactual action advantage function, providing intrinsic\nrewards that enhance credit assignment and stabilize learning under\nnon-stationary conditions. Extensive experiments demonstrate that our method\nimproves both training stability and final performance, achieving competitive\nresults against state-of-the-art methods. The code is available at\nhttps://github.com/NICE-HKU/CL2MARL-SMAC.", "comment": "16 pages; 12figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07548v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06701", "title": "Do Protein Transformers Have Biological Intelligence?", "authors": ["Fudong Lin", "Wanrou Du", "Jinchan Liu", "Tarikul Milon", "Shelby Meche", "Wu Xu", "Xiaoqi Qin", "Xu Yuan"], "summary": "Deep neural networks, particularly Transformers, have been widely adopted for\npredicting the functional properties of proteins. In this work, we focus on\nexploring whether Protein Transformers can capture biological intelligence\namong protein sequences. To achieve our goal, we first introduce a protein\nfunction dataset, namely Protein-FN, providing over 9000 protein data with\nmeaningful labels. Second, we devise a new Transformer architecture, namely\nSequence Protein Transformers (SPT), for computationally efficient protein\nfunction predictions. Third, we develop a novel Explainable Artificial\nIntelligence (XAI) technique called Sequence Score, which can efficiently\ninterpret the decision-making processes of protein models, thereby overcoming\nthe difficulty of deciphering biological intelligence bided in Protein\nTransformers. Remarkably, even our smallest SPT-Tiny model, which contains only\n5.4M parameters, demonstrates impressive predictive accuracy, achieving 94.3%\non the Antibiotic Resistance (AR) dataset and 99.6% on the Protein-FN dataset,\nall accomplished by training from scratch. Besides, our Sequence Score\ntechnique helps reveal that our SPT models can discover several meaningful\npatterns underlying the sequence structures of protein data, with these\npatterns aligning closely with the domain knowledge in the biology community.\nWe have officially released our Protein-FN dataset on Hugging Face Datasets\nhttps://huggingface.co/datasets/Protein-FN/Protein-FN. Our code is available at\nhttps://github.com/fudong03/BioIntelligence.", "comment": "Accepted by European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML-PKDD 2025)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06701v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07214", "title": "Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation", "authors": ["Zhiyuan Zhong", "Zhen Sun", "Yepang Liu", "Xinlei He", "Guanhong Tao"], "summary": "Vision Language Models (VLMs) have shown remarkable performance, but are also\nvulnerable to backdoor attacks whereby the adversary can manipulate the model's\noutputs through hidden triggers. Prior attacks primarily rely on\nsingle-modality triggers, leaving the crucial cross-modal fusion nature of VLMs\nlargely unexplored. Unlike prior work, we identify a novel attack surface that\nleverages cross-modal semantic mismatches as implicit triggers. Based on this\ninsight, we propose BadSem (Backdoor Attack with Semantic Manipulation), a data\npoisoning attack that injects stealthy backdoors by deliberately misaligning\nimage-text pairs during training. To perform the attack, we construct SIMBad, a\ndataset tailored for semantic manipulation involving color and object\nattributes. Extensive experiments across four widely used VLMs show that BadSem\nachieves over 98% average ASR, generalizes well to out-of-distribution\ndatasets, and can transfer across poisoning modalities. Our detailed analysis\nusing attention visualization shows that backdoored models focus on\nsemantically sensitive regions under mismatched conditions while maintaining\nnormal behavior on clean inputs. To mitigate the attack, we try two defense\nstrategies based on system prompt and supervised fine-tuning but find that both\nof them fail to mitigate the semantic backdoor. Our findings highlight the\nurgent need to address semantic vulnerabilities in VLMs for their safer\ndeployment.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07214v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06954", "title": "Safety-Aware Reinforcement Learning for Control via Risk-Sensitive Action-Value Iteration and Quantile Regression", "authors": ["Clinton Enwerem", "Aniruddh G. Puranic", "John S. Baras", "Calin Belta"], "summary": "Mainstream approximate action-value iteration reinforcement learning (RL)\nalgorithms suffer from overestimation bias, leading to suboptimal policies in\nhigh-variance stochastic environments. Quantile-based action-value iteration\nmethods reduce this bias by learning a distribution of the expected cost-to-go\nusing quantile regression. However, ensuring that the learned policy satisfies\nsafety constraints remains a challenge when these constraints are not\nexplicitly integrated into the RL framework. Existing methods often require\ncomplex neural architectures or manual tradeoffs due to combined cost\nfunctions. To address this, we propose a risk-regularized quantile-based\nalgorithm integrating Conditional Value-at-Risk (CVaR) to enforce safety\nwithout complex architectures. We also provide theoretical guarantees on the\ncontraction properties of the risk-sensitive distributional Bellman operator in\nWasserstein space, ensuring convergence to a unique cost distribution.\nSimulations of a mobile robot in a dynamic reach-avoid task show that our\napproach leads to more goal successes, fewer collisions, and better\nsafety-performance trade-offs compared to risk-neutral methods.", "comment": "13 pages, 4 figures. Submission under review", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06954v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07002", "title": "BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction", "authors": ["Yunxiao Shi", "Hong Cai", "Jisoo Jeong", "Yinhao Zhu", "Shizhong Han", "Amin Ansari", "Fatih Porikli"], "summary": "3D occupancy provides fine-grained 3D geometry and semantics for scene\nunderstanding which is critical for autonomous driving. Most existing methods,\nhowever, carry high compute costs, requiring dense 3D feature volume and\ncross-attention to effectively aggregate information. More recent works have\nadopted Bird's Eye View (BEV) or sparse points as scene representation with\nmuch reduced cost, but still suffer from their respective shortcomings. More\nconcretely, BEV struggles with small objects that often experience significant\ninformation loss after being projected to the ground plane. On the other hand,\npoints can flexibly model little objects in 3D, but is inefficient at capturing\nflat surfaces or large objects. To address these challenges, in this paper, we\npresent a novel 3D occupancy prediction approach, BePo, which combines BEV and\nsparse points based representations. We propose a dual-branch design: a\nquery-based sparse points branch and a BEV branch. The 3D information learned\nin the sparse points branch is shared with the BEV stream via cross-attention,\nwhich enriches the weakened signals of difficult objects on the BEV plane. The\noutputs of both branches are finally fused to generate predicted 3D occupancy.\nWe conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymo\nbenchmarks that demonstrate the superiority of our proposed BePo. Moreover,\nBePo also delivers competitive inference speed when compared to the latest\nefficient approaches.", "comment": "Two-page abstract version available at CVPR 2025 Embodied AI Workshop", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07002v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07553", "title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition", "authors": ["Jingchao Wang", "Haote Yang", "Jiang Wu", "Yifan He", "Xingjian Wei", "Yinfan Wang", "Chengjin Liu", "Lingli Ge", "Lijun Wu", "Bin Wang", "Dahua Lin", "Conghui He"], "summary": "Optical Chemical Structure Recognition (OCSR) is crucial for digitizing\nchemical knowledge by converting molecular images into machine-readable\nformats. While recent vision-language models (VLMs) have shown potential in\nthis task, their image-captioning approach often struggles with complex\nmolecular structures and inconsistent annotations. To overcome these\nchallenges, we introduce GTR-Mol-VLM, a novel framework featuring two key\ninnovations: (1) the \\textit{Graph Traversal as Visual Chain of Thought}\nmechanism that emulates human reasoning by incrementally parsing molecular\ngraphs through sequential atom-bond predictions, and (2) the data-centric\nprinciple of \\textit{Faithfully Recognize What You've Seen}, which addresses\nthe mismatch between abbreviated structures in images and their expanded\nannotations. To support model development, we constructed GTR-CoT-1.3M, a\nlarge-scale instruction-tuning dataset with meticulously corrected annotations,\nand introduced MolRec-Bench, the first benchmark designed for a fine-grained\nevaluation of graph-parsing accuracy in OCSR. Comprehensive experiments\ndemonstrate that GTR-Mol-VLM achieves superior results compared to specialist\nmodels, chemistry-domain VLMs, and commercial general-purpose VLMs. Notably, in\nscenarios involving molecular images with functional group abbreviations,\nGTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage\npoints, both in SMILES-based and graph-based metrics. We hope that this work\nwill drive OCSR technology to more effectively meet real-world needs, thereby\nadvancing the fields of cheminformatics and AI for Science. We will release\nGTR-CoT at https://github.com/opendatalab/GTR-CoT.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07553v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06715", "title": "A Framework for Controllable Multi-objective Learning with Annealed Stein Variational Hypernetworks", "authors": ["Minh-Duc Nguyen", "Dung D. Le"], "summary": "Pareto Set Learning (PSL) is popular as an efficient approach to obtaining\nthe complete optimal solution in Multi-objective Learning (MOL). A set of\noptimal solutions approximates the Pareto set, and its mapping is a set of\ndense points in the Pareto front in objective space. However, some current\nmethods face a challenge: how to make the Pareto solution is diverse while\nmaximizing the hypervolume value. In this paper, we propose a novel method to\naddress this challenge, which employs Stein Variational Gradient Descent (SVGD)\nto approximate the entire Pareto set. SVGD pushes a set of particles towards\nthe Pareto set by applying a form of functional gradient descent, which helps\nto converge and diversify optimal solutions. Additionally, we employ diverse\ngradient direction strategies to thoroughly investigate a unified framework for\nSVGD in multi-objective optimization and adapt this framework with an annealing\nschedule to promote stability. We introduce our method, SVH-MOL, and validate\nits effectiveness through extensive experiments on multi-objective problems and\nmulti-task learning, demonstrating its superior performance.", "comment": "Paper is under review", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06715v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06384", "title": "Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering", "authors": ["Yi Ji", "Runzhi Li", "Baolei Mao"], "summary": "With the widespread adoption of Large Language Models (LLMs), prompt\ninjection attacks have emerged as a significant security threat. Existing\ndefense mechanisms often face critical trade-offs between effectiveness and\ngeneralizability. This highlights the urgent need for efficient prompt\ninjection detection methods that are applicable across a wide range of LLMs. To\naddress this challenge, we propose DMPI-PMHFE, a dual-channel feature fusion\ndetection framework. It integrates a pretrained language model with heuristic\nfeature engineering to detect prompt injection attacks. Specifically, the\nframework employs DeBERTa-v3-base as a feature extractor to transform input\ntext into semantic vectors enriched with contextual information. In parallel,\nwe design heuristic rules based on known attack patterns to extract explicit\nstructural features commonly observed in attacks. Features from both channels\nare subsequently fused and passed through a fully connected neural network to\nproduce the final prediction. This dual-channel approach mitigates the\nlimitations of relying only on DeBERTa to extract features. Experimental\nresults on diverse benchmark datasets demonstrate that DMPI-PMHFE outperforms\nexisting methods in terms of accuracy, recall, and F1-score. Furthermore, when\ndeployed actually, it significantly reduces attack success rates across\nmainstream LLMs, including GLM-4, LLaMA 3, Qwen 2.5, and GPT-4o.", "comment": "Accepted by KSEM2025 AI & Sec Workshop", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06384v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07294", "title": "Towards Generalized Source Tracing for Codec-Based Deepfake Speech", "authors": ["Xuanjun Chen", "I-Ming Lin", "Lin Zhang", "Haibin Wu", "Hung-yi Lee", "Jyh-Shing Roger Jang"], "summary": "Recent attempts at source tracing for codec-based deepfake speech\n(CodecFake), generated by neural audio codec-based speech generation (CoSG)\nmodels, have exhibited suboptimal performance. However, how to train source\ntracing models using simulated CoSG data while maintaining strong performance\non real CoSG-generated audio remains an open challenge. In this paper, we show\nthat models trained solely on codec-resynthesized data tend to overfit to\nnon-speech regions and struggle to generalize to unseen content. To mitigate\nthese challenges, we introduce the Semantic-Acoustic Source Tracing Network\n(SASTNet), which jointly leverages Whisper for semantic feature encoding and\nWav2vec2 with AudioMAE for acoustic feature encoding. Our proposed SASTNet\nachieves state-of-the-art performance on the CoSG test set of the CodecFake+\ndataset, demonstrating its effectiveness for reliable source tracing.", "comment": "Submitted to IEEE ASRU 2025", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07294v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07013", "title": "UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment", "authors": ["Wentao Zhao", "Yihe Niu", "Yanbo Wang", "Tianchen Deng", "Shenghai Yuan", "Zhenli Wang", "Rui Guo", "Jingchuan Wang"], "summary": "This work presents UNO, a unified monocular visual odometry framework that\nenables robust and adaptable pose estimation across diverse environments,\nplatforms, and motion patterns. Unlike traditional methods that rely on\ndeployment-specific tuning or predefined motion priors, our approach\ngeneralizes effectively across a wide range of real-world scenarios, including\nautonomous vehicles, aerial drones, mobile robots, and handheld devices. To\nthis end, we introduce a Mixture-of-Experts strategy for local state\nestimation, with several specialized decoders that each handle a distinct class\nof ego-motion patterns. Moreover, we introduce a fully differentiable\nGumbel-Softmax module that constructs a robust inter-frame correlation graph,\nselects the optimal expert decoder, and prunes erroneous estimates. These cues\nare then fed into a unified back-end that combines pre-trained,\nscale-independent depth priors with a lightweight bundling adjustment to\nenforce geometric consistency. We extensively evaluate our method on three\nmajor benchmark datasets: KITTI (outdoor/autonomous driving), EuRoC-MAV\n(indoor/aerial drones), and TUM-RGBD (indoor/handheld), demonstrating\nstate-of-the-art performance.", "comment": "15pages, 8 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07013v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07564", "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems", "authors": ["Peiran Li", "Xinkai Zou", "Zhuohang Wu", "Ruifeng Li", "Shuo Xing", "Hanwen Zheng", "Zhikai Hu", "Yuping Wang", "Haoxi Li", "Qin Yuan", "Yingmo Zhang", "Zhengzhong Tu"], "summary": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-grained information flow control (IFC),\nprecisely tracking provenance, integrity, and confidentiality of all the data\nexchanged between agents, tools, users, and environments. By constraining LLM\nreasoning to respect these security labels, SAFEFLOW prevents untrusted or\nadversarial inputs from contaminating high-integrity decisions. To ensure\nrobustness in concurrent multi-agent settings, SAFEFLOW introduces\ntransactional execution, conflict resolution, and secure scheduling over shared\nstate, preserving global consistency across agents. We further introduce\nmechanisms, including write-ahead logging, rollback, and secure caches, that\nfurther enhance resilience against runtime errors and policy violations. To\nvalidate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark\nsuite designed to evaluate agent reliability under adversarial, noisy, and\nconcurrent operational conditions. Extensive experiments demonstrate that\nagents built with SAFEFLOW maintain impressive task performance and security\nguarantees even in hostile environments, substantially outperforming\nstate-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for\nprincipled, robust, and secure agent ecosystems, advancing the frontier of\nreliable autonomy.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07564v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06761", "title": "The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing", "authors": ["Adrià Molina Rodríguez", "Oriol Ramos Terrades", "Josep Lladós"], "summary": "Achieving robustness in recognition systems across diverse domains is crucial\nfor their practical utility. While ample data availability is usually assumed,\nlow-resource languages, such as ancient manuscripts and non-western languages,\ntend to be kept out of the equations of massive pretraining and foundational\ntechniques due to an under representation. In this work, we aim for building\nmodels which can generalize to new distributions of data, such as alphabets,\nfaster than centralized fine-tune strategies. For doing so, we take advantage\nof the recent advancements in model editing to enhance the incorporation of\nunseen scripts (low-resource learning). In contrast to state-of-the-art\nmeta-learning, we showcase the effectiveness of domain merging in sparse\ndistributions of data, with agnosticity of its relation to the overall\ndistribution or any other prototyping necessity. Even when using the same exact\ntraining data, our experiments showcase significant performance boosts in\n\\textbf{transfer learning} to new alphabets and \\textbf{out-of-domain\nevaluation} in challenging domain shifts, including historical ciphered texts\nand non-Latin scripts. This research contributes a novel approach into building\nmodels that can easily adopt under-represented alphabets and, therefore, enable\ndocument recognition to a wider set of contexts and cultures.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06761v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07330", "title": "JavelinGuard: Low-Cost Transformer Architectures for LLM Security", "authors": ["Yash Datta", "Sharath Rajasekar"], "summary": "We present JavelinGuard, a suite of low-cost, high-performance model\narchitectures designed for detecting malicious intent in Large Language Model\n(LLM) interactions, optimized specifically for production deployment. Recent\nadvances in transformer architectures, including compact BERT(Devlin et al.\n2019) variants (e.g., ModernBERT (Warner et al. 2024)), allow us to build\nhighly accurate classifiers with as few as approximately 400M parameters that\nachieve rapid inference speeds even on standard CPU hardware. We systematically\nexplore five progressively sophisticated transformer-based architectures:\nSharanga (baseline transformer classifier), Mahendra (enhanced\nattention-weighted pooling with deeper heads), Vaishnava and Ashwina (hybrid\nneural ensemble architectures), and Raudra (an advanced multi-task framework\nwith specialized loss functions). Our models are rigorously benchmarked across\nnine diverse adversarial datasets, including popular sets like the NotInject\nseries, BIPIA, Garak, ImprovedLLM, ToxicChat, WildGuard, and our newly\nintroduced JavelinBench, specifically crafted to test generalization on\nchallenging borderline and hard-negative cases. Additionally, we compare our\narchitectures against leading open-source guardrail models as well as large\ndecoder-only LLMs such as gpt-4o, demonstrating superior cost-performance\ntrade-offs in terms of accuracy, and latency. Our findings reveal that while\nRaudra's multi-task design offers the most robust performance overall, each\narchitecture presents unique trade-offs in speed, interpretability, and\nresource requirements, guiding practitioners in selecting the optimal balance\nof complexity and efficiency for real-world LLM security applications.", "comment": "16 pages, 1 Figure and 5 Tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07330v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07225", "title": "Active Lubrication of Transluminal Medical Instruments", "authors": ["Mostafa A. Atalla", "Jelte Nieuwenhuis", "Alan Martin", "Xuan Wang", "Ahranee Canden", "Matt J. Carré", "Roger Lewis", "Aimée Sakes", "Michaël Wiertlewski"], "summary": "Transluminal minimally invasive surgery uses natural orifices and small\nincisions to access internal anatomical structures, promoting quicker recovery\nand reduced morbidity. However, navigating instruments--catheters and\nendoscopes--through anatomical pathways creates frictional interactions with\nluminal walls, risking complications such as perforation, poor haptic feedback,\nand instrument buckling. In this paper, we present a new approach to actively\nlubricate transluminal instruments and dynamically reduce friction with\nsurrounding tissues. This approach employs ultrasonic vibrations, at the\ninstrument surface, to generate a pressurized fluid layer at the contact\ninterface, lubricating the interface and thereby reducing friction. We\nimplemented this approach in a prototype catheter, which we validated under dry\nand liquid-lubricated conditions, across rigid and soft interfaces, and along\nvaried anatomical curvatures. In a cardiac catheter use case, active\nlubrication reduced friction by up to 42% on ex-vivo porcine aorta tissue and\n82% on rigid substrates, denoting its potential performance on healthy and\ncalcified tissue, respectively. Thermal imaging confirmed that temperature at\nthe tissue-catheter interface remained within safe limits. Additionally, the\nsystem effectively prevented buckling during catheter insertion experiment,\nfurther showcasing its potential. By minimizing injury risk and enhancing\nprocedural stability, active lubrication can drastically enhance the safety and\nefficacy of transluminal interventions.", "comment": null, "cate": "physics.med-ph", "url": "http://arxiv.org/abs/2506.07225v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07015", "title": "TABLET: Table Structure Recognition using Encoder-only Transformers", "authors": ["Qiyu Hou", "Jun Wang"], "summary": "To address the challenges of table structure recognition, we propose a novel\nSplit-Merge-based top-down model optimized for large, densely populated tables.\nOur approach formulates row and column splitting as sequence labeling tasks,\nutilizing dual Transformer encoders to capture feature interactions. The\nmerging process is framed as a grid cell classification task, leveraging an\nadditional Transformer encoder to ensure accurate and coherent merging. By\neliminating unstable bounding box predictions, our method reduces resolution\nloss and computational complexity, achieving high accuracy while maintaining\nfast processing speed. Extensive experiments on FinTabNet and PubTabNet\ndemonstrate the superiority of our model over existing approaches, particularly\nin real-world applications. Our method offers a robust, scalable, and efficient\nsolution for large-scale table recognition, making it well-suited for\nindustrial deployment.", "comment": "ICDAR 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07015v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07591", "title": "Automating Exploratory Multiomics Research via Language Models", "authors": ["Shang Qu", "Ning Ding", "Linhai Xie", "Yifei Li", "Zaoqu Liu", "Kaiyan Zhang", "Yibai Xiong", "Yuxin Zuo", "Zhangren Chen", "Ermo Hua", "Xingtai Lv", "Youbang Sun", "Yang Li", "Dong Li", "Fuchu He", "Bowen Zhou"], "summary": "This paper introduces PROTEUS, a fully automated system that produces\ndata-driven hypotheses from raw data files. We apply PROTEUS to clinical\nproteogenomics, a field where effective downstream data analysis and hypothesis\nproposal is crucial for producing novel discoveries. PROTEUS uses separate\nmodules to simulate different stages of the scientific process, from open-ended\ndata exploration to specific statistical analysis and hypothesis proposal. It\nformulates research directions, tools, and results in terms of relationships\nbetween biological entities, using unified graph structures to manage complex\nresearch processes. We applied PROTEUS to 10 clinical multiomics datasets from\npublished research, arriving at 360 total hypotheses. Results were evaluated\nthrough external data validation and automatic open-ended scoring. Through\nexploratory and iterative research, the system can navigate high-throughput and\nheterogeneous multiomics data to arrive at hypotheses that balance reliability\nand novelty. In addition to accelerating multiomic analysis, PROTEUS represents\na path towards tailoring general autonomous systems to specialized scientific\ndomains to achieve open-ended hypothesis generation from data.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07591v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06782", "title": "Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World", "authors": ["Qinting Jiang", "Chuyang Ye", "Dongyan Wei", "Bingli Wang", "Yuan Xue", "Jingyan Jiang", "Zhi Wang"], "summary": "Despite progress, deep neural networks still suffer performance declines\nunder distribution shifts between training and test domains, leading to a\nsubstantial decrease in Quality of Experience (QoE) for applications. Existing\ntest-time adaptation (TTA) methods are challenged by dynamic, multiple test\ndistributions within batches. We observe that feature distributions across\ndifferent domains inherently cluster into distinct groups with varying means\nand variances. This divergence reveals a critical limitation of previous global\nnormalization strategies in TTA, which inevitably distort the original data\ncharacteristics. Based on this insight, we propose Feature-based Instance\nNeighbor Discovery (FIND), which comprises three key components: Layer-wise\nFeature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and\nSelective FABN (S-FABN). LFD stably captures features with similar\ndistributions at each layer by constructing graph structures. While FABN\noptimally combines source statistics with test-time distribution specific\nstatistics for robust feature representation. Finally, S-FABN determines which\nlayers require feature partitioning and which can remain unified, thereby\nenhancing inference efficiency. Extensive experiments demonstrate that FIND\nsignificantly outperforms existing methods, achieving a 30\\% accuracy\nimprovement in dynamic scenarios while maintaining computational efficiency.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06782v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07640", "title": "Stark-Coleman Invariants and Quantum Lower Bounds: An Integrated Framework for Real Quadratic Fields", "authors": ["Ruopengyu Xu", "Chenglian Liu"], "summary": "Class groups of real quadratic fields represent fundamental structures in\nalgebraic number theory with significant computational implications. While\nStark's conjecture establishes theoretical connections between special units\nand class group structures, explicit constructions have remained elusive, and\nprecise quantum complexity bounds for class group computations are lacking.\nHere we establish an integrated framework defining Stark-Coleman invariants\n$\\kappa_p(K) = \\log_p \\left(\n\\frac{\\varepsilon_{\\mathrm{St},p}}{\\sigma(\\varepsilon_{\\mathrm{St},p})} \\right)\n\\mod p^{\\mathrm{ord}_p(\\Delta_K)}$ through a synthesis of $p$-adic Hodge theory\nand extended Coleman integration. We prove these invariants classify class\ngroups under the Generalized Riemann Hypothesis (GRH), resolving the\nisomorphism problem for discriminants $D > 10^{32}$. Furthermore, we\ndemonstrate that this approach yields the quantum lower bound\n$\\exp\\left(\\Omega\\left(\\frac{\\log D}{(\\log \\log D)^2}\\right)\\right)$ for the\nclass group discrete logarithm problem, improving upon previous bounds lacking\nexplicit constants. Our results indicate that Stark units constrain the\ngeometric organization of class groups, providing theoretical insight into\ncomputational complexity barriers.", "comment": "16 pages, 1 figure, 3 tables", "cate": "math.NT", "url": "http://arxiv.org/abs/2506.07640v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07286", "title": "Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI", "authors": ["Aditya Chakravarty"], "summary": "Diffusion models have shown remarkable flexibility for solving inverse\nproblems without task-specific retraining. However, existing approaches such as\nManifold Preserving Guided Diffusion (MPGD) apply only a single gradient update\nper denoising step, limiting restoration fidelity and robustness, especially in\nembedded or out-of-distribution settings. In this work, we introduce a\nmultistep optimization strategy within each denoising timestep, significantly\nenhancing image quality, perceptual accuracy, and generalization. Our\nexperiments on super-resolution and Gaussian deblurring demonstrate that\nincreasing the number of gradient updates per step improves LPIPS and PSNR with\nminimal latency overhead. Notably, we validate this approach on a Jetson Orin\nNano using degraded ImageNet and a UAV dataset, showing that MPGD, originally\ntrained on face datasets, generalizes effectively to natural and aerial scenes.\nOur findings highlight MPGD's potential as a lightweight, plug-and-play\nrestoration module for real-time visual perception in embodied AI agents such\nas drones and mobile robots.", "comment": "Accepted in CVPR 2025 Embodied AI Workshop", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07286v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07016", "title": "MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks", "authors": ["Sanjoy Chowdhury", "Mohamed Elmoghany", "Yohan Abeysinghe", "Junjie Fei", "Sayan Nag", "Salman Khan", "Mohamed Elhoseiny", "Dinesh Manocha"], "summary": "Large multimodal models (LMMs) have shown remarkable progress in audio-visual\nunderstanding, yet they struggle with real-world scenarios that require complex\nreasoning across extensive video collections. Existing benchmarks for video\nquestion answering remain limited in scope, typically involving one clip per\nquery, which falls short of representing the challenges of large-scale,\naudio-visual retrieval and reasoning encountered in practical applications. To\nbridge this gap, we introduce a novel task named AV-HaystacksQA, where the goal\nis to identify salient segments across different videos in response to a query\nand link them together to generate the most informative answer. To this end, we\npresent AVHaystacks, an audio-visual benchmark comprising 3100 annotated QA\npairs designed to assess the capabilities of LMMs in multi-video retrieval and\ntemporal grounding task. Additionally, we propose a model-agnostic, multi-agent\nframework MAGNET to address this challenge, achieving up to 89% and 65%\nrelative improvements over baseline methods on BLEU@4 and GPT evaluation scores\nin QA task on our proposed AVHaystacks. To enable robust evaluation of\nmulti-video retrieval and temporal grounding for optimal response generation,\nwe introduce two new metrics, STEM, which captures alignment errors between a\nground truth and a predicted step sequence and MTGS, to facilitate balanced and\ninterpretable evaluation of segment-level grounding performance. Project:\nhttps://schowdhury671.github.io/magnet_project/", "comment": "Audio-visual learning, Audio-Visual RAG, Multi-Video Linkage", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07016v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07636", "title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling", "authors": ["Haoran Wang", "Zhenyu Hou", "Yao Wei", "Jie Tang", "Yuxiao Dong"], "summary": "Large language models (LLMs) have advanced rapidly from conversational\nproblem solving to addressing real-world tasks involving tool use, such as\nsoftware engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex\nand Cursor, have offered end-to-end automation of the software development\nprocess. However, building effective SWE agents remains challenging due to the\nlack of high-quality training data and effective test cases. To address this\nissue, we present SWE-Dev, an SWE agent built upon open-source LLMs. First, we\ndevelop a robust pipeline to synthesize test cases for patch evaluation.\nSecond, we scale up agent trajectories to construct the training data for\nbuilding SWE-Dev. Experiments on the SWE-bench-Verified benchmark show that the\nSWE-Dev models can achieve top performance among all open SWE agents.\nSpecifically, the success rates of the SWE-Dev 7B and 32B parameter models\nreach 23.4% and 36.6%, respectively, outperforming state-of-the-art open-source\nmodels. All code, models, and datasets are publicly available at\nhttps://github.com/THUDM/SWE-Dev.", "comment": "Accepted to Findings of ACL'25", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07636v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06784", "title": "Caterpillar GNN: Replacing Message Passing with Efficient Aggregation", "authors": ["Marek Černý"], "summary": "Message-passing graph neural networks (MPGNNs) dominate modern graph\nlearning, typically prioritizing maximal expressive power. In contrast, we\nintroduce an \\emph{efficient aggregation} mechanism, deliberately trading off\nsome expressivity for stronger and more structured aggregation capabilities.\nOur approach allows seamless scaling between classical message-passing and\nsimpler methods based on colored or plain walks. We rigorously characterize the\nexpressive power at each intermediate step using homomorphism counts from a\nhierarchy of generalized \\emph{caterpillar graphs}. Based on this foundation,\nwe propose the \\emph{Caterpillar GNN}, whose robust graph-level aggregation\nenables it to successfully tackle synthetic graph-level task specifically\ndesigned to be challenging for classical MPGNNs. Moreover, we demonstrate that,\non real-world datasets, the Caterpillar GNN achieves comparable predictive\nperformance while significantly reducing the number of nodes in the hidden\nlayers of the computational graph.", "comment": "40 pages, 9 figures, 3 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06784v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07795", "title": "LLM Unlearning Should Be Form-Independent", "authors": ["Xiaotian Ye", "Mengqi Zhang", "Shu Wu"], "summary": "Large Language Model (LLM) unlearning aims to erase or suppress undesirable\nknowledge within the model, offering promise for controlling harmful or private\ninformation to prevent misuse. However, recent studies highlight its limited\nefficacy in real-world scenarios, hindering practical adoption. In this study,\nwe identify a pervasive issue underlying many downstream failures: the\neffectiveness of existing unlearning methods heavily depends on the form of\ntraining samples and frequently fails to generalize to alternate expressions of\nthe same knowledge. We formally characterize this problem as Form-Dependent\nBias and systematically investigate its specific manifestation patterns across\nvarious downstream tasks. To quantify its prevalence and support future\nresearch, we introduce ORT, a novel benchmark designed to evaluate the\nrobustness of unlearning methods against variations in knowledge expression.\nResults reveal that Form-Dependent Bias is both widespread and severe among\ncurrent techniques.\n  We argue that LLM unlearning should be form-independent to address the\nendless forms of downstream tasks encountered in real-world security-critical\nscenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR),\na novel training-free method, as a promising solution path. ROCR performs\nunlearning by targeting the invariants in downstream tasks, specifically the\nactivated dangerous concepts. It is capable of modifying model parameters\nwithin seconds to redirect the model's perception of a specific unlearning\ntarget concept to another harmless concept. Extensive experiments demonstrate\nthat ROCR significantly improves unlearning effectiveness compared to\ntraditional methods while generating highly natural outputs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07795v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07338", "title": "Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation", "authors": ["Yijie Deng", "Shuaihang Yuan", "Geeta Chandra Raju Bethala", "Anthony Tzes", "Yu-Shen Liu", "Yi Fang"], "summary": "Instance Image-Goal Navigation (IIN) requires autonomous agents to identify\nand navigate to a target object or location depicted in a reference image\ncaptured from any viewpoint. While recent methods leverage powerful novel view\nsynthesis (NVS) techniques, such as three-dimensional Gaussian splatting\n(3DGS), they typically rely on randomly sampling multiple viewpoints or\ntrajectories to ensure comprehensive coverage of discriminative visual cues.\nThis approach, however, creates significant redundancy through overlapping\nimage samples and lacks principled view selection, substantially increasing\nboth rendering and comparison overhead. In this paper, we introduce a novel IIN\nframework with a hierarchical scoring paradigm that estimates optimal\nviewpoints for target matching. Our approach integrates cross-level semantic\nscoring, utilizing CLIP-derived relevancy fields to identify regions with high\nsemantic similarity to the target object class, with fine-grained local\ngeometric scoring that performs precise pose estimation within promising\nregions. Extensive evaluations demonstrate that our method achieves\nstate-of-the-art performance on simulated IIN benchmarks and real-world\napplicability.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07338v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07045", "title": "Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs", "authors": ["Yikun Ji", "Hong Yan", "Jun Lan", "Huijia Zhu", "Weiqiang Wang", "Qi Fan", "Liqing Zhang", "Jianfu Zhang"], "summary": "The rapid advancement of image generation technologies intensifies the demand\nfor interpretable and robust detection methods. Although existing approaches\noften attain high accuracy, they typically operate as black boxes without\nproviding human-understandable justifications. Multi-modal Large Language\nModels (MLLMs), while not originally intended for forgery detection, exhibit\nstrong analytical and reasoning capabilities. When properly fine-tuned, they\ncan effectively identify AI-generated images and offer meaningful explanations.\nHowever, existing MLLMs still struggle with hallucination and often fail to\nalign their visual interpretations with actual image content and human\nreasoning. To bridge this gap, we construct a dataset of AI-generated images\nannotated with bounding boxes and descriptive captions that highlight synthesis\nartifacts, establishing a foundation for human-aligned visual-textual grounded\nreasoning. We then finetune MLLMs through a multi-stage optimization strategy\nthat progressively balances the objectives of accurate detection, visual\nlocalization, and coherent textual explanation. The resulting model achieves\nsuperior performance in both detecting AI-generated images and localizing\nvisual flaws, significantly outperforming baseline methods.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07045v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07672", "title": "MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents", "authors": ["Yunhe Yan", "Shihe Wang", "Jiajun Du", "Yexuan Yang", "Yuxuan Shan", "Qichen Qiu", "Xianqing Jia", "Xinge Wang", "Xin Yuan", "Xu Han", "Mao Qin", "Yinxiao Chen", "Chen Peng", "Shangguang Wang", "Mengwei Xu"], "summary": "(M)LLM-powered computer use agents (CUA) are emerging as a transformative\ntechnique to automate human-computer interaction. However, existing CUA\nbenchmarks predominantly target GUI agents, whose evaluation methods are\nsusceptible to UI changes and ignore function interactions exposed by\napplication APIs, e.g., Model Context Protocol (MCP). To this end, we propose\nMCPWorld, the first automatic CUA testbed for API, GUI, and API-GUI hybrid\nagents. A key principle of MCPWorld is the use of \"white-box apps\", i.e., those\nwith source code availability and can be revised/re-compiled as needed (e.g.,\nadding MCP support), with two notable advantages:\n  (1) It greatly broadens the design space of CUA, such as what and how the app\nfeatures to be exposed/extracted as CUA-callable APIs.\n  (2) It allows MCPWorld to programmatically verify task completion by directly\nmonitoring application behavior through techniques like dynamic code\ninstrumentation, offering robust, accurate CUA evaluation decoupled from\nspecific agent implementations or UI states.\n  Currently, MCPWorld includes 201 well curated and annotated user tasks,\ncovering diversified use cases and difficulty levels. MCPWorld is also fully\ncontainerized with GPU acceleration support for flexible adoption on different\nOS/hardware environments. Our preliminary experiments, using a representative\nLLM-powered CUA framework, achieve 75.12% task completion accuracy,\nsimultaneously providing initial evidence on the practical effectiveness of\nagent automation leveraging MCP. Overall, we anticipate MCPWorld to facilitate\nand standardize the benchmarking of next-generation computer use agents that\ncan leverage rich external tools. Our code and dataset are publicly available\nat https://github.com/SAAgent/MCPWorld.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07672v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07948", "title": "TokenBreak: Bypassing Text Classification Models Through Token Manipulation", "authors": ["Kasimir Schulz", "Kenneth Yeung", "Kieran Evans"], "summary": "Natural Language Processing (NLP) models are used for text-related tasks such\nas classification and generation. To complete these tasks, input data is first\ntokenized from human-readable text into a format the model can understand,\nenabling it to make inferences and understand context. Text classification\nmodels can be implemented to guard against threats such as prompt injection\nattacks against Large Language Models (LLMs), toxic input and cybersecurity\nrisks such as spam emails. In this paper, we introduce TokenBreak: a novel\nattack that can bypass these protection models by taking advantage of the\ntokenization strategy they use. This attack technique manipulates input text in\nsuch a way that certain models give an incorrect classification. Importantly,\nthe end target (LLM or email recipient) can still understand and respond to the\nmanipulated text and therefore be vulnerable to the very attack the protection\nmodel was put in place to prevent. The tokenizer is tied to model architecture,\nmeaning it is possible to predict whether or not a model is vulnerable to\nattack based on family. We also present a defensive strategy as an added layer\nof protection that can be implemented without having to retrain the defensive\nmodel.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07948v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07050", "title": "From Swath to Full-Disc: Advancing Precipitation Retrieval with Multimodal Knowledge Expansion", "authors": ["Zheng Wang", "Kai Ying", "Bin Xu", "Chunjiao Wang", "Cong Bai"], "summary": "Accurate near-real-time precipitation retrieval has been enhanced by\nsatellite-based technologies. However, infrared-based algorithms have low\naccuracy due to weak relations with surface precipitation, whereas passive\nmicrowave and radar-based methods are more accurate but limited in range. This\nchallenge motivates the Precipitation Retrieval Expansion (PRE) task, which\naims to enable accurate, infrared-based full-disc precipitation retrievals\nbeyond the scanning swath. We introduce Multimodal Knowledge Expansion, a\ntwo-stage pipeline with the proposed PRE-Net model. In the Swath-Distilling\nstage, PRE-Net transfers knowledge from a multimodal data integration model to\nan infrared-based model within the scanning swath via Coordinated Masking and\nWavelet Enhancement (CoMWE). In the Full-Disc Adaptation stage, Self-MaskTune\nrefines predictions across the full disc by balancing multimodal and full-disc\ninfrared knowledge. Experiments on the introduced PRE benchmark demonstrate\nthat PRE-Net significantly advanced precipitation retrieval performance,\noutperforming leading products like PERSIANN-CCS, PDIR, and IMERG. The code\nwill be available at https://github.com/Zjut-MultimediaPlus/PRE-Net.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07050v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07731", "title": "NeurIPS 2025 E2LM Competition : Early Training Evaluation of Language Models", "authors": ["Mouadh Yagoubi", "Yasser Dahou", "Billel Mokeddem", "Younes Belkada", "Phuc H. Le-Khac", "Basma El Amel Boussaha", "Reda Alami", "Jingwei Zuo", "Damiano Marsili", "Mugariya Farooq", "Mounia Lalmas", "Georgia Gkioxari", "Patrick Gallinari", "Philip Torr", "Hakim Hacid"], "summary": "Existing benchmarks have proven effective for assessing the performance of\nfully trained large language models. However, we find striking differences in\nthe early training stages of small models, where benchmarks often fail to\nprovide meaningful or discriminative signals. To explore how these differences\narise, this competition tackles the challenge of designing scientific knowledge\nevaluation tasks specifically tailored for measuring early training progress of\nlanguage models. Participants are invited to develop novel evaluation\nmethodologies or adapt existing benchmarks to better capture performance\ndifferences among language models. To support this effort, we provide three\npre-trained small models (0.5B, 1B, and 3B parameters), along with intermediate\ncheckpoints sampled during training up to 200B tokens. All experiments and\ndevelopment work can be run on widely available free cloud-based GPU platforms,\nmaking participation accessible to researchers with limited computational\nresources. Submissions will be evaluated based on three criteria: the quality\nof the performance signal they produce, the consistency of model rankings at 1\ntrillion tokens of training, and their relevance to the scientific knowledge\ndomain. By promoting the design of tailored evaluation strategies for early\ntraining, this competition aims to attract a broad range of participants from\nvarious disciplines, including those who may not be machine learning experts or\nhave access to dedicated GPU resources. Ultimately, this initiative seeks to\nmake foundational LLM research more systematic and benchmark-informed from the\nearliest phases of model development.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07731v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06793", "title": "Is Optimal Transport Necessary for Inverse Reinforcement Learning?", "authors": ["Zixuan Dong", "Yumi Omori", "Keith Ross"], "summary": "Inverse Reinforcement Learning (IRL) aims to recover a reward function from\nexpert demonstrations. Recently, Optimal Transport (OT) methods have been\nsuccessfully deployed to align trajectories and infer rewards. While OT-based\nmethods have shown strong empirical results, they introduce algorithmic\ncomplexity, hyperparameter sensitivity, and require solving the OT optimization\nproblems. In this work, we challenge the necessity of OT in IRL by proposing\ntwo simple, heuristic alternatives: (1) Minimum-Distance Reward, which assigns\nrewards based on the nearest expert state regardless of temporal order; and (2)\nSegment-Matching Reward, which incorporates lightweight temporal alignment by\nmatching agent states to corresponding segments in the expert trajectory. These\nmethods avoid optimization, exhibit linear-time complexity, and are easy to\nimplement. Through extensive evaluations across 32 online and offline\nbenchmarks with three reinforcement learning algorithms, we show that our\nsimple rewards match or outperform recent OT-based approaches. Our findings\nsuggest that the core benefits of OT may arise from basic proximity alignment\nrather than its optimal coupling formulation, advocating for reevaluation of\ncomplexity in future IRL design.", "comment": "19 pages, 10 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06793v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06395", "title": "Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models", "authors": ["Pengyi Li", "Matvey Skripkin", "Alexander Zubrey", "Andrey Kuznetsov", "Ivan Oseledets"], "summary": "Large language models (LLMs) excel at reasoning, yet post-training remains\ncritical for aligning their behavior with task goals. Existing reinforcement\nlearning (RL) methods often depend on costly human annotations or external\nreward models. We propose Reinforcement Learning via Self-Confidence (RLSC),\nwhich uses the model's own confidence as reward signals-eliminating the need\nfor labels, preference models, or reward engineering. Applied to\nQwen2.5-Math-7B with only 8 samples per question and 4 training epochs, RLSC\nimproves accuracy by +20.10% on AIME2024, +49.40% on MATH500, and +52.50% on\nAMC23. RLSC offers a simple, scalable post-training method for reasoning models\nwith minimal supervision.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06395v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07744", "title": "Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning", "authors": ["Seungho Baek", "Taegeon Park", "Jongchan Park", "Seungjun Oh", "Yusung Kim"], "summary": "Existing offline hierarchical reinforcement learning methods rely on\nhigh-level policy learning to generate subgoal sequences. However, their\nefficiency degrades as task horizons increase, and they lack effective\nstrategies for stitching useful state transitions across different\ntrajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that\nformulates subgoal selection as a graph search problem rather than learning an\nexplicit high-level policy. By embedding states into a Temporal Distance\nRepresentation (TDR) space, GAS clusters semantically similar states from\ndifferent trajectories into unified graph nodes, enabling efficient transition\nstitching. A shortest-path algorithm is then applied to select subgoal\nsequences within the graph, while a low-level policy learns to reach the\nsubgoals. To improve graph quality, we introduce the Temporal Efficiency (TE)\nmetric, which filters out noisy or inefficient transition states, significantly\nenhancing task performance. GAS outperforms prior offline HRL methods across\nlocomotion, navigation, and manipulation tasks. Notably, in the most\nstitching-critical task, it achieves a score of 88.3, dramatically surpassing\nthe previous state-of-the-art score of 1.0. Our source code is available at:\nhttps://github.com/qortmdgh4141/GAS.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07744v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07055", "title": "A Layered Self-Supervised Knowledge Distillation Framework for Efficient Multimodal Learning on the Edge", "authors": ["Tarique Dahri", "Zulfiqar Ali Memon", "Zhenyu Yu", "Mohd. Yamani Idna Idris", "Sheheryar Khan", "Sadiq Ahmad", "Maged Shoman", "Saddam Aziz", "Rizwan Qureshi"], "summary": "We introduce Layered Self-Supervised Knowledge Distillation (LSSKD) framework\nfor training compact deep learning models. Unlike traditional methods that rely\non pre-trained teacher networks, our approach appends auxiliary classifiers to\nintermediate feature maps, generating diverse self-supervised knowledge and\nenabling one-to-one transfer across different network stages. Our method\nachieves an average improvement of 4.54\\% over the state-of-the-art PS-KD\nmethod and a 1.14% gain over SSKD on CIFAR-100, with a 0.32% improvement on\nImageNet compared to HASSKD. Experiments on Tiny ImageNet and CIFAR-100 under\nfew-shot learning scenarios also achieve state-of-the-art results. These\nfindings demonstrate the effectiveness of our approach in enhancing model\ngeneralization and performance without the need for large over-parameterized\nteacher networks. Importantly, at the inference stage, all auxiliary\nclassifiers can be removed, yielding no extra computational cost. This makes\nour model suitable for deploying small language models on affordable\nlow-computing devices. Owing to its lightweight design and adaptability, our\nframework is particularly suitable for multimodal sensing and cyber-physical\nenvironments that require efficient and responsive inference. LSSKD facilitates\nthe development of intelligent agents capable of learning from limited sensory\ndata under weak supervision.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07055v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07736", "title": "RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards", "authors": ["Jingnan Zheng", "Xiangtian Ji", "Yijun Lu", "Chenhang Cui", "Weixiang Zhao", "Gelei Deng", "Zhenkai Liang", "An Zhang", "Tat-Seng Chua"], "summary": "Large Language Models (LLMs) continue to exhibit vulnerabilities despite\ndeliberate safety alignment efforts, posing significant risks to users and\nsociety. To safeguard against the risk of policy-violating content,\nsystem-level moderation via external guard models-designed to monitor LLM\ninputs and outputs and block potentially harmful content-has emerged as a\nprevalent mitigation strategy. Existing approaches of training guard models\nrely heavily on extensive human curated datasets and struggle with\nout-of-distribution threats, such as emerging harmful categories or jailbreak\nattacks. To address these limitations, we propose RSafe, an adaptive\nreasoning-based safeguard that conducts guided safety reasoning to provide\nrobust protection within the scope of specified safety policies. RSafe operates\nin two stages: 1) guided reasoning, where it analyzes safety risks of input\ncontent through policy-guided step-by-step reasoning, and 2) reinforced\nalignment, where rule-based RL optimizes its reasoning paths to align with\naccurate safety prediction. This two-stage training paradigm enables RSafe to\ninternalize safety principles to generalize safety protection capability over\nunseen or adversarial safety violation scenarios. During inference, RSafe\naccepts user-specified safety policies to provide enhanced safeguards tailored\nto specific safety requirements.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07736v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06809", "title": "IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder", "authors": ["Di Lin", "Wanjing Ren", "Xuanbin Li", "Rui Zhang"], "summary": "Self-supervised learning (SSL) methods have been increasingly applied to\ndiverse downstream tasks due to their superior generalization capabilities and\nlow annotation costs. However, most existing heterogeneous graph SSL models\nconvert heterogeneous graphs into homogeneous ones via meta-paths for training,\nwhich only leverage information from nodes at both ends of meta-paths while\nunderutilizing the heterogeneous node information along the meta-paths. To\naddress this limitation, this paper proposes a novel framework named IMPA-HGAE\nto enhance target node embeddings by fully exploiting internal node information\nalong meta-paths. Experimental results validate that IMPA-HGAE achieves\nsuperior performance on heterogeneous datasets. Furthermore, this paper\nintroduce innovative masking strategies to strengthen the representational\ncapacity of generative SSL models on heterogeneous graph data. Additionally,\nthis paper discuss the interpretability of the proposed method and potential\nfuture directions for generative self-supervised learning in heterogeneous\ngraphs. This work provides insights into leveraging meta-path-guided structural\nsemantics for robust representation learning in complex graph scenarios.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06809v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06396", "title": "Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things", "authors": ["Christopher D. Molek", "Roberto Fronteddu", "K. Brent Venable", "Niranjan Suri"], "summary": "The expansion of the Internet of Things (IoT) in the battlefield, Internet of\nBattlefield Things (IoBT), gives rise to new opportunities for enhancing\nsituational awareness. To increase the potential of IoBT for situational\nawareness in critical decision making, the data from these devices must be\nprocessed into consumer-ready information objects, and made available to\nconsumers on demand. To address this challenge we propose a workflow that makes\nuse of natural language processing (NLP) to query a database technology and\nreturn a response in natural language. Our solution utilizes Large Language\nModels (LLMs) that are sized for edge devices to perform NLP as well as\ngraphical databases which are well suited for dynamic connected networks which\nare pervasive in the IoBT. Our architecture employs LLMs for both mapping\nquestions in natural language to Cypher database queries as well as to\nsummarize the database output back to the user in natural language. We evaluate\nseveral medium sized LLMs for both of these tasks on a database representing\npublicly available data from the US Army's Multipurpose Sensing Area (MSA) at\nthe Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion\nparameters) outperforms the other models across all the considered metrics.\nMost importantly, we note that, unlike current methods, our two step approach\nallows the relaxation of the Exact Match (EM) requirement of the produced\nCypher queries with ground truth code and, in this way, it achieves a 19.4%\nincrease in accuracy. Our workflow lays the ground work for deploying LLMs on\nedge devices to enable natural language interactions with databases containing\ninformation objects for critical decision making.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06396v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06815", "title": "Path Integral Optimiser: Global Optimisation via Neural Schrödinger-Föllmer Diffusion", "authors": ["Max McGuinness", "Eirik Fladmark", "Francisco Vargas"], "summary": "We present an early investigation into the use of neural diffusion processes\nfor global optimisation, focusing on Zhang et al.'s Path Integral Sampler. One\ncan use the Boltzmann distribution to formulate optimization as solving a\nSchr\\\"odinger bridge sampling problem, then apply Girsanov's theorem with a\nsimple (single-point) prior to frame it in stochastic control terms, and\ncompute the solution's integral terms via a neural approximation (a Fourier\nMLP). We provide theoretical bounds for this optimiser, results on toy\noptimisation tasks, and a summary of the stochastic theory motivating the\nmodel. Ultimately, we found the optimiser to display promising per-step\nperformance at optimisation tasks between 2 and 1,247 dimensions, but struggle\nto explore higher-dimensional spaces when faced with a 15.9k parameter model,\nindicating a need for work on adaptation in such environments.", "comment": "6 pages. Presented at the OPT Workshop, NeurIPS 2024, Vancouver, CA", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06815v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07826", "title": "R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation", "authors": ["William Ljungbergh", "Bernardo Taveira", "Wenzhao Zheng", "Adam Tonderski", "Chensheng Peng", "Fredrik Kahl", "Christoffer Petersson", "Michael Felsberg", "Kurt Keutzer", "Masayoshi Tomizuka", "Wei Zhan"], "summary": "Validating autonomous driving (AD) systems requires diverse and\nsafety-critical testing, making photorealistic virtual environments essential.\nTraditional simulation platforms, while controllable, are resource-intensive to\nscale and often suffer from a domain gap with real-world data. In contrast,\nneural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a\nscalable solution for creating photorealistic digital twins of real-world\ndriving scenes. However, they struggle with dynamic object manipulation and\nreusability as their per-scene optimization-based methodology tends to result\nin incomplete object models with integrated illumination effects. This paper\nintroduces R3D2, a lightweight, one-step diffusion model designed to overcome\nthese limitations and enable realistic insertion of complete 3D assets into\nexisting scenes by generating plausible rendering effects-such as shadows and\nconsistent lighting-in real time. This is achieved by training R3D2 on a novel\ndataset: 3DGS object assets are generated from in-the-wild AD data using an\nimage-conditioned 3D generative model, and then synthetically placed into\nneural rendering-based virtual environments, allowing R3D2 to learn realistic\nintegration. Quantitative and qualitative evaluations demonstrate that R3D2\nsignificantly enhances the realism of inserted assets, enabling use-cases like\ntext-to-3D asset insertion and cross-scene/dataset object transfer, allowing\nfor true scalability in AD validation. To promote further research in scalable\nand realistic AD simulation, we will release our dataset and code, see\nhttps://research.zenseact.com/publications/R3D2/.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07826v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07080", "title": "FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping", "authors": ["Anatol Garioud", "Sébastien Giordano", "Nicolas David", "Nicolas Gonthier"], "summary": "The growing availability of high-quality Earth Observation (EO) data enables\naccurate global land cover and crop type monitoring. However, the volume and\nheterogeneity of these datasets pose major processing and annotation\nchallenges. To address this, the French National Institute of Geographical and\nForest Information (IGN) is actively exploring innovative strategies to exploit\ndiverse EO data, which require large annotated datasets. IGN introduces\nFLAIR-HUB, the largest multi-sensor land cover dataset with\nvery-high-resolution (20 cm) annotations, covering 2528 km2 of France. It\ncombines six aligned modalities: aerial imagery, Sentinel-1/2 time series, SPOT\nimagery, topographic data, and historical aerial images. Extensive benchmarks\nevaluate multimodal fusion and deep learning models (CNNs, transformers) for\nland cover or crop mapping and also explore multi-task learning. Results\nunderscore the complexity of multimodal fusion and fine-grained classification,\nwith best land cover performance (78.2% accuracy, 65.8% mIoU) achieved using\nnearly all modalities. FLAIR-HUB supports supervised and multimodal\npretraining, with data and code available at\nhttps://ignf.github.io/FLAIR/flairhub.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07080v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07759", "title": "REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models", "authors": ["Diego Forniés-Tabuenca", "Alejandro Uribe", "Urtzi Otamendi", "Arkaitz Artetxe", "Juan Carlos Rivera", "Oier Lopez de Lacalle"], "summary": "Multi-objective optimization is fundamental in complex decision-making tasks.\nTraditional algorithms, while effective, often demand extensive\nproblem-specific modeling and struggle to adapt to nonlinear structures. Recent\nadvances in Large Language Models (LLMs) offer enhanced explainability,\nadaptability, and reasoning. This work proposes Reflective Evolution of\nMulti-objective Heuristics (REMoH), a novel framework integrating NSGA-II with\nLLM-based heuristic generation. A key innovation is a reflection mechanism that\nuses clustering and search-space reflection to guide the creation of diverse,\nhigh-quality heuristics, improving convergence and maintaining solution\ndiversity. The approach is evaluated on the Flexible Job Shop Scheduling\nProblem (FJSSP) in-depth benchmarking against state-of-the-art methods using\nthree instance datasets: Dauzere, Barnes, and Brandimarte. Results demonstrate\nthat REMoH achieves competitive results compared to state-of-the-art approaches\nwith reduced modeling effort and enhanced adaptability. These findings\nunderscore the potential of LLMs to augment traditional optimization, offering\ngreater flexibility, interpretability, and robustness in multi-objective\nscenarios.", "comment": "21 pages, 5 tables, 7 figures and 4 appendixes. Pre-print submitted\n  to IEEE Transactions on Evolutionary Computation", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07759v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06853", "title": "Curvature Enhanced Data Augmentation for Regression", "authors": ["Ilya Kaufman Sirot", "Omri Azencot"], "summary": "Deep learning models with a large number of parameters, often referred to as\nover-parameterized models, have achieved exceptional performance across various\ntasks. Despite concerns about overfitting, these models frequently generalize\nwell to unseen data, thanks to effective regularization techniques, with data\naugmentation being among the most widely used. While data augmentation has\nshown great success in classification tasks using label-preserving\ntransformations, its application in regression problems has received less\nattention. Recently, a novel \\emph{manifold learning} approach for generating\nsynthetic data was proposed, utilizing a first-order approximation of the data\nmanifold. Building on this foundation, we present a theoretical framework and\npractical tools for approximating and sampling general data manifolds.\nFurthermore, we introduce the Curvature-Enhanced Manifold Sampling (CEMS)\nmethod for regression tasks. CEMS leverages a second-order representation of\nthe data manifold to enable efficient sampling and reconstruction of new data\npoints. Extensive evaluations across multiple datasets and comparisons with\nstate-of-the-art methods demonstrate that CEMS delivers superior performance in\nboth in-distribution and out-of-distribution scenarios, while introducing only\nminimal computational overhead. Code is available at\nhttps://github.com/azencot-group/CEMS.", "comment": "Accepted to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06853v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06401", "title": "Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs", "authors": ["Hongming Yang", "Shi Lin", "Jun Shao", "Changting Lin", "Donghai Zhu", "Meng Han", "Qinglei Kong"], "summary": "Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized\nmodels designed to run efficiently on consumer-grade hardware, offering\nsignificant advantages in resource efficiency, cost-effectiveness, and data\nprivacy. However, these models often struggle with limited inference and\nreasoning capabilities, which restrict their performance on complex tasks and\nlimit their practical applicability. Moreover, existing prompt optimization\nmethods typically rely on extensive manual effort or the meta-cognitive\nabilities of state-of-the-art LLMs, making them less effective for LwLLMs. To\naddress these challenges, we introduce DeBoP, a new Direct Behavior\nOptimization Paradigm, original from the Chain-of-Thought (CoT) prompting\ntechnique. Unlike CoT Prompting, DeBoP is an automatic optimization method,\nwhich focuses on the optimization directly on the behavior of LwLLMs. In\nparticular, DeBoP transforms the optimization of complex prompts into the\noptimization of discrete, quantifiable execution sequences using a\ngradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging\ntasks where state-of-the-art LLMs excel but LwLLMs generally underperform.\nExperimental results demonstrate that DeBoP significantly outperforms recent\nprompt optimization methods on most tasks. In particular, DeBoP-optimized\nLwLLMs surpass GPT-3.5 on most tasks while reducing computational time by\napproximately 60% compared to other automatic prompt optimization methods.", "comment": "This work is accepted at ACL 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06401v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07857", "title": "LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds", "authors": ["Zihui Zhang", "Weisheng Dai", "Hongtao Wen", "Bo Yang"], "summary": "We study the problem of unsupervised 3D semantic segmentation on raw point\nclouds without needing human labels in training. Existing methods usually\nformulate this problem into learning per-point local features followed by a\nsimple grouping strategy, lacking the ability to discover additional and\npossibly richer semantic priors beyond local features. In this paper, we\nintroduce LogoSP to learn 3D semantics from both local and global point\nfeatures. The key to our approach is to discover 3D semantic information by\ngrouping superpoints according to their global patterns in the frequency\ndomain, thus generating highly accurate semantic pseudo-labels for training a\nsegmentation network. Extensive experiments on two indoor and an outdoor\ndatasets show that our LogoSP surpasses all existing unsupervised methods by\nlarge margins, achieving the state-of-the-art performance for unsupervised 3D\nsemantic segmentation. Notably, our investigation into the learned global\npatterns reveals that they truly represent meaningful 3D semantics in the\nabsence of human labels during training.", "comment": "CVPR 2025. Code and data are available at:\n  https://github.com/vLAR-group/LogoSP", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07857v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07087", "title": "UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning", "authors": ["Weiqi Yan", "Lvhai Chen", "Huaijia Kou", "Shengchuan Zhang", "Yan Zhang", "Liujuan Cao"], "summary": "Unsupervised Camoflaged Object Detection (UCOD) has gained attention since it\ndoesn't need to rely on extensive pixel-level labels. Existing UCOD methods\ntypically generate pseudo-labels using fixed strategies and train 1 x1\nconvolutional layers as a simple decoder, leading to low performance compared\nto fully-supervised methods. We emphasize two drawbacks in these approaches:\n1). The model is prone to fitting incorrect knowledge due to the pseudo-label\ncontaining substantial noise. 2). The simple decoder fails to capture and learn\nthe semantic features of camouflaged objects, especially for small-sized\nobjects, due to the low-resolution pseudo-labels and severe confusion between\nforeground and background pixels. To this end, we propose a UCOD method with a\nteacher-student framework via Dynamic Pseudo-label Learning called UCOD-DPL,\nwhich contains an Adaptive Pseudo-label Module (APM), a Dual-Branch Adversarial\n(DBA) decoder, and a Look-Twice mechanism. The APM module adaptively combines\npseudo-labels generated by fixed strategies and the teacher model to prevent\nthe model from overfitting incorrect knowledge while preserving the ability for\nself-correction; the DBA decoder takes adversarial learning of different\nsegmentation objectives, guides the model to overcome the foreground-background\nconfusion of camouflaged objects, and the Look-Twice mechanism mimics the human\ntendency to zoom in on camouflaged objects and performs secondary refinement on\nsmall-sized objects. Extensive experiments show that our method demonstrates\noutstanding performance, even surpassing some existing fully supervised\nmethods. The code is available now.", "comment": "Accepted by CVPR 2025 (Hightlight)", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07087v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07807", "title": "A Proposal to Extend the Common Model of Cognition with Metacognition", "authors": ["John Laird", "Christian Lebiere", "Paul Rosenbloom", "Andrea Stocco", "Robert Wray"], "summary": "The Common Model of Cognition (CMC) provides an abstract characterization of\nthe structure and processing required by a cognitive architecture for\nhuman-like minds. We propose a unified approach to integrating metacognition\nwithin the CMC. We propose that metacognition involves reasoning over explicit\nrepresentations of an agent's cognitive capabilities and processes in working\nmemory. Our proposal exploits the existing cognitive capabilities of the CMC,\nmaking minimal extensions in the structure and information available within\nworking memory. We provide examples of metacognition within our proposal.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07807v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06858", "title": "High-Fidelity Scientific Simulation Surrogates via Adaptive Implicit Neural Representations", "authors": ["Ziwei Li", "Yuhan Duan", "Tianyu Xiong", "Yi-Tang Chen", "Wei-Lun Chao", "Han-Wei Shen"], "summary": "Effective surrogate models are critical for accelerating scientific\nsimulations. Implicit neural representations (INRs) offer a compact and\ncontinuous framework for modeling spatially structured data, but they often\nstruggle with complex scientific fields exhibiting localized, high-frequency\nvariations. Recent approaches address this by introducing additional features\nalong rigid geometric structures (e.g., grids), but at the cost of flexibility\nand increased model size. In this paper, we propose a simple yet effective\nalternative: Feature-Adaptive INR (FA-INR). FA-INR leverages cross-attention to\nan augmented memory bank to learn flexible feature representations, enabling\nadaptive allocation of model capacity based on data characteristics, rather\nthan rigid structural assumptions. To further improve scalability, we introduce\na coordinate-guided mixture of experts (MoE) that enhances the specialization\nand efficiency of feature representations. Experiments on three large-scale\nensemble simulation datasets show that FA-INR achieves state-of-the-art\nfidelity while significantly reducing model size, establishing a new trade-off\nfrontier between accuracy and compactness for INR-based surrogates.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06858v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07091", "title": "SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model", "authors": ["Yangkai Lin", "Jiabao Lei", "Kui Jia"], "summary": "Our project page: https://scutyklin.github.io/SceneLCM/. Automated generation\nof complex, interactive indoor scenes tailored to user prompt remains a\nformidable challenge. While existing methods achieve indoor scene synthesis,\nthey struggle with rigid editing constraints, physical incoherence, excessive\nhuman effort, single-room limitations, and suboptimal material quality. To\naddress these limitations, we propose SceneLCM, an end-to-end framework that\nsynergizes Large Language Model (LLM) for layout design with Latent Consistency\nModel(LCM) for scene optimization. Our approach decomposes scene generation\ninto four modular pipelines: (1) Layout Generation. We employ LLM-guided 3D\nspatial reasoning to convert textual descriptions into parametric blueprints(3D\nlayout). And an iterative programmatic validation mechanism iteratively refines\nlayout parameters through LLM-mediated dialogue loops; (2) Furniture\nGeneration. SceneLCM employs Consistency Trajectory Sampling(CTS), a\nconsistency distillation sampling loss guided by LCM, to form fast,\nsemantically rich, and high-quality representations. We also offer two\ntheoretical justification to demonstrate that our CTS loss is equivalent to\nconsistency loss and its distillation error is bounded by the truncation error\nof the Euler solver; (3) Environment Optimization. We use a multiresolution\ntexture field to encode the appearance of the scene, and optimize via CTS loss.\nTo maintain cross-geometric texture coherence, we introduce a normal-aware\ncross-attention decoder to predict RGB by cross-attending to the anchors\nlocations in geometrically heterogeneous instance. (4)Physically Editing.\nSceneLCM supports physically editing by integrating physical simulation,\nachieved persistent physical realism. Extensive experiments validate SceneLCM's\nsuperiority over state-of-the-art techniques, showing its wide-ranging\npotential for diverse applications.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07091v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07820", "title": "Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation", "authors": ["Jiaxiang CHen", "Zhuo Wang", "Mingxi Zou", "Qifan Wang", "Zenglin Xu"], "summary": "Human reasoning is flexible, adaptive, and grounded in prior\nexperience-qualities that large language models (LLMs) still struggle to\nemulate. Existing methods either explore diverse reasoning paths at inference\ntime or search for optimal workflows through expensive operations, but both\nfall short in leveraging multiple reusable strategies in a structured,\nefficient manner. We propose Guideline Forest, a framework that enhances LLMs\nreasoning by inducing structured reasoning strategies-called guidelines-from\nverified examples and executing them via step-wise aggregation. Unlike\ntest-time search or single-path distillation, our method draws on verified\nreasoning experiences by inducing reusable guidelines and expanding each into\ndiverse variants. Much like human reasoning, these variants reflect alternative\nthought patterns, are executed in parallel, refined via self-correction, and\naggregated step by step-enabling the model to adaptively resolve uncertainty\nand synthesize robust solutions.We evaluate Guideline Forest on four\nbenchmarks-GSM8K, MATH-500, MBPP, and HumanEval-spanning mathematical and\nprogrammatic reasoning. Guideline Forest consistently outperforms strong\nbaselines, including CoT, ReAct, ToT, FoT, and AFlow. Ablation studies further\nhighlight the effectiveness of multi-path reasoning and stepwise aggregation,\nunderscoring the Guideline Forest's adaptability and generalization potential.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07820v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06406", "title": "SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities", "authors": ["Guoyang Xia", "Yifeng Ding", "Fengfa Li", "Lei Ren", "Chen Wei", "Fangxiang Feng", "Xiaojie Wang"], "summary": "Mixture of Experts (MoE) architectures have become a key approach for scaling\nlarge language models, with growing interest in extending them to multimodal\ntasks. Existing methods to build multimodal MoE models either incur high\ntraining costs or suffer from degraded language capabilities when adapting\npretrained models. To address this, we propose Soft ModalityAware Routing\n(SMAR), a novel regularization technique that uses Kullback Leibler divergence\nto control routing probability distributions across modalities, encouraging\nexpert specialization without modifying model architecture or heavily relying\non textual data. Experiments on visual instruction tuning show that SMAR\npreserves language ability at 86.6% retention with only 2.5% pure text,\noutperforming baselines while maintaining strong multimodal performance. Our\napproach offers a practical and efficient solution to balance modality\ndifferentiation and language capabilities in multimodal MoE models.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06406v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07996", "title": "UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References", "authors": ["Ming-Feng Li", "Xin Yang", "Fu-En Wang", "Hritam Basak", "Yuyin Sun", "Shreekant Gayaka", "Min Sun", "Cheng-Hao Kuo"], "summary": "6D object pose estimation has shown strong generalizability to novel objects.\nHowever, existing methods often require either a complete, well-reconstructed\n3D model or numerous reference images that fully cover the object. Estimating\n6D poses from partial references, which capture only fragments of an object's\nappearance and geometry, remains challenging. To address this, we propose\nUA-Pose, an uncertainty-aware approach for 6D object pose estimation and online\nobject completion specifically designed for partial references. We assume\naccess to either (1) a limited set of RGBD images with known poses or (2) a\nsingle 2D image. For the first case, we initialize a partial object 3D model\nbased on the provided images and poses, while for the second, we use\nimage-to-3D techniques to generate an initial object 3D model. Our method\nintegrates uncertainty into the incomplete 3D model, distinguishing between\nseen and unseen regions. This uncertainty enables confidence assessment in pose\nestimation and guides an uncertainty-aware sampling strategy for online object\ncompletion, enhancing robustness in pose estimation accuracy and improving\nobject completeness. We evaluate our method on the YCB-Video, YCBInEOAT, and\nHO3D datasets, including RGBD sequences of YCB objects manipulated by robots\nand human hands. Experimental results demonstrate significant performance\nimprovements over existing methods, particularly when object observations are\nincomplete or partially captured. Project page:\nhttps://minfenli.github.io/UA-Pose/", "comment": "CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07996v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07112", "title": "EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring", "authors": ["Changhong Fu", "Hua Lin", "Haobo Zuo", "Liangliang Yao", "Liguo Zhang"], "summary": "Text spotting for industrial panels is a key task for intelligent monitoring.\nHowever, achieving efficient and accurate text spotting for complex industrial\npanels remains challenging due to issues such as cross-scale localization and\nambiguous boundaries in dense text regions. Moreover, most existing methods\nprimarily focus on representing a single text shape, neglecting a comprehensive\nexploration of multi-scale feature information across different texts. To\naddress these issues, this work proposes a novel multi-scale dense text spotter\nfor edge AI-based vision system (EdgeSpotter) to achieve accurate and robust\nindustrial panel monitoring. Specifically, a novel Transformer with efficient\nmixer is developed to learn the interdependencies among multi-level features,\nintegrating multi-layer spatial and semantic cues. In addition, a new feature\nsampling with catmull-rom splines is designed, which explicitly encodes the\nshape, position, and semantic information of text, thereby alleviating missed\ndetections and reducing recognition errors caused by multi-scale or dense text\nregions. Furthermore, a new benchmark dataset for industrial panel monitoring\n(IPM) is constructed. Extensive qualitative and quantitative evaluations on\nthis challenging benchmark dataset validate the superior performance of the\nproposed method in different challenging panel monitoring tasks. Finally,\npractical tests based on the self-designed edge AI-based vision system\ndemonstrate the practicality of the method. The code and demo will be available\nat https://github.com/vision4robotics/EdgeSpotter.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07112v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07824", "title": "Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs", "authors": ["Yao Yan"], "summary": "Multi-digit addition is a clear probe of the computational power of large\nlanguage models. To dissect the internal arithmetic processes in\nLLaMA-3-8B-Instruct, we combine linear probing with logit-lens inspection.\nInspired by the step-by-step manner in which humans perform addition, we\npropose and analyze a coherent four-stage trajectory in the forward\npass:Formula-structure representations become linearly decodable first, while\nthe answer token is still far down the candidate list.Core computational\nfeatures then emerge prominently.At deeper activation layers, numerical\nabstractions of the result become clearer, enabling near-perfect detection and\ndecoding of the individual digits in the sum.Near the output, the model\norganizes and generates the final content, with the correct token reliably\noccupying the top rank.This trajectory suggests a hierarchical process that\nfavors internal computation over rote memorization. We release our code and\ndata to facilitate reproducibility.", "comment": "12 pages, including appendix, 7 figures. EMNLP 2025 submission (ARR\n  May 2025 cycle, reviews pending)", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07824v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06866", "title": "SAFE: Finding Sparse and Flat Minima to Improve Pruning", "authors": ["Dongyeop Lee", "Kwanhee Lee", "Jinseok Chung", "Namhoon Lee"], "summary": "Sparsifying neural networks often suffers from seemingly inevitable\nperformance degradation, and it remains challenging to restore the original\nperformance despite much recent progress. Motivated by recent studies in robust\noptimization, we aim to tackle this problem by finding subnetworks that are\nboth sparse and flat at the same time. Specifically, we formulate pruning as a\nsparsity-constrained optimization problem where flatness is encouraged as an\nobjective. We solve it explicitly via an augmented Lagrange dual approach and\nextend it further by proposing a generalized projection operation, resulting in\nnovel pruning methods called SAFE and its extension, SAFE$^+$. Extensive\nevaluations on standard image classification and language modeling tasks reveal\nthat SAFE consistently yields sparse networks with improved generalization\nperformance, which compares competitively to well-established baselines. In\naddition, SAFE demonstrates resilience to noisy data, making it well-suited for\nreal-world conditions.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06866v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07122", "title": "Image segmentation and classification of E-waste for waste segregation", "authors": ["Prakriti Tripathi", "Theertha Biju", "Maniram Thota", "Rakesh Lingam"], "summary": "Industry partners provided a problem statement that involves classifying\nelectronic waste using machine learning models that will be used by\npick-and-place robots for waste segregation. We started by taking common\nelectronic waste items, such as a mouse and charger, unsoldering them, and\ntaking pictures to create a custom dataset. Then state-of-the art YOLOv11 model\nwas trained and run to achieve 70 mAP in real-time. Mask-RCNN model was also\ntrained and achieved 41 mAP. The model will be further integrated with\npick-and-place robots to perform segregation of e-waste.", "comment": "4 pages, 7 figures. For code and link to dataset, see\n  https://github.com/prakriti16/Image-segmentation-and-classification-of-e-waste", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07122v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07837", "title": "HAIBU-ReMUD: Reasoning Multimodal Ultrasound Dataset and Model Bridging to General Specific Domains", "authors": ["Shijie Wang", "Yilun Zhang", "Zeyu Lai", "Dexing Kong"], "summary": "Multimodal large language models (MLLMs) have shown great potential in\ngeneral domains but perform poorly in some specific domains due to a lack of\ndomain-specific data, such as image-text data or vedio-text data. In some\nspecific domains, there is abundant graphic and textual data scattered around,\nbut lacks standardized arrangement. In the field of medical ultrasound, there\nare ultrasonic diagnostic books, ultrasonic clinical guidelines, ultrasonic\ndiagnostic reports, and so on. However, these ultrasonic materials are often\nsaved in the forms of PDF, images, etc., and cannot be directly used for the\ntraining of MLLMs. This paper proposes a novel image-text reasoning supervised\nfine-tuning data generation pipeline to create specific domain quadruplets\n(image, question, thinking trace, and answer) from domain-specific materials. A\nmedical ultrasound domain dataset ReMUD is established, containing over 45,000\nreasoning and non-reasoning supervised fine-tuning Question Answering (QA) and\nVisual Question Answering (VQA) data. The ReMUD-7B model, fine-tuned on\nQwen2.5-VL-7B-Instruct, outperforms general-domain MLLMs in medical ultrasound\nfield. To facilitate research, the ReMUD dataset, data generation codebase, and\nReMUD-7B parameters will be released at https://github.com/ShiDaizi/ReMUD,\naddressing the data shortage issue in specific domain MLLMs.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07837v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06873", "title": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning", "authors": ["Armin Behnamnia", "Gholamali Aminian", "Alireza Aghaei", "Chengchun Shi", "Vincent Y. F. Tan", "Hamid R. Rabiee"], "summary": "Off-policy learning and evaluation leverage logged bandit feedback datasets,\nwhich contain context, action, propensity score, and feedback for each data\npoint. These scenarios face significant challenges due to high variance and\npoor performance with low-quality propensity scores and heavy-tailed reward\ndistributions. We address these issues by introducing a novel estimator based\non the log-sum-exponential (LSE) operator, which outperforms traditional\ninverse propensity score estimators. Our LSE estimator demonstrates variance\nreduction and robustness under heavy-tailed conditions. For off-policy\nevaluation, we derive upper bounds on the estimator's bias and variance. In the\noff-policy learning scenario, we establish bounds on the regret -- the\nperformance gap between our LSE estimator and the optimal policy -- assuming\nbounded $(1+\\epsilon)$-th moment of weighted reward. Notably, we achieve a\nconvergence rate of $O(n^{-\\epsilon/(1+ \\epsilon)})$ for the regret bounds,\nwhere $\\epsilon \\in [0,1]$ and $n$ is the size of logged bandit feedback\ndataset. Theoretical analysis is complemented by comprehensive empirical\nevaluations in both off-policy learning and evaluation scenarios, confirming\nthe practical advantages of our approach. The code for our estimator is\navailable at the following link:\nhttps://github.com/armin-behnamnia/lse-offpolicy-learning.", "comment": "Accepted as spotlight poster in ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06873v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07136", "title": "Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion", "authors": ["Huaize Liu", "Wenzhang Sun", "Qiyuan Zhang", "Donglin Di", "Biao Gong", "Hao Li", "Chen Wei", "Changqing Zou"], "summary": "Recent breakthroughs in video autoencoders (Video AEs) have advanced video\ngeneration, but existing methods fail to efficiently model spatio-temporal\nredundancies in dynamics, resulting in suboptimal compression factors. This\nshortfall leads to excessive training costs for downstream tasks. To address\nthis, we introduce Hi-VAE, an efficient video autoencoding framework that\nhierarchically encode coarse-to-fine motion representations of video dynamics\nand formulate the decoding process as a conditional generation task.\nSpecifically, Hi-VAE decomposes video dynamics into two latent spaces: Global\nMotion, capturing overarching motion patterns, and Detailed Motion, encoding\nhigh-frequency spatial details. Using separate self-supervised motion encoders,\nwe compress video latents into compact motion representations to reduce\nredundancy significantly. A conditional diffusion decoder then reconstructs\nvideos by combining hierarchical global and detailed motions, enabling\nhigh-fidelity video reconstructions. Extensive experiments demonstrate that\nHi-VAE achieves a high compression factor of 1428$\\times$, almost 30$\\times$\nhigher than baseline methods (e.g., Cosmos-VAE at 48$\\times$), validating the\nefficiency of our approach. Meanwhile, Hi-VAE maintains high reconstruction\nquality at such high compression rates and performs effectively in downstream\ngenerative tasks. Moreover, Hi-VAE exhibits interpretability and scalability,\nproviding new perspectives for future exploration in video latent\nrepresentation and generation.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07136v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07853", "title": "A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms", "authors": ["Hudson de Martim"], "summary": "Effectively representing legal norms for automated processing is a critical\nchallenge, particularly in tracking the diachronic evolution of their\nhierarchical components (e.g., articles, paragraphs). While foundational\nframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legal\ndocuments at a macro level, they lack native mechanisms for granular,\ncomponent-level versioning. This limitation hinders the deterministic\npoint-in-time reconstruction of legal texts, a fundamental capability for\nreliable Legal Tech and AI applications. This paper proposes a structured,\ntemporal model that extends the FRBRoo framework to address this gap. It\nintroduces specialized subclasses of Expressio - Temporal Version (TV) and\nLanguage Version (LV - to represent the state of a legal norm and its\nlinguistic variations at specific points in time. The model applies this same\nparadigm hierarchically, introducing Component Work (CW), Component Temporal\nVersion (CTV), and Component Language Version (CLV) to track the lifecycle of\nindividual articles, paragraphs, and clauses. Using the Brazilian Federal\nConstitution as a case study, the paper demonstrates how each amendment creates\nnew Component Temporal Versions for affected provisions, while unaffected\ncomponents retain their existing versions. This fine-grained, time-aware\narchitecture enables the precise, deterministic retrieval and reconstruction of\nany part of a legal text as it existed on a specific date. The model provides a\nrobust foundation for developing advanced legal information systems, knowledge\ngraphs, and AI tools capable of accurate historical analysis and impact\nassessment, overcoming the limitations of current generative models.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07853v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06884", "title": "FREE: Fast and Robust Vision Language Models with Early Exits", "authors": ["Divya Jyoti Bajpai", "Manjesh Kumar Hanawal"], "summary": "In recent years, Vision-Language Models (VLMs) have shown remarkable\nperformance improvements in Vision-Language tasks. However, their large size\nposes challenges for real-world applications where inference latency is a\nconcern. To tackle this issue, we propose employing Early Exit (EE) strategies\nin VLMs. However, training exit classifiers in VLMs is challenging,\nparticularly with limited labeled training data. To address this, we introduce\nFREE, an adversarial training approach within a GAN-based framework. Here, each\nexit consists of a transformer layer and a classifier. The transformer layer is\nadversarially trained to produce feature representations similar to the final\nlayer, while a feature classifier serves as the discriminator. Our method\nfocuses on performing input-adaptive inference that increases inference speed\nwith minimal drop in performance. Experimental results demonstrate the\neffectiveness of our approach in enhancing accuracy and model robustness by\nmitigating overthinking and the phenomenon of mid-crisis that we highlight. We\nexperimentally validate that our method speeds up the inference process by more\nthan 1.51x while retaining comparable performance. The source code is available\nat https://github.com/Div290/FREE.", "comment": "To appear at the Association of Computational Linguistics (ACL) 2025\n  Conference", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06884v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07138", "title": "Learning Compact Vision Tokens for Efficient Large Multimodal Models", "authors": ["Hao Tang", "Chengchao Shen"], "summary": "Large multimodal models (LMMs) suffer significant computational challenges\ndue to the high cost of Large Language Models (LLMs) and the quadratic\ncomplexity of processing long vision token sequences. In this paper, we explore\nthe spatial redundancy among vision tokens and shorten the length of vision\ntoken sequences for inference acceleration. Specifically, we propose a Spatial\nToken Fusion (STF) method to learn compact vision tokens for short vision token\nsequence, where spatial-adjacent tokens are fused into one. Meanwhile,\nweight-frozen vision encoder can not well adapt to the demand of extensive\ndownstream vision-language tasks. To this end, we further introduce a\nMulti-Block Token Fusion (MBTF) module to supplement multi-granularity features\nfor the reduced token sequence. Overall, we combine STF and MBTF module to\nbalance token reduction and information preservation, thereby improving\ninference efficiency without sacrificing multimodal reasoning capabilities.\nExperimental results demonstrate that our method based on LLaVA-1.5 achieves\ncomparable or even superior performance to the baseline on 8 popular\nvision-language benchmarks with only $25\\%$ vision tokens of baseline. The\nsource code and trained weights are available at\nhttps://github.com/visresearch/LLaVA-STF.", "comment": "The source code and trained weights are available at\n  https://github.com/visresearch/LLaVA-STF", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07138v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07896", "title": "Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark", "authors": ["Shoko Oka"], "summary": "Recent advancements in large language models (LLMs) have revitalized\nphilosophical debates surrounding artificial intelligence. Two of the most\nfundamental challenges - namely, the Frame Problem and the Symbol Grounding\nProblem - have historically been viewed as unsolvable within traditional\nsymbolic AI systems. This study investigates whether modern LLMs possess the\ncognitive capacities required to address these problems. To do so, I designed\ntwo benchmark tasks reflecting the philosophical core of each problem,\nadministered them under zero-shot conditions to 13 prominent LLMs (both closed\nand open-source), and assessed the quality of the models' outputs across five\ntrials each. Responses were scored along multiple criteria, including\ncontextual reasoning, semantic coherence, and information filtering. The\nresults demonstrate that while open-source models showed variability in\nperformance due to differences in model size, quantization, and instruction\ntuning, several closed models consistently achieved high scores. These findings\nsuggest that select modern LLMs may be acquiring capacities sufficient to\nproduce meaningful and stable responses to these long-standing theoretical\nchallenges.", "comment": "52 pages, Additional resources available on GitHub repository", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07896v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07155", "title": "GoTrack: Generic 6DoF Object Pose Refinement and Tracking", "authors": ["Van Nguyen Nguyen", "Christian Forster", "Sindi Shkodrani", "Vincent Lepetit", "Bugra Tekin", "Cem Keskin", "Tomas Hodan"], "summary": "We introduce GoTrack, an efficient and accurate CAD-based method for 6DoF\nobject pose refinement and tracking, which can handle diverse objects without\nany object-specific training. Unlike existing tracking methods that rely solely\non an analysis-by-synthesis approach for model-to-frame registration, GoTrack\nadditionally integrates frame-to-frame registration, which saves compute and\nstabilizes tracking. Both types of registration are realized by optical flow\nestimation. The model-to-frame registration is noticeably simpler than in\nexisting methods, relying only on standard neural network blocks (a transformer\nis trained on top of DINOv2) and producing reliable pose confidence scores\nwithout a scoring network. For the frame-to-frame registration, which is an\neasier problem as consecutive video frames are typically nearly identical, we\nemploy a light off-the-shelf optical flow model. We demonstrate that GoTrack\ncan be seamlessly combined with existing coarse pose estimation methods to\ncreate a minimal pipeline that reaches state-of-the-art RGB-only results on\nstandard benchmarks for 6DoF object pose estimation and tracking. Our source\ncode and trained models are publicly available at\nhttps://github.com/facebookresearch/gotrack", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07155v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07915", "title": "LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement", "authors": ["Dimitris Panagopoulos", "Adolfo Perrusquia", "Weisi Guo"], "summary": "In dynamic environments, the rapid obsolescence of pre-existing environmental\nknowledge creates a gap between an agent's internal model and the evolving\nreality of its operational context. This disparity between prior and updated\nenvironmental valuations fundamentally limits the effectiveness of autonomous\ndecision-making. To bridge this gap, the contextual bias of human domain\nstakeholders, who naturally accumulate insights through direct, real-time\nobservation, becomes indispensable. However, translating their nuanced, and\ncontext-rich input into actionable intelligence for autonomous systems remains\nan open challenge. To address this, we propose LUCIFER (Language Understanding\nand Context-Infused Framework for Exploration and Behavior Refinement), a\ndomain-agnostic framework that integrates a hierarchical decision-making\narchitecture with reinforcement learning (RL) and large language models (LLMs)\ninto a unified system. This architecture mirrors how humans decompose complex\ntasks, enabling a high-level planner to coordinate specialised sub-agents, each\nfocused on distinct objectives and temporally interdependent actions. Unlike\ntraditional applications where LLMs are limited to single role, LUCIFER\nintegrates them in two synergistic roles: as context extractors, structuring\nverbal stakeholder input into domain-aware representations that influence\ndecision-making through an attention space mechanism aligning LLM-derived\ninsights with the agent's learning process, and as zero-shot exploration\nfacilitators guiding the agent's action selection process during exploration.\nWe benchmark various LLMs in both roles and demonstrate that LUCIFER improves\nexploration efficiency and decision quality, outperforming flat,\ngoal-conditioned policies. Our findings show the potential of context-driven\ndecision-making, where autonomous systems leverage human contextual knowledge\nfor operational success.", "comment": "12 pages, 4 Figures, 3 Tables, submitted to the IEEE for possible\n  publication", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07915v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06895", "title": "Scalable Gaussian Processes with Latent Kronecker Structure", "authors": ["Jihao Andreas Lin", "Sebastian Ament", "Maximilian Balandat", "David Eriksson", "José Miguel Hernández-Lobato", "Eytan Bakshy"], "summary": "Applying Gaussian processes (GPs) to very large datasets remains a challenge\ndue to limited computational scalability. Matrix structures, such as the\nKronecker product, can accelerate operations significantly, but their\napplication commonly entails approximations or unrealistic assumptions. In\nparticular, the most common path to creating a Kronecker-structured kernel\nmatrix is by evaluating a product kernel on gridded inputs that can be\nexpressed as a Cartesian product. However, this structure is lost if any\nobservation is missing, breaking the Cartesian product structure, which\nfrequently occurs in real-world data such as time series. To address this\nlimitation, we propose leveraging latent Kronecker structure, by expressing the\nkernel matrix of observed values as the projection of a latent Kronecker\nproduct. In combination with iterative linear system solvers and pathwise\nconditioning, our method facilitates inference of exact GPs while requiring\nsubstantially fewer computational resources than standard iterative methods. We\ndemonstrate that our method outperforms state-of-the-art sparse and variational\nGPs on real-world datasets with up to five million examples, including\nrobotics, automated machine learning, and climate applications.", "comment": "International Conference on Machine Learning 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06895v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07164", "title": "Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs", "authors": ["Qiong Chang", "Xinyuan Chen", "Xiang Li", "Weimin Wang", "Jun Miyazaki"], "summary": "The visual-based SLAM (Simultaneous Localization and Mapping) is a technology\nwidely used in applications such as robotic navigation and virtual reality,\nwhich primarily focuses on detecting feature points from visual images to\nconstruct an unknown environmental map and simultaneously determines its own\nlocation. It usually imposes stringent requirements on hardware power\nconsumption, processing speed and accuracy. Currently, the ORB (Oriented FAST\nand Rotated BRIEF)-based SLAM systems have exhibited superior performance in\nterms of processing speed and robustness. However, they still fall short of\nmeeting the demands for real-time processing on mobile platforms. This\nlimitation is primarily due to the time-consuming Oriented FAST calculations\naccounting for approximately half of the entire SLAM system. This paper\npresents two methods to accelerate the Oriented FAST feature detection on\nlow-end embedded GPUs. These methods optimize the most time-consuming steps in\nOriented FAST feature detection: FAST feature point detection and Harris corner\ndetection, which is achieved by implementing a binary-level encoding strategy\nto determine candidate points quickly and a separable Harris detection strategy\nwith efficient low-level GPU hardware-specific instructions. Extensive\nexperiments on a Jetson TX2 embedded GPU demonstrate an average speedup of over\n7.3 times compared to widely used OpenCV with GPU support. This significant\nimprovement highlights its effectiveness and potential for real-time\napplications in mobile and resource-constrained environments.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07164v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07927", "title": "Solving Inequality Proofs with Large Language Models", "authors": ["Jiayi Sheng", "Luna Lyu", "Jikai Jin", "Tony Xia", "Alex Gu", "James Zou", "Pan Lu"], "summary": "Inequality proving, crucial across diverse scientific and mathematical\nfields, tests advanced reasoning skills such as discovering tight bounds and\nstrategic theorem application. This makes it a distinct, demanding frontier for\nlarge language models (LLMs), offering insights beyond general mathematical\nproblem-solving. Progress in this area is hampered by existing datasets that\nare often scarce, synthetic, or rigidly formal. We address this by proposing an\ninformal yet verifiable task formulation, recasting inequality proving into two\nautomatically checkable subtasks: bound estimation and relation prediction.\nBuilding on this, we release IneqMath, an expert-curated dataset of\nOlympiad-level inequalities, including a test set and training corpus enriched\nwith step-wise solutions and theorem annotations. We also develop a novel\nLLM-as-judge evaluation framework, combining a final-answer judge with four\nstep-wise judges designed to detect common reasoning flaws. A systematic\nevaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even\ntop models like o1 achieve less than 10% overall accuracy under step-wise\nscrutiny; this is a drop of up to 65.5% from their accuracy considering only\nfinal answer equivalence. This discrepancy exposes fragile deductive chains and\na critical gap for current LLMs between merely finding an answer and\nconstructing a rigorous proof. Scaling model size and increasing test-time\ncomputation yield limited gains in overall proof correctness. Instead, our\nfindings highlight promising research directions such as theorem-guided\nreasoning and self-refinement. Code and data are available at\nhttps://ineqmath.github.io/.", "comment": "52 pages, 16 figures", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07927v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06907", "title": "Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations", "authors": ["Fred Xu", "Thomas Markovich"], "summary": "Graph Neural Networks have achieved impressive results across diverse network\nmodeling tasks, but accurately estimating uncertainty on graphs remains\ndifficult, especially under distributional shifts. Unlike traditional\nuncertainty estimation, graph-based uncertainty must account for randomness\narising from both the graph's structure and its label distribution, which adds\ncomplexity. In this paper, making an analogy between the evolution of a\nstochastic partial differential equation (SPDE) driven by Matern Gaussian\nProcess and message passing using GNN layers, we present a principled way to\ndesign a novel message passing scheme that incorporates spatial-temporal noises\nmotivated by the Gaussian Process approach to SPDE. Our method simultaneously\ncaptures uncertainty across space and time and allows explicit control over the\ncovariance kernel smoothness, thereby enhancing uncertainty estimates on graphs\nwith both low and high label informativeness. Our extensive experiments on\nOut-of-Distribution (OOD) detection on graph datasets with varying label\ninformativeness demonstrate the soundness and superiority of our model to\nexisting approaches.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06907v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06440", "title": "Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation", "authors": ["Chuhao Chen", "Zhiyang Dou", "Chen Wang", "Yiming Huang", "Anjun Chen", "Qiao Feng", "Jiatao Gu", "Lingjie Liu"], "summary": "Faithfully reconstructing textured shapes and physical properties from videos\npresents an intriguing yet challenging problem. Significant efforts have been\ndedicated to advancing such a system identification problem in this area.\nPrevious methods often rely on heavy optimization pipelines with a\ndifferentiable simulator and renderer to estimate physical parameters. However,\nthese approaches frequently necessitate extensive hyperparameter tuning for\neach scene and involve a costly optimization process, which limits both their\npracticality and generalizability. In this work, we propose a novel framework,\nVid2Sim, a generalizable video-based approach for recovering geometry and\nphysical properties through a mesh-free reduced simulation based on Linear\nBlend Skinning (LBS), offering high computational efficiency and versatile\nrepresentation capability. Specifically, Vid2Sim first reconstructs the\nobserved configuration of the physical system from video using a feed-forward\nneural network trained to capture physical world knowledge. A lightweight\noptimization pipeline then refines the estimated appearance, geometry, and\nphysical properties to closely align with video observations within just a few\nminutes. Additionally, after the reconstruction, Vid2Sim enables high-quality,\nmesh-free simulation with high efficiency. Extensive experiments demonstrate\nthat our method achieves superior accuracy and efficiency in reconstructing\ngeometry and physical properties from video data.", "comment": "Accepted by CVPR 2025", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.06440v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07177", "title": "Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models", "authors": ["Sangwon Jang", "Taekyung Ki", "Jaehyeong Jo", "Jaehong Yoon", "Soo Ye Kim", "Zhe Lin", "Sung Ju Hwang"], "summary": "Advancements in diffusion models have significantly improved video quality,\ndirecting attention to fine-grained controllability. However, many existing\nmethods depend on fine-tuning large-scale video models for specific tasks,\nwhich becomes increasingly impractical as model sizes continue to grow. In this\nwork, we present Frame Guidance, a training-free guidance for controllable\nvideo generation based on frame-level signals, such as keyframes, style\nreference images, sketches, or depth maps. For practical training-free\nguidance, we propose a simple latent processing method that dramatically\nreduces memory usage, and apply a novel latent optimization strategy designed\nfor globally coherent video generation. Frame Guidance enables effective\ncontrol across diverse tasks, including keyframe guidance, stylization, and\nlooping, without any training, compatible with any video models. Experimental\nresults show that Frame Guidance can produce high-quality controlled videos for\na wide range of tasks and input signals.", "comment": "Project page: https://frame-guidance-video.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07177v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07940", "title": "Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation", "authors": ["Christopher Subia-Waud"], "summary": "Foundation model fine-tuning faces a fundamental challenge: existing AutoML\nplatforms rely on single optimisation strategies that explore only a fraction\nof viable hyperparameter configurations. In this white paper, We introduce\nGradients, a decentralised AutoML platform that transforms hyperparameter\noptimisation into a competitive marketplace where independent miners compete to\ndiscover optimal configurations. Economic incentives align individual\nexploration with collective optimisation goals, driving systematic\ninvestigation of hyperparameter regions that centralised methods miss. We\nevaluate our approach across 180 controlled experiments spanning diverse model\narchitectures (70M to 70B parameters) and task types. Gradients achieves an\n82.8\\% win rate against HuggingFace AutoTrain and 100\\% against TogetherAI,\nDatabricks, and Google Cloud, with mean improvements of 11.8\\% and 42.1\\%\nrespectively. Complex reasoning and retrieval tasks show particularly strong\ngains of 30-40\\%, whilst diffusion models achieve 23.4\\% improvements for\nperson-specific generation. These results demonstrate that competitive,\neconomically-driven approaches can systematically discover superior\nconfigurations that centralised AutoML consistently miss.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07940v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06917", "title": "Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data", "authors": ["Shangjie Du", "Hui Wei", "Dong Yoon Lee", "Zhizhang Hu", "Shijia Pan"], "summary": "This work introduces GraPhy, a graph-based, physics-guided learning framework\nfor high-resolution and accurate air quality modeling in urban areas with\nlimited monitoring data. Fine-grained air quality monitoring information is\nessential for reducing public exposure to pollutants. However, monitoring\nnetworks are often sparse in socioeconomically disadvantaged regions, limiting\nthe accuracy and resolution of air quality modeling. To address this, we\npropose a physics-guided graph neural network architecture called GraPhy with\nlayers and edge features designed specifically for low-resolution monitoring\ndata. Experiments using data from California's socioeconomically disadvantaged\nSan Joaquin Valley show that GraPhy achieves the overall best performance\nevaluated by mean squared error (MSE), mean absolute error (MAE), and R-square\nvalue (R2), improving the performance by 9%-56% compared to various baseline\nmodels. Moreover, GraPhy consistently outperforms baselines across different\nspatial heterogeneity levels, demonstrating the effectiveness of our model\ndesign.", "comment": "Accepted by ACM Transactions on Sensor Networks (TOSN) 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06917v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07188", "title": "Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks", "authors": ["Ni Ding", "Lei He", "Shengbo Eben Li", "Keqiang Li"], "summary": "End-to-end autonomous driving has emerged as a dominant paradigm, yet its\nhighly entangled black-box models pose significant challenges in terms of\ninterpretability and safety assurance. To improve model transparency and\ntraining flexibility, this paper proposes a hierarchical and decoupled\npost-training framework tailored for pretrained neural networks. By\nreconstructing intermediate feature maps from ground-truth labels, surrogate\nsupervisory signals are introduced at transitional layers to enable independent\ntraining of specific components, thereby avoiding the complexity and coupling\nof conventional end-to-end backpropagation and providing interpretable insights\ninto networks' internal mechanisms. To the best of our knowledge, this is the\nfirst method to formalize feature-level reverse computation as well-posed\noptimization problems, which we rigorously reformulate as systems of linear\nequations or least squares problems. This establishes a novel and efficient\ntraining paradigm that extends gradient backpropagation to feature\nbackpropagation. Extensive experiments on multiple standard image\nclassification benchmarks demonstrate that the proposed method achieves\nsuperior generalization performance and computational efficiency compared to\ntraditional training approaches, validating its effectiveness and potential.", "comment": "13 pages, 7 figures,", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07188v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07963", "title": "Reinforcing Multimodal Understanding and Generation with Dual Self-rewards", "authors": ["Jixiang Hong", "Yiran Zhang", "Guanzhong Wang", "Yi Liu", "Ji-Rong Wen", "Rui Yan"], "summary": "Building upon large language models (LLMs), recent large multimodal models\n(LMMs) unify cross-model understanding and generation into a single framework.\nHowever, LMMs still struggle to achieve accurate image-text alignment, prone to\ngenerating text responses contradicting the visual input or failing to follow\nthe text-to-image prompts. Current solutions require external supervision\n(e.g., human feedback or reward models) and only address unidirectional\ntasks-either understanding or generation. In this work, based on the\nobservation that understanding and generation are inverse dual tasks, we\nintroduce a self-supervised dual reward mechanism to reinforce the\nunderstanding and generation capabilities of LMMs. Specifically, we sample\nmultiple outputs for a given input in one task domain, then reverse the\ninput-output pairs to compute the dual likelihood of the model as self-rewards\nfor optimization. Extensive experimental results on visual understanding and\ngeneration benchmarks demonstrate that our method can effectively enhance the\nperformance of the model without any external supervision, especially achieving\nremarkable improvements in text-to-image tasks.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07963v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06926", "title": "Basis Transformers for Multi-Task Tabular Regression", "authors": ["Wei Min Loh", "Jiaqi Shang", "Pascal Poupart"], "summary": "Dealing with tabular data is challenging due to partial information, noise,\nand heterogeneous structure. Existing techniques often struggle to\nsimultaneously address key aspects of tabular data such as textual information,\na variable number of columns, and unseen data without metadata besides column\nnames. We propose a novel architecture, \\textit{basis transformers},\nspecifically designed to tackle these challenges while respecting inherent\ninvariances in tabular data, including hierarchical structure and the\nrepresentation of numeric values. We evaluate our design on a multi-task\ntabular regression benchmark, achieving an improvement of 0.338 in the median\n$R^2$ score and the lowest standard deviation across 34 tasks from the\nOpenML-CTR23 benchmark. Furthermore, our model has five times fewer parameters\nthan the best-performing baseline and surpasses pretrained large language model\nbaselines -- even when initialized from randomized weights.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06926v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07196", "title": "SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning", "authors": ["Mengya Xu", "Zhongzhen Huang", "Dillan Imans", "Yiru Ye", "Xiaofan Zhang", "Qi Dou"], "summary": "Effective evaluation is critical for driving advancements in MLLM research.\nThe surgical action planning (SAP) task, which aims to generate future action\nsequences from visual inputs, demands precise and sophisticated analytical\ncapabilities. Unlike mathematical reasoning, surgical decision-making operates\nin life-critical domains and requires meticulous, verifiable processes to\nensure reliability and patient safety. This task demands the ability to\ndistinguish between atomic visual actions and coordinate complex, long-horizon\nprocedures, capabilities that are inadequately evaluated by current benchmarks.\nTo address this gap, we introduce SAP-Bench, a large-scale, high-quality\ndataset designed to enable multimodal large language models (MLLMs) to perform\ninterpretable surgical action planning. Our SAP-Bench benchmark, derived from\nthe cholecystectomy procedures context with the mean duration of 1137.5s, and\nintroduces temporally-grounded surgical action annotations, comprising the\n1,226 clinically validated action clips (mean duration: 68.7s) capturing five\nfundamental surgical actions across 74 procedures. The dataset provides 1,152\nstrategically sampled current frames, each paired with the corresponding next\naction as multimodal analysis anchors. We propose the MLLM-SAP framework that\nleverages MLLMs to generate next action recommendations from the current\nsurgical scene and natural language instructions, enhanced with injected\nsurgical domain knowledge. To assess our dataset's effectiveness and the\nbroader capabilities of current models, we evaluate seven state-of-the-art\nMLLMs (e.g., OpenAI-o1, GPT-4o, QwenVL2.5-72B, Claude-3.5-Sonnet, GeminiPro2.5,\nStep-1o, and GLM-4v) and reveal critical gaps in next action prediction\nperformance.", "comment": "11 pages, 4 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07196v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07982", "title": "$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment", "authors": ["Victor Barres", "Honghua Dong", "Soham Ray", "Xujie Si", "Karthik Narasimhan"], "summary": "Existing benchmarks for conversational AI agents simulate single-control\nenvironments, where only the AI agent can use tools to interact with the world,\nwhile the user remains a passive information provider. This differs from\nreal-world scenarios like technical support, where users need to actively\nparticipate in modifying the state of the (shared) world. In order to address\nthis gap, we introduce $\\tau^2$-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both\nagent and user make use of tools to act in a shared, dynamic environment that\ntests both agent coordination and communication,\n  2) A compositional task generator that programmatically creates diverse,\nverifiable tasks from atomic components, ensuring domain coverage and\ncontrolled complexity,\n  3) A reliable user simulator tightly coupled with the environment, whose\nbehavior is constrained by tools and observable states, improving simulation\nfidelity,\n  4) Fine-grained analysis of agent performance through multiple ablations\nincluding separating errors arising from reasoning vs\ncommunication/coordination.\n  In particular, our experiments show significant performance drops when agents\nshift from no-user to dual-control, highlighting the challenges of guiding\nusers. Overall, $\\tau^2$-bench provides a controlled testbed for agents that\nmust both reason effectively and guide user actions.", "comment": null, "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.07982v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06446", "title": "Canonical Autoregressive Generation", "authors": ["Ivi Chatzi", "Nina Corvelo Benz", "Stratis Tsirtsis", "Manuel Gomez-Rodriguez"], "summary": "State of the art large language models are trained using large amounts of\ntokens derived from raw text using what is called a tokenizer. Crucially, the\ntokenizer determines the (token) vocabulary a model will use during inference\nas well as, in principle, the (token) language. This is because, while the\ntoken vocabulary may allow for different tokenizations of a string, the\ntokenizer always maps the string to only one of these tokenizations--the\ncanonical tokenization. However, multiple lines of empirical evidence suggest\nthat large language models do not always generate canonical token sequences,\nand this comes with several negative consequences. In this work, we first show\nthat, to generate a canonical token sequence, a model needs to generate\n(partial) canonical token sequences at each step of the autoregressive\ngeneration process underpinning its functioning. Building upon this theoretical\nresult, we introduce canonical sampling, a simple and efficient sampling method\nthat precludes a given model from generating non-canonical token sequences.\nFurther, we also show that, in comparison with standard sampling, the\ndistribution of token sequences generated using canonical sampling is provably\ncloser to the true distribution of token sequences used during training.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06446v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07205", "title": "TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation", "authors": ["Min-Jung Kim", "Dongjin Kim", "Seokju Yun", "Jaegul Choo"], "summary": "Video editing has garnered increasing attention alongside the rapid progress\nof diffusion-based video generation models. As part of these advancements,\nthere is a growing demand for more accessible and controllable forms of video\nediting, such as prompt-based editing. Previous studies have primarily focused\non tasks such as style transfer, background replacement, object substitution,\nand attribute modification, while maintaining the content structure of the\nsource video. However, more complex tasks, including the addition of novel\nobjects and nonrigid transformations, remain relatively unexplored. In this\npaper, we present TV-LiVE, a Training-free and text-guided Video editing\nframework via Layerinformed Vitality Exploitation. We empirically identify\nvital layers within the video generation model that significantly influence the\nquality of generated outputs. Notably, these layers are closely associated with\nRotary Position Embeddings (RoPE). Based on this observation, our method\nenables both object addition and non-rigid video editing by selectively\ninjecting key and value features from the source model into the corresponding\nlayers of the target model guided by the layer vitality. For object addition,\nwe further identify prominent layers to extract the mask regions corresponding\nto the newly added target prompt. We found that the extracted masks from the\nprominent layers faithfully indicate the region to be edited. Experimental\nresults demonstrate that TV-LiVE outperforms existing approaches for both\nobject addition and non-rigid video editing. Project Page:\nhttps://emjay73.github.io/TV_LiVE/", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07205v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08012", "title": "GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior", "authors": ["Penghao Wu", "Shengnan Ma", "Bo Wang", "Jiaheng Yu", "Lewei Lu", "Ziwei Liu"], "summary": "Multimodal Large Language Models (MLLMs) have shown great potential in\nrevolutionizing Graphical User Interface (GUI) automation. However, existing\nGUI models mostly rely on learning from nearly error-free offline trajectories,\nthus lacking reflection and error recovery capabilities. To bridge this gap, we\npropose GUI-Reflection, a novel framework that explicitly integrates\nself-reflection and error correction capabilities into end-to-end multimodal\nGUI models throughout dedicated training stages: GUI-specific pre-training,\noffline supervised fine-tuning (SFT), and online reflection tuning.\nGUI-reflection enables self-reflection behavior emergence with fully automated\ndata generation and learning processes without requiring any human annotation.\nSpecifically, 1) we first propose scalable data pipelines to automatically\nconstruct reflection and error correction data from existing successful\ntrajectories. While existing GUI models mainly focus on grounding and UI\nunderstanding ability, we propose the GUI-Reflection Task Suite to learn and\nevaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a\ndiverse and efficient environment for online training and data collection of\nGUI models on mobile devices. 3) We also present an iterative online reflection\ntuning algorithm leveraging the proposed environment, enabling the model to\ncontinuously enhance its reflection and error correction abilities. Our\nframework equips GUI agents with self-reflection and correction capabilities,\npaving the way for more robust, adaptable, and intelligent GUI automation, with\nall data, models, environments, and tools to be released publicly.", "comment": "Project Page at https://penghao-wu.github.io/GUI_Reflection/", "cate": "cs.AI", "url": "http://arxiv.org/abs/2506.08012v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06940", "title": "Understanding Sharpness Dynamics in NN Training with a Minimalist Example: The Effects of Dataset Difficulty, Depth, Stochasticity, and More", "authors": ["Geonhui Yoo", "Minhak Song", "Chulhee Yun"], "summary": "When training deep neural networks with gradient descent, sharpness often\nincreases -- a phenomenon known as progressive sharpening -- before saturating\nat the edge of stability. Although commonly observed in practice, the\nunderlying mechanisms behind progressive sharpening remain poorly understood.\nIn this work, we study this phenomenon using a minimalist model: a deep linear\nnetwork with a single neuron per layer. We show that this simple model\neffectively captures the sharpness dynamics observed in recent empirical\nstudies, offering a simple testbed to better understand neural network\ntraining. Moreover, we theoretically analyze how dataset properties, network\ndepth, stochasticity of optimizers, and step size affect the degree of\nprogressive sharpening in the minimalist model. We then empirically demonstrate\nhow these theoretical insights extend to practical scenarios. This study offers\na deeper understanding of sharpness dynamics in neural network training,\nhighlighting the interplay between depth, training data, and optimizers.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06940v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2309.11082", "title": "Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning", "authors": ["Chen Jiang", "Hong Liu", "Xuzheng Yu", "Qing Wang", "Yuan Cheng", "Jia Xu", "Zhongyi Liu", "Qingpei Guo", "Wei Chu", "Ming Yang", "Yuan Qi"], "summary": "In recent years, the explosion of web videos makes text-video retrieval\nincreasingly essential and popular for video filtering, recommendation, and\nsearch. Text-video retrieval aims to rank relevant text/video higher than\nirrelevant ones. The core of this task is to precisely measure the cross-modal\nsimilarity between texts and videos. Recently, contrastive learning methods\nhave shown promising results for text-video retrieval, most of which focus on\nthe construction of positive and negative pairs to learn text and video\nrepresentations. Nevertheless, they do not pay enough attention to hard\nnegative pairs and lack the ability to model different levels of semantic\nsimilarity. To address these two issues, this paper improves contrastive\nlearning using two novel techniques. First, to exploit hard examples for robust\ndiscriminative power, we propose a novel Dual-Modal Attention-Enhanced Module\n(DMAE) to mine hard negative pairs from textual and visual clues. By further\nintroducing a Negative-aware InfoNCE (NegNCE) loss, we are able to adaptively\nidentify all these hard negatives and explicitly highlight their impacts in the\ntraining loss. Second, our work argues that triplet samples can better model\nfine-grained semantic similarity compared to pairwise samples. We thereby\npresent a new Triplet Partial Margin Contrastive Learning (TPM-CL) module to\nconstruct partial order triplet samples by automatically generating\nfine-grained hard negatives for matched text-video pairs. The proposed TPM-CL\ndesigns an adaptive token masking strategy with cross-modal interaction to\nmodel subtle semantic differences. Extensive experiments demonstrate that the\nproposed approach outperforms existing methods on four widely-used text-video\nretrieval datasets, including MSR-VTT, MSVD, DiDeMo and ActivityNet.", "comment": "Accepted by ACM MM 2023", "cate": "cs.CV", "url": "http://arxiv.org/abs/2309.11082v3", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07216", "title": "AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?", "authors": ["Nada Aboudeshish", "Dmitry Ignatov", "Radu Timofte"], "summary": "Data augmentation is a crucial technique in deep learning, particularly for\ntasks with limited dataset diversity, such as skeleton-based datasets. This\npaper proposes a comprehensive data augmentation framework that integrates\ngeometric transformations, random cropping, rotation, zooming and\nintensity-based transformations, brightness and contrast adjustments to\nsimulate real-world variations. Random cropping ensures the preservation of\nspatio-temporal integrity while addressing challenges such as viewpoint bias\nand occlusions. The augmentation pipeline generates three augmented versions\nfor each sample in addition to the data set sample, thus quadrupling the data\nset size and enriching the diversity of gesture representations. The proposed\naugmentation strategy is evaluated on three models: multi-stream e2eET, FPPR\npoint cloud-based hand gesture recognition (HGR), and DD-Network. Experiments\nare conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB.\nThe e2eET model, recognized as the state-of-the-art for hand gesture\nrecognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-best\nperforming model on SHREC'17, excels in point cloud-based gesture recognition.\nDD-Net, a lightweight and efficient architecture for skeleton-based action\nrecognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB).\nThe results underline the effectiveness and versatility of the proposed\naugmentation strategy, significantly improving model generalization and\nrobustness across diverse datasets and architectures. This framework not only\nestablishes state-of-the-art results on all three evaluated models but also\noffers a scalable solution to advance HGR and action recognition applications\nin real-world scenarios. The framework is available at\nhttps://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07216v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2406.00971", "title": "MiniGPT-Reverse-Designing: Predicting Image Adjustments Utilizing MiniGPT-4", "authors": ["Vahid Azizi", "Fatemeh Koochaki"], "summary": "Vision-Language Models (VLMs) have recently seen significant advancements\nthrough integrating with Large Language Models (LLMs). The VLMs, which process\nimage and text modalities simultaneously, have demonstrated the ability to\nlearn and understand the interaction between images and texts across various\nmulti-modal tasks. Reverse designing, which could be defined as a complex\nvision-language task, aims to predict the edits and their parameters, given a\nsource image, an edited version, and an optional high-level textual edit\ndescription. This task requires VLMs to comprehend the interplay between the\nsource image, the edited version, and the optional textual context\nsimultaneously, going beyond traditional vision-language tasks. In this paper,\nwe extend and fine-tune MiniGPT-4 for the reverse designing task. Our\nexperiments demonstrate the extensibility of off-the-shelf VLMs, specifically\nMiniGPT-4, for more complex tasks such as reverse designing. Code is available\nat this \\href{https://github.com/VahidAz/MiniGPT-Reverse-Designing}", "comment": "8 pages, 7 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2406.00971v2", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06977", "title": "UdonCare: Hierarchy Pruning for Unseen Domain Discovery in Predictive Healthcare", "authors": ["Pengfei Hu", "Xiaoxue Han", "Fei Wang", "Yue Ning"], "summary": "Domain generalization has become a critical challenge in clinical prediction,\nwhere patient cohorts often exhibit shifting data distributions that degrade\nmodel performance. Typical domain generalization approaches struggle in\nreal-world healthcare settings for two main reasons: (1) patient-specific\ndomain labels are typically unavailable, making domain discovery especially\ndifficult; (2) purely data-driven approaches overlook key clinical insights,\nleading to a gap in medical knowledge integration. To address these problems,\nwe leverage hierarchical medical ontologies like the ICD-9-CM hierarchy to\ngroup diseases into higher-level categories and discover more flexible latent\ndomains. In this paper, we introduce UdonCare, a hierarchy-guided framework\nthat iteratively prunes fine-grained domains, encodes these refined domains,\nand applies a Siamese-type inference mechanism to separate domain-related\nsignals from patient-level features. Experimental results on clinical datasets\n(MIMIC-III and MIMIC-IV) show that the proposed model achieves higher\nperformance compared to other domain generalization baselines when substantial\ndomain gaps presents, highlighting the untapped potential of medical knowledge\nfor enhancing domain generalization in practical healthcare applications.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06977v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07227", "title": "Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning", "authors": ["Tianyi Bai", "Yuxuan Fan", "Jiantao Qiu", "Fupeng Sun", "Jiayi Song", "Junlin Han", "Zichen Liu", "Conghui He", "Wentao Zhang", "Binhang Yuan"], "summary": "Multimodal large language models (MLLMs) have achieved strong performance on\nvision-language tasks but still struggle with fine-grained visual differences,\nleading to hallucinations or missed semantic shifts. We attribute this to\nlimitations in both training data and learning objectives. To address these\nissues, we propose a controlled data generation pipeline that produces\nminimally edited image pairs with semantically aligned captions. Using this\npipeline, we construct the Micro Edit Dataset (MED), containing over 50K\nimage-text pairs spanning 11 fine-grained edit categories, including attribute,\ncount, position, and object presence changes. Building on MED, we introduce a\nsupervised fine-tuning (SFT) framework with a feature-level consistency loss\nthat promotes stable visual embeddings under small edits. We evaluate our\napproach on the Micro Edit Detection benchmark, which includes carefully\nbalanced evaluation pairs designed to test sensitivity to subtle visual\nvariations across the same edit categories. Our method improves difference\ndetection accuracy and reduces hallucinations compared to strong baselines,\nincluding GPT-4o. Moreover, it yields consistent gains on standard\nvision-language tasks such as image captioning and visual question answering.\nThese results demonstrate the effectiveness of combining targeted data and\nalignment objectives for enhancing fine-grained visual reasoning in MLLMs.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07227v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2411.12262", "title": "Low-resource Machine Translation: what for? who for? An observational study on a dedicated Tetun language translation service", "authors": ["Raphael Merx", "Adérito José Guterres Correia", "Hanna Suominen", "Ekaterina Vylomova"], "summary": "Low-resource machine translation (MT) presents a diversity of community needs\nand application challenges that remain poorly understood. To complement surveys\nand focus groups, which tend to rely on small samples of respondents, we\npropose an observational study on actual usage patterns of tetun$.$org, a\nspecialized MT service for the Tetun language, which is the lingua franca in\nTimor-Leste. Our analysis of 100,000 translation requests reveals patterns that\nchallenge assumptions based on existing corpora. We find that users, many of\nthem students on mobile devices, typically translate text from a high-resource\nlanguage into Tetun across diverse domains including science, healthcare, and\ndaily life. This contrasts sharply with available Tetun corpora, which are\ndominated by news articles covering government and social issues. Our results\nsuggest that MT systems for institutionalized minority languages like Tetun\nshould prioritize accuracy on domains relevant to educational contexts, in the\nhigh-resource to low-resource direction. More broadly, this study demonstrates\nhow observational analysis can inform low-resource language technology\ndevelopment, by grounding research in practical community needs.", "comment": "to be published in LoResMT 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2411.12262v4", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06978", "title": "Near Optimal Non-asymptotic Sample Complexity of 1-Identification", "authors": ["Zitian Li", "Wang Chi Cheung"], "summary": "Motivated by an open direction in existing literature, we study the\n1-identification problem, a fundamental multi-armed bandit formulation on pure\nexploration. The goal is to determine whether there exists an arm whose mean\nreward is at least a known threshold $\\mu_0$, or to output None if it believes\nsuch an arm does not exist. The agent needs to guarantee its output is correct\nwith probability at least $1-\\delta$. Degenne & Koolen 2019 has established the\nasymptotically tight sample complexity for the 1-identification problem, but\nthey commented that the non-asymptotic analysis remains unclear. We design a\nnew algorithm Sequential-Exploration-Exploitation (SEE), and conduct\ntheoretical analysis from the non-asymptotic perspective. Novel to the\nliterature, we achieve near optimality, in the sense of matching upper and\nlower bounds on the pulling complexity. The gap between the upper and lower\nbounds is up to a polynomial logarithmic factor. The numerical result also\nindicates the effectiveness of our algorithm, compared to existing benchmarks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06978v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06451", "title": "A Koopman-backstepping approach to data-driven robust output regulation for linear parabolic systems", "authors": ["Joachim Deutscher", "Julian Zimmer"], "summary": "In this paper a solution of the data-driven robust output regulation problem\nfor linear parabolic systems is presented. Both the system as well as the ODE,\ni.e., the disturbance model, describing the disturbances are unknown, but\nfinite-time sequential data obtained from measurements of the output to be\ncontrolled and additional boundary outputs are available. The data-driven\ncontroller is designed in the Koopman operator framework for PDEs, where the\nKoopman modes and eigenvalues are obtained from data using Hankel-DMD. It is\nshown that all system parameters and the eigenvalues of the disturbance model\ncan be recovered from the available measurements by solving an inverse\nSturm-Liouville problem. This allows to directly apply backstepping methods for\nthe robust regulator design. For this, closed-loop stability in the presence of\nsmall errors in the Hankel-DMD is verified in the nominal case. Robust output\nregulation is shown for non-destabilizing model uncertainties. A numerical\nexample demonstrates the results of the paper.", "comment": "11 pages, 3 figures", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06451v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07235", "title": "Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification", "authors": ["Tianyi Bai", "Zengjie Hu", "Fupeng Sun", "Jiantao Qiu", "Yizhen Jiang", "Guangxin He", "Bohan Zeng", "Conghui He", "Binhang Yuan", "Wentao Zhang"], "summary": "Multi-modal large language models (MLLMs) have achieved remarkable\ncapabilities by integrating visual perception with language understanding,\nenabling applications such as image-grounded dialogue, visual question\nanswering, and scientific analysis. However, most MLLMs adopt a static\ninference paradigm, encoding the entire image into fixed visual tokens upfront,\nwhich limits their ability to iteratively refine understanding or adapt to\ncontext during inference. This contrasts sharply with human perception, which\nis dynamic, selective, and feedback-driven. In this work, we introduce a novel\nframework for inference-time visual token scaling that enables MLLMs to perform\niterative, verifier-guided reasoning over visual content. We formulate the\nproblem as a Markov Decision Process, involving a reasoner that proposes visual\nactions and a verifier, which is trained via multi-step Direct Preference\nOptimization (DPO), that evaluates these actions and determines when reasoning\nshould terminate. To support this, we present a new dataset, VTS, comprising\nsupervised reasoning trajectories (VTS-SFT) and preference-labeled reasoning\ncomparisons (VTS-DPO). Our method significantly outperforms existing approaches\nacross diverse visual reasoning benchmarks, offering not only improved accuracy\nbut also more interpretable and grounded reasoning processes. These results\ndemonstrate the promise of dynamic inference mechanisms for enabling\nfine-grained, context-aware visual reasoning in next-generation MLLMs.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07235v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.04762", "title": "GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "summary": "Large language models (LLMs)-based query expansion for information retrieval\naugments queries with generated hypothetical documents with LLMs. However, its\nperformance relies heavily on the scale of the language models (LMs),\nnecessitating larger, more advanced LLMs. This approach is costly,\ncomputationally intensive, and often has limited accessibility. To address\nthese limitations, we introduce GOLFer - Smaller LMs-Generated Documents\nHallucination Filter & Combiner - a novel method leveraging smaller open-source\nLMs for query expansion. GOLFer comprises two modules: a hallucination filter\nand a documents combiner. The former detects and removes non-factual and\ninconsistent sentences in generated documents, a common issue with smaller LMs,\nwhile the latter combines the filtered content with the query using a weight\nvector to balance their influence. We evaluate GOLFer alongside dominant\nLLM-based query expansion methods on three web search and ten low-resource\ndatasets. Experimental results demonstrate that GOLFer consistently outperforms\nother methods using smaller LMs, and maintains competitive performance against\nmethods using large-size LLMs, demonstrating its effectiveness.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.04762v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06980", "title": "MoXGATE: Modality-aware cross-attention for multi-omic gastrointestinal cancer sub-type classification", "authors": ["Sajib Acharjee Dip", "Uddip Acharjee Shuvo", "Dipanwita Mallick", "Abrar Rahman Abir", "Liqing Zhang"], "summary": "Cancer subtype classification is crucial for personalized treatment and\nprognostic assessment. However, effectively integrating multi-omic data remains\nchallenging due to the heterogeneous nature of genomic, epigenomic, and\ntranscriptomic features. In this work, we propose Modality-Aware\nCross-Attention MoXGATE, a novel deep-learning framework that leverages\ncross-attention and learnable modality weights to enhance feature fusion across\nmultiple omics sources. Our approach effectively captures inter-modality\ndependencies, ensuring robust and interpretable integration. Through\nexperiments on Gastrointestinal Adenocarcinoma (GIAC) and Breast Cancer (BRCA)\ndatasets from TCGA, we demonstrate that MoXGATE outperforms existing methods,\nachieving 95\\% classification accuracy. Ablation studies validate the\neffectiveness of cross-attention over simple concatenation and highlight the\nimportance of different omics modalities. Moreover, our model generalizes well\nto unseen cancer types e.g., breast cancer, underscoring its adaptability. Key\ncontributions include (1) a cross-attention-based multi-omic integration\nframework, (2) modality-weighted fusion for enhanced interpretability, (3)\napplication of focal loss to mitigate data imbalance, and (4) validation across\nmultiple cancer subtypes. Our results indicate that MoXGATE is a promising\napproach for multi-omic cancer subtype classification, offering improved\nperformance and biological generalizability.", "comment": "9 pages, 1 figure, 6 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06980v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06452", "title": "Efficient Computation of Closed Substrings", "authors": ["Samkith K Jain", "Neerja Mhaskar"], "summary": "A closed string $u$ is either of length one or contains a border that occurs\nonly as a prefix and as a suffix in $u$ and nowhere else within $u$. In this\npaper, we present a fast and practical $O(n\\log n)$ time algorithm to compute\nall $\\Theta(n^2)$ closed substrings by introducing a compact representation for\nall closed substrings of a string $ w[1..n]$, using only $O(n \\log n)$ space.\nWe also present a simple and space-efficient solution to compute all maximal\nclosed substrings (MCSs) using the suffix array ($\\mathsf{SA}$) and the longest\ncommon prefix ($\\mathsf{LCP}$) array of $w[1..n]$. Finally, we show that the\nexact number of MCSs ($M(f_n)$) in a Fibonacci word $ f_n $, for $n \\geq 5$, is\n$\\approx \\left(1 + \\frac{1}{\\phi^2}\\right) F_n \\approx 1.382 F_n$, where $ \\phi\n$ is the golden ratio.", "comment": "Submitted to SPIRE 2025", "cate": "cs.DS", "url": "http://arxiv.org/abs/2506.06452v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07280", "title": "From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models", "authors": ["Pablo Acuaviva", "Aram Davtyan", "Mariam Hassan", "Sebastian Stapf", "Ahmad Rahimi", "Alexandre Alahi", "Paolo Favaro"], "summary": "Video Diffusion Models (VDMs) have emerged as powerful generative tools,\ncapable of synthesizing high-quality spatiotemporal content. Yet, their\npotential goes far beyond mere video generation. We argue that the training\ndynamics of VDMs, driven by the need to model coherent sequences, naturally\npushes them to internalize structured representations and an implicit\nunderstanding of the visual world. To probe the extent of this internal\nknowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs\nfor new tasks using only a handful of examples. Our method transforms each task\ninto a visual transition, enabling the training of LoRA weights on short\ninput-output sequences without altering the generative interface of a frozen\nVDM. Despite minimal supervision, the model exhibits strong generalization\nacross diverse tasks, from low-level vision (for example, segmentation and pose\nestimation) to high-level reasoning (for example, on ARC-AGI). These results\nreframe VDMs as more than generative engines. They are adaptable visual\nlearners with the potential to serve as the backbone for future foundation\nmodels in vision.", "comment": "27 pages, 23 figures, 9 tables", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07280v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06276", "title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis", "authors": ["Jiatao Gu", "Tianrong Chen", "David Berthelot", "Huangjie Zheng", "Yuyang Wang", "Ruixiang Zhang", "Laurent Dinh", "Miguel Angel Bautista", "Josh Susskind", "Shuangfei Zhai"], "summary": "We present STARFlow, a scalable generative model based on normalizing flows\nthat achieves strong performance in high-resolution image synthesis. The core\nof STARFlow is Transformer Autoregressive Flow (TARFlow), which combines the\nexpressive power of normalizing flows with the structured modeling capabilities\nof Autoregressive Transformers. We first establish the theoretical universality\nof TARFlow for modeling continuous distributions. Building on this foundation,\nwe introduce several key architectural and algorithmic innovations to\nsignificantly enhance scalability: (1) a deep-shallow design, wherein a deep\nTransformer block captures most of the model representational capacity,\ncomplemented by a few shallow Transformer blocks that are computationally\nefficient yet substantially beneficial; (2) modeling in the latent space of\npretrained autoencoders, which proves more effective than direct pixel-level\nmodeling; and (3) a novel guidance algorithm that significantly boosts sample\nquality. Crucially, our model remains an end-to-end normalizing flow, enabling\nexact maximum likelihood training in continuous spaces without discretization.\nSTARFlow achieves competitive performance in both class-conditional and\ntext-conditional image generation tasks, approaching state-of-the-art diffusion\nmodels in sample quality. To our knowledge, this work is the first successful\ndemonstration of normalizing flows operating effectively at this scale and\nresolution.", "comment": "TLDR: We show for the first time that normalizing flows can be scaled\n  for high-resolution and text-conditioned image synthesis", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.06276v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06986", "title": "Fully Explainable Classification Models Using Hyperblocks", "authors": ["Austin Snyder", "Ryan Gallagher", "Boris Kovalerchuk"], "summary": "Building on existing work with Hyperblocks, which classify data using minimum\nand maximum bounds for each attribute, we focus on enhancing interpretability,\ndecreasing training time, and reducing model complexity without sacrificing\naccuracy. This system allows subject matter experts (SMEs) to directly inspect\nand understand the model's decision logic without requiring extensive machine\nlearning expertise. To reduce Hyperblock complexity while retaining\nperformance, we introduce a suite of algorithms for Hyperblock simplification.\nThese include removing redundant attributes, removing redundant blocks through\noverlap analysis, and creating disjunctive units. These methods eliminate\nunnecessary parameters, dramatically reducing model size without harming\nclassification power. We increase robustness by introducing an interpretable\nfallback mechanism using k-Nearest Neighbor (k-NN) classifiers for points not\ncovered by any block, ensuring complete data coverage while preserving model\ntransparency. Our results demonstrate that interpretable models can scale to\nhigh-dimensional, large-volume datasets while maintaining competitive accuracy.\nOn benchmark datasets such as WBC (9-D), we achieve strong predictive\nperformance with significantly reduced complexity. On MNIST (784-D), our method\ncontinues to improve through tuning and simplification, showing promise as a\ntransparent alternative to black-box models in domains where trust, clarity,\nand control are crucial.", "comment": "7 pages, 8 figures, 6 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06986v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07304", "title": "FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos", "authors": ["Kavitha Viswanathan", "Vrinda Goel", "Shlesh Gholap", "Devayan Ghosh", "Madhav Gupta", "Dhruvi Ganatra", "Sanket Potdar", "Amit Sethi"], "summary": "Real-world surveillance often renders faces and license plates unrecognizable\nin individual low-resolution (LR) frames, hindering reliable identification. To\nadvance temporal recognition models, we present FANVID, a novel video-based\nbenchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63\nidentities and 49 license plates from three English-speaking countries. Each\nvideo includes distractor faces and plates, increasing task difficulty and\nrealism. The dataset contains 31,096 manually verified bounding boxes and\nlabels.\n  FANVID defines two tasks: (1) face matching -- detecting LR faces and\nmatching them to high-resolution mugshots, and (2) license plate recognition --\nextracting text from LR plates without a predefined database. Videos are\ndownsampled from high-resolution sources to ensure that faces and text are\nindecipherable in single frames, requiring models to exploit temporal\ninformation. We introduce evaluation metrics adapted from mean Average\nPrecision at IoU > 0.5, prioritizing identity correctness for faces and\ncharacter-level accuracy for text.\n  A baseline method with pre-trained video super-resolution, detection, and\nrecognition achieved performance scores of 0.58 (face matching) and 0.42 (plate\nrecognition), highlighting both the feasibility and challenge of the tasks.\nFANVID's selection of faces and plates balances diversity with recognition\nchallenge. We release the software for data access, evaluation, baseline, and\nannotation to support reproducibility and extension. FANVID aims to catalyze\ninnovation in temporal modeling for LR recognition, with applications in\nsurveillance, forensics, and autonomous vehicles.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07304v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06990", "title": "Modified K-means Algorithm with Local Optimality Guarantees", "authors": ["Mingyi Li", "Michael R. Metel", "Akiko Takeda"], "summary": "The K-means algorithm is one of the most widely studied clustering algorithms\nin machine learning. While extensive research has focused on its ability to\nachieve a globally optimal solution, there still lacks a rigorous analysis of\nits local optimality guarantees. In this paper, we first present conditions\nunder which the K-means algorithm converges to a locally optimal solution.\nBased on this, we propose simple modifications to the K-means algorithm which\nensure local optimality in both the continuous and discrete sense, with the\nsame computational complexity as the original K-means algorithm. As the\ndissimilarity measure, we consider a general Bregman divergence, which is an\nextension of the squared Euclidean distance often used in the K-means\nalgorithm. Numerical experiments confirm that the K-means algorithm does not\nalways find a locally optimal solution in practice, while our proposed methods\nprovide improved locally optimal solutions with reduced clustering loss. Our\ncode is available at https://github.com/lmingyi/LO-K-means.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06990v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06456", "title": "Sample and Expand: Discovering Low-rank Submatrices With Quality Guarantees", "authors": ["Martino Ciaperoni", "Aristides Gionis", "Heikki Mannila"], "summary": "The problem of approximating a matrix by a low-rank one has been extensively\nstudied. This problem assumes, however, that the whole matrix has a low-rank\nstructure. This assumption is often false for real-world matrices. We consider\nthe problem of discovering submatrices from the given matrix with bounded\ndeviations from their low-rank approximations. We introduce an effective\ntwo-phase method for this task: first, we use sampling to discover small nearly\nlow-rank submatrices, and then they are expanded while preserving proximity to\na low-rank approximation. An extensive experimental evaluation confirms that\nthe method we introduce compares favorably to existing approaches.", "comment": null, "cate": "cs.DS", "url": "http://arxiv.org/abs/2506.06456v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07310", "title": "AllTracker: Efficient Dense Point Tracking at High Resolution", "authors": ["Adam W. Harley", "Yang You", "Xinglong Sun", "Yang Zheng", "Nikhil Raghuraman", "Yunqi Gu", "Sheldon Liang", "Wen-Hsuan Chu", "Achal Dave", "Pavel Tokmakov", "Suya You", "Rares Ambrus", "Katerina Fragkiadaki", "Leonidas J. Guibas"], "summary": "We introduce AllTracker: a model that estimates long-range point tracks by\nway of estimating the flow field between a query frame and every other frame of\na video. Unlike existing point tracking methods, our approach delivers\nhigh-resolution and dense (all-pixel) correspondence fields, which can be\nvisualized as flow maps. Unlike existing optical flow methods, our approach\ncorresponds one frame to hundreds of subsequent frames, rather than just the\nnext frame. We develop a new architecture for this task, blending techniques\nfrom existing work in optical flow and point tracking: the model performs\niterative inference on low-resolution grids of correspondence estimates,\npropagating information spatially via 2D convolution layers, and propagating\ninformation temporally via pixel-aligned attention layers. The model is fast\nand parameter-efficient (16 million parameters), and delivers state-of-the-art\npoint tracking accuracy at high resolution (i.e., tracking 768x1024 pixels, on\na 40G GPU). A benefit of our design is that we can train on a wider set of\ndatasets, and we find that doing so is crucial for top performance. We provide\nan extensive ablation study on our architecture details and training recipe,\nmaking it clear which details matter most. Our code and model weights are\navailable at https://alltracker.github.io .", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07310v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06288", "title": "DELPHYNE: A Pre-Trained Model for General and Financial Time Series", "authors": ["Xueying Ding", "Aakriti Mittal", "Achintya Gopal"], "summary": "Time-series data is a vital modality within data science communities. This is\nparticularly valuable in financial applications, where it helps in detecting\npatterns, understanding market behavior, and making informed decisions based on\nhistorical data. Recent advances in language modeling have led to the rise of\ntime-series pre-trained models that are trained on vast collections of datasets\nand applied to diverse tasks across financial domains. However, across\nfinancial applications, existing time-series pre-trained models have not shown\nboosts in performance over simple finance benchmarks in both zero-shot and\nfine-tuning settings. This phenomenon occurs because of a i) lack of financial\ndata within the pre-training stage, and ii) the negative transfer effect due to\ninherently different time-series patterns across domains. Furthermore,\ntime-series data is continuous, noisy, and can be collected at varying\nfrequencies and with varying lags across different variables, making this data\nmore challenging to model than languages. To address the above problems, we\nintroduce a Pre-trained MoDEL for FINance TimE-series (Delphyne). Delphyne\nachieves competitive performance to existing foundation and full-shot models\nwith few fine-tuning steps on publicly available datasets, and also shows\nsuperior performances on various financial tasks.", "comment": null, "cate": "q-fin.ST", "url": "http://arxiv.org/abs/2506.06288v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06999", "title": "Towards Physics-informed Diffusion for Anomaly Detection in Trajectories", "authors": ["Arun Sharma", "Mingzhou Yang", "Majid Farhadloo", "Subhankar Ghosh", "Bharat Jayaprakash", "Shashi Shekhar"], "summary": "Given trajectory data, a domain-specific study area, and a user-defined\nthreshold, we aim to find anomalous trajectories indicative of possible GPS\nspoofing (e.g., fake trajectory). The problem is societally important to curb\nillegal activities in international waters, such as unauthorized fishing and\nillicit oil transfers. The problem is challenging due to advances in AI\ngenerated in deep fakes generation (e.g., additive noise, fake trajectories)\nand lack of adequate amount of labeled samples for ground-truth verification.\nRecent literature shows promising results for anomalous trajectory detection\nusing generative models despite data sparsity. However, they do not consider\nfine-scale spatiotemporal dependencies and prior physical knowledge, resulting\nin higher false-positive rates. To address these limitations, we propose a\nphysics-informed diffusion model that integrates kinematic constraints to\nidentify trajectories that do not adhere to physical laws. Experimental results\non real-world datasets in the maritime and urban domains show that the proposed\nframework results in higher prediction accuracy and lower estimation error rate\nfor anomaly detection and trajectory generation methods, respectively. Our\nimplementation is available at\nhttps://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.06999v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07327", "title": "\"CASE: Contrastive Activation for Saliency Estimation", "authors": ["Dane Williamson", "Yangfeng Ji", "Matthew Dwyer"], "summary": "Saliency methods are widely used to visualize which input features are deemed\nrelevant to a model's prediction. However, their visual plausibility can\nobscure critical limitations. In this work, we propose a diagnostic test for\nclass sensitivity: a method's ability to distinguish between competing class\nlabels on the same input. Through extensive experiments, we show that many\nwidely used saliency methods produce nearly identical explanations regardless\nof the class label, calling into question their reliability. We find that\nclass-insensitive behavior persists across architectures and datasets,\nsuggesting the failure mode is structural rather than model-specific. Motivated\nby these findings, we introduce CASE, a contrastive explanation method that\nisolates features uniquely discriminative for the predicted class. We evaluate\nCASE using the proposed diagnostic and a perturbation-based fidelity test, and\nshow that it produces faithful and more class-specific explanations than\nexisting methods.", "comment": "9 pages, 5 figures. Submitted to IEEE Transactions on Neural Networks\n  and Learning Systems (TNNLS)", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07327v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06462", "title": "Splat and Replace: 3D Reconstruction with Repetitive Elements", "authors": ["Nicolás Violante", "Andreas Meuleman", "Alban Gauthier", "Frédo Durand", "Thibault Groueix", "George Drettakis"], "summary": "We leverage repetitive elements in 3D scenes to improve novel view synthesis.\nNeural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have greatly\nimproved novel view synthesis but renderings of unseen and occluded parts\nremain low-quality if the training views are not exhaustive enough. Our key\nobservation is that our environment is often full of repetitive elements. We\npropose to leverage those repetitions to improve the reconstruction of\nlow-quality parts of the scene due to poor coverage and occlusions. We propose\na method that segments each repeated instance in a 3DGS reconstruction,\nregisters them together, and allows information to be shared among instances.\nOur method improves the geometry while also accounting for appearance\nvariations across instances. We demonstrate our method on a variety of\nsynthetic and real scenes with typical repetitive elements, leading to a\nsubstantial improvement in the quality of novel view synthesis.", "comment": "SIGGRAPH Conference Papers 2025. Project site:\n  https://repo-sam.inria.fr/nerphys/splat-and-replace/", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.06462v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07014", "title": "Comparison of Lightweight Methods for Vehicle Dynamics-Based Driver Drowsiness Detection", "authors": ["Yutaro Nakagama", "Daisuke Ishii", "Kazuki Yoshizoe"], "summary": "Driver drowsiness detection (DDD) prevents road accidents caused by driver\nfatigue. Vehicle dynamics-based DDD has been proposed as a method that is both\neconomical and high performance. However, there are concerns about the\nreliability of performance metrics and the reproducibility of many of the\nexisting methods. For instance, some previous studies seem to have a data\nleakage issue among training and test datasets, and many do not openly provide\nthe datasets they used. To this end, this paper aims to compare the performance\nof representative vehicle dynamics-based DDD methods under a transparent and\nfair framework that uses a public dataset. We first develop a framework for\nextracting features from an open dataset by Aygun et al. and performing DDD\nwith lightweight ML models; the framework is carefully designed to support a\nvariety of onfigurations. Second, we implement three existing representative\nmethods and a concise random forest (RF)-based method in the framework.\nFinally, we report the results of experiments to verify the reproducibility and\nclarify the performance of DDD based on common metrics. Among the evaluated\nmethods, the RF-based method achieved the highest accuracy of 88 %. Our\nfindings imply the issues inherent in DDD methods developed in a non-standard\nmanner, and demonstrate a high performance method implemented appropriately.", "comment": "8 pages, 3 figures, to be published at IV 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07014v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07357", "title": "CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms", "authors": ["Satvik Praveen", "Yoonsung Jung"], "summary": "Object detection is vital in precision agriculture for plant monitoring,\ndisease detection, and yield estimation. However, models like YOLO struggle\nwith occlusions, irregular structures, and background noise, reducing detection\naccuracy. While Spatial Transformer Networks (STNs) improve spatial invariance\nthrough learned transformations, affine mappings are insufficient for non-rigid\ndeformations such as bent leaves and overlaps.\n  We propose CBAM-STN-TPS-YOLO, a model integrating Thin-Plate Splines (TPS)\ninto STNs for flexible, non-rigid spatial transformations that better align\nfeatures. Performance is further enhanced by the Convolutional Block Attention\nModule (CBAM), which suppresses background noise and emphasizes relevant\nspatial and channel-wise features.\n  On the occlusion-heavy Plant Growth and Phenotyping (PGP) dataset, our model\noutperforms STN-YOLO in precision, recall, and mAP. It achieves a 12% reduction\nin false positives, highlighting the benefits of improved spatial flexibility\nand attention-guided refinement. We also examine the impact of the TPS\nregularization parameter in balancing transformation smoothness and detection\nperformance.\n  This lightweight model improves spatial awareness and supports real-time edge\ndeployment, making it ideal for smart farming applications requiring accurate\nand efficient monitoring.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07357v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07364", "title": "Multiple Object Stitching for Unsupervised Representation Learning", "authors": ["Chengchao Shen", "Dawei Liu", "Jianxin Wang"], "summary": "Contrastive learning for single object centric images has achieved remarkable\nprogress on unsupervised representation, but suffering inferior performance on\nthe widespread images with multiple objects. In this paper, we propose a simple\nbut effective method, Multiple Object Stitching (MOS), to refine the\nunsupervised representation for multi-object images. Specifically, we construct\nthe multi-object images by stitching the single object centric ones, where the\nobjects in the synthesized multi-object images are predetermined. Hence,\ncompared to the existing contrastive methods, our method provides additional\nobject correspondences between multi-object images without human annotations.\nIn this manner, our method pays more attention to the representations of each\nobject in multi-object image, thus providing more detailed representations for\ncomplicated downstream tasks, such as object detection and semantic\nsegmentation. Experimental results on ImageNet, CIFAR and COCO datasets\ndemonstrate that our proposed method achieves the leading unsupervised\nrepresentation performance on both single object centric images and\nmulti-object ones. The source code is available at\nhttps://github.com/visresearch/MultipleObjectStitching.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07364v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07033", "title": "Mixture Experts with Test-Time Self-Supervised Aggregation for Tabular Imbalanced Regression", "authors": ["Yung-Chien Wang", "Kuang-Da Wang", "Wei-Yao Wang", "Wen-Chih Peng"], "summary": "Tabular data serve as a fundamental and ubiquitous representation of\nstructured information in numerous real-world applications, e.g., finance and\nurban planning. In the realm of tabular imbalanced applications, data imbalance\nhas been investigated in classification tasks with insufficient instances in\ncertain labels, causing the model's ineffective generalizability. However, the\nimbalance issue of tabular regression tasks is underexplored, and yet is\ncritical due to unclear boundaries for continuous labels and simplifying\nassumptions in existing imbalance regression work, which often rely on known\nand balanced test distributions. Such assumptions may not hold in practice and\ncan lead to performance degradation. To address these issues, we propose MATI:\nMixture Experts with Test-Time Self-Supervised Aggregation for Tabular\nImbalance Regression, featuring two key innovations: (i) the Region-Aware\nMixture Expert, which adopts a Gaussian Mixture Model to capture the underlying\nrelated regions. The statistical information of each Gaussian component is then\nused to synthesize and train region-specific experts to capture the unique\ncharacteristics of their respective regions. (ii) Test-Time Self-Supervised\nExpert Aggregation, which dynamically adjusts region expert weights based on\ntest data features to reinforce expert adaptation across varying test\ndistributions. We evaluated MATI on four real-world tabular imbalance\nregression datasets, including house pricing, bike sharing, and age prediction.\nTo reflect realistic deployment scenarios, we adopted three types of test\ndistributions: a balanced distribution with uniform target frequencies, a\nnormal distribution that follows the training data, and an inverse distribution\nthat emphasizes rare target regions. On average across these three test\ndistributions, MATI achieved a 7.1% improvement in MAE compared to existing\nmethods.", "comment": "Preprint", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07033v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06471", "title": "Energy-stable Port-Hamiltonian Systems", "authors": ["Patrick Buchfink", "Silke Glas", "Hans Zwart"], "summary": "We combine energy-stable and port-Hamiltonian (pH) systems to obtain\nenergy-stable port-Hamiltonian (espH) systems. The idea is to extend the known\nenergy-stable systems with an input-output port, which results in a pH\nformulation. One advantage of the new espH formulation is that it naturally\npreserves its espH structure throughout discretization (in space and time) and\nmodel reduction.", "comment": "10 pages", "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06471v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07368", "title": "C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation", "authors": ["Jiaying He", "Yitong Lin", "Jiahe Chen", "Honghui Xu", "Jianwei Zheng"], "summary": "For the immanent challenge of insufficiently annotated samples in the medical\nfield, semi-supervised medical image segmentation (SSMIS) offers a promising\nsolution. Despite achieving impressive results in delineating primary target\nareas, most current methodologies struggle to precisely capture the subtle\ndetails of boundaries. This deficiency often leads to significant diagnostic\ninaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised\nsegmentation model that synergistically integrates complementary competition\nand contrastive selection. This design significantly sharpens boundary\ndelineation and enhances overall precision. Specifically, we develop an\n$\\textit{Outcome-Driven Contrastive Learning}$ module dedicated to refining\nboundary localization. Additionally, we incorporate a $\\textit{Dynamic\nComplementary Competition}$ module that leverages two high-performing\nsub-networks to generate pseudo-labels, thereby further improving segmentation\nquality. The proposed C3S3 undergoes rigorous validation on two publicly\naccessible datasets, encompassing the practices of both MRI and CT scans. The\nresults demonstrate that our method achieves superior performance compared to\nprevious cutting-edge competitors. Especially, on the 95HD and ASD metrics, our\napproach achieves a notable improvement of at least $6\\%$, highlighting the\nsignificant advancements. The code is available at\nhttps://github.com/Y-TARL/C3S3.", "comment": "6 pages, 4 figures, ICME2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07368v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07040", "title": "Efficient $Q$-Learning and Actor-Critic Methods for Robust Average Reward Reinforcement Learning", "authors": ["Yang Xu", "Swetha Ganesh", "Vaneet Aggarwal"], "summary": "We present the first $Q$-learning and actor-critic algorithms for robust\naverage reward Markov Decision Processes (MDPs) with non-asymptotic convergence\nunder contamination, TV distance and Wasserstein distance uncertainty sets. We\nshow that the robust $Q$ Bellman operator is a strict contractive mapping with\nrespect to a carefully constructed semi-norm with constant functions being\nquotiented out. This property supports a stochastic approximation update, that\nlearns the optimal robust $Q$ function in $\\tilde{\\cO}(\\epsilon^{-2})$ samples.\nWe also show that the same idea can be used for robust $Q$ function estimation,\nwhich can be further used for critic estimation. Coupling it with theories in\nrobust policy mirror descent update, we present a natural actor-critic\nalgorithm that attains an $\\epsilon$-optimal robust policy in\n$\\tilde{\\cO}(\\epsilon^{-3})$ samples. These results advance the theory of\ndistributionally robust reinforcement learning in the average reward setting.", "comment": "arXiv admin note: text overlap with arXiv:2502.16816", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07040v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07369", "title": "Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding", "authors": ["Bolin Chen", "Shanzhi Yin", "Goluck Konuko", "Giuseppe Valenzise", "Zihan Zhang", "Shiqi Wang", "Yan Ye"], "summary": "The rise of deep generative models has greatly advanced video compression,\nreshaping the paradigm of face video coding through their powerful capability\nfor semantic-aware representation and lifelike synthesis. Generative Face Video\nCoding (GFVC) stands at the forefront of this revolution, which could\ncharacterize complex facial dynamics into compact latent codes for bitstream\ncompactness at the encoder side and leverages powerful deep generative models\nto reconstruct high-fidelity face signal from the compressed latent codes at\nthe decoder side. As such, this well-designed GFVC paradigm could enable\nhigh-fidelity face video communication at ultra-low bitrate ranges, far\nsurpassing the capabilities of the latest Versatile Video Coding (VVC)\nstandard. To pioneer foundational research and accelerate the evolution of\nGFVC, this paper presents the first comprehensive survey of GFVC technologies,\nsystematically bridging critical gaps between theoretical innovation and\nindustrial standardization. In particular, we first review a broad range of\nexisting GFVC methods with different feature representations and optimization\nstrategies, and conduct a thorough benchmarking analysis. In addition, we\nconstruct a large-scale GFVC-compressed face video database with subjective\nMean Opinion Scores (MOSs) based on human perception, aiming to identify the\nmost appropriate quality metrics tailored to GFVC. Moreover, we summarize the\nGFVC standardization potentials with a unified high-level syntax and develop a\nlow-complexity GFVC system which are both expected to push forward future\npractical deployments and applications. Finally, we envision the potential of\nGFVC in industrial applications and deliberate on the current challenges and\nfuture opportunities.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07369v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06473", "title": "RadioGami: Batteryless, Long-Range Wireless Paper Sensors Using Tunnel Diodes", "authors": ["Imran Fahad", "Danny Scott", "Azizul Zahid", "Matthew Bringle", "Srinayana Patil", "Ella Bevins", "Carmen Palileo", "Sai Swaminathan"], "summary": "Paper-based interactive RF devices have opened new possibilities for wireless\nsensing, yet they are typically constrained by short operational ranges. This\npaper introduces RadioGami, a method for creating long-range, batteryless RF\nsensing surfaces on paper using low-cost, DIY materials like copper tape,\npaper, and off-the-shelf electronics paired with an affordable radio receiver\n(approx. $20). We explore the design space enabled by RadioGami, including\nsensing paper deformations like bending, tearing, and origami patterns (Miura,\nKresling) at ranges up to 45.73 meters. RadioGami employs a novel ultra-low\npower (35uW) switching circuit with a tunnel diode for wireless functionality.\nThese surfaces can sustainably operate by harvesting energy using tiny\nphotodiodes. We demonstrate applications that monitor object status, track user\ninteractions (rotation, sliding), and detect environmental changes. We\ncharacterize performance, sensitivity, range, and power consumption with\ndeployment studies. RadioGami advances sustainable, tangible, and batteryless\ninterfaces for embodied interaction.", "comment": "The paper is published in the Proceedings of the ACM on Interactive,\n  Mobile, Wearable and Ubiquitous Technologies (IMWUT) and will be presented at\n  UbiComp 2025", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.06473v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07371", "title": "ARGUS: Hallucination and Omission Evaluation in Video-LLMs", "authors": ["Ruchit Rawal", "Reza Shirkavand", "Heng Huang", "Gowthami Somepalli", "Tom Goldstein"], "summary": "Video large language models have not yet been widely deployed, largely due to\ntheir tendency to hallucinate. Typical benchmarks for Video-LLMs rely simply on\nmultiple-choice questions. Unfortunately, VideoLLMs hallucinate far more\naggressively on freeform text generation tasks like video captioning than they\ndo on multiple choice verification tasks. To address this weakness, we propose\nARGUS, a VideoLLM benchmark that measures freeform video captioning\nperformance. By comparing VideoLLM outputs to human ground truth captions,\nARGUS quantifies dual metrics. First, we measure the rate of hallucinations in\nthe form of incorrect statements about video content or temporal relationships.\nSecond, we measure the rate at which the model omits important descriptive\ndetails. Together, these dual metrics form a comprehensive view of video\ncaptioning performance.", "comment": "Project page with all the artifacts:\n  https://ruchitrawal.github.io/argus", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07371v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07054", "title": "Policy Gradient with Tree Search: Avoiding Local Optimas through Lookahead", "authors": ["Uri Koren", "Navdeep Kumar", "Uri Gadot", "Giorgia Ramponi", "Kfir Yehuda Levy", "Shie Mannor"], "summary": "Classical policy gradient (PG) methods in reinforcement learning frequently\nconverge to suboptimal local optima, a challenge exacerbated in large or\ncomplex environments. This work investigates Policy Gradient with Tree Search\n(PGTS), an approach that integrates an $m$-step lookahead mechanism to enhance\npolicy optimization. We provide theoretical analysis demonstrating that\nincreasing the tree search depth $m$-monotonically reduces the set of\nundesirable stationary points and, consequently, improves the worst-case\nperformance of any resulting stationary policy. Critically, our analysis\naccommodates practical scenarios where policy updates are restricted to states\nvisited by the current policy, rather than requiring updates across the entire\nstate space. Empirical evaluations on diverse MDP structures, including Ladder,\nTightrope, and Gridworld environments, illustrate PGTS's ability to exhibit\n\"farsightedness,\" navigate challenging reward landscapes, escape local traps\nwhere standard PG fails, and achieve superior solutions.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07054v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07375", "title": "DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models", "authors": ["Xunjie He", "Christina Dao Wen Lee", "Meiling Wang", "Chengran Yuan", "Zefan Huang", "Yufeng Yue", "Marcelo H. Ang Jr"], "summary": "Collaborative perception plays a crucial role in enhancing environmental\nunderstanding by expanding the perceptual range and improving robustness\nagainst sensor failures, which primarily involves collaborative 3D detection\nand tracking tasks. The former focuses on object recognition in individual\nframes, while the latter captures continuous instance tracklets over time.\nHowever, existing works in both areas predominantly focus on the vehicle\nsuperclass, lacking effective solutions for both multi-class collaborative\ndetection and tracking. This limitation hinders their applicability in\nreal-world scenarios, which involve diverse object classes with varying\nappearances and motion patterns. To overcome these limitations, we propose a\nmulti-class collaborative detection and tracking framework tailored for diverse\nroad users. We first present a detector with a global spatial attention fusion\n(GSAF) module, enhancing multi-scale feature learning for objects of varying\nsizes. Next, we introduce a tracklet RE-IDentification (REID) module that\nleverages visual semantics with a vision foundation model to effectively reduce\nID SWitch (IDSW) errors, in cases of erroneous mismatches involving small\nobjects like pedestrians. We further design a velocity-based adaptive tracklet\nmanagement (VATM) module that adjusts the tracking interval dynamically based\non object motion. Extensive experiments on the V2X-Real and OPV2V datasets show\nthat our approach significantly outperforms existing state-of-the-art methods\nin both detection and tracking accuracy.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07375v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07078", "title": "E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models", "authors": ["Jiaheng Dong", "Hong Jia", "Soumyajit Chatterjee", "Abhirup Ghosh", "James Bailey", "Ting Dang"], "summary": "Speech Foundation Models encounter significant performance degradation when\ndeployed in real-world scenarios involving acoustic domain shifts, such as\nbackground noise and speaker accents. Test-time adaptation (TTA) has recently\nemerged as a viable strategy to address such domain shifts at inference time\nwithout requiring access to source data or labels. However, existing TTA\napproaches, particularly those relying on backpropagation, are\nmemory-intensive, limiting their applicability in speech tasks and\nresource-constrained settings. Although backpropagation-free methods offer\nimproved efficiency, existing ones exhibit poor accuracy. This is because they\nare predominantly developed for vision tasks, which fundamentally differ from\nspeech task formulations, noise characteristics, and model architecture, posing\nunique transferability challenges. In this paper, we introduce E-BATS, the\nfirst Efficient BAckpropagation-free TTA framework designed explicitly for\nspeech foundation models. E-BATS achieves a balance between adaptation\neffectiveness and memory efficiency through three key components: (i)\nlightweight prompt adaptation for a forward-pass-based feature alignment, (ii)\na multi-scale loss to capture both global (utterance-level) and local\ndistribution shifts (token-level) and (iii) a test-time exponential moving\naverage mechanism for stable adaptation across utterances. Experiments\nconducted on four noisy speech datasets spanning sixteen acoustic conditions\ndemonstrate consistent improvements, with 4.1%-13.5% accuracy gains over\nbackpropagation-free baselines and 2.0-6.4 times GPU memory savings compared to\nbackpropagation-based methods. By enabling scalable and robust adaptation under\nacoustic variability, this work paves the way for developing more efficient\nadaptation approaches for practical speech processing systems in real-world\nenvironments.", "comment": "Under Review", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07078v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07376", "title": "Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation", "authors": ["Jintao Tong", "Ran Ma", "Yixiong Zou", "Guangyao Chen", "Yuhua Li", "Ruixuan Li"], "summary": "Cross-domain few-shot segmentation (CD-FSS) is proposed to pre-train the\nmodel on a source-domain dataset with sufficient samples, and then transfer the\nmodel to target-domain datasets where only a few samples are available for\nefficient fine-tuning. There are majorly two challenges in this task: (1) the\ndomain gap and (2) fine-tuning with scarce data. To solve these challenges, we\nrevisit the adapter-based methods, and discover an intriguing insight not\nexplored in previous works: the adapter not only helps the fine-tuning of\ndownstream tasks but also naturally serves as a domain information decoupler.\nThen, we delve into this finding for an interpretation, and find the model's\ninherent structure could lead to a natural decoupling of domain information.\nBuilding upon this insight, we propose the Domain Feature Navigator (DFN),\nwhich is a structure-based decoupler instead of loss-based ones like current\nworks, to capture domain-specific information, thereby directing the model's\nattention towards domain-agnostic knowledge. Moreover, to prevent the potential\nexcessive overfitting of DFN during the source-domain training, we further\ndesign the SAM-SVN method to constrain DFN from learning sample-specific\nknowledge. On target domains, we freeze the model and fine-tune the DFN to\nlearn target-specific knowledge specific. Extensive experiments demonstrate\nthat our method surpasses the state-of-the-art method in CD-FSS significantly\nby 2.69% and 4.68% MIoU in 1-shot and 5-shot scenarios, respectively.", "comment": "ICML 2025 Spotlight", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07376v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07085", "title": "State Entropy Regularization for Robust Reinforcement Learning", "authors": ["Uri Koren", "Yonatan Ashlag", "Mirco Mutti", "Esther Derman", "Pierre-Luc Bacon", "Shie Mannor"], "summary": "State entropy regularization has empirically shown better exploration and\nsample complexity in reinforcement learning (RL). However, its theoretical\nguarantees have not been studied. In this paper, we show that state entropy\nregularization improves robustness to structured and spatially correlated\nperturbations. These types of variation are common in transfer learning but\noften overlooked by standard robust RL methods, which typically focus on small,\nuncorrelated changes. We provide a comprehensive characterization of these\nrobustness properties, including formal guarantees under reward and transition\nuncertainty, as well as settings where the method performs poorly. Much of our\nanalysis contrasts state entropy with the widely used policy entropy\nregularization, highlighting their different benefits. Finally, from a\npractical standpoint, we illustrate that compared with policy entropy, the\nrobustness advantages of state entropy are more sensitive to the number of\nrollouts used for policy evaluation.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07085v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06477", "title": "On geodesic disks enclosing many points", "authors": ["Prosenjit Bose", "Guillermo Esteban", "David Orden", "Rodrigo Silveira", "Tyler Tuttle"], "summary": "Let $ \\Pi(n) $ be the largest number such that for every set $ S $ of $ n $\npoints in a polygon~$ P $, there always exist two points $ x, y \\in S $, where\nevery geodesic disk containing $ x $ and $ y $ contains $ \\Pi(n) $ points of~$\nS $. We establish upper and lower bounds for $ \\Pi(n)$, and show that $\n\\left\\lceil \\frac{n}{5}\\right\\rceil+1 \\leq \\Pi(n) \\leq \\left\\lceil \\frac{n}{4}\n\\right\\rceil +1 $. We also show that there always exist two points $x, y\\in S$\nsuch that every geodesic disk with $x$ and $y$ on its boundary contains at\nleast $ \\frac{n}{3+\\sqrt{5}} \\approx \\left\\lceil \\frac{n}{5.2} \\right\\rceil$\npoints both inside and outside the disk. For the special case where the points\nof $ S $ are restricted to be the vertices of a geodesically convex polygon we\ngive a tight bound of $\\left\\lceil \\frac{n}{3} \\right\\rceil + 1$. We provide\nthe same tight bound when we only consider geodesic disks having $ x $ and $ y\n$ as diametral endpoints. We give upper and lower bounds of $\\left\\lceil\n\\frac{n}{5} \\right\\rceil + 1 $ and $\\frac{n}{6+\\sqrt{26}} \\approx \\left\\lceil\n\\frac{n}{11.1} \\right\\rceil$, respectively, for the two-colored version of the\nproblem. Finally, for the two-colored variant we show that there always exist\ntwo points $x, y\\in S$ where $x$ and $y$ have different colors and every\ngeodesic disk with $x$ and $y$ on its boundary contains at least $\\lceil\n\\frac{n}{11.3}\\rceil+1$ points both inside and outside the disk.", "comment": null, "cate": "cs.CG", "url": "http://arxiv.org/abs/2506.06477v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07399", "title": "MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems", "authors": ["Peiru Yang", "Jinhua Yin", "Haoran Zheng", "Xueying Bai", "Huili Wang", "Yufei Sun", "Xintian Li", "Shangguang Wang", "Yongfeng Huang", "Tao Qi"], "summary": "Multimodal retrieval-augmented generation (RAG) systems enhance large\nvision-language models by integrating cross-modal knowledge, enabling their\nincreasing adoption across real-world multimodal tasks. These knowledge\ndatabases may contain sensitive information that requires privacy protection.\nHowever, multimodal RAG systems inherently grant external users indirect access\nto such data, making them potentially vulnerable to privacy attacks,\nparticularly membership inference attacks (MIAs). % Existing MIA methods\ntargeting RAG systems predominantly focus on the textual modality, while the\nvisual modality remains relatively underexplored. To bridge this gap, we\npropose MrM, the first black-box MIA framework targeted at multimodal RAG\nsystems. It utilizes a multi-object data perturbation framework constrained by\ncounterfactual attacks, which can concurrently induce the RAG systems to\nretrieve the target data and generate information that leaks the membership\ninformation. Our method first employs an object-aware data perturbation method\nto constrain the perturbation to key semantics and ensure successful retrieval.\nBuilding on this, we design a counterfact-informed mask selection strategy to\nprioritize the most informative masked regions, aiming to eliminate the\ninterference of model self-knowledge and amplify attack efficacy. Finally, we\nperform statistical membership inference by modeling query trials to extract\nfeatures that reflect the reconstruction of masked semantics from response\npatterns. Experiments on two visual datasets and eight mainstream commercial\nvisual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves\nconsistently strong performance across both sample-level and set-level\nevaluations, and remains robust under adaptive defenses.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07399v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07088", "title": "Pointwise confidence estimation in the non-linear $\\ell^2$-regularized least squares", "authors": ["Ilja Kuzborskij", "Yasin Abbasi Yadkori"], "summary": "We consider a high-probability non-asymptotic confidence estimation in the\n$\\ell^2$-regularized non-linear least-squares setting with fixed design. In\nparticular, we study confidence estimation for local minimizers of the\nregularized training loss. We show a pointwise confidence bound, meaning that\nit holds for the prediction on any given fixed test input $x$. Importantly, the\nproposed confidence bound scales with similarity of the test input to the\ntraining data in the implicit feature space of the predictor (for instance,\nbecoming very large when the test input lies far outside of the training data).\nThis desirable last feature is captured by the weighted norm involving the\ninverse-Hessian matrix of the objective function, which is a generalized\nversion of its counterpart in the linear setting, $x^{\\top} \\text{Cov}^{-1} x$.\nOur generalized result can be regarded as a non-asymptotic counterpart of the\nclassical confidence interval based on asymptotic normality of the MLE\nestimator. We propose an efficient method for computing the weighted norm,\nwhich only mildly exceeds the cost of a gradient computation of the loss\nfunction. Finally, we complement our analysis with empirical evidence showing\nthat the proposed confidence bound provides better coverage/width trade-off\ncompared to a confidence estimation by bootstrapping, which is a gold-standard\nmethod in many applications involving non-linear predictors such as neural\nnetworks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07088v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07412", "title": "Compressed Feature Quality Assessment: Dataset and Baselines", "authors": ["Changsheng Gao", "Wei Zhou", "Guosheng Lin", "Weisi Lin"], "summary": "The widespread deployment of large models in resource-constrained\nenvironments has underscored the need for efficient transmission of\nintermediate feature representations. In this context, feature coding, which\ncompresses features into compact bitstreams, becomes a critical component for\nscenarios involving feature transmission, storage, and reuse. However, this\ncompression process introduces inherent semantic degradation that is\nnotoriously difficult to quantify with traditional metrics. To address this,\nthis paper introduces the research problem of Compressed Feature Quality\nAssessment (CFQA), which seeks to evaluate the semantic fidelity of compressed\nfeatures. To advance CFQA research, we propose the first benchmark dataset,\ncomprising 300 original features and 12000 compressed features derived from\nthree vision tasks and four feature codecs. Task-specific performance drops are\nprovided as true semantic distortion for the evaluation of CFQA metrics. We\nassess the performance of three widely used metrics (MSE, cosine similarity,\nand Centered Kernel Alignment) in capturing semantic degradation. The results\nunderscore the representativeness of the dataset and highlight the need for\nmore refined metrics capable of addressing the nuances of semantic distortion\nin compressed features. To facilitate the ongoing development of CFQA research,\nwe release the dataset and all accompanying source code at\n\\href{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}.\nThis contribution aims to advance the field and provide a foundational resource\nfor the community to explore CFQA.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07412v1", "AI": {"title_translation": "压缩特征质量评估：数据集与基线", "tldr": "本文提出了压缩特征质量评估（CFQA）问题，并构建了首个CFQA基准数据集和基线，以解决压缩特征的语义退化难以量化的问题。", "motivation": "在资源受限环境中部署大型模型时，需要高效传输中间特征表示。特征编码（压缩特征）在此过程中至关重要，但会引入传统指标难以量化的语义退化。因此，需要评估压缩特征的语义保真度。", "method": "本文提出了压缩特征质量评估（CFQA）研究问题，旨在评估压缩特征的语义保真度。为推动CFQA研究，构建了首个基准数据集，包含300个原始特征和12000个压缩特征，来源于三个视觉任务和四种特征编解码器。使用任务特定的性能下降作为真实的语义失真进行评估。评估了三种常用指标（MSE、余弦相似度、中心核对齐）在捕获语义退化方面的性能。", "result": "评估结果强调了数据集的代表性，并指出需要更精细的指标来解决压缩特征中语义失真的细微差别。", "conclusion": "本文引入了压缩特征质量评估（CFQA）研究问题，并发布了首个CFQA基准数据集和源代码，旨在推动该领域的发展，并为社区探索CFQA提供基础资源。", "translation": "大型模型在资源受限环境中的广泛部署凸显了中间特征表示高效传输的需求。在这种背景下，特征编码将特征压缩成紧凑的比特流，成为涉及特征传输、存储和重用场景的关键组成部分。然而，这种压缩过程引入了固有的语义退化，而这种退化用传统指标来量化是出了名的困难。为了解决这个问题，本文引入了压缩特征质量评估（CFQA）这一研究问题，旨在评估压缩特征的语义保真度。为了推进CFQA研究，我们提出了首个基准数据集，该数据集包含300个原始特征和12000个压缩特征，这些特征来源于三个视觉任务和四种特征编解码器。任务特定的性能下降被作为真实的语义失真，用于评估CFQA指标。我们评估了三种广泛使用的指标（MSE、余弦相似度和中心核对齐）在捕获语义退化方面的性能。结果强调了数据集的代表性，并突出了需要更精细的指标来解决压缩特征中语义失真的细微差别。为了促进CFQA研究的持续发展，我们发布了数据集和所有附带的源代码，网址为\\href{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}。这一贡献旨在推动该领域的发展，并为社区探索CFQA提供基础资源。", "summary": "为了解决资源受限环境下大型模型部署中压缩特征语义退化难以量化的问题，本文提出了压缩特征质量评估（CFQA）这一研究问题。为此，作者构建了首个CFQA基准数据集，该数据集包含来自多种视觉任务和特征编解码器的原始及压缩特征，并以任务性能下降作为真值语义失真。研究评估了现有度量（如MSE、余弦相似度、中心核对齐）在捕获语义退化方面的表现，结果表明数据集具有代表性，并强调了开发更精确度量的重要性。本文还开源了数据集和代码，以促进CFQA领域的进一步研究。", "keywords": "压缩特征, 质量评估, 数据集, 语义失真, 基线", "comments": "这项工作具有重要意义，因为它首次提出了压缩特征质量评估（CFQA）这一明确的研究问题，并构建了首个专门为此目的设计的基准数据集。这为后续研究提供了一个标准化的评估框架和资源，有助于推动特征压缩和语义保真度量领域的发展。数据集的代表性以及对现有指标局限性的揭示，为未来开发更先进的度量方法指明了方向。"}}
{"id": "2506.07092", "title": "Patient Similarity Computation for Clinical Decision Support: An Efficient Use of Data Transformation, Combining Static and Time Series Data", "authors": ["Joydeb Kumar Sana", "Mohammad M. Masud", "M Sohel Rahman", "M Saifur Rahman"], "summary": "Patient similarity computation (PSC) is a fundamental problem in healthcare\ninformatics. The aim of the patient similarity computation is to measure the\nsimilarity among patients according to their historical clinical records, which\nhelps to improve clinical decision support. This paper presents a novel\ndistributed patient similarity computation (DPSC) technique based on data\ntransformation (DT) methods, utilizing an effective combination of time series\nand static data. Time series data are sensor-collected patients' information,\nincluding metrics like heart rate, blood pressure, Oxygen saturation,\nrespiration, etc. The static data are mainly patient background and demographic\ndata, including age, weight, height, gender, etc. Static data has been used for\nclustering the patients. Before feeding the static data to the machine learning\nmodel adaptive Weight-of-Evidence (aWOE) and Z-score data transformation (DT)\nmethods have been performed, which improve the prediction performances. In\naWOE-based patient similarity models, sensitive patient information has been\nprocessed using aWOE which preserves the data privacy of the trained models. We\nused the Dynamic Time Warping (DTW) approach, which is robust and very popular,\nfor time series similarity. However, DTW is not suitable for big data due to\nthe significant computational run-time. To overcome this problem, distributed\nDTW computation is used in this study. For Coronary Artery Disease, our DT\nbased approach boosts prediction performance by as much as 11.4%, 10.20%, and\n12.6% in terms of AUC, accuracy, and F-measure, respectively. In the case of\nCongestive Heart Failure (CHF), our proposed method achieves performance\nenhancement up to 15.9%, 10.5%, and 21.9% for the same measures, respectively.\nThe proposed method reduces the computation time by as high as 40%.", "comment": "This paper presents a novel distributed patient similarity\n  computation (DPSC) technique based on data transformation (DT) methods,\n  utilizing an effective combination of time series and static data", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07092v1", "AI": {"title_translation": "病人相似度计算用于临床决策支持：数据转换、结合静态和时间序列数据的有效利用", "tldr": "该研究提出了一种基于数据转换的分布式病人相似度计算技术，有效结合静态和时间序列数据，显著提升了预测性能并减少了计算时间。", "motivation": "病人相似度计算（PSC）是医疗信息学中的一个基本问题，旨在根据患者历史临床记录测量相似度，以改善临床决策支持。", "method": "提出了一种新颖的分布式病人相似度计算（DPSC）技术，基于数据转换（DT）方法，有效结合时间序列数据（传感器收集，如心率、血压、血氧饱和度、呼吸等）和静态数据（患者背景和人口统计数据，如年龄、体重、身高、性别等）。静态数据通过自适应证据权重（aWOE）和Z-score数据转换处理以提高预测性能，aWOE还用于保护数据隐私。时间序列相似度使用动态时间规整（DTW），并采用分布式DTW计算来解决大数据计算耗时问题。", "result": "对于冠状动脉疾病，该基于DT的方法在AUC、准确性和F-measure方面分别提升了11.4%、10.20%和12.6%。对于充血性心力衰竭（CHF），该方法在相同指标上分别提升了15.9%、10.5%和21.9%。计算时间减少高达40%。", "conclusion": "该研究提出的结合数据转换和分布式计算的病人相似度计算方法，在提升预测性能和降低计算时间方面表现出色，对临床决策支持有显著帮助。", "translation": "病人相似度计算（PSC）是医疗信息学中的一个基本问题。病人相似度计算的目的是根据患者的历史临床记录来衡量患者之间的相似性，这有助于改善临床决策支持。本文提出了一种新颖的分布式病人相似度计算（DPSC）技术，该技术基于数据转换（DT）方法，有效结合了时间序列数据和静态数据。时间序列数据是传感器收集的患者信息，包括心率、血压、血氧饱和度、呼吸等指标。静态数据主要是患者背景和人口统计数据，包括年龄、体重、身高、性别等。静态数据已用于患者聚类。在将静态数据输入机器学习模型之前，已执行自适应证据权重（aWOE）和Z-score数据转换（DT）方法，这提高了预测性能。在基于aWOE的病人相似度模型中，敏感患者信息已使用aWOE进行处理，这保护了训练模型的数据隐私。我们使用动态时间规整（DTW）方法进行时间序列相似度计算，该方法稳健且非常流行。然而，由于计算运行时间长，DTW不适合大数据。为了克服这个问题，本研究使用了分布式DTW计算。对于冠状动脉疾病，我们基于DT的方法在AUC、准确性和F-measure方面分别将预测性能提高了11.4%、10.20%和12.6%。在充血性心力衰竭（CHF）的情况下，我们提出的方法在相同指标上分别实现了高达15.9%、10.5%和21.9%的性能提升。所提出的方法将计算时间减少了高达40%。", "summary": "本文提出了一种新颖的分布式病人相似度计算（DPSC）技术，通过有效结合时间序列和静态数据，并利用数据转换（DT）方法，显著提升了临床决策支持系统的预测性能。该方法采用aWOE和Z-score对静态数据进行转换以提高性能和保护隐私，并使用分布式DTW处理时间序列数据以克服大数据计算效率问题。实验结果表明，该方法在冠状动脉疾病和充血性心力衰竭的预测任务上，性能指标（AUC、准确率、F-measure）有显著提升，同时计算时间大幅减少。", "keywords": "病人相似度计算, 数据转换, 临床决策支持, 时间序列数据, 分布式计算", "comments": "这篇论文的创新点在于结合了数据转换（aWOE和Z-score）和分布式计算（分布式DTW）来处理混合类型的临床数据（静态和时间序列），以实现高效且隐私保护的病人相似度计算。其在提升预测性能和降低计算时间方面的显著成果，对于大数据背景下的临床决策支持系统具有重要实践意义。"}}
{"id": "2506.07414", "title": "DPFormer: Dynamic Prompt Transformer for Continual Learning", "authors": ["Sheng-Kai Huang", "Jiun-Feng Chang", "Chun-Rong Huang"], "summary": "In continual learning, solving the catastrophic forgetting problem may make\nthe models fall into the stability-plasticity dilemma. Moreover, inter-task\nconfusion will also occur due to the lack of knowledge exchanges between\ndifferent tasks. In order to solve the aforementioned problems, we propose a\nnovel dynamic prompt transformer (DPFormer) with prompt schemes. The prompt\nschemes help the DPFormer memorize learned knowledge of previous classes and\ntasks, and keep on learning new knowledge from new classes and tasks under a\nsingle network structure with a nearly fixed number of model parameters.\nMoreover, they also provide discrepant information to represent different tasks\nto solve the inter-task confusion problem. Based on prompt schemes, a unified\nclassification module with the binary cross entropy loss, the knowledge\ndistillation loss and the auxiliary loss is proposed to train the whole model\nin an end-to-end trainable manner. Compared with state-of-the-art methods, our\nmethod achieves the best performance in the CIFAR-100, ImageNet100 and\nImageNet1K datasets under different class-incremental settings in continual\nlearning. The source code will be available at our GitHub after acceptance.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07414v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07099", "title": "Filling the Missings: Spatiotemporal Data Imputation by Conditional Diffusion", "authors": ["Wenying He", "Jieling Huang", "Junhua Gu", "Ji Zhang", "Yude Bai"], "summary": "Missing data in spatiotemporal systems presents a significant challenge for\nmodern applications, ranging from environmental monitoring to urban traffic\nmanagement. The integrity of spatiotemporal data often deteriorates due to\nhardware malfunctions and software failures in real-world deployments. Current\napproaches based on machine learning and deep learning struggle to model the\nintricate interdependencies between spatial and temporal dimensions effectively\nand, more importantly, suffer from cumulative errors during the data imputation\nprocess, which propagate and amplify through iterations. To address these\nlimitations, we propose CoFILL, a novel Conditional Diffusion Model for\nspatiotemporal data imputation. CoFILL builds on the inherent advantages of\ndiffusion models to generate high-quality imputations without relying on\npotentially error-prone prior estimates. It incorporates an innovative\ndual-stream architecture that processes temporal and frequency domain features\nin parallel. By fusing these complementary features, CoFILL captures both rapid\nfluctuations and underlying patterns in the data, which enables more robust\nimputation. The extensive experiments reveal that CoFILL's noise prediction\nnetwork successfully transforms random noise into meaningful values that align\nwith the true data distribution. The results also show that CoFILL outperforms\nstate-of-the-art methods in imputation accuracy. The source code is publicly\navailable at https://github.com/joyHJL/CoFILL.", "comment": "9 pages,3 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07099v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07431", "title": "FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement", "authors": ["Jie He", "Minglang Chen", "Minying Lu", "Bocheng Liang", "Junming Wei", "Guiyan Peng", "Jiaxi Chen", "Ying Tan"], "summary": "Accurate ultrasound image segmentation is a prerequisite for precise\nbiometrics and accurate assessment. Relying on manual delineation introduces\nsignificant errors and is time-consuming. However, existing segmentation models\nare designed based on objects in natural scenes, making them difficult to adapt\nto ultrasound objects with high noise and high similarity. This is particularly\nevident in small object segmentation, where a pronounced jagged effect occurs.\nTherefore, this paper proposes a fetal femur and cranial ultrasound image\nsegmentation model based on feature perception and Mamba enhancement to address\nthese challenges. Specifically, a longitudinal and transverse independent\nviewpoint scanning convolution block and a feature perception module were\ndesigned to enhance the ability to capture local detail information and improve\nthe fusion of contextual information. Combined with the Mamba-optimized\nresidual structure, this design suppresses the interference of raw noise and\nenhances local multi-dimensional scanning. The system builds global information\nand local feature dependencies, and is trained with a combination of different\noptimizers to achieve the optimal solution. After extensive experimental\nvalidation, the FAMSeg network achieved the fastest loss reduction and the best\nsegmentation performance across images of varying sizes and orientations.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07431v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07109", "title": "Towards Universal Offline Black-Box Optimization via Learning Language Model Embeddings", "authors": ["Rong-Xi Tan", "Ming Chen", "Ke Xue", "Yao Wang", "Yaoyuan Wang", "Sheng Fu", "Chao Qian"], "summary": "The pursuit of universal black-box optimization (BBO) algorithms is a\nlongstanding goal. However, unlike domains such as language or vision, where\nscaling structured data has driven generalization, progress in offline BBO\nremains hindered by the lack of unified representations for heterogeneous\nnumerical spaces. Thus, existing offline BBO approaches are constrained to\nsingle-task and fixed-dimensional settings, failing to achieve cross-domain\nuniversal optimization. Recent advances in language models (LMs) offer a\npromising path forward: their embeddings capture latent relationships in a\nunifying way, enabling universal optimization across different data types\npossible. In this paper, we discuss multiple potential approaches, including an\nend-to-end learning framework in the form of next-token prediction, as well as\nprioritizing the learning of latent spaces with strong representational\ncapabilities. To validate the effectiveness of these methods, we collect\noffline BBO tasks and data from open-source academic works for training.\nExperiments demonstrate the universality and effectiveness of our proposed\nmethods. Our findings suggest that unifying language model priors and learning\nstring embedding space can overcome traditional barriers in universal BBO,\npaving the way for general-purpose BBO algorithms. The code is provided at\nhttps://github.com/lamda-bbo/universal-offline-bbo.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07109v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06483", "title": "Noise Consistency Regularization for Improved Subject-Driven Image Synthesis", "authors": ["Yao Ni", "Song Wen", "Piotr Koniusz", "Anoop Cherian"], "summary": "Fine-tuning Stable Diffusion enables subject-driven image synthesis by\nadapting the model to generate images containing specific subjects. However,\nexisting fine-tuning methods suffer from two key issues: underfitting, where\nthe model fails to reliably capture subject identity, and overfitting, where it\nmemorizes the subject image and reduces background diversity. To address these\nchallenges, we propose two auxiliary consistency losses for diffusion\nfine-tuning. First, a prior consistency regularization loss ensures that the\npredicted diffusion noise for prior (non-subject) images remains consistent\nwith that of the pretrained model, improving fidelity. Second, a subject\nconsistency regularization loss enhances the fine-tuned model's robustness to\nmultiplicative noise modulated latent code, helping to preserve subject\nidentity while improving diversity. Our experimental results demonstrate that\nincorporating these losses into fine-tuning not only preserves subject identity\nbut also enhances image diversity, outperforming DreamBooth in terms of CLIP\nscores, background variation, and overall visual quality.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.06483v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06318", "title": "MoE-Gyro: Self-Supervised Over-Range Reconstruction and Denoising for MEMS Gyroscopes", "authors": ["Feiyang Pan", "Shenghe Zheng", "Chunyan Yin", "Guangbin Dou"], "summary": "MEMS gyroscopes play a critical role in inertial navigation and motion\ncontrol applications but typically suffer from a fundamental trade-off between\nmeasurement range and noise performance. Existing hardware-based solutions\naimed at mitigating this issue introduce additional complexity, cost, and\nscalability challenges. Deep-learning methods primarily focus on noise\nreduction and typically require precisely aligned ground-truth signals, making\nthem difficult to deploy in practical scenarios and leaving the fundamental\ntrade-off unresolved. To address these challenges, we introduce Mixture of\nExperts for MEMS Gyroscopes (MoE-Gyro), a novel self-supervised framework\nspecifically designed for simultaneous over-range signal reconstruction and\nnoise suppression. MoE-Gyro employs two experts: an Over-Range Reconstruction\nExpert (ORE), featuring a Gaussian-Decay Attention mechanism for reconstructing\nsaturated segments; and a Denoise Expert (DE), utilizing dual-branch\ncomplementary masking combined with FFT-guided augmentation for robust noise\nreduction. A lightweight gating module dynamically routes input segments to the\nappropriate expert. Furthermore, existing evaluation lack a comprehensive\nstandard for assessing multi-dimensional signal enhancement. To bridge this\ngap, we introduce IMU Signal Enhancement Benchmark (ISEBench), an open-source\nbenchmarking platform comprising the GyroPeak-100 dataset and a unified\nevaluation of IMU signal enhancement methods. We evaluate MoE-Gyro using our\nproposed ISEBench, demonstrating that our framework significantly extends the\nmeasurable range from 450 deg/s to 1500 deg/s, reduces Bias Instability by\n98.4%, and achieves state-of-the-art performance, effectively addressing the\nlong-standing trade-off in inertial sensing.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06318v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07121", "title": "Quality-Diversity Red-Teaming: Automated Generation of High-Quality and Diverse Attackers for Large Language Models", "authors": ["Ren-Jian Wang", "Ke Xue", "Zeyu Qin", "Ziniu Li", "Sheng Tang", "Hao-Tian Li", "Shengcai Liu", "Chao Qian"], "summary": "Ensuring safety of large language models (LLMs) is important. Red teaming--a\nsystematic approach to identifying adversarial prompts that elicit harmful\nresponses from target LLMs--has emerged as a crucial safety evaluation method.\nWithin this framework, the diversity of adversarial prompts is essential for\ncomprehensive safety assessments. We find that previous approaches to\nred-teaming may suffer from two key limitations. First, they often pursue\ndiversity through simplistic metrics like word frequency or sentence embedding\nsimilarity, which may not capture meaningful variation in attack strategies.\nSecond, the common practice of training a single attacker model restricts\ncoverage across potential attack styles and risk categories. This paper\nintroduces Quality-Diversity Red-Teaming (QDRT), a new framework designed to\naddress these limitations. QDRT achieves goal-driven diversity through\nbehavior-conditioned training and implements a behavioral replay buffer in an\nopen-ended manner. Additionally, it trains multiple specialized attackers\ncapable of generating high-quality attacks across diverse styles and risk\ncategories. Our empirical evaluation demonstrates that QDRT generates attacks\nthat are both more diverse and more effective against a wide range of target\nLLMs, including GPT-2, Llama-3, Gemma-2, and Qwen2.5. This work advances the\nfield of LLM safety by providing a systematic and effective approach to\nautomated red-teaming, ultimately supporting the responsible deployment of\nLLMs.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07121v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06484", "title": "The Economic Dispatch of Power-to-Gas Systems with Deep Reinforcement Learning:Tackling the Challenge of Delayed Rewards with Long-Term Energy Storage", "authors": ["Manuel Sage", "Khalil Al Handawi", "Yaoyao Fiona Zhao"], "summary": "Power-to-Gas (P2G) technologies gain recognition for enabling the integration\nof intermittent renewables, such as wind and solar, into electricity grids.\nHowever, determining the most cost-effective operation of these systems is\ncomplex due to the volatile nature of renewable energy, electricity prices, and\nloads. Additionally, P2G systems are less efficient in converting and storing\nenergy compared to battery energy storage systems (BESs), and the benefits of\nconverting electricity into gas are not immediately apparent. Deep\nReinforcement Learning (DRL) has shown promise in managing the operation of\nenergy systems amidst these uncertainties. Yet, DRL techniques face\ndifficulties with the delayed reward characteristic of P2G system operation.\nPrevious research has mostly focused on short-term studies that look at the\nenergy conversion process, neglecting the long-term storage capabilities of\nP2G.\n  This study presents a new method by thoroughly examining how DRL can be\napplied to the economic operation of P2G systems, in combination with BESs and\ngas turbines, over extended periods. Through three progressively more complex\ncase studies, we assess the performance of DRL algorithms, specifically Deep\nQ-Networks and Proximal Policy Optimization, and introduce modifications to\nenhance their effectiveness. These modifications include integrating forecasts,\nimplementing penalties on the reward function, and applying strategic cost\ncalculations, all aimed at addressing the issue of delayed rewards. Our\nfindings indicate that while DRL initially struggles with the complex\ndecision-making required for P2G system operation, the adjustments we propose\nsignificantly improve its capability to devise cost-effective operation\nstrategies, thereby unlocking the potential for long-term energy storage in P2G\ntechnologies.", "comment": "Accepted for publication at the 19th ASME International Conference on\n  Energy Sustainability", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06484v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07456", "title": "PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation", "authors": ["Wei Yao", "Yunlian Sun", "Chang Liu", "Hongwen Zhang", "Jinhui Tang"], "summary": "Driven by advancements in motion capture and generative artificial\nintelligence, leveraging large-scale MoCap datasets to train generative models\nfor synthesizing diverse, realistic human motions has become a promising\nresearch direction. However, existing motion-capture techniques and generative\nmodels often neglect physical constraints, leading to artifacts such as\ninterpenetration, sliding, and floating. These issues are exacerbated in\nmulti-person motion generation, where complex interactions are involved. To\naddress these limitations, we introduce physical mapping, integrated throughout\nthe human interaction generation pipeline. Specifically, motion imitation\nwithin a physics-based simulation environment is used to project target motions\ninto a physically valid space. The resulting motions are adjusted to adhere to\nreal-world physics constraints while retaining their original semantic meaning.\nThis mapping not only improves MoCap data quality but also directly informs\npost-processing of generated motions. Given the unique interactivity of\nmulti-person scenarios, we propose a tailored motion representation framework.\nMotion Consistency (MC) and Marker-based Interaction (MI) loss functions are\nintroduced to improve model performance. Experiments show our method achieves\nimpressive results in generated human motion quality, with a 3%-89% improvement\nin physical fidelity. Project page http://yw0208.github.io/physiinter", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07456v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07134", "title": "Reliable Critics: Monotonic Improvement and Convergence Guarantees for Reinforcement Learning", "authors": ["Eshwar S. R.", "Gugan Thoppe", "Aditya Gopalan", "Gal Dalal"], "summary": "Despite decades of research, it remains challenging to correctly use\nReinforcement Learning (RL) algorithms with function approximation. A prime\nexample is policy iteration, whose fundamental guarantee of monotonic\nimprovement collapses even under linear function approximation. To address this\nissue, we introduce Reliable Policy Iteration (RPI). It replaces the common\nprojection or Bellman-error minimization during policy evaluation with a\nBellman-based constrained optimization. We prove that not only does RPI confer\ntextbook monotonicity on its value estimates but these estimates also lower\nbound the true return. Also, their limit partially satisfies the unprojected\nBellman equation, emphasizing RPI's natural fit within RL. RPI is the first\nalgorithm with such monotonicity and convergence guarantees under function\napproximation. For practical use, we provide a model-free variant of RPI that\namounts to a novel critic. It can be readily integrated into primary model-free\nPI implementations such as DQN and DDPG. In classical control tasks, such\nRPI-enhanced variants consistently maintain their lower-bound guarantee while\nmatching or surpassing the performance of all baseline methods.", "comment": "19 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07134v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06485", "title": "What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models", "authors": ["Kaiser Sun", "Fan Bai", "Mark Dredze"], "summary": "Large language models frequently rely on both contextual input and parametric\nknowledge to perform tasks. However, these sources can come into conflict,\nespecially when retrieved documents contradict the model's parametric\nknowledge. We propose a diagnostic framework to systematically evaluate LLM\nbehavior under context-memory conflict, where the contextual information\ndiverges from their parametric beliefs. We construct diagnostic data that\nelicit these conflicts and analyze model performance across multiple task\ntypes. Our findings reveal that (1) knowledge conflict has minimal impact on\ntasks that do not require knowledge utilization, (2) model performance is\nconsistently higher when contextual and parametric knowledge are aligned, (3)\nmodels are unable to fully suppress their internal knowledge even when\ninstructed, and (4) providing rationales that explain the conflict increases\nreliance on contexts. These insights raise concerns about the validity of\nmodel-based evaluation and underscore the need to account for knowledge\nconflict in the deployment of LLMs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06485v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07460", "title": "GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning", "authors": ["Taeryung Lee", "Hyeongjin Nam", "Gyeongsik Moon", "Kyoung Mu Lee"], "summary": "Sign language generation (SLG), or text-to-sign generation, bridges the gap\nbetween signers and non-signers. Despite recent progress in SLG, existing\nmethods still often suffer from incorrect lexical ordering and low semantic\naccuracy. This is primarily due to sentence-level condition, which encodes the\nentire sentence of the input text into a single feature vector as a condition\nfor SLG. This approach fails to capture the temporal structure of sign language\nand lacks the granularity of word-level semantics, often leading to disordered\nsign sequences and ambiguous motions. To overcome these limitations, we propose\nGLOS, a sign language generation framework with temporally aligned gloss-level\nconditioning. First, we employ gloss-level conditions, which we define as\nsequences of gloss embeddings temporally aligned with the motion sequence. This\nenables the model to access both the temporal structure of sign language and\nword-level semantics at each timestep. As a result, this allows for\nfine-grained control of signs and better preservation of lexical order. Second,\nwe introduce a condition fusion module, temporal alignment conditioning (TAC),\nto efficiently deliver the word-level semantic and temporal structure provided\nby the gloss-level condition to the corresponding motion timesteps. Our method,\nwhich is composed of gloss-level conditions and TAC, generates signs with\ncorrect lexical order and high semantic accuracy, outperforming prior methods\non CSL-Daily and Phoenix-2014T.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07460v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07165", "title": "AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models", "authors": ["Qi Liu", "Jingqing Ruan", "Hao Li", "Haodong Zhao", "Desheng Wang", "Jiansong Chen", "Wan Guanglu", "Xunliang Cai", "Zhi Zheng", "Tong Xu"], "summary": "Existing multi-objective preference alignment methods for large language\nmodels (LLMs) face limitations: (1) the inability to effectively balance\nvarious preference dimensions, and (2) reliance on auxiliary reward/reference\nmodels introduces computational complexity. To address these challenges, we\npropose Adaptive Multi-objective Preference Optimization (AMoPO), a novel\nframework that achieves dynamic balance across preference dimensions. By\nintroducing the multi-objective optimization paradigm to use the\ndimension-aware generation metrics as implicit rewards, AMoPO aligns LLMs with\ndiverse preferences without additional reward models or reference models. We\nintroduce an adaptive weight assignment mechanism that models the generation\nspace as a Gaussian distribution, allowing dynamic prioritization of preference\ndimensions. Empirical results demonstrate that AMoPO outperforms\nstate-of-the-art baselines by 28.5%, and the experiments on 7B, 14B, and 32B\nmodels reveal the scaling ability of AMoPO. Moreover, additional analysis of\nmultiple dimensions verifies its adaptability and effectiveness. These findings\nvalidate AMoPO's capability to achieve dimension-aware preference alignment,\nhighlighting its superiority. Our codes and datasets are available at\nhttps://github.com/Javkonline/AMoPO.", "comment": "Accepted by ACL 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07165v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07464", "title": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO", "authors": ["Jinyoung Park", "Jeehye Na", "Jinyoung Kim", "Hyunwoo J. Kim"], "summary": "Recent works have demonstrated the effectiveness of reinforcement learning\n(RL)-based post-training in enhancing the reasoning capabilities of large\nlanguage models (LLMs). In particular, Group Relative Policy Optimization\n(GRPO) has shown impressive success by employing a PPO-style reinforcement\nalgorithm with group-based normalized rewards. However, the application of GRPO\nto Video Large Language Models (Video LLMs) has been less studied. In this\npaper, we explore GRPO for video LLMs and identify two primary issues that\nimpede its effective learning: (1) reliance on safeguards, and (2) the\nvanishing advantage problem. To mitigate these challenges, we propose\nDeepVideo-R1, a video large language model trained with our proposed Reg-GRPO\n(Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO\nreformulates the GRPO objective as a regression task, directly predicting the\nadvantage in GRPO. This design eliminates the need for safeguards like clipping\nand min functions, thereby facilitating more direct policy guidance by aligning\nthe model with the advantage values. We also design the difficulty-aware data\naugmentation strategy that dynamically augments training samples at solvable\ndifficulty levels, fostering diverse and informative reward signals. Our\ncomprehensive experiments show that DeepVideo-R1 significantly improves video\nreasoning performance across multiple video reasoning benchmarks.", "comment": "Work in progress", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07464v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07168", "title": "Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment", "authors": ["Huanyi Xie", "Lijie Hu", "Lu Yu", "Tianhao Huang", "Longfei Li", "Meng Li", "Jun Zhou", "Huan Wang", "Di Wang"], "summary": "In the realm of Text-attributed Graphs (TAGs), traditional graph neural\nnetworks (GNNs) often fall short due to the complex textual information\nassociated with each node. Recent methods have improved node representations by\nleveraging large language models (LLMs) to enhance node text features, but\nthese approaches typically require extensive annotations or fine-tuning across\nall nodes, which is both time-consuming and costly. To overcome these\nchallenges, we introduce GAGA, an efficient framework for TAG representation\nlearning. GAGA reduces annotation time and cost by focusing on annotating only\nrepresentative nodes and edges. It constructs an annotation graph that captures\nthe topological relationships among these annotations. Furthermore, GAGA\nemploys a two-level alignment module to effectively integrate the annotation\ngraph with the TAG, aligning their underlying structures. Experiments show that\nGAGA achieves classification accuracies on par with or surpassing\nstate-of-the-art methods while requiring only 1% of the data to be annotated,\ndemonstrating its high efficiency.", "comment": "23 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07168v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07471", "title": "Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval", "authors": ["CH Cho", "WJ Moon", "W Jun", "MS Jung", "JP Heo"], "summary": "Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where a\nspecific segment is relevant to a given text query. Typical training processes\nof PRVR assume a one-to-one relationship where each text query is relevant to\nonly one video. However, we point out the inherent ambiguity between text and\nvideo content based on their conceptual scope and propose a framework that\nincorporates this ambiguity into the model learning process. Specifically, we\npropose Ambiguity-Restrained representation Learning~(ARL) to address ambiguous\ntext-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:\nuncertainty and similarity. Uncertainty represents whether instances include\ncommonly shared context across the dataset, while similarity indicates\npair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARL\nhierarchically learns the semantic relationship via multi-positive contrastive\nlearning and dual triplet margin loss. Additionally, we delve into fine-grained\nrelationships within the video instances. Unlike typical training at the\ntext-video level, where pairwise information is provided, we address the\ninherent ambiguity within frames of the same untrimmed video, which often\ncontains multiple contexts. This allows us to further enhance learning at the\ntext-frame level. Lastly, we propose cross-model ambiguity detection to\nmitigate the error propagation that occurs when a single model is employed to\ndetect ambiguous pairs for its training. With all components combined, our\nproposed method demonstrates its effectiveness in PRVR.", "comment": "Accepted to AAAI 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07471v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07179", "title": "Regularized Adaptive Graph Learning for Large-Scale Traffic Forecasting", "authors": ["Kaiqi Wu", "Weiyang Kong", "Sen Zhang", "Yubao Liu", "Zitong Chen"], "summary": "Traffic prediction is a critical task in spatial-temporal forecasting with\nbroad applications in travel planning and urban management. Adaptive graph\nconvolution networks have emerged as mainstream solutions due to their ability\nto learn node embeddings in a data-driven manner and capture complex latent\ndependencies. However, existing adaptive graph learning methods for traffic\nforecasting often either ignore the regularization of node embeddings, which\naccount for a significant proportion of model parameters, or face scalability\nissues from expensive graph convolution operations. To address these\nchallenges, we propose a Regularized Adaptive Graph Learning (RAGL) model.\nFirst, we introduce a regularized adaptive graph learning framework that\nsynergizes Stochastic Shared Embedding (SSE) and adaptive graph convolution via\na residual difference mechanism, achieving both embedding regularization and\nnoise suppression. Second, to ensure scalability on large road networks, we\ndevelop the Efficient Cosine Operator (ECO), which performs graph convolution\nbased on the cosine similarity of regularized embeddings with linear time\ncomplexity. Extensive experiments on four large-scale real-world traffic\ndatasets show that RAGL consistently outperforms state-of-the-art methods in\nterms of prediction accuracy and exhibits competitive computational efficiency.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07179v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07484", "title": "CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization", "authors": ["Dasol Hong", "Wooju Lee", "Hyun Myung"], "summary": "Prompt tuning, which adapts vision-language models by freezing model\nparameters and optimizing only the prompt, has proven effective for\ntask-specific adaptations. The core challenge in prompt tuning is improving\nspecialization for a specific task and generalization for unseen domains.\nHowever, frozen encoders often produce misaligned features, leading to\nconfusion between classes and limiting specialization. To overcome this issue,\nwe propose a confusion-aware loss (CoA-loss) that improves specialization by\nrefining the decision boundaries between confusing classes. Additionally, we\nmathematically demonstrate that a mixture model can enhance generalization\nwithout compromising specialization. This is achieved using confidence-aware\nweights (CoA-weights), which adjust the weights of each prediction in the\nmixture model based on its confidence within the class domains. Extensive\nexperiments show that CoCoA-Mix, a mixture model with CoA-loss and CoA-weights,\noutperforms state-of-the-art methods by enhancing specialization and\ngeneralization. Our code is publicly available at\nhttps://github.com/url-kaist/CoCoA-Mix.", "comment": "8 pages, 5 figures; accepted at ICML 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07484v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07185", "title": "Learning based on neurovectors for tabular data: a new neural network approach", "authors": ["J. C. Husillos", "A. Gallego", "A. Roma", "A. Troncoso"], "summary": "In this paper, we present a novel learning approach based on Neurovectors, an\ninnovative paradigm that structures information through interconnected nodes\nand vector relationships for tabular data processing. Unlike traditional\nartificial neural networks that rely on weight adjustment through\nbackpropagation, Neurovectors encode information by structuring data in vector\nspaces where energy propagation, rather than traditional weight updates, drives\nthe learning process, enabling a more adaptable and explainable learning\nprocess. Our method generates dynamic representations of knowledge through\nneurovectors, thereby improving both the interpretability and efficiency of the\npredictive model. Experimental results using datasets from well-established\nrepositories such as the UCI machine learning repository and Kaggle are\nreported both for classification and regression. To evaluate its performance,\nwe compare our approach with standard machine learning and deep learning\nmodels, showing that Neurovectors achieve competitive accuracy.", "comment": "Submitted to 25th IEEE International Conference on Data Mining (ICDM\n  2025)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07185v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07489", "title": "Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video", "authors": ["Yahao Shi", "Yang Liu", "Yanmin Wu", "Xing Liu", "Chen Zhao", "Jie Luo", "Bin Zhou"], "summary": "We propose DriveAnyMesh, a method for driving mesh guided by monocular video.\nCurrent 4D generation techniques encounter challenges with modern rendering\nengines. Implicit methods have low rendering efficiency and are unfriendly to\nrasterization-based engines, while skeletal methods demand significant manual\neffort and lack cross-category generalization. Animating existing 3D assets,\ninstead of creating 4D assets from scratch, demands a deep understanding of the\ninput's 3D structure. To tackle these challenges, we present a 4D diffusion\nmodel that denoises sequences of latent sets, which are then decoded to produce\nmesh animations from point cloud trajectory sequences. These latent sets\nleverage a transformer-based variational autoencoder, simultaneously capturing\n3D shape and motion information. By employing a spatiotemporal,\ntransformer-based diffusion model, information is exchanged across multiple\nlatent frames, enhancing the efficiency and generalization of the generated\nresults. Our experimental results demonstrate that DriveAnyMesh can rapidly\nproduce high-quality animations for complex motions and is compatible with\nmodern rendering engines. This method holds potential for applications in both\nthe gaming and filming industries.", "comment": "technical report", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07489v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07191", "title": "Analyzing Breast Cancer Survival Disparities by Race and Demographic Location: A Survival Analysis Approach", "authors": ["Ramisa Farha", "Joshua O. Olukoya"], "summary": "This study employs a robust analytical framework to uncover patterns in\nsurvival outcomes among breast cancer patients from diverse racial and\ngeographical backgrounds. This research uses the SEER 2021 dataset to analyze\nbreast cancer survival outcomes to identify and comprehend dissimilarities. Our\napproach integrates exploratory data analysis (EDA), through this we identify\nkey variables that influence survival rates and employ survival analysis\ntechniques, including the Kaplan-Meier estimator and log-rank test and the\nadvanced modeling Cox Proportional Hazards model to determine how survival\nrates vary across racial groups and countries. Model validation and\ninterpretation are undertaken to ensure the reliability of our findings, which\nare documented comprehensively to inform policymakers and healthcare\nprofessionals. The outcome of this paper is a detailed version of statistical\nanalysis that not just highlights disparities in breast cancer treatment and\ncare but also serves as a foundational tool for developing targeted\ninterventions to address the inequalities effectively. Through this research,\nour aim is to contribute to the global efforts to improve breast cancer\noutcomes and reduce treatment disparities.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07191v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06494", "title": "JGS2: Near Second-order Converging Jacobi/Gauss-Seidel for GPU Elastodynamics", "authors": ["Lei Lan", "Zixuan Lu", "Chun Yuan", "Weiwei Xu", "Hao Su", "Huamin Wang", "Chenfanfu Jiang", "Yin Yang"], "summary": "In parallel simulation, convergence and parallelism are often seen as\ninherently conflicting objectives. Improved parallelism typically entails\nlighter local computation and weaker coupling, which unavoidably slow the\nglobal convergence. This paper presents a novel GPU algorithm that achieves\nconvergence rates comparable to fullspace Newton's method while maintaining\ngood parallelizability just like the Jacobi method. Our approach is built on a\nkey insight into the phenomenon of overshoot. Overshoot occurs when a local\nsolver aggressively minimizes its local energy without accounting for the\nglobal context, resulting in a local update that undermines global convergence.\nTo address this, we derive a theoretically second-order optimal solution to\nmitigate overshoot. Furthermore, we adapt this solution into a pre-computable\nform. Leveraging Cubature sampling, our runtime cost is only marginally higher\nthan the Jacobi method, yet our algorithm converges nearly quadratically as\nNewton's method. We also introduce a novel full-coordinate formulation for more\nefficient pre-computation. Our method integrates seamlessly with the\nincremental potential contact method and achieves second-order convergence for\nboth stiff and soft materials. Experimental results demonstrate that our\napproach delivers high-quality simulations and outperforms state-of-the-art GPU\nmethods with 50 to 100 times better convergence.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.06494v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07491", "title": "SpatialLM: Training Large Language Models for Structured Indoor Modeling", "authors": ["Yongsen Mao", "Junhao Zhong", "Chuan Fang", "Jia Zheng", "Rui Tang", "Hao Zhu", "Ping Tan", "Zihan Zhou"], "summary": "SpatialLM is a large language model designed to process 3D point cloud data\nand generate structured 3D scene understanding outputs. These outputs include\narchitectural elements like walls, doors, windows, and oriented object boxes\nwith their semantic categories. Unlike previous methods which exploit\ntask-specific network designs, our model adheres to the standard multimodal LLM\narchitecture and is fine-tuned directly from open-source LLMs.\n  To train SpatialLM, we collect a large-scale, high-quality synthetic dataset\nconsisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with\nground-truth 3D annotations, and conduct a careful study on various modeling\nand training decisions. On public benchmarks, our model gives state-of-the-art\nperformance in layout estimation and competitive results in 3D object\ndetection. With that, we show a feasible path for enhancing the spatial\nunderstanding capabilities of modern LLMs for applications in augmented\nreality, embodied robotics, and more.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07491v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07198", "title": "GGBall: Graph Generative Model on Poincaré Ball", "authors": ["Tianci Bu", "Chuanrui Wang", "Hao Ma", "Haoren Zheng", "Xin Lu", "Tailin Wu"], "summary": "Generating graphs with hierarchical structures remains a fundamental\nchallenge due to the limitations of Euclidean geometry in capturing exponential\ncomplexity. Here we introduce \\textbf{GGBall}, a novel hyperbolic framework for\ngraph generation that integrates geometric inductive biases with modern\ngenerative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder\n(HVQVAE) with a Riemannian flow matching prior defined via closed-form\ngeodesics. This design enables flow-based priors to model complex latent\ndistributions, while vector quantization helps preserve the curvature-aware\nstructure of the hyperbolic space. We further develop a suite of hyperbolic GNN\nand Transformer layers that operate entirely within the manifold, ensuring\nstability and scalability. Empirically, our model reduces degree MMD by over\n75\\% on Community-Small and over 40\\% on Ego-Small compared to state-of-the-art\nbaselines, demonstrating an improved ability to preserve topological\nhierarchies. These results highlight the potential of hyperbolic geometry as a\npowerful foundation for the generative modeling of complex, structured, and\nhierarchical data domains. Our code is available at\n\\href{https://github.com/AI4Science-WestlakeU/GGBall}{here}.", "comment": "29 pages, 3 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07198v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06495", "title": "Optimizing Optimizations: Case Study on Detecting Specific Types of Mathematical Optimization Constraints with E-Graphs in JijModeling", "authors": ["Hiromi Ishii", "Taro Shimizu", "Toshiki Teramura"], "summary": "In solving mathematical optimization problems efficiently, it is crucial to\nmake use of information about specific types of constraints, such as the\none-hot or Special-Ordered Set (SOS) constraints. In many cases, exploiting\nsuch information gives asymptotically better execution time. JijModeling, an\nindustrial-strength mathematical optimization modeller, achieves this by\nseparating the symbolic representation of an optimization problem from the\ninput data. In this paper, we will report a real-world case study on a\nconstraint detection mechanism modulo the algebraic congruence using e-graphs,\nand describe heuristic criteria for designing rewriting systems. We give\nbenchmarking result that shows the performance impact of the constraint\ndetection mechanism.\n  We also introduce egg_recursive, a utility library for writing egg-terms as\nrecursive abstract syntax trees, reducing the burden of writing and maintaining\ncomplex terms in S-expressions.", "comment": "To be presented at EGRAPHS '25\n  https://pldi25.sigplan.org/home/egraphs-2025", "cate": "cs.PL", "url": "http://arxiv.org/abs/2506.06495v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07497", "title": "Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency", "authors": ["Xiangyu Guo", "Zhanqian Wu", "Kaixin Xiong", "Ziyang Xu", "Lijun Zhou", "Gangwei Xu", "Shaoqing Xu", "Haiyang Sun", "Bing Wang", "Guang Chen", "Hangjun Ye", "Wenyu Liu", "Xinggang Wang"], "summary": "We present Genesis, a unified framework for joint generation of multi-view\ndriving videos and LiDAR sequences with spatio-temporal and cross-modal\nconsistency. Genesis employs a two-stage architecture that integrates a\nDiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR\ngenerator with NeRF-based rendering and adaptive sampling. Both modalities are\ndirectly coupled through a shared latent space, enabling coherent evolution\nacross visual and geometric domains. To guide the generation with structured\nsemantics, we introduce DataCrafter, a captioning module built on\nvision-language models that provides scene-level and instance-level\nsupervision. Extensive experiments on the nuScenes benchmark demonstrate that\nGenesis achieves state-of-the-art performance across video and LiDAR metrics\n(FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including\nsegmentation and 3D detection, validating the semantic fidelity and practical\nutility of the generated data.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07497v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07218", "title": "Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward", "authors": ["Tong Xiao", "Xin Xu", "Zhenya Huang", "Hongyu Gao", "Quan Liu", "Qi Liu", "Enhong Chen"], "summary": "Enhancing the multimodal reasoning capabilities of Multimodal Large Language\nModels (MLLMs) is a challenging task that has attracted increasing attention in\nthe community. Recently, several studies have applied Reinforcement Learning\nwith Verifiable Rewards (RLVR) to the multimodal domain in order to enhance the\nreasoning abilities of MLLMs. However, these works largely overlook the\nenhancement of multimodal perception capabilities in MLLMs, which serve as a\ncore prerequisite and foundational component of complex multimodal reasoning.\nThrough McNemar's test, we find that existing RLVR method fails to effectively\nenhance the multimodal perception capabilities of MLLMs, thereby limiting their\nfurther improvement in multimodal reasoning. To address this limitation, we\npropose Perception-R1, which introduces a novel visual perception reward that\nexplicitly encourages MLLMs to perceive the visual content accurately, thereby\ncan effectively incentivizing both their multimodal perception and reasoning\ncapabilities. Specifically, we first collect textual visual annotations from\nthe CoT trajectories of multimodal problems, which will serve as visual\nreferences for reward assignment. During RLVR training, we employ a judging LLM\nto assess the consistency between the visual annotations and the responses\ngenerated by MLLM, and assign the visual perception reward based on these\nconsistency judgments. Extensive experiments on several multimodal reasoning\nbenchmarks demonstrate the effectiveness of our Perception-R1, which achieves\nstate-of-the-art performance on most benchmarks using only 1,442 training data.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07218v1", "AI": {"title_translation": "通过视觉感知奖励提升多模态大语言模型的多模态推理能力", "tldr": "本文提出Perception-R1，通过引入视觉感知奖励来解决现有强化学习方法在多模态大语言模型（MLLMs）中忽视多模态感知能力的问题，从而有效提升MLLMs的多模态感知和推理能力，并在多个基准测试中取得了最先进的性能。", "motivation": "增强多模态大语言模型（MLLMs）的多模态推理能力是一项具有挑战性的任务。现有结合可验证奖励的强化学习（RLVR）方法在提升MLLMs推理能力时，却在很大程度上忽视了作为复杂多模态推理核心前提和基础组成部分的多模态感知能力的提升。McNemar's检验发现，现有RLVR方法未能有效增强MLLMs的多模态感知能力，从而限制了它们在多模态推理方面的进一步改进。", "method": "本文提出了Perception-R1方法，其核心是引入一种新颖的视觉感知奖励，明确鼓励MLLMs准确感知视觉内容。具体步骤包括：首先，从多模态问题的CoT轨迹中收集文本视觉标注，作为奖励分配的视觉参考。其次，在RLVR训练过程中，使用一个判断型大语言模型（judging LLM）来评估视觉标注与MLLM生成响应之间的一致性。最后，根据这些一致性判断来分配视觉感知奖励。", "result": "在多个多模态推理基准测试上进行的广泛实验证明了Perception-R1的有效性。该方法在大多数基准测试上取得了最先进的性能，且仅使用了1,442个训练数据。", "conclusion": "通过引入视觉感知奖励，Perception-R1成功解决了现有RLVR方法在提升多模态大语言模型推理能力时忽视多模态感知能力的问题，从而有效激励了MLLMs的多模态感知和推理能力，并取得了显著的性能提升。", "translation": "增强多模态大语言模型（MLLMs）的多模态推理能力是一项具有挑战性的任务，并日益受到社区的关注。最近，一些研究已将结合可验证奖励的强化学习（RLVR）应用于多模态领域，以增强MLLMs的推理能力。然而，这些工作在很大程度上忽视了MLLMs多模态感知能力的提升，而多模态感知能力是复杂多模态推理的核心前提和基础组成部分。通过McNemar's检验，我们发现现有的RLVR方法未能有效增强MLLMs的多模态感知能力，从而限制了它们在多模态推理方面的进一步改进。为了解决这一限制，我们提出了Perception-R1，它引入了一种新颖的视觉感知奖励，明确鼓励MLLMs准确感知视觉内容，从而能有效激励它们的多模态感知和推理能力。具体而言，我们首先从多模态问题的CoT轨迹中收集文本视觉标注，这些标注将作为奖励分配的视觉参考。在RLVR训练期间，我们采用一个判断型大语言模型（judging LLM）来评估视觉标注与MLLM生成响应之间的一致性，并根据这些一致性判断来分配视觉感知奖励。在多个多模态推理基准测试上进行的广泛实验证明了我们的Perception-R1的有效性，它在大多数基准测试上使用仅1,442个训练数据就取得了最先进的性能。", "summary": "本文针对多模态大语言模型（MLLMs）在多模态推理中忽视多模态感知能力的问题，提出了一种名为Perception-R1的新方法。该方法通过引入独特的视觉感知奖励来解决现有强化学习与可验证奖励（RLVR）方法的不足。Perception-R1通过收集视觉标注作为参考，并利用一个判断型大语言模型评估MLLM响应与视觉标注的一致性来分配奖励，从而明确鼓励MLLMs准确感知视觉内容。实验结果表明，Perception-R1在多个多模态推理基准测试上取得了最先进的性能，有效提升了MLLMs的多模态感知和推理能力。", "keywords": "多模态大语言模型, 视觉感知, 强化学习, 多模态推理, 感知奖励", "comments": "该论文的创新点在于明确识别并解决了现有RLVR方法在提升MLLM推理能力时忽视多模态感知能力的关键限制。通过引入专门的视觉感知奖励，Perception-R1提供了一种新颖且有效的方式来增强MLLMs的底层感知基础，这对于复杂的推理至关重要。仅使用少量训练数据（1,442个）就达到SOTA性能，这表明了该方法的效率和潜力，为未来MLLM的感知增强研究开辟了新方向。"}}
{"id": "2506.07533", "title": "MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts", "authors": ["Wei Tao", "Haocheng Lu", "Xiaoyang Qu", "Bin Zhang", "Kai Lu", "Jiguang Wan", "Jianzong Wang"], "summary": "One of the primary challenges in optimizing large language models (LLMs) for\nlong-context inference lies in the high memory consumption of the Key-Value\n(KV) cache. Existing approaches, such as quantization, have demonstrated\npromising results in reducing memory usage. However, current quantization\nmethods cannot take both effectiveness and efficiency into account. In this\npaper, we propose MoQAE, a novel mixed-precision quantization method via\nmixture of quantization-aware experts. First, we view different quantization\nbit-width configurations as experts and use the traditional mixture of experts\n(MoE) method to select the optimal configuration. To avoid the inefficiency\ncaused by inputting tokens one by one into the router in the traditional MoE\nmethod, we input the tokens into the router chunk by chunk. Second, we design a\nlightweight router-only fine-tuning process to train MoQAE with a comprehensive\nloss to learn the trade-off between model accuracy and memory usage. Finally,\nwe introduce a routing freezing (RF) and a routing sharing (RS) mechanism to\nfurther reduce the inference overhead. Extensive experiments on multiple\nbenchmark datasets demonstrate that our method outperforms state-of-the-art KV\ncache quantization approaches in both efficiency and effectiveness.", "comment": "Accepted by the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07533v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07229", "title": "VARSHAP: Addressing Global Dependency Problems in Explainable AI with Variance-Based Local Feature Attribution", "authors": ["Mateusz Gajewski", "Mikołaj Morzy", "Adam Karczmarz", "Piotr Sankowski"], "summary": "Existing feature attribution methods like SHAP often suffer from global\ndependence, failing to capture true local model behavior. This paper introduces\nVARSHAP, a novel model-agnostic local feature attribution method which uses the\nreduction of prediction variance as the key importance metric of features.\nBuilding upon Shapley value framework, VARSHAP satisfies the key Shapley\naxioms, but, unlike SHAP, is resilient to global data distribution shifts.\nExperiments on synthetic and real-world datasets demonstrate that VARSHAP\noutperforms popular methods such as KernelSHAP or LIME, both quantitatively and\nqualitatively.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07229v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06500", "title": "Improving LLM-Powered EDA Assistants with RAFT", "authors": ["Luyao Shi", "Michael Kazda", "Charles Schmitter", "Hemlata Gupta"], "summary": "Electronic design engineers often struggle to efficiently access relevant\ninformation for tasks like design verification and technology development.\nWhile large language models (LLMs) can enhance productivity as conversational\nagents, pre-trained open-source LLMs lack domain-specific knowledge for\nElectronic Design Automation (EDA). In a Retrieval-Augmented Generation (RAG)\ncontext, LLMs rely on external context but may still produce inaccurate\nresponses. Retrieval-Augmented Fine-Tuning (RAFT) improves LLM performance, but\nacquiring labeled question/answer (Q/A) data in EDA is difficult. To address\nthis, we propose using synthetic Q/A datasets to enhance LLMs with RAFT. Our\nresults show that RAFT with synthetic data significantly boosts LLM performance\nfor RAG-based EDA tasks. We also investigate the impact of using real user\nquestions as Retrieval-Augmented Few-Shot (RAFS) examples for synthetic data\ngeneration. Additionally, we implement secure access control to ensure\nsensitive information is only accessible to authorized personnel. Finally, we\nassess the risk of data leakage and unintended memorization during fine-tuning\nwith synthetic data, providing practical insights.", "comment": "Accepted paper at IEEE International Conference on LLM-Aided Design,\n  2025 (LAD 2025)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06500v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07539", "title": "Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study", "authors": ["Xiaomeng Zhu", "Jacob Henningsson", "Duruo Li", "Pär Mårtensson", "Lars Hanson", "Mårten Björkman", "Atsuto Maki"], "summary": "This paper addresses key aspects of domain randomization in generating\nsynthetic data for manufacturing object detection applications. To this end, we\npresent a comprehensive data generation pipeline that reflects different\nfactors: object characteristics, background, illumination, camera settings, and\npost-processing. We also introduce the Synthetic Industrial Parts Object\nDetection dataset (SIP15-OD) consisting of 15 objects from three industrial use\ncases under varying environments as a test bed for the study, while also\nemploying an industrial dataset publicly available for robotic applications. In\nour experiments, we present more abundant results and insights into the\nfeasibility as well as challenges of sim-to-real object detection. In\nparticular, we identified material properties, rendering methods,\npost-processing, and distractors as important factors. Our method, leveraging\nthese, achieves top performance on the public dataset with Yolov8 models\ntrained exclusively on synthetic data; mAP@50 scores of 96.4% for the robotics\ndataset, and 94.1%, 99.5%, and 95.3% across three of the SIP15-OD use cases,\nrespectively. The results showcase the effectiveness of the proposed domain\nrandomization, potentially covering the distribution close to real data for the\napplications.", "comment": "This is accepted by 2025 IEEE International Conference on Robotics &\n  Automation (ICRA), waiting for publication. 14 pages, 14 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07539v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06344", "title": "A Reinforcement Learning Approach for RIS-aided Fair Communications", "authors": ["Alex Pierron", "Michel Barbeau", "Luca De Cicco", "Jose Rubio-Hernan", "Joaquin Garcia-Alfaro"], "summary": "Reconfigurable Intelligent Surfaces (RISs) are composed of physical elements\nthat can dynamically alter electromagnetic wave properties to enhance\nbeamforming and leading to improvements in areas with low coverage properties.\nThey have the potential to be combined with Reinforcement Learning (RL)\ntechniques to achieve network performance and energy efficiency via\noptimization techniques. In addition to performance and energy improvements, it\nis also crucial to consider the concept of fair communications. RISs must\nensure that User Equipment (UE) units receive their signals with adequate\nstrength, without other UE being deprived of service due to insufficient power.\nIn this paper, we address such a problem. We explore the fairness properties of\nprevious work and propose a novel method that aims at obtaining an efficient\nand fair duplex RIS-RL system for multiple legitimate UE units. We report and\ndiscuss our experimental work and simulation results. We also release our code\nand datasets to foster further research in the topic.", "comment": "7 pages, 6 figures, 1 table, 16 references", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06344v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07240", "title": "Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path Lengths in LLMs", "authors": ["Roy Eisenstadt", "Itamar Zimerman", "Lior Wolf"], "summary": "Recently, techniques such as explicit structured reasoning have demonstrated\nstrong test-time scaling behavior by enforcing a separation between the model's\ninternal \"thinking\" process and the final response. A key factor influencing\nanswer quality in this setting is the length of the thinking stage. When the\nreasoning is too short, the model may fail to capture the complexity of the\ntask. Conversely, when it is too long, the model may overthink, leading to\nunnecessary computation and degraded performance. This paper explores and\nexploits the underlying mechanisms by which LLMs understand and regulate the\nlength of their reasoning during explicit thought processes. First, we show\nthat LLMs encode their progress through the reasoning process and introduce an\ninteractive progress bar visualization, which is then used to reveal insights\non the model's planning dynamics. Second, we manipulate the internal progress\nencoding during inference to reduce unnecessary steps and generate a more\nconcise and decisive chain of thoughts. Our empirical results demonstrate that\nthis \"overclocking\" method mitigates overthinking, improves answer accuracy,\nand reduces inference latency. Our code is publicly available.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07240v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07542", "title": "APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs", "authors": ["Bowen Liu", "Weiyi Zhang", "Peranut Chotcomwongse", "Xiaolan Chen", "Ruoyu Chen", "Pawin Pakaymaskul", "Niracha Arjkongharn", "Nattaporn Vongsa", "Xuelian Cheng", "Zongyuan Ge", "Kun Huang", "Xiaohui Li", "Yiru Duan", "Zhenbang Wang", "BaoYe Xie", "Qiang Chen", "Huazhu Fu", "Michael A. Mahr", "Jiaqi Qu", "Wangyiyang Chen", "Shiye Wang", "Yubo Tan", "Yongjie Li", "Mingguang He", "Danli Shi", "Paisan Ruamviboonsuk"], "summary": "Optical Coherence Tomography (OCT) provides high-resolution, 3D, and\nnon-invasive visualization of retinal layers in vivo, serving as a critical\ntool for lesion localization and disease diagnosis. However, its widespread\nadoption is limited by equipment costs and the need for specialized operators.\nIn comparison, 2D color fundus photography offers faster acquisition and\ngreater accessibility with less dependence on expensive devices. Although\ngenerative artificial intelligence has demonstrated promising results in\nmedical image synthesis, translating 2D fundus images into 3D OCT images\npresents unique challenges due to inherent differences in data dimensionality\nand biological information between modalities. To advance generative models in\nthe fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society\n(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCT\nGeneration from Fundus Images. This paper details the challenge framework\n(referred to as APTOS-2024 Challenge), including: the benchmark dataset,\nevaluation methodology featuring two fidelity metrics-image-based distance\n(pixel-level OCT B-scan similarity) and video-based distance (semantic-level\nvolumetric consistency), and analysis of top-performing solutions. The\nchallenge attracted 342 participating teams, with 42 preliminary submissions\nand 9 finalists. Leading methodologies incorporated innovations in hybrid data\npreprocessing or augmentation (cross-modality collaborative paradigms),\npre-training on external ophthalmic imaging datasets, integration of vision\nfoundation models, and model architecture improvement. The APTOS-2024 Challenge\nis the first benchmark demonstrating the feasibility of fundus-to-3D-OCT\nsynthesis as a potential solution for improving ophthalmic care accessibility\nin under-resourced healthcare settings, while helping to expedite medical\nresearch and clinical applications.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07542v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06345", "title": "Explainable-AI powered stock price prediction using time series transformers: A Case Study on BIST100", "authors": ["Sukru Selim Calik", "Andac Akyuz", "Zeynep Hilal Kilimci", "Kerem Colak"], "summary": "Financial literacy is increasingly dependent on the ability to interpret\ncomplex financial data and utilize advanced forecasting tools. In this context,\nthis study proposes a novel approach that combines transformer-based time\nseries models with explainable artificial intelligence (XAI) to enhance the\ninterpretability and accuracy of stock price predictions. The analysis focuses\non the daily stock prices of the five highest-volume banks listed in the\nBIST100 index, along with XBANK and XU100 indices, covering the period from\nJanuary 2015 to March 2025. Models including DLinear, LTSNet, Vanilla\nTransformer, and Time Series Transformer are employed, with input features\nenriched by technical indicators. SHAP and LIME techniques are used to provide\ntransparency into the influence of individual features on model outputs. The\nresults demonstrate the strong predictive capabilities of transformer models\nand highlight the potential of interpretable machine learning to empower\nindividuals in making informed investment decisions and actively engaging in\nfinancial markets.", "comment": null, "cate": "q-fin.ST", "url": "http://arxiv.org/abs/2506.06345v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07247", "title": "Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models", "authors": ["Ngoc-Quan Pham", "Tuan Truong", "Quyen Tran", "Tan Nguyen", "Dinh Phung", "Trung Le"], "summary": "We introduce Interactive Bayesian Distributional Robustness (IBDR), a novel\nBayesian inference framework that allows modeling the interactions between\nparticles, thereby enhancing ensemble quality through increased particle\ndiversity. IBDR is grounded in a generalized theoretical framework that\nconnects the distributional population loss with the approximate posterior,\nmotivating a practical dual optimization procedure that enforces distributional\nrobustness while fostering particle diversity. We evaluate IBDR's performance\nagainst various baseline methods using the VTAB-1K benchmark and the common\nreasoning language task. The results consistently show that IBDR outperforms\nthese baselines, underscoring its effectiveness in real-world applications.", "comment": "ICML 2025 (Poster)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07247v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07555", "title": "Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries", "authors": ["Haoxiang Wang", "Zinan Lin", "Da Yu", "Huishuai Zhang"], "summary": "Generating high fidelity, differentially private (DP) synthetic images offers\na promising route to share and analyze sensitive visual data without\ncompromising individual privacy. However, existing DP image synthesis methods\nstruggle to produce high resolution outputs that faithfully capture the\nstructure of the original data. In this paper, we introduce a novel method,\nreferred to as Synthesis via Private Textual Intermediaries (SPTI), that can\ngenerate high resolution DP images with easy adoption. The key idea is to shift\nthe challenge of DP image synthesis from the image domain to the text domain by\nleveraging state of the art DP text generation methods. SPTI first summarizes\neach private image into a concise textual description using image to text\nmodels, then applies a modified Private Evolution algorithm to generate DP\ntext, and finally reconstructs images using text to image models. Notably, SPTI\nrequires no model training, only inference with off the shelf models. Given a\nprivate dataset, SPTI produces synthetic images of substantially higher quality\nthan prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID less\nthan or equal to 26.71 under epsilon equal to 1.0, improving over Private\nEvolution FID of 40.36. Similarly, on MM CelebA HQ, SPTI achieves an FID less\nthan or equal to 33.27 at epsilon equal to 1.0, compared to 57.01 from DP fine\ntuning baselines. Overall, our results demonstrate that Synthesis via Private\nTextual Intermediaries provides a resource efficient and proprietary model\ncompatible framework for generating high resolution DP synthetic images,\ngreatly expanding access to private visual datasets.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07555v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07254", "title": "A Stable Whitening Optimizer for Efficient Neural Network Training", "authors": ["Kevin Frans", "Sergey Levine", "Pieter Abbeel"], "summary": "In this work, we take an experimentally grounded look at neural network\noptimization. Building on the Shampoo family of algorithms, we identify and\nalleviate three key issues, resulting in the proposed SPlus method. First, we\nfind that naive Shampoo is prone to divergence when matrix-inverses are cached\nfor long periods. We introduce an alternate bounded update combining a\nhistorical eigenbasis with instantaneous normalization, resulting in\nacross-the-board stability and significantly lower computational requirements.\nSecond, we adapt a shape-aware scaling to enable learning rate transfer across\nnetwork width. Third, we find that high learning rates result in large\nparameter noise, and propose a simple iterate-averaging scheme which unblocks\nfaster learning. To properly confirm these findings, we introduce a pointed\nTransformer training benchmark, considering three objectives (language\nmodelling, image classification, and diffusion modelling) across different\nstages of training. On average, SPlus is able to reach the validation\nperformance of Adam within 44% of the gradient steps and 62% of the wallclock\ntime.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07254v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06506", "title": "Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes", "authors": ["Kshitish Ghate", "Tessa Charlesworth", "Mona Diab", "Aylin Caliskan"], "summary": "To build fair AI systems we need to understand how social-group biases\nintrinsic to foundational encoder-based vision-language models (VLMs) manifest\nin biases in downstream tasks. In this study, we demonstrate that intrinsic\nbiases in VLM representations systematically ``carry over'' or propagate into\nzero-shot retrieval tasks, revealing how deeply rooted biases shape a model's\noutputs. We introduce a controlled framework to measure this propagation by\ncorrelating (a) intrinsic measures of bias in the representational space with\n(b) extrinsic measures of bias in zero-shot text-to-image (TTI) and\nimage-to-text (ITT) retrieval. Results show substantial correlations between\nintrinsic and extrinsic bias, with an average $\\rho$ = 0.83 $\\pm$ 0.10. This\npattern is consistent across 114 analyses, both retrieval directions, six\nsocial groups, and three distinct VLMs. Notably, we find that\nlarger/better-performing models exhibit greater bias propagation, a finding\nthat raises concerns given the trend towards increasingly complex AI models.\nOur framework introduces baseline evaluation tasks to measure the propagation\nof group and valence signals. Investigations reveal that underrepresented\ngroups experience less robust propagation, further skewing their model-related\noutcomes.", "comment": "Accepted to ACL Findings 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06506v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07559", "title": "Cross-channel Perception Learning for H&E-to-IHC Virtual Staining", "authors": ["Hao Yang", "JianYu Wu", "Run Fang", "Xuelian Zhao", "Yuan Ji", "Zhiyu Chen", "Guibin He", "Junceng Guo", "Yang Liu", "Xinhua Zeng"], "summary": "With the rapid development of digital pathology, virtual staining has become\na key technology in multimedia medical information systems, offering new\npossibilities for the analysis and diagnosis of pathological images. However,\nexisting H&E-to-IHC studies often overlook the cross-channel correlations\nbetween cell nuclei and cell membranes. To address this issue, we propose a\nnovel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPL\nfirst decomposes HER2 immunohistochemical staining into Hematoxylin and DAB\nstaining channels, corresponding to cell nuclei and cell membranes,\nrespectively. Using the pathology foundation model Gigapath's Tile Encoder,\nCCPL extracts dual-channel features from both the generated and real images and\nmeasures cross-channel correlations between nuclei and membranes. The features\nof the generated and real stained images, obtained through the Tile Encoder,\nare also used to calculate feature distillation loss, enhancing the model's\nfeature extraction capabilities without increasing the inference burden.\nAdditionally, CCPL performs statistical analysis on the focal optical density\nmaps of both single channels to ensure consistency in staining distribution and\nintensity. Experimental results, based on quantitative metrics such as PSNR,\nSSIM, PCC, and FID, along with professional evaluations from pathologists,\ndemonstrate that CCPL effectively preserves pathological features, generates\nhigh-quality virtual stained images, and provides robust support for automated\npathological diagnosis using multimedia medical data.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07559v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06351", "title": "Deep learning methods for modeling infrasound transmission loss in the middle atmosphere", "authors": ["Alexis Le Pichon", "Alice Janela Cameijo", "Samir Aknine", "Youcef Sklab", "Souhila Arib", "Quentin Brissaud", "Sven Peter Naesholm"], "summary": "Accurate modeling of infrasound transmission losses (TLs) is essential to\nassess the performance of the global International Monitoring System infrasound\nnetwork. Among existing propagation modeling tools, parabolic equation (PE)\nmethod enables TLs to be finely modeled, but its computational cost does not\nallow exploration of a large parameter space for operational monitoring\napplications. To reduce computation times, Brissaud et al. 2023 explored the\npotential of convolutional neural networks trained on a large set of regionally\nsimulated wavefields (< 1000 km from the source) to predict TLs with negligible\ncomputation times compared to PE simulations. However, this method struggles in\nunfavorable initial wind conditions, especially at high frequencies, and causal\nissues with winds at large distances from the source affecting ground TLs close\nto the source. In this study, we have developed an optimized convolutional\nnetwork designed to minimize prediction errors while predicting TLs from\nglobally simulated combined temperature and wind fields spanning over\npropagation ranges of 4000 km. Our approach enhances the previously proposed\none by implementing key optimizations that improve the overall architecture\nperformance. The implemented model predicts TLs with an average error of 8.6 dB\nin the whole frequency band (0.1-3.2 Hz) and explored realistic atmospheric\nscenarios.", "comment": "12 pages, 7 figures", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06351v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07272", "title": "A Cramér-von Mises Approach to Incentivizing Truthful Data Sharing", "authors": ["Alex Clinton", "Thomas Zeng", "Yiding Chen", "Xiaojin Zhu", "Kirthevasan Kandasamy"], "summary": "Modern data marketplaces and data sharing consortia increasingly rely on\nincentive mechanisms to encourage agents to contribute data. However, schemes\nthat reward agents based on the quantity of submitted data are vulnerable to\nmanipulation, as agents may submit fabricated or low-quality data to inflate\ntheir rewards. Prior work has proposed comparing each agent's data against\nothers' to promote honesty: when others contribute genuine data, the best way\nto minimize discrepancy is to do the same. Yet prior implementations of this\nidea rely on very strong assumptions about the data distribution (e.g.\nGaussian), limiting their applicability. In this work, we develop reward\nmechanisms based on a novel, two-sample test inspired by the Cram\\'er-von Mises\nstatistic. Our methods strictly incentivize agents to submit more genuine data,\nwhile disincentivizing data fabrication and other types of untruthful\nreporting. We establish that truthful reporting constitutes a (possibly\napproximate) Nash equilibrium in both Bayesian and prior-agnostic settings. We\ntheoretically instantiate our method in three canonical data sharing problems\nand show that it relaxes key assumptions made by prior work. Empirically, we\ndemonstrate that our mechanism incentivizes truthful data sharing via\nsimulations and on real-world language and image data.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07272v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07565", "title": "OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data", "authors": ["Jinlu Zhang", "Zixi Kang", "Yizhou Wang"], "summary": "Music-driven dance generation offers significant creative potential yet faces\nconsiderable challenges. The absence of fine-grained multimodal data and the\ndifficulty of flexible multi-conditional generation limit previous works on\ngeneration controllability and diversity in practice. In this paper, we build\nOpenDance5D, an extensive human dance dataset comprising over 101 hours across\n14 distinct genres. Each sample has five modalities to facilitate robust\ncross-modal learning: RGB video, audio, 2D keypoints, 3D motion, and\nfine-grained textual descriptions from human arts. Furthermore, we propose\nOpenDanceNet, a unified masked modeling framework for controllable dance\ngeneration conditioned on music and arbitrary combinations of text prompts,\nkeypoints, or character positioning. Comprehensive experiments demonstrate that\nOpenDanceNet achieves high-fidelity and flexible controllability.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07565v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06353", "title": "Large Language Models for EEG: A Comprehensive Survey and Taxonomy", "authors": ["Naseem Babu", "Jimson Mathew", "A. P. Vinod"], "summary": "The growing convergence between Large Language Models (LLMs) and\nelectroencephalography (EEG) research is enabling new directions in neural\ndecoding, brain-computer interfaces (BCIs), and affective computing. This\nsurvey offers a systematic review and structured taxonomy of recent\nadvancements that utilize LLMs for EEG-based analysis and applications. We\norganize the literature into four domains: (1) LLM-inspired foundation models\nfor EEG representation learning, (2) EEG-to-language decoding, (3) cross-modal\ngeneration including image and 3D object synthesis, and (4) clinical\napplications and dataset management tools. The survey highlights how\ntransformer-based architectures adapted through fine-tuning, few-shot, and\nzero-shot learning have enabled EEG-based models to perform complex tasks such\nas natural language generation, semantic interpretation, and diagnostic\nassistance. By offering a structured overview of modeling strategies, system\ndesigns, and application areas, this work serves as a foundational resource for\nfuture work to bridge natural language processing and neural signal analysis\nthrough language models.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06353v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07275", "title": "Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models", "authors": ["Haochen Song", "Dominik Hofer", "Rania Islambouli", "Laura Hawkins", "Ananya Bhattacharjee", "Meredith Franklin", "Joseph Jay Williams"], "summary": "Machine learning approaches, such as contextual multi-armed bandit (cMAB)\nalgorithms, offer a promising strategy to reduce sedentary behavior by\ndelivering personalized interventions to encourage physical activity. However,\ncMAB algorithms typically require large participant samples to learn\neffectively and may overlook key psychological factors that are not explicitly\nencoded in the model. In this study, we propose a hybrid approach that combines\ncMAB for selecting intervention types with large language models (LLMs) to\npersonalize message content. We evaluate four intervention types: behavioral\nself-monitoring, gain-framed, loss-framed, and social comparison, each\ndelivered as a motivational message aimed at increasing motivation for physical\nactivity and daily step count. Message content is further personalized using\ndynamic contextual factors including daily fluctuations in self-efficacy,\nsocial influence, and regulatory focus. Over a seven-day trial, participants\nreceive daily messages assigned by one of four models: cMAB alone, LLM alone,\ncombined cMAB with LLM personalization (cMABxLLM), or equal randomization\n(RCT). Outcomes include daily step count and message acceptance, assessed via\necological momentary assessments (EMAs). We apply a causal inference framework\nto evaluate the effects of each model. Our findings offer new insights into the\ncomplementary roles of LLM-based personalization and cMAB adaptation in\npromoting physical activity through personalized behavioral messaging.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07275v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07566", "title": "Towards the Influence of Text Quantity on Writer Retrieval", "authors": ["Marco Peer", "Robert Sablatnig", "Florian Kleber"], "summary": "This paper investigates the task of writer retrieval, which identifies\ndocuments authored by the same individual within a dataset based on handwriting\nsimilarities. While existing datasets and methodologies primarily focus on page\nlevel retrieval, we explore the impact of text quantity on writer retrieval\nperformance by evaluating line- and word level retrieval. We examine three\nstate-of-the-art writer retrieval systems, including both handcrafted and deep\nlearning-based approaches, and analyze their performance using varying amounts\nof text. Our experiments on the CVL and IAM dataset demonstrate that while\nperformance decreases by 20-30% when only one line of text is used as query and\ngallery, retrieval accuracy remains above 90% of full-page performance when at\nleast four lines are included. We further show that text-dependent retrieval\ncan maintain strong performance in low-text scenarios. Our findings also\nhighlight the limitations of handcrafted features in low-text scenarios, with\ndeep learning-based methods like NetVLAD outperforming traditional VLAD\nencoding.", "comment": "accepted for ICDAR2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07566v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06358", "title": "Towards real-time assessment of infrasound event detection capability using deep learning-based transmission loss estimation", "authors": ["Alice Janela Cameijo", "Alexis Le Pichon", "Youcef Sklab", "Souhila Arib", "Quentin Brissaud", "Sven peter Naesholm", "Constantino Listowski", "Samir Aknine"], "summary": "Accurate modeling of infrasound transmission loss is essential for evaluating\nthe performance of the International Monitoring System, enabling the effective\ndesign and maintenance of infrasound stations to support compliance of the\nComprehensive Nuclear-Test-Ban Treaty. State-of-the-art propagation modeling\ntools enable transmission loss to be finely simulated using atmospheric models.\nHowever, the computational cost prohibits the exploration of a large parameter\nspace in operational monitoring applications. To address this, recent studies\nmade use of a deep learning algorithm capable of making transmission loss\npredictions almost instantaneously. However, the use of nudged atmospheric\nmodels leads to an incomplete representation of the medium, and the absence of\ntemperature as an input makes the algorithm incompatible with long range\npropagation. In this study, we address these limitations by using both wind and\ntemperature fields as inputs to a neural network, simulated up to 130 km\naltitude and 4,000 km distance. We also optimize several aspects of the neural\nnetwork architecture. We exploit convolutional and recurrent layers to capture\nspatially and range-dependent features embedded in realistic atmospheric\nmodels, improving the overall performance. The neural network reaches an\naverage error of 4 dB compared to full parabolic equation simulations and\nprovides epistemic and data-related uncertainty estimates. Its evaluation on\nthe 2022 Hunga Tonga-Hunga Ha'apai volcanic eruption demonstrates its\nprediction capability using atmospheric conditions and frequencies not included\nin the training. This represents a significant step towards near real-time\nassessment of International Monitoring System detection thresholds of explosive\nsources.", "comment": "49 pages, 22 figures", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06358v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07276", "title": "Tokenized Bandit for LLM Decoding and Alignment", "authors": ["Suho Shin", "Chenghao Yang", "Haifeng Xu", "Mohammad T. Hajiaghayi"], "summary": "We introduce the tokenized linear bandit (TLB) and multi-armed bandit (TMAB),\nvariants of linear and stochastic multi-armed bandit problems inspired by LLM\ndecoding and alignment. In these problems, at each round $t \\in [T]$, a user\nsubmits a query (context), and the decision maker (DM) sequentially selects a\ntoken irrevocably from a token set. Once the sequence is complete, the DM\nobserves a random utility from the user, whose expectation is presented by a\nsequence function mapping the chosen token sequence to a nonnegative real value\nthat depends on the query.\n  In both problems, we first show that learning is impossible without any\nstructure on the sequence function. We introduce a natural assumption,\ndiminishing distance with more commons (DDMC), and propose algorithms with\nregret $\\tilde{O}(L\\sqrt{T})$ and $\\tilde{O}(L\\sqrt{T^{2/3}})$ for TLB and\nTMAB, respectively. As a side product, we obtain an (almost) optimality of the\ngreedy decoding for LLM decoding algorithm under DDMC, which justifies the\nunresaonable effectiveness of greedy decoding in several tasks. This also has\nan immediate application to decoding-time LLM alignment, when the misaligned\nutility can be represented as the frozen LLM's utility and a linearly\nrealizable latent function. We finally validate our algorithm's performance\nempirically as well as verify our assumptions using synthetic and real-world\ndatasets.", "comment": "To appear at ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07276v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07570", "title": "LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization", "authors": ["Yixuan Yang", "Zhen Luo", "Tongsheng Ding", "Junru Lu", "Mingqi Gao", "Jinyu Yang", "Victor Sanchez", "Feng Zheng"], "summary": "Automatic indoor layout generation has attracted increasing attention due to\nits potential in interior design, virtual environment construction, and\nembodied AI. Existing methods fall into two categories: prompt-driven\napproaches that leverage proprietary LLM services (e.g., GPT APIs) and\nlearning-based methods trained on layout data upon diffusion-based models.\nPrompt-driven methods often suffer from spatial inconsistency and high\ncomputational costs, while learning-based methods are typically constrained by\ncoarse relational graphs and limited datasets, restricting their generalization\nto diverse room categories. In this paper, we revisit LLM-based indoor layout\ngeneration and present 3D-SynthPlace, a large-scale dataset that combines\nsynthetic layouts generated via a 'GPT synthesize, Human inspect' pipeline,\nupgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000\nscenes, covering four common room types -- bedroom, living room, kitchen, and\nbathroom -- enriched with diverse objects and high-level spatial annotations.\nWe further introduce OptiScene, a strong open-source LLM optimized for indoor\nlayout generation, fine-tuned based on our 3D-SynthPlace dataset through our\ntwo-stage training. For the warum-up stage I, we adopt supervised fine-tuning\n(SFT), which is taught to first generate high-level spatial descriptions then\nconditionally predict concrete object placements. For the reinforcing stage II,\nto better align the generated layouts with human design preferences, we apply\nmulti-turn direct preference optimization (DPO), which significantly improving\nlayout quality and generation success rates. Extensive experiments demonstrate\nthat OptiScene outperforms traditional prompt-driven and learning-based\nbaselines. Moreover, OptiScene shows promising potential in interactive tasks\nsuch as scene editing and robot navigation.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07570v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07288", "title": "EviNet: Evidential Reasoning Network for Resilient Graph Learning in the Open and Noisy Environments", "authors": ["Weijie Guan", "Haohui Wang", "Jian Kang", "Lihui Liu", "Dawei Zhou"], "summary": "Graph learning has been crucial to many real-world tasks, but they are often\nstudied with a closed-world assumption, with all possible labels of data known\na priori. To enable effective graph learning in an open and noisy environment,\nit is critical to inform the model users when the model makes a wrong\nprediction to in-distribution data of a known class, i.e., misclassification\ndetection or when the model encounters out-of-distribution from novel classes,\ni.e., out-of-distribution detection. This paper introduces Evidential Reasoning\nNetwork (EVINET), a framework that addresses these two challenges by\nintegrating Beta embedding within a subjective logic framework. EVINET includes\ntwo key modules: Dissonance Reasoning for misclassification detection and\nVacuity Reasoning for out-of-distribution detection. Extensive experiments\ndemonstrate that EVINET outperforms state-of-the-art methods across multiple\nmetrics in the tasks of in-distribution classification, misclassification\ndetection, and out-of-distribution detection. EVINET demonstrates the necessity\nof uncertainty estimation and logical reasoning for misclassification detection\nand out-of-distribution detection and paves the way for open-world graph\nlearning. Our code and data are available at https://github.com/SSSKJ/EviNET.", "comment": "KDD 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07288v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07572", "title": "Learning Speaker-Invariant Visual Features for Lipreading", "authors": ["Yu Li", "Feng Xue", "Shujie Li", "Jinrui Zhang", "Shuang Yang", "Dan Guo", "Richang Hong"], "summary": "Lipreading is a challenging cross-modal task that aims to convert visual lip\nmovements into spoken text. Existing lipreading methods often extract visual\nfeatures that include speaker-specific lip attributes (e.g., shape, color,\ntexture), which introduce spurious correlations between vision and text. These\ncorrelations lead to suboptimal lipreading accuracy and restrict model\ngeneralization. To address this challenge, we introduce SIFLip, a\nspeaker-invariant visual feature learning framework that disentangles\nspeaker-specific attributes using two complementary disentanglement modules\n(Implicit Disentanglement and Explicit Disentanglement) to improve\ngeneralization. Specifically, since different speakers exhibit semantic\nconsistency between lip movements and phonetic text when pronouncing the same\nwords, our implicit disentanglement module leverages stable text embeddings as\nsupervisory signals to learn common visual representations across speakers,\nimplicitly decoupling speaker-specific features. Additionally, we design a\nspeaker recognition sub-task within the main lipreading pipeline to filter\nspeaker-specific features, then further explicitly disentangle these\npersonalized visual features from the backbone network via gradient reversal.\nExperimental results demonstrate that SIFLip significantly enhances\ngeneralization performance across multiple public datasets. Experimental\nresults demonstrate that SIFLip significantly improves generalization\nperformance across multiple public datasets, outperforming state-of-the-art\nmethods.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07572v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07298", "title": "Pre-trained Large Language Models Learn Hidden Markov Models In-context", "authors": ["Yijia Dai", "Zhaolin Gao", "Yahya Satter", "Sarah Dean", "Jennifer J. Sun"], "summary": "Hidden Markov Models (HMMs) are foundational tools for modeling sequential\ndata with latent Markovian structure, yet fitting them to real-world data\nremains computationally challenging. In this work, we show that pre-trained\nlarge language models (LLMs) can effectively model data generated by HMMs via\nin-context learning (ICL)$\\unicode{x2013}$their ability to infer patterns from\nexamples within a prompt. On a diverse set of synthetic HMMs, LLMs achieve\npredictive accuracy approaching the theoretical optimum. We uncover novel\nscaling trends influenced by HMM properties, and offer theoretical conjectures\nfor these empirical observations. We also provide practical guidelines for\nscientists on using ICL as a diagnostic tool for complex data. On real-world\nanimal decision-making tasks, ICL achieves competitive performance with models\ndesigned by human experts. To our knowledge, this is the first demonstration\nthat ICL can learn and predict HMM-generated sequences$\\unicode{x2013}$an\nadvance that deepens our understanding of in-context learning in LLMs and\nestablishes its potential as a powerful tool for uncovering hidden structure in\ncomplex scientific data.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07298v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07575", "title": "Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models", "authors": ["Ruiyang Zhang", "Hu Zhang", "Hao Fei", "Zhedong Zheng"], "summary": "Large Multimodal Models (LMMs), harnessing the complementarity among diverse\nmodalities, are often considered more robust than pure Language Large Models\n(LLMs); yet do LMMs know what they do not know? There are three key open\nquestions remaining: (1) how to evaluate the uncertainty of diverse LMMs in a\nunified manner, (2) how to prompt LMMs to show its uncertainty, and (3) how to\nquantify uncertainty for downstream tasks. In an attempt to address these\nchallenges, we introduce Uncertainty-o: (1) a model-agnostic framework designed\nto reveal uncertainty in LMMs regardless of their modalities, architectures, or\ncapabilities, (2) an empirical exploration of multimodal prompt perturbations\nto uncover LMM uncertainty, offering insights and findings, and (3) derive the\nformulation of multimodal semantic uncertainty, which enables quantifying\nuncertainty from multimodal responses. Experiments across 18 benchmarks\nspanning various modalities and 10 LMMs (both open- and closed-source)\ndemonstrate the effectiveness of Uncertainty-o in reliably estimating LMM\nuncertainty, thereby enhancing downstream tasks such as hallucination\ndetection, hallucination mitigation, and uncertainty-aware Chain-of-Thought\nreasoning.", "comment": "Project page: https://uncertainty-o.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07575v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07308", "title": "PASS: Private Attributes Protection with Stochastic Data Substitution", "authors": ["Yizhuo Chen", "Chun-Fu", "Chen", "Hsiang Hsu", "Shaohan Hu", "Tarek Abdelzaher"], "summary": "The growing Machine Learning (ML) services require extensive collections of\nuser data, which may inadvertently include people's private information\nirrelevant to the services. Various studies have been proposed to protect\nprivate attributes by removing them from the data while maintaining the\nutilities of the data for downstream tasks. Nevertheless, as we theoretically\nand empirically show in the paper, these methods reveal severe vulnerability\nbecause of a common weakness rooted in their adversarial training based\nstrategies. To overcome this limitation, we propose a novel approach, PASS,\ndesigned to stochastically substitute the original sample with another one\naccording to certain probabilities, which is trained with a novel loss function\nsoundly derived from information-theoretic objective defined for\nutility-preserving private attributes protection. The comprehensive evaluation\nof PASS on various datasets of different modalities, including facial images,\nhuman activity sensory signals, and voice recording datasets, substantiates\nPASS's effectiveness and generalizability.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07308v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06519", "title": "Hierarchical Debate-Based Large Language Model (LLM) for Complex Task Planning of 6G Network Management", "authors": ["Yuyan Lin", "Hao Zhou", "Chengming Hu", "Xue Liu", "Hao Chen", "Yan Xin", "Jianzhong", "Zhang"], "summary": "6G networks have become increasingly complicated due to novel network\narchitecture and newly emerging signal processing and transmission techniques,\nleading to significant burdens to 6G network management. Large language models\n(LLMs) have recently been considered a promising technique to equip 6G networks\nwith AI-native intelligence. Different from most existing studies that only\nconsider a single LLM, this work involves a multi-LLM debate-based scheme for\n6G network management, where multiple LLMs can collaboratively improve the\ninitial solution sequentially. Considering the complex nature of 6G domain, we\npropose a novel hierarchical debate scheme: LLMs will first debate the sub-task\ndecomposition, and then debate each subtask step-by-step. Such a hierarchical\napproach can significantly reduce the overall debate difficulty by sub-task\ndecomposition, aligning well with the complex nature of 6G networks and\nensuring the final solution qualities. In addition, to better evaluate the\nproposed technique, we have defined a novel dataset named 6GPlan, including 110\ncomplex 6G network management tasks and 5000 keyword solutions. Finally, the\nexperiments show that the proposed hierarchical debate can significantly\nimprove performance compared to baseline techniques, e.g. more than 30%\ncoverage rate and global recall rate improvement.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06519v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07576", "title": "Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding", "authors": ["Boyu Chen", "Siran Chen", "Kunchang Li", "Qinglin Xu", "Yu Qiao", "Yali Wang"], "summary": "Video understanding has been considered as one critical step towards world\nmodeling, which is an important long-term problem in AI research. Recently,\nmulti-modal foundation models have shown such potential via large-scale\npretraining. However, these models simply align encoders of different\nmodalities via contrastive learning, while lacking deeper multi-modal\ninteractions, which is critical for understanding complex target movements with\ndiversified video scenes. To fill this gap, we propose a unified Super Encoding\nNetwork (SEN) for video understanding, which builds up such distinct\ninteractions through recursive association of multi-modal encoders in the\nfoundation models. Specifically, we creatively treat those well-trained\nencoders as \"super neurons\" in our SEN. Via designing a Recursive Association\n(RA) block, we progressively fuse multi-modalities with the input video, based\non knowledge integrating, distributing, and prompting of super neurons in a\nrecursive manner. In this way, our SEN can effectively encode deeper\nmulti-modal interactions, for prompting various video understanding tasks in\ndownstream. Extensive experiments show that, our SEN can remarkably boost the\nfour most representative video tasks, including tracking, recognition,\nchatting, and editing, e.g., for pixel-level tracking, the average jaccard\nindex improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popular\nCaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,\nand frame consistency increases 4.1% compared to the popular TuneA-Video\napproach.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07576v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07311", "title": "Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference", "authors": ["Thomas Joshi", "Herman Saini", "Neil Dhillon", "Antoni Viros i Martin", "Kaoutar El Maghraoui"], "summary": "Large Language Models (LLMs) encounter severe memory inefficiencies during\nlong-context inference due to conventional handling of key-value (KV) caches.\nIn this work, we introduce a novel integration of PagedAttention with PyTorch's\nFlexAttention, addressing internal fragmentation and inefficiencies associated\nwith monolithic KV cache allocations. Implemented within IBM's Foundation Model\nStack (FMS), our fused attention kernel efficiently gathers scattered KV data.\nOur benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reduced\ninference latency, growing only linearly (~2x) with sequence length from 128 to\n2048 tokens when utilizing a global KV cache, compared to exponential latency\nincreases without caching. While peak memory usage remains largely unchanged\nfor single-step evaluations (dominated by model weights and activations), paged\nattention causes minimal incremental memory usage, observable only at sequence\nlengths exceeding 2048 tokens due to its power-of-two cache allocations. We\nopen-source the full implementation and discuss its implications for future\nlong-context model deployment.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07311v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07590", "title": "Explore the vulnerability of black-box models via diffusion models", "authors": ["Jiacheng Shi", "Yanfu Zhang", "Huajie Shao", "Ashley Gao"], "summary": "Recent advancements in diffusion models have enabled high-fidelity and\nphotorealistic image generation across diverse applications. However, these\nmodels also present security and privacy risks, including copyright violations,\nsensitive information leakage, and the creation of harmful or offensive content\nthat could be exploited maliciously. In this study, we uncover a novel security\nthreat where an attacker leverages diffusion model APIs to generate synthetic\nimages, which are then used to train a high-performing substitute model. This\nenables the attacker to execute model extraction and transfer-based adversarial\nattacks on black-box classification models with minimal queries, without\nneeding access to the original training data. The generated images are\nsufficiently high-resolution and diverse to train a substitute model whose\noutputs closely match those of the target model. Across the seven benchmarks,\nincluding CIFAR and ImageNet subsets, our method shows an average improvement\nof 27.37% over state-of-the-art methods while using just 0.01 times of the\nquery budget, achieving a 98.68% success rate in adversarial attacks on the\ntarget model.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07590v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07312", "title": "Generative Modeling of Networked Time-Series via Transformer Architectures", "authors": ["Yusuf Elnady"], "summary": "Many security and network applications require having large datasets to train\nthe machine learning models. Limited data access is a well-known problem in the\nsecurity domain. Recent studies have shown the potential of Transformer models\nto enlarge the size of data by synthesizing new samples, but the synthesized\nsamples don't improve the models over the real data. To address this issue, we\ndesign an efficient transformer-based model as a generative framework to\ngenerate time-series data, that can be used to boost the performance of\nexisting and new ML workflows. Our new transformer model achieves the SOTA\nresults. We style our model to be generalizable and work across different\ndatasets, and produce high-quality samples.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07312v1", "AI": {"title_translation": "变压器架构下的网络时间序列生成建模", "tldr": "针对安全领域数据有限的问题，本文提出了一种高效的基于Transformer的生成模型，用于生成高质量时间序列数据，以提升机器学习模型性能，并达到SOTA结果。", "motivation": "许多安全和网络应用需要大量数据集来训练机器学习模型，但数据获取受限是一个普遍问题。现有Transformer模型生成的合成样本未能有效提升模型性能。", "method": "设计了一种高效的基于Transformer的生成框架，用于生成时间序列数据。", "result": "该新型Transformer模型取得了SOTA结果，能够跨不同数据集工作，并生成高质量样本，从而提升现有和新型ML工作流的性能。", "conclusion": "通过设计高效的基于Transformer的生成模型，可以有效解决安全领域数据受限问题，生成高质量时间序列数据，并显著提升机器学习模型的性能。", "translation": "许多安全和网络应用需要大量数据集来训练机器学习模型。有限的数据访问是安全领域的一个众所周知的问题。最近的研究表明，Transformer模型有潜力通过合成新样本来扩大数据规模，但合成样本并未比真实数据更好地改进模型。为了解决这个问题，我们设计了一种高效的基于Transformer的模型作为生成框架，用于生成时间序列数据，该数据可用于提升现有和新型机器学习工作流的性能。我们的新型Transformer模型取得了SOTA结果。我们对模型进行了设计，使其具有通用性，可在不同数据集上工作，并生成高质量样本。", "summary": "本文针对安全和网络应用中数据有限的问题，提出了一种高效的基于Transformer的生成模型。该模型旨在生成高质量的时间序列数据，以弥补数据不足并提升机器学习模型的性能。实验结果表明，该模型达到了最先进的性能，并具有良好的泛化能力，能够生成高质量的样本。", "keywords": "生成模型, Transformer, 时间序列, 数据增强", "comments": "该研究通过改进Transformer模型，解决了安全领域数据稀缺的实际问题，其创新点在于提升了生成数据对下游ML模型性能的贡献，而非仅仅扩大数据量。实现SOTA结果和良好的泛化能力是其重要贡献。"}}
{"id": "2506.06522", "title": "Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance", "authors": ["Aladin Djuhera", "Swanand Ravindra Kadhe", "Syed Zawad", "Farhan Ahmed", "Heiko Ludwig", "Holger Boche"], "summary": "Recent work on large language models (LLMs) has increasingly focused on\npost-training and alignment with datasets curated to enhance instruction\nfollowing, world knowledge, and specialized skills. However, most post-training\ndatasets used in leading open- and closed-source LLMs remain inaccessible to\nthe public, with limited information about their construction process. This\nlack of transparency has motivated the recent development of open-source\npost-training corpora. While training on these open alternatives can yield\nperformance comparable to that of leading models, systematic comparisons remain\nchallenging due to the significant computational cost of conducting them\nrigorously at scale, and are therefore largely absent. As a result, it remains\nunclear how specific samples, task types, or curation strategies influence\ndownstream performance when assessing data quality. In this work, we conduct\nthe first comprehensive side-by-side analysis of two prominent open\npost-training datasets: Tulu-3-SFT-Mix and SmolTalk. Using the Magpie\nframework, we annotate each sample with detailed quality metrics, including\nturn structure (single-turn vs. multi-turn), task category, input quality, and\nresponse quality, and we derive statistics that reveal structural and\nqualitative similarities and differences between the two datasets. Based on\nthese insights, we design a principled curation recipe that produces a new data\nmixture, TuluTalk, which contains 14% fewer samples than either source dataset\nwhile matching or exceeding their performance on key benchmarks. Our findings\noffer actionable insights for constructing more effective post-training\ndatasets that improve model performance within practical resource limits. To\nsupport future research, we publicly release both the annotated source datasets\nand our curated TuluTalk mixture.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06522v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07600", "title": "SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding", "authors": ["Nianbo Zeng", "Haowen Hou", "Fei Richard Yu", "Si Shi", "Ying Tiffany He"], "summary": "Despite recent advances in retrieval-augmented generation (RAG) for video\nunderstanding, effectively understanding long-form video content remains\nunderexplored due to the vast scale and high complexity of video data. Current\nRAG approaches typically segment videos into fixed-length chunks, which often\ndisrupts the continuity of contextual information and fails to capture\nauthentic scene boundaries. Inspired by the human ability to naturally organize\ncontinuous experiences into coherent scenes, we present SceneRAG, a unified\nframework that leverages large language models to segment videos into\nnarrative-consistent scenes by processing ASR transcripts alongside temporal\nmetadata. SceneRAG further sharpens these initial boundaries through\nlightweight heuristics and iterative correction. For each scene, the framework\nfuses information from both visual and textual modalities to extract entity\nrelations and dynamically builds a knowledge graph, enabling robust multi-hop\nretrieval and generation that account for long-range dependencies. Experiments\non the LongerVideos benchmark, featuring over 134 hours of diverse content,\nconfirm that SceneRAG substantially outperforms prior baselines, achieving a\nwin rate of up to 72.5 percent on generation tasks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07600v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07324", "title": "DEF: Diffusion-augmented Ensemble Forecasting", "authors": ["David Millard", "Arielle Carr", "Stéphane Gaudreault", "Ali Baheri"], "summary": "We present DEF (\\textbf{\\ul{D}}iffusion-augmented \\textbf{\\ul{E}}nsemble\n\\textbf{\\ul{F}}orecasting), a novel approach for generating initial condition\nperturbations. Modern approaches to initial condition perturbations are\nprimarily designed for numerical weather prediction (NWP) solvers, limiting\ntheir applicability in the rapidly growing field of machine learning for\nweather prediction. Consequently, stochastic models in this domain are often\ndeveloped on a case-by-case basis. We demonstrate that a simple conditional\ndiffusion model can (1) generate meaningful structured perturbations, (2) be\napplied iteratively, and (3) utilize a guidance term to intuitivey control the\nlevel of perturbation. This method enables the transformation of any\ndeterministic neural forecasting system into a stochastic one. With our\nstochastic extended systems, we show that the model accumulates less error over\nlong-term forecasts while producing meaningful forecast distributions. We\nvalidate our approach on the 5.625$^\\circ$ ERA5 reanalysis dataset, which\ncomprises atmospheric and surface variables over a discretized global grid,\nspanning from the 1960s to the present. On this dataset, our method\ndemonstrates improved predictive performance along with reasonable spread\nestimates.", "comment": "26 pages, 20 plots, journal paper", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07324v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07603", "title": "SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis", "authors": ["Jianhui Wei", "Zikai Xiao", "Danyu Sun", "Luqi Gong", "Zongxin Yang", "Zuozhu Liu", "Jian Wu"], "summary": "Surgical video understanding is pivotal for enabling automated intraoperative\ndecision-making, skill assessment, and postoperative quality improvement.\nHowever, progress in developing surgical video foundation models (FMs) remains\nhindered by the scarcity of large-scale, diverse datasets for pretraining and\nsystematic evaluation. In this paper, we introduce \\textbf{SurgBench}, a\nunified surgical video benchmarking framework comprising a pretraining dataset,\n\\textbf{SurgBench-P}, and an evaluation benchmark, \\textbf{SurgBench-E}.\nSurgBench offers extensive coverage of diverse surgical scenarios, with\nSurgBench-P encompassing 53 million frames across 22 surgical procedures and 11\nspecialties, and SurgBench-E providing robust evaluation across six categories\n(phase classification, camera motion, tool recognition, disease diagnosis,\naction classification, and organ detection) spanning 72 fine-grained tasks.\nExtensive experiments reveal that existing video FMs struggle to generalize\nacross varied surgical video analysis tasks, whereas pretraining on SurgBench-P\nyields substantial performance improvements and superior cross-domain\ngeneralization to unseen procedures and modalities. Our dataset and code are\navailable upon request.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07603v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06382", "title": "On the Fundamental Impossibility of Hallucination Control in Large Language Models", "authors": ["Michał P. Karpowicz"], "summary": "This paper explains \\textbf{why it is impossible to create large language\nmodels that do not hallucinate and what are the trade-offs we should be looking\nfor}. It presents a formal \\textbf{impossibility theorem} demonstrating that no\ninference mechanism can simultaneously satisfy four fundamental properties:\n\\textbf{truthful (non-hallucinatory) generation, semantic information\nconservation, relevant knowledge revelation, and knowledge-constrained\noptimality}. By modeling LLM inference as an \\textbf{auction of ideas} where\nneural components compete to contribute to responses, we prove the\nimpossibility using the Green-Laffont theorem. That mathematical framework\nprovides a rigorous foundation for understanding the nature of inference\nprocess, with implications for model architecture, training objectives, and\nevaluation methods.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.06382v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07328", "title": "Mobility-Aware Asynchronous Federated Learning with Dynamic Sparsification", "authors": ["Jintao Yan", "Tan Chen", "Yuxuan Sun", "Zhaojun Nan", "Sheng Zhou", "Zhisheng Niu"], "summary": "Asynchronous Federated Learning (AFL) enables distributed model training\nacross multiple mobile devices, allowing each device to independently update\nits local model without waiting for others. However, device mobility introduces\nintermittent connectivity, which necessitates gradient sparsification and leads\nto model staleness, jointly affecting AFL convergence. This paper develops a\ntheoretical model to characterize the interplay among sparsification, model\nstaleness and mobility-induced contact patterns, and their joint impact on AFL\nconvergence. Based on the analysis, we propose a mobility-aware dynamic\nsparsification (MADS) algorithm that optimizes the sparsification degree based\non contact time and model staleness. Closed-form solutions are derived, showing\nthat under low-speed conditions, MADS increases the sparsification degree to\nenhance convergence, while under high-speed conditions, it reduces the\nsparsification degree to guarantee reliable uploads within limited contact\ntime. Experimental results validate the theoretical findings. Compared with the\nstate-of-the-art benchmarks, the MADS algorithm increases the image\nclassification accuracy on the CIFAR-10 dataset by 8.76% and reduces the\naverage displacement error in the Argoverse trajectory prediction dataset by\n9.46%.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07328v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07611", "title": "DragNeXt: Rethinking Drag-Based Image Editing", "authors": ["Yuan Zhou", "Junbao Zhou", "Qingshan Xu", "Kesen Zhao", "Yuxuan Wang", "Hao Fei", "Richang Hong", "Hanwang Zhang"], "summary": "Drag-Based Image Editing (DBIE), which allows users to manipulate images by\ndirectly dragging objects within them, has recently attracted much attention\nfrom the community. However, it faces two key challenges:\n(\\emph{\\textcolor{magenta}{i}}) point-based drag is often highly ambiguous and\ndifficult to align with users' intentions; (\\emph{\\textcolor{magenta}{ii}})\ncurrent DBIE methods primarily rely on alternating between motion supervision\nand point tracking, which is not only cumbersome but also fails to produce\nhigh-quality results. These limitations motivate us to explore DBIE from a new\nperspective -- redefining it as deformation, rotation, and translation of\nuser-specified handle regions. Thereby, by requiring users to explicitly\nspecify both drag areas and types, we can effectively address the ambiguity\nissue. Furthermore, we propose a simple-yet-effective editing framework, dubbed\n\\textcolor{SkyBlue}{\\textbf{DragNeXt}}. It unifies DBIE as a Latent Region\nOptimization (LRO) problem and solves it through Progressive Backward\nSelf-Intervention (PBSI), simplifying the overall procedure of DBIE while\nfurther enhancing quality by fully leveraging region-level structure\ninformation and progressive guidance from intermediate drag states. We validate\n\\textcolor{SkyBlue}{\\textbf{DragNeXt}} on our NextBench, and extensive\nexperiments demonstrate that our proposed method can significantly outperform\nexisting approaches. Code will be released on github.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07611v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07612", "title": "Scaling Human Activity Recognition: A Comparative Evaluation of Synthetic Data Generation and Augmentation Techniques", "authors": ["Zikang Leng", "Archith Iyer", "Thomas Plötz"], "summary": "Human activity recognition (HAR) is often limited by the scarcity of labeled\ndatasets due to the high cost and complexity of real-world data collection. To\nmitigate this, recent work has explored generating virtual inertial measurement\nunit (IMU) data via cross-modality transfer. While video-based and\nlanguage-based pipelines have each shown promise, they differ in assumptions\nand computational cost. Moreover, their effectiveness relative to traditional\nsensor-level data augmentation remains unclear. In this paper, we present a\ndirect comparison between these two virtual IMU generation approaches against\nclassical data augmentation techniques. We construct a large-scale virtual IMU\ndataset spanning 100 diverse activities from Kinetics-400 and simulate sensor\nsignals at 22 body locations. The three data generation strategies are\nevaluated on benchmark HAR datasets (UTD-MHAD, PAMAP2, HAD-AW) using four\npopular models. Results show that virtual IMU data significantly improves\nperformance over real or augmented data alone, particularly under limited-data\nconditions. We offer practical guidance on choosing data generation strategies\nand highlight the distinct advantages and disadvantages of each approach.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07612v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07334", "title": "Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models", "authors": ["Haoyu Wang", "Peihao Wang", "Mufei Li", "Shikun Liu", "Siqi Miao", "Zhangyang Wang", "Pan Li"], "summary": "Modern large language models (LLMs) are inherently auto-regressive, requiring\ninput to be serialized into flat sequences regardless of their structural\ndependencies. This serialization hinders the model's ability to leverage\nstructural inductive biases, especially in tasks such as retrieval-augmented\ngeneration (RAG) and reasoning on data with native graph structures, where\ninter-segment dependencies are crucial. We introduce Graph-KV with the\npotential to overcome this limitation. Graph-KV leverages the KV-cache of text\nsegments as condensed representations and governs their interaction through\nstructural inductive biases. In this framework, 'target' segments selectively\nattend only to the KV-caches of their designated 'source' segments, rather than\nall preceding segments in a serialized sequence. This approach induces a\ngraph-structured block mask, sparsifying attention and enabling a\nmessage-passing-like step within the LLM. Furthermore, strategically allocated\npositional encodings for source and target segments reduce positional bias and\ncontext window consumption. We evaluate Graph-KV across three scenarios: (1)\nseven RAG benchmarks spanning direct inference, multi-hop reasoning, and\nlong-document understanding; (2) Arxiv-QA, a novel academic paper QA task with\nfull-text scientific papers structured as citation ego-graphs; and (3) paper\ntopic classification within a citation network. By effectively reducing\npositional bias and harnessing structural inductive biases, Graph-KV\nsubstantially outperforms baselines, including standard costly sequential\nencoding, across various settings. Code and the Graph-KV data are publicly\navailable.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07334v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07627", "title": "Event-Priori-Based Vision-Language Model for Efficient Visual Understanding", "authors": ["Haotong Qin", "Cheng Hu", "Michele Magno"], "summary": "Large Language Model (LLM)-based Vision-Language Models (VLMs) have\nsubstantially extended the boundaries of visual understanding capabilities.\nHowever, their high computational demands hinder deployment on\nresource-constrained edge devices. A key source of inefficiency stems from the\nVLM's need to process dense and redundant visual information. Visual inputs\ncontain significant regions irrelevant to text semantics, rendering the\nassociated computations ineffective for inference. This paper introduces a\nnovel Event-Priori-Based Vision-Language Model, termed EP-VLM. Its core\ncontribution is a novel mechanism leveraging motion priors derived from dynamic\nevent vision to enhance VLM efficiency. Inspired by human visual cognition,\nEP-VLM first employs event data to guide the patch-wise sparsification of RGB\nvisual inputs, progressively concentrating VLM computation on salient regions\nof the visual input. Subsequently, we construct a position-preserving\ntokenization strategy for the visual encoder within the VLM architecture. This\nstrategy processes the event-guided, unstructured, sparse visual input while\naccurately preserving positional understanding within the visual input.\nExperimental results demonstrate that EP-VLM achieves significant efficiency\nimprovements while maintaining nearly lossless accuracy compared to baseline\nmodels from the Qwen2-VL series. For instance, against the original\nQwen2-VL-2B, EP-VLM achieves 50% FLOPs savings while retaining 98% of the\noriginal accuracy on the RealWorldQA dataset. This work demonstrates the\npotential of event-based vision priors for improving VLM inference efficiency,\npaving the way for creating more efficient and deployable VLMs for sustainable\nvisual understanding at the edge.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07627v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06533", "title": "Efficient implementation of high-order isospectral symplectic Runge-Kutta schemes", "authors": ["Clauson Carvalho da Silva", "Christian Lessig", "Carlos Tomei"], "summary": "Isospectral Runge-Kutta methods are well-suited for the numerical solution of\nisospectral systems such as the rigid body and the Toda lattice. More recently,\nthese integrators have been applied to geophysical fluid models, where their\nisospectral property has provided insights into the long-time behavior of such\nsystems. However, higher-order Isospectral Runge-Kutta methods require solving\na large number of implicit equations. This makes the implicit midpoint rule the\nmost commonly used due to its relative simplicity and computational efficiency.\nIn this work, we introduce a novel algorithm that simplifies the implementation\nof general isospectral Runge-Kutta integrators. Our approach leverages block\nmatrix structures to reduce the number of implicit equations per time step to a\nsingle one. This equation can be solved efficiently using fixed-point\niteration. We present numerical experiments comparing performance and accuracy\nof higher-order integrators implemented with our algorithm against the implicit\nmidpoint rule. Results show that, for low-dimensional systems, the higher-order\nintegrators yield improved conservation properties with comparable\ncomputational cost. For high-dimensional systems, while our algorithm continues\nto show better conservation properties, its performance is less competitive,\nthough it can be improved through parallelization.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06533v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07628", "title": "HuSc3D: Human Sculpture dataset for 3D object reconstruction", "authors": ["Weronika Smolak-Dyżewska", "Dawid Malarz", "Grzegorz Wilczyński", "Rafał Tobiasz", "Joanna Waczyńska", "Piotr Borycki", "Przemysław Spurek"], "summary": "3D scene reconstruction from 2D images is one of the most important tasks in\ncomputer graphics. Unfortunately, existing datasets and benchmarks concentrate\non idealized synthetic or meticulously captured realistic data. Such benchmarks\nfail to convey the inherent complexities encountered in newly acquired\nreal-world scenes. In such scenes especially those acquired outside, the\nbackground is often dynamic, and by popular usage of cell phone cameras, there\nmight be discrepancies in, e.g., white balance. To address this gap, we present\nHuSc3D, a novel dataset specifically designed for rigorous benchmarking of 3D\nreconstruction models under realistic acquisition challenges. Our dataset\nuniquely features six highly detailed, fully white sculptures characterized by\nintricate perforations and minimal textural and color variation. Furthermore,\nthe number of images per scene varies significantly, introducing the additional\nchallenge of limited training data for some instances alongside scenes with a\nstandard number of views. By evaluating popular 3D reconstruction methods on\nthis diverse dataset, we demonstrate the distinctiveness of HuSc3D in\neffectively differentiating model performance, particularly highlighting the\nsensitivity of methods to fine geometric details, color ambiguity, and varying\ndata availability--limitations often masked by more conventional datasets.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07628v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07637", "title": "HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition", "authors": ["Yuchong Long", "Wen Sun", "Ningxiao Sun", "Wenxiao Wang", "Chao Li", "Shan Yin"], "summary": "Automated pollen recognition is vital to paleoclimatology, biodiversity\nmonitoring, and public health, yet conventional methods are hampered by\ninefficiency and subjectivity. Existing deep learning models often struggle to\nachieve the requisite localization accuracy for microscopic targets like\npollen, which are characterized by their minute size, indistinct edges, and\ncomplex backgrounds. To overcome this limitation, we introduce HieraEdgeNet, a\nmulti-scale edge-enhancement framework. The framework's core innovation is the\nintroduction of three synergistic modules: the Hierarchical Edge Module (HEM),\nwhich explicitly extracts a multi-scale pyramid of edge features that\ncorresponds to the semantic hierarchy at early network stages; the Synergistic\nEdge Fusion (SEF) module, for deeply fusing these edge priors with semantic\ninformation at each respective scale; and the Cross Stage Partial Omni-Kernel\nModule (CSPOKM), which maximally refines the most detail-rich feature layers\nusing an Omni-Kernel operator - comprising anisotropic large-kernel\nconvolutions and mixed-domain attention - all within a computationally\nefficient Cross-Stage Partial (CSP) framework. On a large-scale dataset\ncomprising 120 pollen classes, HieraEdgeNet achieves a mean Average Precision\n(mAP@.5) of 0.9501, significantly outperforming state-of-the-art baseline\nmodels such as YOLOv12n and RT-DETR. Furthermore, qualitative analysis confirms\nthat our approach generates feature representations that are more precisely\nfocused on object boundaries. By systematically integrating edge information,\nHieraEdgeNet provides a robust and powerful solution for high-precision,\nhigh-efficiency automated detection of microscopic objects.", "comment": "16 pages, 5 figures, 2 tables. The dataset at\n  https://www.kaggle.com/datasets/ayinven/hieraedgenetintegratesdatasets. The\n  models at\n  https://huggingface.co/datasets/AyinMostima/HieraEdgeNetintegratesdatasets.\n  The source code in at https://github.com/AyinMostima/PalynoKit", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07637v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07378", "title": "Moment Alignment: Unifying Gradient and Hessian Matching for Domain Generalization", "authors": ["Yuen Chen", "Haozhe Si", "Guojun Zhang", "Han Zhao"], "summary": "Domain generalization (DG) seeks to develop models that generalize well to\nunseen target domains, addressing the prevalent issue of distribution shifts in\nreal-world applications. One line of research in DG focuses on aligning\ndomain-level gradients and Hessians to enhance generalization. However,\nexisting methods are computationally inefficient and the underlying principles\nof these approaches are not well understood. In this paper, we develop the\ntheory of moment alignment for DG. Grounded in \\textit{transfer measure}, a\nprincipled framework for quantifying generalizability between two domains, we\nfirst extend the definition of transfer measure to domain generalization that\nincludes multiple source domains and establish a target error bound. Then, we\nprove that aligning derivatives across domains improves transfer measure both\nwhen the feature extractor induces an invariant optimal predictor across\ndomains and when it does not. Notably, moment alignment provides a unifying\nunderstanding of Invariant Risk Minimization, gradient matching, and Hessian\nmatching, three previously disconnected approaches to DG. We further connect\nfeature moments and derivatives of the classifier head, and establish the\nduality between feature learning and classifier fitting. Building upon our\ntheory, we introduce \\textbf{C}losed-Form \\textbf{M}oment \\textbf{A}lignment\n(CMA), a novel DG algorithm that aligns domain-level gradients and Hessians in\nclosed-form. Our method overcomes the computational inefficiencies of existing\ngradient and Hessian-based techniques by eliminating the need for repeated\nbackpropagation or sampling-based Hessian estimation. We validate the efficacy\nof our approach through two sets of experiments: linear probing and full\nfine-tuning. CMA demonstrates superior performance in both settings compared to\nEmpirical Risk Minimization and state-of-the-art algorithms.", "comment": "UAI 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07378v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06536", "title": "Modern Minimal Perfect Hashing: A Survey", "authors": ["Hans-Peter Lehmann", "Thomas Mueller", "Rasmus Pagh", "Giulio Ermanno Pibiri", "Peter Sanders", "Sebastiano Vigna", "Stefan Walzer"], "summary": "Given a set $S$ of $n$ keys, a perfect hash function for $S$ maps the keys in\n$S$ to the first $m \\geq n$ integers without collisions. It may return an\narbitrary result for any key not in $S$ and is called minimal if $m = n$. The\nmost important parameters are its space consumption, construction time, and\nquery time. Years of research now enable modern perfect hash functions to be\nextremely fast to query, very space-efficient, and scale to billions of keys.\nDifferent approaches give different trade-offs between these aspects. For\nexample, the smallest constructions get within 0.1% of the space lower bound of\n$\\log_2(e)$ bits per key. Others are particularly fast to query, requiring only\none memory access. Perfect hashing has many applications, for example to avoid\ncollision resolution in static hash tables, and is used in databases,\nbioinformatics, and stringology.\n  Since the last comprehensive survey in 1997, significant progress has been\nmade. This survey covers the latest developments and provides a starting point\nfor getting familiar with the topic. Additionally, our extensive experimental\nevaluation can serve as a guide to select a perfect hash function for use in\napplications.", "comment": null, "cate": "cs.DS", "url": "http://arxiv.org/abs/2506.06536v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07643", "title": "Synthetic Visual Genome", "authors": ["Jae Sung Park", "Zixian Ma", "Linjie Li", "Chenhao Zheng", "Cheng-Yu Hsieh", "Ximing Lu", "Khyathi Chandu", "Quan Kong", "Norimasa Kobori", "Ali Farhadi", "Yejin Choi", "Ranjay Krishna"], "summary": "Reasoning over visual relationships-spatial, functional, interactional,\nsocial, etc.-is considered to be a fundamental component of human cognition.\nYet, despite the major advances in visual comprehension in multimodal language\nmodels (MLMs), precise reasoning over relationships and their generations\nremains a challenge. We introduce ROBIN: an MLM instruction-tuned with densely\nannotated relationships capable of constructing high-quality dense scene graphs\nat scale. To train ROBIN, we curate SVG, a synthetic scene graph dataset by\ncompleting the missing relations of selected objects in existing scene graphs\nusing a teacher MLM and a carefully designed filtering process to ensure\nhigh-quality. To generate more accurate and rich scene graphs at scale for any\nimage, we introduce SG-EDIT: a self-distillation framework where GPT-4o further\nrefines ROBIN's predicted scene graphs by removing unlikely relations and/or\nsuggesting relevant ones. In total, our dataset contains 146K images and 5.6M\nrelationships for 2.6M objects. Results show that our ROBIN-3B model, despite\nbeing trained on less than 3 million instances, outperforms similar-size models\ntrained on over 300 million instances on relationship understanding benchmarks,\nand even surpasses larger models up to 13B parameters. Notably, it achieves\nstate-of-the-art performance in referring expression comprehension with a score\nof 88.9, surpassing the previous best of 87.4. Our results suggest that\ntraining on the refined scene graph data is crucial to maintaining high\nperformance across diverse visual reasoning task.", "comment": "CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07643v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07405", "title": "RiemannFormer: A Framework for Attention in Curved Spaces", "authors": ["Zhongping Ji"], "summary": "This research endeavors to offer insights into unlocking the further\npotential of transformer-based architectures. One of the primary motivations is\nto offer a geometric interpretation for the attention mechanism in\ntransformers. In our framework, the attention mainly involves metric tensors,\ntangent spaces, inner product, and how they relate to each other. These\nquantities and structures at discrete positions are intricately interconnected\nvia the parallel transport of tangent vectors. To make the learning process\nmore efficient, we reduce the number of parameters through ingenious predefined\nconfigurations. Moreover, we introduce an explicit mechanism to highlight a\nneighborhood by attenuating the remote values, given that transformers\ninherently neglect local inductive bias. Experimental results demonstrate that\nour modules deliver significant performance improvements relative to the\nbaseline. More evaluation experiments on visual and large language models will\nbe launched successively.", "comment": "10 pages, 1 figure", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07405v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07652", "title": "FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images", "authors": ["Hangbei Cheng", "Xiaorong Dong", "Xueyu Liu", "Jianan Zhang", "Xuetao Ma", "Mingqiang Wei", "Liansheng Wang", "Junxin Chen", "Yongfei Wu"], "summary": "Accurate lesion segmentation in histopathology images is essential for\ndiagnostic interpretation and quantitative analysis, yet it remains challenging\ndue to the limited availability of costly pixel-level annotations. To address\nthis, we propose FMaMIL, a novel two-stage framework for weakly supervised\nlesion segmentation based solely on image-level labels. In the first stage, a\nlightweight Mamba-based encoder is introduced to capture long-range\ndependencies across image patches under the MIL paradigm. To enhance spatial\nsensitivity and structural awareness, we design a learnable frequency-domain\nencoding module that supplements spatial-domain features with spectrum-based\ninformation. CAMs generated in this stage are used to guide segmentation\ntraining. In the second stage, we refine the initial pseudo labels via a\nCAM-guided soft-label supervision and a self-correction mechanism, enabling\nrobust training even under label noise. Extensive experiments on both public\nand private histopathology datasets demonstrate that FMaMIL outperforms\nstate-of-the-art weakly supervised methods without relying on pixel-level\nannotations, validating its effectiveness and potential for digital pathology\napplications.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07652v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07406", "title": "InverseScope: Scalable Activation Inversion for Interpreting Large Language Models", "authors": ["Yifan Luo", "Zhennan Zhou", "Bin Dong"], "summary": "Understanding the internal representations of large language models (LLMs) is\na central challenge in interpretability research. Existing feature\ninterpretability methods often rely on strong assumptions about the structure\nof representations that may not hold in practice. In this work, we introduce\nInverseScope, an assumption-light and scalable framework for interpreting\nneural activations via input inversion. Given a target activation, we define a\ndistribution over inputs that generate similar activations and analyze this\ndistribution to infer the encoded features. To address the inefficiency of\nsampling in high-dimensional spaces, we propose a novel conditional generation\narchitecture that significantly improves sample efficiency compared to previous\nmethods. We further introduce a quantitative evaluation protocol that tests\ninterpretability hypotheses using feature consistency rate computed over the\nsampled inputs. InverseScope scales inversion-based interpretability methods to\nlarger models and practical tasks, enabling systematic and quantitative\nanalysis of internal representations in real-world LLMs.", "comment": "18 pages, 8 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07406v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06539", "title": "Beyond Facts: Evaluating Intent Hallucination in Large Language Models", "authors": ["Yijie Hao", "Haofei Yu", "Jiaxuan You"], "summary": "When exposed to complex queries containing multiple conditions, today's large\nlanguage models (LLMs) tend to produce responses that only partially satisfy\nthe query while neglecting certain conditions. We therefore introduce the\nconcept of Intent Hallucination. In this phenomenon, LLMs either omit\n(neglecting to address certain parts) or misinterpret (responding to invented\nquery parts) elements of the given query, leading to intent hallucinated\ngeneration. To systematically evaluate intent hallucination, we introduce\nFAITHQA, a novel benchmark for intent hallucination that contains 20,068\nproblems, covering both query-only and retrieval-augmented generation (RAG)\nsetups with varying topics and difficulty. FAITHQA is the first hallucination\nbenchmark that goes beyond factual verification, tailored to identify the\nfundamental cause of intent hallucination. By evaluating various LLMs on\nFAITHQA, we find that (1) intent hallucination is a common issue even for\nstate-of-the-art models, and (2) the phenomenon stems from omission or\nmisinterpretation of LLMs. To facilitate future research, we introduce an\nautomatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting\nintent hallucination. Human evaluation results demonstrate that CONSTRAINT\nSCORE is closer to human performance for intent hallucination compared to\nbaselines.", "comment": "Accepted to ACL 2025 main conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06539v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07670", "title": "ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views", "authors": ["Xiaohan Lu", "Jiaye Fu", "Jiaqi Zhang", "Zetian Song", "Chuanmin Jia", "Siwei Ma"], "summary": "Feed-forward 3D Gaussian Splatting (3DGS) has recently demonstrated promising\nresults for novel view synthesis (NVS) from sparse input views, particularly\nunder narrow-baseline conditions. However, its performance significantly\ndegrades in wide-baseline scenarios due to limited texture details and\ngeometric inconsistencies across views. To address these challenges, in this\npaper, we propose ProSplat, a two-stage feed-forward framework designed for\nhigh-fidelity rendering under wide-baseline conditions. The first stage\ninvolves generating 3D Gaussian primitives via a 3DGS generator. In the second\nstage, rendered views from these primitives are enhanced through an improvement\nmodel. Specifically, this improvement model is based on a one-step diffusion\nmodel, further optimized by our proposed Maximum Overlap Reference view\nInjection (MORI) and Distance-Weighted Epipolar Attention (DWEA). MORI\nsupplements missing texture and color by strategically selecting a reference\nview with maximum viewpoint overlap, while DWEA enforces geometric consistency\nusing epipolar constraints. Additionally, we introduce a divide-and-conquer\ntraining strategy that aligns data distributions between the two stages through\njoint optimization. We evaluate ProSplat on the RealEstate10K and DL3DV-10K\ndatasets under wide-baseline settings. Experimental results demonstrate that\nProSplat achieves an average improvement of 1 dB in PSNR compared to recent\nSOTA methods.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07670v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07407", "title": "Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM", "authors": ["Yihong Jin", "Ze Yang", "Juntian Liu", "Xinhe Xu"], "summary": "With the rapid development of multi-cloud environments, it is increasingly\nimportant to ensure the security and reliability of intelligent monitoring\nsystems. In this paper, we propose an anomaly detection and early warning\nmechanism for intelligent monitoring system in multi-cloud environment based on\nLarge-Scale Language Model (LLM). On the basis of the existing monitoring\nframework, the proposed model innovatively introduces a multi-level feature\nextraction method, which combines the natural language processing ability of\nLLM with traditional machine learning methods to enhance the accuracy of\nanomaly detection and improve the real-time response efficiency. By introducing\nthe contextual understanding capabilities of LLMs, the model dynamically adapts\nto different cloud service providers and environments, so as to more\neffectively detect abnormal patterns and predict potential failures.\nExperimental results show that the proposed model is significantly better than\nthe traditional anomaly detection system in terms of detection accuracy and\nlatency, and significantly improves the resilience and active management\nability of cloud infrastructure.", "comment": "Proceedings of 2025 5th International Symposium on Computer\n  Technology and Information Science (ISCTIS 2025)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07407v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07697", "title": "OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting", "authors": ["Jens Piekenbrinck", "Christian Schmidt", "Alexander Hermans", "Narunas Vaskevicius", "Timm Linder", "Bastian Leibe"], "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful representation for\nneural scene reconstruction, offering high-quality novel view synthesis while\nmaintaining computational efficiency. In this paper, we extend the capabilities\nof 3DGS beyond pure scene representation by introducing an approach for\nopen-vocabulary 3D instance segmentation without requiring manual labeling,\ntermed OpenSplat3D. Our method leverages feature-splatting techniques to\nassociate semantic information with individual Gaussians, enabling fine-grained\nscene understanding. We incorporate Segment Anything Model instance masks with\na contrastive loss formulation as guidance for the instance features to achieve\naccurate instance-level segmentation. Furthermore, we utilize language\nembeddings of a vision-language model, allowing for flexible, text-driven\ninstance identification. This combination enables our system to identify and\nsegment arbitrary objects in 3D scenes based on natural language descriptions.\nWe show results on LERF-mask and LERF-OVS as well as the full ScanNet++\nvalidation set, demonstrating the effectiveness of our approach.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07697v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07408", "title": "Fractional-order Jacobian Matrix Differentiation and Its Application in Artificial Neural Networks", "authors": ["Xiaojun zhou", "Chunna Zhao", "Yaqun Huang", "Chengli Zhou", "Junjie Ye", "Kemeng Xiang"], "summary": "Fractional-order differentiation has many characteristics different from\ninteger-order differentiation. These characteristics can be applied to the\noptimization algorithms of artificial neural networks to obtain better results.\nHowever, due to insufficient theoretical research, at present, there is no\nfractional-order matrix differentiation method that is perfectly compatible\nwith automatic differentiation (Autograd) technology. Therefore, we propose a\nfractional-order matrix differentiation calculation method. This method is\nintroduced by the definition of the integer-order Jacobian matrix. We denote it\nas fractional-order Jacobian matrix differentiation (${{\\bf{J}}^\\alpha }$).\nThrough ${{\\bf{J}}^\\alpha }$, we can carry out the matrix-based\nfractional-order chain rule. Based on the Linear module and the\nfractional-order differentiation, we design the fractional-order Autograd\ntechnology to enable the use of fractional-order differentiation in hidden\nlayers, thereby enhancing the practicality of fractional-order differentiation\nin deep learning. In the experiment, according to the PyTorch framework, we\ndesign fractional-order Linear (FLinear) and replace nn.Linear in the\nmultilayer perceptron with FLinear. Through the qualitative analysis of the\ntraining set and validation set $Loss$, the quantitative analysis of the test\nset indicators, and the analysis of time consumption and GPU memory usage\nduring model training, we verify the superior performance of ${{\\bf{J}}^\\alpha\n}$ and prove that it is an excellent fractional-order gradient descent method\nin the field of deep learning.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07408v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07698", "title": "NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation", "authors": ["Yuxiao Yang", "Peihao Li", "Yuhong Zhang", "Junzhe Lu", "Xianglong He", "Minghan Qin", "Weitao Wang", "Haoqian Wang"], "summary": "3D AI-generated content (AIGC) has made it increasingly accessible for anyone\nto become a 3D content creator. While recent methods leverage Score\nDistillation Sampling to distill 3D objects from pretrained image diffusion\nmodels, they often suffer from inadequate 3D priors, leading to insufficient\nmulti-view consistency. In this work, we introduce NOVA3D, an innovative\nsingle-image-to-3D generation framework. Our key insight lies in leveraging\nstrong 3D priors from a pretrained video diffusion model and integrating\ngeometric information during multi-view video fine-tuning. To facilitate\ninformation exchange between color and geometric domains, we propose the\nGeometry-Temporal Alignment (GTA) attention mechanism, thereby improving\ngeneralization and multi-view consistency. Moreover, we introduce the\nde-conflict geometry fusion algorithm, which improves texture fidelity by\naddressing multi-view inaccuracies and resolving discrepancies in pose\nalignment. Extensive experiments validate the superiority of NOVA3D over\nexisting baselines.", "comment": "8 pages, 7 figures, accepted by ICME 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07698v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07413", "title": "Variational Supervised Contrastive Learning", "authors": ["Ziwen Wang", "Jiajun Fan", "Thao Nguyen", "Heng Ji", "Ge Liu"], "summary": "Contrastive learning has proven to be highly efficient and adaptable in\nshaping representation spaces across diverse modalities by pulling similar\nsamples together and pushing dissimilar ones apart. However, two key\nlimitations persist: (1) Without explicit regulation of the embedding\ndistribution, semantically related instances can inadvertently be pushed apart\nunless complementary signals guide pair selection, and (2) excessive reliance\non large in-batch negatives and tailored augmentations hinders generalization.\nTo address these limitations, we propose Variational Supervised Contrastive\nLearning (VarCon), which reformulates supervised contrastive learning as\nvariational inference over latent class variables and maximizes a\nposterior-weighted evidence lower bound (ELBO) that replaces exhaustive\npair-wise comparisons for efficient class-aware matching and grants\nfine-grained control over intra-class dispersion in the embedding space.\nTrained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,\nImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art\nperformance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy\non ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while\nconverging in just 200 epochs; (2) yields substantially clearer decision\nboundaries and semantic organization in the embedding space, as evidenced by\nKNN classification, hierarchical clustering results, and transfer-learning\nassessments; and (3) demonstrates superior performance in few-shot learning\nthan supervised baseline and superior robustness across various augmentation\nstrategies.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07413v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06544", "title": "Reasoning about External Calls", "authors": ["Sophia Drossopoulou", "Julian Mackay", "Susan Eisenbach", "James Noble"], "summary": "In today's complex software, internal trusted code is tightly intertwined\nwith external untrusted code. To reason about internal code, programmers must\nreason about the potential effects of calls to external code, even though that\ncode is not trusted and may not even be available. The effects of external\ncalls can be limited, if internal code is programmed defensively, limiting\npotential effects by limiting access to the capabilities necessary to cause\nthose effects.\n  This paper addresses the specification and verification of internal code that\nrelies on encapsulation and object capabilities to limit the effects of\nexternal calls. We propose new assertions for access to capabilities, new\nspecifications for limiting effects, and a Hoare logic to verify that a module\nsatisfies its specification, even while making external calls. We illustrate\nthe approach though a running example with mechanised proofs, and prove\nsoundness of the Hoare logic.", "comment": "86 pages, 25 main paper, and 58 pages of appendices, many diagrams\n  and figures", "cate": "cs.PL", "url": "http://arxiv.org/abs/2506.06544v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07705", "title": "Adaptive Blind Super-Resolution Network for Spatial-Specific and Spatial-Agnostic Degradations", "authors": ["Weilei Wen", "Chunle Guo", "Wenqi Ren", "Hongpeng Wang", "Xiuli Shao"], "summary": "Prior methodologies have disregarded the diversities among distinct\ndegradation types during image reconstruction, employing a uniform network\nmodel to handle multiple deteriorations. Nevertheless, we discover that\nprevalent degradation modalities, including sampling, blurring, and noise, can\nbe roughly categorized into two classes. We classify the first class as\nspatial-agnostic dominant degradations, less affected by regional changes in\nimage space, such as downsampling and noise degradation. The second class\ndegradation type is intimately associated with the spatial position of the\nimage, such as blurring, and we identify them as spatial-specific dominant\ndegradations. We introduce a dynamic filter network integrating global and\nlocal branches to address these two degradation types. This network can greatly\nalleviate the practical degradation problem. Specifically, the global dynamic\nfiltering layer can perceive the spatial-agnostic dominant degradation in\ndifferent images by applying weights generated by the attention mechanism to\nmultiple parallel standard convolution kernels, enhancing the network's\nrepresentation ability. Meanwhile, the local dynamic filtering layer converts\nfeature maps of the image into a spatially specific dynamic filtering operator,\nwhich performs spatially specific convolution operations on the image features\nto handle spatial-specific dominant degradations. By effectively integrating\nboth global and local dynamic filtering operators, our proposed method\noutperforms state-of-the-art blind super-resolution algorithms in both\nsynthetic and real image datasets.", "comment": "IEEE TRANSACTIONS ON IMAGE PROCESSING", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07705v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07416", "title": "LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments", "authors": ["Jin Huang", "Yuchao Jin", "Le An", "Josh Park"], "summary": "This paper introduces an efficient Vision-Language Model (VLM) pipeline\nspecifically optimized for deployment on embedded devices, such as those used\nin robotics and autonomous driving. The pipeline significantly reduces the\ncomputational overhead by jointly leveraging patch selection to filter\nirrelevant camera views, a token selection module to reduce input sequence\nlength for the LLM, and speculative decoding to accelerate token generation.\nEvaluation on the NVIDIA DRIVE Thor platform for automonous driving\napplication, our pipeline achieves $2.5\\times$ end-to-end latency reduction\nwithout compromising task accuracy. The speed-up further increases to\n$3.2\\times$ when applying FP8 post-training quantization. These results\ndemonstrate our pipeline as a viable solution for enabling real-time VLM\ndeployment in resource-constrained environments.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07416v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07713", "title": "Consistent Video Editing as Flow-Driven Image-to-Video Generation", "authors": ["Ge Wang", "Songlin Fan", "Hangxu Liu", "Quanjian Song", "Hewei Wang", "Jinfeng Xu"], "summary": "With the prosper of video diffusion models, down-stream applications like\nvideo editing have been significantly promoted without consuming much\ncomputational cost. One particular challenge in this task lies at the motion\ntransfer process from the source video to the edited one, where it requires the\nconsideration of the shape deformation in between, meanwhile maintaining the\ntemporal consistency in the generated video sequence. However, existing methods\nfail to model complicated motion patterns for video editing, and are\nfundamentally limited to object replacement, where tasks with non-rigid object\nmotions like multi-object and portrait editing are largely neglected. In this\npaper, we observe that optical flows offer a promising alternative in complex\nmotion modeling, and present FlowV2V to re-investigate video editing as a task\nof flow-driven Image-to-Video (I2V) generation. Specifically, FlowV2V\ndecomposes the entire pipeline into first-frame editing and conditional I2V\ngeneration, and simulates pseudo flow sequence that aligns with the deformed\nshape, thus ensuring the consistency during editing. Experimental results on\nDAVIS-EDIT with improvements of 13.67% and 50.66% on DOVER and warping error\nillustrate the superior temporal consistency and sample quality of FlowV2V\ncompared to existing state-of-the-art ones. Furthermore, we conduct\ncomprehensive ablation studies to analyze the internal functionalities of the\nfirst-frame paradigm and flow alignment in the proposed method.", "comment": "16 pages, 12 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07713v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07417", "title": "Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs", "authors": ["Nan Sun", "Xixun Lin", "Zhiheng Zhou", "Yanmin Shang", "Zhenlin Cheng", "Yanan Cao"], "summary": "Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims\nto identify whether incoming data deviates from the distribution of the\nin-distribution (ID) training set, has garnered considerable attention in\nsecurity-sensitive fields. Current OOD detection paradigms primarily focus on\nstatic graphs and confront two critical challenges: i) high bias and high\nvariance caused by single-point estimation, which makes the predictions\nsensitive to randomness in the data; ii) score homogenization resulting from\nthe lack of OOD training data, where the model only learns ID-specific\npatterns, resulting in overall low OOD scores and a narrow score gap between ID\nand OOD data. To tackle these issues, we first investigate OOD detection in\ndynamic graphs through the lens of Evidential Deep Learning (EDL).\nSpecifically, we propose EviSEC, an innovative and effective OOD detector via\nEvidential Spectrum-awarE Contrastive Learning. We design an evidential neural\nnetwork to redefine the output as the posterior Dirichlet distribution,\nexplaining the randomness of inputs through the uncertainty of distribution,\nwhich is overlooked by single-point estimation. Moreover, spectrum-aware\naugmentation module generates OOD approximations to identify patterns with high\nOOD scores, thereby widening the score gap between ID and OOD data and\nmitigating score homogenization. Extensive experiments on real-world datasets\ndemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.", "comment": "17 pages,5 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07417v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07720", "title": "ReverB-SNN: Reversing Bit of the Weight and Activation for Spiking Neural Networks", "authors": ["Yufei Guo", "Yuhan Zhang", "Zhou Jie", "Xiaode Liu", "Xin Tong", "Yuanpei Chen", "Weihang Peng", "Zhe Ma"], "summary": "The Spiking Neural Network (SNN), a biologically inspired neural network\ninfrastructure, has garnered significant attention recently. SNNs utilize\nbinary spike activations for efficient information transmission, replacing\nmultiplications with additions, thereby enhancing energy efficiency. However,\nbinary spike activation maps often fail to capture sufficient data information,\nresulting in reduced accuracy. To address this challenge, we advocate reversing\nthe bit of the weight and activation for SNNs, called \\textbf{ReverB-SNN},\ninspired by recent findings that highlight greater accuracy degradation from\nquantizing activations compared to weights. Specifically, our method employs\nreal-valued spike activations alongside binary weights in SNNs. This preserves\nthe event-driven and multiplication-free advantages of standard SNNs while\nenhancing the information capacity of activations. Additionally, we introduce a\ntrainable factor within binary weights to adaptively learn suitable weight\namplitudes during training, thereby increasing network capacity. To maintain\nefficiency akin to vanilla \\textbf{ReverB-SNN}, our trainable binary weight\nSNNs are converted back to standard form using a re-parameterization technique\nduring inference. Extensive experiments across various network architectures\nand datasets, both static and dynamic, demonstrate that our approach\nconsistently outperforms state-of-the-art methods.", "comment": "Accpeted by ICML2024", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07720v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07440", "title": "Federated In-Context Learning: Iterative Refinement for Improved Answer Quality", "authors": ["Ruhan Wang", "Zhiyong Wang", "Chengkai Huang", "Rui Wang", "Tong Yu", "Lina Yao", "John C. S. Lui", "Dongruo Zhou"], "summary": "For question-answering (QA) tasks, in-context learning (ICL) enables language\nmodels to generate responses without modifying their parameters by leveraging\nexamples provided in the input. However, the effectiveness of ICL heavily\ndepends on the availability of high-quality examples, which are often scarce\ndue to data privacy constraints, annotation costs, and distribution\ndisparities. A natural solution is to utilize examples stored on client\ndevices, but existing approaches either require transmitting model parameters -\nincurring significant communication overhead - or fail to fully exploit local\ndatasets, limiting their effectiveness. To address these challenges, we propose\nFederated In-Context Learning (Fed-ICL), a general framework that enhances ICL\nthrough an iterative, collaborative process. Fed-ICL progressively refines\nresponses by leveraging multi-round interactions between clients and a central\nserver, improving answer quality without the need to transmit model parameters.\nWe establish theoretical guarantees for the convergence of Fed-ICL and conduct\nextensive experiments on standard QA benchmarks, demonstrating that our\nproposed approach achieves strong performance while maintaining low\ncommunication costs.", "comment": "27 pages, 16 figures. Accepted to ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07440v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07725", "title": "ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models", "authors": ["Shadi Hamdan", "Chonghao Sima", "Zetong Yang", "Hongyang Li", "Fatma Güney"], "summary": "How can we benefit from large models without sacrificing inference speed, a\ncommon dilemma in self-driving systems? A prevalent solution is a dual-system\narchitecture, employing a small model for rapid, reactive decisions and a\nlarger model for slower but more informative analyses. Existing dual-system\ndesigns often implement parallel architectures where inference is either\ndirectly conducted using the large model at each current frame or retrieved\nfrom previously stored inference results. However, these works still struggle\nto enable large models for a timely response to every online frame. Our key\ninsight is to shift intensive computations of the current frame to previous\ntime steps and perform a batch inference of multiple time steps to make large\nmodels respond promptly to each time step. To achieve the shifting, we\nintroduce Efficiency through Thinking Ahead (ETA), an asynchronous system\ndesigned to: (1) propagate informative features from the past to the current\nframe using future predictions from the large model, (2) extract current frame\nfeatures using a small model for real-time responsiveness, and (3) integrate\nthese dual features via an action mask mechanism that emphasizes\naction-critical image regions. Evaluated on the Bench2Drive CARLA\nLeaderboard-v2 benchmark, ETA advances state-of-the-art performance by 8% with\na driving score of 69.53 while maintaining a near-real-time inference speed at\n50 ms.", "comment": "ICCV 2025 submission. For code, see\n  https://github.com/opendrivelab/ETA", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07725v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07448", "title": "Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs", "authors": ["T. Duy Nguyen-Hien", "Desi R. Ivanova", "Yee Whye Teh", "Wee Sun Lee"], "summary": "Although large language models (LLMs) are highly interactive and extendable,\ncurrent approaches to ensure reliability in deployments remain mostly limited\nto rejecting outputs with high uncertainty in order to avoid misinformation.\nThis conservative strategy reflects the current lack of tools to systematically\ndistinguish and respond to different sources of uncertainty. In this paper, we\nadvocate for the adoption of Bayesian Modeling of Experiments -- a framework\nthat provides a coherent foundation to reason about uncertainty and clarify the\nreducibility of uncertainty -- for managing and proactively addressing\nuncertainty that arises in LLM deployments. This framework enables LLMs and\ntheir users to take contextually appropriate steps, such as requesting\nclarification, retrieving external information, or refining inputs. By\nsupporting active resolution rather than passive avoidance, it opens the door\nto more reliable, transparent, and broadly applicable LLM systems, particularly\nin high-stakes, real-world settings.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07448v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06557", "title": "Infinity Search: Approximate Vector Search with Projections on q-Metric Spaces", "authors": ["Antonio Pariente", "Ignacio Hounie", "Santiago Segarra", "Alejandro Ribeiro"], "summary": "Despite the ubiquity of vector search applications, prevailing search\nalgorithms overlook the metric structure of vector embeddings, treating it as a\nconstraint rather than exploiting its underlying properties. In this paper, we\ndemonstrate that in $q$-metric spaces, metric trees can leverage a stronger\nversion of the triangle inequality to reduce comparisons for exact search.\nNotably, as $q$ approaches infinity, the search complexity becomes logarithmic.\nTherefore, we propose a novel projection method that embeds vector datasets\nwith arbitrary dissimilarity measures into $q$-metric spaces while preserving\nthe nearest neighbor. We propose to learn an approximation of this projection\nto efficiently transform query points to a space where euclidean distances\nsatisfy the desired properties. Our experimental results with text and image\nvector embeddings show that learning $q$-metric approximations enables classic\nmetric tree algorithms -- which typically underperform with high-dimensional\ndata -- to achieve competitive performance against state-of-the-art search\nmethods.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06557v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07737", "title": "SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding", "authors": ["Xuemei Chen", "Huamin Wang", "Hangchi Shen", "Shukai Duan", "Shiping Wen", "Tingwen Huang"], "summary": "Low energy consumption for 3D object detection is an important research area\nbecause of the increasing energy consumption with their wide application in\nfields such as autonomous driving. The spiking neural networks (SNNs) with\nlow-power consumption characteristics can provide a novel solution for this\nresearch. Therefore, we apply SNNs to monocular 3D object detection and propose\nthe SpikeSMOKE architecture in this paper, which is a new attempt for low-power\nmonocular 3D object detection. As we all know, discrete signals of SNNs will\ngenerate information loss and limit their feature expression ability compared\nwith the artificial neural networks (ANNs).In order to address this issue,\ninspired by the filtering mechanism of biological neuronal synapses, we propose\na cross-scale gated coding mechanism(CSGC), which can enhance feature\nrepresentation by combining cross-scale fusion of attentional methods and gated\nfiltering mechanisms.In addition, to reduce the computation and increase the\nspeed of training, we present a novel light-weight residual block that can\nmaintain spiking computing paradigm and the highest possible detection\nperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,\nthe proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,\nModerate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset by\nAP|R11 at 0.7 IoU threshold, respectively. It is important to note that the\nresults of SpikeSMOKE can significantly reduce energy consumption compared to\nthe results on SMOKE. For example,the energy consumption can be reduced by\n72.2% on the hard category, while the detection performance is reduced by only\n4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3\ntimes and computation by 10 times compared to SMOKE.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07737v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07738", "title": "AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization", "authors": ["Lanjiong Li", "Guanhua Zhao", "Lingting Zhu", "Zeyu Cai", "Lequan Yu", "Jian Zhang", "Zeyu Wang"], "summary": "Recent research on generative models has primarily focused on creating\nproduct-ready visual outputs; however, designers often favor access to\nstandardized asset libraries, a domain that has yet to be significantly\nenhanced by generative capabilities. Although open-world scenes provide ample\nraw materials for designers, efficiently extracting high-quality, standardized\nassets remains a challenge. To address this, we introduce AssetDropper, the\nfirst framework designed to extract assets from reference images, providing\nartists with an open-world asset palette. Our model adeptly extracts a front\nview of selected subjects from input images, effectively handling complex\nscenarios such as perspective distortion and subject occlusion. We establish a\nsynthetic dataset of more than 200,000 image-subject pairs and a real-world\nbenchmark with thousands more for evaluation, facilitating the exploration of\nfuture research in downstream tasks. Furthermore, to ensure precise asset\nextraction that aligns well with the image prompts, we employ a pre-trained\nreward model to fulfill a closed-loop with feedback. We design the reward model\nto perform an inverse task that pastes the extracted assets back into the\nreference sources, which assists training with additional consistency and\nmitigates hallucination. Extensive experiments show that, with the aid of\nreward-driven optimization, AssetDropper achieves the state-of-the-art results\nin asset extraction. Project page: AssetDropper.github.io.", "comment": "SIGGRAPH 2025. 11 pages, 12 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07738v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07459", "title": "ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning", "authors": ["Ziwen Wang", "Jiajun Fan", "Ruihan Guo", "Thao Nguyen", "Heng Ji", "Ge Liu"], "summary": "Protein generative models have shown remarkable promise in protein design but\nstill face limitations in success rate, due to the scarcity of high-quality\nprotein datasets for supervised pretraining. We present ProteinZero, a novel\nframework that enables scalable, automated, and continuous self-improvement of\nthe inverse folding model through online reinforcement learning. To achieve\ncomputationally tractable online feedback, we introduce efficient proxy reward\nmodels based on ESM-fold and a novel rapid ddG predictor that significantly\naccelerates evaluation speed. ProteinZero employs a general RL framework\nbalancing multi-reward maximization, KL-divergence from a reference model, and\na novel protein-embedding level diversity regularization that prevents mode\ncollapse while promoting higher sequence diversity. Through extensive\nexperiments, we demonstrate that ProteinZero substantially outperforms existing\nmethods across every key metric in protein design, achieving significant\nimprovements in structural accuracy, designability, thermodynamic stability,\nand sequence diversity. Most impressively, ProteinZero reduces design failure\nrates by approximately 36% - 48% compared to widely-used methods like\nProteinMPNN, ESM-IF and InstructPLM, consistently achieving success rates\nexceeding 90% across diverse and complex protein folds. Notably, the entire RL\nrun on CATH-4.3 can be done with a single 8 X GPU node in under 3 days,\nincluding reward computation. Our work establishes a new paradigm for protein\ndesign where models evolve continuously from their own generated outputs,\nopening new possibilities for exploring the vast protein design space.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07459v1", "AI": {"title_translation": "ProteinZero：通过在线强化学习实现蛋白质生成的自我改进", "tldr": "ProteinZero是一个利用在线强化学习的蛋白质设计框架，通过引入高效的代理奖励模型和多样性正则化，显著提高了蛋白质生成模型的成功率、结构准确性、可设计性、热力学稳定性和序列多样性，并将设计失败率降低了36%-48%。", "motivation": "蛋白质生成模型在蛋白质设计方面表现出巨大潜力，但由于高质量蛋白质数据集的稀缺性，导致监督预训练不足，从而限制了其成功率。", "method": "ProteinZero是一个新颖的框架，通过在线强化学习实现逆折叠模型的规模化、自动化和持续自我改进。它引入了基于ESM-fold和新型快速ddG预测器的有效代理奖励模型，以加速评估。该框架采用通用的强化学习方法，平衡多奖励最大化、与参考模型的KL散度以及蛋白质嵌入层面的多样性正则化，以防止模式崩溃并促进更高的序列多样性。", "result": "ProteinZero在蛋白质设计的各个关键指标上显著优于现有方法，在结构准确性、可设计性、热力学稳定性、序列多样性方面取得了显著改进。它将设计失败率比ProteinMPNN、ESM-IF和InstructPLM等广泛使用的方法降低了约36%-48%，在不同复杂蛋白质折叠中始终实现超过90%的成功率。此外，整个强化学习过程在单个8 X GPU节点上可在3天内完成，包括奖励计算。", "conclusion": "ProteinZero为蛋白质设计建立了一个新范式，模型可以从自身生成的输出中持续进化，为探索广阔的蛋白质设计空间开辟了新的可能性。", "translation": "蛋白质生成模型在蛋白质设计方面展现出卓越的潜力，但由于高质量蛋白质数据集的稀缺性，导致监督预训练不足，其成功率仍然面临限制。我们提出了ProteinZero，这是一个新颖的框架，通过在线强化学习实现逆折叠模型的规模化、自动化和持续自我改进。为了实现计算上可行的在线反馈，我们引入了基于ESM-fold和新型快速ddG预测器的高效代理奖励模型，显著加速了评估速度。ProteinZero采用通用的强化学习框架，平衡多奖励最大化、与参考模型的KL散度以及新颖的蛋白质嵌入层面的多样性正则化，以防止模式崩溃同时促进更高的序列多样性。通过广泛的实验，我们证明ProteinZero在蛋白质设计的每个关键指标上都显著优于现有方法，在结构准确性、可设计性、热力学稳定性以及序列多样性方面取得了显著改进。最令人印象深刻的是，与ProteinMPNN、ESM-IF和InstructPLM等广泛使用的方法相比，ProteinZero将设计失败率降低了约36% - 48%，在多样化和复杂的蛋白质折叠中始终实现超过90%的成功率。值得注意的是，CATH-4.3上的整个强化学习运行，包括奖励计算，可以在不到3天的时间内使用单个8 X GPU节点完成。我们的工作为蛋白质设计建立了一个新范式，模型可以从自身生成的输出中持续进化，为探索广阔的蛋白质设计空间开辟了新的可能性。", "summary": "ProteinZero是一个利用在线强化学习实现蛋白质生成模型自我改进的新框架。它通过引入高效的代理奖励模型和新颖的蛋白质嵌入多样性正则化，克服了高质量蛋白质数据稀缺的限制。实验证明，ProteinZero在结构准确性、可设计性、热力学稳定性、序列多样性等关键指标上显著优于现有方法，并将设计失败率降低了36%-48%，在复杂蛋白质折叠中实现了超过90%的成功率。该方法高效且可扩展，为蛋白质设计开辟了模型持续进化的新途径。", "keywords": "蛋白质生成, 强化学习, 逆折叠模型, 代理奖励, 序列多样性", "comments": "ProteinZero的创新之处在于将在线强化学习引入蛋白质设计，通过自我改进机制克服了传统监督学习对高质量数据集的依赖。其引入的代理奖励模型和多样性正则化是关键的技术贡献，不仅提高了性能，还保证了效率和多样性。这项工作为蛋白质设计领域开辟了一个全新的研究范式，具有重要的科学意义和潜在应用价值。"}}
{"id": "2506.07739", "title": "ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models", "authors": ["Jing Zhong", "Jun Yin", "Peilin Li", "Pengyu Zeng", "Miao Zhang", "Shuai Lu", "Ran Luo"], "summary": "Architectural cultures across regions are characterized by stylistic\ndiversity, shaped by historical, social, and technological contexts in addition\nto geograph-ical conditions. Understanding architectural styles requires the\nability to describe and analyze the stylistic features of different architects\nfrom various regions through visual observations of architectural imagery.\nHowever, traditional studies of architectural culture have largely relied on\nsubjective expert interpretations and historical literature reviews, often\nsuffering from regional biases and limited ex-planatory scope. To address these\nchallenges, this study proposes three core contributions: (1) We construct a\nprofessional architectural style dataset named ArchDiffBench, which comprises\n1,765 high-quality architectural images and their corresponding style\nannotations, collected from different regions and historical periods. (2) We\npropose ArchiLense, an analytical framework grounded in Vision-Language Models\nand constructed using the ArchDiffBench dataset. By integrating ad-vanced\ncomputer vision techniques, deep learning, and machine learning algo-rithms,\nArchiLense enables automatic recognition, comparison, and precise\nclassi-fication of architectural imagery, producing descriptive language\noutputs that ar-ticulate stylistic differences. (3) Extensive evaluations show\nthat ArchiLense achieves strong performance in architectural style recognition,\nwith a 92.4% con-sistency rate with expert annotations and 84.5% classification\naccuracy, effec-tively capturing stylistic distinctions across images. The\nproposed approach transcends the subjectivity inherent in traditional analyses\nand offers a more objective and accurate perspective for comparative studies of\narchitectural culture.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07739v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07467", "title": "Circumventing Backdoor Space via Weight Symmetry", "authors": ["Jie Peng", "Hongwei Yang", "Jing Zhao", "Hengji Dong", "Hui He", "Weizhe Zhang", "Haoyu He"], "summary": "Deep neural networks are vulnerable to backdoor attacks, where malicious\nbehaviors are implanted during training. While existing defenses can\neffectively purify compromised models, they typically require labeled data or\nspecific training procedures, making them difficult to apply beyond supervised\nlearning settings. Notably, recent studies have shown successful backdoor\nattacks across various learning paradigms, highlighting a critical security\nconcern. To address this gap, we propose Two-stage Symmetry Connectivity (TSC),\na novel backdoor purification defense that operates independently of data\nformat and requires only a small fraction of clean samples. Through theoretical\nanalysis, we prove that by leveraging permutation invariance in neural networks\nand quadratic mode connectivity, TSC amplifies the loss on poisoned samples\nwhile maintaining bounded clean accuracy. Experiments demonstrate that TSC\nachieves robust performance comparable to state-of-the-art methods in\nsupervised learning scenarios. Furthermore, TSC generalizes to self-supervised\nlearning frameworks, such as SimCLR and CLIP, maintaining its strong defense\ncapabilities. Our code is available at https://github.com/JiePeng104/TSC.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07467v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06561", "title": "LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles", "authors": ["Ho Yin 'Sam' Ng", "Ting-Yao Hsu", "Aashish Anantha Ramakrishnan", "Branislav Kveton", "Nedim Lipka", "Franck Dernoncourt", "Dongwon Lee", "Tong Yu", "Sungchul Kim", "Ryan A. Rossi", "Ting-Hao 'Kenneth' Huang"], "summary": "Figure captions are crucial for helping readers understand and remember a\nfigure's key message. Many models have been developed to generate these\ncaptions, helping authors compose better quality captions more easily. Yet,\nauthors almost always need to revise generic AI-generated captions to match\ntheir writing style and the domain's style, highlighting the need for\npersonalization. Despite language models' personalization (LaMP) advances,\nthese technologies often focus on text-only settings and rarely address\nscenarios where both inputs and profiles are multimodal. This paper introduces\nLaMP-Cap, a dataset for personalized figure caption generation with multimodal\nfigure profiles. For each target figure, LaMP-Cap provides not only the needed\ninputs, such as figure images, but also up to three other figures from the same\ndocument--each with its image, caption, and figure-mentioning paragraphs--as a\nprofile to characterize the context. Experiments with four LLMs show that using\nprofile information consistently helps generate captions closer to the original\nauthor-written ones. Ablation studies reveal that images in the profile are\nmore helpful than figure-mentioning paragraphs, highlighting the advantage of\nusing multimodal profiles over text-only ones.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06561v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07740", "title": "Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images", "authors": ["Yingping Liang", "Ying Fu", "Yutao Hu", "Wenqi Shao", "Jiaming Liu", "Debing Zhang"], "summary": "Optical flow estimation is a crucial subfield of computer vision, serving as\na foundation for video tasks. However, the real-world robustness is limited by\nanimated synthetic datasets for training. This introduces domain gaps when\napplied to real-world applications and limits the benefits of scaling up\ndatasets. To address these challenges, we propose \\textbf{Flow-Anything}, a\nlarge-scale data generation framework designed to learn optical flow estimation\nfrom any single-view images in the real world. We employ two effective steps to\nmake data scaling-up promising. First, we convert a single-view image into a 3D\nrepresentation using advanced monocular depth estimation networks. This allows\nus to render optical flow and novel view images under a virtual camera. Second,\nwe develop an Object-Independent Volume Rendering module and a Depth-Aware\nInpainting module to model the dynamic objects in the 3D representation. These\ntwo steps allow us to generate realistic datasets for training from large-scale\nsingle-view images, namely \\textbf{FA-Flow Dataset}. For the first time, we\ndemonstrate the benefits of generating optical flow training data from\nlarge-scale real-world images, outperforming the most advanced unsupervised\nmethods and supervised methods on synthetic datasets. Moreover, our models\nserve as a foundation model and enhance the performance of various downstream\nvideo tasks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07740v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07750", "title": "Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation", "authors": ["Hyunsoo Kim", "Donghyun Kim", "Suhyun Kim"], "summary": "How can we generate an image B' that satisfies A:A'::B:B', given the input\nimages A,A' and B? Recent works have tackled this challenge through approaches\nlike visual in-context learning or visual instruction. However, these methods\nare typically limited to specific models (e.g. InstructPix2Pix. Inpainting\nmodels) rather than general diffusion models (e.g. Stable Diffusion, SDXL).\nThis dependency may lead to inherited biases or lower editing capabilities. In\nthis paper, we propose Difference Inversion, a method that isolates only the\ndifference from A and A' and applies it to B to generate a plausible B'. To\naddress model dependency, it is crucial to structure prompts in the form of a\n\"Full Prompt\" suitable for input to stable diffusion models, rather than using\nan \"Instruction Prompt\". To this end, we accurately extract the Difference\nbetween A and A' and combine it with the prompt of B, enabling a plug-and-play\napplication of the difference. To extract a precise difference, we first\nidentify it through 1) Delta Interpolation. Additionally, to ensure accurate\ntraining, we propose the 2) Token Consistency Loss and 3) Zero Initialization\nof Token Embeddings. Our extensive experiments demonstrate that Difference\nInversion outperforms existing baselines both quantitatively and qualitatively,\nindicating its ability to generate more feasible B' in a model-agnostic manner.", "comment": "Published at CVPR 2025", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07750v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07477", "title": "Premise Selection for a Lean Hammer", "authors": ["Thomas Zhu", "Joshua Clune", "Jeremy Avigad", "Albert Qiaochu Jiang", "Sean Welleck"], "summary": "Neural methods are transforming automated reasoning for proof assistants, yet\nintegrating these advances into practical verification workflows remains\nchallenging. Hammers are tools that interface with external automatic theorem\nprovers to automate tedious reasoning steps. They have dramatically improved\nproductivity in proof assistants, but the Lean proof assistant still does not\nhave a hammer despite its growing popularity. We present LeanHammer, the first\nend-to-end domain-general hammer for Lean, built on a novel neural premise\nselection system for a hammer in dependent type theory. Unlike existing Lean\npremise selectors, our approach dynamically adapts to user-specific contexts\nand combines with symbolic proof search and reconstruction to create a\npractical hammer. With comprehensive evaluations, we show that our premise\nselector enables LeanHammer to solve 21\\% more goals relative to existing\npremise selectors, and generalize well to diverse domains. Our work bridges the\ngap between neural retrieval and symbolic reasoning, making formal verification\nmore accessible to researchers and practitioners.", "comment": "LeanHammer is available at https://github.com/JOSHCLUNE/LeanHammer", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07477v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07773", "title": "Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity", "authors": ["Mohamed Djilani", "Nassim Ali Ousalah", "Nidhal Eddine Chenni"], "summary": "We introduce a trend-aware and visually-grounded fashion recommendation\nsystem that integrates deep visual representations, garment-aware segmentation,\nsemantic category similarity and user behavior simulation. Our pipeline\nextracts focused visual embeddings by masking non-garment regions via semantic\nsegmentation followed by feature extraction using pretrained CNN backbones\n(ResNet-50, DenseNet-121, VGG16). To simulate realistic shopping behavior, we\ngenerate synthetic purchase histories influenced by user-specific trendiness\nand item popularity. Recommendations are computed using a weighted scoring\nfunction that fuses visual similarity, semantic coherence and popularity\nalignment. Experiments on the DeepFashion dataset demonstrate consistent gender\nalignment and improved category relevance, with ResNet-50 achieving 64.95%\ncategory similarity and lowest popularity MAE. An ablation study confirms the\ncomplementary roles of visual and popularity cues. Our method provides a\nscalable framework for personalized fashion recommendations that balances\nindividual style with emerging trends. Our implementation is available at\nhttps://github.com/meddjilani/FashionRecommender", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07773v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07492", "title": "Explicit Preference Optimization: No Need for an Implicit Reward Model", "authors": ["Xiangkun Hu", "Lemin Kong", "Tong He", "David Wipf"], "summary": "The generated responses of large language models (LLMs) are often fine-tuned\nto human preferences through a process called reinforcement learning from human\nfeedback (RLHF). As RLHF relies on a challenging training sequence, whereby a\nseparate reward model is independently learned and then later applied to LLM\npolicy updates, ongoing research effort has targeted more straightforward\nalternatives. In this regard, direct preference optimization (DPO) and its many\noffshoots circumvent the need for a separate reward training step. Instead,\nthrough the judicious use of a reparameterization trick that induces an\n\\textit{implicit} reward, DPO and related methods consolidate learning to the\nminimization of a single loss function. And yet despite demonstrable success in\nsome real-world settings, we prove that DPO-based objectives are nonetheless\nsubject to sub-optimal regularization and counter-intuitive interpolation\nbehaviors, underappreciated artifacts of the reparameterizations upon which\nthey are based. To this end, we introduce an \\textit{explicit} preference\noptimization framework termed EXPO that requires no analogous\nreparameterization to achieve an implicit reward. Quite differently, we merely\nposit intuitively-appealing regularization factors from scratch that\ntransparently avoid the potential pitfalls of key DPO variants, provably\nsatisfying regularization desiderata that prior methods do not. Empirical\nresults serve to corroborate our analyses and showcase the efficacy of EXPO.", "comment": "arXiv admin note: substantial text overlap with arXiv:2407.09072", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07492v1", "AI": {"title_translation": "显式偏好优化：无需隐式奖励模型", "tldr": "本文提出了EXPO，一种显式偏好优化框架，旨在解决DPO等隐式奖励方法中存在的次优正则化和反直觉插值行为，并证明其在经验上是有效的。", "motivation": "大型语言模型（LLMs）的偏好微调中，RLHF训练序列复杂。DPO虽然简化了过程，但其依赖的隐式奖励重参数化会导致次优正则化和反直觉的插值行为，这些是现有方法需要解决的缺陷。", "method": "本文引入了EXPO（显式偏好优化）框架。与DPO不同，EXPO不需要通过重参数化来诱导隐式奖励。相反，它从头开始设定直观的正则化因子，以透明地避免关键DPO变体的潜在缺陷，并能证明满足了先前方法未能满足的正则化要求。", "result": "经验结果证实了本文的分析，并展示了EXPO框架的有效性。", "conclusion": "EXPO框架提供了一种无需隐式奖励模型的新型显式偏好优化方法，有效解决了DPO等现有方法中存在的次优正则化和反直觉插值问题，并满足了更强的正则化要求，从而为LLM的偏好对齐提供了一种更优、更透明的解决方案。", "translation": "大型语言模型（LLMs）生成的响应通常通过人类反馈强化学习（RLHF）过程进行微调以适应人类偏好。由于RLHF依赖于一个具有挑战性的训练序列，其中一个独立的奖励模型被独立学习然后应用于LLM策略更新，因此持续的研究工作旨在寻找更直接的替代方案。在这方面，直接偏好优化（DPO）及其许多分支规避了单独奖励训练步骤的需要。相反，通过巧妙地使用一种诱导“隐式”奖励的重参数化技巧，DPO及相关方法将学习整合到单个损失函数的最小化中。然而，尽管在某些实际场景中取得了显著成功，我们证明DPO目标仍然受到次优正则化和反直觉插值行为的影响，这些是其所基于的重参数化未被充分认识的缺陷。为此，我们引入了一个称为EXPO的“显式”偏好优化框架，它不需要类似的重参数化来实现隐式奖励。与此截然不同的是，我们只是从头开始设定了直观吸引人的正则化因子，透明地避免了关键DPO变体的潜在陷阱，并可证明满足了以前方法未能满足的正则化要求。经验结果证实了我们的分析并展示了EXPO的有效性。", "summary": "本文针对大型语言模型（LLMs）偏好微调中现有的RLHF和DPO方法的局限性，提出了一种名为EXPO的显式偏好优化框架。RLHF训练复杂，而DPO虽简化了流程，但其基于隐式奖励的重参数化会导致次优正则化和反直觉插值行为。EXPO通过直接设定直观的正则化因子，避免了重参数化带来的问题，并被证明能满足DPO无法满足的正则化需求。实验结果验证了EXPO的分析正确性及其有效性。", "keywords": "偏好优化, 大型语言模型, 奖励模型, EXPO, DPO", "comments": "这项工作通过提出EXPO框架，提供了一种更透明、更稳健的LLM偏好优化方法，解决了DPO等方法中隐式奖励重参数化带来的深层次问题。其创新点在于从“显式”角度出发，直接构建满足正则化要求的优化目标，而非依赖于复杂的重参数化技巧。这对于LLM的对齐训练具有重要意义。"}}
{"id": "2506.06564", "title": "Learning Neural Controllers with Optimality and Stability Guarantees Using Input-Output Dissipativity", "authors": ["Han Wang", "Keyan Miao", "Diego Madeira", "Antonis Papachristodoulou"], "summary": "Deep learning methods have demonstrated significant potential for addressing\ncomplex nonlinear control problems. For real-world safety-critical tasks,\nhowever, it is crucial to provide formal stability guarantees for the designed\ncontrollers. In this paper, we propose a new framework for designing neural\ncontrollers that achieve both stability and optimality with respect to certain\nfunctions. Our key idea is to exploit the concept of input-output dissipativity\nof nonlinear systems by learning neural storage functions and supply rate\nfunctions. As a generalization of Lyapunov theory, dissipativity theory\nprovides a natural connection to optimal control theory, offering both\nstability guarantees and meaningful optimality certificates. The neural\ncontrollers can be directly derived from the learned supply rate functions and\nguarantee closed-loop stability while inheriting optimality properties that can\nbe shaped towards user-defined control objectives. Extensive numerical\nexperiments demonstrate the effectiveness of our approach.", "comment": "submitted to Automatica", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06564v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07778", "title": "Language-Vision Planner and Executor for Text-to-Visual Reasoning", "authors": ["Yichang Xu", "Gaowen Liu", "Ramana Rao Kompella", "Sihao Hu", "Tiansheng Huang", "Fatih Ilhan", "Selim Furkan Tekin", "Zachary Yahn", "Ling Liu"], "summary": "The advancement in large language models (LLMs) and large vision models has\nfueled the rapid progress in multi-modal visual-text reasoning capabilities.\nHowever, existing vision-language models (VLMs) to date suffer from\ngeneralization performance. Inspired by recent development in LLMs for visual\nreasoning, this paper presents VLAgent, an AI system that can create a\nstep-by-step visual reasoning plan with an easy-to-understand script and\nexecute each step of the plan in real time by integrating planning script with\nexecution verifications via an automated process supported by VLAgent. In the\ntask planning phase, VLAgent fine-tunes an LLM through in-context learning to\ngenerate a step-by-step planner for each user-submitted text-visual reasoning\ntask. During the plan execution phase, VLAgent progressively refines the\ncomposition of neuro-symbolic executable modules to generate high-confidence\nreasoning results. VLAgent has three unique design characteristics: First, we\nimprove the quality of plan generation through in-context learning, improving\nlogic reasoning by reducing erroneous logic steps, incorrect programs, and LLM\nhallucinations. Second, we design a syntax-semantics parser to identify and\ncorrect additional logic errors of the LLM-generated planning script prior to\nlaunching the plan executor. Finally, we employ the ensemble method to improve\nthe generalization performance of our step-executor. Extensive experiments with\nfour visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent\nachieves significant performance enhancement for multimodal text-visual\nreasoning applications, compared to the exiting representative VLMs and LLM\nbased visual composition approaches like ViperGPT and VisProg, thanks to the\nnovel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,\nOutput Verifiers). Code and data will be made available upon paper acceptance.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07778v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07500", "title": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "authors": ["Shakir Yousefi", "Andreas Plesner", "Till Aczel", "Roger Wattenhofer"], "summary": "Modern neural networks demonstrate state-of-the-art performance on numerous\nexisting benchmarks; however, their high computational requirements and energy\nconsumption prompt researchers to seek more efficient solutions for real-world\ndeployment. Logic gate networks (LGNs) learns a large network of logic gates\nfor efficient image classification. However, learning a network that can solve\na simple problem like CIFAR-10 can take days to weeks to train. Even then,\nalmost half of the network remains unused, causing a discretization gap. This\ndiscretization gap hinders real-world deployment of LGNs, as the performance\ndrop between training and inference negatively impacts accuracy. We inject\nGumbel noise with a straight-through estimator during training to significantly\nspeed up training, improve neuron utilization, and decrease the discretization\ngap. We theoretically show that this results from implicit Hessian\nregularization, which improves the convergence properties of LGNs. We train\nnetworks $4.5 \\times$ faster in wall-clock time, reduce the discretization gap\nby $98\\%$, and reduce the number of unused gates by $100\\%$.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07500v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07779", "title": "Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods", "authors": ["Beining Xu", "Junxian Li"], "summary": "Visible images offer rich texture details, while infrared images emphasize\nsalient targets. Fusing these complementary modalities enhances scene\nunderstanding, particularly for advanced vision tasks under challenging\nconditions. Recently, deep learning-based fusion methods have gained attention,\nbut current evaluations primarily rely on general-purpose metrics without\nstandardized benchmarks or downstream task performance. Additionally, the lack\nof well-developed dual-spectrum datasets and fair algorithm comparisons hinders\nprogress.\n  To address these gaps, we construct a high-quality dual-spectrum dataset\ncaptured in campus environments, comprising 1,369 well-aligned visible-infrared\nimage pairs across four representative scenarios: daytime, nighttime, smoke\nocclusion, and underpasses. We also propose a comprehensive and fair evaluation\nframework that integrates fusion speed, general metrics, and object detection\nperformance using the lang-segment-anything model to ensure fairness in\ndownstream evaluation.\n  Extensive experiments benchmark several state-of-the-art fusion algorithms\nunder this framework. Results demonstrate that fusion models optimized for\ndownstream tasks achieve superior performance in target detection, especially\nin low-light and occluded scenes. Notably, some algorithms that perform well on\ngeneral metrics do not translate to strong downstream performance, highlighting\nlimitations of current evaluation practices and validating the necessity of our\nproposed framework.\n  The main contributions of this work are: (1)a campus-oriented dual-spectrum\ndataset with diverse and challenging scenes; (2) a task-aware, comprehensive\nevaluation framework; and (3) thorough comparative analysis of leading fusion\nmethods across multiple datasets, offering insights for future development.", "comment": "11 pages, 13 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07779v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07501", "title": "Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning", "authors": ["Libo Wang"], "summary": "In view of the problem that each subchain in the chain-of-model (CoM) relies\nonly on the information of the previous subchain and may lose long-range\ndependencies due to the causal mask blocking the global context flow between\nmulti-level subchains, this work proposes a graph of causal evolution (GoCE).\nIts core principle is to map the implicit token representation into a\ndifferentiable and sparse causal adjacency matrix, then permeate causal\nconstraints through each layer of calculation using causal-masked attention and\ncausal-MoE. By combining intervention consistency loss test and self-evolution\ngate, the dynamic balance between causal structure learning and adaptive\nupdating of transformer architecture is realized. The researcher built\nexperimental environments in sandboxes built with Claude Sonnet 4,\no4-mini-high, and DeepSeek R1 respectively with the transformer variant\narchitecture introduced in GoCE. It is evaluated on publicly available datasets\nincluding CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the\nbaseline LLMs. The finding proves that GoCE strengthens the transformer's\nability to capture long-range causal dependencies, while the ability to\nself-evolve is improved. It not only surpasses the design of CoM in terms of\ndesign principles, but also provides experience for future research on causal\nlearning and continuous adaptive improvement.", "comment": "The relevant code has been uploaded to the publicly available GitHub\n  repository. The link is:\n  https://github.com/brucewang123456789/GeniusTrail/tree/main/GoCE", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07501v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07785", "title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger", "authors": ["Qi Yang", "Chenghao Zhang", "Lubin Fan", "Kun Ding", "Jieping Ye", "Shiming Xiang"], "summary": "Recent advancements in Large Vision Language Models (LVLMs) have\nsignificantly improved performance in Visual Question Answering (VQA) tasks\nthrough multimodal Retrieval-Augmented Generation (RAG). However, existing\nmethods still face challenges, such as the scarcity of knowledge with reasoning\nexamples and erratic responses from retrieved knowledge. To address these\nissues, in this study, we propose a multimodal RAG framework, termed RCTS,\nwhich enhances LVLMs by constructing a Reasoning Context-enriched knowledge\nbase and a Tree Search re-ranking method. Specifically, we introduce a\nself-consistent evaluation mechanism to enrich the knowledge base with\nintrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with\nHeuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This\nensures that LVLMs can leverage high-quality contextual reasoning for better\nand more consistent responses. Extensive experiments demonstrate that our\nframework achieves state-of-the-art performance on multiple VQA datasets,\nsignificantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods.\nIt highlights the effectiveness of our knowledge base and re-ranking method in\nimproving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.", "comment": "ICML 2025 Spotlight. 22 pages, 16 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07785v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07505", "title": "Reinforcement Learning via Implicit Imitation Guidance", "authors": ["Perry Dong", "Alec M. Lessing", "Annie S. Chen", "Chelsea Finn"], "summary": "We study the problem of sample efficient reinforcement learning, where prior\ndata such as demonstrations are provided for initialization in lieu of a dense\nreward signal. A natural approach is to incorporate an imitation learning\nobjective, either as regularization during training or to acquire a reference\npolicy. However, imitation learning objectives can ultimately degrade long-term\nperformance, as it does not directly align with reward maximization. In this\nwork, we propose to use prior data solely for guiding exploration via noise\nadded to the policy, sidestepping the need for explicit behavior cloning\nconstraints. The key insight in our framework, Data-Guided Noise (DGN), is that\ndemonstrations are most useful for identifying which actions should be\nexplored, rather than forcing the policy to take certain actions. Our approach\nachieves up to 2-3x improvement over prior reinforcement learning from offline\ndata methods across seven simulated continuous control tasks.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07505v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07803", "title": "Image Reconstruction as a Tool for Feature Analysis", "authors": ["Eduard Allakhverdov", "Dmitrii Tarasov", "Elizaveta Goncharova", "Andrey Kuznetsov"], "summary": "Vision encoders are increasingly used in modern applications, from\nvision-only models to multimodal systems such as vision-language models.\nDespite their remarkable success, it remains unclear how these architectures\nrepresent features internally. Here, we propose a novel approach for\ninterpreting vision features via image reconstruction. We compare two related\nmodel families, SigLIP and SigLIP2, which differ only in their training\nobjective, and show that encoders pre-trained on image-based tasks retain\nsignificantly more image information than those trained on non-image tasks such\nas contrastive learning. We further apply our method to a range of vision\nencoders, ranking them by the informativeness of their feature representations.\nFinally, we demonstrate that manipulating the feature space yields predictable\nchanges in reconstructed images, revealing that orthogonal rotations (rather\nthan spatial transformations) control color encoding. Our approach can be\napplied to any vision encoder, shedding light on the inner structure of its\nfeature space. The code and model weights to reproduce the experiments are\navailable in GitHub.", "comment": "23 pages, 14 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07803v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07517", "title": "Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems", "authors": ["Shuqiang Zhang", "Yuchao Zhang", "Jinkun Chen", "Haochen Sui"], "summary": "Recommendation systems (RS) aim to provide personalized content, but they\nface a challenge in unbiased learning due to selection bias, where users only\ninteract with items they prefer. This bias leads to a distorted representation\nof user preferences, which hinders the accuracy and fairness of\nrecommendations. To address the issue, various methods such as error imputation\nbased, inverse propensity scoring, and doubly robust techniques have been\ndeveloped. Despite the progress, from the structural causal model perspective,\nprevious debiasing methods in RS assume the independence of the exogenous\nvariables. In this paper, we release this assumption and propose a learning\nalgorithm based on likelihood maximization to learn a prediction model. We\nfirst discuss the correlation and difference between unmeasured confounding and\nour scenario, then we propose a unified method that effectively handles latent\nexogenous variables. Specifically, our method models the data generation\nprocess with latent exogenous variables under mild normality assumptions. We\nthen develop a Monte Carlo algorithm to numerically estimate the likelihood\nfunction. Extensive experiments on synthetic datasets and three real-world\ndatasets demonstrate the effectiveness of our proposed method. The code is at\nhttps://github.com/WallaceSUI/kdd25-background-variable.", "comment": "In Proceedings of the 31st ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining V.2 (KDD '25), August 3--7, 2025, Toronto, ON,\n  Canada", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07517v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07809", "title": "Incorporating Uncertainty-Guided and Top-k Codebook Matching for Real-World Blind Image Super-Resolution", "authors": ["Weilei Wen", "Tianyi Zhang", "Qianqian Zhao", "Zhaohui Zheng", "Chunle Guo", "Xiuli Shao", "Chongyi Li"], "summary": "Recent advancements in codebook-based real image super-resolution (SR) have\nshown promising results in real-world applications. The core idea involves\nmatching high-quality image features from a codebook based on low-resolution\n(LR) image features. However, existing methods face two major challenges:\ninaccurate feature matching with the codebook and poor texture detail\nreconstruction. To address these issues, we propose a novel Uncertainty-Guided\nand Top-k Codebook Matching SR (UGTSR) framework, which incorporates three key\ncomponents: (1) an uncertainty learning mechanism that guides the model to\nfocus on texture-rich regions, (2) a Top-k feature matching strategy that\nenhances feature matching accuracy by fusing multiple candidate features, and\n(3) an Align-Attention module that enhances the alignment of information\nbetween LR and HR features. Experimental results demonstrate significant\nimprovements in texture realism and reconstruction fidelity compared to\nexisting methods. We will release the code upon formal publication.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07809v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07534", "title": "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows", "authors": ["Clément Bonet", "Christophe Vauthier", "Anna Korba"], "summary": "Many applications in machine learning involve data represented as probability\ndistributions. The emergence of such data requires radically novel techniques\nto design tractable gradient flows on probability distributions over this type\nof (infinite-dimensional) objects. For instance, being able to flow labeled\ndatasets is a core task for applications ranging from domain adaptation to\ntransfer learning or dataset distillation. In this setting, we propose to\nrepresent each class by the associated conditional distribution of features,\nand to model the dataset as a mixture distribution supported on these classes\n(which are themselves probability distributions), meaning that labeled datasets\ncan be seen as probability distributions over probability distributions. We\nendow this space with a metric structure from optimal transport, namely the\nWasserstein over Wasserstein (WoW) distance, derive a differential structure on\nthis space, and define WoW gradient flows. The latter enables to design\ndynamics over this space that decrease a given objective functional. We apply\nour framework to transfer learning and dataset distillation tasks, leveraging\nour gradient flow construction as well as novel tractable functionals that take\nthe form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels\nbetween probability distributions.", "comment": "Accepted as an oral at ICML2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07534v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07811", "title": "Looking Beyond Visible Cues: Implicit Video Question Answering via Dual-Clue Reasoning", "authors": ["Tieyuan Chen", "Huabin Liu", "Yi Wang", "Chaofan Gan", "Mingxi Lyu", "Gui Zou", "Weiyao Lin"], "summary": "Video Question Answering (VideoQA) aims to answer natural language questions\nbased on the given video, with prior work primarily focusing on identifying the\nduration of relevant segments, referred to as explicit visual evidence.\nHowever, explicit visual evidence is not always directly available,\nparticularly when questions target symbolic meanings or deeper intentions,\nleading to significant performance degradation. To fill this gap, we introduce\na novel task and dataset, $\\textbf{I}$mplicit $\\textbf{V}$ideo\n$\\textbf{Q}$uestion $\\textbf{A}$nswering (I-VQA), which focuses on answering\nquestions in scenarios where explicit visual evidence is inaccessible. Given an\nimplicit question and its corresponding video, I-VQA requires answering based\non the contextual visual cues present within the video. To tackle I-VQA, we\npropose a novel reasoning framework, IRM (Implicit Reasoning Model),\nincorporating dual-stream modeling of contextual actions and intent clues as\nimplicit reasoning chains. IRM comprises the Action-Intent Module (AIM) and the\nVisual Enhancement Module (VEM). AIM deduces and preserves question-related\ndual clues by generating clue candidates and performing relation deduction. VEM\nenhances contextual visual representation by leveraging key contextual clues.\nExtensive experiments validate the effectiveness of our IRM in I-VQA tasks,\noutperforming GPT-4o, OpenAI-o3, and fine-tuned VideoChat2 by $0.76\\%$,\n$1.37\\%$, and $4.87\\%$, respectively. Additionally, IRM performs SOTA on\nsimilar implicit advertisement understanding and future prediction in\ntraffic-VQA. Datasets and codes are available for double-blind review in\nanonymous repo: https://github.com/tychen-SJTU/Implicit-VideoQA.", "comment": "Preprint", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07811v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07549", "title": "Improving Memory Efficiency for Training KANs via Meta Learning", "authors": ["Zhangchi Zhao", "Jun Shu", "Deyu Meng", "Zongben Xu"], "summary": "Inspired by the Kolmogorov-Arnold representation theorem, KANs offer a novel\nframework for function approximation by replacing traditional neural network\nweights with learnable univariate functions. This design demonstrates\nsignificant potential as an efficient and interpretable alternative to\ntraditional MLPs. However, KANs are characterized by a substantially larger\nnumber of trainable parameters, leading to challenges in memory efficiency and\nhigher training costs compared to MLPs. To address this limitation, we propose\nto generate weights for KANs via a smaller meta-learner, called MetaKANs. By\ntraining KANs and MetaKANs in an end-to-end differentiable manner, MetaKANs\nachieve comparable or even superior performance while significantly reducing\nthe number of trainable parameters and maintaining promising interpretability.\nExtensive experiments on diverse benchmark tasks, including symbolic\nregression, partial differential equation solving, and image classification,\ndemonstrate the effectiveness of MetaKANs in improving parameter efficiency and\nmemory usage. The proposed method provides an alternative technique for\ntraining KANs, that allows for greater scalability and extensibility, and\nnarrows the training cost gap with MLPs stated in the original paper of KANs.\nOur code is available at https://github.com/Murphyzc/MetaKAN.", "comment": "ICML 2025", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07549v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07813", "title": "Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution", "authors": ["Junseo Bang", "Joonhee Lee", "Kyeonghyun Lee", "Haechang Lee", "Dong Un Kang", "Se Young Chun"], "summary": "Arbitrary-scale image super-resolution aims to upsample images to any desired\nresolution, offering greater flexibility than traditional fixed-scale\nsuper-resolution. Recent approaches in this domain utilize regression-based or\ngenerative models, but many of them are a single-stage upsampling process,\nwhich may be challenging to learn across a wide, continuous distribution of\nscaling factors. Progressive upsampling strategies have shown promise in\nmitigating this issue, yet their integration with diffusion models for flexible\nupscaling remains underexplored. Here, we present CasArbi, a novel\nself-cascaded diffusion framework for arbitrary-scale image super-resolution.\nCasArbi meets the varying scaling demands by breaking them down into smaller\nsequential factors and progressively enhancing the image resolution at each\nstep with seamless transitions for arbitrary scales. Our novel\ncoordinate-guided residual diffusion model allows for the learning of\ncontinuous image representations while enabling efficient diffusion sampling.\nExtensive experiments demonstrate that our CasArbi outperforms prior arts in\nboth perceptual and distortion performance metrics across diverse\narbitrary-scale super-resolution benchmarks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07813v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07814", "title": "M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration", "authors": ["Yongzhen Wang", "Yongjun Li", "Zhuoran Zheng", "Xiao-Ping Zhang", "Mingqiang Wei"], "summary": "Natural images are often degraded by complex, composite degradations such as\nrain, snow, and haze, which adversely impact downstream vision applications.\nWhile existing image restoration efforts have achieved notable success, they\nare still hindered by two critical challenges: limited generalization across\ndynamically varying degradation scenarios and a suboptimal balance between\npreserving local details and modeling global dependencies. To overcome these\nchallenges, we propose M2Restore, a novel Mixture-of-Experts (MoE)-based\nMamba-CNN fusion framework for efficient and robust all-in-one image\nrestoration. M2Restore introduces three key contributions: First, to boost the\nmodel's generalization across diverse degradation conditions, we exploit a\nCLIP-guided MoE gating mechanism that fuses task-conditioned prompts with\nCLIP-derived semantic priors. This mechanism is further refined via cross-modal\nfeature calibration, which enables precise expert selection for various\ndegradation types. Second, to jointly capture global contextual dependencies\nand fine-grained local details, we design a dual-stream architecture that\nintegrates the localized representational strength of CNNs with the long-range\nmodeling efficiency of Mamba. This integration enables collaborative\noptimization of global semantic relationships and local structural fidelity,\npreserving global coherence while enhancing detail restoration. Third, we\nintroduce an edge-aware dynamic gating mechanism that adaptively balances\nglobal modeling and local enhancement by reallocating computational attention\nto degradation-sensitive regions. This targeted focus leads to more efficient\nand precise restoration. Extensive experiments across multiple image\nrestoration benchmarks validate the superiority of M2Restore in both visual\nquality and quantitative performance.", "comment": "13 pages, 8 figures, 3 tables", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07814v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07578", "title": "Denoising the Future: Top-p Distributions for Moving Through Time", "authors": ["Florian Andreas Marwitz", "Ralf Möller", "Magnus Bender", "Marcel Gehrke"], "summary": "Inference in dynamic probabilistic models is a complex task involving\nexpensive operations. In particular, for Hidden Markov Models, the whole state\nspace has to be enumerated for advancing in time. Even states with negligible\nprobabilities are considered, resulting in computational inefficiency and\nincreased noise due to the propagation of unlikely probability mass. We propose\nto denoise the future and speed up inference by using only the top-p states,\ni.e., the most probable states with accumulated probability p. We show that the\nerror introduced by using only the top-p states is bound by p and the so-called\nminimal mixing rate of the underlying model. Moreover, in our empirical\nevaluation, we show that we can expect speedups of at least an order of\nmagnitude, while the error in terms of total variation distance is below 0.09.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07578v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06575", "title": "Evaluating Undergrounding Decisions for Wildfire Ignition Risk Mitigation across Multiple Hazards", "authors": ["Ryan Piansky", "Daniel K. Molzahn", "Nicole D. Jackson", "J. Kyle Skolfield"], "summary": "With electric power infrastructure increasingly susceptible to impacts from\nclimate-driven natural disasters, there is an increasing need for optimization\nalgorithms that determine where to harden the power grid. Prior work has\nprimarily developed optimal hardening approaches for specific acute disaster\nscenarios. Given the extensive costs of hardening the grid, it is important to\nunderstand how a particular set of resilience investments will perform under\nmultiple types of natural hazards. Using a large-scale test case representing\nthe Texas power system, this paper aims to understand how line undergrounding\ninvestment decisions made for wildfire ignition risk mitigation perform during\na range of wildfire, hurricane, and wind events. Given the varying geographical\nspread and damage profile of these events, we show that investment decisions\nmade to address one type of natural disaster do not necessarily improve broader\nresilience outcomes, supporting the need for co-optimization across a range of\nhazards.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06575v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07841", "title": "Diffusion models under low-noise regime", "authors": ["Elizabeth Pavlova", "Xue-Xin Wei"], "summary": "Recent work on diffusion models proposed that they operate in two regimes:\nmemorization, in which models reproduce their training data, and\ngeneralization, in which they generate novel samples. While this has been\ntested in high-noise settings, the behavior of diffusion models as effective\ndenoisers when the corruption level is small remains unclear. To address this\ngap, we systematically investigated the behavior of diffusion models under\nlow-noise diffusion dynamics, with implications for model robustness and\ninterpretability. Using (i) CelebA subsets of varying sample sizes and (ii)\nanalytic Gaussian mixture benchmarks, we reveal that models trained on disjoint\ndata diverge near the data manifold even when their high-noise outputs\nconverge. We quantify how training set size, data geometry, and model objective\nchoice shape denoising trajectories and affect score accuracy, providing\ninsights into how these models actually learn representations of data\ndistributions. This work starts to address gaps in our understanding of\ngenerative model reliability in practical applications where small\nperturbations are common.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07841v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07584", "title": "MIRA: Medical Time Series Foundation Model for Real-World Health Data", "authors": ["Hao Li", "Bowen Deng", "Chang Xu", "Zhiyuan Feng", "Viktor Schlegel", "Yu-Hao Huang", "Yizheng Sun", "Jingyuan Sun", "Kailai Yang", "Yiyao Yu", "Jiang Bian"], "summary": "A unified foundation model for medical time series -- pretrained on open\naccess and ethics board-approved medical corpora -- offers the potential to\nreduce annotation burdens, minimize model customization, and enable robust\ntransfer across clinical institutions, modalities, and tasks, particularly in\ndata-scarce or privacy-constrained environments. However, existing generalist\ntime series foundation models struggle to handle medical time series data due\nto their inherent challenges, including irregular intervals, heterogeneous\nsampling rates, and frequent missing values. To address these challenges, we\nintroduce MIRA, a unified foundation model specifically designed for medical\ntime series forecasting. MIRA incorporates a Continuous-Time Rotary Positional\nEncoding that enables fine-grained modeling of variable time intervals, a\nfrequency-specific mixture-of-experts layer that routes computation across\nlatent frequency regimes to further promote temporal specialization, and a\nContinuous Dynamics Extrapolation Block based on Neural ODE that models the\ncontinuous trajectory of latent states, enabling accurate forecasting at\narbitrary target timestamps. Pretrained on a large-scale and diverse medical\ncorpus comprising over 454 billion time points collect from publicly available\ndatasets, MIRA achieves reductions in forecasting errors by an average of 10%\nand 7% in out-of-distribution and in-distribution scenarios, respectively, when\ncompared to other zero-shot and fine-tuned baselines. We also introduce a\ncomprehensive benchmark spanning multiple downstream clinical tasks,\nestablishing a foundation for future research in medical time series modeling.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07584v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07847", "title": "F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation", "authors": ["Hengzhi Chen", "Liqian Feng", "Wenhua Wu", "Xiaogang Zhu", "Shawn Leo", "Kun Hu"], "summary": "Semantic segmentation of ultra-high-resolution (UHR) remote sensing imagery\nis critical for applications like environmental monitoring and urban planning\nbut faces computational and optimization challenges. Conventional methods\neither lose fine details through downsampling or fragment global context via\npatch processing. While multi-branch networks address this trade-off, they\nsuffer from computational inefficiency and conflicting gradient dynamics during\ntraining. We propose F2Net, a frequency-aware framework that decomposes UHR\nimages into high- and low-frequency components for specialized processing. The\nhigh-frequency branch preserves full-resolution structural details, while the\nlow-frequency branch processes downsampled inputs through dual sub-branches\ncapturing short- and long-range dependencies. A Hybrid-Frequency Fusion module\nintegrates these observations, guided by two novel objectives: Cross-Frequency\nAlignment Loss ensures semantic consistency between frequency components, and\nCross-Frequency Balance Loss regulates gradient magnitudes across branches to\nstabilize training. Evaluated on DeepGlobe and Inria Aerial benchmarks, F2Net\nachieves state-of-the-art performance with mIoU of 80.22 and 83.39,\nrespectively. Our code will be publicly available.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07847v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06566", "title": "AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition", "authors": ["Chen Bao", "Chuanbing Huo", "Qinyu Chen", "Chang Gao"], "summary": "This paper proposes AS-ASR, a lightweight aphasia-specific speech recognition\nframework based on Whisper-tiny, tailored for low-resource deployment on edge\ndevices. Our approach introduces a hybrid training strategy that systematically\ncombines standard and aphasic speech at varying ratios, enabling robust\ngeneralization, and a GPT-4-based reference enhancement method that refines\nnoisy aphasic transcripts, improving supervision quality. We conduct extensive\nexperiments across multiple data mixing configurations and evaluation settings.\nResults show that our fine-tuned model significantly outperforms the zero-shot\nbaseline, reducing WER on aphasic speech by over 30% while preserving\nperformance on standard speech. The proposed framework offers a scalable,\nefficient solution for real-world disordered speech recognition.", "comment": "Under review", "cate": "eess.AS", "url": "http://arxiv.org/abs/2506.06566v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07585", "title": "Aircraft Trajectory Dataset Augmentation in Latent Space", "authors": ["Seokbin Yoon", "Keumjin Lee"], "summary": "Aircraft trajectory modeling plays a crucial role in Air Traffic Management\n(ATM) and is important for various downstream tasks, including conflict\ndetection and landing time prediction. Dataset augmentation through the\naddition of synthetically generated trajectory data is necessary to develop a\nmore robust aircraft trajectory model and ensure that the trajectory dataset is\nsufficient and balanced. In this work, we propose a novel framework called\nATRADA for aircraft trajectory dataset augmentation. In the proposed framework,\na Transformer encoder learns the underlying patterns in the original trajectory\ndataset and converts each data point into a context vector in the learned\nlatent space. The converted dataset in the latent space is projected into\nreduced dimensions using principal component analysis (PCA), and a Gaussian\nmixture model (GMM) is applied to fit the probability distribution of the data\npoints in the reduced-dimensional space. Finally, new samples are drawn from\nthe fitted GMM, the dimension of the samples is reverted to the original\ndimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several\nexperiments demonstrate that the framework effectively generates new,\nhigh-quality synthetic aircraft trajectory data, which were compared to the\nresults of several baselines.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07585v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07848", "title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement", "authors": ["Teng Hu", "Zhentao Yu", "Zhengguang Zhou", "Jiangning Zhang", "Yuan Zhou", "Qinglin Lu", "Ran Yi"], "summary": "Despite recent advances in video generation, existing models still lack\nfine-grained controllability, especially for multi-subject customization with\nconsistent identity and interaction. In this paper, we propose PolyVivid, a\nmulti-subject video customization framework that enables flexible and\nidentity-consistent generation. To establish accurate correspondences between\nsubject images and textual entities, we design a VLLM-based text-image fusion\nmodule that embeds visual identities into the textual space for precise\ngrounding. To further enhance identity preservation and subject interaction, we\npropose a 3D-RoPE-based enhancement module that enables structured\nbidirectional fusion between text and image embeddings. Moreover, we develop an\nattention-inherited identity injection module to effectively inject fused\nidentity features into the video generation process, mitigating identity drift.\nFinally, we construct an MLLM-based data pipeline that combines MLLM-based\ngrounding, segmentation, and a clique-based subject consolidation strategy to\nproduce high-quality multi-subject data, effectively enhancing subject\ndistinction and reducing ambiguity in downstream video generation. Extensive\nexperiments demonstrate that PolyVivid achieves superior performance in\nidentity fidelity, video realism, and subject alignment, outperforming existing\nopen-source and commercial baselines.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07848v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07587", "title": "PrunePEFT: Iterative Hybrid Pruning for Parameter-Efficient Fine-tuning of LLMs", "authors": ["Tongzhou Yu", "Zhuhao Zhang", "Guanghui Zhu", "Shen Jiang", "Meikang Qiu", "Yihua Huang"], "summary": "Parameter Efficient Fine-Tuning (PEFT) methods have emerged as effective and\npromising approaches for fine-tuning pre-trained language models. Compared with\nFull parameter Fine-Tuning (FFT), PEFT achieved comparable task performance\nwith a substantial reduction of trainable parameters, which largely saved the\ntraining and storage costs. However, using the PEFT method requires considering\na vast design space, such as the type of PEFT modules and their insertion\nlayers. Inadequate configurations can lead to sub-optimal results. Conventional\nsolutions such as architectural search techniques, while effective, tend to\nintroduce substantial additional overhead. In this paper, we propose a novel\napproach, PrunePEFT, which formulates the PEFT strategy search as a pruning\nproblem and introduces a hybrid pruning strategy that capitalizes on the\nsensitivity of pruning methods to different PEFT modules. This method extends\ntraditional pruning techniques by iteratively removing redundant or conflicting\nPEFT modules, thereby optimizing the fine-tuned configuration. By efficiently\nidentifying the most relevant modules, our approach significantly reduces the\ncomputational burden typically associated with architectural search processes,\nmaking it a more scalable and efficient solution for fine-tuning large\npre-trained models.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07587v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07850", "title": "SAM2Auto: Auto Annotation Using FLASH", "authors": ["Arash Rocky", "Q. M. Jonathan Wu"], "summary": "Vision-Language Models (VLMs) lag behind Large Language Models due to the\nscarcity of annotated datasets, as creating paired visual-textual annotations\nis labor-intensive and expensive. To address this bottleneck, we introduce\nSAM2Auto, the first fully automated annotation pipeline for video datasets\nrequiring no human intervention or dataset-specific training. Our approach\nconsists of two key components: SMART-OD, a robust object detection system that\ncombines automatic mask generation with open-world object detection\ncapabilities, and FLASH (Frame-Level Annotation and Segmentation Handler), a\nmulti-object real-time video instance segmentation (VIS) that maintains\nconsistent object identification across video frames even with intermittent\ndetection gaps. Unlike existing open-world detection methods that require\nframe-specific hyperparameter tuning and suffer from numerous false positives,\nour system employs statistical approaches to minimize detection errors while\nensuring consistent object tracking throughout entire video sequences.\nExtensive experimental validation demonstrates that SAM2Auto achieves\ncomparable accuracy to manual annotation while dramatically reducing annotation\ntime and eliminating labor costs. The system successfully handles diverse\ndatasets without requiring retraining or extensive parameter adjustments,\nmaking it a practical solution for large-scale dataset creation. Our work\nestablishes a new baseline for automated video annotation and provides a\npathway for accelerating VLM development by addressing the fundamental dataset\nbottleneck that has constrained progress in vision-language understanding.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07850v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07595", "title": "Exploiting Curvature in Online Convex Optimization with Delayed Feedback", "authors": ["Hao Qiu", "Emmanuel Esposito", "Mengxiao Zhang"], "summary": "In this work, we study the online convex optimization problem with curved\nlosses and delayed feedback. When losses are strongly convex, existing\napproaches obtain regret bounds of order $d_{\\max} \\ln T$, where $d_{\\max}$ is\nthe maximum delay and $T$ is the time horizon. However, in many cases, this\nguarantee can be much worse than $\\sqrt{d_{\\mathrm{tot}}}$ as obtained by a\ndelayed version of online gradient descent, where $d_{\\mathrm{tot}}$ is the\ntotal delay. We bridge this gap by proposing a variant of\nfollow-the-regularized-leader that obtains regret of order\n$\\min\\{\\sigma_{\\max}\\ln T, \\sqrt{d_{\\mathrm{tot}}}\\}$, where $\\sigma_{\\max}$ is\nthe maximum number of missing observations. We then consider exp-concave losses\nand extend the Online Newton Step algorithm to handle delays with an adaptive\nlearning rate tuning, achieving regret $\\min\\{d_{\\max} n\\ln T,\n\\sqrt{d_{\\mathrm{tot}}}\\}$ where $n$ is the dimension. To our knowledge, this\nis the first algorithm to achieve such a regret bound for exp-concave losses.\nWe further consider the problem of unconstrained online linear regression and\nachieve a similar guarantee by designing a variant of the Vovk-Azoury-Warmuth\nforecaster with a clipping trick. Finally, we implement our algorithms and\nconduct experiments under various types of delay and losses, showing an\nimproved performance over existing methods.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07595v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07596", "title": "TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts", "authors": ["Torsten Krauß", "Hamid Dashtbani", "Alexandra Dmitrienko"], "summary": "Machine learning is advancing rapidly, with applications bringing notable\nbenefits, such as improvements in translation and code generation. Models like\nChatGPT, powered by Large Language Models (LLMs), are increasingly integrated\ninto daily life. However, alongside these benefits, LLMs also introduce social\nrisks. Malicious users can exploit LLMs by submitting harmful prompts, such as\nrequesting instructions for illegal activities. To mitigate this, models often\ninclude a security mechanism that automatically rejects such harmful prompts.\nHowever, they can be bypassed through LLM jailbreaks. Current jailbreaks often\nrequire significant manual effort, high computational costs, or result in\nexcessive model modifications that may degrade regular utility.\n  We introduce TwinBreak, an innovative safety alignment removal method.\nBuilding on the idea that the safety mechanism operates like an embedded\nbackdoor, TwinBreak identifies and prunes parameters responsible for this\nfunctionality. By focusing on the most relevant model layers, TwinBreak\nperforms fine-grained analysis of parameters essential to model utility and\nsafety. TwinBreak is the first method to analyze intermediate outputs from\nprompts with high structural and content similarity to isolate safety\nparameters. We present the TwinPrompt dataset containing 100 such twin prompts.\nExperiments confirm TwinBreak's effectiveness, achieving 89% to 98% success\nrates with minimal computational requirements across 16 LLMs from five vendors.", "comment": "26 pages, 25 tables, 13 figures, 2 algorithms, to appear in the 43th\n  USENIX Security Symposium (USENIX Security 2025)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07596v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07860", "title": "Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction", "authors": ["Ivan Alberico", "Marco Cannici", "Giovanni Cioffi", "Davide Scaramuzza"], "summary": "In this paper, we present a real-time egocentric trajectory prediction system\nfor table tennis using event cameras. Unlike standard cameras, which suffer\nfrom high latency and motion blur at fast ball speeds, event cameras provide\nhigher temporal resolution, allowing more frequent state updates, greater\nrobustness to outliers, and accurate trajectory predictions using just a short\ntime window after the opponent's impact. We collect a dataset of ping-pong game\nsequences, including 3D ground-truth trajectories of the ball, synchronized\nwith sensor data from the Meta Project Aria glasses and event streams. Our\nsystem leverages foveated vision, using eye-gaze data from the glasses to\nprocess only events in the viewer's fovea. This biologically inspired approach\nimproves ball detection performance and significantly reduces computational\nlatency, as it efficiently allocates resources to the most perceptually\nrelevant regions, achieving a reduction factor of 10.81 on the collected\ntrajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,\nincluding computation and perception - significantly lower than a frame-based\n30 FPS system, which, in the worst case, takes 66 ms solely for perception.\nFinally, we fit a trajectory prediction model to the estimated states of the\nball, enabling 3D trajectory forecasting in the future. To the best of our\nknowledge, this is the first approach to predict table tennis trajectories from\nan egocentric perspective using event cameras.", "comment": "IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  Workshops (CVPRW), Nashville (TN), USA, 2025; 5th International Workshop on\n  Event-Based Vision", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07860v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07616", "title": "FuXi-Air: Urban Air Quality Forecasting Based on Emission-Meteorology-Pollutant multimodal Machine Learning", "authors": ["Zhixin Geng", "Xu Fan", "Xiqiao Lu", "Yan Zhang", "Guangyuan Yu", "Cheng Huang", "Qian Wang", "Yuewu Li", "Weichun Ma", "Qi Yu", "Libo Wu", "Hao Li"], "summary": "Air pollution has emerged as a major public health challenge in megacities.\nNumerical simulations and single-site machine learning approaches have been\nwidely applied in air quality forecasting tasks. However, these methods face\nmultiple limitations, including high computational costs, low operational\nefficiency, and limited integration with observational data. With the rapid\nadvancement of artificial intelligence, there is an urgent need to develop a\nlow-cost, efficient air quality forecasting model for smart urban management.\nAn air quality forecasting model, named FuXi-Air, has been constructed in this\nstudy based on multimodal data fusion to support high-precision air quality\nforecasting and operated in typical megacities. The model integrates\nmeteorological forecasts, emission inventories, and pollutant monitoring data\nunder the guidance of air pollution mechanism. By combining an autoregressive\nprediction framework with a frame interpolation strategy, the model\nsuccessfully completes 72-hour forecasts for six major air pollutants at an\nhourly resolution across multiple monitoring sites within 25-30 seconds. In\nterms of both computational efficiency and forecasting accuracy, it outperforms\nthe mainstream numerical air quality models in operational forecasting work.\nAblation experiments concerning key influencing factors show that although\nmeteorological data contribute more to model accuracy than emission inventories\ndo, the integration of multimodal data significantly improves forecasting\nprecision and ensures that reliable predictions are obtained under differing\npollution mechanisms across megacities. This study provides both a technical\nreference and a practical example for applying multimodal data-driven models to\nair quality forecasting and offers new insights into building hybrid\nforecasting systems to support air pollution risk warning in smart city\nmanagement.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07616v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06589", "title": "Precise Information Control in Long-Form Text Generation", "authors": ["Jacqueline He", "Howard Yen", "Margaret Li", "Shuyue Stella Li", "Zhiyuan Zeng", "Weijia Shi", "Yulia Tsvetkov", "Danqi Chen", "Pang Wei Koh", "Luke Zettlemoyer"], "summary": "A central challenge in modern language models (LMs) is intrinsic\nhallucination: the generation of information that is plausible but\nunsubstantiated relative to input context. To study this problem, we propose\nPrecise Information Control (PIC), a new task formulation that requires models\nto generate long-form outputs grounded in a provided set of short\nself-contained statements, known as verifiable claims, without adding any\nunsupported ones. For comprehensiveness, PIC includes a full setting that tests\na model's ability to include exactly all input claims, and a partial setting\nthat requires the model to selectively incorporate only relevant claims. We\npresent PIC-Bench, a benchmark of eight long-form generation tasks (e.g.,\nsummarization, biography generation) adapted to the PIC setting, where LMs are\nsupplied with well-formed, verifiable input claims. Our evaluation of a range\nof open and proprietary LMs on PIC-Bench reveals that, surprisingly,\nstate-of-the-art LMs still intrinsically hallucinate in over 70% of outputs. To\nalleviate this lack of faithfulness, we introduce a post-training framework,\nusing a weakly supervised preference data construction method, to train an 8B\nPIC-LM with stronger PIC ability--improving from 69.1% to 91.0% F1 in the full\nPIC setting. When integrated into end-to-end factual generation pipelines,\nPIC-LM improves exact match recall by 17.1% on ambiguous QA with retrieval, and\nfactual precision by 30.5% on a birthplace verification task, underscoring the\npotential of precisely grounded generation.", "comment": "56 pages, 8 figures. Code and models are publicly available at\n  https://github.com/jacqueline-he/precise-information-control", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06589v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07863", "title": "VIVAT: Virtuous Improving VAE Training through Artifact Mitigation", "authors": ["Lev Novitskiy", "Viacheslav Vasilev", "Maria Kovaleva", "Vladimir Arkhipkin", "Denis Dimitrov"], "summary": "Variational Autoencoders (VAEs) remain a cornerstone of generative computer\nvision, yet their training is often plagued by artifacts that degrade\nreconstruction and generation quality. This paper introduces VIVAT, a\nsystematic approach to mitigating common artifacts in KL-VAE training without\nrequiring radical architectural changes. We present a detailed taxonomy of five\nprevalent artifacts - color shift, grid patterns, blur, corner and droplet\nartifacts - and analyze their root causes. Through straightforward\nmodifications, including adjustments to loss weights, padding strategies, and\nthe integration of Spatially Conditional Normalization, we demonstrate\nsignificant improvements in VAE performance. Our method achieves\nstate-of-the-art results in image reconstruction metrics (PSNR and SSIM) across\nmultiple benchmarks and enhances text-to-image generation quality, as evidenced\nby superior CLIP scores. By preserving the simplicity of the KL-VAE framework\nwhile addressing its practical challenges, VIVAT offers actionable insights for\nresearchers and practitioners aiming to optimize VAE training.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07863v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06594", "title": "From Model-Based and Adaptive Control to Evolving Fuzzy Control", "authors": ["Daniel Leite", "Igor Škrjanc", "Fernando Gomide"], "summary": "Evolving fuzzy systems build and adapt fuzzy models - such as predictors and\ncontrollers - by incrementally updating their rule-base structure from data\nstreams. On the occasion of the 60-year anniversary of fuzzy set theory,\ncommemorated during the Fuzz-IEEE 2025 event, this brief paper revisits the\nhistorical development and core contributions of classical fuzzy and adaptive\nmodeling and control frameworks. It then highlights the emergence and\nsignificance of evolving intelligent systems in fuzzy modeling and control,\nemphasizing their advantages in handling nonstationary environments. Key\nchallenges and future directions are discussed, including safety,\ninterpretability, and principled structural evolution.", "comment": "4 pages, 2 figures. Fuzz-IEEE 2025 Booklet: 60 Years of Fuzzy Set\n  Theory", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06594v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07619", "title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning", "authors": ["Toby Boyne", "Juan S. Campos", "Becky D. Langdon", "Jixiang Qing", "Yilin Xie", "Shiqiang Zhang", "Calvin Tsay", "Ruth Misener", "Daniel W. Davies", "Kim E. Jelfs", "Sarah Boyall", "Thomas M. Dixon", "Linden Schrecker", "Jose Pablo Folch"], "summary": "Machine learning has promised to change the landscape of laboratory\nchemistry, with impressive results in molecular property prediction and\nreaction retro-synthesis. However, chemical datasets are often inaccessible to\nthe machine learning community as they tend to require cleaning, thorough\nunderstanding of the chemistry, or are simply not available. In this paper, we\nintroduce a novel dataset for yield prediction, providing the first-ever\ntransient flow dataset for machine learning benchmarking, covering over 1200\nprocess conditions. While previous datasets focus on discrete parameters, our\nexperimental set-up allow us to sample a large number of continuous process\nconditions, generating new challenges for machine learning models. We focus on\nsolvent selection, a task that is particularly difficult to model theoretically\nand therefore ripe for machine learning applications. We showcase benchmarking\nfor regression algorithms, transfer-learning approaches, feature engineering,\nand active learning, with important applications towards solvent replacement\nand sustainable manufacturing.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07619v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07624", "title": "Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks", "authors": ["Ali Hariri", "Álvaro Arroyo", "Alessio Gravina", "Moshe Eliasof", "Carola-Bibiane Schönlieb", "Davide Bacciu", "Kamyar Azizzadenesheli", "Xiaowen Dong", "Pierre Vandergheynst"], "summary": "ChebNet, one of the earliest spectral GNNs, has largely been overshadowed by\nMessage Passing Neural Networks (MPNNs), which gained popularity for their\nsimplicity and effectiveness in capturing local graph structure. Despite their\nsuccess, MPNNs are limited in their ability to capture long-range dependencies\nbetween nodes. This has led researchers to adapt MPNNs through rewiring or make\nuse of Graph Transformers, which compromises the computational efficiency that\ncharacterized early spatial message-passing architectures, and typically\ndisregards the graph structure. Almost a decade after its original\nintroduction, we revisit ChebNet to shed light on its ability to model distant\nnode interactions. We find that out-of-box, ChebNet already shows competitive\nadvantages relative to classical MPNNs and GTs on long-range benchmarks, while\nmaintaining good scalability properties for high-order polynomials. However, we\nuncover that this polynomial expansion leads ChebNet to an unstable regime\nduring training. To address this limitation, we cast ChebNet as a stable and\nnon-dissipative dynamical system, which we coin Stable-ChebNet. Our\nStable-ChebNet model allows for stable information propagation, and has\ncontrollable dynamics which do not require the use of eigendecompositions,\npositional encodings, or graph rewiring. Across several benchmarks,\nStable-ChebNet achieves near state-of-the-art performance.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07624v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07878", "title": "Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow", "authors": ["Muhammad Ahmed Humais", "Xiaoqian Huang", "Hussain Sajwani", "Sajid Javed", "Yahya Zweiri"], "summary": "Event cameras unlock new frontiers that were previously unthinkable with\nstandard frame-based cameras. One notable example is low-latency motion\nestimation (optical flow), which is critical for many real-time applications.\nIn such applications, the computational efficiency of algorithms is paramount.\nAlthough recent deep learning paradigms such as CNN, RNN, or ViT have shown\nremarkable performance, they often lack the desired computational efficiency.\nConversely, asynchronous event-based methods including SNNs and GNNs are\ncomputationally efficient; however, these approaches fail to capture sufficient\nspatio-temporal information, a powerful feature required to achieve better\nperformance for optical flow estimation. In this work, we introduce\nSpatio-Temporal State Space Model (STSSM) module along with a novel network\narchitecture to develop an extremely efficient solution with competitive\nperformance. Our STSSM module leverages state-space models to effectively\ncapture spatio-temporal correlations in event data, offering higher performance\nwith lower complexity compared to ViT, CNN-based architectures in similar\nsettings. Our model achieves 4.5x faster inference and 8x lower computations\ncompared to TMA and 2x lower computations compared to EV-FlowNet with\ncompetitive performance on the DSEC benchmark. Our code will be available at\nhttps://github.com/AhmedHumais/E-STMFlow", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07878v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06605", "title": "MedCite: Can Language Models Generate Verifiable Text for Medicine?", "authors": ["Xiao Wang", "Mengjue Tan", "Qiao Jin", "Guangzhi Xiong", "Yu Hu", "Aidong Zhang", "Zhiyong Lu", "Minjia Zhang"], "summary": "Existing LLM-based medical question-answering systems lack citation\ngeneration and evaluation capabilities, raising concerns about their adoption\nin practice. In this work, we introduce \\name, the first end-to-end framework\nthat facilitates the design and evaluation of citation generation with LLMs for\nmedical tasks. Meanwhile, we introduce a novel multi-pass retrieval-citation\nmethod that generates high-quality citations. Our evaluation highlights the\nchallenges and opportunities of citation generation for medical tasks, while\nidentifying important design choices that have a significant impact on the\nfinal citation quality. Our proposed method achieves superior citation\nprecision and recall improvements compared to strong baseline methods, and we\nshow that evaluation results correlate well with annotation results from\nprofessional experts.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06605v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07885", "title": "CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing", "authors": ["Zubin Bhuyan", "Yuanchang Xie", "AngkeaReach Rith", "Xintong Yan", "Nasko Apostolov", "Jimi Oke", "Chengbo Ai"], "summary": "With the increasing availability of aerial and satellite imagery, deep\nlearning presents significant potential for transportation asset management,\nsafety analysis, and urban planning. This study introduces CrosswalkNet, a\nrobust and efficient deep learning framework designed to detect various types\nof pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNet\nincorporates a novel detection approach that improves upon traditional object\ndetection strategies by utilizing oriented bounding boxes (OBB), enhancing\ndetection precision by accurately capturing crosswalks regardless of their\norientation. Several optimization techniques, including Convolutional Block\nAttention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosine\nannealing, are implemented to maximize performance and efficiency. A\ncomprehensive dataset comprising over 23,000 annotated crosswalk instances is\nutilized to train and validate the proposed framework. The best-performing\nmodel achieves an impressive precision of 96.5% and a recall of 93.3% on aerial\nimagery from Massachusetts, demonstrating its accuracy and effectiveness.\nCrosswalkNet has also been successfully applied to datasets from New Hampshire,\nVirginia, and Maine without transfer learning or fine-tuning, showcasing its\nrobustness and strong generalization capability. Additionally, the crosswalk\ndetection results, processed using High-Performance Computing (HPC) platforms\nand provided in polygon shapefile format, have been shown to accelerate data\nprocessing and detection, supporting real-time analysis for safety and mobility\napplications. This integration offers policymakers, transportation engineers,\nand urban planners an effective instrument to enhance pedestrian safety and\nimprove urban mobility.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07885v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06607", "title": "Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit", "authors": ["Charles Goddard", "Fernando Fernandes Neto"], "summary": "We present a training-free method to transplant tokenizers in pretrained\nlarge language models (LLMs) by reconstructing unseen token embeddings via\nOrthogonal Matching Pursuit (OMP). Specifically, we approximate each\nout-of-vocabulary token as a sparse linear combination of shared tokens, in two\nphases: first, compute each new token's representation in the donor embedding\nspace with a small dictionary of shared anchor tokens, then transfer these same\nsparse coefficients back into the base model's embedding space.\n  On two challenging cross-tokenizer tasks--Llama$\\to$Mistral NeMo (12B) and\nQwen$\\to$Llama (1B)--we show that OMP achieves best zero-shot preservation of\nthe base model's performance across multiple benchmarks, while other zero-shot\napproaches degrade significantly. Compared to baselines (zero-init, mean-init,\nand existing approaches like WECHSEL, FOCUS, ZETT), OMP consistently achieves\nthe best overall performance, effectively bridging large tokenizer\ndiscrepancies without gradient updates. Our analysis further identifies\nmismatched numerical tokenization schemes as a critical challenge for\npreserving mathematical reasoning capabilities. This technique enables direct\nreuse of pretrained model weights with new tokenizers, facilitating\ncross-tokenizer knowledge distillation, speculative decoding, ensembling,\nmerging, and domain-specific vocabulary adaptations. We integrate our method\ninto the open-source mergekit-tokensurgeon tool for post hoc vocabulary\nrealignment.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06607v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07666", "title": "ProARD: progressive adversarial robustness distillation: provide wide range of robust students", "authors": ["Seyedhamidreza Mousavi", "Seyedali Mousavi", "Masoud Daneshtalab"], "summary": "Adversarial Robustness Distillation (ARD) has emerged as an effective method\nto enhance the robustness of lightweight deep neural networks against\nadversarial attacks. Current ARD approaches have leveraged a large robust\nteacher network to train one robust lightweight student. However, due to the\ndiverse range of edge devices and resource constraints, current approaches\nrequire training a new student network from scratch to meet specific\nconstraints, leading to substantial computational costs and increased CO2\nemissions. This paper proposes Progressive Adversarial Robustness Distillation\n(ProARD), enabling the efficient one-time training of a dynamic network that\nsupports a diverse range of accurate and robust student networks without\nrequiring retraining. We first make a dynamic deep neural network based on\ndynamic layers by encompassing variations in width, depth, and expansion in\neach design stage to support a wide range of architectures. Then, we consider\nthe student network with the largest size as the dynamic teacher network.\nProARD trains this dynamic network using a weight-sharing mechanism to jointly\noptimize the dynamic teacher network and its internal student networks.\nHowever, due to the high computational cost of calculating exact gradients for\nall the students within the dynamic network, a sampling mechanism is required\nto select a subset of students. We show that random student sampling in each\niteration fails to produce accurate and robust students.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07666v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07886", "title": "EgoM2P: Egocentric Multimodal Multitask Pretraining", "authors": ["Gen Li", "Yutong Chen", "Yiqian Wu", "Kaifeng Zhao", "Marc Pollefeys", "Siyu Tang"], "summary": "Understanding multimodal signals in egocentric vision, such as RGB video,\ndepth, camera poses, and gaze, is essential for applications in augmented\nreality, robotics, and human-computer interaction. These capabilities enable\nsystems to better interpret the camera wearer's actions, intentions, and\nsurrounding environment. However, building large-scale egocentric multimodal\nand multitask models presents unique challenges. Egocentric data are inherently\nheterogeneous, with large variations in modality coverage across devices and\nsettings. Generating pseudo-labels for missing modalities, such as gaze or\nhead-mounted camera trajectories, is often infeasible, making standard\nsupervised learning approaches difficult to scale. Furthermore, dynamic camera\nmotion and the complex temporal and spatial structure of first-person video\npose additional challenges for the direct application of existing multimodal\nfoundation models.\n  To address these challenges, we introduce a set of efficient temporal\ntokenizers and propose EgoM2P, a masked modeling framework that learns from\ntemporally aware multimodal tokens to train a large, general-purpose model for\negocentric 4D understanding. This unified design supports multitasking across\ndiverse egocentric perception and synthesis tasks, including gaze prediction,\negocentric camera tracking, and monocular depth estimation from egocentric\nvideo. EgoM2P also serves as a generative model for conditional egocentric\nvideo synthesis. Across these tasks, EgoM2P matches or outperforms specialist\nmodels while being an order of magnitude faster. We will fully open-source\nEgoM2P to support the community and advance egocentric vision research. Project\npage: https://egom2p.github.io/", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07886v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07673", "title": "How Benchmark Prediction from Fewer Data Misses the Mark", "authors": ["Guanhua Zhang", "Florian E. Dorner", "Moritz Hardt"], "summary": "Large language model (LLM) evaluation is increasingly costly, prompting\ninterest in methods that speed up evaluation by shrinking benchmark datasets.\nBenchmark prediction (also called efficient LLM evaluation) aims to select a\nsmall subset of evaluation points and predict overall benchmark performance\nfrom that subset. In this paper, we systematically assess the strengths and\nlimitations of 11 benchmark prediction methods across 19 diverse benchmarks.\nFirst, we identify a highly competitive baseline: Take a random sample and fit\na regression model on the sample to predict missing entries. Outperforming most\nexisting methods, this baseline challenges the assumption that careful subset\nselection is necessary for benchmark prediction. Second, we discover that all\nexisting methods crucially depend on model similarity. They work best when\ninterpolating scores among similar models. The effectiveness of benchmark\nprediction sharply declines when new models have higher accuracy than\npreviously seen models. In this setting of extrapolation, none of the previous\nmethods consistently beat a simple average over random samples. To improve over\nthe sample average, we introduce a new method inspired by augmented inverse\npropensity weighting. This method consistently outperforms the random sample\naverage even for extrapolation. However, its performance still relies on model\nsimilarity and the gains are modest in general. This shows that benchmark\nprediction fails just when it is most needed: at the evaluation frontier, where\nthe goal is to evaluate new models of unknown capabilities.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07673v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07891", "title": "Video Unlearning via Low-Rank Refusal Vector", "authors": ["Simone Facchiano", "Stefano Saravalle", "Matteo Migliarini", "Edoardo De Matteis", "Alessio Sampieri", "Andrea Pilzer", "Emanuele Rodolà", "Indro Spinelli", "Luca Franco", "Fabio Galasso"], "summary": "Video generative models democratize the creation of visual content through\nintuitive instruction following, but they also inherit the biases and harmful\nconcepts embedded within their web-scale training data. This inheritance\ncreates a significant risk, as users can readily generate undesirable and even\nillegal content. This work introduces the first unlearning technique tailored\nexplicitly for video diffusion models to address this critical issue. Our\nmethod requires 5 multi-modal prompt pairs only. Each pair contains a \"safe\"\nand an \"unsafe\" example that differ only by the target concept. Averaging their\nper-layer latent differences produces a \"refusal vector\", which, once\nsubtracted from the model parameters, neutralizes the unsafe concept. We\nintroduce a novel low-rank factorization approach on the covariance difference\nof embeddings that yields robust refusal vectors. This isolates the target\nconcept while minimizing collateral unlearning of other semantics, thus\npreserving the visual quality of the generated video. Our method preserves the\nmodel's generation quality while operating without retraining or access to the\noriginal training data. By embedding the refusal direction directly into the\nmodel's weights, the suppression mechanism becomes inherently more robust\nagainst adversarial bypass attempts compared to surface-level input-output\nfilters. In a thorough qualitative and quantitative evaluation, we show that we\ncan neutralize a variety of harmful contents, including explicit nudity,\ngraphic violence, copyrights, and trademarks. Project page:\nhttps://www.pinlab.org/video-unlearning.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07891v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07706", "title": "Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation", "authors": ["Boris Martirosyan", "Alexey Karmanov"], "summary": "Latent diffusion models (LDMs) achieve state-of-the-art performance across\nvarious tasks, including image generation and video synthesis. However, they\ngenerally lack robustness, a limitation that remains not fully explored in\ncurrent research. In this paper, we propose several methods to address this\ngap. First, we hypothesize that the robustness of LDMs primarily should be\nmeasured without their text encoder, because if we take and explore the whole\narchitecture, the problems of image generator and text encoders wll be fused.\nSecond, we introduce novel data augmentation techniques designed to reveal\nrobustness shortcomings in LDMs when processing diverse textual prompts. We\nthen fine-tune Stable Diffusion 3 and Stable Diffusion XL models using\nDreambooth, incorporating these proposed augmentation methods across multiple\ntasks. Finally, we propose a novel evaluation pipeline specifically tailored to\nassess the robustness of LDMs fine-tuned via Dreambooth.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07706v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07905", "title": "WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning", "authors": ["Jie Yang", "Feipeng Ma", "Zitian Wang", "Dacheng Yin", "Kang Rong", "Fengyun Rao", "Ruimao Zhang"], "summary": "Building on the success of text-based reasoning models like DeepSeek-R1,\nextending these capabilities to multimodal reasoning holds great promise. While\nrecent works have attempted to adapt DeepSeek-R1-style reinforcement learning\n(RL) training paradigms to multimodal large language models (MLLM), focusing on\ndomain-specific tasks like math and visual perception, a critical question\nremains: How can we achieve the general-purpose visual-language reasoning\nthrough RL? To address this challenge, we make three key efforts: (1) A novel\nScalable Multimodal QA Synthesis pipeline that autonomously generates\ncontext-aware, reasoning-centric question-answer (QA) pairs directly from the\ngiven images. (2) The open-source WeThink dataset containing over 120K\nmultimodal QA pairs with annotated reasoning paths, curated from 18 diverse\ndataset sources and covering various question domains. (3) A comprehensive\nexploration of RL on our dataset, incorporating a hybrid reward mechanism that\ncombines rule-based verification with model-based assessment to optimize RL\ntraining efficiency across various task domains. Across 14 diverse MLLM\nbenchmarks, we demonstrate that our WeThink dataset significantly enhances\nperformance, from mathematical reasoning to diverse general multimodal tasks.\nMoreover, we show that our automated data pipeline can continuously increase\ndata diversity to further improve model performance.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07905v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07735", "title": "Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning", "authors": ["Haizhao Jing", "Haokui Zhang", "Zhenhao Shang", "Rong Xiao", "Peng Wang", "Yanning Zhang"], "summary": "Neural Architecture Representation Learning aims to transform network models\ninto feature representations for predicting network attributes, playing a\ncrucial role in deploying and designing networks for real-world applications.\nRecently, inspired by the success of transformers, transformer-based models\nintegrated with Graph Neural Networks (GNNs) have achieved significant progress\nin representation learning. However, current methods still have some\nlimitations. First, existing methods overlook hardware attribute information,\nwhich conflicts with the current trend of diversified deep learning hardware\nand limits the practical applicability of models. Second, current encoding\napproaches rely on static adjacency matrices to represent topological\nstructures, failing to capture the structural differences between computational\nnodes, which ultimately compromises encoding effectiveness. In this paper, we\nintroduce LeDG-Former, an innovative framework that addresses these limitations\nthrough the synergistic integration of language-based semantic embedding and\ndynamic graph representation learning. Specifically, inspired by large language\nmodels (LLMs), we propose a language embedding framework where both neural\narchitectures and hardware platform specifications are projected into a unified\nsemantic space through tokenization and LLM processing, enabling zero-shot\nprediction across different hardware platforms for the first time. Then, we\npropose a dynamic graph-based transformer for modeling neural architectures,\nresulting in improved neural architecture modeling performance. On the NNLQP\nbenchmark, LeDG-Former surpasses previous methods, establishing a new SOTA\nwhile demonstrating the first successful cross-hardware latency prediction\ncapability. Furthermore, our framework achieves superior performance on the\ncell-structured NAS-Bench-101 and NAS-Bench-201 datasets.", "comment": "9 pages, 3 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07735v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07925", "title": "A Comparative Study of U-Net Architectures for Change Detection in Satellite Images", "authors": ["Yaxita Amin", "Naimisha S Trivedi", "Rashmi Bhattad"], "summary": "Remote sensing change detection is essential for monitoring the everchanging\nlandscapes of the Earth. The U-Net architecture has gained popularity for its\ncapability to capture spatial information and perform pixel-wise\nclassification. However, their application in the Remote sensing field remains\nlargely unexplored. Therefore, this paper fill the gap by conducting a\ncomprehensive analysis of 34 papers. This study conducts a comparison and\nanalysis of 18 different U-Net variations, assessing their potential for\ndetecting changes in remote sensing. We evaluate both benefits along with\ndrawbacks of each variation within the framework of this particular\napplication. We emphasize variations that are explicitly built for change\ndetection, such as Siamese Swin-U-Net, which utilizes a Siamese architecture.\nThe analysis highlights the significance of aspects such as managing data from\ndifferent time periods and collecting relationships over a long distance to\nenhance the precision of change detection. This study provides valuable\ninsights for researchers and practitioners that choose U-Net versions for\nremote sensing change detection tasks.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07925v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07936", "title": "Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models", "authors": ["Chengyue Huang", "Yuchen Zhu", "Sichen Zhu", "Jingyun Xiao", "Moises Andrade", "Shivang Chopra", "Zsolt Kira"], "summary": "Vision-language models (VLMs) are widely assumed to exhibit in-context\nlearning (ICL), a property similar to that of their language-only counterparts.\nWhile recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies\nshow they often rely on shallow heuristics -- such as copying or majority\nvoting -- rather than true task understanding. We revisit this assumption by\nevaluating VLMs under distribution shifts, where support examples come from a\ndataset different from the query. Surprisingly, performance often degrades with\nmore demonstrations, and models tend to copy answers rather than learn from\nthem. To investigate further, we propose a new MM-ICL with Reasoning pipeline\nthat augments each demonstration with a generated rationale alongside the\nanswer. We conduct extensive and comprehensive experiments on both perception-\nand reasoning-required datasets with open-source VLMs ranging from 3B to 72B\nand proprietary models such as Gemini 2.0. We conduct controlled studies\nvarying shot count, retrieval method, rationale quality, and distribution. Our\nresults show limited performance sensitivity across these factors, suggesting\nthat current VLMs do not effectively utilize demonstration-level information as\nintended in MM-ICL.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07936v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06657", "title": "Quantile Regression with Large Language Models for Price Prediction", "authors": ["Nikhita Vedula", "Dushyanta Dhyani", "Laleh Jalali", "Boris Oreshkin", "Mohsen Bayati", "Shervin Malmasi"], "summary": "Large Language Models (LLMs) have shown promise in structured prediction\ntasks, including regression, but existing approaches primarily focus on point\nestimates and lack systematic comparison across different methods. We\ninvestigate probabilistic regression using LLMs for unstructured inputs,\naddressing challenging text-to-distribution prediction tasks such as price\nestimation where both nuanced text understanding and uncertainty quantification\nare critical. We propose a novel quantile regression approach that enables LLMs\nto produce full predictive distributions, improving upon traditional point\nestimates. Through extensive experiments across three diverse price prediction\ndatasets, we demonstrate that a Mistral-7B model fine-tuned with quantile heads\nsignificantly outperforms traditional approaches for both point and\ndistributional estimations, as measured by three established metrics each for\nprediction accuracy and distributional calibration. Our systematic comparison\nof LLM approaches, model architectures, training approaches, and data scaling\nreveals that Mistral-7B consistently outperforms encoder architectures,\nembedding-based methods, and few-shot learning methods. Our experiments also\nreveal the effectiveness of LLM-assisted label correction in achieving\nhuman-level accuracy without systematic bias. Our curated datasets are made\navailable at https://github.com/vnik18/llm-price-quantile-reg/ to support\nfuture research.", "comment": "Accepted to Findings of ACL, 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06657v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07747", "title": "E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time", "authors": ["Adam Breuer"], "summary": "In this paper, we provide the first practical algorithms with provable\nguarantees for the problem of inferring the topics assigned to each document in\nan LDA topic model. This is the primary inference problem for many applications\nof topic models in social science, data exploration, and causal inference\nsettings. We obtain this result by showing a novel non-gradient-based,\ncombinatorial approach to estimating topic models. This yields algorithms that\nconverge to near-optimal posterior probability in logarithmic parallel\ncomputation time (adaptivity) -- exponentially faster than any known LDA\nalgorithm. We also show that our approach can provide interpretability\nguarantees such that each learned topic is formally associated with a known\nkeyword. Finally, we show that unlike alternatives, our approach can maintain\nthe independence assumptions necessary to use the learned topic model for\ndownstream causal inference methods that allow researchers to study topics as\ntreatments. In terms of practical performance, our approach consistently\nreturns solutions of higher semantic quality than solutions from\nstate-of-the-art LDA algorithms, neural topic models, and LLM-based topic\nmodels across a diverse range of text datasets and evaluation parameters.", "comment": "ICML 2025; Code available at: https://github.com/BreuerLabs/E- LDA", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07747v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07943", "title": "Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations", "authors": ["Yizhen Li", "Dell Zhang", "Xuelong Li", "Yiqing Shen"], "summary": "Reasoning Segmentation (RS) is a multimodal vision-text task that requires\nsegmenting objects based on implicit text queries, demanding both precise\nvisual perception and vision-text reasoning capabilities. Current RS approaches\nrely on fine-tuning vision-language models (VLMs) for both perception and\nreasoning, but their tokenization of images fundamentally disrupts continuous\nspatial relationships between objects. We introduce DTwinSeger, a novel RS\napproach that leverages Digital Twin (DT) representation as an intermediate\nlayer to decouple perception from reasoning. Innovatively, DTwinSeger\nreformulates RS as a two-stage process, where the first transforms the image\ninto a structured DT representation that preserves spatial relationships and\nsemantic properties and then employs a Large Language Model (LLM) to perform\nexplicit reasoning over this representation to identify target objects. We\npropose a supervised fine-tuning method specifically for LLM with DT\nrepresentation, together with a corresponding fine-tuning dataset Seg-DT, to\nenhance the LLM's reasoning capabilities with DT representations. Experiments\nshow that our method can achieve state-of-the-art performance on two image RS\nbenchmarks and three image referring segmentation benchmarks. It yields that DT\nrepresentation functions as an effective bridge between vision and text,\nenabling complex multimodal reasoning tasks to be accomplished solely with an\nLLM.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07943v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07754", "title": "Comparing Credit Risk Estimates in the Gen-AI Era", "authors": ["Nicola Lavecchia", "Sid Fadanelli", "Federico Ricciuti", "Gennaro Aloe", "Enrico Bagli", "Pietro Giuffrida", "Daniele Vergari"], "summary": "Generative AI technologies have demonstrated significant potential across\ndiverse applications. This study provides a comparative analysis of credit\nscore modeling techniques, contrasting traditional approaches with those\nleveraging generative AI. Our findings reveal that current generative AI models\nfall short of matching the performance of traditional methods, regardless of\nthe integration strategy employed. These results highlight the limitations in\nthe current capabilities of generative AI for credit risk scoring, emphasizing\nthe need for further research and development before the possibility of\napplying generative AI for this specific task, or equivalent ones.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07754v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07960", "title": "Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920", "authors": ["Ari Vesalainen", "Jenna Kanerva", "Aida Nitsch", "Kiia Korsu", "Ilari Larkiola", "Laura Ruotsalainen", "Filip Ginter"], "summary": "This article presents a large-scale effort to create a structured dataset of\ninternal migration in Finland between 1800 and 1920 using digitized church\nmoving records. These records, maintained by Evangelical-Lutheran parishes,\ndocument the migration of individuals and families and offer a valuable source\nfor studying historical demographic patterns. The dataset includes over six\nmillion entries extracted from approximately 200,000 images of handwritten\nmigration records.\n  The data extraction process was automated using a deep learning pipeline that\nincluded layout analysis, table detection, cell classification, and handwriting\nrecognition. The complete pipeline was applied to all images, resulting in a\nstructured dataset suitable for research.\n  The dataset can be used to study internal migration, urbanization, and family\nmigration, and the spread of disease in preindustrial Finland. A case study\nfrom the Elim\\\"aki parish shows how local migration histories can be\nreconstructed. The work demonstrates how large volumes of handwritten archival\nmaterial can be transformed into structured data to support historical and\ndemographic research.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07960v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07769", "title": "Clustered Federated Learning via Embedding Distributions", "authors": ["Dekai Zhang", "Matthew Williams", "Francesca Toni"], "summary": "Federated learning (FL) is a widely used framework for machine learning in\ndistributed data environments where clients hold data that cannot be easily\ncentralised, such as for data protection reasons. FL, however, is known to be\nvulnerable to non-IID data. Clustered FL addresses this issue by finding more\nhomogeneous clusters of clients. We propose a novel one-shot clustering method,\nEMD-CFL, using the Earth Mover's distance (EMD) between data distributions in\nembedding space. We theoretically motivate the use of EMDs using results from\nthe domain adaptation literature and demonstrate empirically superior\nclustering performance in extensive comparisons against 16 baselines and on a\nrange of challenging datasets.", "comment": "24 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07769v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07964", "title": "SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design", "authors": ["Wenxin Tang", "Jingyu Xiao", "Wenxuan Jiang", "Xi Xiao", "Yuhang Wang", "Xuxin Tang", "Qing Li", "Yuehe Ma", "Junliang Liu", "Shisong Tang", "Michael R. Lyu"], "summary": "Manual slide creation is labor-intensive and requires expert prior knowledge.\nExisting natural language-based LLM generation methods struggle to capture the\nvisual and structural nuances of slide designs. To address this, we formalize\nthe Reference Image to Slide Generation task and propose Slide2Code, the first\nbenchmark with difficulty-tiered samples based on a novel Slide Complexity\nMetric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework\nfor generating editable slides from reference images. SlideCoder integrates a\nColor Gradient-based Segmentation algorithm and a Hierarchical\nRetrieval-Augmented Generation method to decompose complex tasks and enhance\ncode generation. We also release SlideMaster, a 7B open-source model fine-tuned\nwith improved reverse-engineered data. Experiments show that SlideCoder\noutperforms state-of-the-art baselines by up to 40.5 points, demonstrating\nstrong performance across layout fidelity, execution accuracy, and visual\nconsistency. Our code is available at\nhttps://github.com/vinsontang1/SlideCoder.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07964v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07804", "title": "Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability", "authors": ["Jie Bao", "Chuangyin Dang", "Rui Luo", "Hanwei Zhang", "Zhixin Zhou"], "summary": "As deep learning models are increasingly deployed in high-risk applications,\nrobust defenses against adversarial attacks and reliable performance guarantees\nbecome paramount. Moreover, accuracy alone does not provide sufficient\nassurance or reliable uncertainty estimates for these models. This study\nadvances adversarial training by leveraging principles from Conformal\nPrediction. Specifically, we develop an adversarial attack method, termed OPSA\n(OPtimal Size Attack), designed to reduce the efficiency of conformal\nprediction at any significance level by maximizing model uncertainty without\nrequiring coverage guarantees. Correspondingly, we introduce OPSA-AT\n(Adversarial Training), a defense strategy that integrates OPSA within a novel\nconformal training paradigm. Experimental evaluations demonstrate that our OPSA\nattack method induces greater uncertainty compared to baseline approaches for\nvarious defenses. Conversely, our OPSA-AT defensive model significantly\nenhances robustness not only against OPSA but also other adversarial attacks,\nand maintains reliable prediction. Our findings highlight the effectiveness of\nthis integrated approach for developing trustworthy and resilient deep learning\nmodels for safety-critical domains. Our code is available at\nhttps://github.com/bjbbbb/Enhancing-Adversarial-Robustness-with-Conformal-Prediction.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07804v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07966", "title": "SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence", "authors": ["Ziyang Gong", "Wenhao Li", "Oliver Ma", "Songyuan Li", "Jiayi Ji", "Xue Yang", "Gen Luo", "Junchi Yan", "Rongrong Ji"], "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable progress in\nvarious multimodal tasks. To pursue higher intelligence in space, MLLMs require\nintegrating multiple atomic spatial capabilities to handle complex and dynamic\ntasks. However, existing benchmarks struggle to comprehensively evaluate the\nspatial intelligence of common MLLMs from the atomic level to the compositional\nlevel. To fill this gap, we present SpaCE-10, a comprehensive benchmark for\ncompositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial\ncapabilities, which are combined to form 8 compositional capabilities. Based on\nthese definitions, we propose a novel hierarchical annotation pipeline to\ngenerate high-quality and diverse question-answer (QA) pairs. With over 150+\nhours of human expert effort, we obtain over 5k QA pairs for 811 real indoor\nscenes in SpaCE-10, which covers various evaluation settings like point cloud\ninput and multi-choice QA. We conduct an extensive evaluation of common MLLMs\non SpaCE-10 and find that even the most advanced MLLM still lags behind humans\nby large margins. Through our careful study, we also draw several significant\nfindings that benefit the MLLM community. For example, we reveal that the\nshortcoming of counting capability greatly limits the compositional spatial\ncapabilities of existing MLLMs. The evaluation code and benchmark datasets are\navailable at https://github.com/Cuzyoung/SpaCE-10.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07966v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07806", "title": "Identifiable Object Representations under Spatial Ambiguities", "authors": ["Avinash Kori", "Francesca Toni", "Ben Glocker"], "summary": "Modular object-centric representations are essential for *human-like\nreasoning* but are challenging to obtain under spatial ambiguities, *e.g. due\nto occlusions and view ambiguities*. However, addressing challenges presents\nboth theoretical and practical difficulties. We introduce a novel multi-view\nprobabilistic approach that aggregates view-specific slots to capture\n*invariant content* information while simultaneously learning disentangled\nglobal *viewpoint-level* information. Unlike prior single-view methods, our\napproach resolves spatial ambiguities, provides theoretical guarantees for\nidentifiability, and requires *no viewpoint annotations*. Extensive experiments\non standard benchmarks and novel complex datasets validate our method's\nrobustness and scalability.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07806v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07971", "title": "CyberV: Cybernetics for Test-time Scaling in Video Understanding", "authors": ["Jiahao Meng", "Shuyang Sun", "Yue Tan", "Lu Qi", "Yunhai Tong", "Xiangtai Li", "Longyin Wen"], "summary": "Current Multimodal Large Language Models (MLLMs) may struggle with\nunderstanding long or complex videos due to computational demands at test time,\nlack of robustness, and limited accuracy, primarily stemming from their\nfeed-forward processing nature. These limitations could be more severe for\nmodels with fewer parameters. To address these limitations, we propose a novel\nframework inspired by cybernetic principles, redesigning video MLLMs as\nadaptive systems capable of self-monitoring, self-correction, and dynamic\nresource allocation during inference. Our approach, CyberV, introduces a\ncybernetic loop consisting of an MLLM Inference System, a Sensor, and a\nController. Specifically, the sensor monitors forward processes of the MLLM and\ncollects intermediate interpretations, such as attention drift, then the\ncontroller determines when and how to trigger self-correction and generate\nfeedback to guide the next round. This test-time adaptive scaling framework\nenhances frozen MLLMs without requiring retraining or additional components.\nExperiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7B\nby 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitive\nproprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%\nimprovement, achieving performance even comparable to human experts.\nFurthermore, our method demonstrates consistent gains on general-purpose\nbenchmarks, such as VideoMME and WorldSense, highlighting its effectiveness and\ngeneralization capabilities in making MLLMs more robust and accurate for\ndynamic video understanding. The code is released at\nhttps://github.com/marinero4972/CyberV.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07971v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07822", "title": "Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation", "authors": ["Xintong Duan", "Yutong He", "Fahim Tajwar", "Ruslan Salakhutdinov", "J. Zico Kolter", "Jeff Schneider"], "summary": "Although diffusion models have achieved strong results in decision-making\ntasks, their slow inference speed remains a key limitation. While the\nconsistency model offers a potential solution, its applications to\ndecision-making often struggle with suboptimal demonstrations or rely on\ncomplex concurrent training of multiple networks. In this work, we propose a\nnovel approach to consistency distillation for offline reinforcement learning\nthat directly incorporates reward optimization into the distillation process.\nOur method enables single-step generation while maintaining higher performance\nand simpler training. Empirical evaluations on the Gym MuJoCo benchmarks and\nlong horizon planning demonstrate that our approach can achieve an 8.7%\nimprovement over previous state-of-the-art while offering up to 142x speedup\nover diffusion counterparts in inference time.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07822v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06609", "title": "Transferring Features Across Language Models With Model Stitching", "authors": ["Alan Chen", "Jack Merullo", "Alessandro Stolfo", "Ellie Pavlick"], "summary": "In this work, we demonstrate that affine mappings between residual streams of\nlanguage models is a cheap way to effectively transfer represented features\nbetween models. We apply this technique to transfer the weights of Sparse\nAutoencoders (SAEs) between models of different sizes to compare their\nrepresentations. We find that small and large models learn highly similar\nrepresentation spaces, which motivates training expensive components like SAEs\non a smaller model and transferring to a larger model at a FLOPs savings. For\nexample, using a small-to-large transferred SAE as initialization can lead to\n50% cheaper training runs when training SAEs on larger models. Next, we show\nthat transferred probes and steering vectors can effectively recover ground\ntruth performance. Finally, we dive deeper into feature-level transferability,\nfinding that semantic and structural features transfer noticeably differently\nwhile specific classes of functional features have their roles faithfully\nmapped. Overall, our findings illustrate similarities and differences in the\nlinear representation spaces of small and large models and demonstrate a method\nfor improving the training efficiency of SAEs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06609v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07977", "title": "OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation", "authors": ["Jingjing Chang", "Yixiao Fang", "Peng Xing", "Shuhan Wu", "Wei Cheng", "Rui Wang", "Xianfang Zeng", "Gang Yu", "Hai-Bao Chen"], "summary": "Text-to-image (T2I) models have garnered significant attention for generating\nhigh-quality images aligned with text prompts. However, rapid T2I model\nadvancements reveal limitations in early benchmarks, lacking comprehensive\nevaluations, for example, the evaluation on reasoning, text rendering and\nstyle. Notably, recent state-of-the-art models, with their rich knowledge\nmodeling capabilities, show promising results on the image generation problems\nrequiring strong reasoning ability, yet existing evaluation systems have not\nadequately addressed this frontier. To systematically address these gaps, we\nintroduce OneIG-Bench, a meticulously designed comprehensive benchmark\nframework for fine-grained evaluation of T2I models across multiple dimensions,\nincluding prompt-image alignment, text rendering precision, reasoning-generated\ncontent, stylization, and diversity. By structuring the evaluation, this\nbenchmark enables in-depth analysis of model performance, helping researchers\nand practitioners pinpoint strengths and bottlenecks in the full pipeline of\nimage generation. Specifically, OneIG-Bench enables flexible evaluation by\nallowing users to focus on a particular evaluation subset. Instead of\ngenerating images for the entire set of prompts, users can generate images only\nfor the prompts associated with the selected dimension and complete the\ncorresponding evaluation accordingly. Our codebase and dataset are now publicly\navailable to facilitate reproducible evaluation studies and cross-model\ncomparisons within the T2I research community.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07977v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07829", "title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information", "authors": ["Jan Corazza", "Hadi Partovi Aria", "Hyohun Kim", "Daniel Neider", "Zhe Xu"], "summary": "Reinforcement learning (RL) algorithms can find an optimal policy for a\nsingle agent to accomplish a particular task. However, many real-world problems\nrequire multiple agents to collaborate in order to achieve a common goal. For\nexample, a robot executing a task in a warehouse may require the assistance of\na drone to retrieve items from high shelves. In Decentralized Multi-Agent RL\n(DMARL), agents learn independently and then combine their policies at\nexecution time, but often must satisfy constraints on compatibility of local\npolicies to ensure that they can achieve the global task when combined. In this\npaper, we study how providing high-level symbolic knowledge to agents can help\naddress unique challenges of this setting, such as privacy constraints,\ncommunication limitations, and performance concerns. In particular, we extend\nthe formal tools used to check the compatibility of local policies with the\nteam task, making decentralized training with theoretical guarantees usable in\nmore scenarios. Furthermore, we empirically demonstrate that symbolic knowledge\nabout the temporal evolution of events in the environment can significantly\nexpedite the learning process in DMARL.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07829v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07981", "title": "Real-time Localization of a Soccer Ball from a Single Camera", "authors": ["Dmitrii Vorobev", "Artem Prosvetov", "Karim Elhadji Daou"], "summary": "We propose a computationally efficient method for real-time three-dimensional\nfootball trajectory reconstruction from a single broadcast camera. In contrast\nto previous work, our approach introduces a multi-mode state model with $W$\ndiscrete modes to significantly accelerate optimization while preserving\ncentimeter-level accuracy -- even in cases of severe occlusion, motion blur,\nand complex backgrounds. The system operates on standard CPUs and achieves low\nlatency suitable for live broadcast settings. Extensive evaluation on a\nproprietary dataset of 6K-resolution Russian Premier League matches\ndemonstrates performance comparable to multi-camera systems, without the need\nfor specialized or costly infrastructure. This work provides a practical method\nfor accessible and accurate 3D ball tracking in professional football\nenvironments.", "comment": "13 pages, 4 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07981v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06705", "title": "DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains", "authors": ["Zhihui Chen", "Kai He", "Yucheng Huang", "Yunxiao Zhu", "Mengling Feng"], "summary": "Detecting LLM-generated text in specialized and high-stakes domains like\nmedicine and law is crucial for combating misinformation and ensuring\nauthenticity. However, current zero-shot detectors, while effective on general\ntext, often fail when applied to specialized content due to domain shift. We\nprovide a theoretical analysis showing this failure is fundamentally linked to\nthe KL divergence between human, detector, and source text distributions. To\naddress this, we propose DivScore, a zero-shot detection framework using\nnormalized entropy-based scoring and domain knowledge distillation to robustly\nidentify LLM-generated text in specialized domains. We also release a\ndomain-specific benchmark for LLM-generated text detection in the medical and\nlegal domains. Experiments on our benchmark show that DivScore consistently\noutperforms state-of-the-art detectors, with 14.4% higher AUROC and 64.0%\nhigher recall (0.1% false positive rate threshold). In adversarial settings,\nDivScore demonstrates superior robustness than other baselines, achieving on\naverage 22.8% advantage in AUROC and 29.5% in recall. Code and data are\npublicly available.", "comment": "Zhihui Chen and Kai He contributed equally to this work, Mengling\n  Feng is the corresponding author", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06705v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07833", "title": "Improving large language models with concept-aware fine-tuning", "authors": ["Michael K. Chen", "Xikun Zhang", "Jiaxing Huang", "Dacheng Tao"], "summary": "Large language models (LLMs) have become the cornerstone of modern AI.\nHowever, the existing paradigm of next-token prediction fundamentally limits\ntheir ability to form coherent, high-level concepts, making it a critical\nbarrier to human-like understanding and reasoning. Take the phrase \"ribonucleic\nacid\" as an example: an LLM will first decompose it into tokens, i.e.,\nartificial text fragments (\"rib\", \"on\", ...), then learn each token\nsequentially, rather than grasping the phrase as a unified, coherent semantic\nentity. This fragmented representation hinders deeper conceptual understanding\nand, ultimately, the development of truly intelligent systems. In response, we\nintroduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method\nthat redefines how LLMs are fine-tuned. By enabling the learning of sequences\nthat span multiple tokens, this method fosters stronger concept-aware learning.\nOur experiments demonstrate significant improvements compared to conventional\nnext-token finetuning methods across diverse tasks, including traditional\napplications like text summarization and domain-specific ones like de novo\nprotein design. Multi-token prediction was previously only possible in the\nprohibitively expensive pretraining phase; CAFT, to our knowledge, is the first\nto bring the multi-token setting to the post-training phase, thus effectively\ndemocratizing its benefits for the broader community of practitioners and\nresearchers. Finally, the unexpected effectiveness of our proposed method\nsuggests wider implications for the machine learning research community. All\ncode and data are available at https://github.com/michaelchen-lab/caft-llm", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07833v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06616", "title": "Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings", "authors": ["Samuel Kim", "Oghenemaro Imieye", "Yunting Yin"], "summary": "Accurate and interpretable detection of depressive language in social media\nis useful for early interventions of mental health conditions, and has\nimportant implications for both clinical practice and broader public health\nefforts. In this paper, we investigate the performance of large language models\n(LLMs) and traditional machine learning classifiers across three classification\ntasks involving social media data: binary depression classification, depression\nseverity classification, and differential diagnosis classification among\ndepression, PTSD, and anxiety. Our study compares zero-shot LLMs with\nsupervised classifiers trained on both conventional text embeddings and\nLLM-generated summary embeddings. Our experiments reveal that while zero-shot\nLLMs demonstrate strong generalization capabilities in binary classification,\nthey struggle with fine-grained ordinal classifications. In contrast,\nclassifiers trained on summary embeddings generated by LLMs demonstrate\ncompetitive, and in some cases superior, performance on the classification\ntasks, particularly when compared to models using traditional text embeddings.\nOur findings demonstrate the strengths of LLMs in mental health prediction, and\nsuggest promising directions for better utilization of their zero-shot\ncapabilities and context-aware summarization techniques.", "comment": "Submitted to the IEEE EMBS BHI 2025 Conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06616v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07984", "title": "CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray", "authors": ["Mingquan Lin", "Gregory Holste", "Song Wang", "Yiliang Zhou", "Yishu Wei", "Imon Banerjee", "Pengyi Chen", "Tianjie Dai", "Yuexi Du", "Nicha C. Dvornek", "Yuyan Ge", "Zuowei Guo", "Shouhei Hanaoka", "Dongkyun Kim", "Pablo Messina", "Yang Lu", "Denis Parra", "Donghyun Son", "Álvaro Soto", "Aisha Urooj", "René Vidal", "Yosuke Yamagishi", "Zefan Yang", "Ruichi Zhang", "Yang Zhou", "Leo Anthony Celi", "Ronald M. Summers", "Zhiyong Lu", "Hao Chen", "Adam Flanders", "George Shih", "Zhangyang Wang", "Yifan Peng"], "summary": "The CXR-LT series is a community-driven initiative designed to enhance lung\ndisease classification using chest X-rays (CXR). It tackles challenges in open\nlong-tailed lung disease classification and enhances the measurability of\nstate-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve\nthese goals by providing high-quality benchmark CXR data for model development\nand conducting comprehensive evaluations to identify ongoing issues impacting\nlung disease classification performance. Building on the success of CXR-LT\n2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45\ndisease labels, including 19 new rare disease findings. It also introduces a\nnew focus on zero-shot learning to address limitations identified in the\nprevious event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed\nclassification on a large, noisy test set, (ii) long-tailed classification on a\nmanually annotated \"gold standard\" subset, and (iii) zero-shot generalization\nto five previously unseen disease findings. This paper provides an overview of\nCXR-LT 2024, detailing the data curation process and consolidating\nstate-of-the-art solutions, including the use of multimodal models for rare\ndisease detection, advanced generative approaches to handle noisy labels, and\nzero-shot learning strategies for unseen diseases. Additionally, the expanded\ndataset enhances disease coverage to better represent real-world clinical\nsettings, offering a valuable resource for future research. By synthesizing the\ninsights and innovations of participating teams, we aim to advance the\ndevelopment of clinically realistic and generalizable diagnostic models for\nchest radiography.", "comment": "17 pages, 3 figures", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07984v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07843", "title": "Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels", "authors": ["Davide Carbone"], "summary": "Energy-Based Models (EBMs) provide a flexible framework for generative\nmodeling, but their training remains theoretically challenging due to the need\nto approximate normalization constants and efficiently sample from complex,\nmulti-modal distributions. Traditional methods, such as contrastive divergence\nand score matching, introduce biases that can hinder accurate learning. In this\nwork, we present a theoretical analysis of Jarzynski reweighting, a technique\nfrom non-equilibrium statistical mechanics, and its implications for training\nEBMs. We focus on the role of the choice of the kernel and we illustrate these\ntheoretical considerations in two key generative frameworks: (i) flow-based\ndiffusion models, where we reinterpret Jarzynski reweighting in the context of\nstochastic interpolants to mitigate discretization errors and improve sample\nquality, and (ii) Restricted Boltzmann Machines, where we analyze its role in\ncorrecting the biases of contrastive divergence. Our results provide insights\ninto the interplay between kernel choice and model performance, highlighting\nthe potential of Jarzynski reweighting as a principled tool for generative\nlearning.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07843v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06619", "title": "BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs", "authors": ["Jesse Woo", "Fateme Hashemi Chaleshtori", "Ana Marasović", "Kenneth Marino"], "summary": "A core part of legal work that has been under-explored in Legal NLP is the\nwriting and editing of legal briefs. This requires not only a thorough\nunderstanding of the law of a jurisdiction, from judgments to statutes, but\nalso the ability to make new arguments to try to expand the law in a new\ndirection and make novel and creative arguments that are persuasive to judges.\nTo capture and evaluate these legal skills in language models, we introduce\nBRIEFME, a new dataset focused on legal briefs. It contains three tasks for\nlanguage models to assist legal professionals in writing briefs: argument\nsummarization, argument completion, and case retrieval. In this work, we\ndescribe the creation of these tasks, analyze them, and show how current models\nperform. We see that today's large language models (LLMs) are already quite\ngood at the summarization and guided completion tasks, even beating\nhuman-generated headings. Yet, they perform poorly on other tasks in our\nbenchmark: realistic argument completion and retrieving relevant legal cases.\nWe hope this dataset encourages more development in Legal NLP in ways that will\nspecifically aid people in performing legal work.", "comment": "ACL Findings 2025; 10 pages main, 5 pages references, 37 pages\n  appendix", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06619v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07985", "title": "Rethinking Crowd-Sourced Evaluation of Neuron Explanations", "authors": ["Tuomas Oikarinen", "Ge Yan", "Akshay Kulkarni", "Tsui-Wei Weng"], "summary": "Interpreting individual neurons or directions in activations space is an\nimportant component of mechanistic interpretability. As such, many algorithms\nhave been proposed to automatically produce neuron explanations, but it is\noften not clear how reliable these explanations are, or which methods produce\nthe best explanations. This can be measured via crowd-sourced evaluations, but\nthey can often be noisy and expensive, leading to unreliable results. In this\npaper, we carefully analyze the evaluation pipeline and develop a\ncost-effective and highly accurate crowdsourced evaluation strategy. In\ncontrast to previous human studies that only rate whether the explanation\nmatches the most highly activating inputs, we estimate whether the explanation\ndescribes neuron activations across all inputs. To estimate this effectively,\nwe introduce a novel application of importance sampling to determine which\ninputs are the most valuable to show to raters, leading to around 30x cost\nreduction compared to uniform sampling. We also analyze the label noise present\nin crowd-sourced evaluations and propose a Bayesian method to aggregate\nmultiple ratings leading to a further ~5x reduction in number of ratings\nrequired for the same accuracy. Finally, we use these methods to conduct a\nlarge-scale study comparing the quality of neuron explanations produced by the\nmost popular methods for two different vision models.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07985v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07854", "title": "Residual Reweighted Conformal Prediction for Graph Neural Networks", "authors": ["Zheng Zhang", "Jie Bao", "Zhixin Zhou", "Nicolo Colombo", "Lixin Cheng", "Rui Luo"], "summary": "Graph Neural Networks (GNNs) excel at modeling relational data but face\nsignificant challenges in high-stakes domains due to unquantified uncertainty.\nConformal prediction (CP) offers statistical coverage guarantees, but existing\nmethods often produce overly conservative prediction intervals that fail to\naccount for graph heteroscedasticity and structural biases. While residual\nreweighting CP variants address some of these limitations, they neglect graph\ntopology, cluster-specific uncertainties, and risk data leakage by reusing\ntraining sets. To address these issues, we propose Residual Reweighted GNN\n(RR-GNN), a framework designed to generate minimal prediction sets with\nprovable marginal coverage guarantees.\n  RR-GNN introduces three major innovations to enhance prediction performance.\nFirst, it employs Graph-Structured Mondrian CP to partition nodes or edges into\ncommunities based on topological features, ensuring cluster-conditional\ncoverage that reflects heterogeneity. Second, it uses Residual-Adaptive\nNonconformity Scores by training a secondary GNN on a held-out calibration set\nto estimate task-specific residuals, dynamically adjusting prediction intervals\naccording to node or edge uncertainty. Third, it adopts a Cross-Training\nProtocol, which alternates the optimization of the primary GNN and the residual\npredictor to prevent information leakage while maintaining graph dependencies.\nWe validate RR-GNN on 15 real-world graphs across diverse tasks, including node\nclassification, regression, and edge weight prediction. Compared to CP\nbaselines, RR-GNN achieves improved efficiency over state-of-the-art methods,\nwith no loss of coverage.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07854v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06620", "title": "Computationally Efficient Analytical Models of Frequency and Voltage in Low-Inertia Systems", "authors": ["Marena Trujillo", "Amir Sajadi", "Jonathan Shaw", "Bri-Mathias Hodge"], "summary": "In this paper, low-order models of the frequency and voltage response of\nmixed-generation, low-inertia systems are presented. These models are unique in\ntheir ability to efficiently and accurately model frequency and voltage\ndynamics without increasing the computational burden as the share of inverters\nis increased in a system. The models are validated against industry-grade\nelectromagnetic transient simulation, compared to which the proposed models are\nseveral orders of magnitude faster. The accuracy and efficiency of the\nlow-inertia frequency and voltage models makes them well suited for a variety\nof planning and operational studies, especially for multi-scenario and\nprobabilistic studies, as well as for screening studies to establish impact\nzones based on the dynamic interactions between inverters and synchronous\ngenerators.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06620v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07986", "title": "Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers", "authors": ["Zhengyao Lv", "Tianlin Pan", "Chenyang Si", "Zhaoxi Chen", "Wangmeng Zuo", "Ziwei Liu", "Kwan-Yee K. Wong"], "summary": "Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress\nin text-driven visual generation. However, even state-of-the-art MM-DiT models\nlike FLUX struggle with achieving precise alignment between text prompts and\ngenerated content. We identify two key issues in the attention mechanism of\nMM-DiT, namely 1) the suppression of cross-modal attention due to token\nimbalance between visual and textual modalities and 2) the lack of\ntimestep-aware attention weighting, which hinder the alignment. To address\nthese issues, we propose \\textbf{Temperature-Adjusted Cross-modal Attention\n(TACA)}, a parameter-efficient method that dynamically rebalances multimodal\ninteractions through temperature scaling and timestep-dependent adjustment.\nWhen combined with LoRA fine-tuning, TACA significantly enhances text-image\nalignment on the T2I-CompBench benchmark with minimal computational overhead.\nWe tested TACA on state-of-the-art models like FLUX and SD3.5, demonstrating\nits ability to improve image-text alignment in terms of object appearance,\nattribute binding, and spatial relationships. Our findings highlight the\nimportance of balancing cross-modal attention in improving semantic fidelity in\ntext-to-image diffusion models. Our codes are publicly available at\n\\href{https://github.com/Vchitect/TACA}", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07986v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06732", "title": "Neural Spectral Band Generation for Audio Coding", "authors": ["Woongjib Choi", "Byeong Hyeon Kim", "Hyungseob Lim", "Inseon Jang", "Hong-Goo Kang"], "summary": "Audio bandwidth extension is the task of reconstructing missing high\nfrequency components of bandwidth-limited audio signals, where bandwidth\nlimitation is a common issue for audio signals due to several reasons,\nincluding channel capacity and data constraints. While conventional spectral\nband replication is a well-established parametric approach to audio bandwidth\nextension, the SBR usually entails coarse feature extraction and reconstruction\ntechniques, which leads to limitations when processing various types of audio\nsignals. In parallel, numerous deep neural network-based audio bandwidth\nextension methods have been proposed. These DNN-based methods are usually\nreferred to as blind BWE, as these methods do not rely on prior information\nextracted from original signals, and only utilize given low frequency band\nsignals to estimate missing high frequency components. In order to replace\nconventional SBR with DNNs, simply adopting existing DNN-based methodologies\nresults in suboptimal performance due to the blindness of these methods. My\nproposed research suggests a new approach to parametric non-blind bandwidth\nextension, as DNN-based side information extraction and DNN-based bandwidth\nextension are performed only at the front and end of the audio coding pipeline.", "comment": "Accepted to Interspeech 2025", "cate": "eess.AS", "url": "http://arxiv.org/abs/2506.06732v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07992", "title": "PairEdit: Learning Semantic Variations for Exemplar-based Image Editing", "authors": ["Haoguang Lu", "Jiacheng Chen", "Zhenguo Yang", "Aurele Tohokantche Gnanha", "Fu Lee Wang", "Li Qing", "Xudong Mao"], "summary": "Recent advancements in text-guided image editing have achieved notable\nsuccess by leveraging natural language prompts for fine-grained semantic\ncontrol. However, certain editing semantics are challenging to specify\nprecisely using textual descriptions alone. A practical alternative involves\nlearning editing semantics from paired source-target examples. Existing\nexemplar-based editing methods still rely on text prompts describing the change\nwithin paired examples or learning implicit text-based editing instructions. In\nthis paper, we introduce PairEdit, a novel visual editing method designed to\neffectively learn complex editing semantics from a limited number of image\npairs or even a single image pair, without using any textual guidance. We\npropose a target noise prediction that explicitly models semantic variations\nwithin paired images through a guidance direction term. Moreover, we introduce\na content-preserving noise schedule to facilitate more effective semantic\nlearning. We also propose optimizing distinct LoRAs to disentangle the learning\nof semantic variations from content. Extensive qualitative and quantitative\nevaluations demonstrate that PairEdit successfully learns intricate semantics\nwhile significantly improving content consistency compared to baseline methods.\nCode will be available at https://github.com/xudonmao/PairEdit.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07992v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07864", "title": "Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes", "authors": ["Mirko Paolo Barbato", "Giorgia Rigamonti", "Davide Marelli", "Paolo Napoletano"], "summary": "Type 1 Diabetes (T1D) affects millions worldwide, requiring continuous\nmonitoring to prevent severe hypo- and hyperglycemic events. While continuous\nglucose monitoring has improved blood glucose management, deploying predictive\nmodels on wearable devices remains challenging due to computational and memory\nconstraints. To address this, we propose a novel Lightweight Sequential\nTransformer model designed for blood glucose prediction in T1D. By integrating\nthe strengths of Transformers' attention mechanisms and the sequential\nprocessing of recurrent neural networks, our architecture captures long-term\ndependencies while maintaining computational efficiency. The model is optimized\nfor deployment on resource-constrained edge devices and incorporates a balanced\nloss function to handle the inherent data imbalance in hypo- and hyperglycemic\nevents. Experiments on two benchmark datasets, OhioT1DM and DiaTrend,\ndemonstrate that the proposed model outperforms state-of-the-art methods in\npredicting glucose levels and detecting adverse events. This work fills the gap\nbetween high-performance modeling and practical deployment, providing a\nreliable and efficient T1D management solution.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07864v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06737", "title": "C-PATH: Conversational Patient Assistance and Triage in Healthcare System", "authors": ["Qi Shi", "Qiwei Han", "Cláudia Soares"], "summary": "Navigating healthcare systems can be complex and overwhelming, creating\nbarriers for patients seeking timely and appropriate medical attention. In this\npaper, we introduce C-PATH (Conversational Patient Assistance and Triage in\nHealthcare), a novel conversational AI system powered by large language models\n(LLMs) designed to assist patients in recognizing symptoms and recommending\nappropriate medical departments through natural, multi-turn dialogues. C-PATH\nis fine-tuned on medical knowledge, dialogue data, and clinical summaries using\na multi-stage pipeline built on the LLaMA3 architecture. A core contribution of\nthis work is a GPT-based data augmentation framework that transforms structured\nclinical knowledge from DDXPlus into lay-person-friendly conversations,\nallowing alignment with patient communication norms. We also implement a\nscalable conversation history management strategy to ensure long-range\ncoherence. Evaluation with GPTScore demonstrates strong performance across\ndimensions such as clarity, informativeness, and recommendation accuracy.\nQuantitative benchmarks show that C-PATH achieves superior performance in\nGPT-rewritten conversational datasets, significantly outperforming\ndomain-specific baselines. C-PATH represents a step forward in the development\nof user-centric, accessible, and accurate AI tools for digital health\nassistance and triage.", "comment": "Accepted in IEEE ICDH 2025, 10 pages, 8 figures, 5 tables", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06737v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06626", "title": "Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations", "authors": ["Junzhe Wang", "Bichen Wang", "Xing Fu", "Yixin Sun", "Yanyan Zhao", "Bing Qin"], "summary": "In recent years, Large Language Models (LLMs) have made significant progress\nin automated psychological counseling. However, current research focuses on\nsingle-session counseling, which doesn't represent real-world scenarios. In\npractice, psychological counseling is a process, not a one-time event,\nrequiring sustained, multi-session engagement to progressively address clients'\nissues. To overcome this limitation, we introduce a dataset for Multi-Session\nPsychological Counseling Conversation Dataset (MusPsy-Dataset). Our\nMusPsy-Dataset is constructed using real client profiles from publicly\navailable psychological case reports. It captures the dynamic arc of\ncounseling, encompassing multiple progressive counseling conversations from the\nsame client across different sessions. Leveraging our dataset, we also\ndeveloped our MusPsy-Model, which aims to track client progress and adapt its\ncounseling direction over time. Experiments show that our model performs better\nthan baseline models across multiple sessions.", "comment": "15 pages, 19 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06626v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07999", "title": "MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation", "authors": ["Junhao Chen", "Yulia Tsvetkov", "Xiaochuang Han"], "summary": "Recent progress in multimodal generation has increasingly combined\nautoregressive (AR) and diffusion-based approaches, leveraging their\ncomplementary strengths: AR models capture long-range dependencies and produce\nfluent, context-aware outputs, while diffusion models operate in continuous\nlatent spaces to refine high-fidelity visual details. However, existing hybrids\noften lack systematic guidance on how and why to allocate model capacity\nbetween these paradigms. In this work, we introduce MADFormer, a Mixed\nAutoregressive and Diffusion Transformer that serves as a testbed for analyzing\nAR-diffusion trade-offs. MADFormer partitions image generation into spatial\nblocks, using AR layers for one-pass global conditioning across blocks and\ndiffusion layers for iterative local refinement within each block. Through\ncontrolled experiments on FFHQ-1024 and ImageNet, we identify two key insights:\n(1) block-wise partitioning significantly improves performance on\nhigh-resolution images, and (2) vertically mixing AR and diffusion layers\nyields better quality-efficiency balances--improving FID by up to 75% under\nconstrained inference compute. Our findings offer practical design principles\nfor future hybrid generative models.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.07999v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06752", "title": "Depth-Optimal Quantum Layout Synthesis as SAT", "authors": ["Anna B. Jakobsen", "Anders B. Clausen", "Jaco van de Pol", "Irfansha Shaik"], "summary": "Quantum circuits consist of gates applied to qubits. Current quantum hardware\nplatforms impose connectivity restrictions on binary CX gates. Hence, Layout\nSynthesis is an important step to transpile quantum circuits before they can be\nexecuted. Since CX gates are noisy, it is important to reduce the CX count or\nCX depth of the mapped circuits.\n  We provide a new and efficient encoding of Quantum-circuit Layout Synthesis\nin SAT. Previous SAT encodings focused on gate count and CX-gate count. Our\nencoding instead guarantees that we find mapped circuits with minimal circuit\ndepth or minimal CX-gate depth. We use incremental SAT solving and parallel\nplans for an efficient encoding. This results in speedups of more than 10-100x\ncompared to OLSQ2, which guarantees depth-optimality. But minimizing depth\nstill takes more time than minimizing gate count with Q-Synth.\n  We correlate the noise reduction achieved by simulating circuits after\n(CX)-count and (CX)-depth reduction. We find that minimizing for CX-count\ncorrelates better with reducing noise than minimizing for CX-depth. However,\ntaking into account both CX-count and CX-depth provides the best noise\nreduction.", "comment": "24 pages, 4 figures, 11 tables", "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.06752v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07883", "title": "Diffusion Counterfactual Generation with Semantic Abduction", "authors": ["Rajat Rasal", "Avinash Kori", "Fabio De Sousa Ribeiro", "Tian Xia", "Ben Glocker"], "summary": "Counterfactual image generation presents significant challenges, including\npreserving identity, maintaining perceptual quality, and ensuring faithfulness\nto an underlying causal model. While existing auto-encoding frameworks admit\nsemantic latent spaces which can be manipulated for causal control, they\nstruggle with scalability and fidelity. Advancements in diffusion models\npresent opportunities for improving counterfactual image editing, having\ndemonstrated state-of-the-art visual quality, human-aligned perception and\nrepresentation learning capabilities. Here, we present a suite of\ndiffusion-based causal mechanisms, introducing the notions of spatial, semantic\nand dynamic abduction. We propose a general framework that integrates semantic\nrepresentations into diffusion models through the lens of Pearlian causality to\nedit images via a counterfactual reasoning process. To our knowledge, this is\nthe first work to consider high-level semantic identity preservation for\ndiffusion counterfactuals and to demonstrate how semantic control enables\nprincipled trade-offs between faithful causal control and identity\npreservation.", "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07883v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08002", "title": "Aligning Text, Images, and 3D Structure Token-by-Token", "authors": ["Aadarsh Sahoo", "Vansh Tibrewal", "Georgia Gkioxari"], "summary": "Creating machines capable of understanding the world in 3D is essential in\nassisting designers that build and edit 3D environments and robots navigating\nand interacting within a three-dimensional space. Inspired by advances in\nlanguage and image modeling, we investigate the potential of autoregressive\nmodels for a new modality: structured 3D scenes. To this end, we propose a\nunified LLM framework that aligns language, images, and 3D scenes and provide a\ndetailed ''cookbook'' outlining critical design choices for achieving optimal\ntraining and performance addressing key questions related to data\nrepresentation, modality-specific objectives, and more. We evaluate performance\nacross four core 3D tasks -- rendering, recognition, instruction-following, and\nquestion-answering -- and four 3D datasets, synthetic and real-world. We extend\nour approach to reconstruct complex 3D object shapes by enriching our 3D\nmodality with quantized shape encodings, and show our model's effectiveness on\nreal-world 3D object recognition tasks. Project webpage:\nhttps://glab-caltech.github.io/kyvo/", "comment": "Project webpage: https://glab-caltech.github.io/kyvo/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08002v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07884", "title": "Schauder Bases for $C[0, 1]$ Using ReLU, Softplus and Two Sigmoidal Functions", "authors": ["Anand Ganesh", "Babhrubahan Bose", "Anand Rajagopalan"], "summary": "We construct four Schauder bases for the space $C[0,1]$, one using ReLU\nfunctions, another using Softplus functions, and two more using sigmoidal\nversions of the ReLU and Softplus functions. This establishes the existence of\na basis using these functions for the first time, and improves on the universal\napproximation property associated with them.", "comment": "9 pages", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07884v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08003", "title": "Audio-Sync Video Generation with Multi-Stream Temporal Control", "authors": ["Shuchen Weng", "Haojie Zheng", "Zheng Chang", "Si Li", "Boxin Shi", "Xinlong Wang"], "summary": "Audio is inherently temporal and closely synchronized with the visual world,\nmaking it a naturally aligned and expressive control signal for controllable\nvideo generation (e.g., movies). Beyond control, directly translating audio\ninto video is essential for understanding and visualizing rich audio narratives\n(e.g., Podcasts or historical recordings). However, existing approaches fall\nshort in generating high-quality videos with precise audio-visual\nsynchronization, especially across diverse and complex audio types. In this\nwork, we introduce MTV, a versatile framework for audio-sync video generation.\nMTV explicitly separates audios into speech, effects, and music tracks,\nenabling disentangled control over lip motion, event timing, and visual mood,\nrespectively -- resulting in fine-grained and semantically aligned video\ngeneration. To support the framework, we additionally present DEMIX, a dataset\ncomprising high-quality cinematic videos and demixed audio tracks. DEMIX is\nstructured into five overlapped subsets, enabling scalable multi-stage training\nfor diverse generation scenarios. Extensive experiments demonstrate that MTV\nachieves state-of-the-art performance across six standard metrics spanning\nvideo quality, text-video consistency, and audio-video alignment. Project page:\nhttps://hjzheng.net/projects/MTV/.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08003v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07902", "title": "FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling", "authors": ["Sifan Wang", "Zehao Dou", "Tong-Rui Liu", "Lu Lu"], "summary": "Recent advances in generative modeling -- particularly diffusion models and\nflow matching -- have achieved remarkable success in synthesizing discrete data\nsuch as images and videos. However, adapting these models to physical\napplications remains challenging, as the quantities of interest are continuous\nfunctions governed by complex physical laws. Here, we introduce\n$\\textbf{FunDiff}$, a novel framework for generative modeling in function\nspaces. FunDiff combines a latent diffusion process with a function autoencoder\narchitecture to handle input functions with varying discretizations, generate\ncontinuous functions evaluable at arbitrary locations, and seamlessly\nincorporate physical priors. These priors are enforced through architectural\nconstraints or physics-informed loss functions, ensuring that generated samples\nsatisfy fundamental physical laws. We theoretically establish minimax\noptimality guarantees for density estimation in function spaces, showing that\ndiffusion-based estimators achieve optimal convergence rates under suitable\nregularity conditions. We demonstrate the practical effectiveness of FunDiff\nacross diverse applications in fluid dynamics and solid mechanics. Empirical\nresults show that our method generates physically consistent samples with high\nfidelity to the target distribution and exhibits robustness to noisy and\nlow-resolution data. Code and datasets are publicly available at\nhttps://github.com/sifanexisted/fundiff.", "comment": "31 pages, 12 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07902v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08004", "title": "Dynamic View Synthesis as an Inverse Problem", "authors": ["Hidir Yesiltepe", "Pinar Yanardag"], "summary": "In this work, we address dynamic view synthesis from monocular videos as an\ninverse problem in a training-free setting. By redesigning the noise\ninitialization phase of a pre-trained video diffusion model, we enable\nhigh-fidelity dynamic view synthesis without any weight updates or auxiliary\nmodules. We begin by identifying a fundamental obstacle to deterministic\ninversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and\nresolve it by introducing a novel noise representation, termed K-order\nRecursive Noise Representation. We derive a closed form expression for this\nrepresentation, enabling precise and efficient alignment between the\nVAE-encoded and the DDIM inverted latents. To synthesize newly visible regions\nresulting from camera motion, we introduce Stochastic Latent Modulation, which\nperforms visibility aware sampling over the latent space to complete occluded\nregions. Comprehensive experiments demonstrate that dynamic view synthesis can\nbe effectively performed through structured latent manipulation in the noise\ninitialization phase.", "comment": "Project Page: https://inverse-dvs.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08004v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06806", "title": "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification", "authors": ["Subhendu Khatuya", "Shashwat Naidu", "Saptarshi Ghosh", "Pawan Goyal", "Niloy Ganguly"], "summary": "The explosion of textual data has made manual document classification\nincreasingly challenging. To address this, we introduce a robust, efficient\ndomain-agnostic generative model framework for multi-label text classification.\nInstead of treating labels as mere atomic symbols, our approach utilizes\npredefined label descriptions and is trained to generate these descriptions\nbased on the input text. During inference, the generated descriptions are\nmatched to the pre-defined labels using a finetuned sentence transformer. We\nintegrate this with a dual-objective loss function, combining cross-entropy\nloss and cosine similarity of the generated sentences with the predefined\ntarget descriptions, ensuring both semantic alignment and accuracy. Our\nproposed model LAGAMC stands out for its parameter efficiency and versatility\nacross diverse datasets, making it well-suited for practical applications. We\ndemonstrate the effectiveness of our proposed model by achieving new\nstate-of-the-art performances across all evaluated datasets, surpassing several\nstrong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in\nMacro-F1 compared to the closest baseline across all datasets.", "comment": "This work has been accepted to appear at the Association for\n  Computational Linguistics (ACL), 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06806v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07903", "title": "Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces", "authors": ["Kevin Rojas", "Yuchen Zhu", "Sichen Zhu", "Felix X. -F. Ye", "Molei Tao"], "summary": "Diffusion models have demonstrated remarkable performance in generating\nunimodal data across various tasks, including image, video, and text\ngeneration. On the contrary, the joint generation of multimodal data through\ndiffusion models is still in the early stages of exploration. Existing\napproaches heavily rely on external preprocessing protocols, such as tokenizers\nand variational autoencoders, to harmonize varied data representations into a\nunified, unimodal format. This process heavily demands the high accuracy of\nencoders and decoders, which can be problematic for applications with limited\ndata. To lift this restriction, we propose a novel framework for building\nmultimodal diffusion models on arbitrary state spaces, enabling native\ngeneration of coupled data across different modalities. By introducing an\ninnovative decoupled noise schedule for each modality, we enable both\nunconditional and modality-conditioned generation within a single model\nsimultaneously. We empirically validate our approach for text-image generation\nand mixed-type tabular data synthesis, demonstrating that it achieves\ncompetitive performance.", "comment": "Accepted to ICML 2025. Code available at\n  https://github.com/KevinRojas1499/Diffuse-Everything", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07903v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08005", "title": "ZeroVO: Visual Odometry with Minimal Assumptions", "authors": ["Lei Lai", "Zekai Yin", "Eshed Ohn-Bar"], "summary": "We introduce ZeroVO, a novel visual odometry (VO) algorithm that achieves\nzero-shot generalization across diverse cameras and environments, overcoming\nlimitations in existing methods that depend on predefined or static camera\ncalibration setups. Our approach incorporates three main innovations. First, we\ndesign a calibration-free, geometry-aware network structure capable of handling\nnoise in estimated depth and camera parameters. Second, we introduce a\nlanguage-based prior that infuses semantic information to enhance robust\nfeature extraction and generalization to previously unseen domains. Third, we\ndevelop a flexible, semi-supervised training paradigm that iteratively adapts\nto new scenes using unlabeled data, further boosting the models' ability to\ngeneralize across diverse real-world scenarios. We analyze complex autonomous\ndriving contexts, demonstrating over 30% improvement against prior methods on\nthree standard benchmarks, KITTI, nuScenes, and Argoverse 2, as well as a newly\nintroduced, high-fidelity synthetic dataset derived from Grand Theft Auto\n(GTA). By not requiring fine-tuning or camera calibration, our work broadens\nthe applicability of VO, providing a versatile solution for real-world\ndeployment at scale.", "comment": null, "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08005v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06808", "title": "Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events", "authors": ["James A. Michaelov", "Reeka Estacio", "Zhien Zhang", "Benjamin K. Bergen"], "summary": "Can language models reliably predict that possible events are more likely\nthan merely improbable ones? By teasing apart possibility, typicality, and\ncontextual relatedness, we show that despite the results of previous work,\nlanguage models' ability to do this is far from robust. In fact, under certain\nconditions, all models tested - including Llama 3, Gemma 2, and Mistral NeMo -\nperform at worse-than-chance level, assigning higher probabilities to\nimpossible sentences such as 'the car was given a parking ticket by the brake'\nthan to merely unlikely sentences such as 'the car was given a parking ticket\nby the explorer'.", "comment": "Accepted to Findings of ACL 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06808v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07918", "title": "CausalPFN: Amortized Causal Effect Estimation via In-Context Learning", "authors": ["Vahid Balazadeh", "Hamidreza Kamkari", "Valentin Thomas", "Benson Li", "Junwei Ma", "Jesse C. Cresswell", "Rahul G. Krishnan"], "summary": "Causal effect estimation from observational data is fundamental across\nvarious applications. However, selecting an appropriate estimator from dozens\nof specialized methods demands substantial manual effort and domain expertise.\nWe present CausalPFN, a single transformer that amortizes this workflow:\ntrained once on a large library of simulated data-generating processes that\nsatisfy ignorability, it infers causal effects for new observational datasets\nout-of-the-box. CausalPFN combines ideas from Bayesian causal inference with\nthe large-scale training protocol of prior-fitted networks (PFNs), learning to\nmap raw observations directly to causal effects without any task-specific\nadjustment. Our approach achieves superior average performance on heterogeneous\nand average treatment effect estimation benchmarks (IHDP, Lalonde, ACIC).\nMoreover, it shows competitive performance for real-world policy making on\nuplift modeling tasks. CausalPFN provides calibrated uncertainty estimates to\nsupport reliable decision-making based on Bayesian principles. This\nready-to-use model does not require any further training or tuning and takes a\nstep toward automated causal inference (https://github.com/vdblm/CausalPFN).", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07918v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08006", "title": "Dreamland: Controllable World Creation with Simulator and Generative Models", "authors": ["Sicheng Mo", "Ziyang Leng", "Leon Liu", "Weizhen Wang", "Honglin He", "Bolei Zhou"], "summary": "Large-scale video generative models can synthesize diverse and realistic\nvisual content for dynamic world creation, but they often lack element-wise\ncontrollability, hindering their use in editing scenes and training embodied AI\nagents. We propose Dreamland, a hybrid world generation framework combining the\ngranular control of a physics-based simulator and the photorealistic content\noutput of large-scale pretrained generative models. In particular, we design a\nlayered world abstraction that encodes both pixel-level and object-level\nsemantics and geometry as an intermediate representation to bridge the\nsimulator and the generative model. This approach enhances controllability,\nminimizes adaptation cost through early alignment with real-world\ndistributions, and supports off-the-shelf use of existing and future pretrained\ngenerative models. We further construct a D3Sim dataset to facilitate the\ntraining and evaluation of hybrid generation pipelines. Experiments demonstrate\nthat Dreamland outperforms existing baselines with 50.8% improved image\nquality, 17.9% stronger controllability, and has great potential to enhance\nembodied agent training. Code and data will be made available.", "comment": "Project Page: https://metadriverse.github.io/dreamland/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08006v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07919", "title": "Uncovering the Functional Roles of Nonlinearity in Memory", "authors": ["Manuel Brenner", "Georgia Koppe"], "summary": "Memory and long-range temporal processing are core requirements for sequence\nmodeling tasks across natural language processing, time-series forecasting,\nspeech recognition, and control. While nonlinear recurrence has long been\nviewed as essential for enabling such mechanisms, recent work suggests that\nlinear dynamics may often suffice. In this study, we go beyond performance\ncomparisons to systematically dissect the functional role of nonlinearity in\nrecurrent networks--identifying both when it is computationally necessary, and\nwhat mechanisms it enables. We use Almost Linear Recurrent Neural Networks\n(AL-RNNs), which allow fine-grained control over nonlinearity, as both a\nflexible modeling tool and a probe into the internal mechanisms of memory.\nAcross a range of classic sequence modeling tasks and a real-world stimulus\nselection task, we find that minimal nonlinearity is not only sufficient but\noften optimal, yielding models that are simpler, more robust, and more\ninterpretable than their fully nonlinear or linear counterparts. Our results\nprovide a principled framework for selectively introducing nonlinearity,\nbridging dynamical systems theory with the functional demands of long-range\nmemory and structured computation in recurrent neural networks, with\nimplications for both artificial and biological neural systems.", "comment": "Preprint under review", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07919v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08008", "title": "Hidden in plain sight: VLMs overlook their visual representations", "authors": ["Stephanie Fu", "Tyler Bonnen", "Devin Guillory", "Trevor Darrell"], "summary": "Language provides a natural interface to specify and evaluate performance on\nvisual tasks. To realize this possibility, vision language models (VLMs) must\nsuccessfully integrate visual and linguistic information. Our work compares\nVLMs to a direct readout of their visual encoders to understand their ability\nto integrate across these modalities. Across a series of vision-centric\nbenchmarks (e.g., depth estimation, correspondence), we find that VLMs perform\nsubstantially worse than their visual encoders, dropping to near-chance\nperformance. We investigate these results through a series of analyses across\nthe entire VLM: namely 1) the degradation of vision representations, 2)\nbrittleness to task prompt, and 3) the language model's role in solving the\ntask. We find that the bottleneck in performing these vision-centric tasks lies\nin this third category; VLMs are not effectively using visual information\neasily accessible throughout the entire model, and they inherit the language\npriors present in the LLM. Our work helps diagnose the failure modes of\nopen-source VLMs, and presents a series of evaluations useful for future\ninvestigations into visual understanding within VLMs.", "comment": "Project page: https://hidden-plain-sight.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08008v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07920", "title": "W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling", "authors": ["Hossein Babaei", "Mel White", "Richard G. Baraniuk"], "summary": "State Space Models (SSMs) have emerged as powerful components for sequence\nmodeling, enabling efficient handling of long-range dependencies via linear\nrecurrence and convolutional computation. However, their effectiveness depends\nheavily on the choice and initialization of the state matrix. In this work, we\nbuild on the SaFARi framework and existing WaLRUS SSMs to introduce a new\nvariant, W4S4 (WaLRUS for S4), a new class of SSMs constructed from redundant\nwavelet frames. WaLRUS admits a stable diagonalization and supports fast kernel\ncomputation without requiring low-rank approximations, making it both\ntheoretically grounded and computationally efficient. We show that WaLRUS\nretains information over long horizons significantly better than HiPPO-based\nSSMs, both in isolation and when integrated into deep architectures such as S4.\nOur experiments demonstrate consistent improvements across delay reconstruction\ntasks, classification benchmarks, and long-range sequence modeling, confirming\nthat high-quality, structured initialization enabled by wavelet-based state\ndynamic offers substantial advantages over existing alternatives. WaLRUS\nprovides a scalable and versatile foundation for the next generation of deep\nSSM-based models.", "comment": "10 pages, 2 figures, 3 tables", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07920v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06636", "title": "SafeLawBench: Towards Safe Alignment of Large Language Models", "authors": ["Chuxue Cao", "Han Zhu", "Jiaming Ji", "Qichao Sun", "Zhenghao Zhu", "Yinyu Wu", "Juntao Dai", "Yaodong Yang", "Sirui Han", "Yike Guo"], "summary": "With the growing prevalence of large language models (LLMs), the safety of\nLLMs has raised significant concerns. However, there is still a lack of\ndefinitive standards for evaluating their safety due to the subjective nature\nof current safety benchmarks. To address this gap, we conducted the first\nexploration of LLMs' safety evaluation from a legal perspective by proposing\nthe SafeLawBench benchmark. SafeLawBench categorizes safety risks into three\nlevels based on legal standards, providing a systematic and comprehensive\nframework for evaluation. It comprises 24,860 multi-choice questions and 1,106\nopen-domain question-answering (QA) tasks. Our evaluation included 2\nclosed-source LLMs and 18 open-source LLMs using zero-shot and few-shot\nprompting, highlighting the safety features of each model. We also evaluated\nthe LLMs' safety-related reasoning stability and refusal behavior.\nAdditionally, we found that a majority voting mechanism can enhance model\nperformance. Notably, even leading SOTA models like Claude-3.5-Sonnet and\nGPT-4o have not exceeded 80.5% accuracy in multi-choice tasks on SafeLawBench,\nwhile the average accuracy of 20 LLMs remains at 68.8\\%. We urge the community\nto prioritize research on the safety of LLMs.", "comment": "Accepted to ACL2025 Findings", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06636v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08009", "title": "Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion", "authors": ["Xun Huang", "Zhengqi Li", "Guande He", "Mingyuan Zhou", "Eli Shechtman"], "summary": "We introduce Self Forcing, a novel training paradigm for autoregressive video\ndiffusion models. It addresses the longstanding issue of exposure bias, where\nmodels trained on ground-truth context must generate sequences conditioned on\ntheir own imperfect outputs during inference. Unlike prior methods that denoise\nfuture frames based on ground-truth context frames, Self Forcing conditions\neach frame's generation on previously self-generated outputs by performing\nautoregressive rollout with key-value (KV) caching during training. This\nstrategy enables supervision through a holistic loss at the video level that\ndirectly evaluates the quality of the entire generated sequence, rather than\nrelying solely on traditional frame-wise objectives. To ensure training\nefficiency, we employ a few-step diffusion model along with a stochastic\ngradient truncation strategy, effectively balancing computational cost and\nperformance. We further introduce a rolling KV cache mechanism that enables\nefficient autoregressive video extrapolation. Extensive experiments demonstrate\nthat our approach achieves real-time streaming video generation with sub-second\nlatency on a single GPU, while matching or even surpassing the generation\nquality of significantly slower and non-causal diffusion models. Project\nwebsite: http://self-forcing.github.io/", "comment": "Project website: http://self-forcing.github.io/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08009v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07929", "title": "A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle", "authors": ["Amirreza Yasami", "Mohammadali Tofigh", "Mahdi Shahbakhti", "Charles Robert Koch"], "summary": "Accurate driving cycle construction is crucial for vehicle design, fuel\neconomy analysis, and environmental impact assessments. A generative\nPhysics-Informed Expected SARSA-Monte Carlo (PIESMC) approach that constructs\nrepresentative driving cycles by capturing transient dynamics, acceleration,\ndeceleration, idling, and road grade transitions while ensuring model fidelity\nis introduced. Leveraging a physics-informed reinforcement learning framework\nwith Monte Carlo sampling, PIESMC delivers efficient cycle construction with\nreduced computational cost. Experimental evaluations on two real-world datasets\ndemonstrate that PIESMC replicates key kinematic and energy metrics, achieving\nup to a 57.3% reduction in cumulative kinematic fragment errors compared to the\nMicro-trip-based (MTB) method and a 10.5% reduction relative to the\nMarkov-chain-based (MCB) method. Moreover, it is nearly an order of magnitude\nfaster than conventional techniques. Analyses of vehicle-specific power\ndistributions and wavelet-transformed frequency content further confirm its\nability to reproduce experimental central tendencies and variability.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07929v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08010", "title": "Vision Transformers Don't Need Trained Registers", "authors": ["Nick Jiang", "Amil Dravid", "Alexei Efros", "Yossi Gandelsman"], "summary": "We investigate the mechanism underlying a previously identified phenomenon in\nVision Transformers -- the emergence of high-norm tokens that lead to noisy\nattention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a\nsparse set of neurons is responsible for concentrating high-norm activations on\noutlier tokens, leading to irregular attention patterns and degrading\ndownstream visual processing. While the existing solution for removing these\noutliers involves retraining models from scratch with additional learned\nregister tokens, we use our findings to create a training-free approach to\nmitigate these artifacts. By shifting the high-norm activations from our\ndiscovered register neurons into an additional untrained token, we can mimic\nthe effect of register tokens on a model already trained without registers. We\ndemonstrate that our method produces cleaner attention and feature maps,\nenhances performance over base models across multiple downstream visual tasks,\nand achieves results comparable to models explicitly trained with register\ntokens. We then extend test-time registers to off-the-shelf vision-language\nmodels to improve their interpretability. Our results suggest that test-time\nregisters effectively take on the role of register tokens at test-time,\noffering a training-free solution for any pre-trained model released without\nthem.", "comment": "Project page and code: https://avdravid.github.io/test-time-registers", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08010v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07933", "title": "Ensemble-Based Survival Models with the Self-Attended Beran Estimator Predictions", "authors": ["Lev V. Utkin", "Semen P. Khomets", "Vlada A. Efremenko", "Andrei V. Konstantinov", "Natalya M. Verbova"], "summary": "Survival analysis predicts the time until an event of interest, such as\nfailure or death, but faces challenges due to censored data, where some events\nremain unobserved. Ensemble-based models, like random survival forests and\ngradient boosting, are widely used but can produce unstable predictions due to\nvariations in bootstrap samples. To address this, we propose SurvBESA (Survival\nBeran Estimators Self-Attended), a novel ensemble model that combines Beran\nestimators with a self-attention mechanism. Unlike traditional methods,\nSurvBESA applies self-attention to predicted survival functions, smoothing out\nnoise by adjusting each survival function based on its similarity to\nneighboring survival functions. We also explore a special case using Huber's\ncontamination model to define attention weights, simplifying training to a\nquadratic or linear optimization problem. Numerical experiments show that\nSurvBESA outperforms state-of-the-art models. The implementation of SurvBESA is\npublicly available.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07933v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08011", "title": "Play to Generalize: Learning to Reason Through Game Play", "authors": ["Yunfei Xie", "Yinsong Ma", "Shiyi Lan", "Alan Yuille", "Junfei Xiao", "Chen Wei"], "summary": "Developing generalizable reasoning capabilities in multimodal large language\nmodels (MLLMs) remains challenging. Motivated by cognitive science literature\nsuggesting that gameplay promotes transferable cognitive skills, we propose a\nnovel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs\ndevelop out-of-domain generalization of multimodal reasoning through playing\narcade-like games. Specifically, we show that post-training a 7B-parameter MLLM\nvia reinforcement learning (RL) on simple arcade-like games, e.g. Snake,\nsignificantly enhances its downstream performance on multimodal math benchmarks\nlike MathVista, and on multi-discipline questions like MMMU, without seeing any\nworked solutions, equations, or diagrams during RL, suggesting the capture of\ntransferable reasoning skills. Remarkably, our model outperforms specialist\nmodels tuned on multimodal reasoning data in multimodal reasoning benchmarks,\nwhile preserving the base model's performance on general visual benchmarks, a\nchallenge where specialist models often fall short. Our findings suggest a new\npost-training paradigm: synthetic, rule-based games can serve as controllable\nand scalable pre-text tasks that unlock generalizable multimodal reasoning\nabilities in MLLMs.", "comment": "Project Page: https://yunfeixie233.github.io/ViGaL/", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08011v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08013", "title": "StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets", "authors": ["Anh-Quan Cao", "Ivan Lopes", "Raoul de Charette"], "summary": "Multi-task learning for dense prediction is limited by the need for extensive\nannotation for every task, though recent works have explored training with\npartial task labels. Leveraging the generalization power of diffusion models,\nwe extend the partial learning setup to a zero-shot setting, training a\nmulti-task model on multiple synthetic datasets, each labeled for only a subset\nof tasks. Our method, StableMTL, repurposes image generators for latent\nregression. Adapting a denoising framework with task encoding, per-task\nconditioning and a tailored training scheme. Instead of per-task losses\nrequiring careful balancing, a unified latent loss is adopted, enabling\nseamless scaling to more tasks. To encourage inter-task synergy, we introduce a\nmulti-stream model with a task-attention mechanism that converts N-to-N task\ninteractions into efficient 1-to-N attention, promoting effective cross-task\nsharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.", "comment": "Code is available at https://github.com/astra-vision/StableMTL", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08013v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07949", "title": "Cost-Optimal Active AI Model Evaluation", "authors": ["Anastasios N. Angelopoulos", "Jacob Eisenstein", "Jonathan Berant", "Alekh Agarwal", "Adam Fisch"], "summary": "The development lifecycle of generative AI systems requires continual\nevaluation, data acquisition, and annotation, which is costly in both resources\nand time. In practice, rapid iteration often makes it necessary to rely on\nsynthetic annotation data because of the low cost, despite the potential for\nsubstantial bias. In this paper, we develop novel, cost-aware methods for\nactively balancing the use of a cheap, but often inaccurate, weak rater -- such\nas a model-based autorater that is designed to automatically assess the quality\nof generated content -- with a more expensive, but also more accurate, strong\nrater alternative such as a human. More specifically, the goal of our approach\nis to produce a low variance, unbiased estimate of the mean of the target\n\"strong\" rating, subject to some total annotation budget. Building on recent\nwork in active and prediction-powered statistical inference, we derive a family\nof cost-optimal policies for allocating a given annotation budget between weak\nand strong raters so as to maximize statistical efficiency. Using synthetic and\nreal-world data, we empirically characterize the conditions under which these\npolicies yield improvements over prior methods. We find that, especially in\ntasks where there is high variability in the difficulty of examples, our\npolicies can achieve the same estimation precision at a far lower total\nannotation budget than standard evaluation methods.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07949v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08015", "title": "4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos", "authors": ["Zhen Xu", "Zhengqin Li", "Zhao Dong", "Xiaowei Zhou", "Richard Newcombe", "Zhaoyang Lv"], "summary": "We propose 4DGT, a 4D Gaussian-based Transformer model for dynamic scene\nreconstruction, trained entirely on real-world monocular posed videos. Using 4D\nGaussian as an inductive bias, 4DGT unifies static and dynamic components,\nenabling the modeling of complex, time-varying environments with varying object\nlifespans. We proposed a novel density control strategy in training, which\nenables our 4DGT to handle longer space-time input and remain efficient\nrendering at runtime. Our model processes 64 consecutive posed frames in a\nrolling-window fashion, predicting consistent 4D Gaussians in the scene. Unlike\noptimization-based methods, 4DGT performs purely feed-forward inference,\nreducing reconstruction time from hours to seconds and scaling effectively to\nlong video sequences. Trained only on large-scale monocular posed video\ndatasets, 4DGT can outperform prior Gaussian-based networks significantly in\nreal-world videos and achieve on-par accuracy with optimization-based methods\non cross-domain videos. Project page: https://4dgt.github.io", "comment": "Project page: https://4dgt.github.io", "cate": "cs.CV", "url": "http://arxiv.org/abs/2506.08015v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07958", "title": "Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs", "authors": ["Salah A. Faroughi", "Farinaz Mostajeran"], "summary": "Physics-informed Kolmogorov-Arnold Networks (PIKANs), and in particular their\nChebyshev-based variants (cPIKANs), have recently emerged as promising models\nfor solving partial differential equations (PDEs). However, their training\ndynamics and convergence behavior remain largely unexplored both theoretically\nand numerically. In this work, we aim to advance the theoretical understanding\nof cPIKANs by analyzing them using Neural Tangent Kernel (NTK) theory. Our\nobjective is to discern the evolution of kernel structure throughout\ngradient-based training and its subsequent impact on learning efficiency. We\nfirst derive the NTK of standard cKANs in a supervised setting, and then extend\nthe analysis to the physics-informed context. We analyze the spectral\nproperties of NTK matrices, specifically their eigenvalue distributions and\nspectral bias, for four representative PDEs: the steady-state Helmholtz\nequation, transient diffusion and Allen-Cahn equations, and forced vibrations\ngoverned by the Euler-Bernoulli beam equation. We also conduct an investigation\ninto the impact of various optimization strategies, e.g., first-order,\nsecond-order, and hybrid approaches, on the evolution of the NTK and the\nresulting learning dynamics. Results indicate a tractable behavior for NTK in\nthe context of cPIKANs, which exposes learning dynamics that standard\nphysics-informed neural networks (PINNs) cannot capture. Spectral trends also\nreveal when domain decomposition improves training, directly linking kernel\nbehavior to convergence rates under different setups. To the best of our\nknowledge, this is the first systematic NTK study of cPIKANs, providing\ntheoretical insight that clarifies and predicts their empirical performance.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07958v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07969", "title": "A Two-Phase Deep Learning Framework for Adaptive Time-Stepping in High-Speed Flow Modeling", "authors": ["Jacob Helwig", "Sai Sreeharsha Adavi", "Xuan Zhang", "Yuchao Lin", "Felix S. Chim", "Luke Takeshi Vizzini", "Haiyang Yu", "Muhammad Hasnain", "Saykat Kumar Biswas", "John J. Holloway", "Narendra Singh", "N. K. Anand", "Swagnik Guhathakurta", "Shuiwang Ji"], "summary": "We consider the problem of modeling high-speed flows using machine learning\nmethods. While most prior studies focus on low-speed fluid flows in which\nuniform time-stepping is practical, flows approaching and exceeding the speed\nof sound exhibit sudden changes such as shock waves. In such cases, it is\nessential to use adaptive time-stepping methods to allow a temporal resolution\nsufficient to resolve these phenomena while simultaneously balancing\ncomputational costs. Here, we propose a two-phase machine learning method,\nknown as ShockCast, to model high-speed flows with adaptive time-stepping. In\nthe first phase, we propose to employ a machine learning model to predict the\ntimestep size. In the second phase, the predicted timestep is used as an input\nalong with the current fluid fields to advance the system state by the\npredicted timestep. We explore several physically-motivated components for\ntimestep prediction and introduce timestep conditioning strategies inspired by\nneural ODE and Mixture of Experts. As ShockCast is the first framework for\nlearning high-speed flows, we evaluate our methods by generating two supersonic\nflow datasets, available at https://huggingface.co/datasets/divelab. Our code\nis publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07969v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06306", "title": "Benchmarking Early Agitation Prediction in Community-Dwelling People with Dementia Using Multimodal Sensors and Machine Learning", "authors": ["Ali Abedi", "Charlene H. Chu", "Shehroz S. Khan"], "summary": "Agitation is one of the most common responsive behaviors in people living\nwith dementia, particularly among those residing in community settings without\ncontinuous clinical supervision. Timely prediction of agitation can enable\nearly intervention, reduce caregiver burden, and improve the quality of life\nfor both patients and caregivers. This study aimed to develop and benchmark\nmachine learning approaches for the early prediction of agitation in\ncommunity-dwelling older adults with dementia using multimodal sensor data. A\nnew set of agitation-related contextual features derived from activity data was\nintroduced and employed for agitation prediction. A wide range of machine\nlearning and deep learning models was evaluated across multiple problem\nformulations, including binary classification for single-timestamp tabular\nsensor data and multi-timestamp sequential sensor data, as well as anomaly\ndetection for single-timestamp tabular sensor data. The study utilized the\nTechnology Integrated Health Management (TIHM) dataset, the largest publicly\navailable dataset for remote monitoring of people living with dementia,\ncomprising 2,803 days of in-home activity, physiology, and sleep data. The most\neffective setting involved binary classification of sensor data using the\ncurrent 6-hour timestamp to predict agitation at the subsequent timestamp.\nIncorporating additional information, such as time of day and agitation\nhistory, further improved model performance, with the highest AUC-ROC of 0.9720\nand AUC-PR of 0.4320 achieved by the light gradient boosting machine. This work\npresents the first comprehensive benchmarking of state-of-the-art techniques\nfor agitation prediction in community-based dementia care using\nprivacy-preserving sensor data. The approach enables accurate, explainable, and\nefficient agitation prediction, supporting proactive dementia care and aging in\nplace.", "comment": "16 pages, 4 figures, 2 tables", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06306v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06840", "title": "A Statistical Framework for Model Selection in LSTM Networks", "authors": ["Fahad Mostafa"], "summary": "Long Short-Term Memory (LSTM) neural network models have become the\ncornerstone for sequential data modeling in numerous applications, ranging from\nnatural language processing to time series forecasting. Despite their success,\nthe problem of model selection, including hyperparameter tuning, architecture\nspecification, and regularization choice remains largely heuristic and\ncomputationally expensive. In this paper, we propose a unified statistical\nframework for systematic model selection in LSTM networks. Our framework\nextends classical model selection ideas, such as information criteria and\nshrinkage estimation, to sequential neural networks. We define penalized\nlikelihoods adapted to temporal structures, propose a generalized threshold\napproach for hidden state dynamics, and provide efficient estimation strategies\nusing variational Bayes and approximate marginal likelihood methods. Several\nbiomedical data centric examples demonstrate the flexibility and improved\nperformance of the proposed framework.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.06840v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07972", "title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization", "authors": ["Hongzheng Chen", "Yingheng Wang", "Yaohui Cai", "Hins Hu", "Jiajie Li", "Shirley Huang", "Chenhui Deng", "Rongjian Liang", "Shufeng Kong", "Haoxing Ren", "Samitha Samaranayake", "Carla P. Gomes", "Zhiru Zhang"], "summary": "While Large Language Models (LLMs) have demonstrated significant advancements\nin reasoning and agent-based problem-solving, current evaluation methodologies\nfail to adequately assess their capabilities: existing benchmarks either rely\non closed-ended questions prone to saturation and memorization, or subjective\ncomparisons that lack consistency and rigor. In this work, we introduce\nHeuriGym, an agentic framework designed for evaluating heuristic algorithms\ngenerated by LLMs for combinatorial optimization problems, characterized by\nclearly defined objectives and expansive solution spaces. HeuriGym empowers\nLLMs to propose heuristics, receive evaluative feedback via code execution, and\niteratively refine their solutions. We evaluate nine state-of-the-art models on\nnine problems across domains such as computer systems, logistics, and biology,\nexposing persistent limitations in tool use, planning, and adaptive reasoning.\nTo quantify performance, we propose the Quality-Yield Index (QYI), a metric\nthat captures both solution pass rate and quality. Even top models like\nGPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below\nthe expert baseline of 1. Our open-source benchmark aims to guide the\ndevelopment of LLMs toward more effective and realistic problem-solving in\nscientific and engineering domains.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07972v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06315", "title": "An Open-Source Python Framework and Synthetic ECG Image Datasets for Digitization, Lead and Lead Name Detection, and Overlapping Signal Segmentation", "authors": ["Masoud Rahimi", "Reza Karbasi", "Abdol-Hossein Vahabie"], "summary": "We introduce an open-source Python framework for generating synthetic ECG\nimage datasets to advance critical deep learning-based tasks in ECG analysis,\nincluding ECG digitization, lead region and lead name detection, and\npixel-level waveform segmentation. Using the PTB-XL signal dataset, our\nproposed framework produces four open-access datasets: (1) ECG images in\nvarious lead configurations paired with time-series signals for ECG\ndigitization, (2) ECG images annotated with YOLO-format bounding boxes for\ndetection of lead region and lead name, (3)-(4) cropped single-lead images with\nsegmentation masks compatible with U-Net-based models in normal and overlapping\nversions. In the overlapping case, waveforms from neighboring leads are\nsuperimposed onto the target lead image, while the segmentation masks remain\nclean. The open-source Python framework and datasets are publicly available at\nhttps://github.com/rezakarbasi/ecg-image-and-signal-dataset and\nhttps://doi.org/10.5281/zenodo.15484519, respectively.", "comment": "5 pages, 5 figures", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06315v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06842", "title": "PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation", "authors": ["Arkadiusz Modzelewski", "Witold Sosnowski", "Tiziano Labruna", "Adam Wierzbicki", "Giovanni Da San Martino"], "summary": "Disinformation detection is a key aspect of media literacy. Psychological\nstudies have shown that knowledge of persuasive fallacies helps individuals\ndetect disinformation. Inspired by these findings, we experimented with large\nlanguage models (LLMs) to test whether infusing persuasion knowledge enhances\ndisinformation detection. As a result, we introduce the Persuasion-Augmented\nChain of Thought (PCoT), a novel approach that leverages persuasion to improve\ndisinformation detection in zero-shot classification. We extensively evaluate\nPCoT on online news and social media posts. Moreover, we publish two novel,\nup-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets\nenable the evaluation of PCoT on content entirely unseen by the LLMs used in\nour experiments, as the content was published after the models' knowledge\ncutoffs. We show that, on average, PCoT outperforms competitive methods by 15%\nacross five LLMs and five datasets. These findings highlight the value of\npersuasion in strengthening zero-shot disinformation detection.", "comment": "Accepted to ACL 2025 Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06842v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07975", "title": "Hyperpruning: Efficient Search through Pruned Variants of Recurrent Neural Networks Leveraging Lyapunov Spectrum", "authors": ["Caleb Zheng", "Eli Shlizerman"], "summary": "A variety of pruning methods have been introduced for over-parameterized\nRecurrent Neural Networks to improve efficiency in terms of power consumption\nand storage utilization. These advances motivate a new paradigm, termed\n`hyperpruning', which seeks to identify the most suitable pruning strategy for\na given network architecture and application. Unlike conventional\nhyperparameter search, where the optimal configuration's accuracy remains\nuncertain, in the context of network pruning, the accuracy of the dense model\nsets the target for the accuracy of the pruned one. The goal, therefore, is to\ndiscover pruned variants that match or even surpass this established accuracy.\nHowever, exhaustive search over pruning configurations is computationally\nexpensive and lacks early performance guarantees. To address this challenge, we\npropose a novel Lyapunov Spectrum (LS)-based distance metric that enables early\ncomparison between pruned and dense networks, allowing accurate prediction of\npost-training performance. By integrating this LS-based distance with standard\nhyperparameter optimization algorithms, we introduce an efficient hyperpruning\nframework, termed LS-based Hyperpruning (LSH). LSH reduces search time by an\norder of magnitude compared to conventional approaches relying on full\ntraining. Experiments on stacked LSTM and RHN architectures using the Penn\nTreebank dataset, and on AWD-LSTM-MoS using WikiText-2, demonstrate that under\nfixed training budgets and target pruning ratios, LSH consistently identifies\nsuperior pruned models. Remarkably, these pruned variants not only outperform\nthose selected by loss-based baseline but also exceed the performance of their\ndense counterpart.", "comment": "26 pages, 3 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07975v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06349", "title": "Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning", "authors": ["Thien Nhan Vo", "Thanh Xuan Truong"], "summary": "This study addresses the classification of heartbeats from ECG signals\nthrough two distinct approaches: traditional machine learning utilizing\nhand-crafted features and deep learning via transformed images of ECG beats.\nThe dataset underwent preprocessing steps, including downsampling, filtering,\nand normalization, to ensure consistency and relevance for subsequent analysis.\nIn the first approach, features such as heart rate variability (HRV), mean,\nvariance, and RR intervals were extracted to train various classifiers,\nincluding SVM, Random Forest, AdaBoost, LSTM, Bi-directional LSTM, and\nLightGBM. The second approach involved transforming ECG signals into images\nusing Gramian Angular Field (GAF), Markov Transition Field (MTF), and\nRecurrence Plots (RP), with these images subsequently classified using CNN\narchitectures like VGG and Inception.\n  Experimental results demonstrate that the LightGBM model achieved the highest\nperformance, with an accuracy of 99% and an F1 score of 0.94, outperforming the\nimage-based CNN approach (F1 score of 0.85). Models such as SVM and AdaBoost\nyielded significantly lower scores, indicating limited suitability for this\ntask. The findings underscore the superior ability of hand-crafted features to\ncapture temporal and morphological variations in ECG signals compared to\nimage-based representations of individual beats. Future investigations may\nbenefit from incorporating multi-lead ECG signals and temporal dependencies\nacross successive beats to enhance classification accuracy further.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06349v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07976", "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction", "authors": ["Junhong Shen", "Hao Bai", "Lunjun Zhang", "Yifei Zhou", "Amrith Setlur", "Shengbang Tong", "Diego Caples", "Nan Jiang", "Tong Zhang", "Ameet Talwalkar", "Aviral Kumar"], "summary": "The current paradigm of test-time scaling relies on generating long reasoning\ntraces (\"thinking\" more) before producing a response. In agent problems that\nrequire interaction, this can be done by generating thinking traces before\nacting in the world. However, this process does not allow agents to acquire new\ninformation from the environment or adapt their behavior over time. In this\nwork, we propose to scale test-time interaction, an untapped dimension of\ntest-time scaling that increases the agent's interaction horizon to enable\nrunning rich behaviors such as exploration, backtracking, and dynamic\nre-planning within a single rollout. To demonstrate the promise of this scaling\ndimension, we study the domain of web agents. We first show that even\nprompting-based interaction scaling without any training can improve task\nsuccess on web benchmarks non-trivially. Building on this, we introduce TTI\n(Test-Time Interaction), a curriculum-based online reinforcement learning (RL)\napproach that trains agents by adaptively adjusting their rollout lengths.\nUsing a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data\nweb agents on WebVoyager and WebArena benchmarks. We further show that TTI\nenables agents to balance exploration and exploitation adaptively. Our results\nestablish interaction scaling as a powerful, complementary axis to scaling\nper-step compute, offering new avenues for training adaptive agents.", "comment": null, "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07976v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07980", "title": "Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator", "authors": ["Alberto Bazán-Guillén", "Carlos Beis-Penedo", "Diego Cajaraville-Aboy", "Pablo Barbecho-Bautista", "Rebeca P. Díaz-Redondo", "Luis J. de la Cruz Llopis", "Ana Fernández-Vilas", "Mónica Aguilar Igartua", "Manuel Fernández-Veiga"], "summary": "Realistic urban traffic simulation is essential for sustainable urban\nplanning and the development of intelligent transportation systems. However,\ngenerating high-fidelity, time-varying traffic profiles that accurately reflect\nreal-world conditions, especially in large-scale scenarios, remains a major\nchallenge. Existing methods often suffer from limitations in accuracy,\nscalability, or raise privacy concerns due to centralized data processing. This\nwork introduces DesRUTGe (Decentralized Realistic Urban Traffic Generator), a\nnovel framework that integrates Deep Reinforcement Learning (DRL) agents with\nthe SUMO simulator to generate realistic 24-hour traffic patterns. A key\ninnovation of DesRUTGe is its use of Decentralized Federated Learning (DFL),\nwherein each traffic detector and its corresponding urban zone function as an\nindependent learning node. These nodes train local DRL models using minimal\nhistorical data and collaboratively refine their performance by exchanging\nmodel parameters with selected peers (e.g., geographically adjacent zones),\nwithout requiring a central coordinator. Evaluated using real-world data from\nthe city of Barcelona, DesRUTGe outperforms standard SUMO-based tools such as\nRouteSampler, as well as other centralized learning approaches, by delivering\nmore accurate and privacy-preserving traffic pattern generation.", "comment": "21 pages, 7 figures", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07980v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07998", "title": "Generative Modeling of Weights: Generalization or Memorization?", "authors": ["Boya Zeng", "Yida Yin", "Zhiqiu Xu", "Zhuang Liu"], "summary": "Generative models, with their success in image and video generation, have\nrecently been explored for synthesizing effective neural network weights. These\napproaches take trained neural network checkpoints as training data, and aim to\ngenerate high-performing neural network weights during inference. In this work,\nwe examine four representative methods on their ability to generate novel model\nweights, i.e., weights that are different from the checkpoints seen during\ntraining. Surprisingly, we find that these methods synthesize weights largely\nby memorization: they produce either replicas, or at best simple\ninterpolations, of the training checkpoints. Current methods fail to outperform\nsimple baselines, such as adding noise to the weights or taking a simple weight\nensemble, in obtaining different and simultaneously high-performing models. We\nfurther show that this memorization cannot be effectively mitigated by\nmodifying modeling factors commonly associated with memorization in image\ndiffusion models, or applying data augmentations. Our findings provide a\nrealistic assessment of what types of data current generative models can model,\nand highlight the need for more careful evaluation of generative models in new\ndomains. Our code is available at\nhttps://github.com/boyazeng/weight_memorization.", "comment": "Project page at https://boyazeng.github.io/weight_memorization", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.07998v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06400", "title": "ResPF: Residual Poisson Flow for Efficient and Physically Consistent Sparse-View CT Reconstruction", "authors": ["Changsheng Fang", "Yongtong Liu", "Bahareh Morovati", "Shuo Han", "Yu Shi", "Li Zhou", "Shuyi Fan", "Hengyong Yu"], "summary": "Sparse-view computed tomography (CT) is a practical solution to reduce\nradiation dose, but the resulting ill-posed inverse problem poses significant\nchallenges for accurate image reconstruction. Although deep learning and\ndiffusion-based methods have shown promising results, they often lack physical\ninterpretability or suffer from high computational costs due to iterative\nsampling starting from random noise. Recent advances in generative modeling,\nparticularly Poisson Flow Generative Models (PFGM), enable high-fidelity image\nsynthesis by modeling the full data distribution. In this work, we propose\nResidual Poisson Flow (ResPF) Generative Models for efficient and accurate\nsparse-view CT reconstruction. Based on PFGM++, ResPF integrates conditional\nguidance from sparse measurements and employs a hijacking strategy to\nsignificantly reduce sampling cost by skipping redundant initial steps.\nHowever, skipping early stages can degrade reconstruction quality and introduce\nunrealistic structures. To address this, we embed a data-consistency into each\niteration, ensuring fidelity to sparse-view measurements. Yet, PFGM sampling\nrelies on a fixed ordinary differential equation (ODE) trajectory induced by\nelectrostatic fields, which can be disrupted by step-wise data consistency,\nresulting in unstable or degraded reconstructions. Inspired by ResNet, we\nintroduce a residual fusion module to linearly combine generative outputs with\ndata-consistent reconstructions, effectively preserving trajectory continuity.\nTo the best of our knowledge, this is the first application of Poisson flow\nmodels to sparse-view CT. Extensive experiments on synthetic and clinical\ndatasets demonstrate that ResPF achieves superior reconstruction quality,\nfaster inference, and stronger robustness compared to state-of-the-art\niterative, learning-based, and diffusion models.", "comment": null, "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.06400v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08001", "title": "Reparameterized LLM Training via Orthogonal Equivalence Transformation", "authors": ["Zeju Qiu", "Simon Buchholz", "Tim Z. Xiao", "Maximilian Dax", "Bernhard Schölkopf", "Weiyang Liu"], "summary": "While large language models (LLMs) are driving the rapid advancement of\nartificial intelligence, effectively and reliably training these large models\nremains one of the field's most significant challenges. To address this\nchallenge, we propose POET, a novel reParameterized training algorithm that\nuses Orthogonal Equivalence Transformation to optimize neurons. Specifically,\nPOET reparameterizes each neuron with two learnable orthogonal matrices and a\nfixed random weight matrix. Because of its provable preservation of spectral\nproperties of weight matrices, POET can stably optimize the objective function\nwith improved generalization. We further develop efficient approximations that\nmake POET flexible and scalable for training large-scale neural networks.\nExtensive experiments validate the effectiveness and scalability of POET in\ntraining LLMs.", "comment": "Technical report v1 (36 pages, 24 figures, project page:\n  https://spherelab.ai/poet-site/)", "cate": "cs.LG", "url": "http://arxiv.org/abs/2506.08001v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.00654", "title": "Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection", "authors": ["Marco Di Gennaro", "Francesco Panebianco", "Marco Pianta", "Stefano Zanero", "Michele Carminati"], "summary": "Money laundering is a financial crime that poses a serious threat to\nfinancial integrity and social security. The growing number of transactions\nmakes it necessary to use automatic tools that help law enforcement agencies\ndetect such criminal activity. In this work, we present Amatriciana, a novel\napproach based on Graph Neural Networks to detect money launderers inside a\ngraph of transactions by considering temporal information. Amatriciana uses the\nwhole graph of transactions without splitting it into several time-based\nsubgraphs, exploiting all relational information in the dataset. Our\nexperiments on a public dataset reveal that the model can learn from a limited\namount of data. Furthermore, when more data is available, the model outperforms\nother State-of-the-art approaches; in particular, Amatriciana decreases the\nnumber of False Positives (FPs) while detecting many launderers. In summary,\nAmatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55%\nwith respect to other State-of-the-art models.", "comment": null, "cate": "cs.CR", "url": "http://arxiv.org/abs/2506.00654v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06870", "title": "Recursive Semantic Anchoring in ISO 639:2023: A Structural Extension to ISO/TC 37 Frameworks", "authors": ["Bugra Kilictas", "Faruk Alpay"], "summary": "ISO 639:2023 unifies the ISO language-code family and introduces contextual\nmetadata, but it lacks a machine-native mechanism for handling dialectal drift\nand creole mixtures. We propose a formalisation of recursive semantic\nanchoring, attaching to every language entity $\\chi$ a family of fixed-point\noperators $\\phi_{n,m}$ that model bounded semantic drift via the relation\n$\\phi_{n,m}(\\chi) = \\chi \\oplus \\Delta(\\chi)$, where $\\Delta(\\chi)$ is a drift\nvector in a latent semantic manifold. The base anchor $\\phi_{0,0}$ recovers the\ncanonical ISO 639:2023 identity, whereas $\\phi_{99,9}$ marks the maximal drift\nstate that triggers a deterministic fallback. Using category theory, we treat\nthe operators $\\phi_{n,m}$ as morphisms and drift vectors as arrows in a\ncategory $\\mathrm{DriftLang}$. A functor $\\Phi: \\mathrm{DriftLang} \\to\n\\mathrm{AnchorLang}$ maps every drifted object to its unique anchor and proves\nconvergence. We provide an RDF/Turtle schema (\\texttt{BaseLanguage},\n\\texttt{DriftedLanguage}, \\texttt{ResolvedAnchor}) and worked examples -- e.g.,\n$\\phi_{8,4}$ (Standard Mandarin) versus $\\phi_{8,7}$ (a colloquial variant),\nand $\\phi_{1,7}$ for Nigerian Pidgin anchored to English. Experiments with\ntransformer models show higher accuracy in language identification and\ntranslation on noisy or code-switched input when the $\\phi$-indices are used to\nguide fallback routing. The framework is compatible with ISO/TC 37 and provides\nan AI-tractable, drift-aware semantic layer for future standards.", "comment": "21 pages, no figures. Includes formal proofs, RDF/Turtle ontology\n  schema, {\\phi}-index disambiguation cases, and evaluation of\n  transformer-based AI models under semantic drift", "cate": "cs.LO", "url": "http://arxiv.org/abs/2506.06870v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06874", "title": "LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models", "authors": ["Ala Yankouskaya", "Areej B. Babiker", "Syeda W. F. Rizvi", "Sameha Alshakhsi", "Magnus Liebherr", "Raian Ali"], "summary": "There is growing interest in understanding how people interact with large\nlanguage models (LLMs) and whether such models elicit dependency or even\naddictive behaviour. Validated tools to assess the extent to which individuals\nmay become dependent on LLMs are scarce and primarily build on classic\nbehavioral addiction symptoms, adapted to the context of LLM use. We view this\nas a conceptual limitation, as the LLM-human relationship is more nuanced and\nwarrants a fresh and distinct perspective. To address this gap, we developed\nand validated a new 12-item questionnaire to measure LLM dependency, referred\nto as LLM-D12. The scale was based on the authors' prior theoretical work, with\nitems developed accordingly and responses collected from 526 participants in\nthe UK. Exploratory and confirmatory factor analyses, performed on separate\nhalves of the total sample using a split-sample approach, supported a\ntwo-factor structure: Instrumental Dependency (six items) and Relationship\nDependency (six items). Instrumental Dependency reflects the extent to which\nindividuals rely on LLMs to support or collaborate in decision-making and\ncognitive tasks. Relationship Dependency captures the tendency to perceive LLMs\nas socially meaningful, sentient, or companion-like entities. The two-factor\nstructure demonstrated excellent internal consistency and clear discriminant\nvalidity. External validation confirmed both the conceptual foundation and the\ndistinction between the two subscales. The psychometric properties and\nstructure of our LLM-D12 scale were interpreted in light of the emerging view\nthat dependency on LLMs does not necessarily indicate dysfunction but may still\nreflect reliance levels that could become problematic in certain contexts.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.06874v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06679", "title": "Controlled Reach-avoid Set Computation for Discrete-time Polynomial Systems via Convex Optimization", "authors": ["Taoran Wu", "Yiling Xue", "Dejin Ren", "Arvind Easwaran", "Martin Fränzle", "Bai Xue"], "summary": "This paper addresses the computation of controlled reach-avoid sets (CRASs)\nfor discrete-time polynomial systems subject to control inputs. A CRAS is a set\nencompassing initial states from which there exist control inputs driving the\nsystem into a target set while avoiding unsafe sets. However, efficiently\ncomputing CRASs remains an open problem, especially for discrete-time systems.\nIn this paper, we propose a novel framework for computing CRASs which takes\nadvantage of a probabilistic perspective. This framework transforms the\nfundamentally nonlinear problem of computing CRASs into a computationally\ntractable convex optimization problem. By regarding control inputs as\ndisturbances obeying certain probability distributions, a CRAS can be\nequivalently treated as a 0-reach-avoid set in the probabilistic sense, which\nconsists of initial states from which the probability of eventually entering\nthe target set while remaining within the safe set is greater than zero. Thus,\nwe can employ the convex optimization method of computing 0-reach-avoid sets to\nestimate CRASs. Furthermore, inspired by the $\\epsilon$-greedy strategy widely\nused in reinforcement learning, we propose an approach that iteratively updates\nthe aforementioned probability distributions imposed on control inputs to\ncompute larger CRASs. We demonstrate the effectiveness of the proposed method\non extensive examples.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06679v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06904", "title": "Can Biologically Plausible Temporal Credit Assignment Rules Match BPTT for Neural Similarity? E-prop as an Example", "authors": ["Yuhan Helena Liu", "Guangyu Robert Yang", "Christopher J. Cueva"], "summary": "Understanding how the brain learns may be informed by studying biologically\nplausible learning rules. These rules, often approximating gradient descent\nlearning to respect biological constraints such as locality, must meet two\ncritical criteria to be considered an appropriate brain model: (1) good\nneuroscience task performance and (2) alignment with neural recordings. While\nextensive research has assessed the first criterion, the second remains\nunderexamined. Employing methods such as Procrustes analysis on well-known\nneuroscience datasets, this study demonstrates the existence of a biologically\nplausible learning rule -- namely e-prop, which is based on gradient truncation\nand has demonstrated versatility across a wide range of tasks -- that can\nachieve neural data similarity comparable to Backpropagation Through Time\n(BPTT) when matched for task accuracy. Our findings also reveal that model\narchitecture and initial conditions can play a more significant role in\ndetermining neural similarity than the specific learning rule. Furthermore, we\nobserve that BPTT-trained models and their biologically plausible counterparts\nexhibit similar dynamical properties at comparable accuracies. These results\nunderscore the substantial progress made in developing biologically plausible\nlearning rules, highlighting their potential to achieve both competitive task\nperformance and neural data similarity.", "comment": null, "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06904v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06305", "title": "Template-Guided 3D Molecular Pose Generation via Flow Matching and Differentiable Optimization", "authors": ["Noémie Bergues", "Arthur Carré", "Paul Join-Lambert", "Brice Hoffmann", "Arnaud Blondel", "Hamza Tajmouati"], "summary": "Predicting the 3D conformation of small molecules within protein binding\nsites is a key challenge in drug design. When a crystallized reference ligand\n(template) is available, it provides geometric priors that can guide 3D pose\nprediction. We present a two-stage method for ligand conformation generation\nguided by such templates. In the first stage, we introduce a molecular\nalignment approach based on flow-matching to generate 3D coordinates for the\nligand, using the template structure as a reference. In the second stage, a\ndifferentiable pose optimization procedure refines this conformation based on\nshape and pharmacophore similarities, internal energy, and, optionally, the\nprotein binding pocket. We evaluate our approach on a new benchmark of ligand\npairs co-crystallized with the same target and show that it outperforms\nstandard docking tools and open-access alignment methods, especially in cases\ninvolving low similarity to the template or high ligand flexibility.", "comment": null, "cate": "q-bio.BM", "url": "http://arxiv.org/abs/2506.06305v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06930", "title": "DiscoSum: Discourse-aware News Summarization", "authors": ["Alexander Spangher", "Tenghao Huang", "Jialiang Gu", "Jiatong Shi", "Muhao Chen"], "summary": "Recent advances in text summarization have predominantly leveraged large\nlanguage models to generate concise summaries. However, language models often\ndo not maintain long-term discourse structure, especially in news articles,\nwhere organizational flow significantly influences reader engagement. We\nintroduce a novel approach to integrating discourse structure into\nsummarization processes, focusing specifically on news articles across various\nmedia. We present a novel summarization dataset where news articles are\nsummarized multiple times in different ways across different social media\nplatforms (e.g. LinkedIn, Facebook, etc.). We develop a novel news discourse\nschema to describe summarization structures and a novel algorithm, DiscoSum,\nwhich employs beam search technique for structure-aware summarization, enabling\nthe transformation of news stories to meet different stylistic and structural\ndemands. Both human and automatic evaluation results demonstrate the efficacy\nof our approach in maintaining narrative fidelity and meeting structural\nrequirements.", "comment": "8 pages, 3 figures, 10 pages in Appendix", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06930v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06308", "title": "Scientific machine learning in Hydrology: a unified perspective", "authors": ["Adoubi Vincent De Paul Adombi"], "summary": "Scientific machine learning (SciML) provides a structured approach to\nintegrating physical knowledge into data-driven modeling, offering significant\npotential for advancing hydrological research. In recent years, multiple\nmethodological families have emerged, including physics-informed machine\nlearning, physics-guided machine learning, hybrid physics-machine learning, and\ndata-driven physics discovery. Within each of these families, a proliferation\nof heterogeneous approaches has developed independently, often without\nconceptual coordination. This fragmentation complicates the assessment of\nmethodological novelty and makes it difficult to identify where meaningful\nadvances can still be made in the absence of a unified conceptual framework.\nThis review, the first focused overview of SciML in hydrology, addresses these\nlimitations by proposing a unified methodological framework for each SciML\nfamily, bringing together representative contributions into a coherent\nstructure that fosters conceptual clarity and supports cumulative progress in\nhydrological modeling. Finally, we highlight the limitations and future\nopportunities of each unified family to guide systematic research in hydrology,\nwhere these methods remain underutilized.", "comment": null, "cate": "physics.comp-ph", "url": "http://arxiv.org/abs/2506.06308v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06685", "title": "A robust finite element method for linearized magnetohydrodynamics on general domains", "authors": ["L. Beirao da Veiga", "C. Lovadina", "M. Trezzi"], "summary": "We propose a new finite element method for linearized Magnetohydrodynamics.\nThe main novelty is that the proposed scheme is able to handle also non-convex\ndomains and less regular solutions. The method is proved to be pressure robust\nand quasi-robust with respect to both fluid and magnetic Reynolds numbers.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06685v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06309", "title": "Leveraging Novel Ensemble Learning Techniques and Landsat Multispectral Data for Estimating Olive Yields in Tunisia", "authors": ["Mohamed Kefi", "Tien Dat Pham", "Thin Nguyen", "Mark G. Tjoelker", "Viola Devasirvatham", "Kenichi Kashiwagi"], "summary": "Olive production is an important tree crop in Mediterranean climates.\nHowever, olive yield varies significantly due to climate change. Accurately\nestimating yield using remote sensing and machine learning remains a complex\nchallenge. In this study, we developed a streamlined pipeline for olive yield\nestimation in the Kairouan and Sousse governorates of Tunisia. We extracted\nfeatures from multispectral reflectance bands, vegetation indices derived from\nLandsat-8 OLI and Landsat-9 OLI-2 satellite imagery, along with digital\nelevation model data. These spatial features were combined with ground-based\nfield survey data to form a structured tabular dataset. We then developed an\nautomated ensemble learning framework, implemented using AutoGluon to train and\nevaluate multiple machine learning models, select optimal combinations through\nstacking, and generate robust yield predictions using five-fold\ncross-validation. The results demonstrate strong predictive performance from\nboth sensors, with Landsat-8 OLI achieving R2 = 0.8635 and RMSE = 1.17 tons per\nha, and Landsat-9 OLI-2 achieving R2 = 0.8378 and RMSE = 1.32 tons per ha. This\nstudy highlights a scalable, cost-effective, and accurate method for olive\nyield estimation, with potential applicability across diverse agricultural\nregions globally.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06309v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06686", "title": "Learning Distribution-Wise Control in Representation Space for Language Models", "authors": ["Chunyuan Deng", "Ruidi Chang", "Hanjie Chen"], "summary": "Interventions in language models (LMs) are applied strategically to steer\nmodel behavior during the forward pass. Learnable interventions, also known as\nrepresentation fine-tuning, aim to apply pointwise control within the concept\nsubspace and have proven effective in altering high-level behaviors. In this\nwork, we extend this approach to the distribution level, enabling the model to\nlearn not only pointwise transformations but also the surrounding regions of\nthe concept subspace. We demonstrate that these methods perform effectively in\nearly layers, with larger standard deviations correlating strongly with\nimproved performance. Across eight commonsense reasoning and seven arithmetic\nreasoning benchmarks, our distribution-wise interventions consistently\noutperform pointwise interventions in controllability and robustness. These\nresults illustrate that distribution-wise interventions provide a more\ncomprehensive method for steering model behavior and enabling finer-grained\ncontrol over language models. The code is at:\n\\href{https://github.com/chili-lab/D-Intervention}{https://github.com/chili-lab/D-Intervention}.", "comment": "ICML 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06686v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06310", "title": "Enhancing Contrastive Learning-based Electrocardiogram Pretrained Model with Patient Memory Queue", "authors": ["Xiaoyu Sun", "Yang Yang", "Xunde Dong"], "summary": "In the field of automatic Electrocardiogram (ECG) diagnosis, due to the\nrelatively limited amount of labeled data, how to build a robust ECG pretrained\nmodel based on unlabeled data is a key area of focus for researchers. Recent\nadvancements in contrastive learning-based ECG pretrained models highlight the\npotential of exploiting the additional patient-level self-supervisory signals\ninherent in ECG. They are referred to as patient contrastive learning. Its\nrationale is that multiple physical recordings from the same patient may share\ncommonalities, termed patient consistency, so redefining positive and negative\npairs in contrastive learning as intrapatient and inter-patient samples\nprovides more shared context to learn an effective representation. However,\nthese methods still fail to efficiently exploit patient consistency due to the\ninsufficient amount of intra-inter patient samples existing in a batch. Hence,\nwe propose a contrastive learning-based ECG pretrained model enhanced by the\nPatient Memory Queue (PMQ), which incorporates a large patient memory queue to\nmitigate model degeneration that can arise from insufficient intra-inter\npatient samples. In order to further enhance the performance of the pretrained\nmodel, we introduce two extra data augmentation methods to provide more\nperspectives of positive and negative pairs for pretraining. Extensive\nexperiments were conducted on three public datasets with three different data\nratios. The experimental results show that the comprehensive performance of our\nmethod outperforms previous contrastive learning methods and exhibits greater\nrobustness in scenarios with limited labeled data. The code is available at\nhttps://github.com/3hiuwoo/PMQ.", "comment": "8 pages, 4 figures", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06310v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06687", "title": "Optimizing Battery and Line Undergrounding Investments for Transmission Systems under Wildfire Risk Scenarios: A Benders Decomposition Approach", "authors": ["Ryan Piansky", "Rahul K. Gupta", "Daniel K. Molzahn"], "summary": "With electric power infrastructure posing an increasing risk of igniting\nwildfires under continuing climate change, utilities are frequently\nde-energizing power lines to mitigate wildfire ignition risk, which can cause\nload shedding. Recent research advocates for installing battery energy storage\nsystems as well as undergrounding risky overhead lines to reduce the load\nshedding during such de-energizations. Since wildfire ignition risk can exhibit\nsubstantial geographic and temporal variations, it is important to plan battery\ninstallation and line undergrounding investments while considering multiple\npossible scenarios. This paper presents a scenario-based framework for\noptimizing battery installation and line undergrounding investments while\nconsidering many scenarios, each consisting of a day-long time series of\nuncertain parameters for the load demand, renewable generation, and wildfire\nignition risks. This problem is difficult to solve due to a large number of\nscenarios and binary variables associated with the battery placements as well\nas the lines to be undergrounded. To address the computational challenges, we\ndecompose the problem in a two-stage scheme via a Benders decomposition\napproach. The first stage is a master problem formulated as a mixed integer\nlinear programming (MILP) model that makes decisions on the locations and sizes\nof batteries as well as the lines to be undergrounded. The second stage\nconsists of a linear programming model that assesses these battery and line\nundergrounding decisions as modeled by a DC OPF formulation. We demonstrate the\neffectiveness of the proposed scheme on a large-scale transmission network with\nreal world data on wildfire ignition risks, load, and renewable generation.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06687v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06311", "title": "A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration", "authors": ["Meiyan Kang", "Shizuo Kaji", "Sang-Yun Lee", "Taegon Kim", "Hee-Hwan Ryu", "Suyoung Choi"], "summary": "Ground Penetrating Radar (GPR) is a widely used Non-Destructive Testing (NDT)\ntechnique for subsurface exploration, particularly in infrastructure inspection\nand maintenance. However, conventional interpretation methods are often limited\nby noise sensitivity and a lack of structural awareness. This study presents a\nnovel framework that enhances the detection of underground utilities,\nespecially pipelines, by integrating shape-aware topological features derived\nfrom B-scan GPR images using Topological Data Analysis (TDA), with the spatial\ndetection capabilities of the YOLOv5 deep neural network (DNN). We propose a\nnovel shape-aware topological representation that amplifies structural features\nin the input data, thereby improving the model's responsiveness to the\ngeometrical features of buried objects. To address the scarcity of annotated\nreal-world data, we employ a Sim2Real strategy that generates diverse and\nrealistic synthetic datasets, effectively bridging the gap between simulated\nand real-world domains. Experimental results demonstrate significant\nimprovements in mean Average Precision (mAP), validating the robustness and\nefficacy of our approach. This approach underscores the potential of\nTDA-enhanced learning in achieving reliable, real-time subsurface object\ndetection, with broad applications in urban planning, safety inspection, and\ninfrastructure management.", "comment": "15 pages, 6 figures", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06311v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06955", "title": "BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning", "authors": ["Ha-Thanh Nguyen", "Chaoran Liu", "Hirokazu Kiyomaru", "Koichi Takeda", "Yusuke Miyao", "Maki Matsuda", "Yusuke Oda", "Pontus Stenetorp", "Qianying Liu", "Su Myat Noe", "Hideyuki Tachibana", "Kouta Nakayama", "Sadao Kurohashi"], "summary": "We present BIS Reasoning 1.0, the first large-scale Japanese dataset of\nsyllogistic reasoning problems explicitly designed to evaluate\nbelief-inconsistent reasoning in large language models (LLMs). Unlike prior\ndatasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned\nreasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent\nsyllogisms to uncover reasoning biases in LLMs trained on human-aligned\ncorpora. We benchmark state-of-the-art models - including GPT models, Claude\nmodels, and leading Japanese LLMs - revealing significant variance in\nperformance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies\ncritical weaknesses in current LLMs when handling logically valid but\nbelief-conflicting inputs. These findings have important implications for\ndeploying LLMs in high-stakes domains such as law, healthcare, and scientific\nliterature, where truth must override intuitive belief to ensure integrity and\nsafety.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06955v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06689", "title": "A Fast and Lightweight Model for Causal Audio-Visual Speech Separation", "authors": ["Wendi Sang", "Kai Li", "Runxuan Yang", "Jianqiang Huang", "Xiaolin Hu"], "summary": "Audio-visual speech separation (AVSS) aims to extract a target speech signal\nfrom a mixed signal by leveraging both auditory and visual (lip movement) cues.\nHowever, most existing AVSS methods exhibit complex architectures and rely on\nfuture context, operating offline, which renders them unsuitable for real-time\napplications. Inspired by the pipeline of RTFSNet, we propose a novel streaming\nAVSS model, named Swift-Net, which enhances the causal processing capabilities\nrequired for real-time applications. Swift-Net adopts a lightweight visual\nfeature extraction module and an efficient fusion module for audio-visual\nintegration. Additionally, Swift-Net employs Grouped SRUs to integrate\nhistorical information across different feature spaces, thereby improving the\nutilization efficiency of historical information. We further propose a causal\ntransformation template to facilitate the conversion of non-causal AVSS models\ninto causal counterparts. Experiments on three standard benchmark datasets\n(LRS2, LRS3, and VoxCeleb2) demonstrated that under causal conditions, our\nproposed Swift-Net exhibited outstanding performance, highlighting the\npotential of this method for processing speech in complex environments.", "comment": "8 pages, 5 figures", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.06689v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06323", "title": "Composite Reward Design in PPO-Driven Adaptive Filtering", "authors": ["Abdullah Burkan Bereketoglu"], "summary": "Model-free and reinforcement learning-based adaptive filtering methods are\ngaining traction for denoising in dynamic, non-stationary environments such as\nwireless signal channels. Traditional filters like LMS, RLS, Wiener, and Kalman\nare limited by assumptions of stationary or requiring complex fine-tuning or\nexact noise statistics or fixed models. This letter proposes an adaptive\nfiltering framework using Proximal Policy Optimization (PPO), guided by a\ncomposite reward that balances SNR improvement, MSE reduction, and residual\nsmoothness. Experiments on synthetic signals with various noise types show that\nour PPO agent generalizes beyond its training distribution, achieving real-time\nperformance and outperforming classical filters. This work demonstrates the\nviability of policy-gradient reinforcement learning for robust, low-latency\nadaptive signal filtering.", "comment": "5 pages, 9 figures, 1 table, , Keywords: Adaptive filtering,\n  reinforcement learning, PPO, noise reduction, signal denoising", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06323v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06342", "title": "Uncertainty-Aware Multi-view Arrhythmia Classification from ECG", "authors": ["Mohd Ashhad", "Sana Rahmani", "Mohammed Fayiz", "Ali Etemad", "Javad Hashemi"], "summary": "We propose a deep neural architecture that performs uncertainty-aware\nmulti-view classification of arrhythmia from ECG. Our method learns two\ndifferent views (1D and 2D) of single-lead ECG to capture different types of\ninformation. We use a fusion technique to reduce the conflict between the\ndifferent views caused by noise and artifacts in ECG data, thus incorporating\nuncertainty to obtain stronger final predictions. Our framework contains the\nfollowing three modules (1) a time-series module to learn the morphological\nfeatures from ECG; (2) an image-space learning module to learn the\nspatiotemporal features; and (3) the uncertainty-aware fusion module to fuse\nthe information from the two different views. Experimental results on two\nreal-world datasets demonstrate that our framework not only improves the\nperformance on arrhythmia classification compared to the state-of-the-art but\nalso shows better robustness to noise and artifacts present in ECG.", "comment": "This paper has been accepted to IJCNN 2024 conference", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06342v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06998", "title": "What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding", "authors": ["Ming Li", "Zhengyuan Yang", "Xiyao Wang", "Dianqi Li", "Kevin Lin", "Tianyi Zhou", "Lijuan Wang"], "summary": "Large reasoning models (LRMs) achieve strong reasoning performance by\nemitting long chains of thought. Yet, these verbose traces slow down inference\nand often drift into unnecessary detail, known as the overthinking phenomenon.\nTo better understand LRMs' behavior, we systematically analyze the token-level\nmisalignment between reasoning and non-reasoning models. While it is expected\nthat their primary difference lies in the stylistic \"thinking cues\", LRMs\nuniquely exhibit two pivotal, previously under-explored phenomena: a Global\nMisalignment Rebound, where their divergence from non-reasoning models persists\nor even grows as response length increases, and more critically, a Local\nMisalignment Diminish, where the misalignment concentrates at the \"thinking\ncues\" each sentence starts with but rapidly declines in the remaining of the\nsentence. Motivated by the Local Misalignment Diminish, we propose\nFoReaL-Decoding, a collaborative fast-slow thinking decoding method for\ncost-quality trade-off. In FoReaL-Decoding, a Leading model leads the first few\ntokens for each sentence, and then a weaker draft model completes the following\ntokens to the end of each sentence. FoReaL-Decoding adopts a stochastic gate to\nsmoothly interpolate between the small and the large model. On four popular\nmath-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23),\nFoReaL-Decoding reduces theoretical FLOPs by 30 to 50% and trims CoT length by\nup to 40%, while preserving 86 to 100% of model performance. These results\nestablish FoReaL-Decoding as a simple, plug-and-play route to controllable\ncost-quality trade-offs in reasoning-centric tasks.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06998v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06890", "title": "SPC to 3D: Novel View Synthesis from Binary SPC via I2I translation", "authors": ["Sumit Sharma", "Gopi Raju Matta", "Kaushik Mitra"], "summary": "Single Photon Avalanche Diodes (SPADs) represent a cutting-edge imaging\ntechnology, capable of detecting individual photons with remarkable timing\nprecision. Building on this sensitivity, Single Photon Cameras (SPCs) enable\nimage capture at exceptionally high speeds under both low and high\nillumination. Enabling 3D reconstruction and radiance field recovery from such\nSPC data holds significant promise. However, the binary nature of SPC images\nleads to severe information loss, particularly in texture and color, making\ntraditional 3D synthesis techniques ineffective. To address this challenge, we\npropose a modular two-stage framework that converts binary SPC images into\nhigh-quality colorized novel views. The first stage performs image-to-image\n(I2I) translation using generative models such as Pix2PixHD, converting binary\nSPC inputs into plausible RGB representations. The second stage employs 3D\nscene reconstruction techniques like Neural Radiance Fields (NeRF) or Gaussian\nSplatting (3DGS) to generate novel views. We validate our two-stage pipeline\n(Pix2PixHD + Nerf/3DGS) through extensive qualitative and quantitative\nexperiments, demonstrating significant improvements in perceptual quality and\ngeometric consistency over the alternative baseline.", "comment": "Accepted for publication at ICIP 2025", "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.06890v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06346", "title": "LD-RPMNet: Near-Sensor Diagnosis for Railway Point Machines", "authors": ["Wei Li", "Xiaochun Wu", "Xiaoxi Hu", "Yuxuan Zhang", "Sebastian Bader", "Yuhan Huang"], "summary": "Near-sensor diagnosis has become increasingly prevalent in industry. This\nstudy proposes a lightweight model named LD-RPMNet that integrates Transformers\nand Convolutional Neural Networks, leveraging both local and global feature\nextraction to optimize computational efficiency for a practical railway\napplication. The LD-RPMNet introduces a Multi-scale Depthwise Separable\nConvolution (MDSC) module, which decomposes cross-channel convolutions into\npointwise and depthwise convolutions while employing multi-scale kernels to\nenhance feature extraction. Meanwhile, a Broadcast Self-Attention (BSA)\nmechanism is incorporated to simplify complex matrix multiplications and\nimprove computational efficiency. Experimental results based on collected sound\nsignals during the operation of railway point machines demonstrate that the\noptimized model reduces parameter count and computational complexity by 50%\nwhile improving diagnostic accuracy by nearly 3%, ultimately achieving an\naccuracy of 98.86%. This demonstrates the possibility of near-sensor fault\ndiagnosis applications in railway point machines.", "comment": "This paper is accepted for IEEE Sensors Applcations Symposium (SAS)\n  2025", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06346v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06704", "title": "Dynamic and Parametric Retrieval-Augmented Generation", "authors": ["Weihang Su", "Qingyao Ai", "Jingtao Zhan", "Qian Dong", "Yiqun Liu"], "summary": "Retrieval-Augmented Generation (RAG) has become a foundational paradigm for\nequipping large language models (LLMs) with external knowledge, playing a\ncritical role in information retrieval and knowledge-intensive applications.\nHowever, conventional RAG systems typically adopt a static\nretrieve-then-generate pipeline and rely on in-context knowledge injection,\nwhich can be suboptimal for complex tasks that require multihop reasoning,\nadaptive information access, and deeper integration of external knowledge.\nMotivated by these limitations, the research community has moved beyond static\nretrieval and in-context knowledge injection. Among the emerging directions,\nthis tutorial delves into two rapidly growing and complementary research areas\non RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when\nand what to retrieve during the LLM's generation process, enabling real-time\nadaptation to the LLM's evolving information needs. Parametric RAG rethinks how\nretrieved knowledge should be injected into LLMs, transitioning from\ninput-level to parameter-level knowledge injection for enhanced efficiency and\neffectiveness. This tutorial offers a comprehensive overview of recent advances\nin these emerging research areas. It also shares theoretical foundations and\npractical insights to support and inspire further research in RAG.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06704v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07008", "title": "Deep regularization networks for inverse problems with noisy operators", "authors": ["Fatemeh Pourahmadian", "Yang Xu"], "summary": "A supervised learning approach is proposed for regularization of large\ninverse problems where the main operator is built from noisy data. This is\ngermane to superresolution imaging via the sampling indicators of the inverse\nscattering theory. We aim to accelerate the spatiotemporal regularization\nprocess for this class of inverse problems to enable real-time imaging. In this\napproach, a neural operator maps each pattern on the right-hand side of the\nscattering equation to its affiliated regularization parameter. The network is\ntrained in two steps which entails: (1) training on low-resolution\nregularization maps furnished by the Morozov discrepancy principle with\nnonoptimal thresholds, and (2) optimizing network predictions through\nminimization of the Tikhonov loss function regulated by the validation loss.\nStep 2 allows for tailoring of the approximate maps of Step 1 toward\nconstruction of higher quality images. This approach enables direct learning\nfrom test data and dispenses with the need for a-priori knowledge of the\noptimal regularization maps. The network, trained on low-resolution data,\nquickly generates dense regularization maps for high-resolution imaging. We\nhighlight the importance of the training loss function on the network's\ngeneralizability. In particular, we demonstrate that networks informed by the\nlogic of discrepancy principle lead to images of higher contrast. In this case,\nthe training process involves many-objective optimization. We propose a new\nmethod to adaptively select the appropriate loss weights during training\nwithout requiring an additional optimization process. The proposed approach is\nsynthetically examined for imaging damage evolution in an elastic plate. The\nresults indicate that the discrepancy-informed regularization networks not only\naccelerate the imaging process, but also remarkably enhance the image quality\nin complex environments.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07008v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06348", "title": "Multi-Platform Methane Plume Detection via Model and Domain Adaptation", "authors": ["Vassiliki Mancoridis", "Brian Bue", "Jake H. Lee", "Andrew K. Thorpe", "Daniel Cusworth", "Alana Ayasse", "Philip G. Brodrick", "Riley Duren"], "summary": "Prioritizing methane for near-term climate action is crucial due to its\nsignificant impact on global warming. Previous work used columnwise matched\nfilter products from the airborne AVIRIS-NG imaging spectrometer to detect\nmethane plume sources; convolutional neural networks (CNNs) discerned\nanthropogenic methane plumes from false positive enhancements. However, as an\nincreasing number of remote sensing platforms are used for methane plume\ndetection, there is a growing need to address cross-platform alignment. In this\nwork, we describe model- and data-driven machine learning approaches that\nleverage airborne observations to improve spaceborne methane plume detection,\nreconciling the distributional shifts inherent with performing the same task\nacross platforms. We develop a spaceborne methane plume classifier using data\nfrom the EMIT imaging spectroscopy mission. We refine classifiers trained on\nairborne imagery from AVIRIS-NG campaigns using transfer learning,\noutperforming the standalone spaceborne model. Finally, we use CycleGAN, an\nunsupervised image-to-image translation technique, to align the data\ndistributions between airborne and spaceborne contexts. Translating spaceborne\nEMIT data to the airborne AVIRIS-NG domain using CycleGAN and applying airborne\nclassifiers directly yields the best plume detection results. This methodology\nis useful not only for data simulation, but also for direct data alignment.\nThough demonstrated on the task of methane plume detection, our work more\nbroadly demonstrates a data-driven approach to align related products obtained\nfrom distinct remote sensing instruments.", "comment": "12 pages 8 figures. In review", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06348v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06938", "title": "Experimental Evaluation of Static Image Sub-Region-Based Search Models Using CLIP", "authors": ["Bastian Jäckl", "Vojtěch Kloda", "Daniel A. Keim", "Jakub Lokoč"], "summary": "Advances in multimodal text-image models have enabled effective text-based\nquerying in extensive image collections. While these models show convincing\nperformance for everyday life scenes, querying in highly homogeneous,\nspecialized domains remains challenging. The primary problem is that users can\noften provide only vague textual descriptions as they lack expert knowledge to\ndiscriminate between homogenous entities. This work investigates whether adding\nlocation-based prompts to complement these vague text queries can enhance\nretrieval performance. Specifically, we collected a dataset of 741 human\nannotations, each containing short and long textual descriptions and bounding\nboxes indicating regions of interest in challenging underwater scenes. Using\nthese annotations, we evaluate the performance of CLIP when queried on various\nstatic sub-regions of images compared to the full image. Our results show that\nboth a simple 3-by-3 partitioning and a 5-grid overlap significantly improve\nretrieval effectiveness and remain robust to perturbations of the annotation\nbox.", "comment": "14 pages, 4 figures, 2 tables", "cate": "cs.MM", "url": "http://arxiv.org/abs/2506.06938v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06708", "title": "A Survey of Retentive Network", "authors": ["Haiqi Yang", "Zhiyuan Li", "Yi Chang", "Yuan Wu"], "summary": "Retentive Network (RetNet) represents a significant advancement in neural\nnetwork architecture, offering an efficient alternative to the Transformer.\nWhile Transformers rely on self-attention to model dependencies, they suffer\nfrom high memory costs and limited scalability when handling long sequences due\nto their quadratic complexity. To mitigate these limitations, RetNet introduces\na retention mechanism that unifies the inductive bias of recurrence with the\nglobal dependency modeling of attention. This mechanism enables linear-time\ninference, facilitates efficient modeling of extended contexts, and remains\ncompatible with fully parallelizable training pipelines. RetNet has garnered\nsignificant research interest due to its consistently demonstrated cross-domain\neffectiveness, achieving robust performance across machine learning paradigms\nincluding natural language processing, speech recognition, and time-series\nanalysis. However, a comprehensive review of RetNet is still missing from the\ncurrent literature. This paper aims to fill that gap by offering the first\ndetailed survey of the RetNet architecture, its key innovations, and its\ndiverse applications. We also explore the main challenges associated with\nRetNet and propose future research directions to support its continued\nadvancement in both academic research and practical deployment.", "comment": "15 pages, 3 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06708v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07023", "title": "Optimal Transport Driven Asymmetric Image-to-Image Translation for Nuclei Segmentation of Histological Images", "authors": ["Suman Mahapatra", "Pradipta Maji"], "summary": "Segmentation of nuclei regions from histological images enables morphometric\nanalysis of nuclei structures, which in turn helps in the detection and\ndiagnosis of diseases under consideration. To develop a nuclei segmentation\nalgorithm, applicable to different types of target domain representations,\nimage-to-image translation networks can be considered as they are invariant to\ntarget domain image representations. One of the important issues with\nimage-to-image translation models is that they fail miserably when the\ninformation content between two image domains are asymmetric in nature. In this\nregard, the paper introduces a new deep generative model for segmenting nuclei\nstructures from histological images. The proposed model considers an embedding\nspace for handling information-disparity between information-rich histological\nimage space and information-poor segmentation map domain. Integrating\njudiciously the concepts of optimal transport and measure theory, the model\ndevelops an invertible generator, which provides an efficient optimization\nframework with lower network complexity. The concept of invertible generator\nautomatically eliminates the need of any explicit cycle-consistency loss. The\nproposed model also introduces a spatially-constrained squeeze operation within\nthe framework of invertible generator to maintain spatial continuity within the\nimage patches. The model provides a better trade-off between network complexity\nand model performance compared to other existing models having complex network\narchitectures. The performance of the proposed deep generative model, along\nwith a comparison with state-of-the-art nuclei segmentation methods, is\ndemonstrated on publicly available histological image data sets.", "comment": "13 pages, 8 figures", "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07023v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07028", "title": "SiliCoN: Simultaneous Nuclei Segmentation and Color Normalization of Histological Images", "authors": ["Suman Mahapatra", "Pradipta Maji"], "summary": "Segmentation of nuclei regions from histological images is an important task\nfor automated computer-aided analysis of histological images, particularly in\nthe presence of impermissible color variation in the color appearance of\nstained tissue images. While color normalization enables better nuclei\nsegmentation, accurate segmentation of nuclei structures makes color\nnormalization rather trivial. In this respect, the paper proposes a novel deep\ngenerative model for simultaneously segmenting nuclei structures and\nnormalizing color appearance of stained histological images.This model\njudiciously integrates the merits of truncated normal distribution and spatial\nattention. The model assumes that the latent color appearance information,\ncorresponding to a particular histological image, is independent of respective\nnuclei segmentation map as well as embedding map information. The disentangled\nrepresentation makes the model generalizable and adaptable as the modification\nor loss in color appearance information cannot be able to affect the nuclei\nsegmentation map as well as embedding information. Also, for dealing with the\nstain overlap of associated histochemical reagents, the prior for latent color\nappearance code is assumed to be a mixture of truncated normal distributions.\nThe proposed model incorporates the concept of spatial attention for\nsegmentation of nuclei regions from histological images. The performance of the\nproposed approach, along with a comparative analysis with related\nstate-of-the-art algorithms, has been demonstrated on publicly available\nstandard histological image data sets.", "comment": "10 pages, 9 figures", "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07028v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06360", "title": "Towards Generalizable Drowsiness Monitoring with Physiological Sensors: A Preliminary Study", "authors": ["Jiyao Wang", "Suzan Ayas", "Jiahao Zhang", "Xiao Wen", "Dengbo He", "Birsen Donmez"], "summary": "Accurately detecting drowsiness is vital to driving safety. Among all\nmeasures, physiological-signal-based drowsiness monitoring can be more\nprivacy-preserving than a camera-based approach. However, conflicts exist\nregarding how physiological metrics are associated with different drowsiness\nlabels across datasets. Thus, we analyzed key features from electrocardiograms\n(ECG), electrodermal activity (EDA), and respiratory (RESP) signals across four\ndatasets, where different drowsiness inducers (such as fatigue and low arousal)\nand assessment methods (subjective vs. objective) were used. Binary logistic\nregression models were built to identify the physiological metrics that are\nassociated with drowsiness. Findings indicate that distinct different\ndrowsiness inducers can lead to different physiological responses, and\nobjective assessments were more sensitive than subjective ones in detecting\ndrowsiness. Further, the increased heart rate stability, reduced respiratory\namplitude, and decreased tonic EDA are robustly associated with increased\ndrowsiness. The results enhance understanding of drowsiness detection and can\ninform future generalizable monitoring designs.", "comment": "Accepted by HFES2025", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06360v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07032", "title": "A Culturally-diverse Multilingual Multimodal Video Benchmark & Model", "authors": ["Bhuiyan Sanjid Shafique", "Ashmal Vayani", "Muhammad Maaz", "Hanoona Abdul Rasheed", "Dinura Dissanayake", "Mohammed Irfan Kurpath", "Yahya Hmaiti", "Go Inoue", "Jean Lahoud", "Md. Safirur Rashid", "Shadid Intisar Quasem", "Maheen Fatima", "Franco Vidal", "Mykola Maslych", "Ketan Pravin More", "Sanoojan Baliah", "Hasindri Watawana", "Yuhao Li", "Fabian Farestam", "Leon Schaller", "Roman Tymtsiv", "Simon Weber", "Hisham Cholakkal", "Ivan Laptev", "Shin'ichi Satoh", "Michael Felsberg", "Mubarak Shah", "Salman Khan", "Fahad Shahbaz Khan"], "summary": "Large multimodal models (LMMs) have recently gained attention due to their\neffectiveness to understand and generate descriptions of visual content. Most\nexisting LMMs are in English language. While few recent works explore\nmultilingual image LMMs, to the best of our knowledge, moving beyond the\nEnglish language for cultural and linguistic inclusivity is yet to be\ninvestigated in the context of video LMMs. In pursuit of more inclusive video\nLMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, to\nevaluate Video LMMs across 14 languages, including both low- and high-resource\nlanguages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,\nBengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench is\ndesigned to rigorously test video LMMs across 15 categories including eight\nculturally diverse categories, ranging from lifestyles and festivals to foods\nand rituals and from local landmarks to prominent cultural personalities.\nViMUL-Bench comprises both open-ended (short and long-form) and multiple-choice\nquestions spanning various video durations (short, medium, and long) with 8k\nsamples that are manually verified by native language speakers. In addition, we\nalso introduce a machine translated multilingual video training set comprising\n1.2 million samples and develop a simple multilingual video LMM, named ViMUL,\nthat is shown to provide a better tradeoff between high-and low-resource\nlanguages for video understanding. We hope our ViMUL-Bench and multilingual\nvideo LMM along with a large-scale multilingual video training set will help\nease future research in developing cultural and linguistic inclusive\nmultilingual video LMMs. Our proposed benchmark, video LMM and training data\nwill be publicly released at https://mbzuai-oryx.github.io/ViMUL/.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07032v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07035", "title": "AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization", "authors": ["Zixuan Jiang", "Renjing Xu"], "summary": "Deciphering protein function remains a fundamental challenge in protein\nrepresentation learning. The task presents significant difficulties for protein\nlanguage models (PLMs) due to the sheer volume of functional annotation\ncategories and the highly imbalanced distribution of annotated instances across\nbiological ontologies. Inspired by the remarkable success of reinforcement\nlearning from human feedback (RLHF) in large language model (LLM) alignment, we\npropose AnnoDPO, a novel multi-modal framework for protein function prediction\nthat leverages Direct Preference Optimization (DPO) to enhance annotation\nlearning. Our methodology addresses the dual challenges of annotation scarcity\nand category imbalance through preference-aligned training objectives,\nestablishing a new paradigm for biological knowledge integration in protein\nrepresentation learning.", "comment": null, "cate": "q-bio.BM", "url": "http://arxiv.org/abs/2506.07035v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06716", "title": "#P is Sandwiched by One and Two #2DNF Calls: Is Subtraction Stronger Than We Thought?", "authors": ["Max Bannach", "Erik D. Demaine", "Timothy Gomez", "Markus Hecher"], "summary": "The canonical class in the realm of counting complexity is #P. It is well\nknown that the problem of counting the models of a propositional formula in\ndisjunctive normal form (#DNF) is complete for #P under Turing reductions. On\nthe other hand, #DNF $\\in$ spanL and spanL $\\not\\subseteq$ #P unless NL = NP.\nHence, the class of functions logspace-reducible to #DNF is a strict subset of\n#P under plausible complexity-theoretic assumptions. By contrast, we show that\ntwo calls to a (restricted) #2DNF oracle suffice to capture gapP, namely, that\nthe logspace many-one closure of the subtraction between the results of two\n#2DNF calls is gapP. Because #P $\\not\\subseteq$ gapP, #P is strictly contained\nbetween one and two #2DNF oracle calls.\n  Surprisingly, the propositional formulas needed in both calls are linear-time\ncomputable, and the reduction preserves interesting structural as well as\nsymmetry properties, leading to algorithmic applications. We show that a single\nsubtraction suffices to compensate for the absence of negation while still\ncapturing gapP, i.e., our results carry over to the monotone fragments of #2SAT\nand #2DNF. Since our reduction is linear-time, it preserves sparsity and, as a\nconsequence we obtain a sparsification lemma for both #2SAT and #2DNF. This has\nonly been known for kSAT with k $\\geq$ 3 and respective counting versions. We\nfurther show that both #2DNF calls can be combined into a single call if we\nallow a little postprocessing (computable by AC0- or TC0-circuits).\nConsequently, we derive refined versions of Toda's Theorem: PH $\\subseteq$\n[#MON2SAT]$^{log}_{TC0}$ = [#MON2DNF]$^{log}_{TC0}$ and PH $\\subseteq$\n[#IMPL2SAT]$^{log}_{AC0}$. Our route to these results is via structure-aware\nreductions that preserve parameters like treewidth up to an additive overhead.\nThe absence of multiplicative overhead indeed yields parameterized SETH-tight\nlower bounds.", "comment": null, "cate": "cs.CC", "url": "http://arxiv.org/abs/2506.06716v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07044", "title": "Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning", "authors": ["LASA Team", "Weiwen Xu", "Hou Pong Chan", "Long Li", "Mahani Aljunied", "Ruifeng Yuan", "Jianyu Wang", "Chenghao Xiao", "Guizhen Chen", "Chaoqun Liu", "Zhaodonghui Li", "Yu Sun", "Junao Shen", "Chaojun Wang", "Jie Tan", "Deli Zhao", "Tingyang Xu", "Hao Zhang", "Yu Rong"], "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities in understanding common visual elements, largely due to their\nlarge-scale datasets and advanced training strategies. However, their\neffectiveness in medical applications remains limited due to the inherent\ndiscrepancies between data and tasks in medical scenarios and those in the\ngeneral domain. Concretely, existing medical MLLMs face the following critical\nlimitations: (1) limited coverage of medical knowledge beyond imaging, (2)\nheightened susceptibility to hallucinations due to suboptimal data curation\nprocesses, (3) lack of reasoning capabilities tailored for complex medical\nscenarios. To address these challenges, we first propose a comprehensive data\ncuration procedure that (1) efficiently acquires rich medical knowledge data\nnot only from medical imaging but also from extensive medical texts and\ngeneral-domain data; and (2) synthesizes accurate medical captions, visual\nquestion answering (VQA), and reasoning samples. As a result, we build a\nmultimodal dataset enriched with extensive medical knowledge. Building on the\ncurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu\nundergoes multi-stage training to embed medical expertise and enhance its\ntask-solving capabilities progressively. Besides, we preliminarily explore the\npotential of applying reinforcement learning with verifiable rewards paradigm\nto enhance Lingshu's medical reasoning ability. Additionally, we develop\nMedEvalKit, a unified evaluation framework that consolidates leading multimodal\nand textual medical benchmarks for standardized, fair, and efficient model\nassessment. We evaluate the performance of Lingshu on three fundamental medical\ntasks, multimodal QA, text-based QA, and medical report generation. The results\nshow that Lingshu consistently outperforms the existing open-source multimodal\nmodels on most tasks ...", "comment": "Technical Report, 53 pages, 25 tables, and 16 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07044v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06363", "title": "ChemGraph: An Agentic Framework for Computational Chemistry Workflows", "authors": ["Thang D. Pham", "Aditya Tanikanti", "Murat Keçeli"], "summary": "Atomistic simulations are essential tools in chemistry and materials science,\naccelerating the discovery of novel catalysts, energy storage materials, and\npharmaceuticals. However, running these simulations remains challenging due to\nthe wide range of computational methods, diverse software ecosystems, and the\nneed for expert knowledge and manual effort for the setup, execution, and\nvalidation stages. In this work, we present ChemGraph, an agentic framework\npowered by artificial intelligence and state-of-the-art simulation tools to\nstreamline and automate computational chemistry and materials science\nworkflows. ChemGraph leverages graph neural network-based foundation models for\naccurate yet computationally efficient calculations and large language models\n(LLMs) for natural language understanding, task planning, and scientific\nreasoning to provide an intuitive and interactive interface. Users can perform\ntasks such as molecular structure generation, single-point energy, geometry\noptimization, vibrational analysis, and thermochemistry calculations with\nmethods ranging from tight-binding and machine learning interatomic potentials\nto density functional theory or wave function theory-based methods. We evaluate\nChemGraph across 13 benchmark tasks and demonstrate that smaller LLMs\n(GPT-4o-mini, Claude-3.5-haiku, Qwen2.5-14B) perform well on simple workflows,\nwhile more complex tasks benefit from using larger models like GPT-4o.\nImportantly, we show that decomposing complex tasks into smaller subtasks\nthrough a multi-agent framework enables smaller LLM models to match or exceed\nGPT-4o's performance in specific scenarios.", "comment": null, "cate": "physics.chem-ph", "url": "http://arxiv.org/abs/2506.06363v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07180", "title": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "authors": ["Wenrui Zhou", "Shu Yang", "Qingsong Yang", "Zikun Guo", "Lijie Hu", "Di Wang"], "summary": "As video large language models (Video-LLMs) become increasingly integrated\ninto real-world applications that demand grounded multimodal reasoning,\nensuring their factual consistency and reliability is of critical importance.\nHowever, sycophancy, the tendency of these models to align with user input even\nwhen it contradicts the visual evidence, undermines their trustworthiness in\nsuch contexts. Current sycophancy research has largely overlooked its specific\nmanifestations in the video-language domain, resulting in a notable absence of\nsystematic benchmarks and targeted evaluations to understand how Video-LLMs\nrespond under misleading user input. To fill this gap, we propose VISE\n(Video-LLM Sycophancy Benchmarking and Evaluation), the first dedicated\nbenchmark designed to evaluate sycophantic behavior in state-of-the-art\nVideo-LLMs across diverse question formats, prompt biases, and visual reasoning\ntasks. Specifically, VISE pioneeringly brings linguistic perspectives on\nsycophancy into the visual domain, enabling fine-grained analysis across\nmultiple sycophancy types and interaction patterns. In addition, we explore\nkey-frame selection as an interpretable, training-free mitigation strategy,\nwhich reveals potential paths for reducing sycophantic bias by strengthening\nvisual grounding.", "comment": "24 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07180v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07060", "title": "Less is More: some Computational Principles based on Parcimony, and Limitations of Natural Intelligence", "authors": ["Laura Cohen", "Xavier Hinaut", "Lilyana Petrova", "Alexandre Pitti", "Syd Reynal", "Ichiro Tsuda"], "summary": "Natural intelligence (NI) consistently achieves more with less. Infants learn\nlanguage, develop abstract concepts, and acquire sensorimotor skills from\nsparse data, all within tight neural and energy limits. In contrast, today's AI\nrelies on virtually unlimited computational power, energy, and data to reach\nhigh performance. This paper argues that constraints in NI are paradoxically\ncatalysts for efficiency, adaptability, and creativity. We first show how\nlimited neural bandwidth promotes concise codes that still capture complex\npatterns. Spiking neurons, hierarchical structures, and symbolic-like\nrepresentations emerge naturally from bandwidth constraints, enabling robust\ngeneralization. Next, we discuss chaotic itinerancy, illustrating how the brain\ntransits among transient attractors to flexibly retrieve memories and manage\nuncertainty. We then highlight reservoir computing, where random projections\nfacilitate rapid generalization from small datasets. Drawing on developmental\nperspectives, we emphasize how intrinsic motivation, along with responsive\nsocial environments, drives infant language learning and discovery of meaning.\nSuch active, embodied processes are largely absent in current AI. Finally, we\nsuggest that adopting 'less is more' principles -- energy constraints,\nparsimonious architectures, and real-world interaction -- can foster the\nemergence of more efficient, interpretable, and biologically grounded\nartificial systems.", "comment": null, "cate": "q-bio.NC", "url": "http://arxiv.org/abs/2506.07060v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06378", "title": "Transformer-Based Decomposition of Electrodermal Activity for Real-World Mental Health Applications", "authors": ["Charalampos Tsirmpas", "Stasinos Konstantopoulos", "Dimitris Andrikopoulos", "Konstantina Kyriakouli", "Panagiotis Fatouros"], "summary": "Decomposing Electrodermal Activity (EDA) into phasic (short-term,\nstimulus-linked responses) and tonic (longer-term baseline) components is\nessential for extracting meaningful emotional and physiological biomarkers.\nThis study presents a comparative analysis of knowledge-driven, statistical,\nand deep learning-based methods for EDA signal decomposition, with a focus on\nin-the-wild data collected from wearable devices. In particular, the authors\nintroduce the Feel Transformer, a novel Transformer-based model adapted from\nthe Autoformer architecture, designed to separate phasic and tonic components\nwithout explicit supervision. The model leverages pooling and trend-removal\nmechanisms to enforce physiologically meaningful decompositions. Comparative\nexperiments against methods such as Ledalab, cvxEDA, and conventional\ndetrending show that the Feel Transformer achieves a balance between feature\nfidelity (SCR frequency, amplitude, and tonic slope) and robustness to noisy,\nreal-world data. The model demonstrates potential for real-time biosignal\nanalysis and future applications in stress prediction, digital mental health\ninterventions, and physiological forecasting.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06378v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07209", "title": "HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance", "authors": ["Lei Li", "Angela Dai"], "summary": "We present HOI-PAGE, a new approach to synthesizing 4D human-object\ninteractions (HOIs) from text prompts in a zero-shot fashion, driven by\npart-level affordance reasoning. In contrast to prior works that focus on\nglobal, whole body-object motion for 4D HOI synthesis, we observe that\ngenerating realistic and diverse HOIs requires a finer-grained understanding --\nat the level of how human body parts engage with object parts. We thus\nintroduce Part Affordance Graphs (PAGs), a structured HOI representation\ndistilled from large language models (LLMs) that encodes fine-grained part\ninformation along with contact relations. We then use these PAGs to guide a\nthree-stage synthesis: first, decomposing input 3D objects into geometric\nparts; then, generating reference HOI videos from text prompts, from which we\nextract part-based motion constraints; finally, optimizing for 4D HOI motion\nsequences that not only mimic the reference dynamics but also satisfy\npart-level contact constraints. Extensive experiments show that our approach is\nflexible and capable of generating complex multi-object or multi-person\ninteraction sequences, with significantly improved realism and text alignment\nfor zero-shot 4D HOI generation.", "comment": "Project page: https://hoipage.github.io/ Video:\n  https://youtu.be/b1pJU9lKQTE", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07209v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07064", "title": "Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models", "authors": ["Kai Xiong", "Xiao Ding", "Yixin Cao", "Yuxiong Yan", "Li Du", "Yufei Zhang", "Jinglong Gao", "Jiaqian Liu", "Bing Qin", "Ting Liu"], "summary": "Large language models (LLMs) have mastered abundant simple and explicit\ncommonsense knowledge through pre-training, enabling them to achieve human-like\nperformance in simple commonsense reasoning. Nevertheless, LLMs struggle to\nreason with complex and implicit commonsense knowledge that is derived from\nsimple ones (such as understanding the long-term effects of certain events), an\naspect humans tend to focus on more. Existing works focus on complex tasks like\nmath and code, while complex commonsense reasoning remains underexplored due to\nits uncertainty and lack of structure. To fill this gap and align with\nreal-world concerns, we propose a benchmark Com$^2$ focusing on complex\ncommonsense reasoning. We first incorporate causal event graphs to serve as\nstructured complex commonsense. Then we adopt causal theory~(e.g.,\nintervention) to modify the causal event graphs and obtain different scenarios\nthat meet human concerns. Finally, an LLM is employed to synthesize examples\nwith slow thinking, which is guided by the logical relationships in the\nmodified causal graphs. Furthermore, we use detective stories to construct a\nmore challenging subset. Experiments show that LLMs struggle in reasoning depth\nand breadth, while post-training and slow thinking can alleviate this. The code\nand data are available at https://github.com/Waste-Wood/Com2.", "comment": "Accepted by ACL 2025 Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07064v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07228", "title": "Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh", "authors": ["Shuvashis Sarker"], "summary": "Brain tumors, regardless of being benign or malignant, pose considerable\nhealth risks, with malignant tumors being more perilous due to their swift and\nuncontrolled proliferation, resulting in malignancy. Timely identification is\ncrucial for enhancing patient outcomes, particularly in nations such as\nBangladesh, where healthcare infrastructure is constrained. Manual MRI analysis\nis arduous and susceptible to inaccuracies, rendering it inefficient for prompt\ndiagnosis. This research sought to tackle these problems by creating an\nautomated brain tumor classification system utilizing MRI data obtained from\nmany hospitals in Bangladesh. Advanced deep learning models, including VGG16,\nVGG19, and ResNet50, were utilized to classify glioma, meningioma, and various\nbrain cancers. Explainable AI (XAI) methodologies, such as Grad-CAM and\nGrad-CAM++, were employed to improve model interpretability by emphasizing the\ncritical areas in MRI scans that influenced the categorization. VGG16 achieved\nthe most accuracy, attaining 99.17%. The integration of XAI enhanced the\nsystem's transparency and stability, rendering it more appropriate for clinical\napplication in resource-limited environments such as Bangladesh. This study\nhighlights the capability of deep learning models, in conjunction with\nexplainable artificial intelligence (XAI), to enhance brain tumor detection and\nidentification in areas with restricted access to advanced medical\ntechnologies.", "comment": "2024 6th International Conference on Sustainable Technologies for\n  Industry 5.0 (STI)", "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07228v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07066", "title": "From Axioms to Algorithms: Mechanized Proofs of the vNM Utility Theorem", "authors": ["Li Jingyuan"], "summary": "This paper presents a comprehensive formalization of the von\nNeumann-Morgenstern (vNM) expected utility theorem using the Lean 4 interactive\ntheorem prover. We implement the classical axioms of preference-completeness,\ntransitivity, continuity, and independence-enabling machine-verified proofs of\nboth the existence and uniqueness of utility representations. Our formalization\ncaptures the mathematical structure of preference relations over lotteries,\nverifying that preferences satisfying the vNM axioms can be represented by\nexpected utility maximization.\n  Our contributions include a granular implementation of the independence\naxiom, formally verified proofs of fundamental claims about mixture lotteries,\nconstructive demonstrations of utility existence, and computational experiments\nvalidating the results. We prove equivalence to classical presentations while\noffering greater precision at decision boundaries.\n  This formalization provides a rigorous foundation for applications in\neconomic modeling, AI alignment, and management decision systems, bridging the\ngap between theoretical decision theory and computational implementation.", "comment": null, "cate": "econ.TH", "url": "http://arxiv.org/abs/2506.07066v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07234", "title": "A Comprehensive Analysis of COVID-19 Detection Using Bangladeshi Data and Explainable AI", "authors": ["Shuvashis Sarker"], "summary": "COVID-19 is a rapidly spreading and highly infectious virus which has\ntriggered a global pandemic, profoundly affecting millions across the world.\nThe pandemic has introduced unprecedented challenges in public health, economic\nstability, and societal structures, necessitating the implementation of\nextensive and multifaceted health interventions globally. It had a tremendous\nimpact on Bangladesh by April 2024, with around 29,495 fatalities and more than\n2 million confirmed cases. This study focuses on improving COVID-19 detection\nin CXR images by utilizing a dataset of 4,350 images from Bangladesh\ncategorized into four classes: Normal, Lung-Opacity, COVID-19 and\nViral-Pneumonia. ML, DL and TL models are employed with the VGG19 model\nachieving an impressive 98% accuracy. LIME is used to explain model\npredictions, highlighting the regions and features influencing classification\ndecisions. SMOTE is applied to address class imbalances. By providing insight\ninto both correct and incorrect classifications, the study emphasizes the\nimportance of XAI in enhancing the transparency and reliability of models,\nultimately improving the effectiveness of detection from CXR images.", "comment": "2024 4th International Conference on Innovations in Science,\n  Engineering and Technology (ICISET)", "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07234v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07236", "title": "A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning", "authors": ["Jiachen Zhong", "Yiting Wang", "Di Zhu", "Ziwei Wang"], "summary": "Lung cancer remains one of the most prevalent and fatal diseases worldwide,\ndemanding accurate and timely diagnosis and treatment. Recent advancements in\nlarge AI models have significantly enhanced medical image understanding and\nclinical decision-making. This review systematically surveys the\nstate-of-the-art in applying large AI models to lung cancer screening,\ndiagnosis, prognosis, and treatment. We categorize existing models into\nmodality-specific encoders, encoder-decoder frameworks, and joint encoder\narchitectures, highlighting key examples such as CLIP, BLIP, Flamingo,\nBioViL-T, and GLoRIA. We further examine their performance in multimodal\nlearning tasks using benchmark datasets like LIDC-IDRI, NLST, and MIMIC-CXR.\nApplications span pulmonary nodule detection, gene mutation prediction,\nmulti-omics integration, and personalized treatment planning, with emerging\nevidence of clinical deployment and validation. Finally, we discuss current\nlimitations in generalizability, interpretability, and regulatory compliance,\nproposing future directions for building scalable, explainable, and clinically\nintegrated AI systems. Our review underscores the transformative potential of\nlarge AI models to personalize and optimize lung cancer care.", "comment": "Under Review", "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07236v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07079", "title": "On the Generalization of Data-Assisted Control in port-Hamiltonian Systems (DAC-pH)", "authors": ["Mostafa Eslami", "Maryam Babazadeh"], "summary": "This paper introduces a hypothetical hybrid control framework for\nport-Hamiltonian (p$\\mathcal{H}$) systems, employing a dynamic decomposition\nbased on Data-Assisted Control (DAC). The system's evolution is split into two\nparts with fixed topology: Right-Hand Side (RHS)- an intrinsic Hamiltonian flow\nhandling worst-case parametric uncertainties, and Left-Hand Side (LHS)- a\ndissipative/input flow addressing both structural and parametric uncertainties.\nA virtual port variable $\\Pi$ serves as the interface between these two\ncomponents. A nonlinear controller manages the intrinsic Hamiltonian flow,\ndetermining a desired port control value $\\Pi_c$. Concurrently, Reinforcement\nLearning (RL) is applied to the dissipative/input flow to learn an agent for\nproviding optimal policy in mapping $\\Pi_c$ to the actual system input. This\nhybrid approach effectively manages RHS uncertainties while preserving the\nsystem's inherent structure. Key advantages include adjustable performance via\nLHS controller parameters, enhanced AI explainability and interpretability\nthrough the port variable $\\Pi$, the ability to guarantee safety and state\nattainability with hard/soft constraints, reduced complexity in learning\nhypothesis classes compared to end-to-end solutions, and improved\nstate/parameter estimation using LHS prior knowledge and system Hamiltonian to\naddress partial observability. The paper details the p$\\mathcal{H}$\nformulation, derives the decomposition, and presents the modular controller\narchitecture. Beyond design, crucial aspects of stability and robustness\nanalysis and synthesis are investigated, paving the way for deeper theoretical\ninvestigations. An application example, a pendulum with nonlinear dynamics, is\nsimulated to demonstrate the approach's empirical and phenomenological benefits\nfor future research.", "comment": "This paper presents an early investigation of Data-Assisted Control\n  (DAC) with reinforcement learning, showcasing its potential through a simple\n  example. Theoretical analysis is ongoing to establish formal support and\n  guarantees for the proposed approach", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07079v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07296", "title": "HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval", "authors": ["Arian Askari", "Emmanouil Stergiadis", "Ilya Gusev", "Moran Beladev"], "summary": "We present HotelMatch-LLM, a multimodal dense retrieval model for the travel\ndomain that enables natural language property search, addressing the\nlimitations of traditional travel search engines which require users to start\nwith a destination and editing search parameters. HotelMatch-LLM features three\nkey innovations: (1) Domain-specific multi-task optimization with three novel\nretrieval, visual, and language modeling objectives; (2) Asymmetrical dense\nretrieval architecture combining a small language model (SLM) for efficient\nonline query processing and a large language model (LLM) for embedding hotel\ndata; and (3) Extensive image processing to handle all property image\ngalleries. Experiments on four diverse test sets show HotelMatch-LLM\nsignificantly outperforms state-of-the-art models, including VISTA and MARVEL.\nSpecifically, on the test set -- main query type -- we achieve 0.681 for\nHotelMatch-LLM compared to 0.603 for the most effective baseline, MARVEL. Our\nanalysis highlights the impact of our multi-task optimization, the\ngeneralizability of HotelMatch-LLM across LLM architectures, and its\nscalability for processing large image galleries.", "comment": "Accepted at ACL 2025, Main track. 13 Pages, 1 figure", "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.07296v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07301", "title": "Pendulum Tracker -- SimuFísica: A Web-based Tool for Real-time Measurement of Oscillatory Motion", "authors": ["Marco P. M. de Souza", "Juciane G. Maia", "Lilian N. de Andrade"], "summary": "We present Pendulum Tracker, a computer vision-based application that enables\nreal-time measurement of the oscillatory motion of a physical pendulum.\nIntegrated into the educational platform SimuF\\'isica, the system uses the\nOpenCV.js library and runs directly in the browser, working on computers,\ntablets, and smartphones. The application automatically detects the pendulum's\nposition via the device's camera, displaying in real time the angle-versus-time\ngraph and estimates of the oscillation period. Experimental case studies\ndemonstrate its effectiveness in measuring the period, determining\ngravitational acceleration, and analyzing damped oscillations. The results show\nexcellent agreement with theoretical predictions, confirming the system's\naccuracy and its applicability in educational contexts. The accessible\ninterface and the ability to export raw data make Pendulum Tracker a versatile\ntool for experimental physics teaching.", "comment": null, "cate": "physics.ed-ph", "url": "http://arxiv.org/abs/2506.07301v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07104", "title": "How Far Are We from Optimal Reasoning Efficiency?", "authors": ["Jiaxuan Gao", "Shu Yan", "Qixin Tan", "Lu Yang", "Shusheng Xu", "Wei Fu", "Zhiyu Mei", "Kaifeng Lyu", "Yi Wu"], "summary": "Large Reasoning Models (LRMs) demonstrate remarkable problem-solving\ncapabilities through extended Chain-of-Thought (CoT) reasoning but often\nproduce excessively verbose and redundant reasoning traces. This inefficiency\nincurs high inference costs and limits practical deployment. While existing\nfine-tuning methods aim to improve reasoning efficiency, assessing their\nefficiency gains remains challenging due to inconsistent evaluations. In this\nwork, we introduce the reasoning efficiency frontiers, empirical upper bounds\nderived from fine-tuning base LRMs across diverse approaches and training\nconfigurations. Based on these frontiers, we propose the Reasoning Efficiency\nGap (REG), a unified metric quantifying deviations of any fine-tuned LRMs from\nthese frontiers. Systematic evaluation on challenging mathematical benchmarks\nreveals significant gaps in current methods: they either sacrifice accuracy for\nshort length or still remain inefficient under tight token budgets. To reduce\nthe efficiency gap, we propose REO-RL, a class of Reinforcement Learning\nalgorithms that minimizes REG by targeting a sparse set of token budgets.\nLeveraging numerical integration over strategically selected budgets, REO-RL\napproximates the full efficiency objective with low error using a small set of\ntoken budgets. Through systematic benchmarking, we demonstrate that our\nefficiency metric, REG, effectively captures the accuracy-length trade-off,\nwith low-REG methods reducing length while maintaining accuracy. Our approach,\nREO-RL, consistently reduces REG by >=50 across all evaluated LRMs and matching\nQwen3-4B/8B efficiency frontiers under a 16K token budget with minimal accuracy\nloss. Ablation studies confirm the effectiveness of our exponential token\nbudget strategy. Finally, our findings highlight that fine-tuning LRMs to\nperfectly align with the efficiency frontiers remains an open challenge.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07104v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06743", "title": "The State-of-the-Art in Lifelog Retrieval: A Review of Progress at the ACM Lifelog Search Challenge Workshop 2022-24", "authors": ["Allie Tran", "Werner Bailer", "Duc-Tien Dang-Nguyen", "Graham Healy", "Steve Hodges", "Björn Þór Jónsson", "Luca Rossetto", "Klaus Schoeffmann", "Minh-Triet Tran", "Lucia Vadicamo", "Cathal Gurrin"], "summary": "The ACM Lifelog Search Challenge (LSC) is a venue that welcomes and compares\nsystems that support the exploration of lifelog data, and in particular the\nretrieval of specific information, through an interactive competition format.\nThis paper reviews the recent advances in interactive lifelog retrieval as\ndemonstrated at the ACM LSC from 2022 to 2024. Through a detailed comparative\nanalysis, we highlight key improvements across three main retrieval tasks:\nknown-item search, question answering, and ad-hoc search. Our analysis\nidentifies trends such as the widespread adoption of embedding-based retrieval\nmethods (e.g., CLIP, BLIP), increased integration of large language models\n(LLMs) for conversational retrieval, and continued innovation in multimodal and\ncollaborative search interfaces. We further discuss how specific retrieval\ntechniques and user interface (UI) designs have impacted system performance,\nemphasizing the importance of balancing retrieval complexity with usability.\nOur findings indicate that embedding-driven approaches combined with LLMs show\npromise for lifelog retrieval systems. Likewise, improving UI design can\nenhance usability and efficiency. Additionally, we recommend reconsidering\nmulti-instance system evaluations within the expert track to better manage\nvariability in user familiarity and configuration effectiveness.", "comment": null, "cate": "cs.MM", "url": "http://arxiv.org/abs/2506.06743v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07106", "title": "Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models", "authors": ["Samir Abdaljalil", "Hasan Kurban", "Khalid Qaraqe", "Erchin Serpedin"], "summary": "Large language models (LLMs) have shown strong performance across natural\nlanguage reasoning tasks, yet their reasoning processes remain brittle and\ndifficult to interpret. Prompting techniques like Chain-of-Thought (CoT)\nenhance reliability by eliciting intermediate reasoning steps or aggregating\nmultiple outputs. However, they lack mechanisms for enforcing logical structure\nand assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a\nnovel framework that models reasoning as collaboration among three parallel\nagents, each simulating a distinct mode of inference: abductive, deductive, and\ninductive. Each agent produces a reasoning trace, which is structured into a\nformal reasoning graph. To evaluate consistency, we apply Bayesian belief\npropagation guided by natural language inference (NLI), assigning confidence\nscores to each step. The most coherent graph is selected to derive the final\nanswer. Experiments on symbolic (WebOfLies) and numerical (MultiArith)\nreasoning benchmarks show that ToTh consistently outperforms CoT,\nSelf-Consistency, and CoT-Decoding across multiple LLMs, while producing\ninterpretable and logically grounded reasoning chains. Our findings suggest a\npromising direction for building more robust and cognitively inspired LLM\nreasoning. The implementation is available at\nhttps://github.com/KurbanIntelligenceLab/theorem-of-thought.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07106v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06410", "title": "Improving choice model specification using reinforcement learning", "authors": ["Gabriel Nova", "Sander van Cranenburgh", "Stephane Hess"], "summary": "Discrete choice modelling is a theory-driven modelling framework for\nunderstanding and forecasting choice behaviour. To obtain behavioural insights,\nmodellers test several competing model specifications in their attempts to\ndiscover the 'true' data generation process. This trial-and-error process\nrequires expertise, is time-consuming, and relies on subjective theoretical\nassumptions. Although metaheuristics have been proposed to assist choice\nmodellers, they treat model specification as a classic optimisation problem,\nrelying on static strategies, applying predefined rules, and neglecting\noutcomes from previous estimated models. As a result, current metaheuristics\nstruggle to prioritise promising search regions, adapt exploration dynamically,\nand transfer knowledge to other modelling tasks. To address these limitations,\nwe introduce a deep reinforcement learning-based framework where an 'agent'\nspecifies models by estimating them and receiving rewards based on\ngoodness-of-fit and parsimony. Results demonstrate the agent dynamically adapts\nits strategies to identify promising specifications across data generation\nprocesses, showing robustness and potential transferability, without prior\ndomain knowledge.", "comment": "13 pages, 7 figures", "cate": "econ.GN", "url": "http://arxiv.org/abs/2506.06410v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06746", "title": "Adaptive Event-triggered Formation Control of Autonomous Vehicles", "authors": ["Ziming Wang", "Yihuai Zhang", "Chenguang Zhao", "Huan Yu"], "summary": "This paper presents adaptive event-triggered formation control strategies for\nautonomous vehicles (AVs) subject to longitudinal and lateral motion\nuncertainties. The proposed framework explores various vehicular formations to\nenable safe and efficient navigation in complex traffic scenarios, such as\nnarrow passages, collaborative obstacle avoidance, and adaptation to cut-in\nmaneuvers. In contrast to conventional platoon control strategies that rely on\npredefined communication topologies and continuous state transmission, our\napproach employs a sampling-based observer to reconstruct vehicle dynamics.\nBuilding upon an adaptive backstepping continuous-time controller, we design\nthree distinct event-triggered mechanisms, each offering a different trade-off\nbetween formation tracking performance and control efficiency by reducing the\nfrequency of control signal updates. A Lyapunov-based stability analysis is\nconducted to guarantee bounded tracking errors and to avoid Zeno behavior.\nFinally, the proposed event-triggered controllers are validated through\nsimulations of vehicular formation in three scenarios, highlighting their\nimpact on traffic safety and mobility.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06746v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07475", "title": "Text-guided multi-stage cross-perception network for medical image segmentation", "authors": ["Gaoyu Chen"], "summary": "Medical image segmentation plays a crucial role in clinical medicine, serving\nas a tool for auxiliary diagnosis, treatment planning, and disease monitoring,\nthus facilitating physicians in the study and treatment of diseases. However,\nexisting medical image segmentation methods are limited by the weak semantic\nexpression of the target segmentation regions, which is caused by the low\ncontrast between the target and non-target segmentation regions. To address\nthis limitation, text prompt information has greast potential to capture the\nlesion location. However, existing text-guided methods suffer from insufficient\ncross-modal interaction and inadequate cross-modal feature expression. To\nresolve these issues, we propose the Text-guided Multi-stage Cross-perception\nnetwork (TMC). In TMC, we introduce a multistage cross-attention module to\nenhance the model's understanding of semantic details and a multi-stage\nalignment loss to improve the consistency of cross-modal semantics. The results\nof the experiments demonstrate that our TMC achieves a superior performance\nwith Dice of 84.77%, 78.50%, 88.73% in three public datasets (QaTa-COV19,\nMosMedData and Breast), outperforming UNet based networks and text-guided\nmethods.", "comment": null, "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07475v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07118", "title": "RBA-FE: A Robust Brain-Inspired Audio Feature Extractor for Depression Diagnosis", "authors": ["Yu-Xuan Wu", "Ziyan Huang", "Bin Hu", "Zhi-Hong Guan"], "summary": "This article proposes a robust brain-inspired audio feature extractor\n(RBA-FE) model for depression diagnosis, using an improved hierarchical network\narchitecture. Most deep learning models achieve state-of-the-art performance\nfor image-based diagnostic tasks, ignoring the counterpart audio features. In\norder to tailor the noise challenge, RBA-FE leverages six acoustic features\nextracted from the raw audio, capturing both spatial characteristics and\ntemporal dependencies. This hybrid attribute helps alleviate the precision\nlimitation in audio feature extraction within other learning models like deep\nresidual shrinkage networks. To deal with the noise issues, our model\nincorporates an improved spiking neuron model, called adaptive rate smooth\nleaky integrate-and-fire (ARSLIF). The ARSLIF model emulates the mechanism of\n``retuning of cellular signal selectivity\" in the brain attention systems,\nwhich enhances the model robustness against environmental noises in audio data.\nExperimental results demonstrate that RBA-FE achieves state-of-the-art accuracy\non the MODMA dataset, respectively with 0.8750, 0.8974, 0.8750 and 0.8750 in\nprecision, accuracy, recall and F1 score. Extensive experiments on the AVEC2014\nand DAIC-WOZ datasets both show enhancements in noise robustness. It is further\nindicated by comparison that the ARSLIF neuron model suggest the abnormal\nfiring pattern within the feature extraction on depressive audio data, offering\nbrain-inspired interpretability.", "comment": "14 pages", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07118v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07631", "title": "Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline", "authors": ["Brian Gordon", "Yonatan Bitton", "Andreea Marzoca", "Yasumasa Onoe", "Xiao Wang", "Daniel Cohen-Or", "Idan Szpektor"], "summary": "Large Vision-Language Models (VLMs) now generate highly detailed,\nparagraphlength image captions, yet evaluating their factual accuracy remains\nchallenging. Current methods often miss fine-grained errors, being designed for\nshorter texts or lacking datasets with verified inaccuracies. We introduce\nDOCCI-Critique, a benchmark with 1,400 VLM-generated paragraph captions (100\nimages, 14 VLMs) featuring over 10,216 sentence-level human annotations of\nfactual correctness and explanatory rationales for errors, all within paragraph\ncontext. Building on this, we develop VNLI-Critique, a model for automated\nsentence-level factuality classification and critique generation. We highlight\nthree key applications: (1) VNLI-Critique demonstrates robust generalization,\nvalidated by state-of-the-art performance on the M-HalDetect benchmark and\nstrong results in CHOCOLATE claim verification. (2) The VNLI-Critique driven\nAutoRater for DOCCI-Critique provides reliable VLM rankings, showing excellent\nalignment with human factuality judgments (e.g., 0.98 Spearman). (3) An\ninnovative Critic-and-Revise pipeline, where critiques from VNLI-Critique guide\nLLM-based corrections, achieves substantial improvements in caption factuality\n(e.g., a 46% gain on DetailCaps-4870). Our work offers a crucial benchmark\nalongside practical tools, designed to significantly elevate the standards for\nfine-grained evaluation and foster the improvement of VLM image understanding.\nProject page: https://google.github.io/unblocking-detail-caption", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07631v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06751", "title": "Geopolitical biases in LLMs: what are the \"good\" and the \"bad\" countries according to contemporary language models", "authors": ["Mikhail Salnikov", "Dmitrii Korzh", "Ivan Lazichny", "Elvir Karimov", "Artyom Iudin", "Ivan Oseledets", "Oleg Y. Rogov", "Alexander Panchenko", "Natalia Loukachevitch", "Elena Tutubalina"], "summary": "This paper evaluates geopolitical biases in LLMs with respect to various\ncountries though an analysis of their interpretation of historical events with\nconflicting national perspectives (USA, UK, USSR, and China). We introduce a\nnovel dataset with neutral event descriptions and contrasting viewpoints from\ndifferent countries. Our findings show significant geopolitical biases, with\nmodels favoring specific national narratives. Additionally, simple debiasing\nprompts had a limited effect in reducing these biases. Experiments with\nmanipulated participant labels reveal models' sensitivity to attribution,\nsometimes amplifying biases or recognizing inconsistencies, especially with\nswapped labels. This work highlights national narrative biases in LLMs,\nchallenges the effectiveness of simple debiasing methods, and offers a\nframework and dataset for future geopolitical bias research.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06751v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07657", "title": "PIG: Physically-based Multi-Material Interaction with 3D Gaussians", "authors": ["Zeyu Xiao", "Zhenyi Wu", "Mingyang Sun", "Qipeng Yan", "Yufan Guo", "Zhuoer Liang", "Lihua Zhang"], "summary": "3D Gaussian Splatting has achieved remarkable success in reconstructing both\nstatic and dynamic 3D scenes. However, in a scene represented by 3D Gaussian\nprimitives, interactions between objects suffer from inaccurate 3D\nsegmentation, imprecise deformation among different materials, and severe\nrendering artifacts. To address these challenges, we introduce PIG:\nPhysically-Based Multi-Material Interaction with 3D Gaussians, a novel approach\nthat combines 3D object segmentation with the simulation of interacting objects\nin high precision. Firstly, our method facilitates fast and accurate mapping\nfrom 2D pixels to 3D Gaussians, enabling precise 3D object-level segmentation.\nSecondly, we assign unique physical properties to correspondingly segmented\nobjects within the scene for multi-material coupled interactions. Finally, we\nhave successfully embedded constraint scales into deformation gradients,\nspecifically clamping the scaling and rotation properties of the Gaussian\nprimitives to eliminate artifacts and achieve geometric fidelity and visual\nconsistency. Experimental results demonstrate that our method not only\noutperforms the state-of-the-art (SOTA) in terms of visual quality, but also\nopens up new directions and pipelines for the field of physically realistic\nscene generation.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07657v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06753", "title": "Influential scientists shape knowledge flows between science and IGO policy", "authors": ["Kimitaka Asatani", "Yurie Iwata", "Yuta Tomokiyo", "Basil Mahfouz", "Masaru Yarime", "Ichiro Sakata"], "summary": "Intergovernmental organizations (IGOs) increasingly rely on scientific\nevidence, yet the pathways through which scientific research enters policy\nremain opaque. By linking 230,737 scientific papers cited in IGO policy\ndocuments (2015-2023) to their authors and collaboration networks, we identify\na small group of policy-influential scientists (PI-Sci) who dominate this\nknowledge flow. These scientists form tightly interconnected, internationally\nspanning co-authorship networks and achieve policy citations shortly after\npublication, a distinctive feature of cumulative advantage at the\nscience-policy interface. The concentration of influence varies by field:\ntightly clustered in established domains like climate modeling, and more\ndispersed in emerging areas like AI governance. Many PI-Sci serve on high-level\nadvisory bodies (e.g., IPCC), and major IGOs frequently co-cite the same PI-Sci\npapers, indicating synchronized knowledge diffusion through shared expert\nnetworks. These findings reveal how network structure and elite brokerage shape\nthe translation of research into global policy, highlighting opportunities to\nbroaden the scope of knowledge that informs policy.", "comment": null, "cate": "cs.DL", "url": "http://arxiv.org/abs/2506.06753v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07709", "title": "Fine-Grained Motion Compression and Selective Temporal Fusion for Neural B-Frame Video Coding", "authors": ["Xihua Sheng", "Peilin Chen", "Meng Wang", "Li Zhang", "Shiqi Wang", "Dapeng Oliver Wu"], "summary": "With the remarkable progress in neural P-frame video coding, neural B-frame\ncoding has recently emerged as a critical research direction. However, most\nexisting neural B-frame codecs directly adopt P-frame coding tools without\nadequately addressing the unique challenges of B-frame compression, leading to\nsuboptimal performance. To bridge this gap, we propose novel enhancements for\nmotion compression and temporal fusion for neural B-frame coding. First, we\ndesign a fine-grained motion compression method. This method incorporates an\ninteractive dual-branch motion auto-encoder with per-branch adaptive\nquantization steps, which enables fine-grained compression of bi-directional\nmotion vectors while accommodating their asymmetric bitrate allocation and\nreconstruction quality requirements. Furthermore, this method involves an\ninteractive motion entropy model that exploits correlations between\nbi-directional motion latent representations by interactively leveraging\npartitioned latent segments as directional priors. Second, we propose a\nselective temporal fusion method that predicts bi-directional fusion weights to\nachieve discriminative utilization of bi-directional multi-scale temporal\ncontexts with varying qualities. Additionally, this method introduces a\nhyperprior-based implicit alignment mechanism for contextual entropy modeling.\nBy treating the hyperprior as a surrogate for the contextual latent\nrepresentation, this mechanism implicitly mitigates the misalignment in the\nfused bi-directional temporal priors. Extensive experiments demonstrate that\nour proposed codec outperforms state-of-the-art neural B-frame codecs and\nachieves comparable or even superior compression performance to the H.266/VVC\nreference software under random-access configurations.", "comment": null, "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.07709v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06542", "title": "Direct Fisher Score Estimation for Likelihood Maximization", "authors": ["Sherman Khoo", "Yakun Wang", "Song Liu", "Mark Beaumont"], "summary": "We study the problem of likelihood maximization when the likelihood function\nis intractable but model simulations are readily available. We propose a\nsequential, gradient-based optimization method that directly models the Fisher\nscore based on a local score matching technique which uses simulations from a\nlocalized region around each parameter iterate. By employing a linear\nparameterization to the surrogate score model, our technique admits a\nclosed-form, least-squares solution. This approach yields a fast, flexible, and\nefficient approximation to the Fisher score, effectively smoothing the\nlikelihood objective and mitigating the challenges posed by complex likelihood\nlandscapes. We provide theoretical guarantees for our score estimator,\nincluding bounds on the bias introduced by the smoothing. Empirical results on\na range of synthetic and real-world problems demonstrate the superior\nperformance of our method compared to existing benchmarks.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.06542v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06756", "title": "Can Quantized Audio Language Models Perform Zero-Shot Spoofing Detection?", "authors": ["Bikash Dutta", "Rishabh Ranjan", "Shyam Sathvik", "Mayank Vatsa", "Richa Singh"], "summary": "Quantization is essential for deploying large audio language models (LALMs)\nefficiently in resource-constrained environments. However, its impact on\ncomplex tasks, such as zero-shot audio spoofing detection, remains\nunderexplored. This study evaluates the zero-shot capabilities of five LALMs,\nGAMA, LTU-AS, MERaLiON, Qwen-Audio, and SALMONN, across three distinct\ndatasets: ASVspoof2019, In-the-Wild, and WaveFake, and investigates their\nrobustness to quantization (FP32, FP16, INT8). Despite high initial spoof\ndetection accuracy, our analysis demonstrates severe predictive biases toward\nspoof classification across all models, rendering their practical performance\nequivalent to random classification. Interestingly, quantization to FP16\nprecision resulted in negligible performance degradation compared to FP32,\neffectively halving memory and computational requirements without materially\nimpacting accuracy. However, INT8 quantization intensified model biases,\nsignificantly degrading balanced accuracy. These findings highlight critical\narchitectural limitations and emphasize FP16 quantization as an optimal\ntrade-off, providing guidelines for practical deployment and future model\nrefinement.", "comment": "Accepted in Interspeech 2025", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.06756v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07897", "title": "GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution", "authors": ["Shuja Khalid", "Mohamed Ibrahim", "Yang Liu"], "summary": "We present a novel approach for enhancing the resolution and geometric\nfidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution.\nCurrent 3DGS methods are fundamentally limited by their input resolution,\nproducing reconstructions that cannot extrapolate finer details than are\npresent in the training views. Our work breaks this limitation through a\nlightweight generative model that predicts and refines additional 3D Gaussians\nwhere needed most. The key innovation is our Hessian-assisted sampling\nstrategy, which intelligently identifies regions that are likely to benefit\nfrom densification, ensuring computational efficiency. Unlike computationally\nintensive GANs or diffusion approaches, our method operates in real-time\n(0.015s per inference on a single consumer-grade GPU), making it practical for\ninteractive applications. Comprehensive experiments demonstrate significant\nimprovements in both geometric accuracy and rendering quality compared to\nstate-of-the-art methods, establishing a new paradigm for resolution-free 3D\nscene enhancement.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07897v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07142", "title": "Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting", "authors": ["Lennart Meincke", "Ethan Mollick", "Lilach Mollick", "Dan Shapiro"], "summary": "This is the second in a series of short reports that seek to help business,\neducation, and policy leaders understand the technical details of working with\nAI through rigorous testing. In this report, we investigate Chain-of-Thought\n(CoT) prompting, a technique that encourages a large language model (LLM) to\n\"think step by step\" (Wei et al., 2022). CoT is a widely adopted method for\nimproving reasoning tasks, however, our findings reveal a more nuanced picture\nof its effectiveness. We demonstrate two things:\n  - The effectiveness of Chain-of-Thought prompting can vary greatly depending\non the type of task and model. For non-reasoning models, CoT generally improves\naverage performance by a small amount, particularly if the model does not\ninherently engage in step-by-step processing by default. However, CoT can\nintroduce more variability in answers, sometimes triggering occasional errors\nin questions the model would otherwise get right. We also found that many\nrecent models perform some form of CoT reasoning even if not asked; for these\nmodels, a request to perform CoT had little impact. Performing CoT generally\nrequires far more tokens (increasing cost and time) than direct answers.\n  - For models designed with explicit reasoning capabilities, CoT prompting\noften results in only marginal, if any, gains in answer accuracy. However, it\nsignificantly increases the time and tokens needed to generate a response.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07142v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07917", "title": "Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes", "authors": ["Allen Tu", "Haiyang Ying", "Alex Hanson", "Yonghan Lee", "Tom Goldstein", "Matthias Zwicker"], "summary": "Recent extensions of 3D Gaussian Splatting (3DGS) to dynamic scenes achieve\nhigh-quality novel view synthesis by using neural networks to predict the\ntime-varying deformation of each Gaussian. However, performing per-Gaussian\nneural inference at every frame poses a significant bottleneck, limiting\nrendering speed and increasing memory and compute requirements. In this paper,\nwe present Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS), a general\npipeline for accelerating the rendering speed of dynamic 3DGS and 4DGS\nrepresentations by reducing neural inference through two complementary\ntechniques. First, we propose a temporal sensitivity pruning score that\nidentifies and removes Gaussians with low contribution to the dynamic scene\nreconstruction. We also introduce an annealing smooth pruning mechanism that\nimproves pruning robustness in real-world scenes with imprecise camera poses.\nSecond, we propose GroupFlow, a motion analysis technique that clusters\nGaussians by trajectory similarity and predicts a single rigid transformation\nper group instead of separate deformations for each Gaussian. Together, our\ntechniques accelerate rendering by $10.37\\times$, reduce model size by\n$7.71\\times$, and shorten training time by $2.71\\times$ on the NeRF-DS dataset.\nSpeeDe3DGS also improves rendering speed by $4.20\\times$ and $58.23\\times$ on\nthe D-NeRF and HyperNeRF vrig datasets. Our methods are modular and can be\nintegrated into any deformable 3DGS or 4DGS framework.", "comment": "Project Page: https://speede3dgs.github.io/", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07917v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07154", "title": "Syntactic Control of Language Models by Posterior Inference", "authors": ["Vicky Xefteri", "Tim Vieira", "Ryan Cotterell", "Afra Amini"], "summary": "Controlling the syntactic structure of text generated by language models is\nvaluable for applications requiring clarity, stylistic consistency, or\ninterpretability, yet it remains a challenging task. In this paper, we argue\nthat sampling algorithms based on the posterior inference can effectively\nenforce a target constituency structure during generation. Our approach\ncombines sequential Monte Carlo, which estimates the posterior distribution by\nsampling from a proposal distribution, with a syntactic tagger that ensures\nthat each generated token aligns with the desired syntactic structure. Our\nexperiments with GPT2 and Llama3-8B models show that with an appropriate\nproposal distribution, we can improve syntactic accuracy, increasing the F1\nscore from $12.31$ (GPT2-large) and $35.33$ (Llama3-8B) to about $93$ in both\ncases without compromising the language model's fluency. These results\nunderscore both the complexity of syntactic control and the effectiveness of\nsampling algorithms, offering a promising approach for applications where\nprecise control over syntax is essential.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07154v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06765", "title": "Employing Discrete Fourier Transform in Representational Learning", "authors": ["Raoof HojatJalali", "Edmondo Trentin"], "summary": "Image Representation learning via input reconstruction is a common technique\nin machine learning for generating representations that can be effectively\nutilized by arbitrary downstream tasks. A well-established approach is using\nautoencoders to extract latent representations at the network's compression\npoint. These representations are valuable because they retain essential\ninformation necessary for reconstructing the original input from the compressed\nlatent space. In this paper, we propose an alternative learning objective.\nInstead of using the raw input as the reconstruction target, we employ the\nDiscrete Fourier Transform (DFT) of the input. The DFT provides meaningful\nglobal information at each frequency level, making individual frequency\ncomponents useful as separate learning targets. When dealing with\nmultidimensional input data, the DFT offers remarkable flexibility by enabling\nselective transformation across specific dimensions while preserving others in\nthe computation. Moreover, certain types of input exhibit distinct patterns in\ntheir frequency distributions, where specific frequency components consistently\ncontain most of the magnitude, allowing us to focus on a subset of frequencies\nrather than the entire spectrum. These characteristics position the DFT as a\nviable learning objective for representation learning and we validate our\napproach by achieving 52.8% top-1 accuracy on CIFAR-10 with ResNet-50 and\noutperforming the traditional autoencoder by 12.8 points under identical\narchitectural configurations. Additionally, we demonstrate that training on\nonly the lower-frequency components - those with the highest magnitudes yields\nresults comparable to using the full frequency spectrum, with only minimal\nreductions in accuracy.", "comment": "Preprint", "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06765v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07932", "title": "Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor", "authors": ["Rishit Dagli", "Yushi Guan", "Sankeerth Durvasula", "Mohammadreza Mofayezi", "Nandita Vijaykumar"], "summary": "We propose Squeeze3D, a novel framework that leverages implicit prior\nknowledge learnt by existing pre-trained 3D generative models to compress 3D\ndata at extremely high compression ratios. Our approach bridges the latent\nspaces between a pre-trained encoder and a pre-trained generation model through\ntrainable mapping networks. Any 3D model represented as a mesh, point cloud, or\na radiance field is first encoded by the pre-trained encoder and then\ntransformed (i.e. compressed) into a highly compact latent code. This latent\ncode can effectively be used as an extremely compressed representation of the\nmesh or point cloud. A mapping network transforms the compressed latent code\ninto the latent space of a powerful generative model, which is then conditioned\nto recreate the original 3D model (i.e. decompression). Squeeze3D is trained\nentirely on generated synthetic data and does not require any 3D datasets. The\nSqueeze3D architecture can be flexibly used with existing pre-trained 3D\nencoders and existing generative models. It can flexibly support different\nformats, including meshes, point clouds, and radiance fields. Our experiments\ndemonstrate that Squeeze3D achieves compression ratios of up to 2187x for\ntextured meshes, 55x for point clouds, and 619x for radiance fields while\nmaintaining visual quality comparable to many existing methods. Squeeze3D only\nincurs a small compression and decompression latency since it does not involve\ntraining object-specific networks to compress an object.", "comment": null, "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07932v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07169", "title": "CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Dissertações e Trabalhos de Graduação em SI -- XXI Simpósio Brasileiro de Sistemas de Informação", "authors": ["Washington Cunha", "Leonardo Rocha", "Marcos André Gonçalves"], "summary": "Progress in Natural Language Processing (NLP) has been dictated by the rule\nof more: more data, more computing power and more complexity, best exemplified\nby the Large Language Models. However, training (or fine-tuning) large dense\nmodels for specific applications usually requires significant amounts of\ncomputing resources. This \\textbf{Ph.D. dissertation} focuses on an\nunder-investi\\-gated NLP data engineering technique, whose potential is\nenormous in the current scenario known as Instance Selection (IS). The IS goal\nis to reduce the training set size by removing noisy or redundant instances\nwhile maintaining the effectiveness of the trained models and reducing the\ntraining process cost. We provide a comprehensive and scientifically sound\ncomparison of IS methods applied to an essential NLP task -- Automatic Text\nClassification (ATC), considering several classification solutions and many\ndatasets. Our findings reveal a significant untapped potential for IS\nsolutions. We also propose two novel IS solutions that are noise-oriented and\nredundancy-aware, specifically designed for large datasets and transformer\narchitectures. Our final solution achieved an average reduction of 41\\% in\ntraining sets, while maintaining the same levels of effectiveness in all\ndatasets. Importantly, our solutions demonstrated speedup improvements of 1.67x\n(up to 2.46x), making them scalable for datasets with hundreds of thousands of\ndocuments.", "comment": "16 pages, 5 figures, 2 tables", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07169v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06613", "title": "Robust Learnability of Sample-Compressible Distributions under Noisy or Adversarial Perturbations", "authors": ["Arefe Boushehrian", "Amir Najafi"], "summary": "Learning distribution families over $\\mathbb{R}^d$ is a fundamental problem\nin unsupervised learning and statistics. A central question in this setting is\nwhether a given family of distributions possesses sufficient structure to be\n(at least) information-theoretically learnable and, if so, to characterize its\nsample complexity. In 2018, Ashtiani et al. reframed \\emph{sample\ncompressibility}, originally due to Littlestone and Warmuth (1986), as a\nstructural property of distribution classes, proving that it guarantees\nPAC-learnability. This discovery subsequently enabled a series of recent\nadvancements in deriving nearly tight sample complexity bounds for various\nhigh-dimensional open problems. It has been further conjectured that the\nconverse also holds: every learnable class admits a tight sample compression\nscheme.\n  In this work, we establish that sample compressible families remain learnable\neven from perturbed samples, subject to a set of necessary and sufficient\nconditions. We analyze two models of data perturbation: (i) an additive\nindependent noise model, and (ii) an adversarial corruption model, where an\nadversary manipulates a limited subset of the samples unknown to the learner.\nOur results are general and rely on as minimal assumptions as possible. We\ndevelop a perturbation-quantization framework that interfaces naturally with\nthe compression scheme and leads to sample complexity bounds that scale\ngracefully with the noise level and corruption budget. As concrete\napplications, we establish new sample complexity bounds for learning finite\nmixtures of high-dimensional uniform distributions under both noise and\nadversarial perturbations, as well as for learning Gaussian mixture models from\nadversarially corrupted samples, resolving two open problems in the literature.", "comment": "50 pages, 1 figure", "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.06613v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06653", "title": "Explaining Risks: Axiomatic Risk Attributions for Financial Models", "authors": ["Dangxing Chen"], "summary": "In recent years, machine learning models have achieved great success at the\nexpense of highly complex black-box structures. By using axiomatic attribution\nmethods, we can fairly allocate the contributions of each feature, thus\nallowing us to interpret the model predictions. In high-risk sectors such as\nfinance, risk is just as important as mean predictions. Throughout this work,\nwe address the following risk attribution problem: how to fairly allocate the\nrisk given a model with data? We demonstrate with analysis and empirical\nexamples that risk can be well allocated by extending the Shapley value\nframework.", "comment": "This article has been accepted for publication in Quantitative\n  Finance, published by Taylor & Francis", "cate": "q-fin.CP", "url": "http://arxiv.org/abs/2506.06653v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06772", "title": "SynHate: Detecting Hate Speech in Synthetic Deepfake Audio", "authors": ["Rishabh Ranjan", "Kishan Pipariya", "Mayank Vatsa", "Richa Singh"], "summary": "The rise of deepfake audio and hate speech, powered by advanced\ntext-to-speech, threatens online safety. We present SynHate, the first\nmultilingual dataset for detecting hate speech in synthetic audio, spanning 37\nlanguages. SynHate uses a novel four-class scheme: Real-normal, Real-hate,\nFake-normal, and Fake-hate. Built from MuTox and ADIMA datasets, it captures\ndiverse hate speech patterns globally and in India. We evaluate five leading\nself-supervised models (Whisper-small/medium, XLS-R, AST, mHuBERT), finding\nnotable performance differences by language, with Whisper-small performing best\noverall. Cross-dataset generalization remains a challenge. By releasing SynHate\nand baseline code, we aim to advance robust, culturally sensitive, and\nmultilingual solutions against synthetic hate speech. The dataset is available\nat https://www.iab-rubric.org/resources.", "comment": "Accepted in Interspeech 2025", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.06772v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06774", "title": "Mind Games! Exploring the Impact of Dark Patterns in Mixed Reality Scenarios", "authors": ["Luca-Maxim Meinhardt", "Simon Demharter", "Michael Rietzler", "Mark Colley", "Thomas Eßmeyer", "Enrico Rukzio"], "summary": "Mixed Reality (MR) integrates virtual objects with the real world, offering\npotential but raising concerns about misuse through dark patterns. This study\nexplored the effects of four dark patterns, adapted from prior research, and\napplied to MR across three targets: places, products, and people. In a\ntwo-factorial within-subject study with 74 participants, we analyzed 13 videos\nsimulating MR experiences during a city walk. Results show that all dark\npatterns significantly reduced user comfort, increased reactance, and decreased\nthe intention to use MR glasses, with the most disruptive effects linked to\npersonal or monetary manipulation. Additionally, the dark patterns of Emotional\nand Sensory Manipulation and Hiding Information produced similar impacts on the\nuser in MR, suggesting a re-evaluation of current classifications to go beyond\ndeceptive design techniques. Our findings highlight the importance of\ndeveloping ethical design guidelines and tools to detect and prevent dark\npatterns as immersive technologies continue to evolve.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.06774v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07211", "title": "Sword and Shield: Uses and Strategies of LLMs in Navigating Disinformation", "authors": ["Gionnieve Lim", "Bryan Chen Zhengyu Tan", "Kellie Yu Hui Sim", "Weiyan Shi", "Ming Hui Chew", "Ming Shan Hee", "Roy Ka-Wei Lee", "Simon T. Perrault", "Kenny Tsu Wei Choo"], "summary": "The emergence of Large Language Models (LLMs) presents a dual challenge in\nthe fight against disinformation. These powerful tools, capable of generating\nhuman-like text at scale, can be weaponised to produce sophisticated and\npersuasive disinformation, yet they also hold promise for enhancing detection\nand mitigation strategies. This paper investigates the complex dynamics between\nLLMs and disinformation through a communication game that simulates online\nforums, inspired by the game Werewolf, with 25 participants. We analyse how\nDisinformers, Moderators, and Users leverage LLMs to advance their goals,\nrevealing both the potential for misuse and combating disinformation. Our\nfindings highlight the varying uses of LLMs depending on the participants'\nroles and strategies, underscoring the importance of understanding their\neffectiveness in this context. We conclude by discussing implications for\nfuture LLM development and online platform design, advocating for a balanced\napproach that empowers users and fosters trust while mitigating the risks of\nLLM-assisted disinformation.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07211v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06775", "title": "They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse", "authors": ["Walter Paci", "Alessandro Panunzi", "Sandro Pezzelle"], "summary": "Implicit content plays a crucial role in political discourse, where speakers\nsystematically employ pragmatic strategies such as implicatures and\npresuppositions to influence their audiences. Large Language Models (LLMs) have\ndemonstrated strong performance in tasks requiring complex semantic and\npragmatic understanding, highlighting their potential for detecting and\nexplaining the meaning of implicit content. However, their ability to do this\nwithin political discourse remains largely underexplored. Leveraging, for the\nfirst time, the large IMPAQTS corpus, which comprises Italian political\nspeeches with the annotation of manipulative implicit content, we propose\nmethods to test the effectiveness of LLMs in this challenging problem. Through\na multiple-choice task and an open-ended generation task, we demonstrate that\nall tested models struggle to interpret presuppositions and implicatures. We\nconclude that current LLMs lack the key pragmatic capabilities necessary for\naccurately interpreting highly implicit language, such as that found in\npolitical discourse. At the same time, we highlight promising trends and future\ndirections for enhancing model performance. We release our data and code at\nhttps://github.com/WalterPaci/IMPAQTS-PID", "comment": "Accepted to the ACL2025 Findings", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06775v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06718", "title": "IQFM A Wireless Foundational Model for I/Q Streams in AI-Native 6G", "authors": ["Omar Mashaal", "Hatem Abou-Zeid"], "summary": "Foundational models have shown remarkable potential in natural language\nprocessing and computer vision, yet remain in their infancy in wireless\ncommunications. While a few efforts have explored image-based modalities such\nas channel state information (CSI) and frequency spectrograms, foundational\nmodels that operate directly on raw IQ data remain largely unexplored. This\npaper presents, IQFM, the first I/Q signal foundational model for wireless\ncommunications. IQFM supporting diverse tasks: modulation classification,\nangle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavy\npreprocessing or handcrafted features. We also introduce a task-aware\naugmentation strategy that categorizes transformations into core augmentations,\nsuch as cyclic time shifting, and task-specific augmentations. This strategy\nforms the basis for structured, task-dependent representation learning within a\ncontrastive self-supervised learning (SSL) framework. Using this strategy, the\nlightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data,\nachieves up to 99.67% and 65.45% accuracy on modulation and AoA classification,\nrespectively, using only one labeled sample per class, outperforming supervised\nbaselines by up to 7x and 145x. The model also generalizes to\nout-of-distribution tasks; when adapted to new tasks using only 500 samples per\nclass and minimal parameter updates via LoRA, the same frozen encoder achieves\n94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016a\nmodulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs.\n96.64%). These results demonstrate the potential of raw IQ-based foundational\nmodels as efficient, reusable encoders for multi-task learning in AI-native 6G\nsystems.", "comment": null, "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06718v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06785", "title": "Extending dependencies to the taggedPBC: Word order in transitive clauses", "authors": ["Hiram Ring"], "summary": "The taggedPBC (Ring 2025a) contains more than 1,800 sentences of pos-tagged\nparallel text data from over 1,500 languages, representing 133 language\nfamilies and 111 isolates. While this dwarfs previously available resources,\nand the POS tags achieve decent accuracy, allowing for predictive\ncrosslinguistic insights (Ring 2025b), the dataset was not initially annotated\nfor dependencies. This paper reports on a CoNLLU-formatted version of the\ndataset which transfers dependency information along with POS tags to all\nlanguages in the taggedPBC. Although there are various concerns regarding the\nquality of the tags and the dependencies, word order information derived from\nthis dataset regarding the position of arguments and predicates in transitive\nclauses correlates with expert determinations of word order in three\ntypological databases (WALS, Grambank, Autotyp). This highlights the usefulness\nof corpus-based typological approaches (as per Baylor et al. 2023; Bjerva 2024)\nfor extending comparisons of discrete linguistic categories, and suggests that\nimportant insights can be gained even from noisy data, given sufficient\nannotation. The dependency-annotated corpora are also made available for\nresearch and collaboration via GitHub.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06785v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07245", "title": "SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes", "authors": ["Wenxuan Xie", "Yaxun Dai", "Wenhao Jiang"], "summary": "Recent advancements in large language models (LLMs) have significantly\nimproved performance on the Text-to-SQL task. However, prior approaches\ntypically rely on static, pre-processed database information provided at\ninference time, which limits the model's ability to fully understand the\ndatabase contents. Without dynamic interaction, LLMs are constrained to fixed,\nhuman-provided context and cannot autonomously explore the underlying data. To\naddress this limitation, we propose SDE-SQL, a framework that enables large\nlanguage models to perform self-driven exploration of databases during\ninference. This is accomplished by generating and executing SQL probes, which\nallow the model to actively retrieve information from the database and\niteratively update its understanding of the data. Unlike prior methods, SDE-SQL\noperates in a zero-shot setting, without relying on any question-SQL pairs as\nin-context demonstrations. When evaluated on the BIRD benchmark with\nQwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in\nexecution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing\na new state-of-the-art among methods based on open-source models without\nsupervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the\nperformance of SDE-SQL can be further enhanced, yielding an additional 0.52%\nimprovement.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07245v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07274", "title": "Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages", "authors": ["Olga Kellert", "Nemika Tyagi", "Muhammad Imran", "Nelvin Licona-Guevara", "Carlos Gómez-Rodríguez"], "summary": "Code-switching presents a complex challenge for syntactic analysis,\nespecially in low-resource language settings where annotated data is scarce.\nWhile recent work has explored the use of large language models (LLMs) for\nsequence-level tagging, few approaches systematically investigate how well\nthese models capture syntactic structure in code-switched contexts. Moreover,\nexisting parsers trained on monolingual treebanks often fail to generalize to\nmultilingual and mixed-language input. To address this gap, we introduce the\nBiLingua Parser, an LLM-based annotation pipeline designed to produce Universal\nDependencies (UD) annotations for code-switched text. First, we develop a\nprompt-based framework for Spanish-English and Spanish-Guaran\\'i data,\ncombining few-shot LLM prompting with expert review. Second, we release two\nannotated datasets, including the first Spanish-Guaran\\'i UD-parsed corpus.\nThird, we conduct a detailed syntactic analysis of switch points across\nlanguage pairs and communicative contexts. Experimental results show that\nBiLingua Parser achieves up to 95.29% LAS after expert revision, significantly\noutperforming prior baselines and multilingual parsers. These results show that\nLLMs, when carefully guided, can serve as practical tools for bootstrapping\nsyntactic resources in under-resourced, code-switched environments. Data and\nsource code are available at https://github.com/N3mika/ParsingProject", "comment": "16 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07274v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06778", "title": "Continuous Semi-Implicit Models", "authors": ["Longlin Yu", "Jiajun Zha", "Tong Yang", "Tianyu Xie", "Xiangyu Zhang", "S. -H. Gary Chan", "Cheng Zhang"], "summary": "Semi-implicit distributions have shown great promise in variational inference\nand generative modeling. Hierarchical semi-implicit models, which stack\nmultiple semi-implicit layers, enhance the expressiveness of semi-implicit\ndistributions and can be used to accelerate diffusion models given pretrained\nscore networks. However, their sequential training often suffers from slow\nconvergence. In this paper, we introduce CoSIM, a continuous semi-implicit\nmodel that extends hierarchical semi-implicit models into a continuous\nframework. By incorporating a continuous transition kernel, CoSIM enables\nefficient, simulation-free training. Furthermore, we show that CoSIM achieves\nconsistency with a carefully designed transition kernel, offering a novel\napproach for multistep distillation of generative models at the distributional\nlevel. Extensive experiments on image generation demonstrate that CoSIM\nperforms on par or better than existing diffusion model acceleration methods,\nachieving superior performance on FD-DINOv2.", "comment": "26 pages, 8 figures, ICML 2025", "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.06778v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06792", "title": "Fully discrete finite element approximation for the projection method to solve the Chemotaxis-Fluid System", "authors": ["Chenyang Li"], "summary": "In this paper, we investigate a chemotaxis-fluid interaction model governed\nby the incompressible Navier-Stokes equations coupled with the classical\nKeller-Segel chemotaxis system. To numerically solve this coupled system, we\ndevelop a pressure-correction projection finite element method based on a\nprojection framework. The proposed scheme employs a backward Euler method for\ntemporal discretization and a mixed finite element method for spatial\ndiscretization. Nonlinear terms are treated semi-implicitly to enhance\ncomputational stability and efficiency. We further establish rigorous error\nestimates for the fully discrete scheme, demonstrating the convergence of the\nnumerical method. A series of numerical experiments are conducted to validate\nthe stability, accuracy, and effectiveness of the proposed method. The results\nconfirm the scheme's capability to capture the essential dynamical behaviors\nand characteristic features of the chemotaxis-fluid system.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06792v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07281", "title": "Secondary Stakeholders in AI: Fighting for, Brokering, and Navigating Agency", "authors": ["Leah Hope Ajmani", "Nuredin Ali Abdelkadir", "Stevie Chancellor"], "summary": "As AI technologies become more human-facing, there have been numerous calls\nto adapt participatory approaches to AI development -- spurring the idea of\nparticipatory AI. However, these calls often focus only on primary\nstakeholders, such as end-users, and not secondary stakeholders. This paper\nseeks to translate the ideals of participatory AI to a broader population of\nsecondary AI stakeholders through semi-structured interviews. We theorize that\nmeaningful participation involves three participatory ideals: (1) informedness,\n(2) consent, and (3) agency. We also explore how secondary stakeholders realize\nthese ideals by traversing a complicated problem space. Like walking up the\nrungs of a ladder, these ideals build on one another. We introduce three\nstakeholder archetypes: the reluctant data contributor, the unsupported\nactivist, and the well-intentioned practitioner, who must navigate systemic\nbarriers to achieving agentic AI relationships. We envision an AI future where\nsecondary stakeholders are able to meaningfully participate with the AI systems\nthey influence and are influenced by.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07281v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06828", "title": "The Currents of Conflict: Decomposing Conflict Trends with Gaussian Processes", "authors": ["Simon P. von der Maase"], "summary": "I present a novel approach to estimating the temporal and spatial patterns of\nviolent conflict. I show how we can use highly temporally and spatially\ndisaggregated data on conflict events in tandem with Gaussian processes to\nestimate temporospatial conflict trends. These trends can be studied to gain\ninsight into conflict traps, diffusion and tempo-spatial conflict exposure in\ngeneral; they can also be used to control for such phenomenons given other\nestimation tasks; lastly, the approach allow us to extrapolate the estimated\ntempo-spatial conflict patterns into future temporal units, thus facilitating\npowerful, stat-of-the-art, conflict forecasts. Importantly, these results are\nachieved via a relatively parsimonious framework using only one data source:\npast conflict patterns.", "comment": "Total Words: 8122, Total pages: 28, Total figures: 6, Total Tables: 5", "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.06828v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06800", "title": "On the Adaptive Psychological Persuasion of Large Language Models", "authors": ["Tianjie Ju", "Yujia Chen", "Hao Fei", "Mong-Li Lee", "Wynne Hsu", "Pengzhou Cheng", "Zongru Wu", "Zhuosheng Zhang", "Gongshen Liu"], "summary": "Previous work has showcased the intriguing capabilities of Large Language\nModels (LLMs) in instruction-following and rhetorical fluency. However,\nsystematic exploration of their dual capabilities to autonomously persuade and\nresist persuasion, particularly in contexts involving psychological rhetoric,\nremains unexplored. In this paper, we first evaluate four commonly adopted LLMs\nby tasking them to alternately act as persuaders and listeners in adversarial\ndialogues. Empirical results show that persuader LLMs predominantly employ\nrepetitive strategies, leading to low success rates. Then we introduce eleven\ncomprehensive psychological persuasion strategies, finding that explicitly\ninstructing LLMs to adopt specific strategies such as Fluency Effect and\nRepetition Effect significantly improves persuasion success rates. However, no\n``one-size-fits-all'' strategy proves universally effective, with performance\nheavily dependent on contextual counterfactuals. Motivated by these\nobservations, we propose an adaptive framework based on direct preference\noptimization that trains LLMs to autonomously select optimal strategies by\nleveraging persuasion results from strategy-specific responses as preference\npairs. Experiments on three open-source LLMs confirm that the proposed adaptive\npsychological persuasion method effectively enables persuader LLMs to select\noptimal strategies, significantly enhancing their success rates while\nmaintaining general capabilities. Our code is available at\nhttps://github.com/KalinaEine/PsychologicalPersuasion.", "comment": "Working in progress", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06800v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07315", "title": "Towards Competent AI for Fundamental Analysis in Finance: A Benchmark Dataset and Evaluation", "authors": ["Zonghan Wu", "Junlin Wang", "Congyuan Zou", "Chenhan Wang", "Yilei Shao"], "summary": "Generative AI, particularly large language models (LLMs), is beginning to\ntransform the financial industry by automating tasks and helping to make sense\nof complex financial information. One especially promising use case is the\nautomatic creation of fundamental analysis reports, which are essential for\nmaking informed investment decisions, evaluating credit risks, guiding\ncorporate mergers, etc. While LLMs attempt to generate these reports from a\nsingle prompt, the risks of inaccuracy are significant. Poor analysis can lead\nto misguided investments, regulatory issues, and loss of trust. Existing\nfinancial benchmarks mainly evaluate how well LLMs answer financial questions\nbut do not reflect performance in real-world tasks like generating financial\nanalysis reports. In this paper, we propose FinAR-Bench, a solid benchmark\ndataset focusing on financial statement analysis, a core competence of\nfundamental analysis. To make the evaluation more precise and reliable, we\nbreak this task into three measurable steps: extracting key information,\ncalculating financial indicators, and applying logical reasoning. This\nstructured approach allows us to objectively assess how well LLMs perform each\nstep of the process. Our findings offer a clear understanding of LLMs current\nstrengths and limitations in fundamental analysis and provide a more practical\nway to benchmark their performance in real-world financial settings.", "comment": null, "cate": "q-fin.ST", "url": "http://arxiv.org/abs/2506.07315v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07323", "title": "Speech Recognition on TV Series with Video-guided Post-Correction", "authors": ["Haoyuan Yang", "Yue Zhang", "Liqiang Jing"], "summary": "Automatic Speech Recognition (ASR) has achieved remarkable success with deep\nlearning, driving advancements in conversational artificial intelligence, media\ntranscription, and assistive technologies. However, ASR systems still struggle\nin complex environments such as TV series, where overlapping speech,\ndomain-specific terminology, and long-range contextual dependencies pose\nsignificant challenges to transcription accuracy. Existing multimodal\napproaches fail to correct ASR outputs with the rich temporal and contextual\ninformation available in video. To address this limitation, we propose a novel\nmultimodal post-correction framework that refines ASR transcriptions by\nleveraging contextual cues extracted from video. Our framework consists of two\nstages: ASR Generation and Video-based Post-Correction, where the first stage\nproduces the initial transcript and the second stage corrects errors using\nVideo-based Contextual Information Extraction and Context-aware ASR Correction.\nWe employ the Video-Large Multimodal Model (VLMM) to extract key contextual\ninformation using tailored prompts, which is then integrated with a Large\nLanguage Model (LLM) to refine the ASR output. We evaluate our method on a\nmultimodal benchmark for TV series ASR and demonstrate its effectiveness in\nimproving ASR performance by leveraging video-based context to enhance\ntranscription accuracy in complex multimedia environments.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07323v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06915", "title": "Graph Neural Networks in Modern AI-aided Drug Discovery", "authors": ["Odin Zhang", "Haitao Lin", "Xujun Zhang", "Xiaorui Wang", "Zhenxing Wu", "Qing Ye", "Weibo Zhao", "Jike Wang", "Kejun Ying", "Yu Kang", "Chang-yu Hsieh", "Tingjun Hou"], "summary": "Graph neural networks (GNNs), as topology/structure-aware models within deep\nlearning, have emerged as powerful tools for AI-aided drug discovery (AIDD). By\ndirectly operating on molecular graphs, GNNs offer an intuitive and expressive\nframework for learning the complex topological and geometric features of\ndrug-like molecules, cementing their role in modern molecular modeling. This\nreview provides a comprehensive overview of the methodological foundations and\nrepresentative applications of GNNs in drug discovery, spanning tasks such as\nmolecular property prediction, virtual screening, molecular generation,\nbiomedical knowledge graph construction, and synthesis planning. Particular\nattention is given to recent methodological advances, including geometric GNNs,\ninterpretable models, uncertainty quantification, scalable graph architectures,\nand graph generative frameworks. We also discuss how these models integrate\nwith modern deep learning approaches, such as self-supervised learning,\nmulti-task learning, meta-learning and pre-training. Throughout this review, we\nhighlight the practical challenges and methodological bottlenecks encountered\nwhen applying GNNs to real-world drug discovery pipelines, and conclude with a\ndiscussion on future directions.", "comment": null, "cate": "q-bio.BM", "url": "http://arxiv.org/abs/2506.06915v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06942", "title": "Conditional Denoising Diffusion for ISAC Enhanced Channel Estimation in Cell-Free 6G", "authors": ["Mohammad Farzanullah", "Han Zhang", "Akram Bin Sediq", "Ali Afana", "Melike Erol-Kantarci"], "summary": "Cell-free Integrated Sensing and Communication (ISAC) aims to revolutionize\n6th Generation (6G) networks. By combining distributed access points with ISAC\ncapabilities, it boosts spectral efficiency, situational awareness, and\ncommunication reliability. Channel estimation is a critical step in cell-free\nISAC systems to ensure reliable communication, but its performance is usually\nlimited by challenges such as pilot contamination and noisy channel estimates.\nThis paper presents a novel framework leveraging sensing information as a key\ninput within a Conditional Denoising Diffusion Model (CDDM). In this framework,\nwe integrate CDDM with a Multimodal Transformer (MMT) to enhance channel\nestimation in ISAC-enabled cell-free systems. The MMT encoder effectively\ncaptures inter-modal relationships between sensing and location data, enabling\nthe CDDM to iteratively denoise and refine channel estimates. Simulation\nresults demonstrate that the proposed approach achieves significant performance\ngains. As compared with Least Squares (LS) and Minimum Mean Squared Error\n(MMSE) estimators, the proposed model achieves normalized mean squared error\n(NMSE) improvements of 8 dB and 9 dB, respectively. Moreover, we achieve a\n27.8% NMSE improvement compared to the traditional denoising diffusion model\n(TDDM), which does not incorporate sensing channel information. Additionally,\nthe model exhibits higher robustness against pilot contamination and maintains\nhigh accuracy under challenging conditions, such as low signal-to-noise ratios\n(SNRs). According to the simulation results, the model performs well for users\nnear sensing targets by leveraging the correlation between sensing and\ncommunication channels.", "comment": "IEEE PIMRC conference, 6 pages, 6 figures", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06942v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07335", "title": "Improving LLM Reasoning through Interpretable Role-Playing Steering", "authors": ["Anyi Wang", "Dong Shu", "Yifan Wang", "Yunpu Ma", "Mengnan Du"], "summary": "Role-playing has emerged as an effective technique for enhancing the\nreasoning capabilities of large language models (LLMs). However, existing\nmethods primarily rely on prompt engineering, which often lacks stability and\ninterpretability. In this paper, we introduce Sparse Autoencoder Role-Playing\nSteering (SRPS), a novel framework that identifies and manipulates internal\nmodel features associated with role-playing behavior. Our approach extracts\nlatent representations from role-play prompts, selects the most relevant\nfeatures based on activation patterns, and constructs a steering vector that\ncan be injected into the model's residual stream with controllable intensity.\nOur method enables fine-grained control over role-specific behavior and offers\ninsights into how role information influences internal model activations.\nExtensive experiments across various reasoning benchmarks and model sizes\ndemonstrate consistent performance gains. Notably, in the zero-shot\nchain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves\nfrom 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to\n45.10%. These results highlight the potential of SRPS to enhance reasoning\nability in LLMs, providing better interpretability and stability compared to\ntraditional prompt-based role-playing.", "comment": "21 pages, 8 figures, 8 tables", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07335v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06812", "title": "Advancing Question Generation with Joint Narrative and Difficulty Control", "authors": ["Bernardo Leite", "Henrique Lopes Cardoso"], "summary": "Question Generation (QG), the task of automatically generating questions from\na source input, has seen significant progress in recent years.\nDifficulty-controllable QG (DCQG) enables control over the difficulty level of\ngenerated questions while considering the learner's ability. Additionally,\nnarrative-controllable QG (NCQG) allows control over the narrative aspects\nembedded in the questions. However, research in QG lacks a focus on combining\nthese two types of control, which is important for generating questions\ntailored to educational purposes. To address this gap, we propose a strategy\nfor Joint Narrative and Difficulty Control, enabling simultaneous control over\nthese two attributes in the generation of reading comprehension questions. Our\nevaluation provides preliminary evidence that this approach is feasible, though\nit is not effective across all instances. Our findings highlight the conditions\nunder which the strategy performs well and discuss the trade-offs associated\nwith its application.", "comment": "Preprint. Accepted to the BEA 2025 Workshop (ACL)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06812v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07347", "title": "Distributed Risk-Sensitive Safety Filters for Uncertain Discrete-Time Systems", "authors": ["Armin Lederer", "Erfaun Noorani", "Andreas Krause"], "summary": "Ensuring safety in multi-agent systems is a significant challenge,\nparticularly in settings where centralized coordination is impractical. In this\nwork, we propose a novel risk-sensitive safety filter for discrete-time\nmulti-agent systems with uncertain dynamics that leverages control barrier\nfunctions (CBFs) defined through value functions. Our approach relies on\ncentralized risk-sensitive safety conditions based on exponential risk\noperators to ensure robustness against model uncertainties. We introduce a\ndistributed formulation of the safety filter by deriving two alternative\nstrategies: one based on worst-case anticipation and another on proximity to a\nknown safe policy. By allowing agents to switch between strategies, feasibility\ncan be ensured. Through detailed numerical evaluations, we demonstrate the\nefficacy of our approach in maintaining safety without being overly\nconservative.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07347v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06964", "title": "Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning", "authors": ["Subhojyoti Mukherjee", "Viet Dac Lai", "Raghavendra Addanki", "Ryan Rossi", "Seunghyun Yoon", "Trung Bui", "Anup Rao", "Jayakumar Subramanian", "Branislav Kveton"], "summary": "Question answering (QA) agents automatically answer questions posed in\nnatural language. In this work, we learn to ask clarifying questions in QA\nagents. The key idea in our method is to simulate conversations that contain\nclarifying questions and learn from them using reinforcement learning (RL). To\nmake RL practical, we propose and analyze offline RL objectives that can be\nviewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in\nlarge language models. Our work stands in a stark contrast to recently proposed\nmethods, based on SFT and direct preference optimization, which have additional\nhyper-parameters and do not directly optimize rewards. We compare to these\nmethods empirically and report gains in both optimized rewards and language\nquality.", "comment": "39 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06964v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07358", "title": "Lightweight Joint Audio-Visual Deepfake Detection via Single-Stream Multi-Modal Learning Framework", "authors": ["Kuiyuan Zhang", "Wenjie Pei", "Rushi Lan", "Yifang Guo", "Zhongyun Hua"], "summary": "Deepfakes are AI-synthesized multimedia data that may be abused for spreading\nmisinformation. Deepfake generation involves both visual and audio\nmanipulation. To detect audio-visual deepfakes, previous studies commonly\nemploy two relatively independent sub-models to learn audio and visual\nfeatures, respectively, and fuse them subsequently for deepfake detection.\nHowever, this may underutilize the inherent correlations between audio and\nvisual features. Moreover, utilizing two isolated feature learning sub-models\ncan result in redundant neural layers, making the overall model inefficient and\nimpractical for resource-constrained environments.\n  In this work, we design a lightweight network for audio-visual deepfake\ndetection via a single-stream multi-modal learning framework. Specifically, we\nintroduce a collaborative audio-visual learning block to efficiently integrate\nmulti-modal information while learning the visual and audio features. By\niteratively employing this block, our single-stream network achieves a\ncontinuous fusion of multi-modal features across its layers. Thus, our network\nefficiently captures visual and audio features without the need for excessive\nblock stacking, resulting in a lightweight network design. Furthermore, we\npropose a multi-modal classification module that can boost the dependence of\nthe visual and audio classifiers on modality content. It also enhances the\nwhole resistance of the video classifier against the mismatches between audio\nand visual modalities. We conduct experiments on the DF-TIMIT, FakeAVCeleb, and\nDFDC benchmark datasets. Compared to state-of-the-art audio-visual joint\ndetection methods, our method is significantly lightweight with only 0.48M\nparameters, yet it achieves superiority in both uni-modal and multi-modal\ndeepfakes, as well as in unseen types of deepfakes.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07358v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06989", "title": "Correcting for Position Bias in Learning to Rank: A Control Function Approach", "authors": ["Md Aminul Islam", "Kathryn Vasilaky", "Elena Zheleva"], "summary": "Implicit feedback data, such as user clicks, is commonly used in\nlearning-to-rank (LTR) systems because it is easy to collect and it often\nreflects user preferences. However, this data is prone to various biases, and\ntraining an LTR system directly on biased data can result in suboptimal ranking\nperformance. One of the most prominent and well-studied biases in implicit\nfeedback data is position bias, which occurs because users are more likely to\ninteract with higher-ranked documents regardless of their true relevance. In\nthis paper, we propose a novel control function-based method that accounts for\nposition bias in a two-stage process. The first stage uses exogenous variation\nfrom the residuals of the ranking process to correct for position bias in the\nsecond stage click equation. Unlike previous position bias correction methods,\nour method does not require knowledge of the click or propensity model and\nallows for nonlinearity in the underlying ranking model. Moreover, our method\nis general and allows for debiasing any state-of-the-art ranking algorithm by\nplugging it into the second stage. We also introduce a technique to debias\nvalidation clicks for hyperparameter tuning to select the optimal model in the\nabsence of unbiased validation data. Experimental results demonstrate that our\nmethod outperforms state-of-the-art approaches in correcting for position bias.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06989v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07011", "title": "Half-AVAE: Adversarial-Enhanced Factorized and Structured Encoder-Free VAE for Underdetermined Independent Component Analysis", "authors": ["Yuan-Hao Wei", "Yan-Jie Sun"], "summary": "This study advances the Variational Autoencoder (VAE) framework by addressing\nchallenges in Independent Component Analysis (ICA) under both determined and\nunderdetermined conditions, focusing on enhancing the independence and\ninterpretability of latent variables. Traditional VAEs map observed data to\nlatent variables and back via an encoder-decoder architecture, but struggle\nwith underdetermined ICA where the number of latent variables exceeds observed\nsignals. The proposed Half Adversarial VAE (Half-AVAE) builds on the\nencoder-free Half-VAE framework, eliminating explicit inverse mapping to tackle\nunderdetermined scenarios. By integrating adversarial networks and External\nEnhancement (EE) terms, Half-AVAE promotes mutual independence among latent\ndimensions, achieving factorized and interpretable representations. Experiments\nwith synthetic signals demonstrate that Half-AVAE outperforms baseline models,\nincluding GP-AVAE and Half-VAE, in recovering independent components under\nunderdetermined conditions, as evidenced by lower root mean square errors. The\nstudy highlights the flexibility of VAEs in variational inference, showing that\nencoder omission, combined with adversarial training and structured priors,\nenables effective solutions for complex ICA tasks, advancing applications in\ndisentanglement, causal inference, and generative modeling.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07011v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06820", "title": "Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs", "authors": ["Wenyu Zhang", "Yingxu He", "Geyu Lin", "Zhuohan Liu", "Shuo Sun", "Bin Wang", "Xunlong Zou", "Jeremy H. M. Wong", "Qiongqiong Wang", "Hardik B. Sailor", "Nancy F. Chen", "Ai Ti Aw"], "summary": "Audio Large Language Models (AudioLLMs) have achieved strong results in\nsemantic tasks like speech recognition and translation, but remain limited in\nmodeling paralinguistic cues such as emotion. Existing approaches often treat\nemotion understanding as a classification problem, offering little insight into\nthe underlying rationale behind predictions. In this work, we explore emotion\nreasoning, a strategy that leverages the generative capabilities of AudioLLMs\nto enhance emotion recognition by producing semantically aligned,\nevidence-grounded explanations. To support this in multitask AudioLLMs, we\nintroduce a unified framework combining reasoning-augmented data supervision,\ndual-encoder architecture, and task-alternating training. This approach enables\nAudioLLMs to effectively learn different tasks while incorporating emotional\nreasoning. Experiments on IEMOCAP and MELD show that our approach not only\nimproves emotion prediction accuracy but also enhances the coherence and\nevidential grounding of the generated responses.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06820v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07373", "title": "HyColor: An Efficient Heuristic Algorithm for Graph Coloring", "authors": ["Enqiang Zhu", "Yu Zhang", "Haopeng Sun", "Ziqi Wei", "Witold Pedrycz", "Chanjuan Liu", "Jin Xu"], "summary": "The graph coloring problem (GCP) is a classic combinatorial optimization\nproblem that aims to find the minimum number of colors assigned to vertices of\na graph such that no two adjacent vertices receive the same color. GCP has been\nextensively studied by researchers from various fields, including mathematics,\ncomputer science, and biological science. Due to the NP-hard nature, many\nheuristic algorithms have been proposed to solve GCP. However, existing GCP\nalgorithms focus on either small hard graphs or large-scale sparse graphs (with\nup to 10^7 vertices). This paper presents an efficient hybrid heuristic\nalgorithm for GCP, named HyColor, which excels in handling large-scale sparse\ngraphs while achieving impressive results on small dense graphs. The efficiency\nof HyColor comes from the following three aspects: a local decision strategy to\nimprove the lower bound on the chromatic number; a graph-reduction strategy to\nreduce the working graph; and a k-core and mixed degree-based greedy heuristic\nfor efficiently coloring graphs. HyColor is evaluated against three\nstate-of-the-art GCP algorithms across four benchmarks, comprising three\nlarge-scale sparse graph benchmarks and one small dense graph benchmark,\ntotaling 209 instances. The results demonstrate that HyColor consistently\noutperforms existing heuristic algorithms in both solution accuracy and\ncomputational efficiency for the majority of instances. Notably, HyColor\nachieved the best solutions in 194 instances (over 93%), with 34 of these\nsolutions significantly surpassing those of other algorithms. Furthermore,\nHyColor successfully determined the chromatic number and achieved optimal\ncoloring in 128 instances.", "comment": "14 pages, 4 figures", "cate": "cs.DM", "url": "http://arxiv.org/abs/2506.07373v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07083", "title": "Inverse Design of Metamaterials with Manufacturing-Guiding Spectrum-to-Structure Conditional Diffusion Model", "authors": ["Jiawen Li", "Jiang Guo", "Yuanzhe Li", "Zetian Mao", "Jiaxing Shen", "Tashi Xu", "Diptesh Das", "Jinming He", "Run Hu", "Yaerim Lee", "Koji Tsuda", "Junichiro Shiomi"], "summary": "Metamaterials are artificially engineered structures that manipulate\nelectromagnetic waves, having optical properties absent in natural materials.\nRecently, machine learning for the inverse design of metamaterials has drawn\nattention. However, the highly nonlinear relationship between the metamaterial\nstructures and optical behaviour, coupled with fabrication difficulties, poses\nchallenges for using machine learning to design and manufacture complex\nmetamaterials. Herein, we propose a general framework that implements\ncustomised spectrum-to-shape and size parameters to address one-to-many\nmetamaterial inverse design problems using conditional diffusion models. Our\nmethod exhibits superior spectral prediction accuracy, generates a diverse\nrange of patterns compared to other typical generative models, and offers\nvaluable prior knowledge for manufacturing through the subsequent analysis of\nthe diverse generated results, thereby facilitating the experimental\nfabrication of metamaterial designs. We demonstrate the efficacy of the\nproposed method by successfully designing and fabricating a free-form\nmetamaterial with a tailored selective emission spectrum for thermal camouflage\napplications.", "comment": "20 pages, 7 figures", "cate": "physics.optics", "url": "http://arxiv.org/abs/2506.07083v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06824", "title": "Deep reinforcement learning-based joint real-time energy scheduling for green buildings with heterogeneous battery energy storage devices", "authors": ["Chi Liu", "Zhezhuang Xu", "Jiawei Zhou", "Yazhou Yuan", "Kai Ma", "Meng Yuan"], "summary": "Green buildings (GBs) with renewable energy and building energy management\nsystems (BEMS) enable efficient energy use and support sustainable development.\nElectric vehicles (EVs), as flexible storage resources, enhance system\nflexibility when integrated with stationary energy storage systems (ESS) for\nreal-time scheduling. However, differing degradation and operational\ncharacteristics of ESS and EVs complicate scheduling strategies. This paper\nproposes a model-free deep reinforcement learning (DRL) method for joint\nreal-time scheduling based on a combined battery system (CBS) integrating ESS\nand EVs. We develop accurate degradation models and cost estimates, prioritize\nEV travel demands, and enable collaborative ESS-EV operation under varying\nconditions. A prediction model optimizes energy interaction between CBS and\nBEMS. To address heterogeneous states, action coupling, and learning\nefficiency, the DRL algorithm incorporates double networks, a dueling\nmechanism, and prioritized experience replay. Experiments show a 37.94 percent\nto 40.01 percent reduction in operating costs compared to a mixed-integer\nlinear programming (MILP) approach.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.06824v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07140", "title": "Quantile-Optimal Policy Learning under Unmeasured Confounding", "authors": ["Zhongren Chen", "Siyu Chen", "Zhengling Qi", "Xiaohong Chen", "Zhuoran Yang"], "summary": "We study quantile-optimal policy learning where the goal is to find a policy\nwhose reward distribution has the largest $\\alpha$-quantile for some $\\alpha\n\\in (0, 1)$. We focus on the offline setting whose generating process involves\nunobserved confounders. Such a problem suffers from three main challenges: (i)\nnonlinearity of the quantile objective as a functional of the reward\ndistribution, (ii) unobserved confounding issue, and (iii) insufficient\ncoverage of the offline dataset. To address these challenges, we propose a\nsuite of causal-assisted policy learning methods that provably enjoy strong\ntheoretical guarantees under mild conditions. In particular, to address (i) and\n(ii), using causal inference tools such as instrumental variables and negative\ncontrols, we propose to estimate the quantile objectives by solving nonlinear\nfunctional integral equations. Then we adopt a minimax estimation approach with\nnonparametric models to solve these integral equations, and propose to\nconstruct conservative policy estimates that address (iii). The final policy is\nthe one that maximizes these pessimistic estimates. In addition, we propose a\nnovel regularized policy learning method that is more amenable to computation.\nFinally, we prove that the policies learned by these methods are\n$\\tilde{\\mathscr{O}}(n^{-1/2})$ quantile-optimal under a mild coverage\nassumption on the offline dataset. Here, $\\tilde{\\mathscr{O}}(\\cdot)$ omits\npoly-logarithmic factors. To the best of our knowledge, we propose the first\nsample-efficient policy learning algorithms for estimating the quantile-optimal\npolicy when there exist unmeasured confounding.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07140v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06829", "title": "In-Sensor Motion Recognition with Memristive System and Light Sensing Surfaces", "authors": ["Hritom Das", "Imran Fahad", "SNB Tushar", "Sk Hasibul Alam", "Graham Buchanan", "Danny Scott", "Garrett S. Rose", "Sai Swaminathan"], "summary": "In this paper, we introduce a novel device architecture that merges\nmemristive devices with light-sensing surfaces, for energy-efficient motion\nrecognition at the edge. Our light-sensing surface captures motion data through\nin-sensor computation. This data is then processed using a memristive system\nequipped with a HfO2-based synaptic device, coupled with a winner-take-all\n(WTA) circuit, tailored for low-power motion classification tasks. We validate\nour end-to-end system using four distinct human hand gestures - left-to-right,\nright-to-left, bottom-to-top, and top-to-bottom movements - to assess energy\nefficiency and classification robustness. Our experiments show that the system\nrequires an average of only 4.17 nJ for taking our processed analog signal and\nmapping weights onto our memristive system and 0.952 nJ for testing per\nmovement class, achieving 97.22% accuracy even under 5% noise interference. A\nkey advantage of our proposed architecture is its low energy requirement,\nenabling the integration of energy-harvesting solutions such as solar power for\nsustainable autonomous operation. Additionally, our approach enhances data\nprivacy by processing data locally, reducing the need for external data\ntransmission and storage.", "comment": "The paper was published in the 2024 IEEE Computer Society Annual\n  Symposium on VLSI (ISVLSI)", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.06829v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07171", "title": "RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality", "authors": ["Chenlong Zhang", "Zhuoran Jin", "Hongbang Yuan", "Jiaheng Wei", "Tong Zhou", "Kang Liu", "Jun Zhao", "Yubo Chen"], "summary": "The widespread deployment of Large Language Models (LLMs) trained on massive,\nuncurated corpora has raised growing concerns about the inclusion of sensitive,\ncopyrighted, or illegal content. This has led to increasing interest in LLM\nunlearning: the task of selectively removing specific information from a model\nwithout retraining from scratch or degrading overall utility. However, existing\nmethods often rely on large-scale forget and retain datasets, and suffer from\nunnatural responses, poor generalization, or catastrophic utility loss. In this\nwork, we propose Reinforcement UnLearning (RULE), an efficient framework that\nformulates unlearning as a refusal boundary optimization problem. RULE is\ntrained with a small portion of the forget set and synthesized boundary\nqueries, using a verifiable reward function that encourages safe refusal on\nforget--related queries while preserving helpful responses on permissible\ninputs. We provide both theoretical and empirical evidence demonstrating the\neffectiveness of RULE in achieving targeted unlearning without compromising\nmodel utility. Experimental results show that, with only $12%$ forget set and\n$8%$ synthesized boundary data, RULE outperforms existing baselines by up to\n$17.5%$ forget quality and $16.3%$ naturalness response while maintaining\ngeneral utility, achieving forget--retain Pareto optimality. Remarkably, we\nfurther observe that RULE improves the naturalness of model outputs, enhances\ntraining efficiency, and exhibits strong generalization ability, generalizing\nrefusal behavior to semantically related but unseen queries.", "comment": "Paper under review", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07171v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07199", "title": "Audio synthesizer inversion in symmetric parameter spaces with approximately equivariant flow matching", "authors": ["Ben Hayes", "Charalampos Saitis", "György Fazekas"], "summary": "Many audio synthesizers can produce the same signal given different parameter\nconfigurations, meaning the inversion from sound to parameters is an inherently\nill-posed problem. We show that this is largely due to intrinsic symmetries of\nthe synthesizer, and focus in particular on permutation invariance. First, we\ndemonstrate on a synthetic task that regressing point estimates under\npermutation symmetry degrades performance, even when using a\npermutation-invariant loss function or symmetry-breaking heuristics. Then,\nviewing equivalent solutions as modes of a probability distribution, we show\nthat a conditional generative model substantially improves performance.\nFurther, acknowledging the invariance of the implicit parameter distribution,\nwe find that performance is further improved by using a permutation equivariant\ncontinuous normalizing flow. To accommodate intricate symmetries in real\nsynthesizers, we also propose a relaxed equivariance strategy that adaptively\ndiscovers relevant symmetries from data. Applying our method to Surge XT, a\nfull-featured open source synthesizer used in real world audio production, we\nfind our method outperforms regression and generative baselines across audio\nreconstruction metrics.", "comment": "Accepted at ISMIR 2025", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07199v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07248", "title": "Improving the Efficiency of Long Document Classification using Sentence Ranking Approach", "authors": ["Prathamesh Kokate", "Mitali Sarnaik", "Manavi Khopade", "Raviraj Joshi"], "summary": "Long document classification poses challenges due to the computational\nlimitations of transformer-based models, particularly BERT, which are\nconstrained by fixed input lengths and quadratic attention complexity.\nMoreover, using the full document for classification is often redundant, as\nonly a subset of sentences typically carries the necessary information. To\naddress this, we propose a TF-IDF-based sentence ranking method that improves\nefficiency by selecting the most informative content. Our approach explores\nfixed-count and percentage-based sentence selection, along with an enhanced\nscoring strategy combining normalized TF-IDF scores and sentence length.\nEvaluated on the MahaNews LDC dataset of long Marathi news articles, the method\nconsistently outperforms baselines such as first, last, and random sentence\nselection. With MahaBERT-v2, we achieve near-identical classification accuracy\nwith just a 0.33 percent drop compared to the full-context baseline, while\nreducing input size by over 50 percent and inference latency by 43 percent.\nThis demonstrates that significant context reduction is possible without\nsacrificing performance, making the method practical for real-world long\ndocument classification tasks.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07248v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07424", "title": "Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models", "authors": ["Kyeonghyun Kim", "Jinhee Jang", "Juhwan Choi", "Yoonji Lee", "Kyohoon Jin", "YoungBin Kim"], "summary": "Large language models (LLMs) are renowned for their extensive linguistic\nknowledge and strong generalization capabilities, but their high computational\ndemands make them unsuitable for resource-constrained environments. In\ncontrast, small language models (SLMs) are computationally efficient but often\nlack the broad generalization capacity of LLMs. To bridge this gap, we propose\nPiFi, a novel framework that combines the strengths of both LLMs and SLMs to\nachieve high performance while maintaining efficiency. PiFi integrates a single\nfrozen layer from an LLM into a SLM and fine-tunes the combined model for\nspecific tasks, boosting performance without a significant increase in\ncomputational cost. We show that PiFi delivers consistent performance\nimprovements across a range of natural language processing tasks, including\nboth natural language understanding and generation. Moreover, our findings\ndemonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing\ngeneralization to unseen domains and facilitating the transfer of linguistic\nabilities.", "comment": "ACL 2025 main conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07424v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07259", "title": "ALINE: Joint Amortization for Bayesian Inference and Active Data Acquisition", "authors": ["Daolang Huang", "Xinyi Wen", "Ayush Bharti", "Samuel Kaski", "Luigi Acerbi"], "summary": "Many critical applications, from autonomous scientific discovery to\npersonalized medicine, demand systems that can both strategically acquire the\nmost informative data and instantaneously perform inference based upon it.\nWhile amortized methods for Bayesian inference and experimental design offer\npart of the solution, neither approach is optimal in the most general and\nchallenging task, where new data needs to be collected for instant inference.\nTo tackle this issue, we introduce the Amortized Active Learning and Inference\nEngine (ALINE), a unified framework for amortized Bayesian inference and active\ndata acquisition. ALINE leverages a transformer architecture trained via\nreinforcement learning with a reward based on self-estimated information gain\nprovided by its own integrated inference component. This allows it to\nstrategically query informative data points while simultaneously refining its\npredictions. Moreover, ALINE can selectively direct its querying strategy\ntowards specific subsets of model parameters or designated predictive tasks,\noptimizing for posterior estimation, data prediction, or a mixture thereof.\nEmpirical results on regression-based active learning, classical Bayesian\nexperimental design benchmarks, and a psychometric model with selectively\ntargeted parameters demonstrate that ALINE delivers both instant and accurate\ninference along with efficient selection of informative points.", "comment": "27 pages, 13 figures", "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07259v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07261", "title": "RADAR: Recall Augmentation through Deferred Asynchronous Retrieval", "authors": ["Amit Jaspal", "Qian Dang", "Ajantha Ramineni"], "summary": "Modern large-scale recommender systems employ multi-stage ranking funnel\n(Retrieval, Pre-ranking, Ranking) to balance engagement and computational\nconstraints (latency, CPU). However, the initial retrieval stage, often relying\non efficient but less precise methods like K-Nearest Neighbors (KNN), struggles\nto effectively surface the most engaging items from billion-scale catalogs,\nparticularly distinguishing highly relevant and engaging candidates from merely\nrelevant ones. We introduce Recall Augmentation through Deferred Asynchronous\nRetrieval (RADAR), a novel framework that leverages asynchronous, offline\ncomputation to pre-rank a significantly larger candidate set for users using\nthe full complexity ranking model. These top-ranked items are stored and\nutilized as a high-quality retrieval source during online inference, bypassing\nonline retrieval and pre-ranking stages for these candidates. We demonstrate\nthrough offline experiments that RADAR significantly boosts recall (2X\nRecall@200 vs DNN retrieval baseline) by effectively combining a larger\nretrieved candidate set with a more powerful ranking model. Online A/B tests\nconfirm a +0.8% lift in topline engagement metrics, validating RADAR as a\npractical and effective method to improve recommendation quality under strict\nonline serving constraints.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.07261v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07434", "title": "Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding", "authors": ["Feifan Song", "Shaohang Wei", "Wen Luo", "Yuxuan Fan", "Tianyu Liu", "Guoyin Wang", "Houfeng Wang"], "summary": "Large Language Models (LLMs) require alignment with human preferences to\navoid generating offensive, false, or meaningless content. Recently,\nlow-resource methods for LLM alignment have been popular, while still facing\nchallenges in obtaining both high-quality and aligned content. Motivated by the\nobservation that the difficulty of generating aligned responses is concentrated\nat the beginning of decoding, we propose a novel framework, Weak-to-Strong\nDecoding (WSD), to enhance the alignment ability of base models by the guidance\nof a small aligned model. The small model first drafts well-aligned beginnings,\nfollowed by the large base model to continue the rest, controlled by a\nwell-designed auto-switch mechanism. We also collect a new dataset, GenerAlign,\nto fine-tune a small-sized Pilot-3B as the draft model, which effectively\nenhances different base models under the WSD framework to outperform all\nbaseline methods, while avoiding degradation on downstream tasks, termed as the\nalignment tax. Extensive experiments are further conducted to examine the\nimpact of different settings and time efficiency, as well as analyses on the\nintrinsic mechanisms of WSD in depth.", "comment": "Accepted by ACL 2025 Findings", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07434v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06844", "title": "Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models", "authors": ["Naibin Gu", "Peng Fu", "Xiyu Liu", "Ke Ma", "Zheng Lin", "Weiping Wang"], "summary": "Parameter-efficient fine-tuning (PEFT) has become a common method for\nfine-tuning large language models, where a base model can serve multiple users\nthrough PEFT module switching. To enhance user experience, base models require\nperiodic updates. However, once updated, PEFT modules fine-tuned on previous\nversions often suffer substantial performance degradation on newer versions.\nRe-tuning these numerous modules to restore performance would incur significant\ncomputational costs. Through a comprehensive analysis of the changes that occur\nduring base model updates, we uncover an interesting phenomenon: continual\ntraining primarily affects task-specific knowledge stored in Feed-Forward\nNetworks (FFN), while having less impact on the task-specific pattern in the\nAttention mechanism. Based on these findings, we introduce Trans-PEFT, a novel\napproach that enhances the PEFT module by focusing on the task-specific pattern\nwhile reducing its dependence on certain knowledge in the base model. Further\ntheoretical analysis supports our approach. Extensive experiments across 7 base\nmodels and 12 datasets demonstrate that Trans-PEFT trained modules can maintain\nperformance on updated base models without re-tuning, significantly reducing\nmaintenance overhead in real-world applications.", "comment": "Accepted by ACL 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06844v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07299", "title": "Uncertainty-Aware Strategies: A Model-Agnostic Framework for Robust Financial Optimization through Subsampling", "authors": ["Hans Buehler", "Blanka Horvath", "Yannick Limmer", "Thorsten Schmidt"], "summary": "This paper addresses the challenge of model uncertainty in quantitative\nfinance, where decisions in portfolio allocation, derivative pricing, and risk\nmanagement rely on estimating stochastic models from limited data. In practice,\nthe unavailability of the true probability measure forces reliance on an\nempirical approximation, and even small misestimations can lead to significant\ndeviations in decision quality. Building on the framework of Klibanoff et al.\n(2005), we enhance the conventional objective - whether this is expected\nutility in an investing context or a hedging metric - by superimposing an outer\n\"uncertainty measure\", motivated by traditional monetary risk measures, on the\nspace of models. In scenarios where a natural model distribution is lacking or\nBayesian methods are impractical, we propose an ad hoc subsampling strategy,\nanalogous to bootstrapping in statistical finance and related to mini-batch\nsampling in deep learning, to approximate model uncertainty. To address the\nquadratic memory demands of naive implementations, we also present an adapted\nstochastic gradient descent algorithm that enables efficient parallelization.\nThrough analytical, simulated, and empirical studies - including multi-period,\nreal data and high-dimensional examples - we demonstrate that uncertainty\nmeasures outperform traditional mixture of measures strategies and our\nmodel-agnostic subsampling-based approach not only enhances robustness against\nmodel risk but also achieves performance comparable to more elaborate Bayesian\nmethods.", "comment": "18 pages, 12 figures", "cate": "q-fin.CP", "url": "http://arxiv.org/abs/2506.07299v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07449", "title": "LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking", "authors": ["Vahid Azizi", "Fatemeh Koochaki"], "summary": "Recent advances in Large Language Models (LLMs) have driven their adoption in\nrecommender systems through Retrieval-Augmented Generation (RAG) frameworks.\nHowever, existing RAG approaches predominantly rely on flat, similarity-based\nretrieval that fails to leverage the rich relational structure inherent in\nuser-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass,\nend-to-end trainable framework that integrates personalized knowledge graph\ncontext into LLM-based recommendation ranking. Our approach extends the\nLlamaRec architecture by incorporating a lightweight user preference module\nthat dynamically identifies salient relation paths within a heterogeneous\nknowledge graph constructed from user behavior and item metadata. These\npersonalized subgraphs are seamlessly integrated into prompts for a fine-tuned\nLlama-2 model, enabling efficient and interpretable recommendations through a\nunified inference step. Comprehensive experiments on ML-100K and Amazon Beauty\ndatasets demonstrate consistent and significant improvements over LlamaRec\nacross key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates\nthe critical value of structured reasoning in LLM-based recommendations and\nestablishes a foundation for scalable, knowledge-aware personalization in\nnext-generation recommender systems. Code is available\nat~\\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.07449v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07458", "title": "KScope: A Framework for Characterizing the Knowledge Status of Language Models", "authors": ["Yuxin Xiao", "Shan Chen", "Jack Gallifant", "Danielle Bitterman", "Thomas Hartvigsen", "Marzyeh Ghassemi"], "summary": "Characterizing a large language model's (LLM's) knowledge of a given question\nis challenging. As a result, prior work has primarily examined LLM behavior\nunder knowledge conflicts, where the model's internal parametric memory\ncontradicts information in the external context. However, this does not fully\nreflect how well the model knows the answer to the question. In this paper, we\nfirst introduce a taxonomy of five knowledge statuses based on the consistency\nand correctness of LLM knowledge modes. We then propose KScope, a hierarchical\nframework of statistical tests that progressively refines hypotheses about\nknowledge modes and characterizes LLM knowledge into one of these five\nstatuses. We apply KScope to nine LLMs across four datasets and systematically\nestablish: (1) Supporting context narrows knowledge gaps across models. (2)\nContext features related to difficulty, relevance, and familiarity drive\nsuccessful knowledge updates. (3) LLMs exhibit similar feature preferences when\npartially correct or conflicted, but diverge sharply when consistently wrong.\n(4) Context summarization constrained by our feature analysis, together with\nenhanced credibility, further improves update effectiveness and generalizes\nacross LLMs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07458v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07463", "title": "CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models", "authors": ["Guang Liu", "Liangdong Wang", "Jijie Li", "Yang Yu", "Yao Xu", "Jiabei Chen", "Yu Bai", "Feng Liao", "Yonghua Lin"], "summary": "We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered\nfor superior data quality and diverse human-like reasoning trajectory. CCI4.0\noccupies roughly $35$ TB of disk space and comprises two sub-datasets:\nCCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully\ncurated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and\ndiverse sources from math, wiki, arxiv, and code. Although these data are\nmostly sourced from well-processed datasets, the quality standards of various\ndomains are dynamic and require extensive expert experience and labor to\nprocess. So, we propose a novel pipeline justifying data quality mainly based\non models through two-stage deduplication, multiclassifier quality scoring, and\ndomain-aware fluency filtering. We extract $4.5$ billion pieces of\nCoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the\ndistillation of CoT from larger models, our proposed staged CoT extraction\nexemplifies diverse reasoning patterns and significantly decreases the\npossibility of hallucination. Empirical evaluations demonstrate that LLMs\npre-trained in CCI4.0 benefit from cleaner, more reliable training signals,\nyielding consistent improvements in downstream tasks, especially in math and\ncode reflection tasks. Our results underscore the critical role of rigorous\ndata curation and human thinking templates in advancing LLM performance,\nshedding some light on automatically processing pretraining corpora.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07463v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07351", "title": "Decentralized Optimization on Compact Submanifolds by Quantized Riemannian Gradient Tracking", "authors": ["Jun Chen", "Lina Liu", "Tianyi Zhu", "Yong Liu", "Guang Dai", "Yunliang Jiang", "Ivor W. Tsang"], "summary": "This paper considers the problem of decentralized optimization on compact\nsubmanifolds, where a finite sum of smooth (possibly non-convex) local\nfunctions is minimized by $n$ agents forming an undirected and connected graph.\nHowever, the efficiency of distributed optimization is often hindered by\ncommunication bottlenecks. To mitigate this, we propose the Quantized\nRiemannian Gradient Tracking (Q-RGT) algorithm, where agents update their local\nvariables using quantized gradients. The introduction of quantization noise\nallows our algorithm to bypass the constraints of the accurate Riemannian\nprojection operator (such as retraction), further improving iterative\nefficiency. To the best of our knowledge, this is the first algorithm to\nachieve an $\\mathcal{O}(1/K)$ convergence rate in the presence of quantization,\nmatching the convergence rate of methods without quantization. Additionally, we\nexplicitly derive lower bounds on decentralized consensus associated with a\nfunction of quantization levels. Numerical experiments demonstrate that Q-RGT\nperforms comparably to non-quantized methods while reducing communication\nbottlenecks and computational overhead.", "comment": null, "cate": "math.OC", "url": "http://arxiv.org/abs/2506.07351v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06863", "title": "Fourth- and higher-order finite element methods for the incompressible Navier-Stokes equations with Dirichlet boundary conditions", "authors": ["Yang Li", "Heyu Wang", "Qinghai Zhang"], "summary": "Inspired by the unconstrained pressure Poisson equation (PPE) formulation\n[Liu, Liu, \\& Pego, Comm. Pure Appl. Math. 60 (2007): 1443-1487], we previously\nproposed the generic projection and unconstrained PPE (GePUP) formulation\n[Zhang, J. Sci. Comput. 67 (2016): 1134-1180] for numerically solving the\nincompressible Navier-Stokes equations (INSE) with no-slip boundary conditions.\nIn GePUP, the main evolutionary variable does not have to be solenoidal with\nits divergence controlled by a heat equation. This work presents high-order\nfinite-element solvers for the INSE under the framework of method-of-lines.\nContinuous Lagrange finite elements of equal order are utilized for the\nvelocity and pressure finite element spaces to discretize the weak form of\nGePUP in space, while high-order implicit-explicit Runge-Kutta methods are then\nemployed to treat the stiff diffusion term implicitly and the other terms\nexplicitly. Due to the implicit treatment of the diffusion term, the time step\nsize is only restricted by convection. The solver is efficient in that\nadvancing the solution at each time step only involves solving a sequence of\nlinear systems either on the velocity or on the pressure with geometric\nmultigrid methods. Furthermore, the solver is enhanced with adaptive mesh\nrefinement so that the multiple length scales and time scales in flows at\nmoderate or high Reynolds numbers can be efficiently resolved. Numerical tests\nwith various Reynolds numbers are performed for the single-vortex test, the\nlid-driven cavity, and the flow past a cylinder/sphere, demonstrating the\nhigh-order accuracy of GePUP-FEM both in time and in space and its capability\nof accurately and efficiently capturing the right physics. Moreover, our solver\noffers the flexibility in choosing velocity and pressure finite element spaces\nand is free of the standard inf-sup condition.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06863v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07520", "title": "LeVo: High-Quality Song Generation with Multi-Preference Alignment", "authors": ["Shun Lei", "Yaoxun Xu", "Zhiwei Lin", "Huaicheng Zhang", "Wei Tan", "Hangting Chen", "Jianwei Yu", "Yixuan Zhang", "Chenyu Yang", "Haina Zhu", "Shuai Wang", "Zhiyong Wu", "Dong Yu"], "summary": "Recent advances in large language models (LLMs) and audio language models\nhave significantly improved music generation, particularly in lyrics-to-song\ngeneration. However, existing approaches still struggle with the complex\ncomposition of songs and the scarcity of high-quality data, leading to\nlimitations in sound quality, musicality, instruction following, and\nvocal-instrument harmony. To address these challenges, we introduce LeVo, an\nLM-based framework consisting of LeLM and a music codec. LeLM is capable of\nparallelly modeling two types of tokens: mixed tokens, which represent the\ncombined audio of vocals and accompaniment to achieve vocal-instrument harmony,\nand dual-track tokens, which separately encode vocals and accompaniment for\nhigh-quality song generation. It employs two decoder-only transformers and a\nmodular extension training strategy to prevent interference between different\ntoken types. To further enhance musicality and instruction following, we\nintroduce a multi-preference alignment method based on Direct Preference\nOptimization (DPO). This method handles diverse human preferences through a\nsemi-automatic data construction process and DPO post-training. Experimental\nresults demonstrate that LeVo consistently outperforms existing methods on both\nobjective and subjective metrics. Ablation studies further justify the\neffectiveness of our designs. Audio examples are available at\nhttps://levo-demo.github.io/.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07520v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06877", "title": "Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning", "authors": ["Jiaxing Guo", "Wenjie Yang", "Shengzhong Zhang", "Tongshan Xu", "Lun Du", "Da Zheng", "Zengfeng Huang"], "summary": "Outcome-rewarded Large Language Models (LLMs) have demonstrated remarkable\nsuccess in mathematical problem-solving. However, this success often masks a\ncritical issue: models frequently achieve correct answers through fundamentally\nunsound reasoning processes, a phenomenon indicative of reward hacking. We\nintroduce MathOlympiadEval, a new dataset with fine-grained annotations, which\nreveals a significant gap between LLMs' answer correctness and their low\nprocess correctness. Existing automated methods like LLM-as-a-judge struggle to\nreliably detect these reasoning flaws. To address this, we propose\nParaStepVerifier, a novel methodology for meticulous, step-by-step verification\nof mathematical solutions. ParaStepVerifier identifies incorrect reasoning\nsteps. Empirical results demonstrate that ParaStepVerifier substantially\nimproves the accuracy of identifying flawed solutions compared to baselines,\nespecially for complex, multi-step problems. This offers a more robust path\ntowards evaluating and training LLMs with genuine mathematical reasoning.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06877v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06879", "title": "A structure-preserving, second-order-in-time scheme for the von Neumann equation with power nonlinearity", "authors": ["Agissilaos Athanassoulis", "Fotini Karakatsani", "Irene Kyza"], "summary": "In this paper we propose a structure-preserving, linearly implicit,\nsecond-order-in-time scheme for the numerical solution of the von Neumann\nequation with power nonlinearity (also known as the Alber equation). Fourth\norder finite differences are used for the spatial discretization. We highlight\nthe importance of the correct initialization of the method in achieving the\nexpected order of convergence in space and time. As illustrative examples, we\ninvestigate the bifurcation from Landau damping to modulation instability. In\nthat context, amplification factors in the fully developed modulation\ninstability for this nonlinear equation are computed for the first time.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06879v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06880", "title": "Estimation of sparse polynomial approximation error to continuous function", "authors": ["Renzhong Feng", "Bowen Zhang"], "summary": "The sparse polynomial approximation of continuous functions has emerged as a\nprominent area of interest in function approximation theory in recent years. A\nkey challenge within this domain is the accurate estimation of approximation\nerrors. This paper focuses on continuous functions, characterizing their\nsampled values as a combination of the values of their best approximation\npolynomials within a finite-dimensional polynomial space and the associated\nremainder terms. Consequently, the sampled values of a function can be\ninterpreted as noisy samples of the values of its best approximation\npolynomial, with the noise equivalent to the remainder term's values at those\npoints. By selecting a uniformly bounded orthonormal polynomial system as the\nbasis for this finite-dimensional space, it becomes feasible to formulate noise\nconstraint inequalities and l1-minimization problems or their weighted\nl1-minimization variants. This paper provides estimations for the approximation\nerror of the sparse polynomial derived from the l1-minimization method,\ncharacterizing the error in terms of the quasi-norm of the sampled function or\nits best uniform approximation polynomial, the sparsity, and the best\napproximation error. The analysis reveals that if the sampled function is a\nsparse polynomial from a finite-dimensional space, it can be reconstructed\nexactly. Moreover, it is observed that the smoother the sampled function, the\nfewer degrees of the sparse polynomial are required to attain a given\napproximation accuracy. The paper also extends this analysis to estimate the\nL2-norm approximation error for the sparse polynomial obtained via the weighted\nl1-minimization method, noting that in this context, the orthonormal polynomial\nsystem does not need to be uniformly bounded for the conclusions to hold.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06880v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07557", "title": "SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition", "authors": ["Mengsong Wu", "Di Zhang", "Yuqiang Li", "Dongzhan Zhou", "Wenliang Chen"], "summary": "While Large Language Models (LLMs) have achieved remarkable success in a wide\nrange of applications, their performance often degrades in complex reasoning\ntasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a\nnovel framework that leverages a modified Monte Carlo Tree Search (MCTS) to\nenhance LLM reasoning without relying on external reward models. By redefining\nthe Upper Confidence Bound scoring to align with intrinsic self-evaluation\ncapabilities of LLMs and decomposing the inference process into atomic subtasks\naugmented with semantic clustering at each node, SELT effectively balances\nexploration and exploitation, reduces redundant reasoning paths, and mitigates\nhallucination. We validate our approach on challenging benchmarks, including\nthe knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT\nachieves significant improvements in answer accuracy and reasoning robustness\ncompared to baseline methods. Notably, our framework operates without\ntask-specific fine-tuning, demonstrating strong generalizability across diverse\nreasoning tasks. Relevant results and code are available at\nhttps://github.com/fairyshine/SELT .", "comment": "11 pages, 5 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07557v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06882", "title": "On the randomized SVD in infinite dimensions", "authors": ["Daniel Kressner", "David Persson", "André Uschmajew"], "summary": "Randomized methods, such as the randomized SVD (singular value decomposition)\nand Nystr\\\"om approximation, are an effective way to compute low-rank\napproximations of large matrices. Motivated by applications to operator\nlearning, Boull\\'e and Townsend (FoCM, 2023) recently proposed an\ninfinite-dimensional extension of the randomized SVD for a Hilbert--Schmidt\noperator $A$ that invokes randomness through a Gaussian process with a\ncovariance operator $K$. While the non-isotropy introduced by $K$ allows one to\nincorporate prior information on $A$, an unfortunate choice may lead to\nunfavorable performance and large constants in the error bounds. In this work,\nwe introduce a novel infinite-dimensional extension of the randomized SVD that\ndoes not require such a choice and enjoys error bounds that match those for the\nfinite-dimensional case. Moreover, it reflects the common practice of using the\nrandomized SVD with isotropic random vectors, also when approximating\ndiscretized operators. In fact, the theoretical results of this work show how\nthe usual randomized SVD applied to a discretization of $A$ approaches our\ninfinite-dimensional extension as the discretization gets refined, both in\nterms of error bounds and the Wasserstein distance. We also present and analyze\na novel extension of the Nystr\\\"om approximation for self-adjoint positive\nsemi-definite trace class operators.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.06882v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07563", "title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization", "authors": ["Ken Yagel", "Eyal German", "Aviel Ben Siman Tov"], "summary": "Personalized recommendation systems must adapt to user interactions across\ndifferent domains. Traditional approaches like MLoRA apply a single adaptation\nper domain but lack flexibility in handling diverse user behaviors. To address\nthis, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is\nfirst trained independently to specialize in its domain before a gating network\nis trained to weight their contributions dynamically. We evaluate MoE-MLoRA\nacross eight CTR models on Movielens and Taobao, showing that it improves\nperformance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20)\nbut offers limited benefits in structured datasets with low domain diversity\nand sparsity. Further analysis of the number of experts per domain reveals that\nlarger ensembles do not always improve performance, indicating the need for\nmodel-aware tuning. Our findings highlight the potential of expert-based\narchitectures for multi-domain recommendation systems, demonstrating that\ntask-aware specialization and adaptive gating can enhance predictive accuracy\nin complex environments. The implementation and code are available in our\nGitHub repository.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.07563v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07614", "title": "Poisson Midpoint Method for Log Concave Sampling: Beyond the Strong Error Lower Bounds", "authors": ["Rishikesh Srinivasan", "Dheeraj Nagaraj"], "summary": "We study the problem of sampling from strongly log-concave distributions over\n$\\mathbb{R}^d$ using the Poisson midpoint discretization (a variant of the\nrandomized midpoint method) for overdamped/underdamped Langevin dynamics. We\nprove its convergence in the 2-Wasserstein distance ($W_2$), achieving a cubic\nspeedup in dependence on the target accuracy ($\\epsilon$) over the\nEuler-Maruyama discretization, surpassing existing bounds for randomized\nmidpoint methods. Notably, in the case of underdamped Langevin dynamics, we\ndemonstrate the complexity of $W_2$ convergence is much smaller than the\ncomplexity lower bounds for convergence in $L^2$ strong error established in\nthe literature.", "comment": null, "cate": "math.PR", "url": "http://arxiv.org/abs/2506.07614v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06887", "title": "Mixture of Small and Large Models for Chinese Spelling Check", "authors": ["Ziheng Qiao", "Houquan Zhou", "Zhenghua Li"], "summary": "In the era of large language models (LLMs), the Chinese Spelling Check (CSC)\ntask has seen various LLM methods developed, yet their performance remains\nunsatisfactory. In contrast, fine-tuned BERT-based models, relying on\nhigh-quality in-domain data, show excellent performance but suffer from edit\npattern overfitting. This paper proposes a novel dynamic mixture approach that\neffectively combines the probability distributions of small models and LLMs\nduring the beam search decoding phase, achieving a balanced enhancement of\nprecise corrections from small models and the fluency of LLMs. This approach\nalso eliminates the need for fine-tuning LLMs, saving significant time and\nresources, and facilitating domain adaptation. Comprehensive experiments\ndemonstrate that our mixture approach significantly boosts error correction\ncapabilities, achieving state-of-the-art results across multiple datasets. Our\ncode is available at https://github.com/zhqiao-nlp/MSLLM.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06887v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07621", "title": "LoRMA: Low-Rank Multiplicative Adaptation for LLMs", "authors": ["Harsh Bihany", "Shubham Patel", "Ashutosh Modi"], "summary": "Large Language Models have shown remarkable capabilities in the NLP domain.\nTheir effectiveness can mainly be attributed to their ability to adapt to an\narray of downstream tasks. However, generally, full fine-tuning is a\ncomputationally expensive job. To mitigate this, many techniques have been\ndeveloped that prime efficiency, a prominent one being Low-Rank Adaptation\n(LoRA). However, LoRA and its variants employ re-parametrized additive updates.\nIn this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which\nshifts the paradigm of additive updates to a richer space of matrix\nmultiplicative transformations. We tackle challenges such as computational\ncomplexity and rank bottleneck of matrix multiplication by effectively\nre-ordering operations and introducing rank inflation strategies. We conduct\nextensive experiments to demonstrate the effectiveness of our approach in terms\nof various evaluation metrics.", "comment": "Accepted at ACL Findings 2025; 21 pages (9 main paper + 5 pages\n  references + 7 pages appendix)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07621v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06888", "title": "Automatic Speech Recognition of African American English: Lexical and Contextual Effects", "authors": ["Hamid Mojarad", "Kevin Tang"], "summary": "Automatic Speech Recognition (ASR) models often struggle with the phonetic,\nphonological, and morphosyntactic features found in African American English\n(AAE). This study focuses on two key AAE variables: Consonant Cluster Reduction\n(CCR) and ING-reduction. It examines whether the presence of CCR and\nING-reduction increases ASR misrecognition. Subsequently, it investigates\nwhether end-to-end ASR systems without an external Language Model (LM) are more\ninfluenced by lexical neighborhood effect and less by contextual predictability\ncompared to systems with an LM. The Corpus of Regional African American\nLanguage (CORAAL) was transcribed using wav2vec 2.0 with and without an LM. CCR\nand ING-reduction were detected using the Montreal Forced Aligner (MFA) with\npronunciation expansion. The analysis reveals a small but significant effect of\nCCR and ING on Word Error Rate (WER) and indicates a stronger presence of\nlexical neighborhood effect in ASR systems without LMs.", "comment": "submitted to Interspeech 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06888v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07583", "title": "Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models", "authors": ["Ramakrishna Appicharla", "Baban Gain", "Santanu Pal", "Asif Ekbal"], "summary": "Despite the popularity of the large language models (LLMs), their application\nto machine translation is relatively underexplored, especially in context-aware\nsettings. This work presents a literature review of context-aware translation\nwith LLMs. The existing works utilise prompting and fine-tuning approaches,\nwith few focusing on automatic post-editing and creating translation agents for\ncontext-aware machine translation. We observed that the commercial LLMs (such\nas ChatGPT and Tower LLM) achieved better results than the open-source LLMs\n(such as Llama and Bloom LLMs), and prompt-based approaches serve as good\nbaselines to assess the quality of translations. Finally, we present some\ninteresting future directions to explore.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07583v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07667", "title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch", "authors": ["Prarabdh Shukla", "Wei Yin Chong", "Yash Patel", "Brennan Schaffner", "Danish Pruthi", "Arjun Bhagoji"], "summary": "To meet the demands of content moderation, online platforms have resorted to\nautomated systems. Newer forms of real-time engagement($\\textit{e.g.}$, users\ncommenting on live streams) on platforms like Twitch exert additional pressures\non the latency expected of such moderation systems. Despite their prevalence,\nrelatively little is known about the effectiveness of these systems. In this\npaper, we conduct an audit of Twitch's automated moderation tool\n($\\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful\ncontent. For our audit, we create streaming accounts to act as siloed test\nbeds, and interface with the live chat using Twitch's APIs to send over\n$107,000$ comments collated from $4$ datasets. We measure $\\texttt{AutoMod}$'s\naccuracy in flagging blatantly hateful content containing misogyny, racism,\nableism and homophobia. Our experiments reveal that a large fraction of hateful\nmessages, up to $94\\%$ on some datasets, $\\textit{bypass moderation}$.\nContextual addition of slurs to these messages results in $100\\%$ removal,\nrevealing $\\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We\nalso find that contrary to Twitch's community guidelines, $\\texttt{AutoMod}$\nblocks up to $89.5\\%$ of benign examples that use sensitive words in\npedagogical or empowering contexts. Overall, our audit points to large gaps in\n$\\texttt{AutoMod}$'s capabilities and underscores the importance for such\nsystems to understand context effectively.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07667v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06893", "title": "Online Job Assignment", "authors": ["Farbod Ekbatani", "Yiding Feng", "Ian Kash", "Rad Niazadeh"], "summary": "Motivated primarily by applications in cloud computing, we study a simple,\nyet powerful, online allocation problem in which jobs of varying durations\narrive over continuous time and must be assigned immediately and irrevocably to\none of the available offline servers. Each server has a fixed initial capacity,\nwith assigned jobs occupying one unit for their duration and releasing it upon\ncompletion. The algorithm earns a reward for each assignment upon completion.\nWe consider a general heterogeneous setting where both the reward and duration\nof a job depend on the job-server pair. The objective of the online algorithm\nis to maximize the total collected reward, and remain competitive against an\nomniscient benchmark that knows all job arrivals in advance. Our main\ncontribution is the design of a new online algorithm, termed Forward-Looking\nBALANCE (FLB), and using primal-dual framework to establish that it is\n(asymptotically) optimal-competitive.\n  This meta-algorithm has two main primitives: (i) keeping track of the\ncapacity used for each server at each time and applying a penalty function to\nthis quantity, and (ii) adjusting the reward of assigning a job to a server by\nsubtracting the total penalty of a particularly chosen subset of future times,\nin contrast to just looking at the current time. The FLB algorithm then assigns\nthe arriving job to the server with the maximum adjusted reward. If R and D are\nthe ratios of maximum over minimum rewards and durations, we show that the FLB\nalgorithm obtains an asymptotic competitive ratio of\nln(RD)+3lnln(max(R,D))+O(1). We further show this bound has optimal\ndependencies on all the parameters. Our main analysis combines a novel\ndual-fitting technique, which leverages the configuration LP benchmark for this\nproblem, and a novel inductive argument to establish the capacity feasibility\nof the algorithm, which might be of independent interest.", "comment": null, "cate": "cs.DS", "url": "http://arxiv.org/abs/2506.06893v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07687", "title": "Rao-Blackwellised Reparameterisation Gradients", "authors": ["Kevin Lam", "Thang Bui", "George Deligiannidis", "Yee Whye Teh"], "summary": "Latent Gaussian variables have been popularised in probabilistic machine\nlearning. In turn, gradient estimators are the machinery that facilitates\ngradient-based optimisation for models with latent Gaussian variables. The\nreparameterisation trick is often used as the default estimator as it is simple\nto implement and yields low-variance gradients for variational inference. In\nthis work, we propose the R2-G2 estimator as the Rao-Blackwellisation of the\nreparameterisation gradient estimator. Interestingly, we show that the local\nreparameterisation gradient estimator for Bayesian MLPs is an instance of the\nR2-G2 estimator and Rao-Blackwellisation. This lets us extend benefits of\nRao-Blackwellised gradients to a suite of probabilistic models. We show that\ninitial training with R2-G2 consistently yields better performance in models\nwith multiple applications of the reparameterisation trick.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07687v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07691", "title": "Training Superior Sparse Autoencoders for Instruct Models", "authors": ["Jiaming Li", "Haoran Ye", "Yukun Chen", "Xinyue Li", "Lei Zhang", "Hamid Alinejad-Rokny", "Jimmy Chih-Hsien Peng", "Min Yang"], "summary": "As large language models (LLMs) grow in scale and capability, understanding\ntheir internal mechanisms becomes increasingly critical. Sparse autoencoders\n(SAEs) have emerged as a key tool in mechanistic interpretability, enabling the\nextraction of human-interpretable features from LLMs. However, existing SAE\ntraining methods are primarily designed for base models, resulting in reduced\nreconstruction quality and interpretability when applied to instruct models. To\nbridge this gap, we propose\n$\\underline{\\textbf{F}}$inetuning-$\\underline{\\textbf{a}}$ligned\n$\\underline{\\textbf{S}}$equential $\\underline{\\textbf{T}}$raining\n($\\textit{FAST}$), a novel training method specifically tailored for instruct\nmodels. $\\textit{FAST}$ aligns the training process with the data distribution\nand activation patterns characteristic of instruct models, resulting in\nsubstantial improvements in both reconstruction and feature interpretability.\nOn Qwen2.5-7B-Instruct, $\\textit{FAST}$ achieves a mean squared error of 0.6468\nin token reconstruction, significantly outperforming baseline methods with\nerrors of 5.1985 and 1.5096. In feature interpretability, $\\textit{FAST}$\nyields a higher proportion of high-quality features, for Llama3.2-3B-Instruct,\n$21.1\\%$ scored in the top range, compared to $7.0\\%$ and $10.2\\%$ for\n$\\textit{BT(P)}$ and $\\textit{BT(F)}$. Surprisingly, we discover that\nintervening on the activations of special tokens via the SAEs leads to\nimprovements in output quality, suggesting new opportunities for fine-grained\ncontrol of model behavior. Code, data, and 240 trained SAEs are available at\nhttps://github.com/Geaming2002/FAST.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07691v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07664", "title": "Synthesis by Design: Controlled Data Generation via Structural Guidance", "authors": ["Lei Xu", "Sirui Chen", "Yuxuan Huang", "Chaochao Lu"], "summary": "Mathematical reasoning remains challenging for LLMs due to complex logic and\nthe need for precise computation. Existing methods enhance LLM reasoning by\nsynthesizing datasets through problem rephrasing, but face issues with\ngeneration quality and problem complexity. To address this, we propose to\nextract structural information with generated problem-solving code from\nmathematical reasoning and guide data generation with structured solutions.\nApplied to MATH and GSM8K, our approach produces 39K problems with labeled\nintermediate steps and a 6.1K-problem benchmark of higher difficulty. Results\non our benchmark show that model performance declines as reasoning length\nincreases. Additionally, we conducted fine-tuning experiments using the\nproposed training data on a range of LLMs, and the results validate the\neffectiveness of our dataset. We hope the proposed method and dataset will\ncontribute to future research in enhancing LLM reasoning capabilities.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07664v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07760", "title": "Quickest Causal Change Point Detection by Adaptive Intervention", "authors": ["Haijie Xu", "Chen Zhang"], "summary": "We propose an algorithm for change point monitoring in linear causal models\nthat accounts for interventions. Through a special centralization technique, we\ncan concentrate the changes arising from causal propagation across nodes into a\nsingle dimension. Additionally, by selecting appropriate intervention nodes\nbased on Kullback-Leibler divergence, we can amplify the change magnitude. We\nalso present an algorithm for selecting the intervention values, which aids in\nthe identification of the most effective intervention nodes. Two monitoring\nmethods are proposed, each with an adaptive intervention policy to make a\nbalance between exploration and exploitation. We theoretically demonstrate the\nfirst-order optimality of the proposed methods and validate their properties\nusing simulation datasets and two real-world case studies.", "comment": null, "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07760v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07671", "title": "GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation", "authors": ["Ionut-Teodor Sorodoc", "Leonardo F. R. Ribeiro", "Rexhina Blloshmi", "Christopher Davis", "Adrià de Gispert"], "summary": "We present GaRAGe, a large RAG benchmark with human-curated long-form answers\nand annotations of each grounding passage, allowing a fine-grained evaluation\nof whether LLMs can identify relevant grounding when generating RAG answers.\nOur benchmark contains 2366 questions of diverse complexity, dynamism, and\ntopics, and includes over 35K annotated passages retrieved from both private\ndocument sets and the Web, to reflect real-world RAG use cases. This makes it\nan ideal test bed to evaluate an LLM's ability to identify only the relevant\ninformation necessary to compose a response, or provide a deflective response\nwhen there is insufficient information. Evaluations of multiple\nstate-of-the-art LLMs on GaRAGe show that the models tend to over-summarise\nrather than (a) ground their answers strictly on the annotated relevant\npassages (reaching at most a Relevance-Aware Factuality Score of 60%), or (b)\ndeflect when no relevant grounding is available (reaching at most 31% true\npositive rate in deflections). The F1 in attribution to relevant sources is at\nmost 58.9%, and we show that performance is particularly reduced when answering\ntime-sensitive questions and when having to draw knowledge from sparser private\ngrounding sources.", "comment": "ACL 2025 (Findings)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07671v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07770", "title": "Diffusion Models-Aided Uplink Channel Estimation for RIS-Assisted Systems", "authors": ["Yang Wang", "Yin Xu", "Cixiao Zhang", "Zhiyong Chen", "Xiaowu Ou", "Mingzeng Dai", "Meixia Tao", "Wenjun Zhang"], "summary": "This letter proposes a channel estimation method for reconfigurable\nintelligent surface (RIS)-assisted systems through a novel diffusion model (DM)\nframework. We reformulate the channel estimation problem as a denoising\nprocess, which aligns with the reverse process of the DM. To overcome the\ninherent randomness in the reverse process of conventional DM approaches, we\nadopt a deterministic sampling strategy with a step alignment mechanism that\nensures the accuracy of channel estimation while adapting to different\nsignal-to-noise ratio (SNR). Furthermore, to reduce the number of parameters of\nthe U-Net, we meticulously design a lightweight network that achieves\ncomparable performance, thereby enhancing the practicality of our proposed\nmethod. Extensive simulations demonstrate superior performance over a wide\nrange of SNRs compared to baselines. For instance, the proposed method achieves\nperformance improvements of up to 13.5 dB in normalized mean square error\n(NMSE) at SNR = 0 dB. Notably, the proposed lightweight network exhibits almost\nno performance loss compared to the original U-Net, while requiring only 6.59\\%\nof its parameters.", "comment": "5 pages", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.07770v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06913", "title": "OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion", "authors": ["Xian Guo", "Ben Chen", "Siyuan Wang", "Ying Yang", "Chenyi Lei", "Yuqing Ding", "Han Li"], "summary": "Query suggestion plays a crucial role in enhancing user experience in\ne-commerce search systems by providing relevant query recommendations that\nalign with users' initial input. This module helps users navigate towards\npersonalized preference needs and reduces typing effort, thereby improving\nsearch experience. Traditional query suggestion modules usually adopt\nmulti-stage cascading architectures, for making a well trade-off between system\nresponse time and business conversion. But they often suffer from\ninefficiencies and suboptimal performance due to inconsistent optimization\nobjectives across stages. To address these, we propose OneSug, the first\nend-to-end generative framework for e-commerce query suggestion. OneSug\nincorporates a prefix2query representation enhancement module to enrich\nprefixes using semantically and interactively related queries to bridge content\nand business characteristics, an encoder-decoder generative model that unifies\nthe query suggestion process, and a reward-weighted ranking strategy with\nbehavior-level weights to capture fine-grained user preferences. Extensive\nevaluations on large-scale industry datasets demonstrate OneSug's ability for\neffective and efficient query suggestion. Furthermore, OneSug has been\nsuccessfully deployed for the entire traffic on the e-commerce search engine in\nKuaishou platform for over 1 month, with statistically significant improvements\nin user top click position (-9.33%), CTR (+2.01%), Order (+2.04%), and Revenue\n(+1.69%) over the online multi-stage strategy, showing great potential in\ne-commercial conversion.", "comment": "11 pages, 8 figures, and 6 tables", "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.06913v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07801", "title": "MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification", "authors": ["Iustin Sirbu", "Robert-Adrian Popovici", "Cornelia Caragea", "Stefan Trausan-Matu", "Traian Rebedea"], "summary": "We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm\ncombining the paradigms of co-training and consistency regularization with\npseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label\nweighting module designed for three key purposes: selecting and filtering\npseudo-labels based on head agreement and model confidence, and weighting them\naccording to the perceived classification difficulty. This novel module\nenhances and unifies three existing techniques -- heads agreement from\nMultihead Co-training, self-adaptive thresholds from FreeMatch, and Average\nPseudo-Margins from MarginMatch -- resulting in a holistic approach that\nimproves robustness and performance in SSL settings. Experimental results on\nbenchmark datasets highlight the superior performance of MultiMatch, achieving\nstate-of-the-art results on 9 out of 10 setups from 5 natural language\nprocessing datasets and ranking first according to the Friedman test among 19\nmethods. Furthermore, MultiMatch demonstrates exceptional robustness in highly\nimbalanced settings, outperforming the second-best approach by 3.26% -- and\ndata imbalance is a key factor for many text classification tasks.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07801v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07751", "title": "Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking", "authors": ["Silin Gao", "Antoine Bosselut", "Samy Bengio", "Emmanuel Abbe"], "summary": "Recent studies have shown that large language models (LLMs), especially\nsmaller ones, often lack robustness in their reasoning. I.e., they tend to\nexperience performance drops when faced with distribution shifts, such as\nchanges to numerical or nominal variables, or insertions of distracting\nclauses. A possible strategy to address this involves generating synthetic data\nto further \"instantiate\" reasoning problems on potential variations. In\ncontrast, our approach focuses on \"abstracting\" reasoning problems. This not\nonly helps counteract distribution shifts but also facilitates the connection\nto symbolic tools for deriving solutions. We find that this abstraction process\nis better acquired through reinforcement learning (RL) than just supervised\nfine-tuning, which often fails to produce faithful abstractions. Our method,\nAbstraL -- which promotes abstract reasoning in LLMs using RL on granular\nabstraction data -- significantly mitigates performance degradation on recent\nGSM perturbation benchmarks.", "comment": "Under review", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07751v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07816", "title": "Accelerating Constrained Sampling: A Large Deviations Approach", "authors": ["Yingli Wang", "Changwei Tu", "Xiaoyu Wang", "Lingjiong Zhu"], "summary": "The problem of sampling a target probability distribution on a constrained\ndomain arises in many applications including machine learning. For constrained\nsampling, various Langevin algorithms such as projected Langevin Monte Carlo\n(PLMC) based on the discretization of reflected Langevin dynamics (RLD) and\nmore generally skew-reflected non-reversible Langevin Monte Carlo (SRNLMC)\nbased on the discretization of skew-reflected non-reversible Langevin dynamics\n(SRNLD) have been proposed and studied in the literature. This work focuses on\nthe long-time behavior of SRNLD, where a skew-symmetric matrix is added to RLD.\nAlthough the non-asymptotic convergence analysis for SRNLD (and SRNLMC) and the\nacceleration compared to RLD (and PMLC) have been studied in the literature, it\nis not clear how one should design the skew-symmetric matrix in the dynamics to\nachieve good performance in practice. We establish a large deviation principle\n(LDP) for the empirical measure of SRNLD when the skew-symmetric matrix is\nchosen such that its product with the inward unit normal vector field on the\nboundary is zero. By explicitly characterizing the rate functions, we show that\nSRNLD can accelerate the convergence to the target distribution compared to RLD\nwith this choice of the skew-symmetric matrix. Numerical experiments for SRNLMC\nbased on the proposed skew-symmetric matrix show superior performance which\nvalidate the theoretical findings from the large deviations theory.", "comment": "40 pages, 7 figures", "cate": "stat.ML", "url": "http://arxiv.org/abs/2506.07816v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07844", "title": "Conditional Local Independence Testing with Application to Dynamic Causal Discovery", "authors": ["Mingzhou Liu", "Xinwei Sun", "Yizhou Wang"], "summary": "In this note, we extend the conditional local independence testing theory\ndeveloped in Christgau et al. (2024) to Ito processes. The result can be\napplied to causal discovery in dynamic systems.", "comment": "Working paper", "cate": "stat.ME", "url": "http://arxiv.org/abs/2506.07844v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07859", "title": "Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing", "authors": ["Amanuel Anteneh Léandre Brunel", "Carlos González-Arciniegas", "Olivier Pfister"], "summary": "Cubic-phase states are a sufficient resource for universal quantum computing\nover continuous variables. We present results from numerical experiments in\nwhich deep neural networks are trained via reinforcement learning to control a\nquantum optical circuit for generating cubic-phase states, with an average\nsuccess rate of 96%. The only non-Gaussian resource required is\nphoton-number-resolving measurements. We also show that the exact same\nresources enable the direct generation of a quartic-phase gate, with no need\nfor a cubic gate decomposition.", "comment": null, "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.07859v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06929", "title": "Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis", "authors": ["Mikhail Krasitskii", "Grigori Sidorov", "Olga Kolesnikova", "Liliana Chanona Hernandez", "Alexander Gelbukh"], "summary": "We propose a hybrid approach for multilingual sentiment analysis that\ncombines extractive and abstractive summarization to address the limitations of\nstandalone methods. The model integrates TF-IDF-based extraction with a\nfine-tuned XLM-R abstractive module, enhanced by dynamic thresholding and\ncultural adaptation. Experiments across 10 languages show significant\nimprovements over baselines, achieving 0.90 accuracy for English and 0.84 for\nlow-resource languages. The approach also demonstrates 22% greater\ncomputational efficiency than traditional methods. Practical applications\ninclude real-time brand monitoring and cross-cultural discourse analysis.\nFuture work will focus on optimization for low-resource languages via 8-bit\nquantization.", "comment": "6 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06929v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07899", "title": "MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs", "authors": ["Ke Wang", "Yiming Qin", "Nikolaos Dimitriadis", "Alessandro Favero", "Pascal Frossard"], "summary": "Language models deployed in real-world systems often require post-hoc updates\nto incorporate new or corrected knowledge. However, editing such models\nefficiently and reliably - without retraining or forgetting previous\ninformation - remains a major challenge. Existing methods for lifelong model\nediting either compromise generalization, interfere with past edits, or fail to\nscale to long editing sequences. We propose MEMOIR, a novel scalable framework\nthat injects knowledge through a residual memory, i.e., a dedicated parameter\nmodule, while preserving the core capabilities of the pre-trained model. By\nsparsifying input activations through sample-dependent masks, MEMOIR confines\neach edit to a distinct subset of the memory parameters, minimizing\ninterference among edits. At inference, it identifies relevant edits by\ncomparing the sparse activation patterns of new queries to those stored during\nediting. This enables generalization to rephrased queries by activating only\nthe relevant knowledge while suppressing unnecessary memory activation for\nunrelated prompts. Experiments on question answering, hallucination correction,\nand out-of-distribution generalization benchmarks across LLaMA-3 and Mistral\ndemonstrate that MEMOIR achieves state-of-the-art performance across\nreliability, generalization, and locality metrics, scaling to thousands of\nsequential edits with minimal forgetting.", "comment": "The first two authors contributed equally to this work", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07899v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06950", "title": "What Makes a Good Natural Language Prompt?", "authors": ["Do Xuan Long", "Duy Dinh", "Ngoc-Hai Nguyen", "Kenji Kawaguchi", "Nancy F. Chen", "Shafiq Joty", "Min-Yen Kan"], "summary": "As large language models (LLMs) have progressed towards more human-like and\nhuman--AI communications have become prevalent, prompting has emerged as a\ndecisive component. However, there is limited conceptual consensus on what\nexactly quantifies natural language prompts. We attempt to address this\nquestion by conducting a meta-analysis surveying more than 150\nprompting-related papers from leading NLP and AI conferences from 2022 to 2025\nand blogs. We propose a property- and human-centric framework for evaluating\nprompt quality, encompassing 21 properties categorized into six dimensions. We\nthen examine how existing studies assess their impact on LLMs, revealing their\nimbalanced support across models and tasks, and substantial research gaps.\nFurther, we analyze correlations among properties in high-quality natural\nlanguage prompts, deriving prompting recommendations. We then empirically\nexplore multi-property prompt enhancements in reasoning tasks, observing that\nsingle-property enhancements often have the greatest impact. Finally, we\ndiscover that instruction-tuning on property-enhanced prompts can result in\nbetter reasoning models. Our findings establish a foundation for\nproperty-centric prompt evaluation and optimization, bridging the gaps between\nhuman--AI communication and opening new prompting research directions.", "comment": "ACL 2025 Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06950v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07952", "title": "Discrete and Continuous Difference of Submodular Minimization", "authors": ["George Orfanides", "Tim Hoheisel", "Marwa El Halabi"], "summary": "Submodular functions, defined on continuous or discrete domains, arise in\nnumerous applications. We study the minimization of the difference of two\nsubmodular (DS) functions, over both domains, extending prior work restricted\nto set functions. We show that all functions on discrete domains and all smooth\nfunctions on continuous domains are DS. For discrete domains, we observe that\nDS minimization is equivalent to minimizing the difference of two convex (DC)\nfunctions, as in the set function case. We propose a novel variant of the DC\nAlgorithm (DCA) and apply it to the resulting DC Program, obtaining comparable\ntheoretical guarantees as in the set function case. The algorithm can be\napplied to continuous domains via discretization. Experiments demonstrate that\nour method outperforms baselines in integer compressive sensing and integer\nleast squares.", "comment": null, "cate": "math.OC", "url": "http://arxiv.org/abs/2506.07952v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07900", "title": "MiniCPM4: Ultra-Efficient LLMs on End Devices", "authors": ["MiniCPM Team", "Chaojun Xiao", "Yuxuan Li", "Xu Han", "Yuzhuo Bai", "Jie Cai", "Haotian Chen", "Wentong Chen", "Xin Cong", "Ganqu Cui", "Ning Ding", "Shengdan Fan", "Yewei Fang", "Zixuan Fu", "Wenyu Guan", "Yitong Guan", "Junshao Guo", "Yufeng Han", "Bingxiang He", "Yuxiang Huang", "Cunliang Kong", "Qiuzuo Li", "Siyuan Li", "Wenhao Li", "Yanghao Li", "Yishan Li", "Zhen Li", "Dan Liu", "Biyuan Lin", "Yankai Lin", "Xiang Long", "Quanyu Lu", "Yaxi Lu", "Peiyan Luo", "Hongya Lyu", "Litu Ou", "Yinxu Pan", "Zekai Qu", "Qundong Shi", "Zijun Song", "Jiayuan Su", "Zhou Su", "Ao Sun", "Xianghui Sun", "Peijun Tang", "Fangzheng Wang", "Feng Wang", "Shuo Wang", "Yudong Wang", "Yesai Wu", "Zhenyu Xiao", "Jie Xie", "Zihao Xie", "Yukun Yan", "Jiarui Yuan", "Kaihuo Zhang", "Lei Zhang", "Linyue Zhang", "Xueren Zhang", "Yudi Zhang", "Hengyu Zhao", "Weilin Zhao", "Weilun Zhao", "Yuanqian Zhao", "Zhi Zheng", "Ge Zhou", "Jie Zhou", "Wei Zhou", "Zihan Zhou", "Zixuan Zhou", "Zhiyuan Liu", "Guoyang Zeng", "Chao Jia", "Dahai Li", "Maosong Sun"], "summary": "This paper introduces MiniCPM4, a highly efficient large language model (LLM)\ndesigned explicitly for end-side devices. We achieve this efficiency through\nsystematic innovation in four key dimensions: model architecture, training\ndata, training algorithms, and inference systems. Specifically, in terms of\nmodel architecture, we propose InfLLM v2, a trainable sparse attention\nmechanism that accelerates both prefilling and decoding phases for long-context\nprocessing. Regarding training data, we propose UltraClean, an efficient and\naccurate pre-training data filtering and generation strategy, and UltraChat v2,\na comprehensive supervised fine-tuning dataset. These datasets enable\nsatisfactory model performance to be achieved using just 8 trillion training\ntokens. Regarding training algorithms, we propose ModelTunnel v2 for efficient\npre-training strategy search, and improve existing post-training methods by\nintroducing chunk-wise rollout for load-balanced reinforcement learning and\ndata-efficient tenary LLM, BitCPM. Regarding inference systems, we propose\nCPM.cu that integrates sparse attention, model quantization, and speculative\nsampling to achieve efficient prefilling and decoding. To meet diverse\non-device requirements, MiniCPM4 is available in two versions, with 0.5B and 8B\nparameters, respectively. Sufficient evaluation results show that MiniCPM4\noutperforms open-source models of similar size across multiple benchmarks,\nhighlighting both its efficiency and effectiveness. Notably, MiniCPM4-8B\ndemonstrates significant speed improvements over Qwen3-8B when processing long\nsequences. Through further adaptation, MiniCPM4 successfully powers diverse\napplications, including trustworthy survey generation and tool use with model\ncontext protocol, clearly showcasing its broad usability.", "comment": "MiniCPM4 Technical Report", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07900v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06968", "title": "A dependently-typed calculus of event telicity and culminativity", "authors": ["Pavel Kovalev", "Carlo Angiuli"], "summary": "We present a dependently-typed cross-linguistic framework for analyzing the\ntelicity and culminativity of events, accompanied by examples of using our\nframework to model English sentences. Our framework consists of two parts. In\nthe nominal domain, we model the boundedness of noun phrases and its\nrelationship to subtyping, delimited quantities, and adjectival modification.\nIn the verbal domain we define a dependent event calculus, modeling telic\nevents as those whose undergoer is bounded, culminating events as telic events\nthat achieve their inherent endpoint, and consider adverbial modification. In\nboth domains we pay particular attention to associated entailments. Our\nframework is defined as an extension of intensional Martin-L\\\"of dependent type\ntheory, and the rules and examples in this paper have been formalized in the\nAgda proof assistant.", "comment": "52 pages, Agda formalization available at\n  https://doi.org/10.5281/zenodo.15602617", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06968v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06972", "title": "Atomic Reasoning for Scientific Table Claim Verification", "authors": ["Yuji Zhang", "Qingyun Wang", "Cheng Qian", "Jiateng Liu", "Chenkai Sun", "Denghui Zhang", "Tarek Abdelzaher", "Chengxiang Zhai", "Preslav Nakov", "Heng Ji"], "summary": "Scientific texts often convey authority due to their technical language and\ncomplex data. However, this complexity can sometimes lead to the spread of\nmisinformation. Non-experts are particularly susceptible to misleading claims\nbased on scientific tables due to their high information density and perceived\ncredibility. Existing table claim verification models, including\nstate-of-the-art large language models (LLMs), often struggle with precise\nfine-grained reasoning, resulting in errors and a lack of precision in\nverifying scientific claims. Inspired by Cognitive Load Theory, we propose that\nenhancing a model's ability to interpret table-based claims involves reducing\ncognitive load by developing modular, reusable reasoning components (i.e.,\natomic skills). We introduce a skill-chaining schema that dynamically composes\nthese skills to facilitate more accurate and generalizable reasoning with a\nreduced cognitive load. To evaluate this, we create SciAtomicBench, a\ncross-domain benchmark with fine-grained reasoning annotations. With only 350\nfine-tuning examples, our model trained by atomic reasoning outperforms\nGPT-4o's chain-of-thought method, achieving state-of-the-art results with far\nless training data.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06972v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06979", "title": "Research on Aerodynamic Performance Prediction of Airfoils Based on a Fusion Algorithm of Transformer and GAN", "authors": ["MaolinYang", "Yaohui Wang", "Pingyu Jiang"], "summary": "Predicting of airfoil aerodynamic performance is a key part of aircraft\ndesign optimization, but the traditional methods (such as wind tunnel test and\nCFD simulation) have the problems of high cost and low efficiency, and the\nexisting data-driven models face the challenges of insufficient accuracy and\nstrong data dependence in multi-objective prediction. Therefore, this study\nproposes a deep learning model, Deeptrans, based on the fusion of improved\nTransformer and generative Adversarial network (GAN), which aims to predict the\nmulti-parameter aerodynamic performance of airfoil efficiently. By constructing\na large-scale data set and designing a model structure that integrates a\nTransformer coding-decoding framework and confrontation training, synchronous\nand high-precision prediction of aerodynamic parameters is realized.\nExperiments show that the MSE loss of Deeptrans on the verification set is\nreduced to 5.6*10-6, and the single-sample prediction time is only 0.0056\nseconds, which is nearly 700 times more efficient than the traditional CFD\nmethod. Horizontal comparison shows that the prediction accuracy is\nsignificantly better than the original Transformer, GAN, and VAE models. This\nstudy provides an efficient data-driven solution for airfoil aerodynamic\nperformance prediction and a new idea for deep learning modeling complex flow\nproblems.", "comment": "33 pages,10 figures", "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.06979v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06982", "title": "Chain of Methodologies: Scaling Test Time Computation without Training", "authors": ["Cong Liu", "Jie Wu", "Weigang Wu", "Xu Chen", "Liang Lin", "Wei-Shi Zheng"], "summary": "Large Language Models (LLMs) often struggle with complex reasoning tasks due\nto insufficient in-depth insights in their training data, which are typically\nabsent in publicly available documents. This paper introduces the Chain of\nMethodologies (CoM), an innovative and intuitive prompting framework that\nenhances structured thinking by integrating human methodological insights,\nenabling LLMs to tackle complex tasks with extended reasoning. CoM leverages\nthe metacognitive abilities of advanced LLMs, activating systematic reasoning\nthrought user-defined methodologies without explicit fine-tuning. Experiments\nshow that CoM surpasses competitive baselines, demonstrating the potential of\ntraining-free prompting methods as robust solutions for complex reasoning tasks\nand bridging the gap toward human-level reasoning through human-like\nmethodological insights.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06982v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06987", "title": "Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors", "authors": ["Senqi Yang", "Dongyu Zhang", "Jing Ren", "Ziqi Xu", "Xiuzhen Zhang", "Yiliao Song", "Hongfei Lin", "Feng Xia"], "summary": "Metaphors are pervasive in communication, making them crucial for natural\nlanguage processing (NLP). Previous research on automatic metaphor processing\npredominantly relies on training data consisting of English samples, which\noften reflect Western European or North American biases. This cultural skew can\nlead to an overestimation of model performance and contributions to NLP\nprogress. However, the impact of cultural bias on metaphor processing,\nparticularly in multimodal contexts, remains largely unexplored. To address\nthis gap, we introduce MultiMM, a Multicultural Multimodal Metaphor dataset\ndesigned for cross-cultural studies of metaphor in Chinese and English. MultiMM\nconsists of 8,461 text-image advertisement pairs, each accompanied by\nfine-grained annotations, providing a deeper understanding of multimodal\nmetaphors beyond a single cultural domain. Additionally, we propose\nSentiment-Enriched Metaphor Detection (SEMD), a baseline model that integrates\nsentiment embeddings to enhance metaphor comprehension across cultural\nbackgrounds. Experimental results validate the effectiveness of SEMD on\nmetaphor detection and sentiment analysis tasks. We hope this work increases\nawareness of cultural bias in NLP research and contributes to the development\nof fairer and more inclusive language models. Our dataset and code are\navailable at https://github.com/DUTIR-YSQ/MultiMM.", "comment": "This paper has been accepted to the 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2025), Main Conference", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.06987v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07001", "title": "Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text", "authors": ["Yize Cheng", "Vinu Sankar Sadasivan", "Mehrdad Saberi", "Shoumik Saha", "Soheil Feizi"], "summary": "The increasing capabilities of Large Language Models (LLMs) have raised\nconcerns about their misuse in AI-generated plagiarism and social engineering.\nWhile various AI-generated text detectors have been proposed to mitigate these\nrisks, many remain vulnerable to simple evasion techniques such as\nparaphrasing. However, recent detectors have shown greater robustness against\nsuch basic attacks. In this work, we introduce Adversarial Paraphrasing, a\ntraining-free attack framework that universally humanizes any AI-generated text\nto evade detection more effectively. Our approach leverages an off-the-shelf\ninstruction-following LLM to paraphrase AI-generated content under the guidance\nof an AI text detector, producing adversarial examples that are specifically\noptimized to bypass detection. Extensive experiments show that our attack is\nboth broadly effective and highly transferable across several detection\nsystems. For instance, compared to simple paraphrasing attack--which,\nironically, increases the true positive at 1% false positive (T@1%F) by 8.57%\non RADAR and 15.03% on Fast-DetectGPT--adversarial paraphrasing, guided by\nOpenAI-RoBERTa-Large, reduces T@1%F by 64.49% on RADAR and a striking 98.96% on\nFast-DetectGPT. Across a diverse set of detectors--including neural\nnetwork-based, watermark-based, and zero-shot approaches--our attack achieves\nan average T@1%F reduction of 87.88% under the guidance of\nOpenAI-RoBERTa-Large. We also analyze the tradeoff between text quality and\nattack success to find that our method can significantly reduce detection\nrates, with mostly a slight degradation in text quality. Our adversarial setup\nhighlights the need for more robust and resilient detection strategies in the\nlight of increasingly sophisticated evasion techniques.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07001v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07020", "title": "CrossGen: Learning and Generating Cross Fields for Quad Meshing", "authors": ["Qiujie Dong", "Jiepeng Wang", "Rui Xu", "Cheng Lin", "Yuan Liu", "Shiqing Xin", "Zichun Zhong", "Xin Li", "Changhe Tu", "Taku Komura", "Leif Kobbelt", "Scott Schaefer", "Wenping Wang"], "summary": "Cross fields play a critical role in various geometry processing tasks,\nespecially for quad mesh generation. Existing methods for cross field\ngeneration often struggle to balance computational efficiency with generation\nquality, using slow per-shape optimization. We introduce CrossGen, a novel\nframework that supports both feed-forward prediction and latent generative\nmodeling of cross fields for quad meshing by unifying geometry and cross field\nrepresentations within a joint latent space. Our method enables extremely fast\ncomputation of high-quality cross fields of general input shapes, typically\nwithin one second without per-shape optimization. Our method assumes a\npoint-sampled surface, or called a point-cloud surface, as input, so we can\naccommodate various different surface representations by a straightforward\npoint sampling process. Using an auto-encoder network architecture, we encode\ninput point-cloud surfaces into a sparse voxel grid with fine-grained latent\nspaces, which are decoded into both SDF-based surface geometry and cross\nfields. We also contribute a dataset of models with both high-quality signed\ndistance fields (SDFs) representations and their corresponding cross fields,\nand use it to train our network. Once trained, the network is capable of\ncomputing a cross field of an input surface in a feed-forward manner, ensuring\nhigh geometric fidelity, noise resilience, and rapid inference. Furthermore,\nleveraging the same unified latent representation, we incorporate a diffusion\nmodel for computing cross fields of new shapes generated from partial input,\nsuch as sketches. To demonstrate its practical applications, we validate\nCrossGen on the quad mesh generation task for a large variety of surface\nshapes. Experimental results...", "comment": "Project page: https://anonymousproject-homepage.github.io/", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07020v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07036", "title": "\"In This Environment, As That Speaker\": A Text-Driven Framework for Multi-Attribute Speech Conversion", "authors": ["Jiawei Jin", "Zhuhan Yang", "Yixuan Zhou", "Zhiyong Wu"], "summary": "We propose TES-VC (Text-driven Environment and Speaker controllable Voice\nConversion), a text-driven voice conversion framework with independent control\nof speaker timbre and environmental acoustics. TES-VC processes simultaneous\ntext inputs for target voice and environment, accurately generating speech\nmatching described timbre/environment while preserving source content. Trained\non synthetic data with decoupled vocal/environment features via latent\ndiffusion modeling, our method eliminates interference between attributes. The\nRetrieval-Based Timbre Control (RBTC) module enables precise manipulation using\nabstract descriptions without paired data. Experiments confirm TES-VC\neffectively generates contextually appropriate speech in both timbre and\nenvironment with high content retention and superior controllability which\ndemonstrates its potential for widespread applications.", "comment": "Accepted by Interspeech2025", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07036v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07037", "title": "KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering", "authors": ["Zhongze Luo", "Weixuan Wan", "Qizhi Zheng", "Yanhong Bai", "Jingyun Sun", "Jian Wang", "Dan Wang"], "summary": "There are many types of standards in the field of communication. The\ntraditional consulting model has a long cycle and relies on the knowledge and\nexperience of experts, making it difficult to meet the rapidly developing\ntechnological demands. This paper combines the fine-tuning of large language\nmodels with the construction of knowledge graphs to implement an intelligent\nconsultation and question-answering system for communication standards. The\nexperimental results show that after LoRA tuning on the constructed dataset of\n6,587 questions and answers in the field of communication standards,\nQwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the\nfield of communication standards on the test set. BLEU-4 rose from 18.8564 to\n66.8993, and evaluation indicators such as ROUGE also increased significantly,\noutperforming the fine-tuning effect of the comparison model\nLlama-3-8B-Instruct. Based on the ontology framework containing 6 entity\nattributes and 10 relation attributes, a knowledge graph of the communication\nstandard domain containing 13,906 entities and 13,524 relations was\nconstructed, showing a relatively good query accuracy rate. The intelligent\nconsultation and question-answering system enables the fine-tuned model on the\nserver side to access the locally constructed knowledge graph and conduct\ngraphical retrieval of key information first, which is conducive to improving\nthe question-answering effect. The evaluation using DeepSeek as the Judge on\nthe test set shows that our RAG framework enables the fine-tuned model to\nimprove the scores at all five angles, with an average score increase of 2.26%.\nAnd combined with web services and API interfaces, it has achieved very good\nresults in terms of interaction experience and back-end access, and has very\ngood practical application value.", "comment": "23 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07037v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07041", "title": "From Inquisitorial to Adversarial: Using Legal Theory to Redesign Online Reporting Systems", "authors": ["Leijie Wang", "Weizi Wu", "Lirong Que", "Nirvan Tyagi", "Amy X. Zhang"], "summary": "User reporting systems are central to addressing interpersonal conflicts and\nprotecting users from harm in online spaces, particularly those with heightened\nprivacy expectations. However, users often express frustration at their lack of\ninsight and input into the reporting process. Drawing on offline legal\nliterature, we trace these frustrations to the inquisitorial nature of today's\nonline reporting systems, where moderators lead evidence gathering and case\ndevelopment. In contrast, adversarial models can grant users greater control\nand thus are better for procedural justice and privacy protection, despite\ntheir increased risks of system abuse. This motivates us to explore the\npotential of incorporating adversarial practices into online reporting systems.\nThrough literature review, formative interviews, and threat modeling, we find a\nrich design space for empowering users to collect and present their evidence\nwhile mitigating potential abuse in the reporting process. In particular, we\npropose designs that minimize the amount of information shared for reporting\npurposes, as well as supporting evidence authentication. Finally, we discuss\nhow our findings can inform new cryptographic tools and new efforts to apply\ncomparative legal frameworks to online moderation.", "comment": "Under review", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07041v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07042", "title": "Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants", "authors": ["Stergios Chatzikyriakidis"], "summary": "Extracting structured computational representations of historical events from\nnarrative text remains computationally expensive when constructed manually.\nWhile RDF/OWL reasoners enable graph-based reasoning, they are limited to\nfragments of first-order logic, preventing deeper temporal and semantic\nanalysis. This paper addresses both challenges by developing automatic\nhistorical event extraction models using multiple LLMs (GPT-4, Claude, Llama\n3.2) with three enhancement strategies: pure base generation, knowledge graph\nenhancement, and Retrieval-Augmented Generation (RAG). We conducted\ncomprehensive evaluations using historical texts from Thucydides. Our findings\nreveal that enhancement strategies optimize different performance dimensions\nrather than providing universal improvements. For coverage and historical\nbreadth, base generation achieves optimal performance with Claude and GPT-4\nextracting comprehensive events. However, for precision, RAG enhancement\nimproves coordinate accuracy and metadata completeness. Model architecture\nfundamentally determines enhancement sensitivity: larger models demonstrate\nrobust baseline performance with incremental RAG improvements, while Llama 3.2\nshows extreme variance from competitive performance to complete failure. We\nthen developed an automated translation pipeline converting extracted RDF\nrepresentations into Coq proof assistant specifications, enabling higher-order\nreasoning beyond RDF capabilities including multi-step causal verification,\ntemporal arithmetic with BC dates, and formal proofs about historical\ncausation. The Coq formalization validates that RAG-discovered event types\nrepresent legitimate domain-specific semantic structures rather than\nontological violations.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07042v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07068", "title": "Attitude Estimation Using Scalar Measurements", "authors": ["Hassan Alnahhal", "Sifeddine Benahmed", "Soulaimane Berkane", "Tarel Hamel"], "summary": "This paper revisits the problem of orientation estimation for rigid bodies\nthrough a novel framework based on scalar measurements. Unlike traditional\nvector-based methods, the proposed approach enables selective utilization of\nonly the reliable axes of vector measurements while seamlessly incorporating\nalternative scalar modalities such as Pitot tubes, barometers with range\nsensors, and landmark-based constraints. The estimation problem is reformulated\nwithin a linear time-varying (LTV) framework, allowing the application of a\ndeterministic linear Kalman filter. This design guarantees Global Uniform\nExponential Stability (GES) under the Uniform Observability (UO) condition.\nSimulation results demonstrate the effectiveness of the proposed approach in\nachieving robust and accurate attitude estimation, even with partial vector\nmeasurements that simulate sensor axis failure.", "comment": "6 pages", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07068v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07072", "title": "A novel efficient structure-preserving exponential integrator for Hamiltonian systems", "authors": ["Pan Zhang", "Fengyang Xiao", "Lu Li"], "summary": "We propose a linearly implicit structure-preserving numerical method for\nsemilinear Hamiltonian systems with polynomial nonlinearities, combining\nKahan's method and exponential integrator. This approach efficiently balances\ncomputational cost, accuracy and the preservation of key geometric properties,\nincluding symmetry and near-preservation of energy. By requiring only the\nsolution of a single linear system per time step, the proposed method offers\nsignificant computational advantages while comparing with the state-of-the-art\nsymmetric energy-preserving exponential integrators. The stability, efficiency\nand long-term accuracy of the method are demonstrated through numerical\nexperiments on systems such as the Henon-Heiles system, the Fermi-Pasta-Ulam\nsystem and the two-dimensional Zakharov-Kuznestov equation.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07072v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07073", "title": "Insights on Harmonic Tones from a Generative Music Experiment", "authors": ["Emmanuel Deruty", "Maarten Grachten"], "summary": "The ultimate purpose of generative music AI is music production. The\nstudio-lab, a social form within the art-science branch of\ncross-disciplinarity, is a way to advance music production with AI music\nmodels. During a studio-lab experiment involving researchers, music producers,\nand an AI model for music generating bass-like audio, it was observed that the\nproducers used the model's output to convey two or more pitches with a single\nharmonic complex tone, which in turn revealed that the model had learned to\ngenerate structured and coherent simultaneous melodic lines using monophonic\nsequences of harmonic complex tones. These findings prompt a reconsideration of\nthe long-standing debate on whether humans can perceive harmonics as distinct\npitches and highlight how generative AI can not only enhance musical creativity\nbut also contribute to a deeper understanding of music.", "comment": "15th International Workshop on Machine Learning and Music, September\n  9, 2024, Vilnius, Lithuania", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07073v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07076", "title": "Harmony-Aware Music-driven Motion Synthesis with Perceptual Constraint on UGC Datasets", "authors": ["Xinyi Wu", "Haohong Wang", "Aggelos K. Katsaggelos"], "summary": "With the popularity of video-based user-generated content (UGC) on social\nmedia, harmony, as dictated by human perceptual principles, is critical in\nassessing the rhythmic consistency of audio-visual UGCs for better user\nengagement. In this work, we propose a novel harmony-aware GAN framework,\nfollowing a specifically designed harmony evaluation strategy to enhance\nrhythmic synchronization in the automatic music-to-motion synthesis using a UGC\ndance dataset. This harmony strategy utilizes refined cross-modal beat\ndetection to capture closely correlated audio and visual rhythms in an\naudio-visual pair. To mimic human attention mechanism, we introduce\nsaliency-based beat weighting and interval-driven beat alignment, which ensures\naccurate harmony score estimation consistent with human perception. Building on\nthis strategy, our model, employing efficient encoder-decoder and depth-lifting\ndesigns, is adversarially trained based on categorized musical meter segments\nto generate realistic and rhythmic 3D human motions. We further incorporate our\nharmony evaluation strategy as a weakly supervised perceptual constraint to\nflexibly guide the synchronized audio-visual rhythms during the generation\nprocess. Experimental results show that our proposed model significantly\noutperforms other leading music-to-motion methods in rhythmic harmony, both\nquantitatively and qualitatively, even with limited UGC training data. Live\nsamples 15 can be watched at: https://youtu.be/tWwz7yq4aUs", "comment": null, "cate": "cs.MM", "url": "http://arxiv.org/abs/2506.07076v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07081", "title": "Streaming Endpointer for Spoken Dialogue using Neural Audio Codecs and Label-Delayed Training", "authors": ["Sathvik Udupa", "Shinji Watanabe", "Petr Schwarz", "Jan Cernocky"], "summary": "Accurate, low-latency endpointing is crucial for effective spoken dialogue\nsystems. While traditional endpointers often rely on spectrum-based audio\nfeatures, this work proposes real-time speech endpointing for multi-turn\ndialogues using streaming, low-bitrate Neural Audio Codec (NAC) features,\nbuilding upon recent advancements in neural audio codecs. To further reduce\ncutoff errors, we introduce a novel label delay training scheme. At a fixed\nmedian latency of 160 ms, our combined NAC and label delay approach achieves\nsignificant relative cutoff error reductions: 42.7% for a single-stream\nendpointer and 37.5% for a two-stream configuration, compared to baseline\nmethods. Finally, we demonstrate efficient integration with a codec-based\npretrained speech large language model, improving its median response time by\n1200 ms and reducing its cutoff error by 35%.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07081v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07084", "title": "The PML method for calculating the propagating modes of electromagnetic wave in periodic structures", "authors": ["Lide Cai", "Junqing Chen", "Yanpeng Gao"], "summary": "When the electromagnetic wave is incident on the periodic structures, in\naddition to the scattering field, some propagating modes that are traveling in\nthe periodic medium could be generated. In the present paper, we study the\ncalculation of propagating modes. We formulate the problem as a nonlinear\neigenvalue problem in an unbounded periodic domain. Then we use perfectly\nmatched layers to truncate the unbounded domain, recast the problem to a\nquadratic eigenvalue problem, and prove the approximation property of the\ntruncation. Finally, we formulate the quadratic eigenvalue problem to a general\neigenvalue problem, use the finite element method to discrete the truncation\nproblem, and show numerical examples to verify theoretical results.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07084v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07086", "title": "Representation Decomposition for Learning Similarity and Contrastness Across Modalities for Affective Computing", "authors": ["Yuanhe Tian", "Pengsen Cheng", "Guoqing Jin", "Lei Zhang", "Yan Song"], "summary": "Multi-modal affective computing aims to automatically recognize and interpret\nhuman attitudes from diverse data sources such as images and text, thereby\nenhancing human-computer interaction and emotion understanding. Existing\napproaches typically rely on unimodal analysis or straightforward fusion of\ncross-modal information that fail to capture complex and conflicting evidence\npresented across different modalities. In this paper, we propose a novel\nLLM-based approach for affective computing that explicitly deconstructs visual\nand textual representations into shared (modality-invariant) and\nmodality-specific components. Specifically, our approach firstly encodes and\naligns input modalities using pre-trained multi-modal encoders, then employs a\nrepresentation decomposition framework to separate common emotional content\nfrom unique cues, and finally integrates these decomposed signals via an\nattention mechanism to form a dynamic soft prompt for a multi-modal LLM.\nExtensive experiments on three representative tasks for affective computing,\nnamely, multi-modal aspect-based sentiment analysis, multi-modal emotion\nanalysis, and hateful meme detection, demonstrate the effectiveness of our\napproach, which consistently outperforms strong baselines and state-of-the-art\nmodels.", "comment": "13 pages, 4 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07086v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07102", "title": "Decentralized Optimization with Amplified Privacy via Efficient Communication", "authors": ["Wei Huo", "Changxin Liu", "Kemi Ding", "Karl Henrik Johansson", "Ling Shi"], "summary": "Decentralized optimization is crucial for multi-agent systems, with\nsignificant concerns about communication efficiency and privacy. This paper\nexplores the role of efficient communication in decentralized stochastic\ngradient descent algorithms for enhancing privacy preservation. We develop a\nnovel algorithm that incorporates two key features: random agent activation and\nsparsified communication. Utilizing differential privacy, we demonstrate that\nthese features reduce noise without sacrificing privacy, thereby amplifying the\nprivacy guarantee and improving accuracy. Additionally, we analyze the\nconvergence and the privacy-accuracy-communication trade-off of the proposed\nalgorithm. Finally, we present experimental results to illustrate the\neffectiveness of our algorithm.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07102v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07111", "title": "Computational homogenization of parabolic equations with memory effects for a periodic heterogeneous medium", "authors": ["P. N. Vabishchevich"], "summary": "In homogenization theory, mathematical models at the macro level are\nconstructed based on the solution of auxiliary cell problems at the micro level\nwithin a single periodicity cell. These problems are formulated using\nasymptotic expansions of the solution with respect to a small parameter, which\nrepresents the characteristic size of spatial heterogeneity. When studying\ndiffusion equations with contrasting coefficients, special attention is given\nto nonlocal models with weakly conducting inclusions. In this case, macro-level\nprocesses are described by integro-differential equations, where the difference\nkernel is determined by the solution of a nonstationary cell problem. The main\ncontribution of this work is the development of a computational framework for\nthe homogenization of nonstationary processes, accounting for memory effects.\nThe effective diffusion tensor is computed using a standard numerical procedure\nbased on finite element discretization in space. The memory kernel is\napproximated by a sum of exponentials obtained from solving a partial spectral\nproblem on the periodicity cell. The nonlocal macro-level problem is\ntransformed into a local one, where memory effects are incorporated through the\nsolution of auxiliary nonstationary problems. Standard two-level time\ndiscretization schemes are employed, and unconditional stability of the\ndiscrete solutions is proved in appropriate norms. Key aspects of the proposed\ncomputational homogenization technique are illustrated by solving a\ntwo-dimensional model problem.", "comment": "19 pages, 13 figures", "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07111v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07128", "title": "New highly efficient and accurate numerical scheme for the Cahn-Hilliard-Brinkman system", "authors": ["Dawei Chen", "Qinzhen Ren", "Minghui Li"], "summary": "In this paper, based on a generalized scalar auxiliary variable approach with\nrelaxation (R-GSAV), we construct a class of high-order backward\ndifferentiation formula (BDF) schemes with variable time steps for the\nCahn-Hilliard-Brinkman(CHB) system. In theory, it is strictly proved that the\ndesigned schemes are unconditionally energy-stable. With the delicate treatment\nof adaptive strategies, we propose several adaptive time-step algorithms to\nenhance the robustness of the schemes. More importantly, a novel hybrid-order\nadaptive time steps algorithm performs outstanding for the coupled system. The\nhybrid-order algorithm inherits the advantages of some traditional high-order\nBDF adaptive strategies. A comprehensive comparison with some adaptive\ntime-step algorithms is given, and the advantages of the new adaptive time-step\nalgorithms are emphasized. Finally, the effectiveness and accuracy of the new\nmethods are validated through a series of numerical experiments.", "comment": "21 pages, 34 figures", "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07128v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07141", "title": "Highly efficient linear energy stable methods for preserving the original energy dissipation law of the incompressible Navier-Stokes equation", "authors": ["Zihan Weng", "Qi Hong", "Yuezheng Gong"], "summary": "In this paper, we introduce a comprehensive computational framework to\nconstruct highly efficient linear energy stable methods for the incompressible\nNavier-Stokes equation, which preserve the original energy dissipation law. By\nmultiplying the convection term by an identity-one term and incorporating a\nzero stabilization term, we recast the original model as a strongly equivalent\nsystem, while ensuring the retention of the original energy dissipation law.\nSuch nonlinear system is then discretized in time based on the Crank-Nicolson\nschemes and the backward differentiation formulas, resulting in highly\nefficient time-discrete schemes. The proposed schemes are designed to preserve\nthe original energy dissipation law while requiring only the solutions of three\nlinear Stokes systems and a $2\\times 2$ linear system at each time step. The\nfinite difference approximation on a staggered grid is employed for the\ntime-discrete systems to derive fully discrete energy stable schemes, which are\nproven to preserve the original energy dissipation law and be uniquely\nsolvable. We present the efficient implementation of these methods. Various\nnumerical experiments are carried out to verify the accuracy, efficacy, and\nadvantageous performance of our newly developed methods.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07141v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07148", "title": "Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis", "authors": ["Yaping Chai", "Haoran Xie", "Joe S. Qin"], "summary": "Large language model (LLM) is an effective approach to addressing data\nscarcity in low-resource scenarios. Recent existing research designs\nhand-crafted prompts to guide LLM for data augmentation. We introduce a data\naugmentation strategy for the aspect category sentiment analysis (ACSA) task\nthat preserves the original sentence semantics and has linguistic diversity,\nspecifically by providing a structured prompt template for an LLM to generate\npredefined content. In addition, we employ a post-processing technique to\nfurther ensure semantic consistency between the generated sentence and the\noriginal sentence. The augmented data increases the semantic coverage of the\ntraining distribution, enabling the model better to understand the relationship\nbetween aspect categories and sentiment polarities, enhancing its inference\ncapabilities. Furthermore, we propose a confidence-weighted fine-tuning\nstrategy to encourage the model to generate more confident and accurate\nsentiment polarity predictions. Compared with powerful and recent works, our\nmethod consistently achieves the best performance on four benchmark datasets\nover all baselines.", "comment": "10 pages, 7 figures, 4 tables", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07148v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07149", "title": "Technical Report: A Practical Guide to Kaldi ASR Optimization", "authors": ["Mengze Hong", "Di Jiang"], "summary": "This technical report introduces innovative optimizations for Kaldi-based\nAutomatic Speech Recognition (ASR) systems, focusing on acoustic model\nenhancement, hyperparameter tuning, and language model efficiency. We developed\na custom Conformer block integrated with a multistream TDNN-F structure,\nenabling superior feature extraction and temporal modeling. Our approach\nincludes advanced data augmentation techniques and dynamic hyperparameter\noptimization to boost performance and reduce overfitting. Additionally, we\npropose robust strategies for language model management, employing Bayesian\noptimization and $n$-gram pruning to ensure relevance and computational\nefficiency. These systematic improvements significantly elevate ASR accuracy\nand robustness, outperforming existing methods and offering a scalable solution\nfor diverse speech recognition scenarios. This report underscores the\nimportance of strategic optimizations in maintaining Kaldi's adaptability and\ncompetitiveness in rapidly evolving technological landscapes.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07149v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07160", "title": "GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization", "authors": ["Yikun Wang", "Yibin Wang", "Dianyi Wang", "Zimian Peng", "Qipeng Guo", "Dacheng Tao", "Jiaqi Wang"], "summary": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities across diverse domains, particularly in mathematical reasoning,\namid which geometry problem solving remains a challenging area where auxiliary\nconstruction plays a enssential role. Existing approaches either achieve\nsuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring\nmassive computational costs. We posit that reinforcement learning with\nverifiable reward (e.g., GRPO) offers a promising direction for training\nsmaller models that effectively combine auxiliary construction with robust\ngeometric reasoning. However, directly applying GRPO to geometric reasoning\npresents fundamental limitations due to its dependence on unconditional\nrewards, which leads to indiscriminate and counterproductive auxiliary\nconstructions. To address these challenges, we propose Group Contrastive Policy\nOptimization (GCPO), a novel reinforcement learning framework featuring two key\ninnovations: (1) Group Contrastive Masking, which adaptively provides positive\nor negative reward signals for auxiliary construction based on contextual\nutility, and a (2) length reward that promotes longer reasoning chains.\nBuilding on GCPO, we develop GeometryZero, a family of affordable-size\ngeometric reasoning models that judiciously determine when to employ auxiliary\nconstruction. Our extensive empirical evaluation across popular geometric\nbenchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models\nconsistently outperform baselines (e.g. GRPO), achieving an average improvement\nof 4.29% across all benchmarks.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07160v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07162", "title": "Delegation with Costly Inspection", "authors": ["Mohammad T. Hajiaghayi", "Piotr Krysta", "Mohammad Mahdavi", "Suho Shin"], "summary": "We study the problem of delegated choice with inspection cost (DCIC), which\nis a variant of the delegated choice problem by Kleinberg and Kleinberg (EC'18)\nas well as an extension of the Pandora's box problem with nonobligatory\ninspection (PNOI) by Doval (JET'18). In our model, an agent may strategically\nmisreport the proposed element's utility, unlike the standard delegated choice\nproblem which assumes that the agent truthfully reports the utility for the\nproposed alternative. Thus, the principal needs to inspect the proposed element\npossibly along with other alternatives to maximize its own utility, given an\nexogenous cost of inspecting each element. Further, the delegation itself\nincurs a fixed cost, thus the principal can decide whether to delegate or not\nand inspect by herself.\n  We show that DCIC indeed is a generalization of PNOI where the side\ninformation from a strategic agent is available at certain cost, implying its\nNP-hardness by Fu, Li, and Liu (STOC'23). We first consider a costless\ndelegation setting in which the cost of delegation is free. We prove that the\nmaximal mechanism over the pure delegation with a single inspection and an PNOI\npolicy without delegation achieves a $3$-approximation for DCIC with costless\ndelegation, which is further proven to be tight. These results hold even when\nthe cost comes from an arbitrary monotone set function, and can be improved to\na $2$-approximation if the cost of inspection is the same for every element. We\nextend these techniques by presenting a constant factor approximate mechanism\nfor the general setting for rich class of instances.", "comment": "To appear at ACM EC 2025", "cate": "cs.GT", "url": "http://arxiv.org/abs/2506.07162v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07170", "title": "Rectangular Duals on the Cylinder and the Torus", "authors": ["Therese Biedl", "Philipp Kindermann", "Jonathan Klawitter"], "summary": "A rectangular dual of a plane graph $G$ is a contact representation of $G$ by\ninterior-disjoint rectangles such that (i) no four rectangles share a point,\nand (ii) the union of all rectangles is a rectangle. In this paper, we study\nrectangular duals of graphs that are embedded in surfaces other than the plane.\nIn particular, we fully characterize when a graph embedded on a cylinder admits\na cylindrical rectangular dual. For graphs embedded on the flat torus, we can\ntest whether the graph has a toroidal rectangular dual if we are additionally\ngiven a \\textit{regular edge labeling}, i.e. a combinatorial description of\nrectangle adjacencies. Furthermore we can test whether there exists a toroidal\nrectangular dual that respects the embedding and that resides on a flat torus\nfor which the sides are axis-aligned. Testing and constructing the rectangular\ndual, if applicable, can be done efficiently.", "comment": null, "cate": "cs.CG", "url": "http://arxiv.org/abs/2506.07170v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07186", "title": "Value-Set Iteration: Computing Optimal Correlated Equilibria in Infinite-Horizon Multi-Player Stochastic Games", "authors": ["Jiarui Gan", "Rupak Majumdar"], "summary": "We study the problem of computing optimal correlated equilibria (CEs) in\ninfinite-horizon multi-player stochastic games, where correlation signals are\nprovided over time. In this setting, optimal CEs require history-dependent\npolicies; this poses new representational and algorithmic challenges as the\nnumber of possible histories grows exponentially with the number of time steps.\nWe focus on computing $(\\epsilon, \\delta)$-optimal CEs -- solutions that\nachieve a value within $\\epsilon$ of an optimal CE, while allowing the agents'\nincentive constraints to be violated by at most $\\delta$. Our main result is an\nalgorithm that computes an $(\\epsilon,\\delta)$-optimal CE in time polynomial in\n$1/(\\epsilon\\delta(1 - \\gamma))^{n+1}$, where $\\gamma$ is the discount factor,\nand $n$ is the number of agents. For (a slightly more general variant of)\nturn-based games, we further reduce the complexity to a polynomial in $n$. We\nalso establish that the bi-criterion approximation is necessary by proving\nmatching inapproximability bounds.\n  Our technical core is a novel approach based on inducible value sets, which\nleverages a compact representation of history-dependent CEs through the values\nthey induce to overcome the representational challenge. We develop the\nvalue-set iteration algorithm -- which operates by iteratively updating\nestimates of inducible value sets -- and characterize CEs as the greatest fixed\npoint of the update map. Our algorithm provides a groundwork for computing\noptimal CEs in general multi-player stochastic settings.", "comment": null, "cate": "cs.GT", "url": "http://arxiv.org/abs/2506.07186v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07193", "title": "earEOG via Periauricular Electrodes to Facilitate Eye Tracking in a Natural Headphone Form Factor", "authors": ["Tobias King", "Michael Knierim", "Philipp Lepold", "Christopher Clarke", "Hans Gellersen", "Michael Beigl", "Tobias Röddiger"], "summary": "Eye tracking technology is frequently utilized to diagnose eye and\nneurological disorders, assess sleep and fatigue, study human visual\nperception, and enable novel gaze-based interaction methods. However,\ntraditional eye tracking methodologies are constrained by bespoke hardware that\nis often cumbersome to wear, complex to apply, and demands substantial\ncomputational resources. To overcome these limitations, we investigated\nElectrooculography (EOG) eye tracking using 14 electrodes positioned around the\nears, integrated into a custom-built headphone form factor device. In a\ncontrolled experiment, 16 participants tracked stimuli designed to induce\nsmooth pursuits and saccades. Data analysis identified optimal electrode pairs\nfor vertical and horizontal eye movement tracking, benchmarked against\ngold-standard EOG and camera-based methods. The electrode montage nearest the\neyes yielded the best horizontal results. Horizontal smooth pursuits via earEOG\nshowed high correlation with gold-standard measures ($r_{\\mathrm{EOG}} = 0.81,\np = 0.01$; $r_{\\mathrm{CAM}} = 0.56, p = 0.02$), while vertical pursuits were\nweakly correlated ($r_{\\mathrm{EOG}} = 0.28, p = 0.04$; $r_{\\mathrm{CAM}} =\n0.35, p = 0.05$). Voltage deflections when performing saccades showed strong\ncorrelation in the horizontal direction ($r_{\\mathrm{left}} = 0.99, p = 0.0$;\n$r_{\\mathrm{right}} = 0.99, p = 0.0$) but low correlation in the vertical\ndirection ($r_{\\mathrm{up}} = 0.6, p = 0.23$; $r_{\\mathrm{down}} = 0.19, p =\n0.73$). Overall, horizontal earEOG demonstrated strong performance, indicating\nits potential effectiveness, while vertical earEOG results were poor,\nsuggesting limited feasibility in our current setup.", "comment": "12 pages", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07193v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07207", "title": "Methods for pitch analysis in contemporary popular music: Vitalic's use of tones that do not operate on the principle of acoustic resonance", "authors": ["Emmanuel Deruty", "Pascal Arbez-Nicolas", "David Meredith"], "summary": "Vitalic is an electronic music producer who has been active since 2001.\nVitalic's 2005 track \"No Fun\" features a main synthesiser part built from a\nsequence of single inharmonic tones that evoke two simultaneous melodies. This\npart serves as a starting point for examining Vitalic's use of tones that do\nnot operate on the principle of acoustic resonance. The study considers tones\nthat evoke two or more simultaneous pitches and examines various inharmonic\npartial layouts. Examples outside Vitalic's music are also provided to suggest\nthat similar tone properties can be found elsewhere in contemporary popular\nmusic.", "comment": null, "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07207v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07249", "title": "Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages", "authors": ["Lance Calvin Lim Gamboa", "Yue Feng", "Mark Lee"], "summary": "Emerging research on bias attribution and interpretability have revealed how\ntokens contribute to biased behavior in language models processing English\ntexts. We build on this line of inquiry by adapting the information-theoretic\nbias attribution score metric for implementation on models handling\nagglutinative languages, particularly Filipino. We then demonstrate the\neffectiveness of our adapted method by using it on a purely Filipino model and\non three multilingual models: one trained on languages worldwide and two on\nSoutheast Asian data. Our results show that Filipino models are driven towards\nbias by words pertaining to people, objects, and relationships, entity-based\nthemes that stand in contrast to the action-heavy nature of bias-contributing\nthemes in English (i.e., criminal, sexual, and prosocial behaviors). These\nfindings point to differences in how English and non-English models process\ninputs linked to sociodemographic groups and bias.", "comment": "Accepted into the Gender Bias in NLP Workshop at ACL 2025\n  (GeBNLP@ACL2025)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07249v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07253", "title": "Transient Dynamics in Lattices of Differentiating Ring Oscillators", "authors": ["Peter DelMastro", "Arjun Karuvally", "Hananel Hazan", "Hava Siegelmann", "Edward Rietman"], "summary": "Recurrent neural networks (RNNs) are machine learning models widely used for\nlearning temporal relationships. Current state-of-the-art RNNs use integrating\nor spiking neurons -- two classes of computing units whose outputs depend\ndirectly on their internal states -- and accordingly there is a wealth of\nliterature characterizing the behavior of large networks built from these\nneurons. On the other hand, past research on differentiating neurons, whose\noutputs are computed from the derivatives of their internal states, remains\nlimited to small hand-designed networks with fewer than one-hundred neurons.\nHere we show via numerical simulation that large lattices of differentiating\nneuron rings exhibit local neural synchronization behavior found in the\nKuramoto model of interacting oscillators. We begin by characterizing the\nperiodic orbits of uncoupled rings, herein called ring oscillators. We then\nshow the emergence of local correlations between oscillators that grow over\ntime when these rings are coupled together into lattices. As the correlation\nlength grows, transient dynamics arise in which large regions of the lattice\nsettle to the same periodic orbit, and thin domain boundaries separate\nadjacent, out-of-phase regions. The steady-state scale of these correlated\nregions depends on how the neurons are shared between adjacent rings, which\nsuggests that lattices of differentiating ring oscillator might be tuned to be\nused as reservoir computers. Coupled with their simple circuit design and\npotential for low-power consumption, differentiating neural nets therefore\nrepresent a promising substrate for neuromorphic computing that will enable\nlow-power AI applications.", "comment": "15 pages, 10 figures", "cate": "cs.NE", "url": "http://arxiv.org/abs/2506.07253v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07268", "title": "CNFs and DNFs with Exactly $k$ Solutions", "authors": ["L. Sunil Chandran", "Rishikesh Gajjala", "Kuldeep S. Meel"], "summary": "Model counting is a fundamental problem that consists of determining the\nnumber of satisfying assignments for a given Boolean formula. The weighted\nvariant, which computes the weighted sum of satisfying assignments, has\nextensive applications in probabilistic reasoning, network reliability,\nstatistical physics, and formal verification. A common approach for solving\nweighted model counting is to reduce it to unweighted model counting, which\nraises an important question: {\\em What is the minimum number of terms (or\nclauses) required to construct a DNF (or CNF) formula with exactly $k$\nsatisfying assignments?}\n  In this paper, we establish both upper and lower bounds on this question. We\nprove that for any natural number $k$, one can construct a monotone DNF formula\nwith exactly $k$ satisfying assignments using at most $O(\\sqrt{\\log k}\\log\\log\nk)$ terms. This construction represents the first $o(\\log k)$ upper bound for\nthis problem. We complement this result by showing that there exist infinitely\nmany values of $k$ for which any DNF or CNF representation requires at least\n$\\Omega(\\log\\log k)$ terms or clauses. These results have significant\nimplications for the efficiency of model counting algorithms based on formula\ntransformations.", "comment": "To appear in SAT 2025", "cate": "cs.DM", "url": "http://arxiv.org/abs/2506.07268v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07270", "title": "Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs", "authors": ["Atahan Özer", "Çağatay Yıldız"], "summary": "Large language models (LLMs) exhibit remarkable capabilities in question\nanswering and reasoning thanks to their extensive parametric memory. However,\ntheir knowledge is inherently limited by the scope of their pre-training data,\nwhile real-world information evolves continuously. Updating this knowledge\ntypically requires costly and brittle re-training, or in-context learning\n(ICL), which becomes impractical at scale given the volume and volatility of\nmodern information. Motivated by these limitations, we investigate how LLMs\nperform when exposed to temporal text corpora, or documents that reflect\nevolving knowledge over time, such as sports biographies where facts like a\nplayer's \"current team\" change year by year. To this end, we introduce two new\nbenchmarks: Temporal Wiki, which captures factual drift across historical\nWikipedia snapshots, and Unified Clark, which aggregates timestamped news\narticles to simulate real-world information accumulation. Our analysis reveals\nthat LLMs often struggle to reconcile conflicting or outdated facts and can be\nmisled when multiple versions of a fact appear in context. To address these\nissues, we propose a lightweight, agentic framework that incrementally builds a\nstructured, external memory from source documents without requiring\nre-training. This knowledge organization strategy enables models to retrieve\nand reason over temporally filtered, relevant information at inference time.\nEmpirically, our method outperforms ICL and RAG baselines across both\nbenchmarks, especially on questions requiring more complex reasoning or\nintegration of conflicting facts.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07270v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07278", "title": "IDEIA: A Generative AI-Based System for Real-Time Editorial Ideation in Digital Journalism", "authors": ["Victor B. Santos", "Cauã O. Jordão", "Leonardo J. O. Ibiapina", "Gabriel M. Silva", "Mirella E. B. Santana", "Matheus A. Garrido", "Lucas R. C. Farias"], "summary": "This paper presents IDEIA (Intelligent Engine for Editorial Ideation and\nAssistance), a generative AI-powered system designed to optimize the\njournalistic ideation process by combining real-time trend analysis with\nautomated content suggestion. Developed in collaboration with the Sistema\nJornal do Commercio de Comunica\\c{c}\\~ao (SJCC), the largest media conglomerate\nin Brazil's North and Northeast regions, IDEIA integrates the Google Trends API\nfor data-driven topic monitoring and the Google Gemini API for the generation\nof context-aware headlines and summaries. The system adopts a modular\narchitecture based on Node.js, React, and PostgreSQL, supported by Docker\ncontainerization and a CI/CD pipeline using GitHub Actions and Vercel.\nEmpirical results demonstrate a significant reduction in the time and cognitive\neffort required for editorial planning, with reported gains of up to 70\\% in\nthe content ideation stage. This work contributes to the field of computational\njournalism by showcasing how intelligent automation can enhance productivity\nwhile maintaining editorial quality. It also discusses the technical and\nethical implications of incorporating generative models into newsroom\nworkflows, highlighting scalability and future applicability across sectors\nbeyond journalism.", "comment": "9 pages, 5 figures", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07278v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07285", "title": "Research Knowledge Graphs: the Shifting Paradigm of Scholarly Information Representation", "authors": ["Matthäus Zloch", "Danilo Dessì", "Jennifer D'Souza", "Leyla Jael Castro", "Benjamin Zapilko", "Saurav Karmakar", "Brigitte Mathiak", "Markus Stocker", "Wolfgang Otto", "Sören Auer", "Stefan Dietze"], "summary": "Sharing and reusing research artifacts, such as datasets, publications, or\nmethods is a fundamental part of scientific activity, where heterogeneity of\nresources and metadata and the common practice of capturing information in\nunstructured publications pose crucial challenges. Reproducibility of research\nand finding state-of-the-art methods or data have become increasingly\nchallenging. In this context, the concept of Research Knowledge Graphs (RKGs)\nhas emerged, aiming at providing an easy to use and machine-actionable\nrepresentation of research artifacts and their relations. That is facilitated\nthrough the use of established principles for data representation, the\nconsistent adoption of globally unique persistent identifiers and the reuse and\nlinking of vocabularies and data. This paper provides the first\nconceptualisation of the RKG vision, a categorisation of in-use RKGs together\nwith a description of RKG building blocks and principles. We also survey\nreal-world RKG implementations differing with respect to scale, schema, data,\nused vocabulary, and reliability of the contained data. We also characterise\ndifferent RKG construction methodologies and provide a forward-looking\nperspective on the diverse applications, opportunities, and challenges\nassociated with the RKG vision.", "comment": "Extended Semantic Web Conference 2025, In-use track, 10 pages, 1\n  figure", "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.07285v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07295", "title": "Exploring the Impact of Temperature on Large Language Models:Hot or Cold?", "authors": ["Lujun Li", "Lama Sleem", "Niccolo' Gentile", "Geoffrey Nichil", "Radu State"], "summary": "The sampling temperature, a critical hyperparameter in large language models\n(LLMs), modifies the logits before the softmax layer, thereby reshaping the\ndistribution of output tokens. Recent studies have challenged the Stochastic\nParrots analogy by demonstrating that LLMs are capable of understanding\nsemantics rather than merely memorizing data and that randomness, modulated by\nsampling temperature, plays a crucial role in model inference. In this study,\nwe systematically evaluated the impact of temperature in the range of 0 to 2 on\ndata sets designed to assess six different capabilities, conducting statistical\nanalyses on open source models of three different sizes: small (1B--4B), medium\n(6B--13B), and large (40B--80B). Our findings reveal distinct skill-specific\neffects of temperature on model performance, highlighting the complexity of\noptimal temperature selection in practical applications. To address this\nchallenge, we propose a BERT-based temperature selector that takes advantage of\nthese observed effects to identify the optimal temperature for a given prompt.\nWe demonstrate that this approach can significantly improve the performance of\nsmall and medium models in the SuperGLUE datasets. Furthermore, our study\nextends to FP16 precision inference, revealing that temperature effects are\nconsistent with those observed in 4-bit quantized models. By evaluating\ntemperature effects up to 4.0 in three quantized models, we find that the\nMutation Temperature -- the point at which significant performance changes\noccur -- increases with model size.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07295v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07297", "title": "Subjectivity in the Annotation of Bridging Anaphora", "authors": ["Lauren Levine", "Amir Zeldes"], "summary": "Bridging refers to the associative relationship between inferable entities in\na discourse and the antecedents which allow us to understand them, such as\nunderstanding what \"the door\" means with respect to an aforementioned \"house\".\nAs identifying associative relations between entities is an inherently\nsubjective task, it is difficult to achieve consistent agreement in the\nannotation of bridging anaphora and their antecedents. In this paper, we\nexplore the subjectivity involved in the annotation of bridging instances at\nthree levels: anaphor recognition, antecedent resolution, and bridging subtype\nselection. To do this, we conduct an annotation pilot on the test set of the\nexisting GUM corpus, and propose a newly developed classification system for\nbridging subtypes, which we compare to previously proposed schemes. Our results\nsuggest that some previous resources are likely to be severely under-annotated.\nWe also find that while agreement on the bridging subtype category was\nmoderate, annotator overlap for exhaustively identifying instances of bridging\nis low, and that many disagreements resulted from subjective understanding of\nthe entities involved.", "comment": "LAW-XIX, ACL 2025 Workshop", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07297v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07309", "title": "ConfQA: Answer Only If You Are Confident", "authors": ["Yin Huang", "Yifan Ethan Xu", "Kai Sun", "Vera Yan", "Alicia Sun", "Haidar Khan", "Jimmy Nguyen", "Mohammad Kachuee", "Zhaojiang Lin", "Yue Liu", "Aaron Colak", "Anuj Kumar", "Wen-tau Yih", "Xin Luna Dong"], "summary": "Can we teach Large Language Models (LLMs) to refrain from hallucinating\nfactual statements? In this paper we present a fine-tuning strategy that we\ncall ConfQA, which can reduce hallucination rate from 20-40% to under 5% across\nmultiple factuality benchmarks. The core idea is simple: when the LLM answers a\nquestion correctly, it is trained to continue with the answer; otherwise, it is\ntrained to admit \"I am unsure\". But there are two key factors that make the\ntraining highly effective. First, we introduce a dampening prompt \"answer only\nif you are confident\" to explicitly guide the behavior, without which\nhallucination remains high as 15%-25%. Second, we leverage simple factual\nstatements, specifically attribute values from knowledge graphs, to help LLMs\ncalibrate the confidence, resulting in robust generalization across domains and\nquestion types. Building on this insight, we propose the Dual Neural Knowledge\nframework, which seamlessly select between internally parameterized neural\nknowledge and externally recorded symbolic knowledge based on ConfQA's\nconfidence. The framework enables potential accuracy gains to beyond 95%, while\nreducing unnecessary external retrievals by over 30%.", "comment": "10 pages main content, 10 pages appendix, 5 figures, 7 tables", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07309v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07316", "title": "Vulnerability and Defence: A Case for Stackelberg Game Dynamics", "authors": ["Azhar Iqbal", "Ishan Honhaga", "Eyoel Teffera", "Anthony Perry", "Robin Baker", "Glenn Pearce", "Claudia Szabo"], "summary": "This paper examines the tactical interaction between drones and tanks in\nmodern warfare through game theory, particularly focusing on Stackelberg\nequilibrium and backward induction. It describes a high-stakes conflict between\ntwo teams: one using advanced drones for attack, and the other defending using\ntanks. The paper conceptualizes this as a sequential game, illustrating the\ncomplex strategic dynamics similar to Stackelberg competition, where moves and\ncountermoves are carefully analyzed and predicted.", "comment": "20 pages, 5 figures", "cate": "cs.GT", "url": "http://arxiv.org/abs/2506.07316v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07342", "title": "On Sketching Trimmed Statistics", "authors": ["Honghao Lin", "Hoai-An Nguyen", "David P. Woodruff"], "summary": "We present space-efficient linear sketches for estimating trimmed statistics\nof an $n$-dimensional frequency vector $x$, e.g., the sum of $p$-th powers of\nthe largest $k$ frequencies (i.e., entries) in absolute value, or the\n$k$-trimmed vector, which excludes the top and bottom $k$ frequencies. This is\ncalled the $F_p$ moment of the trimmed vector. Trimmed measures are used in\nrobust estimation, as seen in the R programming language's `trim.var' function\nand the `trim' parameter in the mean function. Linear sketches improve time and\nmemory efficiency and are applicable to streaming and distributed settings. We\ninitiate the study of sketching these statistics and give a new condition for\ncapturing their space complexity. When $k \\ge n/poly\\log n$, we give a linear\nsketch using $poly(1/\\varepsilon, \\log n)$ space which provides a $(1 \\pm\n\\varepsilon)$ approximation to the top-$k$ $F_p$ moment for $p \\in [0,2]$. For\ngeneral $k$, we give a sketch with the same guarantees under a condition\nrelating the $k$-th largest frequency to the tail mass, and show this condition\nis necessary. For the $k$-trimmed version, our sketch achieves optimal error\nguarantees under the same condition. We extend our methods to $p > 2$ and also\naddress related problems such as computing the $F_p$ moment of frequencies\nabove a threshold, finding the largest $k$ such that the $F_p$ moment of the\ntop $k$ exceeds $k^{p+1}$, and the $F_p$ moment of the top $k$ frequencies such\nthat each entry is at least $k$. Notably, our algorithm for this third\napplication improves upon the space bounds of the algorithm of Govindan,\nMonemizadeh, and Muthukrishnan (PODS '17) for computing the $h$-index. We show\nempirically that our top $k$ algorithm uses much less space compared to\nCount-Sketch while achieving the same error.", "comment": null, "cate": "cs.DS", "url": "http://arxiv.org/abs/2506.07342v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07356", "title": "Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation", "authors": ["Seokil Ham", "Yubin Choi", "Seungju Cho", "Yujin Yang", "Younghun Kim", "Changick Kim"], "summary": "Recently, major AI service providers such as Google and OpenAI have\nintroduced Finetuning-as-a-Service, which enables users to customize Large\nLanguage Models (LLMs) for specific downstream tasks using their own data.\nHowever, this service is vulnerable to degradation of LLM safety-alignment when\nuser data contains harmful prompts. While some prior works address this issue,\nfundamentally filtering harmful data from user data remains unexplored.\nMotivated by our observation that a directional representation reflecting\nrefusal behavior (called the refusal feature) obtained from safety-aligned LLMs\ncan inherently distinguish between harmful and harmless prompts, we propose the\nRefusal-Feature-guided Teacher (ReFT). Our ReFT model is trained to identify\nharmful prompts based on the similarity between input prompt features and its\nrefusal feature. During finetuning, the ReFT model serves as a teacher that\nfilters harmful prompts from user data and distills alignment knowledge into\nthe base model. Extensive experiments demonstrate that our ReFT-based\nfinetuning strategy effectively minimizes harmful outputs and enhances\nfinetuning accuracy for user-specific tasks, offering a practical solution for\nsecure and reliable deployment of LLMs in Finetuning-as-a-Service.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07356v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07359", "title": "2N-storage Runge-Kutta methods: Order conditions, general properties and some analytic solutions", "authors": ["Alexei Bazavov"], "summary": "Low-storage Runge-Kutta schemes of Williamson's type, so-called 2N-storage\nschemes, are examined. Explicit 2N-storage constraints are derived for the\nfirst time and used to establish new relations between the entries of the\nButcher tableau. An error in the Williamson's formula for converting\ncoefficients between the standard and 2N-storage formats in the special case is\npointed out and corrected. The new relations are used to derive a closed-form\nsolution for four- and five-stage 2N-storage methods with the third order of\nglobal accuracy. Several new four- and five-stage schemes with rational\ncoefficients are presented and numerically examined for illustration.", "comment": "33 pages, 2 figures", "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07359v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07370", "title": "Numerical Approximation and Analysis of the Inverse Robin Problem Using the Kohn-Vogelius Method", "authors": ["Erik Burman", "Siyu Cen", "Bangti Jin", "Zhi Zhou"], "summary": "In this work, we numerically investigate the inverse Robin problem of\nrecovering a piecewise constant Robin coefficient in an elliptic or parabolic\nproblem from the Cauchy data on a part of the boundary, a problem that commonly\narises in applications such as non-destructive corrosion detection. We employ a\nKohn-Vogelius type variational functional for the regularized reconstruction,\nand discretize the resulting optimization problem using the Galerkin finite\nelement method on a graded mesh. We establish rigorous error estimates on the\nrecovered Robin coefficient in terms of the mesh size, temporal step size and\nnoise level. This is achieved by combining the approximation error of the\ndirect problem, a priori estimates on the functional, and suitable conditional\nstability estimates of the continuous inverse problem. We present several\nnumerical experiments to illustrate the approach and to complement the\ntheoretical findings.", "comment": "25 pages", "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07370v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07374", "title": "Extended Version of \"Distributed Adaptive Resilient Consensus Control for Uncertain Nonlinear Multiagent Systems Against Deception Attacks\"", "authors": ["Mengze Yu", "Wei Wang", "Jiaqi Yan"], "summary": "This paper studies distributed resilient consensus problem for a class of\nuncertain nonlinear multiagent systems susceptible to deception attacks. The\nattacks invade both sensor and actuator channels of each agent. A specific\nclass of Nussbaum functions is adopted to manage the attack-incurred multiple\nunknown control directions. Additionally, a general form of these Nussbaum\nfunctions is provided, which helps to ease the degeneration of output\nperformance caused by Nussbaum gains. Then, by introducing finite-time\ndistributed reference systems and local-error-based dynamic gains, we propose a\nnovel distributed adaptive backstepping-based resilient consensus control\nstrategy. We prove that all the closed-loop signals are uniformly bounded under\nattacks, and output consensus errors converge in finite time to a\nclearly-defined residual set whose size can be reduced by tuning control\nparameters, which is superior to existing results. Simulation results display\nthe effectiveness of the proposed controllers.", "comment": "7 pages, 6 figures. submitted to IEEE Control Systems Letters", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07374v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07381", "title": "Multiscale model reduction and two-level Schwarz preconditioner for H(curl) elliptic problems", "authors": ["Chupeng Ma", "Yongwei Zhang"], "summary": "This paper addresses the efficient solution of linear systems arising from\ncurl-conforming finite element discretizations of $H(\\mathrm{curl})$ elliptic\nproblems with heterogeneous coefficients. We first employ the discrete form of\na multiscale spectral generalized finite element method (MS-GFEM) for model\nreduction and prove that the method exhibits exponential convergence with\nrespect to the number of local degrees of freedom. The proposed method and its\nconvergence analysis are applicable in broad settings, including general\nheterogeneous ($L^{\\infty}$) coefficients, domains and subdomains with\nnontrivial topology, irregular subdomain geometries, and high-order finite\nelement discretizations. Furthermore, we formulate the method as an iterative\nsolver, yielding a two-level restricted additive Schwarz type preconditioner\nbased on the MS-GFEM coarse space. The GMRES algorithm, applied to the\npreconditioned system, is shown to converge at a rate of at least $\\Lambda$,\nwhere $\\Lambda$ denotes the error bound of the discrete MS-GFEM approximation.\nNumerical experiments in both two and three dimensions demonstrate the superior\nperformance of the proposed methods in terms of dimensionality reduction.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07381v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07393", "title": "Happiness Finder: Exploring the Role of AI in Enhancing Well-Being During Four-Leaf Clover Searches", "authors": ["Anna Yokokubo", "Takeo Hamada", "Tatsuya Ishizuka", "Hiroaki Mori", "Noboru Koshizuka"], "summary": "A four-leaf clover (FLC) symbolizes luck and happiness worldwide, but it is\nhard to distinguish it from the common three-leaf clover. While AI technology\ncan assist in searching for FLC, it may not replicate the traditional search's\nsense of achievement. This study explores searcher feelings when AI aids the\nFLC search. In this study, we developed a system called ``Happiness Finder''\nthat uses object detection algorithms on smartphones or tablets to support the\nsearch. We exhibited HappinessFinder at an international workshop, allowing\nparticipants to experience four-leaf clover searching using potted artificial\nclovers and the HappinessFinder app. This paper reports the findings from this\ndemonstration.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07393v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07423", "title": "SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation", "authors": ["Janghyeon Yun", "Sang-goo Lee"], "summary": "Text-to-SQL enables non-experts to retrieve data from databases by converting\nnatural language queries into SQL. However, state-of-the-art text-to-SQL\nstudies rely on the BIRD dataset, which assumes that evidence is provided along\nwith questions. Although BIRD facilitates research advancements, it assumes\nthat users have expertise and domain knowledge, contradicting the fundamental\ngoal of text-to-SQL. In addition, human-generated evidence in BIRD contains\ndefects, including missing or erroneous evidence, which affects model\nperformance. To address this issue, we propose SEED (System for Evidence\nExtraction and Domain knowledge generation), an approach that automatically\ngenerates evidence to improve performance and practical usability in real-world\nscenarios. SEED systematically analyzes database schema, description files, and\nvalues to extract relevant information. We evaluated SEED on BIRD and Spider,\ndemonstrating that it significantly improves SQL generation accuracy in the\nno-evidence scenario, and in some cases, even outperforms the setting where\nBIRD evidence is provided. Our results highlight that SEED-generated evidence\nnot only bridges the gap between research and real-world deployment but also\nimproves the adaptability and robustness of text-to-SQL models. Our code is\navailable at https://github.com/felix01189/SEED", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07423v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07429", "title": "Conjoined Predication and Scalar Implicature", "authors": ["Ratna Kandala"], "summary": "Magri (2016) investigates two puzzles arising from conjunction. Although\nMagri has proposed a solution to the second puzzle, the first remains\nunresolved. This first puzzle reveals a hidden interaction among\nquantification, collective/concurrent interpretation, and contextual updating\ndimensions that have yet to be explored. In essence, the problem is that\ncertain forms of sentences like \"Some Italians come from a warm country,\" when\nconjoined as in \"(Only) Some Italians come from a warm country and are blond,\"\nsound infelicitous, even though no obvious alternative triggers a conflicting\nscalar implicature. In this paper, we offer a conceptual analysis of Magri's\nfirst puzzle by situating it within its original theoretical framework. We\nargue that the oddness arises from the collective or concurrent reading of the\nconjunctive predicate: in examples such as \"(Only) Some Italians come from a\nwarm country and are blond,\" this interpretation generates an indirect\ncontextual contradiction. Moreover, we suggest that the pragmatic mechanisms\ngoverning scalar implicature generation extend beyond what is captured by\nexhaustification-based grammatical licensing accounts.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07429v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07433", "title": "The pollution effect for the Ginzburg-Landau equation", "authors": ["Théophile Chaumont-Frelet", "Patrick Henning"], "summary": "In this paper, we investigate the approximation properties of solutions to\nthe Ginzburg-Landau equation (GLE) in finite element spaces. Special attention\nis given to how the errors are influenced by coupling the mesh size $h$ and the\npolynomial degree $p$ of the finite element space to the size of the so-called\nGinzburg-Landau material parameter $\\kappa$. As observed in previous works, the\nfinite element approximations to the GLE are suffering from a numerical\npollution effect, that is, the best-approximation error in the finite element\nspace converges under mild coupling conditions between $h$ and $\\kappa$,\nwhereas the actual finite element solutions possess poor accuracy in a large\npre-asymptotic regime which depends on $\\kappa$. In this paper, we provide a\nnew error analysis that allows us to quantify the pre-asymptotic regime and the\ncorresponding pollution effect in terms of explicit resolution conditions. In\nparticular, we are able to prove that higher polynomial degrees reduce the\npollution effect, i.e., the accuracy of the best-approximation is achieved\nunder relaxed conditions for the mesh size. We provide both error estimates in\nthe $H^1$- and the $L^2$-norm and we illustrate our findings with numerical\nexamples.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07433v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07438", "title": "LG-ANNA-Embedding technical report", "authors": ["Jooyoung Choi", "Hyun Kim", "Hansol Jang", "Changwook Jun", "Kyunghoon Bae", "Hyewon Choi", "Stanley Jungkyu Choi", "Honglak Lee", "Chulmin Yun"], "summary": "This report presents a unified instruction-based framework for learning\ngeneralized text embeddings optimized for both information retrieval (IR) and\nnon-IR tasks. Built upon a decoder-only large language model (Mistral-7B), our\napproach combines in-context learning, soft supervision, and adaptive\nhard-negative mining to generate context-aware embeddings without task-specific\nfine-tuning. Structured instructions and few-shot examples are used to guide\nthe model across diverse tasks, enabling strong performance on classification,\nsemantic similarity, clustering, and reranking benchmarks. To improve semantic\ndiscrimination, we employ a soft labeling framework where continuous relevance\nscores, distilled from a high-performance dense retriever and reranker, serve\nas fine-grained supervision signals. In addition, we introduce adaptive\nmargin-based hard-negative mining, which filters out semantically ambiguous\nnegatives based on their similarity to positive examples, thereby enhancing\ntraining stability and retrieval robustness. Our model is evaluated on the\nnewly introduced MTEB (English, v2) benchmark, covering 41 tasks across seven\ncategories. Results show that our method achieves strong generalization and\nranks among the top-performing models by Borda score, outperforming several\nlarger or fully fine-tuned baselines. These findings highlight the\neffectiveness of combining in-context prompting, soft supervision, and adaptive\nsampling for scalable, high-quality embedding generation.", "comment": "10 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07438v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07453", "title": "Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling", "authors": ["Pritom Saha Akash", "Kevin Chen-Chuan Chang"], "summary": "Topic modeling plays a vital role in uncovering hidden semantic structures\nwithin text corpora, but existing models struggle in low-resource settings\nwhere limited target-domain data leads to unstable and incoherent topic\ninference. We address this challenge by formally introducing domain adaptation\nfor low-resource topic modeling, where a high-resource source domain informs a\nlow-resource target domain without overwhelming it with irrelevant content. We\nestablish a finite-sample generalization bound showing that effective knowledge\ntransfer depends on robust performance in both domains, minimizing latent-space\ndiscrepancy, and preventing overfitting to the data. Guided by these insights,\nwe propose DALTA (Domain-Aligned Latent Topic Adaptation), a new framework that\nemploys a shared encoder for domain-invariant features, specialized decoders\nfor domain-specific nuances, and adversarial alignment to selectively transfer\nrelevant information. Experiments on diverse low-resource datasets demonstrate\nthat DALTA consistently outperforms state-of-the-art methods in terms of topic\ncoherence, stability, and transferability.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07453v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07461", "title": "From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered", "authors": ["Siddartha Devic", "Tejas Srinivasan", "Jesse Thomason", "Willie Neiswanger", "Vatsal Sharan"], "summary": "Large Language Models (LLMs) are increasingly assisting users in the real\nworld, yet their reliability remains a concern. Uncertainty quantification (UQ)\nhas been heralded as a tool to enhance human-LLM collaboration by enabling\nusers to know when to trust LLM predictions. We argue that current practices\nfor uncertainty quantification in LLMs are not optimal for developing useful UQ\nfor human users making decisions in real-world tasks. Through an analysis of 40\nLLM UQ methods, we identify three prevalent practices hindering the community's\nprogress toward its goal of benefiting downstream users: 1) evaluating on\nbenchmarks with low ecological validity; 2) considering only epistemic\nuncertainty; and 3) optimizing metrics that are not necessarily indicative of\ndownstream utility. For each issue, we propose concrete user-centric practices\nand research directions that LLM UQ researchers should consider. Instead of\nhill-climbing on unrepresentative tasks using imperfect metrics, we argue that\nthe community should adopt a more human-centered approach to LLM uncertainty\nquantification.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07461v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07466", "title": "Leveraging Historical and Current Interests for Continual Sequential Recommendation", "authors": ["Gyuseok Lee", "Hyunsik Yoo", "Junyoung Hwang", "SeongKu Kang", "Hwanjo Yu"], "summary": "Sequential recommendation models based on the Transformer architecture show\nsuperior performance in harnessing long-range dependencies within user behavior\nvia self-attention. However, naively updating them on continuously arriving\nnon-stationary data streams incurs prohibitive computation costs or leads to\ncatastrophic forgetting. To address this, we propose Continual Sequential\nTransformer for Recommendation (CSTRec) that effectively leverages\nwell-preserved historical user interests while capturing current interests. At\nits core is Continual Sequential Attention (CSA), a linear attention mechanism\nthat retains past knowledge without direct access to old data. CSA integrates\ntwo key components: (1) Cauchy-Schwarz Normalization that stabilizes training\nunder uneven interaction frequencies, and (2) Collaborative Interest Enrichment\nthat mitigates forgetting through shared, learnable interest pools. We further\nintroduce a technique that facilitates learning for cold-start users by\ntransferring historical knowledge from behaviorally similar existing users.\nExtensive experiments on three real-world datasets indicate that CSTRec\noutperforms state-of-the-art baselines in both knowledge retention and\nacquisition.", "comment": null, "cate": "cs.IR", "url": "http://arxiv.org/abs/2506.07466v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07473", "title": "An introduction to pitch strength in contemporary popular music analysis and production", "authors": ["Emmanuel Deruty"], "summary": "Music information retrieval distinguishes between low- and high-level\ndescriptions of music. Current generative AI models rely on text descriptions\nthat are higher level than the controls familiar to studio musicians. Pitch\nstrength, a low-level perceptual parameter of contemporary popular music, may\nbe one feature that could make such AI models more suited to music production.\nSignal and perceptual analyses suggest that pitch strength (1) varies\nsignificantly across and inside songs; (2) contributes to both small- and\nlarge-scale structure; (3) contributes to the handling of polyphonic\ndissonance; and (4) may be a feature of upper harmonics made audible in a\nperspective of perceptual richness.", "comment": "In Music 2024, Innovation in Music Conference, 14-16 June, 2024,\n  Kristiania University College, Oslo, Norway", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07473v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07479", "title": "Improving Fairness of Large Language Models in Multi-document Summarization", "authors": ["Haoyuan Li Yusen Zhang", "Snigdha Chaturvedi"], "summary": "Fairness in multi-document summarization (MDS) is crucial for providing\ncomprehensive views across documents with diverse social attribute values,\nwhich can significantly impact decision-making. For example, a summarization\nsystem that tends to overrepresent negative reviews of products can mislead\ncustomers into disregarding good products. Previous works measure fairness in\nMDS at two levels: summary-level and corpus-level. While summary-level fairness\nfocuses on individual summaries, corpus-level fairness focuses on a corpus of\nsummaries. Recent methods primarily focus on summary-level fairness. We propose\nFairPO, a preference tuning method that focuses on both summary-level and\ncorpus-level fairness in MDS. To improve summary-level fairness, we propose to\ngenerate preference pairs by perturbing document sets. To improve corpus-level\nfairness, we propose fairness-aware preference tuning by dynamically adjusting\nthe weights of preference pairs. Our experiments show that FairPO outperforms\nstrong baselines while maintaining the critical qualities of summaries. The\ncode is available at https://github.com/leehaoyuan/coverage_fairnes.", "comment": "Accepted to ACL 2025 main", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07479v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07483", "title": "A Hybrid GA LLM Framework for Structured Task Optimization", "authors": ["Berry Feng", "Jonas Lin", "Patrick Lau"], "summary": "GA LLM is a hybrid framework that combines Genetic Algorithms with Large\nLanguage Models to handle structured generation tasks under strict constraints.\nEach output, such as a plan or report, is treated as a gene, and evolutionary\noperations like selection, crossover, and mutation are guided by the language\nmodel to iteratively improve solutions. The language model provides domain\nknowledge and creative variation, while the genetic algorithm ensures\nstructural integrity and global optimization. GA LLM has proven effective in\ntasks such as itinerary planning, academic outlining, and business reporting,\nconsistently producing well structured and requirement satisfying results. Its\nmodular design also makes it easy to adapt to new tasks. Compared to using a\nlanguage model alone, GA LLM achieves better constraint satisfaction and higher\nquality solutions by combining the strengths of both components.", "comment": "7 pages", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07483v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07502", "title": "DEBATE: A Dataset for Disentangling Textual Ambiguity in Mandarin Through Speech", "authors": ["Haotian Guo", "Jing Han", "Yongfeng Tu", "Shihao Gao", "Shengfan Shen", "Wulong Xiang", "Weihao Gan", "Zixing Zhang"], "summary": "Despite extensive research on textual and visual disambiguation,\ndisambiguation through speech (DTS) remains underexplored. This is largely due\nto the lack of high-quality datasets that pair spoken sentences with richly\nambiguous text. To address this gap, we present DEBATE, a unique public Chinese\nspeech-text dataset designed to study how speech cues and\npatterns-pronunciation, pause, stress and intonation-can help resolve textual\nambiguity and reveal a speaker's true intent. DEBATE contains 1,001 carefully\nselected ambiguous utterances, each recorded by 10 native speakers, capturing\ndiverse linguistic ambiguities and their disambiguation through speech. We\ndetail the data collection pipeline and provide rigorous quality analysis.\nAdditionally, we benchmark three state-of-the-art large speech and\naudio-language models, illustrating clear and huge performance gaps between\nmachine and human understanding of spoken intent. DEBATE represents the first\neffort of its kind and offers a foundation for building similar DTS datasets\nacross languages and cultures. The dataset and associated code are available\nat: https://github.com/SmileHnu/DEBATE.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07502v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07506", "title": "What Do Indonesians Really Need from Language Technology? A Nationwide Survey", "authors": ["Muhammad Dehan Al Kautsar", "Lucky Susanto", "Derry Wijaya", "Fajri Koto"], "summary": "There is an emerging effort to develop NLP for Indonesias 700+ local\nlanguages, but progress remains costly due to the need for direct engagement\nwith native speakers. However, it is unclear what these language communities\ntruly need from language technology. To address this, we conduct a nationwide\nsurvey to assess the actual needs of native speakers in Indonesia. Our findings\nindicate that addressing language barriers, particularly through machine\ntranslation and information retrieval, is the most critical priority. Although\nthere is strong enthusiasm for advancements in language technology, concerns\naround privacy, bias, and the use of public data for AI training highlight the\nneed for greater transparency and clear communication to support broader AI\nadoption.", "comment": "26 pages, 12 figures, 5 tables", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07506v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07510", "title": "DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction", "authors": ["Solee Im", "Wonjun Lee", "Jinmyeong An", "Yunsu Kim", "Jungseul Ok", "Gary Geunbae Lee"], "summary": "We present DeRAGEC, a method for improving Named Entity (NE) correction in\nAutomatic Speech Recognition (ASR) systems. By extending the\nRetrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC\nemploys synthetic denoising rationales to filter out noisy NE candidates before\ncorrection. By leveraging phonetic similarity and augmented definitions, it\nrefines noisy retrieved NEs using in-context learning, requiring no additional\ntraining. Experimental results on CommonVoice and STOP datasets show\nsignificant improvements in Word Error Rate (WER) and NE hit ratio,\noutperforming baseline ASR and RAGEC methods. Specifically, we achieved a 28%\nrelative reduction in WER compared to ASR without postprocessing. Our source\ncode is publicly available at: https://github.com/solee0022/deragec", "comment": "ACL2025 Findings", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07510v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07519", "title": "Pseudo-random sequences for low-cost operando impedance measurements of Li-ion batteries", "authors": ["Jussi Sihvo", "Noël Hallemans", "Ai Hui Tan", "David A. Howey", "Stephen. R. Duncan", "Tomi Roinila"], "summary": "Operando impedance measurements are promising for monitoring batteries in the\nfield. In this work, we present pseudo-random sequences for low-cost operando\nbattery impedance measurements. The quadratic-residue ternary sequence and\ndirect-synthesis ternary sequence exhibit specific properties related to\neigenvectors of the discrete Fourier transform matrix that allow\ncomputationally efficient compensation for drifts and transients in operando\nimpedance measurements. We describe the application of pseudo-random sequences\nand provide the data processing required to suppress drift and transients,\nvalidated on simulations. Finally, we perform experimental operando impedance\nmeasurements on a Li-ion battery cell during fast-charging, demonstrating the\napplicability of the proposed method. It's low-cost hardware requirements, fast\nmeasurements, and simple data-processing make the method practical for\nembedding in battery management systems.", "comment": "10 pages, 7 figures", "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07519v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07523", "title": "Towards Large Language Models with Self-Consistent Natural Language Explanations", "authors": ["Sahar Admoni", "Ofra Amir", "Assaf Hallak", "Yftah Ziser"], "summary": "Large language models (LLMs) seem to offer an easy path to interpretability:\njust ask them to explain their decisions. Yet, studies show that these post-hoc\nexplanations often misrepresent the true decision process, as revealed by\nmismatches in feature importance. Despite growing evidence of this\ninconsistency, no systematic solutions have emerged, partly due to the high\ncost of estimating feature importance, which limits evaluations to small\ndatasets. To address this, we introduce the Post-hoc Self-Consistency Bank\n(PSCB) - a large-scale benchmark of decisions spanning diverse tasks and\nmodels, each paired with LLM-generated explanations and corresponding feature\nimportance scores. Analysis of PSCB reveals that self-consistency scores barely\ndiffer between correct and incorrect predictions. We also show that the\nstandard metric fails to meaningfully distinguish between explanations. To\novercome this limitation, we propose an alternative metric that more\neffectively captures variation in explanation quality. We use it to fine-tune\nLLMs via Direct Preference Optimization (DPO), leading to significantly better\nalignment between explanations and decision-relevant features, even under\ndomain shift. Our findings point to a scalable path toward more trustworthy,\nself-consistent LLMs.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07523v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07526", "title": "Generative Voice Bursts during Phone Call", "authors": ["Paritosh Ranjan", "Surajit Majumder", "Prodip Roy"], "summary": "In critical situations, conventional mobile telephony fails to convey\nemergency voice messages to a callee already engaged in another call. The\nstandard call waiting alert does not provide the urgency or content of the\nwaiting call. This paper proposes a novel method for transmitting Generative\nVoice Bursts short, context aware audio messages during ongoing calls, from\neither preauthorized or dynamically prioritized callers. By leveraging\ngenerative AI techniques, the system automatically generates spoken messages\nfrom contextual inputs example like location, health data, images, background\nnoise when the caller is unable to speak due to incapacitation or environmental\nconstraints. The solution incorporates voice, text, and priority inference\nmechanisms, allowing high priority emergency messages to bypass conventional\ncall waiting barriers. The approach employs models such as GPT Neo for\ngenerative text, which is synthesized into audio and delivered in configurable\nintervals G seconds and counts N times, ensuring minimal disruption while\npreserving urgency. This method holds potential for significant impact across\ntelecom, mobile device manufacturing, and emergency communication platforms.", "comment": "12 pages, 2 figures", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07526v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07541", "title": "Bit-level BPE: Below the byte boundary", "authors": ["Sangwhan Moon", "Tatsuya Hiraoka", "Naoaki Okazaki"], "summary": "Byte-level fallbacks for subword tokenization have become a common practice\nin large language models. In particular, it has been demonstrated to be\nincredibly effective as a pragmatic solution for preventing OOV, especially in\nthe context of larger models. However, breaking a character down to individual\nbytes significantly increases the sequence length for long-tail tokens in\nlanguages such as Chinese, Japanese, and Korean (CJK) and other\ncharacter-diverse contexts such as emoji. The increased sequence length results\nin longer computation during both training and inference. In this work, we\npropose a simple compression technique that reduces the sequence length\nlosslessly.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07541v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07547", "title": "From Rapid Release to Reinforced Elite: Citation Inequality Is Stronger in Preprints than Journals", "authors": ["Chiaki Miura", "Ichiro Sakata"], "summary": "Preprint has been considered to mainly supplement journal-based systems for\nthe rapid dissemination of relevant scientific knowledge, and has historically\nbeen by studies indicating that preprints and published reports have comparable\nauthorship, references, and quality.However, as preprint increasingly serve as\nan independent medium for scholarly communication rather than precursors to the\nversion of record, it remains uncertain how preprint usage is shaping\nscientific discourse.Our research revealed that the preprint citations exhibit\non average x times higher inequality than journal citations, consistently among\ncategories.This trend persisted even when controlling for the age, the mean\ncitation count, and the open access status of the journal matched to each of\nthe preprint categories.We also found that the citation inequality in preprints\nis not solely driven by a few highly cited papers or those with no impact, but\nrather reflects a broader systemic effect.Preprint that subsequently published\nunder journal and those not show no significant difference in citation\ninequality.Further analyses of the structural factors show that preferential\nattachment does not significantly contribute to citation inequality in\npreprints, whereas author prestige plays a substantial role.These results\ntogether suggest that researchers disproportionately rely on reputable peers in\nthe unvetted environment.This highlights a potential vulnerability in preprint\necosystems where reputation-driven citation may hinder scientific diversity.", "comment": null, "cate": "cs.DL", "url": "http://arxiv.org/abs/2506.07547v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07558", "title": "Immersive Visualization of Flat Surfaces Using Ray Marching", "authors": ["Fabian Lander", "Diaaeldin Taha"], "summary": "We present an effective method for visualizing flat surfaces using ray\nmarching. Our approach provides an intuitive way to explore translation\nsurfaces, mirror rooms, unfolded polyhedra, and translation prisms while\nmaintaining computational efficiency. We demonstrate the utility of the method\nthrough various examples and provide implementation insights for programmers.\nFinally, we discuss the use of our visualizations in outreach. We make our\nsimulations and code available online.", "comment": "Presented at Bridges Math and Art Conference, Eindhoven 2025. Online\n  demo and code available at\n  https://fabianlander.github.io/apps/raymarchingflatsurfacesapp/ and\n  https://github.com/FabianLander/RayMarchingFlatSurfaces", "cate": "cs.GR", "url": "http://arxiv.org/abs/2506.07558v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07571", "title": "An $O(n\\log n)$ Algorithm for Single-Source Shortest Paths in Disk Graphs", "authors": ["Mark de Berg", "Sergio Cabello"], "summary": "We prove that the single-source shortest-path problem on disk graphs can be\nsolved in $O(n\\log n)$ time, and that it can be solved on intersection graphs\nof fat triangles in $O(n\\log^2 n)$ time.", "comment": "19 pages, 8 figures", "cate": "cs.CG", "url": "http://arxiv.org/abs/2506.07571v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07597", "title": "Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque", "authors": ["Oscar Sainz", "Naiara Perez", "Julen Etxaniz", "Joseba Fernandez de Landa", "Itziar Aldabe", "Iker García-Ferrero", "Aimar Zabala", "Ekhi Azurmendi", "German Rigau", "Eneko Agirre", "Mikel Artetxe", "Aitor Soroa"], "summary": "Instructing language models with user intent requires large instruction\ndatasets, which are only available for a limited set of languages. In this\npaper, we explore alternatives to conventional instruction adaptation pipelines\nin low-resource scenarios. We assume a realistic scenario for low-resource\nlanguages, where only the following are available: corpora in the target\nlanguage, existing open-weight multilingual base and instructed backbone LLMs,\nand synthetically generated instructions sampled from the instructed backbone.\nWe present a comprehensive set of experiments for Basque that systematically\nstudy different combinations of these components evaluated on benchmarks and\nhuman preferences from 1,680 participants. Our conclusions show that target\nlanguage corpora are essential, with synthetic instructions yielding robust\nmodels, and, most importantly, that using as backbone an instruction-tuned\nmodel outperforms using a base non-instructed model, and improved results when\nscaling up. Using Llama 3.1 instruct 70B as backbone our model comes near\nfrontier models of much larger sizes for Basque, without using any Basque data\napart from the 1.2B word corpora. We release code, models, instruction\ndatasets, and human preferences to support full reproducibility in future\nresearch on low-resource language adaptation.", "comment": "Under review", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07597v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07604", "title": "IDENT Review: Recent Advances in Identification of Differential Equations from Noisy Data", "authors": ["Roy Y. He", "Hao Liu", "Wenjing Liao", "Sung Ha Kang"], "summary": "Differential equations and numerical methods are extensively used to model\nvarious real-world phenomena in science and engineering. With modern\ndevelopments, we aim to find the underlying differential equation from a single\nobservation of time-dependent data. If we assume that the differential equation\nis a linear combination of various linear and nonlinear differential terms,\nthen the identification problem can be formulated as solving a linear system.\nThe goal then reduces to finding the optimal coefficient vector that best\nrepresents the time derivative of the given data. We review some recent works\non the identification of differential equations. We find some common themes for\nthe improved accuracy: (i) The formulation of linear system with proper\ndenoising is important, (ii) how to utilize sparsity and model selection to\nfind the correct coefficient support needs careful attention, and (iii) there\nare ways to improve the coefficient recovery. We present an overview and\nanalysis of these approaches about some recent developments on the topic.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07604v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07617", "title": "Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation", "authors": ["Roman Kyslyi", "Yuliia Maksymiuk", "Ihor Pysmennyi"], "summary": "In this paper we introduce the first effort to adapt large language models\n(LLMs) to the Ukrainian dialect (in our case Hutsul), a low-resource and\nmorphologically complex dialect spoken in the Carpathian Highlands. We created\na parallel corpus of 9852 dialect-to-standard Ukrainian sentence pairs and a\ndictionary of 7320 dialectal word mappings. We also addressed data shortage by\nproposing an advanced Retrieval-Augmented Generation (RAG) pipeline to generate\nsynthetic parallel translation pairs, expanding the corpus with 52142 examples.\nWe have fine-tuned multiple open-source LLMs using LoRA and evaluated them on a\nstandard-to-dialect translation task, also comparing with few-shot GPT-4o\ntranslation. In the absence of human annotators, we adopt a multi-metric\nevaluation strategy combining BLEU, chrF++, TER, and LLM-based judgment\n(GPT-4o). The results show that even small(7B) finetuned models outperform\nzero-shot baselines such as GPT-4o across both automatic and LLM-evaluated\nmetrics. All data, models, and code are publicly released at:\nhttps://github.com/woters/vuyko-hutsul", "comment": "Preprint. Will be published at Proceedings of the Fourth Ukrainian\n  Natural Language Processing Workshop (UNLP)", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07617v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07626", "title": "Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation", "authors": ["Kseniia Petukhova", "Ekaterina Kochmar"], "summary": "Large language models (LLMs) hold great promise for educational applications,\nparticularly in intelligent tutoring systems. However, effective tutoring\nrequires alignment with pedagogical strategies - something current LLMs lack\nwithout task-specific adaptation. In this work, we explore whether fine-grained\nannotation of teacher intents can improve the quality of LLM-generated tutoring\nresponses. We focus on MathDial, a dialog dataset for math instruction, and\napply an automated annotation framework to re-annotate a portion of the dataset\nusing a detailed taxonomy of eleven pedagogical intents. We then fine-tune an\nLLM using these new annotations and compare its performance to models trained\non the original four-category taxonomy. Both automatic and qualitative\nevaluations show that the fine-grained model produces more pedagogically\naligned and effective responses. Our findings highlight the value of intent\nspecificity for controlled text generation in educational settings, and we\nrelease our annotated data and code to facilitate further research.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07626v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07635", "title": "Verification of Quantum Circuits through Barrier Certificates using a Scenario Approach", "authors": ["Siwei Hu", "Victor Lopata", "Sadegh Soudjani", "Paolo Zuliani"], "summary": "In recent years, various techniques have been explored for the verification\nof quantum circuits, including the use of barrier certificates, mathematical\ntools capable of demonstrating the correctness of such systems. These\ncertificates ensure that, starting from initial states and applying the\nsystem's dynamics, the system will never reach undesired states. In this paper,\nwe propose a methodology for synthesizing such certificates for quantum\ncircuits using a scenario-based approach, for both finite and infinite time\nhorizons. In addition, our approach can handle uncertainty in the initial\nstates and in the system's dynamics. We present several case studies on quantum\ncircuits, comparing the performance of different types of barrier certificate\nand analyzing which one is most suitable for each case.", "comment": null, "cate": "cs.LO", "url": "http://arxiv.org/abs/2506.07635v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07642", "title": "TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review", "authors": ["Yuan Chang", "Ziyue Li", "Hengyuan Zhang", "Yuanbo Kong", "Yanru Wu", "Zhijiang Guo", "Ngai Wong"], "summary": "While Large Language Models (LLMs) have shown significant potential in\nassisting peer review, current methods often struggle to generate thorough and\ninsightful reviews while maintaining efficiency. In this paper, we propose\nTreeReview, a novel framework that models paper review as a hierarchical and\nbidirectional question-answering process. TreeReview first constructs a tree of\nreview questions by recursively decomposing high-level questions into\nfine-grained sub-questions and then resolves the question tree by iteratively\naggregating answers from leaf to root to get the final review. Crucially, we\nincorporate a dynamic question expansion mechanism to enable deeper probing by\ngenerating follow-up questions when needed. We construct a benchmark derived\nfrom ICLR and NeurIPS venues to evaluate our method on full review generation\nand actionable feedback comments generation tasks. Experimental results of both\nLLM-based and human evaluation show that TreeReview outperforms strong\nbaselines in providing comprehensive, in-depth, and expert-aligned review\nfeedback, while reducing LLM token usage by up to 80% compared to\ncomputationally intensive approaches. Our code and benchmark dataset are\navailable at https://github.com/YuanChang98/tree-review.", "comment": "30 pages, 17 figures", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07642v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07645", "title": "Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models", "authors": ["Maciej Chrabąszcz", "Katarzyna Lorenc", "Karolina Seweryn"], "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\nvarious natural language processing (NLP) tasks in recent years. However, their\nsusceptibility to jailbreaks and perturbations necessitates additional\nevaluations. Many LLMs are multilingual, but safety-related training data\ncontains mainly high-resource languages like English. This can leave them\nvulnerable to perturbations in low-resource languages such as Polish. We show\nhow surprisingly strong attacks can be cheaply created by altering just a few\ncharacters and using a small proxy model for word importance calculation. We\nfind that these character and word-level attacks drastically alter the\npredictions of different LLMs, suggesting a potential vulnerability that can be\nused to circumvent their internal safety mechanisms. We validate our attack\nconstruction methodology on Polish, a low-resource language, and find potential\nvulnerabilities of LLMs in this language. Additionally, we show how it can be\nextended to other languages. We release the created datasets and code for\nfurther research.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07645v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07646", "title": "Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation", "authors": ["Rui Hu", "Xiaolong Lin", "Jiawang Liu", "Shixi Huang", "Zhenpeng Zhan"], "summary": "In this paper, we propose a method for annotating phonemic and prosodic\nlabels on a given audio-transcript pair, aimed at constructing Japanese\ntext-to-speech (TTS) datasets. Our approach involves fine-tuning a large-scale\npre-trained automatic speech recognition (ASR) model, conditioned on ground\ntruth transcripts, to simultaneously output phrase-level graphemes and\nannotation labels. To further correct errors in phonemic labeling, we employ a\ndecoding strategy that utilizes dictionary prior knowledge. The objective\nevaluation results demonstrate that our proposed method outperforms previous\napproaches relying solely on text or audio. The subjective evaluation results\nindicate that the naturalness of speech synthesized by the TTS model, trained\nwith labels annotated using our method, is comparable to that of a model\ntrained with manual annotations.", "comment": "Accepted to INTERSPEECH 2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07646v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07656", "title": "Data-Informed Mathematical Characterization of Absorption Properties in Artificial and Natural Porous Materials", "authors": ["Elishan C. Braun", "Gabriella Bretti", "Melania Di Fazio", "Laura Medeghini", "Mario Pezzella"], "summary": "In this work, we characterize the water absorption properties of selected\nporous materials through a combined approach that integrates laboratory\nexperiments and mathematical modeling. Specifically, experimental data from\nimbibition tests on marble, travertine, wackestone and mortar mock-ups are used\nto inform and validate the mathematical and simulation frameworks. First, a\nmonotonicity-preserving fitting procedure is developed to preprocess the\nmeasurements, aiming to reduce noise and mitigate instrumental errors. The\nimbibition process is then simulated through a partial differential equation\nmodel, with parameters calibrated against rough and smoothed data. The proposed\nprocedure appears particularly effective to characterize absorption properties\nof different materials and it represents a reliable tool for the study and\npreservation of cultural heritage.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07656v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07658", "title": "Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping", "authors": ["Nitin Sharma", "Thomas Wolfers", "Çağatay Yıldız"], "summary": "The paper addresses two critical challenges in language model (LM)\nevaluation: creating reliable domain-specific benchmarks and understanding\nknowledge representation during domain adaptation. We introduce a deterministic\npipeline that converts raw domain corpora into completion-type benchmarks\nwithout relying on LMs or human curation, eliminating benchmark contamination\nissues while enabling evaluation on the latest domain data. Our approach\ngenerates domain-specific keywords and related word lists using TF and Term\nTF-IDF methods and constructs prompt-target pairs. We evaluate models by\nmeasuring their ability to complete these prompts with the correct\ndomain-specific targets, providing a direct assessment of domain knowledge with\nlow computational cost. Through comprehensive experiments across multiple\nmodels (GPT-2 medium/XL, Llama-2/3.1, OLMo-2, Qwen-2, Mistral) and domains, we\ndemonstrate that our benchmark strongly correlates with expert-generated\nbenchmarks while providing a more accurate measure of domain knowledge than\ntraditional perplexity metrics. We reveal that domain adaptation happens\nrapidly in smaller models (within 500 steps) and illustrate a new approach to\ndomain knowledge evaluation in base models during training for early stopping.\nBy extending mechanistic analysis to domain adaptation, we discover that\ninitial-to-mid layers are primarily responsible for attribute extraction, while\nlater layers focus on next token prediction. Furthermore, we show that during\nadaptation, forgetting begins in the middle layers, where attribute extraction\nhappens and is amplified in later layers. Our work provides both a practical\nevaluation methodology for domain-specific LMs and novel insights into\nknowledge representation during adaptation, with implications for more\nefficient fine-tuning strategies and targeted approaches to mitigate\ncatastrophic forgetting.", "comment": "35 pages, 24 figures. First submission", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07658v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07668", "title": "On Deterministically Finding an Element of High Order Modulo a Composite", "authors": ["Ziv Oznovich", "Ben Lee Volk"], "summary": "We give a deterministic algorithm that, given a composite number $N$ and a\ntarget order $D \\ge N^{1/6}$, runs in time $D^{1/2+o(1)}$ and finds either an\nelement $a \\in \\mathbb{Z}_N^*$ of multiplicative order at least $D$, or a\nnontrivial factor of $N$. Our algorithm improves upon an algorithm of Hittmeir\n(arXiv:1608.08766), who designed a similar algorithm under the stronger\nassumption $D \\ge N^{2/5}$. Hittmeir's algorithm played a crucial role in the\nrecent breakthrough deterministic integer factorization algorithms of Hittmeir\nand Harvey (arXiv:2006.16729, arXiv:2010.05450, arXiv:2105.11105). When $N$ is\nassumed to have an $r$-power divisor with $r\\ge 2$, our algorithm provides the\nsame guarantees assuming $D \\ge N^{1/6r}$.", "comment": null, "cate": "cs.DS", "url": "http://arxiv.org/abs/2506.07668v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07675", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.", "comment": null, "cate": "cs.DB", "url": "http://arxiv.org/abs/2506.07675v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07707", "title": "Interaction Analysis by Humans and AI: A Comparative Perspective", "authors": ["Maryam Teimouri", "Filip Ginter", "Tomi \"bgt\" Suovuo"], "summary": "This paper explores how Mixed Reality (MR) and 2D video conferencing\ninfluence children's communication during a gesture-based guessing game.\nFinnish-speaking participants engaged in a short collaborative task using two\ndifferent setups: Microsoft HoloLens MR and Zoom. Audio-video recordings were\ntranscribed and analyzed using Large Language Models (LLMs), enabling iterative\ncorrection, translation, and annotation. Despite limitations in annotations'\naccuracy and agreement, automated approaches significantly reduced processing\ntime and allowed non-Finnish-speaking researchers to participate in data\nanalysis. Evaluations highlight both the efficiency and constraints of\nLLM-based analyses for capturing children's interactions across these\nplatforms. Initial findings indicate that MR fosters richer interaction,\nevidenced by higher emotional expression during annotation, and heightened\nengagement, while Zoom offers simplicity and accessibility. This study\nunderscores the potential of MR to enhance collaborative learning experiences\nfor children in distributed settings.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07707v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07710", "title": "A 40.68-MHz, 200-ns-Settling Active Rectifier and TX-Side Load Monitoring for Minimizing Radiated Power in Biomedical Implants", "authors": ["Ronald Wijermars", "Yi-Han Ou-Yang", "Sijun Du", "Dante Gabriel Muratore"], "summary": "This letter describes a 40.68 MHz wireless power transfer receiver for\nimplantable applications focused on minimizing tissue heating. The system\nfeatures a novel power radiated efficiency optimization strategy and a\nfast-settling active rectifier that maintains high efficiency during load and\nlink variations required for downlink communication. The power radiated\nefficiency optimization explicitly reduces tissue heating while enabling\ntransmitter-side load monitoring for closed-loop control. The active rectifier\nwas fabricated in 40nm CMOS and achieves a voltage conversion ratio of 93.9%\nand a simulated power conversion efficiency of 90.1% in a 0.19 $mm^2$ area,\nresulting in a 118 mW/$mm^2$ power density while integrating the resonance and\nfilter capacitors. The worst-case settling of the on- and off-delay\ncompensation in the active rectifier is 200 ns, which is the fastest reported\nto date.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07710v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07712", "title": "Through the Valley: Path to Effective Long CoT Training for Small Language Models", "authors": ["Renjie Luo", "Jiaxi Li", "Chen Huang", "Wei Lu"], "summary": "Long chain-of-thought (CoT) supervision has become a common strategy to\nenhance reasoning in language models. While effective for large models, we\nidentify a phenomenon we call Long CoT Degradation, in which small language\nmodels (SLMs; <=3B parameters) trained on limited long CoT data experience\nsignificant performance deterioration. Through extensive experiments on the\nQwen2.5, LLaMA3 and Gemma3 families, we demonstrate that this degradation is\nwidespread across SLMs. In some settings, models trained on only 8k long CoT\nexamples lose up to 75% of their original performance before fine-tuning.\nStrikingly, we further observe that for some particularly small models, even\ntraining on 220k long CoT examples fails to recover or surpass their original\nperformance prior to fine-tuning. Our analysis attributes this effect to error\naccumulation: while longer responses increase the capacity for multi-step\nreasoning, they also amplify the risk of compounding mistakes. Furthermore, we\nfind that Long CoT Degradation may negatively impacts downstream reinforcement\nlearning (RL), although this can be alleviated by sufficiently scaled\nsupervised fine-tuning (SFT). Our findings challenge common assumptions about\nthe benefits of long CoT training for SLMs and offer practical guidance for\nbuilding more effective small-scale reasoning models.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07712v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07719", "title": "Multilingual Grammatical Error Annotation: Combining Language-Agnostic Framework with Language-Specific Flexibility", "authors": ["Mengyang Qiu", "Tran Minh Nguyen", "Zihao Huang", "Zelong Li", "Yang Gu", "Qingyu Gao", "Siliang Liu", "Jungyeul Park"], "summary": "Grammatical Error Correction (GEC) relies on accurate error annotation and\nevaluation, yet existing frameworks, such as $\\texttt{errant}$, face\nlimitations when extended to typologically diverse languages. In this paper, we\nintroduce a standardized, modular framework for multilingual grammatical error\nannotation. Our approach combines a language-agnostic foundation with\nstructured language-specific extensions, enabling both consistency and\nflexibility across languages. We reimplement $\\texttt{errant}$ using\n$\\texttt{stanza}$ to support broader multilingual coverage, and demonstrate the\nframework's adaptability through applications to English, German, Czech,\nKorean, and Chinese, ranging from general-purpose annotation to more customized\nlinguistic refinements. This work supports scalable and interpretable GEC\nannotation across languages and promotes more consistent evaluation in\nmultilingual settings. The complete codebase and annotation tools can be\naccessed at https://github.com/open-writing-evaluation/jp_errant_bea.", "comment": "BEA2025", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07719v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07722", "title": "Towards a Unified Benchmark for Arabic Pronunciation Assessment: Quranic Recitation as Case Study", "authors": ["Yassine El Kheir", "Omnia Ibrahim", "Amit Meghanani", "Nada Almarwani", "Hawau Olamide Toyin", "Sadeen Alharbi", "Modar Alfadly", "Lamya Alkanhal", "Ibrahim Selim", "Shehab Elbatal", "Salima Mdhaffar", "Thomas Hain", "Yasser Hifny", "Mostafa Shahin", "Ahmed Ali"], "summary": "We present a unified benchmark for mispronunciation detection in Modern\nStandard Arabic (MSA) using Qur'anic recitation as a case study. Our approach\nlays the groundwork for advancing Arabic pronunciation assessment by providing\na comprehensive pipeline that spans data processing, the development of a\nspecialized phoneme set tailored to the nuances of MSA pronunciation, and the\ncreation of the first publicly available test set for this task, which we term\nas the Qur'anic Mispronunciation Benchmark (QuranMB.v1). Furthermore, we\nevaluate several baseline models to provide initial performance insights,\nthereby highlighting both the promise and the challenges inherent in assessing\nMSA pronunciation. By establishing this standardized framework, we aim to\nfoster further research and development in pronunciation assessment in Arabic\nlanguage technology and related applications.", "comment": "Accepted Interspeech 2025 and ArabicNLP Shared Task 2025", "cate": "cs.SD", "url": "http://arxiv.org/abs/2506.07722v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07726", "title": "Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU", "authors": ["Vincenzo Timmel", "Manfred Vogel", "Daniel Perruchoud", "Reza Kakooee"], "summary": "This paper presents a new long-form release of the Swiss Parliaments Corpus,\nconverting entire multi-hour Swiss German debate sessions (each aligned with\nthe official session protocols) into high-quality speech-text pairs. Our\npipeline starts by transcribing all session audio into Standard German using\nWhisper Large-v3 under high-compute settings. We then apply a two-step GPT-4o\ncorrection process: first, GPT-4o ingests the raw Whisper output alongside the\nofficial protocols to refine misrecognitions, mainly named entities. Second, a\nseparate GPT-4o pass evaluates each refined segment for semantic completeness.\nWe filter out any segments whose Predicted BLEU score (derived from Whisper's\naverage token log-probability) and GPT-4o evaluation score fall below a certain\nthreshold. The final corpus contains 801 hours of audio, of which 751 hours\npass our quality control. Compared to the original sentence-level SPC release,\nour long-form dataset achieves a 6-point BLEU improvement, demonstrating the\npower of combining robust ASR, LLM-based correction, and data-driven filtering\nfor low-resource, domain-specific speech corpora.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07726v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07729", "title": "Minimal Subsampled Rank-1 Lattices for Multivariate Approximation with Optimal Convergence Rate", "authors": ["Felix Bartel", "Alexander D. Gilbert", "Frances Y. Kuo", "Ian H. Sloan"], "summary": "In this paper we show error bounds for randomly subsampled rank-1 lattices.\nWe pay particular attention to the ratio of the size of the subset to the size\nof the initial lattice, which is decisive for the computational complexity. In\nthe special case of Korobov spaces, we achieve the optimal polynomial sampling\ncomplexity whilst having the smallest initial lattice possible. We further\ncharacterize the frequency index set for which a given lattice is\nreconstructing by using the reciprocal of the worst-case error achieved using\nthe lattice in question. This connects existing approaches used in proving\nerror bounds for lattices. We make detailed comments on the implementation and\ntest different algorithms using the subsampled lattice in numerical\nexperiments.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07729v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07748", "title": "Research quality evaluation by AI in the era of Large Language Models: Advantages, disadvantages, and systemic effects", "authors": ["Mike Thelwall"], "summary": "Artificial Intelligence (AI) technologies like ChatGPT now threaten\nbibliometrics as the primary generators of research quality indicators. They\nare already used in at least one research quality evaluation system and\nevidence suggests that they are used informally by many peer reviewers. Since\nusing bibliometrics to support research evaluation continues to be\ncontroversial, this article reviews the corresponding advantages and\ndisadvantages of AI-generated quality scores. From a technical perspective,\ngenerative AI based on Large Language Models (LLMs) equals or surpasses\nbibliometrics in most important dimensions, including accuracy (mostly higher\ncorrelations with human scores), and coverage (more fields, more recent years)\nand may reflect more research quality dimensions. Like bibliometrics, current\nLLMs do not \"measure\" research quality, however. On the clearly negative side,\nLLM biases are currently unknown for research evaluation, and LLM scores are\nless transparent than citation counts. From a systemic perspective, the key\nissue is how introducing LLM-based indicators into research evaluation will\nchange the behaviour of researchers. Whilst bibliometrics encourage some\nauthors to target journals with high impact factors or to try to write highly\ncited work, LLM-based indicators may push them towards writing misleading\nabstracts and overselling their work in the hope of impressing the AI.\nMoreover, if AI-generated journal indicators replace impact factors, then this\nwould encourage journals to allow authors to oversell their work in abstracts,\nthreatening the integrity of the academic record.", "comment": null, "cate": "cs.DL", "url": "http://arxiv.org/abs/2506.07748v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07771", "title": "Pinching-Antenna Systems For Indoor Immersive Communications: A 3D-Modeling Based Performance Analysis", "authors": ["Yulei Wang", "Yalin Liu", "Yaru Fu", "Zhiguo Ding"], "summary": "The emerging pinching antenna (PA) technology has high flexibility to\nreconfigure wireless channels and combat line-of-sight blockage, thus holding\ntransformative potential for indoor immersive applications in 6G. This paper\ninvestigates Pinching-antenna systems (PASS) for indoor immersive\ncommunications. Our contributions are threefold: (1) we construct a 3D model to\ncharacterize the distribution of users, waveguides, and PAs in the PASS; (2) we\ndevelop a general theoretical model on downlink performance of PASS by\ncapturing PA-user relationships and system parameters' impacts; and (3) we\nconduct comprehensive numerical results of the theoretical model and provide\nimplementation guidelines for PASS deployments.", "comment": null, "cate": "cs.PF", "url": "http://arxiv.org/abs/2506.07771v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07777", "title": "Supporting Aging Well through Accessible Digital Games: The Supplemental Role of AI in Game Design for Older Adults", "authors": ["Brandon Lyman", "Yichi Zhang", "Celia Pearce", "Miso Kim", "Casper Harteveld", "Leanne Chukoskie", "Bob De Schutter"], "summary": "As the population continues to age, and gaming continues to grow as a hobby\nfor older people, heterogeneity among older adult gamers is increasing. We\nargue that traditional game-based accessibility features, such as simplified\ninput schemes, redundant information channels, and increased legibility of\ndigital user interfaces, are increasingly limited in the face of this\nheterogeneity. This is because such features affect all older adult players\nsimultaneously and therefore are designed generically. We introduce artificial\nintelligence, although it has its own limitations and ethical concerns, as a\nmethod of creating player-based accessibility features, given the adaptive\nnature of the emerging technology. These accessibility features may help to\naddress unique assemblage of accessibility needs an individual may accumulate\nthrough age. We adopt insights from gerontology, HCI, and disability studies\ninto the digital game design discourse for older adults, and we contribute\ninsight that can guide the integration of player-based accessibility features\nto supplement game-based counterparts. The accessibility of digital games for\nheterogenous older adult audience is paramount, as the medium offers short-term\nsocial, emotional, psychological, cognitive, and physical that support the\nlong-term goal of aging well.", "comment": "21 pages, 1 figure", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07777v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07797", "title": "Lengthscale-informed sparse grids for kernel methods in high dimensions", "authors": ["Elliot J. Addy", "Jonas Latz", "Aretha L. Teckentrup"], "summary": "Kernel interpolation, especially in the context of Gaussian process\nemulation, is a widely used technique in surrogate modelling, where the goal is\nto cheaply approximate an input-output map using a limited number of function\nevaluations. However, in high-dimensional settings, such methods typically\nsuffer from the curse of dimensionality; the number of required evaluations to\nachieve a fixed approximation error grows exponentially with the input\ndimension. To overcome this, a common technique used in high-dimensional\napproximation methods, such as quasi-Monte Carlo and sparse grids, is to\nexploit functional anisotropy: the idea that some input dimensions are more\n'sensitive' than others. In doing so, such methods can significantly reduce the\ndimension dependence in the error. In this work, we propose a generalisation of\nsparse grid methods that incorporates a form of anisotropy encoded by the\nlengthscale parameter in Mat\\'ern kernels. We derive error bounds and perform\nnumerical experiments that show that our approach enables effective emulation\nover arbitrarily high dimensions for functions exhibiting sufficient\nanisotropy.", "comment": "43 pages, 7 figures", "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07797v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07802", "title": "On-The-Fly Symbolic Algorithm for Timed ATL with Abstractions", "authors": ["Nicolaj Ø. Jensen", "Kim G. Larsen", "Didier Lime", "Jiří Srba"], "summary": "Verification of real-time systems with multiple components controlled by\nmultiple parties is a challenging task due to its computational complexity. We\npresent an on-the-fly algorithm for verifying timed alternating-time temporal\nlogic (TATL), a branching-time logic with quantifiers over outcomes that\nresults from coalitions of players in such systems. We combine existing work on\ngames and timed CTL verification in the abstract dependency graph (ADG)\nframework, which allows for easy creation of on-the-fly algorithms that only\nexplore the state space as needed. In addition, we generalize the conventional\ninclusion check to the ADG framework which enables dynamic reductions of the\ndependency graph. Using the insights from the generalization, we present a\nnovel abstraction that eliminates the need for inclusion checking altogether in\nour domain. We implement our algorithms in Uppaal and our experiments show that\nwhile inclusion checking considerably enhances performance, our abstraction\nprovides even more significant improvements, almost two orders of magnitude\nfaster than the naive method. In addition, we outperform Uppaal Tiga, which can\nverify only a strict subset of TATL. After implementing our new abstraction in\nUppaal Tiga, we also improve its performance by almost an order of magnitude.", "comment": "Full version of paper published in CONCUR 2025", "cate": "cs.LO", "url": "http://arxiv.org/abs/2506.07802v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07818", "title": "WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code", "authors": ["Zhiyu Lin", "Zhengda Zhou", "Zhiyuan Zhao", "Tianrui Wan", "Yilun Ma", "Junyu Gao", "Xuelong Li"], "summary": "With the rapid advancement of Generative AI technology, Multimodal Large\nLanguage Models(MLLMs) have the potential to act as AI software engineers\ncapable of executing complex web application development. Considering that the\nmodel requires a confluence of multidimensional sub-capabilities to address the\nchallenges of various development phases, constructing a multi-view evaluation\nframework is crucial for accurately guiding the enhancement of development\nefficiency. However, existing benchmarks usually fail to provide an assessment\nof sub-capabilities and focus solely on webpage generation outcomes. In this\nwork, we draw inspiration from the principles of software engineering and\nfurther propose WebUIBench, a benchmark systematically designed to evaluate\nMLLMs in four key areas: WebUI Perception, HTML Programming,WebUI-HTML\nUnderstanding, and WebUI-to-Code. WebUIBench comprises 21K high-quality\nquestion-answer pairs derived from over 0.7K real-world websites. The extensive\nevaluation of 29 mainstream MLLMs uncovers the skill characteristics and\nvarious weakness that models encountered during the development process.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07818v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07830", "title": "Integrating Artificial Intelligence as Assistive Technology for Older Adult Gamers: A Pilot Study", "authors": ["Yichi Zhang", "Brandon Lyman", "Celia Pearce", "Miso Kim", "Casper Harteveld", "Leanne Chukoskie", "Bob De Schutter"], "summary": "With respect to digital games, older adults are a demographic that is often\nunderserved due to an industry-wide focus on younger audiences' preferences and\nskill sets. Meanwhile, as artificial intelligence (AI) continues to expand into\neveryday technologies, its assistive capabilities have been recognized,\nsuggesting its potential in improving the gaming experience for older gamers.\nTo study this potential, we iteratively developed a pilot survey aimed at\nunderstanding older adult gamers' current gameplay preference, challenges they\nare facing, and their perspectives of AI usage in gaming. This article\ncontributes an overview of our iterative survey-design workflow, and pilot\nresults from 39 participants. During each iteration, we analyzed the survey's\nefficacy and adjusted the content, language, and format to better capture\nmeaningful data, and was able to create a refined survey for a larger, more\nrepresentative future parent study. At the same time, preliminary findings\nsuggest that for older adult gamers, usability issues in gaming remain key\nobstacles, while this demographic's perceptions of AI are shaped by both its\npractical benefits and concerns about autonomy and complexity. These findings\nalso offer early insights for the design of age-inclusive, AI-supported gaming\nexperiences.", "comment": "9 pages, 1 figure", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07830v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07851", "title": "Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning", "authors": ["Yiju Guo", "Wenkai Yang", "Zexu Sun", "Ning Ding", "Zhiyuan Liu", "Yankai Lin"], "summary": "Large language models (LLMs) have demonstrated significant improvements in\ncontextual understanding. However, their ability to attend to truly critical\ninformation during long-context reasoning and generation still falls behind the\npace. Specifically, our preliminary experiments reveal that certain distracting\npatterns can misdirect the model's attention during inference, and removing\nthese patterns substantially improves reasoning accuracy and generation\nquality. We attribute this phenomenon to spurious correlations in the training\ndata, which obstruct the model's capacity to infer authentic causal\ninstruction-response relationships. This phenomenon may induce redundant\nreasoning processes, potentially resulting in significant inference overhead\nand, more critically, the generation of erroneous or suboptimal responses. To\nmitigate this, we introduce a two-stage framework called Learning to Focus\n(LeaF) leveraging intervention-based inference to disentangle confounding\nfactors. In the first stage, LeaF employs gradient-based comparisons with an\nadvanced teacher to automatically identify confounding tokens based on causal\nrelationships in the training corpus. Then, in the second stage, it prunes\nthese tokens during distillation to enact intervention, aligning the student's\nattention with the teacher's focus distribution on truly critical context\ntokens. Experimental results demonstrate that LeaF not only achieves an\nabsolute improvement in various mathematical reasoning and code generation\nbenchmarks but also effectively suppresses attention to confounding tokens\nduring inference, yielding a more interpretable and reliable reasoning model.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07851v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07877", "title": "A distributed motion planning approach to cooperative underwater acoustic source tracking and pursuit", "authors": ["Andrea Tiranti", "Francesco Wanderlingh", "Enrico Simetti", "Marco Baglietto", "Giovanni Indiveri", "Antonio Pascoal"], "summary": "This paper addresses the problem of underwater acoustic source tracking and\npursuit with a team of autonomous underwater vehicles. Producing distributed\ncontrol strategies in an underwater sensor network is not trivial since\ncommunication is primarily acoustic, which makes it intermittent and often\nplagued with major difficulties. For this reason, we propose an optimization\nscheme based on a Partially Observable Markov Decision Process for improving\nthe performance of underwater mobile sensor networks, in which autonomous\nunderwater vehicles (agents) play the role of moving nodes of a network. The\nkey idea is to adjust the agents' guidance strategies to achieve coordinated\nmotion planning, enabling optimal geometric configurations between the agents\nand the target to enhance tracking performance. Such a problem is cast as a\nmulti-objective optimization problem that is solved through a receding horizon\nlookahead optimization scheme since we are interested in long-term tracking\naccuracy. The planning strategy is distributed using the sequential multi-agent\ndecision-making paradigm to make the solving tractable since the optimization\ndepends on the joint action domain. A distributed control framework has been\nimplemented in a simulation environment to validate the proposed approach,\nwhich explicitly accounts for the major limitations imposed by acoustic\ncommunications.", "comment": null, "cate": "eess.SY", "url": "http://arxiv.org/abs/2506.07877v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07926", "title": "FractionalDiffEq.jl: High Performance Fractional Differential Equation Solver in Julia", "authors": ["Qingyu Qu", "Wei Ruan"], "summary": "We present FractionalDiffEq.jl, a comprehensive solver suite for solving\nfractional differential equations, featuring high-performance numerical\nalgorithms in the Julia programming language. FractionalDiffEq.jl is designed\nto be user-friendly and scalable, tackling different types of fractional\ndifferential equations, encompassing powerful numerical algorithms including\npredictor-corrector methods, product-integral methods, and linear multistep\nmethods, etc, and providing a unifying API to accommodate diverse solver\nfeatures. This paper illustrates the convenient usage of FractionalDiffEq.jl in\nmodeling various scientific problems, accompanied by detailed examples and\napplications. FractionalDiffEq.jl leverages best practices in Julia to ensure\nthe high performance of numerical solvers. To validate the efficiency of\nFractionalDiffEq.jl , we conducted extensive benchmarks that prove the\nsuperiority of FractionalDiffEq.jl against other implementations on both stiff\nand non-stiff problems. We further demonstrate its capability on several\nchallenging real-life scenarios including parameter estimation in\nfractional-order tequila fermentation processes, and harmonic oscillator\nproblems, etc, emphasizing the robustness and flexibility of\nFractionalDiffEq.jl.", "comment": null, "cate": "math.NA", "url": "http://arxiv.org/abs/2506.07926v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07930", "title": "Predicting Situation Awareness from Physiological Signals", "authors": ["Kieran J. Smith", "Tristan C. Endsley", "Torin K. Clark"], "summary": "Situation awareness (SA)--comprising the ability to 1) perceive critical\nelements in the environment, 2) comprehend their meanings, and 3) project their\nfuture states--is critical for human operator performance. Due to the\ndisruptive nature of gold-standard SA measures, researchers have sought\nphysiological indicators to provide real-time information about SA. We extend\nprior work by using a multimodal suite of neurophysiological,\npsychophysiological, and behavioral signals, predicting all three levels of SA\nalong a continuum, and predicting a comprehensive measure of SA in a complex\nmulti-tasking simulation. We present a lab study in which 31 participants\ncontrolled an aircraft simulator task battery while wearing physiological\nsensors and responding to SA 'freeze-probe' assessments. We demonstrate the\nvalidity of task and assessment for measuring SA. Multimodal physiological\nmodels predict SA with greater predictive performance ($Q^2$ for levels 1-3 and\ntotal, respectively: 0.14, 0.00, 0.26, and 0.36) than models built with\nshuffled labels, demonstrating that multimodal physiological signals provide\nuseful information in predicting all SA levels. Level 3 SA (projection) was\nbest predicted, and level 2 SA comprehension) was the most challenging to\npredict. Ablation analysis and single sensor models found EEG and eye-tracking\nsignals to be particularly useful to predictions of level 3 and total SA. A\nreduced sensor fusion model showed that predictive performance can be\nmaintained with a subset of sensors. This first rigorous cross-validation\nassessment of predictive performance demonstrates the utility of multimodal\nphysiological signals for inferring complex, holistic, objective measures of SA\nat all levels, non-disruptively, and along a continuum.", "comment": "15 pages, 6 figures, submitted to IEEE Transactions on Human-Machine\n  Systems", "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07930v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07937", "title": "Quantum Graph Transformer for NLP Sentiment Classification", "authors": ["Shamminuj Aktar", "Andreas Bärtschi", "Abdel-Hameed A. Badawy", "Stephan Eidenbenz"], "summary": "Quantum machine learning is a promising direction for building more efficient\nand expressive models, particularly in domains where understanding complex,\nstructured data is critical. We present the Quantum Graph Transformer (QGT), a\nhybrid graph-based architecture that integrates a quantum self-attention\nmechanism into the message-passing framework for structured language modeling.\nThe attention mechanism is implemented using parameterized quantum circuits\n(PQCs), which enable the model to capture rich contextual relationships while\nsignificantly reducing the number of trainable parameters compared to classical\nattention mechanisms. We evaluate QGT on five sentiment classification\nbenchmarks. Experimental results show that QGT consistently achieves higher or\ncomparable accuracy than existing quantum natural language processing (QNLP)\nmodels, including both attention-based and non-attention-based approaches. When\ncompared with an equivalent classical graph transformer, QGT yields an average\naccuracy improvement of 5.42% on real-world datasets and 4.76% on synthetic\ndatasets. Additionally, QGT demonstrates improved sample efficiency, requiring\nnearly 50% fewer labeled samples to reach comparable performance on the Yelp\ndataset. These results highlight the potential of graph-based QNLP techniques\nfor advancing efficient and scalable language understanding.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07937v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07947", "title": "Statistical Hypothesis Testing for Auditing Robustness in Language Models", "authors": ["Paulius Rauba", "Qiyao Wei", "Mihaela van der Schaar"], "summary": "Consider the problem of testing whether the outputs of a large language model\n(LLM) system change under an arbitrary intervention, such as an input\nperturbation or changing the model variant. We cannot simply compare two LLM\noutputs since they might differ due to the stochastic nature of the system, nor\ncan we compare the entire output distribution due to computational\nintractability. While existing methods for analyzing text-based outputs exist,\nthey focus on fundamentally different problems, such as measuring bias or\nfairness. To this end, we introduce distribution-based perturbation analysis, a\nframework that reformulates LLM perturbation analysis as a frequentist\nhypothesis testing problem. We construct empirical null and alternative output\ndistributions within a low-dimensional semantic similarity space via Monte\nCarlo sampling, enabling tractable inference without restrictive distributional\nassumptions. The framework is (i) model-agnostic, (ii) supports the evaluation\nof arbitrary input perturbations on any black-box LLM, (iii) yields\ninterpretable p-values; (iv) supports multiple perturbations via controlled\nerror rates; and (v) provides scalar effect sizes. We demonstrate the\nusefulness of the framework across multiple case studies, showing how we can\nquantify response changes, measure true/false positive rates, and evaluate\nalignment with reference models. Above all, we see this as a reliable\nfrequentist hypothesis testing framework for LLM auditing.", "comment": "arXiv admin note: substantial text overlap with arXiv:2412.00868", "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.07947v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07955", "title": "Implementation Considerations for Automated AI Grading of Student Work", "authors": ["Zewei", "Tian", "Alex Liu", "Lief Esbenshade", "Shawon Sarkar", "Zachary Zhang", "Kevin He", "Min Sun"], "summary": "This study explores the classroom implementation of an AI-powered grading\nplatform in K-12 settings through a co-design pilot with 19 teachers. We\ncombine platform usage logs, surveys, and qualitative interviews to examine how\nteachers use AI-generated rubrics and grading feedback. Findings reveal that\nwhile teachers valued the AI's rapid narrative feedback for formative purposes,\nthey distrusted automated scoring and emphasized the need for human oversight.\nStudents welcomed fast, revision-oriented feedback but remained skeptical of\nAI-only grading. We discuss implications for the design of trustworthy,\nteacher-centered AI assessment tools that enhance feedback while preserving\npedagogical agency.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07955v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07997", "title": "Supporting Construction Worker Well-Being with a Multi-Agent Conversational AI System", "authors": ["Fan Yang", "Yuan Tian", "Jiansong Zhang"], "summary": "The construction industry is characterized by both high physical and\npsychological risks, yet supports of mental health remain limited. While\nadvancements in artificial intelligence (AI), particularly large language\nmodels (LLMs), offer promising solutions, their potential in construction\nremains largely underexplored. To bridge this gap, we developed a\nconversational multi-agent system that addresses industry-specific challenges\nthrough an AI-driven approach integrated with domain knowledge. In parallel, it\nfulfills construction workers' basic psychological needs by enabling\ninteractions with multiple agents, each has a distinct persona. This approach\nensures that workers receive both practical problem-solving support and social\nengagement, ultimately contributing to their overall well-being. We evaluate\nits usability and effectiveness through a within-subjects user study with 12\nparticipants. The results show that our system significantly outperforms the\nsingle-agent baseline, achieving improvements of 18% in usability, 40% in\nself-determination, 60% in social presence, and 60% in trust. These findings\nhighlight the promise of LLM-driven AI systems in providing domain-specific\nsupport for construction workers.", "comment": null, "cate": "cs.HC", "url": "http://arxiv.org/abs/2506.07997v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.08007", "title": "Reinforcement Pre-Training", "authors": ["Qingxiu Dong", "Li Dong", "Yao Tang", "Tianzhu Ye", "Yutao Sun", "Zhifang Sui", "Furu Wei"], "summary": "In this work, we introduce Reinforcement Pre-Training (RPT) as a new scaling\nparadigm for large language models and reinforcement learning (RL).\nSpecifically, we reframe next-token prediction as a reasoning task trained\nusing RL, where it receives verifiable rewards for correctly predicting the\nnext token for a given context. RPT offers a scalable method to leverage vast\namounts of text data for general-purpose RL, rather than relying on\ndomain-specific annotated answers. By incentivizing the capability of\nnext-token reasoning, RPT significantly improves the language modeling accuracy\nof predicting the next tokens. Moreover, RPT provides a strong pre-trained\nfoundation for further reinforcement fine-tuning. The scaling curves show that\nincreased training compute consistently improves the next-token prediction\naccuracy. The results position RPT as an effective and promising scaling\nparadigm to advance language model pre-training.", "comment": null, "cate": "cs.CL", "url": "http://arxiv.org/abs/2506.08007v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06525", "title": "Experimental Performances of mmWave RIS-assisted 5G-Advanced Wireless Deployments in Urban Environments", "authors": ["Ahmet Faruk Coskun", "Alper Tolga Kocaoglu", "Emre Arslan", "Zehra Yigit", "Samed Kesir", "Batuhan Kaplan", "Jianwu Dou", "Yijun Cui"], "summary": "Reconfigurable intelligent surface (RIS) has emerged as a groundbreaking\ntechnology for 6G wireless communication networks, enabling cost-effective\ncontrol over wireless propagation environment. By dynamically manipulating its\ncodebook so as to deflect the direction of the reflected electromagnetic wave,\nRIS can achieve enhanced signal quality, extended coverage, and interference\nmitigation. This study presents experimental performance of ZTE Dynamic 2.0 RIS\nproducts through a series of real-world tests conducted on Turkcell's\nmillimeter-wave (mmWave) testbed. The evaluation involves network coverage\nextension in urban areas, multi-user efficiency, and the integration of virtual\nreality technology to support immersive applications in next-generation 6G\nnetworks. Through a comprehensive measurement-based analysis, the performance\nof the RIS product is demonstrated, highlighting its potential to address\ncritical challenges in mmWave communications and to enable advanced 6G use\ncases.", "comment": "6 pages, 8 figures, 3 tables", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06525v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06528", "title": "RIS Size Determination Across Frequencies and Deployment Scenarios: A Simulation-Based Study", "authors": ["Emre Arslan", "Ahmet Faruk Coskun"], "summary": "Despite the growing interest in the integration of reconfigurable intelligent\nsurfaces (RIS) into next-generation wireless communications systems, a critical\ngap remains in understanding what the dimensions of an RIS must be to provide\nmeaningful performance gains across realistic deployment scenarios. This paper\naddresses this challenge by presenting a practical and scenario-aware\nmethodology for determining optimal RIS dimensions, tailored to specific\nfrequency bands, environments, and use cases. Leveraging a realistic simulation\nmodel that incorporates angular scattering characteristics, practical network\nnode locations, and propagation constraints, we evaluate the RIS-assisted\nperformance in a diverse set of configurations. For selected use-cases, we\nquantify key performance indicators such as average signal-to-noise ratio and\noutage probability, and we demonstrate how RIS size impacts system reliability.\nOur findings show that RIS deployment effectiveness is highly sensitive to both\nphysical size and geometric placement, and that there is no one-size-fits-all\nsolution. The proposed framework, supported by detailed use case tables and\nvalidated through comprehensive simulations, offers design guidelines for\noperators and vendors seeking to deploy RIS in practical wireless network\nsettings.", "comment": "6 pages, 5 figures, 4 tables", "cate": "eess.SP", "url": "http://arxiv.org/abs/2506.06528v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06543", "title": "A Directional-ODE Framework for Discretization of Advection-Diffusion Equations", "authors": ["Amin Jafarimoghaddam", "Manuel Soler", "Irene Ortiz"], "summary": "We present a novel approach that redefines the traditional interpretation of\nexplicit and implicit discretization methods for solving a general class of\nadvection-diffusion equations (ADEs) featuring nonlinear advection, diffusion\noperators, and potential source terms. By reformulating the discrete ADEs as\ndirectional ordinary differential equations (ODEs) along temporal or spatial\ndimensions, we derive analytical solutions that lead to novel update formulas.\nIn essence, the information of discrete ADEs is compressed into these\ndirectional ODEs, which we refer to as representative ODEs. The analytical\nupdate formulas derived from the representative ODEs significantly enhance\nstability, computational efficiency, and spatiotemporal resolution.\nFurthermore, we extend the framework to systems with uncertain parameters and\ncoefficients, showcasing its versatility in addressing complex ADEs encountered\nin modeling and simulation across diverse scientific and engineering\ndisciplines.", "comment": null, "cate": "math.AP", "url": "http://arxiv.org/abs/2506.06543v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06675", "title": "Accurate analysis of the pitch pulse-based magnitude/phase structure of natural vowels and assessment of three lightweight time/frequency voicing restoration methods", "authors": ["Aníbal J. S. Ferreira", "Luis M. T. Jesus", "Laurentino M. M. Leal", "Jorge E. F. Spratley"], "summary": "Whispered speech is produced when the vocal folds are not used, either\nintentionally, or due to a temporary or permanent voice condition. The\nessential difference between natural speech and whispered speech is that\nperiodic signal components that exist in certain regions of the former, called\nvoiced regions, as a consequence of the vibration of the vocal folds, are\nmissing in the latter. The restoration of natural speech from whispered speech\nrequires delicate signal processing procedures that are especially useful if\nthey can be implemented on low-resourced portable devices, in real-time, and\non-the-fly, taking advantage of the established source-filter paradigm of voice\nproduction and related models. This paper addresses two challenges that are\nintertwined and are key in informing and making viable this envisioned\ntechnological realization. The first challenge involves characterizing and\nmodeling the evolution of the harmonic phase/magnitude structure of a sequence\nof individual pitch periods in a voiced region of natural speech comprising\nsustained or co-articulated vowels. This paper proposes a novel algorithm\nsegmenting individual pitch pulses, which is then used to obtain illustrative\nresults highlighting important differences between sustained and co-articulated\nvowels, and suggesting practical synthetic voicing approaches. The second\nchallenge involves model-based synthetic voicing. Three implementation\nalternatives are described that differ in their signal reconstruction\napproaches: frequency-domain, combined frequency and time-domain, and\nphysiologically-inspired separate filtering of glottal excitation pulses\nindividually generated. The three alternatives are compared objectively using\nillustrative examples, and subjectively using the results of listening tests\ninvolving synthetic voicing of sustained and co-articulated vowels in word\ncontext.", "comment": "58 pages, 17 figures, 8 tables", "cate": "eess.AS", "url": "http://arxiv.org/abs/2506.06675v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06790", "title": "Adam assisted Fully informed Particle Swarm Optimzation ( Adam-FIPSO ) based Parameter Prediction for the Quantum Approximate Optimization Algorithm (QAOA)", "authors": ["Shashank Sanjay Bhat", "Peiyong Wang", "Udaya Parampalli"], "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is a prominent\nvariational algorithm used for solving combinatorial optimization problems such\nas the Max-Cut problem. A key challenge in QAOA lies in efficiently identifying\nsuitable parameters (gamma, beta) that lead to high-quality solutions. In this\npaper, we propose a framework that combines Fully Informed Particle Swarm\nOptimization (FIPSO) with adaptive gradient correction using the Adam Optimizer\nto navigate the QAOA parameter space. This approach aims to avoid issues such\nas barren plateaus and convergence to local minima. The proposed algorithm is\nevaluated against two classes of graph instances, Erdos Renyi and\nWatts-Strogatz. Experimental results across multiple QAOA depths consistently\ndemonstrate superior performance compared to random initialization,\nunderscoring the effectiveness and robustness of the proposed optimization\nframework.", "comment": null, "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.06790v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.06835", "title": "Hadamard-$Π$: Equational Quantum Programming", "authors": ["Wang Fang", "Chris Heunen", "Robin Kaarsgaard"], "summary": "Quantum computing offers advantages over classical computation, yet the\nprecise features that set the two apart remain unclear. In the standard quantum\ncircuit model, adding a 1-qubit basis-changing gate -- commonly chosen to be\nthe Hadamard gate -- to a universal set of classical reversible gates yields\ncomputationally universal quantum computation. However, the computational\nbehaviours enabled by this addition are not fully characterised. We give such a\ncharacterisation by introducing a small quantum programming language extending\nthe universal classical reversible programming language $\\Pi$ with a single\nprimitive corresponding to the Hadamard gate. The language comes equipped with\na sound and complete categorical semantics that is specified by a purely\nequational theory, enabling reasoning about the equivalence of quantum programs\nin a way that can be automated. Completeness is shown by means of a novel\nfinite presentation, and corresponding synthesis algorithm, for the groups of\northogonal matrices with entries in the ring $\\mathbb{Z}[\\tfrac{1}{\\sqrt{2}}]$.", "comment": "116 pages", "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.06835v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07094", "title": "CIR bridge for modeling of fish migration on sub-hourly scale", "authors": ["Hidekazu Yoshioka"], "summary": "Bridges, which are stochastic processes with pinned initial and terminal\nconditions, have recently been applied to solve various problems. We show that\na bridge based on the Cox-Ingersoll-Ross process, called a CIR bridge in this\npaper, reasonably models the intraday number of migrating fish at an\nobservation point in a river. The studied fish migrates between sunrise and\nsunset each day, which are considered the initial and terminal times,\nrespectively. The CIR bridge is well-defined as a unique pathwise continuous\nsolution to a stochastic differential equation with unbounded drift and\ndiffusion coefficients and potentially represents the on-off intermittency of\nthe fish count data. Our bridge is theoretically novel in that it admits\nclosed-form time-dependent averages and variances, with which the model\nparameters can be identified efficiently, and is computable by a\nrecently-developed one-step numerical method. The CIR bridge is applied to the\nsub-hourly migration data of the diadromous fish Plecoglossus altivelis\naltivelis in the Nagara River, Japan, from February to June.", "comment": null, "cate": "math.PR", "url": "http://arxiv.org/abs/2506.07094v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07131", "title": "Meaning as Use, Application, Employment, Purpose, Usefulness", "authors": ["Ruy J. G. B. de Queiroz"], "summary": "Arising from the whole body of Wittgenstein's writings is a picture of a (not\nnecessarily straight, linear, but admittedly tireless) journey to come to terms\nwith the mechanics of language as an instrument to conceive `reality' and to\ncommunicate an acquired conception of the `world'. The journey passes through\nmathematics, psychology, color perception, certainty, aesthetic, but, looking\nat it from a sort of birdview, it seems reasonable to say that these are all\nused as `test beds' for his reflections and `experimentations' towards an all\nencompassing perspective of such a fundamental gateway to human reasoning and\nlife-revealing as language. Whatever labelling of Wittgenstein as a mystic, a\nlogicist, a conventionalist, a skeptic, an anti-metaphysics, an anti-realist, a\nverificationist, a pragmatist, and many others, does not seem to do justice to\nhis absolute obsession with being a persistent `deep diver' into the nature of\nlanguage. Working with an open and searchable account of the Nachlass has\nallowed us to identify important aspects of the philosopher's possible common\nline of thinking, in spite of changes of directions, some of them acknowledged\nby Wittgenstein himself. One of those aspects is the association of meaning\nwith use, application, purpose, usefulness of symbols in language, which\nhappens to show itself from the very beginning through to the very late\nwritings. The German terms Gebrauch, Anwendung, \\emph{Verwendung}, Zweck in\nrelation to meaning, sense of signs, words, sentences, appear in several texts\nsince the WW1 Notebooks (1914--1916) up until very late manuscripts from\n1950--51.", "comment": null, "cate": "math.HO", "url": "http://arxiv.org/abs/2506.07131v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07233", "title": "Reducing Object Hallucination in Large Audio-Language Models via Audio-Aware Decoding", "authors": ["Tzu-wen Hsu", "Ke-Han Lu", "Cheng-Han Chiang", "Hung-yi Lee"], "summary": "Large Audio-Language Models (LALMs) can take audio and text as the inputs and\nanswer questions about the audio. While prior LALMs have shown strong\nperformance on standard benchmarks, there has been alarming evidence that LALMs\ncan hallucinate what is presented in the audio. To mitigate the hallucination\nof LALMs, we introduce Audio-Aware Decoding (AAD), a lightweight inference-time\nstrategy that uses contrastive decoding to compare the token prediction logits\nwith and without the audio context. By contrastive decoding, AAD promotes the\ntokens whose probability increases when the audio is present. We conduct our\nexperiment on object hallucination datasets with three LALMs and show that AAD\nimproves the F1 score by 0.046 to 0.428. We also show that AAD can improve the\naccuracy on general audio QA datasets like Clotho-AQA by 5.4% to 10.3%. We\nconduct thorough ablation studies to understand the effectiveness of each\ncomponent in AAD.", "comment": null, "cate": "eess.AS", "url": "http://arxiv.org/abs/2506.07233v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07244", "title": "Quantum SAT Problems with Finite Sets of Projectors are Complete for a Plethora of Classes", "authors": ["Ricardo Rivera Cardoso", "Alex Meiburg", "Daniel Nagaj"], "summary": "Previously, all known variants of the Quantum Satisfiability (QSAT) problem,\ni.e. deciding whether a $k$-local ($k$-body) Hamiltonian is frustration-free,\ncould be classified as being either in $\\mathsf{P}$; or complete for\n$\\mathsf{NP}$, $\\mathsf{MA}$, or $\\mathsf{QMA_1}$. Here, we demonstrate new\nqubit variants of this problem that are complete for $\\mathsf{BQP_1}$,\n$\\mathsf{coRP}$, $\\mathsf{QCMA}$, $\\mathsf{PI(coRP,NP)}$,\n$\\mathsf{PI(BQP_1,NP)}$, $\\mathsf{PI(BQP_1,MA)}$, $\\mathsf{SoPU(coRP,NP)}$,\n$\\mathsf{SoPU(BQP_1,NP)}$, and $\\mathsf{SoPU(BQP_1,MA)}$. Our result implies\nthat a complete classification of quantum constraint satisfaction problems\n(QCSPs), analogous to Schaefer's dichotomy theorem for classical CSPs, must\neither include these 13 classes, or otherwise show that some are equal.\nAdditionally, our result showcases two new types of QSAT problems that can be\ndecided efficiently, as well as the first nontrivial $\\mathsf{BQP_1}$-complete\nproblem. We first prove there are qudit QSAT problems that are complete for\n$\\mathsf{BQP_1}$, $\\mathsf{coRP}$, and $\\mathsf{QCMA}$ by re-defining elements\nof the circuit-to-Hamiltonian transformation. We then show that any QCSP can be\nreduced to a problem in qubits while maintaining the same complexity -\nsomething believed not to be possible classically. The remaining six problems\nare obtained by considering \"sums\" and \"products\" of the first seven QSAT\nproblems. Before this work, the QSAT problems generated in this way resulted in\ncomplete problems for $\\mathsf{PI}$ and $\\mathsf{SoPU}$ classes that were\ntrivially equal to other known classes. We thus commence the study of these new\nand seemingly nontrivial classes. While [Meiburg, 2021] first sought to prove\ncompleteness for the first three classes, we note that his constructions are\nflawed. Here, we rework them and obtain improvements on the required qudit\ndimensionality.", "comment": "81 pages, 14 figures. To appear in TQC2025 proceedings", "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.07244v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07340", "title": "Stable Computation of Laplacian Eigenfunctions Corresponding to Clustered Eigenvalues", "authors": ["Ryoki Endo", "Xuefeng Liu"], "summary": "The accurate computation of eigenfunctions corresponding to tightly clustered\nLaplacian eigenvalues remains an extremely difficult problem. In this paper,\nusing the shape difference quotient of eigenvalues, we propose a stable\ncomputation method for the eigenfunctions of clustered eigenvalues caused by\ndomain perturbation.", "comment": null, "cate": "math.SP", "url": "http://arxiv.org/abs/2506.07340v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07515", "title": "Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition", "authors": ["Asahi Sakuma", "Hiroaki Sato", "Ryuga Sugano", "Tadashi Kumano", "Yoshihiko Kawai", "Tetsuji Ogawa"], "summary": "This paper presents a novel framework for multi-talker automatic speech\nrecognition without the need for auxiliary information. Serialized Output\nTraining (SOT), a widely used approach, suffers from recognition errors due to\nspeaker assignment failures. Although incorporating auxiliary information, such\nas token-level timestamps, can improve recognition accuracy, extracting such\ninformation from natural conversational speech remains challenging. To address\nthis limitation, we propose Speaker-Distinguishable CTC (SD-CTC), an extension\nof CTC that jointly assigns a token and its corresponding speaker label to each\nframe. We further integrate SD-CTC into the SOT framework, enabling the SOT\nmodel to learn speaker distinction using only overlapping speech and\ntranscriptions. Experimental comparisons show that multi-task learning with\nSD-CTC and SOT reduces the error rate of the SOT model by 26% and achieves\nperformance comparable to state-of-the-art methods relying on auxiliary\ninformation.", "comment": "Accepted at INTERSPEECH 2025", "cate": "eess.AS", "url": "http://arxiv.org/abs/2506.07515v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07552", "title": "Quantum Information-Theoretical Size Bounds for Conjunctive Queries with Functional Dependencies", "authors": ["Valter Uotila", "Jiaheng Lu"], "summary": "Deriving formulations for computing and estimating tight worst-case size\nincreases for conjunctive queries with various constraints has been at the core\nof theoretical database research. If the problem has no constraints or only one\nconstraint, such as functional dependencies or degree constraints, tight\nworst-case size bounds have been proven, and they are even practically\ncomputable. If the problem has more than one constraint, computing tight bounds\ncan be difficult in practice and may even require an infinite number of linear\ninequalities in its optimization formulation. While these challenges have been\naddressed with varying methods, no prior research has employed quantum\ninformation theory to address this problem. In this work, we establish a\nconnection between earlier work on estimating size bounds for conjunctive\nqueries with classical information theory and the field of quantum information\ntheory. We propose replacing the classical Shannon entropy formulation with the\nquantum R\\'enyi entropy. Whereas classical Shannon entropy requires infinitely\nmany inequalities to characterize the optimization space, R\\'enyi entropy\nrequires only one type of inequality, which is non-negativity. Although this is\na promising modification, optimization with respect to the quantum states\ninstead of classical distributions creates a new set of challenges that prevent\nus from finding a practically computable, tight worst-case size bound. In this\nline, we propose a quantum version to derive worst-case size bounds. The\nprevious tight classical worst-case size bound can be viewed as a special limit\nof this quantum bound. We also provide a comprehensive background on prior\nresearch and discuss the future possibilities of quantum information theory in\ntheoretical database research.", "comment": "13 pages, 3 figures", "cate": "quant-ph", "url": "http://arxiv.org/abs/2506.07552v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07625", "title": "Half-Iterates of $x(1+x)$, $\\sin(x)$ and $\\exp(x/e)$", "authors": ["Steven Finch"], "summary": "The title reflects the original intent of this paper -- to continue exploring\ncompositional square roots -- focusing on Walker's (1991) study of the Abel\nequation $f(\\exp(x/e))=f(x)+1$ for real $x \\neq e$. An unexpected discovery\nchanged everything. We already knew that \\'Ecalle (1974) developed theory\ninspiring relevant calculations across years. Precise details, however, seemed\nto escape attention until recently. Helpful online posts of Jagy (2012) are\nimportant not to overlook. The new algorithm is exceedingly simple and\noutperforms a rival method, due to Mavecha & Laohakosol (2013), which we\nmistakenly advocated until now. Our loyalty has correspondingly shifted.", "comment": "18 pages; 4 figures", "cate": "math.NT", "url": "http://arxiv.org/abs/2506.07625v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07634", "title": "SongBloom: Coherent Song Generation via Interleaved Autoregressive Sketching and Diffusion Refinement", "authors": ["Chenyu Yang", "Shuai Wang", "Hangting Chen", "Wei Tan", "Jianwei Yu", "Haizhou Li"], "summary": "Generating music with coherent structure, harmonious instrumental and vocal\nelements remains a significant challenge in song generation. Existing language\nmodels and diffusion-based methods often struggle to balance global coherence\nwith local fidelity, resulting in outputs that lack musicality or suffer from\nincoherent progression and mismatched lyrics. This paper introduces\n$\\textbf{SongBloom}$, a novel framework for full-length song generation that\nleverages an interleaved paradigm of autoregressive sketching and\ndiffusion-based refinement. SongBloom employs an autoregressive diffusion model\nthat combines the high fidelity of diffusion models with the scalability of\nlanguage models. Specifically, it gradually extends a musical sketch from short\nto long and refines the details from coarse to fine-grained. The interleaved\ngeneration paradigm effectively integrates prior semantic and acoustic context\nto guide the generation process. Experimental results demonstrate that\nSongBloom outperforms existing methods across both subjective and objective\nmetrics and achieves performance comparable to the state-of-the-art commercial\nmusic generation platforms. Audio samples are available on our demo page:\nhttps://cypress-yang.github.io/SongBloom\\_demo.", "comment": "Submitted to NeurIPS2025", "cate": "eess.AS", "url": "http://arxiv.org/abs/2506.07634v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07700", "title": "Refuting Perfect Matchings in Spectral Expanders is Hard", "authors": ["Ari Biswas", "Rajko Nenadov"], "summary": "This work studies the complexity of refuting the existence of a perfect\nmatching in spectral expanders with an odd number of vertices, in the\nPolynomial Calculus (PC) and Sum of Squares (SoS) proof system. Austrin and\nRisse [SODA, 2021] showed that refuting perfect matchings in sparse $d$-regular\n\\emph{random} graphs, in the above proof systems, with high probability\nrequires proofs with degree $\\Omega(n/\\log n)$. We extend their result by\nshowing the same lower bound holds for \\emph{all} $d$-regular graphs with a\nmild spectral gap.", "comment": null, "cate": "math.CO", "url": "http://arxiv.org/abs/2506.07700v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
{"id": "2506.07911", "title": "Stability and Extension of Steady and Ranging Persistence", "authors": ["Yann-Situ Gazull"], "summary": "Persistent homology is a topological data analysis tool that has been widely\ngeneralized, extending its scope outside the field of topology. Among its\nextensions, steady and ranging persistence was developed to study a wide\nvariety of graph properties. Precisely, given a feature of interest on graphs,\nit is possible to build two types of persistence (steady and ranging\npersistence) that follow the evolution of the feature along graph filtrations.\nThis study extends steady and ranging persistence to other objects using\ncategory theory and investigates the stability of such persistence. In\nparticular, a characterization of the features that induce balanced steady and\nranging persistence is provided. The main results of this study are illustrated\nusing a practical implementation for hypergraphs.", "comment": "20 pages + 11 pages Appendix, preprint", "cate": "math.AT", "url": "http://arxiv.org/abs/2506.07911v1", "AI": {"title_translation": "错误：AI分析失败。", "tldr": "错误：AI分析失败。", "motivation": "错误：AI分析失败。", "method": "错误：AI分析失败。", "result": "错误：AI分析失败。", "conclusion": "错误：AI分析失败。", "translation": "错误：AI分析失败。", "summary": "错误：AI分析失败。", "keywords": "错误：AI分析失败。", "comments": "错误：AI分析失败。"}}
