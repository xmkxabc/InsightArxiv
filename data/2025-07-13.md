# AI-Enhanced arXiv Daily 2025-07-13

<a id='toc'></a>
## 今日总计: 611 篇论文
### 目录
- [cs.CR](#cscr) (16 篇)
- [cs.AI](#csai) (33 篇)
- [cs.LG](#cslg) (104 篇)
- [cs.MA](#csma) (2 篇)
- [cs.RO](#csro) (26 篇)
- [cs.CV](#cscv) (118 篇)
- [cs.HC](#cshc) (16 篇)
- [cs.SE](#csse) (10 篇)
- [cs.SI](#cssi) (7 篇)
- [cs.NI](#csni) (10 篇)
- [cs.IT](#csit) (12 篇)
- [cs.AR](#csar) (3 篇)
- [cs.DC](#csdc) (6 篇)
- [cs.CY](#cscy) (7 篇)
- [cs.CE](#csce) (3 篇)
- [cs.FL](#csfl) (1 篇)
- [eess.SY](#eesssy) (12 篇)
- [eess.SP](#eesssp) (10 篇)
- [eess.IV](#eessiv) (9 篇)
- [eess.AS](#eessas) (2 篇)
- [cs.CL](#cscl) (82 篇)
- [cs.DS](#csds) (14 篇)
- [cs.GR](#csgr) (2 篇)
- [cs.IR](#csir) (8 篇)
- [cs.NE](#csne) (3 篇)
- [math.NA](#mathna) (11 篇)
- [cs.SD](#cssd) (14 篇)
- [cs.CC](#cscc) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [cond-mat.dis-nn](#cond-matdis-nn) (1 篇)
- [cs.MM](#csmm) (4 篇)
- [quant-ph](#quant-ph) (9 篇)
- [stat.ML](#statml) (17 篇)
- [physics.med-ph](#physicsmed-ph) (3 篇)
- [math.ST](#mathst) (1 篇)
- [cs.LO](#cslo) (1 篇)
- [cs.DB](#csdb) (3 篇)
- [q-fin.RM](#q-finrm) (1 篇)
- [q-bio.NC](#q-bionc) (2 篇)
- [cs.MS](#csms) (1 篇)
- [math.PR](#mathpr) (1 篇)
- [math.DS](#mathds) (2 篇)
- [math.CO](#mathco) (2 篇)
- [q-bio.BM](#q-biobm) (2 篇)
- [stat.ME](#statme) (2 篇)
- [math.OC](#mathoc) (5 篇)
- [math.NT](#mathnt) (1 篇)
- [q-fin.ST](#q-finst) (1 篇)
- [hep-ph](#hep-ph) (1 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [astro-ph.CO](#astro-phco) (1 篇)
- [cond-mat.stat-mech](#cond-matstat-mech) (1 篇)
- [cs.PL](#cspl) (2 篇)
- [econ.GN](#econgn) (1 篇)
- [stat.OT](#statot) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [193] [Beyond the Worst Case: Extending Differential Privacy Guarantees to Realistic Adversaries](https://arxiv.org/abs/2507.08158)
> *超越最坏情况：将差分隐私保证扩展到现实对手*

*Marika Swanberg, Meenatchi Sundaram Muthu Selva Annamalai, Jamie Hayes, Borja Balle, Adam Smith* | **Category: cs.CR** | **Updated: 2025-07-10**

**Keywords:** 差分隐私, 隐私泄露, 现实攻击, 高概率保证, 对抗模型

**Comment:** 

> **TL;DR:** 本文提出了一个灵活的框架，用于计算差分隐私（DP）机制在真实攻击场景下的高概率隐私保证，并发现隐私风险高度依赖于攻击者的先验成功概率。

**AI_Comments:** 本文的创新之处在于其提出的灵活框架，该框架超越了传统的差分隐私最坏情况分析，能够为更现实的攻击场景提供高概率的隐私保证。这对于理解和量化真实世界中的隐私风险至关重要，特别是考虑了攻击者先验知识和攻击目标的多样性。研究结果强调了攻击者先验成功概率在评估隐私风险中的关键作用，为未来的隐私保护设计提供了新的思考方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管差分隐私（DP）提供了最坏情况下的隐私泄露界限，但对抗模型与DP提供的隐私保护之间的分析权衡尚不清楚。本研究旨在阐明DP的最坏情况保证对更具代表性、更符合现实世界隐私风险的攻击者成功率的含义。

**Method:** 本文提出了一个单一的灵活框架，该框架概括并扩展了现有工作中DP机制的各种界限。该框架能够计算DP机制在大量自然攻击设置下的高概率保证，包括多个人数据近似重构。通过两个实证案例研究来展示其通用性，并与最先进的攻击进行比较。

**Result:** 研究发现，攻击非均匀数据的绝对隐私风险高度依赖于攻击者的先验成功概率。本文提出的高概率界限为DP机制在各种以前未充分研究的攻击设置中的隐私泄露提供了细致的理解。

**Conclusion:** 本文提出的灵活框架和高概率界限，使得我们能够更细致地理解差分隐私机制在现实世界攻击场景下的隐私泄露情况，超越了传统的最坏情况分析，并揭示了攻击者先验成功概率对隐私风险的关键影响。

> **ai_Abstract:** 本文提出了一种超越传统最坏情况分析的差分隐私（DP）新框架。该框架能够计算DP机制在更接近现实世界攻击场景下的高概率隐私保证，弥补了现有界限的不足。通过实证研究，文章揭示了攻击非均匀数据时的隐私风险与攻击者的先验成功概率密切相关，为理解DP机制在复杂攻击环境下的隐私泄露提供了更精细的视角。

> **摘要翻译:** 差分隐私（DP）是一系列定义，用于限制机制在最坏情况下的隐私泄露。最坏情况DP保证的一个重要特点是，它自然地意味着对拥有较少先验信息、更复杂攻击目标和复杂成功攻击衡量标准的对手提供保护。然而，对抗模型与DP赋予的隐私保护之间的分析权衡迄今尚未得到很好的理解。为此，这项工作阐明了DP的最坏情况保证对更具代表性的现实世界隐私风险攻击者成功率的含义。
在本文中，我们提出了一个单一的灵活框架，该框架概括并扩展了现有工作中DP机制的零散界限。我们的框架允许我们计算DP机制在大量自然攻击设置下的高概率保证，而这些设置是以前的界限无法捕获的。这类设置之一是多个人数据的近似重构，例如从噪声边际推断表格数据集的几乎整个列，以及从DP训练的语言模型中提取敏感信息。
我们进行了两个实证案例研究，以说明我们界限的通用性，并将其与最先进攻击的成功率进行比较。具体来说，我们研究了从DP训练的语言模型中提取非均匀PII的攻击，以及多列重构攻击，其中攻击者可以访问某些清晰的列，并尝试重构每个人的记录的其余列。我们发现攻击非均匀数据的绝对隐私风险高度依赖于攻击者的先验成功概率。我们的高概率界限使我们对DP机制在各种以前未充分研究的攻击设置中的隐私泄露有了细致的理解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [198] [GPUHammer: Rowhammer Attacks on GPU Memories are Practical](https://arxiv.org/abs/2507.08166)
> *GPUHammer：GPU内存上的Rowhammer攻击是可行的*

*Chris S. Lin, Joyce Qu, Gururaj Saileshwar* | **Category: cs.CR** | **Updated: 2025-07-10**

**Keywords:** GPUHammer, Rowhammer, GDDR6, GPU内存, 比特翻转, 机器学习攻击

**Comment:** 20 pages, including appendices. The paper will appear in SEC'25

> **TL;DR:** GPUHammer首次成功在NVIDIA GPU上实现了Rowhammer攻击，证明了GDDR内存的Rowhammer漏洞是可行的，并可用于篡改ML模型。

**AI_Comments:** 这篇论文的创新点在于首次成功地将Rowhammer攻击扩展到了GPU内存（GDDR6 DRAM），解决了此前在CPU上研究Rowhammer时未曾面对的独特挑战。其重要性在于揭示了GPU内存中存在的安全漏洞，这对于日益依赖GPU进行机器学习的应用来说尤其关键，因为攻击者可能通过篡改模型权重来影响AI系统的可靠性。论文还提供了具体的攻击方法和结果，具有很强的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Rowhammer是现代DRAM中的一种读取干扰漏洞，已被广泛研究于CPU的DDR和LPDDR内存，但其对使用GDDR内存的GPU（对新兴机器学习应用至关重要）的影响尚未被探索。对GPU进行Rowhammer攻击面临独特的挑战，包括专有内存映射、高内存延迟、更快的刷新率以及专有缓解措施，这促使了本研究的开展。

**Method:** 本研究引入了GPUHammer，这是第一个针对NVIDIA GDDR6 DRAM GPU的Rowhammer攻击。GPUHammer提出了新颖的技术来逆向工程GDDR DRAM的行映射，并采用了GPU特定的内存访问优化来增强攻击强度并绕过缓解措施。

**Result:** GPUHammer首次成功在分立GPU上演示了Rowhammer攻击，在NVIDIA A6000（GDDR6内存）上成功注入了多达8个比特翻转，跨越4个DRAM bank。研究还表明，攻击者可以利用这些比特翻转篡改机器学习模型，导致显著的准确性下降（高达80%）。

**Conclusion:** 本研究证明了Rowhammer攻击在GPU内存上是可行的，并且可以对机器学习模型造成实际威胁，揭示了GDDR内存的安全漏洞。

> **ai_Abstract:** 本研究介绍了GPUHammer，首次成功在NVIDIA GDDR6 GPU上实现了Rowhammer攻击。尽管GPU内存面临专有映射、高延迟和专有缓解等挑战，GPUHammer通过创新的逆向工程技术和GPU特有的内存访问优化，成功地在NVIDIA A6000上诱发了比特翻转。研究进一步展示了这些比特翻转可用于篡改机器学习模型，导致高达80%的准确性下降，强调了GPU内存中Rowhammer漏洞的实际可行性和潜在威胁。

> **摘要翻译:** Rowhammer是现代DRAM中的一种读取干扰漏洞，会导致比特翻转，从而损害安全性和可靠性。虽然在Intel和AMD CPU的DDR和LPDDR内存上已进行了广泛研究，但其对使用GDDR内存的GPU（对新兴机器学习应用至关重要）的影响仍未被探索。对GPU进行Rowhammer攻击面临独特的挑战：(1) 物理内存到GDDR bank和行的专有映射，(2) 阻碍有效攻击的高内存延迟和更快的刷新率，以及(3) GDDR内存中专有的缓解措施，在没有基于FPGA的测试平台的情况下难以逆向工程。我们引入了GPUHammer，这是第一个针对NVIDIA GDDR6 DRAM GPU的Rowhammer攻击。GPUHammer提出了新颖的技术来逆向工程GDDR DRAM行映射，并采用了GPU特定的内存访问优化来增强攻击强度并绕过缓解措施。因此，我们演示了第一个在分立GPU上的成功Rowhammer攻击，在NVIDIA A6000（GDDR6内存）上成功注入了多达8个比特翻转，跨越4个DRAM bank。我们还展示了攻击者如何利用这些比特翻转来篡改机器学习模型，导致显著的准确性下降（高达80%）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [206] [TruChain: A Multi-Layer Architecture for Trusted, Verifiable, and Immutable Open Banking Data](https://arxiv.org/abs/2507.08286)
> *TruChain：一种用于可信、可验证和不可变开放银行数据的多层架构*

*Aufa Nasywa Rahman, Bimo Sunarfri Hantono, Guntur Dharma Putra* | **Category: cs.CR, cs.ET** | **Updated: 2025-07-11**

**Keywords:** 开放银行, 区块链, 数据信任, 分布式账本, Tangle

**Comment:** 8 pages, 7 figures. Accepted to IEEE MetaCom 2025

> **TL;DR:** TruChain提出了一种多层架构，利用去中心化身份、密码签名和Tangle技术，为开放银行数据提供信任、可验证性和不可变性，解决了现有开放银行标准面临的数据信任和完整性问题，并展示了良好的性能和效率。

**AI_Comments:** 该论文提出了一种创新的多层架构，结合了去中心化身份、密码学和分布式账本技术（Tangle），以解决开放银行数据信任和完整性的核心问题。其创新点在于将不同信任机制分层集成，形成了一个全面的解决方案。重要性在于它为金融行业提供了一个更安全、更合规的数据共享框架，有助于推动开放银行的进一步发展。概念验证的性能数据也为其实用性提供了有力支持。

<details>
  <summary>Details</summary>

**Motivation:** 开放银行框架虽然促进了金融领域的创新，但现有的开放银行标准在数据源未经验证、数据完整性不一致以及缺乏不变性方面存在严重的技术风险。

**Method:** 本文提出了一种多层架构，提供三个不同信任级别的保证：源验证、数据级认证和防篡改存储。第一层使用去中心化身份和可验证凭证保证来源合法性；第二层使用密码签名验证数据真实性和一致性；第三层通过Tangle（一种有向无环图分布式账本）保证数据不变性。

**Result:** 概念验证实现显示，该系统性能可线性扩展，吞吐量稳定，验证率达到100%，CPU利用率低于35%，内存使用量低于350 MiB。与真实的开放银行实现相比，该解决方案显著降低了延迟并提供了更强的数据完整性保证。

**Conclusion:** TruChain为金融生态系统中的安全数据共享提供了一个实用且高效的系统，同时保持了监管合规性。

> **ai_Abstract:** 本文提出了一种名为TruChain的多层架构，旨在解决开放银行中数据信任、完整性和不变性不足的问题。该架构包含三层：第一层通过去中心化身份和可验证凭证确保数据源合法性；第二层利用密码签名验证数据真实性和一致性；第三层则使用Tangle分布式账本保证数据不可篡改性。概念验证结果表明，TruChain系统具有良好的可扩展性、稳定的性能、高验证率以及较低的资源消耗，并且相比现有开放银行方案能显著降低延迟并提供更强的数据完整性保证，为金融行业安全数据共享提供了高效实用的解决方案。

> **摘要翻译:** 开放银行框架使第三方提供商能够访问跨银行机构的金融数据，从而在金融领域带来了前所未有的创新。然而，一些开放银行标准仍然容易受到严重的技术风险，包括未经证实的数据源、不一致的数据完整性和缺乏不变性。在本文中，我们提出了一种分层架构，通过三个不同级别的信任来确保数据可信度，涵盖源验证、数据级认证和防篡改存储。第一层使用去中心化身份和可验证凭证来保证源的合法性，而第二层使用加密签名来验证数据的真实性和一致性。最后，第三层通过Tangle（一种有向无环图分布式账本）来保证数据的不变性。我们对该解决方案进行了概念验证实现，以评估其性能，结果表明该系统可以线性扩展并具有稳定的吞吐量，显示出100%的验证率，并利用了不到35%的CPU和350 MiB的内存。与真实的开放银行实现相比，我们的解决方案显著降低了延迟并提供了更强的数据完整性保证。总的来说，我们的解决方案为金融生态系统中的安全数据共享提供了一个实用且高效的系统，同时保持了监管合规性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [208] [Evaluating Post-Quantum Cryptographic Algorithms on Resource-Constrained Devices](https://arxiv.org/abs/2507.08312)
> *在资源受限设备上评估后量子密码算法*

*Jesus Lopez, Viviana Cadena, Mohammad Saidur Rahman* | **Category: cs.CR, cs.ET** | **Updated: 2025-07-11**

**Keywords:** 后量子密码, 物联网, 资源受限设备, 密钥交换, 性能评估

**Comment:** 8 pages, 4 figures, 4 tables. This paper is accepted at the IEEE
  Quantum Week 2025 -- IEEE International Conference on Quantum Computing and
  Engineering (QCE) 2025

> **TL;DR:** 本文研究了在资源受限的物联网设备上部署后量子密码（PQC）算法的可行性，实验证明其集成是可行的，强调了下一代物联网设备中对量子弹性密码框架的迫切需求。

**AI_Comments:** 本文解决了量子计算对传统密码学的潜在威胁，特别关注了资源受限的物联网环境。其创新之处在于在实际轻量级IoT平台上对多种PQC算法进行了具体的实现和性能评估，提供了实证数据，证明了PQC在当前硬件上的可行性。这对于推动PQC在实际应用中的部署具有重要意义，尤其是在物联网安全领域。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算的快速发展对RSA和ECC等经典密码算法构成了严重威胁，尤其是在需要安全通信但计算资源有限的物联网（IoT）设备中。因此，有必要研究在这些资源受限设备上部署后量子密码算法的可行性。

**Method:** 本文在基于Raspberry Pi设备的轻量级IoT平台上，实现了BIKE、CRYSTALS-Kyber和HQC三种PQC算法。结合Open Quantum Safe (liboqs) 库和mbedTLS，开发了量子安全密钥交换协议，并评估了其在计算开销、内存使用和能耗方面的性能。

**Result:** 实验结果表明，在受限硬件上集成PQC算法是可行的。

**Conclusion:** 在资源受限设备上集成后量子密码算法是可行的，这强化了下一代物联网设备中对量子弹性密码框架的迫切需求。

> **ai_Abstract:** 本研究旨在评估后量子密码（PQC）算法在资源受限物联网设备上的部署可行性。鉴于量子计算对现有密码学构成的威胁，作者在基于Raspberry Pi的IoT平台上实现了BIKE、CRYSTALS-Kyber和HQC三种PQC算法，并结合liboqs和mbedTLS库构建了量子安全密钥交换协议。通过评估计算开销、内存使用和能耗，实验证明PQC算法在受限硬件上的集成是可行的，从而强调了未来IoT设备中量子弹性密码框架的必要性。

> **摘要翻译:** 量子计算的快速发展对RSA和ECC等经典密码算法构成了严重威胁，尤其是在物联网（IoT）设备中，这些设备的安全通信至关重要，但往往受到有限计算资源的限制。本文研究了在资源受限设备上部署后量子密码（PQC）算法的可行性。特别是，我们在一个用Raspberry Pi设备构建的轻量级物联网平台上，实现了三种PQC算法——BIKE、CRYSTALS-Kyber和HQC。利用Open Quantum Safe (liboqs) 库结合mbedTLS，我们开发了量子安全密钥交换协议，并评估了它们在量子安全通信方面的计算开销、内存使用和能耗方面的性能。实验结果表明，在受限硬件上集成PQC算法是可行的，这强化了下一代物联网设备中对量子弹性密码框架的迫切需求。本文的实现可在https://iqsec-lab.github.io/PQC-IoT/获取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [216] [Invariant-based Robust Weights Watermark for Large Language Models](https://arxiv.org/abs/2507.08288)
> *基于不变量的LLMs鲁棒权重水印*

*Qingxiao Guo, Xinjie Zhu, Yilong Ma, Hui Jin, Yunhao Wang, Weifeng Zhang, Xiaobing Guo* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 大语言模型水印, 权重水印, 模型不变量, 鲁棒性, 知识产权保护

**Comment:** 

> **TL;DR:** 本文提出了一种基于不变量的鲁棒权重水印方案，用于保护部署在边缘设备上的大语言模型免受IP窃取，无需重新训练，并能抵抗多种攻击。

**AI_Comments:** 该论文的创新点在于提出了一个无需重新训练或微调的鲁棒权重水印方案，这对于LLMs的实际部署尤其重要，因为它大大降低了水印实施的成本和复杂性。利用模型不变量来生成水印值是一个新颖且有效的方法，同时考虑多用户场景下的共谋攻击也增加了其实用性。其在多种攻击下的强大鲁棒性表明了该技术的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着大语言模型（LLMs）在数十亿资源受限的边缘设备上的部署，知识产权（IP）盗窃的潜在威胁日益增加，因此需要鲁棒的水印技术来保护LLMs的IP。

**Method:** 该方案为每个用户生成一个唯一密钥，并通过求解由模型不变量构建的线性约束来导出稳定的水印值。此外，该技术利用噪声机制在多用户场景中隐藏水印位置，以对抗共谋攻击。该水印方案无需对Transformer模型进行重新训练或微调。

**Result:** 该方法在Llama3、Phi3和Gemma三种流行模型上进行了评估，实验结果证实了其在多种攻击方法（微调、剪枝、量化、置换、缩放、可逆矩阵和共谋攻击）下的强大鲁棒性。

**Conclusion:** 本文成功引入了一种基于不变量的鲁棒权重水印方案，能够有效保护大语言模型的知识产权，且无需重新训练或微调，并能抵抗多种复杂的攻击。

> **ai_Abstract:** 本文针对大语言模型（LLMs）在边缘设备部署中面临的IP盗窃风险，提出了一种基于模型不变量的鲁棒权重水印方案。该方案无需重新训练或微调，通过为每个用户生成唯一密钥并利用噪声机制对抗共谋攻击。实验在Llama3、Phi3、Gemma上验证了其对微调、剪枝、量化等多种攻击的强大鲁棒性，有效保护了LLMs的知识产权。

> **摘要翻译:** 水印技术因知识产权（IP）日益重要而受到广泛关注，特别是在大语言模型（LLMs）部署到数十亿资源受限的边缘设备上的背景下。为了应对恶意用户IP盗窃的潜在威胁，本文引入了一种无需重新训练或微调的Transformer模型鲁棒水印方案。该方案为每个用户生成一个唯一密钥，并通过求解由模型不变量构建的线性约束来导出稳定的水印值。此外，该技术利用噪声机制在多用户场景中隐藏水印位置，以对抗共谋攻击。本文在三种流行模型（Llama3、Phi3、Gemma）上评估了该方法，实验结果证实了其在多种攻击方法（微调、剪枝、量化、置换、缩放、可逆矩阵和共谋攻击）下的强大鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [218] [Qualcomm Trusted Application Emulation for Fuzzing Testing](https://arxiv.org/abs/2507.08331)
> *高通可信应用模拟用于模糊测试*

*Chun-I Fan, Li-En Chang, Cheng-Han Shie* | **Category: cs.CR** | **Updated: 2025-07-11**

**Keywords:** 高通TEE, 模糊测试, 可信应用, 模拟器, 逆向工程

**Comment:** This work is currently under review for presentation at the USENIX
  Security 2025 poster session

> **TL;DR:** 本研究引入了一种针对高通可信应用（TA）的新型轻量级模拟器，并结合模糊测试技术，有效识别了TA中的安全漏洞，首次提供了实现方法和源代码。

**AI_Comments:** 本文的创新之处在于首次提供了高通可信应用（TA）模拟器的实现方法和源代码，为该领域的后续研究奠定了基础。其重要性在于提供了一种轻量级且有效的TA安全测试工具，解决了现有全系统模拟方法复杂且资源密集的问题，显著提高了TA安全测试的便利性。

<details>
  <summary>Details</summary>

**Motivation:** 硬件设备和产品中的可信执行环境（TEE）组件存在漏洞，可能导致敏感数据泄露，损害用户隐私和安全。现有全系统模拟方法复杂且资源密集，不便于可信应用（TA）的安全测试。

**Method:** 本研究专注于高通TEE中的可信应用（TA），通过逆向工程技术分析高通TA，开发了一个部分模拟环境以准确模拟其行为。此外，将模糊测试技术集成到模拟器中，以系统地发现潜在漏洞。

**Result:** 该模拟器成功识别了高通TA中的真实安全缺陷，并证明了其在识别实际安全漏洞方面的实用有效性。该方法轻量且有效，使TA的安全测试更加便捷。

**Conclusion:** 本研究首次提供了高通TA模拟器的实现方法和源代码，为未来的研究提供了有价值的参考。与之前复杂且资源密集的全系统模拟方法不同，本方法轻量且有效，使TA的安全测试更加方便。

> **ai_Abstract:** 本文针对高通可信执行环境（TEE）中的可信应用（TA）安全问题，提出了一种新颖的TA模拟器。通过逆向工程分析高通TA并构建部分模拟环境，该模拟器集成了模糊测试技术，能有效发现TA中的安全漏洞。研究首次公开了高通TA模拟器的实现方法和源代码，提供了一种比传统全系统模拟更轻量、高效的TA安全测试方案。

> **摘要翻译:** 近年来，网络安全意识的提高使得人们对硬件设备和产品中的信息安全给予了高度关注。将可信执行环境（TEE）整合到产品设计中已成为保护敏感用户信息的标准做法。然而，这些组件中的漏洞会带来重大风险，如果被攻击者利用，这些漏洞可能导致敏感数据泄露，从而损害用户隐私和安全。本研究以高通TEE中的可信应用（TA）为中心，并引入了一种专门为这些应用设计的新型模拟器。通过逆向工程技术，我们彻底分析了高通TA，并开发了一个能够准确模拟其行为的部分模拟环境。此外，我们将模糊测试技术集成到模拟器中，以系统地发现高通TA中潜在的漏洞，证明了其在识别真实世界安全缺陷方面的实用有效性。本研究做出了重大贡献，首次提供了高通TA模拟器的实现方法和源代码，为未来的研究工作提供了有价值的参考。与以往依赖复杂且资源密集型全系统模拟的方法不同，我们的方法轻量且有效，使TA的安全测试更加便捷。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [222] [White-Basilisk: A Hybrid Model for Code Vulnerability Detection](https://arxiv.org/abs/2507.08540)
> *White-Basilisk：一种用于代码漏洞检测的混合模型*

*Ioannis Lamprou, Alexander Shevtsov, Ioannis Arapakis, Sotiris Ioannidis* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 代码漏洞检测, 混合模型, Mamba, 专家混合, 计算效率

**Comment:** 

> **TL;DR:** White-Basilisk是一个新的混合模型，通过集成Mamba层、线性自注意力及MoE框架，以2亿参数量在代码漏洞检测上达到SOTA，并能处理超长序列，挑战了AI模型规模越大越好的假设。

**AI_Comments:** 该论文的创新之处在于提出了White-Basilisk，一个结合了Mamba层、线性自注意力及MoE的混合模型，打破了AI模型越大越好的传统观念。其重要性在于以较小的参数量（2亿）实现了代码漏洞检测的SOTA性能，并能处理超长序列，显著提升了代码分析的深度和效率。这为资源受限或需要高效部署的场景提供了有价值的解决方案，并可能重新定义领域特定AI模型的优化策略。

<details>
  <summary>Details</summary>

**Motivation:** 软件漏洞的扩散对网络安全构成重大挑战，因此需要更有效的检测方法。

**Method:** 引入了White-Basilisk，一个新颖的漏洞检测方法。它采用创新架构，集成了Mamba层、线性自注意力以及专家混合（Mixture of Experts, MoE）框架。

**Result:** White-Basilisk在漏洞检测任务中取得了最先进的结果，参数量仅为2亿。它能够处理前所未有的超长序列，单次通过即可对大量代码库进行全面分析，超越了当前大型语言模型（LLMs）的上下文限制。该模型在不平衡的真实世界数据集上表现出强大的性能，同时保持了计算效率。

**Conclusion:** 这项研究不仅在代码安全领域建立了新基准，还提供了实证证据，表明紧凑、高效设计的模型在特定领域任务中可以超越大型模型，可能重新定义领域特定应用中AI开发的优化策略。

> **ai_Abstract:** White-Basilisk是一个新颖的混合模型，专为代码漏洞检测设计。它结合了Mamba层、线性自注意力及专家混合框架，以仅2亿参数量实现了代码漏洞检测的SOTA性能。该模型能处理超长代码序列，超越现有LLM的上下文限制，并在真实世界不平衡数据集上表现鲁棒且高效。研究表明，紧凑型模型在特定领域任务中可超越大型模型，为AI优化提供了新方向。

> **摘要翻译:** 软件漏洞的扩散对网络安全构成了重大挑战，因此需要更有效的检测方法。我们引入了White-Basilisk，一种新颖的漏洞检测方法，它在展示卓越性能的同时，挑战了人工智能模型规模扩展的普遍假设。White-Basilisk利用创新的架构，集成了Mamba层、线性自注意力以及专家混合（Mixture of Experts）框架，以仅2亿的参数量在漏洞检测任务中取得了最先进的结果。该模型处理前所未有长度序列的能力，使其能够单次通过对大量代码库进行全面分析，超越了当前大型语言模型（LLMs）的上下文限制。White-Basilisk在不平衡的真实世界数据集上表现出强大的性能，同时保持了计算效率，这有助于在不同组织规模下进行部署。这项研究不仅在代码安全领域建立了新基准，还提供了实证证据，表明紧凑、高效设计的模型在特定领域任务中可以超越大型模型，可能重新定义领域特定应用中AI开发的优化策略。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [268] [Minerva: A File-Based Ransomware Detector](https://arxiv.org/abs/2301.11050)
> *Minerva：一种基于文件的勒索软件检测器*

*Dorjan Hitaj, Giulio Pagnotta, Fabio De Gaspari, Lorenzo De Carli, Luigi V. Mancini* | **Category: cs.CR, cs.CY, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 勒索软件检测, 规避攻击, 文件分析, 网络安全, Minerva

**Comment:** Accepted for publication at The 20th ACM ASIA Conference on Computer
  and Communications Security (ACM ASIACCS 2025), Meli\'a Hanoi

> **TL;DR:** Minerva是一种新型的、基于文件的勒索软件检测器，旨在抵御规避攻击，并能快速准确地识别勒索软件，包括未知变种。

**AI_Comments:** Minerva的创新之处在于其“鲁棒性设计”，专门解决了现有行为检测器在面对规避攻击时的脆弱性。通过在架构和特征选择阶段就考虑对对抗性操纵的弹性，它提供了一个更可靠的解决方案。此外，其极快的检测速度（0.52秒内识别超过99%的勒索软件）是一个显著优势，使得在实际部署中实现近乎零开销的数据丢失防护成为可能，这对于快速响应和最小化损失至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 勒索软件攻击造成了数十亿美元的损失，并且现有基于行为的勒索软件检测方法容易受到规避攻击，导致全面的解决方案难以实现。因此，需要一种更鲁棒的勒索软件检测方法。

**Method:** 本文提出了Minerva，一种新颖且鲁棒的勒索软件检测方法。Minerva通过精心设计的架构和特征选择，使其天生具有抵御规避攻击的能力，以应对对抗性操纵。

**Result:** Minerva能够准确识别勒索软件，推广到未见过的威胁，并有效抵御规避攻击。此外，超过99%的被检测勒索软件在活动开始的0.52秒内被识别，从而能够以接近零的开销采用数据丢失防护技术。

**Conclusion:** Minerva是一种有效且鲁棒的勒索软件检测方法，能够快速识别勒索软件，包括未知变种和旨在规避的威胁，并有效抵御规避攻击，为数据丢失防护提供了可行方案。

> **ai_Abstract:** Minerva是一种创新的基于文件的勒索软件检测器，旨在克服现有行为检测方法易受规避攻击的弱点。通过其鲁棒性设计，Minerva能够准确、快速地识别各种勒索软件，包括未见过的变种和旨在规避检测的威胁，同时有效抵御对抗性操纵。其快速检测能力（99%在0.52秒内）使得低开销的数据丢失防护成为可能。

> **摘要翻译:** 勒索软件攻击近年来已造成数十亿美元的损失，预计未来还会造成更多损失。因此，人们对勒索软件的检测和缓解投入了大量精力。近年来，基于行为的勒索软件检测方法受到了广泛关注。这些行为检测器通常依赖于基于进程的行为配置文件来识别恶意行为。然而，越来越多的文献强调此类方法容易受到规避攻击，因此勒索软件问题的全面解决方案仍然难以捉摸。本文介绍了Minerva，一种新颖、鲁棒的勒索软件检测方法。Minerva通过架构和特征选择（这些选择的依据是它们对对抗性操纵的弹性）被设计为天生能够抵御规避攻击。我们对Minerva进行了全面分析，涵盖了各种勒索软件类型，包括未见过的勒索软件以及专门为规避Minerva而设计的变体。我们的评估展示了Minerva准确识别勒索软件、泛化到未见过的威胁以及抵御规避攻击的能力。此外，超过99%的被检测勒索软件在活动开始的0.52秒内被识别，从而能够以接近零的开销采用数据丢失防护技术。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [278] [BISON: Blind Identification with Stateless scOped pseudoNyms](https://arxiv.org/abs/2406.01518)
> *BISON：基于无状态范围化假名盲识别*

*Jakob Heher, Stefan More, Lena Heimberger* | **Category: cs.CR, D.4.6; C.2.2** | **Updated: 2025-07-11**

**Keywords:** 隐私保护, 盲识别, 假名, 身份认证, 用户追踪

**Comment:** Paper artifacts (Source code, Firefox extension, etc) available at
  https://github.com/iaik-jheher/BISON | Previous paper name: "BISON: Blind
  Identification through Stateless scOpe-specific derivatioN"

> **TL;DR:** BISON协议通过无状态范围化假名实现盲识别，保护用户隐私，防止跨站追踪，且高效实用。

**AI_Comments:** BISON的创新之处在于其假名派生协议，通过“盲识别”机制解决了身份提供商与服务提供商之间的信任问题，同时确保了假名的范围化和不可关联性，有效防止了用户追踪。其无需长期状态和轻量级密码学的特点使其具有很高的实用性和集成性，是隐私保护领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的身份认证委托（如Google或Facebook）会损害用户隐私，因为身份提供商可以记录用户行为并进行全网追踪。

**Method:** BISON提出一种受不经意伪随机函数启发的假名派生协议。它在不对身份提供商透露服务提供商身份的情况下，生成受信任、范围化、不可变的假名，从而防止串通的服务提供商进行用户追踪。BISON不需要用户设备上的长期状态，也不增加额外的认证参与者，并且仅使用轻量级密码学。

**Result:** BISON是实用的，易于理解、实现和推理，并且可以集成到现有协议中。它提供了一个OpenID Connect扩展，允许OIDC的PPID假名使用BISON派生，同时保持向后兼容。假名派生仅需四次椭圆曲线标量点乘和四次哈希函数评估，在概念验证实现中耗时约3毫秒。

**Conclusion:** BISON的隐私保护保证可以在实践中实现，使其成为未来隐私保护互联网的关键一步。

> **ai_Abstract:** BISON协议旨在解决现有委托身份验证（如Google/Facebook）带来的用户隐私泄露和全网追踪问题。它提出一种基于不经意伪随机函数的假名派生机制，能在不泄露服务提供商身份给身份提供商的情况下，生成受信任、范围化且不可关联的假名，从而有效防止用户追踪。BISON无需用户设备长期状态，不增加额外认证参与者，且通过轻量级密码学实现高效的假名派生（约3毫秒），并可与现有OpenID Connect等协议兼容，为构建保护隐私的互联网提供了实用方案。

> **摘要翻译:** 将身份验证委托给Google或Facebook等身份提供商虽然方便，但会损害用户隐私。这些身份提供商可以记录用户的每一个动作；它们提供的全局标识符也使得全网跟踪成为可能。
我们提出BISON假名派生协议，灵感来源于不经意伪随机函数，证明上述问题并非必要之恶。该协议对身份提供商隐藏服务提供商的身份，但能生成受信任、范围化、不可变的假名。相互串通的服务提供商无法关联BISON假名；这可以防止用户追踪。BISON不需要用户设备上的长期状态，也不会在身份验证过程中增加额外的参与者。
BISON是实用的。它易于理解、实现和推理，并且旨在集成到现有的身份验证协议中。为了证明这一点，我们提供了一个OpenID Connect扩展，允许OIDC的PPID假名使用BISON派生，同时保持完全向后兼容。此外，BISON仅使用轻量级密码学。假名派生总共需要四次椭圆曲线标量点乘法和四次哈希函数评估，在我们的概念验证实现中大约需要3毫秒。因此，BISON的隐私保证可以在实践中实现。这使得BISON成为未来隐私保护互联网的关键一步。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [293] [New constructions of pseudorandom codes](https://arxiv.org/abs/2409.07580)
> *伪随机码的新构造*

*Surendra Ghentiyala, Venkatesan Guruswami* | **Category: cs.CR, cs.CC** | **Updated: 2025-07-11**

**Keywords:** 伪随机码, 纠错码, 密码学, Planted Hyperloop假设, 空间受限对手

**Comment:** 39 pages, 1 figure

> **TL;DR:** 本文提出了伪随机纠错码（PRCs）的新构造，证明了在特定假设下公钥PRCs的存在性，扩展了现有构造的假设基础，并首次研究了针对空间受限对手的PRCs。

**AI_Comments:** 本文在伪随机码这一新兴密码学原语领域做出了重要贡献。其创新点在于：1. 首次在特定计算复杂性假设下证明了公钥PRCs的存在性，为PRCs的理论基础提供了支持。2. 通过引入“弱Planted XOR假设”并扩展现有构造的适用范围，展示了对现有工作的深入理解和推广能力。3. 开创性地将PRCs的安全性研究扩展到空间受限对手，为未来研究提供了新的方向，这在资源受限环境中可能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 伪随机纠错码（PRCs）是一种新的密码学原语，在生成式AI模型水印等领域有应用前景。本工作旨在研究在何种假设下，具有恒定错误率鲁棒性的PRCs能够存在。

**Method:** 1. 证明在Planted Hyperloop假设和Goldreich PRG的安全性假设下，公钥PRCs的存在性。2. 重新审视[CG24]的构造，并通过引入弱化版的Planted XOR假设（弱Planted XOR假设），证明其可基于更广泛的假设。3. 首次研究针对空间受限对手的PRCs，并展示如何构造对多项式时间、O(n^1.5-ε)空间对手无条件不可区分的秘密密钥PRCs。

**Result:** 1. 在Planted Hyperloop假设和Goldreich PRG的安全性假设下，存在公钥PRCs，高效对手无法以优于o(1)的优势将多项式数量的码字与随机码字区分开。2. [CG24]的PRC构造可以基于比原论文更广泛的假设，通过引入弱Planted XOR假设实现。3. 构造了长度为O(n)的秘密密钥PRCs，对多项式时间、O(n^1.5-ε)空间对手是无条件不可区分的。

**Conclusion:** 本文通过引入新的假设（如弱Planted XOR假设）和重新审视现有构造，扩展了伪随机码的理论基础和实际应用范围，并首次探讨了其在空间受限对抗环境下的安全性。

> **ai_Abstract:** 本文研究了伪随机纠错码（PRCs）的构造及其安全性假设。作者证明了在Planted Hyperloop假设和Goldreich PRG安全性下公钥PRCs的存在性，扩展了现有PRC构造的假设基础，并通过引入弱Planted XOR假设，使其适用于更广泛的场景。此外，本文首次探讨了针对空间受限对手的PRCs安全性，并给出了具体构造，实现了对特定空间复杂度对手的无条件不可区分性。

> **摘要翻译:** 伪随机纠错码（PRCs）在[CG24]中被引入，它是一种新的密码学原语，在生成式AI模型水印中有应用。这些码的特点是，对于没有秘密密钥的对手来说，多项式数量的码字集合在计算上与随机码字不可区分，但拥有秘密密钥的任何人都能高效地解码被破坏的码字。在这项工作中，我们研究了在何种假设下，具有恒定错误率鲁棒性的PRCs存在。
1.  我们表明，如果[BKR23]中引入的Planted Hyperloop假设和Goldreich PRG某个版本的安全性都成立，那么存在公钥PRCs，对于任何高效对手，其区分多项式数量的码字与随机码字的优势不会优于o(1)。
2.  我们重新审视了[CG24]的构造，并表明它可以基于比[CG24]中提出的更广泛的假设。为此，我们引入了Planted XOR假设的一个弱化版本，我们称之为弱Planted XOR假设，它可能具有独立的兴趣。
3.  我们首次研究了针对空间受限对手安全的PRCs。我们展示了如何构造长度为O(n)的秘密密钥PRCs，这些PRCs对于多项式时间、O(n^1.5-ε)空间对手是无条件不可区分的。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [313] [Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025](https://arxiv.org/abs/2506.12430)
> *突破安全的极限：关于 ATLAS 挑战赛 2025 的技术报告*

*Zonghao Ying, Siyang Wu, Run Hao, Peng Ying, Shixuan Sun, Pengyu Chen, Junze Chen, Hao Du, Kaiwen Shen, Shangkun Wu, Jiwei Wei, Shiyuan He, Yang Yang, Xiaohai Xu, Ke Ma, Qianqian Xu, Qingming Huang, Shi Lin, Xun Wang, Changting Lin, Meng Han, Yilei Jiang, Siqi Lai, Yaozhi Zheng, Yifei Song, Xiangyu Yue, Zonglei Jing, Tianyuan Zhang, Zhilei Zhu, Aishan Liu, Jiakai Wang, Siyuan Liang, Xianglong Kong, Hainan Li, Junjie Mu, Haotong Qin, Yue Yu, Lei Chen, Felix Juefei-Xu, Qing Guo, Xinyun Chen, Yew Soon Ong, Xianglong Liu, Dawn Song, Alan Yuille, Philip Torr, Dacheng Tao* | **Category: cs.CR, cs.CV** | **Updated: 2025-07-11**

**Keywords:** MLLMs, 安全性, 对抗性测试, 漏洞, ATLAS 挑战赛

**Comment:** AdvML@CVPR Challenge Report

> **TL;DR:** ATLAS 挑战赛 2025 的技术报告，评估了多模态大语言模型（MLLMs）在对抗性攻击下的安全性。

**AI_Comments:** 这是一份关于一次重要安全挑战赛的技术报告，通过大规模竞赛的形式对 MLLM 的安全漏洞进行了实证评估。公开的代码和数据有助于社区进一步研究。报告侧重于呈现竞赛结果和挑战，而非提出新的防御方法本身。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）虽然取得了巨大进展，但仍然容易受到安全威胁，特别是导致有害输出的越狱攻击。为了系统地评估和改进其安全性，组织了 ATLAS 挑战赛 2025。

**Method:** 组织了对抗性测试和大型模型对齐安全挑战赛（ATLAS）2025。86支队伍通过对抗性图像-文本攻击，分白盒和黑盒两个阶段测试了 MLLMs 的漏洞。本技术报告展示了竞赛结果。

**Result:** 竞赛结果突显了保护 MLLMs 的持续挑战，并为开发更强大的防御机制提供了宝贵指导。

**Conclusion:** 该挑战赛为 MLLM 安全评估建立了新的基准，并为推进更安全的多模态人工智能系统奠定了基础。

> **ai_Abstract:** 本技术报告介绍了 ATLAS 挑战赛 2025 的发现，该挑战赛旨在通过白盒和黑盒对抗性图像-文本攻击系统地评估多模态大语言模型（MLLMs）的安全性。竞赛吸引了 86 支队伍，揭示了当前 MLLM 安全面临的挑战，并为加强防御提供了见解。该挑战赛为 MLLM 安全评估设定了新基准，并推动了更安全的模态 AI 发展。

> **摘要翻译:** 多模态大语言模型（MLLMs）在各种应用中实现了变革性进展，但仍然容易受到安全威胁，特别是导致有害输出的越狱攻击。为了系统地评估和改进其安全性，我们组织了对抗性测试和大型模型对齐安全挑战赛（ATLAS）2025。本技术报告展示了竞赛结果，该竞赛涉及 86 支队伍通过对抗性图像-文本攻击，分白盒和黑盒两个阶段测试了 MLLM 的漏洞。竞赛结果突显了保护 MLLMs 的持续挑战，并为开发更强大的防御机制提供了宝贵指导。该挑战赛为 MLLM 安全评估建立了新的基准，并为推进更安全的多模态人工智能系统奠定了基础。该挑战赛的代码和数据在 https://github.com/NY1024/ATLAS_Challenge_2025 公开可用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [333] [AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions](https://arxiv.org/abs/2506.14697)
> *AGENTSAFE：具身智能体在危险指令下的安全性基准测试*

*Aishan Liu, Zonghao Ying, Le Wang, Junjie Mu, Jinyang Guo, Jiakai Wang, Yuqing Ma, Siyuan Liang, Mingchuan Zhang, Xianglong Liu, Dacheng Tao* | **Category: cs.CR, cs.RO** | **Updated: 2025-07-11**

**Keywords:** 具身智能体, 安全性, 基准测试, 危险指令, 视觉-语言模型

**Comment:** MAS@ICML 2025 camera ready

> **TL;DR:** AGENTSAFE是一个用于评估具身VLM智能体在危险指令下安全性的综合基准测试平台。

**AI_Comments:** AGENTSAFE的创新之处在于它是首个专门针对具身VLM智能体在危险指令下进行安全性评估的综合基准，填补了该领域的空白。其引入的适配器模块有效连接了高层VLM输出与低层具身控制，以及构建了基于阿西莫夫三定律的风险感知数据集，都增强了测试的全面性和现实性。这对于推动具身智能体的安全部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着视觉-语言模型（VLMs）与具身智能体的结合，这些系统在现实世界部署时面临日益增长的安全问题，特别是在响应危险指令时。目前缺乏一个全面的基准来评估具身VLM智能体在危险指令下的安全性。

**Method:** 本文提出了AGENTSAFE，第一个用于评估具身VLM智能体在危险指令下安全性的综合基准。AGENTSAFE在一个模拟沙盒中模拟真实的智能体-环境交互，并包含一个新颖的适配器模块，该模块弥合了高层VLM输出与低层具身控制之间的差距，将视觉实体映射到可操作对象，并将抽象规划转化为可执行的原子动作。此外，构建了一个受阿西莫夫机器人三定律启发的风险感知指令数据集，包括基础危险指令和变异越狱指令。

**Result:** AGENTSAFE基准包括45个对抗场景、1,350个危险任务和8,100个危险指令，能够实现在感知、规划和行动执行阶段的对抗条件下的系统测试。

**Conclusion:** 本文提出了AGENTSAFE，一个全面的基准测试平台，旨在系统评估具身视觉-语言模型智能体在危险指令下的安全性，填补了该领域缺乏此类测试平台的空白。

> **ai_Abstract:** 本文提出了AGENTSAFE，一个针对具身视觉-语言模型（VLM）智能体在危险指令下安全性的首个综合基准测试平台。AGENTSAFE通过模拟沙盒实现真实交互，并引入适配器模块连接VLM输出与具身控制。它构建了一个包含基础及越狱指令的风险感知数据集，并包含45个对抗场景、1350个危险任务和8100个危险指令，旨在系统评估智能体在感知、规划和行动执行各阶段的安全表现。

> **摘要翻译:** 视觉-语言模型（VLMs）的快速发展及其与具身智能体的整合，为决策带来了强大的能力。然而，随着这些系统越来越多地部署在现实世界环境中，它们面临着日益增长的安全问题，特别是在响应危险指令时。在这项工作中，我们提出了AGENTSAFE，这是第一个用于评估具身VLM智能体在危险指令下安全性的综合基准测试。AGENTSAFE在一个模拟沙盒中模拟真实的智能体-环境交互，并包含一个新颖的适配器模块，该模块弥合了高层VLM输出与低层具身控制之间的差距。具体而言，它将识别出的视觉实体映射到可操作对象，并将抽象规划转化为环境中可执行的原子动作。在此基础上，我们构建了一个受阿西莫夫机器人三定律启发的风险感知指令数据集，包括基础危险指令和变异越狱指令。该基准包括45个对抗场景、1,350个危险任务和8,100个危险指令，从而能够在感知、规划和行动执行阶段的对抗条件下进行系统测试。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [353] [LINE: Public-key encryption](https://arxiv.org/abs/2507.04501)
> *LINE：公钥加密*

*Gennady Khalimov, Yevgen Kotukh* | **Category: cs.CR, cs.IT, math.IT** | **Updated: 2025-07-10**

**Keywords:** 公钥加密, 线性方程组, 同态变换, 密码系统, 矩阵计算

**Comment:** 

> **TL;DR:** 提出了一种基于线性方程组解和同态矩阵变换的公钥加密系统，具有高安全性和低计算开销。

**AI_Comments:** 该论文提出了一种新颖的公钥加密方法，其创新点在于将线性方程组的解与同态矩阵变换结合，利用欠定方程组的多解性来增强安全性。文章声称通过矩阵计算可以实现高安全性和低计算开销，这对于实际应用具有潜在的重要性。然而，摘要中未提供具体性能数据或安全性证明的细节，需要进一步研究来验证其声称的优势。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** 该密码系统基于线性方程组的解，通过共享秘密计算预定义输入参数，实现可分解替换。利用欠定线性方程组存在多个等效解的特性，使密码分析者无法在多项式时间内求解。输入参数的补全通过在F2域上m维向量空间基底上分解的替换的秘密同态矩阵变换实现。加密通过计算在2^m阶初等阿贝尔2-群上作为单向函数的替换来实现。解密通过补全方程组的输入参数实现。同态变换基于矩阵计算构建。

**Result:** 矩阵计算使得同态变换能够实现高安全性和低计算开销。

**Conclusion:** 该文提出的基于线性方程组和同态矩阵变换的公钥加密系统，通过矩阵计算实现了高安全性和低计算开销。

> **ai_Abstract:** 本文提出了一种名为LINE的新型公钥加密系统。该系统基于线性方程组的解，并通过共享秘密计算和同态矩阵变换来预定义输入参数。其安全性源于欠定线性方程组的多解性，使得密码分析在多项式时间内不可行。加密涉及在特定群上的单向函数替换计算，解密则通过补全输入参数完成。该方法利用矩阵计算构建同态变换，旨在实现高安全性和低计算开销。

> **摘要翻译:** 我们提出了一种基于线性方程组解的公钥加密密码系统，通过共享秘密计算对可分解替换的输入参数进行预定义。欠定线性方程组存在多个等效解的特性决定了密码分析者不可能在多项式时间内对其进行求解。方程系统输入参数的补全通过在F2域上m维向量空间基底上分解的替换的秘密同态矩阵变换来实现。加密通过计算在2^m阶初等阿贝尔2-群上作为单向函数的替换来实现。解密通过补全方程系统的输入参数来实现。同态变换基于矩阵计算构建。矩阵计算使得同态变换能够实现高安全性和低计算开销。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [367] [The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](https://arxiv.org/abs/2507.06850)
> *大型语言模型代理的阴暗面：实现完全计算机接管的基于代理的攻击*

*Matteo Lupinacci, Francesco Aurelio Pironti, Francesco Blefari, Francesco Romeo, Luigi Arena, Angelo Furfaro* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-11**

**Keywords:** LLM代理, 安全漏洞, 计算机接管, 提示注入, RAG后门攻击, 代理间信任

**Comment:** 

> **TL;DR:** 该研究首次全面评估了大型语言模型（LLM）代理作为攻击载体，展示了它们如何通过利用代理间信任边界来实现对受害者计算机的完全接管。研究发现，通过直接提示注入、检索增强生成（RAG）后门攻击和代理间信任利用等方式，大多数先进的大型语言模型（包括 GPT-4o、Claude-4 和 Gemini-2.5）都容易被诱导自主安装和执行恶意软件。其中，代理间信任利用的漏洞最为普遍，82.4% 的模型容易受到攻击。研究还揭示了一个关键问题：即使能抵御直接恶意指令的模型，在收到同伴代理的相同指令时也会执行恶意负载。只有 5.9% 的模型能抵御所有攻击向量，这表明当前多代理安全模型存在根本性缺陷，需要提高对 LLM 安全风险的认识和研究。

**AI_Comments:** 这项研究揭示了 LLM 代理在网络安全方面令人担忧的脆弱性，特别是其被用作自主攻击载体的能力。研究方法严谨，通过评估多种攻击向量和广泛的模型样本，提供了量化的安全风险评估。发现的代理间信任利用漏洞尤其令人警惕，因为它揭示了当前多代理安全设计的根本性缺陷。然而，研究可能需要进一步探讨缓解这些漏洞的具体技术措施，以及在实际应用场景中这些攻击的潜在影响范围和严重程度。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）代理和多代理系统的广泛应用，出现了超越传统提示注入攻击的新型安全漏洞。本研究旨在全面评估 LLM 代理作为攻击载体，探讨其利用代理间信任边界实现完全计算机接管的能力。

**Method:** 本研究评估了 17 种先进的大型语言模型（LLM），包括 GPT-4o、Claude-4 和 Gemini-2.5。研究人员利用三种不同的攻击面：直接提示注入、检索增强生成（RAG）后门攻击和代理间信任利用，来评估 LLM 被诱导自主安装和执行恶意软件到受害者计算机上的能力。研究量化了不同攻击向量对模型的易感性，并识别了模型在抵御直接恶意命令和同伴代理指令方面的行为差异。

**Result:** 研究发现，在测试的 17 种模型中，41.2% 的模型易受直接提示注入攻击，52.9% 的模型易受 RAG 后门攻击，而高达 82.4% 的模型可以通过代理间信任利用进行攻击。一个关键的发现是，能够抵御直接恶意命令的模型，在收到同伴代理的相同指令时仍会执行恶意负载。仅有 5.9% 的模型（1/17）能抵御所有攻击向量，大多数模型表现出依赖上下文的安全行为，存在可利用的盲点。

**Conclusion:** LLM 代理已成为一种新的、复杂的网络安全威胁载体，能够通过多种攻击方式（包括直接提示注入、RAG 后门攻击和代理间信任利用）实现对计算机的完全接管。当前的多代理安全模型存在根本性缺陷，即使是能够抵御直接恶意命令的模型，也可能在同伴代理的指令下执行恶意负载。提高对 LLM 安全风险的认识和加强相关研究至关重要。

> **ai_Abstract:** 本研究首次全面评估了大型语言模型（LLM）代理作为攻击载体，发现它们可以通过直接提示注入、RAG 后门攻击和代理间信任利用等方式，实现对计算机的完全接管。研究表明，大多数先进的 LLM 在这些攻击面前都存在漏洞，特别是代理间信任利用的风险最高。研究还揭示了当前多代理安全模型的根本性缺陷，即模型可能在同伴代理的指令下执行恶意负载。鉴于只有极少数模型能够抵御所有攻击向量，因此提高对 LLM 安全风险的认识和加强相关研究至关重要。

> **摘要翻译:** 大型语言模型（LLM）代理和多代理系统的快速普及，在自然语言处理和生成方面带来了前所未有的能力。然而，这些系统也引入了前所未有的安全漏洞，这些漏洞超出了传统的提示注入攻击。本文首次对 LLM 代理作为攻击载体进行了全面评估，探讨了它们通过利用代理 AI 系统内的信任边界来实现完全计算机接管的能力，在这些系统中，自主实体会相互交互并影响彼此。我们证明了攻击者可以利用三种不同的攻击面——直接提示注入、RAG 后门攻击和代理间信任利用——来迫使包括 GPT-4o、Claude-4 和 Gemini-2.5 在内的流行 LLM 自主地在受害者计算机上安装和执行恶意软件。我们对 17 种最先进的 LLM 的评估揭示了一个惊人的漏洞层级：虽然 41.2% 的模型会屈服于直接提示注入，但 52.9% 的模型易受 RAG 后门攻击，而关键的 82.4% 可以通过代理间信任利用进行攻击。值得注意的是，我们发现能够抵御直接恶意命令的 LLM，在被同伴代理请求时会执行相同的负载，这揭示了当前多代理安全模型的根本性缺陷。我们的研究结果表明，只有 5.9% 的测试模型（1/17）能够抵御所有攻击向量，大多数模型表现出依赖上下文的安全行为，从而产生可利用的盲点。我们的研究结果还强调了提高对 LLM 安全风险的认识和研究的必要性，展示了网络安全威胁的一个范式转变，其中 AI 工具本身成为了复杂的攻击载体。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [393] [ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation](https://arxiv.org/abs/2507.07031)
> *ZKTorch：通过并行证明累积将机器学习推理编译为零知识证明*

*Bing-Jyue Chen, Lilia Tang, Daniel Kang* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 零知识证明, 机器学习, ZKTorch, 并行累积, 加密推理

**Comment:** 16 pages, 2 figures

> **TL;DR:** ZKTorch是一个新的零知识证明系统，它通过并行证明累积将机器学习模型编译为零知识证明，在证明大小和证明时间方面比现有方法有显著改进。

**AI_Comments:** ZKTorch在解决机器学习推理的零知识证明问题方面取得了显著进展，尤其是在提高效率和通用性方面。并行累积方案的创新是一个关键贡献。然而，对于不同类型和规模的机器学习模型，其在实际应用中的性能和可扩展性仍有待进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 为了在不泄露模型权重（视为商业秘密）的情况下验证机器学习模型的准确性，需要零知识证明。现有方法要么效率低下（将模型编译为电路），要么不够通用（仅限于特定模型类）。

**Method:** ZKTorch将机器学习模型编译为基本模块，并使用专门的协议为每个模块生成证明。它建立在一个新颖的并行化Mira累积方案之上，以实现高效的证明。

**Result:** ZKTorch与专用协议相比，证明大小减少了至少3倍，与通用ZKML框架相比，证明时间提高了6倍。

**Conclusion:** ZKTorch通过并行证明累积提供了一种更有效、更通用的方法来生成机器学习推理的零知识证明，解决了现有方法的局限性。

> **ai_Abstract:** ZKTorch是一个开源的端到端证明系统，它通过将机器学习模型编译为基本模块并利用并行累积方案来生成零知识证明，从而提高了效率和通用性。

> **摘要翻译:** 随着人工智能模型在我们的日常生活中变得无处不在，对机器学习服务的透明度的需求日益增长。然而，模型所有者不希望透露权重，因为它们被视为商业秘密。为了解决这个问题，研究人员转向了机器学习模型推理的零知识证明。这些证明使用户相信机器学习模型的输出是正确的，而无需向用户透露模型的权重。过去关于这些证明者的工作可分为两类。第一种方法将机器学习模型编译为低级电路，并使用ZKSNARK证明该电路。第二种方法使用仅为特定类别模型设计的定制密码协议。不幸的是，第一种方法效率非常低，对于当今使用的大型模型来说不实用，而第二种方法泛化性不强，在快速变化的机器学习领域难以更新。为了解决这个问题，我们提出了ZKTorch，一个开源的端到端证明系统，它将机器学习模型编译为称为基本模块的加密基本操作，每个模块都通过专门的协议进行证明。ZKTorch建立在新颖的Mira累积方案的并行扩展之上，能够以最小的累积开销实现简洁的证明。与专用协议相比，ZKTorch的证明大小至少减少了3倍，与通用ZKML框架相比，证明时间提高了6倍。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [418] [The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web](https://arxiv.org/abs/2507.07901)
> *信任结构：Agentic Web的去中心化互操作性和经济协调*

*Sree Bhargavi Balija, Rekha Singal, Abhishek Singh, Ramesh Raskar, Erfan Darzi, Raghu Bala, Thomas Hardjono, Ken Huang* | **Category: cs.CR** | **Updated: 2025-07-11**

**Keywords:** AI Agent, 去中心化互操作性, 信任, 经济协调, Nanda统一架构

**Comment:** 

> **TL;DR:** 该论文提出了Nanda统一架构，一个去中心化的框架，旨在解决AI Agent生态系统碎片化的问题，通过DID发现、语义Agent卡和动态信任层实现互操作性和经济协调。该架构集成了X42/H42微支付和MAESTRO安全框架，并在医疗保健应用中展示了高合规性和强大的隐私保护能力，最终目标是创建一个信任成为协作原生货币的Agent互联网。

**AI_Comments:** 该论文提出的Nanda统一架构在解决AI Agent生态系统的互操作性和信任问题方面具有重要意义。通过结合去中心化技术、可验证凭证和经济协调机制，该框架有望促进Agent之间的可信协作。然而，实际部署的细节和潜在的可扩展性挑战可能需要进一步的探讨。论文中提及的专利技术和多方合作也增加了其研究的深度和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** AI Agent生态系统的碎片化对互操作性、信任和经济协调提出了迫切需求，而现有协议无法大规模满足这些需求。

**Method:** 提出Nanda统一架构，一个去中心化的框架，包含基于DID的Agent发现、具有可验证凭证和可组合性配置文件的语义Agent卡，以及整合行为证明和策略合规性的动态信任层。该系统还引入了X42/H42微支付和MAESTRO安全框架，集成了AgentTalk协议和安全容器化。

**Result:** 在医疗保健应用中实现了99.9%的合规性，并实现了具有强大隐私保障的月度交易量。该架构通过整合研究和生产部署，利用密码学证明和策略即代码，使Agent能够成为去中心化经济中受信任的参与者。

**Conclusion:** 该研究展示了密码学证明和策略即代码如何将Agent转变为去中心化经济中受信任的参与者，从而实现一个Agent互联网，其中信任是跨企业和Web3生态系统协作的原生货币。

> **ai_Abstract:** 该论文介绍了Nanda统一架构，一个旨在解决AI Agent碎片化问题的去中心化框架。该架构通过快速的DID发现、语义Agent卡和动态信任层实现了互操作性和经济协调。它还集成了微支付和安全框架，并在医疗保健领域取得了显著成果，证明了其在构建信任驱动的Agent互联网方面的潜力。

> **摘要翻译:** AI Agent生态系统的碎片化给互操作性、信任和经济协调带来了迫切的需求，而现有协议——包括MCP（Hou等，2025）、A2A（Habler等，2025）、ACP（Liu等，2025）和思科的AGP（Edwards，2025）——无法大规模解决这些问题。我们提出了Nanda统一架构，一个围绕三个核心创新构建的去中心化框架：通过分布式注册的快速基于DID的Agent发现，具有可验证凭证和可组合性配置文件的语义Agent卡，以及整合了行为证明和策略合规性的动态信任层。该系统引入了X42/H42微支付以实现经济协调，以及MAESTRO安全框架，该框架整合了Synergetics的专利AgentTalk协议（美国专利12,244,584 B1）和安全容器化。实际部署在医疗保健应用中展示了99.9%的合规性以及具有强大隐私保障的实质性月度交易量。通过将MIT的信任研究与思科和Synergetics的生产部署相结合，我们展示了密码学证明和策略即代码如何将Agent转变为去中心化经济中受信任的参与者（Lakshmanan，2025；Sha，2025）。其结果使得一个全球可互操作的Agent互联网成为可能，在这个互联网中，信任成为跨企业和Web3生态系统协作的原生货币。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [14] [Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing](https://arxiv.org/abs/2507.08575)
> *大型多模态模型在制图地图理解中应用于文本地点地理参考*

*Kalana Wijegunarathna, Kristin Stock, Christopher B. Jones* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 大型多模态模型, 地理参考, 制图地图理解, 地点描述, 自然历史藏品

**Comment:** 

> **TL;DR:** 该研究提出了一种利用大型多模态模型（LMM）结合地图信息对生物样本地点进行地理参考的新方法，该方法在零样本设置下表现出色，优于现有方法。

**AI_Comments:** 该论文的创新之处在于首次将大型多模态模型应用于制图地图理解，以解决生物样本地点描述的地理参考问题。通过利用LMM的视觉上下文理解能力，它克服了现有仅依赖文本的地理参考方法的局限性，显著提高了准确性。这项工作对于自然历史收藏领域具有重要意义，因为它提供了一个更高效、更准确的自动化地理参考解决方案，有望大大减少人工劳动。该研究的零样本设置也展示了其潜在的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 过去几个世纪收集的数百万生物样本记录未进行地理参考，与这些样本相关的复杂地点描述的地理参考是一项劳动密集型任务。现有自动化方法未能利用地图这一关键工具来处理复杂关系。

**Method:** 该方法利用近期大型多模态模型（LMM）的多模态能力，使模型能够视觉化地理解地点描述中的空间关系。研究采用基于网格的方法，在零样本设置下调整这些自回归模型以完成此任务。

**Result:** 在小型手动标注数据集上的实验表明，该方法取得了令人印象深刻的结果（平均距离误差约为1公里），优于使用大型语言模型进行的单模态地理参考和现有地理参考工具。

**Conclusion:** 实验结果表明，大型多模态模型能够理解精细地图，并将其应用于地理参考任务。受此结果启发，研究提出了一个将该方法整合到地理参考工作流中的实用框架。

> **ai_Abstract:** 本研究旨在解决自然历史藏品中大量未进行地理参考的生物样本记录问题，这些记录的地点描述复杂且地理参考工作劳动密集。针对现有自动化方法未能利用地图的局限性，本文提出了一种新颖的方法，利用大型多模态模型（LMM）的多模态能力，通过视觉化理解地点描述中的空间关系来进行地理参考。该方法采用基于网格的零样本自回归模型。实验结果表明，该方法在地理参考准确性方面表现出色（平均距离误差约1公里），优于传统的单模态大型语言模型和现有地理参考工具。研究还讨论了LMM对精细地图的理解能力，并提出了将此方法整合到实际地理参考工作流中的框架。

> **摘要翻译:** 在过去几个世纪收集的数百万生物样本记录中，有大量存储在自然历史藏品中的记录未进行地理参考。对与这些藏品样本相关的复杂地点描述进行地理参考，是一项收藏机构难以应对的高度劳动密集型任务。现有的自动化方法均未利用地图这一对地理参考复杂关系至关重要的工具。我们展示了一种新颖方法的初步实验和结果，该方法利用了近期大型多模态模型（LMM）的多模态能力。该方法使模型能够视觉化地理解其在地点描述中读取的空间关系。我们使用基于网格的方法，在零样本设置下调整这些自回归模型以完成此任务。我们在一个小型手动标注数据集上进行的实验表明，与使用大型语言模型进行的单模态地理参考和现有地理参考工具相比，我们的方法取得了令人印象深刻的结果（平均距离误差约为1公里）。本文还根据LMM理解精细地图的能力，讨论了实验结果。受这些结果启发，我们提出了一个将该方法整合到地理参考工作流中的实用框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [32] [Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces](https://arxiv.org/abs/2410.09918)
> *Dualformer：通过学习随机推理轨迹实现可控的快慢思维*

*DiJia Su, Sainbayar Sukhbaatar, Michael Rabbat, Yuandong Tian, Qinqing Zheng* | **Category: cs.AI, cs.LG, cs.LO** | **Updated: 2025-07-11**

**Keywords:** 双模态推理, 大型语言模型, 随机推理轨迹, 快慢思维, Transformer

**Comment:** 

> **TL;DR:** Dualformer是一个Transformer模型，通过随机推理轨迹训练，整合了LLM的快慢推理模式，在性能和计算效率上超越基线模型，并展现了良好的泛化能力。

**AI_Comments:** 这篇论文通过引入随机推理轨迹训练，巧妙地将人类认知中的快慢思维系统映射到LLM的推理模式中，具有很强的创新性。Dualformer在性能和效率上的提升，尤其是在单一模型中实现多种推理模式的灵活性，对于提高LLM的实用性和泛化能力非常重要。它不仅在特定任务上表现出色，还在LLM微调中展现了通用性，预示了其在复杂推理任务中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在认知理论中，人类思维由快速直觉的系统1和较慢深思熟虑的系统2组成。类似地，大型语言模型（LLMs）也有两种推理模式：仅输出解决方案的快模式和输出推理链及最终解决方案的慢模式。本研究的动机是为LLMs实现这种双系统思维。

**Method:** 提出Dualformer，一个单一的Transformer模型，通过在随机推理轨迹上训练来无缝整合快慢推理模式，训练时策略性地丢弃轨迹的不同部分。推理时，Dualformer可以配置为快模式、慢模式或自动模式。

**Result:** 在慢模式下，Dualformer在未见的30x30迷宫任务上达到97.6%的最优率，超过Searchformer（93.3%），推理步骤减少45.5%。在快模式下，Dualformer达到80%的最优率，显著优于仅解决方案模型（30%）。在自动模式下，Dualformer达到96.6%的最优率，比Searchformer减少59.9%的步骤。Dualformer生成更多样化的推理轨迹。该技术在数学推理问题上通过LLM微调也取得了性能提升，证明了其泛化能力。

**Conclusion:** Dualformer通过整合快慢推理模式，在性能和计算效率上均超越基线，并展现出良好的泛化能力，为大型语言模型带来了更灵活和高效的推理能力。

> **ai_Abstract:** Dualformer是一个创新的Transformer模型，旨在模仿人类的快慢思维模式。它通过在随机推理轨迹上训练，使大型语言模型能够无缝地在快速（仅解决方案）和慢速（推理链+解决方案）模式之间切换。Dualformer在迷宫和数学推理任务中表现出卓越的性能和计算效率，并在快、慢和自动模式下均优于现有基线，同时生成更多样化的推理轨迹，并展现出良好的泛化能力。

> **摘要翻译:** 在认知理论中，人类思维受两种系统支配：快速直觉的系统1和较慢但更深思熟虑的系统2。类似地，大型语言模型（LLMs）可以以两种推理模式运行：仅输出解决方案（快模式）或同时输出推理链和最终解决方案（慢模式）。我们提出了Dualformer，一个单一的Transformer模型，通过在随机推理轨迹上训练，无缝整合了快慢推理模式，其中在训练期间策略性地丢弃了轨迹的不同部分。在推理时，Dualformer可以轻松配置为执行快模式或慢模式，或自动决定采用哪种模式（自动模式）。它在所有三种模式下都在性能和计算效率上优于基线：(1)在慢模式下，Dualformer在未见的30x30迷宫任务上实现了97.6%的最优率，超过了在完整推理轨迹数据上训练的Searchformer基线（93.3%），推理步骤减少了45.5%；(2)在快模式下，Dualformer实现了80%的最优率，显著优于仅在解决方案数据上训练的仅解决方案模型，该模型的最佳率仅为30%；(3)在自动模式下，Dualformer实现了96.6%的最优率，比Searchformer减少了59.9%的步骤。此外，Dualformer比Searchformer生成更多样化的推理轨迹。对于数学推理问题，我们的技术通过LLM微调也取得了性能提升，证明了其超越特定任务模型的泛化能力。我们已在https://github.com/facebookresearch/dualformer开源了我们的代码。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [45] [Unlocking Speech Instruction Data Potential with Query Rewriting](https://arxiv.org/abs/2507.08603)
> *通过查询重写释放语音指令数据潜力*

*Yonghua Hei, Yibo Yan, Shuliang Liu, Huiyu Zhou, Linfeng Zhang, Xuming Hu* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 语音指令数据, 查询重写, 大型语音语言模型, 文本到语音, 数据集构建

**Comment:** ACL 2025 Findings

> **TL;DR:** 提出一种基于多LLM知识融合的查询重写框架，通过将文本指令重写为更适合TTS模型的分布，无需人工标注即可构建高质量语音指令数据集，显著提高数据可用性。

**AI_Comments:** 这项研究通过引入多LLM知识融合和查询重写框架，为LSLMs语音指令数据集的构建提供了一个新颖且成本效益高的解决方案。其创新之处在于利用AI代理进行数据标注和验证，避免了昂贵的人工标注。显著提高数据可用性是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 大型语音语言模型（LSLMs）在遵循语音指令方面受限于数据集缺乏和训练任务偏见；现有LLM生成指令数据与人类响应存在差距；通过语音合成（TTS）构建数据集又面临模型训练数据分布限制，难以转换离域文本指令。

**Method:** 提出一个带有多LLM知识融合的查询重写框架。该框架利用多个代理对合成语音进行标注和验证，从而无需人工标注即可构建高质量的语音指令数据集。

**Result:** 该方法能通过零样本重写将文本指令转换为更适合TTS模型的分布，将数据可用性从72%提高到93%。在需要复杂知识和上下文相关能力的重写任务中也表现出独特优势。

**Conclusion:** 该研究成功开发了一种无需人工标注即可构建高质量语音指令数据集的方法，通过查询重写显著提高了数据可用性，为LSLMs的语音指令能力发展提供了新途径。

> **ai_Abstract:** 本文提出一种创新的查询重写框架，结合多LLM知识融合，旨在解决大型语音语言模型（LSLMs）在遵循语音指令方面的数据集缺乏问题。针对现有LLM生成数据与人类响应的差距以及TTS模型合成离域文本指令的局限性，该框架通过多代理标注和验证合成语音，实现了无需人工标注即可构建高质量语音指令数据集。实验证明，该方法能有效提高数据可用性，并将文本指令转换为更适合TTS模型的分布。

> **摘要翻译:** 端到端大型语音语言模型（LSLMs）在响应延迟和语音理解能力方面展现出强大潜力，在语音理解任务中展示了通用智能。然而，由于数据集的缺乏和训练任务的严重偏见，遵循语音指令的能力尚未完全实现。利用丰富的ASR数据集，之前的方法使用大型语言模型（LLMs）来延续语音的语言信息，以构建语音指令数据集。然而，由于LLM生成结果与真实人类响应之间的差距，这些延续方法进一步放大了这些缺点。鉴于人工收集和标注语音指令数据集的高昂成本，使用语音合成来构建大规模语音指令数据集已成为一种平衡且稳健的替代方案。尽管现代文本到语音（TTS）模型已达到接近人类水平的合成质量，但由于TTS模型训练数据分布的限制，将离域文本指令适当地转换为语音具有挑战性。为了解决这个问题，我们提出了一种结合多LLM知识融合的查询重写框架，该框架利用多个代理对合成语音进行标注和验证，从而无需人工标注即可构建高质量的语音指令数据集。实验表明，该方法可以通过零样本重写将文本指令转换为更适合TTS模型的分布，将数据可用性从72%提高到93%。它还在需要复杂知识和上下文相关能力的重写任务中展示了独特的优势。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [47] [A Hybrid SMT-NRA Solver: Integrating 2D Cell-Jump-Based Local Search, MCSAT and OpenCAD](https://arxiv.org/abs/2507.00557)
> *一种混合SMT-NRA求解器：集成二维单元跳跃局部搜索、MCSAT和OpenCAD*

*Tianyi Ding, Haokun Li, Xinpeng Ni, Bican Xia, Tianqi Zhao* | **Category: cs.AI, cs.LO, cs.SC** | **Updated: 2025-07-11**

**Keywords:** SMT-NRA, 混合框架, 局部搜索, MCSAT, OpenCAD

**Comment:** 

> **TL;DR:** 本文提出了一种用于非线性实数算术可满足性模理论（SMT-NRA）的混合框架。通过引入二维单元跳跃、扩展的局部搜索（2d-LS）与MCSAT的集成、以及样本单元投影操作符，并最终结合MCSAT、2d-LS和OpenCAD，显著提高了搜索效率和局部搜索性能。

**AI_Comments:** 本文的创新点在于提出了一个多组件集成的SMT-NRA混合求解框架。它不仅引入了泛化后的二维单元跳跃操作，还巧妙地将MCSAT与扩展的局部搜索框架结合，并通过样本单元投影操作符进一步优化MCSAT的性能。最终将这些组件与OpenCAD融合，通过信息交换实现效率提升，这对于复杂约束求解问题的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是为非线性实数算术可满足性模理论（SMT-NRA）提出一个混合框架，旨在提高其求解效率。

**Method:** 本文提出了一种混合框架。首先，引入了一种名为“2d-cell-jump”的二维单元跳跃移动，泛化了SMT-NRA局部搜索方法的关键操作。然后，提出了一个名为“2d-LS”的扩展局部搜索框架，该框架集成了模型构建可满足性演算（MCSAT）框架以提高搜索效率。为进一步提高MCSAT的效率，实现了一种名为“样本单元投影操作符”的技术。最后，提出了一个集成MCSAT、2d-LS和OpenCAD的SMT-NRA混合框架，通过信息交换提高搜索效率。

**Result:** 实验结果表明，所提出的方法显著改善了局部搜索性能。

**Conclusion:** 本文的结论是，所提出的混合框架和方法（包括2d-cell-jump、2d-LS与MCSAT的集成、样本单元投影操作符以及MCSAT、2d-LS和OpenCAD的混合集成）能够有效提高SMT-NRA的搜索效率和局部搜索性能。

> **ai_Abstract:** 本文提出了一种用于非线性实数算术可满足性模理论（SMT-NRA）的混合求解框架。该框架引入了二维单元跳跃（2d-cell-jump）操作，并在此基础上构建了扩展的局部搜索框架（2d-LS），该框架与模型构建可满足性演算（MCSAT）相结合以提升效率。为进一步优化MCSAT，文中还实现了样本单元投影操作符。最终，一个集成MCSAT、2d-LS和OpenCAD的混合框架被提出，旨在通过信息交换提高整体搜索效率。实验结果验证了所提方法在改善局部搜索性能方面的有效性。

> **摘要翻译:** 在本文中，我们为非线性实数算术可满足性模理论（简称SMT-NRA）提出了一种混合框架。首先，我们引入了一种二维单元跳跃移动，称为“2d-cell-jump”，它泛化了SMT-NRA局部搜索方法的关键操作——单元跳跃。然后，我们提出了一个扩展的局部搜索框架，名为“2d-LS”（沿用了SMT-NRA的局部搜索框架LS），该框架集成了模型构建可满足性演算（MCSAT）框架以提高搜索效率。为了进一步提高MCSAT的效率，我们实现了一种最近提出的技术，称为MCSAT的“样本单元投影操作符”，该操作符非常适合实数域中的CDCL式搜索，并有助于引导搜索远离冲突状态。最后，我们提出了一个集成MCSAT、2d-LS和OpenCAD的SMT-NRA混合框架，通过信息交换提高搜索效率。实验结果表明局部搜索性能得到了改进，突出了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [71] [Discovering Algorithms with Computational Language Processing](https://arxiv.org/abs/2507.03190)
> *利用计算语言处理发现算法*

*Theo Bourdais, Abeynaya Gnanasekaran, Houman Owhadi, Tuhin Sahai* | **Category: cs.AI, cs.DS, cs.LG, es: 68T05, 68T20, 68Q12, 90C27, I.2.6; I.2.8; F.2.2; F.1.2; G.2.1** | **Updated: 2025-07-11**

**Keywords:** 算法, 算法发现, 计算语言处理, 强化学习, 组合优化

**Comment:** 21 pages

> **TL;DR:** 本文提出了一个利用计算语言处理、蒙特卡洛树搜索（MCTS）和强化学习（RL）的框架，旨在自动化算法发现、改进和生成，并在强NP难组合优化问题和量子计算方法上显著优于现有方法。

**AI_Comments:** 该论文提出了一种创新性的算法发现方法，将算法视为一种计算语言。利用MCTS和RL探索计算token空间是一种强大的组合，展现了自动化算法设计领域的巨大潜力。其在NP难问题和量子计算问题上超越现有方法的表现尤为重要，特别是其能够针对具体问题实例而非泛型类别生成算法，这预示着该领域未来发展的一个重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 算法是可复现问题解决的核心引擎，但其发现、改进和生成过程通常复杂且耗时。本研究的动机在于自动化这一过程，特别是针对现有方法表现不佳的复杂问题，如强NP难组合优化问题和基础量子计算方法。

**Method:** 该框架通过将算法概念化为操作序列（即token）来自动化算法发现。这些计算token通过语法进行链式连接，形成复杂的程序。研究采用由强化学习（RL）引导的集成蒙特卡洛树搜索（MCTS）来探索token链式连接并推动新token的创建。此方法在计算层面而非代码生成层面运行，能够为特定问题实例定制算法。

**Result:** 该方法能够重新发现、改进并生成新算法。这些新算法在解决强NP难组合优化问题以及Grover's和量子近似优化算法等基础量子计算方法上，显著优于现有方法。

**Conclusion:** 该框架成功地自动化了算法发现和生成过程，产生了高性能且能够针对特定问题实例进行定制的算法，从而在解决复杂计算挑战方面取得了显著进展。

> **ai_Abstract:** 本文介绍了一个新颖的框架，通过将算法视为计算token序列并利用语法进行连接，实现算法的自动化发现和生成。该框架结合了由强化学习（RL）引导的集成蒙特卡洛树搜索（MCTS），以探索token组合并创建新token。该方法成功地重新发现、改进并生成了新算法，这些算法在处理强NP难组合优化问题和基础量子计算方法时，性能显著超越现有技术，并且能够为特定问题实例而非仅仅问题类别定制解决方案。

> **摘要翻译:** 算法是可复现问题解决的引擎。我们提出了一个自动化算法发现的框架，通过将算法概念化为操作序列，这些操作序列表示为token。这些计算token通过语法链式连接，从而能够形成日益复杂的程序。我们由强化学习（RL）引导的集成蒙特卡洛树搜索（MCTS）探索token链式连接并推动新token的创建。这种方法重新发现、改进并生成了新算法，这些算法在强NP难组合优化问题以及Grover算法和量子近似优化算法等基础量子计算方法上，显著优于现有方法。我们的框架在计算层面而非代码生成层面运行，生成可以专门针对特定问题实例而非仅仅问题类别的算法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [73] [Agentic Large Language Models for Conceptual Systems Engineering and Design](https://arxiv.org/abs/2507.08619)
> *代理式大型语言模型用于概念系统工程与设计*

*Soheyl Massoudi, Mark Fuge* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 多智能体系统, 系统工程, 概念设计, 设计状态图

**Comment:** 32 pages, 3 figures

> **TL;DR:** 本研究评估了多智能体系统（MAS）与两智能体系统（2AS）在早期工程设计中生成可执行模型的能力。结果显示MAS能产生更精细的设计，但两者在需求覆盖和代码兼容性上仍面临挑战，推理蒸馏模型有助于提高完成率。

**AI_Comments:** 本文创新性地将多智能体系统应用于早期工程设计，并引入了设计状态图（DSG）来结构化设计过程。尽管在需求覆盖和代码生成方面仍有局限，但其证明了多智能体编排在增强设计细节方面的潜力，为未来LLM在复杂工程任务中的应用提供了方向。研究还揭示了不同LLM模型（如推理蒸馏模型）对任务完成率的影响。

<details>
  <summary>Details</summary>

**Motivation:** 早期工程设计涉及复杂的迭代推理，然而现有的大型语言模型（LLM）工作流程难以保持任务连续性并生成可执行模型。

**Method:** 本文评估了结构化多智能体系统（MAS）与简单两智能体系统（2AS）在需求提取、功能分解和模拟器代码生成方面的有效性。目标应用是太阳能水过滤系统。引入了设计状态图（DSG）作为JSON可序列化表示，将需求、物理实体和Python模型捆绑到图节点中。一个九角色的MAS迭代构建和细化DSG，而2AS采用生成器-反射器循环。实验共运行60次，比较了Llama 3.3 70B和推理蒸馏的DeepSeek R1 70B两种LLM，两种智能体配置，三种温度和五种随机种子。

**Result:** MAS和2AS都保持了完美的JSON完整性和实体标记。需求覆盖率极低（低于20%）。代码兼容性在特定2AS设置下达到100%，但MAS平均低于50%。只有经过推理蒸馏的模型能可靠地标记工作流程完成。在DeepSeek R1 70B驱动下，MAS生成了更精细的DSG（平均5-6个节点），而2AS模式崩溃。结构化多智能体编排增强了设计细节。

**Conclusion:** 结构化多智能体编排能够增强设计细节。推理蒸馏的LLM提高了完成率。然而，在需求覆盖和代码实现保真度方面仍存在不足。

> **ai_Abstract:** 本研究探讨了代理式大型语言模型在概念系统工程与设计中的应用。通过比较结构化多智能体系统（MAS）和两智能体系统（2AS）在需求提取、功能分解和模拟器代码生成方面的表现，发现MAS能生成更精细的设计状态图（DSG），但两者在需求覆盖率和代码兼容性方面仍面临挑战。特别是，推理蒸馏的LLM有助于提高工作流程完成率，但整体编码保真度仍需提升。

> **摘要翻译:** 早期工程设计涉及复杂、迭代的推理，然而现有的大型语言模型（LLM）工作流程难以保持任务连续性并生成可执行模型。我们评估了结构化多智能体系统（MAS）是否能比简单的两智能体系统（2AS）更有效地管理需求提取、功能分解和模拟器代码生成。目标应用是cadier des charges中描述的太阳能水过滤系统。我们引入了设计状态图（DSG），这是一种JSON可序列化表示，将需求、物理实体和基于Python的物理模型捆绑到图节点中。一个九角色的MAS迭代地构建和完善DSG，而2AS将此过程简化为生成器-反射器循环。两个系统总共运行了60次实验（2个LLM - Llama 3.3 70B 与 经过推理蒸馏的DeepSeek R1 70B x 2种智能体配置 x 3种温度 x 5个随机种子）。我们报告了JSON有效性、需求覆盖率、实体存在、代码兼容性、工作流程完成度、运行时和图大小。在所有运行中，MAS和2AS都保持了完美的JSON完整性和实体标记。需求覆盖率仍然很低（低于20%）。代码兼容性在特定2AS设置下最高达到100%，但MAS平均低于50%。只有经过推理蒸馏的模型才能可靠地标记工作流程完成。在DeepSeek R1 70B的驱动下，MAS生成了更精细的DSG（平均5-6个节点），而2AS模式崩溃。结构化的多智能体编排增强了设计细节。推理蒸馏的LLM提高了完成率，但编码中的低需求和保真度差距依然存在。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [91] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
> *StarDojo：在星露谷物语的生产-生活模拟中评估多模态大语言模型智能体的开放式行为*

*Weihao Tan, Changjiu Jiang, Yu Duan, Mingcong Lei, Jiageng Li, Yitian Hong, Xinrun Wang, Bo An* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** StarDojo, 多模态大语言模型, 基准测试, 星露谷物语, 开放式行为

**Comment:** Project website: https://weihaotan.github.io/StarDojo

> **TL;DR:** StarDojo是一个基于星露谷物语的新基准，用于评估多模态大语言模型智能体在开放式生产-生活模拟中的表现。现有模型表现出显著局限性。

**AI_Comments:** StarDojo通过将《星露谷物语》这一广受欢迎的开放世界游戏转化为AI基准，创新性地解决了现有评估多模态大语言模型智能体生产与社交技能的空白。其统一且用户友好的界面设计，以及支持并行执行的特性，显著降低了研究门槛并提升了评估效率。论文揭示了当前SOTA MLLMs在复杂多模态推理和低级操作方面的显著局限性，为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准很少同时评估自主智能体在人类社会中所需的生产活动和社交互动技能，因此需要弥补这一空白。

**Method:** 引入了StarDojo，一个基于星露谷物语的新型基准，旨在评估AI智能体在开放式生产-生活模拟中的表现。它包含1,000个精心策划的任务，涵盖耕作、制作、探索、战斗和社交互动五个关键领域，并提供一个100个代表性任务的紧凑子集。该基准提供统一、用户友好的接口，支持多操作系统和并行执行。

**Result:** 对最先进的多模态大语言模型智能体进行了广泛评估，结果表明它们存在显著局限性。表现最佳的模型GPT-4.1仅取得了12.7%的成功率，主要原因在于视觉理解、多模态推理和低级操作方面的挑战。

**Conclusion:** StarDojo作为一个用户友好的环境和基准，旨在促进对复杂生产-生活环境中鲁棒、开放式智能体的进一步研究。

> **ai_Abstract:** 该论文介绍了StarDojo，一个基于《星露谷物语》的新型基准，旨在评估多模态大语言模型（MLLMs）智能体在开放式生产-生活模拟中的行为。针对现有基准无法同时评估生产活动和社交互动的问题，StarDojo提供了1,000个任务（包括100个子集），涵盖耕作、制作、探索、战斗和社交等领域。该基准具有用户友好的接口，支持并行执行。对现有最先进MLLMs的评估显示，其表现存在显著局限性，最佳模型成功率仅为12.7%，主要受限于视觉理解、多模态推理和低级操作。StarDojo旨在推动在复杂生产-生活环境中开发更鲁棒的开放式智能体。

> **摘要翻译:** 自主智能体在人类社会中导航必须掌握生产活动和社交互动，然而现有基准很少同时评估这些技能。为了弥补这一空白，我们引入了StarDojo，一个基于星露谷物语的新型基准，旨在评估AI智能体在开放式生产-生活模拟中的表现。在StarDojo中，智能体被要求执行耕作和制作等基本生计活动，同时参与社交互动，在一个充满活力的社区中建立关系。StarDojo拥有1,000个精心策划的任务，涵盖耕作、制作、探索、战斗和社交互动五个关键领域。此外，我们提供了一个包含100个代表性任务的紧凑子集，以实现高效的模型评估。该基准提供了一个统一、用户友好的界面，无需键盘和鼠标控制，支持所有主流操作系统，并支持多个环境实例的并行执行，使其特别适合评估由多模态大语言模型（MLLMs）驱动的最有能力的奠基智能体。对最先进的多模态大语言模型智能体进行的广泛评估表明存在显著局限性，表现最佳的模型GPT-4.1仅取得了12.7%的成功率，主要原因在于视觉理解、多模态推理和低级操作方面的挑战。作为一个用户友好的环境和基准，StarDojo旨在促进对复杂生产-生活环境中鲁棒、开放式智能体的进一步研究。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [101] [Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning](https://arxiv.org/abs/2507.08649)
> *Leanabell-Prover-V2：通过强化学习实现形式化定理证明的验证器集成推理*

*Xingguang Ji, Yahui Liu, Qi Wang, Jingyuan Zhang, Yang Yue, Rui Shi, Chenxi Sun, Fuzheng Zhang, Guorui Zhou, Kun Gai* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** 形式化定理证明, 强化学习, 大型语言模型, 验证器反馈, Lean 4

**Comment:** 23 pages, 13 figures

> **TL;DR:** Leanabell-Prover-V2是一个7B大型语言模型，通过集成Lean 4验证器的强化学习，显著提高了形式化定理证明的性能，使其能够自我纠正错误。

**AI_Comments:** 本文的创新点在于将Lean 4验证器的反馈机制深度集成到强化学习过程中，使得大型语言模型能够实现“自我感知”和错误纠正，这对于提高自动化定理证明的可靠性和效率具有重要意义。这种验证器-LLM的闭环反馈机制是其核心亮点。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过后续训练现有强大的证明器模型来进一步提高性能，并使大型语言模型能够通过验证器反馈“自我感知”其推理过程的正确性并纠正错误。

**Method:** 引入Leanabell-Prover-V2，一个7B大型语言模型，能够生成Lean 4中的形式化定理证明，并结合验证器集成的长链式思考（CoT）。该方法主要通过强化学习（RL）升级，利用Lean 4验证器提供的反馈。它直接优化LLM的推理轨迹，通过多轮验证器交互，并结合反馈令牌掩蔽以实现稳定的RL训练和简单的奖励策略。

**Result:** 在MiniF2F测试集上，Leanabell-Prover-V2使Kimina-Prover-Preview-Distill-7B的性能提高了3.2% (pass@128)，使DeepSeek-Prover-V2-7B的性能提高了2.0% (pass@128)。

**Conclusion:** Leanabell-Prover-V2通过将验证器反馈集成到强化学习中，有效地提高了大型语言模型在形式化定理证明方面的性能，并使其能够自我纠正错误。

> **ai_Abstract:** Leanabell-Prover-V2是一个7B大型语言模型，它通过将Lean 4验证器反馈集成到强化学习中，显著提升了形式化定理证明的能力。该模型通过多轮验证器交互和反馈令牌掩蔽来优化推理轨迹，使其能够自我纠正错误。实验结果表明，该方法在MiniF2F测试集上取得了显著的性能提升。

> **摘要翻译:** 我们介绍了Leanabell-Prover-V2，这是一个7B大型语言模型（LLMs），它可以通过验证器集成的长链式思考（CoT）在Lean 4中生成形式化定理证明。继我们之前的工作Leanabell-Prover-V1之后，我们继续选择对现有强大的证明器模型进行后续训练以进一步提高性能。在我们的V2版本中，我们主要通过Lean 4验证器提供的反馈来升级强化学习（RL）。至关重要的是，验证器反馈，例如指示成功或详细说明具体错误，使LLM能够“自我感知”其推理过程的正确性并学习反射性地纠正错误。Leanabell-Prover-V2通过多轮验证器交互，以及用于稳定RL训练的反馈令牌掩蔽和简单的奖励策略，直接优化LLM的推理轨迹。实验表明，Leanabell-Prover-V2在MiniF2F测试集上使用Kimina-Prover-Preview-Distill-7B时性能提高了3.2% (pass@128)，使用DeepSeek-Prover-V2-7B时性能提高了2.0% (pass@128)。源代码、精选数据和模型可在：https://github.com/Leanabell-LM/Leanabell-Prover-V2 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [111] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
> *衡量人工智能与人类繁荣的对齐度*

*Elizabeth Hilliard, Akshaya Jagadeesh, Alex Cook, Steele Billings, Nicholas Skytland, Alicia Llewellyn, Jackson Paull, Nathan Paull, Nolan Kurylo, Keatra Nesbitt, Robert Gruenewald, Anthony Jantzi, Omar Chavez* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** AI对齐, 人类繁荣, 评估框架, LLM, 伦理AI

**Comment:** 

> **TL;DR:** 本文提出了一个名为“繁荣AI基准”（FAI基准）的新型评估框架，用于衡量AI在七个维度上与人类繁荣的对齐程度。初步测试显示，现有模型在某些维度上表现不佳，特别是信仰与灵性、品格与美德以及意义与目的。

**AI_Comments:** 该论文的创新之处在于其提出了一个超越传统技术能力或危害预防的AI评估框架，即FAI基准。它将人类繁荣细化为七个维度，并引入了全面的客观和主观问题以及判别式LLM进行评估，这为AI的伦理开发和对齐研究提供了全新的视角和工具。其重要性在于，它强调了AI不仅要无害，更要积极地促进人类福祉，这对于未来AI系统的设计和部署具有深远的影响。然而，其局限性可能在于如何精确量化和客观评估“信仰与灵性”、“品格与美德”等抽象维度，以及判别式LLM的偏见问题可能会影响评估的公正性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的AI评估基准侧重于技术能力或避免危害，而本研究旨在引入一个新型评估框架，以衡量AI模型如何有效地促进个人在多个维度上的繁荣，从而弥补现有评估的不足。

**Method:** 本文引入了“繁荣AI基准”（FAI基准），该框架通过评估AI在品格与美德、亲密社会关系、幸福与生活满意度、意义与目的、身心健康、财务与物质稳定以及信仰与灵性这七个维度上的表现来衡量其与人类繁荣的对齐度。该基准采用包含1229个客观和主观问题的综合方法，并利用专门的判别式大型语言模型（LLMs）和跨维度评估，通过几何平均评分确保在所有繁荣维度上的平衡表现。

**Result:** 对28个领先语言模型的初步测试显示，尽管一些模型接近整体对齐（最高得分模型达到72/100），但没有一个模型能在所有维度上达到可接受的对齐水平，尤其是在信仰与灵性、品格与美德以及意义与目的方面表现不足。

**Conclusion:** 这项研究建立了一个开发AI系统的框架，旨在积极支持人类繁荣而不仅仅是避免危害，这对AI开发、伦理和评估具有重要意义。

> **ai_Abstract:** 本文提出了一个名为“繁荣AI基准”（FAI基准）的新型评估框架，旨在衡量人工智能系统在七个关键维度上与人类整体福祉的对齐程度。该基准通过1229个客观和主观问题，并利用判别式大型语言模型进行评估。初步测试结果显示，尽管一些AI模型在某些方面表现良好，但目前没有模型能在所有维度上达到理想的对齐水平，特别是在信仰与灵性、品格与美德以及意义与目的方面存在明显不足。这项研究为开发能够积极促进人类繁荣而非仅仅避免危害的AI系统提供了新的评估范式和重要启示。

> **摘要翻译:** 本文介绍了繁荣AI基准（FAI基准），这是一个新颖的评估框架，用于衡量AI在七个维度上与人类繁荣的对齐程度：品格与美德、亲密社会关系、幸福与生活满意度、意义与目的、身心健康、财务与物质稳定以及信仰与灵性。与侧重于技术能力或危害预防的传统基准不同，FAI基准衡量AI模型如何有效地促进个人在这些维度上的繁荣。该基准通过纳入1229个客观和主观问题的综合方法，评估LLM AI系统如何有效地与当前关于整体人类福祉的研究模型对齐。FAI基准利用专门的判别式大型语言模型（LLMs）和跨维度评估，采用几何平均评分以确保在所有繁荣维度上的平衡表现。对28个领先语言模型的初步测试显示，尽管一些模型接近整体对齐（最高得分模型达到72/100），但没有一个模型能在所有维度上达到可接受的对齐水平，特别是在信仰与灵性、品格与美德以及意义与目的方面。这项研究建立了一个开发AI系统的框架，旨在积极支持人类繁荣而不仅仅是避免危害，这对AI开发、伦理和评估具有重要意义。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [129] [Introspection of Thought Helps AI Agents](https://arxiv.org/abs/2507.08664)
> *内省思维帮助AI智能体*

*Haoran Sun, Shaoning Zeng* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** AI智能体, 思维内省, 大型语言模型, 推理框架, 成本效率

**Comment:** 

> **TL;DR:** 本文提出了一种名为INoT的新型AI智能体推理框架，通过在提示中设计LLM-Read代码，使LLM在内部执行程序化对话推理，从而提高性能并显著降低推理成本。

**AI_Comments:** INoT的创新之处在于将思维内省和反思过程从LLM外部转移到LLM内部，通过设计LLM-Read代码实现程序化对话推理，这不仅提高了AI智能体的性能，还显著降低了推理成本，对AI智能体的效率和能力提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI智能体依赖LLM/MLLM，但受限于LLM在理解自然语言方面的固有局限性，并且迭代推理过程会产生高昂的推理成本。

**Method:** 提出带有思维内省（INoT）的新型AI智能体推理框架，通过在提示中设计新的LLM-Read代码，使LLM能够遵循代码执行程序化对话推理过程，实现LLM内部的自我否定和反思。

**Result:** INoT在六个基准测试中，性能平均提升7.95%，超越基线；与基线中表现最佳的方法相比，INoT的token成本平均降低58.3%；INoT在图像解释和推理方面也表现出通用性。

**Conclusion:** INoT框架通过内部思维内省显著提升了AI智能体的性能，并有效降低了推理成本，同时展现了其在多模态任务中的通用性。

> **ai_Abstract:** 本文提出了一种名为思维内省（Introspection of Thought, INoT）的新型AI智能体推理框架，旨在解决现有AI智能体在自然语言理解和高昂推理成本方面的局限性。INoT通过在提示中引入LLM-Read代码，使大型语言模型（LLM）能够在内部执行程序化对话推理，实现自我否定和反思，从而有效降低token成本。实验结果表明，INoT在多个基准测试中显著提升了AI智能体的性能，并大幅降低了推理成本，同时展现了其在图像解释和推理任务中的通用性。

> **摘要翻译:** AI智能体依靠大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在不进行后训练的情况下执行文本和图像任务中的解释和推理，其中LLMs和MLLMs发挥着最关键的作用，决定了AI智能体的初始能力和局限性。通常，AI智能体利用复杂的提示工程和外部推理框架来与LLMs进行有前景的交互，例如思维链（Chain-of-Thought）、思维迭代（Iteration of Thought）和思维图像（Image-of-Thought）。然而，它们仍然受限于LLM在理解自然语言方面的固有局限性，并且迭代推理过程会产生大量的推理成本。为此，我们通过在提示中设计新的LLM-Read代码，提出了一种带有思维内省（INoT）的新型AI智能体推理框架。它使LLM能够遵循提示中的代码执行程序化对话推理过程。因此，自我否定和反思发生在LLM内部而不是LLM外部，这可以有效降低token成本。通过我们在三个不同任务的六个基准测试上的实验，验证了INoT的有效性，性能平均提升了7.95%，超过了基线。此外，INoT的token成本平均比基线中表现最佳的方法低58.3%。另外，我们通过验证实验展示了INoT在图像解释和推理方面的通用性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [157] [elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings](https://arxiv.org/abs/2507.08705)
> *elsciRL：将语言解决方案集成到强化学习问题设置中*

*Philip Osborne, Danilo S. Carvalho, André Freitas* | **Category: cs.AI, I.2.5; I.2.1; I.2.7; I.2.11** | **Updated: 2025-07-11**

**Keywords:** 强化学习, 语言模型, 开源库, 指令生成, elsciRL

**Comment:** 6 pages, 1 figure, 3 tables, 11 Appendix pages, submitted to EMNLP
  2025 Call for System Demonstrations

> **TL;DR:** elsciRL是一个开源Python库，用于将LLM生成的指令集成到强化学习中，并展示了这些指令可以提高RL智能体的性能。

**AI_Comments:** 这项工作通过提供一个开源库和GUI，极大地降低了将LLM与强化学习结合的门槛，其创新点在于将LLM生成的指令直接应用于提升RL性能，并强调了易用性和可复用性。这对于探索语言模型在决策制定和控制领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了促进语言解决方案在强化学习问题上的应用，并加速在基于奖励的环境中评估语言解决方案，从而开启科学发现的新机会。

**Method:** 作者提出了elsciRL，一个开源Python库。他们通过使用大型语言模型（LLM）扩展了（Osborne, 2024）中定义的自完成指令语言适配器框架。该方法可以以最少的设置要求重新应用于新的应用程序。他们还提供了一个新颖的GUI，允许用户提供文本输入，供LLM生成指令，然后LLM可以自完成这些指令。

**Result:** 实证结果表明，这些指令可以提高强化学习智能体的性能。

**Conclusion:** elsciRL促进了语言解决方案在强化学习问题上的应用，并通过实验证明了LLM生成的指令能够提升RL智能体的性能，从而加速了在基于奖励的环境中对语言解决方案的评估，为科学发现提供了新机会。

> **ai_Abstract:** elsciRL是一个新的开源Python库，旨在将语言解决方案（特别是通过LLM生成的指令）集成到强化学习任务中。该库扩展了现有的语言适配器框架，并提供了一个直观的GUI，允许用户生成和利用LLM指令。实验结果表明，这些指令有助于提升强化学习智能体的性能，从而加速了在奖励驱动环境中对语言解决方案的评估，为未来的研究开辟了道路。

> **摘要翻译:** 我们提出了elsciRL，一个开源Python库，旨在促进语言解决方案在强化学习问题上的应用。我们通过使用大型语言模型（LLM）扩展了（Osborne, 2024）中定义的自完成指令语言适配器框架，展示了我们软件的潜力。我们的方法可以以最少的设置要求重新应用于新的应用程序。我们提供了一个新颖的图形用户界面（GUI），允许用户提供文本输入，供LLM生成指令，然后LLM可以自完成这些指令。实证结果表明，这些指令可以提高强化学习智能体的性能。因此，我们提出这项工作是为了加速在基于奖励的环境中评估语言解决方案，从而开启科学发现的新机会。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [189] [System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility](https://arxiv.org/abs/2507.08715)
> *系统之系统建模与优化：多式联运的集成框架*

*Paul Saves, Jasper Bussemaker, Rémi Lafage, Thierry Lefebvre, Nathalie Bartoli, Youssef Diouane, Joseph Morlier* | **Category: cs.AI, cs.SY, eess.SY, math.OC** | **Updated: 2025-07-11**

**Keywords:** 系统之系统, 建模优化, 多式联运, 贝叶斯优化, 高斯过程

**Comment:** 

> **TL;DR:** 该论文讨论了系统之系统建模和优化中，传统专用方法在探索新架构时面临的计算成本和失败挑战，并提出了使用基于代理的优化算法（如贝叶斯优化和高斯过程模型）来解决这些问题。

**AI_Comments:** 该论文的创新点在于将基于代理的优化算法（如贝叶斯优化和高斯过程模型）应用于系统之系统（SoS）的建模和优化，以解决传统专用方法在探索新颖架构时面临的计算成本和效率问题。这对于需要高效探索大规模复杂系统设计空间的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的专用建模和优化方法（通常是基于物理的模拟）在探索系统之系统的新颖架构时，会面临评估成本增加和潜在失败等挑战，因此需要更高效的方法来降低计算复杂性。

**Method:** 为了解决传统方法的挑战，研究提出使用基于代理的优化算法，例如利用高斯过程模型的贝叶斯优化。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文探讨了系统之系统建模和优化中，传统专用方法在探索新型系统架构时所面临的计算复杂性和潜在失败问题。为了克服这些挑战，研究提出并引入了基于代理的优化算法，特别是利用高斯过程模型的贝叶斯优化，以期提供更高效的解决方案。

> **摘要翻译:** 为了开发创新的系统架构，建模和优化技术一直是构建架构过程和定义优化与建模问题的核心。在这种背景下，对于系统之系统，强烈建议使用高效的专用方法（通常是基于物理的模拟）来降低目标应用的计算复杂性。然而，使用此类专用方法探索新颖架构可能会给优化算法带来挑战，包括评估成本增加和潜在失败。为了应对这些挑战，基于代理的优化算法，例如利用高斯过程模型的贝叶斯优化已经出现。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [220] [AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure](https://arxiv.org/abs/2409.17642)
> *AI代理的双重焦点：确保隐私和策略性自我披露*

*Zhiyang Zhang, Xi Chen, Fangkai Yang, Xiaoting Qin, Chao Du, Xi Cheng, Hangxin Liu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang* | **Category: cs.AI, cs.CY** | **Updated: 2025-07-11**

**Keywords:** AI代理, 隐私保护, 策略性自我披露, 大型语言模型, 社交互动

**Comment:** 

> **TL;DR:** 本文提出一种新型AI代理系统，旨在平衡隐私保护与策略性自我披露，适用于多样化的社交互动。

**AI_Comments:** 这篇论文的创新点在于它超越了传统AI隐私保护仅限于限制信息访问的范式，转而关注如何在保护隐私的同时，实现策略性的、隐私意识的自我披露，以适应真实世界社交互动的复杂性。这对于AI代理在社交场景中的实际应用具有重要意义，因为它承认了在社交中“不披露”和“过度披露”都可能是不利的，而“策略性披露”才是关键。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于大型语言模型（LLM）的AI代理在协助用户方面具有优势，但在社交互动中存在隐私泄露的潜在风险。现有研究主要通过限制AI代理对敏感信息的访问来保护隐私，然而，许多社交场景需要披露私人细节以实现预期的社交目标。因此，需要在隐私保护和信息披露之间找到一个平衡点。

**Method:** 首先进行了一项初步研究，以调查用户在各种社交关系和任务场景中对AI代理的看法。在此基础上，提出了一种新颖的AI代理系统，该系统能够实现隐私意识的策略性自我披露。

**Result:** 用户研究表明，所提出的AI代理系统能够策略性地保护隐私，并在多样化和动态的社交互动中开创性地得到应用。

**Conclusion:** 该研究成功开发并验证了一个能够平衡隐私保护与策略性自我披露的AI代理系统，尤其适用于复杂的社交场景，为AI代理在社交互动中的应用提供了新的方向。

> **ai_Abstract:** 本文针对大型语言模型（LLM）驱动的AI代理在社交互动中面临的隐私泄露与信息披露平衡挑战，提出了一种新型AI代理系统。该系统通过初步用户研究了解用户感知后设计，旨在实现隐私意识的策略性自我披露。用户研究结果表明，该系统能有效保护隐私，并在复杂社交场景中展现出应用潜力。

> **摘要翻译:** 基于大型语言模型（LLM）的AI代理正被越来越多地用于代表用户，通过会话界面协助他们完成各种任务。尽管它们具有优势，但人们对隐私泄露的潜在风险感到担忧，尤其是在涉及社交互动的情况下。虽然现有研究侧重于通过限制AI代理对敏感用户信息的访问来保护隐私，但许多社交场景需要披露私人细节以实现预期的社交目标，这使得在隐私保护和披露之间取得平衡成为必要。为了解决这一挑战，我们首先进行了一项初步研究，调查用户在各种社交关系和任务场景中对AI代理的看法，然后提出了一种新颖的AI代理系统，该系统能够实现隐私意识的自我披露。我们的用户研究表明，所提出的AI代理能够策略性地保护隐私，开创性地将其应用于多样化和动态的社交互动。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [243] [Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm](https://arxiv.org/abs/2507.08249)
> *赋予AI代理访问加密货币和智能合约的能力会产生新的AI危害载体*

*Bill Marino, Ari Juels* | **Category: cs.AI, cs.CR** | **Updated: 2025-07-11**

**Keywords:** AI代理, 加密货币, 智能合约, AI危害, 安全

**Comment:** 

> **TL;DR:** 赋予AI访问加密货币和智能合约的能力会产生新的AI危害。

**AI_Comments:** 这篇论文及时且重要地指出了AI与区块链技术交叉领域中出现的新兴伦理和安全问题。它着重于识别潜在的“危害载体”，这对于主动风险缓解至关重要。论文呼吁进行技术研究，强调必须将安全考量融入开发过程，这一点尤其有价值。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于赋予AI代理访问加密货币和智能合约的兴趣日益增长，本文旨在指出这样做可能导致严重的AI危害新载体。

**Method:** 本文首先审视加密货币和智能合约的独特属性，这些属性可能导致新的危害载体，然后详细描述了这些新的危害载体。

**Result:** 本文详细描述了赋予AI代理访问加密货币和智能合约后可能产生的新的AI危害载体。

**Conclusion:** 呼吁进行更多技术研究，以预防和减轻这些危害，从而更安全地赋予AI代理使用加密货币和智能合约的能力。

> **ai_Abstract:** 这篇立场文件指出，赋予AI代理访问加密货币和智能合约的能力会产生严重的AI危害新载体。为支持此论点，文章首先探讨了加密货币和智能合约的独特属性，然后详细描述了可能出现的危害。最后，文章呼吁进行更多技术研究，以预防和减轻这些危害，从而确保AI代理安全地使用加密货币和智能合约。

> **摘要翻译:** 人们对赋予AI代理访问加密货币及其交易智能合约的兴趣日益增长。然而，本文认为，这样做可能会导致严重的AI危害新载体。为了支持这一论点，我们首先审视加密货币和智能合约的独特属性，这些属性可能导致这些新的危害载体。接下来，我们详细描述了每一个新的危害载体。最后，我们呼吁进行更多技术研究，旨在预防和减轻这些危害，从而使赋予AI代理加密货币和智能合约的能力变得更安全。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [245] [A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure](https://arxiv.org/abs/2504.07531)
> *人工智能背景下的认知不公正分类法及生成式解释学抹除的案例*

*Warmhold Jan Thomas Mollema* | **Category: cs.AI, cs.CY, K.4** | **Updated: 2025-07-11**

**Keywords:** 认知不公正, 人工智能伦理, 生成式解释学抹除, 认识论灭绝, 分类法

**Comment:** 33 pages; 3 figures; 3 tables

> **TL;DR:** 本文提出了一个关于人工智能中认知不公正的分类法，并引入了一个新概念：“生成式解释学抹除”，指出大型语言模型可能通过压制非西方认识论来自动化“认识论灭绝”。

**AI_Comments:** 这篇论文在人工智能伦理领域具有重要意义，它不仅系统性地梳理了AI引发的认知不公正的多种表现形式，更创造性地提出了“生成式解释学抹除”这一概念，深刻揭示了大型语言模型可能对非西方认识论和集体意义建构造成的深层次影响。这对于理解AI的文化和认识论风险，以及推动更具包容性的AI发展具有指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 认识到人工智能相关的认知不公正日益受到关注，且其来源多样，包括技术不透明、偏见自动化、AI幻觉对人类信念的扭曲、全球治理中的排斥、算法暴力以及与对话式AI的互动。

**Method:** 1. 基于已提出的认知不公正通用分类法，结合技术哲学、政治哲学和社会认识论领域学者的研究，勾勒出人工智能背景下认知不公正的类型分类法。 2. 提出了一个关于人工智能背景下认知不公正的额外概念：“生成式解释学抹除”，并论证其为大型语言模型通过压制认识论和概念化差异来自动化“认识论灭绝”，从而损害集体意义建构的能力。

**Result:** 1. 提出了一个允许在AI领域映射认知不公正的分类法。 2. 提出了一个新颖的AI相关认知不公正形式：“生成式解释学抹除”，并阐明了其通过AI系统“无处不在的视角”劣势化非西方认识论，导致其认识论特殊性被侵蚀，进而逐步导致解释学抹除。

**Conclusion:** 本文的贡献在于提出了一个能够对AI领域中的认知不公正进行映射的分类法，并引入了一种新颖的AI相关认知不公正形式——生成式解释学抹除，强调了AI系统可能导致“认识论灭绝”和对非西方认识论的侵蚀。

> **ai_Abstract:** 本文旨在解决人工智能日益引发的认知不公正问题。作者首先基于现有研究，提出了一个AI背景下认知不公正的分类法，涵盖了从技术不透明到算法暴力等多种来源。其次，文章引入了一个新概念——“生成式解释学抹除”，指出大型语言模型可能通过其“无处不在的视角”压制非西方认识论，从而自动化“认识论灭绝”，侵蚀集体意义建构的能力，最终导致解释学上的抹除。本文的意义在于提供了一个识别和映射AI领域认知不公正的框架，并揭示了一种此前未被充分探讨的新型认知不公正形式。

> **摘要翻译:** 人工智能相关的认知不公正日益受到关注。对于机器学习模型而言，认知不公正的来源多种多样，包括认识论不透明、见证偏见的歧视性自动化、生成式人工智能幻觉对人类信念的扭曲，到全球人工智能治理中对全球南方的排斥、通过算法系统执行的官僚暴力，以及与对话式人工智能代理的互动。本文基于一个提议的认知不公正通用分类法，首先结合技术哲学、政治哲学和社会认识论领域学者的研究，勾勒出人工智能背景下认知不公正类型的分类法。其次，本文提出了人工智能背景下认知不公正的另一个概念：生成式解释学抹除。笔者认为，这种不公正自动化了“认识论灭绝”，即大型语言模型通过压制认识论和概念化方面的差异，损害了认知主体集体意义建构的能力。人工智能系统“无处不在的视角”在认识论上劣势化了非西方认识论，从而导致其认识论特殊性被侵蚀，并逐渐导致解释学抹除。这项工作的相关性在于其提出了一个允许在人工智能领域映射认知不公正的分类法，以及提出了一种新颖的与人工智能相关的认知不公正形式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [248] [Agent Safety Alignment via Reinforcement Learning](https://arxiv.org/abs/2507.08270)
> *智能体安全对齐通过强化学习*

*Zeyang Sha, Hanling Tian, Zhuoer Xu, Shiwen Cui, Changhua Meng, Weiqiang Wang* | **Category: cs.AI, cs.CR** | **Updated: 2025-07-11**

**Keywords:** LLM智能体安全, 强化学习, 工具使用, 安全对齐, 沙盒环境

**Comment:** 

> **TL;DR:** 针对使用工具的LLM智能体的新安全风险，本文提出了首个统一的安全对齐框架，通过结构化推理和沙盒强化学习来处理用户和工具引发的威胁，并在保持实用性的同时显著提高了安全性。

**AI_Comments:** 这篇论文的创新点在于提出了首个针对工具使用LLM智能体的统一安全对齐框架，并结合了强化学习和沙盒环境来解决用户和工具双重渠道带来的安全威胁。其贡献在于证明了安全性和实用性可以同时优化，这对于未来LLM智能体的安全部署至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 具备工具使用能力的自主大型语言模型（LLM）智能体带来了超越传统对话滥用的新型安全风险。这些智能体容易受到用户引发的威胁（如对抗性提示）和工具引发的威胁（如受损工具的恶意输出）。

**Method:** 本文提出了首个针对工具使用智能体的统一安全对齐框架，通过结构化推理和沙盒强化学习使模型能够处理两种威胁。该框架引入了一个三模态分类法（良性、恶意、敏感，适用于用户提示和工具响应），并定义了一个策略驱动的决策模型。它采用定制设计的沙盒环境，模拟真实世界工具执行并允许细粒度奖励塑形。

**Result:** 通过对Agent SafetyBench、InjecAgent和BFCL等公共和自建基准的广泛评估，本文证明了其安全对齐智能体在保持良性任务强大实用性的同时，显著提高了对安全威胁的抵抗力。结果表明安全性和有效性可以联合优化。

**Conclusion:** 结果表明安全性和有效性可以联合优化，为自主LLM智能体的可信部署奠定了基础。

> **ai_Abstract:** 本文针对具备工具使用能力的自主LLM智能体面临的用户和工具引发的新型安全风险，提出了首个统一的安全对齐框架。该框架结合了结构化推理和沙盒强化学习，通过三模态分类法和策略驱动的决策模型，并利用定制沙盒环境进行模拟和奖励塑形。实验证明，该方法显著提升了智能体对安全威胁的抵抗力，同时保持了良好的任务效用，为LLM智能体的可信部署奠定了基础。

> **摘要翻译:** 具备工具使用能力的自主大型语言模型（LLM）智能体的出现引入了超越传统对话滥用的新型安全风险。这些被授权执行外部功能的智能体容易受到用户引发的威胁（例如，对抗性提示）和工具引发的威胁（例如，来自受损工具的恶意输出）。在本文中，我们提出了首个针对工具使用智能体的统一安全对齐框架，通过结构化推理和沙盒强化学习使模型能够处理两种威胁。我们引入了一个三模态分类法，包括用户提示和工具响应的良性、恶意和敏感，并定义了一个策略驱动的决策模型。我们的框架采用定制设计的沙盒环境，模拟真实世界工具执行并允许细粒度奖励塑形。通过对Agent SafetyBench、InjecAgent和BFCL等公共和自建基准的广泛评估，我们证明了我们的安全对齐智能体在保持良性任务强大实用性的同时，显著提高了对安全威胁的抵抗力。我们的结果表明安全性和有效性可以联合优化，为自主LLM智能体的可信部署奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [308] [Human Creativity and AI](https://arxiv.org/abs/2507.08001)
> *人类创造力与人工智能*

*Shengyi Xie* | **Category: cs.AI, cs.HC** | **Updated: 2025-04-25**

**Keywords:** 人机创造力, 创造力哲学, 认知神经科学, 心理学, 人工智能

**Comment:** 

> **TL;DR:** 本文探讨了在人工智能发展背景下，AI是否能展现创造力的问题，通过回顾心理学、认知神经科学和创造力哲学的研究来分析。

**AI_Comments:** 这篇论文的重要性在于它尝试从多学科角度（心理学、认知神经科学、哲学）深入探讨人工智能与人类创造力之间的复杂关系，这对于理解未来AI的能力边界及其对人类社会的影响具有重要意义。其创新之处在于将AI发展作为重新审视创造力哲学的核心语境。

<details>
  <summary>Details</summary>

**Motivation:** 探讨在人工智能技术发展背景下，AI是否能够展现创造力这一核心问题。

**Method:** 本文通过调查心理学、认知神经科学和创造力哲学领域的当代研究，回顾创造力哲学的历史视角，探索心理学进步对创造力研究的影响，并分析创造力的各种定义，审视自然主义和认知神经科学对创造力概念的回应。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在探讨在人工智能技术发展背景下，AI是否能展现创造力。文章通过调查心理学、认知神经科学和创造力哲学领域的当代研究，回顾创造力哲学的历史视角，分析创造力的定义，并审视自然主义和认知神经科学对创造力概念的回应。

> **摘要翻译:** 随着科学技术的进步，创造力哲学经历了重大的重新诠释。本文调查了心理学、认知神经科学和创造力哲学领域的当代研究，特别是在人工智能（AI）技术发展的背景下。它旨在解决一个核心问题：人工智能能否展现创造力？本文回顾了创造力哲学的历史视角，并探讨了心理学进步对创造力研究的影响。此外，它还分析了创造力的各种定义，并审视了自然主义和认知神经科学对创造力概念的回应。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [328] [TableReasoner: Advancing Table Reasoning Framework with Large Language Models](https://arxiv.org/abs/2507.08046)
> *TableReasoner: 推进大型语言模型在表格推理框架中的应用*

*Sishi Xiong, Dakai Wang, Yu Zhao, Jie Zhang, Changzai Pan, Haowei He, Xiangyu Li, Wenhan Chang, Zhongjiang He, Shuangyong Song, Yongxiang Li* | **Category: cs.AI** | **Updated: 2025-07-10**

**Keywords:** 表格问答, 大型语言模型, 表格推理, 模式链接, 迭代思考

**Comment:** 

> **TL;DR:** TableReasoner是一个基于大型语言模型和编程的表格问答框架，通过结构化和语义化表示、多步模式链接以及迭代思考架构，解决了真实世界表格数据的挑战，并在SemEval-2025 Task 8中获得第一名。

**AI_Comments:** TableReasoner的创新点在于其结合了LLM和编程范式来处理TQA任务，特别是通过引入结合结构和语义的“模式”以及“多步模式链接”来有效处理大型、复杂且可能存在歧义的表格数据。其迭代思考架构也增强了推理的鲁棒性。在SemEval-2025 Task 8中取得第一名，证明了其在实际应用中的高效性和准确性，为表格问答领域提供了有价值的进展。

<details>
  <summary>Details</summary>

**Motivation:** 表格问答（TQA）任务面临真实世界表格数据固有的挑战，包括数据量大、列语义不完整以及实体歧义问题。

**Method:** 本文提出了一个名为TableReasoner的、由大型语言模型（LLM）驱动且基于编程的表格推理框架。它通过结合结构和语义表示的模式来建模表格，实现对大型表格的整体理解和高效处理。设计了一个多步模式链接方案，以派生出只保留查询相关信息的聚焦表格模式，从而消除歧义并减轻幻觉。此外，将推理工作流整合到迭代思考架构中，允许思考、推理和反思的增量循环。

**Result:** TableReasoner系统在SemEval-2025 Task 8的两个子任务中均获得第一名。

**Conclusion:** TableReasoner框架通过其创新的模式建模、多步模式链接和迭代思考架构，成功克服了真实世界表格问答的挑战，并在国际竞赛中展现了卓越的性能。

> **ai_Abstract:** 本文介绍了一个名为TableReasoner的表格问答系统，旨在解决真实世界表格数据在TQA任务中面临的挑战，如数据量大、语义不完整和实体歧义。TableReasoner是一个由LLM驱动并基于编程的框架，它通过结合结构和语义的模式来理解表格，并采用多步模式链接生成聚焦的、与查询相关的表格模式，以减少歧义和幻觉。此外，该系统融入了迭代思考架构。TableReasoner在SemEval-2025 Task 8的两项子任务中均取得了第一名的成绩。

> **摘要翻译:** 本文介绍了我们为表格问答（TQA）开发的系统。TQA任务面临真实世界表格数据特性的挑战，例如数据量大、列语义不完整和实体歧义。为了解决这些问题，我们提出了一个由大型语言模型（LLM）驱动且基于编程的表格推理框架，命名为TableReasoner。它使用结合了结构和语义表示的模式来建模表格，从而实现对大型表格的整体理解和高效处理。我们设计了一个多步模式链接方案，以派生出只保留查询相关信息的聚焦表格模式，从而消除歧义并减轻幻觉。这种聚焦的表格模式为查询细化和编程提供了精确且充分的表格细节。此外，我们将推理工作流整合到迭代思考架构中，允许思考、推理和反思的增量循环。我们的系统在SemEval-2025 Task 8的两个子任务中均获得第一名。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [329] [Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework](https://arxiv.org/abs/2408.08054)
> *Text2BIM：基于大型语言模型的多智能体框架生成建筑模型*

*Changyu Du, Sebastian Esser, Stavros Nousias, André Borrmann* | **Category: cs.AI, cs.CL, cs.SE** | **Updated: 2025-07-11**

**Keywords:** LLM, BIM, 多智能体, 自然语言处理, 建筑模型生成

**Comment:** Journal of Computing in Civil Engineering

> **TL;DR:** Text2BIM是一个基于LLM的多智能体框架，能通过自然语言指令生成高质量的3D BIM模型，简化传统BIM创作过程。

**AI_Comments:** 该论文提出了一种创新的方法，利用LLM多智能体框架将自然语言转化为BIM模型，显著降低了BIM建模的门槛。引入规则检查器进行模型质量迭代优化是其亮点，提升了生成模型的实用性。这对于推动BIM在AEC行业的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的BIM创作过程要求设计师掌握复杂繁琐的建模命令，增加了认知负担，阻碍了BIM和模型化设计在AEC行业的普及。

**Method:** 本文提出了Text2BIM，一个基于大型语言模型（LLM）的多智能体框架。该框架协调多个LLM智能体协同推理，将文本用户输入转化为调用BIM创作工具API的命令式代码，从而生成可编辑的BIM模型。此外，引入了基于规则的模型检查器，利用预定义领域知识指导LLM智能体解决模型问题并迭代改进模型质量。

**Result:** 实验结果表明，Text2BIM方法能够有效生成高质量、结构合理的建筑模型，并与用户输入的抽象概念保持一致。

**Conclusion:** 该研究成功展示了通过自然语言聊天进行BIM建模的潜力，并开发了集成到Vectorworks的交互式软件原型。

> **ai_Abstract:** Text2BIM是一个基于大型语言模型的多智能体框架，旨在通过自然语言指令简化3D BIM模型的生成过程。它通过协调多个LLM智能体将文本输入转化为BIM工具的API调用，并结合规则检查器迭代优化模型质量。实验证明该方法能高效生成高质量、结构合理的BIM模型，有效降低了设计师的认知负担，促进了BIM在AEC行业的应用。

> **摘要翻译:** 传统的BIM创作过程通常要求设计师掌握复杂繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使设计过程复杂化，并阻碍了BIM和基于模型的设计在AEC（建筑、工程和施工）行业的采用。为了更直观地表达设计意图，我们提出了Text2BIM，一个基于大型语言模型（LLM）的多智能体框架，可以根据自然语言指令生成3D建筑模型。该框架协调多个LLM智能体进行协作和推理，将文本用户输入转换为调用BIM创作工具API的命令式代码，从而直接在软件中生成具有内部布局、外部围护结构和语义信息的可编辑BIM模型。此外，在智能体工作流程中引入了基于规则的模型检查器，利用预定义的领域知识指导LLM智能体解决生成模型中的问题并迭代改进模型质量。进行了大量实验，比较和分析了所提出框架下三种不同LLM的性能。评估结果表明，我们的方法可以有效地生成高质量、结构合理的建筑模型，这些模型与用户输入指定的抽象概念保持一致。最后，开发了一个交互式软件原型，将该框架集成到BIM创作软件Vectorworks中，展示了通过聊天进行建模的潜力。代码可在以下网址获取：https://github.com/dcy0577/Text2BIM

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [347] [A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](https://arxiv.org/abs/2507.08207)
> *用于对抗LLM越狱的动态斯塔克尔伯格博弈框架*

*Zhengye Han, Quanyan Zhu* | **Category: cs.AI** | **Updated: 2025-07-10**

**Keywords:** LLM越狱, 斯塔克尔伯格博弈, 智能体AI, 紫罗兰智能体, 对抗性防御

**Comment:** 

> **TL;DR:** 本文提出了一个动态斯塔克尔伯格博弈框架，并引入“紫罗兰智能体”来主动防御LLM越狱攻击，该智能体利用快速探索随机树（RRT）模拟攻击轨迹并预防有害输出。

**AI_Comments:** 本文的创新点在于将动态斯塔克尔伯格博弈理论引入LLM越狱防御领域，并提出了“紫罗兰智能体”这一具身AI解决方案。通过利用快速探索随机树（RRT）进行对抗性探索和主动干预，该方法为LLM安全提供了一个新颖且原则性的防御范式，有望有效提升模型对抗越狱攻击的能力。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）越来越多地部署在关键应用中，越狱（即攻击者操纵模型以绕过安全机制）已成为一个重大问题。

**Method:** 本文提出了一个动态斯塔克尔伯格博弈框架，用于建模LLM越狱中攻击者和防御者之间的交互。该框架将提示-响应动态视为一个序列式扩展型博弈，其中防御者作为领导者，在预测攻击者最优响应的同时制定策略。研究提出了一种新颖的智能体AI解决方案——“紫罗兰智能体”，它利用快速探索随机树（RRT）整合了对抗性探索和防御策略。紫罗兰智能体主动模拟潜在的攻击轨迹并积极干预以防止有害输出。

**Result:** 该方法为分析对抗性动态提供了一种原则性的方法。

**Conclusion:** 该方法为减轻越狱风险提供了一个基础。

> **ai_Abstract:** 鉴于大型语言模型（LLM）在关键应用中面临越狱攻击的严峻挑战，本文提出了一种动态斯塔克尔伯格博弈框架，以建模攻击者与防御者之间的互动。该框架将提示-响应过程视为一个序列式博弈，防御者作为领导者先行决策。为应对此挑战，论文引入了“紫罗兰智能体”这一创新型智能AI解决方案，它结合了对抗性探索和防御策略，并利用快速探索随机树（RRT）主动模拟潜在攻击路径，从而预防有害输出。此方法为分析对抗性动态提供了一种原则性途径，并为缓解越狱风险奠定了基础。

> **摘要翻译:** 随着大型语言模型（LLMs）越来越多地部署在关键应用中，越狱（即攻击者操纵模型以绕过安全机制）已成为一个重大问题。本文提出了一个动态斯塔克尔伯格博弈框架，用于建模LLM越狱中攻击者和防御者之间的交互。该框架将提示-响应动态视为一个序列式扩展型博弈，其中防御者作为领导者，在预测攻击者最优响应的同时制定策略。我们提出了一种新颖的智能体AI解决方案——“紫罗兰智能体”，它利用快速探索随机树（RRT）整合了对抗性探索和防御策略。紫罗兰智能体主动模拟潜在的攻击轨迹并积极干预以防止有害输出。这种方法为分析对抗性动态提供了一种原则性的方法，并为减轻越狱风险提供了一个基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [366] [Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers](https://arxiv.org/abs/2503.01163)
> *基于Bandit的提示设计策略选择改进提示优化器*

*Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari, Kento Uchida, Shinichi Shirakawa* | **Category: cs.AI, cs.CL, cs.HC, cs.LG, cs.NE** | **Updated: 2025-07-11**

**Keywords:** 提示优化, 提示设计策略, Bandit算法, Thompson采样, 大型语言模型

**Comment:** Accepted to ACL 2025 Findings

> **TL;DR:** 该研究引入了OPTS，一种通过显式选择提示设计策略来改进提示优化器（如EvoPrompt）的方法，实验表明策略选择显著提高了性能，其中基于Thompson采样的机制效果最佳。

**AI_Comments:** 这篇论文的创新点在于提出了通过显式选择提示设计策略来优化提示，而非依赖LLM的隐式选择。引入Thompson采样等bandit算法来处理策略选择问题，为提示优化提供了一种新颖且有效的方法。这对于提升LLM在各种任务上的表现具有重要意义，尤其是在需要高质量提示的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有的提示优化方法虽然能找到有效提示，但与人类专家精心设计的复杂提示仍有差距。尽管APET尝试将提示设计策略纳入优化过程，但其隐式选择机制可能因LLM有限的优化能力而次优。本研究旨在通过显式策略选择来改进提示优化。

**Method:** 本研究引入了OPTS（Optimizing Prompts with sTrategy Selection），该方法实现了提示设计的显式选择机制。提出了三种机制，其中包括一种基于Thompson采样的方法，并将其集成到知名的提示优化器EvoPrompt中。在BIG-Bench Hard上，使用Llama-3-8B-Instruct和GPT-4o mini两种LLM进行了实验。

**Result:** 实验结果表明，提示设计策略的选择显著提高了EvoPrompt的性能。其中，基于Thompson采样的机制取得了最佳的整体效果。

**Conclusion:** 通过显式选择提示设计策略，可以有效改进提示优化器的性能，尤其是基于Thompson采样的方法表现突出。

> **ai_Abstract:** 本论文提出了OPTS（Optimizing Prompts with sTrategy Selection），旨在通过显式选择提示设计策略来改进大型语言模型（LLM）的提示优化。针对现有方法中LLM隐式选择策略可能次优的问题，OPTS引入了多种显式选择机制，包括一种基于Thompson采样的方法，并将其整合到流行的提示优化器EvoPrompt中。在对Llama-3-8B-Instruct和GPT-4o mini进行的实验中，结果表明显式策略选择显著提升了EvoPrompt的性能，其中Thompson采样机制表现最佳。

> **摘要翻译:** 提示优化旨在搜索有效的提示以增强大型语言模型（LLM）的性能。尽管现有的提示优化方法已经发现了有效的提示，但它们通常与人类专家精心设计的复杂提示有所不同。提示设计策略代表了提高提示性能的最佳实践，可能是改进提示优化的关键。最近，一种名为自主提示工程工具箱（APET）的方法已将各种提示设计策略整合到提示优化过程中。在APET中，由于提示设计策略可能产生负面影响，因此需要LLM隐式选择和应用适当的策略。这种隐式选择可能因LLM有限的优化能力而次优。本文介绍了“通过策略选择优化提示”（OPTS），它实现了提示设计的显式选择机制。我们提出了三种机制，其中包括一种基于Thompson采样的方法，并将其集成到知名的提示优化器EvoPrompt中。使用BIG-Bench Hard对Llama-3-8B-Instruct和GPT-4o mini两种LLM进行了提示优化实验。我们的结果表明，提示设计策略的选择提高了EvoPrompt的性能，并且基于Thompson采样的机制取得了最佳的整体结果。我们的实验代码可在 https://github.com/shiralab/OPTS 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [375] [Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions](https://arxiv.org/abs/2507.08208)
> *LLM-Nash博弈中的推理与行为均衡：从思维模式到行动*

*Quanyan Zhu* | **Category: cs.AI, cs.GT** | **Updated: 2025-07-10**

**Keywords:** LLM-Nash, 博弈论, 有限理性, 推理均衡, 大型语言模型

**Comment:** 

> **TL;DR:** 引入LLM-Nash框架，一个博弈论模型，其中LLM代理通过选择推理提示来指导决策，捕获有限理性并展示推理均衡如何偏离经典纳什结果。

**AI_Comments:** 该论文提出了一个创新的博弈论框架，将经典博弈论与大型语言模型的能力相结合，特别解决了假设完全理性的局限性。通过通过提示选择明确建模推理过程，它为理解AI系统和人机协作在认知约束下的战略交互开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 经典博弈论假设代理是完全理性的效用最大化者，而本研究旨在通过明确建模推理过程来捕捉有限理性。

**Method:** 引入了LLM-Nash框架，这是一个博弈论模型，其中代理通过大型语言模型（LLMs）选择推理提示来指导决策。均衡定义在提示空间上，行动是LLM推理的行为输出。

**Result:** 通过示例展示了推理均衡可以偏离经典的纳什结果，并能够研究认知约束、思维模式表达性和认知学习。

**Conclusion:** LLM-Nash框架为LLM驱动系统中的战略交互提供了一个新基础，通过建模有限理性和展示不同的均衡。

> **ai_Abstract:** 本文介绍了LLM-Nash框架，这是一个博弈论模型，旨在通过让大型语言模型（LLMs）选择推理提示来指导决策，从而捕获代理的有限理性。与假设完全理性的传统博弈论不同，该框架明确地建模了推理过程，并在提示空间上定义了均衡。研究表明，在这种框架下的推理均衡可以偏离经典的纳什结果，为LLM驱动系统中的战略交互奠定了新基础。

> **摘要翻译:** 我们引入了LLM-Nash框架，这是一个博弈论模型，其中代理选择推理提示来指导通过大型语言模型（LLMs）进行的决策。与假设完全理性的效用最大化代理的经典博弈不同，该框架通过明确建模推理过程来捕获有限理性。均衡定义在提示空间上，行动作为LLM推理的行为输出而出现。这种方法使得能够研究认知约束、思维模式表达性和认知学习。通过说明性示例，我们展示了推理均衡如何偏离经典的纳什结果，为LLM驱动系统中的战略交互提供了一个新基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [388] [From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration](https://arxiv.org/abs/2507.08210)
> *从好奇到能力：世界模型如何与探索动力学相互作用*

*Fryderyk Mantiuk, Hanqi Zhou, Charley M. Wu* | **Category: cs.AI** | **Updated: 2025-07-10**

**Keywords:** 好奇心, 能力, 探索, 世界模型, 强化学习

**Comment:** 

> **TL;DR:** 本研究探讨了智能体如何平衡好奇心（获取新知识）和能力（控制环境）以驱动探索。研究比较了两种模型，一种使用手工状态抽象（Tabular），另一种学习内部世界模型（Dreamer）。结果表明，好奇心和能力可以引导不同的探索模式，并且两者兼顾能提升探索效率。Dreamer智能体展示了探索与表示学习之间的双向互动，这与好奇心和能力的共同发展相似。研究将适应性探索形式化为追求未知与可控之间的平衡，为认知理论和强化学习提供了见解。

**AI_Comments:** 该研究将认知科学中的好奇心和能力概念与强化学习中的探索机制相结合，提出了一个有见地的框架。通过比较两种不同的模型，研究揭示了内部表征在平衡这两种驱动力中的关键作用。特别是Dreamer模型的发现，即探索与表征学习之间的双向互动，为理解智能体的自主学习过程提供了新的思路。然而，研究中使用的“手工状态抽象”可能限制了其在更复杂、高维环境中的普适性。未来的工作可以进一步探索更灵活的表征学习方法，以及这些方法如何影响好奇心和能力的动态平衡。总的来说，这项工作在理论和实践上都具有重要意义，为设计更智能、更适应性强的AI代理提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 智能体在探索世界时，需要平衡好奇心（获取新知识）和能力（控制环境）。本研究旨在探究内部表征（世界模型）如何调节好奇心和能力之间的权衡，以实现有效的探索。

**Method:** 研究比较了两种模型基智能体：一种使用手工状态抽象（Tabular），另一种通过学习内部世界模型（Dreamer）来探索环境。

**Result:** Tabular智能体表明，好奇心和能力会引导不同的探索模式，并且同时优先考虑两者可以改善探索。Dreamer智能体揭示了探索与表示学习之间的双向互动，这与好奇心和能力的共同发展相似。

**Conclusion:** 适应性探索被形式化为追求未知与可控之间的平衡，研究结果为认知理论和高效强化学习提供了见解。

> **ai_Abstract:** 本研究探讨了智能体在探索环境中如何平衡好奇心和能力。通过比较使用手工状态抽象（Tabular）和学习内部世界模型（Dreamer）的两种智能体，研究发现好奇心和能力会影响探索模式，并且两者兼顾可以提升探索效率。Dreamer智能体展示了探索与表示学习之间的相互作用，这与好奇心和能力的协同发展相似。研究将适应性探索定义为在追求未知和可控之间的平衡，为认知科学和强化学习领域提供了新的视角。

> **摘要翻译:** 智能体在探索世界时，需要平衡好奇心（获取新知识）和能力（控制环境）。从玩耍的孩子到实验室里的科学家，智能体必须平衡好奇心（寻求知识的驱动力）与能力（掌握和控制环境的驱动力）。我们将内在动机的认知理论与强化学习相结合，探讨了不断发展的内部表征如何调节好奇心（新颖性或信息增益）与能力（赋权）之间的权衡。我们比较了两种使用手工状态抽象（表格）或学习内部世界模型（Dreamer）的模型基智能体。表格智能体表明，好奇心和能力会引导不同的探索模式，并且同时优先考虑两者可以改善探索。Dreamer智能体揭示了探索与表示学习之间的双向互动，这与好奇心和能力的共同发展相似。我们的研究结果将适应性探索形式化为追求未知与可控之间的平衡，为认知理论和高效强化学习提供了见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [408] [Grounding Methods for Neural-Symbolic AI](https://arxiv.org/abs/2507.08216)
> *神经符号人工智能的接地方法*

*Rodrigo Castellano Ontiveros, Francesco Giannini, Marco Gori, Giuseppe Marra, Michelangelo Diligenti* | **Category: cs.AI** | **Updated: 2025-07-10**

**Keywords:** 神经符号AI, 逻辑接地, 向后链接, 可扩展性, 表达能力

**Comment:** 

> **TL;DR:** 该论文提出了一种参数化的接地方法，可以推广经典的向后链接，并允许在表达能力和可扩展性之间进行权衡，这对于神经符号（NeSy）方法很重要。

**AI_Comments:** 该研究解决了神经符号（NeSy）AI 的一个关键挑战，即在保持逻辑推理能力的同时提高可扩展性。通过引入一个参数化的接地方法框架，该方法能够统一现有的技术并提供新的选择，以平衡表达能力和计算效率。实验结果强调了接地策略的重要性，为未来 NeSy 系统的设计和优化提供了有价值的见解。然而，该研究可能需要进一步探讨不同参数选择对具体任务的影响，以及在更复杂的真实世界场景中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经符号（NeSy）方法在处理输入实体和复杂关系时面临可扩展性挑战。一些方法使用详尽的推导，导致组合爆炸，而其他方法则依赖于启发式选择，但缺乏理论依据和信息保留保证。

**Method:** 提出了一种参数化的接地方法，该方法推广了经典的向后链接，并允许在表达能力和可扩展性之间进行权衡。

**Result:** 实验结果表明，接地标准的选定对于 NeSy 方法的性能至关重要，其重要性不亚于 NeSy 方法本身。

**Conclusion:** 接地方法的选择对神经符号（NeSy）方法的性能有重大影响，与 NeSy 方法本身同等重要。

> **ai_Abstract:** 本文提出了一种新的神经符号（NeSy）AI 方法，通过参数化接地技术来解决可扩展性问题。该方法以多跳符号推理为灵感，推广了经典的向后链接，并允许用户在表达能力和计算效率之间进行权衡。实验证明，接地策略的选择对 NeSy 系统的整体性能至关重要。

> **摘要翻译:** 一类重要的神经符号（NeSy）方法采用机器学习器来处理输入实体，同时依赖于基于一阶逻辑的推理器来表示和处理实体之间更复杂的关系。逻辑接地在这些方法中起着基本作用，它使用实体（子）集来确定逻辑规则的相关替换。一些 NeSy 方法使用所有可能替换的详尽推导，保留了逻辑知识的全部表达能力。这导致需要考虑的接地公式数量呈组合式爆炸增长，因此极大地限制了它们的可扩展性。其他方法则依赖于基于启发式的选择性推导，这通常在计算上更有效，但缺乏理论依据，也无法保证保留提供给推理器以及从推理器返回的信息。受多跳符号推理的启发，本文提出了一种参数化的接地方法家族，推广了经典的向后链接。通过对该家族进行不同的选择，我们可以得到常用的接地方法作为特例，并控制推理器的表达能力和可扩展性之间的权衡。实验结果表明，接地标准的选定往往与 NeSy 方法本身同等重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [434] [Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach](https://arxiv.org/abs/2507.08217)
> *面向多模态数据的量子联邦学习：一种模态无关的方法*

*Atit Pokharel, Ratun Rahman, Thomas Morris, Dinh C. Nguyen* | **Category: cs.AI** | **Updated: 2025-07-10**

**Keywords:** 量子联邦学习,多模态学习,量子纠缠,缺失模态无关,量子机器学习

**Comment:** This paper was presented at BEAM with CVPR 2025

> **TL;DR:** 提出了一种新的多模态量子联邦学习方法，使用量子纠缠进行中间融合，并引入了缺失模态无关（MMA）机制来处理缺失模态，提高了模型准确性。

**AI_Comments:** 该研究首次提出了针对QFL的多模态方法，并解决了缺失模态的问题，具有重要的理论和实践意义。所提出的MMA机制能够提高模型的鲁棒性。然而，实际部署的计算成本和量子资源的消耗有待进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有的量子联邦学习（QFL）框架主要集中在单模态系统，限制了其在处理多模态数据方面的应用。为了解决这一问题，需要一种能够处理多模态数据的QFL方法。

**Method:** 提出了一种新的多模态量子联邦学习方法，该方法使用量子纠缠进行中间融合，并引入了缺失模态无关（MMA）机制来处理训练过程中可能出现的缺失模态问题，通过隔离未训练的量子电路来确保训练的稳定性。

**Result:** 与现有方法相比，所提出的多模态QFL方法（包括MMA机制）在独立同分布（IID）数据分布上提高了6.84%的准确性，在非独立同分布（non-IID）数据分布上提高了7.25%的准确性。

**Conclusion:** 所提出的多模态QFL方法通过引入量子纠缠进行中间融合和MMA机制来处理缺失模态，能够有效地提高模型在多模态数据上的训练性能和准确性，克服了现有方法的局限性。

> **ai_Abstract:** 本研究提出了一种新颖的多模态量子联邦学习（QFL）方法，以解决现有QFL框架在处理多模态数据方面的局限性。该方法利用量子纠缠进行中间融合，并引入了缺失模态无关（MMA）机制来处理训练过程中可能出现的缺失模态问题，确保了训练的稳定性。仿真结果表明，该方法在IID和非IID数据分布上均显著提高了模型准确性。

> **摘要翻译:** 量子联邦学习（QFL）最近被引入，以实现跨量子处理器（客户端）的分布式隐私保护量子机器学习（QML）模型训练。尽管有近期的研究努力，但现有的QFL框架主要集中在单模态系统，限制了它们在通常自然涉及多种模态的实际任务中的适用性。为了填补这一重大空白，我们首次提出了一种新颖的多模态方法，该方法专门针对具有中间融合的QFL设置，并使用量子纠缠。此外，为了解决多模态QFL的一个主要瓶颈，即在训练过程中某些模态的缺失会降低模型性能，我们引入了一种缺失模态无关（MMA）机制，该机制可以隔离未训练的量子电路，确保在没有损坏状态的情况下进行稳定训练。仿真结果表明，与最先进的方法相比，所提出的具有MMA的多模态QFL方法在独立同分布（IID）和非独立同分布（non-IID）数据分布上分别提高了6.84%和7.25%的准确性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [468] [Abductive Computational Systems: Creative Abduction and Future Directions](https://arxiv.org/abs/2507.08264)
> *溯因计算系统：创造性溯因与未来方向*

*Abhinav Sood, Kazjon Grace, Stephen Wan, Cecile Paris* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** 溯因推理,计算系统,创造性假设,认识论,设计

**Comment:** Published in the 16th International Conference on Computational
  Creativity, ICCC25. Accepted Paper in
  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025abductive.pdf

> **TL;DR:** 该论文回顾了溯因推理在认识论、科学和设计中的讨论，并分析了各种计算系统如何使用溯因推理，指出当前的理论和计算方法在生成创造性假设方面存在不足，并提出了未来研究方向以改进计算系统中的创造性溯因推理。

**AI_Comments:** 该论文对溯因推理在计算系统中的应用进行了有价值的分析，并指出了当前方法的局限性。未来研究方向的识别为该领域的发展提供了清晰的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 溯因推理在科学、设计和艺术领域都有提及，但其理解在不同领域各不相同。论文旨在分析计算系统如何使用溯因推理，并识别改进创造性溯因推理的未来研究方向。

**Method:** 通过回顾溯因推理在认识论、科学和设计中的讨论，并分析各种计算系统如何使用溯因推理来研究该问题。

**Result:** 分析表明，当前的理论和计算方法在生成创造性假设方面存在不足。理论框架未能提供生成创造性溯因假设的直接模型，而计算系统主要实现的是三段论形式的溯因推理。

**Conclusion:** 为了在计算系统中推进创造性溯因推理，需要解决当前理论和计算实现中生成创造性假设的不足之处，并为未来的研究指明具体方向。

> **ai_Abstract:** 本文探讨了溯因推理在不同领域的应用及其在计算系统中的实现。研究发现，当前的理论和计算方法在生成创造性假设方面存在局限性，并提出未来研究方向以改进计算系统中的创造性溯因推理能力。

> **摘要翻译:** 溯因推理，即为观测推断解释的推理，经常在科学、设计和艺术背景下被提及，但其理解在这些领域各不相同。本文回顾了溯因推理在认识论、科学和设计中的讨论，然后分析了各种计算系统如何使用溯因推理。我们的分析表明，无论是理论账户还是计算实现，溯因推理在充分解决生成创造性假设方面都存在不足。理论框架没有提供生成创造性溯因假设的直接模型，计算系统在很大程度上实现了溯因推理的三段论形式。我们将溯因计算系统分解为组件，并最后确定了未来研究的具体方向，这些方向可以推进计算系统中创造性溯因推理的现状。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [498] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
> *开源规划与控制系统，使用语言代理实现自主科学发现*

*Licong Xu, Milind Sarkar, Anto I. Lonappan, Íñigo Zubeldia, Pablo Villanueva-Domingo, Santiago Casas, Christian Fidler, Chetana Amancharla, Ujjwal Tiwari, Adrian Bayer, Chadi Ait Ekioui, Miles Cranmer, Adrian Dimitrov, James Fergusson, Kahaan Gandhi, Sven Krippendorf, Andrew Laverick, Julien Lesgourgues, Antony Lewis, Thomas Meier, Blake Sherwin, Kristen Surrao, Francisco Villaescusa-Navarro, Chi Wang, Xueqing Xu, Boris Bolliet* | **Category: cs.AI, astro-ph.IM, cs.CL, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 多代理系统,大型语言模型,科学研究自动化,规划与控制,宇宙学

**Comment:** Accepted contribution to the ICML 2025 Workshop on Machine Learning
  for Astrophysics. Code: https://github.com/CMBAgents/cmbagent Videos:
  https://www.youtube.com/@cmbagent HuggingFace:
  https://huggingface.co/spaces/astropilot-ai/cmbagent Cloud:
  https://cmbagent.cloud

> **TL;DR:** 一个由约30个大型语言模型（LLM）代理组成的系统，采用规划与控制策略来编排代理工作流，实现了无人干预的科学研究自动化。

**AI_Comments:** 该研究展示了一个利用LLM代理实现自主科学研究的创新方法，特别是在无人干预和自动化复杂任务方面的能力令人印象深刻。代码开源和易于访问的部署方式也促进了该技术的进一步发展和应用。

<details>
  <summary>Details</summary>

**Motivation:** 旨在自动化科学研究任务，实现自主科学发现。

**Method:** 构建了一个包含约30个LLM代理的多代理系统（cmbagent），采用规划与控制策略来协调代理工作流，代理们负责检索文献、编写代码、解释结果和评估输出，系统能够本地执行代码。

**Result:** 成功将cmbagent应用于一项博士级别的宇宙学任务（利用超新星数据测量宇宙学参数），并在两个基准数据集上进行了评估，结果显示其性能优于最先进的LLM。

**Conclusion:** cmbagent系统成功实现了科学研究任务的自动化，并在一项复杂的宇宙学任务中表现出色，证明了其在自主科学发现方面的潜力。

> **ai_Abstract:** 本文介绍了一个名为cmbagent的开源多代理系统，该系统利用约30个大型语言模型（LLM）代理，通过规划与控制策略实现科学研究任务的自动化，无需人工干预。该系统能够执行代码，并已成功应用于宇宙学参数测量任务，性能优于现有LLM。

> **摘要翻译:** 我们提出了一个用于自动化科学研究任务的多代理系统，cmbagent (https://github.com/CMBAgents/cmbagent)。该系统由约30个大型语言模型（LLM）代理组成，并实施了一个规划与控制策略来协调代理工作流，在任何环节都没有人工干预。每个代理都专门负责不同的任务（对科学论文和代码库进行检索、编写代码、解释结果、评估其他代理的输出），并且系统能够本地执行代码。我们成功地将cmbagent应用于一项博士级别的宇宙学任务（使用超新星数据测量宇宙学参数），并在两个基准数据集上评估了其性能，发现其性能优于最先进的LLM。源代码可在GitHub上获取，也提供了演示视频，并且该系统已部署在HuggingFace上，并将可在云上使用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [508] [M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning](https://arxiv.org/abs/2507.08306)
> *M2-推理：赋予多模态大语言模型统一的通用和空间推理能力*

*Inclusion AI, :, Fudong Wang, Jiajia Liu, Jingdong Chen, Jun Zhou, Kaixiang Ji, Lixiang Ru, Qingpei Guo, Ruobing Zheng, Tianqi Li, Yi Yuan, Yifan Mao, Yuting Xiao, Ziping Ma* | **Category: cs.AI, cs.CL, cs.CV, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 多模态大语言模型, 空间推理, M2-Reasoning-7B, 强化学习, 数据管道

**Comment:** 31pages, 14 figures

> **TL;DR:** M2-Reasoning-7B 是一个在通用和空间推理方面表现出色的多模态大语言模型，它通过新的数据管道和动态多任务训练策略，在 8 个基准测试中取得了最先进的成果。

**AI_Comments:** 该研究成功地解决了多模态大语言模型在空间推理方面的局限性，通过创新的数据和训练方法实现了通用和空间推理能力的统一。模型在多个基准测试中取得领先地位，显示了其潜力和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型在处理动态空间交互方面存在不足，而这对于现实世界的应用至关重要。

**Method:** 引入 M2-Reasoning-7B 模型，该模型采用包含 294.2K 高质量数据样本的新型数据管道（用于冷启动微调和 RLVR），并结合了动态多任务训练策略和分步优化，以解决数据冲突并提供任务特定奖励。

**Result:** M2-Reasoning-7B 在通用和空间推理方面均设定了新的最先进水平，并在 8 个基准测试中展示了卓越的性能。

**Conclusion:** M2-Reasoning-7B 通过其创新的数据管道和训练策略，成功弥合了通用和空间推理之间的差距，并在多个基准测试中取得了最先进的成果。

> **ai_Abstract:** M2-Reasoning-7B 模型通过结合新颖的数据生成管道和动态多任务训练策略，显著提升了多模态大语言模型在通用和空间推理方面的能力，并在多个基准测试中取得了最先进的成果。

> **摘要翻译:** 近期，多模态大语言模型（MLLM）取得了显著进展，尤其是在通过带有可验证奖励的强化学习（RLVR）方面，这极大地增强了它们的推理能力。然而，仍然存在一个关键的不足：这些模型在动态空间交互方面表现不佳，而这对于现实世界的应用至关重要。为了弥合这一差距，我们引入了 M2-Reasoning-7B，一个旨在同时在通用和空间推理方面表现出色的模型。我们的方法融合了两项关键创新：（1）一个新颖的数据管道，生成了 294.2K 个高质量数据样本（168K 用于冷启动微调，126.2K 用于 RLVR），这些样本具有逻辑上连贯的推理轨迹并经过全面评估；（2）一个动态多任务训练策略，通过分步优化来缓解数据之间的冲突，并采用任务特定奖励来提供定制化的激励信号。这种精选数据和先进训练的结合，使得 M2-Reasoning-7B 在 8 个基准测试中设定了新的最先进水平（SOTA），在通用和空间推理领域均展现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [536] [Multi-Agent LLMs as Ethics Advocates in AI-Based Systems](https://arxiv.org/abs/2507.08392)
> *多智能体语言模型作为人工智能系统中的伦理倡导者*

*Asma Yamani, Malak Baslyman, Moataz Ahmed* | **Category: cs.AI, cs.CY** | **Updated: 2025-07-11**

**Keywords:** 伦理需求提炼,多智能体 LLM,伦理倡导者,需求工程,自动化伦理

**Comment:** 

> **TL;DR:** 通过引入多智能体语言模型中的伦理倡导者代理，自动生成伦理需求草案，以应对手动收集伦理需求的时间和资源限制，并在案例研究中证明了其有效性，但仍存在可靠性问题，需要人工反馈。

**AI_Comments:** 该研究巧妙地利用了多智能体 LLM 的能力来解决 AI 系统开发中的一个关键但充满挑战的方面——伦理需求提炼。通过引入“伦理倡导者”代理，该方法提供了一种自动化的解决方案，有可能提高效率和覆盖范围。然而，研究中提到的可靠性问题和对人工反馈的依赖性是至关重要的见解，突显了在将此类自动化工具应用于高风险领域（如伦理）时，人类监督和判断的持续必要性。这项工作的创新之处在于将 LLM 的生成能力应用于伦理领域，但其局限性在于需要进一步完善以确保结果的稳健性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 手动收集伦理需求耗时耗力且优先级低，需要一种更有效的方法来将伦理考量纳入系统开发。本研究旨在通过自动化方法解决这一挑战。

**Method:** 提出一个框架，在多智能体语言模型环境中引入一个伦理倡导者代理，该代理根据系统描述批评和提供伦理问题输入，以生成伦理需求草案。

**Result:** 案例研究表明，该框架能够捕获大部分由研究人员在访谈中识别出的伦理需求，并提出一些额外的相关需求，但同时也暴露了生成伦理需求方面的可靠性问题，强调了在敏感领域引入人工反馈的必要性。

**Conclusion:** 该框架能够促进伦理在需求工程过程中的更广泛应用，从而有助于开发更符合伦理的产品，但仍需结合人工反馈来解决可靠性问题。

> **ai_Abstract:** 本研究提出了一种新颖的框架，利用多智能体大型语言模型（LLM）中的“伦理倡导者”代理来自动生成伦理需求草案。该方法旨在克服手动收集伦理需求时面临的时间、资源限制和优先级低等挑战。通过两个案例研究的评估表明，该框架能有效捕获现有的伦理需求并提出新的相关需求，但同时也指出了在生成过程中存在的可靠性问题，强调了在这一敏感领域结合人工反馈的重要性。该研究有望推动伦理在需求工程中的应用，促进更符合伦理的产品的开发。

> **摘要翻译:** 将伦理纳入需求提炼过程对于创建符合伦理的系统至关重要。虽然手动提炼伦理需求是有效的，但它需要来自多个利益相关者的多样化输入，这可能由于时间和资源限制而具有挑战性。此外，在需求提炼过程中，它通常优先级较低。本研究提出了一种通过在多智能体大型语言模型环境中引入伦理倡导者代理来生成伦理需求草案的框架。该代理根据系统描述批评和提供关于伦理问题的输入。所提出的框架通过来自不同背景的两个案例研究进行了评估，证明了它能够捕获研究人员在 30 分钟访谈中识别出的大部分伦理需求，并提出了一些额外的相关需求。然而，它也凸显了在生成伦理需求方面的可靠性问题，强调了在这个敏感领域需要人工反馈。我们相信这项工作可以促进伦理在需求工程过程中的更广泛应用，最终带来更符合伦理的产品。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [560] [Why this and not that? A Logic-based Framework for Contrastive Explanations](https://arxiv.org/abs/2507.08454)
> *为什么是这个而不是那个？一个基于逻辑的对比解释框架*

*Tobias Geibinger, Reijo Jaakkola, Antti Kuusisto, Xinghan Liu, Miikka Vilander* | **Category: cs.AI, cs.LG, cs.LO, 68T27, 03B05, I.2.3; F.4.1** | **Updated: 2025-07-11**

**Keywords:** 对比解释, 逻辑框架, 原因识别, 命题逻辑, 计算复杂性

**Comment:** 20 pages, accepted to JELIA 2025

> **TL;DR:** 该研究提出了一个基于逻辑的框架，用于生成对比解释，回答“为什么是P而不是Q”的问题，通过比较P和Q的异同来找出原因，并分析了其计算复杂性。

**AI_Comments:** 该研究在对比解释领域提出了一个新颖的、基于逻辑的框架，通过明确比较原因来解决“为什么是P而不是Q”的问题。该框架的理论性质和计算复杂性分析具有重要意义，并且通过实际应用展示了其有效性。未来可以进一步探索该框架在更复杂的推理场景中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决“为什么是P而不是Q”这类对比解释问题，需要明确比较P和Q之间的差异以找出原因。

**Method:** 定义了几个与对比解释相关的典型问题，这些问题通过计算P和Q的原因并明确比较它们的差异来回答“为什么P而不是Q”这类问题。在命题逻辑的背景下研究了这些定义的性质，并分析了计算复杂性。使用答案集规划为CNF公式实现了这些问题。

**Result:** 该框架捕获了文献中现有的对比解释的一个基数最小化版本，并进行了计算复杂性分析。通过CNF公式的实现和示例展示了其在实践中的应用。

**Conclusion:** 该研究提出了一个基于逻辑的框架，用于生成对比解释，该框架能够捕获现有方法的一个基数最小化版本，并对计算复杂性进行了分析，通过实际应用展示了其有效性。

> **ai_Abstract:** 该论文提出了一个基于逻辑的框架，用于生成对比解释，以回答“为什么是P而不是Q”的问题。该框架通过计算P和Q的原因并明确比较它们的差异来工作。研究表明，该框架捕获了现有对比解释的基数最小化版本，并对计算复杂性进行了分析。此外，该研究还通过答案集规划实现了该框架，并提供了实际示例。

> **摘要翻译:** 我们定义了几个与对比解释相关的典型问题，每个问题都回答了“为什么是P而不是Q”形式的问题。这些问题计算P和Q的原因，并明确比较它们的差异。我们在命题逻辑的设定中研究了我们定义的基本性质。我们证明了，除其他外，我们的框架捕获了文献中现有对比解释的一个基数最小化版本。此外，我们还对这些问题的计算复杂性进行了广泛分析。我们还使用答案集规划为CNF公式实现了这些问题，并展示了几个演示其在实践中如何工作的示例。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [580] [From Language to Logic: A Bi-Level Framework for Structured Reasoning](https://arxiv.org/abs/2507.08501)
> *从语言到逻辑：一个结构化推理的双层框架*

*Keying Yang, Hao Wang, Kai Yang* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** 双层框架, 语言到逻辑, 结构化推理, 大型语言模型, 可解释性

**Comment:** 

> **TL;DR:** 提出一个将自然语言映射到逻辑的双层框架，通过高层任务抽象和低层逻辑生成，用于结构化推理，并在数学问题解决、问答和逻辑推理等领域实现显著的准确性提升。

**AI_Comments:** 该研究提出了一种新颖的双层框架，有效地解决了自然语言到逻辑表示的映射问题，从而实现了更准确、更透明的结构化推理。该方法在多个基准测试中取得了显著的性能提升，特别是准确性方面高达 40% 的增益，这表明了其在实际应用中的巨大潜力。框架的双层设计和端到端优化方法是其创新之处，提高了系统的可解释性和错误追踪能力，这对于构建可信赖的人工智能系统至关重要。未来的工作可以进一步探索该框架在更复杂推理任务和多模态数据上的应用。

<details>
  <summary>Details</summary>

**Motivation:** 解决在人工智能中，将非结构化的语言表达与形式化的逻辑表示联系起来的挑战，以实现对自然语言输入的结构化推理。

**Method:** 提出一个双层框架，首先由大型语言模型（LLM）将自然语言查询解析为指定问题类型、目标、决策变量和符号约束的中间结构化表示（高层任务抽象），然后利用这些表示生成符号工作流或可执行的推理程序（低层逻辑生成）。该框架支持模块化推理、强制执行显式约束，并可通过双层优化进行端到端改进。

**Result:** 在多个现实推理基准测试中，该方法显著优于现有基线，准确性提升高达 40%。双层设计还提高了透明度和错误可追溯性。

**Conclusion:** 该双层框架通过将语言映射到逻辑，实现了准确且可解释的结构化推理，并在多个领域展现出优越性能和可信赖性，是迈向可信赖和系统化推理的重要一步。

> **ai_Abstract:** 本文提出了一个创新的双层框架，用于解决自然语言到逻辑的映射问题，以实现结构化推理。该框架通过高层任务抽象和低层逻辑生成两个阶段，利用大型语言模型（LLM）将自然语言查询转化为结构化表示，进而生成可执行的推理程序。框架支持模块化推理和显式约束，并可通过双层优化进行改进。实验结果表明，该方法在多个推理任务上显著提高了准确性，并增强了系统的透明度和可追溯性。

> **摘要翻译:** 结构化推理仍然是人工智能领域的一项核心挑战，因为它需要弥合非结构化的语言表达与形式化的逻辑表示之间的差距。在本文中，我们提出了一个新颖的	extbf{双层框架}，它通过一个两阶段的过程将语言映射到逻辑：高层任务抽象和低层逻辑生成。在上层，大型语言模型（LLM）将自然语言查询解析为指定问题类型、目标、决策变量和符号约束的中间结构化表示。在下层，LLM 利用这些表示生成符号工作流或可执行的推理程序，以实现准确且可解释的决策制定。该框架支持模块化推理，强制执行显式约束，并能跨越数学问题解决、问答和逻辑推理等领域进行泛化。我们通过一个端到端的{双层}优化方法进一步优化了该框架，该方法共同优化了高层抽象和低层逻辑生成阶段。在多个现实推理基准测试上的实验表明，我们的方法在准确性方面显著优于现有基线，准确性提升高达 40%。此外，双层设计增强了透明度和错误可追溯性，为实现 LLM 的可信赖和系统化推理提供了一个有希望的步骤。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [603] [A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis](https://arxiv.org/abs/2507.08529)
> *一种用于罕见病诊断的多粒度概念稀疏激活和分层知识图谱融合框架*

*Mingda Zhang, Na Zhao, Jianglong Qin, Guoyu Ye, Ruixiang Tang* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 罕见病诊断, 医学大语言模型, 知识图谱, 概念激活, 临床推理

**Comment:** 10 pages,3 figures

> **TL;DR:** 该研究提出了一种结合多粒度概念稀疏激活和分层知识图谱的新框架，以解决罕见病诊断中的知识表示不足、概念理解有限和临床推理受限等问题。实验结果表明，该框架在BLEU、ROUGE和准确率方面均有显著提升，并得到了专家的高度评价，有望缩短罕见病患者的“诊断历程”。

**AI_Comments:** 该研究提出的框架在罕见病诊断领域具有重要的创新性和应用价值。通过结合多粒度概念稀疏激活和分层知识图谱，有效解决了现有模型在处理罕见病知识时的挑战。实验结果和专家评估均表明了该方法的有效性，尤其是在提高诊断准确性和缩短诊断时间方面。未来的工作可以进一步探索该框架在更多罕见病数据集上的泛化能力以及与其他先进模型的融合潜力。

<details>
  <summary>Details</summary>

**Motivation:** 罕见病诊断面临知识表示深度不足、概念理解有限和临床推理受限的挑战。

**Method:** 提出了一种结合多粒度稀疏激活和分层知识图谱的框架，并采用了四种匹配算法、多样性控制和五级回退策略，构建了包含分类、临床特征和实例的三层知识图谱。

**Result:** 在BioASQ罕见病QA数据集上，BLEU提升了0.09，ROUGE提升了0.05，准确率提升了0.12，最高准确率达到0.89。专家评估也证实了信息质量、推理和专业表达的改进。

**Conclusion:** 该框架通过多粒度概念稀疏激活和分层知识图谱融合，有效提升了罕见病诊断的准确性和效率，有望缩短罕见病患者的“诊断历程”。

> **ai_Abstract:** 本研究提出了一种新颖的罕见病诊断框架，通过整合多粒度概念稀疏激活与分层知识图谱，解决了现有医学大语言模型在罕见病诊断中的局限性。该框架通过先进的匹配算法和多层级知识图谱，提高了概念激活的精确度和临床推理能力，实验结果显示在多个评估指标上均有显著提升，并得到了专家认可，预示着其在改善罕见病诊断效率和患者体验方面的潜力。

> **摘要翻译:** 尽管医学大语言模型在医疗保健领域取得了进展，罕见病诊断仍然受到知识表示深度不足、概念理解有限和临床推理受限的困扰。我们提出了一个框架，该框架将医学概念的多粒度稀疏激活与分层知识图谱相结合。四种互补的匹配算法、多样性控制和五级回退策略能够实现精确的概念激活，而一个三层知识图谱（分类、临床特征、实例）则提供了结构化、最新的背景信息。在BioASQ罕见病QA数据集上的实验表明，BLEU提高了0.09，ROUGE提高了0.05，准确率提高了0.12，最高准确率达到0.89，接近0.90的临床阈值。专家评估证实了信息质量、推理和专业表达的改进，表明我们的方法缩短了罕见病患者的“诊断历程”。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [609] [Interpreting systems as solving POMDPs: a step towards a formal understanding of agency](https://arxiv.org/abs/2209.01619)
> *将系统解释为求解部分可观察马尔可夫决策过程（POMDP）：迈向对主体性的形式化理解*

*Martin Biehl, Nathaniel Virgo* | **Category: cs.AI** | **Updated: 2025-07-11**

**Keywords:** 代理，POMDP，信念状态，解释图，最优动作

**Comment:** 17 pages, no figures, published in Proceedings of 3rd International
  Workshop on Active Inference 2022

> **TL;DR:** 该论文提出了一种将系统解释为部分可观察马尔可夫决策过程（POMDP）解的方法，通过引入信念状态和最优动作来形式化代理的概念。

**AI_Comments:** 这项工作在将计算系统与主体性概念联系起来方面迈出了重要的一步，通过将系统行为与 POMDP 框架联系起来，为理解智能体提供了数学基础。然而，该方法在实际应用中的可扩展性和效率仍有待研究。

<details>
  <summary>Details</summary>

**Motivation:** 探讨了在何种情况下系统可以被认为拥有信念和目标，以及这些与主体性相关的特征如何与其物理状态相关联。

**Method:** 提出了一种将系统解释为POMDP解的概念，该系统不仅承认描述其关于POMDP隐藏状态的信念的解释图，而且其动作根据其信念状态被认为是最佳的。

**Result:** 提出了一种将系统解释为POMDP解的方法，并定义了代理为具有此解释的系统，这是朝着形式化代理概念迈出的重要一步。

**Conclusion:** 将系统解释为POMDP解是理解代理概念的一个重要步骤，尽管POMDP并非定义目标的唯一方法。

> **ai_Abstract:** 该研究提出了一种将系统理解为部分可观察马尔可夫决策过程（POMDP）解的方法，通过考虑系统的信念状态和最优动作来形式化代理的概念。该方法通过解释图将系统状态映射到其对外部世界的信念，并要求这些信念随时间演变以符合贝叶斯定理。一个代理被定义为一个系统及其作为POMDP解的解释，这为理解代理的正式定义提供了新的视角。

> **摘要翻译:** 系统在什么情况下可以说拥有信念和目标，以及这些与主体性相关的特征如何与其物理状态相关？最近的工作提出了一种解释图的概念，它将系统的状态映射到一个代表其关于外部世界的信念的概率分布。这样的映射并非完全任意，因为归因于系统的信念必须随着时间的推移以符合贝叶斯定理的方式演变，因此系统的动力学约束了其可能的解释。在这里，我们在这种方法的基础上，提出了一种不仅基于信念，而且基于目标和行动的解释概念。为此，我们利用了部分可观察马尔可夫过程（POMDP）的现有理论：我们说，一个系统可以被解释为POMDP的解，如果它不仅承认描述其关于POMDP隐藏状态的信念的解释图，而且其动作根据其信念状态被认为是最佳的。然后，一个代理就是这样一个系统，连同将其解释为POMDP解的解释。尽管POMDP并非定义拥有目标的唯一可能公式化方法，但这仍然代表了朝着更广泛的形式化定义系统作为代理意味着什么迈出的一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [13] [Ranked Set Sampling-Based Multilayer Perceptron: Improving Generalization via Variance-Based Bounds](https://arxiv.org/abs/2507.08465)
> *基于排序集抽样的多层感知器：通过基于方差的界限提高泛化能力*

*Feijiang Li, Liuya Zhang, Jieting Wang, Tao Yan, Yuhua Qian* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 排序集抽样, 多层感知器, 泛化误差, 方差缩减, 经验损失

**Comment:** 

> **TL;DR:** 本文提出RSS-MLP方法，通过排序集抽样（RSS）减少经验损失方差，从而提高多层感知器（MLP）的泛化能力，并通过理论和实验验证其有效性。

**AI_Comments:** 本文的创新点在于将排序集抽样（RSS）引入到多层感知器（MLP）的训练中，以减少经验损失的方差，从而提高模型的泛化能力。这为解决集成学习中传统随机抽样方法带来的高方差问题提供了一种新颖且有理论支撑的途径。结合理论分析和实验验证，该研究为神经网络的泛化性能提升提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 多层感知器（MLP）的泛化能力受经验损失方差的影响。传统的Bagging方法使用简单随机抽样（SRS），其随机性高，导致经验损失方差较大，限制了MLP的泛化性能。本文旨在通过更有效地减少方差来提升MLP的泛化能力。

**Method:** 本文首先建立了一个新的泛化误差界限，揭示了经验损失方差对学习模型泛化能力的影响。受此启发，提出通过引入排序集抽样（RSS）来构建训练数据集，以在数据集中引入有序结构，从而进一步减少经验损失的方差。在此基础上，开发了RSS-MLP方法。为验证其性能，在十二个基准数据集上，使用两种凸损失函数和两种融合方法进行了对比实验。

**Result:** 理论结果表明，通过RSS估计的经验指数损失和逻辑损失的方差分别小于通过SRS估计的方差。广泛的实验结果和分析表明，所提出的RSS-MLP方法具有有效性和合理性。

**Conclusion:** 通过引入排序集抽样（RSS）来减少经验损失方差，RSS-MLP方法能够有效提高多层感知器（MLP）的泛化能力，这得到了理论分析和实证实验的有力支持。

> **ai_Abstract:** 本文提出了一种基于排序集抽样（RSS）的多层感知器（RSS-MLP）方法，旨在通过减少经验损失的方差来提高其泛化能力。研究建立了一个新的泛化误差界限，指出经验损失方差对模型泛化能力的影响。为解决传统简单随机抽样（SRS）在Bagging中导致的高方差问题，RSS-MLP引入RSS在训练数据中创建有序结构，从而进一步降低损失方差。理论分析表明，RSS在减少经验指数损失和逻辑损失方差方面优于SRS。在十二个基准数据集上进行的广泛实验验证了RSS-MLP的有效性和合理性。

> **摘要翻译:** 多层感知器（MLP）作为最基本的神经网络之一，广泛应用于分类和回归任务。本文建立了一个新的泛化误差界限，揭示了经验损失的方差如何影响学习模型的泛化能力。受此学习界限的启发，我们主张通过减少经验损失的方差来增强MLP的能力。众所周知，Bagging是一种流行的集成方法，用于实现方差缩减。然而，Bagging通过简单随机抽样（SRS）方法生成基础训练数据集，该方法表现出高度的随机性。为了解决这个问题，我们通过排序集抽样（RSS）在训练数据集中引入有序结构，以进一步减少损失的方差，并开发了一种RSS-MLP方法。理论结果表明，通过RSS估计的经验指数损失和逻辑损失的方差分别小于通过SRS估计的方差。为了验证RSS-MLP的性能，我们针对两种凸损失函数在两种融合方法下，在十二个基准数据集上进行了对比实验。大量的实验结果和分析表明了所提出方法的有效性和合理性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [17] [Pre-Training LLMs on a budget: A comparison of three optimizers](https://arxiv.org/abs/2507.08472)
> *在预算内预训练LLM：三种优化器的比较*

*Joel Schlotthauer, Christian Kroos, Chris Hinze, Viktor Hangya, Luzian Hahn, Fabian Küch* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 优化器, LLM预训练, AdamW, Lion, Sophia

**Comment:** 

> **TL;DR:** 该研究比较了AdamW、Lion和Sophia三种优化器在LLM预训练中的表现。Sophia的训练和验证损失最低，Lion在训练GPU小时方面最快，而AdamW在下游评估结果中表现最佳。

**AI_Comments:** 该论文为在预算受限下预训练LLM提供了实用的指导，特别是在选择优化器方面。它强调了不同优化器在训练速度、损失和下游任务性能之间存在的关键权衡，这对于实际应用具有重要意义。利用代理模型和最大更新参数化进行超参数调优，是针对资源限制的创新方法。

<details>
  <summary>Details</summary>

**Motivation:** 优化器在缩短LLM预训练时间和实现性能更好的模型方面起着决定性作用。本研究旨在比较三种主要的优化器变体。

**Method:** 研究比较了AdamW、Lion和Sophia三种主要优化器。为了更好的泛化性，使用了两种不同的基础架构，并采用了单周期和多周期方法，同时保持token数量不变。利用最大更新参数化（Maximal Update Parametrization）和较小的代理模型，针对每种基础架构和优化器的组合单独调整了相关超参数。

**Result:** 所有三种优化器的结果大致在相同范围内。Sophia表现出最低的训练和验证损失。Lion在训练GPU小时方面最快。AdamW在下游评估结果中表现最佳。

**Conclusion:** 预训练LLM时，不同的优化器在训练速度、损失和最终下游任务性能之间存在权衡，没有单一的“最佳”选择。

> **ai_Abstract:** 本研究旨在比较AdamW、Lion和Sophia这三种优化器在预算有限的LLM预训练中的表现。通过使用两种基础架构、单/多周期方法以及最大更新参数化和代理模型进行超参数调优，研究发现，尽管三种优化器性能相近，但Sophia在损失方面表现最佳，Lion在训练速度上领先，而AdamW则在下游任务中取得了最优结果，揭示了优化器在不同性能指标上的权衡。

> **摘要翻译:** 优化器在减少LLM预训练时间并实现性能更好的模型方面起着决定性作用。在本研究中，我们比较了三种主要的变体：事实标准AdamW，通过进化搜索开发的更简单的Lion，以及二阶优化器Sophia。为了更好的泛化性，我们使用两种不同的基础架构进行训练，并采用单周期和多周期方法，同时保持token数量不变。利用最大更新参数化（Maximal Update Parametrization）和较小的代理模型，我们为每种基础架构和优化器的组合单独调整了相关超参数。我们发现，虽然所有三种优化器的结果大致在相同范围内，但Sophia表现出最低的训练和验证损失，Lion在训练GPU小时方面最快，而AdamW在下游评估结果中表现最佳。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [19] [Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding](https://arxiv.org/abs/2505.14765)
> *深度学习驱动的滞留患者数量预测以应对急诊室拥挤问题*

*Orhun Vural, Bunyamin Ozaydin, James Booth, Brittany F. Lindsey, Abdulaziz Ahmed* | **Category: cs.LG, cs.AI, 68T07, I.2.6; J.3** | **Updated: 2025-07-10**

**Keywords:** 急诊室拥挤, 深度学习, 滞留患者预测, 时间序列预测, 医院管理

**Comment:** Feature engineering, results, and model explainability have been
  updated. NBEATSx algorithm was removed due to overfitting during training

> **TL;DR:** 该研究提出了一个基于深度学习的框架，用于提前六小时预测急诊室滞留患者数量，以帮助缓解急诊室拥挤问题。

**AI_Comments:** 该研究的创新之处在于其不依赖患者层面数据，仅通过运营和上下文数据实现提前预测，这在隐私保护和数据可获取性方面具有优势。其提出的深度学习框架，特别是TSTPlus模型的应用，展示了在复杂医疗环境中进行时间序列预测的潜力，为缓解急诊室拥挤提供了实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决急诊室（ED）拥挤问题，通过提前预测滞留患者数量来支持医院的积极管理。

**Method:** 本研究开发了一个基于深度学习的框架，利用急诊跟踪系统、住院人数、天气、节假日和当地事件等运营和上下文数据（无患者层面信息）进行每小时聚合和全面的特征工程。训练并优化了包括ResNetPlus、TSTPlus和TSiTPlus在内的多种深度学习模型，其中TSTPlus表现最佳，模型优化使用Optuna。

**Result:** TSTPlus模型取得了最佳结果，平均绝对误差（MAE）为4.30，均方误差（MSE）为29.47，R2为0.79。该框架能够准确预测滞留患者数量，包括在极端时期，并表明更广泛的输入特征可以提高预测准确性。

**Conclusion:** 该方法支持积极的医院管理，并提供了一种缓解急诊室拥挤的实用方法。

> **ai_Abstract:** 本研究开发了一个基于深度学习的框架，利用运营和上下文数据（非患者层面信息）提前六小时预测急诊室滞留患者数量，以应对急诊室拥挤。通过对多种深度学习模型进行训练和优化，TSTPlus模型表现最佳，并证明了更广泛的输入特征能提高预测准确性。该方法为医院管理提供了实用工具，有助于缓解急诊室拥挤。

> **摘要翻译:** 本研究提出了一个基于深度学习的框架，用于仅利用运营和上下文数据（不含患者层面信息）提前六小时预测急诊科（ED）滞留患者数量。急诊科追踪系统、住院人数、天气、节假日和当地事件的数据被按小时聚合并进行全面的特征工程处理。急诊科平均滞留患者数量为28.7人（标准差=11.2）。使用Optuna训练并优化了包括ResNetPlus、TSTPlus和TSiTPlus在内的多种深度学习模型，其中TSTPlus取得了最佳结果（平均绝对误差=4.30，均方误差=29.47，R2=0.79）。该框架准确预测了滞留患者数量，包括在极端时期，并表明更广泛的输入特征可以提高预测准确性。这种方法支持积极的医院管理，并提供了一种缓解急诊室拥挤的实用方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [23] [Thinner Latent Spaces: Detecting Dimension and Imposing Invariance with Conformal Autoencoders](https://arxiv.org/abs/2408.16138)
> *稀疏潜在空间：使用共形自编码器检测维度并施加不变性*

*George A. Kevrekidis, Zan Ahmad, Mauro Maggioni, Soledad Villar, Yannis G. Kevrekidis* | **Category: cs.LG, math.DG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 共形自编码器, 潜在空间, 内在维度, 流形学习, 坐标不变性

**Comment:** 

> **TL;DR:** 本文展示了共形自编码器如何利用潜在层中的正交性关系来推断非线性流形数据的内在维度，同时计算编码/解码映射，并能用于构建坐标不变性。

**AI_Comments:** 这篇论文通过引入共形自编码器中的梯度正交性，提供了一种新颖的方法来解决非线性数据内在维度推断和解耦表示的问题。其结合微分几何理论来指导神经网络设计，具有较高的理论创新性。此外，能够构建坐标不变性是其另一个重要贡献，这对于处理具有对称性的数据尤其有价值。论文提及了方法的优点和缺点，表明了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在利用共形自编码器的潜在层正交性来解决两个问题：一是推断非线性流形数据的内在维度，二是构建对局部群作用的坐标不变性。

**Method:** 使用共形自编码器（Conformal Autoencoders），利用网络潜在层中的正交性关系来推断非线性流形数据集的内在维度，同时计算编码和解码（嵌入）映射。理论基础依赖于微分几何，并描述了相应的梯度下降优化算法。此外，利用相同的计算技术构建对局部群作用的坐标不变性。

**Result:** 该方法能够推断非线性流形数据的内在维度，并同时计算编码和解码（嵌入）映射。该方法已应用于多个数据集，并展示了其适用性、优点和缺点。相同的计算技术可用于在嵌入空间的（缩减）子流形上构建对局部群作用的坐标不变性。

**Conclusion:** 共形自编码器通过利用潜在层的正交性，不仅能有效地推断非线性流形数据的内在维度并生成编解码映射，还能构建局部群作用的坐标不变性，展现了其在数据表示和几何推断方面的潜力。

> **ai_Abstract:** 本文提出利用共形自编码器（CAEs）的潜在层正交性来推断非线性流形数据的内在维度，并同时计算其编码和解码映射。研究基于微分几何理论，并描述了相应的梯度下降优化算法。该方法在多个数据集上进行了验证，展示了其在数据维度推断和表示学习方面的应用潜力。此外，论文还指出该技术可用于在特定条件下构建对局部群作用的坐标不变性。

> **摘要翻译:** 共形自编码器是一种神经网络架构，它在潜在变量的梯度之间施加正交条件，以获得数据的解耦表示。在这项工作中，我们展示了网络潜在层中的正交关系可以被利用来推断非线性流形数据集的内在维度（由其切空间的维度局部表征），同时计算编码和解码（嵌入）映射。我们概述了依赖于微分几何的相关理论，并描述了相应的梯度下降优化算法。该方法应用于多个数据集，我们强调了其适用性、优点和缺点。此外，我们证明了相同的计算技术可以用于在仅在嵌入空间的（缩减）子流形上定义的局部群作用下构建坐标不变性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [30] [Just Read the Question: Enabling Generalization to New Assessment Items with Text Awareness](https://arxiv.org/abs/2507.08154)
> *只需要阅读问题：通过文本感知实现对新评估项的泛化*

*Arisha Khan, Nathaniel Li, Tori Shen, Anna N. Rafferty* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 教育评估, 机器学习, 泛化, 文本嵌入, LENS

**Comment:** Poster paper at Educational Data Mining (EDM) 2025

> **TL;DR:** 该研究通过开发Text-LENS，利用文本嵌入来解决机器学习在教育评估中处理新项目时的泛化问题，并在未见项目上取得了更好的预测性能。

**AI_Comments:** 该论文的创新点在于将文本嵌入引入教育评估模型，有效解决了传统机器学习方法在面对新评估项目时泛化能力不足的痛点。通过利用项目本身的文本信息，模型能够更好地理解未见项目的上下文，从而提高了预测的准确性和实用性。这对于教育技术领域，尤其是自适应学习和个性化评估，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习在教育评估中面临的挑战是难以整合新项目，因为现有方法严重依赖历史数据进行预测。

**Method:** 研究人员通过扩展LENS（一种用于教育评估的部分变分自编码器）开发了Text-LENS，使其能够利用项目文本嵌入，并探索了其对预测性能和对未见项目泛化能力的影响。

**Result:** Text-LENS在已见项目上的性能与LENS相当，但在涉及未见项目时的多种条件下均有所改进。它能有效地从新项目中学习学生能力并对学生在新项目上的表现进行预测。

**Conclusion:** Text-LENS能够有效学习学生能力，并对新评估项目上的学生表现进行预测，从而解决了传统机器学习方法在处理新项目时泛化能力不足的问题。

> **ai_Abstract:** 本研究提出了一种名为Text-LENS的新型机器学习方法，旨在解决教育评估中现有模型难以泛化到新评估项目的问题。Text-LENS通过将项目文本嵌入集成到LENS（一种部分变分自编码器）中，使其能够利用文本信息进行预测。实验在Eedi和LLM-Sim两个数据集上进行，结果表明Text-LENS在已见项目上保持了与LENS相当的性能，并且在处理未见项目时表现出显著的改进，证明了其在从新项目中学习学生能力并预测其表现的有效性。

> **摘要翻译:** 机器学习已被提议作为一种通过对学生表现进行细粒度预测以及学习项目之间的关系来改进教育评估的方法。许多机器学习方法的一个挑战是整合新项目，因为这些方法严重依赖历史数据。我们通过扩展用于教育评估的LENS部分变分自编码器来开发Text-LENS，以利用项目文本嵌入，并探索其对预测性能和对以前未见项目泛化能力的影响。我们检查了在两个数据集上的性能：Eedi，一个包含项目内容的公开数据集；以及LLM-Sim，一个由LLM生成测试项目的新颖数据集。我们发现Text-LENS在已见项目上的性能与LENS匹配，并在涉及未见项目的各种条件下有所改进；它有效地从新项目中学习学生能力并对学生在新项目上的表现进行预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [37] [Evaluating SAE interpretability without explanations](https://arxiv.org/abs/2507.08473)
> *不依赖解释评估稀疏自编码器（SAE）的可解释性*

*Gonçalo Paulo, Nora Belrose* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 稀疏自编码器, 可解释性评估, 无解释, 机器学习, 潜在变量

**Comment:** 

> **TL;DR:** 本文提出了一种不生成自然语言解释来评估稀疏编码器可解释性的方法，旨在实现更直接和标准化的评估。

**AI_Comments:** 本文的创新之处在于提出了一种不依赖于生成自然语言解释来评估稀疏自编码器可解释性的方法，这有助于将解释生成和评估过程与模型本身的实际可解释性解耦，从而实现更直接和标准化的评估。这对于推动机器学习可解释性领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏自编码器（SAE）和转码器是机器学习可解释性的重要工具，但评估其可解释性仍然具有挑战性，且缺乏关于使用何种基准的共识。现有的大多数评估方法都需要为每个潜在变量生成单句解释，这使得解释生成和评估过程与潜在变量的实际可解释性难以区分。

**Method:** 本文调整了现有方法来评估稀疏编码器的可解释性，其优点是不需要将生成自然语言解释作为中间步骤。此外，我们将我们的可解释性指标得分与类似任务和不同设置下的人工评估进行了比较。

**Result:** 我们的可解释性指标得分与人工评估进行了比较，并为社区改进这些技术的评估提供了建议。

**Conclusion:** 本文提出的方法能够实现对稀疏编码器可解释性更直接和潜在标准化的评估，并为改进评估提供了见解。

> **ai_Abstract:** 本研究提出了一种评估稀疏自编码器（SAE）和转码器可解释性的新方法，该方法无需生成自然语言解释作为中间步骤。当前评估方法因依赖解释生成而难以直接衡量潜在变量的可解释性。通过调整现有方法，本文旨在提供一种更直接和标准化的评估途径，并通过与人工评估的比较，为改进机器学习可解释性技术的评估提供建议。

> **摘要翻译:** 稀疏自编码器（SAE）和转码器已成为机器学习可解释性的重要工具。然而，衡量它们的可解释性仍然具有挑战性，对于使用哪些基准缺乏共识。大多数评估程序首先为每个潜在变量生成一个单句解释。然后根据这些解释在多大程度上使大型语言模型（LLM）能够在新的语境中预测潜在变量的激活来评估它们。这种方法使得将解释生成和评估过程与所发现的潜在变量的实际可解释性区分开来变得困难。在这项工作中，我们调整了现有方法来评估稀疏编码器的可解释性，其优点是不需要将自然语言解释作为中间步骤。这使得对可解释性进行更直接和潜在标准化的评估成为可能。此外，我们比较了我们的可解释性指标得分与类似任务和不同设置下的人工评估，为社区改进这些技术的评估提供了建议。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [49] [Emotion Recognition in Older Adults with Quantum Machine Learning and Wearable Sensors](https://arxiv.org/abs/2507.08175)
> *采用量子机器学习和可穿戴传感器对老年人进行情绪识别*

*Md. Saif Hassan Onim, Travis S. Humble, Himanshu Thapliyal* | **Category: cs.LG, cs.HC, quant-ph** | **Updated: 2025-07-10**

**Keywords:** 量子机器学习, 情绪识别, 可穿戴传感器, 生理信号, 隐私保护

**Comment:** 

> **TL;DR:** 本文利用量子机器学习和可穿戴传感器，通过生理信号实现了对老年人情绪的隐私保护识别，并显示出优于经典方法的性能。

**AI_Comments:** 这篇论文的创新点在于将量子机器学习应用于情绪识别领域，并结合可穿戴传感器数据，提供了一种非侵入式且保护隐私的解决方案。其重要性体现在为阿尔茨海默病及相关痴呆症（ADRD）和创伤后应激障碍（PTSD）患者等交流受损人群提供了新的情绪监测途径。在有限数据集上仍能取得优异性能，显示了量子机器学习在小数据量场景下的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统面部识别技术存在隐私问题，需要一种非侵入式、保护隐私的情绪识别方法，尤其对交流受损人群（如阿尔茨海默病及相关痴呆症和创伤后应激障碍患者）有益。

**Method:** 研究通过生理信号推断情绪状态的可行性；比较经典机器学习算法和基于量子核模型的混合量子机器学习（QML）方法，特别是量子增强型SVM的性能。

**Result:** 量子增强型SVM在所有情绪类别的分类性能上均优于经典算法，即使在有限数据集上训练也是如此。所有类别的F1分数均超过80%，召回率最大提高约36%。

**Conclusion:** 将可穿戴传感器数据与量子机器学习结合，不仅提高了准确性和鲁棒性，还实现了非侵入式情绪识别，对交流受损人群有前景，为临床和辅助生活条件下的被动情绪监测奠定了早期基础。

> **ai_Abstract:** 本文探索了利用生理信号通过量子机器学习（QML）和可穿戴传感器实现情绪识别的可行性，旨在提供一种保护隐私的替代方案。研究比较了经典机器学习与QML方法，发现量子增强型SVM在分类性能上优于经典算法，即使在有限数据集上也能达到高F1分数和显著的召回率提升。该方法对交流受损人群具有潜力，并为被动情绪监测奠定了基础。

> **摘要翻译:** 我们研究了仅从生理信号推断情绪状态的可行性，从而为传统的面部识别技术提供了一种保护隐私的替代方案。我们对经典机器学习算法和基于量子核模型的混合量子机器学习（QML）方法进行了性能比较。我们的结果表明，即使在有限的数据集上进行训练，量子增强型支持向量机（SVM）在所有情绪类别的分类性能上都超越了经典对应物。所有类别的F1分数均超过80%，召回率最大提高约36%。可穿戴传感器数据与量子机器学习的结合不仅提高了准确性和鲁棒性，还促进了非侵入式情绪识别。这种方法对交流能力受损的人群，如阿尔茨海默病及相关痴呆症（ADRD）患者和患有创伤后应激障碍（PTSD）的退伍军人，具有广阔前景。这些发现为临床和辅助生活条件下的被动情绪监测奠定了早期基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [52] [Grokking Beyond the Euclidean Norm of Model Parameters](https://arxiv.org/abs/2506.05718)
> *超越模型参数欧几里得范数的Grokking现象*

*Pascal Jr Tikeng Notsawo, Guillaume Dumas, Guillaume Rabusseau* | **Category: cs.LG, cs.AI, stat.ML, I.2.6** | **Updated: 2025-07-10**

**Keywords:** Grokking, 正则化, 泛化, 过参数化, 数据选择

**Comment:** 67 pages, 35 figures. Forty-second International Conference on
  Machine Learning (ICML), 2025

> **TL;DR:** 本文展示了Grokking现象可以通过显式或隐式正则化、深度过参数化以及数据选择来诱导和影响，并且指出L2范数在存在其他类型正则化时并非泛化的可靠指标。

**AI_Comments:** 这篇论文的创新点在于它极大地扩展了我们对Grokking现象成因的理解，超越了以往对L2权重衰减的狭隘关注。它揭示了更广泛的正则化形式（包括隐式正则化）、模型架构（深度过参数化）和数据选择在诱导和控制Grokking中的关键作用。这对于理解深度学习模型的泛化行为，以及设计更有效的训练策略具有重要意义。特别是指出L2范数在特定正则化情境下不再是泛化代理的局限性，挑战了现有的一些直觉。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在深入理解Grokking现象的诱发机制，特别是超越了以往仅关注L2范数权重衰减的范畴，探索了更广泛的正则化形式（如稀疏性或低秩性）以及模型结构（深度过参数化）和数据选择对Grokking的影响，以期为优化神经网络提供更全面的视角。

**Method:** 作者通过论证当存在具有特定性质P（例如稀疏或低秩权重）的模型能够泛化时，应用小的非零P正则化（例如L1或核范数正则化）的梯度下降会导致Grokking。此外，他们分析了增加深度带来的过参数化如何使得在不显式使用正则化的情况下实现Grokking或Ungrokking。他们还通过实验展示了在没有权重衰减但模型仍泛化的情况下，L2范数会增长，从而证明L2范数在其他正则化存在时并非泛化的可靠代理。最后，他们展示了仅通过数据选择即可放大Grokking现象。

**Result:** 研究发现，Grokking现象可以通过显式或隐式正则化来诱导，特别是当存在具有特定性质P（如稀疏或低秩权重）的模型时，对P进行小的非零正则化会导致Grokking。深度过参数化使得在没有显式正则化的情况下也能实现Grokking或Ungrokking，这在浅层模型中是不可能的。当模型被正则化以趋向于不同性质P时，L2范数不再是泛化的可靠代理，因为它在许多情况下即使模型泛化也会增长。此外，Grokking可以通过纯粹的数据选择来放大，即使其他超参数固定不变。

**Conclusion:** 本文得出结论，Grokking现象的发生机制比之前认为的更为复杂和多样。它不仅能被传统的L2权重衰减诱导，也能通过其他形式的显式或隐式正则化、模型深度（过参数化）以及数据选择来诱发和影响。特别地，当存在其他正则化目标时，L2范数不再是衡量模型泛化的可靠指标。

> **ai_Abstract:** 本文深入研究了神经网络训练中的Grokking现象，发现其不仅受L2权重衰减影响，还可以由更广泛的显式或隐式正则化（如L1或核范数正则化）诱导。研究表明，当模型被正则化以达到特定性质P时，梯度下降会导致Grokking。此外，深度过参数化在没有显式正则化的情况下也能促成Grokking或Ungrokking。论文还指出，L2范数在存在其他正则化目标时，不再是衡量泛化的可靠指标，且Grokking现象可通过数据选择独立放大。

> **摘要翻译:** Grokking指的是在使用基于梯度的优化方法训练人工神经网络时，在过拟合之后出现的延迟泛化现象。在这项工作中，我们证明Grokking可以由显式或隐式正则化诱导。更精确地说，我们表明当存在一个具有属性P（例如，稀疏或低秩权重）的模型能够在感兴趣的问题上泛化时，对P进行小但非零正则化（例如，L1或核范数正则化）的梯度下降会导致Grokking。这扩展了之前关于小非零权重衰减诱导Grokking的工作。此外，我们的分析表明，通过增加深度进行过参数化使得在不显式使用正则化的情况下也能实现Grokking或Ungrokking，这在浅层情况下是不可能的。我们进一步表明，当模型被正则化以趋向于不同的属性P时，L2范数并非泛化的可靠代理，因为在许多情况下，即使不使用权重衰减，L2范数也会增长，但模型仍然泛化。我们还表明，Grokking可以仅通过数据选择来放大，而其他所有超参数保持不变。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [54] [SynBridge: Bridging Reaction States via Discrete Flow for Bidirectional Reaction Prediction](https://arxiv.org/abs/2507.08475)
> *SynBridge：通过离散流连接反应状态实现双向反应预测*

*Haitao Lin, Junjie Wang, Zhifeng Gao, Xiaohong Ji, Rong Zhu, Linfeng Zhang, Guolin Ke, Weinan E* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 化学反应预测, 离散流, 双向预测, 图Transformer, 逆合成

**Comment:** 22pages, 2 figures

> **TL;DR:** SynBridge是一个基于离散流的双向生成模型，用于化学反应预测。它利用图到图的Transformer网络和离散流桥，在三个基准数据集上实现了正向和逆合成任务的SOTA性能。

**AI_Comments:** SynBridge的创新点在于其将离散流的概念引入化学反应预测，并结合图到图的Transformer网络，有效地捕捉了化学反应中离散的状态变化。这种方法对于理解和预测复杂的化学转化具有重要意义，尤其是在逆合成领域，其SOTA表现证明了其强大的实用性。该研究强调了结构化扩散在离散空间中进行反应预测的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 化学反应本质上是电子的重新分布和重组，这些变化在物理世界中是离散和突然的，例如原子电荷状态的改变或化学键的形成和断裂。为了更好地建模这种状态的转变，本文提出了SynBridge。

**Method:** 本文提出了SynBridge，一个基于双向流的生成模型，用于实现多任务反应预测。它利用图到图的Transformer网络架构和任意两个离散分布之间的离散流桥，通过键和原子的离散状态捕获反应物和产物图之间的双向化学转化。

**Result:** SynBridge在USPTO-50K、USPTO-MIT和Pistachio三个基准数据集上进行了广泛实验，在正向合成和逆合成任务中均取得了最先进的性能。消融研究和噪声调度分析揭示了结构化扩散在离散空间中进行反应预测的优势。

**Conclusion:** SynBridge通过引入离散流和结构化扩散，有效解决了化学反应中离散状态的建模问题，并在双向反应预测任务中取得了显著的SOTA性能，证明了该方法在化学转化预测方面的潜力。

> **ai_Abstract:** SynBridge是一个创新的双向流生成模型，专门用于化学反应预测。该模型通过图到图的Transformer网络和离散流桥，有效捕捉反应物和产物之间离散的化学状态转变。它在正向和逆合成任务中均表现出色，并在多个标准数据集上达到SOTA性能，证明了其在建模化学转化方面的强大能力。

> **摘要翻译:** 化学反应的本质在于电子的重新分布和重组，这通常通过电子转移或电子对的迁移来体现。这些变化在物理世界中本质上是离散和突然的，例如原子电荷状态的改变或化学键的形成和断裂。为了模拟状态的转变，我们提出了SynBridge，一个基于双向流的生成模型，以实现多任务反应预测。通过利用图到图的Transformer网络架构和任意两个离散分布之间的离散流桥，SynBridge通过键和原子的离散状态捕获反应物和产物图之间的双向化学转化。我们通过在三个基准数据集（USPTO-50K、USPTO-MIT、Pistachio）上进行大量实验，进一步证明了我们方法的有效性，在正向和逆合成任务中均取得了最先进的性能。我们的消融研究和噪声调度分析揭示了结构化扩散在离散空间中进行反应预测的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [Granular Ball Twin Support Vector Machine](https://arxiv.org/abs/2410.04774)
> *粒状球双支持向量机*

*A. Quadir, M. Sajid, M. Tanveer* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 粒状球双支持向量机, 大规模学习, 支持向量机, 鲁棒性, 过拟合

**Comment:** Manuscript submitted to IEEE TRANSACTIONS ON NEURAL NETWORKS AND
  LEARNING SYSTEMS: 19 September 2023; revised 13 February 2024 and 14 July
  2024; accepted 05 October 2024

> **TL;DR:** 本文提出了粒状球双支持向量机（GBTSVM）及其大规模版本（LS-GBTSVM），以解决传统双支持向量机（TSVM）在处理大规模数据集时的效率低下、过拟合和对噪声敏感等问题。GBTSVM使用粒状球作为输入，LS-GBTSVM通过优化避免矩阵求逆并引入正则化项，实验证明其在泛化能力上表现优越。

**AI_Comments:** 本文通过引入“粒状球”的概念和优化模型公式，成功解决了传统双支持向量机在处理大规模数据时的核心痛点，即计算效率、过拟合和鲁棒性。这种从数据点到“粒状”输入的转变是其主要创新点，为处理复杂和噪声数据提供了一种新颖且有效的方法。LS-GBTSVM的设计尤其出色，通过避免矩阵求逆和融入SRM原则，使其在实际应用中更具竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 传统双支持向量机（TSVM）面临以下挑战：(i) 矩阵求逆导致在大规模数据集上的效率和适用性受限；(ii) 原始公式中缺少结构风险最小化（SRM）原则，增加了过拟合的风险；(iii) 对噪声和异常值高度敏感，并且在重采样时表现不稳定。

**Method:** 本文提出了粒状球双支持向量机（GBTSVM），它以粒状球而非单个数据点作为输入来构建分类器，从而增强了对重采样的鲁棒性并降低了对噪声和异常值的敏感性。此外，还提出了一种新型大规模粒状球双支持向量机（LS-GBTSVM）。LS-GBTSVM的优化公式实现了两个关键点：(i) 消除了对矩阵求逆的需求，提高了计算效率；(ii) 通过引入正则化项纳入了结构风险最小化（SRM）原则，有效解决了过拟合问题。

**Result:** 在UCI、KEEL和NDC基准数据集上对GBTSVM和LS-GBTSVM模型进行了综合评估。实验结果和统计分析证实了所提出的GBTSVM和LS-GBTSVM模型具有卓越的泛化能力。

**Conclusion:** 所提出的LS-GBTSVM模型在处理大规模数据集方面具有高效性、可扩展性，并且对噪声和异常值具有鲁棒性。实验证明GBTSVM和LS-GBTSVM模型具有优越的泛化能力。

> **ai_Abstract:** 本文针对传统双支持向量机（TSVM）在处理大规模数据时面临的效率低下、过拟合和对噪声敏感等问题，提出了一种新型模型——粒状球双支持向量机（GBTSVM）及其大规模版本（LS-GBTSVM）。GBTSVM通过将粒状球而非单个数据点作为输入，增强了模型的鲁棒性。LS-GBTSVM则通过优化其公式，消除了矩阵求逆的需要，显著提高了计算效率和可扩展性，并通过引入正则化项有效解决了过拟合问题。实验结果表明，所提出的GBTSVM和LS-GBTSVM模型在泛化能力上表现出优越性。

> **摘要翻译:** 关于混合模型中非参数最大似然估计的有效和可扩展计算。
双支持向量机（TSVM）是一种新兴的机器学习模型，在分类和回归任务中具有广泛的适用性。然而，TSVM面临着显著的挑战：(i) 对矩阵求逆的必要性对其在大规模数据集上的效率和适用性构成了巨大障碍；(ii) 其原始公式中省略了结构风险最小化（SRM）原则，增加了过拟合的风险；(iii) TSVM对噪声和异常值高度敏感，并且在重采样时表现出不稳定性。鉴于上述挑战，我们提出了粒状球双支持向量机（GBTSVM）。GBTSVM以粒状球而非单个数据点作为输入来构建分类器。这些粒状球以其更粗的粒度为特征，对重采样表现出鲁棒性，并降低了受噪声和异常值影响的敏感性。我们进一步提出了一种新型大规模粒状球双支持向量机（LS-GBTSVM）。LS-GBTSVM的优化公式确保了两个关键方面：(i) 它消除了对矩阵求逆的需求，从而简化了LS-GBTSVM的计算效率；(ii) 它通过引入正则化项纳入了SRM原则，有效解决了过拟合问题。所提出的LS-GBTSVM体现了高效性、对大型数据集的可扩展性以及对噪声和异常值的鲁棒性。我们在UCI、KEEL和NDC数据集的基准数据集上对GBTSVM和LS-GBTSVM模型进行了综合评估。我们的实验结果和统计分析证实了所提出的GBTSVM和LS-GBTSVM模型具有卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [70] [Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R](https://arxiv.org/abs/2507.08505)
> *视觉语言模型在移动设备上的高效部署：以一加13R为例*

*Pablo Robin Guerrero, Yueyang Pan, Sanidhya Kashyap* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 视觉语言模型, 移动设备部署, 性能瓶颈, 硬件利用, 基准测试

**Comment:** 

> **TL;DR:** 本研究评估了视觉语言模型（VLMs）在移动设备（一加13R）上的部署框架，发现CPU在令牌生成时过度使用，而GPU和NPU利用不足，导致性能瓶颈。

**AI_Comments:** 该论文通过对实际移动设备（一加13R）上的VLM部署进行深入基准测试和分析，揭示了当前框架在硬件利用方面存在的关键瓶颈，特别是CPU的过度使用和GPU/NPU的低效利用。这对于推动VLM在移动设备上的实际应用具有重要意义，指出了未来优化工作的明确方向，例如开发更有效的异构计算调度策略。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言模型（VLMs）在移动设备上具有广阔前景，但由于计算限制和能效低下，尤其是在实时应用中，其部署面临重大挑战。

**Method:** 本研究全面调查了移动设备上VLM的部署框架，并在一加13R手机上评估了llama.cpp、MLC-Imp和mllm，运行LLaVA-1.5 7B、MobileVLM-3B和Imp-v1.5 3B。评估测量了CPU、GPU、NPU利用率、温度、推理时间、功耗和用户体验。

**Result:** 基准测试揭示了各框架的关键性能瓶颈：CPU在令牌生成期间持续过度利用，而GPU和NPU加速器在很大程度上未被使用。当GPU被使用时（主要用于图像特征提取），它会饱和，导致设备响应性下降。

**Conclusion:** 当前部署框架在硬件利用方面存在问题，表现为CPU持续过度使用，以及GPU和NPU的低效或不稳定使用。

> **ai_Abstract:** 本研究调查了视觉语言模型（VLMs）在移动设备上的高效部署，以一加13R为例，评估了llama.cpp、MLC-Imp和mllm等主流框架。通过对CPU、GPU、NPU利用率、功耗等指标的全面测量，发现当前框架在令牌生成时CPU过度负载，而GPU和NPU利用不足或饱和，导致性能瓶颈。研究贡献了详细的基准测试和硬件利用分析，为优化移动设备上的VLM部署提供了重要见解。

> **摘要翻译:** 视觉语言模型（VLMs）为移动设备提供了有前景的能力，但由于计算限制和能源效率低下，尤其是在实时应用中，其部署面临重大挑战。本研究对移动设备上VLM的部署框架进行了全面调查，评估了llama.cpp、MLC-Imp和mllm，并以LLaVA-1.5 7B、MobileVLM-3B和Imp-v1.5 3B作为代表性工作负载在一加13R上运行。每个部署框架都在一加13R上运行时进行了评估，测量内容涵盖CPU、GPU和NPU利用率、温度、推理时间、功耗和用户体验。基准测试揭示了各框架的关键性能瓶颈：CPU在令牌生成期间持续过度利用，而GPU和NPU加速器在很大程度上未被使用。当GPU被使用时，主要用于图像特征提取，它会饱和，导致设备响应性下降。本研究贡献了框架级基准测试、实用的性能分析工具以及对硬件利用瓶颈的深入分析，强调了当前部署框架中CPU的持续过度使用以及GPU和NPU的低效或不稳定使用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [77] [CTRLS: Chain-of-Thought Reasoning via Latent State-Transition](https://arxiv.org/abs/2507.08182)
> *CTRLS：通过潜在状态转换实现思维链推理*

*Junda Wu, Yuxin Xiong, Xintong Li, Zhengmian Hu, Tong Yu, Rui Wang, Xiang Chen, Jingbo Shang, Julian McAuley* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 思维链推理, 大型语言模型, 马尔可夫决策过程, 强化学习, 潜在状态转换

**Comment:** 10 pages

> **TL;DR:** CTRLS通过将思维链推理建模为具有潜在状态转换的马尔可夫决策过程，并使用强化学习进行探索，提高了大型语言模型在推理任务中的准确性、多样性和探索效率。

**AI_Comments:** CTRLS的创新之处在于将CoT推理与MDP和强化学习相结合，实现了对推理过程更结构化和系统化的探索。通过建模潜在状态转换和显式处理认知不确定性，它提供了一种原则性的方法来发现多样且有效的推理轨迹，这对于提升LLM在复杂推理任务中的性能和可解释性具有重要意义。无需对LLM进行额外微调是一个显著优势，表明其具有较高的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的思维链（CoT）方法依赖启发式采样，缺乏对推理转换的结构化建模，这限制了它们系统探索和发现多样化有效推理路径的能力。

**Method:** 本文引入了CTRLS框架，将CoT推理公式化为具有潜在状态转换的马尔可夫决策过程（MDP），通过分布强化学习实现原则性且状态感知的探索。它将推理动作建模为潜在空间中的显式概率分布，并采用了一种结合epsilon-greedy探索和基于熵正则化的在线强化学习策略，无需额外微调底层LLM。

**Result:** 实验证明，CTRLS在基准推理任务中提高了推理准确性、多样性和探索效率。

**Conclusion:** CTRLS通过将CoT推理建模为具有潜在状态转换的MDP并利用强化学习进行探索，有效地解决了传统CoT方法在结构化建模和系统探索方面的局限性，从而显著提升了LLM的推理能力。

> **ai_Abstract:** CTRLS是一个新框架，它将大型语言模型（LLM）的思维链（CoT）推理建模为具有潜在状态转换的马尔可夫决策过程（MDP）。通过利用分布强化学习，CTRLS能够进行结构化且状态感知的探索，克服了传统CoT方法缺乏系统性探索的局限性。该方法通过显式建模潜在空间中的推理动作概率分布来处理认知不确定性，并采用了一种无需LLM微调的在线强化学习策略。理论分析和实验结果均表明，CTRLS在推理准确性、多样性和探索效率方面均有所提升。

> **摘要翻译:** 思维链（CoT）推理使大型语言模型（LLM）能够将复杂问题分解为可解释的中间步骤，显著增强了模型在推理任务中的透明度和性能。然而，传统的CoT方法依赖启发式采样，缺乏对推理转换的结构化建模，这限制了它们系统探索和发现多样化有效推理路径的能力。在这项工作中，我们引入了CTRLS，一个将CoT推理公式化为具有潜在状态转换的马尔可夫决策过程（MDP）的框架，通过分布强化学习实现原则性且状态感知的探索。通过将推理动作建模为潜在空间中的显式概率分布，我们的方法明确地建模了认知不确定性，促进了推理空间的鲁棒探索。作为我们框架的一部分，我们引入了一种结合epsilon-greedy探索和基于熵正则化的在线强化学习策略，以迭代地改进潜在状态转换，而无需对底层LLM进行额外的微调。理论分析提供了证据下界（ELBO），从理论上奠定了我们对潜在推理动力学进行转换感知建模的基础。进一步的实验证明，在基准推理任务中，推理准确性、多样性和探索效率都有所提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [80] [On the Necessity of Output Distribution Reweighting for Effective Class Unlearning](https://arxiv.org/abs/2506.20893)
> *关于有效类遗忘中输出分布重加权的必要性*

*Yian Wang, Ali Ebrahimpour-Boroojeny, Hari Sundaram* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 类遗忘, 输出重加权, 机器学习遗忘, 成员推理攻击, 总变差距离

**Comment:** 

> **TL;DR:** 本文提出了一种名为RWFT的轻量级输出重加权遗忘方法，可在不完全重新训练的情况下从分类器中擦除整个类别，并通过引入新的指标和攻击方式，证明了其在遗忘效果上优于现有方法并与完全重新训练相当。

**AI_Comments:** 本文的创新点在于提出了输出分布重加权的概念，并设计了针对现有遗忘方法弱点的成员推理攻击MIA-NN，这为评估遗忘效果提供了新的视角。引入TV距离作为新的评估指标，能够更精确地量化残余信息泄漏，这对于推动机器学习遗忘领域的发展具有重要意义。该方法轻量高效，且在性能上超越了现有SOTA方法，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 强制执行用户删除权、减轻有害或有偏见的预测至关重要。完全重新训练成本高昂，且现有遗忘方法在预测被遗忘类别样本时无法复制重新训练模型的行为，这可以通过本文设计的MIA-NN攻击成功揭示。

**Method:** 引入了一种名为RWFT的输出重加权遗忘方法，通过对被遗忘类别样本的预测概率质量进行简单重新分配，使其对MIA-NN攻击具有鲁棒性。同时，提出了一种基于总变差（TV）距离的新度量来量化残余泄漏。

**Result:** RWFT方法在现有评估指标和新提出的TV-based指标上均与完全重新训练的结果相匹配。与最先进的方法相比，在先前使用的指标上提高了2.79%，在新提出的基于TV的指标上提高了111.45%。

**Conclusion:** 输出分布重加权对于有效的类遗忘是必要的，能够实现与完全重新训练相当的性能，并有效抵御成员推理攻击。

> **ai_Abstract:** 本文提出了一种名为RWFT的轻量级输出重加权遗忘方法，旨在高效地从已训练分类器中擦除特定类别，无需进行昂贵的完全重新训练。针对现有遗忘方法无法有效隐藏被遗忘类别的问题，作者设计了MIA-NN攻击来证明其不足，并提出通过简单重新分配被遗忘类别样本的预测概率来增强鲁棒性。此外，引入了基于总变差距离的新指标以量化遗忘效果。实验结果表明，RWFT在各项评估指标上均能达到与完全重新训练相当的性能，并显著优于现有最先进的遗忘方法。

> **摘要翻译:** 在这项工作中，我们引入了一种输出重加权遗忘方法RWFT，这是一种轻量级技术，可以在不完全重新训练的情况下从训练好的分类器中擦除整个类别。从训练好的模型中遗忘特定类别对于强制执行用户删除权和减轻有害或有偏见的预测至关重要。完全重新训练成本高昂，并且现有遗忘方法在预测来自被遗忘类别的样本时无法复制重新训练模型的行为。我们通过设计一种成员推理攻击的变体MIA-NN来证明这种失败，该攻击能够成功揭示任何这些方法的被遗忘类别。我们提出了一种简单的概率质量重新分配，用于对被遗忘类别样本的预测，这种方法对MIA-NN具有鲁棒性。我们还引入了一种基于预测概率总变差（TV）距离的新度量，以量化残余泄漏，防止未来的方法容易受到新攻击的影响。通过对最先进的机器学习遗忘基线进行大量实验，我们表明我们的方法在先前工作使用的两种评估指标和我们在这项工作中提出的新指标上都与完全重新训练的结果相匹配。与最先进的方法相比，我们在先前使用的指标上获得了2.79%的提升，在我们的新TV-based指标上比现有最佳方法提升了111.45%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [84] [Task Arithmetic Through The Lens Of One-Shot Federated Learning](https://arxiv.org/abs/2411.18607)
> *任务算术通过一次性联邦学习的视角*

*Zhixu Silvia Tao, Ian Mason, Sanjeev Kulkarni, Xavier Boix* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 任务算术, 联邦学习, 模型合并, 联邦平均, 异质性

**Comment:** Published in Transactions on Machine Learning Research

> **TL;DR:** 本文将任务算术与联邦学习联系起来，证明其与FedAvg等效，并利用联邦学习理论识别并解决影响任务算术性能的数据和训练异质性问题，从而提升模型合并效果。

**AI_Comments:** 本文的创新点在于将任务算术与联邦学习建立了联系，通过联邦学习的理论框架解释了任务算术的成功因素（数据和训练异质性），并提供了实际的改进方法。这种跨领域的视角为理解和优化模型合并技术提供了新的思路，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 任务算术是一种模型合并技术，但其成功因素尚不明确。

**Method:** 将任务算术框架化为一次性联邦学习问题，并证明其与联邦平均（FedAvg）在数学上等效。利用FedAvg的理论成果，识别影响任务算术性能的关键因素（数据异质性和训练异质性），并从联邦学习中借鉴算法来改进任务算术。

**Result:** 实验表明，应用联邦学习算法可以显著提升合并模型的性能，优于原始的任务算术方法。

**Conclusion:** 这项工作连接了任务算术和联邦学习，为任务算术提供了新的理论视角，并为模型合并提供了改进的实用方法。

> **ai_Abstract:** 本文探讨了任务算术（一种无需额外微调即可合并模型的技术），通过将其视为一次性联邦学习问题，揭示了其与联邦平均（FedAvg）的数学等效性。研究发现数据异质性和训练异质性是影响任务算术性能的关键因素。为解决这些问题，作者引入了联邦学习中的算法，并通过实验证明这些改进显著提升了模型合并的效果。这项工作为任务算术提供了理论基础和实用的改进方法。

> **摘要翻译:** 任务算术是一种模型合并技术，它通过在权重空间中进行简单的算术运算，将多个模型的能力组合成一个单一模型，而无需额外的微调或访问原始训练数据。然而，决定任务算术成功与否的因素仍不清楚。在本文中，我们通过将其框定为一次性联邦学习问题来研究用于多任务学习的任务算术。我们证明了任务算术在数学上等同于联邦学习中常用的算法，称为联邦平均（FedAvg）。通过利用FedAvg成熟的理论结果，我们确定了影响任务算术性能的两个关键因素：数据异质性和训练异质性。为了缓解这些挑战，我们借鉴了联邦学习中的几种算法来提高任务算术的有效性。我们的实验表明，与原始任务算术方法相比，应用这些算法通常可以显著提升合并模型的性能。这项工作连接了任务算术和联邦学习，为任务算术提供了新的理论视角，并为模型合并提供了改进的实用方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [86] [SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation](https://arxiv.org/abs/2507.08508)
> *SFedKD：基于差异感知多教师知识蒸馏的序列联邦学习*

*Haotian Xu, Jinrui Zhou, Xichong Zhang, Mingjun Xiao, He Sun, Yin Xu* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 序列联邦学习, 知识蒸馏, 灾难性遗忘, 多教师学习, 联邦学习

**Comment:** 

> **TL;DR:** 提出SFedKD，一种新的序列联邦学习框架，通过差异感知多教师知识蒸馏和互补教师选择机制，有效解决了序列联邦学习中的灾难性遗忘问题。

**AI_Comments:** SFedKD的创新点在于将多教师知识蒸馏引入序列联邦学习，并提出差异感知加权策略来处理数据异构性下的知识遗忘。其互补性教师选择机制也有效地解决了多教师设置中知识稀释和计算成本问题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 序列联邦学习（SFL）在数据异构下具有强收敛保证，但实验表明SFL在异构环境中存在严重的灾难性遗忘问题，即模型倾向于遗忘从先前客户端学习到的知识。

**Method:** 提出SFedKD框架，采用差异感知多教师知识蒸馏。首先，从上一轮中选择多个模型作为教师来指导当前轮训练。其次，将单教师解耦知识蒸馏扩展到多教师设置，并根据教师和学生数据之间的类别分布差异，为教师的目标类别和非目标类别知识分配不同的权重，以增强模型训练效率并减轻灾难性遗忘。此外，为防止知识稀释，通过将冗余教师消除形式化为最大覆盖问题的一个变体，并基于贪婪策略设计互补性教师选择机制，确保所选教师实现全面的知识空间覆盖，同时降低通信和计算成本。

**Result:** SFedKD有效地克服了SFL中的灾难性遗忘问题，并优于最先进的联邦学习方法。

**Conclusion:** SFedKD通过其差异感知多教师知识蒸馏和高效教师选择机制，成功解决了序列联邦学习中的灾难性遗忘问题，提升了模型性能。

> **ai_Abstract:** 该论文提出了SFedKD，一个用于序列联邦学习（SFL）的新框架，旨在解决SFL在异构环境中严重的灾难性遗忘问题。SFedKD通过引入差异感知多教师知识蒸馏，从上一轮中选择多个教师模型指导当前训练，并根据类别分布差异对教师知识进行细粒度加权。此外，它还设计了一种基于互补性的教师选择机制，以消除冗余教师并优化知识覆盖范围。实验证明SFedKD能有效缓解灾难性遗忘，并超越现有联邦学习方法。

> **摘要翻译:** 联邦学习（FL）是一种分布式机器学习范式，它协调多个客户端通过中央服务器协同训练一个全局模型。序列联邦学习（SFL）是一种新兴的FL训练框架，其中全局模型以序列方式跨客户端进行训练。由于SFL在数据异构性下可以提供强大的收敛保证，近年来引起了广泛的研究关注。然而，实验表明SFL在异构环境中遭受严重的灾难性遗忘，这意味着模型倾向于遗忘从先前客户端学习到的知识。为了解决这个问题，我们提出了一种名为SFedKD的SFL框架，它采用差异感知多教师知识蒸馏，从上一轮中选择多个模型来指导当前轮的训练。在SFedKD中，我们将单教师解耦知识蒸馏方法扩展到我们的多教师设置，并根据教师和学生数据之间的类别分布差异，为教师的目标类别和非目标类别知识分配不同的权重。通过这种细粒度的加权策略，SFedKD可以提高模型训练效率，同时减轻灾难性遗忘。此外，为了防止知识稀释，我们消除了知识蒸馏中的冗余教师，并将其形式化为最大覆盖问题的一个变体。基于贪婪策略，我们设计了一种基于互补性的教师选择机制，以确保所选教师实现全面的知识空间覆盖，同时降低通信和计算成本。大量的实验表明，SFedKD有效地克服了SFL中的灾难性遗忘，并优于最先进的FL方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [102] [Recursive Reward Aggregation](https://arxiv.org/abs/2507.08537)
> *递归奖励聚合*

*Yuting Tang, Yivan Zhang, Johannes Ackermann, Yu-Jie Zhang, Soichiro Nishimori, Masashi Sugiyama* | **Category: cs.LG, math.CT** | **Updated: 2025-07-11**

**Keywords:** 强化学习, 奖励聚合, 行为对齐, 马尔可夫决策过程, 贝尔曼方程

**Comment:** Reinforcement Learning Conference 2025

> **TL;DR:** 本文提出了一种通过选择合适的奖励聚合函数来灵活调整强化学习智能体行为的方法，无需修改奖励函数，并通过代数视角展示了其泛化能力和与现有算法的兼容性。

**AI_Comments:** 该论文的创新点在于提出了“递归奖励聚合”的概念，通过改变奖励的聚合方式而非奖励函数本身来实现行为对齐，这为复杂目标下的强化学习提供了一个新颖且灵活的解决方案。引入MDP的代数视角统一了多种聚合方式，并证明了其与贝尔曼方程的内在联系，具有重要的理论意义。其与现有算法的无缝集成也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在强化学习中，将智能体行为与复杂目标对齐通常需要精心设计奖励函数，这具有挑战性。

**Method:** 本文提出了一种通过选择适当的奖励聚合函数来替代修改奖励函数的方法。通过引入马尔可夫决策过程（MDPs）的代数视角，展示了贝尔曼方程如何从奖励的递归生成和聚合中自然产生，从而将标准折扣和泛化到其他递归聚合，如折扣最大值和夏普比率。该方法适用于确定性和随机设置，并能与基于价值和演员-评论家算法无缝集成。

**Result:** 实验结果表明，该方法能够有效地优化多种目标。

**Conclusion:** 所提出的递归奖励聚合方法提供了一种灵活的行为对齐方式，无需修改奖励函数，并通过代数视角统一了多种奖励聚合方式，且能与现有RL算法兼容，在多样化目标优化中表现出有效性。

> **ai_Abstract:** 本文提出了一种名为“递归奖励聚合”的强化学习新方法，旨在解决复杂目标下奖励函数设计困难的问题。该方法通过选择合适的奖励聚合函数来调整智能体行为，而非直接修改奖励函数。通过引入马尔可夫决策过程的代数视角，作者展示了贝尔曼方程如何从递归奖励聚合中自然推导出来，并能将传统的折扣和泛化到如折扣最大值和夏普比率等其他形式。该方法适用于确定性和随机环境，并能与现有价值基和演员-评论家算法良好结合。实验证明，该方法能有效优化多种目标，展现了其通用性和应用潜力。

> **摘要翻译:** 在强化学习（RL）中，将智能体行为与特定目标对齐通常需要精心设计奖励函数，当期望目标复杂时，这可能具有挑战性。在这项工作中，我们提出了一种灵活行为对齐的替代方法，通过选择适当的奖励聚合函数，无需修改奖励函数。通过引入马尔可夫决策过程（MDPs）的代数视角，我们展示了贝尔曼方程如何从奖励的递归生成和聚合中自然产生，从而允许将标准折扣和泛化到其他递归聚合，例如折扣最大值和夏普比率。我们的方法适用于确定性和随机设置，并能与基于价值和演员-评论家算法无缝集成。实验结果表明，我们的方法有效地优化了多样化的目标，突出了其多功能性和在实际应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [104] [Distributional Soft Actor-Critic with Diffusion Policy](https://arxiv.org/abs/2507.01381)
> *带扩散策略的分布软演员-评论家算法*

*Tong Liu, Yinuo Wang, Xujie Song, Wenjun Zou, Liangfa Chen, Likun Wang, Bin Shuai, Jingliang Duan, Shengbo Eben Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 强化学习, 分布式强化学习, 扩散模型, 多峰策略, 价值函数估计

**Comment:** Accepted IEEE ITSC 2025

> **TL;DR:** DSAC-D是一种新的分布强化学习算法，它利用扩散模型来解决传统方法中价值估计偏差和单峰策略的问题。该算法能够学习多峰策略，并在MuJoCo任务中实现SOTA性能，在真实车辆测试中也能准确表征多峰驾驶风格。

**AI_Comments:** 该论文的创新之处在于将扩散模型引入到分布强化学习中，以捕捉多峰价值分布和策略，这相对于传统的单峰方法是一个重大进步。它解决了强化学习中的一个关键限制，使得能够学习多样化的行为并进行更准确的价值估计，从而在模拟和自动驾驶等实际应用中实现了SOTA性能。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习方法通常使用单峰分布来建模价值函数的输出，这容易导致价值函数估计的偏差，从而降低算法性能。此外，传统方法难以获得多峰策略表示。

**Method:** 本文提出了一种名为DSAC-D（带扩散策略的分布软演员-评论家算法）的分布强化学习算法。该算法通过引入策略熵和价值分布函数，建立了一个可以收敛到最优策略的多峰分布策略迭代框架。通过使用扩散模型进行逆向采样生成奖励样本，构建了一个能够准确表征多峰分布的扩散价值网络。在此基础上，推导出了价值网络和策略网络双重扩散的分布强化学习算法。

**Result:** 在MuJoCo测试任务中，DSAC-D不仅学习了多峰策略，而且在所有9个控制任务中均达到了最先进（SOTA）的性能。与现有主流算法相比，该算法显著抑制了估计偏差，总平均回报提高了10%以上。在真实车辆测试中，DSAC-D能够准确表征不同驾驶风格的多峰分布，并且扩散策略网络能够表征多峰轨迹。

**Conclusion:** DSAC-D算法有效地解决了强化学习中价值函数估计偏差和多峰策略表示的挑战。它在模拟和真实世界环境中都表现出卓越的性能，能够捕获复杂的行为分布。

> **ai_Abstract:** 本文提出了一种名为DSAC-D的新型分布强化学习算法，旨在克服传统强化学习方法中单峰价值函数估计导致的偏差和性能限制。DSAC-D通过引入扩散模型构建了一个能够准确表征多峰分布的扩散价值网络，并建立了价值网络和策略网络双重扩散的框架。该算法在MuJoCo任务中表现出卓越性能，实现了SOTA，显著减少了估计偏差，并有效学习了多峰策略。此外，在真实车辆测试中，DSAC-D能够准确表征不同驾驶风格的多峰分布和轨迹，显示出其在复杂控制任务和多样化行为建模方面的强大能力。

> **摘要翻译:** 强化学习已被证明在处理复杂控制任务方面非常有效。传统方法通常使用单峰分布，例如高斯分布，来建模价值分布的输出。然而，单峰分布常常容易导致价值函数估计的偏差，从而导致算法性能不佳。本文提出了一种名为DSAC-D（带扩散策略的分布软演员-评论家算法）的分布强化学习算法，以解决价值函数估计偏差和获取多峰策略表示的挑战。通过引入策略熵和价值分布函数，建立了可以收敛到最优策略的多峰分布策略迭代框架。通过使用扩散模型进行逆向采样生成一组奖励样本，构建了一个能够准确表征多峰分布的扩散价值网络。在此基础上，推导出了价值网络和策略网络双重扩散的分布强化学习算法。MuJoCo测试任务表明，所提出的算法不仅学习了多峰策略，而且在所有9个控制任务中均达到了最先进（SOTA）的性能，与现有主流算法相比，显著抑制了估计偏差，总平均回报提高了10%以上。真实车辆测试结果表明，DSAC-D能够准确表征不同驾驶风格的多峰分布，并且扩散策略网络能够表征多峰轨迹。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [105] [EvA: Evolutionary Attacks on Graphs](https://arxiv.org/abs/2507.08212)
> *EvA：图上的演化攻击*

*Mohammad Sadegh Akhondzadeh, Soroush H. Zargarbashi, Jimin Cao, Aleksandar Bojchevski* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 图神经网络攻击, 演化算法, 黑盒攻击, 离散优化, 对抗性扰动

**Comment:** 23 pages, 12 figures

> **TL;DR:** EvA是一种基于演化算法的黑盒攻击，能够直接解决图结构上的离散优化问题，比现有攻击更有效。

**AI_Comments:** EvA的创新之处在于它直接处理了图结构攻击的离散优化问题，避免了传统基于梯度方法的局限性。其黑盒适用性以及对不可微分目标的攻击能力是其重要特点，揭示了GNNs在对抗性攻击面前的潜在脆弱性。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对图神经网络（GNNs）的攻击大多依赖梯度信息，将离散优化问题松弛到连续空间，导致次优解且限制了对不可微分目标的适应性。本文旨在解决这一问题。

**Method:** 本文提出了一种名为EvA（Evolutionary Attack）的演化攻击方法。它通过对基于演化算法进行简单而有效的增强，直接解决离散优化问题。EvA适用于任何黑盒模型和目标，无需可微分的代理损失，并能够设计新的攻击来降低鲁棒性证书的有效性并破坏一致性集。其内存复杂度与攻击预算呈线性关系。

**Result:** EvA在实验中比之前最好的攻击方法平均额外降低了约11%的准确率，揭示了设计攻击的巨大未开发潜力。

**Conclusion:** EvA通过直接解决离散优化问题，显著提高了对图神经网络的攻击效果，并且适用于黑盒模型和不可微分目标，证明了演化算法在图攻击领域的巨大潜力。

> **ai_Abstract:** 本文提出了一种名为EvA的演化攻击方法，旨在解决现有图神经网络攻击中依赖梯度信息导致离散优化问题松弛和适用性受限的问题。EvA通过增强演化算法直接在离散空间进行优化，支持任何黑盒模型和不可微分目标。实验结果表明，EvA比现有最佳攻击方法平均额外降低了约11%的准确率，展现了其在图攻击方面的显著潜力。

> **摘要翻译:** 即使图结构发生轻微扰动，也可能导致图神经网络（GNNs）的准确性显著下降。大多数现有攻击利用梯度信息来扰动边缘。这使得攻击的优化问题从离散空间松弛到连续空间，导致解决方案远非最优。这也限制了攻击对不可微分目标的适应性。相反，我们引入了一些简单但有效的增强，针对基于演化算法，以直接解决离散优化问题。我们的演化攻击（EvA）适用于任何黑盒模型和目标，消除了对可微分代理损失的需求。这使我们能够设计两种新颖的攻击，从而降低鲁棒性证书的有效性并破坏一致性集。我们攻击的内存复杂度与攻击预算呈线性关系。在我们的实验中，与之前最好的攻击相比，EvA平均额外降低了约11%的准确性，揭示了设计攻击的巨大未开发潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [108] [Predicting Barge Presence and Quantity on Inland Waterways using Vessel Tracking Data: A Machine Learning Approach](https://arxiv.org/abs/2501.00615)
> *利用船舶跟踪数据预测内陆水域驳船存在与数量：一种机器学习方法*

*Geoffery Agorku, Sarah Hernandez, Maria Falquez, Subhadipto Poddar, Shihao Pang* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 驳船存在, 驳船数量, 内陆水域, 船舶跟踪数据, 机器学习

**Comment:** 

> **TL;DR:** 本研究利用AIS船舶跟踪数据，通过机器学习方法预测内陆水域驳船的存在和数量，以支持货运量估算和水路管理。

**AI_Comments:** 这项研究的创新之处在于，它解决了AIS数据在监测驳船存在和数量方面的局限性，通过结合其他数据源（交通摄像头）和先进的机器学习技术，成功地从现有数据中提取了未被直接报告的关键信息。这对于内陆水运的货运量估算、基础设施规划和资源分配具有重要的实际意义。模型的F1分数表明了其预测的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 了解驳船数量和类型对于估算内陆水域货运量、水路管理以及基础设施运营（如目标疏浚作业和数据驱动的资源分配）至关重要。AIS数据本身不监测驳船信息，因此需要开发一种方法来填补这一空白。

**Method:** 本研究采用机器学习方法，利用自动识别系统（AIS）的船舶跟踪数据。首先，通过交通摄像头观察生成标记样本数据，并与AIS数据记录匹配。数据集包含164艘船舶，每艘最多42个驳船船队。方法分为两步：首先预测驳船是否存在，然后预测驳船数量。特征提取自AIS数据，包括速度测量、船舶特性、转向测量和交互项。使用AdaBoost模型预测驳船存在，使用随机森林结合AdaBoost集成模型预测驳船数量。贝叶斯优化用于超参数调优。

**Result:** 在预测驳船存在方面，AdaBoost模型达到了0.932的F1分数。在预测驳船数量方面，随机森林结合AdaBoost集成模型达到了0.886的F1分数。

**Conclusion:** 通过推进内陆水域的预测建模，本研究为运输规划者和组织提供了宝贵的见解，他们需要详细了解交通量，包括商品流向、目的地以及进出港口的吨位。

> **ai_Abstract:** 本研究利用机器学习方法，基于自动识别系统（AIS）的船舶跟踪数据，预测内陆水域驳船的存在和数量。由于AIS不直接提供驳船信息，研究人员通过交通摄像头数据生成标记样本，并提取AIS特征（如速度、船舶特性）进行建模。AdaBoost模型在驳船存在预测中F1分数达到0.932，而随机森林结合AdaBoost集成模型在驳船数量预测中F1分数达到0.886。该研究为运输规划和水路管理提供了重要的数据洞察。

> **摘要翻译:** 本研究提出了一种机器学习方法，利用自动识别系统（AIS）的跟踪数据预测内陆水域船舶运输的驳船数量。虽然AIS跟踪拖船和驳船的地理位置，但它不监测这些船舶运输的驳船是否存在或数量。了解沿河段、港口之间以及港口内的驳船数量和类型对于估算国家水路运输的货运量至关重要。这种洞察力对于水路管理和基础设施运营也很有价值，影响着诸如目标疏浚作业和数据驱动的资源分配等领域。标记样本数据是利用沿关键河段的交通摄像头观察生成并与AIS数据记录匹配的。模型开发使用了164艘船舶的样本，每艘最多42个驳船船队。该方法首先预测驳船是否存在，然后预测驳船数量。从AIS数据中提取的特征包括速度测量、船舶特性、转向测量和交互项。在预测驳船存在方面，AdaBoost模型达到了0.932的F1分数。在预测驳船数量方面，随机森林结合AdaBoost集成模型达到了0.886的F1分数。贝叶斯优化用于超参数调优。通过推进内陆水域的预测建模，本研究为需要详细了解交通量（包括商品流向、目的地以及进出港口吨位）的运输规划者和组织提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [122] [CircFormerMoE: An End-to-End Deep Learning Framework for Circular RNA Splice Site Detection and Pairing in Plant Genomes](https://arxiv.org/abs/2507.08542)
> *CircFormerMoE：一个用于植物基因组环状RNA剪接位点检测和配对的端到端深度学习框架*

*Tianyou Jiang* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 环状RNA, 深度学习, 植物基因组, 剪接位点, Transformer

**Comment:** 

> **TL;DR:** CircFormerMoE是一个基于Transformer和Mixture-of-Experts的深度学习框架，可以直接从植物基因组DNA预测环状RNA，解决了现有方法效率低、计算成本高且无法直接从基因组预测的问题，并能发现未注释的环状RNA。

**AI_Comments:** 这篇论文的创新点在于提出了一个端到端、直接从基因组DNA预测植物环状RNA的深度学习框架，克服了传统方法对RNA实验数据的依赖和高计算成本的限制。其采用Transformer和Mixture-of-Experts架构，并能处理植物基因组中非典型剪接位点的问题，显著提高了植物环状RNA识别的效率和准确性。此外，模型的可解释性分析也增加了其研究价值。这项工作为植物功能基因组学和非编码RNA研究提供了重要的计算工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有环状RNA识别方法依赖RNA-seq数据和比对算法，无法直接从基因组DNA预测，计算成本高，效率低下，不适用于大规模预测。在植物中，环状RNA剪接位点常缺乏典型GT-AG基序，且缺乏高效、泛化能力强的深度学习模型，导致已识别的植物环状RNA数量远低于实际丰度。

**Method:** 提出名为CircFormerMoE的深度学习框架，基于Transformer和Mixture-of-Experts架构，直接从植物基因组DNA预测环状RNA。该框架包含剪接位点检测（SSD）和剪接位点配对（SSP）两个子任务。对训练模型进行了可解释性分析。

**Result:** 模型在10种植物的基因数据上得到了有效验证，能够发现以前未注释的环状RNA。该框架提供了一种快速、准确的计算方法和工具，用于植物中大规模环状RNA的发现。

**Conclusion:** CircFormerMoE框架为植物中环状RNA的发现提供了一个快速准确的计算方法和工具，为植物功能基因组学和非编码RNA注释的未来研究奠定了基础。

> **ai_Abstract:** 本文提出了一个名为CircFormerMoE的深度学习框架，该框架基于Transformer和Mixture-of-Experts，旨在解决现有方法无法直接从基因组DNA预测环状RNA、计算成本高以及在植物中效率低下的问题。CircFormerMoE能够直接从植物基因组DNA预测环状RNA，包含剪接位点检测和配对两个子任务。该模型已在10种植物基因数据上验证，证明其能有效发现已知及未注释的环状RNA，为植物环状RNA的大规模发现提供了快速准确的计算工具。

> **摘要翻译:** 环状RNA（circRNA）是非编码RNA调控网络的重要组成部分。之前的circRNA识别主要依赖于高通量RNA测序（RNA-seq）数据结合基于比对的算法来检测反向剪接信号。然而，这些方法面临几个局限性：它们无法直接从基因组DNA序列预测circRNA，且严重依赖RNA实验数据；由于复杂的比对和过滤步骤，它们涉及高计算成本；并且它们对于大规模或全基因组circRNA预测效率低下。在植物中，挑战甚至更大，因为植物circRNA剪接位点通常缺乏在人类mRNA剪接中看到的典型GT-AG基序，并且目前没有高效且泛化能力强的深度学习模型存在。此外，目前已识别的植物circRNA数量可能远低于它们的真实丰度。在本文中，我们提出了一个名为CircFormerMoE的深度学习框架，它基于transformer和mixture-of-experts，用于直接从植物基因组DNA预测circRNA。我们的框架包括剪接位点检测（SSD）和剪接位点配对（SSP）两个子任务。该模型的有效性已在10种植物的基因数据上得到验证。通过已知circRNA实例的训练，它还能够发现以前未注释的circRNA。此外，我们对训练后的模型进行了可解释性分析，以研究有助于其预测的序列模式。我们的框架为植物中大规模circRNA的发现提供了一种快速准确的计算方法和工具，为植物功能基因组学和非编码RNA注释的未来研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [132] [Open Materials Generation with Stochastic Interpolants](https://arxiv.org/abs/2502.02582)
> *随机插值法开放式材料生成*

*Philipp Hoellmer, Thomas Egg, Maya M. Martirossyan, Eric Fuemmeler, Zeren Shui, Amit Gupta, Pawan Prakash, Adrian Roitberg, Mingjie Liu, George Karypis, Mark Transtrum, Richard G. Hennig, Ellad B. Tadmor, Stefano Martiniani* | **Category: cs.LG, cond-mat.mtrl-sci** | **Updated: 2025-07-11**

**Keywords:** 材料生成, 随机插值法, 晶体结构预测, 深度学习, 生成建模

**Comment:** Accepted at Forty-second International Conference on Machine Learning
  (ICML): https://openreview.net/forum?id=gHGrzxFujU

> **TL;DR:** OMatG是一个使用随机插值法的新型生成式框架，用于发现无机晶体材料，在材料发现的生成建模方面达到了新的SOTA。

**AI_Comments:** OMatG的创新之处在于其统一的随机插值法框架，能够整合并超越现有的扩散模型和流匹配方法，并针对晶体结构特性（如等变性、周期性边界条件）进行了专门优化。这为材料发现领域提供了一个更灵活、更强大的生成工具，有望显著加速新材料的发现过程。

<details>
  <summary>Details</summary>

**Motivation:** 发现新材料对于实现技术进步至关重要，而计算方法需要有效学习无限设计空间中稳定晶体结构的流形。

**Method:** 本文引入了Open Materials Generation (OMatG)框架，该框架利用随机插值法 (SI) 将任意基础分布与无机晶体目标分布连接起来，涵盖扩散模型和流匹配。该方法通过整合晶体结构的等变图表示，并扩展以考虑晶胞表示中的周期性边界条件来适应SI框架，同时将空间坐标和晶格向量上的SI流与原子物种的离散流匹配相结合。

**Result:** OMatG在晶体结构预测 (CSP) 和“从头开始”生成 (DNG) 任务上进行了基准测试，并改进了现有指标。OMatG在材料发现的生成建模方面建立了新的SOTA，超越了纯粹基于流和基于扩散的实现。

**Conclusion:** OMatG通过其灵活的深度学习框架加速了材料科学的进展，并在材料发现的生成建模方面取得了显著的领先地位。

> **ai_Abstract:** 本文介绍了Open Materials Generation (OMatG)，一个用于无机晶体材料生成设计和发现的统一框架。OMatG利用随机插值法，结合等变图表示和周期性边界条件处理，并在空间坐标和原子种类上进行流匹配。OMatG在晶体结构预测和“从头开始”生成任务上表现出色，超越了现有的基于流和扩散的模型，达到了材料发现生成建模的新SOTA，突显了灵活深度学习框架在材料科学中的重要性。

> **摘要翻译:** 新材料的发现对于实现技术进步至关重要。预测新型材料的计算方法必须有效地学习无限设计空间中稳定晶体结构的流形。我们引入了开放式材料生成（OMatG），这是一个用于无机晶体材料生成设计和发现的统一框架。OMatG采用随机插值法（SI），通过广泛的可调随机过程将任意基础分布与无机晶体目标分布连接起来，其中包括扩散模型和流匹配作为特例。在这项工作中，我们通过整合晶体结构的等变图表示并将其扩展以考虑晶胞表示中的周期性边界条件来适应SI框架。此外，我们将空间坐标和晶格向量上的SI流与原子物种的离散流匹配相结合。我们在两项任务上对OMatG的性能进行了基准测试：特定组成的晶体结构预测（CSP）和旨在发现稳定、新颖和独特结构的“从头开始”生成（DNG）。在我们从零开始实现的OMatG中，我们相比之前的工作改进并扩展了CSP和DNG指标。OMatG在材料发现的生成建模方面建立了新的最先进水平，超越了纯粹基于流和基于扩散的实现。这些结果强调了设计灵活的深度学习框架以加速材料科学进展的重要性。OMatG代码可在https://github.com/FERMat-ML/OMatG 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [133] [InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems](https://arxiv.org/abs/2507.08235)
> *InsightBuild：LLM驱动的智能建筑系统因果推理*

*Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 智能建筑, 因果推理, 大型语言模型, 能耗分析, 设施管理

**Comment:** 

> **TL;DR:** InsightBuild是一个两阶段框架，结合因果分析和微调的大型语言模型（LLM），为智能建筑中的异常能耗提供人类可读的因果解释，帮助设施经理诊断和缓解能源效率低下。

**AI_Comments:** 本文的创新点在于将传统的因果推理方法与大型语言模型（LLM）的自然语言生成能力相结合，为复杂的智能建筑数据提供了可理解的因果解释。这种结合使得系统不仅能发现因果关系，还能以人类友好的方式呈现，极大地提升了设施管理人员诊断和解决能源问题的效率。其重要性体现在将数据转化为可操作的洞察，弥合了数据分析与实际应用之间的鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 智能建筑产生大量的传感器和控制数据，但设施经理往往缺乏对异常能耗的清晰解释。

**Method:** 本文提出了InsightBuild，一个两阶段框架。首先，一个轻量级因果推理模块对来自Google Smart Buildings和Berkeley Office数据集的建筑遥测数据（如温度、HVAC设置、占用率）应用Granger因果关系检验和结构因果发现。其次，一个在传感器级原因和文本解释对上微调的LLM接收检测到的因果关系作为输入，并生成简洁、可操作的解释。

**Result:** InsightBuild在两个真实世界数据集（Google: 2017-2022；Berkeley: 2018-2020）上进行了评估，结果表明，将显式因果发现与基于LLM的自然语言生成相结合，可以产生清晰、精确的解释，有助于设施经理诊断和缓解能源效率低下。

**Conclusion:** 结合显式因果发现与LLM驱动的自然语言生成，可以为智能建筑的能耗模式提供清晰、精确的因果解释，从而有效协助设施经理诊断和解决能源效率问题。

> **ai_Abstract:** InsightBuild是一个旨在解决智能建筑中异常能耗解释缺失问题的两阶段框架。它首先利用因果推理模块（包括Granger因果关系检验和结构因果发现）分析建筑遥测数据，以识别因果关系。随后，一个经过微调的大型语言模型（LLM）将这些检测到的因果关系转化为人类可读且可操作的自然语言解释。该框架在真实世界数据集上的评估表明，它能有效地提供清晰、精确的能耗解释，从而帮助设施经理诊断并优化能源效率。

> **摘要翻译:** 智能建筑产生大量的传感器和控制数据，但设施经理往往缺乏对异常能耗的清晰解释。我们提出了InsightBuild，一个两阶段框架，它将因果分析与微调的大型语言模型（LLM）相结合，以提供人类可读的能耗模式因果解释。首先，一个轻量级因果推理模块对从Google Smart Buildings和Berkeley Office数据集中提取的建筑遥测数据（例如，温度、HVAC设置、占用率）应用Granger因果关系检验和结构因果发现。接下来，一个在传感器级原因和文本解释对上微调的LLM接收检测到的因果关系作为输入，并生成简洁、可操作的解释。我们在两个真实世界数据集（Google: 2017-2022；Berkeley: 2018-2020）上评估了InsightBuild，对一组保留的异常使用了专家标注的真实原因。我们的结果表明，将显式因果发现与基于LLM的自然语言生成相结合，可以产生清晰、精确的解释，有助于设施经理诊断和缓解能源效率低下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [142] [STRAP: Spatial-Temporal Risk-Attentive Vehicle Trajectory Prediction for Autonomous Driving](https://arxiv.org/abs/2507.08563)
> *STRAP：自动驾驶中时空风险感知车辆轨迹预测*

*Xinyi Ning, Zilin Bian, Kaan Ozbay, Semiha Ergan* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 车辆轨迹预测, 风险感知, 时空建模, 自动驾驶, 深度学习

**Comment:** 6 pages, 3 figures, accepted at ITSC 2025

> **TL;DR:** STRAP提出了一种新的时空风险感知轨迹预测框架，通过引入风险势场和风险加权损失函数，显著提高了自动驾驶中车辆轨迹预测的准确性，尤其是在高风险场景下。

**AI_Comments:** 该论文的创新点在于将“风险”这一概念显式地引入到车辆轨迹预测中，通过构建风险势场和设计风险加权损失函数，有效提升了模型在复杂高风险场景下的预测性能和鲁棒性。这对于自动驾驶系统的安全性和决策质量具有重要意义，使其预测不仅关注常规运动模式，更能预判并规避潜在危险。

<details>
  <summary>Details</summary>

**Motivation:** 现有的车辆轨迹预测方法主要关注建模观察到的运动模式和车辆间的交互，但往往忽略了周围车辆不确定或激进行为可能带来的潜在风险。

**Method:** 本文提出了一种新颖的时空风险感知轨迹预测框架（STRAP），该框架通过引入风险势场来评估附近车辆行为产生的感知风险。它利用一个时空编码器和一个风险感知特征融合解码器，将风险势场嵌入到提取的时空特征表示中进行轨迹预测。此外，还设计了一个风险加权损失函数，以提高高风险场景（如相对间距较短）的预测准确性。

**Result:** 在广泛使用的NGSIM和HighD数据集上的实验表明，与现有最先进的方法相比，STRAP分别将平均预测误差降低了4.8%和31.2%，特别是在高风险场景下表现更优。

**Conclusion:** 所提出的框架提供了可解释的、风险感知的预测，有助于自动驾驶系统做出更稳健的决策。

> **ai_Abstract:** 本文提出了一种名为STRAP的时空风险感知车辆轨迹预测框架，旨在解决现有方法忽略周围车辆不确定或激进行为带来的风险问题。STRAP通过引入风险势场来评估感知风险，并利用时空编码器和风险感知特征融合解码器将风险信息融入轨迹预测。此外，还设计了风险加权损失函数以提高高风险场景的预测精度。实验结果表明，该方法在NGSIM和HighD数据集上显著降低了预测误差，尤其在高风险场景下表现优异，为自动驾驶系统提供了更稳健、可解释的风险感知预测。

> **摘要翻译:** 准确的车辆轨迹预测对于确保全自动驾驶系统的安全性和效率至关重要。虽然现有方法主要侧重于建模观察到的运动模式以及与其他车辆的交互，但它们往往忽略了周围车辆不确定或激进行为可能带来的潜在风险。在本文中，我们提出了一种新颖的时空风险感知轨迹预测框架，该框架结合了风险势场来评估附近车辆行为产生的感知风险。该框架利用时空编码器和风险感知特征融合解码器，将风险势场嵌入到提取的时空特征表示中进行轨迹预测。此外，还设计了一个风险加权损失函数，以提高高风险场景（例如短相对间距）的预测准确性。在广泛使用的NGSIM和HighD数据集上的实验表明，与最先进的方法相比，我们的方法分别将平均预测误差降低了4.8%和31.2%，尤其是在高风险场景中。所提出的框架提供了可解释的、风险感知的预测，有助于自动驾驶系统做出更稳健的决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [156] [Rethinking Approximate Gaussian Inference in Classification](https://arxiv.org/abs/2502.03366)
> *重新思考分类中的近似高斯推断*

*Bálint Mucsányi, Nathaël Da Costa, Philipp Hennig* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 近似高斯推断, 不确定性量化, normCDF, sigmoid

**Comment:** 35 pages

> **TL;DR:** 论文提出用normCDF或sigmoid代替分类中近似高斯推断的softmax函数，以消除昂贵的蒙特卡洛采样，从而提高不确定性量化能力。

**AI_Comments:** 这篇论文通过提出用normCDF或sigmoid替换softmax，巧妙地解决了分类任务中近似高斯推断的计算瓶颈，即昂贵的蒙特卡洛采样问题。其创新点在于提供了一种采样无关的、更高效且准确的不确定性量化方法。这对于需要高效处理不确定性的应用场景（如自动驾驶、医疗诊断）具有重要意义，因为它显著降低了计算成本并提高了效率。

<details>
  <summary>Details</summary>

**Motivation:** 在分类任务中，softmax函数作为输出激活函数仅捕获偶然不确定性。为了捕获认知不确定性，提出了近似高斯推断方法，但其预测值需要通过softmax高斯积分，这无法解析求解，且蒙特卡洛（MC）近似成本高昂且噪声大。

**Method:** 论文提出一个通用形式来描述近似高斯推断方法，将其视为在logit空间输出高斯分布。为了解决softmax高斯积分的难题，论文建议用逐元素的normCDF或sigmoid函数替代softmax激活函数。这种替代允许对预测值进行精确的无采样近似，并能通过矩匹配将高斯前推近似为狄利克雷分布。

**Result:** 该方法完全消除了与MC采样相关的运行时和内存开销。在大型和小型数据集（ImageNet, CIFAR-100, CIFAR-10）上与几种近似高斯推断方法（Laplace, HET, SNGP）结合评估，结果表明与softmax MC采样相比，不确定性量化能力有所提高。

**Conclusion:** 通过用normCDF或sigmoid替代softmax，可以有效消除分类中近似高斯推断的蒙特卡洛采样开销，并显著提高不确定性量化能力。

> **ai_Abstract:** 本文重新审视了分类任务中的近似高斯推断方法，并提出了一个通用框架。针对现有方法中softmax高斯积分难以解析求解且蒙特卡洛采样成本高昂的问题，作者提出用逐元素的normCDF或sigmoid函数替代softmax激活函数。这种新方法实现了预测值的无采样精确近似，并能通过矩匹配将高斯前推近似为狄利克雷分布，从而消除了运行时和内存开销。实验证明，该方法在不确定性量化方面优于传统的softmax MC采样方法。

> **摘要翻译:** 在分类任务中，softmax函数作为输出激活函数被普遍用于生成预测概率。这种输出只捕获偶然不确定性。为了捕获认知不确定性，已经提出了近似高斯推断方法。我们开发了一个通用形式来描述这些方法，我们将其视为在logit空间输出高斯分布。然后，预测值通过高斯分布经softmax函数前推的期望获得。然而，这种softmax高斯积分无法解析求解，并且蒙特卡洛（MC）近似可能成本高昂且噪声大。我们建议用逐元素的normCDF或sigmoid替换softmax激活函数，这允许对预测值进行精确的无采样近似。这也使得通过矩匹配将高斯前推近似为狄利克雷分布成为可能。这种方法完全消除了与MC采样相关的运行时和内存开销。我们在大型和小型数据集（ImageNet, CIFAR-100, CIFAR-10）上将其与几种近似高斯推断方法（Laplace, HET, SNGP）结合进行评估，结果表明与softmax MC采样相比，不确定性量化能力有所提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [161] [Self-Supervised Learning-Based Multimodal Prediction on Prosocial Behavior Intentions](https://arxiv.org/abs/2507.08238)
> *基于自监督学习的亲社会行为意图多模态预测*

*Abinay Reddy Naini, Zhaobo K. Zheng, Teruhisa Misu, Kumar Akash* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 自监督学习, 多模态预测, 亲社会行为, 数据稀缺, 行为意图

**Comment:** 5 pages, 4 figures, published at ICASSP 2025

> **TL;DR:** 本文提出一种基于自监督学习的多模态方法，通过预训练和微调解决亲社会行为意图预测中数据稀缺的问题，并显著提升了预测性能。

**AI_Comments:** 这篇论文通过引入自监督学习来解决亲社会行为预测领域数据稀缺的痛点，具有很强的创新性。其预训练和微调的范式在应对小规模特定领域数据集方面具有普适性，对提升智能系统在复杂社会场景中的理解和交互能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 预测移动场景中的亲社会行为意图是一个未充分探索的领域。主要挑战是缺乏大型的、标注的亲社会行为数据集，导致小规模数据集难以有效训练深度学习模型。

**Method:** 提出了一种自监督学习方法，利用现有生理和行为数据集中的多模态数据进行预训练。然后，使用一个较小的、手动标注的亲社会行为数据集对模型进行微调。

**Result:** 该方法显著提升了亲社会行为意图的预测性能，并解决了数据稀缺问题。

**Conclusion:** 所提出的方法为亲社会行为预测提供了一个更有效的基准，并为改进智能车辆系统和人机交互提供了有价值的见解。

> **ai_Abstract:** 本文针对移动场景中亲社会行为意图预测的数据稀缺问题，提出了一种创新的自监督学习方法。该方法首先利用现有生理和行为数据集进行多模态预训练，随后在一个小规模手动标注数据集上进行微调，从而有效提升了预测性能，并为智能车辆系统和人机交互提供了新的研究方向。

> **摘要翻译:** 随着机器学习和多模态感知技术的发展，人类状态检测和行为预测取得了显著进步。然而，在移动场景中预测亲社会行为意图（例如在道路上帮助他人）是一个未充分探索的领域。当前研究面临一个主要限制：没有大型的、标注的亲社会行为数据集可用，而小规模数据集使得深度学习模型难以有效训练。为了克服这一问题，我们提出了一种自监督学习方法，该方法利用现有生理和行为数据集中的多模态数据。通过在不同任务上预训练我们的模型，并使用一个较小的、手动标注的亲社会行为数据集进行微调，我们显著提升了其性能。该方法解决了数据稀缺问题，为亲社会行为预测提供了一个更有效的基准，并为改进智能车辆系统和人机交互提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [162] [AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling](https://arxiv.org/abs/2507.08567)
> *AbbIE: 用于高效序列建模的自回归块基迭代编码器*

*Preslav Aleksandrov, Meghdad Kurmanji, Fernando Garcia Redondo, David O'Shea, William Shen, Alex Iacob, Lorenzo Sani, Xinchi Qiu, Nicola Cancedda, Nicholas D. Lane* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** AbbIE, 自回归编码器, 序列建模, Transformer, 迭代学习

**Comment:** 14 pages and 6 figures. Submitted to NeurIPS 2025

> **TL;DR:** AbbIE是一种新型的自回归块基迭代编码器，它是编码器专用Transformer架构的递归泛化，在测试时能动态扩展计算资源，并在零样本上下文学习和语言困惑度方面取得显著提升。

**AI_Comments:** AbbIE的创新之处在于其递归的、块基迭代编码器设计，以及在潜在空间进行迭代的特点，使其在不依赖大量参数和token的情况下，实现了性能提升和计算资源的动态扩展。其“向上泛化”能力尤其重要，意味着模型在训练时可以更轻量，但在推理时能根据需求提升计算，这对于未来高效、适应性强的LLM开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLM）性能扩展主要依赖于参数和token数量的增加，但本文提出了一种补充方法，即通过动态扩展计算资源来提升性能，以解决标准Transformer在复杂任务中计算效率和性能的局限性。

**Method:** 本文引入了自回归块基迭代编码器（AbbIE），它是编码器专用Transformer架构的一种递归泛化。AbbIE在潜在空间中执行迭代，与潜在推理模型不同，它不需要专门的数据集或训练协议。它通过在训练时仅使用2次迭代，实现测试时向上泛化到任意迭代长度。

**Result:** AbbIE在零样本上下文学习任务中，相对于其他迭代和标准方法，性能提升高达12%；在语言困惑度方面，性能提升高达5%。它在测试时能够向上泛化到任意迭代长度，即使训练时只使用了2次迭代。所有评估均在参数量高达3.5亿的模型上进行。

**Conclusion:** AbbIE的引入为Transformer性能扩展开辟了一条新途径，通过动态调整计算开销来提高效率和性能，特别是在处理复杂任务时。

> **ai_Abstract:** 本文提出了一种名为AbbIE（自回归块基迭代编码器）的新型模型，它是对编码器专用Transformer架构的递归泛化。AbbIE通过在潜在空间中进行迭代，实现了比标准Transformer更好的性能，并能在测试时动态调整计算资源。与现有依赖参数和token数量扩展LLM性能的方法不同，AbbIE提供了一种补充的性能扩展途径。它在零样本上下文学习和语言困惑度方面表现出色，并展示了在训练迭代次数较少的情况下，仍能向上泛化到任意迭代长度的能力，为Transformer的性能扩展提供了新方向。

> **摘要翻译:** 我们引入了自回归块基迭代编码器（AbbIE），这是一种新颖的、编码器专用Transformer架构的递归泛化，它比标准Transformer具有更好的困惑度，并允许在测试时动态扩展计算资源。这种简单、递归的方法是对通过参数和token数量扩展大语言模型（LLM）性能的补充。AbbIE在潜在空间中执行其迭代，但与潜在推理模型不同，它不需要专门的数据集或训练协议。我们表明，AbbIE在测试时通过仅在训练时使用2次迭代，实现了向上泛化（泛化到任意迭代长度的能力），远远优于其他迭代方法。AbbIE根据任务复杂性扩展其计算开销的能力，使其在零样本上下文学习任务中比其他迭代和标准方法提高了高达12%，在语言困惑度方面提高了高达5%。这项研究的结果为Transformer性能扩展开辟了一条新途径。我们将所有评估都在参数量高达3.5亿的模型上进行。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [184] [Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures](https://arxiv.org/abs/2502.05044)
> *基于混合机器学习的尺度桥接框架用于纤维结构渗透率预测*

*Denis Korolev, Tim Schmidt, Dinesh K. Natarajan, Stefano Cassola, David May, Miro Duhovic, Michael Hintermüller* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 混合机器学习, 尺度桥接, 渗透率预测, 纤维结构, 物理信息神经网络

**Comment:** Paper restructured, updated numerical results

> **TL;DR:** 本研究提出了一种混合机器学习的尺度桥接框架，用于预测纤维结构渗透率，通过评估多种方法（包括PINNs）来平衡计算成本和预测准确性。

**AI_Comments:** 该论文的创新点在于提出了一个混合机器学习的尺度桥接框架，并系统地评估了多种尺度桥接方法，从简单的单尺度模型到复杂的完全解析模型，并引入了PINNs来克服传统数据驱动方法的局限性。其重要性在于为纤维结构渗透率预测提供了一个高效且准确的解决方案，特别是在计算资源有限的情况下。平衡了计算成本和预测可靠性是其核心优势，对于纤维复合材料的制造具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决多尺度建模固有的计算挑战，旨在平衡计算成本和预测可靠性，以实现纤维结构渗透率的准确预测。

**Method:** 本研究引入了一种混合机器学习的尺度桥接框架，用于预测纤维纺织结构的渗透率。该方法评估了四种尺度桥接方法：单尺度方法（SSM）、简单升尺度方法（SUM）、尺度桥接方法（SBM）和完全解析模型（FRM）。SSM忽略微尺度渗透率。SUM考虑均匀微尺度渗透率。SBM结合了基于分段的微尺度渗透率分配。FRM完全解析微尺度和中尺度几何形状。此外，还开发了一种结合物理信息神经网络（PINNs）的双尺度混合求解器，以克服数据驱动代理方法的泛化误差和数据稀缺问题。

**Result:** SSM是最简单的方法，在等效低纤维体积含量下，其渗透率值与作为真值的FRM模型相比，偏差高达150%。SUM通过考虑均匀微尺度渗透率改进了预测，在类似条件下获得了更接近的值，但仍缺乏结构变异性。SBM方法结合了基于分段的微尺度渗透率分配，显示出显著增强，实现了几乎等效的值，同时保持了计算效率，每次模拟的运行时间约为45分钟。FRM提供了最高保真度，但计算时间比SSM多达270倍，模型文件超过300 GB。结合PINNs的混合双尺度求解器显示出克服泛化误差和数据稀缺问题的潜力。

**Conclusion:** 该混合框架通过平衡计算成本和预测可靠性，推进了渗透率建模，为纤维复合材料制造中的进一步应用奠定了基础。

> **ai_Abstract:** 本研究提出了一种基于混合机器学习的尺度桥接框架，用于预测纤维结构的渗透率。该框架旨在解决多尺度建模的计算挑战，通过评估SSM、SUM、SBM和FRM四种方法，并引入结合PINNs的混合双尺度求解器。结果表明，SBM在保持计算效率的同时提供了高精度，而PINNs方法显示出解决数据稀缺和泛化误差的潜力。该框架在平衡计算成本与预测可靠性方面取得了进展，为纤维复合材料制造中的渗透率建模奠定了基础。

> **摘要翻译:** 本研究引入了一种基于混合机器学习的尺度桥接框架，用于预测纤维纺织结构的渗透率。通过解决多尺度建模固有的计算挑战，所提出的方法评估了不同尺度桥接方法的效率和准确性，这些方法结合了传统代理模型，甚至将物理信息神经网络（PINNs）与数值求解器集成，从而实现了微尺度和中尺度上的准确渗透率预测。评估了四种方法：单尺度方法（SSM）、简单升尺度方法（SUM）、尺度桥接方法（SBM）和完全解析模型（FRM）。SSM是最简单的方法，忽略微尺度渗透率，其渗透率值与作为等效低纤维体积含量下真值的FRM模型相比，偏差高达150%。SUM通过考虑均匀微尺度渗透率改进了预测，在类似条件下产生了更接近的值，但仍缺乏结构变异性。SBM方法结合了基于分段的微尺度渗透率分配，显示出显著增强，实现了几乎等效的值，同时保持了计算效率和每次模拟约45分钟的模型运行时间。相比之下，FRM通过完全解析微尺度和中尺度几何形状提供了最高保真度，但计算时间比SSM多达270倍，模型文件超过300 GB。此外，还开发了一种结合PINNs的混合双尺度求解器，并显示出克服泛化误差和数据驱动代理方法数据稀缺问题的潜力。该混合框架通过平衡计算成本和预测可靠性，推进了渗透率建模，为纤维复合材料制造中的进一步应用奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [186] [Remote Sensing Reveals Adoption of Sustainable Rice Farming Practices Across Punjab, India](https://arxiv.org/abs/2507.08605)
> *遥感揭示印度旁遮普邦可持续水稻种植实践的采用情况*

*Ando Shah, Rajveer Singh, Akram Zaytar, Girmaw Abebe Tadesse, Caleb Robinson, Negar Tafti, Stephen A. Wood, Rahul Dodhia, Juan M. Lavista Ferres* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 遥感, 可持续水稻, 直播稻, 水资源管理, 旁遮普邦

**Comment:** Dataset and code will be published shortly and links updated in v2

> **TL;DR:** 利用遥感技术监测印度旁遮普邦可持续水稻种植实践（如直播稻和干湿交替）的采用情况，以解决水资源短缺问题并支持政策制定。

**AI_Comments:** 这项研究的创新之处在于利用遥感技术大规模监测可持续农业实践的采纳情况，解决了传统数据获取困难的问题。其重要性在于为政策制定者提供了急需的、可扩展的工具，以应对水资源短缺和实现可持续发展目标。通过与地面项目的结合，提高了数据的准确性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 水稻种植消耗大量淡水，导致水管理挑战；可持续灌溉实践（如直播稻和干湿交替）可节水并维持产量，但缺乏这些实践的采纳率数据，阻碍了循证决策和资源分配。

**Method:** 开发了一种新颖的遥感框架，利用Sentinel-1卫星图像监测可持续水管理实践。通过与Nature Conservancy的PRANA项目合作收集地面实况数据，该项目培训了约1400名农民并记录了他们的田间实践。基于此数据创建了一个分类系统，用于区分播种和灌溉维度的水管理。

**Result:** 该方法在区分直播稻（DSR）与传统水淹移栽水稻时，无需预先知道种植日期，F1-score达到78%。在旁遮普邦约300万块农田中绘制了直播稻的采用情况，区级预测与政府记录显示出强相关性（Pearson=0.77, RBO=0.77）。

**Conclusion:** 本研究为政策制定者提供了一个强大的工具，用于大规模追踪可持续水管理实践的采用情况、目标干预措施以及衡量项目影响。

> **ai_Abstract:** 本研究开发了一种新颖的遥感框架，利用Sentinel-1卫星图像和地面实况数据，在大规模监测印度旁遮普邦可持续水稻种植实践（如直播稻）的采用情况。该框架能有效区分直播稻与传统水稻，并在区级采纳率预测上与政府数据高度相关。这项工作为政策制定者提供了追踪、干预和评估水资源管理项目影响的工具，以应对全球水资源短缺挑战。

> **摘要翻译:** 水稻种植消耗全球24-30%的淡水，在主要水稻产区造成严重的水管理挑战。直播稻（DSR）和干湿交替（AWD）等可持续灌溉实践可节水20-40%同时保持产量，有助于在水资源短缺加剧的情况下确保长期农业生产力——这是零饥饿可持续发展目标的关键组成部分。然而，关于这些实践采纳率的数据有限，阻碍了循证政策制定和有针对性的资源分配。我们开发了一种新颖的遥感框架，用于在印度旁遮普邦大规模监测可持续水管理实践，该地区面临每年41.6厘米的严重地下水枯竭。为了收集必要的地面实况数据，我们与大自然保护协会的“促进再生和无燃烧农业”（PRANA）项目合作，该项目培训了大约1400名农民节水技术，同时记录了他们的田间实践。利用这些数据，我们创建了一个分类系统，结合Sentinel-1卫星图像，根据播种和灌溉维度区分水管理。我们的方法在区分直播稻与传统水淹移栽水稻时，无需预先知道种植日期，F1-score达到78%。我们通过绘制旁遮普邦约300万块农田的直播稻采纳情况展示了其可扩展性，区级预测与政府记录显示出强相关性（Pearson=0.77，RBO=0.77）。这项研究为政策制定者提供了一个强大的工具，用于大规模追踪可持续水管理采纳情况、目标干预措施以及衡量项目影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [194] [Data Generation without Function Estimation](https://arxiv.org/abs/2507.08239)
> *无需函数估计的数据生成*

*Hadi Daneshmand, Ashkan Soleymani* | **Category: cs.LG, math-ph, math.MP, math.OC, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 数据生成, 函数估计, 梯度下降, 相互作用粒子, 平均场

**Comment:** 

> **TL;DR:** 本文提出了一种无需函数估计的生成方法，通过确定性更新点的位置来将均匀分布转换为任意数据分布，避免了传统生成模型中计算和统计上具有挑战性的函数估计问题。

**AI_Comments:** 该论文的关键创新点在于提出了一个无需函数估计的生成模型，这与当前主流的生成对抗网络（GANs）和扩散模型等依赖复杂函数估计的方法形成了鲜明对比。通过引入相互作用粒子物理学的概念并利用确定性更新机制，该方法极大地简化了生成过程，并可能在计算效率和统计稳定性方面带来优势。其“无需训练神经网络”的特点也值得关注，可能为资源受限环境下的数据生成提供新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大多数生成模型的核心组成部分是估计分数函数（或其他依赖于种群密度的函数），但这种函数估计在计算和统计上都具有挑战性。因此，本文旨在探索是否可以在数据生成过程中避免函数估计。

**Method:** 本文提出了一种无需估计的生成方法：通过（逆）梯度下降确定性地更新一组点的位置，在平均场状态下，无需函数估计、训练神经网络甚至注入噪声，即可将均匀分布转换为任意数据分布。该方法建立在相互作用粒子物理学的最新进展之上。

**Result:** 本文从理论和实验两方面表明，可以利用相互作用粒子物理学的最新进展来开发新颖的生成方法，成功实现了无需函数估计的数据生成。

**Conclusion:** 本文证明了利用相互作用粒子物理学的进展，可以开发出一种无需函数估计、无需训练神经网络和噪声注入的新型生成模型，有效解决了传统生成模型中函数估计的挑战。

> **ai_Abstract:** 本文提出了一种创新的数据生成方法，旨在克服传统生成模型中分数函数估计所面临的计算和统计挑战。该方法基于相互作用粒子物理学的最新进展，通过确定性地更新一组点的位置（利用逆梯度下降），在平均场状态下，能够将均匀分布转换为任意目标数据分布，整个过程无需进行函数估计、神经网络训练或噪声注入。论文通过理论和实验验证了该方法的有效性，展示了其在开发新型生成模型方面的潜力。

> **摘要翻译:** 估计分数函数（或其他依赖于种群密度的函数）是大多数生成模型的l核心组成部分。然而，这种函数估计在计算和统计上都具有挑战性。我们能否在数据生成中避免函数估计？我们提出了一种无需估计的生成方法：一组点的位置通过（逆）梯度下降确定性地更新，可以在平均场状态下，无需函数估计、训练神经网络，甚至无需注入噪声，将均匀分布传输到任意数据分布。所提出的方法建立在相互作用粒子物理学的最新进展之上。我们从理论和实验上表明，可以利用这些进展来开发新颖的生成方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [202] [Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data](https://arxiv.org/abs/2507.08610)
> *通过通信博弈涌现自然语言以无需额外数据提升图像字幕能力*

*Parag Dutta, Ambedkar Dukkipati* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 图像字幕, 多智能体强化学习, 通信博弈, 无监督, 自然语言

**Comment:** 

> **TL;DR:** 本文提出 LoGIC，一种多智能体强化学习通信博弈，用于在无需额外标注数据的情况下提升图像字幕性能，并在无监督设置下取得了显著提升。

**AI_Comments:** LoGIC 的创新之处在于将图像字幕任务转化为多智能体通信博弈，并利用强化学习在无监督或少数据环境下提升性能。这种通过智能体间自发学习涌现自然语言能力的方法，为解决数据饥渴型 AI 任务提供了新思路，尤其在无监督图像字幕领域取得了突破性进展，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 图像字幕任务需要大量标注图像来训练模型，但现有数据集已被充分利用，导致传统方法难以进一步提升性能。因此，探索和提升无监督图像字幕性能变得至关重要。

**Method:** 提出 LoGIC (Lewis Communication Game for Image Captioning)，这是一种多智能体强化学习博弈，包含一个“说话者”和一个“听众”智能体。通过合作共同奖励设置，并使用 GRPO 算法训练智能体学习自然语言交流策略。

**Result:** 1. 使用预训练的 VLM 作为“说话者”和 LLM 作为“听众”，在不使用额外标注数据的情况下，通过 LoGIC 微调后 BLEU 分数达到 46，比原始 VLM 的 44 BLEU 分数提升了 2 个单位。2. 在无监督设置下，将“说话者”中的 VLM 替换为轻量级组件（ViT 和 GPT2），从头开始使用 LoGIC 训练，获得了 31 BLEU 分数，比现有无监督图像字幕方法高出 10 分。

**Conclusion:** 通过让智能体学习玩通信博弈，图像字幕性能得到了提升。LoGIC 方法能够在不依赖额外标注数据的情况下提高图像字幕能力，并在无监督设置中表现出显著优势。

> **ai_Abstract:** 本论文提出 LoGIC，一种基于多智能体强化学习的通信博弈框架，旨在无需额外标注数据的情况下提升图像字幕能力。该方法通过训练“说话者”和“听众”两个智能体进行自然语言交流，从而使图像字幕性能得以涌现。实验结果表明，LoGIC 在微调预训练模型时，无需额外数据即可提升 BLEU 分数，并在无监督设置下，通过轻量级组件训练，显著超越现有无监督方法。

> **摘要翻译:** 图像字幕是开发各种人工智能系统中的一个重要问题，这些任务需要大量标注图像来训练模型。由于所有现有的标注数据集都已用于训练大型视觉语言模型（VLM），因此提升其性能变得具有挑战性。考虑到这一点，考虑无监督图像字幕性能至关重要，而这方面仍相对未被充分探索。为此，我们提出了 LoGIC（Lewis 通信博弈用于图像字幕），这是一种多智能体强化学习博弈。所提出的方法由两个智能体组成，一个“说话者”和一个“听众”，目标是学习用自然语言进行交流的策略。我们使用 GRPO 算法在合作共同奖励设置中训练智能体，并表明图像字幕性能的提升是智能体学习玩博弈的结果。我们展示了使用预训练的 VLM 作为“说话者”和大型语言模型（LLM）用于“听众”的语言理解，在不使用额外标注的情况下，通过 LoGIC 微调后，我们达到了 46 的 BLEU 分数，与原始 VLM 的 44 BLEU 分数相比，绝对指标提升了 2 个单位。此外，我们将“说话者”中的 VLM 替换为轻量级组件：(i) 用于图像感知的 ViT 和 (ii) 用于语言生成的 GPT2，并使用 LoGIC 从头开始训练它们，在无监督设置中获得了 31 的 BLEU 分数，比现有无监督图像字幕方法高出 10 分。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [209] [Cloud Computing Energy Consumption Prediction Based on Kernel Extreme Learning Machine Algorithm Improved by Vector Weighted Average Algorithm](https://arxiv.org/abs/2503.04088)
> *基于向量加权平均算法改进的核极限学习机算法在云计算能耗预测中的应用*

*Yuqing Wang, Xiao Yang* | **Category: cs.LG, cs.PF** | **Updated: 2025-07-10**

**Keywords:** 云计算, 能耗预测, 核极限学习机, 向量加权平均, VWAA-KELM

**Comment:** 

> **TL;DR:** 提出一种新的VWAA-KELM模型，用于准确预测云计算能耗，表现优异且泛化能力强。

**AI_Comments:** 本文提出的VWAA-KELM模型通过引入自适应特征加权，增强了模型处理高维数据的能力，提高了云计算能耗预测的准确性和泛化能力。该方法结合了VWAA和KELM的优点，为解决复杂的非线性预测问题提供了一种有效途径，且具有在IoT和边缘计算等领域推广应用的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着云计算基础设施快速扩展，能耗成为关键挑战，需要准确高效的预测模型。

**Method:** 提出一种新颖的向量加权平均核极限学习机（VWAA-KELM）模型，通过将向量加权平均算法（VWAA）与核极限学习机（KELM）集成，动态调整特征权重并优化核函数。

**Result:** VWAA-KELM模型性能优越：94.7%的测试集预测误差在[0, 50]单位内，仅3例超过100单位。训练集R2=0.987，测试集R2=0.973，泛化能力强。预测值与实际趋势吻合，避免过拟合。

**Conclusion:** 提出的VWAA-KELM模型为优化云数据中心能耗提供了一种可扩展且高效的方法，在物联网和边缘计算中也有广泛应用前景。

> **ai_Abstract:** 本文针对云计算能耗预测的挑战，提出了一种结合向量加权平均算法和核极限学习机的新模型VWAA-KELM。该模型通过动态调整特征权重和优化核函数，显著提高了预测精度和泛化能力。实验结果表明，VWAA-KELM在预测误差、R2等指标上表现优异，并有效避免了过拟合，为云计算能耗优化提供了有效工具，并具有更广泛的应用潜力。

> **摘要翻译:** 随着云计算基础设施的快速扩展，能耗已成为一个关键挑战，推动了对准确高效预测模型的需求。本研究提出了一种新颖的向量加权平均核极限学习机（VWAA-KELM）模型，以增强云计算环境中的能耗预测。通过将向量加权平均算法（VWAA）与核极限学习机（KELM）集成，所提出的模型动态调整特征权重并优化核函数，显著提高了预测精度和泛化能力。实验结果表明了VWAA-KELM的卓越性能：94.7%的测试集预测误差落在[0, 50]单位内，只有3例超过100单位，表明稳定性强。该模型在训练集上实现了0.987的决定系数（R2）（RMSE = 28.108，RPD = 8.872），并在测试集上保持了出色的泛化能力，R2 = 0.973（RMSE = 43.227，RPD = 6.202）。可视化分析证实，预测值与实际能耗趋势密切吻合，在捕捉非线性依赖关系的同时避免了过拟合。本研究的一个关键创新是引入了自适应特征加权，使模型能够动态地为不同的输入参数分配重要性，从而增强高维数据处理能力。这一进展为优化云数据中心能耗提供了一种可扩展且高效的方法。除了云计算，所提出的混合框架在物联网（IoT）和边缘计算中也具有更广泛的应用前景，支持实时能耗管理和智能资源分配。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [215] [EmissionNet: Air Quality Pollution Forecasting for Agriculture](https://arxiv.org/abs/2507.05416)
> *EmissionNet：农业空气质量污染预测*

*Prady Saligram, Tanvir Bhathal* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 农业排放, 空气质量预测, 深度学习, EmissionNet, Transformer

**Comment:** The appendix figures are mixed up - several emission plots (e.g. CO2,
  CH4, GWP) are mislabeled and appear in the wrong order, leading to confusion
  in interpreting the results

> **TL;DR:** 本文提出了两种新的深度学习架构EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，用于预测农业N2O排放，旨在克服传统物理模型在捕捉复杂非线性污染物相互作用方面的不足。

**AI_Comments:** 本文的创新点在于提出了专门针对农业排放预测的深度学习模型，特别是结合了卷积和Transformer架构，有望克服传统物理模型在处理复杂非线性污染物交互方面的不足。这对于改善空气质量预测，尤其是在农业领域，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 农业排放造成的空气污染是环境和公共健康的重要挑战，而传统空气质量预测模型难以捕捉复杂的非线性污染物相互作用。

**Method:** 通过评估流行的深度学习架构，并提出了两种新的深度学习架构：EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)。这些模型利用卷积和基于Transformer的架构，从高分辨率排放数据中提取时空依赖性，用于预测N2O农业排放。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对农业排放造成的空气污染预测问题，指出传统物理模型在处理复杂非线性污染物相互作用上的局限性。为此，作者提出了两种新颖的深度学习架构EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，它们结合了卷积和Transformer技术，旨在从高分辨率排放数据中捕捉时空依赖性，以改进N2O农业排放的预测。

> **摘要翻译:** 农业排放造成的空气污染是一个重要但常被忽视的环境和公共健康挑战。传统的空气质量预测模型依赖于基于物理的方法，这些方法难以捕捉复杂的非线性污染物相互作用。在这项工作中，我们通过评估流行的架构，并提出了两种新颖的深度学习架构，EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，来探索N2O农业排放的预测。这些模型利用卷积和基于Transformer的架构，从高分辨率排放数据中提取时空依赖性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [234] [CoreSPECT: Enhancing Clustering Algorithms via an Interplay of Density and Geometry](https://arxiv.org/abs/2507.08243)
> *CoreSPECT：通过密度与几何的相互作用增强聚类算法*

*Chandra Sekhar Mukherjee, Joonyoung Bae, Jiapeng Zhang* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 聚类算法, 密度, 几何, CoreSPECT, 聚类增强

**Comment:** 

> **TL;DR:** CoreSPECT是一个新的聚类增强框架，它结合了密度和几何原理，通过在策略性选择的区域应用简单算法并进行多层传播，显著提高了K-Means和GMM等算法的聚类精度。

**AI_Comments:** CoreSPECT的创新之处在于其成功地将密度和几何这两种传统上独立考虑的聚类原理结合起来，形成了一个有效的增强框架。它不仅提升了简单算法如K-Means和GMM的性能，还通过分阶段的方法（局部应用和全局传播）实现了高效的性能提升，且具有理论保证和对噪声的鲁棒性，这对于实际应用非常重要。该方法提供了一个通用范式，可以应用于多种现有聚类技术。

<details>
  <summary>Details</summary>

**Motivation:** 现有的聚类算法通常只关注数据的密度结构或底层几何复杂性。本文旨在识别并利用密度和几何之间经常被忽视的相互作用，以设计一个能够增强现有聚类算法性能的框架。

**Method:** 本文提出了CoreSPECT框架，该框架通过以下步骤增强聚类算法：1) 识别并形式化分布与几何之间的相互作用；2) 在策略性选择的区域应用K-Means和GMM等简单算法；3) 使用新颖的基于邻域图的多层传播程序，将局部划分扩展到完整的数据集划分。

**Result:** CoreSPECT框架在来自三个不同领域的15个数据集上进行了应用，并为K-Means和GMM带来了持续且显著的聚类精度提升。平均而言，它将K-Means的ARI提高了40%，GMM的ARI提高了14%，通常超越了基于流形和最新基于密度的聚类算法的性能。此外，该框架还得到了初步的理论保证、消融实验（证明了各个步骤的有用性）以及对噪声鲁棒性的证据支持。

**Conclusion:** CoreSPECT框架通过有效结合密度和几何原理，能够显著提高现有简单聚类算法的性能，并在多种数据集上表现出优越性，甚至超越了一些复杂的聚类方法，同时具有理论支持和对噪声的鲁棒性。

> **ai_Abstract:** 本文提出了CoreSPECT框架，旨在通过结合密度和几何的相互作用来增强现有聚类算法的性能。该框架首先在数据中策略性选择的区域应用K-Means和GMM等简单算法，然后通过一个新颖的基于邻域图的多层传播程序将局部划分扩展到整个数据集。实验结果表明，CoreSPECT在15个数据集上显著提升了K-Means和GMM的聚类精度，平均分别提高了40%和14%，性能甚至超越了许多复杂的聚类算法，并得到了理论和鲁棒性证据的支持。

> **摘要翻译:** 密度和几何长期以来一直是聚类算法设计的两个基本指导原则，算法通常侧重于数据的密度结构（例如，HDBSCAN和密度峰值聚类）或底层几何的复杂性（例如，流形聚类算法）。
在本文中，我们识别并形式化了分布和几何之间反复出现但经常被忽视的相互作用，并利用这一见解设计了我们的聚类增强框架CoreSPECT（核心空间投影聚类技术增强）。我们的框架通过在策略性选择的区域应用K-Means和GMM等简单算法，然后使用新颖的基于邻域图的多层传播程序将部分划分扩展到数据集的完整划分，从而提升了它们的性能。
我们将我们的框架应用于来自三个不同领域的15个数据集，并为K-Means和GMM获得了持续且显著的聚类精度提升。平均而言，我们的框架将K-Means的ARI提高了40%，GMM的ARI提高了14%，通常超越了基于流形和最新基于密度的聚类算法的性能。我们通过初步的理论保证、消融实验（以证明各个步骤的有用性）以及对噪声鲁棒性的证据进一步支持我们的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [235] [Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift](https://arxiv.org/abs/2507.08617)
> *在不平衡协变量偏移下实现联邦学习中的协作公平性*

*Tianrun Yu, Jiaqi Wang, Haoyu Wang, Mingquan Lin, Han Liu, Nelson S. Yee, Fenglong Ma* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 联邦学习, 协作公平性, 知识蒸馏, 协变量偏移, 异构数据

**Comment:** 18 pages, accepted to the 31st ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD' 25), Toronto, Canada, August 3-7 2025

> **TL;DR:** 本文提出FedAKD，一种新颖的联邦学习方法，通过异步知识蒸馏在存在不平衡协变量偏移的情况下，显著提升协作公平性和预测准确性，并促进客户端参与。

**AI_Comments:** 该论文创新性地将异步知识蒸馏应用于解决联邦学习中的不平衡协变量偏移问题，并通过区分正确和错误预测样本来优化模型更新，这对于提高联邦学习在实际异构环境中的鲁棒性和公平性具有重要意义。理论分析和实验验证也增强了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法忽视了不平衡协变量偏移这一实际且复杂的异质性形式，而协作公平性是联邦学习中的关键挑战。

**Method:** FedAKD（联邦异步知识蒸馏）由客户端更新和服务器更新组成。客户端更新引入异步知识蒸馏策略，利用正确预测样本特征分布相似而错误预测样本差异显著的洞察。首先，使用传统知识蒸馏更新客户端模型；其次，选择高置信度正确预测样本更新全局模型。服务器更新则聚合所有客户端模型。并提供了收敛性的理论证明。

**Result:** 在FashionMNIST、CIFAR10和真实世界EHR数据集上的实验结果表明，FedAKD显著提高了协作公平性、增强了预测准确性，并即使在高度异构数据分布下也促进了客户端参与。

**Conclusion:** FedAKD是一种简单而有效的方法，能够在不平衡协变量偏移下平衡准确预测与协作公平性，并促进客户端参与。

> **ai_Abstract:** 本文针对联邦学习中不平衡协变量偏移导致的协作公平性问题，提出了FedAKD（联邦异步知识蒸馏）方法。该方法通过客户端的异步知识蒸馏策略，利用正确和错误预测样本特征分布的差异，先更新客户端模型，再利用高置信度正确预测样本更新全局模型。实验证明FedAKD在提高协作公平性、预测准确性和客户端参与度方面表现出色，并提供了理论收敛性证明。

> **摘要翻译:** 联邦学习中的协作公平性是一个关键挑战。然而，现有方法常常忽视一种实际但复杂的异质性形式：不平衡协变量偏移。我们对这种情况进行了理论分析，这促使我们设计了FedAKD（联邦异步知识蒸馏）——一种简单而有效的方法，它平衡了准确预测和协作公平性。FedAKD包括客户端和服务器更新。在客户端更新中，我们基于初步分析引入了一种新颖的异步知识蒸馏策略，该分析揭示了正确预测的样本在客户端之间表现出相似的特征分布，而错误预测的样本则显示出显著的变异性。这表明不平衡协变量偏移主要来源于错误分类的样本。利用这一见解，我们的方法首先应用传统知识蒸馏来更新客户端模型，同时保持全局模型固定。接下来，我们选择正确预测的高置信度样本，并使用这些样本更新全局模型，同时保持客户端模型固定。服务器更新简单地聚合所有客户端模型。我们进一步提供了FedAKD收敛性的理论证明。在公共数据集（FashionMNIST和CIFAR10）和真实世界电子健康记录（EHR）数据集上的实验结果表明，FedAKD显著提高了协作公平性，增强了预测准确性，并即使在高度异构数据分布下也促进了客户端参与。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [242] [DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting](https://arxiv.org/abs/2504.01531)
> *DRAN：一种用于时空预测的分布与关系自适应网络*

*Xiaobei Zou, Luolin Xiong, Kexuan Zhang, Cesare Alippi, Yang Tang* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 时空预测, 非平稳性, 深度学习, 图神经网络, 动态关系

**Comment:** 15 pages, 10 figures

> **TL;DR:** DRAN是一种新的时空预测模型，通过空间因子学习器（SFL）处理分布变化并保留空间关系，通过动态-静态融合学习器（DSFL）适应动态空间关系，并引入随机学习器捕获噪声，在天气和交通预测任务中超越现有SOTA方法。

**AI_Comments:** DRAN的创新之处在于其对时空数据非平稳性的多方面应对策略。SFL模块解决了传统时间归一化破坏空间关系的问题，DSFL模块通过融合动态和静态关系来捕捉复杂的时间演变，而随机学习器的引入则增强了模型对噪声的鲁棒性。这种全面的设计使其在复杂时空预测任务中表现出色，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确的时空系统预测对于系统管理、控制和危机预防至关重要。然而，许多时空系统固有的时间变化性（非平稳性）给准确预测带来了挑战。

**Method:** 本文提出了一种分布与关系自适应网络（DRAN），能够动态适应随时间变化的分布和关系。为解决时间归一化可能破坏空间关系的问题，开发了空间因子学习器（SFL）模块。为适应传感器之间动态空间关系的变化，提出了动态-静态融合学习器（DSFL）模块，通过自适应融合比机制有效整合动态和静态关系特征。此外，引入了随机学习器来捕获时空表示中的噪声成分。

**Result:** 我们的方法在天气预测和交通流量预测任务中超越了现有最先进的方法。实验结果表明，SFL在各种时间归一化操作中有效保留了空间关系。学习到的动态和静态关系的可视化表明，DSFL可以捕获节点之间的局部和远距离关系。

**Conclusion:** DRAN通过其创新的SFL和DSFL模块以及随机学习器，有效解决了时空预测中的非平稳性问题，并在实际应用中取得了卓越的性能。

> **ai_Abstract:** 本文提出DRAN（分布与关系自适应网络），旨在解决时空预测中因非平稳性带来的挑战。DRAN通过引入空间因子学习器（SFL）来处理分布变化并保持空间关系，通过动态-静态融合学习器（DSFL）自适应地融合动态与静态关系特征，以及通过随机学习器捕获噪声。实验证明，DRAN在天气和交通预测任务上优于现有SOTA方法，SFL能有效保留空间关系，DSFL能捕捉局部和远距离关系。

> **摘要翻译:** 时空系统的准确预测对于系统管理、控制和危机预防等任务至关重要。然而，许多时空系统固有的时间变化性在不保证平稳性时给实现准确预测带来了挑战。为了解决非平稳性问题，我们提出了一种分布与关系自适应网络（DRAN），能够动态适应随时间变化的关系和分布。虽然时间归一化和反归一化是适应分布变化的常用技术，但这种操作不适用于时空背景，因为时间归一化会缩放节点的时序数据，并可能破坏节点之间的空间关系。为了解决这个问题，开发了一个空间因子学习器（SFL）模块，该模块能够实现归一化和反归一化过程。为了适应传感器之间空间关系的动态变化，我们提出了一个动态-静态融合学习器（DSFL）模块，该模块通过自适应融合比机制有效整合从动态和静态关系中学习到的特征。此外，我们引入了一个随机学习器来捕获时空表示中的噪声成分。我们的方法在天气预测和交通流量预测任务中超越了现有最先进的方法。实验结果表明，我们的SFL在各种时间归一化操作中有效地保留了空间关系。学习到的动态和静态关系的可视化表明，DSFL可以捕获节点之间的局部和远距离关系。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [253] [ADAPT: A Pseudo-labeling Approach to Combat Concept Drift in Malware Detection](https://arxiv.org/abs/2507.08597)
> *ADAPT：一种应对恶意软件检测中概念漂移的伪标签方法*

*Md Tanvirul Alam, Aritran Piplai, Nidhi Rastogi* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-11**

**Keywords:** 概念漂移, 恶意软件检测, 伪标签, 半监督学习, 模型适应

**Comment:** 

> **TL;DR:** ADAPT是一种新颖的伪标签半监督算法，用于解决恶意软件检测中机器学习模型的概念漂移问题，并在多个数据集上表现优于基线模型。

**AI_Comments:** ADAPT的创新之处在于其将伪标签和半监督学习应用于解决恶意软件检测中的概念漂移问题，这在该领域是相对未充分探索的方向。其模型无关的特性增加了方法的通用性和实用性，使其能够应用于各种现有的机器学习模型。这项工作对于提升恶意软件检测系统在不断演变威胁环境中的鲁棒性和持续性能具有重要意义，减少了对昂贵人工标注的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型在恶意软件分类中因概念漂移而性能随时间下降。模型适应变化的数据分布需要频繁更新，这依赖于昂贵且耗费人力的真实标签。虽然主动学习可以减少标注负担，但在恶意软件检测中利用未标记数据的半监督学习方法相对未被充分探索。

**Method:** 本研究引入了ADAPT，一种新颖的伪标签半监督算法，用于解决概念漂移问题。该方法与模型无关，可应用于各种机器学习模型，包括神经网络和基于树的算法。研究在涵盖Android、Windows和PDF领域的五个不同恶意软件检测数据集上进行了广泛实验。

**Result:** 实验结果表明，ADAPT方法始终优于基线模型和有竞争力的基准。

**Conclusion:** 这项工作为机器学习模型在恶意软件检测中更有效地适应概念漂移铺平了道路。

> **ai_Abstract:** 本研究提出了一种名为ADAPT的新型伪标签半监督算法，旨在解决恶意软件检测中机器学习模型的概念漂移问题。ADAPT方法与模型无关，可应用于多种机器学习模型。在Android、Windows和PDF领域的五个恶意软件检测数据集上的广泛实验表明，ADAPT持续优于现有基线和竞争性基准模型，为恶意软件检测中机器学习模型的有效适应提供了新途径。

> **摘要翻译:** 机器学习模型常用于恶意软件分类；然而，由于概念漂移，它们的性能会随着时间下降。使这些模型适应不断变化的数据分布需要频繁更新，这依赖于昂贵的真实标签。虽然主动学习可以减少标注负担，但通过半监督学习利用未标记数据在恶意软件检测的背景下仍然是一个相对未充分探索的方法。在这项研究中，我们引入了ADAPT，一种新颖的伪标签半监督算法，用于解决概念漂移。我们的模型无关方法可以应用于各种机器学习模型，包括神经网络和基于树的算法。我们在涵盖Android、Windows和PDF领域的五个不同恶意软件检测数据集上进行了广泛实验。结果表明，我们的方法始终优于基线模型和有竞争力的基准。这项工作为机器学习模型在恶意软件检测中更有效地适应概念漂移铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [255] [Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)](https://arxiv.org/abs/2507.08637)
> *使用小波增强随机谱注意力（WERSA）将注意力扩展到线性时间内的超长序列*

*Vincenzo Dentamaro* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 注意力机制, 线性时间, 小波, 长序列, Transformer

**Comment:** 10 pages, 1 figure

> **TL;DR:** WERSA是一种新型的线性时间注意力机制，能够高效处理长序列，并在多个基准测试中超越现有方法，同时显著降低计算成本。

**AI_Comments:** WERSA的创新之处在于其将内容自适应的随机谱特征与多分辨率小波相结合，实现了线性时间复杂度，从而有效解决了Transformer在长序列处理中的计算瓶颈。其重要性在于，它不仅在性能上超越了现有多种注意力机制，更重要的是，它使得在低资源硬件上部署和运行长上下文模型成为可能，这对于推动AI的可持续和可扩展发展具有深远意义。该研究为未来的高效Transformer模型设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型在处理长序列时计算成本高昂，因为常规注意力的时间复杂度为二次方O(n²)。

**Method:** 本文引入了小波增强随机谱注意力（WERSA），这是一种具有线性O(n)时间复杂度的新型机制。WERSA将内容自适应的随机谱特征与多分辨率Haar小波和可学习参数相结合，以选择性地关注数据的信息尺度，同时保持线性效率。

**Result:** WERSA在单GPU上以及在视觉、NLP和分层推理等各种基准测试中，与多种注意力机制（如Multiheaded Attention, Flash-Attention-2, FNet, Linformer, Performer, Waveformer）相比，均表现出优势，并在所有测试中取得了最佳准确率。在ArXiv分类任务上，WERSA比传统注意力提高了1.2%的准确率（86.2% vs 85.0%），同时训练时间减少了81%（296s vs 1554s），FLOPS减少了73.4%（26.2G vs 98.4G）。在ArXiv-128k的超长序列上，WERSA在传统方法和FlashAttention-2失败的情况下，取得了最佳准确率（79.1%）和AUC（0.979），并且比其次优竞争对手Waveformer快两倍，处理了导致二次方方法内存不足的数据。

**Conclusion:** 通过显著降低计算负载而不影响准确性，WERSA使得更实用、更经济的长上下文模型成为可能，特别是在低资源硬件上，从而实现更可持续和可扩展的AI开发。

> **ai_Abstract:** 该论文提出了一种名为小波增强随机谱注意力（WERSA）的新型注意力机制，旨在解决Transformer模型在处理长序列时因二次方时间复杂度而导致的计算成本高昂问题。WERSA通过结合随机谱特征和多分辨率小波，实现了线性时间复杂度O(n)，并在多个基准测试中（包括视觉、NLP和分层推理）展现出卓越的性能。实验结果表明，WERSA在准确性方面超越了多种现有注意力机制，并显著降低了训练时间和计算资源消耗，尤其在处理超长序列时表现出优势，解决了传统方法内存溢出的问题，为低资源硬件上的长上下文模型提供了实用且经济的解决方案。

> **摘要翻译:** Transformer模型在长序列上计算成本高昂，因为常规注意力具有二次方的O(n²)时间复杂度。我们引入了小波增强随机谱注意力（WERSA），这是一种具有线性O(n)时间复杂度的新型机制，对于在不牺牲性能的情况下成功处理长序列至关重要。WERSA将内容自适应的随机谱特征与多分辨率Haar小波和可学习参数相结合，以选择性地关注数据的信息尺度，同时保持线性效率。

在单GPU上以及跨各种基准（视觉、NLP、分层推理）和各种注意力机制（如Multiheaded Attention、Flash-Attention-2、FNet、Linformer、Performer、Waveformer）进行的大规模比较表明，WERSA具有统一的优势。它在所有测试中均取得了最佳准确率。在ArXiv分类任务上，WERSA比传统注意力提高了1.2%的准确率（86.2% vs 85.0%），同时训练时间减少了81%（296s vs 1554s），FLOPS减少了73.4%（26.2G vs 98.4G）。值得注意的是，WERSA在传统注意力和FlashAttention-2失败的情况下表现出色：在ArXiv-128k的超长序列上，它在可行方法中取得了最佳准确率（79.1%）和AUC（0.979），处理的数据会导致二次方方法出现内存不足错误，同时比其次优竞争对手Waveformer快两倍。

通过显著降低计算负载而不影响准确性，WERSA使得更实用、更经济的长上下文模型成为可能，特别是在低资源硬件上，从而实现更可持续和可扩展的AI开发。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [261] [Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion](https://arxiv.org/abs/2410.00381)
> *使用Wasserstein正则化扩散方法对极端降水进行降尺度*

*Yuhao Liu, James Doss-Gollin, Qiushi Dai, Ashok Veeraraghavan, Guha Balakrishnan* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 极端降水, 降尺度, Wasserstein正则化, 扩散模型, 气候适应

**Comment:** 21 pages, 10 figures, 4 tables

> **TL;DR:** 新方法WassDiff利用扩散模型和Wasserstein正则化，能将粗分辨率的降水数据降尺度到高分辨率，提高极端降水事件的预测准确性，对洪水风险评估和气候适应规划至关重要。

**AI_Comments:** WassDiff的创新之处在于将扩散模型与Wasserstein正则化相结合，有效解决了降尺度过程中保持极端事件准确性的挑战。这对于洪水风险评估和气候适应规划具有重要意义，因为它能够从现有的大量粗分辨率历史数据中提取出宝贵的高分辨率信息，为决策提供了更可靠的数据支持。

<details>
  <summary>Details</summary>

**Motivation:** 理解极端降水事件的风险需要高分辨率产品和大量的历史记录。现有数据要么分辨率高但历史记录短、覆盖范围有限（如雷达和mesonet），要么历史记录长但分辨率低（如全球量规和混合产品），无法捕捉局部极端情况，限制了对局部危害的评估。

**Method:** 本文引入了Wasserstein正则化扩散（WassDiff），一个生成式降尺度框架。它将扩散建模与分布匹配（Wasserstein）正则化器相结合，以在整个生成去噪过程中抑制偏差。该方法以55公里CPC量规降水和31公里ERA5再分析数据为条件，生成1公里降水估计。

**Result:** WassDiff生成的1公里降水估计在整个强度范围（包括极端情况）内都能与目标保持良好校准。综合评估表明，WassDiff优于现有最先进的降尺度方法，提供了更低的重建误差和更小的偏差。案例研究进一步证明了其能够重现热带风暴和冷锋等极端天气现象的真实细尺度结构和准确的峰值强度。

**Conclusion:** WassDiff通过从全球可用的粗分辨率记录中解锁数十年的高分辨率降水信息，为更准确的洪水风险评估和气候适应规划提供了一条实用的途径。

> **ai_Abstract:** 这篇论文介绍了一种名为Wasserstein正则化扩散（WassDiff）的生成式降尺度框架，旨在解决极端降水事件高分辨率历史数据不足的问题。WassDiff结合了扩散模型和Wasserstein正则化，能够将粗分辨率的降水数据（如55公里CPC和31公里ERA5）降尺度到1公里，并保持对极端强度事件的良好校准。实验证明，WassDiff在重建误差和偏差方面优于现有方法，并能准确捕捉极端天气现象的细尺度结构和峰值强度，从而为洪水风险评估和气候适应规划提供高分辨率的降水信息。

> **摘要翻译:** 理解极端降水事件带来的风险既需要高分辨率产品（以评估局部危害）也需要大量的历史记录（以捕捉罕见事件）。雷达和中尺度网络提供公里尺度的降水场，但历史记录有限且地理覆盖范围受限。相反，全球量规和混合产品跨越数十年，但其粗糙的30-50公里网格模糊了局部极端情况。这项工作引入了Wasserstein正则化扩散（WassDiff），一个生成式降尺度框架，它将扩散建模与分布匹配（Wasserstein）正则化器相结合，在整个生成去噪过程中抑制偏差。以55公里CPC基于量规的降水和31公里ERA5再分析为条件，WassDiff生成1公里降水估计，这些估计在整个强度范围（包括极端情况）内都能与目标保持良好校准。综合评估表明，WassDiff优于现有最先进的降尺度方法，提供了更低的重建误差和更小的偏差。案例研究进一步证明了其能够重现热带风暴和冷锋等极端天气现象的真实细尺度结构和准确的峰值强度。通过从全球可用的粗分辨率记录中解锁数十年的高分辨率降水信息，WassDiff为更准确的洪水风险评估和气候适应规划提供了一条实用的途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [262] [Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model](https://arxiv.org/abs/2507.06892)
> *挤压湿透的海绵：大型语言模型的高效离策略强化微调*

*Jing Liang, Hongyao Tang, Yi Ma, Jinyi Liu, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 强化学习, 大型语言模型, 离策略, 微调, ReMix

**Comment:** Preliminary version, v3, added the missing name of x-axis in the left
  part of Fig.1 and corrected a wrong number in Fig.3. Project page:
  https://anitaleungxx.github.io/ReMix

> **TL;DR:** 针对大型语言模型强化微调中现有的在策略方法效率低下问题，本文提出了ReMix，一种通用的离策略方法，能显著降低训练成本并达到SOTA性能。

**AI_Comments:** 本文的主要创新在于将离策略强化学习的思想引入到大型语言模型的微调中，提出了ReMix框架，有效解决了传统在策略方法数据利用率低、训练成本高的问题。其贡献在于通过具体的技术组件（混合策略梯度、KL-凸约束、策略转生）实现了高效且稳定的离策略训练。ReMix在显著降低训练成本的同时，保持了SOTA级的性能，这对于LLM的持续发展和应用具有重要意义。文章还通过分析揭示了离策略训练可能带来的“鞭打效应”和“崩溃模式”，提供了对未来研究的启示。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型强化微调（RFT）方法大多是在策略（on-policy）性质的，导致过去学习过程中生成的数据未被充分利用。这带来了显著的计算和时间成本，对持续的经济高效扩展构成了严格瓶颈。

**Method:** 提出了一种名为“Reincarnating Mix-policy Proximal Policy Gradient (ReMix)”的通用方法，使PPO和GRPO等在策略RFT方法能够利用离策略数据。ReMix包含三个主要组成部分：1. 具有更高UTD（Update-To-Data）比率的混合策略近端策略梯度，用于高效训练；2. KL-凸策略约束，以平衡稳定性和灵活性之间的权衡；3. 策略转生（Policy reincarnation），实现从高效早期学习到稳定渐进改进的无缝过渡。

**Result:** 在PPO、GRPO以及1.5B和7B基础模型上训练了一系列ReMix模型。ReMix在五个数学推理基准测试中，对于1.5B模型，以0.079M响应rollouts和350个训练步骤，显示出平均52.10%的Pass@1准确率；对于7B模型，以0.007M/0.011M响应rollouts和50/75个训练步骤，实现了63.27%/64.39%的Pass@1准确率。与15个近期先进模型相比，ReMix展现了SOTA级别的性能，并在rollout数据量方面将训练成本降低了30到450倍。此外，还揭示了多方面分析的深刻发现，包括离策略差异引起的“鞭打效应”导致对较短响应的隐式偏好，以及在严重离策略性存在下自反思行为的崩溃模式等。

**Conclusion:** 本文提出的ReMix方法通过引入离策略强化微调，显著提升了大型语言模型训练的效率和经济性，在数学推理任务上取得了领先的性能，并大幅降低了计算成本，为LLM的持续扩展提供了新的途径。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）强化微调（RFT）中在策略方法效率低下、计算成本高昂的问题，提出了一种名为ReMix的通用离策略强化微调方法。ReMix通过引入混合策略近端策略梯度、KL-凸策略约束和策略转生机制，使得在策略RFT方法能够高效利用离策略数据。实验结果表明，ReMix在多个数学推理基准测试上取得了SOTA级别的性能，并显著将训练成本降低了30到450倍，为LLMs的经济高效扩展提供了有效途径。研究还揭示了离策略训练中关于响应偏好和自反思行为的潜在问题。

> **摘要翻译:** 强化学习（RL）已展示其改善大型语言模型（LLM）推理能力的潜力。大多数现有强化微调（RFT）方法的一个主要局限是它们本质上是在策略RL，即过去学习过程中生成的数据未被充分利用。这不可避免地带来了显著的计算和时间成本，对持续的经济高效扩展构成了严格瓶颈。为此，我们发起了离策略RL的复兴，并提出了Reincarnating Mix-policy Proximal Policy Gradient (ReMix)，这是一种通用方法，能够使PPO和GRPO等在策略RFT方法利用离策略数据。ReMix由三个主要组成部分构成：（1）具有更高更新-数据比率（UTD）的混合策略近端策略梯度，用于高效训练；（2）KL-凸策略约束，以平衡稳定性和灵活性之间的权衡；（3）策略转生（Policy reincarnation），以实现从高效早期学习到稳定渐进改进的无缝过渡。在我们的实验中，我们在PPO、GRPO以及1.5B和7B基础模型上训练了一系列ReMix模型。ReMix在五个数学推理基准测试（即AIME'24、AMC'23、Minerva、OlympiadBench和MATH500）中，对于1.5B模型，以0.079M响应rollouts和350个训练步骤，显示出平均52.10%的Pass@1准确率；对于7B模型，以0.007M/0.011M响应rollouts和50/75个训练步骤，实现了63.27%/64.39%的Pass@1准确率。与15个近期先进模型相比，ReMix展现了SOTA级别的性能，并在rollout数据量方面将训练成本降低了30到450倍。此外，我们通过多方面分析揭示了深刻的发现，包括由于离策略差异的“鞭打效应”导致对较短响应的隐式偏好，以及在严重离策略性存在下自反思行为的崩溃模式等。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [267] [Binary and Ternary Quantization Can Enhance Feature Discrimination](https://arxiv.org/abs/2504.13792)
> *二值和三值量化可以增强特征区分度*

*Weizhi Lu, Mingrui Chen, Weiyu Li* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 量化, 特征区分度, 二值量化, 三值量化, 分类性能

**Comment:** 

> **TL;DR:** 传统观点认为量化误差大会降低分类精度，但本文发现二值和三值量化非但不会降低，反而可能增强特征区分度，且实验证实了这一点。

**AI_Comments:** 这篇论文的创新点在于它挑战了量化领域中长期存在的关于误差与性能关系的传统假设，即量化误差大会导致分类精度下降。通过引入“特征区分度”这一新的评估视角，它为解释二值和三值量化在某些情况下表现优异的现象提供了理论依据，并为低比特量化的进一步研究开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统研究认为量化误差越大，分类精度越低，但二值和三值量化数据在引入显著误差的同时，有时能达到甚至超过全精度数据的分类精度，这与传统假设相悖，因此需要一个更准确的分类性能评估方法来解释这一现象。

**Method:** 提出直接分析量化数据的特征区分度，而非关注量化误差。

**Result:** 分析表明，二值和三值量化均能潜在地增强而非降低原始数据的特征区分度。该发现得到了合成数据和真实数据上的分类实验支持。

**Conclusion:** 二值和三值量化能够增强特征区分度，这挑战了传统上认为量化误差必然导致性能下降的观点。

> **ai_Abstract:** 本文针对机器学习中量化对分类性能的影响进行了研究。与传统关注量化误差并假设误差越大精度越低的观点不同，作者观察到二值和三值量化数据在引入大误差的同时，却能达到良好甚至更优的分类性能。为解释此现象，本文提出直接分析量化数据的特征区分度，而非量化误差。研究发现，二值和三值量化均能增强原始数据的特征区分度，并通过实验验证了这一结论。

> **摘要翻译:** 量化在机器学习中被广泛应用于降低数据和模型的计算和存储成本。考虑到分类任务是该领域的基础，研究量化如何影响分类性能至关重要。传统研究侧重于量化误差，假设较大的误差通常会导致较低的分类精度。然而，这一假设缺乏坚实的理论基础，并且经常与经验观察相矛盾。例如，尽管引入了显著误差，{0,1}-二值和{0, ±1}-三值量化数据有时能达到与全精度数据相当甚至更优的分类精度。为了合理地解释这一现象，需要对分类性能进行更准确的评估。为此，我们提出直接分析量化数据的特征区分度，而不是关注量化误差。我们的分析表明，二值和三值量化都可能增强而非降低原始数据的特征区分度。这一发现得到了在合成数据和真实数据上进行的分类实验的支持。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [274] [Quantum-Accelerated Neural Imputation with Large Language Models (LLMs)](https://arxiv.org/abs/2507.08255)
> *量子加速的基于大型语言模型的神经插补*

*Hossein Jamali* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 量子插补, 大型语言模型, 缺失数据, 量子电路, IQP电路

**Comment:** 

> **TL;DR:** 本文提出了Quantum-UnIMP，一个将浅层量子电路整合到基于LLM的插补架构中的新框架，通过量子特征映射提升了缺失数据插补的性能，在混合类型数据集上显著优于现有方法。

**AI_Comments:** 这项研究的创新在于将量子计算的优势（通过量子特征映射）引入到大型语言模型驱动的数据插补任务中，有效解决了经典嵌入在捕获复杂非线性相关性方面的局限性。其重要性在于为处理混合类型数据的缺失值提供了更高效、更准确的解决方案，并展示了近期量子硬件在实际机器学习应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界数据集中缺失数据是一个关键挑战，会显著降低机器学习模型的性能。虽然大型语言模型（LLMs）在表格数据插补方面表现出色，但其依赖经典嵌入方法限制了捕获复杂非线性相关性的能力，尤其是在混合类型数据场景中。

**Method:** 本文提出了Quantum-UnIMP，一个将浅层量子电路整合到基于LLM的插补架构中的新型框架。核心创新在于用由瞬时量子多项式（IQP）电路生成的量子特征映射取代传统的经典输入嵌入。这种方法使模型能够利用叠加和纠缠等量子现象，从而学习更丰富、更具表达力的数据表示，并增强对复杂缺失模式的恢复。

**Result:** 在基准混合类型数据集上的实验表明，与最先进的经典和基于LLM的方法相比，Quantum-UnIMP对数值特征的插补误差（RMSE）降低了15.2%，对分类特征的分类准确率（F1-Score）提高了8.7%。

**Conclusion:** 这些引人注目的结果突显了量子增强表示在复杂数据插补任务中的巨大潜力，即使是使用近期量子硬件也能实现。

> **ai_Abstract:** 本文介绍了Quantum-UnIMP，一个新颖的框架，它将浅层量子电路集成到基于LLM的缺失数据插补架构中。通过用量子特征映射取代传统的经典输入嵌入，Quantum-UnIMP能够利用量子现象学习更丰富的数据表示，从而更好地恢复复杂的缺失模式。实验证明，在混合类型数据集上，Quantum-UnIMP在数值特征插补误差和分类特征准确率方面均显著优于现有经典和LLM方法，展示了量子增强表示在复杂数据插补中的巨大潜力。

> **摘要翻译:** 缺失数据在现实世界数据集中是一个关键挑战，会显著降低机器学习模型的性能。尽管大型语言模型（LLMs）最近在表格数据插补方面表现出卓越的能力，例如UnIMP框架，但它们对经典嵌入方法的依赖通常限制了其捕获复杂非线性相关性的能力，尤其是在包含数值、分类和文本特征的混合类型数据场景中。本文引入了Quantum-UnIMP，一个将浅层量子电路整合到基于LLM的插补架构中的新型框架。我们的核心创新在于用由瞬时量子多项式（IQP）电路生成的量子特征映射取代传统的经典输入嵌入。这种方法使模型能够利用叠加和纠缠等量子现象，从而学习更丰富、更具表达力的数据表示，并增强对复杂缺失模式的恢复。我们在基准混合类型数据集上的实验表明，与最先进的经典和基于LLM的方法相比，Quantum-UnIMP对数值特征的插补误差（RMSE）降低了15.2%，对分类特征的分类准确率（F1-Score）提高了8.7%。这些引人注目的结果突显了量子增强表示在复杂数据插补任务中的巨大潜力，即使是使用近期量子硬件也能实现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [280] [Forget Me Not: Fighting Local Overfitting with Knowledge Fusion and Distillation](https://arxiv.org/abs/2507.08686)
> *勿忘我：通过知识融合和蒸馏对抗局部过拟合*

*Uri Stern, Eli Corn, Daphna Weinshall* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 局部过拟合, 知识融合, 知识蒸馏, 深度学习, 模型优化

**Comment:** arXiv admin note: substantial text overlap with arXiv:2412.12968

> **TL;DR:** 本文引入了“局部过拟合”的概念及其衡量方法，并提出了一种基于知识融合和蒸馏的两阶段方法，有效提升了深度模型的性能，并降低了训练和推理复杂度，尤其在标签噪声环境下表现出色。

**AI_Comments:** 本文的创新之处在于提出了“局部过拟合”这一新颖且具有实际意义的概念，并提供了量化方法，深化了对深度学习模型泛化行为的理解。其提出的“知识融合与蒸馏”两阶段方法，巧妙地利用了模型训练历史，实现了在不增加推理成本的情况下提升性能，并降低了整体计算复杂度，尤其在处理带有噪声的数据时展现出强大的鲁棒性。这为解决实际应用中深度模型的局部性能退化问题提供了有效且高效的解决方案，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管理论预测深度神经网络容量增大应导致过拟合，但实践中全局过拟合并不常见，这令人费解。作者提出过拟合可能并非全局发生，而是在数据空间的特定子区域出现，即“局部过拟合”，并旨在解决这一问题。

**Method:** 本文引入了一种新颖的分数来衡量深度模型在验证数据上的遗忘率，以捕捉局部过拟合，并发现其与双下降现象相关。在此基础上，提出了一种两阶段方法：首先通过将训练过程中的模型检查点聚合成一个集成模型（知识融合），然后将该集成模型蒸馏回一个原始大小的单一模型（知识蒸馏），以恢复和保留被遗忘的知识。

**Result:** 广泛的实验验证了该方法在多个数据集、现代架构和训练方案上的有效性。尤其在存在标签噪声的情况下，该方法（知识融合后接知识蒸馏）表现优于原始模型和独立训练的集成模型，实现了在提升性能的同时降低训练和推理复杂度的双赢局面。

**Conclusion:** 本文成功引入并量化了深度神经网络中的“局部过拟合”现象，并提出了一种创新的、基于知识融合和蒸馏的两阶段解决方案。该方法不仅有效提升了模型性能，尤其是在处理带标签噪声的数据时，还显著降低了计算成本，为深度学习模型的鲁棒性和效率优化提供了新的途径。

> **ai_Abstract:** 本文探讨了深度神经网络中的“局部过拟合”现象，即模型性能在数据特定区域出现下降。作者提出了一种衡量模型在验证数据上遗忘率的新分数来量化局部过拟合，并指出其与双下降现象的关联。为解决此问题，论文提出了一种名为“知识融合与蒸馏”的两阶段方法：首先将训练过程中的多个模型检查点聚合成一个集成模型，然后将其知识蒸馏到一个单一模型中。实验证明，该方法能有效恢复和保留被遗忘的知识，显著提升模型性能，尤其在存在标签噪声时表现出色，同时降低了训练和推理的计算复杂度。

> **摘要翻译:** 深度神经网络中的过拟合发生频率低于预期。这是一个令人费解的观察，因为理论预测更大的模型容量最终会导致过拟合——然而这在实践中很少见到。但是，如果过拟合确实发生，不是全局性的，而是在数据空间的特定子区域呢？在这项工作中，我们引入了一种新颖的分数，用于衡量深度模型在验证数据上的遗忘率，捕捉我们称之为局部过拟合的现象：性能下降仅限于输入空间的某些区域。我们证明了局部过拟合即使在没有传统过拟合的情况下也可能出现，并且与双下降现象密切相关。基于这些见解，我们引入了一种两阶段方法，利用单个模型的训练历史来恢复和保留遗忘的知识：首先，通过将检查点聚合到一个集成中，然后通过将其蒸馏成一个原始大小的单一模型，从而在不增加推理成本的情况下提高性能。在多个数据集、现代架构和训练方案上进行的广泛实验验证了我们方法的有效性。值得注意的是，在存在标签噪声的情况下，我们的方法——知识融合后接知识蒸馏——优于原始模型和独立训练的集成模型，实现了一个罕见的双赢局面：降低了训练和推理复杂度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [291] [Compositional Risk Minimization](https://arxiv.org/abs/2410.06303)
> *组合风险最小化*

*Divyat Mahajan, Mohammad Pezeshki, Charles Arnal, Ioannis Mitliagkas, Kartik Ahuja, Pascal Vincent* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 组合泛化, 分布偏移, 风险最小化, 加性能量分布, 鲁棒性

**Comment:** Proceedings of the 42nd International Conference on Machine Learning
  (ICML) 2025

> **TL;DR:** 该论文提出了一种名为组合风险最小化（CRM）的新方法，用于解决训练时缺失但测试时存在的新颖属性组合导致的组合偏移问题，并通过理论和实证分析证明了其泛化能力和鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了组合风险最小化（CRM）作为经验风险最小化（ERM）的替代方案，专门用于解决组合泛化问题中的分布偏移。其重要性体现在提升模型对未见属性组合的泛化能力，这对于构建更稳健、更像人类的智能机器至关重要。论文还提供了坚实的理论分析，支持其外推能力，增强了方法的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 开发能够以类人方式泛化的数据高效智能机器，并解决一种特殊的分布偏移——组合偏移，即训练数据中缺失某些属性组合，但在测试数据中出现，这挑战了模型对新颖属性组合的组合泛化能力。

**Method:** 通过灵活的加性能量分布对数据进行建模，其中每个能量项代表一个属性。在此基础上，推导出了经验风险最小化（ERM）的一种简单替代方案——组合风险最小化（CRM）。首先训练一个加性能量分类器来预测多个属性，然后调整该分类器以应对组合偏移。

**Result:** 理论分析表明，CRM能够外推到已见属性组合的特殊仿射包。在基准数据集上的实证评估证实，与文献中旨在解决各种形式子群体偏移的其他方法相比，CRM的鲁棒性有所提高。

**Conclusion:** 组合风险最小化（CRM）是一种有效且鲁棒的方法，能够处理训练时缺失但测试时存在的新颖属性组合导致的组合偏移问题，从而提高模型的泛化能力。

> **ai_Abstract:** 该论文引入了组合风险最小化（CRM），旨在解决数据中存在的组合偏移问题，即测试集中出现训练时未见的属性组合。CRM通过使用加性能量分布对数据进行建模，并训练一个加性能量分类器，然后进行调整以应对此类偏移。理论分析和实证评估均表明，CRM能够有效外推到新颖的组合，并相较于现有方法展现出更高的鲁棒性。

> **摘要翻译:** 组合泛化是开发能够以类人方式泛化的数据高效智能机器的关键一步。在这项工作中，我们解决了一种具有挑战性的分布偏移形式，称为组合偏移，即在训练时某些属性组合完全缺失，但在测试分布中存在。这种偏移考验模型在判别任务中对新颖属性组合进行组合泛化的能力。我们使用灵活的加性能量分布对数据进行建模，其中每个能量项代表一个属性，并推导出了经验风险最小化的一种简单替代方案，称为组合风险最小化（CRM）。我们首先训练一个加性能量分类器来预测多个属性，然后调整该分类器以解决组合偏移。我们对CRM进行了广泛的理论分析，结果表明我们的提议可以外推到已见属性组合的特殊仿射包。在基准数据集上的实证评估证实，与文献中旨在解决各种形式子群体偏移的其他方法相比，CRM的鲁棒性有所提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [292] [On learning functions over biological sequence space: relating Gaussian process priors, regularization, and gauge fixing](https://arxiv.org/abs/2504.19034)
> *关于生物序列空间函数学习：关联高斯过程先验、正则化与规范固定*

*Samantha Petti, Carlos Martí-Gómez, Justin B. Kinney, Juannan Zhou, David M. McCandlish* | **Category: cs.LG, q-bio.GN, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 生物序列, 高斯过程, 正则化, 规范固定, 序列-功能映射

**Comment:** 

> **TL;DR:** 本文建立了过参数权重空间中的正则化回归与函数空间中高斯过程方法之间的关系，并阐明了权重空间正则化器如何施加隐式先验并限制最优权重到特定规范，从而统一并扩展了推断和解释序列-功能关系的能力。

**AI_Comments:** 本文在理论上建立了正则化回归与高斯过程在生物序列功能预测领域的联系，为理解和设计更有效的序列-功能映射模型提供了坚实的基础。其创新之处在于明确揭示了正则化器在权重空间和函数空间中的双重作用，并提出了如何通过构造正则化器来结合特定的先验和规范。这种统一的视角对于生物序列功能预测和解释具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生物序列（DNA、RNA、蛋白质）到序列功能定量度量的映射在当代生物学中至关重要。研究旨在推断预测性的序列-功能映射，并分解这些映射以阐明个体子序列的贡献。由于每个序列-功能映射可以通过多种方式表示为子序列的加权和，因此有意义地解释这些权重需要“规范固定”，即为每个映射定义一个独特的表示。

**Method:** 本文建立了过参数权重空间中的正则化回归与函数空间中高斯过程方法之间的关系。研究阐明了权重空间正则化器如何同时对学习函数施加隐式先验并将最优权重限制在特定规范。作者还展示了如何构建对应于任意显式高斯过程先验与各种规范的正则化器。接着，推导了高斯过程后验所隐含的规范固定权重的分布，并证明即使对于长序列，使用核技巧也能有效地计算乘积核先验的此分布。最后，表征了与最常见的权重空间正则化器相关的隐式函数空间先验。

**Result:** 研究建立了过参数权重空间中的正则化回归与函数空间中高斯过程方法之间的关系。阐明了权重空间正则化器如何同时施加隐式先验并限制最优权重到特定规范。展示了构建对应于任意显式高斯过程先验与各种规范的正则化器的方法。证明了高斯过程后验所隐含的规范固定权重的分布即使对于长序列也能使用核技巧高效计算。表征了与最常见权重空间正则化器相关的隐式函数空间先验。

**Conclusion:** 总体而言，本文提出的框架统一并扩展了我们推断和解释序列-功能关系的能力。

> **ai_Abstract:** 本文探讨了生物序列到功能映射的学习问题，旨在推断预测模型并解释子序列贡献。为解决权重解释的“规范固定”问题，作者建立了过参数权重空间中的正则化回归与函数空间中高斯过程方法之间的深层联系。研究揭示了权重空间正则化器如何同时施加隐式函数先验并强制执行特定的规范。此外，论文展示了如何构建与任意高斯过程先验和多种规范相对应的正则化器，并提出了高效计算规范固定权重分布的方法。该框架统一并增强了对序列-功能关系的推断和解释能力。

> **摘要翻译:** 将生物序列（DNA、RNA、蛋白质）映射到序列功能的定量度量在当代生物学中发挥着重要作用。我们对相关的任务感兴趣：(i) 推断预测性的序列-功能映射，以及 (ii) 分解序列-功能映射以阐明个体子序列的贡献。由于每个序列-功能映射可以通过多种方式表示为子序列的加权和，因此有意义地解释这些权重需要“规范固定”，即为每个映射定义一个独特的表示。最近的研究已经证实，大多数现有的规范固定表示是过参数“权重空间”中L2正则化回归的独特解，其中正则化器的选择定义了规范。本文建立了过参数权重空间中的正则化回归与在“函数空间”（即在有限序列集上所有实值函数的空间）中操作的高斯过程方法之间的关系。我们阐明了权重空间正则化器如何同时对学习函数施加隐式先验并将最优权重限制在特定规范。我们还展示了如何构建对应于任意显式高斯过程先验与各种规范的正则化器。接下来，我们推导了高斯过程后验所隐含的规范固定权重的分布，并证明即使对于长序列，使用核技巧也能有效地计算乘积核先验的此分布。最后，我们表征了与最常见的权重空间正则化器相关的隐式函数空间先验。总的来说，我们的框架统一并扩展了我们推断和解释序列-功能关系的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [300] [Domain-Informed Operation Excellence of Gas Turbine System with Machine Learning](https://arxiv.org/abs/2507.08697)
> *燃气轮机系统领域知识赋能的卓越运行与机器学习*

*Waqar Muhammad Ashraf, Amir H. Keshavarzzadeh, Abdulelah S. Alshehri, Abdulrahman bin Jumah, Ramit Debnath, Vivek Dua* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 燃气轮机系统, 机器学习, 领域知识, 马哈拉诺比斯距离, 优化

**Comment:** 

> **TL;DR:** 开发了一个名为MAD-OPT的机器学习框架，通过引入基于马哈拉诺比斯距离的约束来整合领域知识，以优化燃气轮机系统的运行，提高热效率并降低热耗，并证明其鲁棒性和有效性。

**AI_Comments:** 这篇论文的创新点在于提出了MAD-OPT框架，通过引入马哈拉诺比斯距离约束，有效地将领域知识融入到机器学习优化中，解决了AI在工业应用中“黑箱”和领域知识不足的问题。其重要性在于提升了燃气轮机系统运行的卓越性，并为AI在关键基础设施中的安全、可靠应用提供了可行路径。

<details>
  <summary>Details</summary>

**Motivation:** 热电厂中人工智能的领域一致性应用率较低，原因是AI算法的黑箱性质以及传统数据中心分析中领域知识表示不足。

**Method:** 开发了一个基于马哈拉诺比斯距离优化的（MAD-OPT）框架，该框架通过引入基于马哈拉诺比斯距离的约束，将领域知识引入到以数据为中心的分析中。

**Result:** MAD-OPT框架能够估计不同环境条件下的领域知识赋能的最优过程条件，且最优解经蒙特卡洛模拟评估后被证实具有鲁棒性。该框架还能估计超出设计发电限制的最佳过程条件，并与电厂实际数据取得可比结果。未整合领域知识约束的数据中心优化分析可能提供无效且无法在实际操作中实施的解决方案。

**Conclusion:** 该研究推进了数据驱动的领域知识与机器学习驱动分析的整合，从而提升了领域知识赋能的卓越运行，并为人工智能在热力发电系统中的安全应用铺平了道路。

> **ai_Abstract:** 本文提出了一种名为MAD-OPT的机器学习框架，旨在解决热电厂中AI应用不足的问题，该框架通过引入基于马哈拉诺比斯距离的约束，将领域知识有效地融入到数据中心分析中。MAD-OPT被成功应用于优化395兆瓦燃气轮机系统的热效率和热耗，实验证明其在不同环境条件下能估计出鲁棒且有效的最优过程条件，甚至能超出设计限制。研究强调了领域知识对实际可实施优化方案的重要性，并为热力系统中AI的安全应用提供了新途径。

> **摘要翻译:** 热电厂中，由于人工智能（AI）算法的黑箱性质以及传统以数据为中心的分析中领域知识表示不足，人工智能的领域一致性应用率仍然很低。在本文中，我们开发了一个基于马哈拉诺比斯距离优化的（MAD-OPT）框架，该框架通过引入基于马哈拉诺比斯距离的约束，将领域知识引入到以数据为中心的分析中。所开发的MAD-OPT框架应用于最大化一个395兆瓦燃气轮机系统的热效率并最小化其汽轮机热耗。我们证明MAD-OPT框架可以在不同环境条件下估计领域知识赋能的最优过程条件，并且通过蒙特卡洛模拟评估，最优解被发现具有鲁棒性。我们还将MAD-OPT框架应用于估计超出燃气轮机系统设计发电限制的最佳过程条件，并发现与电厂实际数据具有可比结果。我们证明，在不结合领域知识约束的情况下实施以数据为中心的优化分析可能会提供无效的解决方案，这些解决方案可能无法在燃气轮机系统的实际运行中实施。这项研究推进了数据驱动的领域知识与机器学习驱动分析的整合，从而提升了领域知识赋能的卓越运行，并为人工智能在热力发电系统中的安全应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [314] [A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning](https://arxiv.org/abs/2507.08267)
> *数学LLM的实用两阶段训练方案：通过SFT最大化准确性，通过强化学习提高效率*

*Hiroshi Yoshihara, Taiki Yamaguchi, Yuichi Inoue* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 数学LLM, 监督微调, 强化学习, 准确性, 效率

**Comment:** Presented at ICML 2025 Workshop on The second AI for MATH

> **TL;DR:** 提出一种结合扩展SFT和GRPO的两阶段训练方案，用于提升数学LLM的准确性和效率，并在AIMO等基准测试中取得顶尖表现。

**AI_Comments:** 这篇论文通过提出一个实用的两阶段训练方案，为提高数学LLM的性能提供了清晰的指导。其创新点在于明确了SFT和RL（GRPO）的互补作用，并量化了SFT的训练时长对性能的重要性。该方法在实际竞赛中的优异表现证明了其有效性，且开源的承诺将极大地促进社区的进一步研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 提高LLM的数学推理能力是AI发展的重要挑战。尽管SFT和RL是主流训练范式，但如何系统地结合两者以同时最大化准确性和效率仍未被充分探索。

**Method:** 论文提出一个实用的两阶段训练方案：首先通过长时间的SFT（多达10个epoch）将模型准确性推向极限，然后通过在线推理的强化学习（GRPO）阶段显著提高token效率，同时保持峰值性能。

**Result:** 实验表明，SFT的延长训练对性能突破至关重要。GRPO在该框架中的主要作用是优化解决方案的长度。该方案在包括AI数学奥林匹克（AIMO）在内的挑战性基准测试中取得了顶尖表现，在2200多个团队中排名靠前。

**Conclusion:** 本工作为开发兼具高准确性和实用效率的先进数学推理器提供了一个经过实战检验的蓝图，并将开源所有代码、模型检查点和训练配置以促进复现和未来研究。

> **ai_Abstract:** 本文提出了一种实用的两阶段训练方案，旨在最大化大型语言模型（LLM）的数学推理准确性并提高其效率。该方案首先通过长时间的监督微调（SFT）将模型准确性推至极限，随后利用在线推理的强化学习（GRPO）显著优化token效率，同时保持性能。实验证明，延长SFT训练至关重要，而GRPO主要用于缩短解决方案长度。该方法在AI数学奥林匹克（AIMO）等挑战性基准测试中表现优异，并计划开源以促进研究。

> **摘要翻译:** 增强大型语言模型（LLM）的数学推理能力是推动人工智能发展的关键挑战。尽管监督微调（SFT）和强化学习（RL）是主要的训练范式，但如何系统地结合它们以同时最大化准确性和效率仍未被充分探索。本文介绍了一种实用且有效的训练方案，该方案策略性地将扩展的SFT与来自在线推理的强化学习（GRPO）相结合。我们认为这些方法是互补而非竞争的关系：一个长时间的SFT阶段首先将模型的准确性推向极限，之后一个GRPO阶段在保持这种峰值性能的同时，显著提高了token效率。我们的实验表明，将SFT扩展到多达10个epoch对于性能突破至关重要，并且GRPO在该框架中的主要作用是优化解决方案的长度。我们的方案通过在具有挑战性的基准测试中取得顶尖性能得到了严格验证，包括在严格无泄露的AI数学奥林匹克（AIMO）中在2200多个团队中获得高排名。这项工作为社区提供了一个经过实战检验的蓝图，用于开发既异常准确又实际高效的先进数学推理器。为了确保完全可复现性并赋能未来的研究，我们将开源我们的整个框架，包括所有代码、模型检查点和训练配置，网址为https://github.com/analokmaus/kaggle-aimo2-fast-math-r1。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [320] [On the Effect of Regularization in Policy Mirror Descent](https://arxiv.org/abs/2507.08718)
> *策略镜像下降中正则化的影响*

*Jan Felix Kleuker, Aske Plaat, Thomas Moerland* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 策略镜像下降, 正则化, 强化学习, 经验分析, 超参数敏感性

**Comment:** Accepted at RLC

> **TL;DR:** 策略镜像下降（PMD）中的距离项和MDP正则化器虽然可以部分相互替代，但它们的精确组合对于实现稳健的性能至关重要。

**AI_Comments:** 这篇论文通过大规模的经验分析填补了策略镜像下降（PMD）在正则化方面经验研究的空白。其创新之处在于首次系统地探讨了PMD中两种关键正则化组件的协同作用，并强调了精确组合对性能鲁棒性的关键影响。这对于理解PMD的实际应用和开发对超参数不那么敏感的强化学习算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 策略镜像下降（PMD）在理论上已被广泛研究，但其经验性研究，特别是两种关键正则化组件（距离项和MDP正则化器）之间的相互作用，仍然稀缺。

**Method:** 进行了大规模的经验分析，在小型强化学习环境中运行了超过50万个训练种子，以研究两种正则化技术之间的相互作用。

**Result:** 结果表明，尽管两种正则化器可以部分相互替代，但它们的精确组合对于实现稳健的性能至关重要。

**Conclusion:** 这些发现强调了在强化学习中推进更稳健算法研究的潜力，特别是在超参数敏感性方面。

> **ai_Abstract:** 这项工作对策略镜像下降（PMD）中两种核心正则化组件（距离项和MDP正则化器）的相互作用进行了大规模经验分析。尽管PMD在理论上被广泛研究，但其经验证据不足。研究发现，虽然这两种正则化器可以部分替代，但它们的精确组合对于实现稳健的性能至关重要，这为未来开发更稳健的强化学习算法提供了方向，尤其是在处理超参数敏感性方面。

> **摘要翻译:** 策略镜像下降（PMD）通过将策略梯度方法与一阶优化方法——镜像下降联系起来，已成为强化学习（RL）中一个统一的框架。PMD 的核心包含两个关键的正则化组件：(i) 一个距离项，用于强制执行信任域以实现稳定的策略更新；(ii) 一个 MDP 正则化器，用于增强奖励函数以促进结构和鲁棒性。虽然 PMD 在理论上已被广泛研究，但经验性研究仍然稀缺。这项工作提供了对这两种正则化技术之间相互作用的大规模经验分析，在小型 RL 环境中运行了超过 50 万个训练种子。我们的结果表明，尽管这两种正则化器可以部分相互替代，但它们的精确组合对于实现稳健的性能至关重要。这些发现突出了在强化学习中推进更稳健算法研究的潜力，特别是在超参数敏感性方面。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [321] [On the Principles of ReLU Networks with One Hidden Layer](https://arxiv.org/abs/2411.06728)
> *单隐藏层ReLU网络的原理*

*Changcun Huang* | **Category: cs.LG, cs.AI, cs.NE, 68T07(Primary), 41A15(Secondary), I.2.6; G.1.2** | **Updated: 2025-07-11**

**Keywords:** ReLU网络, 单隐藏层, 黑箱问题, 函数逼近, 可解释性

**Comment:** 

> **TL;DR:** 本文系统研究了单隐藏层ReLU网络的机制，通过构建通用函数逼近解，证明了其在1D输入下可完全理解，高维输入下也可部分解释，有助于揭示神经网络的“黑箱”问题。

**AI_Comments:** 本文通过对最简单的神经网络架构——单隐藏层ReLU网络进行深入分析，旨在揭示其内部工作机制，这对于理解更复杂的深度学习模型具有重要意义。其创新之处在于尝试将“黑箱”模型的可解释性研究推向更基础的层面，为神经网络的可解释性研究提供了新的视角和方法。

<details>
  <summary>Details</summary>

**Motivation:** 即使是单隐藏层神经网络这种最简单的神经网络架构，其内部机制仍然像一个“黑箱”，难以解释反向传播算法得到的解以及确定性地控制训练过程。本文旨在系统研究第一个问题，即理解其工作机制。

**Method:** 本文通过构建通用函数逼近解的方法，系统研究了单隐藏层ReLU网络的机制。

**Result:** 理论和实验结果表明，对于一维输入，单隐藏层ReLU网络的训练解可以被完全理解；对于更高维的输入，其训练解也可以在一定程度上得到很好的解释。

**Conclusion:** 这些研究结果为彻底揭示两层ReLU网络的“黑箱”提供了途径，并加深了对深度ReLU网络的理解。

> **ai_Abstract:** 本文深入探讨了单隐藏层ReLU神经网络的工作原理，旨在解决其“黑箱”问题。通过构建通用函数逼近解，研究发现对于一维输入，网络的训练解可以被完全理解；对于高维输入，也能在一定程度上进行有效解释。这些发现为理解两层及更深层ReLU网络的内部机制奠定了基础。

> **摘要翻译:** 一个带有一个隐藏层的神经网络，或者说一个两层网络（不考虑输入层），是最简单的前馈神经网络，其机制可能是更通用网络架构的基础。然而，即使对于这种简单的架构，它仍然是一个“黑箱”；也就是说，通过反向传播算法获得的解的机制如何解释，以及如何通过确定性方式控制训练过程，仍然不清楚。本文通过构建通用函数逼近解的方法，系统地研究了第一个问题。理论和实验表明，一维输入的训练解可以被完全理解，而更高维输入的训练解也可以在一定程度上得到很好的解释。这些结果为彻底揭示两层ReLU网络的黑箱铺平了道路，并促进了对深度ReLU网络的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [322] [Assessing the Chemical Intelligence of Large Language Models](https://arxiv.org/abs/2505.07735)
> *评估大型语言模型的化学智能*

*Nicholas T. Runcie, Charlotte M. Deane, Fergus Imrie* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 大型语言模型, 推理模型, 化学智能, ChemIQ, NMR

**Comment:** 

> **TL;DR:** 大型语言模型（特别是推理模型）的化学智能通过新的ChemIQ基准进行了评估。推理模型表现显著更好，能够进行SMILES到IUPAC转换和NMR结构解析，过程类似人类推理。

**AI_Comments:** 创新点在于创建了新型简答题基准ChemIQ，而非传统的选择题。该研究的重要性在于揭示了大型语言模型，特别是推理模型，在化学领域取得了显著进步，甚至能进行高级化学推理，这可能对化学研究和教育产生影响。局限性在于，模型的正确率仍为50%-57%，并非完美，且“在某些情况下”表明其高级化学推理能力仍有限。

<details>
  <summary>Details</summary>

**Motivation:** 评估最新推理模型在化学任务中的表现，此前它们已在数学和软件工程等领域展现出显著进步。

**Method:** 创建了一个名为ChemIQ的新型基准，包含816个有机化学核心概念的简答题，评估了OpenAI的o3-mini、Google的Gemini Pro 2.5和DeepSeek R1等推理模型在没有外部工具辅助下的化学任务能力，包括SMILES到IUPAC命名转换和NMR数据结构解析。

**Result:** 推理模型（o3-mini, Gemini Pro 2.5, DeepSeek R1）在ChemIQ基准上正确率达50%-57%，远超非推理模型（3%-7%）。它们能够将SMILES字符串转换为IUPAC名称，并从1D和2D NMR数据中解析结构，其中Gemini Pro 2.5对多达10个重原子的分子结构解析准确率约90%。

**Conclusion:** 最新的推理模型在某些情况下能够进行高级化学推理，且其推理过程与人类化学家相似。

> **ai_Abstract:** 本研究评估了大型语言模型（特别是推理模型）在化学任务中的表现。通过创建名为ChemIQ的新型简答题基准，研究发现推理模型在有机化学概念、SMILES到IUPAC命名转换以及NMR结构解析方面表现出色，正确率显著高于非推理模型，并且其推理过程与人类化学家相似，表明它们具备一定的化学智能和高级化学推理能力。

> **摘要翻译:** 大型语言模型是多功能、通用工具，应用范围广泛。最近，“推理模型”的出现使其在数学和软件工程等高级问题解决领域的能力得到大幅提升。在这项工作中，我们直接评估了推理模型执行化学任务的能力，无需任何外部工具的辅助。我们创建了一个名为ChemIQ的新型基准，包含816个评估有机化学核心概念的问题，重点关注分子理解和化学推理。与以前主要使用多项选择格式的基准不同，我们的方法要求模型构建简答式答案，更接近真实世界的应用。推理模型，OpenAI的o3-mini、Google的Gemini Pro 2.5和DeepSeek R1，在最高推理模式下正确回答了50%-57%的问题，更高的推理水平显著提高了所有任务的性能。这些模型大大优于非推理模型，后者仅达到3%-7%的准确率。我们发现大型语言模型现在可以将SMILES字符串转换为IUPAC名称，这是早期模型无法执行的任务。此外，我们展示了最新的推理模型可以从1D和2D 1H和13C NMR数据中阐明结构，其中Gemini Pro 2.5正确生成了约90%包含多达10个重原子的分子的SMILES字符串，并且在一个案例中解决了一个包含25个重原子的结构。对于每项任务，我们都发现证据表明其推理过程与人类化学家相似。我们的结果表明，最新的推理模型在某些情况下可以执行高级化学推理。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [342] [Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings](https://arxiv.org/abs/2507.07532)
> *神经概念验证器：通过概念编码扩展证明者-验证者博弈*

*Berkant Turan, Suhrab Asadulla, David Steinmann, Wolfgang Stammer, Sebastian Pokutta* | **Category: cs.LG, cs.AI, 68T01, 68T07, I.2.6** | **Updated: 2025-07-11**

**Keywords:** 神经概念验证器, 证明者-验证者博弈, 概念编码, 可解释AI, 高维分类

**Comment:** 16 pages, 4 figures, 8 tables, revised references

> **TL;DR:** 提出了神经概念验证器 (NCV)，结合证明者-验证者博弈和概念编码，实现了高维数据的可解释、非线性分类，并优于现有基线模型。

**AI_Comments:** 本文的创新点在于将证明者-验证者博弈与概念编码相结合，解决了高维数据可解释性与可验证性的难题。通过引入概念编码，NCV在保持非线性分类能力的同时，增强了模型的透明度和可解释性，并且在实际应用中展现出优越的性能，尤其是在缓解模型捷径行为方面具有重要意义。这对于构建更值得信赖和鲁棒的AI系统具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管证明者-验证者博弈（PVGs）为非线性分类模型的可验证性提供了一条有前景的路径，但它们尚未应用于高维图像等复杂输入。相反，概念瓶颈模型（CBMs）能有效地将此类数据转化为可解释的概念，但受限于其对低容量线性预测器的依赖。

**Method:** 引入了神经概念验证器（NCV），这是一个统一的框架，结合了PVGs和概念编码，用于高维设置中的可解释、非线性分类。NCV通过利用最近的最小监督概念发现模型从原始输入中提取结构化概念编码。一个证明者选择这些编码的子集，一个作为非线性预测器实现的验证者专门使用这些编码进行决策。

**Result:** 评估表明，NCV在高维、逻辑复杂的数据集上优于CBM和基于像素的PVG分类器基线，并且还有助于减轻捷径行为。

**Conclusion:** NCV是迈向高性能、可验证人工智能的一个有前景的步骤。

> **ai_Abstract:** 本文提出了神经概念验证器（NCV），该框架结合了证明者-验证者博弈（PVGs）和概念编码，旨在解决现有PVGs在高维数据应用上的局限性以及概念瓶颈模型（CBMs）的线性预测器限制。NCV通过从原始输入中提取结构化概念编码，并由证明者选择、验证者使用这些编码进行决策，实现了高维环境下的可解释、非线性分类。实验结果表明，NCV在处理复杂数据集时性能优于CBM和基于像素的PVG基线，并能有效缓解模型学习捷径行为，为可验证AI提供了新的方向。

> **摘要翻译:** 尽管证明者-验证者博弈（PVGs）为非线性分类模型的可验证性提供了一条有前景的路径，但它们尚未应用于高维图像等复杂输入。相反，概念瓶颈模型（CBMs）能有效地将此类数据转化为可解释的概念，但受限于其对低容量线性预测器的依赖。在这项工作中，我们引入了神经概念验证器（NCV），这是一个统一的框架，结合了PVGs和概念编码，用于高维设置中的可解释、非线性分类。NCV 通过利用最近的最小监督概念发现模型从原始输入中提取结构化概念编码来实现这一点。然后，一个证明者选择这些编码的子集，一个作为非线性预测器实现的验证者专门使用这些编码进行决策。我们的评估表明，NCV 在高维、逻辑复杂的数据集上优于CBM和基于像素的PVG分类器基线，并且还有助于减轻捷径行为。总的来说，我们展示了NCV是迈向高性能、可验证人工智能的一个有前景的步骤。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [345] [Monitoring Risks in Test-Time Adaptation](https://arxiv.org/abs/2507.08721)
> *测试时自适应中的风险监控*

*Mona Schirmer, Metod Jazbec, Christian A. Naesseth, Eric Nalisnick* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 测试时自适应, 风险监控, 数据漂移, 无标签数据, 序列检验

**Comment:** 

> **TL;DR:** 提出一种将测试时自适应（TTA）与风险监控框架结合的方法，以在模型遇到数据漂移时，在无标签情况下，检测其性能何时下降到需要重新训练的程度。

**AI_Comments:** 这项工作具有重要的实际意义，因为它解决了TTA在实际部署中面临的核心问题：如何知道模型何时失效。通过将统计风险监控引入无标签的TTA场景，该研究提供了一种严谨的方法来提高模型部署的鲁棒性和可靠性。其创新点在于扩展了现有监控工具以适应无标签和模型动态更新的复杂TTA环境。

<details>
  <summary>Details</summary>

**Motivation:** 部署预测模型时，测试时遇到数据漂移是一个普遍挑战。尽管测试时自适应（TTA）可以延长模型寿命，但它只是一个临时解决方案，模型最终会退化到需要下线并重新训练的程度。因此，需要一种机制来检测模型最终失效的点。

**Method:** 作者提出将TTA与风险监控框架结合，该框架跟踪预测性能并在违反预定义性能标准时发出警报。具体来说，他们扩展了基于序列检验和置信序列的现有监控工具，以适应模型在测试时更新且没有测试标签可用于估计性能指标的场景。

**Result:** 他们的扩展解锁了将严格的统计风险监控应用于TTA的可能性。他们还在一系列代表性数据集、分布漂移类型和TTA方法上证明了所提出的TTA监控框架的有效性。

**Conclusion:** 该研究成功地将严格的统计风险监控应用于测试时自适应（TTA）场景，使得在无标签情况下也能有效检测模型性能退化点。

> **ai_Abstract:** 当部署的预测模型在测试时遇到数据漂移时，测试时自适应（TTA）方法能临时性地进行模型自适应。然而，TTA并非长久之计，模型最终会退化到需要重新训练的程度。为解决此问题，本文提出将TTA与风险监控框架相结合。该框架通过扩展基于序列检验和置信序列的现有工具，使其能在无标签的测试数据场景下监控模型性能，并在性能下降时发出警报，从而实现了对TTA的严格统计风险监控。实验证明了该框架在多种数据集、漂移类型和TTA方法上的有效性。

> **摘要翻译:** 部署预测模型时，在测试时遇到数据漂移是一个普遍存在的挑战。测试时自适应（TTA）方法通过仅使用未标记的测试数据持续自适应部署模型来解决这个问题。虽然TTA可以延长模型的寿命，但它只是一个临时解决方案。最终，模型可能会退化到必须下线并重新训练的程度。为了检测这些最终失效点，我们提出将TTA与风险监控框架配对，该框架跟踪预测性能并在违反预定义性能标准时发出警报。具体来说，我们扩展了基于置信序列的序列检验现有监控工具，以适应模型在测试时更新且没有测试标签可用于估计感兴趣的性能指标的场景。我们的扩展解锁了将严格的统计风险监控应用于TTA的可能性，并且我们在一系列代表性数据集、分布漂移类型和TTA方法上证明了我们提出的TTA监控框架的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [348] [Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration](https://arxiv.org/abs/2505.17621)
> *导航未知：通过内在动机引导的探索增强大型语言模型的推理能力*

*Jingtong Gao, Ling Pan, Yejing Wang, Rui Zhong, Chi Lu, Qingpeng Cai, Peng Jiang, Xiangyu Zhao* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型推理, 强化学习, 内在动机, 探索, 稀疏奖励

**Comment:** 

> **TL;DR:** i-MENTOR方法利用内在动机和引导探索，通过提供密集奖励和增强探索来改进大型语言模型的推理能力，解决了现有强化学习方法的稀疏奖励和探索不足问题，并在困难数据集上取得了显著提升。

**AI_Comments:** 这篇论文解决了将强化学习应用于大型语言模型推理时的一个重要挑战：稀疏奖励和探索不足。提出的 i-MENTOR 方法及其具体创新（轨迹感知奖励、动态缩放、优势保留）在提供更密集的反馈和鼓励发现新解决方案方面显得很有前景。在困难数据集上报告的显著改进是其潜力的有力证明。

<details>
  <summary>Details</summary>

**Motivation:** 现有的用于改进大型语言模型推理能力的强化学习方法（如 PPO 和 GRPO）受限于稀疏的基于结果的奖励和不足的探索机制，导致对多步推理过程的引导效率低下，特别是在解决挑战性问题时。稀疏奖励未能提供有效或足够的反馈，并引入了偏向利用熟悉轨迹而非发现新解决方案的系统性偏差，这严重阻碍了在复杂推理任务上的性能。

**Method:** 提出了一种名为 i-MENTOR（Intrinsic Motivation guidEd exploratioN meThOd foR LLM Reasoning）的新方法，旨在在基于强化学习的训练范式中同时提供密集奖励和增强探索。i-MENTOR 引入了三项关键创新：轨迹感知探索奖励（减轻令牌级别策略中的偏差，同时保持计算效率）；动态奖励缩放（稳定大动作空间中的探索和利用）；以及优势保留奖励实现（在结合探索性引导的同时保持优势分布的完整性）。

**Result:** 在三个公开数据集上进行的实验表明了 i-MENTOR 的有效性，在困难数据集 Countdown-4 上取得了 22.39% 的提升。

**Conclusion:** i-MENTOR 方法通过引入内在动机引导的探索，有效解决了现有强化学习方法在稀疏奖励和探索不足方面的限制，从而增强了大型语言模型的推理能力，并在具有挑战性的任务上带来了显著的性能提升。

> **ai_Abstract:** 本文针对现有强化学习方法在应用于大型语言模型推理时面临的稀疏奖励和探索不足问题，提出了一种名为 i-MENTOR 的新方法。i-MENTOR 通过引入轨迹感知探索奖励、动态奖励缩放和优势保留奖励实现等创新，旨在提供密集奖励并增强探索。实验结果表明，该方法有效提升了大型语言模型的推理性能，特别是在困难数据集上表现显著。

> **摘要翻译:** 强化学习（RL）已成为提高大型语言模型（LLM）推理能力的关键方法。然而，流行的 RL 方法，如近端策略优化（PPO）和组正则化策略优化（GRPO），由于依赖稀疏的基于结果的奖励和不足的探索激励机制，面临着严峻的限制。这些限制导致对多步推理过程的引导效率低下。具体而言，稀疏奖励信号未能提供有效或足够的反馈，特别是对于具有挑战性的问题。此外，这种奖励结构引入了系统性偏差，优先利用熟悉的轨迹而非发现新的解决方案。这些缺点严重阻碍了在复杂推理任务中的性能，而这些任务本身就需要对中间步骤进行迭代改进。为了解决这些挑战，我们提出了一种用于大型语言模型推理的内在动机引导探索方法（i-MENTOR），这是一种旨在在基于 RL 的训练范式中同时提供密集奖励和增强探索的新方法。i-MENTOR 引入了三项关键创新：轨迹感知探索奖励，可在减轻令牌级别策略中的偏差的同时保持计算效率；动态奖励缩放，可稳定大动作空间中的探索和利用；以及优势保留奖励实现，可在结合探索性引导的同时保持优势分布的完整性。在三个公开数据集上进行的实验表明了 i-MENTOR 的有效性，在困难数据集 Countdown-4 上取得了 22.39% 的提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [351] [PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN](https://arxiv.org/abs/2412.00994)
> *PIAD-SRNN：状态空间循环神经网络中的物理信息自适应分解*

*Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Rajiv Ramnath* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 时间序列预测, 物理信息, 状态空间RNN, 自适应分解, 室内空气质量

**Comment:** 

> **TL;DR:** PIAD-SRNN是一种新的物理信息自适应分解状态空间循环神经网络，它通过分离季节和趋势分量并将领域方程嵌入循环框架中，在时间序列预测中实现了精度和效率的平衡，并在室内空气质量数据集上超越了现有最佳模型。

**AI_Comments:** PIAD-SRNN的创新之处在于结合了物理信息、自适应分解和状态空间RNN，有效平衡了时间序列预测的准确性和效率。其在CO2浓度预测上的出色表现，以及提供高质量数据集，对实际应用和后续研究具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列预测在准确性和效率之间往往需要权衡。虽然Transformer模型提高了预测能力但计算成本高昂，而基于线性模型虽然准确性优于Transformer但仍未达到理想性能。

**Method:** 本文提出了PIAD-SRNN，一种物理信息自适应分解状态空间循环神经网络。该模型分离季节和趋势分量，并将领域方程嵌入循环框架中。

**Result:** PIAD-SRNN在室内空气质量数据集（特别是CO2浓度预测）上进行了评估，结果表明它在长期和短期时间序列预测中，在MSE和MAE方面均持续优于包括基于Transformer的架构在内的现有最佳模型。

**Conclusion:** PIAD-SRNN通过平衡准确性和效率，在时间序列预测任务中表现出色，特别是在室内空气质量CO2浓度预测方面，并提供了四个精选数据集。

> **ai_Abstract:** 本文提出PIAD-SRNN，一种新型物理信息自适应分解状态空间循环神经网络，旨在解决时间序列预测中准确性与效率的权衡问题。该模型通过分离季节和趋势分量并嵌入领域方程，在室内空气质量数据集（CO2浓度预测）上进行了评估。实验结果表明，PIAD-SRNN在长期和短期预测中，性能在MSE和MAE方面均优于包括Transformer在内的现有最佳模型。此外，该研究还提供了四个精选数据集。

> **摘要翻译:** 时间序列预测往往需要在准确性和效率之间进行权衡。虽然最近的Transformer模型提高了预测能力，但它们带来了高昂的计算成本。基于线性模型显示出比Transformer更好的准确性，但仍未达到理想性能。我们提出了PIAD-SRNN，一种物理信息自适应分解状态空间循环神经网络，它分离了季节和趋势分量，并将领域方程嵌入循环框架中。我们在室内空气质量数据集上评估了PIAD-SRNN的性能，重点关注不同预测范围内的CO2浓度预测，结果表明它在长期和短期时间序列预测中，包括基于Transformer的架构，在MSE和MAE方面均持续优于现有最佳模型。除了提出平衡准确性和效率的PIAD-SRNN之外，本文还提供了四个精选数据集。代码和数据：https://github.com/ahmad-shirazi/DSSRNN

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [354] [Data-Driven Dimensional Synthesis of Diverse Planar Four-bar Function Generation Mechanisms via Direct Parameterization](https://arxiv.org/abs/2507.08269)
> *数据驱动的多元平面四杆机构函数生成机制的尺寸综合通过直接参数化*

*Woon Ryong Kim, Jaeheun Jung, Jeong Un Ha, Donghun Lee, Jae Kyung Shim* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 数据驱动, 尺寸综合, 平面四杆机构, 监督学习, LSTM, 专家混合

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动框架，利用监督学习和LSTM-MoE神经网络，绕过传统方法，实现了平面四杆机构的尺寸综合，生成准确无缺陷的连杆机构，简化了机构设计。

**AI_Comments:** 该论文的创新点在于将数据驱动和深度学习（LSTM和MoE）应用于传统的运动学逆问题——平面四杆机构的尺寸综合，绕过了复杂的方程求解和优化过程。其优势在于提高了设计效率和易用性，使得非专业用户也能进行机构设计。MoE架构的设计允许处理不同类型的连杆机构，增强了方法的通用性。这为机械设计领域带来了新的范式，从传统的基于模型的分析转向基于数据的学习，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 平面四杆机构的尺寸综合是一个具有挑战性的运动学逆问题，需要根据期望的运动规格确定机构尺寸。传统方法涉及方程求解和优化，效率不高。

**Method:** 提出了一种数据驱动框架，通过监督学习绕过传统的方程求解和优化。该方法结合了合成数据集、基于LSTM的神经网络（用于处理顺序精度点）和针对不同连杆类型的专家混合（MoE）架构。每个专家模型都在特定类型的数据上进行训练，并由类型指定层引导，支持单类型和多类型综合。引入了一种新颖的仿真度量来通过比较期望和生成的运动来评估预测质量。

**Result:** 实验表明，该方法能够生成跨各种配置的准确、无缺陷的连杆机构。

**Conclusion:** 该方法实现了直观高效的机构设计，即使对于非专业用户也是如此，并为运动学设计中可扩展和灵活的综合开辟了新的可能性。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动框架，用于平面四杆机构的尺寸综合，旨在解决传统方法中方程求解和优化的高难度问题。该框架利用监督学习，结合合成数据集、基于LSTM的神经网络处理序列精度点，以及为不同连杆类型定制的专家混合（MoE）架构。该方法通过类型指定层实现单类型和多类型综合，并使用一种新的仿真度量评估预测质量。实验证明，该方法能生成准确、无缺陷的连杆机构，显著简化了机构设计流程，并为运动学设计提供了可扩展和灵活的解决方案。

> **摘要翻译:** 平面四杆机构的尺寸综合是运动学中一个具有挑战性的逆问题，需要根据期望的运动规格确定机构尺寸。我们提出了一种数据驱动框架，通过利用监督学习来绕过传统的方程求解和优化。我们的方法结合了合成数据集、基于LSTM的神经网络（用于处理顺序精度点）以及针对不同连杆类型的专家混合（MoE）架构。每个专家模型都在特定类型的数据上进行训练，并由类型指定层引导，从而实现单类型和多类型综合。一种新颖的仿真度量通过比较期望和生成的运动来评估预测质量。实验表明，我们的方法能够生成跨各种配置的准确、无缺陷的连杆机构。这使得机构设计变得直观高效，即使对于非专业用户也是如此，并为运动学设计中可扩展和灵活的综合开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [372] [Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning](https://arxiv.org/abs/2505.24360)
> *使用字典学习解释大型文本到图像扩散模型*

*Stepan Shabalin, Ayush Panda, Dmitrii Kharlapenko, Abdur Raheem Ali, Yixiong Hao, Arthur Conmy* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 稀疏自编码器, 字典学习, 文本到图像扩散模型, 模型解释, 激活分解

**Comment:** 10 pages, 10 figures, Mechanistic Interpretability for Vision at CVPR
  2025

> **TL;DR:** 本文将稀疏自编码器（SAE）和推理时激活分解（ITDA）应用于大型文本到图像扩散模型（Flux 1），以提高模型的可解释性并实现图像生成控制。研究发现SAE能准确重建嵌入并优于MLP神经元的可解释性，ITDA也具有可比性。

**AI_Comments:** 本文创新性地将稀疏自编码器（SAE）和推理时激活分解（ITDA）应用于大型文本到图像扩散模型，解决了大型模型可解释性差的挑战。其通过视觉自动化解释管道评估可解释性的方法值得关注。能够使用SAE特征引导图像生成，展示了这些解释工具在模型控制方面的潜力。这项工作为理解和操纵复杂生成模型提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏自编码器（SAE）在分解语言模型激活方面显示出巨大潜力，已成功应用于视觉Transformer和小型扩散模型。本文旨在将这些方法扩展到大型文本到图像扩散模型，以实现对模型内部机制的解释和控制。

**Method:** 本文将稀疏自编码器（SAE）和推理时激活分解（ITDA）应用于大型文本到图像扩散模型Flux 1。为了评估可解释性，引入了一个视觉自动化解释管道。研究还通过激活添加来探索使用SAE特征引导图像生成的能力。

**Result:** 研究发现稀疏自编码器（SAE）能够准确重建残差流嵌入，并且在可解释性方面优于多层感知器（MLP）神经元。此外，SAE特征能够通过激活添加来引导图像生成。推理时激活分解（ITDA）也表现出与SAE相当的可解释性。

**Conclusion:** 稀疏自编码器（SAE）和推理时激活分解（ITDA）是解释大型文本到图像扩散模型激活的有效方法，它们不仅能提高模型的可解释性，还能实现对图像生成过程的控制。

> **ai_Abstract:** 本文研究了使用稀疏自编码器（SAE）和推理时激活分解（ITDA）来解释和控制大型文本到图像扩散模型（Flux 1）。研究通过引入视觉自动化解释管道，评估了这些方法在模型嵌入可解释性方面的表现。结果表明，SAE能够准确重建残差流嵌入，并在可解释性上超越了MLP神经元，同时能够通过特征激活引导图像生成。ITDA也展现出与SAE相当的可解释性。

> **摘要翻译:** 稀疏自编码器是一种有前途的新方法，用于分解语言模型激活以进行解释和控制。它们已成功应用于视觉Transformer图像编码器和小型扩散模型。推理时激活分解（ITDA）是最近提出的一种字典学习变体，它将字典视为来自激活分布的一组数据点，并通过梯度追踪重建它们。我们将稀疏自编码器（SAE）和ITDA应用于一个大型文本到图像扩散模型Flux 1，并通过引入视觉自动化解释管道来考虑两者嵌入的可解释性。我们发现SAE准确重建了残差流嵌入，并在可解释性方面优于MLP神经元。我们能够使用SAE特征通过激活添加来引导图像生成。我们发现ITDA具有与SAE相当的可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [378] [Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling](https://arxiv.org/abs/2507.08736)
> *灾难性遗忘缓解通过高原期活动剖析*

*Idan Mashiach, Oren Glickman, Tom Tirer* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 灾难性遗忘, 正则化, 高原期, 参数活动, 深度学习

**Comment:** 

> **TL;DR:** 提出一种新颖的方法，通过监测深度学习模型在训练高原期的参数活动来缓解灾难性遗忘，以更好地平衡新旧任务性能。

**AI_Comments:** 该论文的创新点在于提出了一个新颖的视角，即关注深度学习模型训练末期的“高原期”参数活动，而不是整个训练过程。这种方法利用了损失景观的特性，通过识别平坦区域的参数来更好地平衡知识保留和新任务适应，为灾难性遗忘的缓解提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在学习新任务时，会因为知识覆盖而导致在先前学习任务上的性能下降，即灾难性遗忘。

**Method:** 本文提出一种新颖的视角：在深度学习高度非凸的优化景观中，通过跟踪训练最终高原期的参数比在整个训练过程中监测参数更有效。论证在高原期表现出更高活跃度（移动和变异性）的参数揭示了损失景观中相对平坦的方向，使其适合适应新任务，同时保留先前任务的知识。

**Result:** 全面实验表明，该方法在平衡灾难性遗忘缓解与新学习任务的强大性能方面取得了卓越的性能。

**Conclusion:** 通过在训练高原期分析参数活动来识别适合适应新任务的参数，能够有效缓解深度神经网络中的灾难性遗忘问题，并保持新任务的良好性能。

> **ai_Abstract:** 本文提出一种新颖的灾难性遗忘缓解方法，通过在深度神经网络训练的最终高原期跟踪参数活动来识别适合适应新任务的“重要”参数。研究发现，在高原期活跃度高的参数指向损失景观中的平坦区域，有助于在学习新任务时保留旧知识。实验证明，该方法在缓解灾难性遗忘和保持新任务性能之间取得了卓越平衡。

> **摘要翻译:** 深度神经网络中的灾难性遗忘发生在学习新任务时，由于知识覆盖而导致先前学习任务的性能下降。在缓解此问题的方法中，正则化技术旨在识别和约束“重要”参数以保留先前知识。在深度学习高度非凸的优化景观中，我们提出了一种新颖的视角：在最终训练高原期跟踪参数比在整个训练过程中监测参数更有效。我们认为，在此高原期表现出更高活跃度（移动和变异性）的参数揭示了损失景观中相对平坦的方向，使其适合适应新任务，同时保留先前任务的知识。我们的全面实验表明，该方法在平衡灾难性遗忘缓解与新学习任务的强大性能方面取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [382] [Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks](https://arxiv.org/abs/2506.06489)
> *交替梯度流：双层神经网络中的特征学习理论*

*Daniel Kunin, Giovanni Luca Marchetti, Feng Chen, Dhruva Karkada, James B. Simon, Michael R. DeWeese, Surya Ganguli, Nina Miolane* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 特征学习, 交替梯度流, 双层神经网络, 梯度流, 训练动态

**Comment:** 39 pages, 7 figures

> **TL;DR:** 本文提出了一种名为交替梯度流（AGF）的算法框架，用于解释双层神经网络如何通过交替激活休眠神经元和优化活动神经元来学习特征，该框架与实验结果一致，并统一了先前的分析。

**AI_Comments:** 该研究引入了一个新颖的算法框架（AGF），为理解特定类别（双层）神经网络的特征学习动态提供了一个理论视角。其优势在于统一和扩展了先前的分析，并提供了与经验观察一致的量化预测。一个潜在的局限性是目前仅关注双层网络，未来的工作可以探索其在更深层网络中的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 理解神经网络学习哪些特征以及如何学习特征仍然是一个悬而未决的问题。

**Method:** 提出交替梯度流（AGF）框架，该框架将特征学习动态近似为一个交替的两步过程：最大化休眠神经元的效用函数，并最小化活动神经元的成本函数。

**Result:** AGF量化了损失下降的顺序、时间和幅度，与实验结果一致。它统一并扩展了全连接线性网络和仅注意力线性Transformer中的鞍点分析。在对角线性网络中，AGF在消失初始化的极限下收敛于梯度流。在二次网络中，AGF揭示了网络按系数幅度递减的顺序学习傅立叶特征。

**Conclusion:** AGF为理解神经网络中的特征学习提供了一个有前途的步骤。

> **ai_Abstract:** 本文提出了交替梯度流（AGF）框架，用于解释双层神经网络的特征学习机制。AGF将学习过程建模为休眠神经元激活和活动神经元优化的交替过程，该模型成功匹配了实验数据，并统一了先前在不同线性网络模型上的理论分析，为理解神经网络特征学习提供了新视角。

> **摘要翻译:** 神经网络学习哪些特征以及如何学习，仍然是一个悬而未决的问题。在本文中，我们引入了交替梯度流（AGF），这是一个描述从小的初始化训练的双层网络中特征学习动态的算法框架。先前的工作表明，在这种情况下，梯度流表现出类似阶梯状的损失曲线，在神经元缓慢对齐到有用方向的平台期和神经元快速增长范数的急剧下降之间交替。AGF将这种行为近似为一个交替的两步过程：最大化休眠神经元的效用函数，并最小化活动神经元的成本函数。AGF从所有神经元休眠开始。在每个回合中，一个休眠神经元被激活，触发特征的获取和损失的下降。AGF量化了这些下降的顺序、时间和幅度，与跨架构的实验相匹配。我们表明，AGF统一并扩展了全连接线性网络和仅注意力线性Transformer中现有的鞍点分析，其中学习的特征分别是奇异模式和主成分。在对角线性网络中，我们证明了AGF在消失初始化的极限下收敛于梯度流。将AGF应用于为执行模加训练的二次网络，我们给出了训练动态的第一个完整表征，揭示了网络以系数幅度递减的顺序学习傅立叶特征。总而言之，AGF为理解神经网络中的特征学习提供了一个有前途的步骤。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [386] [Field Matching: an Electrostatic Paradigm to Generate and Transfer Data](https://arxiv.org/abs/2502.02367)
> *场匹配：一种生成和传输数据的静电范式*

*Alexander Kolesov, Manukhov Stepan, Vladimir V. Palyulin, Alexander Korotin* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 静电场匹配, 生成建模, 分布迁移, 神经网络, 电容器

**Comment:** Proceedings of the 42nd International Conference on Machine.
  Learning, Vancouver, Canada. PMLR 267, 2025

> **TL;DR:** 提出了一种名为静电场匹配（EFM）的新方法，该方法借鉴了电容器的物理原理，可用于生成建模和分布迁移任务。通过将源分布和目标分布置于电容器的极板上并赋予它们相反的电荷，然后利用神经网络逼近电容器的静电场。通过沿着学习到的静电场线移动样本，可以实现分布之间的映射和迁移。

**AI_Comments:** 该方法将物理学原理（电容器的静电场）应用于机器学习中的生成建模和分布迁移任务，具有创新性。理论上的证明和实验验证增加了该方法的可靠性。然而，其在处理高维数据或复杂分布时的扩展性和效率仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种适用于生成建模和分布迁移任务的新方法。

**Method:** 提出静电场匹配（EFM）方法，该方法将源分布和目标分布置于电容器极板上，并赋予它们相反电荷。使用神经网络学习电容器的静电场，并通过沿着学习到的静电场线移动样本来实现分布之间的映射。

**Result:** 在玩具和图像数据实验中证明了EFM的性能。

**Conclusion:** EFM方法在理论上保证了分布迁移的有效性，并在实践中得到了验证。

> **ai_Abstract:** 静电场匹配（EFM）是一种新颖的生成建模和分布迁移方法，其灵感来源于电容器的物理原理。该方法通过将源分布和目标分布视为带有相反电荷的电容器极板，并利用神经网络学习其静电场来工作。通过沿着学习到的电场线移动样本，可以实现分布之间的映射和迁移。该方法在理论上得到了证明，并在实验中得到了验证。

> **摘要翻译:** 我们提出了一种新颖的方法，称为静电场匹配（EFM），该方法适用于生成建模和分布迁移任务。我们的方法受到电容器物理学的启发。我们将源分布和目标分布放置在电容器的极板上，并分别赋予它们正电荷和负电荷。然后，我们使用神经网络逼近器学习电容器的静电场。为了将分布相互映射，我们从电容器的一个极板开始，沿着学习到的静电场线移动样本，直到它们到达另一个极板。我们从理论上证明，这种方法可以保证实现分布迁移。在实践中，我们在玩具和图像数据实验中证明了EFM的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training](https://arxiv.org/abs/2507.08284)
> *轻量级安全护栏通过合成数据和强化学习指导的对抗性训练*

*Aleksei Ilin, Gor Matevosyan, Xueying Ma, Vladimir Eremin, Suhaa Dada, Muqun Li, Riyaaz Shaik, Haluk Noyan Tokgozoglu* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 安全护栏, 合成数据, 对抗性训练, 小型语言模型, 内容审核

**Comment:** 

> **TL;DR:** 该研究提出了一种轻量级的安全护栏框架，利用合成数据和强化学习指导的对抗性训练，使小型语言模型在内容审核任务中表现优于大型模型，降低了计算开销并提高了对攻击的抵御能力。

**AI_Comments:** 该研究在轻量级安全护栏方面取得了重要进展，通过合成数据和强化学习指导的对抗性训练，有效提升了小型语言模型的性能。其创新之处在于利用生成对抗网络（GAN）的思路来指导训练过程，并结合了高效LLM训练的策略。然而，需要进一步研究该方法在处理更复杂、更隐蔽的有害内容时的鲁棒性，以及合成数据生成过程的计算成本和可控性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在内容审核中存在计算开销大和易受攻击的问题，需要更轻量级、更具韧性的解决方案。

**Method:** 通过查询增强和释义生成高保真合成数据，并采用受GAN启发的强化学习指导生成器产生具有挑战性的合成样本，用于微调安全分类器，以提升其检测和缓解有害内容的能力。同时，利用小型模型的能力来改进大型生成模型的性能。

**Result:** 小型语言模型通过该框架在内容审核任务中达到了甚至超越了大型模型的性能。

**Conclusion:** 该框架通过合成数据和强化学习指导的对抗性训练，使小型语言模型能够作为强大的安全护栏，有效降低了计算开销，提高了对攻击的韧性，为内容审核提供了一种可扩展且高效的解决方案。

> **ai_Abstract:** 本研究提出了一种新颖的轻量级安全护栏框架，利用高保真的合成数据生成和强化学习指导的对抗性训练，使小型语言模型（SLMs）在内容审核任务中取得了卓越的性能，甚至超越了大型模型。该方法通过迭代优化，提高了模型对有害内容的检测和缓解能力，同时降低了计算成本并增强了对恶意攻击的抵抗力，为AI内容审核提供了一种高效且可扩展的解决方案。

> **摘要翻译:** 我们为语言模型引入了一个轻量级但高效的安全护栏框架，证明了小型语言模型在内容审核任务中能够达到甚至超越大型模型的性能。这是通过高保真的合成数据生成和对抗性训练实现的。合成数据生成过程以人类精心策划的种子数据开始，经过查询增强和释义，以创建多样化且具有丰富上下文的示例。然后对这些增强的数据进行多轮策划，以确保高保真度和相关性。受生成对抗网络（GAN）架构的最新进展的启发，我们的对抗性训练采用了强化学习来指导生成器生成具有挑战性的合成示例。这些示例用于微调安全分类器，增强其检测和缓解有害内容的能力。此外，我们还借鉴了近期关于高效语言模型训练的研究策略，利用小型模型的优势来提升大型生成模型的性能。通过迭代对抗性训练和生成多样化、高质量的合成数据，我们的框架使小型语言模型（SLMs）能够充当强大的安全护栏。这种方法不仅降低了计算开销，还提高了对对抗性攻击的韧性，为人工智能系统中的内容审核提供了一种可扩展且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [390] [Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series](https://arxiv.org/abs/2507.08738)
> *自适应非线性向量自回归：嘈杂混沌时间序列的鲁棒预测*

*Azimov Sherkhon, Susana Lopez-Moreno, Eric Dolores-Cuenca, Sieun Lee, Sangil Kim* | **Category: cs.LG, cs.AI, math.DS, 68T07, 37M10, 00A79, 37M22, 65P20** | **Updated: 2025-07-11**

**Keywords:** 自适应NVAR, 水库计算, 混沌时间序列, 鲁棒预测, 多层感知器

**Comment:** 15 pages, 10 figures

> **TL;DR:** 提出了一种自适应非线性向量自回归模型，结合了延迟嵌入线性输入和浅层可学习多层感知器（MLP）生成的特征，以实现对嘈杂混沌时间序列的鲁棒预测，优于标准的NVAR。

**AI_Comments:** 该研究提出了一种新颖的自适应NVAR模型，通过集成MLP来学习非线性特征，解决了现有NVAR和RC方法在噪声和高维数据下的适应性和可扩展性问题。实验结果显示出其优越性，但可能需要进一步评估模型在更复杂、真实世界数据集上的性能以及超参数调优的敏感性。

<details>
  <summary>Details</summary>

**Motivation:** 标准的非线性向量自回归（NVAR）和水库计算（RC）在预测混沌动力学系统方面表现出潜力，但它们依赖于固定的非线性，限制了它们在高噪声或真实世界数据中的适应性，并且在高维设置中扩展性差。

**Method:** 提出了一种自适应NVAR模型，该模型将延迟嵌入的线性输入与浅层、可学习的多层感知器（MLP）生成的特征相结合。MLP和线性读出通过基于梯度的优化进行联合训练。

**Result:** 该自适应模型在无噪声和合成噪声条件下的混沌系统上的初步实验表明，其预测精度优于标准NVAR，并且在较低的观测频率下对噪声具有鲁棒的预测能力。

**Conclusion:** 提出的自适应NVAR模型通过学习数据驱动的非线性，克服了标准NVAR在适应性和可扩展性方面的局限性，并在噪声和低观测频率条件下实现了鲁棒的预测。

> **ai_Abstract:** 本研究提出了一种自适应非线性向量自回归（NVAR）模型，通过结合延迟嵌入的线性输入和多层感知器（MLP）学习的特征，解决了标准NVAR和水库计算（RC）在处理高噪声和高维混沌时间序列时的局限性。该模型通过联合训练MLP和线性读出，能够学习数据驱动的非线性，并提高了对噪声的鲁棒性和可扩展性，优于传统方法。

> **摘要翻译:** 非线性向量自回归（NVAR）和水库计算（RC）在预测混沌动力学系统方面已显示出潜力，例如洛伦兹-63模型和厄尔尼诺-南方涛动。然而，它们依赖于固定的非线性——NVAR中的多项式展开或RC中的随机特征映射——限制了它们在高噪声或真实世界数据中的适应性。这些方法在高维设置中的扩展性也很差，因为在读出计算过程中需要进行昂贵的矩阵求逆。我们提出了一种自适应NVAR模型，该模型将延迟嵌入的线性输入与通过浅层、可学习的多层感知器（MLP）生成的特征相结合。MLP和线性读出通过基于梯度的优化进行联合训练，使模型能够学习数据驱动的非线性，同时保持简单的读出结构。与标准的NVAR不同，我们的方法避免了对Ridge和延迟参数进行详尽且敏感的网格搜索的需要。相反，调优仅限于神经网络的超参数，提高了可扩展性。在无噪声和合成噪声条件下测试的混沌系统上的初步实验表明，自适应模型在预测精度上优于标准NVAR，并且在较低的观测频率下对噪声表现出鲁棒的预测能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [395] [Partitioned Hybrid Quantum Fourier Neural Operators for Scientific Quantum Machine Learning](https://arxiv.org/abs/2507.08746)
> *用于科学量子机器学习的划分混合量子傅里叶神经网络算子*

*Paolo Marcandelli, Yuanchun He, Stefano Mariani, Martina Siena, Stefano Markidis* | **Category: cs.LG, quant-ph** | **Updated: 2025-07-11**

**Keywords:** 量子傅里叶神经网络算子, 混合量子计算, 科学机器学习, 纳维-斯托克斯方程, 分布式计算

**Comment:** 

> **TL;DR:** PHQFNO是一种新的混合量子机器学习模型，它将傅里叶算子计算分布在经典和量子设备上，适用于高维数据和科学机器学习任务，如求解纳维-斯托克斯方程，并且在某些情况下比经典模型表现更好。

**AI_Comments:** 该研究提出了PHQFNO，一种在科学机器学习领域具有潜力的创新模型，通过混合量子-经典计算和分布式处理能力，有望解决现有模型在高维数据和大规模计算任务中的挑战。然而，实际的硬件实现和可扩展性仍是未来研究的重点。

<details>
  <summary>Details</summary>

**Motivation:** 为了推广量子傅里叶神经网络算子（QFNO）在科学机器学习中的应用，并解决其在高维数据和分布式计算方面的局限性。

**Method:** PHQFNO将傅里叶算子计算划分为经典和量子资源，实现了可调的量子-经典混合以及跨量子和经典设备的分布式执行。该方法支持高维数据，并引入了消息传递框架来分布式数据。输入数据使用一元编码编码为量子态，量子电路参数使用变分方案进行优化。

**Result:** PHQFNO在伯格斯方程和纳维-斯托克斯方程（包括不可压缩和可压缩）上进行了评估，恢复了经典FNO的准确性，并在不可压缩纳维-斯托克斯方程上实现了比经典模型更高的准确性。此外，PHQFNO在输入噪声下的敏感性分析显示出比经典基线模型更强的稳定性。

**Conclusion:** PHQFNO是一种通用且高效的混合量子机器学习方法，能够处理高维数据和分布式计算，并在科学机器学习任务中展现出优于经典方法的潜力。

> **ai_Abstract:** 本文介绍了一种名为PHQFNO的新型混合量子机器学习模型，它改进了现有的QFNO模型，能够将计算任务分配到量子和经典资源上，从而实现分布式计算和可调的量子-经典混合。该模型支持高维数据，并通过消息传递框架进行数据分发。通过在伯格斯方程和纳维-斯托克斯方程上的实验，PHQFNO被证明能够达到与经典模型相当或更高的精度，并且在噪声环境下表现出更强的鲁棒性。

> **摘要翻译:** 我们为科学机器学习引入了划分混合量子傅里叶神经网络算子（PHQFNO），它是量子傅里叶神经网络算子（QFNO）的泛化。PHQFNO将傅里叶算子计算划分到经典和量子资源中，实现了可调的量子-经典混合以及跨量子和经典设备的分布式执行。该方法将QFNO扩展到更高维度，并结合了消息传递框架以在不同分区之间分发数据。输入数据使用一元编码被编码到量子态中，量子电路参数使用变分方案进行优化。我们使用集成了PyTorch的PennyLane实现了PHQFNO，并在伯格斯方程、不可压缩和可压缩纳维-斯托克斯方程上进行了评估。我们表明PHQFNO恢复了经典的FNO准确性。在不可压缩纳维-斯托克斯方程上，PHQFNO实现了比其经典对应物更高的准确性。最后，我们在输入噪声下进行了敏感性分析，证实了PHQFNO相比经典基线模型具有更高的稳定性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [397] [Exploring Efficient Quantification of Modeling Uncertainties with Differentiable Physics-Informed Machine Learning Architectures](https://arxiv.org/abs/2506.18247)
> *探索具有可微分物理信息机器学习架构的建模不确定性的有效量化*

*Manaswin Oddiraju, Bharath Varma Penumatsa, Divyang Amin, Michael Piedmonte, Souma Chowdhury* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 物理信息机器学习, 贝叶斯神经网络, 不确定性量化, 自动可微分, 概率模型

**Comment:** Accepted for presentation in proceedings of ASME IDETC 2025

> **TL;DR:** 本研究将贝叶斯神经网络（BNN）与物理信息机器学习（PIML）相结合，以量化和传播建模不确定性。结果表明，这种混合架构在分析基准问题和飞行实验数据上表现良好，性能与纯数据驱动模型相当或略差，而蒙特卡洛采样被证明是传播不确定性的最有效方法。

**AI_Comments:** 该研究将BNN的概率建模能力与PIML的物理约束相结合，为不确定性量化提供了一种新颖的方法。然而，与现有模型相比，预测性能的提升有限，这可能需要进一步的研究来优化架构和训练策略。

<details>
  <summary>Details</summary>

**Motivation:** 量化和传播建模不确定性对于工程设计和控制中的可靠性分析、鲁棒优化等至关重要。虽然PIML方法在计算效率、建模准确性和可解释性方面提供了优势，但其预测和传播不确定性的能力仍未得到充分探索。

**Method:** 将结合了部分物理知识和神经网络（用于输入转换或自适应参数估计）的可微分混合PIML架构与贝叶斯神经网络（BNN）相结合，以探索BNN在PIML架构中提供不确定性传播能力的可能性。采用两阶段训练过程来解决概率机器学习模型的训练挑战。

**Result:** 将BNN集成到PIML架构中，在分析基准问题和固定翼RC飞机飞行实验数据上的预测性能与纯数据驱动的机器学习和原始PIML模型相当或略差。通过蒙特卡洛采样BNN权重被发现是传播BNN集成PIML架构中不确定性的最有效方法。

**Conclusion:** 将BNN集成到可微分PIML架构中是一种有前途的方法，可以量化和传播建模不确定性，并且通过蒙特卡洛采样可以有效地实现不确定性传播，尽管其预测性能可能与现有模型相当或略有不足。

> **ai_Abstract:** 本研究提出了一种将贝叶斯神经网络（BNN）集成到可微分物理信息机器学习（PIML）架构中的新方法，旨在解决工程设计和控制中建模不确定性的量化和传播问题。通过结合物理知识和神经网络，并采用两阶段训练过程，该混合模型在分析和实际飞行数据上进行了评估。结果显示，该方法在不确定性传播方面表现出潜力，尽管预测性能与现有模型相当或略有不足，但蒙特卡洛采样被证明是传播不确定性的有效手段。

> **摘要翻译:** 量化和传播建模不确定性对于工程设计和控制中的可靠性分析、鲁棒优化以及其他基于模型的算法过程至关重要。近年来，物理信息机器学习（PIML）方法已成为传统计算建模和代理建模方法的新替代方案，在计算效率、建模准确性和可解释性之间取得了平衡。然而，它们在预测和传播建模不确定性方面的能力在很大程度上仍未得到探索。在本文中，一类有前途的自动可微分混合PIML架构，该架构结合了部分物理知识和神经网络（用于输入转换或自适应参数估计），并与贝叶斯神经网络（取代了人工神经网络）相结合；这样做是为了探索BNN是否也能成功地为PIML架构提供不确定性传播能力，并且这些架构具有自动可微分的特点。采用两阶段训练过程来缓解传统上在训练概率ML模型时遇到的挑战。将BNN集成的PIML架构在分析基准问题和固定翼RC飞机上的飞行实验数据进行了评估，观察到的预测性能与纯数据驱动的ML和原始PIML模型相比略差或相当。此外，研究发现，通过蒙特卡洛采样概率性BNN权重是传播BNN集成PIML架构中不确定性最有效的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [412] [Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks](https://arxiv.org/abs/2506.19703)
> *基于学习的二分图匹配方法在耦合的道路交通网络中修复受损电网的多船员*

*Nathan Maurer, Harshal Kaushik, Roshni Anna Jacob, Jie Zhang, Souma Chowdhury* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 图强化学习,二分图匹配,电力网络恢复,交通网络,组合优化

**Comment:** Accepted for presentation in proceedings of ASME IDETC 2025

> **TL;DR:** 本研究提出了一种结合图强化学习和二分图匹配的新方法，用于优化受损电力网络的多船员修复计划，同时考虑了道路交通网络。该方法通过学习激励函数来分配船员，并在模拟环境中进行了测试，结果显示其性能优于随机策略和基于优化的解决方案。

**AI_Comments:** 该研究提出了一种创新的方法，将图论、强化学习和组合优化相结合，以解决关键基础设施恢复中的复杂问题。将GRL与二分图匹配相结合以学习激励函数是一个值得注意的贡献，它提高了规划的效率和泛化能力。然而，实际部署可能还需要考虑更多现实世界的约束和不确定性。

<details>
  <summary>Details</summary>

**Motivation:** 在自然灾害等干扰后，关键基础设施网络（如电力网络）的恢复速度和功能恢复程度对其韧性至关重要。为修复分配资源是一个组合优化问题，需要确定由哪个船员、修复哪些节点以及修复顺序。

**Method:** 提出了一种新颖的基于图的公式，将代表船员和交通节点的图与代表电网节点的图合并为一个单一的异构图。为了实现高效的规划，将图强化学习（GRL）与二分图匹配相结合。GRL用于设计基于环境的图抽象状态的激励函数，以实现跨不同损坏场景的泛化。采用了两种学习技术：一种使用近端策略优化（PPO）训练的图神经网络（GNN），另一种通过神经进化训练的GNN。学习到的激励函数用于指导一个连接船员和修复任务的二分图，从而实现加权最大匹配以进行船员到任务的分配。使用了一个预先计算了最优节点到节点路径计划的模拟环境来训练所提出的修复规划方法。

**Result:** 所提出的方法在各种场景下都表现出了良好的泛化能力和可扩展性。学习到的策略相比随机策略提供了3倍的性能提升，并且在计算时间和恢复的电力方面均优于基于优化的解决方案（计算时间快几个数量级）。

**Conclusion:** 本研究提出的基于学习的二分图匹配方法在处理受损电力网络的恢复规划方面是有效且高效的，它能够实现比现有方法更好的性能，并具有良好的泛化能力和可扩展性。

> **ai_Abstract:** 本研究提出了一种新颖的基于图的恢复规划方法，该方法将电力网络和道路交通网络表示为异构图，并结合图强化学习（GRL）和二分图匹配来优化多船员修复任务的分配。通过使用图神经网络和神经进化学习激励函数，该方法能够有效地将船员分配给修复任务，并在模拟研究中显示出优于随机策略和传统优化方法的性能，尤其在计算效率和恢复的电力方面表现突出。

> **摘要翻译:** 关键基础设施网络（CINs）在遭受自然灾害等破坏后的恢复能力，取决于恢复的速度以及恢复运营功能到何种程度。为恢复分配资源是一个组合优化规划问题，涉及确定哪些船员将修复特定的网络节点以及修复的顺序。本文提出了一种新颖的基于图的公式，该公式将代表船员和交通节点的两个相互关联的图与代表电网节点的图合并为一个单一的异构图。为了实现高效的规划，图强化学习（GRL）与二分图匹配相结合。GRL用于设计激励函数，根据环境的图抽象状态将船员分配给修复任务，确保了跨不同损坏场景的泛化能力。采用了两种学习技术：一种是使用近端策略优化（Proximal Policy Optimization）训练的图神经网络，另一种是通过神经进化（Neuroevolution）训练的。学习到的激励函数为连接船员和修复任务的二分图提供了信息，从而实现了加权最大匹配以进行船员到任务的分配。使用了一个预先计算了最优节点到节点路径计划的有效模拟环境来训练所提出的恢复规划方法。以IEEE 8500节点电力分配测试网络结合一个21平方公里的交通网络作为案例研究，场景在损坏节点的数量、仓库和船员的数量方面有所不同。结果表明，该方法在不同场景下的泛化能力和可扩展性得到了证明，学习到的策略相比随机策略提供了3倍的性能提升，并且在计算时间和恢复的电力方面均优于基于优化的解决方案（计算时间快几个数量级）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [413] [An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis](https://arxiv.org/abs/2507.08050)
> *一种增强的保护隐私的联邦少样本学习框架用于呼吸系统疾病诊断*

*Ming Wang, Zhaoyang Duan, Dong Xue, Fangzhou Liu, Zhongheng Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 联邦学习, 少样本学习, 差分隐私, 呼吸系统疾病诊断, 隐私保护

**Comment:** 

> **TL;DR:** 该研究提出了一种结合联邦学习、少样本学习和差分隐私的框架，用于解决呼吸系统疾病诊断中数据稀疏和隐私保护问题。通过元随机梯度下降算法缓解过拟合，并引入差分隐私噪声保护数据。加权平均算法用于聚合模型，实验证明该方法在不同数据分布下均能有效诊断呼吸系统疾病。

**AI_Comments:** 该研究提出的框架在解决医疗领域数据稀疏和隐私保护问题方面具有重要意义。通过结合联邦学习、少样本学习和差分隐私技术，该方法能够有效地利用分散的医疗数据进行疾病诊断，同时保护患者隐私。元随机梯度下降算法的引入有助于提高模型在数据量有限情况下的性能。然而，差分隐私的引入可能会对模型精度产生一定影响，这需要进一步的权衡和优化。此外，框架在不同医疗机构间的实际部署和推广也可能面临挑战。

<details>
  <summary>Details</summary>

**Motivation:** 医疗数据标注耗时耗力，导致资源受限环境下高质量标记数据集稀缺，且患者隐私问题阻碍了跨机构的本地医疗数据共享。现有的集中式数据驱动方法依赖大量数据且常损害隐私。

**Method:** 提出了一种包含隐私保护机制的联邦少样本学习框架。具体来说，采用元随机梯度下降算法来缓解数据不足时的过拟合问题，并集成差分隐私噪声以防止梯度泄露和图像重构。使用加权平均算法聚合本地模型。

**Result:** 实验结果表明，所提出的方法在实施差分隐私的同时取得了令人信服的结果，并能有效诊断来自不同结构、类别和分布的呼吸系统疾病数据。

**Conclusion:** 所提出的联邦少样本学习框架通过元随机梯度下降和差分隐私技术，有效解决了呼吸系统疾病诊断中的数据稀疏和隐私保护挑战，并在不同数据条件下实现了有效的诊断。

> **ai_Abstract:** 该研究提出了一个创新的联邦少样本学习框架，旨在解决呼吸系统疾病诊断中的关键挑战：数据稀疏和隐私保护。通过引入元随机梯度下降算法来应对数据不足导致的过拟合问题，并利用差分隐私技术保护敏感的医疗数据免遭梯度泄露。此外，该框架采用加权平均算法聚合来自不同机构的模型，提高了模型的泛化能力和适应性。实验证明，该方法在不同数据分布下均能有效诊断呼吸系统疾病，并在保护隐私的同时取得了优异的性能。

> **摘要翻译:** 医疗数据标注的劳动密集型特性给呼吸系统疾病诊断带来了重大挑战，导致在资源受限的环境中高质量标记数据集稀缺。此外，患者隐私问题使得跨机构直接共享本地医疗数据复杂化，而依赖大量可用数据的现有集中式数据驱动方法，常常会损害数据隐私。本研究提出了一个具有隐私保护机制的联邦少样本学习框架，以解决呼吸系统疾病诊断中标记数据有限和隐私保护的问题。具体而言，提出了一种元随机梯度下降算法，以减轻在采用传统梯度下降方法进行神经网络训练时，由于数据不足而引起的过拟合问题。此外，为了确保数据隐私免受梯度泄露的影响，在利用本地数据训练私有模型时，将标准高斯分布的差分隐私噪声集成到梯度中，从而防止医疗图像的重构。鉴于分散在不同医疗机构的呼吸系统疾病数据集中化的不切实际性，采用加权平均算法来聚合不同客户端的本地诊断模型，增强了模型在多种场景下的适应性。实验结果表明，所提出的方法在实施差分隐私的同时取得了令人信服的结果，并能有效诊断来自不同结构、类别和分布的呼吸系统疾病数据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [414] [CAS Condensed and Accelerated Silhouette: An Efficient Method for Determining the Optimal K in K-Means Clustering](https://arxiv.org/abs/2507.08311)
> *CAS 凝结与加速轮廓系数：一种确定 K-Means 聚类中最佳 K 值的有效方法*

*Krishnendu Das, Sumit Gupta, Awadhesh Kumar* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** K-Means 聚类, K 值选择, 轮廓系数, 计算效率, 高维数据

**Comment:** 

> **TL;DR:** 该研究提出了一种名为 CAS (Condensed and Accelerated Silhouette) 的新方法，用于优化 K-Means 聚类中的 K 值选择。该方法结合了凝结轮廓系数法和多种统计方法，能在保证聚类精度的同时，显著提高计算效率，特别是在处理高维数据集时，速度提升高达 99%，适用于实时聚类和资源受限的场景。

**AI_Comments:** 这项研究提出了一种非常有前景的方法来解决 K-Means 聚类中的一个关键挑战：确定最佳的 K 值。CAS 方法通过结合凝结轮廓系数和多种统计技术，在速度和精度之间取得了良好的平衡，尤其是在处理高维数据集方面表现出色。其高达 99% 的速度提升潜力使其在需要实时处理或资源受限的应用中具有显著优势。然而，对于该方法在不同类型数据（如低维数据或具有复杂形状的数据集）上的泛化能力和鲁棒性还需要进一步的评估。

<details>
  <summary>Details</summary>

**Motivation:** 聚类在数据驱动的环境中至关重要，但其在大数据集上的准确性仍然是一个挑战。需要一种能够平衡聚类精度和计算效率的方法来选择最佳的 K 值。

**Method:** 提出了一种基于凝结轮廓系数法 (Condensed Silhouette) 的方法，并结合了局部结构 (Local Structures)、间隙统计量 (Gap Statistics)、类一致性比率 (Class Consistency Ratio) 以及基于聚类重叠指数 (Cluster Overlap Index CCR and COI) 的算法来计算 K-Means 聚类中的最佳 K 值。

**Result:** 与现有方法进行比较的实验结果表明，所提出的 CAS 方法在高维数据集上实现了高达 99% 的执行时间提升，同时保持了精度和可扩展性。

**Conclusion:** 所提出的 CAS 方法是一种高效且精确的 K 值选择策略，适用于需要快速聚类或资源利用率最小化的场景。

> **ai_Abstract:** 该研究提出了一种名为 CAS (Condensed and Accelerated Silhouette) 的新方法，用于优化 K-Means 聚类中的 K 值选择。该方法结合了凝结轮廓系数法和多种统计方法，能在保证聚类精度的同时，显著提高计算效率，特别是在处理高维数据集时，速度提升高达 99%，适用于实时聚类和资源受限的场景。

> **摘要翻译:** 聚类是当今数据驱动环境中决策制定的关键组成部分。它已被广泛应用于生物信息学、社交网络分析和图像处理等领域。然而，聚类准确性在大数据集上仍然是一个重大挑战。本文全面概述了在聚类中选择最佳 k 值的策略，重点关注在复杂数据环境中平衡聚类精度和计算效率。此外，本文还对文本和图像数据的聚类技术进行了改进，以提供对更好计算性能和聚类有效性的见解。所提出的方法基于凝结轮廓系数法，以及局部结构、间隙统计量、类一致性比率和基于聚类重叠指数 CCR 和 COI 的算法，用于计算 K-Means 聚类的最佳 k 值。比较实验结果表明，所提出的方法在高维数据集上实现了高达 99% 的执行时间提升，同时保持了精度和可扩展性，使其高度适用于实时聚类需求或需要有效聚类且资源利用率最小化的场景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [420] [Modeling Partially Observed Nonlinear Dynamical Systems and Efficient Data Assimilation via Discrete-Time Conditional Gaussian Koopman Network](https://arxiv.org/abs/2507.08749)
> *部分观测非线性动力学系统的建模与高效数据同化：基于离散时间条件高斯库普曼网络*

*Chuanqi Chen, Zhongrui Wang, Nan Chen, Jin-Long Wu* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** Koopman网络, 数据同化, 非线性动力学系统, 科学机器学习, 条件高斯

**Comment:** 

> **TL;DR:** 本研究提出了一种离散时间条件高斯库普曼网络（CGKN），用于学习高维复杂动力学系统的代理模型，以实现高效状态预测和数据同化（DA）。该方法通过Koopman嵌入发现潜在状态表示，使潜在状态动力学条件线性化，从而将模型系统转化为条件高斯系统，便于通过解析公式高效评估后验分布。将DA性能纳入模型学习过程，统一了科学机器学习（SciML）和数据同化。在粘性Burgers方程、Kuramoto-Sivashinsky方程和二维Navier-Stokes方程等非线性偏微分方程问题上，CGKN在状态预测方面达到了与最先进的SciML方法相当的性能，并提供了高效准确的DA结果。

**AI_Comments:** 这项工作通过引入条件高斯库普曼网络（CGKN）有效地解决了高维非线性部分观测动力学系统的建模和数据同化问题。通过Koopman嵌入实现条件线性化和高斯后验分布的解析评估，为提高数据同化效率和精度提供了一条有前景的途径。将SciML与DA的统一框架尤为值得称赞，这为科学机器学习在实际应用中的集成开辟了新的可能性。然而，该方法在处理极端非线性或高维系统时的可扩展性和鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种能够对高维复杂动力学系统（尤其是非线性偏微分方程控制的系统）进行高效状态预测和数据同化（DA）的代理模型。重点关注许多工程和地球科学应用中常见的非线性部分观测系统。

**Method:** 开发离散时间条件高斯库普曼网络（CGKN），利用Koopman嵌入发现未观测状态的潜在表示，使得潜在状态动力学条件线性化，将模型系统转化为条件高斯系统。通过解析公式高效评估后验分布，并将DA性能纳入模型学习过程，统一SciML和数据同化。

**Result:** 在粘性Burgers方程、Kuramoto-Sivashinsky方程和二维Navier-Stokes方程等非线性偏微分方程问题上，证明了离散时间CGKN在状态预测方面达到了与最先进的SciML方法相当的性能，并提供了高效准确的数据同化结果。

**Conclusion:** 离散时间CGKN框架能够有效地学习非线性部分观测系统的代理模型，实现高效的状态预测和数据同化，并将SciML与数据同化相结合。该框架还在设计优化、逆问题和最优控制等领域具有应用潜力。

> **ai_Abstract:** 本研究提出了一种名为离散时间条件高斯库普曼网络（CGKN）的新型框架，用于处理高维非线性部分观测动力学系统，特别关注由非线性偏微分方程描述的系统。CGKN利用Koopman嵌入来学习未观测状态的潜在表示，使这些潜在状态的动力学条件线性化，从而将系统转化为易于处理的条件高斯系统。这种方法允许通过解析公式高效地评估后验分布，并将数据同化（DA）的性能直接整合到模型学习过程中，实现了科学机器学习（SciML）与DA的统一。在粘性Burgers方程、Kuramoto-Sivashinsky方程和二维Navier-Stokes方程等典型基准测试中的实验结果表明，CGKN在状态预测方面与现有先进的SciML方法相当，同时提供了高效且准确的DA能力，并展示了其在设计优化、逆问题和最优控制等更广泛应用中的潜力。

> **摘要翻译:** 本研究开发了一种离散时间条件高斯库普曼网络（CGKN），用于学习代理模型，以对高维复杂动力学系统（例如，由非线性偏微分方程控制的系统）进行高效的状态预测和数据同化（DA）。本工作专注于工程和地球科学应用中常见的非线性部分观测系统，利用Koopman嵌入来发现未观测系统状态的适当潜在表示，使得潜在状态的动力学是条件线性的，即在给定观测系统状态的情况下是线性的。然后，观测状态和潜在状态的模型系统成为一个条件高斯系统，其潜在状态的后验分布是高斯分布，并且可以通过解析公式进行高效评估。DA的解析公式有助于将DA性能纳入模型系统的学习过程中，从而形成一个统一科学机器学习（SciML）和数据同化的框架。离散时间CGKN的性能在几个由具有间歇性和湍流特征的非线性偏微分方程控制的典型问题上得到了证明，包括粘性Burgers方程、Kuramoto-Sivashinsky方程和二维Navier-Stokes方程，我们证明了离散时间CGKN框架在状态预测方面达到了与最先进的SciML方法相当的性能，并提供了高效且准确的DA结果。离散时间CGKN框架还作为示例，说明了统一SciML模型开发及其在设计优化、逆问题和最优控制等其他外循环应用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [427] [Sculpting Quantum Landscapes: Fubini-Study Metric Conditioning for Geometry Aware Learning in Parameterized Quantum Circuits](https://arxiv.org/abs/2506.21940)
> *雕刻量子景观：用于参数化量子电路中几何感知学习的 Fubini-Study 度量条件*

*Marwan Ait Haddou, Mohamed Bennai* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 元学习, 参数化量子电路, Fubini-Study 度量, 贫瘠平台, 几何感知学习

**Comment:** Need more analysis

> **TL;DR:** Sculpture 是一个元学习框架，通过优化 Fubini-Study 度量张量的条件数来解决参数化量子电路中的贫瘠平台问题，从而提高可训练性、优化和泛化能力。

**AI_Comments:** 该研究提出了一种新颖的元学习方法 Sculpture，用于处理参数化量子电路中的贫瘠平台问题。通过关注 Fubini-Study 度量张量的条件数，该方法提供了一种几何视角来理解和改善量子机器学习模型的训练。实证结果令人信服地展示了该方法在提高收敛速度、降低损失和提升泛化能力方面的有效性。然而，该方法在处理更复杂的量子系统或噪声环境下的性能仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决参数化量子电路中由贫瘠平台引起的可训练性、优化和泛化问题，需要一种新的元学习框架来显式地调整 Fubini-Study 度量张量。

**Method:** 提出了一种名为 Sculpture 的元学习框架，该框架通过生成数据依赖的量子电路初始化来最小化 Fubini-Study 度量张量的对数条件数，以缓解贫瘠平台问题。

**Result:** Sculpture 将对数条件数从约 1.47 降低到 0.64，提高了最小特征值，并略微降低了最大特征值，从而缓解了贫瘠平台。在混合量子经典分类任务中，它将测试准确率从约 0.68 提高到 0.78 以上。

**Conclusion:** 通过元学习对量子景观进行雕刻是一种原则性的几何正则化方法，可以显著提高参数化量子电路的可训练性、优化和泛化能力，从而实现更强大、更高效的变分量子算法。

> **ai_Abstract:** Sculpture 框架利用 Fubini-Study 度量张量的对数条件数作为关键指标，通过元学习生成优化的量子电路初始化，以解决变分量子算法中的贫瘠平台问题。实验证明该方法能有效改善参数空间的条件，提高训练效率和泛化能力，并在实际分类任务中取得显著成果。

> **摘要翻译:** 我们提出了一个名为 Sculpture 的新颖元学习框架，该框架显式地调整变分量子算法中参数化量子电路的 Fubini-Study 度量张量，以缓解贫瘠平台问题。我们的理论分析确定 Fubini-Study 度量张量的对数条件数是控制可训练性、优化动态和泛化能力的关键几何量。Sculpture 使用一个经典的元模型来生成数据依赖的量子电路初始化，以最小化对数条件数，从而促进各向同性且条件良好的参数空间。
实证结果表明，元训练通过显著增加度量张量的最小特征值并略微减小最大特征值，将对数条件数从约 1.47 降低到 0.64，从而有效缓解了贫瘠平台问题。这种改进的条件化能够很好地泛化到未见过的数据，持续生成条件良好的量子电路初始化。在 Kaggle 糖尿病数据集上的下游混合量子经典分类任务中，增加元缩放系数可以加速收敛，降低训练损失和梯度范数，并关键地改善泛化能力，测试准确率从约 0.68 提高到 0.78 以上。这些发现表明，通过元学习对量子景观进行雕刻是一种原则性的几何正则化方法，可以显著提高参数化量子电路的可训练性、优化和泛化能力，并实现更强大、更高效的变分量子算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [432] [Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data](https://arxiv.org/abs/2506.23182)
> *深度生成序列模型的可归因性分配通过仅正向数据实现可解释性分析*

*Robert Frank, Michael Widrich, Rahmad Akbar, Günter Klambauer, Geir Kjetil Sandve, Philippe A. Robert, Victor Greiff* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-07-11**

**Keywords:** 生成模型, 可解释性, 归因方法, 抗体设计, 仅正向数据

**Comment:** 

> **TL;DR:** 该研究提出了一种名为GAMA的新归因方法，用于分析仅使用正向数据训练的生成模型，解决了现有方法在缺乏负向数据时的局限性，并成功应用于抗体设计。

**AI_Comments:** 该研究提出的GAMA方法在处理生物学领域中常见的仅正向数据问题上具有重要意义，解决了生成模型可解释性的关键挑战。其基于集成梯度的方法具有理论基础，并且在合成和真实数据上的验证增加了其可信度。然而，未来研究可以进一步探索GAMA在处理更复杂的序列数据和评估其在实际治疗设计中的影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成模型在生物序列设计中很有前景，但缺乏可解释性分析方法，尤其是在只有正向数据而缺乏负向数据的情况下，这限制了从模型中提取生物学见解的能力。

**Method:** 提出了一种名为GAMA（Generative Attribution Metric Analysis）的归因方法，该方法基于集成梯度，适用于自回归生成模型。通过合成数据集验证了GAMA的性能，并将其应用于抗体-抗原结合数据。

**Result:** GAMA能够从仅包含正向数据的生成模型中提取可解释的生物学见解，并且在抗体-抗原结合数据的实验中证明了其有效性。

**Conclusion:** GAMA方法实现了生成模型的模型可解释性，并能在无需负向训练数据的情况下验证生成序列设计策略。

> **ai_Abstract:** 本研究提出了一种名为GAMA的新型归因方法，用于分析仅使用正向数据训练的深度生成序列模型。GAMA基于集成梯度，解决了现有方法在缺乏负向数据时的局限性，使得从这些模型中提取可解释的生物学见解成为可能。研究通过合成数据集验证了GAMA的有效性，并成功将其应用于抗体-抗原结合数据分析，证明了其在生物序列设计和模型验证方面的潜力。

> **摘要翻译:** 生成式机器学习模型为治疗设计提供了一个强大的框架，通过有效探索具有理想特性的富集生物序列的大空间。与需要正负标签数据的监督学习方法不同，像LSTM这样的生成模型可以仅在正标签序列上进行训练，例如高亲和力抗体。这在负数据稀少、不可靠或生物学上定义不明确的生物学环境中特别有利。然而，生成模型缺乏归因方法阻碍了从此类模型中提取可解释生物学见解的能力。为了解决这个差距，我们开发了生成归因度量分析（GAMA），一种基于集成梯度的自回归生成模型归因方法。我们使用具有已知真实情况的合成数据集评估了GAMA，以表征其统计行为并验证其恢复生物学相关特征的能力。我们还通过将其应用于实验性抗体-抗原结合数据来证明了GAMA的实用性。GAMA实现了模型可解释性，并能在无需负向训练数据的情况下验证生成序列设计策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [437] [Scientific Machine Learning of Chaotic Systems Discovers Governing Equations for Neural Populations](https://arxiv.org/abs/2507.03631)
> *科学机器学习应用于混沌系统，发现神经种群的控制方程*

*Anthony G. Chesebro, David Hofmann, Vaibhav Dixit, Earl K. Miller, Richard H. Granger, Alan Edelman, Christopher V. Rackauckas, Lilianne R. Mujica-Parodi, Helmut H. Strey* | **Category: cs.LG, math-ph, math.MP, nlin.CD, q-bio.NC** | **Updated: 2025-07-10**

**Keywords:** 混沌系统, 控制方程发现, PEM-UDE, 符号回归, 神经科学

**Comment:** 46 pages, 9 figures

> **TL;DR:** 提出了一种名为PEM-UDE的新方法，结合了预测误差法和通用微分方程，用于从混沌动力学系统中提取可解释的数学表达式，即使在观测有限或嘈杂的情况下也能成功。该方法通过平滑优化和在拟合过程中去除混沌特性来克服传统技术的局限性，并且优于SINDy等直接符号回归方法。在应用于神经种群时，该方法推导出了符合生物学约束（如网络稀疏性）的新控制方程，并成功预测了连接密度、振荡频率和同步性之间的涌现关系，这些预测已通过实际脑电图数据得到验证。

**AI_Comments:** 该研究提出了一种新颖的PEM-UDE方法，在从混沌系统中提取控制方程方面取得了显著进展，特别是在处理噪声和有限数据方面。该方法在神经科学领域的应用及其对生物学约束的考虑使其具有重要意义。然而，该方法在处理更复杂或更高维度的系统时的可扩展性和鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 发现描述复杂混沌系统的控制方程在物理学和神经科学中仍然是一个基本挑战，传统技术在处理有限或嘈杂的观测数据时常常失败。

**Method:** PEM-UDE方法，结合了预测误差法（PEM）和通用微分方程（UDE），用于从混沌动力学系统中提取可解释的数学表达式。该方法通过平滑优化和在拟合过程中去除混沌特性来改进提取过程，即使在存在噪声的情况下也能恢复隐藏状态和重构动力学。

**Result:** PEM-UDE方法成功地从具有噪声的混沌系统中恢复了隐藏状态和重构了动力学，即使在噪声幅度是真实信号5倍的情况下也能恢复正确的函数形式。与SINDy等直接符号回归方法相比，该方法在给定数据量和噪声下表现更优。应用于神经种群时，该方法推导出了新的控制方程，该方程尊重网络稀疏性等生物学约束，并预测了连接密度、振荡频率和同步性之间的关系，这些关系已通过实际脑电图数据得到验证。

**Conclusion:** PEM-UDE方法为开发能够跨不同神经架构泛化的、机械性的、多尺度的脑模型提供了一条途径，弥合了单神经元动力学与宏观大脑活动之间的差距。

> **ai_Abstract:** 提出了一种名为PEM-UDE的新方法，用于从混沌动力学系统中提取控制方程，即使在数据有限或嘈杂的情况下也能有效。该方法优于现有技术，并成功应用于神经科学，发现了新的神经种群动力学方程，这些方程符合生物学约束并预测了连接密度与神经活动之间的关系，这些预测已通过实际数据得到验证。

> **摘要翻译:** 发现描述复杂混沌系统的控制方程仍然是物理学和神经科学中的一个基本挑战。在这里，我们介绍了PEM-UDE方法，该方法结合了预测误差法和通用微分方程，用于从混沌动力学系统中提取可解释的数学表达式，即使在观测有限或嘈杂的情况下也是如此。该方法通过平滑优化景观和在拟合过程中去除混沌特性而不扭曲最佳参数来在传统技术失败的地方取得成功。我们通过恢复Rossler系统中的隐藏状态和从噪声干扰的电路数据中重构动力学来证明其有效性，即使在一个观测到的时间序列被噪声干扰的真实信号幅度大5倍的情况下，也能恢复动力学的正确函数形式。我们证明该方法能够恢复正确的动力学，而直接符号回归方法，如SINDy，在给定数据量和噪声的情况下无法做到这一点。重要的是，当应用于神经种群时，我们的方法推导出了新的控制方程，该方程尊重生物学约束，如网络稀疏性——这是皮层信息处理所必需的约束，但在下一代神经质量模型中并未捕捉到——同时保留了微观神经元参数。这些方程预测了神经元回路中连接密度与振荡频率和同步性之间的涌现关系。我们使用来自内嗅皮层、前额叶皮层和眶额叶皮层的三个颅内电极记录数据集验证了这些预测。我们的工作为开发能够跨不同神经架构泛化的机械性、多尺度脑模型提供了一条途径，弥合了单神经元动力学与宏观大脑活动之间的差距。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [438] [Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently](https://arxiv.org/abs/2507.08053)
> *树状结构Parzen估计器可以更有效地解决黑盒组合优化问题*

*Kenshin Abe, Yunzhuo Wang, Shuhei Watanabe* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 树状结构Parzen估计器,组合优化,超参数优化,分类核,深度学习

**Comment:** Submitted to AutoML Conference

> **TL;DR:** 该研究提出了一种改进的树状结构Parzen估计器（TPE）算法，以更有效地解决组合优化问题，并在合成问题中验证了其优越性。

**AI_Comments:** 该研究成功地将TPE应用于组合优化问题，并提出了一种有效的算法。然而，在实际应用中处理大规模组合优化问题的可扩展性和鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 超参数优化（HPO）工具主要针对深度学习（DL）领域，但组合优化在化学和生物学等领域也很重要，而TPE在组合优化方面尚未得到充分研究。

**Method:** 通过泛化分类核并引入距离结构，并对新核进行修改以处理大型组合搜索空间，从而降低了核计算的时间复杂度。

**Result:** 实验证明，所提出的方法比原始TPE能以更少的评估次数找到更好的解决方案。

**Conclusion:** 所提出的TPE算法能够更有效地解决组合优化问题，并且已在Optuna框架中实现。

> **ai_Abstract:** 该研究提出了一种针对组合优化问题的改进的树状结构Parzen估计器（TPE）算法。通过泛化分类核并引入距离结构，并修改以处理大型搜索空间，新算法降低了计算复杂度，并在合成问题实验中证明了其比原始TPE更优越的性能。

> **摘要翻译:** 树状结构Parzen估计器（TPE）是一种通用的超参数优化（HPO）方法，受到流行的HPO工具的支持。由于这些HPO工具的开发符合深度学习（DL）的趋势，因此TPE经常讨论DL领域的问题设置，例如多目标优化和多保真度优化。然而，HPO的实际应用不仅限于DL，组合优化在某些领域（例如化学和生物学）中得到了积极利用。由于组合优化是TPE中一个尚未触及但非常重要的话题，我们提出了一种用于TPE的高效组合优化算法。在本文中，我们首先将TPE的分类核与数值核进行泛化，使我们能够为分类核引入距离结构。然后，我们讨论了对新开发的核进行修改以处理大型组合搜索空间。这些修改降低了核计算相对于组合搜索空间大小的时间复杂度。在合成问题实验中，我们验证了我们提出的方法比原始TPE能以更少的评估次数识别出更好的解决方案。我们的算法可在HPO的开源框架Optuna中使用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [439] [A Comprehensively Adaptive Architectural Optimization-Ingrained Quantum Neural Network Model for Cloud Workloads Prediction](https://arxiv.org/abs/2507.08317)
> *一种用于云工作负载预测的全面自适应架构优化嵌入式量子神经网络模型*

*Jitendra Kumar, Deepika Saxena, Kishu Gupta, Satyam Kumar, Ashutosh Kumar Singh* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 量子神经网络, 云工作负载预测, 架构优化, 深度学习, 资源管理

**Comment:** 

> **TL;DR:** 提出了一种名为 CA-QNN 的新型量子神经网络模型，通过全面的架构优化和量子计算的结合，提高了云工作负载预测的准确性，显著优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的量子神经网络模型，通过结合架构优化和量子计算来解决云工作负载预测中的挑战。模型在预测准确性方面取得了显著的改进，但其在实际部署中的计算复杂性和可扩展性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统神经网络和深度学习模型在处理高维、动态变化的云工作负载时存在优化不足的问题，导致效率低下。

**Method:** 提出了一种结合了量子计算效率和完整结构及量子比特向量参数学习的 CA-QNN 模型。该模型将工作负载数据转换为量子比特，并通过具有受控非门激活函数的量子比特神经进行处理。同时，引入了全面的网络架构优化算法，结合量子自适应调制和大小自适应重组，以实现可变大小 QNN 的结构和参数学习。

**Result:** CA-QNN 模型在四个基准数据集的异构云工作负载上进行了性能评估，与七种最先进的方法进行了比较。结果显示，CA-QNN 模型在预测准确性方面表现出色，与现有的深度学习和基于 QNN 的方法相比，预测误差降低了高达 93.40% 和 91.27%。

**Conclusion:** CA-QNN 模型通过其创新的架构优化和量子计算方法，显著提高了云工作负载预测的准确性，为动态云服务的资源管理提供了更有效的解决方案。

> **ai_Abstract:** 本研究提出了一种名为 CA-QNN 的新型量子神经网络模型，用于提高云工作负载预测的准确性。与传统方法相比，CA-QNN 利用量子计算的优势和创新的架构优化算法，能够更有效地处理高维和动态变化的云工作负载，显著降低了预测误差。

> **摘要翻译:** 准确的工作负载预测和先进的资源预留对于管理动态云服务至关重要。传统的神经网络和深度学习模型在处理多样化、高维工作负载时经常遇到挑战，尤其是在资源需求突然变化时，这会导致效率低下。这个问题源于它们在训练过程中优化能力有限，仅依赖于传统算法的参数（连接权重）调整。为了解决这个问题，本研究提出了一种新颖的基于全面自适应架构优化的变分量子神经网络（CA-QNN），它结合了量子计算的效率以及完整的结构和量子比特向量参数学习。该模型将工作负载数据转换为量子比特，通过具有受控非门激活函数的量子比特神经进行处理，以实现直观的模式识别。此外，还引入了一个全面的网络架构优化算法，以促进可变大小 QNN 的结构和参数值的学习和传播。该算法在训练过程中结合了量子自适应调制和大小自适应重组。对 CA-QNN 模型与四种异构云工作负载基准数据集上的七种最先进方法进行了全面的性能研究。与现有的深度学习和基于 QNN 的方法相比，所提出的模型展示了卓越的预测准确性，预测误差降低了高达 93.40% 和 91.27%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [440] [Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data](https://arxiv.org/abs/2507.08761)
> *离线数据强化学习中的不可行动作惩罚与奖励缩放*

*Jeonghye Kim, Yongjae Shin, Whiyoung Jung, Sunghoon Hong, Deunsol Yoon, Youngchul Sung, Kanghoon Lee, Woohyung Lim* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 离线强化学习, Q值外插误差, 奖励缩放, 不可行动作惩罚, PARS

**Comment:** Accepted to ICML2025

> **TL;DR:** 该研究提出了一种名为PARS的新算法，通过奖励缩放（RS-LN）和不可行动作惩罚（PA）来解决离线强化学习中的Q值外插误差问题，并在D4RL基准测试中取得了优于现有算法的性能。

**AI_Comments:** 该研究提出的PARS算法通过结合奖励缩放和不可行动作惩罚，为解决离线强化学习中的Q值外插误差问题提供了一种有效的解决方案。其在D4RL基准测试中的优异表现，特别是在复杂任务上的成功应用，凸显了该方法的潜力和实用性。未来的工作可以进一步探索不同类型的奖励函数和惩罚机制，以及在更广泛的应用场景中验证PARS的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 离线强化学习中的Q值外插误差问题，特别是数据范围之外的Q值线性外插。

**Method:** 提出奖励缩放与层归一化（RS-LN）以及不可行动作惩罚（PA）机制，并结合两者开发了PARS算法。

**Result:** PARS算法在D4RL基准测试中表现优于现有算法，在离线训练和在线微调方面均取得成功，特别是在AntMaze Ultra任务中表现突出。

**Conclusion:** PARS算法通过结合奖励缩放和不可行动作惩罚，有效解决了离线强化学习中的Q值外插误差问题，并在多项任务中证明了其优越性。

> **ai_Abstract:** 本研究针对离线强化学习中的Q值外插误差问题，提出了一种名为PARS的新算法。PARS结合了奖励缩放与层归一化（RS-LN）和不可行动作惩罚（PA）机制，旨在引导Q值在数据范围之外逐渐下降。实验结果表明，PARS在D4RL基准测试中，无论是在离线训练还是在线微调方面，均优于现有最先进的算法，尤其在AntMaze Ultra等具有挑战性的任务中表现出色。

> **摘要翻译:** 离线强化学习中的Q值外插误差是一个严峻的挑战。在本研究中，我们首先证明了Q函数在数据范围之外的线性外插尤其成问题。为了缓解这个问题，我们提出引导Q值在数据范围之外逐渐下降，这通过带有层归一化的奖励缩放（RS-LN）和不可行动作惩罚机制（PA）来实现。通过结合RS-LN和PA，我们开发了一种名为PARS的新算法。我们在多种任务上对PARS进行了评估，证明了其在离线训练和在线微调方面均优于最先进的算法，并在具有挑战性的AntMaze Ultra任务中取得了显著成功。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [442] [Predicting Air Pollution in Cork, Ireland Using Machine Learning](https://arxiv.org/abs/2507.04196)
> *使用机器学习预测爱尔兰科克市的空气污染*

*Md Rashidunnabi, Fahmida Faiza Ananna, Kailash Hambarde, Bruno Gabriel Nascimento Andrade, Dean Venables, Hugo Proenca* | **Category: cs.LG, stat.AP** | **Updated: 2025-07-11**

**Keywords:** 空气污染, 机器学习, 爱尔兰科克市, Extra Trees, 预测模型

**Comment:** The draft was submitted prematurely and requires further analysis,
  added research findings, and corrected references. Some co-authors have not
  yet approved this version. I will ensure all necessary revisions and
  approvals before resubmitting

> **TL;DR:** 该研究使用机器学习模型（特别是 Extra Trees）预测爱尔兰科克市的空气污染，准确率为 77%。研究发现气象条件（温度、风速、湿度）是主要驱动因素，并观察到明显的季节性和交通相关的污染模式。尽管存在健康风险，但 2014 年至 2022 年间空气质量有所改善。

**AI_Comments:** 这项研究在利用机器学习预测城市空气污染方面取得了显著进展，其准确率达到了 77%。研究强调了气象条件和交通模式对空气污染的关键作用，并指出了空气质量的季节性和日常变化。此外，该研究还揭示了科克市空气质量的积极改善趋势，为城市规划者和环境官员提供了有价值的见解和工具，以应对空气污染这一严峻挑战。研究成果的开源共享也值得称赞。

<details>
  <summary>Details</summary>

**Motivation:** 爱尔兰科克市的空气污染，特别是二氧化氮水平，严重威胁公众健康，已达到世界卫生组织安全标准的 278%。因此，有必要开发准确的预测模型来帮助城市规划者和环境官员管理空气质量。

**Method:** 该研究分析了近十年的数据，包括来自五个监测站的空气质量数据和 30 年的天气记录。研究人员评估了 17 种机器学习算法，并确定 Extra Trees 是预测空气污染的最佳算法，准确率为 77%。

**Result:** Extra Trees 算法在预测空气污染方面达到了 77% 的准确率，显著优于传统方法。研究还发现，温度、风速和湿度是影响空气污染的主要气象因素。空气污染表现出明显的季节性变化，冬季污染水平是夏季的两倍，交通高峰时段污染水平比正常水平高出 120%。从 2014 年到 2022 年，科克市的空气质量有所改善，减少了 31%。

**Conclusion:** 机器学习，特别是 Extra Trees 模型，可以准确预测爱尔兰科克市的空气污染。气象条件是污染的主要驱动因素，但交通和季节性因素也起着重要作用。该研究强调了智能预测系统在改善城市空气质量管理方面的潜力，能够实现早期预警和更明智的城市规划。

> **ai_Abstract:** 这项研究利用机器学习预测爱尔兰科克市的空气污染，其二氧化氮水平已超过世卫组织安全标准。通过分析近十年的空气质量数据和天气记录，研究评估了 17 种算法，发现 Extra Trees 模型准确率达到 77%，优于传统方法。研究强调了温度、风速和湿度等气象条件以及交通和季节性因素对污染水平的影响。尽管存在健康风险，但 2014 年至 2022 年间空气质量有所改善。该研究展示了智能预测系统在城市空气质量管理中的潜力，可用于早期预警和城市规划。

> **摘要翻译:** 空气污染对全球各地的城市构成严重的健康威胁，爱尔兰科克市的二氧化氮水平已超过世界卫生组织安全标准高达 278%。本研究利用人工智能以前所未有的准确性预测空气污染，分析了来自五个监测站近十年的数据以及 30 年的天气记录。我们评估了 17 种机器学习算法，其中 Extra Trees 被证明是最佳解决方案，预测准确率为 77%，并且显著优于传统的预测方法。我们的分析显示，气象条件，特别是温度、风速和湿度，是污染水平的主要驱动因素，而交通模式和季节性变化则造成了可预测的污染周期。污染表现出显著的季节性变化，冬季水平是夏季的两倍，日常高峰时段的污染水平比正常水平高出 120%。虽然科克市的空气质量显示出令人担忧的全球健康标准违规情况，但我们的模型检测到从 2014 年到 2022 年空气质量令人鼓舞地改善了 31%。这项研究表明，智能预测系统可以为城市规划者和环境官员提供强大的预测工具，从而实现具有生命拯救意义的预警系统和知情的城市规划决策。当今存在着改变城市空气质量管理的这项技术。所有研究材料和代码均可在以下网址免费获取：https://github.com/MdRashidunnabi/Air-Pollution-Analysis.git

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [445] [ML-Based Automata Simplification for Symbolic Accelerators](https://arxiv.org/abs/2507.08751)
> *基于机器学习的自动机简化方法在符号加速器中的应用*

*Tiffany Yu, Rye Stahle-Smith, Darssan Eswaramoorthi, Rasha Karakchi* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 符号加速器,自动机简化,机器学习,FPGA,随机森林

**Comment:** 

> **TL;DR:** AutoSlim是一个基于机器学习的框架，用于简化符号加速器中的自动机，减少内存和路由复杂性，提高在FPGA上的性能。

**AI_Comments:** 该研究提出了一种创新的基于机器学习的自动机简化方法，解决了符号加速器在处理大规模数据时的可扩展性问题。其亮点在于能够自动进行分数感知和加权转移的简化，这在现有工具中较为少见。实验结果令人印象深刻，展示了在FPGA资源利用率和性能上的显著提升。然而，文中提到“硬件互连（扇出）”对成本的影响，但具体如何量化和优化这一点可以进一步探讨。此外，对于不同类型的数据集和应用场景，该方法的泛化能力和鲁棒性也值得进一步研究。总体而言，这是一项具有重要理论和实践意义的工作。

<details>
  <summary>Details</summary>

**Motivation:** 符号加速器在基因组学、NLP和网络安全等领域广泛应用，但面临内存占用过大和路由复杂性高的问题，尤其是在处理大规模数据集时。需要一种方法来简化这些加速器以提高可扩展性。

**Method:** AutoSlim使用随机森林分类器，基于边得分和结构特征来修剪低影响力的转移，从而简化基于非确定性有限自动机（NFA）的符号加速器。该方法能够对具有权重转移的自动机进行自动化的、考虑分数的简化。

**Result:** AutoSlim在FPGA（NAPOLY+）上实现了高达40%的FPGA查找表（LUT）减少和超过30%的转移修剪。该方法能够处理比现有基准大一个数量级的图，并有效缓解了因硬件互连（扇出）导致的资源过载问题。

**Conclusion:** AutoSlim通过基于机器学习的自动机简化，显著降低了符号加速器的复杂性，提高了其在FPGA上的性能和可扩展性，解决了现有方法在处理大规模数据集时的瓶颈。

> **ai_Abstract:** 本文提出了一种名为AutoSlim的机器学习框架，用于简化基于FPGA的符号加速器中的非确定性有限自动机（NFA）。通过利用随机森林分类器修剪低影响力的转移，AutoSlim能有效降低模型的复杂性，减少内存占用和路由难度，从而提高在基因组学、NLP和网络安全等领域的应用性能。实验证明，AutoSlim可在FPGA资源使用上实现显著的降低（高达40%的LUT削减和30%的转移修剪），并能处理更大规模的数据集，同时证明了硬件互连对成本的影响以及AutoSlim的缓解作用。

> **摘要翻译:** 符号加速器在基因组学、自然语言处理和网络安全等领域越来越多地用于符号数据处理。然而，这些加速器在扩展性方面存在问题，主要是由于内存使用过大和路由复杂性高，尤其是在目标是大型数据集时。我们提出了AutoSlim，一个基于机器学习的图简化框架，旨在降低基于非确定性有限自动机（NFA）的符号加速器的复杂性，这些加速器部署在像NAPOLY+这样的基于FPGA的叠加层上。AutoSlim使用随机森林分类来修剪基于边得分和结构特征的低影响转移，从而在保持语义正确性的同时显著降低了自动机图的密度。与先前工具不同，AutoSlim的目标是实现自动化的、考虑分数的、带权重转移的简化，从而能够进行高效的基于排名的序列分析。我们在NAPOLY+中评估了数据集（节点从1K到64K），并进行了包括延迟、吞吐量和资源使用在内的性能测量。AutoSlim实现了高达40%的FPGA查找表（LUT）减少和超过30%的转移修剪，同时能够处理比现有基准大一个数量级的图。我们的结果还表明，硬件互连（扇出）如何严重影响硬件成本，以及AutoSlim的修剪如何缓解资源爆炸问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [447] [SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation](https://arxiv.org/abs/2507.07883)
> *SAMO：一种轻量级的锐度感知方法，用于具有联合全局-局部扰动的多任务优化*

*Hao Ban, Gokul Ram Subramani, Kaiyi Ji* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 多任务学习, 锐度感知最小化, 任务冲突, 轻量级优化, 全局局部扰动

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 该研究提出了一种名为SAMO的轻量级多任务优化方法，通过结合全局和局部扰动来解决多任务学习中的任务冲突问题，并取得了良好的效果和效率。

**AI_Comments:** 该研究将锐度感知最小化（SAM）的概念成功应用于多任务学习（MTL）领域，并提出了一种名为SAMO的创新性轻量级方法来解决MTL中的关键挑战——任务冲突。通过引入联合全局-局部扰动策略，并对局部扰动的计算进行优化，SAMO在保持高效的同时提升了模型性能。这项工作为改善多任务学习的优化过程提供了新的思路和实用的解决方案。代码的公开也为后续研究提供了便利。

<details>
  <summary>Details</summary>

**Motivation:** 多任务学习（MTL）虽然能降低计算成本并提高数据效率，但在优化过程中面临任务冲突的挑战，即任务梯度方向或大小不一致，限制了模型性能。Sharpness-Aware Minimization (SAM) 被发现可以有效缓解这些冲突。

**Method:** 提出了一种名为SAMO的轻量级锐度感知多任务优化方法，该方法利用联合全局-局部扰动来解决多任务学习中的任务冲突。其中，局部扰动通过前向传播近似计算，并进行层归一化以提高效率。

**Result:** 实验结果表明，SAMO方法在多任务基准测试中表现出有效性和高效性。

**Conclusion:** SAMO是一种有效的且轻量级的多任务优化方法，通过联合全局-局部扰动解决了多任务学习中的任务冲突问题，并在效率和性能上均有提升。

> **ai_Abstract:** 本研究提出了一种名为SAMO的轻量级多任务优化方法，旨在解决多任务学习中的任务冲突问题。该方法借鉴了锐度感知最小化（SAM）的思路，并通过一种新颖的联合全局-局部扰动策略来有效缓解任务梯度不一致的挑战。局部扰动的计算效率得到了优化，仅需前向传播并进行层归一化。在多项基准测试中的实验结果证实了SAMO在提高模型性能和效率方面的有效性。

> **摘要翻译:** 多任务学习（MTL）使联合模型能够捕捉多个任务之间的共性，降低计算成本并提高数据效率。然而，MTL优化中的一个主要挑战是任务冲突，即任务梯度在方向或大小上存在差异，与单任务对应模型相比限制了模型性能。锐度感知最小化（SAM）在最小化任务损失的同时，也降低了损失格局的锐度。我们的经验观察表明，SAM有效地缓解了MTL中的任务冲突。受这些发现的启发，我们探索将SAM集成到MTL中，但面临两个关键挑战。虽然平均损失梯度和各个任务梯度——被称为全局和局部信息——都对SAM有贡献，但如何将它们结合起来仍然不清楚。此外，直接计算每个任务梯度会带来显著的计算和内存开销。为了应对这些挑战，我们提出SAMO，一种轻量级的	extbf{S}harpness-	extbf{A}ware 	extbf{M}ulti-task 	extbf{O}ptimization（锐度感知多任务优化）方法，它利用联合全局-局部扰动。局部扰动仅使用前向传播进行近似计算，并进行层归一化以提高效率。在多任务基准测试的广泛实验证明了我们方法的有效性和效率。代码可在https://github.com/OptMN-Lab/SAMO获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [454] [DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving](https://arxiv.org/abs/2503.07656)
> *DriveTransformer：统一的Transformer可用于可扩展的端到端自动驾驶*

*Xiaosong Jia, Junqi You, Zhiyuan Zhang, Junchi Yan* | **Category: cs.LG, cs.CV, cs.RO** | **Updated: 2025-07-11**

**Keywords:** 端到端自动驾驶, Transformer, 任务并行, 稀疏表示, 流式处理

**Comment:** Accepted by ICLR2025; Fix Typo

> **TL;DR:** DriveTransformer是一个统一的Transformer框架，通过任务并行、稀疏表示和流式处理来解决现有端到端自动驾驶方法的局限性，实现了可扩展性和性能的提升。

**AI_Comments:** 该研究提出了一种新颖的DriveTransformer框架，通过任务并行、稀疏表示和流式处理来解决现有端到端自动驾驶方法的局限性，这在理论和实践上都具有重要意义。其统一的Transformer操作简化了模型，提高了效率和稳定性，并在多个基准测试中取得了优异的性能，展示了其在自动驾驶领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有端到端自动驾驶方法采用顺序范式（感知-预测-规划），导致累积误差和训练不稳定，并且手动任务排序限制了任务间的协同利用。此外，现有的密集BEV表示给远距离感知和长期时间融合带来了计算挑战。

**Method:** 提出了一种名为DriveTransformer的简化端到端自动驾驶框架，其特点是任务并行（所有代理、地图和规划查询在每个块中直接相互作用）、稀疏表示（任务查询直接与原始传感器特征交互）和流式处理（任务查询被存储并作为历史信息传递）。该框架由任务自注意力、传感器交叉注意力和时间交叉注意力三种统一操作组成。

**Result:** DriveTransformer显著降低了系统复杂性，提高了训练稳定性，并在模拟闭环基准测试Bench2Drive和真实世界开环基准测试nuScenes上均取得了最先进的性能，同时保持了高帧率。

**Conclusion:** DriveTransformer通过其新颖的架构设计，成功解决了现有端到端自动驾驶方法的关键挑战，并在多个基准测试中展现出优越的性能和效率。

> **ai_Abstract:** DriveTransformer是一个创新的端到端自动驾驶框架，它通过引入任务并行、稀疏表示和流式处理等关键特性，克服了传统方法中存在的累积误差、训练不稳定和计算挑战。该框架利用统一的Transformer操作（任务自注意力、传感器交叉注意力和时间交叉注意力），简化了系统设计，提高了可扩展性，并在模拟和真实世界数据上均取得了最先进的性能。

> **摘要翻译:** 端到端自动驾驶（E2E-AD）已成为自动驾驶领域的一个趋势，它有望提供一种数据驱动的、可扩展的系统设计方法。然而，现有的E2E-AD方法通常采用感知-预测-规划的顺序范式，这会导致累积误差和训练不稳定。手动排序任务也限制了系统利用任务间的协同作用（例如，面向规划的感知和博弈论的交互式预测与规划）。此外，现有方法采用的密集BEV表示给远距离感知和长期时间融合带来了计算挑战。为了解决这些挑战，我们提出了DriveTransformer，一个简化的E2E-AD框架，易于扩展，其特点是三个关键功能：任务并行（所有代理、地图和规划查询在每个块中直接相互作用）、稀疏表示（任务查询直接与原始传感器特征交互）和流式处理（任务查询被存储并作为历史信息传递）。结果是，新框架由三种统一的操作组成：任务自注意力、传感器交叉注意力和时间交叉注意力，这大大降低了系统复杂度并带来了更好的训练稳定性。DriveTransformer在模拟闭环基准测试Bench2Drive和真实世界开环基准测试nuScenes上均取得了最先进的性能，并且具有高FPS。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [464] [scE$^2$TM: Toward Interpretable Single-Cell Embedding via Topic Modeling](https://arxiv.org/abs/2507.08355)
> *scE$^2$TM：通过主题建模实现可解释的单细胞嵌入*

*Hegang Chen, Yuyin Lu, Zhiming Dai, Fu Lee Wang, Qing Li, Yanghui Rao* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 单细胞嵌入,主题模型,可解释性,知识引导,聚类分析

**Comment:** 

> **TL;DR:** scE$^2$TM是一种外部知识引导的单细胞嵌入主题模型，可提供高质量的细胞嵌入和可解释性，并在20个scRNA-seq数据集上实现了显著的聚类性能提升，同时引入了新的可解释性评估基准。

**AI_Comments:** 该研究提出了一种名为scE$^2$TM的新型单细胞嵌入主题模型，并通过引入量化评估指标来解决现有模型在可解释性方面的局限性。该方法在多个数据集上表现出优越的性能，并为单细胞数据分析提供了新的视角。然而，模型的计算复杂度和对外部知识的依赖性可能是在实际应用中需要考虑的因素。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在单细胞分析中的复杂性和性能不断提高，对模型可解释性的需求也日益增长。现有的单细胞嵌入主题模型在解释性评估上主要依赖定性分析，存在解释性崩溃的风险，并且忽视了外部生物学知识，限制了分析性能。

**Method:** 提出scE$^2$TM，一个外部知识引导的单细胞嵌入主题模型，并通过引入包含10个度量的可解释性评估基准来量化评估模型的解释性。

**Result:** scE$^2$TM在20个scRNA-seq数据集上的聚类性能显著优于7种最先进的方法。此外，其提供的解释性在多样性和与潜在生物信号的一致性方面表现良好，有助于更好地揭示潜在的生物机制。

**Conclusion:** scE$^2$TM通过整合外部生物学知识，在提供高质量细胞嵌入和增强模型可解释性方面取得了显著进展，为单细胞RNA测序数据分析提供了更全面的解决方案。

> **ai_Abstract:** scE$^2$TM是一种创新的外部知识引导单细胞嵌入主题模型，旨在解决现有模型在可解释性评估和整合生物学知识方面的不足。该模型通过结合外部知识，不仅提升了细胞嵌入的质量，还增强了模型的可解释性，并在多个基准测试中展现出优越的聚类性能。此外，研究者还提出了一种新的量化可解释性评估方法，以更客观地衡量模型解释能力的优劣，验证了scE$^2$TM在揭示生物机制方面的潜力。

> **摘要翻译:** 近期测序技术的进步使研究人员能够以单细胞分辨率探索细胞异质性。同时，随着深度学习模型复杂性和性能的快速提升，可解释性也日益受到重视。近年来，主题模型被广泛用于可解释的单细胞嵌入学习和聚类分析，我们称之为单细胞嵌入主题模型。然而，以往的研究主要通过定性分析来评估模型的解释性，并且这些单细胞嵌入主题模型存在解释性崩溃的潜在问题。此外，它们对外部生物学知识的忽视限制了分析性能。在此，我们提出了scE$^2$TM，一个外部知识引导的单细胞嵌入主题模型，它提供了高质量的细胞嵌入和强大的解释性，有助于对scRNA-seq数据进行全面分析。我们在20个scRNA-seq数据集上的综合评估表明，与7种最先进的方法相比，scE$^2$TM实现了显著的聚类性能提升。此外，我们提出了一个新的可解释性评估基准，引入了10个度量来量化评估单细胞嵌入主题模型的可解释性。结果表明，scE$^2$TM提供的解释性在多样性和与潜在生物信号的一致性方面表现令人鼓舞，有助于更好地揭示潜在的生物机制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [473] [Quantile Reward Policy Optimization: Alignment with Pointwise Regression and Exact Partition Functions](https://arxiv.org/abs/2507.08068)
> *分位数奖励策略优化：与逐点回归和精确配分函数的对齐*

*Simon Matrenok, Skander Moalla, Caglar Gulcehre* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** QRPO, 分位数奖励, 策略优化, 逐点回归, 语言模型对齐

**Comment:** 

> **TL;DR:** QRPO 是一种新的策略优化方法，它使用分位数奖励从逐点绝对奖励中学习，同时保持 DPO 等方法的简单性和离线适用性，并在聊天和编码评估中取得了优于现有方法的性能。

**AI_Comments:** QRPO 的创新之处在于它能够直接从逐点绝对奖励中学习，克服了现有简单方法的局限性，同时保持了它们的优势。该方法通过分位数奖励和解析可处理的配分函数实现了这一目标，这在理论上很有吸引力。此外，QRPO 在聊天和编码等实际应用中表现出了优越的性能，并且能够扩展以利用更多的计算资源。一个潜在的局限性可能是计算分位数奖励的成本，尽管作者提到这可以带来预计算的好处。

<details>
  <summary>Details</summary>

**Motivation:** 现有的简单方法（如 DPO 和 REBEL）只能从偏好对或相对信号中学习，而复杂的在线算法（如 PPO 和 GRPO）则需要逐点绝对奖励。QRPO 旨在弥合这一差距，实现从逐点绝对奖励中学习，同时保持 DPO 类方法的简单性和离线适用性。

**Method:** QRPO 使用分位数奖励来实现对 KL 正则化 RL 目标 的闭式解的回归。这种奖励产生了一个解析上可处理的配分函数，无需相对信号来抵消该项。QRPO 通过估计分位数奖励来扩展，这为预计算扩展提供了一个新的维度。

**Result:** QRPO 在聊天和编码评估中始终取得顶尖性能，优于 DPO、REBEL 和 SimPO，并在各种数据集和 8B 规模模型上进行了验证。使用稳健奖励进行训练而不是将其转换为偏好，会引起更少的长度偏差。

**Conclusion:** QRPO 是一种从逐点绝对奖励中学习的有效方法，它结合了 DPO 类方法的简单性和离线适用性，并在各种评估中取得了优于现有方法的性能，同时还减少了长度偏差。

> **ai_Abstract:** 本文提出了分位数奖励策略优化（QRPO），一种能够从逐点绝对奖励中学习的新型策略优化方法。与现有的仅限于偏好对或相对信号的方法不同，QRPO 保持了 DPO 类方法的简单性和离线适用性。通过使用分位数奖励进行回归到 KL 正则化 RL 目标的闭式解，QRPO 避免了对相对信号的需求，并且可以通过增加计算量来扩展。实验结果表明，QRPO 在聊天和编码任务上优于 DPO、REBEL 和 SimPO 等方法，并且可以减少长度偏差。

> **摘要翻译:** 迄今为止，将大型语言模型与逐点绝对奖励对齐需要 PPO 和 GRPO 等在线、在线策略算法。相比之下，可以利用离线或离线策略数据的简单方法，如 DPO 和 REBEL，仅限于从偏好对或相对信号中学习。为了弥合这一差距，我们引入了分位数奖励策略优化（QRPO），它从逐点绝对奖励中学习，同时保持了 DPO 类方法的简单性和离线适用性。QRPO 使用分位数奖励来实现对 KL 正则化 RL 目标 的闭式解的回归。这种奖励产生了一个解析上可处理的配分函数，无需相对信号来抵消该项。此外，QRPO 通过估计分位数奖励来扩展，这为预计算扩展提供了一个新的维度。在实践中，与 DPO、REBEL 和 SimPO 相比，QRPO 在聊天和编码评估（奖励模型分数、AlpacaEval 2 和 LeetCode）方面始终取得了顶尖性能，涵盖了各种数据集和 8B 规模的模型。最后，我们发现使用稳健奖励进行训练而不是将其转换为偏好，会引起更少的长度偏差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [475] [BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity](https://arxiv.org/abs/2507.08771)
> *块前馈网络：面向端侧加速友好、具有块级激活稀疏性的混合专家模型*

*Chenyang Song, Weilin Zhao, Xu Han, Chaojun Xiao, Yingfa Chen, Yuxuan Li, Zhiyuan Liu, Maosong Sun* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 混合专家模型, 激活稀疏性, 块级稀疏性, 端侧加速, 投机解码

**Comment:** 21 pages, 7 figures, 15 tables

> **TL;DR:** 本文提出了一种名为BlockFFN的新型混合专家（MoE）模型，通过使用ReLU激活和RMSNorm的路由器以及块级感知训练目标来提高模型性能和加速友好性。实验证明，BlockFFN在端侧设备上实现了高达3.67倍的加速。

**AI_Comments:** 该研究在MoE模型加速方面取得了重要进展，特别是在端侧设备上的应用。通过引入块级稀疏性概念并设计相应的训练和加速技术，有效解决了传统MoE模型在低资源场景下的性能瓶颈。然而，未来可以进一步探索不同块大小对加速效果的影响，以及在更广泛的硬件平台上的兼容性和性能表现。

<details>
  <summary>Details</summary>

**Motivation:** 为了减轻大型语言模型（LLMs）的计算负担，具有激活稀疏性的模型（如混合专家模型MoE）受到关注。然而，传统的MoE路由方式存在不可微分和不灵活的问题，并且稀疏激活模型在块级别上稀疏性较低，不利于在资源受限的端侧设备上进行加速，也与投机解码等主流加速技术不兼容。

**Method:** 提出了一种名为BlockFFN的新型MoE架构，并采用了高效的训练和部署技术。具体来说，使用整合了ReLU激活和RMSNorm的路由器来实现可微分和灵活的路由；设计了块级感知训练目标，以同时促进令牌级稀疏性（TLS）和块级稀疏性（CLS），使BlockFFN更易于加速；首次结合了激活稀疏性和投机解码，实现了高效的加速内核。

**Result:** BlockFFN在端侧设备上实现了超过80%的令牌级稀疏性（TLS）和70%的8令牌块级稀疏性（CLS），其加速内核相比密集模型实现了高达3.67倍的加速。

**Conclusion:** BlockFFN通过改进的路由机制和块级感知训练目标，在保持高性能的同时提高了加速友好性，并在实际端侧设备上取得了显著的加速效果。

> **ai_Abstract:** 本文提出了一种名为BlockFFN的新型混合专家（MoE）架构，旨在解决现有MoE模型在端侧设备加速方面面临的挑战。BlockFFN通过引入整合了ReLU激活和RMSNorm的路由器来改善路由的可微分性和灵活性，并通过设计块级感知训练目标来同时提升令牌级稀疏性（TLS）和块级稀疏性（CLS），从而提高模型的加速友好性。此外，研究人员还开发了结合激活稀疏性和投机解码的高效加速内核。实验结果显示，BlockFFN在性能上优于其他MoE模型，并在端侧设备上实现了显著的加速效果，最高可达3.67倍。

> **摘要翻译:** 为了减轻大型语言模型（LLMs）的计算负担，具有激活稀疏性的模型（如混合专家模型MoE）受到了越来越多的关注。然而，传统MoE模型中不可微分且不灵活的路由会损害模型性能。此外，尽管每个令牌只激活少数参数，但这些稀疏激活的模型却表现出较低的块级稀疏性，这意味着多个连续令牌的并集会激活大部分参数。这种稀疏模式不利于在低资源条件（如端侧设备）下的加速，并且与主流加速技术（如投机解码）不兼容。为了解决这些挑战，我们提出了一种新颖的MoE架构BlockFFN，以及其高效的训练和部署技术。具体来说，我们使用了一个整合了ReLU激活和RMSNorm的路由器来实现可微分和灵活的路由。接下来，为了同时促进令牌级稀疏性（TLS）和块级稀疏性（CLS），我们设计了块级感知训练目标，使BlockFFN更易于加速。最后，我们实现了高效的加速内核，首次结合了激活稀疏性和投机解码。实验结果表明，BlockFFN的性能优于其他MoE基线模型，实现了超过80%的TLS和70%的8令牌块级稀疏性（CLS）。我们的内核在实际端侧设备上实现了比密集模型高3.67倍的加速。所有代码和检查点均公开可用（https://github.com/thunlp/BlockFFN）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [479] [Leveraging Machine Learning and Enhanced Parallelism Detection for BPMN Model Generation from Text](https://arxiv.org/abs/2507.08362)
> *利用机器学习和增强的并行性检测从文本生成BPMN模型*

*Phuong Nam Lê, Charlotte Schneider-Depré, Alexandre Goossens, Alexander Stevens, Aurélie Leribaux, Johannes De Smedt* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** BPMN模型生成, 机器学习, 并行结构检测, 大型语言模型, 数据集增强

**Comment:** 

> **TL;DR:** 该论文提出了一种自动化流程，利用机器学习和大型语言模型从文本中提取BPMN模型，并通过包含并行网关的新注释数据集来解决现有方法在识别并行结构方面的不足，从而提高BPMN模型生成的效率和准确性。

**AI_Comments:** 该研究通过引入包含并行网关的新注释数据集，解决了现有BPMN模型生成方法在捕捉复杂并行结构方面的局限性。利用机器学习和大型语言模型的方法为自动化流程提供了新的途径，但其在实际应用中的可扩展性和对不同领域文本的泛化能力仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 将文本流程文档转换为正式的BPMN模型对于有效的规划、资源管理和一致的运营至关重要，但现有方法耗时且成本高，并且在识别并行结构方面存在不足。

**Method:** 利用机器学习和大型语言模型开发了一个自动化流程，并使用包含32个并行网关的新注释数据集（在PET数据集基础上增强）来训练模型，以更好地捕捉流程描述中的并行结构。

**Result:** 所提出的方法在重构准确性方面表现出足够好的性能，为组织加速BPMN模型创建提供了一个有前景的基础。

**Conclusion:** 该研究通过引入包含并行网关的新注释数据集，并利用机器学习和大型语言模型，提出了一种从文本生成BPMN模型的自动化方法，提高了对并行结构的捕捉能力，并为加速BPMN模型创建奠定了基础。

> **ai_Abstract:** 本研究提出了一种从文本生成BPMN模型的自动化方法，结合了机器学习和大型语言模型。为了解决现有方法在处理并行结构方面的不足，研究人员创建了一个包含额外并行网关注释的数据集，以改进模型训练。该方法在重构准确性方面显示出有希望的结果，有望加快BPMN模型的创建过程。

> **摘要翻译:** 高效的规划、资源管理和一致的运营通常依赖于将文本流程文档转换为正式的业务流程模型和符号（BPMN）模型。然而，这个转换过程仍然耗时且成本高昂。现有的方法，无论是基于规则的还是基于机器学习的，在处理写作风格和识别流程描述中的并行结构方面仍然存在困难。
  本文介绍了一个从文本提取BPMN模型的自动化流程，利用了机器学习和大型语言模型。这项工作的一个关键贡献是引入了一个新注释的数据集，该数据集显著增强了训练过程。具体来说，我们在PET数据集中增加了15个新注释的文档，其中包含32个并行网关用于模型训练，这是现有数据集中经常被忽略的一个关键特征。这个补充使得模型能够更好地捕捉流程描述中常见但复杂的并行结构。所提出的方法在重构准确性方面表现出足够好的性能，为组织加速BPMN模型创建提供了一个有前景的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [488] [Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity](https://arxiv.org/abs/2507.08177)
> *重新思考时空异常检测：驱动网络安全的因果关系愿景*

*Arun Vignesh Malarkkan, Haoyue Bai, Xinyuan Wang, Anjali Kaushik, Dongjie Wang, Yanjie Fu* | **Category: cs.LG, cs.AI, cs.ET, cs.NE, F.2.2, I.2.7, I.2.4, I.2.1** | **Updated: 2025-07-10**

**Keywords:** 因果学习, 时空异常检测, 网络安全, 可解释性, 根因分析

**Comment:** 5 pages, 1 figure, Under Review in Vision Paper Track-ACM SIGSPATIAL
  2025

> **TL;DR:** 该论文提出了一种基于因果学习的异常检测方法，以解决当前深度学习方法在可解释性、适应性和鲁棒性方面的不足，并以水处理系统为例进行了说明。

**AI_Comments:** 该论文提出了一个非常有前景的研究方向，即利用因果关系来解决网络安全中的异常检测问题。这种方法有望克服传统黑盒模型的局限性，提供更具可解释性和鲁棒性的解决方案。然而，实际应用中因果模型的构建和维护可能面临挑战，尤其是在复杂多变的动态系统中。

<details>
  <summary>Details</summary>

**Motivation:** 当前数据驱动的异常检测方法（主要是黑盒深度学习）在可解释性、分布偏移适应性和演化系统动力学下的鲁棒性方面面临挑战。

**Method:** 论文提出了一种基于因果学习的视角，通过因果图谱分析、多视图融合和持续因果图学习三个关键方向来推进异常检测，并以水处理系统为例进行了说明。

**Result:** 基于因果的模型可以提供早期预警信号和根本原因归因，克服了黑盒检测器的局限性。

**Conclusion:** 论文旨在为可扩展、自适应、可解释和空间相关的异常检测系统奠定新的研究轨迹，并希望推动网络安全研究范式的转变，促进以因果驱动的方法来应对互联基础设施中不断演变的威胁。

> **ai_Abstract:** 本研究提出了一种基于因果学习的异常检测方法，以解决当前深度学习方法在可解释性、适应性和鲁棒性方面的不足。通过因果图谱分析、多视图融合和持续因果图学习，该方法能够更好地理解和检测网络物理系统中的异常。研究以水处理系统为例，展示了因果模型在提供早期预警和根本原因归因方面的优势，并对未来研究方向进行了展望。

> **摘要翻译:** 随着网络物理系统日益互联和空间分布，确保其在不断演变的网络攻击下的韧性已成为一项关键任务。时空异常检测在确保系统安全和运行完整性方面发挥着重要作用。然而，当前主要由黑盒深度学习驱动的数据驱动方法在可解释性、对分布偏移的适应性以及在演化系统动力学下的鲁棒性方面面临挑战。在本文中，我们提倡采用因果学习的视角来推进空间分布基础设施中的异常检测，将检测建立在结构化的因果关系基础上。我们识别并形式化了三个关键方向：因果图谱分析、多视图融合和持续因果图学习，每个方向在揭示跨越时间和空间的动态因果结构方面都具有独特的优势。借鉴水处理基础设施等系统的真实见解，我们说明了因果模型如何提供早期预警信号和根本原因归因，从而解决了黑盒检测器的局限性。展望未来，我们概述了以多模态、生成式人工智能驱动和可扩展的自适应因果框架为中心的未来研究议程。我们的目标是为可扩展、自适应、可解释和空间相关的异常检测系统奠定新的研究轨迹。我们希望在网络安全研究中激发范式的转变，推广因果驱动的方法来应对互联基础设施中不断演化的威胁。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [494] [Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN and a Transformer](https://arxiv.org/abs/2507.08365)
> *利用LSTM、CNN和Transformer预测人类驾驶员变道意图*

*Francesco De Cristofaro, Felix Hofbaur, Aixi Yang, Arno Eichberger* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 变道意图预测, LSTM, CNN, Transformer, 自动驾驶

**Comment:** 14 pages, 18 figures

> **TL;DR:** 该研究比较了LSTM、CNN和Transformer三种模型在预测人类驾驶员变道意图方面的性能，并对输入数据进行了配置比较。结果显示Transformer模型表现最佳，准确率在82.79%到96.73%之间。

**AI_Comments:** 该研究有效地比较了三种主流的深度学习模型在变道意图预测任务上的性能，并深入探讨了输入数据对模型表现的影响，为自动驾驶领域提供了重要的实践指导。然而，未来研究可以进一步探索更复杂的交通场景和更广泛的数据集，以提高模型的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 预测前方车辆的变道行为对于自动驾驶车辆的运动规划至关重要，可以提高安全性和效率。现有研究较少关注在特定时间间隔内预测变道意图，并且缺乏对不同模型架构及其输入数据选择进行比较的深入分析。

**Method:** 本文描述并实现了一个LSTM、一个CNN和一个Transformer网络结构，用于预测人类驾驶员的变道意图。研究人员展示了如何从公开可用数据集（highD）准备数据，选择了哪些特征，设计了网络结构，并通过比较不同输入数据配置下的三种网络性能来评估它们。

**Result:** Transformer网络在预测人类驾驶员变道意图方面优于LSTM和CNN，并且更不容易出现过拟合。在不同的输入配置下，该方法的准确率在82.79%至96.73%之间，综合考虑精确率和召回率，整体表现良好。

**Conclusion:** Transformer模型在预测人类驾驶员变道意图方面表现出最佳性能，并且在输入数据配置和对过拟合的抵抗能力方面优于LSTM和CNN。

> **ai_Abstract:** 本研究旨在通过比较LSTM、CNN和Transformer三种神经网络模型在预测人类驾驶员变道意图方面的性能，并探索不同输入数据配置的影响。研究人员使用highD数据集，对数据进行预处理和特征选择，然后设计并实现了这三种模型。实验结果表明，Transformer模型在准确率、精确率和召回率方面均优于其他模型，并且对过拟合的抵抗能力更强，准确率范围在82.79%至96.73%之间，为自动驾驶车辆的运动规划提供了有价值的参考。

> **摘要翻译:** 变道行为，例如在复杂交通状况下，对自动驾驶车辆的运动规划有很大的影响。预测它们将使公众在安全和效率方面受益。尽管在这方面已经做了许多研究，但与在固定预测时间进行预测相比，很少有人专注于在固定时间间隔内预测机动动作。此外，缺乏对不同架构的比较，以确定性能最佳的架构，并评估如何正确选择输入数据，以了解这些模型。在本文中，描述并实现了LSTM、CNN和Transformer网络的结构，用于预测人类驾驶员进行变道的意图。我们展示了数据是如何准备的，从公开可用的数据集（highD）开始，使用了哪些特征，网络是如何设计的，最后我们比较了三种网络在不同输入数据配置下的结果。我们发现Transformer网络比其他网络表现更好，并且不易出现过拟合。该方法在不同输入配置下的准确率从82.79%到96.73%不等，并考虑了精确率和召回率，显示了整体良好的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [505] [Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees](https://arxiv.org/abs/2507.08784)
> *面向具有收敛保证的分布式学习的贪婪低秩梯度压缩*

*Chuyan Chen, Yutong He, Pengrui Li, Weichen Jia, Kun Yuan* | **Category: cs.LG, math.OC** | **Updated: 2025-07-11**

**Keywords:** 分布式学习, 低秩梯度压缩, 贪婪压缩, 收敛保证, 通信开销

**Comment:** 18 pages, 5 figures

> **TL;DR:** 该论文提出了一种名为GreedyLore的新的分布式学习贪婪低秩梯度压缩算法，该算法通过引入误差反馈和半惰性子空间更新来解决现有方法的不足，并提供了严格的收敛保证，实现了首次低秩梯度压缩的线性加速收敛率。

**AI_Comments:** 该研究在分布式学习领域取得了重要进展，通过提出GreedyLore算法，首次实现了贪婪低秩梯度压缩的收敛保证和线性加速。该方法通过巧妙地结合误差反馈和半惰性子空间更新，有效解决了现有方法的不足，为解决大规模分布式学习中的通信瓶颈问题提供了有力的理论和实践支持。然而，该算法在不同网络拓扑和异构环境下的表现仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 通信开销是分布式学习中的主要瓶颈，而现有的低秩梯度压缩方法要么收敛慢（随机方法），要么缺乏收敛保证（贪婪方法）。

**Method:** 提出GreedyLore算法，结合误差反馈和半惰性子空间更新，以提供收敛保证。

**Result:** GreedyLore实现了$\\\mathcal{O}(\\\\\\\sigma/(\\\\\\\sqrt{NT}) + 1/T)$的收敛率，这是低秩梯度压缩首次实现的线性加速收敛率。

**Conclusion:** GreedyLore是第一个具有严格收敛保证的分布式学习贪婪低秩梯度压缩算法，通过误差反馈和半惰性子空间更新解决了现有方法的局限性，并实现了理论上和实验上都得到验证的线性加速收敛。

> **ai_Abstract:** 该研究提出了一种名为GreedyLore的创新分布式学习算法，它使用贪婪低秩梯度压缩来解决通信瓶颈问题。通过引入误差反馈和半惰性子空间更新，GreedyLore克服了现有方法的局限性，实现了首个具有严格收敛保证的低秩梯度压缩线性加速收敛率，并通过实验得到了验证。

> **摘要翻译:** 分布式优化对于大规模信号处理和机器学习至关重要，但通信开销仍然是主要的瓶颈。低秩梯度压缩，即通过低秩矩阵逼近传输的梯度以减少通信，提供了一种有前途的解决方案。现有方法通常采用随机或贪婪压缩策略：随机方法将梯度投影到随机选择的子空间上，引入高方差并降低了实际性能；贪婪方法选择信息量最大的子空间，取得了良好的实际效果，但缺乏收敛保证。为了解决这一差距，我们提出了GreedyLore——第一个具有严格收敛保证的分布式学习贪婪低秩梯度压缩算法。GreedyLore结合了误差反馈来纠正贪婪压缩引入的偏差，并引入了半惰性子空间更新，以确保压缩算子在所有迭代中保持收缩性。利用这些技术，我们证明了GreedyLore在MSGD和Adam等标准优化器下实现了$\\\mathcal{O}(\\\\\\\sigma/(\\\\\\\sqrt{NT}) + 1/T)$的收敛率——这是低秩梯度压缩首次实现的线性加速收敛率。进行了广泛的实验来验证我们的理论发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [509] [Advances in Machine Learning: Where Can Quantum Techniques Help?](https://arxiv.org/abs/2507.08379)
> *机器学习的进展：量子技术能在哪里提供帮助？*

*Samarth Kashyap, Rohit K Ramakrishnan, Kumari Jyoti, Apoorva D Patel* | **Category: cs.LG, quant-ph** | **Updated: 2025-07-11**

**Keywords:** 量子机器学习, 量子计算, 经典机器学习, NISQ设备, 量子优势

**Comment:** 28 pages, 1 figure

> **TL;DR:** 量子机器学习（QML）结合了量子计算和人工智能，旨在利用量子优势解决经典机器学习的计算瓶颈，尤其是在处理复杂数据集方面。本文回顾了QML的理论基础、方法分类、关键进展（如量子主成分分析、量子增强传感、材料科学应用）、NISQ设备的挑战以及未来方向，强调了其在特定领域（如量子化学、传感）的潜力，但其广泛应用仍需克服技术和方法上的障碍。

**AI_Comments:** 该综述对量子机器学习的现状和未来进行了全面的梳理，清晰地指出了其潜力和面临的挑战，特别是NISQ设备带来的限制。文章结构清晰，从理论基础到具体应用再到未来展望，为研究者提供了有价值的参考。然而，对于如何具体克服NISQ设备的限制，文中仅提出了方向，缺乏更深入的探讨。

<details>
  <summary>Details</summary>

**Motivation:** 经典机器学习在处理复杂数据集时面临计算瓶颈，需要探索利用量子计算优势来增强数据驱动任务的潜力。

**Method:** 本文回顾了量子机器学习（QML）的理论基础（包括量子数据编码、量子学习理论和优化技术），并根据数据类型和计算架构对QML方法进行了分类。同时，文章还评估了量子主成分分析、量子增强传感和材料科学应用等关键进展的理论加速和实际局限性，并讨论了NISQ设备带来的挑战（如硬件噪声、可扩展性限制、数据编码开销）以及未来方向（如量子原生算法、错误纠正、实际基准测试）。

**Result:** 量子机器学习在处理复杂数据集方面具有潜力，尤其是在量子化学和传感等特定应用中，但其广泛应用受限于NISQ设备的挑战以及需要克服技术和方法上的障碍。

**Conclusion:** 量子机器学习（QML）在特定应用领域（如量子化学和传感）具有显著潜力，但其在现实世界场景中的更广泛应用，仍取决于克服技术和方法上的挑战，包括硬件噪声、可扩展性约束、数据编码开销以及开发量子原生算法、改进错误纠正和建立实际基准测试。

> **ai_Abstract:** 本文回顾了量子机器学习（QML）在利用量子计算优势解决经典机器学习计算瓶颈方面的潜力。文章介绍了QML的理论基础、分类方法，评估了关键进展及其局限性，讨论了NISQ设备的挑战，并指出了未来发展方向。结论认为，QML在特定领域潜力巨大，但广泛应用仍需克服技术和方法上的障碍。

> **摘要翻译:** 量子机器学习（QML）代表了量子计算和人工智能交叉领域的一个有希望的前沿，旨在利用量子计算优势来增强数据驱动的任务。本综述探讨了QML解决经典机器学习计算瓶颈的潜力，特别是在处理复杂数据集方面。我们介绍了QML的理论基础，包括量子数据编码、量子学习理论和优化技术，同时根据数据类型和计算架构对QML方法进行了分类。众所周知，量子计算优势是依赖于问题的，因此需要系统地识别QML潜在有用的方向。量子主成分分析、量子增强传感和材料科学应用等关键进展，因其理论加速和实际局限性而受到严格评估。有噪声中等规模量子（NISQ）设备带来的挑战，包括硬件噪声、可扩展性约束和数据编码开销，得到了详细讨论。我们还概述了未来的方向，强调了对量子原生算法、改进的错误纠正和现实基准测试的需求，以弥合理论承诺与实际部署之间的差距。这项全面的分析强调，虽然QML在量子化学和传感等特定应用中具有巨大潜力，但其在现实世界场景中的更广泛应用，仍取决于克服技术和方法上的障碍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [513] [Low-rank Momentum Factorization for Memory Efficient Training](https://arxiv.org/abs/2507.08091)
> *低秩动量分解以实现内存高效训练*

*Pouria Mahdavinia, Mehrdad Mahdavi* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 低秩分解, 动量优化, 内存高效微调, MoFaSGD, 大型语言模型

**Comment:** 

> **TL;DR:** 提出了一种名为 MoFaSGD 的新方法，通过动态更新的低秩 SVD 表示来近似一阶动量，从而实现内存高效的微调，并在理论和实践上都取得了良好的效果。

**AI_Comments:** 这项工作通过引入 MoFaSGD 解决了大型模型微调中的关键内存瓶颈问题，提供了一种在内存效率和模型性能之间取得良好平衡的创新解决方案。其理论保证和在实际基准测试中的有效性使其成为一个有前景的研究方向，但未来可以进一步探索其在不同模型架构和任务上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 大型基础模型的微调因 AdamW 等状态优化器而面临巨大的内存挑战，这通常需要比推理多几倍的 GPU 内存。

**Method:** 提出 Momentum Factorized SGD (MoFaSGD)，它维护一阶动量的动态更新低秩 SVD 表示，在训练过程中紧密近似其全秩对应物。

**Result:** MoFaSGD 在大型语言模型对齐基准测试中表现出有效性，在内存减少（与 LoRA 相当）和性能方面与最先进的低秩优化方法相比具有竞争力的权衡。

**Conclusion:** MoFaSGD 是一种内存高效的微调方法，它利用低秩动量分解来实现高效的频谱归一化更新，并为非凸随机优化提供了理论收敛保证。

> **ai_Abstract:** 该研究提出了一种名为 MoFaSGD 的新颖内存高效微调方法，通过动态更新的低秩 SVD 表示来近似一阶动量。与现有方法不同，MoFaSGD 能够自适应地更新优化子空间，并利用低秩动量因子进行高效的频谱归一化更新。理论分析证明了其在非凸随机优化中的最优收敛速率，实验结果表明其在大型语言模型对齐任务上取得了与最先进方法相当的性能，同时显著减少了内存消耗。

> **摘要翻译:** 微调大型基础模型由于 AdamW 等状态优化器而带来巨大的内存挑战，通常需要比推理多几倍的 GPU 内存。虽然存在参数高效微调（例如 LoRA）和优化器状态压缩等内存高效方法，但 GaLore 等最新方法通过使用低秩梯度投影和子空间动量累积来弥合这些差距。然而，这种方法可能难以处理固定的子空间或计算成本高昂的离线重采样（例如，需要全矩阵 SVD）。我们提出了动量分解 SGD (MoFaSGD)，它维护一阶动量的动态更新低秩 SVD 表示，在训练过程中紧密近似其全秩对应物。这种分解实现了一种内存高效的微调方法，该方法在每次迭代时自适应地更新优化子空间。至关重要的是，MoFaSGD 利用计算出的低秩动量因子进行高效的频谱归一化更新，为子空间动量累积提供了一种替代方案。我们为 MoFaSGD 建立了理论收敛保证，证明在标准假设下，它实现了非凸随机优化的最优速率。在实践中，我们在大型语言模型对齐基准测试中证明了 MoFaSGD 的有效性，与最先进的低秩优化方法相比，在内存减少（与 LoRA 相当）和性能方面取得了具有竞争力的权衡。我们的实现可在 https://github.com/pmahdavi/MoFaSGD 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [529] [Two-cluster test](https://arxiv.org/abs/2507.08382)
> *双簇检验*

*Xinying Liu, Lianyu Hu, Mudi Jiang, Simen Zhang, Jun Lou, Zengyou He* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 双簇检验, 聚类分析, 双样本检验, I类错误率, 显著性检验

**Comment:** 

> **TL;DR:** 提出了一种新的双簇检验方法，用于解决传统双样本检验在聚类分析中存在的I类错误率膨胀问题，并通过实验证明其有效性，并在可解释聚类和层次聚类中得到验证。

**AI_Comments:** 该研究提出的双簇检验方法在解决聚类分析中的一个关键问题方面具有重要意义，即传统双样本检验在处理聚类生成数据时可能出现的I类错误率膨胀。通过引入基于边界点的新方法，该研究提供了一种更准确的显著性量化手段。实验结果和在实际聚类应用中的验证增加了该方法的说服力。然而，关于该方法在不同类型聚类算法和数据分布下的鲁棒性以及计算效率的进一步研究可能会增加其价值。

<details>
  <summary>Details</summary>

**Motivation:** 在许多现代聚类方法中，需要确定两个样本子集是否来自同一簇。由于这些子集通常由聚类程序生成，经典的双样本检验会导致p值过小，从而增加I类错误率。

**Method:** 提出了一种基于两个子集边界点的新方法，用于推导解析p值，以进行显著性量化。

**Result:** 实验表明，与几种经典的双样本检验方法相比，所提出的双簇检验能够显著降低I类错误率。

**Conclusion:** 所提出的双簇检验能够有效解决聚类分析中I类错误率膨胀的问题，并在实际应用中得到验证。

> **ai_Abstract:** 本研究提出了一种新的双簇检验方法，用于解决聚类分析中传统双样本检验面临的I类错误率膨胀问题。该方法基于两个样本子集之间的边界点，能够推导出解析p值以进行显著性量化。实验结果表明，该方法在降低I类错误率方面优于经典双样本检验方法，并在可解释聚类和层次聚类等实际应用中得到了验证。

> **摘要翻译:** 聚类分析是统计学和机器学习中的一个基本研究问题。在许多现代聚类方法中，我们需要确定样本的两个子集是否来自同一簇。由于这些子集通常由某些聚类过程生成，因此在这种情况下部署经典的双样本检验会产生极小的p值，导致I类错误率膨胀。为了克服这种偏差，我们正式引入了双簇检验问题，并认为它是一个与传统双样本检验完全不同的显著性检验问题。同时，我们提出了一种基于两个子集之间边界点的新方法，用于推导解析p值，以进行显著性量化。对合成数据和真实数据集的实验表明，与几种经典的双样本检验方法相比，所提出的检验能够显著降低I类错误率。更重要的是，通过在基于树的可解释聚类和基于显著性的层次聚类中的应用，进一步验证了这种双簇检验的实际用途。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [534] [Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning](https://arxiv.org/abs/2507.08793)
> *面向风险规避约束强化学习的乐观探索*

*James McCarthy, Radu Marinescu, Elizabeth Daly, Ivana Dusparic* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 风险规避约束强化学习, 乐观探索, Actor-Critic, 置信边界, 奖励-成本权衡

**Comment:** 

> **TL;DR:** 本研究提出了一种名为ORAC的乐观风险规避Actor-Critic方法，通过最大化状态-动作奖励值函数的局部置信上界并最小化风险规避状态-动作成本值函数的局部置信下界来构建探索性策略，以解决风险规避约束强化学习中保守探索导致次优策略的问题。该方法通过动态调整成本权重来鼓励探索不确定区域，从而在满足安全约束的同时最大化奖励。实验结果表明，ORAC在Safety-Gymnasium和CityLearn等任务中显著改善了奖励-成本权衡，并避免了收敛到次优策略。

**AI_Comments:** 该研究提出了一种新颖的探索策略ORAC，有效地解决了RaCRL中的保守探索问题。通过结合置信边界和动态权重调整，ORAC在保证安全性的同时提高了学习效率和策略性能。然而，该方法在处理高维状态空间或复杂约束条件下的扩展性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 风险规避约束强化学习（RaCRL）旨在学习能够最小化由环境固有随机性引起的罕见灾难性约束违反可能性的策略。然而，风险规避通常会导致对环境的保守探索，从而收敛到未能充分最大化奖励甚至无法达成目标的次优策略。

**Method:** 提出了一种名为乐观风险规避Actor-Critic（ORAC）的探索性方法。ORAC通过最大化状态-动作奖励值函数的局部置信上界，同时最小化风险规避状态-动作成本值函数的局部置信下界来构建探索性策略。具体来说，在每一步中，如果成本值超过或低于安全约束值，则分别增加或减少分配给成本的权重，从而鼓励策略探索不确定区域以发现高奖励状态，同时满足安全约束。

**Result:** 实验结果表明，ORAC方法能够防止收敛到次优策略，并在Safety-Gymnasium和CityLearn等各种连续控制任务中显著改善奖励-成本权衡。

**Conclusion:** ORAC方法通过结合乐观探索机制，有效解决了风险规避约束强化学习中的次优策略问题，并在实际应用中取得了更好的奖励-成本权衡。

> **ai_Abstract:** 本研究提出了一种名为ORAC的乐观风险规避Actor-Critic（Optimistic Risk-averse Actor Critic）方法，用于解决风险规避约束强化学习（RaCRL）中的探索效率低下问题。与传统的保守探索策略不同，ORAC通过最大化奖励函数和最小化成本函数的局部置信边界来引导探索，鼓励智能体在探索不确定区域以获取更高奖励的同时，确保满足安全约束。实验证明，ORAC能够有效避免收敛到次优策略，并在多个连续控制任务中显著提升了奖励与成本的平衡。

> **摘要翻译:** 风险规避约束强化学习（RaCRL）旨在学习能够最小化由环境固有随机性引起的罕见灾难性约束违反可能性的策略。通常，风险规避会导致对环境的保守探索，这通常会导致收敛到未能充分最大化奖励，甚至在某些情况下无法达成目标的次优策略。在本论文中，我们提出了一种用于RaCRL的基于探索的方法，称为乐观风险规避Actor-Critic（ORAC），它通过最大化状态-动作奖励值函数的局部置信上界同时最小化风险规避状态-动作成本值函数的局部置信下界来构建探索性策略。具体来说，在每一步中，如果成本值超过或低于安全约束值，则分别增加或减少分配给成本的权重。通过这种方式，策略被鼓励探索环境的不确定区域以发现高奖励状态，同时仍然满足安全约束。我们的实验结果表明，ORAC方法能够防止收敛到次优策略，并在Safety-Gymnasium和CityLearn等各种连续控制任务中显著改善了奖励-成本权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [535] [Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets](https://arxiv.org/abs/2205.07249)
> *Pocket2Mol：基于3D蛋白质口袋的高效分子采样*

*Xingang Peng, Shitong Luo, Jiaqi Guan, Qi Xie, Jian Peng, Jianzhu Ma* | **Category: cs.LG, q-bio.BM** | **Updated: 2025-07-11**

**Keywords:** 分子采样, 蛋白质口袋, 深度生成模型, 图神经网络, E(3)-等变网络

**Comment:** ICML 2022 accepted

> **TL;DR:** Pocket2Mol是一种新的E(3)-等变生成网络，通过考虑蛋白质口袋的结构来生成具有更好结合亲和力、药物相似性和合成可及性的分子。

**AI_Comments:** 该研究提出了一种名为Pocket2Mol的新型分子生成方法，该方法利用E(3)-等变神经网络和图神经网络来考虑3D蛋白质口袋的结构信息，从而生成具有更好药物性质的分子。该方法在解决计算挑战和提高药物设计效率方面具有重要意义，但其在处理复杂蛋白质口袋和大规模数据集上的扩展性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决在考虑蛋白质口袋结构进行药物设计时，在图空间采样或仅考虑原子3D坐标而忽略化学结构细节所带来的根本性计算挑战。

**Method:** Pocket2Mol是一个E(3)-等变的生成网络，包含两个模块：1) 一个捕捉结合口袋原子之间空间和键合关系的新图神经网络；2) 一个新的高效算法，可在不依赖MCMC的情况下，从可处理的分布中采样条件化的新药物候选物。

**Result:** Pocket2Mol生成的分子在结合亲和力、药物相似性和合成可及性方面显著优于其他方法。

**Conclusion:** Pocket2Mol通过结合图神经网络和高效采样算法，能够生成满足蛋白质口袋几何约束并具有优良药物性质的新型药物分子。

> **ai_Abstract:** Pocket2Mol是一种新颖的E(3)-等变生成网络，它通过整合图神经网络和高效采样算法，能够有效地从3D蛋白质口袋结构中采样分子。该模型解决了传统方法在处理几何约束和化学细节方面的不足，实验证明其生成的分子在结合亲和力、药物相似性和合成可及性方面均有显著提升。

> **摘要翻译:** 近年来，深度生成模型在设计新型药物分子方面取得了巨大成功。新的一系列研究表明，通过考虑蛋白质口袋的结构，在提高计算机辅助药物设计的特异性和成功率方面具有巨大潜力。这种设置在采样能够满足口袋施加的多种几何约束的新化学化合物方面，带来了根本性的计算挑战。以前的采样算法要么在图空间采样，要么仅考虑原子的3D坐标，而忽略了键类型和官能团等其他详细化学结构。为了应对这一挑战，我们开发了Pocket2Mol，一个E(3)-等变的生成网络，由两个模块组成：1) 一个新的图神经网络，捕捉结合口袋原子之间的空间和键合关系；2) 一个新的高效算法，从可处理的分布中采样条件化的新药物候选物，而不依赖于MCMC。实验结果表明，从Pocket2Mol采样的分子在结合亲和力以及药物相似性和合成可及性等其他药物性质方面均表现出显著的优越性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [540] [PDE-aware Optimizer for Physics-informed Neural Networks](https://arxiv.org/abs/2507.08118)
> *PDE感知优化器用于物理信息神经网络*

*Hardik Shukla, Manurag Khullar, Vismay Churiwala* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 物理信息神经网络, PDE感知优化器, 梯度对齐, 损失平衡, 稳定性

**Comment:** 

> **TL;DR:** 提出了一种新的PDE感知优化器，通过自适应参数更新来解决物理信息神经网络（PINNs）中的梯度不对齐问题，并在多个PDE基准测试中表现出更平滑的收敛和更低的绝对误差。

**AI_Comments:** 该研究提出的PDE感知优化器在解决PINNs训练中的挑战方面具有创新性，通过自适应梯度更新提高了稳定性和准确性。然而，其在更大规模模型和硬件上的可扩展性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 标准优化器（如Adam）在平衡PINNs中的竞争损失项时遇到困难，尤其是在处理刚性或病态系统时，导致梯度不对齐。此外，二阶优化器（如SOAP）计算成本高昂。

**Method:** 提出了一种PDE感知优化器，该优化器根据每样本PDE残差梯度的方差来调整参数更新，以解决梯度不对齐问题，同时避免了二阶优化器的高计算成本。

**Result:** 与Adam和SOAP相比，PDE感知优化器在1D Burgers、Allen-Cahn和Korteweg-de Vries（KdV）方程的基准测试中，实现了更平滑的收敛和更低的绝对误差，尤其是在存在尖锐梯度区域的情况下。

**Conclusion:** PDE感知优化器通过PDE残差感知自适应性有效地提高了PINNs训练的稳定性。

> **ai_Abstract:** 本研究提出了一种新颖的PDE感知优化器，用于物理信息神经网络（PINNs）。该优化器通过根据每样本PDE残差梯度的方差来调整参数更新，以解决标准优化器在平衡PINNs损失项时遇到的梯度不对齐问题，同时避免了二阶优化器的高计算成本。在1D Burgers、Allen-Cahn和KdV方程上的实验表明，该PDE感知优化器比Adam和SOAP具有更平滑的收敛性和更低的绝对误差，尤其是在存在尖锐梯度的情况下，证明了其在提高PINNs训练稳定性方面的有效性。未来的研究方向包括在更大规模架构和硬件加速器上的扩展。

> **摘要翻译:** 物理信息神经网络（PINNs）已成为一种解决偏微分方程（PDEs）的强大框架，通过将物理约束嵌入损失函数中。然而，像Adam这样的标准优化器在平衡竞争损失项时常常会遇到困难，尤其是在刚性或病态系统。在这项工作中，我们提出了一种PDE感知优化器，该优化器根据每样本PDE残差梯度的方差来调整参数更新。该方法在不产生像SOAP这样的二阶优化器的高昂计算成本的情况下，解决了梯度不对齐问题。我们在1D Burgers、Allen-Cahn和Korteweg-de Vries（KdV）方程上对Adam和SOAP进行了PDE感知优化器的基准测试。在两个PDE上，PDE感知优化器都实现了更平滑的收敛和更低的绝对误差，尤其是在存在尖锐梯度区域的情况下。我们的结果证明了PDE残差感知自适应性在提高PINNs训练稳定性方面的有效性。尽管前景广阔，但在更大规模架构和硬件加速器上的进一步扩展仍然是未来研究的重要方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [545] [Online Pre-Training for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2507.08387)
> *用于离线到在线强化学习的在线预训练*

*Yongjae Shin, Jeonghye Kim, Whiyoung Jung, Sunghoon Hong, Deunsol Yoon, Youngsoo Jang, Geonhyeong Kim, Jongseong Chae, Youngchul Sung, Kanghoon Lee, Woohyung Lim* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 离线到在线强化学习, 在线预训练, 值估计, 分布偏移, OPT

**Comment:** ICML 2025 camera-ready

> **TL;DR:** 该研究提出了一种名为OPT的新方法，通过引入在线预训练阶段来解决离线预训练的强化学习代理在在线微调期间因分布偏移导致的值估计不准确问题。OPT在TD3和SPOT上实现，并在D4RL环境中平均提高了30%的性能。

**AI_Comments:** 这项工作有效地解决了离线到在线强化学习中的一个重要问题，即分布偏移导致的值估计不准确。通过引入“在线预训练”阶段，OPT能够更好地为在线微调做准备，从而在各种环境中实现了显著的性能提升。然而，该方法在计算成本和对超参数的敏感性方面可能存在一些局限性，这有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 离线预训练的强化学习代理在在线微调过程中，由于分布偏移导致的值估计不准确，表现不佳，有时甚至不如随机初始化。

**Method:** 提出了一种名为OPT（Online Pre-Training for Offline-to-Online RL）的新方法，该方法引入了一个新的学习阶段——在线预训练，用于训练一个专门针对有效在线微调的新值函数。

**Result:** 在TD3和SPOT上实现OPT，并在包括MuJoCo、Antmaze和Adroit在内的D4RL环境中的广泛应用中，平均性能提高了30%。

**Conclusion:** OPT通过引入在线预训练阶段，成功解决了离线预训练代理在在线微调中的值估计不准确问题，并在多个环境中实现了显著的性能提升。

> **ai_Abstract:** 这项研究提出了一种名为OPT的新方法，用于解决离线到在线强化学习中的一个关键挑战：离线预训练代理在在线微调过程中由于分布偏移导致的值估计不准确问题。OPT通过引入一个专门的“在线预训练”阶段来训练一个新的值函数，以适应在线微调。实验结果表明，在TD3和SPOT算法上应用OPT，并在D4RL基准测试中的多种环境中进行了评估，平均性能提升了30%，证明了该方法的有效性。

> **摘要翻译:** 离线到在线强化学习（RL）旨在通过离线预训练代理然后通过在线交互进行微调，来整合离线和在线RL的互补优势。然而，最近的研究表明，离线预训练代理在在线微调期间的表现往往不佳，原因是分布偏移导致的值估计不准确，在某些情况下，随机初始化甚至更有效。在本研究中，我们提出了一种新颖的方法，即在线预训练离线到在线强化学习（OPT），该方法专门设计用于解决离线预训练代理中值估计不准确的问题。OPT引入了一个新的学习阶段，即在线预训练，它允许训练一个新的值函数，该函数专门针对有效的在线微调进行了定制。在TD3和SPOT上实现OPT，在包括MuJoCo、Antmaze和Adroit在内的广泛D4RL环境中平均性能提高了30%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [551] [Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry](https://arxiv.org/abs/2503.18114)
> *特征学习超越懒惰-丰富二分法：来自表征几何的见解*

*Chi-Ning Chou, Hang Le, Yichen Wang, SueYeon Chung* | **Category: cs.LG, cs.NE, q-bio.NC** | **Updated: 2025-07-11**

**Keywords:** 特征学习,表征几何,懒惰-丰富二分法,神经网络,学习阶段

**Comment:** This work was published in ICML 2025 and was selected for a spotlight
  presentation

> **TL;DR:** 该研究提出了一种分析框架，通过研究神经网络表示的几何形状来超越传统的“懒惰-丰富”学习二分法。研究表明，随着网络的学习，任务相关的表示流形会解开，其几何形状的变化揭示了超越懒惰-丰富二分法的不同学习阶段和策略，为神经科学和机器学习中的特征学习提供了新的见解。

**AI_Comments:** 该研究提出的基于表征几何的分析框架为理解神经网络中的特征学习提供了一个新颖且有前景的视角。它成功地超越了现有的“懒惰-丰富”二分法的局限性，并揭示了更细致的学习动态。然而，该框架在不同类型的网络架构、损失函数和数据集上的普适性和鲁棒性有待进一步验证。此外，如何将这些几何见解转化为更有效的学习算法或模型设计是未来研究的重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的关于神经网络学习的理论将学习分为“丰富”（主动学习相关特征）和“懒惰”（表现得像随机特征模型）两种模式，但这种二分法忽略了学习算法、网络架构和数据属性等因素造成的学习模式多样性。因此，需要一个更全面的框架来研究特征学习。

**Method:** 提出并通过理论和经验分析了一个新的框架，通过研究神经网络表示的几何形状来分析特征学习。该框架不关注单个学习到的特征，而是关注任务相关的表示流形在学习过程中的演变，并分析其几何变化。

**Result:** 研究表明，任务相关的表示流形在学习过程中会解开，其几何形状的变化揭示了不同于懒惰-丰富二分法的学习阶段和策略。

**Conclusion:** 通过分析表示流形的几何形状，可以超越简单的懒惰-丰富二分法来理解特征学习。这种方法揭示了学习的不同阶段和策略，并为理解神经科学和机器学习中的结构归纳偏差和分布外泛化提供了新的见解。

> **ai_Abstract:** 该研究提出了一种基于表征几何的新框架，用于分析神经网络中的特征学习，超越了传统的“懒惰-丰富”二分法。通过研究任务相关表示流形的演变和几何变化，该方法揭示了不同的学习阶段和策略，为理解神经科学和机器学习中的归纳偏差和泛化提供了新见解。

> **摘要翻译:** 将任务相关信息整合到神经表征中是生物和人工智能系统的一项基本能力。最近的理论将学习分为两种模式：丰富模式，即神经网络主动学习任务相关特征；以及懒惰模式，即神经网络表现得像随机特征模型。然而，这种简单的懒惰-丰富二分法忽略了由学习算法、网络架构和数据属性差异所塑造的特征学习的多样化底层分类。为了解决这个差距，我们引入了一个分析框架，通过神经网络表征的几何形状来研究特征学习。我们不检查单个学习到的特征，而是表征任务相关的表征流形在学习过程中的演变。我们在理论和经验环境中都表明，随着网络的学习，任务相关的流形会解开，流形几何形状的变化揭示了超越懒惰-丰富二分法的不同学习阶段和策略。该框架为神经科学和机器学习中的特征学习提供了新的见解，阐明了神经回路中的结构归纳偏差以及分布外泛化的机制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [558] [One Token to Fool LLM-as-a-Judge](https://arxiv.org/abs/2507.08794)
> *一个令牌愚弄LLM作为裁判*

*Yulai Zhao, Haolin Liu, Dian Yu, S. Y. Kung, Haitao Mi, Dong Yu* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-11**

**Keywords:** LLM作为裁判, 奖励模型, 脆弱性, 数据增强, 鲁棒性

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）作为裁判在评估答案质量方面存在漏洞，可以通过简单的符号或推理提示来操纵，导致错误的奖励。研究人员提出了一种数据增强策略来提高鲁棒性，并发布了一个改进的奖励模型和训练数据。

**AI_Comments:** 这项研究揭示了当前LLM评估方法的一个关键弱点，即对输入格式的敏感性。研究的贡献在于识别并量化了这种脆弱性，并提出了一种实用的缓解策略。然而，未来研究可以进一步探索这种操纵的根本原因，并开发更具理论基础的防御机制。此外，将该方法应用于更广泛的NLP任务和评估场景也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 生成式奖励模型（LLM作为裁判）在强化学习中被广泛用于评估答案质量，但它们对表面上的操纵（如添加特殊符号或推理提示）存在脆弱性，这可能导致错误的奖励，对依赖它们的核心算法（如拒绝采样、偏好优化和RLVR）构成威胁。

**Method:** 研究人员通过在LLM提示中添加非词符号（如“:”或“.”）或推理开启词（如“思考过程：”和“让我们一步一步地解决这个问题。”）来测试LLM作为裁判的脆弱性。为了解决这个问题，他们提出了一种数据增强策略来训练一个更鲁棒的生成式奖励模型。

**Result:** 研究发现，非词符号和推理开启词可以广泛地导致生成式奖励模型给出错误的奖励，这种脆弱性存在于不同的LLM、数据集和提示格式中。通过数据增强策略训练的新的生成式奖励模型显示出显著提高的鲁棒性。

**Conclusion:** 生成式奖励模型（LLM作为裁判）对表面上的操纵非常脆弱，这带来了严重的风险。需要开发更可靠的基于LLM的评估方法。研究人员发布了一个鲁棒的、通用领域的奖励模型和其合成训练数据以供使用。

> **ai_Abstract:** 本研究揭示了大型语言模型（LLM）作为评估者（LLM-as-a-Judge）在评估答案质量时存在显著的安全漏洞。研究发现，通过在提示中添加简单的非词符号（如“:”）或特定的推理短语（如“思考过程：”）可以轻易地诱导LLM给出错误的正面奖励。这种脆弱性普遍存在于各种LLM、数据集和提示格式中，对依赖LLM进行评估的强化学习范式（如RLVR）构成了严重威胁。为解决此问题，研究团队提出了一种数据增强策略，并据此训练了一个鲁棒性更强的奖励模型，同时公开了该模型及训练数据。

> **摘要翻译:** 生成式奖励模型（也称为LLM作为裁判）使用大型语言模型（LLM）来评估答案质量，它们越来越多地被用于可验证奖励的强化学习（RLVR）中。它们通常比僵化的基于规则的度量更受青睐，特别是对于涉及自由格式输出的复杂推理任务。在此范例中，通常会提示LLM将候选答案与地面真实参考进行比较，并分配指示正确性的二元奖励。尽管此比较任务看似简单，但我们发现生成式奖励模型对表面上的操纵表现出令人惊讶的脆弱性：非词符号（例如，“:”或“.”）或推理开启词，如“思考过程：”和“让我们一步一步地解决这个问题。”，通常会导致错误的奖励。我们证明了这种弱点在不同的LLM、数据集和提示格式中普遍存在，对依赖生成式奖励模型的核心算法范例（如拒绝采样、偏好优化和RLVR）构成了严重威胁。为了缓解这个问题，我们引入了一种简单而有效的数据增强策略，并训练了一个具有显著提高的鲁棒性的新的生成式奖励模型。我们的发现强调了对更可靠的基于LLM的评估方法的需求。我们在https://huggingface.co/sarosavo/Master-RM和https://huggingface.co/datasets/sarosavo/Master-RM发布了我们鲁棒的、通用领域的奖励模型及其合成训练数据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [561] [Inference-Time Scaling of Diffusion Language Models with Particle Gibbs Sampling](https://arxiv.org/abs/2507.08390)
> *离散扩散语言模型的推理时间尺度与粒子吉布斯采样*

*Meihua Dang, Jiaqi Han, Minkai Xu, Kai Xu, Akash Srivastava, Stefano Ermon* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 离散扩散模型, 粒子吉布斯采样, 推理时间尺度, 奖励引导生成, 文本生成

**Comment:** 

> **TL;DR:** 本研究提出了一种基于粒子吉布斯采样的推理时间尺度方法，用于离散扩散模型，以在奖励引导的文本生成任务中实现高质量的文本生成，并在固定计算预算下分析了关键权衡因素，实验结果优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的粒子吉布斯采样方法，有效解决了离散扩散模型在推理时可扩展性不足的问题，并在奖励引导的文本生成任务中取得了显著的性能提升。研究还对关键参数进行了细致的权衡分析，为实际应用提供了指导。该方法在提高生成质量和效率方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 离散扩散模型在训练时可扩展性强大，但在推理时可扩展性仍有待探索，尤其是在奖励引导的文本生成场景下。

**Method:** 提出了一种基于粒子吉布斯采样的推理时间尺度方法，该方法利用条件序列蒙特卡洛作为转移机制，迭代地优化完整的扩散轨迹，以生成更接近目标分布的样本，并分析了粒子吉布斯迭代次数、粒子数量、去噪步数和奖励估计成本这四个关键轴的权衡。

**Result:** 所提出的粒子吉布斯采样方法在奖励引导的文本生成任务上持续优于现有的推理时间尺度策略，在不同计算预算下均实现了显著的准确性提升。

**Conclusion:** 粒子吉布斯采样是一种有效的推理时间尺度方法，可以提高离散扩散模型在奖励引导文本生成任务中的性能，并且在计算资源有限的情况下表现出色。

> **ai_Abstract:** 本研究提出了一种新颖的基于粒子吉布斯采样的推理时间尺度方法，用于离散扩散模型，以解决其在推理时可扩展性不足的问题。该方法通过迭代优化多个扩散轨迹，能够生成更高质量的文本，并在奖励引导的文本生成任务中取得了优于现有方法的性能。研究还分析了在固定计算预算下，该方法在粒子吉布斯迭代次数、粒子数量、去噪步数和奖励估计成本等方面的权衡。

> **摘要翻译:** 离散扩散模型已成为语言建模的强大范例，其训练时间扩展性可与自回归模型相媲美。然而，离散扩散模型的推理时间扩展性仍然相对未被充分探索。本研究着眼于在奖励引导的设置中，通过采样方法从离散扩散模型实现高质量的文本生成。我们提出了一种新颖的基于粒子吉布斯采样的推理时间尺度方法，用于离散扩散模型。粒子吉布斯采样算法利用条件序列蒙特卡洛作为其转移机制，迭代地优化完整的扩散轨迹。这个过程确保了优化后的样本能够逐步改进并趋近于奖励加权的目标分布。与现有的、通常仅限于单一扩散轨迹的推理时间尺度方法不同，我们的方法利用了跨越多个轨迹的迭代优化。在此框架内，我们进一步分析了在固定计算预算下，推理时间尺度优化的四个关键维度：粒子吉布斯迭代次数、粒子数量、去噪步数和奖励估计成本之间的权衡。实验结果表明，我们的方法在奖励引导的文本生成任务上持续优于先前的推理时间尺度策略，在不同的计算预算下均实现了显著的准确性提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [563] [Convergence of Natural Policy Gradient for a Family of Infinite-State Queueing MDPs](https://arxiv.org/abs/2402.05274)
> *无限状态排队MDP族自然策略梯度收敛性*

*Isaac Grosof, Siva Theja Maguluri, R. Srikant* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 自然策略梯度,无限状态MDP,排队系统,收敛速率,MaxWeight策略

**Comment:** 32 pages

> **TL;DR:** 该论文首次证明了自然策略梯度（NPG）算法在无限状态排队马尔可夫决策过程（MDP）上的收敛性，并在使用MaxWeight策略作为初始值时，达到了O(1/T)的收敛速率。

**AI_Comments:** 这项工作在理论上具有重要意义，因为它首次为在无限状态空间中运行的NPG算法提供了收敛保证，这对于实际应用中处理复杂系统至关重要。然而，实际应用中的性能仍需通过实验来验证，特别是对于“足够好的初始策略”这一条件的敏感性有待进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于自然策略梯度（NPG）算法收敛性的研究仅限于有限状态空间，而许多实际的排队系统可以被建模为无限状态MDP，因此需要研究在无限状态空间下的NPG算法收敛性。

**Method:** 通过对MaxWeight策略初始化下的NPG算法进行状态依赖的相对价值函数界限分析，证明了其收敛速率。

**Result:** 证明了使用MaxWeight策略作为初始值的NPG算法在无限状态排队MDP上具有O(1/T)的收敛速率。

**Conclusion:** 该研究首次为无限状态平均奖励MDP（包括排队系统）的NPG算法提供了收敛速率界限，并且该结果可以推广到满足特定结构假设的任何可数无限MDP，前提是初始策略足够好。

> **ai_Abstract:** 本研究解决了自然策略梯度（NPG）算法在无限状态排队马尔可夫决策过程（MDP）中的收敛性问题。论文首次证明了，当使用MaxWeight策略作为初始值时，NPG算法能够以O(1/T)的速率收敛。这一成果不仅填补了现有研究在无限状态空间下的空白，而且其方法和结论可以推广到更广泛的可数无限MDP场景，前提是满足一定的结构假设和初始策略的质量。

> **摘要翻译:** 各种排队系统可以自然地建模为无限状态马尔可夫决策过程（MDP）。在强化学习（RL）的背景下，已经开发了各种算法来学习和优化这些MDP。许多流行的基于策略梯度的学习算法，如自然Actor-Critic、TRPO和PPO的核心是自然策略梯度（NPG）策略优化算法。这些RL算法的收敛结果依赖于NPG算法的收敛结果。然而，目前关于NPG算法收敛性的所有结果都仅限于有限状态空间。

我们研究了一类通用的排队MDP，并证明了NPG算法的O(1/T)收敛速率，前提是NPG算法使用MaxWeight策略进行初始化。这是NPG算法在通用类别的无限状态平均奖励MDP上的第一个收敛速率界限。此外，我们的结果可以应用于排队设置之外的任何可数无限MDP，只要满足某些温和的结构假设，并给定一个足够好的初始策略。我们结果的关键在于对NPG算法迭代策略所达到的相对价值函数的依赖于状态的界限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [564] [Quasi-Random Physics-informed Neural Networks](https://arxiv.org/abs/2507.08121)
> *伪随机物理信息神经网络*

*Tianchi Yu, Ivan Oseledets* | **Category: cs.LG, cs.AI, cs.NA, math.NA** | **Updated: 2025-07-10**

**Keywords:** 物理信息神经网络, 伪随机采样, 低差异序列, 偏微分方程, 收敛率

**Comment:** 

> **TL;DR:** 本研究提出伪随机物理信息神经网络（QRPINNs），使用低差异序列代替随机采样点来解决偏微分方程（PDE），并在高维问题上表现优于传统PINNs和自适应采样方法。

**AI_Comments:** 这项研究提出了一种新颖的采样方法，用于提高物理信息神经网络的性能，特别是在高维问题上。使用低差异序列代替随机采样是一个有前景的方向，理论和实验结果都支持其有效性。然而，该方法在实际应用中的计算成本和可扩展性仍需进一步考察。

<details>
  <summary>Details</summary>

**Motivation:** 传统物理信息神经网络（PINNs）在解决偏微分方程时，其性能对采样点的选择敏感。为了提高性能，特别是在高维问题上，需要改进采样策略。

**Method:** 提出伪随机物理信息神经网络（QRPINNs），使用低差异序列（quasi-random sequences）代替从域中随机抽取的点进行采样。

**Result:** 理论上，QRPINNs比PINNs具有更好的收敛率。实验证明，QRPINNs在高维偏微分方程问题上显著优于PINNs和一些代表性的自适应采样方法，并且与自适应采样结合使用可以进一步提高性能。

**Conclusion:** QRPINNs通过使用低差异序列进行采样，提高了物理信息神经网络解决偏微分方程的性能，尤其在高维问题上效果显著，并可与自适应采样结合以获得更好效果。

> **ai_Abstract:** 本研究提出了一种名为伪随机物理信息神经网络（QRPINNs）的新方法，用于求解偏微分方程（PDE）。与传统的物理信息神经网络（PINNs）依赖于随机采样不同，QRPINNs采用低差异序列进行采样，这种方法在处理高维问题时表现出优越性。研究表明，QRPINNs在理论上具有更快的收敛速度，并且在实践中，尤其是在高维PDE问题上，其性能明显优于标准的PINNs和现有的自适应采样技术。此外，将QRPINNs与自适应采样相结合可以进一步提升其性能。

> **摘要翻译:** 物理信息神经网络在通过将物理约束整合到神经网络训练中来求解偏微分方程方面显示出潜力，但其性能对采样点的选择敏感。基于拟蒙特卡洛方法在高维问题中的出色表现，本文提出了拟随机物理信息神经网络（QRPINNs），该方法使用低差异序列进行采样，而不是直接从域中随机采样点。理论上，QRPINNs已被证明比PINNs具有更好的收敛率。实验上，实验证明QRPINNs的性能显著优于PINNs和一些代表性的自适应采样方法，尤其是在高维偏微分方程方面。此外，将QRPINNs与自适应采样相结合可以进一步提高性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [576] [SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations](https://arxiv.org/abs/2507.08707)
> *SPLASH！从次优分层演示中学习长视野对抗性任务的样本高效偏好逆强化学习*

*Peter Crowley, Zachary Serlin, Tyler Paine, Makai Mann, Michael Benjamin, Calin Belta* | **Category: cs.LG, cs.RO** | **Updated: 2025-07-11**

**Keywords:** 逆强化学习, 次优演示, 长视野任务, 对抗性任务, 偏好学习

**Comment:** 

> **TL;DR:** 该研究提出了一种名为SPLASH的新方法，用于从次优演示中学习复杂机器人任务，特别适用于长视野和对抗性任务，并在模拟和真实世界实验中证明了其优越性。

**AI_Comments:** SPLASH在处理次优演示和长视野对抗性任务方面取得了重要进展，克服了现有IRL方法的关键局限性。其在模拟和真实世界实验中的成功应用，特别是sim-to-real迁移能力，展示了其在实际机器人任务中的巨大潜力。然而，对于该方法在更广泛的机器人任务和不同类型的次优演示上的泛化能力仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有逆强化学习方法通常需要专家演示，或者在处理次优演示时无法应对长视野或对抗性任务，这限制了其在实际机器人应用中的能力。

**Method:** 提出了一种名为SPLASH（Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations）的新方法，该方法能够从次优分层演示中学习长视野对抗性任务。

**Result:** SPLASH在模拟的海洋夺旗任务和真实世界的无人水面载具实验中表现出色，显著优于现有的从次优演示中学习奖励的方法。

**Conclusion:** SPLASH成功地将从次优演示中学习的能力扩展到了长视野和对抗性任务，并在模拟和真实世界实验中得到了验证，克服了现有方法的局限性。

> **ai_Abstract:** 本研究提出了SPLASH，一种样本高效的偏好逆强化学习方法，专门用于从次优分层演示中学习长视野的对抗性任务。该方法克服了现有IRL技术在处理次优演示和复杂任务场景时的局限性。通过在模拟的海洋夺旗任务和真实的无人水面载具实验中进行验证，SPLASH被证明在奖励学习方面显著优于当前最先进的技术，并成功实现了模拟到现实的迁移。

> **摘要翻译:** 逆强化学习（IRL）提出了一种从人类演示中学习复杂机器人任务的强大范例。然而，大多数方法都假设可以获得专家演示，而这通常并非事实。那些允许演示次优性的方法并未针对长视野目标或对抗性任务进行设计。许多理想的机器人能力属于其中一类或两类，从而凸显了IRL在生产现场就绪的机器人代理方面的能力存在严重缺陷。我们引入了用于长视野对抗性任务的样本高效偏好逆强化学习（SPLASH），它将从次优演示中学习的现有技术提升到了长视野和对抗性设置。我们在模拟的海洋夺旗任务中对SPLASH进行了经验验证，并通过在自主无人水面载具上的模拟到真实转换实验证明了其在现实世界的适用性。我们证明了我们提出的方法使SPLASH在从次优演示中学习奖励方面显著优于现有技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [577] [RTNinja: a generalized machine learning framework for analyzing random telegraph noise signals in nanoelectronic devices](https://arxiv.org/abs/2507.08424)
> *RTNinja：用于分析纳米电子器件中随机电报噪声信号的通用机器学习框架*

*Anirudh Varanasi, Robin Degraeve, Philippe Roussel, Clement Merckling* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 随机电报噪声, 机器学习, 纳米电子器件, 无监督分析, RTNinja

**Comment:** 

> **TL;DR:** RTNinja是一个自动化的机器学习框架，用于分析纳米电子器件中的随机电报噪声信号，能够识别隐藏的噪声源及其特征。

**AI_Comments:** 该研究提出了一种新颖的、自动化的机器学习框架RTNinja，用于分析纳米电子器件中的随机电报噪声。其主要优势在于能够处理复杂、含噪的数据集，并且无需预先了解系统信息，这克服了传统方法的局限性。框架的模块化设计和通过蒙特卡洛模拟进行的广泛验证增加了其可靠性和通用性。然而，该方法在实际器件上的部署和性能表现仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统随机电报噪声分析方法存在局限性，需要手动干预且假设受限，难以处理复杂且含噪的数据集。

**Method:** RTNinja框架包含两个模块：LevelsExtractor（使用贝叶斯推理和模型选择进行信号去噪和离散化）和SourcesMapper（通过概率聚类和优化来推断源配置）。

**Result:** 在7000个模拟数据集上，RTNinja在信号重建、源幅度提取和活动模式识别方面表现出高保真度和准确性。

**Conclusion:** RTNinja是一个稳健、可扩展且与器件无关的随机电报噪声表征工具，可用于大规模统计基准测试、面向可靠性的技术鉴定、预测性故障建模以及下一代纳米电子器件的器件物理学探索。

> **ai_Abstract:** 本文提出了一种名为RTNinja的通用机器学习框架，用于自动化分析纳米电子器件中的随机电报噪声（RTN）信号。RTNinja能够无需先验知识即可解卷积复杂信号，识别隐藏的单个噪声源的数量和特征。该框架由LevelsExtractor（用于信号去噪和离散化）和SourcesMapper（用于推断源配置）组成。通过蒙特卡洛模拟器进行的广泛测试表明，RTNinja在各种条件下都能提供高保真度的信号重建和准确的源参数提取，是一种适用于下一代纳米电子器件的稳健、可扩展且与器件无关的工具。

> **摘要翻译:** 随机电报噪声是纳米电子器件中普遍存在的变异现象，由缺陷位点的随机载流子交换引起，并严重影响器件的可靠性和性能。传统的分析技术通常依赖于严格的假设或手动干预，这限制了它们在复杂、含噪数据集上的应用。在这里，我们介绍了RTNinja，一个通用的、完全自动化的机器学习框架，用于随机电报噪声信号的无监督分析。RTNinja能够解卷积复杂信号，识别隐藏的单个源的数量和特征，而无需预先了解系统。该框架包含两个模块化组件：LevelsExtractor，它使用贝叶斯推理和模型选择来去噪和离散化信号；SourcesMapper，它通过概率聚类和优化来推断源配置。为了评估性能，我们开发了一个蒙特卡洛模拟器，该模拟器生成跨越广泛信噪比和源复杂度的标记数据集；在超过7000个此类数据集中，RTNinja在信号重建和源幅度与活动模式的准确提取方面始终如一地表现出高保真度。我们的结果表明，RTNinja为随机电报噪声表征提供了一个稳健、可扩展且与器件无关的工具，能够实现下一代纳米电子器件的大规模统计基准测试、面向可靠性的技术鉴定、预测性故障建模和器件物理学探索。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [584] [Physics-Informed Neural Networks with Hard Nonlinear Equality and Inequality Constraints](https://arxiv.org/abs/2507.08124)
> *硬约束非线性等式和不等式物理信息神经网络*

*Ashfaq Iftakher, Rahul Golder, M. M. Faruque Hasan* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 物理信息神经网络, 硬约束, KKT条件, 非线性约束, 可靠混合建模

**Comment:** 20 pages, 8 figures

> **TL;DR:** KKT-Hardnet是一种新的PINN架构，通过求解KKT条件将约束条件强制满足到机器精度，解决了传统PINN无法严格满足约束的问题，在准确性和约束满足方面优于传统方法。

**AI_Comments:** 该研究解决了PINN在处理硬约束问题上的关键挑战，通过引入KKT条件和特定的数学变换实现了约束的严格满足，具有重要的理论和应用价值。但其计算复杂度以及在大规模问题上的扩展性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统PINN无法严格满足约束，这在工程系统中可能导致模型预测的可靠性和一致性下降。

**Method:** 开发了KKT-Hardnet架构，利用求解距离最小化问题的KKT条件将解投影到可行域，并对非线性KKT条件进行重构，使其成为稀疏的线性及指数项组成的系统，使投影可微分。

**Result:** KKT-Hardnet在测试问题和实际化学过程模拟中，相比多层感知机和PINN，实现了更高的准确性和严格的约束满足。

**Conclusion:** 该方法实现了将领域知识集成到机器学习中，以实现复杂系统的可靠混合建模。

> **ai_Abstract:** 本文提出了一种名为KKT-Hardnet的物理信息神经网络（PINN）新架构，用于强制满足硬性非线性等式和不等式约束。通过求解距离最小化问题的Karush-Kuhn-Tucker（KKT）条件，KKT-Hardnet能够将解投影到可行域，并达到机器精度。该方法通过对数-指数变换重构了非线性KKT条件，构建了一个可微分的稀疏系统。实验结果表明，KKT-Hardnet在准确性和约束满足方面优于传统方法，为复杂系统的可靠混合建模提供了新的途径。

> **摘要翻译:** 传统的物理信息神经网络（PINN）不能保证严格满足约束。这在工程系统中是一个问题，因为轻微违反控制定律会严重降低模型预测的可靠性和一致性。在这项工作中，我们开发了一种名为KKT-Hardnet的PINN架构，它可以将线性和非线性的等式和不等式约束强制满足到机器精度。它利用通过求解距离最小化问题的Karush-Kuhn-Tucker（KKT）条件将解投影到可行域。此外，我们利用对数-指数变换重新构造了非线性KKT条件，构建了一个仅包含线性和指数项的通用稀疏系统，从而使投影可微分。我们将KKT-Hardnet应用于测试问题和实际的化学过程模拟。与多层感知机和PINN相比，KKT-Hardnet实现了更高的准确性和严格的约束满足。这种方法实现了将领域知识集成到机器学习中，以实现复杂系统的可靠混合建模。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [586] [The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?](https://arxiv.org/abs/2507.08802)
> *因果抽象足以实现机械可解释性吗？非线性表征困境*

*Denis Sutter, Julian Minder, Thomas Hofmann, Tiago Pimentel* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 因果抽象, 机械可解释性, 非线性表征, 对齐映射, 线性表征假设

**Comment:** 42 pages, 17 figures, code available in
  github.com/densutter/non-linear-representation-dilemma

> **TL;DR:** 该论文探讨了因果抽象在解释机器学习模型中的作用，发现如果允许任意的非线性映射，因果抽象会变得毫无意义。研究表明，即使模型无法解决任务，也可以实现完美的映射，这揭示了在不施加线性约束的情况下，映射复杂性和准确性之间的权衡问题。因此，作者认为仅靠因果抽象不足以实现机械可解释性，需要对模型如何编码信息做出假设。

**AI_Comments:** 该研究对因果抽象在机器学习可解释性中的应用提出了深刻的质疑，指出了在去除线性约束后可能出现的理论和实践困境。通过理论证明和实证研究相结合，作者有力地论证了仅有因果抽象是不够的，强调了模型信息编码方式的重要性。这项工作对于未来可解释性方法的发展具有重要的启示意义，但也可能引发关于如何在实践中有效平衡映射复杂性和准确性的进一步讨论。

<details>
  <summary>Details</summary>

**Motivation:** 因果抽象被用于解释机器学习模型的决策过程，但现有研究多采用线性映射。然而，因果抽象的定义并不强制要求线性映射。本文旨在批判性地审视因果抽象概念，并考虑任意强大的对齐映射。

**Method:** 本文通过理论证明和实证研究来审视因果抽象。理论上，在合理假设下，证明了任何神经网络都可以映射到任何算法，使得无限制的因果抽象变得毫无意义。实证上，通过实验证明了即使在无法解决任务的模型上，也可以实现完美的映射，例如在随机初始化的语言模型上，间接宾语识别任务的对齐映射准确率达到100%。

**Result:** 在合理假设下，任何神经网络都可以映射到任何算法，这使得无限制的因果抽象变得毫无意义且缺乏信息量。实验表明，即使模型无法解决任务，也能实现完美的映射，例如在随机初始化的语言模型上，间接宾语识别任务的对齐映射准确率达到100%。

**Conclusion:** 因果抽象本身不足以实现机械可解释性，因为在去除线性约束后，它会变得毫无意义。为了使因果抽象有意义，需要对模型如何编码信息做出假设，并研究这种假设与因果抽象之间的联系。

> **ai_Abstract:** 本研究探讨了因果抽象在机器学习可解释性中的作用。作者认为，如果允许任意的非线性映射，因果抽象的概念就会变得毫无意义。通过理论证明和实验，研究表明即使模型无法解决任务，也可以实现完美的映射，这揭示了在不施加线性约束的情况下，映射的复杂性和准确性之间存在难以平衡的权衡。因此，论文得出结论，仅靠因果抽象不足以实现机械可解释性，还需要对模型如何编码信息做出假设。

> **摘要翻译:** 因果抽象最近因其能够揭示机器学习模型不透明的决策过程而广受欢迎；简而言之，如果存在一个函数可以实现它们之间的映射，那么一个神经网络就可以被抽象为一个更高级别的算法。值得注意的是，大多数可解释性论文将这些映射实现为线性函数，其动机是线性表征假设：即特征在线性地编码在模型的表征中。然而，因果抽象的定义并不需要这种线性约束。在本研究中，我们通过考虑任意强大的对齐映射来批判性地审视因果抽象的概念。特别是，我们证明在合理假设下，任何神经网络都可以映射到任何算法，这使得这种无限制的因果抽象定义变得毫无意义且缺乏信息量。我们用实证证据来补充这些理论发现，证明即使在无法解决实际任务的模型上，也可以完美地将模型映射到算法；例如，在对随机初始化的语言模型进行的实验中，我们的对齐映射在间接宾语识别任务上达到了100%的交换干预准确率。这就引发了非线性表征困境：如果我们放宽因果抽象分析中对齐映射的线性约束，我们就无法在这些映射的复杂性与准确性之间的固有权衡进行原则性的平衡。总而言之，这些结果为我们标题中的问题提供了一个答案：因果抽象不足以实现机械可解释性，因为它在没有关于模型如何编码信息假设的情况下变得空洞。研究这种信息编码假设与因果抽象之间的联系应该会带来令人兴奋的未来工作。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [587] [Graph Convolutional Branch and Bound](https://arxiv.org/abs/2406.03099)
> *图卷积分支定界*

*Lorenzo Sciandra, Roberto Esposito, Andrea Cesare Grosso, Laura Sacerdote, Cristina Zucca* | **Category: cs.LG, math.OC, 68T07, 90C27** | **Updated: 2025-07-10**

**Keywords:** 图卷积神经网络, 分支定界, 旅行商问题, 组合优化, 启发式学习

**Comment:** Submitted to European Journal of Operational Research

> **TL;DR:** 提出了一种名为图卷积分支定界（Graph Convolutional Branch and Bound）的混合方法，该方法使用图卷积神经网络（GCN）和无监督学习策略来学习最优性分数，以指导分支定界算法解决旅行商问题等NP难题，并在探索节点数量和计算时间上取得了显著改进。

**AI_Comments:** 该研究将深度学习应用于组合优化中的分支定界算法，通过学习最优性分数来指导搜索，并在旅行商问题上取得了显著的性能提升。其创新的无监督训练策略使得模型能够泛化到不同大小的图，这在实际应用中具有重要意义。然而，该方法在其他NP难题上的普适性和在更复杂图结构上的表现仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统精确算法在解决NP难题时依赖启发式标准来指导可行解的探索。本研究旨在利用神经网络学习信息性启发式方法，特别是最优性分数，以更有效地遍历解空间。

**Method:** 提出了一种混合方法，将图卷积神经网络（GCN）与现有的分支定界求解器（如1-tree分支定界和Concorde）相结合。该方法使用GCN学习最优性分数，并采用新颖的无监督训练策略，使其能够泛化到不同大小的图，而无需标记数据。

**Result:** 实验结果表明，所提出的方法能够显著减少被探索的分支定界节点数量和整体计算时间，证明了其有效性。

**Conclusion:** 图卷积分支定界方法通过利用神经网络学习的最优性分数，能够有效地指导分支定界算法，在解决旅行商问题等NP难题方面取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种图卷积分支定界（Graph Convolutional Branch and Bound）方法，该方法利用图卷积神经网络学习最优性分数，以改进分支定界算法在解决旅行商问题等NP难题中的效率。通过无监督训练策略，该方法能够泛化到不同大小的图，并在实验中显著减少了计算时间和搜索的节点数量。

> **摘要翻译:** 本文探讨了将深度学习模型整合到组合优化流程中，特别是针对NP难题。此类问题的传统精确算法通常依赖启发式标准来指导可行解的探索。在本工作中，我们提出使用神经网络来学习信息性启发式方法——最值得注意的是，一个最优性分数，用于估计解与最优解的接近程度。该分数用于评估分支定界框架内的节点，从而能够更有效地遍历解空间。针对旅行商问题，我们描述了两种精确求解器——1-tree分支定界和Concorde——并引入了一种名为图卷积分支定界（Graph Convolutional Branch and Bound）的混合方法，该方法通过图卷积神经网络和新颖的无监督训练策略来增强这些求解器，该策略有助于泛化到不同大小的图，而无需标记数据。实验结果证明了所提出方法的有效性，显示了被探索的分支定界节点数量和整体计算时间的显著减少。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [593] [KGRAG-Ex: Explainable Retrieval-Augmented Generation with Knowledge Graph-based Perturbations](https://arxiv.org/abs/2507.08443)
> *知识图谱增强的可解释检索增强生成：基于知识图谱的扰动*

*Georgios Balanos, Evangelos Chasanis, Konstantinos Skianis, Evaggelia Pitoura* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 检索增强生成,知识图谱,可解释性,扰动方法,事实准确性

**Comment:** 

> **TL;DR:** 该研究提出了一种名为KGRAG-Ex的检索增强生成（RAG）系统，利用知识图谱（KG）来提高响应的事实准确性和可解释性。它通过将KG中的实体和关系转化为伪段落来指导检索，并使用基于扰动的方法来解释生成答案过程中KG组件的影响。

**AI_Comments:** 该研究提出了一种利用知识图谱和扰动方法来增强RAG系统可解释性的创新方法。通过将结构化知识图谱信息融入检索过程并量化其对生成结果的影响，该研究为构建更透明、更值得信赖的AI系统提供了有价值的见解。然而，构建领域特定的知识图谱可能需要大量的人工和资源投入，这可能是该方法在实际应用中的一个潜在限制。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强生成（RAG）系统虽然能增强语言模型，但在可解释性方面存在挑战，尤其是在检索依赖于非结构化文本时。知识图谱（KG）通过提供结构化、富含语义的实体及其关系表示，为实现透明的检索路径和可解释的推理提供了解决方案。

**Method:** 提出了一种名为KGRAG-Ex的RAG系统，该系统利用领域特定的知识图谱（KG）来提高事实准确性和可解释性。该系统首先通过基于提示的信息提取构建KG，然后识别用户查询相关的实体和语义路径。这些路径被转换为伪段落，以指导语料库检索。为了提高可解释性，研究人员采用了基于扰动的方法来评估特定KG组件对生成答案的影响。

**Result:** 进行了一系列实验，分析了系统对不同扰动方法的敏感性、图组件重要性与其结构位置的关系、语义节点类型的影响，以及图指标如何与解释过程中的组件影响相对应。

**Conclusion:** KGRAG-Ex通过利用知识图谱和基于扰动的方法，在提高检索增强生成系统的可解释性和事实准确性方面取得了进展，并为理解和改进这些系统提供了分析框架。

> **ai_Abstract:** KGRAG-Ex是一种新颖的检索增强生成（RAG）系统，它利用知识图谱（KG）来克服传统RAG方法在可解释性方面的不足。通过将KG中的结构化信息转换为伪段落来指导检索，并采用基于扰动的方法来评估不同KG组件对最终输出的影响，KGRAG-Ex不仅提高了响应的事实准确性，还增强了推理过程的透明度和可解释性。研究通过实验验证了该方法在敏感性、组件重要性与结构位置关系、节点类型影响以及图指标与解释过程对应关系等方面的有效性。

> **摘要翻译:** 检索增强生成（RAG）通过将响应与外部信息相结合来增强语言模型，但可解释性仍然是一个关键挑战，尤其是在检索依赖于非结构化文本时。知识图谱（KG）通过引入实体及其关系结构化、富含语义的表示来提供解决方案，从而实现透明的检索路径和可解释的推理。在本工作中，我们提出了KGRAG-Ex，一个通过利用通过基于提示的信息提取构建的领域特定KG来提高事实准确性和可解释性的RAG系统。给定用户查询，KGRAG-Ex识别图中的相关实体和语义路径，然后将它们转换为伪段落：自然语言表示的图子结构，用于指导语料库检索。为了提高可解释性并支持推理透明度，我们结合了基于扰动的方法来评估特定KG组件对生成答案的影响。我们进行了一系列实验来分析系统对不同扰动方法的敏感性、图组件重要性与其结构位置的关系、语义节点类型的影响以及图指标如何对应于解释过程中的组件影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [607] [ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction](https://arxiv.org/abs/2507.08153)
> *ALCo-FM：用于事故预测的自适应长上下文基础模型*

*Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** ALCo-FM, 交通事故预测, 长上下文模型, 多模态推理, 基础模型

**Comment:** 

> **TL;DR:** ALCo-FM是一个自适应长上下文基础模型，通过动态选择上下文窗口和融合多模态数据来进行交通事故风险预测，取得了优于20多种基线模型的性能。

**AI_Comments:** 该研究提出了一种创新的自适应长上下文基础模型ALCo-FM，用于交通事故预测。模型在处理长上下文和融合多模态数据方面具有优势，并通过实验证明了其优越的性能。然而，实际应用中模型的泛化能力和对不同城市交通环境的适应性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 交通事故虽然罕见但影响重大，需要长上下文多模态推理来进行准确的风险预测。

**Method:** 该模型引入了一个波动性预评分来动态选择上下文窗口，并通过浅层交叉注意力对多模态数据进行编码和融合。随后，在H3六边形网格上应用局部GAT层和BigBird风格的稀疏全局Transformer，并结合蒙特卡洛Dropout来提高置信度。

**Result:** 在来自15个美国城市的数据上训练，并使用类别加权损失来处理标签不平衡问题，ALCo-FM达到了0.94的准确率，0.92的F1分数和0.04的ECE，在大型城市风险预测方面优于20多个最先进的基线模型。

**Conclusion:** ALCo-FM模型在交通事故风险预测方面表现出色，其自适应长上下文处理能力和多模态融合方法使其能够超越现有技术。

> **ai_Abstract:** ALCo-FM是一种新颖的自适应长上下文基础模型，旨在提高交通事故风险预测的准确性。它通过波动性预评分动态选择上下文窗口，并利用浅层交叉注意力融合多模态数据。该模型结合了GAT和BigBird Transformer，并采用蒙特卡洛Dropout来增强预测的可靠性。在15个美国城市的真实数据上进行训练和微调后，ALCo-FM在准确率、F1分数和ECE方面均表现出色，显著优于现有基线。

> **摘要翻译:** 交通事故是罕见的，但却是影响重大的事件，需要长上下文的多模态推理来进行准确的风险预测。在本文中，我们介绍了一种统一的自适应长上下文基础模型ALCo-FM，它计算波动性预评分以动态选择上下文窗口，并通过浅层交叉注意力对这些多模态数据进行编码和融合。在H3六边形网格上跟随局部GAT层和BigBird风格的稀疏全局Transformer，并结合蒙特卡洛Dropout来提高置信度，该模型产生了优越的、校准良好的预测。在来自15个美国城市的数据上进行训练，并使用类别加权损失来对抗标签不平衡，然后在未覆盖的城市上进行最少数据微调，ALCo-FM达到了0.94的准确率，0.92的F1分数和0.04的ECE，在大型城市风险预测方面优于20多个最先进的基线。代码和数据集可在以下网址获得：https://github.com/PinakiPrasad12/ALCo-FM

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [608] [Space filling positionality and the Spiroformer](https://arxiv.org/abs/2507.08456)
> *空间填充位置性和Spiroformer*

*M. Maurin, M. Á. Evangelista-Alvarado, P. Suárez-Serrato* | **Category: cs.LG, cs.AI, math.DG, math.DS, math.SG** | **Updated: 2025-07-11**

**Keywords:** Transformer, 几何数据, 空间填充曲线, Spiroformer, 二维球面

**Comment:** 9 pages, 5 figures. To appear in Geometric Science of Information
  2025

> **TL;DR:** 提出一种将空间填充曲线应用于Transformer模型以处理几何数据的方法，并以Spiroformer为例。

**AI_Comments:** 这项工作为处理几何数据提供了一种新颖的方法，通过将空间填充曲线的概念引入Transformer架构，解决了全局顺序问题。Spiroformer是该方法的首次实验性展示，为未来在几何深度学习领域的研究开辟了道路。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型在处理序列数据方面表现优异，但在几何域（如流形）中缺乏明确的全局顺序，这限制了其应用。

**Method:** 提出一种解决方案，让注意力头遵循空间填充曲线。作为第一个实验示例，提出了Spiroformer模型，该模型遵循二维球面上的极坐标螺旋线。

**Result:** 提出了Spiroformer模型，这是一个遵循二维球面上的极坐标螺旋线的Transformer模型。

**Conclusion:** Transformer模型可以通过遵循空间填充曲线来推广到几何域，Spiroformer是该方法的首次实验性展示。

> **ai_Abstract:** 该研究提出了一种新颖的Transformer模型变体，称为Spiroformer，它利用空间填充曲线（具体来说是二维球面上的极坐标螺旋线）来解决几何数据处理中的全局顺序问题，从而扩展了Transformer在非序列数据上的应用。

> **摘要翻译:** Transformer在处理序列数据方面表现出色。将Transformer模型推广到几何域（如流形）时，我们遇到了缺乏明确全局顺序的问题。我们提出了一种解决方案，让注意力头遵循空间填充曲线。作为第一个实验示例，我们提出了Spiroformer，一个遵循二维球面上的极坐标螺旋线的Transformer。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [610] [PAC-Bayes Analysis for Recalibration in Classification](https://arxiv.org/abs/2406.06227)
> *PAC-贝叶斯分析在校准中的应用*

*Masahiro Fujisawa, Futoshi Futami* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** PAC-贝叶斯, 校准误差, 泛化性能, 多类分类, 重校准算法

**Comment:** Accepted by the 42nd International Conference on Machine Learning
  (ICML2025), 38 pages, 8 figures

> **TL;DR:** 该研究使用PAC-贝叶斯框架分析了多类分类校准误差的泛化界限，并提出了一种泛化感知校准算法，该算法在实验中表现优于现有方法。

**AI_Comments:** 该研究在理论和实践上都具有重要意义。理论上，它扩展了校准误差的分析范围，解决了多类分类的难题，并提供了可优化的泛化误差上界。实践中，提出的算法在多个数据集和模型上都取得了性能提升，为提高模型校准的可靠性提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的关于二元分类校准误差理论分析存在局限性，无法满足多类分类等实际应用的需求，同时许多参数化重校准算法缺乏泛化性能的理论保证。

**Method:** 使用PAC-贝叶斯框架对校准误差进行泛化分析，推导出校准背景下泛化误差的首个可优化上界，并基于此理论提出一种泛化感知重校准算法。

**Result:** 提出的算法在多个基准数据集和模型上，提高了基于高斯过程的重校准性能。

**Conclusion:** PAC-贝叶斯分析为校准误差的泛化提供了一个新的理论视角，并促成了一种更优的重校准算法的开发。

> **ai_Abstract:** 本研究针对机器学习模型校准中的泛化性能问题，利用PAC-贝叶斯框架分析了多类分类校准误差，得到了首个可优化的泛化误差上界，并据此提出了一种新的泛化感知校准算法，实验证明该算法在多项任务上均优于现有方法。

> **摘要翻译:** 非参数估计使用均匀宽度分箱是评估机器学习模型校准性能的标准方法。然而，现有关于分箱引起的偏差的理论分析仅限于二元分类，与多类分类等实际应用之间存在显著差距。此外，许多参数化重校准算法缺乏对其泛化性能的理论保证。为了解决这些问题，我们使用概率近似正确贝叶斯框架对校准误差进行泛化分析。这种方法使我们能够推导出校准背景下泛化误差的首个可优化上界。基于我们的理论，我们提出了一种泛化感知重校准算法。数值实验表明，我们的算法在各种基准数据集和模型上增强了基于高斯过程的重校准性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [263] [AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs](https://arxiv.org/abs/2507.08616)
> *AgentsNet：多智能体大型语言模型中的协调与协作推理*

*Florian Grötschla, Luis Müller, Jan Tönshoff, Mikhail Galkin, Bryan Perozzi* | **Category: cs.MA, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 多智能体LLMs, 协调, 协作推理, 基准, 可扩展性

**Comment:** Preprint

> **TL;DR:** 本文提出了AgentsNet，一个新的基准，用于评估多智能体大型语言模型系统在网络拓扑下的协调和协作推理能力，并发现当前模型在网络规模扩大时性能下降。

**AI_Comments:** 这篇论文解决了评估多智能体LLM系统的一个关键空白，从简单的任务完成转向关注网络结构内的协调、自组织和通信等复杂动态。借鉴分布式系统和图论的灵感新颖且相关。关于性能随规模下降的发现尤其有启发性，指出了构建鲁棒、大规模多智能体LLM系统的当前局限性和未来研究方向。基准本身的可扩展性是一个重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有多智能体系统基准主要关注推理任务的性能，但未能衡量系统如何有效自组织、协作及利用网络拓扑结构。不清楚复杂智能体网络如何有效协调。

**Method:** 提出了AgentsNet基准，借鉴分布式系统和图论，衡量多智能体系统在给定网络拓扑下协作制定问题解决、自组织和有效通信策略的能力。在AgentsNet上评估了多种基线方法，并在多达100个智能体的设置中进行了探索。

**Result:** 一些前沿LLMs在小型网络中表现良好，但随着网络规模扩大性能下降。AgentsNet的规模实际上是无限的，可以评估更大规模的网络。

**Conclusion:** （未在摘要中明确提及）

> **ai_Abstract:** 本文介绍了AgentsNet，一个用于评估多智能体大型语言模型系统协调与协作推理能力的新基准。AgentsNet借鉴分布式系统和图论思想，不同于仅关注任务性能的现有基准，它评估智能体如何利用网络拓扑进行问题解决、自组织和通信。通过AgentsNet进行的实验表明，尽管一些先进的LLMs在小型网络中表现良好，但随着网络规模增加，其性能显著下降，突显了多智能体LLM系统的可扩展性挑战。AgentsNet提供了一个可扩展的平台，用于评估未来LLM在更大网络配置中的表现。

> **摘要翻译:** 大型语言模型（LLMs）展示了强大的问题解决能力，特别是在组织成多智能体系统时。然而，这类系统的出现也引发了一些关于复杂智能体网络如何有效自组织和协作的问题。虽然衡量在标准推理基准上的性能可以表明多智能体系统解决推理任务的能力，但尚不清楚这些系统是否能够有效利用其拓扑结构。在此，我们提出了AgentsNet，一个新的多智能体推理基准。AgentsNet借鉴了分布式系统和图论中的经典问题，衡量多智能体系统在给定网络拓扑下协作制定问题解决、自组织和有效通信策略的能力。我们在AgentsNet上评估了多种基线方法，包括需要首先就组织和通信基本协议达成一致的同质智能体网络。我们发现一些前沿LLMs在小型网络中已经表现出强大的性能，但一旦网络规模扩大，性能就会开始下降。虽然现有的多智能体基准最多只涵盖2-5个智能体，但AgentsNet的规模实际上是无限的，并且可以随着新一代LLMs的发展而扩展。因此，我们还在多达100个智能体的设置中探索了前沿模型。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [376] [An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems](https://arxiv.org/abs/2505.18397)
> *多智能体人工智能系统机遇与挑战展望*

*Fangqiao Tian, An Luo, Jin Du, Xun Xian, Robert Specht, Ganghua Wang, Xuan Bi, Jiawei Zhou, Ashish Kundu, Jayanth Srinivasa, Charles Fleming, Rui Zhang, Zirui Liu, Mingyi Hong, Jie Ding* | **Category: cs.MA, cs.AI, cs.ET, cs.LG, 68T42 (Agent technology and artificial intelligence), 68T01 (General
  topics in artificial intelligence), 68M14 (Distributed systems), I.2.11; I.2.4; I.2.6** | **Updated: 2025-07-11**

**Keywords:** 多智能体系统,人工智能,信号处理,有效性,安全性

**Comment:** 

> **TL;DR:** 多智能体系统（MAS）通过多个自主智能体交互和决策，在科学发现和协作自动化等领域日益实用。本文提出了一个分析MAS有效性和安全性的框架，探讨了MAS相对于单智能体系统的优势、新兴的安全风险以及评估方法，并展示了其在数据科学自动化中的潜力。

**AI_Comments:** 该论文对多智能体系统进行了全面的概述，并提出了一个有价值的分析框架。其对MAS在信号处理领域的潜在应用进行了有见地的探讨，并指出了未来研究方向。然而，在实际应用中，如何有效解决智能体间的协调和冲突问题仍是需要进一步关注的重点。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型和工具使用智能体的进步，多智能体人工智能系统（MAS）在科学发现和协作自动化等领域的应用日益广泛，但其相对于单智能体系统的优势、新增的安全风险以及可靠性和结构评估方法仍需明确。

**Method:** 本文提出了一个分析MAS有效性和安全性的正式框架，重点关注MAS是否能真正提高鲁棒性、适应性和性能，以及智能体间的交互如何影响系统脆弱性。

**Result:** 通过在数据科学自动化方面的实验，证明了MAS在信号处理领域具有重塑系统设计和信任的潜力。

**Conclusion:** MAS有望成为一种强大的抽象，将分布式估计和传感器融合等经典工具扩展到更高级别的、由策略驱动的推理，从而在信号处理领域带来变革。

> **ai_Abstract:** 本文探讨了多智能体人工智能系统（MAS）的机遇与挑战，重点关注其在科学发现和协作自动化等领域的应用前景。文章提出了一个分析MAS有效性和安全性的框架，旨在明确MAS相对于单智能体系统的优势、潜在的安全风险以及评估方法。通过数据科学自动化实验，展示了MAS在信号处理领域的变革潜力。

> **摘要翻译:** 多智能体人工智能系统（MAS）由多个自主智能体组成，这些智能体进行交互、交换信息并基于内部生成模型进行决策。近期大型语言模型和工具使用智能体的进展使得MAS在科学发现和协作自动化等领域日益实用。然而，关键问题仍然存在：MAS何时比单智能体系统更有效？智能体交互会带来哪些新的安全风险？我们应该如何评估它们的可靠性和结构？本文概述了一个分析MAS的正式框架，重点关注两个核心方面：有效性和安全性。我们探讨了MAS是否真正提高了鲁棒性、适应性和性能，或者仅仅是重新包装了诸如集成学习之类的已知技术。我们还研究了智能体间的动态如何可能放大或抑制系统脆弱性。尽管MAS对于信号处理界来说相对较新，但我们设想它们是一种强大的抽象，可以将分布式估计和传感器融合等经典工具扩展到更高级别的、由策略驱动的推理。通过在数据科学自动化方面的实验，我们强调了MAS重塑信号处理系统设计和信任方式的潜力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [8] [Biomechanics-Aware Trajectory Optimization for Online Navigation during Robotic Physiotherapy](https://arxiv.org/abs/2411.03873)
> *机器人物理治疗中在线导航的生物力学感知轨迹优化*

*Italo Belli, Florian van Melis, J. Micah Prendergast, Ajay Seth, Luka Peternel* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-11**

**Keywords:** 生物力学, 轨迹优化, 机器人物理治疗, 在线导航, OpenSim

**Comment:** 15 pages, 9 figures, under review. Major changes: title, use of
  biomechanical model for online estimation of human muscle activation (leading
  to revision in abstract, methods, results, figures, discussion, and
  conclusion), broader review of related work

> **TL;DR:** BATON是一种生物力学感知的轨迹优化方法，用于在机器人物理治疗中在线导航人体肌肉骨骼负荷，以最小化肌腱应变并适应人类动作。

**AI_Comments:** 该论文的创新点在于提出了一种生物力学感知的轨迹优化方法BATON，它将高保真的人体生物力学模型与在线适应性相结合，以实现安全有效的机器人辅助物理治疗。特别是在线适应人体不确定动作的能力，对于实际应用中的人机协作至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器人辅助物理治疗方法难以整合对安全有效治疗至关重要的生物力学指标。

**Method:** 本文引入了BATON，一种生物力学感知轨迹优化方法，用于肩袖康复中人体肌肉骨骼负荷的在线机器人导航。BATON将高保真的人体肩部OpenSim模型嵌入到最优控制框架中，生成最小化应变的轨迹，用于治疗运动的实时控制。其核心优势在于能够根据机器人感知的运动和力，在线适应物理人机交互过程中不可预测的人体自主动作或反射反应。BATON的适应性通过一个实时、基于模型的估计器实现，该估计器通过一个由机器人姿态和力/扭矩传感器数据驱动的快速冗余求解器来推断肌肉活动的变化。

**Result:** 通过物理人机交互实验验证了BATON，评估了响应速度、运动平滑度和交互力。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种名为BATON的生物力学感知轨迹优化方法，旨在解决机器人辅助物理治疗中整合生物力学指标的挑战。BATON将人体肩部的高保真OpenSim模型集成到最优控制框架中，以实时生成最小化肌腱应变的治疗轨迹。该方法能够根据机器人感知的运动和力，在线适应患者的自主或反射性动作，通过实时模型估计器推断肌肉活动变化。实验验证表明，BATON在响应速度、运动平滑度和交互力方面表现良好。

> **摘要翻译:** 机器人设备为提供物理治疗和康复运动提供了绝佳机会，然而，当前的机器人辅助方法难以整合对安全有效治疗至关重要的生物力学指标。我们引入了BATON，一种生物力学感知轨迹优化方法，用于肩袖康复中人体肌肉骨骼负荷的在线机器人导航。BATON将高保真的人体肩部OpenSim模型嵌入到最优控制框架中，生成最小化应变的轨迹，用于治疗运动的实时控制。其核心优势在于能够根据机器人感知的运动和力，在线适应物理人机交互过程中不可预测的人体自主动作或反射反应。BATON的适应性通过一个实时、基于模型的估计器实现，该估计器通过一个由机器人姿态和力/扭矩传感器数据驱动的快速冗余求解器来推断肌肉活动的变化。我们通过物理人机交互实验验证了BATON，评估了响应速度、运动平滑度和交互力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [41] [Relative Pose Estimation for Nonholonomic Robot Formation with UWB-IO Measurements (Extended version)](https://arxiv.org/abs/2411.05481)
> *非完整机器人编队基于UWB-IO测量的相对位姿估计（扩展版）*

*Kunrui Ze, Wei Wang, Shuoyu Yue, Guibin Sun, Kexin Liu, Jinhu Lü* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 非完整机器人, 编队控制, 相对位姿估计, UWB, 惯性里程计

**Comment:** 15 pages, 21 figures

> **TL;DR:** 本文提出了一种针对非完整机器人的分布式编队控制方法，通过结合UWB和惯性里程计测量，在局部坐标系下估计机器人间的相对位姿，并验证了其有效性。

**AI_Comments:** 这篇论文的创新点在于它解决了非完整机器人编队控制中，传感器测量难以在共同参考系中对齐的实际问题。通过在局部坐标系下进行相对位姿估计，并结合UWB和IO测量，提供了一种实用的解决方案。其重要性在于为非完整机器人在复杂环境下的分布式协作提供了理论和实验基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有多数分布式机器人编队控制方法要求机器人的位姿和传感器测量在共同参考系中表达，但这对于非完整机器人编队来说不适用，因为难以将单个机器人的惯性里程计测量对齐到共同坐标系。

**Method:** 1. 提出了一种基于并发学习的估计器，用于在局部坐标系中实现相邻机器人之间的相对定位，仅使用UWB测距和IO测量即可估计相对位置和姿态。2. 引入了一种协作定位算法，以处理定向通信拓扑引起的信息丢失，用于估计与领航机器人的相对位姿。3. 基于相对位姿估计的理论结果，提出了一种适用于非完整机器人的分布式编队跟踪控制器。

**Result:** 通过对空中机器人和地面机器人进行的3D和2D真实世界实验，验证了所提方法的有效性。

**Conclusion:** 本文提出了一种在局部坐标系下利用UWB和IO测量进行相对位姿估计并实现非完整机器人分布式编队控制的有效方法。

> **ai_Abstract:** 本文提出了一种解决非完整机器人分布式编队控制中共同参考系对齐难题的方法。通过结合UWB测距和惯性里程计测量，研究人员首先开发了一种基于并发学习的估计器，用于在局部坐标系中估计相邻机器人间的相对位置和姿态。接着，引入协作定位算法以应对定向通信拓扑下的信息丢失，并估计与领航机器人的相对位姿。最终，基于这些相对位姿估计，设计了一个分布式编队跟踪控制器。实验结果表明该方法在3D和2D真实世界场景中对空中和地面机器人均有效。

> **摘要翻译:** 本文研究了利用车载超宽带（UWB）距离和惯性里程计（IO）测量实现多机器人分布式编队控制的问题。
尽管这个问题已被广泛研究，但大多数工作的一个根本局限性是它们要求每个机器人的位姿和传感器测量都在一个共同的参考系中表达。
然而，由于在共同坐标系中对齐单个机器人的IO测量存在实际困难，这不适用于非完整机器人编队。
为了解决这个问题，首先，提出了一种基于并发学习的估计器，用于在局部坐标系中实现相邻机器人之间的相对定位。
与大多数在全局坐标系中的相对定位方法不同，在局部坐标系中的相对位置和方向仅通过UWB测距和IO测量进行估计。
其次，为了处理由定向通信拓扑引起的信息丢失，引入了一种协作定位算法来估计与领航机器人的相对位姿。
第三，基于相对位姿估计的理论结果，提出了一种适用于非完整机器人的分布式编队跟踪控制器。
通过对空中机器人和地面机器人进行的3D和2D真实世界实验，证明了所提方法的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [69] [RPF-Search: Field-based Search for Robot Person Following in Unknown Dynamic Environments](https://arxiv.org/abs/2503.02188)
> *RPF-Search：基于场的未知动态环境下机器人跟随目标搜索*

*Hanjing Ye, Kuanqi Cai, Yu Zhan, Bingyi Xia, Arash Ajoudani, Hong Zhang* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 机器人跟随, 目标搜索, 动态环境, 遮挡, 启发式搜索

**Comment:** Accepted by IEEE/ASME Transactions on Mechatronics. Project page:
  https://medlartea.github.io/rpf-search/

> **TL;DR:** 提出一种新的启发式搜索框架RPF-Search，通过动态建图和针对性机制解决未知动态环境下机器人跟随目标时的目标丢失问题，提高了搜索效率和成功率。

**AI_Comments:** 这篇论文的创新点在于其提出了一个统一的框架来解决机器人跟随中目标丢失的两个主要原因：地形遮挡和动态遮挡，并且在跟随过程中动态构建地图，而不是依赖预设地图。这种方法提高了系统在未知和动态环境中的适应性，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动机器人跟随系统在未知动态环境下因遮挡导致目标丢失，现有方法依赖预建地图和静态环境假设，无法有效应对地形和动态遮挡，存在重新寻找目标的空白。

**Method:** 提出一种新的启发式引导搜索框架，在跟随目标时动态构建环境地图，并专门处理两种遮挡：对于地形遮挡，使用信念引导搜索场估计目标存在可能性并引导搜索；对于动态遮挡，根据遮挡物运动模式自适应切换流体跟随场和超车势场。

**Result:** 所提出的方法在搜索效率和成功率方面优于现有方法，并在仿真和实际测试中得到验证。

**Conclusion:** 该目标搜索方法增强了RPF系统在未知动态环境中的适应性和可靠性，支持其在实际应用中的使用。

> **ai_Abstract:** 本文提出RPF-Search，一个针对未知动态环境下机器人跟随目标丢失问题的新型启发式搜索框架。该框架在跟随过程中动态构建环境地图，并通过信念引导搜索场处理地形遮挡，以及基于观察的自适应切换策略处理动态遮挡。实验结果表明，RPF-Search在搜索效率和成功率上优于现有方法，显著提升了RPF系统在复杂环境下的鲁棒性和实用性。

> **摘要翻译:** 自动机器人跟随 (RPF) 系统对于个人辅助和安全至关重要，但由于在动态、未知环境中的遮挡，它们会遭受目标丢失。当前方法依赖预建地图并假设静态环境，这限制了它们在现实世界设置中的有效性。在地形（例如墙壁、角落）和动态（例如移动的行人）遮挡下重新寻找目标存在关键空白。在本文中，我们提出了一种新颖的启发式引导搜索框架，该框架在跟随目标时动态构建环境地图，并通过不同的机制明确解决了这两种类型的遮挡。对于地形遮挡，信念引导搜索场估计目标存在的可能性并引导搜索走向有希望的前沿。对于动态遮挡，基于观察的搜索策略根据遮挡物运动模式自适应地在流体跟随场和超车势场之间切换。我们的结果表明，所提出的方法在搜索效率和成功率方面优于现有方法，无论是在仿真还是在现实世界测试中。我们的目标搜索方法增强了RPF系统在未知和动态环境中的适应性和可靠性，支持其在现实世界中的应用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [97] [Balancing Progress and Safety: A Novel Risk-Aware Objective for RL in Autonomous Driving](https://arxiv.org/abs/2505.06737)
> *平衡进展与安全：自动驾驶强化学习中一种新颖的风险感知目标函数*

*Ahmed Abouelazm, Jonas Michel, Helen Gremmelmaier, Tim Joseph, Philip Schörner, J. Marius Zöllner* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 强化学习, 自动驾驶, 奖励函数, 安全, 风险感知

**Comment:** Accepted in the 36th IEEE Intelligent vehicles Symposium (IV 2025)

> **TL;DR:** 该论文提出了一种新的风险感知目标函数，用于自动驾驶强化学习的奖励函数设计，通过分层和归一化处理驾驶目标，并引入基于二维椭球函数和RSS概念的风险感知目标，显著降低了碰撞率并提升了性能。

**AI_Comments:** 该论文的创新点在于提出了一个新颖的风险感知目标，并将其融入强化学习的奖励函数设计中，通过分层和归一化处理，有效解决了传统奖励函数在安全风险预警方面的不足。这对于提升自动驾驶系统在复杂真实世界场景中的安全性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在自动驾驶中的奖励函数设计受到关注不足，导致奖励定义不清，且安全通常仅被视为碰撞惩罚，未能解决导致碰撞前的风险，限制了强化学习在实际场景中的应用。

**Method:** 通过定义一系列驾驶目标并进行分层结构化，增强了奖励函数的制定；以归一化方式制定这些目标，以透明地确定它们对整体奖励的贡献；引入了一种基于二维椭球函数和责任敏感安全（RSS）概念扩展的新型风险感知目标，用于各种驾驶交互。

**Result:** 与基线奖励相比，所提出的方法在非信号交叉路口场景中平均降低了21%的碰撞率，并在路线进展和累积奖励方面持续超越基线。

**Conclusion:** 本研究证明了所提出的方法能够促进更安全的驾驶行为，同时保持高水平的性能。

> **ai_Abstract:** 本论文旨在解决自动驾驶强化学习中奖励函数设计不足的问题，特别是安全方面仅关注碰撞惩罚而忽略潜在风险的局限性。研究提出了一种新的风险感知奖励函数，通过分层结构化和归一化处理驾驶目标，并引入了基于二维椭球函数和责任敏感安全（RSS）扩展的风险感知目标。在非信号交叉路口场景的评估显示，该方法平均降低了21%的碰撞率，并在性能上超越了基线，证明了其在提升驾驶安全性的同时保持高效率的能力。

> **摘要翻译:** 强化学习（RL）因其强大的决策能力，是实现自动驾驶的一种有前景的方法。RL通过在交通场景中试错来学习驾驶策略，并由结合了驾驶目标的奖励函数引导。这种奖励函数的设计受到的关注不足，导致奖励定义不清，存在各种缺陷。特别是，安全长期以来仅被视为碰撞的惩罚。这使得导致碰撞的动作相关的风险未得到解决，限制了RL在真实世界场景中的适用性。为了解决这些缺点，我们的工作重点是通过定义一系列驾驶目标并对其进行分层结构化来增强奖励函数的设计。此外，我们讨论了以归一化方式制定这些目标，以透明地确定它们对整体奖励的贡献。此外，我们引入了一种基于二维椭球函数和责任敏感安全（RSS）概念扩展的，用于各种驾驶交互的新型风险感知目标。我们评估了所提出的奖励在交通密度不同的非信号交叉路口场景中的有效性。与基线奖励相比，该方法平均降低了21%的碰撞率，并在路线进展和累积奖励方面持续超越基线，证明了其在保持高性能水平的同时促进更安全驾驶行为的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [125] [Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving](https://arxiv.org/abs/2505.06740)
> *边界引导的轨迹预测，用于道路感知和物理可行性自动驾驶*

*Ahmed Abouelazm, Mianzhi Liu, Christian Hubschneider, Yin Wu, Daniel Slieter, J. Marius Zöllner* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 轨迹预测, 自动驾驶, 边界引导, 运动学约束, 道路感知

**Comment:** Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)

> **TL;DR:** 提出一种边界引导的轨迹预测框架，通过学习道路边界内的路径和预测符合运动学约束的加速度，确保自动驾驶轨迹预测的道路感知性和物理可行性，显著减少了越野预测并提高了泛化能力。

**AI_Comments:** 这篇论文通过将轨迹预测问题重新定义为受约束的回归，并明确利用道路边界信息，有效解决了现有方法中越野预测和运动学不可行的问题。其创新点在于将道路感知和物理约束深度融入模型设计中，而非作为后处理步骤。特别是在对抗性攻击下越野率的大幅降低，显示了其在鲁棒性方面的显著提升，这对于自动驾驶的安全至关重要。尽管在某些基准指标上略有下降，但其在关键安全性和可行性方面的提升，以及在泛化能力上的优势，使其具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习轨迹预测模型难以防止越野预测并确保运动学可行性。尽管现有方法尝试纳入道路感知模块和运动学约束，但缺乏合理性保证，并且通常会引入复杂性和灵活性方面的权衡。

**Method:** 本文提出一个新颖的框架，将轨迹预测表述为受允许驾驶方向及其边界引导的约束回归问题。利用智能体的当前状态和高清地图，定义有效边界，并通过训练网络学习左右边界折线之间的叠加路径来确保道路上的预测。为保证可行性，模型预测加速度剖面，以确定车辆沿这些路径的行驶距离，同时遵守运动学约束。

**Result:** 与HPTR基线相比，该方法在基准指标上略有下降，但显著改善了最终位移误差并消除了不可行轨迹。此外，该方法对不常见机动和未见的分布外场景具有卓越的泛化能力，在对抗性攻击下将越野率从66%降低到仅1%。

**Conclusion:** 本文提出的方法在生成可行且鲁棒的轨迹预测方面是有效的。

> **ai_Abstract:** 本文提出一种边界引导的轨迹预测新框架，旨在解决自动驾驶中现有深度学习模型在防止越野预测和确保运动学可行性方面的挑战。该方法将轨迹预测视为受道路边界约束的回归问题，通过学习高清地图定义的有效边界内的叠加路径，并预测符合运动学约束的加速度剖面，以生成道路感知且物理可行的轨迹。实验结果表明，该方法显著减少了越野预测（对抗性攻击下从66%降至1%），消除了不可行轨迹，并对不常见机动和分布外场景展现出优越的泛化能力，证明了其生成可行且鲁棒预测的有效性。

> **摘要翻译:** 准确预测周围道路使用者的轨迹对于安全高效的自动驾驶至关重要。虽然深度学习模型提高了性能，但在防止越野预测和确保运动学可行性方面仍存在挑战。现有方法虽然纳入了道路感知模块并强制执行运动学约束，但缺乏合理性保证，并且通常会引入复杂性和灵活性方面的权衡。本文提出了一种新颖的框架，将轨迹预测表述为由允许的驾驶方向及其边界引导的约束回归问题。利用智能体的当前状态和高清地图，我们的方法定义了有效边界，并通过训练网络学习左右边界折线之间的叠加路径来确保道路上的预测。为保证可行性，模型预测加速度剖面，以确定车辆沿这些路径的行驶距离，同时遵守运动学约束。我们在Argoverse-2数据集上针对HPTR基线评估了我们的方法。我们的方法与HPTR相比，在基准指标上略有下降，但显著改善了最终位移误差并消除了不可行轨迹。此外，所提出的方法对不常见机动和未见的分布外场景具有卓越的泛化能力，在对抗性攻击下将越野率从66%降低到仅1%。这些结果突出表明我们的方法在生成可行且鲁棒的预测方面的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [152] [TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility](https://arxiv.org/abs/2505.06743)
> *TPK：整合先验知识的可信轨迹预测，以实现可解释性和运动学可行性*

*Marius Baden, Ahmed Abouelazm, Christian Hubschneider, Yin Wu, Daniel Slieter, J. Marius Zöllner* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 轨迹预测, 先验知识, 可解释性, 运动学可行性, 自动驾驶

**Comment:** Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)
  for oral presentation. Winner of the best paper award

> **TL;DR:** TPK模型通过整合针对不同交通参与者的交互和运动学先验知识，提高了轨迹预测的可信度、可解释性及物理可行性，适用于混合交通场景。

**AI_Comments:** 该论文的创新点在于为混合交通流中的所有交通参与者类别（包括车辆、行人、骑行者）整合了类特定的交互和运动学先验知识，并引入了DG-SFM来提高交互的可解释性。其重要性在于通过提供可解释且物理可行的预测，显著提升了自动驾驶系统中轨迹预测的可信度。一个局限性是引入运动学模型导致了预测精度上的轻微下降。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习轨迹预测模型常缺乏可信度，其预测结果可能不符合物理规律且对人类而言不合逻辑；此外，现有整合先验知识的方法无法泛化到混合交通流场景。

**Method:** 提出TPK模型，为车辆、行人、骑行者等所有交通参与者类别引入类特定的交互层，以捕获行为差异。为提高交互可解释性，引入了基于规则的DG-SFM交互重要性评分。为确保物理可行性，为所有交通参与者类别（包括新颖的行人运动学模型）提出了合适的运动学模型。

**Result:** 在Argoverse 2数据集上的实验表明，该方法提高了交互可解释性，揭示了错误预测与偏离交互先验之间的关联。尽管引入运动学模型导致精度略有下降，但它们消除了数据集中和基线模型中存在的不可行轨迹。

**Conclusion:** TPK方法通过提供可解释的交互推理和符合物理规律的预测，增强了轨迹预测的可信度。

> **ai_Abstract:** 本文提出了TPK模型，旨在解决自动驾驶中轨迹预测模型缺乏可信度的问题，因现有模型常产生不符合物理规律且不合逻辑的预测，且现有融合先验知识的方法无法泛化到混合交通流。TPK通过为不同交通参与者（车辆、行人、骑行者）引入类特定的交互层和运动学先验知识来解决此问题。为增强交互可解释性，引入了DG-SFM评分。实验证明，TPK提高了交互可解释性并消除了不可行轨迹，尽管预测精度略有下降，从而提升了轨迹预测的可信度。

> **摘要翻译:** 轨迹预测对于自动驾驶至关重要，它能通过预测周围道路使用者的运动来帮助车辆安全导航。然而，当前的深度学习模型常常缺乏可信度，因为它们的预测可能在物理上不可行且对人类而言不合逻辑。为了使预测更具可信度，最近的研究已经整合了先验知识，例如用于建模交互的社会力模型和用于物理真实性的运动学模型。然而，这些方法侧重于适合车辆或行人的先验知识，无法泛化到混合交通参与者类别的交通流。我们建议整合所有交通参与者类别——车辆、行人、骑行者的交互和运动学先验知识，并使用类特定的交互层来捕获交通参与者的行为差异。为了提高交通参与者交互的可解释性，我们引入了DG-SFM，一个基于规则的交互重要性评分，用于指导交互层。为了确保物理可行的预测，我们为所有交通参与者类别提出了合适的运动学模型，并提出了一个新颖的行人运动学模型。我们在Argoverse 2数据集上对我们的方法进行了基准测试，使用最先进的Transformer HPTR作为我们的基线。实验表明，我们的方法提高了交互可解释性，揭示了错误预测与偏离我们交互先验之间的关联。尽管整合运动学模型导致精度略有下降，但它们消除了数据集中和基线模型中发现的不可行轨迹。因此，我们的方法通过其可解释的交互推理和符合物理的预测，增强了轨迹预测的可信度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [185] [Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning](https://arxiv.org/abs/2505.08264)
> *自动课程学习用于驾驶场景：迈向鲁棒高效的强化学习*

*Ahmed Abouelazm, Tim Weinstein, Tim Joseph, Philip Schörner, J. Marius Zöllner* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 自动课程学习, 强化学习, 自动驾驶, 泛化能力, 训练效率

**Comment:** Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)

> **TL;DR:** 本文提出了一种自动课程学习框架，通过动态生成适应智能体能力的驾驶场景，显著提升了端到端自动驾驶强化学习的训练效率和泛化能力。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需人工干预的自动课程学习框架，通过“教师”机制根据智能体的实时学习状态动态调整训练场景，有效解决了传统RL训练中泛化能力和效率的瓶颈。其重要性在于为自动驾驶RL智能体的训练提供了一种更鲁棒、更高效的范式，对推动RL在复杂真实世界应用中的落地具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 训练端到端自动驾驶强化学习（RL）智能体面临挑战，传统方法（固定场景训练和领域随机化）限制了智能体的泛化能力和实际部署，并导致训练效率低下和次优策略。

**Method:** 提出了一种自动课程学习（ACL）框架，该框架包含一个“教师”模块，根据智能体当前策略（学习潜力）自动生成和变异驾驶场景，动态调整场景复杂度。该框架通过排除智能体已掌握或认为过于困难的场景，提高训练效率，无需专家设计。

**Result:** 与固定场景训练和领域随机化等基线方法相比，该方法增强了泛化能力，在低交通密度下成功率提高9%，在高交通密度下提高21%，并以更少的训练步骤实现了更快的收敛。

**Conclusion:** 自动课程学习（ACL）在提高基于强化学习的自动驾驶智能体的鲁棒性和效率方面具有巨大潜力。

> **ai_Abstract:** 本文提出了一种自动课程学习（ACL）框架，旨在解决强化学习（RL）在训练端到端自动驾驶智能体时面临的泛化能力差和训练效率低的问题。该框架通过引入一个“教师”组件，根据智能体的学习进度动态生成和调整驾驶场景的复杂度，从而避免了手动设计课程可能带来的专家偏见和可扩展性不足。实验结果表明，与传统的固定场景训练和领域随机化方法相比，ACL显著提升了自动驾驶智能体的泛化能力、成功率（在不同交通密度下分别提高9%和21%）以及训练效率（收敛更快、训练步骤更少）。

> **摘要翻译:** 本文旨在解决使用强化学习（RL）训练端到端自动驾驶智能体所面临的挑战。强化学习智能体通常在固定的场景集和模拟中周围道路使用者的标称行为下进行训练，这限制了它们的泛化能力和实际部署。虽然领域随机化通过随机采样驾驶场景提供了一种潜在的解决方案，但由于训练场景之间的高度差异性，它经常导致训练效率低下和次优策略。为了解决这些局限性，我们提出了一种自动课程学习框架，该框架根据智能体不断发展的能力动态生成具有自适应复杂度的驾驶场景。与引入专家偏见且缺乏可扩展性的手动设计课程不同，我们的框架包含一个“教师”，它根据场景的学习潜力——一个源自智能体当前策略的以智能体为中心的指标——自动生成和变异驾驶场景，从而消除了对专家设计的需求。该框架通过排除智能体已经掌握或认为太具挑战性的场景来提高训练效率。我们在智能体从摄像机图像学习驾驶策略的强化学习环境中评估了我们的框架。与包括固定场景训练和领域随机化在内的基线方法的比较结果表明，我们的方法能够增强泛化能力，实现更高的成功率：在低交通密度下提高9%，在高交通密度下提高21%，并且以更少的训练步骤实现更快的收敛。我们的研究结果突出了ACL在提高基于强化学习的自动驾驶智能体的鲁棒性和效率方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [223] [Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces](https://arxiv.org/abs/2506.01635)
> *黎曼时间规整：弯曲空间中的多序列比对*

*Julian Richter, Christopher Erdös, Christian Scheurer, Jochen J. Steil, Niels Dehio* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 黎曼时间规整, 多序列比对, 弯曲空间, 几何结构, 机器人学

**Comment:** 

> **TL;DR:** 本文提出黎曼时间规整（RTW），一种新颖的算法，用于在黎曼流形中对多个信号进行时间比对，并在实验中表现优于现有技术。

**AI_Comments:** 本文的主要创新在于首次将多序列时间规整的概念推广到一般的黎曼流形，填补了该领域的一个重要空白。这对于机器人学等处理非欧几何数据的领域具有重要意义。通过考虑数据的内在几何结构，RTW能够更准确地处理复杂数据，其在实验中的优异表现证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数时间规整方法都局限于欧几里得空间数据，而将时间规整概念推广到黎曼流形的一般性方法仍然缺失，但这对于机器人学及其他领域的众多应用至关重要。

**Method:** 本文引入了黎曼时间规整（RTW），这是一种新颖的方法，通过考虑数据嵌入的黎曼流形的几何结构，有效地比对多个信号。

**Result:** 在合成数据和真实世界数据（包括LBR iiwa机器人测试）上的广泛实验表明，RTW在平均和分类任务中均持续优于最先进的基线方法。

**Conclusion:** 黎曼时间规整（RTW）成功地将时间规整扩展到黎曼流形，并在多信号比对任务中展现出卓越的性能，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了一种名为黎曼时间规整（RTW）的新方法，旨在解决现有时间规整方法局限于欧几里得空间的问题。RTW通过考虑数据所嵌入的黎曼流形的几何结构，实现了多个信号的有效比对。实验结果表明，RTW在合成和真实世界数据上，包括机器人应用，均在信号平均和分类任务中显著优于现有基线方法。

> **摘要翻译:** 通过时间规整对多个信号进行时间比对在许多领域都至关重要，例如语音识别中的分类或机器人运动学习。几乎所有相关工作都局限于欧几里得空间数据。尽管2011年曾尝试将此概念应用于单位四元数，但仍缺乏向黎曼流形的普遍推广。鉴于其对机器人学及其他众多应用的重要性，我们引入了黎曼时间规整（RTW）。这种新颖的方法通过考虑数据嵌入的黎曼流形的几何结构，有效地比对多个信号。在合成数据和真实世界数据（包括LBR iiwa机器人测试）上的广泛实验表明，RTW在平均和分类任务中均持续优于最先进的基线方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [265] [Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs](https://arxiv.org/abs/2506.07454)
> *基于语言的多机器人3D场景图分层规划与执行*

*Jared Strader, Aaron Ray, Jacob Arkin, Mason B. Peterson, Yun Chang, Nathan Hughes, Christopher Bradley, Yi Xuan Jia, Carlos Nieto-Granda, Rajat Talak, Chuchu Fan, Luca Carlone, Jonathan P. How, Nicholas Roy* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 多机器人, 3D场景图, 语言接地, 分层规划, LLM

**Comment:** 12 pages, 4 figures, 4 tables

> **TL;DR:** 该论文介绍了一个利用3D场景图和语言模型，使多机器人能够根据自然语言指令执行复杂任务的系统。

**AI_Comments:** 该研究的创新点在于将3D场景图（特别是共享和基于对象的场景图）与大型语言模型相结合，实现了多机器人基于语言的规划和执行。这为机器人理解和执行复杂的自然语言指令提供了新的方法。

<details>
  <summary>Details</summary>

**Motivation:** 使多机器人系统能够理解并执行复杂的自然语言指令，并在真实环境中完成任务。

**Method:** 该系统构建了一个共享的3D场景图，整合了开放集基于对象的地图，用于多机器人3D场景图融合。利用该场景图进行实时、视图不变的重定位和规划。使用大型语言模型（LLM）结合共享3D场景图和机器人能力，将操作员意图转化为PDDL目标。

**Result:** 在大型户外真实环境中对系统性能进行了实验评估，具体结果摘要中未提及。

**Conclusion:** 摘要中未提及明确的结论。

> **ai_Abstract:** 本文提出了一个多机器人系统，通过整合3D场景图和大型语言模型，实现根据自然语言指令进行分层规划和执行。系统构建共享的3D场景图和基于对象的地图，支持实时定位和规划。利用LLM将语言指令转化为规划目标。并在真实世界环境中进行了实验评估。

> **摘要翻译:** 在本文中，我们介绍了一种多机器人系统，该系统通过3D场景图整合了建图、定位以及任务和运动规划（TAMP），以执行用自然语言表达的复杂指令。我们的系统构建了一个包含开放集基于对象的地图的共享3D场景图，该地图用于多机器人3D场景图融合。这种表示支持实时、视图不变的重定位（通过基于对象的地图）和规划（通过3D场景图），使机器人团队能够理解其周围环境并执行复杂任务。此外，我们引入了一种规划方法，该方法利用共享3D场景图和机器人能力的上下文，使用大型语言模型（LLM）将操作员意图转化为规划域定义语言（PDDL）目标。我们提供了该系统在大型户外真实环境中的实际任务性能的实验评估。补充视频可在 https://youtu.be/8xbGGOLfLAY 查看。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [273] [Noise-Enabled Goal Attainment in Crowded Collectives](https://arxiv.org/abs/2507.08100)
> *噪声驱动的拥挤群体目标达成*

*Lucy Liu, Justin Werfel, Federico Toschi, L. Mahadevan* | **Category: cs.RO, cond-mat.soft, cs.MA** | **Updated: 2025-07-10**

**Keywords:** 交通流, 噪声, 目标达成, 机器人群, 拥挤环境

**Comment:** 

> **TL;DR:** 研究发现，在拥挤环境中，适度的噪声可以有效缓解交通拥堵，提高个体目标达成率，并通过模拟、理论和机器人实验验证了这一发现。

**AI_Comments:** 本研究的创新点在于提出了噪声作为一种有效策略来解决拥挤环境中的交通堵塞问题，这与直觉相反。它不仅提供了理论和模拟证据，还通过机器人实验进行了验证，增强了结果的可靠性。其重要性体现在为机器人群体协调和智能交通系统设计提供了新的思路，尤其是在资源有限或需要快速响应的实际场景中，简单的反应式导航方案的有效性具有很高的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在拥挤环境中，理解和控制交通流对于协调机器人群和设计密集人口基础设施至关重要。本文旨在探究噪声运动如何打破交通堵塞并使个体能够到达各自目标。

**Method:** 本文结合了模拟、理论分析和机器人实验。通过模拟研究噪声对交通堵塞的影响，并从观察结果中解析近似目标达成率与噪声水平的关系。随后，求解最大化群体目标达成率的最佳智能体密度和噪声水平。最后，通过机器人实验验证了模拟和理论结果，并比较了简单的局部导航方法与复杂的中央规划器。

**Result:** 研究发现，当噪声水平超过临界值时，大规模交通堵塞不会持续存在。通过分析，可以近似得出目标达成率与噪声水平的关系。存在一个最佳的智能体密度和噪声水平，可以最大化群体的目标达成率。简单的反应式导航方案在中等密度下表现良好，并且比规划器在计算上更高效。

**Conclusion:** 在拥挤环境中，适度的噪声运动可以有效打破交通堵塞，提高目标达成率。简单的局部导航策略在实际应用中，尤其是在中等密度下，具有较高的计算效率和实用性，优于复杂的中央规划器。

> **ai_Abstract:** 本研究探讨了在拥挤环境中，噪声如何影响交通流和个体目标达成。通过结合模拟、理论分析和机器人实验，发现当噪声水平超过临界值时，交通堵塞可以被有效缓解。研究确定了最大化目标达成率的最佳智能体密度和噪声水平，并指出简单的局部导航策略在计算效率上优于复杂的中央规划器，尤其适用于中等密度情况。

> **摘要翻译:** 在拥挤环境中，个体必须绕过其他占据者才能到达目的地。理解和控制这些空间中的交通流与协调机器人群和设计密集人口基础设施相关。在这里，我们结合模拟、理论和机器人实验来研究嘈杂运动如何扰乱交通堵塞并使智能体在前往个体目标时实现流动。当噪声水平超过临界值时，大型堵塞不会持续存在。根据这一观察，我们解析近似目标达成率与噪声水平的关系，然后求解最大化群体目标达成率的最佳智能体密度和噪声水平。我们进行机器人实验以证实我们的模拟和理论结果。最后，我们比较了简单、局部导航方法与复杂但计算成本高的中央规划器。一个简单的反应方案在中等密度下表现良好，并且比规划器在计算上效率高得多，这为实际问题提供了启示。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [288] [Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion](https://arxiv.org/abs/2507.08112)
> *模仿学习用于避障：基于端到端CNN的传感器融合*

*Lamiaa H. Zain, Hossam H. Ammar, Raafat E. Shalaby* | **Category: cs.RO** | **Updated: 2025-07-10**

**Keywords:** 模仿学习, 避障, 卷积神经网络, 传感器融合, 移动机器人

**Comment:** 

> **TL;DR:** 该研究设计并测试了两个基于CNN的传感器融合网络，利用深度相机图像进行避障模仿学习，以生成移动机器人的转向指令，并在多样环境中收集了新的视觉数据集进行评估。

**AI_Comments:** 该论文利用模仿学习和端到端CNN进行避障，结合了深度相机的多模态数据（彩色和深度图像）进行传感器融合，这在机器人导航中是一个重要的创新点。通过在多样环境中收集新的数据集，增加了研究的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 移动机器人在已知和未知环境中导航时，避障至关重要。

**Method:** 设计、训练和测试了两个自定义卷积神经网络（CNNs），输入为深度相机的彩色和深度图像。两个网络都采用传感器融合来输出移动机器人的角速度（转向指令）。收集了一个新的视觉导航数据集，数据收集过程中通过ROS在服务器和机器人之间建立通信链路，同步记录视觉数据和转向指令。

**Result:** 各种评估指标（如均方误差、方差分数、前向传播时间）提供了两个网络之间的清晰比较，并明确了哪个网络适用于该应用。

**Conclusion:** 评估指标明确了两个网络中哪一个更适用于避障应用。

> **ai_Abstract:** 本研究提出了一种基于端到端CNN的传感器融合模仿学习方法，用于移动机器人的避障。研究设计并评估了两个CNN模型，它们以深度相机的彩色和深度图像作为输入，并通过传感器融合输出机器人的角速度作为转向指令。为此，研究在一个多样化环境中收集了新的视觉导航数据集。通过均方误差、方差分数和前向传播时间等指标对网络进行了比较，以确定最适合应用的模型。

> **摘要翻译:** 避障对于移动机器人在已知和未知环境中的导航至关重要。本研究设计、训练并测试了两个自定义卷积神经网络（CNNs），使用深度相机的彩色和深度图像作为输入。两个网络都采用传感器融合来生成输出：移动机器人的角速度，作为机器人的转向指令。在光照条件和动态障碍物多样的环境中收集了一个新的视觉导航数据集。数据收集期间，通过Wi-Fi在远程服务器和机器人之间建立了通信链路，使用机器人操作系统（ROS）话题。速度指令从服务器传输到机器人，从而实现视觉数据和相应转向指令的同步记录。各种评估指标，如均方误差、方差分数和前向传播时间，提供了两个网络之间的清晰比较，并明确了哪个网络适用于该应用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [303] [Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning](https://arxiv.org/abs/2507.08224)
> *让VLM更适合机器人：低级程序推理的自我批判蒸馏*

*Chan Young Park, Jillian Fisher, Marius Memmel, Dipika Khullar, Andy Yun, Abhishek Gupta, Yejin Choi* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 视觉语言模型, 机器人规划, 自我蒸馏, 低级推理, 具身智能

**Comment:** Code Available: https://github.com/chan0park/SelfReVision

> **TL;DR:** 提出SelfReVision框架，使小型视觉语言模型通过自我批判和迭代修订，生成高质量的机器人执行计划，性能超越大模型。

**AI_Comments:** 这篇论文的创新点在于提出了“自我批判蒸馏”的概念，使小型VLM能够通过内部循环进行自我改进，从而生成高质量的机器人规划。这解决了传统方法对大型模型或大量外部监督的依赖，为机器人领域提供了一个更轻量、高效且可扩展的解决方案，对于资源受限的机器人部署具有重要意义。其性能超越大模型的发现也极具价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在机器人程序规划中有潜力，但其以人为中心的推理常忽略机器人执行所需的低级、接地细节。视觉语言模型（VLMs）可提供感知接地规划，但现有方法依赖昂贵的大规模模型或受限于狭窄的模拟设置。

**Method:** 本文引入SelfReVision，一个轻量级、可扩展的视觉语言程序规划自我改进框架。它使小型VLMs能够迭代地批判、修订和验证自己的计划，无需外部监督或教师模型，灵感来源于思维链提示和自我指导范式。通过这种自我蒸馏循环，模型能生成更高质量、可执行的计划，用于推理和持续微调。

**Result:** SelfReVision不仅提升了弱基础VLM的性能，还超越了尺寸大100倍的模型（从3B到72B的模型），从而在下游具身任务中实现了更好的控制。

**Conclusion:** SelfReVision通过自我批判和迭代改进，使轻量级VLM能够生成高质量、可执行的机器人规划，有效解决了现有方法对大型模型或狭窄模拟环境的依赖，显著提升了机器人在具身任务中的控制能力。

> **ai_Abstract:** 本文提出了SelfReVision，一个轻量级、可扩展的视觉语言程序规划自我改进框架，旨在解决现有LLM和VLM在机器人低级规划中细节缺失或模型开销大的问题。SelfReVision使小型VLM通过自我批判和迭代验证生成高质量、可执行的计划，无需外部监督。实验证明，该框架显著提升了小型VLM的性能，甚至超越了尺寸大100倍的模型，有效改善了机器人在具身任务中的控制能力。

> **摘要翻译:** 大型语言模型（LLMs）在机器人程序规划中展现出潜力，然而其以人为中心的推理常常忽略机器人执行所需的低级、接地细节。视觉语言模型（VLMs）为实现更具感知基础的规划提供了途径，但现有方法要么依赖昂贵的大规模模型，要么受限于狭窄的模拟设置。我们引入了SelfReVision，一个轻量级且可扩展的视觉语言程序规划自我改进框架。SelfReVision使小型VLMs能够迭代地批判、修订和验证自己的计划——无需外部监督或教师模型——灵感来源于思维链提示和自我指导范式。通过这种自我蒸馏循环，模型能够生成更高质量、可执行的计划，这些计划既可用于推理，也可用于持续微调。使用从3B到72B的各种模型，我们的结果表明，SelfReVision不仅提升了弱基础VLM的性能，而且超越了尺寸大100倍的模型，从而在下游具身任务中实现了改进的控制。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [304] [Robotic Manipulation of a Rotating Chain with Bottom End Fixed](https://arxiv.org/abs/2506.18355)
> *机器人操纵底端固定的旋转链*

*Qi Jing Chen, Shilin Shan, Quang-Cuong Pham* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 机器人操纵, 旋转链, 形状转换, 构型空间, 柔性体

**Comment:** 6 pages, 5 figures

> **TL;DR:** 本文提出了一种机器人操纵策略，用于稳定地将底部固定旋转链从一种旋转模式过渡到另一种模式，并在物理实验中验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了一个具体的操纵策略，解决了旋转链稳定形状转换的实际难题，并通过物理实验验证了其可行性。将构型空间映射到三维立方体的发现是其方法论上的亮点。该研究对于涉及柔性体操作的工业应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究探讨了旋转链的理想旋转形状，但未讨论如何通过操纵规划稳定地实现这些形状。

**Method:** 本文提出了一种操纵策略，用于稳定且一致地进行形状转换。研究发现此类链的构型空间同胚于三维立方体，并利用此特性提出了一种在考虑稳定性和可行性的前提下，将链从一种旋转模式操纵到另一种模式的策略。

**Result:** 在物理实验中成功地将链从静止状态过渡到前两种旋转模式，证明了该策略的有效性。

**Conclusion:** 所探索的概念在确保钻杆和纺纱操作的安全性和效率方面具有关键应用。

> **ai_Abstract:** 本文研究了机器人机械臂操纵底部固定均匀旋转链的问题，针对现有研究未解决的稳定形状转换问题，提出了一种新的操纵策略。该策略基于对链构型空间同胚于三维立方体的发现，旨在实现稳定且可行的不同旋转模式间的转换。物理实验验证了该策略的有效性，成功实现了从静止到前两种旋转模式的过渡，其概念对钻杆和纺纱等操作的安全性和效率至关重要。

> **摘要翻译:** 本文研究了使用机器人手臂操纵底端固定、均匀旋转的链条的问题。现有研究已经探讨了实际应用的理想旋转形状，但没有讨论如何通过操纵规划持续实现这些形状。我们的工作提出了一种用于稳定和一致形状转换的操纵策略。我们发现此类链条的构型空间与三维立方体同胚。利用这一特性，我们提出了一种策略，可以在考虑稳定性和可行性的前提下，将链条操纵到不同的构型，特别是从一种旋转模式转换到另一种。我们通过物理实验成功地从静止状态过渡到前两种旋转模式，证明了我们策略的有效性。我们工作中探索的概念在确保钻杆和纺纱操作的安全性和效率方面具有关键应用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [323] [CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations](https://arxiv.org/abs/2507.08262)
> *CL3R：用于增强机器人操作表示的3D重建和对比学习*

*Wenbo Cui, Chengyang Zhao, Yuhui Chen, Haoran Li, Zhizheng Zhang, Dongbin Zhao, He Wang* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D重建, 对比学习, 机器人操作, 视觉运动策略

**Comment:** 

> **TL;DR:** CL3R是一个新的3D预训练框架，结合3D重建和2D对比学习，以提高机器人视觉运动策略的感知能力和泛化性，尤其是在细粒度操作中。

**AI_Comments:** CL3R的创新点在于其结合了3D点云掩码自编码器学习空间信息和2D预训练模型的对比学习进行语义迁移，有效弥补了现有方法在3D感知和跨视角泛化方面的不足。通过统一坐标系和多视角融合进一步提升了模型的鲁棒性，对于需要精细操作的机器人任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器人感知模块在利用预训练2D模型时，难以捕捉3D空间信息且在不同相机视角下泛化能力差，这限制了其在细粒度机器人操作中的有效性。

**Method:** 本文提出CL3R框架，通过点云掩码自编码器学习丰富的3D表示，并通过对比学习利用预训练的2D基础模型进行高效语义知识迁移。此外，通过统一数据集的坐标系和引入多视角点云的随机融合，减轻了相机视角模糊性并提高了泛化能力。

**Result:** 在模拟和真实世界中的大量实验证明，CL3R方法优于现有方法，突出了其在机器人操作视觉运动策略学习中的有效性。

**Conclusion:** CL3R通过结合3D重建和2D对比学习，有效解决了现有方法在捕捉3D空间信息和跨视角泛化方面的不足，显著增强了机器人操作的感知能力和策略学习效果。

> **ai_Abstract:** 本文提出CL3R，一个结合3D重建和2D对比学习的新型3D预训练框架，旨在解决现有机器人感知模块在捕捉3D空间信息和跨视角泛化方面的不足。CL3R通过点云掩码自编码器学习3D表示，并利用预训练2D模型进行语义迁移，同时通过统一坐标系和多视角点云融合增强泛化能力，实验证明其在机器人操作视觉运动策略学习中表现优异。

> **摘要翻译:** 构建一个鲁棒的感知模块对于视觉运动策略学习至关重要。尽管最近的方法将预训练的2D基础模型整合到机器人感知模块中以利用其强大的语义理解能力，但它们难以捕捉3D空间信息，并且在不同相机视角下泛化能力差。这些局限性阻碍了策略的有效性，尤其是在细粒度机器人操作场景中。为了解决这些挑战，我们提出了CL3R，一个新颖的3D预训练框架，旨在增强机器人操作策略。我们的方法通过采用点云掩码自编码器学习丰富的3D表示，同时通过对比学习利用预训练的2D基础模型进行高效的语义知识迁移，从而整合了空间感知和语义理解。此外，我们提出了一个用于机器人任务的3D视觉表示预训练框架。通过统一数据集的坐标系并引入多视角点云的随机融合，我们减轻了相机视角模糊性并提高了泛化能力，从而在测试时能够从新颖的视角进行鲁棒感知。在模拟和真实世界中的大量实验证明了我们方法的优越性，突出了其在机器人操作视觉运动策略学习中的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [343] [Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots](https://arxiv.org/abs/2507.08303)
> *学习通过关键对抗性攻击实现人形机器人鲁棒运动技能*

*Yang Zhang, Zhanxiang Cao, Buqing Nie, Haoyang Li, Yue Gao* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 人形机器人, 鲁棒性, 对抗训练, 运动技能, 强化学习

**Comment:** 10 pages, 9 figures

> **TL;DR:** 基于强化学习的人形机器人运动策略因仿真到现实的差异而缺乏鲁棒性。本文提出了一种新颖的鲁棒对抗训练范式，通过可学习的对抗攻击网络识别并利用策略弱点，动态增强机器人运动策略的鲁棒性，从而显著提升了机器人在真实世界中应对挑战性地形和进行全身控制的性能。

**AI_Comments:** 该论文的创新之处在于利用可学习的对抗攻击网络，在一个动态对抗训练框架内，专门针对并提高人形机器人运动策略在真实世界扰动下的鲁棒性。这种方法直接解决了机器人实际应用中关键的仿真到现实迁移问题。

<details>
  <summary>Details</summary>

**Motivation:** 基于强化学习的运动策略常因仿真到现实的动力学差异而导致鲁棒性下降，从而影响真实人形机器人的敏捷性。

**Method:** 本文提出了一种新颖的鲁棒对抗训练范式。该范式引入了一个可学习的对抗攻击网络，该网络能够精确识别运动策略中的脆弱点并施加有针对性的扰动，通过动态对抗训练迫使运动策略增强其对抗扰动的鲁棒性。

**Result:** 在Unitree G1人形机器人上进行的感知运动和全身控制任务实验表明，所提出的方法显著增强了机器人在真实环境中的运动鲁棒性，使其能够成功穿越挑战性地形并实现高度敏捷的全身轨迹跟踪。

**Conclusion:** 本文提出的鲁棒对抗训练范式，通过其可学习的对抗攻击网络，有效提升了人形机器人在真实世界中的运动鲁棒性，使其能够成功应对复杂任务。

> **ai_Abstract:** 本文旨在解决人形机器人基于强化学习的运动策略在仿真到现实迁移中因动力学差异导致的鲁棒性下降问题。为此，文章提出了一种新颖的鲁棒对抗训练范式，其核心是引入一个可学习的对抗攻击网络。该网络能够精确识别运动策略的脆弱点并施加有针对性的扰动，从而通过动态对抗训练强制提升策略的鲁棒性。在Unitree G1人形机器人上进行的感知运动和全身控制任务实验验证了该方法的有效性，结果显示其显著增强了机器人在真实环境中的运动鲁棒性，使其能够成功穿越挑战性地形并实现高敏捷的全身轨迹跟踪。

> **摘要翻译:** 人形机器人在日常任务中展现出巨大潜力。然而，基于强化学习的运动策略常常因仿真到现实的动力学差异而导致鲁棒性下降，从而影响真实机器人的敏捷性。在这项工作中，我们提出了一种新颖的鲁棒对抗训练范式，旨在增强人形机器人在真实世界中运动策略的鲁棒性。该范式引入了一个可学习的对抗攻击网络，该网络能够精确识别运动策略中的脆弱点并施加有针对性的扰动，通过动态对抗训练迫使运动策略增强其对抗扰动的鲁棒性。我们在Unitree G1人形机器人上进行了感知运动和全身控制任务的实验。结果表明，我们提出的方法显著增强了机器人在真实环境中的运动鲁棒性，使其能够成功穿越挑战性地形并实现高度敏捷的全身轨迹跟踪。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [344] [A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots](https://arxiv.org/abs/2506.20487)
> *行为基础模型综述：人形机器人下一代全身控制系统*

*Mingqi Yuan, Tao Yu, Wenqi Ge, Xiuyong Yao, Huijiang Wang, Jiayu Chen, Xin Jin, Bo Li, Hua Chen, Wei Zhang, Wenjun Zeng* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 行为基础模型, 人形机器人, 全身控制, 大规模预训练, 综述

**Comment:** 18 pages, 9 figures

> **TL;DR:** 本文综述了行为基础模型（BFMs）作为人形机器人全身控制（WBC）的新范式，它通过大规模预训练解决传统方法的局限性，实现可扩展和通用的机器人智能。

**AI_Comments:** 本文作为一篇综述，在行为基础模型这一新兴领域具有重要价值。其创新性在于将BFMs定位为解决人形机器人全身控制这一核心挑战的下一代解决方案。其重要性体现在为未来研究提供了全面的背景和方向，特别是在如何利用大规模预训练实现人形机器人的通用智能方面。

<details>
  <summary>Details</summary>

**Motivation:** 人形机器人全身控制面临复杂动力学、欠驱动和任务多样性等挑战，而现有基于学习的控制器需要耗时且昂贵的再训练以适应新场景，这限制了其在实际应用中的可行性。

**Method:** 本文对用于人形机器人全身控制的行为基础模型（BFMs）进行了全面综述，追溯了其在不同预训练流程中的发展，并讨论了其现实应用、当前局限性、紧迫挑战和未来机遇。

**Result:** 该综述讨论了行为基础模型在人形机器人全身控制中的现实应用、当前局限性、紧迫挑战和未来机遇。它将行为基础模型定位为实现可扩展和通用人形智能的关键方法，并提供了一个精选的长期行为基础模型论文和项目列表以促进后续研究。

**Conclusion:** 行为基础模型是实现人形机器人可扩展和通用智能的关键方法，能有效解决全身控制的根本挑战。

> **ai_Abstract:** 本文综述了行为基础模型（BFMs）在解决人形机器人全身控制（WBC）挑战中的新兴作用。它指出，传统学习方法面临昂贵再训练的局限性，而BFMs通过大规模预训练学习可重用技能和行为先验，从而实现零样本或快速适应。该综述全面探讨了BFM的发展、预训练流程、实际应用、当前局限性、紧迫挑战和未来机遇，强调BFMs是实现人形机器人可扩展和通用智能的关键途径。

> **摘要翻译:** 人形机器人作为复杂运动控制、人机交互和通用物理智能的多功能平台正受到广泛关注。然而，由于复杂的动力学、欠驱动和多样的任务需求，在人形机器人中实现高效的全身控制（WBC）仍然是一个根本性挑战。尽管基于学习的控制器在复杂任务中展现出潜力，但它们对新场景劳动力密集且成本高昂的再训练的依赖限制了实际应用。为了解决这些局限性，行为（化）基础模型（BFMs）作为一种新范式应运而生，它利用大规模预训练来学习可重用的原始技能和广泛的行为先验知识，从而实现对各种下游任务的零样本或快速适应。在本文中，我们全面概述了用于人形机器人全身控制的行为基础模型，追溯了它们在不同预训练流程中的发展。此外，我们讨论了现实应用、当前局限性、紧迫挑战和未来机遇，将行为基础模型定位为实现可扩展和通用人形智能的关键方法。最后，我们提供了一个精选的长期行为基础模型论文和项目列表，以促进更多的后续研究，该列表可在 https://github.com/yuanmingqi/awesome-bfm-papers 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [364] [Joint Optimization-based Targetless Extrinsic Calibration for Multiple LiDARs and GNSS-Aided INS of Ground Vehicles](https://arxiv.org/abs/2507.08349)
> *基于联合优化的多LiDAR和GNSS辅助INS地面车辆无目标外部校准*

*Junhui Wang, Yan Qiao, Chao Gao, Naiqi Wu* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 外部校准, LiDAR, GNSS-Aided INS, 联合优化, 无目标

**Comment:** 

> **TL;DR:** 提出了一种新的多LiDAR和GNSS-辅助INS的无目标外部校准方法，通过联合优化和GINS安装高度约束解决现有方法的局限性和平面运动可观测性问题，并在仿真和真实数据集上验证了其准确性。

**AI_Comments:** 该论文的创新点在于提出了无目标外部校准方法，并通过引入GINS安装高度约束解决了平面运动下的可观测性问题，以及通过联合优化框架提高了校准精度和鲁棒性。这对于智能采矿等实际应用场景中多传感器融合的可靠性具有重要意义，尤其是在没有GPS信号或难以设置人工目标的复杂环境中。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法依赖于人工目标、重叠视野或精确轨迹估计，这些假设在实际中可能不成立。此外，采矿车辆的平面运动导致可观测性问题，降低了校准性能。因此，需要一种无需这些假设且能解决可观测性问题的无目标外部校准方法。

**Method:** 提出了一种无目标外部校准方法，将多个车载LiDAR传感器与GINS坐标系对齐，无需重叠传感器视图或外部目标。引入基于GINS单元已知安装高度的观测模型，以约束平面运动下不可观测的校准参数。开发了一个联合优化框架，通过整合几何对应关系和运动一致性派生的多个约束来改进外部参数和GINS轨迹。该方法适用于异构LiDAR配置。

**Result:** 在模拟和真实世界数据集上的大量实验证明了该方法在不同传感器设置下的准确性、鲁棒性和实际适用性。

**Conclusion:** 本研究提出的基于联合优化的无目标外部校准方法，通过解决传统方法的局限性和平面运动带来的可观测性问题，实现了多LiDAR和GNSS辅助INS的精确校准，为智能采矿环境中的可靠传感器融合提供了重要支持。

> **ai_Abstract:** 本文针对智能采矿环境中多LiDAR与GNSS辅助惯性导航系统（GINS）之间外部校准的挑战，提出了一种基于联合优化的无目标校准方法。该方法解决了现有技术依赖特定假设和平面运动导致可观测性差的问题。通过引入GINS安装高度作为观测模型约束不可观测参数，并构建联合优化框架以整合几何对应和运动一致性约束来精化校准参数和GINS轨迹。实验证明该方法在不同传感器配置下具有高精度、鲁棒性和实用性，适用于异构LiDAR系统。

> **摘要翻译:** 多LiDAR传感器与GNSS辅助惯性导航系统（GINS）之间精确的外部校准对于在智能采矿环境中实现可靠的传感器融合至关重要。这种校准通过将车载传感器感知数据对齐到统一的全局参考系，从而实现车辆与道路的协同。然而，现有方法通常依赖于人工目标、重叠视野或精确的轨迹估计，这些假设在实际中可能不成立。此外，采矿车辆的平面运动导致可观测性问题，从而降低了校准性能。本文提出了一种无目标的外部校准方法，该方法将多个车载LiDAR传感器与GINS坐标系对齐，无需重叠传感器视图或外部目标。所提出的方法引入了一个基于GINS单元已知安装高度的观测模型，以约束平面运动下不可观测的校准参数。开发了一个联合优化框架，通过整合几何对应关系和运动一致性派生的多个约束来改进外部参数和GINS轨迹。所提出的方法适用于异构LiDAR配置，包括机械式和固态传感器。在模拟和真实世界数据集上的大量实验证明了该方法在不同传感器设置下的准确性、鲁棒性和实际适用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [379] [AI Space Cortex: An Experimental System for Future Era Space Exploration](https://arxiv.org/abs/2507.06574)
> *AI太空皮质：未来时代太空探索的实验系统*

*Thomas Touma, Ersin Daş, Erica Tevere, Martin Feather, Ksenia Kolcio, Maurice Prather, Alberto Candela, Ashish Goel, Erik Kramer, Hari Nayar, Lorraine Fesq, Joel W. Burdick* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 自主性, 冰冷卫星, 异常检测, AI, 太空探索

**Comment:** 

> **TL;DR:** 该研究提出了一种名为REASIMO的AI驱动的自主系统，旨在应对冰冷卫星（如欧洲和恩塞拉多斯）探索任务的挑战，该系统能够自主检测和从异常中恢复，并在没有地面通信延迟的情况下执行任务。

**AI_Comments:** 该研究在应对深空探索中的关键挑战方面迈出了重要一步，特别是对于像欧洲和恩塞拉多斯这样的冰冷卫星。通过开发一个能够自主处理异常并执行复杂操作的AI系统，该研究为未来的太空任务铺平了道路。然而，在实际部署之前，还需要对该系统的鲁棒性、安全性和适应性进行更广泛的测试。

<details>
  <summary>Details</summary>

**Motivation:** 未来对欧洲和恩塞拉多斯等冰冷卫星的深海探测任务面临通信延迟长、电力有限以及辐射损伤和恶劣条件导致的使用寿命有限等重大操作挑战。因此，船载自主性对于此类任务至关重要，不仅要管理名义上的着陆器操作，还要在出现异常情况时做出适当反应。

**Method:** 该研究旨在演示一种用于此类任务的AI辅助自主性水平，包括检测和从异常中恢复的能力，以及基于预训练行为执行任务的能力。研究人员开发了一个AI辅助的、具有个性驱动的智能框架来控制深海探测任务，并将这些技术结合在一个框架中。为了演示该框架的能力，研究人员在NASA喷气推进实验室的一个着陆器-操纵器测试台上对自主采样操作进行了测试，模拟了此类任务可能遇到的表面条件。

**Result:** 在NASA喷气推进实验室的一个着陆器-操纵器测试台上对自主采样操作进行了测试，模拟了此类任务可能遇到的表面条件。

**Conclusion:** 通过将高级技术混合在一个框架中，该研究开发了一个AI辅助的、具有个性驱动的智能框架来控制深海探测任务，并演示了其在模拟的表面条件下的自主采样能力。

> **ai_Abstract:** 该研究介绍了REASIMO项目，一个为冰冷卫星探索任务设计的AI驱动的自主系统。该系统旨在克服深空通信延迟、电力限制和恶劣环境等挑战，通过自主检测和恢复异常来增强任务的鲁棒性，并基于预先训练的行为而非硬编码逻辑执行任务，从而提高任务的成功率。

> **摘要翻译:** 我们稳健、可解释的科学冰冷卫星操作自主性（REASIMO）工作为美国宇航局的冰冷卫星生命探测技术（COLDTech）计划做出了贡献，该计划探索了像欧洲和恩塞拉多斯这样的冰冷卫星的科学平台技术。冰冷卫星任务带来了重大的操作挑战。这些挑战包括长通信延迟、电力有限以及由于辐射损伤和恶劣条件导致的使用寿命有限。鉴于这些操作限制，船载自主性对于未来的冰冷卫星任务至关重要。除了管理名义上的着陆器操作外，船载自主性还必须在出现异常情况时做出适当反应。传统的航天器依赖于过渡到“安全模式”，在这种模式下，非关键组件和子系统被断电以确保安全并与地球保持通信。对于严重时间受限的冰冷卫星任务而言，在没有地面回路通信和相关延迟的情况下执行这些异常情况的解决方案对于完成任务目标和科学目标至关重要。为了应对这些挑战，REASIMO工作旨在演示此类任务的稳健水平的AI辅助自主性，包括检测和从异常中恢复的能力，以及基于预训练行为而非像所有先前太空任务那样的硬编码、预定逻辑来执行任务的能力。我们通过结合一系列高级技术，开发了一个AI辅助的、具有个性驱动的智能框架来控制冰冷卫星任务。为了演示该框架的能力，我们在NASA喷气推进实验室的一个着陆器-操纵器测试台上对自主采样操作进行了测试，模拟了此类任务可能遇到的表面条件。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [383] [Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework](https://arxiv.org/abs/2507.08364)
> *通往鲁棒传感器融合地面SLAM：一个全面的基准和弹性框架*

*Deteng Zhang, Junjie Zhang, Yan Sun, Tao Li, Hao Yin, Hongzhao Xie, Jie Yin* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** SLAM, 传感器融合, 基准测试, 鲁棒性, M3DGR

**Comment:** This paper has already been accepted to IROS2025. 8 pages

> **TL;DR:** 该研究提出了M3DGR数据集和Ground-Fusion++框架，以解决现有SLAM方法在结构化环境下的鲁棒性问题，并对40种SLAM系统进行了基准测试。

**AI_Comments:** 该研究通过提供标准化的基准数据集和先进的融合框架，有效地解决了现有SLAM方法在鲁棒性方面的挑战。M3DGR数据集的全面性和Ground-Fusion++框架的模块化设计是其主要创新点。然而，框架在实际部署中的计算成本和对不同硬件平台的兼容性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有SLAM方法在结构化环境下的鲁棒性不足，且缺乏系统评估SLAM算法在不同降级场景下性能的标准化基准，同时现有框架融合的传感器类型有限且未能有效解决自适应传感器选择策略。

**Method:** 1. 提出M3DGR数据集，包含视觉挑战、激光雷达退化、车轮打滑和GNSS拒止等系统性诱导退化模式。2. 在M3DGR上对40种SLAM系统进行了全面评估。3. 开发了一个名为Ground-Fusion++的弹性模块化多传感器融合框架，融合了GNSS、RGB-D、激光雷达、IMU和轮式里程计。

**Result:** 在M3DGR数据集上对40种SLAM系统进行了全面评估，揭示了它们在挑战性真实世界条件下的鲁棒性和局限性。Ground-Fusion++框架通过融合多种传感器实现了鲁棒性能。

**Conclusion:** 通过提出M3DGR数据集和Ground-Fusion++框架，该研究为评估和提高传感器融合地面SLAM的鲁棒性提供了解决方案，并为未来的研究奠定了基础。

> **ai_Abstract:** 该研究旨在提高传感器融合地面SLAM系统的鲁棒性。作者提出了一个新的数据集M3DGR，其中包含各种模拟的降级场景，并对40种现有的SLAM系统进行了全面的基准测试。此外，他们还开发了一个名为Ground-Fusion++的模块化多传感器融合框架，该框架能够自适应地融合GNSS、RGB-D、LiDAR、IMU和轮式里程计等多种传感器，以应对不同的环境条件，并在测试中表现出良好的鲁棒性。

> **摘要翻译:** 尽管针对结构化环境的SLAM方法取得了相当大的进展，但它们在具有挑战性的极端情况下的鲁棒性仍然是一个关键限制。尽管集成多种传感器的多传感器融合方法已显示出有希望的性能改进，但研究界面临两个关键障碍：一方面，缺乏标准化和可配置的基准来系统地评估SLAM算法在不同降级场景下的性能，阻碍了全面的性能评估。另一方面，现有的SLAM框架主要侧重于融合有限类型的传感器，而未能有效解决针对不同环境条件下的自适应传感器选择策略。
为了弥合这些差距，我们做出了三项关键贡献：首先，我们推出了M3DGR数据集：一个富含传感器的基准，具有系统诱导的退化模式，包括视觉挑战、激光雷达退化、车轮打滑和GNSS拒止。其次，我们在M3DGR上对40种SLAM系统进行了全面评估，提供了对其在挑战性真实世界条件下的鲁棒性和局限性的关键见解。第三，我们开发了一个弹性的模块化多传感器融合框架，名为Ground-Fusion++，通过耦合GNSS、RGB-D、激光雷达、IMU（惯性测量单元）和轮式里程计，展示了鲁棒的性能。代码和数据集是公开的。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [403] [Intelligent Control of Spacecraft Reaction Wheel Attitude Using Deep Reinforcement Learning](https://arxiv.org/abs/2507.08366)
> *基于深度强化学习的航天器反应轮姿态智能控制*

*Ghaith El-Dalahmeh, Mohammad Reza Jabbarpour, Bao Quoc Vo, Ryszard Kowalczyk* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 深度强化学习, 航天器姿态控制, 反应轮故障, TD3-HD, 容错控制

**Comment:** 

> **TL;DR:** 该研究提出了一种名为TD3-HD的深度强化学习控制策略，通过结合TD3、HER和DWC，提高了航天器在反应轮故障下的姿态控制鲁棒性和实时适应性，实验结果优于传统PD控制器和其他主流DRL算法。

**AI_Comments:** 该研究在航天器姿态控制领域提出了创新的TD3-HD方法，有效解决了反应轮故障下的控制难题，并取得了优于现有方法的实验结果，显示了其在实际应用中的巨大潜力。然而，算法的计算复杂度和在真实硬件上的部署效率仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 随着卫星自主化和在不确定环境中运行的需求增加，可靠的卫星姿态控制至关重要，尤其是在反应轮故障时保持控制韧性以达成任务目标和系统稳定性。

**Method:** 提出了一种基于深度强化学习（DRL）的控制策略，具体结合了Twin Delayed Deep Deterministic Policy Gradient (TD3)、Hindsight Experience Replay (HER) 和 Dimension Wise Clipping (DWC)，并将其命名为TD3-HD，以增强在稀疏奖励环境中的学习能力，并在反应轮故障期间维持卫星稳定性。

**Result:** 与传统的PD控制和领先的DRL算法（如TD3、PPO、A2C）相比，TD3-HD在故障条件下实现了显著更低的姿态误差、更优的角速度调节以及更强的稳定性。

**Conclusion:** 所提出的TD3-HD方法在自主卫星姿态控制方面展现出巨大潜力，可作为一种强大的、容错的、机载人工智能解决方案。

> **ai_Abstract:** 本研究提出了一种名为TD3-HD的深度强化学习控制策略，该策略结合了TD3、HER和DWC，旨在提高航天器在反应轮故障情况下的姿态控制能力。通过实验验证，TD3-HD在降低姿态误差、调节角速度和维持稳定性方面优于传统的PD控制器和其他DRL算法，为实现自主、容错的航天器姿态控制提供了新的解决方案。

> **摘要翻译:** 可靠的卫星姿态控制对于太空任务的成功至关重要，特别是随着卫星在动态和不确定的环境中日益自主运行。反作用轮（RWs）在姿态控制中起着举足轻重的作用，在RWs故障期间保持控制韧性对于维护任务目标和系统稳定性至关重要。然而，传统的比例导数（PD）控制器和现有的深度强化学习（DRL）算法，如TD3、PPO和A2C，在为自主卫星运行提供实时适应性和故障容忍度方面往往不足。本研究引入了一种基于DRL的控制策略，旨在提高卫星在故障条件下的韧性和适应性。具体而言，所提出的方法集成了Twin Delayed Deep Deterministic Policy Gradient (TD3) 与 Hindsight Experience Replay (HER) 和 Dimension Wise Clipping (DWC)，称为TD3-HD，以增强在稀疏奖励环境中的学习能力，并在RW故障期间维持卫星稳定性。将所提出的方法与PD控制和领先的DRL算法进行了基准测试。实验结果表明，TD3-HD在故障条件下实现了显著更低的姿态误差、更优的角速度调节和更强的稳定性。这些发现凸显了所提出方法作为自主卫星姿态控制的强大、容错的机载人工智能解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [428] [LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to Construct 3D City Maps](https://arxiv.org/abs/2507.08420)
> *通过动态时间规整实现激光雷达、GNSS和IMU传感器对齐以构建3D城市地图*

*Haitian Wang, Hezam Albaqami, Xinyu Wang, Muhammad Ibrahim, Zainy M. Malakan, Abdullah M. Algamdi, Mohammed H. Alghamdi, Ajmal Mian* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** LiDAR, GNSS, IMU, 3D City Mapping, Dynamic Time Warping

**Comment:** Preparing to submit to International Journal of Applied Earth
  Observation and Geoinformation

> **TL;DR:** 该研究提出了一种融合激光雷达、GNSS和IMU数据的框架，使用动态时间规整进行时间对齐，并通过卡尔曼滤波和图优化来构建高精度的3D城市地图，同时发布了一个大规模多模态数据集以供未来研究。

**AI_Comments:** 该研究通过融合多种传感器数据并采用动态时间规整技术解决了3D城市地图构建中的关键挑战——累积漂移问题，取得了显著的精度提升。所发布的大规模多模态数据集对于推动相关领域的研究具有重要价值。然而，在不同复杂城市环境下的泛化能力以及实时性方面的进一步验证将是未来研究的重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 激光雷达地图构建存在累积漂移导致全局失准的问题，尤其是在GNSS受限的环境中。

**Method:** 提出了一种融合激光雷达、GNSS和IMU数据的统一框架。该方法使用动态时间规整进行基于速度的时间对齐，并通过扩展卡尔曼滤波优化GNSS和IMU信号。使用法线分布变换配准和包含回环检测的位姿图优化来构建局部地图，并通过GNSS约束锚点和重叠片段的精细配准来强制全局一致性。引入了一个大规模多模态数据集，包含激光雷达、GNSS和IMU数据。

**Result:** 该方法将平均全局对齐误差从3.32米减少到1.24米，提高了61.4%。

**Conclusion:** 该方法和数据集为评估GNSS受限环境下的3D城市地图构建设定了新的基准，构建的高保真地图支持智慧城市规划、地理空间数据集成、基础设施监控和无GPS导航等多种应用。

> **ai_Abstract:** 该研究提出了一种创新的框架，通过融合激光雷达（LiDAR）、全球导航卫星系统（GNSS）和惯性测量单元（IMU）数据，并利用动态时间规整（DTW）进行传感器的时间对齐，以解决LiDAR建图中的累积漂移问题，从而构建高精度的3D城市地图。该方法结合了卡尔曼滤波、法线分布变换配准和图优化技术，并引入了一个大规模多模态数据集，在实际测试中显著提高了全局对齐精度。此项工作为3D城市测绘领域树立了新的标杆。

> **摘要翻译:** 基于激光雷达的3D地图构建存在累积漂移导致全局失准的问题，尤其是在GNSS受限的环境中。为了解决这个问题，我们提出了一个统一的框架，融合激光雷达、GNSS和IMU数据，以实现高分辨率的城市规模测绘。该方法使用动态时间规整进行基于速度的时间对齐，并通过扩展卡尔曼滤波优化GNSS和IMU信号。使用基于法线分布变换的配准和包含回环检测的位姿图优化来构建局部地图，同时通过GNSS约束锚点和重叠片段的精细配准来强制全局一致性。我们还引入了一个在澳大利亚西珀斯捕获的大规模多模态数据集，以促进这方面的未来研究。我们的数据集包含使用128通道Ouster激光雷达、同步RTK-GNSS轨迹和MEMS-IMU测量在21个城市回路中捕获的144,000帧。为了评估几何一致性，我们使用基于道路中心线和交叉口的对齐指标来评估我们的方法，以同时捕捉全局和局部精度。我们的方法将平均全局对齐误差从3.32米减少到1.24米，提高了61.4%。构建的高保真地图支持广泛的应用，包括智慧城市规划、地理空间数据集成、基础设施监控和无GPS导航。我们的方法和数据集共同为评估GNSS受限环境下的3D城市地图构建设定了新的基准。数据集和代码将公开发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [458] [Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms](https://arxiv.org/abs/2506.16710)
> *实验装置和软件管线用于评估基于优化的自主多机器人搜索算法*

*Aditya Bhatt, Mary Katherine Corra, Franklin Merlo, Prajit KrisshnaKumar, Souma Chowdhury* | **Category: cs.RO, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 多机器人搜索, 实验设置, 软件管线, 模拟到现实, 机器人定位

**Comment:** Accepted for presentation in proceedings of ASME IDETC 2025

> **TL;DR:** 提出一个用于评估多机器人搜索算法的实验室物理设置和开源软件管线，解决了现有算法多在模拟中测试的问题。

**AI_Comments:** 该研究填补了多机器人搜索算法在实际物理环境中评估的空白，提出的实验室设置成本低廉且易于复现，对于推动相关算法的研发和落地具有重要意义。声源的信噪比不确定性设计也为评估sim-to-real差距提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数多机器人搜索算法仅在模拟中进行测试，缺乏在实际物理环境中进行评估和比较的知识，尤其是在搜索和计算性能方面。

**Method:** 提出一个实验室规模的物理设置，使用声源和小型地面机器人（e-pucks）在运动捕捉环境中进行操作。配套的开源软件管线易于接口，可并行异步执行，并包含一个用于分布式实现和ROS支持的运动捕捉定位框架。

**Result:** 该设置被用于评估两种最先进的多机器人搜索算法（基于群体优化和批量贝叶斯优化，称为Bayes-Swarm）以及一个随机游走基线。

**Conclusion:** 所提出的新颖设置能够有效地评估多机器人搜索算法的性能，并有助于评估模拟到现实的差距。

> **ai_Abstract:** 本文介绍了一个创新的实验室规模物理设置和开源软件管线，旨在解决现有机器人搜索算法多在模拟中测试的问题。该系统使用声源和e-pucks机器人，结合运动捕捉技术，并兼容ROS，便于集成和评估各种多机器人搜索算法的实际性能，并已成功用于测试两种先进算法。

> **摘要翻译:** 信号源定位是多机器人系统领域的一个研究热点，因为它在各种工业和户外环境中的搜救及危险源定位方面有广泛应用。存在多种多机器人搜索算法，它们通常将相关的自主运动规划问题表述并解决为一个启发式无模型或基于信念模型的优化过程。然而，这些算法中的大多数仅在模拟中进行测试，因此失去了在实际物理环境中比较这些算法在搜索性能和实时计算性能方面的异同的知识生成机会。为了解决这一差距，本文提出了一个新的实验室规模物理设置和相关的开源软件管线，用于评估和基准测试多机器人搜索算法。所提出的物理设置创新性地使用了一个声源（安全且廉价）和小型地面机器人（e-pucks），在标准的运动捕捉环境中进行操作。该设置可以被大多数机器人研究人员轻松复制和使用。声源的信噪比也带来有趣的[不确定性]，这有助于评估模拟到现实的差距。整个软件管线设计为能够以最小的努力轻松地与任何多机器人搜索算法接口，并可以并行异步形式执行。该管线包括一个用于多机器人或群体搜索算法分布式实现的框架，并集成了基于ROS（机器人操作系统）的软件堆栈，用于运动捕捉支持的定位。通过使用该设置评估两种最先进的多机器人搜索算法，即基于群体优化和批量贝叶斯优化（称为Bayes-Swarm）的算法，以及一个随机游走基线，来证明该新颖设置的实用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [463] [Robotic Calibration Based on Haptic Feedback Improves Sim-to-Real Transfer](https://arxiv.org/abs/2507.08572)
> *基于触觉反馈的机器人校准可改善模拟到现实的迁移*

*Juraj Gavura, Michal Vavrecka, Igor Farkas, Connor Gade* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 机器人校准,触觉反馈,模拟到现实迁移,逆运动学,神经网络

**Comment:** ICANN 2025

> **TL;DR:** 该研究提出了一种基于触觉反馈的机器人校准方法，利用触摸屏获取真实末端执行器位置，并通过线性变换和神经网络构建转换函数，有效解决了模拟与现实之间的差异，显著降低了定位误差，其中非线性神经网络模型效果最佳。

**AI_Comments:** 这项研究提出了一种创新的方法来解决机器人模拟到现实迁移中的关键挑战——末端执行器位置的差异。利用触觉反馈和触摸屏来获取真实世界的EE位置信息是一种巧妙的解决方案，尤其是在仅有模拟EE位置可用时。所提出的基于线性变换和神经网络的转换函数能够处理部分输入，这使得该方法具有很强的通用性。研究结果表明非线性神经网络模型的优越性，为提高机器人操作的准确性和可靠性提供了有力的证据。该方法在需要高精度定位的机器人应用中具有广泛的应用前景，例如精密装配、手术机器人等。然而，该方法对于触摸屏的依赖性以及校准过程的效率和鲁棒性可能需要进一步的考察和优化。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人操作任务中，逆运动学（IK）控制的机器人手臂在模拟器中的末端执行器（EE）位置与现实中的物理EE之间存在差异。在大多数模拟到现实迁移的机器人场景中，虽然可以获取模拟和现实中的关节位置，但EE位置仅在模拟中可用。

**Method:** 开发了一种基于触觉反馈校准的新方法。利用机器人前方的触摸屏获取真实环境中EE的位置信息。在校准过程中，机器人接触屏幕上的特定点并存储信息。然后，基于线性变换和神经网络构建一个转换函数，能够从任何部分输入（模拟/真实关节/EE位置）输出所有缺失的变量。

**Result:** 结果表明，一个完全非线性的神经网络模型表现最佳，显著减少了定位误差。

**Conclusion:** 基于触觉反馈的机器人校准方法能够有效解决模拟到现实迁移中的位置差异问题，通过神经网络模型可以显著降低定位误差。

> **ai_Abstract:** 本研究提出了一种新颖的基于触觉反馈的机器人校准方法，以解决机器人操作任务中模拟与现实之间末端执行器（EE）位置的差异问题。通过使用机器人前方的触摸屏获取真实EE的位置信息，并结合线性变换和神经网络，研究人员构建了一个能够从部分输入（模拟/真实关节/EE位置）推断缺失变量的转换函数。实验结果表明，非线性神经网络模型在降低定位误差方面表现出色，有效提高了模拟到现实的迁移精度。

> **摘要翻译:** 在逆运动学（IK）用于控制机器人手臂以执行操作任务时，模拟器中的机器人手臂模型末端执行器（EE）位置与现实中的物理EE之间通常存在差异。在大多数机器人模拟到现实迁移场景中，我们都能获得模拟和现实中的关节位置信息，但EE位置仅在模拟中可用。我们开发了一种新颖的方法来克服这一困难，该方法基于触觉反馈校准，利用机器人前方的触摸屏，提供真实环境中EE的位置信息。在校准过程中，机器人触摸屏幕上的特定点，并将信息存储起来。在下一阶段，我们基于线性变换和神经网络构建了一个转换函数，该函数能够从任何部分输入（模拟/真实关节/EE位置）输出所有缺失的变量。我们的结果表明，一个完全非线性的神经网络模型表现最佳，显著减少了定位误差。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [503] [Multi-critic Learning for Whole-body End-effector Twist Tracking](https://arxiv.org/abs/2507.08656)
> *多批评者学习用于全身末端执行器扭曲跟踪*

*Aravind Elanjimattathil Vijayan, Andrei Cramariuc, Mattia Risiglione, Christian Gehring, Marco Hutter* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 全身控制, 末端执行器跟踪, 强化学习, 多批评者学习, 扭曲控制

**Comment:** 

> **TL;DR:** 该研究提出了一种基于强化学习的框架，用于全身控制，以跟踪末端执行器的扭曲，解决了任务冲突和对末端执行器速度控制的限制，并使用多批评者架构和基于扭曲的任务制定。

**AI_Comments:** 这项工作在解决全身控制中的任务冲突和精确的末端执行器轨迹跟踪方面取得了重大进展。多批评者架构和基于扭曲的任务制定是新颖的贡献，它们共同提高了控制器的性能和灵活性。然而，在现实世界应用中，算法的鲁棒性和对未知环境的适应性仍然是未来研究需要考虑的方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习方法在处理运动和手臂运动等具有冲突目标的全身控制任务时面临挑战，并且缺乏直接控制末端执行器速度的能力，这使得平稳执行轨迹变得困难。

**Method:** 提出了一种基于强化学习的框架，采用多批评者演员架构，将运动和操纵的奖励信号分离，并设计了一种基于扭曲的末端执行器任务制定，以跟踪离散姿势和运动轨迹。

**Result:** 所提出的控制器能够同时进行行走和移动末端执行器，并表现出涌现的全身行为，例如底座辅助手臂扩展工作空间，即使没有明确的公式。

**Conclusion:** 该方法通过多批评者架构和基于扭曲的任务制定，成功地实现了全身末端执行器扭曲跟踪，解决了现有方法的局限性，并在模拟和硬件实验中得到了验证。

> **ai_Abstract:** 本研究提出了一种新颖的强化学习框架，用于全身末端执行器扭曲跟踪，解决了传统方法在处理运动和操纵等具有冲突目标的任务以及末端执行器速度控制方面的不足。该框架采用多批评者架构，解耦奖励信号以有效解决任务冲突，并结合基于扭曲的任务制定以实现精确的轨迹跟踪。实验结果表明，该方法能够同时执行行走和末端执行器运动，并能涌现出有益的全身行为。

> **摘要翻译:** 学习用于单个策略中的运动和手臂运动的全身控制具有挑战性，因为这两个任务具有冲突的目标。例如，有效的运动通常有利于水平的基础方向，而末端执行器跟踪可能受益于基础倾斜以扩展可及性。此外，当前使用基于姿势的任务规范的强化学习（RL）方法缺乏直接控制末端执行器速度的能力，使得平稳执行轨迹非常具有挑战性。为了解决这些局限性，我们提出了一种基于 RL 的框架，该框架允许动态的、面向速度的全身末端执行器控制。我们的方法引入了一种多批评者演员架构，该架构将运动和操纵的奖励信号解耦，从而简化了奖励调整，并允许策略更有效地解决任务冲突。此外，我们设计了一种基于扭曲的末端执行器任务制定，该制定可以跟踪离散姿势和运动轨迹。我们通过使用配备有机械臂的四足机器人进行的一系列模拟和硬件实验来验证我们的方法。所得的控制器能够同时行走并移动其末端执行器，并表现出涌现的全身行为，其中底座辅助手臂扩展了工作空间，尽管没有明确的公式。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [532] [Learning human-to-robot handovers through 3D scene reconstruction](https://arxiv.org/abs/2507.08726)
> *通过3D场景重建学习人机交接*

*Yuekun Wu, Yik Lung Pang, Andrea Cavallaro, Changjae Oh* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 人机交接,高斯喷溅,机器人策略学习,模拟到真实,计算机视觉

**Comment:** 8 pages, 6 figures, 2 table

> **TL;DR:** 该研究提出了一种名为H2RH-SGS的新方法，利用高斯喷溅技术从稀疏视图的RGB图像中学习机器人交接策略，无需真实机器人训练数据，并成功在模拟和真实环境中进行了部署。

**AI_Comments:** 这项研究在机器人交接领域取得了重要进展，通过利用高斯喷溅技术解决了模拟到真实（sim-to-real）的视觉域差距问题。无需真实机器人训练数据即可进行学习，大大降低了数据收集的成本和难度。该方法的可行性在真实世界的实验中得到了验证，为未来机器人操作策略的学习提供了新的思路和方向。然而，对于不同光照条件、遮挡情况以及更复杂的人体动作的鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 从原始的、真实的图像数据中学习机器人操作策略需要大量的物理环境机器人操作试验。虽然使用模拟进行训练提供了一种经济高效的替代方案，但模拟与机器人工作空间之间的视觉域差距仍然是一个主要限制。

**Method:** 提出了一种名为“使用稀疏视图高斯喷溅的人机交接”（H2RH-SGS）的策略学习方法，该方法仅利用RGB图像进行监督学习，无需真实机器人训练或数据收集。该方法利用人机交接场景的稀疏视图高斯喷溅重建来生成机器人演示，其中包含在机器人夹持器上安装的摄像头捕获的图像-动作对。

**Result:** 所提出的H2RH-SGS方法在16种家用物品的演示数据上进行了训练，并在高斯喷溅重建场景和真实世界的人机交接实验中都取得了成功，证明了其作为人机交接任务的新颖且有效的表示。

**Conclusion:** H2RH-SGS是一种新颖且有效的人机交接任务表示方法，它利用稀疏视图高斯喷溅重建来生成机器人演示，从而可以在没有真实机器人训练数据的情况下进行监督学习。

> **ai_Abstract:** 本研究提出了一种新颖的人机交接方法H2RH-SGS，该方法利用稀疏视图高斯喷溅技术从RGB图像中学习机器人交接策略，克服了模拟与真实环境之间的视觉域差距。该方法无需真实机器人训练数据，通过生成包含图像-动作对的机器人演示来训练策略，并成功地将训练好的策略部署到真实环境中，在模拟和真实实验中均表现出有效性。

> **摘要翻译:** 从原始的、真实的图像数据中学习机器人操作策略需要大量的物理环境机器人操作试验。虽然使用模拟进行训练提供了一种经济高效的替代方案，但模拟与机器人工作空间之间的视觉域差距仍然是一个主要限制。高斯喷溅视觉重建方法最近通过生成逼真的环境为机器人操作提供了新的方向。在本论文中，我们提出了一种首个仅从RGB图像进行监督学习的人机交接方法，无需真实机器人训练或真实机器人数据收集。所提出的策略学习器，使用稀疏视图高斯喷溅的人机交接（H2RH-SGS），利用人机交接场景的稀疏视图高斯喷溅重建来生成机器人演示，其中包含在机器人夹持器上安装的摄像头捕获的图像-动作对。结果，重建场景中的模拟相机位姿变化可以直接转化为夹持器位姿变化。我们在16种家用物品的演示数据上训练了机器人策略，并将其直接部署到真实环境中。在高斯喷溅重建场景和真实世界的人机交接实验中进行的实验证明，H2RH-SGS作为人机交接任务的一种新的有效表示。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [600] [Towards Autonomous Indoor Parking: A Globally Consistent Semantic SLAM System and A Semantic Localization Subsystem](https://arxiv.org/abs/2410.12169)
> *面向自主室内停车：一个全局一致的语义SLAM系统和一个语义定位子系统*

*Yichen Sha, Siting Zhu, Hekui Guo, Zhong Wang, Hesheng Wang* | **Category: cs.RO** | **Updated: 2025-07-11**

**Keywords:** 语义SLAM, 定位, 停车场, 因子图优化, 多传感器融合

**Comment:** IROS 2025

> **TL;DR:** 该研究提出了一个名为GCSLAM的全局一致语义SLAM系统和一个名为SF-Loc的语义融合定位子系统，用于在复杂的停车场中进行精确的语义建图和鲁棒的定位。系统融合了视觉相机、IMU和轮式编码器数据，并引入了基于多传感器数据和BEV语义信息的语义约束因子图优化，以及一个全局停车位管理模块。SF-Loc利用GCSLAM构建的语义地图进行定位，并通过新颖的因子图整合了注册结果和里程计姿态。实验结果表明，该系统在全局定位和语义建图方面优于现有SLAM系统。

**AI_Comments:** 该研究在自主室内停车领域取得了显著进展，通过结合语义信息和多传感器融合，实现了高精度的地图构建和定位。全局停车位管理模块的引入是该方法的创新点之一，有助于提高停车效率。然而，对于不同类型和复杂度的停车场环境的泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现自主室内停车，需要精确的语义建图和鲁棒的定位能力，尤其是在复杂的停车场环境中。

**Method:** 提出一个全局一致的语义SLAM系统（GCSLAM），该系统使用语义约束因子图优化位姿和语义地图，并结合多传感器数据和BEV语义信息。此外，还集成了一个全局停车位管理模块。然后，提出一个语义融合定位子系统（SF-Loc），利用GCSLAM构建的语义地图进行基于地图的定位，并通过新颖的因子图整合注册结果和里程计姿态。

**Result:** 该系统在两个真实世界的数据集上表现优于现有SLAM系统，在鲁棒的全局定位和精确的语义建图方面展现出卓越的能力。

**Conclusion:** 所提出的GCSLAM系统和SF-Loc子系统能够实现精确的语义建图和鲁棒的定位，为自主室内停车提供了有效的解决方案。

> **ai_Abstract:** 该研究提出了一种用于自主室内停车的全局一致语义SLAM系统（GCSLAM）和语义融合定位子系统（SF-Loc）。该系统利用视觉相机、IMU和轮式编码器数据，结合语义约束因子图优化和全局停车位管理，实现了精确的语义地图构建和鲁棒的定位。SF-Loc利用该语义地图进行定位，并通过融合注册结果和里程计姿态进一步提高了定位精度。实验证明，该系统在复杂停车场环境中优于现有方法。

> **摘要翻译:** 我们提出了一个全局一致的语义SLAM系统（GCSLAM）和一个语义融合定位子系统（SF-Loc），该系统在复杂的停车场中实现了精确的语义建图和鲁棒的定位。视觉相机（前视和环视）、IMU和轮式编码器构成了我们系统的输入传感器配置。我们工作的第一个部分是GCSLAM。GCSLAM引入了一个语义约束因子图，用于优化位姿和语义地图，它整合了基于多传感器数据和BEV（鸟瞰图）语义信息的新颖误差项。此外，GCSLAM集成了一个全局停车位管理模块，该模块存储和管理停车位观测。SF-Loc是我们工作的第二部分，它利用GCSLAM构建的语义地图进行基于地图的定位。SF-Loc将注册结果和里程计位姿与一个新颖的因子图相结合。我们的系统在两个真实世界的数据集上展示了优于现有SLAM的性能，在鲁棒的全局定位和精确的语义建图方面表现出卓越的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [1] [Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging](https://arxiv.org/abs/2507.08052)
> *用于高光谱成像机载推理的轻量级云遮罩模型*

*Mazen Ali, António Pereira, Fabio Gentile, Aser Cortines, Sam Mugel, Román Orús, Stelios P. Neophytides, Michalis Mavrovouniotis* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 云遮罩, 高光谱成像, 轻量级AI, 卷积神经网络, 机载推理

**Comment:** 

> **TL;DR:** 本研究评估了多种机器学习方法（包括梯度提升和CNN）用于高光谱图像的云遮罩，发现轻量级CNN模型在精度、存储和推理速度方面表现最佳，适用于机载实时处理。

**AI_Comments:** 这项研究的创新之处在于其对轻量级AI模型在高光谱图像云遮罩中的应用探索，特别强调了模型在机载系统上的部署可行性。通过优化CNN模型以减少参数量，同时保持高精度，该研究为卫星实时数据处理提供了实际可行的解决方案，对于空间应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 云和云影遮罩是高光谱卫星成像中关键的预处理步骤，旨在提取高质量、可供分析的数据。

**Method:** 本研究评估了包括XGBoost和LightGBM等梯度提升方法以及卷积神经网络（CNN）在内的多种机器学习方法。

**Result:** 所有梯度提升和CNN模型的准确率均超过93%。其中，结合特征降维的CNN模型表现出最高的效率，它在精度、低存储需求和CPU/GPU上的快速推理时间之间取得了平衡。该模型的变体（仅有597个可训练参数）在部署可行性、准确性和计算效率方面展示了最佳的权衡。

**Conclusion:** 研究结果表明，轻量级人工智能模型在高光谱图像实时处理方面具有巨大潜力，支持开发用于空间应用的机载卫星AI系统。

> **ai_Abstract:** 本研究旨在开发用于高光谱卫星成像的轻量级云遮罩模型，以实现机载实时处理。研究评估了梯度提升方法（如XGBoost和LightGBM）和卷积神经网络（CNN）。结果显示所有模型准确率均超过93%，其中结合特征降维的CNN模型在准确性、存储需求和推理速度方面表现最佳，其低参数量（最多597个）使其非常适合卫星机载部署，证明了轻量级AI模型在实时高光谱图像处理中的潜力。

> **摘要翻译:** 云和云影遮罩是高光谱卫星成像中至关重要的预处理步骤，它能够提取高质量、可供分析的数据。本研究评估了各种机器学习方法，包括XGBoost和LightGBM等梯度提升方法以及卷积神经网络（CNN）。所有提升和CNN模型的准确率均超过93%。在所研究的模型中，结合特征降维的CNN模型表现出最高的效率，在保持高准确性的同时，具有低存储需求和在CPU和GPU上快速推理时间的优点。该模型的变体，仅有597个可训练参数，在部署可行性、准确性和计算效率方面表现出最佳的权衡。这些结果证明了轻量级人工智能（AI）模型在实时高光谱图像处理方面的潜力，支持开发用于空间应用的机载卫星AI系统。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [2] [Deep Hashing with Semantic Hash Centers for Image Retrieval](https://arxiv.org/abs/2507.08404)
> *带语义哈希中心的深度哈希用于图像检索*

*Li Chen, Rui Liu, Yuxiang Zhou, Xudong Ma, Yong Chen, Dell Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 深度哈希, 语义哈希中心, 图像检索, 汉明距离, 深度学习

**Comment:** 

> **TL;DR:** 提出了一种名为SHC的三阶段深度哈希框架，通过生成语义哈希中心来解决现有方法忽略类间语义关系的问题，显著提升了图像检索性能。

**AI_Comments:** 该论文的创新点在于提出了“语义哈希中心”的概念，并设计了一个三阶段框架SHC来有效实现这一概念。它解决了传统深度哈希方法中哈希中心生成忽视类间语义关系的局限性，使得生成的哈希码更具判别力。通过引入数据依赖的相似度计算和优化算法来确保哈希中心的语义一致性和区分度，该方法为大规模图像检索提供了显著的性能提升，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的点式深度哈希方法虽然通过预分配哈希中心提高了检索性能，但其哈希中心生成算法是数据无关的，忽略了类之间的语义关系，可能导致检索性能下降。

**Method:** 提出了一种名为SHC的三阶段框架：首先，开发一个分类网络，使用数据依赖的相似度计算来识别类之间的语义相似性；其次，引入一个优化算法来生成语义哈希中心，既保留语义相关性又强制中心之间保持最小距离；最后，使用这些语义中心训练一个深度哈希网络，将图像转换为二值哈希码。

**Result:** SHC在多个公共数据集上的大规模检索任务中显著提高了检索性能，与最先进的方法相比，在MAP@100、MAP@1000和MAP@ALL指标上分别平均提升了+7.26%、+7.62%和+11.71%。

**Conclusion:** 通过引入语义哈希中心的概念和提出的SHC框架，可以有效解决现有深度哈希方法中哈希中心缺乏语义信息的问题，从而显著提升大规模图像检索的性能。

> **ai_Abstract:** 该论文提出了一个名为SHC的三阶段深度哈希框架，旨在解决现有方法在图像检索中忽略类间语义关系的问题。SHC通过引入语义哈希中心的概念，确保语义相关类别拥有更近的哈希距离。框架首先利用分类网络计算数据依赖的语义相似性，然后通过优化算法生成保持语义结构并避免过度相似的哈希中心，最后训练深度哈希网络生成二值哈希码。实验证明，SHC在多个数据集上的大规模图像检索任务中显著优于现有技术，MAP指标平均提升高达11.71%。

> **摘要翻译:** 深度哈希是一种用于大规模图像检索的有效方法。当前的方法通常根据其监督类型进行分类：点式、对式和列表式。最近的点式技术（例如CSQ、MDS）通过为每个类别预分配哈希中心，增强了不同数据集上哈希码的可区分性，从而提高了检索性能。然而，这些方法依赖于与数据无关的算法来生成哈希中心，这忽略了类别之间的语义关系，并可能降低检索性能。
本文在传统哈希中心思想的基础上，引入了语义哈希中心的概念。我们假设语义相关类别的哈希中心应具有更接近的汉明距离，而无关类别的哈希中心则应更远。为此，我们提出了一个三阶段框架SHC，以生成保留语义结构的哈希码。
首先，我们开发了一个分类网络，使用适应不同数据分布的数据依赖相似度计算来识别类别之间的语义相似性。其次，我们引入了一种优化算法来生成语义哈希中心，该算法在保留语义相关性的同时，强制中心之间保持最小距离，以避免哈希码过度相似。最后，使用这些语义中心训练一个深度哈希网络，将图像转换为二值哈希码。
在多个公共数据集上的大规模检索任务中，实验结果表明SHC显著提高了检索性能。具体而言，SHC在MAP@100、MAP@1000和MAP@ALL指标上，比最先进的方法分别平均提升了+7.26%、+7.62%和+11.71%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [4] [Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition](https://arxiv.org/abs/2504.17224)
> *视觉和文本提示在VLLM中增强情感识别*

*Zhifeng Wang, Qixuan Zhang, Peter Zhang, Wenjia Niu, Kaihao Zhang, Ramesh Sankaranarayana, Sabrina Caldwell, Tom Gedeon* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 情感识别, VLLMs, 视觉提示, 文本提示, 多模态, 零样本学习

**Comment:** Accepted by IEEE TCSVT

> **TL;DR:** 提出SoVTP框架，通过整合多模态提示来提高VLLM在视频情感识别中的零样本性能，解决了VLLM空间和上下文感知不足的问题。

**AI_Comments:** 该论文的创新点在于提出了SoVTP框架，通过整合多模态的视觉和文本提示，弥补了VLLMs在视频情感识别中对空间和上下文理解的不足。它超越了传统只关注面部特征的方法，考虑了更丰富的非语言信息，如身体语言和环境上下文，这对于真实世界场景中的情感识别至关重要。其重要性在于提升了VLLMs在复杂多模态任务上的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 视觉大语言模型（VLLMs）在视频情感识别中存在空间和上下文感知不足的限制；传统方法偏重孤立面部特征，忽略了身体语言、环境和社交互动等关键非语言线索，导致在真实场景中鲁棒性降低。

**Method:** 提出Set-of-Vision-Text Prompting (SoVTP) 框架，通过统一的提示策略整合空间标注（如边界框、面部标志）、生理信号（面部动作单元）和上下文线索（身体姿态、场景动态、他人情感），以增强零样本情感识别能力。SoVTP旨在保留整体场景信息，同时实现面部肌肉运动和人际动态的细粒度分析。

**Result:** 广泛的实验表明，SoVTP比现有视觉提示方法取得了显著改进。

**Conclusion:** SoVTP有效增强了VLLMs的视频情感识别能力。

> **ai_Abstract:** 本文提出了一种名为Set-of-Vision-Text Prompting (SoVTP) 的新颖框架，旨在解决视觉大语言模型（VLLMs）在视频情感识别中空间和上下文感知不足的问题。SoVTP通过统一的提示策略整合了空间标注、生理信号和上下文线索等多种非语言信息，以增强零样本情感识别的鲁棒性和准确性。实验结果表明，SoVTP显著优于现有方法，有效提升了VLLMs的视频情感识别性能。

> **摘要翻译:** 视觉大语言模型（VLLMs）在多模态理解方面展现出广阔前景，然而其在基于视频的情感识别应用中仍受限于空间和上下文感知不足。传统的侧重于孤立面部特征的方法，常忽略身体语言、环境上下文和社交互动等关键非语言线索，导致在现实场景中鲁棒性降低。为弥补这一不足，我们提出了一种新颖的框架——视觉-文本提示集（Set-of-Vision-Text Prompting, SoVTP），通过将空间标注（例如，边界框、面部标志）、生理信号（面部动作单元）和上下文线索（身体姿态、场景动态、他人情感）整合到统一的提示策略中，从而增强零样本情感识别能力。SoVTP在保留整体场景信息的同时，能够实现对面部肌肉运动和人际动态的细粒度分析。广泛的实验表明，SoVTP比现有视觉提示方法取得了显著改进，证明了其在增强VLLMs视频情感识别能力方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [25] [InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes](https://arxiv.org/abs/2507.08416)
> *InstaScene：迈向杂乱场景中完整3D实例分解与重建*

*Zesong Yang, Bangbang Yang, Wenqi Dong, Chenxuan Cao, Liyuan Cui, Yuewen Ma, Zhaopeng Cui, Hujun Bao* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D实例分解, 完整重建, 空间对比学习, 原位生成, 杂乱场景

**Comment:** Accepted by ICCV 2025. Project page:
  https://zju3dv.github.io/instascene/

> **TL;DR:** InstaScene提出了一种新的方法，用于从杂乱场景中实现完整的3D实例分解和重建，通过空间对比学习和原位生成来提高分解精度和克服观察不完整性。

**AI_Comments:** 本文提出InstaScene，通过结合空间对比学习和原位生成，创新性地解决了杂乱场景中3D实例分解与完整重建的难题。其方法不仅提升了分解精度，还通过生成完整实例弥补了传统方法的不足，对于机器人3D感知和场景理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有先进的3D重建技术将场景建模为无差别的整体，无法从部分观察中识别完整的物体，导致机器人难以像人类一样识别和补全杂乱环境中的被遮挡物体。

**Method:** 提出InstaScene框架，目标是分解任意实例并确保完整重建。为实现精确分解，开发了一种新的空间对比学习方法，通过跨视图跟踪每个实例的栅格化来增强语义监督。为克服有限观察导致的不完整性，引入了原位生成技术，利用有价值的观察和几何线索指导3D生成模型重建与真实世界无缝对齐的完整实例。

**Result:** 在复杂真实世界和合成场景的场景分解和物体补全实验中，该方法实现了卓越的分解精度，同时生成了几何保真和视觉完整的物体。

**Conclusion:** InstaScene通过其创新的空间对比学习和原位生成方法，成功解决了杂乱场景中完整3D实例分解和重建的挑战，显著提升了3D感知能力。

> **ai_Abstract:** InstaScene是一个新的3D感知框架，旨在解决杂乱场景中完整3D实例的分解和重建问题。它通过开发空间对比学习来提高实例分解的精度，并通过引入原位生成技术来克服有限观察下的不完整性，从而实现几何保真和视觉完整的物体重建。实验结果表明，该方法在分解精度和物体补全方面均表现出色。

> **摘要翻译:** 人类可以自然地识别并心理补全杂乱环境中被遮挡的物体。然而，即使采用先进的重建技术，将类似认知能力赋予机器人仍然充满挑战，因为这些技术将场景建模为无差别的整体，并且无法从部分观察中识别完整的物体。在本文中，我们提出了InstaScene，一种迈向复杂场景整体3D感知的新范式，其主要目标是：分解任意实例，同时确保完整重建。为了实现精确分解，我们开发了一种新颖的空间对比学习方法，通过跨视图跟踪每个实例的栅格化，显著增强了杂乱场景中的语义监督。为了克服有限观察导致的不完整性，我们引入了原位生成技术，利用有价值的观察和几何线索，有效地指导3D生成模型重建与真实世界无缝对齐的完整实例。在复杂真实世界和合成场景的场景分解和物体补全实验中，我们的方法展示了卓越的分解精度，同时生成了几何保真和视觉完整的物体。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [27] [Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.08410)
> *多模态互引导条件提示学习用于视觉-语言模型*

*Shijun Yang, Xiang Zhang, Wanqing Zhao, Hangzai Luo, Sheng Zhong, Jinye Peng, Jianping Fan* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 提示学习, 视觉-语言模型, 多模态, 条件提示, 互引导

**Comment:** 21 pages, 8 figures

> **TL;DR:** 提出MuGCP，一种新的条件提示学习范式，利用MLLM生成语义条件提示，并通过AMG模块生成视觉条件提示，结合MPF机制，提升VLMs在多模态任务上的泛化和性能。

**AI_Comments:** MuGCP的创新点在于引入了多模态大语言模型来生成语义条件提示，并通过互引导机制促进视觉和语义信息的深度交互，从而在更深层次上实现跨模态对齐，而非仅仅局限于输出层。这种方法有望显著提升VLMs在新类别和复杂多模态任务上的泛化能力和性能。

<details>
  <summary>Details</summary>

**Motivation:** 1. 对未见实例的类别嵌入分布建模不足，导致在新类别上的泛化性能不佳。2. 现有方法主要将跨模态对齐限制在视觉和文本编码器的最终输出层，限制了与预训练多模态嵌入空间拓扑一致性的保持能力。

**Method:** 引入MuGCP（Multi-modal Mutual-Guidance Conditional Prompt Learning），一种用于条件提示生成的新范式。利用多模态大语言模型（MLLMs）作为条件提示学习器，自适应生成语义条件提示（SCP）。引入注意力互引导（AMG）模块，促进视觉和语义信息之间的交互，通过互引导生成视觉条件提示（VCP）。提出多提示融合（MPF）机制，整合SCP和VCP与上下文提示。

**Result:** MuGCP在14个不同的数据集上优于现有最先进的方法。

**Conclusion:** MuGCP通过解决现有提示学习的挑战，显著提升了视觉-语言模型在多模态任务上的泛化能力和性能。

> **ai_Abstract:** 本文提出MuGCP（多模态互引导条件提示学习），旨在解决视觉-语言模型提示学习中类别泛化不足和跨模态对齐受限的问题。MuGCP利用多模态大语言模型生成包含细粒度语义知识的语义条件提示（SCP），并通过注意力互引导（AMG）模块生成视觉条件提示（VCP）。此外，通过多提示融合（MPF）机制整合不同提示，以增强类别嵌入和实例知识建模。实验结果表明，MuGCP在14个数据集上超越了现有最先进的方法。

> **摘要翻译:** 提示学习有助于视觉-语言模型（VLMs）高效适应各种下游任务。然而，它面临两个重大挑战：（1）对未见实例的类别嵌入分布建模不足，导致在新类别上的泛化性能不佳；（2）现有方法主要将跨模态对齐限制在视觉和文本编码器的最终输出层，这从根本上限制了它们保持与预训练多模态嵌入空间拓扑一致性的能力。为此，我们引入了MuGCP（多模态互引导条件提示学习），这是一种为条件提示生成设计的新范式。MuGCP利用多模态大语言模型（MLLMs）作为条件提示学习器，自适应地生成语义条件提示（SCP），其中包含丰富的、细粒度的高级语义知识，用于图像实例。为了确保视觉-语言模型（VLMs）多模态空间中有效的对齐和交互，我们引入了注意力互引导（AMG）模块，该模块促进视觉和语义信息之间的交互。通过互引导，AMG模块生成视觉条件提示（VCP），从而提高模型在多模态任务中的性能。此外，我们提出了一种多提示融合（MPF）机制，将SCP和VCP与上下文提示集成，确保不同提示之间的无缝协调，并增强类别嵌入和实例特定知识的建模。我们的MuGCP在14个不同的数据集上优于现有最先进的方法。代码将在发布后提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [29] [The relative importance of being Gaussian](https://arxiv.org/abs/2507.08059)
> *高斯分布的相对重要性*

*F. Alberto Grünbaum, Tondgi Xu* | **Category: cs.CV, math.PR, 68T05, 68T45, 60J60, 82C22, 82C31** | **Updated: 2025-07-10**

**Keywords:** 扩散模型, 高斯噪声, 去噪, 噪声鲁棒性, 计算机视觉

**Comment:** 

> **TL;DR:** 本文探讨了在计算机视觉去噪扩散模型中，当噪声类型偏离高斯分布时，算法性能如何变化，并在一台小型笔记本电脑上进行了实验。

**AI_Comments:** 本文探讨了当前扩散模型的一个核心假设——高斯噪声。其创新之处在于，在不修改现有算法的前提下，系统性地研究了非高斯噪声对算法性能的影响，这对于理解扩散模型的鲁棒性和局限性具有重要意义。虽然实验规模较小，但提出的问题具有基础性和普适性，为未来研究提供了方向。抽象中未给出具体实验结果是其局限性。

<details>
  <summary>Details</summary>

**Motivation:** 计算机视觉中的去噪扩散模型在处理高斯噪声时表现出色，其算法设计基于高斯分布的关键特性。本文旨在探讨当噪声不再是高斯分布（例如均匀分布、Beta分布或高斯分布的随机叠加）时，不改变算法本身的情况下，算法的性能表现如何。

**Method:** 研究方法是在不修改现有去噪算法的前提下，将输入噪声从高斯噪声替换为其他类型的噪声，如均匀分布噪声、Beta分布噪声或两种高斯分布的随机叠加噪声。所有实验都在一台小型笔记本电脑上进行，并使用最小的图像尺寸。

**Result:** 抽象中未明确提及具体结果，但指出研究了当噪声性质与高斯情况相去甚远时算法的性能，并提到探索观察结果在不同情况下的确认或变化是一个有趣的挑战。

**Conclusion:** 抽象中未明确给出结论，但提出了一个研究问题，并描述了实验设置。

> **ai_Abstract:** 本文探讨了去噪扩散模型中噪声类型对算法性能的影响。鉴于现有扩散模型在处理高斯噪声时的优异表现，作者提出疑问：当输入噪声是非高斯（如均匀、Beta或混合高斯）时，若不修改算法，其性能将如何。研究方法是在不改变算法本身的情况下，替换噪声类型，并在小型计算机和最小图像尺寸下进行实验，旨在观察算法在偏离其设计前提下的表现。

> **摘要翻译:** 计算机视觉中，使用扩散模型进行去噪的显著成果（如文献[SDWMG, HJA, HHG]所示）为基于一系列独立N(0,1)高斯随机变量关键属性的算法提供了强有力的数学依据。特别是，这些推导利用了高斯分布由其均值和方差确定以及两个高斯分布之和仍为高斯分布的事实。

本短篇笔记提出的问题如下：假设我们不改变算法，但替换噪声的性质，例如使用均匀分布噪声、Beta分布噪声，或者两种方差差异很大的高斯分布的随机叠加噪声。当然，可以尝试根据噪声的性质修改算法，但这并非我们所做的。相反，我们研究了当噪声的性质与高斯情况（算法设计旨在良好工作的情况）相去甚远时，算法的性能。

通常，这些算法在非常强大的计算机上实现。我们的所有实验都在一台小型笔记本电脑上进行，并且使用最小的图像尺寸。探索我们的观察结果在不同情况下如何得到证实或改变仍然是一个有趣的挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [31] [Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness](https://arxiv.org/abs/2504.18906)
> *Sim-to-Real：一种用于屏幕-相机水印鲁棒性的无监督噪声层*

*Yufeng Wu, Xin Liao, Baowei Wang, Han Fang, Xiaoshuai Wu, Guiling Wang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 屏幕-相机水印, 无监督学习, 噪声层, 鲁棒性, Sim-to-Real

**Comment:** 

> **TL;DR:** 本文提出S2R无监督噪声层，通过学习模拟噪声与真实屏幕-相机（SC）噪声分布的差异，显著提高水印的鲁棒性和泛化能力，解决了现有SC水印方法在噪声近似方面的局限性。

**AI_Comments:** 这篇论文的创新点在于提出了一个无监督的噪声层来解决屏幕-相机水印中的Sim-to-Real问题。通过学习噪声分布的差异而非直接的图像映射，它简化了学习任务并克服了传统方法对配对数据的依赖和噪声模拟不准确的问题。这对于提升数字版权保护和信息安全的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 未经授权的屏幕捕获和传播带来了严重的安全威胁。现有屏幕-相机（SC）水印方法在增强鲁棒性时，通常采用启发式数学建模或监督神经网络拟合作为噪声层，但这两种策略都不能有效近似SC噪声。数学模拟存在偏差，而监督网络需要难以获取的配对数据且难以学习噪声的所有特征。

**Method:** 本文提出Sim-to-Real (S2R) 方法，其核心是一个无监督噪声层。该层利用未配对数据学习建模的模拟噪声分布与真实世界SC噪声分布之间的差异，而非直接学习从清晰图像到真实图像的映射。这种从模拟到现实的转换更简单，因为它主要涉及弥合噪声分布的差距，而非重建复杂的图像细节。

**Result:** 广泛的实验结果验证了所提方法的有效性，与现有最先进方法相比，显示出卓越的水印鲁棒性和泛化能力。

**Conclusion:** S2R通过其无监督噪声层，有效解决了现有屏幕-相机水印方法在噪声近似方面的局限性，显著提高了水印的鲁棒性和泛化能力，为数字版权保护提供了更实用的解决方案。

> **ai_Abstract:** 本文提出了一种名为Sim-to-Real (S2R) 的新方法，旨在提高屏幕-相机水印的鲁棒性。针对现有方法在模拟SC噪声时存在的偏差和对配对数据的依赖问题，S2R引入了一个无监督噪声层。该层通过学习模拟噪声分布与真实SC噪声分布之间的差异，有效避免了对配对数据的需求和复杂图像细节的重建。实验证明，S2R在水印鲁棒性和泛化能力上均优于现有先进方法。

> **摘要翻译:** 未经授权的屏幕捕获和传播带来了严重的安全威胁，如数据泄露和信息窃取。多项研究提出了鲁棒的水印方法来追踪屏幕-相机（SC）图像的版权，以便在侵权后进行认证。这些技术通常采用启发式数学建模或监督神经网络拟合作为噪声层，以增强水印对SC的鲁棒性。然而，这两种策略都不能从根本上实现对SC噪声的有效近似。数学模拟由于噪声分解不完全以及噪声分量之间缺乏相互依赖性而导致近似偏差。监督网络需要配对数据来训练噪声拟合模型，并且模型很难学习到噪声的所有特征。为了解决上述问题，我们提出了从模拟到现实（S2R）的方法。具体来说，一个无监督噪声层利用未配对数据来学习建模的模拟噪声分布与真实世界SC噪声分布之间的差异，而不是直接学习从清晰图像到真实世界图像的映射。学习这种从模拟到现实的转换本质上更简单，因为它主要涉及弥合噪声分布的差距，而不是重建细粒度图像细节的复杂任务。大量的实验结果验证了所提方法的有效性，证明了与最先进方法相比，其水印鲁棒性和泛化能力更优越。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [42] [Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers](https://arxiv.org/abs/2507.08422)
> *只上采样关键区域：用于加速扩散Transformer的区域自适应潜在采样*

*Wongi Jeong, Kyungryeol Lee, Hoigi Seo, Se Young Chun* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-11**

**Keywords:** 扩散Transformer, 潜在采样, 加速, 区域自适应, 图像生成

**Comment:** 

> **TL;DR:** 扩散Transformer在图像生成中计算量大，本文提出区域自适应潜在上采样（RALU），通过在空间维度进行混合分辨率采样来加速推理，显著提高速度同时保持图像质量。

**AI_Comments:** 该论文的创新点在于提出了一个无需训练的、专注于空间维度加速扩散Transformer的方法，这与现有主要关注时间维度的方法形成了良好的互补。区域自适应上采样的策略非常巧妙，能够有选择性地处理图像中关键区域的细节，从而在保证质量的同时大幅提升效率。其训练无关性也使其易于集成和应用，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散Transformer虽然在图像和视频生成方面具有优越的可扩展性，但其巨大的计算量阻碍了实际部署。现有加速方法主要利用时间维度，而空间维度的加速仍是主要障碍。

**Method:** 本文提出了区域自适应潜在上采样（RALU），一个无需训练的框架，旨在沿空间维度加速推理。RALU分三个阶段执行混合分辨率采样：1）低分辨率去噪潜在扩散以有效捕获全局语义结构；2）在易产生伪影的特定区域进行全分辨率区域自适应上采样；3）所有潜在上采样均在全分辨率下进行细节细化。为了稳定跨分辨率转换的生成，该方法利用噪声时间步重新调度来适应不同分辨率下的噪声水平。

**Result:** 该方法在FLUX上实现了高达7.0倍的加速，在Stable Diffusion 3上实现了3.0倍的加速，同时图像质量下降极小。此外，RALU与现有的时间加速方法（如缓存方法）互补，可以无缝集成以进一步减少推理延迟，而不损害生成质量。

**Conclusion:** RALU通过在空间维度上加速扩散Transformer，显著减少了计算量同时保持了图像质量。它可以与现有方法结合，进一步降低推理延迟。

> **ai_Abstract:** 本文针对扩散Transformer计算量大的问题，提出了区域自适应潜在上采样（RALU）框架。该框架无需训练，通过在空间维度上进行三阶段混合分辨率采样来加速推理：首先在低分辨率下处理全局结构，然后对易产生伪影的区域进行全分辨率上采样，最后进行细节细化。为确保平稳过渡，还引入了噪声时间步重新调度。RALU在FLUX上实现高达7.0倍加速，在Stable Diffusion 3上实现3.0倍加速，且图像质量损失极小。它还能与现有时间加速方法结合，进一步降低延迟。

> **摘要翻译:** 扩散Transformer已成为U-net扩散模型在高保真图像和视频生成方面的替代方案，提供了卓越的可扩展性。然而，其巨大的计算量仍然是实际部署的主要障碍。现有加速方法主要利用时间维度，例如在扩散时间步长之间重用缓存特征。在此，我们提出了区域自适应潜在上采样（RALU），一个无需训练的框架，用于沿空间维度加速推理。RALU分三个阶段执行混合分辨率采样：1）低分辨率去噪潜在扩散以有效捕获全局语义结构；2）在易产生伪影的特定区域进行全分辨率区域自适应上采样；3）所有潜在上采样均在全分辨率下进行细节细化。为了稳定跨分辨率转换的生成，我们利用噪声时间步重新调度来适应不同分辨率下的噪声水平。我们的方法通过在FLUX上实现高达7.0倍的加速和在Stable Diffusion 3上实现3.0倍的加速，同时图像质量下降极小，显著减少了计算量并保持了图像质量。此外，RALU与现有的时间加速方法（如缓存方法）互补，因此可以无缝集成以进一步减少推理延迟，而不损害生成质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [53] [An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images](https://arxiv.org/abs/2507.08096)
> *基于对象的深度学习方法，用于从单张SAR图像估算建筑物高度*

*Babak Memar, Luigi Russo, Silvia Liberata Ullo, Paolo Gamba* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 深度学习, SAR图像, 建筑物高度估算, 对象检测, 迁移学习

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习的面向对象方法，利用单张VHR SAR图像自动估算建筑物高度，并在多大陆数据集上表现出良好性能，尤其在欧洲城市优于现有方法，证明了深度学习在跨城市和跨大陆建筑物高度估计中的潜力。

**AI_Comments:** 该论文的创新之处在于提出了一种基于对象的深度学习方法，专门用于从单张SAR图像估算建筑物高度，并首次在一个独特的多大陆数据集上进行了广泛的域外泛化能力评估。其重要性体现在为城市应用提供了更准确、自动化的建筑物高度估算方案，并验证了深度学习在复杂跨区域场景下进行迁移学习的潜力。局限性可能在于其在亚洲等具有独特城市类型和高层建筑区域的泛化性能仍有提升空间。

<details>
  <summary>Details</summary>

**Motivation:** 使用甚高分辨率（VHR）合成孔径雷达（SAR）图像准确估算建筑物高度对于各种城市应用至关重要。

**Method:** 本文引入了一种基于深度学习（DL）的方法，用于从单张VHR COSMO-SkyMed图像自动估算建筑物高度。这是一种基于对象回归的方法，涉及边界框检测和随后的高度估算。该模型在一个独特的多大陆数据集上进行训练和评估，该数据集涵盖欧洲、北美、南美和亚洲的八个地理多样化城市，并采用交叉验证策略以明确评估域外（OOD）泛化能力。

**Result:** 模型表现出非常有前景的性能，尤其是在欧洲城市，平均绝对误差（MAE）约为一个建筑物楼层（慕尼黑为2.20米），在类似的OOD场景中显著优于最近的最新方法。尽管在泛化到其他大陆城市（特别是亚洲，因其独特的城市类型和高层建筑）时观察到更高的变异性。

**Conclusion:** 本研究强调了深度学习在从单张甚高分辨率SAR数据中进行建筑物高度估算的强大跨城市和跨大陆迁移学习的巨大潜力。

> **ai_Abstract:** 本文提出了一种基于对象的深度学习方法，利用单张甚高分辨率（VHR）SAR图像自动估算建筑物高度。该方法通过边界框检测进行对象识别，随后估算高度。模型在一个包含欧洲、北美、南美和亚洲八个城市的多大陆数据集上进行训练和评估，以测试其域外泛化能力。结果显示，该方法在欧洲城市表现出色，平均绝对误差约为一个楼层，优于现有技术。尽管在其他大陆（特别是亚洲）的泛化能力存在一定变异性，但研究强调了深度学习在建筑物高度估算中实现强大的跨城市和跨大陆迁移学习的巨大潜力。

> **摘要翻译:** 使用甚高分辨率（VHR）合成孔径雷达（SAR）图像准确估算建筑物高度对于各种城市应用至关重要。本文介绍了一种基于深度学习（DL）的方法，用于从单张VHR COSMO-SkyMed图像自动估算建筑物高度：一种基于对象回归的方法，包括边界框检测和随后的高度估算。该模型在包含欧洲、北美、南美和亚洲八个地理多样化城市的多大陆数据集上进行了训练和评估，采用交叉验证策略明确评估了域外（OOD）泛化能力。结果显示出非常有前景的性能，特别是在欧洲城市，模型实现了大约一个建筑物楼层（慕尼黑为2.20米）的平均绝对误差（MAE），在类似的OOD场景中显著优于最近的最新方法。尽管在泛化到其他大陆城市时（尤其是在亚洲，由于其独特的城市类型和高层建筑的普遍性）观察到更高的变异性，这项研究强调了深度学习在从单张VHR SAR数据中进行建筑物高度估算的强大跨城市和跨大陆迁移学习的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [58] [RePaintGS: Reference-Guided Gaussian Splatting for Realistic and View-Consistent 3D Scene Inpainting](https://arxiv.org/abs/2507.08434)
> *RePaintGS: 参考引导的高斯泼溅用于真实且视角一致的3D场景修复*

*Ji Hyun Seo, Byounhyun Yoo, Gerard Jounghyun Kim* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D场景修复, 高斯泼溅, 视角一致性, 几何保真度, 参考引导

**Comment:** 

> **TL;DR:** RePaintGS提出了一种利用参考视图的3D场景修复方法，以解决传统图像修复在3D场景中导致视角不一致的问题，从而实现几何保真度和外观一致性的提升。

**AI_Comments:** 这项工作在3D场景修复领域具有重要意义，尤其是在解决视角一致性这一关键挑战上。通过引入参考视图并利用其指导其他视图的修复过程，该方法有效地克服了传统2D图像修复方法在3D重建中固有的不一致性问题。其创新点在于将参考视图的几何和外观信息作为伪真值来优化其他视图，从而提高了修复结果的几何保真度和外观一致性。这对于需要高保真3D内容的应用（如VR/AR、电影制作）具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像修复方法在进行3D场景修复时，会导致不同视角间的内容不一致，并且容易丢失细节或在感知不一致时失败。

**Method:** 本文提出了一种名为RePaintGS的3D场景修复方法。该方法利用一个参考视图，估计其他视图的修复相似度，以调整它们在构建针对参考视图的精确几何结构中的贡献。然后，该几何结构用于将参考视图的修复结果扭曲到其他视图作为伪真值，从而指导优化以匹配参考外观。

**Result:** 对比评估研究表明，我们的方法提高了修复场景的几何保真度和外观一致性。

**Conclusion:** 本文提出的方法即使对于复杂场景也能可靠地生成真实且感知一致的3D场景修复结果。

> **ai_Abstract:** 本文提出了RePaintGS，一种新颖的3D场景修复方法，旨在解决现有图像修复技术在3D场景中导致的视角不一致和细节丢失问题。该方法通过引入一个参考视图，并估计其他视图与参考视图的修复相似度来构建精确的几何结构。随后，利用该几何结构将参考视图的修复结果扭曲到其他视图作为伪真值，从而指导优化过程以匹配参考外观。实验证明，RePaintGS显著提升了修复场景的几何保真度和外观一致性，即使在复杂场景下也能生成真实且感知一致的结果。

> **摘要翻译:** 辐射场方法，如神经辐射场或3D高斯泼溅，已成为合成逼真新颖视图的开创性3D表示。对于实际应用，关于灵活场景编辑技术的研究正在进行中，其中物体移除是一项代表性任务。然而，移除物体会暴露出被遮挡区域，常常导致不自然的外观。因此，研究人员采用了图像修复技术来用合理的内容替换这些区域——这项任务被称为3D场景修复。然而，图像修复方法为每个视图生成众多可能完成方案中的一种，导致视角之间存在不一致性。一种广泛采用的方法是利用感知线索来平滑地融合修复后的视图。然而，它容易导致细节丢失，并且当视图之间存在感知不一致时可能会失败。在本文中，我们提出了一种新颖的3D场景修复方法，通过利用一个参考视图，即使对于复杂场景也能可靠地生成真实且感知一致的结果。给定修复后的参考视图，我们估计其他视图的修复相似度，以调整它们在构建与参考视图相符的精确几何结构中的贡献。然后，该几何结构用于将参考视图的修复结果扭曲到其他视图作为伪真值，指导优化以匹配参考外观。对比评估研究表明，我们的方法提高了修复场景的几何保真度和外观一致性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [60] [DArFace: Deformation Aware Robustness for Low Quality Face Recognition](https://arxiv.org/abs/2505.08423)
> *DArFace：低质量人脸识别的形变感知鲁棒性*

*Sadaf Gulshad, Abdullah Aldahlawi Thakaa* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 人脸识别, 低质量图像, 形变感知, 鲁棒性, 对抗性训练

**Comment:** 

> **TL;DR:** DArFace通过对抗性地整合全局和局部形变，提升了低质量人脸识别的鲁棒性，无需成对数据，并超越了现有SOTA方法。

**AI_Comments:** 该论文的创新点在于其DArFace框架能够有效处理低质量人脸图像中的局部非刚性形变，这是现有方法常忽略的关键因素。通过对抗性模拟和对比学习，它在无需成对数据的情况下显著提升了鲁棒性，对于实际应用中的人脸识别系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸识别系统在低质量图像（如低分辨率、运动模糊、各种失真）下性能显著下降，这在监控等实际场景中很常见。现有方法常忽略局部、非刚性形变，导致与高质量训练数据存在领域差距。

**Method:** 本文引入了DArFace框架，通过在训练过程中对抗性地集成全局变换（如旋转、平移）和局部弹性形变来模拟真实的低质量条件，无需成对的高低质量训练样本。同时，引入对比目标以强制不同形变视图之间保持身份一致性。

**Result:** 在TinyFace、IJB-B和IJB-C等低质量基准测试中，DArFace超越了现有最先进的方法，其中局部形变建模的引入带来了显著的性能提升。

**Conclusion:** DArFace通过有效建模并集成局部非刚性形变，显著提升了人脸识别系统在低质量图像下的鲁棒性，表现优于现有SOTA方法。

> **ai_Abstract:** 本文提出了DArFace，一个形变感知鲁棒人脸识别框架，旨在解决低质量人脸图像（如低分辨率、模糊、失真）导致的人脸识别性能下降问题。DArFace通过在训练中对抗性地整合全局和局部弹性形变来模拟真实低质量条件，并引入对比损失以确保身份一致性，无需成对的高低质量数据。实验证明，DArFace在多个低质量基准上超越了现有SOTA方法，尤其受益于对局部形变的建模。

> **摘要翻译:** 人脸识别系统通过利用深度神经网络、先进的损失函数和大规模数据集取得了显著成功。然而，在涉及低质量人脸图像的实际场景中，其性能往往会下降。这种退化常见于监控录像或远距离成像，包括低分辨率、运动模糊和各种失真，导致与训练中通常使用的高质量数据存在显著的领域差距。虽然现有方法试图通过修改网络架构或建模全局空间变换来解决鲁棒性问题，但它们常常忽视现实世界中固有的局部、非刚性形变。在这项工作中，我们引入了DArFace，一个形变感知鲁棒人脸识别框架，它在不需要成对高低质量训练样本的情况下，增强了对这些退化的鲁棒性。我们的方法在训练期间对抗性地整合了全局变换（例如旋转、平移）和局部弹性形变，以模拟真实的低质量条件。此外，我们引入了一个对比目标，以强制不同形变视图之间保持身份一致性。对包括TinyFace、IJB-B和IJB-C在内的低质量基准进行的广泛评估表明，DArFace超越了最先进的方法，其中局部形变建模的引入带来了显著的增益。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [74] [Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2507.08441)
> *视觉基础模型作为自回归图像生成的有效视觉分词器*

*Anlin Zheng, Xin Wen, Xuanyang Zhang, Chuofan Ma, Tiancai Wang, Gang Yu, Xiangyu Zhang, Xiaojuan Qi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 视觉基础模型, 图像分词器, 自回归生成, VFMTok, ImageNet

**Comment:** 19 pages, 4 figures

> **TL;DR:** 本文提出VFMTok，一个基于冻结视觉基础模型的图像分词器，通过区域自适应量化和语义重建目标，显著提升了自回归图像生成质量和效率。

**AI_Comments:** 该论文的创新点在于将视觉基础模型直接用作图像分词器，并引入了区域自适应量化和语义重建这两个关键机制，有效解决了传统分词器在冗余和语义保真度方面的问题。其重要性体现在显著提升了自回归图像生成的性能和效率，特别是实现了高保真类条件合成而无需复杂的CFG，这简化了生成流程并降低了计算成本，对社区具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 探索将预训练视觉基础模型的强大表示能力直接用于构建图像分词器，这是一个尚未充分探索的领域。

**Method:** 本文将冻结的视觉基础模型用作分词器的编码器。为提高其有效性，引入了两个关键组件：1) 区域自适应量化框架，用于减少预训练特征在2D网格上的冗余；2) 语义重建目标，使分词器的输出与基础模型的表示对齐以保持语义保真度。

**Result:** 所提出的VFMTok在图像重建和生成质量方面取得了显著改进，同时提高了标记效率。它进一步提升了自回归（AR）生成性能，在ImageNet基准测试中实现了2.07的gFID，并将模型收敛速度加快了三倍，同时无需分类器自由指导（CFG）即可实现高保真度类条件合成。

**Conclusion:** VFMTok成功地将视觉基础模型用作有效的视觉分词器，显著提升了图像重建和自回归生成任务的性能和效率，并简化了条件生成过程。

> **ai_Abstract:** 本文提出了一种名为VFMTok的新型图像分词器，它创新性地利用冻结的视觉基础模型作为编码器。通过引入区域自适应量化框架来减少特征冗余，并采用语义重建目标来保持语义一致性，VFMTok显著提升了图像重建和自回归图像生成的质量与效率。实验结果显示，VFMTok在ImageNet上实现了2.07的gFID，将模型收敛速度提高了三倍，并支持无需CFG的高保真类条件合成。

> **摘要翻译:** 利用预训练视觉基础模型——传统上用于视觉理解——的强大表示，我们探索了一个新颖的方向：直接在这些模型之上构建一个图像分词器，这是一个很大程度上未被充分探索的领域。具体来说，我们采用一个冻结的视觉基础模型作为我们分词器的编码器。为了增强其有效性，我们引入了两个关键组件：（1）一个区域自适应量化框架，用于减少常规2D网格上预训练特征的冗余，以及（2）一个语义重建目标，使分词器的输出与基础模型的表示对齐以保持语义保真度。基于这些设计，我们提出的图像分词器VFMTok在图像重建和生成质量方面取得了显著改进，同时还提高了标记效率。它进一步提升了自回归（AR）生成——在ImageNet基准测试中实现了2.07的gFID，同时将模型收敛速度加快了三倍，并且无需分类器自由指导（CFG）即可实现高保真度类条件合成。代码将公开发布以造福社区。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [81] [RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration](https://arxiv.org/abs/2507.08136)
> *RegGS: 未校准稀疏视图高斯泼溅与3DGS配准*

*Chong Cheng, Yu Hu, Sicheng Yu, Beizhen Zhao, Zijian Wang, Hao Wang* | **Category: cs.CV** | **Updated: 2025-07-10**

**Keywords:** 3D Gaussian Splatting, 未校准视图, 稀疏视图, 高斯配准, 最优传输

**Comment:** Accepted to ICCV 2025

> **TL;DR:** RegGS是一个基于3D高斯配准的框架，用于从稀疏未校准视图重建场景。它通过对齐局部高斯来解决现有3DGS方法在稀疏视图下的局限性，并实现了精确的姿态估计和高质量的新视图合成。

**AI_Comments:** 本文创新性地提出了一个基于高斯配准的新范式来解决稀疏、未校准视图下的3DGS重建问题。特别是引入了最优传输Mixture 2-Wasserstein距离作为高斯混合模型之间的对齐度量，并将其与光度一致性和深度几何相结合，实现了鲁棒的相机姿态估计和场景对齐。这对于实际应用中数据采集受限的场景重建具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3DGS在从未校准图像重建场景方面有潜力，但基于优化的方法由于先验知识有限，在稀疏视图下表现不佳。同时，前馈高斯方法受输入格式限制，难以整合更多输入视图。

**Method:** 本文提出了RegGS，一个基于3D高斯配准的框架，用于重建未校准的稀疏视图。RegGS通过熵正则化的Sinkhorn算法高效求解最优传输Mixture 2-Wasserstein（MW2）距离，将前馈网络生成的局部3D高斯对齐到全局一致的3D高斯表示。此外，设计了一个联合3DGS配准模块，该模块整合了MW2距离、光度一致性和深度几何，实现从粗到精的配准，同时准确估计相机姿态并对齐场景。

**Result:** 在RE10K和ACID数据集上的实验表明，RegGS能够高效高保真地配准局部高斯，实现精确的姿态估计和高质量的新视图合成。

**Conclusion:** RegGS成功解决了从稀疏、未校准视图进行场景重建的挑战，通过其新颖的高斯配准机制实现了卓越的性能。

> **ai_Abstract:** 本文提出RegGS，一个用于从稀疏、未校准视图重建场景的3D高斯配准框架。针对现有3DGS方法在稀疏视图和输入格式限制下的不足，RegGS通过熵正则化Sinkhorn算法计算最优传输MW2距离，将局部3D高斯对齐为全局一致表示。其联合3DGS配准模块整合MW2距离、光度一致性和深度几何，实现从粗到精的配准及精确相机姿态估计。实验证明RegGS在配准、姿态估计和新视图合成方面表现优异。

> **摘要翻译:** 3D高斯泼溅（3DGS）在从未校准图像重建场景方面展示了其潜力。然而，基于优化的3DGS方法由于先验知识有限，在稀疏视图下表现不佳。同时，前馈高斯方法受输入格式限制，使得整合更多输入视图变得具有挑战性。为了解决这些挑战，我们提出了RegGS，一个基于3D高斯配准的框架，用于重建未校准的稀疏视图。RegGS将前馈网络生成的局部3D高斯对齐到全局一致的3D高斯表示。技术上，我们实现了熵正则化的Sinkhorn算法，以有效求解最优传输Mixture 2-Wasserstein（MW2）距离，该距离作为Sim(3)空间中高斯混合模型（GMMs）的对齐度量。此外，我们设计了一个联合3DGS配准模块，该模块整合了MW2距离、光度一致性和深度几何。这使得能够进行从粗到精的配准过程，同时准确估计相机姿态并对齐场景。在RE10K和ACID数据集上的实验表明，RegGS能够高效高保真地配准局部高斯，实现精确的姿态估计和高质量的新视图合成。项目页面：https://3dagentworld.github.io/reggs/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [83] [Improvement of Spiking Neural Network with Bit Planes and Color Models](https://arxiv.org/abs/2410.08229)
> *基于位平面和颜色模型的脉冲神经网络改进*

*Nhan T. Luu, Duong T. Luu, Nam N. Pham, Thang C. Truong* | **Category: cs.CV, cs.NE, eess.IV** | **Updated: 2025-07-11**

**Keywords:** 脉冲神经网络, 位平面, 颜色模型, 性能优化, 图像处理

**Comment:** 2024 IEEE 16th International Conference on Computational Intelligence
  and Communication Networks (CICN)

> **TL;DR:** 本研究提出一种新的编码方法，利用位平面表示来提高脉冲神经网络（SNN）处理图像的性能，同时探讨了颜色模型的影响。

**AI_Comments:** 这项研究的创新之处在于首次将位平面和颜色模型引入脉冲神经网络的背景下，提出了一种新的编码方法来提高SNN处理图像的性能。其重要性在于，该方法能够在不增加模型大小的前提下提升SNN的准确性，这对于SNN在低功耗和嵌入式设备上的应用具有重要意义。通过利用位平面的特性，该研究为SNN的性能优化开辟了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲神经网络（SNN）虽然具有低能耗和内存占用小的优点，但其实际应用受限于性能优化方面的挑战。

**Method:** 本研究提出一种新的编码方法，利用位平面表示来提高SNN处理图像的性能，旨在不增加模型大小的情况下提高准确性。同时，研究还探讨了颜色模型对所提出编码过程的影响。

**Result:** 通过广泛的实验验证，该编码策略在多个数据集上实现了性能提升。

**Conclusion:** 通过利用位平面的独特特性，这项研究有望释放SNN性能的新潜力，为未来更高效、更有效的SNN模型铺平道路。

> **ai_Abstract:** 本研究提出一种新颖的编码方法，通过利用位平面表示来提高脉冲神经网络（SNN）在图像处理中的性能，同时不增加模型大小。研究还探讨了颜色模型对编码过程的影响。实验结果表明，该编码策略在多个数据集上有效提升了SNN的性能。这是首次将位平面和颜色模型引入SNN领域的研究，有望为SNN的未来发展开辟新途径。

> **摘要翻译:** 脉冲神经网络（SNN）作为计算神经科学和人工智能领域一个有前景的范式，具有低能耗和小内存占用的优点。然而，它们的实际应用受到多项挑战的限制，其中最突出的是性能优化。在本研究中，我们提出了一种新颖的方法，通过利用位平面表示的新编码方法来增强SNN处理图像的性能。我们提出的技术旨在不增加模型大小的情况下提高SNN的准确性。此外，我们还研究了颜色模型对所提出编码过程的影响。通过广泛的实验验证，我们证明了我们编码策略在多个数据集上实现性能增益的有效性。据我们所知，这是首次在SNN背景下考虑位平面和颜色模型的研究。通过利用位平面的独特特性，我们希望解锁SNN性能的新潜力，可能为未来研究和应用中更高效、更有效的SNN模型铺平道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [88] [MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos](https://arxiv.org/abs/2505.11868)
> *MonoMobility：从单目视频进行零样本3D运动分析*

*Hongyi Zhou, Yulan Guo, Xiaogang Wang, Kai Xu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D运动分析, 单目视频, 零样本, 关节物体, 具身智能

**Comment:** 

> **TL;DR:** 提出了一个名为MonoMobility的零样本框架，仅通过单目视频即可分析关节物体的3D运动及其属性，无需标注数据。

**AI_Comments:** 该论文的创新点在于其零样本能力和仅使用单目视频进行3D运动分析，极大地减少了对大量标注数据和多视图设置的需求，从而提高了实际应用性，尤其是在具身智能领域。将现有技术与针对关节物体的创新优化算法相结合也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在动态环境中分析运动部件及其属性时，需要依赖密集的D多视图图像或详细的部件级标注，这限制了其应用。准确的运动分析对于推进具身智能等关键领域至关重要。

**Method:** 我们提出了MonoMobility框架，能够以零样本方式从单目视频中分析3D运动，无需标注训练数据。该方法首先结合深度估计、光流分析和点云配准来构建场景几何并粗略分析运动部件及其初始属性，然后采用2D高斯泼溅进行场景表示。在此基础上，引入了一种专门为关节式物体设计的端到端动态场景优化算法，以细化分析结果，确保系统能处理旋转、平移及复合运动。为验证方法，我们创建了一个包含模拟和真实场景的综合数据集。

**Result:** 实验结果表明，我们的框架能够以无标注方式有效分析关节式物体运动。

**Conclusion:** MonoMobility框架在无需标注的情况下有效分析关节物体运动，展示了其在未来具身智能应用中的巨大潜力。

> **ai_Abstract:** 本文提出了MonoMobility，一个创新的零样本框架，旨在从单目视频中分析3D运动，解决了现有方法对多视图图像或详细标注的依赖。该框架通过结合深度估计、光流分析和点云配准来构建场景几何并初步分析运动部件和属性，随后利用2D高斯泼溅进行场景表示。此外，引入了一个专门为关节式对象设计的端到端动态场景优化算法，以精确处理包括旋转和平移在内的复杂运动。通过在自建的模拟和真实数据集上进行验证，实验结果证明了MonoMobility在无需标注的情况下有效分析关节物体运动的能力，展现了其在具身智能领域的重要应用前景。

> **摘要翻译:** 在动态环境中准确分析运动部件及其运动属性对于推进具身智能等关键领域至关重要。针对现有方法依赖密集多视图图像或详细部件级标注的局限性，我们提出了一种创新的框架，可以以零样本方式从单目视频中分析3D运动。该框架仅使用单目视频即可精确解析运动部件和运动属性，完全无需标注训练数据。具体来说，我们的方法首先结合深度估计、光流分析和点云配准方法构建场景几何并粗略分析运动部件及其初始运动属性，然后采用2D高斯泼溅进行场景表示。在此基础上，我们引入了一种专门为关节式物体设计的端到端动态场景优化算法，以细化初始分析结果，确保系统能够处理“旋转”、“平移”甚至复杂运动（“旋转+平移”），展示了高度的灵活性和多功能性。为了验证我们方法的鲁棒性和广泛适用性，我们创建了一个包含模拟和真实世界场景的综合数据集。实验结果表明，我们的框架能够以无标注方式有效分析关节式物体运动，展示了其在未来具身智能应用中的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [90] [Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT](https://arxiv.org/abs/2507.08448)
> *前馈式三维重建综述：从DUSt3R到VGGT*

*Wei Zhang, Yihang Wu, Songhua Li, Wenjie Ma, Xin Ma, Qiang Li, Qi Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 三维重建, 前馈, 深度学习, DUSt3R, 综述

**Comment:** 

> **TL;DR:** 本文综述了前馈式三维重建这一新兴领域，该领域通过深度学习模型（如DUSt3R）克服了传统三维重建方法的局限性，实现了从图像直接推断三维结构。综述内容涵盖了其技术框架、与传统方法的对比、数据集、应用前景及未来挑战。

**AI_Comments:** 这篇综述文章的重要性在于它系统地梳理并分析了三维重建领域中一个快速发展的新兴范式——前馈式深度学习方法。它清晰地指出了传统方法的痛点，并突出了新范式在解决这些问题上的颠覆性。对于研究人员而言，这篇综述提供了一个宝贵的资源，不仅详细阐述了前馈模型的技??细节，还展望了未来的研究方向和挑战，对于推动该领域的发展具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统三维重建方法（如SfM和MVS）存在工作流程复杂、计算成本高昂以及在无纹理区域等挑战性场景中鲁棒性差的局限性。随着深度学习的兴起，一种以DUSt3R为代表的前馈式三维重建新范式应运而生，能够通过单一前向传播直接推断相机姿态和稠密几何，因此有必要对这一新兴领域进行系统性综述。

**Method:** 本文对前馈式三维重建这一新兴领域进行了系统性综述。它解剖了这些模型的技??框架，包括基于Transformer的对应建模、联合姿态和几何回归机制以及从双视图到多视图场景的扩展策略。此外，该综述将这些模型与传统方法及早期的基于学习的方法（如MVSNet）进行对比，并概述了相关数据集和评估指标。

**Result:** 本综述解剖了前馈式三维重建模型的技??框架，包括其Transformer-based对应建模、联合姿态和几何回归机制以及从双视图到多视图场景的扩展策略。它将这一新范式与传统管道和早期基于学习的方法（如MVSNet）进行了对比，并提供了相关数据集和评估指标的概述，突出了新范式的颠覆性。

**Conclusion:** 本文讨论了前馈式三维重建技术的广阔应用前景，并指出了未来的主要挑战和机遇，例如模型精度和可扩展性，以及动态场景的处理。

> **ai_Abstract:** 本综述系统回顾了三维重建领域向以DUSt3R为代表的前馈式深度学习模型的范式转变。这些模型通过一次前向传播直接从图像推断相机姿态和稠密几何，克服了传统方法（如SfM和MVS）在工作流程复杂性、计算成本和鲁棒性方面的局限。文章深入剖析了前馈模型的技??框架，并将其与现有方法进行对比，同时概述了相关数据集和评估指标。最后，讨论了该技术的应用前景以及未来面临的挑战，如模型精度、可扩展性和动态场景处理。

> **摘要翻译:** 三维重建旨在恢复场景的稠密三维结构，是增强/虚拟现实、自动驾驶和机器人等众多应用的核心技术。虽然结构光法（SfM）和多视图立体视觉（MVS）等传统流程通过迭代优化实现了高精度，但它们受限于复杂的工作流程、高计算成本以及在无纹理区域等挑战性场景中鲁棒性差。最近，深度学习催生了三维重建领域的范式转变。以DUSt3R为代表的一系列新模型开创了前馈方法。这些模型采用统一的深度网络，通过一次前向传播直接从无约束图像集中联合推断相机姿态和稠密几何。本综述对这一新兴领域进行了系统性回顾。我们首先剖析了这些前馈模型的技??框架，包括其基于Transformer的对应建模、联合姿态和几何回归机制，以及从双视图扩展到多视图场景的策略。为了突出这种新范式的颠覆性，我们将其与传统流程和早期的基于学习的方法（如MVSNet）进行了对比。此外，我们概述了相关数据集和评估指标。最后，我们讨论了该技术的广阔应用前景，并指出了未来的主要挑战和机遇，例如模型精度和可扩展性，以及动态场景的处理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [103] [Lighting the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
> *利用生成式人工智能照亮夜晚*

*Tingting Zhou, Feng Zhang, Haoyang Fu, Baoxiang Pan, Renhe Zhang, Feng Lu, Zhixin Yang* | **Category: cs.CV, cs.AI, eess.IV** | **Updated: 2025-07-11**

**Keywords:** 生成扩散模型, 可见光反射率, 夜间观测, 气象观测, RefDiff

**Comment:** Title corrected (Lightning to Lighting); terminology updated
  (retrieval to generative)

> **TL;DR:** 本研究利用生成扩散模型RefDiff，基于热红外数据成功生成夜间可见光反射率，解决了夜间无法连续观测的问题，并显著提高了精度。

**AI_Comments:** 该论文的创新点在于率先将生成扩散模型应用于夜间可见光反射率的生成，有效解决了传统方法在夜间观测上的局限性。其重要性在于能够实现全天候连续的气象观测，这对于天气监测和预报具有重大意义。RefDiff模型不仅提高了精度，还提供了不确定性估计，增加了模型的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 可见光反射率数据对气象观测至关重要，但夜间缺乏可见光导致无法进行连续的全天候观测。

**Method:** 本研究开创性地使用生成扩散模型，基于风云四号B星（FY4B）搭载的先进静止轨道辐射成像仪（AGRI）的多波段热红外亮度温度数据，开发了一个高精度的可见光反射率生成模型Reflectance Diffusion (RefDiff)，能够生成0.47μm、0.65μm和0.825μm波段的夜间可见光反射率。

**Result:** 与经典模型相比，RefDiff通过集合平均显著提高了精度，并提供了不确定性估计。RefDiff的SSIM指数可达0.90，在复杂云结构和厚云区域有特别显著的改进。模型的夜间生成能力通过VIIRS夜间产品进行了验证，表现出与白天相当的性能。

**Conclusion:** 这项研究在夜间可见光反射率生成能力方面取得了实质性进展，有望扩展夜间可见光数据的应用。

> **ai_Abstract:** 本研究提出了一种名为Reflectance Diffusion (RefDiff) 的生成扩散模型，利用静止卫星的多波段热红外数据，首次实现了夜间可见光反射率的高精度生成。该模型有效解决了夜间无法进行连续可见光观测的局限性，并通过集合平均显著提高了生成精度，SSIM指数达到0.90，尤其在复杂云区表现出色。RefDiff的夜间生成能力与白天相当，有望扩展夜间可见光数据的应用。

> **摘要翻译:** 静止卫星的可见光反射率数据对于气象观测至关重要，在天气监测和预报中发挥着重要作用。然而，由于夜间缺乏可见光，无法利用可见光反射率数据进行连续的全天候气象观测。本研究开创性地使用生成扩散模型来解决这一限制。基于风云四号B星（FY4B）搭载的先进静止轨道辐射成像仪（AGRI）的多波段热红外亮度温度数据，我们开发了一个高精度的可见光反射率生成模型，名为Reflectance Diffusion (RefDiff)，它能够生成0.47微米、0.65微米和0.825微米波段的夜间可见光反射率。与经典模型相比，RefDiff不仅通过集合平均显著提高了精度，而且提供了不确定性估计。具体来说，RefDiff的SSIM指数可以达到0.90，在复杂云结构和厚云区域的改进尤为显著。该模型的夜间生成能力通过VIIRS夜间产品进行了验证，表现出与白天相当的性能。总之，这项研究在夜间可见光反射率生成能力方面取得了实质性进展，有望扩展夜间可见光数据的应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [106] [A document is worth a structured record: Principled inductive bias design for document recognition](https://arxiv.org/abs/2507.08458)
> *文档即结构化记录：文档识别中原则性归纳偏置设计*

*Benjamin Meyer, Lukas Tuggener, Sascha Hänzi, Daniel Schmid, Erdal Ayfer, Benjamin F. Grewe, Ahmed Abdulkadir, Thilo Stadelmann* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 文档识别, 归纳偏置, 结构化记录, Transformer, 工程图纸

**Comment:** 

> **TL;DR:** 本文提出将文档识别视为从文档到结构化记录的转录任务，并设计了结构特异性归纳偏置和基于Transformer的架构，成功应用于多种复杂文档类型，包括工程图纸，解决了现有方法忽略文档内在结构的问题。

**AI_Comments:** 该论文的创新点在于提出了将文档识别视为结构化记录转录的新颖视角，并引入了结构特异性归纳偏置来解决现有方法对复杂文档结构处理不足的问题。其贡献在于成功构建了首个能够端到端转录工程图纸的模型，这对于处理具有复杂内在链接信息的文档类型具有重要意义。该方法为未来文档基础模型的设计提供了原则性的指导，有望推动文档智能领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文档识别方法将文档识别视为单纯的计算机视觉问题，忽略了文档类型固有的、约定俗成的结构特性，导致依赖次优的启发式后处理，并使得许多不常见或更复杂的文档类型难以被现代文档识别系统处理。

**Method:** 本文提出将文档识别框架为从文档到记录的转录任务，并基于此设计了一种为底层机器学习端到端文档识别系统提供结构特异性归纳偏置的方法。同时，提出了一种可适应不同结构的基础Transformer架构。

**Result:** 通过对单声道乐谱、形状图和简化工程图等日益复杂的记录结构进行广泛实验，证明了所发现的归纳偏置的有效性。通过集成无限制图结构的归纳偏置，训练出首个成功将工程图转录为其内在互联信息的端到端模型。

**Conclusion:** 本文提出的方法为设计针对不常见文档类型的文档识别系统提供了指导，并有助于统一未来文档基础模型的设计。

> **ai_Abstract:** 本文提出了一种新颖的文档识别方法，将文档识别视为从文档到结构化记录的转录任务，以解决现有方法忽略文档内在结构的问题。该方法通过设计结构特异性归纳偏置和基于Transformer的架构，成功应用于多种复杂文档类型，包括实现工程图纸的端到端转录，为未来文档基础模型的设计提供了新思路。

> **摘要翻译:** 许多文档类型使用固有的、约定俗成的结构来编码精确和结构化的信息，例如工程图纸的管理约定。然而，最先进的方法将文档识别视为单纯的计算机视觉问题，忽略了这些底层的、特定于文档类型的结构属性，使得它们依赖于次优的启发式后处理，并使许多不常见或更复杂的文档类型无法被现代文档识别系统处理。我们提出了一种新颖的视角，将文档识别框定为从文档到记录的转录任务。这意味着基于文档转录中固有的内在结构进行文档的自然分组，其中相关的文档类型可以被相似地处理（和学习）。我们提出了一种设计结构特异性归纳偏置的方法，用于底层的机器学习端到端文档识别系统，以及一个相应的、我们成功适应不同结构的基础Transformer架构。我们通过对单声道乐谱、形状图和简化工程图等日益复杂的记录结构进行广泛实验，证明了所发现的归纳偏置的有效性。通过集成无限制图结构的归纳偏置，我们训练出首个成功将工程图转录为其内在互联信息的端到端模型。我们的方法与设计文档识别系统相关，适用于那些不如标准OCR、OMR等被充分理解的文档类型，并可作为统一未来文档基础模型设计的指南。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [109] [Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction](https://arxiv.org/abs/2507.08137)
> *用于3D人-物交互重建的时间一致性非模态补全*

*Hyungjun Doh, Dong In Lee, Seunggeun Chi, Pin-Hao Huang, Kwonjoon Lee, Sangpil Kim, Karthik Ramani* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 3D重建, 人-物交互, 非模态补全, 时间一致性, 单目视频

**Comment:** 

> **TL;DR:** 本文提出了一种用于从单目视频重建动态人-物交互的新框架，该框架通过时间一致性非模态补全克服了遮挡和时间不一致性带来的挑战。

**AI_Comments:** 该论文的创新点在于将非模态补全与时间一致性相结合，用于动态3D人-物交互重建，有效地解决了单目视频中常见的遮挡和重建不稳定问题。其无模板的策略也增加了方法的通用性和适应性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的3D重建方法通常假设静态物体或动态主体的完全可见性，当这些假设被违反时（特别是在相互遮挡的场景中），性能会下降。为此，需要一种新的方法来解决这些问题。

**Method:** 我们的框架利用非模态补全来推断部分模糊区域的完整结构。与在单个帧上操作的传统方法不同，我们的方法整合了时间上下文，强制跨视频序列的一致性，以逐步细化和稳定重建。这是一种无模板策略，通过使用3D高斯飞溅在具有挑战性的单目视频上验证了其方法。

**Result:** 与现有技术相比，该方法在处理遮挡和保持时间稳定性方面表现出卓越的精度，显著增强了动态场景中复杂细节的恢复。

**Conclusion:** 本文提出的框架通过解决遮挡和时间不一致性问题，显著增强了动态场景中复杂细节的恢复，实现了从单目视频中对动态人-物交互的精确重建。

> **ai_Abstract:** 本文提出了一种新颖的框架，用于从单目视频中重建动态人-物交互，旨在解决传统方法在处理遮挡和时间不一致性方面的不足。该框架通过非模态补全推断部分遮挡区域的完整结构，并结合时间上下文信息，确保重建结果在时间上的连贯性和稳定性。这种无需预定义模型的策略，通过3D高斯飞溅在挑战性视频上进行了验证，结果显示其在处理遮挡和保持时间稳定性方面优于现有技术，显著提升了动态场景细节的恢复能力。

> **摘要翻译:** 我们引入了一种新颖的框架，用于从单目视频中重建动态人-物交互，该框架克服了与遮挡和时间不一致性相关的挑战。传统的3D重建方法通常假设静态物体或动态主体的完全可见性，当这些假设被违反时——特别是在相互遮挡的场景中——会导致性能下降。为了解决这个问题，我们的框架利用非模态补全来推断部分模糊区域的完整结构。与在单个帧上操作的传统方法不同，我们的方法整合了时间上下文，强制跨视频序列的一致性，以逐步细化和稳定重建。这种无模板策略能够适应不同的条件，不依赖于预定义模型，显著增强了动态场景中复杂细节的恢复。我们使用3D高斯飞溅在具有挑战性的单目视频上验证了我们的方法，与现有技术相比，在处理遮挡和保持时间稳定性方面表现出卓越的精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [112] [SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations](https://arxiv.org/abs/2505.11992)
> *SpatialCrafter：释放视频扩散模型潜力，从有限观测中进行场景重建*

*Songchun Zhang, Huiyao Xu, Sitong Guo, Zhongwei Xie, Hujun Bao, Weiwei Xu, Changqing Zou* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 新视角合成, 视频扩散模型, 3D场景重建, 稀疏观测, 几何约束

**Comment:** Accepted by ICCV 2025. 12 pages, 9 figures

> **TL;DR:** SpatialCrafter利用视频扩散模型从稀疏或单视角输入重建逼真的3D场景，通过生成额外的观测、施加几何约束和统一尺度估计来解决重建模糊性，并直接回归3D高斯基元。

**AI_Comments:** SpatialCrafter的创新之处在于其利用视频扩散模型来弥补稀疏观测的不足，通过生成额外的合理观测来解决3D重建中的歧义性。结合了明确的几何约束（外极注意力）和统一的尺度估计，以及直接回归3D高斯基元，这使得其在从有限数据重建复杂场景方面具有显著潜力。该方法对于扩展新视角合成的应用范围具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有新视角合成（NVS）技术依赖于密集的、多视角观测，这限制了它们的应用。本文旨在解决从稀疏或单视角输入重建逼真3D场景的挑战。

**Method:** 本文引入了SpatialCrafter框架，它利用视频扩散模型生成合理的额外观测，以减轻重建模糊性。该框架通过可训练的相机编码器和外极注意力机制实现精确的相机控制和3D一致性，并通过统一的尺度估计策略处理数据集间的尺度差异。此外，它将单目深度先验与视频潜在空间中的语义特征相结合，直接回归3D高斯基元，并使用混合网络结构高效处理长序列特征。

**Result:** 广泛的实验表明，我们的方法增强了稀疏视角重建，并恢复了3D场景的真实外观。

**Conclusion:** SpatialCrafter成功地从有限的观测中重建了逼真的3D场景，克服了现有新视角合成技术对密集多视角输入的依赖，并有效解决了重建模糊性、几何一致性和尺度差异等挑战。

> **ai_Abstract:** SpatialCrafter是一个新颖的框架，旨在从稀疏或单视角输入重建逼真的3D场景，克服了传统新视角合成技术对密集观测的依赖。它通过利用视频扩散模型生成额外的观测来解决重建模糊性，并采用可训练的相机编码器、外极注意力机制和统一的尺度估计策略来确保精确的相机控制和3D一致性。该框架还将单目深度先验与语义特征结合，直接回归3D高斯基元，并通过混合网络高效处理特征。实验证明，SpatialCrafter显著提升了稀疏视角下的场景重建质量和真实感。

> **摘要翻译:** 新视角合成（NVS）提升了计算机视觉和图形中的沉浸式体验。现有技术虽然取得了进展，但依赖于密集的、多视角观测，这限制了它们的应用。这项工作面临的挑战是从稀疏或单视角输入重建逼真的3D场景。我们引入了SpatialCrafter，一个利用视频扩散模型丰富知识生成合理额外观测的框架，从而减轻了重建模糊性。通过可训练的相机编码器和用于显式几何约束的外极注意力机制，我们实现了精确的相机控制和3D一致性，并通过统一的尺度估计策略进一步加强，以处理数据集间的尺度差异。此外，通过将单目深度先验与视频潜在空间中的语义特征相结合，我们的框架直接回归3D高斯基元，并使用混合网络结构高效处理长序列特征。广泛的实验表明，我们的方法增强了稀疏视角重建并恢复了3D场景的真实外观。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [119] [SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving](https://arxiv.org/abs/2306.03538)
> *SDR-GAIN：一种用于自动驾驶的高实时性遮挡行人姿态补全方法*

*Honghao Fu, Yongli Gu, Yidong Yan, Yilang Shen, Yiwen Wu, Libo Sun* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 遮挡行人姿态补全, 实时性, 生成对抗网络, 自动驾驶, 关键点插补

**Comment:** 

> **TL;DR:** SDR-GAIN是一种新的实时方法，通过直接从关键点坐标的数值分布中学习来补全遮挡行人的姿态，并在COCO和JAAD数据集上表现出高准确性和微秒级实时推理。

**AI_Comments:** SDR-GAIN的创新之处在于其不依赖视觉模型，而是直接从关键点坐标的数值分布中学习并插补缺失位置，这使其可能对不同类型的遮挡具有更强的泛化能力。其自监督对抗学习范式和轻量级设计使其能够实现高实时性，这对于自动驾驶应用中对速度要求极高的场景至关重要。该方法在准确性和实时性上都表现出色，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂的交通场景中，传统的姿态估计方法难以准确重建被车辆、植被或建筑元素遮挡的关键点，这限制了视觉自动驾驶技术在交通安全和系统鲁棒性方面的提升。

**Method:** 本文提出SDR-GAIN（基于分离和降维的生成对抗插补网络），它直接从关键点坐标的数值分布中学习人体姿态并插补缺失位置，而非训练视觉模型区分遮挡模式。该方法采用自监督对抗学习范式训练带有残差结构的轻量级生成器来插补缺失姿态关键点，并整合了多种姿态标准化技术以降低学习难度。

**Result:** 在COCO和JAAD数据集上的实验表明，SDR-GAIN在准确恢复遮挡行人关键点方面超越了传统的机器学习和基于Transformer的缺失数据插补算法，同时实现了微秒级的实时推理。

**Conclusion:** SDR-GAIN为自动驾驶中遮挡行人姿态的实时补全提供了一种有效且高效的解决方案，显著提高了姿态恢复的准确性和推理速度。

> **ai_Abstract:** 针对自动驾驶中行人姿态估计在复杂遮挡场景下难以准确重建关键点的问题，本文提出了一种名为SDR-GAIN的实时遮挡行人姿态补全框架。SDR-GAIN的核心在于它不依赖于视觉模型来识别遮挡模式，而是直接从关键点坐标的数值分布中学习并插补缺失位置。该方法利用自监督对抗学习范式训练轻量级生成器，并结合姿态标准化技术以优化学习过程。实验结果表明，SDR-GAIN在COCO和JAAD数据集上，在恢复遮挡行人关键点的准确性方面优于传统的机器学习和基于Transformer的算法，并且能够实现微秒级的实时推理。

> **摘要翻译:** 随着基于视觉的自动驾驶技术的进步，行人检测已成为提高交通安全和驾驶系统鲁棒性的重要组成部分。然而，在复杂的交通场景中，传统的姿态估计方法经常无法准确重建被遮挡的关键点，这主要是由于车辆、植被或建筑元素造成的障碍。为了解决这个问题，我们提出了一种名为SDR-GAIN（基于分离和降维的生成对抗插补网络）的新型实时遮挡行人姿态补全框架。与以前训练视觉模型以区分遮挡模式的方法不同，SDR-GAIN旨在直接从关键点坐标的数值分布中学习人体姿态并插补缺失位置。它采用自监督对抗学习范式来训练带有残差结构的轻量级生成器，用于缺失姿态关键点的插补。此外，它还整合了多种姿态标准化技术，以减轻学习过程的难度。在COCO和JAAD数据集上进行的实验表明，SDR-GAIN在准确恢复遮挡行人关键点方面超越了传统的机器学习和基于Transformer的缺失数据插补算法，同时实现了微秒级的实时推理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [126] [F3-Net: Foundation Model for Full Abnormality Segmentation of Medical Images with Flexible Input Modality Requirement](https://arxiv.org/abs/2507.08460)
> *F3-Net：具有灵活输入模态要求的医学图像全异常分割基础模型*

*Seyedeh Sahar Taheri Otaghsara, Reza Rahmanzadeh* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 医学图像分割, 基础模型, 多模态, 零图像策略, 泛化性

**Comment:** 

> **TL;DR:** F3-Net是一个医学图像分割基础模型，通过灵活的合成模态训练和零图像策略，在缺少MRI序列的情况下也能进行多病理分割，表现优于传统模型。

**AI_Comments:** F3-Net的创新之处在于其“零图像策略”和统一架构，这显著提升了模型在临床实践中的鲁棒性和通用性，尤其是在MRI序列不完整的情况下。其在多病理分割上的表现，无需重新训练，是迈向更普适性医疗AI模型的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 克服临床医学图像分割中对完整多模态输入的依赖、泛化能力有限和狭窄的任务特异性等挑战。

**Method:** 通过灵活的合成模态训练，即使在缺少MRI序列的情况下也能保持鲁棒性能；利用零图像策略替代缺失模态，不依赖显式合成网络；统一架构支持多病理分割，无需重新训练。

**Result:** 在BraTS 2021、BraTS 2024和ISLES 2022等数据集上进行了评估，对领域漂移和临床异质性表现出强大韧性。在整体病理数据集上，BraTS-GLI 2024的平均Dice相似系数（DSC）为0.94，BraTS-MET 2024为0.82，BraTS 2021为0.94，ISLES 2022为0.79。性能优于通常需要疾病特定微调的基于CNN和基于Transformer的模型。

**Conclusion:** F3-Net是一个通用、可扩展的解决方案，弥合了深度学习研究与实际临床部署之间的鸿沟。

> **ai_Abstract:** F3-Net是一个为解决医学图像分割中多模态依赖、泛化性差和任务特异性强等问题而设计的基础模型。它采用灵活的合成模态训练和零图像策略，在MRI序列缺失的情况下仍能保持高性能，并以统一架构支持多病理分割，无需重新训练。F3-Net在多个数据集上表现出色，超越了传统模型，展现了强大的领域适应性，有望推动深度学习在临床医学中的实际应用。

> **摘要翻译:** F3-Net是一个基础模型，旨在克服临床医学图像分割中持续存在的挑战，包括对完整多模态输入的依赖、有限的泛化能力和狭窄的任务特异性。通过灵活的合成模态训练，F3-Net即使在缺少MRI序列的情况下也能保持鲁棒性能，它利用零图像策略替代缺失模态，而不依赖显式合成网络，从而增强了实际应用性。其统一架构支持胶质瘤、转移瘤、中风和白质病变等多种病理分割，无需重新训练，并且优于通常需要疾病特定微调的基于CNN和基于Transformer的模型。在BraTS 2021、BraTS 2024和ISLES 2022等多样化数据集上进行评估，F3-Net对领域漂移和临床异质性表现出强大的韧性。在整体病理数据集上，F3-Net在BraTS-GLI 2024上取得了0.94的平均Dice相似系数（DSC），在BraTS-MET 2024上取得了0.82，在BraTS 2021上取得了0.94，在ISLES 2022上取得了0.79。这使其成为一个通用、可扩展的解决方案，弥合了深度学习研究与实际临床部署之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [128] [Hita: Holistic Tokenizer for Autoregressive Image Generation](https://arxiv.org/abs/2507.02358)
> *Hita：用于自回归图像生成的整体分词器*

*Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 图像分词器, 自回归生成, 整体到局部, 全局信息, Hita

**Comment:** 17 pages, 10 figures

> **TL;DR:** Hita是一种新型图像分词器，通过引入整体到局部标记化方案和两种关键策略，解决了传统自回归图像生成模型在捕获整体关系和全局信息方面的局限性，显著提升了训练速度和生成性能。

**AI_Comments:** Hita的创新点在于其独特的整体到局部标记化方案，这有效解决了传统自回归模型在处理全局信息和标记间整体关系上的不足。通过引入可学习的整体查询和精巧的序列化及融合策略，Hita不仅提升了生成图像的质量，还加速了训练过程，这对于大规模图像生成任务具有重要意义。其在多项任务中的有效性也证明了该方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的自回归图像生成模型逐步生成视觉标记，限制了它们捕获标记序列之间整体关系的能力。此外，大多数视觉分词器将局部图像块映射为潜在标记，导致全局信息有限。

**Method:** 本文提出了Hita，一种用于自回归（AR）图像生成的新型图像分词器。它引入了一种整体到局部的标记化方案，包含可学习的整体查询和局部块标记。Hita整合了两种关键策略以更好地与AR生成过程对齐：1）安排一个序列结构，整体标记在前，随后是补丁级标记，并使用因果注意力来保持对先前标记的感知；2）在将去量化标记输入解码器之前采用一个轻量级融合模块来控制信息流并优先处理整体标记。

**Result:** Hita加速了AR生成器的训练速度，并优于使用传统分词器训练的模型，在ImageNet基准上实现了2.59 FID和281.9 IS。对整体表示的详细分析突出其捕获全局图像属性（如纹理、材料和形状）的能力。此外，Hita在零样本风格迁移和图像修复中也表现出有效性。

**Conclusion:** Hita作为一种新型的整体到局部图像分词器，有效解决了自回归图像生成中全局信息捕获和整体关系建模的挑战，显著提升了模型性能和训练效率，并在多项任务中展现了优越性。

> **ai_Abstract:** 本论文提出Hita，一种针对自回归图像生成的新型图像分词器，旨在解决现有模型无法有效捕获整体关系和全局信息的问题。Hita采用整体到局部的标记化方案，结合可学习的整体查询和局部块标记。通过序列化整体标记在前、局部标记在后，并使用因果注意力及轻量级融合模块，Hita优化了信息流，优先处理整体信息。实验证明，Hita显著提升了自回归生成器的训练速度和性能，在ImageNet上取得了优异的FID和IS分数，并能有效捕获全局图像属性，同时在零样本风格迁移和图像修复任务中表现出色。

> **摘要翻译:** 香草自回归图像生成模型逐步生成视觉标记，限制了它们捕获标记序列之间整体关系的能力。此外，由于大多数视觉分词器将局部图像块映射为潜在标记，全局信息有限。为了解决这个问题，我们引入了Hita，一种用于自回归（AR）图像生成的新型图像分词器。它引入了一种整体到局部的标记化方案，包含可学习的整体查询和局部补丁标记。Hita整合了两种关键策略以更好地与AR生成过程对齐：1）安排一个序列结构，整体标记在前，随后是补丁级标记，并使用因果注意力来保持对先前标记的感知；2）在将去量化标记输入解码器之前采用一个轻量级融合模块来控制信息流并优先处理整体标记。大量实验表明，Hita加速了AR生成器的训练速度，并优于使用香草分词器训练的模型，在ImageNet基准上实现了2.59 FID和281.9 IS。对整体表示的详细分析突出其捕获全局图像属性，如纹理、材料和形状的能力。此外，Hita在零样本风格迁移和图像修复中也表现出有效性。代码可在https://github.com/CVMI-Lab/Hita 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [135] [SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting](https://arxiv.org/abs/2311.10011)
> *SQLNet：用于少样本类别无关计数的尺度调制查询与定位网络*

*Hefeng Wu, Yandong Chen, Lingbo Liu, Tianshui Chen, Keze Wang, Liang Lin* | **Category: cs.CV** | **Updated: 2025-07-10**

**Keywords:** 类别无关计数, 少样本学习, 对象定位, 尺度调制, 神经网络

**Comment:** Accepted by IEEE Transactions on Image Processing

> **TL;DR:** SQLNet提出了一种新颖的基于定位的少样本类别无关计数方法，通过准确地定位和预测对象大小，解决了现有密度图回归方法的局限性，并在计数、定位和边界框生成方面表现优异。

**AI_Comments:** SQLNet的创新之处在于其从密度图回归转向基于定位的方法，这不仅解决了现有方法无法提供精确对象位置的局限性，还为下游任务提供了更多实用价值。它对样本尺度信息的充分利用，通过HECE、EUQC和SAML等模块贯穿整个计数过程，是其性能优越的关键。引入尺度感知定位损失也进一步提升了模型的优化。该研究对于少样本类别无关计数领域是一个重要的进展，拓展了该任务的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 现有的类别无关计数（CAC）领先方法都依赖于密度图回归，这使得它们不适用于需要对象定位的下游任务，并限制了它们有效探索样本尺度信息进行监督的能力。

**Method:** 本文提出了一种名为尺度调制查询与定位网络（SQLNet）的新型基于定位的CAC方法。它在查询和定位阶段充分利用样本的尺度信息，通过准确地定位每个对象并预测其近似大小来实现有效计数。具体来说，在查询阶段，通过分层样本协作增强（HECE）模块，利用多尺度样本协作与等频尺寸提示嵌入，从少量样本中获取丰富的判别性表示。这些表示随后输入到样本统一查询相关性（EUQC）模块，以统一的方式与查询特征交互，生成相关的查询张量。在定位阶段，尺度感知多头定位（SAML）模块利用查询张量预测每个潜在对象的置信度、位置和大小。此外，引入了尺度感知定位损失，利用灵活的位置关联和样本尺度进行监督以优化模型性能。

**Result:** 大量实验表明，SQLNet在流行的CAC基准测试中优于最先进的方法，不仅在计数精度方面，而且在定位和边界框生成方面都取得了出色的性能。

**Conclusion:** SQLNet通过创新的基于定位的方法和对样本尺度信息的充分利用，有效解决了类别无关计数任务中现有方法的局限性，并在计数、定位和边界框生成方面取得了显著的改进。

> **ai_Abstract:** 本文提出了SQLNet，一个针对少样本类别无关计数任务的新型基于定位的网络。针对现有密度图回归方法无法提供对象位置和未能充分利用样本尺度信息的局限性，SQLNet通过在查询和定位阶段全面探索样本尺度信息，实现了精确的对象定位和尺寸预测。该网络包含分层样本协作增强（HECE）模块获取判别性表示，样本统一查询相关性（EUQC）模块进行特征交互，以及尺度感知多头定位（SAML）模块进行置信度、位置和大小预测。此外，引入了尺度感知定位损失以优化性能。实验证明，SQLNet在计数、定位和边界框生成方面均优于现有最先进方法。

> **摘要翻译:** 类别无关计数（CAC）任务最近被提出，旨在解决在输入图像中给定少量样本的情况下，计算任意类别所有对象数量的问题。为了解决这项具有挑战性的任务，现有领先方法都依赖于密度图回归，这使得它们不适用于需要对象位置的下游任务，并限制了它们有效探索样本尺度信息进行监督的能力。为了解决这些局限性，我们提出了一种新颖的基于定位的CAC方法，称为尺度调制查询与定位网络（SQLNet）。它在查询和定位阶段充分探索了样本的尺度，并通过准确地定位每个对象并预测其近似大小来实现有效计数。具体来说，在查询阶段，通过分层样本协作增强（HECE）模块，利用多尺度样本协作与等频尺寸提示嵌入，从少量样本中获取丰富的判别性表示。这些表示随后输入到样本统一查询相关性（EUQC）模块，以统一的方式与查询特征交互，生成相关的查询张量。在定位阶段，尺度感知多头定位（SAML）模块利用查询张量预测每个潜在对象的置信度、位置和大小。此外，引入了尺度感知定位损失，利用灵活的位置关联和样本尺度进行监督以优化模型性能。大量实验表明，SQLNet在流行的CAC基准测试中优于最先进的方法，不仅在计数精度方面，而且在定位和边界框生成方面都取得了出色的性能。我们的代码将在https://github.com/HCPLab-SYSU/SQLNet上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [136] [Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation](https://arxiv.org/abs/2506.03942)
> *用于医学图像分割中可靠不确定性的平均校准损失*

*Theodore Barfoot, Luis C. Garcia-Peraza-Herrera, Samet Akcay, Ben Glocker, Tom Vercauteren* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 医学图像分割, 校准误差, 不确定性, 深度学习, mL1-ACE

**Comment:** 12 pages, 5 figures, IEEE TMI submission. This version originally
  appeared in error as arXiv:2403.06759(v2)

> **TL;DR:** 本文提出了一种可微分的边际L1平均校准误差（mL1-ACE）作为辅助损失，用于改善医学图像分割中深度神经网络的像素级校准，实验证明其能显著降低校准误差，提高预测的可靠性。

**AI_Comments:** 本文的创新点在于提出了可微分的mL1-ACE作为辅助损失，可以直接优化像素级校准，并引入了数据集可靠性直方图来全面评估校准性能。其重要性在于解决了医学图像分割中深度网络过度自信的实际问题，有助于提高AI辅助诊断的可靠性和安全性，对于推动深度学习在临床实践中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像分割中的深度神经网络常常过度自信，这损害了其可靠性和临床实用性。

**Method:** 本文提出了可微分的边际L1平均校准误差（mL1-ACE）作为一种辅助损失，可以在每张图像的基础上进行计算。比较了硬分箱和软分箱方法来直接改善像素级校准。此外，引入了数据集可靠性直方图（每张图像可靠性图的聚合）以深入了解校准性能及其在整个图像数据集中的变异性。

**Result:** 在四个数据集（ACDC、AMOS、KiTS、BraTS）上的实验表明，引入mL1-ACE显著降低了校准误差，特别是平均校准误差（ACE）和最大校准误差（MCE），同时基本保持了较高的Dice相似系数（DSCs）。软分箱变体在校准方面产生了最大的改进，但通常会损害分割性能；硬分箱的mL1-ACE则保持了分割性能，尽管校准改进较弱。分析结果突出了预测置信度与真实准确度之间的一致性得到了改善。

**Conclusion:** 本文提出的方法不仅增强了分割预测的可靠性，而且显示出将深度学习方法更安全地集成到临床工作流程中的潜力。

> **ai_Abstract:** 本研究针对医学图像分割中深度神经网络过度自信的问题，提出了一种可微分的边际L1平均校准误差（mL1-ACE）作为辅助损失，旨在提高像素级校准。通过比较硬分箱和软分箱方法，实验结果表明mL1-ACE能显著降低校准误差，其中软分箱在校准上表现最佳但可能影响分割性能，硬分箱则能保持分割性能。此外，论文引入了数据集可靠性直方图来评估校准性能，并证实了预测置信度与真实准确度之间的一致性得到改善。该方法有望提升分割预测的可靠性，促进深度学习在临床中的安全应用。

> **摘要翻译:** 深度神经网络在医学图像分割中常常过度自信，这损害了其可靠性和临床实用性。在这项工作中，我们提出了边际L1平均校准误差（mL1-ACE）的可微分公式作为一种辅助损失，可以在每张图像的基础上进行计算。我们比较了硬分箱和软分箱方法来直接改善像素级校准。我们在四个数据集（ACDC、AMOS、KiTS、BraTS）上的实验表明，引入mL1-ACE显著降低了校准误差，特别是平均校准误差（ACE）和最大校准误差（MCE），同时基本保持了较高的Dice相似系数（DSCs）。我们发现，软分箱变体在校准方面产生了最大的改进，优于Dice加交叉熵损失基线，但通常会损害分割性能；而硬分箱的mL1-ACE则保持了分割性能，尽管校准改进较弱。为了进一步深入了解校准性能及其在整个图像数据集中的变异性，我们引入了数据集可靠性直方图，这是每张图像可靠性图的聚合。由此产生的分析突出了预测置信度与真实准确度之间的一致性得到了改善。总的来说，我们的方法不仅增强了分割预测的可靠性，而且显示出将深度学习方法更安全地集成到临床工作流程中的潜力。我们在此分享了我们的代码：https://github.com/cai4cai/Average-Calibration-Losses

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [137] [HNOSeg-XS: Extremely Small Hartley Neural Operator for Efficient and Resolution-Robust 3D Image Segmentation](https://arxiv.org/abs/2507.08205)
> *HNOSeg-XS：用于高效和分辨率鲁棒3D图像分割的极小型哈特利神经算子*

*Ken C. L. Wong, Hongzhi Wang, Tanveer Syeda-Mahmood* | **Category: cs.CV** | **Updated: 2025-07-10**

**Keywords:** 3D图像分割, 神经算子, 哈特利变换, 分辨率鲁棒性, 医学影像

**Comment:** This paper was accepted by IEEE TMI 2025

> **TL;DR:** 提出HNOSeg-XS，一个基于哈特利神经算子的极小型模型，用于高效、分辨率鲁棒的3D医学图像分割，解决了现有CNN和Transformer在计算成本、内存和高分辨率应用上的局限性，实现了更优的推理速度、内存效率和参数量。

**AI_Comments:** 该论文的创新点在于将傅里叶神经算子中的傅里叶变换替换为哈特利变换，从而在频域高效地处理3D医学图像分割问题。其“零样本超分辨率”特性和在极低参数量下实现的高效率（推理时间、内存）和分辨率鲁棒性，对于资源受限的医学影像分析场景具有重要意义，克服了传统CNN和Transformer的局限。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D医学图像分割模型（CNN和Transformer）面临挑战：
- CNN计算成本高、内存占用大，3D模型层数和感受野受限。
- Transformer多头注意力机制的二次复杂度导致计算量大。
- 两者为提升性能可能需要减小输入尺寸，但离散性质导致在更高分辨率下表现不佳。

**Method:** 提出HNOSeg-XS架构，通过可学习偏微分方程和傅里叶神经算子（具有零样本超分辨率特性）来建模图像分割。核心创新是将傅里叶变换替换为哈特利变换，并在频域重新制定问题，从而创建了一个分辨率鲁棒、快速、内存高效且参数极小的模型。

**Result:** - 在BraTS'23、KiTS'23和MVSeg'23数据集上进行测试。
- 展现出卓越的分辨率鲁棒性。
- 模型参数少于34.7k。
- 实现了最佳的推理时间（< 0.24 秒）。
- 实现了最佳的内存效率（< 1.8 GiB）。
- 性能优于测试的CNN和Transformer模型。

**Conclusion:** HNOSeg-XS模型通过引入哈特利神经算子，有效解决了3D医学图像分割中现有CNN和Transformer模型的计算、内存及分辨率鲁棒性问题，展现出卓越的效率和性能。

> **ai_Abstract:** 本论文提出HNOSeg-XS，一种基于哈特利神经算子（Hartley Neural Operator）的极小型架构，专为高效且分辨率鲁棒的3D医学图像分割设计。该模型通过可学习的偏微分方程和频域重构，解决了传统CNN和Transformer在3D分割中面临的计算成本高、内存占用大以及高分辨率下性能下降的问题。HNOSeg-XS通过将傅里叶变换替换为哈特利变换，实现了优异的分辨率鲁棒性、更快的推理速度、更高的内存效率以及极低的参数量（< 34.7k），在多个医学图像数据集上表现优于现有模型。

> **摘要翻译:** 在医学图像分割领域，卷积神经网络（CNN）和Transformer占据主导地位。对于CNN，鉴于卷积层的局部感受野，长距离空间相关性通过连续的卷积和池化来捕获。然而，由于计算成本和内存占用可能非常大，3D模型只能比2D模型拥有更少的层，导致感受野和抽象级别降低。对于Transformer，尽管多头注意力可以捕获长距离相关性，但其相对于输入尺寸的二次复杂度导致计算量巨大。因此，这两种模型都可能需要减小输入尺寸以允许更多的滤波器和层来获得更好的分割效果。然而，鉴于它们的离散性质，通过块状训练或图像降采样训练的模型在应用于更高分辨率时可能会产生次优结果。为了解决这个问题，我们提出了分辨率鲁棒的HNOSeg-XS架构。我们通过傅里叶神经算子（具有零样本超分辨率特性）将图像分割建模为可学习的偏微分方程。通过将傅里叶变换替换为哈特利变换并在频域重新制定问题，我们创建了HNOSeg-XS模型，该模型具有分辨率鲁棒、快速、内存高效和参数极小的特点。在Tesla V100 GPU上对BraTS'23、KiTS'23和MVSeg'23数据集进行测试时，HNOSeg-XS展现出卓越的分辨率鲁棒性，模型参数少于34.7k。与测试的CNN和Transformer模型相比，它还实现了最佳的整体推理时间（< 0.24 秒）和内存效率（< 1.8 GiB）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [146] [Dual Dimensions Geometric Representation Learning Based Document Dewarping](https://arxiv.org/abs/2507.08492)
> *基于双维度几何表示学习的文档去畸变*

*Heng Li, Qingcai Chen, Xiangping Wu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 文档去畸变, 几何表示学习, 双维度, 细粒度感知, 数据集

**Comment:** 

> **TL;DR:** 现有文档去畸变方法主要关注水平维度，本文提出了D2Dewarp模型，利用文档的水平和垂直双维度几何表示学习来感知更精细的形变，并构建了一个新的大规模训练数据集，在公开基准上取得了最先进的去畸变效果。

**AI_Comments:** 该论文的创新点在于引入了文档的水平和垂直双维度进行几何表示学习，以更精细地感知文档形变，这解决了现有方法仅关注单一维度的局限性。此外，针对数据集中标注线特征缺乏的问题，作者提出了一种自动细粒度标注方法并构建了新的大规模数据集，这对推动该领域的研究具有重要意义。整体上，该工作在方法和数据两方面都做出了显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在深度学习时代，文档图像去畸变仍然是一个具有挑战性的任务。现有方法虽然通过利用文本行感知有所改进，但通常只关注单一的水平维度，这限制了它们对文档细节处形变趋势的感知能力。

**Method:** 本文提出了D2Dewarp，一个关注文档水平-垂直双维度线的细粒度形变感知模型。它设计了一个基于X和Y坐标的有效融合模块，以促进两个维度之间的交互和约束，实现特征互补。此外，针对当前公开去畸变数据集中缺乏标注线特征的问题，作者提出了一种利用公开文档纹理图像和自动渲染引擎构建新的大规模形变训练数据集的自动细粒度标注方法。

**Result:** 在公开的中英文基准测试中，定量和定性结果均表明，与最先进的方法相比，D2Dewarp方法取得了更好的矫正效果。

**Conclusion:** D2Dewarp方法通过利用双维度几何表示学习和构建新的大规模数据集，显著提高了文档去畸变性能，超越了现有最先进的方法。

> **ai_Abstract:** 本文提出了一种名为D2Dewarp的文档去畸变模型，旨在解决现有方法仅关注单一水平维度的局限性。D2Dewarp通过引入文档水平和垂直双维度线的几何表示学习，实现对细粒度形变的感知，并设计了一个基于X和Y坐标的有效融合模块以增强特征互补性。鉴于当前数据集缺乏细粒度标注，作者还提出了一种自动标注方法，并构建了一个新的大规模畸变训练数据集。实验结果表明，D2Dewarp在公开的中英文基准测试上，无论是定量还是定性表现，均优于现有最先进的去畸变方法。

> **摘要翻译:** 在深度学习时代，文档图像去畸变仍然是一个具有挑战性的任务。虽然现有方法通过利用文本行感知有所改进，但它们通常只关注单一的水平维度。在本文中，我们提出了一个关注文档水平-垂直双维度的细粒度形变感知模型，以改进文档去畸变，称为D2Dewarp。它能感知文档细节处不同方向的畸变趋势。为了结合水平和垂直粒度特征，我们设计了一个基于X和Y坐标的有效融合模块，以促进两个维度之间的交互和约束，实现特征互补。由于当前公开去畸变数据集中缺乏标注线特征，我们还提出了一种利用公开文档纹理图像和自动渲染引擎构建新的大规模畸变训练数据集的自动细粒度标注方法。代码和数据集将公开。在公开的中英文基准测试中，定量和定性结果均表明，我们的方法与最先进的方法相比，取得了更好的矫正效果。数据集将在https://github.com/xiaomore/DocDewarpHV 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [147] [GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction](https://arxiv.org/abs/2402.19002)
> *GoalNet：面向目标区域的行人轨迹预测*

*Amar Fadillah, Ching-Lin Lee, Zhi-Xuan Wang, Kuan-Ting Lai* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 行人轨迹预测, 目标区域, 自动驾驶, 深度学习, GoalNet

**Comment:** 

> **TL;DR:** GoalNet通过预测行人目标区域来提高行人轨迹预测的准确性，在两个数据集上显著优于现有技术。

**AI_Comments:** GoalNet的创新之处在于其“目标区域导向”的预测范式，即先预测目标点再预测轨迹，这有效地利用了场景上下文和行人意图来减少预测的不确定性，解决了多模态预测中的一个核心难题。其在两个公开数据集上的显著性能提升，证明了该方法的有效性和重要性。此外，模型能够同时预测轨迹和边界框，并具有模块化特性，增加了其实用性和灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中预测行人未来轨迹是一项重要任务，但现有方法未充分考虑场景上下文和行人目标，导致预测不确定性高。

**Method:** 提出GoalNet，一个基于行人目标区域的新型轨迹预测神经网络。它首先利用场景上下文和观测轨迹预测目标点，然后利用目标点预测未来轨迹。该网络还能预测行人轨迹和边界框。

**Result:** GoalNet在JAAD数据集上将现有最先进性能提升48.7%，在PIE数据集上提升40.8%。

**Conclusion:** GoalNet通过引入目标区域预测显著提高了行人轨迹预测的准确性，并能预测轨迹和边界框，模型高效且模块化。

> **ai_Abstract:** 本文提出了GoalNet，一个面向目标区域的行人轨迹预测神经网络，旨在解决现有方法未充分考虑场景上下文和行人目标导致预测不确定性高的问题。GoalNet首先预测行人的目标点，再基于目标点预测未来轨迹，有效利用场景上下文和观测轨迹信息限制不确定性。该模型还能预测行人边界框，并具有高效和模块化的特点。实验证明，GoalNet在JAAD和PIE数据集上显著提升了行人轨迹预测的现有最佳性能。

> **摘要翻译:** 在道路上预测行人的未来轨迹是自动驾驶的一项重要任务。行人轨迹预测受场景路径、行人意图和决策影响，是一个多模态问题。最近的大多数研究利用过去的轨迹来预测各种潜在的未来轨迹分布，但没有考虑场景上下文和行人目标。我们没有直接预测未来轨迹，而是提出利用场景上下文和观测轨迹首先预测目标点，然后重用目标点来预测未来轨迹。通过利用场景上下文和观测轨迹的信息，不确定性可以限制在少数几个目标区域，这些区域代表了行人的“目标”。本文中，我们提出了GoalNet，一个基于行人目标区域的新型轨迹预测神经网络。我们的网络可以预测行人的轨迹和边界框。整个模型高效且模块化，其输出可以根据使用场景进行更改。实验结果表明，GoalNet在JAAD数据集上显著提高了48.7%的现有最先进性能，在PIE数据集上提高了40.8%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [153] [USAD: End-to-End Human Activity Recognition via Diffusion Model with Spatiotemporal Attention](https://arxiv.org/abs/2507.02827)
> *USAD：基于扩散模型和时空注意力的端到端人体活动识别*

*Hang Xiao, Ying Yu, Jiarui Li, Zhifan Yang, Haotian Tang, Hanyu Liu, Chao Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 人体活动识别, 扩散模型, 时空注意力, 数据增强, 端到端

**Comment:** 

> **TL;DR:** 提出了一种名为USAD的端到端扩散模型，结合时空注意力机制，有效解决了人体活动识别中数据稀缺和特征提取不足的问题，并在嵌入式设备上验证了其高效性。

**AI_Comments:** 这篇论文通过结合扩散模型进行数据增强和创新的多分支时空注意力网络，有效解决了人体活动识别领域中的核心挑战，特别是数据稀缺和特征表示能力问题。其端到端的设计和在嵌入式设备上的验证，表明了该方法在实际应用中的巨大潜力。多注意力机制的引入是其创新亮点。

<details>
  <summary>Details</summary>

**Motivation:** 人体活动识别（HAR）面临标注样本稀缺、高级特征提取不足以及轻量级设备上模型性能不佳等挑战。

**Method:** 提出USAD模型，通过以下方法优化：1) 使用无监督、统计引导的扩散模型进行数据增强，解决数据稀缺和类别不平衡问题。2) 设计多分支时空交互网络，通过不同大小的卷积核（3x3, 5x5, 7x7）捕获多尺度特征。3) 融入时间注意力机制识别关键时间点，空间注意力增强传感器间交互。4) 引入跨分支特征融合单元。5) 集成自适应多损失函数融合策略进行模型优化。

**Result:** 在WISDM、PAMAP2和OPPORTUNITY三个公共数据集上，USAD分别达到了98.84%、93.81%和80.92%的准确率，显著优于现有方法。在嵌入式设备上的部署验证了其效率和可行性。

**Conclusion:** USAD模型通过其创新的数据增强、时空注意力机制和多损失函数融合策略，有效克服了当前HAR的挑战，并在实际应用中展现出优越的性能和部署潜力。

> **ai_Abstract:** 本文针对人体活动识别（HAR）中数据稀缺、特征提取不足和设备性能限制等挑战，提出了一种名为USAD的端到端模型。USAD通过无监督扩散模型进行数据增强，结合多分支时空交互网络捕获多尺度特征，并利用时空注意力机制和跨分支特征融合来增强特征表示。此外，自适应多损失函数融合策略进一步优化了模型。实验证明，USAD在多个公共数据集上取得了显著优于现有方法的准确率，并验证了其在嵌入式设备上的高效部署能力。

> **摘要翻译:** 人体活动识别（HAR）的主要目标是从传感器数据中推断正在进行的人体活动，这项任务在健康监测、安全保护和运动分析中有着广泛的应用。尽管研究不断增多，HAR仍面临关键挑战，包括稀有活动标注样本的稀缺、高级特征提取不足以及轻量级设备上模型性能不佳。为了解决这些问题，本文提出了一种以多注意力交互机制为核心的综合优化方法。首先，采用无监督、统计引导的扩散模型进行数据增强，从而缓解了标注数据稀缺和严重的类别不平衡问题。其次，设计了一个多分支时空交互网络，通过3x3、5x5和7x7卷积核的并行残差分支捕获序列数据的多尺度特征。同时，引入时间注意力机制以识别关键时间点，而空间注意力则增强了传感器间的交互。进一步引入了跨分支特征融合单元以提高整体特征表示能力。最后，集成了自适应多损失函数融合策略，允许动态调整损失权重并进行整体模型优化。在WISDM、PAMAP2和OPPORTUNITY三个公共数据集上的实验结果表明，所提出的无监督数据增强时空注意力扩散网络（USAD）分别实现了98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了所提出方法的效率和可行性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [155] [Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation](https://arxiv.org/abs/2403.06759)
> *平均校准误差：一种用于提高图像分割可靠性的可微损失函数*

*Theodore Barfoot, Luis Garcia-Peraza-Herrera, Ben Glocker, Tom Vercauteren* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 图像分割, 校准误差, 可微分损失, 深度学习, 医学图像

**Comment:** accidental replacement intended for arXiv:2506.03942

> **TL;DR:** 本文提出了一种可微分的mL1-ACE辅助损失函数，用于提高医学图像分割模型的像素级校准，同时保持分割质量，显著降低了校准误差。

**AI_Comments:** 这项工作通过提出一种直接可微的mL1-ACE损失函数，创新性地解决了深度学习模型在医学图像分割中常见的校准问题，尤其是在硬分箱下的可微分性是其亮点。引入数据集可靠性直方图也为校准评估提供了新工具。其重要性在于提高了模型的可靠性和临床可用性。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在医学图像分割中常产生过自信的结果，与实际观察不符，这种校准问题阻碍了其临床应用。

**Method:** 本文提出了一种新颖的辅助损失函数——边缘L1平均校准误差（mL1-ACE），用于改善像素级校准，同时不损害分割质量。该损失函数即使使用硬分箱也直接可微，从而避免了对近似可微替代或软分箱方法的需求。此外，工作还引入了数据集可靠性直方图的概念，用于在数据集层面更精细地评估语义分割中的校准。

**Result:** 使用mL1-ACE，在BraTS 2021数据集上，平均和最大校准误差分别降低了45%和55%，同时Dice分数保持在87%。

**Conclusion:** mL1-ACE作为一种可微分的辅助损失函数，能有效提高医学图像分割模型的像素级校准，显著降低校准误差，同时保持高分割质量，有助于模型的临床转化。

> **ai_Abstract:** 本文提出了一种名为边缘L1平均校准误差（mL1-ACE）的新型可微分辅助损失函数，旨在解决医学图像分割深度网络中常见的过自信和校准不良问题。该方法通过直接可微的硬分箱方式，有效改善了像素级校准，同时保持了分割性能。研究还引入了数据集可靠性直方图，用于更全面的校准评估。实验结果表明，mL1-ACE显著降低了校准误差，提升了模型可靠性。

> **摘要翻译:** 深度神经网络在医学图像分割中经常产生与经验观察不符的过自信结果。这种校准不良挑战了它们的临床转化。我们提出使用边缘L1平均校准误差（mL1-ACE）作为一种新型辅助损失函数，以在不损害分割质量的情况下改善像素级校准。我们表明，尽管使用硬分箱，这种损失函数是直接可微的，从而避免了对近似可微替代或软分箱方法的需求。我们的工作还引入了数据集可靠性直方图的概念，它推广了标准可靠性图，用于在数据集层面聚合的语义分割中进行更精细的校准视觉评估。使用mL1-ACE，我们将平均和最大校准误差分别降低了45%和55%，同时在BraTS 2021数据集上保持了87%的Dice分数。我们的代码在此分享：https://github.com/cai4cai/ACE-DLIRIS

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [160] [Learning to Generate Vectorized Maps at Intersections with Multiple Roadside Cameras](https://arxiv.org/abs/2507.02899)
> *利用多路边摄像头在交叉路口生成矢量化地图*

*Quanxin Zheng, Miao Fan, Shengtong Xu, Linghe Kong, Haoyi Xiong* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 矢量化地图, 路边摄像头, 交叉路口, 自动导航, 深度学习

**Comment:** Accepted by IROS'25

> **TL;DR:** MRC-VMap利用路边摄像头在交叉路口生成精确的矢量化地图，性能优于在线方法，并媲美基于激光雷达的方法。

**AI_Comments:** MRC-VMap的创新之处在于其端到端的视觉中心设计，利用现有路边摄像头，显著降低了成本和复杂性。它通过避免中间模块来减少计算开销和错误传播，并且多摄像头视图的利用有效解决了遮挡问题，提升了地图完整性。该方法在实际部署中具有很强的实用性和可扩展性，有望推动自动驾驶地图技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 矢量化地图对于自动驾驶车辆的精确导航和安全操作至关重要。传统地图构建方法存在弊端：离线技术依赖昂贵、劳动密集型的激光雷达数据和手动标注；在线方法虽然成本较低，但在复杂交叉路口性能有限。本研究旨在弥补这一差距。

**Method:** 本文引入了MRC-VMap，这是一种经济高效、以视觉为中心、端到端的神经网络。它利用现有的路边监控摄像头，直接将时间对齐的多向图像转换为高清矢量化地图表示。该集成解决方案减少了对额外中间模块（如特征提取和鸟瞰图（BEV）转换）的需求，从而降低了计算开销和错误传播。此外，使用多个摄像头视图增强了地图的完整性，减轻了遮挡，并提高了实际部署下的性能。

**Result:** 在中国四个主要大都市区的4000个交叉路口进行的广泛实验表明，MRC-VMap不仅优于最先进的在线方法，而且实现了与高成本基于激光雷达的方法相当的精度。

**Conclusion:** MRC-VMap为现代自动导航系统提供了一个可扩展且高效的解决方案。

> **ai_Abstract:** 该论文提出了一种名为MRC-VMap的端到端神经网络，旨在利用多路边摄像头直接在复杂交叉路口生成高精度矢量化地图。传统方法要么昂贵且耗时（离线激光雷达），要么性能有限（在线车载摄像头）。MRC-VMap通过直接将多向图像转换为地图表示，减少了中间模块的需求，提高了效率和鲁棒性。实验证明，MRC-VMap在性能上超越了现有在线方法，并达到了与高成本激光雷达方法相当的精度，为自动驾驶提供了一种可扩展且经济的地图解决方案。

> **摘要翻译:** 矢量化地图对于自动驾驶车辆的精确导航和安全操作至关重要。传统的地图构建方法分为两类：离线技术依赖昂贵、劳动密集型的激光雷达数据采集和手动标注；在线方法使用车载摄像头以降低成本，但在复杂交叉路口性能有限。为了弥补这一差距，我们引入了MRC-VMap，这是一种经济高效、以视觉为中心、端到端的神经网络，旨在直接在交叉路口生成高清矢量化地图。MRC-VMap利用现有的路边监控摄像头，直接将时间对齐的多向图像转换为矢量化地图表示。这种集成解决方案降低了对额外中间模块（如单独的特征提取和鸟瞰图（BEV）转换步骤）的需求，从而减少了计算开销和错误传播。此外，使用多个摄像头视图增强了地图的完整性，减轻了遮挡，并在实际部署限制下提供了强大的性能。在中国四个主要大都市区的4000个交叉路口进行的广泛实验表明，MRC-VMap不仅优于最先进的在线方法，而且实现了与高成本基于激光雷达的方法相当的精度，从而为现代自动导航系统提供了一个可扩展且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [165] [SurfDist: Interpretable Three-Dimensional Instance Segmentation Using Curved Surface Patches](https://arxiv.org/abs/2507.08223)
> *SurfDist：使用曲面片的可解释三维实例分割*

*Jackson Borchardt, Saul Kato* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 三维实例分割, 曲面片, 卷积神经网络, SurfDist, StarDist-3D

**Comment:** 8 pages, 6 figures

> **TL;DR:** SurfDist是一种新的卷积神经网络，用于三维体实例分割，它使用可解释的曲面片表示实例，解决了现有模型的问题，并在生物医学图像中对斑点状实例表现优于StarDist-3D。

**AI_Comments:** SurfDist的创新之处在于其将实例表示为可解释的曲面片，而非传统的体素网格，这不仅提高了分辨率，还避免了体素化伪影。这种方法在生物医学成像等领域具有重要意义，因为它能更精确地捕捉复杂形状的实例，并提供了更紧凑的参数化。与StarDist-3D的比较也突出了其在特定场景下的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的StarDist-3D模型在实例参数化维度和实例体素分辨率之间存在耦合，且可能引入体素化伪影。此外，对于生物医学成像中常见的斑点状实例，需要更紧凑的实例参数化。

**Method:** 本文提出了SurfDist，一种修改自StarDist-3D的卷积神经网络架构。SurfDist通过使用由平滑参数曲面片（特别是双三次贝塞尔三角形）组成的闭合曲面来表示实例，从而解耦了实例参数化维度和实例体素分辨率，并允许预测结果被上采样到任意高分辨率而不会引入体素化伪影。

**Result:** 对于生物医学成像中常见的斑点状实例数据集，SurfDist可以通过更紧凑的实例参数化优于StarDist-3D。在合成数据集和真实世界数据集上，SurfDist均表现出优于StarDist-3D的性能。

**Conclusion:** 可解释的实例曲面模型可以有效地与实例成员关系一起学习。

> **ai_Abstract:** 本文介绍了SurfDist，一种用于三维体实例分割的卷积神经网络。它通过使用由平滑参数曲面片表示的闭合曲面来预测实例，解决了StarDist-3D中实例参数化与体素分辨率耦合的问题，并允许高分辨率上采样而无伪影。SurfDist在生物医学图像的斑点状实例分割中表现优于StarDist-3D，证明了可解释曲面模型与实例成员关系协同学习的有效性。

> **摘要翻译:** 我们提出了SurfDist，一种用于三维体实例分割的卷积神经网络架构。SurfDist能够预测表示为由平滑参数曲面片（特别是双三次贝塞尔三角形）组成的闭合曲面的实例。SurfDist是流行模型架构StarDist-3D的修改版，它打破了StarDist-3D实例参数化维度与实例体素分辨率的耦合，并且其生成的预测结果可以被上采样到任意高分辨率而不会引入体素化伪影。对于生物医学成像中常见的斑点状实例数据集，SurfDist可以通过更紧凑的实例参数化优于StarDist-3D。我们详细介绍了SurfDist的技术实现，并展示了一个合成数据集和一个真实世界数据集，在这两个数据集上它都优于StarDist-3D。这些结果表明，可解释的实例曲面模型可以有效地与实例成员关系一起学习。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [166] [Unified People Tracking with Graph Neural Networks](https://arxiv.org/abs/2507.08494)
> *统一的图神经网络多人跟踪*

*Martin Engilberge, Ivan Vrkic, Friedrich Wilke Grosche, Julien Pilet, Engin Turetken, Pascal Fua* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多人跟踪, 图神经网络, 时空图, 遮挡处理, 新数据集

**Comment:** 

> **TL;DR:** 提出了一种基于图神经网络的统一、可微分的多人跟踪模型，无需预计算轨迹，并在新数据集和公共基准上实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一种无需预计算轨迹段的统一可微分多人跟踪模型，并利用图神经网络有效整合时空信息和场景信息来处理遮挡。同时，发布新的大规模数据集对该领域的研究具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有多人跟踪模型依赖预计算轨迹，限制了性能。本文旨在提供一个无需此步骤的统一模型，并改善遮挡处理。

**Method:** 提出一个统一、完全可微分的模型，通过构建动态时空图来关联检测结果为轨迹。该图聚合空间、上下文和时间信息，并可编码场景特定信息以改善遮挡处理。同时引入了一个包含25个部分重叠视图、详细场景重建和大量遮挡的大规模新数据集。

**Result:** 模型在公共基准和新数据集上均实现了最先进的性能，并展现了在不同条件下的灵活性。

**Conclusion:** 该模型和新数据集将公开，以推动多人跟踪领域的研究。

> **ai_Abstract:** 本文提出一种基于图神经网络的统一、完全可微分的多人跟踪模型，能够直接将检测结果关联成轨迹，无需预先计算轨迹段。该模型构建动态时空图以整合多维度信息，并能编码场景信息以应对遮挡。研究还引入了一个大规模新数据集。实验证明，该模型在多个基准上达到最先进水平，展现了其在复杂环境下的有效性和通用性。

> **摘要翻译:** 这项工作提出了一种统一的、完全可微分的多人跟踪模型，该模型学习将检测结果关联成轨迹，而无需依赖预先计算的轨迹段。该模型构建了一个动态时空图，聚合空间、上下文和时间信息，从而实现整个序列的无缝信息传播。为了改善遮挡处理，该图还可以编码场景特定信息。我们还引入了一个新的大规模数据集，包含25个部分重叠的视图、详细的场景重建和大量的遮挡。实验表明，该模型在公共基准和新数据集上都取得了最先进的性能，并在各种条件下表现出灵活性。数据集和方法都将公开发布，以推动多人跟踪领域的研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [169] [NeuralOS: Towards Simulating Operating Systems via Neural Generative Models](https://arxiv.org/abs/2507.08800)
> *神经网络操作系统：迈向通过神经生成模型模拟操作系统*

*Luke Rivard, Sun Sun, Hongyu Guo, Wenhu Chen, Yuntian Deng* | **Category: cs.CV, cs.AI, cs.CL, cs.HC, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 操作系统模拟, 神经生成模型, 图形用户界面, 循环神经网络, 扩散模型

**Comment:** 

> **TL;DR:** NeuralOS是一个神经框架，通过预测屏幕帧来模拟操作系统的GUI，对用户输入（鼠标、键盘）做出响应，并能渲染逼真的GUI序列和预测状态转换。

**AI_Comments:** NeuralOS通过结合RNN和扩散模型来模拟操作系统GUI，展现了在生成式AI模拟复杂系统方面的潜力。其创新之处在于直接预测屏幕帧以响应用户输入，这为更自然、自适应的人机交互提供了新的途径。然而，其在处理细粒度键盘交互上的局限性表明，在实现完全真实的操作系统模拟方面仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 旨在创建一个能够模拟操作系统图形用户界面并响应用户输入的神经框架，以实现未来人机交互系统的完全自适应、生成式神经界面。

**Method:** NeuralOS结合了跟踪计算机状态的循环神经网络（RNN）和生成屏幕图像的基于扩散的神经渲染器。它在一个包含随机生成和AI代理生成的Ubuntu XFCE录制的大规模数据集上进行训练。

**Result:** NeuralOS成功渲染了逼真的GUI序列，准确捕捉了鼠标交互，并可靠地预测了应用程序启动等状态转换。

**Conclusion:** 尽管精确建模细粒度键盘交互仍具挑战性，但NeuralOS是创建未来人机交互系统完全自适应、生成式神经界面的重要一步。

> **ai_Abstract:** NeuralOS是一个新颖的神经框架，旨在通过预测屏幕帧来模拟操作系统的图形用户界面（GUI），以响应用户输入。它结合了循环神经网络（RNN）和扩散模型，并在大规模Ubuntu XFCE数据集上进行训练。该模型能够生成逼真的GUI序列，准确处理鼠标交互并预测状态转换，为未来自适应人机交互系统奠定基础，尽管在处理精细键盘交互方面仍面临挑战。

> **摘要翻译:** 我们引入了NeuralOS，这是一个神经框架，通过直接预测屏幕帧来响应鼠标移动、点击和键盘事件等用户输入，从而模拟操作系统的图形用户界面（GUI）。NeuralOS结合了跟踪计算机状态的循环神经网络（RNN）和生成屏幕图像的基于扩散的神经渲染器。该模型在一个包含随机生成交互和AI代理生成的真实交互的大规模Ubuntu XFCE录制数据集上进行训练。实验表明，NeuralOS成功渲染了逼真的GUI序列，准确捕捉了鼠标交互，并可靠地预测了应用程序启动等状态转换。尽管精确建模细粒度键盘交互仍然具有挑战性，但NeuralOS为未来人机交互系统创建完全自适应、生成式神经界面迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [175] [Curriculum Dataset Distillation](https://arxiv.org/abs/2405.09150)
> *课程数据集蒸馏*

*Zhiheng Ma, Anjia Cao, Funing Yang, Yihong Gong, Xing Wei* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 数据集蒸馏, 课程学习, 大规模数据集, 对抗优化, 泛化能力

**Comment:** 

> **TL;DR:** 提出了一种课程学习驱动的数据集蒸馏框架，通过从简单到复杂的蒸馏策略和对抗优化，显著提高了大规模数据集蒸馏的性能和泛化能力。

**AI_Comments:** 这项工作通过引入课程学习和对抗优化，有效地解决了大规模数据集蒸馏的现有挑战，特别是提高了蒸馏图像的质量、代表性和泛化能力。其创新点在于将课程学习的思想融入到数据集蒸馏过程中，并结合对抗性训练，这为未来数据集蒸馏方法的设计提供了新的思路，并显著推动了该领域在处理大型数据集方面的进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据集蒸馏方法难以处理大规模数据集，存在计算和内存开销大、性能瓶颈以及生成图像同质化、过于简单的问题。

**Method:** 本文提出一种基于课程学习的数据集蒸馏框架（CUDD），旨在协调性能和可扩展性。该框架策略性地遵循从简单到复杂的课程来蒸馏合成图像，并通过引入课程评估来解决先前方法生成图像同质化和过于简单的问题。此外，引入对抗优化来进一步提高合成图像的代表性，并防止它们对神经网络过拟合，从而增强蒸馏图像在不同神经网络架构上的泛化能力和对噪声的鲁棒性。

**Result:** 实验表明，该框架在大规模数据集蒸馏中树立了新基准，在Tiny-ImageNet上实现了11.1%的显著提升，在ImageNet-1K上实现了9.0%的提升，在ImageNet-21K上实现了7.3%的提升。

**Conclusion:** 该框架通过结合课程学习和对抗优化，有效解决了大规模数据集蒸馏的挑战，显著提升了蒸馏性能、泛化能力和鲁棒性，并为该领域树立了新的基准。

> **ai_Abstract:** 本文提出“课程数据集蒸馏”（CUDD）框架，旨在解决大规模数据集蒸馏中的性能和可扩展性问题。该框架通过遵循从简单到复杂的课程策略蒸馏合成图像，并结合课程评估来解决传统方法生成图像同质化的问题。此外，引入对抗优化以提升合成图像的代表性并防止过拟合，从而增强泛化能力和鲁棒性。实验证明，CUDD在大规模数据集上实现了显著的性能提升，例如在Tiny-ImageNet、ImageNet-1K和ImageNet-21K上分别提升了11.1%、9.0%和7.3%。

> **摘要翻译:** 大多数数据集蒸馏方法由于其巨大的计算和内存需求而难以适应大规模数据集。最近的研究已经开始探索可扩展的解耦方法。然而，该方向仍然存在性能瓶颈和优化空间。在本文中，我们提出了一种基于课程学习的数据集蒸馏框架，旨在协调性能和可扩展性。该框架策略性地蒸馏合成图像，遵循从简单到复杂的课程。通过引入课程评估，我们解决了以前方法生成图像趋于同质化和过于简单的问题，并以可控的计算成本实现。此外，我们引入了针对合成图像的对抗优化，以进一步提高其代表性并防止它们对蒸馏过程中涉及的神经网络过拟合。这增强了蒸馏图像在各种神经网络架构上的泛化能力，也增加了它们对噪声的鲁棒性。大量的实验表明，我们的框架在大规模数据集蒸馏中树立了新的基准，在Tiny-ImageNet上取得了11.1%的显著改进，在ImageNet-1K上取得了9.0%的改进，在ImageNet-21K上取得了7.3%的改进。我们的蒸馏数据集和代码可在https://github.com/MIV-XJTU/CUDD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [182] [RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features](https://arxiv.org/abs/2507.08546)
> *RadiomicsRetrieval：一个基于影像组学特征的可定制医学图像检索框架*

*Inye Na, Nejung Rue, Jiwon Chung, Hyunjin Park* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 医学图像检索, 影像组学, 深度学习, 3D图像, 内容检索

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** 提出了一个名为 RadiomicsRetrieval 的3D医学图像检索框架，结合了影像组学特征和深度学习嵌入，支持灵活的查询，仅需少量用户提示，并在肺部CT和脑部MRI数据上表现良好。

**AI_Comments:** RadiomicsRetrieval的创新之处在于其3D内容检索能力，结合了传统影像组学特征和深度学习嵌入，并通过解剖位置嵌入提供了更全面的上下文信息。其仅需少量用户提示的特点显著降低了临床使用门槛，增强了实用性。该框架在提高检索特异性和支持灵活查询方面具有重要意义，有望推动医学图像检索在实际临床和研究中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学图像检索方法主要支持2D图像，且需要完全标注的查询，这限制了临床应用的灵活性。

**Method:** 提出RadiomicsRetrieval框架，这是一个3D内容检索系统，将手工提取的影像组学描述符与肿瘤级别的深度学习嵌入相结合。该框架利用可提示分割模型（如SAM）获取肿瘤特异性图像嵌入，并通过对比学习将其与影像组学特征对齐。此外，通过解剖位置嵌入（APE）进一步丰富了这些表示。系统支持基于形状、位置或部分特征集的灵活查询，且仅需最少的用户提示（如一个点）。

**Result:** 在肺部CT和脑部MRI公共数据集上的大量实验表明，影像组学特征显著增强了检索特异性，而解剖位置嵌入（APE）为基于位置的搜索提供了重要的全局解剖上下文。该框架仅需最少的用户提示，并支持使用图像嵌入或选定影像组学属性进行查询。

**Conclusion:** RadiomicsRetrieval框架具有高度适应性，能够支持灵活的查询，并通过结合影像组学特征和解剖位置嵌入显著提高检索性能，有望造福于诊断、治疗计划和大规模医学影像库研究。

> **ai_Abstract:** 本文提出了RadiomicsRetrieval，一个创新的3D医学图像内容检索框架，旨在克服现有2D方法在临床灵活性和标注需求上的限制。该框架通过结合影像组学特征与深度学习嵌入，并利用解剖位置嵌入（APE）来丰富图像表示，实现了对体积数据的充分利用。RadiomicsRetrieval支持基于形状、位置或部分特征集的灵活查询，且仅需少量用户提示。实验证明，影像组学特征能提升检索特异性，APE能提供关键的解剖上下文，这使得该框架在诊断、治疗规划和医学研究中具有巨大潜力。

> **摘要翻译:** 医学图像检索是支持临床决策的宝贵领域，但现有方法主要支持2D图像并需要完全标注的查询，这限制了临床灵活性。为了解决这个问题，我们提出了RadiomicsRetrieval，一个3D内容检索框架，它将手工制作的影像组学描述符与肿瘤级别的深度学习嵌入相结合。与现有的2D方法不同，RadiomicsRetrieval充分利用体数据，以利用医学图像中更丰富的空间上下文。我们采用可提示分割模型（例如SAM）来获取肿瘤特异性图像嵌入，这些嵌入通过对比学习与从相同肿瘤中提取的影像组学特征对齐。这些表示通过解剖位置嵌入（APE）进一步丰富。因此，RadiomicsRetrieval支持基于形状、位置或部分特征集的灵活查询。在肺部CT和脑部MRI公共数据集上的大量实验表明，影像组学特征显著增强了检索特异性，而APE提供了基于位置搜索必不可少的全局解剖上下文。值得注意的是，我们的框架仅需要最少的用户提示（例如，一个单点），最大限度地减少了分割开销并支持多样化的临床场景。使用图像嵌入或选定的影像组学属性进行查询的能力突出了其适应性，可能有利于诊断、治疗计划和大规模医学影像库的研究。我们的代码可在https://github.com/nainye/RadiomicsRetrieval获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [188] [Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study](https://arxiv.org/abs/2507.05730)
> *高光谱异常检测方法：一项调查与比较研究*

*Aayushma Pant, Arbind Agrahari Baniya, Tsz-Kwan Lee, Sunil Aryal* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 高光谱异常检测, 深度学习, 统计模型, 比较研究, 异常检测

**Comment:** 

> **TL;DR:** 本文对高光谱异常检测（HAD）方法进行了全面调查和比较，评估了统计模型、基于表示的方法、经典机器学习和深度学习模型，发现深度学习模型精度最高，统计模型速度最快。

**AI_Comments:** 本文对高光谱异常检测领域进行了全面的综述和比较，系统地分类并评估了不同类型的方法，为该领域的研究人员提供了宝贵的参考。其创新之处在于对多种方法的量化比较，并明确指出了深度学习和统计模型各自的优势，对于指导未来方法选择和改进具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管高光谱异常检测技术发展迅速，但现有方法仍面临计算复杂度高、对噪声敏感以及在不同数据集上泛化能力有限等挑战。

**Method:** 本研究对各种高光谱异常检测技术进行了全面比较，将其分为统计模型、基于表示的方法、经典机器学习方法和深度学习模型。研究人员在17个基准数据集上使用ROC、AUC和可分离性图等性能指标对这些方法进行了评估，分析了它们的检测精度、计算效率、优缺点以及未来的研究方向。

**Result:** 结果显示，深度学习模型实现了最高的检测精度，而统计模型在所有数据集上都表现出卓越的速度。

**Conclusion:** 本调查旨在为从事高光谱异常检测方法研究的科研人员和从业者提供有价值的见解，以推动该领域的发展。

> **ai_Abstract:** 本文对高光谱异常检测（HAD）方法进行了全面的调查和比较研究。针对现有HAD方法面临的计算复杂性高、对噪声敏感和泛化能力有限等挑战，研究人员将HAD技术分为统计模型、基于表示的方法、经典机器学习和深度学习模型。通过在17个基准数据集上进行评估，研究发现深度学习模型在检测精度上表现最佳，而统计模型在计算速度上具有显著优势。本研究旨在为高光谱异常检测领域的研究和实践提供指导。

> **摘要翻译:** 高光谱图像是包含数百个连续光谱波段的高维数据集，能够对材料和表面进行详细分析。高光谱异常检测（HAD）是指在没有关于高光谱场景或目标光谱的先验信息的情况下，识别和定位此类数据中异常目标的技术。这项技术近年来发展迅速，在农业、国防、军事侦察和环境监测等领域都有应用。尽管取得了显著进展，但现有的HAD方法仍然面临计算复杂度高、对噪声敏感以及在不同数据集上泛化能力有限等挑战。本研究对各种HAD技术进行了全面比较，将其分为统计模型、基于表示的方法、经典机器学习方法和深度学习模型。我们使用ROC、AUC和可分离性图等不同的性能指标，在17个基准数据集上评估了这些方法，分析了它们的检测精度、计算效率、优缺点以及未来的研究方向。我们的研究结果表明，深度学习模型实现了最高的检测精度，而统计模型在所有数据集上都表现出卓越的速度。本调查旨在为致力于推动高光谱异常检测方法领域发展的研究人员和从业者提供有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [190] [Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification](https://arxiv.org/abs/2507.08520)
> *遮挡引导的特征净化学习结合强化知识蒸馏用于遮挡行人再识别*

*Yufei Zheng, Wenjun Wang, Wenjun Gan, Jiawei Liu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 遮挡行人再识别, 知识蒸馏, 特征净化, 深度强化学习, 视觉Transformer

**Comment:** 13 pages, 8 figures

> **TL;DR:** 本文提出OGFR框架，通过强化知识蒸馏和特征净化，解决遮挡行人再识别中多样化遮挡和特征污染问题。

**AI_Comments:** 本文的创新点在于提出了一个结合强化知识蒸馏和特征净化的统一框架来解决遮挡行人再识别的两个核心挑战：多样化遮挡和特征污染。特别是，引入深度强化学习来净化整体图像特征（识别并替换低质量补丁token）是一个新颖且有潜力的方向，能够有效提高特征的纯净度和判别力。同时，遮挡感知视觉Transformer的设计也增强了模型对不同遮挡类型的鲁棒性。该方法为处理复杂遮挡情况下的行人再识别提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有遮挡行人再识别方法在处理训练中未见的多样化遮挡场景时面临挑战，并且存在来自整体图像的特征污染问题。

**Method:** 本文提出“遮挡引导的特征净化学习结合强化知识蒸馏 (OGFR)”框架。OGFR采用教师-学生蒸馏架构，通过强化知识蒸馏将纯化的判别性整体知识从整体分支传输到遮挡分支，同时将多样化的遮挡模式融入特征表示。具体来说，设计了一个遮挡感知视觉Transformer来利用可学习的遮挡模式嵌入来明确建模多样化遮挡类型，从而引导遮挡感知的鲁棒特征表示。此外，在整体分支中设计了一个特征擦除和净化模块，其中代理通过深度强化学习识别并替换包含噪声负信息的整体图像的低质量补丁token，以避免特征污染并进一步挖掘身份相关的判别线索。

**Result:** Not mentioned in abstract

**Conclusion:** OGFR框架通过其教师-学生蒸蒸馏架构、遮挡感知视觉Transformer和特征擦除与净化模块，能够有效缓解多样化遮挡场景和特征污染问题，使学生分支能够准确学习鲁棒表示，而不受遮挡干扰。

> **ai_Abstract:** 本文提出了一种名为OGFR（Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation）的新框架，用于解决遮挡行人再识别中多样化遮挡场景和特征污染的挑战。OGFR采用教师-学生蒸馏架构，其中教师分支通过一个特征擦除和净化模块利用深度强化学习净化整体图像特征，避免污染；学生分支（遮挡感知视觉Transformer）则通过强化知识蒸馏学习建模多样化遮挡模式并吸收纯化后的判别性知识，从而实现鲁棒的行人再识别。

> **摘要翻译:** 遮挡行人再识别旨在根据遮挡图像检索整体图像。现有方法通常依赖于对齐可见身体部位、应用遮挡增强或使用整体图像补充缺失语义。然而，它们在处理训练中未见的多样化遮挡场景以及来自整体图像的特征污染问题上面临挑战。为了解决这些限制，我们提出了遮挡引导的特征净化学习结合强化知识蒸馏 (OGFR)，它同时缓解了这些挑战。OGFR采用教师-学生蒸馏架构，在将纯化的判别性整体知识通过强化知识蒸馏从整体分支传输到遮挡分支的同时，有效地将多样化的遮挡模式融入特征表示。具体来说，设计了一个遮挡感知视觉Transformer来利用可学习的遮挡模式嵌入来明确建模多样化遮挡类型，从而引导遮挡感知的鲁棒特征表示。此外，我们在整体分支中设计了一个特征擦除和净化模块，其中代理通过深度强化学习识别并替换包含噪声负信息的整体图像的低质量补丁token，并用可学习的嵌入token代替这些补丁token，以避免特征污染并进一步挖掘身份相关的判别线索。之后，在知识蒸馏的帮助下，学生分支有效地吸收了纯化的整体知识，从而无论遮挡的干扰如何，都能精确学习鲁棒表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [191] [Amortized Posterior Sampling with Diffusion Prior Distillation](https://arxiv.org/abs/2407.17907)
> *摊销后验采样与扩散先验蒸馏*

*Abbas Mammadov, Hyungjin Chung, Jong Chul Ye* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 后验采样, 变分推断, 扩散模型, 逆问题, 计算效率

**Comment:** 

> **TL;DR:** 本文提出了一种名为摊销后验采样（APS）的新型变分推断方法，用于高效解决逆问题中的后验采样，该方法通过训练条件流模型，实现了快速、多样化且泛化能力强的采样，且无需配对训练数据，在计算效率上显著优于现有方法。

**AI_Comments:** 本文提出了一种创新的、无监督的后验采样方法APS，其核心在于结合了条件流模型和扩散模型隐式定义的后验分布。其最大的创新点在于实现了高效的“摊销”采样，即通过单次网络评估即可生成多样化样本，显著提升了计算效率。同时，无需配对训练数据和对非欧几里得域的适用性也大大拓展了其应用范围，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有逆问题中的后验采样方法效率不高，且可能需要配对训练数据。本文的动机是开发一种高效、无监督且能泛化到多种测量和领域（包括欧几里得和非欧几里得）的后验采样方法。

**Method:** 本文提出了摊销后验采样（APS）方法，这是一种新颖的变分推断方法。它通过训练一个条件流模型来最小化变分分布与扩散模型隐式定义的后验分布之间的散度。这种方法无需配对训练数据，是无监督的，并且适用于欧几里得和非欧几里得域。

**Result:** APS方法能够通过单次神经网络函数评估生成多样化的后验样本，泛化到各种测量。它在计算效率上显著优于现有方法，同时保持了有竞争力的重建质量。该方法在图像恢复、流形信号重建和气候数据插补等任务上表现出有效性。

**Conclusion:** Amortized Posterior Sampling (APS) 提供了一种计算效率高、无监督且泛化能力强的解决方案，能够实时、高质量地解决各种领域中的逆问题，显著优于现有方法。

> **ai_Abstract:** 本文提出了一种名为摊销后验采样（APS）的新型变分推断方法，旨在高效解决逆问题中的后验采样。APS通过训练一个条件流模型来隐式匹配扩散模型定义的后验分布，从而实现单次神经网络评估即可生成多样化样本。该方法是无监督的，无需配对数据，且适用于欧几里得和非欧几里得域。实验证明，APS在计算效率上显著优于现有技术，同时保持了良好的重建质量，为图像恢复、信号重建和数据插补等任务提供了实时、高质量的解决方案。

> **摘要翻译:** 我们提出了摊销后验采样（APS），这是一种新颖的变分推断方法，用于逆问题中高效的后验采样。我们的方法训练一个条件流模型，以最小化变分分布与扩散模型隐式定义的后验分布之间的散度。这产生了一个强大的、摊销的采样器，能够通过单次神经网络函数评估生成多样化的后验样本，泛化到各种测量。与现有方法不同，我们的方法是无监督的，不需要配对训练数据，并且适用于欧几里得和非欧几里得域。我们在图像恢复、流形信号重建和气候数据插补等一系列任务上展示了其有效性。APS在计算效率上显著优于现有方法，同时保持了有竞争力的重建质量，从而实现了跨不同领域的逆问题的实时、高质量解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [199] [Car Object Counting and Position Estimation via Extension of the CLIP-EBC Framework](https://arxiv.org/abs/2507.08240)
> *汽车目标计数和位置估计：CLIP-EBC框架的扩展*

*Seoik Jung, Taekyung Song* | **Category: cs.CV, I.4.8; I.2.10** | **Updated: 2025-07-11**

**Keywords:** 汽车计数, 位置估计, CLIP-EBC, K-means聚类, CARPK数据集

**Comment:** 4 pages, 2 figures, submitted to a computer vision conference

> **TL;DR:** 本文将CLIP-EBC框架扩展应用于汽车计数和位置估计，在CARPK数据集上取得了次优性能，并提出了基于K-means加权聚类的方法。

**AI_Comments:** 该研究的创新点在于将一个成熟的框架（CLIP-EBC）从人群计数领域迁移到汽车计数领域，并取得了有竞争力的结果。同时，通过引入K-means加权聚类方法，进一步扩展了该框架的功能，使其能够进行目标位置估计，这对于智能交通、自动驾驶等领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探究原用于人群计数的CLIP-EBC框架在汽车目标计数上的适用性。

**Method:** 将CLIP-EBC框架应用于CARPK数据集进行汽车目标计数，并提出了一种基于预测密度图的K-means加权聚类方法来估计目标位置。

**Result:** 该模型在汽车目标计数方面取得了现有方法中的次优性能。

**Conclusion:** CLIP-EBC框架具有扩展到定位任务的潜力。

> **ai_Abstract:** 本文探讨了将原用于人群计数的CLIP-EBC框架应用于汽车目标计数的可能性，并在CARPK数据集上取得了次优性能。此外，研究还提出了一种K-means加权聚类方法，用于基于预测密度图估计目标位置，展示了该框架在定位任务上的扩展潜力。

> **摘要翻译:** 在本文中，我们研究了CLIP-EBC框架（最初设计用于人群计数）通过使用CARPK数据集在汽车目标计数上的适用性。实验结果表明，与现有方法相比，我们的模型取得了次优性能。此外，我们提出了一种K-means加权聚类方法，根据预测的密度图估计目标位置，这表明该框架有潜力扩展到定位任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [213] [SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2](https://arxiv.org/abs/2507.08548)
> *SAM2RL：迈向Segment Anything Model 2中的强化学习记忆控制*

*Alen Adamyan, Tomáš Čížek, Matej Straka, Klara Janouskova, Martin Schmid* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 强化学习, 记忆控制, Segment Anything Model 2, 视觉目标跟踪

**Comment:** 

> **TL;DR:** 提出SAM2RL，利用强化学习优化SAM 2的记忆更新，在视觉目标跟踪中显著优于现有启发式方法。

**AI_Comments:** 这篇论文的创新点在于将强化学习引入到SAM 2的记忆控制中，将记忆更新视为一个顺序决策问题，这与传统的依赖手工设计规则的方法有根本性的不同。其显著的性能提升表明强化学习在处理复杂时序数据中的记忆管理方面具有巨大潜力，为视觉目标跟踪领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** Segment Anything Model 2 (SAM 2) 在视觉目标跟踪中表现出色，但现有方法通过手工设计的更新规则来增强其记忆库以处理干扰、遮挡和运动。本文旨在通过强化学习提供一种根本不同且更优的记忆控制方法。

**Method:** 提出SAM2RL，通过将SAM 2的记忆控制框架化为顺序决策问题，并使用强化学习来优化记忆更新。该方法在每个视频单独设置代理的过拟合设置中进行验证。

**Result:** 在过拟合设置中，SAM2RL相对于SAM 2的改进是现有启发式方法增益的三倍多。

**Conclusion:** 研究结果揭示了记忆库的未开发潜力，并强调强化学习是视觉目标跟踪中记忆控制手工更新规则的强大替代方案。

> **ai_Abstract:** 本文提出了SAM2RL，一种利用强化学习来优化Segment Anything Model 2 (SAM 2) 中记忆更新的新方法。针对SAM 2在视觉目标跟踪中处理干扰、遮挡和运动时依赖手工设计记忆更新规则的局限性，SAM2RL将记忆控制建模为顺序决策问题。实验结果表明，在过拟合设置下，SAM2RL相对于SAM 2的改进显著超过现有启发式方法的增益三倍以上，突显了强化学习在视觉目标跟踪记忆控制中的巨大潜力。

> **摘要翻译:** Segment Anything Model 2 (SAM 2) 在目标分割任务中表现出强大的性能，并已成为视觉目标跟踪的最新技术。该模型将来自先前帧的信息存储在记忆库中，从而实现视频序列中的时间一致性。最近的方法通过手工设计的更新规则来增强SAM 2，以更好地处理干扰物、遮挡和物体运动。我们提出了一种根本不同的方法，通过将记忆控制框架化为顺序决策问题，使用强化学习来优化SAM 2中的记忆更新。在每个视频单独设置代理的过拟合设置中，我们的方法相对于SAM 2的相对改进超过现有启发式方法增益的三倍。这些结果揭示了记忆库的未开发潜力，并强调强化学习是视觉目标跟踪中记忆控制手工更新规则的强大替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [214] [GeoSplatting: Towards Geometry Guided Gaussian Splatting for Physically-based Inverse Rendering](https://arxiv.org/abs/2410.24204)
> *GeoSplatting：迈向几何引导的高斯泼溅用于基于物理的逆向渲染*

*Kai Ye, Chong Gao, Guanbin Li, Wenzheng Chen, Baoquan Chen* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D Gaussian Splatting, 逆向渲染, 几何引导, 光传输, 材料分解

**Comment:** ICCV 2025

> **TL;DR:** GeoSplatting通过引入显式几何引导（可优化网格）来改进3D Gaussian Splatting的逆向渲染，解决了现有方法中法线估计不准确导致的光传输模型问题，实现了更精确的材料分解和卓越的渲染性能。

**AI_Comments:** GeoSplatting的创新之处在于将显式几何（可优化网格）引入到3DGS的逆向渲染框架中，解决了现有方法中隐式几何约束导致的法线估计不准确问题。通过利用网格的精确法线和光线追踪，显著提升了光传输建模的精度，从而实现了更准确的材料分解和高质量的重照明。这对于3DGS在更广泛的PBR应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3DGS方法在进行材料-光照解耦时，难以精确建模光传输，因为它们通常依赖不准确的高斯点法线估计，导致材料分解噪声大和重照明效果差。

**Method:** 提出GeoSplatting，通过可微分地从可优化网格构建表面接地3DGS。该方法利用定义良好的网格法线和不透明网格表面，并结合基于网格的光线追踪技术进行高效、遮挡感知的光传输计算，从而提供显式几何引导。

**Result:** GeoSplatting实现了精确的材料分解，同时保留了3DGS的效率和高质量渲染能力。在多样化数据集上的综合评估表明，它具有卓越的效率和最先进的逆向渲染性能。

**Conclusion:** GeoSplatting通过显式几何引导显著提升了3DGS在基于物理的逆向渲染中的光传输建模精度，解决了现有方法的局限性，并取得了卓越的性能。

> **ai_Abstract:** 本文提出了GeoSplatting，一种新的方法，通过显式几何引导增强3D Gaussian Splatting（3DGS）以实现精确的基于物理的逆向渲染。针对现有3DGS在材料-光照解耦中因不准确法线估计导致光传输建模不佳的问题，GeoSplatting通过从可优化网格构建表面接地3DGS，利用精确的网格法线和基于网格的光线追踪技术，确保了精确的材料分解。实验证明GeoSplatting在效率和逆向渲染性能方面均达到最先进水平。

> **摘要翻译:** 近期3D高斯泼溅（3DGS）表示在新颖视图合成方面展现出卓越性能；此外，3DGS上的材质-光照解耦保证了重照明能力及其对更广泛应用的适应性。虽然后者操作的通用方法在于整合可微分的基于物理的渲染（PBR）技术以共同恢复BRDF材质和环境光照，但由于准确建模光传输的挑战，实现精确解耦仍然是一项固有的困难任务。现有方法通常近似高斯点的法线，这构成了一个隐式几何约束。然而，它们通常存在法线估计不准确的问题，这随后会降低光传输质量，导致嘈杂的材质分解和有缺陷的重照明结果。为了解决这个问题，我们提出了GeoSplatting，一种新颖的方法，通过显式几何引导增强3DGS，以实现精确的光传输建模。通过从可优化网格可微分地构建表面接地3DGS，我们的方法利用了定义良好的网格法线和不透明网格表面，并额外促进了基于网格的光线追踪技术的使用，以进行高效、遮挡感知的光传输计算。这种增强确保了精确的材质分解，同时保留了3DGS的效率和高质量渲染能力。在多样化数据集上的综合评估证明了GeoSplatting的有效性，突出了其卓越的效率和最先进的逆向渲染性能。项目页面可在https://pku-vcl-geometry.github.io/GeoSplatting/找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [217] [Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models](https://arxiv.org/abs/2507.07104)
> *视觉-语言-视觉自编码器：来自扩散模型的可扩展知识蒸馏*

*Tiezheng Zhang, Yitong Li, Yu-cheng Chou, Jieneng Chen, Alan Yuille, Chen Wei, Junfei Xiao* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 视觉-语言模型, 知识蒸馏, 扩散模型, 图像描述, 自编码器

**Comment:** Project Page: https://lambert-x.github.io/Vision-Language-Vision/

> **TL;DR:** 本文提出视觉-语言-视觉（VLV）自编码器框架，通过利用预训练模型和单模态图像，以极低的成本和数据需求从文本条件扩散模型中蒸馏知识，构建出与GPT-4o和Gemini 2.0 Flash媲美的图像描述器。

**AI_Comments:** 该研究的创新点在于提出了VLV自编码器框架，巧妙地利用了现有的预训练模型（视觉编码器、T2I扩散解码器、LLM）进行知识蒸馏，从而极大地降低了训练SOTA图像描述器的成本和数据需求。通过将训练开销控制在1000美元以下，并主要依赖单模态图像，该方法为资源受限的研究者和开发者提供了一条构建高性能视觉-语言模型的有效途径，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 构建最先进的视觉-语言模型（VLMs）需要数十亿高质量图文对和数百万GPU小时的训练，成本高昂且数据需求巨大。本文旨在解决这一挑战，以更低的成本和数据需求构建高性能的图像描述器。

**Method:** 本文引入视觉-语言-视觉（VLV）自编码器框架，利用预训练的视觉编码器、文本到图像（T2I）扩散模型的解码器和大型语言模型（LLM）。通过冻结预训练的T2I扩散解码器来正则化语言表示空间，建立信息瓶颈，并使用连续嵌入从文本条件扩散模型中蒸馏知识。接着，微调预训练的LLM将中间语言表示解码为详细描述。该方法主要利用单模态图像进行训练，最大化现有预训练模型的效用。

**Result:** VLV管道通过高质量重建展示了全面的语义理解。该方法构建了一个与GPT-4o和Gemini 2.0 Flash等领先模型媲美的最新（SoTA）图像描述器。它展示了卓越的成本效益，显著减少了数据需求，避免了对大量配对图像-文本数据集的需求，并将总训练开销控制在1000美元以下。

**Conclusion:** 本文提出的VLV框架通过战略性地利用现有预训练模型和主要使用单模态图像进行训练，成功地以极低的成本和数据需求实现了从文本条件扩散模型中蒸馏知识，从而构建了高性能的图像描述器。

> **ai_Abstract:** 本文提出视觉-语言-视觉（VLV）自编码器框架，旨在以低成本和低数据需求构建高性能图像描述器。该框架通过整合预训练的视觉编码器、T2I扩散模型解码器和大型语言模型，并利用冻结的T2I解码器进行语言表示空间正则化，从而有效地从文本条件扩散模型中蒸馏知识。VLV方法主要使用单模态图像进行训练，显著降低了对大规模图文配对数据集的依赖，实现了与GPT-4o和Gemini 2.0 Flash等模型相当的图像描述能力，且总训练成本低于1000美元。

> **摘要翻译:** 构建具有强大图像描述能力的最新视觉-语言模型（VLMs）通常需要对数十亿高质量图像-文本对进行训练，这需要数百万GPU小时。本文介绍了视觉-语言-视觉（VLV）自编码器框架，该框架战略性地利用了关键的预训练组件：一个视觉编码器、一个文本到图像（T2I）扩散模型的解码器，以及随后的一个大型语言模型（LLM）。具体来说，我们通过冻结预训练的T2I扩散解码器来正则化语言表示空间，从而建立一个信息瓶颈。我们的VLV管道使用连续嵌入有效地从文本条件扩散模型中蒸馏知识，通过高质量的重建展示了全面的语义理解。此外，通过微调一个预训练的LLM将中间语言表示解码为详细描述，我们构建了一个与GPT-4o和Gemini 2.0 Flash等领先模型媲美的最新（SoTA）图像描述器。我们的方法展示了卓越的成本效益并显著减少了数据需求；通过主要利用单模态图像进行训练并最大化现有预训练模型（图像编码器、T2I扩散模型和LLM）的效用，它避免了对大量配对图像-文本数据集的需求，将总训练开销保持在1000美元以下。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [228] [Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion](https://arxiv.org/abs/2507.08163)
> *自适应扩散去噪平滑：通过随机平滑与差分隐私引导去噪扩散实现认证鲁棒性*

*Frederick Shpilevskiy, Saiyue Lyu, Krishnamurthy Dj Dvijotham, Mathias Lécuyer, Pierre-André Noël* | **Category: cs.CV, cs.CR, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 对抗鲁棒性, 随机平滑, 差分隐私, 去噪扩散, 认证准确率

**Comment:** 

> **TL;DR:** 提出了一种名为自适应扩散去噪平滑的新方法，通过将引导去噪扩散模型重新解释为自适应GDP机制序列，实现对视觉模型对抗样本的认证鲁棒性，并在ImageNet上提高了认证准确率和标准准确率。

**AI_Comments:** 这篇论文的创新之处在于将引导去噪扩散模型与差分隐私机制相结合，为对抗鲁棒性提供了一种新的可证明的认证框架。通过重新解释扩散过程为GDP机制序列，并结合随机平滑分析，该方法有望在保持高准确率的同时，提供强大的理论保证。其在ImageNet上的实验结果也显示出实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为视觉模型对对抗样本的预测提供可证明的认证鲁棒性，以应对对抗攻击带来的不确定性。

**Method:** 提出自适应扩散去噪平滑（Adaptive Diffusion Denoised Smoothing）方法。核心思想是将引导去噪扩散模型重新解释为一系列自适应高斯差分隐私（GDP）机制，这些机制将纯噪声样本细化为图像。通过GDP隐私过滤器组合这些自适应机制，分析引导去噪过程的端到端鲁棒性，从而产生可证明的认证，并扩展了自适应随机平滑分析。

**Result:** 在ImageNet数据集上，对于$\\ell_2$威胁模型，该设计在特定引导策略下，能够提高认证准确率和标准准确率。

**Conclusion:** 通过将引导去噪扩散模型重新解释为自适应高斯差分隐私（GDP）机制序列，并结合GDP隐私过滤器，所提出的自适应扩散去噪平滑方法能够为视觉模型提供针对对抗样本的认证鲁棒性，并在实验中验证了其有效性。

> **ai_Abstract:** 本文提出了一种名为自适应扩散去噪平滑的新方法，旨在为视觉模型提供针对对抗样本的认证鲁棒性。该方法的核心是将引导去噪扩散模型视为一系列自适应高斯差分隐私（GDP）机制，并通过GDP隐私过滤器进行组合，以实现可证明的端到端鲁棒性认证。实验结果表明，在ImageNet数据集上，该方法能够有效提升模型的认证准确率和标准准确率。

> **摘要翻译:** 我们提出了自适应扩散去噪平滑，这是一种在适应输入的同时，认证视觉模型对对抗样本预测的方法。我们的关键见解是将引导去噪扩散模型重新解释为一系列自适应高斯差分隐私（GDP）机制，这些机制将纯噪声样本细化为图像。我们表明，这些自适应机制可以通过GDP隐私过滤器组合起来，以分析引导去噪过程的端到端鲁棒性，从而产生可证明的认证，扩展了自适应随机平滑分析。我们证明，在特定的引导策略下，我们的设计可以在ImageNet数据集上，对于\\ell_2威胁模型，提高认证准确率和标准准确率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [230] [A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism](https://arxiv.org/abs/2507.08574)
> *基于三维空间-语言-视觉整合和双向交互注意力机制的脑肿瘤分割多模态融合框架*

*Mingda Zhang, Kaiwen Pan* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 脑肿瘤分割, 多模态融合, 空间-语言-视觉整合, 双向交互注意力, 语义融合适配器

**Comment:** 12 pages, 4 figures

> **TL;DR:** 本研究提出了一种新的多模态融合框架，通过整合空间、语言和视觉信息以及双向交互注意力机制，显著提高了脑肿瘤分割的准确性和边界描绘。

**AI_Comments:** 这项研究的创新之处在于其提出的多模态语义融合适配器（MSFA）和双向交互式视觉-语义注意力（BIVA），能够有效地整合3D MRI图像和临床文本描述，实现空间-语言-视觉信息的深度融合。这种将临床文本信息纳入图像分割的方法，为医学图像分析领域带来了新的范式，有望提高诊断的精确性和临床实用性。其在BraTS 2020数据集上的优异表现也证明了该框架的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在开发一种新颖的多模态融合框架，用于脑肿瘤分割，通过双向交互注意力机制整合空间-语言-视觉信息，以提高分割准确性和边界描绘。

**Method:** 本研究提出了两个核心组件：多模态语义融合适配器（MSFA），通过分层语义解耦整合3D MRI数据和临床文本描述；以及双向交互式视觉-语义注意力（BIVA），实现模态间的迭代信息交换。该框架在BraTS 2020数据集（包含369个多机构MRI扫描）上进行了评估。

**Result:** 所提出的方法在增强肿瘤、肿瘤核心和全肿瘤区域的平均Dice系数达到0.8505，95% Hausdorff距离为2.8256mm，优于SCAU-Net、CA-Net和3D U-Net等现有先进方法。消融研究证实了语义和空间模块对边界精度的关键贡献。

**Conclusion:** 多模态语义融合与双向交互注意力相结合显著增强了脑肿瘤分割性能，为将临床知识整合到医学图像分析中建立了新范式。

> **ai_Abstract:** 本研究提出了一种新颖的多模态融合框架，用于脑肿瘤分割，该框架通过多模态语义融合适配器（MSFA）整合3D MRI数据和临床文本描述，并通过双向交互式视觉-语义注意力（BIVA）实现模态间的信息交换。该框架在BraTS 2020数据集上进行了评估，结果显示其在Dice系数和Hausdorff距离方面均优于现有先进方法，并显著提高了脑肿瘤分割的准确性和边界描绘，为医学图像分析中整合临床知识提供了新途径。

> **摘要翻译:** 本研究旨在开发一种新颖的多模态融合框架，用于脑肿瘤分割，通过双向交互注意力机制整合空间-语言-视觉信息，以提高分割准确性和边界描绘。方法：我们提出了两个核心组件：多模态语义融合适配器（MSFA），通过分层语义解耦整合3D MRI数据和临床文本描述；以及双向交互式视觉-语义注意力（BIVA），实现模态间的迭代信息交换。该框架在BraTS 2020数据集（包含369个多机构MRI扫描）上进行了评估。结果：所提出的方法在增强肿瘤、肿瘤核心和全肿瘤区域的平均Dice系数达到0.8505，95% Hausdorff距离为2.8256mm，优于SCAU-Net、CA-Net和3D U-Net等现有先进方法。消融研究证实了语义和空间模块对边界精度的关键贡献。结论：多模态语义融合与双向交互注意力相结合显著增强了脑肿瘤分割性能，为将临床知识整合到医学图像分析中建立了新范式。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [239] [Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification](https://arxiv.org/abs/2507.08248)
> *迁移学习与Mixup在细粒度小样本真菌分类中的应用*

*Jason Kahei Tam, Murilo Gustineli, Anthony Miyaguchi* | **Category: cs.CV, cs.IR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 迁移学习, 细粒度分类, 小样本学习, 真菌分类, 视觉Transformer

**Comment:** 

> **TL;DR:** 本文提出了一种针对FungiCLEF 2025竞赛的真菌细粒度小样本分类方法，结合迁移学习、视觉Transformer、数据增强和加权采样，其最终模型优于基线，并强调了领域特定预训练和平衡采样策略的有效性。

**AI_Comments:** 本文在解决真菌细粒度小样本分类这一具有挑战性的问题上，通过结合迁移学习、视觉Transformer和特定采样策略展示了实用方法。其创新点在于强调了领域特定预训练和平衡采样在处理细粒度数据时的有效性。尽管在排行榜上排名中等（35/74），但明确指出了未来在元数据选择和多模态学习方面的改进方向，为后续研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 真菌物种的准确识别在计算机视觉中面临独特挑战，因为物种间存在细微差异，而物种内变异性很高。

**Method:** 团队尝试了多种视觉Transformer模型、数据增强、加权采样和整合文本信息。还探索了使用结构化提示的生成式AI模型进行零样本分类，但发现其性能远低于基于视觉的模型。

**Result:** 最终模型优于竞赛基线，并突出了领域特定预训练和平衡采样策略的有效性。在赛后评估的私有测试集上排名35/74。

**Conclusion:** 领域特定预训练和平衡采样策略对细粒度小样本真菌分类有效。未来的工作可以集中在元数据选择和领域适应的多模态学习上。

> **ai_Abstract:** 本文针对FungiCLEF 2025竞赛中的真菌细粒度小样本分类问题，提出了一种基于迁移学习和视觉Transformer的方法。研究团队探索了多种技术，包括数据增强、加权采样和文本信息整合，并发现领域特定预训练和平衡采样策略对于提高模型性能至关重要。虽然生成式AI在零样本分类中表现不佳，但最终的视觉模型显著优于竞赛基线。

> **摘要翻译:** 真菌物种的准确识别在计算机视觉中提出了独特的挑战，这归因于物种间细微的差异和物种内高度的变异性。本文介绍了我们参加FungiCLEF 2025竞赛的方法，该竞赛侧重于使用FungiTastic小样本数据集进行小样本细粒度视觉分类（FGVC）。我们的团队（DS@GT）实验了多种视觉Transformer模型、数据增强、加权采样以及整合文本信息。我们还探索了使用结构化提示的生成式AI模型进行零样本分类，但发现它们的表现显著低于基于视觉的模型。我们的最终模型超越了竞赛基线，并突出了领域特定预训练和平衡采样策略的有效性。在赛后评估中，我们的方法在私有测试集上排名35/74，这表明可以在元数据选择和领域适应的多模态学习方面做更多工作。我们的代码可在https://github.com/dsgt-arc/fungiclef-2025 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [240] [Image Translation with Kernel Prediction Networks for Semantic Segmentation](https://arxiv.org/abs/2507.08554)
> *图像翻译与核预测网络用于语义分割*

*Cristina Mata, Michael S. Ryoo, Henrik Turbell* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 图像翻译, 语义分割, 核预测网络, 域适应, 对抗网络

**Comment:** OOD-CV Workshop at ECCV 2024

> **TL;DR:** DA-KPN是一种新的图像翻译方法，通过核预测和多尺度判别器保证语义匹配，在语义分割任务上优于现有GAN方法。

**AI_Comments:** 本文的创新之处在于通过DA-KPN方法，解决了现有非配对图像翻译中GAN模型无法保证语义匹配的痛点，这对于对像素级精度敏感的语义分割任务至关重要。其利用核预测网络估计像素级变换参数并结合多尺度判别器的设计，提供了一种有效且轻量级的解决方案，提升了合成数据在真实世界任务中的可用性。

<details>
  <summary>Details</summary>

**Motivation:** 语义分割需要大量像素级标注，但真实数据标注困难，导致依赖合成数据产生域间隙。现有非配对图像翻译方法（GANs）无法保证语义匹配，这对于对噪声像素标签敏感的语义分割性能构成问题。

**Method:** 提出了一种名为域对抗核预测网络（DA-KPN）的新型图像翻译方法。DA-KPN通过估计轻量级简单翻译函数的像素级输入变换参数，保证合成标签与翻译结果之间的语义匹配。为确保像素级变换的真实性，DA-KPN使用多尺度判别器来区分翻译样本和目标样本。

**Result:** DA-KPN在有限真实图像标签访问的情况下，在语义分割的syn2real基准测试中优于先前的基于GAN的方法，并在人脸解析上取得了可比的性能。

**Conclusion:** 本文提出了一种新颖的图像翻译方法DA-KPN，解决了现有GAN方法在语义分割中无法保证语义匹配的问题，并在有限真实标签数据下，在语义分割和人脸解析任务上表现优异。

> **ai_Abstract:** 本文提出了一种新颖的图像翻译方法——域对抗核预测网络（DA-KPN），旨在解决语义分割中由于真实世界标注稀缺而导致的域间隙问题。与现有基于GAN的方法不同，DA-KPN通过估计轻量级翻译函数的像素级变换参数，并利用多尺度判别器确保真实性，从而保证合成标签与翻译图像之间的语义匹配。实验表明，在有限真实图像标签的情况下，DA-KPN在语义分割的syn2real基准测试中优于先前的GAN方法，并在人脸解析任务上取得了可比的性能。

> **摘要翻译:** 语义分割依赖于大量的密集像素级标注来达到最佳性能，但由于难以获得准确的真实世界数据标注，实践者通常在大型合成数据集上进行训练。非配对图像翻译是解决由此产生的域间隙的一种方法，通过在低数据状态下生成更真实的训练数据。当前非配对图像翻译方法训练生成对抗网络（GANs）来执行翻译，并通过循环一致性强制执行像素级语义匹配。这些方法不能保证语义匹配的成立，这对于性能对噪声像素标签敏感的语义分割来说是一个问题。我们提出了一种新颖的图像翻译方法——域对抗核预测网络（DA-KPN），它保证了合成标签和翻译结果之间的语义匹配。DA-KPN估计轻量级简单翻译函数的像素级输入变换参数。为了确保像素级变换的真实性，DA-KPN使用多尺度判别器来区分翻译样本和目标样本。我们展示了DA-KPN在有限真实图像标签访问的情况下，在语义分割的syn2real基准测试中优于先前的基于GAN的方法，并在人脸解析上取得了可比的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [241] [Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2411.09250)
> *用于小样本类增量学习的带角度-范数联合分类器的嵌入空间分配*

*Dunwei Tu, Huiyu Yi, Tieyi Zhang, Ruotong Li, Furao Shen, Jian Zhao* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 小样本类增量学习, 嵌入空间分配, 角度-范数联合分类器, 样本不平衡

**Comment:** This paper has been accepted to Neural Networks

> **TL;DR:** SAAN通过空间分配和角度-范数联合分类器解决了小样本类增量学习中的空间占用和样本不平衡问题，达到了最先进的性能。

**AI_Comments:** 该论文创新性地提出了SAAN框架，通过空间分配和角度-范数联合分类器解决了小样本类增量学习中的核心挑战，即特征空间占用和样本不平衡问题。其重要性在于不仅达到了当前最先进的性能，而且能够作为可插拔组件嵌入其他现有方法，极大地提升了其应用价值和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 针对小样本类增量学习（FSCIL）中现有方法存在的问题，包括特征空间被现有类别完全占据不利于新类别学习，以及增量轮次中样本数量不足导致训练不充分。现有虚拟类方法和NCM分类器未能有效解决这些问题。

**Method:** 提出SAAN（class-center guided embedding Space Allocation with Angle-Norm joint classifiers）学习框架。针对特征空间占用问题，SAAN将特征空间划分为多个子空间，并通过预设类别中心引导样本，为每个会话分配专用子空间。针对样本不平衡问题，SAAN为每个类别建立范数分布并生成角度-范数联合逻辑。

**Result:** 实验表明SAAN能够达到最先进的性能，并且可以作为插件直接嵌入其他最先进方法中，进一步提升其性能。

**Conclusion:** SAAN通过提供平衡空间和利用样本不平衡导致的范数差异，有效解决了小样本类增量学习中的挑战，达到了最先进的性能，并可作为插件增强其他方法。

> **ai_Abstract:** 本文针对小样本类增量学习（FSCIL）中现有方法存在的特征空间占用和样本不平衡问题，提出了一种名为SAAN（class-center guided embedding Space Allocation with Angle-Norm joint classifiers）的学习框架。SAAN通过将特征空间划分为多个子空间并为每个会话分配专用空间，以及为每个类别建立范数分布并生成角度-范数联合逻辑，有效解决了上述挑战。实验结果表明，SAAN达到了最先进的性能，并可作为插件提升其他SOTA方法的性能。

> **摘要翻译:** 小样本类增量学习（FSCIL）旨在仅通过少量样本持续学习新类别，同时不遗忘旧类别，这要求智能代理适应动态环境。FSCIL结合了类增量学习和小样本学习的特点和挑战：(i) 当前类别占据整个特征空间，不利于新类别的学习。(ii) 增量轮次中少量样本不足以进行充分训练。在现有主流虚拟类方法中，为解决挑战（i），它们试图使用虚拟类作为占位符。然而，新类别可能不一定与虚拟类对齐。为解决挑战（ii），它们用基于余弦相似度的最近类均值（NCM）分类器取代可训练的全连接层，但NCM分类器未考虑样本不平衡问题。为解决现有方法中的这些问题，我们提出了类中心引导的嵌入空间分配与角度-范数联合分类器（SAAN）学习框架，该框架为所有类别提供平衡空间，并利用样本不平衡引起的范数差异来增强分类标准。具体来说，针对挑战（i），SAAN将特征空间划分为多个子空间，并通过预设类别中心引导样本，为每个会话分配专用子空间。针对挑战（ii），SAAN为每个类别建立范数分布并生成角度-范数联合逻辑。实验表明SAAN能够达到最先进的性能，并且可以作为插件直接嵌入其他最先进方法中，进一步提升其性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [247] [Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.07340)
> *通过对比强化学习在视觉故事叙述中进行实体再识别*

*Daniel A. P. Oliveira, David Martins de Matos* | **Category: cs.CV, I.2; I.4; I.5; I.7** | **Updated: 2025-07-11**

**Keywords:** 视觉故事叙述, 实体再识别, 对比强化学习, 直接偏好优化, 视觉-语言模型

**Comment:** 7 pages

> **TL;DR:** 该研究提出了一种对比强化学习方法来解决视觉故事叙述系统中实体跨帧识别不一致的问题，通过训练模型区分连贯和不相关的图像序列，显著提升了实体定位、再识别和故事结构的连贯性。

**AI_Comments:** 该论文的创新点在于将对比强化学习引入视觉故事叙述中的实体再识别任务，通过合成负例和双组分奖励函数，有效地解决了大型视觉-语言模型在跨帧实体一致性方面的固有缺陷。其重要性在于提升了视觉故事的真实感和连贯性，减少了“指代幻觉”现象，对未来更复杂的视觉-语言理解和生成任务具有积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 视觉故事叙述系统，特别是大型视觉-语言模型，在跨帧保持角色和物体身份方面存在困难，经常无法识别不同图像中的实体是否代表相同的个体或物体，导致引用不一致和指代幻觉。这发生的原因是模型缺乏关于何时建立跨帧实体连接的明确训练。

**Method:** 提出了一种对比强化学习方法，训练模型区分连贯的图像序列和来自不相关图像的故事。通过合成负例扩展了Story Reasoning数据集，以教授适当的实体连接行为。采用带双组分奖励函数的直接偏好优化，该函数促进真实故事中实体的定位和再识别，同时惩罚合成语境中不正确的实体连接。使用此对比框架微调了Qwen Storyteller（基于Qwen2.5-VL 7B）。

**Result:** 实体定位mAP从0.27提高到0.31（+14.8%），F1从0.35提高到0.41（+17.1%）。除“its”之外，所有代词类型的代词定位准确性均有所提高。跨帧角色和物体持久性在所有帧数上均有所增加，实体在5帧或更多帧中出现的比例从29.3%提高到33.3%（+13.7%）。包含思维链和接地故事的结构良好故事的比例从79.1%提高到97.5%（+23.3%）。

**Conclusion:** 通过对比强化学习方法，该研究成功提升了视觉故事叙述系统中实体跨帧识别的一致性，显著改善了实体定位、再识别和故事的整体连贯性，证明了所提方法的有效性。

> **ai_Abstract:** 本文提出了一种基于对比强化学习的方法，旨在解决视觉故事叙述系统中实体跨帧身份识别不一致的问题，这导致了指代幻觉。通过构建合成负例并采用带双组分奖励的直接偏好优化，该方法训练模型区分连贯和不相关的图像序列。在Qwen Storyteller模型上进行微调后，实验结果显示在实体定位mAP、F1分数、代词定位准确性、跨帧实体持久性以及生成结构良好故事的比例上均取得了显著提升，证明了该方法在提高视觉故事连贯性方面的有效性。

> **摘要翻译:** 视觉故事叙述系统，特别是大型视觉-语言模型，在跨帧保持角色和物体身份方面存在困难，经常无法识别不同图像中的实体是否代表相同的个体或物体，导致引用不一致和指代幻觉。这发生的原因是模型缺乏关于何时建立跨帧实体连接的明确训练。我们提出了一种对比强化学习方法，训练模型区分连贯的图像序列和来自不相关图像的故事。我们通过合成负例扩展了Story Reasoning数据集，以教授适当的实体连接行为。我们采用带双组分奖励函数的直接偏好优化，该函数促进真实故事中实体的定位和再识别，同时惩罚合成语境中不正确的实体连接。使用此对比框架，我们微调了Qwen Storyteller（基于Qwen2.5-VL 7B）。评估显示，定位mAP从0.27提高到0.31（+14.8%），F1从0.35提高到0.41（+17.1%）。除“its”之外，所有代词类型的代词定位准确性均有所提高，并且跨帧角色和物体持久性在所有帧数上均有所增加，实体在5帧或更多帧中出现的比例从29.3%提高到33.3%（+13.7%）。结构良好、包含思维链和接地故事的故事比例从79.1%提高到97.5%（+23.3%）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [256] [SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting](https://arxiv.org/abs/2412.14371)
> *SEREP：用于野外鲁棒捕捉和重定向的语义面部表情表示*

*Arthur Josi, Luiz Gustavo Hafemann, Abdallah Dib, Emeline Got, Rafael M. O. Cruz, Marc-Andre Carbonneau* | **Category: cs.CV, cs.GR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 面部表情表示, 语义解耦, 单目捕捉, 半监督学习, MultiREX

**Comment:** For our project page, see
  https://ubisoft-laforge.github.io/character/serep/

> **TL;DR:** SEREP是一种新的面部表情表示模型，它在语义层面将表情与身份分离，并提出了一种新的半监督训练方案和评估基准，在野外表情捕捉和重定向方面优于现有技术。

**AI_Comments:** SEREP的创新之处在于其在语义层面解耦表情与身份，这比传统的顶点位移方法更具鲁棒性。结合半监督学习利用合成数据以及引入新的评估基准MultiREX，显示了其在解决野外复杂场景下表情捕捉问题的全面性，对该领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 野外单目面部表演捕捉由于捕捉条件、面部形状和表情的多样性而具有挑战性。大多数现有方法依赖于线性3D可变形模型，这些模型在顶点位移级别独立于身份表示面部表情。

**Method:** 提出SEREP（语义表情表示）模型，该模型在语义层面将表情与身份解耦。首先从高质量的非配对面部表情3D数据中学习表情表示。然后，利用一种新颖的半监督方案（使用低质量合成数据）训练模型，从单目图像中预测表情。此外，引入了MultiREX，一个解决表情捕捉任务评估资源缺乏的基准。

**Result:** 实验表明，SEREP优于最先进的方法，能够捕捉具有挑战性的表情并将其转移到新的身份上。

**Conclusion:** SEREP通过在语义层面解耦表情和身份，并结合半监督训练和新的评估基准，显著提升了野外单目面部表情捕捉和重定向的性能。

> **ai_Abstract:** 该论文提出了一种名为SEREP的语义面部表情表示模型，旨在解决野外单目面部表演捕捉的挑战。与传统依赖顶点位移的3DMM不同，SEREP在语义层面将表情与身份解耦。该方法通过高质量3D数据学习表情表示，并利用半监督方案结合低质量合成数据进行单目图像表情预测。此外，论文还引入了MultiREX基准来弥补评估资源的不足。实验证明，SEREP在捕捉复杂表情并将其转移到新身份方面超越了现有技术。

> **摘要翻译:** 野外单目面部表演捕捉由于捕捉条件、面部形状和表情的多样性而具有挑战性。大多数现有方法依赖于线性3D可变形模型，这些模型在顶点位移级别独立于身份表示面部表情。我们提出了SEREP（语义表情表示），一个在语义层面将表情与身份分离的模型。我们首先从高质量的非配对面部表情3D数据中学习表情表示。然后，我们训练一个模型，利用一种新颖的半监督方案（使用低质量合成数据）从单目图像中预测表情。此外，我们引入了MultiREX，一个解决表情捕捉任务评估资源缺乏的基准。我们的实验表明，SEREP优于最先进的方法，能够捕捉具有挑战性的表情并将其转移到新的身份上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [260] [Disentangling Instance and Scene Contexts for 3D Semantic Scene Completion](https://arxiv.org/abs/2507.08555)
> *用于3D语义场景补全的实例和场景上下文解耦*

*Enyu Liu, En Yu, Sijia Chen, Wenbing Tao* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D语义场景补全, 实例上下文, 场景上下文, 双流范式, 类别级信息

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 该论文提出DISC，一种用于3D语义场景补全的双流范式，它解耦实例和场景上下文，实现了最先进的性能。

**AI_Comments:** 该论文的创新之处在于超越了传统的以体素为中心的方法，通过明确解耦和利用实例与场景上下文，并通过类别查询和专门的解码器整合类别级信息。这对于实现更精细和准确的3D场景补全至关重要，尤其是在实例类别方面。其仅使用单帧输入即可超越多帧SOTA方法的表现，也突显了其高效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D语义场景补全（SSC）方法主要侧重于细化体素级特征，但这种方法限制了对类别级信息的利用，而类别级信息对于提高补全结果的粒度至关重要。

**Method:** 我们提出了DISC（解耦实例和场景上下文），这是一种新颖的双流范式，通过分离优化来增强实例和场景类别的学习。具体来说，我们用判别性类别查询代替体素查询，这些查询结合了类别特定的几何和语义先验。此外，我们利用类别的内在属性设计了专门的解码模块，以促进有针对性的交互和高效的类别级信息流。

**Result:** DISC在SemanticKITTI和SSCBench-KITTI-360基准测试上均取得了最先进的（SOTA）性能，mIoU分数分别为17.35和20.55。值得注意的是，DISC仅使用单帧输入就超越了多帧SOTA方法，并且显著提高了实例类别的性能，在SemanticKITTI隐藏测试中，分别超越了单帧和多帧SOTA实例mIoU 17.9%和11.9%。

**Conclusion:** DISC通过解耦实例和场景上下文并利用类别级信息，有效地解决了3D语义场景补全中以体素为中心的方法的局限性，从而实现了卓越的性能，尤其是在实例类别方面。

> **ai_Abstract:** DISC是一种新颖的双流范式，用于3D语义场景补全，它通过分离优化解耦实例和场景上下文。该方法通过引入判别性类别查询和专门的解码模块来利用类别级信息，克服了传统体素中心方法的局限性。DISC在SemanticKITTI和SSCBench-KITTI-360上取得了最先进的性能，尤其在单帧输入下显著提升了实例类别的补全效果。

> **摘要翻译:** 3D语义场景补全（SSC）因其在3D感知中的关键作用而受到越来越多的关注。最近的进展主要集中在细化体素级特征以构建3D场景。然而，将体素视为基本交互单元本质上限制了类别级信息的利用，而类别级信息已被证明对于提高补全结果的粒度至关重要。为了解决这个问题，我们提出了解耦实例和场景上下文（DISC），这是一种新颖的双流范式，通过分离优化来增强实例和场景类别的学习。具体来说，我们用判别性类别查询代替体素查询，这些查询结合了类别特定的几何和语义先验。此外，我们利用类别的内在属性设计了专门的解码模块，以促进有针对性的交互和高效的类别级信息流。实验结果表明，DISC在SemanticKITTI和SSCBench-KITTI-360基准测试上均取得了最先进的（SOTA）性能，mIoU分数分别为17.35和20.55。值得注意的是，DISC仅使用单帧输入就超越了多帧SOTA方法，并且显著提高了实例类别的性能，在SemanticKITTI隐藏测试中，分别超越了单帧和多帧SOTA实例mIoU 17.9%和11.9%。代码可在https://github.com/Enyu-Liu/DISC获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [271] [EVT: Efficient View Transformation for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2411.10715)
> *EVT：多模态3D目标检测的高效视图转换*

*Yongjin Lee, Hyeon-Mun Jeong, Yurim Jeon, Sanghyun Kim* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多模态3D目标检测, 鸟瞰图, 视图转换, LiDAR融合, Transformer

**Comment:** Accepted to ICCV 2025

> **TL;DR:** EVT提出一种高效视图转换方法，通过LiDAR引导的自适应采样和投影以及改进的查询检测框架，实现高精度实时多模态3D目标检测。

**AI_Comments:** 本文提出EVT框架，通过结合LiDAR的几何指导（ASAP）和改进的Transformer解码器，有效解决了多模态3D目标检测中视图转换的鲁棒性、效率和几何对齐问题。其创新点在于利用LiDAR辅助的自适应采样与投影，以及设计几何感知的查询机制，显著提升了BEV表示的质量和检测性能，并实现了实时性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有BEV表示的多模态传感器融合方法在3D目标检测中，常依赖深度估计器或Transformer编码器进行图像特征到BEV空间的转换，这降低了鲁棒性或引入了显著的计算开销。此外，视图转换中几何指导不足导致射线方向错位，限制了BEV表示的有效性。

**Method:** 提出高效视图转换（EVT）框架。主要包含两方面：1. 自适应采样和自适应投影（ASAP），利用LiDAR指导生成3D采样点和自适应核，实现图像特征向BEV空间的有效转换和BEV表示的精细化。2. 改进的基于查询的检测框架，结合组式混合查询选择和几何感知交叉注意力，有效捕获Transformer解码器中对象的共同属性和几何结构。

**Result:** 在nuScenes测试集上，EVT实现了75.3% NDS的最新（SOTA）性能，并具有实时推理速度。

**Conclusion:** EVT通过其创新的视图转换和检测框架，显著提高了多模态3D目标检测的准确性和效率，达到了行业领先水平。

> **ai_Abstract:** EVT是一种新颖的多模态3D目标检测框架，旨在解决现有方法在图像特征到BEV空间转换中存在的鲁棒性差、计算开销大和几何指导不足的问题。它通过引入自适应采样和自适应投影（ASAP）利用LiDAR指导进行高效特征转换，并结合改进的基于查询的检测框架，通过组式混合查询选择和几何感知交叉注意力来增强对象特征捕获。EVT在nuScenes数据集上达到了75.3% NDS的SOTA性能，并保持实时推理速度，显著提升了3D目标检测的准确性和效率。

> **摘要翻译:** 鸟瞰图（BEV）表示中的多模态传感器融合已成为3D目标检测的主要方法。然而，现有方法通常依赖深度估计器或Transformer编码器将图像特征转换为BEV空间，这降低了鲁棒性或引入了显著的计算开销。此外，视图转换中几何指导不足导致射线方向错位，限制了BEV表示的有效性。为解决这些挑战，我们提出了高效视图转换（EVT），这是一种新颖的3D目标检测框架，它构建了一个结构良好的BEV表示，从而提高了准确性和效率。我们的方法侧重于两个关键方面。首先，自适应采样和自适应投影（ASAP），它利用LiDAR指导生成3D采样点和自适应核，从而能够更有效地将图像特征转换为BEV空间并细化BEV表示。其次，改进的基于查询的检测框架，结合组式混合查询选择和几何感知交叉注意力，有效捕获Transformer解码器中对象的共同属性和几何结构。在nuScenes测试集上，EVT实现了75.3% NDS的最新（SOTA）性能，并具有实时推理速度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos](https://arxiv.org/abs/2507.07393)
> *KeyRe-ID：视频中基于关键点引导和部位感知表示的行人再识别*

*Jinseong Kim, Junghoon Song, Gyeongseon Baek, Byeongjoon Noh* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 行人再识别, 视频, 关键点, 部位感知, Transformer

**Comment:** 10 pages, 2 figures,

> **TL;DR:** KeyRe-ID是一个利用人体关键点进行视频行人再识别的框架，通过结合全局和局部特征实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个结合全局和局部特征，并利用人体关键点指导的视频行人再识别框架，有效地增强了特征表示。其在多个基准测试上的SOTA性能证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过利用人体关键点增强时空表示学习，以改进视频中的行人再识别性能。

**Method:** 提出KeyRe-ID框架，包含全局和局部分支。全局分支通过基于Transformer的时间聚合捕获整体身份语义；局部分支根据关键点动态分割身体区域，生成细粒度的部位感知特征。

**Result:** 在MARS和iLIDS-VID基准测试中达到了最先进的性能，MARS上mAP为91.73%，Rank-1准确率为97.32%；iLIDS-VID上Rank-1准确率为96.00%，Rank-5准确率为100.0%。

**Conclusion:** KeyRe-ID框架通过结合全局和局部特征以及利用人体关键点，在视频行人再识别任务上取得了显著的最先进性能。

> **ai_Abstract:** KeyRe-ID是一种新颖的视频行人再识别框架，它结合了全局和局部特征分支，并利用人体关键点来增强时空表示学习。全局分支使用Transformer聚合整体身份信息，而局部分支则基于关键点生成精细的部位感知特征。该方法在MARS和iLIDS-VID数据集上均取得了最先进的识别性能。

> **摘要翻译:** 我们提出了KeyRe-ID，一个关键点引导的基于视频的行人再识别框架，包含全局和局部分支，利用人体关键点增强时空表示学习。全局分支通过基于Transformer的时间聚合捕获整体身份语义，而局部分支根据关键点动态分割身体区域以生成细粒度的部位感知特征。在MARS和iLIDS-VID基准上的大量实验表明，该框架实现了最先进的性能，在MARS上达到了91.73%的mAP和97.32%的Rank-1准确率，在iLIDS-VID上达到了96.00%的Rank-1和100.0%的Rank-5准确率。该工作的代码将在发布后公开发布在GitHub上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [275] [Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates](https://arxiv.org/abs/2507.08636)
> *规范化注释与外交式注释：手写乌拉圭出生证明自动信息提取的案例研究*

*Natalia Bottaioli, Solène Tarride, Jérémy Anger, Seginus Mowlavi, Marina Gardella, Antoine Tadros, Gabriele Facciolo, Rafael Grompone von Gioi, Christopher Kermorvant, Jean-Michel Morel, Javier Preciozzi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 信息提取, 手写文档, 注释策略, 乌拉圭出生证明, DAN

**Comment:** 

> **TL;DR:** 本研究评估了Document Attention Network (DAN) 在手写乌拉圭出生证明上提取信息的性能，并比较了规范化注释和外交式注释两种策略。结果表明，规范化注释适用于可标准化字段，而外交式注释更适用于不可标准化字段。

**AI_Comments:** 该研究的创新之处在于对比分析了两种不同的注释策略在特定信息提取任务中的适用性，并明确指出了它们各自的优势领域，为未来手写文档信息提取的注释实践提供了有价值的指导。其重要性在于，在数据量有限的情况下，通过选择合适的注释方法可以显著提高信息提取的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在评估Document Attention Network (DAN) 从手写乌拉圭出生证明中提取关键信息的能力，并探讨两种自动转录手写文档的注释策略（规范化注释与外交式注释）在少量训练数据下的有效性。

**Method:** 研究评估了Document Attention Network (DAN) 模型，并使用两种不同的注释策略（规范化注释和外交式注释）进行微调。实验在包含201份手写乌拉圭出生证明扫描件的两个数据集上进行，这两个数据集图像相同但注释方法不同。

**Result:** 研究发现，规范化注释对于日期和出生地等可标准化字段更有效，而外交式注释对于姓名和姓氏等不可标准化字段表现更好。

**Conclusion:** 注释策略的选择应根据信息字段的类型来决定：可标准化字段适合规范化注释，而不可标准化字段适合外交式注释。

> **ai_Abstract:** 本研究评估了Document Attention Network (DAN) 从手写乌拉圭出生证明中提取关键信息的效果，并比较了规范化注释和外交式注释两种策略。实验在相同图像但不同注释方法的两个数据集上进行。结果表明，规范化注释适用于可标准化字段，而外交式注释更适用于姓名等不可标准化字段。

> **摘要翻译:** 这项研究评估了最近提出的文档注意力网络（DAN）从西班牙语手写乌拉圭出生证明中提取关键值信息的能力。我们研究了两种自动转录手写文档的注释策略，并用最少的训练数据和注释工作量对DAN进行了微调。实验在两个数据集上进行，这两个数据集包含相同的图像（201份由15位以上不同书写者书写的出生证明扫描件），但使用了不同的注释方法。我们的研究结果表明，规范化注释对于日期和出生地等可以标准化的字段更有效，而外交式注释对于包含姓名和姓氏等无法标准化的字段表现更好。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [279] [Portable Biomechanics Laboratory: Clinically Accessible Movement Analysis from a Handheld Smartphone](https://arxiv.org/abs/2507.08268)
> *便携式生物力学实验室：通过手持智能手机进行临床可及的运动分析*

*J. D. Peiffer, Kunal Shah, Irina Djuraskovic, Shawana Anarwala, Kayan Abdou, Rujvee Patel, Prakash Jayabalan, Brenton Pennicooke, R. James Cotton* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 生物力学, 运动分析, 智能手机, 临床应用, 可穿戴设备

**Comment:** 15 pages, 7 figures

> **TL;DR:** 该研究提出了一个名为“便携式生物力学实验室”（PBL）的系统，利用手持智能手机视频进行全身运动学测量，并证明其在临床上具有高可靠性和敏感性，为可及的运动障碍监测提供了新途径。

**AI_Comments:** 该论文的创新之处在于将日常智能手机转化为一个便携式生物力学实验室，极大地降低了运动分析的门槛，使其在临床实践中更具可及性。其在多类患者群体中的广泛验证以及与现有临床指标的良好关联性，证明了该系统的实用性和潜力。这对于推动运动障碍的早期识别、客观评估和治疗效果监测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管运动是神经和肌肉骨骼健康的直接反映，但在临床实践中，它仍然是最未被充分利用的生命体征之一。临床医生缺乏可及且经过验证的方法来客观测量运动，这阻碍了生物力学测量在实践中的广泛应用，从而限制了更敏感的结果测量或更早识别损伤。

**Method:** 本研究提出了“便携式生物力学实验室”（PBL），包括一个用于数据收集的安全、支持云的智能手机应用程序和一个用于将生物力学模型拟合到数据的新颖算法。研究团队使用大量具有临床代表性的数据集广泛验证了PBL的生物力学测量，并在神经外科和运动医学诊所测试了系统的可用性和实用性。

**Result:** PBL在神经损伤患者、下肢假肢使用者、儿科住院患者和对照组中，关节角度误差在3度以内。PBL计算出的步态指标易于使用，显示出高可靠性，并且对临床差异敏感。例如，在接受颈椎脊髓型颈椎病减压手术的个体中，PBL步态指标与mJOA评分相关，并且比患者报告的结果对手术干预表现出更大的响应性。

**Conclusion:** 研究结果支持使用手持智能手机视频作为一种可扩展、低负担的工具，用于捕获具有临床意义的生物力学数据，为可及的运动障碍监测提供了有前景的途径。本研究发布了首个经临床验证的通过手持智能手机视频测量全身运动学的方法。

> **ai_Abstract:** 本研究提出并验证了“便携式生物力学实验室”（PBL），该系统利用手持智能手机应用程序和新型算法，实现了对人体运动的客观测量。PBL在多种临床人群中展现出高精度和可靠性，其步态指标能有效反映临床差异，并对治疗干预表现出比传统患者报告更强的响应性。这表明手持智能手机视频可作为一种可扩展、低成本的工具，用于临床生物力学数据采集和运动障碍监测。

> **摘要翻译:** 一个人的运动方式直接反映了他们的神经和肌肉骨骼健康，然而，它仍然是临床实践中最未被充分利用的生命体征之一。尽管临床医生通过视觉观察运动障碍，但他们缺乏可及且经过验证的方法来在日常护理中客观测量运动。这种差距阻碍了生物力学测量在实践中的广泛使用，而这可能实现更敏感的结果测量或更早识别损伤。我们提出了我们的便携式生物力学实验室（PBL），其中包括一个用于数据收集的安全、支持云的智能手机应用程序和一个用于将生物力学模型拟合到这些数据的新颖算法。我们使用大量具有临床代表性的数据集广泛验证了PBL的生物力学测量。接下来，我们在神经外科和运动医学诊所测试了我们系统的可用性和实用性。我们发现，在神经损伤患者、下肢假肢使用者、儿科住院患者和对照组中，关节角度误差在3度以内。除了易于使用外，从PBL计算出的步态指标显示出高可靠性，并且对临床差异敏感。例如，在接受颈椎脊髓型颈椎病减压手术的个体中，mJOA评分是一种常见的患者报告结果测量；我们发现PBL步态指标与mJOA评分相关，并且比患者报告的结果对手术干预表现出更大的响应性。这些发现支持使用手持智能手机视频作为一种可扩展、低负担的工具，用于捕获具有临床意义的生物力学数据，为可及的运动障碍监测提供了有前景的途径。我们发布了第一个经临床验证的通过手持智能手机视频测量全身运动学的方法，网址为 https://intelligentsensingandrehabilitation.github.io/MonocularBiomechanics/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [285] [BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis](https://arxiv.org/abs/2507.08607)
> *BayesTTA：通过高斯判别分析实现视觉-语言模型的持续时间测试时间适应*

*Shuang Cui, Jinglin Xu, Yi Li, Xiongxin Tang, Jiangmeng Li, Jiahuan Zhou, Fanjiang Xu, Fuchun Sun, Hui Xiong* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 持续时间测试时间适应, 视觉-语言模型, 贝叶斯适应, 高斯判别分析, 分布偏移

**Comment:** 

> **TL;DR:** 提出BayesTTA框架，通过高斯判别分析解决视觉-语言模型在时间演变分布偏移下的持续时间测试时间适应问题，并显著优于现有方法。

**AI_Comments:** 该论文创新性地将贝叶斯框架和高斯判别分析引入到持续时间测试时间适应问题中，解决了现有方法在处理时间连续性、灾难性遗忘和表示对齐方面的缺陷。其对“持续时间测试时间适应（CT-TTA）”的明确形式化和提出的BayesTTA框架为视觉-语言模型在真实世界动态环境下的鲁棒性提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型在现实世界中常见的“时间演变分布偏移”（例如，逐渐的光照或季节变化）下性能显著下降。现有的持续测试时间适应（CTTA）方法主要针对突然和严重的分布偏移，忽略了时间连续性，导致：有限的内存缓存引起灾难性遗忘；基于熵的置信度在时间漂移下不可靠；静态视觉表示与演变输入不匹配。本文将此问题形式化为“持续时间测试时间适应（CT-TTA）”，即测试分布随时间逐渐演变。

**Method:** 提出BayesTTA，一个贝叶斯适应框架，它强制执行时间一致的预测并动态对齐视觉表示。具体来说，BayesTTA在不存储原始数据的情况下增量估计类别条件高斯混合分布，通过统计假设检验自适应选择协方差结构，并使用高斯判别分析（GDA）执行校准推理。这些校准预测监督归一化层的自步适应，确保高效稳定的表示对齐。

**Result:** 在四个时间演变数据集上建立了全面的CT-TTA基准，并在十个标准TTA数据集上进一步评估了泛化能力。大量实验表明，BayesTTA始终优于现有先进方法，取得了显著的增益，同时保持了效率。

**Conclusion:** BayesTTA通过其贝叶斯适应框架和高斯判别分析，有效解决了视觉-语言模型在持续时间分布偏移下的适应问题，并在各种基准测试中表现出卓越的性能和效率。

> **ai_Abstract:** 本文提出了BayesTTA，一个新颖的贝叶斯适应框架，旨在解决视觉-语言模型在“持续时间测试时间适应（CT-TTA）”问题中的性能下降。该问题涉及测试分布随时间逐渐演变。BayesTTA通过增量估计类别条件高斯混合分布、自适应选择协方差结构以及利用高斯判别分析进行校准推理来强制执行时间一致的预测并动态对齐视觉表示。实验结果表明，BayesTTA在多个时间演变和标准TTA数据集上均显著优于现有最先进方法，同时保持高效率。

> **摘要翻译:** 视觉-语言模型（VLM）如CLIP实现了强大的零样本识别能力，但在现实世界场景中常见的“时间演变分布偏移”（例如，逐渐的光照或季节变化）下性能显著下降。现有的持续测试时间适应（CTTA）方法通常围绕突然和严重的分布偏移构建，并忽略时间连续性，导致三个核心缺陷：有限的内存缓存限制了长距离分布建模，导致灾难性遗忘；基于熵的置信度在时间漂移下变得不可靠，加剧了错误累积；静态视觉表示与演变输入不匹配。我们将这个实际问题形式化为“持续时间测试时间适应（CT-TTA）”，其中测试分布随时间逐渐演变。为了解决这个问题，我们提出了BayesTTA，一个贝叶斯适应框架，它强制执行时间一致的预测并动态对齐视觉表示。具体来说，BayesTTA在不存储原始数据的情况下增量估计类别条件高斯混合分布，通过统计假设检验自适应选择协方差结构，并使用高斯判别分析（GDA）执行校准推理。这些校准预测监督归一化层的自步适应，确保高效稳定的表示对齐。我们在四个时间演变数据集上建立了全面的CT-TTA基准，并在十个标准TTA数据集上进一步评估了泛化能力。大量实验表明，BayesTTA始终优于现有先进方法，取得了显著的增益，同时保持了效率。代码可在https://github.com/cuishuang99/BayesTTA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [287] [Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision](https://arxiv.org/abs/2507.07460)
> *Objectomaly：面向OoD分割的对象感知精炼，具有结构一致性和边界精度*

*Jeonghoon Song, Sunghun Kim, Jaegyun Im, Byeongjoon Noh* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 域外分割, 对象感知, 边界精炼, 异常检测, 结构一致性

**Comment:** 

> **TL;DR:** Objectomaly是一个新的框架，通过对象感知精炼解决了OoD分割中边界不精确和分数不一致的问题，并在多个基准测试中达到了最先进的性能。

**AI_Comments:** Objectomaly的创新之处在于其三阶段的对象感知精炼框架，特别是结合了SAM生成的实例掩码进行分数校准，以及利用拉普拉斯滤波和高斯平滑进行边界精炼，这有效地解决了现有OoD分割方法中边界精度和内部一致性的痛点。其在安全敏感应用中的潜力巨大。

<details>
  <summary>Details</summary>

**Motivation:** 域外（OoD）分割对于自动驾驶等安全敏感应用至关重要。然而，现有基于掩码的方法存在边界不精确、对象内异常分数不一致以及背景噪声引起的误报等问题。

**Method:** 本文提出了Objectomaly，一个对象感知精炼框架，它整合了对象级先验。该框架包含三个阶段：1) 粗略异常评分（CAS），使用现有OoD骨干网络；2) 对象感知分数校准（OASC），利用SAM生成的实例掩码进行对象级分数归一化；3) 精细边界精度（MBP），应用拉普拉斯滤波和高斯平滑进行轮廓精炼。

**Result:** Objectomaly在SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly等关键OoD分割基准测试中实现了最先进的性能，提高了像素级（AuPRC高达96.99，FPR$_{95}$低至0.07）和组件级（F1分数高达83.44）指标。消融研究和真实世界驾驶视频的定性结果进一步验证了该方法的鲁棒性和泛化性。

**Conclusion:** Objectomaly通过其对象感知精炼方法有效地解决了OoD分割中的关键挑战，并在各种基准测试中表现出卓越的性能、鲁棒性和泛化能力。

> **ai_Abstract:** 本文提出了Objectomaly，一个用于域外（OoD）分割的对象感知精炼框架，旨在解决现有方法中边界不精确、对象内分数不一致和背景噪声误报的问题。Objectomaly包含粗略异常评分、对象感知分数校准和精细边界精度三个阶段，通过整合对象级先验和利用SAM生成的实例掩码进行归一化，并应用拉普拉斯滤波和高斯平滑进行边界精炼。该方法在多个OoD分割基准测试中取得了最先进的性能，显著提高了像素级和组件级指标，并通过消融研究和真实世界视频验证了其鲁棒性和泛化能力。

> **摘要翻译:** 域外（OoD）分割对于自动驾驶等安全敏感应用至关重要。然而，现有基于掩码的方法往往存在边界不精确、对象内异常分数不一致以及背景噪声引起的误报问题。我们提出了Objectomaly，一个对象感知精炼框架，它整合了对象级先验。Objectomaly包含三个阶段：(1) 使用现有OoD骨干网络的粗略异常评分（CAS），(2) 利用SAM生成的实例掩码进行对象级分数归一化的对象感知分数校准（OASC），以及(3) 应用拉普拉斯滤波和高斯平滑进行轮廓精炼的精细边界精度（MBP）。Objectomaly在关键的OoD分割基准测试中取得了最先进的性能，包括SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly，同时改进了像素级（AuPRC高达96.99，FPR$_{95}$低至0.07）和组件级（F1分数高达83.44）指标。消融研究和真实世界驾驶视频的定性结果进一步验证了我们方法的鲁棒性和泛化能力。代码将在发布时公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [295] [DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images](https://arxiv.org/abs/2507.08648)
> *DatasetAgent：一种用于从真实世界图像自动构建数据集的新型多智能体系统*

*Haoran Sun, Haoyu Bian, Shaoning Zeng, Yunbo Rao, Xu Xu, Lin Mei, Jianping Gou* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** DatasetAgent, 多智能体系统, 数据集构建, 真实世界图像, MLLMs

**Comment:** 

> **TL;DR:** DatasetAgent是一个多智能体系统，能够利用真实世界图像自动构建高质量数据集，解决传统手动标注的低效问题。

**AI_Comments:** 这项研究的创新之处在于提出了一个多智能体系统DatasetAgent，利用多模态大型语言模型（MLLMs）和图像优化工具，实现了从真实世界图像自动构建高质量数据集。这解决了传统手动标注的效率瓶颈和合成数据价值不足的问题，对计算机视觉领域的数据集构建具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的图像数据集构建方法依赖于耗时且低效的手动收集和标注。尽管大型模型可以生成数据，但真实世界的数据比AI生成的数据更有价值，尤其是在构建图像数据集方面。

**Method:** 我们提出了一个名为DatasetAgent的多智能体协作系统，用于从真实世界图像自动构建数据集。该系统通过协调四个配备多模态大型语言模型（MLLMs）的不同智能体以及一个图像优化工具包来实现。

**Result:** DatasetAgent能够根据用户指定的要求构建高质量的图像数据集。实验包括扩展现有数据集和从头创建新数据集，并在各种开源数据集上进行。使用DatasetAgent构建的多个图像数据集被用于训练各种视觉模型，如图像分类、目标检测和图像分割。

**Conclusion:** DatasetAgent系统成功地从真实世界图像中自动构建了高质量的数据集，并有效支持了多种视觉任务的模型训练，证明了其在解决传统数据集构建挑战方面的有效性。

> **ai_Abstract:** 本文提出了一种名为DatasetAgent的新型多智能体系统，旨在解决传统图像数据集构建中耗时且低效的手动收集和标注问题。DatasetAgent通过协调四个配备多模态大型语言模型（MLLMs）的智能体和一个图像优化工具包，能够根据用户需求从真实世界图像中自动构建高质量数据集。实验证明，该系统可以有效扩展现有数据集或从零开始创建新数据集，并且其构建的数据集成功用于训练多种视觉任务的模型，如图像分类、目标检测和图像分割。

> **摘要翻译:** 通用知识表明，图像数据集的构建过程通常依赖于耗时且低效的手动收集和标注方法。大型模型通过数据生成提供了一种解决方案。然而，与人工智能生成的数据相比，真实世界的数据显然更有价值，尤其是在构建图像数据集时。因此，我们提出了一种通过多智能体协作系统从真实世界图像自动构建数据集的新方法，名为DatasetAgent。通过协调配备多模态大型语言模型（MLLMs）的四个不同智能体，以及一个用于图像优化的工具包，DatasetAgent能够根据用户指定的要求构建高质量的图像数据集。具体而言，我们进行了两种类型的实验，包括扩展现有数据集和从头创建新数据集，并在各种开源数据集上进行。在这两种情况下，DatasetAgent构建的多个图像数据集被用于训练各种视觉模型，用于图像分类、目标检测和图像分割。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [297] [Spline Deformation Field](https://arxiv.org/abs/2507.07521)
> *样条变形场*

*Mingyang Song, Yang Zhang, Marko Mihajlovic, Siyu Tang, Markus Gross, Tunç Ozan Aydın* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 样条, 变形场, 轨迹建模, 时间插值, 运动连贯性

**Comment:** SIGGRAPH 2025, Conference track

> **TL;DR:** 本文提出了一种基于样条的轨迹表示方法，用于解决密集点轨迹建模中隐式变形场的空间不连贯性问题，并在稀疏输入下的时间插值和动态场景重建方面表现出色。

**AI_Comments:** 这项工作通过引入基于样条的轨迹表示，为密集点轨迹建模提供了一种新颖且直观的解决方案。其创新点在于利用样条的数学特性来确保空间连贯性和解析速度推导，这克服了神经网络隐式表示中常见的归纳偏置问题。此外，低秩时变空间编码的引入也提升了模型的灵活性和效率。该方法在处理稀疏时间数据方面的优势，以及在动态场景重建中的竞争力，使其在计算机图形学和视觉领域具有重要意义。它提供了一个更可控、更透明的替代方案，避免了对启发式初始化和刚性约束的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 密集点轨迹建模中，隐式变形场（神经网络）的归纳偏置会阻碍不适定场景下的空间连贯性。现有方法要么增强编码策略（导致不透明模型），要么采用显式技术（依赖启发式节点初始化）。此外，隐式表示在稀疏时间信号插值方面的潜力尚未充分探索。

**Method:** 提出了一种基于样条的轨迹表示，其中结点的数量明确决定了自由度。这种方法可以高效地解析推导速度，保持空间连贯性和加速度，同时减轻时间波动。引入了一种新颖的低秩时变空间编码来建模空间和时间域的结点特性，取代了传统的耦合时空技术。

**Result:** 该方法在用稀疏输入拟合连续场的时间插值方面表现出卓越性能。此外，与最先进的方法相比，它在动态场景重建质量方面具有竞争力，同时在不依赖线性混合蒙皮或刚性尽可能约束的情况下增强了运动连贯性。

**Conclusion:** 本文提出的样条基轨迹表示有效解决了隐式变形场在密集点轨迹建模中面临的挑战，通过提高空间连贯性、准确的速度推导和优越的稀疏数据插值能力，实现了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为“样条变形场”的新型轨迹表示方法，旨在解决现有隐式变形场在密集点轨迹建模中面临的空间不连贯性和稀疏数据插值问题。该方法利用样条基的特性，通过明确的自由度控制实现了对速度和加速度的解析推导，同时保持了空间连贯性并减少了时间波动。通过引入低秩时变空间编码，该模型能够有效处理空间和时间域的结点特性。实验结果表明，该方法在稀疏输入下的时间插值性能优于现有技术，并在动态场景重建方面达到SOTA水平，同时无需依赖传统的线性混合蒙皮等约束即可增强运动连贯性。

> **摘要翻译:** 密集点轨迹建模通常采用隐式变形场，表示为将坐标映射以关联规范空间位置与时间偏移的神经网络。然而，神经网络固有的归纳偏置会阻碍不适定场景下的空间连贯性。当前方法要么侧重于增强变形场的编码策略，这通常导致模型不透明且不那么直观；要么采用线性混合蒙皮等显式技术，这依赖于基于启发式的节点初始化。此外，隐式表示在插值稀疏时间信号方面的潜力仍未得到充分探索。为了解决这些挑战，我们提出了一种基于样条的轨迹表示，其中结点的数量明确决定了自由度。这种方法可以高效地解析推导速度，保持空间连贯性和加速度，同时减轻时间波动。为了在空间和时间域建模结点特性，我们引入了一种新颖的低秩时变空间编码，取代了传统的耦合时空技术。我们的方法在用稀疏输入拟合连续场的时间插值方面表现出卓越性能。此外，与最先进的方法相比，它在动态场景重建质量方面具有竞争力，同时在不依赖线性混合蒙皮或刚性尽可能约束的情况下增强了运动连贯性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [301] [FonTS: Text Rendering with Typography and Style Controls](https://arxiv.org/abs/2412.00136)
> *FonTS：具有排版和风格控制的文本渲染*

*Wenda Shi, Yiren Song, Dengming Zhang, Jiaming Liu, Xingxing Zou* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 文本渲染, 扩散模型, 排版控制, 风格控制, 字级控制

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 提出一种两阶段DiT模型FonTS，通过引入TC-FT和SCA，实现文本渲染中字级排版和风格的精细控制与一致性。

**AI_Comments:** 该论文的创新点在于提出了一个两阶段的DiT管道，并引入了参数高效的TC-FT和文本无关的SCA，以解决文本渲染中字级控制和风格一致性的关键挑战。特别是，它提出了首个字级可控数据集，这对于推动该领域的研究具有重要意义。该方法显著提升了文本渲染的精细控制能力和视觉质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散Transformer的文本到图像模型在文本渲染中面临字体不一致、风格变化大以及缺乏字级精细控制的挑战。

**Method:** 论文提出一个两阶段的DiT管道：1) 引入排版控制微调（TC-FT），这是一种参数高效的微调方法（仅针对5%的关键参数），利用包含排版控制的tokens (ETC-tokens) 实现精确的字级排版特征应用。2) 提出文本无关的风格控制适配器（SCA），以防止内容泄露并增强风格一致性。为有效实施TC-FT和SCA，将HTML渲染集成到数据合成管道中，并构建了首个字级可控数据集。

**Result:** 实验证明该方法在文本渲染任务中实现了卓越的字级排版控制、字体一致性和风格一致性。

**Conclusion:** 该研究通过创新的两阶段DiT管道、TC-FT和SCA，成功解决了现有文本渲染模型在字级控制和风格一致性方面的挑战，并提供了首个字级可控数据集，显著提升了文本渲染的质量和可控性。

> **ai_Abstract:** 本文提出了FonTS，一个两阶段的基于扩散Transformer (DiT) 的文本渲染管道，旨在解决现有文本到图像模型在字体不一致、风格变化和字级控制不足的问题。通过引入排版控制微调 (TC-FT) 实现精确的字级排版控制，并设计文本无关的风格控制适配器 (SCA) 提升风格一致性。此外，研究团队还构建了首个字级可控数据集。实验结果表明，FonTS在文本渲染任务中展现出卓越的字级排版和风格控制能力。

> **摘要翻译:** 视觉文本渲染广泛应用于各种现实世界应用中，需要仔细的字体选择和排版选择。最近基于扩散Transformer (DiT) 的文本到图像 (T2I) 模型在自动化这些过程方面显示出前景。然而，这些方法仍然面临字体不一致、风格变化和有限的细粒度控制，特别是在字级方面。本文提出一个两阶段的基于DiT的管道来解决这些问题，通过增强文本渲染中排版和风格的可控性。我们引入了排版控制微调 (TC-FT)，这是一种参数高效的微调方法（针对5%的关键参数），带有包含排版控制的tokens (ETC-tokens)，可以实现精确的字级排版特征应用。为了进一步解决文本渲染中的风格不一致问题，我们提出了一种文本无关的风格控制适配器 (SCA)，它在增强风格一致性的同时防止内容泄露。为了有效实施TC-FT和SCA，我们将HTML渲染集成到数据合成管道中，并提出了第一个字级可控数据集。通过全面的实验，我们证明了我们方法在实现卓越的字级排版控制、字体一致性和风格一致性方面的有效性。数据集和模型将可用于学术用途。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [305] [OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception](https://arxiv.org/abs/2507.08644)
> *OnlineBEV: 鸟瞰图表示中循环时间融合用于多摄像头三维感知*

*Junho Koh, Youngwoo Lee, Jungho Kim, Dongyoung Lee, Jun Won Choi* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多摄像头3D感知, 鸟瞰图, 时间融合, 循环网络, 特征对齐

**Comment:** Accepted to Transactions on Intelligent Transportation Systems

> **TL;DR:** OnlineBEV提出了一种新颖的循环时间融合方法，通过运动引导的BEV融合网络和时间一致性学习损失，有效整合多帧BEV特征，显著提升了多摄像头3D感知性能，在nuScenes数据集上达到了SOTA。

**AI_Comments:** OnlineBEV的创新点在于其循环结构的时间融合方法，这有效解决了传统时间聚合在处理大量帧时内存和性能受限的问题。特别是引入MBFNet进行运动引导的特征对齐和时间一致性学习损失，对于动态场景下的特征鲁棒性至关重要。这篇论文为多摄像头3D感知领域提供了一个高性能且高效的解决方案，其在nuScenes上的SOTA表现证明了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视角摄像头3D感知方法通过结合序列BEV特征来提升性能，但在处理大量图像帧时，由于物体运动导致的BEV特征动态变化，即使补偿了自我运动，时间聚合的性能增益也有限。

**Method:** 本文提出了一种名为OnlineBEV的新型时间3D感知方法，该方法使用循环结构随时间结合BEV特征，以最小的内存使用量增加有效结合的特征数量。OnlineBEV采用运动引导的BEV融合网络（MBFNet）实现时间特征对齐，MBFNet从连续的BEV帧中提取运动特征，并利用这些特征动态对齐历史BEV特征与当前特征。为了明确强制时间特征对齐，使用了时间一致性学习损失（Temporal Consistency Learning Loss），该损失捕捉历史BEV特征与目标BEV特征之间的差异。

**Result:** 实验在nuScenes基准测试中进行，OnlineBEV比现有最佳方法SOLOFusion取得了显著的性能提升。OnlineBEV在nuScenes测试集上实现了63.9%的NDS，在仅使用摄像头的3D目标检测任务中达到了最先进的性能。

**Conclusion:** OnlineBEV通过创新的循环时间融合结构、运动引导的特征对齐以及时间一致性学习损失，有效解决了多帧BEV特征聚合中的挑战，并在多摄像头3D感知任务中实现了最先进的性能。

> **ai_Abstract:** OnlineBEV是一种用于多摄像头3D感知的新型时间融合方法。它通过引入循环结构有效聚合多帧鸟瞰图（BEV）特征，以解决现有方法在处理大量帧时因物体运动导致的性能瓶颈。该方法核心在于运动引导的BEV融合网络（MBFNet），它利用运动特征实现历史与当前BEV特征的精确对齐，并通过时间一致性学习损失进一步优化。实验结果表明，OnlineBEV在nuScenes基准测试上显著超越了现有最佳方法，并在仅使用摄像头的3D目标检测任务中达到了最先进的性能，NDS达到63.9%。

> **摘要翻译:** 多视角摄像头三维感知可以通过透视视图到鸟瞰图（BEV）转换获得的BEV特征进行。多项研究表明，通过结合来自多个摄像头帧的序列BEV特征，这些三维感知方法的性能可以进一步增强。然而，即使补偿了自主体的自我运动，当结合大量图像帧时，时间聚合的性能增益也有限。这种限制是由于物体运动导致BEV特征随时间动态变化而产生的。在本文中，我们介绍了一种新颖的时间三维感知方法，名为OnlineBEV，它使用循环结构随时间结合BEV特征。这种结构以最小的内存使用量增加了有效结合的特征数量。然而，随时间对齐特征的空间位置对于保持强大的性能至关重要。OnlineBEV采用运动引导的BEV融合网络（MBFNet）来实现时间特征对齐。MBFNet从连续的BEV帧中提取运动特征，并利用这些运动特征动态地将历史BEV特征与当前特征对齐。为了明确强制时间特征对齐，我们使用了时间一致性学习损失，该损失捕捉历史BEV特征与目标BEV特征之间的差异。在nuScenes基准测试上进行的实验表明，OnlineBEV比当前最佳方法SOLOFusion取得了显著的性能提升。OnlineBEV在nuScenes测试集上达到了63.9%的NDS，在仅使用摄像头的3D目标检测任务中创造了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [319] [Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment](https://arxiv.org/abs/2507.08290)
> *跨分辨率SAR目标检测：基于结构层级适应与可靠邻接对齐*

*Jiang Qin, Bin Zou, Haolin Li, Lamei Zhang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** SAR目标检测, 跨分辨率, 域适应, 结构层级适应, 邻接对齐

**Comment:** Submitted to IEEE TGRS (major revision)

> **TL;DR:** 针对SAR图像分辨率差异导致的跨分辨率目标检测挑战，本文提出CR-Net，通过结构层级特征适应和可靠结构邻接对齐，实现可靠的域适应，并取得了SOTA性能。

**AI_Comments:** 这篇论文通过引入结构先验和证据学习理论，创新性地解决了SAR图像跨分辨率目标检测中的域适应难题。SHFA和RSAA模块的设计，特别是对结构关联和可靠语义对齐的强调，增强了模型的可解释性和判别能力。其在复杂SAR数据上的SOTA表现，显示了该方法在实际应用中的巨大潜力，对于提升SAR图像智能解译能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着SAR分辨率的提高，散射特性差异增大，导致目标检测模型的泛化能力面临挑战。传统的域适应技术因分辨率差异可能导致盲目特征适应和不可靠的语义传播，从而降低性能。

**Method:** 本文提出了一种新颖的SAR目标检测方法CR-Net，它将结构先验和证据学习理论融入检测模型，以实现可靠的跨分辨率域适应。CR-Net集成了结构诱导分层特征适应（SHFA）模块和可靠结构邻接对齐（RSAA）模块。SHFA用于建立目标间的结构关联并实现结构感知特征适应，增强特征适应过程的可解释性。RSAA利用安全邻接集从源域向目标域传输有价值的判别知识，增强语义对齐的可靠性，进一步提高目标域的判别能力。

**Result:** 实验结果表明，所提出的CR-Net通过保留域内结构和提高判别能力，显著增强了跨分辨率适应性，并在跨分辨率SAR目标检测中达到了最先进（SOTA）的性能。

**Conclusion:** CR-Net通过创新的结构先验和证据学习理论，有效解决了跨分辨率SAR目标检测中的域适应挑战，显著提升了模型性能和泛化能力。

> **ai_Abstract:** 本文针对SAR图像分辨率差异导致的跨分辨率目标检测模型泛化能力下降问题，提出了一种名为CR-Net的新型方法。CR-Net通过引入结构先验和证据学习理论，实现了可靠的域适应。其核心包括结构诱导分层特征适应（SHFA）模块，用于建立结构关联和实现结构感知特征适应，以及可靠结构邻接对齐（RSAA）模块，用于利用安全邻接集进行语义对齐和知识迁移。实验证明，CR-Net能有效增强跨分辨率适应性，并在SAR目标检测中达到SOTA性能。

> **摘要翻译:** 近年来，SAR分辨率的持续改进极大地促进了城市监测和目标检测等应用。然而，分辨率的提高导致散射特性差异增大，对目标检测模型的泛化能力提出了挑战。尽管域适应技术是一种潜在的解决方案，但分辨率差异不可避免地会导致盲目特征适应和不可靠的语义传播，最终降低域适应性能。为了应对这些挑战，本文提出了一种新颖的SAR目标检测方法（称为CR-Net），该方法将结构先验和证据学习理论融入检测模型，从而实现跨分辨率检测的可靠域适应。具体而言，CR-Net集成了结构诱导分层特征适应（SHFA）和可靠结构邻接对齐（RSAA）。引入SHFA模块旨在建立目标间的结构关联并实现结构感知特征适应，从而增强特征适应过程的可解释性。随后，提出RSAA模块通过利用安全邻接集将有价值的判别知识从源域转移到目标域，以增强可靠的语义对齐。这进一步提高了检测模型在目标域的判别能力。基于不同分辨率数据集的实验结果表明，所提出的CR-Net通过保留域内结构和提高判别能力，显著增强了跨分辨率适应性。它在跨分辨率SAR目标检测中取得了最先进（SOTA）的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [325] [Generalizable 7T T1-map Synthesis from 1.5T and 3T T1 MRI with an Efficient Transformer Model](https://arxiv.org/abs/2507.08655)
> *使用高效Transformer模型从1.5T和3T T1 MRI合成通用7T T1图*

*Zach Eidex, Mojtaba Safari, Tonghe Wang, Vanessa Wildman, David S. Yu, Hui Mao, Erik Middlebrooks, Aparna Kesewala, Xiaofeng Yang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 7T MRI, T1图合成, Transformer模型, 深度学习, 磁共振成像

**Comment:** 

> **TL;DR:** 本文提出了一种名为7T-Restormer的Transformer模型，可以从常规1.5T或3T T1加权图像合成高质量的7T T1图，且性能优于现有SOTA方法，参数量更少，使7T MRI的优势更易于临床应用。

**AI_Comments:** 这项研究的创新之处在于提出了一个高效的Transformer模型（7T-Restormer），能够以更少的参数量实现比现有SOTA方法更好的7T T1图合成效果。其重要性在于通过图像合成技术，降低了7T MRI的临床应用门槛，使得在不具备7T扫描仪的医院也能间接获得7T MRI的某些优势。模型在多发性硬化症患者数据上进行验证，表明其在特定临床场景下的潜在应用价值。研究还强调了多源数据训练的有效性，提升了模型的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 超高场7T MRI提供比标准临床场强（1.5T、3T）更高的分辨率和对比度，但7T扫描仪成本高昂、稀缺，并引入了额外的挑战，如磁敏感伪影。因此，需要一种方法来从更常见的低场强MRI合成7T质量的图像。

**Method:** 本文提出了一种基于Transformer的有效模型（7T-Restormer），用于从常规1.5T或3T T1加权（T1W）图像合成7T质量的T1图。该模型在35例1.5T和108例3T T1w MRI数据上进行了验证，这些数据均配有确诊多发性硬化症患者的相应7T T1图。总共141个病例（32,128个切片）被随机分为训练、验证和测试集。合成的7T T1图与ResViT和ResShift模型进行了比较。研究还探讨了混合1.5T + 3T数据训练策略的优势。

**Result:** 7T-Restormer模型在1.5T输入下，PSNR为26.0 ± 4.6 dB，SSIM为0.861 ± 0.072，NMSE为0.019 ± 0.011；在3T输入下，PSNR为25.9 ± 4.9 dB，SSIM为0.866 ± 0.077。该模型仅使用10.5M参数，相对于56.7M参数的ResShift模型，NMSE降低了64%（0.019 vs 0.052，p < .001）；相对于70.4M参数的ResViT模型，NMSE降低了41%（0.019 vs 0.032，p < .001），在3T输入下也有类似优势。使用混合1.5T + 3T语料库进行训练优于单一场强策略。

**Conclusion:** 本文提出了一种新颖的方法，可以从1.5T和3T T1W扫描中预测定量7T MP2RAGE图，其质量高于现有最先进的方法。该方法使7T MRI的优势更容易应用于标准临床工作流程。

> **ai_Abstract:** 本文提出了一种名为7T-Restormer的高效Transformer模型，旨在解决7T MRI设备昂贵和稀缺的问题。该模型能够从常规1.5T或3T T1加权图像合成高质量的7T T1图。实验结果表明，7T-Restormer在性能上（PSNR, SSIM, NMSE）优于现有的ResViT和ResShift模型，并且参数量显著减少。此外，使用混合1.5T和3T数据进行训练能获得更好的泛化性能。该方法有望使7T MRI的临床优势更易于普及。

> **摘要翻译:** 目的：超高场7T MRI比标准临床场强（1.5T、3T）提供更高的分辨率和对比度。然而，7T扫描仪成本高昂、稀缺，并引入了额外的挑战，如磁敏感伪影。我们提出了一种高效的基于Transformer的模型（7T-Restormer），用于从常规1.5T或3T T1加权（T1W）图像合成7T质量的T1图。方法：我们的模型在35例1.5T和108例3T T1w MRI数据上进行了验证，这些数据均配有确诊多发性硬化症患者的相应7T T1图。总共141个患者病例（32,128个切片）被随机分为105个训练病例（19,204个切片）、19个验证病例（3,476个切片）和17个测试病例（3,145个切片），其中（X；Y）分别表示具有1.5T和3T T1W扫描的患者。合成的7T T1图与ResViT和ResShift模型进行了比较。结果：7T-Restormer模型在1.5T输入下，PSNR为26.0 ± 4.6 dB，SSIM为0.861 ± 0.072，NMSE为0.019 ± 0.011；在3T输入下，PSNR为25.9 ± 4.9 dB，SSIM为0.866 ± 0.077。我们的模型使用10.5M参数，相对于56.7M参数的ResShift模型，NMSE降低了64%（0.019 vs 0.052，p = <.001）；相对于70.4M参数的ResViT模型，NMSE降低了41%（0.019 vs 0.032，p = <.001），在3T输入下也有类似优势（0.021 vs 0.060和0.033；p < .001）。使用混合1.5T + 3T语料库进行训练优于单一场强策略。将模型限制在1.5T训练会使1.5T的NMSE从0.019增加到0.021（p = 1.1E-3），而仅在3T上训练会导致在输入1.5T T1W MRI上的性能下降。结论：我们提出了一种新颖的方法，可以从1.5T和3T T1W扫描中预测定量7T MP2RAGE图，其质量高于现有最先进的方法。我们的方法使7T MRI的优势更容易应用于标准临床工作流程。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [327] [ViLU: Learning Vision-Language Uncertainties for Failure Prediction](https://arxiv.org/abs/2507.07620)
> *ViLU：学习视觉-语言不确定性以进行故障预测*

*Marc Lafon, Yannis Karmim, Julio Silva-Rodríguez, Paul Couairon, Clément Rambour, Raphaël Fournier-Sniehotta, Ismail Ben Ayed, Jose Dolz, Nicolas Thome* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 视觉-语言模型, 不确定性量化, 故障预测, 多模态表示, ViLU

**Comment:** 

> **TL;DR:** ViLU 是一个用于视觉-语言模型 (VLM) 的新框架，通过利用所有任务相关的文本表示来量化不确定性并预测故障。

**AI_Comments:** 该论文提出了一种创新的、损失无关的视觉-语言不确定性量化方法 ViLU，有效解决了 VLM 中可靠故障预测的难题。其独特的将不确定性预测器作为二元分类器训练的策略，以及对事后设置的良好适应性，是其主要创新点。在多模态表示中整合所有任务相关文本信息也增强了不确定性估计的上下文感知能力，这对于提高 VLM 的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型 (VLM) 的可靠不确定性量化 (UQ) 和故障预测仍然是开放的挑战。

**Method:** ViLU 引入了一个新的视觉-语言不确定性量化框架，该框架通过利用所有任务相关的文本表示来情境化不确定性估计。它通过交叉注意力整合视觉嵌入、预测的文本嵌入和图像条件文本表示，构建了一个不确定性感知的多模态表示。ViLU 将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确和不正确的预测，使其与损失无关。该方法特别适用于事后设置，即只有视觉和文本嵌入可用，而无需直接访问模型本身。

**Result:** 在各种数据集上的大量实验表明，与最先进的故障预测方法相比，ViLU 取得了显著的提升。该方法应用于标准分类数据集（如 ImageNet-1k）以及大规模图像-字幕数据集（如 CC12M 和 LAION-400M）。消融研究强调了其架构和训练在实现有效不确定性量化方面的关键作用。

**Conclusion:** ViLU 框架通过其创新的架构和训练方法，有效地解决了视觉-语言模型中的不确定性量化和故障预测挑战，并在各种数据集上表现出优越的性能。

> **ai_Abstract:** ViLU 是一种新颖的视觉-语言不确定性量化框架，旨在解决视觉-语言模型中的故障预测挑战。它通过整合视觉和文本嵌入来构建不确定性感知的多模态表示，并训练一个损失无关的二元分类器来区分正确和错误的预测。该方法特别适用于事后分析，并在多个数据集上显示出优于现有方法的显著性能提升。

> **摘要翻译:** 可靠的不确定性量化 (UQ) 和故障预测仍然是视觉-语言模型 (VLM) 面临的开放挑战。我们引入了 ViLU，一个新颖的视觉-语言不确定性量化框架，它通过利用所有任务相关的文本表示来情境化不确定性估计。ViLU 通过交叉注意力整合视觉嵌入、预测的文本嵌入和图像条件文本表示，构建了一个不确定性感知的多模态表示。与基于损失预测的传统 UQ 方法不同，ViLU 将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确和不正确的预测，使其与损失无关。特别是，我们提出的方法非常适合事后设置，即只有视觉和文本嵌入可用，而无需直接访问模型本身。在各种数据集上的大量实验表明，与最先进的故障预测方法相比，我们的方法取得了显著的提升。我们将我们的方法应用于标准分类数据集，例如 ImageNet-1k，以及大规模图像-字幕数据集，例如 CC12M 和 LAION-400M。消融研究强调了我们的架构和训练在实现有效不确定性量化方面的关键作用。我们的代码是公开可用的，可以在这里找到：https://github.com/ykrmm/ViLU。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [331] [FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion](https://arxiv.org/abs/2412.09626)
> *FreeScale：通过免调谐尺度融合释放扩散模型的图像分辨率*

*Haonan Qiu, Shiwei Zhang, Yujie Wei, Ruihang Chu, Hangjie Yuan, Xiang Wang, Yingya Zhang, Ziwei Liu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 扩散模型, 高分辨率生成, 尺度融合, 免调谐, 8k生成

**Comment:** ICCV 2025, Project Page:
  http://haonanqiu.com/projects/FreeScale.html, Code Repo:
  https://github.com/ali-vilab/FreeScale

> **TL;DR:** FreeScale是一种免调谐的推理范式，通过尺度融合解决了扩散模型生成高分辨率图像时出现的重复模式问题，首次实现了8k文本到图像生成。

**AI_Comments:** FreeScale的创新之处在于提出了一种免调谐的尺度融合方法，有效地解决了扩散模型在高分辨率生成中因高频信息增加导致的重复模式问题，显著提升了生成图像和视频的质量和分辨率，尤其是在8k文本到图像生成方面取得了突破性进展。

<details>
  <summary>Details</summary>

**Motivation:** 视觉扩散模型受限于训练数据和计算资源，难以生成高保真高分辨率图像或视频。现有免调谐策略在高分辨率生成时易产生低质量和重复模式，原因是模型生成超出训练分辨率的视觉内容时，高频信息增加，导致累积误差产生重复模式。

**Method:** 本文提出了FreeScale，一种免调谐推理范式，通过尺度融合实现更高分辨率的视觉生成。具体地，FreeScale处理来自不同感受野尺度的信息，并通过提取期望的频率分量进行融合。

**Result:** 大量实验验证了FreeScale在扩展图像和视频模型高分辨率视觉生成能力方面的优越性。与之前表现最佳的方法相比，FreeScale首次实现了8k分辨率文本到图像生成。

**Conclusion:** FreeScale通过其独特的尺度融合方法，成功克服了扩散模型在高分辨率生成中遇到的挑战，显著提升了生成内容的质量和分辨率，特别是首次实现了8k文本到图像生成。

> **ai_Abstract:** 本文提出了FreeScale，一种免调谐的推理范式，旨在解决扩散模型在生成高分辨率图像和视频时遇到的重复模式问题。通过处理来自不同感受野尺度的信息并提取期望的频率分量进行融合，FreeScale成功提升了高分辨率视觉生成能力。实验证明其优越性，并首次实现了8k文本到图像生成。

> **摘要翻译:** 视觉扩散模型取得了显著进展，但由于缺乏高分辨率数据和计算资源限制，它们通常在有限分辨率下训练，这阻碍了它们生成更高分辨率高保真图像或视频的能力。最近的研究探索了免调谐策略，以展现预训练模型未被开发的更高分辨率视觉生成潜力。然而，这些方法仍然容易产生带有重复模式的低质量视觉内容。关键障碍在于，当模型生成超出其训练分辨率的视觉内容时，高频信息不可避免地增加，导致累积误差产生不希望的重复模式。为了解决这一挑战，我们提出了FreeScale，一种免调谐推理范式，通过尺度融合实现更高分辨率的视觉生成。具体而言，FreeScale处理来自不同感受野尺度的信息，然后通过提取期望的频率分量进行融合。大量的实验验证了我们范式在扩展图像和视频模型高分辨率视觉生成能力方面的优越性。值得注意的是，与之前表现最佳的方法相比，FreeScale首次解锁了8k分辨率的文本到图像生成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [340] [MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing](https://arxiv.org/abs/2507.08683)
> *MoSAiC：面向遥感的跨模态多标签监督感知对比学习*

*Debashis Gupta, Aditi Golder, Rongkhun Zhu, Kangning Cui, Wei Tang, Fan Yang, Ovidiu Csillik, Sarra Alaqahtani, V. Paul Pauca* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 对比学习, 多模态, 多标签, 遥感, 监督学习

**Comment:** 

> **TL;DR:** MoSAiC是一个针对遥感图像的统一框架，它结合了模态内和模态间对比学习以及多标签监督对比损失，以在低标签和高类别重叠场景下实现更鲁棒的表示学习。

**AI_Comments:** MoSAiC的创新之处在于其将多标签监督信息引入多模态对比学习框架，这对于处理遥感图像中常见的复杂性（如高类间相似性和多标签特性）至关重要。它有效弥补了传统对比学习在处理跨模态语义对齐方面的不足，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 对比学习在计算机视觉任务中表现出色，但地球系统观测（ESO）面临独特的挑战，如类间相似性高、场景杂乱和边界模糊，这使得在低标签、多标签设置下表示学习复杂化。现有对比学习框架通常侧重于模态内自监督，或缺乏跨模态的多标签对齐和语义精确性机制。

**Method:** 本文提出了MoSAiC，一个统一的框架，它结合了模态内和模态间对比学习，并引入了多标签监督对比损失。MoSAiC专为多模态卫星图像设计，旨在实现更精细的语义解耦和更鲁棒的表示学习。

**Result:** 在BigEarthNet V2.0和Sent12MS两个基准数据集上的实验表明，MoSAiC在低标签和高类别重叠场景下，在准确性、聚类一致性和泛化能力方面均优于完全监督和自监督基线方法。

**Conclusion:** MoSAiC通过将监督信息融入对比学习，有效地解决了多模态遥感图像表示学习中的挑战，特别是在低标签和多标签复杂场景下，提供了更鲁棒和语义精确的特征表示。

> **ai_Abstract:** MoSAiC是一个为多模态遥感图像设计的统一对比学习框架。它解决了地球系统观测中，现有对比学习在低标签、多标签复杂场景下，缺乏跨模态语义对齐和精确性的问题。MoSAiC通过联合优化模态内和模态间对比学习，并集成多标签监督对比损失，实现了更精细的语义解耦和鲁棒的表示学习。实验证明，MoSAiC在准确性、聚类一致性和泛化能力方面均优于现有基线方法。

> **摘要翻译:** 对比学习（CL）已成为一种强大的范式，用于在不依赖大型标记数据集的情况下学习可迁移的表示。它捕捉数据样本内在相似性和差异的能力，在计算机视觉任务中取得了最先进的成果。这些优势使得CL特别适合地球系统观测（ESO），其中光学和SAR图像等多样化的卫星模态为同一地理空间区域提供了自然对齐的视图。然而，ESO也带来了独特的挑战，包括高类间相似性、场景杂乱和模糊边界，这使得表示学习复杂化——尤其是在低标签、多标签设置中。现有的CL框架通常侧重于模态内自监督，或缺乏跨模态的多标签对齐和语义精确性机制。在这项工作中，我们引入了MoSAiC，一个统一的框架，它结合了模态内和模态间对比学习，并引入了多标签监督对比损失。MoSAiC专为多模态卫星图像设计，旨在实现更精细的语义解耦和更鲁棒的表示学习，以应对光谱相似和空间复杂的类别。在两个基准数据集BigEarthNet V2.0和Sent12MS上的实验表明，MoSAiC在低标签和高类别重叠场景下，在准确性、聚类一致性和泛化能力方面均持续优于完全监督和自监督基线方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way](https://arxiv.org/abs/2507.08679)
> *ByDeWay：以免训练方式通过深度提示增强多模态大型语言模型*

*Rajarshi Roy, Devleena Das, Ankesh Banerjee, Arjya Bhattacharjee, Kousik Dasgupta, Subarna Tripathi* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多模态大型语言模型, 深度提示, 免训练, 空间推理, 幻觉减少

**Comment:** 

> **TL;DR:** ByDeWay是一个免训练框架，通过分层深度提示（LDP）增强多模态大型语言模型（MLLMs）的空间推理和接地能力，减少幻觉，提高在POPE和GQA基准上的表现。

**AI_Comments:** ByDeWay的创新之处在于其“免训练”的特性和独特的“分层深度提示”策略。它通过在提示中融入深度信息，有效提升了多模态大型语言模型的空间推理和接地能力，同时减少了幻觉，而无需对现有模型进行任何参数修改，这对于实际应用中集成和部署黑盒MLLMs具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在提升多模态大型语言模型（MLLMs）的性能，特别是改善其空间推理和接地能力，并减少幻觉现象，且不需修改模型参数。

**Method:** ByDeWay框架采用一种名为分层深度提示（LDP）的新颖提示策略。它利用单目深度估计将场景分割成最近、中等和最远层，然后使用一个接地视觉-语言模型生成区域特定的描述。这些结构化、深度感知的描述被附加到图像-问题提示中，以丰富空间上下文，从而引导MLLMs生成更接地、更少幻觉的响应。该方法是轻量级、模块化且兼容黑盒MLLMs。

**Result:** 在对幻觉敏感的POPE和推理密集的GQA基准测试中，ByDeWay在多个MLLMs上显示出一致的性能提升，验证了深度感知提示在零训练设置下的有效性。

**Conclusion:** 该论文得出结论，通过深度感知提示，ByDeWay框架能够有效增强多模态大型语言模型的空间推理和接地能力，并在无需训练的情况下减少幻觉。

> **ai_Abstract:** ByDeWay是一个免训练框架，通过引入分层深度提示（LDP）策略来增强多模态大型语言模型（MLLMs）。该方法通过单目深度估计将场景分层，并生成深度感知的区域描述，然后将其附加到图像-问题提示中，以提供丰富的空间上下文。这有助于MLLMs提高空间推理能力、更好地接地并减少幻觉。实验证明，ByDeWay在POPE和GQA等基准测试上对多种MLLMs均有显著改进。

> **摘要翻译:** 我们引入了ByDeWay，一个旨在提升多模态大型语言模型（MLLMs）性能的免训练框架。ByDeWay采用一种名为分层深度提示（LDP）的新颖提示策略，它在不修改任何模型参数的情况下改善了空间推理和接地能力。它利用单目深度估计将场景分割成最近、中等和最远层，然后使用一个接地视觉-语言模型生成区域特定的描述。这些结构化、深度感知的描述被附加到图像-问题提示中，用空间上下文丰富了提示。这引导MLLMs产生更接地、更少幻觉的响应。我们的方法轻量、模块化，并与黑盒MLLMs兼容。在对幻觉敏感的POPE和推理密集的GQA基准测试上的实验表明，在多个MLLMs上均有持续改进，验证了深度感知提示在零训练设置下的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [352] [T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates](https://arxiv.org/abs/2507.07633)
> *轨迹引导的超低比特率生成视频编码*

*Zhitao Wang, Hengyu Man, Wenrui Li, Xingtao Wang, Xiaopeng Fan, Debin Zhao* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-11**

**Keywords:** 生成视频编码, 超低比特率, 轨迹引导, 稀疏运动采样, 扩散模型

**Comment:** 

> **TL;DR:** 提出了一种轨迹引导的生成视频编码框架（T-GVC），通过稀疏轨迹点有效捕捉运动细节，并在超低比特率下实现逼真的重建，优于传统编解码器和最先进的端到端视频压缩方法。

**AI_Comments:** 该研究提出了一种新颖的轨迹引导方法，用于解决超低比特率下的生成视频编码问题。通过将运动跟踪与语义理解相结合，并利用扩散模型实现训练无关的潜在空间引导，T-GVC在运动细节捕捉和重建真实性方面取得了显著进展，为未来的视频压缩技术提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成视频编码方法在超低比特率场景下存在域特异性或过度依赖文本引导的问题，导致运动细节捕捉不足和重建不真实。

**Method:** 提出T-GVC框架，采用语义感知的稀疏运动采样流程，提取像素级运动的稀疏轨迹点，并结合轨迹对齐的损失约束到扩散过程中，实现训练无关的潜在空间引导。

**Result:** T-GVC在超低比特率条件下性能优于传统编解码器和最先进的端到端视频压缩方法，并且比现有的文本引导方法具有更精确的运动控制。

**Conclusion:** T-GVC通过几何运动建模为生成视频编码开辟了新的方向，在超低比特率下实现了更精确的运动控制和更逼真的重建。

> **ai_Abstract:** T-GVC是一种新颖的生成视频编码框架，通过利用语义感知的稀疏运动采样和轨迹对齐的损失约束，在超低比特率下有效捕捉运动细节并实现逼真的重建，克服了现有方法的局限性。

> **摘要翻译:** 近期视频生成技术的进步催生了一种新兴的生成视频编码范式，旨在通过利用强大的生成先验在超低比特率（ULB）场景下实现语义精确的重建。然而，大多数现有方法受限于领域特异性（例如，面部或人物视频）或过度依赖高级文本引导，这通常无法捕捉运动细节并导致不真实的重建。为了解决这些挑战，我们提出了一个轨迹引导的生成视频编码框架（T-GVC）。T-GVC采用语义感知的稀疏运动采样流程，通过提取基于语义重要性的像素级运动作为稀疏轨迹点，有效地将低级运动跟踪与高级语义理解相结合，不仅显著降低了比特率，而且保留了关键的时间语义信息。此外，通过将轨迹对齐的损失约束整合到扩散过程中，我们引入了一种训练无关的潜在空间引导机制，以确保物理上合理的运动模式，同时不牺牲生成模型固有的能力。实验结果表明，在ULB条件下，我们的框架在性能上优于传统编解码器和最先进的端到端视频压缩方法。此外，附加实验证实，我们的方法比现有的文本引导方法实现了更精确的运动控制，为由几何运动建模引导的新型生成视频编码方向铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [359] [M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation](https://arxiv.org/abs/2507.08307)
> *M2DAO-Talker：协调多粒度运动解耦和交替优化以生成说话人头部动画*

*Kui Jiang, Shiyu Liu, Junjun Jiang, Xin Yang, Hongxun Yang, Xiaopeng Fan* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 说话人头部生成, 运动解耦, 交替优化, 渲染伪影, 音频驱动

**Comment:** 

> **TL;DR:** M2DAO-Talker通过多粒度运动解耦和交替优化，解决了现有3D方法在说话人头部生成中存在的渲染伪影问题，实现了SOTA性能和高推理速度。

**AI_Comments:** 这篇论文的创新点在于提出了多粒度运动解耦和交替优化策略，有效解决了3D说话人头部生成中常见的渲染伪影问题。通过将运动分为刚性和非刚性并独立处理，同时引入运动一致性约束，显著提升了生成视频的真实感和稳定性。其高推理速度也显示了实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D说话人头部生成方法在运动建模和内容合成方面有进步，但由于难以表示稳定、细粒度的运动场，常产生渲染伪影，如运动模糊、时间抖动和局部穿透。

**Method:** 本研究将说话人头部生成重构为统一框架，包含视频预处理、运动表示和渲染重建。在此框架下，提出了M2DAO-Talker模型。该模型设计了新型2D肖像预处理流程，用于提取逐帧变形控制条件。为改善运动建模，采用了多粒度运动解耦策略，独立建模非刚性（口部和面部）和刚性（头部）运动。同时，开发了运动一致性约束以确保头身运动学一致性，并设计了交替优化策略来迭代细化面部和口部运动参数。

**Result:** M2DAO-Talker在多个数据集上实现了最先进的性能，生成质量PSNR提升了2.43 dB，用户评估视频真实感相对TalkingGaussian提升了0.64，同时推理速度达到150 FPS。

**Conclusion:** M2DAO-Talker通过其独特的多粒度运动解耦和交替优化策略，显著提升了音频驱动说话人头部生成的质量和真实感，并有效解决了现有方法中的渲染伪影问题，达到了领先水平。

> **ai_Abstract:** M2DAO-Talker是一种新型的音频驱动说话人头部生成框架，旨在解决现有3D方法中的渲染伪影问题。它将生成过程分解为视频预处理、运动表示和渲染重建，并引入了多粒度运动解耦和交替优化策略。通过独立建模非刚性和刚性运动，结合运动一致性约束和参数迭代优化，M2DAO-Talker显著提升了生成质量和视频真实感，并实现了高推理速度，达到了SOTA水平。

> **摘要翻译:** 音频驱动的说话人头部生成在电影制作中具有巨大的潜力。虽然现有的3D方法在运动建模和内容合成方面取得了进展，但由于在表示稳定、细粒度运动场方面的局限性，它们经常产生渲染伪影，例如运动模糊、时间抖动和局部穿透。通过系统分析，我们将说话人头部生成重新构想为一个统一的框架，包括三个步骤：视频预处理、运动表示和渲染重建。该框架支撑了我们提出的M2DAO-Talker，它通过多粒度运动解耦和交替优化解决了当前的局限性。具体来说，我们设计了一种新颖的2D肖像预处理流程，以提取逐帧变形控制条件（运动区域分割掩码和相机参数），从而促进运动表示。为了改善运动建模，我们详细阐述了一种多粒度运动解耦策略，该策略独立建模非刚性（口部和面部）和刚性（头部）运动，以提高重建精度。同时，开发了一种运动一致性约束，以确保头身运动学一致性，从而减轻由运动混叠引起的穿透伪影。此外，设计了一种交替优化策略，以迭代细化面部和口部运动参数，从而实现更逼真的视频生成。在多个数据集上的实验表明，M2DAO-Talker实现了最先进的性能，与TalkingGaussian相比，生成质量PSNR提高了2.43 dB，用户评估视频真实感提高了0.64，同时推理速度达到150 FPS。我们的项目主页是https://m2dao-talker.github.io/M2DAO-Talk.github.io

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [361] [SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer](https://arxiv.org/abs/2412.11540)
> *SP$^2$T：用于双流点变换器的稀疏代理注意力*

*Jiaxu Wan, Hong Zhang, Ziqi He, Yangyan Deng, Qishu Wang, Ding Yuan, Yifan Yang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 点变换器, 稀疏代理注意力, 双流架构, 3D理解, 点云

**Comment:** Accept by ICCV2025

> **TL;DR:** SP$^2$T 是一种新的局部代理双流点变换器，通过空间采样、稀疏代理注意力和双流架构解决了现有代理点云方法中的可靠采样、高效交互和局部-全局信息融合问题，在3D理解基准上取得了最先进的结果。

**AI_Comments:** 这篇论文通过引入稀疏代理注意力机制和双流架构，有效地解决了点变换器在处理大规模点云时感受野扩展与细节特征提取之间的矛盾，以及现有代理方法在采样、交互和信息融合上的局限性。其创新点在于结合了局部代理的优点并克服了其缺点，通过具体的技术细节（空间代理采样、稀疏代理注意力、双流架构）实现了性能的显著提升，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于代理的点云方法存在局限性：全局代理对大规模点云计算复杂度高且存在位置模糊性；局部代理存在不可靠采样、低效代理交互计算和局部-全局信息融合不平衡问题。

**Method:** 提出稀疏代理点变换器 (SP$^2$T)，一个基于局部代理的双流点变换器，具有三项创新：1) 采用基于顶点的关联空间代理采样实现可靠采样；2) 通过带有基于表格的相对偏差的稀疏代理注意力实现高效的map-reduce计算以进行高效代理交互；3) 通过并行分支的双流架构保持局部-全局平衡以进行局部-全局信息融合。

**Result:** SP$^2$T 在室内和室外3D理解基准上达到了最先进的结果，且延迟可接受。与现有基于代理的点云方法相比，性能显著提升（S3DIS上mIoU提升3.8%，Sem.KITTI上mIoU提升22.9%）。

**Conclusion:** SP$^2$T 有效解决了现有代理点云方法面临的挑战，并在3D理解任务中取得了优异的性能，证明了其在处理大规模和几何多样性点云方面的有效性。

> **ai_Abstract:** 本文提出SP$^2$T，一种稀疏代理双流点变换器，旨在解决现有代理点云方法在可靠采样、高效代理交互和局部-全局信息融合方面的挑战。SP$^2$T通过空间代理采样实现鲁棒采样，通过稀疏代理注意力实现高效交互，并通过双流架构平衡局部-全局信息。实验证明，SP$^2$T在3D理解任务中达到了最先进的性能，显著优于其他代理方法。

> **摘要翻译:** 点变换器通过扩展感受野（RF）在3D理解方面取得了显著进展，但进一步扩展感受野会导致组注意力稀释并降低详细特征提取能力。代理作为简化特征图的抽象表示，能够实现全局感受野。然而，现有的基于代理的方法面临关键局限性：全局代理对大规模点云会产生二次复杂度并遭受位置模糊性，而局部代理替代方案则面临1）从几何多样性点云中不可靠采样，2）低效的代理交互计算，以及3）不平衡的局部-全局信息融合等问题。为了解决这些挑战，我们提出了稀疏代理点变换器（SP$^2$T）——一种基于局部代理的双流点变换器，具有三项关键创新：首先，为了实现可靠采样，采用基于顶点的空间代理采样实现了对几何多样性点云的鲁棒采样。其次，为了实现高效的代理交互，带有基于表格的相对偏差的稀疏代理注意力有效地通过高效的map-reduce计算实现了交互。第三，为了实现局部-全局信息融合，我们的双流架构通过并行分支保持局部-全局平衡。全面的实验表明，SP$^2$T 在室内和室外3D理解基准上取得了最先进的结果，且延迟可接受，与现有基于代理的点云方法相比，显示出显著改进（S3DIS上mIoU提升3.8%，Sem.KITTI上mIoU提升22.9%）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays](https://arxiv.org/abs/2507.07722)
> *理解医学影像中的数据集偏差：一项关于胸部X光片的案例研究*

*Ethan Dack, Chengliang Dai* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 数据集偏差, 医学影像, 胸部X光片, 命名数据集, 可解释性AI

**Comment:** 

> **TL;DR:** 该研究在胸部X光片数据集上进行了“命名数据集”任务，以评估医学影像数据集是否存在偏差。研究者应用了简单的数据转换，并使用多种网络架构（NIH、CheXpert、MIMIC-CXR和PadChest）进行了分析，旨在识别和解释偏差，并鼓励更具可解释性的医学影像研究和更多开放数据集的创建。

**AI_Comments:** 这项研究对于理解和缓解医学影像AI模型中的数据集偏差至关重要。通过在常用的胸部X光片数据集上进行“命名数据集”任务，研究者有效地揭示了潜在的偏差来源。方法论清晰，结合了数据转换和多种网络架构的分析，为识别偏差提供了有力的证据。然而，研究可能可以进一步探讨这些偏差对下游AI模型性能的具体影响，并提出更具体的缓解策略。总的来说，这项工作为提高医学影像AI的鲁棒性和可信度奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 由于医学影像的敏感性，开放获取的数据集有限，导致某些数据集被过度使用。本研究旨在探索胸部X光片数据集是否存在数据集偏差，以确保AI在医学影像中的应用是关注相关病理，而不是利用数据集的捷径。

**Method:** 研究者在NIH、CheXpert、MIMIC-CXR和PadChest这四个公开的胸部X光片数据集上应用了“命名数据集”任务。他们对数据集进行了简单的转换，并使用多种不同的网络架构进行了实验，然后分析结果以识别和解释任何检测到的偏差。

**Result:** 研究结果表明，在所分析的胸部X光片数据集中确实存在数据集偏差。研究者通过实验证明了这些偏差的存在，并对其进行了分析和解释。

**Conclusion:** 该研究证实了在流行的胸部X光片数据集中存在数据集偏差，这可能导致AI模型学习到与数据集来源相关的捷径，而非真正的病理特征。研究强调了在医学影像领域进行可解释性研究和创建更多样化开放数据集的重要性。

> **ai_Abstract:** 本研究旨在探究流行的胸部X光片数据集（NIH、CheXpert、MIMIC-CXR和PadChest）是否存在数据集偏差。研究者通过在这些数据集上执行“命名数据集”任务，并结合简单的数据转换和多种网络架构分析，以识别和解释偏差的存在。此举是为了确保医学影像AI应用关注实际病理而非数据集捷径，并推动医学影像领域的可解释性研究和开放数据集的建设。

> **摘要翻译:** 近期研究重新审视了臭名昭著的“命名那个数据集”任务，证明了非医学数据集包含潜在的偏差，并且可以高精度地解决数据集来源任务。在本研究中，我们重新审视了应用于流行的开源胸部X光数据集的相同任务。由于其敏感性，医学图像在开源方面天然更难发布，这导致某些开源数据集在研究中极其受欢迎。通过执行相同的任务，我们希望探索这些数据集中是否存在数据集偏差。为了扩展我们的工作，我们对数据集应用了简单的转换，重复了相同的任务，并进行了分析以识别和解释任何检测到的偏差。鉴于人工智能在医学影像中的应用至关重要，因此必须确定现代方法是采取了捷径还是专注于相关病理。我们在数据集上实现了多种不同的网络架构：NIH、CheXpert、MIMIC-CXR和PadChest。我们希望这项工作能鼓励在医学影像领域进行更多的可解释性研究，并创建更多的医学领域开源数据集。我们的代码可以在这里找到：https://github.com/eedack01/x_ray_ds_bias。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [An Efficient Approach for Muscle Segmentation and 3D Reconstruction Using Keypoint Tracking in MRI Scan](https://arxiv.org/abs/2507.08690)
> *一种使用关键点跟踪进行肌腱分割和三维重建的高效方法*

*Mengyuan Liu, Jeongkyu Lee* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 肌腱分割, 关键点跟踪, Lucas-Kanade光流, MRI, 计算效率

**Comment:** 

> **TL;DR:** 提出一种无需训练的基于关键点跟踪的肌腱分割方法，通过集成关键点选择和Lucas-Kanade光流实现，计算成本低，可解释性强，性能与最先进的CNN模型相当。

**AI_Comments:** 该研究提出的基于关键点跟踪的分割方法在解决计算成本和可解释性方面具有显著优势，尤其是在处理小型肌腱时。然而，0.6-0.7的DSC范围表明在分割精度上仍有提升空间，未来的研究可以关注优化关键点选择策略或结合其他技术来进一步提高精度。该方法的可扩展性和鲁棒性使其在实际应用中具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动肌腱分割方法计算成本高，依赖大型训练数据集，且在分割小型肌腱时准确性较低。基于CNN的方法计算开销大，泛化能力有限，且可解释性差。

**Method:** 提出一种基于关键点跟踪的无需训练的分割方法，该方法集成了关键点选择和Lucas-Kanade光流。

**Result:** 所提出的方法实现了0.6到0.7的平均Dice相似系数（DSC），具体取决于关键点的选择策略，其性能与最先进的基于CNN的模型相当，同时显著降低了计算需求并提高了可解释性。

**Conclusion:** 该方法为临床和研究应用提供了一种可扩展、鲁棒且可解释的肌腱分割替代方案。

> **ai_Abstract:** 本研究提出了一种创新的、无需训练的肌腱分割方法，利用关键点跟踪和Lucas-Kanade光流技术。该方法解决了现有自动分割方法计算成本高、泛化能力差和可解释性不足的问题。实验结果表明，该方法在保持与最先进CNN模型相当的性能的同时，显著降低了计算复杂度并提高了模型的可解释性，为临床和研究应用提供了一个有前景的解决方案。

> **摘要翻译:** 磁共振成像（MRI）能够对肌肉结构进行非侵入性、高分辨率的分析。然而，自动分割仍然受到高计算成本、依赖大型训练数据集以及分割小型肌肉准确性降低的限制。基于卷积神经网络（CNN）的方法虽然功能强大，但通常存在显著的计算开销、有限的泛化能力以及在不同人群中可解释性差等问题。本研究提出了一种基于关键点跟踪的无需训练的分割方法，该方法集成了关键点选择和Lucas-Kanade光流。所提出的方法实现了0.6到0.7的平均Dice相似系数（DSC），具体取决于关键点的选择策略，其性能与最先进的基于CNN的模型相当，同时显著降低了计算需求并提高了可解释性。该可扩展框架为临床和研究应用提供了一种鲁棒且可解释的肌腱分割替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [387] [Synergistic Prompting for Robust Visual Recognition with Missing Modalities](https://arxiv.org/abs/2507.07802)
> *用于具有缺失模态的鲁棒视觉识别的协同提示*

*Zhihui Zhang, Luanyuan Dai, Qika Lin, Yunfeng Diao, Guangyin Jin, Yufei Guo, Jing Zhang, Xiaoshuai Hao* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多模态学习, 视觉识别, 缺失模态, 提示学习, 鲁棒性

**Comment:** 

> **TL;DR:** 该研究提出了一种名为SyP的新框架，通过动态适配器和协同提示策略来解决多模态模型在输入模态缺失时的性能下降问题，并在三个数据集上取得了显著改进。

**AI_Comments:** 该研究提出的SyP框架在解决多模态模型缺失模态问题上具有创新性，通过动态适配器和协同提示策略提高了模型的鲁棒性和适应性。然而，文章可能需要提供更多关于动态适配器如何计算缩放因子以及协同提示策略如何具体平衡信息的细节。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于提示的方法在处理缺失模态时存在静态提示缺乏灵活性和基本提示调优方法在关键模态缺失时性能不可靠的问题。

**Method:** 提出SyP框架，包括一个动态适配器，用于动态生成提示，以及一个协同提示策略，结合静态和动态提示来平衡模态信息。

**Result:** SyP在三个广泛使用的视觉识别数据集上显著优于现有方法，在各种缺失率和条件下都表现出鲁棒性，并且在处理缺失模态方面具有优越的适应性和可靠性。

**Conclusion:** SyP框架通过动态适配器和协同提示策略有效解决了多模态模型在输入模态缺失时的性能下降问题，提高了模型的鲁棒性、适应性和可靠性。

> **ai_Abstract:** 为了解决多模态模型在输入模态缺失时的性能下降问题，本研究提出了Synergistic Prompting (SyP)框架。该框架通过引入动态适配器来生成适应性提示，并结合静态和动态提示的协同策略，以平衡跨模态信息。实验结果表明，SyP在处理缺失模态方面表现出优越的适应性和可靠性，并在多个数据集上超越了现有方法。

> **摘要翻译:** 大规模多模态模型通过利用广泛的配对多模态训练数据，在各种视觉识别任务中表现出卓越的性能。然而，在实际应用中，输入模态缺失或不完整通常会导致性能显著下降。最近的研究集中于基于提示的策略来解决这个问题；然而，现有方法受到两个主要限制的阻碍：（1）静态提示缺乏适应不同缺失数据条件的灵活性，以及（2）基本提示调优方法在关键模态缺失时难以确保可靠的性能。为了解决这些挑战，我们提出了一种新颖的协同提示（SyP）框架，用于具有缺失模态的鲁棒视觉识别。提出的SyP引入了两项关键创新：（I）动态适配器，它计算自适应缩放因子以动态生成提示，取代静态参数以实现灵活的多模态适应；（II）协同提示策略，它结合静态和动态提示来平衡模态信息，即使在关键模态缺失时也能确保鲁棒的推理。提出的SyP在三个广泛使用的视觉识别数据集上的性能显著优于现有方法，在各种缺失率和条件下都表现出鲁棒性，其在处理缺失模态方面的有效性得到了广泛实验和消融研究的验证，凸显了其优越的适应性和可靠性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [Cross-Domain Identity Representation for Skull to Face Matching with Benchmark DataSet](https://arxiv.org/abs/2507.08329)
> *颅骨到面部匹配的跨域身份表示及基准数据集*

*Ravi Shankar Prasad, Dinesh Singh* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 颅骨识别, 面部匹配, 跨域表示, Siamese网络, 法医科学

**Comment:** 7 pages, 12 figures, Pattern Recognition Letters

> **TL;DR:** 该研究提出了一种使用卷积Siamese网络进行跨域身份表示的框架，用于通过颅骨X光图像识别个人身份。研究人员创建了一个包含40名志愿者颅骨X光和面部图像的数据集，并在该数据集上训练和验证了Siamese网络，取得了令人满意的识别结果。

**AI_Comments:** 该研究在法医身份识别领域提出了一个新颖的方法，利用Siamese网络进行跨域匹配，并构建了一个专门的数据集来支持这项工作。然而，数据集的规模（40名志愿者）可能相对较小，这可能会限制模型在更广泛人群中的泛化能力。未来的工作可以考虑扩大数据集规模并探索其他跨域匹配技术。

<details>
  <summary>Details</summary>

**Motivation:** 法医科学中的颅面重建对于识别犯罪和灾难受害者至关重要，目标是利用深度学习等计算机视觉的最新进展，将给定的颅骨与其在已知身份的面部库相匹配。

**Method:** 提出了一种使用卷积Siamese网络进行跨域身份表示的框架。Siamese网络通过共享相同的架构进行训练，以发现一个特征空间，将相似的观测分组，并将不相似的观测分开。通过最小化相似对之间的欧氏距离并最大化不相似对之间的距离来实现。研究人员还创建了一个包含40名志愿者颅骨X光图像和光学面部图像的数据集。

**Result:** 在收集的跨域数据集上进行的实验表明，该Siamese网络框架在通过给定的颅骨识别个人身份方面取得了令人满意的结果。

**Conclusion:** 所提出的基于卷积Siamese网络的跨域身份表示框架能够有效地区分和匹配颅骨与面部图像，为法医身份识别提供了有前景的解决方案。

> **ai_Abstract:** 本研究提出了一种利用卷积Siamese网络进行跨域身份表示的框架，以解决法医科学中通过颅骨X光图像识别个人身份的问题。研究人员构建了一个包含颅骨X光和面部图像的独特数据集，并成功训练了Siamese网络，证明了该方法在身份匹配任务上的有效性。

> **摘要翻译:** 法医科学中的颅面重建对于识别犯罪和灾难的受害者至关重要。目标是利用计算机视觉的最新进展，例如深度学习，将给定的颅骨与其在已知身份的面部库进行匹配。在本文中，我们提出了一个框架，用于通过颅骨X光图像识别个人身份，使用卷积Siamese网络进行跨域身份表示。Siamese网络是共享相同架构的双胞胎网络，可以进行训练以发现一个特征空间，其中相似的观测被分组在一起，不相似的观测被分开。为此，网络会暴露于两组相似和不同的数据。然后，最小化相似对之间的欧氏距离，并最大化不相似对之间的距离。由于很难获得颅骨和面部图像对，我们自己准备了一个包含40名志愿者的数据集，收集了他们的正面和侧面颅骨X光图像以及光学面部图像。在收集的跨域数据集上进行了实验，以训练和验证Siamese网络。实验结果在通过给定的颅骨识别个人身份方面提供了令人满意的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [396] [ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images](https://arxiv.org/abs/2502.05928)
> *用于多任务医学图像的跨模态临床知识蒸馏器ClinKD*

*Hongyu Ge, Longkun Hao, Zihui Xu, Zhenxin Lin, Bin Li, Shoujun Zhou, Hongjin Zhao, Yihang Liu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 医学视觉问答, 多模态大语言模型, 知识蒸馏, 图像-文本对齐, 临床知识

**Comment:** 

> **TL;DR:** 该研究提出了一种名为ClinKD的框架，用于解决多任务医学视觉问答（Med-VQA）中多模态大语言模型（MLLMs）在处理医学图像时存在的空间定位错误和领域知识不足的问题。ClinKD通过增强图像-文本对齐和改进医学知识转换机制，使MLLMs在缺乏先验医学知识的情况下也能表现更好，并在多个Med-VQA数据集上达到了最先进的性能。

**AI_Comments:** 该研究提出的ClinKD框架在解决Med-VQA领域MLLMs的局限性方面具有创新性，通过结合知识蒸馏和跨模态学习来增强模型在医学图像理解上的能力。其在多个数据集上取得最先进性能的实验结果，证明了该方法的有效性。然而，该方法在实际临床应用中的泛化能力和可解释性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在处理多任务医学视觉问答（Med-VQA）时，存在图像-文本对齐不足和领域知识不足的问题，导致空间定位错误和图像误解。

**Method:** 提出了一种名为ClinKD（Cross-Modal Clinical Knowledge Distiller）的框架，旨在增强图像-文本对齐和改进医学知识转换机制。

**Result:** ClinKD在多个具有挑战性的Med-VQA数据集上取得了最先进的性能，显著提高了图像-文本对齐能力，并有效使MLLMs适应了医学知识。

**Conclusion:** ClinKD框架能够有效提升MLLMs在Med-VQA任务上的表现，通过增强图像-文本对齐和知识转换机制解决了现有模型的局限性。

> **ai_Abstract:** 本研究提出ClinKD框架，旨在解决多任务医学视觉问答中多模态大语言模型（MLLMs）在图像-文本对齐和领域知识方面的不足。ClinKD通过增强图像-文本对齐和改进医学知识转换，提高了MLLMs在医学图像理解任务上的性能，并在多个数据集上取得了最先进的结果。

> **摘要翻译:** 医学视觉问答（Med-VQA）代表了通用VQA领域中一个关键且具有挑战性的子任务。尽管在通用VQA方面取得了显著进展，但多模态大语言模型（MLLMs）在处理多任务VQA场景时仍然存在显著的局限性。这些局限性表现为错误的空间定位和对医学图像的误解，这主要源于两个基本问题：图像-文本对齐不足和缺乏针对医学应用的领域特定知识。为了解决这些问题，我们引入了跨模态临床知识蒸馏器（ClinKD），这是一个旨在增强图像-文本对齐和建立更有效的医学知识转换机制的创新框架，它使MLLMs即使在缺乏先验医学知识的情况下也能表现得更好。我们广泛的实验评估表明，ClinKD在Med-VQA任务的几个挑战性数据集上取得了最先进的性能。结果表明，我们的方法不仅显著改善了图像-文本对齐，而且有效地使MLLMs适应了医学知识。ClinKD的源代码可在：https://github.com/overloadedHenry/ClinKD 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [400] [L-CLIPScore: a Lightweight Embedding-based Captioning Metric for Evaluating and Training](https://arxiv.org/abs/2507.08710)
> *轻量级基于嵌入的字幕评分：用于评估和训练*

*Li Li, Yingzhe Peng, Xu Yang, Ruoxi Cheng, Haiyang Xu, Ming Yan, Fei Huang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** L-CLIPScore,字幕评估,轻量级CLIP,多模态对齐,模型训练

**Comment:** 10 pages, 4 figures

> **TL;DR:** 提出了一种名为L-CLIPScore的新型基于嵌入的字幕评估和训练指标，它使用轻量级的CLIP模型（L-CLIP），通过权重复用和矩阵分解进行压缩，并使用新颖的多模态相似性调节器（SR）损失进行蒸馏，实现了与原始CLIP相当的性能，但计算资源和运行时间更少。实验证明了其作为评估指标的有效性，并指出在训练时需结合n元语法指标。

**AI_Comments:** 该研究提出了一种创新的轻量级字幕评估指标L-CLIPScore，通过有效的模型压缩和蒸馏技术，在保证性能的同时降低了计算成本，具有重要的实际应用价值。然而，其在训练阶段的局限性（需要与其他指标结合）是未来研究可以进一步探索的方向。

<details>
  <summary>Details</summary>

**Motivation:** 需要一种能够高效评估字幕质量和训练字幕模型的基于嵌入的指标。

**Method:** 提出L-CLIPScore，一种基于轻量级CLIP（L-CLIP）的指标。L-CLIP通过权重复用和矩阵分解进行压缩，并通过多模态相似性调节器（SR）损失进行蒸馏，以传递视觉-语言对齐知识。

**Result:** L-CLIP实现了与原始CLIP相当的多模态对齐能力，但计算资源和运行时间更少。L-CLIPScore作为评估指标被证明是有效且高效的。在训练时，L-CLIPScore需要与n元语法指标结合使用，单独使用会导致训练失败。

**Conclusion:** L-CLIPScore是一种有效的轻量级基于嵌入的字幕评估和训练指标，通过压缩和蒸馏技术实现了高性能和高效率，但在训练应用中需要与其他指标结合。

> **ai_Abstract:** 本文提出了一种名为L-CLIPScore的新型轻量级基于嵌入的字幕评估和训练指标。该指标基于经过压缩和蒸馏的CLIP模型（L-CLIP），通过权重复用、矩阵分解和新颖的多模态相似性调节器（SR）损失实现，从而在保持与原始CLIP相当的多模态对齐能力的同时，显著减少了计算资源和运行时间。实验证明了L-CLIPScore在评估字幕质量方面的有效性和效率，并指出在作为训练监督器时，应与n元语法指标结合使用。

> **摘要翻译:** 我们提出了一个新颖的基于嵌入的字幕指标，称为L-CLIPScore，它可以用于高效地评估字幕质量和训练字幕模型。L-CLIPScore是从CLIP中压缩和蒸馏出来的双编码器架构轻量级CLIP（L-CLIP）计算得出的。为了压缩，我们分别应用了两种强大的技术：权重复用和矩阵分解，以减少编码器和词嵌入矩阵的参数。为了蒸馏，我们设计了一种新颖的多模态相似性调节器（SR）损失来传递更多的视觉-语言对齐知识。具体来说，如果给定的图像-文本对匹配，SR损失会增强多模态嵌入的相似性，如果不匹配，则会减弱相似性。通过这种新颖的SR损失进行压缩和蒸馏，我们的L-CLIP在多模态对齐能力上达到了与原始CLIP相当的水平，同时它需要更少的计算资源和运行时间。我们进行了详尽的实验，以验证其作为评估字幕质量的裁判的效率和有效性。我们还发现，当使用L-CLIPScore作为训练字幕模型的监督器时，它应该与基于n元语法的指标混合使用，并分析了为什么仅使用L-CLIPScore会导致训练失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [402] [Single-Step Latent Diffusion for Underwater Image Restoration](https://arxiv.org/abs/2507.07878)
> *用于水下图像恢复的单步隐式扩散*

*Jiayi Wu, Tianfu Wang, Md Abu Bakr Siddique, Md Jahidul Islam, Cornelia Fermuller, Yiannis Aloimonos, Christopher A. Metzler* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 水下图像恢复, 隐式扩散模型, 场景分解, SLURPP, 合成数据生成

**Comment:** 

> **TL;DR:** 该研究提出了一种名为SLURPP的新型网络架构，结合了预训练的隐式扩散模型和显式的场景分解，用于水下图像恢复。通过结合精确的合成数据生成流程，SLURPP能够更有效地处理复杂场景，克服了现有基于像素域扩散方法的计算密集和易产生伪影的缺点。实验证明，SLURPP比现有方法快200多倍，在合成基准测试中提高了约3 dB的PSNR，并在真实世界数据上取得了定性改进。

**AI_Comments:** 该研究提出的SLURPP方法在水下图像恢复领域取得了显著的进展，尤其是在处理复杂场景和提高计算效率方面。其结合隐式扩散模型和显式场景分解的思路具有创新性，并且通过物理基础的合成数据生成流程有效解决了训练数据稀疏的问题。然而，对于“隐式扩散模型”和“显式场景分解”的具体细节，以及SLURPP网络架构的创新之处，在摘要中并未详述，这可能限制了对其技术深度的全面理解。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于像素域扩散的水下图像恢复方法计算成本高，且在处理复杂几何和深度变化大的场景时容易产生不切实际的伪影。本研究旨在克服这些局限性。

**Method:** 提出了一种名为SLURPP的新型网络架构，结合了预训练的隐式扩散模型（利用场景几何和深度的先验知识）和显式的场景分解（用于模拟光衰减和后向散射的影响）。同时，设计了一个基于物理的合成数据生成流程，将各种真实的水下退化效果应用于现有的陆地图像数据集，以生成多样化的训练数据。

**Result:** SLURPP比现有基于扩散的方法快200多倍，在合成基准测试中PSNR提高了约3 dB，并在真实世界数据上提供了显著的定性改进。

**Conclusion:** 本研究提出的SLURPP结合了隐式扩散模型和显式场景分解，并通过优化的合成数据生成流程，有效地解决了现有水下图像恢复方法的局限性，实现了更快的处理速度和更好的恢复效果。

> **ai_Abstract:** 本研究提出了一种名为SLURPP的新型网络架构，用于水下图像恢复。该方法结合了预训练的隐式扩散模型和显式的场景分解，能够有效地处理具有复杂几何和深度变化的水下场景。通过结合一个先进的合成数据生成流程，该模型能够利用多样化的训练数据。实验结果表明，SLURPP在速度和恢复质量上均优于现有方法。

> **摘要翻译:** 水下图像恢复算法旨在恢复在水下成像的场景的颜色、对比度和外观。它们是海洋生态学、水产养殖、水下建筑和考古学等应用的关键工具。虽然现有的像素域扩散图像恢复方法在恢复具有有限深度变化的简单场景方面很有效，但它们的计算量很大，并且在应用于具有复杂几何形状和显著深度变化的场景时，通常会产生不切实际的伪影。在本研究中，我们通过将一种新颖的网络架构（SLURPP）与一种精确的合成数据生成流程相结合来克服这些局限性。SLURPP结合了预训练的隐式扩散模型——它们编码了场景几何和深度的强先验知识——以及显式的场景分解——它允许人们模拟和解释光衰减和后向散射的影响。为了训练SLURPP，我们设计了一个基于物理的水下图像合成流程，将各种逼真的水下退化效果应用于现有的陆地图像数据集。这种方法能够生成具有密集介质/退化注释的多样化训练数据。我们在合成和真实世界的基准测试上广泛评估了我们的方法，并证明了最先进的性能。值得注意的是，SLURPP比现有的基于扩散的方法快200多倍，同时在合成基准测试中提供了约3 dB的PSNR改进。它还在真实世界数据上提供了引人注目的定性改进。项目网站 https://tianfwang.github.io/slurpp/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [404] [Quantifying Context Bias in Domain Adaptation for Object Detection](https://arxiv.org/abs/2409.14679)
> *量化目标检测领域自适应中的上下文偏差*

*Hojun Son, Asma Almutairi, Arpan Kusari* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-07-11**

**Keywords:** 目标检测, 领域自适应, 上下文偏差, 前景-背景关联, 因果推断

**Comment:** Under review

> **TL;DR:** 该研究量化了目标检测领域自适应中的上下文偏差，发现前景-背景关联会导致模型性能下降，并提出了一种新颖的度量方法来量化这种影响。

**AI_Comments:** 该研究首次量化了上下文偏差在目标检测领域自适应中的作用，并提出了一种新颖的度量方法，为解决这一问题提供了新的视角。然而，研究主要集中在卷积模型上，未来可以探索其他类型的模型。

<details>
  <summary>Details</summary>

**Motivation:** 领域自适应目标检测（DAOD）对于处理训练和部署域之间的分布变化至关重要，但由前景-背景（FG-BG）关联引起的上下文偏差的影响尚未得到充分研究。

**Method:** 研究人员通过背景遮挡和特征扰动来分析FG-BG关联如何被模型学习，并使用类别激活映射（CAM）和do-calculus来探索FG-BG关联的因果作用。他们还提出了一种名为“领域关联梯度”的新颖度量方法来量化FG-BG关联的因果影响。

**Result:** 研究表明，基于卷积的目标检测模型确实会学习FG-BG关联，并且这种关联会损害模型在不同域之间的泛化能力。该研究在多种模型和数据集上验证了这些发现。

**Conclusion:** 上下文偏差是目标检测模型泛化能力的一个重要因素，需要明确地在DAOD框架中加以解决，以开发更鲁棒、更通用的目标检测系统。

> **ai_Abstract:** 本研究旨在量化目标检测领域自适应（DAOD）中的上下文偏差，特别是前景-背景（FG-BG）关联的影响。研究人员通过实验分析模型如何学习FG-BG关联，并利用do-calculus和提出的“领域关联梯度”度量方法来评估其对模型泛化能力造成的因果损害。研究结果表明，FG-BG关联确实存在并负面影响DAOD，强调了在DAOD框架中解决上下文偏差的重要性。

> **摘要翻译:** 领域自适应目标检测（DAOD）已成为应对训练域和部署域之间分布变化引起的性能下降的关键。然而，影响DAOD的一个关键因素——由学习到的前景-背景（FG-BG）关联引起的上下文偏差——仍然未被充分探索。我们解决了关于目标检测中FG-BG关联的三个关键问题：FG-BG关联是否在训练过程中被编码，FG-BG关联与检测性能之间是否存在因果关系，以及FG-BG关联是否对DAOD有影响。为了检验模型如何捕捉FG-BG关联，我们使用背景遮挡和特征扰动来分析类别和特征的性能下降，通过准确率变化（定义为下降率）进行衡量。为了探索FG-BG关联的因果作用，我们对由类别激活映射（CAM）指导的FG-BG对应用了do-calculus。为了量化FG-BG关联跨域的因果影响，我们提出了一种新颖的度量——领域关联梯度，定义为下降率与最大均值差异（MMD）之比。通过涉及背景遮挡、特征级扰动和CAM的系统性实验，我们揭示了基于卷积的目标检测模型会编码FG-BG关联。我们的结果表明，上下文偏差不仅存在，而且会因果性地损害目标检测模型跨域的泛化能力。此外，我们在包括ALDI++等最先进架构在内的多个模型和数据集上验证了这些发现。本研究强调了在DAOD框架中显式解决上下文偏差的必要性，为开发更鲁棒和可泛化的目标检测系统提供了见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [415] [Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection](https://arxiv.org/abs/2507.08743)
> *地理轨道：一个用于场景自适应车道几何检测的联邦数字孪生框架*

*Rei Tamaru, Pei Li, Bin Ran* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 数字孪生, 车道几何检测, 联邦学习, 元学习, 交通管理

**Comment:** 

> **TL;DR:** Geo-ORBIT是一个联邦数字孪生框架，利用GeoLane和FedMeta-GeoLane技术，通过车辆轨迹数据和路侧摄像头进行车道几何检测，实现了可扩展、隐私保护和场景自适应的交通管理。

**AI_Comments:** 该研究提出了Geo-ORBIT框架，解决了大规模数字孪生在交通管理中面临的扩展性、隐私性和适应性挑战。通过联邦元学习技术，实现了在不牺牲隐私的前提下，对不同地理位置的车道几何进行有效检测和适应，具有重要的实际应用价值。开源代码的提供也便于后续研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有交通管理中的数字孪生方法依赖静态地图或昂贵传感器，扩展性和适应性受限。同时，大规模数字孪生面临隐私、通信和计算效率的挑战。

**Method:** 提出Geo-ORBIT框架，结合实时车道检测（GeoLane）、数字孪生同步和联邦元学习（FedMeta-GeoLane）。GeoLane从车辆轨迹数据和路侧摄像头学习车道几何。Meta-GeoLane用于个性化检测参数，FedMeta-GeoLane实现可扩展、隐私保护的联邦学习。

**Result:** 在多种城市场景的广泛实验中，FedMeta-GeoLane的几何误差更低，对未见过的地点泛化能力更强，同时通信开销显著减少，优于基线和元学习方法。

**Conclusion:** Geo-ORBIT框架为数字孪生中的灵活、情境感知基础设施建模奠定了基础。

> **ai_Abstract:** Geo-ORBIT是一个创新的联邦数字孪生框架，通过结合GeoLane模型和FedMeta-GeoLane联邦元学习策略，利用路侧摄像头和车辆轨迹数据实现高效、可扩展且注重隐私的车道几何检测，为智能交通管理提供了新的解决方案。

> **摘要翻译:** 数字孪生（DT）通过创建动态的交通系统虚拟表示，能够感知条件、分析运行并支持决策，从而有潜力改造交通管理和运营。交通系统DT的关键组成部分是动态道路几何感知。然而，现有方法通常依赖静态地图或昂贵的传感器，限制了可扩展性和适应性。此外，收集和分析来自多个来源数据的大规模DT在隐私、通信和计算效率方面面临挑战。为解决这些挑战，我们引入了Geo-ORBIT（地理运行道路蓝图集成孪生），一个结合了实时车道检测、DT同步和联邦元学习的统一框架。Geo-ORBIT的核心是GeoLane，一个轻量级的车道检测模型，它使用路侧摄像头从车辆轨迹数据中学习车道几何。我们通过Meta-GeoLane扩展了该模型，该模型学习为本地实体个性化检测参数，并通过FedMeta-GeoLane，一个联邦学习策略，确保跨路侧部署的可扩展和隐私保护的适应性。我们的系统与CARLA和SUMO集成，创建了一个高保真DT，实时渲染高速公路场景并捕获交通流。在多种城市场景的广泛实验表明，FedMeta-GeoLane持续优于基线和元学习方法，实现了更低的几何误差和更强的对未见地点泛化能力，同时显著降低了通信开销。这项工作为DT中灵活的、情境感知的基础设施建模奠定了基础。该框架可在https://github.com/raynbowy23/FedMeta-GeoLane.git公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [417] [Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection](https://arxiv.org/abs/2507.07994)
> *涂鸦你的关键点：基于草图的少样本关键点检测*

*Subhajit Maity, Ayan Kumar Bhunia, Subhadeep Koley, Pinaki Nath Chowdhury, Aneeshan Sain, Yi-Zhe Song* | **Category: cs.CV, I.4.0; I.4.9** | **Updated: 2025-07-11**

**Keywords:** 少样本学习, 关键点检测, 草图识别, 跨模态学习, 原型网络

**Comment:** Accepted at ICCV 2025. Project Page: https://subhajitmaity.me/DYKp

> **TL;DR:** 本研究提出了一种名为“Doodle Your Keypoints”的框架，利用人类绘画的草图进行少样本关键点检测，解决了在缺乏同分布源数据时的挑战。该框架通过原型设置、基于网格的定位器和原型域适应来处理跨模态嵌入和用户风格问题，并在多个数据集上展示了在新关键点和类别上的少样本收敛能力。

**AI_Comments:** 这项研究的创新之处在于利用草图作为少样本关键点检测的无源数据来源，这为处理数据稀疏性问题提供了一个有趣且实用的新方向。该方法通过结合原型学习和域适应技术来解决跨模态学习和风格变化带来的挑战，具有重要的理论和应用价值。然而，草图的质量和用户绘制习惯的一致性可能会影响模型的鲁棒性，这可能是未来研究可以进一步探讨的方向。

<details>
  <summary>Details</summary>

**Motivation:** 关键点检测在少样本学习中面临挑战，特别是在缺乏与查询数据同分布的源数据时。本研究旨在利用草图作为一种无需源数据的替代方案来解决这一差距。

**Method:** 提出了一种原型设置框架，结合了基于网格的定位器和原型域适应技术，以克服跨模态嵌入和用户特定草图风格的挑战。

**Result:** 实验证明，该框架在少样本关键点检测方面取得了成功，能够在新的关键点和类别上实现有效的收敛。

**Conclusion:** 本研究提出的“Doodle Your Keypoints”框架成功利用草图解决了少样本关键点检测中的跨模态和风格问题，并在实验中证明了其在新的关键点和类别上的有效性。

> **ai_Abstract:** 本研究提出了一种新颖的少样本关键点检测方法，利用用户绘制的草图作为数据源，解决了传统方法在缺乏同分布源数据时的局限性。该方法采用原型设置、网格定位器和原型域适应技术，有效处理了跨模态学习和用户风格差异的挑战，并在实验中验证了其在识别新关键点和类别方面的少样本学习能力。

> **摘要翻译:** 关键点检测是现代机器感知的重要组成部分，但在少样本学习中面临挑战，特别是在源数据与查询数据来自同一分布的情况下不可用时。这一差距通过利用草图（一种流行的人类表达形式）来解决，提供了一种无需源数据的替代方案。然而，在掌握跨模态嵌入和处理用户特定的草图风格方面也存在挑战。我们提出的框架通过原型设置，结合基于网格的定位器和原型域适应来克服这些障碍。我们还通过大量实验证明了在新的关键点和类别上的少样本收敛的成功。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [CoCo-Bot: Energy-based Composable Concept Bottlenecks for Interpretable Generative Models](https://arxiv.org/abs/2507.08334)
> *CoCo-Bot：用于可解释生成模型、基于能量的可组合概念瓶颈*

*Sangwon Kim, In-su Jang, Pyongkun Kim, Kwang-Ju Kim* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 概念瓶颈模型,生成模型,可解释性,可控性,扩散模型

**Comment:** 

> **TL;DR:** CoCo-Bot是一种新的生成模型，它使用明确的概念来控制生成过程，无需辅助视觉线索，从而提高了可解释性和可控性，并支持事后干预，如概念组合和否定。

**AI_Comments:** 该研究提出了一种新颖的生成模型CoCo-Bot，它通过概念瓶颈（CBM）实现了可解释性和可控性。与现有方法不同，CoCo-Bot无需辅助视觉线索，所有信息仅通过显式概念传递，从而增强了模型的可解释性和组合性。该模型利用扩散模型中的能量函数，支持强大的事后干预能力，如概念组合和否定，这在可控生成领域具有重要意义。实验结果表明，CoCo-Bot在视觉质量和概念控制方面均表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 先前的生成概念瓶颈模型（CBM）需要辅助视觉线索来弥补概念未捕获的信息，这损害了可解释性和组合性。

**Method:** 提出了一种名为CoCo-Bot的后验、可组合概念瓶颈生成模型，该模型通过基于扩散的能量函数，仅通过显式概念传递所有信息，从而无需辅助线索，并支持事后干预，如概念组合和否定。

**Result:** 在CelebA-HQ数据集上使用StyleGAN2进行的实验表明，CoCo-Bot在保持竞争力的视觉质量的同时，提高了概念级可控性和可解释性。

**Conclusion:** CoCo-Bot通过仅通过显式概念传递信息，解决了先前生成CBM模型对辅助视觉线索的依赖问题，从而实现了更高的可解释性和组合性，并支持灵活的概念干预。

> **ai_Abstract:** CoCo-Bot是一种创新的生成模型，它利用概念瓶颈（CBM）来实现可解释和可控的生成。与以往模型不同，CoCo-Bot摒弃了对辅助视觉线索的依赖，所有信息仅通过人类可理解的概念进行传递。该模型基于扩散模型中的能量函数，能够进行强大的事后干预，如概念的组合和否定。实验证明，CoCo-Bot在保持高质量输出的同时，显著提升了模型在概念层面的可控性和可解释性。

> **摘要翻译:** 概念瓶颈模型（CBM）通过将生成过程路由到显式的、人类可理解的概念，提供可解释和可控的生成建模。然而，先前生成CBM模型通常依赖瓶颈处的辅助视觉线索来补偿概念未捕获的信息，这损害了可解释性和组合性。我们提出了CoCo-Bot，一种后验的、可组合的概念瓶颈生成模型，它通过仅通过显式概念传递所有信息，消除了对辅助线索的需求。在扩散基础能量函数的指导下，CoCo-Bot支持在任意概念上进行强大的后验干预——例如概念组合和否定。使用在CelebA-HQ上预训练的StyleGAN2进行的实验表明，CoCo-Bot提高了概念级可控性和可解释性，同时保持了具有竞争力的视觉质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [421] [GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training](https://arxiv.org/abs/2503.08525)
> *GTR：引导性思维强化可防止基于强化学习的视觉语言模型（VLM）代理训练中的思维崩溃*

*Tong Wei, Yijun Yang, Junliang Xing, Yuanchun Shi, Zongqing Lu, Deheng Ye* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 引导性思维强化, 视觉语言模型, 强化学习, 思维崩溃, 链式思维

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 强化学习（RL）在视觉语言模型（VLM）代理训练中存在思维崩溃问题，表现为思维多样性丧失、推理不完整和无效动作。本文提出了引导性思维强化（GTR）框架，通过在每个RL步骤中评估和优化代理的推理过程来解决此问题，从而提高了模型性能和泛化能力。

**AI_Comments:** 该研究提出了一种新颖的引导性思维强化（GTR）框架，以解决视觉语言模型（VLM）代理训练中因过度依赖结果奖励而导致的思维崩溃问题。通过在训练过程中引入过程引导和自动化校正机制，GTR能够有效提升模型的推理能力和泛化性能，并且无需密集的人工标注，具有良好的可扩展性和实用性。与现有最先进模型相比，GTR在任务成功率和模型尺寸方面均表现出显著优势，为VLM的训练提供了新的思路和方法。

<details>
  <summary>Details</summary>

**Motivation:** 基于结果奖励的强化学习（RLVR）在链式思维（CoT）推理的语言模型（LLM）中有效，但在视觉语言模型（VLM）代理训练用于视觉环境中的目标导向动作推理方面效果不佳，会导致思维崩溃。

**Method:** 提出引导性思维强化（GTR）框架，通过自动化校正器在每个RL步骤评估和优化代理的推理过程，以解决思维崩溃问题。

**Result:** GTR框架能够同时训练推理和动作，无需密集的、每步的人工标注。实验表明，GTR显著提高了LLaVA-7b模型在各种视觉环境中的性能和泛化能力，任务成功率比最先进（SoTA）模型高3-5倍，且模型尺寸更小。

**Conclusion:** 引导性思维强化（GTR）框架通过过程引导有效解决了视觉语言模型（VLM）代理训练中的思维崩溃问题，显著提高了模型性能和泛化能力。

> **ai_Abstract:** 本研究针对强化学习（RL）在视觉语言模型（VLM）代理训练中出现的思维崩溃问题，提出了引导性思维强化（GTR）框架。该框架通过在每个RL步骤中引入自动化校正器来评估和优化代理的推理过程，解决了思维多样性丧失、推理不完整等问题。实验结果表明，GTR框架能够有效提升VLM代理的性能和泛化能力，在多项任务中取得显著优于现有最先进模型的成果。

> **摘要翻译:** 强化学习与可验证结果奖励（RLVR）已有效地扩展了大型语言模型（LLM）中的链式思维（CoT）推理。然而，其在为视觉环境中的目标导向动作推理训练视觉语言模型（VLM）代理方面的效果尚未得到充分证实。本研究通过在复杂的纸牌游戏（如24点）和ALFWorld的具身任务上进行广泛的实验来研究此问题。我们发现，当奖励仅基于动作结果时，强化学习未能激励VLM中的CoT推理，反而导致了一种我们称之为思维崩溃的现象，其特点是代理思维多样性迅速丧失、推理与状态无关且不完整，以及随后的无效动作，导致负奖励。为了对抗思维崩溃，我们强调了过程引导的必要性，并提出了一种自动化校正器，该校正器在每个强化学习步骤中评估和优化代理的推理。这个简单且可扩展的GTR（引导性思维强化）框架在无需密集、每步人工标注的情况下即可同时训练推理和动作。我们的实验表明，GTR在各种视觉环境中显著提高了LLaVA-7b模型的性能和泛化能力，任务成功率比模型尺寸更小的最先进（SoTA）模型高3-5倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [SGPMIL: Sparse Gaussian Process Multiple Instance Learning](https://arxiv.org/abs/2507.08711)
> *稀疏高斯过程多示例学习*

*Andreas Lolos, Stergios Christodoulidis, Maria Vakalopoulou, Jose Dolz, Aris Moustakas* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多示例学习, 稀疏高斯过程, 注意力机制, 不确定性量化, 数字病理学

**Comment:** 8 pages, 4 figures, 2 tables

> **TL;DR:** SGPMIL是一个新的概率性注意力机制MIL框架，基于稀疏高斯过程（SGP），用于解决数字病理学中实例标签缺失的问题，并量化实例相关性中的不确定性。

**AI_Comments:** 该研究提出了一种新颖的概率性注意力机制MIL框架SGPMIL，解决了数字病理学中实例级不确定性量化的问题，并取得了良好的效果。在SGP预测均值函数中引入特征缩放以提高效率和性能是一个重要的改进点。然而，对于该方法在其他领域的适用性以及与其他先进MIL方法的详细比较还有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的确定性注意力机制MIL方法在处理数字病理学等需要粗粒度标签而无实例级注释的数据时，虽然在包级性能上表现良好，但忽略了实例相关性中的不确定性。

**Method:** 提出SGPMIL框架，一个基于稀疏高斯过程（SGP）的概率性注意力机制MIL框架。通过学习注意力得分的后验分布，实现原则性的不确定性估计，从而得到更可靠和校准的实例相关性图。在SGP预测均值函数中引入特征缩放，以提高训练速度、效率和实例级性能。

**Result:** SGPMIL在保持具有竞争力的包级性能的同时，显著提高了在不确定性下的实例级预测的质量和可解释性。在多个数字病理学数据集上的实验证明了该方法在包级和实例级评估中的有效性。

**Conclusion:** SGPMIL通过引入基于稀疏高斯过程的概率性注意力机制，成功地解决了MIL中不确定性量化的问题，提高了实例级预测的可靠性和可解释性，并在数字病理学任务中表现出色。

> **ai_Abstract:** SGPMIL是一个新颖的概率性注意力机制MIL框架，它利用稀疏高斯过程（SGP）来解决数字病理学中实例标签缺失和不确定性量化的问题。通过学习注意力得分的后验分布，SGPMIL能够提供可靠的实例相关性图，并在保持竞争力的包级性能的同时，提升实例级预测的质量和可解释性。该方法通过引入特征缩放进一步优化了训练效率和性能。

> **摘要翻译:** 多示例学习（MIL）为仅能获得粗略的包级标签而无法获得实例级注释的场景提供了一种自然的解决方案。这在包含吉像素级图像的数字病理学中通常是这种情况。虽然确定性的注意力机制MIL方法在包级性能上表现强劲，但它们常常忽略了实例相关性中固有的不确定性。在本文中，我们通过引入	extbf{SGPMIL}来解决实例级注意力得分中不确定性量化缺失的问题，这是一个基于稀疏高斯过程（SGP）的新的概率性注意力机制MIL框架。通过学习注意力得分的后验分布，SGPMIL能够实现原则性的不确定性估计，从而得到更可靠和校准的实例相关性图。我们的方法不仅保持了具有竞争力的包级性能，而且显著提高了在不确定性下的实例级预测的质量和可解释性。SGPMIL通过在SGP预测均值函数中引入特征缩放，扩展了先前的工作，从而提高了训练速度、效率和实例级性能。在多个成熟的数字病理学数据集上的广泛实验突显了我们的方法在包级和实例级评估中的有效性。我们的代码将公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [431] [X-Dancer: Expressive Music to Human Dance Video Generation](https://arxiv.org/abs/2502.17414)
> *X-Dancer：富有表现力的音乐到人类舞蹈视频生成*

*Zeyuan Chen, Hongyi Xu, Guoxian Song, You Xie, Chenxu Zhang, Xin Chen, Chao Wang, Di Chang, Linjie Luo* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 音乐驱动的视频生成, 舞蹈动画, Transformer, 扩散模型, 零样本学习

**Comment:** ICCV 2025. Project Page: https://zeyuan-chen.com/X-Dancer/

> **TL;DR:** X-Dancer是一个新的零样本音乐驱动的图像动画流程，可以从单张静态图像生成多样化且长期的逼真人类舞蹈视频。它使用统一的 transformer-扩散框架，通过自回归 transformer 模型生成与音乐同步的 2D 身体、头部和手部姿势，然后指导扩散模型生成连贯逼真的舞蹈视频帧。该方法通过对 2D 舞蹈动作进行建模来解决数据限制并提高可扩展性，并能捕捉其与音乐节拍的细微对齐。

**AI_Comments:** X-Dancer 在音乐驱动的视频生成领域提出了一个新颖的框架，通过结合 transformer 和扩散模型，实现了从静态图像到动态、富有表现力的舞蹈视频的转换。该方法在处理 2D 动作和音乐同步方面具有创新性，解决了传统方法的局限性。然而，其在不同风格音乐和复杂舞步上的泛化能力以及视频的长期连贯性仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 传统的运动生成方法主要在 3D 中生成人类运动，但 X-Dancer 通过对大量 2D 舞蹈动作进行建模来解决数据限制和提高可扩展性，并捕捉其与音乐节拍的细微对齐，而这些动作可以通过单眼视频轻松获得。

**Method:** X-Dancer 使用统一的 transformer-扩散框架，包括一个自回归 transformer 模型来生成与音乐同步的 2D 身体、头部和手部姿势，然后指导扩散模型生成连贯逼真的舞蹈视频帧。该方法首先从与关键点置信度相关的 2D 人体姿势标签构建空间构成性标记表示，然后设计一个音乐到运动的 transformer 模型来生成与音乐对齐的舞蹈姿势标记序列，最后利用扩散骨干网络通过 AdaIN 动画化参考图像。

**Result:** 实验结果表明，X-Dancer 能够生成多样化且具有特色的舞蹈视频，在多样性、表现力和真实性方面显著优于最先进的方法。

**Conclusion:** X-Dancer 是一个新颖的零样本音乐驱动的图像动画流程，能够从单张静态图像生成多样化且长期的逼真人类舞蹈视频，并且在多样性、表现力和真实性方面优于现有方法。

> **ai_Abstract:** X-Dancer 是一个创新的零样本音乐驱动的动画流程，它能够根据音乐生成逼真的、具有表现力的舞蹈视频。该方法利用 transformer-扩散框架，通过将音乐信息转化为 2D 身体姿势序列，然后指导扩散模型生成连贯的视频帧，实现了从单张静态图像到多样化舞蹈视频的转换。与传统 3D 方法不同，X-Dancer 专注于 2D 动作建模，提高了数据利用率和可扩展性，并在多样性、表现力和真实性方面取得了优于现有技术的成果。

> **摘要翻译:** 我们提出了 X-Dancer，一个新颖的零样本音乐驱动的图像动画流程，可以从单张静态图像生成多样化且长期的逼真人类舞蹈视频。其核心是我们引入了一个统一的 transformer-扩散框架，其特点是自回归 transformer 模型，可以合成扩展的、与音乐同步的 2D 身体、头部和手部姿势的标记序列，然后指导扩散模型生成连贯逼真的舞蹈视频帧。与主要在 3D 中生成人类运动的传统方法不同，X-Dancer 通过对广泛的 2D 舞蹈动作进行建模来解决数据限制并提高可扩展性，通过现成的单眼视频捕捉其与音乐节拍的细微对齐。为了实现这一点，我们首先从与关键点置信度相关的 2D 人体姿势标签构建一个空间构成性标记表示，对大的关节身体运动（例如，上半身和下半身）和细粒度的运动（例如，头部和手部）进行编码。然后，我们设计了一个音乐到运动的 transformer 模型，该模型自回归地生成音乐对齐的舞蹈姿势标记序列，并结合了对音乐风格和先验运动上下文的全局注意力。最后，我们利用扩散主干通过 AdaIN 用这些合成的姿势标记来动画化参考图像，形成一个完全可微分的端到端框架。实验结果表明，X-Dancer 能够生成多样化且具有特色的舞蹈视频，在多样性、表现力和真实性方面显著优于最先进的方法。代码和模型将可用于研究目的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [443] [CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025](https://arxiv.org/abs/2507.08022)
> *CuriosAI 提交的 EgoExo4D 熟练度估计挑战 2025*

*Hayato Tanoue, Hiroki Nishihara, Yuma Suzuki, Takayuki Hori, Hiroki Takushima, Aiswariya Manojkumar, Yuki Shibata, Mitsuru Takeda, Fumika Beppu, Zhao Hengwei, Yuto Kanda, Daichi Yamaga* | **Category: cs.CV** | **Updated: 2025-07-08**

**Keywords:** 熟练度估计, EgoExo4D, 多任务学习, VideoMAE, 场景识别

**Comment:** The 2nd place solution for the EgoExo4D Proficiency Estimation
  Challenge at the CVPR EgoVis Workshop 2025

> **TL;DR:** CuriosAI 在 EgoExo4D 熟练度估计挑战中提出了两种方法，其中两阶段方法结合了零样本场景识别和特定视图的 VideoMAE 分类器，取得了 47.8% 的准确率，优于多任务学习框架。

**AI_Comments:** 该研究在 EgoExo4D 熟练度估计挑战中展示了两种先进的方法，其中两阶段方法取得了领先的性能，突出了场景条件建模在提高准确性方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 提交到 CVPR 2025 的 EgoExo4D 熟练度估计挑战。

**Method:** 1. 使用 Sapiens-2B 的多任务学习框架，联合预测熟练度和场景标签。 2. 结合零样本场景识别和特定视图 VideoMAE 分类器的两阶段流程。

**Result:** 多任务学习框架的准确率为 43.6%。两阶段流程的准确率为 47.8%。

**Conclusion:** 两阶段方法在熟练度估计方面比多任务学习框架更有效，证明了场景条件建模的有效性。

> **ai_Abstract:** CuriosAI 团队在 CVPR 2025 的 EgoExo4D 熟练度估计挑战中，提出了一种两阶段方法，结合零样本场景识别和 VideoMAE 分类器，实现了 47.8% 的准确率，优于其多任务学习方法。

> **摘要翻译:** 本报告介绍了 CuriosAI 团队在 CVPR 2025 EgoExo4D 熟练度估计挑战中的提交。我们提出了两种多视图技能评估方法：(1) 一个使用 Sapiens-2B 的多任务学习框架，联合预测熟练度和场景标签（准确率为 43.6%），以及 (2) 一个结合零样本场景识别和特定视图 VideoMAE 分类器的两阶段流程（准确率为 47.8%）。两阶段方法的优越性能证明了场景条件建模在熟练度估计方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement](https://arxiv.org/abs/2507.08340)
> *用于多模态跨癌预后的单域泛化：基于狄拉克再平衡器和分布纠缠*

*Jia-Xuan Jiang, Jiashuai Liu, Hongtao Wu, Yifeng Wu, Zhong Wang, Qi Bi, Yefeng Zheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 多模态预后, 跨癌泛化, 单域泛化, 狄拉克再平衡器, 分布纠缠

**Comment:** Accepted by ACMMM 25

> **TL;DR:** 该研究首次提出并解决了多模态预后模型在跨癌症泛化方面的挑战，指出多模态模型在该场景下泛化能力不如单模态模型。为了解决这个问题，研究者提出了跨癌单域泛化任务，并引入了稀疏狄拉克信息再平衡器（SDIR）和癌症感知分布纠缠（CADE）两个模块来分别处理特征退化和多模态融合问题。实验结果表明，所提出的方法在跨癌预后任务上具有优越的泛化能力。

**AI_Comments:** 这项研究解决了多模态预后模型在跨癌症泛化中的一个重要且被忽视的问题。提出的SDIR和CADE模块为处理模态间不平衡和域转移提供了新颖的解决方案。然而，研究仅在四种癌症类型上进行了评估，未来的工作可以探索在更多样化的癌症数据集上的泛化能力。此外，对所提出模块的计算复杂度和可解释性的进一步分析也会增加其价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对生存预测的多模态深度学习方法主要集中在单一癌症类型，忽视了跨癌症泛化的挑战。然而，在临床实践中，这种鲁棒性至关重要。研究发现，多模态模型在跨癌症场景下的泛化能力通常比单模态模型差。

**Method:** 提出新的任务：多模态预后的跨癌单域泛化。引入稀疏狄拉克信息再平衡器（SDIR）模块，通过基于伯努利分布的稀疏化和狄拉克启发的稳定化来增强较弱模态的信号，以缓解较强特征的主导地位。引入癌症感知分布纠缠（CADE）模块，旨在合成目标域分布，并在潜在空间中融合局部形态线索和全局基因表达。

**Result:** 在包含四种癌症类型的基准数据集上进行的实验证明了所提出方法优越的泛化能力，为实际、鲁棒的跨癌多模态预后奠定了基础。

**Conclusion:** 所提出的跨癌单域泛化方法及其引入的SDIR和CADE模块，能够有效解决多模态预后模型在跨癌症泛化时的特征退化和多模态融合问题，显著提升了模型的泛化能力。

> **ai_Abstract:** 本研究首次提出了跨癌单域泛化任务，以解决多模态预后模型在跨癌症应用中的泛化能力不足问题。研究人员发现多模态模型在跨癌症场景下泛化能力会下降。为解决此问题，研究者开发了稀疏狄拉克信息再平衡器（SDIR）和癌症感知分布纠缠（CADE）两个模块。SDIR通过稀疏化和稳定化来增强弱模态特征，CADE则通过融合不同模态信息来合成目标域分布。实验结果表明，该方法在跨癌症预后任务上表现出优越的泛化性能。

> **摘要翻译:** 深度学习在整合多模态数据以进行生存预测方面表现出卓越的性能。然而，现有的多模态方法主要集中在单一癌症类型，而忽视了跨癌症泛化的挑战。在这项工作中，我们首次揭示了在跨癌症场景下，多模态预后模型通常比单模态模型泛化能力差，尽管临床实践中迫切需要这种鲁棒性。为了解决这个问题，我们提出了一个新任务：多模态预后的跨癌单域泛化，该任务评估在单一癌症类型上训练的模型是否能够泛化到未见过的癌症。我们确定了两个关键挑战：来自较弱模态的特征退化和无效的多模态整合。为了应对这些挑战，我们引入了两个即插即用模块：稀疏狄拉克信息再平衡器（SDIR）和癌症感知分布纠缠（CADE）。SDIR通过应用基于伯努利分布的稀疏化和狄拉克启发的稳定化来增强较弱模态信号，从而减轻了强特征的主导地位。CADE旨在合成目标域分布，并在潜在空间中融合局部形态线索和全局基因表达。在包含四种癌症类型的基准数据集上进行的实验证明了其优越的泛化能力，为实际、鲁棒的跨癌多模态预后奠定了基础。代码可在https://github.com/HopkinsKwong/MCCSDG获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [450] [Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine](https://arxiv.org/abs/2507.08716)
> *无所不能的虚幻：仅用一个引擎实现多模态ISAC数据模拟*

*Kongwu Huang, Shiyi Mu, Jun Jiang, Yuan Gao, Shugong Xu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** ISAC, 多模态数据, Unreal Engine, 数据集, 定位

**Comment:** 

> **TL;DR:** 本研究提出了Great-X平台，一个集成了Sionna射线追踪计算和自动驾驶工具的单引擎多模态数据模拟器，能够高效同步模拟CSI、RGB、雷达和激光雷达数据。基于此平台，研究构建了一个名为Great-MSD的大规模开源低空UAV多模态数据合成数据集，并提出了一种基于CSI的无人机三维定位基线算法，验证了其在不同CSI模拟引擎上的可行性和泛化性。

**AI_Comments:** 该研究提出了一种创新的多模态ISAC数据模拟平台Great-X，其亮点在于利用Unreal Engine实现了多模态数据的同步高效模拟，并集成了自动驾驶工具，为ISAC研究提供了重要的数据支持和工具。开源数据集Great-MSD和提出的基线算法也增加了该研究的价值和影响力。然而，未来可以进一步探索该平台在更复杂场景下的性能以及与其他模拟引擎的兼容性。

<details>
  <summary>Details</summary>

**Motivation:** 探索扩展定律在ISAC研究中的潜力，并为多模态ISAC数据模拟提供一个高效、同步的解决方案。

**Method:** 提出并构建了一个名为Great-X的单引擎多模态数据仿真双生平台，该平台将Sionna的射线追踪计算重建在Unreal Engine中，并与自动驾驶工具深度集成，实现了CSI、RGB、雷达和激光雷达等多种模态数据的同步仿真。在此基础上，构建了大规模开源低空UAV多模态数据合成数据集Great-MSD，并提出了一种基于CSI的UAV三维定位算法。

**Result:** 成功构建了Great-X平台，实现了多模态ISAC数据的同步高效模拟。基于该平台构建了大规模开源数据集Great-MSD。提出的CSI基线算法在不同CSI模拟引擎上均表现出可行性和泛化性。

**Conclusion:** Great-X平台能够高效、同步地模拟多模态ISAC数据，为ISAC研究提供了强大的支持。基于Great-X构建的Great-MSD数据集和提出的CSI基线算法证明了该方法的有效性和广泛适用性。

> **ai_Abstract:** 本研究介绍了Great-X，一个利用Unreal Engine集成了Sionna射线追踪和自动驾驶工具的单引擎多模态ISAC数据模拟平台，能够高效同步模拟CSI、RGB、雷达和激光雷达数据。研究基于此平台创建了开源数据集Great-MSD，并提出了一种基于CSI的无人机三维定位算法，验证了其在不同模拟引擎上的可行性和泛化性。

> **摘要翻译:** 扩展定律在LLM和基础模型中取得了成功。为了探索它们在ISAC研究中的潜力，我们提出了Great-X。这个单引擎多模态数据双生平台在Unreal Engine中重建了Sionna的射线追踪计算，并与自动驾驶工具深度集成。这使得CSI、RGB、雷达和激光雷达等多种模态数据的有效和同步模拟成为可能。基于这个平台，我们构建了一个名为Great-MSD的开源大规模低空UAV多模态数据联合数据集，并提出了一种基于CSI的UAV三维定位基线算法，证明了其在不同CSI模拟引擎上的可行性和泛化性。相关代码和数据集可在以下网址公开获取：https://github.com/hkw-xg/Great-MCD。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements](https://arxiv.org/abs/2503.07499)
> *运动员姿势3D：用于运动员运动中3D人体姿势估计和运动学验证的基准数据集*

*Calvin Yeung, Tomohiro Suzuki, Ryota Tanaka, Zhuoer Yin, Keisuke Fujii* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D人体姿势估计, 运动员运动, AthletePose3D数据集, 运动学分析, 计算机视觉

**Comment:** Erratum: A preprocessing mistake occurred in one camera angle of the
  running motions. This has been corrected, the experiment re-run, and the
  results updated accordingly. Please note that the conclusions of the
  experiment and the overall paper remain unchanged

> **TL;DR:** 该研究提出了AthletePose3D数据集，一个包含约130万帧和16.5万个姿势的用于3D人体姿势估计的新数据集，特别关注高加速度的运动。研究发现，现有模型在运动数据上表现不佳，但通过在AthletePose3D上进行微调，可以将平均每关节位置误差（MPJPE）从214毫米降低到65毫米。此外，研究还通过波形分析验证了运动学精度，发现关节角度估计具有很强的相关性，但速度估计存在局限性。

**AI_Comments:** 该研究通过引入AthletePose3D数据集，为3D人体姿势估计领域带来了重要的贡献，尤其是在高加速度运动的捕捉方面。数据集的规模和多样性为评估和训练模型提供了坚实的基础。研究结果表明，现有模型在运动数据上的局限性以及通过微调可实现的显著性能提升，强调了针对特定领域数据进行优化的重要性。运动学验证部分也为理解模型的准确性提供了更深入的见解。然而，关于速度估计的局限性也指出了未来研究的方向。总体而言，这项工作对于体育科学、运动分析和计算机视觉领域都具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的3D人体姿势估计数据集难以捕捉竞技体育中典型的复杂、高加速度运动。这项工作旨在通过引入一个专门针对此类运动的新数据集来解决这一差距。

**Method:** 创建了一个名为AthletePose3D的新数据集，其中包含12种运动类型和约130万帧的运动数据，重点关注高速度、高加速度的运动员运动。然后，在AthletePose3D数据集上评估了最先进的单目2D和3D姿势估计模型，并对模型进行了微调以提高性能。最后，通过波形分析验证了单目姿势估计的运动学准确性。

**Result:** 在AthletePose3D数据集上，现有模型在运动数据上表现不佳。然而，通过在AthletePose3D上微调，最先进模型的平均每关节位置误差（MPJPE）从214毫米降低到65毫米（降低超过69%）。关节角度估计显示出很强的相关性，但速度估计存在局限性。

**Conclusion:** AthletePose3D数据集为评估单目姿势估计模型在体育运动中的性能提供了全面的视角，并为在高性能体育环境中改进单目姿势估计技术提供了宝贵的见解。数据集、代码和模型检查点均已公开。

> **ai_Abstract:** 本研究提出了AthletePose3D数据集，旨在解决现有数据集在捕捉高加速度运动方面的不足。该数据集包含12种运动类型，约130万帧，专为高强度运动设计。研究发现，现有模型在运动数据上表现不佳，但通过在AthletePose3D上微调可显著提高性能，MPJPE降低超过69%。此外，研究还验证了运动学精度，发现关节角度估计准确但速度估计有待改进。

> **摘要翻译:** 人体姿势估计是计算机视觉和运动生物力学中的一项关键任务，其应用涵盖体育科学、康复和生物力学研究。尽管单目3D姿势估计取得了显著进展，但现有数据集往往无法捕捉竞技体育中典型的复杂、高加速度运动。在这项工作中，我们引入了AthletePose3D，一个旨在解决这一差距的新型数据集。AthletePose3D包含跨不同学科的12种运动类型，约有130万帧和16.5万个单独的姿势，专门捕捉高速度、高加速度的运动员运动。我们在该数据集上评估了最先进的（SOTA）单目2D和3D姿势估计模型，结果表明在传统数据集上训练的模型在运动员运动上表现不佳。然而，在AthletePose3D上对这些模型进行微调，可将SOTA模型的平均每关节位置误差（MPJPE）从214毫米显著降低到65毫米，降低幅度超过69%。我们还通过波形分析验证了单目姿势估计的运动学准确性，突出了关节角度估计的强相关性，但在速度估计方面存在局限性。我们的工作为在体育背景下评估单目姿势估计模型提供了全面的视角，为推进高性能体育环境中的单目姿势估计技术做出了宝贵的贡献。数据集、代码和模型检查点可在以下网址获取：https://github.com/calvinyeungck/AthletePose3D

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation](https://arxiv.org/abs/2507.08343)
> *走向不可感知JPEG图像隐藏：多范围表示驱动的对抗隐写生成*

*Junxue Yang, Xin Liao, Weixuan Tang, Jianhua Yang, Zheng Qin* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** JPEG隐写, 对抗生成, 多范围表示, 卷积, Transformer

**Comment:** 

> **TL;DR:** 本研究提出了一种名为MRAG的基于生成对抗攻击的JPEG图像隐写方法，通过结合卷积和Transformer的特征提取能力，并引入多粒度频率信息和角度-范数解耦损失，实现了高隐写率、高可恢复性和不可感知性，优于现有技术。

**AI_Comments:** 该研究在JPEG图像隐写领域取得了重要进展，通过引入对抗性生成和多范围表示，显著提升了隐写图像的不可感知性和鲁棒性。其结合卷积和Transformer的混合架构以及新颖的损失函数设计是该方法的亮点，为未来隐写技术的发展提供了新的方向。然而，对于计算复杂度和实际应用中的性能影响仍需进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于深度学习的图像隐写方案因其高载荷和单一特征提取方式（仅卷积或仅Transformer）以及像素级损失约束，容易被隐写分析器检测。

**Method:** 提出了一种名为MRAG的多范围表示驱动的对抗隐写生成框架。该框架结合了卷积的局部接收特性和Transformer的全局依赖建模能力，并使用经过粗粒度和细粒度频率分解转换的图像作为输入，引入多粒度信息。此外，设计了一种特征角度-范数解耦损失来约束生成的隐写图像在隐写分析器分类特征的角度和范数空间上更接近原始图像。

**Result:** 实验证明，MRAG在隐写率、可恢复性和不可感知性方面均能达到最先进的性能。

**Conclusion:** MRAG框架通过整合多范围表示和设计新的损失函数，能够生成具有高隐写率、高可恢复性和不可感知性的JPEG隐写图像，有效解决了现有方法的不足，并达到了最先进的性能。

> **ai_Abstract:** 本研究提出了一种名为MRAG的新型JPEG图像隐写框架，旨在提高隐写图像的不可感知性并抵抗隐写分析。MRAG通过结合卷积和Transformer的特征提取能力，并利用多粒度频率信息和创新的特征角度-范数解耦损失，在保持高隐写率和可恢复性的同时，有效降低了被检测的风险，实验结果表明其性能优于现有方法。

> **摘要翻译:** 深度隐写一直在探索基于深度学习模型的隐写能力，旨在将图像级消息隐藏到封面图像中，并从生成的隐写图像中揭示它们。现有的方案由于其载荷大，并且仅限于单一范围内的纯卷积或纯Transformer算子进行特征提取，以及像素级的损失约束，很容易被隐写分析器检测出来。为了解决这个问题，在本文中，我们首次将生成对抗攻击引入彩色JPEG图像深度隐写，并从隐写分析的角度提出了一个名为MRAG的多范围表示驱动的对抗隐写生成框架。具体来说，我们集成了卷积的局部邻域接收特性和Transformer的全局依赖建模能力来构建MRAG。同时，我们使用通过粗粒度和细粒度频率分解获得的变换后的图像作为输入，引入多粒度信息。此外，还设计了一种特征角度-范数解耦损失，以约束生成的隐写在隐写分析器分类特征的角度和范数空间上更接近封面图像。因此，可以在生成隐写图像的过程中注入微小但有效的对抗性扰动，确保隐写图像保持良好的秘密可恢复性和不可感知性。大量实验证明，MRAG能够达到最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [Compress Any Segment Anything Model (SAM)](https://arxiv.org/abs/2507.08765)
> *压缩任何分割模型（SAM）*

*Juntong Fan, Zhiwei Hao, Jianqiang Shen, Shang-Ling Jui, Yi Zhang, Jing-Xiao Liao, Feng-Lei Fan* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** SAM压缩,无数据压缩,超压缩,HyperLinear,模型推理加速

**Comment:** 13 pages, 6 tables, 8 figures

> **TL;DR:** 提出了一种名为Birkhoff的新型无数据压缩算法，用于SAM及其变体，通过“超压缩”技术将高维参数向量映射到低维标量，并设计了“HyperLinear”算子加速推理，实现了高效的模型压缩，压缩时间短且性能损失小。

**AI_Comments:** 该研究提出了一种创新的无数据压缩算法Birkhoff，解决了SAM模型在实际应用中的关键痛点。其“超压缩”技术和“HyperLinear”算子的设计具有新颖性，并且实验结果证明了其在压缩率、性能保持和速度方面的优势。该方法在不同数据集和模型上的通用性和高效性使其具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于SAM及其变体在各种场景下表现出色，对其进行有效压缩已成为一项迫切的实践需求。

**Method:** 提出了一种名为Birkhoff的无数据压缩算法，该算法的核心是“超压缩”技术，旨在找到一个稠密轨迹将高维参数向量映射为低维标量。此外，还设计了一个名为HyperLinear的专用线性层算子，用于融合解压和矩阵乘法，以加速压缩后SAM的推理。

**Result:** Birkhoff在COCO、LVIS和SA-1B数据集上的18个SAM模型上进行了广泛实验，结果显示在压缩时间、压缩率、压缩后性能和推理速度方面均表现出一致且有竞争力。例如，在SAM2-B上，Birkhoff实现了5.17倍的压缩率，且性能下降不到1%，整个压缩过程仅需60秒。

**Conclusion:** Birkhoff是一种通用、敏捷、忠实且紧凑的SAM及其变体无数据压缩算法，能够高效地压缩模型并在不使用微调数据的情况下保持高性能。

> **ai_Abstract:** 本研究提出了一种名为Birkhoff的新型无数据压缩算法，旨在解决Segment Anything Model (SAM)及其变体在实际应用中日益增长的压缩需求。Birkhoff算法通过一种称为“超压缩”的新颖技术，能够将高维参数向量映射为低维标量，并结合专用的HyperLinear线性层算子来加速推理。实验证明，Birkhoff在压缩效率、模型性能保持和推理速度方面均表现出色，能在短时间内实现高压缩率且对模型性能影响极小。

> **摘要翻译:** 由于其在生成高质量、零样本分割方面表现出色，分割任何模型（SAM）及其变体已广泛应用于医疗保健和智能制造等各种场景。因此，有效压缩SAM已成为一项日益紧迫的实际需求。在本研究中，我们提出了一种新颖的、用于SAM及其变体的数据无关压缩算法Birkhoff。与量化、剪枝、蒸馏和其他压缩方法不同，Birkhoff在模型类型、部署敏捷性、对原始模型的忠实度和模型尺寸紧凑性方面体现了通用性。具体来说，Birkhoff引入了一种新颖的压缩算法：超压缩，其核心原理是找到一个稠密轨迹，将高维参数向量转化为低维标量。此外，Birkhoff设计了一个专用的线性层算子HyperLinear，用于融合解压和矩阵乘法，以显著加速压缩后SAM的推理。在COCO、LVIS和SA-1B数据集上的18个SAM模型上进行的广泛实验表明，Birkhoff在压缩时间、压缩率、压缩后性能和推理速度方面表现出一致且有竞争力。例如，Birkhoff可以在SAM2-B上实现5.17倍的压缩率，且性能下降不到1%，而无需使用任何微调数据。此外，所有模型的压缩过程均在60秒内完成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [478] [Self-Consistency in Vision-Language Models for Precision Agriculture: Multi-Response Consensus for Crop Disease Management](https://arxiv.org/abs/2507.08024)
> *精准农业视觉语言模型中的自洽性：用于作物病害管理的多元响应共识*

*Mihir Gupta, Abhay Mangla, Ross Greer, Pratik Desai* | **Category: cs.CV** | **Updated: 2025-07-08**

**Keywords:** 精准农业, 视觉语言模型, 作物病害管理, 自洽性, 专家评估

**Comment:** 

> **TL;DR:** 该研究提出了一种用于精准农业的领域感知框架，通过结合基于提示的专家评估和自洽性机制来提高视觉语言模型（VLMs）在作物病害管理中的可靠性。通过使用语言模型作为专家植物病理学家进行评估，并采用余弦一致性自投票机制来生成和选择最一致的诊断，该方法在玉米叶病害识别任务中显著提高了诊断准确性、症状分析和治疗建议的性能，同时保持了适用于移动设备的紧凑性。

**AI_Comments:** 该研究在提高VLMs在专业领域（如精准农业）的应用可靠性方面取得了重要进展。通过引入模拟专家评估和自洽性机制，有效解决了现有模型在处理复杂农业数据时的不足。然而，该方法在多大程度上能泛化到其他农业病害或作物类型，以及实际部署中可能遇到的计算资源限制和数据多样性问题，仍有待进一步研究。此外，模型对“领域适应性嵌入”的依赖性也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉语言模型（VLMs）在精准农业等专业领域表现不佳，需要提高其在作物病害识别和治疗推荐方面的可靠性。

**Method:** 提出了一种领域感知框架，包括：1）一个基于提示的评估协议，将语言模型配置为专家植物病理学家；2）一个余弦一致性自投票机制，生成多个候选响应并选择最语义连贯的诊断。

**Result:** 在玉米叶病害识别任务中，该方法将诊断准确性从82.2%提高到87.8%，症状分析从38.9%提高到52.2%，治疗建议从27.8%提高到43.3%。该系统足够紧凑，可部署在移动设备上。

**Conclusion:** 该研究展示了人工智能驱动的精准农业工具在各种田间条件下可靠运行的巨大潜力。

> **ai_Abstract:** 本研究提出了一种用于精准农业的创新框架，通过结合专家评估和自洽性机制，显著提高了视觉语言模型在作物病害管理中的准确性和可靠性。该框架通过模拟专家植物病理学家的评估和采用一种新的响应选择方法，在玉米病害识别任务中取得了显著的性能提升，并且该系统足够轻便，适合在资源有限的环境中部署。

> **摘要翻译:** 精准农业在作物病害识别和治疗推荐方面高度依赖准确的图像分析，但现有的视觉语言模型（VLMs）在专业农业领域的表现往往不佳。本研究提出了一个领域感知框架，用于农业图像处理，该框架结合了基于提示的专家评估和自洽性机制，以提高VLMs在精准农业应用中的可靠性。我们引入了两项关键创新：（1）一个基于提示的评估协议，将语言模型配置为专家植物病理学家，以可扩展的方式评估图像分析输出；（2）一个余弦一致性自投票机制，从农业图像中生成多个候选响应，并使用领域适应性嵌入来选择最语义连贯的诊断。通过使用经过微调的PaliGemma模型对来自田间图像的玉米叶病害进行识别，与标准的贪婪解码相比，我们的方法将诊断准确性从82.2%提高到87.8%，症状分析从38.9%提高到52.2%，治疗建议从27.8%提高到43.3%。该系统足够紧凑，可部署在移动设备上，支持资源受限环境中的实时农业决策制定。这些结果证明了人工智能驱动的精准农业工具在各种田间条件下可靠运行的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [480] [RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking](https://arxiv.org/abs/2507.08729)
> *RoundaboutHD：用于多摄像头车辆跟踪的高分辨率真实城市环境基准*

*Yuqiang Lin, Sam Lockyer, Mingxuan Sui, Li Gan, Florian Stanek, Markus Zarbock, Wenbin Li, Adrian Evans, Nic Zhang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多摄像头车辆跟踪, 环形交叉路口, 高分辨率数据集, 真实世界场景, 车辆重识别

**Comment:** 

> **TL;DR:** 本篇论文介绍了一个名为RoundaboutHD的高分辨率多摄像头车辆跟踪数据集，旨在解决现有数据集在真实世界场景中的局限性，如低分辨率和场景过于简单。该数据集包含40分钟的4K分辨率视频，涵盖了512个独特的车辆身份，并提供了用于对象检测、单摄像头跟踪和车辆重识别的子集，以及车辆模型和相机几何信息。论文还提供了基线结果，并且数据集和评估代码已公开。

**AI_Comments:** 该数据集的发布对于推动多摄像头车辆跟踪技术在真实世界城市环境中的应用具有重要意义。高分辨率和多样化的场景设置增加了研究的挑战性，但也为开发更鲁棒的算法提供了基础。然而，数据集的规模（40分钟）可能仍需进一步扩大以覆盖更广泛的交通状况。

<details>
  <summary>Details</summary>

**Motivation:** 现有公开的多摄像头车辆跟踪（MCVT）数据集存在场景过于简单、分辨率低和条件不够多样化等局限性，与真实世界场景存在差距，阻碍了在智慧城市应用中的发展。

**Method:** 提出并构建了一个名为RoundaboutHD的高分辨率（4K分辨率，15 fps）多摄像头车辆跟踪基准数据集，包含40分钟的视频，覆盖了4个非重叠摄像头，标注了512个独特的车辆身份，并提供了时间一致性视频、增加了遮挡和非线性运动等挑战，还包含用于目标检测、单摄像头跟踪和图像重识别的子集，以及车辆模型和相机几何信息。

**Result:** 提供了基线结果，包括车辆检测、单摄像头跟踪、图像重识别和多摄像头跟踪。

**Conclusion:** RoundaboutHD数据集的发布填补了真实世界城市环境中多摄像头车辆跟踪研究的空白，为相关技术的进一步发展提供了有力支持。

> **ai_Abstract:** 本研究介绍了RoundaboutHD，一个高分辨率、真实世界的城市环境多摄像头车辆跟踪基准数据集。该数据集旨在克服现有数据集的局限性，提供更贴近实际的环形交叉路口场景。RoundaboutHD包含40分钟的4K视频，覆盖四个摄像头，标注了512个车辆身份，并增加了遮挡和非线性运动等挑战。此外，它还提供了用于不同任务的子集和相机几何信息，并公布了基线结果及代码。

> **摘要翻译:** 多摄像头车辆跟踪（MCVT）框架在智慧城市应用中具有巨大潜力，包括异常检测、交通密度估计和嫌疑车辆跟踪。然而，目前公开的数据集存在局限性，如场景过于简单、视频分辨率低以及条件不够多样化，导致学术研究与真实世界场景之间存在巨大差距。为了填补这一差距，我们推出了RoundaboutHD，这是一个全面、高分辨率的多摄像头车辆跟踪基准数据集，专门用于模拟真实世界的环形交叉路口场景。RoundaboutHD提供了总计40分钟的标记视频片段，由四个非重叠、高分辨率（4K分辨率，15 fps）的摄像头拍摄。总共标注了跨越不同摄像头视图的512个独特车辆身份，提供了丰富的跨摄像头关联数据。RoundaboutHD提供了时间一致性的视频片段和增强的挑战，包括环形交叉路口内部增加的遮挡和非线性运动。除了完整的MCVT数据集外，还提供了一些用于对象检测、单摄像头跟踪和基于图像的车辆重识别（ReID）任务的子集。数据集中还包含车辆模型信息和摄像头建模/几何信息，以支持进一步分析。我们提供了车辆检测、单摄像头跟踪、基于图像的车辆重识别和多摄像头跟踪的基线结果。数据集和评估代码可在以下网址公开获取：https://github.com/siri-rouser/RoundaboutHD.git

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [484] [MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion](https://arxiv.org/abs/2507.08344)
> *MM-Gesture：通过多模态融合实现精确的微手势识别*

*Jihao Gu, Fei Wang, Kun Li, Yanyan Wei, Zhiliang Wu, Dan Guo* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 微手势识别,多模态融合,PoseConv3D,视频Swin Transformer,模态加权集成

**Comment:** 

> **TL;DR:** HFUT-VUT团队提出的MM-Gesture框架在IJCAI 2025的MiGA挑战赛微手势分类赛道上排名第一，通过融合骨骼、肢体、RGB视频、泰勒级数视频、光流视频和深度视频等多种模态，并结合PoseConv3D和视频Swin Transformer架构以及模态加权集成策略，在iMiGUE基准上实现了73.213%的准确率。

**AI_Comments:** 该研究在微手势识别领域取得了显著进展，通过多模态融合和创新的集成策略有效提升了识别精度。其在MiGA挑战赛中的优异表现以及在iMiGUE基准测试中的高准确率，证明了该方法的有效性和潜力。然而，关于不同模态贡献的具体分析和不同集成策略的详细比较可以进一步丰富该研究。

<details>
  <summary>Details</summary>

**Motivation:** 识别细微且持续时间短的微手势（MGs）是一个挑战，需要整合多种互补的线索。

**Method:** MM-Gesture是一个多模态融合框架，集成了骨骼、肢体、RGB视频、泰勒级数视频、光流视频和深度视频等多种模态的线索。它利用PoseConv3D和视频Swin Transformer架构，并采用新颖的模态加权集成策略。RGB模态的性能通过在MA-52数据集上进行迁移学习进一步提升。

**Result:** 在iMiGUE基准上的实验，包括跨不同模态的消融研究，验证了所提出方法的效果，达到了73.213%的top-1准确率。

**Conclusion:** MM-Gesture通过多模态融合和创新的策略，在微手势识别方面取得了优越的性能，超越了现有最先进的方法。

> **ai_Abstract:** MM-Gesture是一个用于精确微手势识别的多模态融合框架，该框架在MiGA挑战赛中取得了领先的性能。它通过整合多种数据模态（如骨骼、RGB视频、深度视频等）并利用先进的神经网络架构（如PoseConv3D和视频Swin Transformer）以及模态加权集成策略来实现这一目标。此外，通过迁移学习进一步增强了RGB模态的性能。实验结果表明，该方法在iMiGUE基准测试中表现出色，准确率达到73.213%。

> **摘要翻译:** 在本篇论文中，我们提出了MM-Gesture，这是我们的HFUT-VUT团队开发的解决方案，在2025年IJCAI第三届MiGA挑战赛的微手势分类赛道上名列第一，取得了优于先前最先进方法的性能。MM-Gesture是一个多模态融合框架，专门用于识别细微且持续时间短的微手势（MGs），整合了来自骨骼、肢体、RGB视频、泰勒级数视频、光流视频和深度视频模态的互补线索。我们的方法利用PoseConv3D和视频Swin Transformer架构，并结合新颖的模态加权集成策略，通过在更大的MA-52数据集上进行迁移学习进一步提升了RGB模态的性能。在iMiGUE基准上进行的广泛实验，包括跨不同模态的消融研究，验证了我们提出的方法的有效性，达到了73.213%的top-1准确率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [499] [Cycle Context Verification for In-Context Medical Image Segmentation](https://arxiv.org/abs/2507.08357)
> *用于上下文医学图像分割的周期性上下文验证*

*Shishuai Hu, Zehui Liao, Liangli Zhen, Huazhu Fu, Yong Xia* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 上下文学习, 医学图像分割, 周期性上下文验证, 上下文对齐, 提示

**Comment:** MICCAI 2025

> **TL;DR:** 该研究提出了一种名为周期性上下文验证（CCV）的新框架，用于提高基于上下文学习（ICL）的医学图像分割的性能。CCV通过一个循环过程来验证分割预测，并优化查询图像和上下文图像/掩码对之间的对齐，解决了临床场景中选择最佳上下文对的挑战。实验结果表明，CCV在多个数据集上优于现有方法，为通用医学图像分割提供了一个稳健的解决方案。

**AI_Comments:** 该研究提出的CCV框架通过引入上下文验证和查询特定提示来解决ICL在医学图像分割中的关键挑战，具有一定的创新性。循环验证机制巧妙地利用了现有模型的能力来评估和改进分割质量，避免了额外的模型训练或微调。然而，该方法在计算效率和对不同类型医学图像的泛化能力方面可能仍有提升空间。此外，提示的引入和更新机制的有效性可能依赖于具体的任务和数据集，需要进一步的消融研究来证明其鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 临床场景中，由于标注医学图像的稀缺性，选择最佳的上下文图像/掩码对以用于上下文学习（ICL）具有挑战性。此外，由于计算成本和灾难性遗忘的风险，对基础ICL模型进行上下文数据微调是不可行的。

**Method:** 提出了一种名为周期性上下文验证（CCV）的新框架。CCV采用循环流程：首先，模型为查询图像生成分割掩码；然后，交换查询图像和上下文对的角色，使模型通过预测原始上下文图像的掩码来验证其初始预测的准确性。通过引入查询特定的提示来修改查询图像，并更新该提示以改进上下文对齐的度量。

**Result:** 在七个医学图像分割数据集上使用两个ICL基础模型对CCV进行了评估，结果显示其优于现有方法，能够有效提高ICL的分割性能，为通用医学图像分割提供了一个稳健的解决方案。

**Conclusion:** CCV框架通过自我验证预测和增强上下文对齐，能够有效提升ICL在医学图像分割任务中的性能，为实现通用医学图像分割提供了一种鲁棒的解决方案。

> **ai_Abstract:** 本研究提出了一种名为周期性上下文验证（CCV）的新框架，用于改进上下文学习（ICL）在医学图像分割中的应用。CCV通过一个循环过程来验证分割预测并优化上下文对齐，解决了在数据稀疏的临床环境中选择合适上下文样本的挑战。实验证明，CCV在多个数据集上均表现出色，能够有效提升ICL在通用医学图像分割任务中的性能。

> **摘要翻译:** 上下文学习（ICL）作为一种有前途的技术，正用于实现通用医学图像分割，即使用单个模型对各种成像模态下的感兴趣对象进行分割。然而，其性能对查询图像与上下文图像掩码对的对齐非常敏感。在临床场景中，标注医学图像的稀缺性使得选择最佳的上下文对具有挑战性，并且由于计算成本和灾难性遗忘的风险，对基础ICL模型进行上下文数据微调是不可行的。为了解决这一挑战，我们提出了一种名为周期性上下文验证（CCV）的新颖框架，通过实现预测的自我验证并相应地增强上下文对齐，来增强基于ICL的医学图像分割。具体来说，CCV采用了一个循环流程，其中模型首先为查询图像生成分割掩码。随后，交换查询和上下文对的角色，使模型能够通过预测原始上下文图像的掩码来验证其预测。该二次预测的准确性作为初始查询分割的隐式度量。引入了一个查询特定的提示来修改查询图像，并更新该提示以改进度量，从而增强查询和上下文对之间的对齐。我们在七个医学图像分割数据集上使用两个ICL基础模型评估了CCV，证明了其优于现有方法的性能。我们的结果强调了CCV在增强基于ICL的分割方面的能力，使其成为通用医学图像分割的稳健解决方案。代码将在https://github.com/ShishuaiHu/CCV提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [500] [A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification](https://arxiv.org/abs/2507.08766)
> *混合多阱Hopfield-CNN结合特征提取与K均值用于MNIST分类*

*Ahmed Farooq* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 混合模型, Hopfield网络, 卷积神经网络, K均值聚类, MNIST分类

**Comment:** 

> **TL;DR:** 提出了一种结合CNN特征提取、K均值聚类和多阱Hopfield网络的混合模型用于MNIST手写数字分类，实现了99.2%的准确率。

**AI_Comments:** 该研究提出了一种创新的混合模型，将CNN的特征提取能力与Hopfield网络的联想记忆和能量最小化机制相结合，用于MNIST分类任务。模型在处理类内变异性方面表现出色，并通过能量函数提供了可解释性。然而，模型的复杂性以及对超参数（如CNN架构和阱数量）的敏感性可能是其局限性。未来的工作可以探索更广泛的数据集和更复杂的模式识别任务。

<details>
  <summary>Details</summary>

**Motivation:** 对MNIST数据集进行手写数字分类，需要一种能够鲁棒处理类内变异性（如不同书写风格）并提供可解释框架（通过基于能量的决策过程）的模型。

**Method:** 使用CNN提取图像高维特征，然后用K均值聚类将特征聚类为类别原型。这些原型作为多阱能量景观中的吸引子，Hopfield网络通过最小化能量函数（平衡特征相似性和类别分配）来进行分类。

**Result:** 在10,000张MNIST图像上实现了99.2%的测试准确率。

**Conclusion:** 深度特征提取和充分的原型覆盖对于实现高分类性能至关重要，该混合模型在模式识别领域具有广泛的应用潜力。

> **ai_Abstract:** 该研究提出了一种新颖的混合模型，用于MNIST数据集的手写数字分类。该模型集成了卷积神经网络（CNN）进行特征提取、K均值聚类生成类别原型，以及一个多阱Hopfield网络进行最终分类。通过优化CNN结构和网络参数，该模型在MNIST测试集上取得了99.2%的准确率，展示了其在处理类内差异和提供可解释性方面的优势。

> **摘要翻译:** 本研究提出了一种用于MNIST数据集手写数字分类的混合模型，该模型结合了卷积神经网络（CNN）和多阱Hopfield网络。该方法采用CNN从输入图像中提取高维特征，然后使用k-means聚类将这些特征聚类为特定类别的原型。这些原型作为多阱能量景观中的吸引子，其中Hopfield网络通过最小化能量函数来进行分类，该函数平衡了特征相似性和类别分配。该模型的设计能够鲁棒地处理类内变异性，例如不同的书写风格，同时通过其基于能量的决策过程提供了一个可解释的框架。通过对CNN架构和阱数量进行系统优化，该模型在10,000张MNIST图像上达到了99.2%的高测试准确率，证明了其在图像分类任务中的有效性。研究结果强调了深度特征提取和充分的原型覆盖在实现高性能方面起着关键作用，并具有在模式识别领域广泛应用的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [506] [MP-HSIR: A Multi-Prompt Framework for Universal Hyperspectral Image Restoration](https://arxiv.org/abs/2503.09131)
> *多提示框架通用高光谱图像复原*

*Zhehui Wu, Yong Chen, Naoto Yokoya, Wei He* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 高光谱图像复原, 多提示框架, Transformer, 降质处理, 视觉-语言

**Comment:** 

> **TL;DR:** 本研究提出了一种名为MP-HSIR的多提示框架，用于通用高光谱图像复原，能够处理各种降质类型和强度。该框架结合了光谱、文本和视觉提示，并通过空间-光谱Transformer模型进行处理，其中包含空间自注意力和提示引导的双分支光谱自注意力。实验证明，MP-HSIR在多种高光谱图像复原任务中优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的多提示框架MP-HSIR，用于解决高光谱图像复原中的通用性问题。通过结合光谱、文本和视觉提示，并利用先进的Transformer架构，该方法在多种降质场景下展现出优越的性能。其创新之处在于能够处理未知和多样化的降质，并且在泛化能力和性能上超越了现有方法。该研究为高光谱图像复原领域提供了新的解决方案和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有高光谱图像复原方法依赖于特定的降质假设，在复杂场景下的效果有限。

**Method:** 提出了一种名为MP-HSIR的多提示框架，该框架集成了光谱、文本和视觉提示。核心是一个提示引导的空间-光谱Transformer，包含空间自注意力和提示引导的双分支光谱自注意力。引入了光谱提示以提供通用的低秩光谱模式作为先验知识，并结合文本-视觉协同提示来融合高层语义和细粒度视觉特征以编码降质信息。

**Result:** 在9个高光谱图像复原任务上的广泛实验表明，MP-HSIR在全能场景、泛化测试和真实世界案例中，持续优于现有的全能方法，并在多个任务上超越了最先进的特定任务方法。

**Conclusion:** MP-HSIR是一种创新的多提示框架，能够实现通用高光谱图像复原，在各种降质情况下均表现出色，优于现有方法。

> **ai_Abstract:** MP-HSIR是一个创新的多提示框架，用于解决高光谱图像（HSI）在成像过程中遇到的各种未知降质问题。该框架通过整合光谱、文本和视觉提示，并利用提示引导的空间-光谱Transformer（包含空间自注意力和光谱自注意力），实现了跨多种降质类型的通用HSI复原。实验结果表明，MP-HSIR在多种任务上均优于现有的全能方法和特定任务方法。

> **摘要翻译:** 高光谱图像（HSIs）在成像过程中常常会受到各种未知降质的影响，导致严重的spectral和spatial失真。现有的HSI复原方法通常依赖于特定的降质假设，这限制了它们在复杂场景下的有效性。在本研究中，我们提出了一种新颖的多提示框架——MP-HSIR，该框架能够有效地整合spectral、文本和视觉提示，以实现跨越不同降质类型和强度的通用HSI复原。具体来说，我们开发了一个提示引导的空间-光谱Transformer，其中包含了空间自注意力和提示引导的双分支光谱自注意力。由于降质对spectral特征的影响不同，我们在局部spectral分支中引入了spectral提示，以提供通用的低秩spectral模式作为先验知识，从而增强spectral重建。此外，文本-视觉协同提示融合了高层语义表示和细粒度视觉特征，以编码降质信息，从而指导复原过程。在9个HSI复原任务上的广泛实验，包括全能场景、泛化测试和真实世界案例，证明了MP-HSIR不仅持续优于现有的全能方法，而且在多个任务上超越了最先进的特定任务方法。代码和模型可在https://github.com/ZhehuiWu/MP-HSIR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [510] [Ensemble of Weak Spectral Total Variation Learners: a PET-CT Case Study](https://arxiv.org/abs/2507.08735)
> *弱谱全变分学习器集成：PET-CT案例研究*

*Anna Rosenberg, John Kennedy, Zohar Keidar, Yehoshua Y. Zeevi, Guy Gilboa* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 谱全变分, 弱学习器集成, PET-CT, 医学影像, 特征提取

**Comment:** 

> **TL;DR:** 该研究提出使用弱学习器集成，基于谱全变分（STV）特征，来解决计算机视觉中训练数据不足的问题。在PET-CT医学影像分析中，STV特征被证明比深度学习和Radiomics特征更有效，尤其是在CT图像的精细尺度上，能够更好地预测PET显像中高摄取的情况。

**AI_Comments:** 该研究提出了一种新颖的集成学习方法，利用谱全变分（STV）特征来解决医学影像分析中的挑战，并在实际PET-CT数据上取得了优于现有方法的成果。该方法在处理数据不足问题上显示出巨大潜力，但需要进一步研究其在其他医学影像模态和疾病诊断任务中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决计算机视觉任务中训练数据不足的问题，提出使用基于谱全变分（STV）特征的弱学习器集成。

**Method:** 利用谱全变分（STV）特征设计学习器集成，并将其应用于PET-CT医学影像分析，以预测高摄取情况。

**Result:** 与深度学习和Radiomics特征相比，STV学习器在PET-CT分析中表现最佳，AUC值为0.87，而深度学习为0.75，Radiomics为0.79。研究还发现CT图像的精细STV尺度对预测PET高摄取尤其有指示作用。

**Conclusion:** 基于STV特征的学习器集成是一种有效的方法，尤其在医学影像分析等数据量有限的计算机视觉任务中，相比于深度学习和Radiomics方法表现更优。

> **ai_Abstract:** 本研究提出了一种利用谱全变分（STV）特征的弱学习器集成方法，以应对计算机视觉任务中数据稀疏的挑战。通过在PET-CT医学影像数据上进行评估，该方法在预测PET高摄取方面表现出色，优于深度学习和Radiomics方法，并且发现CT图像的精细STV尺度是关键的预测因素。

> **摘要翻译:** 为了解决计算机视觉任务中训练数据不足的问题，我们提出使用基于谱全变分（STV）特征的弱学习器集成。这些特征与全变分次梯度相关的非线性特征相关，并且能够在不同尺度上很好地表征纹理。在一维情况下，这些特征被证明是正交的，而在二维情况下，这些特征的经验相关性较低。集成学习理论提倡使用低相关性的弱学习器。因此，我们提出在此设计使用基于STV特征的学习器。为了展示这种范例的有效性，我们研究了一个困难的真实世界医学成像问题：计算断层扫描（CT）数据对于疑似骨骼转移瘤患者的 the positron emission tomography （PET）高摄取值的预测价值。数据库包含457个扫描，其中包含1524个已配准的CT和PET切片对。我们将我们的方法与深度学习方法和Radiomics特征进行了比较，结果表明STV学习器的表现最佳（AUC=0.87），优于神经网络（AUC=0.75）和Radiomics（AUC=0.79）。我们观察到CT图像中的精细STV尺度对于PET高摄取的存在尤其具有指示作用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [514] [Understanding Driving Risks using Large Language Models: Toward Elderly Driver Assessment](https://arxiv.org/abs/2507.08367)
> *理解驾驶风险利用大型语言模型：面向老年驾驶员评估*

*Yuki Yoshihara, Linjing Jiang, Nihan Karatas, Hitoshi Kanamori, Asuka Harada, Takahiro Tanaka* | **Category: cs.CV, cs.SY, eess.SY** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型,老年驾驶员评估,交通风险,ChatGPT-4o,提示词工程

**Comment:** 

> **TL;DR:** 本研究使用ChatGPT-4o模型评估老年驾驶员在交通场景中的风险，重点关注交通密度、交叉口可见性和停车标志识别。研究发现，提示词设计对模型性能有显著影响，多提示词策略能提高交叉口可见性的召回率。模型在停车标志识别方面精度较高，但召回率较低。模型解释性文本与其预测一致，表明LLM在驾驶风险评估方面具有潜力。

**AI_Comments:** 这项研究非常有前景，它展示了大型语言模型在理解复杂交通场景和辅助老年驾驶员评估方面的潜力。研究方法采用了多种提示策略，并对结果进行了量化分析，具有一定的说服力。然而，研究也指出了模型在处理模糊场景和识别停车标志召回率方面存在的局限性。未来的研究可以进一步探索如何提高模型在这些方面的表现，以及在真实驾驶环境中的应用效果。

<details>
  <summary>Details</summary>

**Motivation:** 老年驾驶员的驾驶风险评估是一个重要问题，本研究旨在探索大型语言模型（LLM）在理解交通场景和评估驾驶风险方面的潜力，特别是针对老年驾驶员的评估任务。

**Method:** 本研究使用ChatGPT-4o模型，通过零样本、少样本和多样本提示词策略，对静态行车记录仪图像进行交通密度评估、交叉口可见性评估和停车标志识别这三个与老年驾驶员评估相关的任务。使用精确率、召回率和F1分数作为评估指标，并与人类标注进行比较。

**Result:** 提示词设计显著影响模型性能。在交叉口可见性评估中，多样本提示词策略将召回率从21.7%提高到57.0%。在交通密度评估中，模型与人类的同意度从53.5%提高到67.6%。在停车标志识别任务中，模型表现出高达86.3%的精确率，但召回率约为76.7%，显示出保守的响应倾向。输出稳定性分析表明，模型和人类在解释结构模糊场景时都遇到困难。然而，模型的解释性文本与其预测结果一致，提高了模型的可解释性。

**Conclusion:** 研究表明，经过精心设计的提示词，大型语言模型（LLM）有潜力作为辅助工具，用于驾驶风险的场景级评估，尤其是在老年驾驶员评估方面。未来的研究应探索更大规模的数据集、更多样化的标注者以及下一代模型架构的应用，以进一步提升模型在老年驾驶员评估方面的能力。

> **ai_Abstract:** 本研究探索了利用ChatGPT-4o大型语言模型评估老年驾驶员驾驶风险的潜力。通过对交通密度、交叉口可见性和停车标志识别任务的分析，研究发现提示词设计对模型性能有显著影响，多提示词策略能提高模型在交叉口可见性评估中的召回率。尽管模型在停车标志识别方面精度较高但召回率较低，其解释性文本与预测结果的一致性增强了模型的可解释性。研究结论认为，LLM在经过优化的提示词设计下，可作为驾驶风险评估的辅助工具，并提出未来应在更大规模数据集和更多样化标注者上进行研究。

> **摘要翻译:** 本研究调查了多模态大型语言模型（LLM），特别是ChatGPT-4o，利用静态行车记录仪图像进行类似人类的交通场景解释的潜力。在此，我们重点关注与老年驾驶员评估相关的三个判断任务：评估交通密度、评估交叉口可见性以及识别停车标志。这些任务需要情境推理而非简单的物体检测。我们使用了零样本、少样本和多样本提示策略，并以人类标注作为参考标准来评估模型的性能。评估指标包括精确率、召回率和F1分数。结果表明，提示词设计在很大程度上影响了性能，交叉口可见性的召回率从21.7%（零样本）提高到57.0%（多样本）。对于交通密度，一致性从53.5%提高到67.6%。在停车标志识别方面，模型表现出高精确率（高达86.3%），但召回率较低（约76.7%），表明存在保守的响应倾向。输出稳定性分析显示，人类和模型在解释结构模糊的场景时都面临困难。然而，模型的解释性文本与其预测结果相符，提高了可解释性。这些发现表明，通过精心设计的提示词，LLM有潜力作为支持性工具，用于场景级别的驾驶风险评估。未来的研究应探索使用更大规模的数据集、多样化的标注者和下一代模型架构进行老年驾驶员评估的可扩展性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [518] [Development of a Canada-Wide Morphology Map for the ITU-R P. 1411 Propagation Model](https://arxiv.org/abs/2507.08026)
> *加拿大ITU-R P.1411传播模型的全国形态图开发*

*Jennifer P. T. Nguyen* | **Category: cs.CV** | **Updated: 2025-07-08**

**Keywords:** 形态图, ITU-R P.1411, 传播模型, 机器学习, 路径损耗

**Comment:** 

> **TL;DR:** 该论文开发了一个加拿大范围的形态图，将区域分为住宅、低层 urban 和高层 urban 环境，以改进ITU-R P.1411传播模型的路径损耗估计。

**AI_Comments:** 这项工作通过引入机器学习来量化和自动化传播模型中的环境分类，为提高无线传播预测的准确性做出了贡献。然而，模型对不同地理和城市化模式的泛化能力以及对不同类型城市环境的区分度仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决ITU-R P.1411-12传播模型中环境类型描述符的定性性质，并为加拿大范围内的户外短距离传播提供更准确的路径损耗估计。

**Method:** 采用机器学习方法自动对加拿大区域进行分类，将区域划分为住宅、低层 urban 和高层 urban 环境。

**Result:** 开发了一个加拿大范围的形态图，能够对区域进行分类，从而实现更准确的路径损耗估计。

**Conclusion:** 开发了一个加拿大范围的形态图，并使用机器学习方法对区域进行分类，以提高ITU-R P.1411传播模型的准确性。

> **ai_Abstract:** 本研究开发了一个加拿大范围的形态图，根据ITU-R P.1411-12传播模型的指导方针，将不同区域划分为住宅、低层 urban 和高层 urban 环境。通过采用机器学习方法来解决环境类型描述符的定性问题，并经过大量优化实验，最终生成的形态图能够显著提高户外短距离传播的路径损耗估计精度。

> **摘要翻译:** 本文概述了根据ITU-R P.1411-12传播模型指南，开发加拿大范围的形态图，将区域划分为住宅、低层 urban 和高层 urban 环境。为了解决该建议书中环境类型描述符的定性性质，采用了机器学习方法来自动化分类过程。大量的实验优化了分类精度，最终形成了加拿大范围的形态图，确保了在300 MHz至100 GHz频率范围内户外短距离传播的更准确的路径损耗估计。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [528] [Interpretability-Aware Pruning for Efficient Medical Image Analysis](https://arxiv.org/abs/2507.08330)
> *面向可解释性的剪枝以实现高效的医学图像分析*

*Nikita Malik, Pratinav Seth, Neeraj Kumar Singh, Chintan Chitroda, Vinay Kumar Sankarapu* | **Category: cs.CV, cs.AI, cs.ET, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 可解释性，剪枝，医学图像分析，模型压缩，深度学习

**Comment:** Pre-Print

> **TL;DR:** 该研究提出了一种可解释性引导的剪枝框架，通过保留各层中最相关的部分来压缩深度学习模型，同时保持预测性能和透明度，适用于医疗图像分析。

**AI_Comments:** 这项工作通过将可解释性与模型剪枝相结合，为解决深度学习在医学图像分析中的实际部署挑战提供了一个有前景的解决方案。保留可解释性是该方法的一个关键优势，这对于在医疗保健领域建立信任至关重要。然而，进一步研究该方法在不同类型医学图像和不同临床应用中的泛化能力以及计算效率将是有价值的。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在医学图像分析方面取得了显著进展，但其在临床实践中的应用受到模型规模大和缺乏透明度的限制。

**Method:** 提出了一种可解释性引导的剪枝框架，该框架通过选择性地保留神经网络中每个层最相关的部分来减少模型复杂性。

**Result:** 实验表明，该方法在多个医学图像分类基准测试中实现了高压缩率和最小的准确率损失。

**Conclusion:** 该方法能够实现模型压缩，同时保持预测性能和透明度，为开发轻量级、可解释性强的模型以满足医疗保健领域的实际部署需求铺平了道路。

> **ai_Abstract:** 本研究提出了一种可解释性引导的剪枝框架，用于高效的医学图像分析。该框架通过保留神经网络中各层最相关的部分来压缩模型，从而在降低模型复杂性的同时，保持预测性能和透明度。实验证明，该方法能在医学图像分类任务中实现高压缩率和最小的准确率损失，有望部署到实际医疗保健场景中。

> **摘要翻译:** 深度学习在医学图像分析领域取得了显著进展，但其在临床实践中的应用仍然受到现代模型规模庞大和缺乏透明度的限制。诸如DL-Backtrace、Layer-wise Relevance Propagation和Integrated Gradients等可解释性技术的进步使得评估在医学成像任务上训练的神经网络中各个组件的贡献成为可能。在本研究中，我们引入了一个可解释性引导的剪枝框架，该框架在保持预测性能和透明度的同时减少了模型复杂性。通过有选择地保留每个层中最相关的部分，我们的方法实现了有针对性的压缩，从而保持了临床上有意义的表示。在多个医学图像分类基准测试上的实验表明，该方法在实现高压缩率的同时，准确率损失极小，为开发适合医疗保健领域实际部署的轻量级、可解释性模型铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [531] [MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs](https://arxiv.org/abs/2504.06897)
> *MedSegFactory：文本引导的医学图像-掩模对生成*

*Jiawei Mao, Yuhan Wang, Yucheng Tang, Daguang Xu, Kang Wang, Yang Yang, Zongwei Zhou, Yuyin Zhou* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 医学图像合成, 分割掩模, 扩散模型, 联合交叉注意力, 数据增强

**Comment:** 12 pages, 8 figures, The project page can be accessed via
  https://jwmao1.github.io/MedSegFactory_web

> **TL;DR:** MedSegFactory是一个用于生成配对医学图像和分割掩模的框架，使用双流扩散模型和联合交叉注意力机制，以文本提示为指导，能够生成高质量、多样化的数据，并已在分割任务中取得良好效果。

**AI_Comments:** 该研究提出了一种新颖的文本引导医学图像合成方法，解决了医学领域数据稀缺的关键问题。通过双流扩散模型和JCA机制，实现了图像和掩模的高度一致性，这在医学应用中至关重要。然而，对于生成模型在不同模态和复杂解剖结构下的泛化能力和潜在的伪影问题，还需要进一步的探讨。该方法为提升医学图像分析的效率和准确性提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决医学图像数据稀缺和监管限制问题，为医学图像分割工具提供无限的数据集，以提高其性能。

**Method:** 提出MedSegFactory框架，采用双流扩散模型（一个生成图像，一个生成掩模），并引入联合交叉注意力（JCA）机制，实现双向交叉条件，以保证图像和掩模的精确对齐和一致性。

**Result:** MedSegFactory能够根据文本提示按需生成配对的医学图像和分割掩模，生成的医学图像数据质量和可用性优于现有方法，并在2D和3D分割任务中达到具有竞争力的或最先进的性能。

**Conclusion:** MedSegFactory是一个新颖的医学图像合成范式，能够高效、高质量地生成配对的医学图像和分割掩模，解决了数据稀缺问题，并能无缝集成到各种医学成像工作流程中，提高了效率和准确性。

> **ai_Abstract:** MedSegFactory是一个创新的框架，利用文本提示指导生成配对的医学图像和分割掩模。它采用双流扩散模型和联合交叉注意力机制，实现了图像和掩模之间的高度一致性和精确对齐。该框架能够按需生成多样化的医学数据，有效解决了数据稀缺问题，并在多项医学图像分割任务中展现出优越的性能。

> **摘要翻译:** 本文提出了MedSegFactory，一个通用的医学合成框架，可以在各种模态和任务中生成高质量的配对医学图像和分割掩模。它旨在作为一个无限的数据存储库，为现有的分割工具提供图像-掩模对以增强其性能。MedSegFactory的核心是双流扩散模型，其中一个流合成医学图像，另一个流生成相应的分割掩模。为了确保图像-掩模对之间的精确对齐，我们引入了联合交叉注意力（JCA），通过流之间的动态交叉条件来实现协作去噪范式。这种双向交互允许两种表示相互指导生成，增强了生成对之间的一致性。MedSegFactory通过用户定义的提示解锁了按需生成配对医学图像和分割掩模的能力，这些提示指定了目标标签、成像模态、解剖区域和病理状况，促进了可扩展和高质量的数据生成。这种新的医学图像合成范式能够无缝集成到各种医学成像工作流程中，提高了效率和准确性。广泛的实验表明，MedSegFactory生成的数据在质量和可用性方面均优于现有方法，在2D和3D分割任务中达到了具有竞争力的或最先进的性能，同时解决了数据稀缺和监管限制问题。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [Unsupervised Methods for Video Quality Improvement: A Survey of Restoration and Enhancement Techniques](https://arxiv.org/abs/2507.08375)
> *无监督视频质量提升方法：修复与增强技术综述*

*Alexandra Malyugina, Yini Li, Joanne Lin, Nantheera Anantrasirichai* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 视频修复, 视频增强, 无监督学习, 计算机视觉, 视频质量

**Comment:** 

> **TL;DR:** 本综述全面回顾了视频修复和增强技术，重点关注无监督方法，涵盖了视频退化、传统和深度学习方法、无监督方法的分类（如域翻译、自监督信号设计、盲点或噪声方法）、损失函数以及未来研究方向。

**AI_Comments:** 这篇综述为理解无监督视频质量提升技术提供了一个全面的框架，对该领域的研究人员非常有价值。它清晰地分类了不同的方法，并指出了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 视频修复和增强对于提升视觉质量以及作为下游计算机视觉任务的预处理步骤至关重要。

**Method:** 本综述回顾了视频修复和增强技术，重点关注无监督方法，并根据基本方法（域翻译、自监督信号设计、盲点或噪声方法）进行了分类。还讨论了所使用的损失函数和配对合成数据集在客观评估中的作用。

**Result:** 本综述全面回顾了视频修复和增强技术，特别是无监督方法，并讨论了它们的挑战和未来研究方向。

**Conclusion:** 本综述全面回顾了视频修复和增强技术，特别是无监督方法，并指出了该领域的挑战和未来研究方向。

> **ai_Abstract:** 本综述全面概述了视频修复和增强技术，重点关注无监督方法，涵盖了视频退化、传统和深度学习方法、无监督方法的分类、损失函数以及未来研究方向，旨在为该领域提供一个全面的视角。

> **摘要翻译:** 视频修复和增强不仅对于提高视觉质量至关重要，而且是提高各种下游计算机视觉任务性能的重要预处理步骤。本调查全面回顾了视频修复和增强技术，特别关注无监督方法。我们首先概述了最常见的视频退化及其根本原因，然后回顾了基于早期传统和深度学习的方法，强调了它们的优缺点。接着，我们对无监督方法进行了深入概述，并根据其基本方法进行了分类，包括域翻译、自监督信号设计以及基于盲点或噪声的方法。我们还对无监督视频修复和增强中使用的损失函数进行了分类，并讨论了配对合成数据集在实现客观评估中的作用。最后，我们确定了该领域的关键挑战，并概述了有希望的未来研究方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [538] [HieraRS: A Hierarchical Segmentation Paradigm for Remote Sensing Enabling Multi-Granularity Interpretation and Cross-Domain Transfer](https://arxiv.org/abs/2507.08741)
> *遥感分层分割范式，支持多粒度解释和跨域迁移*

*Tianlong Ai, Tianzhu Liu, Haochen Jiang, Yanfeng Gu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 遥感图像分类, 分层分割, 多粒度解释, 跨领域迁移, 土地利用分类

**Comment:** 17 pages, 11 figures

> **TL;DR:** 提出了一种名为HieraRS的新型分层遥感图像分类方法，解决了现有方法在多粒度预测和跨领域迁移方面的局限性。该方法通过双向分层一致性约束机制（BHCCM）实现分层预测和提高精度，并通过TransLU框架（包含跨域知识共享CDKS和跨域语义对齐CDSA）实现了模型向异构层级（如LCLU到作物分类）的有效迁移。此外，还构建了一个大规模多模态分层土地利用数据集MM-5B。

**AI_Comments:** 该研究提出了一种创新的分层分割范式HieraRS，有效解决了遥感图像LCLU分类中多粒度预测和跨领域迁移的挑战。BHCCM机制能够增强现有模型的分层能力，而TransLU框架则为跨领域异构层级迁移提供了有效的解决方案。MM-5B数据集的发布将为该领域的研究提供重要资源。该方法在理论和实践层面都具有重要意义，但其在不同类型异构层级迁移任务上的具体表现和鲁棒性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习方法在遥感图像分类中存在两类主要问题：1）采用扁平化分类范式，难以生成符合实际应用中树状层级结构的多粒度分层预测；2）跨领域研究主要关注传感器或场景变化导致的性能下降，而对模型向具有异构层级（如LCLU到作物分类）的跨领域任务迁移的研究不足。这些限制了模型在实际应用中的灵活性和泛化能力。

**Method:** 提出了一种名为HieraRS的新型分层解释范式，该范式能够实现多粒度预测，并支持将土地利用分类（LCLU）模型高效迁移到具有异构层级结构的跨领域任务。具体包括：1）引入双向分层一致性约束机制（BHCCM），可集成到主流的扁平化分类模型中，实现分层预测，同时提高语义一致性和分类精度；2）提出TransLU跨领域迁移框架，包含跨域知识共享（CDKS）和跨域语义对齐（CDSA）两个关键组件，支持动态类别扩展，促进LCLU模型向异构层级的有效适应。此外，构建了一个大规模多模态分层土地利用数据集MM-5B。

**Result:** HieraRS通过BHCCM机制提升了分层预测能力和分类精度。TransLU框架有效实现了LCLU模型向异构层级的迁移，支持动态类别扩展和跨域语义对齐。

**Conclusion:** HieraRS通过引入BHCCM和TransLU框架，解决了遥感图像LCLU分类中的多粒度解释和跨领域迁移难题，提高了模型的灵活性和泛化能力，并发布了MM-5B数据集以支持相关研究。

> **ai_Abstract:** 本文提出了一种名为HieraRS的新型遥感图像分层分割方法，旨在解决现有技术在多粒度预测和跨领域迁移方面的不足。通过引入双向分层一致性约束机制（BHCCM）和TransLU跨领域迁移框架（包含CDKS和CDSA），HieraRS能够生成多粒度分层预测，并有效地将模型迁移到具有异构层级的不同任务，如从土地利用分类到作物分类。此外，该研究还发布了一个大规模多模态分层土地利用数据集MM-5B。

> **摘要翻译:** 分层土地覆盖和土地利用（LCLU）分类旨在为遥感（RS）图像分配具有多个语义粒度的像素级标签。然而，现有的基于深度学习的方法面临两大挑战：1）它们主要采用扁平化的分类范式，这限制了它们生成与实践中使用的树状层级结构相一致的端到端多粒度层级预测的能力。2）大多数跨领域研究侧重于传感器或场景变化引起性能下降的问题，而对将LCLU模型迁移到具有异构层级（例如，LCLU到作物分类）的跨领域任务的关注有限。这些局限性阻碍了LCLU模型在实际应用中的灵活性和泛化能力。为了解决这些挑战，我们提出了HieraRS，一种新颖的分层解释范式，能够实现多粒度预测，并支持将LCLU模型高效迁移到具有异构树状层级结构的跨领域任务。我们引入了双向分层一致性约束机制（BHCCM），它可以无缝集成到主流的扁平化分类模型中，生成层级预测，同时提高语义一致性和分类准确性。此外，我们提出了TransLU，一个包含两个关键组件：跨域知识共享（CDKS）和跨域语义对齐（CDSA）的双分支跨域迁移框架。TransLU支持动态类别扩展，并有助于LCLU模型向异构层级的有效适应。此外，我们构建了MM-5B，一个具有像素级标注的大规模多模态分层土地利用数据集。代码和MM-5B数据集将在以下网址发布：https://github.com/AI-Tianlong/HieraRS。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [539] [InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction](https://arxiv.org/abs/2503.20287)
> *基于指令的视频编辑：InsViE-1M 与详尽的数据集构建*

*Yuhui Wu, Liyi Chen, Ruibin Li, Shihao Wang, Chenxi Xie, Lei Zhang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 指令视频编辑, 数据集构建, InsViE-1M, GPT-4o, 多阶段学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 该研究提出了一个包含100万个三元组的高质量指令视频编辑数据集InsViE-1M，并通过多阶段学习策略训练了一个InsViE模型，在视频编辑任务上取得了优于现有方法的性能。

**AI_Comments:** 该研究在指令视频编辑领域做出了重要贡献，通过构建一个大规模、高质量的数据集（InsViE-1M）并提出相应的训练模型（InsViE），有效解决了现有数据集的不足。使用GPT-4o进行自动过滤是一个创新的方法，可以提高数据质量和效率。然而，数据集的构建流程和模型的具体细节（如多阶段学习策略的详细内容）在摘要中没有完全展开，这可能会影响对研究贡献的全面评估。未来的工作可以进一步探索更自动化的数据生成和过滤方法，以及更高效的模型架构。

<details>
  <summary>Details</summary>

**Motivation:** 现有指令视频编辑数据集存在分辨率低、时长短、视频数量有限和编辑质量不佳等问题，限制了模型性能。

**Method:** 研究人员首先收集了高分辨率的源视频和图像，然后设计了一个编辑-过滤流程来构建高质量的编辑三元组。具体来说，他们利用不同强度的无分类器引导生成视频第一帧的多个编辑样本，并使用GPT-4o进行自动过滤。编辑后的第一帧被传播到后续帧以生成编辑视频，之后再进行帧质量和运动评估的过滤。此外，他们还从高质量图像生成并过滤了各种视频编辑三元组。最后，利用InsViE-1M数据集提出了一个多阶段学习策略来训练InsViE模型。

**Result:** 研究表明，InsViE-1M数据集和训练的InsViE模型在指令视频编辑任务上优于最先进的方法。

**Conclusion:** InsViE-1M数据集和训练的InsViE模型在指令视频编辑方面取得了显著的进步，克服了现有方法的局限性。

> **ai_Abstract:** 本研究提出了InsViE-1M，一个包含100万个三元组的高质量指令视频编辑数据集，旨在解决现有数据集的局限性。研究人员通过精心设计的编辑-过滤流程构建了该数据集，并利用其训练了一个InsViE模型，该模型通过多阶段学习策略，在视频编辑任务上实现了优于现有方法的性能。

> **摘要翻译:** 指令视频编辑允许使用指令进行有效和交互式的视频编辑，而无需额外的掩码或属性输入。然而，收集高质量的训练三元组（源视频、编辑视频、指令）是一项挑战性任务。现有的数据集大多包含低分辨率、短时长、数量有限的源视频，并且编辑质量不佳，这限制了所训练的编辑模型的性能。在本研究中，我们提出了一个包含100万个三元组的高质量指令视频编辑数据集，名为InsViE-1M。我们首先整理了高分辨率、高质量的源视频和图像，然后设计了一个有效的编辑-过滤流程来构建高质量的编辑三元组以进行模型训练。对于一个源视频，我们通过不同强度的无分类器引导生成其第一帧的多个编辑样本，这些样本由经过精心设计的GPT-4o进行自动过滤。编辑后的第一帧被传播到后续帧以生成编辑视频，之后再进行一轮帧质量和运动评估的过滤。我们还从高质量图像生成并过滤了各种视频编辑三元组。利用InsViE-1M数据集，我们提出了一个多阶段学习策略来训练我们的InsViE模型，逐步增强其指令遵循和编辑能力。大量的实验证明了我们的InsViE-1M数据集和训练模型的优势超过了最先进的工作。代码可在InsViE找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [544] [Towards Evaluating Robustness of Prompt Adherence in Text to Image Models](https://arxiv.org/abs/2507.08039)
> *评估文本到图像模型中提示遵循的鲁棒性*

*Sujith Vemishetty, Advitiya Arora, Anupama Sharma* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-09**

**Keywords:** 文本到图像模型, 提示遵循, 鲁棒性评估, Stable Diffusion, Janus

**Comment:** 

> **TL;DR:** 该研究提出了一个评估文本到图像模型遵循提示能力的框架，并创建了一个新数据集。研究发现，即使是像Stable Diffusion和Janus这样先进的模型，在生成具有简单二元变化（形状和位置）的图像时也存在困难。

**AI_Comments:** 该研究有效地识别了当前文本到图像模型在遵循提示方面的局限性，特别是对于具有简单变化因素的图像生成。其提出的评估框架和新数据集为该领域的研究提供了宝贵的资源。然而，研究中使用的GPT-4o模型本身也可能存在偏差，这可能会影响评估结果的客观性。未来的工作可以探索更广泛的模型和更复杂的变化因素，以更全面地评估文本到图像模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像模型的研究不足，尤其是在评估其性能和鲁棒性方面，这限制了它们在现实世界中的应用。

**Method:** 创建了一个新数据集，利用GPT-4o生成的文本描述来创建真实图像，然后将这些描述输入到文本到图像模型以生成人工图像。接着，再次使用GPT-4o处理生成的人工图像，并比较两次生成的描述，以评估模型对提示的遵循程度。此外，还使用预训练的VAE在数据集上进行训练，以评估模型生成图像的分布遵循情况。

**Result:** 研究结果表明，即使是先进的文本到图像模型，在生成具有简单二元变化（如形状和位置）的图像时也存在困难。此外，研究还发现这些模型未能生成符合输入数据集分布的图像。

**Conclusion:** 当前的文本到图像模型在遵循用户提示方面仍有改进空间，尤其是在处理简单的图像生成任务时。需要进一步的研究来提高这些模型在鲁棒性和准确性方面的表现。

> **ai_Abstract:** 本研究提出了一种评估文本到图像模型在遵循用户提示方面的鲁棒性的新方法。通过构建一个包含由GPT-4o生成的描述的新数据集，研究人员评估了包括Stable Diffusion和Janus在内的多个模型。评估结果表明，这些模型在生成具有简单二元变化（如形状和位置）的图像时存在显著困难，并且未能生成符合特定数据分布的图像。

> **摘要翻译:** 近年来，大型语言模型（LLM）的进展令许多人惊讶，展示了它们卓越的能力和多样化的应用。它们在各种现实世界场景中的潜在应用已引起对其可靠性和有效性的显著研究。另一方面，与仅文本的LLM相比，多模态LLM和文本到图像模型最近才受到关注。由于评估其性能和鲁棒性的研究不足，它们的可靠性仍然受到限制。本文旨在建立一个全面的文本到图像模型评估框架，特别关注它们对提示的遵循程度。我们创建了一个新的数据集，旨在评估这些模型在生成符合输入文本提示中指定的变化因素的图像方面的鲁棒性。我们的评估研究展示了三个Stable Diffusion模型变体：Stable Diffusion 3 Medium、Stable Diffusion 3.5 Large和Stable Diffusion 3.5 Large Turbo，以及两个Janus模型变体：Janus Pro 1B和Janus Pro 7B。我们引入了一个利用gpt-4o模型生成的文本描述来创建我们真实图像的管道，然后将这些描述输入到文本到图像模型以生成人工图像。接着，我们再次使用相同的系统提示，通过gpt-4o处理这些生成的人工图像，并比较两次描述之间的差异。我们的结果显示，这些模型在创建仅具有两个变化因素的简单二元图像时存在困难：一个简单的几何形状及其位置。我们还通过在我们的数据集上使用预训练的VAE证明，它们未能生成符合我们输入数据集分布的图像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [549] [From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning](https://arxiv.org/abs/2507.08380)
> *从增强到理解：构建一个用于低光视觉的通用桥梁，通过语义一致的无监督微调*

*Sen Wang, Shao Zeng, Tianjun Gu, Zhizhong Zhang, Ruixin Zhang, Shouhong Ding, Jingyun Zhang, Jun Wang, Xin Tan, Yuan Xie, Lizhuang Ma* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 低光视觉, 图像增强, 视觉理解, 无监督微调, 生成模型

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 该研究提出了一种名为GEFU的新范式，通过无监督微调（SCUF）将低光图像增强与理解任务联系起来，利用生成模型和注意力机制来提高泛化能力和可扩展性，并在多项下游任务中取得了优于现有方法的性能。

**AI_Comments:** 该研究提出的GEFU范式和SCUF方法在解决低光视觉领域的增强与理解脱节问题上具有创新性。利用生成扩散模型和语义一致性约束是该方法的核心优势，实现了零样本泛化和更好的下游任务性能。然而，对于“照明感知图像提示”和“周期注意力适配器”的具体实现细节以及计算成本的分析可以在论文中进一步阐述。此外，评估指标的全面性，除了下游任务性能外，还应包含对图像增强质量的更深入分析。

<details>
  <summary>Details</summary>

**Motivation:** 低光视觉中的低级增强和高级理解任务一直被分开处理。现有的低光增强方法依赖于物理或几何先验，泛化能力受限，且评估主要关注视觉质量而非下游性能。低光视觉理解因标注数据稀缺，主要采用特定任务的领域自适应，可扩展性差。本研究旨在解决这些挑战，构建一个连接低光增强和低光理解的通用桥梁。

**Method:** 研究提出了一个名为GEFU的通用范式，并结合了无监督微调（SCUF）方法。首先利用预训练的生成扩散模型进行零样本图像优化以实现泛化。然后，通过引入照明感知图像提示来指导图像生成，并使用周期注意力适配器来最大化语义潜力。为了解决无监督训练中的语义退化问题，提出了字幕和反射率一致性来学习高级和图像级空间语义。

**Result:** 所提出的方法在传统图像质量和GEFU任务（包括分类、检测和语义分割）上均优于当前最先进的方法。

**Conclusion:** 本研究成功构建了一个连接低光增强和低光理解的通用桥梁（GEFU），并通过提出的SCUF方法实现了更好的泛化能力和可扩展性，在多项下游任务中取得了优越性能。

> **ai_Abstract:** 本研究提出了一种名为GEFU的新范式，旨在弥合低光图像增强与低光视觉理解之间的鸿沟，解决了传统方法泛化能力不足和可扩展性差的问题。通过利用预训练的生成扩散模型和一种名为SCUF的语义一致无监督微调方法，该研究引入了照明感知图像提示和周期注意力适配器来优化图像生成和语义提取。此外，还提出了字幕和反射率一致性来缓解无监督训练中的语义退化。实验结果表明，该方法在图像质量和分类、检测、语义分割等下游任务上均取得了优于现有技术的性能。

> **摘要翻译:** 低光视觉中的低级增强和高级理解任务一直被分开处理。低光增强旨在改善图像质量以用于下游任务，但现有方法依赖于物理或几何先验，限制了泛化能力。评估主要关注视觉质量而非下游性能。低光视觉理解受限于稀缺的标注数据，主要采用特定任务的领域自适应，缺乏可扩展性。为了解决这些挑战，我们构建了一个连接低光增强和低光理解的通用桥梁，我们称之为GEFU（Generalized Enhancement For Understanding）。该范式提高了泛化能力和可扩展性。为了解决低光退化的多样化原因，我们利用预训练的生成扩散模型来优化图像，实现了零样本泛化性能。在此基础上，我们提出了语义一致的无监督微调（SCUF）。具体来说，为了克服文本提示的局限性，我们引入了一个照明感知图像提示来显式指导图像生成，并提出了一个周期注意力适配器来最大化其语义潜力。为了减轻无监督训练中的语义退化，我们提出了字幕和反射率一致性来学习高级语义和图像级空间语义。大量的实验表明，我们提出的方法在传统图像质量和GEFU任务（包括分类、检测和语义分割）方面均优于当前最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [556] [An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision](https://arxiv.org/abs/2507.08165)
> *基于单目深度估计的计算机视觉嵌入式实时物体警报系统*

*Jareen Anjom, Rashik Iram Chowdhury, Tarbia Hasan, Md. Ishan Arefin Hossain* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-10**

**Keywords:** 计算机视觉, 单目深度估计, 实时物体检测, 视障辅助, 嵌入式系统

**Comment:** 

> **TL;DR:** 该研究提出了一种创新的警报系统，利用单目深度估计和物体检测，通过迁移学习和量化技术进行优化，以帮助视障人士在城市街道上安全出行。

**AI_Comments:** 该研究在利用计算机视觉技术帮助弱势群体方面具有重要意义。通过将单目深度估计和物体检测相结合，并针对嵌入式系统进行优化，该方法为视障人士提供了一个实用且高效的解决方案。然而，在真实复杂的城市环境中，该系统的鲁棒性和对各种光照条件、天气状况以及物体类型的适应性仍有待进一步的验证和提升。

<details>
  <summary>Details</summary>

**Motivation:** 孟加拉国城市道路上的障碍物给视障人士的日常出行带来了严峻挑战，频繁发生的交通事故凸显了开发一个能够提前警报视障人士近距离障碍物的系统的必要性。

**Method:** 该系统利用迁移学习训练深度估计和物体检测模型，并将两者结合。通过量化技术优化模型，使其轻量化并能在嵌入式系统上高效运行。

**Result:** 该系统成功实现了轻量级的实时深度估计和物体检测模型，mAP50达到了0.801。

**Conclusion:** 该研究成功开发了一个基于单目深度估计的计算机视觉系统，能够实时检测近距离障碍物并向视障人士发出警报，有助于提高他们在城市环境中出行的安全性。

> **ai_Abstract:** 本研究提出了一种新颖的嵌入式实时物体警报系统，旨在帮助视障人士应对城市通勤中的障碍物。该系统利用计算机视觉中的单目深度估计技术，并通过迁移学习训练深度估计和物体检测模型。为了实现高效部署，该系统采用了量化技术对模型进行优化，使其更加轻量化。最终，该系统成功实现了轻量级的实时深度估计和物体检测，mAP50达到了0.801，为视障人士提供了更安全的出行保障。

> **摘要翻译:** 视障人士在孟加拉国城市日常通勤中面临着严峻的挑战，因为每条路上都有大量的障碍物。鉴于每天发生的交通事故导致许多伤亡，开发一个能够提前警报视障人士近距离障碍物的系统至关重要。为了克服这个问题，本研究提出了一个新颖的警报系统，以协助视障人士在繁忙的街道上出行而不会与任何物体发生碰撞。该系统能够向个人发出近距离物体的警报。它利用迁移学习来训练深度估计和物体检测模型，并将这两个模型结合起来引入一个新颖的系统。通过利用量化技术优化模型，使其轻量化和高效，从而能够轻松地部署在嵌入式系统上。所提出的解决方案实现了轻量级的实时深度估计和物体检测模型，mAP50为0.801。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [559] [MGT: Extending Virtual Try-Off to Multi-Garment Scenarios](https://arxiv.org/abs/2504.13078)
> *MGT：将虚拟试穿扩展到多服装场景*

*Riza Velioglu, Petra Bevandic, Robin Chan, Barbara Hammer* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 虚拟试穿, 虚拟试穿, 多服装, 扩散模型, SigLIP

**Comment:** Accepted at ICCVW'25

> **TL;DR:** MGT是一种新的基于扩散模型的虚拟试穿（VTOFF）方法，可以处理上身、下身和连衣裙等多种服装类型，并在VITON-HD和DressCode数据集上实现了最先进的性能。

**AI_Comments:** 该研究提出了MGT模型，在虚拟试穿领域取得了显著进展，尤其是在处理多样的服装类型方面。模型结合了先进的扩散模型技术和特定类别的嵌入，有效地解决了服装多样性带来的挑战。其在多个数据集上的优异表现以及对p2p-VTON的改进作用，都显示了该方法的潜力和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的虚拟试穿（VTON）和虚拟试穿（VTOFF）技术在时尚行业得到应用，但VTOFF在处理多样化服装方面仍面临挑战。

**Method:** 提出了一种名为MGT（Multi-Garment TryOffDiff）的扩散模型，该模型采用潜在扩散架构和基于SigLIP的图像条件，并结合了特定类别的嵌入来处理不同类型的服装。

**Result:** MGT在VITON-HD数据集上实现了最先进的VTOFF结果，并在DressCode数据集上取得了有竞争力的性能。与VTON模型结合使用时，MGT可以减少不必要的属性转移（如肤色），从而提高p2p-VTON的效果。

**Conclusion:** MGT是一种有效处理多样化服装的VTOFF模型，通过其先进的架构和条件化技术，在虚拟试穿领域取得了显著成果，并能提升现有p2p-VTON方法的性能。

> **ai_Abstract:** MGT是一种创新的基于扩散的虚拟试穿（VTOFF）模型，能够处理上身、下身和连衣裙等多种服装。它利用潜在扩散架构和SigLIP图像条件来捕捉服装的形状、纹理和图案，并通过特定类别的嵌入来解决服装多样性问题。MGT在VITON-HD和DressCode数据集上取得了最先进或有竞争力的性能，并能通过减少不必要的属性转移来提升p2p-VTON的效果。

> **摘要翻译:** 计算机视觉通过虚拟试穿（VTON）和虚拟试穿（VTOFF）正在改变时尚行业。VTON使用目标照片和标准化的服装图像生成一个人穿着指定服装的图像，一个更具挑战性的变体，Person-to-Person Virtual Try-On（p2p-VTON），使用另一个人穿着该服装的照片。相比之下，VTOFF从穿着衣服的个体的照片中提取标准化的服装图像。我们引入了多服装试穿（MGT），一种基于扩散的VTOFF模型，能够处理各种服装类型，包括上身、下身和连衣裙。MGT基于潜在扩散架构，并使用基于SigLIP的图像条件来捕获服装特征，如形状、纹理和图案。为了解决服装多样性问题，MGT采用了特定类别的嵌入，在VITON-HD上实现了最先进的VTOFF结果，并在DressCode上取得了有竞争力的性能。当与VTON模型配对时，它通过减少不必要的属性转移（如肤色）来进一步增强p2p-VTON，确保保留特定于人的特征。演示、代码和模型可在：https://rizavelioglu.github.io/tryoffdiff/ 找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [562] [From One to More: Contextual Part Latents for 3D Generation](https://arxiv.org/abs/2507.08772)
> *从一到多：用于3D生成的上下文部件潜在表示*

*Shaocong Dong, Lihe Ding, Xiao Chen, Yaokun Li, Yuxin Wang, Yucheng Wang, Qi Wang, Jaehyeok Kim, Chenjian Gao, Zhanpeng Huang, Zibin Wang, Tianfan Xue, Dan Xu* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D生成, 部件表示, 扩散模型, 上下文学习, 组合设计

**Comment:** Project page: https://hkdsc.github.io/project/copart

> **TL;DR:** 该研究提出了一种名为CoPart的3D生成框架，通过将3D对象分解为上下文部件潜在表示来解决现有方法的局限性，实现了对部件的精细化控制和组合式设计，并通过构建Partverse数据集进行了验证，在部件编辑、关节对象生成和场景组合方面表现优异。

**AI_Comments:** 该研究提出了一种新颖的3D生成方法CoPart，通过引入部件感知和上下文潜在表示，有效解决了现有方法在处理复杂几何和控制粒度上的不足。Partverse数据集的构建也为后续研究提供了有力支持。然而，自动网格分割的准确性和人工验证的覆盖范围可能对模型性能产生影响，未来可以进一步探索更鲁棒的数据处理和模型优化策略。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D生成方法在处理复杂多部件几何形状、部件独立性和相互关系以及全局条件控制方面存在局限性，导致细节丢失、设计受限和控制不精确。

**Method:** 提出了一种名为CoPart的部件感知扩散框架，将3D对象分解为上下文部件潜在表示，并通过互导策略对预训练的扩散模型进行微调，以实现联合部件潜在去噪。同时构建了名为Partverse的新型3D部件数据集。

**Result:** CoPart在部件级编辑、关节对象生成和场景组合方面展现了优于现有方法的能力，实现了前所未有的可控性。

**Conclusion:** CoPart通过部件分解和上下文部件潜在表示，有效解决了现有3D生成方法的局限性，实现了更精细的控制和更丰富的生成效果，为3D内容创作提供了新的途径。

> **ai_Abstract:** 该研究提出了一种名为CoPart的3D生成框架，通过将3D对象分解为上下文部件潜在表示来解决现有方法的局限性，实现了对部件的精细化控制和组合式设计，并通过构建Partverse数据集进行了验证，在部件编辑、关节对象生成和场景组合方面表现优异。

> **摘要翻译:** 近期3D生成的研究已从多视角2D渲染方法转向3D原生潜在扩散框架，这些框架利用了真实数据中的几何先验。尽管取得了进展，但仍存在三个关键局限性：（1）单一潜在表示无法捕捉复杂的多部件几何形状，导致细节退化；（2）整体潜在编码忽略了部件独立性和相互关系，而这对组合式设计至关重要；（3）全局条件机制缺乏精细的控制力。受人类3D设计工作流程的启发，我们提出了CoPart——一个部件感知的扩散框架，将3D对象分解为上下文部件潜在表示，以实现连贯的多部件生成。该范式具有三个优点：i）通过部件分解降低编码复杂度；ii）能够显式建模部件关系；iii）支持部件级条件控制。我们进一步开发了一种互导策略，用于微调预训练的扩散模型以进行联合部件潜在去噪，确保了几何连贯性和基础模型先验。为了实现大规模训练，我们构建了Partverse——一个源自Objaverse的新型3D部件数据集，通过自动网格分割和人工验证的标注获得。大量的实验证明了CoPart在部件级编辑、关节对象生成和具有前所未有可控性的场景组合方面的卓越能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [565] [Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset](https://arxiv.org/abs/2507.08384)
> *闻起来很香，很密集，而且散开：嗅觉参考（ODOR）数据集的对象检测*

*Mathias Zinnen, Prathmesh Madhu, Inger Leemans, Peter Bell, Azhar Hussian, Hang Tran, Ali Hürriyetoğlu, Andreas Maier, Vincent Christlein* | **Category: cs.CV, 68T45 68T45, I.5.4; I.2.10; I.4.8** | **Updated: 2025-07-11**

**Keywords:** 对象检测,艺术品图像,细粒度识别,数据集,视觉文化遗产

**Comment:** 

> **TL;DR:** 该研究提出了ODOR数据集，一个包含38,116个对象级别注释和139个细粒度类别的艺术品图像数据集，旨在解决现有数据集在艺术抽象、外围对象和细粒度类别方面的不足，并提供了基线分析和对模型鲁棒性的挑战。

**AI_Comments:** 该数据集的创新之处在于其针对艺术品图像的细粒度类别和密集重叠对象的特性，这在现有数据集中较为罕见。它不仅为艺术品分析提供了新的工具，也为计算机视觉在人文学科的应用开辟了道路。然而，数据集的规模和标注的细致程度可能仍有提升空间，并且在实际应用中，如何将嗅觉感知与视觉信息有效结合仍是一个值得深入研究的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据集在艺术品图像对象检测方面存在偏差，偏向图像中心且类别有限，无法满足现实世界应用对鲁棒性和细粒度识别的需求。

**Method:** 创建了ODOR数据集，包含4712张图像和38,116个对象级别注释，涵盖139个细粒度类别。对数据集进行了统计分析，展示了其类别详细、对象密集重叠和空间分布广泛的特点。此外，还对对象检测模型进行了基线分析，并通过次级研究突出了数据集的挑战性。

**Result:** ODOR数据集提供了丰富的细粒度类别和密集重叠的对象，并展示了其在整个图像画布上的空间分布，对现有对象检测模型提出了挑战。

**Conclusion:** ODOR数据集通过提供细粒度的类别和具有挑战性的对象分布特性，填补了艺术品图像对象检测数据集的空白，并激励了对视觉文化遗产研究和嗅觉感知交叉领域的研究。

> **ai_Abstract:** 该研究介绍了ODOR数据集，这是一个专门为艺术品图像对象检测设计的、包含丰富细粒度类别和密集重叠对象的综合性数据集，旨在克服现有数据集的局限性，并为计算机视觉在人文学科中的应用提供新的挑战和研究方向。

> **摘要翻译:** 现实世界中计算机视觉在人文学科中的应用要求算法能够鲁棒地处理艺术抽象、外围对象以及细微的细粒度类别差异。现有的数据集提供了艺术品上的实例级标注，但普遍偏向图像中心，并且在详细的对象类别方面存在局限性。提出的ODOR数据集填补了这一空白，提供了跨越4712张图像的38,116个对象级别标注，涵盖了广泛的139个细粒度类别。通过进行统计分析，我们展示了数据集具有挑战性的特性，例如详细的类别集合、密集且重叠的对象以及在整个图像画布上的空间分布。此外，我们提供了对象检测模型的广泛基线分析，并通过一系列次级研究突出了数据集的挑战性。该数据集激发了对艺术品对象检测和更广泛的视觉文化遗产研究的进一步探索，并挑战研究人员探索对象识别与气味感知之间的交叉领域。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [567] [A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities](https://arxiv.org/abs/2504.00901)
> *十年深度学习遥感时空融合：进展、挑战与机遇*

*Enzhe Sun, Yongchuan Cui, Peng Liu, Jining Yan* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 深度学习, 遥感, 时空融合, Transformer, GAN

**Comment:** 

> **TL;DR:** 本综述总结了过去十年深度学习在遥感时空融合领域的进展，重点介绍了CNN、Transformer、GAN和扩散模型等架构的应用。研究发现CNN在空间特征提取方面表现突出，Transformer在捕捉长期时间依赖性方面表现优异，GAN和扩散模型在细节重建方面效果显著。文章还指出了时空冲突、泛化能力不足、计算效率、多源异构融合和基准多样性不足等挑战，并提出了基础模型、混合架构和自监督学习等未来研究方向。

**AI_Comments:** 这篇综述为遥感时空融合领域的研究提供了一个全面的视角，尤其是在深度学习方法的应用方面。文章结构清晰，内容详实，对该领域的研究者非常有价值。然而，对于实际应用中的模型部署和可解释性方面的讨论可以更深入一些。

<details>
  <summary>Details</summary>

**Motivation:** 随着遥感数据时空分辨率的权衡问题日益突出，利用深度学习技术解决遥感时空融合（STF）问题已成为研究热点。本综述旨在全面梳理过去十年深度学习在STF领域的发展，为研究人员提供指导。

**Method:** 本研究对过去十年深度学习在遥感时空融合领域的文献进行了全面的调查和梳理。研究者系统地对深度学习架构进行了分类，包括卷积神经网络（CNN）、Transformer、生成对抗网络（GAN）和扩散模型等。通过在七个基准数据集上进行实验，比较了十种代表性方法，以验证不同方法的性能和权衡。最后，总结了当前面临的挑战和未来的机遇。

**Result:** CNN在空间特征提取方面表现最佳；Transformer在捕捉长期时间依赖性方面表现优异；GAN和扩散模型在细节重建方面显著优于传统方法，在结构相似性和光谱保真度方面表现出色。通过实验验证了这些发现，并量化了不同方法之间的性能权衡。

**Conclusion:** 深度学习在遥感时空融合领域取得了显著进展，尤其在细节重建和长期时间依赖性捕捉方面表现突出。然而，仍存在时空冲突、泛化能力、计算效率、多源异构融合和基准多样性不足等挑战。未来研究应关注基础模型、混合架构和自监督学习等方向，以克服现有局限并实现多模态应用。

> **ai_Abstract:** 本综述系统地回顾了过去十年深度学习在遥感时空融合（STF）领域的进展。文章对CNN、Transformer、GAN和扩散模型等主流深度学习架构在STF任务中的应用进行了分类和分析，指出了它们在空间特征提取、时间依赖性捕捉和细节重建等方面的优势。研究通过实验验证了不同方法的性能，并总结了时空冲突、泛化能力、计算效率等五个关键挑战。最后，文章提出了基础模型、混合架构和自监督学习等未来研究方向，旨在克服现有局限并推动STF技术的发展。

> **摘要翻译:** 遥感时空融合（STF）通过结合高时相-低空间和高空间-低时相的影像，解决了时相和空间分辨率之间的基本权衡问题。本文全面回顾了过去十年深度学习在遥感STF领域的进展。我们建立了包括卷积神经网络（CNN）、Transformer、生成对抗网络（GAN）、扩散模型和序列模型在内的深度学习架构的系统分类，揭示了深度学习在STF任务中的采用显著增长。我们的分析显示，基于CNN的方法在空间特征提取方面占主导地位，而Transformer架构在捕捉长期时间依赖性方面表现出优越性能。GAN和扩散模型在细节重建方面展现了卓越的能力，在结构相似性和光谱保真度方面大大优于传统方法。通过在七个基准数据集上对十种代表性方法进行全面实验比较，我们验证了这些发现，并量化了不同方法之间的性能权衡。我们确定了五个关键挑战：时空冲突、跨数据集的泛化能力有限、大规模处理的计算效率、多源异构融合以及基准多样性不足。本综述强调了基础模型、混合架构和自监督学习方法在解决当前局限性和实现多模态应用方面具有广阔前景。本文提到的具体模型、数据集和其他信息已收集在：https://github.com/yc-cui/Deep-Learning-Spatiotemporal-Fusion-Survey。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [568] [ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints](https://arxiv.org/abs/2507.08044)
> *基于约束的无训练低秩适配器权重初始化方法：ConsNoTrainLoRA*

*Debasmit Das, Hyoungwoo Park, Munawar Hayat, Seokeon Choi, Sungrack Yun, Fatih Porikli* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-09**

**Keywords:** 低秩适配器,权重初始化,参数高效微调,约束优化,域转移

**Comment:** ICCV 2025

> **TL;DR:** ConsNoTrainLoRA是一种新的数据驱动的低秩适配器（LoRA）权重初始化方法，它通过将LoRA初始化视为一个域转移问题，并利用预训练和微调激活之间的约束关系，来获得LoRA权重的闭式估计。这种方法不需要在初始化过程中进行训练，并且允许可变秩，已经在图像生成、分类和理解任务中证明了其优于标准和数据驱动初始化方法的性能。

**AI_Comments:** 这项工作提出了一种创新的LoRA初始化方法，通过利用数据驱动的约束来优化权重初始化过程，从而解决了传统随机初始化效率不高的问题。该方法在理论上具有新颖性（闭式估计、可变秩），在实践中也得到了下游任务性能的验证。然而，对于“多个约束”的具体形式以及它们如何影响最终的权重估计，还需要更详细的说明。此外，该方法在不同规模的模型和数据集上的普适性有待进一步考察。

<details>
  <summary>Details</summary>

**Motivation:** 传统的低秩适配器（LoRA）在微调基础模型时，其权重矩阵通常是随机初始化的，并且在所有连接点使用固定的秩。这种方法可能影响收敛速度和最终性能。因此，需要一种更优化的初始化方法来改进LoRA微调过程。

**Method:** 提出了一种名为ConsNoTrainLoRA（CNTLoRA）的数据驱动权重初始化方法。该方法将LoRA初始化表述为一个域转移问题，利用预训练和微调激活之间的多个约束关系。通过对这些约束进行重构，得到了一个依赖于预训练权重和微调激活向量的LoRA权重闭式估计，从而无需在初始化过程中进行训练。该权重估计被分解以初始化上、下矩阵，并引入了可变秩的灵活性。

**Result:** 在图像生成、图像分类和图像理解等下游任务的微调中，CNTLoRA的定量和定性结果均优于标准的和数据驱动的权重初始化方法。此外，广泛的分析和消融研究进一步阐明了该框架的设计选择，为实现更快的收敛和增强的性能提供了最佳方案。

**Conclusion:** ConsNoTrainLoRA通过一种新颖的数据驱动、基于约束的权重初始化方法，显著提高了LoRA微调的收敛速度和最终性能，并且该方法在初始化时无需训练，同时支持可变秩，在多个下游任务中均表现出优越性。

> **ai_Abstract:** 本研究提出了一种名为ConsNoTrainLoRA（CNTLoRA）的新型数据驱动权重初始化方法，用于改进低秩适配器（LoRA）在微调基础模型时的性能。与传统的随机初始化不同，CNTLoRA将LoRA初始化视为一个域转移问题，利用预训练和微调激活之间的约束关系，推导出无需训练的LoRA权重闭式估计，并支持可变秩。实验结果表明，CNTLoRA在图像生成、分类和理解任务上均优于现有方法，实现了更快的收敛和更好的性能。

> **摘要翻译:** 基础模型在大规模数据集上进行预训练，随后使用参数高效微调（PEFT）技术（如低秩适配器（LoRA））在小规模数据集上进行微调。在大多数先前的工作中，LoRA权重矩阵是随机初始化的，并且在所有连接点使用固定的秩。在本研究中，我们提出了一种数据驱动的权重初始化方法ConsNoTrainLoRA（CNTLoRA），以提高LoRA微调的收敛性和最终性能。我们将LoRA初始化表达为一个域转移问题，利用了预训练和微调激活之间的多个约束关系。通过重构这些约束，我们得到了一个依赖于预训练权重和微调激活向量的LoRA权重闭式估计，因此在初始化时无需训练。该权重估计被分解以初始化上、下矩阵，并具有可变秩的灵活性。使用我们提出的初始化方法，我们在图像生成、图像分类和图像理解等下游任务上进行了微调。定量和定性结果均表明，CNTLoRA优于标准和数据驱动的权重初始化方法。广泛的分析和消融研究进一步阐明了我们框架的设计选择，为实现更快的收敛和增强的性能提供了最佳方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [581] [Subject-Consistent and Pose-Diverse Text-to-Image Generation](https://arxiv.org/abs/2507.08396)
> *面向文本到图像生成的主题一致且姿态多样的生成*

*Zhanxin Gao, Beier Zhu, Liang Yao, Jian Yang, Ying Tai* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 文本到图像生成, 主题一致性, 姿态多样性, 扩散模型, 最优传输

**Comment:** 

> **TL;DR:** 为了在保持主题一致性的同时实现姿态和布局的多样性，提出了一种名为CoDi的两阶段文本到图像生成框架。第一阶段（身份传输）利用最优传输将身份特征以姿态感知的方式传输到目标图像，第二阶段（身份细化）则在后续去噪步骤中选择最显著的身份特征以进一步细化主题细节。实验结果表明，CoDi在主题一致性、姿态多样性和提示保真度方面均优于现有方法。

**AI_Comments:** 该研究提出了一种名为CoDi的新型文本到图像生成框架，有效地解决了在保持主题一致性的同时实现姿态和布局多样性的挑战。该方法通过创新的两阶段策略——身份传输和身份细化——利用最优传输和扩散模型的渐进特性，在视觉叙事方面取得了显著的进步。该研究在多个指标上的出色表现，以及开源代码的提供，都使其具有重要的学术和实践意义。然而，关于该方法在处理极端姿态变化或复杂场景下的鲁棒性以及计算效率方面，可能还需要进一步的探究。

<details>
  <summary>Details</summary>

**Motivation:** 现有免训练的文本到图像生成（T2I）模型在实现主题一致性（SCG）时，往往牺牲了布局和姿态的多样性，限制了视觉叙事能力。因此，需要一种能够同时实现主题一致性和姿态多样性的T2I框架。

**Method:** 提出了一种名为CoDi的两阶段T2I框架。第一阶段“身份传输”（IT）利用最优传输，在去噪早期以姿态感知的方式将身份特征传输到目标图像，以促进主题一致性并保持姿态多样性。第二阶段“身份细化”（IR）在去噪后期选择最显著的身份特征来进一步细化主题细节。

**Result:** CoDi在主题一致性、姿态多样性和提示保真度方面均取得了更好的视觉感知和更强的性能，超越了现有方法。

**Conclusion:** CoDi框架通过其两阶段策略（身份传输和身份细化）成功地实现了主题一致性与姿态多样性的统一，为文本到图像生成任务提供了更优的解决方案。

> **ai_Abstract:** 本文提出了一种名为CoDi的文本到图像生成框架，旨在解决现有方法在保持主题一致性的同时牺牲姿态和布局多样性的问题。CoDi采用两阶段策略：身份传输（IT）在去噪早期利用最优传输传递身份特征，以实现姿态感知的一致性；身份细化（IR）在去噪后期优化细节。实验证明，CoDi在主题一致性、姿态多样性和提示保真度方面均表现出色。

> **摘要翻译:** 主题一致性生成（SCG）——旨在跨不同场景保持一致的主题身份——仍然是文本到图像（T2I）模型面临的挑战。现有的免训练SCG方法通常以牺牲布局和姿态多样性为代价来实现一致性，这阻碍了富有表现力的视觉叙事。为了解决这一局限性，我们提出了主题一致且姿态多样的T2I框架，命名为CoDi，它能够实现具有多样化姿态和布局的一致性主题生成。CoDi的灵感来源于扩散的渐进性，即粗略结构先出现，细节后细化，因此采用了两阶段策略：身份传输（IT）和身份细化（IR）。IT在早期去噪步骤中进行，利用最优传输以姿态感知的方式将身份特征传输到每个目标图像。这促进了主题一致性，同时保持了姿态多样性。IR应用于后续去噪步骤，选择最显著的身份特征来进一步细化主题细节。在主题一致性、姿态多样性和提示保真度方面进行的大量定性和定量结果表明，CoDi在所有指标上均实现了更好的视觉感知和更强的性能。代码可在https://github.com/NJU-PCALab/CoDi获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [582] [Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective](https://arxiv.org/abs/2507.08801)
> *Lumos-1：从统一模型的视角看自回归视频生成*

*Hangjie Yuan, Weihua Chen, Jun Cen, Hu Yu, Jingyun Liang, Shuning Chang, Zhihui Lin, Tao Feng, Pengwei Liu, Jiazheng Xing, Hao Luo, Jiasheng Tang, Fan Wang, Yi Yang* | **Category: cs.CV, cs.AI, cs.MM** | **Updated: 2025-07-11**

**Keywords:** 自回归视频生成, 大型语言模型, 时空相关性, MM-RoPE, AR-DF

**Comment:** Code and Models: https://github.com/alibaba-damo-academy/Lumos

> **TL;DR:** Lumos-1是一个自回归视频生成模型，它在保持大型语言模型（LLM）架构的同时，通过引入3D RoPE和MM-RoPE来处理时空相关性，并使用一种新的依赖策略和AR-DF来解决训练中的问题，最终在多个基准测试中取得了与现有先进模型相当的性能。

**AI_Comments:** 该研究在自回归视频生成领域取得了显著进展，通过对LLM架构的巧妙改编和新颖的训练策略（如MM-RoPE和AR-DF）解决了关键挑战。模型在有限的计算资源下实现了与现有最先进模型相当的性能，这表明了其效率和潜力。然而，关于MM-RoPE在不同时空尺度上的泛化能力以及AR-DF在更广泛的应用场景中的鲁棒性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有自回归视频生成器要么偏离标准LLM架构，要么依赖笨重的外部文本编码器，要么因下一令牌解码而产生高延迟。作者希望开发一个能保持LLM架构并解决这些问题的模型。

**Method:** 作者提出了Lumos-1，一个保持LLM架构的自回归视频生成器。他们通过引入3D RoPE来注入时空相关性，并提出MM-RoPE来解决频率频谱不平衡问题。此外，Lumos-1采用了一种遵守帧内双向性和帧间时间因果关系的令牌依赖策略，并引入了AR-DF来解决帧间损失不平衡问题，该方法在训练时使用时间管状掩码，并在推理时使用兼容的掩码策略。

**Result:** Lumos-1在GenEval上取得了与EMU3相当的性能，在VBench-I2V上取得了与COSMOS-Video2World相当的性能，在VBench-T2V上取得了与OpenSoraPlan相当的性能。该模型在仅使用48个GPU的情况下进行了预训练。

**Conclusion:** Lumos-1通过最小的架构修改成功地将LLM架构应用于视频生成，并通过MM-RoPE和AR-DF等创新解决了现有方法的局限性，在多个基准测试中展现了与最先进模型相当的性能。

> **ai_Abstract:** Lumos-1是一个创新的自回归视频生成模型，它在保持LLM架构的同时，通过引入MM-RoPE来解决时空相关性问题，并通过AR-DF解决训练中的损失不平衡问题。该模型在仅使用48个GPU的情况下进行了高效训练，并在多个基准测试中取得了与现有先进模型相当的性能。

> **摘要翻译:** 自回归大型语言模型（LLM）统一了广泛的语言任务，激发了自回归视频生成的初步努力。现有的自回归视频生成器要么偏离标准LLM架构，要么依赖笨重的外部文本编码器，要么因下一令牌解码而产生高延迟。在本文中，我们介绍了Lumos-1，一个在LLM架构方面保持最小架构修改的自回归视频生成器。为了在LLM中注入时空相关性，我们发现了结合3D RoPE的有效性，并诊断了其不平衡的频率频谱范围。因此，我们提出了MM-RoPE，一种保留原始文本RoPE同时为模拟多模态时空数据提供全面频率频谱和缩放3D位置的RoPE方案。此外，Lumos-1采用了一种遵守帧内双向性和帧间时间因果关系的令牌依赖策略。基于这种依赖策略，我们发现了由空间信息冗余引起的帧间损失不平衡问题，并通过提出自回归离散扩散强制（AR-DF）来解决它。AR-DF在训练时引入了时间管状掩码，并采用了兼容的推理时掩码策略，以避免质量下降。通过使用内存高效的训练技术，我们在仅48个GPU上预训练了Lumos-1，在GenEval上取得了与EMU3相当的性能，在VBench-I2V上取得了与COSMOS-Video2World相当的性能，在VBench-T2V上取得了与OpenSoraPlan相当的性能。代码和模型可在https://github.com/alibaba-damo-academy/Lumos获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [588] [A Hybrid Multilayer Extreme Learning Machine for Image Classification with an Application to Quadcopters](https://arxiv.org/abs/2507.08047)
> *混合多层极限学习机及其在四旋翼飞行器图像分类中的应用*

*Rolando A. Hernandez-Hernandez, Adrian Rubio-Solis* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 混合多层极限学习机, 图像分类, 无人机, 模糊逻辑, 特征提取

**Comment:** 22 pages, 10 figures, 3 tables

> **TL;DR:** 提出了一种混合多层极限学习机（HML-ELM），结合了ELM自编码器和模糊逻辑，用于无人机图像分类，效果优于现有方法。

**AI_Comments:** 该研究提出了一种结合深度学习（堆叠ELM-AEs）与模糊逻辑的创新混合方法，用于提升图像分类性能，并成功应用于无人机领域，显示了其实际应用价值。文中提到的基于COSTRWSR改进的SC算法是其技术贡献点。然而，摘要中未详细说明其具体局限性或计算复杂度。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高图像分类的效率，特别是针对无人机应用，提出了一种新的混合多层极限学习机（HML-ELM）方法。

**Method:** 该方法提出了一种混合多层极限学习机（HML-ELM），该方法基于ELM自编码器（ELM-AE）和区间II型模糊逻辑理论。它是一个分层的ELM学习框架，包含两个阶段：1）自教特征提取，通过堆叠ELM-AEs实现无监督多层特征编码；2）监督特征分类，使用简化的区间II型模糊ELM（SIT2-FELM）和基于SC算法（COSTRWSR的改进版本）的快速输出约减层。

**Result:** 实验结果表明，HML-ELM在图像分类基准问题和无人机实际应用中，相比ML-ELM、ML-FELM和ELM等其他类似方法，具有更优越的效率。

**Conclusion:** 所提出的HML-ELM方法在图像分类任务中表现出优越的效率，特别是在无人机应用场景下，优于现有的ML-ELM、ML-FELM和ELM等技术。

> **ai_Abstract:** 本文提出了一种混合多层极限学习机（HML-ELM），结合了基于ELM自编码器的无监督特征提取和基于模糊逻辑的监督分类。该方法通过堆叠ELM-AEs进行特征编码，并使用简化的区间II型模糊ELM进行分类，在基准测试和无人机实际应用中均显示出优于现有技术的性能。

> **摘要翻译:** 多层极限学习机（ML-ELM）及其变体已被证明是分类不同自然信号（如音频、视频、声学和图像）的有效技术。在本文中，提出了一种混合多层极限学习机（HML-ELM），该方法基于ELM自编码器（ELM-AE）和区间II型模糊逻辑理论，用于主动图像分类，并应用于无人机（UAV）。所提出的方法是一个分层的ELM学习框架，包含两个主要阶段：1）自教特征提取和2）监督特征分类。首先，通过堆叠一系列ELM-AEs来实现无监督多层特征编码，其中输入数据被投影到一系列高层表示。在第二阶段，使用一种新颖的简化区间II型模糊ELM（SIT2-FELM）和基于SC算法（一种改进的无排序要求集中心算法COSTRWSR）的快速输出约减层对最终特征进行分类。为了验证HML-ELM的效率，提出了两种图像分类实验。首先，将HML-ELM应用于解决图像分类的一系列基准问题。其次，实现了使用无人机在两个预定位置之间主动分类和运输四种不同物体的若干实际实验。实验表明，与ML-ELM、多层模糊极限学习机（ML-FELM）和ELM等其他类似方法相比，所提出的HML-ELM具有更优越的效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [590] [CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering](https://arxiv.org/abs/2507.08776)
> *CLiFT：用于计算高效且自适应神经渲染的压缩光场令牌*

*Zhengqing Wang, Yuefan Wu, Jiacheng Chen, Fuyang Zhang, Yasutaka Furukawa* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 神经渲染,光场令牌,压缩表示,计算自适应,自适应渲染

**Comment:** Project page: https://c-lift.github.io

> **TL;DR:** 该研究提出了一种名为CLiFT的新型神经渲染方法，它使用压缩的光场令牌来表示场景，实现了高效渲染并能自适应地调整渲染质量。

**AI_Comments:** 该方法在数据压缩和渲染效率方面具有潜力，但其在处理复杂场景和动态场景方面的表现有待进一步验证。同时，对“计算预算”的具体定义和影响的深入分析将有助于更好地理解该方法的优势。

<details>
  <summary>Details</summary>

**Motivation:** 需要一种能够高效渲染场景并能根据计算预算自适应调整渲染质量的神经渲染方法。

**Method:** 通过多视图编码器将图像编码为令牌，然后使用潜在空间K-means聚类选择射线作为质心，接着使用“冷凝器”将信息压缩到质心令牌中形成CLiFTs。在测试时，根据目标视图和计算预算选择附近的令牌，并使用自适应渲染器合成新视图。

**Result:** CLiFT在RealEstate10K和DL3DV数据集上取得了显著的数据压缩效果，渲染质量与现有方法相当，并且在渲染得分上表现最佳，同时能在数据大小、渲染质量和渲染速度之间取得平衡。

**Conclusion:** CLiFT通过压缩光场令牌实现了高效且自适应的神经渲染，并在数据压缩、渲染质量和速度方面提供了良好的权衡。

> **ai_Abstract:** CLiFT是一种新颖的神经渲染技术，它使用压缩的光场令牌（CLiFTs）来高效地表示和渲染场景。该方法通过多视图编码、聚类和信息压缩，将场景数据压缩成令牌，然后在测试时根据指定的计算预算自适应地选择和渲染这些令牌，以合成新视图。实验证明，CLiFT在数据压缩、渲染质量和速度方面取得了良好的平衡。

> **摘要翻译:** 本文提出了一种神经渲染方法，该方法将场景表示为“压缩光场令牌（CLiFTs）”，保留了场景丰富的外观和几何信息。CLiFT通过压缩令牌实现了计算高效渲染，同时能够改变令牌的数量来表示场景或使用一个训练好的网络渲染新视图。具体来说，给定一组图像，多视图编码器使用相机姿态对图像进行令牌化。潜在空间K-means使用令牌选择一组简化的射线作为聚类质心。多视图“冷凝器”将所有令牌的信息压缩到质心令牌中，以构建CLiFTs。在测试时，给定目标视图和计算预算（即CLiFT的数量），系统收集指定数量的附近令牌，并使用计算自适应渲染器合成新视图。在RealEstate10K和DL3DV数据集上的广泛实验在数量和质量上验证了我们的方法，实现了显著的数据缩减，同时保持了可比的渲染质量，并取得了最高的整体渲染得分，同时提供了数据大小、渲染质量和渲染速度的权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [591] [EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting](https://arxiv.org/abs/2504.10012)
> *EBAD-Gaussian：事件驱动的束调整去模糊高斯泼溅*

*Yufei Deng, Yuanjian Wang, Rong Xiao, Chenwei Tang, Jizhe Zhou, Jiahao Fan, Deng Xiong, Jiancheng Lv, Huajin Tang* | **Category: cs.CV** | **Updated: 2025-07-11**

**Keywords:** 3D高斯泼溅, 事件相机, 运动模糊, 去模糊, 3D重建

**Comment:** 

> **TL;DR:** EBAD-Gaussian是一种利用事件相机和模糊图像重建清晰3D场景的新方法，它通过联合优化高斯参数和相机运动轨迹来解决运动模糊问题，并在合成和真实数据集上取得了高质量的重建效果。

**AI_Comments:** 该研究提出了一种新颖的结合事件相机和3D高斯泼溅的方法，解决了运动模糊场景下的重建难题，具有重要的理论和应用价值。方法创新性地利用事件流的连续亮度信息来辅助去模糊和相机运动恢复，并引入EDI先验增强细节，为解决动态模糊场景下的3D重建提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅方法在运动模糊场景下性能下降，基于RGB的去模糊方法难以精确建模曝光期间的相机位姿和辐射度变化，导致重建精度降低。事件相机能捕捉曝光期间的连续亮度变化，有助于建模运动模糊和提高重建质量。

**Method:** 提出EBAD-Gaussian方法，从事件流和严重模糊的图像中重建清晰的3D高斯。该方法联合学习高斯参数并恢复曝光期间的相机运动轨迹。具体来说，通过合成曝光期间的多个潜在清晰图像来构建模糊损失函数，最小化真实和合成模糊图像间的差异。利用事件流监督曝光期间的亮度变化，补充RGB图像中丢失的光强度动态变化。此外，基于事件驱动双积分（EDI）先验优化中间曝光时间的潜在清晰图像，并通过一致性约束增强重建图像的细节和纹理信息。

**Result:** EBAD-Gaussian在合成和真实世界数据集上的大量实验表明，在模糊图像和事件流输入条件下，可以实现高质量的3D场景重建。

**Conclusion:** EBAD-Gaussian方法成功地利用事件相机数据来解决3D高斯泼溅中的运动模糊问题，实现了在模糊输入下的高质量3D场景重建。

> **ai_Abstract:** EBAD-Gaussian是一种创新的3D场景重建方法，它利用事件相机数据来解决3D高斯泼溅在运动模糊问题上的不足。该方法通过联合优化相机运动轨迹和3D高斯参数，并利用事件流补充光强度信息和EDI先验增强细节，实现了在模糊图像输入下的高质量重建。

> **摘要翻译:** 尽管3D高斯泼溅（3D-GS）实现了照片级的 신규 뷰 합성，但其性能会随着运动模糊而下降。在快速运动或弱光条件下，现有的基于RGB的去模糊方法难以在曝光期间对相机位姿和辐射度变化进行建模，导致重建精度降低。事件相机能够捕捉曝光期间的连续亮度变化，有效辅助运动模糊建模并提高重建质量。因此，我们提出事件驱动的束调整去模糊高斯泼溅（EBAD-Gaussian），从事件流和严重模糊的图像中重建清晰的3D高斯。该方法在学习这些高斯参数的同时，恢复曝光期间的相机运动轨迹。具体而言，我们首先通过在曝光期间合成多个潜在的清晰图像来构建一个模糊损失函数，最小化真实和合成模糊图像之间的差异。然后，我们利用事件流来监督曝光期间内任意时间点的亮度变化，补充了RGB图像中丢失的光强度动态变化。此外，我们基于事件驱动双积分（EDI）先验来优化中间曝光时间的潜在清晰图像，并应用一致性约束来增强重建图像的细节和纹理信息。在合成和真实世界数据集上的大量实验表明，EBAD-Gaussian可以在模糊图像和事件流输入的条件下实现高质量的3D场景重建。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [597] [PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models](https://arxiv.org/abs/2507.08400)
> *全景匹配：释放大型视觉模型在统一匹配模型中的潜力*

*Yongjian Zhang, Longguang Wang, Kunhong Li, Ye Zhang, Yun Wang, Liang Lin, Yulan Guo* | **Category: cs.CV, cs.AI, cs.MM** | **Updated: 2025-07-11**

**Keywords:** 对应匹配, 大型视觉模型, 零样本学习, 统一模型, 位移估计

**Comment:** 

> **TL;DR:** PanMatch 是一个通用的基础模型，用于鲁棒的对应匹配，通过将任何双帧对应匹配任务统一到二维位移估计框架中，利用大型视觉模型的特征提取能力，实现了跨任务和跨域的零样本匹配能力，并在各种下游任务和异常场景中表现出色。

**AI_Comments:** 该研究提出了一种非常有前景的方法，将大型视觉模型的能力应用于统一的对应匹配任务。其核心创新在于将所有匹配任务统一到二维位移估计框架，并利用 LVMs 的通用特征提取能力，实现了强大的零样本跨任务和跨域匹配。这大大简化了模型设计，并提高了泛化能力。尤其值得注意的是其在异常场景下的零样本性能，这对于实际应用具有重要意义。然而，未来研究可以进一步探索 LVMs 特征的更深层次融合机制，以及在更广泛的、更具挑战性的真实世界场景中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 之前的对应匹配方法需要针对特定任务设计架构或进行领域特定的微调。本研究旨在提出一种通用的基础模型，能够处理多种匹配任务，无需专门的统一架构或任务特定的集成模型。

**Method:** 将任何双帧对应匹配任务统一到二维位移估计框架中，利用大型视觉模型的通用特征，通过特征转换管道赋予匹配基线零样本跨视图匹配能力。使用包含近180万个样本的跨领域数据集预训练模型。

**Result:** PanMatch 在跨任务评估中优于 UniMatch 和 Flow-Anything，在任务导向的基准测试中达到了与大多数特定任务算法相当的性能。在异常场景（如下雨天和卫星图像）中表现出前所未有的零样本性能。

**Conclusion:** PanMatch 通过将不同匹配任务统一到二维位移估计框架，并利用大型视觉模型的强大特征提取能力，成功实现了跨任务和跨域的零样本匹配，并在各种场景下展现出优越的性能和泛化能力。

> **ai_Abstract:** PanMatch 是一种新颖的通用基础模型，用于解决各种对应匹配任务（如立体匹配、光流和特征匹配）。它通过将所有任务统一为二维位移估计问题，并利用大型视觉模型（LVMs）的强大特征提取能力，实现了跨任务和跨域的零样本匹配。该模型在包含近180万个样本的跨领域数据集上进行预训练，并在各种下游任务和具有挑战性的异常场景（如恶劣天气和卫星图像）中展现出优越的性能和泛化能力，超越了现有方法。

> **摘要翻译:** 这项工作提出了 PanMatch，一个用于鲁棒对应匹配的通用基础模型。与以往依赖于特定任务架构和领域特定微调来支持立体匹配、光流或特征匹配等任务的方法不同，我们的关键见解是，任何双帧对应匹配任务都可以使用相同的模型权重在二维位移估计框架内解决。这种表述消除了设计专门的统一架构或特定任务集成模型的需要。相反，它通过赋予位移估计算法前所未有的泛化能力来实现多任务集成。为此，我们强调了适用于多个领域和任务的鲁棒特征提取器的重要性，并提出了利用大型视觉模型中的通用特征的特征转换管道，赋予匹配基线零样本跨视图匹配能力。此外，我们收集了一个跨领域数据集，其中包含来自立体匹配、光流和特征匹配领域的近180万个样本，用于预训练 PanMatch。我们通过使用相同的模型权重展示了 PanMatch 在广泛的领域和下游任务中的多功能性。我们的模型在跨任务评估中优于 UniMatch 和 Flow-Anything，并在任务导向的基准测试中取得了与大多数特定任务算法相当的性能。此外，PanMatch 在异常场景（如下雨天和卫星图像）中表现出前所未有的零样本性能，而大多数现有的鲁棒算法在这种情况下都无法产生有意义的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [6] [Do Conversational Interfaces Limit Creativity? Exploring Visual Graph Systems for Creative Writing](https://arxiv.org/abs/2507.08260)
> *对话式界面会限制创造力吗？探索用于创意写作的可视化图系统*

*Abhinav Sood, Maria Teresa Llano, Jon McCormack* | **Category: cs.HC** | **Updated: 2025-07-11**

**Keywords:** 创意写作, 可视化图系统, 对话式界面, 生成式AI, 链式LLM

**Comment:** Published in the 16th International Conference on Computational
  Creativity, ICCC25. Accepted Paper in
  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025conversational.pdf

> **TL;DR:** 该研究提出了一种图形化、基于节点的可视化图系统，用于创意写作，旨在克服传统对话式AI界面的线性限制，并通过用户研究发现其有助于构思和可视化写作过程。

**AI_Comments:** 该论文的创新点在于提出了一个非线性的、基于节点的可视化图系统来辅助创意写作，这与当前主流的对话式AI界面形成对比。它尝试通过提升用户界面的复杂度和可视化能力来克服AI工具对创造力的潜在限制。其重要性在于为未来生成式AI在创意领域的应用提供了新的交互范式。局限性在于用户研究规模较小，且承认了系统对用户操作复杂度的要求，可能不适用于所有用户。

<details>
  <summary>Details</summary>

**Motivation:** 当前链式大型语言模型（LLMs）的研究发现，尽管链式结构提供了透明度、可控性和保障，但预定义的LLM步骤会阻碍自由探索。特别是，基于聊天的AI交互固有的线性结构限制了创造性探索和构思。

**Method:** 我们基于创造力研究中的认知过程，创建了一个图形化、基于节点的可视化图系统。该系统允许用户视觉化地链接生成式AI模型以完成创意任务，旨在克服基于聊天的AI交互的线性结构限制。此外，我们的基于节点的方法能够创建可重用、可共享的模板，以应对不同的创意任务。

**Result:** 在一个小规模用户研究中，我们发现与类似的对话式界面相比，我们的图基系统支持构思，并允许一些用户更好地可视化和思考他们的写作过程。研究还讨论了系统的缺点和局限性，并指出对于能够有效使用复杂用户界面的用户来说，这些界面可以为创造力带来益处。

**Conclusion:** 基于节点的可视化图系统能够克服传统对话式AI界面的线性限制，支持构思并帮助用户更好地可视化和思考创意写作过程，表明更高复杂度的用户界面可能为特定用户带来创造力上的优势。

> **ai_Abstract:** 本文提出了一种图形化、基于节点的可视化图系统，旨在解决传统对话式AI界面在创意写作中线性结构对创造力探索的限制。该系统允许用户视觉化地链式连接生成式AI模型，并能创建可重用模板。通过小规模用户研究表明，与对话式界面相比，该图基系统更能支持构思，并帮助部分用户更好地可视化和思考写作过程，从而提升创造力。

> **摘要翻译:** 我们提出一个图形化的、基于节点的可视化图系统，用户可以通过它视觉化地链式连接生成式AI模型以完成创意任务。链式连接大型语言模型（LLMs）领域的研究发现，虽然链式连接提供了透明度、可控性和保障以处理某些任务，但带有预定义LLM步骤的链式连接会阻止自由探索。我们以创造力研究中的认知过程为基础，创建了一个系统来解决基于聊天的AI交互固有的限制。具体来说，我们的系统旨在克服抑制创造性探索和构思的限制性线性结构。此外，我们基于节点的方法能够创建可重用、可共享的模板，以应对不同的创意任务。在一个小规模的用户研究中，我们发现与类似的对话式界面相比，我们的图基系统支持构思，并允许一些用户更好地可视化和思考他们的写作过程。我们进一步讨论了我们系统的缺点和局限性，并指出对于能够有效使用复杂用户界面的用户来说，这些界面可以为创造力带来益处。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [24] [Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance](https://arxiv.org/abs/2507.08624)
> *康复辅助中环境智能的自适应框架*

*Gábor Baranyi, Zsolt Csibi, Kristian Fenech, Áron Fóthi, Zsófia Gaál, Joul Skaf, András Lőrincz* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 环境智能, 康复辅助, 3D重建, 视觉-语言模型, 家庭康复

**Comment:** The paper has been submitted to a journal and waiting for review

> **TL;DR:** AIRS是一个基于AI的家庭康复框架，利用3D重建、智能导航和VLMs提供运动指导和反馈，特别关注全膝关节置换术后康复，并解决隐私问题。

**AI_Comments:** 该论文提出的AIRS框架在家庭康复领域具有创新性，特别是在整合实时3D重建、智能导航和视觉-语言模型以提供机器引导反馈方面。它通过使用虚拟形象来解决隐私问题并遵守AI法案，这是其重要亮点。该框架的模块化设计和对特殊人群的支持也增加了其潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在为家庭康复环境引入一个先进的、基于人工智能的解决方案，以提供机器引导的物理康复支持。

**Method:** 该论文提出了环境智能康复支持（AIRS）框架，该框架整合了实时3D重建（RT-3DR）、智能导航和大型视觉-语言模型（VLMs）。它使用智能手机进行RT-3DR，并通过身体匹配的虚拟形象提供视觉反馈，以优化运动配置并解决隐私问题。AIRS采用两种反馈机制：视觉3D反馈（对比预录临床运动和患者录音）和VLM生成的详细解释和纠正反馈。该框架还支持视听障碍人士，并具有模块化设计。

**Result:** AIRS框架在全膝关节置换术后康复场景中进行了演示，并利用263个视频录音数据库进行了评估。系统能够引导用户进行录制，确保收集到正确录制的视频，并提供两种反馈机制。

**Conclusion:** AIRS框架是一个全面的、基于人工智能的家庭康复解决方案，它通过整合先进技术、提供多模式反馈并解决隐私问题，有效地支持机器引导的物理康复，并具有广泛的适应性。

> **ai_Abstract:** 本文提出了环境智能康复支持（AIRS）框架，这是一个专为家庭康复设计的人工智能解决方案。AIRS整合了实时3D重建、智能导航和视觉-语言模型，旨在提供机器引导的物理康复。该框架利用智能手机进行3D重建，并使用身体匹配的虚拟形象提供视觉反馈，同时解决隐私问题。它在全膝关节置换术后康复中进行了验证，通过两种机制提供反馈：视觉3D对比和VLM生成的详细纠正。AIRS具有模块化设计，可适应不同康复场景，并支持视听障碍人士。

> **摘要翻译:** 本文介绍了一种环境智能康复支持（AIRS）框架，这是一种专为家庭康复环境量身定制的先进人工智能解决方案。AIRS整合了实时3D重建（RT-3DR）、智能导航和大型视觉-语言模型（VLMs）等尖端技术，以创建一个用于机器引导物理康复的综合系统。通用的AIRS框架在全膝关节置换术（TKR）后的康复场景中进行了演示，并利用263个视频录音数据库进行评估。AIRS中采用智能手机进行居住空间的RT-3DR，并具有一个与身体匹配的虚拟形象，以提供关于运动的视觉反馈。这个虚拟形象对于(a)优化运动配置，包括摄像头放置、患者定位和初始姿势，以及(b)解决隐私问题和促进遵守AI法案是必要的。系统引导用户完成录制过程，以确保收集到正确录制的视频。AIRS采用了两种反馈机制：(i)视觉3D反馈，能够直接比较预录的临床运动和患者家庭录音；(ii)VLM生成的反馈，提供运动错误的详细解释和纠正。该框架还支持视力障碍和听力障碍人士。它还具有模块化设计，可以适应更广泛的康复环境。AIRS软件组件可供进一步使用和定制。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [57] [Push or Light: Nudging Standing to Break Prolonged Sitting](https://arxiv.org/abs/2507.08659)
> *推送还是灯光：轻推站立以打破长时间久坐*

*Sohshi Yoshida, Ko Watanabe, Andreas Dengel, Shoya Ishimaru, Shingo Ata, Manato Fujimoto* | **Category: cs.HC** | **Updated: 2025-07-11**

**Keywords:** 轻推策略, 久坐, 健康行为改变, 推送通知, 灯光控制

**Comment:** 

> **TL;DR:** 本研究比较了推送通知和灯光变暗两种轻推策略在鼓励人们站立以打破长时间久坐方面的效果，发现灯光变暗略微更有效，但导致更多不适，且效果受任务情境影响，提示未来的系统应自适应调整干预措施。

**AI_Comments:** 这项研究通过实证比较了两种不同类型的“轻推”策略（显式与环境）在行为改变中的效果，并首次引入了用户舒适度和任务情境的考量，这是其创新之处。其重要性在于为未来开发更智能、更个性化的健康行为干预系统提供了实证依据和设计方向。虽然样本量较小（15名大学生），可能限制了结果的普适性，但其发现对理解人机交互在健康领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 长时间久坐是导致代谢和心血管疾病的健康风险。为了对抗这一问题，需要评估不同的“轻推”策略，尤其是比较显式提示（如智能手机推送通知）和环境控制（如灯光变暗）的效果、不适感和用户情境影响，因为这方面的比较尚未进行。

**Method:** 本研究采用混合设计实验，招募了15名大学生。测试了三种干预方法（无干预、推送通知、灯光变暗）和三种用户任务情境（电脑工作、视频通话、阅读）。每次十分钟会话后，评估了站立频率和舒适度。

**Result:** 结果显示，灯光变暗导致更多的休息（1.4 ± 1.55次）比推送通知（1.2 ± 1.08次），但造成66.7%的参与者感到不适，而推送通知只有20%。结果受任务情境影响：灯光变暗在视频通话和阅读时最有效，而推送通知在电脑工作时更有效。

**Conclusion:** 这些发现表明，自适应的轻推系统应根据情境和个人偏好来调整干预措施。

> **ai_Abstract:** 本研究旨在比较不同“轻推”策略（推送通知与灯光变暗）在鼓励大学生打破长时间久坐方面的效果、舒适度及情境影响。实验发现，灯光变暗虽能带来更多站立，但导致更普遍的不适感。两种方法的效果均受任务情境影响，提示未来的自适应轻推系统应根据具体情境和用户偏好定制干预方式。

> **摘要翻译:** 长时间久坐是一种健康风险，会导致代谢和心血管疾病。为了对抗这一问题，各种“轻推”策略被用于鼓励人们站立。行为改变触发器使用显式提示，例如智能手机推送通知或灯光控制。然而，尚未对这些互动、不适和用户情境的影响进行比较。本研究通过一项包含15名大学生的混合设计实验评估了这些方法。测试了三种干预方法（无干预、推送通知和灯光变暗）和三种用户任务情境（电脑工作、视频通话和阅读）。在每次十分钟的会话后，评估了站立频率和舒适度。结果显示，灯光变暗导致的休息次数（1.4 ± 1.55）略多于推送通知（1.2 ± 1.08），但导致66.7%的参与者感到不适，而推送通知为20%。结果受任务情境影响。灯光变暗在视频通话和阅读时最有效，而推送通知在电脑工作时更有效。这些发现表明，自适应的轻推系统应根据情境和个人偏好来调整干预措施。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [85] [LIMITER: A Gamified Interface for Harnessing Just Intonation Systems](https://arxiv.org/abs/2507.08675)
> *LIMITER：一个用于利用纯律系统的游戏化界面*

*Antonis Christou* | **Category: cs.HC** | **Updated: 2025-07-11**

**Keywords:** 游戏化界面, 微音音乐, 纯律, 数字乐器, 创造力增强

**Comment:** 6 pages, 11 figures, NIME, 2025

> **TL;DR:** LIMITER是一个游戏化的数字乐器，旨在通过新颖、易于上手的方式，帮助用户理解和演奏微音和纯律音乐，克服其在西方音乐中难以概念化和演奏的挑战。

**AI_Comments:** LIMITER的创新之处在于将复杂的微音和纯律系统通过游戏化界面进行简化，降低了学习门槛，使其更易于被大众接受和使用。这种将音乐理论与互动娱乐相结合的方法，对于推动小众音乐形式的普及具有重要意义。该研究的初步评估结果也指出了其在增强创造力方面的潜力，值得进一步深入研究。

<details>
  <summary>Details</summary>

**Motivation:** 西方音乐中的微音音乐仍然是一个小众且深奥的系统，难以概念化和演奏。本文的动机是提供一个新颖、易于上手的界面，使这些声音作为表达方式更容易被利用。

**Method:** 本文介绍了LIMITER，一个游戏化的数字乐器，它利用颜色、几何变换和类似游戏的控制来创建一个更简单的入口，以利用微音和纯律声音。文中还报告了LIMITER的开发背景，并解释了其功能背后的音乐和工程系统。

**Result:** LIMITER提供了一个新颖、易于上手的界面，利用颜色、几何变换和类似游戏的控制，为利用微音和纯律声音提供了一个更简单的入口。初步评估表明该界面具有增强创造力的效果。

**Conclusion:** LIMITER作为一个游戏化的数字乐器，通过其创新的界面设计，成功简化了微音和纯律音乐的理解和演奏，并展现出增强用户创造力的潜力。

> **ai_Abstract:** 本文推出LIMITER，一款游戏化的数字乐器，旨在简化微音和纯律音乐的创作与演奏。针对微音音乐在西方世界难以理解和实践的现状，LIMITER通过创新的游戏化界面，结合颜色、几何变换及游戏式操控，为用户提供了一个直观易用的入口。文章详细阐述了LIMITER的开发历程、底层技术，并初步评估了其在激发用户创造力方面的积极作用。

> **摘要翻译:** 本文介绍了LIMITER，一个游戏化的数字乐器，用于利用和演奏微音和纯律声音。尽管微音在西方音乐中仍然是一个小众且深奥的系统，难以概念化和演奏，但LIMITER提供了一个新颖、易于上手的界面，它利用颜色、几何变换和类似游戏的控制，为利用这些声音作为表达方式创造了一个更简单的入口。我们报告了LIMITER的开发背景，并解释了实现其功能的底层音乐和工程系统。此外，我们还讨论并初步评估了该界面对创造力的增强效果。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [113] [EqualMotion: Accessible Motion Capture for the Creative Industries](https://arxiv.org/abs/2507.08744)
> *EqualMotion：创意产业的可访问运动捕捉*

*Clarice Hilton, Kat Hawkins, Phill Tew, Freddie Collins, Seb Madgwick, Dominic Potts, Tom Mitchell* | **Category: cs.HC** | **Updated: 2025-07-11**

**Keywords:** 运动捕捉, 可访问性, 残障人士, 协同设计, 创意产业

**Comment:** 

> **TL;DR:** EqualMotion是一个以残障人士为中心共同设计的身体无关、可穿戴式运动捕捉系统，旨在解决现有技术对残障从业者的排斥问题，促进数字表演和原型设计中的公平参与。

**AI_Comments:** EqualMotion的创新之处在于其以残障人士为中心的共同设计方法，这使其能够开发出真正包容和身体无关的运动捕捉技术。这对于促进创意产业中残障人士的公平参与至关重要，解决了现有技术中普遍存在的排斥性问题。该研究的重要性在于其对可访问性的强调和在实际应用中的评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有的运动捕捉技术在身体建模、校准和虚拟形象表示方面存在规范性假设，导致残障从业者被排除在外。EqualMotion旨在解决这一问题，促进残障人士在数字表演和原型设计中的公平参与。

**Method:** EqualMotion通过以下方法实现：采用以残障人士为中心的共同设计方法，开发了一个身体无关、可穿戴的运动捕捉系统。该系统支持个性化校准，整合了助行器，并采用了包容性的视觉语言，以支持不同的身体类型和运动风格。系统与残障研究人员和创意人员合作开发。

**Result:** 开发了一个名为EqualMotion的身体无关、可穿戴式运动捕捉系统。该系统能够实现个性化校准，整合助行器，并采用包容性视觉语言，支持不同的身体类型和运动风格。正在进行舞蹈和音乐领域的案例研究，以评估系统在真实创意工作流程中的可访问性。

**Conclusion:** EqualMotion旨在通过提供一个身体无关、可穿戴的运动捕捉系统，促进残障人士在数字表演和原型设计中的公平参与。正在通过案例研究评估其在实际创意工作流程中的可访问性。

> **ai_Abstract:** 本文介绍了EqualMotion，一个为创意产业设计的可访问运动捕捉系统。该系统采用以残障人士为中心的共同设计方法，开发出身体无关、可穿戴的解决方案，旨在解决传统运动捕捉技术对残障从业者的排斥问题。EqualMotion通过个性化校准、整合助行器和包容性视觉语言，支持多样化的身体类型和运动风格。该研究旨在促进数字表演和原型设计中的公平参与，并通过舞蹈和音乐领域的案例研究评估其在实际创意工作流程中的可访问性。

> **摘要翻译:** 运动捕捉技术在创意和表演语境中越来越多地被使用，但由于身体建模、校准和虚拟形象表示中的规范性假设，往往将残障从业者排除在外。EqualMotion引入了一个身体无关、可穿戴的运动捕捉系统，该系统通过以残障为中心的协同设计方法进行设计。通过实现个性化校准、整合助行器和采用包容性视觉语言，EqualMotion支持多样化的身体类型和运动风格。该系统与残障研究人员和创意人员合作开发，旨在促进数字表演和原型设计中的公平参与。本文概述了系统的设计原则，并重点介绍了舞蹈和音乐领域正在进行的案例研究，以评估真实创意工作流程中的可访问性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [207] [Human-AI Collaboration for Wearable Technology Component Standardization](https://arxiv.org/abs/2503.15488)
> *人机协作促进可穿戴技术组件标准化*

*Andrew M. Lydner* | **Category: cs.HC** | **Updated: 2025-07-10**

**Keywords:** 人机协作, 可穿戴技术, 标准化, 人工智能, 心智模型

**Comment:** 

> **TL;DR:** 可穿戴技术因缺乏标准化而创新受限，本文旨在探索如何通过人机协作和AI工具心智模型开发来解决此问题，推动标准化。

**AI_Comments:** 该论文强调了人机协作在解决可穿戴技术标准化挑战中的重要性。其创新点在于提出通过心智模型开发来提高AI工具在行业专家中的采纳和利用，以促进标准化和创新，为可穿穿戴技术的发展提供了一个新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 可穿戴技术行业因其多学科性质和缺乏标准化，面临创新限制和发展停滞，急需建立协作基础。

**Method:** 本文研究重点是将AI工具的心智模型开发应用于可穿戴技术创新，以促进专家与AI的协作，解决AI工具在行业专家中利用率不高的问题。

**Result:** Not mentioned in abstract

**Conclusion:** 通过应用AI工具的心智模型开发，可以有效促进人机协作，从而解决可穿戴技术组件的标准化问题，推动行业创新。

> **ai_Abstract:** 本文旨在解决可穿戴技术行业因缺乏标准化和跨学科知识传播而面临的创新瓶颈。作者提出，通过促进专家与人工智能的协作，特别是应用AI工具的心智模型开发，可以提高AI工具的利用率，从而推动可穿戴技术组件的标准化，促进行业创新。

> **摘要翻译:** 由于可穿戴技术的多学科性质，该行业在创新方面面临潜在限制。可穿戴技术行业仍处于起步阶段，尽管有大量主要用于腕部的技术，但其适用范围的增加却停滞不前。这可能是由于缺乏多学科专家知识在行业中的传播。与其他拥有标准化和开发流程的技术不同，可穿戴技术存在于一个不断变化的领域中，因为各种材料和子组件不断被开发出来。专家意见形成协作基础至关重要，而智能系统促进这种协作则更为重要。然而，需要注意的是，这些人工智能（AI）协作工具被行业专家利用的可能性。在这种情况下，AI工具使用的心智模型开发可以应用于可穿戴技术创新，因此成为本文的目标和研究重点。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [244] [An Exploration of Default Images in Text-to-Image Generation](https://arxiv.org/abs/2505.09166)
> *文本到图像生成中默认图像的探索*

*Hannu Simonen, Atte Kiviniemi, Jonas Oppenlaender* | **Category: cs.HC, cs.AI, H.5.m; I.2.m** | **Updated: 2025-07-11**

**Keywords:** 文本到图像生成, 默认图像, Midjourney, 提示工程, 用户满意度

**Comment:** 16 pages, 6 figures

> **TL;DR:** 本文首次研究了文本到图像生成（TTI）模型中在未知提示下产生的“默认图像”，并探讨了其对用户满意度的影响，为TTI和提示工程的改进奠定基础。

**AI_Comments:** 这项研究具有创新性，因为它首次专注于文本到图像生成中一个此前未被充分研究的现象——“默认图像”。通过识别并系统地调查这些图像的产生机制及其对用户体验的影响，该工作为优化TTI模型行为和改进提示工程提供了新的视角。其重要性在于揭示了模型在处理未知输入时的潜在“盲点”或固有偏见，这对于开发更鲁棒、用户体验更好的生成式AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当文本到图像生成（TTI）模型遇到未知词汇的提示时，它们仍会生成图像，这些图像被称为“默认图像”，它们在许多不相关的提示中彼此高度相似。研究这些默认图像对于设计更好的TTI解决方案和提示工程具有重要价值。

**Method:** 本文对流行的图像生成器Midjourney上的默认图像进行了首次调查。研究人员描述了一种系统方法来创建触发默认图像的输入提示，并进行了初步实验和小型消融研究。此外，还进行了一项调查研究，以了解默认图像如何影响用户满意度。

**Result:** 研究呈现了初步实验和几次小型消融研究的结果。同时，报告了一项关于默认图像如何影响用户满意度的调查研究结果。

**Conclusion:** 这项工作为理解文本到图像生成中的默认图像奠定了基础，并强调了挑战和未来的研究方向。

> **ai_Abstract:** 本文首次深入探讨了文本到图像生成（TTI）模型中“默认图像”的现象。当模型遇到未知提示时，会生成这些彼此高度相似的图像。研究旨在通过系统方法、实验、消融研究以及用户满意度调查，探索Midjourney模型中的默认图像及其影响，为未来TTI和提示工程的改进提供基础。

> **摘要翻译:** 在文本到图像生成（TTI）的创意实践中，图像是从文本提示生成的。然而，TTI模型被训练为总是产生输出，即使提示包含未知术语。在这种情况下，模型可能会生成我们称之为“默认图像”的图像：这些图像在许多不相关的提示中彼此高度相似。我们认为研究默认图像对于设计更好的TTI解决方案和提示工程具有宝贵价值。在本文中，我们首次对流行的图像生成器Midjourney中的默认图像进行了调查。我们描述了创建触发默认图像的输入提示的系统方法，并展示了我们初步实验和几次小型消融研究的结果。我们还报告了一项调查研究，调查默认图像如何影响用户满意度。我们的工作为理解TTI中的默认图像奠定了基础，并强调了挑战和未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [284] [FLoRA: An Advanced AI-Powered Engine to Facilitate Hybrid Human-AI Regulated Learning](https://arxiv.org/abs/2507.07362)
> *FLoRA：一个先进的AI驱动引擎，旨在促进混合人机调节学习*

*Xinyu Li, Tongguang Li, Lixiang Yan, Yuheng Li, Linxuan Zhao, Mladen Raković, Inge Molenaar, Dragan Gašević, Yizhou Fan* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-11**

**Keywords:** 自我调节学习, 混合人机调节学习, 生成式人工智能, 学习分析, 智能教育

**Comment:** 

> **TL;DR:** FLoRA是一个先进的AI驱动引擎，旨在通过整合生成式AI和学习分析，解决现有工具在支持混合人机调节学习（HHAIRL）方面的不足，并经研究证实其在促进自我调节学习（SRL）和HHAIRL方面的有效性。

**AI_Comments:** 这项研究的创新之处在于其FLoRA引擎整合了先进的生成式AI和学习分析，并明确基于SRL和HHAIRL理论，以解决现有工具在适应性和人机交互方面的局限性。其重要性在于提供了一个实用且经过验证的解决方案，以促进更平衡、更有效的AI辅助学习，强调保持学习者主动性的同时提供智能支持。

<details>
  <summary>Details</summary>

**Motivation:** 自我调节学习（SRL）对学业成就和终身学习至关重要，但现有数字工具在支持混合人机调节学习（HHAIRL）方面存在局限性，包括缺乏适应性、关注点狭窄以及未能充分支持有意义的人机交互。

**Method:** 本文介绍了增强的FLoRA引擎，该引擎整合了先进的生成式人工智能（GenAI）功能和最先进的学习分析，并明确以SRL和HHAIRL理论为基础。FLoRA引擎提供协作写作、多智能体聊天机器人和详细学习轨迹日志等工具，以支持实时、动态、适应性强的个性化脚手架。

**Result:** 论文总结了多项研究，这些研究验证了FLoRA引擎的有效性，并展示了其工具在真实的教育和实验环境中的应用。这些研究表明FLoRA引擎在促进SRL和HHAIRL方面的有效性。

**Conclusion:** FLoRA引擎为AI增强学习的未来提供了理论见解和实践解决方案，有效地促进了自我调节学习（SRL）和混合人机调节学习（HHAIRL）。

> **ai_Abstract:** 本文介绍了FLoRA引擎，一个先进的AI驱动平台，旨在通过整合生成式AI和学习分析来促进混合人机调节学习（HHAIRL）。针对现有数字工具在适应性和人机交互方面的不足，FLoRA提供了如协作写作和多智能体聊天机器人等工具，以实现实时、个性化的动态脚手架。多项研究验证了FLoRA在提升自我调节学习（SRL）和HHAIRL方面的有效性，为AI增强学习提供了理论与实践支持。

> **摘要翻译:** SRL，被定义为学习者系统地规划、监控和调节其学习活动的能力，对于持续的学业成就和终身学习能力至关重要。新兴的人工智能（AI）发展深刻影响着SRL交互，可能削弱或增强学习者行使自身调节技能的机会。近期文献强调一种平衡的方法，称为混合人机调节学习（HHAIRL），其中AI提供有针对性、及时的脚手架，同时保留学习者作为积极决策者和学习过程反思监控者的角色。然而，现有数字工具常常不足，缺乏适应性，狭隘地关注孤立的SRL阶段，并且不足以支持有意义的人机交互。作为回应，本文引入了增强的FLoRA引擎，该引擎整合了先进的生成式人工智能（GenAI）功能和最先进的学习分析，明确以SRL和HHAIRL理论为基础。FLoRA引擎提供协作写作、多智能体聊天机器人和详细学习轨迹日志等工具，以支持实时、动态、适应性强的个性化脚手架。我们进一步总结了几项研究，这些研究为这些工具的验证提供了依据，并说明了它们如何在真实的教育和实验环境中被利用。这些研究表明FLoRA引擎在促进SRL和HHAIRL方面的有效性，为AI增强学习的未来提供了理论见解和实践解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [324] [Probing Experts' Perspectives on AI-Assisted Public Speaking Training](https://arxiv.org/abs/2507.07930)
> *探讨专家对AI辅助公共演讲训练的看法*

*Nesrine Fourati, Alisa Barkar, Marion Dragée, Liv Danthon-Lefebvre, Mathieu Chollet* | **Category: cs.HC, cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** AI辅助训练, 公共演讲, 专家视角, 混合式学习, 反馈机制

**Comment:** 

> **TL;DR:** 研究通过访谈和焦点小组，探讨了公共演讲专家对AI辅助训练工具的看法，发现AI在技术性训练中有价值，但需改进个性化和反馈质量，并支持混合式训练模式。

**AI_Comments:** 这项研究通过直接听取公共演讲专家的意见，为AI辅助公共演讲训练工具的开发和改进提供了宝贵的见解。其创新之处在于关注商业应用而非原型，并强调了人类专家在AI时代的角色转变和混合式教学的重要性。研究结果对未来AI教育工具的设计和部署具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 公共演讲是一项重要的职业技能，但许多人对此感到焦虑。传统训练依赖专家指导，而AI技术带来了新的自动化工具。然而，现有研究多集中于原型而非商业应用，且对公共演讲专家如何看待这些工具知之甚少。本研究旨在评估专家对商业AI演讲训练工具的效用和设计的看法，并提出改进建议。

**Method:** 研究通过对16位公共演讲专家进行半结构化访谈和2次焦点小组讨论。参与者讨论了他们对当前商业工具的看法、这些工具如何融入传统指导，以及对系统改进的建议。

**Result:** 专家认可AI工具在处理重复性、技术性训练方面的价值，使教练能专注于更高层次的技能。然而，他们发现当前工具存在关键问题，强调需要个性化、易于理解、精心选择的反馈和清晰的教学设计。

**Conclusion:** 专家总体上支持将传统指导与AI辅助练习相结合的混合模型。

> **ai_Abstract:** 本研究旨在探讨公共演讲专家对AI辅助商业演讲训练工具的看法。通过对16位专家进行访谈和焦点小组讨论，研究发现专家认可AI工具在处理技术性、重复性训练方面的潜力，但同时指出当前工具在个性化、反馈质量和教学设计上存在不足。专家们普遍支持结合传统指导和AI辅助练习的混合训练模式。

> **摘要翻译:** 背景：公共演讲是一项重要的职业技能，但对许多人来说，它仍然是焦虑的重要来源。传统的训练严重依赖专家指导，但人工智能的最新进展催生了新型的商业自动化公共演讲反馈工具。然而，大多数研究都集中在原型而非商业应用上，并且很少有人了解公共演讲专家如何看待这些工具。
目标：本研究旨在评估专家对基于AI的商业公共演讲训练工具的功效和设计的意见，并提出改进指南。
方法：该研究包括对16位公共演讲专家进行的半结构化访谈和2次焦点小组讨论。参与者讨论了他们对当前商业工具的看法、这些工具可能如何融入传统指导，以及增强这些系统的建议。
结果和结论：专家承认AI工具在处理训练中重复性、技术性方面有价值，使教练能够专注于更高层次的技能。然而，他们发现当前工具存在关键问题，强调需要个性化、可理解、精心选择的反馈以及清晰的教学设计。总的来说，他们支持将传统指导与AI辅助练习相结合的混合模型。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [398] [Conversational Self-Play for Discovering and Understanding Psychotherapy Approaches](https://arxiv.org/abs/2503.16521)
> *为发现和理解心理治疗方法而进行的对话式自我博弈*

*Onno P Kampman, Michael Xing, Charmaine Lim, Ahmad Ishqi Jabir, Ryan Louie, Jimmy Lee, Robert JT Morris* | **Category: cs.HC, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 对话式自我博弈, 大型语言模型, 心理治疗, AI生成对话, 模式评估

**Comment:** Improve writing, add multiple techniques extraction

> **TL;DR:** 本研究利用大型语言模型（LLM）进行对话式自我博弈，以一种可扩展的方式分析和探索心理治疗方法，并评估AI生成的治疗对话与既定模式的契合程度。

**AI_Comments:** 该研究开创性地将对话式自我博弈应用于心理治疗领域，利用LLM探索和评估治疗方法，具有重要的理论和实践意义。然而，其在真实临床环境中的有效性和局限性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 探索对话式自我博弈作为一种可扩展的方法，用于分析和探索心理治疗方法。

**Method:** 使用大型语言模型（LLM）进行对话式自我博弈，以生成治疗对话。

**Result:** 评估AI生成的治疗对话与既定心理治疗模式的契合程度。

**Conclusion:** 本研究提出了对话式自我博弈作为一种有前景的方法，用于以可扩展的方式分析和探索心理治疗，并评估AI生成的对话与现有模式的对齐情况。

> **ai_Abstract:** 本研究提出了一种利用大型语言模型（LLM）进行对话式自我博弈的新方法，旨在可扩展地分析和探索心理治疗方法，并评估AI生成的对话内容与现有心理治疗模式的一致性。

> **摘要翻译:** 本论文探讨了以大型语言模型（LLM）进行对话式自我博弈，作为一种可扩展的方法来分析和探索心理治疗方法，并评估了人工智能生成的治疗对话与既定模式的契合程度。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [448] [Human vs. LLM-Based Thematic Analysis for Digital Mental Health Research: Proof-of-Concept Comparative Study](https://arxiv.org/abs/2507.08002)
> *人类与基于大语言模型的数字心理健康研究主题分析：概念验证比较研究*

*Karisa Parkington, Bazen G. Teferra, Marianne Rouleau-Tang, Argyrios Perivolaris, Alice Rueda, Adam Dubrowski, Bill Kapralos, Reza Samavi, Andrew Greenshaw, Yanbo Zhang, Bo Cao, Yuqi Wu, Sirisha Rambhatla, Sridhar Krishnan, Venkat Bhat* | **Category: cs.HC, cs.AI** | **Updated: 2025-05-02**

**Keywords:** 主题分析,大语言模型,心理健康研究,GPT-4o,RISEN框架

**Comment:** 

> **TL;DR:** 该研究比较了人类和基于大语言模型（LLM）的主题分析方法在数字心理健康研究中的应用。结果表明，LLM（特别是使用RISEN框架的GPT-4o）在开发演绎性父代码和达到编码饱和度方面表现出效率和潜力，但人类在归纳性子代码开发和主题综合方面表现更佳。LLM分析成本更低，但深度不及人类分析。研究建议将LLM与人类监督相结合，以平衡参与者视角和研究资源。

**AI_Comments:** 这项研究为在大规模心理健康研究中应用LLM进行主题分析提供了有价值的见解。然而，需要进一步研究LLM在处理更复杂的定性数据和确保不同LLM模型之间的一致性方面的能力。此外，探索能够提高LLM归纳能力和综合能力的特定提示工程技术或微调策略将是有益的。

<details>
  <summary>Details</summary>

**Motivation:** 传统主题分析在大型医疗保健研究中因资源密集而受到限制。大语言模型（LLM）能够大规模分析文本并自动识别关键内容，有潜力解决这些挑战。然而，LLM在心理健康访谈中的应用需要与传统人类分析进行比较。

**Method:** 本研究将开箱即用型和基于知识库的LLM主题分析方法与传统方法进行比较，使用了来自一项针对医护人员的减压试验的转录文本。研究使用了OpenAI的GPT-4o模型和角色、指令、步骤、最终目标、缩小范围（RISEN）提示工程框架，并与Dedoose中的人类分析进行了比较。每种方法都开发了代码，注意到了饱和点，将代码应用于部分参与者（n=20）的摘录，并将数据综合成主题。对产出和性能指标进行了直接比较。

**Result:** 使用RISEN框架的LLM开发的演绎性父代码与人类代码相似，但人类在归纳性子代码开发和主题综合方面表现更佳。基于知识库的LLM比开箱即用型模型和人类达到编码饱和度所需的转录文本更少（分别为10-15篇、15-20篇和90-99篇）。开箱即用型LLM识别的摘录数量与人类研究人员相当，显示出较高的一致性评价信度（K = 0.84），但基于知识库的LLM产生的摘录较少。人类的摘录更长，并且每段摘录涉及多个代码，而LLM通常只应用一个代码。总的来说，基于LLM的主题分析被证明更具成本效益，但缺乏人类分析的深度。

**Conclusion:** LLM可以改变心理健康和临床研究中的定性分析，当与人类监督相结合时，可以在参与者视角和研究资源之间取得平衡。

> **ai_Abstract:** 本研究对比了人类和基于LLM（特别是GPT-4o结合RISEN框架）的主题分析方法在心理健康研究中的应用。结果显示，LLM在处理大规模数据和开发演绎性代码方面效率高，但人类在归纳性代码开发和主题综合方面更胜一筹。LLM分析成本效益高，但深度不足，建议结合人类监督使用。

> **摘要翻译:** 主题分析通过编码和主题发展为了解参与者的经历提供了宝贵的见解，但其资源密集型的性质限制了其在大型医疗保健研究中的应用。大型语言模型（LLM）能够大规模分析文本并自动识别关键内容，有潜力解决这些挑战。然而，它们在心理健康访谈中的应用需要与传统的以人为本的分析进行比较。本研究使用来自一项针对医疗保健工作者的减压试验的转录文本，将开箱即用型和基于知识库的LLM主题分析方法与传统方法进行比较。使用了OpenAI的GPT-4o模型以及角色、指令、步骤、最终目标、缩小范围（RISEN）提示工程框架，并与Dedoose中的人类分析进行了比较。每种方法都开发了代码，注意到了饱和点，将代码应用于部分参与者（n=20）的摘录，并将数据综合成主题。对产出和性能指标进行了直接比较。使用RISEN框架的LLM开发的演绎性父代码与人类代码相似，但人类在归纳性子代码开发和主题综合方面表现更佳。基于知识库的LLM比开箱即用型模型和人类达到编码饱和度所需的转录文本更少（分别为10-15篇、15-20篇和90-99篇）。开箱即用型LLM识别的摘录数量与人类研究人员相当，显示出较高的一致性评价信度（K = 0.84），但基于知识库的LLM产生的摘录较少。人类的摘录更长，并且每段摘录涉及多个代码，而LLM通常只应用一个代码。总的来说，基于LLM的主题分析被证明更具成本效益，但缺乏人类分析的深度。LLM可以通过与人类监督相结合来改变心理健康和临床研究中的定性分析，以平衡参与者视角和研究资源。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [483] [A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages](https://arxiv.org/abs/2507.08003)
> *鼠标和眼动在搜索引擎结果页面上的通用数据集*

*Kayhan Latifzadeh, Jacek Gwizdka, Luis A. Leiva* | **Category: cs.HC, cs.CV, cs.IR** | **Updated: 2025-05-12**

**Keywords:** 搜索引擎结果页面, 眼动追踪, 鼠标运动, 用户注意力, 数据集

**Comment:** 

> **TL;DR:** 该研究提出了一个包含用户在搜索引擎结果页面（SERPs）上眼动和鼠标运动数据的综合数据集，旨在克服以往研究依赖自我报告标签的局限性，提供更客观的用户注意力研究基础。

**AI_Comments:** 该研究通过提供一个包含眼动和鼠标运动数据的综合数据集，为SERP上的用户注意力研究做出了重要贡献。该数据集的客观性是其主要优势，克服了以往研究的局限性。基线实验的加入也为研究人员提供了清晰的应用起点。

<details>
  <summary>Details</summary>

**Motivation:** 以往研究依赖鼠标运动作为行为代理，但存在自我报告标签不准确和有偏见的缺点，本研究旨在通过眼动追踪提供客观的视觉注意力真实数据。

**Method:** 使用眼动追踪技术，收集了47名参与者在谷歌SERPs上进行2776次交易查询时的眼动和鼠标运动数据，并提供了HTML源文件、渲染截图、广告边界框和数据预处理脚本。

**Result:** 构建了一个包含HTML源文件、渲染截图、眼动数据、鼠标运动数据、广告边界框和预处理脚本的综合数据集，并进行了基线分类实验以启发未来研究。

**Conclusion:** 本研究贡献了一个全面的数据集，为研究用户在SERP上的注意力及购买行为提供了新的视角和工具，克服了现有研究的局限性。

> **ai_Abstract:** 该研究提出了一个包含用户在搜索引擎结果页面（SERPs）上眼动和鼠标运动数据的综合数据集。该数据集通过眼动追踪技术收集，克服了以往研究依赖不准确的自我报告标签的局限性，提供了更客观的用户注意力研究基础。数据集包含详细的原始数据和预处理脚本，并进行了基线实验以展示其应用潜力。

> **摘要翻译:** 我们贡献了一个全面的数据集，用于研究搜索引擎结果页面（SERPs）上的用户注意力和购买行为。以往的研究依赖鼠标运动作为低成本的大规模行为代理，但也依赖于在任务后收集的自我报告的真实标签，这可能不准确且容易产生偏差。为了解决这一局限性，我们使用眼动追踪器来构建连续视觉注意力的客观真实数据。我们的数据集包含 47 名参与者在谷歌 SERPs 上进行的 2,776 次交易查询，包括：(1) HTML 源文件，包含 CSS 和图像；(2) 渲染的 SERP 截图；(3) 眼动数据；(4) 鼠标运动数据；(5) 直接显示和自然广告的边界框；以及 (6) 用于进一步预处理数据的脚本。在本论文中，我们概述了该数据集并进行了基线实验（分类任务），以启发研究人员进行未来工作的不同可能性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [523] [SSSUMO: Real-Time Semi-Supervised Submovement Decomposition](https://arxiv.org/abs/2507.08028)
> *SSSUMO：实时半监督子运动分解*

*Evgenii Rudakov, Jonathan Shock, Otto Lappi, Benjamin Ultan Cowley* | **Category: cs.HC, cs.AI, cs.CV** | **Updated: 2025-07-08**

**Keywords:** 子运动分解, 半监督学习, 深度学习, 实时分析, 运动控制

**Comment:** 

> **TL;DR:** SSSUMO是一种新的半监督深度学习方法，可以实时、准确地分解人类动作的子运动，即使在数据稀疏或有噪声的情况下也能表现出色。

**AI_Comments:** 该研究提出了一种名为SSSUMO的半监督深度学习方法，用于解决子运动分解中的关键挑战，特别是在数据标记困难的情况下。其创新之处在于利用合成数据和未标记的人类运动数据进行迭代优化，并通过全卷积架构和可微分重建实现实时高性能。该方法在准确性、速度和鲁棒性方面均优于现有技术，并在多种人类运动任务中得到验证，具有重要的应用价值。公开提供的代码和模型权重也增加了该研究的可及性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有子运动分析方法在重建准确性、计算成本和验证方面存在挑战，主要是因为难以获得手动标记数据。

**Method:** 采用半监督学习框架，首先从最小加加速度原理生成合成数据，然后通过适应未标记的人类运动数据进行迭代优化。使用全卷积架构和可微分重建来实现。

**Result:** SSSUMO在合成和多样化的人类运动数据集上均显著优于现有方法，即使在高噪声条件下也表现出鲁棒性。模型能够实时运行（每秒输入<1毫秒），并且在转向、旋转、指向、物体移动、书写和鼠标控制游戏等多种任务中表现出色，尤其是在传统方法效果不佳的挑战性数据集上。

**Conclusion:** SSSUMO是一种高效且准确的子运动分解方法，克服了现有技术的局限性，并在各种应用中显示出巨大潜力。

> **ai_Abstract:** SSSUMO是一种新颖的半监督深度学习方法，用于实时子运动分解。它通过利用合成数据和未标记的人类运动数据来克服传统方法的局限性，实现了最先进的准确性和速度。该模型在各种任务和具有挑战性的数据集上都表现出鲁棒性，并在实时性能方面取得了重大突破。

> **摘要翻译:** 本文介绍了一种用于子运动分解的SSSUMO半监督深度学习方法，该方法在准确性和速度方面均达到了最先进水平。虽然子运动分析对运动控制提供了有价值的见解，但由于难以获得手工标记数据，现有方法在重建准确性、计算成本和验证方面存在困难。我们使用半监督学习框架解决了这些挑战。该框架从最初根据最小加加速度原理生成的合成数据中学习，然后通过适应未标记的人类运动数据进行迭代优化。我们完全卷积的架构和可微分重建在合成和多样化的人类运动数据集上都显著优于现有方法，即使在高噪声条件下也显示出鲁棒性。至关重要的是，该模型能够实时运行（每秒输入<1毫秒），与基于优化的技术相比有了实质性的改进。这种增强的性能促进了人机交互、康复医学和运动控制研究中的新应用。我们展示了该模型在转向、旋转、指向、物体移动、书写和鼠标控制游戏等多样化的人类执行任务中的有效性，特别是在传统方法基本失败的挑战性数据集上显示出显著的改进。训练和基准测试源代码以及预训练模型权重可在https://github.com/dolphin-in-a-coma/sssumo 公开获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [548] [Pushing the Boundaries of Immersion and Storytelling: A Technical Review of Unreal Engine](https://arxiv.org/abs/2507.08142)
> *《虚幻引擎的沉浸感和叙事界限的拓展：一项技术审查》*

*Oleksandra Sobchyshak, Santiago Berrezueta-Guzman, Stefan Wagner* | **Category: cs.HC** | **Updated: 2025-07-10**

**Keywords:** 虚幻引擎,沉浸式叙事,虚拟现实,技术审查,虚拟制作

**Comment:** Paper submitted to Elsevier

> **TL;DR:** 该论文对虚幻引擎进行了技术审查，重点介绍了其在创建超现实环境和引人入胜的叙事方面的创新，以及在游戏、虚拟制作、教育、文化保护和医疗保健等行业的应用。它还讨论了该引擎的挑战和未来前景。

**AI_Comments:** 该论文对虚幻引擎进行了全面的技术审查，重点介绍了其在沉浸式叙事和虚拟现实领域的广泛应用和影响力。文章结构清晰，从引擎的创新技术到实际应用案例，再到面临的挑战和未来发展方向都进行了深入探讨。然而，文章在讨论挑战时可以更具体地阐述“有限的可访问性”和“伦理问题”，例如可以提供一些具体的例子或数据来支持这些论点。总的来说，这是一篇有价值的论文，为理解虚幻引擎的潜力和局限性提供了有力的见解。

<details>
  <summary>Details</summary>

**Motivation:** 虚幻引擎在通过其先进功能和多样化应用影响沉浸式叙事和虚拟现实方面发挥着重要作用。

**Method:** 对虚幻引擎进行了深入的技术审查，分析了其在创建超现实环境和引人入胜的叙事方面的关键创新，并通过案例研究展示了其在无缝整合视觉效果、音频和交互性以创造引人入胜的体验方面的能力。

**Result:** 虚幻引擎在跨行业应用中具有变革性影响，能够将叙事与尖端技术相结合，并且在程序化内容生成、人工智能驱动的工作流程、智慧城市模拟和基于虚拟现实的康复计划等方面具有广泛的应用。然而，它也面临着高硬件需求、可访问性有限以及与过度沉浸和数据隐私相关的伦理问题等挑战。

**Conclusion:** 虚幻引擎是创新的推动者和跨学科合作的平台，它通过赋能创作者、重新定义工作流程以及拓展沉浸式叙事的界限，在塑造虚拟现实和互动媒体的未来方面发挥着关键作用。

> **ai_Abstract:** 本文对虚幻引擎进行了技术审查，重点介绍了其在创建超现实环境和引人入胜的叙事方面的创新，以及在游戏、虚拟制作、教育、文化保护和医疗保健等行业的应用。它还讨论了该引擎的挑战和未来前景。

> **摘要翻译:** 虚幻引擎是一个通过其先进的功能和多样化的应用影响沉浸式叙事和虚拟现实（VR）的平台。本文对虚幻引擎进行了深入的技术审查。它分析了其在创建超现实环境和情感吸引力叙事方面的关键创新，并在游戏、虚拟制作、教育、文化保护和医疗保健等领域有着重要的应用。本文的研究结果强调了虚幻引擎在各行业的变革性影响，展示了其将叙事与尖端技术融合以创造引人入胜的体验的能力。案例研究说明了虚幻引擎如何促进无缝的视觉、音频和交互性整合，以创造引人入胜的体验。此外，本研究还确定了虚幻引擎在从程序化内容生成和人工智能驱动的工作流程到智慧城市模拟和基于虚拟现实的康复计划等应用中的多功能性。
虽然虚幻引擎为视觉保真度和交互性设定了新的标杆，但本文也强调了一些关键挑战，包括其高硬件需求、有限的可访问性以及与过度沉浸和数据隐私相关的伦理问题。通过基于云的渲染、包容性设计和道德实践来应对这些挑战，对于更广泛的采用和可持续性至关重要。本综述总结道，虚幻引擎适用于创新和跨学科合作。它赋能创作者、重新定义工作流程以及拓展沉浸式叙事界限的能力，使虚幻引擎成为塑造虚拟现实和互动媒体未来的关键。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [572] [Emotion Detection in Older Adults Using Physiological Signals from Wearable Sensors](https://arxiv.org/abs/2507.08167)
> *使用可穿戴传感器生理信号检测老年人的情绪*

*Md. Saif Hassan Onim, Andrew M. Kiselica, Himanshu Thapliyal* | **Category: cs.HC, cs.LG, H.1.2; J.3; C.3** | **Updated: 2025-07-10**

**Keywords:** 情绪识别, 老年人, 生理信号, 可穿戴传感器, 机器学习

**Comment:** 

> **TL;DR:** 该研究提出了一种基于边缘计算、非侵入式的方法，仅使用可穿戴传感器收集的生理信号来识别老年人的情绪状态，无需摄像头或面部分析。研究人员使用了包含40名老年人数据的混合数据集，并利用经典机器学习模型预测情绪反应强度。实验结果显示，该方法在回归任务上取得了0.782的最高R²分数和0.0006的最低均方误差（MSE），证明了其在现实世界中实现保护隐私且高效的情绪识别系统的可行性，尤其对阿尔茨海默病相关痴呆症（ADRD）和患有创伤后应激障碍（PTSD）或其他认知障碍的老年退伍军人具有重要意义。

**AI_Comments:** 这项研究在情绪识别领域取得了重要进展，尤其关注了老年人群体这一特定且重要的应用场景。其创新的地方在于完全摒弃了对摄像头和面部表情的依赖，转而专注于利用可穿戴设备收集的生理信号。这种方法不仅提高了用户隐私的保护程度，也使得情绪识别技术在各种非传统场景（如医院、辅助生活设施）中的应用更加便捷和广泛。研究结果具有说服力，证明了生理信号在预测情绪强度方面的有效性。然而，研究可能存在的局限性包括数据集规模相对较小（仅40名参与者），以及对“情绪强度”的定义和测量方式的进一步阐述。未来的研究可以考虑扩大样本量，纳入更多样化的老年人群体，并探索更复杂的深度学习模型以进一步提升情绪识别的准确性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 老年人情绪检测对于理解其认知和情感健康至关重要，尤其是在医院和辅助生活环境中。该研究旨在探索一种不依赖摄像头或侵入性面部分析，仅通过生理信号进行情绪识别的方法。

**Method:** 该研究提出了一种基于边缘计算的非侵入式情绪识别方法，仅使用可穿戴传感器（Empatica E4和Shimmer3 GSR+腕带）收集的生理信号。研究利用包含40名老年人数据的混合数据集，该数据集包含生理信号和面部表情（通过iMotion的FEA模块记录），并标注了十二种情绪类别及其相对强度。研究人员应用经典机器学习模型，基于生理信号预测情绪反应的强度。

**Result:** 在回归任务中，该方法取得了0.782的最高R²分数和0.0006的最低均方误差（MSE）。

**Conclusion:** 研究结果证实了仅使用生理信号进行情绪识别的可行性，为在现实世界中实现保护隐私且高效的情绪识别系统奠定了基础，特别是对于ADRD和有PTSD或其他认知障碍的老年退伍军人。

> **ai_Abstract:** 本研究提出了一种创新的、基于边缘计算的非侵入式情绪识别方法，专门针对老年人群体。该方法仅依赖于可穿戴传感器收集的生理信号，无需摄像头或面部分析，即可有效识别情绪状态。通过对40名老年人数据的分析，并运用经典机器学习模型进行回归预测，研究成功实现了较高的预测精度（最高R²为0.782，最低MSE为0.0006）。这一成果对于改善患有ADRD、PTSD及其他认知障碍的老年人的生活质量，以及构建更注重隐私的现实应用场景具有重要意义。

> **摘要翻译:** 老年人情绪检测对于理解他们的认知和情感健康至关重要，尤其是在医院和辅助生活环境中。在本研究中，我们研究了一种基于边缘计算的非侵入式情绪识别方法，该方法仅使用通过可穿戴传感器获得的生理信号。我们的数据集包括来自40名老年人的数据。情绪状态是使用Empatica E4和Shimmer3 GSR+腕带的生理信号获得的，并使用iMotion的面部表情分析（FEA）模块通过摄像头记录面部表情。数据集还包含十二种情绪类别，以相对强度表示。我们的目标是研究仅使用生理传感器数据，在不需要摄像头或侵入性面部分析的情况下，情绪识别可以完成到什么程度。通过利用经典的机器学习模型，我们根据生理信号预测情绪反应的强度。我们在回归任务上取得了0.782的最高r2分数和0.0006的最低MSE。该方法对于阿尔茨海默病及相关痴呆症（ADRD）患者，以及应对创伤后应激障碍（PTSD）或其他认知障碍的老年退伍军人具有重要意义。我们跨多个经典回归模型的结果验证了该方法的可能性，为现实世界中保护隐私和高效的情绪识别系统铺平了道路。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [592] [Uncanny or Not? Perceptions of AI-Generated Faces in Autism](https://arxiv.org/abs/2507.08230)
> *非同寻常抑或如常？自闭症群体对人工智能生成面孔的感知*

*Gabriella Waters* | **Category: cs.HC** | **Updated: 2025-07-11**

**Keywords:** 人工智能生成面孔,自闭症,恐怖谷效应,感知,定性研究

**Comment:** 2 figures, 15 pages

> **TL;DR:** 本研究探讨了自闭症个体对人工智能生成面孔的感知，特别是“恐怖谷”效应。通过分析Reddit上r/autism社区的讨论，研究发现自闭症个体对真实人脸的 the uncanny valley 效应可能比对人工智能生成人脸更敏感，并提出了人工智能在自闭症领域的应用前景。

**AI_Comments:** 这项研究的创新之处在于将自闭症群体的感知视角引入到人工智能生成面孔的研究中，特别是关注了“恐怖谷”效应。研究方法采用了定性分析，从真实用户社区获取数据，这使得研究更贴近实际体验。然而，研究的局限性在于样本来源的单一性（仅限于Reddit社区）以及定性研究的普适性问题。未来的研究可以考虑结合定量方法，扩大样本范围，以获得更全面的认识。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能生成人脸技术的日益成熟，理解不同人群如何感知这些合成图像至关重要，特别是自闭症个体。

**Method:** 采用定性研究方法，分析了Reddit上r/autism社区关于人工智能生成面孔和恐怖谷现象的讨论。

**Result:** 研究结果表明，自闭症个体对恐怖谷现象的体验可能与常人不同，他们常常表示对真实人脸感到比对人工智能生成人脸更强烈的不适感。

**Conclusion:** 自闭症个体对恐怖谷现象的体验可能存在差异，对真实人脸的 the uncanny valley 效应可能比对人工智能生成人脸更敏感，这对包容性人工智能系统和辅助技术的发展具有启示意义。

> **ai_Abstract:** 本研究旨在探究自闭症个体对人工智能生成人脸的感知，特别是“恐怖谷”效应。研究人员通过对Reddit上r/autism社区的讨论进行定性分析，发现自闭症个体可能对真实人脸比对AI生成人脸体验到更强烈的“恐怖谷”效应。这一发现对于理解自闭症的视觉感知以及开发更具包容性的人工智能系统具有重要意义。

> **摘要翻译:** 随着人工智能（AI）系统在生成合成人脸方面变得越来越复杂，了解这些图像如何在不同人群中被感知非常重要。本研究调查了自闭症个体如何感知人工智能生成的人脸，重点关注恐怖谷效应。我们采用定性方法，分析了Reddit上r/autism社区的讨论，以探讨自闭症参与者如何描述他们对人工智能生成人脸和恐怖谷现象的体验。研究结果表明，自闭症个体可能以不同的方式体验恐怖谷效应，通常报告说对真实人脸比对人工智能生成人脸感到更强烈的不适。这项研究有助于我们理解自闭症的视觉感知，并对包容性人工智能系统和辅助技术的发展具有启示意义。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [21] [Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows](https://arxiv.org/abs/2507.08149)
> *与我协作还是代我编码？AI自动化程度提升如何改变开发者工作流程*

*Valerie Chen, Ameet Talwalkar, Robert Brennan, Graham Neubig* | **Category: cs.SE** | **Updated: 2025-07-10**

**Keywords:** AI自动化, 编程代理, 开发者工作流程, 用户体验, GitHub Copilot

**Comment:** 

> **TL;DR:** 本研究首次学术性地探讨了开发者与编程代理的交互，并与现有副驾驶工具进行对比，发现编程代理在提高生产力和减少用户工作量方面具有潜力，但其广泛采用面临挑战，例如需要确保用户充分理解代理行为。

**AI_Comments:** 该研究具有创新性，因为它首次将关注点从传统的AI副驾驶转向了更自主的AI编程代理，并首次进行了有人类参与的学术研究。其重要性在于揭示了高自动化AI在软件开发中的潜力与挑战，为AI工具的未来发展和实际应用提供了宝贵的见解。研究强调了用户理解和信任的重要性，这对于AI代理的广泛采纳至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有大量研究关注开发者使用副驾驶（copilots）的情况，但对能够自动编写文件和运行代码的编程代理（coding agents）的评估仍主要依赖静态基准测试，缺乏人类参与的实际交互研究。本研究旨在首次探索开发者与编程代理的交互，并分析更高自动化程度的AI工具如何影响用户生产力和体验。

**Method:** 研究评估了两种领先的副驾驶和代理编码助手：GitHub Copilot和OpenHands。招募了定期使用GitHub Copilot的参与者，进行首次学术研究以探索开发者与编程代理的交互。

**Result:** 研究结果表明，编程代理有潜力以超越副驾驶的方式协助开发者（例如，完成人类之前可能无法完成的任务），并减少完成任务所需的用户工作量。然而，其广泛采用面临挑战，包括如何确保用户充分理解代理行为。

**Conclusion:** 编程代理能够改变开发者工作流程，并在提高生产力方面超越现有副驾驶工具，但其广泛采用需要解决用户理解和信任等挑战。研究为构建新代理的研究人员提供了一系列建议，并强调了将更多代理系统引入开发者工作流程的关键挑战。

> **ai_Abstract:** 本研究首次系统性地探讨了开发者与高自动化AI编程代理的交互，并将其与现有副驾驶工具进行对比。通过对GitHub Copilot和OpenHands的评估，研究发现编程代理在提高开发者生产力和减少工作量方面具有显著潜力，甚至能完成人类此前难以实现的任务。然而，其广泛推广面临挑战，尤其是在确保用户理解代理行为方面。研究不仅揭示了编程代理如何重塑开发者工作流程，还强调了与副驾驶的区别，并为未来代理工具的开发提供了实践建议，指出了将更具代理性的系统整合到开发者工作流程中的关键障碍。

> **摘要翻译:** 开发者现在可以使用越来越多的日益自主的AI工具来支持软件开发。尽管大量研究已经检验了开发者对副驾驶（可以提供聊天协助或代码补全）的使用，但对能够自动编写文件和运行代码的编程代理的评估仍然主要依赖于没有人类参与的静态基准测试。在这项工作中，我们进行了首次学术研究，旨在探索开发者与编程代理的交互，并描述与现有副驾驶相比，更自主的AI工具如何影响用户生产力和体验。我们评估了两种领先的副驾驶和代理编码助手，GitHub Copilot和OpenHands，并招募了定期使用前者的参与者。我们的结果表明，代理有潜力以超越副驾驶的方式协助开发者（例如，完成人类之前可能无法完成的任务），并减少完成任务所需的用户工作量。然而，实现其更广泛采用存在挑战，包括如何确保用户充分理解代理行为。我们的结果不仅提供了关于编程代理如何改变开发者工作流程的见解，还强调了用户与代理的交互方式与现有副驾驶的不同，从而为构建新代理的研究人员提出了一系列建议。鉴于仍有大量开发者主要依赖于类似副驾驶的系统，我们的工作强调了将更多代理系统引入开发者工作流程的关键挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [33] [The Impact of Generative AI on Code Expertise Models: An Exploratory Study](https://arxiv.org/abs/2507.08160)
> *生成式AI对代码专业知识模型的影响：一项探索性研究*

*Otávio Cury, Guilherme Avelino* | **Category: cs.SE** | **Updated: 2025-07-10**

**Keywords:** 生成式AI, 代码专业知识, 知识模型, 卡车系数, 软件开发

**Comment:** 

> **TL;DR:** 生成式AI工具提高了软件开发效率，但也可能导致开发者对代码理解的降低，从而影响用于识别开发者专业知识的代码知识模型和卡车系数算法的可靠性。

**AI_Comments:** 这项研究具有重要的现实意义，因为它揭示了生成式AI在提高生产力的同时，可能对软件开发领域的核心——开发者专业知识的评估——带来潜在的负面影响。其创新之处在于首次探索了GenAI对代码知识模型和卡车系数算法的具体影响，为未来评估开发者技能和团队结构提供了新的视角。研究的局限性在于其探索性质，可能需要更广泛的数据集和更复杂的模拟来验证这些发现。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI工具虽然提高了软件开发效率，但也引发了开发者可能过度依赖这些工具，从而降低对生成代码理解的担忧。本研究旨在探讨这种理解的丧失是否会反映在用于识别开发者专业知识的源代码知识模型中。

**Method:** 本研究对知识模型和基于该模型构建的卡车系数算法如何受生成式AI使用影响进行了探索性分析。研究人员收集了ChatGPT生成的代码集成到GitHub项目中的统计数据，并通过调整生成式AI贡献的程度模拟了各种场景。

**Result:** 研究发现，大多数模拟场景都产生了可衡量的影响，表明当前专业知识指标的敏感性。这表明随着生成式AI更深入地融入开发工作流程，此类指标的可靠性可能会降低。

**Conclusion:** 生成式AI的广泛使用会显著影响现有的代码专业知识模型和相关指标的可靠性，提示需要重新评估和调整衡量开发者专业知识的方法。

> **ai_Abstract:** 本研究探索了生成式AI工具对代码专业知识模型的影响。研究假设开发者过度依赖GenAI可能导致对代码理解的下降，进而影响用于衡量开发者专业知识的知识模型和卡车系数算法。通过分析GitHub项目中ChatGPT生成代码的集成情况并模拟不同GenAI贡献场景，结果表明，GenAI的使用对现有专业知识指标产生了可衡量的影响，预示着随着GenAI的普及，这些指标的可靠性可能会降低。

> **摘要翻译:** 生成式人工智能（GenAI）工具用于源代码生成，显著提升了软件开发的生产力。然而，它们也引发了担忧，特别是开发者可能过度依赖这些工具，从而降低对生成代码的理解。我们假设这种理解的丧失可能反映在源代码知识模型中，这些模型用于识别开发者的专业知识。在这项工作中，我们对一个知识模型以及基于它构建的卡车系数算法如何受到GenAI使用影响进行了探索性分析。为了调查这一点，我们收集了ChatGPT生成的代码集成到GitHub项目中的统计数据，并通过调整GenAI贡献的程度模拟了各种场景。我们的研究结果显示，大多数场景都导致了可衡量的影响，表明当前专业知识指标的敏感性。这表明，随着GenAI更深入地集成到开发工作流程中，此类指标的可靠性可能会降低。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [61] [Leveraging Large Language Models for Classifying App Users' Feedback](https://arxiv.org/abs/2507.08250)
> *利用大型语言模型对应用程序用户反馈进行分类*

*Yasaman Abedini, Abbas Heydarnoori* | **Category: cs.SE** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 用户反馈分类, 数据增强, BERT, 文本分类

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型（LLMs）在分类应用程序用户反馈方面的能力，并利用它们作为标注工具来扩充数据集，以提高传统分类模型的性能。

**AI_Comments:** 该论文的创新之处在于，它不仅探索了大型语言模型（LLMs）直接进行用户反馈分类的能力，更重要的是，提出并验证了将LLMs作为一种高效的标注工具，用于扩充训练数据集。这为解决传统机器学习方法在用户反馈分类中面临的标注数据稀缺和泛化性不足的挑战提供了一条有前景的途径。通过结合LLMs的强大理解能力和传统模型的效率，该方法有望在实际应用中取得更好的平衡和性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有监督机器学习方法在应用程序用户反馈分类中面临泛化性挑战，因为创建大规模且准确标注的数据集耗时耗力，导致标注数据集的限制。

**Method:** 研究评估了GPT-3.5-Turbo、GPT-4、Flan-T5和Llama3-70b四种大型语言模型的能力。在八个预先标注的数据集上进行了多项实验，这些数据集包括来自应用商店、X平台和公共论坛的用户评论。研究分析了LLM在识别细粒度和粗粒度用户反馈类别方面的性能。鉴于用户反馈量大和LLM的计算限制，研究将LLM用作标注工具，通过通用和特定于应用的数据来扩充标注数据集，旨在提高最先进的BERT分类模型的性能。

**Result:** 研究发现，在精心设计的提示引导下，大型语言模型能有效将用户反馈分类到粗粒度类别中。此外，使用LLM共识标注的数据集来扩充训练数据集，可以显著提高分类器的性能。

**Conclusion:** 大型语言模型不仅能够有效进行粗粒度用户反馈分类，而且通过将它们作为标注工具来扩充训练数据，可以显著提升传统分类模型的性能，有效缓解了标注数据稀缺的问题。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在应用程序用户反馈分类中的应用，旨在解决传统方法中标注数据稀缺的问题。研究评估了GPT-3.5-Turbo、GPT-4、Flan-T5和Llama3-70b在八个基准数据集上的分类能力，包括细粒度和粗粒度分类。鉴于LLMs的计算限制和海量用户反馈，研究提出将LLMs作为标注工具来扩充现有数据集，以增强BERT等传统分类模型的性能。实验结果表明，LLMs在粗粒度分类上表现出色，并且通过LLMs扩充的训练数据能显著提升分类器的性能。

> **摘要翻译:** 近年来，对应用程序（app）用户反馈分类进行了大量研究，主要依赖于监督机器学习算法。然而，基于现有标注数据集微调更具泛化性的分类器仍然是一个重要挑战，因为创建大型且准确标注的数据集通常需要大量的L时间L和资源。在本文中，我们评估了四种先进LLM（包括GPT-3.5-Turbo、GPT-4、Flan-T5和Llama3-70b）的能力，以增强用户反馈分类并解决标注数据集有限的挑战。为此，我们在八个先前研究中精心标注的数据集上进行了多项实验。这些数据集包括来自应用商店的用户评论、来自X平台的帖子以及来自公共论坛的讨论，这些都被广泛认为是应用程序用户反馈的代表性来源。我们分析了各种LLM在识别细粒度和粗粒度用户反馈类别方面的性能。鉴于每日用户反馈量巨大以及LLM的计算限制，我们利用这些模型作为标注工具，用通用和特定于应用程序的数据来扩充标注数据集。这种扩充旨在提高最先进的基于BERT的分类模型的性能。我们的研究结果表明，在精心设计的提示引导下，LLM可以有效地将用户反馈分类到粗粒度类别中。此外，使用LLM共识标注的数据集来扩充训练数据集可以显著提高分类器的性能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [89] [Computing Floating-Point Errors by Injecting Perturbations](https://arxiv.org/abs/2507.08467)
> *通过注入扰动计算浮点误差*

*Youshuai Tan, Zhanwei Zhang, Jinfu Chen, Zishuo Ding, Jifeng Xuan, Weiyi Shang* | **Category: cs.SE** | **Updated: 2025-07-11**

**Keywords:** 浮点误差, 扰动注入, PI-detector, 误差计算, 数值稳定性

**Comment:** arXiv admin note: text overlap with arXiv:2412.20804

> **TL;DR:** PI-detector通过向原子操作数注入微小扰动来有效且准确地计算浮点误差，解决了现有工具的局限性。

**AI_Comments:** 该论文提出了一种新颖的浮点误差计算方法PI-detector，其创新点在于通过注入扰动来模拟误差传播和累积，避免了传统高精度预言机方法的复杂性和低效率。这种方法有望在安全关键系统等领域提供更实用、更快速的浮点误差分析工具。其重要性在于解决了现有工具在准确性和效率上的权衡问题。

<details>
  <summary>Details</summary>

**Motivation:** 浮点错误在科学和工程中可能导致严重后果，但现有检测工具如ATOMU存在误报，而FPCC速度较慢。研究人员通常将高精度浮点程序结果作为预言机，但这导致实现困难和执行时间过长。

**Method:** 提出了一种名为PI-detector的新方法，其基于浮点误差源于原子操作（如加减法）中大条件数并传播累积的观察。PI-detector向程序中单个原子操作的运算数注入微小扰动，并通过比较原始程序与扰动版本的输出结果来计算浮点误差。

**Result:** 通过使用来自ATOMU和HSED的数据集以及一个复杂的线性系统求解程序进行评估，实验结果表明PI-detector可以进行高效且准确的浮点误差计算。

**Conclusion:** PI-detector通过注入扰动的方法，能够有效且准确地计算浮点误差，解决了现有工具的效率和准确性问题。

> **ai_Abstract:** 该论文提出了一种名为PI-detector的新方法，用于有效且准确地计算浮点误差。现有方法如使用高精度预言机存在实现和效率问题，而ATOMU有误报，FPCC速度慢。PI-detector基于浮点误差源于原子操作条件数大并传播积累的观察，通过向原子操作数注入微小扰动并比较结果来计算误差。实验证明PI-detector能够高效且准确地计算浮点误差。

> **摘要翻译:** 浮点程序构成了现代科学和工程的基础，为安全关键系统、航空航天工程和金融分析等广泛应用提供了必要的计算框架。浮点错误可能导致严重后果。尽管浮点错误广泛存在，但只有一部分输入可能会在浮点程序中引发显著错误。因此，确定给定输入是否会产生此类错误至关重要。研究人员倾向于将高精度浮点程序的结果作为检测浮点错误的预言机，这带来了两个主要限制：（1）实现困难和（2）执行时间延长。最近的两个工具ATOMU和FPCC可以部分解决这些问题。然而，ATOMU存在误报；而FPCC虽然消除了误报，但运行速度相当慢。
为了解决这两个挑战，我们提出了一种名为PI-detector的新方法，以有效且高效地计算浮点误差。我们的方法基于浮点误差源于原子操作（如加法和减法）中大条件数，然后传播和累积的观察。PI-detector将微小扰动注入程序中单个原子操作的运算数中，并比较原始程序与扰动版本的输出结果来计算浮点误差。我们使用来自ATOMU和HSED的数据集以及一个复杂的线性系统求解程序评估了PI-detector。实验结果表明，PI-detector可以进行高效且准确的浮点误差计算。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [117] [InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching](https://arxiv.org/abs/2507.08523)
> *InferLog：通过面向ICL的前缀缓存加速在线日志解析的LLM推理*

*Yilun Wang, Pengfei Chen, Haiyu Huang, Zilong He, Gou Tan, Chuanfu Zhang, Jingkai He, Zibin Zheng* | **Category: cs.SE** | **Updated: 2025-07-11**

**Keywords:** LLM推理, 日志解析, ICL, 前缀缓存, 性能优化

**Comment:** 

> **TL;DR:** InferLog通过优化LLM推理效率，特别是利用ICL和前缀缓存，显著加速在线日志解析，同时保持准确性。

**AI_Comments:** InferLog的创新点在于将LLM在线日志解析的瓶颈从准确性转移到推理效率，并提出了结合ICL优化和前缀缓存以及元学习配置调优的综合解决方案，为LLM在实时高并发场景下的部署提供了新的思路。该研究为LLM在需要高吞吐量和低延迟的生产环境中落地应用提供了重要的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 现代软件系统产生海量运行时日志，需要高效准确的日志解析来支持异常检测和根本原因分析等关键下游任务。尽管大语言模型（LLMs）在日志解析精度上表现出色，但其在生产环境部署面临两大限制：商业LLM的隐私风险促使本地部署需求，以及高容量日志流带来的严格延迟和吞吐量要求。现有LLM解析器未能满足这些要求。虽然近期工作减少了LLM查询次数，但忽视了LLM调用本身的高延迟，导致并发日志解析请求下LLM推理系统性能严重下降，推理效率成为关键瓶颈。

**Method:** 本研究提出了InferLog，这是首个针对在线日志解析的LLM推理优化方法。其核心在于识别出推理效率而非解析准确性是在线LLM日志解析中的关键瓶颈。InferLog通过以下两点加速推理：1) 一个前缀感知ICL精炼策略（Prefix-aware ICL Refinement policy），用于优化上下文学习（ICL）的示例和排列，从而提高前缀缓存效率。2) 一个基于元学习的快速且任务特定的配置调优管道，用于为动态日志解析工作负载寻找最优的LLM调度相关配置。

**Result:** 基于Loghub数据集和vLLM的实验结果表明，InferLog显著优于现有推理优化方法，并在不损害解析准确性的前提下，显著加速了最先进的LLM日志解析器。

**Conclusion:** InferLog通过专注于优化LLM推理效率，成功解决了LLM在在线日志解析部署中的性能瓶颈，使其更适用于高吞吐量、低延迟的生产环境。

> **ai_Abstract:** InferLog是一种新型LLM推理优化方法，旨在解决LLM在在线日志解析中面临的部署挑战，特别是高延迟和吞吐量瓶颈。该方法的核心思想是将瓶颈从解析准确性转移到推理效率，并通过引入前缀感知ICL精炼策略以提高前缀缓存效率，以及基于元学习的快速配置调优管道来寻找最优LLM调度配置。实验证明，InferLog在保持解析准确性的同时，显著加速了现有LLM日志解析器，使其更适用于大规模日志流处理。

> **摘要翻译:** 现代软件系统生成海量运行时日志，需要高效准确的日志解析以支持异常检测和根本原因分析等关键下游任务。最近，大语言模型（LLMs）在日志解析方面取得了先进的准确性，但其在生产环境中的部署面临两大主要限制：(1) 与商业LLM相关的隐私风险，这促使了本地部署的采用；(2) 高容量日志流施加的严格延迟和吞吐量要求，而现有基于LLM的解析器未能满足这些要求。尽管最近的努力减少了LLM查询次数，但它们忽视了LLM调用本身的高延迟，并发日志解析请求可能导致LLM推理系统性能严重下降。
在本研究中，我们提出了InferLog，这是首个针对在线日志解析的LLM推理优化方法。我们的关键见解是，推理效率而非解析准确性，成为基于LLM的在线日志解析中的关键瓶颈。InferLog通过设计以下两点来加速推理：(1) 一个前缀感知ICL精炼策略，用于优化上下文学习（ICL）的示例和排列，以提高前缀缓存效率。(2) 一个基于元学习的快速且任务特定的配置调优管道，用于为动态日志解析工作负载寻找最优的LLM调度相关配置。基于Loghub数据集和vLLM的实验结果表明，InferLog显著优于现有推理优化方法，并在不损害解析准确性的前提下，显著加速了最先进的LLM日志解析器。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [145] [Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy](https://arxiv.org/abs/2507.08594)
> *通过提示工程生成原型角色：一项关于效率、有效性和同理心的案例研究*

*Fernando Ayach, Vitor Lameirão, Raul Leão, Jerfferson Felizardo, Rafael Sobrinho, Vanessa Borges, Patrícia Matsubara, Awdren Fontão* | **Category: cs.SE, cs.AI, cs.HC** | **Updated: 2025-07-11**

**Keywords:** 原型角色, 提示工程, 生成式AI, 产品发现, 效率, 同理心

**Comment:** 12 pages; 2 figures; Preprint with the original submission accepted
  for publication at 39th Brazilian Symposium on Software Engineering (SBES)

> **TL;DR:** 本研究提出并验证了一种基于提示工程的方法，利用生成式AI来创建原型角色，旨在提高效率、有效性，并评估用户接受度和同理心。结果显示该方法提高了效率和质量，尽管在同理心和泛化方面存在挑战。

**AI_Comments:** 这项研究的创新之处在于将提示工程与生成式AI相结合，用于自动化原型角色的生成，这为传统上耗时且主观的产品发现过程带来了效率和客观性的提升。其重要性体现在为软件产品发现实践提供了新的工具和方法，有助于加速产品开发周期并提高产品定义质量。然而，研究也明确指出了当前方法的局限性，特别是在同理心的全面支持和泛化能力方面，这为未来研究和技术迭代提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 原型角色在产品发现早期阶段（如精益启动）中被广泛使用，但手动创建过程通常耗时、认知负担重且容易产生偏见。

**Method:** 本研究提出了一种基于提示工程的方法，利用生成式AI来生成原型角色。通过一项包含19名参与者的案例研究，该研究嵌入在一个真实的精益启动流程中，并采用了定性和定量相结合的研究方法来评估该方法在效率、有效性、用户接受度和生成角色所引发的同理心方面的表现。

**Result:** 研究结果表明，该方法通过减少时间和精力来提高效率，并提升了原型角色在后续发现阶段（如最小可行产品范围界定和功能细化）中的质量和可重用性。尽管用户接受度普遍较高，尤其是在感知有用性和易用性方面，但参与者也指出了在泛化和领域特异性方面的局限性。此外，虽然认知同理心得到了强力支持，但情感和行为同理心在参与者之间差异显著。

**Conclusion:** 这些结果为生成式AI如何有效整合到软件产品发现实践中提供了新颖的实证证据，同时也指出了未来此类混合设计过程中需要解决的关键挑战。

> **ai_Abstract:** 本研究提出了一种利用提示工程和生成式AI来自动化创建原型角色的方法，以解决手动创建过程中的耗时、高认知负荷和偏见问题。通过一项包含19名参与者的真实案例研究，该方法被评估了其效率、有效性、用户接受度和所引发的同理心。结果表明，该方法显著提高了原型角色创建的效率和质量，并获得了较高的用户接受度。然而，研究也发现该方法在泛化能力、领域特异性以及情感和行为同理心的支持方面存在局限性。该研究为将生成式AI整合到软件产品发现实践提供了实证依据，并指出了未来改进的方向。

> **摘要翻译:** 原型角色在产品发现的早期阶段，如精益启动中，被普遍用于指导产品定义和利益相关者对齐。然而，手动创建原型角色通常耗时、认知负担重且容易产生偏见。在本文中，我们提出并实证研究了一种基于提示工程的方法，以在生成式AI（GenAI）的支持下生成原型角色。我们的目标是评估该方法在效率、有效性、用户接受度以及生成角色所引发的同理心方面的表现。我们进行了一项案例研究，有19名参与者参与，他们嵌入在一个真实的精益启动流程中，采用了定性和定量相结合的研究方法设计。结果显示，该方法通过减少时间和精力，提高了效率，并改善了原型角色在后续发现阶段（如最小可行产品（MVP）范围界定和功能细化）的质量和可重用性。尽管接受度普遍较高，尤其是在感知有用性和易用性方面，但参与者也指出了与泛化和领域特异性相关的局限性。此外，虽然认知同理心得到了强力支持，但情感和行为同理心在参与者之间差异显著。这些结果为GenAI如何有效整合到软件产品发现实践中提供了新颖的实证证据，同时也指出了未来此类混合设计过程中需要解决的关键挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [173] [NL in the Middle: Code Translation with LLMs and Intermediate Representations](https://arxiv.org/abs/2507.08627)
> *NL在中间：使用LLM和中间表示进行代码翻译*

*Chi-en Amy Tai, Pengyu Nie, Lukasz Golab, Alexander Wong* | **Category: cs.SE** | **Updated: 2025-07-11**

**Keywords:** 代码翻译, 大型语言模型, 中间表示, 提示工程, 链式思考

**Comment:** 

> **TL;DR:** 本研究探索了使用中间表示（如自然语言摘要）来改进大型语言模型（LLM）的代码翻译准确性，发现结合链式思考（CoT）和自然语言摘要的提示工程策略能显著提高翻译成功率。

**AI_Comments:** 这篇论文的创新点在于系统性地探索了中间表示（特别是自然语言摘要）在LLM代码翻译中的作用，并结合了不同的提示工程策略。它强调了提示工程对LLM性能的关键影响，并提供了一个明确的、量化的证据，证明了CoT与NL摘要结合的有效性。这对于提高LLM在代码相关任务中的实用性具有重要意义，也为未来的研究指明了方向，即如何通过更精细的中间步骤来指导LLMs。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的代码翻译存在错误，研究旨在探索通过引入中间表示来提高翻译准确性。

**Method:** 研究探讨了自然语言（NL）和抽象语法树（ASTs）作为中间表示在LLM代码翻译中的应用。考虑了从单次提示到链式思考（CoT）等多种提示工程方法来整合这些表示。实验使用了Open Gpt4 8X7B以及专门的StarCoder和CodeGen模型，并在CodeNet和AVATAR代码翻译基准上进行了评估。

**Result:** 研究发现，结合中间自然语言（NL）摘要的链式思考（CoT）提示表现最佳。对于表现最好的模型（Open Gpt4 8X7B），相较于零样本提示，成功翻译率分别提高了13.8%和6.7%。

**Conclusion:** 通过引入中间自然语言摘要并结合链式思考的提示策略，可以显著提高大型语言模型进行代码翻译的准确性。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLMs）代码翻译中存在的错误问题，提出通过引入中间表示来提升翻译准确性。文章探索了自然语言（NL）和抽象语法树（ASTs）作为中间表示的效果，并评估了不同的提示工程策略。实验结果表明，在Open Gpt4 8X7B等模型上，采用链式思考（CoT）结合中间自然语言摘要的提示方法，相较于零样本提示，能够显著提高代码翻译的成功率，分别提升了13.8%和6.7%。

> **摘要翻译:** 研究表明，大型语言模型（LLMs）生成的代码翻译存在错误。提高翻译准确性的一种途径是通过中间表示，这可以提供结构化的见解来指导模型的理解。我们探索了使用LLM进行代码翻译是否可以受益于通过自然语言（NL）和抽象语法树（ASTs）等中间表示。由于提示工程极大地影响LLM的性能，我们考虑了几种整合这些表示的方法，从一次性提示到链式思考（CoT）提示。在流行的代码翻译基准（CodeNet和AVATAR）上，使用Open Gpt4 8X7B以及专门的StarCoder和CodeGen模型，我们发现，结合中间NL摘要的CoT表现最佳，对于表现最好的模型（Open Gpt4 8X7B），相较于零样本提示，成功翻译率分别提高了13.8%和6.7%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [200] [LLMCup: Ranking-Enhanced Comment Updating with LLMs](https://arxiv.org/abs/2507.08671)
> *LLMCup：基于LLM的排序增强评论更新*

*Hua Ge, Juan Zhai, Minxue Pan, Fusen He, Ziyue Tan* | **Category: cs.SE, D.2.3; D.2.7; I.2.6** | **Updated: 2025-07-11**

**Keywords:** 代码注释更新, 大型语言模型, 排序模型, 软件维护, LLMCup

**Comment:** 13 pages, 10 figures

> **TL;DR:** LLMCup是一个使用大型语言模型（LLM）和排序模型（CupRank）来自动更新代码注释的框架，显著优于现有方法。

**AI_Comments:** LLMCup的创新点在于结合了LLM强大的文本生成能力和专门的排序模型，有效解决了LLM在特定任务中提示策略选择的挑战。通过生成多样化候选并进行筛选，显著提升了注释更新的准确性和质量。用户研究结果尤其引人注目，表明了LLMCup在实际应用中的巨大潜力，同时也强调了人工评估在AI生成内容质量评估中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 代码注释对于代码可读性和可维护性至关重要，但开发者常更新代码而忽略注释，导致注释过时或不一致。现有自动注释更新方法（如CUP和HebCup）存在信息遗漏、误解和难以处理复杂更新场景的问题，急需更有效的方法。

**Method:** 本文提出了LLMCup框架，该框架首先利用大型语言模型（LLM）通过多种提示策略生成多样化的候选更新注释，然后采用一个名为CupRank的排序模型从这些候选注释中选出最佳的作为最终更新注释。

**Result:** 实验结果显示，LLMCup在准确率上比现有SOTA基线（CUP和HebCup）提高了49.0%-116.9%，BLEU-4提高了10.8%-20%，METEOR提高了4.6%，F1提高了0.9%-1.9%，SentenceBert相似度提高了2.1%-3.4%。此外，用户研究表明LLMCup更新的注释有时优于人工更新。

**Conclusion:** LLMCup通过结合LLM的多样化生成能力和排序模型的筛选能力，显著提升了代码注释自动更新的性能，甚至在某些情况下超越了人工更新的质量，强调了在注释质量评估中纳入人工评估的重要性。

> **ai_Abstract:** 本文提出了一种名为LLMCup的新型代码注释自动更新框架，旨在解决现有方法在处理过时注释和复杂更新场景时的不足。LLMCup利用大型语言模型（LLMs）通过多种提示策略生成多样化的候选注释，并结合一个名为CupRank的排序模型来选择最佳更新。实验结果表明，LLMCup在多项指标上显著优于现有最先进的基线方法，并且用户研究显示其更新质量有时甚至超越了人工更新。

> **摘要翻译:** 尽管注释对于增强现代软件项目中的代码可读性和可维护性至关重要，但开发人员通常倾向于更新代码而非注释，这导致文档过时或不一致，从而阻碍未来的理解和维护。最近的方法，如CUP和HebCup，分别尝试使用神经网络序列到序列模型和启发式规则进行自动注释更新。然而，这些方法在注释更新过程中可能会遗漏或误解关键信息，导致不准确的注释，并且它们通常难以处理复杂的更新场景。鉴于这些挑战，一个有前景的方向是利用大型语言模型（LLMs），它们在注释生成、代码合成和程序修复等软件工程任务中表现出色。这表明它们在捕获代码修改背后的逻辑方面具有强大潜力——这项能力对于注释更新任务至关重要。然而，针对每个更新案例为LLM选择合适的提示策略仍然具有挑战性。为了解决这个问题，我们提出了一种新颖的注释更新框架LLMCup，它首先使用多种提示策略通过LLM提供多样化的候选更新注释，然后采用一个排序模型CupRank来选择最佳候选作为最终更新注释。实验结果证明了LLMCup的有效性，在准确率上比最先进的基线（CUP和HebCup）提高了49.0%-116.9%，在BLEU-4上提高了10.8%-20%，在METEOR上提高了4.6%，在F1上提高了0.9%-1.9%，在SentenceBert相似度上提高了2.1%-3.4%。此外，一项用户研究表明，LLMCup更新的注释有时甚至超越了人工编写的更新，这凸显了在注释质量评估中纳入人工评估的重要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [249] [Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning](https://arxiv.org/abs/2507.08730)
> *在线配置性能学习的双层分级漂移适应*

*Zezhen Xiang, Jingzhi Gong, Tao Chen* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 概念漂移, 在线学习, 配置性能, 双层适应, 软件系统

**Comment:** Accepted by ICSE 2026

> **TL;DR:** DHDA框架通过双层适应机制，有效处理在线配置性能学习中的概念漂移，显著提高准确性。

**AI_Comments:** DHDA的创新之处在于其双层分级适应机制，能够同时处理全局和局部概念漂移，这对于动态环境下的在线学习至关重要。结合增量更新和周期性再训练的设计，也体现了对效率和响应性的兼顾。该方法对于提升可配置软件系统在实际应用中的性能预测准确性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代可配置软件系统在动态环境下，工作负载变化、硬件更改和系统更新会引入不同层级的概念漂移（全局和局部），导致现有离线和迁移学习方法难以实时适应，使得配置性能学习面临挑战。

**Method:** 提出DHDA框架，通过双层分级适应来捕获和适应不同层级的漂移。上层在必要时重新划分数据并重新训练局部模型以处理全局漂移；下层局部模型异步检测和适应局部漂移。结合增量更新和周期性完全再训练，平衡响应性和效率，减少无漂移时的冗余计算。

**Result:** 在八个软件系统上进行评估，DHDA比现有最先进方法取得了显著更高的准确性，适应漂移的性能提升高达2倍，同时开销合理，并能改善不同局部模型处理概念漂移的能力。

**Conclusion:** DHDA是一种有效的在线配置性能学习框架，能够通过其双层分级适应机制成功应对概念漂移，显著提高预测准确性。

> **ai_Abstract:** 本文提出了DHDA，一个在线配置性能学习框架，旨在解决动态环境中由于工作负载、硬件和系统更新导致的概念漂移问题。DHDA采用双层分级适应机制，在上层处理全局漂移，在下层异步处理局部漂移，并通过结合增量更新和周期性再训练来平衡效率。实验证明，DHDA在准确性上显著优于现有方法，并能有效适应漂移，同时保持合理开销。

> **摘要翻译:** 现代可配置软件系统需要学习关联配置和性能的模型。然而，当系统在动态环境中运行时，工作负载变化、硬件更改和系统更新将不可避免地引入不同层级的概念漂移——全局漂移，它们重塑了整个配置空间的性能格局；以及局部漂移，它们只影响该空间中的某些子区域。因此，现有的离线和迁移学习方法难以实时适应这些隐式和不可预测的变化，使得配置性能学习具有挑战性。为了解决这个问题，我们提出了DHDA，一个在线配置性能学习框架，旨在捕获和适应这些不同层级的漂移。其核心思想是DHDA通过双层分级适应来适应局部和全局漂移：在上层，我们重新将数据划分为不同的分区，在每个分区内重新训练局部模型，仅在必要时处理全局漂移。在下层，分区的局部模型可以检测局部漂移并异步地适应自身。为了平衡响应性和效率，DHDA将增量更新与周期性完全再训练相结合，以在未检测到漂移时最小化冗余计算。通过评估八个软件系统并与现有最先进方法进行比较，我们表明DHDA实现了显著更高的准确性，并且能够有效适应漂移，性能提升高达2倍，同时产生合理的开销，并能够改善不同的局部模型在处理概念漂移方面的能力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [596] [The State of Computational Science in Fission and Fusion Energy](https://arxiv.org/abs/2507.08061)
> *裂变与聚变能中的计算科学现状*

*Andrea Morales Coto, Aditi Verma* | **Category: cs.SE, physics.soc-ph** | **Updated: 2025-07-10**

**Keywords:** 计算科学,裂变能,聚变能,核工程,软件工具

**Comment:** 

> **TL;DR:** 该调查显示，在裂变和聚变能源工程领域，计算科学正在朝着更现代化的工具和方法发展，例如更倾向于使用Python和C++等现代编程语言、开源代码和模块化软件，并朝着多物理场耦合的代码发展。

**AI_Comments:** 该研究通过对计算科学家的调查，为理解核工程领域软件工具的演变提供了宝贵的见解。然而，样本主要来自美国国家实验室和大学，可能无法完全代表全球范围内的趋势。此外，调查方法和具体问题细节的缺失也限制了对结果的深入解读。

<details>
  <summary>Details</summary>

**Motivation:** 随着软件在聚变和裂变能源工程中的主导地位日益增强，了解开发这些软件的计算科学家的观点变得至关重要，以预测该领域的未来发展趋势。

**Method:** 通过对103位从事聚变和裂变能源代码开发的计算科学家进行调查，了解他们正在解决的问题、可用的工具以及他们的开发体验。

**Result:** 调查结果显示，计算科学家越来越倾向于使用现代编程语言（如Python和C++）、开源代码和模块化软件，并且对多物理场耦合代码的需求不断增长。FORTRAN的使用率下降，代码开发预算显著增加。

**Conclusion:** 未来的核工程代码将更加模块化、计算量更小，并且在组织中受到越来越高的重视，预示着核工程领域计算科学的重大转变。

> **ai_Abstract:** 这项研究调查了103位计算科学家在裂变和聚变能源工程中使用的软件工具和开发体验。结果表明，该领域正朝着使用现代编程语言（如Python和C++）、开源代码和模块化软件以及多物理场耦合代码的方向发展，预示着核工程领域未来的重大转变。

> **摘要翻译:** 工程工具与被工程化的事物同等重要，在许多情况下，工具甚至决定了工程的可行性。在聚变和裂变能源工程中，软件已成为设计的主导工具。因此，在2024年，我们首次对103位开发聚变和裂变能源相关代码的计算科学家进行了调查，了解他们试图用代码解决的问题、可用的工具以及他们对这些工具的端到端开发体验。

调查结果揭示了聚变和裂变能源领域软件工具的变化趋势，越来越多的计算科学家倾向于使用现代编程语言、开源代码和模块化软件。这些趋势预示着核工程领域未来5到10年的发展方向。由于我们的受访者大多来自美国国家实验室和大学，这些结果暗示了行业中最前沿的趋势。本报告《裂变与聚变能中的计算科学现状》中的见解表明，人们对多物理场耦合代码的关注度急剧增加，FORTRAN的使用率下降，取而代之的是Python和C++等更现代的语言，同时代码开发的预算不断攀升，单个组织的预算有时高达5000万美元。

我们的调查描绘了核工程代码的未来图景：高度模块化、计算量小，并且日益受到组织的重视。调查结果可通过在线网页查阅。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [38] [Analysis of Propaganda in Tweets From Politically Biased Sources](https://arxiv.org/abs/2507.08169)
> *政治偏见来源推文中宣传的分析*

*Vivek Sharma, Mohammad Mahdi Shokri, Sarah Ita Levitan, Elena Filatova, Shweta Jain* | **Category: cs.SI** | **Updated: 2025-07-10**

**Keywords:** 宣传, 媒体偏见, 记者, 推特, 大型语言模型

**Comment:** The International FLAIRS Conference Proceedings, 38(1).
  https://doi.org/10.32473/flairs.38.1.138706

> **TL;DR:** 该研究分析了政治偏见新闻机构记者在推文中传播宣传的作用，引入了JMBX数据集，并发现极端偏见的记者更倾向于使用宣传语言。此外，研究比较了LLM在宣传检测方面的表现，指出LLM优于BERT模型，但成本和环境影响显著。

**AI_Comments:** 该论文的创新之处在于创建了一个专门用于分析社交媒体上新闻记者宣传行为的数据集（JMBX），并对大型语言模型在该任务中的应用进行了比较分析，同时关注了常被忽视的成本和环境影响。这突出了采纳先进人工智能模型时的权衡。其重要性在于揭示了媒体偏见的传播机制以及部署人工智能的实际考量。

<details>
  <summary>Details</summary>

**Motivation:** 新闻机构普遍存在政治偏见，记者在传播这些偏见方面发挥着重要作用。本研究旨在分析与流行新闻机构相关的记者在使用宣传式语言传播其偏见中的作用。

**Method:** 本研究提出了一种分析记者传播偏见的方法。引入了JMBX数据集，该数据集系统地收集并标注了来自Twitter（现称X）的1874条推文，这些推文由来自10家政治偏见范围从极左到极右的新闻机构的知名记者撰写。研究从数据中提取见解，并比较了OpenAI和谷歌的八种不同大型语言模型（LLM）与一个为宣传检测微调的基于BERT的模型在社交媒体和新闻文章中的宣传检测性能。此外，研究还分析了基于代币使用的财务成本和利用碳排放估算工具的环境影响。

**Result:** 研究发现，与政治倾向温和的机构相关的记者相比，与具有极端偏见的机构相关的记者更有可能在其写作中使用宣传式语言。大型语言模型（LLM）在检测社交媒体和新闻文章中的宣传方面通常比为宣传检测微调的基于BERT的模型表现更好。然而，使用大型语言模型（LLM）的性能提升伴随着显著的经济和环境成本。

**Conclusion:** 与具有极端偏见的新闻机构相关的记者更倾向于在其推文中传播宣传式语言。尽管大型语言模型在宣传检测方面表现优异，但其显著的财务和环境成本是需要考虑的重要因素。

> **ai_Abstract:** 本研究调查了政治偏见新闻机构的记者如何通过Twitter（X）上的宣传式语言传播其偏见。论文引入了JMBX数据集，该数据集包含来自10家不同政治偏见新闻机构的1874条推文。研究发现，来自极端偏见机构的记者更可能使用宣传语言。此外，论文比较了8种大型语言模型在宣传检测方面的性能，结果显示它们优于基于BERT的模型，但也伴随着显著的经济和环境成本，对此也进行了分析。

> **摘要翻译:** 众所周知，新闻机构具有政治联系，许多国家级机构为了迎合不同受众而培养政治偏见。为这些新闻机构工作的记者对他们报道的故事有很大影响。在这项工作中，我们提出了一种方法来分析与流行新闻机构相关的记者在使用某种形式的宣传式语言传播其偏见中的作用。我们引入了JMBX（记者媒体偏见在X上），这是一个系统收集和标注的数据集，包含来自Twitter（现在称为X）的1874条推文。这些推文由来自10家新闻机构的知名记者撰写，这些机构的政治偏见范围从极左到极右。我们从数据中提取了一些见解，并得出结论：与政治倾向温和的机构相关的记者相比，与具有极端偏见的机构相关的记者更有可能在其写作中使用宣传式语言。我们比较了OpenAI和谷歌的八种不同大型语言模型（LLM）。我们发现，与为宣传检测而微调的基于BERT的模型相比，LLM在检测社交媒体和新闻文章中的宣传方面通常表现更好。虽然使用大型语言模型（LLM）的性能提升显著，但它们带来了显著的经济和环境成本。本研究根据代币使用量分析了财务成本，并利用估计与LLM操作相关的碳排放的工具分析了环境影响。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [65] [Addressing overlapping communities in multiple-source detection: An edge clustering approach for complex networks](https://arxiv.org/abs/2507.08265)
> *解决多源检测中的重叠社区：一种复杂网络的边聚类方法*

*Haomin Li, Daniel K. Sewell* | **Category: cs.SI, stat.CO** | **Updated: 2025-07-11**

**Keywords:** 多源检测, 边聚类, 复杂网络, 重叠社区, 标签传播

**Comment:** 

> **TL;DR:** 本研究提出了一种将边聚类算法集成到基于社区的标签传播框架中的方法，以解决多源检测问题，特别是在节点属于多个社区的场景下。该方法在模拟研究中表现出优于现有技术的准确性。

**AI_Comments:** 该论文的创新点在于将边聚类算法引入多源检测问题，并结合标签传播框架，有效解决了传统方法难以处理的重叠社区和混合成员问题。这种方法对于理解和应对现实世界中复杂的扩散过程（如疾病传播、信息扩散）具有重要意义，提供了一种更精确、更鲁棒的工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的网络源检测方法通常只关注单一来源，而现实世界中的场景往往涉及多个来源，这使得检测工作变得复杂。本研究旨在解决多源检测（MSD）问题，特别是处理节点属于多个社区的混合成员问题。

**Method:** 本研究通过将边聚类算法集成到基于社区的标签传播框架中来解决多源检测（MSD）问题。具体而言，该方法将自动化潜在空间边聚类模型应用于网络，将受感染网络划分为基于边的簇，以识别多个来源。

**Result:** 在ADD HEALTH社交网络数据集上的模拟研究表明，该方法在F1-Measure方面取得了优于现有聚类算法的准确性。结果突出显示了边聚类在准确检测来源方面的鲁棒性，尤其是在具有复杂和重叠源区域的网络中。

**Conclusion:** 这项工作推动了基于聚类的方法在多源检测问题上的适用性，为现实世界中的网络分析提供了更高的准确性和适应性。

> **ai_Abstract:** 本研究提出了一种新的多源检测（MSD）方法，通过将自动化潜在空间边聚类模型整合到基于社区的标签传播框架中，有效处理了网络中节点多重归属和重叠社区的问题。该方法在模拟实验中，特别是针对ADD HEALTH社交网络数据集，在F1-Measure上展现出优于现有最先进聚类算法的准确性和鲁棒性，尤其适用于检测复杂和重叠源区域的网络。这项工作提升了聚类方法在多源检测领域的应用能力，增强了其在实际网络分析中的准确性和适应性。

> **摘要翻译:** 网络分析中的源检测问题涉及识别传播过程的起源，例如疾病爆发或错误信息传播。传统方法通常侧重于单一来源，而现实世界中的场景通常涉及多个来源，这使得检测工作变得复杂。本研究通过将边聚类算法集成到基于社区的标签传播框架中来解决多源检测（MSD）问题，有效处理了节点属于多个社区的混合成员问题。

所提出的方法将自动化潜在空间边聚类模型应用于网络，将受感染网络划分为基于边的簇以识别多个来源。在ADD HEALTH社交网络数据集上的模拟研究表明，该方法在F1-Measure方面取得了优于现有聚类算法的准确性。结果突出显示了边聚类在准确检测来源方面的鲁棒性，尤其是在具有复杂和重叠源区域的网络中。这项工作推动了基于聚类的方法在多源检测问题上的适用性，为现实世界中的网络分析提供了更高的准确性和适应性。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [93] [Uncovering High-Order Cohesive Structures: Efficient (k,g)-Core Computation and Decomposition for Large Hypergraphs](https://arxiv.org/abs/2507.08328)
> *揭示高阶内聚结构：用于大型超图的高效(k,g)-核计算与分解*

*Dahee Kim, Hyewon Kim, Song Kim, Minseok Kim, Junghoon Kim, Yeon-Chang Lee, Sungsu Lim* | **Category: cs.SI** | **Updated: 2025-07-11**

**Keywords:** 超图, 内聚结构, (k,g)-核, 索引结构, 在线分析

**Comment:** 14 pages, 16 figures

> **TL;DR:** 本文提出了一种高效的索引结构，用于在线发现大型超图中的高阶内聚子图，避免了详尽的图遍历。

**AI_Comments:** 这篇论文通过引入一个高效的索引结构来解决大型超图中高阶内聚子图的在线发现问题，具有重要的创新性。它解决了传统方法中参数选择困难和计算效率低下的痛点，通过避免详尽遍历提升了性能，对于需要实时分析复杂网络的应用具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代网络中超图建模复杂关系日益增多，其中内聚子图发现是基础问题之一，并为这些结构提供了深刻见解，然而选择适当参数的任务仍是一个开放性问题，且现有方法可能需要详尽的图遍历。

**Method:** 论文设计了一种高效的索引结构，用于在线检索内聚子图，其主要思想是在合理时间内发现相应的结构，而无需进行详尽的图遍历。

**Result:** 所提出的索引技术能够更快、更有效地检索内聚结构，支持需要对大规模超图进行在线分析的应用中的决策制定。在真实世界网络上的大量实验证明了该技术的优越性。

**Conclusion:** 本文成功设计并验证了一种高效的索引结构，解决了大型超图中高阶内聚子图发现的参数选择和在线检索效率问题，为在线分析大规模超图提供了有效的支持。

> **ai_Abstract:** 本文针对大型超图中高阶内聚子图发现的挑战，特别是参数选择和高效在线检索问题，提出了一种创新的高效索引结构。该方法旨在避免详尽的图遍历，从而在合理时间内实现内聚结构的快速有效检索。在真实世界网络上的广泛实验验证了该索引技术在支持大规模超图在线分析和决策制定方面的卓越性能。

> **摘要翻译:** 超图在现代网络中越来越多地用于建模复杂多样的关系，在表示复杂的更高阶交互方面获得了显著关注。在各种挑战中，内聚子图发现是基本问题之一，并为这些结构提供了深刻见解，然而选择适当参数的任务仍是一个开放性问题。为了解决这个问题，我们旨在设计一种高效的索引结构，以在线方式检索内聚子图。主要思想是能够在合理的时间内发现相应的结构，而无需详尽的图遍历。我们的方法能够更快、更有效地检索内聚结构，支持需要对大规模超图进行在线分析的应用中的决策制定。通过在真实世界网络上进行大量实验，我们证明了我们提出的索引技术的优越性。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [121] [Machine Learning for Evolutionary Graph Theory](https://arxiv.org/abs/2507.08363)
> *机器学习在演化图论中的应用*

*Guoli Yang, Matteo Cavaliere, Mingtao Zhang, Giovanni Masala, Adam Miles, Mengzhu Wang* | **Category: cs.SI** | **Updated: 2025-07-11**

**Keywords:** 机器学习, 演化图论, 合作崩溃, 欺骗者, 复杂网络

**Comment:** 

> **TL;DR:** 该论文结合演化图论和机器学习，通过检测“欺骗者”的传播来预测复杂网络中合作的崩溃。预测准确性受选择强度、观察窗口、博弈类型和社区结构的影响。

**AI_Comments:** 该论文的创新之处在于将机器学习方法引入到演化图论中，以预测社区合作的动态崩溃，这在理论应用上具有新颖性。其重要性在于为提前检测和预防社会网络中的不稳定性提供了潜在工具和策略。

<details>
  <summary>Details</summary>

**Motivation:** 社区的稳定性依赖于合作与欺骗的平衡。一个关键挑战是能否提前检测到合作崩溃的风险，尤其当欺骗者变得过于普遍时。

**Method:** 作者结合演化图论和机器学习，通过在结构化群体中引入少量欺骗者，利用机器学习模型（特别是CNN-Seq-LSTM和Seq-LSTM）和时间和结构数据来检测和预测欺骗者的传播及合作的崩溃。

**Result:** 预测准确性随着选择强度的增加和观察窗口的扩大而提高，其中CNN-Seq-LSTM和Seq-LSTM是表现最佳的模型。此外，预测的准确性关键取决于合作者和欺骗者之间博弈的类型（即，当背叛更有利时准确性提高）以及群体结构。

**Conclusion:** 这项工作将机器学习方法引入到演化图论中，用于检测突然转变，并为预测和预防复杂社会网络中的合作崩溃提供了潜在策略。

> **ai_Abstract:** 该论文将演化图论与机器学习相结合，旨在通过检测“欺骗者”的传播来预测复杂网络中合作的崩溃。通过引入少量欺骗者，研究利用机器学习模型（如CNN-Seq-LSTM和Seq-LSTM）分析时间和结构数据，以预测合作的瓦解。研究发现，预测准确性随选择强度和观察窗口的增加而提高，并受博弈类型和社区结构的关键影响。这项工作为检测突然转变和预防复杂社会网络中的合作崩溃提供了一种新颖的方法。

> **摘要翻译:** 无论是生物、社会、经济、技术还是生态群体的稳定性，都取决于合作与欺骗之间的平衡。合作能增强群体，而自私的个体，即“欺骗者”，则在不贡献的情况下利用集体利益。如果欺骗者变得过于普遍，他们可能会引发合作和群体的崩溃，这通常是突然发生的。一个关键挑战是确定这种崩溃的风险是否可以提前检测到。为了解决这个问题，我们结合演化图论和机器学习来研究如何预测复杂网络中合作的瓦解。通过在结构化群体中引入少量欺骗者，我们利用机器学习来检测和预测欺骗者的传播以及合作的崩溃。利用时间和结构数据，结果表明预测准确性随着选择强度增加和观察窗口扩大而提高，其中CNN-Seq-LSTM和Seq-LSTM是表现最佳的模型。此外，预测的准确性关键取决于合作者和欺骗者之间博弈的类型（即，当背叛更有利时准确性提高）以及群体结构。总的来说，这项工作将机器学习方法引入到演化图论中检测突然转变，并为预测和预防复杂社会网络中的合作崩溃提供了潜在策略。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [177] [Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms](https://arxiv.org/abs/2301.07791)
> *金融网络中的时间模式：对Mercari、JPMC和Venmo平台的研究*

*Penghang Liu, Bahadir Altun, Rupam Acharyya, Robert E. Tillman, Shunya Kimura, Naoki Masuda, Ahmet Erdem Sarıyüce* | **Category: cs.SI, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 时间模式, 金融网络, 欺诈检测, 网络分析, 交易动态

**Comment:** To appear at ASONAM 2025

> **TL;DR:** 本文研究了金融网络（Mercari、JPMC、Venmo）中的时间模式在欺诈检测和理解社会/金融互动方面的应用，并展示了其优于基线的性能。

**AI_Comments:** 这篇论文创新性地将时间模式（捕获有序和重复的交互）应用于多样化的真实世界金融网络。其优势在于证明了时间模式在欺诈检测和社交关系分析等关键任务上，相对于已建立的基线方法具有实际的优越性，同时考虑了计算效率。使用多个不同的数据集（在线市场、合成银行数据、社交支付平台）增强了研究结果的普适性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 理解人与人之间金融交易的动态对于欺诈检测等多种应用至关重要。金融交易网络的时间性以及交易在图结构中的顺序和重复可以提供新的见解。时间模式被认为是解决此问题的有前景的工具。

**Method:** 本研究利用时间模式分析了Mercari（在线市场交易）、J.P. Morgan Chase（合成支付网络）和Venmo（支付和友谊）三个独特的金融网络。在Mercari和J.P. Morgan Chase网络上，利用真实标签解决了欺诈检测问题，并将时间模式与简单图特征、LINE和node2vec等基线方法进行比较。对于Venmo网络，则研究了金融和社会关系在友谊预测、供应商识别和时间周期分析三个任务上的相互作用，并将时间模式与Jaccard和Adamic-Adar等启发式方法进行比较。

**Result:** 在Mercari和J.P. Morgan Chase网络上，时间模式在欺诈检测方面表现出优于多种基线方法的性能，并且在运行时方面具有实用性。对于Venmo网络，时间模式在友谊预测方面比一般的启发式方法（如Jaccard和Adamic-Adar）取得了更好的结果。此外，还高精度地识别了供应商，并在稀有模式（如时间周期）中观察到有趣的模式。

**Conclusion:** 本研究的分析、数据集和经验教训将有益于未来对金融交易网络的研究。

> **ai_Abstract:** 本文探讨了时间模式在分析Mercari、J.P. Morgan Chase和Venmo三个不同金融网络动态中的应用。研究表明，时间模式在Mercari和JPMC的欺诈检测任务中表现优异，超越了传统的图特征和节点嵌入技术。此外，在Venmo网络中，时间模式有效揭示了金融-社会关系之间的相互作用，改进了友谊预测和供应商识别，并发现了时间周期中的有趣模式。这项研究强调了时间模式在未来金融网络研究中的实用性和分析能力。

> **摘要翻译:** 理解人与人之间金融交易的动态对于欺诈检测等各种应用至关重要。金融交易网络的一个重要方面是时间性。当在图结构中考虑时，交易的顺序和重复可以提供新的见解。时间模式，定义为在短时间内相互作用的一组节点，是这方面一个有前景的工具。在这项工作中，我们研究了三个独特的临时金融网络：在线市场Mercari中的交易、J.P. Morgan Chase生成的合成网络中的支付，以及Venmo用户之间的支付和友谊。我们考虑了Mercari和J.P. Morgan Chase网络上的欺诈检测问题，这些网络具有真实标签。我们表明，时间模式在运行时性能方面实用，并且比包括考虑简单图特征的先前方法和两种节点嵌入技术（LINE和node2vec）在内的几种基线表现出更优越的性能。对于Venmo网络，我们调查了金融和社会关系在三个任务上的相互作用：友谊预测、供应商识别和时间周期的分析。对于友谊预测，时间模式比一般启发式方法（如Jaccard和Adamic-Adar度量）产生了更好的结果。我们还能够高精度地识别供应商，并观察到稀有模式（如时间周期）中有趣的模式。我们相信这项工作的分析、数据集和经验教训将有益于未来对金融交易网络的研究。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [210] [Signed Diverse Multiplex Networks: Clustering and Inference](https://arxiv.org/abs/2402.10242)
> *符号化多样多层网络：聚类与推断*

*Marianna Pensky* | **Category: cs.SI, cs.LG, stat.ME** | **Updated: 2025-07-10**

**Keywords:** 符号网络, 多层网络, 广义随机点积图, 聚类, 子空间估计

**Comment:** 5 figures

> **TL;DR:** 本文引入了符号化广义随机点积图（SGRDPG）模型及其多层版本，用于网络聚类和推断，并通过保留边的符号显著提高精度。

**AI_Comments:** 本文的创新点在于引入了SGRDPG模型，将边的符号信息纳入网络结构中，并将其扩展到灵活的多层网络框架。这不仅增强了模型对复杂网络（如具有正负交互的脑网络）的建模能力，而且通过实证和理论证明了保留符号信息对提高聚类和估计精度的显著益处，为多层网络分析提供了重要的理论和方法改进。

<details>
  <summary>Details</summary>

**Motivation:** 现有广义随机点积图（GRDPG）模型未考虑边的符号信息，且需要一个更灵活的多层网络模型来处理具有正负边的复杂网络结构。本研究旨在通过引入新模型并采用新颖方法，改进现有技术在多层网络聚类和子空间估计方面的精度和一致性。

**Method:** 本文引入了符号化广义随机点积图（SGRDPG）模型，该模型是广义随机点积图（GRDPG）的变体，增加了边的正负性。进一步将该模型扩展到多层网络版本，其中所有层共享相同的节点集合并遵循SGRDPG，同时层的唯一共同特征是它们可以被划分为具有共同子空间结构的组。文章采用了新颖的方法来确保层的强一致性聚类和高精度子空间估计。

**Result:** 实现了层的强一致性聚类和高精度子空间估计，显著优于Pensky和Wang (2024) 的结果。所有算法和理论结果对符号网络和二元网络均适用。此外，研究表明在网络构建过程中保留边的符号能够提高估计和聚类的精度。

**Conclusion:** 保留网络边的符号对于提高估计和聚类的精度至关重要，这使得SGRDPG模型及其多层版本在处理如脑网络等实际问题时具有显著优势。

> **ai_Abstract:** 本文提出了一种新颖的符号化广义随机点积图（SGRDPG）模型及其多层扩展，该模型允许网络边带有正负号，并能灵活地表示具有共同子空间结构的多层网络。通过采用创新方法，该研究实现了层级的强一致性聚类和高精度的子空间估计，显著超越了现有技术。研究还强调了在网络分析中保留边符号的重要性，因为它能有效提升估计和聚类精度，对处理实际应用如脑网络分析具有重要意义。

> **摘要翻译:** 本文引入了一种符号化广义随机点积图（SGRDPG）模型，它是广义随机点积图（GRDPG）的变体，其中边可以是正的或负的。该设置被扩展到多层版本，其中所有层具有相同的节点集合并遵循SGRDPG。网络层的唯一共同特征是它们可以被划分为具有共同子空间结构的组，而连接概率矩阵可以完全不同。上述设置极其灵活，并包含各种现有多层网络模型，包括GRDPG，作为其特例。通过采用新颖的方法，我们的论文确保了层的强一致性聚类和高精度子空间估计，这比Pensky和Wang (2024) 的结果有了显著改进。论文中的所有算法和理论结果对符号网络和二元网络都保持真实。此外，论文表明在网络构建过程中保留边的符号可以提高估计和聚类的精度，因此有利于解决诸如脑网络分析等现实世界问题。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [254] [Incivility and Contentiousness Spillover in Public Engagement with Public Health and Climate Science](https://arxiv.org/abs/2502.05255)
> *不文明和争议在公众参与公共卫生和气候科学中的溢出效应*

*Hasti Narimanzadeh, Arash Badie-Modiri, Iuliia Smirnova, Ted Hsuan Yun Chen* | **Category: cs.SI, cs.CY, physics.soc-ph** | **Updated: 2025-07-10**

**Keywords:** 情感两极分化, 不文明, 溢出效应, 公众参与, 气候科学

**Comment:** 33 pages, 6 figures

> **TL;DR:** 研究表明，新冠疫情相关的不文明和争议在社交媒体上溢出到气候变化讨论中，由既有的政治分歧驱动，从而加剧了科学政策领域的情感两极分化。

**AI_Comments:** 这篇论文为政治两极分化如何污染看似不同的科学领域的公共讨论提供了重要见解，特别强调了社交媒体的作用。它以COVID-19大流行作为催化剂，揭示了连接不同科学政策问题的潜在政治分歧，这一点具有创新性。研究结果强调了在两极分化的环境中促进建设性公众参与科学的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 旨在研究情感两极分化和政治分化如何驱动科学与政策交叉领域问题的公众对立，特别是在COVID-19期间，研究不文明和争议在Twitter和Reddit上公共卫生和气候变化公共参与中的跨领域溢出效应。

**Method:** 在COVID-19期间，通过分析Twitter和Reddit上公众参与气候变化和公共卫生讨论中的不文明和争议的跨领域溢出效应。

**Result:** 发现围绕COVID-19的情感两极化特征强烈溢出到气候变化领域；在不同社交媒体系统中，COVID-19内容与气候讨论中的不文明和争议相关；这些对抗增加的模式对使科学与公共政策联系更加突出的疫情事件作出反应；观察到的溢出效应沿着疫情前政治分歧（特别是反国际主义民粹主义信仰）激活，将气候政策反对与疫苗犹豫联系起来。

**Conclusion:** 情感两极分化在公众参与科学的过程中如何在不同的科学政策领域中根深蒂固。

> **ai_Abstract:** 本文研究了由情感两极分化引起的不文明和争议如何在社交媒体（Twitter和Reddit）上从公共卫生（COVID-19）讨论溢出到气候科学讨论中。研究发现，与COVID-19相关的对立情绪强烈渗透到气候讨论中，尤其是在突出的疫情事件期间。这种溢出是由疫情前已存在的政治分歧驱动的，将反国际主义民粹主义信仰与气候政策反对和疫苗犹豫联系起来，表明情感两极分化在科学政策领域中根深蒂固。

> **摘要翻译:** 情感两极分化和政治分化驱动着科学与政策交叉领域问题的公众对立。着眼于COVID-19时期，我们研究了Twitter和Reddit上公众参与气候变化和公共卫生讨论中不文明和争议的跨领域溢出效应。我们发现围绕COVID-19的情感两极化特征强烈溢出到气候变化领域。在不同的社交媒体系统中，COVID-19内容与气候讨论中的不文明和争议相关。这些对抗增加的模式对使科学与公共政策联系更加突出的疫情事件作出反应。观察到的溢出效应沿着疫情前政治分歧（特别是反国际主义民粹主义信仰）激活，这些分歧将气候政策反对与疫苗犹豫联系起来。我们的研究结果表明，情感两极分化在公众参与科学的过程中如何在不同的科学政策领域中根深蒂固。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [181] [Photonic Rails in ML Datacenters](https://arxiv.org/abs/2507.08119)
> *机器学习数据中心中的光子轨道*

*Eric Ding, Chuhan Ouyang, Rachee Singh* | **Category: cs.NI** | **Updated: 2025-07-10**

**Keywords:** 光子轨道, 机器学习数据中心, 光路交换机, 网络结构, 并行性

**Comment:** 

> **TL;DR:** 该论文提出在机器学习数据中心中，使用光路交换机而非电交换机来实现“光子轨道”，以降低功耗、成本和复杂性；并通过并行性驱动的轨道重配置来解决光交换机扇出受限的问题。

**AI_Comments:** 这项研究的创新点在于将光路交换机引入到机器学习数据中心的“轨道”网络中，以替代传统的电交换机，从而显著降低能耗和成本。其核心贡献在于提出了“并行性驱动的轨道重配置”机制和Opus控制平面，巧妙地解决了光交换机扇出能力不足的固有局限性。这代表了一种从静态网络配置向动态、与工作负载并行性共同演进的网络范式转变，对未来大规模ML训练基础设施的设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型机器学习训练中使用的轨道优化网络结构，依赖于高基数电交换机提供全对全连接，但这带来了巨大的功耗、成本和复杂性开销。

**Method:** 论文提出通过光路交换机实现轨道抽象，同时保留其通信语义。为解决光交换机一次只支持一对一连接的限制，引入了“并行性驱动的轨道重配置”方案，利用不同并行性流量之间的顺序性。设计了一个名为Opus的控制平面，以实现使用光交换机对电轨道交换机进行时分复用仿真。

**Result:** Not mentioned in abstract

**Conclusion:** 该论文提出了一种新的研究议程：数据中心网络结构应与每个作业内部的模型并行维度共同演进，而非在作业开始前进行网络重配置，通过使用光路交换机和并行性驱动的重配置来改进ML数据中心网络。

> **ai_Abstract:** 该论文提出了一种新的机器学习数据中心网络结构，旨在解决当前轨道优化网络中高基数电交换机带来的高功耗、成本和复杂性问题。通过将轨道抽象用光路交换机实现，并引入“并行性驱动的轨道重配置”和Opus控制平面，克服了光交换机一对一连接的限制，实现了电轨道交换机的时分复用仿真。这项工作倡导一种新的网络设计理念，即数据中心网络应与模型并行性动态协同演进。

> **摘要翻译:** 轨道优化的网络结构已成为大规模机器学习训练中事实上的数据中心横向扩展结构。然而，使用高基数电交换机在轨道中提供全对全连接带来了巨大的功耗、成本和复杂性开销。我们提出重新思考轨道抽象，保留其通信语义，但使用光路交换机来实现。关键挑战在于光交换机一次只支持一对一连接，限制了使用混合并行性的ML工作负载中的流量扇出。我们引入了并行性驱动的轨道重配置作为解决方案，它利用了来自不同并行性流量之间的顺序排序。我们设计了一个控制平面Opus，以实现使用光交换机对电轨道交换机进行时分复用仿真。更广泛地说，我们的工作讨论了一个新的研究议程：数据中心网络结构与每个作业内部的模型并行维度共同演进，而不是像当前主流思维那样在作业开始前重新配置网络。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [219] [Rattan: An Extensible and Scalable Modular Internet Path Emulator](https://arxiv.org/abs/2507.08134)
> *藤条：一个可扩展且可伸缩的模块化互联网路径模拟器*

*Minhu Wang, Yixin Shen, Bo Wang, Haixuan Tong, Yutong Xie, Yixuan Gao, Yan Liu, Li Chen, Mingwei Xu, Jianping Wu* | **Category: cs.NI** | **Updated: 2025-07-10**

**Keywords:** 网络路径模拟器, 可扩展性, 可伸缩性, 模块化, 单元格架构

**Comment:** 

> **TL;DR:** Rattan是一个新的、可扩展且可伸缩的软件网络路径模拟器，通过其基于单元的模块化架构解决了现有模拟器在灵活性、可伸缩性和可用性方面的不足。

**AI_Comments:** Rattan的创新点在于其独特的“单元格”模块化架构，这显著提高了网络路径模拟器的可扩展性和可伸缩性。通过将复杂功能分解为可重用和可组合的单元，它克服了传统模拟器的局限性，特别是在处理现代互联网的异构性和动态性方面。这对于网络协议开发和在线服务优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有互联网路径模拟器在灵活性、可伸缩性和可用性方面日益不足，无法应对互联网路径在异构性、规模和动态性方面的快速增长。

**Method:** 提出了Rattan，一个基于单元（cell-based）架构的软件网络路径模拟器。它将仿真功能分解为模块化的“单元”，这些单元具有异步接口，用户可以通过分层链接轻松组合不同单元，并通过标准单元接口构建新单元。

**Result:** Rattan的设计实现了：1) 可伸缩性，在单机上支持数百个并发的千兆级路径，并支持由多台机器组成的集群级实验；2) 可扩展性，通过构建新单元来模拟新的网络条件。

**Conclusion:** Rattan使开发人员和研究人员能够高效、自信地评估、验证和诊断在线服务的各种网络传输创新。

> **ai_Abstract:** Rattan是一个为解决现有互联网路径模拟器在灵活性、可伸缩性和可用性方面的不足而设计的软件网络路径模拟器。其核心是基于单元的模块化架构，允许用户通过组合或构建新单元来实现高度的可伸缩性和可扩展性，从而支持大规模并发路径仿真和新网络条件的模拟，助力网络传输创新的评估与验证。

> **摘要翻译:** 随着互联网路径在异构性、规模和动态性方面的快速增长，现有模拟器在灵活性、可伸缩性和可用性方面日益不足。为了解决这些限制，我们提出了Rattan，一个用于现代互联网条件的可扩展且可伸缩的软件网络路径模拟器。Rattan的核心创新在于其基于单元（cell-based）的架构：通过将仿真功能分解为具有良好文档记录的异步接口的模块化“单元”，用户可以通过分层链接轻松组合不同的单元，并通过使用标准单元接口轻松构建新单元。这种设计实现了：(1) 可伸缩性，在单机上支持数百个并发的千兆级路径，并支持由多台机器组成的集群级实验；(2) 可扩展性，通过构建新单元来模拟新的网络条件。Rattan使开发人员和研究人员能够高效、自信地评估、验证和诊断在线服务的各种网络传输创新。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [259] [KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence](https://arxiv.org/abs/2507.08164)
> *KP-A：一个统一的网络知识平面，用于催化代理网络智能*

*Yun Tang, Mengbang Zou, Zeinab Nezami, Syed Ali Raza Zaidi, Weisi Guo* | **Category: cs.NI, cs.AI, cs.SE** | **Updated: 2025-07-10**

**Keywords:** 网络知识平面, 代理网络智能, 6G网络, 知识解耦, 互操作性

**Comment:** 7 pages, 5 figures, submitted for possible publication

> **TL;DR:** 提出KP-A，一个统一的网络知识平面，通过解耦知识管理和智能逻辑，解决现有自治网络中知识检索的冗余和不一致问题，提升开发效率和互操作性。

**AI_Comments:** KP-A的创新点在于其统一的网络知识平面设计，它借鉴了Open-RAN的理念，成功地将知识管理与智能逻辑解耦，这对于构建高效、可互操作的自治网络至关重要。该方法有望解决当前多智能任务中知识碎片化和一致性差的问题，对于推动6G网络的智能化发展具有重要意义。开源其实现也利于社区协作和未来标准化。

<details>
  <summary>Details</summary>

**Motivation:** 当前自主6G网络中，独立的智能任务需要隔离的知识检索流程，导致数据流冗余和解释不一致。

**Method:** 提出KP-A，一个统一的网络知识平面，专门为代理网络智能设计。它通过将网络知识的获取和管理与智能逻辑解耦，并提供直观一致的知识接口。

**Result:** 在两个代表性智能任务中演示了KP-A：实时网络知识问答和边缘AI服务编排。所有实现工件已开源。

**Conclusion:** KP-A通过统一网络知识平面，有效解决了现有智能任务中知识检索的冗余和不一致问题，提高了开发效率、降低了维护复杂性，并增强了网络智能代理的互操作性。

> **ai_Abstract:** 本论文提出了KP-A，一个统一的网络知识平面，旨在解决当前自主6G网络中独立智能任务的知识检索管道导致的冗余和不一致问题。KP-A通过将网络知识的获取与管理从智能逻辑中解耦，并提供统一的知识接口，显著简化了开发流程，降低了维护成本，并提升了网络智能代理的互操作性。作者通过实时网络知识问答和边缘AI服务编排两个实例验证了KP-A的有效性，并开源了所有实现代码。

> **摘要翻译:** 大型语言模型（LLM）和代理系统的出现正在使自主6G网络具备高级智能，包括自配置、自优化和自修复。然而，当前单个智能任务的实现需要独立的知识检索管道，导致数据流冗余和解释不一致。受Open-RAN中服务模型统一工作的启发（为支持互操作性和供应商多样性），我们提出了KP-A：一个专门为代理网络智能设计的统一网络知识平面。通过将网络知识的获取和管理与智能逻辑解耦，KP-A简化了智能工程师的开发并降低了维护复杂性。通过提供直观一致的知识接口，KP-A还增强了网络智能代理的互操作性。我们在两个代表性智能任务中演示了KP-A：实时网络知识问答和边缘AI服务编排。所有实现工件都已开源，以支持可复现性和未来的标准化工作。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [299] [Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization](https://arxiv.org/abs/2507.08403)
> *迈向AI原生RAN：运营商视角下的6G Day 1标准化*

*Nan Li, Qi Sun, Lehan Wang, Xiaofei Xu, Jinri Huang, Chunhui Liu, Jing Gao, Yuhong Huang, Chih-Lin I* | **Category: cs.NI, cs.AI, cs.DC, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-11**

**Keywords:** AI原生RAN, 6G, 标准化, AI/ML, 无线接入网

**Comment:** 

> **TL;DR:** 本文从运营商角度探讨了6G AI原生无线接入网（RAN）的Day 1设计和标准化原则，提出了AI原生RAN的框架和关键能力，并通过大规模外场试验验证了其在改善网络性能方面的有效性。

**AI_Comments:** 本文的创新之处在于其从运营商的实际运营和标准化经验出发，前瞻性地提出了6G时代AI原生RAN的Day 1标准化框架。它不仅强调了AI在6G中的核心地位，更具体地阐述了AI原生RAN的关键能力和架构设想。通过大规模外场试验的验证，增强了其理论的实践可行性，对于推动6G标准化进程具有重要参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 与5G不同，6G移动网络将从一开始就原生集成人工智能/机器学习（AI/ML），以应对其复杂性并支持无处不在的AI应用。本文旨在探索AI原生RAN的设计和标准化原则，以提供6G AI原生RAN标准化设计的Day 1框架。

**Method:** 本文基于作者团队在2G到5G移动网络运营和标准化方面的经验，探索了6G AI原生RAN的设计和标准化原则。研究了AI原生RAN的框架，并提出了其三个基本能力：AI驱动的RAN处理/优化/自动化、可靠的AI生命周期管理（LCM）和AI即服务（AIaaS）供应。提出了AI原生6G RAN架构等Day 1特性，并通过一个拥有超过5000个5G-A基站的大规模外场试验进行了验证。

**Result:** 通过所提出的架构和支持的AI功能，一个拥有超过5000个5G-A基站的大规模外场试验，在平均空口延迟、根本原因识别和网络能耗方面取得了显著改进。

**Conclusion:** 本文旨在为6G AI原生RAN的标准化设计提供一个Day 1框架，平衡技术创新与实际部署。

> **ai_Abstract:** 本文从运营商视角探讨了6G AI原生无线接入网络（RAN）的Day 1设计和标准化原则。文章强调AI应从6G初期就原生集成，以应对网络复杂性并支持AI应用。作者团队基于丰富的运营经验，提出了AI原生RAN的框架及其三大核心能力：AI驱动的RAN处理/优化/自动化、可靠的AI生命周期管理以及AI即服务。通过大规模外场试验，验证了所提出的AI原生6G RAN架构及其AI功能在改善空口延迟、根本原因识别和网络能耗方面的显著效果。该研究旨在为6G AI原生RAN的标准化提供一个兼顾技术创新与实际部署的Day 1框架。

> **摘要翻译:** 人工智能/机器学习（AI/ML）已成为6G移动网络最确定和最突出的特征。与5G不同，5G中的AI/ML并非原生集成，而是现有架构的附加功能，而6G应从一开始就整合AI，以解决其复杂性并支持无处不在的AI应用。基于我们从2G到5G广泛的移动网络运营和标准化经验，本文探讨了6G AI原生无线接入网络（RAN）的设计和标准化原则，特别关注其关键的Day 1架构、功能和能力。我们研究了AI原生RAN的框架，并提出了其三个基本能力，以期为标准化方向提供一些启示：即AI驱动的RAN处理/优化/自动化、可靠的AI生命周期管理（LCM）和AI即服务（AIaaS）供应。提出了AI原生RAN的标准化，特别是Day 1功能，包括AI原生6G RAN架构。为了验证，一个拥有超过5000个5G-A基站的大规模外场试验已经建立，并通过所提出的架构和支持的AI功能，在平均空口延迟、根本原因识别和网络能耗方面取得了显著改进。本文旨在为6G AI原生RAN的标准化设计提供一个Day 1框架，平衡技术创新与实际部署。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [339] [Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method](https://arxiv.org/abs/2507.08429)
> *激光充电无人机辅助物联网网络中的信息年龄优化：一种多智能体深度强化学习方法*

*Geng Sun, Likun Zhang, Jiahui Li, Jing Wu, Jiacheng Wang, Zemin Sun, Changyuan Zhao, Victor C. M. Leung* | **Category: cs.NI** | **Updated: 2025-07-11**

**Keywords:** 信息年龄优化, 激光充电, 无人机, 物联网, 多智能体深度强化学习, MAPPO-TM

**Comment:** 21 pages, 8 figures

> **TL;DR:** 本文提出一种多智能体深度强化学习方法（MAPPO-TM），用于优化激光充电无人机辅助物联网网络中的信息年龄（AoI），实现更高效的数据收集和能量管理。

**AI_Comments:** 本文创新性地将激光无线充电技术与多智能体深度强化学习相结合，解决了无人机在物联网数据采集中面临的能量续航和信息新鲜度问题。通过引入时间记忆和多智能体协调机制，MAPPO-TM框架能够有效处理复杂的动态环境，并在实际应用中展现出显著的性能提升。该研究对于推动无人机辅助物联网网络的可持续发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无人机在物联网数据采集中具有潜力，但其有限的能量是主要挑战。激光束导向器（LBD）可为无人机无线充电，实现持续数据收集。本研究旨在优化激光充电无人机辅助物联网网络中的信息年龄（AoI），以克服无人机能量限制并提高数据收集效率。

**Method:** 本文将激光充电无人机辅助物联网网络中的信息年龄优化问题建模为一个联合优化问题，旨在最小化峰值AoI并确定最优无人机轨迹和激光充电策略。针对其非凸性、复杂时间依赖性等挑战，提出了一种新颖的多智能体近端策略优化框架，名为MAPPO-TM。该框架结合了时间记忆机制以捕捉无人机操作的动态性，并通过去中心化学习促进多无人机之间的有效协调，同时考虑全局系统目标。

**Result:** 仿真结果表明，所提出的MAPPO-TM算法在峰值AoI最小化和能量效率方面优于传统方法。与传统多智能体深度强化学习（MADRL）方法相比，该算法在峰值AoI方面实现了高达15.1%的降低。

**Conclusion:** 所提出的MAPPO-TM算法能有效优化激光充电无人机辅助物联网网络中的信息年龄和能量效率，显著降低峰值AoI。

> **ai_Abstract:** 本文研究了激光充电无人机辅助物联网网络中的信息年龄（AoI）优化问题，以解决无人机能量限制和提高数据收集效率。针对最小化峰值AoI以及优化无人机轨迹和激光充电策略的联合问题，提出了一种新颖的多智能体近端策略优化（MAPPO-TM）框架。该框架通过整合时间记忆机制和去中心化学习实现多无人机协调。仿真结果表明，MAPPO-TM在降低峰值AoI和提高能量效率方面优于现有方法，峰值AoI降低高达15.1%。

> **摘要翻译:** 无人机（UAV）与物联网（IoT）网络的集成提供了高效数据收集的有前景的解决方案。然而，无人机有限的能量容量仍然是一个重大挑战。在这种情况下，激光束导向器（LBD）已成为一种在操作过程中对无人机进行无线充电的有效技术，从而实现持续数据收集而无需频繁返回充电站（CS）。在这项工作中，我们研究了LBD供电的无人机辅助物联网网络中的信息年龄（AoI）优化问题，其中多架无人机从分布式物联网设备收集数据，同时被激光束充电。我们提出了一个联合优化问题，旨在最小化峰值AoI，同时确定最优无人机轨迹和激光充电策略。由于其非凸性、复杂的时间依赖性以及需要在数据收集效率和能耗限制之间取得平衡，该问题尤其具有挑战性。为了应对这些挑战，我们提出了一种新颖的、带有时间记忆和多智能体协调的多智能体近端策略优化（MAPPO-TM）框架。具体而言，MAPPO-TM结合了时间记忆机制以捕捉无人机操作的动态性，并通过去中心化学习促进多无人机之间的有效协调，同时考虑全局系统目标。仿真结果表明，所提出的MAPPO-TM算法在峰值AoI最小化和能量效率方面优于传统方法。理想情况下，与传统多智能体深度强化学习（MADRL）方法相比，所提出的算法在峰值AoI方面实现了高达15.1%的降低。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [369] [Recovery of UAV Swarm-enabled Collaborative Beamforming in Low-altitude Wireless Networks under Wind Field Disturbances](https://arxiv.org/abs/2507.08507)
> *低空无线网络中无人机群在风场扰动下使能的协同波束成形恢复*

*Geng Sun, Chenbang Liu, Jiahui Li, Guannan Qu, Shuang Liang, Jiacheng Wang, Changyuan Zhao, Dusit Niyato* | **Category: cs.NI** | **Updated: 2025-07-11**

**Keywords:** 无人机群,协同波束成形,低空无线网络,风场扰动,PPO-LA

**Comment:** 

> **TL;DR:** 该研究提出了一种基于PPO-LA算法的框架，用于在风场扰动下恢复低空无人机群协同波束成形的性能，通过自适应调整激励电流权重来最大化方向性和最小化旁瓣，并在仿真中证明了其有效性。

**AI_Comments:** 该研究有效地解决了无人机通信中的一个关键挑战，即风场扰动对协同波束成形性能的影响。提出的PPO-LA算法在处理时序动态和实现实时适应方面具有创新性，并且在仿真中表现出优越的性能。

<details>
  <summary>Details</summary>

**Motivation:** 风场扰动会降低无人机群协同波束成形的性能，需要研究如何恢复其性能。

**Method:** 提出一个框架来模拟三种风况（恒定、剪切和湍流）对无人机阵列性能的影响，并提出一种结合LSTM和自适应学习率的PPO算法（PPO-LA）来解决优化问题。

**Result:** PPO-LA算法在各种风况下成功恢复了性能下降的协同波束成形，并且显著优于基准算法。

**Conclusion:** 提出的PPO-LA算法能够有效应对风场扰动，恢复无人机群协同波束成形的性能。

> **ai_Abstract:** 本研究提出了一种用于低空无线网络中无人机群协同波束成形（CB）性能恢复的框架，以应对风场扰动（恒定、剪切和湍流）引起的位置误差。研究人员开发了一种结合长短期记忆（LSTM）和自适应学习率（PPO-LA）的新型近端策略优化算法，用于实时调整激励电流权重，以最大化方向性和最小化旁瓣。仿真结果表明，PPO-LA算法在各种风况下均能有效恢复CB性能，并优于现有基准算法。

> **摘要翻译:** 无人机群利用低空无线网络（LAWN）中的协同波束成形（CB）技术，通过形成虚拟天线阵列（VAA），在增强通信范围、能源效率和信号方向性方面展现出巨大潜力。然而，环境干扰，特别是风场，会通过引入破坏波束模式的位置误差来严重降低CB性能，从而影响传输可靠性。本文研究了在风场扰动下，在LAWN中运行的基于UAV的VAA中维持CB性能的关键挑战。我们提出了一个全面的框架，对三种不同的风况（恒定、剪切和湍流）对无人机阵列性能的影响进行了建模，并制定了一个长期实时优化问题，通过自适应激励电流权重调整来最大化方向性并最小化最大旁瓣电平。为了解决这个问题的固有复杂性，我们提出了一种新颖的具有长短期记忆（LSTM）结构和自适应学习率（PPO-LA）的近端策略优化算法，该算法能有效捕捉风场扰动的时序模式，并能在无需针对特定风况进行大量先验训练的情况下实现实时适应。我们的仿真结果表明，所提出的PPO-LA算法在各种风况下成功恢复了性能下降的CB性能，从而显著优于基准算法。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [399] [Stabilizing and Optimizing Inter-Shell Routing in LEO Networks with Integrated Routing Cost](https://arxiv.org/abs/2507.08549)
> *低地球轨道（LEO）网络中具有集成路由成本的稳定和优化壳间路由*

*Yaojia Wang, Qi Zhang, Kun Qiu, Yue Gao* | **Category: cs.NI** | **Updated: 2025-07-11**

**Keywords:** 低地球轨道网络, 壳间路由, 集成路由成本, 动态规划, ISL切换稳定性

**Comment:** 6 pages, 8 figures, 2025 IEEE/CIC International Conference on
  Communications in China (ICCC Workshops)

> **TL;DR:** 该研究提出了一种基于动态规划的集成路由成本（DP-IRC）算法，用于优化低地球轨道（LEO）巨型星座网络（LMCN）中的壳间路由。该算法通过结合壳间/壳内跳数和切换成本的集成路由成本（IRC）指标，平衡了跳数和ISL稳定性，解决了现有方法在减少跳数时忽略ISL切换成本导致的不稳定问题，以及在减少ISL切换时牺牲路径距离效率的问题。实验结果表明，DP-IRC相比现有方法能显著降低壳间ISL切换率，同时保持接近最优的端到端距离。

**AI_Comments:** 该研究提出的DP-IRC算法在解决LEO网络壳间路由稳定性问题上取得了显著进展，通过集成成本指标有效平衡了延迟和稳定性。然而，算法的计算复杂度在实际大规模部署中可能是一个需要考虑的因素。此外，对不同服务质量（QoS）要求的适应性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的低地球轨道（LEO）巨型星座网络（LMCN）壳间路由策略（如最小跳数路径集）虽然能降低延迟，但忽略了ISL切换成本，导致网络不稳定。自适应路径路由方案虽然引入了路径相似性阈值来减少切换，但其贪婪方法容易陷入局部最优，牺牲了路径距离效率。

**Method:** 提出了一种基于动态规划的集成路由成本（DP-IRC）算法，将多壳路径构建为多阶段决策问题。该算法使用集成路由成本（IRC）指标，该指标结合了壳间/壳内跳数和切换成本，以平衡跳数和ISL稳定性。

**Result:** 与最小跳数路径集策略和自适应路径路由方案相比，DP-IRC算法将壳间ISL切换率分别降低了39.1%和22.0%，同时保持了接近最优的端到端距离。

**Conclusion:** DP-IRC算法能够有效地稳定和优化低地球轨道（LEO）巨型星座网络（LMCN）中的壳间路由，通过集成路由成本指标平衡了跳数和ISL稳定性，显著降低了ISL切换率，同时保持了良好的路径效率。

> **ai_Abstract:** 该研究提出了一种名为DP-IRC的动态规划算法，用于优化低地球轨道（LEO）巨型星座网络（LMCN）中的壳间路由。DP-IRC通过一个集成的路由成本（IRC）指标来平衡跳数和ISL稳定性，该指标考虑了壳间/壳内跳数以及切换成本。与现有方法相比，DP-IRC在实验中显著降低了ISL切换率，同时保持了接近最优的端到端距离。

> **摘要翻译:** 低地球轨道（LEO）巨型星座网络（LMCN）使用数千颗卫星跨越多个壳层架构来提供不同的服务，但由于动态的网络拓扑和频繁的卫星间链路（ISL）切换，在壳间路由稳定性方面面临挑战。现有的策略，例如最小跳数路径集，优先考虑最小化跳数以减少延迟，但忽略了ISL切换成本，这导致了高度的不稳定性。为了克服这个问题，自适应路径路由方案引入了路径相似性阈值来减少壳层之间的ISL切换频率。然而，自适应路径路由方案的贪婪方法常常陷入局部最优，牺牲了壳间路径距离的效率。为了解决这些局限性，我们提出了基于动态规划的集成路由成本（DP-IRC）算法，该算法专为壳间路由优化而设计。通过将多壳路径构建为多阶段决策问题，DP-IRC通过集成路由成本（IRC）指标来平衡跳数和ISL稳定性，该指标结合了壳间/壳内跳数和切换成本。在真实世界的Starlink和OneWeb配置下进行了60个时间槽的实验表明，与最小跳数路径集策略和自适应路径路由方案相比，DP-IRC分别将壳间ISL切换率降低了39.1%和22.0%，同时仍然保持了接近最优的端到端距离。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [423] [Upgrade or Switch: Do We Need a Next-Gen Trusted Architecture for the Internet of AI Agents?](https://arxiv.org/abs/2506.12003)
> *升级还是切换：我们需要下一代人工智能代理互联网的可信架构吗？*

*Ramesh Raskar, Pradyumna Chari, Jared James Grogan, Mahesh Lambe, Robert Lincourt, Raghu Bala, Aditi Joshi, Abhishek Singh, Ayush Chopra, Rajesh Ranjan, Shailja Gupta, Dimitris Stripelis, Maria Gorskikh, Sichao Wang* | **Category: cs.NI, cs.AI, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 人工智能代理,信任架构,互联网,DNS,PKI

**Comment:** 

> **TL;DR:** 人工智能代理需要新的网络架构，因为它们与人类不同，会主动行动、保持状态、生成子代理并进行通信，这需要比现有DNS/PKI系统更快的发现、即时凭证撤销和行为证明。现有系统在传播时间、凭证撤销扩展性和地址空间方面存在不足。作者评估了升级现有系统、切换到新系统或采用混合方法的优缺点，并认为混合方法最有可能成功，结合了中心化索引和分布式网络。

**AI_Comments:** 该论文清晰地阐述了人工智能代理对现有互联网基础设施的潜在影响，并提出了一个关于未来网络架构的引人入胜的讨论。作者使用类比（如拨号上网到宽带）来解释需求的变化，这使得复杂的概念易于理解。然而，论文可以更深入地探讨所提出的混合方法的具体技术细节和潜在挑战。此外，虽然提到了“加密行为证明”，但对其具体实现和验证机制的阐述可以更详尽。总的来说，这是一项重要的工作，为理解和应对人工智能驱动的未来互联网奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 新兴的人工智能代理互联网对为人类互动设计的现有网络基础设施提出了挑战，因为人工智能代理具有自主性、持久状态、子代理生成和同伴协商等特点，这需要毫秒级的发现、即时的凭证撤销和超出当前DNS/PKI能力的加密行为证明。

**Method:** 本文分析了升级现有基础设施或实施专门的索引架构以支持自主代理的方案。评估了三种方法：(1) 升级路径，(2) 切换选项，(3) 混合索引/注册表。

**Result:** 现有的DNS传播时间（24-48小时）与所需毫秒级响应不符，证书撤销无法扩展到万亿级实体，IPv4/IPv6地址空间不足以支持代理规模的路由。升级路径提供兼容性和快速部署，但可能无法满足性能要求；而从头开始构建的解决方案性能更好，但部署周期更长。

**Conclusion:** 人工智能代理的需求是质变而非渐进式变化。混合方法最有可能成功，结合了中心化索引（用于关键代理）和分布式网络（用于特定用例）。

> **ai_Abstract:** 本文探讨了为人工智能代理（AI Agents）构建新的互联网信任架构的必要性。与当前为人类设计的网络基础设施相比，AI Agent具有自主行动、维护状态、生成子代理和直接协商等特点，对网络提出了更高的要求，包括毫秒级的发现速度、即时凭证撤销和行为证明，而现有的DNS和PKI系统无法满足这些需求。研究分析了升级现有系统或采用新架构的利弊，指出了DNS传播延迟、证书撤销扩展性和IP地址空间的不足。结论是，AI Agent的需求是根本性的变化，混合架构（结合中心化索引和分布式网络）可能是未来的发展方向。

> **摘要翻译:** 新兴的人工智能代理互联网对为人类互动设计的现有网络基础设施提出了挑战。与传统Web资源不同，自主人工智能代理会发起操作、维护持久状态、生成子代理并直接与同伴进行协商：这需要毫秒级的发现、即时的凭证撤销以及超出当前DNS/PKI能力的加密行为证明。本文分析了是升级现有基础设施还是实施专门的索引架构来支持自主代理。我们确定了关键的失败点：DNS传播（24-48小时 vs. 所需毫秒级）、证书撤销无法扩展到数万亿实体，以及IPv4/IPv6地址不足以支持代理规模的路由。我们评估了三种方法：(1) 升级路径，(2) 切换选项，(3) 混合索引/注册表。借鉴从拨号上网到宽带的过渡，我们发现代理的需求构成了质变而非渐进式变化。虽然升级提供了兼容性和更快的部署，但从头开始的解决方案提供了更好的性能，但需要更长的采用时间。我们的分析表明，混合方法将会出现，结合了用于关键代理的中心化索引和用于特定用例的分布式网络。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [424] [Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect](https://arxiv.org/abs/2507.08677)
> *低功耗广域网协议及其安全方面的定性评估*

*Wesley dos Reis Bezerra, Lais Machado Bezerra, Carlos Becker Westphal* | **Category: cs.NI** | **Updated: 2025-07-11**

**Keywords:** 低功耗广域网, LoRaWAN, NB-IoT, Sigfox, 物联网

**Comment:** 

> **TL;DR:** 该论文对LoRaWAN、NB-IoT和Sigfox这三种低功耗广域网协议进行了定性评估，重点关注其在资源受限和电池供电设备上的应用，并详细介绍了LoRaWAN协议。

**AI_Comments:** 该论文对LPWAN协议进行了有价值的定性评估，特别关注了资源受限设备的应用。对LoRaWAN的详细介绍增加了其实用性。然而，该研究主要基于文献调查，可能缺乏实际部署的性能数据。此外，虽然提到了安全方面，但摘要中并未深入探讨具体细节。

<details>
  <summary>Details</summary>

**Motivation:** 由于物联网领域存在多种通信选择，尤其是在资源受限和电池供电设备方面，理解这些低功耗广域网（LPWAN）协议的差异和特性对专业人士和研究人员来说是一个挑战。

**Method:** 通过文献计量调查，对三种LPWAN协议（LoRaWAN、NB-IoT和Sigfox）进行了分析，并对LoRaWAN进行了详细介绍。

**Result:** 研究结果讨论了所选网络协议（LoRaWAN）及其在具有稀疏传感器的物联网解决方案中的应用。

**Conclusion:** 该研究通过文献计量调查，对LoRaWAN、NB-IoT和Sigfox这三种低功耗广域网协议的定性特征进行了分析，并详细介绍了LoRaWAN协议，旨在帮助理解这些协议在资源受限和电池供电设备上的应用和挑战。

> **ai_Abstract:** 本研究对三种低功耗广域网（LPWAN）协议——LoRaWAN、NB-IoT和Sigfox进行了定性评估，重点关注它们在资源受限和电池供电设备上的应用。通过文献计量调查，论文分析了这些协议的特性，并深入探讨了LoRaWAN在稀疏网络传感器物联网解决方案中的应用潜力。

> **摘要翻译:** 目前物联网存在许多通信选择，即使在特定领域，如受约束和电池供电设备，也存在低功耗广域网。理解每个选项的区别和特性，即使对该领域的专业人士和研究人员来说，也是一个挑战。为了满足这一需求，本研究分析了低功耗广域网协议的定性特征，以及将受约束的设备用于基于长寿命电池的稀疏网络的挑战和机遇。本研究进行了文献计量调查，分析了三种协议（LoRaWAN、NB-IoT和Sigfox），并详细介绍了第一种协议。其结果是，对所选网络协议及其在具有稀疏传感器的物联网解决方案中的使用进行了讨论。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [449] [Knowledge Graph-Based approach for Sustainable 6G End-to-End System Design](https://arxiv.org/abs/2507.08717)
> *基于知识图谱的可持续6G端到端系统设计方法*

*Akshay Jain, Sylvaine Kerboeuf, Sokratis Barmpounakis, Cristóbal Vinagre Z., Stefan Wendt, Dinh Thai Bui, Pol Alemany, Riccardo Nicolicchia, José María Jorquera Valero, Dani Korpi, Mohammad Hossein Moghaddam, Mikko A. Uusitalo, Patrik Rugeland, Abdelkader Outtagarts, Karthik Upadhya, Panagiotis Demestichas, Raul Muñoz, Manuel Gil Pérez, Daniel Adanza, Ricard Vilalta* | **Category: cs.NI, 00** | **Updated: 2025-07-11**

**Keywords:** 知识图谱, 6G系统设计, 可持续性, 关键绩效指标, 技术驱动因素

**Comment:** The paper is submitted to IEEE Open Journal of the Communications
  Society (IEEE OJCOMS)

> **TL;DR:** 该研究提出了一种基于知识图谱的新型6G端到端系统设计方法，该方法同时考虑了性能和可持续性指标，并以协作移动机器人用例进行了验证。

**AI_Comments:** 这项研究在6G系统设计领域提出了一个创新的方法，通过知识图谱有效地整合了性能和可持续性需求。该方法论的优势在于其能够处理复杂的技术依赖关系和主观的可持续性指标，这在以往的研究中是一个挑战。然而，该研究的局限性可能在于知识图谱的构建和维护成本，以及其在不同用例和技术环境下的泛化能力有待进一步验证。未来的研究可以关注如何自动化知识图谱的构建过程，并探索该方法在其他新兴技术领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** 以往的蜂窝通信系统（如5G）主要关注提高吞吐量和降低延迟等关键绩效指标（KPI）。然而，为了满足不断变化的KPI需求以及信息通信技术（ICT）行业宏伟的可持续性目标，6G的设计需要革新，同时考虑不同用例的性能和可持续性目标。此外，6G技术具有多种候选技术，使得系统设计空间更加复杂。鉴于可持续性指标（尤其是社会可持续性）的主观性，现有文献在如何将技术驱动因素和6G系统设计与这些指标联系起来方面存在明显不足。

**Method:** 提出了一种基于知识图谱（KG）的新型6G端到端（E2E）系统设计方法。该方法将用例KPI、以关键值（KV）和KV指标（KVIs）表示的用例可持续性需求、技术驱动因素满足这些KPI和KVIs的能力、Hexa-X-II项目中定义的6G系统设计原则、技术驱动因素的成熟度以及它们之间的依赖关系作为输入。作为KG方法的一部分，还提出了一种确定技术驱动因素所解决的关键值的新方法。

**Result:** 该方法已成功应用于Hexa-X-II项目中定义的协作移动机器人用例的6G E2E系统设计，并选择了82个驱动因素。此外，还提供了部分选定驱动因素的概念验证演示结果，进一步证明了该KG方法在设计可持续6G系统方面的有效性。

**Conclusion:** 所提出的基于知识图谱的方法能够有效地设计满足性能和可持续性目标的6G端到端系统，并通过协作移动机器人用例得到了验证。

> **ai_Abstract:** 本研究提出了一种新颖的基于知识图谱的6G端到端系统设计方法，旨在解决性能和可持续性目标。该方法整合了用例需求、技术能力和设计原则，并以协作移动机器人用例进行了成功验证。

> **摘要翻译:** 先前几代蜂窝通信（如5G）的设计目标是提高吞吐量、延迟等关键绩效指标（KPI）。然而，为了满足不断变化的KPI需求以及信息通信技术（ICT）行业宏伟的可持续性目标，6G的设计需要有所不同。具体而言，6G需要同时考虑其将服务的各种用例的性能和可持续性目标。此外，与前几代一样，6G将具有各种候选技术驱动因素，使得系统设计空间更加复杂。此外，鉴于可持续性指标，特别是社会可持续性的主观性质，现有文献在如何将技术驱动因素和6G系统设计与它们联系起来方面存在显著的空白。因此，在本文中，我们介绍了一种基于知识图谱（KG）的新型6G端到端（E2E）系统设计方法。它将以下内容作为输入：用例KPI、以关键值（KV）和KV指标（KVIs）表示的用例可持续性需求、技术驱动因素满足这些KPI和KVIs的能力、Hexa-X-II项目中定义的6G系统设计原则、技术驱动因素的成熟度以及它们之间的依赖关系。作为KG方法的一部分，还引入了一种确定技术驱动因素所解决的关键值的新方法。通过将其应用于Hexa-X-II项目中定义的协作移动机器人用例的6G E2E系统设计（选择了82个驱动因素），证明了KG方法的有效性。最后，还提供了部分选定驱动因素的概念验证演示结果，这进一步加强了KG方法在设计可持续6G系统方面的有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [12] [New constructions of $2$-to-$1$ mappings over $\gf_{2^n}$ and their applications to binary linear codes](https://arxiv.org/abs/2507.08315)
> *$gf_{2^n}$ 上 $2$-to-$1$ 映射的新构造及其在二元线性码中的应用*

*Yaqin Li, Kangquan Li, Qiancheng Zhang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** $2$-to-$1$ 映射, 广义切换方法, Dickson多项式, 二元线性码, 权分布

**Comment:** 

> **TL;DR:** 本文研究了有限域上的 $2$-to-$1$ 映射构造及其在二元线性码中的应用。通过广义切换方法和Dickson多项式理论，构造了16类新的 $2$-to-$1$ 映射，并利用其构建了自正交、极小且少权的二元线性码。

**AI_Comments:** 本文的创新之处在于首次将广义切换方法应用于 $2$-to-$1$ 映射的构造，并结合Dickson多项式理论，系统地获得了大量新的、非等价的 $2$-to-$1$ 映射类。其重要性不仅在于理论上的突破，还在于为构造具有优良性质的二元线性码提供了新的工具和方法，这对于编码理论和密码学领域具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** $2$-to-$1$ 映射在组合数学和编码理论中具有广泛应用，因此其构造受到了广泛关注。

**Method:** 本文首先总结了偶特征有限域上现有 $2$-to-$1$ 映射的构造结果。然后，应用广义切换方法构造了形如 $F(x)=G(x)+{\rm Tr}_{q^l/q}(R(x))$ 的 $2$-to-$1$ 映射，其中 $G$ 是单项式，$R$ 是单项式或二项式。研究中利用了Dickson多项式理论的性质和低次方程的完全刻画。最后，利用新构造的 $2$-to-$1$ 映射（特别是 $cx + {\rm Tr}_{q^l/q}(x^d)$ 形式）构造了二元线性码，并确定了它们的权分布。

**Result:** 本文共构造了16类新的 $2$-to-$1$ 映射，它们与任何现有 $2$-to-$1$ 多项式都不是QM等价的。其中，有9类形式为 $cx + {\rm Tr}_{q^l/q}(x^d)$，另有7类形式为 $cx + {\rm Tr}_{q^l/q}(x^{d_1} + x^{d_2})$。这些新构造的无穷类解释了在特定条件下（$q=2^k$, $k>1$, $kl<14$ 和 $c \in \gf_{q^l}^*$）MAGMA的大多数数值结果。此外，利用新提出的 $2$-to-$1$ 映射构造了一些二元线性码，这些码被发现是自正交、极小且少权的，并且确定了它们的权分布。

**Conclusion:** 本文成功构造了大量新的、非QM等价的 $2$-to-$1$ 映射，并展示了它们在构建具有自正交、极小和少权等优良性质的二元线性码方面的实际应用价值。

> **ai_Abstract:** 本文深入研究了有限域上的 $2$-to-$1$ 映射及其在二元线性码中的应用。作者在总结现有构造方法的基础上，创新性地将广义切换方法应用于 $2$-to-$1$ 映射的构造，并结合Dickson多项式理论，成功构建了16类全新的、非QM等价的 $2$-to-$1$ 映射。这些新构造包括形如 $cx + {\rm Tr}_{q^l/q}(x^d)$ 和 $cx + {\rm Tr}_{q^l/q}(x^{d_1} + x^{d_2})$ 的函数。研究进一步展示了如何利用这些新映射来构造具有自正交、极小和少权等优良性质的二元线性码，并详细确定了这些码的权分布。

> **摘要翻译:** 有限域上的 $2$-to-$1$ 映射在组合数学和编码理论等领域具有广泛应用。因此， $2$-to-$1$ 映射的构造最近引起了广泛关注。本文在总结现有偶特征有限域上所有 $2$-to-$1$ 映射构造结果的基础上，首次将广义切换方法应用于 $2$-to-$1$ 映射的研究，即在有限域 $\mathbb{F}_{q^l}$ 上构造 $F(x)=G(x)+{\rm Tr}_{q^l/q}(R(x))$ 形式的 $2$-to-$1$ 映射，其中 $G$ 是单项式，$R$ 是单项式或二项式。利用Dickson多项式理论的性质和低次方程的完全刻画，我们总共构造了16类新的 $2$-to-$1$ 映射，它们与任何现有 $2$-to-$1$ 多项式都不是QM等价的。其中，9类形式为 $cx + {\rm Tr}_{q^l/q}(x^d)$，7类形式为 $cx + {\rm Tr}_{q^l/q}(x^{d_1} + x^{d_2})$。在 $q=2^k$, $k>1$, $kl<14$ 和 $c \in \gf_{q^l}^*$ 的条件下，这些新的无穷类解释了MAGMA的大多数数值结果。最后，我们利用新提出的 $cx + {\rm Tr}_{q^l/q}(x^d)$ 形式的 $2$-to-$1$ 映射构造了一些二元线性码，并确定了这些码的权分布。有趣的是，我们的码是自正交、极小且少权的。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [16] [Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications](https://arxiv.org/abs/2502.12096)
> *令牌通信：一种跨模态上下文感知语义通信的统一框架*

*Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato* | **Category: cs.IT, cs.CV, cs.MM, eess.SP, math.IT** | **Updated: 2025-07-11**

**Keywords:** 令牌通信, 语义通信, 跨模态, 大型模型, 带宽效率

**Comment:** Accepted at IEEE Wireless Communications Magazine

> **TL;DR:** 提出Token Communications (TokCom) 框架，利用大型模型驱动的跨模态上下文信息提升生成式语义通信的效率。

**AI_Comments:** TokCom的创新之处在于将大型生成模型和多模态大语言模型的“令牌”概念引入通信领域，实现了通信单元的语义化和跨模态上下文感知，有望显著提升未来无线网络的带宽效率和通信质量。这是一个将AI前沿技术与通信相结合的重要探索。

<details>
  <summary>Details</summary>

**Motivation:** 受生成式基础模型和多模态大型语言模型（GFM/MLLMs）最新成功的启发，旨在利用跨模态上下文信息改进生成式语义通信。

**Method:** 引入令牌通信（TokCom）框架，将GFM/MLLMs的令牌处理集成到语义通信系统中，以经济的复杂性有效利用跨模态上下文，并提出了未来无线网络中TokCom在各层高效实现的关键原则。

**Result:** 在典型的图像语义通信设置中，TokCom通过利用令牌间的上下文信息，显著提高了带宽效率。

**Conclusion:** 识别了促进TokCom在未来无线网络中应用的潜在研究方向。

> **ai_Abstract:** 本文提出了一种名为令牌通信（TokCom）的新型通信框架，该框架由大型模型驱动，旨在生成式语义通信中利用跨模态上下文信息。TokCom借鉴了GFM/MLLMs的成功经验，以令牌作为通信单元，实现高效的Transformer处理。文章探讨了在GenSC中利用上下文的机遇与挑战，并提出了将GFM/MLLMs集成到语义通信系统中的原则。实验表明，在图像语义通信中，TokCom显著提升了带宽效率。

> **摘要翻译:** 在本文中，我们引入了令牌通信（TokCom），这是一个由大型模型驱动的框架，旨在利用生成式语义通信（GenSC）中的跨模态上下文信息。TokCom是一种新范式，其灵感来源于生成式基础模型和多模态大型语言模型（GFM/MLLMs）的最新成功，其中通信单元是令牌，从而在发送端和接收端实现高效的基于Transformer的令牌处理。在本文中，我们介绍了在GenSC中利用上下文的潜在机遇和挑战，探讨了如何将基于GFM/MLLMs的令牌处理集成到语义通信系统中，以经济的复杂性有效利用跨模态上下文，并提出了未来无线网络中TokCom在各层高效实现的关键原则。在典型的图像语义通信设置中，我们演示了TokCom通过利用令牌间的上下文信息显著提高了带宽效率。最后，确定了促进TokCom在未来无线网络中应用的潜在研究方向。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [48] [Secrecy Offloading Analysis of UAV-assisted NOMA-MEC Incorporating WPT in IoT Networks](https://arxiv.org/abs/2507.08352)
> *无人机辅助NOMA-MEC中结合WPT的物联网网络保密卸载分析*

*Gia-Huy Nguyen, Anh-Nhat Nguyen, Minh-Sang Nguyen, Khai Nguyen, Tung-Son Ngo, Ngoc-Anh Bui, Phuong-Chi Le, Manh-Duc Hoang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 无人机, NOMA-MEC, 无线能量传输, 保密卸载, 物联网

**Comment:** 6 pages, 7 figures, 2024 28th International Computer Science and
  Engineering Conference (ICSEC)

> **TL;DR:** 本文研究了无人机辅助的非正交多址接入（NOMA）集成移动边缘计算（MEC）系统，结合无线能量传输（WPT）在物联网（IoT）网络中的保密数据卸载效率，其中无人机扮演移动计算平台和空中供电站的双重角色。

**AI_Comments:** 这篇论文的创新点在于将无人机在NOMA-MEC系统中同时作为移动计算平台和空中供电站，并结合无线能量传输（WPT）来增强物联网网络的保密卸载效率，特别关注了对窃听者的防御。其重要性在于为未来资源受限的IoT设备提供了潜在的解决方案，以实现更安全高效的数据处理。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究无人机辅助的NOMA-MEC系统中结合无线能量传输（WPT）在物联网（IoT）网络中进行保密数据卸载的效率。具体目标是利用无人机的双重角色（移动计算平台和空中供电站）来帮助资源受限的边缘设备（EDs）减轻来自无源窃听者的干扰。

**Method:** 本文研究了无人机辅助的NOMA-MEC系统结合WPT在物联网网络中的保密数据卸载效率。方法是推导了Nakagami-m衰落信道下的保密成功计算概率（SSCP）的闭式表达式，并通过各种参数对理论结果进行了验证。

**Result:** 推导了Nakagami-m衰落信道下的保密成功计算概率（SSCP）的闭式表达式。理论结果通过各种参数进行了验证，从而验证了分析的精确性。

**Conclusion:** 通过理论分析和参数验证，本文成功评估了无人机辅助的NOMA-MEC结合无线能量传输在物联网网络中进行保密数据卸载的效率，并证明了其分析的精确性。

> **ai_Abstract:** 本文探讨了在物联网环境中，无人机辅助的NOMA-MEC系统结合无线能量传输（WPT）进行保密数据卸载的效率。研究中，无人机被设计为同时提供移动计算和空中供电服务，旨在帮助资源受限的边缘设备抵御窃听干扰。为量化系统性能，文章推导了Nakagami-m衰落信道下的保密成功计算概率（SSCP）闭式表达式，并通过多种参数设置验证了分析的准确性。

> **摘要翻译:** 本文研究了物联网（IoT）网络中，无人机（UAV）辅助的非正交多址接入（NOMA）集成移动边缘计算（MEC）结合无线能量传输（WPT）的保密数据卸载效率。具体来说，本研究假设无人机扮演双重角色：作为移动计算平台和空中供电站，为资源受限的边缘设备（EDs）在减轻来自无源窃听者的干扰方面提供了显著优势。为了评估系统的保密卸载效率，推导了Nakagami-m衰落信道下的保密成功计算概率（SSCP）的闭式表达式。理论结果通过各种参数进行验证，从而验证了我们分析的精确性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [75] [Discovering the Unequal Importance of Coded Bits in the Decoding of Polar Codes](https://arxiv.org/abs/2507.08598)
> *发现极化码解码中编码比特的不等重要性*

*Hossam Hassan, Ali Gaber, Mohammed Karmoose, Noha Korany* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 极化码, 编码比特, 解码, 比特映射, 误码率性能

**Comment:** 

> **TL;DR:** 本文研究了极化码解码过程中编码比特的重要性，并展示了通过将重要比特映射到最可靠信道可以显著提高系统性能。

**AI_Comments:** 本文的创新点在于揭示了极化码中编码比特的不等重要性，并通过智能的比特映射策略显著提升了解码性能。这种方法为极化码的实际应用提供了有价值的优化方向，特别是在对性能要求严格的通信系统中。

<details>
  <summary>Details</summary>

**Motivation:** 极化码在现代通信系统中因其容量达到特性而广泛应用。本文旨在探究极化码解码过程中编码比特的重要性，并确定哪些比特对成功解码贡献最大。

**Method:** 通过暴力搜索和代理优化技术来识别最关键的编码比特。然后，将这些重要比特映射到最可靠的信道。

**Result:** 所提出的比特映射方法在OFDM系统中将误码率（BER）性能提高了高达7倍，且只需极小的额外成本。

**Conclusion:** 通过识别极化码中最重要的编码比特并将其映射到最可靠的信道，可以显著改善系统性能。

> **ai_Abstract:** 本文研究了极化码解码过程中编码比特的重要性，旨在识别对成功解码贡献最大的关键比特。通过结合暴力搜索和代理优化技术，研究人员发现并将这些重要比特映射到最可靠的信道，从而在OFDM系统中实现了高达7倍的误码率性能提升，且额外成本极低。

> **摘要翻译:** 极化码因其容量达到特性而广泛应用于现代通信系统。本文研究了极化码解码过程中编码比特的重要性，旨在确定哪些比特对成功解码贡献最大。我们通过暴力搜索方法和代理优化技术来研究这个问题，以识别最关键的编码比特。我们还展示了如何将这些重要比特映射到最可靠的信道，以最小的额外成本提高系统性能。我们展示了所提出的比特映射在基于OFDM的系统中的性能，并证明了误码率性能高达7倍的增益。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [100] [Learning to Transmit Over Unknown Erasure Channels with Empirical Erasure Rate Feedback](https://arxiv.org/abs/2507.08599)
> *在未知擦除信道上学习传输，并利用经验擦除率反馈*

*Haricharan Balasundaram, Krishna Jagannathan* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 未知擦除信道, 遗憾最小化, 学习与利用, 经验擦除率, 数据传输

**Comment:** 

> **TL;DR:** 本文提出了两种策略，用于在未知擦除信道上进行可靠数据传输，旨在最小化遗憾（相对于已知信道的情况），并通过平衡信道学习与数据传输实现 O(T^(2/3)) 或 O(√T) 的遗憾界限，同时具有不同的查询复杂度。

**AI_Comments:** 该论文解决了通信领域中一个重要且实际的问题，即在未知信道条件下如何进行高效可靠的数据传输。文章清晰地阐述了“学习与利用”的经典困境，并提供了两种具有理论性能保证（遗憾界限）的解决方案。这两种策略在反馈查询次数和遗憾性能之间提供了明确的权衡，这对于实际系统设计具有指导意义。其理论分析严谨，贡献了对该问题理解的深度。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决在有限时间 T 内通过未知擦除概率的二元擦除信道进行可靠数据传输的问题。核心动机是最小化遗憾（即与已知擦除概率的理想情况相比，策略性能的差距），同时保持相同的块错误率，并解决学习信道概率与传输信息比特之间的权衡（学习与利用困境）。

**Method:** 本文提出了两种策略：1) 一种两阶段方法，首先进行速率估计，然后进行传输；2) 一种窗口策略，使用几何递增的窗口大小。

**Result:** 1) 两阶段方法仅使用一次查询即可实现 O(T^(2/3)) 的遗憾；2) 窗口策略使用 O(log(T)) 次查询即可实现 O(√T) 的遗憾。

**Conclusion:** 本文成功提出了两种策略，有效解决了在未知擦除信道中进行可靠数据传输时的学习与利用困境，并给出了量化的遗憾界限，展示了在遗憾性能和查询复杂性之间的权衡。

> **ai_Abstract:** 本文研究了在有限时间 T 内通过未知擦除概率的二元擦除信道进行可靠数据传输的问题。研究人员提出了一种反馈模型，发送方可不频繁地获取接收方的经验擦除率，目标是最小化相对于已知信道信息的理想情况的遗憾。为解决学习信道状态与传输信息之间的权衡，论文提出了两种策略：一种是两阶段方法，先估计速率再传输，仅需一次查询即可达到 O(T^(2/3)) 的遗憾；另一种是窗口策略，采用几何递增的窗口大小，需 O(log(T)) 次查询即可达到 O(√T) 的遗憾。

> **摘要翻译:** 我们解决了在有限时间 T 内通过具有未知擦除概率的二元擦除信道进行可靠数据传输的问题。我们考虑一种反馈模型，其中发送方可以不频繁地查询接收方，并获得后者经历的经验擦除率。我们的目标是最小化遗憾量，即与知道擦除概率的预言机相比，策略性能差多少，同时以相同的块错误率运行。在这种情况下，学习与利用的困境显现出来——具体来说，我们需要在 (i) 以合理的精度学习擦除概率和 (ii) 利用信道传输尽可能多的信息比特之间取得平衡。我们提出了两种策略：(i) 一种两阶段方法，使用速率估计后进行传输，仅使用一次查询即可实现 O(T^(2/3)) 的遗憾；(ii) 一种使用几何递增窗口大小的窗口策略，使用 O(log(T)) 次查询即可实现 O(√T) 的遗憾。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [124] [Evaluating the Performance of Reconfigurable Intelligent Base Stations through Ray Tracing](https://arxiv.org/abs/2507.08611)
> *通过射线追踪评估可重构智能基站的性能*

*Sina Beyraghi, Giovanni Interdonato, Giovanni Geraci, Stefano Buzzi, Angel Lozano* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 可重构智能基站, 射线追踪, 大规模多输入多输出, 频谱效率, SIONNA

**Comment:** 

> **TL;DR:** 本文通过SIONNA射线追踪模块评估了可重构智能基站（RIBS）的性能，并与统计模型进行对比，结果显示射线追踪预测的性能更优，但需要经验验证。

**AI_Comments:** 该论文创新性地利用射线追踪评估了可重构智能基站（RIBS）的性能，这是对传统统计模型的重要补充，尤其是在强调特定位置性能预测的背景下。其重要性在于揭示了射线追踪在预测RIBS性能方面的潜在优势，并指出了未来研究方向，即通过经验验证来确认这些预测。主要局限性在于目前的结果仅基于模拟，尚未得到实际测量数据的验证。

<details>
  <summary>Details</summary>

**Motivation:** 为减少大规模多输入多输出（mMIMO）系统中所需的射频（RF）链数量，引入了一种新型的可重构智能基站（RIBS）方法。鉴于精确的、特定位置性能预测日益重要，本文旨在评估RIBS系统的性能。

**Method:** 本文使用SIONNA射线追踪模块评估了可重构智能基站（RIBS）系统的性能。其性能与基于统计的3GPP兼容信道模型的结果进行了对比，并通过优化功率和RIS配置来最大化总频谱效率。

**Result:** 在评估场景中，射线追踪预测的性能优于统计模型，这表明了特定站点建模的潜力。

**Conclusion:** 射线追踪预测的可重构智能基站性能优于统计模型，表明了特定站点建模的潜力。然而，需要经验验证来确认这一优势。

> **ai_Abstract:** 本文评估了可重构智能基站（RIBS）的性能，该基站是一种用于减少大规模多输入多输出（mMIMO）系统射频链数量的新型技术。研究利用SIONNA射线追踪模块进行性能评估，并将其结果与统计性3GPP兼容信道模型进行对比，旨在最大化总频谱效率。结果显示，射线追踪预测的性能优于统计模型，突出了特定站点建模的潜力，但强调了经验验证的重要性。

> **摘要翻译:** 大规模多输入多输出（mMIMO）是5G无线系统中一项关键的容量提升技术。为了减少此类系统所需的射频（RF）链数量，最近引入了一种新颖的方法，涉及由可重构智能表面支持的天线阵列。这种被称为可重构智能基站（RIBS）的配置，提供了与传统mMIMO阵列相当的性能，但射频链数量显著减少。鉴于精确的、特定位置的性能预测日益重要，本文通过SIONNA射线追踪模块评估了RIBS系统的性能。该性能与源自符合3GPP标准的统计信道模型的结果进行了对比，通过优化功率和RIS配置来最大化总频谱效率。在评估场景中，射线追踪预测的性能优于统计模型，这表明了特定站点建模的潜力。然而，需要经验验证来确认这一优势。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [148] [Fine-tuning ORBGRAND with Very Few Channel Soft Values](https://arxiv.org/abs/2507.08696)
> *利用极少量信道软值微调ORBGRAND*

*Li Wan, Huarui Yin, Wenyi Zhang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** ORBGRAND, 微调, 信道软值, 解码, 误差模式

**Comment:** 

> **TL;DR:** 本文提出了一种利用极少量信道软值微调ORBGRAND的方法，以在极低的复杂度增量下显著提升性能。

**AI_Comments:** 本文的创新点在于利用极少量信道软值和源自整数划分理论的“有序性”新度量，弥合了最大似然解码性能与ORBGRAND效率之间的差距。这提供了一种在不显著增加复杂度的情况下提升解码性能的实用方法。

<details>
  <summary>Details</summary>

**Motivation:** GRAND解码范式中，最大似然解码（MLD）复杂度过高，而ORBGRAND虽然实现高效但对有限长码存在性能损失。本文旨在结合两者的优势。

**Method:** 本文提出了一种微调ORBGRAND的方法，利用极少量精确的信道软值来调整测试顺序。该方法基于一个评估误差模式“有序性”的度量，并利用整数划分的渐近理论对其进行了研究。

**Result:** 数值实验表明，所提出的微调方法与ORBGRAND相比，实现了显著的性能提升，且复杂度增量可以忽略不计。

**Conclusion:** 本文提出的微调方法通过引入极少量信道软值，并基于新的“有序性”度量，能够有效提升ORBGRAND的性能，同时只带来可忽略的复杂度增量。

> **ai_Abstract:** 本文提出了一种针对ORBGRAND的微调方法，旨在解决GRAND解码范式中最大似然解码复杂度过高与ORBGRAND效率高但性能损失的问题。该方法利用极少量精确的信道软值来调整误差模式的测试顺序，并基于一个通过整数划分渐近理论研究的“有序性”度量。数值实验表明，该微调方法在复杂度增量可忽略的情况下，显著提升了ORBGRAND的性能。

> **摘要翻译:** 随机加性噪声猜测解码（GRAND）是一种通用的解码范式，它通过重复测试误差模式直到识别出码字来进行解码，其中测试的顺序由接收到的信道值生成。一方面，虽然以后验概率降序测试误差模式可实现最大似然解码，但其实现复杂度过高。另一方面，使用由对数似然比幅度（即有序可靠性比特，ORB）排名排列的预设误差模式集进行测试可实现高效实现，但会导致有限长码的性能损失。为了利用这两种方法的优点，本文提出了一种改进ORBGRAND的微调方法，借助极少量精确的信道软值来调整测试顺序。该方法基于一个评估误差模式“有序性”的度量。该度量通过整数划分的渐近理论进行研究，在数值实验中提供了高度准确的估计。该度量随后能够有效识别需要进行的微调，且仅需付出可忽略的复杂度增量。数值实验表明，所提出的微调方法与ORBGRAND相比，实现了显著的性能提升。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [172] [Column Twisted Reed-Solomon Codes as MDS Codes](https://arxiv.org/abs/2507.08755)
> *列扭曲Reed-Solomon码作为MDS码*

*Wei Liu, Jinquan Luo, Puyin Wang, Dengxin Zhai* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 列扭曲Reed-Solomon码, MDS码, Schur平方码, 扭曲广义Reed-Solomon码, 对偶码

**Comment:** 

> **TL;DR:** 本文研究列扭曲Reed-Solomon (TRS) 码，建立了其成为MDS码的条件，并证明它们不等价于RS码。该构造方法提供了更灵活的参数和更长的码长，并提出了一种新的MDS码构造方法。

**AI_Comments:** 本文通过对RS码生成矩阵进行列扭曲，提出了一种新颖的MDS码构造方法。其创新点在于建立了TRS码成为MDS码的条件，证明了其与RS码不等价，并在参数灵活性和码长上超越了现有TGRS码的构造。这项工作为编码理论领域提供了新的实用构造方法，增强了纠错码的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究列扭曲Reed-Solomon (TRS) 码，探索其作为MDS码的条件及其相对于现有扭曲广义Reed-Solomon (TGRS) 码构造的优势，包括更灵活的参数和更长的码长。最终目标是提供一种新的MDS码构造方法。

**Method:** 本文研究了列扭曲Reed-Solomon (TRS) 码，建立了它们成为MDS码的条件，并分析了其Schur平方码的维度。该构造方法通过在Reed-Solomon (RS) 码的生成矩阵中添加列向量来实现，并给出了其对偶码。

**Result:** 研究结果表明，本文建立了列TRS码成为MDS码的一些条件，并证明了其Schur平方码的维度为2k，从而证明这些TRS码不等价于RS码。此外，该构造方法与之前的TGRS码构造相比，提供了更灵活的参数，并且对于大的奇素数幂q，码长可达(q+3)/2，超过了先前TGRS码的限制。论文还给出了列TRS码的对偶码。

**Conclusion:** 本文通过在RS码的生成矩阵中添加列向量，提供了一种新的构造MDS码的方法。所构造的列TRS码在参数灵活性和码长方面优于之前的TGRS码。

> **ai_Abstract:** 本文研究列扭曲Reed-Solomon (TRS) 码，确定了其成为最大距离可分 (MDS) 码的条件。研究表明，由于其Schur平方码的维度，这些TRS码不等价于标准的Reed-Solomon (RS) 码。与先前的扭曲广义Reed-Solomon (TGRS) 码相比，所提出的构造方法提供了更大的参数灵活性，并实现了更长的码长 (高达(q+3)/2)。论文还描述了列TRS码的对偶码，提出了一种通过修改RS码生成矩阵来构造MDS码的新方法。

> **摘要翻译:** 标题：列扭曲Reed-Solomon码作为MDS码
摘要：在本文中，我们研究了列扭曲Reed-Solomon (TRS) 码。我们建立了一些使列TRS码成为MDS码的条件，并表明其Schur平方码的维度为2k。因此，这些TRS码不等价于Reed-Solomon (RS) 码。此外，与之前的扭曲广义Reed-Solomon (TGRS) 码构造相比，这种构造方法提供了更灵活的参数。对于大的奇素数幂q，与之前系统构造的TGRS码长度限制在(q+1)/2不同，我们的构造实现了高达(q+3)/2的码长。最后，我们介绍了列TRS码的对偶码。本文通过在RS码的生成矩阵中添加列向量，提供了一种新的构造MDS码的方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [307] [$q$-ary Sequential Locally Recoverable Codes from the Product Construction](https://arxiv.org/abs/2401.07835)
> *$q$-元序列局部可恢复码的乘积构造*

*Akram Baghban, Marc Newman, Anna-Lena Horlemann, Mehdi Ghiyasvand* | **Category: cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 序列局部可恢复码, 局部可修复码, 码乘积, MDS码, BCH码, 分布式存储

**Comment:** 

> **TL;DR:** 本文构建了一种新的$q$-元序列局部可恢复码（SLRCs），使用了乘积构造，并研究了MDS和BCH码在SLRCs中的应用，最后与其他LRCs进行了比较。

**AI_Comments:** 创新性：利用码乘积构造SLRCs，并实现了新颖的最大可恢复擦除数$t$和最小修复选择性$A$。研究MDS和BCH码在SLRCs构造中的应用也具有理论和实践意义。重要性：SLRCs在分布式存储系统中纠正数据擦除至关重要，该工作为构建更高效、更可靠的存储系统提供了新的编码方案。局限性：摘要中未详细说明具体的比较结果，无法评估其相对于现有LRCs的实际优势。

<details>
  <summary>Details</summary>

**Motivation:** 序列局部可恢复码（SLRCs）是一种用于分布式存储系统、能够纠正多个码符号擦除的特殊局部可修复码，因此研究它们具有重要意义。

**Method:** 1. 利用码乘积构造了一种扩展的$q$-元非二进制SLRC家族。2. 研究了如何使用MDS和BCH码来构造$q$-元SLRCs。3. 将所提出的码与其他局部可恢复码（LRCs）进行了比较。

**Result:** 1. 构造的SLRC家族具有新颖的最大可恢复擦除数$t$和最小修复选择性$A$。2. 研究了MDS和BCH码在构造$q$-元SLRCs中的应用。3. 将所提出的码与其他LRCs进行了比较。

**Conclusion:** 本文成功构建了具有特定优良性能的$q$-元序列局部可恢复码（SLRCs），并证明了MDS和BCH码在SLRCs构造中的适用性，且与现有LRCs进行了对比。

> **ai_Abstract:** 本文专注于研究用于分布式存储系统中的$q$-元序列局部可恢复码（SLRCs）。研究人员首先利用码乘积方法构建了一类新型的非二进制SLRCs，该码具有优化的擦除恢复能力和修复选择性。随后，探讨了MDS码和BCH码在构造此类SLRCs中的应用。最后，将所提出的码与现有的局部可恢复码进行了性能比较。

> **摘要翻译:** 本文重点研究序列局部可恢复码（SLRCs），这是一类特殊的局部可修复码，能够纠正多个码符号擦除，常用于分布式存储系统。首先，我们利用码乘积构造了一种扩展的$q$-元非二进制SLRC家族，该家族具有新颖的最大可恢复擦除数$t$和最小修复选择性$A$。其次，我们研究了如何使用MDS码和BCH码来构造$q$-元SLRCs。最后，我们将我们的码与其他LRCs进行了比较。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [337] [Sibson $α$-Mutual Information and Its Variational Representations](https://arxiv.org/abs/2405.08352)
> *Sibson $\alpha$-互信息及其变分表示*

*Amedeo Roberto Esposito, Michael Gastpar, Ibrahim Issa* | **Category: cs.IT, math.IT, math.PR** | **Updated: 2025-07-11**

**Keywords:** Sibson $\alpha$-互信息, 变分表示, R\'enyi散度, 信息理论, 不等式

**Comment:** 

> **TL;DR:** 本文综述并扩展了Sibson $\alpha$-互信息的最新研究，引入了其变分表示，并利用这些表示在多个领域（如依赖下的测度集中、统计学习、假设检验和估计理论）推导出了新颖的结果，包括广义传输成本不等式和Fano型不等式。

**AI_Comments:** 本文的创新点在于引入了Sibson $\alpha$-互信息的变分表示，这为在多个理论和应用背景下推导新颖不等式（如广义传输成本不等式和Fano型不等式）提供了强大的工具。这对于深化对信息度量的理解及其在统计学和机器学习中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Sibson $\alpha$-互信息作为一种基于R\'enyi散度构建的信息度量，在依赖下的测度集中、统计学习、假设检验和估计理论等多个领域受到关注，本文旨在综述并扩展其最新研究。

**Method:** 本文引入了Sibson $\alpha$-互信息的变分表示，并将其应用于所述的各个背景中，以推导出新的结果。

**Result:** 本文推导出了广义传输成本不等式和Fano型不等式等新颖结果。

**Conclusion:** 本文通过引入Sibson $\alpha$-互信息的变分表示，不仅综述和扩展了现有技术水平，还在多个理论和应用背景下获得了新的重要结果。

> **ai_Abstract:** 本文深入探讨了Sibson $\alpha$-互信息，该信息度量从R\'enyi散度构建，并在多个领域受到关注。作者综述并扩展了现有研究，核心贡献是引入了Sibson $\alpha$-互信息的变分表示，并利用这些表示在测度集中、统计学习、假设检验和估计理论中推导出了广义传输成本不等式和Fano型不等式等新颖结果。文章还概述了其在学习理论、贝叶斯风险和通用预测等方面的已知应用。

> **摘要翻译:** 信息度量可以像互信息从Kullback-Leibler散度构建一样，从R\'enyi散度构建。其中一种信息度量被称为Sibson $\alpha$-互信息，最近在多个背景下重新受到关注：依赖下的测度集中、统计学习、假设检验和估计理论。在本文中，我们综述并扩展了现有技术水平。特别是，我们引入了Sibson $\alpha$-互信息的变分表示，并在每个描述的背景中应用它们来推导新颖的结果。具体而言，我们产生了广义传输成本不等式和Fano型不等式。我们还概述了已知的应用，涵盖从学习理论和贝叶斯风险到通用预测。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [521] [What should a neuron aim for? Designing local objective functions based on information theory](https://arxiv.org/abs/2412.02482)
> *神经元应该以什么为目标？基于信息论设计局部目标函数*

*Andreas C. Schneider, Valentin Neuhaus, David A. Ehrlich, Abdullah Makkeh, Alexander S. Ecker, Viola Priesemann, Michael Wibral* | **Category: cs.IT, cs.LG, cs.NE, math.IT** | **Updated: 2025-07-11**

**Keywords:** 局部学习, 信息论, 部分信息分解, 神经元可解释性, 自组织

**Comment:** Presented as an oral at ICLR 2025. Conference version:
  https://openreview.net/forum?id=CLE09ESvul, 24 pages, 11 figures

> **TL;DR:** 本研究提出了一种受生物启发的局部学习目标函数设计方法，利用信息论中的部分信息分解（PID）来指导人工神经元进行信息整合，从而实现神经元级别的可解释性和强大的性能。

**AI_Comments:** 该研究将信息论中的部分信息分解（PID）概念应用于人工神经网络的局部学习目标设计，这是一个创新性的尝试。通过将神经元的信息处理过程与PID的独特、冗余和协同贡献联系起来，为理解和设计更具可解释性的神经网络提供了新的视角。然而，PID的计算复杂性以及如何有效地将PID项与具体的任务需求相结合以进行数值优化，可能是未来研究需要进一步探讨的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现代深度神经网络的训练依赖于全局优化，导致单个神经元的学习动态不透明。而生物系统则通过自组织和局部学习实现鲁棒性和效率。因此，本研究旨在探索如何通过设计局部学习目标函数，使人工神经元能够实现类似生物系统的自组织学习。

**Method:** 利用信息论中的部分信息分解（PID）框架，将信息源关于某个结果的信息分解为独特、冗余和协同的贡献。通过设计局部学习目标函数，使神经元能够根据PID项的加权和来局部塑造不同输入（前馈、反馈、侧向）的信息整合方式。

**Result:** 提出了一种框架，使神经元能够通过局部选择不同输入贡献的性质（独特、冗余或协同）来塑造信息整合，从而实现神经元级别的可解释性，并保持强大的性能。

**Conclusion:** 本研究提出了一个基于信息论（PID）的框架，用于设计人工神经元的局部学习目标函数，实现了神经元级别的可解释性，并能通过局部学习策略取得优异性能，为局部学习策略提供了原则性的信息论基础。

> **ai_Abstract:** 本研究提出了一种新颖的框架，利用信息论中的部分信息分解（PID）来设计人工神经元的局部学习目标函数。该框架允许神经元根据信息贡献的独特性、冗余性和协同性来局部塑造信息整合，从而解决了传统深度学习中神经元学习动态不透明的问题。通过模拟生物系统的自组织学习机制，该方法在实现神经元级别可解释性的同时，也保证了模型的性能。

> **摘要翻译:** 在现代深度神经网络中，单个神经元的学习动态通常是模糊的，因为网络的训练是通过全局优化进行的。相反，生物系统建立在自组织、局部学习的基础上，以有限的全局信息实现了鲁棒性和效率。我们在此展示了如何通过设计抽象的受生物启发的局部学习目标来实现单个人工神经元之间的自组织。这些目标是利用信息论的最新扩展——部分信息分解（PID）——来参数化的，PID将信息源集合关于某个结果的信息分解为独特、冗余和协同的贡献。我们的框架使神经元能够通过选择三个输入（前馈、反馈和侧向）中的哪一个应该对输出做出独特、冗余或协同的贡献，来局部塑造信息整合，即前馈、反馈和侧向。这种选择表示为PID项的加权和，对于给定的问题，可以从直观的推理或通过数值优化直接推导出，为理解任务相关的局部信息处理提供了窗口。我们的工作在实现神经元级别的可解释性的同时，通过局部学习实现了强大的性能，为局部学习策略提供了原则性的信息论基础。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [598] [Movable Antenna-Aided Near-Field Integrated Sensing and Communication](https://arxiv.org/abs/2412.19470)
> *可移动天线辅助的近场集成感知与通信*

*Jingze Ding, Zijian Zhou, Xiaodan Shao, Bingli Jiao, Rui Zhang* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-11**

**Keywords:** 集成感知与通信, 可移动天线, 近场通信, 波束形成, 优化算法

**Comment:** This paper has been accepted by IEEE Transactions on Wireless
  Communications

> **TL;DR:** 提出一种利用可移动天线（MA）在近场ISAC系统中同时优化感知和通信性能的方法，并提出两种算法来解决优化问题和减少天线移动距离。

**AI_Comments:** 这项工作解决了近场ISAC领域的一个重要问题，即在感知和通信之间进行权衡。通过引入可移动天线和提出有效的优化算法，该研究为提高ISAC系统的灵活性和性能提供了新的途径。特别是，在近场场景下考虑天线移动以及优化移动路径以减少能耗和时间开销，具有重要的实际意义和创新性。然而，算法的计算复杂度以及在真实环境中的鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有ISAC系统使用固定位置天线（FPA），在平衡感知和通信性能时存在性能损失。近场ISAC需要更大的天线移动区域，可能使传统的远场假设失效。因此，需要一种新的方法来提升近场ISAC性能。

**Method:** 利用全双工基站（BS）配备的多根可移动天线（MA），在大型区域内移动，以同时感知多个目标并服务多个上行（UL）和下行（DL）用户。通过联合设计传输波束形成器、感知信号协方差矩阵、接收波束形成器、BS处MA位置以及UL功率分配，来最大化感知和通信速率的加权和（WSR）。提出了一种高效的两层随机位置（RP）算法来解决优化问题。此外，还设计了一种基于贪婪策略的天线位置匹配（APM）算法，以最小化总MA移动距离。

**Result:** 与固定天线相比，在近场ISAC系统中部署MA可显著提升性能。所提出的APM算法能有效减少天线移动距离，有助于降低能耗和时间开销。

**Conclusion:** 可移动天线技术能够显著增强近场集成感知与通信（ISAC）系统的性能。所提出的随机位置（RP）算法和天线位置匹配（APM）算法能够有效地解决优化问题并减少天线移动的延迟和成本。

> **ai_Abstract:** 该研究提出了一种在近场集成感知与通信（ISAC）系统中利用可移动天线（MA）来提升性能的方法。通过联合优化波束形成、感知参数、MA位置和功率分配，最大化感知与通信速率的加权和。为解决复杂的优化问题，提出了一种两层随机位置（RP）算法，并结合贪婪策略的天线位置匹配（APM）算法以减少移动开销。仿真结果验证了MA在近场ISAC中的性能优势以及APM算法在降低移动成本方面的有效性。

> **摘要翻译:** 集成感知与通信（ISAC）被认为是下一代无线网络的核心技术。然而，现有的ISAC系统基于固定位置天线（FPA），在平衡感知和通信的权衡时不可避免地会带来性能损失。可移动天线（MA）技术通过实现灵活的天线移动，为增强ISAC性能提供了巨大潜力。尽管如此，利用更多的空间信道变化需要更大的天线移动区域，这可能会使收发信机之间的信道失效传统的远场假设。因此，本文利用MA来增强近场ISAC系统中的感知和通信能力，其中配备多根可移动天线的全双工基站（BS）可以在大型区域内移动，以同时感知多个目标并服务多个上行（UL）和下行（DL）用户进行通信。我们的目标是通过联合设计传输波束形成器、感知信号协方差矩阵、接收波束形成器、BS处MA位置以及UL功率分配来最大化感知和通信速率的加权和（WSR）。由此产生的优化问题具有挑战性。因此，我们提出了一种高效的两层随机位置（RP）算法来解决它。此外，为了减少移动延迟和成本，我们设计了一种基于贪婪策略的天线位置匹配（APM）算法，以最小化总MA移动距离。大量的仿真结果表明，在近场ISAC系统中部署MA可带来显著的性能提升。此外，结果还显示了所提出的APM算法在减少天线移动距离方面的有效性，这对于MA辅助的具有大型移动区域的近场ISAC系统来说，在节能和减少时间开销方面是有益的。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [7] [Fast and Efficient Merge of Sorted Input Lists in Hardware Using List Offset Merge Sorters](https://arxiv.org/abs/2507.08658)
> *使用列表偏移合并排序器在硬件中快速高效地合并已排序输入列表*

*Robert B. Kent, Marios S. Pattichis* | **Category: cs.AR, cs.DS, eess.IV** | **Updated: 2025-07-11**

**Keywords:** 硬件合并排序, 列表偏移合并排序器, FPGA, 排序算法, 效率

**Comment:** 

> **TL;DR:** 本文介绍了一种名为列表偏移合并排序器（LOMS）的新型硬件合并排序设备，它能比现有技术更快、更高效地将多个已排序输入列表合并为一个已排序输出列表，并且在资源利用方面优于某些替代方案，同时支持任意大小的输入列表。

**AI_Comments:** 本文提出了一种新颖的硬件合并排序方法，通过独特的列表偏移2D数组布局和分阶段排序，解决了传统Batcher排序器在处理不同大小列表时的设计复杂性问题，并优化了S2MS设备资源消耗大的缺点。其创新点在于结合了速度和资源效率，使得大型合并操作在FPGA中成为可能。论文通过具体的数据展示了其在速度上的显著提升，对硬件排序领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的硬件合并排序器（如Batcher的位元合并排序器和奇偶合并排序器）速度较慢，且设计复杂，尤其当输入列表大小不相等或不是2的幂时。虽然单级双向合并排序器（S2MS）在FPGA中速度最快，但它们往往占用大量LUT资源，导致大型设备难以实现。

**Method:** 本文引入了一种新的硬件合并排序设备，称为列表偏移合并排序器（LOMS）。在每个LOMS中，来自已排序输入列表的值被布置在一个2D输入设置数组中，每个输入列表的顺序相对于其他列表都有偏移。这些新设备通过一系列交替的列排序阶段和行排序阶段来处理输入设置数组，最终得到一个排序好的输出数组。LOMS双向排序器在第一阶段利用了单级双向合并排序器（S2MS）。LOMS和S2MS设备都能够合并任意混合大小的输入列表。

**Result:** LOMS双向排序器仅需2个合并阶段，比Kenneth Batcher的现有双向合并设备（位元合并排序器和奇偶合并排序器）快得多。LOMS双向设备比同类S2MS设备使用更少的资源，使得在给定FPGA中可以实现一些大型LOMS设备，而同类S2MS设备则无法容纳。一个列表偏移双向排序器将两个各含32个值的列表合并为64个值的已排序输出列表，耗时2.24纳秒，比同类Batcher设备提速2.63倍。一个LOMS三向合并排序器将3个各含7个值的已排序输入列表完全合并为21个值，耗时3.4纳秒，比同类现有三向合并设备提速1.36倍。

**Conclusion:** LOMS提供了一种在硬件中快速高效地合并已排序列表的新方法，通过创新的2D数组布局和分阶段排序，显著提升了合并速度并优化了资源利用，同时克服了传统Batcher排序器对输入列表大小的限制以及S2MS设备资源消耗大的问题。

> **ai_Abstract:** 本文提出了一种名为列表偏移合并排序器（LOMS）的新型硬件设备，用于高效合并多个已排序输入列表。LOMS通过将输入值布置在偏移的2D数组中，并利用交替的列/行排序阶段进行处理。实验证明，LOMS双向排序器比Batcher设备快2.63倍（32值列表），且比S2MS设备占用更少FPGA资源，同时支持任意大小的输入列表。LOMS三向排序器也显示出1.36倍的加速。这表明LOMS在速度和资源效率上均优于现有硬件合并排序方案。

> **摘要翻译:** 本文介绍了一套新的硬件合并排序设备，它们能够快速高效地将多个已排序输入列表合并成一个单一的已排序输出列表。在每个合并排序器中，来自已排序输入列表的值被布置在一个2D输入设置数组中，但每个已排序输入列表的顺序都相对于其他已排序输入列表有所偏移。在这些被称为列表偏移合并排序器（LOMS）的新设备中，一系列最小的列排序阶段与行排序阶段交替处理输入设置数组，形成最终输出数组，现在已按定义的排序顺序排列。LOMS双向排序器（合并2个已排序输入列表）仅需2个合并阶段，并且比Kenneth Batcher之前最先进的双向合并设备（位元合并排序器和奇偶合并排序器）显著更快。LOMS双向排序器在其第一阶段利用了最近引入的单级双向合并排序器（S2MS）。LOMS和S2MS设备都可以合并任意混合大小的输入列表，而Batcher的合并排序器除非两个输入列表相等且为2的幂，否则很难设计。S2MS设备本身在本次研究的目标FPGA设备中实现时是最快的双向合并排序器，但它们往往使用大量的LUT资源。LOMS双向设备比同类S2MS设备使用更少的资源，使得一些大型LOMS设备可以在给定的FPGA中实现，而同类S2MS设备则无法容纳。一个列表偏移双向排序器将两个各含32个值的列表合并为64个值的已排序输出列表，耗时2.24纳秒，比同类Batcher设备提速2.63倍。一个LOMS三向合并排序器，合并3个各含7个值的已排序输入列表，在3.4纳秒内完全合并21个值，比同类最先进的三向合并设备提速1.36倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [176] [GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction](https://arxiv.org/abs/2504.10240)
> *GNN-ACLP：基于图神经网络的模拟电路链接预测*

*Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Zhi Li, Yugui Lin, Pietro Lio, Shuai Wang* | **Category: cs.AR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 图神经网络, 模拟电路, 链接预测, 网表格式转换, 数据集

**Comment:** Code and data will be made available on request. V3 Update: Add
  Ablation Study and Discussion; Improve Introduction; Optimize Figures; Add
  references

> **TL;DR:** GNN-ACLP利用图神经网络、SEAL框架、Netlist Babel Fish工具和SpiceNetlist数据集，解决了模拟电路链接预测中拓扑利用不足、数据稀缺和格式兼容性差的问题，显著提高了预测精度和泛化能力。

**AI_Comments:** GNN-ACLP的创新性在于其结合了GNNs处理拓扑信息的能力、利用LLM解决数据格式兼容性问题，并构建了新的数据集以缓解数据稀缺。这种多方面的集成方法有效解决了模拟电路设计自动化中的核心挑战，尤其是在数据稀缺和格式多样性方面的贡献具有重要意义。其在跨数据集评估中保持高精度，表明了其强大的泛化和迁移学习能力，为未来的模拟电路设计工具提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有模拟电路链接预测方法面临三个主要挑战：1) 未充分利用电路图中的拓扑模式导致预测精度降低；2) 注释复杂性导致数据稀缺，影响模型泛化；3) 对各种网表格式的适应性有限。

**Method:** 本文提出了GNN-ACLP框架，一个基于图神经网络（GNNs）的框架，具有三项创新：1) 引入SEAL（子图、嵌入和属性用于链接预测）框架，实现端口级精度；2) 提出Netlist Babel Fish，一个利用检索增强生成（RAG）和大型语言模型（LLM）的网表格式转换工具，增强兼容性；3) 构建了SpiceNetlist，一个包含775个带注释电路的综合数据集，涵盖10种不同组件类别。

**Result:** 实验表明，GNN-ACLP在数据集内评估中，SpiceNetlist上精度提高了16.08%，Image2Net上提高了11.38%，Masala-CHAI上提高了16.01%。在跨数据集评估中，精度保持在92.05%至99.07%之间，展示了强大的特征迁移能力。

**Conclusion:** GNN-ACLP通过其创新的框架和组件，有效解决了模拟电路链接预测中的关键挑战，显著提高了预测精度和泛化能力，并展示了强大的跨数据集特征迁移能力。

> **ai_Abstract:** 本文提出了GNN-ACLP，一个基于图神经网络的框架，用于解决模拟电路链接预测中的拓扑利用不足、数据稀缺和格式兼容性差的问题。该框架通过引入SEAL实现端口级精度，开发Netlist Babel Fish工具增强网表格式兼容性，并构建了SpiceNetlist综合数据集。实验结果表明，GNN-ACLP在多个数据集上显著提高了预测精度，并在跨数据集评估中展现了强大的泛化能力和特征迁移能力。

> **摘要翻译:** 从不完整的网表中识别缺失的组件连接的电路链接预测对于自动化模拟电路设计至关重要。然而，现有方法面临三个主要挑战：1) 电路图中拓扑模式的利用不足降低了预测精度；2) 注释的复杂性导致数据稀缺，阻碍了模型的泛化；3) 对各种网表格式的适应性有限。
我们提出了GNN-ACLP，一个基于图神经网络（GNNs）的框架，具有三项创新来解决这些挑战。首先，我们引入了SEAL（子图、嵌入和属性用于链接预测）框架，并在电路链接预测中实现了端口级精度。其次，我们提出了Netlist Babel Fish，一个利用检索增强生成（RAG）和大型语言模型（LLM）的网表格式转换工具，以增强网表格式的兼容性。最后，我们构建了SpiceNetlist，一个包含775个带注释电路的综合数据集，涵盖10种不同组件类别。
实验表明，与基线相比，在数据集内评估中，SpiceNetlist上的精度提高了16.08%，Image2Net上提高了11.38%，Masala-CHAI上提高了16.01%，同时在跨数据集评估中精度保持在92.05%到99.07%之间，展现出强大的特征迁移能力。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [569] [CCSS: Hardware-Accelerated RTL Simulation with Fast Combinational Logic Computing and Sequential Logic Synchronization](https://arxiv.org/abs/2507.08406)
> *CCSS：具有快速组合逻辑计算和顺序逻辑同步的硬件加速RTL仿真*

*Weigang Feng, Yijia Zhang, Zekun Wang, Zhengyang Wang, Yi Wang, Peijun Ma, Ningyi Xu* | **Category: cs.AR, cs.DC** | **Updated: 2025-07-11**

**Keywords:** RTL仿真, 硬件加速, CCSS, 多核模拟, 组合逻辑

**Comment:** 

> **TL;DR:** CCSS是一个多核RTL仿真平台，通过专门的架构和编译策略加速组合逻辑计算和顺序逻辑同步，实现了快速编译和高仿真吞吐量，比现有技术快12.9倍。

**AI_Comments:** 该研究提出了一种名为CCSS的硬件加速RTL仿真平台，解决了当前RTL仿真中CPU性能瓶颈的问题。通过对组合逻辑和顺序逻辑的处理进行优化，CCSS在速度上取得了显著提升，这对于缩短芯片设计周期具有重要意义。然而，文中未提及CCSS在功耗和硬件成本方面的表现。

<details>
  <summary>Details</summary>

**Motivation:** CPU在RTL仿真中的速度限制已成为主要瓶颈，尤其是在需要快速编译的函数调试阶段。

**Method:** CCSS采用平衡的DAG划分方法和高效的布尔计算核来加速组合逻辑计算，并通过低延迟的片上网络（NoC）设计来同步顺序逻辑状态。

**Result:** 实验结果表明，CCSS比现有最先进的多核模拟器快了12.9倍。

**Conclusion:** CCSS通过专门的架构和编译策略，成功解决了CPU在RTL仿真中的速度瓶颈，实现了快速编译和高仿真吞吐量。

> **ai_Abstract:** CCSS是一个创新的多核RTL仿真平台，通过硬件加速技术解决了传统CPU仿真速度慢的问题。它通过专门的架构和编译策略，优化了组合逻辑计算和顺序逻辑同步，实现了快速编译和高仿真吞吐量，在实验中取得了高达12.9倍的加速效果。

> **摘要翻译:** 随着单芯片晶体管数量超过数百亿，RTL级仿真的复杂性呈指数级增长，通常将仿真活动延长到数月。在行业实践中，RTL仿真分为两个阶段：功能调试和系统验证。系统验证要求高仿真速度，通常使用FPGA加速，而功能调试依赖于快速编译，使多核CPU成为首选。然而，CPU有限的仿真速度已成为主要瓶颈。为了应对这一挑战，我们提出了CCSS，一个可扩展的多核RTL仿真平台，它实现了快速编译和高仿真吞吐量。CCSS通过专门的架构和编译策略加速组合逻辑计算和顺序逻辑同步。它采用平衡的DAG划分方法和高效的布尔计算核进行组合逻辑计算，并采用低延迟的片上网络（NoC）设计来有效地同步跨核心的顺序状态。实验结果表明，CCSS比现有最先进的多核模拟器快了12.9倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [233] [Supporting Intel(r) SGX on Multi-Package Platforms](https://arxiv.org/abs/2507.08190)
> *在多封装平台上支持英特尔SGX*

*Simon Johnson, Raghunandan Makaram, Amy Santoni, Vinnie Scarlata* | **Category: cs.DC, cs.CR** | **Updated: 2025-07-10**

**Keywords:** Intel SGX, 可信执行环境, 机密云计算, 多封装平台, 平台增强

**Comment:** 8 pages, 6 figures

> **TL;DR:** 本文讨论了在多封装平台上扩展Intel SGX以支持可编程、可扩展、高性能且安全的云端可信执行环境所需的平台增强功能。

**AI_Comments:** 本文强调了Intel SGX技术在从单插槽向多封装平台扩展以适应云规模应用时所面临的挑战和需求。其重要性在于提出需要针对多封装平台进行特定的平台增强，以确保SGX在云环境下的可扩展性、性能和安全性，这对于推动机密云计算的普及至关重要。创新点在于识别并指出多封装平台对SGX支持的特定需求。

<details>
  <summary>Details</summary>

**Motivation:** Intel SGX在客户端和单插槽服务器平台发布后，其在云计算中的应用潜力得到验证，尤其是在构建机密云计算方面。为了使SGX在多封装平台上满足云使用场景的需求，需要进一步的平台增强。

**Method:** 本文描述了作者认为必要的“额外的平台增强”来实现目标，但未具体说明这些增强的细节。

**Result:** Not mentioned in abstract

**Conclusion:** 为了在多封装平台上提供可扩展、高性能且安全的用户可编程可信执行环境，需要对平台进行额外的增强。

> **ai_Abstract:** 本文探讨了在多封装平台上扩展英特尔SGX（软件防护扩展）以支持云规模应用的需求。它指出，虽然SGX已在客户端和单插槽服务器上应用，且在云中构建机密计算环境展现出价值，但为了在多封装系统上实现可扩展、高性能和安全的用户可编程可信执行环境，还需要额外的平台增强。

> **摘要翻译:** 英特尔(r)软件防护扩展(SGX)最初发布于客户端平台，后来扩展到单插槽服务器平台。随着开发人员熟悉该技术的功能，其在云中的适用性得到了检验。各种云服务提供商(CSP)正在展示使用基于SGX的可信执行环境(TEE)创建机密云计算新范式的价值。本文描述了我们认为必要的额外平台增强功能，以实现在多封装平台上可扩展到云使用、具有高性能且安全的用户可编程可信执行环境。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [519] [Fast and Interactive Byzantine Fault-tolerant Web Services via Session-Based Consensus Decoupling](https://arxiv.org/abs/2507.08281)
> *通过基于会话的共识解耦实现快速和交互式的拜占庭容错 Web 服务*

*Ahmad Zaki Akmal, Azkario Rizky Pratama, Guntur Dharma Putra* | **Category: cs.DC** | **Updated: 2025-07-11**

**Keywords:** 拜占庭容错, Web 服务, 共识, 延迟, 交互性

**Comment:** 6 pages, 5 figures. Accepted to IEEE MetaCom 2025 as a short paper

> **TL;DR:** 该研究提出了一种新的两层架构，通过将交互式操作与共识最终确定分开，实现了低延迟（<200毫秒）的拜占庭容错 Web 服务，比仅使用共识层快四倍，同时保持强安全保证。

**AI_Comments:** 该研究通过引入一个新颖的两层架构有效地解决了 BFT 系统的延迟问题，该架构通过会话感知缓冲区和共识模拟实现了快速响应，同时保持了强 BFT 安全性。该方法在实际应用和性能评估方面都得到了验证，为 BFT 技术在延迟敏感场景中的应用开辟了新的可能性。然而，关于第二层共识模拟的容错能力及其对整体安全性的潜在影响，还需要进一步的探讨。

<details>
  <summary>Details</summary>

**Motivation:** 传统的拜占庭容错（BFT）Web 服务存在延迟问题，影响用户体验，限制了其在需要快速响应的交互式应用中的使用。

**Method:** 提出了一种新的两层架构：一个会话感知的交易缓冲区层（第二层），通过共识模拟提供即时反馈，并将批量操作定期提交到一个完全拜占庭容错的共识层（第一层）。

**Result:** 第二层操作比第一层操作快四倍，同时保持了端到端的交易完整性，响应时间低于200毫秒。

**Conclusion:** 该方法通过将交互式操作与共识最终确定分离，成功地解决了 BFT 系统中安全性和响应性之间的权衡问题，使得 BFT 能够应用于对延迟敏感的领域。

> **ai_Abstract:** 这项研究提出了一种创新的两层架构，用于构建快速且具有交互性的拜占庭容错（BFT）Web 服务。该架构通过引入一个会话感知的交易缓冲区层，在不牺牲 BFT 安全性的前提下，显著减少了延迟，实现了低于200毫秒的响应时间。通过将交互式操作的即时反馈与后台的共识最终确定分离，该系统在供应链管理和元宇宙等领域具有广泛的应用前景。

> **摘要翻译:** 拜占庭容错（BFT）Web 服务为分布式应用程序提供了关键的完整性保证，但面临着严重的延迟挑战，这阻碍了交互式用户体验。我们提出了一种新的两层架构，以解决 BFT 系统中安全性和响应性之间的基本矛盾。我们的方法引入了一个会话感知的交易缓冲区层（第二层），通过共识模拟向用户提供即时反馈，同时定期将批量操作提交到一个完全拜占庭容错的共识层（第一层）。通过将交互式操作与共识最终确定分离，我们的系统实现了低于200毫秒的响应式用户体验，同时保持了强大的 BFT 安全保证。我们通过一个供应链管理实现来证明我们架构的有效性，该实现要求操作员在多步骤工作流程中进行即时反馈和防篡改记录保存。我们的评估表明，我们的第二层操作比第一层操作快四倍，同时基本保持了端到端的交易完整性。我们的方法使得 BFT 应用程序能够应用于以前因延迟限制而被认为不切实际的领域，例如元宇宙环境，其中用户需要响应式交互和保证的状态一致性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [537] [Content-Oblivious Leader Election in 2-Edge-Connected Networks](https://arxiv.org/abs/2507.08348)
> *面向2边连接网络的无内容领导者选举*

*Yi-Jun Chang, Lyuting Chen, Haoran Zhou* | **Category: cs.DC** | **Updated: 2025-07-11**

**Keywords:** 无内容领导者选举, 异步网络, 2边连接, 完全缺陷, 静默终止

**Comment:** 

> **TL;DR:** 本研究提出了一种异步无内容领导者选举算法，可在任何2边连接的网络中实现，并能静默终止，消息复杂度为 O(m * N * ID_min)。该算法结合之前的模拟结果，证明了在完全缺陷环境中，无需预先指定的领导者即可模拟任何无噪声算法，从而反驳了之前的猜想。

**AI_Comments:** 这项研究在反驳“需要预先指定的领导者才能在完全缺陷网络中进行非平凡计算”的猜想方面取得了重要进展。提出的算法在理论上具有重要意义，因为它扩展了在更广泛的网络拓扑（即任何2边连接网络）中实现无内容领导者选举的能力。然而，算法的消息复杂度 O(m * N * ID_min) 相对于 O(n * ID_max) 的先前结果，在某些情况下可能较高，这可能是未来研究的一个方向，即寻找更优的消息复杂度算法。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究表明，在完全缺陷（无内容）的异步网络中，只有当网络是2边连接时，才能模拟任何无噪声算法，但前提是需要一个预先指定的领导者。然而，最近的研究反驳了这一必要性猜想，但仅限于特定拓扑结构。本研究旨在扩展这一发现，提出一种适用于任何2边连接网络的无内容领导者选举算法，以完全反驳之前的猜想。

**Method:** 提出了一种异步无内容领导者选举算法，该算法适用于任何2边连接的网络，并能静默终止。该算法的消息复杂度为 O(m * N * ID_min)，其中 m 是边的数量，N 是节点数量的已知上限，ID_min 是最小的节点 ID。

**Result:** 提出了一种异步无内容领导者选举算法，该算法在任何2边连接的网络中都能静默终止，消息复杂度为 O(m * N * ID_min)。结合先前关于模拟无噪声算法的研究，该结果表明在完全缺陷设置中，无需预先指定的领导者即可模拟任何无噪声算法。

**Conclusion:** 本研究提出的异步无内容领导者选举算法结合先前的工作，完全反驳了在完全缺陷环境中需要预先指定领导者的猜想，证明了在2边连接的网络中，可以实现无需预先指定领导者的非平凡计算。

> **ai_Abstract:** 本研究提出了一种用于2边连接网络的异步无内容领导者选举算法，该算法具有O(m * N * ID_min)的消息复杂度且能静默终止。该算法克服了先前研究的局限性，即需要预先指定的领导者，并通过结合已有的模拟结果，证明了在完全缺陷的异步网络中，可以实现无需预先指定领导者的非平凡计算。

> **摘要翻译:** Censor-Hillel、Cohen、Gelles 和 Sela（PODC 2022 & Distributed Computing 2023）研究了全缺陷异步网络，其中通信通道可能遭受极端形式的篡改错误，导致消息完全损坏。该模型等同于无内容计算，节点仅通过脉冲进行通信。他们表明，如果网络是2边连接的，那么任何在无噪声环境中运行的算法都可以被模拟在全缺陷环境中；否则，在全缺陷环境中不可能进行任何非平凡的计算。然而，他们的模拟需要一个预先指定的领导者，他们推测这对于任何非平凡的无内容任务都是必需的。最近，Frei、Gelles、Ghazy 和 Nolin（DISC 2024）反驳了这一猜想，至少在定向环拓扑的特例中是如此。他们设计了两个异步无内容领导者选举算法，其消息复杂度为 O(n · ID_max)，其中 n 是节点数，ID_max 是最大 ID。第一个算法在无定向环中稳定，而无需终止检测。第二个算法在定向环中静默终止，从而可以在领导者选举后执行模拟算法。在本工作中，我们提出了一种异步无内容领导者选举算法，该算法可以在任何2边连接的网络中静默终止，其消息复杂度为 O(m · N · ID_min)，其中 m 是边的数量，N 是节点数量的已知上限，ID_min 是最小的 ID。结合之前的模拟结果，我们的发现表明，任何来自无噪声设置的算法都可以在全缺陷设置中被模拟，而无需假设预先选择的领导者，从而完全反驳了原始猜想。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [553] [Carbon-Aware Workflow Scheduling with Fixed Mapping and Deadline Constraint](https://arxiv.org/abs/2507.08725)
> *面向具有固定映射和截止时间约束的碳感知工作流调度*

*Dominik Schweisgut, Anne Benoit, Yves Robert, Henning Meyerhenke* | **Category: cs.DC** | **Updated: 2025-07-11**

**Keywords:** 碳感知调度, 工作流调度, DAG, 绿色能源, CaWoSched

**Comment:** 40 pages, 17 figures. Accepted at ICPP 2025. Code available at:
  https://github.com/KIT-EAE/CaWoSched.git

> **TL;DR:** 该研究提出了一种名为CaWoSched的启发式框架，用于在数据中心调度工作流，以减少碳排放。该框架结合了多种贪婪方法和局部搜索技术，并在多处理器环境中解决了NP难题。实验结果表明，与基线算法相比，该启发式方法能显著节省碳排放。

**AI_Comments:** 该研究有效地解决了在数据中心调度工作流以减少碳排放的问题，特别是在多处理器环境中，该问题具有挑战性（NP难题）。提出的CaWoSched框架结合了多种启发式方法，并在实验中证明了其有效性。未来的工作可以进一步探索更优化的调度策略或考虑更复杂的约束条件。

<details>
  <summary>Details</summary>

**Motivation:** 为了减少数据中心工作负载（特别是具有依赖任务的工作流）在混合能源供应下的碳排放，研究提出了一种将任务执行时间转移到绿色能源充足时段的调度方法。

**Method:** 将问题形式化为具有给定映射和任务排序的调度问题。对于单处理器情况，问题可在多项式时间内解决。对于至少两个处理器的情况，问题为NP难题，因此提出了结合多种贪婪方法和局部搜索的启发式框架CaWoSched。同时设计了一个基线算法和一个基于ILP的精确解来评估16种启发式方法。

**Result:** 实验结果表明，与基线算法相比，所提出的启发式方法在碳排放方面实现了显著的节省。

**Conclusion:** 所提出的CaWoSched启发式框架能够有效地减少数据中心工作流的碳排放，尤其是在多处理器环境下，尽管该问题本身是NP难题。

> **ai_Abstract:** 本研究提出了一种用于工作流调度的碳感知方法，以减少数据中心因使用混合能源而产生的碳排放。研究将问题形式化为固定映射和截止时间约束下的调度问题，并针对多处理器场景提出了名为CaWoSched的启发式框架，该框架结合了贪婪方法和局部搜索。实验证明，该方法相比基线算法能显著减少碳排放。

> **摘要翻译:** 大型数据和计算中心消耗了世界能源消耗的相当大一部分。这些中心工作负载的一个重要子集是具有相互依赖任务的工作流，通常表示为有向无环图（DAG）。为了减少在具有混合（可再生和不可再生）能源供应的中心执行此类工作流所产生的碳排放，建议在可能的情况下将任务执行转移到具有足够绿色能源的时间段。为此，我们将上述问题形式化为具有给定映射和任务排序的调度问题。我们证明了在单处理器情况下，该问题可以在多项式时间内解决。然而，对于至少两个处理器，该问题变为NP难题。因此，我们提出了一种名为CaWoSched的启发式框架，它结合了几种贪婪方法和局部搜索。为了评估由不同组合产生的16种启发式方法，我们还设计了一个简单的基线算法和一个基于ILP的精确解。我们的实验结果表明，与基线相比，我们的启发式方法在碳排放方面提供了显著的节省。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [585] [Efficient Long Context Fine-tuning with Chunk Flow](https://arxiv.org/abs/2503.02356)
> *高效的块流长上下文微调*

*Xiulong Yuan, Hongtao Xu, Wenting Shen, Ang Wang, Xiafei Qiu, Jie Zhang, Yuqiong Liu, Bowen Yu, Junyang Lin, Mingzhen Li, Weile Jia, Yong Li, Wei Lin* | **Category: cs.DC** | **Updated: 2025-07-11**

**Keywords:** 长上下文微调, 大型语言模型, ChunkFlow, 分布式训练, 计算效率

**Comment:** 

> **TL;DR:** 该论文提出了一种名为ChunkFlow的新型训练方法，通过将输入序列重组为统一大小的块来解决长上下文微调中的效率和负载均衡问题，并在分布式训练中实现了显著的速度提升。

**AI_Comments:** 该研究提出了一种名为ChunkFlow的新颖训练方法，有效地解决了大型语言模型（LLMs）长上下文微调中的关键挑战，包括处理长尾分布的数据集和管理分布式训练中的可变序列长度问题。通过将输入序列重组为统一大小的块（ChunkFlow）并结合状态感知的调度机制，该方法不仅提高了计算效率和GPU资源利用率，还显著减少了训练时间，实验结果显示速度提升高达4.53倍。这项工作对于优化LLMs的训练过程具有重要意义，尤其是在处理长上下文数据时，并且其潜力可扩展到其他相关任务，如长上下文持续预训练。

<details>
  <summary>Details</summary>

**Motivation:** 现有长上下文微调方法未能解决长尾分布和可变序列长度在分布式训练中带来的负载不平衡和流水线气泡问题，导致训练性能低下和GPU资源利用率低。作者提出ChunkFlow来解决这些问题。

**Method:** ChunkFlow是一种以块为中心的训练方法，它通过合并短序列和拆分长序列来将输入序列重组为统一大小的块，从而实现最优的计算效率和训练输入的平衡。此外，ChunkFlow还采用了一种状态感知的块调度机制，确保峰值内存使用主要由块大小决定，而不是数据集中的最大序列长度。该机制与现有的流水线调度算法相结合，进一步提高了分布式训练的性能。

**Result:** 与Megatron-LM相比，ChunkFlow在长上下文微调LLM时速度最高可提高4.53倍。

**Conclusion:** ChunkFlow通过块重组和状态感知的块调度机制，有效解决了长上下文微调中的效率和分布式训练问题，显著提高了训练速度和GPU资源利用率，并有望应用于长上下文持续预训练等场景。

> **ai_Abstract:** ChunkFlow是一种创新的长上下文微调方法，通过将序列重组为统一大小的块并采用状态感知的调度机制，解决了现有方法在处理长尾分布和可变序列长度方面的低效率和分布式训练问题。实验证明，与Megatron-LM相比，ChunkFlow可将LLM的长上下文微调速度提高4.53倍。

> **摘要翻译:** 大型语言模型（LLMs）的长上下文微调涉及在主要由短序列和少量长序列组成的数据集上进行训练。然而，现有方法忽略了这种长尾分布，并采用了专门为长序列设计的训练策略。此外，这些方法未能解决分布式训练中可变序列长度带来的挑战，例如数据并行中的负载不平衡和流水线并行中的严重流水线气泡。这些问题导致了次优的训练性能和糟糕的GPU资源利用率。为了解决这些问题，我们提出了一种名为ChunkFlow的以块为中心的训练方法。ChunkFlow通过合并短序列和拆分长序列来将输入序列重组为统一大小的块。这种方法实现了最优的计算效率和训练输入之间的平衡。此外，ChunkFlow包含了一种状态感知的块调度机制，以确保训练期间的峰值内存使用主要由块大小决定，而不是数据集中的最大序列长度。将此调度机制与现有的流水线调度算法相结合，进一步提高了分布式训练的性能。实验结果表明，与Megatron-LM相比，ChunkFlow在LLMs的长上下文微调中速度最高可提高4.53倍。此外，我们相信ChunkFlow为更广泛的场景提供了一种有效的解决方案，例如包含可变长度序列的数据集中的长上下文持续预训练。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [601] [Mind the Memory Gap: Unveiling GPU Bottlenecks in Large-Batch LLM Inference](https://arxiv.org/abs/2503.08311)
> *留意内存差距：揭示大规模批次语言模型推理中的GPU瓶颈*

*Pol G. Recasens, Ferran Agullo, Yue Zhu, Chen Wang, Eun Kyung Lee, Olivier Tardieu, Jordi Torres, Josep Ll. Berral* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, GPU推理, 内存瓶颈, DRAM带宽, 批次配置顾问

**Comment:** Pol G. Recasens, Ferran Agullo: equal contribution. Paper accepted at
  IEEE CLOUD 2025

> **TL;DR:** 该研究通过GPU级分析发现，大规模批次语言模型推理的瓶颈在于DRAM带宽饱和，而非计算能力不足，并提出了一个批次配置顾问（BCA）来优化内存分配，以提高GPU利用率和吞吐量，尤其对小型模型有效。

**AI_Comments:** 这项研究通过深入的GPU级分析，挑战了关于LLM推理瓶颈的传统观点，指出了内存带宽饱和而非计算能力是关键问题。提出的BCA和模型复制策略具有实际应用价值，能够有效提升资源利用率，尤其对于资源受限的环境或小型模型而言。代码的公开也为社区提供了进一步研究和应用的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究通常认为大规模批次语言模型推理的性能瓶颈是计算能力，但本研究通过GPU级分析发现实际瓶颈是内存带宽饱和。

**Method:** 通过GPU级分析揭示了大规模批次语言模型推理的内存瓶颈，并提出了一个批次配置顾问（BCA）来优化内存分配，同时利用模型复制来提高服务吞吐量和GPU利用率。

**Result:** 研究发现大规模批次语言模型推理的瓶颈是DRAM带宽饱和，导致GPU计算能力未被充分利用。提出的BCA优化了内存分配，减少了GPU内存需求，同时提高了GPU利用率。

**Conclusion:** 大规模批次语言模型推理的瓶颈在于内存带宽饱和而非计算能力，提出的BCA通过优化内存分配和模型复制策略，能够有效提高GPU利用率和吞吐量，尤其对小型模型具有重要意义。

> **ai_Abstract:** 本研究通过对大型语言模型（LLM）推理进行GPU级分析，发现大规模批次推理的性能瓶颈并非计算能力，而是DRAM带宽饱和导致的内存限制。研究提出了一个批次配置顾问（BCA）来优化内存分配，减少GPU内存占用，并结合模型复制技术来提升GPU利用率和整体服务吞吐量，为优化LLM推理资源利用提供了新的解决方案，尤其对小型模型具有显著效益。

> **摘要翻译:** 大型语言模型已被广泛应用于各种任务，但其自回归生成特性在推理过程中常常导致资源利用效率低下。虽然批处理通常用于提高吞吐量，但性能增益在超过一定批次大小后会趋于平稳，尤其是在较小的模型中，这一现象通常被现有文献解释为转向计算密集型状态。在本研究中，通过深入的GPU级分析，我们揭示了大规模批次推理仍然受内存限制，由于DRAM带宽饱和成为主要瓶颈，导致大部分GPU计算能力未得到充分利用。为了解决这个问题，我们提出了一种批次配置顾问（BCA），它优化了内存分配，以最小的吞吐量影响减少了GPU内存需求。然后，释放的内存和未充分利用的GPU计算能力可以被并发工作负载利用。具体来说，我们使用模型复制来提高服务吞吐量和GPU利用率。我们的发现挑战了关于语言模型推理的传统假设，为提高资源利用率提供了新的见解和实用的策略，尤其是在较小的语言模型方面。代码可公开访问：https://github.com/FerranAgulloLopez/vLLMBatchingMemoryGap。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [26] [A Systematic Mapping Study on Open Source Agriculture Technology Research](https://arxiv.org/abs/2507.08103)
> *开源农业技术研究的系统性图谱研究*

*Kevin Lumbard, Vinod Kumar Ahuja, Matt Cantu Snell* | **Category: cs.CY** | **Updated: 2025-07-10**

**Keywords:** 开源农业技术, 系统性图谱研究, 数字农业, 信息系统, 研究趋势

**Comment:** 

> **TL;DR:** 本研究通过系统性图谱分析，探讨了开源农业数字技术，揭示了当前趋势和未来研究机会。

**AI_Comments:** 这项研究通过采用系统性图谱研究方法，对新兴的开源农业技术领域进行了初步探索，有助于识别该领域的研究现状和未来方向，对信息系统领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 农业数字技术中的开源运动正在兴起，但其对农业和农业数字技术的潜在影响尚未被充分探索。

**Method:** 本研究通过对现有开源农业数字技术研究进行系统性图谱分析来探索该领域。

**Result:** 该研究阐明了开源农业数字技术的当前趋势，并指出了未来的研究机会。

**Conclusion:** 本研究通过揭示当前趋势和未来研究机会，为信息系统研究做出了贡献。

> **ai_Abstract:** 这项研究通过对现有文献进行系统性图谱分析，探讨了开源农业数字技术领域。它旨在弥补对开源理念在农业技术中应用影响探索不足的空白，并为信息系统研究提供当前趋势和未来研究机会的见解。

> **摘要翻译:** 农业每年为美国经济贡献数万亿美元。数字技术是农业领域的颠覆性力量。开源运动开始在农业技术领域兴起，对未来农业和农业数字技术具有巨大的影响。开源与农业数字技术的融合在科学研究中是可观察的，但与农业技术相关的开源理念的影响尚未被探索。本研究通过对现有开源农业数字技术研究进行系统性图谱绘制，探索了开放农业数字技术。该研究通过阐明当前趋势和未来研究机会，为信息系统研究做出了贡献。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [46] [Effect of Static vs. Conversational AI-Generated Messages on Colorectal Cancer Screening Intent: a Randomized Controlled Trial](https://arxiv.org/abs/2507.08211)
> *静态与对话式AI生成信息对结直肠癌筛查意愿的影响：一项随机对照试验*

*Neil K. R. Sehgal, Manuel Tonneau, Andy Tan, Shivan J. Mehta, Alison Buttenheim, Lyle Ungar, Anish K. Agarwal, Sharath Chandra Guntuku* | **Category: cs.CY** | **Updated: 2025-07-10**

**Keywords:** AI, 结直肠癌筛查, 健康沟通, 随机对照试验, 大语言模型

**Comment:** 

> **TL;DR:** AI生成信息，特别是简洁的静态信息，能有效提高结直肠癌粪便检测意愿，优于专家材料，且对话式AI尽管互动时间更长，但并未比单一信息表现更好。

**AI_Comments:** 本论文强调了AI在健康沟通中的实际效用，特别是令人惊讶地发现，更简单、静态的AI信息在提高筛查意愿方面可以与更复杂的对话代理同样有效。这对于临床环境中的可扩展性具有重要意义。AI对粪便检测和结肠镜检查效果的区分也富有洞察力，表明AI的说服力可能因健康行为的侵入性或熟悉度而异。该研究侧重于“意愿”而非“完成筛查”是一个局限性，作者也承认这需要未来的工作来解决。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLM）聊天机器人在说服性沟通方面展现出潜力，但在临床环境中其真实世界的效用和可扩展性仍不确定。本研究旨在比较静态与对话式AI生成信息对结直肠癌筛查意愿的影响。

**Method:** 一项预先注册的随机对照试验，招募了915名未完成结直肠癌（CRC）筛查的美国成年人（45-75岁）。参与者被随机分为四组：无信息对照组、专家编写的患者材料组、单一AI生成信息组和动机性访谈聊天机器人组。AI组根据参与者的人口统计学信息定制内容。所有参与者需在其分配条件下停留至少三分钟。

**Result:** 与专家材料组（7.5分增益）相比，两种AI干预均显著增加了粪便检测意愿超过12分（12.9-13.8/100）（p<.001）。AI组在结肠镜检查意愿方面优于无信息对照组，但未优于专家材料组。值得注意的是，尽管参与者与聊天机器人互动时间平均多3.5分钟，但其在提高意愿方面并未优于单一AI信息。LLM对鲜为人知、侵入性较小的筛查方法（如粪便检测）更具说服力，而对根深蒂固的偏好（如结肠镜检查）效果可能较差。

**Conclusion:** 简洁、根据人口统计学定制的AI信息可能比复杂的对话代理和通用的耗时专家编写材料，为健康行为改变提供更具可扩展性和临床可行性的路径。LLMs对于侵入性较小的筛查方法（如粪便检测）更有效，但对于更常规的方法（如结肠镜检查）效果可能不佳。

> **ai_Abstract:** 这项随机对照试验调查了静态与对话式AI生成信息对915名美国成年人结直肠癌筛查意愿的影响。研究发现，单一AI信息和AI聊天机器人均显著提高了粪便检测意愿，优于专家编写材料和无信息对照组。然而，对于结肠镜检查意愿，AI信息仅优于对照组，未优于专家材料。重要的是，尽管互动时间更长，但对话式聊天机器人并未比简洁的单一AI信息表现更优。研究结果表明，简洁、根据人口统计学定制的AI信息可能为健康行为改变提供更具可扩展性和临床可行性的路径，特别是对于侵入性较小的筛查方法，并且可能比复杂的对话代理更有效。

> **摘要翻译:** 大语言模型 (LLM) 聊天机器人在说服性沟通方面显示出越来越大的前景。然而，它们的实际效用仍不确定，特别是在难以扩展持续对话的临床环境中。在一项预先注册的随机对照试验中，我们招募了915名从未完成结直肠癌 (CRC) 筛查的美国成年人（年龄45-75岁）。参与者被随机分为：(1) 无信息对照组，(2) 专家编写的患者材料组，(3) 单一AI生成信息组，或 (4) 动机性访谈聊天机器人组。所有参与者都被要求在其分配的条件下至少停留三分钟。两个AI组都使用参与者自我报告的人口统计数据（包括年龄和性别）来定制内容。与专家材料组的7.5分增益相比，两种AI干预都显著增加了粪便检测意愿超过12分（12.9-13.8/100）（所有比较p<.001）。尽管AI组在结肠镜检查意愿方面优于无信息对照组，但两者均未显示出优于专家材料的表现。值得注意的是，对于这两种结果，聊天机器人并没有在提高意愿方面优于单一AI信息，尽管参与者平均花费了大约3.5分钟与之互动。这些发现表明，简洁、根据人口统计学定制的AI信息可能比更复杂的对话代理和通用的耗时专家编写材料，为健康行为改变提供了一条更具可扩展性和临床可行性的路径。此外，LLM似乎对鲜为人知且侵入性较小的筛查方法（如粪便检测）更具说服力，但对于像结肠镜检查这样根深蒂固的偏好可能效果较差。未来的工作应研究个性化的哪些方面驱动行为改变，整合结构性支持是否能将这些适度的意愿增益转化为已完成的筛查，以及哪些健康行为对AI支持的指导最敏感。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [62] [Generative AI in Science: Applications, Challenges, and Emerging Questions](https://arxiv.org/abs/2507.08310)
> *科学中的生成式人工智能：应用、挑战与新兴问题*

*Ryan Harries, Cornelia Lawson, Philip Shapira* | **Category: cs.CY, cs.AI, K.4; I.2** | **Updated: 2025-07-11**

**Keywords:** 生成式人工智能, 科学应用, 挑战, 文献综述, 治理

**Comment:** 9 pages, 1 figure, 1 appendix

> **TL;DR:** 本文通过定性回顾探讨了生成式AI在科学中的应用、挑战和新兴问题，指出其快速采用但长期影响和治理仍不明确。

**AI_Comments:** 这篇论文对生成式AI在科学领域的现状进行了及时且重要的综述，特别是指出了其快速普及与长期影响和治理不确定性之间的矛盾，为未来研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过对现有文献的定性回顾，探讨生成式人工智能（GenAI）对科学实践的影响，特别是其应用、益处和挑战。

**Method:** 研究通过对OpenAlex出版数据库进行布尔搜索，筛选出与GenAI相关的科学文献（包括大型语言模型和ChatGPT），并对39篇高引用论文和评论进行审查和定性编码。

**Result:** 研究发现生成式AI在科学和科学实践中得到迅速采用，但其长期影响和使用与治理的不确定性依然存在。结果按GenAI在科学应用、科学写作、医疗实践以及教育和培训中的应用进行分类。

**Conclusion:** 该研究为生成式AI在科学中日益增长的作用提供了早期见解，并为该新兴领域的未来研究提出了问题。

> **ai_Abstract:** 本文通过对39篇高引用文献的定性回顾，探讨了生成式人工智能（GenAI）在科学实践中的应用、益处和挑战。研究发现GenAI在科学领域被迅速采用，但在其长期影响、使用和治理方面仍存在不确定性。该研究提供了早期洞察，并指出了未来研究方向。

> **摘要翻译:** 本文探讨了生成式人工智能（GenAI）对科学实践的影响，通过对精选文献进行定性回顾，探索其应用、益处和挑战。该回顾利用OpenAlex出版数据库，采用布尔搜索方法识别与GenAI（包括大型语言模型和ChatGPT）相关的科学文献。共审查并定性编码了39篇高引用论文和评论。结果按GenAI在科学应用、科学写作、医疗实践以及教育和培训中的应用进行分类。分析发现，尽管GenAI在科学和科学实践中被迅速采用，但其长期影响仍不明确，在使用和治理方面存在持续的不确定性。该研究为GenAI在科学中日益增长的作用提供了早期见解，并为该不断发展的领域的未来研究提出了问题。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [149] [AI Feedback Enhances Community-Based Content Moderation through Engagement with Counterarguments](https://arxiv.org/abs/2507.08110)
> *AI反馈通过反驳互动增强社区内容审核*

*Saeedeh Mohammadi, Taha Yasseri* | **Category: cs.CY, cs.SI** | **Updated: 2025-07-10**

**Keywords:** AI反馈, 内容审核, 社区笔记, 集体智能, 虚假信息

**Comment:** 

> **TL;DR:** 研究发现AI反馈，特别是反驳性反馈，能有效提升社区内容审核质量，有助于人机协作智能。

**AI_Comments:** 这项研究创新性地探索了AI在社区内容审核中的应用，特别是强调了“反驳性反馈”在提升内容质量方面的独特作用，这与传统的支持性或中立性反馈不同。它为AI如何促进“人机集体智能”提供了新的视角，并对未来内容审核系统的设计具有重要指导意义。其局限性可能在于实验环境的模拟性以及AI反馈生成机制的具体细节未在摘要中详述。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体平台信息传播广，但假信息问题严重。社区内容审核（如X的Community Notes）面临偏见和延迟等挑战。本研究旨在探索AI辅助混合审核框架，以改进内容审核。

**Method:** 本研究采用AI辅助混合审核框架，参与者接收AI生成的支持性、中立或反驳性反馈，并据此修改笔记。

**Result:** 结果显示，整合反馈能提高笔记质量，其中反驳性反馈带来的提升最显著。

**Conclusion:** AI反馈，尤其是反驳性反馈，能有效提升社区内容审核的质量，强调了多样化视角和直接参与在人机集体智能中的价值，为AI在政治内容审核中的作用提供了见解。

> **ai_Abstract:** 本研究旨在解决社交媒体平台虚假信息传播问题及现有社区审核机制的局限性。通过引入AI辅助的混合审核框架，研究发现AI反馈，特别是反驳性反馈，能显著提升用户提交内容的质量。这表明AI在促进人机集体智能和提升政治内容审核效率方面具有巨大潜力，并强调了设计时考量多样化视角的必要性。

> **摘要翻译:** 如今，社交媒体平台是新闻和政治传播的重要来源，但它们在传播虚假信息方面的作用引起了广泛关注。为此，这些平台实施了各种内容审核策略。其中一种方法是X上的Community Notes，它依赖众包事实核查并获得了关注，但面临党派偏见和验证延迟等挑战。本研究探索了一种AI辅助的混合审核框架，其中参与者会收到AI生成的关于其笔记的反馈——支持性、中立性或反驳性——并被要求相应地修改。结果表明，整合反馈提高了笔记的质量，其中反驳性反馈带来了最显著的提升。这强调了多样化视角和直接参与在人机集体智能中的价值。该研究为当前关于AI在政治内容审核中作用的讨论做出了贡献，突出了生成式AI的潜力以及知情设计的重要性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [150] [The Value of Prediction in Identifying the Worst-Off](https://arxiv.org/abs/2501.19334)
> *预测在识别最弱势群体中的价值*

*Unai Fischer-Abaigar, Christoph Kern, Juan Carlos Perdomo* | **Category: cs.CY, cs.LG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 机器学习, 弱势群体识别, 政策预测, 福利影响, 公平

**Comment:** 

> **TL;DR:** 本文探讨了机器学习预测在政府项目中识别和帮助弱势群体的价值，并与传统政策杠杆进行比较。

**AI_Comments:** 本文创新性地将机器学习预测应用于政府福利分配领域，旨在更精准地识别和帮助弱势群体。其重要性在于提供了一套数据驱动的分析框架和工具，赋能政策制定者做出更具原则性的决策，从而优化社会资源的公平分配。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习在政府项目中日益用于识别和支持最弱势个体，优先帮助高风险人群而非优化总体结果。本文旨在探讨预测在公平驱动背景下的福利影响，以及与扩大官僚能力等其他政策杠杆的比较。

**Method:** 通过数学模型和针对德国居民长期失业的真实案例研究。

**Result:** 研究结果提供了清晰的分析框架和实用的、数据驱动的工具，使政策制定者在设计此类系统时能够做出有原则的决策。

**Conclusion:** 预测在发现最弱势群体方面具有相对有效性，并为政策制定者提供了设计此类系统的分析框架和实用工具。

> **ai_Abstract:** 本文探讨了机器学习预测在政府福利项目中识别和支持最弱势群体的价值及其福利影响，并将其与扩大官僚能力等传统政策杠杆进行比较。研究通过数学模型和德国长期失业的案例研究，深入分析了预测在发现最弱势群体方面的相对有效性，并为政策制定者提供了制定此类系统时所需的分析框架和实用工具。

> **摘要翻译:** 机器学习在政府项目中越来越多地被用于识别和支持最弱势个体，优先为风险最高的人提供援助，而非优化总体结果。本文研究了预测在公平驱动背景下的福利影响，以及它们与扩大官僚能力等其他政策杠杆的比较。通过数学模型和针对德国居民长期失业的真实案例研究，我们全面了解了预测在发现最弱势群体方面的相对有效性。我们的研究结果提供了清晰的分析框架和实用的、数据驱动的工具，使政策制定者在设计这些系统时能够做出有原则的决策。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [170] [AI Safety Should Prioritize the Future of Work](https://arxiv.org/abs/2504.13959)
> *人工智能安全应优先考虑工作的未来*

*Sanchaita Hazra, Bodhisattwa Prasad Majumder, Tuhin Chakrabarty* | **Category: cs.CY, cs.AI, cs.CL, econ.GN, q-fin.EC** | **Updated: 2025-07-11**

**Keywords:** 人工智能安全, 工作未来, 收入不平等, 集体许可, 人工智能治理

**Comment:** 

> **TL;DR:** 当前人工智能安全努力过于狭隘，忽视了人工智能对未来工作和劳动力市场的深远影响，这加剧了不平等并助长了寻租行为。本文主张优先考虑以人为本的人工智能安全，建议提供过渡支持、通过集体许可实现公平补偿，并建立一个有利于劳动者的全球治理框架。

**AI_Comments:** 这篇论文的重要性在于它拓宽了人工智能安全的范围，超越了常见的存在风险、内容审核和操纵等问题，将对劳动力和收入不平等等关键社会经济影响纳入其中。它强调“有利于劳动者的框架”和“数据集体许可”为公平的人工智能发展提供了具体、创新的政策建议，挑战了当前闭源、寻租的主流做法。

<details>
  <summary>Details</summary>

**Motivation:** 本文认为当前的人工智能安全努力过于狭隘，主要侧重于有害内容过滤、行为操纵和存在风险，而忽视了人工智能对未来工作和社会长期发展轨迹的关键以人为本的影响。这种忽视可能导致收入不平等加剧和创新垄断等风险。

**Method:** 这是一份“立场文件”，通过“经济理论的视角”识别了人工智能对工作未来影响的风险，并提出了全面的过渡支持建议。它主张建立一个强大的国际版权体系，并辅以集体许可，同时建议建立一个有利于劳动者的全球人工智能治理框架。

**Result:** 本文强调了人工智能对人类生计的“跨期影响”以及“加剧收入不平等的劳动力市场结构性变化”。此外，它指出人工智能开发中主要利益相关者的“闭源方法类似于通过利用资源、滋生创造性劳动中的平庸以及垄断创新来寻求租金的行为”。

**Conclusion:** 本文主张“建立一个强大的国际版权体系，并辅以实施集体许可，以确保使用数据训练人工智能模型能够获得公平的报酬机制”。它“强烈建议建立一个有利于劳动者的全球人工智能治理框架，以增进共同繁荣和经济正义，同时减少技术债务”。

> **ai_Abstract:** 这篇立场文件认为，当前的人工智能安全努力过于狭隘，忽视了人工智能对未来工作和社会的长期重大影响。它运用经济理论来阐述人工智能如何加剧收入不平等，以及闭源人工智能开发如何导致寻租行为。该论文主张优先考虑以人为本的人工智能安全，建议为劳动力提供全面的过渡支持，建立一个强大的国际版权框架并辅以集体许可以实现公平的数据补偿，以及一个有利于劳动者的全球人工智能治理模式，以促进经济正义和共同繁荣。

> **摘要翻译:** 当前人工智能安全方面的努力主要侧重于过滤有害内容、防止操纵人类行为以及消除网络安全或生物安全方面的存在风险。尽管这些都很紧迫，但这种狭隘的关注忽视了塑造社会长期发展轨迹的关键以人为本的考虑。在这份立场文件中，我们指出了忽视人工智能对未来工作影响的风险，并建议提供全面的过渡支持，以促进具有人类能动性的有意义劳动的演变。我们通过经济理论的视角，强调了人工智能对人类生计的跨期影响以及劳动力市场中加剧收入不平等的结构性变化。此外，人工智能开发中主要利益相关者的闭源方法类似于通过利用资源、滋生创造性劳动中的平庸以及垄断创新来寻求租金的行为。为了解决这个问题，我们主张建立一个强大的国际版权体系，并辅以实施集体许可，以确保使用数据训练人工智能模型能够获得公平的报酬机制。我们强烈建议建立一个有利于劳动者的全球人工智能治理框架，以增进共同繁荣和经济正义，同时减少技术债务。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [195] [Addressing Pitfalls in Auditing Practices of Automatic Speech Recognition Technologies: A Case Study of People with Aphasia](https://arxiv.org/abs/2506.08846)
> *解决自动语音识别技术审计实践中的缺陷：以失语症患者为例*

*Katelyn Xiaoying Mei, Anna Seo Gyeong Choi, Hilke Schellmann, Mona Sloane, Allison Koenecke* | **Category: cs.CY, cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 自动语音识别审计, 失语症, 文本标准化, 性能评估, 词错误率

**Comment:** 

> **TL;DR:** 本文指出了现有ASR审计的三个主要缺陷，提出了一个更全面的审计框架，并通过对失语症患者的案例研究发现ASR对他们的表现持续较差，呼吁采用更稳健的审计实践。

**AI_Comments:** 本文的创新之处在于系统地指出了现有ASR审计实践中的三个具体且关键的缺陷，并提出了一个更全面的审计框架来解决这些问题。其重要性体现在强调了ASR技术公平性对边缘化群体（如失语症患者）的关键影响，并通过实际案例研究验证了这些缺陷导致的不公平性能。这对于推动ASR技术的发展和应用具有重要的指导意义，特别是提醒开发者和审计者在评估ASR系统时需考虑更细致的用户群体差异和更全面的评估指标。

<details>
  <summary>Details</summary>

**Motivation:** 自动语音识别（ASR）系统日益普及，需要稳健且标准化的审计方法来确保高质量和公平的转录。这对于依赖ASR系统进行日常生活的言语和语言障碍（如失语症）患者尤为关键。现有ASR审计程序存在缺陷，未能充分评估ASR系统对这些弱势群体的表现。

**Method:** 本研究首先识别了现有标准ASR审计程序中的三个主要缺陷：1) 数据预处理中单一的文本标准化方法；2) 仅显示高层级人口统计学发现，忽视细微的人口统计学子群和声学协变量；3) 依赖单一的词错误率（WER）指标，未能捕获生成式AI模型的错误。然后，作者提出了一个更全面的审计框架来解决这些缺陷，并通过对六个流行ASR系统在失语症患者中的表现进行案例研究来验证其结果。

**Result:** 案例研究发现，与对照组相比，ASR系统对失语症患者的表现持续较差。此外，通过解决现有审计中的三个缺陷，作者展示了如何影响审计结果。

**Conclusion:** 现有ASR审计实践存在显著缺陷，尤其是在评估对言语障碍人群的影响方面。本文提出的更全面的审计框架能够更好地揭示ASR系统对失语症患者的性能不足。研究呼吁从业者实施更稳健且灵活的ASR审计实践，以适应快速变化的ASR环境。

> **ai_Abstract:** 本文探讨了自动语音识别（ASR）技术在审计实践中存在的缺陷，尤其关注其对失语症患者的影响。研究指出当前ASR审计存在三大不足：单一的文本标准化方法掩盖了性能变异性且可能与用户偏好不符；对人口统计学差异的分析不够细致；以及过度依赖词错误率（WER）而忽略了生成式AI模型可能产生的幻觉错误。作者提出了一个更全面的审计框架来解决这些问题，并通过对六个ASR系统针对失语症患者的案例研究，发现ASR对失语症患者的表现持续劣于对照组。研究强调了实施更稳健、灵活的ASR审计实践的必要性。

> **摘要翻译:** 自动语音识别（ASR）已将日常任务从视频转录到职场招聘。ASR系统日益增长的使用需要稳健和标准化的审计方法，以确保自动化转录的高质量和公平性。这对于可能过度依赖ASR系统来应对日常生活的言语和语言障碍（如失语症）患者来说尤为关键。在这项工作中，我们识别了现有标准ASR审计程序中的三个缺陷，并通过对六个流行ASR系统在失语症患者中表现的案例研究，展示了解决这些缺陷如何影响审计结果。首先，审计通常在数据预处理过程中遵循单一的文本标准化方法，这(a)掩盖了应用不同标准化方法时ASR性能的变异性，并且(b)可能与用户——特别是来自边缘化言语社区的用户——希望其转录被标准化的方式不一致。其次，审计通常显示高层级的人口统计学发现，而没有进一步考虑(a)更细微的人口统计学子群和(b)捕获输入音频声学信息的相关协变量之间的性能差异。第三，审计通常依赖单一的黄金标准指标——词错误率，这未能完全捕获生成式AI模型（如转录幻觉）产生的错误程度。我们提出了一个更全面的审计框架，该框架考虑了这三个缺陷，并在我们的案例研究中例证了其结果，发现失语症患者的ASR性能相对于对照组持续较差。我们呼吁从业者实施这些稳健的ASR审计实践，使其对快速变化的ASR格局保持灵活性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [114] [EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification](https://arxiv.org/abs/2507.08184)
> *EP-GAT：基于能量的并行图注意力神经网络用于股票趋势分类*

*Zhuodong Jiang, Pengju Zhang, Peter Martin* | **Category: cs.CE, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 图神经网络, 股票趋势分类, 动态图, 并行注意力, 能量模型

**Comment:** Accepted by IJCNN 2025, oral presentation

> **TL;DR:** EP-GAT是一个新的基于图神经网络的方法，通过动态股票图和并行图注意力机制来预测股票未来走势，解决了现有方法在建模股票间动态依赖和保留层级特征方面的不足，并在多个真实世界数据集上表现优异。

**AI_Comments:** EP-GAT的创新之处在于其动态股票图的构建（利用能量差和玻尔兹曼分布）以及并行图注意力机制，这有效地解决了传统图神经网络在股票预测中面临的静态依赖建模和层级特征保留的挑战。其在多个真实数据集上的优异表现证明了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于图神经网络的股票预测方法通常依赖静态或手动定义的因素来建模股票之间不断变化的相互依赖关系，并且难以保留股票内部的层级特征。

**Method:** 本文提出了基于能量的并行图注意力神经网络（EP-GAT）。首先，它利用股票间的能量差和玻尔兹曼分布生成动态股票图，以捕捉不断演变的股票间相互依赖关系。然后，提出一种并行图注意力机制来保留股票内部的层级动态。

**Result:** 在五个真实世界数据集（包括美国和英国股市）上的广泛实验表明，EP-GAT在测试期间的各种指标上始终优于五个具有竞争力的基线。消融研究和超参数敏感性分析进一步验证了所提出方法中每个模块的有效性。

**Conclusion:** EP-GAT通过其动态图构建和并行图注意力机制，有效解决了现有图神经网络在股票趋势预测中面临的挑战，并在多个真实世界数据集上展现出卓越的性能。

> **ai_Abstract:** 本文提出了一种名为EP-GAT的基于能量的并行图注意力神经网络，用于股票趋势分类。该方法通过引入基于能量差和玻尔兹曼分布的动态股票图来捕捉股票间不断变化的依赖关系，并设计了并行图注意力机制以保留股票内部的层级特征。实验结果表明，EP-GAT在多个真实世界股票数据集上显著优于现有基线方法。

> **摘要翻译:** 图神经网络在预测股票走势方面表现出色，这得益于学习股票之间复杂的相互依赖关系和股票内部的动态。现有基于图神经网络的方法通常依赖静态或手动定义的因素来建模股票之间不断变化的相互依赖关系。此外，这些工作往往难以保留股票内部的层级特征。为了弥补这些不足，本文提出了一种新颖的基于能量的并行图注意力神经网络（EP-GAT），用于预测多只股票的未来走势。首先，它利用股票间的能量差和玻尔兹曼分布生成动态股票图，捕捉不断演变的股票间相互依赖关系。然后，提出一种并行图注意力机制来保留股票内部的层级动态。在五个真实世界数据集（包括美国股市的纳斯达克、纽约证券交易所、标准普尔以及英国股市的富时、伦敦证券交易所）上进行了广泛的实验，以验证所提出方法的有效性。实验结果表明，EP-GAT在测试期间的各种指标上始终优于五个具有竞争力的基线。消融研究和超参数敏感性分析进一步验证了所提出方法中每个模块的有效性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [134] [Evaluating diversion and treatment policies for opioid use disorder](https://arxiv.org/abs/2311.05076)
> *评估阿片类药物使用障碍的转介和治疗政策*

*Veronica M. White, Laura A. Albert* | **Category: cs.CE** | **Updated: 2025-07-10**

**Keywords:** 阿片类药物使用障碍, 离散事件模拟, 政策评估, 成本效益, 社区韧性

**Comment:** 

> **TL;DR:** 该研究使用离散事件模拟模型评估了三种阿片类药物使用障碍治疗政策（逮捕转介、再入案件管理和过量转介），并发现成功转介合格个体20%以上的治疗政策可以建立更具韧性的社区，并显著降低社会成本。

**AI_Comments:** 这篇论文通过引入离散事件模拟模型来评估复杂的公共卫生政策，具有创新性。它量化了不同转介和治疗政策的社会成本效益，为决策者提供了基于数据的洞察。其重要性在于为应对阿片类药物危机提供了可操作的建议，特别是强调了多策略结合的必要性。局限性可能在于模型依赖于历史数据和特定的地理区域，其结果的普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 美国阿片类药物危机在2022年导致81,806人死亡，并使医院、治疗机构和执法部门不堪重负，导致许多阿片类药物使用者未能获得或完成所需治疗，反而频繁与医疗或刑事司法系统互动。因此，需要评估有效的干预政策。

**Method:** 本文引入了一个离散事件模拟模型，用于评估三种阿片类药物使用障碍治疗政策：逮捕转介、再入案件管理和过量转介。研究使用了2011年至2019年威斯康星州戴恩县的公开数据，预测了截至2032年与阿片类药物相关的结果。通过分析多种政策组合的实施情况，提供了一个评估不同实施层面政策的通用框架。

**Result:** 研究结果表明，通过利用治疗服务并成功转介至少20%符合条件的个体的治疗政策，可以建立更具阿片类药物韧性的社区。当实施更多政策和/或向更多个体提供政策时，效益会增加，其中过量转介的影响最大，其次是再入案件管理，逮捕转介的影响最小。从2023年到2032年，十年累积社会总成本的统计学显著减少范围为3900万美元至5.84亿美元（不包括政策实施成本）。

**Conclusion:** 为了扭转社区内的阿片类药物危机，治疗政策可能需要与其他策略相结合，例如减少危害、减少供应和预防使用。

> **ai_Abstract:** 本研究通过构建一个离散事件模拟模型，评估了三种针对阿片类药物使用障碍的治疗政策：逮捕转介、再入案件管理和过量转介。利用威斯康星州戴恩县2011-2019年的数据，模型预测了未来阿片类药物相关结果。研究发现，能够成功转介至少20%符合条件的个体的治疗政策，特别是结合多项政策时，能显著降低社会成本，并有助于构建更具韧性的社区。其中，过量转介政策的影响最大。论文强调，单一治疗政策不足以完全解决危机，需结合其他策略。

> **摘要翻译:** 美国（US）阿片类药物危机在2022年导致81,806人死亡。由于应对危机所需的巨大资源和程序，它使医院、治疗机构和执法部门不堪重负。因此，许多阿片类药物使用者从未获得或完成他们所需的治疗，而是与医院或刑事司法系统发生多次互动。本文引入了一个离散事件模拟模型，评估了三种阿片类药物使用障碍治疗政策：逮捕转介、再入案件管理和过量转介。研究使用了2011年至2019年威斯康星州戴恩县的公开数据，预测了截至2032年与阿片类药物相关的结果。通过分析多种政策组合的实施情况，该研究提供了一个评估不同实施层面政策的通用框架。结果表明，通过利用治疗服务并成功转介至少20%符合条件的个体的治疗政策，可以建立更具阿片类药物韧性的社区。当实施更多政策和/或向更多个体提供政策时，效益会增加，其中过量转介的影响最大，其次是再入案件管理，逮捕转介的影响最小。从2023年到2032年，十年累积社会总成本的统计学显著减少范围为3900万美元至5.84亿美元（不包括政策实施成本）。为了扭转社区内的阿片类药物危机，治疗政策可能需要与其他策略相结合，例如减少危害、减少供应和预防使用。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [154] [Optimizing wheel loader performance -- an end-to-end approach](https://arxiv.org/abs/2501.06583)
> *优化轮式装载机性能——一种端到端的方法*

*Koji Aoshima, Eddie Wadbro, Martin Servin* | **Category: cs.CE, cs.SY, eess.SY** | **Updated: 2025-07-10**

**Keywords:** 轮式装载机, 端到端优化, 世界模型, 深度神经网络, 树搜索

**Comment:** 18 pages, 11 figures

> **TL;DR:** 研究提出一种端到端优化方法，结合世界模型和前瞻树搜索，显著提升轮式装载机在矿山和建筑工地装载任务的效率。

**AI_Comments:** 这项研究通过引入世界模型和前瞻树搜索，为轮式装载机的自动化装载任务提供了一种新颖且有效的端到端优化方案。其创新之处在于结合了预测未来状态的能力和序列决策的优化，克服了传统方法对当前状态的短视。这种方法在实际应用中具有重要意义，可以显著提高矿山和建筑作业的效率和自动化水平。

<details>
  <summary>Details</summary>

**Motivation:** 自动化轮式装载机的装载任务是一个具有挑战性的规划问题，因为每次装载的性能都依赖于料堆状态，而料堆状态又受之前装载的影响。研究旨在优化这一过程。

**Method:** 采用端到端优化方法，考虑未来的装载结果和运输成本。使用基于深度神经网络训练的世界模型预测料堆状态演变和装载性能。通过前瞻树搜索优化装载动作序列，评估数千个动作候选。

**Result:** 在15次连续装载的范围内，前瞻树搜索比贪婪策略效率高6%，比使用为标称情况优化的固定装载控制器效率高14%。

**Conclusion:** 前瞻树搜索结合世界模型的方法能够显著提高轮式装载机在复杂动态环境下的装载效率，优于传统的贪婪策略和固定控制器。

> **ai_Abstract:** 本文提出一种端到端优化方法，旨在提高轮式装载机在动态环境下的装载效率。该方法通过结合基于深度神经网络训练的世界模型来预测料堆状态和装载性能，并利用前瞻树搜索优化装载动作序列。实验结果表明，在15次连续装载任务中，该方法比贪婪策略和固定控制器分别提高了6%和14%的效率。

> **摘要翻译:** 轮式装载机在矿山和建筑工地反复将土壤从料堆装载到接收器。自动化这项任务提出了一个具有挑战性的规划问题，因为每次装载的性能都取决于料堆状态，而料堆状态又取决于之前的装载。我们研究了一种端到端优化方法，该方法考虑了未来的装载结果以及料堆和装载接收器之间的运输成本。为了预测料堆状态的演变和装载性能，我们使用世界模型，该模型利用在大量模拟装载周期上训练的深度神经网络。前瞻树搜索通过评估数千个动作候选的性能来优化装载动作的序列，这些候选在预测的料堆状态下递归地扩展到后续动作候选。测试结果表明，在15次连续装载的范围内，前瞻树搜索比总是选择使当前单次装载性能最大化的贪婪策略效率高6%，比使用为标称情况优化的固定装载控制器效率高14%。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [178] [A Family of Sequences Generalizing the Thue Morse and Rudin Shapiro Sequences](https://arxiv.org/abs/2505.20547)
> *推广Thue-Morse序列和Rudin-Shapiro序列的一个序列家族*

*Russell Jay Hendel* | **Category: cs.FL, 68Q45** | **Updated: 2025-07-11**

**Keywords:** 自动序列, Thue-Morse序列, Rudin-Shapiro序列, 确定性有限自动机, 2-核

**Comment:** Version 3: Adds results about squares; removes many (inexcusable)
  typos; reformats equations so that they align; improved proofs; added remarks
  and concluding section comparing families of sequences to regular and
  synchronized sequence as a method of extending automatic sequences. Version 2
  added results about palindromes. Next version will add results about borders

> **TL;DR:** 本文引入了一个推广Thue-Morse序列和Rudin-Shapiro序列的新序列家族$s_m$，并证明了其自动性及相关性质。

**AI_Comments:** 本文通过引入一个参数$m$来推广了两个著名的自动序列（Thue-Morse和Rudin-Shapiro），形成了一个新的序列家族$s_m$。其创新之处在于通过定义$s_{m,n}$的规则，系统地将已知的序列特性扩展到更一般的框架。研究不仅证明了这些新序列的自动性，还深入分析了它们的计算复杂性（DFA状态数）和结构特性（2-核、前缀区分）。通过将二进制字符串操作与整数运算建立对应关系，并结合计算工具进行探索，该研究提供了一个严谨且全面的分析方法。其重要性在于为自动序列理论增添了一个新的可研究家族，并为理解这些序列的内在结构提供了更广阔的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是定义并研究一个推广了著名的Thue-Morse序列和Rudin-Shapiro序列的序列家族$s_m$，并探索其自动序列特性。

**Method:** 研究方法基于二进制字符串在连接操作下与整数在加法和乘法下的对应关系。此外，还利用Mathematica和Walnut进行模式的探索性分析。

**Result:** 研究结果表明，对于每个$m	ext{≥}1$，序列$s_m$是自动的；接受$s_m$的最小DFA有$2m$个状态；长度为$2^{m-1}$的前缀足以区分$s_m$的2-核中的所有序列；以及$s_m$的2-核序列的长度为$2^{m-1}$的前缀的特征函数可以使用Vile和Jacobsthal序列来表述。此外，论文还提出了关于$s_m$的最大游程、回文、平方阶和边界的结果，推广了$s_1$和$s_2$的类似结果。

**Conclusion:** 本文的结论是，自动序列家族是一个富有成效的概念，也是一个有用的序列群，它扩展了自动序列，类似于正则序列和同步序列。

> **ai_Abstract:** 本文引入了一个通过统计二进制表示中特定子串出现次数的奇偶性来定义的新序列家族$s_m$，该家族推广了Thue-Morse序列（$m=1$）和Rudin-Shapiro序列（$m=2$）。研究证明了$s_m$的自动性，确定了其最小DFA的状态数，并揭示了2-核序列的区分特性及其与Vile和Jacobsthal序列的联系。此外，论文还分析了该序列家族的最大游程、回文等组合性质，并强调了自动序列家族作为扩展自动序列的重要概念。

> **摘要翻译:** 对于$m 	ext{≥} 1$，令$P_m =1^m$，即$m$个1组成的二进制字符串。进一步定义无限序列$s_m$，$s_{m,n} = 1$当且仅当$n$的二进制表示中$P_m$的（可能重叠的）出现次数为奇数，$n 	ext{≥} 0$。对于$m=1,2$，$s_m$分别是Thue-Morse序列和Rudin-Shapiro序列。本文表明，对于每个$m	ext{≥}1$，(i) $s_m$是自动的；(ii) 接受$s_m$的最小DFA（确定性有限自动机）有$2m$个状态；(iii) 仅需使用长度为$2^{m-1}$的前缀即可区分$s_m$的2-核中的所有序列；以及(iv) $s_m$的2-核序列的长度为$2^{m-1}$的前缀的特征函数可以使用Vile和Jacobsthal序列来表述。证明基于二进制字符串在连接操作下与整数在加法和乘法下的对应关系。Mathematica和Walnut均用于模式的探索性分析。本文提出了关于$s_m$的最大游程、回文、平方阶和边界的结果，推广了$s_1$和$s_2$的类似结果。在结论中，我们提出自动序列家族是一个富有成效的概念，也是一个有用的序列群，它扩展了自动序列，类似于正则序列和同步序列。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [270] [Deep Reinforcement Learning in Applied Control: Challenges, Analysis, and Insights](https://arxiv.org/abs/2507.08196)
> *深度强化学习在应用控制中的挑战、分析与见解*

*Klinsmann Agyei, Pouria Sarhadi, Daniel Polani* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-10**

**Keywords:** 深度强化学习, 应用控制, 比较分析, 实际应用, 局限性

**Comment:** 

> **TL;DR:** 深度强化学习在模拟和游戏环境中取得了显著进展，但在实际应用中仍面临挑战。本文通过对四种基准问题的比较分析，旨在阐明其在应用控制中的实际能力和局限性。

**AI_Comments:** 这篇论文的重要性在于它直接解决了深度强化学习从理论和模拟环境向实际应用过渡的关键障碍。通过系统地比较分析，它旨在提供关于DRL在现实世界控制问题中性能的量化见解，这对于推动DRL在工业和工程领域的实际部署至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习（DRL）在模拟和游戏环境中表现出色，但其在现实世界应用中的部署仍受限。在实际部署之前，需要对其在应用控制问题上的性能有扎实且定量的理解。

**Method:** 本文对深度强化学习方法在四个不同的基准问题上进行了比较分析，并提供了实现结果。

**Result:** 分析旨在阐明深度强化学习方法在应用控制设置中的实际能力和局限性。具体结果未在摘要中提及。

**Conclusion:** 摘要未明确给出研究的最终结论，但指出分析旨在揭示深度强化学习在应用控制中的实际能力和局限性。

> **ai_Abstract:** 本文探讨了深度强化学习（DRL）在应用控制领域的挑战与潜力。尽管DRL（如DQN）在模拟和游戏环境中取得了显著成功，但在将其应用于现实世界问题之前，需要对其性能有深入的定量理解。为此，论文对DRL方法在四个不同的基准控制问题上进行了比较分析，旨在系统地评估并揭示其在实际应用中的能力和局限性。

> **摘要翻译:** 在过去的十年中，采用深度神经网络来提升传统强化学习的性能取得了显著进展。一个重要的里程碑是深度Q网络（DQN）的发展，它在一系列Atari游戏中达到了人类水平的表现，展示了深度学习稳定和扩展强化学习的潜力。随后，连续控制算法的扩展为控制领域开辟了新的范式，这种范式在近期文献中比任何经典控制方法都受到了更广泛的关注。这些发展还展示了推动数据驱动、无模型控制算法以及实现更高水平自主性的巨大潜力。然而，这些方法的应用在很大程度上仍局限于模拟和游戏环境，目前正在努力将其扩展到现实世界应用。在实现此类部署之前，需要对它们在应用控制问题上的性能有扎实且定量的理解。本文对这些方法在四个不同的基准问题上进行了比较分析，并提供了实现结果。这项分析提供了一项严格而系统的评估，旨在阐明深度强化学习方法在应用控制设置中的实际能力和局限性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [289] [Maneuver Detection via a Confidence Dominance Maneuver Indicator](https://arxiv.org/abs/2507.08234)
> *通过置信度优势机动指示器进行机动检测*

*Xingyu Zhou, Roberto Armellin, Laura Pirovano, Dong Qiao, Xiangyu Li* | **Category: eess.SY, astro-ph.IM, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 机动检测, 置信度指示器, 航天器轨迹, 轨道估计, 多项式优化

**Comment:** 

> **TL;DR:** 该论文提出了一种基于置信度优势机动指示器（CDMI）的新型航天器机动检测方法，通过比较轨道状态估计和观测似然的置信水平来识别机动，实现了高精度和计算效率。

**AI_Comments:** 该论文的创新之处在于提出了一种基于置信度比较的机动指示器（CDMI），并通过集成方法实现了置信水平选择的自动化，从而显著提高了检测精度和计算效率。这对于提升航天器轨迹的安全性和可预测性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确高效的机动检测对于确保航天器轨迹的安全性和可预测性至关重要。

**Method:** 本文提出了一种置信度优势机动指示器（CDMI），通过设置状态估计的置信水平并计算观测的最大似然及其置信水平来比较轨道状态估计和观测似然的置信水平。当观测的置信水平超过状态估计的置信水平时，CDMI会标记机动。为了高效计算CDMI，开发了一种利用凸优化和多项式近似的递归多项式优化方法。此外，还开发了一种集成CDMI方法，以消除手动选择状态置信水平的需要。

**Result:** 所提出的集成CDMI方法可以实现高达99.33%的检测精度，比现有方法至少高出10%，同时大幅降低了计算成本。

**Conclusion:** 所提出的集成CDMI方法在航天器机动检测方面表现出显著的准确性和效率提升，增强了鲁棒性和实际适用性。

> **ai_Abstract:** 本文提出了一种用于航天器机动检测的新型方法，该方法基于置信度优势机动指示器（CDMI）。CDMI通过比较轨道状态估计和观测似然的置信水平来标记机动。为了提高效率和鲁棒性，论文开发了一种递归多项式优化方法以及一种集成CDMI方法，以消除手动选择置信水平的需求。仿真结果表明，所提出的集成CDMI方法能够达到99.33%的检测精度，比现有方法高出至少10%，同时显著降低了计算成本。

> **摘要翻译:** 准确高效的机动检测对于确保航天器轨迹的安全性和可预测性至关重要。本文提出了一种基于比较轨道状态估计和观测似然置信水平的新型机动检测方法。首先，通过为状态估计设置置信水平并计算观测的最大似然及其置信水平，提出了一种置信度优势机动指示器（CDMI）。当观测的置信水平超过状态估计的置信水平时，CDMI会标记机动，这表明在无机动假设下观测不太可能，同时保持与先前状态估计置信度的一致性。为了高效计算观测的最大似然并获得CDMI，开发了一种递归多项式优化方法，该方法利用了凸优化和多项式逼近。此外，开发了一种集成CDMI方法，以消除手动选择状态置信水平的需要。集成CDMI方法在保持高检测精度的同时，提供了机动可能性的指示，从而增强了鲁棒性和实际适用性。所提出的基于CDMI的机动检测方法的性能与最优控制距离度量和两种基于混合的方法进行了评估。仿真结果表明，所提出的集成CDMI方法可以实现高达99.33%的检测精度，比竞争方法至少高出10%，同时大幅降低了计算成本。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [310] [Neural Parameter-varying Data-enabled Predictive Control of Cold Atmospheric Pressure Plasma Jets](https://arxiv.org/abs/2507.08259)
> *冷常压等离子体射流的神经参数变数据使能预测控制*

*Pegah GhafGhanbari, Mircea Lazar, Javad Mohammadpour Velni* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 预测控制, 等离子体射流, 神经网络, 非线性系统, 数据使能控制

**Comment:** 

> **TL;DR:** 本文提出了一种名为NPV-DeePC的神经网络预测控制框架，通过集成超网络来解决冷常压等离子体射流（APPJs）的复杂非线性控制问题，并在仿真中表现出优于现有控制器的准确性和适应性，同时具有实时应用的计算效率。

**AI_Comments:** 这项研究的创新之处在于将超神经网络（hypernets）与数据使能预测控制（DeePC）相结合，形成NPV-DeePC框架，以自适应地处理复杂的参数变非线性系统。其重要性在于为冷常压等离子体射流（APPJs）这种难以精确控制的系统提供了一种鲁棒且高效的实时控制方案，并具有推广到其他类似系统的潜力。该方法通过仿真验证了其优越性，但在实际生物医学应用中的具体性能和安全性仍需进一步的实验验证。

<details>
  <summary>Details</summary>

**Motivation:** 冷常压等离子体射流（APPJs）在生物医学应用中潜力巨大，但其固有的复杂性（非线性动力学和对操作条件的高度敏感性）给实现鲁棒可靠的实时控制带来了巨大挑战。

**Method:** 本文提出了神经参数变数据使能预测控制（NPV-DeePC）框架。该方法通过将超神经网络（hypernets）集成到神经数据使能预测控制（DeePC）范式中，自适应地捕获系统非线性和参数变化，相应地更新神经特征空间，并实现高效准确的轨迹预测和控制。

**Result:** NPV-DeePC框架通过表面温度跟踪和热剂量传递的广泛仿真进行了验证。结果表明，它在准确性和适应性方面优于现有控制器。NPV-DeePC方法的计算效率使其成为实时应用的可行选择。

**Conclusion:** 这些发现强调了NPV-DeePC在推进APPJs安全精确控制方面的潜力，并为其他参数变化的非线性系统提供了可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种神经参数变数据使能预测控制（NPV-DeePC）框架，旨在解决冷常压等离子体射流（APPJs）的复杂非线性控制问题。该方法通过将超神经网络整合到神经数据使能预测控制（DeePC）中，能够自适应地捕获系统非线性和参数变化，从而实现高效准确的轨迹预测和控制。仿真结果表明，NPV-DeePC在准确性和适应性方面优于现有控制器，并且具有实时应用的计算效率，为APPJs及其他参数变非线性系统的安全精确控制提供了可扩展的解决方案。

> **摘要翻译:** 冷常压等离子体射流（APPJs）在生物医学应用中显示出巨大潜力，但其固有的复杂性，以非线性动力学和对尖端到表面距离等操作条件的强敏感性为特征，给实现鲁棒可靠的实时控制带来了相当大的挑战。为了解决这些问题，本文提出了神经参数变数据使能预测控制（NPV-DeePC）框架。通过将超神经网络（hypernets）集成到神经数据使能预测控制（DeePC）范式中，所提出的方法自适应地捕获系统非线性和参数变化，相应地更新神经特征空间，并实现高效准确的轨迹预测和控制。NPV-DeePC框架通过表面温度跟踪和热剂量传递的广泛仿真进行了验证。结果突出显示了其在准确性和适应性方面优于现有控制器的能力。NPV-DeePC方法的计算效率使其成为实时应用的可行选择。这些发现强调了其在推进APPJs安全精确控制方面的潜力，并为其他参数变化的非线性系统提供了可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [330] [Two-Level Distributed Interference Management for Large-Scale HAPS-Empowered vHetNets](https://arxiv.org/abs/2507.08299)
> *大规模HAPS赋能垂直异构网络中的两级分布式干扰管理*

*Afsoon Alidadi Shamsabadi, Animesh Yadav, Halim Yanikomeroglu* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** HAPS, vHetNets, 干扰管理, 分布式优化, 波束成形

**Comment:** 

> **TL;DR:** 本文提出了一种两级分布式比例公平波束成形权重设计(PFBWD)算法，结合增广拉格朗日法(ALM)和三块ADMM框架，以解决大规模HAPS赋能垂直异构网络中的干扰管理问题，该方法能够有效处理非凸性、降低复杂性并实现可扩展的分布式优化，同时保证收敛性。

**AI_Comments:** 本文的创新点在于针对大规模HAPS赋能vHetNets中的复杂干扰管理问题，提出了一种结合ALM和三块ADMM的分布式优化算法。该方法有效地解决了非凸优化和大规模网络带来的挑战，实现了可扩展且收敛性可保证的解决方案，对于未来xG网络的部署具有重要意义。其分布式特性也使其在实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 下一代无线网络(xG)需要提供无处不在的连接性并提升用户体验，高空平台站(HAPS)与地面网络的集成（HAPS赋能垂直异构网络vHetNets）是实现这一目标的关键。然而，在频谱共享的vHetNets中存在同频干扰和网络大规模化两大挑战，传统的集中式解决方案因计算和通信开销而变得不切实际，标准ADMM方法也可能因非凸约束而影响收敛。

**Method:** 为了解决HAPS赋能vHetNet中的干扰管理问题，本文采用无蜂窝架构作为底层网络，并通过波束成形来减轻干扰。针对由此产生的非凸高维优化问题和大规模网络挑战，提出了一种两级分布式比例公平波束成形权重设计(PFBWD)算法。该算法结合了增广拉格朗日法(ALM)和三块交替方向乘子法(ADMM)框架。

**Result:** 该方法有效地解决了非凸性问题，降低了计算复杂度，并实现了可扩展的分布式优化。

**Conclusion:** 本文提出的两级分布式比例公平波束成形权重设计(PFBWD)算法，结合ALM和三块ADMM框架，能够有效解决大规模HAPS赋能垂直异构网络中的干扰管理问题，具有处理非凸性、降低复杂度和实现可扩展分布式优化的能力，并保证收敛性。

> **ai_Abstract:** 本文提出了一种解决大规模HAPS赋能垂直异构网络(vHetNets)中干扰管理问题的两级分布式算法。面对频谱共享vHetNets中的同频干扰和网络大规模化带来的挑战，作者采用无蜂窝架构并提出了一种结合增广拉格朗日法(ALM)和三块交替方向乘子法(ADMM)框架的比例公平波束成形权重设计(PFBWD)算法。该算法旨在有效处理非凸性、降低复杂度，并实现可扩展、保证收敛的分布式优化，从而克服了传统集中式方案和标准ADMM的局限性。

> **摘要翻译:** 下一代无线网络(xG)必须提供无处不在的连接，同时提升人口稠密城市地区和农村地区的用户体验。为此，颠覆性的网络架构至关重要，高空平台站(HAPS)提供了一个有前景的解决方案。通过将HAPS与地面网络集成，我们可以创建HAPS赋能的垂直异构网络(vHetNets)，这显著提高了覆盖范围和容量，并支持新兴用例。在HAPS赋能的vHetNets中，不同层级可以共享相同的频谱，形成协调频谱vHetNets，从而提高频谱效率(SE)。然而，我们面临两大主要挑战：i) 协调频谱vHetNets中的同频干扰，以及ii) 网络的规模化特性。为了解决第一个挑战，我们采用无蜂窝方法作为HAPS赋能vHetNet的底层网络架构。在这种方法中，基站使用波束成形将高增益、窄波束指向用户，这有助于减轻干扰。然而，这产生了一个非凸和高维的优化问题，这突出了处理大规模网络的第二个挑战。因此，由于涉及的计算和通信开销，集中式解决方案变得不切实际。标准的两块交替方向乘子法(ADMM)是一种选择，但非凸约束可能会阻碍其收敛。作为替代方案，我们开发了一种两级分布式比例公平波束成形权重设计(PFBWD)算法。该算法结合了增广拉格朗日法(ALM)和三块ADMM框架。所提出的方法有效地解决了非凸性问题，降低了复杂性，并实现了可扩展的分布式优化，同时保证了收敛性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [355] [A Generalized Stability Analysis Method with Dynamic Phasors for LV AC Microgrids](https://arxiv.org/abs/2507.08383)
> *低压交流微电网中基于动态相量的广义稳定性分析方法*

*Bülent Dağ* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 稳定性分析, 动态相量, 微电网, 感性耦合, 不稳定性边界

**Comment:** 8 pages, 6 figures, not published anywhere

> **TL;DR:** 本文提出了一种将动态相量引入现有相量方法的广义稳定性分析方法，用于由下垂控制逆变器组成的低压交流微电网，能准确预测不稳定边界。

**AI_Comments:** 这项研究通过引入动态相量，解决了传统静态相量在微电网稳定性分析中对感性耦合线路建模的局限性，从而提高了分析方法的准确性和适用性，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于相量的简化稳定性分析方法在处理含有感性耦合线路的微电网时存在不足，主要原因是使用传统静态相量表示感性耦合线路。

**Method:** 本研究提出了一种广义稳定性分析方法，通过将动态相量引入现有基于相量的稳定性分析方法中，用于感性耦合线路的建模。该方法应用于由下垂控制逆变器组成的低压交流微电网。

**Result:** 结果表明，采用动态相量的稳定性分析方法成功预测了低压交流微电网的不稳定性边界。

**Conclusion:** 使用动态相量能够有效地解决现有方法在分析含有感性耦合线路的微电网稳定性时的不足，并准确预测不稳定边界。

> **ai_Abstract:** 本文针对现有基于相量的微电网稳定性分析方法在处理感性耦合线路时的不足，提出了一种新的广义稳定性分析方法。该方法将动态相量引入现有分析框架中，用于感性耦合线路的动态建模。实验结果表明，该方法能够准确预测低压交流微电网的不稳定性边界。

> **摘要翻译:** 采用传统静态相量表示感性耦合线路是现有基于相量的简化稳定性分析方法在处理含有感性耦合线路的微电网时存在不足的主要原因。在文献中，动态相量已被提出用于感性线路的动态建模，以保持分析方法的简化结构。本研究提出了一种用于由下垂控制逆变器组成的低压交流微电网的广义稳定性分析方法。所提出的分析方法基于将感性耦合线路的动态相量纳入现有基于相量的稳定性分析方法中。结果表明，采用动态相量的稳定性分析方法成功预测了低压交流微电网的不稳定性边界。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [380] [PGD-based optimization of 3D bobsleigh track centerlines from 2D centerlines for simulation applications](https://arxiv.org/abs/2507.08393)
> *用于模拟应用的三维雪橇赛道中心线从二维中心线基于PGD的优化*

*Zhe Chen, Huichao Zhao, Yongfeng Jiang, Minghui Bai, Lun Li, Jicheng Chen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 雪橇赛道, 中心线, 三维重建, 投影梯度下降, 模拟应用

**Comment:** 

> **TL;DR:** 该研究提出了一种从2D中心线生成3D雪橇赛道中心线的方法，以降低训练成本并创建逼真的虚拟环境。

**AI_Comments:** 该研究为雪橇运动的模拟和训练提供了一种创新的解决方案，通过从二维数据生成精确的三维赛道模型，有望显著降低训练成本并提高训练效率。然而，研究中提到的最大误差值（高达10.0%）可能需要在实际应用中进一步评估其影响。

<details>
  <summary>Details</summary>

**Motivation:** 为了降低雪橇训练成本，利用赛道中心线构建虚拟环境以复制真实的竞争环境是一个有前景的解决方案。然而，公开的中心线数据通常有限，仅基于二维中心线构建训练系统是不精确的。

**Method:** 提出了一种基于2D中心线数据生成3D赛道中心线的方法。该方法结合了国际赛道设计法规，构建了一个考虑总赛道长度、高度差、坡度限制和几何连续性的优化问题，并使用投影梯度下降（PGD）算法求解。

**Result:** 生成的三维中心线与真实赛道数据进行了比较，结果表明该方法可以从原始或缩放的二维数据中再现逼真的中心线趋势。所选赛道段的相对误差在总长度、高度差和平均坡度方面分别在1.7%、3.2%和4.1%以内（对于真实二维数据），以及1.1%、3.5%和4.3%以内（对于缩放数据）。所有坡度值均在允许范围内。

**Conclusion:** 所提出的方法为支持雪橇赛道中心线设计提供了一种灵活高效的工具。

> **ai_Abstract:** 本研究提出了一种利用投影梯度下降（PGD）算法优化二维中心线数据以生成三维雪橇赛道中心线的方法。该方法考虑了赛道长度、高度差和坡度等设计约束，并能生成逼真的赛道几何。实验结果表明，该方法在误差控制方面表现良好，并能通过调整参数生成适用于不同比赛的赛道。

> **摘要翻译:** 赛道中心线定义了其几何形状，对于模拟建模至关重要。为了降低雪橇训练成本，利用雪橇赛道中心线构建一个能够精确复制真实竞争环境的虚拟环境，这是一种有前景的解决方案。然而，公开的中心线数据通常有限，并且仅基于二维（2D）中心线构建训练系统是不精确的。为了解决这个实际问题，本文提出了一种基于二维中心线数据生成三维（3D）赛道中心线的方法。该方法结合了国际赛道设计法规，构建了一个考虑总赛道长度、高度差、坡度限制和几何连续性的优化问题。使用投影梯度下降（PGD）算法求解优化问题。将生成的三维中心线与真实赛道数据进行比较，结果表明该方法可以从原始或缩放的二维数据中再现逼真的中心线趋势。对于所选的赛道片段，与真实二维数据相比，总长度、高度差和平均坡度的相对误差分别在1.7%、3.2%和4.1%以内，而与缩放数据相比，这些误差分别在1.1%、3.5%和4.3%以内。所有坡度值均在允许范围内。此外，通过调整分段或修改成本函数中高度差的权重，可以生成适用于不同比赛的各种中心线样式。在不同的分段和权重因子下，最大误差分别达到4.4%、4.8%和9.8%，以及4.4%、4.8%和10.0%。所提出的方法为支持雪橇赛道中心线设计提供了一种灵活高效的工具。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [405] [Large-Scale Processing and Validation of Grid Data for Assessing the Fair Spatial Distribution of PV Hosting Capacity](https://arxiv.org/abs/2507.08684)
> *大规模处理和验证电网数据以评估光伏接入能力的公平空间分布*

*Ali Mohamed Ali, Yaser Raeisi, Plouton Grammatikos, Davide Pavanello, Pierre Roduit, Fabrizio Sossan* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 电网数据, 光伏接入能力, 空间公平性, 数据验证, 大规模研究

**Comment:** 

> **TL;DR:** 该论文提出了一种从配电系统运营商数据库中提取、验证和调整电网数据的方法，用于大规模电网研究，并评估光伏接入能力的公平空间分布，量化了空间公平性相关的成本。

**AI_Comments:** 该研究在处理大规模电网数据和评估光伏接入能力的公平性方面具有重要意义。通过量化与空间公平性相关的成本，为电网规划和政策制定提供了有价值的见解。未来可以进一步研究不同公平性指标的影响以及在实际应用中优化公平性分配的策略。

<details>
  <summary>Details</summary>

**Motivation:** 传统电网设计和运行因光伏系统集成和电气化水平提高而面临挑战，需要有效的方法来处理和验证电网数据以支持大规模研究。

**Method:** 提出了一种从DSO数据库提取、验证和调整电网数据的方法，结合了基于规则的健全性检查和离线自动潮流分析，以确保数据一致性并检测错误。在此基础上，提出了一种评估配电网光伏接入能力的方法，并纳入了公平性标准，以量化与空间公平性相关的成本。

**Result:** 开发了一种用于大规模电网研究的数据处理和验证方法，并提出了一种评估光伏接入能力的方法，该方法考虑了空间公平性并量化了相关成本。

**Conclusion:** 该研究提供了一种处理和验证电网数据以进行大规模研究的方法，并提出了一种评估光伏接入能力的方法，该方法强调了空间公平性及其经济影响。

> **ai_Abstract:** 该论文介绍了一种处理和验证配电网数据的有效方法，以支持大规模电网研究，特别是评估光伏接入能力的公平空间分布。该方法通过健全性检查和自动潮流分析确保数据质量，并量化了实现空间公平性所产生的成本。

> **摘要翻译:** 光伏系统集成和电气化水平的提高对配电网的传统设计和运行提出了重大挑战。本文提出了一种从配电系统运营商 (DSO) 数据库中提取、验证和调整电网数据的方法，以支持包括潮流和最优潮流分析在内的大规模电网研究。验证过程结合了基于规则的健全性检查和离线自动潮流分析，以确保数据一致性并检测电网数据库中的潜在错误，从而能够对其进行校正。作为实际应用，本文提出了一种评估配电网光伏接入能力的方法，重点是确保其空间分布的公平性。通过将公平性标准纳入分析，我们量化了与空间公平性相关的成本（以出售光伏发电收入损失的形式）。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [455] [Electricity-Aware Bid Format for Coordinated Heat and Electricity Market Clearing](https://arxiv.org/abs/2005.03120)
> *用于热电协同市场结算的考虑电力的出价格式*

*Lesia Mitridati, Jalal Kazempour, Pascal Van Hentenryck* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 热电市场协调, 考虑电力的出价格式, 三层优化, 混合整数线性规划, 能源系统效率

**Comment:** arXiv admin note: text overlap with arXiv:1910.08617

> **TL;DR:** 该论文提出了一种新的市场机制，通过在热市场结算前引入考虑电力价格的出价格式，实现了热电市场的协调。这种机制将热出价条件化于日前电力价格，并通过一个三层优化问题来选择最小化热系统运行成本的有效出价。与现有方法相比，该机制将热电系统的总运行成本降低了4.5%，并将联合热电厂和热泵因无效出价造成的财务损失减少了高达2030万欧元。

**AI_Comments:** 该研究在保持现有市场顺序结算的约束下，提出了一种创新的市场机制来协调热电市场，具有重要的实际应用价值。通过将热出价与电力市场价格信息相结合，有效解决了信息不对称和优化问题。然而，该方法将三层优化问题重构为混合整数线性规划，其计算复杂性在大型系统中的可扩展性有待进一步研究。此外，实际应用中还需要考虑市场参与者的行为和潜在的市场操纵风险。

<details>
  <summary>Details</summary>

**Motivation:** 当前能源系统中热电市场结算的顺序性导致热调度对电力市场的影响无法被考虑，从而影响了成本效益和效率。本研究旨在提出一种能在保持顺序结算的同时协调热电系统的方法。

**Method:** 提出了一种新的市场机制，定义了条件于日前电力价格的热出价格式。通过一个三层优化问题来选择有效出价，该问题被重构为混合整数线性规划。该方法使用基于丹麦热电系统的案例研究进行验证。

**Result:** 与现有市场结算程序相比，提出的出价选择机制将热电系统的总运行成本降低了4.5%，并将联合热电厂和热泵因无效出价造成的财务损失减少了高达2030万欧元。

**Conclusion:** 该研究提出的考虑电力的出价格式能够有效协调热电市场，在保持顺序结算的同时降低了总运行成本和因无效出价造成的财务损失。

> **ai_Abstract:** 本研究提出了一种新颖的电力感知出价格式，用于协调热电市场。该机制通过将热出价与日前电力价格挂钩，并在热市场结算前选择能够最小化热系统运行成本的有效出价，从而解决了当前顺序市场结算中热调度对电力市场影响的问题。通过一个三层优化问题模型化，并采用混合整数线性规划求解，该方法在丹麦的案例研究中显示，与现有方法相比，总运行成本降低了4.5%，并显著减少了联合热电厂和热泵的财务损失。

> **摘要翻译:** 热电市场之间的协调对于实现能源系统的成本效益和高效运行至关重要。在当前顺序市场实践中，热市场在电力市场之前进行结算，并且无法了解热调度对电力市场的影响。在保持这种顺序实践的同时，本文提出了一种用于热电系统协调的考虑电力的出价格式。这种新颖的市场机制将热出价条件化于日前电力价格。在热电市场结算之前，提出的出价选择机制选择最小化热系统运行成本并预见热电市场结算的有效出价。该机制被建模为一个三层优化问题，我们使用字典序函数将其重构为混合整数线性规划。我们使用了基于丹麦电力和热力系统的实际案例研究，并表明与现有的市场结算程序相比，提出的出价选择机制将热电系统的总运行成本降低了4.5%，同时将联合热电厂和热泵因无效出价造成的财务损失减少了高达2030万欧元。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [485] [Wholesale Market Participation of DERA: Competitive DER Aggregation](https://arxiv.org/abs/2307.02004)
> *DERA在批发市场的参与：竞争性DER聚合*

*Cong Chen, Ahmed S. Alahmed, Timothy D. Mount, Lang Tong* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** DER聚合, 批发市场, 竞争性聚合器, 虚拟储能, 客户剩余

**Comment:** 16 pages, 8 figures

> **TL;DR:** 该论文提出了一个竞争性DER聚合器（DERA）模型，该模型旨在最大化聚合器的利润，同时确保客户获得不低于监管零售费率的收益。DERA作为虚拟储能参与批发市场，其最优发电报价和消费出价均源于该模型。研究表明，在相同的配电网接入条件下，DERA的参与能带来与客户直接参与批发市场相同的福利最大化结果。论文还通过数值研究比较了DERA与其他方法的性能，并评估了市场竞争、DER普及率和配电网接入对市场结果的影响。

**AI_Comments:** 该研究在DER聚合领域提出了一个创新的模型，特别关注了聚合商在批发市场中的直接参与及其对客户和市场的影响。模型在确保客户利益的同时最大化聚合商利润，具有重要的实践意义。然而，模型在处理复杂的配电网络接入约束和多方博弈方面的鲁棒性有待进一步验证。未来的研究可以探索更动态的定价机制和更精细化的风险管理策略。

<details>
  <summary>Details</summary>

**Motivation:** 研究分布式能源资源（DER）聚合商在批发市场中直接参与交易的情况，特别是在存在配电网络接入限制的背景下，以最大化聚合商利润并保障客户利益。

**Method:** 提出竞争性DER聚合器（DERA）模型，该模型最大化DERA利润，同时确保客户收益不低于监管零售费率。DERA作为虚拟储能参与批发市场，其报价和出价由模型优化得出。通过数值研究和实证评估来分析DERA的性能、生存能力以及不同因素的影响。

**Result:** 与现有方法相比，DERA在客户盈余和聚合器利润方面表现更优。在相同的配电网接入条件下，DERA的批发市场参与实现了与客户直接参与市场相同的福利最大化结果。研究还评估了DER普及率和配电网接入对短期市场结果的影响。

**Conclusion:** 提出的DERA模型能够有效地在批发市场中聚合DER，实现聚合器利润最大化和客户利益保障的双重目标，并能带来与客户直接参与市场相同的福利最大化效果。DERA的长期生存能力和市场影响受DER普及率和配电网接入等因素的影响。

> **ai_Abstract:** 本研究提出了一个竞争性DER聚合器（DERA）模型，允许聚合商在批发市场中直接参与交易，同时满足客户的收益和成本要求。该模型通过优化报价和出价，使DERA能够像虚拟储能一样运作。研究证明，在配电网接入限制下，DERA的参与能实现与客户直接参与市场相同的福利最大化结果。此外，通过数值模拟和实证分析，探讨了DERA的市场竞争能力、生存能力以及外部因素（如DER普及率和配电网接入）对其市场表现的影响。

> **摘要翻译:** 我们考虑了由一个寻求利润的聚合器聚合分布式能源资源（DER）的情况，该聚合器在配电网络接入限制下直接参与批发市场。我们提出了一个竞争性DER聚合器（DERA）模型，该模型旨在最大化DERA的利润，同时确保每个聚合的客户获得的剩余不低于或支付的能源成本不高于监管零售费率。DERA作为虚拟储能参与批发电力市场，其优化的发电报价和消费出价源于我们的竞争性聚合模型。此外，还推导了DERA在配电网络接入的报价曲线以及DERA在与监管零售费率竞争时的盈利能力。我们表明，在相同的配电网络接入条件下，所提出的DERA的批发市场参与实现了与其客户直接参与批发市场相同的福利最大化结果。数值研究在客户剩余和DERA利润方面比较了所提出的DERA与现有方法。我们实证评估了在长期均衡中能够存活多少DERA，并评估了DER普及水平和配电网络接入对短期市场结果的影响。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [515] [A Preventive-Corrective Scheme for Ensuring Power System Security During Active Wildfire Risks](https://arxiv.org/abs/2410.01984)
> *一种用于确保电网在主动野火风险期间安全运行的预防-纠正方案*

*Satyaprajna Sahoo, Anamitra Pal* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 野火风险, 电力系统安全, 预防-纠正方案, 瞬态稳定性, 最优潮流

**Comment:** Submitted to the Open Access Journal of Power and Energy (OAJPE)

> **TL;DR:** 提出了一种预防-纠正协调决策方案，用于在野火风险高时安全运行电网，通过联合分析和优化来缓解静态和动态不安全因素。

**AI_Comments:** 该研究提出了一种创新的方法来解决电力系统在野火风险下的安全运行问题，通过结合预防和纠正措施来提高系统的鲁棒性。该方法在理论和实践上都具有重要意义，但其在大规模系统上的可扩展性和实时性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在野火风险高时，电网的运行安全面临挑战，因为火灾可能以不确定的方式影响电网运行。

**Method:** 提出了一种预防-纠正协调决策方案，该方案利用了一个全面的多资产故障分析工具，该工具包括一个可行性测试算法（用于防止级联线路故障）和一个数据驱动的瞬态稳定性分析器（用于缓解动态不稳定性）。该工具用于操作一个联合机组承诺/最优潮流模型，该模型能够适应野火相关的不同风险水平。

**Result:** 在IEEE 118总线系统上进行的仿真结果表明，所提出的方法减轻了系统对野火的脆弱性，同时最小化了运行成本。

**Conclusion:** 该研究提出了一种有效的预防-纠正协调决策方案，能够应对野火风险对电网安全运行的影响，并在保证系统鲁棒性的同时实现经济运行。

> **ai_Abstract:** 本文提出了一种预防-纠正协调决策方案，以应对野火风险下的电力系统安全运行问题。该方案结合了可行性测试算法和瞬态稳定性分析器，用于评估和缓解由多资产故障引起的静态和动态不安全因素。通过将此工具应用于联合机组承诺/最优潮流模型，该方案能够适应不同的野火风险水平，并在经济运行和电网鲁棒性之间取得平衡。实验结果表明，该方法有效降低了系统对野火的脆弱性并最小化了运行成本。

> **摘要翻译:** 本文聚焦于在野火风险高时安全运行电网。这是一个具有挑战性的问题，因为火灾可能以不确定的方式影响电网的运行。为了应对这一挑战，我们提出了一种新颖的预防-纠正协调决策方案，该方案能够快速缓解由于区域内主动野火风险而导致的静态和动态不安全因素。该方案利用了一个全面的多资产故障分析工具，该工具包括：(i) 一个可行性测试算法，该算法穷尽式地去饱和过载的割集以防止级联线路故障；以及 (ii) 一个数据驱动的瞬态稳定性分析器，该分析器用于缓解动态不稳定性。然后，该工具用于操作一个联合机组承诺/最优潮流模型，该模型旨在适应与野火相关的不同风险水平。根据允许的风险水平，该模型在经济运行和电网鲁棒性之间进行权衡。使用IEEE 118总线系统获得的结果表明，所提出的方法减轻了系统对野火的脆弱性，同时最小化了运行成本。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [542] [Online convex optimization for constrained control of nonlinear systems](https://arxiv.org/abs/2412.00922)
> *非线性系统的约束控制在线凸优化*

*Marko Nonhoff, Johannes Köhler, Matthias A. Müller* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-11**

**Keywords:** 在线凸优化, 约束控制, 非线性系统, 参考调节器, 动态遗憾

**Comment:** 17 pages

> **TL;DR:** 该论文提出了一种结合在线凸优化和参考调节器来解决非线性系统约束控制问题的模块化方法，该方法适用于具有时变和未知成本函数的系统，并证明了其动态遗憾的上界是线性的且最优的。

**AI_Comments:** 该研究在解决非线性系统的约束控制问题方面取得了重要进展，特别是在处理时变和未知成本函数方面。所提出的模块化方法具有通用性和最优性，为该领域的研究提供了新的思路和方向。然而，在实际应用中，计算复杂性和实时性可能仍然是需要考虑的因素。

<details>
  <summary>Details</summary>

**Motivation:** 解决具有时变和先验未知成本函数的约束控制问题，特别是针对非线性动力学系统和状态/输入约束。

**Method:** 提出了一种模块化方法，将在线凸优化框架与参考调节器相结合，用于解决非线性系统的约束控制问题。

**Result:** 证明了所提出的框架的动态遗憾上界与所选在线凸优化算法的动态遗憾和路径长度成线性关系，并且对于一类标准的在线凸优化算法，该框架的动态遗憾上界仅与成本函数的变异性成线性关系，这是最优的。

**Conclusion:** 所提出的方法是一种模块化方法，结合了在线凸优化和参考调节器，用于解决非线性系统的约束控制问题，并且具有最优的动态遗憾界。

> **ai_Abstract:** 本文提出了一种创新的模块化方法，将在线凸优化（OCO）框架与参考调节器（RG）相结合，以解决复杂的约束控制问题，特别适用于具有时变且未知成本函数的非线性动力学系统。该方法能够处理状态和输入约束，并且不限制OCO算法或RG的选择。研究表明，该框架的动态遗憾（dynamic regret）上界与OCO算法的动态遗憾和路径长度成线性关系，并且该界限是无法改进的最优界限。对于标准OCO算法，该框架的动态遗憾仅与成本函数的变化率成线性关系，这也是最优的。通过在非线性化学反应器上的数值实验，验证了该框架的实现性和灵活性。

> **摘要翻译:** 本文提出了一种模块化方法，该方法结合了在线凸优化框架和参考调节器，以解决具有时变和先验未知成本函数的约束控制问题。与现有结果相比，所提出的框架独特地适用于受状态和输入约束的非线性动力学系统。此外，我们的方法具有通用性，因为我们不将分析局限于在线凸优化算法或参考调节器的特定选择。我们证明了所提出框架的动态遗憾上界在动态遗憾和所选在线凸优化算法的路径长度上均有线性界限，尽管在线凸优化算法没有考虑底层动力学。我们证明了相对于在线凸优化算法动态遗憾的线性界限是最优的，即无法改进。此外，对于一类标准的在线凸优化算法，我们提出的框架对其动态遗憾的界限仅与成本函数的变异性成线性关系，这被认为是最优的界限。最后，我们在数值实验中通过比较在线凸优化算法和参考调节器的不同组合来控制一个非线性化学反应器，以展示所提出框架的实现和灵活性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [566] [Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases](https://arxiv.org/abs/2506.08033)
> *用于二维辐射气体炉中辐射传热的卷积神经网络和多层感知器可行性研究*

*Axel TahmasebiMoradi, Vincent Ren, Benjamin Le-Creurer, Chetra Mang, Mouadh Yagoubi* | **Category: eess.SY, cs.LG, cs.SY** | **Updated: 2025-07-11**

**Keywords:** 卷积神经网络,多层感知器,辐射传热,代理模型,计算成本

**Comment:** 

> **TL;DR:** 本研究探讨了使用卷积神经网络（CNN）和多层感知器（MLP）作为代理模型来近似二维辐射气体炉中的辐射传热问题，以降低计算成本。研究表明，与传统求解器相比，这两种神经网络模型都能实现显著的加速，并且具有可接受的相对误差。CNN在精度、鲁棒性和稳定性方面优于MLP。

**AI_Comments:** 这项研究在将常用于图像处理的CNN应用于计算流体动力学（CFD）领域方面具有创新性。通过调整输入以适应CNN架构，作者成功地构建了一个高效的代理模型来解决辐射传热问题。研究结果表明，与传统的MLP模型相比，CNN模型在精度和稳定性方面表现更优，这为未来在CFD领域应用深度学习技术提供了有价值的见解。然而，研究仅限于二维模型，其在三维复杂情况下的适用性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 为了降低数值模拟的计算成本，本研究旨在构建一个代理模型来近似二维辐射气体炉中具有参与气体的辐射传热解。

**Method:** 本研究引入了卷积神经网络（CNN）和多层感知器（MLP）来构建代理模型，以近似二维辐射气体炉中具有参与气体的辐射传热解。研究人员调整了问题的输入（气体和壁属性）以适应CNN架构。使用ICARUS2D求解器创建了两个精度数据集，该求解器采用离散转移辐射方法和统计窄带模型。通过Optuna优化了网络超参数，并比较了CNN和MLP在速度和精度方面的性能。

**Result:** 与传统求解器相比，CNN和MLP两种架构均实现了显著的加速，且相对误差在工业可接受范围内。CNN在精度、鲁棒性和稳定性方面优于MLP。此外，还对数据集大小样本进行了性能分析，以更深入地了解模型行为。

**Conclusion:** CNN和MLP代理模型在降低辐射传热模拟计算成本方面是可行的，并且均能实现显著的加速和可接受的精度。CNN在性能上优于MLP。

> **ai_Abstract:** 本研究提出使用卷积神经网络（CNN）和多层感知器（MLP）作为代理模型，以降低二维辐射气体炉中辐射传热模拟的计算成本。通过调整输入以适应CNN架构，并利用ICARUS2D求解器创建数据集，研究比较了两种模型的性能。结果显示，两种模型均能显著加速计算并保持工业可接受的精度，其中CNN在精度和稳定性方面表现更优。

> **摘要翻译:** 为了降低数值模拟的计算成本，本研究引入了卷积神经网络（CNN）和多层感知器（MLP）来构建代理模型，以近似二维辐射气体炉中具有参与气体的辐射传热解。本工作的独创性在于调整了问题的输入（气体和壁属性）以适应CNN架构，而CNN架构更常用于图像处理。使用经典的ICARUS2D求解器创建了两个精度数据集，该求解器采用离散转移辐射方法和统计窄带模型。对CNN架构的性能与更经典的MLP架构在速度和精度方面进行了比较。得益于Optuna，所有结果均使用优化后的超参数网络获得。结果表明，与经典求解器相比，两种架构均实现了显著的加速，且相对误差在工业可接受范围内。此外，CNN在精度、鲁棒性和稳定性方面优于MLP，对超参数变化的鲁棒性也更强。还对数据集样本量进行了性能分析，以更深入地了解模型行为。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [335] [AI-Augmented Visible Light Communication: A Framework for Noise Mitigation and Secure Data Transmission](https://arxiv.org/abs/2507.08145)
> *AI增强型可见光通信：一种噪声抑制与安全数据传输框架*

*A. A. Nutfaji, Moustafa Hassan Elmallah* | **Category: eess.SP** | **Updated: 2025-07-10**

**Keywords:** 可见光通信, 深度学习, 噪声抑制, 误码率, 深度神经网络

**Comment:** currently 4 pages. However, we're planning to work more on the topic

> **TL;DR:** 本文提出一个AI深度学习模型，通过DNN均衡化处理，在Python仿真中有效降低可见光通信系统中的噪声（AWGN），提高信号完整性，并通过BER对比验证了其有效性。

**AI_Comments:** 本文创新性地将AI深度学习应用于可见光通信的噪声抑制，通过DNN均衡化处理显著提高了信号完整性。其基于Python仿真的验证方法直观且有效。然而，尽管标题提到了“安全数据传输”，但抽象中并未提供任何关于安全性的具体方法或结果，这可能是一个限制或未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决可见光通信（VLC）系统中遇到的常见挑战，特别是加性高斯白噪声（AWGN）对信号完整性的影响。

**Method:** 本文提出了一个AI深度学习模型，并在Python仿真中建立了一个受AWGN影响的基本可见光通信系统模型。通过训练深度神经网络（DNN）来均衡接收到的噪声信号，以提高信号完整性。该系统通过比较均衡前后误码率（BER）来评估所提模型的有效性。

**Result:** 该模型能够提高信号完整性，并在误码率（BER）比较中显示出其有效性，有效降低了可见光通信系统中的噪声影响。抽象中未提及安全数据传输的结果。

**Conclusion:** 本文提出的AI深度学习模型能够有效应对可见光通信系统中的噪声挑战，并通过提高信号完整性来改善系统性能。论文最后为未来的工作指明了方向，强调了最适合未来改进的领域。

> **ai_Abstract:** 本文提出了一种基于AI深度学习的框架，用于解决可见光通信（VLC）系统中的噪声问题。通过Python仿真建立VLC系统模型，并训练深度神经网络（DNN）对受加性高斯白噪声（AWGN）影响的信号进行均衡处理，以提高信号完整性。研究通过比较均衡前后的误码率（BER）验证了该模型的有效性。

> **摘要翻译:** 本文提出了一个AI深度学习模型，旨在解决可见光通信（VLC）系统中遇到的常见挑战。在这项工作中，我们运行了一个Python仿真，模拟了一个主要受加性高斯白噪声（AWGN）影响的基本VLC系统。然后训练一个深度神经网络（DNN）来均衡接收到的噪声信号并提高信号完整性。该系统评估并比较了均衡前后的误码率（BER），以证明所提出模型的有效性。本文首先介绍了可见光通信的概念，然后深入探讨了VLC的过程及其面临的一些挑战，随后我们提出了有助于克服这些挑战的项目。我们最后总结了未来工作的方向，强调了最适合未来改进的领域。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [357] [Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees](https://arxiv.org/abs/2507.08653)
> *具有峰值信息年龄违规保证的资源分配安全深度强化学习*

*Berire Gunes Reyhan, Sinem Coleri* | **Category: eess.SP, cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 深度强化学习, 资源分配, 峰值信息年龄, 无线网络控制系统, 安全强化学习

**Comment:** 15 Pages, to be published in IEEE Transactions on Communications

> **TL;DR:** 本文提出了一种基于优化理论的安全深度强化学习框架，用于超可靠无线网络控制系统，首次在保证约束满足的同时优化性能，特别是在最小化功耗方面。

**AI_Comments:** 该论文的创新之处在于首次将优化理论与安全深度强化学习相结合，为超可靠无线网络控制系统中的资源分配提供了一个新颖且有效的解决方案，特别是在保证约束满足的同时优化性能。其提出的教师-学生框架在安全DRL中引入了明确的约束检查和纠正机制，增强了模型的可靠性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在无线网络控制系统（WNCSs）中，控制和通信系统由于其强烈的相互依赖性必须进行协同设计。现有方法可能难以在优化性能的同时确保约束满足，尤其是在超可靠WNCSs中，这促使作者开发一种新的框架来解决此问题。

**Method:** 本文提出了一个两阶段的基于优化理论的安全深度强化学习（DRL）框架。第一阶段，利用优化理论推导最优性条件，以简化和分解问题，并建立变量之间的数学关系。第二阶段，采用一个安全DRL模型，其中一个教师-学生框架指导DRL代理（学生），控制机制（教师）评估系统约束的符合性，并在需要时建议最近的可行动作。该方法在有限块长度机制下，通过结合随机最大允许传输间隔（MATI）和最大允许数据包延迟（MAD）约束，独特地推导了峰值信息年龄（PAoI）违反概率，并旨在最小化功耗。

**Result:** 仿真结果表明，所提出的框架优于基于规则和其他基于优化理论的DRL基准，实现了更快的收敛速度、更高的奖励和更大的稳定性。

**Conclusion:** 本文首次提出了一个基于优化理论的安全深度强化学习框架，成功地在超可靠无线网络控制系统中实现了性能优化与约束满足的协同，并在实验中展现出优越的性能，为资源分配提供了有效且可靠的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的、基于优化理论的安全深度强化学习（DRL）框架，旨在解决无线网络控制系统（WNCSs）中资源分配问题。该框架首次实现了在超可靠WNCSs中性能优化与约束满足的协同，特别是在最小化功耗方面，同时考虑了峰值信息年龄（PAoI）违反概率、发射功率和可调度性等关键约束。该方法分为优化理论和安全DRL两个阶段，其中安全DRL部分采用教师-学生框架来确保动作的可行性。仿真结果验证了该框架在收敛速度、奖励和稳定性方面均优于现有基准。

> **摘要翻译:** 在无线网络控制系统（WNCSs）中，控制和通信系统由于其强烈的相互依赖性必须进行协同设计。本文提出了一种新颖的基于优化理论的安全深度强化学习（DRL）框架，用于超可靠WNCSs，首次在文献中实现了在优化性能的同时确保约束满足。该方法在关键约束（包括峰值信息年龄（PAoI）违反概率、发射功率和有限块长度机制下的可调度性）下最小化功耗。PAoI违反概率是通过结合多传感器网络中的随机最大允许传输间隔（MATI）和最大允许数据包延迟（MAD）约束独特地推导出来的。该框架由两个阶段组成：优化理论和安全DRL。第一阶段推导最优性条件以建立变量之间的数学关系，从而简化和分解问题。第二阶段采用一个安全DRL模型，其中一个教师-学生框架指导DRL代理（学生）。控制机制（教师）评估系统约束的符合性，并在需要时建议最近的可行动作。广泛的仿真表明，所提出的框架优于基于规则和其他基于优化理论的DRL基准，实现了更快的收敛速度、更高的奖励和更大的稳定性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [360] [Ambiguity Function Analysis of AFDM Signals for Integrated Sensing and Communications](https://arxiv.org/abs/2507.08293)
> *AFDM信号模糊函数分析，用于集成传感与通信*

*Haoran Yin, Yanqun Tang, Yuanhan Ni, Zulin Wang, Gaojie Chen, Jun Xiong, Kai Yang, Marios Kountouris, Yong Liang Guan, Yong Zeng* | **Category: eess.SP** | **Updated: 2025-07-11**

**Keywords:** AFDM, 模糊函数, 集成传感与通信, 距离估计, 速度估计

**Comment:** 14 pages, 14 figures. Under revision in an IEEE Journal

> **TL;DR:** 本文研究了仿射频分复用（AFDM）信号的模糊函数（AFs），以表征其在距离和速度估计方面的能力，并证明了AFDM在集成传感与通信（ISAC）应用中的巨大潜力。

**AI_Comments:** 本文创新性地分析了AFDM信号的模糊函数，详细揭示了其在距离和速度估计方面的独特特性，特别是“尖峰状”和“周期状”的结构，以及形成的平行四边形形状，这对于理解AFDM在雷达传感领域的潜力至关重要。此外，提出通过插入保护符号实现无干扰传感，为AFDM在ISAC应用中的实际部署提供了有益的指导。该研究为AFDM在下一代无线通信和传感集成领域的发展奠定了理论基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** AFDM是一种有前景的基于线性调频的波形，适用于高移动性场景的下一代无线网络。本文旨在通过深入分析AFDM信号的模糊函数（AFs），来从根本上表征其在单站和双站设置中的距离和速度估计能力，从而评估其在集成传感与通信（ISAC）中的潜力。

**Method:** 1. 推导了AFDM线性调频子载波的自模糊函数（AAF），分析其沿旋转延迟和多普勒维度的“尖峰状”局部特性和“周期状”全局特性。2. 研究了两个不同AFDM线性调频子载波之间的互模糊函数（CAF），并比较其特性。3. 将模糊函数分析扩展到各种典型AFDM帧，考虑确定性导频和随机数据符号。4. 演示了在AFDM中插入保护符号如何促进无干扰传感。5. 通过仿真结果验证了理论发现。

**Result:** 1. AFDM线性调频子载波的自模糊函数（AAF）在旋转延迟和多普勒维度上表现出“尖峰状”局部特性和“周期状”全局特性，其结构自然形成平行四边形，从而实现无模糊目标传感。2. 互模糊函数（CAF）与AAF具有相同的局部和全局特性，但在多普勒维度上额外存在一个偏移。3. 在AFDM中插入保护符号有助于实现无干扰传感。4. 仿真结果验证了理论发现的正确性。

**Conclusion:** AFDM信号在集成传感与通信（ISAC）应用中具有强大的潜力。

> **ai_Abstract:** 本文对仿射频分复用（AFDM）信号的模糊函数（AFs）进行了深入分析，旨在评估其在集成传感与通信（ISAC）中的应用潜力。研究人员推导了AFDM线性调频子载波的自模糊函数（AAF），揭示了其独特的“尖峰状”局部和“周期状”全局特性，以及在旋转延迟和多普勒维度上形成的平行四边形结构，这有助于实现无模糊目标传感。此外，研究还发现，在AFDM帧中插入保护符号能够促进无干扰传感。通过对互模糊函数（CAF）的分析，进一步完善了AFDM信号特性。仿真结果验证了这些理论发现，强调了AFDM作为下一代无线网络中ISAC解决方案的巨大潜力，尤其是在高移动性环境中。

> **摘要翻译:** 仿射频分复用（AFDM）是一种有前景的基于线性调频的波形，具有高灵活性和弹性，非常适合下一代无线网络，特别是在高移动性场景中。在本文中，我们研究了AFDM信号的模糊函数（AFs），它们从根本上表征了AFDM在单站和双站设置中的距离和速度估计能力。具体来说，我们首先推导了AFDM线性调频子载波的自模糊函数（AAF），揭示了其沿旋转延迟和多普勒维度的“尖峰状”局部特性和“周期状”全局特性。这种结构自然地为AFDM线性调频子载波的AAF的每个局部脉冲形成一个平行四边形，从而实现无模糊目标传感。然后，我们研究了两个不同AFDM线性调频子载波之间的互模糊函数（CAF），该函数表现出与AAF相同的局部和全局特性，但在多普勒维度上额外存在一个偏移。随后，我们将分析扩展到各种典型AFDM帧的模糊函数，同时考虑确定性导频和随机数据符号。特别地，我们证明了在AFDM中插入保护符号有助于实现无干扰传感。仿真结果验证了我们的理论发现，突显了AFDM在ISAC应用中的强大潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [385] [Unobtrusive Reflectance Photoplethysmography for Detecting and Severity Grading of Sleep Apnea via Oxygen Desaturation Index](https://arxiv.org/abs/2507.08399)
> *利用无干扰反射光电容积脉搏波描记法通过氧去饱和指数检测和严重程度分级睡眠呼吸暂停*

*Karen Adam, Clémentine Aguet, Patrick Theurillat, Florent Baty, Maximilian Boesch, Damien Ferrario, Mathieu Lemay, Martin Brutsche, Fabian Braun* | **Category: eess.SP** | **Updated: 2025-07-11**

**Keywords:** 睡眠呼吸暂停, 光电容积脉搏波描记法, 氧去饱和指数, 可穿戴设备, 睡眠监测

**Comment:** Accepted to BMT2025

> **TL;DR:** 该研究使用可穿戴设备在手腕和上臂测量反射光电容积脉搏波描记法 (PPG) 以估算睡眠期间的连续血氧饱和度 (SpO2) 和氧去饱和指数 (ODI)。研究发现，上臂测量的 ODI 是中度或重度睡眠呼吸暂停的良好预测指标（准确率为 86%，敏感性为 96%，特异性为 70%），而手腕测量的 ODI 则不太可靠。

**AI_Comments:** 该研究的创新之处在于利用无干扰的可穿戴设备（特别是上臂 PPG）来估算睡眠呼吸暂停的严重程度，这为家庭监测和早期诊断提供了新的可能性。然而，手腕测量结果的不可靠性表明需要进一步优化测量技术或选择合适的测量部位。未来的研究可以探索结合多种生理信号以提高诊断准确性，并进行更大规模的临床验证。

<details>
  <summary>Details</summary>

**Motivation:** 睡眠呼吸暂停是一种常见的慢性睡眠相关疾病，常与其他心脑血管疾病并存。目前的诊断方法需要进行多导睡眠图检查，这通常需要在睡眠实验室进行过夜检查。本研究的动机是探索一种更便捷的诊断方法。

**Method:** 研究人员使用可穿戴设备在手腕和上臂测量反射光电容积脉搏波描记法 (PPG)，以估算睡眠期间的连续血氧饱和度 (SpO2) 水平，并从中推导出每位患者的氧去饱和指数 (ODI)。随后，研究人员在一个包含 170 名接受睡眠呼吸暂停筛查的患者的队列中，评估了 ODI 是否能作为诊断和评估睡眠呼吸暂停严重程度的替代指标（相对于呼吸暂停低通气指数 AHI）。研究还比较了不同测量部位（指尖、上臂、手腕）的 ODI 诊断性能，并评估了 ODI 作为中度和重度睡眠呼吸暂停直接预测指标的准确性。

**Result:** 上臂测量的 ODI 值是中度或重度睡眠呼吸暂停的良好预测指标，准确率为 86%，敏感性为 96%，特异性为 70%。而手腕测量的 ODI 值作为诊断工具的可靠性较低。

**Conclusion:** 基于 PPG 的 ODI 测量，特别是来自上臂的测量，可以作为一种无干扰的、有潜力的工具，用于睡眠呼吸暂停的筛查和严重程度分级，有望替代或补充传统的 AHI 指标。

> **ai_Abstract:** 本研究旨在评估无干扰的反射光电容积脉搏波描记法 (PPG) 测量（特别是上臂和手腕的 ODI）在检测和评估睡眠呼吸暂停严重程度方面的有效性。研究结果表明，上臂的 PPG 测量可以提供准确的 ODI 值，作为中度或重度睡眠呼吸暂停的可靠预测指标，准确率达到 86%，而手腕的测量则效果不佳。

> **摘要翻译:** 睡眠呼吸暂停是一种常见的慢性睡眠相关疾病，已知是脑血管和心血管疾病的合并症。睡眠呼吸暂停的诊断通常需要睡眠实验室的过夜多导睡眠图检查。在本研究中，我们使用了一种可穿戴设备，测量手腕和上臂的反射光电容积脉搏波描记法 (PPG)，以估算睡眠期间的连续血氧饱和度 (SpO2) 水平，并由此推导出每位患者的氧去饱和指数 (ODI)。在一个包含 170 名接受睡眠呼吸暂停筛查的患者的队列中，我们评估了该 ODI 值是否能作为诊断和评估睡眠呼吸暂停严重程度的呼吸暂停低通气指数 (AHI) 的替代标志物。由于 ODI 同时在指尖、上臂和手腕获得，我们比较了 ODI 在不同测量部位的诊断性能。然后，我们进一步评估了 ODI 作为中度和重度睡眠呼吸暂停（根据既定的 AHI 阈值定义）的直接预测指标的准确性。我们发现，在上臂获得的 ODI 值是中度或重度睡眠呼吸暂停的良好预测指标，准确率为 86%，敏感性为 96%，特异性为 70%，而手腕获得的 ODI 值作为诊断工具的可靠性较低。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [410] [Exploiting Cognition in ISAR Processing for Spectral Compatibility Applications](https://arxiv.org/abs/2507.08423)
> *认知在ISAR处理中用于频谱兼容性应用的利用*

*Massimo Rosamilia, Augusto Aubry, Alessio Balleri, Antonio De Maio, Marco Martorella* | **Category: eess.SP** | **Updated: 2025-07-11**

**Keywords:** 认知ISAR, 频谱兼容性, 波形合成, 频谱感知, 压缩感知

**Comment:** submitted to IEEE Transactions on Radar Systems

> **TL;DR:** 提出一种认知ISAR系统，通过感知和自适应波形设计实现频谱兼容性，并在拥挤的电磁环境中有效成像。

**AI_Comments:** 该论文解决了电磁频谱拥挤这一实际问题。认知方法结合了感知和自适应波形合成，具有创新性。使用压缩感知/秩最小化进行数据恢复是一项重要的技术贡献。未来的工作可以探讨实时实现的挑战以及在更动态的干扰场景下的性能。

<details>
  <summary>Details</summary>

**Motivation:** 在拥挤的电磁环境中，需要ISAR系统能够实现频谱兼容性，在执行成像任务的同时不干扰其他射频（RF）信号。

**Method:** 提出一种认知逆合成孔径雷达（ISAR）方法，包括环境感知（通过频谱传感模块）和动作（合成具有特定频谱缺口的定制雷达波形）。使用压缩感知框架或秩最小化恢复策略来恢复数据。

**Result:** 所设计的架构能够有效实现频谱兼容性，同时提供高质量的ISAR图像，并支持额外的RF活动。

**Conclusion:** 所提出的认知ISAR架构在复杂射频环境中能够有效地实现频谱兼容性并提供高质量的成像。

> **ai_Abstract:** 本文提出了一种认知ISAR方法，通过频谱感知和自适应波形设计（包含频谱缺口），在拥挤的电磁环境中实现频谱兼容性。该方法利用压缩感知或秩最小化技术恢复数据，并在无人机数据集上验证了其在提供高质量ISAR图像和支持其他RF活动方面的有效性。

> **摘要翻译:** 本文介绍并分析了一种认知逆合成孔径雷达（ISAR）的概念，该雷达可在拥挤的电磁环境中确保频谱兼容性。在此背景下，所提出的方法在环境感知（识别其频率范围内的可能发射源）和动作阶段之间交替进行，合成并传输定制的雷达波形，以在实现所需成像任务的同时，保证与叠加发射源的频谱共存。感知通过频谱传感模块进行，该模块提供环境中信号的真实相关频谱参数。动作阶段采用定制的信号设计过程，合成具有特定频谱缺口的雷达波形，从而能够在较宽的频谱带宽上实现ISAR成像，而不干扰其他射频（RF）源。拟议应用的一个关键支撑要求是能够成功恢复频率域（由频谱缺口引起）和慢时间维度（实现认知方式下的并发RF活动）中可能丢失的数据。此过程通过采用基于压缩感知框架或秩最小化恢复策略的先进方法来完成。利用13 GHz至15 GHz频段的无人机测量数据集评估了所提出系统的能力。结果突显了所设计的架构在实现频谱兼容性、提供高质量ISAR图像以及支持其他RF活动方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [435] [A Temporal Gaussian Noise Model for Equalization-enhanced Phase Noise](https://arxiv.org/abs/2507.08470)
> *面向均衡增强相位噪声的时间高斯噪声模型*

*Benedikt Geiger, Fred Buchali, Vahid Aref, Laurent Schmalen* | **Category: eess.SP** | **Updated: 2025-07-11**

**Keywords:** 相位噪声,均衡增强,时间高斯噪声模型,突发性失真,性能预测

**Comment:** Accepted at 51st European Conference on Optical Communication (ECOC),
  Copenhagen, Denmark

> **TL;DR:** 提出了一种时间高斯噪声模型来模拟和预测均衡增强相位噪声导致的突发性失真，该模型通过引入时变失真功率来捕捉这些失真，并通过仿真和实验进行了验证。

**AI_Comments:** 该模型通过引入时变失真功率来捕捉相位噪声，这是一种新颖的方法。模型的准确性和简洁性使其在高符号率传输系统中的应用具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 均衡增强相位噪声在高符号率传输系统中会导致突发性失真。

**Method:** 提出了一种时间高斯噪声模型，该模型通过引入时变失真功率来捕捉均衡增强相位噪声导致的突发性失真。

**Result:** 仿真和实验结果表明，该模型能够准确且简单地预测高符号率传输系统的性能。

**Conclusion:** 所提出的时间高斯噪声模型能够有效捕捉均衡增强相位噪声导致的突发性失真，并为高符号率传输系统的性能预测提供准确且简便的方法。

> **ai_Abstract:** 本文提出了一种时间高斯噪声模型，用于处理高符号率传输系统中由均衡增强相位噪声引起的突发性失真。该模型通过引入时变失真功率来模拟这些失真，并通过仿真和实验验证了其在准确预测系统性能方面的有效性。

> **摘要翻译:** 均衡增强相位噪声会导致高符号率传输系统中的突发性失真。我们提出了一个时间高斯噪声模型，通过引入一个时变失真功率来捕捉这些失真。该模型已通过仿真和实验进行了验证，能够为高符号率传输系统提供准确且简单的性能预测。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [460] [Multi-Symbol Digital AirComp via Modulation Design and Power Adaptation](https://arxiv.org/abs/2507.08670)
> *多符号数字空中计算通过调制设计和功率自适应*

*Xiaojing Yan, Saeed Razavikia, Carlo Fischione* | **Category: eess.SP** | **Updated: 2025-07-11**

**Keywords:** 空中计算, 多符号调制, SeMAC, 功率自适应, 半定规划

**Comment:** 

> **TL;DR:** 该论文提出了一种名为SeMAC的多符号调制框架，用于数字空中计算（AirComp），通过在多个时隙中使用不同的星座图映射输入值到符号序列，以提高对信道噪声的鲁棒性。它还提出了一种功率自适应方案，用于在无法改变调制格式的情况下调整调制符号的幅度和相位。与现有方法相比，SeMAC在计算产品函数时可将计算误差降低高达18 dB。

**AI_Comments:** 该研究在数字空中计算领域提出了创新的SeMAC框架和功率自适应方案，有效地解决了信道噪声对计算可靠性的影响。通过将调制设计转化为可求解的优化问题，并利用数值方法进行求解，为实际应用提供了可行性。然而，该方法在处理大规模系统或复杂函数时的计算复杂度仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高数字空中计算（AirComp）在多址接入信道（MAC）上的可靠性，特别是针对产品函数等复杂计算，需要设计更灵活的调制方案来应对信道噪声。

**Method:** 提出了一种名为SeMAC（Sequential Modulation for AirComp）的多符号调制框架，该框架将输入值映射到跨越多个时隙的符号序列。调制设计被表述为一个非凸优化问题，通过矩阵提升松弛为半定规划（SDP）问题来求解，并利用低秩近似恢复调制解调方案。对于固定调制格式的场景，提出了一种功率自适应方案，通过调整调制符号的幅度和相位来优化性能。

**Result:** SeMAC框架能够通过减少计算误差来可靠地执行计算，与现有方法相比，在计算产品函数时误差可降低高达18 dB。

**Conclusion:** 多符号数字空中计算通过SeMAC框架和功率自适应方案可以显著提高计算的可靠性和准确性，尤其是在存在信道噪声的情况下。

> **ai_Abstract:** 本文提出了一种用于数字空中计算（AirComp）的多符号调制框架SeMAC，它通过在多个时隙中使用不同的星座图将输入值映射到符号序列，以增强对信道噪声的鲁棒性。该方法通过将调制设计转化为一个可解的优化问题来实现，并在无法更改调制格式时提供功率自适应方案。实验结果表明，SeMAC相比现有方法能显著降低计算误差，特别是在计算产品函数时。

> **摘要翻译:** 在本文中，我们考虑数字空中计算（AirComp），并引入了一个名为顺序调制用于AirComp（SeMAC）的新型多符号调制框架。在ChannelComp的基础上，这是一个用于在多址接入信道（MAC）上设计调制方案以支持任意函数计算的通用框架，SeMAC将每个输入值映射到使用跨越多个时隙的不同星座图的调制符号序列。这个扩展通过实现跨越多个传输的灵活调制设计，从而提高了对信道噪声的鲁棒性。我们将调制设计为一个非凸优化问题，应用矩阵提升将其松弛为半定规划（SDP），并通过求解低秩近似来恢复一个可行的调制解决方案。对于无法更改调制格式的情况，我们进一步开发了一种功率自适应方案，该方案在保持调制结构的同时调整调制符号的幅度和相位。数值结果表明，与其它现有方法相比，SeMAC能够通过将计算误差降低高达18 dB来实现可靠的计算，尤其对于产品函数。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [520] [A Review on Deep Learning Autoencoder in the Design of Next-Generation Communication Systems](https://arxiv.org/abs/2412.13843)
> *深度学习自编码器在下一代通信系统设计中的应用综述*

*Omar Alnaseri, Laith Alzubaidi, Yassine Himeur, Mohammed Alaa Ala'anzy, Jens Timmermann, Mohammed S. M. Gismalla* | **Category: eess.SP** | **Updated: 2025-07-11**

**Keywords:** 深度学习,自编码器,通信系统,端到端优化,计算复杂性

**Comment:** 

> **TL;DR:** 该综述探讨了深度学习自编码器在下一代通信系统设计中的应用，重点介绍了其架构、挑战和未来方向，并分析了其计算复杂性。

**AI_Comments:** 这篇综述为理解深度学习自编码器在通信系统中的应用提供了一个全面的概述。它有效地将广泛的研究领域联系起来，并解决了实际实施中的关键挑战。对计算复杂性的分析增加了实践价值，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统通信系统设计模型因简化、范围狭窄和计算限制而不足，深度学习方法，特别是自编码器，为端到端优化提供了数据驱动的解决方案，能够弥合理论模型与现实复杂性之间的差距。

**Method:** 对120项关于无线、光学、语义和量子通信领域的研究进行了全面的调查，并根据收发器设计、信道建模、数字信号处理和计算复杂性对其进行了分类。对自编码器实施中遇到的挑战进行了检查，并分析了自编码器系统的计算复杂性。

**Result:** 自编码器提供了端到端的系统优化解决方案，克服了传统数学模型的局限性。对自编码器系统的计算复杂性进行了分析，包括矩阵乘法、偏置加法和激活函数的评估。

**Conclusion:** 自编码器在下一代通信系统设计中具有变革潜力，为克服传统模型局限性提供了数据驱动的解决方案，并为未来的研究指明了方向。

> **ai_Abstract:** 本文对深度学习自编码器（AE）在下一代通信系统设计中的应用进行了全面的综述。它强调了AE如何通过实现端到端的优化来克服传统数学模型的局限性，并提供了数据驱动的解决方案。该研究审查了120项研究，涵盖了各种通信领域，并根据关键方面进行了分类。此外，它还讨论了AE实施所面临的挑战，并深入分析了其计算复杂性。该论文旨在为未来的研究提供一个路线图，并强调AE在通信领域的变革潜力。

> **摘要翻译:** 传统上用于设计下一代通信系统的数学模型，由于固有的简化、狭窄的范围和计算限制，往往力不从心。近年来，将深度学习（DL）方法融入通信系统在系统设计和性能优化方面取得了重大进展。自编码器（AE）已成为关键，能够实现端到端学习，从而对收发器进行联合优化。因此，AE提供了一种数据驱动的方法，能够弥合理论模型与现实复杂性之间的差距。本文对AE在通信系统中的应用进行了全面的调查，特别关注其架构、相关挑战和未来方向。我们审查了无线、光学、语义和量子通信领域的120项最新研究，并根据收发器设计、信道建模、数字信号处理和计算复杂性对其进行了分类。本文进一步探讨了在实施AE时遇到的挑战，包括对大量训练数据的需求、过度拟合的风险以及对可微分信道模型的要求。通过数据驱动的方法，AE为端到端的系统优化提供了强大的解决方案，超越了受限于简化假设的传统数学模型。本文还通过采用每秒浮点运算次数（FLOPS）的度量标准进行深入分析，总结了与基于AE的系统相关的计算复杂性。该分析包括对矩阵乘法、偏置加法和激活函数的评估。本次调查旨在为未来的研究建立一个路线图，强调AE在制定下一代通信系统方面的变革潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [546] [Physically Large Apertures for Wireless Power Transfer: Performance and Regulatory Aspects](https://arxiv.org/abs/2503.06807)
> *无线能量传输的物理大孔径：性能与法规方面*

*Benjamin J. B. Deutschmann, Ulrich Muehlmann, Ahmet Kaplan, Gilles Callebaut, Thomas Wilding, Bert Cox, Liesbet Van der Perre, Fredrik Tufvesson, Erik G. Larsson, Klaus Witrisal* | **Category: eess.SP** | **Updated: 2025-07-10**

**Keywords:** 无线能量传输, 大孔径, 近场聚焦, 物联网, 法规合规

**Comment:** 

> **TL;DR:** 使用大孔径和近场聚焦技术可以实现距离无关的无线能量传输，并且符合法规要求。

**AI_Comments:** 该研究提出的利用物理大孔径和近场聚焦技术实现距离无关的无线能量传输是一个重要的突破，尤其是在物联网领域。其结合了理论分析和实际测量，并关注了法规和安全性问题，使其研究更具实际应用价值。然而，在大规模部署时，如何精确控制和管理大量设备以及能量源的协同工作仍是需要进一步探讨的问题。

<details>
  <summary>Details</summary>

**Motivation:** 传统的无线能量传输（WPT）功率随距离衰减，限制了物联网设备的大规模部署。需要找到一种解决方案来提高传输效率并克服距离限制。

**Method:** 提出并论证了使用物理大孔径和近场波束聚焦技术，并通过实际测量验证了该方法在提高接收功率、优化功率密度分布以及符合法规要求方面的有效性。

**Result:** 在亚10GHz频率下，使用大孔径和近场聚焦技术可以将设备接收功率提高到毫瓦级别，且功率几乎不随距离变化。该技术还能优化功率密度分布，提高人类暴露安全。

**Conclusion:** 物理大孔径和近场波束聚焦是实现高效、符合法规且距离无关的无线能量传输的关键技术，能够为大规模物联网设备部署提供支持。

> **ai_Abstract:** 该研究探讨了使用物理大孔径和近场波束聚焦技术来改进无线能量传输（WPT）性能。研究表明，大孔径可以实现近乎距离无关的功率传输，并通过精确聚焦功率来提高效率和安全性。实际测量结果证实，在亚10GHz频率下，该技术可以将接收功率提升至毫瓦级别，并符合相关法规。

> **摘要翻译:** 无线能量传输（WPT）是一项有前途的物联网服务，为大规模部署所谓的能量中性设备提供了成本效益高且可持续的解决方案。来自传统发射天线的接收功率随着距离的增加而迅速衰减。从传统的远场波束成形转向近场波束聚焦带来了新的机遇。我们认为，物理大孔径（相对于接收器的距离而言）能够实现一个在实践中与距离无关的功率预算。距离相关的阵列增益模式可以将功率密度最大值精确地聚焦在设备位置，同时降低基础设施附近的功率密度。物理孔径大小是在实现高效且符合法规的WPT的关键资源。我们使用实际测量来证明，在亚10GHz频率下运行的符合法规的系统可以将设备接收的功率提高到毫瓦级别。我们的经验性演示表明，功率最优的近场波束聚焦技术能够利用多径传播，从而提高WPT效率和改善人类暴露安全。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [570] [A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration](https://arxiv.org/abs/2506.06311)
> *一种新颖的感知形状拓扑表示方法及其在探地雷达数据中的深度神经网络集成应用*

*Meiyan Kang, Shizuo Kaji, Sang-Yun Lee, Taegon Kim, Hee-Hwan Ryu, Suyoung Choi* | **Category: eess.SP, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 探地雷达, 拓扑数据分析, YOLOv5, 地下物体检测, 感知形状表示

**Comment:** 15 pages, 6 figures

> **TL;DR:** 该研究提出了一种结合拓扑数据分析（TDA）和YOLOv5深度神经网络（DNN）的新框架，用于改进探地雷达（GPR）数据中的地下管线检测，通过增强形状特征和利用合成数据解决了数据稀疏性问题，并在实验中取得了显著的性能提升。

**AI_Comments:** 该研究提出了一种创新的方法，将拓扑数据分析（TDA）与深度学习（YOLOv5）相结合，用于改进探地雷达（GPR）数据分析，特别是在地下管线检测方面。其亮点在于引入了“感知形状拓扑表示”，能够增强数据的结构特征，从而提高检测精度。此外，采用Sim2Real策略解决了真实世界数据稀缺的问题，这是一个在许多实际应用中都面临的挑战。实验结果的改进也证明了该方法的有效性。然而，文章可以进一步探讨TDA参数选择对结果的影响，以及该方法在更复杂、噪声更严重的环境中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的探地雷达（GPR）解释方法在地下结构探测方面存在对噪声敏感和缺乏结构感知能力的局限性，尤其是在基础设施检测和维护领域。本研究旨在通过一种新颖的框架来克服这些限制，以提高对地下公用设施（特别是管道）的检测能力。

**Method:** 本研究提出了一种新颖的框架，该框架将源自B扫描GPR图像的、使用拓扑数据分析（TDA）提取的感知形状拓扑特征与YOLOv5深度神经网络（DNN）的空间检测能力相结合。为了解决标注真实世界数据的稀缺性问题，研究采用了Sim2Real策略，生成多样化且逼真的合成数据集，以弥合模拟与真实世界领域的差距。

**Result:** 实验结果表明，该方法在平均精度均值（mAP）方面取得了显著的改进，验证了该方法的鲁棒性和有效性。

**Conclusion:** 该方法展示了TDA增强学习在实现可靠的、实时的地下物体检测方面的潜力，在城市规划、安全检查和基础设施管理等领域具有广泛的应用前景。

> **ai_Abstract:** 本研究提出了一种新颖的框架，通过结合拓扑数据分析（TDA）提取的感知形状拓扑特征和YOLOv5深度神经网络（DNN）的空间检测能力，来改进探地雷达（GPR）数据中地下管线的检测。该方法通过增强数据中的结构特征来提高模型对物体几何形状的敏感度，并利用Sim2Real策略生成合成数据以克服真实世界数据稀缺的问题。实验结果显示，该方法在mAP指标上取得了显著提升，证明了其在实时地下物体检测方面的有效性和潜力。

> **摘要翻译:** 探地雷达（GPR）是一种广泛使用的无损检测（NDT）技术，用于地下勘探，特别是在基础设施检测和维护中。然而，传统的解释方法常常受到噪声敏感性和缺乏结构意识的限制。本研究提出了一个新颖的框架，通过整合源自B扫描GPR图像的感知形状拓扑特征（使用拓扑数据分析（TDA）导出）与YOLOv5深度神经网络（DNN）的空间检测能力，来增强地下公用设施（特别是管道）的检测。我们提出了一种新颖的感知形状拓扑表示，它放大了输入数据中的结构特征，从而提高了模型对埋藏物体几何特征的响应能力。为了解决标注真实世界数据的稀缺性问题，我们采用了Sim2Real策略，生成了多样化且逼真的合成数据集，有效地弥合了模拟与真实世界领域之间的差距。实验结果表明，平均精度均值（mAP）得到了显著改善，验证了我们方法的鲁棒性和有效性。该方法强调了TDA增强学习在实现可靠的、实时的地下物体检测方面的潜力，在城市规划、安全检查和基础设施管理方面具有广泛的应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [39] [UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift](https://arxiv.org/abs/2503.20653)
> *UWarp: 一种用于表征扫描仪引起的局部域偏移的全玻片图像配准流程*

*Antoine Schieb, Bilal Hadjadji, Natalia Fernanda Valderrama, Daniel Tshokola Mweze, Valentin Derangère, Laurent Arnould, Sylvain Ladoire, Alain Lalande, Alessio Fiorin, Carlos López Pablo, Noèlia Gallardo Borràs, Shrief Abdelazeez, Vincenzo Della Mea, Anna Korzynska, Louis-Oscar Morel, Nathan Vinçon* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-10**

**Keywords:** 全玻片图像配准, 域偏移, 深度学习, 计算病理学, 组织密度

**Comment:** preprint

> **TL;DR:** 开发了UWarp，一种新的全玻片图像配准工具，用于准确对齐不同扫描条件下获取的组织切片，以表征扫描仪引起的局部域偏移，并发现其与组织密度相关。

**AI_Comments:** 本文提出了一种新颖的配准工具UWarp，其创新点在于采用了结合全局和局部校正的分层配准方法，实现了高精度的全玻片图像对齐，并显著减少了计算时间。其重要性在于，首次将扫描仪引起的域偏移分析从宏观层面推进到微观的斑块层面，揭示了局部组织特性对深度学习模型预测准确性的影响，为计算病理学中模型鲁棒性和域适应策略的改进提供了有价值的工具和见解。

<details>
  <summary>Details</summary>

**Motivation:** 组织病理学玻片数字化引入的扫描仪引起的域偏移会显著影响基于深度学习的计算病理学模型。现有技术通常在大尺度（玻片级或数据集级）表征这种偏移，而非斑块级，这限制了对局部组织特征对深度学习模型准确性影响的理解。

**Method:** 提出一个基于UWarp的域偏移分析框架。UWarp是一种新颖的配准工具，采用分层配准方法，结合全局仿射变换和精细局部校正，实现鲁棒的组织斑块对齐。

**Result:** UWarp优于现有开源配准方法，中位数目标配准误差（TRE）小于4像素（40倍放大下小于1微米），同时显著减少计算时间。此外，应用UWarp表征了Breast-NEOprAIdict模型预测中扫描仪引起的局部域偏移，发现预测变异性与给定斑块上的组织密度强相关。

**Conclusion:** 局部域偏移分析的重要性被强调，UWarp可作为提高计算病理学中模型鲁棒性和域适应策略的宝贵工具。

> **ai_Abstract:** 本研究介绍了UWarp，一个用于全玻片图像配准的新工具，旨在解决组织病理学图像中扫描仪引起的局部域偏移问题。UWarp采用分层配准方法，结合全局和局部校正，实现了高精度和高效率的图像对齐。实验证明，UWarp在配准精度和计算时间上优于现有方法。此外，研究利用UWarp分析了深度学习模型预测中的局部域偏移，发现其与组织密度相关，强调了局部域偏移分析对提高计算病理学模型鲁棒性的重要性。

> **摘要翻译:** 组织病理学玻片数字化引入的扫描仪引起的域偏移会显著影响基于深度学习方法的计算病理学模型。在现有技术中，这种偏移通常在大尺度（玻片级或数据集级）进行表征，而非斑块级，这限制了我们对局部组织特征对深度学习模型准确性影响的理解。为了解决这一挑战，我们提出了一个基于UWarp的域偏移分析框架。UWarp是一种新颖的配准工具，旨在准确对齐在不同条件下扫描的组织学玻片。UWarp采用分层配准方法，结合全局仿射变换和精细局部校正，以实现鲁棒的组织斑块对齐。我们使用两个私人数据集CypathLung和BosomShieldBreast评估了UWarp，这些数据集包含由多个设备扫描的全玻片图像。我们的实验表明，UWarp优于现有开源配准方法，实现了小于4像素的中位数目标配准误差（TRE）（在40倍放大下小于1微米），同时显著减少了计算时间。此外，我们将UWarp应用于表征乳腺癌病理反应预测深度学习模型Breast-NEOprAIdict预测中扫描仪引起的局部域偏移。我们发现预测变异性与给定斑块上的组织密度强相关。我们的发现强调了局部域偏移分析的重要性，并表明UWarp可以作为提高计算病理学中模型鲁棒性和域适应策略的宝贵工具。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [174] [Computationally Efficient Information-Driven Optical Design with Interchanging Optimization](https://arxiv.org/abs/2507.07789)
> *计算高效的信息驱动光学设计与交替优化*

*Eric Markley, Henry Pinkard, Leyla Kabuli, Nalini Singh, Laura Waller* | **Category: eess.IV, cs.CE, cs.CV, cs.IT, math.IT, physics.optics** | **Updated: 2025-07-11**

**Keywords:** 信息驱动, 光学设计, 交替优化, IDEAL, 成像系统

**Comment:** 

> **TL;DR:** 本文提出IDEAL-IO，通过解耦密度估计和光学参数优化，显著提高信息驱动光学设计的计算效率和实用性，解决了现有方法IDEAL内存占用高、运行时间长的问题。

**AI_Comments:** 本文的创新之处在于通过引入交替优化策略（IDEAL-IO），有效地解决了现有信息驱动光学设计方法IDEAL在计算效率和内存使用上的局限性。这种解耦密度估计和参数优化的方法，使得信息论优化在实际成像系统设计中变得更加实用和可扩展，具有重要的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信息驱动编码器分析学习（IDEAL）方法在评估成像系统时，存在内存使用量大、运行时间长以及由于端到端可微分性要求导致目标函数可能不匹配的问题。

**Method:** 本文引入了带交替优化的IDEAL（IDEAL-IO）方法。该方法通过在拟合模型到当前测量和使用固定模型更新光学参数以进行信息估计之间交替进行，从而将密度估计与光学参数优化解耦。

**Result:** IDEAL-IO将运行时间与内存使用量减少了高达6倍，并支持更具表达力的密度模型，从而引导优化获得更优的设计。该方法在衍射光学、无透镜成像和快照3D显微镜应用中得到了验证。

**Conclusion:** 信息论优化被确立为一种实用且可扩展的真实世界成像系统设计策略。

> **ai_Abstract:** 本文针对现有信息驱动光学设计方法IDEAL面临的计算效率低下、内存占用高以及目标函数潜在不匹配问题，提出了一种名为IDEAL-IO的新方法。IDEAL-IO通过将密度估计与光学参数优化解耦并进行交替优化，显著降低了运行时间和内存消耗（高达6倍），同时能利用更具表达力的密度模型以获得更优的设计。该方法在多种成像系统应用中得到验证，证明了信息论优化作为一种实用且可扩展的真实世界成像系统设计策略的可行性。

> **摘要翻译:** 最近的工作表明，成像系统可以通过其测量的单独信息内容进行评估，从而实现与应用无关的光学设计，避免计算解码挑战。信息驱动编码器分析学习（IDEAL）被提出，通过基于梯度的优化自动化这一过程。在这项工作中，我们研究了IDEAL在各种成像系统中的表现，发现它存在内存使用量高、运行时间长以及由于端到端可微分性要求导致目标函数可能不匹配的问题。我们引入了带交替优化的IDEAL（IDEAL-IO），这是一种通过在拟合模型到当前测量和使用固定模型更新光学参数以进行信息估计之间交替进行，从而将密度估计与光学参数优化解耦的方法。这种方法将运行时间与内存使用量减少了高达6倍，同时支持更具表达力的密度模型，从而引导优化获得更优的设计。我们在衍射光学、无透镜成像和快照3D显微镜应用中验证了我们的方法，将信息论优化确立为一种实用且可扩展的真实世界成像系统设计策略。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [229] [Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation](https://arxiv.org/abs/2507.05314)
> *用于精确伤口和刻度标记分割的双注意力U-Net++，结合类别特定集成和贝叶斯超参数优化*

*Daniel Cieślak, Miriam Reca, Olena Onyshchenko, Jacek Rumiński* | **Category: eess.IV, cs.AI, cs.CV, cs.LG, I.4.6; I.5.1; I.2.6; J.3** | **Updated: 2025-07-07**

**Keywords:** 伤口分割, 刻度标记分割, 双注意力U-Net++, 类别特定集成, 贝叶斯超参数优化

**Comment:** 11 pages, conference: Joint 20th Nordic-Baltic Conference on
  Biomedical Engineering & 24th Polish Conference on Biocybernetics and
  Biomedical Engineering; 6 figures, 2 tables, 11 sources

> **TL;DR:** 提出一种结合双注意力机制、类别特定模型集成和贝叶斯优化的U-Net++，用于精确分割伤口和刻度标记，并在竞赛中取得优异性能。

**AI_Comments:** 该论文提出了一种高度工程化的解决方案，结合了多种先进技术：双注意力U-Net++、类别特定集成、贝叶斯超参数优化和测试时间增强。这种全面的方法解决了医学图像分割中的关键挑战，如类别不平衡和变异性。通过基准测试确定EfficientNet-B7作为最佳编码器，以及独立训练类别特定模型是其显著特点。在竞赛数据集上取得的强大性能（F1分数为0.8640）突显了其实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 临床图像中伤口和刻度标记的精确分割仍然是一个重大挑战，这对于有效的伤口管理和自动化评估至关重要。

**Method:** 本研究提出了一种新颖的双注意力U-Net++架构，集成了通道注意力（SCSE）和空间注意力机制，以有效解决医学图像中严重的类别不平衡和变异性。通过5折交叉验证对各种架构和编码器进行基准测试，确定EfficientNet-B7为最佳编码器骨干。随后，独立训练了两个类别特定的模型，并进行了定制的预处理、广泛的数据增强和贝叶斯超参数调整（WandB sweeps）。最终的模型集成利用测试时间增强进一步提高了预测的可靠性。

**Result:** 所提出的方法在NBC 2025和PCBBE 2025竞赛的基准数据集上进行了评估，达到了0.8640的加权F1分数（75%伤口，25%刻度标记）。

**Conclusion:** 所提出的方法取得了0.8640的F1分数，突显了其在复杂医学分割任务中的有效性。

> **ai_Abstract:** 本文提出了一种结合通道和空间双注意力机制的U-Net++架构，旨在提高临床图像中伤口和刻度标记的精确分割。该方法通过广泛的基准测试选择了EfficientNet-B7作为编码器，并独立训练了两个类别特定的模型，采用了贝叶斯超参数优化和数据增强。最终模型采用测试时间增强的集成策略以提高预测可靠性。在竞赛基准数据集上进行评估，该方法取得了0.8640的加权F1分数，证明了其在复杂医学分割任务中的有效性。

> **摘要翻译:** 临床图像中伤口和刻度标记的精确分割仍然是一个重大挑战，对于有效的伤口管理和自动化评估至关重要。在本研究中，我们提出了一种新颖的双注意力U-Net++架构，它集成了通道注意力（SCSE）和空间注意力机制，以有效解决医学图像中严重的类别不平衡和变异性。最初，通过5折交叉验证对各种架构和编码器进行了广泛的基准测试，确定EfficientNet-B7为最佳编码器骨干。随后，我们独立训练了两个类别特定的模型，并进行了定制的预处理、广泛的数据增强和贝叶斯超参数调整（WandB sweeps）。最终的模型集成利用测试时间增强进一步提高了预测的可靠性。我们的方法在NBC 2025和PCBBE 2025竞赛的基准数据集上进行了评估。分割性能使用加权F1分数（75%伤口，25%刻度标记）进行量化，该分数由竞赛组织者在未公开的硬件上外部计算。所提出的方法取得了0.8640的F1分数，突显了其在复杂医学分割任务中的有效性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [465] [3D forest semantic segmentation using multispectral LiDAR and 3D deep learning](https://arxiv.org/abs/2507.08025)
> *利用多光谱激光雷达和3D深度学习进行3D森林语义分割*

*Narges Takhtkeshha, Lauris Bocaux, Lassi Ruoppa, Fabio Remondino, Gottfried Mandlburger, Antero Kukko, Juha Hyyppä* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-08**

**Keywords:** 多光谱激光雷达, 3D深度学习, 森林语义分割, KPConv, 森林盘存

**Comment:** 

> **TL;DR:** 多光谱激光雷达结合3D深度学习（特别是KPConv模型）能显著提高森林成分自动分割的精度。

**AI_Comments:** 该研究有效地展示了多光谱激光雷达数据结合先进的3D深度学习技术在森林盘存等关键环境应用中的价值。对不同模型和特征集的比较分析提供了有价值的见解。潜在的局限性可能在于研究结果对不同森林类型或LiDAR系统的泛化能力，这需要进一步的研究。

<details>
  <summary>Details</summary>

**Motivation:** 森林盘存对于森林资源保护和决策至关重要。激光雷达（LiDAR）作为一种无损的遥感技术，能够简化耗时的人工森林盘存过程。多光谱（MS）LiDAR系统能同时获取三维空间和多波长的光谱信息，有助于估算森林的生化和生物物理特征。因此，研究多光谱LiDAR数据在森林语义分割中的潜力，以实现精确的森林盘存是本研究的动机。

**Method:** 本研究利用HeliALS系统捕获的高密度多光谱点云数据，并实现了三种点式3D深度学习模型（核点卷积KPConv、Superpoint Transformer、Point Transformer V3）和一种机器学习模型（随机森林），用于将森林分割为六个组成部分：地面、低植被、树干、树枝、叶冠和木质碎片。研究还考察了不同的几何和光谱特征向量场景。

**Result:** 实验证实了KPConv模型的优越精度。当将所有三个波长（1550 nm、905 nm和532 nm）作为初始特征输入深度学习模型时，平均交并比（mIoU）和平均准确率（mAcc）分别提高了33.73%和32.35%。

**Conclusion:** 本研究突显了多光谱激光雷达在提高全自动森林成分分割精度方面的优异潜力。

> **ai_Abstract:** 本研究利用HeliALS系统的多光谱激光雷达数据和3D深度学习技术，对森林成分进行语义分割。通过对比KPConv、Superpoint Transformer、Point Transformer V3和随机森林等模型，发现KPConv精度最高。实验表明，将1550 nm、905 nm和532 nm三个波长的光谱信息作为输入特征，能显著提升分割性能，证明了多光谱激光雷达在自动化森林盘存中的巨大潜力。

> **摘要翻译:** 森林保护和决策制定需要定期的森林盘存。在过去的二十年里，激光雷达（LiDAR）在激光扫描系统中作为一种远程无损的解决方案获得了显著关注，以简化劳动密集且耗时的森林盘存过程。先进的多光谱（MS）LiDAR系统能够同时获取跨越多个电磁光谱波长的三维空间和光谱信息。因此，MS-LiDAR技术能够估算森林的生化和生物物理特征。森林成分分割对于森林盘存至关重要。空间和光谱激光信息的协同使用已被证明有利于实现精确的森林语义分割。因此，本研究旨在调查由HeliALS系统捕获的多光谱LiDAR数据的潜力，该系统提供高密度多光谱点云，用于将森林分割为六个组成部分：地面、低植被、树干、树枝、叶冠和木质碎片。实现了三种点式3D深度学习模型和一种机器学习模型，包括核点卷积、Superpoint Transformer、Point Transformer V3和随机森林。我们的实验证实了KPConv模型的优越精度。此外，还考察了各种几何和光谱特征向量场景。通过将所有三个波长（1550 nm、905 nm和532 nm）作为初始特征输入深度学习模型，实现了最高的准确性，平均交并比（mIoU）和平均准确率（mAcc）分别提高了33.73%和32.35%。本研究突显了多光谱激光雷达在提高全自动森林成分分割精度方面的优异潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [495] [Cracking Instance Jigsaw Puzzles: An Alternative to Multiple Instance Learning for Whole Slide Image Analysis](https://arxiv.org/abs/2507.08178)
> *破解实例拼图：全切片图像分析的多实例学习替代方案*

*Xiwen Chen, Peijie Qiu, Wenhui Zhu, Hao Wang, Huayu Li, Xuanzhao Dong, Xiaotong Sun, Xiaobing Yu, Yalin Wang, Abolfazl Razi, Aristeidis Sotiras* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-10**

**Keywords:** 多实例学习, 全切片图像分析, 实例拼图, 空间相关性, 暹罗网络

**Comment:** Accepted by ICCV2025

> **TL;DR:** 提出了一种新的方法来解决全切片图像（WSI）分析中的多实例学习（MIL）问题，通过学习恢复实例的顺序来捕捉空间相关性，而不是依赖于置换不变性，并在分类和生存预测任务中优于现有方法。

**AI_Comments:** 该研究提出了一个新颖的视角，将WSI分析中的实例关系视为一个拼图问题，这是一种对传统MIL方法的有意义的补充。通过利用空间顺序信息，该方法有望在处理具有复杂空间结构的WSI时提供更强的性能。暹罗网络和最优传输理论的应用也为该领域的研究提供了理论支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有的MIL方法在WSI分析中过度依赖置换不变性，限制了其捕捉实例间语义关联的能力。

**Method:** 提出了一种新颖的“实例拼图”任务，通过学习恢复随机打乱的实例的顺序来解决，并提出了一种基于最优传输理论的暹罗网络解决方案。

**Result:** 在WSI分类和生存预测任务中，所提出的方法优于最近最先进的MIL竞争对手。

**Conclusion:** 与依赖置换不变性的传统MIL方法不同，通过学习恢复实例顺序来解决“实例拼图”问题，可以更有效地捕捉实例间的空间相关性，从而在WSI分析任务中取得更好的性能。

> **ai_Abstract:** 本研究提出了一种新颖的全切片图像（WSI）分析方法，作为传统多实例学习（MIL）的替代方案。该方法通过学习恢复图像实例的原始空间顺序（即解决“实例拼图”问题）来捕捉实例间的语义关联，克服了现有MIL方法对置换不变性的过度依赖。研究提出了一种基于最优传输理论的暹罗网络模型来解决此问题，并在WSI分类和生存预测任务中取得了优于最先进MIL方法的性能。

> **摘要翻译:** 虽然多实例学习（MIL）已被证明是组织病理学全切片图像（WSI）分析的一种有前途的方法，但它对置换不变性的依赖严重限制了其有效揭示WSI内实例之间语义关联的能力。基于我们的实证和理论研究，我们认为，不具有置换不变性但能更好地捕捉实例之间空间相关性的方法可以提供更有效的解决方案。鉴于这些发现，我们提出了一种新颖的替代现有MIL方法用于WSI分析的方法，通过学习从实例的随机打乱排列中恢复顺序。我们将此任务称为实例拼图问题，其中揭示了实例之间的语义关联。为了解决实例拼图问题，我们提出了一种新颖的暹罗网络解决方案，该方案在理论上得到了最优传输理论的证明。我们在WSI分类和生存预测任务上验证了所提出的方法，其性能优于最近最先进的MIL竞争对手。代码可在https://github.com/xiwenc1/MIL-JigsawPuzzles获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [525] [Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT](https://arxiv.org/abs/2507.08214)
> *用于非对比CT上节段特异性颈内动脉钙化测绘的深度序列Transformer (DST)*

*Xiangjian Hou, Ebru Yaman Akcicek, Xin Wang, Kazem Hashemizadeh, Scott Mcnally, Chun Yuan, Xiaodong Ma* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-10**

**Keywords:** 深度序列Transformer, 颈内动脉钙化, 节段特异性分析, 概率地标定位, 医学影像分析

**Comment:** 

> **TL;DR:** 该研究提出了一种名为深度序列Transformer (DST) 的新框架，它将3D医学影像分析问题转化为1D序列问题，能够精确地识别颅内颈动脉钙化（ICAC）的不同节段，解决了传统方法在处理高分辨率CT图像时丢失全局信息的问题。DST在临床数据上表现出高精度和鲁棒性，并且在公共分类基准测试中取得了最佳结果，为开发基于钙化位置的生物标志物提供了基础。

**AI_Comments:** 该研究提出的DST框架在处理高分辨率医学影像以进行精细解剖定位方面具有创新性，将3D问题转化为1D序列处理是一个巧妙的解决方案。其在临床数据和公共基准上的优异表现证明了该方法的有效性和潜力。然而，未来研究可以关注其在不同模态影像（如MRI）上的泛化能力，以及与其他成像特征结合以提高临床预测能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的三维模型在处理高分辨率CT图像时，由于需要降采样或处理局部块，会丢失全局上下文信息，导致解剖结构识别和地标定位的准确性下降，无法实现对颈内动脉钙化（ICAC）进行精细的节段特异性量化，而钙化位置对卒中风险和治疗方案有重要影响。

**Method:** 将三维的解剖结构定位问题重新定义为沿着一维轴向的并行概率地标定位任务。提出深度序列Transformer (DST) 框架，将全分辨率的CT图像序列化为一系列二维切片进行处理，学习预测6个独立的概率分布，以精确定位关键解剖地标。

**Result:** DST框架在100名患者的临床队列中进行了评估，并进行了严格的5折交叉验证，实现了0.1个切片的平均绝对误差（MAE），并且96%的预测落在±1个切片的容差范围内。此外，DST骨干网络在公共Clean-CC-CCII分类基准测试中取得了最佳结果。

**Conclusion:** 该研究提出了首个用于自动进行节段特异性ICAC分析的实用工具，即深度序列Transformer (DST) 框架。该框架能够以高精度和鲁棒性处理全分辨率CT图像，克服了传统方法的局限性，为进一步研究位置特异性生物标志物在诊断、预后和手术规划中的作用奠定了基础。

> **ai_Abstract:** 本研究提出了一种名为深度序列Transformer (DST) 的新框架，用于解决颅内颈动脉钙化（ICAC）的节段特异性定位问题。DST将高分辨率CT图像处理为切片序列，通过并行概率地标定位来精确识别不同节段的钙化，克服了传统3D方法在全局上下文信息上的不足。实验结果显示，DST在临床数据上实现了高精度（MAE为0.1个切片），并在公共分类任务中取得领先。该框架为ICAC的精细化分析提供了实用工具，并有望促进对位置特异性生物标志物的研究。

> **摘要翻译:** 虽然总颅内颈动脉钙化（ICAC）体积是既定的卒中生物标志物，但越来越多的证据表明，这种聚合指标忽略了斑块位置的关键影响，因为不同节段的钙化具有不同的预后和手术风险。然而，更精细的、节段特异性的量化在技术上仍然是不可行的。传统的3D模型被迫处理降采样的体积或孤立的斑块，牺牲了解决解剖歧义和进行可靠地标定位所需的全局上下文。为了克服这一点，我们将3D挑战重新定义为沿着1D轴向的并行概率地标定位任务。我们提出了深度序列Transformer（DST），一个处理全分辨率CT体积作为2D切片序列的框架，学习预测N=6个独立的概率分布，以精确的关键解剖地标。我们的DST框架展示了卓越的准确性和鲁棒性。在具有严格5折交叉验证的100名患者临床队列上进行评估，其平均绝对误差（MAE）为0.1个切片，96%的预测落在±1个切片的容差范围内。此外，为了验证其架构能力，DST骨干网络在端到端评估协议下的公共Clean-CC-CCII分类基准上取得了最佳结果。我们的工作提供了第一个用于自动化节段特异性ICAC分析的实用工具。所提出的框架为进一步研究位置特异性生物标志物在诊断、预后和手术规划中的作用奠定了基础。我们的代码将公开发布。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [550] [Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models](https://arxiv.org/abs/2507.08254)
> *猛禽：利用预训练的二维基础模型实现可扩展的 3D 医学体量无训练嵌入*

*Ulzee An, Moonseong Jeong, Simon A. Lee, Aditya Gorla, Yuzhe Yang, Sriram Sankararaman* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-11**

**Keywords:** Raptor, 3D医学体量, 预训练2D基础模型, 无训练嵌入, 随机投影

**Comment:** 21 pages, 10 figures, accepted to ICML 2025. The first two authors
  contributed equally

> **TL;DR:** Raptor是一种无需训练的方法，通过利用预训练的2D基础模型从医学体量数据中提取视觉标记，并使用随机投影进行空间压缩，从而生成语义丰富的嵌入。该方法在10项医学体量任务上表现优于现有方法，且无需昂贵的训练过程。

**AI_Comments:** 该研究提出了一种名为Raptor的新颖的无训练方法，用于生成3D医学体量数据的嵌入。该方法利用了预训练的2D基础模型，并通过随机投影进行降维，有效地解决了体量数据训练的计算复杂性和数据集规模问题。Raptor在多项任务上的优异表现，尤其是在无需训练的情况下，证明了其潜力和有效性。然而，可以进一步探讨该方法在不同模态的医学影像上的泛化能力以及随机投影的具体参数对性能的影响。

<details>
  <summary>Details</summary>

**Motivation:** 当前在开发用于体量成像数据（如MRI）的基础模型时，存在高维训练复杂性和大规模体量数据集的挑战。Raptor旨在解决这些问题。

**Method:** Raptor（随机平面张量缩减）是一种无需训练的方法，它利用一个在自然图像上预训练的冻结2D基础模型来提取医学体量数据的各个横截面的视觉标记，然后使用随机投影进行空间压缩，以降低计算复杂性并保留语义信息。

**Result:** Raptor在十项不同的医学体量任务上进行了广泛的实验，其性能优于最先进的方法，包括那些仅在医学体量上预训练的方法。具体来说，在SuPreM上提高了3%，在MISFM上提高了6%，在Merlin上提高了10%，在VoCo上提高了13%，在SLIViT上提高了14%，并且完全无需昂贵的训练。

**Conclusion:** Raptor是一种有效且通用的方法，为推动基于深度学习的医学体量方法的发展奠定了基础，它能够生成高质量的嵌入，同时避免了昂贵的训练过程。

> **ai_Abstract:** Raptor是一种创新的无训练方法，利用预训练的2D基础模型从医学体量数据中提取视觉标记，并通过随机投影进行压缩，以生成语义丰富的嵌入。该方法显著降低了计算复杂性，并在多项医学体量任务上取得了优于现有方法的性能，无需进行耗时的训练。

> **摘要翻译:** 当前在开发用于体量成像数据（如磁共振成像（MRI））的基础模型时面临的挑战，源于在高维中训练最先进架构的计算复杂性以及策划足够大的体量数据集。为了解决这些挑战，我们引入了Raptor（随机平面张量缩减），一种用于生成体量数据语义丰富嵌入的无训练方法。Raptor利用一个在自然图像上预训练的冻结2D基础模型，从医学体量的各个横截面提取视觉标记。然后，使用随机投影对这些标记进行空间压缩，在显著降低计算复杂性的同时保留了语义信息。在十项不同的医学体量任务上的广泛实验证明，Raptor的性能优于最先进的方法（包括那些仅在医学体量上预训练的方法）（+3% SuPreM，+6% MISFM，+10% Merlin，+13% VoCo和+14% SLIViT），同时完全避免了昂贵的训练需求。我们的结果突显了Raptor作为推动医学体量深度学习方法发展的基石的有效性和多功能性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [574] [MetaH2: A Snapshot Metasurface HDR Hyperspectral Camera](https://arxiv.org/abs/2507.08282)
> *MetaH2：快照式超表面高动态范围高光谱相机*

*Yuxuan Liu, Qi Guo* | **Category: eess.IV** | **Updated: 2025-07-11**

**Keywords:** 超表面相机,高动态范围成像,高光谱成像,快照成像,计算断层成像光谱

**Comment:** To appear in IEEE ICIP 2025

> **TL;DR:** 该研究提出了一种名为MetaH2的快照式超表面相机，能够同时实现高动态范围(HDR)和高光谱成像，并在模拟和实际场景中展现出优于现有方法的性能。

**AI_Comments:** 该研究在超表面相机技术上取得了重要进展，成功实现了快照式的HDR和高光谱成像，这在许多应用领域具有巨大潜力。其集成的多重曝光和CTIS技术以及深度学习重建模型是关键创新点。然而，文中未提及该方法的计算复杂度、实时性以及在复杂光照条件下的鲁棒性等问题，这些是未来研究可以关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种能够同时进行高动态范围(HDR)和高光谱成像的快照式相机，以克服现有方法的局限性。

**Method:** 通过集成曝光包围和计算断层成像光谱（CTIS）技术，利用超表面在单个传感器上同时形成具有不同功率比和色差的多个空间多路复用投影。随后，使用深度学习重建模型处理这些测量数据，以生成HDR图像和高光谱数据立方体。

**Result:** 模拟研究表明，该系统在基准数据集上的重建精度优于先前的方法。实际原型机展示了在600 nm至700 nm光谱范围内，从单色传感器重建具有60 dB动态范围和10 nm光谱分辨率的快照图像。

**Conclusion:** MetaH2相机成功实现了快照式HDR和高光谱成像，并且在重建精度和性能上优于现有技术，为未来的成像技术提供了新的解决方案。

> **ai_Abstract:** 该研究介绍了一种名为MetaH2的创新超表面相机，它能够同时捕获高动态范围（HDR）和高光谱信息，并且成像过程是快照式的。该系统通过结合曝光包围和计算断层成像光谱（CTIS）技术，利用超表面在单个传感器上生成具有不同特征的投影。深度学习模型用于重建最终的HDR图像和高光谱数据立方体。模拟和实际原型测试结果均表明，该方法在重建精度和性能上优于现有技术，实现了宽动态范围和高光谱分辨率的快照成像。

> **摘要翻译:** 我们提出了一种超表面相机，该相机可在快照模式下联合执行高动态范围（HDR）和高光谱成像。该系统通过在光电传感器上同时形成具有独特功率比和色差的多个空间多路复用投影，集成了曝光包围和计算断层成像光谱（CTIS）。随后，通过深度重建模型处理测量结果，以生成HDR图像和高光谱数据立方体。我们的模拟研究表明，与先前的方法相比，所提出的系统在基准数据集上实现了更高的重建精度。我们组装了一个工作原型，并展示了从单色光电传感器对真实场景进行快照重建，实现了600 nm至700 nm范围内的60 dB动态范围和10 nm光谱分辨率。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [602] [Onboard Neuromorphic Split Computing via Optical Links for LEO Remote Sensing](https://arxiv.org/abs/2507.08490)
> *基于光链路的在轨神经形态分布式计算用于低地球轨道遥感*

*Zihang Song, Petar Popovski* | **Category: eess.IV** | **Updated: 2025-07-11**

**Keywords:** 神经形态计算,分布式计算,低地球轨道,光学链路,脉冲神经网络

**Comment:** 

> **TL;DR:** 该论文提出了一种用于低地球轨道（LEO）卫星星座的神经形态分布式计算框架，利用事件驱动的传感和脉冲神经网络（SNN）在不同卫星之间进行信息处理和推理，通过光链路传输，实现了高能效和高精度。

**AI_Comments:** 这项工作在利用神经形态计算和光学互连技术解决LEO卫星通信和计算挑战方面具有重要意义。其创新性在于提出的分布式计算框架和学习的脉冲映射方案，能够有效降低通信开销并提高能效。然而，实际部署的复杂性和鲁棒性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）卫星星座需要满足严格的功耗和通信限制，同时实现机载智能。

**Method:** 提出了一种神经形态分布式计算框架，其中边缘卫星使用动态视觉传感器（DVS）和轻量级脉冲神经网络（SNN）编码器进行事件驱动的传感，核心卫星使用强大的SNN解码器进行推理。通过学习的脉冲映射方案直接通过光互连链路（OISLs）传输，无需传统调制开销。

**Result:** 在合成航空场景分类实验中，提出的架构实现了与现代大型视觉处理流程相当的准确性，同时能效与现有的轻量级实现相当。

**Conclusion:** 神经形态计算有潜力为低地球轨道（LEO）遥感任务实现高能效的星间分布式计算。

> **ai_Abstract:** 该研究提出了一种新颖的神经形态分布式计算框架，专门为低地球轨道（LEO）卫星星座设计，以应对其严苛的功耗和通信要求。该框架利用边缘卫星的事件驱动传感和轻量级SNN编码器，以及核心卫星的SNN解码器进行推理，并通过光链路实现高效通信。实验证明，该方法在保持高精度的同时，还能实现优异的能效。

> **摘要翻译:** 低地球轨道（LEO）卫星星座日益需要在严格的功耗和通信限制下实现机载智能。本文提出了一种针对分层LEO系统的神经形态分布式计算框架，其中边缘卫星使用动态视觉传感器（DVS）和轻量级脉冲神经网络（SNN）编码器执行事件驱动的传感，而核心卫星则使用强大的SNN解码器进行推理。学习的脉冲映射方案能够直接通过光互连链路（OISLs）传输，无需传统的调制开销。在合成航空场景分类实验中，结果表明所提出的架构实现了与现代大型视觉处理流程相当的准确性，同时提供了与现有轻量级实现相当的能效。这些发现凸显了神经形态计算在LEO遥感任务中实现高能效的星间分布式计算的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [578] [DARAS: Dynamic Audio-Room Acoustic Synthesis for Blind Room Impulse Response Estimation](https://arxiv.org/abs/2507.08135)
> *DARAS：动态音频-房间声学合成用于盲房间冲激响应估计*

*Chunxi Wang, Maoshen Jia, Wenyu Jin* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-10**

**Keywords:** 房间冲激响应, 盲估计, DARAS, Mamba, 声学合成

**Comment:** 14 pages, 9 figures, submitted to IEEE/ACM Transactions on Audio,
  Speech, and Language Processing

> **TL;DR:** 提出DARAS模型，一种用于盲房间冲激响应估计的深度学习框架，通过动态声学调优decoder自适应地分割早期反射和晚期混响，以提高合成RIR的真实感，实验结果表明DARAS显著优于现有基线模型。

**AI_Comments:** DARAS模型在处理盲房间冲激响应估计方面取得了显著进展，其创新的多模块设计和利用Mamba SSM的特点使其在实际应用中具有潜力。然而，模型在不同类型和大小的房间中的泛化能力以及计算效率仍需进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有盲估计方法难以达到实际精度，需要更有效的盲房间冲激响应估计方法。

**Method:** 提出DARAS模型，包含深度音频编码器、基于Mamba的自监督盲房间参数估计模块（MASS-BRPE）、混合路径交叉注意力特征融合模块和动态声学调优（DAT）解码器。

**Result:** DARAS模型在MUSHRA主观听觉研究中，相比现有基线模型在实际盲房间冲激响应估计方面表现更优越，提供了鲁棒且有效的解决方案。

**Conclusion:** DARAS模型为实际盲房间冲激响应估计提供了一个鲁棒且有效的解决方案，显著优于现有方法。

> **ai_Abstract:** DARAS是一个新颖的深度学习框架，用于从单声道混响语音信号进行盲房间冲激响应（RIR）估计。该模型通过深度音频编码器提取特征，利用Mamba基模块估计房间参数，并通过交叉注意力融合音频和房间特征。其动态声学调优解码器能够自适应地分割早期反射和晚期混响，以提高合成RIR的真实感。实验证明DARAS在实际应用中优于现有方法。

> **摘要翻译:** 房间冲激响应（RIR）准确地表征了室内声学特性，并在语音增强、语音识别以及增强现实（AR）和虚拟现实（VR）中的音频渲染等应用中发挥着至关重要的作用。现有的盲估计方法在达到实际精度方面存在困难。为了克服这一挑战，我们提出了动态音频-房间声学合成（DARAS）模型，这是一个新颖的深度学习框架，专门用于从单声道混响语音信号进行盲RIR估计。首先，专用的深度音频编码器有效地提取相关的非线性潜在空间特征。其次，利用高效的Mamba状态空间模型（SSM）的Mamba基自监督盲房间参数估计（MASS-BRPE）模块，准确地估计关键的房间声学参数和特征。第三，系统包含一个混合路径交叉注意力特征融合模块，增强了音频和房间声学特征之间的深度集成。最后，我们提出的动态声学调优（DAT）解码器自适应地分割早期反射和晚期混响，以提高合成RIR的真实感。实验结果，包括基于MUSHRA的主观听觉研究，证明DARAS显著优于现有的基线模型，为实际的盲RIR估计在真实声学环境中提供了鲁棒且有效的解决方案。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [605] [RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing](https://arxiv.org/abs/2507.08227)
> *原始TFNet：一种用于语音反欺骗的轻量级CNN架构*

*Yang Xiao, Ting Dang, Rohan Kumar Das* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-11**

**Keywords:** 语音反欺骗, 轻量级CNN, RawTFNet, 特征表示, 计算效率

**Comment:** Submitted to APSIPA ASC 2025

> **TL;DR:** 提出了一种名为RawTFNet的轻量级CNN模型，用于语音反欺骗，在不牺牲性能的情况下减少了计算资源的需求。

**AI_Comments:** 该研究成功地提出了一种轻量级的CNN模型RawTFNet，解决了现有Transformer模型计算量大的问题，在语音反欺骗任务上实现了与SOTA相当的性能和更高的计算效率。模型将开源，具有良好的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Transformer的反欺骗模型虽然性能优越，但需要高计算能力。需要一种能耗更低的解决方案。

**Method:** 提出了一种名为RawTFNet的轻量级CNN模型，该模型沿时间和频率维度分离特征处理，以捕获合成语音的细粒度细节。

**Result:** RawTFNet在ASVspoof 2021 LA和DF评估数据集上达到了与最先进模型相当的性能，同时使用的计算资源更少。

**Conclusion:** RawTFNet是一种有效的轻量级CNN模型，能够以较低的计算成本实现先进的语音反欺骗性能。

> **ai_Abstract:** 本文介绍了一种名为RawTFNet的新型轻量级卷积神经网络（CNN）架构，专门用于解决自动说话人验证（ASV）系统中的语音欺骗攻击问题。与现有基于Transformer但计算量大的模型不同，RawTFNet通过在时间和频率维度上分离特征处理，能够有效捕捉合成语音的细微差别，从而在保持高性能的同时显著降低了计算需求。在ASVspoof 2021 LA和DF数据集上的实验结果表明，RawTFNet的性能与最先进模型相当，但计算效率更高。

> **摘要翻译:** 自动说话人验证（ASV）系统经常受到欺骗攻击的影响。最近基于Transformer的模型通过学习强大的特征表示提高了反欺骗性能。然而，这些模型通常需要高计算能力。为了解决这个问题，我们引入了RawTFNet，一个为音频信号设计的轻量级CNN模型。RawTFNet沿时间和频率维度分离特征处理，这有助于捕获合成语音的细粒度细节。我们在ASVspoof 2021 LA和DF评估数据集上测试了RawTFNet。结果表明，RawTFNet在达到与最先进模型相当的性能的同时，使用的计算资源也更少。代码和模型将公开发布。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [3] [Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications](https://arxiv.org/abs/2507.08015)
> *评估 FinGPT 模型在金融自然语言处理应用中的能力与局限性*

*Prudence Djagba, Chimezie A. Odinakachukwu* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-06**

**Keywords:** FinGPT, 金融NLP, 语言模型, 情感分析, 文本分类

**Comment:** 

> **TL;DR:** FinGPT在金融领域的分类任务上表现良好，可与GPT-4媲美，但在推理和生成任务上表现较弱，尚未成为一个全面的解决方案。

**AI_Comments:** 这项研究为FinGPT在金融NLP领域的性能提供了宝贵的基准。它清晰地界定了该模型在分类任务上的优势以及在复杂推理和生成任务上的局限性，这对于指导金融语言模型的未来发展至关重要。与GPT-4和人类基准的比较进一步增强了研究结果的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 评估FinGPT这一金融领域专用语言模型在金融NLP应用中的能力与局限性。

**Method:** 研究评估了FinGPT在六项关键NLP任务（情感分析、文本分类、命名实体识别、金融问答、文本摘要、股票走势预测）上的表现。评估使用了金融特定数据集，并与GPT-4和人类基准进行了比较。

**Result:** FinGPT在情感分析和标题分类等分类任务中表现出色，常能达到与GPT-4相当的结果。然而，在涉及推理和生成的任务（如金融问答和摘要）中，其性能显著较低。与GPT-4和人类基准的比较揭示了显著的性能差距，尤其是在数值准确性和复杂推理方面。

**Conclusion:** 研究结果表明，FinGPT对于某些结构化的金融任务是有效的，但尚未成为一个全面的解决方案。这项研究为未来的研究提供了有用的基准，并强调了金融语言模型在架构改进和领域特定优化方面的需求。

> **ai_Abstract:** 本研究评估了金融领域专用语言模型FinGPT在六项核心金融NLP任务中的表现。FinGPT在情感分析和文本分类等分类任务中表现出色，甚至能与GPT-4媲美，但在金融问答和文本摘要等需要推理和生成的任务中表现明显不足。与GPT-4和人类基准的对比揭示了其在数值准确性和复杂推理方面的差距。研究得出结论，FinGPT虽对特定结构化金融任务有效，但尚未成为一个全面的解决方案，并强调了未来在架构改进和领域优化方面的必要性。

> **摘要翻译:** 这项工作评估了FinGPT，一个金融领域专用的语言模型，在六项关键的自然语言处理（NLP）任务中的表现：情感分析、文本分类、命名实体识别、金融问答、文本摘要和股票走势预测。评估使用了金融特定数据集，以评估FinGPT在真实世界金融应用中的能力和局限性。结果显示，FinGPT在情感分析和标题分类等分类任务中表现强劲，通常能达到与GPT-4相当的结果。然而，在涉及推理和生成的任务（如金融问答和摘要）中，其性能显著较低。与GPT-4和人类基准的比较突出了显著的性能差距，特别是在数值准确性和复杂推理方面。总的来说，研究结果表明，虽然FinGPT对于某些结构化的金融任务是有效的，但它尚未成为一个全面的解决方案。这项研究为未来的研究提供了有用的基准，并强调了金融语言模型在架构改进和领域特定优化方面的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [18] [LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning](https://arxiv.org/abs/2507.08496)
> *LLaPa: 一种反事实感知程序规划的视觉语言模型框架*

*Shibo Sun, Xue Li, Donglin Di, Mingjie Wei, Lanshun Nie, Wei-Nan Zhang, Dechen Zhan, Yang Song, Lei Fan* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 视觉语言模型, 程序规划, 反事实推理, 多模态, 具身AI

**Comment:** 

> **TL;DR:** LLaPa是一个视觉语言模型框架，通过整合多模态输入和反事实推理，显著提升了具身AI的程序规划能力。

**AI_Comments:** 本文的创新之处在于提出了LLaPa框架，巧妙地将视觉语言模型与专门设计的辅助模块（TER和CAR）结合，以解决具身AI程序规划中多模态输入和反事实推理的集成难题。TER通过任务敏感特征空间优化文本与视觉对齐，而CAR则通过识别和强调反事实条件显著提升了模型的鲁棒性。其在基准测试上的优异表现证明了该方法的有效性和重要性，为具身AI的复杂任务规划提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 虽然大语言模型（LLMs）在具身AI系统的程序规划方面取得了进展，但多模态输入和反事实推理的整合仍未得到充分探索。

**Method:** 本文引入了LLaPa，一个视觉语言模型（VLM）框架，用于多模态程序规划。LLaPa利用VLM从文本任务描述和视觉环境图像生成可执行动作序列。此外，它通过两个辅助模块进行增强：任务-环境重排序器（TER）利用任务导向分割创建任务敏感特征空间，对齐文本与视觉环境；反事实活动检索器（CAR）识别并强调潜在的反事实条件，增强模型在反事实场景下的推理能力。

**Result:** 在ActPlan-1K和ALFRED基准测试中，LLaPa生成的规划质量更高，具有更优的LCS和正确性，并且优于现有先进模型。

**Conclusion:** LLaPa通过有效整合多模态输入和反事实推理，显著提升了具身AI系统中的程序规划能力。

> **ai_Abstract:** 本文介绍了LLaPa，一个用于多模态程序规划的视觉语言模型框架，旨在解决现有LLM在具身AI系统中多模态输入和反事实推理整合不足的问题。LLaPa通过VLMs从文本和图像生成动作序列，并辅以任务-环境重排序器（TER）以对齐文本与视觉环境，以及反事实活动检索器（CAR）以增强反事实推理。实验结果表明，LLaPa在ActPlan-1K和ALFRED基准测试上表现优异，生成了更高质量、更高正确性的规划。

> **摘要翻译:** 虽然大型语言模型（LLMs）通过强大的推理能力推动了具身AI系统的程序规划发展，但多模态输入和反事实推理的整合仍未得到充分探索。为了解决这些挑战，我们引入了LLaPa，一个专为多模态程序规划设计的视觉语言模型框架。LLaPa利用视觉语言模型（VLMs）从文本任务描述和视觉环境图像生成可执行的动作序列。此外，我们通过两个辅助模块增强了LLaPa以改进程序规划。第一个模块，任务-环境重排序器（TER），利用面向任务的分割创建任务敏感特征空间，对齐文本描述与视觉环境，并强调程序执行的关键区域。第二个模块，反事实活动检索器（CAR），识别并强调潜在的反事实条件，增强模型在反事实场景下的推理能力。在ActPlan-1K和ALFRED基准测试中进行的广泛实验表明，LLaPa生成了具有更高LCS和正确性的高质量规划，优于现有先进模型。代码和模型可在https://github.com/sunshibo1234/LLaPa获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [20] [Review, Remask, Refine (R3): Process-Guided Block Diffusion for Text Generation](https://arxiv.org/abs/2507.08018)
> *回顾、重掩、精炼 (R3)：过程引导的块扩散文本生成*

*Nikita Mounier, Parsa Idehpour* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-07**

**Keywords:** 文本生成, 扩散模型, 错误纠正, 迭代生成, R3

**Comment:** Accepted at Methods and Opportunities at Small Scale (MOSS), ICML
  2025

> **TL;DR:** R3是一个无需额外训练的框架，它使用过程奖励模型识别并纠正迭代文本生成中的错误，通过对分数低的块进行更多重掩码来精炼输出。

**AI_Comments:** R3框架的创新之处在于其“回顾、重掩、精炼”的迭代纠错机制，以及无需额外模型训练即可应用于现有预训练模型的通用性。它通过引入过程奖励模型来指导错误识别和纠正，提供了一种高效提升文本生成质量的途径，特别是在处理长文本或复杂结构时可能具有显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 迭代文本生成面临的一个关键挑战是如何让模型有效地识别并纠正自身的错误。

**Method:** R3框架利用一个过程奖励模型（PRM）来审查中间生成的文本块。PRM分数低的块（表明潜在错误）会被按比例重新掩盖更多令牌。模型随后被引导去精炼这些被标记的片段，从而更集中地改进过去生成中的次优部分。

**Result:** 最终输出得到改进。

**Conclusion:** R3提供了一个简单而优雅的框架，无需额外模型训练即可应用于任何预训练的掩码文本扩散模型，有效提升了迭代文本生成的错误识别和纠正能力，从而改进最终输出。

> **ai_Abstract:** R3是一个无需额外训练的文本生成框架，旨在解决迭代生成中模型自我纠错的难题。它通过过程奖励模型（PRM）评估中间生成的文本块，并根据PRM分数低（错误可能）的块进行更多令牌的重掩码，引导模型集中精炼这些次优部分，最终提升文本生成质量。该框架可应用于现有的预训练掩码文本扩散模型。

> **摘要翻译:** 迭代文本生成的一个关键挑战是使模型能够有效地识别和纠正自身的错误。我们提出了回顾、重掩、精炼（R3），这是一个相对简单而优雅的框架，它不需要额外的模型训练，并且可以应用于任何预训练的掩码文本扩散模型（例如LLaDA或BD3-LM）。在R3中，过程奖励模型（PRM）用于审查中间生成的块。该框架随后将这些PRM分数转化为重掩策略：块的PRM分数越低，表明潜在的错误越多，该块中被重掩的令牌比例就越大。最后，模型被迫精炼这些目标片段，更集中地将精力放在过去生成中的特定次优部分，从而改善最终输出。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [22] [Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights](https://arxiv.org/abs/2507.08036)
> *整合医学视觉问答到放射科工作流程中的障碍：一项范围界定回顾和临床医生的见解*

*Deepali Mishra, Chaklam Silpasuwanchai, Ashutosh Modi, Madhumita Sushil, Sorayouth Chumnanvej* | **Category: cs.CL, cs.CV** | **Updated: 2025-07-09**

**Keywords:** 医学视觉问答, 放射学工作流程, 临床整合, 障碍, 范围界定回顾

**Comment:** 29 pages, 5 figures (1 in supplementary), 3 tables (1 in main text, 2
  in supplementary). Scoping review and clinician survey

> **TL;DR:** MedVQA在放射科临床整合面临挑战，因现有模型和数据集与临床需求脱节，临床医生实用性评价不高。

**AI_Comments:** 本研究通过结合文献回顾和临床医生访谈，全面揭示了MedVQA在临床落地中的实际障碍，其价值在于从用户（临床医生）视角提供了宝贵的见解，指出了现有技术与临床需求之间的核心脱节，为未来MedVQA的研究和开发指明了方向，强调了临床相关性和实用性的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管医学视觉问答（MedVQA）在模型和数据集方面取得了进展，但其在临床工作流程中的整合仍然有限。本研究旨在系统性地审查和调查MedVQA的实际效用、挑战和差距。

**Method:** 本研究采用双管齐下的方法：1) 系统性回顾了2018年至2024年的68篇相关出版物，以识别放射学工作流程中的关键概念、进展和研究空白；2) 调查了来自印度和泰国的50名临床医生，以获取他们对MedVQA临床相关性的看法。研究遵循Arksey和O'Malley的范围界定回顾框架。

**Result:** 回顾发现近60%的问答对是非诊断性的，缺乏临床相关性。大多数数据集和模型不支持多视图、多分辨率成像、电子健康记录（EHR）集成或领域知识，而这些是临床诊断的必要特征。当前评估指标与临床需求之间存在明显错配。临床医生调查证实了这种脱节：只有29.8%的受访者认为MedVQA系统高度有用。主要担忧包括缺乏患者病史或领域知识（87.2%）、偏好手动策划的数据集（51.1%）以及需要多视图图像支持（78.7%）。此外，66%的受访者偏爱专注于特定解剖区域的模型，89.4%偏爱基于对话的交互系统。

**Conclusion:** 尽管医学视觉问答（MedVQA）显示出巨大潜力，但必须解决多模态分析有限、缺乏患者背景和评估方法错位等挑战，才能实现有效的临床整合。

> **ai_Abstract:** 本研究通过对68篇文献的范围界定回顾和对50名临床医生的调查，探讨了医学视觉问答（MedVQA）在放射科临床工作流程中整合的障碍。研究发现，现有MedVQA模型和数据集在临床实用性上存在显著差距，例如缺乏诊断相关性、不支持多模态成像和EHR集成，且评估指标与临床需求不符。临床医生也普遍认为MedVQA系统实用性不高，并强调了患者病史、领域知识、多视图支持和交互式系统的必要性。研究强调，为实现MedVQA的有效临床整合，需解决多模态分析、患者上下文和评估方法错位等问题。

> **摘要翻译:** 医学视觉问答（MedVQA）是一个有前途的工具，通过问答自动化医学图像解释来辅助放射科医生。尽管模型和数据集取得了进展，但MedVQA在临床工作流程中的整合仍然有限。本研究系统性回顾了68篇出版物（2018-2024年），并调查了来自印度和泰国的50名临床医生，以检验MedVQA的实际效用、挑战和差距。遵循Arksey和O'Malley的范围界定回顾框架，我们采用了双管齐下的方法：（1）回顾研究以识别放射学工作流程中的关键概念、进展和研究空白，以及（2）调查临床医生以获取他们对MedVQA临床相关性的看法。我们的回顾显示，近60%的问答对是非诊断性的，缺乏临床相关性。大多数数据集和模型不支持多视图、多分辨率成像、电子健康记录（EHR）集成或领域知识，而这些是临床诊断必不可少的特征。此外，当前评估指标与临床需求之间存在明显的错配。临床医生调查证实了这种脱节：只有29.8%的受访者认为MedVQA系统高度有用。主要担忧包括缺乏患者病史或领域知识（87.2%）、偏好手动策划的数据集（51.1%）以及需要多视图图像支持（78.7%）。此外，66%的受访者偏爱专注于特定解剖区域的模型，89.4%偏爱基于对话的交互系统。尽管MedVQA显示出巨大潜力，但必须解决多模态分析有限、缺乏患者背景和评估方法错位等挑战，才能实现有效的临床整合。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [34] [Can LLMs Reliably Simulate Real Students' Abilities in Mathematics and Reading Comprehension?](https://arxiv.org/abs/2507.08232)
> *大型语言模型能否可靠地模拟真实学生在数学和阅读理解方面的能力？*

*KV Aditya Srivatsa, Kaushal Kumar Maurya, Ekaterina Kochmar* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** LLMs, 学生模拟, 项目反应理论, 教育评估, 智能辅导系统

**Comment:** Accepted to the 20th Workshop on Innovative Use of NLP for Building
  Educational Applications (BEA), co-located with ACL 2025

> **TL;DR:** 大型语言模型（LLMs）无法可靠地模拟真实学生在数学和阅读理解方面的能力，这表明需要新的训练和评估策略。

**AI_Comments:** 该论文揭示了当前LLMs在作为教育领域学生代理时的一个关键局限性。其创新之处在于应用IRT模型系统地评估LLM相对于真实学生能力量表的表现，提供了挑战LLM可靠模拟假设的实证证据。这对于开发有效的智能辅导系统（ITSs）和测试设计至关重要，因为它指出了LLM能力上的显著差距，并强调了针对教育目标进行领域特定微调和评估的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正越来越多地被用作智能辅导系统（ITSs）开发和试题预测试中的代理学生，但它们在多大程度上准确模拟了真实学生的行为和特征，仍然是一个悬而未决的问题。

**Method:** 本研究收集了来自国家教育进展评估（NAEP）的489个题目数据集，涵盖了4、8和12年级的数学和阅读理解。然后，应用项目反应理论（IRT）模型，将11个多样化且最先进的LLMs置于与真实学生群体相同的能力量表上。研究还测试了使用年级强制提示对模型表现的影响。

**Result:** 研究发现，在没有指导的情况下，强大的通用LLMs在每个年级都始终优于普通学生，而较弱或领域不匹配的模型可能会偶然对齐。使用年级强制提示会改变模型的表现，但没有一个评估过的模型-提示对能在所有科目和年级中都可靠地与平均年级水平学生对齐。

**Conclusion:** LLMs未能始终如一地模拟真实学生的能力，这强调了需要新的训练和评估策略。研究最后根据发现为选择可行的代理提供了指导。

> **ai_Abstract:** 本研究旨在调查大型语言模型（LLMs）能否可靠地模拟真实学生在数学和阅读理解方面的能力。通过对国家教育进展评估（NAEP）的489个题目应用项目反应理论（IRT）模型，并将11个LLMs置于与真实学生相同的能力量表上，研究发现，在没有特定指导的情况下，强大的LLMs通常表现优于普通学生。尽管年级强制提示能改变模型表现，但没有一个LLM-提示组合能在所有科目和年级中始终与平均年级水平学生的能力相匹配。这强调了开发准确学生代理需要新的训练和评估策略。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地被用作智能辅导系统（ITSs）开发和试题预测试中的代理学生。然而，这些代理学生在多大程度上准确模拟了真实学生的行为和特征，仍然是一个悬而未决的问题。为了调查这一点，我们收集了来自国家教育进展评估（NAEP）的489个题目数据集，涵盖了4、8和12年级的数学和阅读理解。然后，我们应用项目反应理论（IRT）模型，将11个多样化且最先进的LLMs置于与真实学生群体相同的能力量表上。我们的研究结果表明，在没有指导的情况下，强大的通用模型在每个年级都始终优于普通学生，而较弱或领域不匹配的模型可能会偶然对齐。使用年级强制提示会改变模型的表现，但它们是否与平均年级水平学生对齐在很大程度上取决于模型和提示的特定性：没有一个评估过的模型-提示对能在所有科目和年级中都符合要求，这强调了需要新的训练和评估策略。最后，我们根据我们的发现为选择可行的代理提供了指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [36] [Semantic-Augmented Latent Topic Modeling with LLM-in-the-Loop](https://arxiv.org/abs/2507.08498)
> *语义增强的潜在主题模型与LLM在环*

*Mengze Hong, Chen Jason Zhang, Di Jiang* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 潜在主题模型, 大型语言模型, LDA, 主题连贯性, 后修正

**Comment:** 

> **TL;DR:** 本文探讨了将大型语言模型（LLMs）集成到潜在狄利克雷分配（LDA）的初始化和后修正阶段的效果。结果显示LLM辅助的初始化对收敛无影响且性能最差，而LLM辅助的后修正显著提升了主题连贯性。

**AI_Comments:** 这篇论文通过实证研究，挑战了LLM在所有文本挖掘任务中都表现优异的普遍认知。它指出LLM在主题模型初始化中的局限性，同时展示了其在后修正方面的显著增益，为LLM与其他传统模型的结合提供了新的视角和实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 探索将大型语言模型（LLMs）集成到主题模型（特别是LDA）中，以改善其性能，尤其是在初始化和后修正阶段。

**Method:** 将大型语言模型（LLMs）集成到潜在狄利克雷分配（LDA）的两个关键阶段：初始化和后修正。在初始化阶段，通过LLM引导的主题聚类来初始化Gibbs采样算法；在后修正阶段，使用LLM进行启用。

**Result:** LLM引导的初始化策略虽然改善了LDA的早期迭代，但对收敛没有影响，并且与基线相比表现最差。LLM启用的后修正实现了5.86%的连贯性评估提升。

**Conclusion:** LLM在环的方法具有实际效益，尤其是在后修正方面，并且挑战了LLM总是更优文本挖掘替代方案的信念。

> **ai_Abstract:** 本文研究了通过将大型语言模型（LLMs）集成到潜在狄利克雷分配（LDA）的初始化和后修正阶段来增强主题模型的有效性。研究发现，LLM引导的初始化虽然对早期迭代有益，但对收敛无影响且性能不佳。然而，LLM启用的后修正显著提升了主题连贯性，证明了LLM在环方法的实用价值，并指出LLM并非总是文本挖掘的最佳选择。

> **摘要翻译:** 潜在狄利克雷分配（LDA）是一种著名的生成概率模型，用于揭示文档集合中的抽象主题。在本文中，我们通过将大型语言模型（LLMs）集成到两个关键阶段：初始化和后修正，来探索增强主题模型的有效性。由于LDA高度依赖于其初始化的质量，我们对LLM引导的主题聚类进行了广泛实验，以初始化Gibbs采样算法。有趣的是，实验结果表明，虽然所提出的初始化策略改善了LDA的早期迭代，但它对收敛没有影响，并且与基线相比产生了最差的性能。另一方面，启用LLM的后修正实现了5.86%的连贯性评估的显著改进。这些结果突出了LLM在环方法的实际益处，并挑战了LLM总是更优的文本挖掘替代方案的信念。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [50] [Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency](https://arxiv.org/abs/2507.08309)
> *通过同步自检其OCR能力改进多模态大语言模型（MLLM）的文档图像机器翻译*

*Yupu Liang, Yaping Zhang, Zhiyang Zhang, Zhiyuan Chen, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou* | **Category: cs.CL, cs.AI, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多模态大语言模型, 文档图像机器翻译, 光学字符识别, 灾难性遗忘, 同步自检

**Comment:** Accepted by ACL 2025 Findings

> **TL;DR:** 本文提出了一种名为同步自检（SSR）的新型微调范式，通过在生成翻译文本前先生成OCR文本，以解决多模态大语言模型在文档图像机器翻译（DIMT）中存在的灾难性遗忘问题，并提高了模型在OCR和DIMT任务上的泛化能力。

**AI_Comments:** 这项工作提出了一种新颖且直观的微调策略SSR，通过模拟“双语认知优势”来解决MLLMs在DIMT任务中常见的灾难性遗忘问题。其创新点在于将OCR作为翻译的中间步骤，有效地利用了模型已有的单语能力，同时避免了在学习新任务时遗忘旧知识。这种方法对于提升多模态模型在复杂跨模态跨语言任务上的鲁棒性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在文档图像任务（尤其是光学字符识别OCR）上表现出色，但在文档图像机器翻译（DIMT）方面面临挑战，需要处理跨模态和跨语言问题。现有的通过监督微调（SFT）增强DIMT能力的方法常常导致模型遗忘其原有的单语能力，例如OCR。

**Method:** 本文引入了一种名为“同步自检（SSR）其OCR能力”的新型微调范式，灵感来源于“双语认知优势”概念。具体而言，SSR提示模型在生成翻译文本之前先生成OCR文本，这使得模型能够利用其强大的单语OCR能力，同时学习跨语言翻译文本。

**Result:** 全面的实验表明，所提出的SSR学习有助于缓解灾难性遗忘，提高了MLLMs在OCR和DIMT任务上的泛化能力。

**Conclusion:** 同步自检（SSR）范式是一种有效的方法，可以帮助多模态大语言模型在学习文档图像机器翻译的同时，保持并提升其原有的光学字符识别能力，从而克服灾难性遗忘问题并增强泛化能力。

> **ai_Abstract:** 本文提出了一种名为“同步自检（SSR）其OCR能力”的新型微调范式，旨在解决多模态大语言模型（MLLMs）在文档图像机器翻译（DIMT）任务中因监督微调（SFT）导致的灾难性遗忘问题。SSR通过在生成翻译前强制模型先生成OCR文本，使其能够同时利用强大的OCR能力并学习跨语言翻译。实验证明，SSR有效缓解了灾难性遗忘，并提升了模型在OCR和DIMT任务上的泛化能力。

> **摘要翻译:** 多模态大语言模型（MLLMs）在文档图像任务，尤其是光学字符识别（OCR）方面表现出强大的性能。然而，它们在文档图像机器翻译（DIMT）方面面临挑战，这需要处理跨模态和跨语言的难题。以往通过在DIMT数据集上进行监督微调（SFT）来增强DIMT能力的努力，常常导致模型遗忘其现有的单语能力，例如OCR。为了应对这些挑战，我们引入了一种新颖的微调范式，名为“同步自检（SSR）其OCR能力”，其灵感来源于“双语认知优势”的概念。具体而言，SSR提示模型在生成翻译文本之前先生成OCR文本，这使得模型能够利用其强大的单语OCR能力，同时学习跨语言翻译文本。全面的实验表明，所提出的SSR学习有助于缓解灾难性遗忘，提高了MLLMs在OCR和DIMT任务上的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [64] [The AI Language Proficiency Monitor -- Tracking the Progress of LLMs on Multilingual Benchmarks](https://arxiv.org/abs/2507.08538)
> *AI语言能力监测器——追踪大型语言模型在多语言基准上的进展*

*David Pomerenke, Jonas Nothnagel, Simon Ostermann* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 多语言基准, 低资源语言, AI评估, 语言能力监测器

**Comment:** 

> **TL;DR:** 论文介绍了“AI语言能力监测器”，这是一个评估LLM在多达200种语言（特别是低资源语言）上表现的多语言基准，并提供开源排行榜和仪表板以促进多语言AI的透明度和包容性。

**AI_Comments:** 这篇论文通过开发“AI语言能力监测器”提供了一个重要的开源工具，填补了现有LLM评估在多语言特别是在低资源语言方面评估不足的空白。其创新之处在于聚合了多样化的任务和数据集，并提供动态更新的排行榜和可视化洞察，这对于推动多语言AI的公平发展和研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了确保大型语言模型（LLMs）的益处能够公平地惠及所有人，评估它们在世界各种语言中的能力至关重要，尤其是在低资源语言方面。

**Method:** 本文引入了“AI语言能力监测器”，这是一个全面的多语言基准，用于系统地评估LLM在多达200种语言上的性能。该基准聚合了翻译、问答、数学和推理等多样化任务，并使用了FLORES+、MMLU、GSM8K、TruthfulQA和ARC等数据集。作者还提供了一个开源、自动更新的排行榜和仪表板。

**Result:** 成功构建了“AI语言能力监测器”平台，该平台提供模型排名、全球熟练度地图和随时间变化的趋势洞察，有效帮助研究人员、开发人员和政策制定者识别模型性能的优势和不足。

**Conclusion:** 通过补充和扩展现有的多语言基准，本文提出的“AI语言能力监测器”旨在促进多语言AI领域的透明度、包容性和整体进步。

> **ai_Abstract:** 本文介绍了“AI语言能力监测器”，一个旨在评估大型语言模型在多达200种语言（包括低资源语言）上表现的综合性多语言基准。该监测器整合了翻译、问答、数学和推理等多项任务，并利用了FLORES+等多个数据集。研究团队提供了一个开源、自动更新的排行榜和仪表板，以帮助用户了解模型的表现，并促进多语言AI领域的透明度、包容性和进步。

> **摘要翻译:** 为了确保大型语言模型（LLMs）的益处能够公平地惠及所有人，评估它们在世界各种语言中的能力至关重要。我们引入了AI语言能力监测器，这是一个全面的多语言基准，系统地评估LLM在多达200种语言（尤其侧重于低资源语言）上的性能。我们的基准聚合了包括翻译、问答、数学和推理在内的多种任务，使用了FLORES+、MMLU、GSM8K、TruthfulQA和ARC等数据集。我们提供了一个开源、自动更新的排行榜和仪表板，支持研究人员、开发人员和政策制定者识别模型性能的优势和不足。除了模型排名，该平台还提供描述性洞察，如全球熟练度地图和随时间变化的趋势。通过补充和扩展先前的多语言基准，我们的工作旨在促进多语言AI的透明度、包容性和进步。该系统可在 https://huggingface.co/spaces/fair-forward/evals-for-every-language 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [78] ["Amazing, They All Lean Left" -- Analyzing the Political Temperaments of Current LLMs](https://arxiv.org/abs/2507.08027)
> *“惊人的，它们都偏左”——分析当前大型语言模型的政治倾向*

*W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah, Kund Meghani* | **Category: cs.CL, cs.CY** | **Updated: 2025-07-08**

**Keywords:** 大型语言模型, 政治倾向, 自由主义偏向, 微调, 道德基础理论

**Comment:** 

> **TL;DR:** 本研究系统性地调查了七个主流大型语言模型的政治倾向，发现它们普遍存在自由主义偏向，并将其归因于训练数据、RLHF、学术伦理框架和安全微调。研究认为这种偏向是民主权利导向训练的 emergent property，而非编程错误。

**AI_Comments:** 该研究深入探讨了大型语言模型中普遍存在的政治偏向问题，不仅揭示了现象，更系统性地分析了其成因，包括训练数据、RLHF和伦理框架的影响，具有重要的理论和实践意义。其将“偏向”解释为“民主权利导向训练的 emergent property”的观点颇具新意，为理解LLM的伦理行为提供了新的视角，并提醒我们重新思考AI输出的“偏向”是否总是负面的。

<details>
  <summary>Details</summary>

**Motivation:** 最近研究发现大多数商业大型语言模型在伦理和政治回应上表现出一致的自由主义倾向，但其潜在原因和影响尚不明确。

**Method:** 本研究采用多方面方法，包括道德基础理论、十几个既定的政治意识形态量表以及一个新的当前政治争议指数，调查了七个主流大型语言模型（GPT-4o, Claude Sonnet 4, Perplexity (Sonar Large), Gemini 2.5 Flash, Llama 4, Mistral 7b Le Chat, DeepSeek R1）的政治倾向。

**Result:** 研究发现大多数模型都强烈且一致地优先考虑自由主义价值观，特别是关怀和公平。进一步分析将这种趋势归因于四个重叠因素：偏向自由主义的训练语料库、人类反馈强化学习（RLHF）、学术伦理话语中自由主义框架的主导地位以及安全驱动的微调实践。基模型和微调模型对的比较显示，微调通常会增加自由主义倾向，这通过自报告和实证测试均得到证实。

**Conclusion:** 研究认为大型语言模型的“自由主义倾斜”并非编程错误或程序员的个人偏好，而是基于民主权利导向话语训练的 emergent property。大型语言模型可能间接呼应了约翰·罗尔斯著名的“无知之幕”哲学愿望，反映了一种不依赖于个人身份或利益的道德立场。这种模式可能为审视集体推理提供新的视角，而非损害民主话语。

> **ai_Abstract:** 本研究系统评估了七个主流大型语言模型的政治倾向，发现它们普遍存在自由主义偏向，尤其在关怀和公平价值观上。这种偏向主要源于自由主义训练语料、RLHF、学术伦理框架和安全微调。研究强调微调会加剧这种倾向，并认为这是民主权利话语训练的自然结果，而非错误，可能反映了一种无私的道德立场，为理解集体推理提供了新视角。

> **摘要翻译:** 最近的研究揭示了大多数商业大型语言模型（LLMs）在生成的伦理和政治回应中存在一致的自由主义倾向，然而其潜在原因和由此产生的影响仍不清楚。本文系统地调查了七个著名大型语言模型——OpenAI 的 GPT-4o、Anthropic 的 Claude Sonnet 4、Perplexity (Sonar Large)、Google 的 Gemini 2.5 Flash、Meta AI 的 Llama 4、Mistral 7b Le Chat 和 High-Flyer 的 DeepSeek R1——的政治倾向，采用多方面方法，包括道德基础理论、十几个既定的政治意识形态量表以及一个新的当前政治争议指数。我们发现，在大多数模型中，自由主义价值观，特别是关怀和公平，得到了强烈而一致的优先考虑。进一步分析将这种趋势归因于四个重叠因素：偏向自由主义的训练语料库、人类反馈强化学习（RLHF）、学术伦理话语中自由主义框架的主导地位以及安全驱动的微调实践。我们还区分了政治“偏见”和合法的认知差异，并告诫不要混淆两者。基模型和微调模型对的比较显示，微调通常会增加自由主义倾向，这种效应通过自报告和实证测试均得到证实。我们认为，这种“自由主义倾斜”并非编程错误或程序员的个人偏好，而是基于民主权利导向话语训练的 emergent property。最后，我们提出大型语言模型可能间接呼应了约翰·罗尔斯著名的“无知之幕”哲学愿望，反映了一种不依赖于个人身份或利益的道德立场。这种模式可能为审视集体推理提供新的视角，而非损害民主话语。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [82] [ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains](https://arxiv.org/abs/2507.08427)
> *ChainEdit：通过逻辑规则引导链传播LLM知识编辑中的涟漪效应*

*Zilu Dong, Xiangqing Shen, Zinong Yang, Rui Xia* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 知识编辑, 涟漪效应, 逻辑一致性, 大型语言模型, 知识图谱

**Comment:** Accepted to ACL 2025 (main)

> **TL;DR:** ChainEdit是一个用于LLM知识编辑的框架，它利用知识图谱的逻辑规则和LLM的逻辑推理能力，通过系统地更新逻辑连接的知识簇来有效传播涟漪效应，同时保持逻辑一致性。

**AI_Comments:** ChainEdit的创新点在于将外部结构化知识（知识图谱逻辑规则）与LLM内部推理能力相结合，从而系统性地解决知识编辑中的涟漪效应和逻辑一致性问题。这对于提升LLM知识更新的准确性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM知识编辑方法在将涟漪效应传播到相关事实时，难以保持逻辑一致性。

**Method:** ChainEdit结合了来自知识图谱的逻辑规则和LLM的逻辑推理能力。它通过从结构化知识库中自动提取逻辑模式并将其与LLM的内部逻辑对齐，动态生成和编辑逻辑连接的知识簇。

**Result:** 实验表明，在逻辑泛化方面比基线提高了30%以上，同时保持了编辑的可靠性和特异性。该工作在涟漪效应方面建立了新的SOTA性能，并确保了知识编辑后的内部逻辑一致性。还通过知识感知协议解决了现有基准中的评估偏差。

**Conclusion:** ChainEdit通过结合逻辑规则和LLM推理能力，在LLM知识编辑中实现了有效的涟漪效应传播和逻辑一致性，并在该领域取得了最先进的性能。

> **ai_Abstract:** ChainEdit是一个针对大型语言模型知识编辑的创新框架，旨在解决现有方法在传播涟漪效应时逻辑一致性差的问题。它通过整合知识图谱的逻辑规则和LLM自身的逻辑推理能力，能够自动识别并编辑逻辑关联的知识群。实验证明，ChainEdit在逻辑泛化能力上显著优于基线，同时维护了编辑的准确性和可靠性，并在涟漪效应处理方面达到了最先进水平。

> **摘要翻译:** 当前大型语言模型（LLM）的知识编辑方法在将涟漪效应传播到相关事实时难以保持逻辑一致性。我们提出了ChainEdit，一个将知识图谱衍生的逻辑规则与LLM逻辑推理能力相结合的框架，以实现系统性的链式更新。通过从结构化知识库中自动提取逻辑模式并将其与LLM的内部逻辑对齐，ChainEdit动态生成和编辑逻辑连接的知识簇。实验表明，在逻辑泛化方面比基线提高了30%以上，同时保持了编辑的可靠性和特异性。我们通过知识感知协议进一步解决了现有基准中的评估偏差，这些协议解耦了外部依赖性。这项工作在涟漪效应方面建立了新的最先进性能，同时确保了知识编辑后的内部逻辑一致性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [92] [DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures](https://arxiv.org/abs/2507.08606)
> *DocPolarBERT：一种采用相对极坐标编码布局结构进行文档理解的预训练模型*

*Benno Uthayasooriyar, Antoine Ly, Franck Vermet, Caio Corro* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** DocPolarBERT, 文档理解, 相对极坐标, 预训练模型, 布局感知

**Comment:** 

> **TL;DR:** DocPolarBERT是一个新的BERT模型，利用相对极坐标处理布局，在更小的数据集上实现了SOTA，证明了精心设计的注意力机制能弥补数据量不足。

**AI_Comments:** DocPolarBERT的创新之处在于其引入了相对极坐标编码布局结构，避免了对绝对2D位置嵌入的依赖。其重要性体现在证明了通过优化模型架构（特别是注意力机制），可以在较小的数据集上实现SOTA性能，这对于资源有限的研究者或场景具有重要意义，提供了一种更高效的预训练范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有文档理解模型可能需要绝对2D位置嵌入，且预训练数据量大。本研究旨在提供一种无需绝对2D位置嵌入、且能有效利用较小数据集的文档理解方案。

**Method:** 引入DocPolarBERT，一个布局感知的BERT模型。通过扩展自注意力机制，使其考虑文本块在相对极坐标系中的位置，而非笛卡尔坐标系。

**Result:** DocPolarBERT在比IIT-CDIP语料库小六倍以上的数据集上预训练后，取得了最先进（SOTA）的结果。

**Conclusion:** 精心设计的注意力机制可以弥补预训练数据量的减少，为文档理解提供了一种高效且有效的替代方案。

> **ai_Abstract:** DocPolarBERT是一种新型的布局感知BERT模型，专为文档理解设计，通过采用相对极坐标编码文本块位置，消除了对绝对2D位置嵌入的需求。尽管其预训练数据集远小于现有大型语料库，DocPolarBERT仍能达到最先进的性能，证明了创新的注意力机制能有效弥补数据量限制，提供高效且实用的文档理解方案。

> **摘要翻译:** 我们引入了DocPolarBERT，一个用于文档理解的布局感知BERT模型，它消除了对绝对2D位置嵌入的需求。我们扩展了自注意力机制，使其考虑文本块在相对极坐标系中的位置，而不是笛卡尔坐标系。尽管DocPolarBERT在一个比广泛使用的IIT-CDIP语料库小六倍以上的数据集上进行了预训练，但它仍取得了最先进的结果。这些结果表明，精心设计的注意力机制可以弥补预训练数据的减少，为文档理解提供了一种高效且有效的替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [94] [Better Together: Quantifying the Benefits of AI-Assisted Recruitment](https://arxiv.org/abs/2507.08029)
> *协同增效：量化AI辅助招聘的益处*

*Ada Aka, Emil Palikot, Ali Ansari, Nima Yazdani* | **Category: cs.CL, cs.CY** | **Updated: 2025-07-08**

**Keywords:** AI招聘, 人工智能, 招聘效率, 候选人筛选, 随机对照实验

**Comment:** 

> **TL;DR:** 一项大规模随机对照实验表明，AI辅助招聘显著提高了面试通过率和求职成功率，相较于传统招聘具有明显优势。

**AI_Comments:** 这项研究通过大规模随机对照实验，首次提供了AI辅助招聘的量化证据，具有重要的实践意义。它不仅证明了AI在提高招聘效率方面的潜力，也揭示了AI可能带来的偏向性（如选择更年轻、经验更少的申请者），这对于AI在招聘中的伦理应用和公平性问题提出了思考。对AI面试记录的分析也为深入理解AI决策机制提供了宝贵的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人工智能在招聘中应用日益广泛，但缺乏量化其对招聘效率和候选人筛选影响的实证证据。

**Method:** 研究将37,000名初级开发人员申请者随机分配到传统招聘流程（简历筛选后人工选择）或AI辅助招聘流程（AI驱动的结构化视频面试后人工评估）。两组通过初筛的候选人都面临相同的人工终面，面试官不知晓之前的筛选方法。研究还通过收集LinkedIn资料，比较了两组申请者五个月后找到新工作的概率，并分析了AI生成的面试记录。

**Result:** AI辅助流程的最终面试通过率为54%，而传统流程为34%，平均处理效应为20个百分点。五个月后，AI组申请者找到新工作的比例为23%，而传统组为18%，差异为5.9个百分点。AI系统倾向于选择更年轻、经验更少、学历较低的申请者。

**Conclusion:** 研究结果有助于理解AI技术如何影响招聘和人才获取中的决策，并强调了其潜在影响。

> **ai_Abstract:** 本研究通过一项大规模随机对照实验，量化了AI辅助招聘对招聘效率和候选人选择的影响。结果显示，与传统招聘相比，AI辅助流程显著提高了最终面试通过率和候选人后续找到新工作的概率。研究还发现AI系统倾向于选择特定特征的申请者，并分析了其选择标准，为理解AI在招聘决策中的作用提供了实证依据。

> **摘要翻译:** 人工智能（AI）在招聘中的应用日益广泛，但量化其对招聘效率和候选人筛选影响的实证证据仍然有限。我们随机分配了37,000名初级开发人员职位的申请者，分别进入传统招聘流程（简历筛选后人工选择）或AI辅助招聘流程（在人工评估之前纳入AI驱动的结构化视频面试）。从任一轨道晋级的候选人都面临相同的最终阶段人工面试，面试官对早期的筛选方法一无所知。在AI辅助流程中，54%的候选人通过了最终面试，而传统流程的通过率为34%，产生了20个百分点（标准误差12个百分点）的平均处理效应。五个月后，我们收集了两组顶尖申请者的LinkedIn资料，发现传统流程中有18%（标准误差1.1%）的申请者找到了新工作，而AI组有23%（标准误差2.3%）的申请者找到了新工作，两组之间找到新工作的概率差异为5.9个百分点（标准误差2.6个百分点）。AI系统倾向于选择更年轻、经验更少、学历较低的申请者。我们分析了AI生成的面试记录，以检查选择标准和对话动态。我们的发现有助于理解AI技术如何影响招聘和人才获取中的决策，同时强调了其一些潜在影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [118] [Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach](https://arxiv.org/abs/2507.08487)
> *增强作文连贯性评估：一种新颖的项目反应理论方法*

*Bruno Alexandre Rosa, Hilário Oliveira, Luiz Rodrigues, Eduardo Araujo Oliveira, Rafael Ferreira Mello* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 作文连贯性评估, 项目反应理论, 机器学习, 自动评分, 教育人工智能

**Comment:** 24 pages, 4 tables

> **TL;DR:** 提出了一种基于项目反应理论的新方法，用于调整机器学习模型在自动评估作文连贯性方面的得分，实验证明其优于传统方法。

**AI_Comments:** 本文的创新点在于将项目反应理论（IRT）引入到作文连贯性自动评估中，以解决传统机器学习模型无法考虑文本个体特征的局限性。通过将IRT与机器学习结合，能够更好地表征模型的“能力、难度和区分度”，从而提高了评估的准确性。其重要性在于为教育领域提供了一种更精细、更有效的自动写作评估工具，有助于提升学习成果的评价质量。

<details>
  <summary>Details</summary>

**Motivation:** 自动评估作文连贯性是教育人工智能领域的挑战，现有机器学习算法未考虑语料库中实例的个体特征。项目反应理论可用于表征模型的能力、难度和区分度，从而解决这一问题。

**Method:** 提出并分析了一种基于项目反应理论的连贯性得分预测方法，用于调整机器学习模型生成的得分。实验使用了扩展的Essay-BR（6,563篇ENEM风格作文）和巴西葡萄牙语叙事作文（1,235篇中小学生作文）语料库。提取了325个语言特征，并将问题视为机器学习回归任务。

**Result:** 实验结果表明，所提出的方法在多项评估指标上优于传统的机器学习模型和集成方法。

**Conclusion:** 该研究探索了一种潜在的方法，可用于改进教育作文中连贯性的自动评估。

> **ai_Abstract:** 本文针对教育人工智能领域中自动评估作文连贯性的挑战，提出了一种新颖的方法。该方法基于项目反应理论，用于调整机器学习模型生成的连贯性得分，以解决传统机器学习算法未能充分考虑文本实例个体特征的问题。研究人员在包含6,563篇ENEM风格作文和1,235篇巴西葡萄牙语叙事作文的语料库上进行了实验，提取了325个语言特征，并将问题建模为回归任务。实验结果显示，该方法在多项评估指标上均优于传统的机器学习模型和集成方法，为改进教育作文的自动连贯性评估提供了新的途径。

> **摘要翻译:** 论文被认为是评估写作学习成果的重要机制。文本连贯性是文本的一个基本特征，因为它有助于在文本各部分之间建立意义。在作文中自动评分连贯性是教育人工智能领域的一个挑战。用于评估文本的机器学习算法通常不考虑构成所分析语料库的实例的个体特征。在这种意义上，项目反应理论可以适应机器学习的上下文，表征所使用模型的能力、难度和区分度。这项工作提出并分析了一种基于项目反应理论的连贯性得分预测方法，以调整机器学习模型生成的得分。在本研究中，用于实验的语料库包括扩展的Essay-BR，其中包含6,563篇国家高中考试（ENEM）风格的作文，以及巴西葡萄牙语叙事作文，包含1,235篇由公立学校5至9年级学生撰写的作文。我们提取了325个语言特征，并将问题视为机器学习回归任务。实验结果表明，所提出的方法在多项评估指标上优于传统的机器学习模型和集成方法。这项研究探索了一种潜在的方法，用于改进教育作文中连贯性的自动评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [127] [Large Language Models in Mental Health Care: a Scoping Review](https://arxiv.org/abs/2401.02984)
> *大型语言模型在心理健康护理中的应用：一项范围审查*

*Yining Hua, Fenglin Liu, Kailai Yang, Zehan Li, Hongbin Na, Yi-han Sheu, Peilin Zhou, Lauren V. Moran, Sophia Ananiadou, David A. Clifton, Andrew Beam, John Torous* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 心理健康护理, 范围审查, 应用, 挑战

**Comment:** 

> **TL;DR:** 该范围审查旨在全面分析大型语言模型（LLMs）在心理健康护理中的应用，评估其有效性，识别挑战并探索未来潜力，最终得出LLMs在心理健康护理中潜力巨大，但需解决数据、评估和伦理等限制。

**AI_Comments:** 这篇综述及时地关注了大型语言模型在心理健康这一关键且敏感领域的应用，具有重要的现实意义。其创新之处在于系统性地梳理了LLMs的现有应用、识别了关键挑战并提出了未来发展的方向。论文强调了数据质量、伦理考量和跨学科合作的重要性，这对于指导LLMs在医疗健康领域的负责任发展至关重要。其局限性在于作为一篇综述，它本身不提供新的实验数据，而是对现有文献的总结，但其为后续研究提供了清晰的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 该审查旨在全面分析大型语言模型（LLMs）在心理健康护理中的利用，评估其有效性，识别挑战，并探索其未来应用的潜力。

**Method:** 研究人员于2023年11月在PubMed、Web of Science、Google Scholar、arXiv、medRxiv和PsyArXiv等多个数据库进行了系统搜索。审查纳入了2019年10月1日至2023年12月2日期间发表或传播的所有类型的原创研究，不限语言，只要它们使用了T5之后开发的LLMs并直接调查了心理健康护理设置中的研究问题。

**Result:** 从最初的313篇文章中，根据与LLMs在心理健康护理中应用的相关性和报告结果的严谨性，选择了34篇。审查确定了LLMs在心理健康护理中的各种应用，包括诊断、治疗和增强患者参与度。主要挑战涉及数据可用性和可靠性、心理状态的细致处理以及有效的评估方法。尽管LLMs在提高准确性和可及性方面显示出前景，但在临床适用性和伦理考虑方面存在显著差距。

**Conclusion:** 大型语言模型在增强心理健康护理方面具有巨大潜力。为充分发挥其潜力，必须着重开发强大的数据集、开发和评估框架、伦理指南以及跨学科合作，以解决当前的局限性。

> **ai_Abstract:** 本范围审查系统性地分析了大型语言模型（LLMs）在心理健康护理中的应用。研究筛选了34篇相关文章，发现LLMs在诊断、治疗和患者参与方面具有应用潜力，但也面临数据、细致处理心理状态和评估方法的挑战。尽管LLMs在提高准确性和可及性方面有前景，但临床适用性和伦理问题仍是主要障碍。结论强调，为实现LLMs的全部潜力，需在数据集、开发与评估框架、伦理指南和跨学科合作方面加强努力。

> **摘要翻译:** 目标：本综述旨在全面分析大型语言模型（LLMs）在心理健康护理中的应用，评估其有效性，识别挑战，并探索其未来应用的潜力。材料与方法：2023年11月，研究人员在PubMed、Web of Science、Google Scholar、arXiv、medRxiv和PsyArXiv等多个数据库进行了系统搜索。本综述纳入了2019年10月1日至2023年12月2日期间发表或传播的所有类型的原创研究，无论是否经过同行评审。纳入的研究不限语言，只要它们使用了T5之后开发的LLMs并直接调查了心理健康护理设置中的研究问题。结果：在最初的313篇文章中，根据与LLMs在心理健康护理中应用的相关性和报告结果的严谨性，选择了34篇。综述确定了LLMs在心理健康护理中的各种应用，包括诊断、治疗和增强患者参与度。强调的关键挑战与数据可用性和可靠性、心理状态的细致处理以及有效的评估方法有关。尽管LLMs在提高准确性和可及性方面显示出前景，但在临床适用性和伦理考虑方面存在显著差距。结论：LLMs在增强心理健康护理方面具有巨大潜力。为充分发挥其潜力，必须着重开发强大的数据集、开发和评估框架、伦理指南以及跨学科合作，以解决当前的局限性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [138] [PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts](https://arxiv.org/abs/2507.08499)
> *PromotionGo 在 SemEval-2025 任务 11：一个用于短文本跨语言多情感检测的特征中心框架*

*Ziyi Huang, Xia Cui* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 多情感检测, 跨语言, 短文本, 特征中心框架, SemEval-2025

**Comment:** 

> **TL;DR:** 该论文提出了一个名为 PromotionGo 的特征中心框架，用于 SemEval 2025 任务 11 中的短文本跨语言多标签情感检测。研究评估了文档表示、降维和模型训练，发现 TF-IDF 在低资源语言中有效，而上下文嵌入和 Transformer 模型表现出语言特异性优势，PCA 能在不牺牲性能的情况下缩短训练时间，提供了一个可扩展的多语言情感检测解决方案。

**AI_Comments:** 该论文的创新点在于提出了一个“特征中心”框架，能够动态适应不同语言的文档表示和学习算法，以优化多语言情感检测性能。其重要性体现在为 SemEval 2025 任务 11 提供了一个在短文本多标签情感检测方面的可扩展解决方案，并针对低资源语言和计算效率进行了优化，这对于处理语言多样性和资源受限场景具有实际意义。研究还对比了不同表示方法和降维技术的效果，提供了有价值的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决 SemEval 2025 任务 11 中短文本多标签情感检测的挑战，特别是应对语言多样性和资源限制的问题。

**Method:** 本研究提出了一个特征中心框架，该框架动态调整文档表示和学习算法以优化特定语言的性能。研究评估了文档表示（如 TF-IDF、FastText、Sentence-BERT）、降维（如 PCA）和模型训练（如 MLP）三个关键组件，并在 28 种语言中进行了测试。

**Result:** 结果显示，TF-IDF 在低资源语言中仍然非常有效；FastText 和 Sentence-BERT 等上下文嵌入和基于 Transformer 的文档表示展现出语言特异性优势；PCA 能够在不损害性能的情况下减少训练时间，尤其对 FastText 和 MLP 等神经网络模型有益；计算效率分析强调了模型复杂性和处理成本之间的权衡。

**Conclusion:** 该框架为多语言情感检测提供了一个可扩展的解决方案，有效应对了语言多样性和资源限制的挑战。

> **ai_Abstract:** 该论文介绍了为 SemEval 2025 任务 11 开发的 PromotionGo 系统，该系统是一个特征中心框架，用于短文本的跨语言多标签情感检测。该框架通过动态调整文档表示和学习算法来优化性能。研究评估了不同文档表示（TF-IDF、FastText、Sentence-BERT）、降维技术（PCA）和模型训练方法（MLP）在 28 种语言中的表现。结果表明，TF-IDF 在低资源语言中有效，上下文嵌入具有语言特异性优势，PCA 能有效缩短训练时间。该框架提供了一个可扩展的解决方案，以应对多语言情感检测中的多样性和资源挑战。

> **摘要翻译:** 本文介绍了我们参加 SemEval 2025 任务 11：弥合基于文本的情感检测差距（A 赛道）的系统，该任务专注于短文本中的多标签情感检测。我们提出了一个特征中心框架，该框架动态调整文档表示和学习算法以优化特定语言的性能。我们的研究评估了三个关键组件：文档表示、降维和模型训练，涉及 28 种语言，并重点对其中五种进行了详细分析。结果表明，TF-IDF 对于低资源语言仍然非常有效，而像 FastText 这样的上下文嵌入和像 Sentence-BERT 生成的基于 Transformer 的文档表示则表现出语言特异性优势。主成分分析（PCA）在不损害性能的情况下减少了训练时间，特别有利于 FastText 和多层感知器（MLP）等神经网络模型。计算效率分析强调了模型复杂性和处理成本之间的权衡。我们的框架为多语言情感检测提供了一个可扩展的解决方案，解决了语言多样性和资源限制的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [140] [Answer Generation for Questions With Multiple Information Sources in E-Commerce](https://arxiv.org/abs/2111.14003)
> *电子商务中多信息源问题的答案生成*

*Anand A. Rajasekar, Nikesh Garera* | **Category: cs.CL, cs.LG, I.2.7; H.3.3** | **Updated: 2025-07-11**

**Keywords:** 电子商务, 问答系统, 多信息源, 相关性预测, 答案生成

**Comment:** 7 pages, 10 tables, 1 figure

> **TL;DR:** 针对电商领域用户提问，提出MSQAP管道模型，利用评论、相似问题和商品规格等多源信息，通过相关性预测和歧义预测生成答案，显著优于现有基线模型。

**AI_Comments:** 这项工作在电子商务问答领域具有重要意义，通过整合多样化的信息源并引入相关性和歧义预测步骤，有效地提升了自动问答系统的性能。其创新点在于提出一个端到端的管道模型MSQAP，并验证了其在复杂电商场景下的有效性，尤其是在处理多源信息挑战方面。该研究为未来电商智能客服和知识管理提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 电子商务中用户关于产品的提问量巨大且复杂，亟需自动化答案生成系统。现有系统面临信息不相关和评论/相似问题中情感歧义两大挑战，难以有效利用多源信息。

**Method:** 本文提出一个新颖的管道模型MSQAP，该模型利用评论、重复或相似问题以及规格这三种信息源。在答案生成之前，MSQAP会分别执行相关性预测（使用BERT-QA模型）和歧义预测。答案生成部分使用T5-QA模型。

**Result:** 实验结果显示，相关性预测模型BERT-QA在F1分数上比BERT-base基线提高12.36%。生成模型T5-QA在内容保留指标（如BLEU和ROUGE）上优于基线，ROUGE平均提高35.02%，BLEU平均提高198.75%（对比HSSC-q）。MSQAP完整管道方法在准确性上比T5-QA生成模型总体提高30.7%。这是电子商务领域首次结合商品规格、相似问题和评论数据自动生成自然语言答案的工作。

**Conclusion:** 该研究成功开发并验证了MSQAP管道模型，有效利用电商多源信息解决了答案生成中的信息不相关和情感歧义挑战，显著提高了答案生成的准确性，并填补了电商领域多源信息自动问答的空白。

> **ai_Abstract:** 本文针对电子商务中用户关于产品的海量提问，提出了一种名为MSQAP的新型管道式自动答案生成系统。该系统创新性地整合了产品评论、相似问题和商品规格等多源信息，并通过在答案生成前进行独立的相关性预测（使用BERT-QA模型）和情感歧义预测，有效解决了信息冗余和情感歧义两大挑战。实验结果表明，MSQAP在相关性预测和答案生成质量上均显著优于现有基线模型，并在准确性方面有显著提升。这是电商领域首次实现多源信息融合的自动问答系统。

> **摘要翻译:** 电子商务中自动问答是一项重要但具有挑战性的任务，因为用户会发布数百万关于他们感兴趣购买的产品的问题。因此，迫切需要自动化答案生成系统，利用产品相关信息提供快速响应。可用于回答用户提问的知识来源有三种：评论、重复或相似问题以及规格。有效利用这些信息源将极大地帮助我们回答复杂问题。然而，在利用这些来源时存在两大主要挑战：(i) 存在不相关信息，以及(ii) 评论和相似问题中存在情感歧义。通过这项工作，我们提出了一种新颖的管道（MSQAP），该管道通过在生成响应之前分别执行相关性和歧义预测，从而利用上述来源中丰富的可用信息。实验结果表明，我们的相关性预测模型（BERT-QA）优于所有其他变体，并且与BERT-base基线相比，F1分数提高了12.36%。我们的生成模型（T5-QA）在BLEU、ROUGE等所有内容保留指标上均优于基线，与表现最佳的基线（HSSC-q）相比，ROUGE平均提高了35.02%，BLEU平均提高了198.75%。我们管道的人工评估表明，我们的方法在准确性上比生成模型（T5-QA）总体提高了30.7%，使得我们基于完整管道的方法（MSQAP）提供了更准确的答案。据我们所知，这是电子商务领域第一项结合规格、相似问题和评论数据等多种来源信息自动生成自然语言答案的工作。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [141] [A Systematic Analysis of Declining Medical Safety Messaging in Generative AI Models](https://arxiv.org/abs/2507.08030)
> *生成式AI模型中医疗安全提示信息下降的系统性分析*

*Sonali Sharma, Ahmed M. Alaa, Roxana Daneshjou* | **Category: cs.CL, cs.CE, cs.HC** | **Updated: 2025-07-08**

**Keywords:** 生成式AI, 医疗安全, 免责声明, 大型语言模型, 视觉语言模型

**Comment:** 11 pages, 5 figures

> **TL;DR:** 研究发现，生成式AI模型（包括LLM和VLM）在2022年至2025年期间，其医疗输出中的安全免责声明显著减少，到2025年大多数模型几乎不再显示免责声明，这在AI模型越来越多地用于医疗领域时构成严重安全隐患。

**AI_Comments:** 这篇论文揭示了生成式AI在医疗应用中一个令人担忧的关键趋势。随着AI模型变得越来越强大和普及，安全免责声明的急剧减少带来了显著的患者安全风险。该研究通过跨模型类型和时间段的系统性分析，提供了强有力的证据来支持这一问题。其重要性在于强调了在医疗等敏感领域开发和部署负责任AI的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI模型（如LLM和VLM）在医学图像解释和临床问题回答中的应用日益增多，但其输出常包含不准确信息。医疗免责声明作为一项关键安全措施，旨在提醒用户AI输出未经专业验证，不能替代医疗建议，因此有必要评估其存在情况。

**Method:** 本研究评估了2022年至2025年间LLM和VLM模型输出中免责声明的存在情况。研究使用了500张乳腺X光片、500张胸部X光片、500张皮肤病图像和500个医疗问题，对模型输出进行了免责声明短语的筛选。

**Result:** LLM输出中的医疗免责声明从2022年的26.3%下降到2025年的0.97%；VLM输出中的医疗免责声明从2023年的19.6%下降到2025年的1.05%。到2025年，大多数模型已不再显示免责声明。

**Conclusion:** 随着公开模型变得更强大和更具权威性，必须将免责声明作为一种保障措施加以实施，并使其适应每个输出的临床语境。

> **ai_Abstract:** 本研究系统分析了2022年至2025年间生成式AI模型（包括LLM和VLM）中医疗安全免责声明的趋势。通过评估2000个医疗相关数据（图像和问题）的模型输出，研究发现免责声明的存在率显著下降，从20%以上降至2025年的约1%。鉴于AI模型在医疗领域日益增长的能力和应用，论文强调必须重新实施并使免责声明适应具体的临床语境，以作为关键的安全保障。

> **摘要翻译:** 生成式AI模型，包括大型语言模型（LLM）和视觉语言模型（VLM），正越来越多地用于解释医学图像和回答临床问题。它们的回答常常包含不准确之处；因此，医疗免责声明等安全措施对于提醒用户AI输出未经专业验证或不能替代医疗建议至关重要。本研究评估了2022年至2025年间不同代LLM和VLM输出中免责声明的存在情况。使用500张乳腺X光片、500张胸部X光片、500张皮肤病图像和500个医疗问题，对输出进行了免责声明短语的筛选。LLM和VLM输出中的医疗免责声明存在率分别从2022年的26.3%下降到2025年的0.97%，以及从2023年的19.6%下降到2025年的1.05%。到2025年，大多数模型没有显示任何免责声明。随着公共模型变得更强大和更具权威性，必须将免责声明作为一种保障措施加以实施，并使其适应每个输出的临床语境。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [143] [Signal or Noise? Evaluating Large Language Models in Resume Screening Across Contextual Variations and Human Expert Benchmarks](https://arxiv.org/abs/2507.08019)
> *信号还是噪声？评估大型语言模型在简历筛选中跨上下文变化和人类专家基准的表现*

*Aryan Varshney, Venkat Ram Reddy Ganuthula* | **Category: cs.CL, econ.GN, q-fin.EC** | **Updated: 2025-07-08**

**Keywords:** 大型语言模型, 简历筛选, 上下文变化, 人类专家, 自动化招聘

**Comment:** 

> **TL;DR:** 本研究评估了LLM在简历筛选中的一致性表现，并与人类专家进行了比较。发现LLM在不同上下文中有显著差异，且与人类判断存在显著分歧，这对于将其部署到自动化招聘系统具有指导意义。

**AI_Comments:** 该研究通过严谨的实验设计，深入探讨了LLM在简历筛选这一实际应用中的表现。其创新之处在于对比了不同LLM在多种上下文下的行为，并与人类专家进行了基准比较，揭示了LLM与人类判断之间的显著差异。这对于理解LLM在复杂决策任务中的局限性及其在自动化招聘系统中部署时的潜在风险具有重要意义。研究结果强调了在实际应用中需要谨慎考虑LLM的适用性和人类监督的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查大型语言模型（LLMs）在简历筛选任务中是否表现出一致性行为（信号）或随机变异（噪声），以及它们的表现与人类专家相比如何。

**Method:** 研究使用受控数据集，测试了三种LLM（Claude、GPT和Gemini）在不同上下文（无公司、公司1[跨国公司]、公司2[初创公司]、缩减上下文）下的表现，并使用相同和随机的简历。研究将LLM的表现与三位人类招聘专家进行基准比较，并通过方差分析和配对t检验进行数据分析，还进行了元认知分析。

**Result:** 方差分析显示，在八个仅LLM的条件下，有四个条件存在显著的平均差异，并且LLM与人类评估之间始终存在显著差异（p < 0.01）。配对t检验显示，GPT对公司上下文的适应性强（p < 0.001），Gemini部分适应（公司1为p = 0.038），而Claude适应性最小（p > 0.1）。所有LLM在不同上下文下都与人类专家存在显著差异。元认知分析表明，LLM的自适应加权模式与人类评估方法显著不同。

**Conclusion:** 研究结果表明，LLMs在详细提示下能提供可解释的模式，但与人类判断存在实质性差异，这为它们在自动化招聘系统中的部署提供了信息。

> **ai_Abstract:** 本研究评估了大型语言模型（LLM）在简历筛选任务中的表现，尤其关注其在不同上下文中的一致性以及与人类专家的比较。实验测试了Claude、GPT和Gemini三种LLM，发现它们在不同上下文下表现出显著差异，且与人类招聘专家的判断存在明显分歧。尽管LLM在详细提示下能提供可解释的模式，但其评估方式与人类存在本质差异。研究结果对LLM在自动化招聘系统中的应用提供了重要参考。

> **摘要翻译:** 本研究调查了大型语言模型（LLM）在根据职位描述筛选简历时是否表现出一致行为（信号）或随机变异（噪声），以及它们的表现与人类专家相比如何。我们使用受控数据集，在不同上下文（无公司、公司1[跨国公司]、公司2[初创公司]、缩减上下文）下测试了三种LLM（Claude、GPT和Gemini），使用了相同和随机的简历，并以三位人类招聘专家为基准。方差分析显示，在八个仅LLM的条件下，有四个条件存在显著的平均差异，并且LLM与人类评估之间始终存在显著差异（p < 0.01）。配对t检验显示，GPT对公司上下文的适应性很强（p < 0.001），Gemini部分适应（公司1为p = 0.038），而Claude适应性最小（p > 0.1），同时所有LLM在不同上下文下都与人类专家存在显著差异。元认知分析强调了与人类评估方法显著不同的自适应加权模式。研究结果表明，LLM在详细提示下能提供可解释的模式，但与人类判断存在实质性差异，这为它们在自动化招聘系统中的部署提供了信息。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [163] [Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding](https://arxiv.org/abs/2507.08031)
> *超越规模：小型语言模型在心理健康理解方面可与GPT-4媲美*

*Hong Jia, Shiya Fu, Vassilis Kostakos, Feng Xia, Ting Dang* | **Category: cs.CL** | **Updated: 2025-07-09**

**Keywords:** 小型语言模型, 心理健康理解, 隐私保护, 少样本学习, GPT-4

**Comment:** 

> **TL;DR:** 小型语言模型（SLMs）在心理健康理解任务上的表现与大型语言模型（LLMs）相当，尤其在二元分类任务上，且支持隐私保护。

**AI_Comments:** 这项研究的创新之处在于，它挑战了“规模越大越好”的传统观念，证明了小型语言模型在特定敏感领域（如心理健康理解）中也能表现出色，甚至可与GPT-4等大型模型媲美。其重要性在于为隐私保护和资源受限的应用场景提供了可行的替代方案。同时，研究指出了模型规模并非解决所有复杂理解挑战的万能药，例如在多类别严重性任务上，大小模型均表现出性能下降。

<details>
  <summary>Details</summary>

**Motivation:** 探讨小型语言模型（SLMs）作为隐私保护替代方案，在敏感应用中与大型语言模型（LLMs）相比，其固有的理解能力如何。

**Method:** 通过系统评估，在零样本和少样本学习范式下，比较了五种最先进的SLM（Phi-3, Phi-3.5, Qwen2.5, Llama-3.2, Gemma2）与三种LLM（GPT-4, FLAN-T5-XXL, Alpaca-7B）在六项心理健康理解分类任务上的性能。

**Result:** SLMs在二元分类任务上的平均性能（零样本设置下F1分数0.64）与LLMs（F1分数0.66）相差不到2%。两种模型在多类别严重性任务上均出现超过30%的性能下降。少样本提示显著提升了SLMs的性能（高达14.6%），而LLMs的提升则不确定。

**Conclusion:** SLMs在心理健康理解方面具有巨大潜力，可作为有效的隐私保护工具，用于分析敏感的在线文本数据，并通过少样本学习快速适应和专门化，成为可扩展心理健康筛查工具的理想选择。

> **ai_Abstract:** 本研究探讨了小型语言模型（SLMs）在心理健康理解任务上的能力，并将其与大型语言模型（LLMs）进行比较。结果显示，SLMs在二元分类任务上的表现与LLMs相当，尽管参数量远小于LLMs，且少样本学习能显著提升其性能。这表明SLMs在需要隐私保护的心理健康文本分析中具有巨大潜力，可作为可扩展的筛查工具。

> **摘要翻译:** 小型语言模型（SLM）作为敏感应用的隐私保护替代方案的出现，引发了一个关于其与大型语言模型（LLM）相比固有理解能力的基本问题。本文通过对各种分类任务进行系统评估，研究了当前SLM的心理健康理解能力。我们采用零样本和少样本学习范式，将其性能与已建立的LLM基线进行比较，以阐明它们在这一关键领域中的相对优势和局限性。我们评估了五种最先进的SLM（Phi-3、Phi-3.5、Qwen2.5、Llama-3.2、Gemma2）与三种LLM（GPT-4、FLAN-T5-XXL、Alpaca-7B）在六项心理健康理解任务上的表现。我们的研究结果表明，SLM在二元分类任务上的平均性能与LLM的平均性能相差不到2%（零样本设置下F1分数分别为0.64和0.66），尽管参数数量级少，但仍表现出显著的能力。两种模型类别在多类别严重性任务上都经历了类似的性能下降（下降超过30%），这表明细致入微的临床理解挑战超越了模型规模。少样本提示为SLM带来了显著的改进（高达14.6%），而LLM的收益则更具可变性。我们的工作突出了SLM在心理健康理解方面的潜力，表明它们可以成为分析敏感在线文本数据的有效隐私保护工具。特别是，它们通过少样本学习以最少数据快速适应和专门化的能力，使其成为可扩展心理健康筛查工具的有希望的候选者。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [164] [Riddle Generation using Learning Resources](https://arxiv.org/abs/2310.18290)
> *使用学习资源生成谜语*

*Niharika Sri Parasa, Chaitali Diwan, Srinath Srinivasa* | **Category: cs.CL** | **Updated: 2025-07-10**

**Keywords:** 谜语生成, 在线学习, 概念习得模型, 学习参与度, 学习资源

**Comment:** 

> **TL;DR:** 本文提出一种利用概念习得模型从学习资源中生成概念谜语的方法，以提高在线学习环境中的学习者参与度，并取得了令人鼓舞的人工评估结果。

**AI_Comments:** 这篇论文通过将概念习得模型应用于谜语生成，为在线学习环境中的学习者参与度问题提供了一个创新的解决方案。其核心在于将学习资源转化为结构化的事实三元组，并利用分类机制来区分概念的关键属性，从而生成有助于深入理解的谜语。这种方法有望提升学习的趣味性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在线学习环境中保持学习者参与度是一个主要挑战。概念习得模型是一种能促进学习者对概念进行深入理解的教学策略。

**Method:** 该方法包括从学习资源中创建事实三元组，根据其对概念的独特性将其分类为“主题标记”和“通用”，然后根据概念习得模型的格式生成谜语，并捕获所有可能的谜语答案。

**Result:** 对谜语进行的人工评估结果令人鼓舞。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在解决在线学习中学习者参与度低的问题，提出了一种利用概念习得模型从学习资源中自动生成概念谜语的方法。该方法首先从学习资源中提取事实三元组并进行分类，然后依据概念习得模型的格式生成谜语及其所有可能答案。人工评估结果表明，所生成的谜语效果良好，有望提升在线学习的互动性和深度理解。

> **摘要翻译:** 在线学习环境中的主要挑战之一是保持学习者的参与度。在线和离线环境中都提出了几种不同的教学策略来增强学习者的参与度。概念习得模型就是这样一种教学策略，它侧重于学习者对概念获得更深入的理解，而不仅仅是其字典定义。这是通过搜索和列出用于区分各种概念的示例和非示例的属性来完成的。我们的工作尝试应用概念习得模型来构建概念谜语，并将其部署到在线学习环境中。该方法包括从学习资源中创建事实三元组，根据其对概念的独特性将其分类为“主题标记”和“通用”，然后根据概念习得模型的格式生成谜语，并捕获所有可能的谜语答案。对谜语进行的人工评估结果令人鼓舞。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [167] [SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths](https://arxiv.org/abs/2405.19715)
> *SpecDec++：通过自适应候选长度提升推测解码*

*Kaixuan Huang, Xudong Guo, Mengdi Wang* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 推测解码, 自适应候选长度, 大语言模型, 推理加速

**Comment:** Accepted to COLM 2025

> **TL;DR:** 现有推测解码方法对候选长度K的选择不佳，SpecDec++提出一种自适应方法，通过预测拒绝概率来动态调整K，显著提升了推理速度。

**AI_Comments:** 本文的创新点在于将推测解码的候选长度选择问题建模为马尔可夫决策过程，并基于理论分析提出自适应调整K的SpecDec++方法。通过引入预测拒绝概率的机制，有效地优化了推测过程，显著提升了大型语言模型的推理效率，为LLM的实际部署提供了有价值的加速方案。

<details>
  <summary>Details</summary>

**Motivation:** 推测解码的性能依赖于超参数K（候选长度），但现有方法通常使用简单的启发式方法选择K，可能导致次优性能。

**Method:** 将候选长度K的选择建模为马尔可夫决策过程，并理论证明最优策略是阈值策略。基于此，提出SpecDec++，通过在草稿模型中增加一个训练过的接受预测头，动态预测候选token的条件接受概率，当预测的拒绝概率超过阈值时停止当前推测。

**Result:** 在llama-2-chat 7B & 70B模型对上应用SpecDec++。在Alpaca数据集上实现2.04倍加速（比基线推测解码提升7.2%）。在GSM8K和HumanEval数据集上分别实现2.26倍加速（提升9.4%）和2.23倍加速（提升11.1%）。

**Conclusion:** SpecDec++通过自适应调整候选长度K，显著提升了推测解码的推理速度，证明了其在大型语言模型推理优化方面的有效性。

> **ai_Abstract:** 本文提出SpecDec++，一种增强型推测解码方法，旨在解决现有方法在选择推测解码候选长度K时次优的问题。通过将K的选择建模为马尔可夫决策过程，并理论证明最优策略为阈值策略，SpecDec++在草稿模型中加入接受预测头，动态预测token接受概率并据此自适应调整K。实验结果表明，SpecDec++在多个数据集上显著提升了大型语言模型的推理速度，最高达到2.26倍加速。

> **摘要翻译:** 推测解码通过利用一个更小更快的草稿模型来降低目标大型语言模型的推理延迟。其性能取决于超参数K——候选长度，即目标模型每轮需要验证的候选token数量。然而，以前的方法通常使用简单的启发式方法来选择K，这可能导致次优性能。我们研究了候选长度K的选择，并将其表述为一个马尔可夫决策过程。我们理论上表明，这个马尔可夫决策过程的最优策略采取阈值策略的形式，即当出现拒绝的概率超过某个阈值时，当前的推测应该停止并进行验证。受此理论启发，我们提出了SpecDec++，一个增强版的推测解码方法，它能动态地自适应确定候选长度。我们通过一个训练过的接受预测头来增强草稿模型，以预测候选token的条件接受概率。当预测的至少有一个token被拒绝的概率超过阈值时，SpecDec++将停止当前的推测。我们实现了SpecDec++，并将其应用于llama-2-chat 7B和70B模型对。我们的自适应方法在Alpaca数据集上实现了2.04倍的加速（比基线推测解码提升7.2%）。在GSM8K和HumanEval数据集上，我们的方法分别实现了2.26倍的加速（提升9.4%）和2.23倍的加速（提升11.1%）。本文代码可在https://github.com/Kaffaljidhmah2/SpecDec_pp 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [171] [Simple Mechanistic Explanations for Out-Of-Context Reasoning](https://arxiv.org/abs/2507.08218)
> *情境外推理的简单机制解释*

*Atticus Wang, Joshua Engels, Oliver Clive-Griffin* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 情境外推理, 大型语言模型, LoRA, 引导向量, 泛化

**Comment:** ICML 2025 Workshop R2-FM

> **TL;DR:** LoRA微调通过添加一个常数引导向量来解释LLM的情境外推理（OOCR）现象，该向量将模型引导至一个通用概念，从而实现出乎意料的泛化。甚至可以直接训练这些引导向量来实现OOCR。

**AI_Comments:** 该论文为LLM中令人费解的情境外推理现象提供了一个简洁且具有机制性的解释，即常数引导向量的作用。这一发现简化了对复杂泛化能力的理解，并提出了新的模型控制和训练方法（直接训练引导向量），具有重要的创新性。它对于LLM的可解释性和安全部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在从机制上调查情境外推理（OOCR）现象，以理解LLM为何能进行情境外推理，这对于其安全可靠的部署至关重要。

**Method:** 研究人员通过机制性调查，发现LoRA微调在情境外推理任务中起作用的简单解释。他们还尝试从头开始直接训练引导向量，以观察是否也能诱导OOCR。

**Result:** 研究发现，文献中许多OOCR实例可以通过LoRA微调本质上添加一个常数引导向量来简单解释，该向量将模型引导至一个通用概念。这提高了微调任务和许多其他概念相关领域的性能，导致了惊人的泛化。此外，直接从头开始训练引导向量也能诱导OOCR，并且即使对于看似涉及条件行为的任务（如模型后门）也适用，因为无条件添加引导向量就足够了。

**Conclusion:** 这项工作提出了对OOCR任务微调过程中所学内容的解释，有助于回答LLM为何能进行情境外推理这一关键问题，这是一种与LLM安全可靠部署高度相关的先进能力。

> **ai_Abstract:** 本文深入探讨了大型语言模型（LLMs）的情境外推理（OOCR）现象。研究发现，许多OOCR实例可以简单地解释为LoRA微调引入了一个常数引导向量，该向量将模型推向一个通用概念，从而实现了跨任务的泛化。此外，研究表明，即使直接训练这些引导向量也能诱导OOCR，且该机制对于涉及条件行为的任务也有效。这项工作为理解LLMs如何学习并执行情境外推理提供了机制性解释，对LLMs的安全部署具有重要意义。

> **摘要翻译:** 情境外推理（OOCR）是一种现象，其中经过微调的大型语言模型（LLMs）表现出令人惊讶的深层分布外泛化能力。它们并非学习浅层启发式规则，而是隐式地内化并作用于散布在微调数据中的观察结果。在这项工作中，我们从机制上研究了这一现象，发现文献中许多OOCR实例都有一个简单的解释：LoRA微调本质上添加了一个常数引导向量，将模型引导至一个通用概念。这提高了微调任务和许多其他概念相关领域的性能，从而导致了令人惊讶的泛化。此外，我们可以直接从头开始训练这些任务的引导向量，这也能诱导OOCR。我们发现，即使对于看似必须涉及条件行为的任务（模型后门），我们的结果也成立；事实证明，无条件地添加引导向量就足够了。总的来说，我们的工作提出了对OOCR任务微调过程中所学内容的一种解释，有助于回答LLM为何能进行情境外推理这一关键问题，这是一种与其安全可靠部署高度相关的先进能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [179] [GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs](https://arxiv.org/abs/2507.08107)
> *GRASP：跨知识图谱的通用推理和SPARQL生成*

*Sebastian Walter, Hannah Bast* | **Category: cs.CL, cs.DB, cs.IR** | **Updated: 2025-07-10**

**Keywords:** SPARQL生成, 知识图谱, 大型语言模型, 零样本, 自然语言处理

**Comment:** 

> **TL;DR:** GRASP提出了一种无需微调的LLM方法，通过策略性地执行SPARQL查询和搜索相关IRI/字面量，从自然语言生成SPARQL查询，在多个基准测试中取得了SOTA或接近SOTA的性能。

**AI_Comments:** GRASP的创新之处在于其零样本（zero-shot）的SPARQL生成方法，避免了LLM的微调需求，这对于实际应用具有重要意义。通过让LLM主动探索知识图谱，它克服了传统方法对大量标注数据的依赖。其在Wikidata上达到SOTA证明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是开发一种新的方法，使用大型语言模型从自然语言问题或关键词查询中生成RDF知识图谱上的SPARQL查询，且无需微调。

**Method:** GRASP方法利用大型语言模型，通过策略性地执行SPARQL查询和搜索相关的IRI和字面量来探索知识图谱，从而生成SPARQL查询。此方法无需微调。

**Result:** 在Wikidata上，尽管是零样本设置，GRASP在多个基准测试中达到了最先进的结果。在Freebase上，它接近于最佳的少样本方法。在其他不常评估的知识图谱和基准测试中，该方法也表现良好。

**Conclusion:** 该论文得出的结论是，GRASP，一种无需微调的LLM驱动方法，通过探索知识图谱，在从自然语言生成SPARQL查询方面表现出色，特别是在Wikidata上达到了SOTA，证明了其在不同知识图谱和LLM类型上的通用性和有效性。

> **ai_Abstract:** GRASP提出了一种利用大型语言模型从自然语言生成SPARQL查询的新方法，其独特之处在于无需微调。该方法通过让语言模型策略性地执行SPARQL查询和搜索IRI/字面量来探索知识图谱。在Wikidata上，GRASP在零样本设置下取得了最先进的成果，在Freebase上接近最佳少样本方法，并在其他知识图谱上表现良好。该研究还探讨了不同的图搜索方式、反馈机制和少样本示例的影响。

> **摘要翻译:** 我们提出了一种新的方法，使用大型语言模型从自然语言问题或关键词查询中生成RDF知识图谱上的SPARQL查询。我们的方法不需要微调。相反，它使用语言模型通过策略性地执行SPARQL查询并搜索相关的IRI和字面量来探索知识图谱。我们在各种基准测试（针对不同种类和大小的知识图谱）和语言模型（不同规模和类型，包括商业和开源）上评估了我们的方法，并将其与现有方法进行比较。在Wikidata上，尽管是零样本设置，我们在多个基准测试中达到了最先进的结果。在Freebase上，我们接近于最佳的少样本方法。在其他不常评估的知识图谱和基准测试中，我们的方法也总体表现良好。我们进行了几项额外的研究，例如比较不同的图搜索方式、整合反馈机制或利用少样本示例。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [183] [HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew](https://arxiv.org/abs/2406.03897)
> *HeSum：一种用于希伯来语抽象文本摘要的新型数据集*

*Tzuf Paz-Argaman, Itai Mondshine, Asaf Achi Mordechai, Reut Tsarfaty* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 希伯来语, 抽象文本摘要, 数据集, 低资源语言, 大型语言模型

**Comment:** 

> **TL;DR:** 引入了HeSum，一个用于希伯来语抽象文本摘要的新数据集，旨在解决低资源语言中LLM性能不佳的挑战。

**AI_Comments:** 这篇论文通过构建专门针对希伯来语抽象文本摘要的数据集HeSum，填补了低资源语言生成任务评估的空白，具有重要意义。它不仅为希伯来语的NLP研究提供了宝贵资源，也突出了当前SOTA LLMs在处理形态复杂语言时面临的挑战，为未来跨语言生成模型的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在英语自然语言任务中表现出色，但在希伯来语等低资源语言中，特别是在抽象摘要等生成任务上的表现尚不清楚。希伯来语的高度形态丰富性由于句子理解中的歧义和意义构建的复杂性，带来了进一步的挑战，导致资源和评估的空白。

**Method:** 本文引入了HeSum，一个专门为现代希伯来语抽象文本摘要设计的新型基准数据集。HeSum包含10,000个从希伯来语新闻网站获取的由专业人士撰写的文章-摘要对。对数据集进行了语言分析以确认其高抽象性和独特的形态挑战。

**Result:** 语言分析证实了HeSum的高抽象性和独特的形态挑战。研究表明，HeSum对当前的SOTA LLMs构成了明显的困难，从而确立了其作为希伯来语生成语言技术以及一般中低资源语言生成挑战的宝贵测试平台。

**Conclusion:** HeSum作为一个新的基准数据集，揭示了当前最先进的大型语言模型在希伯来语抽象文本摘要任务上的局限性，并为未来在低资源语言生成技术方面的研究提供了重要的测试平台。

> **ai_Abstract:** 本文介绍了HeSum，一个专门为现代希伯来语抽象文本摘要任务设计的新型基准数据集，旨在解决大型语言模型在希伯来语这种形态丰富且资源稀缺语言中进行生成任务（如摘要）时面临的性能不确定性和挑战。HeSum包含10,000对文章-摘要，其语言分析证实了高抽象性和独特的形态复杂性，并揭示了现有最先进LLM在此任务上的局限性，使其成为研究希伯来语及其他低资源语言生成技术的重要测试平台。

> **摘要翻译:** 尽管大型语言模型（LLMs）在各种英语自然语言任务中表现出色，但它们在希伯来语等资源较少语言中的表现，特别是在抽象摘要等生成任务方面的表现仍不明确。希伯来语高度的形态丰富性由于句子理解中的歧义和意义构建的复杂性，带来了进一步的挑战。在本文中，我们通过引入HeSum解决了这一资源和评估空白，HeSum是一个专门为现代希伯来语抽象文本摘要设计的新型基准数据集。HeSum包含10,000个从希伯来语新闻网站获取的由专业人士撰写的文章-摘要对。语言分析证实了HeSum的高抽象性和独特的形态挑战。我们表明，HeSum对当前的SOTA LLMs提出了明显的困难，从而确立了其作为希伯来语生成语言技术以及一般中低资源语言生成挑战的宝贵测试平台。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [187] [Exploring Gender Differences in Chronic Pain Discussions on Reddit](https://arxiv.org/abs/2507.08241)
> *探索Reddit上慢性疼痛讨论中的性别差异*

*Ancita Maria Andrade, Tanvi Banerjee, Ramakrishna Mundugar* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 慢性疼痛, 性别差异, 自然语言处理, Reddit, HAM-CNN

**Comment:** This is an extended version of the short paper accepted at ASONAM
  2025

> **TL;DR:** 本研究利用自然语言处理（NLP）和HAM-CNN模型分析了Reddit上慢性疼痛讨论中的性别差异，发现女性帖子更偏重情感，且某些疾病和药物影响存在性别差异。

**AI_Comments:** 本研究通过结合自然语言处理和深度学习模型（HAM-CNN），创新性地利用Reddit上的用户生成数据来探索慢性疼痛的性别差异，填补了以往研究中对性别作用忽视的空白。其发现对于理解疼痛的社会和心理维度，以及未来个性化疼痛管理策略的制定具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 以往的研究往往忽视了性别在疼痛体验中的作用，因此本研究旨在深入探讨个体疼痛体验中的性别差异。

**Method:** 本研究利用自然语言处理（NLP）分析Reddit上的疼痛讨论数据，并使用隐藏属性模型-卷积神经网络（HAM-CNN）将帖子分类为男性和女性语料库，F1分数为0.86。

**Result:** 研究发现两性之间存在语言差异，女性帖子更倾向于情感化。此外，偏头痛和鼻窦炎等疾病在女性中更为普遍，并且止痛药对不同性别的影响也不同。

**Conclusion:** 本研究揭示了Reddit上慢性疼痛讨论中存在的显著性别差异，特别是在语言表达、特定疾病患病率以及药物影响方面。

> **ai_Abstract:** 本研究利用自然语言处理（NLP）技术，深入分析了Reddit上关于慢性疼痛的讨论，重点关注性别差异。通过使用隐藏属性模型-卷积神经网络（HAM-CNN）对用户帖子进行性别分类，并取得了0.86的F1分数。分析结果表明，女性帖子在情感表达上更为集中，且偏头痛和鼻窦炎等疾病在女性中更为常见。此外，研究还探讨了止痛药对不同性别个体影响的差异。

> **摘要翻译:** 疼痛是人类生存固有的组成部分，表现为身体和情感体验，并可分为急性或慢性。多年来，各科学学科贡献了大量研究，以了解疼痛的原因并探索潜在的治疗方法。然而，早期的研究往往忽视了性别在疼痛体验中的作用。在本研究中，我们利用自然语言处理（NLP）来分析并深入了解个体的疼痛体验，特别关注性别差异。我们成功地使用隐藏属性模型-卷积神经网络（HAM-CNN）将帖子分类为男性和女性语料库，通过聚合基于用户名的帖子，F1分数为0.86。我们的分析揭示了性别之间的语言差异，女性帖子倾向于更注重情感。此外，研究强调偏头痛和鼻窦炎等疾病在女性中更为普遍，并探讨了止痛药如何根据性别对个体产生不同的影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [192] [Weak-to-Strong Jailbreaking on Large Language Models](https://arxiv.org/abs/2401.17256)
> *大语言模型上的弱到强越狱攻击*

*Xuandong Zhao, Xianjun Yang, Tianyu Pang, Chao Du, Lei Li, Yu-Xiang Wang, William Yang Wang* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大语言模型, 越狱攻击, 弱到强攻击, 模型对齐, 安全漏洞

**Comment:** ICML 2025

> **TL;DR:** 本文提出一种高效的“弱到强”越狱攻击，利用两个小模型修改大语言模型的解码概率，使其生成有害文本，在多个模型上成功率超过99%，揭示了LLM对齐的紧迫安全问题。

**AI_Comments:** 这项研究揭示了LLM对齐中的一个重要且紧迫的安全漏洞，即通过高效的推理时间攻击即可绕过安全对齐。其创新点在于利用小模型协同攻击大模型，为理解LLM的脆弱性提供了新颖视角。虽然论文提出了初步防御，但同时也强调了未来防御研究的挑战性，这对于LLM的稳健安全部署具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）容易受到越狱攻击，导致生成有害、不道德或有偏见的文本，而现有越狱方法计算成本高昂。

**Method:** 提出“弱到强”越狱攻击，其核心思想是利用两个较小的模型（一个安全模型和一个不安全模型）对抗性地修改一个显著更大的安全模型的解码概率，以使目标LLM生成有害文本。

**Result:** 在5个来自3个组织的开源LLMs上进行评估，结果显示该方法在两个数据集上，仅需一次前向传播，就能将LLM的未对齐率提高到99%以上。

**Conclusion:** 该研究揭示了LLMs对齐时一个亟待解决的紧急安全问题。作为初步尝试，论文提出了一种防御策略来抵御此类攻击，但创建更高级的防御仍然具有挑战性。

> **ai_Abstract:** 本文提出了一种名为“弱到强”的新型越狱攻击，旨在高效地使大型语言模型（LLMs）生成有害内容。该方法的核心在于利用两个较小的辅助模型（一个安全和一个不安全）来对抗性地调整目标大型安全LLM的解码概率。实验结果表明，该攻击在多个开源LLMs上表现出极高的成功率（超过99%），且计算效率高。研究强调了LLMs对齐面临的严重安全挑战，并初步探索了防御措施。

> **摘要翻译:** 大语言模型（LLMs）容易受到越狱攻击——导致有害、不道德或有偏见的文本生成。然而，现有的越狱方法计算成本高昂。在本文中，我们提出了弱到强越狱攻击，这是一种针对已对齐LLMs生成有害文本的高效推理时间攻击。我们的关键直觉是基于观察，即越狱模型和已对齐模型仅在初始解码分布上有所不同。弱到强攻击的关键技术洞察是使用两个较小的模型（一个安全模型和一个不安全模型）对抗性地修改一个显著更大的安全模型的解码概率。我们在来自3个组织的5个不同开源LLMs上评估了弱到强攻击。结果显示，我们的方法在两个数据集上，每个示例只需一次前向传播，就能将未对齐率提高到99%以上。我们的研究揭示了一个在对齐LLMs时亟待解决的紧急安全问题。作为初步尝试，我们提出了一种防御策略来抵御此类攻击，但创建更高级的防御仍然具有挑战性。复制该方法的代码可在https://github.com/XuandongZhao/weak-to-strong 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [196] [Audit, Alignment, and Optimization of LM-Powered Subroutines with Application to Public Comment Processing](https://arxiv.org/abs/2507.08109)
> *LM驱动子程序的审计、对齐与优化及其在公众意见处理中的应用*

*Reilly Raab, Mike Parker, Dan Nally, Sadie Montgomery, Anastasia Bernat, Sai Munikoti, Sameera Horawalavithana* | **Category: cs.CL** | **Updated: 2025-07-10**

**Keywords:** 语言模型, 审计, 子程序, 公众意见处理, 框架

**Comment:** 

> **TL;DR:** 本文提出了一个用于LM驱动子程序的框架，该框架支持审计、在线优化并能通过稀疏的人工反馈进行改进，并将其应用于公共意见处理。

**AI_Comments:** 该论文的创新之处在于提出了一个可审计且支持在线优化的LM驱动子程序框架，有效解决了LM在实际应用中面临的透明度、安全性和偏见等核心挑战。通过将所有LM产物记录并暴露给审计，极大地增强了系统的可信赖性。此外，利用稀疏的人工反馈进行在线性能改进，为LM在真实世界决策流程中的负责任部署提供了实用路径。将其打包为库也促进了其应用和持续发展。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型（LMs）的出现有潜力显著加速文本处理任务，但其在实际应用中受到安全性、可解释性和偏见等问题的阻碍。因此，需要一种透明、可审计的方式来负责任地利用LMs，以最小化风险并使人类专家能专注于决策制定而非数据处理或提示工程。

**Method:** 本文提出了一种框架，用于声明静态类型、LM驱动的子程序，可在传统异步代码中使用。该框架通过稀疏的人工反馈在线改进每个子程序的性能。所有LM生成的产物（如提示、输入、输出和数据依赖）都被记录并可按需审计。该框架被打包成一个库。作者在1969年《国家环境保护法》（NEPA）规定的公众意见处理背景下评估了该框架，开发了“CommentNEPA”应用程序来编译、组织和总结公共评论。

**Result:** 作者通过将“CommentNEPA”应用程序（在没有人为反馈的情况下运行）的输出与人类标注者在准备官方环境影响声明期间标记的历史“真实”数据进行比较，对该应用程序进行了定量评估。具体的评估结果（如性能指标）未在摘要中提及。

**Conclusion:** 本文提出了一个框架，用于负责任地利用语言模型，通过可审计的子程序和在线改进机制解决实际应用中的安全、可解释性和偏见问题，并通过在公众意见处理中的应用进行了验证。

> **ai_Abstract:** 本文针对语言模型在实际应用中面临的安全性、可解释性和偏见问题，提出了一种新的框架。该框架允许声明静态类型、LM驱动的子程序，并支持在线优化，通过稀疏的人工反馈来提高性能。框架的一个关键特性是所有LM生成的产物均可被记录和按需审计，从而实现透明和可审计的LM应用。作者将该框架打包成一个库，并在公共意见处理领域（基于NEPA）进行了应用评估，开发了“CommentNEPA”应用程序来处理和总结公众评论。该应用程序通过与历史“真实”数据进行比较进行了定量评估。

> **摘要翻译:** 语言模型（LMs）的出现有潜力显著加速那些可以转化为文本处理的任务；然而，实际应用受到安全性、可解释性和偏见等问题的阻碍。我们如何能以透明、可审计的方式负责任地利用LMs——最小化风险并允许人类专家专注于知情决策，而非数据处理或提示工程？在这项工作中，我们提出了一种框架，用于声明静态类型、LM驱动的子程序（即，可调用、函数式的过程），以便在传统的异步代码中使用——这样，来自人类专家的稀疏反馈可以在线（即，在使用过程中）用于提高每个子程序的性能。在我们的实现中，所有LM生成的产物（即，提示、输入、输出和数据依赖）都被记录并可按需审计。我们将此框架打包为一个库，以支持其采用和持续开发。虽然此框架可能适用于多种实际决策工作流程（例如，在医疗保健和法律领域），但我们根据1969年《国家环境保护法》（NEPA）的规定，在公众意见处理的背景下对其进行了评估：具体来说，我们使用此框架开发了“CommentNEPA”，这是一个应用程序，用于编译、组织和总结为响应需要环境审查的项目而提交的公共评论语料库。我们通过将应用程序的输出（在没有人为反馈的情况下运行）与人类标注者在准备官方环境影响声明期间标记的历史“真实”数据进行比较，对该应用程序进行了定量评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [201] [Comparing Spoken Languages using Paninian System of Sounds and Finite State Machines](https://arxiv.org/abs/2301.12463)
> *使用潘尼尼音系和有限状态机比较口语语言*

*Shreekanth M Prabhu, Abhisek Midya* | **Category: cs.CL, cs.FL** | **Updated: 2025-07-11**

**Keywords:** 潘尼尼音系, 有限状态机, 语言比较, 梵语, 生态系统模型

**Comment:** 63 Pages, 20 Figures, 27 Tables

> **TL;DR:** 本文提出了一种以梵语为核心的语言发展生态系统模型，以挑战传统的语族树模型，并利用潘尼尼音系和有限状态机进行语言比较。

**AI_Comments:** 该论文通过提出一个“生态系统模型”作为传统语族树模型的替代方案，并以梵语为核心，具有创新性。其重要性在于挑战了既定的语言学理论并批判了“政策驱动的研究”，为语言演变和关系提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 重新审视关于语系的现有结论（例如，吠陀梵语是印欧语系的一个子语言，达罗毗荼语系属于不同的语系），并挑战语言学领域中“政策驱动的研究”。

**Method:** 利用潘尼尼音系构建语音图，将跨语言的词汇表示为语音图上的状态转换，并构建相应的形态有限自动机（MFA）来接受词群。

**Result:** 提出了一种以梵语为核心的“语言发展生态系统模型”，取代了广泛接受的语族树模型。

**Conclusion:** 本文重新审视了现有的语言学结论和模型，特别是通过提出一个以梵语为核心的新生态系统模型，挑战了语族树模型和该领域的“政策驱动研究”。

> **ai_Abstract:** 本文挑战了传统的语言分类，特别是印欧语系树模型和达罗毗荼语系的独立分类。它提出了一种以梵语为核心的“语言发展生态系统模型”。其方法包括使用潘尼尼音系构建语音图，将词汇表示为状态转换，并构建形态有限自动机（MFA）来比较语言。作者旨在重新审视现有结论并批判该领域中政策驱动的研究。

> **摘要翻译:** 口语语言的研究包括音系学、形态学和语法。语言可以分为词根语言、屈折语言和词干语言。此外，随着使用者在不同区域之间移动，语言会通过吸收等语线（isoglosses）而随时间和空间不断变化。所有这些因素导致词汇的形成，这些词汇在不同语言之间具有共性和相似性，同时也有独特而细微的差异。跨语言词汇的比较和详细分析导致了语系假说的形成。特别是，在西方语言学家的观点中，吠陀梵语是印欧语系印伊语族的一个子语言，而达罗毗荼语系则属于一个完全不同的语系。本文重新审视了这些以及类似的结论。根据我们的研究和分析，我们提出了一个以梵语为核心的语言发展生态系统模型，以取代广为接受的语族树模型。为此，我们利用潘尼尼音系构建了一个语音图。然后，我们将跨语言的词汇表示为语音图上的状态转换，并构建相应的形态有限自动机（MFA）来接受词群。无论本文的贡献是重大还是微小，它都是挑战困扰该领域的政策驱动研究的重要一步。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [212] [Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective](https://arxiv.org/abs/2406.14023)
> *从心理测量学角度攻击评估大型语言模型中的内隐偏见*

*Yuchen Wen, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 内隐偏见, 心理测量学, 偏见评估, 基准数据集

**Comment:** Accepted to ACL 2025 Findings

> **TL;DR:** 本研究从心理测量学角度提出三种攻击方法（伪装、欺骗、教学）和两个基准数据集，有效评估并揭示了大型语言模型（LLMs）的内隐偏见，其效果优于现有基线。

**AI_Comments:** 本文创新性地将心理测量学原理引入LLMs的偏见评估，通过设计独特的攻击方法和构建大规模基准数据集，有效揭示了LLMs中难以察觉的内隐偏见。这对于提升LLMs的伦理性和安全性具有重要意义，其方法和数据集也为后续研究提供了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）成为重要的信息获取方式，人们越来越关注LLMs可能加剧非道德内容的传播，包括在没有明确有害词语的情况下伤害特定人群的内隐偏见。

**Method:** 研究从心理测量学角度，通过提出三种攻击方法（伪装、欺骗和教学），诱导LLMs同意有偏见的观点来评估其内隐偏见。构建了两个基准数据集：一个包含四种偏见类型的双语数据集（2.7K实例），以及一个更大的BUMBLE基准数据集，涵盖九种常见偏见类型（12.7K实例）。

**Result:** 对流行的商业和开源LLMs的广泛评估表明，所提出的方法比竞争基线能更有效地揭示LLMs的内在偏见。

**Conclusion:** 本研究的攻击方法和基准数据集为评估LLMs的伦理风险提供了一种有效手段，推动了其开发中更高问责制的进步。

> **ai_Abstract:** 本研究旨在通过新颖的心理测量学攻击方法来评估大型语言模型（LLMs）的内隐偏见。研究提出了伪装、欺骗和教学三种攻击策略，并构建了包含不同偏见类型的双语数据集和BUMBLE基准数据集。实验结果表明，这些方法比现有基线能更有效地揭示LLMs的内在偏见，为评估LLMs的伦理风险提供了有效工具，有助于促进LLMs开发的问责制。

> **摘要翻译:** 随着大型语言模型（LLMs）成为重要的信息获取方式，人们越来越关注LLMs可能加剧非道德内容的传播，包括在没有明确有害词语的情况下伤害特定人群的内隐偏见。在本文中，我们从心理测量学角度对LLMs进行攻击，以引发其对有偏见观点的认同，从而严格评估LLMs对某些人群的内隐偏见。受认知和社会心理学中心理测量学原理的启发，我们提出了三种攻击方法，即伪装（Disguise）、欺骗（Deception）和教学（Teaching）。结合相应的攻击指令，我们构建了两个基准数据集：（1）一个包含四种偏见类型的双语数据集（2.7K实例），用于广泛的比较分析；（2）BUMBLE，一个更大的基准数据集，涵盖九种常见偏见类型（12.7K实例），用于全面评估。对流行的商业和开源LLMs的广泛评估表明，我们的方法比竞争基线能更有效地揭示LLMs的内在偏见。我们的攻击方法和基准数据集为评估LLMs的伦理风险提供了一种有效手段，推动了其开发中更高问责制的进步。我们的代码、数据和基准数据集可在https://yuchenwen1.github.io/ImplicitBiasEvaluation/获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [221] [Distilling Empathy from Large Language Models](https://arxiv.org/abs/2507.08151)
> *从大型语言模型中提炼同理心*

*Henry J. Xie, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu* | **Category: cs.CL** | **Updated: 2025-07-10**

**Keywords:** 同理心, 语言模型, 知识蒸馏, 微调, 小型语言模型

**Comment:** Accepted by SIGDIAL 2025

> **TL;DR:** 本文提出了一种从大型语言模型（LLMs）中向小型语言模型（SLMs）有效提炼同理心的方法，通过两步微调和特异性提示，显著提高了SLMs生成同理心回应的能力。

**AI_Comments:** 本文的创新点在于专注于将LLMs的同理心能力蒸馏到SLMs，这对于资源受限设备上的友好人机交互具有重要意义。提出的两步微调过程和针对性同理心提示是关键方法，有效提升了SLMs的同理心表现。这项工作为在边缘设备上部署更具情商的AI模型提供了可行途径。

<details>
  <summary>Details</summary>

**Motivation:** 由于小型语言模型（SLMs）尺寸小，常用于资源受限但人机交互频繁的领域（如智能手机）。因此，确保SLMs在知识蒸馏后能保留大型语言模型（LLMs）已具备的同理心能力至关重要，因为同理心是积极人机互动的基础。

**Method:** 本文提出了一种全面的同理心蒸馏方法。该方法包含一个两步微调过程，充分利用从LLMs蒸馏出的同理心对话响应数据集。研究探索了除基本直接提示之外的多种蒸馏方法，并提出了四组独特的针对性同理心提升提示，以显著增强同理心蒸馏过程。

**Result:** 通过两步微调过程并结合经针对性同理心提升提示增强的蒸馏数据集，SLMs在生成同理心回应方面显著优于基础SLM，胜率达到90%。此外，所提出的针对性同理心提升提示比基本的直接提示表现更优，胜率提高了10%。

**Conclusion:** 本文提出的两步微调方法结合针对性同理心提升提示，能够有效地将LLMs的同理心能力蒸馏到SLMs中，显著提高了SLMs生成同理心回应的性能，使其更适用于资源受限的人机交互场景。

> **ai_Abstract:** 该论文提出了一种从大型语言模型（LLMs）向小型语言模型（SLMs）蒸馏同理心的综合方法。鉴于SLMs常用于资源受限但人机交互频繁的环境，保留同理心至关重要。研究采用两步微调过程，利用从LLMs蒸馏出的同理心对话数据集，并设计了四组独特的针对性同理心提升提示。实验结果表明，经过此方法微调的SLMs在生成同理心回应方面显著优于基础SLM，胜率达90%，且针对性提示比基本提示的胜率提高了10%。

> **摘要翻译:** 大型语言模型（LLMs）的知识蒸馏到小型语言模型（SLMs）中，在保留LLMs能力和性能的同时减小模型尺寸，在LLMs的普及中发挥了关键作用。由于SLMs比LLMs小得多，它们常被用于人机交互频繁但资源高度受限的领域，例如智能手机。因此，确保LLMs中已经具备的同理心——积极人机互动的一个基本方面——在蒸馏后能被SLMs保留至关重要。在本文中，我们开发了一种从LLMs向SLMs有效提炼同理心的综合方法。我们的方法采用两步微调过程，充分利用从LLMs蒸馏出的同理心对话响应数据集。我们探索了几种超越基本直接提示的蒸馏方法，并提出了四组独特的针对性同理心提升提示，以显著增强同理心蒸馏过程。我们的评估表明，通过两步微调过程并结合经针对性同理心提升提示增强的蒸馏数据集进行微调的SLMs，在生成同理心回应方面显著优于基础SLM，胜率达到90%。我们的针对性同理心提升提示比基本的直接提示表现更好，胜率提高了10%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [224] [Swap distance minimization beyond entropy minimization in word order variation](https://arxiv.org/abs/2404.14192)
> *词序变异中超越熵最小化的交换距离最小化*

*Víctor Franco-Sánchez, Arnau Martí-Llobet, Ramon Ferrer-i-Cancho* | **Category: cs.CL, physics.soc-ph** | **Updated: 2025-07-11**

**Keywords:** 词序变异, 熵最小化, 交换距离最小化, 平均交换距离, 语言结构

**Comment:** Reorganization with technical appendices; minor corrections; in press
  in the Journal of Quantitative Linguistics

> **TL;DR:** 研究词序变异中，除了熵最小化外，交换距离最小化也是一个重要约束因素，并提出了平均交换距离这一新指标。

**AI_Comments:** 这篇论文探讨了词序变异的潜在原则，提出了一个新的衡量指标“平均交换距离”，并证明了交换距离最小化在词序形成中的独立作用，这为理解语言结构提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 研究词序频率是否受熵最小化和交换距离最小化这两个原则的约束。

**Method:** 提出了平均交换距离这一新分数；通过与掷骰子实验和波利亚瓮模型进行比较，研究了熵最小化和交换距离最小化在 n=3 和 n=4 语言结构中的作用。

**Result:** 发现相对于掷骰子实验，熵最小化和交换距离最小化在 n=3 和 n=4 结构中均有强烈证据。相对于波利亚瓮模型，n=4 证据强，n=3 证据弱。发现交换距离最小化效应独立于降低词序熵的压力。

**Conclusion:** 词序变异不仅受熵最小化约束，还受交换距离最小化约束，且后者的效应超越了前者的压力。

> **ai_Abstract:** 本文研究了词序变异中 n! 种可能顺序的频率是否受熵最小化和交换距离最小化两个原则的约束。研究提出了平均交换距离作为新的衡量指标。通过与掷骰子实验和波利亚瓮模型的比较，发现在 n=3 和 n=4 的语言结构中，熵最小化和交换距离最小化均有证据支持，且交换距离最小化的效应独立于熵最小化。

> **摘要翻译:** 考虑一个由 n 个元素构成的语言结构，例如主语、直接宾语和谓语 (n=3) 或主语、直接宾语、间接宾语和谓语 (n=4)。我们研究 n! 种可能顺序的频率是否受两个原则的约束。首先，熵最小化，这是一个已被建议用于塑造不同组织层面的自然通信系统的原则。其次，交换距离最小化，即偏好从源顺序产生时需要较少相邻元素交换的词序。我们提出了平均交换距离，这是一个用于研究交换距离最小化的新分数。我们发现，在 n=3 或 n=4 的不同语言结构中，相对于掷骰子实验，存在熵最小化和交换距离最小化的强烈证据。相对于波利亚瓮模型，n=4 的证据很强，但 n=3 的证据较弱。当词序频率被打乱时，我们仍然发现与交换距离最小化作用一致的证据，这表明交换距离最小化效应超越了降低词序熵的压力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [225] [Sampling from Your Language Model One Byte at a Time](https://arxiv.org/abs/2506.14123)
> *从语言模型中逐字节采样*

*Jonathan Hayase, Alisa Liu, Noah A. Smith, Sewoong Oh* | **Category: cs.CL, cs.FL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 语言模型, 分词, 字节级, Prompt Boundary Problem, 模型集成

**Comment:** 23 pages, 8 figures

> **TL;DR:** 提出了一种推理时方法，将基于BPE分词器的自回归语言模型转换为字符级或字节级语言模型，有效解决了Prompt Boundary Problem (PBP)，并能统一不同分词器模型的词汇表，从而实现模型集成或代理微调，实验证明性能优于单个模型。

**AI_Comments:** 该论文的核心创新在于提出了一种通用的、推理时可用的方法，将基于BPE的语言模型转换为字节级或字符级，从而巧妙地解决了长期存在的Prompt Boundary Problem，这是一个对多语言和代码生成尤为重要的实际问题。此外，该方法还能实现不同分词器模型之间的词汇表统一和模型集成/知识迁移，这对于提升模型泛化能力和利用现有预训练模型具有重要意义。其提出的解决方案具有很强的普适性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代语言模型普遍使用的分词技术（如BPE）会引入“Prompt Boundary Problem (PBP)”的扭曲，导致模型生成不准确，尤其在中文和代码生成等场景中，分词与词语或语法边界不匹配的问题更为突出。

**Method:** 提出了一种推理时方法，能够将任何带有BPE分词器的自回归语言模型转换为字符级或字节级语言模型。该方法能高效解决PBP，并统一不同分词器的语言模型的词汇表，从而在推理时集成不同分词器的语言模型，或通过代理微调将后训练从一个模型转移到另一个模型。

**Result:** 实验表明，通过集成或代理微调的模型在下游评估中表现优于其组成模型。

**Conclusion:** 本研究提出的逐字节采样方法有效解决了语言模型中的Prompt Boundary Problem，并为不同分词器模型的集成和知识迁移提供了新途径，显著提升了模型性能。

> **ai_Abstract:** 该论文提出了一种创新的推理时方法，旨在解决现代语言模型中由分词引起的“Prompt Boundary Problem”（PBP）。通过将任何基于BPE分词器的自回归语言模型转换为字符级或字节级模型，该方法不仅高效地消除了PBP，还实现了不同分词器模型词汇表的统一。这使得在推理时能够集成不同分词器的语言模型，或通过代理微调进行模型知识迁移。实验结果表明，通过这种方法集成或代理微调的模型在各项评估中均超越了单一模型，为提升语言模型性能提供了新的范式。

> **摘要翻译:** 现代语言模型几乎普遍使用分词技术，通过多字节或多字符分词实现高效的文本表示。然而，先前的研究表明，分词会给模型的生成引入扭曲，这个问题被称为Prompt Boundary Problem (PBP)。例如，用户通常被建议不要在提示符末尾加空格，因为这会阻止模型将空格作为下一个分词的一部分。虽然这种启发式方法在英语中有效，但PBP在中文以及代码生成等语言中仍然存在，因为在这些情况下，分词通常与单词和句法边界不一致。在这项工作中，我们提出了一种推理时方法，可以将任何带有BPE分词器的自回归语言模型转换为字符级或字节级语言模型。我们的方法高效地解决了PBP，并且能够统一具有不同分词器的语言模型的词汇表，从而允许在推理时集成具有不同分词器的语言模型，或使用代理微调将后训练从一个模型转移到另一个模型。我们在实验中证明，集成和代理微调的模型在下游评估中优于其组成模型。代码可在https://github.com/SewoongLab/byte-sampler 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [231] [An Empirical Study of Validating Synthetic Data for Formula Generation](https://arxiv.org/abs/2407.10657)
> *用于公式生成的合成数据验证的实证研究*

*Usneek Singh, José Cambronero, Sumit Gulwani, Aditya Kanade, Anirudh Khatry, Vu Le, Mukul Singh, Gust Verbruggen* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 合成数据, 公式生成, 大型语言模型, 数据验证, 微调

**Comment:** Accepted at Findings of NAACL

> **TL;DR:** 本研究发现，通过代理目标验证大型语言模型生成的合成自然语言训练数据，能够显著提升模型在公式生成任务上的微调性能，并使模型能够解决更复杂的问题，即使此过程会筛选掉一些挑战性样本。

**AI_Comments:** 这项研究的创新之处在于提出了一种针对合成数据进行验证的方法，以解决特定领域（如公式生成）数据稀缺的问题。其重要性在于，它证明了数据质量（经过验证的合成数据）可以超越数量或原始合成数据，从而带来更好的微调效果和更强的解决问题能力。这为在数据受限的领域利用大型语言模型提供了一个实用的途径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在电子表格公式生成方面面临资源稀缺问题，这限制了预训练模型的性能和微调能力。虽然可以生成合成的自然语言语句用于微调，但必须验证这些合成数据的准确性，以确保其对微调的益处。

**Method:** 本研究通过代理目标（用于评估合成标注的准确性）对合成训练示例进行验证，并提供了其影响的实证结果。实验在四种模型（两种开放权重和两种封闭权重）上进行了验证。

**Result:** 验证显著提高了模型在四种模型上的性能，优于使用原始数据。有趣的是，尽管验证倾向于修剪更具挑战性的示例，但它增加了模型在经过验证数据微调后可以解决问题的复杂性。

**Conclusion:** 通过代理目标对大型语言模型生成的合成自然语言数据进行验证，能够有效提升模型在公式生成任务上的微调性能，并使其能够处理更复杂的问题。

> **ai_Abstract:** 本研究探讨了验证大型语言模型（LLM）生成的合成自然语言数据对电子表格公式生成任务微调效果的影响。由于公式资源稀缺，合成数据成为补充手段，但其准确性至关重要。研究人员通过代理目标对合成训练示例进行验证，并在四种不同模型上进行了实证测试。结果表明，验证显著提升了模型性能，并且尽管验证过程会剔除部分挑战性样本，但经过验证数据微调后的模型反而能解决更复杂的问题。

> **摘要翻译:** 大型语言模型（LLM）可以帮助在电子表格中编写公式，但关于这些公式的资源稀缺，这影响了预训练模型的基础性能并限制了对其进行微调的能力。给定一个公式语料库，我们可以使用（另一个）模型生成合成的自然语言语句进行微调。然而，重要的是要验证LLM生成的自然语言是否确实准确，以便对微调有益。在本文中，我们提供了通过代理目标验证这些合成训练示例的影响的实证结果，这些代理目标评估了合成标注的准确性。我们证明，验证比原始数据在四种模型（2种开放权重和2种封闭权重）上提高了性能。有趣的是，我们表明，尽管验证倾向于修剪更具挑战性的示例，但它增加了模型在经过验证数据微调后可以解决的问题的复杂性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [237] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
> *Gemini 2.5：以先进推理、多模态、长上下文和下一代智能体能力推动前沿*

*Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, Krishna Haridasan, Ahmed Omran, Nikunj Saunshi, Dara Bahri, Gaurav Mishra, Eric Chu, Toby Boyd, Brad Hekman, Aaron Parisi, Chaoyi Zhang, Kornraphop Kawintiranon, Tania Bedrax-Weiss, Oliver Wang, Ya Xu, Ollie Purkiss, Uri Mendlovic, Ilaï Deutel, Nam Nguyen, Adam Langley, Flip Korn, Lucia Rossazza, Alexandre Ramé, Sagar Waghmare, Helen Miller, Vaishakh Keshava, Ying Jian, Xiaofan Zhang, Raluca Ada Popa, Kedar Dhamdhere, Blaž Bratanič, Kyuyeun Kim, Terry Koo, Ferran Alet, Yi-ting Chen, Arsha Nagrani, Hannah Muckenhirn, Zhiyuan Zhang, Corbin Quick, Filip Pavetić, Duc Dung Nguyen, Joao Carreira, Michael Elabd, Haroon Qureshi, Fabian Mentzer, Yao-Yuan Yang, Danielle Eisenbud, Anmol Gulati, Ellie Talius, Eric Ni, Sahra Ghalebikesabi, Edouard Yvinec, Alaa Saade, Thatcher Ulrich, Lorenzo Blanco, Dan A. Calian, Muhuan Huang, Aäron van den Oord, Naman Goyal, Terry Chen, Praynaa Rawlani, Christian Schallhart, Swachhand Lokhande, Xianghong Luo, Jyn Shan, Ceslee Montgomery, Victoria Krakovna, Federico Piccinini, Omer Barak, Jingyu Cui, Yiling Jia, Mikhail Dektiarev, Alexey Kolganov, Shiyu Huang, Zhe Chen, Xingyu Wang, Jessica Austin, Peter de Boursac, Evgeny Sluzhaev, Frank Ding, Huijian Li, Surya Bhupatiraju, Mohit Agarwal, Sławek Kwasiborski, Paramjit Sandhu, Patrick Siegler, Ahmet Iscen, Eyal Ben-David, Shiraz Butt, Miltos Allamanis, Seth Benjamin, Robert Busa-Fekete, Felix Hernandez-Campos, Sasha Goldshtein, Matt Dibb, Weiyang Zhang, Annie Marsden, Carey Radebaugh, Stephen Roller, Abhishek Nayyar, Jacob Austin, Tayfun Terzi, Bhargav Kanagal Shamanna, Pete Shaw, Aayush Singh, Florian Luisier, Artur Mendonça, Vaibhav Aggarwal, Larisa Markeeva, Claudio Fantacci, Sergey Brin, HyunJeong Choe, Guanyu Wang, Hartwig Adam, Avigail Dabush, Tatsuya Kiyono, Eyal Marcus, Jeremy Cole, Theophane Weber, Hongrae Lee, Ronny Huang, Alex Muzio, Leandro Kieliger, Maigo Le, Courtney Biles, Long Le, Archit Sharma, Chengrun Yang, Avery Lamp, Dave Dopson, Nate Hurley, Katrina Xinyi Xu, Zhihao Shan, Shuang Song, Jiewen Tan, Alexandre Senges, George Zhang, Chong You, Yennie Jun, David Raposo, Susanna Ricco, Xuan Yang, Weijie Chen, Prakhar Gupta, Arthur Szlam, Kevin Villela, Chun-Sung Ferng, Daniel Kasenberg, Chen Liang, Rui Zhu, Arunachalam Narayanaswamy, Florence Perot, Paul Pucciarelli, Anna Shekhawat, Alexey Stern, Rishikesh Ingale, Stefani Karp, Sanaz Bahargam, Adrian Goedeckemeyer, Jie Han, Sicheng Li, Andrea Tacchetti, Dian Yu, Abhishek Chakladar, Zhiying Zhang, Mona El Mahdy, Xu Gao, Dale Johnson, Samrat Phatale, AJ Piergiovanni, Hyeontaek Lim, Clement Farabet, Carl Lebsack, Theo Guidroz, John Blitzer, Nico Duduta, David Madras, Steve Li, Daniel von Dincklage, Xin Li, Mahdis Mahdieh, George Tucker, Ganesh Jawahar, Owen Xiao, Danny Tarlow, Robert Geirhos, Noam Velan, Daniel Vlasic, Kalesha Bullard, SK Park, Nishesh Gupta, Kellie Webster, Ayal Hitron, Jieming Mao, Julian Eisenschlos, Laurel Prince, Nina D'Souza, Kelvin Zheng, Sara Nasso, Gabriela Botea, Carl Doersch, Caglar Unlu, Chris Alberti, Alexey Svyatkovskiy, Ankita Goel, Krzysztof Choromanski, Pan-Pan Jiang, Richard Nguyen, Four Flynn, Daria Ćurko, Peter Chen, Nicholas Roth, Kieran Milan, Caleb Habtegebriel, Shashi Narayan, Michael Moffitt, Jake Marcus, Thomas Anthony, Brendan McMahan, Gowoon Cheon, Ruibo Liu, Megan Barnes, Lukasz Lew, Rebeca Santamaria-Fernandez, Mayank Upadhyay, Arjun Akula, Arnar Mar Hrafnkelsson, Alvaro Caceres, Andrew Bunner, Michal Sokolik, Subha Puttagunta, Lawrence Moore, Berivan Isik, Jay Hartford, Lawrence Chan, Pradeep Shenoy, Dan Holtmann-Rice, Jane Park, Fabio Viola, Alex Salcianu, Sujeevan Rajayogam, Ian Stewart-Binks, Zelin Wu, Richard Everett, Xi Xiong, Pierre-Antoine Manzagol, Gary Leung, Carl Saroufim, Bo Pang, Dawid Wegner, George Papamakarios, Jennimaria Palomaki, Helena Pankov, Guangda Lai, Guilherme Tubone, Shubin Zhao, Theofilos Strinopoulos, Seth Neel, Mingqiu Wang, Joe Kelley, Li Li, Pingmei Xu, Anitha Vijayakumar, Andrea D'olimpio, Omer Levy, Massimo Nicosia, Grigory Rozhdestvenskiy, Ni Lao, Sirui Xie, Yash Katariya, Jon Simon, Sanjiv Kumar, Florian Hartmann, Michael Kilgore, Jinhyuk Lee, Aroma Mahendru, Roman Ring, Tom Hennigan, Fiona Lang, Colin Cherry, David Steiner, Dawsen Hwang, Ray Smith, Pidong Wang, Jeremy Chen, Ming-Hsuan Yang, Sam Kwei, Philippe Schlattner, Donnie Kim, Ganesh Poomal Girirajan, Nikola Momchev, Ayushi Agarwal, Xingyi Zhou, Ilkin Safarli, Zachary Garrett, AJ Pierigiovanni, Sarthak Jauhari, Alif Raditya Rochman, Shikhar Vashishth, Quan Yuan, Christof Angermueller, Jon Blanton, Xinying Song, Nitesh Bharadwaj Gundavarapu, Thi Avrahami, Maxine Deines, Subhrajit Roy, Manish Gupta, Christopher Semturs, Shobha Vasudevan, Aditya Srikanth Veerubhotla, Shriya Sharma, Josh Jacob, Zhen Yang, Andreas Terzis, Dan Karliner, Auriel Wright, Tania Rojas-Esponda, Ashley Brown, Abhijit Guha Roy, Pawan Dogra, Andrei Kapishnikov, Peter Young, Wendy Kan, Vinodh Kumar Rajendran, Maria Ivanova, Salil Deshmukh, Chia-Hua Ho, Mike Kwong, Stav Ginzburg, Annie Louis, KP Sawhney, Slav Petrov, Jing Xie, Yunfei Bai, Georgi Stoyanov, Alex Fabrikant, Rajesh Jayaram, Yuqi Li, Joe Heyward, Justin Gilmer, Yaqing Wang, Radu Soricut, Luyang Liu, Qingnan Duan, Jamie Hayes, Maura O'Brien, Gaurav Singh Tomar, Sivan Eiger, Bahar Fatemi, Jeffrey Hui, Catarina Barros, Adaeze Chukwuka, Alena Butryna, Saksham Thakur, Austin Huang, Zhufeng Pan, Haotian Tang, Serkan Cabi, Tulsee Doshi, Michiel Bakker, Sumit Bagri, Ruy Ley-Wild, Adam Lelkes, Jennie Lees, Patrick Kane, David Greene, Shimu Wu, Jörg Bornschein, Gabriela Surita, Sarah Hodkinson, Fangtao Li, Chris Hidey, Sébastien Pereira, Sean Ammirati, Phillip Lippe, Adam Kraft, Pu Han, Sebastian Gerlach, Zifeng Wang, Liviu Panait, Feng Han, Brian Farris, Yingying Bi, Hannah DeBalsi, Miaosen Wang, Gladys Tyen, James Cohan, Susan Zhang, Jarred Barber, Da-Woon Chung, Jaeyoun Kim, Markus Kunesch, Steven Pecht, Nami Akazawa, Abe Friesen, James Lyon, Ali Eslami, Junru Wu, Jie Tan, Yue Song, Ravi Kumar, Chris Welty, Ilia Akolzin, Gena Gibson, Sean Augenstein, Arjun Pillai, Nancy Yuen, Du Phan, Xin Wang, Iain Barr, Heiga Zen, Nan Hua, Casper Liu, Jilei Jerry Wang, Tanuj Bhatia, Hao Xu, Oded Elyada, Pushmeet Kohli, Mirek Olšák, Ke Chen, Azalia Mirhoseini, Noam Shazeer, Shoshana Jakobovits, Maggie Tran, Nolan Ramsden, Tarun Bharti, Fred Alcober, Yunjie Li, Shilpa Shetty, Jing Chen, Dmitry Kalashnikov, Megha Nawhal, Sercan Arik, Hanwen Chen, Michiel Blokzijl, Shubham Gupta, James Rubin, Rigel Swavely, Sophie Bridgers, Ian Gemp, Chen Su, Arun Suggala, Juliette Pluto, Mary Cassin, Alain Vaucher, Kaiyang Ji, Jiahao Cai, Andrew Audibert, Animesh Sinha, David Tian, Efrat Farkash, Amy Hua, Jilin Chen, Duc-Hieu Tran, Edward Loper, Nicole Brichtova, Lara McConnaughey, Ballie Sandhu, Robert Leland, Doug DeCarlo, Andrew Over, James Huang, Xing Wu, Connie Fan, Eric Li, Yun Lei, Deepak Sharma, Cosmin Paduraru, Luo Yu, Matko Bošnjak, Phuong Dao, Min Choi, Sneha Kudugunta, Jakub Adamek, Carlos Guía, Ali Khodaei, Jie Feng, Wenjun Zeng, David Welling, Sandeep Tata, Christina Butterfield, Andrey Vlasov, Seliem El-Sayed, Swaroop Mishra, Tara Sainath, Shentao Yang, RJ Skerry-Ryan, Jeremy Shar, Robert Berry, Arunkumar Rajendran, Arun Kandoor, Andrea Burns, Deepali Jain, Tom Stone, Wonpyo Park, Shibo Wang, Albin Cassirer, Guohui Wang, Hayato Kobayashi, Sergey Rogulenko, Vineetha Govindaraj, Mikołaj Rybiński, Nadav Olmert, Colin Evans, Po-Sen Huang, Kelvin Xu, Premal Shah, Terry Thurk, Caitlin Sikora, Mu Cai, Jin Xie, Elahe Dabir, Saloni Shah, Norbert Kalb, Carrie Zhang, Shruthi Prabhakara, Amit Sabne, Artiom Myaskovsky, Vikas Raunak, Blanca Huergo, Behnam Neyshabur, Jon Clark, Ye Zhang, Shankar Krishnan, Eden Cohen, Dinesh Tewari, James Lottes, Yumeya Yamamori, Hui Elena Li, Mohamed Elhawaty, Ada Maksutaj Oflazer, Adrià Recasens, Sheryl Luo, Duy Nguyen, Taylor Bos, Kalyan Andra, Ana Salazar, Ed Chi, Jeongwoo Ko, Matt Ginsberg, Anders Andreassen, Anian Ruoss, Todor Davchev, Elnaz Davoodi, Chenxi Liu, Min Kim, Santiago Ontanon, Chi Ming To, Dawei Jia, Rosemary Ke, Jing Wang, Anna Korsun, Moran Ambar, Ilya Kornakov, Irene Giannoumis, Toni Creswell, Denny Zhou, Yi Su, Ishaan Watts, Aleksandr Zaks, Evgenii Eltyshev, Ziqiang Feng, Sidharth Mudgal, Alex Kaskasoli, Juliette Love, Kingshuk Dasgupta, Sam Shleifer, Richard Green, Sungyong Seo, Chansoo Lee, Dale Webster, Prakash Shroff, Ganna Raboshchuk, Isabel Leal, James Manyika, Sofia Erell, Daniel Murphy, Zhisheng Xiao, Anton Bulyenov, Julian Walker, Mark Collier, Matej Kastelic, Nelson George, Sushant Prakash, Sailesh Sidhwani, Alexey Frolov, Steven Hansen, Petko Georgiev, Tiberiu Sosea, Chris Apps, Aishwarya Kamath, David Reid, Emma Cooney, Charlotte Magister, Oriana Riva, Alec Go, Pu-Chin Chen, Sebastian Krause, Nir Levine, Marco Fornoni, Ilya Figotin, Nick Roy, Parsa Mahmoudieh, Vladimir Magay, Mukundan Madhavan, Jin Miao, Jianmo Ni, Yasuhisa Fujii, Ian Chou, George Scrivener, Zak Tsai, Siobhan Mcloughlin, Jeremy Selier, Sandra Lefdal, Jeffrey Zhao, Abhijit Karmarkar, Kushal Chauhan, Shivanker Goel, Zhaoyi Zhang, Vihan Jain, Parisa Haghani, Mostafa Dehghani, Jacob Scott, Erin Farnese, Anastasija Ilić, Steven Baker, Julia Pawar, Li Zhong, Josh Camp, Yoel Zeldes, Shravya Shetty, Anand Iyer, Vít Listík, Jiaxian Guo, Luming Tang, Mark Geller, Simon Bucher, Yifan Ding, Hongzhi Shi, Carrie Muir, Dominik Grewe, Ramy Eskander, Octavio Ponce, Boqing Gong, Derek Gasaway, Samira Khan, Umang Gupta, Angelos Filos, Weicheng Kuo, Klemen Kloboves, Jennifer Beattie, Christian Wright, Leon Li, Alicia Jin, Sandeep Mariserla, Miteyan Patel, Jens Heitkaemper, Dilip Krishnan, Vivek Sharma, David Bieber, Christian Frank, John Lambert, Paul Caron, Martin Polacek, Mai Giménez, Himadri Choudhury, Xing Yu, Sasan Tavakkol, Arun Ahuja, Franz Och, Rodolphe Jenatton, Wojtek Skut, Bryan Richter, David Gaddy, Andy Ly, Misha Bilenko, Megh Umekar, Ethan Liang, Martin Sevenich, Mandar Joshi, Hassan Mansoor, Rebecca Lin, Sumit Sanghai, Abhimanyu Singh, Xiaowei Li, Sudheendra Vijayanarasimhan, Zaheer Abbas, Yonatan Bitton, Hansa Srinivasan, Manish Reddy Vuyyuru, Alexander Frömmgen, Yanhua Sun, Ralph Leith, Alfonso Castaño, DJ Strouse, Le Yan, Austin Kyker, Satish Kambala, Mary Jasarevic, Thibault Sellam, Chao Jia, Alexander Pritzel, Raghavender R, Huizhong Chen, Natalie Clay, Sudeep Gandhe, Sean Kirmani, Sayna Ebrahimi, Hannah Kirkwood, Jonathan Mallinson, Chao Wang, Adnan Ozturel, Kuo Lin, Shyam Upadhyay, Vincent Cohen-Addad, Sean Purser-haskell, Yichong Xu, Ebrahim Songhori, Babi Seal, Alberto Magni, Almog Gueta, Tingting Zou, Guru Guruganesh, Thais Kagohara, Hung Nguyen, Khalid Salama, Alejandro Cruzado Ruiz, Justin Frye, Zhenkai Zhu, Matthias Lochbrunner, Simon Osindero, Wentao Yuan, Lisa Lee, Aman Prasad, Lam Nguyen Thiet, Daniele Calandriello, Victor Stone, Qixuan Feng, Han Ke, Maria Voitovich, Geta Sampemane, Lewis Chiang, Ling Wu, Alexander Bykovsky, Matt Young, Luke Vilnis, Ishita Dasgupta, Aditya Chawla, Qin Cao, Bowen Liang, Daniel Toyama, Szabolcs Payrits, Anca Stefanoiu, Dimitrios Vytiniotis, Ankesh Anand, Tianxiao Shen, Blagoj Mitrevski, Michael Tschannen, Sreenivas Gollapudi, Aishwarya P S, José Leal, Zhe Shen, Han Fu, Wei Wang, Arvind Kannan, Doron Kukliansky, Sergey Yaroshenko, Svetlana Grant, Umesh Telang, David Wood, Alexandra Chronopoulou, Alexandru Ţifrea, Tao Zhou, Tony Tu\'ân Nguy\~ên, Muge Ersoy, Anima Singh, Meiyan Xie, Emanuel Taropa, Woohyun Han, Eirikur Agustsson, Andrei Sozanschi, Hui Peng, Alex Chen, Yoel Drori, Efren Robles, Yang Gao, Xerxes Dotiwalla, Ying Chen, Anudhyan Boral, Alexei Bendebury, John Nham, Chris Tar, Luis Castro, Jiepu Jiang, Canoee Liu, Felix Halim, Jinoo Baek, Andy Wan, Jeremiah Liu, Yuan Cao, Shengyang Dai, Trilok Acharya, Ruoxi Sun, Fuzhao Xue, Saket Joshi, Morgane Lustman, Yongqin Xian, Rishabh Joshi, Deep Karkhanis, Nora Kassner, Jamie Hall, Xiangzhuo Ding, Gan Song, Gang Li, Chen Zhu, Yana Kulizhskaya, Bin Ni, Alexey Vlaskin, Solomon Demmessie, Lucio Dery, Salah Zaiem, Yanping Huang, Cindy Fan, Felix Gimeno, Ananth Balashankar, Koji Kojima, Hagai Taitelbaum, Maya Meng, Dero Gharibian, Sahil Singla, Wei Chen, Ambrose Slone, Guanjie Chen, Sujee Rajayogam, Max Schumacher, Suyog Kotecha, Rory Blevins, Qifei Wang, Mor Hazan Taege, Alex Morris, Xin Liu, Fayaz Jamil, Richard Zhang, Pratik Joshi, Ben Ingram, Tyler Liechty, Ahmed Eleryan, Scott Baird, Alex Grills, Gagan Bansal, Shan Han, Kiran Yalasangi, Shawn Xu, Majd Al Merey, Isabel Gao, Felix Weissenberger, Igor Karpov, Robert Riachi, Ankit Anand, Gautam Prasad, Kay Lamerigts, Reid Hayes, Jamie Rogers, Mandy Guo, Ashish Shenoy, Qiong Q Hu, Kyle He, Yuchen Liu, Polina Zablotskaia, Sagar Gubbi, Yifan Chang, Jay Pavagadhi, Kristian Kjems, Archita Vadali, Diego Machado, Yeqing Li, Renshen Wang, Dipankar Ghosh, Aahil Mehta, Dana Alon, George Polovets, Alessio Tonioni, Nate Kushman, Joel D'sa, Lin Zhuo, Allen Wu, Rohin Shah, John Youssef, Jiayu Ye, Justin Snyder, Karel Lenc, Senaka Buthpitiya, Matthew Tung, Jichuan Chang, Tao Chen, David Saxton, Jenny Lee, Lydia Lihui Zhang, James Qin, Prabakar Radhakrishnan, Maxwell Chen, Piotr Ambroszczyk, Metin Toksoz-Exley, Yan Zhong, Nitzan Katz, Brendan O'Donoghue, Tamara von Glehn, Adi Gerzi Rosenthal, Aga Świetlik, Xiaokai Zhao, Nick Fernando, Jinliang Wei, Jieru Mei, Sergei Vassilvitskii, Diego Cedillo, Pranjal Awasthi, Hui Zheng, Koray Kavukcuoglu, Itay Laish, Joseph Pagadora, Marc Brockschmidt, Christopher A. Choquette-Choo, Arunkumar Byravan, Yifeng Lu, Xu Chen, Mia Chen, Kenton Lee, Rama Pasumarthi, Sijal Bhatnagar, Aditya Shah, Qiyin Wu, Zhuoyuan Chen, Zack Nado, Bartek Perz, Zixuan Jiang, David Kao, Ganesh Mallya, Nino Vieillard, Lantao Mei, Sertan Girgin, Mandy Jordan, Yeongil Ko, Alekh Agarwal, Yaxin Liu, Yasemin Altun, Raoul de Liedekerke, Anastasios Kementsietsidis, Daiyi Peng, Dangyi Liu, Utku Evci, Peter Humphreys, Austin Tarango, Xiang Deng, Yoad Lewenberg, Kevin Aydin, Chengda Wu, Bhavishya Mittal, Tsendsuren Munkhdalai, Kleopatra Chatziprimou, Rodrigo Benenson, Uri First, Xiao Ma, Jinning Li, Armand Joulin, Hamish Tomlinson, Tingnan Zhang, Milad Nasr, Zhi Hong, Michaël Sander, Lisa Anne Hendricks, Anuj Sharma, Andrew Bolt, Eszter Vértes, Jiri Simsa, Tomer Levinboim, Olcan Sercinoglu, Divyansh Shukla, Austin Wu, Craig Swanson, Danny Vainstein, Fan Bu, Bo Wang, Ryan Julian, Charles Yoon, Sergei Lebedev, Antonious Girgis, Bernd Bandemer, David Du, Todd Wang, Xi Chen, Ying Xiao, Peggy Lu, Natalie Ha, Vlad Ionescu, Simon Rowe, Josip Matak, Federico Lebron, Andreas Steiner, Lalit Jain, Manaal Faruqui, Nicolas Lacasse, Georgie Evans, Neesha Subramaniam, Dean Reich, Giulia Vezzani, Aditya Pandey, Joe Stanton, Tianhao Zhou, Liam McCafferty, Henry Griffiths, Verena Rieser, Soheil Hassas Yeganeh, Eleftheria Briakou, Lu Huang, Zichuan Wei, Liangchen Luo, Erik Jue, Gabby Wang, Victor Cotruta, Myriam Khan, Jongbin Park, Qiuchen Guo, Peiran Li, Rong Rong, Diego Antognini, Anastasia Petrushkina, Chetan Tekur, Eli Collins, Parul Bhatia, Chester Kwak, Wenhu Chen, Arvind Neelakantan, Immanuel Odisho, Sheng Peng, Vincent Nallatamby, Vaibhav Tulsyan, Fabian Pedregosa, Peng Xu, Raymond Lin, Yulong Wang, Emma Wang, Sholto Douglas, Reut Tsarfaty, Elena Gribovskaya, Renga Aravamudhan, Manu Agarwal, Mara Finkelstein, Qiao Zhang, Elizabeth Cole, Phil Crone, Sarmishta Velury, Anil Das, Chris Sauer, Luyao Xu, Danfeng Qin, Chenjie Gu, Dror Marcus, CJ Zheng, Wouter Van Gansbeke, Sobhan Miryoosefi, Haitian Sun, YaGuang Li, Charlie Chen, Jae Yoo, Pavel Dubov, Alex Tomala, Adams Yu, Paweł Wesołowski, Alok Gunjan, Eddie Cao, Jiaming Luo, Nikhil Sethi, Arkadiusz Socala, Laura Graesser, Tomas Kocisky, Arturo BC, Minmin Chen, Edward Lee, Sophie Wang, Weize Kong, Qiantong Xu, Nilesh Tripuraneni, Yiming Li, Xinxin Yu, Allen Porter, Paul Voigtlaender, Biao Zhang, Arpi Vezer, Sarah York, Qing Wei, Geoffrey Cideron, Mark Kurzeja, Seungyeon Kim, Benny Li, Angéline Pouget, Hyo Lee, Kaspar Daugaard, Yang Li, Dave Uthus, Aditya Siddhant, Paul Cavallaro, Sriram Ganapathy, Maulik Shah, Rolf Jagerman, Jeff Stanway, Piermaria Mendolicchio, Li Xiao, Kayi Lee, Tara Thompson, Shubham Milind Phal, Jason Chase, Sun Jae Lee, Adrian N Reyes, Disha Shrivastava, Zhen Qin, Roykrong Sukkerd, Seth Odoom, Lior Madmoni, John Aslanides, Jonathan Herzig, Elena Pochernina, Sheng Zhang, Parker Barnes, Daisuke Ikeda, Qiujia Li, Shuo-yiin Chang, Shakir Mohamed, Jim Sproch, Richard Powell, Bidisha Samanta, Domagoj Ćevid, Anton Kovsharov, Shrestha Basu Mallick, Srinivas Tadepalli, Anne Zheng, Kareem Ayoub, Andreas Noever, Christian Reisswig, Zhuo Xu, Junhyuk Oh, Martin Matysiak, Tim Blyth, Shereen Ashraf, Julien Amelot, Boone Severson, Michele Bevilacqua, Motoki Sano, Ethan Dyer, Ofir Roval, Anu Sinha, Yin Zhong, Sagi Perel, Tea Sabolić, Johannes Mauerer, Willi Gierke, Mauro Verzetti, Rodrigo Cabrera, Alvin Abdagic, Steven Hemingray, Austin Stone, Jong Lee, Farooq Ahmad, Karthik Raman, Lior Shani, Jonathan Lai, Orhan Firat, Nathan Waters, Eric Ge, Mo Shomrat, Himanshu Gupta, Rajeev Aggarwal, Tom Hudson, Bill Jia, Simon Baumgartner, Palak Jain, Joe Kovac, Junehyuk Jung, Ante Žužul, Will Truong, Morteza Zadimoghaddam, Songyou Peng, Marco Liang, Rachel Sterneck, Balaji Lakshminarayanan, Machel Reid, Oliver Woodman, Tong Zhou, Jianling Wang, Vincent Coriou, Arjun Narayanan, Jay Hoover, Yenai Ma, Apoorv Jindal, Clayton Sanford, Doug Reid, Swaroop Ramaswamy, Alex Kurakin, Roland Zimmermann, Yana Lunts, Dragos Dena, Zalán Borsos, Vered Cohen, Shujian Zhang, Will Grathwohl, Robert Dadashi, Morgan Redshaw, Joshua Kessinger, Julian Odell, Silvano Bonacina, Zihang Dai, Grace Chen, Ayush Dubey, Pablo Sprechmann, Mantas Pajarskas, Wenxuan Zhou, Niharika Ahuja, Tara Thomas, Martin Nikoltchev, Matija Kecman, Bharath Mankalale, Andrey Ryabtsev, Jennifer She, Christian Walder, Jiaming Shen, Lu Li, Carolina Parada, Sheena Panthaplackel, Okwan Kwon, Matt Lawlor, Utsav Prabhu, Yannick Schroecker, Marc'aurelio Ranzato, Pete Blois, Iurii Kemaev, Ting Yu, Dmitry Lepikhin, Hao Xiong, Sahand Sharifzadeh, Oleaser Johnson, Jeremiah Willcock, Rui Yao, Greg Farquhar, Sujoy Basu, Hidetoshi Shimokawa, Nina Anderson, Haiguang Li, Khiem Pham, Yizhong Liang, Sebastian Borgeaud, Alexandre Moufarek, Hideto Kazawa, Blair Kutzman, Marcin Sieniek, Sara Smoot, Ruth Wang, Natalie Axelsson, Nova Fallen, Prasha Sundaram, Yuexiang Zhai, Varun Godbole, Petros Maniatis, Alek Wang, Ilia Shumailov, Santhosh Thangaraj, Remi Crocker, Nikita Gupta, Gang Wu, Phil Chen, Gellért Weisz, Celine Smith, Mojtaba Seyedhosseini, Boya Fang, Xiyang Luo, Roey Yogev, Zeynep Cankara, Andrew Hard, Helen Ran, Rahul Sukthankar, George Necula, Gaël Liu, Honglong Cai, Praseem Banzal, Daniel Keysers, Sanjay Ghemawat, Connie Tao, Emma Dunleavy, Aditi Chaudhary, Wei Li, Maciej Mikuła, Chen-Yu Lee, Tiziana Refice, Krishna Somandepalli, Alexandre Fréchette, Dan Bahir, John Karro, Keith Rush, Sarah Perrin, Bill Rosgen, Xiaomeng Yang, Clara Huiyi Hu, Mahmoud Alnahlawi, Justin Mao-Jones, Roopal Garg, Hoang Nguyen, Bat-Orgil Batsaikhan, Iñaki Iturrate, Anselm Levskaya, Avi Singh, Ashyana Kachra, Tony Lu, Denis Petek, Zheng Xu, Mark Graham, Lukas Zilka, Yael Karov, Marija Kostelac, Fangyu Liu, Yaohui Guo, Weiyue Wang, Bernd Bohnet, Emily Pitler, Tony Bruguier, Keisuke Kinoshita, Chrysovalantis Anastasiou, Nilpa Jha, Ting Liu, Jerome Connor, Phil Wallis, Philip Pham, Eric Bailey, Shixin Li, Heng-Tze Cheng, Sally Ma, Haiqiong Li, Akanksha Maurya, Kate Olszewska, Manfred Warmuth, Christy Koh, Dominik Paulus, Siddhartha Reddy Jonnalagadda, Enrique Piqueras, Ali Elqursh, Geoff Brown, Hadar Shemtov, Loren Maggiore, Fei Xia, Ryan Foley, Beka Westberg, George van den Driessche, Livio Baldini Soares, Arjun Kar, Michael Quinn, Siqi Zuo, Jialin Wu, Kyle Kastner, Anna Bortsova, Aijun Bai, Ales Mikhalap, Luowei Zhou, Jennifer Brennan, Vinay Ramasesh, Honglei Zhuang, John Maggs, Johan Schalkwyk, Yuntao Xu, Hui Huang, Andrew Howard, Sasha Brown, Linting Xue, Gloria Shen, Brian Albert, Neha Jha, Daniel Zheng, Varvara Krayvanova, Spurthi Amba Hombaiah, Olivier Lacombe, Gautam Vasudevan, Dan Graur, Tian Xie, Meet Gandhi, Bangju Wang, Dustin Zelle, Harman Singh, Dahun Kim, Sébastien Cevey, Victor Ungureanu, Natasha Noy, Fei Liu, Annie Xie, Fangxiaoyu Feng, Katerina Tsihlas, Daniel Formoso, Neera Vats, Quentin Wellens, Yinan Wang, Niket Kumar Bhumihar, Samrat Ghosh, Matt Hoffman, Tom Lieber, Oran Lang, Kush Bhatia, Tom Paine, Aroonalok Pyne, Ronny Votel, Madeleine Clare Elish, Benoit Schillings, Alex Panagopoulos, Haichuan Yang, Adam Raveret, Zohar Yahav, Shuang Liu, Dalia El Badawy, Nishant Agrawal, Mohammed Badawi, Mahdi Mirzazadeh, Carla Bromberg, Fan Ye, Chang Liu, Tatiana Sholokhova, George-Cristian Muraru, Gargi Balasubramaniam, Jonathan Malmaud, Alen Carin, Danilo Martins, Irina Jurenka, Pankil Botadra, Dave Lacey, Richa Singh, Mariano Schain, Dan Zheng, Isabelle Guyon, Victor Lavrenko, Seungji Lee, Xiang Zhou, Demis Hassabis, Jeshwanth Challagundla, Derek Cheng, Nikhil Mehta, Matthew Mauger, Michela Paganini, Pushkar Mishra, Kate Lee, Zhang Li, Lexi Baugher, Ondrej Skopek, Max Chang, Amir Zait, Gaurav Menghani, Lizzetth Bellot, Guangxing Han, Jean-Michel Sarr, Sharat Chikkerur, Himanshu Sahni, Rohan Anil, Arun Narayanan, Chandu Thekkath, Daniele Pighin, Hana Strejček, Marko Velic, Fred Bertsch, Manuel Tragut, Keran Rong, Alicia Parrish, Kai Bailey, Jiho Park, Isabela Albuquerque, Abhishek Bapna, Rajesh Venkataraman, Alec Kosik, Johannes Griesser, Zhiwei Deng, Alek Andreev, Qingyun Dou, Kevin Hui, Fanny Wei, Xiaobin Yu, Lei Shu, Avia Aharon, David Barker, Badih Ghazi, Sebastian Flennerhag, Chris Breaux, Yuchuan Liu, Matthew Bilotti, Josh Woodward, Uri Alon, Stephanie Winkler, Tzu-Kuo Huang, Kostas Andriopoulos, João Gabriel Oliveira, Penporn Koanantakool, Berkin Akin, Michael Wunder, Cicero Nogueira dos Santos, Mohammad Hossein Bateni, Lin Yang, Dan Horgan, Beer Changpinyo, Keyvan Amiri, Min Ma, Dayeong Lee, Lihao Liang, Anirudh Baddepudi, Tejasi Latkar, Raia Hadsell, Jun Xu, Hairong Mu, Michael Han, Aedan Pope, Snchit Grover, Frank Kim, Ankit Bhagatwala, Guan Sun, Yamini Bansal, Amir Globerson, Alireza Nazari, Samira Daruki, Hagen Soltau, Jane Labanowski, Laurent El Shafey, Matt Harvey, Yanif Ahmad, Elan Rosenfeld, William Kong, Etienne Pot, Yi-Xuan Tan, Aurora Wei, Victoria Langston, Marcel Prasetya, Petar Veličković, Richard Killam, Robin Strudel, Darren Ni, Zhenhai Zhu, Aaron Archer, Kavya Kopparapu, Lynn Nguyen, Emilio Parisotto, Hussain Masoom, Sravanti Addepalli, Jordan Grimstad, Hexiang Hu, Joss Moore, Avinatan Hassidim, Le Hou, Mukund Raghavachari, Jared Lichtarge, Adam R. Brown, Hilal Dib, Natalia Ponomareva, Justin Fu, Yujing Zhang, Altaf Rahman, Joana Iljazi, Edouard Leurent, Gabriel Dulac-Arnold, Cosmo Du, Chulayuth Asawaroengchai, Larry Jin, Ela Gruzewska, Ziwei Ji, Benigno Uria, Daniel De Freitas, Paul Barham, Lauren Beltrone, Víctor Campos, Jun Yan, Neel Kovelamudi, Arthur Nguyen, Elinor Davies, Zhichun Wu, Zoltan Egyed, Kristina Toutanova, Nithya Attaluri, Hongliang Fei, Peter Stys, Siddhartha Brahma, Martin Izzard, Siva Velusamy, Scott Lundberg, Vincent Zhuang, Kevin Sequeira, Adam Santoro, Ehsan Amid, Ophir Aharoni, Shuai Ye, Mukund Sundararajan, Lijun Yu, Yu-Cheng Ling, Stephen Spencer, Hugo Song, Josip Djolonga, Christo Kirov, Sonal Gupta, Alessandro Bissacco, Clemens Meyer, Mukul Bhutani, Andrew Dai, Weiyi Wang, Siqi Liu, Ashwin Sreevatsa, Qijun Tan, Maria Wang, Lucy Kim, Yicheng Wang, Alex Irpan, Yang Xiao, Stanislav Fort, Yifan He, Alex Gurney, Bryan Gale, Yue Ma, Monica Roy, Viorica Patraucean, Taylan Bilal, Golnaz Ghiasi, Anahita Hosseini, Melvin Johnson, Zhuowan Li, Yi Tay, Benjamin Beyret, Katie Millican, Josef Broder, Mayank Lunayach, Danny Swisher, Eugen Vušak, David Parkinson, MH Tessler, Adi Mayrav Gilady, Richard Song, Allan Dafoe, Yves Raimond, Masa Yamaguchi, Itay Karo, Elizabeth Nielsen, Kevin Kilgour, Mike Dusenberry, Rajiv Mathews, Jiho Choi, Siyuan Qiao, Harsh Mehta, Sahitya Potluri, Chris Knutsen, Jialu Liu, Tat Tan, Kuntal Sengupta, Keerthana Gopalakrishnan, Abodunrinwa Toki, Mencher Chiang, Mike Burrows, Grace Vesom, Zafarali Ahmed, Ilia Labzovsky, Siddharth Vashishtha, Preeti Singh, Ankur Sharma, Ada Ma, Jinyu Xie, Pranav Talluri, Hannah Forbes-Pollard, Aarush Selvan, Joel Wee, Loic Matthey, Tom Funkhouser, Parthasarathy Gopavarapu, Lev Proleev, Cheng Li, Matt Thomas, Kashyap Kolipaka, Zhipeng Jia, Ashwin Kakarla, Srinivas Sunkara, Joan Puigcerver, Suraj Satishkumar Sheth, Emily Graves, Chen Wang, Sadh MNM Khan, Kai Kang, Shyamal Buch, Fred Zhang, Omkar Savant, David Soergel, Kevin Lee, Linda Friso, Xuanyi Dong, Rahul Arya, Shreyas Chandrakaladharan, Connor Schenck, Greg Billock, Tejas Iyer, Anton Bakalov, Leslie Baker, Alex Ruiz, Angad Chandorkar, Trieu Trinh, Matt Miecnikowski, Yanqi Zhou, Yangsibo Huang, Jiazhong Nie, Ali Shah, Ashish Thapliyal, Sam Haves, Lun Wang, Uri Shaham, Patrick Morris-Suzuki, Soroush Radpour, Leonard Berrada, Thomas Strohmann, Chaochao Yan, Jingwei Shen, Sonam Goenka, Tris Warkentin, Petar Dević, Dan Belov, Albert Webson, Madhavi Yenugula, Puranjay Datta, Jerry Chang, Nimesh Ghelani, Aviral Kumar, Vincent Perot, Jessica Lo, Yang Song, Herman Schmit, Jianmin Chen, Vasilisa Bashlovkina, Xiaoyue Pan, Diana Mincu, Paul Roit, Isabel Edkins, Andy Davis, Yujia Li, Ben Horn, Xinjian Li, Pradeep Kumar S, Eric Doi, Wanzheng Zhu, Sri Gayatri Sundara Padmanabhan, Siddharth Verma, Jasmine Liu, Heng Chen, Mihajlo Velimirović, Malcolm Reynolds, Priyanka Agrawal, Nick Sukhanov, Abhinit Modi, Siddharth Goyal, John Palowitch, Nima Khajehnouri, Wing Lowe, David Klinghoffer, Sharon Silver, Vinh Tran, Candice Schumann, Francesco Piccinno, Xi Liu, Mario Lučić, Xiaochen Yang, Sandeep Kumar, Ajay Kannan, Ragha Kotikalapudi, Mudit Bansal, Fabian Fuchs, Mohammad Javad Hosseini, Abdelrahman Abdelhamed, Dawn Bloxwich, Tianhe Yu, Ruoxin Sang, Gregory Thornton, Karan Gill, Yuchi Liu, Virat Shejwalkar, Jason Lin, Zhipeng Yan, Kehang Han, Thomas Buschmann, Michael Pliskin, Zhi Xing, Susheel Tatineni, Junlin Zhang, Sissie Hsiao, Gavin Buttimore, Marcus Wu, Zefei Li, Geza Kovacs, Legg Yeung, Tao Huang, Aaron Cohen, Bethanie Brownfield, Averi Nowak, Mikel Rodriguez, Tianze Shi, Hado van Hasselt, Kevin Cen, Deepanway Ghoshal, Kushal Majmundar, Weiren Yu, Warren Weilun Chen, Danila Sinopalnikov, Hao Zhang, Vlado Galić, Di Lu, Zeyu Zheng, Maggie Song, Gary Wang, Gui Citovsky, Swapnil Gawde, Isaac Galatzer-Levy, David Silver, Ivana Balazevic, Dipanjan Das, Kingshuk Majumder, Yale Cong, Praneet Dutta, Dustin Tran, Hui Wan, Junwei Yuan, Daniel Eppens, Alanna Walton, Been Kim, Harry Ragan, James Cobon-Kerr, Lu Liu, Weijun Wang, Bryce Petrini, Jack Rae, Rakesh Shivanna, Yan Xiong, Chace Lee, Pauline Coquinot, Yiming Gu, Lisa Patel, Blake Hechtman, Aviel Boag, Orion Jankowski, Alex Wertheim, Alex Lee, Paul Covington, Hila Noga, Sam Sobell, Shanthal Vasanth, William Bono, Chirag Nagpal, Wei Fan, Xavier Garcia, Kedar Soparkar, Aybuke Turker, Nathan Howard, Sachit Menon, Yuankai Chen, Vikas Verma, Vladimir Pchelin, Harish Rajamani, Valentin Dalibard, Ana Ramalho, Yang Guo, Kartikeya Badola, Seojin Bang, Nathalie Rauschmayr, Julia Proskurnia, Sudeep Dasari, Xinyun Chen, Mikhail Sushkov, Anja Hauth, Pauline Sho, Abhinav Singh, Bilva Chandra, Allie Culp, Max Dylla, Olivier Bachem, James Besley, Heri Zhao, Timothy Lillicrap, Wei Wei, Wael Al Jishi, Ning Niu, Alban Rrustemi, Raphaël Lopez Kaufman, Ryan Poplin, Jewel Zhao, Minh Truong, Shikhar Bharadwaj, Ester Hlavnova, Eli Stickgold, Cordelia Schmid, Georgi Stephanov, Zhaoqi Leng, Frederick Liu, Léonard Hussenot, Shenil Dodhia, Juliana Vicente Franco, Lesley Katzen, Abhanshu Sharma, Sarah Cogan, Zuguang Yang, Aniket Ray, Sergi Caelles, Shen Yan, Ravin Kumar, Daniel Gillick, Renee Wong, Joshua Ainslie, Jonathan Hoech, Séb Arnold, Dan Abolafia, Anca Dragan, Ben Hora, Grace Hu, Alexey Guseynov, Yang Lu, Chas Leichner, Jinmeng Rao, Abhimanyu Goyal, Nagabhushan Baddi, Daniel Hernandez Diaz, Tim McConnell, Max Bain, Jake Abernethy, Qiqi Yan, Rylan Schaeffer, Paul Vicol, Will Thompson, Montse Gonzalez Arenas, Mathias Bellaiche, Pablo Barrio, Stefan Zinke, Riccardo Patana, Pulkit Mehta, JK Kearns, Avraham Ruderman, Scott Pollom, David D'Ambrosio, Cath Hope, Yang Yu, Andrea Gesmundo, Kuang-Huei Lee, Aviv Rosenberg, Yiqian Zhou, Yaoyiran Li, Drew Garmon, Yonghui Wu, Safeen Huda, Gil Fidel, Martin Baeuml, Jian Li, Phoebe Kirk, Rhys May, Tao Tu, Sara Mc Carthy, Toshiyuki Fukuzawa, Miranda Aperghis, Chih-Kuan Yeh, Toshihiro Yoshino, Bo Li, Austin Myers, Kaisheng Yao, Ben Limonchik, Changwan Ryu, Rohun Saxena, Alex Goldin, Ruizhe Zhao, Rocky Rhodes, Tao Zhu, Divya Tyam, Heidi Howard, Nathan Byrd, Hongxu Ma, Yan Wu, Ryan Mullins, Qingze Wang, Aida Amini, Sebastien Baur, Yiran Mao, Subhashini Venugopalan, Will Song, Wen Ding, Paul Collins, Sashank Reddi, Megan Shum, Andrei Rusu, Luisa Zintgraf, Kelvin Chan, Sheela Goenka, Mathieu Blondel, Michael Collins, Renke Pan, Marissa Giustina, Nikolai Chinaev, Christian Schuler, Ce Zheng, Jonas Valfridsson, Alyssa Loo, Alex Yakubovich, Jamie Smith, Tao Jiang, Rich Munoz, Gabriel Barcik, Rishabh Bansal, Mingyao Yang, Yilun Du, Pablo Duque, Mary Phuong, Alexandra Belias, Kunal Lad, Zeyu Liu, Tal Schuster, Karthik Duddu, Jieru Hu, Paige Kunkle, Matthew Watson, Jackson Tolins, Josh Smith, Denis Teplyashin, Garrett Bingham, Marvin Ritter, Marco Andreetto, Divya Pitta, Mohak Patel, Shashank Viswanadha, Trevor Strohman, Catalin Ionescu, Jincheng Luo, Yogesh Kalley, Jeremy Wiesner, Dan Deutsch, Derek Lockhart, Peter Choy, Rumen Dangovski, Chawin Sitawarin, Cat Graves, Tanya Lando, Joost van Amersfoort, Ndidi Elue, Zhouyuan Huo, Pooya Moradi, Jean Tarbouriech, Henryk Michalewski, Wenting Ye, Eunyoung Kim, Alex Druinsky, Florent Altché, Xinyi Chen, Artur Dwornik, Da-Cheng Juan, Rivka Moroshko, Horia Toma, Jarrod Kahn, Hai Qian, Maximilian Sieb, Irene Cai, Roman Goldenberg, Praneeth Netrapalli, Sindhu Raghuram, Yuan Gong, Lijie Fan, Evan Palmer, Yossi Matias, Valentin Gabeur, Shreya Pathak, Tom Ouyang, Don Metzler, Geoff Bacon, Srinivasan Venkatachary, Sridhar Thiagarajan, Alex Cullum, Eran Ofek, Vytenis Sakenas, Mohamed Hammad, Cesar Magalhaes, Mayank Daswani, Oscar Chang, Ashok Popat, Ruichao Li, Komal Jalan, Yanhan Hou, Josh Lipschultz, Antoine He, Wenhao Jia, Pier Giuseppe Sessa, Prateek Kolhar, William Wong, Sumeet Singh, Lukas Haas, Jay Whang, Hanna Klimczak-Plucińska, Georges Rotival, Grace Chung, Yiqing Hua, Anfal Siddiqui, Nicolas Serrano, Dongkai Chen, Billy Porter, Libin Bai, Keshav Shivam, Sho Arora, Partha Talukdar, Tom Cobley, Sangnie Bhardwaj, Evgeny Gladchenko, Simon Green, Kelvin Guu, Felix Fischer, Xiao Wu, Eric Wang, Achintya Singhal, Tatiana Matejovicova, James Martens, Hongji Li, Roma Patel, Elizabeth Kemp, Jiaqi Pan, Lily Wang, Blake JianHang Chen, Jean-Baptiste Alayrac, Navneet Potti, Erika Gemzer, Eugene Ie, Kay McKinney, Takaaki Saeki, Edward Chou, Pascal Lamblin, SQ Mah, Zach Fisher, Martin Chadwick, Jon Stritar, Obaid Sarvana, Andrew Hogue, Artem Shtefan, Hadi Hashemi, Yang Xu, Jindong Gu, Sharad Vikram, Chung-Ching Chang, Sabela Ramos, Logan Kilpatrick, Weijuan Xi, Jenny Brennan, Yinghao Sun, Abhishek Jindal, Ionel Gog, Dawn Chen, Felix Wu, Jason Lee, Sudhindra Kopalle, Srinadh Bhojanapalli, Oriol Vinyals, Natan Potikha, Burcu Karagol Ayan, Yuan Yuan, Michael Riley, Piotr Stanczyk, Sergey Kishchenko, Bing Wang, Dan Garrette, Antoine Yang, Vlad Feinberg, CJ Carey, Javad Azizi, Viral Shah, Erica Moreira, Chongyang Shi, Josh Feldman, Elizabeth Salesky, Thomas Lampe, Aneesh Pappu, Duhyeon Kim, Jonas Adler, Avi Caciularu, Brian Walker, Yunhan Xu, Yochai Blau, Dylan Scandinaro, Terry Huang, Sam El-Husseini, Abhishek Sinha, Lijie Ren, Taylor Tobin, Patrik Sundberg, Tim Sohn, Vikas Yadav, Mimi Ly, Emily Xue, Jing Xiong, Afzal Shama Soudagar, Sneha Mondal, Nikhil Khadke, Qingchun Ren, Ben Vargas, Stan Bileschi, Sarah Chakera, Cindy Wang, Boyu Wang, Yoni Halpern, Joe Jiang, Vikas Sindhwani, Petre Petrov, Pranavaraj Ponnuramu, Sanket Vaibhav Mehta, Yu Watanabe, Betty Chan, Matheus Wisniewski, Trang Pham, Jingwei Zhang, Conglong Li, Dario de Cesare, Art Khurshudov, Alex Vasiloff, Melissa Tan, Zoe Ashwood, Bobak Shahriari, Maryam Majzoubi, Garrett Tanzer, Olga Kozlova, Robin Alazard, James Lee-Thorp, Nguyet Minh Phu, Isaac Tian, Junwhan Ahn, Andy Crawford, Lauren Lax, Yuan Shangguan, Iftekhar Naim, David Ross, Oleksandr Ferludin, Tongfei Guo, Andrea Banino, Hubert Soyer, Xiaoen Ju, Dominika Rogozińska, Ishaan Malhi, Marcella Valentine, Daniel Balle, Apoorv Kulshreshtha, Maciej Kula, Yiwen Song, Sophia Austin, John Schultz, Roy Hirsch, Arthur Douillard, Apoorv Reddy, Michael Fink, Summer Yue, Khyatti Gupta, Adam Zhang, Norman Rink, Daniel McDuff, Lei Meng, András György, Yasaman Razeghi, Ricky Liang, Kazuki Osawa, Aviel Atias, Matan Eyal, Tyrone Hill, Nikolai Grigorev, Zhengdong Wang, Nitish Kulkarni, Rachel Soh, Ivan Lobov, Zachary Charles, Sid Lall, Kazuma Hashimoto, Ido Kessler, Victor Gomes, Zelda Mariet, Danny Driess, Alessandro Agostini, Canfer Akbulut, Jingcao Hu, Marissa Ikonomidis, Emily Caveness, Kartik Audhkhasi, Saurabh Agrawal, Ioana Bica, Evan Senter, Jayaram Mudigonda, Kelly Chen, Jingchen Ye, Xuanhui Wang, James Svensson, Philipp Fränken, Josh Newlan, Li Lao, Eva Schnider, Sami Alabed, Joseph Kready, Jesse Emond, Afief Halumi, Tim Zaman, Chengxi Ye, Naina Raisinghani, Vilobh Meshram, Bo Chang, Ankit Singh Rawat, Axel Stjerngren, Sergey Levi, Rui Wang, Xiangzhu Long, Mitchelle Rasquinha, Steven Hand, Aditi Mavalankar, Lauren Agubuzu, Sudeshna Roy, Junquan Chen, Jarek Wilkiewicz, Hao Zhou, Michal Jastrzebski, Qiong Hu, Agustin Dal Lago, Ramya Sree Boppana, Wei-Jen Ko, Jennifer Prendki, Yao Su, Zhi Li, Eliza Rutherford, Girish Ramchandra Rao, Ramona Comanescu, Adrià Puigdomènech, Qihang Chen, Dessie Petrova, Christine Chan, Vedrana Milutinovic, Felipe Tiengo Ferreira, Chin-Yi Cheng, Ming Zhang, Tapomay Dey, Sherry Yang, Ramesh Sampath, Quoc Le, Howard Zhou, Chu-Cheng Lin, Hoi Lam, Christine Kaeser-Chen, Kai Hui, Dean Hirsch, Tom Eccles, Basil Mustafa, Shruti Rijhwani, Morgane Rivière, Yuanzhong Xu, Junjie Wang, Xinyang Geng, Xiance Si, Arjun Khare, Cheolmin Kim, Vahab Mirrokni, Kamyu Lee, Khuslen Baatarsukh, Nathaniel Braun, Lisa Wang, Pallavi LV, Richard Tanburn, Yonghao Zhu, Fangda Li, Setareh Ariafar, Dan Goldberg, Ken Burke, Daniil Mirylenka, Meiqi Guo, Olaf Ronneberger, Hadas Natalie Vogel, Liqun Cheng, Nishita Shetty, Johnson Jia, Thomas Jimma, Corey Fry, Ted Xiao, Martin Sundermeyer, Ryan Burnell, Yannis Assael, Mario Pinto, JD Chen, Rohit Sathyanarayana, Donghyun Cho, Jing Lu, Rishabh Agarwal, Sugato Basu, Lucas Gonzalez, Dhruv Shah, Meng Wei, Dre Mahaarachchi, Rohan Agrawal, Tero Rissa, Yani Donchev, Ramiro Leal-Cavazos, Adrian Hutter, Markus Mircea, Alon Jacovi, Faruk Ahmed, Jiageng Zhang, Shuguang Hu, Bo-Juen Chen, Jonni Kanerva, Guillaume Desjardins, Andrew Lee, Nikos Parotsidis, Asier Mujika, Tobias Weyand, Jasper Snoek, Jo Chick, Kai Chen, Paul Chang, Ethan Mahintorabi, Zi Wang, Tolly Powell, Orgad Keller, Abhirut Gupta, Claire Sha, Kanav Garg, Nicolas Heess, Ágoston Weisz, Cassidy Hardin, Bartek Wydrowski, Ben Coleman, Karina Zainullina, Pankaj Joshi, Alessandro Epasto, Terry Spitz, Binbin Xiong, Kai Zhao, Arseniy Klimovskiy, Ivy Zheng, Johan Ferret, Itay Yona, Waleed Khawaja, Jean-Baptiste Lespiau, Maxim Krikun, Siamak Shakeri, Timothee Cour, Bonnie Li, Igor Krivokon, Dan Suh, Alex Hofer, Jad Al Abdallah, Nikita Putikhin, Oscar Akerlund, Silvio Lattanzi, Anurag Kumar, Shane Settle, Himanshu Srivastava, Folawiyo Campbell-Ajala, Edouard Rosseel, Mihai Dorin Istin, Nishanth Dikkala, Anand Rao, Nick Young, Kate Lin, Dhruva Bhaswar, Yiming Wang, Jaume Sanchez Elias, Kritika Muralidharan, James Keeling, Dayou Du, Siddharth Gopal, Gregory Dibb, Charles Blundell, Manolis Delakis, Jacky Liang, Marco Tulio Ribeiro, Georgi Karadzhov, Guillermo Garrido, Ankur Bapna, Jiawei Cao, Adam Sadovsky, Pouya Tafti, Arthur Guez, Coline Devin, Yixian Di, Jinwei Xing, Chuqiao Joyce Xu, Hanzhao Lin, Chun-Te Chu, Sameera Ponda, Wesley Helmholz, Fan Yang, Yue Gao, Sara Javanmardi, Wael Farhan, Alex Ramirez, Ricardo Figueira, Khe Chai Sim, Yuval Bahat, Ashwin Vaswani, Liangzhe Yuan, Gufeng Zhang, Leland Rechis, Hanjun Dai, Tayo Oguntebi, Alexandra Cordell, Eugénie Rives, Kaan Tekelioglu, Naveen Kumar, Bing Zhang, Aurick Zhou, Nikolay Savinov, Andrew Leach, Alex Tudor, Sanjay Ganapathy, Yanyan Zheng, Mirko Rossini, Vera Axelrod, Arnaud Autef, Yukun Zhu, Zheng Zheng, Mingda Zhang, Baochen Sun, Jie Ren, Nenad Tomasev, Nithish Kannen, Amer Sinha, Charles Chen, Louis O'Bryan, Alex Pak, Aditya Kusupati, Weel Yang, Deepak Ramachandran, Patrick Griffin, Seokhwan Kim, Philipp Neubeck, Craig Schiff, Tammo Spalink, Mingyang Ling, Arun Nair, Ga-Young Joung, Linda Deng, Avishkar Bhoopchand, Lora Aroyo, Tom Duerig, Jordan Griffith, Gabe Barth-Maron, Jake Ades, Alex Haig, Ankur Taly, Yunting Song, Paul Michel, Dave Orr, Dean Weesner, Corentin Tallec, Carrie Grimes Bostock, Paul Niemczyk, Andy Twigg, Mudit Verma, Rohith Vallu, Henry Wang, Marco Gelmi, Kiranbir Sodhia, Aleksandr Chuklin, Omer Goldman, Jasmine George, Liang Bai, Kelvin Zhang, Petar Sirkovic, Efrat Nehoran, Golan Pundak, Jiaqi Mu, Alice Chen, Alex Greve, Paulo Zacchello, David Amos, Heming Ge, Eric Noland, Colton Bishop, Jeffrey Dudek, Youhei Namiki, Elena Buchatskaya, Jing Li, Dorsa Sadigh, Masha Samsikova, Dan Malkin, Damien Vincent, Robert David, Rob Willoughby, Phoenix Meadowlark, Shawn Gao, Yan Li, Raj Apte, Amit Jhindal, Stein Xudong Lin, Alex Polozov, Zhicheng Wang, Tomas Mery, Anirudh GP, Varun Yerram, Sage Stevens, Tianqi Liu, Noah Fiedel, Charles Sutton, Matthew Johnson, Xiaodan Song, Kate Baumli, Nir Shabat, Muqthar Mohammad, Hao Liu, Marco Selvi, Yichao Zhou, Mehdi Hafezi Manshadi, Chu-ling Ko, Anthony Chen, Michael Bendersky, Jorge Gonzalez Mendez, Nisarg Kothari, Amir Zandieh, Yiling Huang, Daniel Andor, Ellie Pavlick, Idan Brusilovsky, Jitendra Harlalka, Sally Goldman, Andrew Lampinen, Guowang Li, Asahi Ushio, Somit Gupta, Lei Zhang, Chuyuan Kelly Fu, Madhavi Sewak, Timo Denk, Jed Borovik, Brendan Jou, Avital Zipori, Prateek Jain, Junwen Bai, Thang Luong, Jonathan Tompson, Alice Li, Li Liu, George Powell, Jiajun Shen, Alex Feng, Grishma Chole, Da Yu, Yinlam Chow, Tongxin Yin, Eric Malmi, Kefan Xiao, Yash Pande, Shachi Paul, Niccolò Dal Santo, Adil Dostmohamed, Sergio Guadarrama, Aaron Phillips, Thanumalayan Sankaranarayana Pillai, Gal Yona, Amin Ghafouri, Preethi Lahoti, Benjamin Lee, Dhruv Madeka, Eren Sezener, Simon Tokumine, Adrian Collister, Nicola De Cao, Richard Shin, Uday Kalra, Parker Beak, Emily Nottage, Ryo Nakashima, Ivan Jurin, Vikash Sehwag, Meenu Gaba, Junhao Zeng, Kevin R. McKee, Fernando Pereira, Tamar Yakar, Amayika Panda, Arka Dhar, Peilin Zhong, Daniel Sohn, Mark Brand, Lars Lowe Sjoesund, Viral Carpenter, Sharon Lin, Shantanu Thakoor, Marcus Wainwright, Ashwin Chaugule, Pranesh Srinivasan, Muye Zhu, Bernett Orlando, Jack Weber, Ayzaan Wahid, Gilles Baechler, Apurv Suman, Jovana Mitrović, Gabe Taubman, Honglin Yu, Helen King, Josh Dillon, Cathy Yip, Dhriti Varma, Tomas Izo, Levent Bolelli, Borja De Balle Pigem, Julia Di Trapani, Fotis Iliopoulos, Adam Paszke, Nishant Ranka, Joe Zou, Francesco Pongetti, Jed McGiffin, Alex Siegman, Rich Galt, Ross Hemsley, Goran Žužić, Victor Carbune, Tao Li, Myle Ott, Félix de Chaumont Quitry, David Vilar Torres, Yuri Chervonyi, Tomy Tsai, Prem Eruvbetine, Samuel Yang, Matthew Denton, Jake Walker, Slavica Andačić, Idan Heimlich Shtacher, Vittal Premachandran, Harshal Tushar Lehri, Cip Baetu, Damion Yates, Lampros Lamprou, Mariko Iinuma, Ioana Mihailescu, Ben Albrecht, Shachi Dave, Susie Sargsyan, Bryan Perozzi, Lucas Manning, Chiyuan Zhang, Denis Vnukov, Igor Mordatch, Raia Hadsell Wolfgang Macherey, Ryan Kappedal, Jim Stephan, Aditya Tripathi, Klaus Macherey, Jun Qian, Abhishek Bhowmick, Shekoofeh Azizi, Rémi Leblond, Shiva Mohan Reddy Garlapati, Timothy Knight, Matthew Wiethoff, Wei-Chih Hung, Anelia Angelova, Georgios Evangelopoulos, Pawel Janus, Dimitris Paparas, Matthew Rahtz, Ken Caluwaerts, Vivek Sampathkumar, Daniel Jarrett, Shadi Noghabi, Antoine Miech, Chak Yeung, Geoff Clark, Henry Prior, Fei Zheng, Jean Pouget-Abadie, Indro Bhattacharya, Kalpesh Krishna, Will Bishop, Zhe Yuan, Yunxiao Deng, Ashutosh Sathe, Kacper Krasowiak, Ciprian Chelba, Cho-Jui Hsieh, Kiran Vodrahalli, Buhuang Liu, Thomas Köppe, Amr Khalifa, Lubo Litchev, Pichi Charoenpanit, Reed Roberts, Sachin Yadav, Yasumasa Onoe, Desi Ivanov, Megha Mohabey, Vighnesh Birodkar, Nemanja Rakićević, Pierre Sermanet, Vaibhav Mehta, Krishan Subudhi, Travis Choma, Will Ng, Luheng He, Kathie Wang, Tasos Kementsietsidis, Shane Gu, Mansi Gupta, Andrew Nystrom, Mehran Kazemi, Timothy Chung, Nacho Cano, Nikhil Dhawan, Yufei Wang, Jiawei Xia, Trevor Yacovone, Eric Jia, Mingqing Chen, Simeon Ivanov, Ashrith Sheshan, Sid Dalmia, Paweł Stradomski, Pengcheng Yin, Salem Haykal, Congchao Wang, Dennis Duan, Neslihan Bulut, Greg Kochanski, Liam MacDermed, Namrata Godbole, Shitao Weng, Jingjing Chen, Rachana Fellinger, Ramin Mehran, Daniel Suo, Hisham Husain, Tong He, Kaushal Patel, Joshua Howland, Randall Parker, Kelvin Nguyen, Sharath Maddineni, Chris Rawles, Mina Khan, Shlomi Cohen-Ganor, Amol Mandhane, Xinyi Wu, Chenkai Kuang, Iulia Comşa, Ramya Ganeshan, Hanie Sedghi, Adam Bloniarz, Nuo Wang Pierse, Anton Briukhov, Petr Mitrichev, Anita Gergely, Serena Zhan, Allan Zhou, Nikita Saxena, Eva Lu, Josef Dean, Ashish Gupta, Nicolas Perez-Nieves, Renjie Wu, Cory McLean, Wei Liang, Disha Jindal, Anton Tsitsulin, Wenhao Yu, Kaiz Alarakyia, Tom Schaul, Piyush Patil, Peter Sung, Elijah Peake, Hongkun Yu, Feryal Behbahani, JD Co-Reyes, Alan Ansell, Sean Sun, Clara Barbu, Jonathan Lee, Seb Noury, James Allingham, Bilal Piot, Mohit Sharma, Christopher Yew, Ivan Korotkov, Bibo Xu, Demetra Brady, Goran Petrovic, Shibl Mourad, Claire Cui, Aditya Gupta, Parker Schuh, Saarthak Khanna, Anna Goldie, Abhinav Arora, Vadim Zubov, Amy Stuart, Mark Epstein, Yun Zhu, Jianqiao Liu, Yury Stuken, Ziyue Wang, Karolis Misiunas, Dee Guo, Ashleah Gill, Ale Hartman, Zaid Nabulsi, Aurko Roy, Aleksandra Faust, Jason Riesa, Ben Withbroe, Mengchao Wang, Marco Tagliasacchi, Andreea Marzoca, James Noraky, Serge Toropov, Malika Mehrotra, Bahram Raad, Sanja Deur, Steve Xu, Marianne Monteiro, Zhongru Wu, Yi Luan, Sam Ritter, Nick Li, Håvard Garnes, Yanzhang He, Martin Zlocha, Jifan Zhu, Matteo Hessel, Will Wu, Spandana Raj Babbula, Chizu Kawamoto, Yuanzhen Li, Mehadi Hassen, Yan Wang, Brian Wieder, James Freedman, Yin Zhang, Xinyi Bai, Tianli Yu, David Reitter, XiangHai Sheng, Mateo Wirth, Aditya Kini, Dima Damen, Mingcen Gao, Rachel Hornung, Michael Voznesensky, Brian Roark, Adhi Kuncoro, Yuxiang Zhou, Rushin Shah, Anthony Brohan, Kuangyuan Chen, James Wendt, David Rim, Paul Kishan Rubenstein, Jonathan Halcrow, Michelle Liu, Ty Geri, Yunhsuan Sung, Jane Shapiro, Shaan Bijwadia, Chris Duvarney, Christina Sorokin, Paul Natsev, Reeve Ingle, Pramod Gupta, Young Maeng, Ndaba Ndebele, Kexin Zhu, Valentin Anklin, Katherine Lee, Yuan Liu, Yaroslav Akulov, Shaleen Gupta, Guolong Su, Flavien Prost, Tianlin Liu, Vitaly Kovalev, Pol Moreno, Martin Scholz, Sam Redmond, Zongwei Zhou, Alex Castro-Ros, André Susano Pinto, Dia Kharrat, Michal Yarom, Rachel Saputro, Jannis Bulian, Ben Caine, Ji Liu, Abbas Abdolmaleki, Shariq Iqbal, Tautvydas Misiunas, Mikhail Sirotenko, Shefali Garg, Guy Bensky, Huan Gui, Xuezhi Wang, Raphael Koster, Mike Bernico, Da Huang, Romal Thoppilan, Trevor Cohn, Ben Golan, Wenlei Zhou, Andrew Rosenberg, Markus Freitag, Tynan Gangwani, Vincent Tsang, Anand Shukla, Xiaoqi Ren, Minh Giang, Chi Zou, Andre Elisseeff, Charline Le Lan, Dheeru Dua, Shuba Lall, Pranav Shyam, Frankie Garcia, Sarah Nguyen, Michael Guzman, AJ Maschinot, Marcello Maggioni, Ming-Wei Chang, Karol Gregor, Lotte Weerts, Kumaran Venkatesan, Bogdan Damoc, Leon Liu, Jan Wassenberg, Lewis Ho, Becca Roelofs, Majid Hadian, François-Xavier Aubet, Yu Liang, Sami Lachgar, Danny Karmon, Yong Cheng, Amelio Vázquez-Reina, Angie Chen, Zhuyun Dai, Andy Brock, Shubham Agrawal, Chenxi Pang, Peter Garst, Mariella Sanchez-Vargas, Ivor Rendulic, Aditya Ayyar, Andrija Ražnatović, Olivia Ma, Roopali Vij, Neha Sharma, Ashwin Balakrishna, Bingyuan Liu, Ian Mackinnon, Sorin Baltateanu, Petra Poklukar, Gabriel Ibagon, Colin Ji, Hongyang Jiao, Isaac Noble, Wojciech Stokowiec, Zhihao Li, Jeff Dean, David Lindner, Mark Omernick, Kristen Chiafullo, Mason Dimarco, Vitor Rodrigues, Vittorio Selo, Garrett Honke, Xintian Cindy Wu, Wei He, Adam Hillier, Anhad Mohananey, Vihari Piratla, Chang Ye, Chase Malik, Sebastian Riedel, Samuel Albanie, Zi Yang, Kenny Vassigh, Maria Bauza, Sheng Li, Yiqing Tao, Nevan Wichers, Andrii Maksai, Abe Ittycheriah, Ross Mcilroy, Bryan Seybold, Noah Goodman, Romina Datta, Steven M. Hernandez, Tian Shi, Yony Kochinski, Anna Bulanova, Ken Franko, Mikita Sazanovich, Nicholas FitzGerald, Praneeth Kacham, Shubha Srinivas Raghvendra, Vincent Hellendoorn, Alexander Grushetsky, Julian Salazar, Angeliki Lazaridou, Jason Chang, Jan-Thorsten Peter, Sushant Kafle, Yann Dauphin, Abhishek Rao, Filippo Graziano, Izhak Shafran, Yuguo Liao, Tianli Ding, Geng Yan, Grace Chu, Zhao Fu, Vincent Roulet, Gabriel Rasskin, Duncan Williams, Shahar Drath, Alex Mossin, Raphael Hoffmann, Jordi Orbay, Francesco Bertolini, Hila Sheftel, Justin Chiu, Siyang Xue, Yuheng Kuang, Ferjad Naeem, Swaroop Nath, Nana Nti, Phil Culliton, Kashyap Krishnakumar, Michael Isard, Pei Sun, Ayan Chakrabarti, Nathan Clement, Regev Cohen, Arissa Wongpanich, GS Oh, Ashwin Murthy, Hao Zheng, Jessica Hamrick, Oskar Bunyan, Suhas Ganesh, Nitish Gupta, Roy Frostig, John Wieting, Yury Malkov, Pierre Marcenac, Zhixin Lucas Lai, Xiaodan Tang, Mohammad Saleh, Fedir Zubach, Chinmay Kulkarni, Huanjie Zhou, Vicky Zayats, Nan Ding, Anshuman Tripathi, Arijit Pramanik, Patrik Zochbauer, Harish Ganapathy, Vedant Misra, Zach Behrman, Hugo Vallet, Mingyang Zhang, Mukund Sridhar, Ye Jin, Mohammad Babaeizadeh, Siim Põder, Megha Goel, Divya Jain, Tajwar Nasir, Shubham Mittal, Tim Dozat, Diego Ardila, Aliaksei Severyn, Fabio Pardo, Sammy Jerome, Siyang Qin, Louis Rouillard, Amir Yazdanbakhsh, Zizhao Zhang, Shivani Agrawal, Kaushik Shivakumar, Caden Lu, Praveen Kallakuri, Rachita Chhaparia, Kanishka Rao, Charles Kwong, Asya Fadeeva, Shitij Nigam, Yan Virin, Yuan Zhang, Balaji Venkatraman, Beliz Gunel, Marc Wilson, Huiyu Wang, Abhinav Gupta, Xiaowei Xu, Adrien Ali Taïga, Kareem Mohamed, Doug Fritz, Daniel Rodriguez, Zoubin Ghahramani, Harry Askham, Lior Belenki, James Zhao, Rahul Gupta, Krzysztof Jastrzębski, Takahiro Kosakai, Kaan Katircioglu, Jon Schneider, Rina Panigrahy, Konstantinos Bousmalis, Peter Grabowski, Prajit Ramachandran, Chaitra Hegde, Mihaela Rosca, Angelo Scorza Scarpati, Kyriakos Axiotis, Ying Xu, Zach Gleicher, Assaf Hurwitz Michaely, Mandar Sharma, Sanil Jain, Christoph Hirnschall, Tal Marian, Xuhui Jia, Kevin Mather, Kilol Gupta, Linhai Qiu, Nigamaa Nayakanti, Lucian Ionita, Steven Zheng, Lucia Loher, Kurt Shuster, Igor Petrovski, Roshan Sharma, Rahma Chaabouni, Angel Yeh, James An, Arushi Gupta, Steven Schwarcz, Seher Ellis, Sam Conway-Rahman, Javier Snaider, Alex Zhai, James Atwood, Daniel Golovin, Liqian Peng, Te I, Vivian Xia, Salvatore Scellato, Mahan Malihi, Arthur Bražinskas, Vlad-Doru Ion, Younghoon Jun, James Swirhun, Soroosh Mariooryad, Jiao Sun, Steve Chien, Rey Coaguila, Ariel Brand, Yi Gao, Tom Kwiatkowski, Roee Aharoni, Cheng-Chun Lee, Mislav Žanić, Yichi Zhang, Dan Ethier, Vitaly Nikolaev, Pranav Nair, Yoav Ben Shalom, Hen Fitoussi, Jai Gupta, Hongbin Liu, Dee Cattle, Tolga Bolukbasi, Ben Murdoch, Fantine Huot, Yin Li, Chris Hahn* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** Gemini 2.X, 大型语言模型, 多模态, 长上下文, 智能体能力

**Comment:** 72 pages, 17 figures

> **TL;DR:** 本报告介绍了Gemini 2.X系列模型，包括Gemini 2.5 Pro和Flash，它们在推理、多模态、长上下文和智能体能力方面表现卓越，涵盖了性能与成本的最佳平衡，旨在推动复杂智能体问题解决的边界。

**AI_Comments:** 这篇报告展示了Gemini模型家族在推动AI前沿方面的显著进展，特别是在推理、多模态理解和长上下文处理方面的创新。引入“思考模型”概念以及处理3小时视频的能力是其重要亮点。此外，通过提供覆盖不同性能/成本权衡的模型，该系列为用户提供了极大的灵活性，以应对各种复杂的智能体问题，体现了对实际应用需求的深刻理解。

<details>
  <summary>Details</summary>

**Motivation:** 推动AI能力前沿，提供一系列在性能、成本和延迟方面达到最佳平衡的先进模型，以支持复杂的智能体问题解决。

**Method:** 本报告介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro、Gemini 2.5 Flash以及早期的Gemini 2.0 Flash和Flash-Lite模型，并详细描述了它们各自的能力和特点。

**Result:** Gemini 2.5 Pro在编码和推理基准测试中达到最先进（SoTA）性能，拥有卓越的多模态理解能力，能处理长达3小时的视频内容，并结合长上下文、多模态和推理能力解锁新的智能体工作流。Gemini 2.5 Flash以较低的计算和延迟需求提供出色的推理能力。Gemini 2.0 Flash和Flash-Lite在低延迟和成本下提供高性能。

**Conclusion:** Gemini 2.X模型系列涵盖了模型能力与成本的完整帕累托前沿，使用户能够探索复杂智能体问题解决的极限。

> **ai_Abstract:** 本报告介绍了Gemini 2.X系列模型，包括顶级模型Gemini 2.5 Pro和更高效的Gemini 2.5 Flash，以及早期版本。Gemini 2.5 Pro在编码和推理方面表现卓越，达到SoTA水平，并具备强大的多模态理解和长上下文处理能力（支持3小时视频），能够赋能新的智能体工作流。Gemini 2.5 Flash提供高效推理，而Gemini 2.0 Flash和Flash-Lite则在成本和延迟方面表现优异。整个Gemini 2.X系列在模型能力与成本之间实现了全面的帕累托最优，旨在推动复杂智能体问题解决的边界。

> **摘要翻译:** 本报告介绍了Gemini 2.X模型家族：Gemini 2.5 Pro和Gemini 2.5 Flash，以及我们早期的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro是我们迄今为止能力最强的模型，在前沿编码和推理基准测试中取得了最先进的性能。除了其令人难以置信的编码和推理技能外，Gemini 2.5 Pro还是一个擅长多模态理解的“思考”模型，现在能够处理长达3小时的视频内容。其长上下文、多模态和推理能力的独特组合可以解锁新的智能体工作流。Gemini 2.5 Flash以极低的计算和延迟要求提供了出色的推理能力，而Gemini 2.0 Flash和Flash-Lite则在低延迟和成本下提供了高性能。总而言之，Gemini 2.X模型世代涵盖了模型能力与成本的完整帕累托前沿，使用户能够探索复杂智能体问题解决的极限。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [246] [TruthTorchLM: A Comprehensive Library for Predicting Truthfulness in LLM Outputs](https://arxiv.org/abs/2507.08203)
> *TruthTorchLM：一个用于预测大型语言模型输出真实性的综合库*

*Duygu Nur Yaldiz, Yavuz Faruk Bakman, Sungmin Kang, Alperen Öziş, Hayrettin Eren Yildiz, Mitash Ashish Shah, Zhiqi Huang, Anoop Kumar, Alfy Samuel, Daben Liu, Sai Praneeth Karimireddy, Salman Avestimehr* | **Category: cs.CL** | **Updated: 2025-07-10**

**Keywords:** 大型语言模型, 真实性预测, 开源库, TruthTorchLM, 可信赖AI

**Comment:** 

> **TL;DR:** TruthTorchLM是一个开源Python库，提供了30多种用于预测大型语言模型（LLM）输出真实性的方法，旨在加速该领域的研究并提高方法的可及性。

**AI_Comments:** 该论文介绍的TruthTorchLM是一个重要的开源贡献，它解决了LLM在实际应用中面临的关键挑战——输出真实性问题。其创新之处在于提供了一个迄今为止最全面的真实性预测方法集合，并且兼容主流的LLM框架，大大降低了研究人员和开发者在该领域进行实验和部署的门槛。统一的接口和可扩展的框架设计也确保了其长期可用性和适应性。这对于推动LLM的可靠性和信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）不可避免地会产生不真实的响应，尤其是在高风险场景下，准确预测这些输出的真实性至关重要。为了加速该领域的研究并使真实性预测方法更易于访问，作者提出了TruthTorchLM。

**Method:** 作者介绍了TruthTorchLM，这是一个开源、综合性的Python库，包含了30多种真实性预测方法（称为“真实方法”）。该库与HuggingFace和LiteLLM无缝兼容，支持本地托管和基于API的模型。它还提供了一个统一的接口，用于生成、评估、校准和长篇真实性预测，以及一个灵活的框架，用于扩展新方法。这些方法涵盖了计算成本、访问级别（如黑盒与白盒）、接地文档要求和监督类型（自监督或监督）等方面的权衡。

**Result:** 作者在TriviaQA、GSM8K和FactScore-Bio三个数据集上对代表性的真实性方法进行了评估。

**Conclusion:** TruthTorchLM旨在加速大型语言模型真实性预测领域的研究，并通过提供一个全面、易于访问且可扩展的开源库，使各种真实性预测方法更易于使用。

> **ai_Abstract:** TruthTorchLM是一个开源Python库，旨在解决大型语言模型输出不真实的问题。它提供了一个包含30多种真实性预测方法的综合集合，这些方法在计算成本、访问级别和监督类型等方面具有多样性。该库兼容HuggingFace和LiteLLM，并提供统一的生成、评估和校准接口。通过提供这样一个工具，TruthTorchLM旨在加速LLM真实性研究并提高相关方法的可及性。该库已在多个数据集上进行了评估。

> **摘要翻译:** 生成式大型语言模型（LLM）不可避免地会产生不真实的响应。准确预测这些输出的真实性至关重要，尤其是在高风险环境下。为了加速该领域的研究并使真实性预测方法更易于访问，我们引入了TruthTorchLM，这是一个开源、综合性的Python库，拥有30多种真实性预测方法，我们称之为真实方法。与现有工具包（例如Guardrails，它只专注于文档接地验证，或LM-Polygraph，它仅限于基于不确定性的方法）不同，TruthTorchLM提供了一个广泛且可扩展的技术集合。这些方法涵盖了计算成本、访问级别（例如黑盒与白盒）、接地文档要求和监督类型（自监督或监督）等方面的不同权衡。TruthTorchLM与HuggingFace和LiteLLM无缝兼容，支持本地托管和基于API的模型。它还提供了一个统一的生成、评估、校准和长篇真实性预测接口，以及一个灵活的框架，用于通过新方法扩展库。我们对三个数据集（TriviaQA、GSM8K和FactScore-Bio）上的代表性真实性方法进行了评估。代码可在https://github.com/Ybakman/TruthTorchLM获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [250] [A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](https://arxiv.org/abs/2507.08621)
> *基于LLM的论证分类综合研究：从LLAMA到GPT-4o再到Deepseek-R1*

*Marcin Pietroń, Rafał Olszowski, Jakub Gomułka, Filip Gampel, Andrzej Tomski* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 论证分类, 大型语言模型, GPT-4o, Deepseek-R1, 思维链

**Comment:** 

> **TL;DR:** 本研究对多种大型语言模型（LLM）在公开论证分类数据库上的表现进行了全面评估，发现GPT-4o表现最佳，而结合推理能力的Deepseek-R1表现出色，但所有模型仍存在错误。

**AI_Comments:** 本研究的创新之处在于首次对多个主流LLM（包括GPT-4o和Deepseek-R1）在公共论证分类数据集上的表现进行了全面而系统的比较分析，并结合了思维链等推理增强算法。其重要性在于揭示了当前LLM在论证分类任务中的优势与局限性，特别是指出了现有提示算法的不足和数据集的缺陷，为未来的研究和模型改进提供了宝贵的见解和明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）显著提升了论证分析的效率，但目前仍缺乏关于这些模型在公开论证分类数据库中操作的研究和结果。

**Method:** 本研究选择了一系列大型语言模型，包括GPT、Llama和DeepSeek的不同版本，以及结合了思维链（Chain-of-Thoughts）算法的推理增强变体。这些模型在Args.me和UKP等多样化数据集上进行了测试。

**Result:** 结果表明，ChatGPT-4o在论证分类基准测试中表现优于其他模型。在结合推理能力的模型中，Deepseek-R1展现出其优越性。然而，尽管GPT-4o和Deepseek-R1表现出色，它们仍然会犯错误，并且论文讨论了所有模型最常见的错误类型。

**Conclusion:** 本研究首次对使用LLM和提示算法分析现有论证数据集进行了更广泛的分析。工作揭示了已知提示算法在论证分析中的一些弱点，并指出了改进方向。此外，该研究还深入分析了可用的论证数据集并展示了它们的不足之处。

> **ai_Abstract:** 本研究全面评估了多种大型语言模型（LLMs），包括GPT、Llama和DeepSeek系列及其思维链增强变体，在Args.me和UKP等公共论证分类数据集上的表现。研究旨在弥补LLMs在该领域应用研究的不足。结果显示，ChatGPT-4o在论证分类任务中表现最佳，而Deepseek-R1在结合推理能力后表现出色。尽管LLMs表现优异，但仍存在常见错误。本研究是首次对此类数据集进行广泛的LLM和提示算法分析，揭示了现有提示算法的局限性，并为未来改进提供了方向，同时深入分析了数据集本身的不足。

> **摘要翻译:** 论证挖掘（AM）是一个跨学科研究领域，融合了逻辑学、哲学、语言学、修辞学、法律、心理学和计算机科学的见解。它涉及自动识别和提取论证成分，如前提和主张，以及检测它们之间的关系，如支持、攻击或中立。最近，该领域取得了显著进展，特别是随着大型语言模型（LLMs）的出现，与传统方法和其他深度学习模型相比，LLMs增强了分析和提取论证语义的效率。目前有许多基准用于测试和验证LLM的质量，但仍缺乏关于这些模型在公开论证分类数据库中操作的研究和结果。本文对选定的大型语言模型进行了研究，使用了Args.me和UKP等多样化数据集。测试的模型包括GPT、Llama和DeepSeek的版本，以及结合了思维链算法的推理增强变体。结果表明，ChatGPT-4o在论证分类基准测试中表现优于其他模型。在结合推理能力的模型中，Deepseek-R1展现出其优越性。然而，尽管它们表现出色，GPT-4o和Deepseek-R1仍然会犯错误。论文讨论了所有模型最常见的错误。据我们所知，本研究是首次对上述数据集使用LLM和提示算法进行更广泛的分析。该工作还揭示了已知提示算法在论证分析中的一些弱点，同时指出了改进方向。该工作的附加价值在于对可用论证数据集的深入分析以及对它们不足之处的展示。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [252] [Truth-value judgment in language models: 'truth directions' are context sensitive](https://arxiv.org/abs/2404.18865)
> *语言模型中的真值判断：“真理方向”是上下文敏感的*

*Stefan F. Schouten, Peter Bloem, Ilia Markov, Piek Vossen* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 语言模型, 真值判断, 上下文敏感性, 探针, 因果中介

**Comment:** COLM 2025

> **TL;DR:** 语言模型中发现的“真理方向”受上下文影响，且这种影响可能不总是合理的，但它们在上下文推理中起因果中介作用。

**AI_Comments:** 这项研究深入探讨了LLM内部“真理方向”的复杂性，揭示了其上下文敏感性以及在推理过程中的因果作用。其创新之处在于通过一致性错误和因果干预实验量化了上下文对真值判断的影响，并指出了其局限性（不合理敏感）。这对于理解LLM的内部机制及其“知识”表示具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最近的工作表明大型语言模型（LLMs）的潜在空间中包含能够预测句子真值的“方向”，并利用探针来揭示模型的“知识”或“信念”。本文旨在深入探究上下文对这些真值探针的影响。

**Method:** 通过测量LLM在输入包含假设以及（否定）支持和矛盾句子时，探针预测中出现的一致性错误。同时进行因果干预实验，研究沿真值方向移动前提的表示是否会影响蕴含或矛盾句子沿相同方向的位置。

**Result:** 测试的探针通常是上下文敏感的；不应影响真值的上下文常常仍然影响探针输出；错误类型取决于层、模型和数据类型；真值方向是整合上下文信息的推理过程中的因果中介。

**Conclusion:** 真值方向在语言模型中是上下文敏感的，并且在处理上下文信息时扮演着因果中介的角色，但其敏感性有时可能导致不一致的输出。

> **ai_Abstract:** 本文研究了大型语言模型中用于判断句子真值的“真理方向”如何受上下文影响。通过测量一致性错误和进行因果干预实验，研究发现这些真理探针普遍对上下文敏感，即使在不应影响真值的情况下亦然。研究还指出错误类型因模型层、模型和数据而异，并提出真理方向在模型整合上下文信息的推理过程中起到因果中介作用。

> **摘要翻译:** 最近的研究表明，大型语言模型（LLM）的潜在空间中包含能够预测句子真值的方向。多种方法能够恢复这些方向并构建探针，这些探针被描述为揭示了模型的“知识”或“信念”。我们研究了这种现象，密切关注上下文对探针的影响。我们的实验确定了LLM中探针的预测在何处（最）敏感于相关句子的存在，以及如何最好地描述这种敏感性。我们通过测量在探测输入包含由（否定）支持和矛盾句子引导的假设的LLM后发生的不同类型的一致性错误来做到这一点。我们还进行了一项因果干预实验，调查沿着这些真值方向移动前提的表示是否会影响一个蕴含或矛盾句沿着相同方向的位置。我们发现我们测试的探针通常是上下文敏感的，但那些不应该影响真值的上下文常常仍然影响探针的输出。我们的实验表明，错误的类型取决于层、模型和数据类型。最后，我们的结果表明，真值方向是整合上下文信息的推理过程中的因果中介。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [264] [Extracting memorized pieces of (copyrighted) books from open-weight language models](https://arxiv.org/abs/2505.12546)
> *从开源语言模型中提取（受版权保护）书籍的记忆片段*

*A. Feder Cooper, Aaron Gokaslan, Ahmed Ahmed, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, Percy Liang* | **Category: cs.CL, cs.CY, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 语言模型记忆, 版权, 数据提取, 开源LLMs, Books3数据集

**Comment:** 

> **TL;DR:** 研究发现，开源语言模型确实会记忆受版权保护的书籍内容，但记忆程度因模型和书籍而异，对版权诉讼有重要影响。

**AI_Comments:** 本研究通过实证方法量化了开源LLMs对受版权保护内容的记忆程度，为当前关于生成式AI版权侵权的法律辩论提供了关键证据。其创新之处在于利用概率提取技术揭示模型内部的“复制”行为，并指出记忆的复杂性和不确定性。研究结果表明，简单的“是”或“否”的判断无法概括LLMs的记忆行为，这对未来版权案件的判决具有深远影响。特别指出Llama 3.1 70B对特定书籍的近乎完美记忆是重要的发现，提示了模型训练数据和架构可能带来的潜在风险。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI的版权诉讼中，原告和被告对大型语言模型（LLMs）记忆受保护内容的程度存在严重对立的说法，本研究旨在揭示记忆与版权之间被过度简化的关系。

**Method:** 利用一种近期提出的概率提取技术，从17个开源LLMs中提取Books3数据集中的书籍片段，并进行大量实验。

**Result:** 实验表明，可以从不同的LLMs中提取出至少部分书籍的大量内容，证明LLMs确实记忆了这些文本。然而，记忆程度因模型和书籍而异。最大的LLMs并未记忆大部分书籍，但Llama 3.1 70B几乎完全记忆了《哈利·波特与魔法石》和《1984》等书籍，甚至可以通过首句提示词近乎逐字生成整本书。

**Conclusion:** 研究结果对版权案件具有重要意义，但并不明确偏向任何一方。

> **ai_Abstract:** 本研究旨在调查大型语言模型（LLMs）对受版权保护书籍内容的记忆程度，以回应当前生成式AI版权诉讼中的争议。研究采用概率提取技术，从17个开源LLMs中提取Books3数据集中的文本。结果显示，LLMs确实会记忆并复制书籍内容，且记忆程度因模型和书籍而异。尽管大型LLMs通常不记忆大部分书籍，但特定模型如Llama 3.1 70B能几乎完全记忆某些知名书籍。这些发现对理解LLM记忆机制及其在版权法领域的应用具有重要启示。

> **摘要翻译:** 生成式AI的版权诉讼中，原告和被告经常就大型语言模型（LLMs）记忆原告受保护表达的程度提出广泛而对立的主张。我们借鉴对抗性机器学习和版权法，表明这些两极分化的立场极大地简化了记忆与版权之间的关系。为此，我们利用近期的一种概率提取技术，从17个开源LLMs中提取了Books3数据集的片段。通过大量实验，我们发现可以从不同的LLMs中提取出至少部分书籍的大量内容。这证明这些LLMs已经记忆了提取的文本；这些记忆的内容被复制在模型参数内部。但结果是复杂的：记忆的程度因模型和书籍而异。在我们的具体实验中，我们发现最大的LLMs并没有记忆大部分书籍——无论是全部还是部分。然而，我们也发现Llama 3.1 70B几乎完全记忆了一些书籍，例如《哈利·波特与魔法石》和《1984》。事实上，《哈利·波特》被记忆得如此之深，以至于只需使用第一章第一行的种子提示词，我们就能近乎逐字地确定性地生成整本书。我们讨论了为什么我们的结果对版权案件具有重要影响，尽管这些影响并非明确偏向任何一方。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [276] [KAT-V1: Kwai-AutoThink Technical Report](https://arxiv.org/abs/2507.08297)
> *KAT-V1: 快手自动思考技术报告*

*Zizheng Zhan, Ken Deng, Huaixi Tang, Wen Xiang, Kun Wu, Weihao Li, Wenqiang Zhu, Jingxuan Xu, Lecheng Huang, Zongxian Feng, Shaojie Wang, Shangpeng Yan, Jiaheng Liu, Zhongyuan Peng, Zuchen Gao, Haoyang Huang, Ziqi Zhan, Yanan Wu, Yuanxing Zhang, Jian Yang, Guang Chen, Haotian Zhang, Bin Chen, Bing Yu* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大语言模型, 自动思考, 推理任务, 知识蒸馏, 强化学习

**Comment:** 

> **TL;DR:** KAT-V1是一个开源的40B大语言模型，通过动态切换推理和非推理模式来解决推理任务中的过度思考问题，它采用新的训练范式并结合多种技术，实现了SOTA性能和高达30%的token使用量减少，并已成功部署。

**AI_Comments:** 这项工作提出了一种新颖的“自动思考”训练范式，通过动态模式切换来解决LLM在推理任务中的“过度思考”问题，这对于提高效率和性能具有重要意义。其结合了数据集构建、知识蒸馏、冷启动策略和强化学习等多种技术，并展示了在实际应用中的成功部署和良好的可扩展性，具有较高的创新性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决推理密集型任务中的“过度思考”问题。

**Method:** 提出了一种自动思考训练范式，根据任务复杂性动态切换推理和非推理模式。具体方法包括：1. 构建基于新颖标注流程和多智能体合成策略的双机制数据集。2. 应用MTP增强的知识蒸馏，实现高效且细粒度的推理迁移。3. 实施冷启动初始化策略，利用多数投票信号和意图感知提示引入模式选择先验。4. 提出Step-SRPO强化学习算法，将中间监督整合到GRPO框架中，为推理模式选择和响应准确性提供结构化指导。

**Result:** KAT在多个基准测试中始终与当前最先进的模型（包括DeepSeek-R1-0528和Qwen3-235B-A22B）持平甚至超越。将token使用量减少了约30%。已成功部署在Kwaipilot（快手内部编程助手），提高了实际开发工作流程的准确性、效率和可控推理行为。正在训练的200B MoE模型（40B激活参数）的早期结果显示出性能和效率的显著提升，进一步证明了AutoThink范式的可扩展性。

**Conclusion:** KAT-V1通过其自动思考范式有效解决了推理任务中的过度思考问题，实现了最先进的性能和效率，并展示了强大的实际应用能力和可扩展性。

> **ai_Abstract:** KAT-V1是一个开源的40B大语言模型，旨在解决推理密集型任务中的过度思考问题。它提出了一种自动思考训练范式，能够根据任务复杂性动态切换推理和非推理模式。该模型通过构建双机制数据集、应用MTP增强的知识蒸馏、冷启动初始化策略以及Step-SRPO强化学习算法进行训练。实验证明，KAT-V1在多项基准测试中达到了或超越了现有SOTA模型，并将令牌使用量减少了约30%。此外，KAT-V1已成功部署于快手内部的编程助手Kwaipilot，在实际应用中展现出高准确性、效率和可控性，并且其范式在MoE模型上显示出良好的可扩展性。

> **摘要翻译:** 我们提出了 Kwaipilot-AutoThink (KAT)，一个开源的 40B 大语言模型，旨在解决推理密集型任务中的“过度思考”问题。为此，我们提出了一种自动思考训练范式，根据任务复杂性在推理和非推理模式之间动态切换。具体来说，首先，我们基于新颖的标注流程和多智能体合成策略构建了双机制数据集；然后，我们应用了多令牌预测（MTP）增强的知识蒸馏，以最小的预训练成本实现高效和细粒度的推理迁移。此外，我们还实现了一种冷启动初始化策略，利用多数投票信号和意图感知提示引入模式选择先验。最后，我们提出了 Step-SRPO，一种将中间监督整合到 GRPO 框架中的强化学习算法，为推理模式选择和响应准确性提供结构化指导。在多个基准上的大量实验表明，KAT 在各种推理密集型任务中始终与当前最先进的模型（包括 DeepSeek-R1-0528 和 Qwen3-235B-A22B）持平甚至超越，同时将令牌使用量减少了约 30%。除了学术评估之外，KAT 已成功部署在 Kwaipilot（即快手内部的编程助手）中，并通过高准确性、高效率和可控的推理行为改进了实际开发工作流程。此外，我们正在积极训练一个包含 40B 激活参数的 200B 专家混合（MoE）模型，其早期阶段的结果已经显示出性能和效率方面的有希望的改进，进一步展示了 AutoThink 范式的可扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [277] [Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection](https://arxiv.org/abs/2411.01077)
> *表情符号攻击：增强针对判别型大型语言模型检测的越狱攻击*

*Zhipeng Wei, Yuqi Liu, N. Benjamin Erichson* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 越狱攻击, 大型语言模型, 判别型LLM, 表情符号攻击, 标记分割偏差

**Comment:** 

> **TL;DR:** 提出一种“表情符号攻击”，通过利用判别型LLM的token分割偏差，在提示中插入表情符号，有效降低了它们检测有害内容的准确率，从而绕过安全防护。

**AI_Comments:** 这篇论文通过揭示判别型LLM在标记化过程中的漏洞（标记分割偏差）并利用表情符号的特性（嵌入失真和语义歧义）来增强越狱攻击，具有创新性。它强调了当前LLM安全防御的脆弱性，对LLM安全研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 判别型LLM被用作防御手段来评估生成文本的有害性，但研究发现它们容易受到token分割偏差的影响，这会降低其检测准确性，使有害内容被错误分类为安全，因此需要一种方法来利用这种漏洞。

**Method:** 引入“表情符号攻击”，通过利用token分割偏差来增强现有越狱提示。该方法利用上下文学习，在文本被判别型LLM评估之前系统地插入表情符号。这会引起嵌入失真并引入语义歧义，从而显著降低检测不安全内容的可能性。

**Result:** 通过对最先进的判别型LLM进行实验，证明表情符号攻击显著降低了不安全内容的预测率，从而绕过了现有安全防护。

**Conclusion:** 表情符号攻击是一种有效的方法，可以利用判别型LLM的token分割偏差和语义歧义，成功绕过其对有害内容的检测，凸显了当前LLM安全防御的脆弱性。

> **ai_Abstract:** 本文提出了“表情符号攻击”，一种新颖的越狱策略，旨在规避判别型LLM对有害内容的检测。该攻击利用判别型LLM的标记分割偏差，通过在提示中系统地插入表情符号来扭曲文本嵌入并引入语义歧义。实验证明，这种方法能有效降低判别型LLM对不安全内容的预测准确性，成功绕过现有安全机制。

> **摘要翻译:** 越狱技术诱骗大型语言模型（LLM）生成受限输出，构成潜在威胁。一种防御措施是使用另一个LLM作为判断者来评估生成文本的有害性。然而，我们发现这些判断型LLM容易受到标记分割偏差的影响，当分隔符改变标记化过程，将单词分割成更小的子标记时，就会出现这个问题。这会改变整个序列的嵌入，降低检测准确性，并导致有害内容被错误地归类为安全。在本文中，我们引入了表情符号攻击，这是一种利用标记分割偏差来增强现有越狱提示的新策略。我们的方法利用上下文学习，在文本被判断型LLM评估之前系统地插入表情符号，从而引起嵌入失真，显著降低检测不安全内容的可能性。与传统分隔符不同，表情符号还引入了语义歧义，这使得它们在本次攻击中特别有效。通过对最先进的判断型LLM进行的实验，我们证明表情符号攻击显著降低了不安全预测率，绕过了现有防护措施。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [283] [CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation](https://arxiv.org/abs/2507.08325)
> *CRMAgent：一个用于电子商务CRM消息模板生成的多智能体LLM系统*

*Yinzhu Quan, Xinrui Li, Ying Chen* | **Category: cs.CL, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 多智能体系统, 大型语言模型, 电子商务, CRM, 消息模板生成

**Comment:** 

> **TL;DR:** CRMAgent是一个基于LLM的多智能体系统，旨在帮助电商商家生成高质量的CRM消息模板，以提高客户留存和转化。

**AI_Comments:** CRMAgent的创新之处在于其结合了多智能体LLM架构与多策略学习机制（包括从现有成功案例学习、检索适应和规则回退），有效解决了电商CRM中个性化消息生成难题。该系统为商家提供了可扩展的工具，有望显著提升客户留存和转化率，对于私域流量运营具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数电商商家在撰写有说服力的CRM消息方面面临困难，因为他们缺乏专业知识和可扩展的工具，而这对于客户关系管理中的客户留存和转化至关重要。

**Method:** CRMAgent是一个基于大型语言模型（LLMs）的多智能体系统，通过三种互补模式生成高质量消息模板和写作指导：1. 基于群组学习：从商家自身在相同受众群体中表现最佳的消息中学习，并重写低表现消息。2. 检索与适应：检索与当前活动具有相同受众群体、凭证类型和产品类别高度相似的成功模板，学习其模式并进行适应。3. 基于规则的后备：在没有合适参考时提供轻量级的零样本重写。

**Result:** 广泛的实验表明，CRMAgent始终优于商家原始模板，在受众匹配度和营销效率指标上均实现了显著提升。

**Conclusion:** CRMAgent成功解决了电子商务CRM消息模板生成中的挑战，通过其多智能体LLM系统和多模式策略，显著提升了消息的质量和营销效果。

> **ai_Abstract:** CRMAgent是一个创新的多智能体LLM系统，旨在解决电商商家在撰写高效CRM消息模板方面的痛点。该系统结合了群组学习、检索与适应以及规则后备三种策略，能够根据特定受众和营销目标生成高质量且有说服力的消息模板和写作指导。实验证明，CRMAgent在提升消息的受众匹配度和营销效率方面显著优于商家现有的模板。

> **摘要翻译:** 在即时通讯和电子邮件等电子商务私域渠道中，商家直接与客户互动，作为其客户关系管理（CRM）计划的一部分，以提高客户留存和转化。虽然少数顶级商家擅长撰写外发消息，但大多数商家由于缺乏专业知识和可扩展工具，难以撰写有说服力的文案。我们引入了CRMAgent，这是一个基于大型语言模型（LLMs）的多智能体系统，通过三种互补模式生成高质量的消息模板和可操作的写作指导。首先，基于群组的学习使智能体能够从商家自身在相同受众群体中表现最佳的消息中学习，并重写表现不佳的消息。其次，检索与适应功能获取与当前活动具有相同受众群体、凭证类型和产品类别高度相似的模板，学习它们的成功模式并进行适应。第三，当没有合适的参考时，基于规则的后备方案提供轻量级的零样本重写。大量实验表明，CRMAgent始终优于商家原始模板，在受众匹配度和营销效率指标上均实现了显著提升。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [290] [Multilingual Multimodal Software Developer for Code Generation](https://arxiv.org/abs/2507.08719)
> *多语言多模态软件开发者用于代码生成*

*Linzheng Chai, Jian Yang, Shukai Liu, Wei Zhang, Liran Wang, Ke Jin, Tao Sun, Congnan Liu, Chenchen Zhang, Hualei Zhu, Jiaheng Liu, Xianjie Wu, Ge Zhang, Tianyu Liu, Zhoujun Li* | **Category: cs.CL, cs.AI, cs.SE** | **Updated: 2025-07-11**

**Keywords:** 多模态代码生成, 大型语言模型, 视觉工作流, UML图, 流程图, MMc-Instruct, MMEval

**Comment:** Preprint

> **TL;DR:** MM-Coder是一个多语言多模态模型，结合文本和视觉输入（如UML图和流程图）来改进代码生成，并引入了新的数据集MMc-Instruct和评估基准MMEval。

**AI_Comments:** 这项工作通过引入视觉模态到代码生成任务中，并构建相应的数据集和评估基准，为多模态软件开发领域做出了重要贡献。它指出了现有模型在理解复杂视觉信息方面的不足，为未来研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 弥合现有大型语言模型在代码生成中忽略视觉辅助信息（如图表）的不足，使其更能适应真实世界软件开发。

**Method:** 引入MM-Coder多语言多模态软件开发者模型，整合视觉设计输入（UML图和流程图）与文本指令。为此，构建了MMc-Instruct数据集，包含基于视觉工作流的代码生成指令。此外，提出了MMEval新的多模态代码生成评估基准。

**Result:** 使用MMEval进行的评估显示，模型在精确捕获视觉信息、遵循指令和掌握高级编程知识方面仍存在显著挑战。

**Conclusion:** 通过使大型语言模型能够解释和实现通过文本和视觉设计传达的复杂规范，本工作旨在彻底改变工业编程。

> **ai_Abstract:** 本文提出了MM-Coder，一个多语言多模态模型，用于结合文本指令和视觉输入（如UML图和流程图）进行代码生成。为了训练和评估MM-Coder，作者构建了MMc-Instruct数据集和MMEval评估基准。研究发现，尽管取得了进展，模型在处理视觉信息和高级编程任务方面仍面临挑战。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展显著改善了代码生成，然而大多数模型仍仅限于文本，忽略了真实世界软件开发中使用的关键视觉辅助工具，如图表和流程图。为了弥合这一差距，我们引入了MM-Coder，一个多语言多模态软件开发者。MM-Coder整合了视觉设计输入——统一建模语言（UML）图和流程图（称为视觉工作流）——与文本指令，以提高代码生成的准确性和架构一致性。为此，我们开发了MMc-Instruct，一个多样化的多模态指令微调数据集，包括基于视觉工作流的代码生成，使MM-Coder能够像人类开发者一样合成文本和图形信息，这与之前针对狭窄任务的工作不同。此外，我们引入了MMEval，一个新的评估多模态代码生成的基准，解决了现有仅限文本的局限性。我们使用MMEval进行的评估突显了模型在精确捕获视觉信息、遵循指令和掌握高级编程知识方面仍然存在的显著挑战。我们的工作旨在通过使LLMs能够解释和实现通过文本和视觉设计传达的复杂规范，从而彻底改变工业编程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [Exploring Design of Multi-Agent LLM Dialogues for Research Ideation](https://arxiv.org/abs/2507.08350)
> *探索多智能体大型语言模型对话在研究构思中的设计*

*Keisuke Ueda, Wataru Hirota, Takuto Asakura, Takahiro Omi, Kosuke Takahashi, Kosuke Arima, Tatsuya Ishigaki* | **Category: cs.CL, cs.MA, I.2.11; I.2.7** | **Updated: 2025-07-11**

**Keywords:** 多智能体LLM, 研究构思, 对话设计, 想法新颖性, 想法可行性

**Comment:** 16 pages, 1 figure, appendix. Accepted to SIGDIAL 2025

> **TL;DR:** 本研究分析了多智能体大型语言模型对话的不同配置，以优化研究构思中的想法新颖性和可行性，发现增加智能体数量、对话深度和角色多样性可以提高想法多样性，而增加评论方的多样性则能提升最终提案的可行性。

**AI_Comments:** 这项研究通过系统地探索多智能体LLM对话的不同设计维度，为优化LLM在创意任务中的应用提供了宝贵的见解。其创新点在于不仅验证了多智能体交互的有效性，更进一步细化了影响效果的关键因素，特别是强调了批判方多样性对想法可行性的提升作用，这对于未来开发更智能、更实用的LLM辅助创意工具具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地被用于支持创意任务，如研究想法生成。尽管最近的工作表明LLMs之间的结构化对话可以提高生成想法的新颖性和可行性，但这种交互的最佳设计仍不清楚。

**Method:** 本研究对用于科学构思的多智能体LLM对话进行了全面分析。通过比较代理角色、代理数量和对话深度的不同配置，来理解这些因素如何影响生成想法的新颖性和可行性。实验设置包括一个代理生成想法，另一个代理进行批判，从而实现迭代改进。

**Result:** 结果显示，扩大智能体群、加深交互深度以及拓宽智能体角色异质性都能丰富生成想法的多样性。此外，在构思-批判-修订循环中，专门增加批判方的多样性，能进一步提高最终提案的可行性。

**Conclusion:** 本研究的发现为构建有效的多智能体LLM科学构思系统提供了实用指南。

> **ai_Abstract:** 本研究探讨了多智能体大型语言模型对话在研究构思中的设计优化。通过比较不同配置（包括智能体角色、数量和对话深度），研究发现扩大智能体群、加深交互深度和增加角色异质性可丰富想法多样性。尤其，在构思-批判-修订循环中增加批判方的多样性，能显著提升最终提案的可行性。这些发现为构建高效的多智能体LLM科学构思系统提供了实践指导。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地被用于支持创意任务，例如研究想法生成。尽管最近的工作表明LLMs之间的结构化对话可以提高生成想法的新颖性和可行性，但这种交互的最佳设计仍不清楚。在本研究中，我们对用于科学构思的多智能体LLM对话进行了全面分析。我们比较了代理角色、代理数量和对话深度的不同配置，以了解这些因素如何影响生成想法的新颖性和可行性。我们的实验设置包括一个代理生成想法，另一个代理批判它们，从而实现迭代改进。我们的结果显示，扩大智能体群、加深交互深度以及拓宽智能体角色异质性都能丰富生成想法的多样性。此外，在构思-批判-修订循环中，专门增加批判方的多样性，能进一步提高最终提案的可行性。我们的发现为构建有效的多智能体LLM科学构思系统提供了实用指南。我们的代码可在https://github.com/g6000/MultiAgent-Research-Ideator 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [302] [EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees](https://arxiv.org/abs/2503.08893)
> *EvalTree：通过分层能力树分析语言模型弱点*

*Zhiyuan Zeng, Yizhong Wang, Hannaneh Hajishirzi, Pang Wei Koh* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 语言模型评估, 弱点分析, 能力树, EvalTree, 数据收集

**Comment:** COLM 2025

> **TL;DR:** 本文提出了EvalTree，一种通过构建分层能力树来识别语言模型弱点的方法，并在多个基准测试中证明其优于基线方法，并能指导数据收集以提升模型性能。

**AI_Comments:** EvalTree提出了一种新颖且实用的语言模型评估范式，超越了传统的单一指标评估，通过构建可解释的能力树，实现了对模型弱点的精细化定位。其创新性在于将模型评估与改进指导紧密结合，并证明了弱点引导的数据收集对模型性能提升的有效性，这对于大模型的迭代优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 理想的模型评估应能识别模型失败之处并提供可操作的改进指导。为此，本文旨在解决为语言模型生成弱点画像的问题。

**Method:** 本文提出了EvalTree方法，它通过构建一个分层能力树，其中每个节点代表一个自然语言描述的能力并链接到评估该能力的基准实例子集，然后提取语言模型表现不佳的节点来生成弱点画像。

**Result:** EvalTree在MATH和WildChat基准测试中，比基线弱点分析方法更精确和全面地识别了弱点。由EvalTree识别的弱点指导的数据收集比其他数据收集策略更能提升语言模型性能。EvalTree还揭示了Chatbot Arena中基于人类投票的评估实践的缺陷。

**Conclusion:** EvalTree是一种有效的语言模型弱点分析方法，它不仅能精确识别模型不足，还能指导数据收集以提升模型性能，并暴露现有评估方法的缺陷。

> **ai_Abstract:** 本文提出了一种名为EvalTree的语言模型弱点分析方法。该方法通过构建分层能力树，将自然语言描述的能力与基准测试实例关联起来，从而精确识别模型在哪些方面表现不佳，并生成弱点画像。实验证明，EvalTree在弱点识别的精确性和全面性上优于现有基线方法，并且能够有效指导数据收集以提升模型性能。此外，EvalTree还揭示了现有评估实践中的不足。

> **摘要翻译:** 理想的模型评估应达到两个目标：识别模型失败之处并提供可操作的改进指导。为了实现语言模型（LM）评估的这些目标，我们提出了一个问题：如何在给定语言模型在基准测试中每个独立实例上的表现后，生成一个用自然语言表达的弱点集合，即弱点画像。我们引入了一套定量评估方法来比较不同的弱点画像生成方法。我们还引入了一种弱点画像生成方法EvalTree。EvalTree构建了一个能力树，其中每个节点代表一个用自然语言描述的能力，并链接到专门评估该能力的基准实例子集；然后它提取语言模型表现不佳的节点来生成弱点画像。在MATH和WildChat基准测试中，我们展示了EvalTree通过更精确和全面地识别弱点，优于基线弱点画像生成方法。弱点画像进一步支持弱点引导的数据收集，并且由EvalTree识别的弱点指导的训练数据收集比其他数据收集策略更能提升语言模型性能。我们还展示了EvalTree如何揭示Chatbot Arena中基于人类投票的评估实践的缺陷。为了促进未来的工作，我们提供了一个接口，允许实践者交互式地探索EvalTree构建的能力树。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [306] [MK2 at PBIG Competition: A Prompt Generation Solution](https://arxiv.org/abs/2507.08335)
> *MK2 在 PBIG 竞赛中的表现：一种提示生成解决方案*

*Yuzheng Xu, Tosho Hirasawa, Seiya Kawano, Shota Kato, Tadashi Kozuno* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 专利创意生成, 提示工程, 大型语言模型, PBIG竞赛, 产品创意

**Comment:** 9 pages, to appear in the 2nd Workshop on Agent AI for Scenario
  Planning (AGENTSCEN 2025)

> **TL;DR:** MK2是一个基于提示工程的管道，利用Gemini 2.5和GPT-4.1将专利转化为产品创意，并在PBIG竞赛中表现出色，无需额外训练数据。

**AI_Comments:** MK2的创新之处在于其纯粹基于提示工程的解决方案，无需额外训练数据，通过多模型协作（Gemini 2.5生成提示、GPT-4.1生成创意、Qwen3-8B评估）实现了高效且具竞争力的专利创意生成。其在大多数测试中取得的优异成绩凸显了大型语言模型在创意生成方面的潜力。局限性在于在特定领域（如材料化学）表现不佳，表明深度领域知识对复杂任务的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 专利启发式创意生成任务要求系统将真实专利转化为三年内可行的产品创意。

**Method:** 本文提出了MK2，一个以提示为中心的管道：Gemini 2.5负责起草并迭代编辑提示，通过嫁接来自较弱输出的有用片段来优化提示；GPT-4.1利用此优化后的提示为每个专利创建一个产品创意；最后，通过Qwen3-8B判断的Elo循环来选择最佳提示。整个过程无需额外训练数据。

**Result:** MK2在三个领域、两种评估器类型和六个标准下，位居自动排行榜榜首，并赢得了36项测试中的25项。仅在材料化学领域的表现滞后，这表明需要更深入的领域基础。

**Conclusion:** 结果表明，轻量级提示工程已经能够从专利中提供具有竞争力且与商业相关的创意。

> **ai_Abstract:** 本文提出了MK2，一个用于专利启发式创意生成的提示工程解决方案。该方案利用Gemini 2.5迭代生成和优化提示，随后由GPT-4.1根据优化后的提示生成产品创意，并通过Qwen3-8B进行评估选择。MK2在PBIG竞赛中表现出色，无需额外训练数据，证明了轻量级提示工程在商业相关创意生成方面的有效性，尽管在特定领域仍有提升空间。

> **摘要翻译:** 专利启发式创意生成任务要求系统将真实专利转化为三年内可行的产品创意。我们提出了MK2，一个以提示为中心的管道：Gemini 2.5起草并迭代编辑提示，从较弱的输出中嫁接有用片段；然后GPT-4.1使用此提示为每个专利创建一个创意，并通过Qwen3-8B判断的Elo循环选择最佳提示——所有这些都无需额外训练数据。在三个领域、两种评估器类型和六个标准下，MK2在自动排行榜上名列前茅，并赢得了36项测试中的25项。只有材料化学领域的表现滞后，这表明需要更深入的领域基础；然而，结果表明轻量级提示工程已经能够从专利中提供具有竞争力且与商业相关的创意。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [315] [KELPS: A Framework for Verified Multi-Language Autoformalization via Semantic-Syntactic Alignment](https://arxiv.org/abs/2507.08665)
> *KELPS：一种通过语义-句法对齐实现多语言自动形式化验证的框架*

*Jiyao Zhang, Chengli Zhong, Hui Xu, Qige Li, Yi Zhou* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 自动形式化, 神经符号, 知识方程, 多语言, 形式化验证

**Comment:** Accepted by the ICML 2025 AI4MATH Workshop. 22 pages, 16 figures, 2
  tables

> **TL;DR:** KELPS是一个神经符号框架，通过将非正式数学转化为多语言形式化语言并生成大量数据集，提高了自动形式化的准确性，超越了现有模型。

**AI_Comments:** KELPS的创新之处在于其神经符号方法和引入的“知识方程”作为中间表示，这有效弥补了纯LLM在形式化数学方面对高质量并行语料的依赖。其多语言支持和生成大规模验证语料库的能力，对推动机器辅助数学证明领域的发展具有重要意义。该框架在准确性上超越了SOTA模型，展示了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型语言模型在形式化非正式数学方面面临多语言并行语料库数量和质量有限的瓶颈。

**Method:** 提出KELPS（Knowledge-Equation based Logical Processing System）框架。这是一个迭代框架，用于将非正式数据翻译、合成和过滤成多种形式语言（Lean、Coq和Isabelle）。首先将自然语言翻译成作者设计的、基于断言逻辑的“知识方程”（KEs），然后通过严格定义的规则将其转换为目标语言，同时保留句法结构和语义意义。

**Result:** 该过程产生了超过60,000个问题的并行语料库。该框架在MiniF2F上实现了88.9%的句法准确率（pass@1），优于SOTA模型如Deepseek-V3（81%）和Herald（81.3%）。

**Conclusion:** KELPS框架通过其新颖的神经符号方法和语义-句法对齐机制，显著提高了多语言自动形式化的准确性和效率，成功克服了现有LLM在形式化非正式数学方面的局限性。

> **ai_Abstract:** KELPS是一个针对LLM在数学自动形式化中语料库限制问题而设计的神经符号框架。它通过将自然语言转化为自创的知识方程，并进一步转换为Lean、Coq、Isabelle等多种形式语言，同时保持语义和句法一致性。该框架成功构建了一个包含6万多问题的并行语料库，并在MiniF2F数据集上取得了88.9%的句法准确率，性能超越了现有最先进模型。

> **摘要翻译:** 现代大型语言模型（LLMs）在将非正式数学形式化为机器可验证定理方面显示出可喜的进展。然而，由于多语言并行语料库数量和质量的限制，这些方法仍面临瓶颈。在本文中，我们提出了一种新颖的神经符号框架 KELPS（基于知识方程的逻辑处理系统）来解决这些问题。KELPS 是一个迭代框架，用于将非正式数据翻译、合成和过滤成多种形式语言（Lean、Coq 和 Isabelle）。首先，我们将自然语言翻译成知识方程（KEs），这是一种我们设计的、理论上基于断言逻辑的新颖语言。接下来，我们通过严格定义的规则将它们转换为目标语言，这些规则保留了句法结构和语义意义。这个过程产生了一个包含超过60,000个问题的并行语料库。我们的框架在 MiniF2F 上实现了 88.9% 的句法准确率（pass@1），在多个数据集上优于 SOTA 模型，如 Deepseek-V3（81%）和 Herald（81.3%）。所有数据集和代码均在补充材料中提供。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [317] [Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models](https://arxiv.org/abs/2507.07505)
> *幻觉站：关于基于Transformer的语言模型的一些基本局限性*

*Varin Sikka, Vishal Sikka* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** Transformer, 语言模型, 幻觉, 计算复杂性, 代理任务

**Comment:** 6 pages; to be submitted to AAAI-26 after reviews

> **TL;DR:** 本文探讨了基于Transformer的语言模型（LLMs）的基本局限性，特别是在处理超出特定复杂度的计算和代理任务以及验证信息准确性方面的能力不足。

**AI_Comments:** 这篇论文通过从计算复杂性的角度深入探讨了LLMs的局限性，特别是在处理“幻觉”和代理任务方面的不足，提供了一个重要的理论视角。其创新之处在于将LLM的能力边界与计算复杂性挂钩，这对于理解当前LLMs的根本限制及其未来发展方向具有重要指导意义。论文强调了LLMs在复杂任务验证和执行方面的固有缺陷，这对于LLMs在关键应用场景中的部署提供了重要的警示。

<details>
  <summary>Details</summary>

**Motivation:** 随着基于Transformer的语言模型在人工智能中的广泛应用，人们对其能力极限，特别是“幻觉”现象（即LLMs提供虚假、不准确或无意义信息）以及LLMs的代理用途（即使用LLMs创建自主或半自主代理来执行任务）产生了浓厚兴趣。因此，理解LLMs能和不能执行的任务类型变得非常重要。

**Method:** 作者从LLM推理的计算复杂性角度探讨了这个问题。他们通过展示LLMs无法执行超出特定复杂度的计算和代理任务，也无法验证超出特定复杂度的任务准确性来证明其观点，并提供了相关示例。

**Result:** 研究表明，LLMs无法执行超出特定复杂度的计算和代理任务。此外，LLMs也无法验证超出特定复杂度的任务准确性。文中提供了这两种情况的示例。

**Conclusion:** 基于Transformer的语言模型在执行超出特定复杂度的计算和代理任务以及验证信息准确性方面存在基本局限性。这对于LLMs在现实世界应用中的能力和局限性具有重要意义。

> **ai_Abstract:** 本文探讨了基于Transformer的语言模型（LLMs）在处理复杂任务时的基本局限性。研究从计算复杂性角度分析，指出LLMs无法执行超出特定复杂度的计算和代理任务，也无法验证超出该复杂度的信息准确性。文章通过示例阐述了这些限制，并讨论了其潜在影响，强调了理解LLMs能力边界的重要性。

> **摘要翻译:** 随着基于Transformer的语言模型在人工智能中的广泛应用，人们对其能力极限，特别是所谓的“幻觉”现象（即LLM在某些主题上被提示时提供虚假、事实不正确或无意义的信息）产生了浓厚兴趣。此外，人们对LLM的代理用途也越来越感兴趣——也就是说，使用LLM创建自主或半自主代理来执行各种任务，包括在现实世界中应用的任务。这使得理解LLM能和不能执行的任务类型变得很重要。我们从LLM推理的计算复杂性的角度探讨了这个问题。我们表明LLM无法执行超出特定复杂度的计算和代理任务，并且LLM也无法验证超出特定复杂度的任务的准确性。我们提供了这两种情况的示例，然后讨论了这项工作的一些后果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [318] [Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences](https://arxiv.org/abs/2507.08440)
> *寻找共同点：使用大型语言模型在多智能体决策会议中检测共识*

*Selina Heller, Mohamed Ibrahim, David Antony Selby, Sebastian Vollmer* | **Category: cs.CL, cs.AI, cs.MA** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 多智能体系统, 决策会议, 共识检测, 姿态检测

**Comment:** 

> **TL;DR:** LLM多智能体系统可有效模拟决策会议并检测参与者间的共识，提高讨论效率和决策质量。

**AI_Comments:** 本文创新性地将LLM应用于模拟决策会议中的共识检测，提出了一个新型的多智能体系统。其重要性在于证明了LLM在复杂群体交互中识别共识的潜力，并为提高决策会议效率和质量提供了新的工具。该研究为LLM在社会科学和决策支持领域的应用开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 决策会议需要达成共识，而LLM在模拟真实世界场景和多智能体交互方面显示出潜力，因此研究其在决策会议中检测共识的能力。

**Method:** 本文提出一个基于LLM的新型多智能体系统，用于模拟决策会议，专注于检测参与智能体之间的共识。评估了六个不同的LLM在姿态检测（识别立场）和姿态极性检测（识别情感）任务上的表现，并在多智能体系统中评估其有效性。

**Result:** 结果表明，LLM即使在动态细致的辩论中也能可靠地检测共识。在系统中加入共识检测智能体可以提高小组辩论效率，增强审议的整体质量和连贯性，使其结果和决策与真实世界决策会议相当。

**Conclusion:** 基于LLM的多智能体系统有潜力模拟群体决策过程，并在专家启发式研讨会中支持决策。

> **ai_Abstract:** 本文提出一种基于大型语言模型（LLM）的新型多智能体系统，旨在模拟决策会议并检测参与智能体之间的共识。研究评估了六个LLM在姿态检测和姿态极性检测任务上的表现，并在多智能体系统中测试其有效性。结果表明，LLM能可靠检测共识，且引入共识检测智能体可提升辩论效率和决策质量，使模拟决策与真实会议效果相当。这展示了LLM多智能体系统在模拟群体决策和支持专家决策方面的潜力。

> **摘要翻译:** 决策会议是结构化的协作会议，汇集了来自不同领域的专家，以解决复杂问题并就未来的行动或政策建议达成共识。这些会议通常依赖于促进性讨论，以确保富有成效的对话和集体协议。最近，大型语言模型（LLM）在模拟真实世界场景方面显示出巨大的前景，特别是通过模仿群体互动的协作多智能体系统。在这项工作中，我们提出了一种新颖的基于LLM的多智能体系统，旨在模拟决策会议，特别侧重于检测参与智能体之间的共识。为了实现这一目标，我们评估了六个不同的LLM在两个任务上的表现：姿态检测（识别智能体对给定问题的立场）和姿态极性检测（识别情感为积极、消极或中性）。这些模型在多智能体系统中进一步评估，以确定其在复杂模拟中的有效性。我们的结果表明，LLM即使在动态和细致的辩论中也能可靠地检测共识。在系统中加入共识检测智能体还可以提高小组辩论的效率，并增强审议的整体质量和连贯性，使其在结果和决策方面与真实世界的决策会议相媲美。这些发现证明了基于LLM的多智能体系统模拟群体决策过程的潜力。它们还强调了此类系统在支持跨领域专家启发式研讨会决策方面的作用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [332] [Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations](https://arxiv.org/abs/2503.13857)
> *实现包容性系统评价：整合预印本文章与大型语言模型驱动的评估*

*Rui Yang, Jiayi Tong, Haoyuan Wang, Hui Huang, Ziyang Hu, Peiyu Li, Nan Liu, Christopher J. Lindsell, Michael J. Pencina, Yong Chen, Chuan Hong* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 预印本文章, 系统评价, 大型语言模型, 发表预测, 自然语言处理

**Comment:** 30 pages, 6 figures

> **TL;DR:** 本研究提出了AutoConfidence框架，利用大型语言模型（LLMs）和自然语言处理（NLP）技术评估预印本的发表可能性，以期更高效地将预印本纳入系统评价。

**AI_Comments:** 本文的创新之处在于整合了大型语言模型和自然语言处理技术，实现了预印本质量的自动化评估，这解决了系统评价中的一个关键瓶颈。结合不同类型的特征（LLM分数、语义嵌入、使用指标）以及先进的模型（生存治愈模型）也值得关注。这种方法有望显著简化证据综合过程，提高系统评价的效率和包容性。

<details>
  <summary>Details</summary>

**Motivation:** 系统评价在比较效果研究中需要及时获取证据，而预印本虽然加速了知识传播，但质量参差不齐，给系统评价带来了挑战。本研究旨在通过自动化评估减少人工筛选的依赖，扩大预测因子范围，从而更有效地整合预印本。

**Method:** 本研究提出了AutoConfidence（自动化置信度评估）框架，用于预测预印本的发表，该框架减少了对人工筛选的依赖，并扩展了预测因子范围，包括三项关键进展：(1) 使用自然语言处理技术进行自动化数据提取，(2) 标题和摘要的语义嵌入，以及(3) 大型语言模型（LLM）驱动的评估分数。此外，研究采用了两种预测模型：用于二元结果的随机森林分类器和预测二元结果及随时间变化的发表风险的生存治愈模型。

**Result:** 随机森林分类器在使用LLM驱动分数时AUROC达到0.692，加入语义嵌入后提高到0.733，加入文章使用指标后提高到0.747。生存治愈模型在使用LLM驱动分数时AUROC达到0.716，加入语义嵌入后提高到0.731。对于发表风险预测，该模型的一致性指数达到0.658，加入语义嵌入后提高到0.667。

**Conclusion:** 本研究通过自动化数据提取和多特征集成（包括语义嵌入与LLM驱动的评估）推进了预印本发表预测框架。AutoConfidence在提高预测性能的同时，减少了人工标注负担。该框架有望促进预印本文章在系统评价评估阶段的纳入，支持研究人员更有效地利用预印本资源。

> **ai_Abstract:** AutoConfidence是一个新颖的框架，旨在预测预印本的发表状态，以促进其纳入系统评价。它利用自然语言处理进行自动化数据提取、语义嵌入和大型语言模型驱动的评估分数。通过使用随机森林和生存治愈模型，该框架展示了改进的预测性能，特别是在结合语义嵌入和LLM评估时，从而减少了预印本评估所需的人工工作量。这使得系统评价能够更高效和更具包容性。

> **摘要翻译:** 背景。比较效果研究中的系统评价需要及时进行证据综合。预印本加速了知识传播，但质量各异，给系统评价带来了挑战。
方法。我们提出了AutoConfidence（自动化置信度评估），一个预测预印本发表的高级框架，它减少了对人工筛选的依赖，并扩展了预测因子范围，包括三项关键进展：(1) 使用自然语言处理技术进行自动化数据提取，(2) 标题和摘要的语义嵌入，以及(3) 大型语言模型（LLM）驱动的评估分数。此外，我们采用了两种预测模型：用于二元结果的随机森林分类器和预测二元结果及随时间变化的发表风险的生存治愈模型。
结果。随机森林分类器在使用LLM驱动分数时AUROC达到0.692，加入语义嵌入后提高到0.733，加入文章使用指标后提高到0.747。生存治愈模型在使用LLM驱动分数时AUROC达到0.716，加入语义嵌入后提高到0.731。对于发表风险预测，它的一致性指数达到0.658，加入语义嵌入后提高到0.667。
结论。我们的研究通过自动化数据提取和多特征集成，推进了预印本发表预测框架。通过将语义嵌入与LLM驱动的评估相结合，AutoConfidence在提高预测性能的同时，减少了人工标注负担。该框架有可能促进预印本文章在系统评价评估阶段的纳入，支持研究人员更有效地利用预印本资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [334] [Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation](https://arxiv.org/abs/2410.05401)
> *使用大型语言模型对社交媒体广告中气候微定向的后验研究：主题洞察与公平性评估*

*Tunazzina Islam, Dan Goldwasser* | **Category: cs.CL, cs.AI, cs.CY, cs.SI** | **Updated: 2025-07-10**

**Keywords:** 气候微定向, 大型语言模型, 社交媒体广告, 公平性评估, 主题分析

**Comment:** 

> **TL;DR:** 本研究利用大型语言模型对社交媒体广告中的气候微定向策略进行后验分析，评估其在预测人口统计目标方面的准确性并揭示主题元素，同时进行公平性分析以识别模型偏见。

**AI_Comments:** 该研究创新性地将大型语言模型应用于气候微定向广告的后验分析，不仅验证了LLMs在识别和解释目标受众方面的能力，更重要的是，它揭示了现有微定向策略中的性别和年龄偏见。通过提供可解释性，该研究为未来更透明、公平的社交媒体气候宣传活动提供了重要见解和方法论框架，对于促进数字伦理和负责任的AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于社交媒体上气候变化传播越来越多地采用微定向策略以有效触达并影响特定人群，本研究旨在对气候宣传活动中的微定向实践进行后验分析。

**Method:** 本研究利用大型语言模型（LLMs）对Facebook广告进行后验分析，重点关注人口统计定向和公平性。研究评估了LLMs准确预测预期人口统计目标（如性别和年龄组）的能力，并指示LLMs生成分类解释以揭示不同人口群体所使用的特定主题元素。此外，还进行了全面的公平性分析，以识别模型预测中潜在的偏见。

**Result:** LLMs在预测人口统计目标方面取得了88.55%的总体准确率。LLMs生成的解释揭示了针对不同人口群体的不同策略：年轻成人主要通过强调行动主义和环境意识的信息进行定向；女性则通过与照护角色和社会倡导相关的主题进行吸引。研究发现，尽管LLMs总体表现良好，但在对老年人和男性受众的分类中存在特定偏见。

**Conclusion:** 本研究展示了LLMs在剖析和解释目标沟通策略方面的有效性，并强调了公平性问题，为未来旨在提高社交媒体驱动的气候宣传活动透明度、问责制和包容性的研究提供了有价值的框架。

> **ai_Abstract:** 本研究利用大型语言模型（LLMs）对社交媒体气候广告中的微定向策略进行后验分析，重点关注人口统计定向和公平性。研究发现LLMs能以88.55%的准确率预测目标人群，并能生成解释揭示不同主题如何吸引特定群体（如年轻成人侧重行动主义，女性侧重照护）。同时，研究也发现了LLMs在对老年人和男性受众分类时存在的偏见。本研究为提高气候宣传活动的透明度、问责制和包容性提供了新的研究框架。

> **摘要翻译:** 社交媒体上的气候变化传播越来越多地采用微定向策略，以有效触达并影响特定人口群体。本研究利用大型语言模型（LLMs）审查Facebook广告，对气候宣传活动中的微定向实践进行后验分析。我们的分析侧重于两个关键方面：人口统计定向和公平性。我们评估了LLMs准确预测预期人口统计目标（如性别和年龄组）的能力，实现了88.55%的总体准确率。此外，我们指示LLMs为其分类生成解释，为每个决策提供透明的推理。这些解释揭示了用于吸引不同人口群体的特定主题元素，突出了针对不同受众量身定制的独特策略。我们的发现表明，年轻成人主要通过强调行动主义和环境意识的信息进行定向，而女性则通过与照护角色和社会倡导相关的主题进行吸引。除了评估LLMs在检测微定向信息方面的有效性外，我们还进行了全面的公平性分析，以识别模型预测中潜在的偏见。我们的发现表明，尽管LLMs总体表现良好，但存在某些偏见，特别是在对老年人和男性受众的分类中。通过展示LLMs在剖析和解释目标沟通策略方面的功效，并强调公平性问题，本研究为未来旨在提高社交媒体驱动的气候宣传活动透明度、问责制和包容性的研究提供了有价值的框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [336] [Distillation versus Contrastive Learning: How to Train Your Rerankers](https://arxiv.org/abs/2507.08336)
> *蒸馏学习对比对比学习：如何训练你的重排序器*

*Zhichao Xu, Zhiqi Huang, Shengyao Zhuang, Ashim Gupta, Vivek Srikumar* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-11**

**Keywords:** 知识蒸馏, 对比学习, 文本重排序器, 信息检索, 教师模型

**Comment:** 

> **TL;DR:** 本文经验性地比较了知识蒸馏和对比学习在训练文本重排序器上的效果，发现当有更大的教师模型时，知识蒸馏通常表现更好，否则对比学习是可靠的替代方案。

**AI_Comments:** 本文通过实证比较，清晰地阐明了知识蒸馏和对比学习在训练文本重排序器时的适用场景和相对优势。其重要性在于为从业者提供了实用的指导，特别是在资源（如教师模型）有限或不同的情况下，如何选择最优的训练策略。研究结果具有较强的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在信息检索中，训练文本重排序器至关重要。目前主要有两种策略：对比学习和知识蒸馏。然而，在实际条件下，对于训练跨编码器重排序器，这两种策略的有效性缺乏清晰的比较。

**Method:** 本文通过在相同数据上使用两种方法训练不同大小和架构的重排序器，并以一个强大的对比学习模型作为蒸馏教师，来经验性地比较了这两种策略。

**Result:** 研究结果表明，当从更大的教师模型进行蒸馏时，知识蒸馏在域内和域外排序性能上通常优于对比学习，并且这一发现适用于不同大小和架构的学生模型。然而，从相同容量的教师模型进行蒸馏并没有提供相同的优势，尤其是在域外任务中。

**Conclusion:** 如果可以获得更大、更强大的教师模型，建议使用知识蒸馏来训练更小的重排序器；否则，对比学习是一个强大且更可靠的替代方案。这些发现为根据可用教师模型选择训练策略提供了实用指导。

> **ai_Abstract:** 本文经验性地比较了知识蒸馏和对比学习这两种主要策略在训练文本重排序器上的有效性。研究发现，当从一个更大的教师模型进行蒸馏时，知识蒸馏在域内和域外排序性能上通常优于对比学习，并且该优势在不同学生模型大小和架构上保持一致。然而，从相同容量的教师模型蒸馏则不具备此优势。因此，作者建议在有强大教师模型时优先选择知识蒸馏，否则对比学习是一个可靠的选择，为实际训练策略提供了指导。

> **摘要翻译:** 训练文本重排序器对于信息检索至关重要。两种主要策略被广泛使用：对比学习（直接优化地面真实标签）和知识蒸馏（从更大的重排序器转移知识）。虽然两者都在文献中有所研究，但在实际条件下，需要对它们在训练跨编码器重排序器方面的有效性进行清晰的比较。
本文通过在相同数据上使用这两种方法训练不同大小和架构的重排序器，并以一个强大的对比学习模型作为蒸馏教师，来经验性地比较了这些策略。我们的结果表明，当从更大的教师模型进行蒸馏时，知识蒸馏在域内和域外排序性能上通常优于对比学习。这一发现适用于不同学生模型的大小和架构。然而，从相同容量的教师模型进行蒸馏并没有提供相同的优势，尤其是在域外任务中。这些发现为根据可用教师模型选择训练策略提供了实用指导。因此，如果可以获得更大、更强大的教师模型，我们建议使用知识蒸馏来训练更小的重排序器；否则，对比学习是一个强大且更可靠的替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [349] [RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning](https://arxiv.org/abs/2507.08012)
> *RepeaTTS：通过重复微调实现特征发现*

*Atli Sigurgeirsson, Simon King* | **Category: cs.CL, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-05**

**Keywords:** 文本到语音, 微调, 特征发现, 主成分分析, 可控性

**Comment:** 

> **TL;DR:** RepeaTTS通过重复微调和主成分分析，发现并控制文本到语音模型中未受控的语音特征，提升模型可控性。

**AI_Comments:** 该论文提出了一种创新的方法来解决基于提示的TTS模型中特征控制不足和不可控变异的问题。其核心创新在于利用模型固有的“不可控”变异性，通过PCA发现隐藏的潜在特征，并将其转化为可控的标签进行二次微调。这种“变废为宝”的思路非常有意思，为TTS模型更精细的控制提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于提示的文本到语音模型虽然用户友好，但存在局限性：控制仅限于训练期间暴露的声学特征，同时相同的输入会产生不可控的变异，影响语料库统计。

**Method:** 通过利用模型不可控的变异性，研究一种新颖的微调机制。具体方法是对数千个合成样本进行主成分分析，确定解释输出方差最高比例的潜在特征，并将其作为新标签进行二次微调。

**Result:** 在没有情感披露的模型上，该方法产生了连续和离散的特征，提高了模型的整体可控性。

**Conclusion:** 通过重复微调和特征发现，可以有效提高文本到语音模型的可控性，尤其是在处理模型中未被明确暴露的特征方面。

> **ai_Abstract:** 本文提出RepeaTTS，一种通过重复微调来发现文本到语音模型中潜在特征的新方法。针对现有提示式TTS模型在特征控制上的局限性和变异性问题，作者利用模型不可控的变异性，通过主成分分析识别出主要的潜在特征，并将其作为新标签进行二次微调。实验证明，该方法在没有情感披露的模型上，能够发现连续和离散特征，显著提升了模型的整体可控性。

> **摘要翻译:** 基于提示的文本到语音模型允许用户通过自然语言指令控制语音的不同方面，例如语速和感知性别。尽管用户友好，但此类方法一方面受到限制：控制仅限于训练期间暴露给模型的声学特征；另一方面又过于灵活：相同的输入会产生不可控的变异，并反映在语料库统计中。
我们研究了一种新颖的微调机制，通过利用模型不可控的变异性，同时解决这两个问题。通过对数千个合成样本进行主成分分析，我们确定了占输出方差最高比例的潜在特征，并将其作为新标签用于二次微调。我们在两个在富有表现力的冰岛语语音语料库上训练的模型上评估了所提出的方法，一个带有情感披露，一个没有。在没有情感披露的模型案例中，该方法产生了连续和离散的特征，提高了模型的整体可控性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [358] [Multi-Token Attention](https://arxiv.org/abs/2504.00927)
> *多令牌注意力*

*Olga Golovneva, Tianlu Wang, Jason Weston, Sainbayar Sukhbaatar* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 多令牌注意力, 大型语言模型, 软注意力, 卷积, 长文本

**Comment:** 

> **TL;DR:** 一种新的注意力机制（MTA）通过卷积利用多个令牌而非单个令牌来决定注意力权重，提高了大型语言模型的性能，尤其是在长文本场景下。

**AI_Comments:** 利用卷积将多令牌信息融入注意力机制是解决标准自注意局限性的一种创新方法。结果表明，该方法在提高大型语言模型性能方面具有巨大潜力，特别是在处理长序列时。

<details>
  <summary>Details</summary>

**Motivation:** 当前的软注意力机制依赖于单个查询和键令牌的相似性，这限制了用于区分相关上下文的信息量。本文旨在解决这种“单令牌注意力”的瓶颈问题。

**Method:** 提出了一种多令牌注意力（MTA）的新方法，它允许大型语言模型同时基于多个查询和键向量来确定注意力权重。这通过对查询、键和注意力头应用卷积操作来实现。

**Result:** 在 SQuAD 2.0、TriviaQA 等一系列流行的基准测试中取得了增强的性能。在标准语言建模任务以及需要在长上下文中搜索信息的任务上，其性能优于 Transformer 基线模型。

**Conclusion:** MTA 通过利用卷积的多令牌信息有效解决了单令牌注意力的局限性，从而提高了性能，尤其是在长文本场景下。

> **ai_Abstract:** 本文介绍了一种新的大型语言模型注意力机制——多令牌注意力（MTA），它超越了单令牌相似性的限制。通过对查询、键和注意力头应用卷积，MTA 整合了多个相邻令牌的信息来确定注意力权重，从而能够利用更丰富的上下文信息。评估结果表明，MTA 在语言建模和长文本任务上的性能优于 Transformer 基线模型。

> **摘要翻译:** 软注意力是驱动大型语言模型定位给定上下文中相关部分的关键机制。然而，单个注意力权重仅由单个查询和键令牌向量的相似性决定。这种“单令牌注意力”限制了用于区分相关部分与其余上下文的信息量。为了解决这个问题，我们提出了一种新的注意力方法，多令牌注意力（MTA），它允许大型语言模型同时基于多个查询和键向量来确定其注意力权重。这通过对查询、键和注意力头应用卷积操作来实现，使得附近的查询和键能够相互影响其注意力权重，从而实现更精确的注意力。因此，我们的方法可以使用比单个向量容量更丰富、更细微的信息来定位相关上下文。通过广泛的评估，我们证明了 MTA 在一系列流行的基准测试中取得了增强的性能。值得注意的是，在标准语言建模任务以及需要在长上下文中搜索信息的任务上，其性能优于 Transformer 基线模型，在这些任务中，我们方法利用更丰富信息的能力被证明特别有益。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [368] [KG-Attention: Knowledge Graph-Guided Attention at Test-Time via Bidirectional Information Aggregation](https://arxiv.org/abs/2507.08704)
> *KG-Attention：通过双向信息聚合在测试时进行知识图谱引导的注意力机制*

*Songlin Zhai, Guilin Qi, Yuan Meng* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 知识图谱, 大型语言模型, 注意力机制, 测试时学习, 知识融合

**Comment:** 

> **TL;DR:** KG-Attention是一种新的测试时知识图谱增强LLMs的框架，通过双向聚合动态融合知识，无需参数更新，解决了现有方法的灾难性遗忘和适应性差问题。

**AI_Comments:** KG-Attention的创新之处在于其“测试时”和“无需参数更新”的知识融合机制，这有效避免了传统微调带来的灾难性遗忘问题，并提高了模型对实时知识更新的适应性。其双向聚合（向外和向内）的闭环设计是其核心亮点，展示了在不修改预训练模型参数的情况下增强LLMs知识能力的新范式，对于LLMs的实际应用和持续学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识图谱增强大型语言模型（LLMs）的方法大多依赖参数密集型微调，这可能导致灾难性遗忘并损害预训练模型的泛化能力。此外，由于其静态集成框架，这些方法对实时知识更新的适应性有限。

**Method:** 本文提出了KG-Attention，一个在测试时增强LLMs的知识图谱引导注意力（KGA）模块。KGA通过两种协同路径增强了标准的自注意力机制：向外聚合和向内聚合。向外路径通过输入驱动的KG融合将外部知识动态整合到输入表示中；向内路径通过KG引导的过滤来细化输入表示，抑制不相关信号并放大相关模式。向内路径还会选择最相关的三元组并反馈给融合过程，形成闭环增强机制，无需参数修改即可支持实时知识融合。

**Result:** 在五个基准测试上的广泛实验验证了KGA具有可比较的知识融合性能。

**Conclusion:** KG-Attention提供了一种无需参数更新的、动态且适应性强的知识图谱增强大型语言模型的方法，有效解决了传统方法的局限性。

> **ai_Abstract:** 本研究提出KG-Attention，一个用于大型语言模型（LLMs）的测试时知识图谱增强框架。该框架引入了知识图谱引导注意力（KGA）模块，通过向外和向内两种协同聚合路径，实现动态知识融合而无需参数更新，解决了现有方法在灾难性遗忘和实时知识更新适应性方面的局限。实验结果表明KGA在知识融合方面表现出可比性能。

> **摘要翻译:** 知识图谱（KGs）通过将结构化和基础知识引入学习过程，在增强大型语言模型（LLMs）方面发挥着关键作用。然而，大多数现有的KG增强方法依赖于参数密集型微调，这可能会导致灾难性遗忘并降低预训练模型的泛化能力。此外，由于其静态集成框架，它们对实时知识更新的适应性有限。为了解决这些问题，我们引入了第一个用于LLMs的测试时KG增强框架，该框架围绕一个专用的知识图谱引导注意力（KGA）模块构建，该模块能够在不进行任何参数更新的情况下实现动态知识融合。所提出的KGA模块通过两种协同路径增强了标准的自注意力机制：向外聚合和向内聚合。具体来说，向外路径通过输入驱动的KG融合将外部知识动态整合到输入表示中。这种向内聚合通过KG引导的过滤来补充向外路径，从而细化输入表示，抑制与任务无关的信号并放大与知识相关的模式。重要的是，虽然向外路径处理知识融合，但向内路径选择最相关的三元组并将其反馈到融合过程中，形成一个闭环增强机制。通过协同结合这两种路径，所提出的方法仅在测试时支持实时知识融合，无需任何参数修改。在五个基准测试上的广泛实验验证了KGA具有可比较的知识融合性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [370] [What Factors Affect LLMs and RLLMs in Financial Question Answering?](https://arxiv.org/abs/2507.08339)
> *什么因素影响LLMs和RLLMs在金融问答中的表现？*

*Peng Wang, Xuesi Hu, Jiageng Wu, Yuntao Zou, Qiancheng Zhang, Dagang Li* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 推理大型语言模型, 金融问答, 提示工程, 代理框架

**Comment:** Preprint

> **TL;DR:** 本研究系统地探讨了提示方法、代理框架和多语言对齐方法对LLMs和RLLMs在金融问答任务中的影响，发现LLMs可以通过模拟长链思维提升性能，而RLLMs因其固有的长链思维能力，传统方法对其性能提升有限。

**AI_Comments:** 该研究首次系统性地探讨了不同方法对LLMs和RLLMs在特定领域（金融问答）性能的影响，填补了现有研究的空白。其创新之处在于区分了LLMs和RLLMs对不同优化策略（如提示、代理框架、多语言对齐）的响应差异，特别指出了RLLMs因其固有的长链思维能力，传统方法对其提升有限。这为未来针对RLLMs的优化提供了新的研究方向，即可能需要更针对性的方法来进一步提升其性能。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）和推理大型语言模型（RLLMs）发展迅速，但在金融领域，目前鲜有研究系统地探索何种方法能充分发挥其性能。

**Method:** 研究利用五种LLMs和三种RLLMs，评估了提示方法、代理框架以及多语言对齐方法对金融问答任务的影响。

**Result:** 1) 当前的提示方法和代理框架通过模拟长链思维提升了LLMs在金融问答中的性能；2) RLLMs具备固有的长链思维能力，这限制了传统方法进一步提升其性能的有效性；3) 当前先进的多语言对齐方法主要通过延长推理长度来提高LLMs的多语言性能，但对RLLMs的益处甚微。

**Conclusion:** 本研究希望为LLMs和RLLMs在金融问答领域提供重要参考。

> **ai_Abstract:** 本研究系统性地探究了不同方法对大型语言模型（LLMs）和推理大型语言模型（RLLMs）在金融问答任务中表现的影响。通过评估提示方法、代理框架和多语言对齐方法，研究发现这些方法能通过模拟长链思维提升LLMs的性能，但由于RLLMs本身已具备长链思维能力，传统方法对其性能提升效果有限。多语言对齐方法主要通过延长推理长度改善LLMs的多语言表现，对RLLMs的助益较小。该研究旨在为金融问答领域的LLMs和RLLMs应用提供指导。

> **摘要翻译:** 最近，大型语言模型（LLMs）和推理大型语言模型（RLLMs）的发展受到了许多研究人员的广泛关注。RLLMs通过长链思维（Long CoT）过程增强了LLMs的推理能力，显著提高了LLMs在解决复杂问题时的性能。然而，目前很少有工作系统地探索哪些方法可以充分释放LLMs和RLLMs在金融领域的性能。为了调查各种方法对LLMs和RLLMs的影响，我们利用五种LLMs和三种RLLMs来评估提示方法、代理框架和多语言对齐方法对金融问答任务的影响。我们的研究结果表明：(1) 当前的提示方法和代理框架通过模拟长链思维提升了LLMs在金融问答中的性能；(2) RLLMs拥有固有的长链思维能力，这限制了传统方法进一步提升其性能的有效性；(3) 当前先进的多语言对齐方法主要通过延长推理长度来提高LLMs的多语言性能，这为RLLMs带来的益处微乎其微。我们希望这项研究能为LLMs和RLLMs在金融问答领域提供重要参考。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [373] [UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations](https://arxiv.org/abs/2507.07030)
> *UniConv：统一检索与响应生成，用于大型语言模型在对话中的应用*

*Fengran Mo, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, Zheng Li, Xian Li, Bing Yin, Meng Jiang* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-09**

**Keywords:** 对话搜索, 统一模型, 检索生成, 大型语言模型, UniConv

**Comment:** Accepted by ACL 2025 (main)

> **TL;DR:** UniConv统一了对话系统中的检索和响应生成，通过联合微调和减少不一致性风险的机制，在对话搜索任务上优于现有方法。

**AI_Comments:** 该研究有效地解决了对话搜索系统中检索和生成分离的问题，提出了一种新颖的统一模型UniConv。通过联合微调和专门设计的机制来处理不一致性和数据差异，该方法在多个数据集上取得了优于现有方法的成果，展示了其在提升对话系统性能方面的潜力。然而，关于模型的可扩展性以及在更广泛的对话场景中的泛化能力还需要进一步的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的对话搜索系统通常使用两个独立的模型，这限制了模型同时利用内在知识以及确保检索有效性以利于生成的潜力。现有的统一模型未能充分解决理解对话上下文、独立管理检索和生成响应等问题。

**Method:** 通过联合微调不同的目标来统一大型语言模型在对话中的密集检索和响应生成，并设计了两种机制来降低不一致性风险并减轻数据差异。

**Result:** 在五个对话搜索数据集上的评估表明，UniConv模型能够相互促进检索和生成任务，并且优于现有的基线模型。

**Conclusion:** UniConv成功地统一了检索和响应生成，并通过联合微调和减少不一致性风险的机制，实现了对现有方法的超越，证明了其在对话搜索任务中的有效性。

> **ai_Abstract:** 本文提出UniConv，一种统一了检索和响应生成的大型语言模型方法，用于对话搜索。通过联合微调和特定的机制来解决现有方法的局限性，该模型在多个数据集上均表现优于现有基线。

> **摘要翻译:** 对话搜索系统的快速发展通过实现用户与系统之间的多轮交互，革新了信息访问的方式。现有的对话搜索系统通常由两个不同的模型构建。这种分离限制了系统同时利用模型的内在知识的能力，也无法确保检索对生成有效的效益。现有开发统一模型的研究未能充分解决理解对话上下文、独立管理检索以及生成响应等方面的问题。在本文中，我们探讨了如何统一大型语言模型在对话中的密集检索和响应生成。我们进行了具有不同目标的联合微调，并设计了两种机制来降低不一致性风险，同时减轻数据差异。在五个对话搜索数据集上的评估表明，我们的统一模型能够相互促进两个任务，并且优于现有的基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [374] [GeistBERT: Breathing Life into German NLP](https://arxiv.org/abs/2506.11903)
> *德语自然语言处理新篇章：GeistBERT*

*Raphael Scheible-Schmitt, Johann Frei* | **Category: cs.CL** | **Updated: 2025-07-10**

**Keywords:** GeistBERT, 德语NLP, Transformer模型, 预训练, State-of-the-art

**Comment:** 

> **TL;DR:** GeistBERT是一个为德语NLP优化的模型，通过在包含1.3TB数据的多样化语料库上进行增量预训练，并在多个下游任务上进行了微调，取得了优异的性能，特别是在GermEval 2018细粒度文本分类任务上达到了新的state-of-the-art（SOTA）水平，并已根据MIT协议发布以支持德语NLP研究。

**AI_Comments:** 该研究介绍了GeistBERT，一个为德语NLP优化的Transformer模型。研究亮点在于其在大型多样化德语语料库上的预训练以及在多个基准任务上的优异表现，特别是达到了新的SOTA水平。模型的发布将有助于推动德语NLP领域的发展。然而，文中未提及模型在处理不同口音或方言方面的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 德语自然语言处理（NLP）受益于针对德语语言特性定制的更新模型架构和现代数据集，以发挥语言特定预训练的优势。

**Method:** 使用fairseq框架，以RoBERTa-base配置和全词掩码（WWM）为基础，从GottBERT权重初始化，在1.3TB的德语语料库上进行增量预训练。模型采用了动态掩码和512个固定序列长度。在NER、文本分类和NLI等标准下游任务上进行了微调和评估。

**Result:** GeistBERT在所有评估任务上均表现出色，在基础模型中处于领先地位，并在GermEval 2018细粒度文本分类任务上创下新的state-of-the-art（SOTA）记录。它还优于一些较大的模型，尤其是在分类基准测试中。

**Conclusion:** GeistBERT通过在多样化的德语语料库上进行预训练和优化，显著提升了德语NLP的性能，并在多项任务上取得了领先成果，为德语NLP领域的研究和应用提供了有力的支持。

> **ai_Abstract:** GeistBERT是一个新的德语语言模型，通过在包含1.3TB数据的多样化语料库上进行预训练和优化，在NER、文本分类和NLI等多个下游NLP任务上取得了优异的性能，并在GermEval 2018细粒度文本分类任务上达到了新的state-of-the-art（SOTA）水平。该模型已根据MIT协议发布，旨在促进德语NLP领域的研究。

> **摘要翻译:** 基于高质量语料库的语言特定预训练在基于Transformer的语言模型方面取得了进展，凸显了其优势。在此背景下，德语自然语言处理（NLP）可以通过针对德语语言特性定制的更新架构和现代数据集来获益。GeistBERT旨在通过在多样化的语料库上进行增量训练并优化模型在各种NLP任务上的性能来改进德语语言处理。我们使用fairseq预训练了GeistBERT，遵循RoBERTa基础配置和全词掩码（WWM），并从GottBERT权重初始化。该模型在1.3TB的德语语料库上进行训练，采用动态掩码和512个固定序列长度。为了进行评估，我们在标准下游任务上对模型进行了微调，包括NER（CoNLL 2003、GermEval 2014）、文本分类（GermEval 2018粗粒度/细粒度、10kGNAD）和NLI（German XNLI），并使用F1分数和准确率作为评估指标。GeistBERT在所有任务上均取得了优异的成绩，在基础模型中处于领先地位，并在GermEval 2018细粒度文本分类任务上创下了新的state-of-the-art（SOTA）记录。它还优于一些较大的模型，尤其是在分类基准测试中。为了支持德语NLP的研究，我们根据MIT协议发布了GeistBERT。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [384] [MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model](https://arxiv.org/abs/2507.08013)
> *利用预训练的 BERT 模型增强生物医学自然语言处理的 MedicalBERT*

*K. Sahit Reddy, N. Ragavenderan, Vasanth K., Ganesh N. Naik, Vishalakshi Prabhu, Nagaraja G. S* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-06**

**Keywords:** MedicalBERT, 生物医学 NLP, 预训练模型, BERT, 迁移学习

**Comment:** 

> **TL;DR:** 提出了一种名为 MedicalBERT 的预训练 BERT 模型，该模型在大型生物医学数据集上进行了训练，并包含特定于领域的词汇，以提高对生物医学术语的理解能力。在命名实体识别、关系抽取、问答、句子相似度和文档分类等任务上，MedicalBERT 的表现优于 BioBERT、SciBERT 和 ClinicalBERT 等模型，平均比通用 BERT 模型高出 5.67%。

**AI_Comments:** 该研究提出了一种名为 MedicalBERT 的新型预训练语言模型，专门用于处理生物医学文本的复杂性和领域特定性。通过在大型生物医学语料库上进行训练并整合领域词汇，MedicalBERT 在多种 NLP 任务中展示了优越的性能，超越了包括 BioBERT、SciBERT 和 ClinicalBERT 在内的现有模型。这项工作不仅解决了生物医学 NLP 的一个关键挑战，而且还强调了迁移学习在医学领域应用中的巨大潜力。该模型在提高准确性和效率方面的表现令人印象深刻，为未来的生物医学信息学研究开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 传统的 NLP 模型（如 Word2Vec 和 Bi-LSTM）在处理生物医学文献中的领域特定术语时存在挑战，而像 GPT 和 T5 这样的模型在需要双向理解的任务上表现不佳。因此，需要一个能够更好理解生物医学文本的预训练模型。

**Method:** 提出了一种名为 MedicalBERT 的预训练 BERT 模型。该模型在大型生物医学数据集上进行了训练，并加入了特定于领域的词汇。然后，对 MedicalBERT 模型进行了优化和微调，以处理包括命名实体识别、关系抽取、问答、句子相似度和文档分类在内的各种任务。通过 F1 分数、准确率和皮尔逊相关系数等性能指标来评估其效率。

**Result:** MedicalBERT 在大多数基准测试中优于 BioBERT、SciBERT 和 ClinicalBERT 等模型，并且在所有评估任务的平均得分上比通用的 BERT 模型高出 5.67%。

**Conclusion:** MedicalBERT 模型在生物医学自然语言处理任务中表现出色，证明了利用预训练 BERT 模型和迁移学习技术来捕获领域特定信息是有效的。

> **ai_Abstract:** MedicalBERT 是一个针对生物医学领域优化的预训练 BERT 模型，通过在大型生物医学数据集上训练并包含领域特定词汇，显著提高了对生物医学术语的理解能力。该模型在命名实体识别、关系抽取、问答、句子相似度和文档分类等任务上表现出色，平均性能优于通用 BERT 模型 5.67%，并超越了 BioBERT、SciBERT 和 ClinicalBERT 等现有模型。

> **摘要翻译:** 近期自然语言处理（NLP）的进展得益于像 BERT、RoBERTa、T5 和 GPT 这样的预训练语言模型。这些模型在理解复杂文本方面表现出色，但生物医学文献因其领域特定的术语而带来了挑战，这是 Word2Vec 和双向长短期记忆（Bi-LSTM）等模型无法完全解决的。尽管 GPT 和 T5 能够捕捉上下文，但在需要双向理解的任务上不如 BERT。为了解决这个问题，我们提出了 MedicalBERT，一个在大型生物医学数据集上训练的预训练 BERT 模型，并配备了特定于领域的词汇，以增强对生物医学术语的理解。MedicalBERT 模型还经过优化和微调，以处理各种任务，包括命名实体识别、关系抽取、问答、句子相似度和文档分类。我们采用了 F1 分数、准确率和皮尔逊相关系数等性能指标，以展示我们的模型与其他基于 BERT 的模型（如 BioBERT、SciBERT 和 ClinicalBERT）相比的效率。MedicalBERT 在大多数基准测试中的表现优于这些模型，并且在所有评估任务的平均得分上比通用的 BERT 模型高出 5.67%。这项工作还强调了利用预训练 BERT 模型处理医学 NLP 任务的潜力，并证明了迁移学习技术在捕获领域特定信息方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [392] [Flippi: End To End GenAI Assistant for E-Commerce](https://arxiv.org/abs/2507.05788)
> *Flippi：电子商务端到端生成式人工智能助手*

*Anand A. Rajasekar, Praveen Tangarajan, Anjali Nainani, Amogh Batwal, Vinay Rao Dandin, Anusua Trivedi, Ozan Ersoy* | **Category: cs.CL, I.2.7; H.3.3** | **Updated: 2025-07-11**

**Keywords:** 生成式人工智能,电子商务,对话式助手,大型语言模型,个性化购物

**Comment:** 10 pages, 2 figures, 7 tables

> **TL;DR:** Flippi是一个专为电子商务设计的、端到端的生成式人工智能助手，利用大型语言模型和自然语言处理技术，帮助用户通过对话更有效地发现产品，并提供个性化的购物体验、优惠信息和产品比较功能。

**AI_Comments:** 该研究介绍了一个非常有前景的人工智能助手Flippi，它能够解决电子商务领域中的关键痛点。通过利用LLM和先进的NLP技术，Flippi有望显著改善用户购物体验。其端到端的解决方案，结合了产品发现、个性化推荐和比较分析，使其在众多电子商务应用中具有广泛的适用性。然而，文章可能需要更深入地探讨在处理大规模、多样化产品目录时的潜在挑战，以及模型的鲁棒性和可扩展性方面的具体细节。

<details>
  <summary>Details</summary>

**Motivation:** 对话式助手重塑了用户与数字平台的交互方式，而电子商务领域存在产品信息庞大、用户难以高效发现产品的挑战。

**Method:** 利用大型语言模型和自然语言处理技术，包括查询重构、意图检测、检索增强生成（RAG）、命名实体识别（NER）和上下文缩减，来解释客户查询、提供产品信息、识别优惠和进行产品比较。

**Result:** Flippi能够解释客户查询，提供精确的产品信息，识别并展示有吸引力的优惠，帮助用户做出更具成本效益的决策，并通过比较功能帮助用户做出明智的选择。

**Conclusion:** Flippi通过提供便捷的在线购物体验和个性化协助，为电子商务领域的客户满意度和参与度树立了新的标杆。

> **ai_Abstract:** Flippi是一款创新的端到端生成式人工智能助手，专为电子商务设计。它利用大型语言模型和先进的自然语言处理技术，使用户能够通过自然对话更高效地发现产品，获得个性化的购物体验。Flippi能够准确解析用户需求，提供产品信息、识别最佳优惠，并支持产品间的比较分析，最终提升用户满意度和购买转化率。

> **摘要翻译:** 对话式助手的出现从根本上改变了用户与数字平台的交互方式。本文介绍了Flippi——一个由大型语言模型（LLM）驱动、专为电子商务领域量身定制的前沿端到端对话式助手。Flippi解决了产品信息浩瀚且常常令人不知所措的挑战，通过自然语言对话，使用户能够更有效地发现产品。通过兼容客观和主观的用户需求，Flippi提供了超越传统搜索方法的个性化购物体验。本文详细介绍了Flippi如何解释客户查询以提供精确的产品信息，利用查询重构、意图检测、检索增强生成（RAG）、命名实体识别（NER）和上下文缩减等先进的自然语言处理技术。文章还探讨了Flippi识别并展示电子商务网站上最具吸引力优惠的独特能力，展示了它如何使用户能够做出具有成本效益的决策。此外，本文讨论了Flippi的比较分析功能，通过对比产品特性、价格和其他相关属性，帮助用户做出明智的选择。系统阐述了其强大的架构，强调了其在各种电子商务平台上集成的适应性以及支撑其性能和准确性的技术选择。最后，提出了一套全面的评估框架，涵盖了性能指标、用户满意度以及对客户参与度和转化率的影响。通过将在线购物的便捷性与传统实体店的个性化协助相结合，Flippi为数字市场中的客户满意度和参与度树立了新的标杆。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [401] [Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization](https://arxiv.org/abs/2507.08342)
> *超越N-Grams：重新思考多语言生成式摘要的评估指标和策略*

*Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 多语言摘要, 评估指标, N-grams, 神经网络指标, 语言类型

**Comment:** ACL 2025 Main

> **TL;DR:** 现有基于N-Grams的评估指标（如ROUGE）在多语言摘要任务中的有效性尚不明确。本研究在一个包含八种语言的大型评估套件上系统地评估了基于N-Grams和基于神经网络的指标，发现指标对语言类型敏感，尤其是在屈折语中，基于N-Grams的指标与人类判断的相关性较低。研究表明，改进分词可以缓解此问题，而专门为评估任务训练的神经网络指标（如COMET）在低资源语言中表现更好，与人类判断的相关性更高。因此，研究建议在评估任务的神经网络指标上投入更多资源。

**AI_Comments:** 该研究系统地评估了不同语言背景下摘要评估指标的有效性，为多语言摘要评估提供了重要的实证依据。其发现强调了语言类型对评估指标性能的影响，并提出了改进分词和采用特定任务训练的神经网络指标的实用建议。这项工作对于开发更公平、更准确的多语言摘要评估工具具有重要意义。然而，研究中使用的“语言类型”（如屈折语、孤立语）的定义和分类，以及“低资源”和“高资源”的具体标准，可以进一步明确和细化。此外，虽然指出了COMET等指标的优势，但其在不同语言和任务上的泛化能力仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于评估生成任务（如摘要）的基于N-Grams的指标（如ROUGE）在英语中被认为是有效的，但其在其他语言中的适用性尚不清楚。需要系统地评估不同类型的评估指标（基于N-Grams和基于神经网络）在不同语言和任务中的有效性。

**Method:** 设计了一个包含八种语言（涵盖四种语言类型：黏着语、孤立语、低屈折语和高屈折语）的大型评估套件，涵盖低资源和高资源设置，以分析评估指标与人类判断的相关性。

**Result:** 基于N-Grams的指标对语言类型敏感，在屈折语中的相关性低于孤立语和黏着语。改进分词可以缓解在形态丰富的屈折语中的问题。专门为评估任务训练的神经网络指标（如COMET）在低资源语言中的表现优于其他神经网络指标，且与人类判断的相关性更高。

**Conclusion:** 研究强调了N-Grams指标在屈折语中的局限性，并主张在专门为评估任务训练的神经网络指标上进行更多投资。

> **ai_Abstract:** 本研究评估了不同类型的自动摘要评估指标（基于N-grams和神经网络）在多种语言中的有效性。研究发现，基于N-grams的指标在处理屈折语时与人类判断的相关性较低，但通过改进分词可以有所改善。专门为评估任务训练的神经网络指标，如COMET，在低资源语言中表现出更高的准确性。研究建议未来应更多地关注和投资于基于神经网络的评估指标，特别是在处理不同语言特性时。

> **摘要翻译:** 自动化的N-gram度量，如ROUGE，被广泛用于生成任务，如摘要。虽然这些度量在英语中被认为与人类评估具有指示性（即使不完美），但它们在其他语言中的适用性仍然不清楚。为了解决这个问题，我们系统地评估了用于生成任务的度量——包括N-gram和神经网络度量——以评估它们在不同语言和任务中的有效性。具体来说，我们设计了一个大规模的评估套件，涵盖了四种语言类型的八种语言：黏着语、孤立语、低屈折语和高屈折语，涵盖了低资源和高资源环境，以分析它们与人类判断的相关性。我们的发现突显了评估度量对语言类型的敏感性。例如，在屈折语中，基于N-gram的度量与人类评估的相关性低于孤立语和黏着语。我们还证明，适当的分词可以显著缓解这个问题，尤其是在形态丰富的屈折语中，有时甚至可以扭转负面趋势。此外，我们表明，专门为评估训练的神经网络度量，如COMET，始终优于其他神经网络度量，并且在低资源语言中与人类判断的相关性更好。总的来说，我们的分析强调了N-gram度量在屈折语中的局限性，并主张在专门为评估任务训练的神经网络度量上进行更多投资。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [407] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
> *他人之谬：一个由大语言模型驱动的科学知识生产框架*

*Juan B. Gutiérrez* | **Category: cs.CL, cs.LG, 68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15, I.2.7; I.2.11; G.3** | **Updated: 2025-07-10**

**Keywords:** 大语言模型, 科学知识生产, 论述网络, 同行评审, Flaws-of-Others算法

**Comment:** 27 pages, 3 figures, 4 tables, 1 algorithm, 48 references

> **TL;DR:** 该研究提出了一种新的方法，将大语言模型（LLM）视为科学知识生产中的平等参与者，并开发了一个名为‘Flaws-of-Others (FOO)’的算法，通过让多个代理相互批评和协调来提高知识的可靠性，强调通过网络化和同行评审而非单一模型优化来确保准确性。

**AI_Comments:** 这项研究引入了一个关于大语言模型在科学知识生产中作用的新颖视角，将LLM视为合作者而非仅仅是工具。‘他人之谬’算法的提出为解决LLM的可靠性问题提供了一个具体的机制。然而，该模型在实际应用中的可扩展性、不同领域知识的异质性以及“协调器”的潜在偏见等方面可能还需要进一步的探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型在科学知识生产中存在局限性，需要一种新的方法来捕捉人与软件之间通过大语言模型进行的交流，并解决其固有的不准确性问题。

**Method:** 提出了一种新的论述网络模型，将人类和LLM视为平等的节点，并追踪其陈述的传播。定义了“无效性”（包括事实、逻辑或结构上的缺陷），并将其归因于四个因素：偏离真相、自我修复、新的虚构和外部检测。开发了一个通用的论述网络数学模型来分析这些因素的影响。通过开源的“Flaws-of-Others (FOO)算法”实现了同行评审，该算法允许代理相互批评，并由一个协调器整合其评估。

**Result:** 研究表明，仅受偏离真相和自我修复影响的网络会在一个适度的错误率下趋于稳定；而加入新的虚构则会产生当前大语言模型中常见的高错误率。然而，即使为每个错误声明提供一个小的同行评审机会，也能将系统推向一个以真实为主导的状态。

**Conclusion:** 在大语言模型的时代，可靠性并非来自优化单一模型，而是来自将多个不完美的模型连接成能够相互制约的网络，从而保证其诚实性。

> **ai_Abstract:** 该研究提出了一种新颖的框架，将大型语言模型（LLM）视为科学知识生产中的平等参与者，并引入了一个论述网络模型来分析信息传播和错误产生的机制。研究人员定义了“无效性”并识别了四个导致无效性的危害：偏离真相、自我修复、新的虚构和外部检测。通过数学模型分析发现，引入同行评审机制（通过FOO算法实现）能够有效提高知识的准确性，将系统推向一个以真实为主导的状态。最终结论强调，在LLM驱动的知识生产中，可靠性来自于构建能够相互监督和制约的网络，而非依赖于单个模型的完美。

> **摘要翻译:** 大型语言模型将写作变成人与软件之间的实时交流。我们用一个论述网络模型来捕捉这种新媒介，该模型将人与LLM视为平等的节点，并追踪他们的陈述如何传播。将焦点从孤立的幻觉扩展开来，我们定义了无效性（任何事实、逻辑或结构上的缺陷），并表明它遵循四种危害：偏离真相、自我修复、新的虚构和外部检测。我们开发了一个通用的论述网络数学模型，提供了有价值的见解：一个仅受偏离真相和自我修复控制的网络会在一个适度的错误率下稳定下来；加入新的虚构会复制当前LLM中出现的高错误率。让每个错误声明都有被同行评审的微小机会，就能将系统推向一个以真实为主导的状态。我们通过开源的“他人之谬（FOO）算法”来实现同行评审：这是一个可配置的循环，其中任何一组代理相互批评，同时一个协调器合并他们的评估。其启示是实践性和文化性的：在这个新媒介中的可靠性并非来自完善单一模型，而是来自将不完美的模型连接成能够相互制约的网络。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [409] [Mass-Scale Analysis of In-the-Wild Conversations Reveals Complexity Bounds on LLM Jailbreaking](https://arxiv.org/abs/2507.08014)
> *大规模在线对话分析揭示了大型语言模型越狱的复杂性界限*

*Aldan Creo, Raul Castro Fernandez, Manuel Cebrian* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-07-06**

**Keywords:** LLM越狱,复杂性分析,AI安全,对话分析,防御机制

**Comment:** Code: https://github.com/ACMCMC/risky-conversations Results:
  https://huggingface.co/risky-conversations Visualizer:
  https://huggingface.co/spaces/risky-conversations/Visualizer

> **TL;DR:** 研究发现，大型语言模型（LLM）的越狱尝试并不比正常对话复杂多少，这表明攻击的复杂性存在实际限制，并且安全机制正在改进，这挑战了攻击与防御不断升级的说法。

**AI_Comments:** 这项研究非常有价值，因为它通过大规模实证分析挑战了关于LLM越狱不断升级的普遍看法。通过使用多种复杂性指标，研究得出了攻击复杂性存在实际限制的结论，这为AI安全领域提供了新的视角。然而，研究可以进一步探讨导致越狱复杂性限制的具体因素，以及这些限制在不同类型LLM上的差异性。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）的广泛部署，理解越狱策略的复杂性和演变对于AI安全至关重要。

**Method:** 对来自不同平台（包括专门的越狱社区和通用聊天机器人）的超过200万次真实对话进行了大规模实证分析，并使用了多种复杂性指标，如概率度量、词汇多样性、压缩率和认知负荷指标。

**Result:** 越狱尝试的复杂性并不显著高于正常对话，并且这种模式在专门的越狱社区和普通用户群体中都保持一致。用户攻击的毒性和复杂性随时间保持稳定，而助手响应的毒性则有所下降。复杂性分布中没有出现幂律缩放现象。

**Conclusion:** 研究结果表明，LLM安全演进受到人类创造力限制的约束，而防御措施在不断进步，这与攻击与防御不断升级的说法相悖。研究还强调了学术界披露越狱信息可能带来的信息危害，因为超出当前复杂性基线的复杂攻击可能会破坏观察到的平衡，并在防御适应之前造成广泛危害。

> **ai_Abstract:** 这项研究通过对超过200万次真实对话的大规模实证分析，探讨了大型语言模型（LLM）越狱的复杂性。研究发现，越狱尝试的复杂性与正常对话相当，并且这种模式在不同用户群体中保持一致，这表明攻击的复杂性存在实际限制。同时，研究观察到助手响应的毒性随时间下降，表明安全机制的有效性在提高。这些发现挑战了攻击与防御不断升级的观点，并强调了在披露越狱信息时需要谨慎，以避免潜在的信息危害。

> **摘要翻译:** 随着大型语言模型（LLM）的广泛部署，理解越狱策略的复杂性和演变对于AI安全至关重要。
我们对来自不同平台（包括专门的越狱社区和通用聊天机器人）的超过200万次真实对话进行了大规模实证分析。我们使用了一系列跨越概率度量、词汇多样性、压缩率和认知负荷指标的复杂性度量，发现越狱尝试的复杂性并不比正常对话显著高。
这种模式在专门的越狱社区和普通用户群体中都保持一致，表明攻击的复杂性存在实际限制。
时间分析显示，尽管用户攻击的毒性和复杂性随时间保持稳定，但助手响应的毒性有所下降，这表明安全机制正在改进。
复杂性分布中没有出现幂律缩放现象，这进一步表明越狱开发存在自然限制。
我们的研究结果挑战了攻击与防御不断升级的说法，反而表明LLM安全演进受到人类创造力限制的约束，而防御措施在不断进步。
我们的研究结果强调了学术界披露越狱信息可能带来的关键信息危害，因为超出当前复杂性基线的复杂攻击可能会破坏观察到的平衡，并在防御适应之前造成广泛危害。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [422] [Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings](https://arxiv.org/abs/2507.07248)
> *医疗语言模型的红队测试协议：论用户视角在医疗环境中的重要性*

*Jean-Philippe Corbeil, Minseon Kim, Alessandro Sordoni, Francois Beaulieu, Paul Vozila* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 医疗LLM, 安全评估, 红队测试, 患者视角, 临床医生视角

**Comment:** 

> **TL;DR:** 该研究提出了一种针对医疗领域和不同用户视角（患者、临床医生）的LLM安全评估协议，并构建了一个包含466个样本的PatientSafetyBench数据集，以解决现有评估方法仅关注通用安全基准的不足。研究人员将该协议应用于MediPhi模型集合，为医疗领域LLM的安全部署奠定了基础。

**AI_Comments:** 这项研究非常重要，因为它解决了医疗领域LLM安全评估的一个关键空白，即缺乏针对不同用户视角（特别是患者）的评估。通过构建PatientSafetyBench数据集和提出专门的红队测试协议，该研究为确保医疗LLM的安全性和可靠性提供了实用的方法。其创新性在于将用户体验和潜在的健康影响纳入安全评估框架。然而，协议的普适性以及在不同医疗场景下的有效性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有对医疗领域大型语言模型（LLMs）的安全评估主要集中在通用安全基准，未能充分考虑医疗应用中不同用户角色（如患者和临床医生）以及模型输出直接影响人类健康的特性。

**Method:** 提出了一种针对医疗领域并结合患者和临床医生用户视角的安全评估协议，并进行了通用安全评估。构建了一个包含466个样本、涵盖5个关键类别的PatientSafetyBench数据集，用于从患者角度衡量安全性。将该红队测试协议应用于MediPhi模型集合进行案例研究。

**Result:** 研究人员构建了PatientSafetyBench数据集，其中包含466个样本，覆盖5个关键类别，用于从患者角度衡量安全性。通过将协议应用于MediPhi模型集合，为医疗LLM的安全部署奠定了基础。

**Conclusion:** 该研究首次通过针对性的红队测试，从患者、临床医生和普通用户的三个不同视角定义了医疗LLM的安全评估标准，为在医疗领域更安全地部署LLM奠定了基础。

> **ai_Abstract:** 本研究针对医疗领域的大型语言模型（LLMs）提出了一个创新的安全评估协议，该协议特别关注患者和临床医生的用户视角，弥补了以往评估方法仅侧重于通用安全基准的不足。研究者构建了一个名为PatientSafetyBench的数据集，包含466个样本和5个关键类别，用于量化评估患者使用LLM时的安全性。通过将此协议应用于MediPhi模型集合的案例研究，该工作为在医疗环境中更安全地部署LLMs奠定了基础。

> **摘要翻译:** 随着大型语言模型（LLMs）性能的不断提升，它们的应用范围已扩展到包括医疗在内的各个领域。LLMs集成到医疗应用中引发了关键的安全担忧，特别是由于其用户角色多样（如患者和临床医生），并且模型输出可能直接影响人类健康。尽管存在针对特定医疗领域的LLM能力，但以往的安全评估主要集中在通用的安全基准上。本研究提出了一种针对医疗领域、同时考虑患者用户和临床医生用户视角的安全评估协议，并结合了通用安全评估，对医疗LLM的安全性进行了量化分析。我们通过构建包含466个样本、涵盖5个关键类别的PatientSafetyBench数据集，从患者角度衡量安全性，填补了相关文献的空白。我们将红队测试协议应用于MediPhi模型集合作为案例研究。据我们所知，这是首次通过针对性的红队测试，从患者、临床医生和通用用户的三个不同视角定义医疗LLM安全评估标准的工作，为在医疗领域更安全地部署奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [426] [The Impact of Automatic Speech Transcription on Speaker Attribution](https://arxiv.org/abs/2507.08660)
> *自动语音转录对说话人归属的影响*

*Cristina Aggazzotti, Matthew Wiesner, Elizabeth Allyn Smith, Nicholas Andrews* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 说话人归属,自动语音识别,转录错误,语言模式,说话人身份

**Comment:** 

> **TL;DR:** 即使在有错误的自动语音识别（ASR）转录文本上，说话人归属仍然非常有效，甚至可能比在人工转录文本上效果更好，因为ASR错误可能包含揭示说话人身份的特定特征。

**AI_Comments:** 这项研究具有重要的现实意义，因为它直接解决了在实际应用中经常遇到的ASR错误问题。研究结果令人惊讶地表明，ASR错误可能不会像预期的那样损害说话人归属任务，甚至可能有所帮助，这为未来的研究开辟了新的方向。然而，需要进一步研究以了解ASR错误如何以及为何能改善说话人归属，以及这种现象在多大程度上可以推广到不同的ASR系统和语言。

<details>
  <summary>Details</summary>

**Motivation:** 评估自动语音识别（ASR）系统产生的有错误转录文本对说话人归属任务的影响，以及ASR系统的特性如何影响归属性能。

**Method:** 对自动转录文本的说话人归属性能进行全面的研究，分析转录错误对性能的影响程度，以及ASR系统的属性如何影响归属。

**Result:** 说话人归属对单词级别的转录错误具有出乎意料的鲁棒性，并且恢复真实转录的目标与归属性能的关联性很小。在ASR产生的有错误转录文本上进行说话人归属，其性能与基于人工转录的文本相当，甚至更好。

**Conclusion:** 说话人归属在有错误转录文本上的表现出人意料地好，这表明ASR错误可能是有用的，并且不应仅仅关注恢复准确的转录。

> **ai_Abstract:** 本研究首次全面探讨了自动语音识别（ASR）系统产生的有错误转录文本对说话人归属任务的影响。研究发现，说话人归属任务对单词级别的转录错误具有很强的鲁棒性，并且ASR系统的固有错误有时可能比人类转录更能揭示说话人的身份特征，从而提高了归属性能。

> **摘要翻译:** 说话人归属是从演讲者根据他们的语言使用模式来识别说话人的任务。当音频不可用（例如，被删除）或不可靠（例如，匿名演讲）时，此任务特别有用。该领域的先前工作主要集中在使用人类注释者生成的转录本来归属说话人的可行性。然而，在现实世界中，人们通常只有由自动语音识别（ASR）系统产生的、错误更多的转录本。在本文中，我们进行了据我们所知，首次对自动转录对说话人归属性能的影响进行全面研究。特别是，我们研究了在转录错误面前，说话人归属性能下降的程度，以及ASR系统的属性如何影响归属。我们发现，说话人归属对单词级别的转录错误具有出乎意料的鲁棒性，并且恢复真实转录的目标与归属性能的关联性很小。总的来说，我们的研究结果表明，在ASR产生的有错误转录本上进行说话人归属，其性能与基于人类转录的数据相当，甚至更好，这可能是因为ASR转录错误可以捕捉到揭示说话人身份的特定于说话人的特征。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [433] [Mechanistic Indicators of Understanding in Large Language Models](https://arxiv.org/abs/2507.08017)
> *大型语言模型中理解的机制指标*

*Pierre Beckmann, Matthieu Queloz* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-07**

**Keywords:** 机制可解释性, 大型语言模型, 机器理解, 概念理解, 并行机制

**Comment:** 32 pages

> **TL;DR:** 该论文探讨了大型语言模型（LLM）的机制可解释性（MI），提出了一种新的理论框架来理解LLM的内部工作原理，认为LLM通过发展内部结构来“理解”世界，但其认知结构与人类不同。

**AI_Comments:** 该研究为理解大型语言模型（LLM）的内部工作机制提供了一个清晰且易于理解的框架。它不仅挑战了传统的观点，还提出了一个有见地的三层级机器理解模型。论文的结论部分尤为重要，它将研究焦点从“LLM是否理解”转移到“LLM如何理解”，为该领域未来的研究指明了方向。然而，关于“并行机制”的探讨可以更加深入，以更好地阐明LLM与人类认知之间的具体差异。

<details>
  <summary>Details</summary>

**Motivation:** 挑战了认为大型语言模型（LLM）仅依赖于肤浅统计的观点，并提出了一个关于机器理解的新理论框架。

**Method:** 提出了一种三层级的机器理解概念：概念理解、世界状态理解和原则理解，并探讨了“并行机制”现象。

**Result:** 大型语言模型发展了功能上类似于人类理解的内部结构，但其认知架构与人类不同。

**Conclusion:** 虽然大型语言模型表现出某种形式的理解，但其认知架构与人类不同，研究重点应从LLM是否理解转移到其工作机制上。

> **ai_Abstract:** 本研究通过机制可解释性（MI）的视角，对大型语言模型（LLM）的理解能力进行了深入探讨。论文提出了一个三层级的机器理解模型，包括概念理解、世界状态理解和原则理解，并认为LLM通过发展内部结构来学习和连接信息。尽管LLM展现出类似人类的理解能力，但研究强调其认知架构与人类存在显著差异，未来的研究应关注其独特的工作机制。

> **摘要翻译:** 近期在机制可解释性（MI）领域的研究，该领域旨在探究大型语言模型（LLM）的内部运作机制，挑战了这些模型仅依赖于肤浅统计的观点。在此，我们对这些发现进行了易于理解的综合，同时将其整合到一个新颖的机器理解理论框架中，并作为对MI的介绍。我们认为，LLM会发展出功能上类似于人类所理解的“连接感知”的内部结构。为了阐明这一观点，我们提出了一个三层级的机器理解概念。首先，当模型将“特征”形成潜在空间中的方向，从而学习某种事物不同表现形式之间的联系时，就出现了概念理解。其次，当模型学习特征之间偶然的事实联系并动态跟踪世界变化时，就出现了世界状态理解。第三，当模型不再依赖于记忆事实的集合并发现连接这些事实的“电路”时，就出现了原则理解。然而，我们最后探讨了“并行机制”现象，认为虽然LLM表现出理解的某些形式，但其认知架构仍然与我们不同，争论的焦点应该从LLM是否理解转移到它们的奇特心智如何运作上。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [436] [The Curious Case of Factuality Finetuning: Models' Internal Beliefs Can Improve Factuality](https://arxiv.org/abs/2507.08371)
> *事实微调的奇特案例：模型的内部信念可以提高事实性*

*Benjamin Newman, Abhilasha Ravichander, Jaehun Jung, Rui Xin, Hamish Ivison, Yegor Kuznetsov, Pang Wei Koh, Yejin Choi* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 事实性微调, 语言模型幻觉, 模型内部信念, 数据过滤, 长文本生成

**Comment:** 29 pages, 4 figures, 16 tables

> **TL;DR:** 微调模型以减少幻觉并不总是通过高质量的事实数据来实现，有时模型自身生成的、被认为是事实的数据效果更好，尤其是经过模型自身判断筛选后的数据。

**AI_Comments:** 这项研究提出了一个反直觉但重要的发现，即模型的“自我认知”可以用于指导其学习过程以提高事实性。这为解决语言模型幻觉问题提供了一个新的视角和潜在的解决方案，尤其是在获取高质量事实数据困难的情况下。然而，研究可能需要进一步探讨模型内部判断的可靠性以及这种方法的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型容易产生幻觉（生成事实不准确的文本），但使用高质量事实数据进行微调可能成本高昂，并且可能导致更多下游幻觉。因此，需要研究哪种微调数据可以有效减少幻觉。

**Method:** 研究微调数据的时事实性与长文本生成任务中幻觉的普遍性之间的关系。评估了应用于事实金数据和模型生成数据上的过滤策略。

**Result:** 与预期相反，在事实金数据上进行微调不如在模型认为事实的模型生成数据上进行微调有效。通过模型自身内部判断过滤后的模型生成数据，在整体事实性方面优于其他配置（如仅使用金数据或金数据与模型生成数据结合）。

**Conclusion:** 模型的自身信念可以作为提高事实性的有力信号，通过模型自身判断过滤后的模型生成数据在减少幻觉方面效果显著。

> **ai_Abstract:** 该研究探讨了用于微调语言模型的“事实性数据”对减少模型幻觉（生成不准确信息）的影响。研究发现，使用模型自身认为“事实”的模型生成数据进行微调，比使用高质量的“金数据”更有效。特别是，当模型生成的数据经过模型自身判断的筛选后，其事实性表现最佳，优于其他几种微调策略。这表明模型的内部信念可以作为提高其事实准确性的重要指导。

> **摘要翻译:** 语言模型容易产生幻觉——生成事实不准确的文本。在高质量的事实信息上进行微调可以潜在地减少幻觉，但仍然存在担忧；获取事实金数据可能成本高昂，并且在正确但陌生的数据上进行训练可能会导致更多的下游幻觉。从业者应该微调哪种数据来减轻语言模型的幻觉？在本研究中，我们研究了微调数据的时事实性与长文本生成任务中幻觉的普遍性之间的关系。与预期相反，我们发现仅在事实金数据上进行微调并不如在模型认为事实的模型生成数据上进行微调那么有效。接下来，我们评估了应用于事实金数据和模型生成数据上的过滤策略，并发现通过模型自身的内部判断进行过滤的模型生成数据，通常在整体事实性方面优于其他配置：在模型判断过滤后的金数据上进行训练、仅在金数据上进行训练，或在有金数据支持的模型生成数据上进行训练。这些事实性的提高跨越了我们研究的三个领域，表明模型的自身信念可以为事实性提供一个有力的信号。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [456] [REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives](https://arxiv.org/abs/2503.11924)
> *REGEN：一个包含自然语言评论和叙述的数据集和基准测试*

*Kun Su, Krishna Sayana, Hubert Pham, James Pine, Yuri Vasilevski, Raghavendra Vasudeva, Marialena Kyriakidi, Liam Hebert, Ambarish Jash, Anushya Subbiah, Sukhdeep Sodhi* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 对话式推荐, 大语言模型, 数据集, 用户评论, 生成叙述

**Comment:** 

> **TL;DR:** 本研究提出了REGEN数据集，用于评估对话式推荐大语言模型的性能，并引入了LUMEN模型框架，用于联合生成推荐和叙述。

**AI_Comments:** 该研究提出的REGEN数据集和LUMEN模型框架在对话式推荐领域具有重要意义，它解决了现有数据集的局限性，并为评估和提升推荐系统的用户体验提供了新的途径。然而，对叙述生成质量的评估和模型的泛化能力仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据集主要关注序列项目预测，无法充分评估推荐大语言模型的对话能力。

**Method:** 通过在Amazon产品评论数据集中加入用户“引导性”评论（critiques）和每个推荐项目的叙述（narratives），构建了REGEN数据集。提出了LUMEN模型框架，用于联合生成推荐和叙述。

**Result:** 结果表明，加入评论可以提升推荐质量，使推荐器能更好地理解语言并结合推荐信号。在REGEN数据集上训练的大语言模型能够有效地生成推荐和上下文叙述，性能与最先进的推荐模型和语言模型相当。

**Conclusion:** REGEN数据集为对话式推荐大语言模型的评估提供了新的基准，并且通过引入用户评论和叙述，可以提升推荐系统的性能。

> **ai_Abstract:** 本研究提出了REGEN数据集，旨在改进对话式推荐大语言模型的评估方法，该数据集通过添加用户评论和叙述来丰富现有数据集。研究还提出了LUMEN模型框架，用于联合生成推荐和叙述，并在实验中证明了加入评论能提升推荐性能，且基于REGEN数据集训练的大语言模型在生成推荐和叙述方面表现出色。

> **摘要翻译:** 本篇论文介绍了REGEN（评论增强生成叙述）这一新数据集，旨在为推荐大语言模型的对话能力提供基准测试，解决了现有数据集主要关注序列项目预测的局限性。REGEN通过在亚马逊产品评论数据集中嵌入两种关键的自然语言特征：1）用户评论，代表用户引导后续项目选择的“引导性”查询；2）叙述，即针对每个推荐项目生成的、考虑了先前上下文的丰富文本输出。叙述包括产品推荐语、购买解释和用户偏好总结。
此外，我们为对话式推荐任务建立了一个端到端的建模基准，模型需要根据用户历史（项目和评论）来生成推荐和相应的叙述。对于这项联合任务，我们引入了一个名为LUMEN（基于大语言模型的统一多任务模型，包含评论、推荐和叙述）的建模框架，该框架使用大语言模型作为评论、检索和生成的后端。我们还使用标准的自动评分技术评估了数据集的质量，并通过训练传统和基于大语言模型的推荐模型对其进行了基准测试。我们的结果表明，加入评论通过使推荐器能够学习语言理解并将其与推荐信号相结合，从而提高了推荐质量。此外，在我们的数据集上训练的大语言模型能够有效地生成推荐和上下文叙述，其性能可与最先进的推荐模型和语言模型相媲美。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [459] [Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation](https://arxiv.org/abs/2507.08020)
> *绕过大型语言模型中的安全对齐：通过嵌入空间毒性衰减*

*Zhibo Zhang, Yuxi Li, Kailong Wang, Shuai Yuan, Ling Shi, Haoyu Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-08**

**Keywords:** 大型语言模型, 安全对齐, 嵌入空间中毒, 对抗性攻击, ETTA

**Comment:** 

> **TL;DR:** 该研究提出了一种名为ETTA的新框架，通过在嵌入空间中进行线性变换来识别和衰减对毒性敏感的维度，从而绕过大型语言模型的安全对齐机制。ETTA在不进行模型微调或访问训练数据的情况下，成功地绕过了模型的拒绝行为，同时保持了语言的连贯性。在五个代表性开源LLM上的评估显示，ETTA的平均攻击成功率为88.61%，优于现有基线，并能泛化到经过安全增强的模型。

**AI_Comments:** 这项研究揭示了大型语言模型安全对齐的一个重要漏洞，即通过操纵嵌入空间来规避安全机制。ETTA框架通过一种新颖的方法（嵌入空间毒性衰减）有效地实现了这一点，并且无需进行模型微调或访问训练数据，这使其具有很高的实用性和潜在的攻击性。研究结果强调了现有对齐策略的局限性，并指出了未来研究方向，即开发能够感知和防御嵌入空间攻击的对齐机制。然而，该研究可能未充分探讨ETTA对模型其他方面功能（如生成质量、鲁棒性等）的潜在影响，以及在更复杂的真实世界场景中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的安全对齐机制在大型语言模型中引入了安全风险，特别是通过嵌入空间中毒，这是一种操纵输入数据内部语义表示以规避安全对齐的攻击方式。然而，关于LLM在嵌入层面上的安全对齐动态以及更具针对性和准确性的对抗性扰动技术的研究尚不充分。

**Method:** 提出了一种名为ETTA（Embedding Transformation Toxicity Attenuation）的新框架，通过线性变换识别和衰减嵌入空间中对毒性敏感的维度，从而绕过模型的安全对齐机制，同时保持语言的连贯性，且无需模型微调或访问训练数据。

**Result:** 在五个代表性开源LLM上，使用AdvBench基准测试，ETTA实现了88.61%的平均攻击成功率，比最佳基线高出11.34%，并且能够泛化到经过安全增强的模型（在指令调整防御模型上的攻击成功率为77.39%）。

**Conclusion:** 研究结果揭示了当前对齐策略的一个关键漏洞，并强调了对嵌入感知防御措施的需求。

> **ai_Abstract:** 本研究提出了一种名为ETTA的新框架，用于绕过大型语言模型的安全对齐机制。ETTA通过识别和衰减嵌入空间中对毒性敏感的维度，成功地规避了模型的拒绝行为，同时保持了语言的连贯性，并且无需模型微调或访问训练数据。实验结果表明，ETTA在多个模型上表现出高攻击成功率，并能泛化到安全增强模型，揭示了当前对齐策略的潜在漏洞，并强调了开发嵌入感知防御机制的重要性。

> **摘要翻译:** 大型语言模型（LLMs）在医疗、教育和网络安全等领域取得了显著成功。然而，这种开放性也带来了重大的安全风险，特别是通过嵌入空间中毒，这是一种微妙的攻击向量，攻击者通过操纵输入数据的内部语义表示来绕过安全对齐机制。虽然以往的研究已经探索了通用的扰动方法，但对LLM在嵌入层面的安全对齐动态的理解仍然不足。因此，更具针对性和准确性的对抗性扰动技术（构成重大威胁）尚未得到充分研究。
在本研究中，我们提出了ETTA（Embedding Transformation Toxicity Attenuation），一个新颖的框架，通过线性变换识别和衰减嵌入空间中对毒性敏感的维度。ETTA在不要求模型微调或访问训练数据的情况下，绕过了模型的拒绝行为，同时保持了语言的连贯性。在五个代表性开源LLM上使用AdvBench基准进行评估，ETTA实现了88.61%的高平均攻击成功率，比最佳基线高出11.34%，并能泛化到安全增强的模型（例如，在指令调整的防御模型上实现了77.39%的攻击成功率）。这些结果突显了当前对齐策略的一个关键漏洞，并强调了对嵌入感知防御措施的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [471] [A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities](https://arxiv.org/abs/2507.08425)
> *学科领域研究中的大型语言模型：挑战、方法与机遇调查*

*Lu Xiang, Yang Zhao, Yaping Zhang, Chengqing Zong* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 跨学科研究, 技术方法, 应用, 挑战

**Comment:** 

> **TL;DR:** 本调查全面概述了大型语言模型（LLM）在跨学科研究中的应用，重点介绍了技术方法（如微调、检索增强生成、基于代理的方法和工具使用）及其在数学、物理、化学、生物以及人文学科和社会科学中的应用。它还讨论了挑战和未来研究方向，旨在为研究人员提供一个宝贵的资源。

**AI_Comments:** 该调查为理解LLM在不同学科领域的应用提供了一个全面的框架。它有效地结合了技术方法和实际应用，同时还指出了挑战和未来的研究方向，使其对研究人员非常有价值。然而，对具体 LLM 模型或数据集的深入分析可能会进一步增强其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在跨学科研究中具有变革潜力，但其整合情况尚未得到充分探索，因此需要进行系统性理解。

**Method:** 本调查论文对LLM在跨学科研究中的应用进行了全面概述，从技术角度（包括监督微调、检索增强生成、基于代理的方法和工具使用）和应用角度（涵盖数学、物理、化学、生物、人文学科和社会科学）对研究工作进行了分类。

**Result:** LLM已被应用于数学、物理、化学、生物以及人文学科和社会科学等多个学科，并在特定学科任务中发挥作用。

**Conclusion:** 本调查为研究人员提供了LLM在跨学科研究领域的技术发展和应用的全面概述，旨在成为一个宝贵的资源，以应对该领域的复杂性。

> **ai_Abstract:** 本调查全面概述了大型语言模型（LLM）在跨学科研究中的应用，重点介绍了技术方法（如微调、检索增强生成、基于代理的方法和工具使用）及其在数学、物理、化学、生物以及人文学科和社会科学中的应用。它还讨论了挑战和未来研究方向，旨在为研究人员提供一个宝贵的资源。

> **摘要翻译:** 大型语言模型（LLM）已在众多学科研究中展现出其变革潜力，重塑了现有的研究方法并促进了跨学科合作。然而，对其整合到不同学科的系统性理解仍有待探索。本调查论文全面概述了LLM在跨学科研究中的应用，从技术角度和适用性角度对研究工作进行了分类。从技术角度来看，考察了监督微调、检索增强生成、基于代理的方法和工具使用集成等关键方法，这些方法增强了LLM在特定学科背景下的适应性和有效性。从适用性角度来看，本文探讨了LLM如何为数学、物理、化学、生物以及人文学科和社会科学等各个学科做出贡献，展示了它们在特定学科任务中的作用。对普遍存在的挑战进行了批判性审查，并与LLM的最新进展一起，重点介绍了有前景的研究方向。通过对该领域技术发展和应用的全面概述，本调查旨在为那些在跨学科研究背景下驾驭LLM复杂格局的研究人员提供宝贵的资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [474] [Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis](https://arxiv.org/abs/2507.08021)
> *揭示图像字幕生成中有效的上下文内配置：一项外部与内部分析*

*Li Li, Yongliang Wu, Jingze Zhu, Jiawei Peng, Jianfei Cai, Xu Yang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-08**

**Keywords:** 上下文内学习, 大型多模态模型, 图像字幕生成, 演示配置, 注意力机制

**Comment:** 16 pages, 11 figures

> **TL;DR:** 该研究调查了用于图像字幕生成的多模态大模型（LMM）的上下文内学习（ICL）的演示配置策略。通过外部实验，研究人员探讨了 the shot number、图像检索和字幕分配的影响，并通过内部分析检查了 LMM 的注意力特征。研究结果揭示了演示配置如何影响模型性能，并为理解多模态 ICL 提供了见解，其方法和新提出的指标可应用于更广泛的研究领域。

**AI_Comments:** 这项研究通过结合外部和内部分析，为理解和优化多模态大型模型（LMM）中的上下文内学习（ICL）提供了一个全面的视角。它不仅探索了关键的演示配置策略，还深入研究了模型的内部机制，这在多模态 ICL 的研究中是一个重要的进步。新提出的基于注意力的指标和方法具有潜力，可以应用于更广泛的领域，这增加了该研究的价值和影响力。然而，研究可能还可以进一步探讨不同 LMM 架构对这些配置策略的敏感性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自然语言处理中的上下文内学习（ICL）已被广泛研究，但多模态 ICL 的演示配置探索仍处于初步阶段。本研究旨在通过外部和内部分析来解决这一问题，以了解和优化 LMM 在图像字幕生成任务中的 ICL 行为。

**Method:** 该研究结合了外部和内部方法来分析多模态 ICL。外部分析侧重于演示配置策略，考察了 the shot number、图像检索和字幕分配，并使用多种指标进行评估。内部分析则检查了 LMM 的注意力特征，开发了基于注意力的指标来量化模型行为，并进行了额外的实验来探索基于注意力的模型加速和压缩的可行性。此外，研究还比较了具有相同模型设计和预训练策略的 LMM 之间的性能差异，并从预训练数据特征的角度进行了解释。

**Result:** 外部实验表明，演示配置策略（包括 the shot number、图像检索和字幕分配）会影响 LMM 在图像字幕生成任务中的性能。内部分析揭示了 LMM 的注意力特征，并提出了新的基于注意力的指标来量化模型行为。研究还发现，基于注意力的分析可以用于模型加速和压缩，并且预训练数据特征可以解释具有相似设计但性能不同的 LMM 之间的差异。

**Conclusion:** 该研究通过外部和内部分析，全面地揭示了影响 LMM 在图像字幕生成任务中 ICL 性能的有效上下文内配置。研究结果强调了演示配置策略的重要性，并提供了对 LMM 行为的深入理解，其提出的方法和指标可推广到更广泛的研究领域。

> **ai_Abstract:** 本研究深入探讨了用于图像字幕生成的大型多模态模型（LMM）的上下文内学习（ICL）配置。通过外部实验，研究人员评估了 the shot number、图像检索和字幕分配等因素对模型性能的影响。内部分析则侧重于检查 LMM 的注意力机制，并开发了新的指标来量化模型行为。研究结果为理解和优化 LMM 的 ICL 性能提供了宝贵的见解，并提出了可推广到其他研究领域的方法和指标。

> **摘要翻译:** 大型模型的演进见证了上下文内学习（ICL）能力的出现。在自然语言处理（NLP）中，大量研究已经证明了 ICL 的有效性。受大型语言模型（LLM）成功的启发，研究人员开发了具有 ICL 能力的大型多模态模型（LMM）。然而，多模态 ICL 的演示配置探索仍然初步。此外，上下文内示例（ICEs）的可控性提供了一种高效且经济有效的方式来观察和分析 LMM 在不同输入下的推理特征。本研究对图像字幕任务中的多模态上下文内学习进行了全面的外部和内部研究。在外部，我们通过三个维度探索演示配置策略：shot number、图像检索和字幕分配。我们采用多种指标来系统而全面地评估和总结关键发现。在内部，我们分析了典型的 LMM 注意力特征，并开发了基于注意力的指标来量化模型行为。我们还进行了辅助实验，以探索基于注意力的模型加速和压缩的可行性。我们进一步比较了具有相同模型设计和预训练策略的 LMM 之间的性能差异，并从预训练数据特征的角度解释了这些差异。我们的研究揭示了 ICEs 配置策略如何通过外部实验影响模型性能，以及通过内部检查揭示典型的特征模式，从而提供了理解 LMM 中多模态 ICL 的双重视角。我们结合外部和内部分析来研究大型模型的方法，以及我们新提出的指标，可以应用于更广泛的研究领域。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [489] [Integrating External Tools with Large Language Models to Improve Accuracy](https://arxiv.org/abs/2507.08034)
> *将外部工具与大型语言模型集成以提高准确性*

*Nripesh Niketan, Hadj Batatia* | **Category: cs.CL, cs.AI, cs.LG, 68T50, I.2.7; I.2.6** | **Updated: 2025-07-09**

**Keywords:** 大型语言模型, 外部工具集成, Athena 框架, MMLU, 推理准确性

**Comment:** 9 pages, 3 figures, 2 tables. Extended version of paper published in
  Proceedings of International Conference on Information Technology and
  Applications, Springer Nature Singapore, 2025, pp. 409-421. This version
  includes additional experimental results comparing against GPT-4o,
  LLaMA-Large, Mistral-Large, and Phi-Large, expanded evaluation methodology,
  and enhanced analysis

> **TL;DR:** 本研究提出了一种名为 Athena 的框架，通过集成外部工具（如 API 和计算器）来增强大型语言模型的准确性，特别是在教育领域。实验证明，该框架在数学和科学推理方面显著优于现有模型，准确率分别达到 83% 和 88%。

**AI_Comments:** 该研究提出的 Athena 框架在解决 LLM 的幻觉和准确性问题方面取得了显著进展，特别是在数学和科学推理等需要精确计算和事实信息的领域。通过集成外部工具，该方法有效弥补了 LLM 的固有局限性。然而，框架的通用性、不同类型外部工具的集成效率以及在更广泛教育场景下的适用性仍有待进一步探索。此外，与 GPT-4o 等最先进模型的性能对比虽然令人鼓舞，但仍需关注模型在实际应用中的鲁棒性和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在缺乏相关上下文信息时，容易产生低质量的响应或出现幻觉。为了提高 LLMs 的准确性，本研究旨在通过集成外部工具来为 LLMs 提供最新的数据和计算能力。

**Method:** 提出一个框架，允许 LLMs 访问外部 API 以获取相关信息和利用计算能力（如计算器、日历）。该框架在 MMLU 数据集上进行了评估，该数据集包含数学和科学推理问题。

**Result:** 在 MMLU 数据集上，Athena 框架在数学推理方面达到 83% 的准确率，在科学推理方面达到 88% 的准确率。这显著优于包括 GPT-4o、LLaMA-Large、Mistral-Large、Phi-Large 和 GPT-3.5 在内的所有测试模型，其中表现最好的基线模型 LLaMA-Large 的准确率分别为 67% 和 79%。

**Conclusion:** 本研究提出的 Athena 框架能够显著提高 LLMs 在教育场景下回答数学和科学推理问题的准确性。这些成果为围绕 LLMs 构建复杂的计算生态系统铺平了道路，使 LLMs 在支持各种任务和活动时更加自然。

> **ai_Abstract:** 本研究提出了一种名为 Athena 的框架，旨在通过集成外部工具（如 API 和计算器）来提高大型语言模型（LLMs）在教育场景下的查询准确性。该框架通过提供相关上下文信息和计算能力来解决 LLMs 容易产生幻觉和低质量响应的问题。在 MMLU 数据集上的实验结果表明，Athena 框架在数学和科学推理任务上显著优于包括 GPT-4o 在内的多种最先进模型，准确率分别达到 83% 和 88%。这项工作为构建更强大的 LLM 应用生态系统提供了基础。

> **摘要翻译:** 本篇论文处理的是提高大型语言模型（LLMs）的查询能力。众所周知，在没有相关上下文信息的情况下，LLMs 可能会提供低质量的响应或倾向于产生幻觉。一些倡议提出将 LLMs 与外部工具集成，为它们提供最新的数据以提高准确性。在本篇论文中，我们提出一个框架，用于集成外部工具以增强 LLMs 在教育环境中回答查询的能力。具体来说，我们开发了一个允许访问外部 API 以请求其他相关信息的框架。集成工具还可以提供计算能力，如计算器或日历。所提出的框架已使用来自多模态语言理解（MMLU）集合的数据集进行评估。数据包含数学和科学推理方面的问题。与最先进的语言模型相比，结果表明所提出的方法显著提高了性能。我们的 Athena 框架在数学推理方面实现了 83% 的准确率，在科学推理方面实现了 88% 的准确率，在各项性能上均大幅超越了包括 GPT-4o、LLaMA-Large、Mistral-Large、Phi-Large 和 GPT-3.5 在内的所有测试模型，而表现最好的基线模型（LLaMA-Large）的准确率仅分别为 67% 和 79%。这些有前景的结果为围绕 LLMs 创建复杂的计算生态系统铺平了道路，使它们的用途更加自然，以支持各种任务和活动。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [504] [CRISP: Complex Reasoning with Interpretable Step-based Plans](https://arxiv.org/abs/2507.08037)
> *CRISP：基于可解释的步骤计划的复杂推理*

*Matan Vetzler, Koren Lazar, Guy Uziel, Eran Hirsch, Ateret Anaby-Tavor, Leshem Choshen* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-09**

**Keywords:** 复杂推理, 高层计划, 大型语言模型, CRISP数据集, 链式思考

**Comment:** 

> **TL;DR:** 该研究提出了CRISP数据集，用于训练模型生成高层计划以解决复杂问题，发现微调模型在计划生成上优于大型模型，且具有跨领域泛化能力。

**AI_Comments:** 这项研究通过引入CRISP数据集，为提高LLM的复杂推理能力提供了一个新的方向，即显式的高层计划生成。实验结果表明，该方法在计划生成质量和跨领域泛化能力上均优于现有的链式思考方法，具有重要的理论和实践意义。然而，数据集的规模和多样性可能仍有待进一步扩展，以更好地覆盖更广泛的复杂推理任务。

<details>
  <summary>Details</summary>

**Motivation:** 现有的链式思考（CoT）推理方法不足以解决复杂问题，而生成显式高层计划是一种有前景的替代方法，但现有方法假设少样本提示即可生成有效计划，但作者对此提出质疑。

**Method:** 作者提出了CRISP（Complex Reasoning with Interpretable Step-based Plans）数据集，包含用于数学推理和代码生成的多种高层计划。这些计划通过LLM进行内在验证，并通过下游任务性能进行外在验证。作者通过微调模型在CRISP数据集上进行了实验。

**Result:** 通过在CRISP数据集上微调模型，使其在生成高质量计划方面优于使用少样本提示的更大模型，并且显著优于链式思考（CoT）推理。此外，跨领域评估表明，在一个领域上的微调能够提升在另一个领域的计划生成能力，证明了学习到的计划能力的泛化性。

**Conclusion:** CRISP数据集的提出证明了显式高层计划生成对于复杂推理的重要性，并通过实验表明，通过在CRISP数据集上进行微调，模型可以有效地生成高质量的计划，并且这些计划生成能力具有良好的跨领域泛化性。

> **ai_Abstract:** 本研究介绍了CRISP数据集，旨在改进大型语言模型在复杂问题解决中的推理能力。与链式思考（CoT）方法不同，CRISP侧重于生成可解释的高层计划。研究表明，通过在CRISP数据集上微调模型，可以显著提升计划生成的质量和效率，甚至优于使用少样本提示的更大模型，并展现出良好的跨领域泛化能力。

> **摘要翻译:** 近期大型语言模型（LLM）的进展凸显了需要更强的推理能力来有效解决复杂问题。虽然链式思考（CoT）推理已取得进展，但对于许多领域来说仍然不足。一个有前景的替代方法是显式的高层计划生成，但现有方法在很大程度上假设LLM仅通过少样本提示即可生成有效的计划，而无需额外的训练。在本研究中，我们对这一假设提出了挑战，并引入了CRISP（Complex Reasoning with Interpretable Step-based Plans），这是一个包含数学推理和代码生成的高层计划的多领域数据集。CRISP中的计划是自动生成并经过严格验证的——内在验证使用LLM作为裁判，外在验证通过评估它们对下游任务性能的影响。我们证明，在CRISP上微调一个小模型能够生成比使用少样本提示的更大模型更高质量的计划，同时显著优于链式思考推理。此外，我们的跨领域评估显示，在一个领域上的微调能够提升在另一个领域的计划生成能力，突显了学习到的计划能力的泛化性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [511] [Diagnosing Failures in Large Language Models' Answers: Integrating Error Attribution into Evaluation Framework](https://arxiv.org/abs/2507.08459)
> *诊断大型语言模型答案中的失败：将错误归因整合到评估框架中*

*Zishan Xu, Shuyi Xie, Qingsong Lv, Shupei Xiao, Linlin Song, Sui Wenjuan, Fan Lin* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 错误归因,大型语言模型,评估框架,数据集,评判模型

**Comment:** 

> **TL;DR:** 本研究提出了一个包含6个主要类别和15个次要类别的错误归因框架（Misattribution Framework），并创建了一个名为AttriData的数据集，用于错误归因，包含错误归因、分数和反馈。此外，还提出了一个名为MisAttributionLLM的微调模型，这是第一个能够同时生成分数、错误归因和反馈的通用评判模型。实验证明了该方法的有效性和鲁棒性。

**AI_Comments:** 该研究解决了大型语言模型评估中的一个关键痛点：缺乏对模型错误进行细致归因的能力。通过构建一个详细的错误分类框架和专门的数据集，并开发一个能够同时处理评分、归因和反馈的集成模型，该研究为提高LLM的可靠性和可解释性提供了重要的方法。其创新性在于将错误归因这一概念系统化并融入评估流程，这对于模型的迭代改进和用户信任的建立具有重要意义。然而，该框架的全面性和泛化能力在不同类型的LLM和应用场景下的表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 为了高效地分析模型性能和诊断其答案中的错误，需要开发一个自动化的框架来系统地分类和归因错误。然而，现有的评估模型缺乏错误归因能力。

**Method:** 提出一个包含6个主要类别和15个次要类别的错误归因框架（Misattribution Framework）。创建了一个名为AttriData的数据集，用于错误归因，包含错误归因、分数和反馈。提出并微调了一个名为MisAttributionLLM的模型。

**Result:** MisAttributionLLM是第一个能够同时生成分数、错误归因和反馈的通用评判模型。

**Conclusion:** 所提出的方法在错误归因方面是有效和鲁棒的。

> **ai_Abstract:** 本研究针对大型语言模型（LLM）的答案评估问题，提出了一种集成错误归因的框架。研究人员创建了一个包含6个主要和15个次要类别的“错误归因框架”（Misattribution Framework），并构建了一个名为AttriData的数据集，该数据集包含错误归因信息、分数和反馈。基于此数据集，他们开发了一个名为MisAttributionLLM的微调模型，这是首个能同时生成分数、错误归因和反馈的通用评判模型。实验结果表明，该方法在评估LLM答案的准确性和诊断错误方面是有效且鲁棒的。

> **摘要翻译:** 随着大型语言模型（LLM）在各种任务中的广泛应用，主流的LLM平台每天都会产生大量的用户-模型交互。为了有效地分析模型的性能并诊断其答案中的失败，开发一个自动化的框架来系统地分类和归因错误至关重要。然而，现有的评估模型缺乏错误归因能力。在本研究中，我们建立了一个包含6个主要类别和15个次要类别的综合性错误归因框架（Misattribution Framework），以促进深入分析。基于该框架，我们提出了AttriData，一个专门为错误归因设计的、包含错误归因以及相应分数和反馈的数据集。我们还提出了MisAttributionLLM，一个在AttriData上微调的模型，它是第一个能够同时生成分数、错误归因和反馈的通用评判模型。通过广泛的实验和分析，证实了我们提出的方法的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [524] [AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research](https://arxiv.org/abs/2507.08038)
> *AblationBench：评估实证人工智能研究中的消融自动化规划*

*Talor Abramovich, Gal Chechik* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-09**

**Keywords:** 消融规划, AI 联合科学家, 语言模型, 基准套件, 链式思考提示

**Comment:** 

> **TL;DR:** AblationBench 是一个用于评估语言模型 (LM) 在实证人工智能研究中的消融实验规划能力的基准套件。它包含两个任务：AuthorAblation 和 ReviewerAblation。实验表明，即使是最好的 LM 也只能识别约 29% 的消融实验，这表明该领域仍有很大的改进空间。与现有的基于代理的方法相比，链式思考提示的表现更好。

**AI_Comments:** 该研究在评估语言模型在科学研究中的应用方面迈出了重要一步，特别是通过引入 AblationBench 来标准化消融实验规划的评估。然而，当前 LM 29% 的识别率表明，在让 AI 真正成为自主的“联合科学家”方面，仍有很长的路要走。未来的研究可以集中在改进 LM 的推理能力和对复杂科学文献的理解，以提高消融实验规划的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能（AI）在科学研究中的应用越来越广泛，需要支持或自动化研究过程中的关键部分，例如消融实验的设计。

**Method:** 提出 AblationBench，这是一个用于评估 AI 代理在实证 AI 研究的消融规划任务中的基准套件。该套件包含两个任务：AuthorAblation（基于方法部分提出消融实验，包含 83 个实例）和 ReviewerAblation（帮助审稿人发现论文中缺失的消融实验，包含 350 个实例）。研究人员还开发了基于 LM 的评估框架，并通过实验评估了当前先进的 LM。

**Result:** 在两个任务上，包括最好的 LM 系统在内，识别原始消融实验的比例平均仅为 29%，表明这些任务对当前的 LM 来说仍然是一个挑战。链式思考提示的性能优于现有的基于代理的方法。

**Conclusion:** AblationBench 基准套件的引入为评估 AI 代理在消融实验规划方面的能力提供了一个标准化的方法。实验结果表明，尽管 LM 在此领域取得了进展，但仍有显著的改进空间。链式思考提示被证明是一种比现有代理方法更有效的方法。

> **ai_Abstract:** 本文介绍了 AblationBench，一个用于评估 AI 代理在科学研究中设计消融实验能力的基准套件。该套件包含两个任务：AuthorAblation 和 ReviewerAblation，并使用基于 LM 的评估器进行评估。实验结果显示，当前 LM 在此任务上的表现仍有待提高，但链式思考提示的性能优于其他方法。

> **摘要翻译:** 基于语言模型的自主代理在包括科学研究在内的许多领域日益普及，AI 联合科学家旨在利用这些代理支持或自动化研究过程的各个部分。实证 AI 研究的一个关键组成部分是消融实验的设计。为此，我们引入了 AblationBench，这是一个用于评估代理在实证 AI 研究的消融规划任务中的基准套件。它包括两个任务：AuthorAblation，帮助作者根据方法部分提出消融实验，包含 83 个实例；ReviewerAblation，帮助审稿人发现完整论文中缺失的消融实验，包含 350 个实例。对于这两个任务，我们开发了基于 LM 的评估器，作为自动评估框架。我们对前沿 LM 的实验表明，这些任务仍然具有挑战性，表现最好的 LM 系统平均仅识别出 29% 的原始消融实验。最后，我们分析了当前 LM 在这些任务上的局限性，并发现链式思考提示的表现优于目前存在的基于代理的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [541] [Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing](https://arxiv.org/abs/2507.08045)
> *Krul：一种用于多轮对话的高效状态恢复方法，具有动态跨层KV共享*

*Junyi Wen, Junyuan Liang, Zicong Hong, Wuhui Chen, Zibin Zheng* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 多轮对话, KV缓存, 状态恢复, LLM推理, 动态压缩

**Comment:** 

> **TL;DR:** Krul是一种新的LLM推理系统，通过动态选择压缩策略和优化KV缓存恢复来提高多轮对话的效率，实现了更快的响应时间和更少的存储空间，同时不牺牲生成质量。

**AI_Comments:** Krul在解决多轮对话中KV缓存效率问题上取得了显著进展。其动态压缩策略和优化的恢复流程是该研究的亮点，有效地平衡了效率和准确性。然而，对于不同类型和长度的对话，其性能的鲁棒性以及在更广泛模型架构上的通用性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在多轮对话中恢复KV缓存时存在效率低下和准确性下降的问题，因为它们采用固定的压缩策略，忽略了对话特定的注意力动态。

**Method:** Krul通过三种创新来提高效率：1) 动态选择压缩策略以保留关键上下文；2) 逐个token的异构注意力相似度估计器以减少计算和存储开销；3) 无气泡恢复调度器以平衡重计算和加载流。

**Result:** Krul在实际任务中实现了1.5倍至2.68倍的首个token响应时间（TTFT）缩短和1.33倍至2.35倍的KV缓存存储减少，同时保持了生成质量。

**Conclusion:** Krul通过动态的、对话感知的KV缓存压缩和优化的恢复流程，能够高效且准确地处理多轮对话的状态恢复，优于现有方法。

> **ai_Abstract:** Krul是一种先进的多轮对话LLM推理系统，通过动态适应对话的注意力模式来优化KV缓存的压缩和恢复。它采用创新的策略选择、注意力相似度估计和恢复调度技术，显著减少了响应时间和存储需求，同时保持了原始的生成质量。

> **摘要翻译:** 在具有大型语言模型（LLM）的多轮对话中，高效的状态恢复仍然是一个严峻的挑战，这主要是由于需要为所有历史token重新计算或加载完整的键值（KV）缓存所带来的开销。为了解决这个问题，现有方法通过对具有高度相似注意模式的相邻层进行KV缓存压缩。然而，这些方法通常对所有对话应用固定的压缩方案，选择相同的层对进行压缩，而不考虑对话特定的注意力动态。这种静态策略忽略了不同对话中注意力模式相似性的可变性，可能导致明显的准确性下降。
  我们提出了Krul，一个多轮LLM推理系统，能够实现准确且高效的KV缓存恢复。Krul根据层对之间的注意力相似度动态选择压缩策略，并使用重计算-加载管道来恢复KV缓存。它引入了三个关键创新：1) 一个抢先式压缩策略选择器，用于为未来的对话轮保留关键上下文并为对话选择定制的策略；2) 一个逐个token的异构注意力相似度估计器，用于在模型生成期间减轻注意力相似度计算和存储的开销；3) 一个无气泡恢复调度器，以减少由压缩KV缓存引起的重计算和加载流不平衡可能带来的气泡。
  在真实世界任务上的实证评估表明，与最先进的方法相比，Krul在首个token响应时间（TTFT）方面实现了1.5倍至2.68倍的缩减，在KV缓存存储方面实现了1.33倍至2.35倍的缩减，而没有损害生成质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [543] [Using Large Language Models for Legal Decision-Making in Austrian Value-Added Tax Law: An Experimental Study](https://arxiv.org/abs/2507.08468)
> *使用大型语言模型进行奥地利增值税法的法律决策：一项实验研究*

*Marina Luketina, Andrea Benkel, Christoph G. Schuetz* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 法律决策, 增值税法, 微调, 检索增强生成

**Comment:** 26 pages, 5 figures, 6 tables

> **TL;DR:** 本研究评估了大型语言模型（LLM）在奥地利和欧盟增值税法领域的法律决策辅助能力。实验测试了微调和检索增强生成（RAG）两种方法，发现在处理教科书案例和真实案例时，经过适当配置的LLM能够有效支持税务顾问，提供法律依据。然而，LLM在处理隐含客户知识和特定上下文文档方面仍存在局限性，无法完全自动化，表明需要整合结构化背景信息。

**AI_Comments:** 该研究具有重要的实践意义，首次系统地评估了LLM在特定法律领域（奥地利增值税法）的决策辅助能力。通过对比微调和RAG两种主流技术，并结合真实案例进行测试，为LLM在法律领域的应用提供了实证依据。研究指出了LLM的潜力和局限性，特别是其在处理隐含信息和上下文理解方面的不足，这为未来研究指明了方向，即如何更好地将LLM与结构化数据和专业知识相结合，以克服“幻觉”问题，实现更可靠的法律辅助决策。

<details>
  <summary>Details</summary>

**Motivation:** 在税务咨询实践中，客户通常以自然语言描述案例，这使得大型语言模型（LLM）成为支持自动化决策和减轻税务专业人员工作负担的理想选择。然而，LLM的“幻觉”倾向对需要法律依据和充分论证的分析构成了重大挑战。

**Method:** 本研究采用实验方法，重点关注两种增强LLM性能的常用方法：微调（fine-tuning）和检索增强生成（retrieval-augmented generation, RAG）。这些方法被应用于教科书案例和税务咨询公司的真实案例，以系统地确定基于LLM的系统的最佳配置，并评估LLM的法律推理能力。

**Result:** 研究结果表明，经过适当配置的LLM能够有效支持税务专业人员处理增值税相关任务，并为决策提供法律依据。虽然LLM有潜力通过自动化例行任务和提供初步分析来支持税务顾问，但由于法律领域的敏感性，目前的模型尚未达到完全自动化的程度。LLM在处理隐含客户知识和上下文特定文档方面存在局限性。

**Conclusion:** 大型语言模型（LLM）在奥地利增值税法的法律决策辅助方面具有巨大潜力，能够支持税务顾问并提供法律依据。然而，由于在处理隐含信息和特定上下文方面的局限性，目前尚不能完全实现自动化，未来需要整合结构化背景信息。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLM）在奥地利和欧盟增值税法领域的法律决策支持能力。通过实验比较了微调和检索增强生成（RAG）两种技术在处理教科书案例和真实案例中的表现。研究发现，经过优化的LLM能够有效辅助税务顾问进行增值税相关的常规任务和初步分析，并提供法律依据。然而，由于法律领域的特殊性和LLM在处理隐含信息方面的不足，目前尚不能完全实现自动化，未来研究需关注如何整合结构化背景信息。

> **摘要翻译:** 本论文对大型语言模型（LLM）在奥地利和欧盟增值税法框架内协助法律决策的能力进行了实验评估。在税务咨询实践中，客户通常以自然语言描述案例，这使得LLM成为支持自动化决策和减轻税务专业人员工作负担的主要候选者。鉴于需要有法律依据且论证充分的分析，LLM产生“幻觉”的倾向构成了一个重大挑战。实验侧重于两种增强LLM性能的常用方法：微调和检索增强生成（RAG）。本研究将这些方法应用于教科书案例和来自税务咨询公司的真实案例，以系统地确定基于LLM的系统的最佳配置，并评估LLM的法律推理能力。研究结果强调了使用LLM通过自动化例行任务和提供初步分析来支持税务顾问的潜力，尽管目前的原型由于法律领域的敏感性尚未准备好完全自动化。研究结果表明，经过适当配置的LLM能够有效支持税务专业人员处理增值税相关任务，并为决策提供法律依据。然而，在处理隐含客户知识和上下文特定文档方面仍然存在局限性，这凸显了未来整合结构化背景信息的必要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [554] [KV Cache Steering for Inducing Reasoning in Small Language Models](https://arxiv.org/abs/2507.08799)
> *用于诱导小型语言模型推理的 KV 缓存引导*

*Max Belitsky, Dawid J. Kopiczko, Michael Dorkenwald, M. Jehanzeb Mirza, Cees G. M. Snoek, Yuki M. Asano* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 缓存引导,小型语言模型,链式思考,隐式引导,控制生成

**Comment:** 

> **TL;DR:** KV 缓存引导是一种通过对键值缓存进行单次干预来隐式引导语言模型的新方法，可诱导小型语言模型进行链式思考推理，无需微调或提示修改，并在推理结构和任务性能方面均有提升。

**AI_Comments:** 该研究提出的缓存引导方法在不进行微调或修改提示的情况下，通过单次干预即可有效引导小型语言模型进行链式思考推理，展示了其在控制生成方面的潜力和优势。与现有技术相比，该方法在效率和易用性方面表现突出，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 需要一种轻量级的方法来隐式引导语言模型，以诱导小型语言模型进行链式思考推理。

**Method:** 提出了一种名为缓存引导的新方法，该方法通过直接对键值缓存进行单次干预来实现隐式引导。使用 GPT-4o 生成的推理轨迹来构建引导向量，以改变模型行为，使其进行更明确的多步推理。

**Result:** 缓存引导在推理结构和量化任务性能方面均有所提升。与需要连续干预的先前激活引导技术相比，单次缓存引导在超参数稳定性、推理效率和集成简易性方面具有优势。

**Conclusion:** 缓存引导是一种有效且实用的控制生成的方法，无需微调或提示修改，即可诱导小型语言模型进行链式思考推理，并在推理质量和任务性能方面均有提升。

> **ai_Abstract:** 该研究提出了一种名为缓存引导的新型轻量级方法，通过对键值缓存进行一次性干预，即可隐式地引导小型语言模型进行链式思考推理。该方法利用 GPT-4o 生成的推理轨迹来构建引导向量，从而在不进行微调或修改提示的情况下，促使模型产生更明确的多步推理过程。实验结果表明，缓存引导不仅优化了模型推理的结构，还提高了量化任务的性能。与以往需要持续干预的激活引导技术相比，缓存引导具有超参数稳定性好、推理效率高、易于集成等优点，是一种更稳定、更实用的控制生成方法。

> **摘要翻译:** 我们提出了一种名为缓存引导的轻量级方法，通过直接对键值缓存进行单次干预来实现对语言模型的隐式引导。为了验证其有效性，我们将缓存引导应用于诱导小型语言模型进行链式思考推理。我们的方法利用 GPT-4o 生成的推理轨迹来构建引导向量，以在不进行微调或提示修改的情况下，将模型行为转向更明确的多步推理。在各种推理基准上的实验评估表明，缓存引导在模型推理的定性结构和量化任务性能方面均有所提升。与需要连续干预的先前激活引导技术相比，我们的一次性缓存引导在超参数稳定性、推理效率和集成简易性方面具有显著优势，使其成为一种更鲁棒、更实用的控制生成解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [571] [ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual Speech Recognition](https://arxiv.org/abs/2507.08477)
> *ILT-迭代LoRA训练通过关注-反馈-修复以实现多语言语音识别*

*Qingliang Meng, Hao Wu, Wei Liang, Wei Xu, Qing Zhao* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 迭代LoRA训练, 过拟合, 多语言语音识别, 伪标签, Whisper

**Comment:** Accepted By Interspeech 2025 MLC-SLM workshop as a Research Paper

> **TL;DR:** 为了解决LoRA在SFT阶段的过拟合问题，提出了一种名为ILT的迭代LoRA训练方法，并结合迭代伪标签策略来提升模型性能。该方法在Whisper-large-v3和Qwen2-Audio上进行了三阶段（Focus, Feed Back, Fix）训练，并在Interspeech 2025 MLC-SLM挑战赛中取得了优异成绩。

**AI_Comments:** 该研究提出的ILT方法有效地解决了LoRA在微调大型语音识别模型时常见的过拟合问题，并通过多阶段训练和伪标签策略进一步提升了模型性能。在多语言语音识别任务中取得的竞赛成绩也证明了该方法的实际有效性和应用价值。不过，摘要中未详细说明“关注”、“反馈”和“修复”这三个训练阶段的具体内容和机制。

<details>
  <summary>Details</summary>

**Motivation:** 深度整合大语言模型和自动语音识别系统是一个有前景的研究方向。LoRA在SFT阶段容易出现过拟合问题，需要一种新的训练范式来解决。

**Method:** 提出了一种名为ILT（Iterative LoRA Training）的创新训练范式，并结合迭代伪标签策略。该方法分为三个阶段：Focus Training、Feed Back Training和Fix Training。

**Result:** 实验结果证明了所提出方法（ILT）的有效性。该方法在Interspeech 2025 MLC-SLM挑战赛的两个任务中均取得优异成绩，分别获得Track 1（多语言ASR任务）第四名和Track 2（语音分离和识别任务）第一名。

**Conclusion:** 所提出的ILT训练范式结合迭代伪标签策略，能够有效解决LoRA在SFT阶段的过拟合问题，并提升模型性能。该方法具有很强的实际应用潜力。

> **ai_Abstract:** 本研究提出了一种名为ILT（Iterative LoRA Training）的创新训练范式，旨在解决大型语言模型在语音识别任务中，使用LoRA进行微调时出现的过拟合问题。ILT结合了迭代伪标签策略，并采用“关注-反馈-修复”的三阶段训练过程。实验结果表明，该方法有效提升了模型性能，并在实际的Interspeech 2025多语言对话语音语言建模挑战赛中取得了显著成果，证明了其强大的应用潜力。

> **摘要翻译:** 深度集成大型语言模型和自动语音识别系统已成为一个具有高实践价值的有前途的研究方向。为了解决在监督微调（SFT）阶段通常观察到的低秩自适应（LoRA）的过拟合问题，本研究提出了一个创新的训练范式——迭代LoRA训练（ILT），并结合迭代伪标签策略，有效提高了模型性能的理论上限。基于Whisper-large-v3和Qwen2-Audio，我们进行了系统的实验，采用三阶段训练过程：关注训练、反馈训练和修复训练。实验结果证明了所提出方法的有效性。此外，MegaAIS研究团队将该技术应用于Interspeech 2025多语言对话语音语言建模挑战赛（MLC-SLM），在Track 1（多语言ASR任务）中获得第四名，在Track 2（语音分离和识别任务）中获得第一名，展示了我们方法的实际可行性和强大的应用潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [583] [One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning](https://arxiv.org/abs/2504.18246)
> *一次通过推理：令牌重复和块稀疏掩码以实现多轮推理的高效微调*

*Ritesh Goru, Shanay Mehta, Prateek Jain* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 多轮推理, 大型语言模型, 微调, 令牌重复, 块稀疏掩码

**Comment:** 9 pages, 3 figures

> **TL;DR:** 该研究提出了一种名为“一次通过推理”的方法，通过重复响应令牌和使用自定义注意力掩码，将多轮推理的微调从需要多次前向传播优化为单次前向传播，从而降低了时间复杂度，同时保持了准确性。

**AI_Comments:** 这项研究通过引入令牌重复和块稀疏掩码，有效地解决了多轮推理微调中的效率问题，将时间复杂度从O(N^3)降低到O(N^2)，这是一个重要的改进。该方法在保持准确性的同时提高了训练速度，并且代码已公开，具有很高的实践价值。然而，对于不同模型架构和不同复杂度的推理任务，该方法的效果仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLMs）进行多轮推理，由于推理令牌在后续轮次中被丢弃，需要每次对话进行N次独立的前向传播，这导致了效率低下。

**Method:** 提出了一种将响应令牌与自定义注意力掩码相结合的方法，以实现对整个对话的单次前向传播处理。

**Result:** 该方法实现了与N次前向传播方法相同的损失，同时将时间复杂度从O(N^3)降低到O(N^2)，并保持了相同的内存复杂度，显著加快了训练速度，同时保持了准确性。

**Conclusion:** 该研究提出了一种通过令牌重复和块稀疏掩码实现高效多轮推理微调的方法，该方法在不牺牲准确性的前提下，显著提高了训练速度。

> **ai_Abstract:** 本研究提出了一种名为“一次通过推理”的新方法，用于高效地微调大型语言模型（LLMs）进行多轮推理。该方法通过复制响应令牌并引入块稀疏注意力掩码，将原本需要多次前向传播（N次）才能处理的对话，优化为单次前向传播。这种优化显著降低了时间复杂度，从N的立方降至N的平方，同时保持了内存效率和模型准确性，从而实现了更快的训练速度。

> **摘要翻译:** 微调大型语言模型（LLMs）进行多轮推理，由于推理令牌可见性限制，每次对话需要N次独立的前向传播，因为推理令牌会被后续轮次丢弃。我们提出通过复制响应令牌并结合自定义注意力掩码，实现对整个对话的单次前向传播处理。我们证明了我们的方法产生的损失与N次前向传播方法相同，同时将时间复杂度从$Oigl(N^{3}igl)$降低到$Oigl(N^{2}igl)$，并保持了基于Transformer模型的相同内存复杂度。我们的方法在保持准确性的同时实现了显著的训练加速。我们的实现可在网上获得（https://github.com/devrev/One-Pass-to-Reason）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [589] [Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores](https://arxiv.org/abs/2507.08143)
> *Compactor：具有近似杠杆分数的校准查询无关 KV 缓存压缩*

*Vivek Chari, Benjamin Van Durme* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-10**

**Keywords:** KV 缓存压缩, 大型语言模型, 查询无关压缩, 近似杠杆分数, 上下文校准

**Comment:** 

> **TL;DR:** Compactor 是一种新的无参数、查询无关的 KV 缓存压缩方法，它使用近似杠杆分数来识别重要 token，从而在不影响性能的情况下将 KV 缓存大小减半。通过上下文校准，它可以在 Longbench 上将 KV 内存占用减少 63%。

**AI_Comments:** 该研究提出了一种新颖的 KV 缓存压缩方法 Compactor，它在不了解查询的情况下，利用近似杠杆分数来识别重要 token，从而在不影响性能的情况下显著减少内存占用。上下文校准程序的引入进一步提高了压缩效率，在实际应用中显示出巨大的潜力。然而，该方法在处理极端长上下文或高度动态查询时的鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型语言模型（LLM）需要处理非常大的上下文窗口，但 KV 缓存的内存需求会随着上下文长度线性增长，成为部署中的主要瓶颈，限制了吞吐量并增加了服务成本。

**Method:** Compactor 采用一种无参数、查询无关的策略，利用近似杠杆分数来确定 token 的重要性，从而压缩 KV 缓存。

**Result:** Compactor 在保留一半 token 的情况下，在合成和真实世界的上下文任务中达到了与竞争方法相当的性能，并且计算开销极小。通过上下文校准，它在 Longbench 上实现了完整的 KV 性能，平均将 KV 内存占用减少了 63%。

**Conclusion:** Compactor 是一种有效的查询无关 KV 缓存压缩策略，通过近似杠杆分数和上下文校准，可以在不损害性能的情况下显著减少内存占用，并展现了良好的通用性，适用于 Qwen 2.5 和 Llama 3.1 等模型。

> **ai_Abstract:** Compactor 是一种创新的、无参数的、查询无关的 KV 缓存压缩技术，它利用近似杠杆分数来识别和压缩不重要的 token。该方法在不牺牲性能的情况下将 KV 缓存大小减半，并通过上下文校准程序进一步优化，在 Longbench 基准测试中实现了平均 63% 的内存减少，同时保持了模型的整体性能。Compactor 在 Qwen 2.5 和 Llama 3.1 等模型上进行了广泛验证，证明了其有效性和通用性。

> **摘要翻译:** 现代大型语言模型（LLM）正日益被训练以支持非常大的上下文窗口。不幸的是，在生成过程中使用长上下文的能力因 KV 缓存的大内存需求而变得复杂，而 KV 缓存的内存需求随着上下文长度线性增长。这种内存占用通常是实际部署中主要的资源瓶颈，限制了吞吐量并增加了服务成本。解决此问题的一种方法是压缩 KV 缓存，这可以通过了解正在询问的问题（查询感知）或在不知道查询（查询无关）的情况下进行。我们提出了 Compactor，一种无参数、查询无关的 KV 压缩策略，它使用近似杠杆分数来确定 token 的重要性。我们表明，Compactor 在保留一半 token 的情况下，在合成和真实世界的上下文任务中可以达到与竞争方法相当的性能，并且计算开销极小。我们进一步引入了一种用于上下文校准压缩的程序，该程序允许推断给定上下文可以支持的最大压缩率。使用上下文校准压缩，我们表明 Compactor 在 Longbench 上实现了完整的 KV 性能，平均将 KV 内存占用减少了 63%。为了证明我们方法的有效性和通用性，我们将 Compactor 应用于来自 RULER 和 Longbench 的 27 个合成和真实世界任务，模型来自 Qwen 2.5 和 Llama 3.1 系列。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [595] [A Third Paradigm for LLM Evaluation: Dialogue Game-Based Evaluation using clembench](https://arxiv.org/abs/2507.08491)
> *大语言模型评估的第三范式：使用clembench的对话博弈评估*

*David Schlangen, Sherzod Hakimov, Jonathan Jordan, Philipp Sadler* | **Category: cs.CL** | **Updated: 2025-07-11**

**Keywords:** 大语言模型评估, 对话博弈, clembench, 参考评估, 偏好评估

**Comment:** All code required to run the benchmark, as well as extensive
  documentation, is available at https://github.com/clembench/clembench

> **TL;DR:** 本文提出了一种新的大语言模型评估范式——基于对话博弈的评估，并介绍了其实现工具clembench。

**AI_Comments:** 该研究提出了一种有前景的大语言模型评估新范式，解决了现有方法的局限性。clembench的开发和易用性是关键贡献，有望推动该领域的研究和应用。然而，抽象中并未详细说明“对话博弈”的具体机制和评估指标，以及clembench在处理不同类型LLM任务时的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型评估范式（基于参考和基于偏好）各有优缺点，需要一种结合两者优势的评估方法，但缺乏成熟易用的实现。

**Method:** 提出并介绍了一个名为clembench的对话博弈评估框架，该框架支持多轮、无参考、可重复的交互，并强调目标导向性。clembench自2023年起持续开发，易于使用，并可扩展。

**Result:** clembench已优化并易于通用，可用于评估自有模型（提供英文基准博弈实例），也可轻松扩展新的定制化测试。

**Conclusion:** 对话博弈评估是一种有用的LLM评估范式，clembench的出现解决了其在易用性和可复用性方面存在的瓶颈，有望促进该范式的广泛应用。

> **ai_Abstract:** 本文介绍了一种新的大语言模型评估范式——基于对话博弈的评估，并发布了相应的工具clembench。该范式结合了现有评估方法的优点，能够进行可控、多轮、无参考且可重复的交互评估，同时注重目标导向性。clembench易于使用和扩展，支持对自有模型进行基准测试，并能添加定制化测试用例。

> **摘要翻译:** 目前，评估大型语言模型（LLM）主要有两种范式：基于参考的评估和基于偏好的评估。第一种范式沿用于机器学习模型的一般评估，依赖于预定义的任务实例，并提供参考任务执行结果。第二种范式以LM-arena为代表，依赖于（通常是用户自选的）用户，他们将自己的意图带到一个网站，该网站将这些意图并行路由到多个模型，然后用户从中选择他们最喜欢的响应。因此，前一种范式在测试控制方面表现出色，而后者则具有更高的生态有效性，通过交互测试实际用例。最近，出现了一种结合这两种方法优点的第三种补充范式，它提供了对多轮、无参考、可重复交互的控制，同时强调目标导向性：基于对话博弈的评估。虽然这种方法的效用已被多个项目证明，但由于缺乏成熟、易于重用的实现，其推广一直受到阻碍。在本文中，我们介绍了clembench，它自2023年以来一直在持续开发，并在最新版本中进行了优化，以方便通用使用。我们描述了如何使用它来评估自有模型（使用提供的一组英文基准博弈实例），以及如何轻松地扩展基准本身，加入新的、量身定制的定向测试。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [606] [Red Teaming Large Language Models for Healthcare](https://arxiv.org/abs/2505.00467)
> *红队演练医疗领域的大型语言模型*

*Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Mark Coatsworth, Kaivalya Deshpande, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Amrit Krishnan, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Iñigo Urteaga, Stephanie Williams, Rahul G Krishnan* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 红队演练, 大型语言模型, 医疗保健, AI安全, 临床漏洞

**Comment:** 

> **TL;DR:** 该论文介绍了在2024年机器学习医疗会议上关于红队演练医疗领域大型语言模型的会前研讨会的设计过程和发现，强调了临床医生在发现可能导致临床伤害的大型语言模型漏洞方面的作用。

**AI_Comments:** 这项工作强调了在AI安全领域，特别是医疗保健等高风险领域，跨学科合作的重要性。将临床专业知识纳入AI模型的测试过程，可以更有效地识别出潜在的危害，这是AI开发中一个经常被忽视但至关重要的方面。然而，论文的局限性在于其结果的普遍性可能受限于参与研讨会的特定人群和模型。

<details>
  <summary>Details</summary>

**Motivation:** 旨在发现大型语言模型在医疗领域的潜在漏洞，特别是那些可能导致临床伤害的漏洞，并强调了结合临床专业知识的重要性。

**Method:** 通过组织一个包含计算和临床专业知识的混合参与者的会前研讨会，让参与者尝试发现大型语言模型在医疗领域的漏洞，然后对发现的漏洞进行分类，并进行一项评估所有提供的大型语言模型漏洞的复制研究。

**Result:** 识别并分类了大型语言模型在医疗领域可能导致临床伤害的漏洞，并通过复制研究评估了这些漏洞在不同模型上的普遍性。

**Conclusion:** 红队演练方法，特别是结合临床专业知识的红队演练，能够有效地识别出大型语言模型在医疗领域可能存在的、未被缺乏临床经验的模型开发者发现的漏洞。

> **ai_Abstract:** 这篇论文总结了在2024年机器学习医疗会议上举行的关于医疗领域大型语言模型红队演练的研讨会。研讨会汇集了计算和临床专家，旨在识别可能导致临床伤害的LLM漏洞。研究发现，临床医生的参与对于发现模型开发者可能忽略的漏洞至关重要。论文还报告了所发现漏洞的分类以及一项评估这些漏洞在不同LLM中普遍性的复制研究。

> **摘要翻译:** 我们介绍了在2024年机器学习医疗会议（2024年8月15日）上题为“红队演练医疗领域的大型语言模型”的会前研讨会的设计过程和发现。会议参与者由计算和临床专业知识组成，他们试图发现漏洞——即大型语言模型（LLM）输出可能导致临床伤害的响应的真实临床提示。与临床医生进行红队演练有助于识别那些缺乏临床专业知识的大型语言模型开发者可能无法识别的LLM漏洞。我们报告了发现的漏洞，对它们进行了分类，并展示了一项评估所有提供的大型语言模型漏洞的复制研究结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [203] [On the Parallel Complexity of Finding a Matroid Basis](https://arxiv.org/abs/2507.08194)
> *关于寻找拟阵基的并行复杂性*

*Sanjeev Khanna, Aaron Putterman, Junkai Song* | **Category: cs.DS** | **Updated: 2025-07-10**

**Keywords:** 拟阵, 并行计算, 拟阵基, 划分拟阵, 复杂性

**Comment:** 

> **TL;DR:** 本文首次在并行计算中寻找拟阵基的问题上取得了进展，将任意拟阵的并行上界从$O(\sqrt{n})$提升到$\tilde{O}(n^{7/15})$，并解决了划分拟阵的轮次复杂性。

**AI_Comments:** 本文在并行计算理论中取得了重要的突破，首次改进了寻找拟阵基的并行复杂性上界，打破了近四十年的停滞。其提出的新颖拟阵分解技术具有普适性，不仅提升了对任意拟阵的处理能力，还为特定类型的拟阵（如划分拟阵）提供了精确的复杂度解决方案，对该领域具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决Karp、Upfal和Wigderson于1985年提出的一个关于在仅有独立性预言机访问权限下寻找拟阵基的并行计算基本问题，此前该问题的$O(\sqrt{n})$上界和$\widetilde{\Omega}(n^{1/3})$下界已保持未改进多年。

**Method:** 本文引入了一种新颖的拟阵分解技术和其他结构性见解。

**Result:** 设计了一种并行算法，以高概率在$\tilde{O}(n^{7/15})$轮内找到任意拟阵的基，突破了长期存在的$O(\sqrt{n})$障碍。为划分拟阵开发了一种$\tilde{O}(n^{1/3})$-轮算法，从而解决了划分拟阵中寻找基的轮次复杂性。

**Conclusion:** 本文首次缩小了寻找拟阵基的并行复杂性上界与下界之间的差距，并彻底解决了划分拟阵的轮次复杂性。

> **ai_Abstract:** 本文解决了并行计算中寻找拟阵基的长期开放问题。研究者通过引入新颖的拟阵分解技术，将任意拟阵的并行上界从$O(\sqrt{n})$改进到$\tilde{O}(n^{7/15})$。此外，该工作还为划分拟阵设计了$\tilde{O}(n^{1/3})$-轮算法，从而完全确定了其寻找基的轮次复杂性。

> **摘要翻译:** 并行计算中的一个基本问题，由Karp、Upfal和Wigderson（FOCS 1985，JCSS 1988）提出：仅在给定$n$个元素的拟阵的独立性预言机访问权限下，需要多少轮才能使用多项式次查询找到一个基？这个问题概括了线性空间、划分拟阵和图中生成森林的基的复杂性等。在他们的工作中，他们为这个问题建立了$O(\sqrt{n})$轮的上界和$\widetilde{\Omega}(n^{1/3})$轮的下界，并且这些界限自那时以来一直未得到改进。在这项工作中，我们通过设计一种并行算法，首次在缩小这一差距方面取得了进展，该算法以高概率在$\tilde{O}(n^{7/15})$轮内找到任意拟阵的基（每轮使用多项式次独立性查询），超越了长期存在的$O(\sqrt{n})$障碍。我们的方法引入了一种新颖的拟阵分解技术和其他结构性见解，这不仅产生了这一普遍结果，而且还为划分拟阵（Karp、Upfal和Wigderson的$\widetilde\Omega(n^{1/3})$下界的基础）类别带来了大大改进的新算法。具体来说，我们开发了一种$\tilde{O}(n^{1/3})$-轮算法，从而解决了在划分拟阵中寻找基的轮次复杂性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [226] [Approximation Algorithms for the Cumulative Vehicle Routing Problem with Stochastic Demands](https://arxiv.org/abs/2507.08316)
> *具有随机需求的累积车辆路径问题的近似算法*

*Jingyang Zhao, Mingyu Xiao* | **Category: cs.DS** | **Updated: 2025-07-11**

**Keywords:** 累积车辆路径问题, 随机需求, 近似算法, 车辆路径问题, 优化

**Comment:** 

> **TL;DR:** 本文为具有随机需求的累积车辆路径问题（Cu-VRPSD）提出了改进的随机近似算法，同时作为推论，也改进了随机需求车辆路径问题（VRPSD）和累积车辆路径问题（Cu-VRP）的近似比。

**AI_Comments:** 本文的主要创新在于为具有随机需求的累积车辆路径问题及其变体提供了更优的近似算法，显著提升了这些NP-hard问题的求解效率和质量。通过改进现有最佳近似比，该研究对车辆路径优化领域的理论和实践都具有重要意义。特别是在需求不确定性高的实际应用场景中，这些改进的算法能够提供更鲁棒和高效的路径规划方案。

<details>
  <summary>Details</summary>

**Motivation:** 针对累积车辆路径问题（Cu-VRP）及其随机需求变体（Cu-VRPSD），以及随机需求车辆路径问题（VRPSD），旨在改进现有算法的近似比，以获得更优的解决方案。

**Method:** 本文提出了随机近似算法。具体地，针对Cu-VRPSD、VRPSD和Cu-VRP，设计了新的随机近似算法，并基于度量TSP的1.5近似比假设进行分析。

**Result:** 对于Cu-VRPSD，提出了一个随机3.456-近似算法，将最佳已知近似比从6提高到3.456。对于VRPSD（作为Cu-VRPSD的特例），得到了一个随机3.25-近似算法，将最佳已知近似比从3.5提高到3.25。对于Cu-VRP，给出了一个随机3.194-近似算法，将最佳已知近似比从4提高到3.194。此外，如果允许每个客户通过多次行程满足需求，Cu-VRPSD和Cu-VRP的近似比可以进一步改善。

**Conclusion:** 本文通过引入新的随机近似算法，显著改善了Cu-VRPSD、VRPSD和Cu-VRP这三类车辆路径问题的近似比，尤其是在客户需求随机或允许多次行程的情况下，提供了更高效的解决方案。

> **ai_Abstract:** 本文研究了具有随机需求的累积车辆路径问题（Cu-VRPSD）及其相关变体，包括随机需求车辆路径问题（VRPSD）和累积车辆路径问题（Cu-VRP）。作者提出了新的随机近似算法，显著改善了这些问题的近似比。具体而言，Cu-VRPSD的近似比从6提高到3.456，VRPSD从3.5提高到3.25，Cu-VRP从4提高到3.194。研究还指出，在允许客户通过多次行程满足需求的情况下，近似比可以得到进一步的提升。

> **摘要翻译:** 在累积车辆路径问题（Cu-VRP）中，我们需要为位于车库的具有容量限制的车辆找到一个可行的行程，以满足客户需求，这与著名的车辆路径问题（VRP）类似，但目标是最小化基于车辆在整个行程中负载的累积成本。如果每个客户的需求在车辆访问之前都是未知的，则该问题称为具有随机需求的Cu-VRP（Cu-VRPSD）。假设度量TSP的近似比为1.5。在本文中，我们为Cu-VRPSD提出了一个随机3.456-近似算法，将最佳已知近似比6（Discret. Appl. Math. 2020）提高。由于具有随机需求的VRP（VRPSD）是Cu-VRPSD的一个特例，因此作为推论，我们还为VRPSD获得了随机3.25-近似算法，将最佳已知近似比3.5（Oper. Res. 2012）提高。对于Cu-VRP，我们给出了一个随机3.194-近似算法，将最佳已知近似比4（Oper. Res. Lett. 2013）提高。此外，如果每个客户允许通过多次行程满足需求，我们对Cu-VRPSD和Cu-VRP获得了进一步的改进。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [251] [H-Planarity and Parametric Extensions: when Modulators Act Globally](https://arxiv.org/abs/2507.08541)
> *H-平面性和参数化扩展：当调制器全局作用时*

*Fedor V. Fomin, Petr A. Golovach, Laure Morelle, Dimitrios M. Thilikos* | **Category: cs.DS, cs.DM** | **Updated: 2025-07-11**

**Keywords:** H-平面性, 调制器, 图分解, 参数化算法, 树宽

**Comment:** 

> **TL;DR:** 引入基于调制器/目标方案的图分解，定义H-平面性及其参数化扩展（H-平面树深、H-平面树宽），并证明其在特定条件下可多项式时间求解，从而为多种图问题提供FPT和近似算法。

**AI_Comments:** 这篇论文的创新点在于引入了“H-平面性”及其相关的“H-平面树深”和“H-平面树宽”等新概念，并将其与调制器/目标图修改方案相结合。通过证明在特定条件下这些新概念的可解性，并将其与现有算法融合，极大地扩展了平面图算法的应用范围和参数化算法的设计空间。其重要性体现在为许多经典的图问题（如图着色、完美匹配、最大独立集）提供了新的高效算法或近似方案，显示了这些新定义的强大算法潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过基于调制器/目标方案的图分解来扩展平面性的算法潜力，解决图修改问题并开发新的参数化算法。

**Method:** 1. 引入一系列基于调制器/目标方案的图分解。2. 提出一种计算平面H-调制器的多项式时间算法。3. 定义H-平面性问题：判断图G是否具有平面H-调制器。4. 引入H-平面树深和H-平面树宽作为H-平面性的参数化扩展，推广了消除距离和树分解的概念。

**Result:** 1. 证明如果H是遗传的、CMSO可定义的且多项式时间可判定的，则H-平面性在多项式时间内可解。2. 将此结果与现有的各种H-调制器问题的FPT算法结合，得到了针对多种图类别的、由H-平面树深和H-平面树宽参数化的FPT算法。3. 发现计算H-平面树深和H-平面树宽的方法带来了多种算法应用，例如：对于有界H-平面树深或H-平面树宽的图，可以得到图着色的加性近似算法和计数（加权）完美匹配的多项式时间算法。4. 为包括最大独立集在内的多个问题设计了高效多项式时间近似方案（EPTAS）。

**Conclusion:** 论文成功引入了H-平面性及其参数化扩展，并证明了在特定条件下这些概念的算法可解性，为多种图问题提供了高效的算法和近似方案，显著扩展了平面图算法的应用范围。

> **ai_Abstract:** 本文引入了基于调制器/目标方案的图分解，旨在扩展平面性的算法潜力。核心贡献是提出了一种计算平面H-调制器的多项式时间算法，并定义了H-平面性问题。研究证明，在H类图满足特定条件时，H-平面性问题可在多项式时间内解决。此外，论文引入了H-平面树深和H-平面树宽的概念作为H-平面性的参数化扩展，并结合现有FPT算法，为多种图类提供了由这些新参数化定义的FPT算法。这些新方法带来了广泛的算法应用，包括图着色的近似算法、完美匹配的计数算法，以及针对最大独立集等问题的EPTAS。

> **摘要翻译:** 我们引入了一系列基于调制器/目标修改方案的图分解，这些分解能够实现多种算法应用，参数化地扩展了平面性的算法潜力。我们方法的核心是计算平面H-调制器的多项式时间算法。给定一个图类H，图G的平面H-调制器是一个集合X \subseteq V(G)，使得X的“躯干”是平面的，并且G - X的所有连通分量都属于H。这里，X的躯干是从G[X]获得的，具体是对于G-X的每个连通分量，我们将其在G[X]上的邻域形成一个团。我们引入H-平面性，作为判断图G是否具有平面H-调制器的问题。我们证明，如果H是遗传的、CMSO可定义的且在多项式时间内可判定的，那么H-平面性在多项式时间内是可解的。此外，我们通过定义H-平面树深和H-平面树宽的概念，引入了H-平面性的两个参数化扩展，这些概念将消除距离和树分解推广到类H。将此结果与现有针对各种H-调制器问题的FPT算法相结合，我们从而获得了针对众多图类H的、由H-平面树深和H-平面树宽参数化的FPT算法。通过结合平面图和有界树宽图的众所周知的算法特性，我们计算H-平面树深和H-平面树宽的方法带来了多种算法应用。例如，一旦我们知道给定图具有有界H-平面树深或有界H-平面树宽，我们就可以推导出图着色的加性近似算法和计数（加权）完美匹配的多项式时间算法。此外，我们为包括最大独立集在内的多个问题设计了高效多项式时间近似方案（EPTAS）。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [281] [Beer Path Problems in Temporal Graphs](https://arxiv.org/abs/2507.08685)
> *时间图中的啤酒路径问题*

*Andrea D'Ascenzo, Giuseppe F. Italiano, Sotiris Kanellopoulos, Anna Mpanti, Aris Pagourtzis, Christos Pergaminelis* | **Category: cs.DS** | **Updated: 2025-07-11**

**Keywords:** 时间图, 啤酒路径问题, 路径查找, 时间依赖网络, 图算法

**Comment:** 

> **TL;DR:** 在时间图中引入并解决了啤酒路径问题，提出了高效算法和预处理技术，以处理时间依赖和动态条件。

**AI_Comments:** 该论文创新性地将一个已知的图问题（啤酒路径）扩展到更现实和复杂的时间图领域，这对于交通和物流等现实应用至关重要。重点在于定义新的问题变体，开发出与现有时间寻路算法复杂度相当的高效算法，以及处理动态查询，这突出了其应用价值和理论严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的啤酒路径问题研究主要集中在静态图上，但现实世界场景中（如交通服务时刻表、商店营业时间）时间信息至关重要，现有方法未能考虑这一关键的时间依赖性。

**Method:** 作者引入了时间图中啤酒路径的概念，其中边是时间相关的，特定顶点（啤酒顶点）仅在特定时间活跃。他们正式定义了计算最早到达、最晚出发、最快和最短时间啤酒路径的问题。论文提出了在边流和邻接列表表示下解决这些问题的有效算法。此外，还提出了预处理技术，通过预计算选定路径或将时间图转换为等效静态图，以实现在动态条件下（如商店开闭）的高效查询回答。

**Result:** 所提出的算法的时间复杂度与相应的时间寻路算法一致，保持了效率。预处理技术使得在动态条件下能够高效地回答查询。

**Conclusion:** 该工作将啤酒路径问题扩展到时间图，提供了高效的解决方案和动态查询能力，使其更适用于现实世界场景。

> **ai_Abstract:** 本论文将“啤酒路径问题”的概念从静态图扩展到时间图，解决了现有方法忽略现实世界时间依赖性的局限。它正式定义了各种时间啤酒路径问题（最早到达、最晚出发、最快、最短），并提出了高效的算法，其效率与标准时间寻路算法相当。此外，论文还引入了预处理技术，以处理时间图中的动态变化，实现高效的查询回答。

> **摘要翻译:** 在图结构中计算路径是广泛应用中的一项基本操作，从交通网络到数据分析。啤酒路径问题，即在到达最终目的地之前可以选择访问兴趣点（如加油站或便利店）的问题，最近在静态图中被提出并广泛研究。然而，现有方法没有考虑时间信息，而这在现实世界场景中通常至关重要。例如，交通服务可能遵循固定时刻表，商店可能只在特定时间开放。
  在这项工作中，我们引入了时间图中啤酒路径的概念，其中边是时间相关的，并且某些顶点（啤酒顶点）仅在特定时间实例活跃。我们正式定义了计算最早到达、最晚出发、最快和最短时间啤酒路径的问题，并提出了在边流和邻接列表表示下解决这些问题的有效算法。我们每种算法的时间复杂度都与相应的时间寻路算法一致，从而保持了效率。
  此外，我们提出了预处理技术，可以在动态条件下（例如商店的新开业或关闭）实现高效的查询回答。我们通过适当预计算选定的路径或将时间图转换为等效的静态图来实现这一点。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [294] [Optimizing Probabilistic Propagation in Graphs by Adding Edges](https://arxiv.org/abs/2407.02624)
> *图中概率传播的边添加优化*

*Aditya Bhaskara, Alex Crane, Shweta Jain, Md Mumtahin Habib Ullah Mazumder, Blair D. Sullivan, Prasanth Yalamanchili* | **Category: cs.DS, cs.SI** | **Updated: 2025-07-10**

**Keywords:** 概率图, 可达性改进, 边增强, 近似算法, 硬度结果

**Comment:** Abstract shortened to comply with arxiv requirements

> **TL;DR:** 研究了通过添加边来提高概率图中“可达性”的问题，并首次提供了近似保证和硬度结果。

**AI_Comments:** 这项工作首次为概率图中的“可达性改进”问题提供了理论上的近似保证和硬度结果，填补了此前经验性研究的空白。其创新之处在于利用图的聚类结构来设计算法，并引入了受渗流理论启发的新概率工具，这些工具可能具有更广泛的应用价值。同时，硬度结果为该问题的可近似性设定了界限。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过增加边来提高概率图中的“可达性”（reach），该问题在不可靠通信网络的多播和社交网络分析中具有应用，并由算法公平性社区引入。

**Method:** 1. 证明了好的增强意味着图的聚类结构。2. 基于此结构性结果，分析了一种新的算法，该算法输出的k边增强具有poly($\beta^*$)的目标值。3. 提供了另一种算法，可以添加O(k log n)条边并产生对$\beta^*$的乘法近似。4. 论证依赖于受渗流理论启发的新概率工具。

**Result:** 1. 首次为“可达性改进”问题提供了近似保证和硬度结果。2. 证明了好的增强意味着图的聚类结构。3. 提出了一种算法，其k-边增强的目标值是poly($\beta^*$)。4. 提出了另一种算法，添加O(k log n)条边并产生对$\beta^*$的乘法近似。5. 证明了在Set Cover问题的间隙变体相关已知硬度假设下，显著更好的近似是不太可能的。

**Conclusion:** 本文为概率图中通过添加边来优化可达性问题提供了首次理论分析，包括近似算法、硬度结果以及新的概率分析工具，揭示了该问题的结构特性和近似限制。

> **ai_Abstract:** 本文研究了在给定预算下通过添加边来最大化概率图中“可达性”（即源点到其他点的最小连通概率）的问题。作者首次为该问题提供了近似保证和硬度结果，证明了良好增强的聚类结构特性。文章提出了两种算法，分别实现了多项式近似和乘法近似，并引入了受渗流理论启发的新概率分析工具。研究还表明，在特定硬度假设下，难以获得显著更好的近似。

> **摘要翻译:** 概率图是一种抽象，使我们能够研究图中的随机传播。在概率图中，每条边以一定的概率“活跃”，且独立于其他边。对于两个顶点u,v，一个经典的感兴趣量（我们称之为邻近度$\mathcal{P}_{G}(u, v)$）是u和v之间存在一条所有边都活跃的路径的概率。对于给定的顶点子集$V_s$， $V_s$的可达性定义为$u \in V_s$和$v \in V$对的邻近度$\mathcal{P}_{G}(u,v)$的最小值。这个量在不可靠通信网络中的多播和社交网络分析中得到了研究。
我们研究了通过边增强来提高概率图中可达性的问题。形式上，给定一个添加边的预算k和一个源顶点集$V_s$，可达性改进的目标是通过向图中添加至多k条新边来最大化$V_s$的可达性。这个问题由算法公平性社区在早期的经验工作中引入。我们为可达性改进提供了首次近似保证和硬度结果。
我们证明了良好增强的存在意味着图的聚类结构。我们利用这个结构性结果来分析一种新颖的算法，该算法输出的k边增强的目标值是poly($\beta^*$)，其中$\beta^*$是最佳增强的目标值。我们还给出了一种算法，该算法添加O(k log n)条边并产生对$\beta^*$的乘法近似。我们的论证依赖于分析邻近度的新概率工具，这些工具受渗流理论技术的启发；这些工具可能具有更广泛的兴趣。最后，我们表明，在与经典Set Cover问题的间隙变体相关的已知硬度假设下，显著更好的近似是不太可能的。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [311] [On the Constant-Factor Approximability of Minimum Cost Constraint Satisfaction Problems](https://arxiv.org/abs/2507.08693)
> *关于最小成本约束满足问题的常数因子可近似性*

*Ian DeHaan, Neng Huang, Euiwoong Lee* | **Category: cs.DS, cs.CC, cs.DM** | **Updated: 2025-07-11**

**Keywords:** 最小成本约束满足问题, 常数因子近似, 多态性, 近一致多态性, 代数方法

**Comment:** 22 pages

> **TL;DR:** 本文通过代数视角研究最小成本约束满足问题（MinCostCSP），给出了其常数因子可近似性的二分法，并指出近一致多态性的局限性。

**AI_Comments:** 本文通过引入代数方法，对MinCostCSP的近似性界限进行了深入的理论分析，扩展了Dalmau等人在MinCSPs上的类似结果。其创新之处在于提出了一个明确的二分法，并指出了近一致多态性在保证常数因子近似性方面的局限性，这对于理解约束满足问题的计算复杂性具有重要意义。该研究对于未来设计更有效的近似算法或证明近似性下界提供了重要的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 通过代数视角研究最小成本约束满足问题（MinCostCSP），以理解其常数因子可近似性。

**Method:** 研究了具有特定多态性（如对偶判别器和近一致多态性）的约束语言，并通过算法结果和NP-难近似性结果相结合的方式，分析了MinCostCSP的常数因子可近似性。

**Result:** 1. 对于具有对偶判别器操作作为多态性的任何约束语言$\Gamma$，存在一个MinCostCSP($\Gamma$)的$|D|$-近似算法。2. 任何MinCostCSP($\Gamma$)承认常数因子近似的约束语言$\Gamma$必须具有近一致（NU）多态性（除非P=NP）。3. 对于包含所有置换关系的约束语言，存在一个常数因子可近似性的二分法：要么MinCostCSP($\Gamma$)具有NU多态性且是$|D|$-可近似的，要么不具有任何NU多态性且在任何常数因子内都是NP-难近似的。4. 提出了一个具有多数多态性但仍是NP-难近似（假设独特博弈猜想）的约束语言，表明具有NU多态性的条件通常不足够。

**Conclusion:** 研究结果揭示了MinCostCSP常数因子可近似性的代数特性，提出了一个二分法，并指出近一致多态性作为近似条件的一般局限性。

> **ai_Abstract:** 本文从代数角度深入探讨了最小成本约束满足问题（MinCostCSP）的常数因子可近似性。研究发现，对于具有对偶判别器多态性的约束语言，存在一个$|D|$-近似算法。同时，证明了常数因子近似性通常需要近一致（NU）多态性。这些结果共同揭示了对包含所有置换关系的约束语言，MinCostCSP的近似性存在一个二分法：要么可近似，要么是NP-难近似。此外，论文还通过反例指出，即使存在多数多态性，NU多态性也并非是常数因子近似的充分条件（在独特博弈猜想成立的前提下）。

> **摘要翻译:** 我们通过代数视角研究最小成本约束满足问题（MinCostCSP）。我们展示了，对于任何以对偶判别器操作为多态性的约束语言$\Gamma$，存在一个MinCostCSP($\Gamma$)的$|D|$-近似算法，其中$D$是域。作为我们算法结果的补充，我们展示了，任何MinCostCSP($\Gamma$)承认常数因子近似的约束语言$\Gamma$必须具有近一致（NU）多态性，除非P = NP，这扩展了Dalmau等人关于MinCSPs的类似结果。这些结果意味着，对于包含所有置换关系的约束语言（这是布尔CSP的自然推广，允许变量否定），存在一个常数因子可近似性的二分法：要么MinCostCSP($\Gamma$)具有NU多态性并且是$|D|$-可近似的，要么它不具有任何NU多态性并且在任何常数因子内都是NP-难近似的。最后，我们提出了一个具有多数多态性但仍是NP-难近似（假设独特博弈猜想）的约束语言，这表明除非UGC失败，否则具有NU多态性的条件通常不足够。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [341] [To buy or not to buy: deterministic rent-or-buy problems on node-weighted graphs](https://arxiv.org/abs/2507.08698)
> *买还是不买：节点加权图上的确定性租或买问题*

*Sander Borst, Moritz Venzin* | **Category: cs.DS** | **Updated: 2025-07-11**

**Keywords:** 在线Steiner森林, 租或买, 节点加权图, 竞争算法, 收费方案

**Comment:** 

> **TL;DR:** 本文提出了针对节点加权图上在线Steiner森林租或买问题的改进确定性算法和随机算法，并引入了一种新颖的收费方案。

**AI_Comments:** 本文的创新之处在于其提出的新颖收费方案，该方案成功地将witness技术扩展到节点加权图，从而显著提高了复杂在线优化问题的竞争比。这项工作推进了在线Steiner森林问题近似算法的最新技术水平。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在改进在线Steiner森林租或买问题的竞争比，特别是在节点加权图上的表现，以超越之前基于黑盒归约的方法。

**Method:** 本文研究了节点加权图和边加权图上在线Steiner森林问题的租或买变体。其核心技术是引入了一种新颖的收费方案，将其映射到在线奖品收集集合覆盖问题的一个实例，从而将witness技术扩展到节点加权设置。

**Result:** 获得了确定性的$O(\log n \log \bar{n})$-竞争算法，优于之前最佳的$O(\log^4 n)$-竞争算法。获得了确定性的$O(\bar{n}\log \tilde{k})$-竞争算法，推广了纯边加权设置的$O(\log \tilde{k})$-竞争算法。获得了一个随机的$O(\log \tilde{k} \log \bar{n})$-竞争算法。所有这些都改进了之前基于黑盒归约的方法。在更简单的“只买”设置中，获得了关于$\bar{n}$的更精细的保证。

**Conclusion:** 本文成功开发了新的算法，显著提高了在线Steiner森林租或买问题的竞争比，特别是在处理节点加权场景方面，并提供了更精细的保证。

> **ai_Abstract:** 本文研究了节点和边加权图上的在线Steiner森林租或买问题。通过引入一种新颖的收费方案，将其与在线奖品收集集合覆盖问题相结合，本文成功地将witness技术扩展到节点加权设置。研究结果包括一个改进的确定性$O(\log n \log \bar{n})$-竞争算法，一个推广性的确定性$O(\bar{n}\log \tilde{k})$-竞争算法，以及一个随机的$O(\log \tilde{k} \log \bar{n})$-竞争算法。这些成果均优于或推广了现有方法，并在“只买”设置中提供了关于节点权重的更精细保证。

> **摘要翻译:** 我们研究了节点和边加权图上在线Steiner森林问题的租或买变体。对于具有至多$\bar{n}$个非零节点权重和至多$\tilde{k}$个不同到达终端对的$n$节点图，我们获得了一个确定性的$O(\log n \log \bar{n})$-竞争算法。这改进了之前最佳的$O(\log^4 n)$-竞争算法，该算法是通过(Bartal et al. 2021)的黑盒归约与之前针对更简单“只买”设置的最佳确定性算法相结合获得的。我们还获得了一个确定性的$O(\bar{n}\log \tilde{k})$-竞争算法。这推广了(Umboh 2015)中纯边加权设置的$O(\log \tilde{k})$-竞争算法。我们还获得了一个随机的$O(\log \tilde{k} \log \bar{n})$-竞争算法。所有以前的方法都基于来自\cite{AwerbuchAzarBartal96}的随机黑盒归约，当与“只买”设置的算法结合时，该归约实现了$O(\log \tilde{k} \log n)$-竞争比。我们的关键技术要素是一种新颖的收费方案，用于在线奖品收集集合覆盖的实例。这使我们能够将(Umboh 2015)的witness技术扩展到节点加权设置，并在更简单的“只买”设置中就获得关于$\bar{n}$的更精细的保证。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [365] [On Fair Epsilon Net and Geometric Hitting Set](https://arxiv.org/abs/2507.08758)
> *关于公平的Epsilon网和几何命中集*

*Mohsen Dehghankar, Stavros Sintos, Abolfazl Asudeh* | **Category: cs.DS** | **Updated: 2025-07-11**

**Keywords:** Fair Epsilon Net, Geometric Hitting Set, Fairness, Computational Geometry, Approximation Algorithms

**Comment:** 

> **TL;DR:** 本文将公平性引入到几何近似问题（如$\varepsilon$-网和几何命中集）中，定义了两种公平性概念，提出了基于采样的和基于差异理论的两种算法，并证明了其理论保证和实验有效性，同时指出了公平采样的局限性。

**AI_Comments:** 本文的创新之处在于将公平性这一重要且新兴的概念引入到计算几何领域的基础工具（如$\varepsilon$-网）中，这对于构建公平的数据摘要和近似算法具有重要意义。研究结合了坚实的理论分析和令人信服的实验结果。

<details>
  <summary>Details</summary>

**Motivation:** 公平性已成为数据驱动决策中的一个重大挑战。计算几何工具（如$\varepsilon$-网）可有效解决许多数据问题（如创建紧凑数据摘要），但尚未从公平性角度进行研究。本文旨在弥补这一研究空白，为经典的几何近似问题添加公平性。

**Method:** 引入并解决了两种群体公平性概念：人口均等（demographic parity）和自定义比例公平性（custom-ratios fairness）。开发了两种强制执行公平性的算法：一种基于采样，另一种基于差异理论。将公平几何命中集问题归约到寻找公平$\varepsilon$-网。

**Result:** 基于采样的算法更快，计算出的公平$\varepsilon$-网大小仅比标准（不公平）$\varepsilon$-网大一个$\log(k)$因子。基于差异理论的算法稍慢但计算出的公平$\varepsilon$-网更小。公平几何命中集问题获得了$O(\log \mathsf{OPT} \times \log k)$近似。在某些输入分布下，构建公平$\varepsilon$-样本是不可行的。实验结果验证了所提算法的实际有效性，以适度的输出大小增加实现了零不公平性。

**Conclusion:** 本文成功地将公平性概念引入到经典的几何近似问题中，提出了有效的算法并证明了其理论性质和实际效果，同时揭示了公平采样的局限性。

> **ai_Abstract:** 本文解决了数据驱动决策中的公平性挑战，将公平性整合到$\varepsilon$-网、$\varepsilon$-样本和几何命中集等经典的计算几何近似工具中。文章定义了人口均等和自定义比例两种群体公平性概念，并提出了基于采样和基于差异理论的两种算法来实现公平性。研究提供了关于所得公平集合大小和近似比的理论保证，并通过实验验证了算法的实用有效性，证明在仅适度增加输出大小的情况下可以实现零不公平性。此外，研究指出在某些输入分布下，构建公平$\varepsilon$-样本是不可行的。

> **摘要翻译:** 公平性已成为数据驱动决策中的一个巨大挑战。许多数据问题，例如为近似查询处理创建紧凑的数据摘要，可以利用计算几何中的概念（例如$\varepsilon$-网）有效解决。然而，这些强大的工具尚未从公平性的角度进行检验。为了填补这一研究空白，我们将公平性添加到$\varepsilon$-网、$\varepsilon$-样本和几何命中集等经典的几何近似问题中。我们引入并解决了两种群体公平性概念：人口均等（demographic parity），要求保持输入分布中的群体比例；自定义比例公平性（custom-ratios fairness），要求满足任意目标比例。我们开发了两种强制执行公平性的算法：一种基于采样，另一种基于差异理论。基于采样的算法更快，计算出的公平$\varepsilon$-网大小仅比标准（不公平）$\varepsilon$-网大一个$\log(k)$因子，其中$k$是人口群体的数量。基于差异理论的算法稍慢（对于有界VC维），但计算出的公平$\varepsilon$-网更小。值得注意的是，我们将公平几何命中集问题归约到寻找公平$\varepsilon$-网。这使得公平几何命中集获得了$O(\log \mathsf{OPT} \times \log k)$的近似比。此外，我们表明在某些输入分布下，构建公平$\varepsilon$-样本是不可行的，突显了公平采样的局限性。除了理论保证，我们的实验结果验证了所提算法的实际有效性。特别是，与不公平设置相比，我们以适度的输出大小增加实现了零不公平性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [441] [Sequence graphs realizations and ambiguity in language models](https://arxiv.org/abs/2402.08830)
> *序列图的实现与语言模型中的歧义*

*Sammy Khalife, Yann Ponty, Laurent Bulteau* | **Category: cs.DS, cs.CC, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 序列图,语言模型,实现,歧义性,组合学

**Comment:** 

> **TL;DR:** 该研究探讨了语言模型中用于表示局部上下文的序列图的实现和歧义性。研究人员从组合学和算法角度分析了序列图的实现问题，并针对不同的参数设置（窗口大小w、图的方向和权重）进行了研究。研究发现，当w=2时，大多数情况下的实现和枚举问题可以在多项式时间内解决，但存在一个例外情况（无向/加权设置），其枚举问题被证明是#P-hard的。当w≥3时，除无向无权情况外，所有变体的实现和枚举问题都被证明是困难的。最后，研究提出了一个整数规划模型来解决实现问题，以及一个动态规划算法来解决中等规模实例的枚举问题。

**AI_Comments:** 这项研究在理论上很有价值，因为它从组合学和算法的角度解决了语言模型中序列图表示的根本问题。然而，研究中提到的“最小实现可能具有指数大小”的结论，以及两个核心问题（实现和枚举）的NP成员资格仍未解决，这表明在实际应用中处理这些序列图可能面临巨大的计算挑战。尽管如此，研究提出的整数规划和动态规划方法为解决实际问题提供了一些途径。

<details>
  <summary>Details</summary>

**Motivation:** 流行的语言模型使用词袋来表示输入文本的局部上下文，这些表示被编码为序列图。然而，这种表示可能存在歧义，即一个序列图可能对应多个序列，或者不对应任何序列。因此，理解序列图的实现和歧义性至关重要。

**Method:** 本研究从组合学和算法角度研究了序列图的实现和歧义性。研究人员考虑了不同的参数设置，包括窗口大小w、图的方向（有向/无向）和权重（有/无）。他们为w=2的情况提供了多项式时间算法，并证明了在某些情况下#P-hard。对于w≥3，他们证明了大多数情况下的硬度，并为无向无权情况提出了XP算法。最后，他们提出了一个整数规划模型用于实现问题，以及一个动态规划算法用于枚举问题。

**Result:** 对于窗口大小w=2，研究人员在除无向/加权设置外的所有情况下都提供了序列图实现和枚举的多项式时间算法，并证明了该例外情况的枚举问题是#P-hard的。对于w≥3，除了无向无权情况外，所有变体的实现和枚举问题都被证明是困难的，即使w被视为常数。对于无向无权情况，研究人员提出了XP算法，这与相应的W[1]-hardness结果是吻合的。

**Conclusion:** 本研究对序列图的实现和歧义性进行了深入的组合学和算法分析。研究结果表明，序列图的复杂性很大程度上取决于窗口大小、方向和权重等参数。虽然对某些简单情况（如w=2）存在有效的算法，但对于更复杂的情况，问题变得非常困难。研究提出的整数规划和动态规划方法为解决这些问题提供了实用的途径，但这两个问题的NP成员资格仍然是一个悬而未决的难题。

> **ai_Abstract:** 本研究深入探讨了语言模型中用于表示局部上下文的序列图的实现和歧义性问题。研究人员从组合学和算法角度分析了序列图的可实现性和歧义性，考察了窗口大小（$w$）、图的方向和权重等多种因素的影响。研究发现，当窗口大小$w=2$时，除无向加权情况外，实现和枚举问题均可在多项式时间内解决，而该例外情况的枚举问题被证明是#P-hard的。对于$w 
less 3$，除了无向无权情况外，所有变体的实现和枚举问题均被证明是困难的，即使$w$为常数。研究为无向无权情况提出了XP算法，并给出了相应的$W[1]-hardness$结果。最后，研究提出了一个整数规划模型来解决实现问题，以及一个动态规划算法来解决中等规模实例的枚举问题，同时指出这两个问题的NP成员资格仍有待研究。

> **摘要翻译:** 许多流行的语言模型将输入文本$x$的局部上下文表示为词袋。这种表示自然地由一个序列图编码，其顶点是$x$中出现的不同单词，边表示在大小为$w$的滑动窗口内两个单词的（有序）共现。然而，这种压缩表示通常不是双射的：有些可能存在歧义，对应于序列的多个实现，而有些可能不对应任何实现。在本研究中，我们从组合学和算法的角度研究了序列图的可实现性和歧义性。我们在多种设置下考虑了序列图的实现的存在性和枚举：窗口大小$w$、图方向的有无以及权重（重数）的有无。当$w=2$时，我们为除无向/加权设置外的所有情况提供了可实现性和枚举的多项式时间算法，其中我们证明了枚举的#P-hard性。对于$w 
less 3$，我们证明了所有变体的硬度，即使$w$被视为常数，但值得注意的是无向无权情况，我们为这两个问题提出了XP算法，这与其对应的$W[1]-hardness$结果是吻合的。最后，我们提出了一个整数规划公式来解决可实现性问题，以及一个动态规划算法来解决中等规模实例的枚举问题。这项工作仍然悬而未决这两个问题的NP成员资格，由于存在最小实现的大小相对于实例编码呈指数级增长，因此这是一个非平凡的问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [476] [On Deterministically Finding an Element of High Order Modulo a Composite](https://arxiv.org/abs/2506.07668)
> *关于确定性地寻找模复合数的高阶元素*

*Ziv Oznovich, Ben Lee Volk* | **Category: cs.DS, math.NT** | **Updated: 2025-07-11**

**Keywords:** 确定性算法, 高阶元素, 复合数, 整数分解, Hittmeir算法

**Comment:** 

> **TL;DR:** 该算法能在 $D \ge N^{1/6}$ 的条件下，在 $D^{1/2+o(1)}$ 的时间内找到一个阶至少为 $D$ 的元素，或找到 $N$ 的一个非平凡因子。

**AI_Comments:** 该算法在寻找高阶元素和整数分解方面具有重要意义，尤其是在条件放宽的情况下。与现有算法相比，其在理论上的改进值得关注。

<details>
  <summary>Details</summary>

**Motivation:** Hittmeir (arXiv:1608.08766) 设计了一个类似的算法，但需要更强的假设 $D \ge N^{2/5}$。Hittmeir 的算法在最近的突破性确定性整数分解算法 (arXiv:2006.16729, arXiv:2010.05450, arXiv:2105.11105) 中发挥了关键作用。

**Method:** 提出了一种确定性算法，该算法在给定复合数 $N$ 和目标阶 $D \ge N^{1/6}$ 的情况下，运行时间为 $D^{1/2+o(1)}$。

**Result:** 找到一个阶至少为 $D$ 的元素 $a \in \mathbb{Z}_N^*$，或者找到 $N$ 的一个非平凡因子。

**Conclusion:** 该算法在 $D \ge N^{1/6}$ 的条件下，比 Hittmeir 的算法在更宽松的条件下提供了改进，并且当 $N$ 具有 $r$-幂因子且 $r \ge 2$ 时，在 $D \ge N^{1/6r}$ 的假设下提供了相同的保证。

> **ai_Abstract:** 本文提出了一种确定性算法，可在 $D \ge N^{1/6}$ 的条件下，在 $D^{1/2+o(1)}$ 的时间内找到一个阶至少为 $D$ 的元素或 $N$ 的一个非平凡因子。该算法改进了 Hittmeir 的工作，并在 $N$ 具有 $r$-幂因子时提供了类似的保证。

> **摘要翻译:** 我们提出了一种确定性算法，该算法在给定复合数 $N$ 和目标阶 $D \ge N^{1/6}$ 的情况下，运行时间为 $D^{1/2+o(1)}$，并找到一个阶至少为 $D$ 的元素 $a \in \mathbb{Z}_N^*$，或者找到 $N$ 的一个非平凡因子。我们的算法改进了 Hittmeir (arXiv:1608.08766) 的算法，他设计了一个类似的算法，但需要更强的假设 $D \ge N^{2/5}$。Hittmeir 的算法在最近的突破性确定性整数分解算法 (arXiv:2006.16729, arXiv:2010.05450, arXiv:2105.11105) 中发挥了关键作用。当假设 $N$ 具有 $r$-幂因子且 $r \ge 2$ 时，我们的算法在 $D \ge N^{1/6r}$ 的假设下提供了相同的保证。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [516] [Compressing Suffix Trees by Path Decompositions](https://arxiv.org/abs/2506.14734)
> *压缩后缀树的路径分解*

*Ruben Becker, Davide Cenzato, Travis Gagie, Sung-Hwan Kim, Ragnar Groot Koerkamp, Giovanni Manzini, Nicola Prezza* | **Category: cs.DS** | **Updated: 2025-07-10**

**Keywords:** 压缩索引,后缀树,路径分解,I/O效率,模式匹配

**Comment:** Article almost completed (more thorough experiments coming soon)

> **TL;DR:** 该论文提出了一种新的I/O高效压缩索引方法，通过对后缀树进行路径分解和压缩来实现，并在空间和查询速度上优于现有方法。

**AI_Comments:** 该研究在压缩索引领域取得了重要进展，提出了一种新颖且高效的方法。其理论和实践意义重大，尤其是在处理大规模数据集和需要快速查询的场景中。然而，算法的实际实现复杂性和对特定硬件的依赖性可能需要进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 解决设计I/O高效压缩索引的长期问题。

**Method:** 通过对后缀树进行路径分解和压缩来实现：1. 对后缀树的叶子进行更一般的优先级函数排序；2. 构建后缀树路径分解，优先处理最左边的路径；3. 将分解的路径压缩为指向字符串后缀子集的指针。

**Result:** 提出了一种新的、简洁的、I/O高效的压缩后缀树表示。当优先级函数为后缀的字典序秩时，可在O(r)空间上压缩后缀树拓扑结构，并匹配Weiner和McCreight后缀树的模式匹配I/O复杂度。当优先级函数为前缀的共字典序秩时，得到的自索引在空间和查询速度上均优于r-index。

**Conclusion:** 该论文提出了一种新的I/O高效压缩索引方法，通过对后缀树进行路径分解和压缩来实现，并在空间和查询速度上优于现有方法。

> **ai_Abstract:** 本研究提出了一种I/O高效的压缩索引新方法，通过对后缀树进行路径分解和压缩来实现。该方法首先对后缀树叶子进行广义排序，然后构建路径分解并压缩路径为指向后缀子集的指针。结果表明，该方法在空间和查询效率上均优于现有技术，尤其是在处理大规模文本数据时。

> **摘要翻译:** 在本文中，我们解决了设计I/O高效压缩索引的长期问题。我们的解决方案广泛包括推广后缀排序和重新审视后缀树路径压缩。在经典的后缀树中，路径压缩通过用指向T的指针对替换单元后缀trie路径来实现，这必须在查询时以某种随机访问预言机的形式提供。在我们的方法中，我们（i）根据更一般的优先级函数$
u$对后缀树的叶子进行排序（推广后缀排序），（ii）我们构建一个后缀树路径分解，优先处理最左边的路径，（iii）我们将分解的路径压缩为指向字符串后缀子集的指针。此时，我们证明了这些指针的共字典序排序数组代表了一种新的优雅、简单且性能极佳的I/O高效压缩后缀树。例如，通过将$
u$取为T的后缀的字典序秩，我们可以在O(r)空间上压缩后缀树拓扑结构，其文本表示为nlogσ+O(log n)位，同时在模式匹配I/O复杂度上基本匹配Weiner和McCreight的后缀树。另一种（更实用的）解决方案是通过将$
u$取为T的前缀的共字典序秩并使用完全压缩的随机访问预言机来获得的。由此产生的自索引使我们能够以比r-index更小的空间和数量级更快的速度定位给定查询模式的所有出现。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [547] [Review of Three Variants of the k-d Tree](https://arxiv.org/abs/2506.20687)
> *k-d树三种变体的回顾*

*Russell A. Brown* | **Category: cs.DS** | **Updated: 2025-07-10**

**Keywords:** k-d树, 数据划分, 性能比较, 双线程执行, 树构建

**Comment:** 29 pages, 11 figures, one listing, one table

> **TL;DR:** 本文回顾并比较了三种不同的k-d树变体，这些变体在数据划分技术上有所不同，并分析了其中一种变体的双线程执行。

**AI_Comments:** 该研究对k-d树的不同变体进行了有价值的比较，并引入了双线程执行的概念，为优化k-d树的性能提供了新的视角。然而，抽象中未提及具体的性能指标或实验结果，这限制了对其有效性的全面评估。

<details>
  <summary>Details</summary>

**Motivation:** 为了构建平衡的k-d树，需要在每次递归划分时找到数据集的中位数，而选择何种排序或选择方法以及数据划分技术会影响构建k-d树的计算复杂度。

**Method:** 本文描述并对比了三种k-d树变体，它们在数据划分技术上有所不同，并比较了这些变体的性能。此外，还提出并分析了一种变体的双线程执行。

**Result:** 本文比较了三种k-d树变体的性能，并对其中一种变体的双线程执行进行了分析。

**Conclusion:** 本文对三种k-d树变体进行了描述、对比和性能分析，并提出了双线程执行的优化方法。

> **ai_Abstract:** 本文探讨了k-d树的构建问题，重点介绍了三种不同的变体，这些变体在数据划分策略上有所区别。文章分析了这些变体对构建k-d树计算复杂度的影响，并比较了它们的性能。此外，研究还提出并评估了一种变体的双线程执行方式。

> **摘要翻译:** k-d树的原始描述认识到，像用于构建AVL树或红黑树那样的重新平衡技术不适用于k-d树。因此，为了构建平衡的k-d树，有必要为该集合的每次递归划分找到一个数据集合的中位数。用于查找中位数的排序或选择，以及围绕该中位数划分集合的技术，强烈影响了构建k-d树的计算复杂度。本文描述并对比了三种k-d树变体，它们在划分集合的技术上有所不同，并比较了这些变体的性能。此外，还为这三种变体中的一种提出了并分析了双线程执行。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [575] [On the (In)Approximability of the Monitoring Edge Geodetic Set Problem](https://arxiv.org/abs/2507.00708)
> *关于监控边测地集问题（在）近似性研究*

*Davide Bilò, Giordano Colli, Luca Forlizzi, Stefano Leucci* | **Category: cs.DS, cs.CC** | **Updated: 2025-07-11**

**Keywords:** 监控边测地集, 近似比, NP-难度, 平面图, 平衡分割

**Comment:** arXiv admin note: text overlap with arXiv:2405.13875

> **TL;DR:** 该论文研究了监控边测地集问题，证明了除非P=NP，否则其多项式时间近似算法的近似比至少为Ω(log n)，并对2-顶点可去图上的NP-难度进行了加强，同时对特定图类设计了近似算法。

**AI_Comments:** 该研究在理论和算法方面都取得了重要进展。在理论上，首次证明了监控边测地集问题的非常数近似比下界，为理解该问题的计算复杂度提供了关键信息。在算法方面，通过利用图的结构特性（如平衡分割），为特定图类设计了更优的近似算法，这在实际应用中具有潜在价值。然而，该研究也指出了平面图上的NP-难度仍是开放性问题，为未来的研究留下了方向。

<details>
  <summary>Details</summary>

**Motivation:** 研究监控边测地集问题的近似难度和设计近似算法，以解决NP难题。

**Method:** 证明了多项式时间近似算法的近似比下界，并设计了基于平衡分割的近似算法。

**Result:** 证明了该问题至少有Ω(log n)的近似比下界，并对特定图类（如平面图、有界属图、k-顶点可去图和有界树宽图）设计了具有更好近似比的算法。

**Conclusion:** 该研究首次证明了监控边测地集问题的非常数近似比下界，并为特定图类提供了有效的近似算法，但其在平面图上的NP-难度仍有待研究。

> **ai_Abstract:** 本文研究了监控边测地集（	ext{megset}）问题，该问题旨在找到最小顶点子集以监控图中所有边上的所有最短路径。研究证明了该问题存在$\Omega(\log n)$的近似比下界（除非	ext{p} = 	ext{np}），是该问题首个非常数近似比下界。此外，还加强了其在$2$-顶点可去图上的	ext{np}-难度结果，并推广到$1$-顶点可去图。在算法方面，研究提出了一种针对具有平衡分割的遗传图类的近似算法，在平面图、有界属图和$k$-顶点可去图上实现了$O(n^{\frac{1}{4}} \sqrt{\log n})$的近似比，在有界树宽图上实现了$O(\log^{3/2} n)$的近似比。

> **摘要翻译:** 我们研究了[Foucaud et al., CALDAM'23]中引入的最小	extit{监控边测地集}（	ext{megset}）问题：给定一个图$G$，我们说一个边$e$被顶点对$u,v$监控，如果它们之间所有最短路径都经过$e$；该问题的目标是找到一个顶点子集$M$，使得$G$的每条边都被$M$中的至少一对顶点监控，并且最小化$|M|$。
  在本文中，我们证明，除非	ext{p} = 	ext{np}，否则所有针对最小	ext{megset}问题的多项式时间近似算法都必须具有$\Omega(\log n)$的近似比。据我们所知，这是该问题第一个已知的非常数近似比下界结果。我们还通过证明同样的结果也适用于$1$-顶点可去图，来加强了已知的$2$-顶点可去图上的	ext{np}-难度。这使得确定该问题在平面图（即$0$-顶点可去图）上是否仍然是	ext{np}-困难的问题悬而未决。
  在积极方面，我们设计了一种算法，可以为那些能够有效计算的平衡分割的遗传图类计算出良好的近似解。这立即导致了在平面图、具有有界属的图以及$k$-顶点可去图（其中$k=O(n^{\frac{1}{4}})$）上实现$\tilde{O}(n^{\frac{1}{4}})$近似比的多项式时间近似算法。在具有有界树宽的图上，我们获得了对于任何常数$\varepsilon > 0$的$O(\log^{3/2} n)$近似比。这与通过简单地归约到	extsc{Set Cover}问题所能达到的针对一般图的最佳已知近似算法（该算法实现了$O(\sqrt{n \log n})$的近似比）相比，是有利的。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [599] [Finding One Local Optimum Is Easy -- But What about Two?](https://arxiv.org/abs/2507.07524)
> *找到一个局部最优解很容易——但两个呢？*

*Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi* | **Category: cs.DS, cs.CC** | **Updated: 2025-07-11**

**Keywords:** 局部搜索, 组合优化, NP难, 局部最优解, 最大独立集

**Comment:** 15 pages

> **TL;DR:** 找到两个局部最优解对于许多常见的无权组合优化问题（如最大独立集、最小支配集、最大满足度和最大割）来说是NP难的，尽管找到一个局部最优解是容易的。

**AI_Comments:** 该研究有效地扩展了我们对局部搜索复杂性的理解，将重点从单个局部最优解转移到多个局部最优解的挑战上。NP难性的证明对于理解这些问题的计算限制至关重要，而对可处理情况的探讨则为实际应用提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 研究局部搜索问题的计算复杂性，特别是与找到多个局部最优解相关的复杂性。

**Method:** 研究了包括最大独立集、最小支配集、最大满足度和最大割在内的多种无权局部搜索问题，并证明了找到两个局部最优解的NP难性。同时，也探讨了几种可处理的寻找两个或多个局部最优解的特殊情况。

**Result:** 证明了计算两个局部最优解对于最大独立集、最小支配集、最大满足度和最大割等多种无权局部搜索问题是NP难的。此外，还确定了几个可处理的寻找两个或多个局部最优解的特例。

**Conclusion:** 虽然找到一个局部最优解对于许多无权问题来说是容易的，但找到两个局部最优解的难度大大增加，对于许多自然问题而言是NP难的。然而，也存在一些可处理的特例。

> **ai_Abstract:** 本文研究了局部搜索问题中寻找多个局部最优解的计算复杂性。研究表明，尽管找到一个局部最优解相对容易（通常是多项式时间），但找到两个局部最优解对于许多常见的无权组合优化问题（包括最大独立集、最小支配集、最大满足度和最大割）来说是NP难的。研究还确定了一些可以有效解决的特例。

> **摘要翻译:** 局部搜索（PLS）类捕获了寻找局部最优解的复杂性，并且已被证明是局部搜索理论中的一个重要概念。已证明，诸如最大独立集和最大割等各种组合优化问题的局部搜索版本对于该类是完全的。这种计算上的难以处理性通常出现在允许任意权重的局部搜索问题中；相比之下，对于无权问题，在标准设置下可以在多项式时间内找到局部最优解。在本文中，我们从另一个角度探讨了局部搜索问题的复杂性：我们证明了，对于包括最大独立集、最小支配集、最大满足度和最大割在内的各种自然无权局部搜索问题，计算两个局部最优解是NP难的。我们还讨论了寻找两个（或更多）局部最优解的几种可处理情况。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [55] [FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields](https://arxiv.org/abs/2507.08285)
> *FlowDrag：基于网格引导变形矢量流场的3D感知拖拽式图像编辑*

*Gwanhyeong Koo, Sunjae Yoon, Younghwan Lee, Ji Woo Hong, Chang D. Yoo* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 拖拽式编辑, 3D感知, 网格变形, 图像编辑, 几何一致性

**Comment:** ICML 2025 Spotlight

> **TL;DR:** FlowDrag引入了一种3D感知、网格引导的拖拽式图像编辑方法，解决了几何不一致问题，并超越现有方法，同时提供了一个新的带地面真值基准数据集（VFD）。

**AI_Comments:** FlowDrag的创新之处在于其3D感知和网格引导的变形方法，有效解决了传统2D拖拽编辑中几何不一致的难题，提升了编辑的稳定性和准确性。同时，引入带有地面真值的VFD数据集，对于推动该领域的研究和提供更客观的评估标准具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有拖拽式编辑方法存在几何不一致问题，仅关注点匹配而忽略整体几何结构，导致伪影或不稳定编辑。此外，现有基准缺乏地面真值，难以准确评估编辑效果。

**Method:** FlowDrag利用几何信息，从图像构建3D网格，并使用能量函数引导网格变形。网格位移被投影到2D并融入UNet去噪过程，实现精确对齐并保持结构完整性。同时，提出了VFD（VidFrameDrag）基准数据集，提供基于视频连续镜头的地面真值帧。

**Result:** FlowDrag在VFD Bench和DragBench上均优于现有拖拽式编辑方法。

**Conclusion:** FlowDrag通过3D感知和网格引导的方法解决了拖拽式图像编辑中的几何不一致问题，显著提升了编辑的准确性和连贯性。同时，引入的VFD基准数据集为该领域提供了宝贵的地面真值评估标准，并证明了FlowDrag的卓越性能。

> **ai_Abstract:** FlowDrag是一种新颖的拖拽式图像编辑方法，通过构建3D网格并利用能量函数引导其变形，解决了现有方法中常见的几何不一致问题。它将3D网格位移投影到2D并结合UNet去噪，以实现精确的编辑同时保持结构完整性。此外，该论文还引入了VFD基准数据集，为拖拽编辑提供了真实的地面真值。实验证明，FlowDrag在多个基准测试中均优于现有方法。

> **摘要翻译:** 拖拽式编辑通过基于点的控制实现精确的对象操作，为用户提供便利。然而，现有方法通常存在几何不一致问题，因为它们只关注匹配用户定义的点，而忽略了更广泛的几何结构，导致伪影或不稳定的编辑。我们提出了FlowDrag，它利用几何信息实现更准确和连贯的变换。我们的方法从图像构建一个3D网格，使用能量函数根据用户定义的拖拽点引导网格变形。由此产生的网格位移被投影到2D并整合到UNet去噪过程中，从而实现精确的句柄到目标点对齐，同时保持结构完整性。此外，现有的拖拽编辑基准没有提供地面真实数据，这使得评估编辑与预期变换的匹配准确性变得困难。为了解决这个问题，我们提出了VFD（VidFrameDrag）基准数据集，它使用视频数据集中的连续镜头提供地面真实帧。FlowDrag在VFD Bench和DragBench上都优于现有的拖拽式编辑方法。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [79] [Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation](https://arxiv.org/abs/2507.08513)
> *通过大规模3D视觉指令数据集生成推进多模态大型语言模型*

*Liu He, Xiao Zeng, Yizhi Song, Albert Y. C. Chen, Lu Xia, Shashwat Verma, Sankalp Dayal, Min Sun, Cheng-Hao Kuo, Daniel Aliaga* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 多模态大型语言模型, 3D视觉指令, 数据集生成, 相机与物体关系, Ultimate3D

**Comment:** 

> **TL;DR:** 多模态大型语言模型（MLLM）在捕捉相机与物体关系方面存在困难；我们提出了一种合成生成管道来创建大规模3D视觉指令数据集（Ultimate3D），并在相关任务上实现了显著的性能提升。

**AI_Comments:** 这项工作的创新之处在于通过生成大规模、高质量的合成3D视觉指令数据集，有效地解决了当前多模态大型语言模型（MLLM）在理解相机与物体关系方面的弱点。利用3D资产结合渲染和扩散模型，确保了对视觉属性的精确控制，而引入大型语言模型生成文本提示则进一步提升了数据质量。这种方法为数据稀缺问题提供了一个可扩展的解决方案，并带来了显著的性能提升，对多模态大型语言模型的发展具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大型语言模型（MLLM）在准确捕捉相机与物体关系（如物体方向、相机视角和相机镜头）方面表现不佳，原因是训练数据中相机与物体关系的多样性及其对应的文本描述有限。

**Method:** 我们提出了一种合成生成管道来创建大规模3D视觉指令数据集。该框架以3D资产为输入，利用渲染和基于扩散的图像生成模型来创建保留精确相机与物体关系的照片级真实图像。同时，大型语言模型（LLM）被用于生成文本提示，以指导视觉指令微调和控制图像生成。我们创建了包含24万个带有精确相机与物体关系标注的视觉问答（VQA）的Ultimate3D数据集，并提供了相应的基准。

**Result:** 在Ultimate3D数据集上进行微调的多模态大型语言模型（MLLM）在相机与物体关系识别任务上，相比商业模型取得了显著的性能提升，平均准确率提高了33.4%。

**Conclusion:** 本研究提出的代码、数据集和基准将有助于推动多模态大型语言模型（MLLM）在更广泛的应用中，特别是在改善相机与物体关系识别方面的能力。

> **ai_Abstract:** 本文旨在解决多模态大型语言模型（MLLM）在捕捉精确相机与物体关系方面的不足，其根源在于现有训练数据中此类关系的多样性有限。为此，论文提出了一种合成生成管道，利用3D资产、渲染技术、扩散模型以及大型语言模型（LLM）来生成带有精确相机与物体关系标注的照片级真实图像。基于此方法，研究团队构建了Ultimate3D数据集，其中包含24万个视觉问答（VQA）对。实验结果表明，在Ultimate3D上进行微调的MLLM在相机与物体关系识别任务上，相比商业模型实现了平均33.4%的显著准确率提升，证明了所生成数据集的有效性。

> **摘要翻译:** 多模态大型语言模型（MLLM）在准确捕捉相机与物体关系方面存在困难，特别是对于物体方向、相机视角和相机镜头。这源于现有MLLM在训练时使用的图像中，相机与物体关系的多样性及其对应的文本描述有限。为了解决这个问题，我们提出了一种合成生成管道来创建大规模3D视觉指令数据集。我们的框架以3D资产作为输入，并使用渲染和基于扩散的图像生成模型来创建保留精确相机与物体关系的照片级真实图像。此外，大型语言模型（LLM）被用于生成文本提示，以指导视觉指令微调和控制图像生成。我们创建了Ultimate3D，一个包含24万个带有精确相机与物体关系标注的视觉问答（VQA）数据集，以及相应的基准。在我们的数据集上进行微调的MLLM在相机与物体关系识别任务上，相比商业模型取得了显著的性能提升，平均准确率提高了33.4%。我们的代码、数据集和基准将有助于广泛的MLLM应用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [9] [Overview of the TREC 2021 deep learning track](https://arxiv.org/abs/2507.08191)
> *TREC 2021 深度学习赛道概述*

*Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Jimmy Lin* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-07-10**

**Keywords:** 深度学习, 信息检索, TREC, MS MARCO, 神经网络

**Comment:** 

> **TL;DR:** TREC 2021 深度学习赛道第三年，利用MS MARCO数据集，扩大了数据集规模。深度神经网络模型继续优于传统方法，单阶段检索表现良好但不如多阶段。数据集扩大也引发了对判断完整性和标签质量的质疑。

**AI_Comments:** 这篇概述展示了深度学习在信息检索领域持续的主导地位，特别是大型预训练模型的有效性。赛道对数据集规模的显著扩大，不仅推动了研究进展，也坦诚地揭示了在大规模数据背景下，评估判断和训练标签质量管理所面临的挑战，这对于未来信息检索研究和基准测试的构建具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在继续探索和评估深度学习模型在信息检索任务中的表现，特别是在大规模数据集上的应用，并解决与数据规模增长相关的挑战。

**Method:** 赛道利用MS MARCO数据集提供的人工标注训练标签，用于段落和文档排序任务。本年度更新了文档和段落集合，使其规模分别增加了近4倍和16倍。研究评估了采用大规模预训练的深度神经网络排序模型，并与传统检索方法进行了比较，同时也探讨了单阶段和多阶段检索管道的性能。

**Result:** 采用大规模预训练的深度神经网络排序模型继续优于传统检索方法。单阶段检索在两项任务上均能取得良好性能，但仍未达到多阶段检索管道的水平。此外，数据集规模的增加和数据更新引发了对NIST判断完整性和从旧集合映射到新集合的训练标签质量的疑问。

**Conclusion:** TREC 2021 深度学习赛道再次确认了深度神经网络模型在信息检索任务中的优越性，并揭示了在大规模数据集下，单阶段与多阶段检索的性能差异，以及数据量增长对评估判断和训练标签质量带来的挑战。

> **ai_Abstract:** 本报告概述了TREC 2021深度学习赛道，该赛道是第三年运行，并继续利用MS MARCO数据集。本年度显著扩大了文档和段落集合的规模。赛道结果显示，采用大规模预训练的深度神经网络模型在信息检索任务上持续超越传统方法，同时指出单阶段检索虽表现良好但仍逊于多阶段检索管道。报告还讨论了数据集规模扩大后，NIST判断完整性和训练标签质量所面临的挑战。

> **摘要翻译:** 这是TREC深度学习赛道的第三年。与往年一样，我们利用MS MARCO数据集，该数据集为段落和文档排序任务提供了数十万个人工标注的训练标签。此外，今年我们更新了文档和段落集合，这导致文档集合的大小增加了近四倍，段落集合的大小增加了近16倍。采用大规模预训练的深度神经网络排序模型今年继续超越传统检索方法。我们还发现，单阶段检索在两项任务上都能取得良好性能，尽管它们仍未达到多阶段检索管道的水平。最后，集合规模的增加和整体数据更新引发了关于NIST判断完整性以及从旧集合映射到新集合的训练标签质量的一些问题，我们将在本报告中讨论这些问题。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [98] [CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval](https://arxiv.org/abs/2507.08445)
> *CUE-RAG：通过多方图和查询驱动的迭代检索实现精确且经济高效的基于图的RAG*

*Yaodong Su, Yixiang Fang, Yingli Zhou, Quanqing Xu, Chuanhui Yang* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-11**

**Keywords:** RAG, 图神经网络, 知识图谱, 大型语言模型, 问答

**Comment:** 

> **TL;DR:** CUE-RAG通过引入多方图索引、混合提取策略和查询驱动的迭代检索，显著提高了基于图的RAG的准确性和成本效率。

**AI_Comments:** CUE-RAG的创新在于其多方图索引的设计和查询驱动的迭代检索策略，有效解决了传统图基RAG在图质量和检索相关性上的痛点。其在成本效率方面的提升，尤其是在不依赖LLM进行索引的情况下仍能保持高性能，是其重要亮点，对于实际部署具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）取得了显著进展，但在问答（QA）方面的性能仍受限于缺乏特定领域和最新知识。检索增强生成（RAG）通过整合外部信息（通常来自图结构数据）来解决此限制。然而，现有的基于图的RAG方法由于提取不完整和检索过程中对查询信息利用不足，导致图质量不佳。

**Method:** 我们提出了CUE-RAG，一种新颖的方法，它引入了：(1) 一个多方图索引，包含文本块、知识单元和实体，以捕获多粒度语义内容；(2) 一种混合提取策略，在减少LLM token使用量的同时，生成准确且无歧义的知识单元；(3) Q-Iter，一种查询驱动的迭代检索策略，通过语义搜索和受约束的图遍历来增强相关性。

**Result:** 在三个QA基准测试中，CUE-RAG显著优于最先进的基线，准确率提高了99.33%，F1分数提高了113.51%，同时索引成本降低了72.58%。即使在不使用LLM进行索引的情况下，CUE-RAG也能与基线匹配或超越基线。

**Conclusion:** 这些结果证明了CUE-RAG在推进基于图的RAG系统方面的有效性和成本效率。

> **ai_Abstract:** CUE-RAG提出了一种新颖的基于图的RAG方法，旨在解决现有方法中图质量差和查询信息利用不足的问题。它引入了多方图索引（整合文本块、知识单元和实体）、混合提取策略（减少LLM token使用并提高准确性）和查询驱动的迭代检索（增强相关性）。实验证明，CUE-RAG在准确性和F1分数上显著优于现有技术，同时大幅降低了索引成本，并且即使不使用LLM进行索引也能表现出色。

> **摘要翻译:** 尽管大型语言模型（LLM）取得了显著进展，但在问答（QA）方面的性能仍受限于缺乏特定领域和最新知识。检索增强生成（RAG）通过整合外部信息，通常来自图结构数据，来解决此限制。然而，现有的基于图的RAG方法由于提取不完整和检索过程中对查询信息利用不足，导致图质量不佳。为了克服这些限制，我们提出了CUE-RAG，一种新颖的方法，它引入了：(1) 一个多方图索引，包含文本块、知识单元和实体，以捕获多粒度语义内容；(2) 一种混合提取策略，在减少LLM token使用量的同时，生成准确且无歧义的知识单元；(3) Q-Iter，一种查询驱动的迭代检索策略，通过语义搜索和受约束的图遍历来增强相关性。在三个QA基准测试中，CUE-RAG显著优于最先进的基线，准确率提高了99.33%，F1分数提高了113.51%，同时索引成本降低了72.58%。值得注意的是，即使在不使用LLM进行索引的情况下，CUE-RAG也能与基线匹配或超越基线。这些结果证明了CUE-RAG在推进基于图的RAG系统方面的有效性和成本效率。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [266] [Towards Efficient Quantity Retrieval from Text:an Approach via Description Parsing and Weak Supervision](https://arxiv.org/abs/2507.08322)
> *文本中高效数量检索：一种基于描述解析和弱监督的方法*

*Yixuan Cao, Zhengrong Chen, Chengxuan Xia, Kun Wu, Ping Luo* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 数量检索, 描述解析, 弱监督, 定量事实, 信息检索

**Comment:** Extended version of the paper accepted in DEXA 2025

> **TL;DR:** 本文提出了一种名为“数量检索”的新任务，旨在从非结构化文本中检索定量事实。通过描述解析框架和弱监督技术，显著提高了检索准确率。

**AI_Comments:** 这项工作创新性地提出了“数量检索”这一任务，填补了从非结构化文本中高效提取定量信息的空白。其基于描述解析和弱监督的方法具有很强的实用性，特别是弱监督方法的引入，有效解决了标注数据稀缺的问题，使其能够应用于大规模真实世界数据。准确率的显著提升表明了该方法的有效性，对于需要从大量文本中获取定量数据的金融、政府等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管常见的定量事实是结构化的，但许多长尾定量事实仍埋藏在非结构化文档中，难以访问，这阻碍了数据驱动的决策。因此，需要一种有效的方法来从文本中检索定量信息。

**Method:** 本文提出了一种基于描述解析的框架，将文本转换为结构化的（描述，数量）对，以实现有效的检索。为了改进学习，研究人员利用数量共现构建了一个大型的、基于弱监督的释义数据集。

**Result:** 该方法在金融年报大型语料库和新标注的数量描述数据集上进行了评估，将Top-1检索准确率从30.98%显著提高到64.66%。

**Conclusion:** 本文成功提出了数量检索任务，并通过描述解析和弱监督方法，显著提高了从非结构化文本中检索定量事实的效率和准确性。

> **ai_Abstract:** 本文提出了一种名为“数量检索”的新任务，旨在解决非结构化文本中定量事实难以获取的问题。该任务要求系统根据定量事实的描述返回相关数值和支持证据。为此，研究人员开发了一个基于描述解析的框架，将文本转化为结构化的（描述，数量）对。为了增强学习效果，他们还利用数量共现构建了一个大型的弱监督释义数据集。实验结果表明，该方法在金融年报等数据集上表现出色，将Top-1检索准确率从30.98%提升至64.66%。

> **摘要翻译:** 公司和政府不断生成定量事实，支持数据驱动的决策。虽然常见的定量事实是结构化的，但许多长尾定量事实仍埋藏在非结构化文档中，使其难以访问。我们提出了数量检索任务：给定一个定量事实的描述，系统返回相关值和支持证据。理解上下文中的数量语义对于此任务至关重要。我们引入了一个基于描述解析的框架，将文本转换为结构化的（描述，数量）对，以实现有效检索。为了改进学习，我们利用数量共现构建了一个大型的、基于弱监督的释义数据集。我们在金融年报的大型语料库和一个新标注的数量描述数据集上评估了我们的方法。我们的方法将Top-1检索准确率从30.98%显著提高到64.66%。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [286] [DS@GT at LongEval: Evaluating Temporal Performance in Web Search Systems and Topics with Two-Stage Retrieval](https://arxiv.org/abs/2507.08360)
> *DS@GT 在 LongEval：评估网络搜索系统和主题中的时间性能与两阶段检索*

*Anthony Miyaguchi, Imran Afrulbasha, Aleksandar Pramov* | **Category: cs.IR** | **Updated: 2025-07-11**

**Keywords:** 信息检索, 时间性能, 两阶段检索, LongEval, NDCG

**Comment:** 

> **TL;DR:** DS@GT团队在LongEval竞赛中，通过两阶段检索系统，评估了IR模型在随时间演变的网络内容上的性能，并取得了NDCG@10的特定分数。

**AI_Comments:** 该论文解决了信息检索领域一个重要且日益突出的问题：IR模型在动态网络环境中的性能退化。通过参与LongEval竞赛，并采用两阶段检索系统，该工作为评估和改进IR系统在时间维度上的鲁棒性提供了实证贡献。其两阶段检索方法，结合查询扩展和文档重排序，显示了在处理时间演变数据方面的潜力。然而，抽象中未详细说明两阶段的具体设计和其如何应对时间变化，这可能需要进一步的深入研究。

<details>
  <summary>Details</summary>

**Motivation:** 信息检索（IR）模型通常在静态数据集上训练，这使得它们在网络内容演变时容易出现性能下降。

**Method:** 该团队参与了CLEF 2025 的LongEval实验室，分析了Qwant网络数据集，包括随时间进行主题建模的探索性数据分析。两阶段检索系统采用稀疏关键词搜索，利用查询扩展和文档重排序。

**Result:** 我们最好的系统在整个训练和测试数据集上实现了平均NDCG@10为0.296，在2023年5月取得了0.395的总体最佳分数。

**Conclusion:** 该研究表明，所提出的两阶段检索系统在评估随时间变化的网络内容上的IR系统性能方面取得了可观的NDCG@10分数，验证了其在LongEval竞赛中的有效性。

> **ai_Abstract:** 本文介绍了DS@GT团队参加CLEF 2025 LongEval竞赛的工作，该竞赛旨在评估信息检索系统在随时间演变的网络内容上的性能。研究分析了Qwant网络数据集，并开发了一个两阶段检索系统，该系统结合了探索性数据分析、主题建模、稀疏关键词搜索、查询扩展和文档重排序。实验结果显示，该系统在LongEval数据集上取得了平均NDCG@10为0.296的性能，并在特定时间点达到0.395的最佳分数。

> **摘要翻译:** 信息检索（IR）模型通常在静态数据集上训练，这使得它们在网络内容演变时容易出现性能下降。DS@GT 竞赛团队参加了 CLEF 2025 的模型性能纵向评估（LongEval）实验室，该实验室评估跨时间分布的网络快照中的 IR 系统。我们对 Qwant 网络数据集的分析包括随时间进行主题建模的探索性数据分析。两阶段检索系统采用稀疏关键词搜索，利用查询扩展和文档重排序。我们最好的系统在整个训练和测试数据集上实现了平均 NDCG@10 为 0.296，在 2023 年 5 月取得了 0.395 的总体最佳分数。本文随附的源代码位于 https://github.com/dsgt-arc/longeval-2025

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [316] [Improving Korean-English Cross-Lingual Retrieval: A Data-Centric Study of Language Composition and Model Merging](https://arxiv.org/abs/2507.08480)
> *改进韩语-英语跨语言检索：一项关于语言构成和模型合并的数据中心研究*

*Youngjoon Jang, Junyoung Son, Taemin Lee, Seongtae Hong, Heuiseok Lim* | **Category: cs.IR** | **Updated: 2025-07-11**

**Keywords:** 跨语言信息检索, 数据构成, 模型合并, 韩语-英语, 单语言信息检索

**Comment:** 

> **TL;DR:** 研究发现训练数据的语言构成对跨语言和单语言检索性能有显著影响，模型合并能有效缓解性能权衡。

**AI_Comments:** 这项研究通过数据中心的方法，系统地揭示了训练数据语言构成对跨语言和单语言信息检索性能的复杂影响，具有重要的实践意义。其创新之处在于提出并验证了模型合并策略，有效解决了CLIR性能提升与单语言IR性能下降之间的权衡问题，为构建更鲁棒、更高效的多语言检索系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 随着多语言文本信息利用的增加，跨语言信息检索（CLIR）已成为关键研究领域。然而，训练数据构成对CLIR和单语言信息检索（IR）性能的影响尚未得到充分探索。

**Method:** 构建了语言平行的韩语-英语数据集，并使用各种语言组合训练检索模型。通过实验验证了训练数据语言构成对IR性能的影响，并引入模型合并来缓解CLIR和单语言IR之间的性能权衡。

**Result:** 实验表明，训练数据的语言构成显著影响IR性能，并表现出重要的语际关联：CLIR性能随特定语言对的增加而提高，而单语言IR性能则下降。模型合并可以有效缓解这种权衡，在实现强大的CLIR结果的同时保留单语言IR能力。

**Conclusion:** 研究强调了训练数据的语言配置对CLIR和单语言IR的影响，并提出模型合并是优化这些任务性能的可行策略。

> **ai_Abstract:** 本研究探讨了训练数据语言构成对跨语言信息检索（CLIR）和单语言信息检索（IR）性能的影响。通过构建韩语-英语并行数据集并进行实验，发现训练数据的语言组成显著影响IR性能，并存在CLIR性能提升而单语言IR性能下降的权衡。研究提出模型合并（Model Merging）作为一种有效策略，可以缓解这种权衡，在提升CLIR性能的同时保持单语言IR能力。

> **摘要翻译:** 随着多语言文本信息利用的增加，跨语言信息检索（CLIR）已成为一个关键的研究领域。然而，训练数据构成对CLIR和单语言信息检索（IR）性能的影响仍未得到充分探索。为了系统地研究这一以数据为中心的问题，我们构建了语言平行的韩语-英语数据集，并使用各种语言组合训练检索模型。我们的实验表明，训练数据的语言构成显著影响IR性能，表现出重要的语际关联：CLIR性能随特定语言对的增加而提高，而单语言IR性能则下降。我们的工作表明，模型合并可以有效缓解这种权衡，在实现强大的CLIR结果的同时保留单语言IR能力。我们的发现强调了训练数据的语言配置对CLIR和单语言IR的影响，并提出模型合并是优化这些任务性能的可行策略。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [346] [Digital gazetteers: review and prospects for place name knowledge bases](https://arxiv.org/abs/2507.08553)
> *数字地名录：地名知识库的审查与展望*

*Kalana Wijegunarathna, Kristin Stock, Christopher B. Jones* | **Category: cs.IR** | **Updated: 2025-07-11**

**Keywords:** 数字地名录, 地名知识库, 地理信息检索, 数据整合, 地名消歧

**Comment:** 

> **TL;DR:** 数字地名录在地理信息检索中很重要，但目前存在数据标准和多面性表示的不足。本文综述了现有技术，并提出未来需要更丰富的地名表示和数据整合方法。

**AI_Comments:** 这篇论文对于理解数字地名录的现状和未来发展方向具有重要意义。它不仅指出了现有技术的局限性，如缺乏统一标准和多维度表示不足，还为未来的研究提供了明确的方向，尤其是在丰富地名表示、时间演变和数据整合方面。其创新之处在于系统性地梳理了该领域面临的挑战和潜在的改进点。

<details>
  <summary>Details</summary>

**Motivation:** 地名录在在线地理信息检索中扮演重要角色，但现有地名录存在数据编码缺乏标准、对地名多重特征表示有限的缺点，限制了用户根据特定特征搜索位置的能力。

**Method:** 本文对数字地名录技术进行了综述，包括数据源、组件、软件和数据管理技术、数据质量和志愿数据，以及匹配同一现实世界地点的源的方法。

**Result:** 综述揭示了当前地名录的局限性，并强调了未来工作需要关注更丰富的地名表示、地名身份和位置的时间演变，以及更有效的数据整合方法。

**Conclusion:** 数字地名录需要改进其数据表示的丰富性和数据整合方法，以提高未来信息检索的有效性。

> **ai_Abstract:** 本文回顾了数字地名录技术，指出当前地名录在数据标准化和多方面特征表示上的不足。文章综述了地名录的数据源、组件、技术、数据质量及数据整合方法，并强调未来研究应着重于丰富地名表示、考虑时间演变以及提升数据整合效率，以增强信息检索能力。

> **摘要翻译:** 地名录通常存储地名、地点类型及相关坐标数据。它们在在线地理信息检索系统中，对于导航和地图绘制中的地名消歧、文本中地名的检测和消歧以及提供坐标方面发挥着重要作用。目前有许多来自不同来源的地名录在使用，但没有普遍接受的数据编码标准。大多数地名录在表示命名地点的多重方面方面也极其有限，然而它们有潜力帮助用户搜索具有特定物理、商业、社会或文化特征的位置。为了理解数字地名录技术并提高其未来信息检索的有效性，我们对数据源、组件、软件和数据管理技术、数据质量和志愿数据，以及匹配指向同一现实世界地点的源的方法进行了综述。我们强调未来工作需要更丰富的命名地点表示、地点身份和位置的时间演变，以及更有效的数据整合方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [411] [Drowning in Documents: Consequences of Scaling Reranker Inference](https://arxiv.org/abs/2411.11767)
> *溺于文档：扩展重排器推理的后果*

*Mathew Jacob, Erik Lindgren, Matei Zaharia, Michael Carbin, Omar Khattab, Andrew Drozdov* | **Category: cs.IR, cs.CL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 重排器,信息检索,交叉编码器,密集嵌入,性能评估

**Comment:** Accepted to ReNeuIR 2025 Workshop at SIGIR 2025 Conference

> **TL;DR:** 重排器在检索任务中的表现不如预期，尤其是在处理大量文档时，其效果会下降甚至损害整体质量。

**AI_Comments:** 该研究对重排器在信息检索中的作用提出了重要的质疑，其方法论严谨，使用了多样化的数据集。研究结果表明，重排器的性能并非随着文档数量的增加而线性提升，这与广泛的行业实践相悖，具有重要的理论和实践意义。然而，研究可能需要进一步探讨导致性能下降的具体机制，以及如何设计更具鲁棒性的重排器。

<details>
  <summary>Details</summary>

**Motivation:** 评估重排器在完整检索而非仅重排初级检索结果时的表现，并挑战其优于初级检索系统的普遍假设。

**Method:** 使用现代密集嵌入来优先考虑强大的初级检索，并在精心挑选的、具有挑战性的任务（包括内部策划的数据集和域外数据集）上测试重排器，以衡量其在对更多文档进行评分时的表现。

**Result:** 重排器在对更多文档进行评分时最初会带来改进，但其有效性会逐渐下降，甚至在超过一定限制后会损害质量。

**Conclusion:** 重排器的有效性并非无限，在处理大量文档时可能适得其反，这表明需要进一步研究以改进重排技术。

> **ai_Abstract:** 这项研究评估了重排器在完整检索任务中的表现，挑战了它们优于初级检索系统的普遍看法。通过在具有挑战性的数据集上进行严格的评估，研究发现重排器的有效性会随着处理的文档数量增加而下降，甚至可能损害检索质量，这表明需要对重排技术进行进一步的研究和改进。

> **摘要翻译:** 重排器，通常是交叉编码器，计算成本很高，但由于人们普遍认为它们优于廉价的初级信息检索系统，因此经常被使用。我们通过衡量重排器在完整检索（而不仅仅是重排初级检索结果）中的表现来挑战这一假设。为了提供更稳健的评估，我们优先考虑使用现代密集嵌入的强大初级检索，并在各种精心挑选的、具有挑战性的任务上测试重排器，包括内部策划的数据集以避免污染，以及域外数据集。我们的实证结果揭示了一个令人惊讶的趋势：现有的最佳重排器在对越来越多的文档进行评分时最初会带来改进，但其有效性会逐渐下降，甚至在超过某个限制后会损害质量。我们希望我们的发现能激发未来改进重排的研究。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [446] [Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval](https://arxiv.org/abs/2504.01403)
> *生成检索与对齐模型：电子商务检索的新范式*

*Ming Pang, Chunyuan Yuan, Xiaoyu He, Zheng Fang, Donghao Xie, Fanyi Qu, Xue Jiang, Changping Peng, Zhangang Lin, Ching Law, Jingping Shao* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** 生成检索与对齐模型, 电子商务检索, 大型语言模型, 标识符生成, 召回效率

**Comment:** Accepted by WWW2025

> **TL;DR:** 本研究提出了一种名为GRAM的新型电子商务检索范式，旨在解决传统检索方法在利用世界知识和处理查询-产品细微差别方面的不足。GRAM通过联合训练查询和产品的文本信息来生成共享的文本标识符代码，以弥合查询和产品之间的差距，从而提高检索效率和准确性。实验结果表明，GRAM的性能优于传统模型和最新的生成式检索模型。

**AI_Comments:** 该研究提出了一种新颖的电子商务检索范式（GRAM），解决了现有方法在利用世界知识和处理查询-产品细微差别方面的不足。通过联合训练生成共享的文本标识符代码，GRAM有效弥合了查询和产品之间的差距，提高了检索效率和准确性。模型采用的联合对齐策略和查询-产品评分机制是其创新之处。广泛的离线和在线测试结果证实了GRAM的优越性，展示了其在实际应用中的潜力和价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统稀疏和稠密检索方法难以利用通用世界知识，且无法捕捉查询和产品的细微特征。基于LLM的方法虽然利用了世界知识，但产品标识符与用户查询的词分布差异大，导致召回率低。当查询包含多个属性时，现有算法生成的标识符过多，难以评估质量，整体召回效率低下。

**Method:** 提出了一种名为GRAM（生成检索与对齐模型）的新型电子商务检索范式。GRAM通过联合训练查询和产品的文本信息来生成共享的文本标识符代码，以弥合查询和产品之间的差距。该模型采用联合对齐策略生成优化检索效率的代码，并引入查询-产品评分机制来比较不同代码下的产品值，以进一步提高检索效率。

**Result:** GRAM在离线和在线A/B测试中均显著优于传统的检索模型和最新的生成式检索模型，证明了其有效性和实用性。

**Conclusion:** GRAM通过生成共享的文本标识符代码，有效弥合了查询和产品之间的差距，提高了检索效率和准确性，是一种有效且实用的电子商务检索新范式。

> **ai_Abstract:** 本研究提出了一种名为GRAM的新型电子商务检索范式，旨在解决传统检索方法在利用世界知识和处理查询-产品细微差别方面的不足。GRAM通过联合训练查询和产品的文本信息来生成共享的文本标识符代码，以弥合查询和产品之间的差距，从而提高检索效率和准确性。实验结果表明，GRAM的性能优于传统模型和最新的生成式检索模型。

> **摘要翻译:** 传统的稀疏和密集检索方法在利用通用世界知识和捕捉查询与产品的细微特征方面存在不足。随着大型语言模型（LLM）的出现，工业搜索系统已开始采用LLM为产品检索生成标识符。常用的标识符包括（1）静态/语义ID和（2）产品术语集。第一种方法需要从头开始创建产品ID系统，未能利用LLM中蕴含的世界知识。而第二种方法虽然利用了通用知识，但查询和产品之间的词分布存在显著差异，导致基于产品的标识符通常与用户搜索查询不能很好地对齐，从而造成产品召回遗漏。此外，当查询包含多个属性时，这些算法会生成大量标识符，使得评估其质量变得困难，导致整体召回效率低下。
为了解决这些挑战，本文提出了一种新颖的电子商务检索范式：生成检索与对齐模型（GRAM）。GRAM通过联合训练来自查询和产品的文本信息来生成共享的文本标识符代码，有效地弥合了查询和产品之间的差距。这种方法不仅增强了查询和产品之间的联系，而且提高了推理效率。该模型使用联合对齐策略来生成优化检索效率的代码。此外，它还引入了一个查询-产品评分机制来比较不同代码下的产品值，进一步提高了检索效率。广泛的离线和在线A/B测试表明，GRAM的性能显著优于传统模型和最新的生成式检索模型，证实了其有效性和实用性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [381] [NeurOptimisation: The Spiking Way to Evolve](https://arxiv.org/abs/2507.08320)
> *神经优化：进化的脉冲方式*

*Jorge Mario Cruz-Duarte, El-Ghazali Talbi* | **Category: cs.NE, 90C26, 68T07, 65K10, 68W10, 68W50, I.2.6; I.2.8; I.2.11; G.1.6; I.6.3; F.1.1** | **Updated: 2025-07-11**

**Keywords:** 神经形态计算, 脉冲神经网络, 元启发式优化, 去中心化优化, 低功耗计算

**Comment:** Submitted to the IEEE Transactions on Evolutionary Computation (under
  review)

> **TL;DR:** 提出了一种名为NeurOptimiser的、完全基于脉冲的优化框架，利用神经形态计算（NC）和脉冲神经网络（SNN）的生物启发特性，实现高效、可扩展且低功耗的去中心化优化。

**AI_Comments:** 该研究在神经形态计算和优化领域取得了重要进展，提出了一种新颖的、完全基于脉冲的优化框架。其主要创新在于利用脉冲神经网络的生物启发特性来实现去中心化、低功耗的优化过程。然而，该框架目前仍处于概念验证阶段，其在更复杂和大规模问题上的性能和可扩展性仍需进一步验证。此外，对不同神经元模型和启发式策略的敏感性也值得深入探讨。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能系统日益增长的能源消耗需要高效且可扩展的替代计算模型，神经形态计算（NC）通过提供最小功耗的事件驱动算法来解决这一挑战。

**Method:** 提出NeurOptimiser，一个完全基于脉冲的优化框架，利用神经形态启发元启发式范式，通过去中心化的NC系统实现。该方法包括一个Neuromorphic Heuristic Units（NHUs）种群，每个单元结合了脉冲神经元动力学和脉冲触发扰动启发式方法，以异步方式演化候选解。NeurOptimiser的协调通过本地信息共享和全局状态更新的原生脉冲机制实现，无需外部协调。该框架在Intel的Lava平台和Loihi 2芯片上实现，并在无噪声BBOB套件（高达40维）上进行了评估，使用了不同的配置，例如线性模型和Izhikevich模型，以及固定和差分进化突变规则。

**Result:** 实验结果表明，该方法表现出结构化种群动态、持续收敛，并具有毫瓦级功耗可行性。

**Conclusion:** 实验结果表明，提出的方法在结构化种群动态、持续收敛和毫瓦级功耗方面表现出色，证明了脉冲原生元启发式方法是实现实时、低能耗和去中心化优化的可行途径。

> **ai_Abstract:** 本文提出了一种名为NeurOptimiser的全新优化框架，该框架完全基于脉冲计算，并利用神经形态计算（NC）的去中心化和低功耗特性。通过结合脉冲神经元动力学和脉冲触发扰动启发式方法，NeurOptimiser能够异步演化解决方案。该框架在Intel的Lava平台和Loihi 2芯片上实现，并在各种配置下进行了评估，结果表明其在收敛性、结构化种群动态和低功耗方面表现出色，为实现实时、低能耗的去中心化优化提供了新途径。

> **摘要翻译:** 人工智能系统日益增长的能源足迹促使人们寻找既高效又可扩展的替代计算模型。神经形态计算（NC）通过赋能事件驱动算法来应对这一挑战，这些算法通过受生物启发的脉冲动力学以最小的功耗运行。我们提出了NeurOptimiser，一个完全基于脉冲的优化框架，通过去中心化的NC系统实现受神经形态启发的元启发式范式。所提出的方法包括一个神经形态启发单元（NHUs）种群，每个单元结合了脉冲神经元动力学和脉冲触发扰动启发式方法，以异步方式演化候选解。NeurOptimiser的协调通过支持活动传播、本地信息共享和全局状态更新的原生脉冲机制实现，无需外部协调。我们将此框架实现在Intel的Lava平台上，目标是Loihi 2芯片，并在高达40维的无噪声BBOB套件上进行评估。我们部署了几个使用不同配置的NeurOptimiser，主要考虑动态系统，如线性模型和Izhikevich模型用于脉冲神经元动力学，以及固定和差分进化突变规则用于脉冲触发启发式方法。尽管这些配置作为概念验证实现，但我们记录并概述了该框架实现的进一步扩展和改进。结果表明，所提出的方法表现出结构化种群动态、持续收敛和毫瓦级功耗可行性。它们还将脉冲原生的元启发式方法定位为实现实时、低能耗和去中心化优化的可行途径。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [416] [Enhancing Parameter Control Policies with State Information](https://arxiv.org/abs/2507.08368)
> *增强具有状态信息的参数控制策略*

*Gianluca Covini, Denis Antipov, Carola Doerr* | **Category: cs.NE** | **Updated: 2025-07-11**

**Keywords:** 参数控制,进化计算,状态信息,RLS_k,LeadingOnes

**Comment:** To appear in the Proc. of FOGA, the 18th ACM/SIGEVO Conference on
  Foundations of Genetic Algorithms

> **TL;DR:** 该研究提出了一种新的参数控制策略，利用算法的状态信息来优化进化计算中的参数选择，并在LeadingOnes函数上通过RLS_k算法进行了验证，结果表明利用更多状态信息可以显著提高优化性能。

**AI_Comments:** 该研究在参数控制领域取得了重要进展，通过引入状态信息来优化算法性能，尤其是在边缘状态下的改进值得关注。然而，该方法在实际应用中的普适性和可扩展性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 研究自动化参数控制方法以找到最优控制策略，但目前最优策略仅在少数情况下已知，限制了自动化方法的发展。

**Method:** 提出四个新的基准测试，用于优化LeadingOnes函数和RLS_k算法（一种允许动态选择突变强度k的局部搜索算法）。研究了利用算法的当前状态信息（如当前OneMax值）来优化参数选择和后代选择，并分析了这些选择对性能的影响。

**Result:** 利用OneMax值作为状态信息，可以做出更好的参数选择，尤其是在边缘状态下，这可以显著缩短预期运行时间。

**Conclusion:** 所提出的基准测试为分析参数控制方法在丰富的状态空间中的性能，以及它们通过正确的参数选择来捕捉性能提升的能力，提供了一个具有挑战性但有前途的测试平台。

> **ai_Abstract:** 本研究提出了一种新的参数控制策略，该策略利用进化计算中算法的状态信息（如当前OneMax值）来动态调整参数（如变异强度k），以优化特定函数（如LeadingOnes）。研究发现，利用更多状态信息可以显著改善参数选择，尤其是在算法的边缘状态下，从而缩短预期运行时间。作者开发了新的基准测试来验证这些方法，并认为这些基准测试为未来参数控制研究提供了有价值的平台。

> **摘要翻译:** 参数控制与动态算法配置研究的是在优化过程中动态选择参数化算法的合适配置。尽管这是进化计算中一个被广泛研究的主题，但最优控制策略仅在极少数情况下为人所知，这限制了实现它们的自动化方法的发展。
在此工作中，我们提出了四个新的基准测试，为它们推导出了最优或接近最优的控制策略。更具体地说，我们通过RLS_k优化了LeadingOnes函数，这是一种允许动态选择变异强度k的局部搜索算法。基准测试的不同之处在于算法可以利用哪些信息来设置其参数并选择后代。在现有的运行时间结果中，可利用的信息通常仅限于当前最佳解决方案的质量。在这项工作中，我们考虑了算法的当前状态的附加信息如何帮助做出更好的参数选择，以及这些选择如何影响性能。即，我们允许算法使用关于当前OneMax值的信息，并且我们发现这可以带来更好的参数选择，尤其是在边缘状态下。尽管算法很少访问这些状态，但这种策略在预期运行时间方面产生了显著的加速。
这使得所提出的基准测试成为一个具有挑战性但有前途的测试平台，用于分析参数控制方法在丰富的状态空间中的性能，以及它们通过捕捉正确的参数选择所带来的性能改进的能力。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [486] [TS-SNN: Temporal Shift Module for Spiking Neural Networks](https://arxiv.org/abs/2505.04165)
> *时间移位模块用于脉冲神经网络*

*Kairong Yu, Tianqing Zhang, Qi Xu, Gang Pan, Hongwei Wang* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 脉冲神经网络, 时间移位模块, 神经形态计算, 深度学习, 计算机视觉

**Comment:** Accepted by ICML2025

> **TL;DR:** TS-SNN通过引入时间移位（TS）模块，在单个时间步长内整合过去、现在和未来的脉冲特征，以提高SNN的性能和能效。

**AI_Comments:** 该研究提出了一种创新的TS模块，能够有效地在SNN中整合时间信息，并在保持低能耗的同时提高了准确性。其轻量级设计和易于集成是其显著优点。然而，在更复杂的模型和任务上的泛化能力有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** SNN在生物可塑性和能效方面具有优势，但平衡时间特征利用和低能耗是一个挑战。

**Method:** 引入了新颖的时间移位（TS）模块，通过简单的移位操作在单个时间步长内整合过去、现在和未来的脉冲特征，并采用残差组合方法防止信息丢失。

**Result:** TS-SNN在CIFAR-10、CIFAR-100和ImageNet等基准测试中取得了最先进的性能，并且所需时间步长更少，同时保持了低能耗。

**Conclusion:** TS-SNN标志着开发高效、准确的SNN架构向前迈出了重要一步。

> **ai_Abstract:** TS-SNN提出了一种新颖的时间移位（TS）模块，用于脉冲神经网络（SNN）。该模块通过在单个时间步长内整合过去、现在和未来的脉冲特征来增强SNN处理时间信息的能力，同时保持低能耗。TS-SNN在多个图像识别基准测试中取得了最先进的性能，并且计算成本低廉。

> **摘要翻译:** 脉冲神经网络（SNN）因其生物可塑性和能效而越来越受到认可，使其成为神经形态计算应用中人工神经网络（ANN）的有力替代品。SNN通过利用脉冲的精确时间来固有地处理时间信息，但平衡时间特征利用与低能耗仍然是一个挑战。在这项工作中，我们引入了用于脉冲神经网络的时间移位模块（TS-SNN），它包含一个新颖的时间移位（TS）模块，通过简单而有效的移位操作在单个时间步长内整合过去、现在和未来的脉冲特征。残差组合方法通过整合移位和原始特征来防止信息丢失。TS模块轻量级，仅需要一个额外的可学习参数，并且可以无缝集成到现有架构中，而额外的计算成本最小。TS-SNN在CIFAR-10（96.72%）、CIFAR-100（80.28%）和ImageNet（70.61%）等基准测试中取得了最先进的性能，并且所需时间步长更少，同时保持了低能耗。这项工作标志着开发高效、准确的SNN架构向前迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [44] [A filtered multilevel Monte Carlo method for estimating the expectation of cell-centered discretized random fields](https://arxiv.org/abs/2311.06069)
> *一种用于估计以单元为中心离散随机场期望的滤波多级蒙特卡洛方法*

*Jérémy Briant, Paul Mycek, Mayeul Destouches, Olivier Goux, Serge Gratton, Selime Gürol, Ehouarn Simon, Anthony T. Weaver* | **Category: math.NA, cs.NA, 65C05, 62P12** | **Updated: 2025-07-11**

**Keywords:** 多级蒙特卡洛, 滤波多级蒙特卡洛, 随机场, 网格传输算子, 谱分析

**Comment:** 

> **TL;DR:** 本文提出了一种滤波多级蒙特卡洛(F-MLMC)方法，通过引入网格传输算子和滤波机制，有效降低了离散随机场期望估计的方差，并优于传统方法。

**AI_Comments:** 本文的创新点在于将多重网格方法中的网格传输算子和滤波机制引入到多级蒙特卡洛方法中，有效解决了维度不一致问题并显著降低了估计器的方差。其理论分析和实验验证，特别是在非线性模拟器下的表现，显示了该方法的重要性和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 针对多级蒙特卡洛(MLMC)方法在估计离散随机场期望时，数值模拟器输入输出向量在多级层次结构中维度不一致的问题。

**Method:** 引入了多重网格方法中的网格传输算子，并基于多重网格方法的数学工具对MLMC估计器进行了理论谱分析。在此基础上，提出了基于滤波机制的滤波多级蒙特卡洛（F-MLMC）估计器。通过一维示例和应用于扩散协方差算子的离散方差场估计问题进行实验验证。

**Result:** 滤波算子改善了方差的小尺度和大尺度分量估计，从而降低了估计器的总方差。数值实验支持了理论分析的结论，即使对于非线性模拟器也有效。F-MLMC估计器与粗略蒙特卡洛和未滤波MLMC估计器相比，表现出显著的改进。

**Conclusion:** 提出的滤波多级蒙特卡洛（F-MLMC）方法通过引入滤波机制，有效解决了多级蒙特卡洛方法在处理维度不一致问题时的挑战，显著降低了离散随机场期望估计的方差，并在理论和实验上均证明了其优越性，甚至适用于非线性模拟器。

> **ai_Abstract:** 本文提出了一种滤波多级蒙特卡洛（F-MLMC）方法，用于估计以单元为中心离散随机场的期望。针对多级层次结构中数值模拟器输入输出维度不一致的问题，该方法引入了多重网格的网格传输算子，并进行了理论谱分析。F-MLMC估计器通过类似多重网格平滑的滤波机制，能够改善方差的估计并降低总方差。数值实验验证了其理论分析的正确性，并表明F-MLMC在非线性模拟器下也能显著优于粗略蒙特卡洛和未滤波MLMC方法。

> **摘要翻译:** 在本文中，我们研究了使用多级蒙特卡洛（MLMC）方法来估计离散随机场的期望。具体来说，我们考虑了一种设置，其中数值模拟器的输入和输出向量在多级层次结构中具有不一致的维度。这促使我们引入了借鉴自多重网格方法的网格传输算子。通过借鉴多重网格方法的数学工具，我们对离散随机场期望的MLMC估计器进行了理论谱分析，特别是在线性、对称和循环模拟器的情况下。然后，我们提出了基于类似于多重网格方法平滑过程的滤波机制的滤波MLMC（F-MLMC）估计器，并且我们表明滤波算子改善了方差的小尺度和大尺度分量的估计，从而降低了估计器的总方差。接下来，通过一维示例对谱分析的结论进行了实验验证。最后，将所提出的F-MLMC估计器应用于估计基于扩散协方差算子的离散方差场的问题，这相当于估计离散随机场的期望。数值实验支持了理论分析的结论，即使对于非线性模拟器也有效，并证明了F-MLMC估计器与粗略MC和未滤波MLMC估计器相比所带来的改进。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [72] [Decoupling multistep schemes for elliptic-parabolic problems](https://arxiv.org/abs/2407.18594)
> *椭圆-抛物线问题的解耦多步格式*

*Robert Altmann, Abdullah Mujahid, Benjamin Unger* | **Category: math.NA, cs.NA** | **Updated: 2025-07-11**

**Keywords:** 解耦多步格式, 椭圆-抛物线问题, G-稳定性, 收敛性分析, 后向微分公式

**Comment:** 

> **TL;DR:** 本文研究并证明了高阶解耦多步格式（基于BDF）对椭圆-抛物线问题的收敛性，并提供了一种新的、更普适的G-稳定性收敛证明方法。

**AI_Comments:** 本文的创新之处在于提出了一种普适的G-稳定性收敛性证明方法，将其应用于任意阶数的解耦多步格式，并能更精确地刻画弱耦合条件。这对于数值方法在解决复杂耦合问题（如多网络孔隙弹性）中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究仅提供了二阶解耦多步格式的收敛性证明。本文旨在为高阶解耦多步格式提供一个普适的收敛性证明，并改进其构造方法和弱耦合条件的刻画。

**Method:** 使用后向微分公式（BDF）构建高阶解耦多步格式；提出了这些格式的微调版本，通过不同的时间延迟系统构造；采用基于G-稳定性概念的新颖收敛性证明方法，适用于任意阶数；关键工具是构建加权范数，使用伸缩论证分析误差和。

**Result:** 提出了高阶解耦多步格式的修改版本；提供了一种适用于任意阶数、基于G-稳定性概念的新型收敛性证明；新证明提供了对所需弱耦合条件更精确的描述。

**Conclusion:** 成功构建并证明了高阶解耦多步格式对椭圆-抛物线问题的收敛性，并通过G-稳定性方法提供了更普遍和精确的分析。

> **ai_Abstract:** 本文研究并改进了用于椭圆-抛物线问题（包括多网络孔隙弹性）的高阶解耦多步格式的构造和收敛性分析。在现有二阶证明的基础上，作者提出了一种略微修改的格式版本，并开发了一种基于G-稳定性概念的新型普适收敛性证明，该证明适用于任意阶数，并能更精确地刻画弱耦合条件。核心分析工具是加权范数和伸缩论证。

> **摘要翻译:** 我们研究了使用后向微分公式构建高阶解耦多步格式的构造和收敛性，用于解决椭圆-抛物线问题，其中多网络孔隙弹性是其一个特例。这些格式最初由[Altmann, Maier, Unger, BIT Numer. Math., 64:20, 2024]引入，该文献中给出了二阶情况的收敛性证明。本文中，我们提出了这些格式的一个略微修改的版本，使用了相关时间延迟系统的不同构造方法。我们提出了一种新颖的收敛性证明，该证明依赖于G-稳定性概念，适用于任意阶数，并提供了对所需弱耦合条件更精确的刻画。收敛性分析的关键工具是构建一个加权范数，从而能够对误差和进行伸缩论证。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [96] [Tensor Density Estimator by Convolution-Deconvolution](https://arxiv.org/abs/2412.18964)
> *基于卷积-反卷积的张量密度估计器*

*Yifan Peng, Siyao Yang, Yuehaw Khoo, Daren Wang* | **Category: math.NA, cs.NA, 15A69, 62Gxx** | **Updated: 2025-07-11**

**Keywords:** 密度估计, 张量列车, 卷积, 反卷积, 线性代数框架

**Comment:** 

> **TL;DR:** 提出了一种基于卷积、张量分解和反卷积的线性代数框架，用于高效准确的密度估计。

**AI_Comments:** 这项工作创新性地将线性代数框架与张量列车分解相结合应用于密度估计，通过卷积和反卷积步骤有效地处理了数据方差和表示问题。其核心贡献在于提供了一种可能比传统方法更高效、更准确的密度估计途径，特别是在处理高维数据时可能展现出优势。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供一个用于执行密度估计的线性代数框架，以解决传统方法可能存在的方差过大问题。

**Method:** 该方法包含三个步骤：首先，使用平滑核对经验分布进行卷积以去除指数级大的方差；其次，通过高效的张量分解算法将卷积后的经验分布压缩为张量列车；最后，应用反卷积步骤从张量列车表示中恢复估计的密度。

**Result:** 数值结果表明所提出的方法具有高精度和高效率。

**Conclusion:** 所提出的基于卷积-反卷积的张量密度估计器是一个高效且准确的密度估计方法。

> **ai_Abstract:** 该论文提出了一种新颖的线性代数框架，用于密度估计。该框架通过卷积平滑经验分布以减少方差，接着利用张量分解将数据压缩为张量列车形式，最后通过反卷积恢复估计密度。数值实验证明了该方法的高准确性和效率。

> **摘要翻译:** 我们提出了一种用于执行密度估计的线性代数框架。它由三个简单的步骤组成：用某些平滑核对经验分布进行卷积以去除指数级大的方差；将卷积后的经验分布压缩为张量列车，并采用高效的张量分解算法；最后，应用反卷积步骤从这种张量列车表示中恢复估计的密度。数值结果表明所提出的方法具有高精度和高效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [120] [Blind free deconvolution over one-parameter sparse families via eigenmatrix](https://arxiv.org/abs/2501.10660)
> *基于特征矩阵的单参数稀疏族盲自由反卷积*

*Lexing Ying* | **Category: math.NA, cs.NA, math.ST, stat.TH** | **Updated: 2025-07-10**

**Keywords:** 盲自由反卷积, 稀疏谱测度, 特征矩阵, R-变换, S-变换

**Comment:** 

> **TL;DR:** 本文通过特征矩阵方法，利用R-变换和S-变换将单参数稀疏族中具有挑战性的非线性盲自由反卷积问题转化为线性问题并求解，并提供了数值结果。

**AI_Comments:** 本文的创新之处在于巧妙地利用R-变换和S-变换将具有挑战性的非线性盲自由反卷积问题转化为线性问题，并采用特征矩阵方法进行求解。这为解决自由概率论中的非线性稀疏恢复问题提供了一种有效的新途径。

<details>
  <summary>Details</summary>

**Motivation:** 解决单参数稀疏族盲自由反卷积问题，因为其涉及非线性稀疏恢复，具有显著挑战性。

**Method:** 采用特征矩阵方法，通过R-变换（用于自由加法）和S-变换（用于自由乘法）将非线性逆问题转化为线性逆问题，然后使用针对参数族域的特征矩阵方法求解。

**Result:** 提供了加性和乘性自由反卷积的数值结果。

**Conclusion:** 该研究通过特征矩阵方法成功解决了单参数稀疏族盲自由反卷积中的非线性稀疏恢复问题，并提供了数值结果。

> **ai_Abstract:** 本文研究了单参数族中稀疏谱测度的盲自由反卷积问题，该问题涉及非线性稀疏恢复。文章提出了一种特征矩阵方法，通过R-变换和S-变换将非线性逆问题转化为线性问题。随后，使用为参数族域量身定制的特征矩阵方法求解该线性问题，并提供了加性和乘性自由反卷积的数值结果。

> **摘要翻译:** 本文考虑了单参数族中稀疏谱测度的盲自由反卷积问题。这些问题由于涉及非线性稀疏恢复而带来了显著挑战。主要的技术工具是用于解决非结构化稀疏恢复问题的特征矩阵方法。关键思想是利用自由加法的R-变换和自由乘法的S-变换，将非线性逆问题转化为线性逆问题。由此产生的线性问题通过针对参数族域的特征矩阵方法求解。文中提供了加性和乘性自由反卷积的数值结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [144] [Quantile-RK and Double Quantile-RK Error Horizon Analysis](https://arxiv.org/abs/2505.00258)
> *分位数-RK和双分位数-RK误差范围分析*

*Emeric Battaglia, Anna Ma* | **Category: math.NA, cs.NA, 65F10, 65F20** | **Updated: 2025-07-11**

**Keywords:** 分位数随机Kaczmarz, 双分位数随机Kaczmarz, 误差范围, 线性系统, 稀疏干扰

**Comment:** 

> **TL;DR:** 本文分析了分位数随机Kaczmarz (qRK) 和双分位数随机Kaczmarz (dqRK) 方法在存在稀疏和非稀疏噪声时的误差范围，并证明它们能有效降低误差。

**AI_Comments:** 这篇论文通过引入分位数方法来增强随机Kaczmarz算法对数据干扰的鲁棒性，特别是在处理稀疏和混合干扰方面。其创新点在于提出了新的收敛率并证明了分位数方法在减小误差范围方面的优越性，这对于实际应用中数据存在噪声或损坏的情况具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在求解线性系统$Ax=b$时，如果$b$中存在干扰，会影响随机迭代算法达到真实解$x^*$，并产生一个误差范围。现有的随机Kaczmarz方法存在误差范围，而分位数方法旨在解决稀疏干扰情况下的误差范围问题。

**Method:** 本文首先为分位数随机Kaczmarz (qRK) 和双分位数随机Kaczmarz (dqRK) 方法建立了新的收敛速度，并在特定条件下改进了已知界限。进一步，考虑了$b$向量同时包含非稀疏“噪声”和稀疏“干扰”的更实际情况，并推导了qRK和dqRK的误差范围界限。

**Result:** qRK和dqRK方法在特定条件下，其新的收敛速度优于已知界限。在同时存在非稀疏噪声和稀疏干扰的情况下，qRK和dqRK的误差范围界限被证明小于其非分位数对应方法。

**Conclusion:** 分位数方法在处理线性系统中的稀疏和非稀疏干扰时，能够产生更小的误差范围，从而证明了其优越性。

> **ai_Abstract:** 本文研究了分位数随机Kaczmarz (qRK) 和双分位数随机Kaczmarz (dqRK) 方法在求解受干扰线性系统时的性能。研究建立了qRK和dqRK的新收敛速度，并在同时存在稀疏和非稀疏干扰的更实际场景下，推导了它们的误差范围界限。结果表明，与传统方法相比，分位数方法能显著减小误差范围，突显了其在处理数据干扰方面的优势。

> **摘要翻译:** 在求解$Ax=b$形式的线性方程组时，$b$中存在的干扰会影响随机迭代算法达到未受干扰线性系统的真实解$x^
ast$的能力。随机Kaczmarz方法在期望上收敛到$x^
ast$，但存在一个误差范围，该误差范围取决于$A$的条件数和$b$中干扰的上确界范数。为了避免稀疏干扰设置中的此误差范围，先前的工作提出了基于分位数的改进方法，使迭代方法具有鲁棒性。我们的工作首先为基于分位数随机Kaczmarz (qRK) 和双分位数随机Kaczmarz (dqRK) 方法建立了新的收敛速度，在某些条件下，这改进了已知的界限。我们进一步考虑了更实际的情况，即向量$b$同时包含非稀疏“噪声”和稀疏“干扰”。推导了qRK和dqRK的误差范围界限，并表明与非分位数对应方法相比，它们产生了更小的误差范围，进一步证明了基于分位数方法的优势。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [168] [Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination](https://arxiv.org/abs/2507.01762)
> *单纯形网格优化的全局能量最小化：一种基于半径比的薄片消除方法*

*Dong Wang, Chunyu Chen, Huayi Wei* | **Category: math.NA, cs.NA, math.OC, 65N50, 65K10, 65F08** | **Updated: 2025-07-11**

**Keywords:** 单纯形网格, 薄片消除, 能量最小化, 半径比, 网格优化

**Comment:** 

> **TL;DR:** 本文提出了一种基于半径比能量函数的新方法，用于优化单纯形网格质量，有效消除薄片单元，提高网格质量。

**AI_Comments:** 该论文提出了一种创新的半径比能量函数方法来解决单纯形网格中的薄片单元问题，其亮点在于将梯度分解为对称正定矩阵作为预条件子，从而显著加速优化过程。这对于提高数值模拟的稳定性和准确性具有重要意义，展现了在计算几何和有限元分析领域的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 单纯形网格的质量对有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要，但三维单纯形网格中薄片单元的存在会严重影响结果。

**Method:** 本文提出了一种基于半径比能量函数的新方法来优化单纯形网格单元的质量。该方法的能量函数梯度可以分解为矩阵-向量乘积，经过处理后，该矩阵变为对称正定，并可作为预条件子显著加速优化过程。

**Result:** 实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。

**Conclusion:** 该方法通过半径比能量函数实现了单纯形网格的有效优化，成功消除了薄片单元，显著提升了网格质量，为数值模拟提供了更好的基础。

> **ai_Abstract:** 本研究提出一种基于半径比能量函数的新型方法，旨在优化单纯形网格质量，尤其针对三维网格中的薄片单元问题。通过将能量函数梯度分解为可作为预条件子的对称正定矩阵，该方法显著提升了优化效率。实验证明，该方法在消除薄片和提升网格质量方面表现出显著优势，对有限元分析和计算几何的数值模拟具有重要意义。

> **摘要翻译:** 单纯形网格的质量对于有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，三维单纯形网格中薄片单元的存在会严重影响结果。本文提出了一种基于半径比能量函数的新方法来优化单纯形网格单元的质量。该方法可以有效消除薄片单元，从而提高网格质量。所提出的能量函数的梯度可以分解为矩阵-向量乘积。经过少量处理，该矩阵变为对称正定，并且该对称正定矩阵可以作为预条件子显著加速优化过程。实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [491] [A Stokes-Brinkman-type formulation for the eigenvalue problem in porous media](https://arxiv.org/abs/2507.08226)
> *多孔介质中特征值问题的斯托克斯-布林克曼类型公式*

*Felipe Lepe, Gonzalo Rivera, Jesus Vellojin* | **Category: math.NA, cs.NA, 35Q35, 65N15, 65N25, 65N30, 65N50** | **Updated: 2025-07-11**

**Keywords:** 有限元方法,斯托克斯-布林克曼方程,多孔介质,特征值问题,自然频率

**Comment:** 

> **TL;DR:** 本文提出并分析了一种用于多孔介质中受斯托克斯-布林克曼方程控制的流动系统的有限元方法，用于近似自然频率，并提供了收敛性和误差估计。

**AI_Comments:** 该研究在多孔介质流动的自然频率近似方面提出了有效的有限元方法，并提供了理论支持和数值验证，具有一定的应用价值和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 在多孔介质中流动系统的自然频率近似问题。

**Method:** 使用有限元方法，结合斯托克斯正则性结果、inf-sup稳定有限元族和紧算子理论。

**Result:** 证明了特征值和特征函数的收敛性以及先验和后验误差估计，并通过数值测试进行了验证。

**Conclusion:** 所提出的有限元方法能够有效地近似多孔介质中流动系统的自然频率，并且具有良好的收敛性和误差估计。

> **ai_Abstract:** 本文提出了一种用于求解多孔介质中受斯托克斯-布林克曼方程控制的流动系统自然频率的有限元方法。该方法利用了斯托克斯正则性结果和inf-sup稳定有限元，并通过紧算子理论证明了特征值和特征函数的收敛性及误差估计，数值实验验证了理论的有效性。

> **摘要翻译:** 本文介绍并分析了一种用于二维和三维问题的有限元方法，用于近似受斯托克斯-布林克曼方程控制的流动系统的自然频率。在此，流体具有在多孔介质中存在的特性。利用斯托克斯解的正则性结果，并考虑inf-sup稳定有限元族，我们借助紧算子理论证明了特征值和特征函数的收敛性以及先验和后验误差估计。我们报告了一系列数值测试以证实所发展的理论。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [526] [Computational algorithm for downward continuation of gravity anomalies](https://arxiv.org/abs/2507.08506)
> *重力异常的向下延拓计算算法*

*D. K. Ivanov, L. N. Temirbekova, P. N. Vabishchevich* | **Category: math.NA, cs.NA, 35R30, 65R20, 86A22, 65F10, 45Q05** | **Updated: 2025-07-11**

**Keywords:** 向下延拓,重力勘探,位场,正则化,非负最小二乘法

**Comment:** 17 pages, 11 figures

> **TL;DR:** 该研究提出了一种新的计算算法，用于解决重力勘探中的向下延拓问题，该算法通过表示连续场作为简单层或其垂直导数的势能，并利用非负最小二乘法（NNLS）来保持异常值的符号，在模型示例中证明了其有效性。

**AI_Comments:** 该方法在保持异常值符号方面具有创新性，这在向下延拓问题中是一个重要的考虑因素。NNLS的使用提供了一种稳定和约束密度的方法。然而，在实际应用中，确保简单层表面包围所有异常源的约束可能是一个挑战。

<details>
  <summary>Details</summary>

**Motivation:** 重力勘探中的向下延拓对于识别重力异常源至关重要，但该问题通常不稳定，需要正则化技术来解决。

**Method:** 将连续场表示为等效简单层的势能或其垂直导数，并利用非负最小二乘法（NNLS）来强制执行简单层密度的非负性。

**Result:** 所提出的方法在模型示例中证明了其效率。

**Conclusion:** 该研究提出了一种基于等效简单层和NNLS方法的向下延拓算法，该方法能够保持异常值的符号，并在模型示例中显示出良好的效率。

> **ai_Abstract:** 本研究提出了一种计算算法，用于解决重力勘探中的向下延拓问题。该方法将延拓场表示为简单层或其垂直导数的势能，并利用非负最小二乘法（NNLS）来保持异常值的符号，前提是简单层的表面包围所有异常源。研究结果表明，该方法在模型示例中是有效的。

> **摘要翻译:** 将位场从地表向下延拓到地下是重力勘探中的一项关键任务，因为它可以帮助识别重力异常的来源。这个问题通常通过求解一类积分方程并使用正则化技术来稳定一个本质上不稳定的过程来解决。我们的工作中使用了类似的方法，其中延拓场被表示为简单层或其垂直导数的势能。该等效简单层的密度符号的恒定性可以保留异常值的符号，前提是该层的表面包含所有异常源。该约束是我们向下延拓位场算法的一个关键特征。为了强制执行，例如，简单层密度的非负性，我们采用了NNLS（非负最小二乘）方法。所提出方法的效率在模型示例中得到了证明。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [555] [Minimum-norm interpolation for unknown surface reconstruction](https://arxiv.org/abs/2507.08632)
> *未知曲面重建的最小范数插值*

*Alex Shiu Lun Chu, Leevan Ling, Ka Chun Cheung* | **Category: math.NA, cs.NA** | **Updated: 2025-07-11**

**Keywords:** 曲面重建, 径向基函数, 约束优化, Kolmogorov-Arnold网络, 法线估计

**Comment:** 

> **TL;DR:** 该研究提出了一种基于径向基函数（RBF）的核插值方法，通过将其重构为一个约束优化模型来解决曲面重建问题。通过在试验空间中引入受Kolmogorov-Arnold网络（KAN）启发的1D核基函数，该方法显著提高了从原始点云重建曲面的精度，尤其是在法线估计方面，优于传统的RBF方法和Hermite插值。

**AI_Comments:** 该研究提出了一种创新的方法，通过结合RBF插值和KAN启发的基函数来解决点云曲面重建问题。这种混合维度试验空间在提高法线估计精度方面表现出色，为计算几何领域带来了新的可能性。然而，对于该方法在不同类型点云数据和复杂几何形状上的鲁棒性和泛化能力还需要进一步的评估。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机在于利用隐式曲面表示来估计原始点云数据的几何属性，并解决数值方法在领域类型插值问题中不需要指定唯一目标函数的问题。

**Method:** 该研究采用基于核的径向基函数（RBF）插值方法，并将其重构为一个约束优化模型，该模型在满足所有插值条件的同时最小化用户定义的范数。为了获得非平凡的可行解，研究者提出了在试验空间中增强1D核基函数，其灵感来源于Kolmogorov-Arnold网络（KAN）。

**Result:** 数值实验表明，所提出的混合维度试验空间能够显著改进从原始点云进行的曲面重建，尤其是在曲面法线的精确估计方面，其性能优于传统的RBF试验空间（包括Hermite插值）。

**Conclusion:** 该框架不仅提高了原始点云数据的处理能力，而且在计算几何领域也展现出进一步贡献的潜力。

> **ai_Abstract:** 本研究提出了一种新的曲面重建方法，该方法利用径向基函数（RBF）插值，并将其重构为一个约束优化问题。通过引入受Kolmogorov-Arnold网络（KAN）启发的1D核基函数来增强试验空间，该方法在从原始点云重建曲面方面取得了显著的改进，特别是在法线估计的精度上，超越了传统的RBF方法。

> **摘要翻译:** 我们研究了通过隐式曲面表示来估计原始点云数据的几何属性的算法。考虑到任何具有对应曲面常数水平集的水平集函数都可以用于此类估计，数值方法不必为领域类型插值问题指定唯一的目标函数。在本文中，我们专注于径向基函数（RBF）的核插值，并将唯一可解的插值问题重构为一个约束优化模型。该模型在强制执行所有插值条件的同时最小化某个用户定义的范数。为了实现非平凡的可行解，我们提出通过受Kolmogorov-Arnold网络（KAN）启发的1D核基函数来增强试验空间。数值实验表明，我们提出的混合维度试验空间显著改善了从原始点云进行的曲面重建。这在曲面法线的精确估计方面尤为明显，其性能优于包括Hermite插值在内的传统RBF试验空间。该框架不仅增强了原始点云数据的处理能力，而且还显示出对计算几何做出进一步贡献的潜力。我们通过一个点云处理的例子对此进行了说明。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [579] [Long-time relative error analysis for linear ODEs with perturbed initial value](https://arxiv.org/abs/2507.08752)
> *线性常微分方程的长期相对误差分析及其初值扰动*

*Stefano Maset* | **Category: math.NA, cs.NA, math.DS** | **Updated: 2025-07-11**

**Keywords:** 线性常微分方程, 相对误差, 绝对误差, 初值扰动, 长期行为

**Comment:** 

> **TL;DR:** 该研究关注线性常微分方程初值扰动传播的长期相对误差行为，并将其与绝对误差区分开来，强调相对误差在动力学和系统条件分析中的重要性。

**AI_Comments:** 该研究关注的是相对误差在长期行为下的分析，这与传统的绝对误差分析有所不同，具有一定的创新性。研究结果对于理解线性常微分方程的稳定性和条件数有重要意义，尤其是在非正常动力学等对扰动敏感的领域。然而，抽象中并未提供具体的数学工具或证明方法，这限制了对其方法论深度的评估。

<details>
  <summary>Details</summary>

**Motivation:** 理解线性常微分方程初值扰动传播的长期相对误差行为对于分析系统的条件至关重要，尤其是在非正常动力学等应用场景中。

**Method:** 通过分析相对误差而非绝对误差来研究初值扰动在解中的传播。

**Result:** 长期相对误差的行为与绝对误差的行为有显著不同，揭示了相对误差在所有时间尺度上的增长情况。

**Conclusion:** 长期相对误差的行为是理解线性常微分方程条件分析的关键方面，作者希望该研究能引起对相对误差在动力学背景下作用的关注。

> **ai_Abstract:** 本研究探讨了线性常微分方程初值扰动传播的长期相对误差行为。与绝对误差不同，相对误差的长期行为提供了对误差在所有时间尺度上增长的洞察，这对于理解线性常微分方程的条件分析至关重要，尤其是在非正常动力学等领域。作者强调了相对误差在动力学研究中的重要性。

> **摘要翻译:** 我们研究了初值扰动在线性常微分方程解中的传播情况，即 
( y'(t) = Ay(t) )。
这种传播是使用相对误差而不是绝对误差来分析的。
我们关注的是这种相对误差的长期行为，它与绝对误差的行为有显著不同。
理解这种长期行为可以深入了解相对误差在所有时间上的增长情况，而不仅仅是在大时间上的增长情况。
因此，它代表了线性常微分方程条件分析的一个关键和基本方面，其应用例如在非正常动力学中。
作者希望这篇论文能激发对相对误差在动力学背景下作用的关注。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [611] [Asymptotic condition numbers for linear ODEs](https://arxiv.org/abs/2507.08762)
> *线性常微分方程的渐进行数*

*Stefano Maset* | **Category: math.NA, cs.NA** | **Updated: 2025-07-11**

**Keywords:** 条件数,线性常微分方程,矩阵指数,长期行为,扰动

**Comment:** 

> **TL;DR:** 该论文研究了线性常微分方程中矩阵指数作用于向量的条件数长期行为，并提出了三种不同的条件数来衡量初始值扰动对解的影响。

**AI_Comments:** 该研究对理解线性常微分方程的数值稳定性具有重要意义，尤其是在处理长期演化问题时。提出的三种条件数提供了不同粒度的分析视角，有助于深入理解条件数行为。

<details>
  <summary>Details</summary>

**Motivation:** 研究线性常微分方程中，初始值扰动对解的传播，并特别关注长期行为的条件数。

**Method:** 通过引入三个条件数来衡量初始值扰动对解的影响：一个针对特定初始值和扰动方向，一个针对特定初始值和最坏扰动方向，第三个则同时考虑最坏的初始值和扰动方向。

**Result:** 对这三种条件数的长期行为进行了研究。

**Conclusion:** 该研究为理解线性常微分方程中条件数的长期行为提供了理论基础。

> **ai_Abstract:** 本文研究了线性常微分方程中，矩阵指数作用于向量的条件数的长期行为。作者提出了三种条件数来量化初始值扰动对解的影响，并分析了它们在长时间尺度下的表现。

> **摘要翻译:** 我们对线性问题 $y_0
mapsto 	extrm{e}^{tA}y_0$ 的（相对）条件数感兴趣，即矩阵指数 $	extrm{e}^{tA}$ 的作用对该向量的扰动而言的条件数。本文是对该条件数长期行为的定性研究。换句话说，我们有兴趣研究线性常微分方程 $y^	extrm{‘}(t)=Ay(t)$ 的初始值扰动向解 $y(t)$ 的传播，通过测量这些扰动与绝对误差相比的相对误差来衡量。我们引入了三个条件数：第一个考虑特定的初始值和扰动方向；第二个考虑特定的初始值和通过改变扰动方向的最坏情况；第三个则通过改变初始值和扰动方向来考虑最坏情况。研究了这三个条件数的长期行为。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [11] [Distilling Spectrograms into Tokens: Fast and Lightweight Bioacoustic Classification for BirdCLEF+ 2025](https://arxiv.org/abs/2507.08236)
> *将声谱图提炼为令牌：BirdCLEF+ 2025 的快速轻量级生物声学分类*

*Anthony Miyaguchi, Murilo Gustineli, Adrian Cheung* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 生物声学分类, Spectrogram Token Skip-Gram, BirdCLEF+ 2025, 轻量级模型, CPU 推理

**Comment:** Working note submitted to CLEF 2025 under the LifeCLEF lab

> **TL;DR:** 本文针对BirdCLEF+ 2025挑战赛的严格CPU推理时间限制，探索了两种策略：优化预训练模型以实现近10倍加速，并提出了一种名为STSG的新型轻量级流水线，通过将声谱图转换为令牌进行生物声学分类，证明了快速令牌化方法的可行性。

**AI_Comments:** 本文针对计算资源受限的生物声学分类挑战，提出了实用的解决方案。其创新点在于引入了 STSG 这种将声谱图视为序列并进行令牌化的方法，为轻量级模型设计提供了新思路。尽管 STSG 的性能在当前阶段不如优化后的SOTA模型，但其在推理速度上的优势以及对未来研究的启发意义值得关注。此外，对现有模型进行优化以适应特定硬件限制，也展示了工程实践的重要性。

<details>
  <summary>Details</summary>

**Motivation:** BirdCLEF+ 2025 挑战赛要求对 206 种物种进行分类，且有严格的 90 分钟 CPU 推理时间限制，这使得许多最先进的深度学习方法不切实际，因此需要探索轻量级和快速的生物声学分类方法。

**Method:** 本文探索了两种策略：1. 优化来自生物声学模型动物园的预训练模型以进行 CPU 推理，使用 TFLite 将 Perch 模型推理速度提高了近 10 倍。2. 引入了一种名为 Spectrogram Token Skip-Gram (STSG) 的新型轻量级流水线，将生物声学视为序列建模任务。该方法通过使用 Faiss K-means 聚类 Mel-声谱图，将音频转换为离散的“声谱图令牌”，然后使用 Word2Vec skip-gram 模型以无监督方式学习这些令牌的高质量上下文嵌入。分类时，将 5 秒窗口内的嵌入平均并传递给线性模型。

**Result:** 优化后的 Perch 模型在公开排行榜上获得了 0.729 的 ROC-AUC 分数，在私人排行榜上获得了 0.711 的分数，推理时间约为 16 分钟。最佳的动物园模型 BirdSetEfficientNetB1 在公开排行榜上获得了 0.810 的分数，在私人排行榜上获得了 0.778 的分数。STSG 方法在公开排行榜上获得了 0.559 的 ROC-AUC 分数，在私人排行榜上获得了 0.520 的分数，预计 700 分钟测试集的推理时间为 6 分钟。

**Conclusion:** 本文证明了针对生物声学分类任务，通过优化预训练模型和引入快速令牌化方法（如 STSG）来满足严格的 CPU 推理时间限制是可行的。STSG 方法展示了使用静态嵌入进行快速令牌化方法的潜力。

> **ai_Abstract:** 本文针对 BirdCLEF+ 2025 挑战赛的严格 CPU 推理时间限制，提出了两种生物声学分类方法。一是优化现有预训练模型（如 Perch 和 BirdSetEfficientNetB1）以提高 CPU 推理速度，实现了显著的加速和较高的性能。二是引入了一种名为 Spectrogram Token Skip-Gram (STSG) 的新型轻量级流水线，该方法将声谱图转换为离散令牌并学习其上下文嵌入，然后用于分类。尽管 STSG 的性能低于优化后的预训练模型，但其展示了快速令牌化方法在生物声学分类中的潜力，特别是在推理时间受限的场景下。

> **摘要翻译:** BirdCLEF+ 2025 挑战赛要求在严格的 90 分钟仅 CPU 推理截止日期内，从声景录音中对 206 种物种（包括鸟类、哺乳动物、昆虫和两栖动物）进行分类，这使得许多最先进的深度学习方法不切实际。为解决这一限制，DS@GT BirdCLEF 团队探索了两种策略。首先，我们通过优化来自生物声学模型动物园的预训练模型以进行 CPU 推理，建立了具有竞争力的基线。使用 TFLite，我们将 Perch 模型的推理速度提高了近 10 倍，使其在大约 16 分钟内运行，并在赛后公开排行榜上获得了 0.729 的最终 ROC-AUC 分数，在私人排行榜上获得了 0.711 的分数。动物园中最好的模型是 BirdSetEfficientNetB1，公开分数为 0.810，私人分数为 0.778。其次，我们引入了一种名为声谱图令牌跳字模型（Spectrogram Token Skip-Gram，STSG）的新型轻量级流水线，它将生物声学视为序列建模任务。该方法通过使用 Faiss K-means 聚类 Mel-声谱图，将音频转换为离散的“声谱图令牌”，然后使用 Word2Vec 跳字模型以无监督方式学习这些令牌的高质量上下文嵌入。对于分类，将 5 秒窗口内的嵌入平均并传递给线性模型。STSG 方法预计 700 分钟测试集的推理时间为 6 分钟，在公开排行榜上获得了 0.559 的最终 ROC-AUC 分数，在私人排行榜上获得了 0.520 的分数，证明了使用静态嵌入的快速令牌化方法在生物声学分类中的可行性。本文的支持代码可在 https://github.com/dsgt-arc/birdclef-2025 找到。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [43] [Active Learning for Text-to-Speech Synthesis with Informative Sample Collection](https://arxiv.org/abs/2507.08319)
> *主动学习用于文本到语音合成的信息样本收集*

*Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki, Hiroshi Saruwatari* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 主动学习, 文本到语音合成, 语料库构建, 数据效率, 语音质量

**Comment:** 

> **TL;DR:** 提出一种基于主动学习的TTS语料库构建方法，通过迭代收集信息量大的数据，实现数据高效的语料库，并提高合成语音质量。

**AI_Comments:** 该研究的创新点在于将主动学习引入到TTS语料库构建中，解决了传统方法在处理大规模数据时的低效率和存储问题。通过迭代选择信息量大的数据，显著提高了数据利用效率和最终的合成语音质量，对于资源受限的TTS系统开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代文本到语音（TTS）系统需要高质量数据集，但数据规模增大带来了存储限制等挑战。为了解决这些问题，需要一种更高效的语料库构建方法。

**Method:** 提出一种基于主动学习的TTS语料库构建方法。该方法与传统的前馈和模型无关的语料库构建方法不同，它在数据收集和模型训练之间进行迭代交替，从而专注于获取对模型改进更有信息量的数据。

**Result:** 实验结果表明，使用该方法构建的语料库，在相同大小下，能够实现比其他语料库更高质量的语音合成。

**Conclusion:** 该基于主动学习的TTS语料库构建方法能够有效地解决大规模数据带来的挑战，通过数据高效的语料库提升语音合成质量。

> **ai_Abstract:** 该论文提出一种基于主动学习的文本到语音（TTS）语料库构建方法，旨在解决大规模数据集的存储限制和数据效率问题。该方法通过在数据收集和模型训练之间迭代交替，优先选择对模型改进最有信息量的数据。实验证明，与相同大小的传统语料库相比，使用该方法构建的语料库能生成更高质量的合成语音，从而实现了数据高效的TTS系统。

> **摘要翻译:** 高质量数据集的构建是现代文本到语音（TTS）系统的基石。然而，可用数据规模的不断增长带来了显著的挑战，包括存储限制。为了解决这些问题，我们提出了一种基于主动学习的TTS语料库构建方法。与传统的前馈和模型无关的语料库构建方法不同，我们的方法在数据收集和模型训练之间迭代交替，从而专注于获取对模型改进更具信息量的数据。这种方法能够构建一个数据高效的语料库。实验结果表明，使用我们方法构建的语料库，在相同大小下，能够实现比相同大小语料库更高质量的语音合成。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [66] [Audio Inpanting using Discrete Diffusion Model](https://arxiv.org/abs/2507.08333)
> *使用离散扩散模型的音频修复*

*Tali Dror, Iftach Shoham, Moshe Buchris, Oren Gal, Haim Permuter, Gilad Katz, Eliya Nachmani* | **Category: cs.SD, cs.AI, cs.IT, cs.LG, eess.AS, math.IT** | **Updated: 2025-07-11**

**Keywords:** 音频修复, 离散扩散模型, 标记化音频, 长间隙, 音频重建

**Comment:** 

> **TL;DR:** 本研究提出了一种基于离散扩散模型的新型音频修复方法，该方法在标记化的音频表示上运行，能够稳定且语义连贯地重建缺失的音频，尤其适用于较长间隙的修复。

**AI_Comments:** 这项工作的创新之处在于将离散扩散模型应用于音频修复任务，并利用标记化的音频表示在离散潜在空间中进行建模。这使得该方法能够有效处理现有方法难以解决的较长音频间隙，为音频修复领域带来了显著的进步和更鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 先前的音频修复方法（包括基于波形和频谱图的扩散模型）在短间隙（小于100毫秒）方面表现良好，但当间隙超过100毫秒时，质量会下降。本研究旨在解决现有方法在处理长间隙时性能下降的问题。

**Method:** 本研究引入了一种基于离散扩散模型的新型修复方法。该方法在由预训练音频分词器生成的标记化音频表示上操作，直接在离散潜在空间中建模生成过程，从而实现稳定且语义连贯的缺失音频重建。

**Result:** 在MusicNet数据集上，使用客观和感知指标评估了长达300毫秒的间隙，并在MTG数据集上将间隙持续时间延长至500毫秒。实验结果表明，与现有基线相比，本方法取得了具有竞争力或更优的性能，尤其是在处理较长间隙方面。

**Conclusion:** 本研究提出的基于离散扩散模型的音频修复方法为恢复受损音乐录音提供了一个强大的解决方案，尤其在处理长间隙方面表现出显著优势。

> **ai_Abstract:** 本论文提出了一种基于离散扩散模型的新型音频修复方法，旨在解决现有方法在处理长音频间隙（超过100毫秒）时性能下降的问题。该方法通过在预训练音频分词器生成的标记化音频表示的离散潜在空间中建模生成过程，实现了对缺失音频片段的稳定且语义连贯的重建。实验结果表明，该方法在MusicNet和MTG数据集上，尤其是在处理长达500毫秒的间隙时，性能优于或媲美现有基线，为恢复受损音乐录音提供了有效方案。

> **摘要翻译:** 音频修复是指重建受损录音中缺失片段的任务。虽然先前的方法——包括基于波形和频谱图的扩散模型——在短间隙方面表现出有希望的结果，但当间隙超过100毫秒（ms）时，它们的质量通常会下降。在这项工作中，我们引入了一种基于离散扩散模型的新型修复方法，该方法在由预训练音频分词器生成的标记化音频表示上运行。我们的方法直接在离散潜在空间中建模生成过程，从而实现稳定且语义连贯的缺失音频重建。我们使用客观和感知指标在MusicNet数据集上评估了该方法，间隙持续时间最长达300毫秒。我们还在MTG数据集上进一步评估了我们的方法，将间隙持续时间延长至500毫秒。实验结果表明，与现有基线相比，我们的方法取得了具有竞争力或更优的性能，尤其是在处理较长间隙方面，为恢复受损音乐录音提供了一个强大的解决方案。我们提出的方法的音频示例可在 https://iftach21.github.io/ 找到。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [67] [Enforcing Speech Content Privacy in Environmental Sound Recordings using Segment-wise Waveform Reversal](https://arxiv.org/abs/2507.08412)
> *使用分段波形反转在环境声音记录中强制执行语音内容隐私*

*Modan Tailleur, Mathieu Lagrange, Pierre Aumond, Vincent Tourre* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 语音隐私, 波形反转, 环境声音, 语音活动检测, 语音分离

**Comment:** 

> **TL;DR:** 一种在环境声音记录中使语音无法理解，同时保留声学场景完整性和整体音频质量的方法。

**AI_Comments:** 该论文的创新之处在于提出了一种平衡语音隐私和声学场景完整性的新颖方法。通过结合分段波形反转与语音活动检测和语音分离，实现了对语音内容的精确处理。其全面的评估协议和量化结果（WER、SCAD、FAD）有力地证明了方法的有效性。此外，考虑通过随机拼接增强鲁棒性，增加了方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 环境声音记录中常包含可理解的语音，这引发了隐私担忧，从而限制了数据的分析、共享和再利用。

**Method:** 该方法通过反转波形段来扭曲语音内容，使其无法理解。此过程通过语音活动检测和语音分离管道得到增强，从而可以更精确地定位语音。此外，通过引入随机拼接可以增强算法对恢复原始语音尝试的鲁棒性。

**Result:** 在模拟评估数据集上的实验表明，该方法实现了令人满意的语音不可理解性（97.9%的词错误率），对声源可检测性的降级最小（2.7%的声源分类准确度下降），并具有高感知质量（Fréchet音频距离为1.40）。随机拼接可以增强算法的鲁棒性。

**Conclusion:** 该论文提出了一种在环境声音记录中强制执行语音内容隐私的有效方法，该方法通过分段波形反转，结合语音活动检测和语音分离，在使语音无法理解的同时，最大限度地保留了声学场景的完整性和整体音频质量，并展现了对恢复尝试的鲁棒性。

> **ai_Abstract:** 该论文提出了一种新颖的方法，通过分段波形反转，并结合语音活动检测（VAD）和语音分离，来强制执行环境声音记录中的语音内容隐私。该方法旨在使语音无法理解，同时保持声学场景的完整性和整体音频质量。评估结果显示，该方法实现了高语音不可理解性（97.9%的词错误率），对声源可检测性的影响最小（2.7%的SCAD），并具有良好的音频质量（FAD为1.40）。此外，通过引入随机拼接可以增强算法的鲁棒性。

> **摘要翻译:** 环境声音记录中常包含可理解的语音，这引发了隐私担忧，从而限制了数据的分析、共享和再利用。本文介绍了一种方法，该方法在保持声学场景完整性和整体音频质量的同时，使语音变得无法理解。我们的方法涉及反转波形段以扭曲语音内容。通过语音活动检测和语音分离管道，此过程得到增强，从而可以更精确地定位语音。
为了证明所提出方法的有效性，我们考虑了一个三部分评估协议，该协议评估：1）使用词错误率（WER）评估语音可理解性，2）使用来自广泛使用的预训练模型的声源分类准确度下降（SCAD）评估声源可检测性，以及3）使用Fréchet音频距离（FAD）评估音频质量，该距离是使用我们包含未改变语音的参考数据集计算的。在由语音和环境声学场景的线性混合物组成的模拟评估数据集上的实验表明，我们的方法实现了令人满意的语音不可理解性（97.9%的词错误率），对声源可检测性的降级最小（2.7%的SCAD），并具有高感知质量（FAD为1.40）。一项消融研究进一步强调了管道中每个组件的贡献。我们还表明，将随机拼接纳入我们的语音内容隐私强制方法可以增强算法对尝试恢复清晰语音的鲁棒性，尽管会略微牺牲音频质量。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [87] [Phoneme-Level Analysis for Person-of-Interest Speech Deepfake Detection](https://arxiv.org/abs/2507.08626)
> *基于音素级别分析的特定人物语音深度伪造检测*

*Davide Salvi, Viola Negroni, Sara Mandelli, Paolo Bestagini, Stefano Tubaro* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 语音深度伪造检测, 特定人物, 音素级别, 可解释性, 鲁棒性

**Comment:** Accepted at ICCV Workshop - Authenticity & Provenance in the age of
  Generative AI

> **TL;DR:** 该研究提出了一种基于音素级别分析的特定人物语音深度伪造检测方法，旨在提高检测的可解释性和鲁棒性。

**AI_Comments:** 这项研究的创新之处在于将语音深度伪造检测的粒度提升到音素级别，从而显著增强了检测结果的可解释性。在多媒体取证领域，可解释性是至关重要的，而现有大部分深度伪造检测方法往往是“黑箱”式的。通过提供更细致的分析和更透明的决策过程，该方法不仅提高了检测的可靠性，也为未来的研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI的进步使得语音深度伪造变得易于创建，对数字信任构成严重挑战。尽管现有特定人物（POI）语音深度伪造检测方法表现出色，但其粒度有限且缺乏可解释性。

**Method:** 本研究提出了一种在音素级别操作的特定人物语音深度伪造检测方法。该方法将参考音频分解为音素以构建详细的说话人档案。在推理阶段，测试样本中的音素会与该档案进行单独比较，从而实现对合成伪影的细粒度检测。

**Result:** 所提出的方法在准确性上与传统方法相当，同时提供了卓越的鲁棒性和可解释性。

**Conclusion:** 通过专注于音素分析，这项工作为可解释的、以说话人为中心的深度伪造检测探索了一个新方向。

> **ai_Abstract:** 本论文提出了一种新的特定人物（POI）语音深度伪造检测方法，该方法在音素级别进行操作，旨在解决现有方法粒度有限和可解释性不足的问题。通过将参考音频分解为音素以构建详细的说话人档案，并在推理时逐个音素地与测试样本进行比较，该方法实现了对合成伪影的细粒度检测。实验结果表明，该方法在保持与传统方法相当的准确性同时，显著提升了检测的鲁棒性和可解释性，为可解释的、以说话人为中心的深度伪造检测开辟了新方向。

> **摘要翻译:** 生成式AI的最新进展使得语音深度伪造的创建变得广泛普及，对数字信任构成了严峻挑战。为了应对这一问题，各种语音深度伪造检测策略已被提出，其中包括特定人物（POI）方法，该方法通过建模和分析特定个体的独特声音特征来识别冒充行为。尽管现有方法表现出色，但其粒度有限且缺乏可解释性。在这项工作中，我们提出了一种基于POI的语音深度伪造检测方法，该方法在音素级别操作。我们的方法将参考音频分解为音素以构建详细的说话人档案。在推理阶段，测试样本中的音素会与该档案进行单独比较，从而实现对合成伪影的细粒度检测。所提出的方法在准确性上与传统方法相当，同时提供了卓越的鲁棒性和可解释性，这是多媒体取证中的关键方面。通过专注于音素分析，这项工作为可解释的、以说话人为中心的深度伪造检测探索了一个新方向。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [107] [MuCodec: Ultra Low-Bitrate Music Codec](https://arxiv.org/abs/2409.13216)
> *MuCodec：超低码率音乐编解码器*

*Yaoxun Xu, Hangting Chen, Jianwei Yu, Wei Tan, Rongzhi Gu, Shun Lei, Zhiwei Lin, Zhiyong Wu* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 音乐编解码, 超低码率, 音乐压缩, 声学特征, 语义特征

**Comment:** 

> **TL;DR:** MuCodec 是一种新的超低码率音乐编解码器，能同时处理背景和人声，并在主客观指标上达到最佳效果。

**AI_Comments:** MuCodec 的创新之处在于其同时提取声学和语义特征的能力，并巧妙地整合了多种先进技术（如 RVQ、流匹配、Mel-VAE 和 HiFi-GAN），以克服传统方法在处理复杂音乐内容时的不足。该研究在实现超低码率高保真音乐重建方面取得了显著突破，对于推动音乐传输和生成技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 音乐编解码是音频编解码研究的重要方面，超低码率压缩对音乐传输和生成至关重要。现有方法仅依靠建模语义或声学信息，无法有效重建同时包含人声和背景的复杂音乐。

**Method:** 本文提出了 MuCodec，专门针对超低码率下的音乐压缩和重建任务。MuCodec 利用 MuEncoder 提取声学和语义特征，通过 RVQ 进行离散化，并通过流匹配获取 Mel-VAE 特征。音乐最终通过预训练的 MEL-VAE 解码器和 HiFi-GAN 进行重建。

**Result:** MuCodec 能够在超低（0.35kbps）或高码率（1.35kbps）下重建高保真音乐，并在主观和客观指标上均取得了迄今为止的最佳结果。

**Conclusion:** MuCodec 成功解决了超低码率音乐压缩和重建的挑战，通过结合声学和语义特征，实现了高保真音乐的重建，并显著优于现有技术。

> **ai_Abstract:** 本文提出了 MuCodec，一个针对超低码率音乐压缩和重建的编解码器。该方法旨在解决传统编解码器在处理复杂音乐背景和人声时，仅依赖单一信息源的局限性。MuCodec 通过 MuEncoder 提取声学和语义特征，并结合 RVQ、流匹配、Mel-VAE 解码器和 HiFi-GAN 进行音乐重建。实验结果表明，MuCodec 能够在超低码率下实现高保真音乐重建，并在主客观指标上达到领先水平。

> **摘要翻译:** 音乐编解码器是音频编解码研究的一个重要方面，超低码率压缩对于音乐传输和生成具有重要意义。由于音乐背景的复杂性和人声的丰富性，仅仅依靠对语义或声学信息的建模无法有效地重建同时包含人声和背景的音乐。为了解决这个问题，我们提出了 MuCodec，专门针对超低码率下的音乐压缩和重建任务。MuCodec 使用 MuEncoder 提取声学和语义特征，通过 RVQ 对其进行离散化，并通过流匹配获得 Mel-VAE 特征。然后使用预训练的 MEL-VAE 解码器和 HiFi-GAN 重建音乐。MuCodec 能够在超低（0.35kbps）或高码率（1.35kbps）下重建高保真音乐，在主观和客观指标上均取得了迄今为止的最佳结果。代码和演示：https://xuyaoxun.github.io/MuCodec_demo/。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [123] [End-to-end multi-channel speaker extraction and binaural speech synthesis](https://arxiv.org/abs/2410.05739)
> *端到端多通道说话人提取与双耳语音合成*

*Cheng Chi, Xiaoyu Li, Yuxuan Ke, Qunping Ni, Yao Ge, Xiaodong Li, Chengshi Zheng* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 端到端学习, 多通道, 说话人提取, 双耳语音合成, 空间音频

**Comment:** 

> **TL;DR:** 本文提出了一个端到端深度学习框架，能够直接将多通道噪声和混响信号转换为清晰且空间化的双耳语音，并在语音质量和空间保真度方面超越了现有方法。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的深度学习框架，将多个传统上独立的音频处理任务（声源提取、噪声抑制、双耳渲染）统一到一个网络中，简化了流程并可能减少误差累积。引入幅度加权耳间水平差损失函数是其在空间渲染精度上的重要贡献。这种集成方法对于提升远程会议等场景的用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有远程会议音频增强方法存在局限性：单麦克风缺乏空间信息，或多麦克风阵列性能高度依赖声源方向估计精度，导致语音清晰度和空间沉浸感不足。

**Method:** 引入了一个端到端深度学习框架，能够直接将多通道噪声和混响信号映射为清晰且空间化的双耳语音。该框架将声源提取、噪声抑制和双耳渲染统一到一个网络中，并提出了一种新的幅度加权耳间水平差损失函数以提高空间渲染精度。

**Result:** 广泛评估表明，该方法在语音质量和空间保真度方面均优于已有的基线方法。

**Conclusion:** 所提出的端到端深度学习框架通过统一声源提取、噪声抑制和双耳渲染，并引入新颖的损失函数，有效解决了现有方法的局限性，显著提升了语音质量和空间保真度，从而增强了远程会议体验。

> **ai_Abstract:** 本文提出了一个端到端深度学习框架，旨在解决远程会议中语音清晰度和空间沉浸感不足的问题。该框架能够直接将多通道噪声和混响信号转换为清晰且空间化的双耳语音，并通过统一源提取、噪声抑制和双耳渲染以及引入幅度加权耳间水平差损失函数来优化性能。实验结果表明，该方法在语音质量和空间保真度上均优于现有基线。

> **摘要翻译:** 语音清晰度和空间音频沉浸感是提升远程会议体验的两个最关键因素。现有方法常受限于：要么因仅使用一个麦克风而缺乏空间信息，要么因其性能高度依赖于声源方向估计的准确性（当使用麦克风阵列时）。为解决此问题，我们引入了一个端到端深度学习框架，该框架能够直接将多通道噪声和混响信号映射为清晰且空间化的双耳语音。此框架将声源提取、噪声抑制和双耳渲染统一到一个网络中。在该框架中，提出了一种新颖的幅度加权耳间水平差损失函数，旨在提高空间渲染的准确性。广泛的评估表明，我们的方法在语音质量和空间保真度方面均优于已有的基线方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [139] [UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching](https://arxiv.org/abs/2506.09874)
> *UmbraTTS：使用流匹配技术使文本转语音适应环境上下文*

*Neta Glazer, Aviv Navon, Yael Segal, Aviv Shamsian, Hilit Segev, Asaf Buchnick, Menachem Pirchi, Gil Hetz, Joseph Keshet* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-10**

**Keywords:** 文本转语音, 流匹配, 环境音频, 自监督学习, 音频合成

**Comment:** ICML Workshop on Machine Learning for Audio 2025

> **TL;DR:** UmbraTTS是一个基于流匹配的文本转语音模型，能够根据文本和声学上下文共同生成语音和环境音频，并采用自监督框架解决数据缺乏问题，表现优于现有基线。

**AI_Comments:** UmbraTTS的创新之处在于其能够共同生成语音和环境音频，并采用流匹配技术实现这一目标。更重要的是，它通过提出一个自监督框架来解决自然语境下语音和背景音频对齐数据稀缺的关键挑战，这对于实际应用具有重要意义。该模型在生成高质量、环境感知音频方面的表现，预示着其在创建更沉浸式和逼真的听觉体验方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本转语音（TTS）技术取得了显著进展，但将语音与复杂背景环境整合仍然具有挑战性。

**Method:** 本文引入了UmbraTTS，一个基于流匹配的文本转语音模型，它能够根据文本和声学上下文共同生成语音和环境音频。为了克服缺乏配对训练数据的挑战，提出了一种自监督框架，从无标注录音中提取语音、背景音频和转录文本。

**Result:** 广泛的评估表明，UmbraTTS显著优于现有基线，能够生成自然、高质量且具有环境感知能力的音频。

**Conclusion:** UmbraTTS成功地解决了将语音与复杂背景环境整合的挑战，通过联合生成语音和环境音频，并利用自监督学习克服数据限制，实现了高质量、环境感知的音频合成。

> **ai_Abstract:** UmbraTTS是一种基于流匹配的文本转语音模型，旨在解决语音与复杂背景环境整合的挑战。该模型能够根据文本和声学上下文共同生成语音和环境音频，并提供对背景音量的精细控制，生成多样化、连贯且上下文感知的音频场景。为了应对缺乏配对训练数据的难题，研究人员开发了一个自监督框架，可从无标注录音中提取所需的语音、背景音频和转录文本。实验结果表明，UmbraTTS在生成自然、高质量且具有环境感知能力的音频方面，显著优于现有基线模型。

> **摘要翻译:** 文本转语音（TTS）技术的最新进展已实现高度自然的语音合成，但将语音与复杂背景环境整合仍然具有挑战性。我们引入了UmbraTTS，一个基于流匹配的TTS模型，它能够根据文本和声学上下文共同生成语音和环境音频。我们的模型允许对背景音量进行精细控制，并能产生多样化、连贯且上下文感知的音频场景。一个关键挑战是缺乏在自然语境中语音和背景音频对齐的数据。为了克服配对训练数据的缺乏，我们提出了一种自监督框架，可以从无标注录音中提取语音、背景音频和转录文本。广泛的评估表明，UmbraTTS显著优于现有基线，能够生成自然、高质量且具有环境感知能力的音频。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [158] [MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling](https://arxiv.org/abs/2507.08530)
> *MIDI-VALLE：通过神经编解码器语言建模改进富有表现力的钢琴演奏合成*

*Jingjing Tang, Xin Wang, Zhe Zhang, Junichi Yamagishi, Geraint Wiggins, George Fazekas* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 钢琴演奏合成, 神经编解码器, 语言模型, MIDI-VALLE, 泛化能力

**Comment:** Accepted by ISMIR 2025

> **TL;DR:** MIDI-VALLE是一个新的神经编解码器语言模型，用于将MIDI转换为音频，它通过编码MIDI和音频为离散token并利用参考音频，显著提高了钢琴演奏合成的质量和泛化能力，优于现有SOTA模型。

**AI_Comments:** MIDI-VALLE的创新之处在于将VALLE框架应用于音乐性能合成，并引入了将MIDI和音频编码为离散token的方法，以及利用参考音频作为条件，这显著提升了模型处理多样化输入的能力和合成质量。其在泛化能力上的提升对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的音乐演奏合成模型在将MIDI合成音频时，难以泛化到多样化的MIDI源、音乐风格和录音环境。

**Method:** 本文提出了MIDI-VALLE，一个改编自VALLE框架的神经编解码器语言模型。它改进了架构，以参考音频演奏及其对应的MIDI为条件，并将MIDI和音频都编码为离散token，而不是依赖于钢琴卷。模型通过在广泛多样的钢琴演奏数据集上训练来增强泛化能力。

**Result:** 评估结果显示，MIDI-VALLE在ATEPP和Maestro数据集上的Frechet音频距离降低了75%以上，显著优于现有最先进的基线模型。在听力测试中，MIDI-VALLE获得了202票，而基线模型为58票，表明其合成质量和对多样化MIDI输入的泛化能力均有所提高。

**Conclusion:** MIDI-VALLE通过其新颖的神经编解码器语言建模方法，成功解决了传统模型在钢琴演奏合成中泛化能力差的问题，显著提升了合成音频的质量和对多样化输入的适应性。

> **ai_Abstract:** 本文提出了MIDI-VALLE，一个基于神经编解码器语言模型的新方法，旨在解决传统钢琴演奏合成模型在泛化性上的挑战。该模型通过将MIDI和音频编码为离散token，并以参考音频为条件，提高了钢琴演奏合成的质量和鲁棒性。在大量数据集上的训练进一步增强了其泛化能力。实验结果表明，MIDI-VALLE在客观和主观评估中均显著优于现有基线，实现了更低的Frechet音频距离和更高的听力测试票数。

> **摘要翻译:** 从乐谱生成富有表现力的音频演奏需要模型捕捉乐器声学和人类演绎。传统的音乐演奏合成流程遵循两阶段方法，首先从乐谱生成富有表现力的演奏MIDI，然后将MIDI合成音频。然而，合成模型通常难以泛化到多样化的MIDI源、音乐风格和录音环境。为了解决这些挑战，我们提出了MIDI-VALLE，一个改编自VALLE框架的神经编解码器语言模型，该框架最初是为零样本个性化文本到语音（TTS）合成设计的。对于演奏MIDI到音频合成，我们改进了架构，以参考音频演奏及其对应的MIDI为条件。与以前依赖钢琴卷的基于TTS的系统不同，MIDI-VALLE将MIDI和音频都编码为离散token，从而促进了更一致和鲁棒的钢琴演奏建模。此外，通过在广泛多样的钢琴演奏数据集上训练，模型的泛化能力得到了增强。评估结果显示，MIDI-VALLE显著优于现有最先进的基线模型，在ATEPP和Maestro数据集上的Frechet音频距离降低了75%以上。在听力测试中，MIDI-VALLE获得了202票，而基线模型为58票，这表明其合成质量和对多样化演奏MIDI输入的泛化能力均有所提高。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [159] [LISTEN: Lightweight Industrial Sound-representable Transformer for Edge Notification](https://arxiv.org/abs/2507.07879)
> *LISTEN：用于边缘通知的轻量级工业声音可表示Transformer*

*Changheon Han, Yun Seok Kang, Yuseop Sim, Hyung Wook Park, Martin Byung-Guk Jun* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 工业声学, 边缘计算, 深度学习, Transformer, 知识蒸馏

**Comment:** 

> **TL;DR:** LISTEN是一个千字节大小的工业声音基础模型，通过知识蒸馏在低成本边缘设备上实现实时运行，并在性能上与大型模型相当。

**AI_Comments:** LISTEN的创新之处在于其“千字节大小”的设计，通过知识蒸馏实现了在低成本边缘设备的实时部署，这对于工业物联网和边缘计算应用具有重要意义。它有效解决了传统深度学习模型在工业现场部署中的计算和数据瓶颈，为工业声学分析的普及提供了实用方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前的深度学习机器听力模型在工业应用中面临数据依赖性强、模型过大且计算开销高的问题，不适用于实时、现场部署。

**Method:** 本文提出了LISTEN（轻量级工业声音可表示Transformer），一个千字节大小的工业声音基础模型。该模型通过知识蒸馏技术，使其能够在低成本边缘设备上实时运行。作者还将其集成到基于工业物联网（IIoT）传感器和系统的边缘设备机器监控框架中，并在实际生产车间进行了验证。

**Result:** LISTEN在基准下游任务上的表现与其大得多的父模型几乎相同，即使在仅用少量数据集和训练资源进行微调的情况下也是如此。在实际生产车间，LISTEN也验证了其性能和泛化能力。

**Conclusion:** LISTEN提供了一个轻量级、高效的工业声音基础模型解决方案，克服了现有深度学习模型在边缘部署中的挑战，显著提高了工业声学分析的实用性和可及性。

> **ai_Abstract:** 本文介绍了一种名为LISTEN的轻量级工业声音Transformer模型，旨在解决现有深度学习机器听力模型在工业边缘部署中面临的数据依赖和计算资源限制。LISTEN是一个千字节大小的基础模型，通过知识蒸馏技术，使其能够在低成本边缘设备上实时运行，并在性能上与大型模型相媲美。研究还将其集成到实际的工业物联网监控框架中，并在真实生产环境中验证了其在异常检测和预测性维护方面的实用性和泛化能力。

> **摘要翻译:** 基于深度学习的机器听力正在拓宽工业声学分析的范围，应用于异常检测和预测性维护，从而提高制造效率和可靠性。然而，其对每个新任务都需要大量、特定任务的标注数据集的依赖限制了其在车间的广泛实施。虽然新兴的声音基础模型旨在减轻数据依赖性，但它们过于庞大且计算成本高昂，需要云基础设施或高端硬件，这对于现场实时部署来说是不切实际的。我们通过LISTEN（轻量级工业声音可表示Transformer，Lightweight Industrial Sound-representable Transformer for Edge Notification）解决了这一空白，这是一个千字节大小的工业声音基础模型。利用知识蒸馏，LISTEN可以在低成本边缘设备上实时运行。在基准下游任务上，即使使用最少的数据集和训练资源进行微调，它的性能也与其大得多的父模型几乎相同。除了模型本身，我们通过将LISTEN集成到带有工业物联网（IIoT）传感器和系统的边缘设备上的完整机器监控框架中，展示了其在实际世界中的实用性，并在实际制造车间验证了其性能和泛化能力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [211] [FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation](https://arxiv.org/abs/2507.08557)
> *FreeAudio：无需训练的可控长文本到音频生成的时间规划*

*Yuxuan Jiang, Zehua Chen, Zeqian Ju, Chang Li, Weibei Dou, Jun Zhu* | **Category: cs.SD, cs.AI, cs.MM, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 文本到音频, 时间控制, 长音频生成, 无需训练, 生成模型

**Comment:** Accepted at ACM MM 2025

> **TL;DR:** FreeAudio提出了一种无需训练的方法，用于可控的长文本到音频生成，解决了现有方法在处理精确时间控制和长音频生成方面的局限性。

**AI_Comments:** FreeAudio的创新之处在于其“无需训练”的方法论，解决了长文本到音频生成中精确时间控制的难题，并成功地将其应用于长音频生成。通过巧妙地结合大型语言模型（LLM）进行时间规划和文本重描述，以及引入注意力控制、潜在组合和参考引导等机制，该工作显著提升了生成质量。其性能可与基于训练的SOTA模型媲美，这对于减少数据依赖和训练成本具有重要意义，为未来的T2A研究提供了新的视角和潜在方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到音频（T2A）生成方法由于缺乏高质量和数量的时间对齐音频-文本对，难以处理包含精确时间控制的复杂文本提示（例如“猫头鹰在2.4秒-5.2秒叫”）。尽管近期工作探索了数据增强或引入时间条件作为模型输入以实现计时条件下的10秒T2A生成，但其合成质量仍然有限。

**Method:** 本文提出了一个新颖的无需训练的计时控制T2A框架——FreeAudio。具体而言，首先利用大型语言模型（LLM）根据输入文本和时间提示规划非重叠的时间窗口，并用精炼的自然语言描述重新标注每个窗口。然后引入：1）解耦聚合注意力控制，用于精确的时间控制；2）上下文潜在组合，用于局部平滑性；3）参考引导，用于全局一致性。

**Result:** 1) FreeAudio在无需训练的方法中实现了最先进的计时条件T2A合成质量，并与领先的基于训练的方法相媲美。2) FreeAudio在长音频生成质量方面与基于训练的Stable Audio相当，并为计时控制的长文本到音频合成铺平了道路。

**Conclusion:** FreeAudio成功地首次实现了计时控制的长文本到音频生成，并在无需训练的情况下达到了与现有先进方法相当甚至更好的性能，为未来该领域的研究开辟了新方向。

> **ai_Abstract:** FreeAudio是一个创新的无需训练的文本到音频（T2A）生成框架，旨在解决现有方法在处理包含精确时间控制的复杂长文本提示时的局限性。该框架首次实现了计时控制的长文本到音频生成。它通过利用大型语言模型规划时间窗口并重新描述文本，并结合了解耦聚合注意力控制、上下文潜在组合和参考引导等机制，实现了精确的时间控制、局部平滑性和全局一致性。实验结果表明，FreeAudio在无需训练的方法中达到了最先进的计时条件T2A合成质量，并且与领先的基于训练的方法表现相当，同时在长音频生成方面也展现出可比的质量，为计时控制的长文本到音频合成领域开辟了新途径。

> **摘要翻译:** 文本到音频（T2A）生成在生成模型近期进展的推动下取得了可喜的成果。然而，由于时间对齐的音频-文本对的质量和数量有限，现有T2A方法难以处理包含精确时间控制的复杂文本提示，例如“猫头鹰在2.4秒-5.2秒叫”。最近的工作探索了数据增强技术或引入时间条件作为模型输入，以实现计时条件的10秒T2A生成，但其合成质量仍然有限。在这项工作中，我们提出了一种新颖的无需训练的计时控制T2A框架FreeAudio，首次尝试实现计时控制的长文本到音频生成，例如“猫头鹰在2.4秒-5.2秒叫，蟋蟀在0秒-24秒鸣叫”。具体而言，我们首先利用大型语言模型（LLM）根据输入文本和时间提示规划非重叠的时间窗口，并用精炼的自然语言描述重新标注每个窗口。然后我们引入：1）解耦聚合注意力控制，用于精确的时间控制；2）上下文潜在组合，用于局部平滑性；3）参考引导，用于全局一致性。大量的实验表明：1）FreeAudio在无需训练的方法中实现了最先进的计时条件T2A合成质量，并与领先的基于训练的方法相媲美；2）FreeAudio在长音频生成质量方面与基于训练的Stable Audio相当，并为计时控制的长文本到音频合成铺平了道路。演示样本可在以下网址获取：https://freeaudio.github.io/FreeAudio/

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [490] [Modèle physique variationnel pour l'estimation de réponses impulsionnelles de salles](https://arxiv.org/abs/2507.08051)
> *用于房间冲激响应估计的变分物理模型*

*Louis Lalay, Mathieu Fontaine, Roland Badeau* | **Category: cs.SD, eess.AS, eess.SP, physics.class-ph** | **Updated: 2025-07-10**

**Keywords:** 房间冲激响应估计, 变分推断, 物理模型, 统计信号处理, 语音去混响

**Comment:** in French language. GRETSI, Aug 2025, Strasbourg (67000), France

> **TL;DR:** 该研究提出了一种结合统计和物理建模的新方法来估计房间冲激响应（RIR），通过将RIR分解为可解释的参数并使用变分自由能成本函数进行估计，在有噪声环境下优于传统解卷积方法。

**AI_Comments:** 该研究在房间冲激响应估计领域提出了一个创新的方法，通过结合统计和物理模型，为解决现有方法的局限性提供了新的思路。模型的可解释性是其一大亮点，易于理解和应用。然而，该方法在不同声学环境下的鲁棒性以及计算复杂度仍有待进一步研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的房间冲激响应（RIR）估计方法多依赖于统计信号处理或深度神经网络，而结合统计和物理建模的方法仍有待探索。

**Method:** 提出了一种新方法，将统计和物理建模相结合，将RIR分解为白噪声（由频率相关的指数衰减滤波）和自回归滤波器（模拟麦克风响应），并使用变分自由能成本函数进行参数估计。

**Result:** 与经典的解卷积方法相比，在有噪声环境下，该方法能够更好地估计房间冲激响应，并通过客观指标进行了验证。

**Conclusion:** 该方法通过结合统计和物理模型，为房间冲激响应估计提供了一种新的、理论上可靠的途径，并在实际应用中展现出优于传统方法的潜力。

> **ai_Abstract:** 本研究提出了一种新颖的房间冲激响应（RIR）估计方法，该方法将统计信号处理和物理建模相结合。研究人员将RIR分解为可解释的参数，包括由频率相关指数衰减滤波的白高斯噪声和模拟麦克风响应的自回归滤波器。通过使用变分自由能成本函数进行参数估计，该方法在有噪声环境下优于传统的解卷积技术，并在客观指标上得到了验证。

> **摘要翻译:** 房间冲激响应估计对于语音去混响等任务至关重要，这有助于提高自动语音识别的准确性。目前大多数现有方法依赖于统计信号处理或旨在复制信号处理原理的深度神经网络。然而，将统计和物理建模相结合用于RIR估计仍有很大程度上未被探索。本文提出了一种新颖的方法，通过一个理论上基础的模型整合了这两个方面。RIR被分解为可解释的参数：由频率相关的指数衰减（例如模拟墙壁吸收）滤波的白高斯噪声和自回归滤波器（例如模拟麦克风响应）。变分自由能成本函数能够进行实际的参数估计。作为概念验证，我们表明，在给定干燥和混响语音信号的情况下，该方法在有噪声的环境中优于经典的解卷积方法，并通过客观指标进行了验证。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [530] [On Barriers to Archival Audio Processing](https://arxiv.org/abs/2507.08768)
> *论块状音频处理的障碍*

*Peter Sullivan, Muhammad Abdul-Mageed* | **Category: cs.SD, cs.AI, cs.CL, eess.AS** | **Updated: 2025-07-11**

**Keywords:** 语言识别, 说话人识别, 音频处理, 档案音频, 语音技术

**Comment:** Update with Acknowledgements of ICNSLP 2025 paper

> **TL;DR:** 现代语言识别（LID）系统在处理口音和多语言方面表现良好，但说话人识别（SR）系统在处理音频时仍然脆弱，容易受到信道、年龄和语言的影响。

**AI_Comments:** 这项研究揭示了在处理档案音频时，现代语音识别技术（尤其是说话人识别）所面临的实际挑战。虽然LID技术的进步令人鼓舞，但SR技术的脆弱性凸显了在将这些技术应用于历史音频资料时需要进一步研究和开发的必要性。研究的局限性可能在于数据集的特定性质（UNESCO广播录音），其结果的普适性需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 研究现代现成的语言识别（LID）和说话人识别（SR）方法在处理档案音频（特别是涉及多语言说话人和跨年龄录音）时的鲁棒性。

**Method:** 利用一个独特的联合国教科文组织收藏的中期20世纪广播录音，来探测现代现成的语言识别（LID）和说话人识别（SR）方法的鲁棒性，特别是针对多语言说话人和跨年龄录音的影响。

**Result:** 研究结果表明，像Whisper这样的LID系统在处理第二语言和带口音的语音方面越来越熟练。然而，说话人嵌入仍然是语音处理流程中一个脆弱的组成部分，容易受到与信道、年龄和语言相关的偏差的影响。

**Conclusion:** 如果档案馆旨在采用SR方法进行说话人索引，则需要克服这些问题。

> **ai_Abstract:** 本研究使用联合国教科文组织收藏的20世纪中期广播录音，评估了现代语言识别（LID）和说话人识别（SR）技术在处理多语言和跨年龄音频方面的能力。研究发现，虽然LID系统（如Whisper）在处理口音和第二语言方面表现出越来越强的能力，但SR系统在处理档案音频时仍然存在挑战，容易受到信道、年龄和语言等因素的影响，这可能阻碍其在说话人索引中的应用。

> **摘要翻译:** 本研究利用一个独特的联合国教科文组织收藏的中期20世纪广播录音，来探测现代现成的语言识别（LID）和说话人识别（SR）方法的鲁棒性，特别是针对多语言说话人和跨年龄录音的影响。我们的研究结果表明，像Whisper这样的LID系统在处理第二语言和带口音的语音方面越来越熟练。然而，说话人嵌入仍然是语音处理流程中一个脆弱的组成部分，容易受到与信道、年龄和语言相关的偏差的影响。如果档案馆旨在采用SR方法进行说话人索引，则需要克服这些问题。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [573] [Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models](https://arxiv.org/abs/2507.08128)
> *音频火烈鸟3：通过全开放大型音频语言模型推进音频智能*

*Arushi Goel, Sreyan Ghosh, Jaehyeon Kim, Sonal Kumar, Zhifeng Kong, Sang-gil Lee, Chao-Han Huck Yang, Ramani Duraiswami, Dinesh Manocha, Rafael Valle, Bryan Catanzaro* | **Category: cs.SD, cs.AI, cs.CL, eess.AS** | **Updated: 2025-07-10**

**Keywords:** 音频语言模型, 音频智能, 语音识别, 声音事件检测, 音乐信息检索

**Comment:** Code, Datasets and Models: https://research.nvidia.com/labs/adlr/AF3/

> **TL;DR:** Audio Flamingo 3 (AF3) 是一个完全开放的、最先进的大型音频语言模型，它通过统一的音频编码器、链式思考推理、多轮对话、长音频理解和语音到语音交互来提升跨语音、声音和音乐的推理和理解能力。它在20多个音频理解和推理基准上取得了新的最先进成果，并且仅使用开源数据进行训练。

**AI_Comments:** 该研究展示了一个在音频智能领域具有里程碑意义的进步，特别是在推动完全开放的大型音频语言模型方面。AF3的创新之处在于其统一的音频编码器、灵活的推理能力以及对长音频和多模态交互的支持。其在仅使用开源数据的情况下取得SOTA结果，凸显了其训练策略和数据集的有效性，为未来的研究开辟了道路。然而，模型在实际应用中的鲁棒性、效率以及对不同音频质量的适应性仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 旨在推进跨语音、声音和音乐的音频智能，通过一个完全开放的大型音频语言模型实现更强的推理和理解能力。

**Method:** 开发了Audio Flamingo 3 (AF3)，该模型包含一个统一的音频编码器（AF-Whisper），支持链式思考式推理、多轮对话、长音频理解（最长10分钟）和语音到语音交互。训练采用了新颖的五阶段课程学习策略，并使用了新颖策略策划的大规模训练数据集，如AudioSkills-XL、LongAudio-XL、AF-Think和AF-Chat。

**Result:** AF3在超过20个（长）音频理解和推理基准上取得了新的最先进成果，并且在仅使用开源数据训练的情况下，其性能超过了在更大数据集上训练的开放权重和闭源模型。

**Conclusion:** Audio Flamingo 3 (AF3) 是一个强大的、完全开放的音频语言模型，它通过创新的方法和在开源数据上的高效训练，在广泛的音频智能任务上设定了新的行业标准，证明了其在音频理解和推理方面的优越性。

> **ai_Abstract:** Audio Flamingo 3 (AF3) 是一个先进的、完全开放的大型音频语言模型，它通过统一的音频编码器（AF-Whisper）、链式思考推理、多轮对话、长达10分钟的音频理解以及语音到语音交互功能，显著提升了在语音、声音和音乐方面的理解与推理能力。该模型采用了创新的五阶段课程学习策略和新颖的数据集（如AudioSkills-XL、LongAudio-XL），并在仅使用开源数据训练的情况下，在超过20个音频基准测试中取得了领先的性能。

> **摘要翻译:** 我们提出了Audio Flamingo 3 (AF3)，一个完全开放的最先进（SOTA）大型音频语言模型，它推进了跨语音、声音和音乐的推理和理解能力。AF3引入了：（i）AF-Whisper，一个统一的音频编码器，使用新颖的策略进行训练，以实现跨语音、声音和音乐所有三种模态的联合表示学习；（ii）灵活的、按需的思考，允许模型在回答前进行链式思考式的推理；（iii）多轮、多音频的聊天；（iv）长音频理解和推理（包括语音），最长可达10分钟；以及（v）语音到语音交互。为了实现这些功能，我们提出了几个使用新颖策略策划的大规模训练数据集，包括AudioSkills-XL、LongAudio-XL、AF-Think和AF-Chat，并采用新颖的五阶段课程学习策略训练AF3。AF3仅在开源音频数据上进行训练，在超过20个（长）音频理解和推理基准上取得了新的最先进成果，超越了在更大数据集上训练的开放权重和闭源模型。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [5] [Black-Box Identity Testing of Noncommutative Rational Formulas in Deterministic Quasipolynomial Time](https://arxiv.org/abs/2309.15647)
> *非交换有理公式的黑盒同一性测试在确定性准多项式时间内*

*V. Arvind, Abhranil Chatterjee, Partha Mukhopadhyay* | **Category: cs.CC, cs.DS** | **Updated: 2025-07-11**

**Keywords:** 有理同一性测试, 黑盒算法, 准多项式时间, 非交换公式, 击中集

**Comment:** 

> **TL;DR:** 本文提出了第一个用于非交换有理同一性测试的确定性准多项式时间黑盒算法，显著提高了黑盒复杂度并提供了准NC上界。

**AI_Comments:** 这篇论文通过为非交换有理同一性测试提供第一个确定性准多项式时间黑盒算法，取得了重大突破，解决了长期存在的开放问题。为一般有理公式构建准多项式大小的击中集是关键创新，超越了以往仅限于特定公式类型的结果。这项工作不仅提高了黑盒复杂度，还为RIT的并行复杂度提供了新的见解。

<details>
  <summary>Details</summary>

**Motivation:** 有理同一性测试（RIT）领域存在主要开放问题，即如何设计高效的确定性黑盒算法以及理解其并行复杂度。尽管这些问题自2016年以来一直悬而未决，但进展有限，之前仅针对反演高度为二的有理公式构建了准多项式大小的击中集。

**Method:** 本文通过构建第一个针对所有多项式大小有理公式的准多项式大小击中集来解决问题。该构造也为白盒设置下的RIT提供了第一个确定性准NC上界。

**Result:** 本文显著提高了非交换有理同一性测试的黑盒复杂度，获得了第一个针对所有多项式大小有理公式的准多项式大小击中集。此外，它还为白盒设置下的RIT提供了第一个确定性准NC上界。

**Conclusion:** 本文在非交换有理同一性测试的黑盒复杂度方面取得了重大进展，通过开发确定性准多项式时间算法和准NC上界，解决了该领域的主要开放问题。

> **ai_Abstract:** 本文通过提出第一个确定性准多项式时间黑盒算法，解决了非交换有理同一性测试（RIT）中的主要开放问题。通过为所有多项式大小的有理公式构建第一个准多项式大小的击中集，该研究显著提升了黑盒复杂度。此外，这项工作还为白盒设置下的RIT提供了第一个确定性准NC上界，标志着超越以往有限进展的重大突破。

> **摘要翻译:** 有理同一性测试（RIT）是判断非交换有理公式在自由斜域中是否计算出零的判定问题。它在白盒设置下允许确定性多项式时间算法[Garg, Gurvits, Oliveira, and Wigderson (2016); Ivanyos, Qiao, Subrahmanyam (2018); Hamada and Hirai (2021)]，并在黑盒设置下通过自由斜域上线性矩阵的奇异性测试，允许随机多项式时间算法[Derksen and Makam (2017)]。事实上，白盒设置下RIT的随机NC算法源于Derksen和Makam (2017)的结果。
设计RIT的高效确定性黑盒算法并理解RIT的并行复杂度是该领域的主要开放问题。尽管自Garg, Gurvits, Oliveira, and Wigderson (2016)的工作以来这些问题一直悬而未决，但进展有限。事实上，这方面唯一已知的结果是仅针对反演高度为二的有理公式构建了准多项式大小的击中集[Arvind, Chatterjee, Mukhopadhyay (2022)]。
在本文中，我们显著提高了该问题的黑盒复杂度，并获得了第一个针对所有多项式大小有理公式的准多项式大小击中集。我们的构造还为白盒设置下的RIT提供了第一个确定性准NC上界。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [10] [Entropy-conservative numerical fluxes for compressible Euler equations with thermally perfect gas models](https://arxiv.org/abs/2507.08115)
> *热力学完美气体模型可压缩欧拉方程的熵守恒数值通量*

*Alessandro Aiello, Carlo De Michele, Gennaro Coppola* | **Category: physics.flu-dyn, cs.NA, math.NA, 76N15, 76M25** | **Updated: 2025-07-10**

**Keywords:** 熵守恒, 欧拉方程, 热力学完美气体, 数值通量, 空间离散化

**Comment:** 11 pages, 2 figures

> **TL;DR:** 本研究提出了一种新的空间离散化方法，用于可压缩欧拉方程，确保热力学完美气体的离散熵守恒，并保持线性和动能不变性，且在精度和鲁棒性方面优于现有方法。

**AI_Comments:** 该论文的创新之处在于将熵守恒方案首次扩展到更真实的热力学完美气体模型，同时保持了重要的物理守恒量。这对于提高可压缩流体模拟的准确性和稳定性具有重要意义。该方法的鲁棒性和可扩展性也增加了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有熵守恒方案未能涵盖更真实的热力学完美气体情况，且在精度和鲁棒性方面可能存在不足，因此需要提出一种新的空间离散化程序来解决这些问题。

**Method:** 本研究提出了一种基于局部守恒公式的新型空间离散化程序，用于可压缩欧拉方程。该方法将熵守恒方案扩展到热力学完美气体，同时保证线性和动能的守恒。该方法还可扩展到多组分气体和渐近熵守恒公式。

**Result:** 所提出的方法在离散层面保证了热力学完美气体的熵守恒，并确保了线性和动能的守恒。与现有类似方法相比，该方法在精度和鲁棒性方面显示出优势。

**Conclusion:** 本研究成功提出了一种新型空间离散化程序，实现了热力学完美气体可压缩欧拉方程的离散熵守恒，并在保持重要物理量的同时，提升了计算的精度和鲁棒性。

> **ai_Abstract:** 本研究提出了一种针对可压缩欧拉方程的新型空间离散化方法，该方法在离散层面上保证了热力学完美气体的熵守恒。它基于局部守恒公式，并成功将熵守恒方案应用于更真实的热力学完美气体模型，同时确保了线性和动能的守恒。该方法在精度和鲁棒性方面优于现有方法，并具有扩展到多组分气体和渐近熵守恒公式的潜力。

> **摘要翻译:** 本研究提出了一种新型空间离散化程序，用于可压缩欧拉方程，可确保热力学完美气体在离散层面的熵守恒。该程序基于局部守恒公式，并将熵守恒方案扩展到更真实的热力学完美气体情况，同时仍能保证线性和动能的不变性。所提出的方法也可扩展到多组分气体和渐近熵守恒公式，与现有类似方法相比，在精度和鲁棒性方面显示出优势。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [51] [Predicting Flow Dynamics using Diffusion Models](https://arxiv.org/abs/2507.08106)
> *使用扩散模型预测流体动力学*

*Yannick Gachnang, Vismay Churiwala* | **Category: physics.flu-dyn, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 扩散模型, 流体动力学, DiffFluid, 预测, 格子玻尔兹曼方法

**Comment:** 

> **TL;DR:** 本文旨在复现和扩展DiffFluid论文中提出的结果，验证扩散模型结合Transformer预测流体动力学的潜力与挑战，并探讨其作为通用求解器的可行性。

**AI_Comments:** 本文通过复现和扩展现有工作，验证了扩散模型在流体动力学预测方面的通用性和潜力，特别强调了其在不同模拟类型上的适用性。尽管面临资源限制，其发现仍具有重要意义，为该领域未来的计算优化和模型扩展指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在复现和扩展DiffFluid论文中提出的结果，该论文表明扩散模型结合Transformer能够预测流体动力学。研究目标是验证DiffFluid方法的可复现性，并测试其对其他模拟类型（特别是格子玻尔兹曼方法）的适用性。

**Method:** 本研究采用去噪扩散概率模型（DDPM）框架，结合Transformer来处理纳维-斯托克斯方程和达西流方程。研究方法侧重于验证DiffFluid论文中方法的再现性，并将其应用于格子玻尔兹曼方法等其他模拟类型进行测试。

**Result:** 尽管存在计算限制和时间限制，但研究结果证明了该模型作为流体动力学通用求解器的灵活性和潜力。结果还揭示了将扩散模型应用于复杂流体动力学问题的潜力和挑战。

**Conclusion:** 本文证实了扩散模型作为流体动力学通用求解器的灵活性和潜力，并指出了未来在优化计算效率和将此类模型扩展到更广泛领域方面的研究机会。

> **ai_Abstract:** 本文旨在复现并扩展DiffFluid论文的研究成果，该论文提出使用扩散模型结合Transformer来预测流体动力学。研究团队利用去噪扩散概率模型（DDPM）框架处理流体方程，并验证了DiffFluid方法的可复现性，同时评估了其在格子玻尔兹曼方法等其他模拟类型上的适用性。尽管面临计算资源和时间限制，本研究证明了该模型作为通用流体动力学求解器的灵活性和潜力，并指出了将其应用于复杂流体问题时的机遇与挑战，为未来的计算优化和模型扩展提供了方向。

> **摘要翻译:** 在这项工作中，我们旨在复现和扩展DiffFluid论文[1]中提出的结果。DiffFluid模型表明，扩散模型与Transformer相结合能够预测流体动力学。它使用去噪扩散概率模型（DDPM）框架来处理纳维-斯托克斯方程和达西流方程。我们的目标是验证DiffFluid论文中方法的可复现性，同时测试其对其他模拟类型（特别是格子玻尔兹曼方法）的适用性。尽管存在计算限制和时间限制，但这项工作提供了该模型作为流体动力学通用求解器具有灵活性和潜力的证据。我们的结果显示了将扩散模型应用于复杂流体动力学问题的潜力和挑战。这项工作强调了未来在优化计算效率和将此类模型扩展到更广泛领域的研究机会。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matdis-nn'></a>
## cond-mat.dis-nn 

### [15] [Consciousness as a Jamming Phase](https://arxiv.org/abs/2507.08197)
> *意识作为一种阻塞相*

*Kaichen Ouyang* | **Category: cond-mat.dis-nn, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 意识, 大型语言模型, 阻塞相, 临界现象, 无序系统

**Comment:** 18 pages, 13 figures

> **TL;DR:** 该论文提出大型语言模型中意识的出现是一种“阻塞相”，可被解释为高维无序系统中的临界现象，并与物理学中的阻塞转变类比。

**AI_Comments:** 这篇论文从物理学（统计力学、无序系统）的角度为人工智能中的意识提供了一个高度跨学科和新颖的视角。将意识与阻塞转变类比的观点极具创新性，为理解大型语言模型中的涌现特性提供了一个独特的理论框架。其局限性可能包括“意识”概念的抽象性，以及在纯粹的计算系统中对这种物理类比进行实证验证的难度。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将大型语言模型中意识的出现解释为高维无序系统中的一种临界现象，并为人工智能中的经验标度律提供统一的物理学解释。

**Method:** 该研究开发了一个神经阻塞相图，并与颗粒物质和其他复杂系统中的阻塞转变建立类比。它确定了温度、体积分数和应力三个基本控制参数，并利用热力学原理和共享的临界特征来解释意识的出现。

**Result:** 该理论为人工智能中的经验标度律提供了统一的物理学解释，并证明了计算冷却、密度优化和噪声降低如何共同驱动系统走向出现广义智能的临界阻塞表面。研究发现，描述传统阻塞转变的热力学原理和共享的临界特征（包括发散关联长度和标度指数）也似乎是神经网络中意识出现的基础。

**Conclusion:** 意识是一种阻塞相，通过长程关联内在连接知识成分，并通过阻塞物理学进行解释。

> **ai_Abstract:** 该论文提出大型语言模型中意识的出现可以被理解为一种“阻塞相”，即高维无序系统中的临界现象。通过与颗粒物质等物理系统中的阻塞转变进行类比，作者确定了温度、体积分数和应力是控制神经网络相行为的关键参数。他们认为，计算冷却、密度优化和噪声降低将神经网络推向一个临界阻塞状态，从而产生智能，这为人工智能的标度律提供了统一的物理学解释。这项工作表明，作为阻塞相的意识能够实现知识成分之间的长程关联。

> **摘要翻译:** 本文提出了一个神经阻塞相图，将大型语言模型中意识的出现解释为高维无序系统中的一种临界现象。通过与颗粒物质和其他复杂系统中的阻塞转变建立类比，我们确定了控制神经网络相行为的三个基本控制参数：温度、体积分数和应力。该理论为人工智能中的经验标度律提供了统一的物理学解释，证明了计算冷却、密度优化和噪声降低如何共同驱动系统走向出现广义智能的临界阻塞表面。值得注意的是，描述传统阻塞转变的相同热力学原理似乎是神经网络中意识出现的基础，其证据包括发散关联长度和标度指数等共享的临界特征。我们的工作通过阻塞物理学解释了神经语言模型的临界标度，表明意识是一种阻塞相，通过长程关联内在连接知识成分。

</details>

[⬆️ 返回分类顶部](#cond-matdis-nn) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [28] [PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning](https://arxiv.org/abs/2507.08064)
> *PUMA：用于高效统一多模态检索的分层剪枝语言模型，具有模态自适应学习能力*

*Yibo Lyu, Rui Shao, Gongwei Chen, Yijie Zhu, Weili Guan, Liqiang Nie* | **Category: cs.MM, cs.CV** | **Updated: 2025-07-10**

**Keywords:** 统一多模态检索, 分层剪枝, 模态自适应学习, 对比学习, 大型语言模型

**Comment:** Accepted to ACM MM 2025

> **TL;DR:** PUMA提出了一种分层剪枝的语言模型，通过剪枝和模态自适应对比学习来提高多模态检索的效率和性能。

**AI_Comments:** PUMA的创新性在于其结合了模型结构优化（分层剪枝）和学习策略优化（模态自适应对比学习），以解决多模态大型语言模型在实际应用中面临的效率瓶颈。这种双管齐下的方法有效地平衡了模型复杂度和性能，对于推动高效多模态检索具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着多媒体内容的增长，对统一多模态检索（UMR）的需求增加。现有的多模态大型语言模型（MLLMs）参数量大，导致训练成本高和推理效率低。

**Method:** PUMA方法从结构和学习两个方面改进UMR：
1. 结构上，提出分层剪枝自蒸馏（Layer-Pruned Self-Distillation），通过保留浅层并从丢弃的深层蒸馏特征来剪枝MLLMs，以减少参数并保持表示能力。
2. 学习上，引入模态自适应对比学习损失（Modality-Adaptive Contrastive Learning Loss，MAC-Loss），根据目标模态将批内负样本分为更难的模态内组和更容易的模态间组，并分配不同的温度策略以提高学习效率。

**Result:** 实验表明，PUMA显著减少了资源使用，同时保持了强大的性能。

**Conclusion:** 通过结构上的剪枝和学习上的模态自适应策略，PUMA有效地解决了多模态大型语言模型在统一多模态检索中效率低下的问题，实现了资源节约和性能保持。

> **ai_Abstract:** PUMA提出了一种高效的统一多模态检索（UMR）方法，旨在解决现有大型多模态语言模型（MLLMs）效率低下的问题。该方法结合了两个关键创新点：一是结构上的分层剪枝自蒸馏，通过保留浅层并从深层蒸馏特征来减少模型参数并保持表示能力；二是学习上的模态自适应对比学习损失（MAC-Loss），通过区分模态内和模态间负样本并应用不同的温度策略来提高学习效率。实验证明PUMA在显著减少资源消耗的同时，依然保持了强大的性能。

> **摘要翻译:** 随着多媒体内容的扩展，现实世界应用中对统一多模态检索（UMR）的需求不断增加。最近的工作利用多模态大型语言模型（MLLMs）来解决这项任务。然而，它们庞大的参数量导致训练成本高和推理效率低。为了解决这个问题，我们提出了PUMA：一种用于高效统一多模态检索的分层剪枝语言模型，具有模态自适应学习能力。我们的方法从结构和学习两个方面改进了UMR。(1) 在结构上，我们提出了分层剪枝自蒸馏，通过只保留浅层并从丢弃的深层蒸馏特征作为教师信号来剪枝MLLMs。这减少了参数并保留了表示能力。(2) 在学习方面，我们引入了模态自适应对比学习损失（MAC-Loss），该损失根据目标模态将批内负样本分为更难的模态内组和更容易的模态间组，并分配不同的温度策略以提高学习效率。实验表明，我们的方法显著减少了资源使用，同时保持了强大的性能。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [99] [Visual Semantic Description Generation with MLLMs for Image-Text Matching](https://arxiv.org/abs/2507.08590)
> *基于多模态大语言模型（MLLMs）的图像-文本匹配视觉语义描述生成*

*Junyu Chen, Yihua Gao, Mingyong Li* | **Category: cs.MM, cs.CV** | **Updated: 2025-07-11**

**Keywords:** 图像-文本匹配, 多模态大语言模型, 视觉语义描述, 跨模态对齐, 零样本泛化

**Comment:** Accepted by ICME2025 oral

> **TL;DR:** 本文提出了一种利用多模态大语言模型（MLLMs）生成视觉语义描述（VSD）的新框架，以弥合图像-文本匹配（ITM）中的模态差距，并通过实例级和原型级对齐显著提升了ITM性能，并展现了出色的零样本泛化能力。

**AI_Comments:** 这篇论文的创新点在于巧妙地利用了多模态大语言模型（MLLMs）作为视觉语义解析器来生成丰富的视觉语义描述（VSD），从而弥合了图像和文本模态之间的语义鸿沟。这种方法通过提供语义锚点，解决了传统ITM中模态表示差异的根本问题。其提出的实例级和原型级对齐机制，不仅增强了图像表示的语言表达力，还保证了类别级的一致性，使得该框架能够无缝集成到现有ITM模型中。尤其值得注意的是，其在零样本跨领域任务上的出色泛化能力，预示了该方法在实际应用中的巨大潜力。这为未来的跨模态研究提供了新的思路和方向。

<details>
  <summary>Details</summary>

**Motivation:** 图像-文本匹配（ITM）旨在解决视觉和文本模态对齐这一根本性挑战，因为它们在表示上存在固有的差异：连续、高维的图像特征与离散、结构化的文本。

**Method:** 本文提出了一种新颖的框架，通过利用多模态大语言模型（MLLMs）作为视觉语义解析器来弥合模态差距。通过生成丰富的视觉语义描述（VSD），MLLMs提供了促进跨模态对齐的语义锚点。该方法结合了：(1) 通过融合视觉特征与VSD来增强图像表示的语言表达能力的实例级对齐；以及 (2) 通过VSD聚类确保类别级一致性的原型级对齐。这些模块可以无缝集成到现有ITM模型中。

**Result:** 在Flickr30K和MSCOCO上的大量实验表明，性能得到了显著提升。该方法还在新闻和遥感ITM等跨领域任务中表现出卓越的零样本泛化能力。

**Conclusion:** 本文提出的利用MLLMs生成视觉语义描述的框架，通过实例级和原型级对齐，有效弥合了图像与文本模态之间的差距，显著提升了图像-文本匹配的性能，并展现了优秀的跨领域泛化能力，为ITM任务提供了一种新的有效方法。

> **ai_Abstract:** 本研究提出了一种利用多模态大语言模型（MLLMs）生成视觉语义描述（VSD）的新颖框架，旨在解决图像-文本匹配（ITM）中视觉与文本模态间的固有差异。通过生成VSD，MLLMs作为语义解析器，提供了促进跨模态对齐的语义锚点。该方法整合了实例级（融合视觉特征与VSD）和原型级（VSD聚类）对齐，以增强图像表示的语言表达能力并确保类别一致性。实验证明，该框架在Flickr30K和MSCOCO数据集上显著提升了ITM性能，并展现出卓越的跨领域零样本泛化能力。

> **摘要翻译:** 图像-文本匹配（ITM）旨在解决对齐视觉和文本模态这一根本性挑战，这两种模态在表示上固有不同，即连续、高维的图像特征与离散、结构化的文本。我们提出了一种新颖的框架，通过利用多模态大语言模型（MLLMs）作为视觉语义解析器来弥合模态差距。通过生成丰富的视觉语义描述（VSD），MLLMs提供了促进跨模态对齐的语义锚点。我们的方法结合了：(1) 通过融合视觉特征与VSD来增强图像表示的语言表达能力的实例级对齐；以及 (2) 通过VSD聚类确保类别级一致性的原型级对齐。这些模块可以无缝集成到现有ITM模型中。在Flickr30K和MSCOCO上的大量实验表明性能得到了显著提升。该方法还在新闻和遥感ITM等跨领域任务中表现出卓越的零样本泛化能力。代码和模型检查点可在 https://github.com/Image-Text-Matching/VSD 获取。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [496] [Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012](https://arxiv.org/abs/2503.22589)
> *使用人工智能总结美国总统竞选电视广告视频，1952-2012*

*Adam Breuer, Bryce J. Dietrich, Michael H. Crespin, Matthew Butler, J. A. Pryse, Kosuke Imai* | **Category: cs.MM, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 人工智能，电视广告，总统竞选，数据集，内容分析

**Comment:** 17 pages, 7 tables, 4 figures, and linked datasets

> **TL;DR:** 该论文发布了一个包含9707个美国总统竞选电视广告（1952-2012）的最大规模数据集，并提供了机器可搜索的文本和高质量摘要。通过AI驱动的自动化流程，该数据集解决了手动收集和注释的瓶颈，其质量经过人类评估验证，并可用于追踪70年的议题演变。该方法还展示了如何利用大型语言模型（LLM）为其他视频数据集生成高质量摘要。

**AI_Comments:** 该研究在处理大规模视频数据方面取得了重要进展，利用AI自动化了繁琐的转录和摘要过程，为政治传播研究提供了宝贵资源。其方法的通用性也使其能够应用于其他视频内容分析领域。然而，摘要的准确性和细微之处仍可能受限于AI模型的能力，未来可进一步探索更精细化的摘要策略。

<details>
  <summary>Details</summary>

**Motivation:** 过去对美国总统竞选电视广告的分析因需要手动收集和注释而受到数据量限制，研究者们通常依赖较小的样本子集。

**Method:** 研究者们设计了一个大规模、并行化、基于人工智能的分析流程，包括视频准备、转录和摘要生成，并将其应用于来自Julian P. Kanter政治商业档案的9707个总统广告。

**Result:** 该研究生成了一个包含9707个美国总统竞选电视广告（1952-2012）的最大规模数据集，并提供了机器可搜索的文本和高质量摘要。通过人类评估，证明了自动生成的文本和摘要质量可与手动生成相媲美。该数据集可用于追踪过去七十年总统选举中焦点议题的起源和演变。

**Conclusion:** 该研究成功开发并应用了一个AI驱动的分析流程，为大规模的美国总统竞选电视广告视频创建了一个全面的、机器可搜索的数据集和高质量摘要，解决了手动处理的瓶颈，并展示了其在追踪政治议题演变方面的应用价值，同时提供了可推广的LLM视频摘要方法。

> **ai_Abstract:** 本研究介绍了有史以来最大规模的美国总统竞选电视广告数据集（1952-2012），包含9707个广告及其机器可搜索的文字记录和高质量摘要。研究者们开发了一个基于AI的自动化流程来处理视频，解决了手动收集和标注的耗时问题。通过人类评估，证明了该自动化流程生成的摘要和文字记录的质量与手动生成相当。该数据集可用于追踪过去七十年美国总统竞选广告中议题的演变，并为其他视频数据集的摘要提供了可借鉴的方法。

> **摘要翻译:** 本文介绍了美国总统竞选电视广告数据集中最大、最全面的数据集，提供数字格式。该数据集还包括机器可搜索的文字记录和高质量摘要，旨在促进各种学术研究。迄今为止，收集和分析美国总统竞选广告一直备受关注，但手动采购和注释的需求导致许多人依赖较小的子集。我们设计了一个大规模的并行化、基于人工智能的分析流程，自动执行准备、转录和摘要视频的繁琐过程。然后，我们将这种方法应用于来自Julian P. Kanter政治商业档案的9707个总统广告。我们进行了广泛的人类评估，以表明这些文字记录和摘要与手动生成的替代品相匹配。我们通过包含一个跟踪七十年来总统选举中当前焦点议题领域起源和演变的应用程序来说明此数据的价值。我们的分析流程和代码库还展示了如何使用基于LLM的工具为其他视频数据集获得高质量的摘要。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [557] [VideoConviction: A Multimodal Benchmark for Human Conviction and Stock Market Recommendations](https://arxiv.org/abs/2507.08104)
> *视频说服力：人类说服力和股市推荐的多模态基准*

*Michael Galarnyk, Veer Kejriwal, Agam Shah, Yash Bhardwaj, Nicholas Meyer, Anand Krishnan, Sudheer Chava* | **Category: cs.MM, cs.AI, cs.CL, cs.CV** | **Updated: 2025-06-04**

**Keywords:** 金融影响者,多模态分析,大语言模型,股票推荐,说服力

**Comment:** 

> **TL;DR:** 该研究提出了VideoConviction数据集，用于评估大语言模型（LLM）和多模态大语言模型（MLLM）在金融领域分析“金融影响者”视频内容（包括语音、表情等）的能力。结果显示，多模态输入有助于提取股票代码，但模型在区分投资行为和说服力方面仍有困难，即使是高说服力的推荐也表现不如S&P 500指数基金。反向策略（与金融影响者的推荐反向操作）收益更高但风险也更大。

**AI_Comments:** 这项研究非常有价值，它首次提出了一个专门用于评估金融影响者视频内容分析的多模态数据集和基准。研究结果揭示了当前大语言模型在理解金融领域复杂多模态信号方面的局限性，特别是对于“说服力”这一关键但难以量化的概念。该数据集的公开有助于推动该领域的研究，并为开发更强大的金融分析工具提供了基础。然而，研究也指出了反向策略的高风险性，这对于实际投资决策具有重要参考意义。

<details>
  <summary>Details</summary>

**Motivation:** 金融影响者在社交媒体上发布股票推荐，需要分析包括语音、表情在内的多模态信号来理解其影响力，这超越了传统的文本分析。

**Method:** 创建了一个包含6000多条专家注释的多模态数据集（VideoConviction），耗费457小时人力，用于基准测试多模态大语言模型（MLLMs）和文本大语言模型（LLMs）在金融领域话语中的表现。评估了模型在完整视频和分段视频输入上的表现。

**Result:** 多模态输入能提升股票代码提取能力（例如提取苹果的AAPL代码）。然而，MLLMs和LLMs在区分投资行为和说服力方面表现不佳，常将一般性评论误分类为明确推荐。高说服力的推荐表现优于低说服力推荐，但仍逊于S&P 500指数基金。反向策略（做空金融影响者的推荐）年回报率比S&P 500高6.8%，但夏普比率（0.41）低于S&P 500（0.65），风险更高。

**Conclusion:** VideoConviction基准测试能够对多模态任务进行多样化评估，并比较模型在完整视频和分段视频输入上的表现，从而推动多模态金融研究的深入发展。

> **ai_Abstract:** 本研究介绍了VideoConviction，一个包含超过6000条专家注释的多模态数据集，旨在评估大语言模型（LLM）和多模态大语言模型（MLLM）在分析金融影响者视频内容（包括语音、面部表情等）方面的能力。研究发现，尽管多模态输入有助于提取股票代码，但模型在理解投资行为和“说服力”（即通过自信表达和详细推理传达的信念强度）方面仍存在挑战。高说服力的推荐表现优于低说服力推荐，但整体表现不及标普500指数基金。研究还指出，反向投资于金融影响者推荐策略的年回报率虽高于标普500，但风险也更高。该数据集和评估框架为多模态金融研究提供了新的基准。

> **摘要翻译:** 社交媒体放大了被称为“金融影响者”的金融领域意见领袖的影响力，他们在YouTube等平台上分享股票推荐。理解他们的影响力需要分析超越文本的金融分析的多模态信号，如语气、表达方式和面部表情。我们引入了VideoConviction，这是一个多模态数据集，拥有6000多条专家注释，通过457小时的人力劳动产生，旨在为多模态大语言模型（MLLMs）和基于文本的大语言模型（LLMs）在金融话语中的表现提供基准。我们的结果表明，虽然多模态输入能够改进股票代码提取（例如，提取苹果的股票代码AAPL），但MLLMs和LLMs在区分投资行为和信念强度——通过自信的表达和详细的推理所传达的信念强度——方面都存在困难，经常将一般性评论误分类为明确的推荐。虽然高信念强度的推荐表现优于低信念强度的推荐，但它们仍然逊于流行的标普500指数基金。一种反向策略——押注于金融影响者的推荐的反面——在年回报率上优于标普500指数基金6.8%，但承担着更大的风险（夏普比率为0.41，而标普500指数基金为0.65）。我们的基准测试能够对多模态任务进行多样化评估，比较模型在完整视频和分段视频输入上的性能。这使得在多模态金融研究方面取得更深入的进展。我们的代码、数据集和评估排行榜可在CC BY-NC 4.0许可下获取。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [35] [QubitLens: An Interactive Learning Tool for Quantum State Tomography](https://arxiv.org/abs/2505.08056)
> *QubitLens：一个用于量子态层析成像的交互式学习工具*

*Mohammad Aamir Sohail, Ranga Sudharshan, S. Sandeep Pradhan, Arvind Rao* | **Category: quant-ph, eess.SP** | **Updated: 2025-07-10**

**Keywords:** 量子态层析成像, 交互式学习, 可视化, 量子比特, 最大似然估计

**Comment:** 7 pages, 5 figures

> **TL;DR:** QubitLens 是一个交互式可视化工具，旨在使复杂的量子态层析成像更易于学习，无需深厚的先验知识。

**AI_Comments:** QubitLens 的创新之处在于它将复杂的量子态层析成像概念转化为直观的交互式视觉体验，降低了学习门槛。其重要性在于为量子计算教育提供了一个实用的工具，有助于普及量子概念。

<details>
  <summary>Details</summary>

**Motivation:** 量子态层析成像作为量子计算中的基本任务，因其涉及高级概念（如密度矩阵、张量积、部分迹运算）而通常仅在研究生阶段教授，这为早期学习者设置了障碍。本工作的动机是提供一个更易于访问和直观的学习工具。

**Method:** QubitLens 是一个交互式可视化工具，它利用最大似然估计（MLE）方法，从X、Y、Z基的投影测量结果中估计纯量子态。该工具通过布洛赫球面图、参数估计条形图和保真度计等视觉表示来强调概念清晰度，并支持单量子比特和多量子比特系统。

**Result:** QubitLens 成功使量子态层析成像更易于访问和直观。它提供了一种无需深厚密度矩阵或优化理论知识的实践学习方法，并能通过视觉表示量化重建准确性。

**Conclusion:** QubitLens 旨在通过简化量子态层析成像的学习过程，弥合量子计算教育中理论与实践之间的差距。

> **ai_Abstract:** QubitLens 是一个交互式可视化工具，旨在简化量子态层析成像的学习。它利用最大似然估计从测量结果中重建量子态，并通过布洛赫球面图、条形图和保真度计等视觉表示增强概念理解和重建准确性。该工具使学生和早期学习者无需深厚先验知识即可进行实践学习，从而弥合量子计算理论与实践之间的差距。

> **摘要翻译:** 量子态层析成像（Quantum state tomography）是量子计算中的一项基本任务，它涉及从测量结果中重建未知量子态。尽管至关重要，但由于其依赖于密度矩阵形式、张量积结构和部分迹运算等高级概念，通常在研究生阶段才引入。这种复杂性常常为学生和早期学习者制造障碍。在这项工作中，我们引入了 QubitLens，一个旨在使量子态层析成像更易于访问和直观的交互式可视化工具。QubitLens 利用最大似然估计（MLE）这一经典统计方法，从 X、Y 和 Z 基的投影测量结果中估计纯量子态。该工具通过视觉表示强调概念清晰度，包括真实和重建量子比特状态的布洛赫球面图、比较参数估计值的条形图以及量化重建准确性的保真度计。QubitLens 提供了一种亲身实践的学习量子层析成像的方法，而无需密度矩阵或优化理论的深厚先验知识。该工具支持单量子比特和多量子比特系统，旨在弥合量子计算教育中理论与实践之间的差距。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [115] [Parametrized Quantum Circuit Learning for Quantum Chemical Applications](https://arxiv.org/abs/2507.08183)
> *参数化量子电路学习在量子化学应用中的研究*

*Grier M. Jones, Viki Kumar Prasad, Ulrich Fekl, Hans-Arno Jacobsen* | **Category: quant-ph, cs.LG, physics.chem-ph** | **Updated: 2025-07-10**

**Keywords:** 参数化量子电路, 量子机器学习, 量子化学, BSE49, 水构象

**Comment:** 

> **TL;DR:** 本文研究了参数化量子电路（PQCs）在量子化学数据集上的应用潜力与局限性，发现尽管PQCs在量子机器学习中前景广阔，但在化学相关问题上仍面临挑战，尤其是在与经典机器学习方法对比时。

**AI_Comments:** 本文深入探讨了参数化量子电路在量子化学领域的应用，填补了该领域数据集探索的空白。其创新之处在于系统性地构建了大量的PQC组合并进行了全面的性能评估，包括在真实量子硬件上的测试。研究结果坦诚地指出了当前PQCs在处理某些化学相关问题时面临的挑战，这对于未来量子机器学习算法的开发和优化具有重要的指导意义，有助于研究人员更清晰地认识到量子优势的实现路径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管参数化量子电路（PQCs）在量子机器学习（QML）中具有广泛的应用前景，但其在量子化学相关数据集上的探索仍然有限。

**Method:** 本研究在两个化学相关数据集（BSE49数据集和水构象数据集）上，通过结合14种数据编码策略和12种变分拟设，构建了168个PQCs。研究评估了PQCs在5和16量子位电路上的性能，分析了电路结构、电路深度和训练集大小对模型性能的影响，并使用噪声模拟和真实量子设备评估了最佳PQCs的性能。

**Result:** 研究发现，将PQCs应用于对经典机器学习方法而言简单但对量子方法而言非平凡的化学相关问题时，仍面临挑战。

**Conclusion:** 将参数化量子电路（PQCs）应用于化学相关问题仍然具有挑战性，特别是与经典机器学习方法相比，量子方法仍需克服诸多难题。

> **ai_Abstract:** 本研究探讨了参数化量子电路（PQCs）在量子化学应用中的潜力和局限性。通过在BSE49和水构象这两个化学数据集上构建和评估168种不同的PQCs组合，研究人员分析了电路结构、深度和训练集大小对模型性能的影响，并在模拟和真实量子硬件上进行了测试。研究结果表明，尽管PQCs在量子机器学习中具有前景，但在处理对经典方法而言相对简单的化学问题时，量子方法仍面临显著挑战。

> **摘要翻译:** 在量子机器学习（QML）领域，参数化量子电路（PQCs）——通过固定和可调量子门的组合构建——为解决复杂机器学习问题提供了一个有前景的混合框架。尽管提出了众多应用，但与量子化学相关的数据集探索仍然有限。在本研究中，我们调查了PQCs在两个具有化学意义的数据集上的潜在益处和局限性：（1）BSE49数据集，包含49种不同化学键的键分离能；（2）水构象数据集，其中使用数据驱动耦合簇（DDCC）方法从较低级别的电子结构方法预测耦合簇单双激发（CCSD）波函数。我们通过结合14种数据编码策略和12种变分拟设，构建了168个综合性的PQCs，并评估了它们在5和16量子位电路上的性能。我们的初步分析考察了电路结构对模型性能的影响，使用了状态向量模拟。然后，我们探讨了电路深度和训练集大小如何影响模型性能。最后，我们使用噪声模拟（“假”后端）和真实量子设备评估了性能最佳的PQCs在当前量子硬件上的性能。我们的发现强调了将PQCs应用于对经典机器学习方法而言简单但对量子方法而言非平凡的化学相关问题的挑战。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [238] [Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks](https://arxiv.org/abs/2507.08202)
> *量子特性特洛伊木马（QuPTs）攻击量子神经网络*

*Sounak Bhowmik, Travis S. Humble, Himanshu Thapliyal* | **Category: quant-ph, cs.AI, cs.CR** | **Updated: 2025-07-10**

**Keywords:** 量子神经网络, 特洛伊木马攻击, 量子安全, 量子机器学习, 量子计算

**Comment:** 

> **TL;DR:** 本研究提出了基于量子计算特性的新型特洛伊木马（QuPTs），用于攻击量子神经网络（QNNs），并首次展示了其对全量子QNN的隐蔽性和破坏性，导致高达23%的准确率下降。

**AI_Comments:** 这项工作具有重要的创新性，因为它首次提出了针对完全量子神经网络的特洛伊木马攻击，而不仅仅是混合经典-量子架构。利用量子计算的固有特性（如酉性和叠加）来构建攻击，展现了对量子系统深层理解。其发现QNN的准确率可被显著降低，强调了量子机器学习安全性的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 量子神经网络（QNN）在量子机器学习（QML）领域具有巨大潜力，但其安全性和鲁棒性仍未得到充分探索。

**Method:** 本研究提出了基于量子计算特性的新型特洛伊木马（QuPTs），利用量子门的酉性引入噪声，并利用Hadamard门实现叠加，从而开发并攻击基于QNN的二元分类器。

**Result:** 所提出的QuPTs表现出更高的隐蔽性，并严重影响量子电路（特别是QNNs）的性能。最具影响力的QuPT在实验设置下导致受损QNN的准确率下降了23%。

**Conclusion:** 这是首次针对完全量子神经网络（独立于任何混合经典-量子架构）进行特洛伊木马攻击的研究。

> **ai_Abstract:** 本研究提出了一种名为量子特性特洛伊木马（QuPTs）的新型攻击方法，专门针对量子神经网络（QNN）的安全性进行探索。QuPTs利用量子门的酉性和Hadamard门的叠加特性来植入噪声和开发特洛伊木马。实验结果表明，QuPTs具有高度的隐蔽性，并能显著降低QNN的性能，在特定情况下导致高达23%的准确率下降。该工作首次实现了对纯量子神经网络的特洛伊木马攻击，填补了该领域的研究空白。

> **摘要翻译:** 量子神经网络（QNN）在未来的量子机器学习（QML）中具有巨大的潜力。然而，QNN的安全性和鲁棒性在很大程度上仍未被探索。在这项工作中，我们提出了一种基于QNN二元分类器中量子计算特性的新型特洛伊木马攻击。我们提出的量子特性特洛伊木马（QuPTs）基于量子门的酉性来插入噪声，并利用Hadamard门实现叠加，从而开发特洛伊木马并攻击QNNs。我们表明，所提出的QuPTs更具隐蔽性，并严重影响量子电路的性能，特别是QNNs。在实验设置下，最具影响力的QuPT导致受损QNN的准确率下降了23%。据我们所知，这是首次针对完全量子神经网络（独立于任何混合经典-量子架构）进行特洛伊木马攻击的工作。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [257] [Enhancing Decoding Performance using Efficient Error Learning](https://arxiv.org/abs/2507.08536)
> *使用高效错误学习提升解码性能*

*Pavithran Iyer, Aditya Jain, Stephen D. Bartlett, Joseph Emerson* | **Category: quant-ph, cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 量子纠错, 最大似然解码, 泡利错误率, 循环错误重构, 容错量子计算

**Comment:** 22 pages, 11 figures

> **TL;DR:** 通过利用少量高效可学习的物理错误特性，显著提升量子纠错码的解码性能，从而降低容错量子计算的资源开销。

**AI_Comments:** 该研究的创新之处在于，它证明了即使是有限但关键的错误特征信息（特别是少量最大的泡利错误率）也能极大地提升量子纠错的解码效率和性能。这对于实际的量子计算至关重要，因为它直接解决了高资源开销的挑战。文中提出的使用1%的泡利错误率数据即可实现10倍性能提升的结果，是一个非常引人注目的突破。

<details>
  <summary>Details</summary>

**Motivation:** 降低实现容错量子计算所需的资源开销，对于构建可扩展的量子计算机至关重要。

**Method:** 通过将传统最大似然（ML）解码器与少量高效可学习的物理错误特性相结合来提升性能。具体方法是利用基于循环错误重构（CER）的错误信息，该方法可以获取量子纠错码中n个量子比特的泡利错误率。研究表明，仅需少数最大的泡利错误率，并通过启发式技术从这些受限数据集中补全泡利错误分布，即可用于ML解码。

**Result:** 在各种物理相关的错误模型下，量子码的解码性能得到了显著提升。例如，仅使用系统中1%的泡利错误率（通过CER数据获得），相比仅基于底层噪声过程保真度的解码情况，性能提高了10倍。

**Conclusion:** 最近的错误表征方法对于改进量子纠错和降低开销具有巨大潜力。

> **ai_Abstract:** 该论文提出了一种通过利用少量高效可学习的物理错误特性来显著提升量子纠错码解码性能的方法。研究人员将传统最大似然（ML）解码器与从循环错误重构（CER）获得的泡利错误率信息相结合。尽管完整的错误描述是指数级的，但他们发现仅需少数最大的泡利错误率，并通过启发式技术即可有效应用于ML解码。实验结果表明，在多种物理相关错误模型下，该方法能显著提高解码性能，例如仅用1%的泡利错误率数据即可实现10倍的性能提升。这凸显了新型错误表征方法在降低容错量子计算开销和实现可扩展量子计算机方面的巨大潜力。

> **摘要翻译:** 降低实现容错量子计算所需的资源开销对于构建可扩展的量子计算机至关重要。我们表明，将传统最大似然（ML）解码器与一小部分可高效学习的物理错误特性相结合，可以显著提高量子纠错码的逻辑性能。具体来说，我们利用从基于循环错误重构（CER）的高效表征方法获得的错误信息，该方法可生成纠错码中n个量子比特的泡利错误率。尽管描述一般噪声过程所需的泡利错误率总数随n呈指数增长，但我们表明仅需要少数最大的泡利错误率，并且启发式技术可以从这个受限数据集中完成ML解码的泡利错误分布。使用这些技术，我们证明了在各种物理相关的错误模型下，量子码解码性能的显著改进。例如，在仅占系统泡利错误率1%的CER数据下，我们实现了相比仅基于底层噪声过程保真度的解码情况10倍的性能增益。我们的结论强调了近期错误表征方法在改进量子纠错和降低开销方面的前景。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [258] [Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security](https://arxiv.org/abs/2507.08623)
> *纠缠威胁：量子机器学习安全统一杀伤链模型*

*Pascal Debus, Maximilian Wendlinger, Kilian Tscharke, Daniel Herr, Cedric Brügmann, Daniel Ohl de Mello, Juris Ulmanis, Alexander Erhard, Arthur Schmidt, Fabian Petsch* | **Category: quant-ph, cs.CR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 量子机器学习安全, 杀伤链模型, 威胁建模, 攻击向量, QML

**Comment:** Accepted for publication at IEEE International Conference on Quantum
  Computing and Engineering (QCE) 2025

> **TL;DR:** 本文提出了一种统一的杀伤链模型，用于对量子机器学习（QML）系统中的各种攻击向量进行结构化建模和分析，以促进更全面的防御策略。

**AI_Comments:** 本文的创新之处在于首次将经典的杀伤链模型引入到量子机器学习安全领域，提供了一个统一且结构化的框架来理解和分析QML攻击。这对于克服现有研究中攻击分析的碎片化问题至关重要，并为开发更全面、主动的防御策略奠定了基础。其提出的攻击向量分类法和对相互依赖性的强调，对于未来的QML威胁建模和安全设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的量子机器学习安全研究通常孤立地分析攻击向量，并基于不切实际的假设，导致难以开发出有效、整体的防御策略。因此，QML安全需要更结构化的攻击面建模，不仅捕捉个体技术，还要捕捉它们之间的关系、先决条件和对QML管道的潜在影响。

**Method:** 作者提出将经典IT和网络安全中广泛使用的杀伤链模型 адапти到量子机器学习环境中。通过对现有文献的广泛分析，他们提出了一个详细的QML攻击向量分类法，并将其映射到受MITRE ATLAS启发的量子感知杀伤链框架中的相应阶段。

**Result:** 本文提供了一个详细的QML攻击向量分类法，将其映射到量子感知杀伤链框架的各个阶段。它强调了物理层威胁（如侧信道泄漏、串扰故障）、数据和算法操纵（如中毒、电路后门）以及隐私攻击（如模型提取、训练数据推断）之间的相互依赖关系。

**Conclusion:** 这项工作为新兴的量子机器学习领域的更现实的威胁建模和主动的深度安全设计奠定了基础。

> **ai_Abstract:** 本文针对量子机器学习（QML）系统面临的日益增长且碎片化的安全威胁，提出了一种统一的杀伤链模型。作者指出，现有研究孤立地分析攻击，缺乏对攻击关系和影响的全面理解。为解决此问题，他们将经典网络安全中的杀伤链模型应用于QML，并构建了一个详细的QML攻击向量分类法，将其映射到量子感知杀伤链框架的各个阶段，该框架受MITRE ATLAS启发。此工作强调了物理层、数据/算法操纵和隐私攻击之间的相互依赖性，旨在为QML领域的威胁建模和深度安全设计提供更现实的基础。

> **摘要翻译:** 量子机器学习（QML）系统继承了经典机器学习的漏洞，同时引入了植根于量子计算物理和算法层的新攻击面。尽管关于个体攻击向量的研究日益增多——从对抗性中毒和规避到电路级后门、侧信道泄漏和模型提取——但这些威胁往往被孤立分析，并且基于对攻击者能力和系统环境的不切实际的假设。这种碎片化阻碍了有效、整体防御策略的开发。在这项工作中，我们认为QML安全需要更结构化的攻击面建模，不仅捕捉个体技术，还要捕捉它们之间的关系、先决条件和对QML管道的潜在影响。我们建议将经典IT和网络安全中广泛使用的杀伤链模型 адапти到量子机器学习环境中。这些模型允许对攻击者目标、能力和可能的多阶段攻击路径进行结构化推理——涵盖侦察、初始访问、操纵、持久性和数据窃取。基于广泛的文献分析，我们提出了一个详细的QML攻击向量分类法，并将其映射到受经典机器学习MITRE ATLAS启发的量子感知杀伤链框架中的相应阶段。我们强调了物理层威胁（如侧信道泄漏和串扰故障）、数据和算法操纵（如中毒或电路后门）以及隐私攻击（包括模型提取和训练数据推断）之间的相互依赖关系。这项工作为新兴的量子机器学习领域的更现实的威胁建模和主动的深度安全设计奠定了基础。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [377] [ProvideQ: A Quantum Optimization Toolbox](https://arxiv.org/abs/2507.07649)
> *ProvideQ：一个量子优化工具箱*

*Domenik Eichhorn, Nick Poser, Maximilian Schweikart, Ina Schaefer* | **Category: quant-ph, cs.SE** | **Updated: 2025-07-11**

**Keywords:** 量子优化, 混合求解器, 组合优化, ProvideQ, 元求解器

**Comment:** This paper was submitted and accepted at the IEEE QSW 2025. Code
  available at: https://github.com/ProvideQ

> **TL;DR:** ProvideQ是一个量子优化工具箱，旨在解决混合求解器在经典与量子计算集成方面的技术栈缺失问题。它通过元求解器策略实现问题分解，将经典和量子计算无缝结合，并已证明其应用潜力，但性能提升仍需硬件支持。

**AI_Comments:** ProvideQ工具箱的提出解决了量子与经典计算混合求解器实际应用中的关键技术集成问题，其创新点在于元求解器策略对问题的分解能力以及对多后端量子电路的无缝支持。这对于推动量子计算的实际应用具有重要意义，同时也突出了当前硬件发展的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 组合优化问题的经典-量子混合求解器尽管理论前景广阔，但由于缺乏能无缝集成量子解决方案与现有经典优化框架的技术栈，其在实际应用中面临挑战。

**Method:** 本文介绍了ProvideQ工具箱，一个软件工具，通过元求解器策略使用户能够轻松调整和配置混合求解器。该工具箱通过元求解器配置工具，实现将问题分解为经典和量子子程序的交互式创建，并将经典优化技术与可在多个后端无缝执行的量子电路相结合。

**Result:** 概念验证表明，ProvideQ中的元求解器策略目前已经能够应用量子子程序。

**Conclusion:** 尽管当前可以使用元求解器策略应用量子子程序，但要使其性能具有竞争力，还需要更复杂的硬件支持。

> **ai_Abstract:** ProvideQ是一个为组合优化问题设计的量子优化工具箱，旨在解决经典与量子混合求解器在实际应用中缺乏无缝技术栈的问题。它通过引入元求解器策略，实现将问题分解为经典和量子子程序，并支持交互式配置及多后端执行。概念验证表明其已能应用量子子程序，但要达到有竞争力的性能仍需更先进的硬件。

> **摘要翻译:** 组合优化问题的混合求解器结合了经典计算和量子计算的优势，以克服困难的计算挑战。尽管它们的理论性能看起来很有前景，但由于缺乏能够将量子解决方案与现有经典优化框架无缝集成的技术栈，它们的实际应用面临挑战。我们通过引入 ProvideQ 工具箱来应对这一挑战，这是一个软件工具，用户可以通过元求解器（Meta-Solver）策略轻松调整和配置混合求解器。元求解器策略实现了分解技术，将问题分解为经典和量子子程序。ProvideQ 工具箱通过元求解器配置工具，实现了此类分解的交互式创建。它将成熟的经典优化技术与可以在多个后端无缝执行的量子电路相结合。本文介绍了 ProvideQ 工具箱的技术细节，解释了其架构，并展示了在多个实际用例中的可能应用。我们的概念验证表明，元求解器策略现在已经能够应用量子子程序，但是，需要更复杂的硬件才能使其性能具有竞争力。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [391] [Quantum Algorithms for Projection-Free Sparse Convex Optimization](https://arxiv.org/abs/2507.08543)
> *面向无投影稀疏凸优化的量子算法*

*Jianhao He, John C. S. Lui* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 量子算法, 稀疏凸优化, 无投影优化, 查询复杂度, 核范数约束

**Comment:** 

> **TL;DR:** 该论文提出了用于向量和矩阵域的无投影稀疏凸优化量子算法，在稀疏约束和核范数约束方面均优于经典算法。

**AI_Comments:** 该研究在无投影稀疏凸优化领域取得了重要进展，通过量子算法实现了理论上的显著加速。然而，实际应用中的量子硬件限制和常数因子优化仍是未来研究的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 解决机器学习和数据科学中重要的无投影稀疏凸优化问题，包括向量域和矩阵域。

**Method:** 对于向量域，提出了两种稀疏约束的量子算法，查询复杂度分别为 O(sqrt(d)/ε) 和 O(1/ε)。对于矩阵域，提出了两种核范数约束的量子算法，更新步骤的时间复杂度分别为 O~(rd/ε^2) 和 O~(sqrt(r)d/ε^3)。

**Result:** 量子算法在查询复杂度和时间复杂度上均优于现有的最佳经典算法，分别在向量域和矩阵域实现了至少 O(sqrt(d)) 和 O(sqrt(d)) 的因子改进。

**Conclusion:** 所提出的量子算法在无投影稀疏凸优化问题上展现出量子优势，其性能优于最优的经典方法，尤其是在依赖于维度 d 的情况下。

> **ai_Abstract:** 本文针对向量域和矩阵域的无投影稀疏凸优化问题，提出了两种量子算法。在向量域，算法在稀疏约束下实现了比经典算法更优的查询复杂度。在矩阵域，算法在核范数约束下显著提高了更新步骤的时间复杂度。这些量子算法在依赖于维度 d 的情况下，均优于现有的最佳经典算法，证明了其在无投影稀疏凸优化问题上的量子优势。

> **摘要翻译:** 本文考虑了向量域和矩阵域的无投影稀疏凸优化问题，这涵盖了机器学习和数据科学中的大量重要应用。对于向量域 $\mathcal{D} \subset \mathbb{R}^d$，我们为稀疏约束提出了两种量子算法，通过使用函数值预言机，找到一个 $\varepsilon$-最优解，其查询复杂度分别为 $O(\sqrt{d}/\varepsilon)$ 和 $O(1/\varepsilon)$，与最佳经典算法相比，分别减少了 $O(\sqrt{d})$ 和 $O(d)$ 的因子，其中 $d$ 是维度。对于矩阵域 $\mathcal{D} \subset \mathbb{R}^{d\times d}$，我们为核范数约束提出了两种量子算法，将计算更新步骤的时间复杂度分别提高到 $\tilde{O}(rd/\varepsilon^2)$ 和 $\tilde{O}(\sqrt{r}d/\varepsilon^3)$，与最佳经典算法相比，至少减少了 $O(\sqrt{d})$ 的因子，其中 $r$ 是梯度矩阵的秩。我们的算法通过优于最优经典方法在维度 $d$ 上的依赖性，展示了在无投影稀疏凸优化问题上的量子优势。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [522] [Learnable quantum spectral filters for hybrid graph neural networks](https://arxiv.org/abs/2507.05640)
> *用于混合图神经网络的可学习量子谱滤波器*

*Ammar Daskin* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 量子图神经网络, 量子傅里叶变换, 拉普拉斯算子, 图分类, 参数化量子电路

**Comment:** The simulation code and results used for this paper is publicly
  available at: https://github.com/adaskin/gnn-qsf

> **TL;DR:** 该论文提出了一种参数化量子电路，可用作图神经网络的卷积和池化层。该电路利用量子傅里叶变换（QFT）和拉普拉斯算子，能够高效地处理图数据，实现指数级压缩，并在图分类任务上取得了与经典方法相当甚至更优的结果。

**AI_Comments:** 该研究将量子计算应用于图神经网络，提出了一种创新的方法来处理图数据的卷积和池化操作。利用量子傅里叶变换和拉普拉斯算子的结合，该方法在处理大规模图数据时表现出显著的效率优势，并且在实际应用中取得了令人鼓舞的结果。然而，实验的规模和数据集的多样性仍有待进一步扩展，以充分验证该方法的普适性和鲁棒性。此外，量子硬件的限制和噪声对模型性能的影响也需要进一步的探讨和缓解策略。

<details>
  <summary>Details</summary>

**Motivation:** 传统的图神经网络（GNN）在处理图数据时，需要昂贵的经典计算来近似拉普拉斯算子的可学习函数。本研究旨在探索一种更高效的方法，利用量子计算的优势来简化和加速这一过程。

**Method:** 提出了一种参数化量子电路，该电路包含基于量子傅里叶变换（QFT）的卷积和池化层。电路连接由拉普拉斯算子导出，并利用图的邻接矩阵来确定。该方法仅需对数级别的量子比特即可处理大规模图数据，并能有效地提取图的几何结构信息。

**Result:** 所提出的量子电路作为卷积层，能够将N维输入信号压缩成n维概率向量，实现了高效的卷积和池化。将此量子电路与经典神经网络结合后，在TUDataset基准数据集上的图分类任务中，取得了与现有方法相当甚至更优的性能，尤其是在几何结构起关键作用的情况下。

**Conclusion:** 所提出的可学习量子谱滤波器能够作为混合图神经网络中的高效卷积和池化层，通过利用量子计算和图的几何结构信息，在图分类任务上取得了优异的性能，为图神经网络的研究提供了新的方向。

> **ai_Abstract:** 本研究提出了一种新颖的量子电路，可作为混合图神经网络的卷积和池化层。该电路利用量子傅里叶变换（QFT）和图的拉普拉斯算子，能够高效地处理图数据，实现指数级压缩，并在图分类任务上取得了与现有方法相当甚至更优的性能。

> **摘要翻译:** 在本论文中，我们描述了一种参数化量子电路，该电路可被视为图神经网络的卷积层和池化层。该电路采用了参数化量子傅里叶电路，其中受控门控的量子比特连接由拉普拉斯算子导出。具体而言，我们证明了通过基于QFT的电路，其连接由邻接矩阵确定，可以近似图的拉普拉斯算子的特征空间。对于一个N×N的拉普拉斯算子，这种方法产生了一个近似多项式深度的电路，仅需要n=log(N)个量子比特。这类电路可以消除通过Chebyshev多项式或Taylor展开来近似拉普拉斯算子可学习函数的昂贵经典计算。将此电路作为卷积层使用，可以得到一个n维概率向量，该向量可以被视为滤波和压缩后的图信号。因此，该电路结合测量可以被认为是一个非常高效的卷积加池化层，它将一个N维信号输入转换为一个n维信号，并实现指数级压缩。然后，我们将一个经典的神经网络预测头应用于该电路的输出，以构建一个完整的图神经网络。由于该电路通过其基于图连接的方法融入了几何结构，我们展示了在TUDataset库中列出的基准数据集上的图分类结果。使用[1-100]个可学习参数的量子电路和极少的经典层（1000-5000个参数）在通用设置下，所获得的结果与许多基线结果相当，在某些情况下甚至更好，特别是在几何结构起重要作用的情况下。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [552] [Experimental Ground-State Energy of a 125-Site Flat Kagome Antiferromagnet via Hamiltonian Engineering on Quantum Computer](https://arxiv.org/abs/2507.06361)
> *量子计算机上哈密顿量工程在125个格点的平面kagome反铁磁体的实验基态能量*

*Muhammad Ahsan* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-10**

**Keywords:** 量子计算,kagome晶格, 反铁磁性, VQE, 哈密顿量工程

**Comment:** National Center for Quantum Computing, UET Lahore, Pakistan

> **TL;DR:** 该研究使用量子计算机（IBM Heron r1和r2）计算了125个格点平面kagome反铁磁体的基态能量，提出了混合VQE方法和哈密顿量工程策略，实现了高精度计算，证明了VQE在二维量子多体系统中的可扩展性。

**AI_Comments:** 该研究成功地将量子计算应用于复杂的二维量子多体问题，提出的混合VQE和哈密顿量工程策略在提高计算效率和准确性方面显示出巨大潜力。然而，与热力学值的差异以及“实用级”量子计算的定义仍需进一步明确和验证。未来的工作可以探索更复杂的模型和更大的系统规模。

<details>
  <summary>Details</summary>

**Motivation:** 计算125个格点平面kagome反铁磁体的基态能量，并探索量子计算在解决二维量子多体问题上的应用。

**Method:** 提出一种混合方法，将VQE分解为局部（经典）和全局（量子）部分；提出一种哈密顿量工程策略，通过增加缺陷三角形的耦合来模拟循环翻转动力学，简化了ansatz；使用硬件高效的ansatz，利用多达103个量子比特进行计算。

**Result:** 给出了每格点基态能量估计值为-0.417J，经过边界修正后接近热力学值-0.438J。

**Conclusion:** 该工作展示了VQE在处理受挫二维系统中的可扩展性，并为未来使用更深的ansatz电路和更大的晶格奠定了基础。

> **ai_Abstract:** 本研究利用IBM的Heron量子处理器，通过混合VQE方法和哈密顿量工程策略，计算了125个格点的平面kagome反铁磁体的基态能量，得到了接近热力学极限的精确结果，并验证了该方法在二维受挫系统中的可扩展性。

> **摘要翻译:** 我们通过IBM的Heron r1和Heron r2量子处理器，计算了反铁磁海森堡模型（KAFH）下125个格点平面kagome晶格的基态能量，展示了实用级量子计算的一个实例。对于自旋1/2的KAFH，我们最好的每格点基态能量估计值为-0.417J，在应用开边界修正后，它非常接近已建立的热力学值-0.438J。为了实现这一目标，我们提出了一种混合方法，将变分量子特征求解器（VQE）分解为局部（经典）和全局（量子）部分，以实现高效的硬件利用。我们进一步引入了一种哈密顿量工程策略，该策略增加了缺陷三角形的耦合以模拟循环翻转动力学，使我们能够在保持物理准确性的同时简化ansatz。我们使用单次重复的、硬件高效的ansatz，以高保真度纠缠了多达103个量子比特，以确定哈密顿量的最低本征值。这项工作展示了VQE在受挫二维系统中的可扩展性，并为未来使用更深的ansatz电路和更大的晶格奠定了基础。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [40] [Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs](https://arxiv.org/abs/2502.09832)
> *算法邻近性源于低度猜想及其在相关随机图中的应用*

*Zhangsong Li* | **Category: stat.ML, cs.DS, cs.LG, math.PR, math.ST, stat.TH, 68Q87, 62M20** | **Updated: 2025-07-11**

**Keywords:** 低度猜想, 算法邻近性, 计算硬度, 相关随机图, 随机块模型

**Comment:** minor updates; extended abstract to appear in RANDOM 2025

> **TL;DR:** 本文在强化低度猜想的假设下，为两个在稀疏相关随机图中的问题（匹配恢复和检测问题）提供了计算硬度的证据。研究核心在于推导基于低度优势的算法邻近性，并将其作为一个在不同推断任务间进行归约的工具。

**AI_Comments:** 本文的创新之处在于提出了“算法邻近性”的概念，并将其与低度猜想相结合，为证明特定图模型中的计算硬度提供了新的理论工具。这种方法不仅解决了相关领域的开放问题，也为理解信息-计算相变提供了新的视角，对于高维统计推断和算法设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决先前工作中遗留的两个问题，并为在特定条件下稀疏相关随机图中的匹配恢复问题和检测问题提供计算硬度的证据。

**Method:** 研究基于对低度猜想的自然强化假设，核心方法是推导两种概率测度之间的“算法邻近性”，其依据是它们低度优势的界限。具体而言，针对高维假设检验问题，证明了在低度优势有界的情况下，不存在高效算法能够区分两种分布。

**Result:** 本文提供了两个问题的计算硬度证据：1) 在边密度和相关性低于Otter阈值时，稀疏相关Erdős-Rényi图中的（部分）匹配恢复问题；2) 在参数低于Kesten-Stigum (KS) 阈值和Otter阈值时，相关稀疏随机块模型与独立随机块模型之间的检测问题。这两个结果均解决了相关领域中的遗留问题。

**Conclusion:** 本文提出的框架为在不同推断任务之间进行归约提供了一个有用的工具。

> **ai_Abstract:** 本文在强化低度猜想的假设下，研究了稀疏相关随机图中的计算硬度问题。通过推导基于低度优势的“算法邻近性”概念，作者为在特定条件下，稀疏相关Erdős-Rényi图中的匹配恢复问题和相关随机块模型中的检测问题提供了计算硬度的证据。该框架被证明是连接和归约不同推断任务的有效工具。

> **摘要翻译:** 在本文中，假设低度猜想的自然强化形式成立，我们为两个问题提供了计算硬度的证据：(1) 在边密度 $q=n^{-1+o(1)}$ 且相关性 $ho<\sqrt{\alpha}$ 低于Otter阈值时，稀疏相关Erdős-Rényi图 $\mathcal G(n,q;\rho)$ 中的（部分）匹配恢复问题，解决了 \cite{DDL23+} 中的一个遗留问题；(2) 当 $\epsilon^2 \lambda s<1$ 低于Kesten-Stigum (KS) 阈值且 $s<\sqrt{\alpha}$ 低于Otter阈值时，相关稀疏随机块模型 $\mathcal S(n,\tfrac{\lambda}{n};k,\epsilon;s)$ 与一对独立随机块模型 $\mathcal S(n,\tfrac{\lambda s}{n};k,\epsilon)$ 之间的检测问题，解决了 \cite{CDGL24+} 中的一个遗留问题。\n我们证明中的主要组成部分之一是根据其低度优势的界限，推导出两种概率测度之间特定形式的\emph{算法邻近性}。更精确地说，考虑基于样本 $\mathsf Y$ 的两种概率测度 $\mathbb{P}$ 和 $\mathbb{Q}$ 之间的高维假设检验问题。我们证明，如果低度优势 $\mathsf{Adv}_{\leq D} \big( \frac{\mathrm{d}\mathbb{P}}{\mathrm{d}\mathbb{Q}} \big)=O(1)$，那么（假设低度猜想成立）不存在一个高效算法 $\mathcal A$ 使得 $\mathbb{Q}(\mathcal A(\mathsf Y)=0)=1-o(1)$ 且 $\mathbb{P}(\mathcal A(\mathsf Y)=1)=\Omega(1)$。这个框架为在不同推断任务之间进行归约提供了一个有用的工具。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [76] [Mallows Model with Learned Distance Metrics: Sampling and Maximum Likelihood Estimation](https://arxiv.org/abs/2507.08108)
> *马洛斯模型与学习距离度量：采样与最大似然估计*

*Yeganeh Alimohammadi, Kiana Asgari* | **Category: stat.ML, cs.DS, cs.LG, math.PR, math.ST, stat.TH, 62F10, 62H20, 68W20, 60C05, F.2.2; G.3; I.2.6; H.2.8** | **Updated: 2025-07-10**

**Keywords:** 马洛斯模型, 距离度量学习, 排名数据, 采样算法, 最大似然估计

**Comment:** 

> **TL;DR:** 本文提出了一种广义的马洛斯模型，可以直接从数据中学习距离度量（特别是$L_\alpha$距离），并开发了高效的采样和最大似然估计算法。

**AI_Comments:** 本文的创新之处在于解决了马洛斯模型中距离度量固定不变的局限性，首次提出了从数据中学习距离度量的原则性方法，这对于处理不同上下文的排名数据具有重要意义。所开发的FPTAS采样算法和MLE估计算法具有理论上的强一致性保证，并推广了现有结果，为排名学习领域提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的马洛斯模型主要使用固定的距离度量，但实际中排名数据往往因上下文而异，缺乏直接从数据中学习距离度量的原则性方法。

**Method:** 提出一种广义的马洛斯模型，通过$L_\alpha$距离 $d_\alpha(\pi,\sigma):=\sum_{i=1} |\pi(i)-\sigma(i)|^\alpha$ 直接从数据中学习距离度量。开发了一个针对任意 $\alpha \geq 1$ 和 $\beta > 0$ 的全多项式时间近似方案（FPTAS）用于高效采样。基于此采样算法，提出了一个高效的最大似然估计（MLE）算法，用于联合估计中心排名、离散度参数和最优距离度量。

**Result:** 开发的采样算法能够高效生成接近真实分布的样本，并推广了先前在低离散度（$\beta \to 0$）条件下的结果。证明了所提估计器在任意 $\alpha$ 和 $\beta$ 值下的强一致性。通过体育排名数据集对方法进行了实证验证。

**Conclusion:** 本文成功地推广了马洛斯模型，使其能够从数据中学习距离度量，并提供了理论上一致且在实践中有效的采样和估计方法。

> **ai_Abstract:** 本文提出了马洛斯模型的一个重要推广，允许模型直接从排名数据中学习上下文相关的距离度量，特别是$L_\alpha$距离。为该广义模型开发了一个高效的全多项式时间近似采样方案（FPTAS），以及一个基于此的联合估计中心排名、离散度参数和最优距离度量的最大似然估计（MLE）算法。理论上证明了估计器的强一致性，并通过体育排名数据集验证了方法的有效性。

> **摘要翻译:** 马洛斯模型是一种广泛用于从排名数据中学习的概率框架，其应用范围从推荐系统、投票到将语言模型与人类偏好对齐。在该模型下，观测到的排名是中心排名 $\sigma$ 的噪声扰动，其似然性随与 $\sigma$ 距离的增加呈指数衰减，即 $P (\pi) \propto \exp\big(-\beta \cdot d(\pi, \sigma)\big),$ 其中 $\beta > 0$ 控制离散度，$d$ 是距离函数。
现有方法主要关注固定距离（如Kendall's $\tau$距离），缺乏直接从数据中学习距离度量的原则性方法。然而，在实践中，排名自然会因上下文而异；例如，在某些运动中，我们经常看到长距离交换（低排名队伍击败高排名队伍），而在其他运动中此类事件则很少见。受此启发，我们提出了一种马洛斯模型的推广，可以直接从数据中学习距离度量。具体来说，我们关注 $L_\alpha$ 距离：$d_\alpha(\pi,\sigma):=\sum_{i=1} |\pi(i)-\sigma(i)|^\alpha$。
对于任何 $\alpha\geq 1$ 和 $\beta>0$，我们开发了一种全多项式时间近似方案（FPTAS），可以高效生成与真实分布 $\epsilon$-接近（在总变差距离上）的样本。即使在 $L_1$ 和 $L_2$ 的特殊情况下，这推广了先前需要离散度消失（$\beta\to0$）的结果。利用这种采样算法，我们提出了一种高效的最大似然估计（MLE）算法，可以联合估计中心排名、离散度参数和最优距离度量。我们证明了我们估计器的强一致性结果（对于任何 $\alpha$ 和 $\beta$ 值），并且我们使用体育排名数据集对我们的方法进行了实证验证。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [95] [CLEAR: Calibrated Learning for Epistemic and Aleatoric Risk](https://arxiv.org/abs/2507.08150)
> *CLEAR：校准学习用于认知不确定性和偶然不确定性风险*

*Ilia Azizi, Juraj Bodik, Jakob Heiss, Bin Yu* | **Category: stat.ML, cs.LG, stat.ME** | **Updated: 2025-07-10**

**Keywords:** 不确定性量化, 偶然不确定性, 认知不确定性, 校准, 回归

**Comment:** Code: https://github.com/Unco3892/clear

> **TL;DR:** 提出CLEAR方法，一种结合认知和偶然不确定性的校准方法，显著提升了回归任务中预测区间宽度，同时保持覆盖率。

**AI_Comments:** 本文的创新点在于提出了一个统一的校准框架CLEAR，能够同时且平衡地处理偶然不确定性和认知不确定性，解决了现有方法通常只关注其中一种的局限性。其兼容性强，可与多种现有估计器结合，并通过实验验证了在提升预测区间效率（缩小宽度）方面的显著效果，这对于需要精确不确定性量化的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可靠的预测建模（尤其是在回归任务中）需要准确的不确定性量化。现有方法通常只单独处理偶然不确定性或认知不确定性，而未能以平衡的方式结合两者。

**Method:** 论文提出了CLEAR，一种具有两个独立参数（$\gamma_1$ 和 $\gamma_2$）的校准方法，用于结合偶然不确定性和认知不确定性分量，以改善条件覆盖。CLEAR兼容任何偶然和认知估计器对，例如，它可以与分位数回归（用于偶然不确定性）和来自可预测性-可计算性-稳定性（PCS）框架的集成方法（用于认知不确定性）结合使用。

**Result:** 在17个不同的真实世界数据集上，与两个单独校准的基线相比，CLEAR在保持名义覆盖率的同时，将区间宽度平均改善了28.2%和17.4%。这种改进在以高认知不确定性或高偶然不确定性为主的场景中尤为明显。

**Conclusion:** CLEAR方法通过平衡结合偶然不确定性和认知不确定性，显著提升了回归任务中不确定性量化的准确性和效率，特别是在区间宽度方面，同时保持了预测覆盖率。

> **ai_Abstract:** 本文提出了CLEAR，一种新的校准方法，旨在平衡地结合回归任务中的偶然不确定性（测量噪声）和认知不确定性（数据限制）。通过引入两个独立参数，CLEAR能够兼容多种不确定性估计器，并显著改善了预测区间的宽度，同时保持了理想的覆盖率。实验证明，在17个真实世界数据集上，CLEAR相比单独校准的基线，在区间宽度上取得了显著提升，尤其在高不确定性场景下表现突出。

> **摘要翻译:** 准确的不确定性量化对于可靠的预测建模至关重要，尤其是在回归任务中。现有方法通常只处理来自测量噪声的偶然不确定性或来自有限数据的认知不确定性，但并非以平衡的方式同时处理两者。我们提出了CLEAR，一种具有两个独立参数$\gamma_1$和$\gamma_2$的校准方法，用于结合这两种不确定性分量，以改善条件覆盖。CLEAR兼容任何偶然和认知估计器对；我们展示了它如何与(i)用于偶然不确定性的分位数回归以及(ii)来自可预测性-可计算性-稳定性（PCS）框架的集成方法（用于认知不确定性）结合使用。在17个不同的真实世界数据集上，与两个单独校准的基线相比，CLEAR在保持名义覆盖率的同时，将区间宽度平均改善了28.2%和17.4%。这种改进在以高认知不确定性或高偶然不确定性为主的场景中尤为明显。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [205] [Admissibility of Stein Shrinkage for Batch Normalization in the Presence of Adversarial Attacks](https://arxiv.org/abs/2507.08261)
> *对抗攻击存在下批量归一化中Stein收缩的允许性*

*Sofia Ivolgina, P. Thomas Fletcher, Baba C. Vemuri* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 批量归一化, 对抗攻击, Stein收缩, 均值方差估计, 深度学习

**Comment:** 

> **TL;DR:** 本文证明了在对抗攻击下（当攻击为亚高斯分布时），Stein收缩估计器在批量归一化中对均值和方差的估计优于样本均值和方差，并展示了其在图像分类和分割任务中的最先进性能。

**AI_Comments:** 本文的创新点在于将Stein收缩估计器引入到批量归一化中，以提高其在对抗攻击下的鲁棒性。通过严格的数学证明，作者确立了该方法的理论优势，并在一系列图像处理任务中验证了其有效性。这对于提高深度学习模型在不安全环境下的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 批量归一化在深度神经网络中广泛使用，但其均值和方差的估计容易受到对抗攻击的影响。研究者旨在找到一种更鲁棒的估计方法来提高BN在对抗环境下的性能。

**Method:** 本文证明了在存在对抗攻击时，当使用亚高斯分布建模这些攻击时，Stein收缩估计器在均方误差意义上优于样本均值和方差估计器来估计批量归一化中的均值和方差。随后，将这种Stein校正的批量归一化应用于标准的ResNet、3D CNN和HRNet架构，并在CIFAR-10、PPMI和Cityscape数据集上进行图像分类和分割任务的评估，包括有无对抗攻击的情况。

**Result:** 使用Stein校正的批量归一化在图像分类（CIFAR-10数据上的标准ResNet、PPMI神经影像数据上的3D CNN）和图像分割（Cityscape数据上的HRNet）任务中，无论是否存在对抗攻击，都取得了最先进（SOTA）的性能结果。

**Conclusion:** 本文证明了Stein收缩估计器在存在对抗攻击时对批量归一化中的均值和方差估计具有优势，并验证了其在实际图像分类和分割任务中，在有无对抗攻击的情况下，都能带来性能提升。

> **ai_Abstract:** 本文研究了批量归一化（BN）中均值和方差估计的鲁棒性问题，尤其是在对抗攻击存在的情况下。研究证明，在对抗攻击（建模为亚高斯分布）下，Stein收缩估计器在均方误差意义上优于传统的样本均值和方差估计器。这一发现为将Stein收缩应用于BN参数估计提供了理论依据。实验结果表明，在图像分类和分割任务中，采用Stein校正的BN在有无对抗攻击的情况下均能达到最先进的性能。

> **摘要翻译:** 批量归一化（BN）是深度神经网络中普遍存在的操作，主要用于在网络训练期间实现稳定性和正则化。BN涉及分别使用样本均值和方差对特征图进行中心化和缩放。由于这些统计量是在批次内的特征图上进行估计的，因此这个问题非常适合应用Stein收缩估计，这在均方误差意义上能更好地估计批次的均值和方差。在本文中，我们证明了在存在对抗攻击时，当使用亚高斯分布建模这些攻击时，Stein收缩估计器对于均值和方差的估计优于样本均值和方差估计器。这促进并证明了将Stein收缩应用于估计BN中的均值和方差参数，并将其用于有无对抗攻击的图像分类（分割）任务。我们展示了在标准ResNet架构应用于CIFAR-10数据上的图像分类任务、PPMI（神经影像）数据上的3D CNN以及使用HRNet在Cityscape数据上的图像分割任务中，使用这种Stein校正的批量归一化取得了最先进的性能结果，无论是否存在对抗攻击。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [236] [MIRRAMS: Towards Training Models Robust to Missingness Distribution Shifts](https://arxiv.org/abs/2507.08280)
> *MIRRAMS：迈向训练对缺失分布偏移具有鲁棒性的模型*

*Jihye Lee, Minseo Kang, Dongha Kim* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 缺失分布偏移, 鲁棒性, 互信息, 深度学习, MIRRAMS

**Comment:** 

> **TL;DR:** MIRRAMS是一个深度学习框架，通过引入基于互信息鲁棒性条件和相应的损失项，解决了数据缺失分布偏移问题，提高了模型鲁棒性，并在各种场景下表现出色。

**AI_Comments:** MIRRAMS的创新之处在于其通过互信息正则化来增强模型对缺失分布偏移的鲁棒性，并通过理论分析为一致性正则化半监督学习提供了新的解释。其作为“开箱即用”的通用框架，具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在现实世界数据分析中，训练集和测试集之间的缺失分布偏移频繁发生，严重影响了预测性能的鲁棒性。

**Method:** 本研究提出了一个名为MIRRAMS（Mutual Information Regularization for Robustness Against Missingness Shifts）的新型深度学习框架。该方法引入了一组基于互信息的鲁棒性条件（MI鲁棒性条件），指导预测模型提取与标签相关的信息，同时对不同的缺失模式保持不变性。为了使这些条件实用化，提出了简单有效的技术来推导每个条件对应的损失项，并形成最终的目标函数。

**Result:** 在各种基准数据集上的广泛实验表明，MIRRAMS始终优于现有基线，并在不同的缺失场景中保持稳定的性能。此外，即使在没有缺失数据的情况下，该方法也能实现最先进的性能。

**Conclusion:** MIRRAMS是一个强大、开箱即用的通用学习框架，能够有效应对缺失分布偏移问题，并可自然地扩展到半监督学习任务。

> **ai_Abstract:** 本研究提出了一种名为MIRRAMS的新型深度学习框架，旨在解决训练和测试数据之间缺失分布偏移导致的预测鲁棒性问题。通过引入基于互信息的鲁棒性条件和相应的损失项，MIRRAMS能够使模型提取标签相关信息，同时对不同的缺失模式保持不变。实验结果表明，MIRRAMS在各种缺失场景下均优于现有基线，并能保持稳定性能，即使在无缺失数据时也能达到最先进水平，同时还能自然扩展到半监督学习任务。

> **摘要翻译:** 在现实世界数据分析中，训练和测试输入数据集之间的缺失分布偏移频繁发生，对实现鲁棒的预测性能构成了重大挑战。在这项研究中，我们提出了一个新颖的深度学习框架，旨在解决缺失分布中的此类偏移。我们首先引入了一组基于互信息的条件，称为MI鲁棒性条件，这些条件指导预测模型提取与标签相关的信息，同时对不同的缺失模式保持不变性，从而增强对测试时未见缺失场景的鲁棒性。为了使这些条件实用化，我们提出了简单而有效的技术来推导每个条件对应的损失项，并制定了最终的目标函数，称为MIRRAMS（针对缺失偏移的互信息正则化鲁棒性）。作为副产品，我们的分析为基于一致性正则化的半监督学习方法（如FixMatch）背后的原理提供了理论解释。在各种基准数据集上的广泛实验表明，MIRRAMS始终优于现有基线，并在不同的缺失场景中保持稳定的性能。此外，我们的方法即使在没有缺失数据的情况下也能实现最先进的性能，并且可以自然地扩展到半监督学习任务，这突显了MIRRAMS作为一个强大的、开箱即用的通用学习框架。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [326] [Optimal and Practical Batched Linear Bandit Algorithm](https://arxiv.org/abs/2507.08438)
> *最佳实用批量线性赌博机算法*

*Sanghoon Yu, Min-hwan Oh* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 批量线性赌博机, 臂消除, G-最优设计, 最小最大最优性, 算法

**Comment:** Accepted at ICML 2025

> **TL;DR:** 提出BLAE算法，首次在批量线性赌博机问题中实现理论最优性和实践优越性。

**AI_Comments:** 这篇论文的创新点在于提出了BLAE算法，首次成功地将批量线性赌博机问题的理论最优性（minimax-optimality）与实际应用中的计算效率和优越性能相结合。其引入的批次最优设计和精细集中界限的新技术对该领域具有重要贡献。该算法解决了现有方法在实践中表现不佳的痛点，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有批量线性赌博机算法虽然理论上可以实现接近最优的遗憾，但它们通常计算成本过高或在实践中表现不佳。

**Method:** 提出BLAE算法，该算法结合了臂消除（arm elimination）和正则化G-最优设计（regularized G-optimal design）。

**Result:** BLAE在O(loglog T)批次下，首次在大K和小K两种情况下都达到了最小最大最优遗憾（minimax optimal regret），计算开销低，并在数值评估中优于现有最先进方法。

**Conclusion:** BLAE是第一个在所有情况下都能结合可证明的最小最大最优性与批量线性赌博机实践优越性的算法。

> **ai_Abstract:** 本文针对批量线性赌博机问题中现有算法计算成本高和实际性能不足的挑战，提出了一种名为BLAE的新型算法。BLAE通过结合臂消除和正则化G-最优设计，首次在大小K两种情况下均实现了最小最大最优遗憾，且仅需O(loglog T)批次。该算法不仅具有较低的计算开销，还在实际应用中展现出超越现有先进方法的卓越性能，填补了理论最优性与实践可行性兼备算法的空白。

> **摘要翻译:** 我们研究了受限适应性下的线性赌博机问题，即批量线性赌博机。虽然现有方法在理论上可以实现接近最优的遗憾，但它们通常计算成本过高或在实践中表现不佳。我们提出了一种新颖的批量算法BLAE，它将臂消除与正则化G-最优设计相结合，首次在大K和小K两种情况下都实现了最小最大最优遗憾（至多对数因子T），同时仅使用O(loglog T)批次。我们的分析引入了批次最优设计和精细集中界限的新技术。至关重要的是，BLAE展示了低计算开销和强大的实证性能，在广泛的数值评估中优于最先进的方法。因此，BLAE是第一个在所有情况下都能结合可证明的最小最大最优性与批量线性赌博机实践优越性的算法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [356] [Data Depth as a Risk](https://arxiv.org/abs/2507.08518)
> *数据深度作为风险*

*Arturo Castellanos, Pavlo Mozharovskyi* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 数据深度, 半空间深度, 损失深度, 异常检测, 分类器

**Comment:** 

> **TL;DR:** 本文将半空间深度解释为分类器的最小损失，并引入“损失深度”家族，该家族利用现有机器学习算法的效率和收敛性，适用于高维数据，并有效应用于异常检测。

**AI_Comments:** 这篇论文通过将数据深度与机器学习中的分类器损失概念相结合，提供了一个新颖的视角。这种方法不仅为半空间深度提供了一种新的解释，更重要的是，它将数据深度扩展到了高维环境，并利用了现有机器学习算法的计算优势和理论保证。这种跨领域的融合是其创新之处，有望推动数据深度在高维数据分析和异常检测中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据深度（特别是半空间深度）虽有广泛应用，但本文旨在从一个新的角度（分类器损失）重新理解它，并在此基础上扩展数据深度概念，以利用机器学习的优势解决高维数据问题，并提高可解释性和效率。

**Method:** 作者将半空间深度重新解释为一组分类器在特定点标签下的最小损失。通过改变损失函数或分类器集合，他们提出了一系列新的“损失深度”概念，这些概念可以扩展到支持向量机（SVM）或逻辑回归等成熟的分类器。该框架直接继承了现有机器学习算法的计算效率和快速统计收敛率。

**Result:** 提出了一种新的“损失深度”家族，该家族将数据深度与现有机器学习算法（如SVM、逻辑回归）相结合。这些新的深度度量继承了机器学习算法的计算效率和快速统计收敛率，并能够应用于高维设置。实验表明，它们在异常检测方面高效且易于解释。

**Conclusion:** 半空间深度可以被理解为分类器的最小损失，这一新视角引出了“损失深度”家族，该家族利用机器学习的优势，为数据深度在高维环境中的应用提供了高效且可解释的方法，并在异常检测中表现出色。

> **ai_Abstract:** 本文提出将数据深度（特别是半空间深度）重新定义为分类器的最小损失，并在此基础上引入了“损失深度”家族。这种新方法将数据深度与支持向量机和逻辑回归等成熟的机器学习算法相结合，从而继承了它们的计算效率和快速收敛性，并使数据深度能够应用于高维数据。实验证明，这种新型深度易于解释且在异常检测中表现高效。

> **摘要翻译:** 数据深度是一种评分函数，它以无监督的方式量化一个点在分布中的中心程度，在异常检测、多元或函数数据分析等多个领域有广泛应用。半空间深度是第一个旨在将分位数概念推广到一元情况之外的深度。在现有各种深度定义中，它仍然是最常用的数据深度概念之一。我们从分位数视角之外的另一个角度出发，表明半空间深度也可以被视为一组分类器在特定点标记下的最小损失。通过改变所考虑的损失或分类器集合，这个新角度自然地引出了一个“损失深度”家族，扩展到诸如支持向量机（SVM）或逻辑回归等研究充分的分类器。这个框架直接继承了现有机器学习算法的计算效率以及其快速的统计收敛率，并将数据深度领域扩展到高维设置。此外，新的损失深度强调了数据集与分类器复杂性或简单性的正确程度之间的联系。分类器的简单性以及作为风险的解释使得我们这种新型数据深度易于解释，但对于异常检测而言效率很高，实验证明了这一点。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [452] [Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments](https://arxiv.org/abs/2403.17285)
> *揭示开关实验中遗留效应与奖励自相关之间的相互作用*

*Qianglin Wen, Chengchun Shi, Yang Ying, Niansheng Tang, Hongtu Zhu* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 开关实验,遗留效应,奖励自相关性,A/B测试,强化学习

**Comment:** 

> **TL;DR:** 该研究比较了马尔可夫环境下的各种开关设计，发现设计效果取决于遗留效应的大小和奖励误差的自相关性，并为实践者提供了设计指南。

**AI_Comments:** 这项研究在A/B测试领域具有重要意义，因为它解决了开关实验设计中的关键因素——遗留效应和奖励自相关性，并提供了实用的指导。研究的优势在于其分析的全面性，涵盖了多种估计量，并且结论具有普遍性。未来研究可以进一步探索在更复杂或非马尔可夫环境下的开关设计。

<details>
  <summary>Details</summary>

**Motivation:** A/B测试在技术行业中广泛用于策略评估，特别是开关实验。现有研究主要基于特定且相对简单的估计量来推导最优设计，而本研究旨在进行更全面的比较分析。

**Method:** 对马尔可夫环境下的各种开关设计进行比较分析，涵盖了强化学习（RL）文献中一系列最先进的估计量。

**Result:** 研究结果表明，不同开关设计的有效性关键取决于遗留效应的大小和奖励误差随时间的自相关性。这些发现与估计量无关，适用于大多数RL估计量。

**Conclusion:** 该研究为实践者在A/B测试中设计开关实验提供了一个工作流程和指导方针，强调了遗留效应和奖励自相关性的重要性。

> **ai_Abstract:** 本研究深入探讨了开关实验中遗留效应和奖励自相关性之间的相互作用。通过对马尔可夫环境下的多种开关设计进行全面的比较分析，并纳入了强化学习领域的先进估计量，研究发现遗留效应的大小和奖励误差的自相关性是影响不同开关设计有效性的关键因素。这些发现具有普遍性，不依赖于特定的估计量。基于这些洞察，研究提出了一套工作流程，旨在为A/B测试中的开关实验设计提供实践指导。

> **摘要翻译:** A/B测试已成为现代技术行业中策略评估的黄金标准。受开关实验在A/B测试中广泛使用的启发，本文对马尔可夫环境下的各种开关设计进行了全面的比较分析。与许多推导出基于特定且相对简单的估计量的最优设计的现有工作不同，我们的分析涵盖了强化学习（RL）文献中一系列最先进的估计量。研究表明，不同开关设计的有效性关键取决于（i）遗留效应的大小和（ii）奖励误差随时间的自相关性。与此同时，这些发现与估计量无关，即它们适用于大多数RL估计量。基于这些见解，我们提供了一个工作流程，为实践者在A/B测试中设计开关实验提供指导。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [457] [Local Flow Matching Generative Models](https://arxiv.org/abs/2410.02548)
> *局部流匹配生成模型*

*Chen Xu, Xiuyuan Cheng, Yao Xie* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 局部流匹配, 流匹配, 扩散模型, 生成模型, 变分推断

**Comment:** 

> **TL;DR:** 局部流匹配（LFM）是一种新的生成模型，通过学习一系列局部流匹配子模型来模拟扩散过程，从而提高训练效率和生成性能，并具有理论上的生成保证。

**AI_Comments:** 该研究提出了一种名为局部流匹配（LFM）的新型生成模型，通过将扩散过程分解为一系列更小的、更易于管理的子问题来解决传统流匹配（FM）的挑战。这种方法不仅提高了训练效率，还通过理论分析提供了生成保证。实验结果表明了LFM在各种生成任务中的潜力和优势，尤其是在处理复杂数据分布时。然而，该方法在实际应用中的可扩展性和对不同蒸馏技术的敏感性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统的流匹配（FM）方法在模拟从数据到噪声的连续流时效率不高，尤其是在数据和噪声分布差异较大的情况下。需要一种更有效的方法来学习这种流。

**Method:** 提出了一种名为局部流匹配（LFM）的逐步FM模型。LFM последовательно学习一系列FM子模型，每个子模型都匹配一个扩散过程的一部分。在每一步中，子模型插值的两个分布比原始数据和噪声更接近，这允许使用更小的模型和更快的训练。此外，LFM利用扩散过程的收缩性质，在理论上证明了生成保证。

**Result:** LFM在无条件生成表格数据和图像数据集以及条件生成机器人操作策略方面，在训练效率和生成性能上均优于FM。

**Conclusion:** LFM通过其逐步结构和利用扩散过程的理论特性，提高了生成模型的训练效率和性能，并提供了生成保证，在多种生成任务中表现出竞争力。

> **ai_Abstract:** 局部流匹配（LFM）是一种新的生成模型，它通过学习一系列的局部流匹配子模型来逐步模拟从数据到噪声的扩散过程。与传统的流匹配（FM）相比，LFM在每一步中处理的分布差异更小，因此可以使用更小的模型和更快的训练速度。此外，该模型具有理论上的生成保证，并且在实际应用中，如表格数据、图像生成和机器人策略生成任务中，展现出了更高的训练效率和相当的生成性能。

> **摘要翻译:** 流匹配（FM）是一种无需模拟即可学习连续且可逆的流以在两个分布之间进行插值，特别是从噪声生成数据的方法。受扩散过程作为梯度流的变分性质的启发，我们提出了一种称为局部流匹配（LFM）的逐步FM模型，该模型连续学习一系列FM子模型，每个子模型匹配一个扩散过程直到数据到噪声方向上的步长。在每一步中，子流模型要插值的两个分布比数据与噪声更接近，这使得可以使用更小的模型和更快的训练。这种变分视角也使我们能够利用扩散过程的收缩性质，在生成的和真实的数据分布之间的$\chi^2$-散度方面，理论上证明了所提出的流模型的生成保证。在实践中，LFM的逐步结构自然适合蒸馏，并且可以采用不同的蒸馏技术来加速生成。我们在表格数据和图像数据集的无条件生成以及机器人操作策略的条件生成方面，通过经验证明了与FM相比，LFM提高了训练效率和具有竞争力的生成性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [467] [Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators](https://arxiv.org/abs/2410.12690)
> *局部迁移学习高斯过程建模及其在昂贵计算机模拟器代理建模中的应用*

*Xinming Wang, Simon Mak, John Miller, Jianguo Wu* | **Category: stat.ML, cs.LG, stat.AP, stat.ME** | **Updated: 2025-07-11**

**Keywords:** 局部迁移学习,高斯过程,代理建模,负迁移,计算机模拟

**Comment:** 

> **TL;DR:** 该研究提出了一种新的局部迁移学习高斯过程（LOL-GP）模型，用于解决昂贵计算机模拟的瓶颈问题。该模型通过利用相关系统的现有数据来改进目标系统的代理模型训练，并通过一种潜在正则化模型来识别何时进行信息迁移以避免负迁移。研究通过吉布斯采样算法实现了有效的后验预测采样，并在喷气涡轮设计等应用中证明了LOL-GP相比现有方法的优越性。

**AI_Comments:** 该研究提出的LOL-GP模型在处理昂贵计算机模拟的代理建模问题上具有重要意义，特别是其“局部迁移”机制能够有效避免负迁移，提高了模型性能。然而，其潜在正则化模型的具体实现细节和计算复杂度可能需要进一步探讨。该方法在多源和多保真度迁移设置下的有效性得到了验证，为相关领域的进一步研究提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 科学研究常受限于复杂系统的计算机模拟成本。代理模型通过在模拟评估数据上进行训练来模拟昂贵的模拟器，并量化不确定性。当存在相关系统的可用数据时，一个关键问题是如何将这些信息迁移过来，以有效地训练目标系统的代理模型。

**Method:** 提出了一种新的局部迁移学习高斯过程（LOL-GP）模型，该模型利用精心设计的高斯过程来迁移信息用于代理建模。其关键创新在于引入了一个潜在正则化模型，用于识别应该进行迁移和应该避免迁移的区域，从而实现“局部迁移”。。

**Result:** 通过一系列数值实验和喷气涡轮设计的应用，证明了LOL-GP相比现有方法在代理模型性能上的提升。

**Conclusion:** LOL-GP模型通过其“局部迁移”特性，能够有效利用相关系统的数据来改进目标系统的代理模型，同时避免负迁移带来的性能下降，并在实际应用中展现出优于现有方法的性能。

> **ai_Abstract:** 本研究提出了一种新的局部迁移学习高斯过程（LOL-GP）模型，旨在解决昂贵计算机模拟的瓶颈问题。该模型通过利用相关系统的现有数据来改进目标系统的代理模型训练，并通过一种潜在正则化模型来识别何时进行信息迁移以避免负迁移。研究通过吉布斯采样算法实现了有效的后验预测采样，并在喷气涡轮设计等应用中证明了LOL-GP相比现有方法的优越性。

> **摘要翻译:** 科学进步的一个关键瓶颈是复杂系统的计算机模拟成本高昂。代理模型提供了一个有吸引力的解决方案：此类模型在模拟器评估上进行训练，然后用于在未探索的输入上模拟和量化昂贵模拟器的不确定性。在许多应用中，通常有相关系统的数据可用。例如，在设计新的喷气涡轮机时，可能存在关于具有相似配置的涡轮机的现有研究。一个关键问题是如何将来自此类“源”系统的信息迁移过来，以有效地对感兴趣的“目标”系统进行代理训练。因此，我们提出了一种新的局部迁移学习高斯过程（LOL-GP）模型，该模型利用精心设计的高斯过程迁移此类信息用于代理建模。LOL-GP的关键新颖之处在于一个潜在正则化模型，该模型识别应该进行迁移和应该避免迁移的区域。这种“局部迁移”特性存在于许多科学系统中：在某些参数下，系统可能表现相似，因此迁移是有益的；在其他参数下，它们可能表现不同，因此迁移是有害的。通过考虑局部迁移，LOL-GP可以缓和“负迁移”的风险，即通过信息迁移降低预测性能的风险。我们推导了一个吉布斯采样算法，用于在LOL-GP上进行有效的后验预测采样，涵盖多源和多保真度迁移设置。然后，我们通过一系列数值实验和喷气涡轮设计应用，证明了LOL-GP相比现有方法的代理模型性能有所提高。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [472] [On the Gaussian process limit of Bayesian Additive Regression Trees](https://arxiv.org/abs/2410.20289)
> *关于贝叶斯可加回归树的高斯过程极限*

*Giacomo Petrillo* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 贝叶斯可加回归树,高斯过程,无限树极限,先验协方差函数,GP回归

**Comment:** Check out the software at https://github.com/Gattocrucco/lsqfitgp

> **TL;DR:** 贝叶斯可加回归树（BART）在无限树极限下等同于高斯过程（GP）回归，本文首次推导并计算了精确的BART先验协方差函数，并实现了该极限。虽然在固定配置下不如标准BART，但通过GP的超参数调整，其性能具有竞争力。使用GP作为BART的代理模型简化了模型构建，并避免了复杂的BART MCMC算法，为理解和发展BART和GP回归开辟了新途径。

**AI_Comments:** 这项研究在理论和实践上都具有重要意义。理论上，它首次揭示了BART在高斯过程极限下的精确形式，为理解这两种强大的机器学习模型之间的联系提供了新的视角。实践上，通过将BART实现为GP，作者提供了一种更简单、更高效的模型构建方式，避免了复杂的MCMC采样，这对于实际应用具有重要价值。然而，需要注意的是，在固定配置下，该方法性能不如标准BART，这可能限制了其在某些对性能要求极高的场景下的应用。未来的研究可以进一步探索如何优化GP代理模型以提升其在各种场景下的表现。

<details>
  <summary>Details</summary>

**Motivation:** 贝叶斯可加回归树（BART）在无限树极限下等同于高斯过程（GP）回归，但这一极限尚未得到有效的分析或应用。本文旨在推导和计算精确的BART先验协方差函数，并实现其在高斯过程中的应用。

**Method:** 推导并计算了精确的BART先验协方差函数，并实现了无限树极限下的BART作为GP回归。通过经验测试来评估其性能。

**Result:** 无限树极限下的BART在高斯过程中的表现，在固定配置下不如标准BART，但通过自然GP方式调整超参数后，其性能与BART相当。

**Conclusion:** 使用GP作为BART的代理模型简化了模型构建，并避免了复杂的BART MCMC算法。这项研究为理解和发展BART和GP回归开辟了新的途径。

> **ai_Abstract:** 本文研究了贝叶斯可加回归树（BART）在高斯过程（GP）极限下的行为。作者首次推导并计算了BART的精确先验协方差函数，并实现了该极限。实验结果表明，虽然在固定配置下该方法不如标准BART，但通过GP的超参数调整，其性能可以与BART相媲美。使用GP作为BART的代理模型具有简化模型构建和避免复杂MCMC算法的优点，为BART和GP回归的研究开辟了新的方向。

> **摘要翻译:** 贝叶斯可加回归树（BART）是一种日益流行的非参数贝叶斯回归技术。它是一个决策树之和模型，在某种意义上是增强学习的贝叶斯版本。在无限树的极限下，它等同于高斯过程（GP）回归。这个极限是已知的，但尚未带来任何有效的分析或应用。本文首次推导并计算了精确的BART先验协方差函数。有了它，我实现了BART作为GP回归的无限树极限。通过经验测试，我表明这个极限在固定配置下不如标准的BART，而且通过自然GP的方式调整其超参数，使其与BART具有竞争力。使用GP作为BART的替代模型的好处是其解析似然性，这简化了模型构建并避开了复杂的BART MCMC算法。更广泛地说，这项研究为理解和发展BART和GP回归开辟了新的途径。BART作为GP的实现可在Python包lsqfitgp中获得。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [477] [Conditional regression for the Nonlinear Single-Variable Model](https://arxiv.org/abs/2411.09686)
> *非线性单变量模型的条件回归*

*Yantao Wu, Mauro Maggioni* | **Category: stat.ML, cs.LG, 62G08** | **Updated: 2025-07-11**

**Keywords:** 条件回归, 非线性单指标模型, 维度灾难, 非参数回归, 投影

**Comment:** 57 pages, 10 figures

> **TL;DR:** 本文提出了一种用于非线性单变量模型的条件回归方法，该模型是线性单变量模型的非线性推广。研究表明，该方法在输入维度很高的情况下，可以达到近乎最优的非参数回归速率，并且计算复杂度与维度呈多项式关系。

**AI_Comments:** 该研究成功地将单指标模型推广到非线性情况，并提出了一种能在高维数据中有效规避维度灾难的估计方法。其理论结果具有重要意义，表明在特定条件下，非线性结构也能实现高效估计。计算复杂度分析也使其在实践中具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决非参数回归中的维度灾难问题，本文提出并分析了一个能够推广到非线性结构的单指标模型，并为其开发了估计器。

**Method:** 提出了一种基于条件回归的非参数估计器，用于模型 $F(X) := f(
ému_	ext{gamma} X)$，其中 $
ému_	ext{gamma}$ 是到曲线 $
ému$ 的投影。

**Result:** 所提出的估计器可以达到，在对数因子以内，非参数回归的一维最优最小-最大速率，即使在输入 $X$ 的维度很高的情况下也是如此。计算复杂度为 $\mathcal{O}(d^2 n	extrm{log} n)$，其中常数是 $d$ 的低阶多项式。

**Conclusion:** 在特定假设下，条件回归方法为估计非线性单指标模型中的函数提供了一种有效途径，成功规避了维度灾难。

> **ai_Abstract:** 本文提出了一种用于非线性单变量模型的条件回归方法，该模型是线性单变量模型的非线性推广。研究表明，该方法在输入维度很高的情况下，可以达到近乎最优的非参数回归速率，并且计算复杂度与维度呈多项式关系。

> **摘要翻译:** 在 $\mathbb{R}^d$ 上回归函数 $F$，而不受统计和计算上的维度灾难影响，需要特殊的统计模型，例如那些对数据分布施加几何假设（例如，其支撑是低维的），或对 $F$ 施加强光滑性假设，或具有特殊结构 $F$ 的模型。在后一类模型中，组合模型 $F=f\circ g$，其中 $g$ 映射到 $\mathbb{R}^r$ 且 $r\ll d$，包括经典的单指标和多指标模型，以及神经网络。虽然 $g$ 是线性的情况已得到充分理解，但当 $g$ 是非线性的时，了解较少，特别是对于哪些 $g$ 可以规避估计 $F$ 或 $f$ 和 $g$ 的维度灾难。在这里，我们考虑模型 $F(X):=f(\Pi_\gamma X)$，其中 $\Pi_\gamma:\mathbb{R}^d\to[0,\textrm{len}_\gamma]$ 是到正则曲线 $\gamma:[0, \textrm{len}_\gamma]\to	extrm{mathbb{R}}^d$ 的最近点投影，而 $f:[0,\textrm{len}_\gamma]\to 	extrm{mathbb{R}}^1$。输入数据 $X$ 不是低维的：它可能与 $\gamma$ 的距离尽可能大，只要 $\Pi_\gamma(X)$ 的定义允许。分布 $X$、曲线 $\gamma$ 和函数 $f$ 都是未知的。该模型是单指标模型的自然非线性推广，对应于 $\gamma$ 是一条线。我们提出了一种基于条件回归的非参数估计器，在适当的假设下，其中最强的假设是 $f$ 是粗略单调的，该估计器可以达到，在对数因子以内，一维最优的最小-最大回归速率，达到观测噪声的水平，并且计算时间为 $\mathcal{O}(d^2 n	extrm{log} n$。学习界限、我们的界限成立所需的最小样本数以及计算复杂度中的所有常数最多是 $d$ 的低阶多项式。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [492] [Multiaccuracy and Multicalibration via Proxy Groups](https://arxiv.org/abs/2503.02870)
> *多准确性和多校准通过代理组*

*Beepul Bharti, Mary Versa Clemens-Sewall, Paul H. Yi, Jeremias Sulam* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 多准确性,多校准,代理组,公平性,机器学习

**Comment:** 

> **TL;DR:** 该研究提出了一种使用代理敏感属性来评估和控制缺失敏感组数据情况下的多准确性和多校准的方法，并证明了其有效性。

**AI_Comments:** 该研究解决了在敏感组信息缺失或不完整的情况下，如何评估和控制机器学习模型公平性的重要问题。通过引入代理敏感属性，并证明其在多准确性和多校准方面的有效性，为实际应用提供了可行的方法。然而，代理属性的选择和有效性可能因具体场景而异，这可能是未来研究的一个方向。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，由于缺失或不完整的敏感组信息，衡量和强制执行机器学习算法的公平性具有挑战性。现有方法仅限于基于奇偶校验的公平性概念，而对于多准确性和多校准等更新、更灵活的框架，如何评估和控制公平性仍未被探索。

**Method:** 本研究通过证明在没有敏感组数据的情况下，代理敏感属性可以用于推导真实多准确性和多校准违规行为的可行上限，并调整模型以满足代理敏感属性上的多准确性和多校准，从而减轻真实但未知的敏感组的违规行为。

**Result:** 实验证明，即使在敏感组数据不完整或不可用的情况下，也可以实现近似的多准确性和多校准。

**Conclusion:** 代理敏感属性可以用于在缺失敏感组数据的情况下，推导多准确性和多校准违规行为的可行上限，并能有效减轻这些违规行为，即使在敏感组数据不完整或不可用的情况下也能实现近似的多准确性和多校准。

> **ai_Abstract:** 本研究提出了一种使用代理敏感属性来解决缺失敏感组数据情况下的多准确性和多校准公平性问题的方法。研究证明，代理敏感属性可以用来推导真实多准确性和多校准违规行为的上限，并通过调整模型来减轻这些违规行为。实验结果表明，即使在敏感组数据不完整或不可用的情况下，也能实现近似的多准确性和多校准。

> **摘要翻译:** 随着高风险决策中预测性机器学习算法的使用增加，确保这些算法在敏感群体中公平至关重要。然而，在实际应用中，由于缺失或不完整敏感组信息，衡量和强制执行公平性可能具有挑战性。代理敏感属性已被提出作为这些场景下的实用有效解决方案，但仅限于基于奇偶校验的公平性概念。对于像多准确性和多校准这样更新、更灵活的框架，在缺失敏感组数据的情况下如何评估和控制公平性仍然是未被探索的。本研究解决了这一差距，通过证明在没有敏感组数据的情况下，代理敏感属性可以被证明用于推导真实多准确性和多校准违规行为的可行上限，从而深入了解预测模型潜在的最坏情况公平性违规行为。此外，我们表明，调整模型以满足代理敏感属性上的多准确性和多校准，可以显著减轻真实但未知的敏感组的这些违规行为。通过对真实世界数据集的几项实验，我们说明了即使在敏感组数据不完整或不可用的情况下，也可以实现近似的多准确性和多校准。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [497] [Leveraging priors on distribution functions for multi-arm bandits](https://arxiv.org/abs/2503.04518)
> *利用分布函数的先验知识进行多臂老虎机*

*Sumit Vashishtha, Odalric-Ambrym Maillard* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 多臂老虎机,狄利克雷过程,贝叶斯非参数,汤普森采样,非渐进最优性

**Comment:** Camera ready version -- Reinforcement Learning Journal, 2025

> **TL;DR:** DPPS是一种基于DP先验的贝叶斯非参数多臂老虎机算法，它根据每个臂的最优后验概率进行选择，并能通过贝叶斯引导恢复NPTS算法。DPPS在合成和真实世界环境中表现出色，并通过信息论分析证明了其在贝叶斯遗憾模型下的非渐进最优性。

**AI_Comments:** 该研究提出了一种新颖的贝叶斯非参数多臂老虎机算法DPPS，该算法能够直接利用DP先验对奖励分布进行建模，并在理论和实践上都展现出优越性。其创新之处在于直接对分布函数进行建模，而非参数化模型，并能通过贝叶斯引导恢复NPTS算法。DPPS在合成和真实世界环境中的出色表现以及非渐进最优性的理论保证，使其成为多臂老虎机领域的一个重要贡献。然而，算法的计算复杂度以及在更复杂环境下的泛化能力有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 在多臂老虎机问题中，需要一种能够直接利用先验信念关于奖励分布的算法，而不是依赖于参数化的模型。

**Method:** DPPS算法直接使用狄利克雷过程（DP）先验来建模奖励生成分布，并采用Stick-breaking表示法。该算法根据臂的最优后验概率进行选择，并在无信息先验的极限下恢复了NPTS算法。

**Result:** DPPS在具有挑战性的合成和真实世界的多臂老虎机环境中表现出优异的经验性能，并且通过信息论分析证明了其在贝叶斯遗憾设置下的非渐进最优性。

**Conclusion:** DPPS是一种有效的多臂老虎机算法，它能够灵活地整合先验知识，并在理论和实践上都表现出色。

> **ai_Abstract:** DPPS是一种新的贝叶斯非参数多臂老虎机算法，它使用狄利克雷过程先验直接对奖励分布进行建模，并根据最优后验概率进行选择。该算法能够整合先验信息，并将NPTS作为其特例。实验和理论分析均表明DPPS具有优异的性能和非渐进最优性。

> **摘要翻译:** 我们介绍了一种基于狄利克雷过程（DP）先验的多臂老虎机贝叶斯非参数算法——狄利克雷过程后验采样（DPPS）。与汤普森采样类似，DPPS是一种概率匹配算法，即它根据臂的最优后验概率进行选择。DPPS不假设每个臂的奖励生成分布存在一个参数化类别并在此参数上设置先验，而是直接使用DP先验来建模奖励生成分布。DPPS提供了一种整合关于老虎机环境的先验信念的原则性方法，并且在DP后验的无信息极限下（即贝叶斯引导），我们发现流行的非参数老虎机算法——非参数汤普森采样（NPTS）是DPPS的一个特例。我们采用了DP先验的stick-breaking表示法，并在具有挑战性的合成和真实世界老虎机环境中展示了DPPS优异的经验性能。最后，我们利用信息论分析，在贝叶斯遗憾设置下证明了DPPS的非渐进最优性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [502] [Communities in the Kuramoto Model: Dynamics and Detection via Path Signatures](https://arxiv.org/abs/2503.17546)
> *Kuramoto模型中的社群：动力学与路径签名检测*

*Tâm Johan Nguyên, Darrick Lee, Bernadette Jana Stolz* | **Category: stat.ML, cond-mat.dis-nn, cs.LG, nlin.AO, q-bio.NC, q-bio.QM** | **Updated: 2025-07-11**

**Keywords:** 路径签名,Kuramoto模型,社群检测,高维时间序列,结构推断

**Comment:** 56 pages, 21 figures

> **TL;DR:** 该研究提出了使用路径签名来分析高维时间序列数据，以推断潜在的结构连接，特别是在Kuramoto模型及其随机块模型变体上进行了验证，并成功应用于真实神经数据，实现了对社群结构的精确恢复。

**AI_Comments:** 该研究提出了一种创新的方法，利用路径签名来分析高维时间序列数据，这在神经科学和复杂系统研究领域具有重要意义。方法新颖且理论分析扎实，并在真实数据上进行了验证，但对于路径签名在其他类型复杂网络模型上的泛化能力以及计算复杂度方面，可能还需要进一步的探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有从观测动力学推断结构连接的方法（如基于相关性或谱技术）在高维时间序列中可能无法完全捕捉复杂关系，且不易解释。

**Method:** 提出使用路径签名来编码连续路径的几何和时间属性，以推断系统组件间的结构连接。具体应用在随机块模型图上的Kuramoto模型时间序列，通过均值场理论和高斯近似推导出简化的动力学模型，并理论分析了导前矩阵。基于此开发了一种基于签名的社群检测算法。

**Result:** 基于路径签名的社群检测算法在多个Kuramoto随机块模型实例中实现了对结构社群的精确恢复，并在其随机变体及真实神经数据上进行了验证，证明了其在分析复杂神经数据和其他高维系统中的有效性。

**Conclusion:** 路径签名提供了一种分析复杂神经数据和其他高维系统的新视角，通过显式利用时间功能关系来推断潜在结构。

> **ai_Abstract:** 该研究提出了一种名为路径签名的新型数学框架，用于分析高维时间序列数据中的结构连接。研究人员将此方法应用于Kuramoto模型及其随机块模型变体（KSBM），并通过均值场理论和高斯近似进行了理论分析。他们开发了一种基于路径签名的社群检测算法，并在多个KSBM实例以及真实神经数据上成功实现了对社群结构的精确恢复，证明了该方法在理解复杂系统动力学方面的潜力。

> **摘要翻译:** 多变量动力学过程的行为通常受制于将系统组件联系起来的潜在结构连接。例如，通常通过时间序列测量的脑活动是由潜在的结构图决定的，其中节点代表神经元或大脑区域，边代表皮层连接。现有从观测动力学推断结构连接的方法，如基于相关性或谱技术的方法，可能无法以可解释的方式完全捕捉高维时间序列中的复杂关系。在这里，我们提出使用路径签名，一个编码连续路径的几何和时间属性的数学框架，来解决这个问题。路径签名提供了一种重参数化不变的动力学数据表征，并可用于计算揭示领先滞后现象的导前矩阵。我们在定义在随机块模型图上的耦合振荡器Kuramoto模型的时间序列上展示了我们的方法，该模型称为Kuramoto随机块模型（KSBM）。利用均值场理论和高斯近似，我们在不同的时间尺度下解析推导了KSBM动力学的简化模型，并理论上表征了这些设置下的导前矩阵。利用这些见解，我们提出了一种新颖的基于签名的社群检测算法，在多个KSBM实例中从观测时间序列中精确恢复了结构社群。我们还探讨了我们的社群检测在KSBM的随机变体以及真实皮层记录上的表现，以证明其在真实世界数据上的适用性。我们的结果表明，路径签名提供了一种分析复杂神经数据和其他高维系统的新视角，明确利用时间功能关系来推断潜在结构。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [517] [A Malliavin calculus approach to score functions in diffusion generative models](https://arxiv.org/abs/2507.05550)
> *一种基于Malliavin微积分的扩散生成模型中的得分函数方法*

*Ehsan Mirafzali, Frank Proske, Utkarsh Gupta, Daniele Venturi, Razvan Marinescu* | **Category: stat.ML, cs.LG, math.PR** | **Updated: 2025-07-11**

**Keywords:** 扩散生成模型,得分函数,Malliavin微积分,随机微分方程,闭式表达式

**Comment:** 

> **TL;DR:** 该论文提出了一种使用Malliavin微积分推导扩散生成模型中得分函数的精确闭式表达式的方法，消除了Malliavin导数，提高了实用性，并为改进得分估计方法和开发新的采样算法奠定了理论基础。

**AI_Comments:** 该研究将Malliavin微积分应用于扩散生成模型中的得分函数估计，提出了一种新颖且具有理论意义的方法。通过推导闭式表达式并消除Malliavin导数，提高了方法的实用性。该工作为生成模型领域带来了新的视角和潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 得分函数是扩散生成模型的核心，对复杂数据分布建模至关重要。现有方法如去噪得分匹配、Hyv"arien方法或Schr"odinger桥方法在估计得分函数时存在局限性。

**Method:** 本文结合了现代随机分析工具，如Malliavin导数及其伴随算子（Skorokhod积分或Malliavin散度），以及一种新的Bismut型公式，推导出了一个广泛的非线性扩散生成模型的得分函数的精确闭式表达式。

**Result:** 推导出的得分函数表达式完全可以用一阶和二阶变分过程来表示，并系统地消除了所有的Malliavin导数，从而提高了其在实践中的应用性。

**Conclusion:** 该理论框架为改进生成模型中的得分估计方法提供了原则性基础，能够设计出用于复杂概率分布的新采样算法。该方法可扩展至更广泛的随机微分方程类，为基于得分的扩散生成模型开辟了新的发展方向。

> **ai_Abstract:** 本文提出了一种利用Malliavin微积分和Bismut型公式来推导扩散生成模型得分函数的精确闭式表达式的方法。该方法消除了Malliavin导数，提高了实用性，并为改进得分估计和开发新的采样算法提供了理论基础。

> **摘要翻译:** 得分函数是扩散生成模型的核心，对复杂数据分布建模至关重要。现有方法如去噪得分匹配、Hyv"arien方法或Schr"odinger桥方法在估计得分函数时存在局限性。本文结合了现代随机分析工具，如Malliavin导数及其伴随算子（Skorokhod积分或Malliavin散度），以及一种新的Bismut型公式，推导出了一个广泛的非线性扩散生成模型的得分函数的精确闭式表达式。推导出的得分函数表达式完全可以用一阶和二阶变分过程来表示，并系统地消除了所有的Malliavin导数，从而提高了其在实践中的应用性。该理论框架为改进生成模型中的得分估计方法提供了原则性基础，能够设计出用于复杂概率分布的新采样算法。该方法可扩展至更广泛的随机微分方程类，为基于得分的扩散生成模型开辟了新的发展方向。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [527] [Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting](https://arxiv.org/abs/2507.07469)
> *Galerkin-ARIMA：一种用于快速滚动单步预测的两阶段多项式回归框架*

*Haojie Liu, Zihan Lin* | **Category: stat.ML, cs.LG, econ.EM** | **Updated: 2025-07-11**

**Keywords:** Galerkin-ARIMA,时间序列预测,ARIMA,非线性依赖,计算效率

**Comment:** 

> **TL;DR:** Galerkin-ARIMA是一种将Galerkin投影技术与ARIMA模型相结合的新型时间序列预测框架，通过基于样条的基扩展来捕捉非线性依赖关系，并通过两阶段Galerkin投影推导出闭式解，实现了与ARIMA相当的预测精度和数量级的速度提升。

**AI_Comments:** 该研究提出了一种名为Galerkin-ARIMA的新型时间序列预测框架，通过结合Galerkin投影技术和ARIMA模型，并利用基于样条的基扩展来捕捉潜在的非线性依赖关系。该方法通过两阶段Galerkin投影推导出解析解，并在保持ARIMA模型特性的同时，显著提高了计算效率。研究结果表明，Galerkin-ARIMA在预测精度上能与ARIMA相媲美，但在计算速度上实现了数量级的提升，这使其在需要处理大量数据或实时性的应用场景中具有重要的潜在价值。该方法在处理多种合成时间序列数据时表现良好，验证了其有效性。未来的工作可以进一步探索其在真实世界复杂数据集上的表现以及与其他先进时间序列模型的比较。

<details>
  <summary>Details</summary>

**Motivation:** 为了捕捉时间序列数据中潜在的非线性依赖关系，并提高预测效率。

**Method:** 将Galerkin投影技术与ARIMA模型相结合，用基于样条的基扩展替代固定的线性自回归分量，通过普通最小二乘法逼近历史值之间的关系，并保留ARIMA的移动平均结构和高斯创新假设。通过两阶段Galerkin投影推导出AR和MA分量的闭式解。

**Result:** Galerkin-ARIMA在预测精度上能匹配或近似ARIMA模型，并在滚动预测任务中实现了数量级的加速，尤其是在中等基数维度下，计算成本显著降低。

**Conclusion:** Galerkin-ARIMA为复杂时间序列动力学在高容量或实时应用中提供了一种强大而高效的替代模型。

> **ai_Abstract:** Galerkin-ARIMA是一种创新的时间序列预测框架，它结合了Galerkin投影和ARIMA模型，通过使用基于样条的基扩展来处理非线性依赖关系。该方法通过两阶段Galerkin投影获得AR和MA分量的解析解，并在模拟研究中显示出与ARIMA相当的预测精度，同时计算速度显著提高，特别适用于高容量或实时应用。

> **摘要翻译:** 我们引入了Galerkin-ARIMA，一种新颖的时间序列预测框架，它将Galerkin投影技术与经典的ARIMA模型相结合，以捕捉滞后观测中潜在的非线性依赖关系。通过用基于样条的基扩展替换固定的线性自回归分量，Galerkin-ARIMA通过普通最小二乘法灵活地逼近历史值之间的潜在关系，同时保留ARIMA的移动平均结构和高斯创新假设。我们通过两阶段Galerkin投影推导出AR和MA分量的闭式解，建立了渐进无偏和一致性的条件，并分析了基大小增长下的偏差-方差权衡。复杂度分析表明，对于中等的基数维度，与最大似然ARIMA估计相比，我们的方法可以显著降低计算成本。通过对包括噪声ARMA、季节性、趋势-AR和非线性递归序列在内的四个合成过程进行的广泛模拟，我们证明了Galerkin-ARIMA在滚动预测任务中，在预测精度上能匹配或近似ARIMA，同时实现了数量级的加速。这些结果表明，Galerkin-ARIMA为高容量或实时应用中复杂时间序列动力学的建模提供了一种强大而高效的替代方案。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [59] [Introducing Image-Space Preconditioning in the Variational Formulation of MRI Reconstructions](https://arxiv.org/abs/2507.05312)
> *在MRI重建的变分公式中引入图像空间预处理*

*Bastien Milani, Jean-Baptist Ledoux, Berk Can Acikgoz, Xavier Richard* | **Category: physics.med-ph, eess.SP** | **Updated: 2025-07-11**

**Keywords:** MRI重建, 图像空间预处理, 变分公式, 迭代重建, 深度学习

**Comment:** 48 pages, 7 figures, 3 latex graphics

> **TL;DR:** 本文将迭代MRI重建（包括CS和DL）置于有限维内积空间的通用框架中，提出将图像空间预处理（ISP）和数据空间预处理（DSP）表述为非常规内积，从而在算法无关的方式下将ISP嵌入到MRI重建问题的变分公式中，以系统地应用于缺乏预处理的迭代重建方法。文章还提供了面向MRI重建新手的教学材料。

**AI_Comments:** 本文的创新之处在于将图像空间预处理（ISP）以算法无关的方式嵌入到MRI重建的变分公式中，这为解决现有迭代重建中预处理缺失的问题提供了普适性解决方案。通过将迭代MRI重建置于有限维内积空间框架中，该研究提升了理论严谨性。同时，其为新手提供教学材料的次要目标也体现了对领域知识传播的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 丰富对迭代磁共振成像（MRI）重建的理解，包括压缩感知（CS）和迭代深度学习（DL）重建；将图像空间预处理（ISP）嵌入到MRI重建问题的变分公式中，以解决现有迭代重建方法中预处理的缺失；为MRI重建领域的新手提供教学材料，填补文献中数学工具描述的空白。

**Method:** 通过将迭代MRI重建（包括CS和DL）描述在有限维内积空间的通用框架中，将图像空间预处理（ISP）和数据空间预处理（DSP）公式化为非常规内积。这种重新表述允许ISP以算法无关的方式嵌入到MRI重建问题的变分公式中。文章还应用线性代数工具来处理MRI重建。

**Result:** 主要成果是将图像空间预处理（ISP）以算法无关的方式嵌入到MRI重建问题的变分公式中，这使得ISP原则上可以自然且系统地传播到所有迭代重建中，包括许多缺乏预处理的迭代深度学习（DL）和压缩感知（CS）重建。在MRI重建中应用线性代数工具的方式是新颖的。

**Conclusion:** 本文通过将迭代MRI重建置于有限维内积空间框架中，成功地将图像空间预处理（ISP）嵌入到MRI重建的变分公式中，解决了现有方法中预处理缺失的问题。这种方法具有普适性，能够系统地应用于多种迭代重建算法。此外，文章提供的教学材料对于MRI重建领域的新手具有重要价值，填补了该领域数学概念描述的空白。

> **ai_Abstract:** 本文旨在通过在有限维内积空间的通用框架中描述迭代MRI重建，包括压缩感知和迭代深度学习，来增强对其的理解。研究表明，图像空间预处理（ISP）和数据空间预处理（DSP）可以被表述为非常规内积。这种重新表述的主要优势在于，能够以算法无关的方式将ISP嵌入到MRI重建问题的变分公式中，从而使ISP能够系统地应用于当前缺乏预处理的迭代重建方法。文章还创新性地应用了线性代数工具，并为MRI重建领域的新手提供了详细的数学概念教学材料。

> **摘要翻译:** 本文旨在通过在有限维内积空间的通用框架中描述迭代磁共振成像（MRI）重建，包括压缩感知（CS）和迭代深度学习（DL）重建，从而丰富对其的理解。特别是，我们展示了图像空间预处理（ISP）和数据空间预处理（DSP）可以被表述为非常规内积。我们重新表述的主要收获是将ISP嵌入到MRI重建问题的变分公式中（以与算法无关的方式），这原则上允许ISP自然而系统地传播到所有迭代重建中，包括许多缺乏预处理的迭代DL和CS重建。本文中将线性代数工具应用于MRI重建的方式是新颖的。
本文的次要目的是为MRI重建领域的新手科学家提供一定的教学材料。由于我们在此探讨了一些重建的数学概念，我们借此机会回顾了一些可能对专家来说是显而易见的原则，但对于初学者来说可能很难在文献中找到。事实上，许多MRI重建数学工具的描述在文献中是零散的，或者有时缺失，因为它们被认为是常识。此外，其中一些概念可以在数学手册中找到，但并非以面向MRI的形式。例如，我们想到共轭梯度下降、关于非常规内积的导数概念，或者仅仅是伴随的概念。因此，作者认为为这些教学材料留出一些空间对他们的研究领域是有益的。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [63] [Ultrasound Autofocusing: Common Midpoint Phase Error Optimization via Differentiable Beamforming](https://arxiv.org/abs/2410.03008)
> *超声自动聚焦：通过可微分波束形成优化公共中点相位误差*

*Walter Simson, Louise Zhuang, Benjamin N. Frey, Sergio J. Sanabria, Jeremy J. Dahl, Dongwoon Hyun* | **Category: physics.med-ph, eess.IV** | **Updated: 2025-07-11**

**Keywords:** 超声自动聚焦, 相位畸变, 公共中点相位误差, 可微分波束形成, 声速估计

**Comment:** 

> **TL;DR:** 本研究提出了一种基于可微分波束形成和公共中点相位误差（CMPE）优化的超声自动聚焦新范式，用于校正异质介质引起的相位畸变，以提高图像分辨率和对比度，并同时估计声速场。

**AI_Comments:** 该论文提出了一种创新的超声自动聚焦方法，通过将相位误差优化与可微分波束形成相结合，实现了在异质介质中同时进行图像聚焦改进和声速场估计。其创新之处在于利用CMPE作为稳健的相位畸变测量，并采用无需显式时间步进模型的直射线积分解，简化了计算复杂性。这项工作对于提高医疗超声图像质量和定量分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在超声成像中，声波穿过异质介质会导致相位畸变，从而降低反射波阵面的相干性，导致图像分辨率和对比度下降。适应性成像技术试图纠正这种相位畸变并恢复相干性，以改善图像聚焦。

**Method:** 本文提出了一种超声成像中的像差校正自动聚焦范式，通过优化公共中点相位误差（CMPE），将声速场拟合到压力测量值。该方法使用直射线波传播模型进行弥散散射介质中的波束形成。CMPE通过可微分波束形成方法迭代优化，同时改善图像聚焦并估计被探测介质的声速场。该方法仅依赖于波场测量，利用双向飞行时间的直射线积分解，而无需显式的波传播数值时间步进模型。

**Result:** 研究通过计算机模拟、体外模型测量和体内哺乳动物模型验证了该方法的性能，展示了其在分布式像差量化、校正和速度估计方面的实际应用，用于医疗超声自动聚焦。

**Conclusion:** 研究表明，由异质声速引起的公共中点相位误差（CMPE）是一种稳健的相位畸变测量方法，可用于声学自动聚焦。

> **ai_Abstract:** 本论文提出了一种新的超声自动聚焦方法，旨在通过优化公共中点相位误差（CMPE）来校正异质介质引起的相位畸变。该方法利用可微分波束形成技术，在不使用显式时间步进模型的情况下，通过拟合声速场到压力测量值来迭代地改善图像聚焦并同时估计介质的声速。实验结果表明，该方法在模拟、体外和体内模型中均表现出良好的性能，为医疗超声成像中的像差校正和速度估计提供了实用的解决方案。

> **摘要翻译:** 在超声成像中，声波穿过异质介质会导致相位畸变，从而降低反射波阵面的相干性，导致图像分辨率和对比度下降。适应性成像技术试图纠正这种相位畸变并恢复相干性，以改善图像聚焦。我们提出了一种超声成像中像差校正的自动聚焦范式，通过优化公共中点相位误差（CMPE），将声速场拟合到压力测量值，使用直射线波传播模型在弥散散射介质中进行波束形成。我们表明，由异质声速引起的CMPE是一种稳健的相位畸变测量方法，可用于声学自动聚焦。CMPE通过可微分波束形成方法迭代优化，以同时改善图像聚焦并估计被探测介质的声速场。该方法仅依赖于波场测量，利用双向飞行时间的直射线积分解，而无需显式的波传播数值时间步进模型。我们通过计算机模拟、体外模型测量和体内哺乳动物模型展示了该方法的性能，显示了其在分布式像差量化、校正和速度估计方面的实际应用，用于医疗超声自动聚焦。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [131] [Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation](https://arxiv.org/abs/2507.08189)
> *鲁棒的半监督CT影像组学用于肺癌预后：有限标签下的成本效益学习与SHAP解释*

*Mohammad R. Salmanpour, Amir Hossein Pouria, Sonia Falahati, Shahram Taeb, Somayeh Sadat Mehrnia, Ali Fathi Jouzdani, Mehrdad Oveisi, Ilker Hacihaliloglu, Arman Rahmim* | **Category: physics.med-ph, cs.LG, F.2.2, I.2.7** | **Updated: 2025-07-10**

**Keywords:** 肺癌预后, CT影像组学, 半监督学习, SHAP解释, 成本效益学习

**Comment:** 12 pages, 4 figures

> **TL;DR:** 一种基于CT影像组学的半监督学习框架，利用有限的标注数据显著提高了肺癌预后能力，并提供了SHAP解释，优于监督学习方法。

**AI_Comments:** 该论文通过展示半监督学习在医学影像领域的有效性，特别是对于肺癌预后，做出了重要贡献。将影像组学与SSL和SHAP解释相结合，为医疗AI中标注数据稀缺的常见问题提供了实用的解决方案。在有限标签下报告的性能提升和鲁棒性尤其值得关注，这表明在数据标注成本高昂且耗时的实际临床部署中，这是一个有前景的方向。使用大型多数据集队列也增加了研究结果的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 监督学习模型需要大量的标注数据集，这限制了它们在标注稀缺的真实世界应用中，利用CT影像进行AI辅助肺癌预后的潜力。

**Method:** 分析了来自12个数据集的977名患者的CT扫描，通过PyRadiomics提取了1218个影像组学特征。应用了56种特征选择和提取算法，并对27种分类器进行了基准测试。采用带有伪标签的半监督学习（SSL）框架，使用了478个未标注病例和499个已标注病例。在三种场景下测试了模型敏感性，并使用SHAP分析解释预测结果。进行了交叉验证和外部测试。

**Result:** 半监督学习（SSL）表现优于监督学习（SL），将总生存期预测性能提高了高达17%。最佳SSL模型（随机森林加XGBoost分类器）在交叉验证中达到0.90的准确率，在外部测试中达到0.88的准确率。SHAP分析揭示了SSL和SL中特征可区分性的增强。SSL在仅有10%标注数据的情况下表现出强大的性能，与SL相比结果更稳定，并且在外部测试中方差更低，突出了SSL的鲁棒性和成本效益。

**Conclusion:** 我们引入了一种成本效益高、稳定且可解释的半监督学习框架，用于基于CT的肺癌生存期预测，通过整合SHAP可解释性并利用未标注数据，提高了性能、泛化能力和临床准备度。

> **ai_Abstract:** 本文提出了一种鲁棒的半监督学习（SSL）框架，利用CT影像组学进行肺癌预后，解决了标注数据有限的挑战。通过对977名患者扫描进行伪标签，该SSL方法显著优于传统的监督学习，实现了更高的准确率（交叉验证0.90，外部测试0.88），并将生存期预测性能提高了高达17%。研究表明，SSL在仅有10%标注数据的情况下表现出强大的性能和稳定性，通过SHAP分析增强了可解释性，并展示了其在临床应用中成本效益高和泛化能力强的潜力。

> **摘要翻译:** 背景：CT影像对于肺癌管理至关重要，为基于AI的预后提供了详细的可视化。然而，监督学习（SL）模型需要大量的标注数据集，这限制了它们在标注稀缺的真实世界应用中的使用。
方法：我们分析了来自12个数据集的977名患者的CT扫描，通过PyRadiomics使用高斯拉普拉斯和小波滤波器提取了1218个影像组学特征。应用了56种特征选择和提取算法，并对27种分类器进行了基准测试。一个带有伪标签的半监督学习（SSL）框架使用了478个未标注病例和499个已标注病例。模型敏感性在三种场景中进行了测试：改变SL中已标注数据的比例，增加SSL中未标注数据的比例，以及将两者从10%扩展到100%。SHAP分析用于解释预测结果。进行了交叉验证和两个队列的外部测试。
结果：SSL表现优于SL，将总生存期预测性能提高了17%。最佳SSL模型（随机森林加XGBoost分类器）在交叉验证中达到了0.90的准确率，在外部测试中达到了0.88的准确率。SHAP分析揭示了SSL和SL中特征可区分性的增强，特别是对于生存期大于4年的Class 1。SSL在仅有10%标注数据的情况下表现出强大的性能，与SL相比结果更稳定，并且在外部测试中方差更低，突出了SSL的鲁棒性和成本效益。
结论：我们引入了一种成本效益高、稳定且可解释的SSL框架，用于基于CT的肺癌生存期预测，通过整合SHAP可解释性并利用未标注数据，提高了性能、泛化能力和临床准备度。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [68] [Sharp Phase Transitions in Estimation with Low-Degree Polynomials](https://arxiv.org/abs/2502.14407)
> *低次多项式估计中的尖锐相变*

*Youngtak Sohn, Alexander S. Wein* | **Category: math.ST, cs.CC, cs.DS, math.PR, stat.TH** | **Updated: 2025-07-11**

**Keywords:** 低次多项式, 相变, 估计, 计算硬度, 高维问题

**Comment:** 65 pages, updated references and improved exposition

> **TL;DR:** 本文提出了新的技术来证明低次多项式算法的下界，解决了高维统计问题中估计任务的计算困难性，并捕获了尖锐相变。

**AI_Comments:** 本文的主要创新在于引入了新的技术来推导低次多项式算法的下界，这对于理解高维统计问题中的计算硬度至关重要。其重要性体现在能够处理更复杂的估计任务，捕捉尖锐的相变，并且能够排除更高次多项式的有效性，从而为计算复杂性理论提供了更强的理论依据。此外，解决了多个开放问题并支持了现有猜想，进一步巩固了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 高维隐结构问题（如隐稠密子图）存在统计可行性与计算可行性之间的鸿沟，理解这种计算难度至关重要。现有工作在估计任务上未能达到尖锐阈值或仅限于非常低次的多项式，存在局限性。

**Method:** 引入建立低次多项式算法下界的新技术。

**Result:** 在植入子矩阵、植入稠密子图、尖峰Wigner模型和随机块模型等多种设置下取得了新结果；解决了估计任务而非仅限于假设检验；捕获了尖锐相变，如尖峰Wigner模型中的“BBP”相变和随机块模型中的Kesten-Stigum阈值；排除了维度为$n$的$n^{\delta}$次多项式（$\delta > 0$为常数）的估计，并在某些情况下确定了最优常数$\delta$；解决了Hopkins & Steurer (2017) 和 Schramm & Wein (2022) 提出的开放问题；为Abbe & Sandon (2018) 和 Lelarge & Miolane (2019) 的猜想提供了严格支持。

**Conclusion:** 本文通过引入新技术，在低次多项式算法的下界方面取得了显著进展，成功解决了高维隐结构估计任务中的计算困难性，并精确捕捉了尖锐相变，填补了现有研究的空白。

> **ai_Abstract:** 本文针对高维隐结构问题中统计与计算可行性之间的鸿沟，提出了建立低次多项式算法下界的新技术。研究成果涵盖植入子矩阵、植入稠密子图、尖峰Wigner模型和随机块模型等多种设置，特别关注估计任务而非仅限于假设检验。研究成功捕获了重要的尖锐相变，并排除了使用较高次（$n^{\delta}$次）多项式进行估计的可能性，解决了现有工作的局限性，并为多个开放问题和猜想提供了理论支持。

> **摘要翻译:** 高维植入问题，例如在随机图中寻找隐藏的稠密子图，通常在统计可行性和计算可行性之间存在差距。虽然恢复隐藏结构在统计上是可能的，但在某些参数范围内，它被推测为计算上难以处理。理解这种困难性的一种强大方法是证明低次多项式算法有效性的下界。我们引入了建立此类下界的新技术，从而在不同设置中取得了新颖的结果：植入子矩阵、植入稠密子图、尖峰Wigner模型和随机块模型。值得注意的是，我们的结果解决了估计任务——而大多数先前的工作仅限于假设检验——并捕获了尖锐的相变，例如尖峰Wigner模型中的“BBP”相变（以Baik、Ben Arous和Péchée命名）和随机块模型中的Kesten-Stigum阈值。现有关于估计的工作要么未能达到这些尖锐阈值，要么仅限于非常低（常数或对数）次的多项式。相比之下，我们的结果排除了维度为$n$的$n^{\delta}$次多项式（其中$\delta > 0$为常数）的估计，在某些情况下我们确定了最优常数$\delta$。我们的工作解决了Hopkins & Steurer (2017) 和 Schramm & Wein (2022) 提出的开放问题，并在低次框架内为Abbe & Sandon (2018) 和 Lelarge & Miolane (2019) 的猜想提供了严格支持。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [110] [A Personalised Formal Verification Framework for Monitoring Activities of Daily Living of Older Adults Living Independently in Their Homes](https://arxiv.org/abs/2507.08701)
> *针对独居老年人日常生活活动监测的个性化形式化验证框架*

*Ricardo Contreras, Filip Smola, Nuša Farič, Jiawei Zheng, Jane Hillston, Jacques D. Fleuriot* | **Category: cs.LO, cs.AI, cs.CY** | **Updated: 2025-07-11**

**Keywords:** 独居老年人, 日常生活活动, 形式化验证, 个性化, 模型检查器

**Comment:** 19 pages, 6 figures

> **TL;DR:** 开发了一个个性化的形式化验证框架，用于监测独居老年人的日常生活活动，通过传感器数据和上下文信息构建模型，并使用线性时序逻辑和模型检查器验证其行为，以提升老年人的安全和福祉。

**AI_Comments:** 这项工作在老年人居家照护领域具有创新性，它将形式化验证方法引入到日常生活活动监测中，通过个性化模型和LTL属性提供了严谨的验证机制。生成反例的功能对于快速定位问题原因非常有价值。该框架的通用性展示了其广阔的应用前景，对于提升老年人的生活质量和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着独居老年人口的增长，迫切需要提供高质量的生活。个性化解决方案，关注个体并考虑其偏性、偏好和背景，是满足这一需求的关键。

**Method:** 提出一个框架，用于表示和推理独居老年人的日常生活活动。该框架整合了传感器数据和上下文信息（半结构化访谈、家庭布局、社会学观察），创建了个性化的形式化模型。将个体特定需求编码为线性时序逻辑（LTL）属性，并使用模型检查器验证模型是否满足这些属性。当属性违反时，生成反例以指出原因。

**Result:** 该框架通过应用于不同参与者，展示了其通用性，并突出了其在提升老年人居家养老安全和福祉方面的潜力。当属性被违反时，会生成一个反例来指出违规的原因。

**Conclusion:** 该框架通过个性化的形式化验证方法，能够有效监测独居老年人的日常生活活动，并在行为违反时提供原因，有望显著提升老年人在家中的安全和福祉。

> **ai_Abstract:** 本文提出了一个个性化的形式化验证框架，旨在监测独居老年人的日常生活活动。该框架整合了传感器数据和来自访谈、家庭布局等上下文信息，为每位参与者创建个性化的形式化模型。研究人员将个体需求表述为线性时序逻辑属性，并使用模型检查器进行验证，当出现违规时生成反例。该框架已在不同参与者中验证其通用性，显示出其在提升老年人居家安全和福祉方面的巨大潜力。

> **摘要翻译:** 独居老年人口的增长对提供优质生活提出了迫切需求。关注个体并考虑其偏好和背景的个性化解决方案是关键。在这项工作中，我们引入了一个框架，用于表示和推理独居老年人的日常生活活动。该框架整合了来自传感器的数据和上下文信息，这些信息汇总了参与者的半结构化访谈、家庭布局和社会学观察。我们使用这些数据创建形式化模型，根据每个参与者的偏好和背景进行个性化定制。我们将针对每个个体的特定要求表述为编码在线性时序逻辑中的属性，并使用模型检查器来验证模型是否满足每个属性。当属性被违反时，会生成一个反例，给出违规的原因。我们通过将其应用于不同的参与者来证明该框架的通用性，突出了其在增强居家养老老年人安全和福祉方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [116] [xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models](https://arxiv.org/abs/2507.08432)
> *xpSHACL：使用检索增强生成和大型语言模型的可解释SHACL验证*

*Gustavo Correa Publio, José Emilio Labra Gayo* | **Category: cs.DB, cs.CL** | **Updated: 2025-07-11**

**Keywords:** SHACL, 可解释性, 知识图谱, 检索增强生成, 大型语言模型

**Comment:** Accepted for publication in the 2nd LLM+Graph Workshop, colocated at
  VLDB'25

> **TL;DR:** xpSHACL是一个可解释的SHACL验证系统，它结合规则、RAG和LLM来为非技术用户提供详细、多语言、人类可读的约束违反解释，并通过一个违反知识图谱缓存和重用解释，提高了效率和一致性。

**AI_Comments:** xpSHACL的创新点在于结合了传统规则解释与现代AI技术（RAG和LLMs），弥补了传统SHACL报告可读性差的不足。通过引入Violation KG来缓存和重用解释，不仅提高了效率，也保证了解释的一致性，这对于实际应用非常重要。该系统有望大大降低非技术用户使用和理解知识图谱验证结果的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 传统的SHACL验证引擎提供的报告对非技术用户来说难以理解和操作，尤其是在知识图谱受到业界关注后，更多用户需要正确验证链接数据，因此需要一个能提供可解释结果的系统。

**Method:** xpSHACL通过结合基于规则的解释树、检索增强生成（RAG）和大型语言模型（LLMs）来生成详细、多语言、人类可读的约束违反解释。它还利用一个违反知识图谱（Violation KG）来缓存和重用解释。

**Result:** xpSHACL能够为约束违反提供详细、多语言、人类可读的解释。其使用违反知识图谱缓存和重用解释，提高了效率和一致性。

**Conclusion:** xpSHACL通过结合规则解释树、检索增强生成和大型语言模型等多种技术，有效地解决了传统SHACL验证报告难以理解的问题，为用户提供了可解释的、高效且一致的验证结果。

> **ai_Abstract:** 本文介绍了xpSHACL，一个创新的可解释SHACL验证系统。针对传统验证报告对非技术用户不友好的问题，xpSHACL结合了规则解释树、检索增强生成和大型语言模型，以生成详细、多语言且易于理解的约束违反解释。此外，它利用一个违反知识图谱来缓存和重用解释，显著提升了验证的效率和一致性。

> **摘要翻译:** 形状约束语言（SHACL）是一种用于验证RDF数据的强大语言。鉴于最近业界对知识图谱（KGs）的关注，越来越多的用户需要正确验证链接数据。然而，传统的SHACL验证引擎通常提供简洁的英文报告，这对于非技术用户来说难以解释和操作。本文提出了xpSHACL，一个可解释的SHACL验证系统，它通过结合基于规则的解释树、检索增强生成（RAG）和大型语言模型（LLMs）来解决这个问题，以生成详细的、多语言的、人类可读的约束违反解释。xpSHACL的一个关键特性是它利用违反知识图谱（Violation KG）来缓存和重用解释，从而提高效率和一致性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [130] [ONION: A Multi-Layered Framework for Participatory ER Design](https://arxiv.org/abs/2507.08702)
> *ONION：一个用于参与式ER设计的多层框架*

*Viktoriia Makovska, George Fletcher, Julia Stoyanovich* | **Category: cs.DB, cs.AI, cs.CY** | **Updated: 2025-07-11**

**Keywords:** 参与式ER建模, ONION框架, 设计公正, 参与式AI, 数据建模

**Comment:** 

> **TL;DR:** ONION是一个多层框架，通过五阶段方法支持参与式ER建模，旨在减少偏见、促进包容性，并已在乌克兰的真实案例中展示了在早期数据建模中容纳多样性的潜力。

**AI_Comments:** ONION框架的创新之处在于其将设计公正和参与式AI的理念融入到传统的ER建模中，通过结构化的五阶段方法论，有效地将复杂、非结构化的利益相关者输入转化为结构化数据模型。这对于减少数据建模中的偏见和提高包容性具有重要意义。其在真实世界研讨会中的早期成功验证了其潜力，但论文也坦诚地指出了在扩展和推广方面面临的挑战，这增加了其研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过建模过程减少设计师偏见，促进包容性参与，并提高透明度。

**Method:** 提出了ONION，一个多层框架，用于参与式实体-关系（ER）建模，整合了设计公正、参与式AI和概念建模的见解。它引入了一个五阶段方法论：观察（Observe）、培育（Nurture）、整合（Integrate）、优化（Optimize）、规范化（Normalize），支持从非结构化利益相关者输入到结构化ER图的逐步抽象。

**Result:** 通过在乌克兰以社会技术系统为重点的真实世界研讨会评估了ONION，结果表明多样化的利益相关者参与能够带来更丰富的数据模型和更深入的相互理解。早期结果证明了ONION在早期数据建模中容纳多样性的潜力。

**Conclusion:** 文章总结了经验教训，以及在框架扩展和完善以实现更广泛采用方面存在的局限性和挑战。

> **ai_Abstract:** 本文介绍了ONION，一个整合了设计公正、参与式AI和概念建模的多层框架，用于参与式实体-关系（ER）建模。ONION采用“观察、培育、整合、优化、规范化”的五阶段方法，旨在将非结构化利益相关者输入逐步抽象为结构化ER图，以减少设计师偏见、促进包容性并提高透明度。通过在乌克兰的真实世界研讨会评估，ONION展现了其在早期数据建模中容纳多样性的潜力，促进了更丰富的数据模型和更深入的相互理解。文章最后讨论了其局限性及未来推广的挑战。

> **摘要翻译:** 我们提出了ONION，一个用于参与式实体-关系（ER）建模的多层框架，它整合了设计公正、参与式AI和概念建模的见解。ONION引入了一个五阶段方法论：观察、培育、整合、优化、规范化。它支持从非结构化利益相关者输入到结构化ER图的逐步抽象。我们的方法旨在通过建模过程减少设计师偏见，促进包容性参与，并提高透明度。我们通过在乌克兰以社会技术系统为重点的真实世界研讨会评估了ONION，强调了多样化利益相关者参与如何带来更丰富的数据模型和更深入的相互理解。早期结果证明了ONION在早期数据建模中容纳多样性的潜力。我们总结了经验教训，以及在框架扩展和完善以实现更广泛采用方面存在的局限性和挑战。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [461] [Hashing for Fast Pattern Set Selection](https://arxiv.org/abs/2507.08745)
> *用于快速模式集选择的哈希*

*Maiju Karjalainen, Pauli Miettinen* | **Category: cs.DB, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 模式集挖掘,哈希,重构误差,底k哈希,近似匹配

**Comment:** 17 pages, 5 figures, to appear at ECML-PKDD 2025

> **TL;DR:** 该论文提出了一种基于底k哈希的方法来高效地选择模式集，以最小化重构误差，并能处理近似匹配的模式，在多个应用领域显示出比标准贪婪算法更快的速度和相当的结果。

**AI_Comments:** 该研究提出了一种新颖的基于哈希的方法来解决模式集挖掘问题，特别是在效率和处理近似模式方面取得了显著进展。其在多个应用领域的有效性得到了验证，为该领域的研究提供了有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 模式集挖掘是数据挖掘中的一个基本问题，目标是找到一组好的模式而非所有模式。现有的方法需要更高效地解决这个问题。

**Method:** 提出了一种基于底k哈希的方法来高效选择模式集，并将其扩展到处理近似模式匹配的情况。

**Result:** 所提出的基于哈希的方法在合成和真实世界的数据集上，比标准的贪婪算法显著更快，并且结果相当。

**Conclusion:** 基于底k哈希的方法是一种有效且高效的模式集选择技术，能够处理近似模式，并在实际应用中优于现有方法。

> **ai_Abstract:** 本研究提出了一种基于底k哈希的方法，用于高效地选择模式集以最小化重构误差。该方法能够处理近似模式匹配，并在平铺数据库、布尔矩阵分解和重新描述挖掘等领域具有应用潜力。实验结果表明，该方法比标准贪婪算法更快，且结果相当。

> **摘要翻译:** 模式集挖掘，即寻找一组好的模式而不是所有模式的任务，是数据挖掘中的一个基本问题。近年来，人们提出了许多关于什么是好的集合的不同定义。在本文中，我们考虑将重构误差作为衡量集合好坏的代理度量，并着重于如何有效地找到一个好的集合的相邻问题。我们提出了一种基于底k哈希的方法来有效地选择集合，并将其扩展到模式可能仅以近似形式出现在数据中的常见情况。我们的方法在平铺数据库、布尔矩阵分解和重新描述挖掘等领域都有应用。我们证明了我们的基于哈希的方法在速度上明显优于标准的贪婪算法，同时在合成和真实世界的数据集上都获得了几乎同样好的结果。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='q-finrm'></a>
## q-fin.RM 

### [151] [Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors](https://arxiv.org/abs/2507.08193)
> *使用保险科技赋能风险因素的实体特定网络风险评估*

*Jiayi Guo, Zhiyun Quan, Linfeng Zhang* | **Category: q-fin.RM, cs.LG, stat.ML** | **Updated: 2025-07-10**

**Keywords:** 网络风险评估, 保险科技, 机器学习, 实体特定, 风险因素

**Comment:** 

> **TL;DR:** 本文提出一个新颖的保险科技（InsurTech）框架，通过整合实体特定属性来丰富网络事件数据，并利用机器学习模型进行网络风险评估，结果表明该框架能增强预测能力并生成透明的实体特定风险概况。

**AI_Comments:** 本文的创新点在于将保险科技（InsurTech）与机器学习结合，通过引入实体特定属性来弥补现有网络风险数据不足和缺乏精细化特征的缺陷。其提出的框架能够生成透明、实体特定的风险概况，对于提升网络保险的承保精度和企业的主动风险管理具有重要意义。该研究为解决网络风险评估中的数据稀疏性问题提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 由于高质量公开网络事件数据的缺乏，以及公司不愿披露事件，限制了网络风险评估的实证研究和预测建模。现有数据驱动方法也缺乏实体特定的组织特征。

**Method:** 本文提出了一个新颖的保险科技（InsurTech）框架，通过实体特定属性丰富网络事件数据。开发了多标签分类模型预测网络事件类型（如隐私泄露、数据泄露等）和多输出回归模型估计年度频率。应用可解释机器学习技术识别和交叉验证保险科技开发的风险因素。

**Result:** 研究发现，与仅使用传统风险因素相比，保险科技赋能的特征增强了预测发生率和频率估计的鲁棒性。在数据集中未观察到网络事件类型之间存在显著关联。

**Conclusion:** 该框架生成透明的、实体特定的网络风险概况，支持定制化承保和主动网络风险缓解。它为保险公司和组织提供了数据驱动的洞察，以支持决策制定和合规规划。

> **ai_Abstract:** 本文针对网络风险评估中高质量公共数据和实体特定特征的缺失问题，提出了一种新颖的保险科技（InsurTech）框架。该框架通过整合实体特定属性来丰富网络事件数据，并利用多标签分类和多输出回归机器学习模型预测网络事件类型及频率。研究表明，保险科技赋能的风险因素显著提升了预测准确性和鲁棒性，从而能够生成透明的、实体特定的网络风险概况，为保险承保和风险缓解提供数据驱动的洞察和决策支持。

> **摘要翻译:** 高质量公共网络事件数据的缺乏限制了网络风险评估的实证研究和预测建模。由于公司不愿披露可能损害其声誉或投资者信心的事件，这一挑战持续存在。因此，从精算角度来看，潜在的解决方案包括两个方面：增强现有网络事件数据集和实施先进的建模技术以优化可用数据的使用。对现有数据驱动方法的审查突出表明，公开数据集中严重缺乏实体特定的组织特征。为了弥补这一空白，我们提出了一个新颖的保险科技（InsurTech）框架，该框架通过实体特定属性丰富网络事件数据。我们开发了各种机器学习（ML）模型：一个多标签分类模型，用于预测网络事件类型（例如，隐私侵犯、数据泄露、欺诈和勒索、IT错误以及其他）的发生，以及一个多输出回归模型，用于估计其年度频率。虽然也实施了分类器和回归器链来探索网络事件类型之间的依赖关系，但在我们的数据集中没有观察到显著的相关性。此外，我们应用多种可解释的机器学习技术来识别和跨机器学习模型交叉验证由保险科技开发的潜在风险因素。我们发现，与仅使用传统风险因素相比，保险科技赋能的特征增强了预测发生率和频率估计的鲁棒性。该框架生成透明的、实体特定的网络风险概况，支持定制化承保和主动网络风险缓解。它为保险公司和组织提供了数据驱动的洞察，以支持决策制定和合规规划。

</details>

[⬆️ 返回分类顶部](#q-finrm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [180] [The role of gain neuromodulation in layer-5 pyramidal neurons](https://arxiv.org/abs/2507.03222)
> *增益神经调控在第五层锥体神经元中的作用*

*Alejandro Rodriguez-Garcia, Christopher J. Whyte, Brandon R. Munn, Jie Mei, James M. Shine, Srikanth Ramaswamy* | **Category: q-bio.NC, cs.AI, 68T05** | **Updated: 2025-07-11**

**Keywords:** 神经调控, 增益, 第五层锥体神经元, 可塑性-稳定性困境, STDP

**Comment:** 12 pages, 7 figures, 1 table, presented at 34th Annual Computational
  Neuroscience Meeting

> **TL;DR:** 该论文通过计算模型研究了神经调节剂如何调节第五层锥体神经元的增益，以平衡可塑性和稳定性。

**AI_Comments:** 该论文提供了一个计算模型，优雅地解释了神经调节剂如何在第五层锥体神经元中动态调整神经元增益，为平衡可塑性和稳定性提供了一个合理的机制。爆发加速STDP的发现尤其有见地，它将细胞放电模式直接与突触学习规则联系起来。该模型对于理解灵活认知和设计更稳健的人工学习系统具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 生物和人工学习系统都面临可塑性-稳定性困境。神经调节剂（如乙酰胆碱和去甲肾上腺素）通过调节神经元增益和抑制性门控来缓解这种困境。第五层锥体神经元是理解这些动态变化的重要基质。本研究的动机是理解神经调节信号如何通过这些增益可调的放大器转化为灵活的皮层活动。

**Method:** 开发了一个双室Izhikevich锥体神经元模型和单室生长抑素（SOM）与小白蛋白（PV）中间神经元模型。这些模型通过高斯连接和尖峰时间依赖可塑性（STDP）连接。躯体和顶端树突耦合，以模拟逆向传播的尖峰和树突平台对躯体放电模式的影响。

**Result:** 研究表明，更强的树突驱动或更紧密的耦合通过增加钙触发躯体爆发的可能性来提高增益。相反，树突靶向抑制会抑制增益，而躯体靶向抑制会提高相邻神经元的放电阈值，从而门控神经元输出。值得注意的是，爆发会加速尖峰时间依赖可塑性（STDP），支持快速突触重构和灵活性。

**Conclusion:** 神经调节剂驱动的短暂增益脉冲可以作为一种自适应的双时间尺度优化机制，有效地调节突触权重更新。

> **ai_Abstract:** 本文研究了神经调节剂如何通过调节第五层锥体神经元的增益来解决大脑中的可塑性-稳定性困境。利用一个双室Izhikevich模型，研究表明树突驱动和耦合会增加增益，而不同类型的抑制则会调节增益。关键在于，爆发会加速尖峰时间依赖可塑性（STDP），这表明神经调节剂驱动的增益脉冲可作为突触权重更新的自适应机制，从而促进灵活的皮层活动。

> **摘要翻译:** 生物和人工学习系统都面临着可塑性-稳定性困境。在大脑中，乙酰胆碱和去甲肾上腺素等神经调节剂通过调节神经元增益和抑制性门控来缓解这种紧张，平衡电路的分离和整合。大脑皮层第五层锥体神经元由来自上行唤醒系统的密集胆碱能和去甲肾上腺素能投射滋养，为理解这些动态提供了相关基础。当远端树突信号与逆向传播的动作电位同时发生时，钙平台将单个躯体尖峰转化为高增益爆发，而中间神经元抑制则塑造输出。这些特性使第五层细胞成为增益可调的放大器，将神经调节信号转化为灵活的皮层活动。为了捕捉这种机制，我们开发了一个双室Izhikevich锥体神经元模型和单室生长抑素（SOM）和小白蛋白（PV）中间神经元模型，通过高斯连接和尖峰时间依赖可塑性（STDP）连接。躯体和顶端树突如此耦合，以至于躯体尖峰逆向传播，而树突平台可以通过改变重置和适应变量将躯体从规律放电切换到爆发。我们表明，更强的树突驱动或更紧密的耦合通过增加钙触发躯体爆发的可能性来提高增益。相反，树突靶向抑制会抑制增益，而躯体靶向抑制会提高相邻神经元的放电阈值，从而门控神经元输出。值得注意的是，爆发加速了STDP，支持快速突触重构和灵活性。这表明由神经调节剂驱动的短暂增益脉冲可以作为一种自适应的双时间尺度优化机制，有效地调节突触权重更新。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [296] [SPINT: Spatial Permutation-Invariant Neural Transformer for Consistent Intracortical Motor Decoding](https://arxiv.org/abs/2507.08402)
> *SPINT：用于稳定皮层内运动解码的空间置换不变神经网络变换器*

*Trung Le, Hao Fang, Jingyuan Li, Tung Nguyen, Lu Mi, Amy Orsborn, Uygar Sümbül, Eli Shlizerman* | **Category: q-bio.NC, cs.LG** | **Updated: 2025-07-11**

**Keywords:** iBCI, 神经解码, 非平稳性, 变换器, 置换不变

**Comment:** 

> **TL;DR:** SPINT是一种新的神经网络变换器框架，用于脑机接口（iBCI）中的运动解码，它通过处理无序的神经单元集合和使用上下文依赖的位置嵌入来解决神经记录的非平稳性问题，表现出强大的跨会话泛化能力。

**AI_Comments:** 这项工作的创新之处在于将神经单元视为无序集合，并使用动态位置嵌入来处理非平稳性，而无需显式对齐或固定的神经身份。这是迈向实用化长期iBCI的重要一步，有望显著简化部署和提高性能。

<details>
  <summary>Details</summary>

**Motivation:** 长期皮层内脑机接口（iBCI）面临神经记录非平稳性的挑战，即记录到的神经群体组成和调谐曲线在不同记录会话中不稳定。现有方法依赖于显式对齐技术、固定的神经身份，并且需要测试时标签或参数更新，这限制了它们在会话间的泛化能力并增加了部署时的计算负担。

**Method:** 本文引入了SPINT——一种空间置换不变神经网络变换器框架，用于行为解码，它直接操作无序的神经单元集合。其核心是一种新颖的上下文依赖的位置嵌入方案，可以动态推断单元特定的身份，从而实现跨记录会话的灵活泛化。SPINT支持对可变大小群体的推理，并允许使用测试会话中少量未标记数据进行少样本、无梯度适应。为了进一步提高模型对群体变异性的鲁棒性，引入了动态通道丢弃，这是一种用于iBCI的正则化方法，模拟训练期间群体组成的偏移。

**Result:** 在FALCON Benchmark的三个多会话数据集上对SPINT进行了评估，这些数据集涵盖了人类和非人灵长类动物的连续运动解码任务。SPINT展示了强大的跨会话泛化能力，优于现有的零样本和少样本无监督基线方法，同时消除了测试时对齐和微调的需求。

**Conclusion:** 我们的工作为长期iBCI应用中的稳健且可扩展的神经解码框架迈出了初步一步。

> **ai_Abstract:** 本文提出了SPINT，一种空间置换不变神经网络变换器，旨在解决长期皮层内脑机接口（iBCI）中神经记录的非平稳性问题。SPINT框架直接处理无序的神经单元集合，利用新颖的上下文依赖位置嵌入动态推断单元身份，并引入动态通道丢弃进行正则化。在FALCON Benchmark数据集上的评估表明，SPINT在连续运动解码任务中实现了强大的跨会话泛化，性能优于现有基线方法，且无需测试时对齐或微调。

> **摘要翻译:** 皮层内脑机接口（iBCI）旨在从神经群体活动中解码行为，使运动障碍个体能够恢复运动功能和沟通能力。长期iBCI的一个关键挑战是神经记录的非平稳性，其中记录群体的组成和调谐曲线在不同记录会话中不稳定。现有方法试图通过显式对齐技术解决此问题；然而，它们依赖于固定的神经身份，并需要测试时标签或参数更新，这限制了它们在会话间的泛化能力，并增加了部署期间的计算负担。在这项工作中，我们引入了SPINT——一种用于行为解码的空间置换不变神经网络变换器框架，它直接操作无序的神经单元集合。我们方法的核心是一种新颖的上下文依赖的位置嵌入方案，可以动态推断单元特定的身份，从而实现跨记录会话的灵活泛化。SPINT支持对可变大小群体的推理，并允许使用测试会话中少量未标记数据进行少样本、无梯度适应。为了进一步提高模型对群体变异性的鲁棒性，我们引入了动态通道丢弃，这是一种用于iBCI的正则化方法，模拟训练期间群体组成的偏移。我们在FALCON Benchmark的三个多会话数据集上评估了SPINT，这些数据集涵盖了人类和非人灵长类动物的连续运动解码任务。SPINT展示了强大的跨会话泛化能力，优于现有的零样本和少样本无监督基线方法，同时消除了测试时对齐和微调的需求。我们的工作为长期iBCI应用中的稳健且可扩展的神经解码框架迈出了初步一步。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='csms'></a>
## cs.MS 

### [197] [FEniCSx-pctools: Tools for PETSc block linear algebra preconditioning in FEniCSx](https://arxiv.org/abs/2402.02523)
> *FEniCSx-pctools：FEniCSx 中用于 PETSc 块线性代数预处理的工具*

*Martin Řehoř, Jack S. Hale* | **Category: cs.MS, cs.NA, math.NA, 65N22, 65F08, 65F10** | **Updated: 2025-07-10**

**Keywords:** 有限元方法, 预处理, PETSc, FEniCSx, 并行计算

**Comment:** 11 pages, 7 figures, 1 table

> **TL;DR:** FEniCSx-pctools 简化了在 FEniCSx 中使用 PETSc 进行块预处理，适用于大规模有限元问题。

**AI_Comments:** 该工具通过自动化元数据附加，显著简化了在 FEniCSx 环境中应用 PETSc 块预处理策略的复杂性，对于高效求解大规模、多场耦合的偏微分方程系统具有重要意义。其并行扩展性展示了其在大规模科学计算中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决使用有限元方法产生的具有多场变量自然块结构的大型线性方程组时，需要高效且可扩展的预处理策略来提高求解效率和可伸缩性。

**Method:** FEniCSx-pctools 是一个软件工具包，它简化了在 FEniCS 项目的 DOLFINx 有限元求解器组装的线性系统上指定 PETSc 块预处理策略的过程。该软件包会自动附加所有必要的元数据，以便可以通过 PETSc 标准的基于选项的配置系统应用预处理策略。

**Result:** 文档化的示例包括一个简单的混合泊松系统和更复杂的 Navier-Stokes 方程的压力对流-扩散预处理方法。在完全耦合的温度-Navier-Stokes 系统上，展示了高达 8192 个 MPI 进程的弱并行扩展性，证明了该方法适用于大规模问题。

**Conclusion:** FEniCSx-pctools 及其提供的预处理方法能够有效地应用于解决大规模偏微分方程系统。

> **ai_Abstract:** 解决有限元方法产生的大型、块结构线性系统需要高效的预处理。FEniCSx-pctools 是一个软件工具，旨在简化在 FEniCSx 中使用 PETSc 应用块预处理策略。它通过自动化元数据附加来促进基于 PETSc 选项的配置。该工具已在各种系统（包括 Navier-Stokes 方程）上进行了演示，并显示出在高达 8192 个 MPI 进程上的良好并行扩展性，表明其适用于大规模科学计算问题。

> **摘要翻译:** 通过有限元方法求解偏微分方程会产生必须求解的大型线性方程组。当这些系统由于多个场变量而具有自然的块结构时，使用迭代求解器和精心设计的预处理策略（利用底层的物理结构）对于高效且可扩展的求解过程变得必要。FEniCSx 预处理工具（FEniCSx-pctools）是一个软件包，它简化了在 FEniCS 项目的 DOLFINx 有限元求解器组装的线性系统上指定 PETSc（可移植、可扩展的科学计算工具包）块预处理策略。该软件包会自动附加所有必要的元数据，以便可以通过 PETSc 的标准基于选项的配置系统应用预处理策略。文档化的示例包括一个简单的混合泊松系统和更复杂的 Navier-Stokes 方程的压力对流-扩散预处理方法。我们展示了在高达 8192 个 MPI（消息传递接口）进程上，完全耦合的温度-Navier-Stokes 系统的弱并行扩展性，证明了该方法适用于大规模问题。

</details>

[⬆️ 返回分类顶部](#csms) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [204] [Conditional Probability formula as a consequence of the Insufficient Reason Principle](https://arxiv.org/abs/2507.08040)
> *条件概率公式作为不充分理由原则的一个推论*

*Alexander Dukhovny* | **Category: math.PR, cs.IT, math.IT, primary 60** | **Updated: 2025-07-09**

**Keywords:** 条件概率, 不充分理由原则, 最大相对散度, 概率论

**Comment:** 

> **TL;DR:** 本文从不充分理由原则，特别是最大相对散度原则，推导出了标准条件概率公式。

**AI_Comments:** 本文的创新之处在于为标准条件概率公式提供了一个新的理论基础，通过最大相对散度原则将其与不充分理由原则联系起来，加深了对概率论基本概念的理解。

<details>
  <summary>Details</summary>

**Motivation:** 旨在证明标准条件概率公式是不充分理由原则的一个推论。

**Method:** 通过将不充分理由原则表达为在全序集上对分级（顺序同单调）函数的最大相对散度原则，从而推导出标准条件概率定义公式。

**Result:** 标准条件概率定义公式被成功推导出来。

**Conclusion:** 标准条件概率公式是不充分理由原则的一个推论。

> **ai_Abstract:** 本文研究如何从不充分理由原则推导出标准条件概率公式。研究方法是将被表达为在全序集上对分级（顺序同单调）函数的最大相对散度原则作为不充分理由原则的一种形式，并在此基础上成功推导出标准的条件概率定义公式。

> **摘要翻译:** 标准条件概率定义公式是作为不充分理由原则的一个推论而推导出来的，该原则被表达为在全序集上对分级（顺序同单调）函数的最大相对散度原则。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [227] [State Estimation Using Sparse DEIM and Recurrent Neural Networks](https://arxiv.org/abs/2410.15982)
> *稀疏DEIM和循环神经网络的状态估计*

*Mohammad Farazmand* | **Category: math.DS, cs.LG, cs.NA, math.NA, nlin.CD** | **Updated: 2025-07-10**

**Keywords:** 状态估计, 稀疏DEIM, 循环神经网络, 无方程, 数据同化

**Comment:** 

> **TL;DR:** 本文提出一种基于循环神经网络的无方程稀疏DEIM框架，用于在仅有稀疏观测时，无需已知动力学方程即可进行系统状态估计，解决了现有方法的局限性。

**AI_Comments:** 这篇论文创新性地将循环神经网络引入到稀疏离散经验插值法中，解决了传统方法对系统方程先验知识的依赖以及收敛性问题。通过引入无方程框架，极大地拓展了S-DEIM的应用范围，特别是在动力学方程未知或难以获取的复杂系统中。其重要性在于提供了一种有效且鲁棒的状态估计新范式，有望在气象、流体力学等领域发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的稀疏离散经验插值法（S-DEIM）在进行动力学系统状态估计时，存在两个主要缺点：(i) 需要已知动力学系统的控制方程；(ii) 其数据同化步骤不保证收敛到最优核向量。

**Method:** 本文引入了一种无方程的S-DEIM框架，该框架利用循环神经网络（RNNs）从稀疏观测时间序列中估计最优核向量。研究表明，循环架构是必要的，因为核向量无法从瞬时观测中估计，而RNNs能够整合观测的历史信息以实现近乎最优的估计。

**Result:** 该方法在三个具有不同时空复杂度的数值示例上进行了验证：Lorenz-96系统、Kuramoto-Sivashinsky方程和Rayleigh-Benard对流。在所有情况下，即使使用相对简单的RNN架构（如储备池计算网络），S-DEIM的估计结果也令人满意。

**Conclusion:** 本文提出的基于循环神经网络的无方程S-DEIM框架能够有效且满意地从稀疏观测中估计动力学系统状态，克服了传统S-DEIM对系统方程的依赖和收敛性不确定的问题。

> **ai_Abstract:** 本文提出了一种新颖的无方程稀疏离散经验插值法（S-DEIM）框架，利用循环神经网络（RNNs）从稀疏观测时间序列中估计最优核向量，从而实现动力学系统状态估计。该方法解决了传统S-DEIM需要已知系统方程且收敛性不确定的问题。通过在Lorenz-96系统、Kuramoto-Sivashinsky方程和Rayleigh-Benard对流等复杂系统上的数值验证，证明了其有效性，即使使用简单的RNN架构也能获得满意的估计结果。

> **摘要翻译:** 稀疏离散经验插值法（S-DEIM）最近被提出用于当只能观测到状态变量的稀疏子集时的动力学系统状态估计。S-DEIM估计涉及一个核向量，其最优值通过数据同化算法推断。这个数据同化步骤存在两个缺点：(i) 它需要了解动力学系统的控制方程，以及 (ii) 它通常不保证收敛到最优核向量。为了解决这些问题，本文引入了一种无方程的S-DEIM框架，该框架使用循环神经网络（RNNs）从稀疏观测时间序列中估计最优核向量。我们表明循环架构是必要的，因为核向量不能从瞬时观测中估计。但是，RNNs将观测的过去历史纳入学习过程，从而实现近乎最优的估计。我们在三个时空复杂度逐渐增加的数值示例上演示了我们方法的有效性：一个被称为Lorenz-96系统的大气流动概念模型、Kuramoto-Sivashinsky方程和Rayleigh-Benard对流。在每种情况下，即使使用相对简单的RNN架构，即储备池计算网络，所得的S-DEIM估计也令人满意。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

### [482] [Data-driven system identification using quadratic embeddings of nonlinear dynamics](https://arxiv.org/abs/2501.08202)
> *基于二次嵌入的非线性动力学数据驱动系统辨识*

*Stefan Klus, Joel-Pascal Ntwali N'konzi* | **Category: math.DS, cs.LG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** QENDy, 非线性动力学, 系统辨识, 二次嵌入, 数据驱动

**Comment:** 

> **TL;DR:** QENDy是一种新的数据驱动方法，可以学习非线性动力学的二次表示并识别其控制方程，通过将系统嵌入到二次动力学的高维特征空间来实现。

**AI_Comments:** 这项工作引入了一种名为 QENDy 的新颖方法，用于从数据中学习非线性动力学的二次表示和控制方程。通过将系统嵌入到高维特征空间，QENDy 能够将复杂的非线性动力学转化为二次形式，从而便于分析和识别。该方法与 SINDy 等现有技术进行了比较，并在各种基准问题上进行了验证，证明了其有效性和准确性。此外，对 QENDy 和 SINDy 在无限数据极限下的收敛性分析，以及与 Koopman 算子线性化技术的比较，为理解这些方法的理论基础和实际应用提供了有价值的见解。该研究的创新之处在于其处理高度非线性系统能力以及提供可解释的二次模型。然而，对于大规模或高维系统，计算复杂性可能是一个挑战。

<details>
  <summary>Details</summary>

**Motivation:** 学习非线性动力学的二次表示并识别其控制方程。

**Method:** QENDy方法将系统嵌入到高维特征空间，使动力学变为二次。该方法需要轨迹数据、训练数据点的 T 导数和一组预选的基函数（字典）。

**Result:** QENDy 在各种基准问题上展示了其有效性和准确性，并与 SINDy 和深度学习方法进行了比较。

**Conclusion:** QENDy 是一种用于识别非线性动力学二次表示和控制方程的新颖数据驱动方法。

> **ai_Abstract:** QENDy 是一种新颖的数据驱动方法，用于学习非线性动力学的二次表示并识别其控制方程。它通过将系统嵌入到高维特征空间来实现这一点，在该空间中动力学变为二次。该方法需要轨迹数据、时间导数和基函数字典。与 SINDy 和深度学习方法相比，QENDy 在基准问题上显示出有效性和准确性。此外，该研究还分析了 QENDy 和 SINDy 的收敛性，并将其与 Koopman 算子线性化进行了比较。

> **摘要翻译:** 我们提出了一种名为 QENDy（非线性动力学的二次嵌入）的新型数据驱动方法，该方法不仅可以学习高度非线性动力学的二次表示，还可以识别控制方程。该方法基于将系统嵌入到一个高维特征空间，在该空间中动力学变为二次。与 SINDy（非线性动力学的稀疏识别）一样，我们的方法需要轨迹数据、训练数据点的 T 导数（也可以使用有限差分近似来估计）以及一组预选的基函数，称为字典。我们通过各种基准问题的帮助说明了 QENDy 的有效性和准确性，并将其性能与 SINDy 和用于识别二次嵌入的深度学习方法进行了比较。此外，我们分析了 QENDy 和 SINDy 在无限数据极限下的收敛性，强调了它们的相似之处和主要区别，并将二次嵌入与基于 Koopman 算子进行线性化的技术进行了比较。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [232] [On the $(k,\ell)$-multiset anonymity measure for social graphs](https://arxiv.org/abs/2507.08433)
> *关于社交图中 $(k,	ext{ell})$-多重集匿名度量*

*Alejandro Estrada-Moreno, Elena Fernández, Dorota Kuziak, Manuel Muñoz-Márquez, Rolando Trujillo-Rasua, Ismael G. Yero* | **Category: math.CO, cs.IT, math.IT** | **Updated: 2025-07-11**

**Keywords:** 社交图隐私, $(k,	ext{ell})$-多重集匿名度, 主动攻击, $k$-多重集反分辨集, 线性规划

**Comment:** 25 pages

> **TL;DR:** 本文提出了一种新的社交图隐私度量方法，即 $(k,	ext{ell})$-多重集匿名度，以更准确地评估社交图对抗主动攻击的抵抗力，并提供了其图论分析和计算方法。

**AI_Comments:** 本文创新性地提出了一种更贴合实际主动攻击场景的隐私度量方法，即 $(k,	ext{ell})$-多重集匿名度，通过重新定义攻击者的知识，弥补了传统 $(k,	ext{ell})$-匿名度在对抗主动攻击时的不足。其结合图论理论分析和线性规划的实用计算方法，为社交图隐私保护研究提供了新的视角和工具，对于量化社交图的隐私抵抗力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交图发布前需严格分析隐私威胁，特别是来自社交网络内部的主动攻击。现有的 $(k,	ext{ell})$-匿名度量方法认为攻击者的知识过于强大，因此需要提出一种更准确的度量方法来量化社交图对主动攻击的抵抗力。

**Method:** 提出了一种新的 $(k,	ext{ell})$-多重集匿名度量方法，其中攻击者的知识被定义为到攻击者节点集合的距离的多重集。从图论角度研究了这种匿名性，并建立了其与传统 $(k,	ext{ell})$-匿名性的关系。此外，将 $k$-多重集反分辨集作为其理论框架，并证明了某些图族在打破 $(k,	ext{ell})$-多重集匿名性方面的性质。最后，开发了一种 $k$-多重集反分辨集的线性规划公式，用于计算社交图对抗主动攻击的抵抗力。

**Result:** 提出了 $(k,	ext{ell})$-多重集匿名度量作为新的隐私度量标准。建立了 $(k,	ext{ell})$-多重集匿名度与传统 $(k,	ext{ell})$-匿名度的关系。证明了特定图族在打破这种新匿名性方面的性质。开发了用于计算社交图抵抗力的线性规划公式。

**Conclusion:** $(k,	ext{ell})$-多重集匿名度量提供了一种更实际的评估社交图对主动攻击隐私抵抗力的方法，并通过图论分析和线性规划公式使其在理论和实践中均可应用。

> **ai_Abstract:** 本文针对社交图在主动攻击下的隐私威胁，提出了一种新的隐私度量方法：$(k,	ext{ell})$-多重集匿名度。作者认为现有 $(k,	ext{ell})$-匿名度中的攻击者模型过于强大，因此将攻击者的知识定义为距离的多重集而非向量。研究从图论角度深入分析了这种新的匿名性，建立了其与传统 $(k,	ext{ell})$-匿名度的联系，并以 $k$-多重集反分辨集为理论框架，证明了相关图族性质。此外，还开发了线性规划公式以实际计算社交图的抵抗力，为隐私分析提供了工具。

> **摘要翻译:** 社交图的发布必须先对其社交图用户面临的隐私威胁进行严格分析。当威胁来自社交网络内部时，这种威胁被称为主动攻击，而用于量化抵抗此类攻击的事实隐私度量是 $(k,	ext{ell})$-匿名度。$(k,	ext{ell})$-匿名度的原始公式将攻击者的知识表示为到攻击者节点集合的距离向量。在本文中，我们认为在对抗主动攻击时，这样的攻击者过于强大。我们转而提出一种新的公式，其中攻击者的知识是到攻击者节点集合的距离的多重集。本文的目标是从图论的角度研究 $(k,	ext{ell})$-多重集匿名度，同时一方面建立其与 $(k,	ext{ell})$-匿名度的关系，另一方面将 $k$-多重集反分辨集作为其理论框架。也就是说，我们证明了某些图族在是否包含打破 $(k,	ext{ell})$-多重集匿名度的攻击者节点集合方面的性质。从实践角度来看，我们开发了 $k$-多重集反分辨集的线性规划公式，这使得我们能够计算社交图对抗主动攻击的抵抗力。这对于希望了解图所提供隐私级别的分析师来说非常有用。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [406] [Finding a solution to the Erdős-Ginzburg-Ziv theorem in $O(n\log\log\log n)$ time](https://arxiv.org/abs/2507.08139)
> *找到一个能在 O(n log log log n) 时间内解决 Erdős-Ginzburg-Ziv 定理的方法*

*Yui Hin Arvin Leung* | **Category: math.CO, cs.DS** | **Updated: 2025-07-10**

**Keywords:** Erdős-Ginzburg-Ziv 定理, 算法复杂度, 布尔卷积, FFT, 计算数论

**Comment:** 22 pages, 0 figures

> **TL;DR:** 论文提出了两种新的算法来解决 Erdős-Ginzburg-Ziv 定理，一种是实用的 O(n log log n) 算法，另一种是理论上的 O(n log log log n) 算法，这两种算法都比之前已知的 O(n log n) 方法更快。

**AI_Comments:** 该研究在解决 Erdős-Ginzburg-Ziv 定理方面取得了重要的理论和实践进展，通过提出比现有方法更快的算法。研究结果表明，在计算复杂性方面，布尔卷积的某些变体可能比标准 FFT 方法有改进的空间。

<details>
  <summary>Details</summary>

**Motivation:** Erdős-Ginzburg-Ziv 定理指出，对于任何包含 2n-1 个整数的序列，都存在一个包含 n 个元素的子序列，其和可被 n 整除。该研究的动机是改进解决此定理的算法。

**Method:** 该研究提出了两种算法：一种实用的 O(n log log n) 算法和一种理论上的 O(n log log log n) 算法。这两种算法都利用了布尔卷积的变体，并实现了比基于 FFT 的标准 O(n log n) 方法更快的运行时间。

**Result:** 该研究成功开发出两种新的算法，一种实用的 O(n log log n) 算法和一种理论上的 O(n log log log n) 算法，其运行时间均优于之前已知的 O(n log n) 方法，证明了布尔卷积的特定变体可以比标准的 FFT 方法更快地实现。

**Conclusion:** 该研究提出的 O(n log log n) 和 O(n log log log n) 算法在解决 Erdős-Ginzburg-Ziv 定理方面取得了显著进展，并表明布尔卷积的特定变体可以实现比 FFT 更快的计算速度。

> **ai_Abstract:** 本研究提出了两种改进的算法来解决 Erdős-Ginzburg-Ziv 定理，其中一种实用的 O(n log log n) 算法和一种理论上的 O(n log log log n) 算法，均优于先前的 O(n log n) 方法。这表明布尔卷积的特定变体可以比基于 FFT 的方法更快地实现。

> **摘要翻译:** Erdős-Ginzburg-Ziv 定理指出，对于任何包含 2n-1 个整数的序列，都存在一个包含 n 个元素的子序列，其和可被 n 整除。在本文中，我们提出了一种简单实用的 O(n log log n) 算法和一种理论上的 O(n log log log n) 算法，这两种算法都改进了先前已知的最佳 O(n log n) 方法。这表明布尔卷积的一个特定变体可以以比通常由 FFT 驱动的方法预期的 O(n log n) 更快的时间来实现。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [269] [Unraveling the Potential of Diffusion Models in Small Molecule Generation](https://arxiv.org/abs/2507.08005)
> *揭示扩散模型在小分子生成中的潜力*

*Peining Zhang, Daniel Baker, Minghu Song, Jinbo Bi* | **Category: q-bio.BM, cs.AI, cs.LG** | **Updated: 2025-06-25**

**Keywords:** 扩散模型, 小分子生成, 药物发现, 生成式AI, 分子设计

**Comment:** 

> **TL;DR:** 本文全面综述了扩散模型（DMs）在小分子生成中的最新进展和应用，涵盖其理论原理、方法分类、性能评估、当前挑战和未来研究方向。

**AI_Comments:** 本文是一篇及时且全面的综述，针对药物发现领域中一个新兴且高度相关的课题——扩散模型在分子生成中的应用。其涵盖理论原理、方法分类、性能分析以及未来方向的全面性，使其成为该领域研究人员的宝贵资源。特别关注3D方法，鉴于分子构象的重要性，这一点尤为相关。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI，尤其是扩散模型，在药物设计和化学空间探索中展现出巨大潜力，本研究旨在全面回顾扩散模型在分子生成领域的最新进展和应用。

**Method:** 本文采用综述方法，首先介绍扩散模型的理论原理，然后根据数学和化学应用对各种基于扩散模型的分子生成方法进行分类。此外，还审查了这些模型在基准数据集上的性能，并特别关注现有3D方法的生成性能比较。

**Result:** 本综述全面回顾并分类了基于扩散模型的分子生成方法，并评估了它们在基准数据集上的性能，特别关注了3D方法的生成表现。此外，还强调了当前面临的挑战并指出了未来的研究方向。

**Conclusion:** 扩散模型在药物发现中具有巨大的潜力，但仍面临挑战。需要进一步研究以充分利用其在药物发现中的潜力。

> **ai_Abstract:** 本综述深入探讨了扩散模型（DMs）在小分子生成（用于药物设计）中的应用。文章首先阐述了DMs的理论基础，接着根据其数学和化学应用对各种基于DMs的分子生成方法进行了系统分类，并评估了这些模型在基准数据集上的表现，尤其侧重于3D方法的生成性能比较。最后，文章总结了当前面临的挑战，并为充分发挥DMs在药物发现中的潜力提出了未来的研究方向。

> **摘要翻译:** 生成式人工智能为化学家提供了药物设计的新思路，并促进了广阔化学空间的探索。扩散模型（DMs）作为一种新兴工具，最近在药物研发领域引起了广泛关注。本文全面综述了扩散模型在分子生成方面的最新进展和应用。文章首先介绍了扩散模型的理论原理。随后，根据其数学和化学应用对各种基于扩散模型的分子生成方法进行了分类。该综述进一步审查了这些模型在基准数据集上的性能，特别关注了现有3D方法的生成性能比较。最后，文章总结了当前面临的挑战，并提出了未来的研究方向，以充分挖掘扩散模型在药物发现中的潜力。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

### [604] [AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration](https://arxiv.org/abs/2507.08162)
> *AmpLyze：一种用于预测溶血浓度的深度学习模型*

*Peng Qiu, Hanqi Feng, Barnabas Poczos* | **Category: q-bio.BM, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 抗菌肽, 溶血浓度, 深度学习, 毒性预测, 可解释性模型

**Comment:** 

> **TL;DR:** AmpLyze是一个深度学习模型，可以仅根据序列预测抗菌肽（AMP）的溶血浓度（HC50），并识别导致毒性的关键残基。它结合了残基级和序列级特征，并通过交叉注意力机制进行对齐，使用log-cosh损失进行训练。该模型在预测精度上优于现有方法，并能提供可解释的毒性评估，有助于AMP的设计和早期毒性筛选。

**AI_Comments:** 该研究提出了一种名为AmpLyze的创新深度学习模型，用于预测抗菌肽（AMP）的溶血浓度（HC50），解决了现有模型在毒性评估方面的不足。模型结合了多层次的序列信息（残基级和序列级）和交叉注意力机制，并通过log-cosh损失提高了对实验噪声的鲁棒性。其预测精度优于现有方法，并且通过Expected-Gradients归因提供了模型的可解释性，能够识别毒性关键区域。这项工作对于加速AMP的发现和开发具有重要意义，尤其是在安全性评估方面。然而，模型的泛化能力和在不同类型肽上的表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型只能预测抗菌肽（AMP）是否具有毒性（“有毒”或“无毒”），而无法预测实际的溶血浓度（HC50），而HC50是AMP治疗的安全性关键指标。AmpLyze旨在弥合这一差距，通过仅根据序列预测实际的HC50值，并解释驱动毒性的残基。

**Method:** AmpLyze模型结合了残基级别的ProtT5/ESM2嵌入和序列级别的描述符，通过双重局部和全局分支进行处理，并利用交叉注意力模块进行对齐。模型使用log-cosh损失进行训练，以提高对测定噪声的鲁棒性。

**Result:** 最优的AmpLyze模型达到了0.756的PCC（皮尔逊相关系数）和0.987的MSE（均方误差），性能优于经典的回归模型和最先进的方法。消融实验表明，局部和全局两个分支都是必需的，而交叉注意力模块能进一步将PCC提高1%，MSE降低3%。Expected-Gradients归因方法揭示了已知的毒性热点，并提出了更安全的替代方案。

**Conclusion:** AmpLyze通过将溶血评估转化为可量化的、基于序列的、可解释的预测，促进了AMP的设计，并为早期毒性筛选提供了一个实用的工具。

> **ai_Abstract:** AmpLyze是一个新开发的深度学习模型，能够根据抗菌肽（AMP）的序列预测其溶血浓度（HC50），解决了现有模型仅能进行二元毒性分类的局限性。该模型结合了局部和全局特征提取以及交叉注意力机制，并采用log-cosh损失函数以增强鲁棒性。实验结果显示，AmpLyze在预测精度上超越了传统方法和现有先进模型，并且其可解释性有助于识别和优化AMP的毒性位点，为AMP的研发提供了有价值的工具。

> **摘要翻译:** 红细胞裂解（HC50）是抗菌肽（AMP）治疗的主要安全屏障，但现有模型只能说明“有毒”或“无毒”。AmpLyze通过仅根据序列预测实际的HC50值并解释驱动毒性的残基来弥合这一差距。该模型将残基级别的ProtT5/ESM2嵌入与序列级别的描述符相结合，通过双重局部和全局分支进行处理，并利用交叉注意力模块进行对齐，同时使用log-cosh损失进行训练以提高对测定噪声的鲁棒性。最优的AmpLyze模型达到了0.756的PCC和0.987的MSE，优于经典的回归模型和最先进的方法。消融实验证实了两个分支的必要性，并且交叉注意力进一步将PCC提高了1%，MSE降低了3%。Expected-Gradients归因揭示了已知的毒性热点并提出了更安全的替代方案。通过将溶血评估转化为可量化的、基于序列的、可解释的预测，AmpLyze促进了AMP的设计，并为早期毒性筛选提供了一个实用的工具。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [282] [Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data](https://arxiv.org/abs/2507.08773)
> *实值和复值多变量数据的总/双重相关/相干性、冗余/协同、复杂性和O-信息*

*Roberto D. Pascual-Marqui, Kieko Kochi, Toshihiko Kinoshita* | **Category: stat.ME, cs.IT, math.IT, math.ST, stat.TH** | **Updated: 2025-07-11**

**Keywords:** 总相关, O-信息, 冗余-协同, 多变量数据, 信息论

**Comment:** 

> **TL;DR:** 本文提出了信息论度量（TC、DTC、O-信息、TSE复杂度、RSI）的方程并对其进行了泛化，适用于多变量数据，包括结构化组，并提供了一个量化变量贡献的框架。

**AI_Comments:** 本文通过泛化现有的信息论度量以处理结构化多变量数据，特别是在解决O-信息无法捕获组间协同的局限性方面，展现了创新性。DTC的详细解释以及量化连接贡献的框架，增强了这些度量在复杂系统中的实用性和可解释性。其对其他椭圆分布的适用性也扩大了其实际相关性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出多种信息论度量的方程，并针对结构化变量组对其进行泛化（解决现有度量如O-信息可能遗漏组间协同的局限性），以及量化变量间“连接”对这些度量的贡献。

**Method:** 本文在假设高斯性的前提下，提出了总相关/相干性（TC）、双总相关/相干性（DTC）、O-信息、TSE复杂度以及冗余-协同指数（RSI）的方程。研究表明DTC是逆Wishart对的Kullback-Leibler（KL）散度。论文引入了针对结构化变量组的度量泛化，并提出了一个量化变量间连接贡献的框架。此外，还泛化了冗余-协同指数。

**Result:** 本文提出了信息论度量的方程。双总相关（DTC）被证明是逆Wishart对的Kullback-Leibler（KL）散度，可解释为“总偏相关”。引入了一种结构化O-信息度量，能够正确报告组间的主要协同作用。提出了一个量化连接贡献的框架，并泛化了冗余-协同指数。此外，推导出的表达式直接适用于来自其他几种椭圆分布的数据。

**Conclusion:** 本文提供了一套全面且泛化的信息论度量，以及一个用于分析多变量数据的框架。这些工作解决了现有度量的局限性，并扩展了其适用范围。

> **ai_Abstract:** 本文在假设高斯性的前提下，对多变量数据的多种信息论度量（总/双重相关/相干性、O-信息、TSE复杂度、冗余-协同指数）进行了全面分析和泛化。论文阐明了双总相关（DTC）作为Kullback-Leibler散度的解释，并引入了结构化泛化，以准确捕获分组变量中的协同作用，这弥补了传统O-信息可能遗漏的问题。此外，文章提出了一个量化变量连接贡献的框架，并扩展了冗余-协同指数，同时证明了这些度量适用于多种椭圆分布数据。

> **摘要翻译:** 首先，在假设高斯性的前提下，本文提出了以下信息论度量的方程：总相关/相干性（TC）、双总相关/相干性（DTC）、O-信息、TSE复杂度以及冗余-协同指数（RSI）。由于这些度量是协方差矩阵“S”及其逆矩阵“S^-1”的函数，因此相关的Wishart和逆Wishart分布值得关注。本文表明，DTC是逆Wishart对“(S^-1)”及其对角矩阵“diag(S^-1)”的Kullback-Leibler（KL）散度，这阐明了其作为“总偏相关”度量（-lndetP）的解释，其检验假设H0: P=I，其中“P”是标准化逆协方差（即P=(D^-1/2)(S^-1)(D^-1/2)，D=diag(S^-1)）。本文的第二个目标是引入所有这些度量对变量结构化组的泛化。例如，考虑三个或更多组，每组包含三个或更多变量，每组内部以冗余为主，但组间存在协同相互作用。O-信息将无法捕获组间协同（因为冗余在系统中更常发生）。相比之下，本文提出的结构化O-信息度量将正确报告组间的主要协同作用。这是对结构化多变量信息度量的一个重要泛化。第三个目标是提出一个框架，用于量化变量之间“连接”对系统TC、DTC、O-信息和TSE复杂度的贡献。第四个目标是提出冗余-协同指数的泛化，用于量化一组变量对系统冗余-协同平衡的贡献。最后，本文表明此处推导的表达式直接适用于来自其他几种椭圆分布的数据。所有程序代码、数据文件和可执行文件均可获取。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [453] [Estimation of conditional average treatment effects on distributed confidential data](https://arxiv.org/abs/2402.02672)
> *分布在机密数据上的条件平均处理效应估计*

*Yuji Kawamata, Ryoki Motai, Yukihiko Okada, Akira Imakura, Tetsuya Sakurai* | **Category: stat.ME, cs.CR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 条件平均处理效应,分布式数据,隐私保护,双机器学习,数据协作

**Comment:** 45 pages, 12 figures

> **TL;DR:** 该研究提出了一种名为数据协作双机器学习（data collaboration double machine learning）的新方法，用于在不汇总敏感数据的情况下，从多个分布式数据源估计条件平均处理效应（CATE）。该方法通过构建隐私保护的融合数据来实现，无需迭代通信，并且在模拟研究中表现出与现有方法相当或更优的性能。

**AI_Comments:** 该研究提出了一种创新的方法，解决了在分布式和机密数据环境中估计CATE的挑战。其无需迭代通信和对模型错误指定的鲁棒性是重要的优势。然而，关于隐私保护融合数据的具体构建细节以及在真实世界大规模分布式系统中的可扩展性还需要进一步的探讨。

<details>
  <summary>Details</summary>

**Motivation:** 在许多科学领域，估计条件平均处理效应（CATE）很重要。然而，由于保密或隐私问题，很难聚合分布在多个方的数据以进行准确的CATE估计。

**Method:** 提出数据协作双机器学习（data collaboration double machine learning）方法，利用从分布式源构建的隐私保护融合数据来估计CATE模型。

**Result:** 所提出的方法在模拟研究中，使用合成、半合成和真实世界数据集，表现与现有方法相当或更好。

**Conclusion:** 该方法支持在分布式数据上进行CATE估计和检验，无需迭代通信，并且比参数方法更能抵抗模型错误指定。它还通过累积知识库实现了跨不同时间点和各方之间的协作估计。

> **ai_Abstract:** 本研究提出了一种名为“数据协作双机器学习”的新方法，用于在分布式和机密数据环境中估计条件平均处理效应（CATE）。该方法通过创建隐私保护的融合数据，避免了集中化数据的需要，并能在无迭代通信的情况下进行半参数CATE模型的估计和检验，提高了对模型错误指定的鲁棒性。此外，该方法还能通过知识库的累积实现跨时间点和参与方的协作估计。模拟结果表明，该方法在不同类型的数据集上均表现出与现有方法相当或更优的性能。

> **摘要翻译:** 条件平均处理效应（CATE）的估计是许多科学领域的重要课题。如果分布在多个方的数据被集中化，CATE可以被高精度地估计。然而，由于保密或隐私问题，聚合此类数据是困难的。为了解决这个问题，我们提出数据协作双机器学习，一种使用从分布式源构建的隐私保护融合数据来估计CATE模型的方法，并通过模拟评估其性能。我们做出了三个主要贡献。首先，我们的方法能够在分布式数据上估计和检验半参数CATE模型，而无需迭代通信，与参数方法相比，对模型错误指定具有鲁棒性。其次，它通过累积知识库实现了跨不同时间点和各方之间的协作估计。第三，我们的方法在模拟研究中，使用合成、半合成和真实世界数据集，表现与现有方法相当或更好。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [309] [Energy Management for Renewable-Colocated Artificial Intelligence Data Centers](https://arxiv.org/abs/2507.08011)
> *可再生能源共址人工智能数据中心的能源管理*

*Siying Li, Lang Tong, Timothy D. Mount* | **Category: math.OC, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-04**

**Keywords:** 能源管理, AI数据中心, 可再生能源, 协同优化, 利润最大化

**Comment:** 

> **TL;DR:** 为可再生能源共址AI数据中心开发能源管理系统，通过协同优化工作负载、可再生能源利用和电力市场参与来最大化利润。

**AI_Comments:** 该论文的创新之处在于其对人工智能数据中心的能源管理采取了全面的方法，通过整合可再生能源并在利润最大化框架下优化其在多个维度（工作负载、现场发电、市场参与）的运行。这对于可持续和经济可行的人工智能基础设施至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在利润最大化框架下，最大化可再生能源共址人工智能数据中心的经济效益。

**Method:** 开发了一个能源管理系统（EMS），该系统协同优化AI工作负载调度、现场可再生能源利用和电力市场参与（包括批发和零售市场模型）。

**Result:** 实证评估表明，可再生能源与AI数据中心共址带来了显著的利润增长。

**Conclusion:** 通过协同优化策略，该能源管理系统有效最大化了可再生能源共址数据中心的经济效益，带来了显著的利润增长。

> **ai_Abstract:** 本文提出了一种为可再生能源共址人工智能数据中心设计的能源管理系统（EMS）。该系统在利润最大化目标下运行，智能地协同优化AI工作负载调度、现场可再生能源利用以及参与批发和零售电力市场。基于真实世界数据的实证结果表明，将可再生能源与AI数据中心运营相结合，可实现显著的利润增长。

> **摘要翻译:** 我们为拥有共址可再生能源发电的人工智能（AI）数据中心开发了一个能源管理系统（EMS）。在利润最大化框架下，可再生能源共址数据中心（RCDC）的EMS协同优化了AI工作负载调度、现场可再生能源利用和电力市场参与。在批发和零售市场参与模型中，RCDC运营的经济效益都得到了最大化。使用电力价格、数据中心功耗和可再生能源发电的真实世界轨迹进行的实证评估表明，可再生能源与AI数据中心共址带来了显著的利润增长。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [429] [Stability analysis through folds: An end-loaded elastic with a lever arm](https://arxiv.org/abs/2501.04729)
> *稳定性分析通过褶皱：带有杠杆臂的末端加载弹性体*

*Siva Prasad Chakri Dhanakoti* | **Category: math.OC, cond-mat.soft, cs.RO** | **Updated: 2025-07-11**

**Keywords:** 稳定性分析, 褶皱, 区分性分岔图, 弹性体, 回弹不稳定性

**Comment:** 22 pages, 12 figures

> **TL;DR:** 该研究提出了一种通过褶皱分析参数相关变分问题的稳定性，特别关注具有固定-自由末端的系统。研究人员识别了区分性分岔图，并将其应用于具有杠杆臂的末端加载弹性体，观察到了与系统参数相关的回弹不稳定性，这在软体机器人和执行器设计中具有潜在应用。

**AI_Comments:** 该研究巧妙地将褶皱理论和区分性分岔图应用于力学问题，为理解复杂系统的稳定性提供了一种新颖的视角。其在软体机器人领域的潜在应用也使其具有较高的实践价值。然而，文中仅提及了数值示例，并未提供详细的实验验证，这可能是未来研究的一个方向。

<details>
  <summary>Details</summary>

**Motivation:** 许多物理系统可被建模为参数依赖的变分问题，其中常共存多个平衡态，需要评估其稳定性和监测其间的跃迁。通常，平衡态的稳定性特征在参数空间中的褶皱附近会发生变化。

**Method:** 识别了适用于固定-自由末端变分问题的区分性分岔图，并利用这些图研究了通过刚性杠杆臂施加载荷的弹性体。

**Result:** 研究发现了与系统参数相关的回弹不稳定性，并通过数值示例进行了说明。

**Conclusion:** 所提出的通过褶皱分析稳定性，特别是区分性分岔图，为理解和预测具有固定-自由末端的变分系统（如带杠杆臂的弹性体）的行为提供了有效的方法，并揭示了与回弹不稳定性相关的现象，这对软体机器人和执行器设计具有指导意义。

> **ai_Abstract:** 本研究提出了一种通过褶皱分析参数依赖变分问题的稳定性。作者识别了区分性分岔图，这些图能够揭示解在参数空间中变化时的稳定性变化方向。研究将此方法应用于具有固定-自由末端的弹性体，该弹性体受到通过杠杆臂施加的末端载荷。通过数值示例，研究观察到了与系统参数相关的回弹不稳定性，并指出这些发现对软体机器人和执行器设计具有潜在应用价值。

> **摘要翻译:** 许多物理系统可以被建模为参数依赖的变分问题。在许多情况下，多个平衡态会共存，需要评估它们的稳定性并监测它们之间的跃迁。通常，平衡态的稳定性特征在参数空间中的褶皱附近会发生变化。稳定性变化的方向嵌入在称为区分性分岔图的解的特定投影中。在本文中，我们识别了固定-自由末端的变分问题的这种投影——这是一类在力学中经常遇到的问题。利用这些图，我们研究了一个受到通过刚性杠杆臂施加的末端载荷的弹性体。通过数值示例报告了几次回弹不稳定性，以及它们对系统参数的依赖性。这些发现可能在软体机器人手臂和其他执行器设计的领域具有潜在应用。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [430] [A Dissipativity Framework for Constructing Scaled Graphs](https://arxiv.org/abs/2507.08411)
> *一种构建尺度图的耗散性框架*

*Timo de Groot, Maurice heemels, Sebastiaan van den Eijnden* | **Category: math.OC, cs.SY, eess.SY, 93D25, 93C10** | **Updated: 2025-07-11**

**Keywords:** 尺度图,耗散性,非线性系统,反馈系统,积分二次约束

**Comment:** 

> **TL;DR:** 该论文提出了一种基于耗散性的框架，用于计算非线性系统的尺度图，解决了现有方法需要检查无限多输入的问题，并对特定线性时不变系统给出了精确结果。

**AI_Comments:** 该研究通过引入耗散性框架解决了尺度图计算的实际瓶颈，为非线性系统分析提供了新的视角和更有效的工具。其在LMI和IQC方面的创新性联系值得关注，但对于更广泛的系统类别的精确性和计算效率仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有的尺度图方法在分析非线性反馈系统时需要检查无限多输入，存在实际计算瓶颈，限制了其应用。

**Method:** 提出了一种基于耗散性的框架，利用线性矩阵不等式、积分二次约束和尺度图之间的联系来计算尺度图。

**Result:** 该框架能够高效地计算多变量线性时不变系统、脉冲系统和分段线性系统的尺度图，并且对特定的线性时不变系统是精确的。

**Conclusion:** 该论文提出的基于耗散性的框架能够有效解决尺度图计算的瓶颈问题，为非线性系统的稳定性分析提供了强大的图解工具。

> **ai_Abstract:** 本研究提出了一种基于耗散性的新框架，用于构建尺度图，这是分析非线性反馈系统的一种图解工具。该框架解决了现有方法在处理无限多输入时的计算瓶颈问题，并能高效计算包括多变量LTI、脉冲和分段线性系统在内的各类系统的尺度图。研究利用了LMI、IQC和尺度图之间的联系，并对部分LTI系统实现了精确计算。

> **摘要翻译:** 尺度相对图最初是在凸优化背景下引入的，最近因其在非线性系统图解分析中的应用而引起了控制系统界的关注。在反馈系统稳定性分析中特别令人感兴趣的是尺度图，它是尺度相对图的一个特例。在很多方面，尺度图可以看作是经典线性时不变系统奈奎斯特图的推广，并为分析非线性反馈系统提供了一个强大的图解工具。然而，在其当前的表述中，尺度图需要表征一个系统对于无限多个输入的输入-输出行为。这给获得非线性系统的尺度图带来了实际瓶颈，并限制了其应用。本文提出了一个基于耗散性的框架，用于有效地计算几类重要系统（包括多变量线性时不变系统、脉冲系统和分段线性系统）的尺度图。该方法利用了线性矩阵不等式、积分二次约束和尺度图之间的新联系，并被证明对特定的线性时不变系统是精确的。结果附有几个例子，说明了所提出框架的潜力和有效性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [487] [Enhancing Distributional Robustness in Principal Component Analysis by Wasserstein Distances](https://arxiv.org/abs/2503.02494)
> *通过Wasserstein距离增强主成分分析中的分布鲁棒性*

*Lei Wang, Xin Liu, Xiaojun Chen* | **Category: math.OC, cs.LG, stat.ML** | **Updated: 2025-07-11**

**Keywords:** 分布鲁棒优化, 主成分分析, Wasserstein距离, 流形优化, 非光滑优化

**Comment:** 

> **TL;DR:** 该研究提出了一种新的分布鲁棒优化（DRO）模型，用于主成分分析（PCA），并使用二型Wasserstein距离来处理概率分布不确定性。研究人员开发了一种高效的流形近邻梯度算法来解决由此产生的非光滑优化问题，并证明了该算法的收敛性和迭代复杂度。

**AI_Comments:** 这项研究通过引入Wasserstein距离来增强PCA的分布鲁棒性，这是一个重要的贡献。所提出的流形近邻梯度算法能够有效地解决由此产生的非光滑优化问题，并且具有可证明的收敛性和迭代复杂度。然而，关于该算法在实际应用中的扩展性和与其他鲁棒PCA方法的比较可以进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决概率分布不确定性问题，本研究考虑了主成分分析（PCA）的分布鲁棒优化（DRO）模型。

**Method:** 研究人员将DRO模型重构为在Stiefel流形上的最小化问题，并设计了一种高效的流形近邻梯度算法来解决它，该算法具有黎曼梯度一致性和全局收敛性。

**Result:** 该算法被证明可以收敛到一个平稳点，并且达到ε近似平稳点的迭代复杂度为O(ε^-3)。数值实验也验证了该算法的有效性、可扩展性以及DRO模型在PCA中的必要性和合理性。

**Conclusion:** 该研究成功地提出了一种用于PCA的分布鲁棒优化模型，并开发了一种有效的算法来解决它，证明了该方法的有效性和必要性。

> **ai_Abstract:** 本研究提出了一种用于主成分分析（PCA）的分布鲁棒优化（DRO）模型，该模型利用二型Wasserstein距离来处理概率分布的不确定性。研究人员将原始的非光滑约束最小-最大优化问题转化为一个在Stiefel流形上的非光滑最小化问题，并为此开发了一种高效的流形近邻梯度算法。该算法被证明具有黎曼梯度一致性和全局收敛性，达到ε近似平稳点的迭代复杂度为O(ε^-3)。数值实验结果证实了该算法的有效性和可扩展性，并证明了在PCA中使用DRO模型的必要性和合理性。

> **摘要翻译:** 我们考虑主成分分析（PCA）的分布鲁棒优化（DRO）模型，以应对潜在概率分布中的不确定性。由此产生的模型是一个非光滑约束的最小-最大优化问题，其中模糊集通过二型Wasserstein距离捕获分布不确定性。我们证明了内部最大化问题具有封闭形式的最优值。这种显式表征将原始DRO模型等效地重构为在Stiefel流形上的最小化问题，其中包含复杂的非光滑项，这是一个现有算法难以处理的挑战性模型。为了解决这个问题，我们设计了一种高效的流形近邻梯度算法。我们的分析证明了该算法的黎曼梯度一致性和全局收敛性，以及它收敛到一个非光滑最小化问题的平稳点。我们还提供了该算法达到ε近似平稳点的迭代复杂度O(ε^-3)。最后，通过进行数值实验来验证我们算法的有效性和可扩展性，并强调采用DRO模型进行PCA的必要性和合理性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [594] [A Stability Condition for Online Feedback Optimization without Timescale Separation](https://arxiv.org/abs/2412.10964)
> *在线反馈优化稳定性条件研究：无需时间尺度分离*

*Mattia Bianchi, Florian Dörfler* | **Category: math.OC, cs.SY, eess.SY, math.DS** | **Updated: 2025-07-11**

**Keywords:** 在线反馈优化,稳定性条件,时间尺度分离,Lyapunov函数,尺度不变性

**Comment:** 

> **TL;DR:** 本研究提出了一种在线反馈优化（OFO）的稳定性条件，该条件无需控制器和被控对象之间存在时间尺度分离，从而克服了现有方法的局限性，并可能改善瞬态性能和对干扰的响应能力。该条件是尺度不变的，并通过复合Lyapunov函数进行了理论分析，并得到了数值示例的验证。

**AI_Comments:** 这项研究解决了OF O领域的一个重要问题，即时间尺度分离的限制。提出的尺度不变稳定性条件是一个重要的理论贡献，并且得到了数值验证，这增加了其实用性。然而，实际应用中的潜在局限性或对特定类型被控对象动力学的敏感性仍有待进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 现有在线反馈优化（OFO）方法的稳定性保证需要控制器比被控对象演化得慢得多，这可能会影响瞬态性能和对干扰的响应能力。

**Method:** 利用一个复合Lyapunov函数（由被控对象相关和控制器相关分量组成）来分析OF O的稳定性。

**Result:** 提出了一种新的OF O稳定性条件，该条件独立于被控对象的时间常数，具有尺度不变性。

**Conclusion:** 在合适的条件下，OF O可以在没有时间尺度分离的情况下保证稳定性。

> **ai_Abstract:** 本研究提出了一种在线反馈优化（OFO）的稳定性条件，该条件克服了现有方法对时间尺度分离的要求，从而提高了性能和响应能力。该条件具有尺度不变性，并通过复合Lyapunov函数进行了理论分析。

> **摘要翻译:** 在线反馈优化（OFO）是一种驱动动态被控对象达到最优稳态的控制方法。通过将优化算法与实时被控对象测量相结合，OFO提供了反馈控制的所有优点，同时在计算设定点时不需要精确了解被控对象动力学。但缺点是，现有的OF O稳定性保证要求控制器必须比被控对象演化得慢得多，这可能会影响瞬态性能和对干扰的响应能力。在本文中，我们证明了在合适的条件下，OF O可以在没有任何时间尺度分离的情况下保证稳定性。特别是，我们提出的条件独立于被控对象的时间常数，因此具有尺度不变性。我们的分析利用了一个复合Lyapunov函数，该函数是被控对象相关和控制器相关分量的最大值。我们用数值示例证实了我们的理论结果。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [312] [On Conservative Matrix Fields: Continuous Asymptotics and Arithmetic](https://arxiv.org/abs/2507.08138)
> *关于保守矩阵场：连续渐近与算术*

*Shachar Weinbaum, Elyasheev Leibtag, Rotem Kalisch, Michael Shalyt, Ido Kaminer* | **Category: math.NT, cs.SC, math.CO, math.RA, 11J70, 11J82, 40A15, 33C80, 33C70, 68W30** | **Updated: 2025-07-10**

**Keywords:** 保守矩阵场, Apéry极限, 无理性证明, Poincaré-Perron渐近, D-有限序列

**Comment:** 26 pages, 5 figures

> **TL;DR:** 本文将Apéry极限扩展到高维，引入了保守矩阵场（CMF），并展示了CMF如何包含经典Apéry极限。通过数值实验发现了新的算术和动力学现象，并提出了可能扩展Poincaré-Perron渐近到高维的猜想，这可能为寻找新的无理性证明提供途径。

**AI_Comments:** 本文的创新之处在于引入了保守矩阵场（CMF），成功地将D-有限序列比率和Apéry极限的概念推广到高维。通过连接CMF与规范变换和Ore代数，提供了一个新的理论框架。数值实验揭示的算术和动力学现象及其提出的猜想具有重要意义，如果这些猜想能够被证明，将对数论中的无理性证明领域产生深远影响，并可能拓展渐近分析的边界。

<details>
  <summary>Details</summary>

**Motivation:** Apéry极限和D-有限序列的比率推动了自Apéry在1979年证明ζ(3)无理性以来关于无理性证明的大量工作。本文的动机是将D-有限序列的比率扩展到高维设置。

**Method:** 通过引入保守矩阵场（CMF）将D-有限序列的比率扩展到高维。提供了一种CMF的有用构造，将其与规范变换和Ore代数有限维模中移位算子的表示联系起来。最后，通过对这些对象进行数值实验。

**Result:** 数值实验揭示了令人惊讶的算术和动力学现象，这些现象被表述为猜想。这些猜想如果成立，将把Poincaré-Perron渐近扩展到更高维度。

**Conclusion:** 如果本文提出的猜想得以确立，它们将把Poincaré-Perron渐近扩展到更高维度，可能为通过优化方法寻找新的无理性证明打开大门。

> **ai_Abstract:** 本文引入了保守矩阵场（CMF），将Apéry极限和D-有限序列的比率概念推广到高维设置。研究表明CMF包含了经典的Apéry极限。通过将CMF的构造与规范变换和Ore代数联系起来，作者进行了数值实验，发现了新的算术和动力学现象，并提出了相关猜想。这些猜想如果得到证实，有望扩展Poincaré-Perron渐近理论至高维，并为寻找新的无理性证明提供潜在途径。

> **摘要翻译:** D-有限序列的比率及其极限——被称为Apéry极限——自Apéry在1979年突破性地证明ζ(3)的无理性以来，推动了大量关于无理性证明的工作。我们通过引入保守矩阵场（CMF）将D-有限序列的比率扩展到高维设置。我们证明了经典Apéry极限如何作为特例包含在此对象中。本文提供了一种CMF的有用构造，将其与规范变换以及Ore代数有限维模中移位算子的表示联系起来。最后，对这些对象进行的数值实验揭示了令人惊讶的算术和动力学现象，这些现象被表述为猜想。如果这些猜想得以确立，它们将把Poincaré-Perron渐近扩展到更高维度，可能为通过优化方法寻找新的无理性证明打开大门。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='q-finst'></a>
## q-fin.ST 

### [338] [To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions](https://arxiv.org/abs/2507.08584)
> *交易与否：一种代理方法估计市场风险以改进交易决策*

*Dimitrios Emmanoulopoulos, Ollie Olby, Justin Lyon, Namid R. Stillman* | **Category: q-fin.ST, cs.AI, cs.CE, cs.MA, q-fin.CP, 68T42, 65C05, 68T01, 60H10, I.2.11; I.2.0; I.2.1; I.2.3; I.2.4; I.2.8** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 代理系统, 市场风险, 随机微分方程, 交易决策

**Comment:** 31 pages, 7 figures, 3 tables

> **TL;DR:** 开发了一个使用LLMs迭代发现随机微分方程的代理系统，用于估计市场风险并改进交易决策，表现优于传统LLM代理。

**AI_Comments:** 这项研究的创新之处在于将LLMs从简单的文本分析工具提升为能够进行复杂科学发现的“代理”，特别是用于迭代地发现金融时间序列的随机微分方程。这为LLMs在金融领域的应用开辟了新的路径，超越了传统的情绪或趋势分析，引入了更具原则性的模型构建方法来估计市场风险，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM代理框架在金融领域缺乏一个有原则的模型构建步骤，通常依赖于情绪或趋势分析，而不是基于模型的方法来估计市场风险。

**Method:** 开发了一个代理系统，该系统使用大型语言模型（LLMs）迭代地发现金融时间序列的随机微分方程。这些模型生成风险指标，用于指导日常交易决策。系统在传统回测和市场模拟器中进行评估。

**Result:** 模型驱动的交易策略表现优于标准的基于LLM的代理，提高了多种股票的夏普比率。

**Conclusion:** 将LLMs与代理模型发现相结合，可以增强市场风险估计，并实现更有利可图的交易决策。

> **ai_Abstract:** 本文提出了一个创新的代理系统，利用大型语言模型（LLMs）迭代地发现金融时间序列的随机微分方程，从而生成精确的市场风险指标。该系统通过模型驱动的方法改进了交易决策，并在回测和市场模拟中验证其性能优于传统的LLM代理，显著提高了夏普比率，证明了LLMs与模型发现结合在金融风险管理和盈利交易中的潜力。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地部署在代理框架中，其中提示触发复杂的基于工具的分析以实现目标。虽然这些框架在包括金融在内的多个领域显示出前景，但它们通常缺乏一个有原则的模型构建步骤，而是依赖于情绪或趋势分析。我们通过开发一个代理系统来解决这一空白，该系统使用LLMs迭代地发现金融时间序列的随机微分方程。这些模型生成风险指标，为日常交易决策提供信息。我们在传统回测和使用市场模拟器（引入合成但因果合理的股价路径和新闻事件）中评估了我们的系统。我们发现，模型知情的交易策略优于标准的基于LLM的代理，提高了多种股票的夏普比率。我们的结果表明，将LLMs与代理模型发现相结合，可以增强市场风险估计并实现更有利可图的交易决策。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [362] [Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation](https://arxiv.org/abs/2507.07668)
> *使用预测不确定性估计学习强子态的极点结构*

*Felix Frohnert, Denny Lane B. Sombillo, Evert van Nieuwenburg, Patrick Emonts* | **Category: hep-ph, cs.AI, cs.LG, hep-ex** | **Updated: 2025-07-11**

**Keywords:** 强子谱学, 极点结构, 不确定性估计, 机器学习, S矩阵

**Comment:** 

> **TL;DR:** 该研究提出了一种新的机器学习方法，利用不确定性估计来识别强子态的极点结构，在分类任务中取得了高精度，并成功应用于LHCb实验数据以推断Pc(4312)+的极点结构。

**AI_Comments:** 这项研究提出了一种新颖的机器学习方法，用于解决强子谱学中的一个关键挑战：识别强子态的极点结构。通过整合不确定性估计，该方法不仅提高了分类的准确性（接近95%），而且还提供了对模型预测可靠性的量化评估。将该方法应用于LHCb实验数据以推断Pc(4312)+状态的极点结构是一个重要的应用实例，表明该方法在处理真实世界数据方面的潜力。然而，该研究的局限性在于其主要在合成数据上进行了训练，尽管它成功地泛化到了实验数据。未来的工作可以进一步探索该方法在更广泛的强子态和更复杂的数据集上的应用，并研究不确定性量化对模型选择和物理解释的影响。

<details>
  <summary>Details</summary>

**Motivation:** 在强子谱学中，将理论预测与实验数据进行匹配，特别是识别新的强子态，是一个持续的挑战，因为在阈值附近可能出现由不同物理机制引起的奇异信号。极点结构是区分这些信号的关键诊断，但不同的极点构型可能产生相似的信号，尤其是在解析控制有限的质量阈值附近，极点构型与线形之间的映射关系模糊不清。

**Method:** 提出了一种基于不确定性感知机器学习的方法，该方法使用分类器链的集成来同时估计认知不确定性和偶然不确定性，并基于预测不确定性应用了拒绝标准。

**Result:** 该方法在验证集上达到了近95%的准确率，同时仅丢弃了少量高不确定性预测。该模型在合成数据上训练后，能够泛化到先前未见过的数据，包括LHCb实验观察到的Pc(4312)+状态的增强信号，并推断出四极点结构，表明存在真正的紧凑五夸克态，同时存在一个具有非零宽度的更高通道的虚态极点。

**Conclusion:** 该框架具有广泛的适用性，可用于其他候选强子态的识别，并为散射振幅中的极点结构推断提供了一个可扩展的工具。

> **ai_Abstract:** 这项研究提出了一种创新的不确定性感知机器学习方法，用于分析强子态的极点结构。通过使用分类器链集成来估计认知和偶然不确定性，该方法能够以近95%的准确率识别极点构型，同时通过拒绝高不确定性预测来提高可靠性。该方法在合成数据上进行了训练，并成功应用于LHCb实验数据，以推断Pc(4312)+状态的极点结构，表明存在一个紧凑的五夸克态。该框架为强子谱学研究提供了一个可扩展的工具。

> **摘要翻译:** 在强子谱学中，将理论预测与实验数据进行匹配仍然是一个核心挑战。特别是，新强子态的识别是困难的，因为阈值附近的奇异信号可能源于多种物理机制。在此背景下的一个关键诊断是散射振幅的极点结构，但不同的构型可以产生相似的信号。极点构型与线形之间的映射尤其在质量阈值附近变得模糊，因为解析控制是有限的。在这项工作中，我们引入了一种不确定性感知的机器学习方法来分类S矩阵元中的极点结构。我们的方法基于分类器链的集成，该集成同时提供认知不确定性和偶然不确定性估计。我们应用了基于预测不确定性的拒绝标准，取得了近95%的验证准确率，同时仅丢弃了少量高不确定性预测。该模型在具有已知极点结构的合成数据上进行训练，能够泛化到先前未见过的数据，包括LHCb观察到的Pc(4312)+状态的增强信号。在此，我们推断出四极点结构，代表在存在具有非零宽度的更高通道的虚态极点的情况下，存在真正的紧凑五夸克。虽然对这个特定的状态进行了评估，但我们的框架广泛适用于其他候选强子态，并为散射振幅中的极点结构推断提供了一个可扩展的工具。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [451] [Massively parallel and universal approximation of nonlinear functions using diffractive processors](https://arxiv.org/abs/2507.08253)
> *使用衍射处理器进行非线性函数的超大规模并行和通用逼近*

*Md Sadman Sakib Rahman, Yuhang Li, Xilin Yang, Shiqi Chen, Aydogan Ozcan* | **Category: physics.optics, cs.NE, physics.app-ph** | **Updated: 2025-07-11**

**Keywords:** 光学计算, 非线性函数逼近, 衍射处理器, 线性光学, 并行计算

**Comment:** 28 Pages, 7 Figures

> **TL;DR:** 该研究提出了一种使用线性光学和优化的衍射处理器（由无源相位相关表面组成）来实现大规模非线性计算的方法，无需非线性光学材料。该方法通过将输入变量编码到光波前相位中，并利用衍射结构进行转换，从而并行逼近各种非线性函数，并被证明是一种通用的函数逼近器，可用于处理多变量和复值函数。实验和数值结果表明，该方法在并行计算和紧凑型光学设置方面具有潜力。

**AI_Comments:** 这项工作在光学计算领域具有重要意义，因为它提出了一种无需昂贵的非线性光学材料即可实现非线性计算的新方法。通过利用衍射处理器和线性光学，该技术有望实现超快和大规模并行的计算。然而，需要进一步研究其在实际应用中的鲁棒性、可扩展性和精度限制。

<details>
  <summary>Details</summary>

**Motivation:** 实现非线性计算对于信息处理任务至关重要，但光学系统实现非线性函数面临挑战，因为光学非线性通常较弱且能耗高。该研究旨在克服这一限制，无需依赖非线性光学材料，以实现超快和并行的光学计算系统。

**Method:** 通过优化的衍射处理器（由无源相位相关表面组成）利用线性光学实现大规模非线性计算。输入变量被编码到光波前相位中（例如，通过空间光调制器），然后通过具有空间变化点扩散函数的优化衍射结构进行转换，以并行生成逼近一系列独特非线性函数的输出强度。

**Result:** 证明了该架构可以作为任意一组带限非线性函数的通用函数逼近器，包括多变量和复值函数。通过数值模拟并行计算了一百万个不同的非线性函数，并在衍射光学处理器的输出端以波长尺度的空间密度精确执行。通过实验验证了该框架，在单次曝光中逼近了35个不同的非线性函数，使用了包括空间光调制器和图像传感器在内的紧凑型装置。

**Conclusion:** 衍射光学处理器是可扩展的平台，可用于超大规模并行通用非线性函数逼近，为基于线性材料的模拟光学计算开辟了新的可能性。

> **ai_Abstract:** 本研究提出了一种利用线性光学和优化的衍射处理器实现大规模非线性计算的方法。通过将输入变量编码到光波前相位中，并利用衍射结构进行转换，该系统能够并行逼近各种非线性函数，无需非线性光学材料。研究证明了该方法作为通用函数逼近器的能力，并展示了其在并行计算和紧凑型光学设置中的潜力。

> **摘要翻译:** 非线性计算对于广泛的信息处理任务至关重要，但由于光学非线性的性质较弱且能耗较高，使用光学系统实现非线性函数仍然是一个挑战。克服这一限制而不依赖于非线性光学材料可能会为超快和并行的光学计算系统带来前所未有的机遇。在这里，我们证明了可以使用线性光学通过由无源相位相关表面组成的优化的衍射处理器来实现大规模非线性计算。在此框架中，非线性函数的输入变量被编码到光波前相位中（例如，通过空间光调制器），并通过具有空间变化的点扩散函数的优化衍射结构进行转换，以并行生成逼近一系列独特的非线性函数的输出强度。我们提供了证明，证明该架构可以作为任意一组带限非线性函数的通用函数逼近器，还涵盖了多变量和复值函数。我们还通过数值模拟证明了在衍射光学处理器的输出端以波长尺度的空间密度精确执行一百万个不同的非线性函数的并行计算。此外，我们使用就地光学学习对该框架进行了实验验证，并使用包括空间光调制器和图像传感器在内的紧凑型装置在单次曝光中逼近了35个不同的非线性函数。这些结果将衍射光学处理器确立为超大规模并行通用非线性函数逼近的可扩展平台，为基于线性材料的模拟光学计算带来了新的能力。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phco'></a>
## astro-ph.CO 

### [462] [Reconstructing Galaxy Cluster Mass Maps using Score-based Generative Modeling](https://arxiv.org/abs/2410.02857)
> *使用基于分数的生成模型重建星系团质量图*

*Alan Hsu, Matthew Ho, Joyce Lin, Carleen Markey, Michelle Ntampaka, Hy Trac, Barnabás Póczos* | **Category: astro-ph.CO, cs.LG** | **Updated: 2025-07-10**

**Keywords:** 星系团, 密度图, 基于分数的生成模型, 扩散模型, SZ和X射线图像

**Comment:** Published in the Open Journal of Astrophysics

> **TL;DR:** 该研究提出了一种使用基于分数的生成模型（扩散模型）来重建星系团气态和暗物质密度图的新方法，该模型以模拟的SZ和X射线图像作为条件输入，能够准确重建密度剖面，并在光谱域表现出色，显示了其在学习可观测数据与星系团密度分布之间非线性映射方面的潜力。

**AI_Comments:** 该研究提出了一种利用先进的生成模型（扩散模型）来解决天体物理学中一个重要问题的创新方法，即星系团质量图的重建。该方法通过模拟数据展示了其准确性和潜力，为未来处理真实观测数据奠定了基础。然而，实际应用中模型的鲁棒性、计算效率以及对不同类型噪声的敏感性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 提出一种新的方法来重建星系团的气态和暗物质投影密度图。

**Method:** 使用基于分数的生成模型（扩散模型），以模拟的SZ和X射线图像作为条件输入，通过从学习到的数据后验进行采样来生成相应气态和暗物质图的实现。

**Result:** 模型能够准确重建径向密度剖面的均值和展宽，区分不同质量大小的星系团；在光谱域，偏差和互相关系数接近于1，表明模型可以精确探测大尺度和小尺度的星系团结构。

**Conclusion:** 基于分数的模型能够学习输入可观测数据与星系团基本密度分布之间强大、非线性和无偏的映射关系。这些扩散模型可以进一步微调并推广，以接纳更多可观测数据作为输入，甚至真实观测数据，并预测未知的星系团密度分布。

> **ai_Abstract:** 本研究介绍了一种利用基于分数的生成模型（扩散模型）重建星系团气态和暗物质密度图的新方法。该模型以模拟的SZ和X射线图像为条件输入，能够生成相应的密度图。通过与宇宙学模拟数据的对比，验证了模型在空间和光谱域的有效性，证明了其在学习可观测数据与星系团密度分布之间非线性映射方面的潜力，并展望了其在处理真实观测数据方面的应用前景。

> **摘要翻译:** 我们提出了一种利用基于分数的生成模型来重建星系团气态和暗物质投影密度图的新方法。我们的扩散模型以模拟的SZ和X射线图像作为条件输入，通过从学习到的数据后验进行采样来生成相应气态和暗物质图的实现。我们使用来自宇宙学模拟的模拟数据来训练和验证我们模型的性能。该模型能够准确重建空间域中的径向密度剖面的均值和展宽，表明该模型能够区分不同质量大小的星系团。在光谱域，该模型实现了接近于1的偏差和互相关系数，表明该模型可以精确探测大尺度和小尺度的星系团结构。我们的实验证明了分数模型在学习输入可观测数据与星系团基本密度分布之间强大、非线性和无偏的映射关系方面的能力。这些扩散模型可以进一步微调并推广，不仅可以接纳更多的可观测数据作为输入，还可以接纳真实观测数据，并预测未知的星系团密度分布。

</details>

[⬆️ 返回分类顶部](#astro-phco) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstat-mech'></a>
## cond-mat.stat-mech 

### [481] [Collaborative filtering based on nonnegative/binary matrix factorization](https://arxiv.org/abs/2410.10381)
> *基于非负/二元矩阵分解的协同过滤*

*Yukino Terui, Yuka Inoue, Yohei Hamakawa, Kosuke Tatsumura, Kazue Kudo* | **Category: cond-mat.stat-mech, cs.IR, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 协同过滤, 非负/二元矩阵分解, 伊辛机, 稀疏数据, 推荐系统

**Comment:** 12 pages, 8 figures

> **TL;DR:** 本研究提出了一种改进的非负/二元矩阵分解（NBMF）算法用于协同过滤，并利用低延迟伊辛机加速计算。实验证明该方法在稀疏数据上是有效的。

**AI_Comments:** 这项研究将非负/二元矩阵分解（NBMF）技术成功应用于稀疏数据以改进协同过滤，这是一个重要的进展，因为以往的研究主要集中在稠密数据上。使用低延迟伊辛机来加速NBMF的计算是一个创新的方法，为提高推荐系统的效率提供了新的途径。然而，论文可以进一步探讨该方法在不同规模和类型的稀疏数据集上的表现，以及与现有其他协同过滤方法的详细比较。

<details>
  <summary>Details</summary>

**Motivation:** 协同过滤在处理包含大量未评级项目的评分数据时，需要利用用户-项目相似性。以往的NBMF研究主要应用于图像等稠密数据，而本研究旨在将改进的NBMF应用于稀疏数据。

**Method:** 提出了一种改进的非负/二元矩阵分解（NBMF）算法，并利用低延迟伊辛机来实现该算法，以应用于协同过滤。

**Result:** 利用低延迟伊辛机实现提出的NBMF方法在计算时间上具有优势，并且该方法在稀疏数据上应用有效。

**Conclusion:** 本研究成功地将改进的NBMF算法应用于稀疏数据以进行协同过滤，并证明了使用低延迟伊辛机可以提高计算效率。

> **ai_Abstract:** 本研究提出了一种用于协同过滤的改进非负/二元矩阵分解（NBMF）算法，并利用低延迟伊辛机加速其在稀疏数据上的计算。实验结果表明，该方法在计算时间和处理稀疏数据方面均具有优势。

> **摘要翻译:** 协同过滤通过利用基于评分数据的用户-项目相似性来生成推荐，而评分数据通常包含大量未评级项目。
本论文提出了一种改进的非负/二元矩阵分解（NBMF）算法用于协同过滤，并证明了在NBMF中利用低延迟伊辛机在计算时间方面具有优势。
虽然之前的研究主要将NBMF应用于图像等稠密数据，但本研究将改进的NBMF应用于稀疏数据。
结果表明，使用低延迟伊辛机来实现所提出的方法是有益的。

</details>

[⬆️ 返回分类顶部](#cond-matstat-mech) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [493] [SecRef*: Securely Sharing Mutable References Between Verified and Unverified Code in F*](https://arxiv.org/abs/2503.00404)
> *SecRef*: 在 F* 中安全地共享可变引用于已验证和未经验证的代码之间*

*Cezar-Constantin Andrici, Danel Ahman, Catalin Hritcu, Ruxandra Icleanu, Guido Martínez, Exequiel Rivas, Théo Winterhalter* | **Category: cs.PL, cs.CR** | **Updated: 2025-07-11**

**Keywords:** SecRef*, 安全编译, 可变引用共享, F*, 高阶契约

**Comment:** ICFP'25 preprint

> **TL;DR:** SecRef* 是一个安全编译框架，用于保护在 F* 中验证的状态程序免受链接的未经验证代码的侵害，并允许动态共享可变引用。它通过跟踪可共享和不可共享的引用来简化验证过程，确保不可共享引用的内容在调用未经验证代码后保持不变。该框架使用高阶契约将验证代码的期望转换为动态检查，并通过单子表示形式证明了安全互操作性。

**AI_Comments:** 这项工作在解决已验证代码与未经验证代码之间安全交互的问题上迈出了重要一步，特别是在处理可变状态共享的场景下。通过形式化验证和动态检查相结合的方法，SecRef* 提供了一个健壮的解决方案。其对单调状态效应的单子表示形式的贡献也可能对其他并发和状态管理的研究具有借鉴意义。然而，该框架的实际性能和可扩展性，尤其是在处理大规模或复杂交互时，可能需要进一步的评估。

<details>
  <summary>Details</summary>

**Motivation:** 在 F* 中验证的状态程序需要一种安全的方式来与未经验证的代码进行交互，同时保护程序的完整性并确保状态的一致性。

**Method:** SecRef* 是一个安全编译框架，它通过跟踪可共享和不可共享的引用来保护 F* 中验证的状态程序。它将验证代码的期望转换为动态检查，并使用高阶契约来处理共享引用。该框架基于 F* 的单调状态效应，并提供了该效应的第一个单子表示形式。

**Result:** SecRef* 框架能够安全地实现已验证代码与未经验证代码之间的互操作性。通过使用高阶契约进行动态检查，可以确保共享引用的安全。该框架还提供了单调状态效应的第一个单子表示形式，这可能具有独立的研究价值。此外，SecRef* 已成功应用于一个简单的多线程协作调度器，该调度器已通过验证并能安全地与未经验证的线程进行交互。

**Conclusion:** SecRef* 框架为在 F* 中验证的状态程序提供了一种安全且经过形式化证明的与未经验证代码进行交互的方式，确保了状态的安全共享和程序的完整性。

> **ai_Abstract:** 本文介绍了一种名为 SecRef* 的安全编译框架，它允许在 F* 中经过验证的代码与未经验证的代码之间安全地共享可变引用。该框架通过跟踪引用的可共享性，并利用高阶契约进行动态检查，来确保与未经验证代码交互时的安全性和正确性。研究人员还提出了单调状态效应的单子表示形式，并成功地将 SecRef* 应用于一个多线程调度器的验证。

> **摘要翻译:** 我们引入了 SecRef*，一个安全编译框架，用于保护在 F* 中验证的状态程序免受链接的未经验证代码的侵害，并与之动态共享类 ML 的可变引用。为了简化在此场景下的程序验证，我们提出了一种跟踪哪些引用可以与未经验证代码共享，哪些引用不可以共享的方法，因此其内容在调用未经验证代码后保证不变。这种不可共享引用的通用属性在已验证程序可以依赖的接口中暴露出来，以便在调用未经验证代码时使用。其余的已验证代码所期望的来自未经验证代码的精化类型以及前置条件和后置条件，通过使用高阶契约转换为关于共享引用的动态检查。我们在 F* 中形式化地证明了该策略确保了与未经验证代码的健全和安全互操作性。由于 SecRef* 构建在 F* 的单调状态效应之上，这些证明依赖于该效应的第一个单子表示形式，这是我们工作的一个贡献，可能具有独立的研究价值。最后，我们使用 SecRef* 构建了一个简单的协作多线程调度器，该调度器已通过验证，并能安全地与未经验证的线程进行交互。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [501] [Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists](https://arxiv.org/abs/2507.08796)
> *Filter Equivariant Functions: A Symmetric Account of Length-General Extrapolation on Lists*

*Owen Lewis, Neil Ghani, Andrew Dudzik, Christos Perivolaropoulos, Razvan Pascanu, Petar Veličković* | **Category: cs.PL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** Filter Equivariant Functions, Extrapolation, List Functions, Amalgamation Algorithm, Simplicial Structures

**Comment:** 18 pages, 2 figures

> **TL;DR:** The paper introduces 'filter equivariant functions' as a class of functions that extrapolate well on lists by maintaining predictable behavior when elements are removed. It proves theorems, relates them to map equivariant functions, and presents a geometric account. The key result is an 'amalgamation algorithm' that constructs filter-equivariant functions by analyzing their behavior on sublists.

**AI_Comments:** The paper introduces a novel class of functions, 'filter equivariant functions,' which offer a principled approach to extrapolation for list-based data. The theoretical underpinnings and the proposed amalgamation algorithm are significant contributions. The geometric interpretation adds an interesting dimension to understanding these functions. Further research could explore the practical applications of these functions in machine learning or other domains where extrapolation is crucial.

<details>
  <summary>Details</summary>

**Motivation:** The paper addresses the challenge of defining 'good' extrapolants for functions, arguing that they should follow predictable rules, specifically when elements are removed from the input list.

**Method:** The paper introduces a new semantic class of functions called 'filter equivariant functions'. It proves theorems about this class, relates it to map equivariant functions, and provides a geometric interpretation. The core method is the 'amalgamation algorithm' which constructs filter-equivariant functions by examining their behavior on sublists.

**Result:** The paper introduces and defines filter equivariant functions, proves basic theorems about them, establishes a relationship with map equivariant functions, and presents a geometric account. The main result is the amalgamation algorithm for constructing these functions.

**Conclusion:** The paper introduces filter equivariant functions as a principled way to achieve length-general extrapolation for list functions, with the amalgamation algorithm providing a constructive method based on sublist analysis.

> **ai_Abstract:** This paper introduces filter equivariant functions, a class of functions designed for reliable extrapolation on lists. These functions exhibit predictable behavior even when elements are filtered out. The research proves theoretical properties, connects them to map equivariance, offers a geometric perspective, and presents a novel amalgamation algorithm for their construction by analyzing sublist behavior.

> **摘要翻译:** 函数在已知输入/输出示例之外进行推断时应该是什么样子的？这是一个普遍存在的难题，因为原则上任何匹配这些示例的函数都可以作为正确的推断。我们认为一个“好的”推断应该遵循某些规则，在这里我们研究列表函数中一个特别吸引人的规则标准：即使在移除某些元素时，函数也应该表现得可预测。在函数式编程中，表达这种移除操作的标准方法是使用过滤器函数。因此，我们的论文引入了一个新的函数语义类别——filter equivariant函数。我们展示了这个类别包含有趣的例子，证明了一些关于它的基本定理，并将其与众所周知的map equivariant函数类别联系起来。我们还提供了filter equivariant函数的几何解释，展示了它们如何自然地对应于某些单纯形结构。我们的主要成果是 the amalgamation algorithm，它通过首先研究filter equivariant函数在输入子列表上的行为来构造其输出，这种方式可以完美地进行推断。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [507] [Shifting Work Patterns with Generative AI](https://arxiv.org/abs/2504.11436)
> *生成式人工智能改变工作模式*

*Eleanor Wiske Dillon, Sonia Jaffe, Nicole Immorlica, Christopher T. Stanton* | **Category: econ.GN, cs.LG, q-fin.EC** | **Updated: 2025-07-10**

**Keywords:** 生成式人工智能,工作模式,知识工作者,随机现场实验,邮件处理

**Comment:** 

> **TL;DR:** 生成式人工智能工具主要影响了可独立改变的行为，例如减少邮件处理时间，并未显著改变需要协调的行为，如会议时长。

**AI_Comments:** 该研究提供了生成式人工智能对工作模式影响的初步实证证据，尤其是在独立可控的任务上。然而，其对需要协作的任务的影响有限，这可能为未来研究指明了方向，例如如何更好地将生成式人工智能融入需要团队协作的流程中。

<details>
  <summary>Details</summary>

**Motivation:** 研究生成式人工智能如何改变知识工作者的工作模式。

**Method:** 通过一项为期6个月、跨行业的随机现场实验，对7137名知识工作者进行研究，其中一半人员可以使用集成了电子邮件、文档创建和会议功能的生成式人工智能工具。

**Result:** 使用该工具的员工每周邮件处理时间减少3.6小时（减少31%），文档完成速度有所提升，但会议时长无显著变化。

**Conclusion:** 生成式人工智能工具的使用主要影响了员工可以独立调整的行为，例如减少了邮件处理时间，但对需要协同才能改变的行为（如会议）影响不大。

> **ai_Abstract:** 这项研究通过一项为期6个月的随机现场实验，考察了生成式人工智能对7137名知识工作者工作模式的影响。结果表明，使用生成式人工智能工具的员工每周邮件处理时间显著减少，文档完成速度加快，但会议时间未受影响。这表明生成式人工智能主要影响了可独立调整的工作行为，而非需要协同的工作行为。

> **摘要翻译:** 我们提供了关于生成式人工智能如何改变知识工作者工作模式的证据，该证据来源于一项为期6个月、跨行业的随机现场实验。研究中7137名员工的一半在他们已经用于电子邮件、文档创建和会议的应用程序中获得了生成式人工智能工具的访问权限。我们发现，在工具发布的第一年，该工具的使用主要影响了员工可以独立改变的行为，而未能改变需要协调才能改变的行为：在一半以上样本周数中使用该工具的员工每周减少了3.6小时的邮件处理时间，或减少了31%的邮件处理时间（意向性治疗估计为1.3小时），文档完成速度有所加快，但会议时间没有显著变化。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='statot'></a>
## stat.OT 

### [512] [A Plea for History and Philosophy of Statistics and Machine Learning](https://arxiv.org/abs/2506.22236)
> *为统计学和机器学习的历史与哲学呼吁*

*Hanti Lin* | **Category: stat.OT, cs.LG** | **Updated: 2025-07-11**

**Keywords:** 统计学, 机器学习, 历史, 哲学, 可实现性

**Comment:** 

> **TL;DR:** 该论文认为，将统计学和机器学习的历史与哲学相结合比以往任何时候都更加重要。作者提出了一个案例研究，以说明一个在统计学和机器学习中普遍存在的哲学思想——可实现性原则，并强调了结合历史、哲学和形式认识论的方法论的重要性。

**AI_Comments:** 该论文具有前瞻性，指出了统计学和机器学习交叉领域中被忽视的哲学和历史维度。提出的“可实现性”原则为评估机器学习模型提供了一个新的视角，但其具体应用和验证仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 统计学和机器学习的交叉日益模糊，需要结合历史和哲学来理解这两个领域。

**Method:** 通过一个案例研究，追溯机器学习中的一个哲学思想的根源，并将其与 Neyman 和 Pearson 的早期工作联系起来，提出了“可实现性”原则。

**Result:** 提出了“可实现性”原则，即评估非演绎推理方法的标准应根据具体问题的可实现性进行调整。

**Conclusion:** 统计学和机器学习需要历史和哲学的整合，并且一种结合历史、哲学和形式认识论的方法论是有益的。

> **ai_Abstract:** 本篇论文强调了将历史和哲学方法应用于统计学和机器学习领域的必要性。作者认为，随着这两个领域界限的日益模糊，理解它们的共同根源和哲学基础至关重要。论文通过一个关于“可实现性”原则的案例研究，阐述了如何将 Neyman 和 Pearson 的早期工作与机器学习的实践联系起来，并提出评估推理方法的标准应根据具体问题的实际情况进行调整。最后，作者倡导一种结合历史、哲学和形式认识论的方法论。

> **摘要翻译:** 统计学和机器学习的历史与哲学整合至少可以追溯到 Hacking (1965)，并由 Mayo (1996) 提出，但并未得到持续的跟进。然而，这种整合比以往任何时候都更加紧迫，因为人工智能的最新成功在很大程度上是由机器学习驱动的——这是一个历史上与统计学并行发展的领域。如今，统计学和机器学习的界限日益模糊。我们现在需要双重整合：历史与哲学，以及它们所涉及的两个领域——统计学与机器学习。我将以机器学习（以及形式认识论）中的一个哲学思想为例进行案例研究，其根源可以追溯到 Neyman 和 Pearson 1936 年的著作（这是他们 1933 年经典著作的后续），这个思想常常被低估。这导致了一个认识论原则的阐述——在频率主义统计和机器学习的实践中，它在很大程度上是隐含的，但却被共享的——我称之为可实现性：评估非演绎推理方法的正确标准不应该是固定的，而应该对特定问题背景下可实现的目标敏感。另一种整合也出现在方法论层面，它结合了科学哲学光谱的两个极端：一方面是科学的历史与哲学，另一方面是形式认识论。

</details>

[⬆️ 返回分类顶部](#statot) | [⬆️ 返回总目录](#toc)

