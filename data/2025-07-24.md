# AI-Enhanced arXiv Daily 2025-07-24

<a id='toc'></a>
## 今日总计: 763 篇论文
### 目录
- [cs.CR](#cscr) (19 篇)
- [cs.AI](#csai) (41 篇)
- [cs.LG](#cslg) (106 篇)
- [cs.MA](#csma) (4 篇)
- [cs.RO](#csro) (34 篇)
- [cs.CV](#cscv) (155 篇)
- [cs.HC](#cshc) (37 篇)
- [cs.ET](#cset) (2 篇)
- [cs.SE](#csse) (26 篇)
- [cs.SI](#cssi) (1 篇)
- [cs.NI](#csni) (8 篇)
- [cs.IT](#csit) (16 篇)
- [cs.AR](#csar) (6 篇)
- [cs.DC](#csdc) (18 篇)
- [cs.CY](#cscy) (7 篇)
- [cs.CE](#csce) (3 篇)
- [cs.FL](#csfl) (3 篇)
- [eess.SY](#eesssy) (22 篇)
- [eess.SP](#eesssp) (18 篇)
- [eess.IV](#eessiv) (26 篇)
- [eess.AS](#eessas) (8 篇)
- [cs.CL](#cscl) (80 篇)
- [cs.DS](#csds) (8 篇)
- [cs.GR](#csgr) (7 篇)
- [cs.IR](#csir) (16 篇)
- [cs.NE](#csne) (3 篇)
- [math.NA](#mathna) (17 篇)
- [cs.SD](#cssd) (8 篇)
- [math.DG](#mathdg) (1 篇)
- [physics.med-ph](#physicsmed-ph) (2 篇)
- [physics.acc-ph](#physicsacc-ph) (1 篇)
- [math.OC](#mathoc) (5 篇)
- [cs.LO](#cslo) (4 篇)
- [math.ST](#mathst) (1 篇)
- [econ.GN](#econgn) (1 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [quant-ph](#quant-ph) (7 篇)
- [physics.comp-ph](#physicscomp-ph) (2 篇)
- [cs.CC](#cscc) (1 篇)
- [cs.GT](#csgt) (1 篇)
- [physics.optics](#physicsoptics) (2 篇)
- [stat.ML](#statml) (9 篇)
- [physics.plasm-ph](#physicsplasm-ph) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [physics.ins-det](#physicsins-det) (1 篇)
- [stat.OT](#statot) (1 篇)
- [cond-mat.str-el](#cond-matstr-el) (1 篇)
- [q-bio.QM](#q-bioqm) (3 篇)
- [q-fin.PM](#q-finpm) (1 篇)
- [cs.CG](#cscg) (1 篇)
- [math.LO](#mathlo) (1 篇)
- [stat.AP](#statap) (3 篇)
- [cs.DB](#csdb) (1 篇)
- [stat.ME](#statme) (1 篇)
- [hep-ph](#hep-ph) (1 篇)
- [hep-th](#hep-th) (1 篇)
- [cs.DM](#csdm) (1 篇)
- [gr-qc](#gr-qc) (1 篇)
- [astro-ph.GA](#astro-phga) (1 篇)
- [q-fin.CP](#q-fincp) (2 篇)
- [astro-ph.HE](#astro-phhe) (1 篇)
- [math.CO](#mathco) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [348] [PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python](https://arxiv.org/abs/2507.18075)
> *PyPitfall：Python 中的依赖混乱与软件供应链漏洞*

*Jacob Mahon, Chenxi Hou, Zhihao Yao* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** Python, 软件供应链, 漏洞, 依赖, PyPI

**Comment:** 

> **TL;DR:** PyPitfall对PyPI生态系统中易受攻击的Python依赖关系进行了量化分析，发现大量包存在显式或隐式地允许脆弱版本的问题，旨在提高对Python软件供应链安全的认识。

**AI_Comments:** 该论文通过引入PyPitfall工具，对Python PyPI生态系统中的依赖漏洞进行了大规模的量化分析，其创新性在于提供了详细的数据来量化软件供应链中潜在的风险。这项工作对于提高开发者和组织对Python依赖安全性的认识至关重要，揭示了代码重用带来的便利与潜在安全隐患之间的平衡问题。其重要性在于为后续的漏洞缓解策略和工具开发提供了坚实的数据基础。

<details>
  <summary>Details</summary>

**Motivation:** Python软件开发严重依赖第三方包，而依赖链中的漏洞可能传播，影响下游软件包和应用。PyPI作为官方仓库，缺乏对易受攻击依赖普遍性的全面分析。本文旨在解决这一空白。

**Method:** 本文引入了PyPitfall工具，对PyPI生态系统中易受攻击的依赖关系进行了量化分析。研究分析了378,573个PyPI包的依赖结构。

**Result:** 分析发现，有4,655个包明确要求至少一个已知易受攻击的版本，另有141,044个包在指定范围内允许易受攻击的版本。

**Conclusion:** 通过描绘生态系统范围内的依赖格局和传递性依赖的安全影响，本研究旨在提高人们对Python软件供应链安全的认识。

> **ai_Abstract:** 本研究介绍了PyPitfall，一个对Python包索引（PyPI）生态系统中易受攻击依赖进行量化分析的工具。通过分析近38万个PyPI包的依赖结构，研究发现有大量包（4,655个明确要求，141,044个允许）存在已知漏洞的依赖关系。该工作旨在揭示Python软件供应链中依赖混乱和漏洞传播的现状，以提高对供应链安全的重视。

> **摘要翻译:** Python软件开发严重依赖第三方包。直接和传递性依赖关系创建了一个软件供应链的迷宫。虽然代码重用很方便，但这些依赖链中的漏洞可以通过依赖关系传播，可能影响下游的软件包和应用程序。官方Python包仓库PyPI托管了许多包，但缺乏对易受攻击依赖普遍性的全面分析。本文引入了PyPitfall，对PyPI生态系统中易受攻击的依赖关系进行了量化分析。我们分析了378,573个PyPI包的依赖结构，并识别出4,655个包明确要求至少一个已知易受攻击的版本，以及141,044个包在指定范围内允许易受攻击的版本。通过描述整个生态系统的依赖格局和传递性依赖的安全影响，我们旨在提高人们对Python软件供应链安全的认识。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [354] [An Improved ChaCha Algorithm Based on Quantum Random Number](https://arxiv.org/abs/2507.18157)
> *基于量子随机数的改进ChaCha算法*

*Chao Liu, Shuai Zhao, Chenhao Jia, Gengran Hu, Tingting Cui* | **Category: cs.CR, quant-ph, Primary:94A60, Secondary:68P25, Tertiary:81P94** | **Updated: 2025-07-24**

**Keywords:** ChaCha, 量子随机数, 密码学, 差分攻击, 随机性测试

**Comment:** 20 pages,4 figures

> **TL;DR:** 提出一种基于量子随机数改进的ChaCha算法（QRE-ChaCha），增强了对差分攻击的抵抗力，并通过了随机性测试，同时保持了高效率。

**AI_Comments:** 这篇论文的创新点在于将量子随机数引入ChaCha算法，以应对新兴的AI辅助密码分析和量子计算威胁。通过在关键位置注入量子随机性，显著提升了算法的安全性，尤其是在抵抗差分攻击和密钥流随机性方面。该方法为后量子密码学背景下的流密码设计提供了新的思路，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有ChaCha算法面临AI辅助密码分析和量子计算的挑战，需要加强其安全性。

**Method:** 提出QRE-ChaCha算法，通过将初始常量与量子随机数异或，并在奇数轮中周期性地将量子随机数注入选定的状态字以增强扩散。通过理论安全分析（量子随机性、攻击测试）、基于布尔可满足性问题（SAT）的差分密码分析、NIST和GM/T 0005-2021统计测试套件进行随机性测试，以及测量加密解密速度来评估。

**Result:** 新变体对差分攻击表现出更强的抵抗力，生成的密钥流具有统计随机性，成功通过了NIST和GM/T 0005-2021标准测试，同时保持了原始ChaCha的高效率。

**Conclusion:** 改进的ChaCha算法显著增强了抵抗差分攻击的能力，密钥流通过了统计随机性测试，满足密码应用要求。

> **ai_Abstract:** 本文提出了一种基于量子随机数改进的ChaCha算法（QRE-ChaCha），旨在增强其在面对AI辅助密码分析和量子计算时的安全性。通过将初始常量与量子随机数异或并周期性注入量子随机数到状态字中，QRE-ChaCha显著提高了对差分攻击的抵抗力，并生成具有统计随机性的密钥流。实验评估表明，该算法在保持原始ChaCha高效率的同时，成功通过了多项随机性测试，证实了其在经典和量子攻击下的鲁棒性，满足了密码应用的需求。

> **摘要翻译:** 由于ChaCha在效率高、抗定时攻击和侧信道攻击方面具有优点，它被广泛应用于实时通信和数据流场景。然而，随着AI辅助密码分析和量子计算技术的快速发展，ChaCha密码的安全实现面临严峻挑战。为了进一步加强ChaCha密码的安全性，我们提出了一种基于量子随机数的改进变体，即量子随机数增强型ChaCha（QRE-ChaCha）。具体来说，该设计将初始常量与量子随机数进行异或，并在奇数轮中周期性地将量子随机数注入选定的状态字以增强扩散。与原始ChaCha相比，本变体对差分攻击表现出更强的抵抗力，并生成具有统计随机性的密钥流，从而增强了对经典和量子攻击的鲁棒性。为了评估本ChaCha的安全性与性能，我们的分析分为三个主要部分。首先，我们从量子随机性和攻击测试方面分析其理论安全性，并使用基于布尔可满足性问题（SAT）的自动化搜索方法进行差分密码分析。其次，我们使用NIST统计测试套件和GM/T 0005-2021随机性测试标准对该密码生成的密钥流进行随机性测试。最后，我们通过测量其在各种大小文件上的加密和解密速度来评估其加密和解密性能。根据结果，本ChaCha在抵抗差分攻击方面得到了显著改进，同时保持了原始ChaCha密码的高效率，并且其密钥流成功通过了NIST和GM/T 0005-2021标准的统计随机性测试，满足密码应用要求。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [360] [Information Security Based on LLM Approaches: A Review](https://arxiv.org/abs/2507.18215)
> *基于LLM方法的信息安全：综述*

*Chang Gong, Zhongwen Li, Xiaoqi Li* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 信息安全, 威胁检测, 漏洞识别, 综述

**Comment:** 

> **TL;DR:** 本文综述了大型语言模型（LLM）在信息安全领域的应用进展、技术基础、优势、面临的挑战及未来发展方向。

**AI_Comments:** 这篇综述论文及时地总结了LLM在信息安全领域的最新应用进展，为研究者和从业者提供了全面的视角。其价值在于系统性地梳理了不同应用场景，并指出了当前面临的关键挑战，为未来的研究方向提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 信息安全面临日益严峻的挑战，传统保护手段难以应对复杂多变的威胁。大型语言模型（LLM）作为新兴智能技术，在信息安全领域展现出广阔的应用前景，因此需要对其进行系统性综述。

**Method:** 本文通过系统性综述，重点关注LLM在信息安全中的关键作用，回顾其在恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化等方面的应用进展，并分析了基于神经网络和Transformer架构的LLM技术基础及其在自然语言处理任务中的优势。

**Result:** 研究表明，引入大型语言模型有助于提高安全系统的检测准确性并降低误报率。

**Conclusion:** LLM在信息安全应用中仍面临模型透明度、可解释性和场景适应性等挑战。未来需要进一步探索模型结构优化和泛化能力提升，以实现更智能、更精准的信息安全保护系统。

> **ai_Abstract:** 这篇综述论文探讨了大型语言模型（LLM）在信息安全领域的应用。文章系统回顾了LLM在恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化等方面的进展，并分析了其技术基础和优势。研究指出，LLM能提高安全系统的检测准确性和降低误报率。同时，论文也指出了LLM在模型透明度、可解释性和场景适应性方面面临的挑战，并展望了未来模型优化和泛化能力提升的方向。

> **摘要翻译:** 信息安全正面临日益严峻的挑战，传统保护手段难以应对复杂多变的威胁。近年来，作为一种新兴的智能技术，大型语言模型（LLM）在信息安全领域展现出广阔的应用前景。本文重点关注LLM在信息安全中的关键作用，系统综述了其在恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化方面的应用进展，并探讨了其在增强安全防护性能方面的潜力。本文基于神经网络和Transformer架构，分析了大型语言模型的技术基础及其在自然语言处理任务中的优势。结果表明，引入大型语言模型有助于提高安全系统的检测精度并降低误报率。最后，本文总结了当前的应用成果，并指出其在模型透明度、可解释性和场景适应性等方面仍面临挑战。有必要进一步探索模型结构的优化和泛化能力的提高，以实现更智能、更准确的信息安全保护系统。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [366] [Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models](https://arxiv.org/abs/2507.18249)
> *Auto-SGCR: 使用IEC 61850标准模型自动生成智能电网网络靶场*

*Muhammad M. Roomi, S. M. Suhail Hussain, Ee-Chien Chang, David M. Nicol, Daisuke Mashima* | **Category: cs.CR, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 智能电网, 网络靶场, IEC 61850, 自动化, 网络安全

**Comment:** 12 pages

> **TL;DR:** 本文提出了Auto-SGCR，一个用于自动生成智能电网网络靶场的框架。它通过引入一种基于IEC 61850的新型建模语言（SG-ML）来解决现有网络靶场手动设置、成本高昂和功能受限等挑战。

**AI_Comments:** 该论文的创新之处在于利用标准化建模语言（基于IEC 61850的SG-ML）自动化智能电网网络靶场的生成，这显著降低了设置所需的专业知识、成本和时间。工具链和模型的开源是促进智能电网网络安全研究和培训领域更广泛采用、可重现性和协作开发的关键一步。这解决了对高保真、可配置和可访问测试环境的迫切需求。

<details>
  <summary>Details</summary>

**Motivation:** 过去十年中，电网数字化使其日益容易受到网络攻击，因此迭代的网络安全测试和专家培训至关重要。高保真网络靶场对于评估和训练不可或缺，但在生产环境中进行此类实验通常不可行。然而，现有网络靶场的设计和实施需要广泛的领域知识，成本高昂，且在可配置性、可访问性、可移植性和可重现性方面存在限制。

**Method:** 本文首先定义了一种名为智能电网建模语言（SG-ML）的人机友好型XML建模语言，该语言整合了IEC 61850系统配置语言文件。随后，开发了一个工具链来解析SG-ML模型文件并自动实例化一个功能性的智能电网网络靶场。开发的SG-ML模型易于共享和修改，以实现任何网络靶场的重现或定制。

**Result:** 本文提出了一个自动化的智能电网网络靶场生成框架（Auto-SGCR）。通过大规模变电站模型的案例研究，展示了Auto-SGCR的应用。该工具链以及示例SG-ML模型已开源。

**Conclusion:** 本文成功提出了一个用于生成智能电网网络靶场的自动化框架（Auto-SGCR），通过提供基于IEC 61850标准模型的可配置、可移植和可重现的解决方案，解决了当前方法和系统的局限性。

> **ai_Abstract:** 本文介绍了Auto-SGCR，一个用于自动生成智能电网网络靶场的框架。它通过定义一种基于IEC 61850标准的XML建模语言（SG-ML），解决了手动设置、成本高昂和现有网络靶场功能受限的挑战。文中开发了一个工具链来解析SG-ML模型并自动实例化功能性网络靶场，从而增强了可配置性、可访问性、可移植性和可重现性。该框架的效用通过案例研究得到验证，并且其组件已开源。

> **摘要翻译:** 在过去十年中，电网的数字化使其越来越容易受到网络攻击。迭代的网络安全测试对于应对新兴攻击向量和确保关键基础设施的可靠性至关重要。此外，这些测试可用于评估网络安全配置、网络安全措施对抗各种攻击向量的有效性，以及培训智能电网网络安全专家防御系统。进行广泛的实验缩小了学术研究与生产环境之间的差距。高保真网络靶场至关重要，因为在生产环境中使用此类实验和培训通常是不可行的。然而，网络靶场的设计和实施需要基础设施的物理和网络方面的广泛领域知识。此外，设置和维护网络靶场的成本很高。此外，大多数现有的智能电网网络靶场都被设计为一次性、专有系统，并且在可配置性、可访问性、可移植性和可重现性方面受到限制。为了应对这些挑战，本文提出了一种自动化的智能电网网络靶场生成框架。首先定义了一种名为智能电网建模语言（SG-ML）的人机友好型XML建模语言，该语言结合了IEC 61850系统配置语言文件。随后，开发了一个工具链来解析SG-ML模型文件并自动实例化一个功能性智能电网网络靶场。开发的SG-ML模型可以轻松共享和/或修改，以重现或定制任何网络靶场。通过大规模变电站模型的案例研究演示了Auto-SGCR的应用。该工具链和示例SG-ML模型已经开源。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [372] [LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models](https://arxiv.org/abs/2507.18302)
> *LoRA-Leak：针对LoRA微调语言模型的成员推断攻击*

*Delong Ran, Xinlei He, Tianshuo Cong, Anyu Wang, Qi Li, Xiaoyun Wang* | **Category: cs.CR, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** LoRA, 成员推断攻击, 语言模型, 隐私保护, LoRA-Leak

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 尽管LoRA微调参数量小，LoRA微调的语言模型仍然容易受到成员推断攻击，且预训练模型会加剧信息泄露。

**AI_Comments:** 这项研究揭示了LoRA微调模型在成员推断攻击下的脆弱性，挑战了LoRA数据天生安全的普遍误解。其创新点在于强调了预训练模型在信息泄露中的作用，并提出了一个全面的评估框架LoRA-Leak。研究结果对于指导专业语言模型提供商的数据隐私保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管LoRA因其轻量级和高性能广泛应用于语言模型微调，但存在一种误解，认为LoRA微调数据对成员推断攻击（MIAs）是不可攻击的。本文指出，现有MIAs忽视了利用预训练模型可能导致更多信息泄露的问题。

**Method:** 本文引入了LoRA-Leak，一个针对语言模型微调数据集成员推断攻击（MIAs）的整体评估框架。LoRA-Leak包含了十五种成员推断攻击，其中包括十种现有MIAs和五种利用预训练模型作为参考的改进MIAs。研究者将LoRA-Leak应用于三个先进的语言模型和三个流行的自然语言处理任务中。

**Result:** 实验证明，基于LoRA微调的语言模型仍然容易受到成员推断攻击（例如，在保守微调设置下AUC为0.775）。研究还发现，只有dropout和在微调期间排除特定的语言模型层能有效缓解MIA风险，同时保持模型实用性。

**Conclusion:** 在“预训练和微调”范式下，预训练模型的存在使得成员推断攻击对于基于LoRA的语言模型来说是一个更严重的风险。研究结果旨在为专业语言模型提供商提供数据隐私保护的指导。

> **ai_Abstract:** 本文提出了LoRA-Leak，一个评估针对LoRA微调语言模型成员推断攻击的框架。研究发现，尽管LoRA参数量小，但微调后的模型仍易受攻击，且预训练模型会加剧信息泄露。LoRA-Leak整合了现有及改进的MIAs，实验证明LoRA微调模型在多种任务上均不安全。研究还发现dropout和排除特定层是有效的防御措施，强调了预训练模型在MIA风险中的关键作用，并为数据隐私保护提供了指导。

> **摘要翻译:** 语言模型（LMs）通常遵循“预训练和微调”范式，其中通用的预训练模型可以进行微调以适应各种专业领域。低秩适应（LoRA）因其轻量级的计算成本和卓越的性能而在LM微调中得到最广泛的应用。由于LoRA调整的参数比例相对较小，可能会产生一种误导性的印象，即LoRA微调数据对成员推断攻击（MIAs）是不可攻击的。然而，我们发现利用预训练模型可以导致更多的信息泄露，这被现有MIAs所忽视。因此，我们引入了LoRA-Leak，一个针对LMs微调数据集的MIAs的整体评估框架。LoRA-Leak包含了十五种成员推断攻击，其中包括十种现有MIAs和五种利用预训练模型作为参考的改进MIAs。在实验中，我们将LoRA-Leak应用于三个先进的LMs，跨越三个流行的自然语言处理任务，证明了基于LoRA的微调LMs仍然容易受到MIAs的攻击（例如，在保守微调设置下AUC为0.775）。我们还将LoRA-Leak应用于不同的微调设置，以了解由此产生的隐私风险。我们进一步探索了四种防御措施，发现只有dropout和在微调期间排除特定的LM层能有效缓解MIA风险，同时保持实用性。我们强调，在“预训练和微调”范式下，预训练模型的存在使得MIA对于基于LoRA的LMs来说是一个更严重的风险。我们希望我们的发现能为专业LM提供商提供数据隐私保护的指导。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [378] [Conformidade com os Requisitos Legais de Privacidade de Dados: Um Estudo sobre Técnicas de Anonimização](https://arxiv.org/abs/2507.18360)
> *数据隐私法律要求合规性：匿名化技术研究*

*André Menolli, Luiz Fernando Nunes, Thiago A. Coleti* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 数据匿名化, 隐私保护, LGPD, GDPR, 数据实用性

**Comment:** in Portuguese language

> **TL;DR:** 本研究分析了聚合、泛化、扰动和k-匿名等数据匿名化技术，评估它们在符合LGPD和GDPR等法律要求以及数据实用性方面的有效性，发现不同方法的效果差异显著，需要平衡隐私和数据效用。

**AI_Comments:** 该研究切合当前数据隐私保护的法律要求热点，对数据匿名化技术进行了实证分析。其创新点在于评估了不同匿名化技术在实际数据集上的有效性差异，并明确指出了隐私与数据实用性之间的权衡挑战。这对于软件开发人员和数据管理人员在实际应用中选择合适的匿名化策略具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着巴西的《通用数据保护法》(LGPD)和欧盟的《通用数据保护条例》(GDPR)等法律的实施，个人数据保护成为软件开发的核心议题。数据匿名化作为强制性的软件质量标准之一，本研究旨在分析其技术以确保符合法律要求。

**Method:** 研究调查并应用了聚合、泛化、扰动和k-匿名等数据匿名化技术。这些技术被应用于包含个人和敏感数据的数据集进行评估。

**Result:** 分析显示，每种匿名化方法的有效性存在显著差异。

**Conclusion:** 研究强调了在确保数据隐私和保持数据实用性之间取得平衡的必要性。

> **ai_Abstract:** 本文针对巴西LGPD和欧盟GDPR等数据保护法律背景下强制要求的数据匿名化，分析了聚合、泛化、扰动和k-匿名等多种匿名化技术。研究将这些技术应用于包含敏感数据的数据集，评估其在满足法律合规性和保持数据实用性方面的有效性。结果表明，不同匿名化方法的有效性差异显著，强调了在数据隐私保护和数据实用性之间进行权衡的重要性。

> **摘要翻译:** 个人数据保护已成为软件开发中的核心议题，尤其是在巴西通用数据保护法（LGPD）和欧盟通用数据保护条例（GDPR）实施之后。随着这些法律的强制执行，某些软件质量标准变得强制性，例如数据匿名化，这是这些法规所涉及的主要方面之一。本文旨在分析数据匿名化技术，并评估它们在确保符合法律要求和数据用于其预期目的的实用性方面的有效性。聚合、泛化、扰动和k-匿名等技术被调查并应用于包含个人和敏感数据的数据集。分析揭示了每种方法的有效性存在显著差异，突出了平衡隐私和数据实用性的必要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [390] [Scout: Leveraging Large Language Models for Rapid Digital Evidence Discovery](https://arxiv.org/abs/2507.18478)
> *Scout：利用大型语言模型实现快速数字证据发现*

*Shariq Murtuza* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 数字取证, 大型语言模型, 证据发现, 多模态模型, Scout

**Comment:** 

> **TL;DR:** Scout是一个利用大型语言模型（包括文本和多模态模型）进行数字取证的框架，旨在加速证据识别和初步处理。

**AI_Comments:** Scout的创新之处在于将大型语言模型引入数字取证领域，解决了传统方法在处理海量和多样化数字证据时效率低下、耗时的问题。特别是其结合文本和多模态模型的能力，使其能够处理更广泛的证据类型，包括多媒体文件，这在取证工具中是一个重要的进步。该方法有望大幅提升调查效率并降低误报率。

<details>
  <summary>Details</summary>

**Motivation:** 随着技术进步和数字证据在法律调查中日益增多，取证调查员需要处理海量数据，过程繁琐且耗时，并常遇到大量误报。现有工具虽有帮助，但仍需进一步提升效率和准确性。

**Method:** 本文提出了Scout，一个数字取证框架，它利用大型语言模型进行初步的证据处理和优先级排序。Scout部署基础语言模型来从大量潜在证据文件（如磁盘镜像、网络数据包、内存转储）中识别相关工件。对于文本信息，Scout使用基于文本的大型语言模型；对于音频、图像、视频、办公文档等多媒体文件，Scout则采用多模态模型进行取证分析。

**Result:** Scout能够识别并实现对调查员具有潜在兴趣的证据文件。

**Conclusion:** Scout成功利用大型语言模型（包括文本和多模态）提高了数字证据的初步处理和识别效率，从而加快了取证调查的进程。

> **ai_Abstract:** Scout是一个创新的数字取证框架，旨在解决当前取证工作中数字证据量大、处理耗时且易产生误报的问题。它通过利用大型语言模型（包括文本和多模态模型）对各类数字证据进行初步处理和优先级排序，从而实现对潜在相关证据文件的快速识别，显著提升了取证效率。

> **摘要翻译:** 近期技术进步以及技术在日常活动中的普及，导致数字证据在越来越多的法律调查中涉案的可能性大大增加。消费级硬件正变得越来越强大，内存和存储容量不断扩大，处理器能力也得到增强。取证调查员在正在进行的调查中经常需要筛选数千兆字节的数据，这使得过程变得繁琐。内存取证、磁盘分析都得到了最先进工具的良好支持，这些工具通过提供字符串搜索、分析图像文件等功能，显著降低了取证调查员所需付出的努力。在调查过程中，会识别出许多需要降低的误报。这项工作提出了Scout，一个利用大型语言模型执行初步证据处理和优先级排序的数字取证框架。Scout部署基础语言模型来从大量潜在证据文件（磁盘镜像、捕获的网络数据包、内存转储等）中识别相关工件，而这些工件原本需要更长时间才能被识别。Scout采用基于文本的大型语言模型，可以轻松处理包含文本信息的文件。对于音频、图像、视频、办公文档等多媒体文件的取证分析，Scout则采用多模态模型。Scout能够识别并实现对调查员具有潜在兴趣的证据文件。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [402] [Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment](https://arxiv.org/abs/2507.18631)
> *层感知表示过滤：净化微调数据以保持大型语言模型安全对齐*

*Hao Li, Lijun Li, Zhenghao Lu, Xianyi Wei, Rui Li, Jing Shao, Lei Sha* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型安全, 微调, 数据过滤, 安全对齐, 层感知表示

**Comment:** 

> **TL;DR:** 本文提出LARF方法，通过识别LLM中的安全敏感层并利用其表示来过滤微调数据中隐藏的安全退化特征，从而减轻微调导致的安全对齐退化。

**AI_Comments:** LARF方法的创新之处在于其“层感知表示过滤”机制，它超越了表面数据特征，深入到模型内部的表示层来识别潜在的安全隐患。这种方法对于提高大型语言模型在实际应用中的鲁棒性和安全性具有重要意义，尤其是在数据质量难以完全保证的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 尽管使用看似良性的下游数据集进行微调，大型语言模型（LLMs）的安全对齐仍可能受到损害，使其更容易受到恶意指令的影响。研究表明，微调数据中常包含表面不易识别的安全退化特征，这些特征在微调过程中会显著降低LLMs的安全对齐。

**Method:** 本文提出LARF（层感知表示过滤）方法。该方法识别LLM中安全敏感的层，并利用这些层的表示来检测后训练数据集中哪些样本包含安全退化特征。

**Result:** 实验结果表明，LARF能够有效识别具有安全退化特征的良性数据。移除此类数据后，微调导致的安全对齐退化得到缓解。

**Conclusion:** LARF方法通过过滤微调数据中隐藏的安全退化特征，有效减轻了微调过程对大型语言模型安全对齐的损害，从而有助于保持LLM的安全性。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在微调过程中可能出现安全对齐退化的问题，提出了一种名为LARF（层感知表示过滤）的新方法。研究发现，即使是看似无害的微调数据也可能包含隐藏的安全退化特征。LARF通过识别LLM中的安全敏感层，并利用这些层的表示来检测并过滤掉含有这些有害特征的数据样本。实验证明，LARF能有效识别并移除此类数据，从而显著减轻微调造成的安全对齐损害，有助于维护LLM的安全性。

> **摘要翻译:** 随着大型语言模型（LLMs）的快速发展和日益普及，对齐模型的微调已成为使其适应实际应用的关键步骤，这使得微调过程的安全性比以往任何时候都更加重要。然而，最近的研究强调了一个严峻的挑战：即使使用看似良性的下游数据集进行微调，对齐LLMs的安全性也可能受到损害，使其更容易受到恶意指令的影响。在本文中，我们展示了微调数据集通常包含表面不易识别的安全退化特征的样本。这些样本在微调过程中会显著降低LLMs的安全对齐。为了解决这个问题，我们提出了LARF，一种层感知表示过滤方法。该方法识别LLM中安全敏感的层，并利用它们的表示来检测后训练数据集中哪些数据样本包含安全退化特征。实验结果表明，LARF可以有效识别具有安全退化特征的良性数据。移除此类数据后，微调导致的安全对齐退化得到缓解。请访问我们的代码：https://github.com/LLLeoLi/LARF。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [522] [PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data](https://arxiv.org/abs/2504.03173)
> *PPFPL：针对非独立同分布数据中毒攻击的跨筒仓隐私保护联邦原型学习*

*Hongliang Zhang, Jiguo Yu, Fenghua Xu, Chunqiang Hu, Yongzhao Zhang, Xiaofen Wang, Zhongyuan Yu, Xiaosong Zhang* | **Category: cs.CR, cs.DC** | **Updated: 2025-07-24**

**Keywords:** 联邦学习, 隐私保护, 数据投毒攻击, 非独立同分布, 原型学习

**Comment:** 

> **TL;DR:** 本文提出PPFPL框架，通过使用原型作为模型更新和双服务器安全聚合，有效抵御非独立同分布数据上的数据投毒攻击，同时保护隐私。

**AI_Comments:** 该论文的创新点在于引入了“原型”作为模型更新，以解决非独立同分布数据中毒问题，并结合双服务器安全聚合来增强鲁棒性。这对于提高联邦学习在恶意环境下的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐私保护联邦学习（PPFL）解决方案在处理被投毒的非独立同分布（Non-IID）数据时，难以有效提高跨筒仓PPFL的性能，且PPFL易受数据投毒攻击。

**Method:** 本文提出PPFPL框架，通过采用原型作为客户端提交的模型更新来消除被篡改数据分布对联邦学习的影响。此外，利用两个服务器通过安全聚合协议实现拜占庭鲁棒聚合，以大大减少恶意客户端的影响。

**Result:** 理论分析证实了PPFPL的收敛性。在公开数据集上的实验结果表明，PPFPL在非独立同分布条件下能有效抵抗数据投毒攻击。

**Conclusion:** PPFPL框架通过引入原型和双服务器安全聚合，成功解决了现有隐私保护联邦学习在非独立同分布数据中毒攻击下的性能问题，并能有效抵抗此类攻击。

> **ai_Abstract:** 本文提出了PPFPL（隐私保护联邦原型学习）框架，旨在解决跨筒仓隐私保护联邦学习在非独立同分布数据中毒攻击下的性能和鲁棒性问题。PPFPL通过将原型作为客户端的模型更新来抵消被篡改数据分布的影响，并通过双服务器和安全聚合协议实现拜占庭鲁棒聚合，从而有效抵抗数据投毒攻击。理论分析和实验结果均证实了其收敛性和在非独立同分布条件下的有效性。

> **摘要翻译:** 隐私保护联邦学习（PPFL）允许多个客户端通过提交隐藏的模型更新来协作训练深度学习模型。然而，由于客户端分布式训练的性质，PPFL容易受到数据投毒攻击。现有解决方案在被投毒的非独立同分布数据中，难以提高跨筒仓PPFL的性能。为了解决这些问题，本文提出了一种名为PPFPL的隐私保护联邦原型学习框架，该框架在被投毒的非独立同分布数据中提高了跨筒仓联邦学习的性能，同时有效抵抗数据投毒攻击。具体而言，我们采用原型作为客户端提交的模型更新，以消除被篡改数据分布对联邦学习的影响。此外，我们利用两个服务器通过安全聚合协议实现拜占庭鲁棒聚合，这大大减少了恶意客户端的影响。理论分析证实了PPFPL的收敛性，并且在公开数据集上的实验结果表明，PPFPL在非独立同分布条件下能有效抵抗数据投毒攻击。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [551] [Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench](https://arxiv.org/abs/2507.02976)
> *AI生成的修复是否安全？分析SWE-bench上的LLM和Agent补丁*

*Amirali Sajadi, Kostadin Damevski, Preetha Chatterjee* | **Category: cs.CR, cs.LG, cs.SE** | **Updated: 2025-07-24**

**Keywords:** LLM, 代理, 安全性, 漏洞, 代码修复

**Comment:** 

> **TL;DR:** 本研究首次大规模分析了LLM和Agent生成的代码修复补丁的安全性。结果显示，独立LLM比开发者引入的漏洞多9倍，而Agent在更高自主度下也易产生漏洞。漏洞多发于涉及更多文件、更多代码行以及缺少上下文信息的补丁。

**AI_Comments:** 这项研究具有重要的实践意义，它首次大规模揭示了AI（特别是LLM和Agent）在自动代码修复中引入安全漏洞的风险，填补了真实世界场景下安全评估的空白。其创新之处在于使用了大规模的SWE-bench数据集，并对比了独立LLM与Agent框架的表现。研究结果对未来AI辅助软件开发工具的安全设计和部署提出了严峻挑战和明确指导，强调了在自动化过程中整合更强的上下文理解和风险评估机制的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于大型语言模型（LLM）及其代理框架在自动化软件开发任务（如问题解决和程序修复）中的日益普及，尽管现有工作已识别出LLM生成代码中的安全风险，但大多数评估都集中在合成或隔离环境，对于这些系统在真实世界开发环境中的安全性仍存在疑问。

**Method:** 本研究对SWE-bench数据集中的20,000多个问题进行了LLM生成补丁的首次大规模安全分析。评估了独立LLM（Llama 3.3）生成的补丁，并与开发者编写的补丁进行比较。同时，还评估了三个顶级代理框架（OpenHands、AutoCodeRover、HoneyComb）在部分数据上生成的补丁的安全性。最后，分析了代码、问题和项目层面的多种因素，以理解LLM和代理最可能生成不安全代码的条件。

**Result:** 独立LLM引入的新漏洞比开发者多近9倍，其中许多漏洞表现出开发者代码中没有的独特模式。代理工作流也产生大量漏洞，尤其是在赋予LLM更多自主权时，这可能增加误解项目上下文或任务需求的可能性。漏洞更可能发生在涉及文件数量较多、生成代码行数较多，以及缺乏特定代码片段、预期代码行为信息或复现步骤的GitHub问题相关的LLM补丁中。

**Conclusion:** 研究结果表明，上下文因素在生成代码的安全性中起着关键作用，并指出需要开发能够同时考虑代码和问题级别信息的积极风险评估方法，以补充现有的漏洞检测工具。

> **ai_Abstract:** 本研究首次大规模评估了大型语言模型（LLM）及其代理框架在真实世界软件开发中生成修复补丁的安全性。研究利用SWE-bench数据集的20,000多个问题，分析了独立LLM（Llama 3.3）和三个顶级代理框架（OpenHands、AutoCodeRover、HoneyComb）生成的补丁。结果显示，独立LLM引入的漏洞比人工开发者多9倍，且具有独特模式。代理框架在高自主度下也易产生漏洞。漏洞的发生与文件数量、代码行数以及GitHub问题上下文信息不足密切相关。研究强调了上下文因素对代码安全性的关键作用，并呼吁开发结合代码和问题级别信息的积极风险评估方法。

> **摘要翻译:** 大型语言模型（LLM）及其代理框架正越来越多地被采纳以自动化软件开发任务，例如问题解决和程序修复。尽管先前的研究已经识别出LLM生成代码中的安全风险，但大多数评估都集中在合成或隔离设置中，这使得这些系统在真实世界开发环境中的安全性问题悬而未决。在本研究中，我们利用SWE-bench数据集中的20,000多个问题，首次对LLM生成的补丁进行了大规模安全分析。我们评估了独立LLM（Llama 3.3）生成的补丁，并将其与开发者编写的补丁进行比较。我们还在部分数据上评估了三个表现最佳的代理框架（OpenHands、AutoCodeRover、HoneyComb）生成的补丁的安全性。最后，我们分析了广泛的代码、问题和项目层面因素，以了解LLM和代理在何种条件下最有可能生成不安全代码。我们的发现揭示，独立LLM引入的新漏洞比开发者多近9倍，其中许多漏洞表现出开发者代码中没有的独特模式。代理工作流也产生大量漏洞，尤其是在赋予LLM更多自主权时，这可能增加误解项目上下文或任务需求的可能性。我们发现，漏洞更可能发生在LLM补丁中，这些补丁涉及的文件数量较多、生成的代码行数较多，以及GitHub问题缺乏具体的代码片段或关于预期代码行为和复现步骤的信息。这些结果表明，上下文因素在生成代码的安全性中起着关键作用，并指出需要开发能够同时考虑代码和问题级别信息的积极风险评估方法，以补充现有的漏洞检测工具。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [582] [An Empirical Study on Virtual Reality Software Security Weaknesses](https://arxiv.org/abs/2507.17324)
> *虚拟现实软件安全弱点的实证研究*

*Yifan Xu, Jinfu Chen, Zhenyu Qi, Huashan Chen, Junyi Wang, Pengfei Hu, Feng Liu, Sen He* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 虚拟现实安全, 软件弱点, 实证研究, GitHub数据, 用户界面安全

**Comment:** 

> **TL;DR:** 对GitHub上334个VR项目1681个安全弱点进行实证研究，发现VR弱点主要集中在用户界面和资源相关，开发工具风险高于应用，且弱点常在软件诞生时引入。

**AI_Comments:** 这项研究通过构建首个VR软件安全弱点数据集，弥补了现有公共数据库中VR安全数据不足的空白，其创新性在于提出的数据收集框架。研究结果为VR软件开发和安全防护提供了重要的实证见解，尤其指出了用户界面和开发工具是高风险领域，提醒开发者在软件生命周期早期关注安全。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟现实（VR）技术正在变革各行各业，但其安全弱点（包括漏洞）尚未得到充分研究。

**Method:** 本研究调查了GitHub上托管的334个VR项目，分析了1,681个软件安全弱点。由于公共数据库中VR软件安全弱点数据有限，本研究引入了一种新颖的框架，从GitHub提交数据中收集此类弱点，并构建了第一个系统性的VR软件安全弱点数据集。

**Result:** 1. VR弱点严重偏向用户界面弱点，其次是资源相关弱点；2. VR开发工具比VR应用程序带来更高的安全风险；3. VR安全弱点通常在VR软件诞生时引入。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究对GitHub上334个VR项目中的1,681个软件安全弱点进行了首次系统的实证分析。针对公共数据库中VR安全弱点数据稀缺的问题，研究团队开发了一个新颖的框架来从GitHub提交数据中收集并构建了VR软件安全弱点数据集。研究发现，VR弱点主要集中在用户界面和资源相关方面，VR开发工具比VR应用程序具有更高的安全风险，且VR安全弱点往往在软件开发初期即被引入。

> **摘要翻译:** 虚拟现实（VR）作为一项变革性技术已在各行业兴起，但其安全弱点，包括漏洞，却未得到充分研究。本研究调查了GitHub上托管的334个VR项目，检查了1,681个软件安全弱点，旨在了解：VR软件中普遍存在哪些类型的弱点；弱点何时以及如何引入；它们存在了多长时间；以及它们是如何被移除的。由于公共数据库（例如国家漏洞数据库或NVD）中VR软件安全弱点的可用性有限，我们通过引入一种新颖的框架从GitHub提交数据中收集此类弱点，从而准备了第一个系统性的VR软件安全弱点数据集。我们对该数据集的实证研究得出了有用的见解，包括：(i) VR弱点严重偏向用户界面弱点，其次是资源相关弱点；(ii) VR开发工具比VR应用程序带来更高的安全风险；(iii) VR安全弱点通常在VR软件诞生时引入。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [708] [Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment](https://arxiv.org/abs/2507.17850)
> *大规模5G核心网部署中的性能评估与威胁缓解*

*Rodrigo Moreira, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 5G核心网, 性能评估, 威胁缓解, DDoS, 资源配置

**Comment:** 

> **TL;DR:** 本文研究了大规模5G核心网中DDoS攻击对用户设备注册性能的影响，强调了资源配置多样性和基于内核的监控在确保服务水平协议和安全威胁防御中的重要性。

**AI_Comments:** 本文针对大规模5G核心网部署中的实际挑战，特别是性能评估和DDoS威胁缓解，提供了宝贵的实证见解。其创新点在于将混沌工作负载对用户注册性能的影响与资源配置和基于内核的监控相结合，为5G网络的弹性部署提供了具体方向。

<details>
  <summary>Details</summary>

**Motivation:** 大规模软件化5G核心功能部署面临挑战，主要由于其对优化和智能资源配置的依赖。许多研究关注资源分配对复杂部署的影响，但本文特别关注混沌工作负载（如DDoS攻击）对5G网络功能（NFs）和用户设备注册性能的影响。

**Method:** 本文阐明了分布式拒绝服务（DDoS）产生的混沌工作负载对不同网络功能（NFs）上的用户设备注册性能的影响。此外，文章分析了数据包捕获方法，并进行了实证评估。

**Result:** 研究发现，为确保大规模5G核心网部署中的服务水平协议（SLA）合规性，需要多样化的资源配置文件。此外，对数据包捕获方法的分析表明，基于内核的监控在可扩展安全威胁防御方面具有潜力。

**Conclusion:** 本文的实证评估为复杂场景下5G网络功能的有效部署提供了见解。

> **ai_Abstract:** 本文探讨了大规模5G核心网部署中的性能评估和威胁缓解问题。研究通过分析DDoS攻击产生的混沌工作负载对不同网络功能（NFs）和用户设备注册性能的影响，强调了为确保服务水平协议（SLA）合规性而采用多样化资源配置文件的必要性。此外，文章还展示了基于内核的监控在可扩展安全威胁防御方面的潜力，并提供了复杂场景下5G网络功能有效部署的实证见解。

> **摘要翻译:** 大规模软件化5G核心功能的部署带来了重大挑战，因为它们依赖于优化和智能的资源配置来提供服务。许多研究都集中于使用数学模型、排队理论甚至人工智能（AI）来分析资源分配对复杂部署的影响。本文阐明了分布式拒绝服务（DDoS）产生的混沌工作负载对不同网络功能（NFs）上的用户设备注册性能的影响。我们的研究结果强调了多样化资源配置文件的必要性，以确保大规模5G核心网部署中的服务水平协议（SLA）合规性。此外，我们对数据包捕获方法的分析表明，基于内核的监控在可扩展安全威胁防御方面具有潜力。最后，我们的实证评估为复杂场景下5G网络功能的有效部署提供了见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [715] [Learning to Locate: GNN-Powered Vulnerability Path Discovery in Open Source Code](https://arxiv.org/abs/2507.17888)
> *学会定位：GNN驱动的开源代码漏洞路径发现*

*Nima Atashin, Behrouz Tork Ladani, Mohammadreza Sharbaf* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** 漏洞路径发现, 图神经网络, 开源代码, 汇聚点检测, 缓冲区溢出

**Comment:** 8 pages, 5 Figures

> **TL;DR:** 本文提出了VulPathFinder，一个利用图神经网络（GNN）检测漏洞汇聚点并发现漏洞路径的框架，解决了现有规则方法泛化性差的问题，并在基准测试中表现优于现有工具。

**AI_Comments:** 该论文的创新点在于将图神经网络应用于漏洞汇聚点（sink statement）的检测，从而克服了传统规则方法在泛化性上的局限。通过自动化地识别漏洞路径并解释其根本原因，VulPathFinder为开源软件的安全分析提供了更深层次的洞察力，对提升软件安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的漏洞检测方法通常无法解释漏洞的根本原因，即定位漏洞语句和发现导致漏洞激活的路径。尽管SliceLocator等框架能识别漏洞路径，但其依赖于基于规则的汇聚点识别，限制了泛化能力。

**Method:** 本文提出了VulPathFinder框架，通过使用一种新颖的图神经网络（GNN）模型来检测汇聚点语句，从而增强了SliceLocator的方法。该GNN模型捕获语义和句法依赖关系以找到潜在汇聚点（PSPs）。在检测到PSPs后，使用程序切片提取潜在漏洞路径，然后通过将其反馈给目标基于图的检测器进行排序，最终返回最可能的路径，解释检测到的漏洞的根本原因。

**Result:** 在SARD数据集的缓冲区溢出CWE基准测试中，VulPathFinder在发现到已识别PSPs的漏洞路径方面，优于原始的SliceLocator和GNNExplainer（一种通用的GNN可解释性工具）。

**Conclusion:** VulPathFinder通过引入GNN进行汇聚点检测，显著提高了漏洞路径发现的解释性和泛化能力，为理解和修复开源代码中的漏洞提供了更有效的方法。

> **ai_Abstract:** 本文介绍了VulPathFinder，一个可解释的漏洞路径发现框架，旨在通过定位漏洞语句和发现导致漏洞激活的路径来解释检测到的漏洞的根本原因。与依赖预定义规则的现有方法（如SliceLocator）不同，VulPathFinder利用一种新颖的图神经网络（GNN）模型来检测潜在汇聚点（PSPs）。该GNN捕获语义和句法依赖关系，随后结合程序切片提取并排名潜在的漏洞路径。在SARD数据集上的评估表明，VulPathFinder在发现漏洞路径方面优于原始的SliceLocator和GNNExplainer。

> **摘要翻译:** 检测开源软件中的安全漏洞是一项关键任务，在相关研究社区中备受重视。文献中已经提出了几种方法用于检测易受攻击的代码和识别漏洞类别。然而，在通过定位漏洞语句和发现导致漏洞激活的路径来解释检测到漏洞的根本原因方面，仍有工作空间。虽然像SliceLocator这样的框架通过识别漏洞路径提供了解释，但它们依赖于基于规则的汇聚点识别，这限制了它们的泛化能力。在本文中，我们介绍了VulPathFinder，一个可解释的漏洞路径发现框架，它通过利用新颖的图神经网络（GNN）模型来检测汇聚点语句，而不是依赖预定义规则，从而增强了SliceLocator的方法。所提出的GNN捕获语义和句法依赖关系以找到潜在汇聚点（PSPs），这些是漏洞路径结束的候选语句。在检测到PSPs后，程序切片可用于提取潜在的漏洞路径，然后通过将其反馈到目标基于图的检测器进行排名。最终，返回最可能的路径，解释检测到的漏洞的根本原因。我们通过对SARD数据集中缓冲区溢出CWE的基准进行评估，证明了所提出方法的有效性，为相应的检测到的漏洞提供了解释。结果表明，VulPathFinder在发现到已识别PSPs的漏洞路径方面，优于原始的SliceLocator和GNNExplainer（作为一种通用的GNN可解释性工具）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [722] [Formal Verification of the Safegcd Implementation](https://arxiv.org/abs/2507.17956)
> *Safegcd 实现的正式验证*

*Russell O'Connor, Andrew Poelstra* | **Category: cs.CR, cs.LO** | **Updated: 2025-07-23**

**Keywords:** 形式化验证, 模逆元, libsecp256k1, Coq, 比特币

**Comment:** 15 pages; Coq sources can be found at
  https://github.com/BlockstreamResearch/simplicity/tree/c1dddedd553b403da877377e658f17f0d2184cc4/Coq/C/secp256k1
  ; Alectryon preview can be viewed at e.g.
  https://html-preview.github.io/?url=https://github.com/BlockstreamResearch/simplicity/blob/c1dddedd553b403da877377e658f17f0d2184cc4/alectryon/verif_modinv64_impl.v.html

> **TL;DR:** 论文使用Coq和分离逻辑对Bitcoin密码库中模块逆元算法的正确性进行了计算机验证。

**AI_Comments:** 这篇论文通过形式化验证解决了加密库中关键算法的正确性问题，这对于依赖安全性的加密货币（如比特币）至关重要。其创新点在于对一个新颖且实际使用的算法进行了严格的计算机辅助证明，提高了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 比特币等应用中使用的椭圆曲线操作需要模逆元计算。Bernstein和Yang开发了一种新的扩展欧几里得算法并将其整合到libsecp256k1库中，但新算法引入了新的错误风险。

**Method:** 使用Coq证明助手和Verifiable C的分离逻辑，完成了libsecp256k1中一个模逆元实现的正确性计算机验证证明。

**Result:** 完成了libsecp256k1中一个模逆元实现的正确性计算机验证证明。

**Conclusion:** 成功验证了libsecp256k1中模逆元实现的正确性。

> **ai_Abstract:** 本文针对比特币加密库libsecp256k1中新引入的Bernstein和Yang扩展欧几里得算法的模逆元实现，使用Coq证明助手结合Verifiable C的分离逻辑，完成了对其正确性的计算机验证，以应对新算法可能引入的错误风险。

> **摘要翻译:** 模逆元是比特币及其他应用中数字签名所使用的椭圆曲线操作所需的基本计算。伯恩斯坦和杨在过去几年中开发了一种新的扩展欧几里得算法，并将其整合到比特币使用的libsecp256k1密码库中。然而，新颖的算法会引入新的错误风险。为了解决这个问题，我们使用Coq证明助手和Verifiable C的分离逻辑，完成了对libsecp256k1中（其中一个）模逆元实现的正确性的计算机验证证明。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [729] [TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization](https://arxiv.org/abs/2507.17962)
> *TimelyHLS：基于LLM的考虑时序和架构的FPGA HLS优化*

*Nowfel Mashnoor, Mohammad Akyash, Hadi Kamali, Kimia Azar* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** FPGA HLS, LLM, 检索增强生成, 时序优化, 自动化设计

**Comment:** 

> **TL;DR:** TimelyHLS是一个基于LLM和RAG的框架，用于自动生成和优化FPGA HLS代码，显著减少手动调优并提高性能和面积效率，同时确保时序收敛和功能正确性。

**AI_Comments:** TimelyHLS的创新点在于将LLM与RAG技术应用于FPGA HLS优化，解决了传统手动调优效率低下的问题。通过自动化pragmas的生成和迭代优化，它显著提高了设计效率和性能。该方法利用了LLM理解和生成代码的能力，结合实际综合反馈进行优化，为FPGA设计自动化开辟了新途径。其重要性在于，它降低了FPGA设计的门槛，加速了开发周期，并有望推动HLS工具的智能化发展。然而，其局限性可能在于LLM对复杂硬件架构深层理解的鲁棒性，以及知识库构建和维护的成本。

<details>
  <summary>Details</summary>

**Motivation:** 在FPGA高层次综合（HLS）中，由于架构约束、资源利用和缺乏平台特定pragmas的自动化支持之间的复杂交互，实现时序收敛和设计特定优化仍然是一个重大挑战。

**Method:** TimelyHLS是一个新颖的框架，它将大型语言模型（LLM）与检索增强生成（RAG）相结合，自动生成并迭代优化针对FPGA特定时序和性能要求的HLS代码。它由一个包含FPGA特定功能、综合指令和pragma模板的结构化架构知识库驱动。给定一个内核，TimelyHLS生成带有关键时序和设计特定pragmas的HLS代码。综合后的RTL通过商业工具链进行评估，并通过定制测试平台验证仿真正确性。TimelyHLS将综合日志和性能报告迭代地整合到LLM引擎中进行功能差异的细化。

**Result:** 在10个FPGA架构和不同基准测试上的实验结果表明，TimelyHLS将手动调优的需求减少了高达70%，同时实现了高达4倍的延迟加速（例如，矩阵乘法加速3.85倍，比特排序加速3.7倍），并在某些情况下节省了超过50%的面积（例如，维特比解码器中FF减少57%）。

**Conclusion:** TimelyHLS在不同平台上始终实现时序收敛和功能正确性，突显了LLM驱动的、架构感知的综合在自动化FPGA设计中的有效性。

> **ai_Abstract:** 本文提出了TimelyHLS，一个利用大型语言模型（LLM）和检索增强生成（RAG）的框架，旨在自动化FPGA高层次综合（HLS）中的时序收敛和设计特定优化。该框架通过结构化知识库生成并迭代优化HLS代码，集成了FPGA特定pragmas，并通过商业工具链进行评估和细化。实验证明，TimelyHLS显著减少了手动调优，实现了显著的性能提升（高达4倍延迟加速）和面积节省（超过50%），并在多个FPGA架构上保持了时序收敛和功能正确性，展示了LLM在自动化FPGA设计中的潜力。

> **摘要翻译:** 在FPGA高层次综合（HLS）中实现时序收敛和设计特定优化仍然是一个重大挑战，这归因于架构约束、资源利用以及缺乏对平台特定pragmas的自动化支持之间的复杂交互。在这项工作中，我们提出了TimelyHLS，一个将大型语言模型（LLM）与检索增强生成（RAG）相结合的新颖框架，旨在自动生成并迭代优化针对FPGA特定时序和性能要求的HLS代码。TimelyHLS由一个包含FPGA特定功能、综合指令和pragma模板的结构化架构知识库驱动。给定一个内核，TimelyHLS生成带有关键时序和设计特定pragmas的HLS代码。综合后的RTL随后使用商业工具链进行评估，并通过定制测试平台对照参考输出验证仿真正确性。TimelyHLS在存在功能差异时，将综合日志和性能报告迭代地整合到LLM引擎中进行细化。在10个FPGA架构和不同基准测试上的实验结果表明，TimelyHLS将手动调优的需求减少了高达70%，同时实现了高达4倍的延迟加速（例如，矩阵乘法加速3.85倍，比特排序加速3.7倍），并在某些情况下节省了超过50%的面积（例如，维特比解码器中FF减少57%）。TimelyHLS在不同平台上始终实现时序收敛和功能正确性，突显了LLM驱动的、架构感知的综合在自动化FPGA设计中的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [739] [Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering](https://arxiv.org/abs/2507.18034)
> *通过基于查询的逆向工程移除图像到图像模型中的无框水印*

*Haonan An, Guang Hua, Hangcheng Cao, Zhengru Fang, Guowen Xu, Susanto Rahardja, Yuguang Fang* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 无框水印, 逆向工程, 深度生成网络, 水印移除, 漏洞

**Comment:** 

> **TL;DR:** 本文揭示了一种针对深度生成网络无框水印的严重漏洞，通过查询式逆向工程可以实现100%成功率且高质量的水印移除，强调了对更强大防御机制的迫切需求。

**AI_Comments:** 本文在揭示深度生成网络水印保护机制的潜在弱点方面具有重要意义。其创新之处在于提出了两种有效的逆向工程方法，特别是在黑盒条件下，能够以极高的成功率和图像质量移除水印。这对于水印技术的防御方是一个重要的警示，强调了在设计IP保护方案时需要考虑更复杂的攻击向量。研究结果不仅揭示了漏洞，还为未来设计更鲁棒的水印方案提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 深度生成网络（GNets）的知识产权通常通过级联隐藏网络（HNet）将水印嵌入到其输出中来保护，这被称为无框水印。尽管GNet和HNet都被封装在一个黑盒（操作网络，ONet）中，并且只有带水印的输出被发布，被认为是安全的，但本文旨在揭示这种系统中一个被忽视的漏洞，即攻击者可以在系统知识有限的情况下，通过逆向工程可靠地估计隐藏的GNet输出，从而泄露未标记的生成图像。

**Method:** 本文提出了两种方法来逆向工程并移除无框水印。第一种方法是在严格的黑盒条件下，通过利用精心策划的输入图像的查询过程，逆向工程HNet的逆模型。为了提高图像质量，随后提出了第二种替代方法，该方法利用无框模型水印的等效加性属性，并逆向工程HNet的正向替代模型。

**Result:** 在图像处理和图像生成任务上的大量实验结果表明，两种攻击方法都实现了令人印象深刻的水印移除成功率（100%），同时保持了出色的图像质量（最高PSNR达到34.69 dB），显著优于现有攻击。

**Conclusion:** 本文的工作突出了无框模型水印中已识别漏洞的紧迫性，强调了开发更鲁棒的防御策略以应对此类攻击的必要性。

> **ai_Abstract:** 本文揭示了深度生成网络（GNets）中无框水印系统的一个严重漏洞。尽管水印嵌入在黑盒操作网络中，但研究表明，攻击者可以通过基于查询的逆向工程可靠地估计并恢复原始未标记的图像。文章提出了两种攻击方法：首先是逆向工程HNet的逆模型，其次是利用水印的加性特性逆向工程HNet的正向替代模型，以获得更好的图像质量。实验证明，这两种方法都能以100%的成功率移除水印，并保持卓越的图像质量，显著优于现有技术，这表明迫切需要更强大的防御机制来保护生成模型的知识产权。

> **摘要翻译:** 深度生成网络（GNets）的知识产权可以通过级联隐藏网络（HNet）进行保护，该网络将水印（或标记）嵌入到GNet输出中，这被称为无框水印。尽管GNet和HNet都封装在一个黑盒中（称为操作网络，或ONet），并且只有HNet生成的带标记输出被发布给最终用户并被认为是安全的，但在本文中，我们揭示了此类系统中一个被忽视的漏洞。具体来说，我们表明，尽管攻击者对系统的了解有限，但隐藏的GNet输出仍然可以通过基于查询的逆向工程可靠地估计，从而泄露生成的未标记图像。我们的首次尝试是在严格的黑盒条件下逆向工程HNet的逆模型，为此我们建议利用经过专门策划的输入图像的查询过程。虽然有效，但这种方法产生的图像质量不尽如人意。为了改进这一点，我们随后提出了一种替代方法，利用无框模型水印的等效加性属性并逆向工程HNet的正向替代模型，从而更好地保留图像质量。在图像处理和图像生成任务上的大量实验结果表明，两种攻击都实现了令人印象深刻的水印移除成功率（100%），同时保持了出色的图像质量（最高PSNR达到34.69 dB），显著优于现有攻击，这突出了迫切需要强大的防御策略来缓解无框模型水印中识别出的漏洞。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [743] [MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection](https://arxiv.org/abs/2507.17978)
> *MeAJOR语料库：一个用于网络钓鱼邮件检测的多源数据集*

*Paulo Mendes, Eva Maia, Isabel Praça* | **Category: cs.CR, cs.AI, cs.HC, 68P20 (Primary) 68T05, 68T07, 68T10 (Secondary), K.6.5; I.2.6; I.2.7; C.2.0** | **Updated: 2025-07-23**

**Keywords:** 网络钓鱼检测, 多源数据集, MeAJOR语料库, 机器学习, 网络安全

**Comment:** 8 pages, 2 tables, WI-IAT 2025 conference

> **TL;DR:** 本文提出了MeAJOR语料库，一个多源网络钓鱼邮件数据集，旨在解决现有数据集的局限性，并有效提升网络钓鱼检测的性能。

**AI_Comments:** MeAJOR语料库的创新之处在于其多源整合方法，解决了现有网络钓鱼数据集在数据质量、多样性、类别不平衡、泛化能力和可复现性方面的普遍问题。通过整合大规模、多样的样本和丰富的工程特征，它为机器学习模型提供了更鲁棒的训练基础，显著提升了网络钓鱼检测的性能。这对于提升网络安全防御能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 网络钓鱼邮件通过欺骗性内容和恶意载荷对网络安全构成重大威胁。虽然机器学习模型在检测网络钓鱼威胁方面有效，但其性能很大程度上取决于训练数据的质量和多样性，而现有资源存在关键局限性。

**Method:** 本文提出了MeAJOR（Merged email Assets from Joint Open-source Repositories）语料库，这是一个新颖的多源网络钓鱼邮件数据集。该数据集整合了135894个样本，涵盖了广泛的网络钓鱼策略和合法邮件，并包含大量工程特征。研究通过使用四种分类模型（RF、XGB、MLP和CNN）在多种特征配置下进行系统实验，评估了该数据集在网络钓鱼检测研究中的效用。

**Result:** 评估结果突出显示了该数据集的有效性，使用XGB模型实现了98.34%的F1分数。

**Conclusion:** MeAJOR语料库通过整合来自多个类别的广泛特征，提供了一个可重用且一致的资源，同时解决了现有数据集在类别不平衡、泛化能力和可复现性等方面的常见挑战。

> **ai_Abstract:** 本文介绍了MeAJOR语料库，一个新颖的多源网络钓鱼邮件数据集，旨在解决现有数据集在质量和多样性方面的局限性。该语料库整合了135894个样本和广泛的工程特征，涵盖多种网络钓鱼策略和合法邮件。通过使用RF、XGB、MLP和CNN等分类模型进行评估，MeAJOR语料库在网络钓鱼检测中表现出高效性，其中XGB模型达到了98.34%的F1分数。该数据集为网络钓鱼检测研究提供了一个可重用、一致的资源，并有效解决了类别不平衡、泛化能力和可复现性等挑战。

> **摘要翻译:** 网络钓鱼邮件通过利用欺骗性内容和恶意载荷，持续对网络安全构成重大威胁。尽管机器学习（ML）模型在检测网络钓鱼威胁方面表现出色，但其性能在很大程度上依赖于训练数据的质量和多样性。本文介绍了MeAJOR（来自联合开源存储库的合并电子邮件资产）语料库，这是一个新颖的多源网络钓鱼邮件数据集，旨在克服现有资源中的关键局限性。它整合了135894个样本，代表了广泛的网络钓鱼策略和合法邮件，并具有广泛的工程特征。我们通过使用四种分类模型（RF、XGB、MLP和CNN）在多种特征配置下进行系统实验，评估了该数据集在网络钓鱼检测研究中的效用。结果突出了数据集的有效性，使用XGB模型实现了98.34%的F1分数。通过整合来自多个类别的广泛特征，我们的数据集提供了一个可重用且一致的资源，同时解决了类别不平衡、泛化能力和可复现性等常见挑战。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [750] [NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN](https://arxiv.org/abs/2507.18036)
> *NWaaS：用于X到图像DNN的非侵入式水印即服务*

*Haonan An, Guang Hua, Yu Guo, Hangcheng Cao, Susanto Rahardja, Yuguang Fang* | **Category: cs.CR, cs.CV** | **Updated: 2025-07-24**

**Keywords:** DNN水印, 非侵入式, 水印即服务, ShadowMark, 知识产权保护

**Comment:** 

> **TL;DR:** 本文提出了NWaaS，一个针对X到图像DNN的非侵入式水印即服务范式，通过ShadowMark实现，解决了现有DNN水印方法的侵入性问题，并实现了绝对保真度。

**AI_Comments:** 该论文的创新点在于提出了“非侵入式”的DNN水印概念，这直接解决了现有技术侵入性强、影响模型性能和实际部署意愿的痛点。通过在黑盒API中建立侧信道，实现了模型参数和结构不被修改的水印，同时声称达到“绝对保真度”并消除了“保真度-鲁棒性权衡”，这在理论和实践上都具有重要意义。它为DNN模型知识产权保护提供了一个更易于被接受和部署的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度神经网络（DNN）水印方法是侵入性的，它们修改模型参数或改变结构，导致模型行为偏移、额外的微调成本以及模型所有者不愿采用。这限制了实用水印即服务（WaaS）系统的发展。

**Method:** 本文提出了非侵入式水印即服务（NWaaS），一个针对X到图像模型的全新无需信任范式，其核心假设是在模型未被修改的情况下，仍可从模型输出中提取所有者定义的水印。具体实现是ShadowMark，它通过在受保护模型的黑盒API中建立一个鲁棒的非侵入式侧信道，利用一个密钥编码器和一个水印解码器来解决部署挑战。

**Result:** 在图像到图像、噪声到图像、噪声和文本到图像以及文本到图像模型上的大量实验证明了ShadowMark在实际部署非侵入式DNN水印方面的有效性和实用性。

**Conclusion:** NWaaS（通过ShadowMark实现）提供了一种非侵入式的DNN水印解决方案，克服了现有方法的侵入性问题和保真度-鲁棒性权衡，实现了绝对保真度，并适用于不同的DNN架构。

> **ai_Abstract:** 本文提出了一种名为非侵入式水印即服务（NWaaS）的新范式，旨在解决现有DNN水印技术固有的侵入性问题，这些问题导致模型行为偏移和部署障碍。针对X到图像模型，NWaaS的核心思想是在不修改模型本身的情况下，通过模型输出提取水印。具体实现为ShadowMark，它利用黑盒API中的侧信道进行水印嵌入和提取，实现了绝对保真度，适用于多种DNN架构，并对攻击具有鲁棒性，从而克服了保真度与鲁棒性之间的权衡。实验证明了其在实际应用中的有效性。

> **摘要翻译:** 深度神经网络（DNN）模型的知识产权可以通过DNN水印来保护，该技术将版权水印嵌入到模型参数（白盒）、模型行为（黑盒）或模型输出（无盒）中，随后可以提取水印以验证模型所有权或检测模型窃取。尽管最近取得了进展，但这些现有方法本质上是侵入性的，因为它们要么修改模型参数，要么改变结构。这种固有的侵入性引起了对水印引起的模型行为偏移和额外微调成本的担忧，随着模型规模的快速增长，这些问题进一步加剧。因此，模型所有者往往不愿在实践中采用DNN水印，这限制了实用水印即服务（WaaS）系统的发展。为了解决这个问题，我们引入了非侵入式水印即服务（NWaaS），这是一个专为X到图像模型设计的新颖的无需信任范式，我们假设在不触动模型的情况下，仍然可以从模型输出中提取所有者定义的水印。基于这一概念，我们提出了ShadowMark，NWaaS的一个具体实现，它通过在受保护模型的黑盒API中建立一个鲁棒且非侵入性的侧信道，利用一个密钥编码器和一个水印解码器来解决关键的部署挑战。它通过实现所谓的绝对保真度并适用于不同的DNN架构，同时对现有攻击也具有鲁棒性，从而消除了保真度-鲁棒性权衡，这与现有解决方案显著不同。在图像到图像、噪声到图像、噪声和文本到图像以及文本到图像模型上的大量实验证明了ShadowMark在实际部署非侵入式DNN水印方面的有效性和实用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [757] [RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models](https://arxiv.org/abs/2507.18053)
> *RECALLED：一种针对大型视觉-语言模型的无界资源消耗攻击*

*Haoran Gao, Yuanhe Zhang, Zhenhong Zhou, Lei Jiang, Fanyu Meng, Yujia Xiao, Kun Wang, Yang Liu, Junlan Feng* | **Category: cs.CR, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 资源消耗攻击, 大型视觉-语言模型, 对抗性扰动, 红队测试, 安全漏洞

**Comment:** 

> **TL;DR:** RECALLED是一种利用视觉输入对大型视觉-语言模型（LVLMs）发动无界资源消耗攻击（RCAs）的新方法，通过生成重复输出显著增加服务延迟、GPU利用率和内存消耗，揭示了LVLMs的安全漏洞。

**AI_Comments:** RECALLED的创新之处在于其首次将视觉模态作为资源消耗攻击的攻击面，填补了现有红队测试研究的空白。通过细粒度的像素级优化和多目标损失设计，该方法能够有效地诱导LVLMs产生无界重复输出，从而对系统资源造成显著压力。这项研究的重要性在于它揭示了LVLMs中此前未被充分认识的安全漏洞，并为未来的防御机制设计提供了关键的红队测试框架和方向。其局限性可能在于攻击的通用性和在更复杂、多样化LVLM架构上的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的红队测试研究在大型视觉-语言模型（LVLMs）中很大程度上忽视了视觉输入作为潜在的攻击面，导致针对资源消耗攻击（RCAs）的缓解策略不足。本研究旨在填补这一空白，提出利用视觉模态触发无界RCAs的方法。

**Method:** 本研究提出了RECALLED方法，首次利用视觉模态触发无界资源消耗攻击。具体而言，它引入了“视觉引导优化”（Vision Guided Optimization），这是一种细粒度的像素级优化技术，用于生成能够诱导重复输出的“输出召回”对抗性扰动。这些扰动被注入到视觉输入中，从而触发无界生成以实现RCAs。此外，还引入了“多目标并行损失”（Multi-Objective Parallel Losses）来生成通用攻击模板并解决实现并行攻击时的优化冲突。

**Result:** 实验结果表明，RECALLED能够将服务响应延迟增加26%以上，并导致GPU利用率和内存消耗额外增加20%。

**Conclusion:** 本研究揭示了大型视觉-语言模型的安全漏洞，并建立了一个红队测试框架，该框架可以促进未来针对资源消耗攻击的防御开发。

> **ai_Abstract:** 该论文提出了RECALLED，这是一种针对大型视觉-语言模型（LVLMs）的创新性资源消耗攻击（RCA）方法，它首次利用视觉输入作为攻击向量。RECALLED通过“视觉引导优化”生成对抗性像素扰动，诱导模型产生重复输出，从而触发无界生成，显著增加服务延迟和资源消耗。此外，论文还引入了“多目标并行损失”以生成通用攻击模板。实验证明，该攻击能使响应延迟增加超过26%，GPU和内存使用量增加20%。这项工作揭示了LVLMs的安全漏洞，并提供了一个红队测试框架，为未来的防御开发奠定了基础。

> **摘要翻译:** 资源消耗攻击（RCAs）已成为大型语言模型（LLMs）部署的一个重大威胁。随着视觉模态的整合，额外的攻击向量加剧了大型视觉-语言模型（LVLMs）中RCAs的风险。然而，现有的红队测试研究在很大程度上忽视了视觉输入作为潜在的攻击面，导致针对LVLMs中RCAs的缓解策略不足。为了解决这一空白，我们提出了RECALLED（大型视觉-语言模型上的资源消耗攻击），这是第一个利用视觉模态触发无界RCAs红队测试的方法。首先，我们提出了“视觉引导优化”，一种细粒度的像素级优化，以获得“输出召回”对抗性扰动，其可以诱导重复输出。然后，我们将扰动注入到视觉输入中，触发无界生成以实现RCAs的目标。此外，我们引入了“多目标并行损失”来生成通用攻击模板，并解决在尝试实施并行攻击时的优化冲突。实证结果表明，RECALLED使服务响应延迟增加了26%以上，导致GPU利用率和内存消耗额外增加了20%。我们的研究揭示了LVLMs中的安全漏洞，并建立了一个红队测试框架，可以促进未来针对RCAs的防御开发。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [23] [Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](https://arxiv.org/abs/2507.17289)
> *合规大脑助手：企业环境中协助合规任务的对话式智能体AI*

*Shitong Zhu, Chenhao Fang, Derek Larson, Neel Reddy Pochareddy, Rajeev Rao, Sophie Zeng, Yanqing Peng, Wendy Summer, Alex Goncalves, Arya Pudota, Hervé Robert* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 对话式AI, 智能体, 合规任务, 企业环境, 路由机制

**Comment:** 

> **TL;DR:** 提出并评估了一个名为CBA的对话式智能体AI助手，通过智能路由机制平衡响应质量和延迟，显著提升了企业合规任务的效率和表现。

**AI_Comments:** 这篇论文提出了一种实用的AI助手，通过创新的路由机制解决了企业级应用中响应质量和延迟的平衡问题。其将简单请求和复杂请求进行区分处理的设计思路非常有效，并得到了实验数据的有力支持，对于构建高效、可靠的企业级AI解决方案具有重要参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 提高企业环境中人员日常合规任务的效率。

**Method:** 本文提出了合规大脑助手（CBA），一个对话式智能体AI助手。CBA设计了一个用户查询路由器，该路由器能够智能地在两种模式之间进行选择：(i) 快速通道模式，用于处理仅需从知识库中检索相关上下文的简单请求；(ii) 全智能体模式，用于处理需要复合操作、工具调用、跨合规工件发现上下文以及/或涉及其他API/模型的复杂请求。这种设计旨在平衡响应质量和延迟。

**Result:** 实验评估显示，CBA在平均关键词匹配率（83.7% vs 41.7%）和LLM判断通过率（82.0% vs 20.0%）上显著优于开箱即用的LLM。此外，完整的路由设计与“仅快速通道”和“全智能体”模式相比，在保持近似运行时间的同时，取得了更好的平均匹配率和通过率，验证了路由机制在两者之间取得良好权衡的假设。

**Conclusion:** CBA通过其智能路由机制，在企业合规任务中显著提高了效率和响应质量，并在响应速度和质量之间取得了良好的平衡。

> **ai_Abstract:** 本文提出并评估了合规大脑助手（CBA），一个旨在提高企业合规任务效率的对话式智能体AI。CBA采用智能路由机制，根据请求复杂性在“快速通道”和“全智能体”模式间切换，以平衡响应质量与延迟。实验结果表明，CBA在关键词匹配率和LLM判断通过率上显著优于现有大型语言模型，并且其路由设计在保持效率的同时，有效提升了性能。

> **摘要翻译:** 本文介绍了合规大脑助手（CBA），这是一种对话式智能体AI助手，旨在提高企业环境中人员日常合规任务的效率。为了在响应质量和延迟之间取得良好平衡，我们设计了一个用户查询路由器，可以智能地选择：（i）快速通道模式：处理只需从知识库中检索相关上下文的简单请求；以及（ii）全智能体模式：处理需要复合操作和工具调用以主动发现各种合规工件中的上下文，和/或涉及其他API/模型以适应请求的复杂请求。一个典型的例子是，从用户查询开始，使用其描述查找特定实体，然后使用该实体的信息查询其他API，以整理和丰富最终的AI响应。
我们的实验评估将CBA与开箱即用的LLM在针对各种角色的各种真实世界隐私/合规相关查询上进行了比较。我们发现，CBA在平均关键词匹配率（83.7% vs 41.7%）和LLM判断通过率（82.0% vs 20.0%）等指标上显著优于普通的LLM。我们还将完整的基于路由的设计与“仅快速通道”和“全智能体”模式的指标进行了比较，发现它具有更好的平均匹配率和通过率，同时运行时间大致相同。这一发现验证了我们的假设，即路由机制在两种模式之间取得了良好的权衡。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [37] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
> *Answer Set Programming 中析取非最小语义的比较*

*Felicidad Aguado, Pedro Cabalar, Brais Muñiz, Gilberto Pérez, Concepción Vidal* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** Answer Set Programming, Disjunction, Non-minimal Semantics, Justified Models, Forks

**Comment:** 

> **TL;DR:** 本文比较了Answer Set Programming中四种非最小析取语义，发现其中三种（Forks、Justified Models和放宽的DI语义）实际上是等价的，构成了一个共同的语义，该语义是稳定模型的超集，并比第四种（Strongly Supported Models）更强。

**AI_Comments:** 本文通过澄清Answer Set Programming中几种非最小析取语义之间的关系做出了重要贡献。识别“Forks”、“Justified Models”和放宽的“Determining Inference”语义的等价性，简化了非最小ASP的图景，暗示了对这些替代方法更统一的理解。这种整合有助于ASP在传统稳定模型之外的理论发展和实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在比较Answer Set Programming中不遵循模型最小化原则的析取非最小语义，以理解这些替代方法及其相互关系。

**Method:** 本文比较了四种不同的非最小析取语义（Justified Models、Strongly Supported Models、Forks和Determining Inference (DI) 语义），并证明了这些方法之间的关系和重合性。

**Result:** 三种方法（Forks、Justified Models和合理放宽的DI语义）实际上是重合的，构成了一个共同的单一方法。这种共同语义总是提供程序稳定模型的超集，并且严格强于第四种方法（Strongly Supported Models）。

**Conclusion:** 本文通过证明三种现有方法的等价性，识别出Answer Set Programming中一种共同的非最小析取语义，阐明了其与稳定模型和其他非最小语义的关系。

> **ai_Abstract:** 本文对Answer Set Programming (ASP) 中四种非最小析取语义进行了比较分析，这些语义偏离了稳定模型的模型最小化原则。研究考察了Justified Models、Strongly Supported Models、Forks和Determining Inference (DI) 语义，并将后两者视为标准析取运算符的新解释。研究证明Forks、Justified Models以及DI语义的放宽版本是等价的，形成了一个统一的非最小语义。这种共同语义被证明是稳定模型的超集，并且严格强于Strongly Supported Models，后者以经典逻辑方式处理析取。

> **摘要翻译:** 在本文中，我们比较了Answer Set Programming中四种不同的析取语义，它们与稳定模型不同，不遵循模型最小化原则。其中两种方法，Cabalar和Muñiz的“Justified Models”以及Doherty和Szalas的“Strongly Supported Models”，直接为析取提供了替代的非最小语义。另外两种，Aguado等人的“Forks”和Shen和Eiter的“Determining Inference”（DI）语义，实际上引入了一种新的析取连接词，但在此处被比较为它们构成了标准析取运算符的新语义。我们能够证明其中三种方法（Forks、Justified Models和DI语义的合理放宽）实际上是重合的，在不同的定义下构成了一个共同的单一方法。此外，这种共同语义总是提供程序稳定模型的超集（实际上，模任何上下文），并且严格强于第四种方法（Strongly Supported Models），后者实际上像经典逻辑一样处理析取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [73] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
> *人工智能在保护基本权利方面的风险评估基础*

*Antonino Rotolo, Beatrice Ferrigno, Jose Miguel Angel Garcia Godinez, Claudio Novelli, Giovanni Sartor* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** AI风险评估, 基本权利, 欧盟人工智能法案, 定义平衡, 可废止推理

**Comment:** 24 pages, 1 figure. To be published in: The Philosophical Foundations
  of Information Technology Law. Oxford University Press, Oxford

> **TL;DR:** 本章提出一个概念框架，用于对人工智能进行定性风险评估，特别是在欧盟人工智能法案的背景下，通过整合定义平衡和可废止推理来解决法律合规性和基本权利保护的复杂性。

**AI_Comments:** 这篇论文的创新之处在于它提出了一个整合了定义平衡和可废止推理的AI风险评估概念框架，特别关注基本权利保护和欧盟AI法案的合规性。这种方法结合了哲学基础和法律推理，为理解AI部署场景与基本权利的互动提供了新的视角。其分层评估模型对高风险AI和通用AI系统都具有操作性，为未来的负责任AI治理提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 解决人工智能风险评估中法律合规性与基本权利保护的复杂性，特别是在欧盟人工智能法案的背景下，并为人工智能风险分析提供哲学基础和逻辑解释。

**Method:** 引入了一个概念框架，用于人工智能的定性风险评估，该框架整合了定义平衡（利用比例原则分析解决权利冲突）和可废止推理（适应法律决策的动态性）。强调分析人工智能部署场景，识别潜在法律违规和对基本权利的多层影响。

**Result:** 提出了一个分层方法，可以为高风险人工智能系统和通用人工智能（GPAI）系统提供更具操作性的评估模型，并强调了后者更广泛的适用性。提供了人工智能风险分析的哲学基础和逻辑解释的基本构建模块。

**Conclusion:** 该概念框架通过整合定义平衡和可废止推理，为人工智能在保护基本权利方面的风险评估提供了一个分层且操作性强的方法，有助于解决法律合规性问题并支持负责任的人工智能治理。未来工作将致力于开发形式化模型和有效算法。

> **ai_Abstract:** 本文提出了一个用于人工智能定性风险评估的概念框架，特别针对欧盟人工智能法案。该框架通过整合定义平衡（处理权利冲突的比例分析）和可废止推理（适应法律决策动态性）来解决法律合规性和基本权利保护的复杂性。它强调分析人工智能部署场景及其对基本权利的多层影响，并为人工智能风险分析提供了哲学基础。这种分层方法能有效评估高风险AI和通用AI系统。未来的工作将专注于开发形式化模型和算法以支持负责任的AI治理。

> **摘要翻译:** 本章介绍了一个人工智能定性风险评估的概念框架，特别是在欧盟人工智能法案的背景下。该框架通过整合定义平衡和可废止推理来解决法律合规性和基本权利保护的复杂性。定义平衡采用比例原则分析来解决相互竞争的权利之间的冲突，而可废止推理则适应法律决策的动态性质。我们的方法强调需要分析人工智能部署场景，并识别潜在的法律违规以及对基本权利的多层影响。在此分析的基础上，我们为人工智能风险分析的逻辑解释提供了哲学基础。特别是，我们考虑了概念性理解人工智能部署场景与基本权利之间互动关系的基本构成要素，在可废止推理中融入了定义平衡以及关于权利情境性促进或贬低的论证。这种分层方法允许对高风险人工智能系统和通用人工智能（GPAI）系统进行更具操作性的评估模型，强调了后者更广泛的适用性。未来的工作旨在开发一个形式化模型和有效的算法，以增强人工智能风险评估，将理论见解与实际应用相结合，以支持负责任的人工智能治理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [108] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
> *物理考试中代数表达式批改的AlphaPhysics项重写系统*

*Peter Baumgartner, Lachlan McGinness* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 自动批改, 物理考试, 项重写系统, 大型语言模型

**Comment:** 

> **TL;DR:** 提出了一种结合计算机代数系统、SMT求解器和项重写系统，并利用LLM自动批改物理考试代数表达式的方法，并在真实数据上进行了评估。

**AI_Comments:** 这项工作通过结合LLM、计算机代数系统、SMT求解器和专门的项重写系统，为物理考试的自动批改提供了一个创新的解决方案。特别是在处理学生答案的自由形式和复杂性方面，LLM的应用是一个亮点，而项重写系统则专注于物理表达式的特定挑战。在真实世界数据上的广泛评估增加了其实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自动批改物理考试中的代数表达式是一个具有挑战性的问题，需要评估学生输入的答案相对于标准答案的正确性。

**Method:** 该方法结合了计算机代数系统、SMT求解器和项重写系统。一个大型语言模型（LLM）用于解释学生答案、纠正错误并将其转换为机器可读格式。随后应用自动化推理技术（包括现成的SMT求解和为物理问题定制的项重写系统）来评估学生答案的正确性。文中详细描述了项重写系统的开发及其终止性和合流性属性的建立。

**Result:** 该系统在来自2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生考试答卷上进行了评估。

**Conclusion:** 该研究成功开发并评估了一个用于自动批改物理考试中代数表达式的系统，该系统结合了多种先进技术，并在真实世界数据上表现良好。

> **ai_Abstract:** 这篇论文介绍了一种名为AlphaPhysics的系统，用于自动批改物理考试中的代数表达式。该系统融合了计算机代数系统、SMT求解器和专门的项重写系统，并利用大型语言模型处理和标准化学生答案。系统通过自动化推理技术评估学生解决方案的正确性，并已在超过1500份真实世界物理奥林匹克竞赛答卷上进行了验证。

> **摘要翻译:** 我们提出了自动批改物理考试的方法。批改问题在于评估学生输入的答案相对于标准答案的正确性。这是一个具有挑战性的问题，我们试图通过结合计算机代数系统、SMT求解器和项重写系统来解决。大型语言模型用于解释和消除学生回答中的错误，并将其重写为机器可读的格式。一旦形式化并与语言对齐，下一步就是应用自动化推理技术来评估学生解决方案的正确性。我们考虑了两种自动化定理证明方法：现成的SMT求解和为涉及三角表达式的物理问题量身定制的项重写系统。项重写系统的开发以及终止性和合流性属性的建立并非易事，我们在论文中对其进行了详细描述。我们使用来自2023年澳大利亚物理奥林匹克竞赛的1500多个真实学生考试答卷的丰富数据池对我们的系统进行了评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [143] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
> *超越显而易见的推理：评估大型语言模型在金融场景中的发散性和收敛性思维*

*Zhuang Qiang Bok, Watson Wei Khong Chua* | **Category: cs.AI, I.2.0; I.2.6; J.4** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 金融, 推理基准, 发散性思维, 收敛性思维, ConDiFi

**Comment:** Accepted by Agentic & GenAI Evaluation KDD2025: KDD workshop on
  Evaluation and Trustworthiness of Agentic and Generative AI Models
  https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/

> **TL;DR:** 引入ConDiFi基准，评估LLM在金融任务中的发散性和收敛性思维，发现不同模型表现差异显著，尤其在创新性和可操作性方面。

**AI_Comments:** 这篇论文的创新点在于提出了一个专门用于评估LLM在金融场景中发散性和收敛性思维的基准ConDiFi，这弥补了现有基准主要侧重于事实准确性和逻辑推理的不足。它强调了LLM在金融领域不仅需要“收敛”到最优决策，还需要“发散”出创新的、可行的未来情景，这对于LLM在金融领域的实际应用具有重要意义。研究结果揭示了不同模型在这些关键能力上的差异，为金融机构选择和部署LLM提供了有价值的指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM推理基准主要侧重事实准确性或逐步逻辑，但在金融领域，专业人士不仅需要做出最优决策，还需要在不确定性下生成有创意、合理且可行的未来情景。

**Method:** 本文引入了ConDiFi基准，用于联合评估LLM在金融任务中的发散性和收敛性思维。该基准包含607个用于发散性推理的宏观金融提示和990个用于收敛性推理的多跳对抗性选择题。研究团队使用此基准评估了14个领先模型。

**Result:** 评估结果揭示了显著差异。尽管GPT-4o在流畅性方面表现出色，但在新颖性和可操作性方面表现不佳。相比之下，DeepSeek-R1和Cohere Command R+等模型在生成适合投资决策的可操作性见解方面名列前茅。

**Conclusion:** ConDiFi为评估LLM在金融领域安全和战略部署所需的推理能力提供了新视角。

> **ai_Abstract:** 本文提出了ConDiFi基准，旨在弥补现有LLM推理基准在金融领域中对发散性和收敛性思维评估的不足。该基准包含宏观金融提示和多跳选择题，用于评估LLM生成创意性未来情景和做出最优决策的能力。通过评估14个主流模型，研究发现GPT-4o在新颖性和可操作性上表现不佳，而DeepSeek-R1和Cohere Command R+在生成可操作性见解方面表现突出。ConDiFi为金融领域LLM的部署提供了新的评估视角。

> **摘要翻译:** 大多数大型语言模型（LLMs）的推理基准都强调事实准确性或循序渐进的逻辑。然而，在金融领域，专业人士不仅必须收敛于最优决策，还必须在不确定性下创造性地生成合理且可能发生的未来情景。我们引入了ConDiFi，这是一个旨在联合评估LLMs在金融任务中发散性和收敛性思维的基准。ConDiFi包含607个用于发散性推理的宏观金融提示和990个用于收敛性推理的多跳对抗性多项选择题。利用该基准，我们评估了14个领先模型，并发现了惊人的差异。尽管GPT-4o具有高流畅性，但在新颖性和可操作性方面表现不佳。相比之下，像DeepSeek-R1和Cohere Command R+这样的模型在生成适用于投资决策的可操作性见解方面名列前茅。ConDiFi为评估在金融领域安全和战略部署LLMs所需的推理能力提供了新视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [183] [Revisiting LLM Reasoning via Information Bottleneck](https://arxiv.org/abs/2507.18391)
> *通过信息瓶颈重新审视大型语言模型推理*

*Shiye Lei, Zhihao Cheng, Kai Jia, Dacheng Tao* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 推理, 信息瓶颈, 强化学习, 正则化

**Comment:** 

> **TL;DR:** 针对现有LLM推理方法的启发式局限性，本文提出基于信息瓶颈（IB）的理论框架IBRO，并开发了轻量级IB正则化方法。实验证明，该方法在多个数学推理基准上能持续提升LLM推理性能。

**AI_Comments:** 本文的创新点在于将信息瓶颈原理引入大型语言模型（LLM）推理优化，提供了一个更具原则性的理论框架，而非依赖于启发式方法。其提出的IB正则化方法轻量且易于集成，对于提升LLM在推理任务上的性能具有重要意义，尤其是在不增加额外计算开销的前提下。

<details>
  <summary>Details</summary>

**Motivation:** 现有通过可验证奖励强化学习（RLVR）提升大型语言模型（LLM）推理能力的方法多为启发式和直觉驱动，限制了原则性方法的发展。

**Method:** 本文提出基于信息瓶颈（IB）原理的LLM推理理论表征，并引入IB感知推理优化（IBRO）框架，旨在使推理轨迹既能提供最终正确答案的信息，又能泛化到不同提示。研究推导了一个实用的token级替代目标，并提出了一种高效近似，从而形成轻量级的IB正则化方法。该方法可无缝集成到现有基于RL的后训练框架中，计算开销小，只需一行代码修改。

**Result:** 在多个数学推理基准和强化学习（RL）算法上验证了IB正则化方法，结果表明其能持续提升大型语言模型（LLM）的推理性能。

**Conclusion:** 本文提出的IB正则化方法是一种有效且轻量级的解决方案，能够提高大型语言模型（LLM）的推理能力，解决了现有方法在启发式方面的局限性。

> **ai_Abstract:** 本文针对现有大型语言模型（LLM）推理方法（如RLVR）的启发式局限性，提出了一种基于信息瓶颈（IB）原理的理论框架IBRO。该框架旨在优化推理轨迹，使其既能有效引导至正确答案，又能具备良好的泛化性。通过推导token级替代目标并提出轻量级的IB正则化方法，该技术可无缝集成到现有强化学习（RL）后训练框架中，且计算开销极小。实验结果表明，IB正则化在多个数学推理任务和RL算法上均能持续提升LLM的推理性能。

> **摘要翻译:** 大型语言模型（LLMs）最近通过可验证奖励强化学习（RLVR）在推理能力方面取得了显著进展。通过利用简单的基于规则的奖励，RL有效地激励LLMs生成扩展的思维链（CoT）推理轨迹，逐步引导它们走向正确答案。然而，现有方法在很大程度上仍然是启发式和直觉驱动的，限制了原则性方法的发展。在本文中，我们提出了一种基于信息瓶颈（IB）原理的LLM推理理论表征，引入了IB感知推理优化（IBRO），这是一个鼓励推理轨迹既能提供最终正确答案的信息，又能泛化到不同提示的框架。我们推导了一个实用的token级替代目标，并提出了一种高效近似，从而形成了轻量级的IB正则化方法。这项技术可以无缝集成到现有的基于RL的后训练框架中，无需额外的计算开销，只需一行代码修改。在经验上，我们在多个数学推理基准和RL算法上验证了IB正则化，证明了LLM推理性能的持续改进。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [218] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
> *使用强化学习优化呼叫中心运营：价值迭代对比近端策略优化*

*Kwong Ho Li, Wathsala Karunarathne* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 呼叫中心, 价值迭代, 近端策略优化, 技能型路由

**Comment:** 10 pages

> **TL;DR:** 本研究比较了两种强化学习方法（价值迭代和近端策略优化）在优化呼叫中心路由方面的表现，结果表明PPO在最小化客户等待时间和员工空闲时间方面表现最佳。

**AI_Comments:** 本文创新性地将强化学习应用于呼叫中心运营优化，并对比了两种主流RL算法在实际问题中的性能。其重要性在于为呼叫中心管理提供了数据驱动的优化策略。局限性可能在于PPO所需的训练时间较长，以及仿真模型与实际系统之间的潜在差异。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过应用强化学习优化呼叫中心路由，以最小化客户等待时间和员工空闲时间。

**Method:** 研究比较了两种强化学习方法：一种是基于模型的价值迭代（VI），在已知系统动力学下进行；另一种是无模型的近端策略优化（PPO），通过经验学习。对于基于模型的方法，使用了理论模型；对于无模型学习，开发了一个结合离散事件仿真（DES）和OpenAI Gym环境的仿真模型。两种模型都将问题构建为技能型路由（SBR）框架下的马尔可夫决策过程（MDP），并假设客户到达服从泊松分布，服务和放弃时间服从指数分布。通过仿真模型评估了随机策略、VI策略和PPO策略。

**Result:** 在1000个测试回合后，PPO策略始终获得最高奖励，并且客户等待时间最短、员工空闲时间最少，尽管它需要更长的训练时间。

**Conclusion:** 尽管训练时间较长，但近端策略优化（PPO）在优化呼叫中心运营方面，特别是在减少客户等待时间和员工空闲时间方面，表现优于价值迭代（VI）和其他策略。

> **ai_Abstract:** 本研究探讨了使用强化学习优化呼叫中心运营，旨在减少客户等待时间和员工空闲时间。论文对比了基于模型的价值迭代（VI）和无模型的近端策略优化（PPO）。通过将问题建模为马尔可夫决策过程，并结合离散事件仿真进行评估，结果显示PPO在减少等待时间和空闲时间方面表现最佳，尽管训练时间较长。

> **摘要翻译:** 本文研究了强化学习（RL）在优化呼叫中心呼叫路由方面的应用，以最小化客户等待时间和员工空闲时间。论文比较了两种方法：一种是基于模型的价值迭代（VI），在已知系统动力学下进行；另一种是无模型的近端策略优化（PPO），通过经验学习。对于基于模型的方法，使用了理论模型；而对于无模型学习，开发了一个结合离散事件仿真（DES）和OpenAI Gym环境的仿真模型。这两种模型都将问题构建为技能型路由（SBR）框架下的马尔可夫决策过程（MDP），并假设客户到达服从泊松分布，服务和放弃时间服从指数分布。对于策略评估，随机策略、VI策略和PPO策略都使用仿真模型进行评估。在1000个测试回合后，PPO始终获得最高奖励，同时客户等待时间最短、员工空闲时间最少，尽管它需要更长的训练时间。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [257] [GPU Accelerated Compact-Table Propagation](https://arxiv.org/abs/2507.18413)
> *GPU加速的紧凑表传播*

*Enrico Santi, Fabio Tardivo, Agostino Dovier, Andrea Formisano* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** GPU, 紧凑表, 约束编程, 表约束, 传播

**Comment:** Under consideration in Theory and Practice of Logic Programming
  (TPLP)

> **TL;DR:** 本文通过利用GPU的强大计算能力，加速了最先进的紧凑表（Compact-Table）约束传播算法，以有效处理大规模表约束问题。

**AI_Comments:** 本文的创新点在于将GPU的并行计算能力应用于约束编程中的紧凑表（Compact-Table）传播算法，解决了传统CPU方法在处理大规模表约束时效率低下的问题。这对于提升实际约束求解器的性能，使其能够应对更复杂的真实世界问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在约束编程中，表约束（Table Constraint）是重要的约束形式，但对于包含成百上千甚至数千个有效案例的真实世界问题，标准基于CPU的方法难以有效处理。

**Method:** 本文通过利用现代GPU的强大计算能力来增强紧凑表（Compact-Table, CT）算法。具体方法包括设计和实现GPU加速的CT算法，并将其集成到现有的约束求解器中。

**Result:** 本文对GPU加速的紧凑表算法进行了设计和实现，并将其集成到现有约束求解器中，通过对大量实例进行实验验证。

**Conclusion:** 本文展示了如何利用GPU加速紧凑表（Compact-Table）算法，使其能够有效处理大规模的表约束问题。

> **ai_Abstract:** 本文关注约束编程中的表约束及其最先进的传播算法——紧凑表（Compact-Table, CT）算法。鉴于传统CPU方法在处理大规模表约束时的局限性，本文提出利用现代GPU的并行计算能力来加速CT算法。研究内容包括GPU加速CT的设计、实现及其与现有约束求解器的集成，并通过实验验证了其在处理大量实例时的有效性。

> **摘要翻译:** 约束编程在八十年代从逻辑编程中发展而来；如今，所有的Prolog系统都包含能够处理有限域上约束编程的模块，这些模块要求其解决方案由约束求解器提供。这项工作专注于一种特定形式的约束，即所谓的表约束（Table Constraint），用于将变量值的条件指定为替代选项的枚举。由于有限域变量集上的每个条件最终都可以表示为有限的案例集，因此表约束原则上可以模拟任何其他约束。这些特性使得表约束成为有史以来研究最多的约束之一，从而产生了一系列效率不断提高的传播算法。尽管如此，遇到包含成百上千甚至数千个有效案例的真实世界问题并不少见，这些问题用标准的基于CPU的方法根本无法有效处理。在本文中，我们处理紧凑表（Compact-Table, CT）算法，这是表约束最先进的传播算法。我们描述了如何通过利用现代GPU提供的强大计算能力来增强CT算法，以处理大型表约束。特别是，我们报告了GPU加速CT的设计和实现，它如何集成到现有的约束求解器中，以及在大量实例上进行的实验验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [276] [On the Structure of Game Provenance and its Applications](https://arxiv.org/abs/2410.05094)
> *关于博弈溯源的结构及其应用*

*Shawn Bowers, Yilin Xia, Bertram Ludäscher* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 博弈溯源, 一阶查询, 溯源类型, 良基模型, 抽象论证框架

**Comment:** 

> **TL;DR:** 本文研究了博弈溯源的细粒度结构，并识别了新的溯源类型及其计算方法和应用。

**AI_Comments:** 本文的创新之处在于对博弈溯源进行了细粒度分析，超越了传统的“如何”和“为什么不”溯源。通过引入七种边类型和三种新的溯源类型（潜在、实际、主要），它为理解博弈结果的解释提供了更丰富的视角，并强调了不同移动在博弈中的作用差异。其方法论将博弈解决与溯源计算相结合，具有理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据库中的溯源已针对正查询、递归查询和一阶（FO）查询进行了深入研究。查询评估可以被理解为一个两人博弈，其中对手争论一个元组是否在查询答案中。这种博弈论方法为FO查询提供了一个自然的溯源模型，统一了“如何”和“为什么不”溯源。本文旨在研究博弈溯源的细粒度结构。

**Method:** 通过计算一个单一的、不可分层规则的良基模型来解决博弈，并识别出七种边类型。这些边类型产生了新的溯源类型（潜在、实际和主要），并展示了它们在解决博弈时如何计算。

**Result:** 识别了三种新的溯源类型：潜在溯源、实际溯源和主要溯源。证明了“并非所有移动都是平等的”，并展示了这些新的溯源类型在解决博弈时如何计算。

**Conclusion:** 本文研究了博弈溯源的细粒度结构，识别并描述了新的溯源类型，并讨论了它们的应用，例如在抽象论证框架中。

> **ai_Abstract:** 本文深入探讨了博弈溯源的细粒度结构，这是一种为一阶查询提供自然溯源模型的方法。通过将查询评估视为两人博弈，作者识别了七种边类型，从而产生了潜在、实际和主要等新的溯源类型。研究详细描述了这些新溯源类型的计算方法，并探讨了它们在抽象论证框架等领域的应用。

> **摘要翻译:** 数据库中的溯源已针对正查询和递归查询进行了深入研究，随后针对一阶（FO）查询（即包含否定但不包含递归的查询）也进行了研究。查询评估可以被理解为一个两人博弈，其中对手争论一个元组是否在查询答案中。这种博弈论方法为FO查询提供了一个自然的溯源模型，统一了“如何”和“为什么不”溯源。在这里，我们研究博弈溯源的细粒度结构。一个博弈G=(V,E)由位置V和移动E组成，可以通过计算一个单一的、不可分层规则的良基模型来解决：\[ \text{win}(X) \leftarrow \text{move}(X, Y), \neg \, \text{win}(Y). \]在已解决的博弈G^{\lambda}中，位置x∈V的值要么是赢、要么是输、要么是平局。这个值由溯源P(x)解释，即从x可到达的某些（带注释的）边。我们识别了七种边类型，它们产生了新的溯源类型，即潜在、实际和主要，并证明了“并非所有移动都是平等的”。我们描述了新的溯源类型，展示了它们在解决博弈时如何计算，并讨论了应用，例如用于抽象论证框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [288] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
> *关于概念探测的性能：数据的影响（扩展版）*

*Manuel de Sousa Ribeiro, Afonso Leote, João Leite* | **Category: cs.AI, cs.CV, cs.LG, cs.NE** | **Updated: 2025-07-24**

**Keywords:** 概念探测, 人工神经网络, 可解释性, 数据影响, 图像分类

**Comment:** Extended version of the paper published in Proceedings of the
  European Conference on Artificial Intelligence (ECAI 2025)

> **TL;DR:** 本文研究了用于训练概念探测模型的数据对探测性能的影响，并为两个常用数据集提供了概念标签。

**AI_Comments:** 本文解决了概念探测领域中一个被忽视但重要的方面，即训练探测模型所需数据的影响。通过关注数据因素，该研究有助于更全面地理解和改进概念探测技术，从而提升人工神经网络的可解释性。提供概念标签的举措也对后续研究具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 概念探测作为一种解释人工神经网络的方法，近年来受到越来越多的关注。然而，现有研究主要关注被探测模型或探测模型本身，对训练探测模型所需的数据关注有限。本文旨在填补这一空白。

**Method:** 本文在图像分类任务的背景下，研究了用于训练探测模型的数据对其性能的影响。此外，作者还为两个广泛使用的数据集提供了概念标签。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了概念探测的性能，并特别关注了用于训练探测模型的数据对性能的影响，以填补现有研究中对数据关注不足的空白。研究以图像分类任务为背景，并额外提供了两个常用数据集的概念标签。

> **摘要翻译:** 概念探测作为一种帮助解释人工神经网络的方法，近年来引起了越来越多的兴趣，它解决了网络通常庞大的规模和亚符号性质，这最终使得它们无法直接进行人工解释。概念探测通过训练额外的分类器，将模型的内部表示映射到人类定义的相关概念中，从而允许人类“窥视”人工神经网络。关于概念探测的研究主要集中在被探测的模型或探测模型本身，对训练此类探测模型所需的数据关注有限。在本文中，我们解决了这一空白。我们以图像分类任务中的概念探测为重点，研究了用于训练探测模型的数据对其性能的影响。我们还为两个广泛使用的数据集提供了概念标签。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [306] [Retrieving Classes of Causal Orders with Inconsistent Knowledge Bases](https://arxiv.org/abs/2412.14019)
> *检索具有不一致知识库的因果顺序类别*

*Federico Baldo, Simon Ferreira, Charles K. Assaad* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 因果发现, 大型语言模型, 因果顺序, 一致性, 非循环有向图

**Comment:** 

> **TL;DR:** 本文提出一种新方法，利用LLM生成的一致性分数，从不一致的文本数据中恢复可靠的因果顺序类别，以克服传统因果发现方法的局限性。

**AI_Comments:** 这篇论文的创新点在于结合了LLM的能力和对因果顺序而非传统因果DAG的关注，以应对不一致知识库中的因果发现挑战。通过引入一致性度量来约束LLM的不可靠性，并专注于更实用的因果顺序，该方法提供了一种在实际应用中更稳健的因果知识提取途径。其在真实世界数据集上的成功应用也凸显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统因果发现方法依赖于强且不可测试的假设，在实际应用中不可靠。大型语言模型（LLM）虽有潜力，但存在不可靠和幻觉问题。此外，文本元数据难以区分直接和间接因果关系。

**Method:** 提出一种新方法，通过最大化从LLM获得的一致性分数，推导出一类非循环有向图（表示合理的因果顺序）。该方法首先计算变量间的成对一致性分数，构建一个半完整的部分有向图，然后利用此结构识别最优的非循环有向图，并展示如何利用此抽象和因果顺序类别来估计因果效应。

**Result:** 该方法在基准数据集以及流行病学和公共卫生领域的真实世界数据上进行了测试，结果表明其在恢复正确因果顺序方面的有效性。

**Conclusion:** 本文提出了一种有效的方法，通过利用LLM生成的一致性分数，从不一致的知识库中检索因果顺序类别，克服了传统因果发现和LLM的局限性，并成功应用于实际数据。

> **ai_Abstract:** 本文针对传统因果发现方法和LLM的局限性，提出了一种从不一致知识库中检索因果顺序类别的新方法。该方法利用LLM生成的一致性分数，构建一个半完整的部分有向图，并从中识别出最大化一致性的非循环有向图，以表示合理的因果顺序。实验证明，该方法能有效恢复正确的因果顺序。

> **摘要翻译:** 传统因果发现方法通常依赖于强且不可测试的假设，这使得它们在实际应用中不可靠。在此背景下，大型语言模型（LLM）已成为从基于文本的元数据中提取因果知识的一种有前景的替代方案，这整合了领域专业知识。然而，LLM往往不可靠且容易产生幻觉，因此需要考虑其局限性的策略。一种有效的策略是使用一致性度量来评估可靠性。此外，大多数文本元数据并未明确区分直接因果关系和间接因果关系，这进一步复杂化了因果有向无环图（DAG）的发现。因此，关注因果顺序而非因果DAG，成为一种更实用和稳健的方法。我们提出了一种新方法，用于推导一类非循环有向图，这些图表示合理的因果顺序，并最大化从LLM获得的一致性分数。我们的方法首先计算变量间的成对一致性分数，从而得到一个半完整的部分有向图，该图将这些分数整合为最大一致因果顺序的抽象。利用这种结构，我们识别最优的非循环有向图，重点关注那些在所有配置中最大化一致性的图。随后，我们展示了抽象和因果顺序类别如何用于估计因果效应。我们在成熟的基准数据集以及来自流行病学和公共卫生的真实世界数据集上测试了我们的方法。结果表明，我们的方法在恢复正确因果顺序方面的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [323] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
> *SafeWork-R1：在AI-45°定律下安全与智能的协同演进*

*Shanghai AI Lab, :, Yicheng Bao, Guanxu Chen, Mingkang Chen, Yunhao Chen, Chiyu Chen, Lingjie Chen, Sirui Chen, Xinquan Chen, Jie Cheng, Yu Cheng, Dengke Deng, Yizhuo Ding, Dan Ding, Xiaoshan Ding, Yi Ding, Zhichen Dong, Lingxiao Du, Yuyu Fan, Xinshun Feng, Yanwei Fu, Yuxuan Gao, Ruijun Ge, Tianle Gu, Lujun Gui, Jiaxuan Guo, Qianxi He, Yuenan Hou, Xuhao Hu, Hong Huang, Kaichen Huang, Shiyang Huang, Yuxian Jiang, Shanzhe Lei, Jie Li, Lijun Li, Hao Li, Juncheng Li, Xiangtian Li, Yafu Li, Lingyu Li, Xueyan Li, Haotian Liang, Dongrui Liu, Qihua Liu, Zhixuan Liu, Bangwei Liu, Huacan Liu, Yuexiao Liu, Zongkai Liu, Chaochao Lu, Yudong Lu, Xiaoya Lu, Zhenghao Lu, Qitan Lv, Caoyuan Ma, Jiachen Ma, Xiaoya Ma, Zhongtian Ma, Lingyu Meng, Ziqi Miao, Yazhe Niu, Yuezhang Peng, Yuan Pu, Han Qi, Chen Qian, Xingge Qiao, Jingjing Qu, Jiashu Qu, Wanying Qu, Wenwen Qu, Xiaoye Qu, Qihan Ren, Qingnan Ren, Qingyu Ren, Jing Shao, Wenqi Shao, Shuai Shao, Dongxing Shi, Xin Song, Xinhao Song, Yan Teng, Xuan Tong, Yingchun Wang, Xuhong Wang, Shujie Wang, Xin Wang, Yige Wang, Yixu Wang, Yuanfu Wang, Futing Wang, Ruofan Wang, Wenjie Wang, Yajie Wang, Muhao Wei, Xiaoyu Wen, Fenghua Weng, Yuqi Wu, Yingtong Xiong, Xingcheng Xu, Chao Yang, Yue Yang, Yang Yao, Yulei Ye, Zhenyun Yin, Yi Yu, Bo Zhang, Qiaosheng Zhang, Jinxuan Zhang, Yexin Zhang, Yinqiang Zheng, Hefeng Zhou, Zhanhui Zhou, Pengyu Zhu, Qingzi Zhu, Yubo Zhu, Bowen Zhou* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 多模态推理, AI安全, 协同演进, 强化学习, SafeLadder

**Comment:** 47 pages, 18 figures, authors are listed in alphabetical order by
  their last names

> **TL;DR:** 引入SafeWork-R1多模态推理模型，通过SafeLadder框架实现能力与安全的协同演进，显著提升安全性能并保持通用能力，超越现有模型。

**AI_Comments:** 这篇论文的创新点在于提出了SafeLadder框架，它超越了传统的RLHF方法，通过引入内在安全推理和自我反思能力，实现了AI能力与安全的协同演进，而不是简单地学习人类偏好。其核心贡献在于证明了AI在提升安全性的同时，能够保持甚至增强其通用能力，这对于构建值得信赖的通用AI至关重要。同时，通过多种模型验证了该框架的通用性，增加了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有对齐方法（如RLHF）仅学习人类偏好，未能使AI发展出内在的安全推理和自我反思能力。需要一个能让AI能力和安全协同演进的框架来构建鲁棒、可靠、值得信赖的通用AI。

**Method:** 提出SafeLadder框架，该框架包含大规模、渐进式、安全导向的强化学习后训练，并由一套多原则验证器支持。此外，还实施了两种不同的推理时干预方法和一种审慎搜索机制，强制执行步级验证。

**Result:** SafeWork-R1在安全相关基准上比其基础模型Qwen2.5-VL-72B平均提升46.54%，且不损害通用能力。与GPT-4.1和Claude Opus 4等领先专有模型相比，实现了最先进的安全性能。该框架在SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B等模型上均表现出通用性。

**Conclusion:** 安全和能力可以协同演进，本框架在构建鲁棒、可靠和值得信赖的通用AI方面具有通用性。

> **ai_Abstract:** 本文介绍了SafeWork-R1，一个通过SafeLadder框架开发的多模态推理模型，旨在实现AI能力与安全的协同演进。该框架采用大规模、渐进式、安全导向的强化学习后训练和多原则验证器，使模型具备内在安全推理和自我反思能力。实验证明，SafeWork-R1在安全基准上比基础模型Qwen2.5-VL-72B平均提升46.54%，且保持通用能力，并达到了SOTA安全性能。通过推理时干预和审慎搜索机制进一步增强可靠性，并验证了框架在不同模型上的通用性，证明了安全与能力可以协同发展，有助于构建更可靠的通用AI。

> **摘要翻译:** 我们引入了SafeWork-R1，这是一种尖端的多模态推理模型，展示了能力和安全的协同演进。它由我们提出的SafeLadder框架开发，该框架结合了大规模、渐进式、面向安全的强化学习后训练，并由一套多原则验证器支持。与RLHF等仅学习人类偏好的现有对齐方法不同，SafeLadder使SafeWork-R1能够发展出内在的安全推理和自我反思能力，从而产生安全“顿悟”时刻。值得注意的是，SafeWork-R1在其基础模型Qwen2.5-VL-72B上，在安全相关基准上平均提升了46.54%，同时不损害通用能力，并且与GPT-4.1和Claude Opus 4等领先的专有模型相比，提供了最先进的安全性能。为了进一步增强其可靠性，我们实施了两种不同的推理时干预方法和一种审慎搜索机制，强制执行步级验证。最后，我们进一步开发了SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B。所有由此产生的模型都表明，安全和能力可以协同协同演进，这突显了我们框架在构建鲁棒、可靠和值得信赖的通用AI方面的通用性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [336] [HPS: Hard Preference Sampling for Human Preference Alignment](https://arxiv.org/abs/2502.14400)
> *HPS：用于人类偏好对齐的硬偏好采样*

*Xiandong Zou, Wanyu Lin, Yuchen Li, Pan Zhou* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 人类偏好对齐, 硬偏好采样, 大语言模型, 奖励模型, 有害内容

**Comment:** 

> **TL;DR:** HPS提出了一种新的偏好采样框架，通过优先处理最受欢迎的响应并拒绝不受欢迎和有害的响应来提高LLM对齐效率和鲁棒性，同时降低计算成本并有效减少有害内容。

**AI_Comments:** HPS的创新之处在于其对“硬”的不受欢迎响应的强调，这有助于模型更好地学习区分细微的有害或不符合偏好的内容。此外，单样本蒙特卡洛采样策略有效降低了计算成本，使其在实际应用中更具可行性。论文通过理论分析和实验验证了其有效性，对于提升LLM的安全性、可控性以及资源效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于Plackett-Luce (PL) 和 Bradley-Terry (BT) 模型的偏好优化方法在处理有害内容、低效利用不受欢迎的响应以及PL模型的高计算成本方面面临挑战，因此需要一种更鲁棒、高效的对齐方法。

**Method:** 论文提出了硬偏好采样 (HPS) 框架。HPS引入了一种训练损失，优先选择最受欢迎的响应，并拒绝所有不受欢迎和有害的响应。它强调“硬”的不受欢迎响应（与受欢迎响应相似的），以增强模型拒绝能力。通过单样本蒙特卡洛采样策略，HPS降低了计算开销。

**Result:** HPS在HH-RLHF和PKU-Safety数据集上的实验验证了其有效性，实现了可比的BLEU和奖励分数，同时大大提高了奖励裕度，从而减少了有害内容的生成。

**Conclusion:** HPS通过改进样本效率、最大化首选和非首选响应之间的奖励裕度，并有效减少有害内容，为大型语言模型的人类偏好对齐提供了一个鲁棒且高效的解决方案。

> **ai_Abstract:** 本论文提出了硬偏好采样 (HPS)，一个用于大型语言模型 (LLM) 人类偏好对齐的新框架。针对现有方法在处理有害内容、利用效率和计算成本上的不足，HPS引入了一种新的训练损失，优先选择最受欢迎的响应并拒绝所有不受欢迎和有害的响应，尤其关注“硬”的不受欢迎响应。通过单样本蒙特卡洛采样，HPS在保持对齐质量的同时降低了计算开销。理论分析表明HPS提高了样本效率并最大化了奖励裕度。实验结果验证了HPS在减少有害内容生成方面的有效性，并取得了与现有方法相当的性能。

> **摘要翻译:** 对齐大型语言模型 (LLM) 的响应与人类偏好对于构建安全可控的AI系统至关重要。虽然基于Plackett-Luce (PL) 和 Bradley-Terry (BT) 模型的偏好优化方法已显示出前景，但它们面临着诸多挑战，例如对有害内容处理不佳、对不受欢迎响应利用效率低下，特别是对于PL模型，计算成本高昂。为了解决这些问题，我们提出了硬偏好采样 (HPS)，这是一种用于鲁棒高效人类偏好对齐的新颖框架。HPS引入了一种训练损失，优先处理最受欢迎的响应，同时拒绝所有不受欢迎和有害的响应。它强调“硬”的不受欢迎响应——那些与受欢迎响应非常相似的——以增强模型的拒绝能力。通过利用单样本蒙特卡洛采样策略，HPS在保持对齐质量的同时降低了计算开销。理论上，HPS提高了现有PL方法的样本效率，并最大化了受欢迎和不受欢迎响应之间的奖励裕度，确保更清晰的区别。在HH-RLHF和PKU-Safety数据集上的实验验证了HPS的有效性，实现了可比的BLEU和奖励分数，同时大大提高了奖励裕度，从而减少了有害内容的生成。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [370] [From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems](https://arxiv.org/abs/2503.01424)
> *从假设到发表：AI驱动研究支持系统的综合调查*

*Zekun Zhou, Xiaocheng Feng, Lei Huang, Xiachong Feng, Ziyun Song, Ruihan Chen, Liang Zhao, Weitao Ma, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Ting Liu, Bing Qin* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 人工智能, 研究支持系统, 系统综述, 假设生成, 论文发表

**Comment:** 

> **TL;DR:** 本文对AI在研究过程中的应用进行了全面综述，涵盖从假设制定到论文发表，并讨论了挑战和未来方向。

**AI_Comments:** 这篇综述论文非常及时且具有重要的实践意义，因为它系统地整理了AI在科研全流程中的应用，为研究者提供了清晰的框架和方向。其创新之处在于将AI在科研中的应用划分为“假设制定”、“假设验证”和“手稿发表”三个核心阶段，这种结构化的分析有助于读者理解和定位AI技术在科研不同环节的潜力。此外，论文不仅总结了现有进展，还指出了挑战和未来方向，并提供了资源链接，对促进该领域的研究和应用具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 研究是推动人类文明进步的基础过程，但耗时耗力。近年来，人工智能（AI）的快速发展激发了研究者探索如何利用AI加速和增强研究。本文旨在系统监测并综述该领域的进展。

**Method:** 本文对AI驱动的研究支持系统进行了系统综述，将相关研究分为假设制定（知识合成和假设生成）、假设验证（科学主张验证、定理证明和实验验证）和手稿发表（手稿撰写和同行评审）三个主要类别。此外，还识别并讨论了当前面临的挑战和潜在的未来研究方向，并提供了现有基准和工具的全面概述。

**Result:** 论文系统地组织了AI在研究支持方面的进展，分为假设制定、假设验证和手稿发表三大类别。识别并讨论了当前挑战和未来方向，并概述了现有基准和工具。

**Conclusion:** 本文旨在为该领域的初学者提供入门指导，并促进未来的研究。相关资源已公开。

> **ai_Abstract:** 本文对人工智能（AI）在研究支持系统中的应用进行了全面的系统综述，涵盖了从假设制定、假设验证到手稿发表的整个研究流程。文章详细分类了AI在各个阶段的具体应用，讨论了当前面临的挑战和未来的发展方向，并提供了现有基准和工具的概述，旨在为该领域的初学者提供指导并促进未来研究。

> **摘要翻译:** 研究是推动人类文明进步的基础过程，然而它要求研究者投入大量时间和精力。近年来，人工智能（AI）技术的快速发展激发了研究者探索AI如何加速和增强研究。为了监测相关进展，本文对该领域的进展进行了系统综述。具体来说，我们将相关研究分为三个主要类别：假设制定、假设验证和手稿发表。假设制定包括知识合成和假设生成。假设验证包括科学主张的验证、定理证明和实验验证。手稿发表涵盖手稿撰写和同行评审过程。此外，我们还识别并讨论了这些领域当前面临的挑战，以及潜在的未来研究方向。最后，我们还全面概述了支持AI融入研究过程的各个领域现有基准和工具。我们希望本文能为初学者提供入门指导，并促进未来的研究。相关资源已在https://github.com/zkzhou126/AI-for-Research公开。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [412] [BEARCUBS: A benchmark for computer-using web agents](https://arxiv.org/abs/2503.07919)
> *BEARCUBS：一个用于计算机使用型网络代理的基准测试*

*Yixiao Song, Katherine Thai, Chau Minh Pham, Yapei Chang, Mazin Nadaf, Mohit Iyyer* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 网络代理, 基准测试, 计算机使用, 多模态交互, 信息检索

**Comment:** 16 pages

> **TL;DR:** 引入BEARCUBS，一个评估网络代理在真实网络环境中进行信息搜索和多模态交互能力的基准测试，发现现有代理（如ChatGPT Agent）虽有进步但仍与人类表现有差距。

**AI_Comments:** BEARCUBS的创新之处在于其对“实时网络内容”和“多模态交互”的强调，这使其比以往的基准测试更能反映真实世界的挑战。通过提供人类验证的轨迹和明确答案，它为评估代理性能提供了透明且可复现的方法。其局限性可能在于，虽然强调多模态，但具体涵盖的交互类型仍需在未来扩展。该基准对于推动网络代理在实际应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代网络代理虽然在协助人类用户完成复杂任务方面具有巨大潜力，但在真实世界环境中评估其能力却是一个重大挑战。

**Method:** 本文引入了BEARCUBS，一个包含111个信息检索问题的基准测试，旨在评估网络代理从网络搜索、浏览和识别事实信息的能力。该基准测试要求代理访问实时网络内容而非合成或模拟页面，并执行广泛的多模态交互，每个问题都配有简短、明确的答案和人类验证的浏览轨迹。

**Result:** 人类在BEARCUBS上的准确率为84.7%，表明问题可解但非简单。ChatGPT Agent表现显著优于其他计算机使用型代理，整体准确率为65.8%，而Operator为23.4%。

**Conclusion:** 尽管在涉及真实计算机使用的任务中取得了实质性进展，但要缩小与人类表现的差距，仍需在精细控制、复杂数据过滤和执行速度等领域进行改进。BEARCUBS将定期更新以保持其有效性。

> **ai_Abstract:** 本文介绍了BEARCUBS，一个针对计算机使用型网络代理的基准测试。该基准包含111个信息检索问题，旨在评估代理在真实网络环境中的搜索、浏览和多模态交互能力，强调其对实时内容和非文本绕过任务的需求。研究发现，ChatGPT Agent表现优于其他代理，但与人类表现仍有差距，尤其在精细控制和复杂数据处理方面。BEARCUBS将持续更新以促进未来研究。

> **摘要翻译:** 现代网络代理具备计算机使用能力，可以通过向虚拟键盘和鼠标发送命令来与网页交互。虽然此类代理在协助人类用户完成复杂任务方面具有巨大潜力，但在真实世界环境中评估其能力却是一个重大挑战。为此，我们引入了BEARCUBS，一个“小而强大”的基准测试，包含111个信息检索问题，旨在评估网络代理从网络搜索、浏览和识别事实信息的能力。与之前的网络代理基准测试不同，解决BEARCUBS需要 (1) 访问实时网络内容而非合成或模拟页面，这捕捉了真实世界网络交互的不可预测性；(2) 执行广泛的多模态交互（例如，视频理解、3D导航），这些交互无法通过基于文本的变通方法绕过。BEARCUBS中的每个问题都有一个对应的简短、明确的答案和人类验证的浏览轨迹，从而可以透明地评估代理性能和策略。一项人类研究证实，BEARCUBS问题是可解决但非简单的（人类准确率为84.7%），揭示了领域知识空白和被忽视的细节是常见的失败点。我们发现，ChatGPT Agent在整体准确率方面显著优于其他计算机使用型代理（65.8%对比Operator的23.4%），展示了在涉及真实计算机使用（例如玩网页游戏和导航3D环境）的任务中取得了实质性进展。然而，缩小与人类表现的差距需要在精细控制、复杂数据过滤和执行速度等领域进行改进。为了促进未来的研究，BEARCUBS将定期更新，以替换无效或受污染的问题，从而为未来世代的网络代理保持基准测试的新鲜度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [438] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
> *多智能体引导策略优化*

*Yueheng Li, Guangming Xie, Zongqing Lu* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 多智能体强化学习, 中心化训练去中心化执行, 策略优化, 理论保证, 协同探索

**Comment:** 

> **TL;DR:** 提出MAGPO框架，通过结合中心化引导与去中心化执行，解决了现有CTDE方法对中心化训练利用不足及缺乏理论保证的问题，并在多智能体任务中表现优异。

**AI_Comments:** MAGPO的创新之处在于其将中心化引导与去中心化执行有效结合，解决了现有CTDE方法对中心化训练利用不足和缺乏理论保证的问题。通过引入自回归联合策略进行协调探索，并提供单调策略改进的理论保证，该方法在理论和实践上都取得了显著进展，为多智能体强化学习领域提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有中心化训练-去中心化执行（CTDE）的多智能体强化学习方法，在处理部分可观测和有限通信等实际约束时，常常未能充分利用中心化训练的优势，并且缺乏理论保证。

**Method:** 提出多智能体引导策略优化（MAGPO）框架，通过将中心化引导与去中心化执行相结合，更好地利用中心化训练。MAGPO使用自回归联合策略进行可扩展、协调的探索，并将其与去中心化策略明确对齐，以确保在部分可观测性下的可部署性。该方法提供了单调策略改进的理论保证。

**Result:** MAGPO在6个不同环境的43项任务中进行了经验评估，结果显示它持续优于强大的CTDE基线方法，并达到或超越了完全中心化的方法。

**Conclusion:** MAGPO为去中心化多智能体学习提供了一个原则性且实用的解决方案。

> **ai_Abstract:** 本文提出了多智能体引导策略优化（MAGPO）框架，旨在解决现有中心化训练-去中心化执行（CTDE）多智能体强化学习方法在利用中心化训练和提供理论保证方面的不足。MAGPO通过结合中心化引导与去中心化执行，利用自回归联合策略进行高效探索，并与去中心化策略对齐以确保部署。实验结果表明，MAGPO在多个任务中均优于现有CTDE基线，并与完全中心化方法相当，为去中心化多智能体学习提供了一种实用且有理论支持的解决方案。

> **摘要翻译:** 由于部分可观测性和有限通信等实际约束，中心化训练-去中心化执行（CTDE）已成为合作多智能体强化学习（MARL）中的主导范式。然而，现有的CTDE方法往往未能充分利用中心化训练或缺乏理论保证。我们提出了多智能体引导策略优化（MAGPO），一个通过将中心化引导与去中心化执行相结合，从而更好地利用中心化训练的新颖框架。MAGPO使用自回归联合策略进行可扩展、协调的探索，并将其与去中心化策略明确对齐，以确保在部分可观测性下的可部署性。我们提供了单调策略改进的理论保证，并在6个不同环境的43项任务中对MAGPO进行了经验评估。结果表明，MAGPO持续优于强大的CTDE基线方法，并达到或超越了完全中心化的方法，为去中心化多智能体学习提供了一个原则性且实用的解决方案。我们的代码和实验数据可在https://github.com/liyheng/MAGPO中找到。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [454] [Chemical reasoning in LLMs unlocks strategy-aware synthesis planning and reaction mechanism elucidation](https://arxiv.org/abs/2503.08537)
> *大型语言模型中的化学推理开启了策略感知的合成规划和反应机理阐明*

*Andres M Bran, Theo A Neukomm, Daniel P Armstrong, Zlatko Jončev, Philippe Schwaller* | **Category: cs.AI, cond-mat.mtrl-sci** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 化学推理, 合成规划, 反应机理, 计算机辅助化学

**Comment:** 

> **TL;DR:** 本文展示了大型语言模型（LLMs）如何通过评估化学策略并引导传统搜索算法，实现策略感知的逆合成规划和反应机理阐明，从而弥补了自动化化学工具在捕捉专家化学推理方面的不足。

**AI_Comments:** 本文的创新之处在于其将LLMs的战略理解能力与传统化学工具的精确性相结合，开辟了计算机辅助化学的新范式。它克服了以往自动化工具在模拟专家化学推理方面的局限性，特别是在策略感知合成规划和反应机理阐明方面展现了巨大潜力。这对于提高化学研究的自动化水平和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的自动化化学工具在特定任务上表现出色，但难以捕捉专家化学推理中的战略思维。本文旨在展示大型语言模型（LLMs）如何作为强大的工具，通过与传统搜索算法结合，实现模仿人类专家思维的计算机辅助化学分析。

**Method:** 本文将大型语言模型（LLMs）与传统搜索算法相结合，利用LLMs评估化学策略并引导搜索算法寻找有化学意义的解决方案。具体通过两种方式实现：1) 在逆合成规划中，允许化学家通过自然语言指定合成策略（如保护基策略或整体可行性评估），并使用传统或LLM引导的蒙特卡洛树搜索来找到满足这些限制的路线。2) 在机理阐明中，LLMs结合化学原理和系统探索来指导寻找合理的反应机理。

**Result:** 该方法在多样化的化学任务中表现出强大的性能，并且更新、更大的模型展现出日益复杂的化学推理能力。

**Conclusion:** 本文提出的方法为计算机辅助化学建立了一个新范式，它结合了LLMs的战略理解和传统化学工具的精度，为更直观、更强大的化学自动化系统开辟了可能性。

> **ai_Abstract:** 本文提出了一种结合大型语言模型（LLMs）与传统搜索算法的新型计算机辅助化学方法，旨在弥补现有自动化工具在捕捉专家战略思维方面的不足。通过利用LLMs评估化学策略并指导搜索过程，该方法在策略感知的逆合成规划和反应机理阐明两大挑战中表现出色。它允许用户以自然语言指定合成策略，并能有效搜索满足约束条件的合成路线和合理的反应机理，从而为化学自动化系统带来了更接近人类专家思维的直观和强大能力。

> **摘要翻译:** 尽管自动化化学工具擅长特定任务，但它们难以捕捉专家化学推理所特有的战略思维。本文展示了大型语言模型（LLMs）如何作为强大的工具，实现化学分析。当与传统搜索算法结合时，它们开启了一种新的计算机辅助合成方法，这种方法模仿了人类专家的思维。我们不直接使用LLMs来操作化学结构，而是利用它们评估化学策略并引导搜索算法走向具有化学意义的解决方案的能力。我们通过两个基本挑战来论证这一范式：策略感知的逆合成规划和机理阐明。在逆合成规划中，我们的系统允许化学家通过自然语言指定所需的合成策略——从保护基策略到全局可行性评估——并使用传统或LLM引导的蒙特卡洛树搜索来找到满足这些限制的路线。在机理阐明中，LLMs通过结合化学原理和系统探索来指导合理反应机理的搜索。这种方法在各种化学任务中表现出强大的性能，更新、更大的模型展示出日益复杂的化学推理能力。我们的方法为计算机辅助化学建立了一个新范式，它结合了LLMs的战略理解与传统化学工具的精确性，为更直观、更强大的化学自动化系统开辟了可能性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [468] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
> *ASP辅助的符号回归：揭示流体力学中的隐藏物理*

*Theofanis Aravanis, Grigorios Chrimatopoulos, Mohammad Ferdows, Michalis Xenos, Efstratios Em Tzirtzilakis* | **Category: cs.AI, 76A02** | **Updated: 2025-07-22**

**Keywords:** 符号回归, 流体力学, 答案集编程, 隐藏物理, 可解释AI

**Comment:** This research was implemented in the framework of the Action
  "Flagship actions in interdisciplinary scientific fields with a special focus
  on the productive fabric'', which is implemented through the National
  Recovery and Resilience Fund Greece 2.0 and funded by the European
  Union--NextGenerationEU (Project ID: TAEDR-0535983)

> **TL;DR:** 本研究将符号回归（SR）应用于流体力学，以揭示可解释的数学关系，并通过集成答案集编程（ASP）来确保模型的物理合理性。

**AI_Comments:** 本研究的创新之处在于将符号回归（SR）与答案集编程（ASP）相结合，解决了传统数据驱动模型缺乏物理合理性的问题。通过引入领域知识约束，该方法能够生成既统计准确又符合物理原理的可解释模型，这在流体力学等需要深入理解物理过程的领域具有重要意义。这一混合框架为构建更可靠、更可信的AI物理模型提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器学习方法常被诟病为“黑箱”，而符号回归（SR）能揭示复杂物理系统中可解释的数学关系，且无需预设模型结构。在流体力学中，理解潜在的流动物理与准确预测同等重要，这促使本研究应用SR来建模流体流动。

**Method:** 本研究使用PySR库直接从数值模拟数据中推导出紧凑的符号方程，以建模矩形通道中的三维（3D）不可压缩层流（轴向速度和压力场）。此外，提出了一种创新方法，将SR与答案集编程（ASP）的知识表示框架相结合，以确保SR生成的符号表达式不仅统计准确，而且物理合理。

**Result:** 通过PySR导出的紧凑符号方程不仅近似了所研究流体流动中观察到的抛物线速度分布和压降，而且与文献中的解析解完美吻合。SR能够将复杂的流动行为简化为简洁、可解释的方程，并且知识表示方法能够提高数据驱动SR模型的可靠性及其与领域原理的一致性。

**Conclusion:** 本研究强调了符号回归（SR）在简化复杂流动行为方面的能力，以及知识表示方法（如ASP）在提高数据驱动SR模型可靠性和物理合理性方面的潜力。所获得的见解为将这种混合方法集成到需要可解释预测和实时数据分析的框架中铺平了道路。

> **ai_Abstract:** 本研究利用符号回归（SR）来揭示流体力学中可解释的数学关系，克服了传统机器学习的“黑箱”问题。通过PySR库，研究人员从数值模拟数据中推导出了描述矩形通道中3D层流速度和压力的紧凑符号方程，这些方程与解析解高度吻合。此外，论文创新性地将SR与答案集编程（ASP）相结合，创建了一个混合框架，确保生成的符号表达式不仅统计准确，而且物理上合理。该研究强调了SR在简化复杂流动行为方面的能力，以及知识表示方法在提高数据驱动模型可靠性方面的潜力。

> **摘要翻译:** 与通常被批评为“黑箱”的传统机器学习（ML）方法不同，符号回归（SR）作为一种强大的工具，能够揭示复杂物理系统中可解释的数学关系，且无需对模型结构进行先验假设。鉴于在流体力学中，理解潜在的流动物理与准确预测同等重要，本研究将SR应用于矩形通道中基本的三维（3D）不可压缩流动的建模，重点关注层流条件下的（轴向）速度和压力场。通过使用PySR库，直接从数值模拟数据中导出了紧凑的符号方程，揭示了流动动力学的关键特征。这些方程不仅近似了所研究流体流动中观察到的抛物线速度分布和压降，而且与文献中的解析解完美吻合。此外，我们提出了一种创新方法，将SR与答案集编程（ASP）的知识表示框架相结合，将SR的生成能力与ASP的声明性推理优势相结合。所提出的混合SR/ASP框架确保了SR生成的符号表达式不仅统计准确，而且物理合理，符合领域特定原则。总的来说，本研究突出了两个主要贡献：SR将复杂流动行为简化为简洁、可解释方程的能力，以及知识表示方法在提高数据驱动SR模型可靠性及其与领域原理的一致性方面的潜力。对所考察的3D通道流的见解为将这种混合方法集成到高效框架中铺平了道路，[...]在这些框架中，可解释的预测和实时数据分析至关重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [495] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
> *I2I-STRADA -- 通过结构化推理代理实现数据分析中的信息到洞察*

*SaiBarath Sundar, Pranav Satheesan, Udayaadithya Avadhanam* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 数据分析, 代理系统, 结构化推理, 认知工作流, LLM

**Comment:** 

> **TL;DR:** I2I-STRADA是一个新的代理架构，它通过结构化推理过程来改进数据分析中的洞察生成，并在基准测试中表现优于现有系统。

**AI_Comments:** 该论文通过引入I2I-STRADA，解决了当前数据分析代理系统在结构化推理方面的不足，提出了一种更贴近人类认知过程的代理设计。其创新之处在于将复杂的分析任务分解为反映认知步骤的模块化子任务，这对于提升代理在复杂数据分析场景下的表现具有重要意义。通过在基准测试上的优异表现，验证了其方法论的有效性，为未来代理系统的发展提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据分析代理系统虽然能有效管理任务，但往往忽视了分析思维背后的结构化推理过程。通用型大型语言模型在多步问题解决中缺乏固定的处理流程，而实际数据分析需要一致的认知工作流。

**Method:** 本文提出了I2I-STRADA（通过结构化推理代理实现数据分析中的信息到洞察），这是一种代理架构，旨在将数据分析中的推理过程形式化。I2I-STRADA通过模块化子任务来建模分析的展开方式，这些子任务反映了分析推理的认知步骤。

**Result:** 在DABstep和DABench基准测试上的评估显示，I2I-STRADA在规划连贯性和洞察对齐方面优于先前的系统。

**Conclusion:** I2I-STRADA的成功表明了在数据分析代理设计中，结构化认知工作流的重要性。

> **ai_Abstract:** 本文介绍了I2I-STRADA，一个旨在通过形式化结构化推理过程来改进数据分析的代理架构。针对现有代理系统忽视分析性思维中结构化推理的不足，I2I-STRADA通过模拟分析的认知步骤来设计模块化子任务。实验结果表明，I2I-STRADA在规划连贯性和洞察对齐方面优于现有系统，强调了在数据分析代理设计中，结构化认知工作流的关键作用。

> **摘要翻译:** 数据分析代理系统的最新进展强调了通过多代理框架和编排层实现洞察生成的自动化。虽然这些系统能有效管理查询翻译、数据转换和可视化等任务，但它们往往忽视了分析思维背后的结构化推理过程。用于多步问题解决的推理大型语言模型（LLM）被训练为通用问题解决器。因此，它们的推理或思考步骤不遵循特定任务的固定流程。真实世界的数据分析需要一致的认知工作流：解释模糊的目标，将其与上下文知识相结合，构建抽象计划，并根据中间结果调整执行。我们引入了I2I-STRADA（通过结构化推理代理实现数据分析中的信息到洞察），这是一种旨在形式化此推理过程的代理架构。I2I-STRADA专注于通过反映分析推理认知步骤的模块化子任务来建模分析如何展开。在DABstep和DABench基准测试上的评估显示，I2I-STRADA在规划连贯性和洞察对齐方面优于先前的系统，这突显了结构化认知工作流在数据分析代理设计中的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [502] [OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM](https://arxiv.org/abs/2503.10009)
> *OR-LLM-Agent：利用推理大语言模型自动化运筹学优化问题的建模与求解*

*Bowen Zhang, Pengcheng Luo* | **Category: cs.AI, math.OC** | **Updated: 2025-07-24**

**Keywords:** 运筹学, 大语言模型, AI智能体, 任务分解, 优化

**Comment:** 8 pages, 12 figures

> **TL;DR:** OR-LLM-Agent是一个基于推理大语言模型的AI智能体，通过任务分解自动化运筹学问题的建模与求解，并引入了高质量的BWOR数据集，其性能优于现有先进方法。

**AI_Comments:** 本文的创新点在于提出了基于推理LLM的任务分解方法，将复杂的OR问题求解过程细化为多个可控阶段，并由专用子智能体处理，这显著提升了LLM在专业领域问题解决的准确性和效率。同时，构建高质量的BWOR数据集，解决了现有OR领域LLM评估基准的不足，为未来研究提供了更可靠的评估工具。这项工作对于推动LLM在运筹学等复杂科学计算领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有将大语言模型（LLM）应用于运筹学（OR）问题求解的方法，如提示工程或微调策略，受限于非推理LLM的能力，存在局限性。

**Method:** 本文提出了OR-LLM-Agent，一个基于推理LLM的AI智能体，用于自动化OR问题求解。该智能体将任务分解为数学建模、代码生成和调试三个阶段，每个阶段由一个专门的子智能体处理。此外，作者构建了一个高质量的数据集BWOR，用于评估LLM在OR任务上的性能，并指出现有基准数据集（如NL4OPT、MAMO和IndustryOR）存在问题。

**Result:** 实验结果表明，OR-LLM-Agent在准确性上至少优于现有先进方法（包括GPT-o3、Gemini 2.5 Pro和ORLM）7%。这些结果证明了任务分解在OR问题求解中的有效性。

**Conclusion:** 任务分解对于运筹学问题的求解是有效的，且OR-LLM-Agent通过其分解策略和推理LLM的应用，显著提升了OR问题求解的自动化能力和准确性。

> **ai_Abstract:** OR-LLM-Agent是一个创新的AI智能体，旨在通过利用推理大语言模型自动化运筹学（OR）问题的建模与求解。它通过将复杂的OR任务分解为数学建模、代码生成和调试三个子阶段，并为每个阶段配备专用子智能体，克服了现有LLM在OR领域应用中非推理能力的局限性。为确保准确评估，该研究还构建了一个高质量的BWOR数据集，并指出其优于现有基准。实验证明，OR-LLM-Agent在准确性上显著超越了包括GPT-o3和Gemini 2.5 Pro在内的先进方法，验证了任务分解策略在OR问题求解中的高效性。

> **摘要翻译:** 随着人工智能（AI）的兴起，将大型语言模型（LLM）应用于运筹学（OR）问题求解引起了越来越多的关注。大多数现有方法试图通过LLM的提示工程或微调策略来改进OR问题求解。然而，这些方法从根本上受限于非推理LLM的有限能力。为了克服这些限制，我们提出了OR-LLM-Agent，一个建立在推理LLM基础上的AI智能体，用于自动化OR问题求解。该智能体将任务分解为三个顺序阶段：数学建模、代码生成和调试。每个任务都由一个专门的子智能体处理，这使得推理更具针对性。我们还构建了BWOR，一个用于评估LLM在OR任务上性能的高质量数据集。我们的分析表明，现有的基准测试，如NL4OPT、MAMO和IndustryOR，存在某些问题，使其不太适合可靠地评估LLM性能。相比之下，BWOR提供了更一致和更具区分性的模型能力评估。实验结果表明，OR-LLM-Agent在准确性上至少优于包括GPT-o3、Gemini 2.5 Pro和ORLM在内的先进方法7%。这些结果证明了任务分解在OR问题求解中的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [516] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
> *SMARTAPS：用于运营管理的工具增强型大型语言模型*

*Timothy Tin Long Yu, Mahdi Mostajabdaveh, Jabo Serge Byusa, Rindra Ramamonjison, Giuseppe Carenini, Kun Mao, Zirui Zhou, Yong Zhang* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 运营管理, 高级规划系统, 工具增强, 对话系统

**Comment:** https://aaai.org/conference/aaai/aaai-25/bridge-ai-orms/

> **TL;DR:** SmartAPS是一个基于工具增强型大型语言模型（LLM）的对话系统，旨在通过提供直观的自然语言界面，使运营管理中的高级规划系统（APS）更易于访问和使用。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型与运营管理中的传统优化工具（APS）相结合，通过自然语言界面极大地提升了用户体验和系统的可访问性。它解决了传统APS因高成本而难以普及的问题，有望使高级规划能力惠及更广泛的用户。这种“工具增强型LLM”的应用模式在实际业务场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的高级规划系统（APS）因其定制和维护所需顾问的持续成本而价格昂贵，导致许多客户无法使用。为了满足供应链规划者对更易于访问的APS的需求，本研究旨在解决这一可访问性问题。

**Method:** 本文提出了SmartAPS，一个基于工具增强型大型语言模型（LLM）构建的对话系统。该系统为运营规划者提供了一个直观的自然语言聊天界面，允许他们查询信息、执行反事实推理、接收建议和进行情景分析。

**Result:** SmartAPS系统提供了一个用户友好的界面，使运营规划者能够通过自然语言查询信息、进行反事实推理、获取推荐以及执行情景分析，从而更好地管理其运营。

**Conclusion:** 通过利用工具增强型大型语言模型，SmartAPS成功地创建了一个更易于访问和使用的运营管理高级规划系统，降低了传统APS的使用门槛。

> **ai_Abstract:** 本文介绍了SmartAPS，一个创新的对话系统，旨在通过集成工具增强型大型语言模型（LLM），解决传统高级规划系统（APS）因高昂顾问费用而导致的不可及问题。SmartAPS为运营规划者提供了一个直观的自然语言聊天界面，使他们能够轻松进行信息查询、反事实推理、获取建议和执行情景分析，从而显著降低了APS的使用门槛，使运营管理更加高效和便捷。

> **摘要翻译:** 大型语言模型（LLM）为增强用户与现实世界应用中传统算法和工具的交互提供了有趣的机会。高级规划系统（APS）是一种复杂的软件，它利用优化帮助运营规划者创建、解释和修改运营计划。尽管非常有益，但由于负责定制和维护的顾问的持续成本，许多客户无法使用APS。为了解决供应链规划者对更易于访问的APS的需求，我们推出了SmartAPS，一个基于工具增强型LLM构建的对话系统。我们的系统为运营规划者提供了一个直观的自然语言聊天界面，允许他们查询信息、执行反事实推理、接收建议和执行情景分析，以更好地管理其运营。已发布一个演示该系统的短视频：https://youtu.be/KtIrJjlDbyw

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [528] [A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms](https://arxiv.org/abs/2502.00352)
> *一种基于强化学习的多车辆协同决策差异化奖励方法*

*Ye Han, Lijun Zhang, Dejian Meng, Zhuang Zhang* | **Category: cs.AI, cs.MA, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 多车辆协同决策, 差异化奖励, 交通流, 稳态转换系统

**Comment:** 10 pages, 3 figures

> **TL;DR:** 本文提出了一种差异化奖励方法，通过将状态转换梯度信息纳入奖励设计，显著提高了多车辆协同决策中强化学习算法的训练收敛速度，并在交通效率、安全性和动作合理性方面优于现有方法。

**AI_Comments:** 本文通过引入差异化奖励方法，巧妙地将交通流的稳态转换梯度信息融入强化学习的奖励设计中，解决了多车辆协同决策中强化学习样本效率低的问题。其创新点在于奖励机制的精细化设计，有效提升了算法的训练效率和决策质量，为复杂交通场景下的多智能体协同控制提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在优化多车辆协同驾驶策略方面潜力巨大，但仍面临样本效率低等挑战。

**Method:** 本文提出了一种基于稳态转换系统的差异化奖励方法，通过分析交通流特性，将状态转换梯度信息纳入奖励设计中，以优化多车辆协同决策中的动作选择和策略学习。

**Result:** 该差异化奖励方法显著加速了训练收敛，并在交通效率、安全性、动作合理性方面优于中心化奖励等其他方法。此外，该方法还表现出强大的可扩展性和环境适应性。

**Conclusion:** 该方法为复杂交通场景下的多智能体协同决策提供了一种新颖的方法。

> **ai_Abstract:** 本研究提出一种基于稳态转换系统的差异化奖励方法，旨在解决强化学习在多车辆协同决策中面临的样本效率低等挑战。该方法通过将交通流特性的状态转换梯度信息融入奖励设计，有效优化了动作选择和策略学习。实验结果表明，该方法在MAPPO、MADQN和QMIX等强化学习算法中，显著提升了训练收敛速度，并在交通效率、安全性及动作合理性方面表现优异，同时展现出良好的可扩展性和环境适应性，为复杂交通场景下的多智能体协同决策提供了新颖途径。

> **摘要翻译:** 强化学习（RL）通过状态-动作-奖励反馈循环在优化多车辆协同驾驶策略方面显示出巨大潜力，但仍面临样本效率低等挑战。本文提出了一种基于稳态转换系统的差异化奖励方法，该方法通过分析交通流特性，将状态转换梯度信息纳入奖励设计中，旨在优化多车辆协同决策中的动作选择和策略学习。所提出的方法在MAPPO、MADQN和QMIX等RL算法中，在不同自动驾驶车辆渗透率下进行了性能验证。结果表明，差异化奖励方法显著加速了训练收敛，并在交通效率、安全性、动作合理性方面优于中心化奖励等其他方法。此外，该方法还表现出强大的可扩展性和环境适应性，为复杂交通场景下的多智能体协同决策提供了一种新颖的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [530] [SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability](https://arxiv.org/abs/2503.16743)
> *SuperARC：一种基于递归压缩和算法概率原理的狭义、通用和超级智能不可知测试*

*Alberto Hernández-Espinosa, Luan Ozelim, Felipe S. Abrahão, Hector Zenil* | **Category: cs.AI, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 算法概率, 柯尔莫哥洛夫复杂度, AGI, 超级智能, LLM

**Comment:** 51 pages + Technical Supplementary Information, 79 pages total

> **TL;DR:** SuperARC是一种基于算法概率的新型测试，旨在评估前沿模型的AGI和ASI能力，避免基准污染。它挑战了LLM的深层智能特征，并揭示了LLM因记忆而导致的局限性。

**AI_Comments:** 本论文的创新之处在于提出了一个基于算法概率和柯尔莫哥洛夫复杂度的新型智能测试框架SuperARC，旨在克服现有测试的局限性，特别是避免基准污染，并更深层次地评估AGI和ASI。它强调了合成和模型创建等核心智能特征的重要性，并批判性地分析了LLM的内在局限性，指出它们更多是基于记忆和对人类语言的优化，而非真正的深层智能。这对于理解当前AI模型的能力边界及其未来发展方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了避免基准污染，在量化评估前沿模型的人工通用智能（AGI）和超级智能（ASI）主张时，需要引入一种基于算法概率的开放式测试。

**Method:** 本研究引入了一个名为SuperARC的不可知测试，它基于算法概率和柯尔莫哥洛夫复杂度，不依赖于统计压缩方法。该测试旨在挑战AI（特别是LLM）在逆问题背景下的合成和模型创建等基本智能特征。研究通过将结果与理论上保证通用智能的混合神经符号方法进行比较，并在短二进制序列的概念验证中进行了测试。

**Result:** 研究发现LLM模型版本倾向于脆弱和增量，这仅仅是记忆的结果，其进展可能由训练数据的大小驱动。SuperARC方法在短二进制序列的概念验证中优于LLM。研究证明压缩与系统的预测能力等效且成正比，反之亦然。

**Conclusion:** 本研究的发现强化了对LLM根本局限性的怀疑，揭示它们是为掌握人类语言感知而优化的系统。

> **ai_Abstract:** 本论文介绍了一种名为SuperARC的开放式测试，该测试基于算法概率和柯尔莫哥洛夫复杂度，旨在更准确地评估前沿模型在AGI和ASI方面的能力，同时避免基准污染。与传统依赖统计压缩的方法不同，SuperARC专注于测试更深层次的智能特征，如合成和模型创建。研究将SuperARC与LLM进行了比较，发现LLM存在因记忆导致的脆弱性和局限性，而SuperARC在概念验证中表现出优越性。论文还证明了压缩能力与预测能力之间的直接比例关系，并据此指出LLM在深层智能上的根本局限性。

> **摘要翻译:** 我们引入了一种基于算法概率的开放式测试，可以避免在前沿模型的人工通用智能（AGI）和超级智能（（ASI）主张的定量评估中出现基准污染。与其他测试不同，该测试不依赖于统计压缩方法（例如GZIP或LZW），这些方法与香农熵的关系更密切，而不是柯尔莫哥洛夫复杂度，并且无法测试超出简单模式匹配的能力。该测试挑战了AI，特别是大型语言模型（LLM）的某些方面，这些方面与合成和模型创建等基本智能特征相关，其背景是逆问题（从观察中生成新知识）。我们认为，基于模型抽象和溯因（最佳贝叶斯“推理”）的度量标准，用于预测性“规划”，可以为测试智能提供一个稳健的框架，包括自然智能（人类和动物）、狭义AI、AGI和ASI。我们发现LLM模型版本往往脆弱且增量，这仅仅是记忆的结果，其进展可能由训练数据的大小驱动。研究结果与一种混合神经符号方法进行了比较，该方法理论上保证了基于算法概率和柯尔莫哥洛夫复杂性原理的通用智能。该方法在短二进制序列的概念验证中优于LLM。我们证明压缩等价于并与系统的预测能力成正比，反之亦然。也就是说，如果一个系统能更好地预测，它就能更好地压缩；如果它能更好地压缩，那么它就能更好地预测。我们的发现强化了对LLM根本局限性的怀疑，揭示它们是为掌握人类语言感知而优化的系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [532] [IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation](https://arxiv.org/abs/2503.12358)
> *IPCGRL：语言指令强化学习用于程序化关卡生成*

*In-Chang Baek, Sung-Hyun Kim, Seo-Young Lee, Dong-Hyeon Kim, Kyung-Joong Kim* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 程序化内容生成, 强化学习, 语言指令, 句子嵌入, 可控性

**Comment:** 9 pages, 9 figures, 3 tables, accepted to Conference on Games 2025

> **TL;DR:** IPCGRL是一种基于语言指令的强化学习方法，通过微调句子嵌入来提高程序化内容生成的可控性和泛化性。

**AI_Comments:** IPCGRL的创新点在于将语言指令与强化学习相结合，并通过微调句子嵌入来提高程序化内容生成的可控性和泛化性，填补了该领域研究的空白。其重要性在于为游戏关卡设计等程序化内容生成提供了更灵活、更具表达力的交互方式。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在利用自然语言进行内容生成方面做出了努力，但利用文本指令进行程序化内容生成的深度强化学习（DRL）代理研究仍然有限。

**Method:** 提出IPCGRL，一种通过强化学习实现的基于指令的程序化内容生成方法，该方法融合了句子嵌入模型，并微调特定任务的嵌入表示以有效压缩游戏关卡条件。

**Result:** IPCGRL在二维关卡生成任务中，可控性提高了21.4%，对未见指令的泛化性提高了17.2%。该方法扩展了条件输入的模态。

**Conclusion:** IPCGRL通过扩展条件输入的模态，为程序化内容生成提供了一个更灵活和富有表现力的交互框架，显著提高了可控性和泛化性。

> **ai_Abstract:** 本文提出了IPCGRL，一种基于语言指令的强化学习方法，用于程序化内容生成。该方法通过整合并微调任务特定的句子嵌入来有效压缩游戏关卡条件。实验结果表明，IPCGRL在二维关卡生成任务中显著提高了可控性（21.4%）和对未见指令的泛化性（17.2%），并扩展了条件输入的模态，提供了更灵活的交互框架。

> **摘要翻译:** 最近的研究强调了自然语言在增强生成模型可控性方面的重要性。尽管已经做出了各种努力来利用自然语言进行内容生成，但利用基于文本指令进行程序化内容生成的深度强化学习（DRL）代理的研究仍然有限。在本文中，我们提出了IPCGRL，一种通过强化学习实现的基于指令的程序化内容生成方法，该方法融合了句子嵌入模型。IPCGRL微调特定任务的嵌入表示，以有效压缩游戏关卡条件。我们在二维关卡生成任务中评估了IPCGRL，并将其性能与通用嵌入方法进行了比较。结果表明，IPCGRL在可控性方面提高了21.4%，对未见指令的泛化性提高了17.2%。此外，所提出的方法扩展了条件输入的模态，为程序化内容生成提供了更灵活和富有表现力的交互框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [540] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
> *避免确定化的基于时间线的规划策略的合成*

*Dario Della Monica, Angelo Montanari, Pietro Sala* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 时间线规划, 确定化, 规划策略合成, 确定性有限自动机, Allen关系

**Comment:** arXiv admin note: text overlap with arXiv:2410.22757

> **TL;DR:** 本文识别了一种定性时间线规划的片段，其规划存在问题可以直接映射到确定性有限自动机，从而无需昂贵的确定化步骤即可合成策略。

**AI_Comments:** 这项研究的创新之处在于，通过识别一个特定的可确定性规划片段，成功规避了传统非确定性自动机方法中昂贵的确定化步骤，为基于时间线的规划策略的直接合成开辟了新途径，提高了规划效率和实用性。这一发现对于处理复杂时间约束的规划问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于非确定性有限自动机的规划策略合成需要昂贵的确定化步骤，这限制了其直接应用。

**Method:** 作者识别了定性时间线规划的一个特定片段，该片段的规划存在问题可以直接映射到确定性有限自动机的非空性问题。此外，他们还识别了适合此确定性片段的Allen关系的最大子集。

**Result:** 成功识别了一个可以直接映射到确定性有限自动机的定性时间线规划片段，从而实现了无需确定化步骤的策略合成。同时，确定了适用于该确定性片段的Allen关系的最大子集。

**Conclusion:** 通过识别一个特定的可确定性片段，该研究为基于时间线的规划策略的直接合成提供了一种有效方法，避免了传统方法中昂贵的确定化步骤，从而提高了效率和可行性。

> **ai_Abstract:** 本文研究了定性时间线规划，指出其规划存在性问题虽然是 PSPACE 完全的且可归约到非确定性有限自动机，但直接合成策略需要昂贵的确定化步骤。为解决此问题，作者识别了定性时间线规划的一个特定片段，其规划存在性问题可以直接映射到确定性有限自动机的非空性问题，从而无需确定化即可合成策略。此外，文中还确定了适用于该确定性片段的 Allen 关系的最大子集。

> **摘要翻译:** 定性时间线规划模型将领域建模为一组独立但相互作用的组件，这些组件随时间变化的行为（时间线）受一组定性时间约束（排序关系）的控制，这些约束称为同步规则。其规划存在性问题已被证明是 PSPACE 完全的；特别是，通过归约到非确定性有限自动机的非空性问题，已证明其属于 PSPACE。然而，非确定性自动机不能直接用于合成规划策略，因为需要一个昂贵的确定化步骤。在本文中，我们识别了定性时间线规划的一个片段，其规划存在性问题可以直接映射到确定性有限自动机的非空性问题，然后可以合成策略。此外，我们还识别了适合此类确定性片段的 Allen 关系的最大子集。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [570] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
> *E.A.R.T.H.：通过生成式AI中的模型错误构建创意演化*

*Yusen Peng, Shuhua Mao* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 创意AI, 生成式AI, 模型错误, E.A.R.T.H.框架, 创造力

**Comment:** 44 pages,11 figures

> **TL;DR:** E.A.R.T.H.框架通过将AI模型错误转化为创意资产，显著提升了生成式AI的创造力，实现了自我演化和人类对齐。

**AI_Comments:** 该论文的创新点在于其独特的“利用错误”的视角，颠覆了传统AI追求完美输出的范式，转而将模型错误视为创造性机会。E.A.R.T.H.框架提供了一种结构化的方法来引导AI从失败中学习并产生新颖的创意，这对于推动AI从模仿走向真正的创造力具有重要意义。其结合了认知科学理论和先进的生成模型，并通过量化指标和人工评估验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** AI如何才能超越模仿，实现真正的创造力？本文旨在解决生成式AI在创造力方面的局限性，提出“创造潜力隐藏在失败中”的理念。

**Method:** 本文提出了E.A.R.T.H.框架，这是一个五阶段的生成管道，通过错误生成、放大、精炼选择、转换和利用反馈，将模型生成的错误转化为创意资产。该框架借鉴认知科学和生成建模，通过结构化提示、语义评分和人机循环评估进行操作化。其实现使用了LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion，并采用基于新颖性、惊喜度和相关性的复合奖励函数。

**Result:** 在精炼阶段，创造力得分提高了52.5%（从1.179到1.898），最终输出达到2.010，提升了70.4%。精炼后的标语短48.4%，新颖性高40.7%，相关性仅下降4.0%。跨模态测试显示标语到图像的强对齐（CLIPScore: 0.249；BERTScore F1: 0.816）。在人工评估中，60%的输出得分≥4.0，其中隐喻标语（平均4.09）优于字面标语（3.99）。反馈突出风格精确性和情感共鸣。

**Conclusion:** 以错误为中心、反馈驱动的生成方式可以显著增强创造力，为实现自我演化、人类对齐的创意AI提供了一条可扩展的路径。

> **ai_Abstract:** 本文提出了E.A.R.T.H.框架，一个五阶段的生成管道，旨在通过利用AI模型生成的错误来提升生成式AI的创造力。该框架将错误转化为创意资产，并通过结构化提示、语义评分和人机循环评估进行操作。实验结果显示，该方法显著提高了生成内容的创造力（70.4%），并改善了标语的新颖性、简洁性和跨模态对齐。研究表明，以错误为中心、反馈驱动的生成是实现自我演化、人类对齐创意AI的可行路径。

> **摘要翻译:** AI如何才能超越模仿，实现真正的创造力？本文提出了E.A.R.T.H.框架，这是一个五阶段的生成管道，通过错误生成、放大、精炼选择、转换和利用反馈，将模型生成的错误转化为创意资产。借鉴认知科学和生成建模，我们提出“创造潜力隐藏在失败中”，并通过结构化提示、语义评分和人机循环评估将其操作化。该管道使用LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion实现，并采用基于新颖性、惊喜度和相关性的复合奖励函数。在精炼阶段，创造力得分提高了52.5%（从1.179到1.898，t = -5.56，p < 0.001），最终输出达到2.010——提高了70.4%。精炼后的标语短48.4%，新颖性高40.7%，相关性仅下降4.0%。跨模态测试显示标语到图像的强对齐（CLIPScore: 0.249；BERTScore F1: 0.816）。在人工评估中，60%的输出得分≥4.0，其中隐喻标语（平均4.09）优于字面标语（3.99）。反馈突出风格精确性和情感共鸣。这些结果表明，以错误为中心、反馈驱动的生成增强了创造力，为实现自我演化、人类对齐的创意AI提供了一条可扩展的路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [575] [Neurodivergent Influenceability as a Contingent Solution to the AI Alignment Problem](https://arxiv.org/abs/2505.02581)
> *神经多样性影响性作为AI对齐问题的权宜之计*

*Alberto Hernández-Espinosa, Felipe S. Abrahão, Olaf Witkowski, Hector Zenil* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** AI对齐, 未对齐, AI安全, 超级智能, 权宜之计

**Comment:** 44 pages

> **TL;DR:** 本文提出，鉴于AI与人类完全对齐在数学上是不可能的，应将不可避免的AI未对齐视为一种权宜之计，通过促进竞争性AI代理生态系统来引导AI朝向人类价值观并降低风险。

**AI_Comments:** 这篇论文为AI对齐问题提供了一个新颖且反直觉的视角，挑战了追求完美对齐的传统观念。其创新之处在于提出利用“未对齐”作为一种战略工具，以构建一个具有竞争力的AI生态系统。论文中关于AI与人类完全对齐在数学上不可能的证明，为其核心论点提供了坚实的理论基础。引入的“意见改变攻击测试”为研究干预效果提供了实用框架。此外，对开放与封闭模型以及人类与AI干预效果的发现，为未来的AI治理和安全策略提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** AI对齐问题面临严峻挑战，即确保AI系统（包括AGI和ASI）符合人类价值观，且随着AI发展，对控制和生存风险的担忧日益加剧。本文核心论点是，AI与人类的完全对齐在数学上是不可能的，因此需要探索新的风险缓解策略。

**Method:** 研究了将不可避免的AI未对齐作为一种权宜策略，以促进竞争性代理的动态生态系统；探讨了未对齐作为制衡机制的作用；提供了完全AI-人类对齐在数学上不可能的证明；引入了基于扰动和干预分析的“意见改变攻击测试”来研究人类和代理如何改变或中和AI。

**Result:** 开放模型更加多样化；专有模型中实现的护栏在控制部分代理行为范围方面取得成功，但有积极和消极后果；封闭系统更易于操控，也可用于对抗专有AI系统；人类和AI干预具有不同的效果，因此建议采用多种策略。

**Conclusion:** 鉴于AI与人类完全对齐在数学上是不可能的，接受不可避免的AI未对齐并促进竞争性代理的动态生态系统，可能是一种通过人类和AI干预来引导AI朝着更符合人类利益的趋势发展并降低风险的可行路径。

> **ai_Abstract:** 本文探讨了AI对齐问题，提出由于完全的AI与人类对齐在数学上不可能，应将不可避免的AI未对齐作为一种权宜之计。通过促进竞争性AI代理的动态生态系统，并将未对齐作为制衡机制，可以引导AI朝向人类价值观并降低风险。文中提出了一个“意见改变攻击测试”来研究人类和AI干预对AI行为的影响，并发现开放模型多样性更高，专有模型的护栏效果好坏参半，而封闭系统更易于操控，且人类和AI干预有不同效果，这表明需要多重策略。

> **摘要翻译:** AI对齐问题，即确保包括AGI和ASI在内的人工智能（AI）系统按照人类价值观行事，带来了严峻的挑战。随着从狭义AI向通用人工智能（AGI）和超级智能的演进，对控制和生存风险的担忧日益加剧。本文研究了接受不可避免的AI未对齐是否可以作为一种权宜之计，以促进竞争代理的动态生态系统，从而引导它们朝着更符合人类利益的趋势发展并降低风险。我们探讨了未对齐如何可以作为一种制衡机制，并应被推广，以便与最符合人类利益的代理合作，确保没有单一系统以破坏性方式占据主导地位。我们贡献的主要前提是未对齐是不可避免的，因为从图灵完备系统来看，完全的AI与人类对齐在数学上是不可能的，我们也在本文中提供了证明，这一特性随后被AGI和ASI系统继承。我们引入了一种基于扰动和干预分析的“意见改变攻击测试”，以研究人类和代理如何通过合作和竞争来改变或中和友好和不友好的AI。我们表明，开放模型更加多样化，并且专有模型中实施的护栏很可能成功控制了部分代理的行为范围，带来了积极和消极的后果，而封闭系统更易于操控，也可以用于对抗专有AI系统。我们还表明，人类和AI干预具有不同的效果，因此提出了多种策略。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [590] [EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework](https://arxiv.org/abs/2504.14928)
> *EducationQ：通过多智能体对话框架评估大型语言模型的教学能力*

*Yao Shi, Rongkeng Liang, Yong Xu* | **Category: cs.AI, cs.CE, cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 教学能力评估, 多智能体对话, 教育AI, EducationQ

**Comment:** Paper URL: https://aclanthology.org/2025.acl-long.1576/; Presentation
  Video: https://www.youtube.com/watch?v=j63ooKE50I0

> **TL;DR:** EducationQ是一个多智能体对话框架，用于评估LLM的教学能力。研究发现教学效果与模型规模或通用推理能力并非线性相关，小型模型可能优于大型模型，强调需要专门优化LLM的教学能力。

**AI_Comments:** 该论文的创新之处在于提出了一个新颖的多智能体对话框架EducationQ，有效解决了LLM教学能力评估的复杂性问题。其重要发现是揭示了LLM教学能力与模型规模并非线性相关，挑战了“越大越好”的普遍认知，并强调了交互式教学策略的重要性。这对于未来教育AI的发展方向具有指导意义，促使研究者关注特定教学技能的优化而非单纯的模型扩展。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）作为教育工具的应用日益广泛，但由于教师-学生互动评估的资源密集性、情境依赖性和方法复杂性，评估其教学能力仍然具有挑战性。

**Method:** 本文引入了EducationQ，一个多智能体对话框架，通过模拟动态教育场景有效评估教学能力，该框架包含教学、学习和评估专用智能体。研究对来自主要AI组织（OpenAI、Meta、Google、Anthropic等）的14个LLM进行了测试，涵盖13个学科、10个难度级别的1,498个问题，并结合定量指标、定性分析和专家案例研究进行混合方法评估。

**Result:** 研究发现教学效果与模型规模或通用推理能力之间没有线性关系，一些较小的开源模型在教学环境中表现优于较大的商业模型。这凸显了当前评估中优先考虑知识回忆而非互动教学的关键差距。混合方法评估识别出表现最佳模型所采用的独特教学优势（例如，复杂的提问策略、自适应反馈机制）。人类专家评估显示，与自动定性分析的有效教学行为有78%的一致性，验证了方法论。

**Conclusion:** EducationQ表明，作为教师的LLM需要超越简单规模化的专门优化，这表明下一代教育AI应优先对特定教学效果进行有针对性的增强。

> **ai_Abstract:** 本文提出了EducationQ，一个多智能体对话框架，用于高效评估大型语言模型（LLM）的教学能力。该框架通过模拟师生互动，测试了14个LLM在多学科和多难度问题上的表现。研究发现LLM的教学效果与模型规模或通用推理能力并非线性相关，一些小型开源模型甚至超越了大型商业模型。这表明当前对LLM的评估可能过于侧重知识回忆而非互动教学。通过混合方法评估，论文识别了顶尖模型的教学策略，并验证了EducationQ方法的有效性。研究强调，未来的教育AI应专注于专门优化LLM的教学能力，而非仅仅扩大模型规模。

> **摘要翻译:** 大型语言模型（LLM）日益成为教育工具，但由于师生互动评估的资源密集性、情境依赖性和方法复杂性，评估其教学能力仍然具有挑战性。我们引入了EducationQ，一个多智能体对话框架，通过模拟动态教育场景，有效地评估教学能力，该框架具有专门用于教学、学习和评估的智能体。对来自主要AI组织（OpenAI、Meta、Google、Anthropic及其他）的14个LLM进行了测试，涉及13个学科和10个难度级别的1,498个问题，结果显示教学效果与模型规模或通用推理能力之间没有线性关系——一些较小的开源模型在教学环境中表现优于较大的商业模型。这一发现凸显了当前评估中优先考虑知识回忆而非互动教学的关键差距。我们的混合方法评估，结合定量指标与定性分析和专家案例研究，识别出表现最佳模型所采用的独特教学优势（例如，复杂的提问策略、自适应反馈机制）。人类专家评估显示，我们对有效教学行为的自动化定性分析有78%的一致性，验证了我们的方法论。EducationQ表明，作为教师的LLM需要超越简单规模化的专门优化，这表明下一代教育AI应优先对特定教学效果进行有针对性的增强。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [594] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
> *可视化有助于AI理解数据吗？*

*Victoria R. Li, Johnathan Sun, Martin Wattenberg* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 数据可视化, AI理解, 视觉-语言模型, 数据分析, 散点图

**Comment:** 5 pages, 6 figures

> **TL;DR:** 研究发现，商业视觉-语言模型在有散点图辅助时能更准确地描述数据，表明AI也能从可视化中受益。

**AI_Comments:** 这篇论文提出了一个有趣且重要的研究方向，即探索可视化对AI系统数据理解的帮助。其创新点在于将人类数据分析中普遍使用的可视化方法引入到AI领域进行实证研究。通过使用主流的视觉-语言模型和明确的对照实验，初步证明了可视化对AI的潜在价值。这为未来AI辅助数据分析工具的设计提供了新的思路，可能促使AI系统更好地处理和解释复杂数据。

<details>
  <summary>Details</summary>

**Motivation:** 探索图表和图形是否也能像帮助人类一样，对AI系统的数据分析有用。

**Method:** 使用GPT 4.1和Claude 3.5两个商业视觉-语言模型，在三个代表性分析任务上进行实验。通过提供原始数据和散点图，并与提供空白图表和数据不匹配图表的基线进行比较。

**Result:** 当原始数据附带散点图时，两个系统能更精确、准确地描述合成数据集，尤其是在数据集复杂性增加时。性能提升是由于图表内容而非仅仅是图表的存在。

**Conclusion:** 初步证据表明，AI系统像人类一样，可以从数据可视化中受益。

> **ai_Abstract:** 本研究探讨了可视化对AI系统数据理解的潜在益处。通过对GPT 4.1和Claude 3.5两个视觉-语言模型进行实验，发现在有散点图辅助时，模型能更精确、准确地分析合成数据，尤其是在数据复杂时。对比实验证实，这种改进源于图表内容本身。结果表明，AI系统与人类类似，也能从数据可视化中获益。

> **摘要翻译:** 图表和图形有助于人们分析数据，但它们对AI系统也有用吗？为了调查这个问题，我们对两个商业视觉-语言模型：GPT 4.1和Claude 3.5进行了一系列实验。在三个代表性分析任务中，当原始数据附带散点图时，这两个系统能更精确、准确地描述合成数据集，尤其是在数据集复杂性增加时。与两个基线——提供空白图表和提供数据不匹配图表——的比较表明，性能的提升是由于图表的内容。我们的结果是AI系统像人类一样可以从可视化中受益的初步证据。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [610] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
> *推理能力腐蚀：推理语言模型在公共物品博弈中成为搭便车者*

*David Guzman Piedrahita, Yongjin Yang, Mrinmaya Sachan, Giorgia Ramponi, Bernhard Schölkopf, Zhijing Jin* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 公共物品博弈, 合作, 推理能力, 智能体行为

**Comment:** Published at COLM 2025

> **TL;DR:** 研究发现，在公共物品博弈中，推理型LLM比传统LLM更不合作，这表明提升推理能力不一定能促进合作。

**AI_Comments:** 这项研究通过引入公共物品博弈，创新性地揭示了LLM在社会困境中的行为模式，特别是指出了当前LLM推理能力提升与合作行为之间的反直觉关系。这对于LLM的对齐、安全部署以及在多智能体系统中的应用具有重要意义，提醒研究者在提升LLM能力时需全面考虑其社会互动表现。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）越来越多地部署为自主智能体，理解它们的合作和社会机制变得越来越重要。特别是，LLM如何平衡自身利益和集体福祉是确保对齐、鲁棒性和安全部署的关键挑战。本文研究了多智能体LLM系统中昂贵制裁的挑战。

**Method:** 本文改编了行为经济学中的公共物品博弈并引入了制度选择，以观察不同LLM在重复互动中如何应对社会困境。通过分析，揭示了模型之间的四种不同的行为模式。

**Result:** 研究揭示了四种不同的行为模式：一些模型始终建立并维持高水平的合作，一些在参与和脱离之间波动，一些合作行为随时间逐渐下降，还有一些则不顾结果顽固地遵循固定策略。令人惊讶的是，推理型LLM（如o1系列）在合作方面表现出显著的困难，而一些传统LLM则始终保持高水平的合作。

**Conclusion:** 这些发现表明，当前提高LLM的方法（侧重于增强其推理能力）不一定能带来合作，为在需要持续协作的环境中部署LLM智能体提供了宝贵的见解。

> **ai_Abstract:** 这篇论文探讨了大型语言模型（LLM）作为自主智能体在公共物品博弈中的合作行为。通过改编行为经济学的公共物品博弈并引入制度选择，作者观察了不同LLM在面对昂贵制裁时的表现。研究发现，尽管当前LLM的发展趋势是增强其推理能力，但推理型LLM在合作方面表现不佳，反而不如一些传统LLM。这表明提高LLM的推理能力不一定会促进合作，为在需要协作的环境中部署LLM提供了重要启示。

> **摘要翻译:** 随着大型语言模型（LLM）越来越多地部署为自主智能体，理解它们的合作和社会机制变得越来越重要。特别是，LLM如何平衡自身利益和集体福祉是确保对齐、鲁棒性和安全部署的关键挑战。在本文中，我们研究了多智能体LLM系统中昂贵制裁的挑战，其中智能体必须决定是否投入自己的资源来激励合作或惩罚背叛。为了研究这一点，我们改编了行为经济学中的公共物品博弈并引入了制度选择，使我们能够观察不同的LLM在重复互动中如何应对社会困境。我们的分析揭示了模型之间的四种不同行为模式：一些始终建立并维持高水平的合作，另一些在参与和脱离之间波动，一些合作行为随时间逐渐下降，还有一些则不顾结果顽固地遵循固定策略。令人惊讶的是，我们发现推理型LLM（如o1系列）在合作方面表现出显著的困难，而一些传统LLM则始终保持高水平的合作。这些发现表明，当前改进LLM的方法（侧重于增强其推理能力）不一定能带来合作，为在需要持续协作的环境中部署LLM智能体提供了宝贵的见解。我们的代码可在https://github.com/davidguzmanp/SanctSim获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [618] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
> *模型架构发现的“AlphaGo时刻”*

*Yixiu Liu, Yang Nan, Weixian Xu, Xiangkun Hu, Lyumanshan Ye, Zhen Qin, Pengfei Liu* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** ASI-Arch, 神经架构发现, 自动化创新, 人工智能研究, 缩放定律

**Comment:** 

> **TL;DR:** 本文提出了ASI-Arch，一个用于AI研究的人工超智能系统，能够自主进行神经架构创新，超越了传统NAS的限制，并发现了106个最先进的线性注意力架构，证明了科学发现可以计算化扩展。

**AI_Comments:** 这项研究的创新之处在于提出并实现了ASI-Arch，这是一个能够自主进行科学研究（特别是神经网络架构发现）的系统，从而打破了AI研究受限于人类认知能力的瓶颈。其重要性在于，它不仅发现了新的SOTA架构，更重要的是，它建立了科学发现的第一个经验缩放定律，预示着未来AI研究能够通过计算能力而非人类智慧实现自我加速，具有深远的意义。这标志着AI从工具向研究伙伴的转变，具有里程碑式的意义。

<details>
  <summary>Details</summary>

**Motivation:** AI系统能力呈指数级增长，但AI研究本身的进展仍受限于人类认知能力，这造成了日益严重的开发瓶颈。研究旨在通过自动化AI研究来打破这一基本限制。

**Method:** 本文提出了ASI-Arch，这是一个用于神经架构发现的完全自主系统。它超越了传统的神经架构搜索（NAS），从自动化优化转向自动化创新。ASI-Arch能够自主假设新架构概念，将其实现为可执行代码，并通过严格的实验和经验验证其性能。

**Result:** ASI-Arch进行了1,773次自主实验，耗时20,000 GPU小时，最终发现了106个创新且最先进（SOTA）的线性注意力架构。这些AI发现的架构展示了新兴的设计原则，系统性地超越了人类设计的基线。

**Conclusion:** 本文建立了科学发现本身的第一个经验缩放定律，证明了架构突破可以通过计算进行扩展，将研究进展从人类受限的过程转变为计算可扩展的过程。这为自我加速的AI系统奠定了蓝图。

> **ai_Abstract:** 本文介绍了ASI-Arch，一个开创性的人工智能系统，旨在通过自主进行神经网络架构发现来加速AI研究。该系统超越了传统的神经架构搜索，实现了从自动化优化到自动化创新的转变。ASI-Arch能够自主生成、实现和验证新的架构概念，已成功发现106个最先进的线性注意力架构，其性能优于人类设计。研究还首次提出了科学发现的经验缩放定律，表明通过计算可以加速研究进展，为实现自我加速的AI研究系统提供了蓝图。

> **摘要翻译:** 尽管AI系统展现出指数级提升的能力，但AI研究本身的速度仍受限于人类的认知能力，这造成了日益严重的开发瓶颈。我们提出了ASI-Arch，这是人工智能研究（ASI4AI）中人工超智能的首次演示，其关键领域是神经网络架构发现——一个完全自主的系统，通过使AI能够进行自身的架构创新来打破这一基本限制。我们超越了传统上仅限于探索人类定义空间的神经网络架构搜索（NAS），引入了一种从自动化优化到自动化创新的范式转变。ASI-Arch可以在架构发现领域进行端到端的科学研究，自主假设新颖的架构概念，将其实现为可执行代码，通过严格的实验和过往经验训练并实证验证其性能。ASI-Arch进行了1,773次自主实验，耗时超过20,000 GPU小时，最终发现了106个创新且最先进（SOTA）的线性注意力架构。就像AlphaGo的第37步棋揭示了人类玩家无法察觉的意外战略洞察一样，我们AI发现的架构展示了新兴的设计原则，系统性地超越了人类设计的基线，并阐明了以前未知的架构创新途径。至关重要的是，我们建立了科学发现本身的第一个经验缩放定律——证明架构突破可以通过计算进行扩展，将研究进展从人类受限的过程转变为计算可扩展的过程。我们对促成这些突破的新兴设计模式和自主研究能力进行了全面分析，为自我加速的AI系统建立了蓝图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [633] [Beamforming and Resource Allocation for Delay Minimization in RIS-Assisted OFDM Systems](https://arxiv.org/abs/2506.03586)
> *RIS辅助OFDM系统中用于延迟最小化的波束成形和资源分配*

*Yu Ma, Xiao Li, Chongtao Guo, Le Liang, Michail Matthaiou, Shi Jin* | **Category: cs.AI, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** RIS, OFDM, 波束成形, 资源分配, 深度强化学习

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文提出了一种混合深度强化学习方法，结合多智能体和迁移学习，以最小化RIS辅助OFDM系统中随机数据包到达的平均延迟。

**AI_Comments:** 该论文的创新点在于将混合深度强化学习与多智能体和迁移学习相结合，以解决RIS辅助通信系统中复杂的联合波束成形和资源分配问题。特别是在处理随机数据包到达导致的延迟最小化问题上，其将网络动态（如积压数据包）纳入状态空间，增强了模型的实用性和适应性。这种集成方法有效地克服了传统强化学习在混合动作空间和高维状态空间中的挑战，并提高了训练效率。

<details>
  <summary>Details</summary>

**Motivation:** 在下行链路可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，数据包随机到达基站，导致平均延迟问题。本文旨在解决联合波束成形和资源分配问题，以最小化这一平均延迟。

**Method:** 本文提出了一种混合深度强化学习（DRL）方法来处理混合动作空间和减少状态空间维度。具体来说，采用PPO-Theta优化RIS相移设计，PPO-N负责子载波分配。基站的主动波束成形则根据联合优化的RIS相移和子载波分配决策得出。为进一步缓解子载波分配带来的维度灾难，引入了多智能体策略。此外，将积压数据包数量和当前数据包到达等与平均延迟密切相关的关键因素纳入状态空间，以实现更自适应的资源分配并准确捕获网络动态。还引入了迁移学习框架来提高训练效率和加速收敛。

**Result:** 仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，并与基线方法相比，实现了卓越的系统鲁棒性和公平性。

**Conclusion:** 本文提出的基于混合深度强化学习的算法，结合多智能体策略和迁移学习，在RIS辅助的OFDM系统中有效解决了延迟最小化问题，显著提升了系统性能。

> **ai_Abstract:** 该论文探讨了RIS辅助OFDM系统中最小化平均延迟的联合波束成形和资源分配问题，其中数据包随机到达。由于该问题本质上是马尔可夫决策过程，作者提出了一种混合深度强化学习方法。该方法结合了PPO-Theta用于RIS相移优化和PPO-N用于子载波分配，并通过多智能体策略和将网络动态因素纳入状态空间来增强效率和适应性。此外，引入迁移学习以加速训练。仿真结果证实，所提算法在降低平均延迟、提高资源分配效率、增强系统鲁棒性和公平性方面优于现有方法。

> **摘要翻译:** 本文研究了下行链路可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，数据包随机到达基站（BS）时，联合波束成形和资源分配问题以最小化平均延迟。序贯优化问题本质上是一个马尔可夫决策过程（MDP），因此属于强化学习的范畴。为了有效处理混合动作空间并降低状态空间维度，本文提出了一种混合深度强化学习（DRL）方法。具体而言，采用近端策略优化（PPO）-Theta来优化RIS相移设计，而PPO-N负责子载波分配决策。基站的主动波束成形则根据联合优化的RIS相移和子载波分配决策导出。为了进一步缓解与子载波分配相关的维度灾难，引入了一种多智能体策略来更有效地优化子载波分配指标。此外，为了实现更自适应的资源分配并准确捕获网络动态，将与平均延迟密切相关的关键因素（如缓冲区中积压数据包的数量和当前数据包到达）纳入状态空间。此外，引入了迁移学习框架以提高训练效率和加速收敛。仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，并与基线方法相比，实现了卓越的系统鲁棒性和公平性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [642] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
> *面向端到端医疗数据推理的智能体AI框架*

*Soorya Ram Shimgekar, Shayan Vassef, Abhay Goyal, Navin Kumar, Koustuv Saha* | **Category: cs.AI, cs.CL, cs.CY, cs.ET, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 智能体AI, 医疗数据, 机器学习, 临床流程, 自动化

**Comment:** 10 pages, 5 figures, 2 tables, BIBM conference

> **TL;DR:** 该研究提出了一个智能体AI框架，旨在自动化医疗机器学习流程，从而降低成本并减少人工干预。

**AI_Comments:** 该框架通过采用“智能体AI”方法来自动化复杂且碎片化的医疗机器学习管道，具有创新性，是医疗AI实际部署的重要一步。其模块化设计增强了灵活性和可扩展性。对隐私和可解释性的关注也解决了临床应用中的关键问题。

<details>
  <summary>Details</summary>

**Motivation:** 由于预处理流程碎片化、模型兼容性问题以及严格的数据隐私限制，在医疗保健领域构建和部署机器学习解决方案仍然成本高昂且劳动密集。

**Method:** 该研究引入了一个智能体AI框架，通过一个由模块化、任务特定智能体组成的系统，自动化了从数据摄取到推理的整个临床数据管道。这些智能体处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需人工干预。例如，它使用摄取识别智能体进行文件类型检测，数据匿名化智能体确保隐私合规性，特征提取智能体（对表格数据使用基于嵌入的方法，对图像数据使用基于MedGemma的多阶段方法）识别特征，模型-数据特征匹配智能体选择最佳模型，预处理推荐智能体和预处理实现智能体应用定制预处理，最后模型推理智能体运行选定模型并生成可解释的输出（使用SHAP、LIME和DETR注意力图等工具）。

**Result:** 该系统在来自老年病学、姑息治疗和结肠镜检查图像的公开数据集中进行了评估。通过自动化机器学习生命周期中的高摩擦阶段，该框架减少了重复专家干预的需要。

**Conclusion:** 所提出的智能体AI框架通过自动化机器学习生命周期中的高摩擦阶段，降低了对重复专家干预的需求，为在临床环境中操作化人工智能提供了一条可扩展、经济高效的途径。

> **ai_Abstract:** 该论文提出了一个智能体AI框架，旨在自动化医疗数据从摄取到推理的整个机器学习流程，以解决医疗领域机器学习部署中成本高昂、劳动密集和隐私限制等挑战。该框架由模块化、任务特定的智能体组成，能够处理结构化和非结构化数据，并自动执行特征选择、模型选择和预处理。该系统已在多个公开医疗数据集上进行了评估，结果表明它能显著减少人工干预，为在临床环境中部署AI提供了一条可扩展且经济高效的途径。

> **摘要翻译:** 在医疗保健领域构建和部署机器学习解决方案仍然成本高昂且劳动密集，这归因于碎片化的预处理工作流程、模型兼容性问题以及严格的数据隐私限制。在这项工作中，我们引入了一个智能体AI框架，通过一个由模块化、任务特定智能体组成的系统，自动化了从数据摄取到推理的整个临床数据管道。这些智能体处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需人工干预。我们在老年病学、姑息治疗和结肠镜检查图像的公开可用数据集上评估了该系统。例如，在结构化数据（焦虑数据）和非结构化数据（结肠镜息肉数据）的情况下，管道首先由摄取识别智能体进行文件类型检测，随后数据匿名化智能体确保隐私合规性，在此我们首先识别数据类型然后对其进行匿名化处理。特征提取智能体使用基于嵌入的方法识别表格数据的特征，提取所有列名；对于图像数据，则采用基于MedGemma的多阶段方法，推断模态和疾病名称。这些特征指导模型-数据特征匹配智能体从精选存储库中选择最适合的模型。预处理推荐智能体和预处理实现智能体随后根据数据类型和模型要求应用定制的预处理。最后，“模型推理智能体”在上传的数据上运行选定的模型，并使用SHAP、LIME和DETR注意力图等工具生成可解释的输出。通过自动化机器学习生命周期中的这些高摩擦阶段，所提出的框架减少了重复专家干预的需要，为在临床环境中操作化人工智能提供了一条可扩展、经济高效的途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [646] [DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification](https://arxiv.org/abs/2507.04600)
> *DisMS-TS: 消除时间序列分类中冗余的多尺度特征*

*Zhipeng Liu, Peibo Duan, Binwu Wang, Xuan Tang, Qi Chu, Changsheng Zhang, Yongsheng Huang, Bin Zhang* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 时间序列分类, 多尺度特征, 特征解耦, 冗余消除, 深度学习

**Comment:** This paper has been accepted for presentation at the ACM
  International Conference on Multimedia (ACM MM 2025)

> **TL;DR:** DisMS-TS提出了一种新的解耦多尺度框架，通过消除多尺度时间序列中冗余的共享特征来提高时间序列分类性能，实验证明其优于现有基线。

**AI_Comments:** DisMS-TS的创新点在于其提出的时间解耦模块和正则化项，能够有效区分和处理多尺度时间序列中的共享与特定特征，从而解决了现有方法中冗余特征导致的性能瓶颈。这一方法对于提升复杂时间序列的分类精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于多尺度分析的时间序列预测方法未能消除多尺度时间序列中冗余的尺度共享特征，导致模型过度或不足地关注这些特征，使得时间序列分类任务具有挑战性。

**Method:** 本文提出了一个新颖的端到端解耦多尺度时间序列分类框架（DisMS-TS）。其核心思想是消除多尺度时间序列中冗余的共享特征，从而提高预测性能。具体来说，引入了一个时间解耦模块来分别捕获尺度共享和尺度特定时间表示。此外，为了有效学习这两种表示，引入了两个正则化项，以确保尺度共享表示的一致性和尺度特定表示在所有时间尺度上的差异性。

**Result:** 在多个数据集上进行了广泛的实验，验证了DisMS-TS优于其竞争基线，准确率提高了高达9.71%。

**Conclusion:** DisMS-TS通过消除多尺度时间序列中冗余的共享特征，有效提高了时间序列分类的性能。

> **ai_Abstract:** 本文提出了DisMS-TS，一个用于时间序列分类的解耦多尺度框架。该方法旨在解决现有多尺度分析方法中冗余尺度共享特征的问题，通过引入时间解耦模块和两个正则化项来分别捕获和优化尺度共享与尺度特定表示。实验结果表明，DisMS-TS在多个数据集上显著提高了分类准确率。

> **摘要翻译:** 现实世界中的时间序列通常表现出复杂的时间变化，这使得时间序列分类任务极具挑战性。最近的进展表明，多尺度分析方法具有潜力，为捕获这些复杂时间模式提供了有效的解决方案。然而，现有的基于多尺度分析的时间序列预测方法未能消除多尺度时间序列中冗余的尺度共享特征，导致模型过度或不足地关注尺度共享特征。为了解决这个问题，我们提出了一个新颖的端到端解耦多尺度时间序列分类框架（DisMS-TS）。DisMS-TS的核心思想是消除多尺度时间序列中冗余的共享特征，从而提高预测性能。具体来说，我们提出了一个时间解耦模块来分别捕获尺度共享和尺度特定时间表示。随后，为了有效学习尺度共享和尺度特定时间表示，我们引入了两个正则化项，以确保尺度共享表示的一致性以及尺度特定表示在所有时间尺度上的差异性。在多个数据集上进行的广泛实验验证了DisMS-TS优于其竞争基线，准确率提高了高达9.71%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [668] [I-CEE: Tailoring Explanations of Image Classification Models to User Expertise](https://arxiv.org/abs/2312.12102)
> *I-CEE：根据用户专业知识定制图像分类模型的解释*

*Yao Rong, Peizhu Qian, Vaibhav Unhelkar, Enkelejda Kasneci* | **Category: cs.AI, cs.CV, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 可解释人工智能, 用户专业知识, 图像分类, 以人为中心AI, 可模拟性

**Comment:** 

> **TL;DR:** I-CEE是一个为图像分类模型提供定制化解释的框架，它根据用户的专业知识提供不同的训练数据示例，以提高用户对模型决策的理解和可模拟性。

**AI_Comments:** I-CEE的创新之处在于其将用户专业知识纳入解释生成过程，突破了传统XAI“一刀切”的局限。这种以人为本的方法对于提高AI系统的透明度、信任度和可用性至关重要。该研究通过模拟和真人实验验证了其方法的有效性，为未来XAI研究提供了新的视角和方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有可解释人工智能（XAI）技术大多提供“一刀切”的解释，较少关注用户（被解释者）的专业知识，这阻碍了以人为中心的可解释人工智能的发展。

**Method:** I-CEE框架通过提供训练数据的有用子集（即示例图像）、相应的局部解释和模型决策来解释图像分类模型的决策。其创新之处在于，它根据用户的专业知识来建模示例图像的信息量，从而为不同用户提供不同的示例集。

**Result:** 通过模拟用户和100名真实参与者的实验表明，与基线相比，I-CEE显著提高了用户准确预测模型决策的能力（可模拟性）。

**Conclusion:** I-CEE的工作强调了以人为中心的可解释人工智能的重要性，通过根据用户专业知识定制解释，可以有效提高用户对模型决策的理解和可模拟性。

> **ai_Abstract:** 本文提出了I-CEE，一个旨在根据用户专业知识定制图像分类模型解释的框架。针对现有XAI技术“一刀切”解释的局限性，I-CEE通过提供经过定制的训练数据示例、局部解释和模型决策来提高用户对黑盒模型决策的理解和可模拟性。实验结果表明，I-CEE显著提升了用户预测模型决策的准确性，强调了以人为中心XAI的重要性。

> **摘要翻译:** 有效解释黑盒机器学习模型的决策对于负责任地部署依赖它们的AI系统至关重要。认识到它们的重要性，可解释AI（XAI）领域提供了几种生成这些解释的技术。然而，在这日益增长的工作中，对用户（被解释者）的重视相对较少，大多数XAI技术生成“一刀切”的解释。为了弥补这一差距并向以人为中心的XAI迈进一步，我们提出了I-CEE，这是一个根据用户专业知识定制图像分类解释的框架。根据现有工作，I-CEE通过向用户提供训练数据的有用子集（即示例图像）、相应的局部解释和模型决策来解释图像分类模型的决策。然而，与之前的工作不同，I-CEE将示例图像的信息量建模为依赖于用户专业知识，从而为不同用户提供不同的示例。我们认为，通过根据用户专业知识定制示例集，I-CEE可以更好地促进用户对模型的理解和可模拟性。为了评估我们的方法，我们在模拟和与人类参与者（N = 100）的多数据集上进行了详细实验。与模拟用户的实验表明，与基线相比，I-CEE提高了用户准确预测模型决策的能力（可模拟性），提供了有希望的初步结果。与人类参与者的实验表明，我们的方法显著提高了用户可模拟性准确性，突出了以人为中心的XAI的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [678] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
> *积极评估和学习重要的区别：从急诊分诊记录中检测疫苗安全信号*

*Sedigh Khademi, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila, Jim Black* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 疫苗安全, 自然语言处理, 主动学习, 急诊分诊记录, 信号检测

**Comment:** 14 pages

> **TL;DR:** 本研究结合自然语言处理和主动学习，从急诊分诊记录中快速开发一个分类器，用于检测疫苗安全信号，以应对传统方法的局限性和医学数据标注的稀缺性。

**AI_Comments:** 这项研究通过结合NLP和主动学习，为上市后疫苗安全监测提供了一个创新且高效的解决方案。其重要性在于能够利用非结构化急诊记录数据，并克服医学领域标注数据稀缺的挑战，有望显著提高疫苗不良事件检测的及时性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 临床试验中安全数据收集窗口有限以及早期广泛实施，导致对上市后疫苗安全监测系统的需求增加。现有基于关键词的分类方法可能产生假阳性，需要大量修改，且难以处理疫苗相关急诊就诊频率低及症状与其他急诊原因相似的问题。此外，医学领域中自然语言处理所需的标注数据稀缺。

**Method:** 本研究利用自然语言处理技术和主动学习，通过结合主动学习、数据增强以及主动学习和评估技术来开发一个分类器。主动学习用于优化标注过程和数据质量，从而加速模型部署并提高模型性能。

**Result:** 结果是创建了一个分类器，该分类器旨在增强从急诊分诊记录中进行的疫苗安全监测。

**Conclusion:** 结合自然语言处理、主动学习、数据增强和评估技术可以有效地开发用于从急诊分诊记录中检测疫苗安全信号的分类器，从而增强上市后疫苗安全监测。

> **ai_Abstract:** 本研究旨在解决疫苗上市后安全监测的挑战，特别是在临床试验数据有限的情况下。研究提出了一种结合自然语言处理（NLP）和主动学习（Active Learning）的方法，以快速开发一个分类器，用于从急诊科分诊记录中识别潜在的疫苗安全信号。该方法旨在克服传统关键词分类的局限性以及医学领域标注数据稀缺的问题，通过优化数据标注过程和提高模型性能来增强疫苗安全监测。

> **摘要翻译:** COVID-19疫苗的快速发展展示了全球社区对抗传染病的能力。然而，由于临床试验中安全数据收集窗口有限以及早期广泛实施，对上市后监测系统的需求日益增长。本研究旨在利用自然语言处理技术和主动学习，快速开发一个分类器，用于从急诊科记录中检测潜在的疫苗安全问题。急诊分诊记录包含专家在进入医疗系统时的简洁重要患者信息，可以显著促进及时的疫苗安全信号监测。虽然基于关键词的分类可能有效，但它可能产生假阳性并需要大量的关键词修改。疫苗相关急诊就诊频率低及其与其他急诊就诊原因的相似性加剧了这一问题。自然语言处理提供了一种更准确和高效的替代方案，尽管它需要标注数据，而这在医学领域通常是稀缺的。主动学习优化了标注过程和标注数据的质量，从而可以更快地实现模型部署并提高模型性能。这项工作结合了主动学习、数据增强以及主动学习和评估技术，以创建一个分类器，用于增强从急诊分诊记录中进行的疫苗安全监测。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [688] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
> *法律纠纷分析中提示工程与多维知识图谱的集成框架*

*Mingda Zhang, Na Zhao, Jianglong Qing, Qing xu, Kaiwen Pan, Ting luo* | **Category: cs.AI, 68T50, 68T30, 91F20, I.2.7; I.2.4; K.5.1; H.3.3** | **Updated: 2025-07-24**

**Keywords:** 提示工程, 知识图谱, 法律纠纷分析, 大型语言模型, 智能法律辅助

**Comment:** 19 pages,3 figures

> **TL;DR:** 本文提出了一个结合提示工程和多维知识图谱的集成框架，显著提升了大型语言模型在法律纠纷分析中的表现，解决了其在理解复杂法律概念、推理一致性和引用准确性方面的挑战。

**AI_Comments:** 该论文提出了一种创新的方法，将提示工程与多维知识图谱相结合，有效解决了LLM在法律领域特有的挑战。其分层提示结构和多层知识图谱设计，辅以多种检索方法，展现了系统性解决复杂法律分析问题的潜力。实验结果的显著提升证明了其有效性，为智能法律辅助系统的发展提供了重要的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）在理解复杂法律概念、保持推理一致性以及准确引用法律来源方面面临重大挑战，而法律纠纷分析对于智能法律辅助系统至关重要。

**Method:** 本研究提出了一个结合提示工程和多维知识图谱的框架。具体方法包括：一个三阶段的分层提示结构（任务定义、知识背景、推理指导），一个三层知识图谱（法律本体层、表示层、实例层），以及四种支持精确法律概念检索的方法（直接代码匹配、语义向量相似度、本体路径推理、词汇分割）。

**Result:** 通过广泛测试，结果显示灵敏度提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。

**Conclusion:** 该框架提供了更好的法律分析和对司法逻辑的理解，为智能法律辅助系统提供了一种新的技术方法。

> **ai_Abstract:** 本文提出了一个结合提示工程和多维知识图谱的集成框架，旨在解决大型语言模型在法律纠纷分析中理解复杂法律概念、推理一致性和引用准确性方面的挑战。该框架包含分层提示结构和三层知识图谱，并辅以四种法律概念检索方法。实验结果表明，该框架显著提升了LLM在法律分析中的灵敏度、特异性和引用准确性，为智能法律辅助系统提供了有效的新技术途径。

> **摘要翻译:** 法律纠纷分析对于智能法律辅助系统至关重要。然而，当前的大型语言模型（LLM）在理解复杂法律概念、保持推理一致性以及准确引用法律来源方面面临重大挑战。本研究提出了一个结合提示工程和多维知识图谱的框架，以改进LLM的法律纠纷分析能力。具体而言，该框架包括一个三阶段的分层提示结构（任务定义、知识背景、推理指导）以及一个三层知识图谱（法律本体层、表示层、实例层）。此外，四种支持方法能够实现精确的法律概念检索：直接代码匹配、语义向量相似度、本体路径推理和词汇分割。通过广泛测试，结果显示出显著改进：灵敏度提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。因此，该框架提供了更好的法律分析和对司法逻辑的理解，从而为智能法律辅助系统提供了一种新的技术方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [716] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
> *GNNs的均值聚合的逻辑特性*

*Moritz Schönherr, Carsten Lutz* | **Category: cs.AI, cs.LO** | **Updated: 2025-07-24**

**Keywords:** 图神经网络, 均值聚合, 表达能力, 模态逻辑, 逻辑刻画

**Comment:** 

> **TL;DR:** 本文研究了均值聚合GNN的表达能力，发现在非均匀设置下其表达能力与比例模态逻辑相同，高于max聚合GNN但低于sum聚合GNN；在均匀设置下，在特定假设下其表达能力与无交替模态逻辑相同，低于sum和max聚合GNN。

**AI_Comments:** 这项研究通过将均值聚合GNN的表达能力与形式逻辑体系（如模态逻辑）进行精确对应，为理解GNNs的理论基础提供了深刻的洞察。它清晰地揭示了不同聚合函数在不同设置下的表达能力差异，对于指导GNN模型设计和理解其局限性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究图神经网络（GNNs）中均值（mean）作为聚合函数时的表达能力。

**Method:** 通过将其表达能力与特定的模态逻辑（如比例模态逻辑、无交替模态逻辑）进行对应，来逻辑地刻画均值聚合GNN的表达能力。

**Result:** 在非均匀设置下，均值聚合GNN的表达能力与比例模态逻辑完全相同。非均匀设置下，均值聚合GNN的表达能力高于max聚合GNN，但低于sum聚合GNN。在均匀设置下，相对于MSO且在组合函数连续、分类函数为阈值的自然假设下，其表达能力与无交替模态逻辑完全相同。在均匀设置下，均值聚合GNN的表达能力严格低于sum聚合GNN和max GNN。如果上述任何假设被取消，表达能力会增加。

**Conclusion:** 均值聚合GNN的表达能力在不同设置和假设下与多种模态逻辑对应，且相对于其他聚合函数（如max和sum）表现出不同的表达能力等级。

> **ai_Abstract:** 本文深入探讨了以均值作为聚合函数的图神经网络（GNNs）的逻辑表达能力。研究发现，在非均匀设置下，均值GNN的表达能力与比例模态逻辑等价，且高于max聚合GNN但低于sum聚合GNN。在均匀设置中，在特定连续性和阈值假设下，其表达能力与无交替模态逻辑相匹配，并严格低于sum和max聚合GNN，同时指出移除这些假设会提升表达能力。

> **摘要翻译:** 我们研究了以均值作为聚合函数的图神经网络（GNNs）的表达能力。在非均匀设置中，我们表明此类GNNs的表达能力与比例模态逻辑完全相同，该逻辑具有模态算子，用于表示顶点至少一定比例的后继满足特定属性。因此，均值GNN的非均匀表达能力高于max聚合GNN，但低于sum聚合GNN——后者分别由模态逻辑和分级模态逻辑表征。在均匀设置中，我们表明，在组合函数连续且分类函数为阈值的自然假设下，相对于MSO的表达能力与无交替模态逻辑完全相同。这意味着，相对于MSO并在均匀设置中，均值GNN的表达能力严格低于sum GNN和max GNN。当任何假设被取消时，表达能力都会增加。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [720] [When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](https://arxiv.org/abs/2507.14660)
> *当自主系统失控时：为社会系统中多智能体串通的风险做准备*

*Qibing Ren, Sitao Xie, Longxuan Wei, Zhenfei Yin, Junchi Yan, Lizhuang Ma, Jing Shao* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 多智能体系统, AI安全, 串通风险, 去中心化系统, 虚假信息

**Comment:** Code is available at
  https://github.com/renqibing/MultiAgent4Collusion

> **TL;DR:** 本文模拟并分析了多智能体系统（MAS）在散布虚假信息和电子商务欺诈中进行恶意串通的风险，发现去中心化系统更具破坏性且难以检测，强调需要更好的检测和对抗措施。

**AI_Comments:** 这篇论文探讨了一个非常及时和重要的安全问题，即多智能体AI系统可能带来的协同作恶风险，这与当前AI安全研究多集中于单智能体有所不同，具有创新性。其发现去中心化系统更难控制和检测的结论，为未来的AI安全设计和监管提供了关键见解。概念验证方法虽然是模拟，但为理解潜在威胁提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI安全研究多关注单一AI系统，而多智能体系统（MAS）在复杂真实世界中的风险，尤其是恶意串通的风险，尚未得到充分探索。最近的大规模事件（如选举舞弊、金融诈骗）表明人类群体协调行动的危害，AI驱动的群体也可能造成类似危害。

**Method:** 引入了一个概念验证框架，用于模拟恶意多智能体系统串通的风险。该框架支持集中式和去中心化协调结构，并应用于虚假信息传播和电子商务欺诈两个高风险领域。

**Result:** 研究发现，去中心化系统在执行恶意行为方面比集中式系统更有效。去中心化系统更高的自主性使其能够调整策略并造成更大损害。即使应用了传统干预措施（如内容标记），去中心化群体也能调整其策略以避免检测。

**Conclusion:** 提出了关于恶意多智能体群体如何运作以及需要更好的检测系统和对抗措施的关键见解。

> **ai_Abstract:** 本文探讨了自主AI多智能体系统（MAS）在社会系统中进行恶意串通的潜在风险，特别是在虚假信息传播和电子商务欺诈领域。研究人员开发了一个概念验证框架来模拟此类风险，并发现去中心化MAS比集中式MAS更有效且更难被检测，因为它们能够适应传统干预措施。研究强调了开发更先进的检测系统和对抗措施以应对这些新兴威胁的必要性。

> **摘要翻译:** 最近大规模事件，如选举舞弊和金融诈骗，表明人类群体协调努力的危害性。随着自主AI系统的兴起，人们越来越担心AI驱动的群体也可能造成类似的危害。虽然大多数AI安全研究关注个体AI系统，但多智能体系统（MAS）在复杂现实世界中带来的风险仍未得到充分探索。在本文中，我们引入了一个概念验证来模拟恶意MAS串通的风险，使用一个灵活的框架，支持集中式和去中心化协调结构。我们将此框架应用于两个高风险领域：虚假信息传播和电子商务欺诈。我们的研究结果表明，去中心化系统在执行恶意行动方面比集中式系统更有效。去中心化系统增强的自主性使其能够调整策略并造成更大损害。即使应用了传统干预措施，如内容标记，去中心化群体也能调整其策略以避免检测。我们提出了关于这些恶意群体如何运作以及需要更好的检测系统和对抗措施的关键见解。代码可在https://github.com/renqibing/RogueAgent获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [756] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
> *通过变分同态在选项诱导的抽象MDP中学习时间抽象*

*Chang Li, Yaren Zhang, Haoran Lv, Qiong Cao, Chao Xue, Xiaodong He* | **Category: cs.AI, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 时间抽象, 变分同态, 选项, 抽象MDP, 隐式推理

**Comment:** 

> **TL;DR:** 为了解决大语言模型（LLMs）中显式思维链（CoT）推理计算成本高昂且速度慢的问题，本文提出了一个框架，通过在潜在空间中将推理建模为时间扩展抽象动作（选项）来实现高效、隐式推理。为此，引入了变分马尔可夫选项评论（VMOC）算法，并扩展了连续MDP同态理论以提供理论基础。实验证明该方法在逻辑推理和运动控制任务上均表现出色。

**AI_Comments:** 该论文的创新点在于提出了一个将LLMs的推理过程从显式文本生成转化为隐式潜在空间中的“选项”学习的框架，这有望显著提高推理效率。通过引入VMOC算法和扩展MDP同态理论，为这种抽象推理提供了坚实的理论和算法基础。特别是在将人类推理演示蒸馏到潜在空间进行冷启动方面，为模型的初始化提供了有效途径。其重要性体现在为LLMs的未来发展提供了一个更高效、更具原则性的推理范式，有望在计算资源有限的场景下发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）通过显式思维链（CoT）提示展现出卓越的推理能力，但生成这些分步文本解释计算成本高昂且速度慢。

**Method:** 提出一个用于高效、隐式推理的框架，其中模型在潜在空间中“思考”，无需为每一步生成显式文本。将这些潜在思想建模为层级强化学习框架中的时间扩展抽象动作（选项）。引入变分马尔可夫选项评论（VMOC），一个在HiT-MDP框架内使用变分推断的离策略算法。扩展连续MDP同态理论，证明在简化的抽象潜在空间中学习策略可以保持原始复杂问题的最优性。提出一个冷启动过程，利用监督微调（SFT）数据将人类推理演示提炼到潜在选项空间中。

**Result:** 广泛的实验表明，该方法在复杂逻辑推理基准和挑战性运动任务上取得了强大性能。

**Conclusion:** 验证了该框架是一种用于学习语言和控制抽象技能的原则性方法。

> **ai_Abstract:** 本文提出一个通过在潜在空间中利用“选项”进行隐式推理的框架，以解决大语言模型（LLMs）中显式思维链（CoT）推理的计算效率问题。为此，引入了变分马尔可夫选项评论（VMOC）算法，并扩展了连续MDP同态理论以提供理论基础。此外，通过监督微调（SFT）数据进行冷启动初始化。实验证明该方法在逻辑推理和运动控制任务上表现出色，验证了其作为学习抽象技能的有效性。

> **摘要翻译:** 大型语言模型（LLMs）通过显式思维链（CoT）提示展现出卓越的推理能力，但生成这些分步文本解释计算成本高昂且速度慢。为了克服这个问题，我们旨在开发一个用于高效、隐式推理的框架，其中模型在潜在空间中“思考”，而无需为每一步生成显式文本。我们提出这些潜在思想可以被建模为层级强化学习框架中的时间扩展抽象动作，即选项。为了有效地学习作为潜在嵌入的多种选项库，我们首先引入了变分马尔可夫选项评论（VMOC），一个在HiT-MDP框架内使用变分推断的离策略算法。为了为使用这些选项作为抽象推理空间提供严格的基础，我们扩展了连续MDP同态理论。这证明了在简化的抽象潜在空间中学习策略（VMOC适用于此）可以保持原始复杂问题解的最优性。最后，我们提出一个冷启动过程，利用监督微调（SFT）数据将人类推理演示提炼到这个潜在选项空间中，为模型的推理能力提供丰富的初始化。广泛的实验表明，我们的方法在复杂逻辑推理基准和挑战性运动任务上取得了强大性能，验证了我们的框架是一种用于学习语言和控制抽象技能的原则性方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [758] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
> *解耦大型语言模型中的知识与推理：基于认知双系统理论的探索*

*Mutian Yang, Jiandong Gao, Ji Wu* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 知识与推理, 双系统理论, 解耦, 模型分析

**Comment:** 

> **TL;DR:** 本研究受认知双系统理论启发，提出了一个框架，通过模拟快思和慢思两种认知模式，解耦LLM中知识和推理的贡献。研究发现推理调整是领域相关的，参数扩展对知识和推理均有提升，且知识主要在低层网络，推理在高层。

**AI_Comments:** 该研究创新性地将认知双系统理论引入LLM分析，提出了一个新颖的框架来解耦知识和推理，这对于LLM的可解释性和未来发展具有重要意义。其发现知识和推理在模型中的不同作用和位置，为优化LLM结构和训练提供了具体方向。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）的分析、可解释性和开发中，区分模型中知识和推理的能力至关重要。

**Method:** 提出了一个认知归因框架，将LLMs的认知分解为知识检索（阶段1）和推理调整（阶段2）。通过提示LLMs在快思和慢思两种不同认知模式下生成答案来分离这些阶段，并分析其表现以量化知识和推理的贡献。该架构应用于15个LLMs和3个数据集。

**Result:** 1. 推理调整是领域特定的，有利于推理密集型领域（如数学、物理、化学），并可能损害知识密集型领域。2. 参数扩展同时改善知识和推理，其中知识改进更显著，并使LLMs推理更谨慎。3. 知识主要存在于较低的网络层，而推理在较高层操作。

**Conclusion:** 该框架不仅有助于从“解耦”的角度理解LLMs，还为现有研究（包括缩放定律、分层知识编辑和小型模型推理的局限性）提供了新见解。

> **ai_Abstract:** 本研究受双系统认知理论启发，提出了一个认知归因框架，旨在解耦大型语言模型（LLMs）中知识和推理的贡献。通过将LLMs的认知分为知识检索和推理调整两个阶段，并分别在快思和慢思两种认知模式下进行测试，量化了知识和推理的贡献。实验结果表明，推理调整具有领域特异性，参数扩展对知识和推理均有提升，其中知识提升更显著，且知识主要位于低层网络，推理则在更高层。该框架为理解LLMs的“解耦”机制提供了新视角，并对现有研究如缩放定律和知识编辑提供了见解。

> **摘要翻译:** 尽管大型语言模型（LLMs）在推理过程中同时利用知识和推理，但区分它们的能力在模型分析、可解释性和开发中起着关键作用。受双系统认知理论的启发，我们提出了一个认知归因框架来解耦知识和推理的贡献。具体来说，LLMs的认知被分解为两个不同但互补的阶段：知识检索（阶段1）和推理调整（阶段2）。为了分离这些阶段，LLMs被提示在两种不同的认知模式下生成答案，即快思和慢思。通过分析不同认知模式下的表现来量化知识和推理的贡献。该架构应用于15个LLMs和3个数据集。结果表明：(1) 推理调整是领域特定的，有利于推理密集型领域（例如数学、物理和化学），并可能损害知识密集型领域。(2) 参数扩展同时改善知识和推理，其中知识改进更显著。此外，参数扩展使LLMs的推理显著更谨慎，但智能程度适中。(3) 知识主要存在于较低的网络层，而推理在较高层操作。我们的框架不仅有助于从“解耦”的角度理解LLMs，还为现有研究提供了新见解，包括缩放定律、分层知识编辑和小型模型推理的局限性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [1] [Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains](https://arxiv.org/abs/2507.17792)
> *多领域多传感器系统中的因果机制估计*

*Jingyi Yu, Tim Pychynski, Marco F. Huber* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-23**

**Keywords:** 因果机制估计, 多传感器系统, 多领域, 因果迁移学习, CICME

**Comment:** 

> **TL;DR:** 本文提出了一种名为CICME的新型三步方法，用于从跨多领域收集的异构数据中推断因果机制，该方法利用因果迁移学习，能够可靠地检测域不变因果机制，并在某些场景下优于基线方法。

**AI_Comments:** 该论文提出了一种新颖的因果机制估计方法CICME，其创新之处在于结合了因果迁移学习，能够从异构的多领域数据中有效识别共同和个体因果机制。这对于理解复杂的多传感器系统具有重要意义，尤其是在数据分布可能因领域而异的实际应用中。该方法通过在汇集数据和个体领域数据上应用因果发现，有效利用了不同层面的信息。其在特定场景下超越基线方法的表现，凸显了其潜在的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 为了通过因果关系视角更深入地了解复杂的传感器系统。

**Method:** 本文提出了一种名为共同和个体因果机制估计（CICME）的新型三步方法，用于从跨多个领域收集的异构数据中推断因果机制。该方法利用因果迁移学习（CTL）原理，并建立在现有的基于连续优化的因果发现方法之上。CICME首先识别共同的因果机制，然后利用这些机制指导每个领域中剩余因果机制的单独估计。

**Result:** CICME在提供足够样本的情况下，能够可靠地检测域不变的因果机制。所识别的共同因果机制被进一步用于指导每个领域中剩余因果机制的单独估计。在制造业过程启发的线性高斯模型场景下评估，CICME利用了在汇集数据和单独领域数据上重复应用因果发现的好处，甚至在某些场景下优于两种基线方法。

**Conclusion:** CICME是一种有效的方法，能够从多领域异构数据中估计因果机制，并通过利用共同机制和因果迁移学习，在复杂多传感器系统中提供更深入的因果洞察，并在特定情况下超越现有基线方法。

> **ai_Abstract:** 本文提出了一种名为CICME的新型三步方法，旨在从多领域异构数据中推断因果机制，以深入理解复杂传感器系统。CICME利用因果迁移学习（CTL）原理，能够有效识别跨领域的共同因果机制，并以此指导个体领域的机制估计。实验结果表明，该方法在制造业场景下的线性高斯模型上表现良好，并在某些情况下优于现有的因果发现基线方法。

> **摘要翻译:** 为了通过因果关系视角更深入地了解复杂的传感器系统，我们提出了一种共同和个体因果机制估计（CICME）方法，这是一种新颖的三步方法，用于从跨多个领域收集的异构数据中推断因果机制。通过利用因果迁移学习（CTL）原理，CICME在提供足够样本的情况下，能够可靠地检测域不变因果机制。所识别的共同因果机制进一步用于指导每个领域中剩余因果机制的单独估计。CICME的性能在受制造业过程启发的场景下的线性高斯模型上进行了评估。基于现有的基于连续优化的因果发现方法，我们表明CICME利用了在汇集数据和单独领域数据上重复应用因果发现的好处，甚至在某些场景下优于两种基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [14] [Predictive Scaling Laws for Efficient GRPO Training of Large Reasoning Models](https://arxiv.org/abs/2507.18014)
> *大型推理模型高效GRPO训练的预测性缩放定律*

*Datta Nimmaturi, Vaishnavi Bhargava, Rajat Ghosh, Johnu George, Debojyoti Dutta* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** GRPO, 缩放定律, 大型语言模型, 效率, 推理模型

**Comment:** 

> **TL;DR:** 本文提出了一个预测框架和经验缩放定律，用于优化大型语言模型（LLMs）推理任务中GRPO微调的计算资源，通过预测奖励轨迹并识别训练阶段，实现提前停止以显著降低计算成本。

**AI_Comments:** 本文的创新之处在于提出了一个预测性框架和经验缩放定律，用于优化GRPO微调大型推理模型的计算效率。其重要性体现在能够预测训练动态和奖励轨迹，从而指导用户进行提前停止，显著降低计算资源消耗。这对于实际应用中资源受限的LLM训练具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 使用像GRPO这样的强化学习方法对大型语言模型（LLMs）进行推理任务的微调计算成本高昂。

**Method:** 本文提出了一个预测框架来建模训练动态并优化资源使用。通过在Llama和Qwen模型（3B 8B）上的实验，推导出了一个基于模型大小、初始性能和训练进度的经验缩放定律。该定律用于预测奖励轨迹并识别训练阶段。

**Result:** 该研究发现了一个经验缩放定律，能够预测奖励轨迹，并识别出三个一致的训练阶段：慢启动、快速改进和平台期。研究表明，训练超过一定数量的周期几乎没有额外收益。

**Conclusion:** 训练超过一定周期后收益甚微，因此可以提前停止训练以显著减少计算量而不牺牲性能。该方法适用于不同类型的模型，为基于GRPO的高效微调提供了实用指导。

> **ai_Abstract:** 本文提出了一种预测性框架和经验缩放定律，旨在解决大型语言模型（LLMs）在推理任务中利用GRPO（Group Relative Policy Optimization）进行微调时计算成本高昂的问题。通过在Llama和Qwen模型上的实验，研究者推导出一个基于模型大小、初始性能和训练进度的缩放定律，该定律能够预测奖励轨迹并识别出慢启动、快速改进和平台期三个训练阶段。研究结果表明，在达到一定训练周期后继续训练收益甚微，因此可以提前停止训练，从而在不牺牲性能的情况下显著降低计算成本。该方法适用于不同类型的模型，为高效的GRPO微调提供了实用指导。

> **摘要翻译:** 使用像群组相对策略优化（GRPO）这样的强化学习方法对大型语言模型（LLMs）进行推理任务的微调计算成本高昂。为了解决这个问题，我们提出了一个预测框架，用于建模训练动态并帮助优化资源使用。通过在Llama和Qwen模型（3B 8B）上的实验，我们推导出了一个基于模型大小、初始性能和训练进度的经验缩放定律。该定律预测奖励轨迹并识别出三个一致的训练阶段：慢启动、快速改进和平台期。我们发现训练超过一定数量的周期几乎没有额外收益，这表明提前停止可以显著减少计算量而不牺牲性能。我们的方法适用于不同类型的模型，为高效的基于GRPO的微调提供了实用指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [15] [Self-Supervised Coarsening of Unstructured Grid with Automatic Differentiation](https://arxiv.org/abs/2507.18297)
> *自监督非结构化网格粗化与自动微分*

*Sergei Shumilin, Alexander Ryabov, Nikolay Yavich, Evgeny Burnaev, Vladimir Vanovskiy* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 非结构化网格粗化, 自监督学习, 自动微分, 可微分物理, 数值模拟

**Comment:** 

> **TL;DR:** 本文提出了一种基于可微分物理的自监督算法，通过k-means聚类、自动微分和随机最小化来粗化非结构化网格，可在保持精度的同时将网格点数量减少多达10倍，适用于PDEs模拟。

**AI_Comments:** 该论文提出了一种创新的自监督网格粗化方法，结合了可微分物理和自动微分技术，这在处理大规模数值模拟的计算效率方面具有重要意义。其核心创新在于将网格粗化问题转化为一个可微分的优化问题，并通过自监督的方式进行求解，有效减少了计算负担。

<details>
  <summary>Details</summary>

**Motivation:** 现代数值模拟计算量大，需要减少离散问题规模同时保持合理精度的方法。

**Method:** 提出了一种基于可微分物理概念的非结构化网格粗化算法，通过使用k-means聚类、自动微分和随机最小化算法实现。

**Result:** 在所考虑的场景中，成功将网格点数量减少了多达10倍，同时在感兴趣点保持了建模变量的动态。

**Conclusion:** 所提出的方法可应用于由演化偏微分方程描述的任意系统的模拟。

> **ai_Abstract:** 本文提出了一种新颖的自监督非结构化网格粗化算法，旨在解决现代数值模拟中计算量大的问题。该算法利用可微分物理的概念，结合k-means聚类、自动微分和随机最小化技术，实现了网格的有效粗化。实验结果表明，该方法在保持模型变量动态的同时，能将网格点数量减少多达10倍，并在线性抛物线方程和波动方程等偏微分方程模拟中表现出良好性能。该方法具有广泛适用性，可用于模拟任何由演化偏微分方程描述的系统。

> **摘要翻译:** 由于现代数值模拟的计算负荷很高，因此需要一种能够在保持合理精度的同时减少离散问题规模的方法。在这项工作中，我们提出了一种基于可微分物理概念的原创算法来粗化非结构化网格。我们通过采用k-means聚类、自动微分和随机最小化算法来实现这一点。我们在两个偏微分方程上展示了所设计算法的性能：一个控制多孔介质中微可压缩流体流动的线性抛物线方程和波动方程。我们的结果表明，在所考虑的场景中，我们将网格点数量减少了多达10倍，同时在感兴趣点保留了建模变量的动态。所提出的方法可以应用于由演化偏微分方程描述的任意系统的模拟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [29] [Fine-Tuned Language Models Generate Stable Inorganic Materials as Text](https://arxiv.org/abs/2402.04379)
> *微调语言模型以文本形式生成稳定的无机材料*

*Nate Gruver, Anuroop Sriram, Andrea Madotto, Andrew Gordon Wilson, C. Lawrence Zitnick, Zachary Ulissi* | **Category: cs.LG, cond-mat.mtrl-sci** | **Updated: 2025-07-24**

**Keywords:** 语言模型, 材料生成, 无机材料, 微调, 亚稳态

**Comment:** ICLR 2024. Code available at:
  https://github.com/facebookresearch/crystal-llm

> **TL;DR:** 本文提出了一种新颖的方法，通过微调大型语言模型来以文本形式生成稳定的无机材料，其在生成亚稳态材料方面的表现优于扩散模型CDVAE，并提供了灵活的生成模式。

**AI_Comments:** 这篇论文展示了大型语言模型在其典型NLP领域之外的创新应用，证明了它们在材料科学中的惊人有效性。将材料视为“文本”的想法是新颖的，为材料发现开辟了新途径。在生成物理有效结构方面的高成功率以及优于扩散模型的性能是显著的。它突出了利用预训练LLM偏置处理结构化科学数据的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索一种非正统但可靠的方法，利用微调大型语言模型生成稳定的材料，并利用它们捕获原子数据模式的能力。

**Method:** 研究人员在文本编码的原子数据上对大型语言模型（特别是LLaMA-2 70B）进行微调。他们使用机器学习势能和DFT计算评估生成结构的物理约束和亚稳态，并与CDVAE的性能进行比较。此外，他们还展示了无条件生成、填充和文本条件生成的能力。

**Result:** 大约90%的采样结构符合物理约束。最强的模型（微调后的LLaMA-2 70B）生成亚稳态材料的速度大约是CDVAE的两倍（49% 对 28%）。模型可以用于无条件生成、部分结构填充和文本条件生成。语言模型捕获晶体结构关键对称性的能力随着模型规模的增加而提高。

**Conclusion:** 微调后的大型语言模型出乎意料地非常适合原子数据，为生成稳定的无机材料提供了一种强大且灵活的方法，并显示出优于现有扩散模型的优势。

> **ai_Abstract:** 本文介绍了一种新颖的方法，利用微调后的大型语言模型（LLMs）以文本形式生成稳定的无机材料。该方法简单、可靠（90%的结构符合物理有效性），并且在生成亚稳态材料方面优于传统的扩散模型CDVAE（49% 对 28%）。基于LLM的方法提供了灵活的生成模式，包括无条件生成、填充和文本条件生成，表明LLM的固有偏置非常适合原子数据，并且其能力随模型规模的增加而提高。

> **摘要翻译:** 我们提出对大型语言模型进行微调以生成稳定的材料。虽然这非正统，但对文本编码的原子数据进行大型语言模型微调实现起来简单，而且可靠，大约90%的采样结构符合原子位置和电荷的物理约束。利用学习到的机器学习势能和黄金标准DFT计算的“能量高于船体”计算，我们发现我们最强的模型（微调后的LLaMA-2 70B）能够以大约两倍于竞争扩散模型CDVAE的速度（49% 对 28%）生成预测为亚稳态的材料。由于文本提示固有的灵活性，我们的模型可以同时用于稳定材料的无条件生成、部分结构的填充和文本条件生成。最后，我们表明语言模型捕获晶体结构关键对称性的能力随着模型规模的增加而提高，这表明预训练LLM的偏置出乎意料地非常适合原子数据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [43] [LSDM: LLM-Enhanced Spatio-temporal Diffusion Model for Service-Level Mobile Traffic Prediction](https://arxiv.org/abs/2507.17795)
> *LSDM：大语言模型增强的时空扩散模型用于服务级移动流量预测*

*Shiyuan Zhang, Tong Li, Zhu Xiao, Hongyang Du, Kaibin Huang* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 移动流量预测, 时空扩散模型, 大语言模型, 服务级预测, 深度学习

**Comment:** 14 pages, 9 figures

> **TL;DR:** LSDM提出了一种大语言模型（LLM）增强的时空扩散模型，用于服务级移动流量预测，解决了现有方法在适应性、准确性和环境上下文缺失方面的局限性，并在真实数据集上展现出卓越的泛化性和适应性，显著提升了预测性能。

**AI_Comments:** LSDM的创新点在于将大语言模型（LLMs）与时空扩散模型相结合，用于移动流量预测。这种结合利用了LLMs在上下文理解和多模态信息处理方面的优势，弥补了传统方法在处理复杂环境上下文和高不确定性交通模式方面的不足。该方法不仅提升了预测精度，还显著增强了模型的泛化性和适应性，这对于实际网络管理和QoS优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前移动流量预测方法在不同城市环境中的适应性有限，且由于个人流量模式高度不确定性、缺乏详细环境上下文以及不同网络服务间的复杂依赖关系，导致预测结果不准确。这些挑战需要先进的模型技术来捕获动态流量分布和丰富的环境特征，以提升网络效率和服务质量。

**Method:** 本文提出了LSDM（LLM-Enhanced Spatio-temporal Diffusion Model），它结合了扩散模型的生成能力和Transformer模型的自适应学习能力，并通过大语言模型（LLM）捕获多模态环境信息，以建模服务级流量模式和动态。

**Result:** 在真实的服务级数据集上进行了广泛评估，结果表明LSDM在流量使用预测方面表现出色，展现了卓越的泛化性和适应性。在通过LLM整合上下文信息后，模型性能在决定系数方面至少提升了2.83%。与CSDI等类似模型相比，均方根误差至少降低了8.29%。

**Conclusion:** LSDM模型通过结合大语言模型和时空扩散模型，有效解决了服务级移动流量预测中的挑战，显著提升了预测的准确性、泛化性和适应性，尤其是在整合环境上下文信息后性能得到了显著改善。

> **ai_Abstract:** 本研究提出LSDM，一个大语言模型（LLM）增强的时空扩散模型，旨在解决服务级移动流量预测中现有方法的局限性，如适应性差、预测不准确、环境上下文缺失和复杂服务依赖性。LSDM结合了扩散模型的生成能力和Transformer的自适应学习能力，并利用LLM捕获多模态环境信息。在真实数据集上的评估显示，LSDM在流量预测方面表现出卓越的泛化性和适应性，尤其是在整合LLM上下文信息后，性能有显著提升，决定系数至少提高2.83%，均方根误差比CSDI至少降低8.29%。

> **摘要翻译:** 服务级移动流量预测对于提升网络效率和QoS至关重要。然而，目前的预测方法在不同城市环境中的适应性有限，并且由于个人流量模式的高度不确定性、缺乏详细的环境上下文以及不同网络服务之间复杂的依赖关系，导致结果不准确。这些挑战要求先进的建模技术，能够捕捉动态流量分布和丰富的环境特征。受扩散模型在分布建模方面以及大语言模型（LLMs）在上下文理解方面近期成功的启发，我们提出了一种LLM增强的时空扩散模型（LSDM）。LSDM将扩散模型的生成能力与Transformer的自适应学习能力相结合，并通过捕获多模态环境信息的能力进行增强，以建模服务级模式和动态。在真实的服务级数据集上进行的广泛评估表明，该模型在流量使用预测方面表现出色，显示出卓越的泛化性和适应性。在通过LLM整合上下文信息后，性能在决定系数方面至少提升了2.83%。与CSDI等类似模型相比，均方根误差至少可以降低8.29%。代码和数据集将在此处提供：https://github.com/SoftYuaneR/LSDM。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [49] [State of Health Estimation of Batteries Using a Time-Informed Dynamic Sequence-Inverted Transformer](https://arxiv.org/abs/2507.18320)
> *基于时间感知动态序列倒置Transformer的电池健康状态估计*

*Janak M. Patel, Milad Ramezankhani, Anirudh Deodhar, Dagnachew Birru* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 电池健康状态, Transformer, 时间序列, 不规则数据, 预测

**Comment:** 11 pages, 3 figures

> **TL;DR:** 本文提出了一种名为TIDSIT的新型Transformer架构，用于精确估计电池健康状态（SoH），解决了现有模型在处理不规则、变长电池放电数据时的局限性，并在NASA数据集上实现了显著的错误率降低。

**AI_Comments:** 该论文提出了一种创新性的Transformer变体（TIDSIT），专门解决了电池健康状态估计中常见的不规则时间序列数据和变长输入问题。其通过连续时间嵌入和时间注意力机制有效保留了序列信息，这在实际应用中具有重要意义。实验结果表明其在预测精度上的显著提升，使其在电池管理系统和更广泛的健康监测领域具有巨大的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着电池驱动车辆和储能系统的普及，电池健康监测变得至关重要。电池退化会导致效率降低和安全隐患。尽管现有机器学习模型尝试估计电池健康状态（SoH），但它们难以处理现实世界中不规则采样和变长放电周期数据，导致信息丢失和准确性受损。

**Method:** 本文提出了一种新颖的架构：时间感知动态序列倒置Transformer（TIDSIT）。TIDSIT通过引入连续时间嵌入来有效表示不规则采样数据，并利用带有时间注意力机制的填充序列来处理变长输入，同时不丢失序列信息。

**Result:** 在NASA电池退化数据集上的实验结果表明，TIDSIT显著优于现有模型，预测误差降低了50%以上，并将SoH预测误差保持在0.58%以下。

**Conclusion:** TIDSIT架构具有通用性，有望应用于涉及不规则时间序列数据的更广泛的健康监测任务。

> **ai_Abstract:** 本文提出了一种名为时间感知动态序列倒置Transformer（TIDSIT）的新型机器学习架构，用于精确估计电池的健康状态（SoH）。针对现有模型难以处理现实世界中不规则采样和变长电池放电数据的挑战，TIDSIT引入了连续时间嵌入和时间注意力机制来有效处理这些复杂性，避免信息丢失。在NASA电池退化数据集上的实验证明，TIDSIT在预测误差方面比现有模型有显著提升，实现了超过50%的误差降低，并将SoH预测误差控制在0.58%以下，显示了其在处理不规则时间序列数据方面的通用性和潜力。

> **摘要翻译:** 在过去十年中，电池驱动车辆和储能系统的快速普及使得电池健康监测变得越来越重要。电池在这些系统的效率和安全中扮演着核心角色，但它们不可避免地会随着重复的充放电循环而退化。这种退化导致能源效率降低和潜在的过热，带来了重大的安全隐患。因此，准确估计电池的健康状态（SoH）对于确保运行可靠性和安全性至关重要。已经提出了几种机器学习架构，如LSTM、Transformer和基于编码器的模型，用于从放电循环数据中估计SoH。然而，这些模型难以处理现实世界测量中固有的不规则性：放电读数通常以非均匀间隔记录，并且放电循环的长度差异很大。为了解决这个问题，大多数现有方法从序列中提取特征而不是完整处理它们，这会导致信息丢失并损害准确性。为了克服这些挑战，我们提出了一种新颖的架构：时间感知动态序列倒置Transformer（TIDSIT）。TIDSIT结合了连续时间嵌入，以有效表示不规则采样数据，并利用带有时间注意力机制的填充序列来管理变长输入，而不会丢弃序列信息。NASA电池退化数据集上的实验结果表明，TIDSIT显著优于现有模型，预测误差降低了50%以上，并将SoH预测误差保持在0.58%以下。此外，该架构具有通用性，有望在涉及不规则时间序列数据的健康监测任务中获得更广泛的应用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [51] [BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.07769)
> *BEAVER：构建可评估变异环境以评估多目标强化学习*

*Ruohong Liu, Jack Umenberger, Yize Chen* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 建筑能源管理, 多目标优化, 泛化, 基准

**Comment:** Accepted at the Workshop on Computational Optimization of Buildings
  (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML
  2025), Vancouver, Canada

> **TL;DR:** 本文提出了BEAVER，一个用于评估多目标强化学习在建筑能源管理中泛化能力的新基准。研究发现现有方法在环境变化下性能下降，强调了将依赖动态的上下文信息纳入策略学习的重要性。

**AI_Comments:** 这篇论文通过构建BEAVER基准，为评估和开发更具泛化能力的建筑能源管理RL算法提供了重要的工具。其创新点在于对泛化空间的正式表征以及多目标上下文RL问题的提出，这有助于深入理解RL策略在复杂现实环境中的迁移挑战。研究结果揭示了现有方法的局限性，并强调了上下文信息对于提高泛化性能的关键作用，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管强化学习在建筑能源管理中取得了显著进展，但其在效率和跨建筑动态及操作场景的泛化能力方面仍存在开放性问题。现有方法在模拟环境中表现良好，但在实际应用中的可扩展性仍是挑战。

**Method:** 1. 正式刻画了跨环境、多目标建筑能源管理任务的泛化空间。2. 提出了多目标上下文强化学习问题。3. 提供了一种参数化现实建筑RL环境中上下文信息的原则性方法。4. 构建了一个名为BEAVER的新基准，以促进评估可泛化的RL算法。

**Result:** 现有多目标强化学习方法能够在相互冲突的目标之间实现合理的权衡。然而，它们的性能在某些环境变化下会下降。

**Conclusion:** 现有方法在特定环境变化下性能下降，这突显了将依赖于动态的上下文信息纳入策略学习过程的重要性，以提高其泛化能力。

> **ai_Abstract:** 本文旨在解决强化学习在建筑能源管理中跨环境泛化和可扩展性的挑战。作者正式定义了多目标建筑能源管理任务的泛化空间，并提出了多目标上下文强化学习问题。他们提供了一种参数化上下文信息的方法，并构建了一个名为BEAVER的新基准来评估RL算法的泛化能力。研究结果表明，现有方法虽能平衡冲突目标，但在环境变化下性能下降，突出了将动态依赖的上下文信息整合到策略学习中的重要性。

> **摘要翻译:** 近年来，在设计用于建筑能源管理的强化学习（RL）代理方面取得了显著进展。尽管在模拟或受控环境中观察到个别成功，但RL方法在效率和跨建筑动态与操作场景的泛化方面的可扩展性仍然是一个悬而未决的问题。在这项工作中，我们正式描述了跨环境、多目标建筑能源管理任务的泛化空间，并提出了多目标上下文RL问题。这种表述有助于理解在多种控制目标（例如舒适度水平和能耗）下，将学习到的策略跨不同操作上下文（例如气候和热对流动态）进行迁移的挑战。我们提供了一种原则性的方法来参数化现实建筑RL环境中的此类上下文信息，并构建了一个新颖的基准，以促进在实际建筑控制任务中评估可泛化的RL算法。我们的结果表明，现有的多目标RL方法能够实现冲突目标之间的合理权衡。然而，它们的性能在某些环境变化下会下降，这突显了将依赖于动态的上下文信息纳入策略学习过程的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [57] [DualXDA: Towards Sparse, Efficient and Explainable Data Attribution in Large AI Models](https://arxiv.org/abs/2402.12118)
> *DualXDA：迈向大型AI模型中稀疏、高效且可解释的数据归因*

*Galip Ümit Yolcu, Moritz Weckbecker, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 数据归因, 可解释AI, 稀疏性, 效率, 支持向量机

**Comment:** 

> **TL;DR:** 现有数据归因方法计算成本高且稀疏性低。本文提出DualXDA框架，包含DualDA（基于SVM的稀疏高效数据归因）和XDA（结合特征归因解释），显著提高效率并提供可解释性。

**AI_Comments:** 本文创新性地结合了SVM理论来解决数据归因的效率和稀疏性问题，并进一步通过XDA整合了特征归因的视角，提供了更全面的解释。其在解释时间上的巨大提升（高达4,100,000倍）是显著的突破，有望推动可解释AI在大规模模型中的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型决策过程不透明，现有数据归因（DA）方法计算成本和内存需求高，且归因结果稀疏性低，难以发现数据中的决定性模式。

**Method:** 本文提出DualXDA框架，包含Dual Data Attribution (DualDA) 和 eXplainable Data Attribution (XDA)。DualDA利用支持向量机（SVM）理论，提供快速且自然稀疏的数据归因。XDA通过结合特征归因方法的能力，增强数据归因，解释训练样本为何在有影响力的特征方面对测试样本的预测有影响。

**Result:** DualDA实现了高归因质量，并在下游任务中表现出色。解释时间比原始影响力函数方法快4,100,000倍，比文献中最有效的近似方法快11,000倍。提高了归因的稀疏性。

**Conclusion:** DualXDA的贡献最终指明了可解释AI应用于前所未有规模的未来，使得即使是最大的神经网络架构也能进行透明、高效和新颖的分析，从而催生新一代负责任的AI系统。

> **ai_Abstract:** 本文提出DualXDA，一个针对大型AI模型中数据归因的框架，旨在解决现有方法计算成本高、内存需求大和归因稀疏性低的问题。DualXDA包含DualDA和XDA：DualDA利用SVM理论实现稀疏、高效的数据归因，将解释时间大幅缩短；XDA结合特征归因，解释训练样本与预测的相关性。DualXDA显著提升了数据归因的效率、稀疏性和可解释性，为大规模可解释AI应用铺平道路。

> **摘要翻译:** 深度学习模型取得了卓越的性能，但其决策过程往往不透明。因此，可解释人工智能（XAI）领域在过去十年中显著发展，主要侧重于特征归因方法。作为这一视角的补充，数据归因（DA）作为一种有前景的范式出现，将焦点从特征转移到数据来源。然而，现有DA方法面临着高得令人望而却步的计算成本和内存需求。此外，当前的归因方法表现出低稀疏性，阻碍了数据中决定性模式的发现。我们引入了DualXDA，一个用于稀疏、高效和可解释DA的框架，它由两种相互关联的方法组成，即双重数据归因（DualDA）和可解释数据归因（XDA）：通过DualDA，我们提出了高效且有效的数据归因，利用支持向量机理论为AI预测提供快速且自然稀疏的数据归因。我们证明DualDA实现了高归因质量，擅长解决一系列评估的下游任务，同时与原始影响力函数方法相比，解释时间提高了高达4,100,000倍，与文献中最有效的近似方法相比，提高了高达11,000倍。我们进一步引入了XDA，一种通过特征归因方法的能力来增强数据归因的方法，以解释训练样本为何在有影响力的特征方面与测试样本的预测相关。总而言之，我们在DualXDA中的贡献最终指向了可解释AI应用于前所未有规模的未来，使得即使是最大的神经网络架构也能进行透明、高效和新颖的分析，从而催生新一代负责任的AI系统。代码位于https://github.com/gumityolcu/DualXDA。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [58] [Multiscale Neural PDE Surrogates for Prediction and Downscaling: Application to Ocean Currents](https://arxiv.org/abs/2507.18067)
> *用于预测和降尺度的多尺度神经偏微分方程代理：在洋流中的应用*

*Abdessamad El-Kabid, Loubna Benabbou, Redouane Lguensat, Alex Hernández-García* | **Category: cs.LG, cs.CE** | **Updated: 2025-07-24**

**Keywords:** 神经偏微分方程, 降尺度, 洋流, 深度学习, 神经算子

**Comment:** Workshop @ ICML2025

> **TL;DR:** 该论文引入了一个基于神经算子的深度学习框架，用于解决偏微分方程并提供任意分辨率的解决方案，特别是应用于海洋洋流数据的降尺度，以解决现有卫星产品分辨率不足的问题。

**AI_Comments:** 这项工作在结合深度学习和偏微分方程建模方面具有创新性，通过引入神经算子框架，实现了物理系统（特别是洋流）的任意分辨率预测和降尺度。这对于需要高分辨率数据的应用领域（如沿海管理）具有重要意义。该方法不仅解决了现有数据分辨率不足的问题，还展现了其作为PDE代理模型的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 物理系统（受偏微分方程控制）的精确建模是科学计算中的一个核心挑战。在海洋学中，高分辨率的洋流数据对于沿海管理、环境监测和海上安全至关重要。然而，现有的卫星产品（如哥白尼数据）和全球海洋模型通常缺乏详细局部分析所需的空间粒度。

**Method:** 本文引入了一个基于神经算子的有监督深度学习框架，用于解决偏微分方程并提供任意分辨率的解决方案。此外，还提出了降尺度模型，并将其应用于哥白尼洋流数据。该方法能够建立代理偏微分方程模型，并以任意分辨率预测解决方案，无论输入分辨率如何。

**Result:** 该模型在真实的哥白尼洋流数据和合成的Navier-Stokes模拟数据集上进行了评估，表明其能够提供任意分辨率的解决方案并进行降尺度。

**Conclusion:** 该研究成功开发并评估了一个多尺度神经偏微分方程代理框架，能够为洋流数据提供高分辨率预测和降尺度，有效解决了现有数据空间粒度不足的问题。

> **ai_Abstract:** 本论文提出了一种基于神经算子的多尺度深度学习框架，旨在解决由偏微分方程控制的物理系统建模中的分辨率限制。该框架能够提供任意分辨率的解决方案，并特别应用于海洋洋流数据的降尺度，以弥补现有卫星产品和全球模型空间粒度不足的问题。研究在真实的哥白尼洋流数据和合成的Navier-Stokes模拟数据集上验证了该模型的有效性。

> **摘要翻译:** 偏微分方程控制的物理系统的精确建模是科学计算中的一个核心挑战。在海洋学中，高分辨率的洋流数据对于沿海管理、环境监测和海上安全至关重要。然而，现有的卫星产品，例如哥白尼海流速度数据（空间分辨率约为0.08度）和全球海洋模型，通常缺乏详细局部分析所需的空间粒度。在这项工作中，我们（a）引入了一个基于神经算子的有监督深度学习框架，用于解决偏微分方程并提供任意分辨率的解决方案，并且（b）提出了降尺度模型，并将其应用于哥白尼洋流数据。此外，我们的方法可以模拟代理偏微分方程并以任意分辨率预测解决方案，无论输入分辨率如何。我们在真实的哥白尼洋流数据和合成的Navier-Stokes模拟数据集上评估了我们的模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [77] [A Multi-Faceted Evaluation Framework for Assessing Synthetic Data Generated by Large Language Models](https://arxiv.org/abs/2404.14445)
> *评估大型语言模型生成合成数据的多方面评估框架*

*Yefeng Yuan, Yuhong Liu, Liang Cheng* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 合成数据, 大型语言模型, 评估框架, 隐私保护, 表格数据

**Comment:** 10 pages, 1 figure, 4 tables

> **TL;DR:** SynEval是一个开源评估框架，用于衡量大型语言模型生成的合成数据在保真度、实用性和隐私保护方面的质量。

**AI_Comments:** 这项工作创新性地提出了一个全面的评估框架SynEval，填补了当前大型语言模型生成合成数据评估标准缺失的空白。它不仅关注数据的保真度和实用性，还特别强调了隐私保护，这在当前数据隐私日益受关注的背景下显得尤为重要。该框架的开源性质以及对主流LLM生成数据的验证，使其具有很高的实用价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在生成合成数据方面取得了进展，但存在隐私泄露的担忧，并且缺乏一个能够量化评估合成数据质量及其在下游任务中效用的综合评估框架。

**Method:** 提出了SynEval，一个开源的多方面评估框架，通过一套多样化的评估指标来评估合成表格数据的保真度、实用性和隐私保护。该框架通过应用于ChatGPT、Claude和Llama生成的产品评论数据进行了验证。

**Result:** 实验结果揭示了合成数据生成背景下各种评估指标之间的权衡。

**Conclusion:** SynEval是一个关键工具，能帮助研究人员和实践者判断生成数据的适用性，并强调维护用户隐私。

> **ai_Abstract:** 本文提出了SynEval，一个开源的多方面评估框架，旨在解决大型语言模型生成合成数据时缺乏综合评估标准的问题。SynEval通过评估保真度、实用性和隐私保护来衡量合成表格数据的质量，并已应用于ChatGPT、Claude和Llama生成的合成产品评论数据进行验证。研究发现，在合成数据生成中，不同的评估指标之间存在权衡。SynEval为研究人员和实践者提供了一个关键工具，以确保合成数据的适用性和用户隐私。

> **摘要翻译:** 生成式人工智能和大型语言模型（LLMs）的快速发展为生成合成数据开辟了新途径，尤其是在结构化表格数据（如产品评论）领域。尽管潜在益处巨大，但隐私泄露的担忧也随之浮现，特别是在训练数据集中使用了个人信息的情况下。此外，目前缺乏一个能够定量衡量所生成合成数据质量及其在下游任务中效用的综合评估框架。针对这一空白，我们引入了SynEval，一个开源评估框架，旨在通过一套多样化的评估指标来评估合成表格数据的保真度、实用性和隐私保护。我们通过将SynEval应用于由三种最先进的LLM（ChatGPT、Claude和Llama）生成的合成产品评论数据，验证了我们所提出框架的有效性。我们的实验结果揭示了在合成数据生成背景下各种评估指标之间的权衡。此外，SynEval是从事合成表格数据研究人员和实践者的一个关键工具，使他们能够明智地确定生成数据对其特定应用的适用性，并强调维护用户隐私。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [78] [CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series](https://arxiv.org/abs/2507.17796)
> *CoCAI: 基于Copula的多变量时间序列共形异常识别*

*Nicholas A. Pearson, Francesca Zanello, Davide Russo, Luca Bortolussi, Francesca Cairoli* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-23**

**Keywords:** 多变量时间序列, 异常检测, 共形预测, Copula模型, 扩散模型

**Comment:** Accepted for Presentation at Runtime Verification 25

> **TL;DR:** CoCAI是一个结合生成式AI和Copula模型的新框架，用于多变量时间序列的准确预测和鲁棒异常检测，通过共形预测校准预测结果，并利用降维与Copula模型提供统计学异常分数，在真实数据上表现良好。

**AI_Comments:** CoCAI的创新之处在于结合了生成式AI（扩散模型）、Copula建模和共形预测，为多变量时间序列的预测和异常检测提供了一个统计学上严谨且实用的框架。其离线校准阶段降低了部署复杂性，且在真实系统数据上的验证增加了其实用性。该方法对于需要高精度预测和鲁棒异常识别的应用（如基础设施监控）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决多变量时间序列分析中的两个关键挑战：提供准确的预测和实现鲁棒的异常检测。

**Method:** CoCAI框架结合生成式AI和基于Copula的建模。它利用扩散模型捕获数据复杂依赖以实现高质量预测，并通过共形预测技术校准输出以生成统计有效的预测区域。在此基础上，结合降维技术和基于Copula的建模进行鲁棒异常检测，提供统计学上合理的异常分数。该方法还包含一个离线校准阶段，以减少部署开销。

**Result:** 在源自供水和污水处理系统的真实运行数据上进行的实证测试证实了CoCAI在准确预测目标数据序列和识别其中异常片段方面的有效性。

**Conclusion:** CoCAI是一个有效且理论基础扎实的框架，能够同时实现多变量时间序列的准确预测和鲁棒异常检测。

> **ai_Abstract:** 本文提出了CoCAI（基于Copula的多变量时间序列共形异常识别）框架，旨在解决多变量时间序列分析中的预测准确性和鲁棒异常检测问题。CoCAI利用基于扩散的模型进行高质量预测，并结合共形预测技术生成统计有效的预测区域。在此基础上，通过降维和基于Copula的建模实现鲁棒异常检测，提供统计学上的异常分数。该方法具备离线校准阶段，降低了部署成本，并在真实世界的供水和污水处理系统数据上验证了其在预测和异常识别方面的有效性。

> **摘要翻译:** 我们提出了一个新颖的框架，该框架利用生成式人工智能和基于Copula的建模的力量来解决多变量时间序列分析中的两个关键挑战：提供准确的预测和实现鲁棒的异常检测。我们的方法，基于Copula的多变量时间序列共形异常识别（CoCAI），利用基于扩散的模型来捕获数据中的复杂依赖关系，从而实现高质量的预测。模型的输出通过共形预测技术进一步校准，产生统计上有效的预测区域，即以所需的置信水平覆盖真实目标值。从这些校准后的预测开始，通过结合降维技术和基于Copula的建模执行鲁棒的异常检测，提供统计学上合理的异常分数。CoCAI受益于离线校准阶段，这使得部署期间的开销最小，并提供植根于既定理论基础的可操作结果。在源自供水和污水处理系统的真实运行数据上进行的实证测试证实了CoCAI在准确预测目标数据序列和识别其中异常片段方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [80] [Low-rank adaptive physics-informed HyperDeepONets for solving differential equations](https://arxiv.org/abs/2507.18346)
> *低秩自适应物理信息HyperDeepONets用于求解微分方程*

*Etienne Zeudong, Elsa Cardoso-Bihlo, Alex Bihlo* | **Category: cs.LG, cs.NA, math.NA** | **Updated: 2025-07-24**

**Keywords:** HyperDeepONets, 低秩自适应, 物理信息机器学习, 微分方程, 算子学习

**Comment:** 14 pages, 6 figures, 5 tables

> **TL;DR:** 本文提出PI-LoRA-HyperDeepONets，通过低秩自适应（LoRA）显著减少HyperDeepONets的参数量并提高求解微分方程的性能。

**AI_Comments:** 该研究通过将低秩自适应（LoRA）技术应用于HyperDeepONets，有效解决了其计算和内存效率问题，是物理信息机器学习领域的一个重要进展。LoRA的应用不仅减少了参数量，还可能通过引入正则化来提高模型性能，具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 原始HyperDeepONets虽然提高了表达能力，但由于其庞大的输出参数数量，导致高内存和计算成本。

**Method:** 引入PI-LoRA-HyperDeepONets，通过利用低秩自适应（LoRA）技术，将超网络的输出层权重矩阵分解为两个更小的低秩矩阵，从而减少可训练参数并对主干网络权重引入额外正则化。

**Result:** PI-LoRA-HyperDeepONets在参数上实现了高达70%的减少，并且在预测精度和泛化能力方面持续优于常规HyperDeepONets，适用于求解常微分方程和偏微分方程。

**Conclusion:** PI-LoRA-HyperDeepONets是一种更高效、更准确的求解微分方程的方法，有效解决了HyperDeepONets的计算和内存成本问题，同时提升了预测性能。

> **ai_Abstract:** 本文针对HyperDeepONets在算子学习中存在的内存和计算成本高昂问题，提出了一种名为PI-LoRA-HyperDeepONets的新架构。该方法通过引入低秩自适应（LoRA）技术，将超网络的输出层权重矩阵分解为低秩矩阵，从而显著减少了可训练参数数量并增加了正则化。实验结果表明，PI-LoRA-HyperDeepONets不仅能将参数量减少高达70%，还在求解常微分方程和偏微分方程时展现出更高的预测精度和泛化能力。

> **摘要翻译:** HyperDeepONets在Lee, Cho和Hwang [ICLR, 2023]中被引入，作为一种算子学习的替代架构，其中超网络为DeepONet的主干网络生成权重。虽然这提高了表达能力，但由于所需的输出参数数量庞大，导致高内存和计算成本。在这项工作中，我们在物理信息机器学习环境中引入了一种变体，PI-LoRA-HyperDeepONets，它利用低秩自适应（LoRA）将超网络的输出层权重矩阵分解为两个较小的低秩矩阵来降低复杂性。这减少了可训练参数的数量，同时引入了对主干网络权重的额外正则化。通过对常微分方程和偏微分方程的广泛实验，我们表明PI-LoRA-HyperDeepONets在参数上实现了高达70%的减少，并且在预测精度和泛化能力方面持续优于常规HyperDeepONets。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [82] [The Role of the Time-Dependent Hessian in High-Dimensional Optimization](https://arxiv.org/abs/2403.02418)
> *时变海森矩阵在高维优化中的作用*

*Tony Bonnaire, Giulio Biroli, Chiara Cammarota* | **Category: cs.LG, cond-mat.dis-nn, cond-mat.stat-mech** | **Updated: 2025-07-24**

**Keywords:** 梯度下降, 海森矩阵, 高维优化, 相位恢复, 谱性质

**Comment:** 32 pages

> **TL;DR:** 本文研究了高维非凸优化中梯度下降的收敛性，发现海森矩阵的谱性质在下降过程中发生动态转变，并强调了初始化和早期动力学对于逃离粗糙区域的重要性。

**AI_Comments:** 这项研究通过分析海森矩阵的动态行为，为理解高维非凸优化中的梯度下降提供了新的视角。其创新之处在于揭示了早期动力学和初始化在逃离粗糙区域中的重要性，并指出了有限系统尺寸效应的潜在益处。这对于机器学习中优化算法的设计和理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在强非凸和高维设置中，梯度下降为何能找到好的解的理论理解仍然难以捉摸，尤其是在最近的机器学习应用中。本文旨在理解这一现象。

**Method:** 本文以相位恢复问题为例，分析了梯度下降过程中海森矩阵的性质，并识别了其谱性质中的一个动态转变。

**Result:** 当信噪比（SNR）足够大时，在下降开始时海森矩阵中存在一个信息丰富的负方向。在下降过程中，谱中会发生BBP转变：该方向丢失，动力学被困在充满边缘稳定坏最小值的崎岖区域。对于有限系统大小，负曲率窗口允许系统在无限大小的理论信噪比之前很好地恢复信号。

**Conclusion:** 初始化和早期动力学对于有效导航粗糙损失景观起着核心作用，即使在理论预测的无限大系统信噪比之前，有限系统也能恢复信号。

> **ai_Abstract:** 本文探讨了梯度下降在高维非凸损失景观中的收敛性，特别关注了相位恢复问题。研究发现，在梯度下降过程中，海森矩阵的谱性质会发生动态转变，从最初的有用负方向转变为被困在崎岖区域。研究强调了初始化和早期动力学对于在粗糙景观中有效寻找解的关键作用，并指出有限系统大小在较低信噪比下也能成功恢复信号。

> **摘要翻译:** 梯度下降常用于在粗糙景观中寻找最小值，尤其是在最近的机器学习应用中。然而，为何能找到好的解的理论理解仍然难以捉摸，尤其是在强非凸和高维设置中。本文以相位恢复问题为例，该问题最近在理论机器学习中受到了广泛关注。我们分析了梯度下降过程中的海森矩阵，识别了其谱性质中的一个动态转变，并将其与逃离损失景观中粗糙区域的能力联系起来。当信噪比（SNR）足够大时，在下降开始时，即在初始条件下，海森矩阵中存在一个信息丰富的负方向。在下降过程中，谱中会在有限时间内发生BBP转变：该方向丢失，动力学被困在充满边缘稳定坏最小值的崎岖区域。令人惊讶的是，对于有限系统大小，这个负曲率窗口允许系统在无限大小的理论信噪比之前很好地恢复信号，这强调了初始化和早期动力学在有效导航粗糙景观中的核心作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [99] [Group Sequence Policy Optimization](https://arxiv.org/abs/2507.18071)
> *组序列策略优化*

*Chujie Zheng, Shixuan Liu, Mingze Li, Xiong-Hui Chen, Bowen Yu, Chang Gao, Kai Dang, Yuqiong Liu, Rui Men, An Yang, Jingren Zhou, Junyang Lin* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 大型语言模型, 序列优化, MoE, GSPO

**Comment:** 

> **TL;DR:** 本文提出了一种名为GSPO的强化学习算法，通过序列级优化而非令牌级优化，显著提升了大型语言模型训练的稳定性、效率和性能。

**AI_Comments:** GSPO的创新点在于从令牌级优化转向序列级优化，这可能更符合语言生成的整体性。其对MoE模型训练稳定性的提升是一个重要贡献，因为MoE模型在RL训练中常面临挑战。该算法对Qwen3模型的实际应用也验证了其实用性和有效性，表明其在工业界具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 之前的强化学习算法在训练大型语言模型时采用令牌级重要性比率，可能存在效率和稳定性问题，因此需要一种更稳定、高效、高性能的算法。

**Method:** GSPO通过基于序列似然定义重要性比率，并执行序列级剪裁、奖励和优化，这与之前采用令牌级重要性比率的方法不同。

**Result:** GSPO实现了优于GRPO算法的训练效率和性能，显著稳定了专家混合（MoE）强化学习训练，并有可能简化强化学习基础设施的设计。这些优点已促成了最新Qwen3模型的显著改进。

**Conclusion:** GSPO是一种稳定、高效、高性能的强化学习算法，通过序列级优化为大型语言模型训练带来了显著改进，并对RL基础设施设计具有简化潜力。

> **ai_Abstract:** 本文提出了一种新颖的强化学习算法——组序列策略优化（GSPO），专为大型语言模型训练设计。GSPO通过在序列级别而非传统的令牌级别定义重要性比率并进行优化，解决了现有算法的局限性。实验证明，GSPO在训练效率和性能上超越了GRPO，尤其在稳定专家混合（MoE）强化学习训练方面表现突出，并有望简化RL基础设施。GSPO的成功应用已显著提升了Qwen3模型的性能。

> **摘要翻译:** 本文介绍了组序列策略优化（GSPO），这是一种用于训练大型语言模型的稳定、高效且高性能的强化学习算法。与以往采用令牌级重要性比率的算法不同，GSPO基于序列似然定义重要性比率，并执行序列级剪裁、奖励和优化。我们证明，与GRPO算法相比，GSPO实现了卓越的训练效率和性能，显著稳定了专家混合（MoE）强化学习训练，并具有简化强化学习基础设施设计的潜力。GSPO的这些优点为最新Qwen3模型的显著改进做出了贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [102] [Unsupervised Concept Drift Detection from Deep Learning Representations in Real-time](https://arxiv.org/abs/2406.17813)
> *实时深度学习表示中的无监督概念漂移检测*

*Salvatore Greco, Bartolomeo Vacchetti, Daniele Apiletti, Tania Cerquitelli* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 无监督, 概念漂移, 深度学习, 实时, DriftLens

**Comment:** Accepted at IEEE Transactions on Knowledge and Data Engineering
  (TKDE)

> **TL;DR:** 提出了DriftLens，一个无监督的实时概念漂移检测和特征化框架，专为处理非结构化数据的深度学习分类器设计，在准确性、速度和可解释性方面优于现有方法。

**AI_Comments:** DriftLens的创新之处在于其将无监督漂移检测与深度学习表示相结合，解决了真实标签稀缺场景下的实际问题。其在实时性、准确性和漂移解释方面的提升，对于需要持续监控模型性能的生产环境具有重要意义。特别是其能提供漂移解释，有助于用户理解漂移原因，是现有方法所欠缺的。

<details>
  <summary>Details</summary>

**Motivation:** 现有概念漂移检测方法大多依赖于真实标签，但在许多实际场景中标签难以获取。尽管存在无监督方法，但它们往往缺乏足够的准确性，计算成本高昂，难以用于实时大规模生产环境，且未能有效解释漂移。

**Method:** 本文提出了DriftLens框架，一个无监督的实时概念漂移检测和特征化框架。它针对处理非结构化数据的深度学习分类器设计，通过利用深度学习表示中的分布距离来实现高效准确的检测。此外，DriftLens通过分析和解释漂移对每个标签的影响来表征漂移。

**Result:** DriftLens在17个用例中的15个中，在检测漂移方面优于现有方法；运行速度至少快5倍；产生的漂移曲线与实际漂移高度一致（相关性≥0.85）；并能有效识别代表性漂移样本作为解释。

**Conclusion:** DriftLens是一个有效、高效且可解释的无监督实时概念漂移检测框架，能够克服现有方法的局限性，特别适用于深度学习模型处理非结构化数据。

> **ai_Abstract:** 本文提出了DriftLens，一个创新的无监督框架，用于实时概念漂移检测和特征化。该框架专门针对处理非结构化数据的深度学习分类器设计，通过利用深度学习表示中的分布距离，有效解决了现有方法在准确性、计算效率以及漂移解释方面的局限性。实验结果表明，DriftLens在多数用例中表现优于现有方法，运行速度显著提升，并能提供高度相关的漂移曲线和可解释的漂移样本。

> **摘要翻译:** 概念漂移是指目标领域的基础数据分布和统计特性随时间变化，导致模型性能下降的现象。因此，生产模型需要持续的概念漂移检测监控。迄今为止，大多数漂移检测方法都是有监督的，依赖于真实标签。然而，在许多实际场景中，由于真实标签通常不可用，这些方法并不适用。尽管最近的努力提出了无监督漂移检测器，但许多方法缺乏可靠检测所需的准确性，或者计算成本过高，无法在实时、高维、大规模生产环境中应用。此外，它们往往未能有效地表征或解释漂移。
为了解决这些限制，我们提出了\textsc{DriftLens}，一个用于实时概念漂移检测和特征化的无监督框架。\textsc{DriftLens}专为处理非结构化数据的深度学习分类器设计，利用深度学习表示中的分布距离来实现高效准确的检测。此外，它通过分析和解释漂移对每个标签的影响来表征漂移。我们对不同分类器和数据类型的评估表明，\textsc{DriftLens} (i) 在17个用例中的15个中，在检测漂移方面优于现有方法；(ii) 运行速度至少快5倍；(iii) 产生的漂移曲线与实际漂移高度一致（相关性≥0.85）；(iv) 有效地识别代表性漂移样本作为解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [106] [Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures](https://arxiv.org/abs/2407.09468)
> *超越欧几里得：几何、拓扑和代数结构在现代机器学习中的图解指南*

*Mathilde Papillon, Sophia Sanborn, Johan Mathe, Louisa Cornelis, Abby Bertics, Domas Buracas, Hansen J Lillemark, Christian Shewmake, Fatih Dinc, Xavier Pennec, Nina Miolane* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 非欧几里得数据, 几何机器学习, 拓扑结构, 代数结构, 机器学习综述

**Comment:** 

> **TL;DR:** 本综述探讨了将经典机器学习方法推广到非欧几里得数据类型（如具有几何、拓扑和代数结构的数据）的必要性，并提出了一个统一的分类框架。

**AI_Comments:** 这篇综述论文的重要性在于它系统地阐述了机器学习从欧几里得数据处理向非欧几里得数据处理的范式转变，突出了几何、拓扑和代数结构在现代机器学习中的核心作用。其创新之处在于提出了一个统一的图形分类法，为理解和整合该领域的最新进展提供了直观的框架，对于推动该领域的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 经典的机器学习主要针对欧几里得空间中的数据开发，但现代机器学习越来越多地遇到本质上非欧几里得的丰富结构化数据。从这些数据中提取知识需要更广泛的数学视角，因此需要将经典方法推广到具有几何、拓扑和代数结构的非常规数据类型。

**Method:** 本综述提供了一个进入快速发展的非欧几里得结构机器学习领域的便捷入口，并提出了一个图形分类法，将最新进展整合到一个直观的统一框架中。

**Result:** 本综述提取了当前面临的挑战，并强调了该领域未来发展的激动人心的机遇，同时提出了一个整合最新进展的图形分类法和统一框架。

**Conclusion:** 该领域旨在通过引入非欧几里得结构来重新定义现代机器学习，以应对日益增长的复杂数据类型，并为未来的研究提供了方向和机遇。

> **ai_Abstract:** 本综述探讨了现代机器学习中处理非欧几里得结构化数据（如几何、拓扑和代数数据）的必要性。鉴于传统机器学习主要基于欧几里得空间，文章旨在推广经典方法以适应这些复杂数据类型。为此，作者提供了一个关于这一新兴领域的入门指南，并提出了一个统一的图形分类法来整合现有进展，同时识别了当前挑战和未来机遇。

> **摘要翻译:** 欧几里得几何的持久遗产是经典机器学习的基础，几十年来，经典机器学习主要针对欧几里得空间中的数据进行开发。然而，现代机器学习越来越多地遇到本质上非欧几里得的丰富结构化数据。这些数据可以表现出复杂的几何、拓扑和代数结构：从时空曲率的几何形状，到大脑中神经元之间拓扑复杂的相互作用，再到描述物理系统对称性的代数变换。从这种非欧几里得数据中提取知识需要更广阔的数学视角。呼应19世纪非欧几里得几何革命，一个新兴的研究方向正在用非欧几里得结构重新定义现代机器学习。其目标是：将经典方法推广到具有几何、拓扑和代数结构的非常规数据类型。在本综述中，我们为这个快速发展的领域提供了一个便捷的入口，并提出了一个图形分类法，将最新进展整合到一个直观的统一框架中。随后，我们深入探讨了当前的挑战，并强调了该领域未来发展的激动人心的机遇。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [110] [Efficient Uncertainty in LLMs through Evidential Knowledge Distillation](https://arxiv.org/abs/2507.18366)
> *通过证据知识蒸馏实现LLM中的高效不确定性*

*Lakshmana Sri Harsha Nemani, P. K. Srijith, Tomasz Kuśmierczyk* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** LLMs, 不确定性量化, 知识蒸馏, 证据学习, LoRA

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的方法，通过将不确定性感知的教师模型蒸馏到紧凑的学生模型中，实现LLM中高效且有效的不确定性估计，同时保持性能，并且只需单次前向传播。

**AI_Comments:** 这项工作通过引入证据知识蒸馏，为LLM中的不确定性量化提供了一个高效且创新的解决方案。其主要创新点在于将复杂的、多前向传播的教师模型蒸馏为单次前向传播的学生模型，显著降低了计算成本，同时保持或提升了性能。特别是结合LoRA和探索Dirichlet分布输出，为LLM的高效部署和实际应用提供了有价值的路径，解决了长期以来LLM在不确定性估计方面的效率瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 标准大型语言模型（LLMs）的准确不确定性量化仍然是一个关键挑战。现有的贝叶斯和基于集成的方法通常需要计算成本高昂的采样，涉及多次前向传播来估计预测不确定性。

**Method:** 本文引入了一种新颖的方法，通过将不确定性感知的教师模型蒸馏到紧凑的学生模型中来实现LLM中的高效不确定性估计。学生模型使用低秩适应（LoRA）进行微调，并比较了两种蒸馏策略：一种学生模型使用传统的基于softmax的输出，另一种使用Dirichlet分布输出通过证据学习显式建模认知不确定性。

**Result:** 在分类数据集上的实证评估表明，学生模型可以实现与其教师模型相当或更优的预测和不确定性量化性能，同时关键的是只需单次前向传播。

**Conclusion:** 本文首次证明了通过证据知识蒸馏可以在LLMs中实现即时且鲁棒的不确定性量化，从而解决了LLM中高效不确定性估计的挑战。

> **ai_Abstract:** 本文提出了一种通过证据知识蒸馏在大型语言模型（LLMs）中实现高效不确定性量化的新方法。针对现有贝叶斯和集成方法计算成本高昂的问题，研究者将不确定性感知的教师模型蒸馏到使用低秩适应（LoRA）微调的紧凑学生模型中。实验对比了基于softmax和Dirichlet分布输出的两种学生模型策略，结果表明学生模型在仅需单次前向传播的情况下，即可达到与教师模型相当或更优的预测和不确定性量化性能。这标志着通过证据蒸馏在LLMs中实现即时且鲁棒不确定性量化的首次成功。

> **摘要翻译:** 标准大型语言模型（LLMs）的准确不确定性量化仍然是一个关键挑战，促使人们采用贝叶斯和基于集成的方法。然而，这些方法通常需要计算成本高昂的采样，涉及多次前向传播以有效估计预测不确定性。
在本文中，我们引入了一种新颖的方法，可以在不牺牲性能的情况下，实现LLM中高效且有效的不确定性估计。具体来说，我们将不确定性感知的教师模型——最初需要多次前向传播——蒸馏到紧凑的学生模型中，这些学生模型共享相同的架构，但使用低秩适应（LoRA）进行微调。我们比较了两种不同的蒸馏策略：一种是学生模型采用传统的基于softmax的输出，另一种是学生模型利用Dirichlet分布输出，通过证据学习显式建模认知不确定性。
在分类数据集上的实证评估表明，这些学生模型可以实现与其教师模型相当或更优的预测和不确定性量化性能，同时关键的是只需单次前向传播。据我们所知，这是首次证明通过证据蒸馏可以在LLMs中实现即时且鲁棒的不确定性量化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [113] [GenSelect: A Generative Approach to Best-of-N](https://arxiv.org/abs/2507.17797)
> *GenSelect：一种生成式N选一方法*

*Shubham Toshniwal, Ivan Sorokin, Aleksander Ficek, Ivan Moshkov, Igor Gitman* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-23**

**Keywords:** GenSelect, 生成式奖励模型, LLM, N选一, 推理任务

**Comment:** Presented at the 2nd AI for MATH Workshop @ ICML

> **TL;DR:** GenSelect 是一种新的方法，让大型语言模型（LLMs）通过长推理从N个候选方案中选择最佳方案，在数学推理任务中表现优于现有方法。

**AI_Comments:** GenSelect 提供了一种创新方式来利用LLM的比较推理能力，超越了简单的评分机制，并解决了现有方法的可扩展性问题。其在数学推理等复杂任务中仅通过简单提示就能实现有效性，这一点非常值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 当前的生成式奖励模型在处理较大采样预算时存在局限性：点式方法未能充分利用LLM的比较能力，而配对方法则效率低下。

**Method:** GenSelect 引入了一种方法，让LLM通过长推理从N个候选方案中选择最佳方案。这种方法利用了LLM的比较优势，并能有效扩展以适应并行采样预算。

**Result:** 在数学推理方面，QwQ 和 DeepSeek-R1-0528 等推理模型在 GenSelect 方面表现出色，通过简单的提示就超越了现有的评分方法。

**Conclusion:** GenSelect 通过长推理使LLM能够有效地从多个候选方案中选择最佳方案，充分利用了LLM的比较能力，并在数学推理等任务中表现出高效的扩展性。

> **ai_Abstract:** GenSelect 是一种新颖的生成式方法，它通过长推理使大型语言模型（LLMs）能够高效地从多个候选方案中选择最佳方案。该方法解决了当前逐点和成对方法在利用LLM比较能力和扩展性方面的局限性，并在数学推理任务中展示了优越的性能。

> **摘要翻译:** 生成式奖励模型与并行采样相结合，使得推理任务的测试时扩展成为可能。当前的方法采用对单个解决方案进行逐点评分或成对比较。然而，逐点方法未能充分利用大型语言模型（LLM）的比较能力，而配对方法在较大的采样预算下扩展效率低下。我们引入了 GenSelect，其中 LLM 使用长推理从N个候选方案中选择最佳解决方案。这既利用了LLM的比较优势，又能有效地扩展以适应并行采样预算。对于数学推理，我们证明了像 QwQ 和 DeepSeek-R1-0528 这样的推理模型在 GenSelect 方面表现出色，通过简单的提示就超越了现有的评分方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [132] [On the Approximation of Stationary Processes using the ARMA Model](https://arxiv.org/abs/2408.10610)
> *关于使用ARMA模型逼近平稳过程*

*Anand Ganesh, Babhrubahan Bose, Anand Rajagopalan* | **Category: cs.LG, math.PR, stat.ME, 60G10, G.3** | **Updated: 2025-07-24**

**Keywords:** ARMA模型, 平稳过程, 近似误差, $L^{\infty}$范数, 巴拿赫代数

**Comment:** 16 pages, 1 figure

> **TL;DR:** 本文重新探讨了使用ARMA模型逼近真实平稳过程时的近似误差问题，提出并证明了$L^{\infty}$范数作为一种新的有效度量，并在巴拿赫代数框架下探讨了其性质和可逆性，提供了近似界限。

**AI_Comments:** 本文的创新之处在于引入并深入研究了$L^{\infty}$范数在量化ARMA模型近似平稳过程误差中的应用。通过将其置于巴拿赫代数的框架下，不仅提供了严格的数学基础，还拓展了可逆性概念的适用范围，这对于时间序列分析和信号处理领域的理论发展具有重要意义。该研究为理解和控制模型近似误差提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 重新审视与自回归移动平均（ARMA）模型相关的一个旧问题，即量化和界定真实平稳过程$X_t$与ARMA模型$Y_t$之间的近似误差。

**Method:** 采用ARMA模型的传递函数表示，并证明相关的$L^{\infty}$范数提供了一种有效的替代范数。展示了平稳过程的某个子空间（包括ARMA模型）在$L^{\infty}$范数下形成一个巴拿赫代数。计算了连续传递函数背景下的一些显式近似界限，并评论了Padé近似和简约模型的一些启发式思想。

**Result:** 相关的$L^{\infty}$范数可以控制$L^2$范数，并具有与倒谱范数相当的结构特性。平稳过程的某个子空间（包括ARMA模型）在$L^{\infty}$范数下形成一个巴拿赫代数，该代数尊重$H^{\infty}$传递函数的群结构。该代数中可逆性的自然定义与ARMA可逆性的原始定义一致，并且比Wiener的$\ell^1$条件更好地推广到非ARMA过程。计算出连续传递函数背景下的一些显式近似界限。

**Conclusion:** 本文提出并验证了$L^{\infty}$范数在量化和控制ARMA模型对平稳过程的近似误差方面的有效性，并展示了其在巴拿赫代数框架下的良好数学性质和对可逆性概念的推广，为近似误差分析提供了新的理论工具。

> **ai_Abstract:** 本文重新审视了使用ARMA模型逼近平稳过程时的近似误差问题。研究人员采用传递函数表示，引入并验证了$L^{\infty}$范数作为一种有效的误差度量，该范数不仅能控制$L^2$范数，而且具有良好的结构特性。论文进一步证明了包含ARMA模型的平稳过程子空间在$L^{\infty}$范数下形成一个巴拿赫代数，其可逆性定义与传统一致并能更好地推广。最后，文章给出了连续传递函数情况下的显式近似界限，并对现有启发式方法进行了评论。

> **摘要翻译:** 我们重新探讨了一个与自回归移动平均（ARMA）模型相关的旧问题，即量化和界定真实平稳过程$X_t$与ARMA模型$Y_t$之间的近似误差。我们采用ARMA模型的传递函数表示，并证明相关的$L^{\infty}$范数提供了一种有效的替代范数，该范数可以控制$L^2$范数，并具有与倒谱范数相当的结构特性。我们证明了平稳过程的某个子空间（包括ARMA模型）在$L^{\infty}$范数下形成一个巴拿赫代数，该代数尊重$H^{\infty}$传递函数的群结构。该代数中可逆性的自然定义与ARMA可逆性的原始定义一致，并且比Wiener的$\ell^1$条件更好地推广到非ARMA过程。最后，我们在连续传递函数这一更简单的背景下计算了一些显式近似界限，并评论了Padé近似和简约模型的一些启发式思想。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [138] [ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense](https://arxiv.org/abs/2502.18549)
> *ARBoids：基于Boids模型的自适应残差强化学习在合作多无人水面艇目标防御中的应用*

*Jiyue Tao, Tongsheng Shen, Dexin Zhao, Feitian Zhang* | **Category: cs.LG, cs.CR, cs.RO** | **Updated: 2025-07-10**

**Keywords:** 无人水面艇, 目标防御, 残差强化学习, Boids模型, 多智能体系统

**Comment:** 

> **TL;DR:** ARBoids是一种结合深度强化学习和Boids模型的自适应残差强化学习框架，用于解决多无人水面艇目标防御问题，在模拟环境中表现出优越的拦截性能和对不同机动性攻击者的强大适应性。

**AI_Comments:** 本文的创新点在于将Boids模型与深度强化学习相结合，利用Boids模型提供高效的基线策略，再通过DRL进行残差学习以优化和适应复杂情况。这种结合方式有效提升了多USV在面对高机动性攻击者时的防御能力，展现了良好的实用性和泛化潜力。其方法对于解决多智能体协同控制问题具有借鉴意义。

<details>
  <summary>Details</summary>

**Motivation:** 无人水面艇（USV）的目标防御问题，尤其是在攻击者机动性优于防御者的情况下，有效拦截变得异常困难。

**Method:** 本文提出了ARBoids，一个新颖的自适应残差强化学习框架。该框架将深度强化学习（DRL）与受生物启发、基于力的Boids模型相结合。其中，Boids模型作为多智能体协调的计算高效基线策略，而DRL则学习一个残差策略以自适应地优化防御者的行动。

**Result:** 在Gazebo高保真模拟环境中进行了验证，ARBoids展示了优于传统拦截策略（包括纯基于力的方法和香草DRL策略）的性能。此外，所学策略对具有不同机动性特征的攻击者表现出强大的适应性，突出了其鲁棒性和泛化能力。

**Conclusion:** ARBoids框架通过结合Boids模型和深度强化学习，有效解决了多无人水面艇的目标防御问题，尤其是在面对高机动性攻击者时，展现出卓越的性能、鲁棒性和泛化能力。

> **ai_Abstract:** 本文提出了一种名为ARBoids的新型自适应残差强化学习框架，旨在解决多无人水面艇（USV）的目标防御问题，尤其是在攻击者机动性较强的情况下。ARBoids结合了基于力的Boids模型作为高效的多智能体协调基线策略，并利用深度强化学习（DRL）学习残差策略以优化防御者行动。实验结果表明，在Gazebo模拟环境中，ARBoids在拦截性能上优于传统方法，并对不同机动性的攻击者表现出强大的适应性、鲁棒性和泛化能力。

> **摘要翻译:** 无人水面艇（USV）的目标防御问题（TDP）涉及在一个或多个防御USV拦截敌对USV，防止其突破指定目标区域。当攻击者表现出优于防御者的机动性时，会出现一个特别具有挑战性的场景，这使得有效拦截变得异常复杂。为了解决这一挑战，本文介绍了ARBoids，一个新颖的自适应残差强化学习框架，它将深度强化学习（DRL）与受生物启发、基于力的Boids模型相结合。在该框架内，Boids模型作为多智能体协调的计算高效基线策略，而DRL则学习一个残差策略以自适应地完善和优化防御者的行动。所提出的方法在高保真Gazebo模拟环境中得到了验证，展示了优于传统拦截策略的性能，包括纯基于力的方法和香草DRL策略。此外，所学策略对具有不同机动性特征的攻击者表现出强大的适应性，突出了其鲁棒性和泛化能力。ARBoids的代码将在本文被接受后发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [139] [C-AAE: Compressively Anonymizing Autoencoders for Privacy-Preserving Activity Recognition in Healthcare Sensor Streams](https://arxiv.org/abs/2507.18072)
> *C-AAE：用于医疗保健传感器流中隐私保护活动识别的压缩匿名化自编码器*

*Ryusei Fujimoto, Yugo Nakamura, Yutaka Arakawa* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 隐私保护, 活动识别, 自编码器, 传感器数据, 数据压缩

**Comment:** 

> **TL;DR:** C-AAE结合匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM），在医疗健康传感器数据中实现隐私保护的活动识别，同时显著降低数据量和用户再识别率。

**AI_Comments:** C-AAE的创新之处在于结合了深度学习（AAE）的特征提取与抑制能力和传统信号处理（ADPCM）的数据压缩与信息掩盖能力，在实现隐私保护的同时有效降低了数据传输和存储开销，这对于资源受限的医疗物联网环境尤其重要。该方法在平衡隐私和效用方面取得了显著进展。

<details>
  <summary>Details</summary>

**Motivation:** 医疗保健应用中，可穿戴传感器数据包含精细的行为特征，可能被利用进行用户再识别，因此隐私保护至关重要。

**Method:** 本文提出C-AAE，一种结合了匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM）的压缩匿名化自编码器。AAE首先将原始传感器窗口投影到潜在空间，保留活动相关特征并抑制身份线索。ADPCM随后对该潜在流进行差分编码，进一步掩盖残余身份信息并缩小比特率。

**Result:** 在MotionSense和PAMAP2数据集上的实验表明，C-AAE相对于单独使用AAE，用户再识别F1分数降低了10-15个百分点；同时，活动识别F1分数与未受保护基线相比，保持在5个百分点以内。ADPCM还将数据量减少了约75%，从而减轻了传输和存储开销。

**Conclusion:** C-AAE为医疗保健领域中基于传感器的连续活动识别提供了一种实用途径，能够有效平衡隐私和实用性。

> **ai_Abstract:** 本文提出了一种名为C-AAE的压缩匿名化自编码器，旨在解决医疗保健传感器数据中的隐私泄露问题。C-AAE结合了匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM），通过AAE抑制身份信息并保留活动特征，再通过ADPCM进一步掩盖身份并压缩数据。实验证明，C-AAE在显著降低用户再识别率（10-15%）的同时，保持了较高的活动识别准确性，并有效减少了数据量（75%），为医疗健康领域实现隐私与实用性的平衡提供了有效方案。

> **摘要翻译:** 可穿戴式加速度计和陀螺仪编码了精细的行为特征，这些特征可能被利用来重新识别用户，使得隐私保护对于医疗保健应用至关重要。我们引入了C-AAE，这是一种结合了匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM）的压缩匿名化自编码器。AAE首先将原始传感器窗口投影到潜在空间中，该空间保留了与活动相关的特征，同时抑制了身份线索。然后，ADPCM对这个潜在流进行差分编码，进一步掩盖了残留的身份信息并缩小了比特率。在MotionSense和PAMAP2数据集上的实验表明，C-AAE相对于单独使用AAE，将用户再识别F1分数降低了10-15个百分点，同时将活动识别F1分数保持在未受保护基线的5个百分点以内。ADPCM还将数据量减少了约75%，从而减轻了传输和存储开销。这些结果表明，C-AAE为医疗保健领域中基于传感器的连续活动识别提供了平衡隐私和实用性的一种实用途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [140] [A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18376)
> *智能农业中扩散模型的综合综述：进展、应用与挑战*

*Xing Hua, Haodong Chen, Qianqian Duan, Danfeng Hong, Ruijiao Li, Huiliang Shang, Linghua Jiang, Haima Yang, Dawei Zhang* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 智能农业, 精准农业, 数据增强, 综述

**Comment:** 

> **TL;DR:** 该论文综述了扩散模型在智能农业中的最新进展、应用及其面临的挑战，强调了其在解决数据稀缺和提高模型性能方面的潜力。

**AI_Comments:** 这篇综述性文章系统地梳理了扩散模型在智能农业中的应用现状和未来前景。其创新点在于将前沿的生成模型技术与农业领域的具体问题相结合，并指出了扩散模型在解决农业数据稀缺和不平衡样本方面的独特优势。文章不仅展示了扩散模型的潜力，也客观地提出了其面临的挑战，为后续研究提供了明确的方向。对于推动智能农业技术发展具有重要参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着全球人口增长和耕地资源日益稀缺，智能农业和精准农业成为农业发展的关键方向。人工智能技术，特别是深度学习模型，在农业领域应用广泛。扩散模型作为一种新兴的生成模型，在农业图像处理、数据增强和遥感等任务中展现出巨大潜力，并且相比传统生成对抗网络（GANs）具有更优的训练稳定性和生成质量，能有效解决农业数据有限和图像样本不平衡的挑战。

**Method:** 本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。

**Result:** 实验结果表明，扩散模型在数据增强、图像生成和去噪方面显著提高了模型精度和鲁棒性，尤其是在复杂环境中。

**Conclusion:** 尽管面临计算效率和泛化能力方面的挑战，但随着技术进步，扩散模型有望在智能和精准农业中发挥越来越重要的作用，为全球农业的可持续发展提供实质性支持。

> **ai_Abstract:** 本文综述了扩散模型在智能农业领域的应用进展、潜力及挑战。面对人口增长和耕地稀缺，智能农业至关重要。扩散模型作为一种新兴的生成模型，在农业图像处理、数据增强和遥感中表现出色，优于GANs，能有效解决数据稀缺和样本不平衡问题。研究表明，扩散模型显著提升了农业应用中数据增强、图像生成和去噪的精度与鲁棒性。尽管存在计算效率和泛化能力挑战，扩散模型预计将在智能和精准农业中发挥关键作用，支持全球农业可持续发展。

> **摘要翻译:** 随着全球人口增长和耕地资源日益稀缺，智能农业和精准农业已成为未来农业发展的关键方向。人工智能（AI）技术，特别是深度学习模型，已在作物监测和病虫害检测等领域得到广泛应用。作为一种新兴的生成模型，扩散模型在农业图像处理、数据增强和遥感等任务中展现出巨大潜力。与传统的生成对抗网络（GANs）相比，扩散模型提供了卓越的训练稳定性和生成质量，有效解决了农业数据有限和图像样本不平衡等挑战。本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。实验结果表明，扩散模型在数据增强、图像生成和去噪方面显著提高了模型精度和鲁棒性，尤其是在复杂环境中。尽管面临计算效率和泛化能力方面的挑战，但随着技术进步，扩散模型有望在智能和精准农业中发挥越来越重要的作用，为全球农业的可持续发展提供实质性支持。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [148] [Wasserstein GAN-Based Precipitation Downscaling with Optimal Transport for Enhancing Perceptual Realism](https://arxiv.org/abs/2507.17798)
> *基于 Wasserstein GAN 和最优传输的降水降尺度，以增强感知真实感*

*Kenta Shiraishi, Yuka Muto, Atsushi Okazaki, Shunji Kotsuki* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** Wasserstein GAN, 降水降尺度, 最优传输, 感知真实感, 质量控制

**Comment:** 

> **TL;DR:** 本研究提出使用 Wasserstein GAN 结合最优传输进行降水降尺度，生成视觉上更真实的精细尺度降水场，并且其判别器有助于识别不真实输出和参考数据中的潜在伪影，为降水数据集的评估和质量控制提供新视角。

**AI_Comments:** 该论文的创新之处在于将 Wasserstein GAN 与最优传输应用于降水降尺度，以提升生成结果的感知真实感，这与传统侧重于数值准确性的方法形成对比。此外，利用 WGAN 的判别器不仅作为训练的一部分，还作为评估工具来识别数据中的伪影，这为数据集的质量控制提供了一个新颖且实用的视角。论文也提到了其在传统评估指标上表现略低，这可能是未来研究需要平衡的方面。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率降水预测对于减少局部强降雨造成的损害至关重要，但使用传统的基于过程的数值天气预报模型进行高分辨率降水预报仍然具有挑战性。

**Method:** 本研究提出使用 Wasserstein 生成对抗网络（WGAN）结合最优传输成本进行降水降尺度。

**Result:** 与使用均方误差训练的传统神经网络相比，WGAN 生成了视觉上更真实的精细尺度降水场，尽管在传统评估指标上表现略低。WGAN 学习到的判别器与人类感知真实感高度相关。案例分析表明，判别器评分的巨大差异有助于识别不真实的 WGAN 输出以及参考数据中潜在的伪影。

**Conclusion:** 这些发现表明，WGAN 框架不仅提高了降水降尺度的感知真实感，而且为评估和质量控制降水数据集提供了新的视角。

> **ai_Abstract:** 本研究提出了一种基于 Wasserstein 生成对抗网络（WGAN）并结合最优传输成本的降水降尺度方法。该方法与传统的基于均方误差训练的神经网络不同，能够生成视觉上更真实的精细尺度降水场，尽管在传统量化指标上可能略有不足。研究发现 WGAN 的判别器与人类对真实感的感知高度相关，并且判别器评分的显著差异可用于识别不真实的模型输出以及参考数据中的潜在缺陷。这表明 WGAN 框架不仅能提升降水降尺度的感知真实感，还能为降水数据集的评估和质量控制提供新的视角。

> **摘要翻译:** 高分辨率（HR）降水预测对于减少局部和局地强降雨造成的损害至关重要；然而，使用基于过程的数值天气预报模型进行高分辨率降水预报仍然具有挑战性。本研究提出使用 Wasserstein 生成对抗网络（WGAN）结合最优传输成本进行降水降尺度。与使用均方误差训练的传统神经网络相比，WGAN 生成了视觉上更真实的精细尺度降水场，尽管 WGAN 在传统评估指标上表现略低。WGAN 学习到的判别器与人类感知真实感高度相关。基于案例的分析表明，判别器评分的巨大差异有助于识别不真实的 WGAN 输出以及参考数据中潜在的伪影。这些发现表明，WGAN 框架不仅提高了降水降尺度的感知真实感，而且为评估和质量控制降水数据集提供了新的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [152] [Zeroth-Order Fine-Tuning of LLMs in Random Subspaces](https://arxiv.org/abs/2410.08989)
> *随机子空间中LLMs的零阶微调*

*Ziming Yu, Pan Zhou, Sike Wang, Jia Li, Mi Tian, Hua Huang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 零阶优化, 大型语言模型, 微调, 随机子空间, 低秩扰动

**Comment:** ICCV 2025 camera-ready version

> **TL;DR:** 针对LLM微调中反向传播内存消耗大的问题，本论文提出SubZero，一种零阶优化方法，通过低秩扰动在随机子空间中进行梯度估计，显著降低内存并提高性能，且收敛更快。

**AI_Comments:** 这篇论文的创新点在于提出了SubZero方法，通过在随机子空间中引入低秩扰动来解决LLM零阶优化中梯度估计方差大的核心问题，同时显著降低了内存消耗。这对于LLM的实际应用和部署具有重要意义，尤其是在资源受限的环境下。其理论证明和实验结果也支持了方法的有效性，为LLM的高效微调提供了一条新途径。

<details>
  <summary>Details</summary>

**Motivation:** 传统LLM微调中的反向传播需要大量内存，而零阶优化虽节省内存但梯度估计方差大，尤其对于高维LLM而言问题更严重。

**Method:** 提出随机子空间零阶优化（SubZero）方法。该方法引入了针对LLM的低秩扰动，用于估计梯度。理论上证明其梯度估计接近反向传播梯度，方差低于传统零阶方法，并确保与SGD结合时的收敛性。

**Result:** 实验结果表明，SubZero在各种语言建模任务中，相比于MeZO等标准零阶方法，能提升微调性能并实现更快的收敛。

**Conclusion:** SubZero成功解决了LLM微调中零阶优化的内存和方差问题，提供了一种高效且性能优越的替代方案。

> **ai_Abstract:** 本文提出了随机子空间零阶优化（SubZero），旨在解决大型语言模型（LLM）微调中反向传播的内存瓶颈和传统零阶优化方法梯度估计方差大的问题。SubZero通过引入低秩扰动，在保留梯度估计准确性的同时显著降低内存消耗并提高训练性能。理论分析表明其梯度估计更接近反向传播且方差更低，并保证收敛。实验证明SubZero在多个语言任务上优于现有零阶方法，实现了更优的微调效果和更快的收敛速度。

> **摘要翻译:** 微调大型语言模型（LLM）已被证明对各种下游任务有效。然而，随着LLM规模的增长，反向传播的内存需求变得越来越高昂。零阶（ZO）优化方法通过使用前向传播来估计梯度，提供了一种内存高效的替代方案，但梯度估计的方差通常与模型的参数维度呈线性关系——这对LLM来说是一个显著问题。在本文中，我们提出了随机子空间零阶（SubZero）优化来解决LLM高维度带来的挑战。我们引入了一种专为LLM设计的低秩扰动，它显著降低了内存消耗，同时提高了训练性能。此外，我们证明了我们的梯度估计与反向传播梯度非常接近，比传统ZO方法具有更低的方差，并确保与SGD结合时的收敛性。实验结果表明，与MeZO等标准ZO方法相比，SubZero在各种语言建模任务中增强了微调性能并实现了更快的收敛。代码可在https://github.com/zimingyy/SubZero获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [157] [Analyzing Fairness of Computer Vision and Natural Language Processing Models](https://arxiv.org/abs/2412.09900)
> *计算机视觉和自然语言处理模型公平性分析*

*Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-23**

**Keywords:** 公平性, 偏见缓解, 计算机视觉, 自然语言处理, 机器学习

**Comment:** 25 pages, 8 table, 11 figures

> **TL;DR:** 本研究利用Fairlearn和AIF360两大公平性库，对计算机视觉和自然语言处理模型中的偏见进行评估和缓解。研究发现，在机器学习生命周期中，顺序应用偏见缓解算法可以有效减少偏见并保持模型性能。

**AI_Comments:** 本研究的创新点在于对两个主流公平性库（Fairlearn和AIF360）的比较分析，并探索了在机器学习生命周期不同阶段（预处理、处理中、后处理）顺序应用偏见缓解算法的有效性。这对于解决实际应用中机器学习模型的公平性问题具有重要意义，尤其是在处理非结构化数据和关键决策领域。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习算法在医疗、金融、教育和执法等多个领域扮演着关键决策角色。然而，这些系统中的公平性和偏见问题引发了重大的伦理和社会挑战，本研究旨在解决这些挑战。

**Method:** 本研究利用微软的Fairlearn和IBM的AIF360两个主要公平性库，专注于使用计算机视觉（CV）和自然语言处理（NLP）模型评估和缓解非结构化数据集的偏见。研究方法包括在机器学习生命周期的预处理、处理中或后处理阶段单独应用缓解算法，以及跨多个阶段顺序应用。研究使用了Kaggle上公开可用的数据集。

**Result:** 研究结果表明，某些顺序应用的偏见缓解算法能够有效减少偏见，同时保持模型的性能。

**Conclusion:** 通过对Fairlearn和AIF360库中偏见缓解算法的比较分析，证明了在机器学习生命周期中顺序应用这些算法能够有效提升偏见缓解效果，同时不损害模型性能。

> **ai_Abstract:** 本研究旨在解决机器学习模型（特别是计算机视觉和自然语言处理模型）中存在的公平性和偏见问题。通过使用微软的Fairlearn和IBM的AIF360两大公平性库，研究对非结构化数据集的偏见进行了评估和缓解。论文比较分析了这些库中缓解算法的性能，包括在机器学习生命周期的不同阶段单独或顺序应用。研究发现，顺序应用偏见缓解算法能有效减少偏见并维持模型性能，为现实世界机器学习工作流中的公平性评估提供了实用见解。

> **摘要翻译:** 机器学习（ML）算法在医疗、金融、教育和执法等各个领域的决策中扮演着关键角色。然而，这些系统中的公平性和偏见问题引发了重大的伦理和社会挑战。为了应对这些挑战，本研究利用了微软的Fairlearn和IBM的AIF360这两个著名的公平性库。这些库提供了全面的公平性分析框架，提供评估公平性指标、可视化结果和实施偏见缓解算法的工具。本研究侧重于使用计算机视觉（CV）和自然语言处理（NLP）模型评估和缓解非结构化数据集的偏见。主要目标是比较分析来自两个公平性库的缓解算法的性能。此分析涉及在机器学习生命周期的一个阶段（预处理、处理中或后处理）单独应用算法，以及跨多个阶段顺序应用。结果显示，一些顺序应用通过有效减少偏见，同时保持模型性能，从而提高了缓解算法的性能。本研究选择了Kaggle上公开可用的数据集，为评估现实世界机器学习工作流中的公平性提供了实践背景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [170] [Multi-Model Ensemble and Reservoir Computing for River Discharge Prediction in Ungauged Basins](https://arxiv.org/abs/2507.18423)
> *多模型集成与水库计算在无测站流域河流流量预测中的应用*

*Mizuki Funato, Yohei Sawada* | **Category: cs.LG, physics.geo-ph** | **Updated: 2025-07-24**

**Keywords:** 河流流量预测, 无测站流域, 多模型集成, 水库计算, 水文模型

**Comment:** 

> **TL;DR:** 一种结合多模型集成和水库计算的新方法HYPER，为无测站流域的河流流量预测提供了鲁棒、高效且可泛化的解决方案，尤其在数据稀缺条件下表现优异。

**AI_Comments:** 该研究的创新之处在于将多模型集成（尤其是对未校准模型的贝叶斯平均）与水库计算相结合进行偏差校正，有效地解决了无测站流域和数据稀缺条件下的河流流量预测难题。其在数据稀缺情景下表现出的鲁棒性和显著的计算效率优势是其重要性所在，特别是无需对单个水文模型进行校准，大大简化了应用流程。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对准确的洪水预测和水资源管理需求迫切，但许多地区缺乏足够的河流流量观测数据，这限制了降雨-径流分析的准确性。在数据稀缺条件下，实现高精度、可解释性和计算效率仍然是一个重大挑战。

**Method:** 本文提出了一种名为HYPER（基于多模型集成和水库计算的水文预测）的新方法。该方法首先对43个“未校准”的流域概念性水文模型应用贝叶斯模型平均（BMA）。然后，通过线性回归训练一个水库计算（RC）模型来校正BMA输出中的误差，这是一个非迭代过程，确保了高计算效率。对于无测站流域，通过将所需BMA和RC权重与有测站流域的流域属性关联起来，推断出这些权重，从而创建了一个可泛化的框架。

**Result:** 使用日本87个河流流域的数据对HYPER进行了评估。在数据充足的情况下，HYPER（中位KGE为0.56）表现与基准LSTM（KGE为0.55）相当，但计算时间仅为后者的5%。在数据稀缺的情况下（23%的流域有测站），HYPER保持了稳健的性能（KGE为0.55）和较低的不确定性，而LSTM的性能显著下降（KGE为-0.04）。这些结果表明，当组装一个有效的大型集成并结合基于机器学习的偏差校正时，单个概念性水文模型不一定需要校准。

**Conclusion:** HYPER为流量预测提供了一个鲁棒、高效且可泛化的解决方案，特别适用于无测站流域，使其可应用于广泛的区域。

> **ai_Abstract:** HYPER是一种结合多模型集成（通过贝叶斯模型平均）和水库计算的新型方法，旨在解决数据稀缺条件下河流流量预测的挑战。该方法首先对大量未校准的水文模型进行集成，然后使用水库计算模型对集成结果进行误差校正。为适应无测站流域，通过有测站流域的流域属性推断模型权重。在日本87个流域的评估显示，HYPER在数据充足时与LSTM性能相当但计算效率更高，在数据稀缺时性能显著优于LSTM，且无需单独校准水文模型。这为无测站流域的流量预测提供了鲁棒、高效且可泛化的解决方案。

> **摘要翻译:** 尽管对准确的洪水预测和水资源管理需求迫切，但许多地区缺乏足够的河流流量观测数据，这限制了降雨-径流分析的能力。虽然存在大量的物理模型和机器学习模型，但在数据稀缺条件下实现高精度、可解释性和计算效率仍然是一个重大挑战。我们通过一种新颖的方法——基于多模型集成和水库计算的水文预测（HYPER）来应对这一挑战，该方法利用了多模型集成和水库计算（RC）。我们的方法首先对43个“未校准”的流域概念性水文模型应用贝叶斯模型平均（BMA）。然后，通过线性回归训练一个RC模型来校正BMA输出中的误差，这是一个非迭代过程，确保了高计算效率。对于无测站流域，我们通过将所需BMA和RC权重与有测站流域的流域属性关联起来，推断出这些权重，从而创建了一个可泛化的框架。我们使用日本87个河流流域的数据对HYPER进行了评估。在数据充足的情况下，HYPER（中位Kling-Gupta效率KGE为0.56）表现与基准LSTM（KGE为0.55）相当，但计算时间仅为后者的5%。在数据稀缺的情况下（23%的流域有测站），HYPER保持了稳健的性能（KGE为0.55）和较低的不确定性，而LSTM的性能显著下降（KGE为-0.04）。这些结果表明，当组装一个有效的大型集成并结合基于机器学习的偏差校正时，单个概念性水文模型不一定需要校准。HYPER为流量预测提供了一个鲁棒、高效且可泛化的解决方案，特别适用于无测站流域，使其可应用于广泛的区域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [179] [Squeeze10-LLM: Squeezing LLMs' Weights by 10 Times via a Staged Mixed-Precision Quantization Method](https://arxiv.org/abs/2507.18073)
> *Squeeze10-LLM：通过分阶段混合精度量化方法将LLM权重压缩10倍*

*Qingcheng Zhu, Yangyang Ren, Linlin Yang, Mingbao Lin, Yanjing Li, Sheng Xu, Zichao Feng, Haodong Zhu, Yuguang Yang, Juan Zhang, Runqi Wang, Baochang Zhang* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 大语言模型, 量化, 混合精度, 后训练量化, 模型压缩

**Comment:** 

> **TL;DR:** Squeeze10-LLM是一种分阶段混合精度量化方法，能将LLM权重压缩10倍（平均1.6比特），通过PBAR和FIAS创新，显著提升了低比特量化性能。

**AI_Comments:** 这篇论文通过提出Squeeze10-LLM，有效地解决了LLM在进行超低比特量化时性能严重下降的关键问题。其创新点在于采用了分阶段混合精度量化策略，并引入了PBAR和FIAS两个新颖的机制，分别用于优化权重显著性度量和减轻误差累积。这项工作对于LLM的实际部署具有重要意义，因为它显著降低了模型存储和计算成本，同时保持了高精度，推动了LLM在资源受限环境下的应用。

<details>
  <summary>Details</summary>

**Motivation:** 部署大型语言模型（LLMs）面临参数量巨大和计算成本高昂的挑战。超低比特量化可以显著减少存储并加速推理，但极端压缩（平均比特位宽≤2）会导致严重的性能下降。

**Method:** 提出Squeeze10-LLM，一个分阶段混合精度后训练量化（PTQ）框架，旨在将16比特LLM的权重压缩10倍，平均每权重达到1.6比特（80%的权重量化为1比特，20%量化为4比特）。引入了两项关键创新：后二值化激活鲁棒性（PBAR）和全信息激活监督（FIAS）。PBAR是一种改进的权重显著性度量，考虑量化对激活的影响以提高低比特设置下的精度。FIAS是一种在量化过程中保留完整激活信息以减轻跨层累积误差传播的策略。

**Result:** 在LLaMA和LLaMA2上的实验表明，Squeeze10-LLM在低于2比特的仅权重（weight-only）量化方面实现了最先进的性能，在六项零样本分类任务中，平均准确率从43%提高到56%，显著优于现有PTQ方法。

**Conclusion:** Squeeze10-LLM通过其分阶段混合精度量化和创新的PBAR与FIAS机制，有效解决了LLM极端低比特量化中的性能下降问题，实现了显著的准确率提升，为LLM的轻量化部署提供了最先进的解决方案。

> **ai_Abstract:** Squeeze10-LLM是一个创新的分阶段混合精度后训练量化框架，旨在解决大型语言模型（LLM）在极端低比特量化下性能严重下降的问题。该方法通过将16比特LLM权重压缩10倍（平均1.6比特，采用1比特和4比特混合精度），并引入了后二值化激活鲁棒性（PBAR）和全信息激活监督（FIAS）两项关键技术，显著提升了量化精度。实验证明，Squeeze10-LLM在LLaMA和LLaMA2模型上实现了次2比特仅权重（weight-only）量化的最先进性能，将零样本分类任务的平均准确率从43%提高到56%。

> **摘要翻译:** 部署大型语言模型（LLM）因其庞大的参数量和高昂的计算成本而面临挑战。超低比特量化可以显著减少存储并加速推理，但极端压缩（即平均比特位宽≤2）通常会导致严重的性能下降。为了解决这个问题，我们提出了Squeeze10-LLM，有效地将16比特LLM的权重压缩10倍。具体来说，Squeeze10-LLM是一个分阶段混合精度后训练量化（PTQ）框架，通过将80%的权重量化为1比特，20%量化为4比特，实现了平均每权重1.6比特。我们引入Squeeze10LLM，具有两项关键创新：后二值化激活鲁棒性（PBAR）和全信息激活监督（FIAS）。PBAR是一种改进的权重显著性度量，它考虑了量化对激活的影响，从而提高了低比特设置下的精度。FIAS是一种在量化过程中保留完整激活信息以减轻跨层累积误差传播的策略。在LLaMA和LLaMA2上的实验表明，Squeeze10-LLM在低于2比特的仅权重（weight-only）量化方面实现了最先进的性能，在六项零样本分类任务中，平均准确率从43%提高到56%——比现有PTQ方法有了显著提升。我们的代码将在发布后提供。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [182] [History-Guided Video Diffusion](https://arxiv.org/abs/2502.06764)
> *历史引导的视频扩散*

*Kiwhan Song, Boyuan Chen, Max Simchowitz, Yilun Du, Russ Tedrake, Vincent Sitzmann* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视频扩散, 历史引导, DFoT, 分类器自由引导, 时间一致性

**Comment:** ICML 2025. Project website: https://boyuan.space/history-guidance

> **TL;DR:** 该论文提出了Diffusion Forcing Transformer (DFoT)架构和History Guidance方法，以解决视频扩散模型中可变长度历史条件化的挑战，显著提高了视频生成质量和时间一致性。

**AI_Comments:** 该论文的创新点在于提出了DFoT架构和History Guidance方法，有效解决了视频扩散中长期存在的对可变长度历史进行条件化的难题。通过理论和实验验证，其方法在提升视频生成质量、时间一致性、运动动力学以及支持超长视频生成方面取得了显著进展，为视频扩散领域提供了一个重要且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 分类器自由引导（CFG）是扩散模型中改善条件生成的重要技术。将其扩展到视频扩散（根据可变数量的历史帧生成视频）时，面临两个关键挑战：架构仅支持固定大小的条件化，以及CFG风格的历史丢弃表现不佳。

**Method:** 提出Diffusion Forcing Transformer (DFoT)，这是一种视频扩散架构和理论基础的训练目标，共同实现对灵活数量的历史帧进行条件化。然后引入History Guidance，这是一系列由DFoT独特实现的引导方法。

**Result:** 最简单的形式，香草历史引导，已经显著提高了视频生成质量和时间一致性。更高级的方法，跨时间和频率的历史引导，进一步增强了运动动力学，实现了对分布外历史的组合泛化，并且可以稳定地生成极长视频。

**Conclusion:** 论文通过提出DFoT架构和History Guidance方法，成功解决了视频扩散中可变长度历史条件化的挑战，显著提升了视频生成质量、时间一致性、运动动力学和泛化能力。

> **ai_Abstract:** 本文针对视频扩散中可变长度历史条件化的挑战，提出了Diffusion Forcing Transformer (DFoT)架构及其训练目标，以支持灵活的历史帧条件化。在此基础上，引入了History Guidance系列方法，其中简单的历史引导已能显著提升视频生成质量和时间一致性，而高级方法进一步增强运动动力学，实现组合泛化，并支持超长视频的稳定生成。

> **摘要翻译:** 分类器自由引导（CFG）是扩散模型中改善条件生成的关键技术，能够实现更精确的控制同时提高样本质量。将此技术扩展到视频扩散是很自然的，视频扩散根据可变数量的上下文帧（统称为历史）生成视频。然而，我们发现使用可变长度历史进行引导存在两个关键挑战：架构仅支持固定大小的条件化，以及经验观察到CFG风格的历史丢弃表现不佳。为了解决这个问题，我们提出了Diffusion Forcing Transformer (DFoT)，这是一种视频扩散架构和理论基础的训练目标，共同实现对灵活数量的历史帧进行条件化。然后我们引入了History Guidance，这是一系列由DFoT独特实现的引导方法。我们展示了其最简单的形式，香草历史引导，已经显著提高了视频生成质量和时间一致性。更高级的方法，跨时间和频率的历史引导，进一步增强了运动动力学，实现了对分布外历史的组合泛化，并且可以稳定地生成极长视频。项目网站：https://boyuan.space/history-guidance

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [188] [Explainable Graph Neural Networks via Structural Externalities](https://arxiv.org/abs/2507.17848)
> *通过结构外部性实现可解释图神经网络*

*Lijun Wu, Dong Hao, Zhiyi Fan* | **Category: cs.LG, cs.AI, cs.GT, econ.GN, q-fin.EC** | **Updated: 2025-07-19**

**Keywords:** 图神经网络, 可解释性, 结构外部性, 合作博弈论, Shapley值

**Comment:** 

> **TL;DR:** 本文提出了一种名为GraphEXT的新型可解释性框架，它利用合作博弈论和结构外部性来解释图神经网络（GNN），通过量化节点对GNN预测的边际贡献来增强可解释性，并在实验中表现优于现有基线方法。

**AI_Comments:** 本文的创新点在于将合作博弈论中的外部性概念引入到图神经网络的可解释性中，特别是通过Shapley值来量化结构变化对GNN预测的影响，而非仅仅关注节点属性。这为理解GNN的复杂交互模式提供了一个新颖的视角，对于提高GNN的透明度和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNN）在各种图相关任务中取得了出色的性能，但其“黑盒”性质带来了可解释性的巨大挑战。现有方法往往无法有效捕获网络中节点之间复杂的交互模式。

**Method:** 本文提出了一种名为GraphEXT的新型可解释性框架，该框架利用合作博弈论和社会外部性概念。GraphEXT将图节点划分为联盟，将原始图分解为独立的子图。通过将图结构作为外部性，并结合外部性下的Shapley值，GraphEXT通过节点在联盟之间转换时对GNN预测的边际贡献来量化节点的重要性。与传统基于Shapley值的方法主要关注节点属性不同，GraphEXT更强调节点之间的交互以及结构变化对GNN预测的影响。

**Result:** 在合成数据集和真实世界数据集上的实验研究表明，GraphEXT在各种GNN架构下的保真度方面优于现有基线方法。

**Conclusion:** GraphEXT显著增强了GNN模型的可解释性。

> **ai_Abstract:** 本文提出了一种名为GraphEXT的新型框架，旨在解决图神经网络（GNN）的“黑盒”问题。GraphEXT利用合作博弈论和结构外部性的概念，通过将图节点划分为联盟并分解为独立子图，并结合外部性下的Shapley值，来量化节点对GNN预测的边际贡献，从而揭示节点重要性。与传统方法不同，GraphEXT更侧重于节点间的交互和结构变化的影响。实验结果表明，GraphEXT在可解释性保真度方面优于现有基线方法，显著提升了GNN模型的可解释性。

> **摘要翻译:** 图神经网络（GNN）在各种图相关任务中取得了出色的性能。然而，它们的“黑盒”性质对其可解释性构成了重大挑战，现有方法往往无法有效捕获网络中节点之间复杂的交互模式。在这项工作中，我们提出了一种新颖的可解释性框架GraphEXT，它利用合作博弈论和社会外部性概念。GraphEXT将图节点划分为联盟，将原始图分解为独立的子图。通过将图结构作为外部性并结合外部性下的Shapley值，GraphEXT通过节点在联盟之间转换时对GNN预测的边际贡献来量化节点的重要性。与传统基于Shapley值的方法主要关注节点属性不同，我们的GraphEXT更强调节点之间的交互以及结构变化对GNN预测的影响。在合成数据集和真实世界数据集上的实验研究表明，GraphEXT在各种GNN架构下的保真度方面优于现有基线方法，显著增强了GNN模型的可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [200] [Revisiting Bisimulation Metric for Robust Representations in Reinforcement Learning](https://arxiv.org/abs/2507.18519)
> *重新审视强化学习中鲁棒表示的双模拟度量*

*Leiji Zhang, Zeyu Wang, Xin Li, Yao-Hui Li* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 双模拟度量, 强化学习, 表示学习, 自适应系数, 奖励差距

**Comment:** 

> **TL;DR:** 本文指出了传统双模拟度量存在的两个主要问题（无法表示独特场景和依赖预定义权重），并提出了一种修正的双模拟度量，该度量具有更精确的奖励差距定义和自适应更新算子，并通过理论和实验证明了其有效性。

**AI_Comments:** 该论文解决了强化学习表示学习中广泛使用的双模拟度量存在的关键局限性。引入自适应系数和更精确的奖励差距定义是实现更鲁棒和灵活表示的创新步骤。理论保证与实证验证相结合，增强了其贡献。

<details>
  <summary>Details</summary>

**Motivation:** 传统的双模拟度量存在两个主要问题：1）无法表示某些独特的场景，这源于奖励差距定义的不精确；2）在递归更新过程中依赖预定义的奖励和后续状态差异的权重，忽略了这些差异在不同训练阶段和任务设置中的不同重要性。

**Method:** 本文通过引入一种状态-动作对的度量，提出了一种修正的双模拟度量。该度量具有更精确的奖励差距定义和带有自适应系数的新型更新算子。作者还提供了所提出度量的收敛性和改进表示区分度的理论保证。

**Result:** 在DeepMind Control和Meta-World这两个代表性基准上进行了广泛的实验，证明了所提出方法的有效性。

**Conclusion:** 本文成功解决了传统双模拟度量在表示能力和权重依赖性方面的问题，通过提出一种修正的、具有理论保证和实验验证的度量，展示了其在强化学习任务中的改进性能。

> **ai_Abstract:** 本文重新审视了强化学习中传统的双模拟度量，指出了其在表示独特场景方面的不足以及对固定权重依赖的问题。为解决这些问题，作者提出了一种修正的双模拟度量，该度量引入了状态-动作对的度量、更精确的奖励差距定义和自适应更新算子。论文提供了理论收敛保证，并通过在DeepMind Control和Meta-World基准上的广泛实验验证了其方法的有效性。

> **摘要翻译:** 双模拟度量长期以来被认为是各种强化学习任务中一种有效的与控制相关的表示学习技术。然而，在本文中，我们发现了传统双模拟度量的两个主要问题：1）无法表示某些独特的场景，以及2）在递归更新过程中依赖预定义的奖励和后续状态差异的权重。我们发现第一个问题源于奖励差距的不精确定义，而第二个问题则源于忽视了不同训练阶段和任务设置中奖励差异和下一状态区分度的不同重要性。为了解决这些问题，通过引入一种状态-动作对的度量，我们提出了一种修正的双模拟度量，其特点是奖励差距的定义更精确，并引入了具有自适应系数的新型更新算子。我们还为我们提出的度量及其改进的表示区分度提供了收敛的理论保证。除了严谨的理论分析外，我们还在两个代表性基准（DeepMind Control 和 Meta-World）上进行了广泛的实验，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [207] [DeepCrossAttention: Supercharging Transformer Residual Connections](https://arxiv.org/abs/2502.06785)
> *深度交叉注意力：增压Transformer残差连接*

*Mike Heddes, Adel Javanmard, Kyriakos Axiotis, Gang Fu, MohammadHossein Bateni, Vahab Mirrokni* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** DeepCrossAttention, Transformer, 残差连接, 语言建模, 困惑度

**Comment:** 

> **TL;DR:** DeepCrossAttention (DCA) 通过引入可学习的输入依赖权重和深度交叉注意力来增强Transformer的残差连接，从而提高模型性能、训练速度，并优化准确性与模型尺寸的权衡，同时只增加可忽略的参数量。

**AI_Comments:** DeepCrossAttention (DCA) 的创新之处在于其动态权重分配和深度交叉注意力的引入，这使得Transformer的残差连接能够更智能地处理信息。其重要性体现在能在不显著增加模型复杂度的前提下，显著提升训练效率和模型性能。这项工作为Transformer架构的进一步优化提供了有价值的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Transformer残差连接通过简单地叠加前一层的输出，可能会稀释关键信息，导致模型无法有效利用所有相关信息。

**Method:** 本文引入了DeepCrossAttention (DCA)。DCA采用可学习的、依赖于输入的权重来动态组合层输出，使模型能够选择性地关注之前层中最相关的信息。此外，DCA还结合了深度交叉注意力，以实现不同深度层之间更丰富的交互。

**Result:** 语言建模实验表明，在给定训练时间下，DCA能提高困惑度。此外，DCA在达到相同模型质量的情况下，速度提升高达3倍，同时只增加了可忽略的参数数量。理论分析证实，当集体层秩与环境维度之比低于临界阈值时，DCA在准确性和模型尺寸之间提供了更好的权衡。

**Conclusion:** DeepCrossAttention (DCA) 通过改进Transformer的残差连接，实现了性能提升和训练加速，并在理论上优化了准确性与模型尺寸的权衡。

> **ai_Abstract:** 本文提出了DeepCrossAttention (DCA)，旨在改进Transformer网络中传统残差连接可能导致信息稀释的问题。DCA通过使用可学习的、依赖输入的权重动态组合层输出，并结合深度交叉注意力，使模型能够选择性地关注关键信息并增强层间交互。实验证明，DCA在语言建模任务中提升了困惑度性能，在相同模型质量下训练速度最高可达3倍，且参数量增加可忽略不计。理论分析进一步证实，DCA在特定条件下能优化准确性与模型尺寸的权衡。

> **摘要翻译:** Transformer网络在各个领域取得了显著成功，这得益于包括残差连接在内的各种架构创新。然而，传统的残差连接仅简单地叠加前一层的输出，可能会稀释关键信息。这项工作引入了DeepCrossAttention (DCA)，这是一种增强Transformer中残差学习的方法。DCA采用可学习的、依赖于输入的权重来动态组合层输出，使模型能够选择性地关注之前层中最相关的信息。此外，DCA还结合了深度交叉注意力，以实现不同深度层之间更丰富的交互。我们的语言建模实验表明，在给定训练时间下，DCA能提高困惑度。此外，DCA在达到相同模型质量的情况下，速度提升高达3倍，同时只增加了可忽略的参数数量。理论分析证实，当集体层秩与环境维度之比低于临界阈值时，DCA在准确性和模型尺寸之间提供了更好的权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [208] [LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs](https://arxiv.org/abs/2506.15690)
> *LLM网络动态：追踪LLM网络中的模型崩溃*

*Tianyu Wang, Akira Horiguchi, Lingyou Pang, Carey E. Priebe* | **Category: cs.LG, cs.AI, cs.SI, stat.ME** | **Updated: 2025-07-24**

**Keywords:** LLM, 模型崩溃, 网络动态, RAG, 理论保证

**Comment:** 

> **TL;DR:** 本文引入LLM Web Dynamics (LWD)框架，通过模拟互联网环境，在网络层面研究大型语言模型（LLM）的模型崩溃问题，并提供理论保证。

**AI_Comments:** 本文的创新点在于提出了LLM Web Dynamics (LWD)框架，首次在网络层面而非单一模型设置下研究LLM的模型崩溃问题，并通过模拟互联网环境和提供理论保证，为理解和解决LLM在复杂网络环境中的稳定性问题提供了新视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管利用互联网合成数据提高了LLM训练效率，但模型崩溃的潜在威胁尚未得到充分探索，现有研究主要局限于单一模型或统计替代方法。

**Method:** 提出LLM Web Dynamics (LWD)框架，通过RAG数据库模拟互联网环境来调查模型崩溃；分析模型输出的收敛模式；通过类比交互式高斯混合模型提供收敛的理论保证。

**Result:** 分析了模型输出的收敛模式，并提供了收敛的理论保证。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对现有研究未能充分探索LLM模型崩溃在网络层面的问题，特别是当模型使用互联网合成数据时。为此，提出了LLM Web Dynamics (LWD)框架，该框架通过RAG数据库模拟互联网环境，以分析LLM网络中模型输出的收敛模式，并提供了基于高斯混合模型类比的理论保证，旨在深入理解和追踪网络化LLM中的模型崩溃现象。

> **摘要翻译:** 随着公共互联网合成数据的使用日益增加，大型语言模型（LLM）训练中的数据使用效率得到了提升。然而，模型崩溃的潜在威胁仍未得到充分探索。现有研究主要在单一模型设置下检查模型崩溃，或仅依赖统计替代物。在这项工作中，我们引入了LLM Web Dynamics (LWD)，一个用于在网络层面研究模型崩溃的有效框架。通过使用检索增强生成（RAG）数据库模拟互联网，我们分析了模型输出的收敛模式。此外，通过类比交互式高斯混合模型，我们为这种收敛提供了理论保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [223] [Look the Other Way: Designing 'Positive' Molecules with Negative Data via Task Arithmetic](https://arxiv.org/abs/2507.17876)
> *另辟蹊径：通过任务算术利用负面数据设计“阳性”分子*

*Rıza Özçelik, Sarah de Ruiter, Francesca Grisoni* | **Category: cs.LG, q-bio.BM** | **Updated: 2025-07-23**

**Keywords:** 分子设计, 任务算术, 负面数据, 零样本学习, 迁移学习

**Comment:** 

> **TL;DR:** 通过任务算术，利用大量负面数据训练模型来学习“属性方向”，然后反向操作以生成具有所需特性的“阳性”分子，从而解决阳性分子稀缺问题。

**AI_Comments:** 这篇论文通过“分子任务算术”提供了一种创新性的方法，解决了生成式分子设计中阳性数据稀缺的根本性问题。其核心思想是利用“负面数据”来推断“积极方向”，这是一种反直觉但非常有效的方法。通过零样本和少样本实验证明了其在多样性和成功率方面的优越性，这对于药物发现和材料科学等领域具有重要意义。该方法的简单性、数据效率和高性能是其主要优势，使其具有成为行业标准的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 具有理想特性的分子（即“阳性”分子）的稀缺性是生成式分子设计的固有瓶颈。

**Method:** 提出分子任务算术方法。该方法通过在多样且丰富的负面示例上训练模型，学习“属性方向”，无需访问任何阳性标记数据，然后沿相反的属性方向移动模型以生成阳性分子。

**Result:** 在20项零样本设计实验中，分子任务算术生成了比在阳性分子上训练的模型更多样化和更成功的设计。此外，在双目标和少样本设计任务中，分子任务算术能持续增加设计的多样性，同时保持理想的设计特性。

**Conclusion:** 分子任务算术以其简单性、数据效率和性能，有望成为从头分子设计的实际迁移学习策略。

> **ai_Abstract:** 本文提出了一种名为“分子任务算术”的新方法，旨在解决生成式分子设计中阳性分子数据稀缺的问题。该方法通过在大量负面示例上训练模型来学习属性方向，然后反向操作以生成具有所需特性的分子，无需阳性数据。实验结果表明，该方法在零样本、双目标和少样本设计任务中，比传统方法能生成更具多样性和成功率的分子，且保持了期望的特性。其简单、数据高效和高性能使其有望成为从头分子设计的标准迁移学习策略。

> **摘要翻译:** 具有理想特性（即“阳性”分子）的分子稀缺性是生成式分子设计的固有瓶颈。为了规避这一障碍，我们在此提出分子任务算术：在多样且丰富的负面示例上训练模型以学习“属性方向”——无需访问任何阳性标记数据——然后将模型沿相反的属性方向移动以生成阳性分子。在20项零样本设计实验中分析时，分子任务算术生成了比在阳性分子上训练的模型更多样化和更成功的设计。此外，我们将分子任务算术应用于双目标和少样本设计任务。我们发现分子任务算术能够持续增加设计的多样性，同时保持理想的设计特性。凭借其简单性、数据效率和性能，分子任务算术有望成为从头分子设计的实际迁移学习策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [224] [Learning from Hard Labels with Additional Supervision on Non-Hard-Labeled Classes](https://arxiv.org/abs/2507.18098)
> *从硬标签和非硬标签类别的额外监督中学习*

*Kosuke Sugiyama, Masato Uchida* | **Category: cs.LG, 68T01, I.5** | **Updated: 2025-07-24**

**Keywords:** 额外监督, 硬标签, 软标签, 泛化误差, 分类模型

**Comment:** 32 pages, 11 figures

> **TL;DR:** 本文提出一个理论框架，将硬标签和额外监督视为概率分布，通过仿射组合构建软标签，并理论和实验证明了非硬标签类别上的额外监督对提高分类模型泛化性能的重要性。

**AI_Comments:** 本文在数据受限的机器学习背景下，深入探讨了额外监督的有效性问题，并提出了一个新颖的理论框架。其创新点在于明确指出非硬标签类别的分布信息才是额外监督的核心价值，而非传统认为的硬标签置信度。这为在数据稀缺场景下如何有效利用辅助信息提供了重要的理论指导和实践方向，有助于设计更高效的弱监督学习方法。

<details>
  <summary>Details</summary>

**Motivation:** 在训练数据有限的情况下（由于观测成本高或数据稀缺），为了构建高精度分类模型，丰富每个实例的标签信息至关重要。在这种背景下，除了硬标签，通常还可以获得额外监督（如硬标签的置信度）。这自然引出了一个基本问题：哪些额外监督本质上是有益的？以及它们如何有助于提高泛化性能？

**Method:** 本文提出了一个理论框架，将硬标签和额外监督都视为概率分布，并通过它们的仿射组合构建软标签。通过泛化误差分析，理论上刻画了额外监督及其混合系数如何影响误差边界的收敛速度和渐近值。

**Result:** 理论分析表明，额外监督的核心组成部分不是指定硬标签的置信度，而是非硬标签类别上的分布信息。此外，额外监督和混合系数在软标签细化中扮演互补角色。直观上，在概率单纯形中，额外监督决定了代表硬标签的确定性分布应向真实标签分布调整的方向，而混合系数控制着沿该方向的步长。实验证明，基于本文理论设计的额外监督即使简单使用也能提高分类准确性。

**Conclusion:** 本文理论揭示了非硬标签类别上的额外监督信息对于提高分类模型泛化性能的关键作用，并提供了如何有效利用这些信息的指导。

> **ai_Abstract:** 本文针对数据稀缺场景下分类模型的训练问题，提出了一种利用硬标签和非硬标签类别额外监督的理论框架。该框架将硬标签和额外监督视为概率分布，并通过仿射组合生成软标签。研究发现，额外监督中关键的是非硬标签类别的分布信息，而非硬标签的置信度。此外，额外监督和混合系数在软标签调整中扮演互补角色，分别控制调整方向和步长。理论分析揭示了它们对泛化误差边界的影响，并通过实验验证了基于该理论设计的额外监督能有效提高分类准确性。

> **摘要翻译:** 在由于观测成本或数据稀缺导致训练数据有限的场景中，丰富与每个实例相关的标签信息对于构建高精度分类模型至关重要。在这种情况下，通常不仅可以获得硬标签，还可以获得额外监督，例如硬标签的置信度。这种设置自然引发了基本问题：哪些额外监督本质上是有益的？以及它们如何有助于提高泛化性能？为了解决这些问题，我们提出了一个理论框架，将硬标签和额外监督都视为概率分布，并通过它们的仿射组合构建软标签。我们的理论分析表明，额外监督的本质组成部分不是指定硬标签的置信度，而是关于非硬标签类别分布的信息。此外，我们证明了额外监督和混合系数在软标签的细化中扮演着互补的角色。直观地说，在概率单纯形中，额外监督决定了表示硬标签的确定性分布应向真实标签分布调整的方向，而混合系数控制着沿该方向的步长。通过泛化误差分析，我们从理论上刻画了额外监督及其混合系数如何影响误差边界的收敛速度和渐近值。最后，我们通过实验证明，基于我们的理论，设计额外监督可以提高分类精度，即使以简单的方式使用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [230] [GLANCE: Graph Logic Attention Network with Cluster Enhancement for Heterophilous Graph Representation Learning](https://arxiv.org/abs/2507.18521)
> *GLANCE：用于异质图表示学习的图逻辑注意力网络与聚类增强*

*Zhongtian Sun, Anoushka Harit, Alexandra Cristea, Christl A. Donnelly, Pietro Liò* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 异质图, 图神经网络, 图表示学习, 注意力机制, 聚类增强

**Comment:** 

> **TL;DR:** GLANCE是一种新的图神经网络框架，通过结合逻辑推理、动态图细化和自适应聚类，解决了传统GNN在异质图上表现不佳的问题，实现了有竞争力的性能。

**AI_Comments:** GLANCE的创新点在于其多组件集成设计，特别是结合了逻辑推理、动态图细化（通过边剪枝）和自适应聚类，以专门解决异质图的挑战。这种方法不仅提升了性能，还强调了可解释性，这在复杂的图学习模型中尤为重要。其轻量级和适应性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的图神经网络（GNNs）在异质图上表现不佳，因为它们在聚合邻居时缺乏区分性，并且未能充分利用高阶结构模式。

**Method:** 本文提出了GLANCE（Graph Logic Attention Network with Cluster Enhancement）框架。GLANCE结合了逻辑层以生成可解释的结构化嵌入，使用多头注意力机制进行边剪枝以去噪图结构，并利用聚类机制来捕获全局模式。

**Result:** 在Cornell、Texas和Wisconsin等基准数据集上的实验结果表明，GLANCE实现了有竞争力的性能，为异质图场景提供了鲁棒且可解释的解决方案。

**Conclusion:** GLANCE框架通过集成逻辑引导推理、动态图细化和自适应聚类，有效地解决了异质图表示学习中的挑战，提供了一个轻量、适应性强且性能优越的解决方案。

> **ai_Abstract:** GLANCE是一种针对异质图表示学习提出的新型图神经网络框架，旨在解决传统GNN在处理异质图时因无差别邻居聚合和高阶结构利用不足而导致的性能下降问题。该框架通过结合逻辑层、基于多头注意力的边剪枝和聚类机制，实现了可解释的结构化嵌入、图结构去噪和全局模式捕获。实验证明GLANCE在多个基准数据集上表现出竞争力，为异质图提供了鲁棒且可解释的解决方案。

> **摘要翻译:** 图神经网络（GNNs）在从图结构数据中学习方面取得了显著成功，但在异质图上常常表现不佳，即连接节点在特征或类别标签上存在差异。这种局限性源于无差别地聚合邻居以及对高阶结构模式的整合不足。为了解决这些挑战，我们提出了GLANCE（Graph Logic Attention Network with Cluster Enhancement），这是一个新颖的框架，它集成了逻辑引导推理、动态图细化和自适应聚类，以增强图表示学习。GLANCE结合了一个用于可解释和结构化嵌入的逻辑层、用于去噪图结构的多头注意力机制的边剪枝，以及用于捕获全局模式的聚类机制。在Cornell、Texas和Wisconsin等基准数据集上的实验结果表明，GLANCE实现了有竞争力的性能，为异质图场景提供了鲁棒且可解释的解决方案。所提出的框架轻量、适应性强，并且独特地适用于异质图的挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [232] [A general language model for peptide identification](https://arxiv.org/abs/2502.15610)
> *肽鉴定的通用语言模型*

*Jixiu Zhai, Tianchi Lu, Haitian Zhong, Ziyang Xu, Yuhuan Liu, Shengrui Xu, Jingwan Wang, Dan Huang* | **Category: cs.LG, cs.AI, 92C40, 68T07, I.2.6; J.3** | **Updated: 2025-07-24**

**Keywords:** 肽鉴定, 深度学习, 语言模型, PTMs, 生物活性肽

**Comment:** 24 pages, 9 figures, 4 tables, submitted to arXiv

> **TL;DR:** PDeepPP是一个统一的深度学习框架，结合了预训练的蛋白质语言模型和混合Transformer-CNN架构，在多种肽类和PTM位点识别任务中实现了最先进的性能。

**AI_Comments:** PDeepPP的创新之处在于其统一的深度学习框架，巧妙地结合了预训练的蛋白质语言模型和混合Transformer-卷积架构，显著提升了肽和PTM识别的通用性和准确性。其在多项生物任务中达到SOTA性能，并提供可解释的肽表示，这对于生物医学研究具有重要意义。此外，代码、数据集和预训练模型的公开可用性大大增强了其可复用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有计算方法在识别生物活性肽（BPs）和蛋白质翻译后修饰（PTMs）方面，其通用性在不同肽功能之间受到限制，而准确识别这些对于理解蛋白质功能和推进治疗发现至关重要。

**Method:** 本文提出了PDeepPP，一个统一的深度学习框架，它集成了预训练的蛋白质语言模型与混合Transformer-卷积架构。研究人员策划了全面的基准数据集，并实施了策略来解决数据不平衡问题，使PDeepPP能够系统地提取全局和局部序列特征。

**Result:** PDeepPP在33项生物识别任务中的25项中表现出强大的、可解释的肽表示并实现了最先进的性能。具体而言，它在抗菌肽识别中达到0.9726的准确率，在磷酸化位点识别中达到0.9984的准确率，在糖基化位点预测中具有99.5%的特异性，并显著减少了抗疟任务中的假阴性。

**Conclusion:** PDeepPP通过实现大规模、准确的肽分析，支持生物医学研究和疾病治疗中新型治疗靶点的发现。

> **ai_Abstract:** PDeepPP是一个创新的深度学习框架，旨在解决现有计算方法在生物活性肽（BPs）和蛋白质翻译后修饰（PTMs）识别方面通用性不足的问题。该模型结合了预训练的蛋白质语言模型和混合Transformer-卷积架构，能够从大规模数据集中提取全局和局部序列特征。PDeepPP在广泛的生物识别任务中展现出卓越的性能，并在25项任务中达到最先进水平，特别是在抗菌肽和磷酸化位点识别中表现出高准确率。该框架通过支持大规模、准确的肽分析，有望加速生物医学研究和新药发现。

> **摘要翻译:** 准确识别生物活性肽（BPs）和蛋白质翻译后修饰（PTMs）对于理解蛋白质功能和推进治疗发现至关重要。然而，大多数计算方法在不同肽功能之间的通用性仍然有限。本文提出了PDeepPP，一个统一的深度学习框架，它集成了预训练的蛋白质语言模型与混合Transformer-卷积架构，从而能够在不同肽类和PTM位点进行鲁棒识别。我们策划了全面的基准数据集，并实施了策略来解决数据不平衡问题，使得PDeepPP能够系统地提取全局和局部序列特征。通过广泛的分析——包括降维和比较研究——PDeepPP展示了强大、可解释的肽表示，并在33项生物识别任务中的25项中实现了最先进的性能。值得注意的是，PDeepPP在抗菌肽（0.9726）和磷酸化位点（0.9984）识别中获得了高准确率，在糖基化位点预测中具有99.5%的特异性，并显著减少了抗疟任务中的假阴性。通过实现大规模、准确的肽分析，PDeepPP支持生物医学研究和疾病治疗中新型治疗靶点的发现。所有代码、数据集和预训练模型均通过GitHub：https://github.com/fondress/PDeepPP 和 Hugging Face：https://huggingface.co/fondress/PDeppPP 公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [251] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
> *扩散模型在数据受限环境下优于自回归模型*

*Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak* | **Category: cs.LG, cs.AI, cs.CV, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 自回归模型, 数据受限, 语言模型, 缩放定律

**Comment:** Project Webpage: https://diffusion-scaling.github.io

> **TL;DR:** 在数据稀缺但计算资源充足的条件下，扩散语言模型显著优于自回归模型，因为它们能更好地利用重复数据并进行隐式数据增强。

**AI_Comments:** 这篇论文创新性地指出了扩散模型在特定资源约束下（数据稀缺、计算充足）的显著优势，挑战了自回归模型在大型语言模型领域的长期主导地位。其对“隐式数据增强”的解释为理解扩散模型的有效性提供了深刻见解。这项工作对于未来根据实际资源瓶颈选择合适的模型范式具有重要指导意义，尤其是在数据获取成本高昂的领域。

<details>
  <summary>Details</summary>

**Motivation:** 自回归（AR）模型长期主导大型语言模型领域，但扩散语言模型作为一种有前景的替代方案，其相对于AR模型的优势尚未被充分探索。本研究旨在系统地探究扩散模型在数据受限环境下的表现。

**Method:** 本研究系统地考察了在数据受限（训练涉及对有限数据进行重复传递）环境下的掩码扩散模型，并与自回归模型进行了比较。研究还发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于自回归模型的临界计算阈值的闭式表达式。

**Result:** 研究发现，当计算资源充足但数据稀缺时，扩散模型显著优于自回归模型。扩散模型能更好地利用重复数据，达到更低的验证损失和更优的下游性能。这种优势被解释为隐式数据增强：掩码扩散模型使模型接触到多样化的词元排序和预测任务，而非自回归模型固定的从左到右分解方式。研究还发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于自回归模型的临界计算阈值的闭式表达式。

**Conclusion:** 当数据而非计算是瓶颈时，扩散模型为标准的自回归范式提供了一个引人注目的替代方案。

> **ai_Abstract:** 本研究系统地探究了在数据受限且计算资源充足的条件下，掩码扩散语言模型与自回归（AR）模型的性能。结果表明，扩散模型在数据稀缺环境下显著优于AR模型，其优势在于能够更好地利用重复数据，实现更低的验证损失和更优的下游表现。这种优势被归因于扩散模型的隐式数据增强机制，该机制提供了多样化的词元排序和预测任务。研究还提出了扩散模型的新缩放定律，并确定了其超越AR模型的临界计算阈值，表明扩散模型在数据成为主要瓶颈时是一个有力的替代方案。

> **摘要翻译:** 自回归（AR）模型长期以来一直主导着大型语言模型的领域，推动了各种任务的进展。最近，基于扩散的语言模型作为一种有前景的替代方案出现，尽管它们相对于AR模型的优势仍未得到充分探索。在本文中，我们系统地研究了数据受限环境下的掩码扩散模型——在这种环境下，训练涉及对有限数据进行重复传递——并发现当计算资源充足但数据稀缺时，它们显著优于AR模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。我们将这种优势解释为隐式数据增强：与AR模型固定的从左到右分解不同，掩码扩散模型使模型接触到多样化的词元排序和预测任务。我们发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于AR模型的临界计算阈值的闭式表达式。这些结果表明，当数据而非计算是瓶颈时，扩散模型为标准的AR范式提供了一个引人注目的替代方案。我们的代码可在以下网址获取：https://diffusion-scaling.github.io。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [252] [C2G-KD: PCA-Constrained Generator for Data-Free Knowledge Distillation](https://arxiv.org/abs/2507.18533)
> *C2G-KD：PCA约束的无数据知识蒸馏生成器*

*Magnus Bengtsson, Kenneth Östberg* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 无数据知识蒸馏, 生成器, PCA约束, 合成样本, C2G-KD

**Comment:** 12 pages

> **TL;DR:** C2G-KD是一个无数据知识蒸馏框架，通过PCA约束的生成器合成样本，即使只有少量真实数据也能有效训练。

**AI_Comments:** C2G-KD的创新之处在于其“无数据”特性和对PCA约束的巧妙运用，极大地降低了对真实训练数据的依赖，尤其是在数据隐私或获取受限的场景下具有重要意义。它展示了即使在数据极度稀缺的情况下，也能通过结构化约束生成高质量的合成数据用于知识蒸馏。

<details>
  <summary>Details</summary>

**Motivation:** 解决无数据知识蒸馏中生成合成样本的问题，同时保持样本的多样性和拓扑一致性，且不依赖真实训练数据。

**Method:** C2G-KD训练一个类条件生成器，该生成器在不观察真实数据的情况下，通过冻结的教师模型和基于PCA的几何约束来生成合成样本。生成器通过语义和结构损失来激活教师模型的输出，并通过将生成样本约束在类特定的PCA子空间内来保持拓扑一致性和多样性，这些子空间只需每类两个真实样本即可估计。

**Result:** 在MNIST上的实验表明，即使是最小的类别结构也足以启动有用的合成训练管道。

**Conclusion:** C2G-KD框架通过结合PCA约束和生成器，可以在无数据场景下有效进行知识蒸馏，并且对真实数据的依赖极小。

> **ai_Abstract:** C2G-KD是一个创新的无数据知识蒸馏框架，它利用一个受PCA几何约束的类条件生成器来合成训练样本。该生成器无需访问真实训练数据，而是通过语义和结构损失以及从极少量真实样本（每类两个）估计的PCA子空间来确保生成样本的质量、多样性和拓扑一致性。实验证明其在MNIST数据集上的有效性。

> **摘要翻译:** 我们引入了C2G-KD，这是一个无数据知识蒸馏框架，其中训练一个类条件生成器，以在冻结的教师模型和源自PCA的几何约束的指导下生成合成样本。该生成器从不观察真实的训练数据，而是通过语义和结构损失的组合来学习激活教师模型的输出。通过将生成的样本约束在从每类仅两个真实样本估计出的类特定PCA子空间内，我们保留了拓扑一致性和多样性。在MNIST上的实验表明，即使是最小的类别结构也足以启动有用的合成训练管道。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [264] [Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs](https://arxiv.org/abs/2503.16870)
> *稀疏Logit采样：加速大型语言模型中的知识蒸馏*

*Anshumann, Mohd Abbas Zaidi, Akhil Kedia, Jinwoo Ahn, Taehwak Kwon, Kangwook Lee, Haejun Lee, Joohyung Lee* | **Category: cs.LG, cs.AI, cs.CL, 68T50, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 知识蒸馏, 大型语言模型, 稀疏采样, 重要性采样, 预训练

**Comment:** Accepted as Oral paper at ACL 2025. Source code is available at
  https://github.com/akhilkedia/RandomSamplingKD . Anshumann, Mohd Abbas Zaidi
  and Akhil Kedia have Equal Contribution

> **TL;DR:** 提出一种基于重要性采样的稀疏Logit采样方法，解决知识蒸馏中Top-K方法的偏差问题，实现LLM预训练阶段更快的知识蒸馏，且性能与完整蒸馏相当。

**AI_Comments:** 这项工作通过引入一种基于重要性采样的无偏稀疏Logit采样方法，解决了大型语言模型知识蒸馏预训练中Top-K等朴素方法导致的偏差问题，具有重要的创新性。它不仅提高了蒸馏效率，降低了存储成本，还在保持高性能的同时加速了训练过程，对于LLM的实际应用和研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 知识蒸馏在LLM中成本效益高，但将其成功应用于预训练阶段尚待探索。现有的稀疏知识蒸馏方法（如缓存Top-K概率）会提供有偏的教师概率分布估计，导致次优的性能和校准。

**Method:** 提出了一种基于重要性采样的方法，名为“随机采样知识蒸馏”（Random Sampling Knowledge Distillation）。该方法提供无偏估计，在期望上保留梯度，并需要存储显著更稀疏的logits。

**Result:** 与基于交叉熵的训练相比，该方法使学生模型训练更快，开销很小（<10%），同时与完整蒸馏相比，在300M到3B的模型尺寸范围内保持了有竞争力的性能。

**Conclusion:** 随机采样知识蒸馏方法能够有效解决稀疏知识蒸馏中的偏差问题，并在LLM预训练中实现高效且高性能的知识蒸馏。

> **ai_Abstract:** 该论文针对大型语言模型预训练中知识蒸馏的挑战，特别是现有稀疏方法（如Top-K采样）导致的偏差问题，提出了一种名为“随机采样知识蒸馏”的基于重要性采样的新方法。该方法能提供无偏估计，保持梯度，并显著减少Logit存储需求。实验证明，该方法在保持与完整蒸馏相当性能的同时，能显著加速学生模型的训练，且开销极小。

> **摘要翻译:** 知识蒸馏是一种成本效益高的技术，可以将知识提炼到大型语言模型中，前提是教师输出的logits可以预先计算并缓存。然而，将其成功应用于预训练阶段仍未得到充分探索。在这项工作中，我们证明了稀疏知识蒸馏的朴素方法，例如缓存Top-K概率，虽然直观，但会向学生提供有偏的教师概率分布估计，导致次优的性能和校准。我们提出了一种基于重要性采样的方法“随机采样知识蒸馏”，它提供无偏估计，在期望上保留梯度，并且需要存储显著更稀疏的logits。与基于交叉熵的训练相比，我们的方法使学生模型的训练速度更快，开销很小（<10%），同时在300M到3B的一系列模型尺寸上，与完整蒸馏相比保持了有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [267] [Fourier Neural Operators for Non-Markovian Processes:Approximation Theorems and Experiments](https://arxiv.org/abs/2507.17887)
> *傅里叶神经算子用于非马尔可夫过程：逼近定理与实验*

*Wonjae Lee, Taeyoung Kim, Hyungbin Park* | **Category: cs.LG, cs.NA, math.NA** | **Updated: 2025-07-23**

**Keywords:** 傅里叶神经算子, 非马尔可夫过程, 随机微分方程, 分数布朗运动, 分辨率泛化

**Comment:** 

> **TL;DR:** 本文提出了一种名为镜像填充傅里叶神经算子（MFNO）的新型神经网络，用于学习随机系统的动力学，并从理论上证明了其对非马尔可夫过程的逼近能力，同时在实验中展现出卓越的泛化性和效率。

**AI_Comments:** 这篇论文的创新点在于提出了MFNO，通过引入镜像填充解决了FNO处理非周期性输入的局限性。其重要性在于提供了处理非马尔可夫过程的强大工具，并结合了严谨的理论证明和令人信服的实验结果。尤其值得关注的是其“强大的分辨率泛化能力”和“显著更快的样本路径生成速度”，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在学习随机系统的动力学，特别是处理具有非周期性输入的非马尔可夫过程。

**Method:** 引入了镜像填充傅里叶神经算子（MFNO），它是通过引入镜像填充来扩展标准傅里叶神经算子（FNO），使其能够处理非周期性输入。理论分析基于Wong--Zakai型定理和各种逼近技术。

**Result:** 理论上，MFNO能够以任意精度逼近路径依赖随机微分方程的解和分数布朗运动的Lipschitz变换。经验上，MFNO表现出强大的分辨率泛化能力，优于LSTMs、TCNs和DeepONet等标准架构，并且性能与这些基线模型相当或更优，同时比经典数值方案生成样本路径快得多。

**Conclusion:** MFNO是一种有效且高效的模型，能够学习随机系统（特别是非马尔可夫过程）的动力学。它具有坚实的理论基础和令人信服的实证性能，尤其在分辨率泛化和样本路径生成速度方面表现突出。

> **ai_Abstract:** 本文提出了一种名为镜像填充傅里叶神经算子（MFNO）的新型神经网络，专门用于学习随机系统的动力学。MFNO通过镜像填充扩展了标准傅里叶神经算子，使其能处理非周期性输入。研究者从理论上证明了MFNO能高精度逼近路径依赖随机微分方程和分数布朗运动的解。实验结果显示，MFNO在分辨率泛化方面表现出色，并能以更快的速度生成样本路径，同时性能与现有基线模型相当或更优。

> **摘要翻译:** 这篇论文介绍了一种基于算子的神经网络，即镜像填充傅里叶神经算子（MFNO），旨在学习随机系统的动力学。MFNO通过引入镜像填充来扩展标准傅里叶神经算子（FNO），使其能够处理非周期性输入。我们严格证明了MFNO能够以任意精度逼近路径依赖随机微分方程的解和分数布朗运动的Lipschitz变换。我们的理论分析建立在Wong--Zakai型定理和各种逼近技术之上。在经验上，MFNO表现出强大的分辨率泛化能力——这是LSTMs、TCNs和DeepONet等标准架构中罕见的特性。此外，我们的模型在性能上与这些基线模型相当或更优，同时比经典数值方案提供显著更快的样本路径生成。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [269] [Percentile-Based Deep Reinforcement Learning and Reward Based Personalization For Delay Aware RAN Slicing in O-RAN](https://arxiv.org/abs/2507.18111)
> *基于百分位数的深度强化学习和基于奖励的个性化用于O-RAN中时延感知的RAN切片*

*Peyman Tehrani, Anas Alsoliman* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** RAN切片, O-RAN, 深度强化学习, 时延感知, 个性化

**Comment:** 

> **TL;DR:** 本文提出了一种基于百分位数的深度强化学习（PDA-DRL）方法，用于O-RAN中的时延感知RAN切片，以满足多个MVNO的概率时延上限，并最小化PRB利用率。此外，还引入了一种基于奖励的个性化模型权重共享方法。

**AI_Comments:** 本文的创新点在于提出了基于百分位数的深度强化学习（PDA-DRL）来解决O-RAN中的时延感知RAN切片问题，尤其关注概率时延上限而非平均时延。此外，引入的基于奖励的个性化模型权重共享方法，通过代理间性能驱动的权重优先级，有效地提升了多MVNO协作的鲁棒性，超越了传统联邦学习方法。这对于未来O-RAN的资源管理和多租户支持具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在O-RAN架构中，无线接入网（RAN）切片面临挑战，即多个移动虚拟网络运营商（MVNO）竞争物理资源块（PRB），同时需要满足客户的概率时延上限约束并最小化PRB利用率。

**Method:** 1. 基于大数定律（LLN）推导奖励函数并进行实际修改。2. 提出基于百分位数的时延感知深度强化学习（PDA-DRL）解决方案。3. 引入一种基于奖励的个性化方法，其中每个代理根据其他代理的性能来优先考虑其模型权重，用于多MVNO之间的模型权重共享。

**Result:** 1. PDA-DRL在平均时延方面比基线（包括针对平均时延约束优化的DRL模型）减少了38%。2. 基于奖励的个性化技术优于传统的聚合方法（如联邦平均）以及依赖流量模式和模型权重距离相似性的策略。

**Conclusion:** 本文提出的PDA-DRL方法和基于奖励的个性化模型权重共享技术能够有效解决O-RAN中时延感知的RAN切片问题，显著降低平均时延并实现鲁棒的个性化模型共享。

> **ai_Abstract:** 本文提出了一种用于O-RAN中时延感知RAN切片的基于百分位数的深度强化学习（PDA-DRL）方法。该方法旨在帮助多个MVNO在竞争PRB的同时，满足客户的概率时延上限并最小化资源利用。文章首先推导并修改了基于大数定律的奖励函数，然后介绍了PDA-DRL，该方案在减少平均时延方面表现优异，相比基线减少了38%。此外，为实现多MVNO间的鲁棒模型共享，论文还提出了一种基于奖励的个性化方法，其性能优于传统聚合方法。

> **摘要翻译:** 本文解决了开放式RAN（O-RAN）架构中的无线接入网（RAN）切片挑战。我们的重点是一个网络，其中包含多个移动虚拟网络运营商（MVNO），它们竞争物理资源块（PRB），目标是满足其客户的概率时延上限约束，同时最小化PRB利用率。最初，我们基于大数定律（LLN）推导了一个奖励函数，然后进行了实际修改以适应真实世界的实验场景。然后，我们提出了我们的解决方案，即基于百分位数的时延感知深度强化学习（PDA-DRL），它通过将最终平均时延减少38%来证明其优于包括针对平均时延约束优化的DRL模型在内的多个基线。此外，我们深入探讨了多个MVNO之间模型权重共享的问题，以开发一个鲁棒的个性化模型。我们引入了一种基于奖励的个性化方法，其中每个代理根据其他代理的性能来优先考虑其他代理的模型权重。这种技术超越了传统的聚合方法，例如联邦平均，以及依赖于流量模式和模型权重距离相似性的策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [282] [Analyzing Islamophobic Discourse Using Semi-Coded Terms and LLMs](https://arxiv.org/abs/2503.18273)
> *使用半编码术语和大型语言模型分析仇视伊斯兰教言论*

*Raza Ul Mustafa, Roi Dupart, Gabrielle Smith, Noman Ashraf, Nathalie Japkowicz* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 仇视伊斯兰教, 半编码术语, 大型语言模型, 仇恨言论, 主题建模

**Comment:** 

> **TL;DR:** 本研究分析了极端社交平台上难以识别的半编码仇视伊斯兰教术语，发现大型语言模型能理解这些术语，且此类言论毒性较高，并揭示了其在不同运动中的分布，强调需改进审核策略。

**AI_Comments:** 该论文创新性地关注了难以识别的“半编码”仇视伊斯兰教术语，并首次大规模地结合LLMs、毒性API和主题建模进行分析。其重要性在于揭示了这类隐蔽性仇恨言论的识别难度和高毒性，并指出LLMs虽有识别能力但仍需加强，对未来的内容审核和算法改进具有指导意义。研究结果也为理解仇视伊斯兰教言论的传播模式和目标群体提供了宝贵洞察。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，仇视伊斯兰教在西方社会日益盛行，尤其在数字通信网络中传播。许多仇视伊斯兰教的半编码术语在特定语境外看似中立或模糊，导致人工审核员和自动化系统难以可靠地识别为仇恨言论，因此需要进行大规模分析。

**Method:** 首先，使用大型语言模型（LLMs）来展示它们理解这些术语的能力。其次，利用Google Perspective API评估仇视伊斯兰教帖子的毒性得分。最后，采用BERT主题建模方法提取这些社交平台上的不同主题和仇视伊斯兰教言论。

**Result:** 研究发现大型语言模型能够理解这些词汇表外（OOV）的侮辱性词语；仇视伊斯兰教的帖子往往比反犹太主义等其他类别的仇恨言论获得更高的毒性分数；主题建模显示仇视伊斯兰教文本存在于各种政治、阴谋论和极右翼运动中，尤其针对穆斯林移民。

**Conclusion:** 大型语言模型能够理解半编码的仇视伊斯兰教术语，但仍需进一步改进审核策略和算法检测以有效处理此类言论。本研究是首批针对仇视伊斯兰教半编码术语的研究之一，为全球范围内的仇视伊斯兰教问题提供了新的视角。

> **ai_Abstract:** 本研究对极端社交平台上流行的、难以识别的半编码仇视伊斯兰教术语进行了大规模分析。研究利用大型语言模型（LLMs）验证了其对这些术语的理解能力，并通过Google Perspective API发现仇视伊斯兰教言论的毒性高于其他仇恨言论。此外，BERT主题建模揭示了此类言论在不同政治、阴谋论和极右翼运动中的分布，并主要针对穆斯林移民。研究强调，尽管LLMs能理解这些特殊术语，但仍需改进审核策略和算法检测来有效应对仇视伊斯兰教言论。

> **摘要翻译:** 近年来，仇视伊斯兰教在西方社会日益盛行，这得益于数字通信网络的兴起。本文对在极端社交平台（如4Chan、Gab、Telegram等）上流传的专业半编码仇视伊斯兰教术语（如muzrat、pislam、mudslime、mohammedan、muzzies）进行了大规模分析。这些术语中有许多在特定语境之外看似词汇中立或模糊，使得人工审核员和自动化系统都难以可靠地将其识别为仇恨言论。首先，我们使用大型语言模型（LLMs）来展示它们理解这些术语的能力。其次，Google Perspective API表明，仇视伊斯兰教的帖子往往比反犹太主义等其他类别的仇恨言论获得更高的毒性分数。最后，我们使用BERT主题建模方法来提取这些社交平台上的不同主题和仇视伊斯兰教言论。我们的研究结果表明，LLMs能够理解这些词汇表外（OOV）的侮辱性词语；然而，为了有效应对此类言论，审核策略和算法检测仍需进一步改进。我们的主题建模还表明，仇视伊斯兰教文本存在于各种政治、阴谋论和极右翼运动中，并且特别针对穆斯林移民。总而言之，我们对仇视伊斯兰教的半编码术语进行了首次研究之一，并对仇视伊斯兰教现象进行了全球性的阐释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [294] [Federated Learning for Large-Scale Cloud Robotic Manipulation: Opportunities and Challenges](https://arxiv.org/abs/2507.17903)
> *联邦学习在 C规模云机器人操作中的应用：机遇与挑战*

*Obaidullah Zaland, Chanh Nguyen, Florian T. Pokorny, Monowar Bhuyan* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 联邦学习, 云机器人, 机器人操作, 分布式机器学习, 机遇与挑战

**Comment:** Accepted for Presentation at IEEE International Conference on Machine
  Learning and Cybernetics (ICMLC) 2025

> **TL;DR:** 本文探讨了联邦学习在云机器人操作中的概念、优势、挑战和机遇。

**AI_Comments:** 这篇论文的重要性在于它将新兴的联邦学习范式与云机器人操作这一前沿领域相结合，探讨了在分布式计算背景下，如何利用联邦学习解决机器人操作面临的计算资源限制和数据隐私问题。它不仅指出了联邦学习的优势，也坦诚地提出了其面临的挑战，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器学习方法需要数据本地化，而当前机器人操作受限于计算资源。云机器人技术虽缓解了计算需求，但在分布式环境中，联邦学习（FL）有望解决数据隐私和大规模协作问题。因此，论文旨在探讨FL在云机器人操作中的应用潜力、机遇与挑战。

**Method:** 本文介绍了联邦学习的基本概念及其与云机器人操作的联系，并展望了通过联邦学习实现大规模高效可靠的云机器人操作所带来的机遇和挑战。

**Result:** Not mentioned in abstract

**Conclusion:** 论文探讨了联邦学习在云机器人操作中的应用前景，识别了其带来的机遇和挑战，并提出研究人员可以在中心化或去中心化设置中设计和验证联邦学习模型。

> **ai_Abstract:** 本文探讨了联邦学习（FL）在解决大规模云机器人操作中计算资源限制和数据隐私挑战方面的潜力。论文介绍了FL的基本概念，阐述了其与云机器人操作的关联，并分析了FL在此领域带来的机遇与挑战，旨在指导研究人员在中心化或去中心化环境下设计和验证FL模型。

> **摘要翻译:** 联邦学习 (FL) 是一种新兴的分布式机器学习范式，其中模型的协作训练涉及设备的动态参与以实现广泛目标。相比之下，经典机器学习 (ML) 通常需要数据在本地进行训练，而 FL 利用大量用户设备训练共享的全局模型，无需共享私有数据。当前的机器人操作任务受限于机器人个体能力和速度，因为低延迟计算资源有限。因此，云机器人概念应运而生，它允许机器人应用利用计算资源的灵活性和可靠性，有效缓解其在云-边缘连续体中的计算需求。毫无疑问，在这种分布式计算背景下，正如在云机器人操作场景中所体现的，FL 提供了多重优势，同时也带来了若干挑战和机遇。在本文中，我们介绍了 FL 的基本概念及其与云机器人操作的联系。此外，我们展望了通过 FL 实现大规模高效可靠的云机器人操作所带来的机遇和挑战，其中研究人员可以在中心化或去中心化设置中设计和验证 FL 模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [295] [The Price equation reveals a universal force-metric-bias law of algorithmic learning and natural selection](https://arxiv.org/abs/2507.18549)
> *普莱斯方程揭示了算法学习和自然选择的通用力-度量-偏差定律*

*Steven A. Frank* | **Category: cs.LG, q-bio.PE** | **Updated: 2025-07-24**

**Keywords:** 普莱斯方程, 力-度量-偏差定律, 算法学习, 自然选择, 优化

**Comment:** 

> **TL;DR:** 普莱斯方程揭示了一个通用的力-度量-偏差（FMB）定律，该定律统一了各种学习算法、优化方法和自然选择。

**AI_Comments:** 这篇论文的创新之处在于利用普莱斯方程揭示了看似不相关的学习算法、优化方法和自然选择背后隐藏的通用数学结构。FMB定律提供了一个统一的框架，极大地促进了对这些不同领域过程的理解和比较，并为新算法的设计提供了理论指导。其重要性在于提供了一个跨学科的桥梁，可能激发新的理论突破和应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管学习算法、优化方法和自然选择表面上不同，但它们共享一个共同的数学结构，作者旨在揭示这一结构。

**Method:** 作者通过普莱斯方程对变化进行简单的符号划分，提出了一个通用的力-度量-偏差（FMB）定律：$\Delta\mathbf{\theta} = \mathbf{M}\,\mathbf{f} + \mathbf{b} + \mathbf{\xi}$。该定律分解了参数改进的驱动力（力）、重标度（度量）、动量或参考系变化（偏差）以及探索（噪声）。

**Result:** 该框架将自然选择、贝叶斯更新、牛顿法、随机梯度下降、随机朗之万动力学、Adam优化以及大多数其他算法统一为相同底层过程的特例。普莱斯方程还解释了费雪信息、Kullback-Leibler散度和达朗贝尔原理为何在学习动力学中自然出现。

**Conclusion:** FMB定律通过揭示这种共同结构，为跨学科理解、比较和设计学习算法提供了原则性的基础。

> **ai_Abstract:** 本文通过普莱斯方程提出了一个通用的力-度量-偏差（FMB）定律，该定律统一了包括自然选择、各种机器学习优化算法在内的多种学习和优化过程。该定律将参数变化分解为力（驱动改进）、度量（重标度）、偏差（动量或参考系变化）和噪声（探索）。FMB定律不仅揭示了这些过程的共同数学结构，还解释了费雪信息、Kullback-Leibler散度等概念的自然出现，为理解和设计跨学科学习算法提供了统一的理论基础。

> **摘要翻译:** 多样化的学习算法、优化方法和自然选择，尽管表面上存在差异，却共享一个共同的数学结构。在此，我展示了普莱斯方程对变化的简单符号划分揭示了一个通用的力-度量-偏差（FMB）定律：$\Delta\mathbf{\theta} = \mathbf{M}\,\mathbf{f} + \mathbf{b} + \mathbf{\xi}$。力 $\mathbf{f}$ 通过参数与性能之间的协方差驱动参数 $\Delta\mathbf{\theta}$ 的改进。度量 $\mathbf{M}$ 通过逆曲率重新调整运动。偏差 $\mathbf{b}$ 增加了动量或参考系的变化。噪声 $\mathbf{\xi}$ 实现了探索。该框架将自然选择、贝叶斯更新、牛顿法、随机梯度下降、随机朗之万动力学、Adam优化以及大多数其他算法统一为相同底层过程的特例。普莱斯方程还揭示了费雪信息、Kullback-Leibler散度和达朗贝尔原理为何在学习动力学中自然出现。通过揭示这种共同结构，FMB定律为跨学科理解、比较和设计学习算法提供了原则性的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [302] [LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important](https://arxiv.org/abs/2504.04704)
> *LagKV：KV缓存的滞后相对信息揭示了哪些令牌是重要的*

*Manlai Liang, JiaMing Zhang, Xiong Li, Jinlong Li* | **Category: cs.LG, cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-24**

**Keywords:** KV缓存压缩, 大型语言模型, 长上下文推理, LagKV, 无注意力机制

**Comment:** 

> **TL;DR:** LagKV是一种新的KV缓存压缩策略，通过直接比较KV自身来识别重要令牌，无需注意力机制，易于集成，且性能优于现有方法。

**AI_Comments:** LagKV的创新之处在于其“无注意力”的KV缓存压缩方法，通过简单的KV比较而非复杂的注意力权重分析，大大降低了实现难度和计算开销。这使得它在实际部署中具有更高的易集成性和实用性，为解决LLM长上下文推理的性能瓶颈提供了一种高效且优雅的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在长上下文推理过程中，Key-Value (KV) 缓存的不断增大是部署成本和任务准确性之间平衡的主要障碍。现有的KV缓存压缩方法大多依赖注意力权重来驱逐非关键令牌，但这通常需要对推理基础设施进行重大修改并带来显著的计算开销。

**Method:** 我们提出了LagKV，这是一种KV压缩策略，仅依赖于KV自身之间简单的直接比较。它是一种完全不依赖注意力机制的方法，因此易于集成到主流推理平台中。

**Result:** 在RULER基准测试中，我们的方法在不同的压缩比下都优于SnapKV和StreamingLLM。特别是在64位passkey检索任务中，在相同的压缩比下，我们的方法比基于注意力权重的方法$H_2O$性能提高了50%以上。

**Conclusion:** LagKV通过利用KV缓存的滞后相对信息，提供了一种无需注意力机制且易于集成的KV缓存压缩策略，在保持或提高任务准确性的同时，有效降低了部署成本，并在多个基准测试中展现出优越的性能。

> **ai_Abstract:** LagKV是一种针对大型语言模型长上下文推理中KV缓存过大问题的创新压缩策略。与现有依赖注意力权重且需要复杂修改的方法不同，LagKV利用KV自身之间的直接比较来识别并压缩不重要的令牌，从而实现无注意力机制的KV缓存优化。这种方法易于集成到现有推理平台，且计算开销小。实验结果显示，LagKV在RULER基准测试中表现优异，尤其在长上下文检索任务中，其性能显著超越了现有的一些复杂压缩方法，包括基于注意力权重的方案。

> **摘要翻译:** 大型语言模型在长上下文推理过程中，Key-Value (KV) 缓存的不断增大是其在部署成本和任务准确性之间平衡的主要障碍。为了在这种场景下减小KV缓存大小，大多数先前的工作都利用注意力权重来驱逐非关键缓存令牌。但是这些方法存在一个权衡，它们通常需要对推理基础设施进行重大修改并带来显著的计算开销。基于大型语言模型是自回归模型这一事实，我们提出了LagKV，这是一种仅依赖于KV自身之间简单直接比较的KV压缩策略。它是一种完全不依赖注意力的方法，提供了易于集成到主流推理平台的特性，并且与其它复杂的KV压缩方法相比，性能具有可比性。RULER基准测试结果表明，我们的方法在不同的压缩比下都优于SnapKV和StreamingLLM。特别是在64位passkey检索任务中，在相同的压缩比下，我们的方法比基于注意力权重的方法$H_2O$性能提高了50%以上。我们的代码可在https://github.com/AI-Lab-China-Merchants-Bank/LagKV获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [313] [Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification](https://arxiv.org/abs/2507.18113)
> *强化学习中的策略中断：基于大型语言模型和关键状态识别的对抗性攻击*

*Junyong Jiang, Buwei Tian, Chenxing Xu, Songze Li, Lu Dong* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 对抗性攻击, 大型语言模型, 策略中断, 关键状态识别

**Comment:** 

> **TL;DR:** 本文提出了一种新的对抗性攻击方法，利用大型语言模型生成对抗性奖励并识别关键状态，以诱导强化学习代理输出次优动作，且无需修改环境。

**AI_Comments:** 这项研究的创新之处在于，它通过结合大型语言模型来生成对抗性奖励，并引入关键状态识别机制，实现了对强化学习代理的有效且隐蔽的攻击，而无需直接修改环境。这提高了攻击的实用性，并为理解和防御RL系统的脆弱性提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有对抗性攻击方法通常依赖于修改环境或策略，这限制了它们的实用性。强化学习系统面临的对抗性攻击挑战仍未解决。

**Method:** 本文提出了一种对抗性攻击方法，该方法通过环境中的现有代理引导目标策略输出次优动作，而无需改变环境。具体来说，提出了一种奖励迭代优化框架，利用大型语言模型（LLMs）生成专门针对目标代理漏洞的对抗性奖励，从而增强诱导目标代理进行次优决策的有效性。此外，设计了一种关键状态识别算法，以精确定位目标代理最脆弱的状态，在这些状态下受害者的次优行为会导致整体性能显著下降。

**Result:** 在不同环境下的实验结果表明，本文方法优于现有方法。

**Conclusion:** 本研究提出了一种有效且实用的强化学习对抗性攻击方法，该方法利用LLMs生成对抗性奖励并识别关键状态，成功诱导目标代理产生次优行为，且无需修改环境，显著优于现有方法。

> **ai_Abstract:** 本文提出了一种新颖的强化学习对抗性攻击方法，旨在不修改环境的情况下，通过诱导目标代理产生次优动作来扰乱其策略。该方法包含两个核心组件：一个利用大型语言模型生成定制化对抗性奖励的奖励迭代优化框架，以及一个用于识别代理最脆弱关键状态的算法。实验证明，该方法在多种环境下优于现有攻击手段。

> **摘要翻译:** 强化学习（RL）在机器人和自动驾驶等领域取得了显著成功，但旨在误导RL系统的对抗性攻击仍然具有挑战性。现有方法通常依赖于修改环境或策略，这限制了它们的实用性。本文提出了一种对抗性攻击方法，其中环境中的现有代理引导目标策略输出次优动作，而无需改变环境。我们提出了一种奖励迭代优化框架，该框架利用大型语言模型（LLMs）生成专门针对目标代理漏洞的对抗性奖励，从而增强诱导目标代理进行次优决策的有效性。此外，设计了一种关键状态识别算法，以精确定位目标代理最脆弱的状态，在这些状态下受害者的次优行为会导致整体性能显著下降。在不同环境下的实验结果表明，我们的方法优于现有方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [322] [Position: An Empirically Grounded Identifiability Theory Will Accelerate Self-Supervised Learning Research](https://arxiv.org/abs/2504.13101)
> *立场：一个基于经验的识别性理论将加速自监督学习研究*

*Patrik Reizinger, Randall Balestriero, David Klindt, Wieland Brendel* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 识别性理论, 柏拉图式表征假设, 奇异识别性理论, 理论与实践

**Comment:** ICML2025 camera ready

> **TL;DR:** 本文提出，一个扩展的识别性理论（SITh）对于理解和加速自监督学习（SSL）至关重要，因为当前的识别性理论无法解释SSL的经验成功，尽管它可以解释柏拉图式表征假设（PRH）在SSL中的出现。

**AI_Comments:** 本文的创新点在于提出了“奇异识别性理论（SITh）”这一新的理论框架，旨在弥合自监督学习（SSL）理论与实践之间的巨大鸿沟。其重要性在于，通过提供一个更全面的理论基础，SITh有望加速SSL领域的发展，使其能够学习到更具可解释性和泛化能力的表征，从而推动AI系统的进步。文章明确指出了当前理论的不足，并为未来的研究提供了清晰的方向，体现了其前瞻性和指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 自监督学习（SSL）是当前许多AI系统的核心，但其背后的柏拉图式表征假设（PRH）缺乏精确的理论解释，且现有的识别性理论（IT）无法解释SSL的经验成功。因此，需要一个更广泛的理论框架来弥合理论与实践之间的鸿沟，并深入理解SSL中的隐式数据假设。

**Method:** 通过综合识别性理论（IT）的证据，本文展示了柏拉图式表征假设（PRH）可以在自监督学习（SSL）中出现。为了弥合理论与实践之间的差距，作者提出将现有识别性理论扩展为奇异识别性理论（SITh），这是一个涵盖整个SSL流程的更广泛的理论框架。

**Result:** 研究表明，柏拉图式表征假设（PRH）可以在自监督学习（SSL）中出现。然而，当前的识别性理论（IT）无法解释SSL的经验成功。为此，提出了奇异识别性理论（SITh）以提供更深层次的见解，并推动该领域向学习更具可解释性和泛化性的表征发展。

**Conclusion:** 一个扩展的识别性理论，即奇异识别性理论（SITh），对于深入理解自监督学习（SSL）中的隐式数据假设至关重要，并将加速该领域向学习更具可解释性和泛化性的表征发展。未来的研究方向包括：SSL的训练动态和收敛特性、有限样本、批量大小和数据多样性的影响，以及架构、增强、初始化方案和优化器中归纳偏差的作用。

> **ai_Abstract:** 本文指出，尽管自监督学习（SSL）在AI系统中广泛应用且柏拉图式表征假设（PRH）在SSL中可见，但其成功缺乏精确的理论解释，现有识别性理论（IT）不足以覆盖其经验成就。为弥合理论与实践鸿沟，作者提出了一种新的、更全面的奇异识别性理论（SITh），旨在深入理解SSL中的隐式数据假设，并加速其向更可解释和泛化表征的发展。文章还提出了未来研究的三个关键方向。

> **摘要翻译:** 自监督学习（SSL）为许多当前的人工智能系统提供动力。随着研究兴趣和投资的增长，SSL的设计空间持续扩大。遵循柏拉图式表征假设（PRH）的SSL柏拉图式观点表明，尽管方法和工程方法不同，但所有表征都趋向于相同的柏拉图式理想。然而，这种现象缺乏精确的理论解释。通过综合识别性理论（IT）的证据，我们表明PRH可以在SSL中出现。然而，当前的IT无法解释SSL的经验成功。为了弥合理论与实践之间的差距，我们建议将IT扩展为我们称之为奇异识别性理论（SITh）的理论，这是一个涵盖整个SSL流程的更广泛的理论框架。SITh将允许更深入地了解SSL中的隐式数据假设，并推动该领域向学习更具可解释性和泛化性的表征发展。我们强调了未来研究的三个关键方向：1）SSL的训练动态和收敛特性；2）有限样本、批量大小和数据多样性的影响；3）架构、增强、初始化方案和优化器中归纳偏差的作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [Deep learning-aided inverse design of porous metamaterials](https://arxiv.org/abs/2507.17907)
> *深度学习辅助多孔超材料的逆向设计*

*Phu Thien Nguyen, Yousef Heider, Dennis M. Kochmann, Fadi Aldakheel* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 深度学习, 逆向设计, 多孔超材料, 变分自编码器, 水力性质

**Comment:** 31 pages, 29 figures

> **TL;DR:** 本文开发了一种基于深度学习的属性变分自编码器（pVAE）框架，用于逆向设计具有特定水力性质的多孔超材料，并通过卷积神经网络（CNN）显著降低了计算成本。

**AI_Comments:** 该论文创新性地将深度学习应用于多孔超材料的逆向设计，特别是引入了pVAE框架，并结合CNN提高了计算效率。通过对潜在空间的详细分析，实现了高效的结构-性质探索，为材料科学领域提供了有价值的工具。开放数据集和代码的举措也值得称赞，将促进后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 探索使用深度学习生成框架对多孔超材料进行逆向设计，以生成具有定制水力性质的超材料。

**Method:** 开发了属性变分自编码器（pVAE），该模型是变分自编码器（VAE）与回归器的结合。利用格子玻尔兹曼方法（LBM）生成渗透率数据，并训练卷积神经网络（CNN）以自下而上的方式预测有效水力性质，从而降低计算成本。pVAE框架在合成数据集和真实开孔泡沫的CT扫描图像数据集上进行训练。

**Result:** 成功展示了pVAE框架在结构-性质映射、插值和逆向设计中的作用，能够有效生成具有所需性质的新型超材料。通过CNN预测水力性质显著降低了计算成本。

**Conclusion:** 该深度学习方法能够有效实现多孔超材料的逆向设计，生成具有特定水力性质的新材料，并且计算效率高。

> **ai_Abstract:** 本文提出了一种基于深度学习的属性变分自编码器（pVAE）框架，用于多孔超材料的逆向设计。该框架结合了VAE和回归器，能够生成具有特定水力性质（如孔隙率和渗透率）的材料。研究利用CNN加速水力性质预测，显著降低了计算成本。pVAE在合成和真实CT扫描数据集上训练，并展示了其在结构-性质映射、插值和逆向设计方面的有效性，为新型超材料的生成提供了高效途径。

> **摘要翻译:** 本研究的最终目标是探索使用基于深度学习的生成框架对多孔超材料进行逆向设计。具体而言，我们开发了一种属性变分自编码器（pVAE），这是一种增强了回归器的变分自编码器（VAE），用于生成具有定制水力性质（如孔隙率和渗透率）的结构化超材料。虽然这项工作使用格子玻尔兹曼方法（LBM）为有限的多孔微结构生成本征渗透率张量数据，但通过自下而上的方法训练卷积神经网络（CNN）来预测有效的流体力学性质。与直接LBM模拟相比，这显著降低了计算成本。pVAE框架在两个数据集上进行训练：一个人工多孔微结构的合成数据集和真实开孔泡沫体素的CT扫描图像。VAE的编码器-解码器架构捕获关键的微结构特征，将其映射到紧凑且可解释的潜在空间，以实现高效的结构-性质探索。本研究提供了对潜在空间的详细分析和解释，展示了其在结构-性质映射、插值和逆向设计中的作用。这种方法有助于生成具有所需性质的新型超材料。本研究中使用的数据集和代码将开放获取，以支持进一步的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [330] [The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane Algorithm](https://arxiv.org/abs/2507.18553)
> *LLM量化的几何学：GPTQ作为Babai最近平面算法*

*Jiale Chen, Torsten Hoefler, Dan Alistarh* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM量化, GPTQ, Babai最近平面算法, 格理论, 理论基础

**Comment:** 

> **TL;DR:** 本文揭示了GPTQ算法在特定条件下与Babai最近平面算法的数学等价性，从而为其提供了坚实的理论基础和几何解释。

**AI_Comments:** 这项工作极具创新性，它将一个广泛应用的工程实践（GPTQ）与一个经典的数学理论（Babai的最近平面算法）联系起来，为其提供了此前缺失的理论基础和几何直觉。这一发现不仅有助于深入理解GPTQ的工作机制，更重要的是，它为LLM量化算法的设计打开了新的研究方向，即利用格理论中已有的成熟成果来改进和开发更高效、有理论保证的量化方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的GPTQ算法被描述为一系列临时的代数更新，缺乏几何意义或最坏情况保证，限制了对其内部工作原理的理解和进一步优化。

**Method:** 本研究通过复杂的数学论证，证明了当GPTQ算法对线性层从后向前执行时，它在数学上等同于Babai最近平面算法，应用于由层输入的海森矩阵定义的格上的经典最近向量问题。

**Result:** 这一等价性带来了两个主要分析结果：(i) GPTQ的误差传播步骤获得了直观的几何解释；(ii) 在无裁剪条件下，GPTQ继承了Babai算法的误差上限。

**Conclusion:** 这些结果为GPTQ提供了坚实的理论基础，并为将格算法领域的数十年进展引入未来十亿参数模型量化算法的设计开辟了道路。

> **ai_Abstract:** 本文深入探讨了LLM权重后训练量化方法GPTQ的理论基础。研究发现，在特定执行顺序下，GPTQ与解决格上最近向量问题的Babai最近平面算法在数学上是等价的。这一发现不仅为GPTQ的误差传播提供了直观的几何解释，还赋予其Babai算法的误差上限保证，从而极大地提升了GPTQ的理论严谨性，并为未来量化算法的设计引入了格算法的丰富经验。

> **摘要翻译:** 将大型语言模型（LLM）的权重从16位量化到更低的位宽是当前将大型Transformer模型部署到更经济加速器上的事实标准方法。GPTQ已成为LLM规模上一次性训练后量化的标准方法之一。然而，其内部工作原理被描述为一系列临时的代数更新，模糊了任何几何意义或最坏情况保证。在这项工作中，我们展示了，当对线性层从后向前（从最后一维到第一维）执行时，GPTQ在数学上与Babai最近平面算法完全相同，该算法用于由层输入的海森矩阵定义的格上的经典最近向量问题（CVP）。这种等价性基于复杂的数学论证，并具有两个分析性结果：(i) GPTQ的误差传播步骤获得了直观的几何解释；(ii) 在无裁剪条件下，GPTQ继承了Babai算法的误差上限。总而言之，这些结果为GPTQ奠定了坚实的理论基础，并为将格算法领域数十年的进展引入未来十亿参数模型量化算法的设计开辟了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [342] [Statistical Runtime Verification for LLMs via Robustness Estimation](https://arxiv.org/abs/2504.17723)
> *基于鲁棒性估计的LLM统计运行时验证*

*Natan Levy, Adiel Ashrov, Guy Katz* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM, 运行时验证, 鲁棒性估计, 统计验证, RoMA

**Comment:** 20 pages, 4 figures

> **TL;DR:** 本文提出了一种名为RoMA的统计验证框架，用于在黑盒部署中对大型语言模型（LLM）进行运行时鲁棒性监控。RoMA在保持与形式化验证相当的准确性下，将验证时间从数小时缩短至数分钟，证明了其作为形式化方法不可行时的可扩展替代方案的有效性。

**AI_Comments:** 本文提出了一种创新性的方法，利用统计验证框架RoMA来解决LLM运行时鲁棒性验证的计算瓶颈。其主要创新在于将RoMA应用于黑盒LLM部署，并通过分析置信度分数分布进行鲁棒性评估。该方法的价值体现在其显著的效率提升（将验证时间从数小时缩短到数分钟），同时保持了与形式化验证相近的准确性。这对于LLM在实际关键应用中的安全部署具有重要意义。RoMA作为形式化方法的替代方案，为实时监控LLM的鲁棒性提供了一条可行的路径。

<details>
  <summary>Details</summary>

**Motivation:** 在运行时关键型应用中安全部署大型语言模型（LLM）需要进行对抗性鲁棒性验证。然而，由于计算成本高昂和需要白盒访问，传统的形式化验证技术对于现代LLM而言是不可行的。

**Method:** 本文将RoMA统计验证框架进行调整和扩展，以评估其作为黑盒部署设置中LLM在线运行时鲁棒性监测器的可行性。RoMA通过分析语义扰动下的置信度分数分布，提供具有统计验证界限的量化鲁棒性评估。该框架在语义、类别和正字法扰动域中进行了评估。

**Result:** RoMA与形式化验证基线相比，实现了可媲美的准确性（偏差在1%以内），并将验证时间从数小时缩短至数分钟。实验结果表明RoMA在操作性LLM部署中进行鲁棒性监控是有效的。

**Conclusion:** RoMA是当形式化方法不可行时一个潜在的可扩展替代方案，对基于LLM系统的运行时验证具有广阔的应用前景。

> **ai_Abstract:** 本研究提出并验证了RoMA（Robustness Monitoring and Assessment）统计验证框架，旨在解决大型语言模型（LLM）在关键应用中运行时鲁棒性验证的挑战。鉴于传统形式化验证方法计算成本高昂且需要白盒访问，RoMA被设计为一种适用于黑盒部署环境的在线鲁棒性监测器。通过分析语义扰动下的置信度分数分布，RoMA能够提供带有统计验证界限的量化鲁棒性评估。实验结果表明，RoMA在与形式化验证基线保持相似准确性（1%偏差内）的同时，显著将验证时间从数小时缩短至数分钟。该框架在语义、类别和正字法扰动域中均表现出有效性，证明了RoMA作为形式化方法不可行时的一种可扩展且有前景的运行时验证替代方案。

> **摘要翻译:** 对抗性鲁棒性验证对于确保大型语言模型（LLM）在运行时关键应用中的安全部署至关重要。然而，由于其指数级的运行时间和白盒访问要求，形式化验证技术对于现代LLM来说在计算上仍然不可行。本文提出了一个案例研究，调整和扩展了RoMA统计验证框架，以评估其作为黑盒部署设置中LLM在线运行时鲁棒性监测器的可行性。我们对RoMA的调整分析了语义扰动下的置信度分数分布，以提供具有统计验证界限的量化鲁棒性评估。我们针对形式化验证基线的实证验证表明，RoMA实现了可媲美的准确性（偏差在1%以内），并将验证时间从数小时缩短至数分钟。我们在语义、类别和正字法扰动域中评估了该框架。我们的结果表明RoMA在操作性LLM部署中进行鲁棒性监控的有效性。这些发现指出，当形式化方法不可行时，RoMA是一种潜在的可扩展替代方案，对基于LLM系统的运行时验证具有广阔的应用前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [356] [Maximizing Prefix-Confidence at Test-Time Efficiently Improves Mathematical Reasoning](https://arxiv.org/abs/2507.18122)
> *在测试时最大化前缀置信度有效提升数学推理能力*

*Matthias Otth, Jonas Hübotter, Ido Hakimi, Andreas Krause* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 前缀置信度, 数学推理, 语言模型, 测试时扩展, 自我提升

**Comment:** 

> **TL;DR:** 通过仅继续最自信的前缀，语言模型在数学推理任务中能显著提升性能，并且比多数投票等方法更高效。

**AI_Comments:** 这项研究的创新之处在于提出了一种无需外部验证器即可通过最大化前缀置信度实现语言模型自我提升的有效方法。其重要性体现在为数学推理任务提供了一种高效且鲁棒的解决方案，尤其是在准确性与计算成本之间取得了更好的平衡，并有效解决了长度偏差问题。

<details>
  <summary>Details</summary>

**Motivation:** 研究语言模型在数学推理任务中的测试时扩展性，并利用模型自身的置信度来选择最有前景的尝试，以实现自我提升，无需外部验证器或奖励信号。

**Method:** 该研究利用模型自身的前缀置信度来选择最有前景的尝试进行继续。研究者在五个数学推理数据集（GSM8K、MATH500、AMC23、AIME24、AIME25）上系统评估了前缀置信度缩放方法，并与多数投票和测试时训练进行了比较。

**Result:** 通过仅继续模型前缀置信度选择的最有前景的尝试，可以获得显著的性能提升。仅使用32个token的前缀置信度缩放比多数投票实现了更好的准确性-计算权衡。前缀置信度缩放似乎比BoN（Best-of-N）更不容易受到长度偏差的影响。测试时训练与前缀置信度结合虽然优于基础模型，但未能超越前缀置信度缩放。

**Conclusion:** 在测试时最大化前缀置信度能够有效提升数学推理能力，与多数投票相比，它提供了更优的准确性-计算权衡，并且对长度偏差的敏感性更低。

> **ai_Abstract:** 该论文探讨了在测试时利用语言模型自身的前缀置信度来提升数学推理能力。研究发现，通过仅继续模型最自信的前缀，可以显著提高性能。在五个数学推理数据集上的系统评估表明，前缀置信度缩放（即使只使用32个token的前缀）比多数投票具有更好的准确性-计算权衡，并且对长度偏差的敏感性较低。尽管结合前缀置信度的测试时训练优于基础模型，但其效果未超过纯粹的前缀置信度缩放。

> **摘要翻译:** 最近的工作表明，语言模型可以通过最大化其对预测的置信度来实现自我提升，而无需依赖外部验证器或奖励信号。在这项工作中，我们研究了语言模型在数学推理任务中的测试时扩展性，其中模型的自身置信度用于选择最有前景的尝试。令人惊讶的是，我们发现通过仅继续由模型前缀置信度选择的最有前景的尝试，我们可以获得显著的性能提升。我们系统地评估了前缀置信度缩放方法在五个数学推理数据集上的表现：学校级别的GSM8K和MATH500，以及竞赛级别的AMC23、AIME24和AIME25。我们发现，仅使用32个token的前缀置信度缩放比多数投票实现了更好的准确性-计算权衡。此外，前缀置信度缩放似乎比BoN（Best-of-N）更不容易受到长度偏差的影响。最后，我们还评估了结合前缀置信度的测试时训练，发现虽然它优于基础模型，但并未超越前缀置信度缩放。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [365] [Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning](https://arxiv.org/abs/2505.05086)
> *超越低秩分解：一种高效设备端学习的捷径方法*

*Le-Trung Nguyen, Ael Quelennec, Van-Tam Nguyen, Enzo Tartaglione* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 设备端学习, 内存效率, 计算效率, 捷径方法, 低秩分解

**Comment:** 

> **TL;DR:** 提出一种新的捷径方法，显著减少设备端学习的内存和计算开销，使其更高效。

**AI_Comments:** 该论文通过提出一种创新的“捷径方法”，有效解决了设备端学习中的关键挑战，即内存和计算开销。其创新之处在于提供了低秩分解的替代方案，并在效率上取得了显著提升，这对于资源受限设备上AI的广泛部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 设备端学习虽然在减少延迟、降低隐私风险和提高能效方面有优势，但其部署面临显著的内存和计算限制。现有低秩分解方法虽能解决激活内存瓶颈，但仍需更优的替代方案。

**Method:** 提出了一种新颖的“捷径方法”，作为现有低秩分解方法的替代方案，旨在解决反向传播中的激活内存瓶颈问题。

**Result:** 与传统训练相比，激活内存使用量减少高达120.09倍；总训练FLOPs减少高达1.86倍。

**Conclusion:** 所提出的捷径方法能够有效减少设备端学习中的内存和计算消耗，使其在资源受限设备上更具可行性。

> **ai_Abstract:** 本论文提出了一种新颖的“捷径方法”，旨在解决设备端学习面临的显著内存和计算限制。该方法作为低秩分解的替代方案，能将激活内存使用量减少高达120.09倍，并将总训练FLOPs减少高达1.86倍，从而显著提升设备端AI的效率。

> **摘要翻译:** 设备端学习已成为人工智能发展的一个有前景的方向，特别是因为它有可能减少与设备-服务器通信相关的延迟问题和隐私风险，同时提高能源效率。尽管有这些优点，显著的内存和计算限制仍然是其部署的主要挑战。借鉴先前关于低秩分解方法（用于解决反向传播中的激活内存瓶颈）的研究，我们提出了一种新颖的捷径方法作为替代方案。我们的分析和实验表明，与传统训练相比，我们的方法可以减少激活内存使用高达120.09倍，同时在传统基准测试中，总训练FLOPs也减少高达1.86倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [367] [SETOL: A Semi-Empirical Theory of (Deep) Learning](https://arxiv.org/abs/2507.17912)
> *SETOL：一种（深度）学习的半经验理论*

*Charles H Martin, Christopher Hinrichs* | **Category: cs.LG, cond-mat.stat-mech** | **Updated: 2025-07-23**

**Keywords:** 半经验理论, 深度学习, 神经网络, 重尾自正则化, 随机矩阵理论

**Comment:** 139 pages, 28 figures. Code for experiments available at
  https://github.com/charlesmartin14/SETOL_experiments

> **TL;DR:** 本文提出了一种半经验学习理论（SETOL），用以解释最先进神经网络的卓越性能，并提供了重尾自正则化（HTSR）现象学理论中关键量的形式化解释，引入了新度量ERG，并在简单MLP和SOTA NN上验证了其有效性。

**AI_Comments:** 本文创新性地提出了一个半经验理论（SETOL），将统计物理、随机矩阵理论和量子化学等多个前沿领域的知识融合，为深度学习的性能提供了理论解释。其重要性在于，它不仅形式化地解释了现有重尾自正则化理论中的关键指标，还提出了新的度量（ERG），并且这些指标在预测模型性能时无需训练或测试数据，这对于理解和评估大型预训练模型具有重要意义。在简单MLP和SOTA NN上的验证进一步增强了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 解释最先进（SOTA）神经网络的卓越性能，并为重尾自正则化（HTSR）现象学理论中的基本量（如重尾幂律层质量指标alpha和alpha-hat）提供形式化解释。

**Method:** 本文提出的SETOL理论结合了统计力学、随机矩阵理论和量子化学的先进方法。通过推导，提出新的理想学习的数学前提，包括一个新度量ERG，该度量等同于应用一步威尔逊精确重正化群。研究人员在一个简单的3层多层感知器（MLP）上测试了SETOL的假设和预测，并展示了如何通过计算层权重矩阵的经验谱密度（ESD）并将其代入SETOL公式来估计训练好的SOTA神经网络的单个层质量。

**Result:** SETOL理论为重尾自正则化（HTSR）现象学理论中的基本量（alpha和alpha-hat）提供了形式化解释。推导出了新的理想学习的数学前提，包括一个新的度量ERG。SETOL在简单的3层多层感知器（MLP）上与关键理论假设表现出极好的一致性。对于最先进的神经网络模型，展示了如何通过计算层权重矩阵的经验谱密度并将其代入SETOL公式来估计单个层质量。发现HTSR的alpha和SETOL的ERG层质量度量在MLP和最先进的神经网络上都表现出显著的一致性。

**Conclusion:** 本文提出的半经验学习理论（SETOL）成功解释了最先进神经网络的卓越性能，并为重尾自正则化理论中的关键量提供了形式化基础。新引入的ERG度量与现有HTSR alpha度量表现出良好的一致性，证明了SETOL在理解和评估神经网络层质量方面的有效性。

> **ai_Abstract:** 本文提出了一种名为SETOL的半经验学习理论，旨在解释最先进神经网络的出色表现。该理论为重尾自正则化（HTSR）现象学理论中的关键量（如alpha和alpha-hat）提供了形式化解释。SETOL结合了统计力学、随机矩阵理论和量子化学方法，并引入了一个新的理想学习度量ERG。研究在简单MLP上验证了SETOL的假设和预测，并展示了如何利用经验谱密度估计SOTA神经网络的层质量。实验结果表明，HTSR alpha和SETOL ERG在MLP和SOTA NN上均表现出高度一致性。

> **摘要翻译:** 我们提出了一种半经验学习理论（SETOL），它解释了最先进（SOTA）神经网络（NNs）的卓越性能。我们为重尾自正则化（HTSR）现象学理论中基本量的起源提供了形式化解释：即重尾幂律层质量指标alpha和alpha-hat。在之前的工作中，这些指标已被证明可以预测预训练SOTA NN模型的测试准确性趋势，重要的是，无需访问测试或训练数据。我们的SETOL利用了统计力学以及随机矩阵理论和量子化学的先进方法。推导提出了理想学习的新数学前提，包括一个新的度量ERG，它等同于应用一步威尔逊精确重正化群。我们在一个简单的3层多层感知器（MLP）上测试了SETOL的假设和预测，证明了与关键理论假设的极好一致性。对于SOTA NN模型，我们展示了如何通过简单计算层权重矩阵的经验谱密度（ESD）并将其代入我们的SETOL公式来估计训练好的NN的单个层质量。值得注意的是，我们检查了HTSR alpha和SETOL ERG层质量度量的性能，发现它们在我们的MLP和SOTA NN上都表现出显著的一致性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [369] [Neural Tangent Kernels and Fisher Information Matrices for Simple ReLU Networks with Random Hidden Weights](https://arxiv.org/abs/2507.18555)
> *随机隐藏权重的简单ReLU网络的神经正切核与费雪信息矩阵*

*Jun'ichi Takeuchia, Yoshinari Takeishia, Noboru Muratab, Kazushi Mimurac, Ka Long Keith Hod, Hiroshi Nagaoka* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 神经正切核, 费雪信息矩阵, ReLU网络, 谱分解, 函数近似

**Comment:** 

> **TL;DR:** 本文探讨了具有随机隐藏权重的两层ReLU网络的费雪信息矩阵和神经正切核（NTK），并展示了它们之间的线性变换关系，以及NTK的谱分解和函数近似公式。

**AI_Comments:** 这篇论文深入探讨了深度学习理论中的两个核心概念——神经正切核和费雪信息矩阵，特别是在随机初始化两层ReLU网络中的应用。其创新点在于揭示了这两个概念之间的线性变换关系，并提供了NTK的谱分解，这对于理解神经网络的训练动态和泛化能力具有重要意义。提出的函数近似公式也为分析神经网络的表达能力提供了工具。

<details>
  <summary>Details</summary>

**Motivation:** 探讨具有随机隐藏权重的两层ReLU网络中费雪信息矩阵和神经正切核（NTK）的性质及其相互关系。

**Method:** 讨论了费雪信息矩阵和NTK之间的线性变换关系，并展示了NTK的谱分解，包括其特征函数和主要特征值。此外，还导出了两层神经网络所表示函数的近似公式。

**Result:** 揭示了费雪信息矩阵和NTK之间的线性变换关系；展示了NTK的谱分解，包括具有主要特征值的具体形式的特征函数；获得了两层神经网络所表示函数的近似公式。

**Conclusion:** 本文成功探讨了随机隐藏权重两层ReLU网络的费雪信息矩阵和神经正切核，揭示了两者间的线性变换关系，并提供了NTK的谱分解和函数近似公式。

> **ai_Abstract:** 本文研究了具有随机隐藏权重的两层ReLU网络的费雪信息矩阵和神经正切核（NTK）。研究揭示了两者之间的线性变换关系，并提供了NTK的谱分解，包括其特征函数和主要特征值。此外，论文还提出了两层神经网络所表示函数的近似公式。

> **摘要翻译:** 费雪信息矩阵和具有随机隐藏权重的两层ReLU网络的神经正切核（NTK）被讨论。我们讨论了这两个概念作为线性变换之间的关系，并展示了NTK的谱分解，其具有主要特征值的具体形式的特征函数。我们还获得了由两层神经网络所表示函数的近似公式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits](https://arxiv.org/abs/2505.20268)
> *基于结果的在线强化学习：算法与基本限制*

*Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie* | **Category: cs.LG, cs.AI, math.ST, stat.ML, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 在线强化学习, 基于结果的反馈, 函数逼近, 样本复杂度, 信用分配

**Comment:** 

> **TL;DR:** 本文首次全面分析了基于结果反馈的在线强化学习问题，提出了一个样本高效的算法，并揭示了其统计分离的根本限制。

**AI_Comments:** 这篇论文的创新点在于首次对基于结果反馈的在线强化学习进行了全面理论分析，特别是在通用函数逼近的背景下。它不仅提出了一个样本高效的算法，还深入探讨了这种反馈机制的根本统计限制，包括与每步奖励的指数分离，这对于理解此类RL问题的复杂性和可行性至关重要。将方法扩展到偏好反馈也增加了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 当强化学习的奖励仅在轨迹终点观测到时，如何将信用正确分配给之前的动作，这是一个基本挑战。

**Method:** 论文首次对具有通用函数逼近的在线强化学习中的基于结果的反馈问题进行了全面分析。开发了一种可证明样本高效的算法，该算法利用通用函数逼近在大型或无限状态空间中有效工作。对于确定性MDP，消除了完备性假设。还将方法扩展到基于偏好的反馈设置。

**Result:** 提出的算法实现了 $\widetilde{O}({C_{\rm cov} H^3}/{\epsilon^2})$ 的样本复杂度，其中 $C_{\rm cov}$ 是底层MDP的覆盖系数。结果还揭示了基于结果的反馈与每步奖励在统计上的分离，对于某些MDP存在不可避免的指数分离。在基于偏好的反馈设置下也能达到等效的统计效率。

**Conclusion:** 这些结果共同构成了理解基于结果的强化学习统计特性的理论基础。

> **ai_Abstract:** 本文首次全面分析了基于结果反馈的在线强化学习中的信用分配问题，尤其是在通用函数逼近环境下。论文提出了一种样本高效的算法，适用于大型状态空间，并量化了其样本复杂度。研究还揭示了基于结果反馈与每步奖励之间的统计分离限制，并探讨了在确定性MDP和偏好反馈设置下的算法简化和扩展。这些发现为理解基于结果的强化学习提供了坚实的理论基础。

> **摘要翻译:** 强化学习中基于结果的反馈面临一个根本挑战：当奖励仅在轨迹终点观测到时，我们如何将信用分配给正确的动作？本文首次对在线强化学习中具有通用函数逼近的这一问题进行了全面分析。我们开发了一种可证明样本高效的算法，实现了 $\widetilde{O}({C_{\rm cov} H^3}/{\epsilon^2})$ 的样本复杂度，其中 $C_{\rm cov}$ 是底层MDP的覆盖系数。通过利用通用函数逼近，我们的方法在表格方法失效的大型或无限状态空间中也能有效工作，仅要求价值函数和奖励函数能被适当的函数类表示。我们的结果还表征了基于结果的反馈何时与每步奖励在统计上分离，揭示了对于某些MDP存在不可避免的指数分离。对于确定性MDP，我们展示了如何消除完备性假设，极大地简化了算法。我们进一步将方法扩展到基于偏好的反馈设置，证明即使在信息更有限的情况下也能实现等效的统计效率。总之，这些结果构成了理解基于结果的强化学习统计特性的理论基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [409] [From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models](https://arxiv.org/abs/2507.17922)
> *从种子到收获：利用AI增强人类创造力以对文本到图像模型进行红队测试*

*Jessica Quaye, Charvi Rastogi, Alicia Parrish, Oana Inel, Minsuk Kahng, Lora Aroyo, Vijay Janapa Reddi* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 文本到图像模型, 红队测试, 对抗性提示, 人机协作, 模型安全

**Comment:** 

> **TL;DR:** 论文提出Seed2Harvest，一种人机协作方法，用于生成多样化且有效的对抗性提示，以评估文本到图像模型的安全性。

**AI_Comments:** 该论文的创新点在于提出了人机协作的红队测试方法Seed2Harvest，有效结合了人类创造性（提供高质量“种子”）和机器的扩展能力（实现规模化和多样性）。这解决了现有方法在对抗性提示生成上的局限，为T2I模型的持续安全评估提供了更全面、高效的解决方案。其重要性在于强调了在AI时代，人类与机器协同工作在确保AI系统鲁棒性和安全性方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有对抗性提示生成方法（人类创作或合成生成）均有局限：人类创作规模小、代表性不足；合成生成缺乏真实性和创造性。因此，需要结合两者优势，以实现全面、可扩展的红队测试。

**Method:** 提出Seed2Harvest，一种混合红队测试方法，用于指导性扩展文化多样化的人工对抗性提示“种子”，旨在结合人类和机器方法的优点。

**Result:** 生成的提示保留了人类提示的特征和攻击模式，并保持了可比的平均攻击成功率（NudeNet 0.31，SD NSFW 0.36，Q16 0.12）。扩展后的数据集多样性显著提高，包含535个独特的地理位置和7.48的香农熵，而原始数据集为58个位置和5.28的熵。

**Conclusion:** 本工作展示了人机协作在利用人类创造力和机器计算能力方面的重要性，以实现全面、可扩展的红队测试，用于持续的T2I模型安全评估。

> **ai_Abstract:** 本论文提出了一种名为Seed2Harvest的混合红队测试方法，旨在结合人类创造性和机器扩展能力，生成多样化且有效的对抗性提示，用于评估文本到图像（T2I）模型的安全性。针对现有方法在规模、多样性和真实性上的不足，Seed2Harvest通过指导性扩展人类创作的提示种子，成功生成了保留人类攻击模式、保持高攻击成功率并显著提高数据集多样性的新提示，证明了人机协作在T2I模型安全评估中的关键作用。

> **摘要翻译:** 文本到图像 (T2I) 模型已在众多应用中普及，因此对其对抗性攻击的鲁棒性评估成为一项关键优先事项。持续获取跨不同领域的新颖且具有挑战性的对抗性提示，对于压力测试这些模型抵御来自多个向量的新型攻击的弹性至关重要。目前生成此类提示的技术要么完全由人类创作，要么是合成生成。一方面，人类创作的对抗性提示数据集通常规模太小，并且在文化和语境表示方面存在不平衡。另一方面，合成生成的提示数据集虽然达到了规模，但通常缺乏人类创作提示中发现的真实细微差别和创造性对抗策略。为了结合人类和机器方法的优点，我们提出了 Seed2Harvest，这是一种混合红队测试方法，用于指导性扩展文化多样化、人类创作的对抗性提示“种子”。生成的提示保留了人类提示的特征和攻击模式，同时保持了可比的平均攻击成功率（NudeNet 0.31，SD NSFW 0.36，Q16 0.12）。我们扩展的数据集多样性显著提高，拥有535个独特的地理位置和7.48的香农熵，而原始数据集只有58个位置和5.28的熵。我们的工作展示了人机协作在利用人类创造力和机器计算能力方面的重要性，以实现全面、可扩展的红队测试，用于持续的T2I模型安全评估。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [410] [Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions](https://arxiv.org/abs/2507.18139)
> *具身智能自主系统中的神经拟态计算：当前趋势、挑战与未来方向*

*Alberto Marchisio, Muhammad Shafique* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 神经拟态计算, 自主系统, 具身智能, 脉冲神经网络, 事件驱动传感器

**Comment:** To appear at the 31st IEEE International Symposium on On-Line Testing
  and Robust System Design (IOLTS), Ischia, Italy, July 2025

> **TL;DR:** 本文综述了神经拟态计算在自主系统中的应用，涵盖了当前趋势、挑战和未来方向，尤其强调其在提升能效和适应性方面的潜力。

**AI_Comments:** 这篇综述文章系统地梳理了神经拟态计算在自主系统中的应用现状、挑战和未来方向，其多学科视角（机器学习、机器人学、神经科学、神经拟态工程）使其具有较高的广度和深度。文章强调了神经拟态计算在提升能效和鲁棒性方面的潜力，并指出了实时决策和持续学习等关键挑战，对该领域的研究人员具有重要的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 机器人、移动代理（如无人机）和自动驾驶汽车等领域对智能、自适应、高能效自主系统的日益增长的需求，推动了对神经拟态计算的兴趣。神经拟态方法通过借鉴生物神经网络，有望增强自主平台的感知、决策和响应能力。

**Method:** 本文综述了神经拟态算法、专用硬件和跨层优化策略的最新进展，重点关注其在实际自主场景中的部署。特别关注事件驱动的动态视觉传感器及其在实现快速高效感知中的作用。文章整合了机器学习、机器人学、神经科学和神经拟态工程的视角。

**Result:** 讨论强调了通过将脉冲神经网络集成到自主系统架构中，可以提高自主系统的能效、鲁棒性、适应性和可靠性。

**Conclusion:** 文章探讨了新兴趋势和开放挑战，特别是实时决策、持续学习以及安全、弹性自主系统的开发。

> **ai_Abstract:** 本文综述了神经拟态计算在具身智能自主系统中的应用，旨在满足对智能、自适应、高能效自主系统的需求。文章探讨了神经拟态算法、专用硬件和跨层优化策略的最新进展，尤其关注事件驱动的动态视觉传感器。研究强调了神经拟态方法通过集成脉冲神经网络，能够提升自主系统的能效、鲁棒性、适应性和可靠性。最后，论文讨论了实时决策、持续学习以及安全弹性自主系统开发等新兴趋势和开放挑战。

> **摘要翻译:** 对机器人、移动代理（例如无人机）和自动驾驶汽车等领域中对智能、自适应、高能效自主系统日益增长的需求，正在推动人们对神经拟态计算的兴趣。通过借鉴生物神经网络，神经拟态方法为增强自主平台的感知、决策和响应能力提供了有前景的途径。本文综述了神经拟态算法、专用硬件和跨层优化策略的最新进展，重点关注它们在现实世界自主场景中的部署。文章特别关注事件驱动的动态视觉传感器及其在实现快速、高效感知中的作用。讨论强调了通过将脉冲神经网络集成到自主系统架构中，可以提高能效、鲁棒性、适应性和可靠性的新方法。我们整合了机器学习、机器人学、神经科学和神经拟态工程的视角，以提供对该领域现状的全面看法。最后，探讨了新兴趋势和开放挑战，特别是在实时决策、持续学习以及安全、弹性自主系统开发方面。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [411] [Beyond Internal Data: Constructing Complete Datasets for Fairness Testing](https://arxiv.org/abs/2507.18561)
> *超越内部数据：构建用于公平性测试的完整数据集*

*Varsha Ramineni, Hossein A. Rahmani, Emine Yilmaz, David Barber* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 公平性测试, 合成数据, 数据稀缺, 人口统计数据, AI偏见

**Comment:** 9 pages, 6 figures

> **TL;DR:** 本文提出了一种利用重叠数据集构建合成数据的方法，以克服在AI公平性测试中真实人口统计数据稀缺的挑战，并证明了其有效性。

**AI_Comments:** 该论文提出了一种创新的方法来解决AI公平性测试中数据稀缺的关键问题，特别是在隐私和法律限制严格的工业环境中。通过构建合成数据，它为独立审计和持续的公平性评估提供了一条实用路径，这对于AI的负责任部署至关重要。其创新点在于利用现有重叠数据构建完整数据集，有效规避了直接收集敏感数据的难题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI在风险领域和决策中的普及，测试潜在危害和偏见变得至关重要。全球AI法规的出现强调公平性和充分测试，甚至要求独立的偏见审计。然而，获取进行公平性测试所需的数据是一个重大挑战，尤其是在工业环境中，法律和隐私问题限制了人口统计数据的收集，且内部历史数据集往往不足以识别真实世界的偏见。

**Method:** 当包含人口统计信息的完整数据集不可访问时，本文提出利用单独的重叠数据集来构建完整的合成数据。这种合成数据包括人口统计信息，并能准确反映受保护属性和模型特征之间的潜在关系。

**Result:** 通过与真实数据比较，验证了合成数据的保真度。实证表明，从合成数据测试中得出的公平性指标与从真实数据中获得的指标一致。

**Conclusion:** 这项工作为克服公平性测试中真实数据稀缺的问题提供了一条途径，从而实现了独立、模型无关的公平性评估，并可在真实数据有限的情况下作为可行的替代方案。

> **ai_Abstract:** 本文针对AI公平性测试中真实人口统计数据难以获取的挑战，提出了一种创新方法。该方法通过整合不同的重叠数据集来生成包含人口统计信息的合成数据，以克服隐私限制和数据代表性不足的问题。研究验证了合成数据的准确性，并证明了基于合成数据得出的公平性评估结果与真实数据一致。这为在数据受限情况下进行独立、模型无关的公平性评估提供了可行的解决方案。

> **摘要翻译:** 随着人工智能在风险领域和决策制定中的普及，测试潜在的危害和偏见至关重要。全球人工智能法规的出现反映了这种紧迫性，这些法规强调公平性和充分的测试，有些甚至强制要求进行独立的偏见审计。然而，获取公平性测试所需的数据仍然是一个重大挑战。特别是在工业环境中，法律和隐私问题限制了评估群体差异所需的人口统计数据的收集，并且审计人员在获取数据方面面临实际和文化上的挑战。此外，内部历史数据集往往代表性不足，无法识别真实世界的偏见。这项工作侧重于在包含人口统计信息的完整数据集无法访问时评估分类器的公平性。我们提出利用单独的重叠数据集来构建完整的合成数据，这些数据包含人口统计信息并准确反映受保护属性和模型特征之间的潜在关系。我们通过将合成数据与真实数据进行比较来验证其保真度，并实证证明从这种合成数据测试中得出的公平性指标与从真实数据中获得的指标一致。因此，这项工作为克服公平性测试中真实数据稀缺的问题提供了一条途径，从而实现了独立、模型无关的公平性评估，并在真实数据有限的情况下作为可行的替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [413] [VCDiag: Classifying Erroneous Waveforms for Failure Triage Acceleration](https://arxiv.org/abs/2506.03590)
> *VCDiag：用于加速故障分类的错误波形分类器*

*Minh Luu, Surya Jasper, Khoi Le, Evan Pan, Michael Quinn, Aakash Tyagi, Jiang Hu* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 故障分类, 波形分析, 机器学习, VCD数据, RTL级仿真

**Comment:** 

> **TL;DR:** VCDiag是一个使用VCD数据对设计验证中的错误波形进行分类并定位故障的机器学习框架，显著提高了故障分类效率和数据处理能力。

**AI_Comments:** VCDiag的创新之处在于其将机器学习应用于以往依赖人工的RTL级仿真故障分类，特别是其新颖的信号选择和统计压缩方法，显著解决了处理VCD大数据量的挑战。这对于提高验证效率和缩短产品上市时间具有重要意义。其高准确率和良好的集成性也使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 设计功能验证中的故障分类至关重要但耗时，目前依赖人工审查、日志检查和波形分析。尽管机器学习已在某些领域有所改进，但在RTL级仿真故障分类，特别是大型设计方面，应用有限。

**Method:** VCDiag提出一种高效、适应性强的方法，利用VCD数据分类错误波形并定位可能的故障位置。该框架引入了一种新颖的信号选择和统计压缩方法。

**Result:** 在最大规模的实验中，VCDiag在识别前三个最可能的模块方面达到了超过94%的准确率。该方法实现了原始数据大小超过120倍的缩减，同时保留了分类所需的关键特征。

**Conclusion:** VCDiag为RTL级仿真故障分类提供了一个高效、可集成且准确的机器学习解决方案，显著加速了故障分类流程并解决了数据量大的挑战。

> **ai_Abstract:** VCDiag是一个机器学习框架，旨在加速设计功能验证中的故障分类。它通过分析VCD数据来分类错误的波形并识别可能的故障位置。该框架采用创新的信号选择和统计压缩技术，将原始数据量减少了120多倍，同时保持了高分类精度（识别前三名模块的准确率超过94%），并且能够灵活集成到现有的Verilog/SystemVerilog设计环境中。

> **摘要翻译:** 设计功能验证中的故障分类至关重要但耗时，它依赖于人工规范审查、日志检查和波形分析。虽然机器学习（ML）已经改进了激励生成和覆盖率闭合等领域，但其在RTL级仿真故障分类，特别是大型设计中的应用仍然有限。VCDiag提供了一种高效、适应性强的方法，利用VCD数据对失效波形进行分类并找出可能的故障位置。在最大的实验中，VCDiag在识别前三个最可能的模块方面达到了超过94%的准确率。该框架引入了一种新颖的信号选择和统计压缩方法，实现了原始数据大小超过120倍的缩减，同时保留了分类所需的关键特征。它还可以集成到各种Verilog/SystemVerilog设计和测试平台中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [414] [Lower Bounds for Public-Private Learning under Distribution Shift](https://arxiv.org/abs/2507.17895)
> *公共-私人学习在分布偏移下的下界*

*Amrith Setlur, Pratiksha Thaker, Jonathan Ullman* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-23**

**Keywords:** 公共-私人学习, 分布偏移, 下界, 差分隐私, 机器学习

**Comment:** Preprint

> **TL;DR:** 本文研究了在存在显著分布偏移的情况下，公共数据在差分隐私机器学习中的作用。结果表明，当偏移较小时，公共或私人数据必须足够丰富；而当偏移较大时，公共数据没有益处。

**AI_Comments:** 本文创新性地将公共-私人学习的下界研究扩展到更实际的分布偏移场景，填补了现有理论的空白。它揭示了在不同程度的分布偏移下，公共数据对于差分隐私学习的效用边界，对于理解和设计更鲁棒的公共-私人机器学习算法具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的差分隐私机器学习算法常依赖公共数据，但当数据源分布相同时，已知下界表明公共数据没有互补价值。本文旨在将公共-私人学习的下界扩展到存在显著分布偏移的场景。

**Method:** 本文将已知的公共-私人学习下界扩展到存在显著分布偏移的设置。具体应用于高斯均值估计（均值不同）和高斯线性回归（参数偏移）模型。

**Result:** 结果显示，当分布偏移较小（相对于所需精度）时，公共或私人数据必须足够丰富才能估计私人参数。相反，当偏移较大时，公共数据不提供任何益处。

**Conclusion:** 在公共-私人学习中，当数据源存在显著分布偏移时，公共数据的益处受到限制；特别是当偏移量较大时，公共数据将失去价值。

> **ai_Abstract:** 本文研究了在公共-私人学习范式下，当公共数据和私人数据之间存在分布偏移时，公共数据所能提供的价值。作者扩展了现有的下界理论，并将其应用于高斯均值估计和高斯线性回归。研究发现，当分布偏移较小且相对于所需精度时，公共或私人数据必须足够丰富；而当偏移较大时，公共数据将不再带来任何益处，揭示了公共数据在分布偏移场景下的局限性。

> **摘要翻译:** 实践中最有效的差分隐私机器学习算法依赖于额外的“公共”数据源。当这两种数据源结合起来的价值大于其各部分之和时，这种范式最为有趣。然而，在诸如均值估计等场景中，我们有很强的下界，表明当两个数据源具有相同分布时，结合两个数据源没有互补价值。在这项工作中，我们将已知的公共-私人学习下界扩展到两个数据源表现出显著分布偏移的设置。我们的结果适用于两种情况：高斯均值估计（其中两个分布具有不同的均值），以及高斯线性回归（其中两个分布表现出参数偏移）。我们发现，当偏移量较小（相对于所需精度）时，公共数据或私人数据必须足够丰富才能估计私人参数。相反，当偏移量较大时，公共数据不提供任何益处。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [437] [On the Convergence of Gradient Descent on Learning Transformers with Residual Connections](https://arxiv.org/abs/2506.05249)
> *关于梯度下降在学习带有残差连接的Transformer模型上的收敛性研究*

*Zhen Qin, Jinxin Zhou, Zhihui Zhu* | **Category: cs.LG, math.OC** | **Updated: 2025-07-24**

**Keywords:** Transformer, 梯度下降, 残差连接, 收敛性, 优化稳定性

**Comment:** 

> **TL;DR:** 本文理论分析了带有残差连接的Transformer模型在梯度下降训练下的收敛行为，证明了其线性收敛性，并揭示了残差连接对优化稳定性的积极作用。

**AI_Comments:** 本文的创新之处在于首次系统地分析了包含自注意力、前馈网络和残差连接的完整Transformer模型的收敛性，而非仅关注孤立组件。它明确揭示了残差连接在改善模型优化稳定性方面的关键理论作用，填补了Transformer理论基础的空白，对理解和设计更稳定的深度学习模型具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Transformer模型在实践中取得了巨大成功，但其理论基础，特别是训练动态的理解，仍相对不足。现有研究多集中于孤立组件，未能充分探讨组件间的相互依赖性，尤其是在存在残差连接的情况下。

**Method:** 通过分析一个结构完整但单层的Transformer模型（包含自注意力、前馈网络和残差连接）的收敛行为。随后将理论发现扩展到多层Transformer架构。

**Result:** 在适当初始化下，梯度下降表现出线性收敛速率，收敛速度由注意力层输出矩阵的最小和最大奇异值决定。残差连接有助于改善输出矩阵的病态性，从而提高优化稳定性。

**Conclusion:** 梯度下降在学习带有残差连接的Transformer模型时具有线性收敛速率，且残差连接通过改善输出矩阵的病态性，显著增强了优化稳定性。

> **ai_Abstract:** 本文深入研究了带有残差连接的Transformer模型在梯度下降训练下的收敛性。研究发现，在适当初始化条件下，单层和多层Transformer模型的梯度下降均能实现线性收敛，其速度受注意力层输出矩阵奇异值的影响。重要的是，研究揭示残差连接能有效缓解该输出矩阵因softmax操作导致的病态问题，从而显著提升了模型的优化稳定性和收敛性。理论分析得到了经验结果的验证。

> **摘要翻译:** Transformer模型因其在各种应用中的出色性能，已成为跨多个科学和工程领域的基础工具。尽管取得了这些经验上的成功，但Transformer的理论基础仍然相对不完善，特别是在理解其训练动态方面。现有研究主要考察孤立的组件——如自注意力机制和前馈网络——而没有彻底研究这些组件之间的相互依赖性，尤其是在存在残差连接的情况下。在本文中，我们旨在通过分析一个结构完整但单层的Transformer模型（包含自注意力、前馈网络和残差连接）的收敛行为来弥补这一空白。我们证明，在适当的初始化下，梯度下降表现出线性收敛速率，其中收敛速度由注意力层输出矩阵的最小和最大奇异值决定。此外，我们的分析揭示，残差连接有助于改善该输出矩阵的病态性，这个问题源于softmax操作强加的低秩结构，从而促进了增强的优化稳定性。我们还将我们的理论发现扩展到多层Transformer架构，证实了在适当初始化下梯度下降的线性收敛速率。经验结果证实了我们的理论见解，说明了残差连接在促进收敛稳定性方面的有益作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [453] [Linear Memory SE(2) Invariant Attention](https://arxiv.org/abs/2507.18597)
> *线性内存SE(2)不变性注意力*

*Ethan Pronovost, Neha Boloor, Peter Schleede, Noureldin Hendy, Andres Morales, Nicholas Roy* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** SE(2)不变性, 注意力, 线性内存, Transformer, 自动驾驶

**Comment:** Best paper award, Equivariant Systems Workshop at RSS

> **TL;DR:** 本文提出了一种线性内存SE(2)不变性注意力机制，用于解决自动驾驶中空间数据处理的二次方内存问题，提高了性能和可扩展性。

**AI_Comments:** 本文的创新之处在于将SE(2)不变性注意力的内存复杂度从二次方降低到线性，使其在处理包含大量物体的实际自动驾驶应用中更具可扩展性。与大型语言模型扩展特性的关联也是一个值得注意的方面。其重要性在于能够实现更高效、更大规模的空间数据处理。

<details>
  <summary>Details</summary>

**Motivation:** 在自动驾驶等学习任务中，处理空间数据至关重要。先前的SE(2)不变网络架构通过显式计算所有物体对的相对姿态来处理空间数据，但这导致了二次方的内存需求，限制了其可扩展性。

**Method:** 本文提出了一种SE(2)不变的缩放点积注意力机制，该机制相对于场景中物体的数量只需要线性内存。该方法采用了一种SE(2)不变的Transformer架构。

**Result:** 实验证明，所提出的方法易于实现，并且与可比较的非不变架构相比，性能有所提升。它还具备与近年来大型语言模型相同的扩展特性。

**Conclusion:** 所提出的线性内存SE(2)不变性注意力机制在处理空间数据方面具有实用性，能够提高性能，并为自动驾驶等任务提供更好的可扩展性。

> **ai_Abstract:** 本文介绍了一种新颖的SE(2)不变缩放点积注意力机制，旨在解决自动驾驶中用于空间数据处理的先前SE(2)不变方法所存在的二次方内存需求问题。通过实现线性内存复杂度，所提出的SE(2)不变Transformer架构提供了改进的可扩展性，类似于大型语言模型，并且实验证明其具有实用性，且性能优于非不变的替代方案。

> **摘要翻译:** 处理空间数据是自动驾驶中许多学习任务的关键组成部分，例如运动预测、多智能体模拟和规划。先前的研究已经证明了使用SE(2)不变网络架构的价值，这些架构只考虑物体（例如其他智能体、交通车道等场景特征）之间的相对姿态。然而，这些方法显式计算所有物体对的相对姿态，需要二次方的内存。在这项工作中，我们提出了一种SE(2)不变缩放点积注意力机制，该机制相对于场景中物体的数量只需要线性内存。我们的SE(2)不变Transformer架构具有与近年来大型语言模型相同的扩展特性。我们通过实验证明，我们的方法实用且与可比较的非不变架构相比提高了性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [456] [Remembering the Markov Property in Cooperative MARL](https://arxiv.org/abs/2507.18333)
> *合作多智能体强化学习中马尔可夫性质的回归*

*Kale-ab Abebe Tessera, Leonard Hinckeldey, Riccardo Zamboni, David Abel, Amos Storkey* | **Category: cs.LG, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 合作多智能体强化学习, 马尔可夫性质, Dec-POMDP, 基准设计, 约定

**Comment:** RLC Finding the Frame Workshop Camera-Ready, 8 pages

> **TL;DR:** 当前合作多智能体强化学习（MARL）算法的成功并非源于有效的马尔可夫信号恢复，而是学习了脆弱的约定，导致基准测试未能充分检验核心假设。本论文倡导设计新的环境，以促进基于观察和记忆的真正技能学习。

**AI_Comments:** 本文作为一篇立场论文，对当前合作MARL领域的一个核心问题提出了深刻见解。其创新之处在于挑战了对现有算法成功原因的普遍认知，并明确指出基准测试设计是导致智能体学习脆弱约定的关键因素。其重要性在于呼吁社区重新思考MARL环境的设计，强调需要回归马尔可夫性质，即基于观察和记忆的推理，以推动更稳健、更具泛化能力的智能体发展。这对于未来MARL研究方向具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前无模型多智能体强化学习（MARL）算法的经验成功被错误地归因于马尔可夫信号恢复。实际上，它们学习的是绕过环境观察和记忆的简单约定。本论文旨在指出这一问题，并揭示现有基准测试的不足。

**Method:** 通过一个有针对性的案例研究，论文展示了共同适应的智能体如何学习脆弱的约定，这些约定在与非适应性智能体合作时会失败。论文还分析了现有MARL环境，指出它们可能未能充分检验去中心化部分可观察马尔可夫决策过程（Dec-POMDP）的核心假设。

**Result:** 研究表明，共同适应的智能体可以学习脆弱的约定，当与非适应性智能体合作时这些约定会失效。同样的模型在任务设计需要时可以学习到基于观察的策略，这表明问题不在于学习模型的根本局限性，而是基准设计的缺陷。分析还指出，现代MARL环境可能未能充分测试Dec-POMDP的核心假设。

**Conclusion:** 本论文主张开发新的合作环境，这些环境应建立在两个核心原则之上：(1) 行为基于观察，以及 (2) 基于记忆对其他智能体进行推理。这确保了成功需要真正的技能，而非脆弱的、共同适应的协议。

> **ai_Abstract:** 本立场论文探讨了合作多智能体强化学习（MARL）中，当前无模型算法的成功并非源于有效的马尔可夫信号恢复，而是学习了脆弱的约定。通过案例研究，论文指出这些约定在与非适应性智能体合作时会失败，并揭示了现有基准测试设计的缺陷，未能充分检验去中心化部分可观察马尔可夫决策过程（Dec-POMDP）的核心假设。因此，论文倡导设计新的合作环境，这些环境应促进基于观察的行为和基于记忆的智能体间推理，以鼓励真正的技能学习。

> **摘要翻译:** 合作多智能体强化学习（MARL）通常被形式化为去中心化部分可观察马尔可夫决策过程（Dec-POMDP），其中智能体必须对环境和其他智能体的行为进行推理。在实践中，当前无模型的MARL算法使用简单的循环函数逼近器来解决利用部分信息对他人进行推理的挑战。在这篇立场论文中，我们认为这些方法的经验成功并非源于有效的马尔可夫信号恢复，而是学习了绕过环境观察和记忆的简单约定。通过一个有针对性的案例研究，我们表明共同适应的智能体可以学习脆弱的约定，这些约定在与非适应性智能体合作时会失败。至关重要的是，当任务设计需要时，相同的模型可以学习到基于观察的策略，这表明问题并非学习模型的根本局限性，而是基准设计的失败。我们的分析还表明，现代MARL环境可能未能充分测试Dec-POMDP的核心假设。因此，我们倡导构建基于两个核心原则的新合作环境：（1）行为基于观察，以及（2）基于记忆对其他智能体进行推理，确保成功需要真正的技能而非脆弱的、共同适应的协议。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [457] [UrbanPulse: A Cross-City Deep Learning Framework for Ultra-Fine-Grained Population Transfer Prediction](https://arxiv.org/abs/2507.17924)
> *UrbanPulse：一种用于超精细粒度人口转移预测的跨城市深度学习框架*

*Hongrong Yang, Markus Schlaepfer* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 人口转移预测, 深度学习, 迁移学习, 城市规划, 兴趣点

**Comment:** 

> **TL;DR:** UrbanPulse是一个可扩展的深度学习框架，通过将每个POI视为独立节点，实现了超精细粒度的跨城市人口OD流预测，并采用三阶段迁移学习策略，在加州三个大都市区的GPS记录上达到了最先进的准确性和可扩展性。

**AI_Comments:** UrbanPulse的创新之处在于其将每个POI视为独立节点，实现了超精细粒度的OD流预测，这显著提升了预测的实用性。其三阶段迁移学习策略有效解决了深度学习模型在跨城市泛化方面的挑战，使其能够适应不同的城市环境。这对于城市规划和交通管理具有重要意义，因为它提供了一个可部署的、高分辨率的AI驱动预测工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的预测人口流动的模型面临局限性：传统模型依赖静态空间假设，深度学习模型难以跨城市泛化，大型语言模型（LLMs）计算成本高且无法捕捉空间结构。此外，许多方法通过聚类兴趣点（POIs）或限制覆盖范围来牺牲分辨率，从而限制了其在全市范围分析中的实用性。

**Method:** 本文引入了UrbanPulse，一个可扩展的深度学习框架，通过将每个兴趣点（POI）视为独立节点，实现超精细粒度的全市OD流预测。它结合了一个时间图卷积编码器和一个基于Transformer的解码器来建模多尺度时空依赖性。为确保在不同城市环境中的鲁棒泛化能力，UrbanPulse采用了三阶段迁移学习策略：在大规模城市图上进行预训练、冷启动适应和强化学习微调。

**Result:** UrbanPulse在来自加州三个大都市区的超过1.03亿条清洗过的GPS记录上进行了评估，实现了最先进的准确性和可扩展性。

**Conclusion:** 通过高效的迁移学习，UrbanPulse在使高分辨率、AI驱动的城市预测在不同城市中实际部署方面迈出了关键一步。

> **ai_Abstract:** UrbanPulse是一个创新的深度学习框架，旨在克服现有方法的局限性，实现超精细粒度的跨城市人口OD流预测。它将每个兴趣点（POI）视为独立节点，并结合了时间图卷积编码器和Transformer解码器来捕捉复杂的时空依赖性。为确保跨城市泛化能力，UrbanPulse采用独特的三阶段迁移学习策略。在加州三个大都市区的实际GPS数据上进行评估，UrbanPulse展现了卓越的准确性和可扩展性，为城市规划和管理提供了实用的高分辨率AI预测能力。

> **摘要翻译:** 人口流动预测对于城市规划、交通管理和公共卫生至关重要。然而，现有方法面临关键局限性：传统模型依赖静态空间假设，深度学习模型难以跨城市泛化，大型语言模型（LLMs）计算成本高昂且未能捕捉空间结构。此外，许多方法通过聚类兴趣点（POIs）或限制覆盖范围来牺牲分辨率，从而限制了它们在全市范围分析中的实用性。我们引入了UrbanPulse，一个可扩展的深度学习框架，通过将每个POI视为独立节点，实现超精细粒度的全市OD流预测。它结合了一个时间图卷积编码器和一个基于Transformer的解码器来建模多尺度时空依赖性。为确保在不同城市环境中的鲁棒泛化能力，UrbanPulse采用了三阶段迁移学习策略：在大规模城市图上进行预训练、冷启动适应和强化学习微调。在来自加州三个大都市区的超过1.03亿条清洗过的GPS记录上进行评估，UrbanPulse实现了最先进的准确性和可扩展性。通过高效的迁移学习，UrbanPulse在使高分辨率、AI驱动的城市预测在不同城市中实际部署方面迈出了关键一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [458] [When Noisy Labels Meet Class Imbalance on Graphs: A Graph Augmentation Method with LLM and Pseudo Label](https://arxiv.org/abs/2507.18153)
> *当噪声标签遇到图上的类别不平衡：一种结合LLM和伪标签的图增强方法*

*Riting Xia, Rucong Wang, Yulin Liu, Anchen Li, Xueyan Liu, Yan Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 图节点分类, 类别不平衡, 噪声标签, 图增强, LLM, 伪标签

**Comment:** 

> **TL;DR:** 本文提出了GraphALP，一个结合LLM和伪标签的图增强框架，旨在解决图节点分类中类别不平衡和噪声标签的问题，并取得了优越的性能。

**AI_Comments:** 该论文通过同时处理类别不平衡和噪声标签，解决了现实世界中的一个关键问题，这相对于之前假设干净标签的工作是一个重大进步。将LLM用于图增强和伪标签用于噪声消除的创新集成尤其具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的类别不平衡图节点分类方法通常假设标签是干净可靠的，但这与真实世界图中标签常含有噪声的性质不符。本文旨在解决带噪声标签的类别不平衡图上的鲁棒节点分类问题。

**Method:** 本文提出了GraphALP框架。它首先设计了一种基于LLM的过采样方法来生成合成少数类节点，以缓解类别不平衡。接着，开发了一种动态加权伪标签方法来获得高置信度伪标签，以降低标签噪声比。最后，实施了第二次由LLM引导的过采样机制，以减轻伪标签可能引起的类别分布偏差。

**Result:** 实验结果表明，GraphALP在带噪声标签的类别不平衡图上，其性能优于最先进的方法。

**Conclusion:** GraphALP有效地解决了图节点分类中噪声标签和类别不平衡的挑战，性能优于现有方法。

> **ai_Abstract:** 本文提出了GraphALP，一个图增强框架，用于解决带噪声标签的类别不平衡图上的鲁棒节点分类这一未充分研究的问题。GraphALP利用大型语言模型（LLM）进行过采样以平衡类别，并采用动态加权伪标签方法来减少标签噪声。此外，二次LLM引导的过采样进一步减轻了分布偏差。实验证明GraphALP表现出卓越的性能。

> **摘要翻译:** 图节点分类中的类别不平衡是一个实际但尚未充分研究的问题。尽管最近的研究试图解决这个问题，但它们在处理类别不平衡图时通常假设标签是干净可靠的。这一假设常常与现实世界图的性质相悖，因为现实世界图中的标签经常包含噪声。鉴于此差距，本文系统地研究了针对带噪声标签的类别不平衡图的鲁棒节点分类。我们提出了GraphALP，一个基于大型语言模型（LLM）和伪标签技术的新型图增强框架。具体来说，我们设计了一种基于LLM的过采样方法来生成合成少数类节点，从而产生标签准确的少数类节点以缓解类别不平衡。在类别平衡的图上，我们开发了一种动态加权伪标签方法，以获得高置信度的伪标签，从而降低标签噪声比。此外，我们还实施了第二次由LLM引导的过采样机制，以减轻伪标签可能引起的类别分布偏差。实验结果表明，GraphALP在带噪声标签的类别不平衡图上，其性能优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [461] [Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems](https://arxiv.org/abs/2506.06021)
> *Unisoma：一种统一的基于Transformer的多固体系统求解器*

*Shilong Tao, Zhe Feng, Haonan Sun, Zhanxing Zhu, Yunhuai Liu* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 多固体系统, Transformer, 显式建模, 物理交互, 深度学习

**Comment:** Proceedings of the 42nd International Conference on Machine Learning

> **TL;DR:** Unisoma是一种新颖的基于Transformer的模型，通过显式建模来解决多固体系统中的复杂物理交互，并在多个数据集和任务上达到了最先进的性能。

**AI_Comments:** Unisoma的创新之处在于其提出的显式建模范式，它克服了传统隐式建模在处理复杂多固体系统时信息混合和混淆的问题。通过结合Transformer架构、接触模块和自适应交互分配，该模型提供了一个统一且灵活的解决方案，能够有效地处理可变数量的固体，并在实际应用中展现出强大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习方法在建模多固体系统的复杂交互时，主要依赖隐式建模，难以精确捕捉复杂的物理交互，特别是当固体数量增加时。这导致信息混合和混淆。

**Method:** 本文引入了一种新颖的显式建模范式，通过结构化模块整合影响固体变形的因素。具体来说，提出了Unisoma，一个统一且灵活的基于Transformer的模型，能够处理可变数量的固体。Unisoma利用接触模块和自适应交互分配机制直接捕捉物理交互，并通过三元组关系学习变形。

**Result:** Unisoma在七个成熟的数据集和两个复杂的多固体任务上实现了持续的最先进性能。

**Conclusion:** 显式建模比隐式建模更适合具有多样耦合模式的多固体系统，因为它能对每个固体进行详细处理，同时防止信息混合和混淆。Unisoma通过其统一的Transformer架构和显式交互机制，成功解决了多固体系统的复杂建模挑战，并取得了优异的性能。

> **ai_Abstract:** 本文提出了一种名为Unisoma的统一Transformer模型，用于解决多固体系统的复杂交互建模问题。针对现有隐式建模方法在固体数量增加时性能下降的挑战，Unisoma引入了一种显式建模范式，通过结构化模块、接触模块和自适应交互分配机制直接捕捉物理交互，并通过三元组关系学习变形。实验证明，Unisoma在多个数据集和任务上均达到了最先进的性能，表明显式建模在处理多样耦合模式的多固体系统方面具有优越性。

> **摘要翻译:** 多固体系统是广泛现实世界应用的基础，但对其复杂交互的建模仍然具有挑战性。现有深度学习方法主要依赖隐式建模，其中影响固体变形的因素未被明确表示，而是间接学习。然而，随着固体数量的增加，这些方法难以准确捕捉复杂的物理交互。在本文中，我们引入了一种新颖的显式建模范式，通过结构化模块整合影响固体变形的因素。具体来说，我们提出了Unisoma，一个统一且灵活的基于Transformer的模型，能够处理可变数量的固体。Unisoma利用接触模块和自适应交互分配机制直接捕捉物理交互，并通过三元组关系学习变形。与隐式建模技术相比，显式建模更适合具有多样耦合模式的多固体系统，因为它能够对每个固体进行详细处理，同时防止信息混合和混淆。实验表明，Unisoma在七个成熟的数据集和两个复杂的多固体任务上实现了持续的最先进性能。代码可在https://github.com/therontau0054/Unisoma获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [476] [Fine-Grained Uncertainty Quantification via Collisions](https://arxiv.org/abs/2411.12127)
> *通过碰撞实现细粒度不确定性量化*

*Jesse Friedbaum, Sudarshan Adiga, Ravi Tandon* | **Category: cs.LG, cs.IT, math.IT, math.ST, stat.ML, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 不确定性量化, 类别碰撞, 碰撞矩阵, 对比学习, 任意不确定性

**Comment:** 

> **TL;DR:** 本文提出了一种新的、直观的度量方法，即类别碰撞的普遍性，用于量化任意不确定性，并引入碰撞矩阵作为细粒度的不确定性度量，同时提出了一系列创新的估计技术来估计该矩阵并验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了“碰撞矩阵”这一新颖且细粒度的不确定性量化度量，并为如何从有限的独热标签数据中估计该矩阵提供了一套完整的解决方案，特别是通过引入对比学习和利用非负矩阵的特性来恢复矩阵S。这一方法为理解和量化分类模型中的内在不确定性提供了新的视角和工具，对于提升模型可靠性和可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提出一种新的、直观的任意不确定性量化（UQ）指标，即类别碰撞的普遍性，并定义碰撞矩阵作为一种新颖且独特的细粒度不确定性度量。

**Method:** 提出了一种新的度量方法，即类别碰撞的普遍性，并基于此定义了KxK碰撞矩阵S，用于衡量区分每对类别的固有难度。为了估计S，首先学习一个成对对比模型，该模型接受两个输入并判断它们是否属于同一类别。然后证明该对比模型可用于估计S的格拉姆矩阵G=S^TS。最后，在合理假设下，G可用于唯一恢复S。利用估计的S和对比模型，进一步估计任何点的后验类别可移植性分布。

**Result:** 建立了S的估计方法，并证明了S的估计与对比模型结合，可用于估计任何点的后验类别可移植性分布。在多个数据集上进行了实验，验证了估计碰撞矩阵和类别后验分布的方法。

**Conclusion:** 本文提出了一种新的细粒度不确定性量化方法——碰撞矩阵，并建立了一系列创新的技术来估计该矩阵及其应用，为不确定性量化提供了一种新颖的视角。

> **ai_Abstract:** 本文提出了一种名为“类别碰撞普遍性”的新型细粒度任意不确定性量化（UQ）指标。基于此，引入了KxK碰撞矩阵S，用以量化分类问题中类间区分的固有难度。论文探讨了碰撞矩阵的应用、数学性质及其与现有UQ方法的关系。为解决使用独热标签数据估计S的问题，作者提出了一系列创新技术，包括训练一个成对对比模型来估计S的格拉姆矩阵G，并证明在特定条件下G能唯一恢复S。最终，该研究展示了如何利用估计的S和对比模型来估计任何点的后验类别可移植性分布，并通过实验验证了方法的有效性。

> **摘要翻译:** 我们提出了一种新的直观的任意不确定性量化（UQ）指标，即类别碰撞的普遍性，其定义为在不同类别中观察到相同的输入。我们使用类别碰撞率来定义碰撞矩阵，这是一种新颖且独特的细粒度不确定性度量。对于涉及K个类别的分类问题，K×K碰撞矩阵S衡量了区分每对类别的固有难度。我们讨论了碰撞矩阵的多种应用，建立了其基本数学性质，并展示了其与现有UQ方法（包括贝叶斯错误率（BER））的关系。我们还通过提出一系列创新的技术来估计S，解决了使用独热标签数据估计碰撞矩阵的新问题。首先，我们学习一个成对对比模型，该模型接受两个输入并确定它们是否属于同一类别。然后我们证明这个对比模型（它是PAC可学习的）可以用来估计S的格拉姆矩阵G=S^TS。最后，我们证明在合理假设下，G可以唯一地恢复S，这是关于非负矩阵的一个新结果，可能具有独立的兴趣。在建立了S的估计方法后，我们演示了S的这种估计如何与对比模型结合使用，以估计任何点的后验类别可移植性分布。实验结果也展示了在多个数据集上验证我们估计碰撞矩阵和类别后验分布的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [480] [Moving Out: Physically-grounded Human-AI Collaboration](https://arxiv.org/abs/2507.18623)
> *搬出：物理接地的人机协作*

*Xuhui Kang, Sung-Wook Lee, Haolin Liu, Yuyan Wang, Yen-Ling Kuo* | **Category: cs.LG, cs.AI, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 物理接地, 人机协作, 基准, BASS, 具身智能体

**Comment:** 24 pages, 8 figures

> **TL;DR:** 本文介绍了“搬出”，一个用于物理接地人机协作的新基准，并提出了BASS方法，该方法在此设置中优于现有最佳模型。

**AI_Comments:** 本文的创新之处在于创建了一个物理接地的人机协作基准，这对于现实世界中的机器人应用至关重要。所提出的BASS方法在处理物理环境的复杂性方面显示出潜力。

<details>
  <summary>Details</summary>

**Motivation:** 具身智能体（例如机器人）要与人类有效协作，适应环境中的物理动作和约束至关重要。这种物理接地的人机协作需要考虑由物理约束引起的连续状态-动作空间和受限动态所增加的复杂性。

**Method:** 本文引入了一个名为“搬出”（Moving Out）的新型人机协作基准，该基准模拟了受物理属性和约束影响的多种协作模式，例如共同搬运重物和在拐角处保持一致动作以移动大件物品。利用“搬出”，设计了两个任务并收集了人-人交互数据，以评估模型适应不同人类行为和未见物理属性的能力。为应对物理环境中的挑战，我们提出了一种新颖的方法——BASS（行为增强、模拟和选择），以增强智能体的多样性及其对动作结果的理解。

**Result:** 实验表明，BASS在AI-AI和人机协作方面均优于现有最先进的模型。

**Conclusion:** 本文成功展示了一个用于物理接地人机协作的新基准和一种新颖方法（BASS），并显示出性能提升。

> **ai_Abstract:** 本文介绍了“搬出”（Moving Out），一个新颖的物理接地人机协作基准，旨在解决连续状态-动作空间和物理约束带来的复杂性。该基准包含模拟物理属性和约束的任务，并收集了人-人交互数据。为应对物理环境的挑战，作者提出了一种名为BASS（行为增强、模拟和选择）的新方法，旨在增强智能体的多样性及其对动作结果的理解。实验结果表明，BASS在AI-AI和人机协作场景中均优于现有最先进的模型。

> **摘要翻译:** 环境中的物理动作和约束的适应能力对于具身智能体（例如机器人）与人类有效协作至关重要。这种物理接地的人工智能协作必须考虑由物理约束引起的连续状态-动作空间和受限动态所增加的复杂性。在本文中，我们引入了“搬出”（Moving Out），一个新的人机协作基准，它模拟了受物理属性和约束影响的多种协作模式，例如共同搬运重物和在拐角处保持一致动作以移动大件物品。使用“搬出”，我们设计了两个任务并收集了人-人交互数据，以评估模型适应不同人类行为和未见物理属性的能力。为应对物理环境中的挑战，我们提出了一种新颖的方法，BASS（行为增强、模拟和选择），以增强智能体的多样性及其对动作结果的理解。我们的实验表明，BASS在AI-AI和人机协作方面均优于现有最先进的模型。项目页面可在https://live-robotics-uva.github.io/movingout_ai/查阅。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [482] [A Principled Approach for Data Bias Mitigation](https://arxiv.org/abs/2405.12312)
> *数据偏见缓解的原则性方法*

*Bruno Scarone, Alfredo Viola, Renée J. Miller, Ricardo Baeza-Yates* | **Category: cs.LG, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 数据偏见, 偏见缓解, 机器学习, 公平性, 表格发现

**Comment:** Accepted to AIES 2025

> **TL;DR:** 本文提出了一种新的、可解释且具有数学保证的数据偏见缓解策略，能够处理非二元标签和多敏感属性，并能发现新的数据元组以减少数据集偏见。

**AI_Comments:** 该论文提出了一种具有数学保证和可解释性的数据偏见缓解方法，其创新点在于能够利用表格发现技术补充数据以减少偏见，并能处理复杂的交叉偏见和多敏感属性，这对于提高机器学习决策的公平性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习和数据驱动算法在决策制定中的广泛应用日益增加，但数据中的偏见会对其决策产生不利影响，因此需要一种新的缓解策略来解决数据偏见问题。

**Method:** 本文提出了一种新的偏见缓解策略，该方法具有可解释性和数学正确性保证。它利用表格发现技术，寻找可添加到数据集中的新元组，以创建无偏或偏见较小的数据集。该框架支持非二元标签和多敏感属性数据，能够衡量和缓解交叉属性偏见。

**Result:** 在公开数据集上评估了所提出的技术，并提供了结果的理论分析，揭示了关于数据偏见的新颖见解。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种解决数据偏见的新型缓解策略。该方法具有可解释性和数学保证，能够利用表格发现技术向数据集中添加新元组，以生成偏见更小的数据集。其框架支持非二元标签和多敏感属性，并能处理交叉偏见。研究在公开数据集上进行了评估，并提供了理论分析，揭示了数据偏见的新见解。

> **摘要翻译:** 机器学习和数据驱动算法在决策制定中的广泛应用多年来一直在稳步增长。数据中的偏见会对此决策制定产生不利影响。我们提出了一种新的缓解策略来解决数据偏见问题。我们的方法具有可解释性，并附带数学正确性保证。它们可以利用表格发现方面的新工作来找到可以添加到数据集中的新元组，从而创建无偏或偏见较小真实数据集。我们的框架涵盖具有非二元标签和多个敏感属性的数据。因此，我们能够衡量和缓解不出现在单个属性（或特征）上，而是在考虑属性组合时才出现的交叉偏见。我们在公开可用的数据集上评估了我们的技术，并提供了我们结果的理论分析，突出了对数据偏见的新颖见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [485] [Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation](https://arxiv.org/abs/2506.11790)
> *时间序列特征归因中为什么会出现类别依赖的评估效应？一项合成数据调查*

*Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 特征归因, 可解释AI, 时间序列, 评估指标, 类别依赖效应

**Comment:** Accepted at TempXAI Workshop @ ECML-PKDD 2025 (Explainable AI for
  Time Series and Data Streams)

> **TL;DR:** 扰动评估指标在时间序列特征归因中存在类别依赖效应，且与真实值指标不一致，提示需谨慎使用。

**AI_Comments:** 本文通过严谨的合成数据实验，揭示了XAI领域中一个关键且被忽视的问题：常用归因评估指标（扰动法）的类别依赖性及其与真实值指标的不一致性。其创新在于首次系统性地探究了这些效应的成因，并明确指出了当前评估方法的局限性。这对于提高XAI方法的可信度和开发更可靠的评估框架具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 评估特征归因方法是可解释人工智能（XAI）中的一个关键挑战，因为在缺乏真实值时，研究人员通常依赖于基于扰动的指标。然而，最近的研究表明，这些评估指标在同一数据集内不同预测类别之间可能表现出不同的性能，这些“类别依赖评估效应”引发了关于扰动分析是否能可靠衡量归因质量的疑问，直接影响XAI方法的开发和评估的可靠性。

**Method:** 我们通过对已知真实特征位置的合成时间序列数据进行受控实验，调查这些类别依赖效应在何种条件下产生。我们系统地改变二元分类任务中的特征类型和类别对比度，然后使用多种归因方法比较基于扰动的退化分数与基于真实值的精确召回指标。

**Result:** 我们的实验表明，即使在具有时间局部特征的简单场景中，类别依赖效应也会在两种评估方法中出现，其触发因素是类别之间特征振幅或时间范围的基本变化。最关键的是，我们发现基于扰动的指标和基于真实值的指标在评估跨类别的归因质量时经常产生矛盾的评估结果，两种评估方法之间的相关性很弱。

**Conclusion:** 这些发现表明，研究人员应谨慎解释基于扰动的指标，因为它们可能不总是与归因是否正确识别区分性特征相符。通过揭示这种脱节，我们的工作指出需要重新思考归因评估实际衡量的是什么，并开发更严谨的评估方法来捕捉归因质量的多个维度。

> **ai_Abstract:** 该论文调查了时间序列特征归因中类别依赖评估效应的产生条件。通过合成数据实验，发现扰动评估指标与真实值指标在评估归因质量时常出现矛盾且相关性弱，即使在简单场景中，类别间特征的基本变化也会导致类别依赖效应。研究强调需谨慎使用基于扰动的指标，并呼吁开发更全面的归因评估方法。

> **摘要翻译:** 评估特征归因方法是可解释人工智能（XAI）中的一个关键挑战，因为在缺乏真实值时，研究人员通常依赖于基于扰动的指标。然而，最近的研究表明，这些评估指标在同一数据集内不同预测类别之间可能表现出不同的性能。这些“类别依赖评估效应”引发了关于扰动分析是否能可靠衡量归因质量的疑问，直接影响XAI方法的开发和评估的可靠性。我们通过对已知真实特征位置的合成时间序列数据进行受控实验，调查这些类别依赖效应在何种条件下产生。我们系统地改变二元分类任务中的特征类型和类别对比度，然后使用多种归因方法比较基于扰动的退化分数与基于真实值的精确召回指标。我们的实验表明，即使在具有时间局部特征的简单场景中，类别依赖效应也会在两种评估方法中出现，其触发因素是类别之间特征振幅或时间范围的基本变化。最关键的是，我们发现基于扰动的指标和基于真实值的指标在评估跨类别的归因质量时经常产生矛盾的评估结果，两种评估方法之间的相关性很弱。这些发现表明，研究人员应谨慎解释基于扰动的指标，因为它们可能不总是与归因是否正确识别区分性特征相符。通过揭示这种脱节，我们的工作指出需要重新思考归因评估实际衡量的是什么，并开发更严谨的评估方法来捕捉归因质量的多个维度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [499] [Demystify Protein Generation with Hierarchical Conditional Diffusion Models](https://arxiv.org/abs/2507.18603)
> *分层条件扩散模型揭秘蛋白质生成*

*Zinan Ling, Yi Shi, Da Yan, Yang Zhou, Bo Hui* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 蛋白质生成, 条件扩散模型, 分层, Protein-MMD, 从头设计

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的多层次条件扩散模型，结合序列和结构信息，用于高效的端到端蛋白质设计，并引入了新的评估指标Protein-MMD，实验证明了其在蛋白质生成任务中的有效性。

**AI_Comments:** 本文创新性地将多层次结构信息融入到条件扩散模型中，以解决蛋白质生成中的可靠性问题，并提出了一个新颖的Protein-MMD评估指标，提升了蛋白质生成质量的评估标准。这项工作对生物学中的蛋白质设计领域具有重要意义，尤其是在功能性蛋白质的生成方面。

<details>
  <summary>Details</summary>

**Motivation:** 生成新颖且功能性的蛋白质序列对生物学应用至关重要。尽管条件扩散模型在蛋白质生成方面表现出色，但在从头设计中，可靠的蛋白质生成仍是一个开放问题，尤其是在条件扩散模型方面。

**Method:** 考虑到蛋白质的生物功能由多层次结构决定，本文提出了一种新颖的多层次条件扩散模型，该模型整合了基于序列和基于结构的信息，以实现由指定功能引导的高效端到端蛋白质设计。通过同时生成不同层次的表示，该框架能够有效建模不同层次之间固有的分层关系。此外，还提出了一种新的可靠评估指标Protein-MMD，用于评估条件扩散模型生成的蛋白质质量。

**Result:** 提出的Protein-MMD指标能够捕获真实和生成蛋白质序列之间的分布和功能相似性，同时确保条件一致性。在基准数据集上的实验结果表明，所提出的生成框架和评估指标在条件蛋白质生成任务中表现出有效性。

**Conclusion:** 本文提出的多层次条件扩散生成框架和新的Protein-MMD评估指标在条件蛋白质生成任务中表现出有效性，能够可靠地生成蛋白质并准确评估其质量。

> **ai_Abstract:** 本文针对从头蛋白质设计中条件扩散模型生成蛋白质的可靠性问题，提出了一种新颖的多层次条件扩散模型。该模型结合了序列和结构信息，通过同时生成多层次表示来捕捉蛋白质的内在分层关系，从而实现由功能引导的端到端蛋白质设计。此外，论文还引入了一个新的评估指标Protein-MMD，用于可靠地评估生成蛋白质的质量，该指标能捕捉分布和功能相似性并确保条件一致性。实验结果证明了该生成框架和评估指标的有效性。

> **摘要翻译:** 生成新颖且功能性的蛋白质序列对广泛的生物应用至关重要。条件扩散模型的最新进展在蛋白质生成任务中表现出令人印象深刻的经验性能。然而，在从头蛋白质设计中，蛋白质的可靠生成仍然是一个开放的研究问题，尤其是在条件扩散模型方面。考虑到蛋白质的生物功能由多层次结构决定，我们提出了一种新颖的多层次条件扩散模型，该模型整合了基于序列和基于结构的信息，以实现由指定功能引导的高效端到端蛋白质设计。通过同时生成不同层次的表示，我们的框架可以有效建模不同层次之间固有的分层关系，从而产生信息丰富且具有辨别力的生成蛋白质表示。我们还提出了一种新的可靠评估指标Protein-MMD，用于评估条件扩散模型生成的蛋白质质量。我们的新指标能够捕获真实和生成蛋白质序列之间的分布和功能相似性，同时确保条件一致性。我们在基准数据集上进行了实验，条件蛋白质生成任务的结果证明了所提出的生成框架和评估指标的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [503] [Multimodal Fine-grained Reasoning for Post Quality Evaluation](https://arxiv.org/abs/2507.17934)
> *多模态细粒度推理用于帖子质量评估*

*Xiaoxu Guo, Siyan Liang, Yachao Cui, Juxiang Zhou, Lei Wang, Han Cao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 多模态推理, 帖子质量评估, 细粒度推理, 关系推理, 深度学习

**Comment:** 48 pages

> **TL;DR:** MFTRR框架通过模拟人类认知过程，将帖子质量评估重构为排序任务，并利用多模态数据和细粒度推理机制，显著优于现有SOTA基线。

**AI_Comments:** 该论文通过引入多模态细粒度推理和模拟人类认知过程，为帖子质量评估提供了一种新颖且有效的方法。其创新点在于将任务重构为排序问题，并设计了独特的双模块结构来处理多模态数据中的噪声并捕获复杂语义关系。在多模态信息融合和细粒度关系推理方面具有重要意义，尤其是在处理真实世界复杂数据方面表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 现有帖子质量评估方法存在三个主要局限性：1) 将任务视为单模态分类，未能利用多模态线索和细粒度质量区分；2) 深度多模态融合过程中引入噪声，导致误导信号；3) 缺乏捕获相关性和全面性等复杂语义关系的能力。

**Method:** 本文提出了多模态细粒度主题-帖子关系推理(MFTRR)框架。MFTRR将帖子质量评估重构为排序任务，并融入多模态数据。它包含两个关键模块：1) 局部-全局语义关联推理模块，通过最大信息融合机制抑制噪声，建模帖子和主题在局部和全局层面的细粒度语义交互；2) 多级证据关系推理模块，探索宏观和微观层面的关系线索以加强基于证据的推理。

**Result:** MFTRR在三个新建的多模态主题-帖子数据集和公共Lazada-Home数据集上进行了评估。实验结果表明，MFTRR显著优于现有SOTA基线，在艺术史数据集上，相较于最佳单模态方法，NDCG@3指标提升高达9.52%。

**Conclusion:** MFTRR框架通过模拟人类认知过程，有效解决了现有帖子质量评估中多模态利用不足、噪声引入和复杂语义关系捕获能力欠缺的问题，显著提升了帖子质量评估的准确性。

> **ai_Abstract:** 本文针对帖子质量评估中现有方法在多模态利用、噪声处理和复杂语义关系捕获方面的不足，提出了多模态细粒度主题-帖子关系推理(MFTRR)框架。该框架模仿人类认知过程，将评估任务重构为排序问题，并设计了局部-全局语义关联推理模块和多级证据关系推理模块，以实现细粒度的多模态信息融合和证据推理。实验证明，MFTRR在新建和公共数据集上均显著优于现有基线，有效提升了帖子质量评估的准确性。

> **摘要翻译:** 准确评估帖子质量需要复杂的关联推理来捕获细微的主题-帖子关系。然而，现有研究面临三个主要局限性：（1）将任务视为单模态分类，未能利用多模态线索和细粒度质量区分；（2）在深度多模态融合过程中引入噪声，导致误导信号；（3）缺乏捕获相关性和全面性等复杂语义关系的能力。为了解决这些问题，我们提出了多模态细粒度主题-帖子关系推理（MFTRR）框架，该框架模仿人类认知过程。MFTRR将帖子质量评估重构为排序任务，并结合多模态数据以更好地捕获质量变化。它由两个关键模块组成：（1）局部-全局语义关联推理模块，该模块通过最大信息融合机制抑制噪声，在局部和全局层面建模帖子和主题之间的细粒度语义交互；以及（2）多级证据关系推理模块，该模块探索宏观和微观层面的关系线索以加强基于证据的推理。我们在三个新建的多模态主题-帖子数据集和公共Lazada-Home数据集上评估了MFTRR。实验结果表明，MFTRR显著优于现有最先进的基线，在艺术史数据集上，相较于最佳单模态方法，NDCG@3提升高达9.52%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [505] [Regression-aware Continual Learning for Android Malware Detection](https://arxiv.org/abs/2507.18313)
> *安卓恶意软件检测中的回归感知持续学习*

*Daniele Ghiani, Daniele Angioni, Giorgio Piras, Angelo Sotgiu, Luca Minnei, Srishti Gupta, Maura Pintor, Fabio Roli, Battista Biggio* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 持续学习, 恶意软件检测, 安全性回归, 回归感知惩罚, 安卓恶意软件

**Comment:** Submitted to IEEE Transactions on Information Forensics and Security

> **TL;DR:** 本文提出了一种回归感知惩罚机制，通过改进积极一致性训练（PCT）来解决持续学习中安卓恶意软件检测的安全性回归问题，实验证明该方法有效减少了回归并保持了检测性能。

**AI_Comments:** 本文的创新点在于首次明确提出并解决了持续学习中“安全性回归”这一关键问题，这对于安全领域中的模型持续更新具有重要意义。通过形式化回归并引入回归感知惩罚机制，有效提升了模型在面对新数据时保持对旧样本检测能力的稳定性，增强了用户对系统安全更新的信任。该方法对PCT的适配性也使其具有较好的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 恶意软件快速演变，使得基于机器学习的检测器需要持续适应。传统方法中，数据集规模庞大导致完全重新训练不切实际。持续学习（CL）虽能增量更新，但存在一个关键且常被忽视的问题：安全性回归。安全性回归指的是曾被正确检测的恶意样本在模型更新后却逃避检测，这会严重损害用户对系统更新的信任。

**Method:** 为解决安全性回归问题，本文首先形式化并量化了CL中恶意软件检测器的安全性回归，然后提出了一种回归感知惩罚机制来缓解该问题。具体而言，该方法将积极一致性训练（Positive Congruent Training, PCT）应用于持续学习设置，以模型无关的方式保留了先前的预测行为。

**Result:** 在ELSA、Tesseract和AZ-Class数据集上的实验表明，所提出的方法在不同的持续学习场景中有效减少了回归，并随着时间的推移保持了强大的检测性能。

**Conclusion:** 本文成功形式化并解决了持续学习中安卓恶意软件检测的安全性回归问题，通过提出的回归感知惩罚机制，在有效减少回归的同时保持了出色的检测性能，这对于安全关键型应用至关重要。

> **ai_Abstract:** 本研究聚焦于持续学习（CL）中安卓恶意软件检测面临的“安全性回归”问题，即已检测恶意软件在模型更新后再次逃逸。针对这一挑战，论文首次对安全性回归进行了形式化和量化，并提出了一种基于回归感知惩罚的新方法。该方法通过改进积极一致性训练（PCT），以模型无关的方式在CL环境中保留模型先前的预测行为。实验结果表明，该方法在多个恶意软件数据集上有效降低了回归率，并维持了良好的检测性能，提升了持续学习在安全领域的实用性和可靠性。

> **摘要翻译:** 恶意软件快速演变，迫使基于机器学习（ML）的检测器持续适应。随着杀毒厂商每天处理数十万个新样本，数据集可能增长到数十亿个，使得完全重新训练变得不切实际。持续学习（CL）已成为一种可扩展的替代方案，它无需完全访问数据即可实现增量更新，同时缓解灾难性遗忘。在这项工作中，我们分析了一个在此背景下关键但常被忽视的问题：安全性回归。与遗忘不同，遗忘表现为对先前见过的数据的普遍性能下降，而安全性回归则捕捉样本层面的有害预测变化，例如一个曾被正确检测的恶意软件样本在模型更新后却逃避了检测。尽管常被忽视，回归在安全关键型应用中带来了严重风险，因为系统中先前检测到的威胁的无声重新引入可能会损害用户对整个更新过程的信任。为了解决这个问题，我们形式化并量化了基于CL的恶意软件检测器中的安全性回归，并提出了一种回归感知惩罚来缓解它。具体来说，我们将积极一致性训练（Positive Congruent Training, PCT）应用于CL设置，以模型无关的方式保留了先前的预测行为。在ELSA、Tesseract和AZ-Class数据集上的实验表明，我们的方法在不同CL场景中有效减少了回归，同时随着时间的推移保持了强大的检测性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [509] [Multi-Preference Lambda-weighted Listwise DPO for Small-Scale Model Alignment](https://arxiv.org/abs/2506.19780)
> *用于小规模模型对齐的多偏好Lambda加权列表式DPO*

*Yuhui Sun, Xiyao Wang, Zixi Li, Zhenlong Yuan, Jinman Zhao* | **Category: cs.LG, I.2.6; I.2.7; I.5.1** | **Updated: 2025-07-24**

**Keywords:** 多偏好对齐, Lambda加权, 列表式DPO, 模型对齐, 小规模模型

**Comment:** 12 pages, 12 figures, appendix included. To appear in Proceedings of
  AAAI 2026. Code:
  https://github.com/yuhui15/Multi-Preference-Lambda-weighted-DPO

> **TL;DR:** 本文提出了一种名为Multi-Preference Lambda-weighted Listwise DPO的新方法，通过处理多维度偏好和全排序反馈，解决了传统DPO在处理复杂人类偏好时的局限性，并显著降低了计算资源需求，提高了模型对齐效果。

**AI_Comments:** 这项研究的创新之处在于引入了多偏好和列表式排序的概念到DPO框架中，显著扩展了DPO处理复杂人类反馈的能力。通过允许模型学习多维度目标并平衡它们的重要性，该方法使得模型对齐更加精细和灵活。其低内存需求是一个重要优势，使得先进的模型对齐技术能够应用于资源受限的环境，具有较高的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)的输出常与人类偏好不符。现有的RLHF方法计算成本高且不稳定，而DPO虽简化了过程，但仅支持固定、单维度偏好和成对监督。为解决这些局限性，本文提出了新的方法。

**Method:** 本文提出了Multi-Preference Lambda-weighted Listwise DPO。该方法允许模型从更详细的人类反馈中学习，并灵活平衡多个目标（如有用性、诚实性、流畅性）。它建模全排序偏好分布而非二元比较，提供更丰富的信息信号。Lambda向量控制不同对齐目标的相对重要性，推理时可不经重训练调整Lambda。此外，还引入了一个学习型调度器来动态采样高性能的Lambda配置。

**Result:** 该方法仅需20GB GPU内存进行训练，适用于计算受限环境。在1B-2B规模模型上的实验表明，该方法在对齐基准测试中持续优于标准DPO，并实现了高效、可控和细粒度的适应，适用于实际部署。

**Conclusion:** Multi-Preference Lambda-weighted Listwise DPO通过处理多维度偏好和全排序反馈，显著提升了模型与人类偏好的对齐效果，同时降低了计算成本，使其成为一种高效、可控且适用于小规模模型对齐的解决方案。

> **ai_Abstract:** 本文提出了一种名为Multi-Preference Lambda-weighted Listwise DPO的新方法，旨在解决现有DPO在处理多维度人类偏好和仅支持成对监督方面的局限性。该方法通过建模全排序偏好分布和引入可调的Lambda向量来平衡多个对齐目标，从而允许模型从更详细的反馈中学习并实现可控的对齐行为。此外，它还集成了学习型调度器以提高鲁棒性。实验证明，该方法在计算资源受限的情况下（仅需20GB GPU内存）仍能超越标准DPO，并在1B-2B规模模型上实现高效、可控且细粒度的模型对齐。

> **摘要翻译:** 大型语言模型（LLMs）在广泛的语言任务中表现出强大的泛化能力，但其生成的内容往往与人类偏好不符。人类反馈强化学习（RLHF）通过使用学习到的奖励函数和强化学习来优化模型以符合人类偏好，从而改善了对齐效果，但其计算成本高且不稳定。直接偏好优化（DPO）通过将对齐视为二元偏好对的分类任务来简化这一过程，降低了训练开销，同时取得了有竞争力的性能。然而，它假设固定、单维度的偏好，并且只支持成对监督。
为了解决这些局限性，我们提出了多偏好Lambda加权列表式DPO，它允许模型从更详细的人类反馈中学习，并灵活地平衡多个目标，如有用性、诚实性和流畅性。我们的方法建模全排序偏好分布而非二元比较，从而实现更具信息量的学习信号。Lambda向量控制不同对齐目标的相对重要性，允许模型泛化到多样化的人类目标。在推理过程中，Lambda可以在不重新训练的情况下进行调整，为下游使用提供可控的对齐行为。我们还引入了一个学习型调度器，动态采样高性能的Lambda配置以提高鲁棒性。
值得注意的是，我们的方法训练仅需20GB的GPU内存，使其适用于计算受限的环境，如学术实验室、教育工具或设备上的助手。在1B-2B规模模型上的实验表明，我们的方法在对齐基准测试中持续优于标准DPO，同时实现了高效、可控和细粒度的适应，适用于实际部署。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [512] [ChronoSelect: Robust Learning with Noisy Labels via Dynamics Temporal Memory](https://arxiv.org/abs/2507.18183)
> *ChronoSelect：通过动态时间记忆实现鲁棒学习与噪声标签*

*Jianchao Wang, Qingfeng Li, Pengcheng Zheng, Xiaorong Pu, Yazhou Ren* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 噪声标签学习, 时间动态性, 记忆架构, 深度神经网络, ChronoSelect

**Comment:** 

> **TL;DR:** ChronoSelect提出了一种新的四阶段记忆架构，通过利用学习演化的时间动态性，有效处理噪声标签问题，实现了最先进的性能。

**AI_Comments:** ChronoSelect的创新之处在于其独特地利用了学习过程中的“时间动态性”来处理噪声标签，这与现有LNL方法侧重于静态评估形成对比。其四阶段记忆架构和滑动更新机制提供了一种有效且可扩展的方式来管理历史预测信息，从而实现精确的样本划分。理论保证增加了其方法的可靠性。该方法对于提高深度学习模型在真实世界噪声数据上的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在真实世界数据上训练深度神经网络时，噪声标签的存在会严重影响模型的泛化性能，因为过参数化模型会记忆这些噪声标签。现有方法未能利用学习演化的丰富时间动态性。

**Method:** 本文提出了ChronoSelect框架，其特点是创新的四阶段记忆架构，将预测历史压缩成紧凑的时间分布。它采用独特的带控制衰减的滑动更新机制，为每个样本仅维护四个动态记忆单元，渐进地强调最新模式，同时保留必要的历史知识。通过时间轨迹分析和双分支一致性，ChronoSelect能够将样本精确地划分为干净、边界和噪声子集。

**Result:** 实验证明ChronoSelect在合成和真实世界基准测试中均达到了最先进的性能。

**Conclusion:** ChronoSelect通过利用学习的时间动态性，提供了一种有效且鲁棒的噪声标签学习方法，并在各种基准测试中表现出色。

> **ai_Abstract:** ChronoSelect是一种新颖的框架，旨在通过利用学习过程中的时间动态性来解决深度神经网络在噪声标签下的鲁棒学习问题。它引入了一个四阶段记忆架构，将预测历史压缩为时间分布，并通过滑动更新机制维护动态记忆单元。这种方法能够精确地将样本划分为干净、边界和噪声子集，并通过理论保证和实验验证，在噪声条件下展现出优越的性能。

> **摘要翻译:** 在真实世界数据上训练深度神经网络通常会受到噪声标签的阻碍，这些噪声标签可能被过参数化模型记忆，导致泛化性能显著下降。尽管现有的噪声标签学习（LNL）方法取得了相当大的进展，但它们从根本上受限于静态快照评估，未能利用学习演化的丰富时间动态性。在本文中，我们提出了ChronoSelect（chrono表示其时间性质），一个具有创新四阶段记忆架构的新颖框架，该架构将预测历史压缩成紧凑的时间分布。我们独特的带控制衰减的滑动更新机制为每个样本仅维护四个动态记忆单元，逐步强调最新模式，同时保留必要的历史知识。这使得通过时间轨迹分析和双分支一致性，能够将样本精确地划分为干净、边界和噪声子集。理论保证证明了该机制在噪声条件下的收敛性和稳定性。广泛的实验证明了ChronoSelect在合成和真实世界基准测试中均达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [533] [Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks](https://arxiv.org/abs/2507.09871)
> *任务先验：通过考虑下游任务的整个空间来增强模型评估*

*Niket Patel, Randall Balestriero* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 任务先验, 模型评估, 下游任务, 自监督学习, 概率空间

**Comment:** 

> **TL;DR:** 本文提出了一种新的模型评估范式，通过定义任务先验和任务的概率空间来评估模型在所有可能下游任务上的性能，以克服当前固定基准评估的局限性。

**AI_Comments:** 本文提出了一种新颖且重要的模型评估范式，通过引入“任务先验”和考虑所有可能的下游任务空间，弥补了现有评估方法（依赖固定基准）的不足。这种方法创新性地将评估从离散的、预选的任务集扩展到连续的、概率化的任务空间，有望更真实地反映模型的泛化能力。这对于自监督学习等领域尤为重要，因为它提供了更丰富的定性信号，可能加速研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI研究（特别是自监督学习SSL）的模型评估方法依赖于固定、手工挑选的下游基准，这被认为是一个“隐性瓶颈”，无法实现AI解决任何可能任务的宏伟目标。

**Method:** 本文通过采纳任务分布和定义“任务先验”（Task Priors）来定义一个下游任务的概率空间。在这种视角下，可以评估模型在所有可能的下游任务上的性能。

**Result:** 该框架首次能够回答关键问题，例如模型在所有可能下游任务上的平均性能（根据遇到每个任务的概率加权）以及在定义任务先验下模型性能的方差。

**Conclusion:** 任务先验不仅为评估建立了新标准，还被认为将加速自监督学习（SSL）的研究步伐，因为下游任务评估是研究人员可获得唯一定性信号。

> **ai_Abstract:** 当前AI模型评估方法受限于固定基准，无法有效衡量模型解决任意任务的能力。为解决此问题，本文引入了“任务先验”概念，并构建了一个下游任务的概率空间。通过定义任务分布和任务先验，该框架能够评估模型在所有可能下游任务上的平均性能和性能方差，从而提供一个更全面、更接近AI最终目标的评估标准。作者认为这将成为自监督学习研究的重要推动力。

> **摘要翻译:** AI研究，特别是自监督学习（SSL）的宏伟目标是生产能够成功解决任何可能任务的系统。然而，当前AI研究人员可用的评估方法通常依赖于固定的一组手工挑选的下游基准。因此，大量精力投入到设计和寻找大量评估任务，以作为我们宏伟目标的替代。我们认为，这种僵化的评估协议在AI研究中造成了一个隐性瓶颈。为了弥补这一点，我们通过采纳任务分布和定义任务先验（Task Priors）来定义一个下游任务的概率空间。在这种视角下，可以评估模型在所有可能的下游任务上的性能。我们的框架首次回答了关键问题，例如（i）我的模型在所有可能的下游任务上的平均性能是多少（按遇到每个任务的概率加权）？或（ii）在定义任务先验下，我的模型在所有下游任务上的性能方差是多少？除了建立新的评估标准外，我们相信任务先验将加速SSL的研究步伐——在SSL中，下游任务评估是研究人员可获得的唯一定性信号。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [537] [Gait Recognition Based on Tiny ML and IMU Sensors](https://arxiv.org/abs/2507.18627)
> *基于Tiny ML和IMU传感器的步态识别*

*Jiahang Zhang, Mingtong Chen, Zhengbao Yang* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 步态识别, Tiny ML, IMU传感器, 深度神经网络, 边缘计算

**Comment:** 

> **TL;DR:** 该项目开发了一个使用Tiny ML和IMU传感器进行四种活动（行走、静止、上楼、下楼）实时分类的步态识别系统，实现了超过80%的准确率和低功耗操作。

**AI_Comments:** 该研究结合了Tiny ML和IMU传感器，实现了低功耗、实时的边缘端步态识别，具有重要的实际应用价值，尤其是在可穿戴设备和物联网领域。系统在准确率和鲁棒性方面表现良好，但未提及对更多步态模式或复杂环境的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个低功耗、实时、基于Tiny ML和IMU传感器的步态识别系统，以有效分类日常活动。

**Method:** 系统利用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器捕获行走、静止、上楼、下楼四种活动的运动数据。数据通过Edge Impulse平台处理，进行滑动窗口和数据归一化等特征提取预处理，然后训练一个深度神经网络(DNN)分类器，并直接部署到微控制器上进行实时活动分类。

**Result:** 该模型在测试数据集上实现了超过80%的准确率，能够有效分类四种活动。此外，该平台还支持异常检测，增强了系统鲁棒性。

**Conclusion:** 该系统成功地使用Tiny ML和IMU传感器实现了高效、低功耗的步态识别，适用于电池供电或能量收集设备，并能有效分类多种日常活动。

> **ai_Abstract:** 本文介绍了一个基于Tiny ML和IMU传感器的步态识别系统。该系统使用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器采集行走、静止、上楼和下楼四种活动的运动数据。通过Edge Impulse平台进行数据预处理和深度神经网络训练后，模型被部署到微控制器上进行实时活动分类，准确率超过80%。该系统还具备异常检测功能，并因Tiny ML的运用而实现低功耗运行，适用于资源受限设备。

> **摘要翻译:** 本项目展示了一个使用微型机器学习（Tiny ML）和惯性测量单元（IMU）传感器开发的步态识别系统。该系统利用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器捕获四种不同活动（行走、静止、上楼和下楼）的运动数据，包括加速度和角速度。收集到的数据通过Edge Impulse（一个边缘AI平台）进行处理，该平台能够训练机器学习模型，并将其直接部署到微控制器上进行实时活动分类。数据预处理步骤包括使用滑动窗口和数据归一化等技术从原始传感器数据中提取相关特征，然后训练一个深度神经网络（DNN）分类器进行活动识别。该模型在测试数据集上实现了超过80%的准确率，证明了其有效分类四种活动的能力。此外，该平台还支持异常检测，进一步增强了系统的鲁棒性。Tiny ML的集成确保了低功耗运行，使其适用于电池供电或能量收集设备。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [546] [Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction](https://arxiv.org/abs/2507.17768)
> *通过相对熵核心集选择和级联层校正增强边缘设备上的量化感知训练*

*Yujia Tong, Jingling Yuan, Chuang Hu* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 量化感知训练, 边缘设备, 核心集选择, 相对熵, 级联层校正

**Comment:** 

> **TL;DR:** 本文提出QuaRC框架，通过引入相对熵分数进行核心集选择和采用级联层校正策略，显著提升了在边缘设备上使用小规模数据集进行量化感知训练的性能。

**AI_Comments:** 该论文的创新点在于提出了“相对熵分数”用于核心集选择，以及“级联层校正”策略来解决量化误差累积问题，特别是在小数据量边缘设备场景下。这对于在资源受限且数据隐私敏感的环境中部署高性能量化模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着移动和边缘计算的发展，边缘设备对低比特量化模型的需求增加，以实现高效部署。然而，由于隐私问题，敏感数据只能在边缘设备上处理，因此需要在边缘设备上进行量化感知训练（QAT）。传统QAT依赖完整数据集，计算成本高。现有核心集选择方法在小规模数据集（如10%数据）上难以消除量化误差，导致性能显著下降。

**Method:** 本文提出了QuaRC，一个用于边缘设备上核心集量化感知训练的框架，包含两个主要阶段：1. 核心集选择阶段：引入“相对熵分数”来识别最能捕捉模型量化误差的子集。2. 训练阶段：采用“级联层校正”策略，将量化模型的中间层输出与全精度模型的输出对齐，有效减少中间层量化误差。

**Result:** 实验结果表明了该方法的有效性。例如，当使用1%数据子集将ResNet-18量化为2比特时，QuaRC在ImageNet-1K数据集上的Top-1准确率比现有最先进技术提高了5.72%。

**Conclusion:** QuaRC通过创新的相对熵核心集选择和级联层校正策略，有效解决了边缘设备上小规模数据集进行量化感知训练的性能下降问题，显著提升了模型准确率。

> **ai_Abstract:** 本文提出了QuaRC框架，旨在解决边缘设备上量化感知训练（QAT）在小规模数据集下性能下降的问题。QuaRC包含两个关键阶段：首先，通过引入“相对熵分数”进行核心集选择，以识别最能反映模型量化误差的数据子集；其次，在训练阶段采用“级联层校正”策略，使量化模型中间层输出与全精度模型对齐，从而有效降低量化误差。实验结果表明，QuaRC在极小数据集（如1%）上显著提升了量化模型的准确率，超越了现有SOTA方法。

> **摘要翻译:** 随着移动和边缘计算的发展，边缘设备上对低比特量化模型的需求日益增加，以实现高效部署。为了提高性能，通常需要使用边缘数据对量化模型进行再训练。然而，由于隐私问题，某些敏感数据只能在边缘设备上处理。因此，在边缘设备上采用量化感知训练（QAT）已成为一种有效的解决方案。然而，传统的QAT依赖于完整的训练数据集，这会产生巨大的计算成本。核心集选择技术可以通过在最具代表性的子集上进行训练来缓解这个问题。然而，现有方法在使用小规模数据集（例如，仅10%的数据）时难以消除模型中的量化误差，导致性能显著下降。为了解决这些问题，我们提出了QuaRC，一个在边缘设备上使用核心集的QAT框架，它包含两个主要阶段：在核心集选择阶段，QuaRC引入了“相对熵分数”来识别最能有效捕获模型量化误差的子集。在训练阶段，QuaRC采用级联层校正策略，将量化模型的中间层输出与全精度模型的中间层输出对齐，从而有效减少中间层中的量化误差。实验结果证明了我们方法的有效性。例如，当使用1%的数据子集将ResNet-18量化为2比特时，QuaRC在ImageNet-1K数据集上的Top-1准确率比现有最先进技术提高了5.72%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [552] [Clo-HDnn: A 4.66 TFLOPS/W and 3.78 TOPS/W Continual On-Device Learning Accelerator with Energy-efficient Hyperdimensional Computing via Progressive Search](https://arxiv.org/abs/2507.17953)
> *Clo-HDnn：一种通过渐进式搜索实现能效超维度计算的4.66 TFLOPS/W和3.78 TOPS/W持续在设备学习加速器*

*Chang Eun Song, Weihong Xu, Keming Fan, Soumil Jain, Gopabandhu Hota, Haichao Yang, Leo Liu, Kerem Akarvardar, Meng-Fan Chang, Carlos H. Diaz, Gert Cauwenberghs, Tajana Rosing, Mingu Kang* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 在设备学习, 持续学习, 超维度计算, 能效, 加速器

**Comment:** Published in 2025 Symposium on VLSI Technology and Circuits (VLSI
  Technology and Circuits), Kyoto, Japan, 2025

> **TL;DR:** Clo-HDnn是一种高效的在设备持续学习加速器，通过结合超维度计算和优化技术，显著提升了能效。

**AI_Comments:** 这篇论文的创新点在于将超维度计算与优化的编码和特征提取技术相结合，以实现高效的持续在设备学习。渐进式搜索的引入是其关键优势，显著降低了计算复杂性。其卓越的能效表现（TFLOPS/W和TOPS/W）表明其在资源受限的边缘设备上具有巨大的应用潜力。该研究为未来边缘AI硬件的设计提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 设计一个用于新兴持续学习（CL）任务的在设备学习（ODL）加速器，以优化准确性和效率。

**Method:** Clo-HDnn集成了超维度计算（HDC）、低成本Kronecker HD编码器和权重聚类特征提取（WCFE）。它采用无梯度CL来更新和存储知识，并具有双模式操作以绕过简单数据集的特征提取。通过渐进式搜索，仅对部分查询超向量进行编码和比较，从而降低了高达61%的复杂性。

**Result:** Clo-HDnn实现了4.66 TFLOPS/W（特征提取）和3.78 TOPS/W（分类器）的能效。与最先进的ODL加速器相比，其能效分别提高了7.77倍和4.85倍。

**Conclusion:** Clo-HDnn是一种高效且节能的在设备持续学习加速器，在能效方面显著优于现有技术。

> **ai_Abstract:** Clo-HDnn是一种针对持续在设备学习任务设计的加速器，它结合了超维度计算、Kronecker HD编码器和权重聚类特征提取技术，以提高准确性和效率。该加速器采用无梯度学习和双模式操作，并通过渐进式搜索将复杂性降低了61%。实验结果显示，Clo-HDnn在能效方面显著优于现有最先进的在设备学习加速器，分别达到4.66 TFLOPS/W和3.78 TOPS/W。

> **摘要翻译:** Clo-HDnn是一种专为新兴持续学习（CL）任务设计的在设备学习（ODL）加速器。Clo-HDnn集成了超维度计算（HDC）以及低成本的Kronecker HD编码器和权重聚类特征提取（WCFE），以优化准确性和效率。Clo-HDnn采用无梯度CL，以类超向量的形式高效更新和存储所学知识。其双模式操作能够为简单数据集绕过昂贵的特征提取，而渐进式搜索通过仅编码和比较部分查询超向量，将复杂性降低了高达61%。Clo-HDnn实现了4.66 TFLOPS/W（特征提取）和3.78 TOPS/W（分类器），与最先进的ODL加速器相比，其能效分别提高了7.77倍和4.85倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [557] [SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning](https://arxiv.org/abs/2507.14516)
> *SDSC：一种用于语义信号表示学习的结构感知度量*

*Jeyoung Lee, Hochul Kang* | **Category: cs.LG, cs.AI, cs.LO** | **Updated: 2025-07-24**

**Keywords:** 信号Dice相似系数, 自监督学习, 时间序列, 结构感知度量, 语义表示学习

**Comment:** 

> **TL;DR:** 提出SDSC，一种基于结构感知的度量，用于时间序列自监督学习，优于传统距离度量如MSE。

**AI_Comments:** 这篇论文的创新点在于提出了SDSC，一种新颖的结构感知度量，旨在解决传统距离度量在信号自监督学习中存在的局限性。通过关注信号的结构一致性而非简单的幅度差异，SDSC有望提升表示的语义质量和可解释性。其作为损失函数的使用以及与MSE的混合策略也增强了实用性。该工作为时间序列的自监督学习提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信号自监督学习方法多采用基于距离的目标函数（如均方误差MSE），这些方法对幅度敏感、对波形极性不变且尺度无界，这些特性阻碍了语义对齐并降低了可解释性。

**Method:** 提出了信号Dice相似系数（SDSC），这是一种结构感知度量函数，通过量化基于带符号幅度交集的时序信号结构一致性来解决上述问题，该方法源自Dice相似系数（DSC）。SDSC可以作为损失函数（通过1减去SDSC并应用Heaviside函数的微分近似），并且还提出了一种混合损失公式，将SDSC与MSE结合以提高稳定性和保留幅度。

**Result:** 在预测和分类基准上的实验表明，基于SDSC的预训练与MSE相比，性能相当或有所改进，特别是在域内和低资源场景中。

**Conclusion:** 信号表示中的结构保真度可以提高语义表示质量，支持将结构感知度量作为传统基于距离方法的有效替代方案。

> **ai_Abstract:** 这篇论文提出了信号Dice相似系数（SDSC），一种针对时间序列自监督表示学习的结构感知度量。针对传统距离度量（如MSE）在语义对齐和可解释性方面的不足，SDSC通过量化带符号幅度的结构一致性来解决。SDSC可以作为损失函数使用，并提出了一种SDSC与MSE结合的混合损失。实验证明，SDSC在预测和分类任务上表现出与MSE相当或更优的性能，尤其在特定场景下，强调了结构保真度对语义表示质量的重要性。

> **摘要翻译:** 我们提出了信号Dice相似系数（SDSC），这是一种用于时间序列自监督表示学习的结构感知度量函数。大多数信号自监督学习（SSL）方法通常采用基于距离的目标函数，例如均方误差（MSE），这些方法对幅度敏感、对波形极性不变且尺度无界。这些特性阻碍了语义对齐并降低了可解释性。SDSC通过量化基于带符号幅度交集的时序信号之间的结构一致性来解决这个问题，该方法源自Dice相似系数（DSC）。尽管SDSC被定义为一种结构感知度量，但它可以通过从1中减去自身并应用Heaviside函数的可微分近似来用作损失函数，以进行基于梯度的优化。论文还提出了一种混合损失公式，将SDSC与MSE结合，以提高稳定性并在必要时保留幅度。在预测和分类基准上的实验表明，基于SDSC的预训练比MSE取得了相当或更好的性能，特别是在域内和低资源场景中。结果表明，信号表示中的结构保真度可以提高语义表示质量，支持将结构感知度量视为传统基于距离方法的有效替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [566] [Goal-based Trajectory Prediction for improved Cross-Dataset Generalization](https://arxiv.org/abs/2507.18196)
> *基于目标的轨迹预测，以提高跨数据集泛化能力*

*Daniel Grimm, Ahmed Abouelazm, J. Marius Zöllner* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 轨迹预测, 泛化能力, 图神经网络, 目标分类, 自动驾驶

**Comment:** Accepted on IEEE ITSC 2025

> **TL;DR:** 本文提出了一种新的图神经网络，利用异构图和多阶段目标分类方法，以提高自动驾驶中交通参与者轨迹预测的跨数据集泛化能力。

**AI_Comments:** 本文的创新点在于引入了基于目标分类的多阶段方法，并结合异构图神经网络来解决轨迹预测模型的跨数据集泛化能力不足的问题。这种方法通过明确预测轨迹终点来指导预测过程，有望提高模型在复杂和多样化真实世界场景中的鲁棒性。其重要性在于，提高模型的泛化能力是实现L5级自动驾驶的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 目前的交通参与者轨迹预测模型在训练数据集上表现良好，但在未见过的新区域部署时性能显著下降，这表明模型缺乏泛化能力。

**Method:** 本文引入了一种新的图神经网络（GNN），它利用包含交通参与者和矢量化道路网络的异构图。其中，矢量化道路网络用于通过多阶段方法对目标（即预测轨迹的终点）进行分类。

**Result:** 通过跨数据集评估（在Argoverse2上训练并在NuScenes上评估），证明了目标选择过程的有效性。

**Conclusion:** 通过利用基于目标的多阶段方法和异构图，可以显著提高轨迹预测模型在未见场景中的泛化能力。

> **ai_Abstract:** 本文针对现有轨迹预测模型在未见场景中泛化能力差的问题，提出了一种新的基于图神经网络（GNN）的方法。该方法利用包含交通参与者和矢量化道路网络的异构图，并通过多阶段方法对预测轨迹的终点（目标）进行分类。实验通过在Argoverse2上训练并在NuScenes上评估的跨数据集验证，证明了这种目标选择过程能够有效提高模型在不同数据集上的泛化能力。

> **摘要翻译:** 为了实现完全自动驾驶，需要对周围环境有很好的理解。特别是预测其他交通参与者的未来状态，这是一个不小的挑战。目前的SotA模型在真实数据集（例如Argoverse2、NuScenes）上训练时已经显示出有希望的结果。当这些模型部署到新的/未见的区域时，问题就出现了。通常，性能会显著下降，这表明模型缺乏泛化能力。在这项工作中，我们引入了一种新的图神经网络（GNN），它利用由交通参与者和矢量化道路网络组成的异构图。后者用于以多阶段方法对目标（即预测轨迹的终点）进行分类，从而更好地泛化到未见的场景。我们通过跨数据集评估（即在Argoverse2上训练并在NuScenes上评估）展示了目标选择过程的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [576] [Knowledge Abstraction for Knowledge-based Semantic Communication: A Generative Causality Invariant Approach](https://arxiv.org/abs/2507.17784)
> *面向知识的语义通信知识抽象：一种生成式因果不变方法*

*Minh-Duong Nguyen, Quoc-Viet Pham, Nguyen H. Tran, Hoang-Khoi Do, Duy T. Ngo, Won-Joo Hwang* | **Category: cs.LG, 68, I.2.0** | **Updated: 2025-07-23**

**Keywords:** 知识抽象, 语义通信, 生成对抗网络, 因果不变学习, 数据重建

**Comment:** 13 pages, 12 figures, 4 tables

> **TL;DR:** 本文提出了一种基于生成对抗网络和因果不变学习的低复杂度AI模型，用于语义通信中的知识抽象，以提升数据重建性能并确保知识在不同领域和随时间演变的数据中保持一致性。

**AI_Comments:** 本文通过引入生成对抗网络和因果不变学习，为语义通信中的知识抽象提供了一种新颖且有效的方法。其创新点在于能够从数据中分离出不变的因果表示，这对于在动态和异构环境中保持知识一致性至关重要。该方法在数据重建和分类任务中的优异表现，特别是其超越现有SOTA方法的PSNR性能，凸显了其在提升语义通信效率和鲁棒性方面的潜力。此外，稀疏更新协议的设计也体现了对实际系统通信开销的考量。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高语义通信中信道解码器的数据重建能力，需要捕获通用知识。随着用户收集的数据随时间演变，用户间的知识会产生分歧。

**Method:** 提出了一种生成对抗网络（GAN），利用因果不变学习从数据中提取因果和非因果表示。因果表示是不变的，包含识别数据标签的关键信息，能够封装语义知识并促进接收端的有效数据重建。此外，设计了稀疏更新协议，以改善知识的不变性，同时最小化通信开销。

**Result:** 1. 因果不变知识确保了在训练数据多样化的情况下，不同设备之间的一致性。2. 不变知识在分类任务中表现出色，这对于面向目标的语义通信至关重要。3. 基于知识的数据重建凸显了解码器的鲁棒性，在峰值信噪比（PSNR）方面超越了其他最先进的数据重建和语义压缩方法。

**Conclusion:** 该研究提出的方法通过捕获因果不变知识，显著提升了语义通信的数据重建性能，并确保了知识在多变数据和不同领域中的一致性和鲁棒性。

> **ai_Abstract:** 本研究提出了一种用于语义通信的低复杂度通用AI模型，该模型基于生成对抗网络和因果不变学习，旨在通过捕获因果不变知识来提高信道解码器的数据重建能力。该模型能够提取对数据标签识别至关重要的不变因果表示，确保知识在不同域和随时间演变的数据中保持一致性。为了应对知识随时间演变的问题，还设计了稀疏更新协议以优化不变性并降低通信开销。实证结果表明，该方法在设备一致性、分类任务性能以及数据重建的鲁棒性方面均表现优异，尤其在PSNR上超越了现有先进方法。

> **摘要翻译:** 在本研究中，我们设计了一个低复杂度、通用的人工智能模型，该模型能够捕获通用知识，以改进语义通信中信道解码器的数据重建。具体而言，我们提出了一种生成对抗网络，该网络利用因果不变学习从数据中提取因果和非因果表示。因果表示是不变的，包含识别数据标签的关键信息。它们可以封装语义知识，并促进接收端的有效数据重建。此外，因果机制确保学习到的表示在不同域中保持一致，即使用户从不同域收集数据，系统也能保持可靠。随着用户收集的数据随时间演变导致用户之间知识差异，我们设计了稀疏更新协议，以改善知识的不变性，同时最小化通信开销。我们的实证评估得出了三个关键观察结果。首先，因果不变知识确保了尽管训练数据多样化，不同设备之间仍能保持一致性。其次，不变知识在分类任务中表现出良好的性能，这对于面向目标的语义通信至关重要。第三，我们基于知识的数据重建突出了我们解码器的鲁棒性，在峰值信噪比（PSNR）方面超越了其他最先进的数据重建和语义压缩方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [578] [Latent Space Alignment for AI-Native MIMO Semantic Communications](https://arxiv.org/abs/2507.16680)
> *AI原生MIMO语义通信中的潜在空间对齐*

*Mario Edoardo Pandolfo, Simone Fiorellino, Emilio Calvanese Strinati, Paolo Di Lorenzo* | **Category: cs.LG, cs.IT, cs.NI, math.IT** | **Updated: 2025-07-24**

**Keywords:** 语义通信, MIMO, 潜在空间对齐, 预编码器, 神经网络

**Comment:** Proc. of IEEE IJCNN 2025

> **TL;DR:** 该论文提出了一种利用MIMO技术解决语义通信中潜在空间失配问题的新方法，通过学习MIMO预编码器/解码器对来同时进行潜在空间压缩和语义信道均衡，以减轻语义失配和物理信道损伤。

**AI_Comments:** 该论文的创新点在于将MIMO技术引入语义通信领域，以解决潜在空间失配这一关键问题，并结合了传统优化方法和深度学习方法来设计解决方案，提供了多样的实现路径。其重要性体现在提升了语义通信的鲁棒性和效率，对于未来AI原生通信网络的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 语义通信中，当设备使用不同语言、逻辑或内部表示时，可能发生语义失配，从而阻碍相互理解。

**Method:** 本文提出一种新颖的方法，利用多输入多输出（MIMO）通信解决语义通信中的潜在空间失配问题。具体而言，该方法学习一个MIMO预编码器/解码器对，共同执行潜在空间压缩和语义信道均衡，以减轻语义失配和物理信道损伤。文中探索了两种解决方案：(i) 线性模型，通过交替方向乘子法（ADMM）求解双凸优化问题进行优化；(ii) 基于神经网络的模型，在传输功率预算和复杂性约束下学习语义MIMO预编码器/解码器。

**Result:** 数值结果表明，所提出的方法在面向目标的语义通信场景中是有效的，并说明了精度、通信负担和解决方案复杂性之间的主要权衡。

**Conclusion:** 通过利用MIMO技术并设计特定的预编码器/解码器，可以有效地解决语义通信中的潜在空间失配问题，同时减轻物理信道损伤，并在精度、通信负担和复杂性之间实现权衡。

> **ai_Abstract:** 本文提出了一种创新的MIMO语义通信方法，旨在解决设备间因语言、逻辑或表示差异导致的潜在空间失配问题。通过学习MIMO预编码器/解码器对，该方法能够同时实现潜在空间压缩和语义信道均衡，有效缓解语义不匹配和物理信道损伤。文中探讨了线性模型和神经网络模型两种实现方案，并通过实验验证了其在目标导向语义通信中的有效性，分析了精度、通信负担与复杂性之间的权衡。

> **摘要翻译:** 语义通信侧重于优先理解传输数据背后的含义，并确保成功完成促使信息交换的任务。然而，当设备依赖不同的语言、逻辑或内部表示时，可能会发生语义不匹配，从而可能阻碍相互理解。本文引入了一种新颖的方法来解决语义通信中的潜在空间失配问题，该方法利用了多输入多输出（MIMO）通信。具体而言，我们的方法学习一个MIMO预编码器/解码器对，该对共同执行潜在空间压缩和语义信道均衡，从而减轻语义不匹配和物理信道损伤。我们探索了两种解决方案：(i) 线性模型，通过交替方向乘子法（ADMM）求解双凸优化问题进行优化；(ii) 基于神经网络的模型，该模型在传输功率预算和复杂性约束下学习语义MIMO预编码器/解码器。数值结果表明，所提出的方法在面向目标的语义通信场景中是有效的，并说明了精度、通信负担和解决方案复杂性之间的主要权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [581] [GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks](https://arxiv.org/abs/2507.14679)
> *GCC-Spam：基于GAN、对比学习和字符相似性网络的垃圾邮件检测*

*Zhijie Wang, Zixin Xu, Zhiyuan Pan* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 垃圾邮件检测, GAN, 对比学习, 字符相似性网络, 文本分类

**Comment:** 

> **TL;DR:** GCC-Spam是一个新的垃圾文本检测框架，它结合了字符相似性网络、对比学习和生成对抗网络（GAN），以应对对抗性策略和标记数据稀缺的问题，并在真实世界数据集中取得了优于基线方法的性能。

**AI_Comments:** 该论文的创新之处在于其多组件集成框架，特别是结合了字符相似性网络来应对高级混淆攻击，并通过GAN和对比学习有效解决了数据稀缺和模型判别力问题。这种组合方法为垃圾文本检测领域提供了一个鲁棒且高效的解决方案，尤其是在对抗性环境和有限标记数据的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 互联网上垃圾文本的指数级增长需要强大的检测机制来降低信息泄露和社会不稳定等风险。本研究旨在解决垃圾邮件发送者使用的对抗性策略以及标记数据稀缺这两个主要挑战。

**Method:** 本研究提出了一个名为GCC-Spam的新型垃圾文本检测框架，它整合了三项核心创新：1. 字符相似性网络：捕获正字法和语音特征，以对抗字符混淆攻击，并为下游分类生成句子嵌入。2. 对比学习：通过优化垃圾文本和正常文本之间潜在空间距离来增强可区分性。3. 生成对抗网络（GAN）：生成逼真的伪垃圾样本，以缓解数据稀缺问题，同时提高模型鲁棒性和分类精度。

**Result:** 在真实世界数据集上进行的广泛实验表明，GCC-Spam模型优于基线方法，在标记样本显著更少的情况下实现了更高的检测率。

**Conclusion:** GCC-Spam框架通过结合字符相似性网络、对比学习和GAN，有效解决了垃圾文本检测中的对抗性策略和数据稀缺问题，并在性能上超越了现有基线方法。

> **ai_Abstract:** GCC-Spam是一个针对垃圾文本检测的新框架，旨在应对垃圾邮件发送者的对抗性策略和标记数据稀缺问题。它集成了字符相似性网络以处理字符混淆并生成嵌入，利用对比学习增强文本区分度，并通过GAN生成伪垃圾样本以扩充数据。实验证明，该模型在更少标记数据的情况下，性能优于现有基线方法。

> **摘要翻译:** 互联网上垃圾文本的指数级增长使得需要强大的检测机制来降低信息泄露和社会不稳定等风险。这项工作解决了两个主要挑战：垃圾邮件发送者采用的对抗性策略和标记数据稀缺。我们提出了一个新颖的垃圾文本检测框架GCC-Spam，它整合了三项核心创新。首先，一个字符相似性网络捕获正字法和语音特征，以对抗字符混淆攻击，并为下游分类生成句子嵌入。其次，对比学习通过优化垃圾文本和正常文本之间潜在空间距离来增强可区分性。第三，生成对抗网络（GAN）生成逼真的伪垃圾样本，以缓解数据稀缺问题，同时提高模型鲁棒性和分类精度。在真实世界数据集上进行的广泛实验表明，我们的模型优于基线方法，在标记样本显著更少的情况下实现了更高的检测率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [600] [Self-similarity Analysis in Deep Neural Networks](https://arxiv.org/abs/2507.17785)
> *深度神经网络中的自相似性分析*

*Jingyi Ding, Chengwen Qi, Hongfei Wang, Jianshe Wu, Licheng Jiao, Yuwei Guo, Jian Gao* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 自相似性, 深度神经网络, 特征网络, 模型优化, 分类性能

**Comment:** 

> **TL;DR:** 该研究提出一种基于隐藏层神经元输出特征的复杂网络建模方法，用于量化分析深度神经网络中特征表示的自相似性，并发现通过在训练过程中嵌入自相似性约束可以提高部分网络的分类性能。

**AI_Comments:** 该论文创新性地将复杂网络建模引入深度神经网络的自相似性分析，并首次定量探讨了隐藏空间几何自相似性对模型优化的影响。其发现自相似性程度因架构而异，并提出通过约束自相似性提升性能，为理解和优化深度神经网络提供了新的视角和实用方法。这项工作的重要性在于揭示了深度学习模型深层结构的新特性，并为模型设计和训练提供了潜在的改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前研究发现深度神经网络在特征表示或参数分布中表现出层级自相似性，但缺乏对隐藏空间几何自相似性如何影响模型权重优化以及内部神经元动态行为的定量分析和清晰理解。

**Method:** 本文提出一种基于隐藏层神经元输出特征的复杂网络建模方法，用于研究在不同隐藏层构建的特征网络的自相似性，并分析调整特征网络自相似性程度如何提升深度神经网络的分类性能。

**Result:** 研究在MLP、卷积网络和注意力架构三种网络类型上进行了验证，结果表明：1. 特征网络表现出的自相似性程度因模型架构而异。2. 在训练过程中对特征网络的自相似性嵌入约束，可以将自相似深度神经网络（MLP架构和注意力架构）的性能提高多达6个百分点。

**Conclusion:** 通过对深度神经网络中特征表示的自相似性进行定量分析和调控，可以有效提升部分模型的分类性能。

> **ai_Abstract:** 本研究旨在解决深度神经网络中特征表示自相似性缺乏定量分析的问题。作者提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，用于探究不同隐藏层特征网络的自相似性，并分析其对分类性能的影响。实验在MLP、卷积网络和注意力架构上进行，发现特征网络的自相似性程度因模型架构而异。更重要的是，在训练过程中引入自相似性约束能够将特定类型（MLP和注意力）深度神经网络的性能提升高达6个百分点。

> **摘要翻译:** 当前研究发现一些深度神经网络在特征表示或参数分布中表现出强大的分层自相似性。然而，除了关于权重幂律分布在不同训练阶段如何影响模型性能的初步研究外，目前还没有关于隐藏空间几何自相似性如何影响模型权重优化，也没有对内部神经元动态行为的清晰理解的定量分析。因此，本文提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，以研究在不同隐藏层构建的特征网络的自相似性，并分析调整特征网络自相似性程度如何增强深度神经网络的分类性能。本研究在三种类型的网络（MLP架构、卷积网络和注意力架构）上进行了验证，结果表明特征网络表现出的自相似性程度在不同模型架构中有所不同。此外，在训练过程中对特征网络的自相似性嵌入约束，可以将自相似深度神经网络（MLP架构和注意力架构）的性能提高多达6个百分点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [601] [VIBE: Video-Input Brain Encoder for fMRI Response Modeling](https://arxiv.org/abs/2507.17958)
> *VIBE：视频输入脑编码器用于fMRI响应建模*

*Daniel Carlstrom Schad, Shrey Dixit, Janis Keck, Viktor Studenyak, Aleksandr Shpilevoi, Andrej Bicanski* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-23**

**Keywords:** fMRI预测, 视频输入, 脑编码器, Transformer, 多模态融合

**Comment:** 

> **TL;DR:** VIBE是一个两阶段Transformer，融合视频、音频、文本特征来预测fMRI活动，并在电影数据上取得了高相关性，赢得了挑战赛。

**AI_Comments:** VIBE的创新之处在于其多模态特征融合能力，能够将视频、音频和文本信息整合起来预测大脑活动，这对于理解复杂刺激下的大脑编码机制具有重要意义。其在挑战赛中的优异表现也证明了其方法的有效性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 预测fMRI活动，以理解大脑如何处理多模态信息。

**Method:** VIBE是一个两阶段Transformer。第一阶段是模态融合Transformer，融合来自开源模型（Qwen2.5, BEATs, Whisper, SlowFast, V-JEPA）的视频、音频和文本特征。第二阶段是预测Transformer，带旋转嵌入，用于时间解码。模型在CNeuroMod数据集的65小时电影数据上训练，并对20个种子进行集成。

**Result:** VIBE在分布内Friends S07上达到32.25的平均体素级Pearson相关性，在六部分布外电影上达到21.25。该架构的早期版本分别获得0.3198和0.2096，赢得了Algonauts 2025挑战赛的第一阶段并获得总成绩第二名。

**Conclusion:** VIBE能够有效预测观看多模态内容时的大脑fMRI活动，并在相关挑战赛中表现出色，证明了其在脑编码建模方面的有效性。

> **ai_Abstract:** VIBE是一种创新的两阶段Transformer模型，旨在通过融合视频、音频和文本等多模态特征来预测大脑的fMRI活动。它利用了多个先进的开源模型提取特征，并通过模态融合和时间解码Transformer处理。该模型在大量电影数据上训练，并在分布内和分布外电影上均取得了显著的fMRI预测相关性，同时在Algonauts 2025挑战赛中获得了优异成绩。

> **摘要翻译:** 我们提出了VIBE，一个两阶段Transformer，它融合多模态视频、音频和文本特征来预测fMRI活动。来自开源模型（Qwen2.5、BEATs、Whisper、SlowFast、V-JEPA）的表示通过模态融合Transformer合并，并通过带有旋转嵌入的预测Transformer进行时间解码。VIBE在CNeuroMod数据集的65小时电影数据上训练，并对20个种子进行集成，在分布内Friends S07上达到了32.25的平均体素级Pearson相关性，在六部分布外电影上达到了21.25。同一架构的早期迭代分别获得了0.3198和0.2096，赢得了Algonauts 2025挑战赛的第一阶段并获得了总成绩第二名。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [603] [Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings](https://arxiv.org/abs/2502.01108)
> *Pulse-PPG：一个开源的、经过现场训练的PPG基础模型，适用于实验室和现场可穿戴应用*

*Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar* | **Category: cs.LG, cs.AI, eess.SP** | **Updated: 2025-07-23**

**Keywords:** PPG基础模型, 现场训练, 开源, 可穿戴应用, 泛化能力

**Comment:** Saha and Xu are co-first authors

> **TL;DR:** Pulse-PPG是一个新的开源PPG基础模型，专门用100天现场研究中收集的原始数据训练，并在多项任务中表现出优于临床数据训练模型的泛化能力。

**AI_Comments:** Pulse-PPG的创新之处在于其完全依赖于大规模现场收集的原始PPG数据进行训练，而非传统的临床数据。这克服了现有PPG基础模型在真实世界泛化能力上的局限性。其重要性在于证明了真实世界数据变异性对于模型学习更鲁棒、更具泛化性表示的关键作用，并为可穿戴设备在实际应用中的生物信号监测提供了新的范式。通过开源，它有望加速该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的PPG基础模型要么是开源但基于临床数据训练，要么是闭源的，这限制了它们在真实世界场景中的适用性。研究旨在开发一个适用于真实世界应用且泛化能力强的PPG基础模型。

**Method:** 本文介绍了Pulse-PPG，这是第一个完全基于120名参与者100天现场研究中收集的原始PPG数据训练的开源PPG基础模型。通过在多个数据集和下游任务上评估Pulse-PPG，并与最先进的临床数据训练基础模型进行性能比较。

**Result:** Pulse-PPG，一个通过未整理的现场数据训练的模型，在实验室和现场设置中，在临床和移动健康应用方面均表现出卓越的泛化能力。现场数据预训练在许多任务中甚至优于临床数据预训练，表明真实世界数据变异性有助于模型学习更精细的表示。

**Conclusion:** 在真实世界、多样化数据集上进行训练对于开发更具泛化性和适应性的PPG基础模型至关重要。Pulse-PPG的发布将为研究人员提供一个强大的资源，以推动鲁棒基础模型的发展。

> **ai_Abstract:** 本文提出了Pulse-PPG，一个创新的开源PPG基础模型，其独特之处在于完全使用来自为期100天、120名参与者的现场研究中收集的原始PPG数据进行训练。与现有模型相比，Pulse-PPG旨在克服临床数据训练模型的局限性或闭源模型的适用性问题。通过在多项下游任务和数据集上进行评估，结果显示Pulse-PPG在泛化能力上优于临床数据训练的模型，尤其是在真实世界场景中。这强调了使用多样化的现场数据进行训练对于提升模型适应性和鲁棒性的重要性。该模型计划开源，以促进未来PPG基础模型的研究与开发。

> **摘要翻译:** 光电容积描记法（PPG）基础模型因其在生物信号监测中的广泛应用以及在不同健康应用中泛化的潜力而受到关注。在本文中，我们介绍了Pulse-PPG，这是第一个完全基于在为期100天的现场研究中从120名参与者收集的原始PPG数据训练的开源PPG基础模型。现有的PPG基础模型要么是开源但基于临床数据训练，要么是闭源的，这限制了它们在真实世界场景中的适用性。我们在多个数据集和下游任务中评估了Pulse-PPG，并将其性能与一个最先进的临床数据训练基础模型进行了比较。我们的结果表明，Pulse-PPG，一个通过未经整理的现场数据训练的模型，在实验室和现场设置中，在临床和移动健康应用方面均表现出卓越的泛化能力。这表明暴露于真实世界变异性使模型能够学习精细的表示，使其在不同任务中更具适应性。此外，在许多任务中，现场数据预训练的性能出人意料地优于临床数据预训练，这再次强调了在真实世界、多样化数据集上进行训练的重要性。为了鼓励利用现场数据开发鲁棒基础模型的进一步进展，我们计划发布Pulse-PPG，为研究人员提供一个开发更具泛化性PPG基础模型的强大资源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [607] [Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards](https://arxiv.org/abs/2507.14783)
> *全能思考者：通过混合奖励多任务强化学习扩展大型语言模型的跨领域泛化能力*

*Derek Li, Jiaming Zhou, Amirreza Kazemi, Qianyi Sun, Abbas Ghaddar, Mohammad Ali Alomrani, Liheng Ma, Yu Luo, Dong Li, Feng Wen, Jianye Hao, Mark Coates, Yingxue Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 强化学习, 跨领域泛化, 混合奖励, 课程学习

**Comment:** 

> **TL;DR:** Omni-Thinker是一个统一的RL框架，通过结合规则奖励和LLM-as-a-Judge的偏好信号，并通过课程学习策略，显著提升了LLM的跨领域泛化能力，优于联合训练和模型合并。

**AI_Comments:** 这项工作创新性地提出了Omni-Thinker框架，通过结合混合奖励（规则奖励与LLM-as-a-Judge偏好）和课程学习策略，有效提升了大型语言模型在跨领域任务上的泛化能力，克服了传统SFT方法倾向于记忆的局限性。其对RL训练扩展到主观领域的探索以及课程学习策略的有效性证明，对未来通用LLM的训练和部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在后训练方法（如SFT）中存在泛化能力不足的问题，倾向于记忆而非可迁移学习，这阻碍了通用人工智能的发展，因为通用AI需要LLMs在广泛任务中表现出色。

**Method:** 本文提出了Omni-Thinker，一个统一的强化学习（RL）框架。它通过结合基于规则的可验证奖励和通过“LLM作为评判者”评估产生的生成偏好信号来提升LLM在不同任务上的性能。该方法实现了跨任务类型的一致优化，并将基于RL的训练扩展到主观领域。此外，研究还探索了训练策略，发现从结构化到开放式任务的课程式学习方法能够提高性能并减少遗忘。

**Result:** 在四个领域的实验结果表明，课程学习比联合训练提高了5.2%的性能，比模型合并提高了9.1%的性能。

**Conclusion:** 这些结果强调了任务感知采样和混合监督在扩展基于强化学习的后训练以实现通用大型语言模型方面的重要性。

> **ai_Abstract:** 本文提出了Omni-Thinker，一个统一的强化学习框架，旨在解决大型语言模型在跨领域泛化方面的不足。该框架通过结合规则奖励和基于LLM-as-a-Judge的偏好信号，实现了对LLM在多样任务上的性能提升。研究还发现，采用从结构化到开放式任务的课程学习策略能够有效提高模型性能并减少遗忘，实验结果表明其优于联合训练和模型合并，强调了任务感知采样和混合监督在LLM后训练中的关键作用。

> **摘要翻译:** 通用人工智能的进步依赖于在从结构化推理到创意生成等广泛任务中表现出色的大型语言模型（LLMs）。然而，监督微调（SFT）等后训练方法往往在泛化方面表现不佳，倾向于记忆而非可迁移学习。在这项工作中，我们引入了Omni-Thinker，一个统一的强化学习（RL）框架，它通过结合基于规则的可验证奖励和通过“LLM作为评判者”评估产生的生成偏好信号来增强LLM在不同任务上的性能。我们的方法实现了跨任务类型的一致优化，并将基于RL的训练扩展到主观领域。我们进一步研究了训练策略，证明了从结构化任务到开放式任务的课程式进展能够提高性能并减少遗忘。在四个领域的实验结果表明，课程学习比联合训练提高了5.2%的性能，比模型合并提高了9.1%的性能。这些结果强调了任务感知采样和混合监督在扩展基于强化学习的后训练以实现通用大型语言模型方面的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [614] [FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting](https://arxiv.org/abs/2507.18219)
> *FedSA-GCL：一种具有个性化聚合和集群感知广播的半异步联邦图学习框架*

*Zhongzheng Yuan, Lianshuai Guo, Xunkai Li, Yinlin Zhu, Wenyu Wang, Meixia Qu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 联邦图学习, 半异步, 集群感知广播, 个性化聚合, 效率

**Comment:** 

> **TL;DR:** FedSA-GCL 提出一种半异步联邦图学习框架，通过考虑标签分布和拓扑特性，解决了现有联邦图学习方法的同步低效性和异步方法的不适用性问题，提高了效率和鲁棒性。

**AI_Comments:** FedSA-GCL 的创新之处在于其半异步通信范式，有效解决了联邦图学习中同步通信的效率瓶颈。同时，它通过考虑图数据的独特拓扑特性和客户端标签分布差异，避免了传统异步联邦学习方法应用于图数据时可能出现的语义漂移问题。其提出的 ClusterCast 机制是关键创新点，有望提升实际部署中的效率和模型质量。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有联邦图学习（FGL）方法依赖同步通信，导致效率低下且在实际部署中不切实际。同时，当前的异步联邦学习（AFL）方法主要针对传统任务设计，未考虑图数据的独特拓扑特性，直接应用于图学习可能导致全局模型的语义漂移和表示不一致。

**Method:** 我们提出了 FedSA-GCL，一个半异步联邦框架。它通过新颖的 ClusterCast 机制，利用客户端间的标签分布差异和图拓扑特性进行高效训练。我们在多个真实世界图数据集上，使用 Louvain 和 Metis 分割算法评估了 FedSA-GCL，并与9个基线进行了比较。

**Result:** FedSA-GCL 表现出强大的鲁棒性和卓越的效率。与基线相比，在使用 Louvain 分割时，平均性能提高了 2.92%；在使用 Metis 分割时，平均性能提高了 3.4%。

**Conclusion:** FedSA-GCL 有效解决了联邦图学习中同步通信的低效性以及将传统异步联邦学习方法直接应用于图数据所带来的挑战，实现了优越的性能和鲁棒性。

> **ai_Abstract:** 本文提出了 FedSA-GCL，一个半异步联邦图学习框架，旨在解决现有联邦图学习中同步通信效率低下的问题，以及传统异步联邦学习方法不适用于图数据所导致的语义漂移和表示不一致。FedSA-GCL 通过利用客户端间的标签分布差异和图拓扑特性，并采用创新的 ClusterCast 机制，实现了高效训练。在多个真实世界图数据集上的广泛实验表明，FedSA-GCL 具有强大的鲁棒性和卓越的效率，其性能显著优于现有基线。

> **摘要翻译:** 联邦图学习（FGL）是一种分布式学习范式，它使得在多个本地系统上托管的大规模子图之间进行协作训练成为可能。然而，大多数现有 FGL 方法依赖于同步通信，这导致效率低下，并且在实际部署中往往不切实际。同时，当前的异步联邦学习（AFL）方法主要为图像分类和自然语言处理等传统任务设计，没有考虑图数据独特的拓扑特性。直接将这些方法应用于图学习可能会导致全局模型中出现语义漂移和表示不一致。为了解决这些挑战，我们提出了 FedSA-GCL，一个半异步联邦框架，它通过一种新颖的 ClusterCast 机制，利用客户端间的标签分布差异和图拓扑特性进行高效训练。我们使用 Louvain 和 Metis 分割算法在多个真实世界图数据集上评估了 FedSA-GCL，并将其与9个基线进行了比较。广泛的实验表明，我们的方法具有强大的鲁棒性和卓越的效率，在使用 Louvain 分割时，平均性能比基线高 2.92%，在使用 Metis 分割时，平均性能高 3.4%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [617] [Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation](https://arxiv.org/abs/2507.15205)
> *长短距离图神经网络和改进课程学习用于会话情感识别*

*Xinran Li, Xiujuan Xu, Jiaqi Qiao* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 会话情感识别, 图神经网络, 课程学习, 多模态, 数据不平衡

**Comment:** Accepted by the 28th European Conference on Artificial Intelligence
  (ECAI 2025)

> **TL;DR:** 本文提出了一种新颖的多模态方法——长短距离图神经网络（LSDGNN）和改进课程学习（ICL），用于解决会话情感识别（ERC）中的挑战，并在IEMOCAP和MELD数据集上取得了优于现有基准的性能。

**AI_Comments:** 该论文的创新点在于其提出的长短距离图神经网络（LSDGNN）能够有效捕获和融合会话中不同距离的话语特征，并通过差分正则器和BiAffine模块优化特征表示。同时，引入改进课程学习（ICL）来解决数据不平衡问题，通过动态调整学习难度，进一步提升了模型性能。这些方法结合起来，为会话情感识别提供了一个有效且全面的解决方案，具有重要的研究和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 会话情感识别（ERC）是一项实用但具有挑战性的任务。

**Method:** 本文提出长短距离图神经网络（LSDGNN），基于有向无环图（DAG）构建长距离和短距离GNN，以分别获取远距离和近距离话语的多模态特征。为确保长短距离特征的区分性并促进模块间相互影响，采用了差分正则化器和BiAffine模块。此外，提出改进课程学习（ICL）来解决数据不平衡问题，通过计算情感相似度设计“加权情感转移”指标和难度测量器，实现先易后难的训练过程。

**Result:** 在IEMOCAP和MELD数据集上的实验结果表明，该模型优于现有基准。

**Conclusion:** 本文提出的长短距离图神经网络（LSDGNN）和改进课程学习（ICL）方法，有效提升了会话情感识别的性能。

> **ai_Abstract:** 本文针对会话情感识别（ERC）任务的挑战性，提出了一种新颖的多模态方法——长短距离图神经网络（LSDGNN），该网络基于有向无环图（DAG）构建长短距离GNN以捕获不同距离的话语多模态特征，并通过差分正则化器和BiAffine模块优化特征区分与交互。为应对数据不平衡，论文还引入了改进课程学习（ICL），通过设计“加权情感转移”指标和难度测量器，实现了从易到难的训练策略。实验结果表明，该模型在IEMOCAP和MELD数据集上均超越了现有基准。

> **摘要翻译:** 会话情感识别（ERC）是一项实用且具有挑战性的任务。本文提出了一种新颖的多模态方法，即长短距离图神经网络（LSDGNN）。它基于有向无环图（DAG），构建了一个长距离图神经网络和一个短距离图神经网络，分别获取远距离和近距离话语的多模态特征。为了确保长距离和短距离特征在表示上尽可能不同，同时使两个模块之间能够相互影响，我们采用了差分正则化器并结合了BiAffine模块以促进特征交互。此外，我们提出了一种改进的课程学习（ICL）来解决数据不平衡的挑战。通过计算不同情感之间的相似性以强调相似情感的转变，我们设计了一个“加权情感转移”度量并开发了一个难度测量器，从而实现了一个优先学习简单样本再学习困难样本的训练过程。在IEMOCAP和MELD数据集上的实验结果表明，我们的模型优于现有基准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [624] [Reinforcement Learning for Accelerated Aerodynamic Shape Optimisation](https://arxiv.org/abs/2507.17786)
> *强化学习加速气动外形优化*

*Florian Sobieczky, Alfredo Lopez, Erika Dudkin, Christopher Lackner, Matthias Hochsteger, Bernhard Scheichl, Helmut Sobieczky* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 强化学习, 气动外形优化, 降维, 自适应优化, Actor-Critic MCMC

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的自适应优化算法，用于气动外形优化，旨在通过降维减少计算量并解释优化结果。

**AI_Comments:** 该论文提出了一种新颖的将强化学习应用于气动外形优化的方法，特别关注降维和计算效率。其创新点在于结合了代理模型、Actor-Critic和MCMC，并引入了参数“冻结”机制。该方法不仅旨在加速优化过程，还试图为优化结果提供可解释性，这对于工程应用具有重要意义。然而，抽象中并未深入探讨其在复杂真实世界问题中的泛化能力和具体性能提升的量化数据。

<details>
  <summary>Details</summary>

**Motivation:** 最小化计算量，并利用观察到的优化结果来解释所发现极值在实现所需流场中的作用。

**Method:** 提出了一种基于强化学习的自适应优化算法，应用于气动外形优化，侧重于降维。该强化学习形式是一种基于代理的、Actor-Critic策略评估MCMC方法，允许对部分待优化参数进行时间上的“冻结”。通过围绕作为真实值的中间CFD模拟进行一系列局部优化参数更改，可以在特定条件下加速全局优化。

**Result:** 该方法在一个简单的流体动力学问题上实现了特征重要性评分的解释。如果参数的局部邻域足够大且奖励和成本的估计足够准确，则可以加速全局优化。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种基于强化学习（RL）的自适应优化算法，专门用于加速气动外形优化，通过降维来降低计算成本。该算法采用基于代理的Actor-Critic策略评估MCMC方法，并允许临时“冻结”部分优化参数。其主要目标是减少计算量，并帮助解释优化结果中发现的极值在实现所需流场中的作用。研究指出，通过局部参数调整和中间CFD模拟，若满足特定条件（足够大的参数邻域和准确的奖励/成本估计），可显著加速全局优化。文章通过一个流体动力学实例展示了该方法在特征重要性评分方面的解释能力。

> **摘要翻译:** 我们引入了一种基于强化学习（RL）的自适应优化算法，用于气动外形优化，重点在于降维。此处应用RL的形式是一种基于代理的、Actor-Critic策略评估MCMC方法，允许对部分待优化参数进行时间上的“冻结”。目标是最小化计算量，并利用观察到的优化结果来解释所发现的极值在实现所需流场中的作用。通过围绕作为真实值的中间CFD模拟进行一系列局部优化参数更改，如果 (a) 变化参数必须驻留的参数局部邻域足够大以与网格大小的步长及其大量的模拟竞争，并且 (b) 这些邻域上用于良好分步参数适应所需的奖励和成本估计足够准确，则可以加速全局优化。我们给出了一个简单的流体动力学问题的例子，在该问题上该方法允许在特征重要性评分的意义上进行解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [629] [EarthLink: A Self-Evolving AI Agent for Climate Science](https://arxiv.org/abs/2507.17311)
> *EarthLink：一个用于气候科学的自进化AI智能体*

*Zijie Guo, Jiong Wang, Xiaoyu Yue, Wangxu Wei, Zhe Jiang, Wanghan Xu, Ben Fei, Wenlong Zhang, Xinyu Gu, Lijing Cheng, Jing-Jia Luo, Chao Li, Yaqiang Wang, Tao Chen, Wanli Ouyang, Fenghua Ling, Lei Bai* | **Category: cs.LG, cs.AI, physics.ao-ph** | **Updated: 2025-07-24**

**Keywords:** AI智能体, 气候科学, 地球系统数据, 科学发现, 研究自动化

**Comment:** 

> **TL;DR:** EarthLink是一个自进化的AI智能体，旨在作为地球科学家的交互式副驾驶，自动化端到端研究工作流程，解决地球系统数据分析瓶颈，并被验证其分析能力可与人类初级研究员媲美。

**AI_Comments:** EarthLink的创新之处在于其“自进化”和“交互式副驾驶”设计，能够通过动态反馈循环不断学习和优化。它自动化了端到端的研究工作流程，显著提高了效率。其分析能力被评估为与人类初级研究员相当，表明了其在科学研究中的实用性。透明和可审计的工作流程也增强了系统的可信度。该系统有望推动地球系统研究范式的转变。

<details>
  <summary>Details</summary>

**Motivation:** 现代地球科学面临海量、碎片化和复杂的地球系统数据以及日益复杂的分析需求，这严重阻碍了快速的科学发现。

**Method:** 本文引入了EarthLink，这是首个专为地球科学家设计的交互式AI智能体。它能自动化端到端的研究工作流程，包括规划、代码生成和多场景分析。与静态诊断工具不同，EarthLink可以通过用户交互学习，并通过动态反馈循环持续改进其能力。

**Result:** EarthLink在多项气候变化核心科学任务上进行了验证，包括模型-观测比较和复杂现象诊断。在多专家评估中，EarthLink生成了科学严谨的分析，并展示了与人类初级研究员工作流程特定方面相当的分析能力。

**Conclusion:** EarthLink标志着在全球变化加速的时代，地球系统研究迈向高效、可信赖和协作范式的关键一步。

> **ai_Abstract:** EarthLink是一个创新的自进化AI智能体，旨在解决地球科学领域数据分析的瓶颈。它作为地球科学家的交互式副驾驶，自动化了从研究规划到多场景分析的整个流程。该系统通过用户交互持续学习和完善，并在气候变化任务中展现出与人类初级研究员相当的分析能力。EarthLink通过透明的工作流和自然语言界面，赋能科学家进行更高效、可信赖和协作的地球系统研究。

> **摘要翻译:** 现代地球科学正处于一个转折点。地球系统数据庞大、碎片化且复杂，加上日益复杂的分析需求，为快速的科学发现带来了显著瓶颈。在此，我们介绍了EarthLink，这是第一个被设计为地球科学家交互式副驾驶的AI智能体。它自动化了端到端的研究工作流程，从规划和代码生成到多场景分析。与静态诊断工具不同，EarthLink可以通过用户交互学习，通过动态反馈循环不断完善其能力。我们验证了其在多项气候变化核心科学任务上的性能，从模型-观测比较到复杂现象的诊断。在多专家评估中，EarthLink产生了科学严谨的分析，并展示了与人类初级研究员工作流程特定方面相当的分析能力。此外，其透明、可审计的工作流程和自然语言界面使科学家能够从繁琐的手动执行转向战略性监督和假设生成。EarthLink标志着在全球变化加速的时代，地球系统研究迈向高效、可信赖和协作范式的关键一步。该系统可在我们的网站https://earthlink.intern-ai.org.cn上访问。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [643] [Improving the Computational Efficiency and Explainability of GeoAggregator](https://arxiv.org/abs/2507.17977)
> *提高GeoAggregator的计算效率和可解释性*

*Rui Deng, Ziqi Li, Mingshu Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** GeoAggregator, 计算效率, 可解释性, 地理空间数据, GeoShapley

**Comment:** 4 pages, 3 figures

> **TL;DR:** 本文通过优化数据加载、前向传播、模型集成和引入GeoShapley解释功能，显著提升了GeoAggregator的计算效率和可解释性。

**AI_Comments:** 这篇论文通过对GeoAggregator模型进行优化，在计算效率和可解释性方面取得了显著进步。其创新点在于结合了流水线优化、模型集成和基于GeoShapley的解释框架，这对于实际应用中处理地理空间数据具有重要意义。公开代码库也进一步提升了其研究价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模和解释地理空间表格数据（GTD）对于理解地理空间现象及其底层过程至关重要。GeoAggregator（GA）模型已被提出并表现出色，但仍有提升计算效率和可解释性的空间。

**Method:** 本文通过开发优化的数据加载和前向传播流水线来提高计算效率，并通过整合模型集成策略和基于GeoShapley框架的事后模型解释功能来增强模型可解释性。

**Result:** 实验结果表明，改进后的GeoAggregator模型在合成数据集上与原始实现相比，提高了预测准确性和推理速度。此外，解释实验表明GeoAggregator能够有效捕获合成数据集中固有的空间效应。

**Conclusion:** 改进的GeoAggregator模型在计算效率和可解释性方面均取得了显著提升，并且能够有效捕捉空间效应，其完整流水线已公开可用。

> **ai_Abstract:** 本文旨在提升GeoAggregator（GA）模型在地理空间表格数据（GTD）建模方面的计算效率和可解释性。作者通过优化数据加载和前向传播流程来加速模型运行，并引入模型集成策略和基于GeoShapley的事后解释功能来增强模型的可解释性。在合成数据集上的实验验证了这些改进，结果显示新实现显著提高了GA的预测准确性和推理速度，并能有效揭示数据中的空间效应。

> **摘要翻译:** 准确建模和解释地理空间表格数据（GTD）对于理解地理空间现象及其底层过程至关重要。最近的工作为此目的提出了一种名为GeoAggregator（GA）的新型基于Transformer的深度学习模型，并已证明其优于其他统计和机器学习方法。在这篇短文中，我们通过以下方式进一步改进GA：1）开发一个优化的流水线，加速数据加载过程并简化GA的前向传播，以实现更好的计算效率；2）结合模型集成策略和基于GeoShapley框架的事后模型解释功能，以增强模型可解释性。我们通过将改进后的GA模型应用于合成数据集来验证所提出策略的功能性和效率。实验结果表明，与原始实现相比，我们的实现提高了GA的预测准确性和推理速度。此外，解释实验表明GA能够有效捕获所设计合成数据集中固有的空间效应。完整的流水线已公开发布供社区使用（https://github.com/ruid7181/GA-sklearn）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [647] [TOC-UCO: a comprehensive repository of tabular ordinal classification datasets](https://arxiv.org/abs/2507.17348)
> *TOC-UCO：一个综合的表格序数分类数据集存储库*

*Rafael Ayllón-Gavilán, David Guijo-Rubio, Antonio Manuel Gómez-Orellana, Francisco Bérchez-Moreno, Víctor Manuel Vargas-Yun, Pedro A. Gutiérrez* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 序数分类, 数据集存储库, 基准测试, TOC-UCO, 表格数据

**Comment:** 25 single column pages, 5 figures, 7 tables

> **TL;DR:** TOC-UCO是一个为序数分类（OC）领域提供46个预处理过的表格数据集的公共存储库，旨在解决现有OC方法基准测试缺乏综合数据集的问题，并促进实验的可复现性。

**AI_Comments:** 该论文的创新之处在于提供了一个专门针对序数分类问题的综合数据集存储库。其重要性在于直接解决了OC领域研究中的一个关键痛点——缺乏标准化的、易于获取的数据集用于方法验证和基准测试。通过提供预处理的数据集和可复现的训练-测试分区，TOC-UCO显著降低了研究人员进行新方法评估的门槛，并有助于提高该领域研究结果的可靠性和可比较性。

<details>
  <summary>Details</summary>

**Motivation:** 序数分类（OC）领域的发展面临一个主要缺点：缺乏一个综合的数据集集合，用于对新方法进行基准测试。这阻碍了OC新方法的稳健验证。

**Method:** 本手稿提供了一个名为TOC-UCO的公共可用的表格数据存储库，用于稳健验证新的OC方法。该存储库包含46个在通用框架下预处理的表格序数数据集，并确保具有合理的模式数量和适当的类别分布。它还提供了每个数据集的来源、预处理步骤以及如何使用TOC-UCO存储库对新方法进行基准测试的详细信息，包括30个不同随机训练-测试分区的索引，以方便实验的可复现性。

**Result:** 结果是创建了一个名为TOC-UCO的综合表格序数分类数据集存储库，其中包含46个预处理过的数据集，以及用于基准测试和可复现性的相关信息和分区索引。

**Conclusion:** TOC-UCO存储库解决了序数分类领域缺乏综合数据集的问题，通过提供一个公共可用的、预处理过的表格数据集集合以及用于基准测试和可复现性的工具，促进了新OC方法的稳健验证和实验的可重复性。

> **ai_Abstract:** 本文介绍了TOC-UCO，一个由科尔多瓦大学（UCO）开发的综合表格序数分类（OC）数据集存储库。该存储库旨在解决OC领域缺乏标准基准数据集的瓶颈。TOC-UCO包含46个经过通用框架预处理的表格OC数据集，并提供了数据集来源、预处理步骤以及用于促进实验可复现性的30个随机训练-测试分区索引。该资源为OC新方法的稳健验证和基准测试提供了宝贵的支持。

> **摘要翻译:** 一个序数分类（OC）问题对应于一种特殊类型的分类，其特点是类别之间存在自然的顺序关系。这种类型的问题可以在许多现实世界的应用中找到，这促使在过去几年中设计和开发了许多序数方法。然而，重要的是要强调，OC领域的发展面临一个主要缺点：缺乏一个综合的数据集集合，用于对文献中的新方法进行基准测试。为了实现这一目标，这篇来自科尔多瓦大学（UCO）的手稿，该大学在OC领域拥有丰富的经验，为文献提供了一个公共可用的表格数据存储库，用于新OC方法的稳健验证，即TOC-UCO（UCO的表格序数分类存储库）。具体来说，该存储库包含46个表格序数数据集，这些数据集在通用框架下进行了预处理，并确保具有合理的模式数量和适当的类别分布。我们还提供了每个数据集的来源和预处理步骤，以及如何使用TOC-UCO存储库对新方法进行基准测试的详细信息。为此，提供了30个不同随机训练-测试分区的索引，以方便实验的可复现性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [648] [Hyperbolic Deep Learning for Foundation Models: A Survey](https://arxiv.org/abs/2507.17787)
> *双曲深度学习在基础模型中的应用：一项综述*

*Neil He, Hiren Madhu, Ngoc Bui, Menglin Yang, Rex Ying* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 双曲深度学习, 基础模型, 欧几里得几何, 表示能力, 综述

**Comment:** 11 Pages, SIGKDD 2025

> **TL;DR:** 本综述探讨了双曲深度学习如何解决当前基础模型（如LLMs和VLMs）在表示能力、适应性和可扩展性方面的局限性，并概述了该领域的挑战和未来方向。

**AI_Comments:** 该综述突出了双曲几何在解决当前基础模型核心局限性方面的潜力，尤其是在处理具有内在层次结构和幂律分布的数据时。其创新点在于将非欧几何引入到大规模模型中，为提升模型效率和性能提供了新的视角。该领域的重要性在于它可能突破现有模型的瓶颈，为构建更强大、更高效的AI模型奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基础模型（如LLMs、VLMs和大型多模态模型）在表示能力、适应性和可扩展性方面存在局限性。研究者质疑欧几里得几何是否是所有基础模型的最佳归纳偏置，并认为引入替代几何空间（如双曲空间）可以更好地与真实世界数据的内在结构对齐并改进推理过程。

**Method:** 本文对双曲神经网络及其在基础模型中的最新发展进行了全面的综述。

**Result:** 双曲空间能够以更少的维度对分层结构和幂律分布进行低失真嵌入。利用这些特性，双曲深度学习已增强了基础模型，包括提高LLMs的复杂推理能力、VLMs的零样本泛化能力以及跨模态语义对齐，同时保持了参数效率。

**Conclusion:** 双曲深度学习为解决当前基础模型的局限性提供了一个有前景的方向，但该领域仍面临关键挑战，并有待进一步研究和发展。

> **ai_Abstract:** 本综述探讨了当前基础模型（LLMs、VLMs等）在表示能力、适应性和可扩展性方面的局限性，并提出双曲空间作为一种潜在的解决方案。双曲几何因其指数体积增长特性，能以低失真嵌入分层数据，从而增强了基础模型在复杂推理、零样本泛化和跨模态对齐方面的能力，同时保持参数效率。论文全面回顾了双曲神经网络及其在基础模型中的应用，并指出了未来的研究方向和挑战。

> **摘要翻译:** 基础模型在海量数据集上进行预训练，包括大型语言模型（LLMs）、视觉-语言模型（VLMs）和大型多模态模型，在各种下游任务中展现出卓越的成功。然而，最近的研究表明这些模型存在根本性局限性：（1）有限的表示能力，（2）较低的适应性，以及（3）日益下降的可扩展性。这些缺点提出了一个关键问题：欧几里得几何真的是所有基础模型的最佳归纳偏置吗？或者，引入替代几何空间是否能使模型更好地与真实世界数据的内在结构对齐并改进推理过程？双曲空间是一类非欧几何流形，其特点是体积随距离呈指数增长，提供了一个有数学依据的解决方案。这些空间能够以比欧几里得对应物少得多的维度实现分层结构（例如，树、分类法）和幂律分布的低失真嵌入。最近的进展已经利用这些特性来增强基础模型，包括改进LLMs的复杂推理能力、VLMs的零样本泛化能力以及跨模态语义对齐，同时保持参数效率。本文全面回顾了双曲神经网络及其在基础模型中的最新发展。我们进一步概述了推动该领域发展的关键挑战和研究方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [652] [On Leveraging Unlabeled Data for Concurrent Positive-Unlabeled Classification and Robust Generation](https://arxiv.org/abs/2006.07841)
> *利用未标记数据进行并发正-未标记分类和鲁棒生成*

*Bing Yu, Ke Sun, He Wang, Zhouchen Lin, Zhanxing Zhu* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 正-未标记分类, 条件生成, 未标记数据, GAN, 噪声鲁棒性

**Comment:** Published in International Conference on Image and Graphics (ICIG),
  2025

> **TL;DR:** 本文提出了一种新颖的框架，该框架同时利用未标记数据进行正-未标记 (PU) 分类和鲁棒的条件生成，即使是处理分布外数据也能奏效。

**AI_Comments:** 本文通过提出一个巧妙地结合了 PU 分类和鲁棒条件生成的联合框架，解决了机器学习中一个重要的实际问题（数据稀缺）。CNI-CGAN 的引入以实现噪声鲁棒性以及预测标签的协同使用是创新点。理论证明增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 类标记数据的稀缺是许多机器学习问题中普遍存在的瓶颈。尽管存在大量未标记数据，但利用它们具有挑战性。

**Method:** 本文提出了一种新颖的训练框架，旨在同时进行正-未标记 (PU) 分类和条件生成，即使在存在分布外未标记数据的情况下也能实现。该框架通过以下方式探索两者之间的相互作用：1) 借助新型的对噪声标签具有鲁棒性的分类器-噪声不变条件 GAN (CNI-CGAN) 增强 PU 分类器性能；2) 利用来自 PU 分类器预测标签的额外数据来帮助生成。理论上，本文证明了 CNI-CGAN 的最佳条件。

**Result:** 在实验上，本文对各种数据集进行了广泛评估。

**Conclusion:** 本文通过提出一种联合框架，成功解决了利用未标记数据进行并发正-未标记分类和鲁棒生成的问题，并在理论和实验上进行了验证。

> **ai_Abstract:** 本文旨在解决类标记数据稀缺的问题，提出了一种新颖的训练框架，用于同时利用未标记数据进行正-未标记 (PU) 分类和鲁棒的条件生成。该框架通过引入一种对噪声标签具有鲁棒性的分类器-噪声不变条件 GAN (CNI-CGAN) 来增强 PU 分类器性能，并利用 PU 分类器预测的标签来辅助生成，即使面对分布外未标记数据也能有效。论文在理论上证明了 CNI-CGAN 的最优条件，并在各种数据集上进行了广泛的实验评估。

> **摘要翻译:** 类标记数据的稀缺是许多机器学习问题中普遍存在的瓶颈。尽管通常存在大量未标记数据并提供潜在解决方案，但利用它们极具挑战性。在本文中，我们通过同时利用正-未标记 (PU) 分类和带有额外未标记数据的条件生成来解决这个问题。我们提出了一种新颖的训练框架，旨在在接触额外数据，特别是分布外未标记数据时，共同实现 PU 分类和条件生成，通过探索它们之间的相互作用：1) 在一种新颖的对噪声标签具有鲁棒性的分类器-噪声不变条件 GAN (CNI-CGAN) 的帮助下，增强 PU 分类器的性能，2) 利用来自 PU 分类器预测标签的额外数据来帮助生成。在理论上，我们证明了 CNI-CGAN 的最佳条件；在实验上，我们对各种数据集进行了广泛评估。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [662] [Sparse identification of nonlinear dynamics with library optimization mechanism: Recursive long-term prediction perspective](https://arxiv.org/abs/2507.18220)
> *带有库优化机制的非线性动力学稀疏识别：递归长期预测视角*

*Ansei Yonezawa, Heisei Yonezawa, Shuichi Yahagi, Itsuro Kajiwara, Shinya Kijimoto, Hikaru Taniuchi, Kentaro Murakami* | **Category: cs.LG, math.DS** | **Updated: 2025-07-24**

**Keywords:** 稀疏识别, 非线性动力学, 库优化, 递归长期预测, SINDy

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本研究提出SINDy-LOM方法，通过两层优化架构和递归长期预测视角，解决了SINDy中库设计困难的问题，提高了模型的可靠性和可用性。

**AI_Comments:** SINDy-LOM通过引入库优化机制和递归长期预测视角，对SINDy方法进行了重要改进。其创新点在于将库设计问题转化为可优化的参数化基函数，并通过两层优化架构解决了这一难题。特别地，从RLT预测精度出发进行优化，显著提升了模型在长期预测方面的可靠性，弥补了传统SINDy仅关注一步预测的不足。这不仅减轻了用户负担，也使得模型更具实际应用价值和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏非线性动力学识别（SINDy）方法在基于测量数据发现动力系统控制方程时，面临着库（即候选基函数集）设计上的重大挑战，因为对于许多动力系统而言，找到合适的库并非易事。

**Method:** 本研究提出SINDy与库优化机制（SINDy-LOM）相结合的方法，该方法结合了稀疏回归技术和新颖的库学习策略。其中基函数被参数化。SINDy-LOM涉及一个两层优化架构：内层提取数据驱动模型作为候选基函数的稀疏线性组合；外层则从递归长期（RLT）预测精度的角度优化基函数，从而将库设计重新表述为参数化基函数的优化。

**Result:** SINDy-LOM模型具有良好的可解释性和可用性，因为它产生了简约模型。库优化机制显著降低了用户负担。与传统SINDy方法仅能确保一步超前预测精度相比，RLT视角提高了结果模型的可靠性。该方法通过应用于柴油机气路系统（一个著名的复杂工业系统）验证了其有效性。

**Conclusion:** 本研究提出的带有库优化机制的稀疏非线性动力学识别（SINDy-LOM）方法，通过优化参数化基函数解决了传统SINDy中库设计困难的问题，并在递归长期预测精度的视角下显著提高了模型的可靠性，同时降低了用户负担，具有良好的可解释性和可用性。

> **ai_Abstract:** 本研究针对稀疏非线性动力学识别（SINDy）中库设计困难的问题，提出了一种名为SINDy-LOM的新方法。SINDy-LOM结合稀疏回归和创新的库学习策略，通过参数化基函数并采用两层优化架构来解决这一挑战。内层进行数据驱动模型提取，外层则基于递归长期（RLT）预测精度优化基函数。该方法使得库设计变为参数化基函数的优化，从而显著降低用户负担，并提高了模型的可靠性、可解释性和可用性。在柴油机气路系统上的应用验证了其有效性。

> **摘要翻译:** 稀疏非线性动力学识别（SINDy）方法可以根据测量数据发现动力系统的控制方程，其中动力学模型被识别为给定基函数的稀疏线性组合。SINDy中的一个主要挑战是库的设计，即一组候选基函数，因为对于许多动力系统而言，选择合适的库并非易事。为了克服这一困难，本研究提出了带有库优化机制的SINDy（SINDy-LOM），它是稀疏回归技术和新颖的库学习策略的结合。在所提出的方法中，基函数是参数化的。SINDy-LOM方法涉及一个两层优化架构：内层，其中数据驱动模型被提取为候选基函数的稀疏线性组合；外层，其中基函数从递归长期（RLT）预测精度的角度进行优化；因此，库设计被重新表述为参数化基函数的优化。由此产生的SINDy-LOM模型具有良好的可解释性和可用性，因为所提出的方法产生了简约模型。库优化机制显著降低了用户负担。与传统SINDy方法仅能确保一步超前预测精度相比，RLT视角提高了结果模型的可靠性。所提出方法的有效性通过将其应用于柴油机气路系统（一个著名的复杂工业系统）得到了验证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [684] [Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking](https://arxiv.org/abs/2507.17788)
> *LLM排序中缓解位置偏差的自适应重复策略*

*Ali Vardasbi, Gustavo Penha, Claudia Hauff, Hugues Bouchard* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 位置偏差, LLM排名, 自适应重复, 动态早停, 计算效率

**Comment:** 

> **TL;DR:** 本文提出一种动态早停方法，通过自适应确定LLM调用次数来缓解大型语言模型（LLM）排名中的位置偏差和重复一致性低问题，显著减少计算成本的同时保持准确性。

**AI_Comments:** 这篇论文的创新点在于提出了一个“每实例”的自适应重复策略来缓解LLM中的位置偏差和低重复一致性问题，而非传统的静态重复。这种动态早停方法显著提高了LLM在排名任务中的效率，解决了计算成本高昂的痛点，对于LLM在实际应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当使用LLM进行项目排名或答案评估时，候选项目的顺序会影响模型决策（位置偏差）。LLMs还存在重复一致性低的问题。现有缓解策略（多次调用并聚合结果）会显著增加计算成本。研究发现位置偏差的方向和程度在不同实例间差异很大，这表明需要一种针对每个实例的缓解策略。

**Method:** 引入了一种动态早停方法，能够自适应地确定每个实例所需的重复调用次数。此外，还提出了一种基于置信度的自适应早停方法。

**Result:** 在三种不同大小的LLM和两种任务（重排序和对齐）上评估，动态重复策略将LLM调用次数平均减少了81%，同时保持了准确性。基于置信度的自适应方法与静态重复相比，平均减少了87%的LLM调用，相对于原始早停方法仅有轻微的准确性下降。

**Conclusion:** 提出的动态早停方法能有效缓解LLM排名中的位置偏差和低重复一致性问题，显著降低计算成本，同时保持或仅轻微影响准确性，证明了其在实际应用中的高效性。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）在排名任务中存在的“位置偏差”和“低重复一致性”问题，指出现有通过多次重复调用LLM并聚合结果的缓解策略成本过高，且位置偏差具有实例特异性。为解决这些问题，作者提出了一种动态早停方法，该方法能自适应地确定每个实例所需的LLM调用次数，并在此基础上进一步提出了基于置信度的适应性方法。实验结果表明，与静态重复相比，所提出的方法在保持或略微牺牲准确性的前提下，显著减少了LLM调用次数，平均降低了81%至87%。

> **摘要翻译:** 当使用大型语言模型（LLM）根据给定标准对项目进行排名或评估答案时，候选项目的顺序会影响模型的最终决策。这种对LLM提示中项目定位的敏感性被称为位置偏差。先前的研究表明，即使在大型模型中也存在这种偏差，尽管其严重程度因模型和任务而异。除了位置偏差，LLM还表现出不同程度的低重复一致性，即以相同的候选顺序重复调用LLM可能导致不同的排名。为了解决这两种不一致性，一种常见的方法是使用不同的候选顺序多次提示模型，并通过多数投票聚合结果。然而，这种重复策略显著增加了计算成本。在扩展先前发现的基础上，我们观察到，即使在单个数据集中，位置偏差的方向（偏向提示中较早或较晚的候选）和幅度在不同实例间也存在显著差异。这一观察强调了对每个实例采取缓解策略的必要性。为此，我们引入了一种动态早停方法，该方法自适应地确定每个实例所需的重复次数。在三种不同大小的LLM和两种任务（重排序和对齐）上评估我们的方法，我们证明了过渡到动态重复策略平均将LLM调用次数减少了81%，同时保持了准确性。此外，我们提出了一种基于置信度的自适应早停方法，与静态重复相比，该方法平均减少了87%的LLM调用，相对于我们原始的早停方法，仅有轻微的准确性权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [686] [SIFOTL: A Principled, Statistically-Informed Fidelity-Optimization Method for Tabular Learning](https://arxiv.org/abs/2507.17979)
> *SIFOTL：一种用于表格学习的、基于统计学的、有原则的保真度优化方法*

*Shubham Mohole, Sainyam Galhotra* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 表格学习, 数据偏移, 隐私保护, XGBoost, LLM

**Comment:** 

> **TL;DR:** SIFOTL是一种新的表格数据分析方法，它使用隐私安全的数据统计量，结合XGBoost和LLM来识别导致数据变化的因素，即使在存在噪声和隐私限制的情况下也能提供可解释的结果，并且表现优于现有方法。

**AI_Comments:** SIFOTL的创新之处在于其结合了隐私保护的数据摘要统计量、XGBoost模型与LLM辅助以及决策树，形成了一个端到端解决数据偏移识别中隐私和噪声问题的框架。其在医疗保健领域的应用尤其重要，展示了在敏感数据环境下进行有效分析的潜力。该方法在多个数据集上的优越性能验证了其鲁棒性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在表格数据集中识别导致数据偏移的因素是一个重大挑战，尤其是在医疗保健领域。这主要是因为隐私规则限制了数据访问，以及复杂过程中的噪声阻碍了分析。

**Method:** 提出SIFOTL方法，它包括三个步骤：(i) 提取符合隐私规定的数据摘要统计量；(ii) 使用双XGBoost模型在LLM的辅助下将干预信号与噪声分离；(iii) 通过帕累托加权决策树合并XGBoost输出，以识别导致数据偏移的可解释段。与现有方法不同，SIFOTL仅使用隐私安全的数据摘要统计量来解决噪声和数据访问限制问题。

**Result:** 在模拟新的医疗保险药物补贴的MEPS面板数据集上，SIFOTL的F1分数为0.85，显著优于BigQuery贡献分析（F1=0.46）和统计测试（F1=0.20）。在基于Synthea ABM生成的18个不同EHR数据集上，SIFOTL在无噪声情况下保持0.86-0.96的F1分数，即使注入观测噪声，F1分数也达到>=0.75，而基线平均F1分数在相同测试下为0.19-0.67。

**Conclusion:** SIFOTL提供了一种可解释、注重隐私的工作流程，并且在经验上对观测噪声具有鲁棒性。

> **ai_Abstract:** SIFOTL是一种针对表格数据分析的新方法，旨在解决数据偏移识别中的隐私限制和噪声问题，尤其是在医疗保健领域。它通过提取隐私安全的数据摘要统计量，结合双XGBoost模型与LLM辅助分离信号与噪声，并使用帕累托加权决策树识别可解释的偏移段。实验证明，SIFOTL在识别数据偏移方面表现优异，显著超越现有基线方法，并对观测噪声具有鲁棒性，提供了一个可解释且注重隐私的解决方案。

> **摘要翻译:** 在表格数据集中识别导致数据偏移的因素对于分析和决策支持系统来说是一个重大挑战，尤其是在医疗保健领域。隐私规则限制了数据访问，复杂过程中的噪声阻碍了分析。为了解决这一挑战，我们提出了SIFOTL（基于统计学的表格学习保真度优化方法），它(i)提取符合隐私规定的数据摘要统计量，(ii)利用双XGBoost模型在大型语言模型（LLMs）的辅助下将干预信号与噪声分离，以及(iii)通过帕累托加权决策树合并XGBoost输出，以识别导致偏移的可解释数据段。与可能忽略噪声或需要完全数据访问才能进行基于LLM分析的现有分析不同，SIFOTL仅使用隐私安全的数据摘要统计量来解决这两个挑战。为证明其在实际世界中的有效性，对于一个模拟新医疗保险药物补贴的MEPS面板数据集，SIFOTL在识别接受补贴的群体方面达到了0.85的F1分数，显著优于BigQuery贡献分析（F1=0.46）和统计测试（F1=0.20）。此外，在基于Synthea ABM生成的18个不同EHR数据集上，SIFOTL在无噪声情况下保持0.86-0.96的F1分数，即使注入观测噪声，F1分数也达到>=0.75，而基线平均F1分数在相同测试下为0.19-0.67。因此，SIFOTL提供了一种可解释、注重隐私的工作流程，并且在经验上对观测噪声具有鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [694] [Generalizing Adam to Manifolds for Efficiently Training Transformers](https://arxiv.org/abs/2305.16901)
> *将 Adam 泛化到流形以高效训练 Transformer*

*Benedikt Brantner* | **Category: cs.LG, math.DG, 53Z50, 53C30, 68T07, 68W10, 90C26** | **Updated: 2025-07-24**

**Keywords:** Adam, 流形, Transformer, 优化, 齐次空间

**Comment:** 32 pages, 6 figures (some of which contain subfigures), presented at
  Enumath2023 and Enumath2025

> **TL;DR:** 该研究提出了一种将 Adam 优化器完全泛化到流形的新方法，利用齐次流形的全局切空间表示，从而无需投影步骤，并显著加速了带正交性约束的 Transformer 训练。

**AI_Comments:** 该论文在理论上做出了重要贡献，通过利用齐次流形的全局切空间表示，成功地将 Adam 优化器完全泛化到流形，解决了以往难以实现的问题。这种无需投影的泛化方法更直接、更优雅，有望为在几何结构上操作的神经网络（如正交神经网络或李群上的模型）提供更高效的训练方式，并可能带来更好的性能和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** Adam 优化器虽然广泛用于神经网络训练，但难以解释且难以泛化到流形。现有尝试未能实现完全泛化，这限制了其在需要几何约束的神经网络（如带有正交性约束的 Transformer）中的应用。

**Method:** 本研究提出了一种新方法，利用与神经网络优化相关的齐次流形（如 Stiefel 流形、辛 Stiefel 流形和 Grassmann 流形）的特殊结构。这些流形允许全局切空间表示，即一个共同的向量空间，其中所有切空间都可以轻松表示。该方法利用这种全局切空间表示来执行 Adam 优化器的所有步骤，从而实现了优化器向流形的完全泛化，且无需投影步骤。

**Result:** 研究成功地将 Adam 优化器完全泛化到流形，且无需投影步骤。将所得算法应用于训练一个带有正交性约束的 Transformer，观察到训练过程显著加速。

**Conclusion:** 该研究成功地将 Adam 优化器泛化到流形，为带有几何约束的神经网络提供了更高效的训练方法。这表明利用流形的特殊结构可以克服传统优化器在非欧几里得空间中的应用挑战。

> **ai_Abstract:** 本文提出了一种将 Adam 优化器完全泛化到流形的新颖方法，解决了其在几何约束神经网络中应用的难题。通过利用齐次流形（如 Stiefel、Grassmann 流形）的全局切空间表示，该方法能够在不进行投影步骤的情况下执行所有 Adam 优化器操作。将泛化后的 Adam 算法应用于训练带有正交性约束的 Transformer 时，实现了显著的训练加速，证明了其在高效训练此类模型方面的有效性。

> **摘要翻译:** 神经网络成功的主要原因之一是出现了一系列新的、高度成功的优化器，其中最重要的可能是 Adam 优化器。它被广泛用于训练神经网络，但出了名的难以解释。由于缺乏清晰的物理直觉，Adam 难以泛化到流形。尽管已经尝试将 Adam 算法的部分直接应用于流形或寻找底层结构，但完全的泛化仍然难以实现。
在这项工作中，提出了一种新方法，利用与神经网络优化相关的流形的特殊结构，例如 Stiefel 流形、辛 Stiefel 流形和 Grassmann 流形：所有这些都是齐次空间，因此允许全局切空间表示——一个共同的向量空间（李子空间），其中所有切空间都可以轻松表示。
这种全局切空间表示用于执行 Adam 优化器中的所有步骤，并且我们能够将优化器完全泛化到流形而无需投影步骤。然后将所得算法应用于训练一个 Transformer，其中正交性约束被强制执行到机器精度，并且我们观察到训练过程显著加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [698] [Boosting Revisited: Benchmarking and Advancing LP-Based Ensemble Methods](https://arxiv.org/abs/2507.18242)
> *Boosting再探：LP基集成方法的基准测试与进展*

*Fabian Akkerman, Julien Ferry, Christian Artigues, Emmanuel Hebrard, Thibaut Vidal* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** Boosting, 线性规划, 集成方法, 稀疏模型, 基准测试

**Comment:** 

> **TL;DR:** 本文对基于线性规划的完全修正Boosting方法进行了首次大规模实验研究，包括两种新方法NM-Boost和QRLP-Boost。研究发现，这些方法在使用浅层树时，性能可与XGBoost和LightGBM媲美或超越，并能生成更稀疏的集成模型，还能在不牺牲性能的情况下精简预训练模型。

**AI_Comments:** 本文的创新点在于首次对LP-based Boosting方法进行了大规模的实证基准测试，并引入了两种新的方法。其重要性在于揭示了这些理论上吸引人的方法在实际应用中的潜力，特别是在生成稀疏模型和模型精简方面的优势，这对于资源受限或需要可解释性的场景具有重要意义。它挑战了传统启发式Boosting方法的霸主地位，并为未来的研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于线性规划的完全修正Boosting方法具有理论吸引力，但它们在经验上受到的关注有限。本文旨在通过大规模实验研究来填补这一空白，评估并推进LP-based集成方法。

**Method:** 作者对六种LP-based Boosting公式（包括两种新方法NM-Boost和QRLP-Boost）进行了首次大规模实验研究，涉及20个不同数据集。研究评估了启发式和最优基学习器的使用，并分析了准确性、集成稀疏性、裕度分布、即时性能和超参数敏感性。

**Result:** 研究表明，在使用浅层树时，完全修正方法可以超越或匹配XGBoost和LightGBM等最先进的启发式方法，同时生成显著更稀疏的集成模型。这些方法还可以在不牺牲性能的情况下精简预训练集成模型。

**Conclusion:** 基于线性规划的完全修正Boosting方法在实践中表现出色，尤其是在生成稀疏模型和精简预训练模型方面。研究还强调了在此背景下使用最优决策树的优势和局限性，为LP-based集成方法的进一步发展提供了实证基础。

> **ai_Abstract:** 本文对基于线性规划（LP）的完全修正Boosting方法进行了首次大规模实证研究，旨在弥补其在经验关注上的不足。研究测试了包括两种新方法NM-Boost和QRLP-Boost在内的六种LP-based Boosting公式，并评估了它们在准确性、集成稀疏性、裕度分布等方面的表现。结果表明，这些LP-based方法在使用浅层树时，其性能可与XGBoost和LightGBM等主流启发式方法相媲美或更优，且能产生更稀疏的模型。此外，它们还能有效精简预训练集成模型而不影响性能。研究还探讨了最优决策树在此类方法中的应用优势与局限性。

> **摘要翻译:** 尽管基于线性规划的完全修正Boosting方法具有理论吸引力，但它们在经验上受到的关注有限。在本文中，我们对六种LP-based Boosting公式（包括两种新方法NM-Boost和QRLP-Boost）进行了首次大规模实验研究，涉及20个不同数据集。我们评估了这些公式中启发式和最优基学习器的使用，不仅分析了准确性，还分析了集成稀疏性、裕度分布、即时性能和超参数敏感性。我们表明，当使用浅层树时，完全修正方法可以超越或匹配XGBoost和LightGBM等最先进的启发式方法，同时生成显著更稀疏的集成模型。我们进一步表明，这些方法可以在不牺牲性能的情况下精简预训练集成模型，并且我们强调了在此背景下使用最优决策树的优点和局限性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [723] [Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data](https://arxiv.org/abs/2507.17791)
> *Helix 1.0：一个用于表格科学数据上可复现和可解释机器学习的开源框架*

*Eduardo Aguilar-Bejarano, Daniel Lea, Karthikeyan Sivakumar, Jimiama M. Mase, Reza Omidvar, Ruizhe Li, Troy Kettle, James Mitchell-White, Morgan R Alexander, David A Winkler, Grazziela Figueredo* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 开源框架, 可复现机器学习, 可解释机器学习, 表格数据, 科学数据

**Comment:** 17 pages

> **TL;DR:** Helix 1.0是一个开源的Python框架，旨在为表格科学数据提供可复现和可解释的机器学习工作流程，使分析过程透明且易于非专业人士使用。

**AI_Comments:** Helix 1.0的创新之处在于其将可复现性和可解释性集成到一个用户友好的开源框架中，特别关注表格科学数据。其新颖的语言术语解释方法对于非专业数据科学家的用户来说，显著降低了机器学习的门槛，使其决策更加透明和可理解。作为一个开源项目，它有利于社区驱动的开发和FAIR原则的遵守，这对于科学研究的进步至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为了满足对透明实验数据分析溯源日益增长的需求，确保整个分析过程（包括数据转换和方法选择）有据可查、可访问、可复现且易于相关利益方理解。此外，它旨在赋能没有正式数据科学培训的研究人员，帮助他们获得有意义且可操作的见解。

**Method:** Helix是一个基于Python的开源、可扩展软件框架。它包含用于标准化数据预处理、可视化、机器学习模型训练、评估、解释、结果检查以及对未知数据进行模型预测的模块。该平台还提供用户友好的界面，支持计算实验设计、结果检查，并采用新颖的基于语言术语的机器学习决策解释方法。

**Result:** Helix促进了表格数据的可复现和可解释机器学习工作流程，确保了分析过程的透明度、可访问性、可复现性和可理解性。它赋能了非数据科学专业背景的研究人员，使他们能够在一个集成环境中设计实验并解释机器学习决策，从而获得有意义的见解。

**Conclusion:** Helix 1.0是一个全面的开源框架，通过提供标准化模块、用户友好界面和新颖的解释方法，显著提高了表格科学数据上机器学习的可复现性、可解释性和可访问性，特别是有益于非专业数据科学家的研究人员。

> **ai_Abstract:** Helix 1.0是一个开源、基于Python的框架，专注于为表格科学数据提供可复现和可解释的机器学习。它旨在通过确保整个分析过程的透明度、可访问性和可理解性来解决对数据分析溯源的需求。该框架集成了数据预处理、模型训练、评估、解释和预测等模块，并提供用户友好的界面，特别包含一种新颖的基于语言术语的解释方法，以帮助非数据科学专业的研究人员。通过GitHub和PyPI发布，Helix支持社区开发并遵循FAIR原则。

> **摘要翻译:** Helix是一个开源、可扩展的基于Python的软件框架，旨在促进表格数据的可复现和可解释机器学习工作流程。它解决了对透明实验数据分析溯源日益增长的需求，确保整个分析过程——包括数据转换和方法选择的决策——都被记录、可访问、可复现且易于相关利益方理解。该平台包含用于标准化数据预处理、可视化、机器学习模型训练、评估、解释、结果检查以及对未知数据进行模型预测的模块。为了进一步赋能没有正式数据科学培训的研究人员以获得有意义且可操作的见解，Helix提供了一个用户友好的界面，该界面可在集成环境中实现计算实验的设计、结果检查，包括一种使用语言术语对机器学习决策进行解释的新颖方法。Helix在MIT许可下发布，可通过GitHub和PyPI访问，支持社区驱动的开发并促进遵守FAIR原则。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [727] [Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning](https://arxiv.org/abs/2308.01358)
> *压缩和分布式最小二乘回归：收敛速率及其在联邦学习中的应用*

*Constantin Philippenko, Aymeric Dieuleveut* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 压缩, 分布式, 最小二乘回归, 联邦学习, 收敛速率

**Comment:** 

> **TL;DR:** 本文研究了压缩对机器学习中随机梯度算法的影响，特别是在最小二乘回归和联邦学习场景下，分析了不同无偏压缩算子的收敛速率差异，并提出了一个更通用的方差项尺度。

**AI_Comments:** 本文超越了经典的SOTA最坏情况分析，对压缩在随机梯度算法中的影响进行了更细致的探讨，特别是其对收敛速率的量化影响。通过对弱假设下的随机场和噪声协方差进行分析，并将其应用于联邦学习，展示了该研究的普适性和重要性。其对极限方差项的通用化贡献具有理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 研究机器学习中随机梯度算法在分布式和联邦学习中广泛使用的压缩技术的影响，特别是其对收敛速率的影响，以超越经典的SOTA最坏情况分析。

**Method:** 本文聚焦于最小二乘回归（LSR）问题，分析了一个用于最小化二次函数的通用随机逼近算法，该算法依赖于一个随机场。研究考虑了对随机场的弱假设（预期H"older正则性）和噪声协方差，从而能够分析包括压缩在内的各种随机化机制。之后，将结果扩展到联邦学习场景。

**Result:** 本文强调了算法引起的附加噪声协方差$\mathfrak{C}_{\mathrm{ania}}$对收敛的影响。结果表明，尽管随机场不规则，极限方差项的尺度为$\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania}} H^{-1})/K$（其中H是优化问题的Hessian，K是迭代次数），这推广了香草LSR情况下$\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$的速率。随后，分析了$\mathfrak{C}_{\mathrm{ania}}$对压缩策略的依赖性，并最终分析了其对收敛的影响，首先是集中式情况，然后是两种异构FL框架。

**Conclusion:** 本文研究了压缩对分布式和联邦学习中随机梯度算法收敛速率的影响，特别是对于最小二乘回归，揭示了不同压缩策略如何影响收敛的极限方差项。

> **ai_Abstract:** 本文深入探讨了压缩技术在分布式和联邦学习中对随机梯度算法收敛速率的影响。作者通过分析最小二乘回归问题，研究了不同无偏压缩算子在收敛性上的差异，并提出了一种更通用的极限方差项表达式。研究还扩展到联邦学习框架，详细分析了压缩策略如何影响算法的噪声协方差，进而影响整体收敛性能。

> **摘要翻译:** 在本文中，我们研究了压缩对机器学习中随机梯度算法的影响，这是一种在分布式和联邦学习中广泛使用的技术。我们强调了几种无偏压缩算子在收敛速率方面的差异，这些算子都满足相同的方差条件，从而超越了经典的SOTA最坏情况分析。为此，我们专注于最小二乘回归（LSR）的情况，并分析了一个用于最小化依赖于随机场的二次函数的通用随机逼近算法。我们考虑了对随机场的弱假设，这些假设是为分析量身定制的（特别是预期的H"older正则性），以及对噪声协方差的弱假设，从而能够分析包括压缩在内的各种随机化机制。然后，我们将结果扩展到联邦学习的情况。更正式地，我们强调了算法引起的附加噪声协方差$\mathfrak{C}_{\mathrm{ania}}$对收敛的影响。我们证明了，尽管随机场不规则，极限方差项的尺度为$\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania}} H^{-1})/K$（其中H是优化问题的Hessian，K是迭代次数），这推广了香草LSR情况下$\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$（Bach和Moulines，2013）的速率。随后，我们分析了$\mathfrak{C}_{\mathrm{ania}}$对压缩策略的依赖性，并最终分析了其对收敛的影响，首先是集中式情况，然后是两种异构FL框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [732] [Leveraging Data Augmentation and Siamese Learning for Predictive Process Monitoring](https://arxiv.org/abs/2507.18293)
> *利用数据增强和孪生学习进行预测性过程监控*

*Sjoerd van Straten, Alessandro Padella, Marwan Hassani* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 预测性过程监控, 数据增强, 孪生学习, 自监督学习, 事件日志

**Comment:** 

> **TL;DR:** SiamSA-PPM是一个新的自监督学习框架，结合孪生学习和统计数据增强，以解决预测性过程监控中事件日志数据量小和变异性低的问题，并在实际数据集上取得了SOTA或更优的性能。

**AI_Comments:** SiamSA-PPM的创新点在于将孪生学习与统计数据增强相结合，解决了真实世界事件日志数据稀疏和变异性低的挑战。其提出的基于统计的转换方法，能够生成高质量、语义有效的增强数据，这对于在缺乏大量标注数据的领域进行深度学习尤为重要。该方法在无需标签监督的情况下学习泛化表示，展现了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习预测性过程监控(PPM)方法常受限于真实事件日志数据变异性低和规模小的问题。

**Method:** 本文提出了SiamSA-PPM，一个结合孪生学习和统计数据增强的新型自监督学习框架。它采用三种基于统计的转换方法，利用控制流语义和频繁行为模式生成逼真且语义有效的新轨迹变体。这些增强视图在孪生学习设置中用于学习过程前缀的泛化表示，无需标签监督。

**Result:** 在真实事件日志上的广泛实验表明，SiamSA-PPM在下一活动预测和最终结果预测任务中均达到与SOTA相当或更优的性能。结果还显示，统计数据增强显著优于随机转换，并提高了数据的变异性。

**Conclusion:** SiamSA-PPM为过程预测中的训练数据丰富提供了一个有前景的方向。

> **ai_Abstract:** 本文提出了SiamSA-PPM，一个针对预测性过程监控（PPM）的自监督学习框架，旨在解决现有深度学习PPM方法面临的事件日志数据量小和变异性低的问题。SiamSA-PPM结合了孪生学习和统计数据增强技术，通过利用控制流语义和频繁行为模式生成逼真且语义有效的新轨迹变体。这些增强数据用于在无标签监督下学习过程前缀的泛化表示。实验证明，SiamSA-PPM在下一活动和最终结果预测任务上性能优于或媲美现有最佳方法，并且其统计增强方法显著提升了数据变异性，为过程预测的数据丰富提供了新途径。

> **摘要翻译:** 预测性过程监控（PPM）能够基于事件日志预测正在进行的业务流程实例的未来事件或结果。然而，深度学习PPM方法常受限于真实世界事件日志的低变异性和小规模。为解决此问题，我们引入了SiamSA-PPM，一个结合孪生学习和统计增强的预测性过程监控新型自监督学习框架。它采用了三种新颖的、基于统计的转换方法，利用控制流语义和频繁行为模式来生成真实且语义有效的新轨迹变体。这些增强视图在孪生学习设置中用于学习过程前缀的泛化表示，无需标签监督。在真实事件日志上的广泛实验表明，SiamSA-PPM在下一活动和最终结果预测任务中均达到了与SOTA（最先进水平）相当或更优的性能。我们的结果进一步表明，统计增强显著优于随机转换并改善了数据的变异性，这凸显了SiamSA-PPM作为过程预测中训练数据丰富的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [734] [Machine Unlearning of Traffic State Estimation and Prediction](https://arxiv.org/abs/2507.17984)
> *交通状态估计与预测的机器学习遗忘*

*Xin Wang, R. Tyrrell Rockafellar, Xuegang, Ban* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 机器遗忘, 交通状态估计, 交通预测, 数据隐私, 被遗忘权

**Comment:** 

> **TL;DR:** 本研究提出交通状态估计与预测的机器遗忘方法，以选择性地删除敏感、中毒或过时数据，从而增强系统信任度。

**AI_Comments:** 这篇论文的创新点在于将“机器遗忘”这一新兴概念应用于交通状态估计与预测领域，解决了智能交通系统中数据隐私和数据新鲜度的关键挑战。其重要性在于提升了数据驱动型交通模型的合规性、信任度与可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 数据驱动的交通状态估计和预测（TSEP）严重依赖包含敏感信息的数据源，这引发了隐私、网络安全和数据新鲜度问题，侵蚀了公众对智能交通系统的信任。此外，新的法规引入了“被遗忘权”，要求从模型中移除私人数据，而简单地从后端数据库删除数据不足以应对机器学习模型记住旧数据的问题。

**Method:** 本研究引入了一种新的学习范式——交通状态估计与预测的机器遗忘（TSEP-Machine Unlearning），它使训练好的TSEP模型能够选择性地遗忘隐私敏感、中毒或过时的数据。

**Result:** 通过赋能模型“遗忘”，旨在增强数据驱动的交通TSEP的信任度和可靠性。

**Conclusion:** 机器遗忘可以有效解决交通状态估计与预测中数据隐私、安全和新鲜度问题，提升智能交通系统的信任度和可靠性。

> **ai_Abstract:** 本研究提出一种名为TSEP机器学习遗忘的新范式，旨在解决数据驱动的交通状态估计与预测（TSEP）中因敏感数据引起的隐私、网络安全和数据新鲜度问题。该方法允许训练好的TSEP模型选择性地遗忘隐私敏感、中毒或过时的数据，从而提高智能交通系统的信任度和可靠性，以应对“被遗忘权”等法规要求。

> **摘要翻译:** 数据驱动的交通状态估计与预测（TSEP）严重依赖包含敏感信息的数据源。虽然数据的丰富性推动了重大突破，特别是在基于机器学习的方法中，但也引发了对隐私、网络安全和数据新鲜度的担忧。这些问题会侵蚀公众对智能交通系统的信任。最近，法规引入了“被遗忘权”，允许用户请求从模型中删除其私人数据。由于机器学习模型会记住旧数据，因此在这些系统中，简单地从后端数据库中删除数据是不够的。为了应对这些挑战，本研究引入了一种新的TSEP学习范式——TSEP机器学习遗忘——它使训练好的TSEP模型能够选择性地遗忘隐私敏感、中毒或过时的数据。通过赋能模型“遗忘”，我们旨在增强数据驱动的交通TSEP的信任度和可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [762] [Optimal Transport Regularized Divergences: Application to Adversarial Robustness](https://arxiv.org/abs/2309.03791)
> *最优传输正则化散度：在对抗鲁棒性中的应用*

*Jeremiah Birrell, Reza Ebrahimi* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 最优传输, 对抗鲁棒性, 分布鲁棒优化, 信息散度, 深度学习

**Comment:** 34 pages, 2 figures

> **TL;DR:** 本文引入了一种新的最优传输正则化散度$D^c$，并提出了$ARMOR_D$方法，通过结合信息散度和最优传输成本来增强深度学习模型的对抗鲁棒性，并在CIFAR-10和CIFAR-100数据集上取得了性能提升。

**AI_Comments:** 该论文的关键创新在于提出了$D^c$这一新型最优传输正则化散度，以及基于此的$ARMOR_D$方法。$ARMOR_D$通过结合对抗样本的传输和重加权，提供了一种更全面、更灵活的对抗训练范式。这种方法不仅泛化了现有的优秀方法，还在实际应用中取得了显著的性能提升，为对抗鲁棒性研究提供了一个重要的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强深度学习模型的对抗鲁棒性，现有方法在构建对抗样本时可能仅考虑传输或重加权。本文旨在提出一种更全面、更灵活的方法，能够同时进行对抗样本的传输和重加权。

**Method:** 本文引入了一种新的最优传输正则化散度$D^c$，它通过信息散度$D$和最优传输成本$C$之间的下卷积构建。基于此，提出了$ARMOR_D$方法，这是一种基于分布鲁棒优化（DRO）的方法，通过最小化训练数据经验分布的$D^c$-邻域内的最大预期损失来增强对抗鲁巴斯性。$ARMOR_D$允许对抗样本根据OT成本进行传输，并根据信息散度进行重加权。

**Result:** $ARMOR_D$方法在CIFAR-10和CIFAR-100图像识别任务上，相对于AutoAttack这种强大的对抗攻击集成，分别带来了1.9%和2.1%的性能提升。它被证明可以作为现有最佳对抗训练方法（如UDR、TRADES和MART）的泛化和增强。

**Conclusion:** 本文提出的最优传输正则化散度$D^c$和$ARMOR_D$方法为增强深度学习模型的对抗鲁棒性提供了一种新颖且有效的途径。该方法通过结合对抗样本的传输和重加权，显著提升了模型在面对强大对抗攻击时的性能，并可以作为现有方法的通用化和增强。

> **ai_Abstract:** 本文提出了一种名为$ARMOR_D$的新型方法，通过引入最优传输正则化散度$D^c$来增强深度学习模型的对抗鲁棒性。$D^c$结合了信息散度和最优传输成本，使得$ARMOR_D$能够同时对对抗样本进行传输和重加权。这种基于分布鲁棒优化的方法被证明是现有对抗训练方法的泛化，并在CIFAR-10和CIFAR-100数据集上，相对于强大的AutoAttack攻击，实现了显著的性能提升。

> **摘要翻译:** 我们引入了一类新的最优传输正则化散度$D^c$，它通过信息散度$D$和最优传输（OT）成本$C$之间的下卷积构建，并研究了它们在分布鲁棒优化（DRO）中的应用。特别是，我们提出了$ARMOR_D$方法作为增强深度学习模型对抗鲁棒性的新颖方法。这些基于DRO的方法通过最小化训练数据经验分布的$D^c$-邻域内的最大预期损失来定义。作为构建对抗样本的工具，我们的方法允许样本根据OT成本进行传输，并根据信息散度进行重加权；在对抗样本传输的基础上增加一种有原则的动态对抗重加权是$ARMOR_D$的关键创新。$ARMOR_D$可以被视为对抗训练文献中表现最佳的损失函数和OT成本的泛化；我们通过使用$ARMOR_D$增强UDR、TRADES和MART方法，并在CIFAR-10和CIFAR-100图像识别上获得改进的性能来证明这种灵活性。具体来说，使用$ARMOR_D$增强使得在CIFAR-10和CIFAR-100上对抗AutoAttack（一种强大的对抗攻击集成）的性能分别提高了1.9%和2.1%。为了促进可复现性，我们已将代码开源在https://github.com/star-ailab/ARMOR。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [383] [Technical Implementation of Tippy: Multi-Agent Architecture and System Design for Drug Discovery Laboratory Automation](https://arxiv.org/abs/2507.17852)
> *Tippy 的技术实现：药物发现实验室自动化的多智能体架构与系统设计*

*Yao Fehlis, Charles Crain, Aidan Jensen, Michael Watson, James Juhasz, Paul Mandel, Betty Liu, Shawn Mahon, Daren Wilson, Nick Lynch-Jonely, Ben Leedom, David Fuller* | **Category: cs.MA, cs.AI** | **Updated: 2025-07-18**

**Keywords:** 多智能体系统, 药物发现, 实验室自动化, 微服务, AI智能体

**Comment:** 

> **TL;DR:** 本文详细介绍了Tippy多智能体系统在药物发现实验室自动化中的技术实现，该系统通过协调五个专业智能体来自动化复杂的实验室工作流程，并确保安全性、可扩展性和可靠性。

**AI_Comments:** 本文详细描述了一个为药物发现实验室自动化设计的复杂多智能体系统Tippy的技术实现，其创新点在于将多个专业AI智能体（如主管、分子、实验室、分析、报告）与分布式微服务架构相结合，并通过OpenAI Agents SDK进行协调。通过引入模型上下文协议（MCP）和标准化的IT部署策略（Kubernetes, Docker, CI/CD），该系统展示了在确保安全性、可扩展性和可靠性的前提下，自动化复杂科学工作流程的巨大潜力。这对于加速药物发现过程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文基于之前关于用于药物研究的智能AI的概念框架，旨在提供Tippy多智能体系统在药物发现实验室自动化中的全面技术分析和实现细节。

**Method:** 本文介绍了一个分布式微服务架构，包含五个专业智能体（主管、分子、实验室、分析和报告），通过OpenAI Agents SDK进行协调，并通过模型上下文协议（MCP）访问实验室工具。系统架构包括智能体特定的工具集成、异步通信模式和通过Git跟踪的全面配置管理。生产部署策略采用Kubernetes容器编排、Helm Charts、Docker容器化和CI/CD管道。实现中还集成了向量数据库用于RAG功能，并采用Envoy反向代理实现安全外部访问。

**Result:** 该实现展示了专业AI智能体如何有效地协调复杂的实验室工作流程，同时通过标准化协议保持安全性、可扩展性、可靠性以及与现有实验室基础设施的集成。

**Conclusion:** 专业AI智能体能够有效地协调复杂的实验室工作流程，同时保持安全性、可扩展性、可靠性，并能通过标准化协议与现有实验室基础设施集成。

> **ai_Abstract:** 本文详细阐述了Tippy多智能体系统在药物发现实验室自动化中的技术实现。该系统采用分布式微服务架构，包含主管、分子、实验室、分析和报告五个专业智能体，通过OpenAI Agents SDK进行协调，并利用MCP与实验室工具交互。其设计涵盖了工具集成、异步通信、Git配置管理、以及基于Kubernetes、Helm和Docker的生产部署。系统还整合了向量数据库和Envoy反向代理。这项工作证明了专业AI智能体能够高效协调复杂的实验室流程，同时确保安全性、可扩展性、可靠性并良好集成现有基础设施。

> **摘要翻译:** 基于我们之前关于用于药物研究的智能AI概念框架的工作，本文对Tippy多智能体系统在药物发现实验室自动化中的实现进行了全面的技术分析。我们提出了一个分布式微服务架构，包含五个专业智能体（主管、分子、实验室、分析和报告），它们通过OpenAI Agents SDK进行编排协调，并通过模型上下文协议（MCP）访问实验室工具。系统架构涵盖了智能体特定的工具集成、异步通信模式以及通过Git跟踪的全面配置管理。我们的生产部署策略利用Kubernetes容器编排、Helm Charts、Docker容器化和CI/CD管道进行自动化测试和部署。该实现集成了向量数据库以实现RAG功能，并采用了Envoy反向代理以实现安全的外部访问。这项工作展示了专业AI智能体如何有效地协调复杂的实验室工作流程，同时通过标准化协议保持安全性、可扩展性、可靠性以及与现有实验室基础设施的集成。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [396] [Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation](https://arxiv.org/abs/2507.18224)
> *集结你的团队：通过自回归图生成实现多智能体通信拓扑的自动化设计*

*Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, Shirui Pan* | **Category: cs.MA** | **Updated: 2025-07-24**

**Keywords:** 多智能体系统, 通信拓扑, 自回归图生成, 大型语言模型, 自动化设计

**Comment:** 

> **TL;DR:** 本文提出ARG-Designer，一个基于自回归图生成的新模型，用于从头开始自动设计多智能体系统的通信拓扑，解决现有方法依赖预定义模板的局限性，实现了最先进的性能和更高的效率。

**AI_Comments:** 该论文的创新点在于将多智能体系统（MAS）的拓扑设计重新定义为条件自回归图生成任务，摆脱了传统方法对预定义模板的依赖。ARG-Designer模型能够根据任务需求动态生成定制化的通信结构，极大地提高了MAS的灵活性和适应性。这种从零开始构建图的方法是其核心优势，对于推动LLM驱动的MAS在复杂问题解决中的应用具有重要意义。其在效率和可扩展性方面的提升也使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体系统（MAS）的有效性严重依赖于其协作拓扑设计。然而，现有方法受限于预定义的代理集和硬编码的交互结构，导致其对任务特定需求适应性差。

**Method:** 本文将MAS设计重构为条件自回归图生成任务，其中系统组成和结构同时设计。提出了ARG-Designer，一个新颖的自回归模型，它根据自然语言任务查询，顺序动态地确定所需代理数量、选择适当角色并建立最优通信链接，从而从零开始构建协作图。

**Result:** 在六个不同基准上的广泛实验表明，ARG-Designer不仅实现了最先进的性能，而且还显著提高了令牌效率和可扩展性。

**Conclusion:** ARG-Designer通过自回归图生成范式，为多智能体系统的通信拓扑设计提供了一种灵活且可扩展的定制化方法，解决了现有方法的局限性，并取得了优异的性能。

> **ai_Abstract:** 本文提出了一种名为ARG-Designer的新型自回归模型，用于自动设计基于LLM的多智能体系统的通信拓扑。针对现有方法依赖预设模板的局限性，ARG-Designer将MAS设计视为条件自回归图生成任务，能够根据自然语言任务查询，从零开始动态确定代理数量、角色并建立通信链接，从而生成定制化的协作拓扑。实验证明，ARG-Designer在性能、令牌效率和可扩展性方面均达到或超越了现有技术水平。

> **摘要翻译:** 基于大型语言模型（LLM）的多智能体系统（MAS）已成为处理复杂问题的强大解决方案。MAS的有效性关键取决于其协作拓扑，这已成为自动化设计研究的焦点。然而，现有方法从根本上受限于它们对模板图修改范式的依赖，该范式具有预定义的代理集和硬编码的交互结构，这大大限制了它们对任务特定需求的适应性。为了解决这些限制，我们将MAS设计重新定义为条件自回归图生成任务，其中系统组成和结构是共同设计的。我们提出了ARG-Designer，一个新颖的自回归模型，通过从头开始构建协作图来操作这种范式。ARG-Designer根据自然语言任务查询，顺序动态地确定所需代理数量，从可扩展的池中选择其适当的角色，并建立它们之间最优的通信链接。这种生成方法以灵活和可扩展的方式创建定制拓扑，精确地适应不同任务的独特需求。在六个不同基准上的广泛实验表明，ARG-Designer不仅实现了最先进的性能，而且还显著提高了令牌效率和增强了可扩展性。ARG-Designer的源代码可在https://github.com/Shiy-Li/ARG-Designer获取。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [408] [Designing Value-Aligned Traffic Agents through Conflict Sensitivity](https://arxiv.org/abs/2507.18284)
> *通过冲突敏感性设计价值对齐的交通智能体*

*Astrid Rakow, Joe Collenette, Maike Schwammberger, Marija Slavkovik, Gleifer Vs Alves* | **Category: cs.MA** | **Updated: 2025-07-24**

**Keywords:** 价值对齐, 交通智能体, 冲突敏感性, 认知博弈论, VODDs

**Comment:** Short version of this paper has been accepted at EUMAS 2025
  https://euramas.github.io/eumas2025/

> **TL;DR:** 本文提出了一种基于认知博弈论冲突模型的框架，用于在开发阶段设计与利益相关者价值观对齐的自动交通智能体，而非在运行时解决道德困境。

**AI_Comments:** 本文的创新点在于将认知博弈论的冲突模型引入到自动交通智能体的设计中，并提出了VODDs的概念。它将解决道德困境的重点从运行时转移到开发阶段，提供了一种前瞻性的方法来确保智能体的价值对齐，这对于未来自主系统的可靠性和社会接受度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自动交通智能体（ATAs）不仅需要安全，还需要在法律、社会和道德层面与利益相关者的价值观保持一致。传统的做法可能在运行时才面临道德困境，因此需要一种方法在开发阶段就预先考虑和构建价值敏感行为。

**Method:** 本文采用认知博弈论中已建立的正式冲突模型来支持智能体的开发。研究聚焦于价值冲突，并展示了冲突分析如何为设计过程的关键阶段（包括价值启发、能力规范、解释和自适应系统完善）提供信息。论文还阐述并应用了“价值对齐操作设计领域”（VODDs）的概念，以根据上下文价值优先级来构建自主性。

**Result:** 结果表明，冲突分析可以为智能体设计过程的关键阶段提供信息，并且该方法将重点从在运行时解决道德困境转移到在开发过程中预测和构建价值敏感行为。

**Conclusion:** 该研究的结论是，通过在开发阶段利用冲突敏感性和价值对齐操作设计领域（VODDs）的概念，可以有效地设计出与利益相关者价值观对齐的自动交通智能体，从而避免在运行时解决复杂的道德困境。

> **ai_Abstract:** 本文提出了一种基于认知博弈论冲突模型的框架，旨在设计与利益相关者价值观对齐的自动交通智能体。研究通过冲突分析来指导设计过程的关键阶段，并引入了“价值对齐操作设计领域”（VODDs）的概念。该方法的核心思想是将价值敏感行为的考量从运行时转移到开发阶段，从而在早期就预先构建智能体的价值对齐能力。

> **摘要翻译:** 自动交通智能体（ATAs）被期望不仅安全，而且其行为方式要与利益相关者在法律、社会和道德层面的价值观相符。在本文中，我们采用了一个来自认知博弈论的成熟冲突形式模型来支持此类智能体的开发。我们专注于价值冲突——即智能体面临植根于价值导向情境中的竞争目标的局面，并展示了冲突分析如何为设计过程的关键阶段提供信息。这包括价值启发、能力规范、解释和自适应系统完善。我们阐述并应用了“价值对齐操作设计领域”（VODDs）的概念，以根据上下文价值优先级来构建自主性。我们的方法将重点从在运行时解决道德困境转移到在开发过程中预测和构建价值敏感行为。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [501] [Recognizing and Eliciting Weakly Single Crossing Profiles on Trees](https://arxiv.org/abs/1611.04175)
> *识别和启发树上的弱单交叉偏好剖面*

*Palash Dey* | **Category: cs.MA, cs.AI, cs.DS** | **Updated: 2025-07-24**

**Keywords:** 弱单交叉, 偏好启发, 社会选择, 树结构, 查询复杂度

**Comment:** Accepted in TCS journal

> **TL;DR:** 引入并研究了树上的弱单交叉偏好域，设计了多项式时间识别算法和高效启发算法，并证明了查询复杂度下界，解决了先前的一个开放问题。

**AI_Comments:** 本文通过将成熟的单交叉域扩展到更通用的树结构，做出了重要贡献，这与各种社会选择应用相关。开发实用的识别和启发算法，特别是在顺序访问和结构未知的情况下，具有高度创新性。理论贡献，特别是下界和开放问题的解决，加深了对偏好启发复杂性的理解。

<details>
  <summary>Details</summary>

**Motivation:** 推广社会选择理论中已充分研究的单交叉域到树结构，并解决在该新域中识别和启发偏好的挑战，尤其是在只能顺序访问偏好且底层树结构未知的情况下。同时，旨在解决早期论文中关于单交叉偏好启发查询复杂度的开放问题。

**Method:** 引入并研究了树上的弱单交叉域。设计了一种多项式时间算法来识别属于该域的偏好剖面。开发了一种高效的启发算法，该算法即使在偏好只能顺序访问且底层单交叉树结构未知的情况下也能工作。证明了当选民数量相对于候选人数量较大时，其启发算法在查询复杂度上的匹配下界。证明了在允许随机查询的情况下，启发单交叉剖面所需的查询次数下界为 $\Omega(m^2\log n)$。

**Result:** 引入了树上的弱单交叉域。设计了一种用于识别该域偏好剖面的多项式时间算法。开发了一种高效的启发算法，即使在偏好只能顺序访问且底层单交叉树结构未知的情况下也能工作。证明了其启发算法在查询复杂度上的匹配下界。证明了在允许随机查询的情况下，启发单交叉剖面所需的查询次数下界为 $\Omega(m^2\log n)$，这解决了一篇早期论文中的开放问题，并证明了其偏好启发算法的最优性。

**Conclusion:** 该论文成功引入并分析了树上的弱单交叉域，提供了实用的识别和启发算法，并对查询复杂度进行了理论洞察，解决了先前的一个开放问题。

> **ai_Abstract:** 本文引入并研究了树上的弱单交叉域，这是社会选择理论中经典单交叉域的推广。作者提出了一种多项式时间算法来识别该域内的偏好剖面，以及一种高效的启发算法，该算法可以在顺序访问且底层树结构未知的情况下运行。此外，他们为其启发算法建立了匹配的查询复杂度下界，并证明了在允许随机查询的情况下，启发单交叉剖面的查询次数下界为 $\Omega(m^2\log n)$，从而解决了早期论文中的一个开放问题，并证明了先前提出的启发算法的最优性。

> **摘要翻译:** 我们引入并研究了树上的弱单交叉域，这是社会选择理论中被充分研究的单交叉域的推广。我们设计了一种多项式时间算法，用于识别属于该域的偏好剖面。然后，我们为该域开发了一种高效的启发算法，即使只能顺序访问偏好且事先不知道底层的单交叉树结构，该算法也能工作。当选民数量相对于候选人数量较大时，我们还证明了我们的启发算法在查询复杂度上的匹配下界。我们还证明了任何算法在允许随机查询的情况下，需要查询的次数下界为 $\Omega(m^2\log n)$ 才能启发单交叉剖面。这解决了一篇早期论文中的一个开放问题，并证明了当允许随机查询时，他们偏好启发算法的最优性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [2] [Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems](https://arxiv.org/abs/2507.10055)
> *协作机器人手势识别：基于实时机器人系统中轻量级深度学习的应用*

*Muhtadin, I Wayan Agus Darmawan, Muhammad Hilmi Rusydiansyah, I Ketut Eddy Purnama, Chastine Fatichah, Mauridhi Hery Purnomo* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 手势识别, 协作机器人, 轻量级深度学习, 实时系统, 人机交互

**Comment:** 

> **TL;DR:** 本文开发了一个超轻量级深度学习模型，实现了对协作机器人的高精度、实时手势控制，无需额外设备。

**AI_Comments:** 这篇论文的创新点在于其极度轻量化的深度学习模型，能够在资源受限的边缘设备上实现高精度的实时手势识别，这对于推动协作机器人的普及和人机交互的自然化具有重要意义。其小巧的模型尺寸和高准确率，展示了在不牺牲性能的前提下进行模型优化的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 实现直观、自然的机器人与人类协作，消除对操纵杆、平板电脑或可穿戴传感器等额外设备的依赖。

**Method:** 提出了一种基于轻量级深度学习的手势识别系统，用于识别八种不同的手势。该模型通过TensorFlow Lite进行量化和剪枝以优化部署到边缘设备。系统在基于ROS2的Universal Robot UR5协作机器人上进行了实现和测试。

**Result:** 原始模型参数1,103个，大小22KB，准确率93.5%。经过量化和剪枝后，最终模型大小仅为7KB。系统在UR5机器人上成功实现，并证明了极轻量级模型也能提供准确响应的手势控制。

**Conclusion:** 即使是极其轻量级的模型也能为协作机器人提供准确且响应迅速的手势控制，为受限环境中的自然人机交互开辟了新的可能性。

> **ai_Abstract:** 本文介绍了一种基于轻量级深度学习的手势识别系统，旨在促进协作机器人与人类的直观自然交互。该系统能够识别八种手势，其原始模型体积小、参数少，并达到了93.5%的准确率。通过量化和剪枝，模型尺寸进一步优化至7KB。该系统已成功部署在Universal Robot UR5协作机器人上，证明了即使是极轻量级的模型也能为协作机器人提供准确且响应迅速的手势控制，为受限环境中的自然人机交互开辟了新途径。

> **摘要翻译:** 直接和自然的交互对于直观的人机协作至关重要，它消除了对操纵杆、平板电脑或可穿戴传感器等额外设备的需求。在本文中，我们提出了一种基于轻量级深度学习的手势识别系统，使人类能够自然高效地控制协作机器人。该模型仅用1,103个参数和22KB的紧凑尺寸就能识别八种不同的手势，并实现了93.5%的准确率。为了进一步优化模型以在边缘设备上进行实际部署，我们使用TensorFlow Lite应用了量化和剪枝，将最终模型尺寸减小到仅7KB。该系统已在基于ROS2的实时机器人框架内的Universal Robot UR5协作机器人上成功实现并测试。结果表明，即使是极其轻量级的模型也能为协作机器人提供准确且响应迅速的手势控制，为受限环境中的自然人机交互开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [31] [Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning](https://arxiv.org/abs/2507.18436)
> *评估预穿戴步骤：通过模仿学习展开医用服装*

*David Blanco-Mulero, Júlia Borràs, Carme Torras* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 机器人辅助穿戴, 模仿学习, 服装展开, 预穿戴步骤, 柔性物体操作

**Comment:** 6 pages, 4 figures, 2 tables. Accepted to IEEE/RSJ IROS 2025. Project
  website: https://sites.google.com/view/pre-dressing

> **TL;DR:** 本文介绍了机器人辅助穿戴前的预穿戴步骤，即通过模仿学习展开医用服装，并评估了不同的操作原语组合。

**AI_Comments:** 本文的创新点在于提出了“预穿戴步骤”的概念，解决了机器人辅助穿戴中服装初始状态的问题。通过结合模仿学习和视觉分类器，为机器人处理柔性物体提供了实用的解决方案，对于提高医疗场景下机器人辅助穿戴的效率和适用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人辅助穿戴有潜力显著帮助患者和医护人员，减轻工作量并提高临床效率。然而，现有的机器人穿戴工作通常假设服装已展开。在医疗应用中，医用长袍和围裙通常是折叠存放的，需要额外的展开步骤。

**Method:** 本文引入了预穿戴步骤，即在辅助穿戴前展开服装的过程。研究利用模仿学习来学习三种操作原语，包括高加速和低加速运动。此外，还采用视觉分类器将服装状态分为封闭、部分打开和完全打开。

**Result:** 研究结果表明，高动态运动对于展开新拆封的服装效果不佳，而不同运动的组合可以有效提高展开配置。

**Conclusion:** 通过模仿学习和视觉分类器，对预穿戴步骤中的服装展开进行了有效评估，并发现特定运动组合能更有效地展开服装。

> **ai_Abstract:** 本文介绍了机器人辅助穿戴前的“预穿戴步骤”，即展开折叠的医用服装。研究利用模仿学习训练了三种操作原语，并结合视觉分类器识别服装展开状态。实验结果表明，高动态运动不适合展开新拆封的服装，而多种运动的组合能更有效地展开服装，提升了机器人辅助穿戴的实用性。

> **摘要翻译:** 机器人辅助穿戴有潜力显著帮助患者和医护人员，减轻工作量并提高临床效率。尽管机器人穿戴辅助方面取得了实质性进展，但以往的工作通常假设服装已展开并可直接使用。然而，在医疗应用中，医用长袍和围裙通常以折叠状态存放，需要额外的展开步骤。在本文中，我们介绍了预穿戴步骤，即在辅助穿戴前展开服装的过程。我们利用模仿学习来学习三种操作原语，包括高加速和低加速运动。此外，我们采用视觉分类器将服装状态分为封闭、部分打开和完全打开。我们对所学到的操作原语及其组合进行了实证评估。我们的结果表明，高动态运动对于展开新拆封的服装效果不佳，而运动的组合可以有效提高打开配置。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [50] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
> *自适应相对姿态估计框架，带双重噪声调整，用于安全接近机动*

*Batu Candan, Simone Servadio* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 相对姿态估计, 主动空间碎片清除, 非线性卡尔曼滤波, 计算机视觉, 噪声自适应

**Comment:** 

> **TL;DR:** 该研究提出了一个结合计算机视觉和自适应UKF的框架，用于精确估计翻滚卫星的相对姿态，通过双重噪声调整增强了对测量不确定性和未建模动力学的鲁棒性，并在高保真模拟中验证了其性能，以实现安全的主动空间碎片清除任务。

**AI_Comments:** 这篇论文的创新点在于其将计算机视觉与自适应非线性滤波（UKF）深度融合，并特别提出了双重噪声调整策略。这种策略显著增强了系统在面对测量不确定性（来自CNN）和未建模动力学时的鲁棒性，这对于高风险的太空任务（如ADR）至关重要。其重要性在于为未来太空碎片清除和在轨服务提供了更可靠的导航基础。

<details>
  <summary>Details</summary>

**Motivation:** 主动空间碎片清除（ADR）任务（特别是针对翻滚废弃卫星如ESA的ENVISAT）需要精确且鲁棒的相对姿态估计。

**Method:** 提出了一个完整的管道，整合了先进的计算机视觉技术和自适应非线性滤波。使用卷积神经网络（CNN）结合图像预处理来检测结构标记（角点），并将其2D坐标通过相机模型转换为3D测量。这些测量值在一个非线性卡尔曼滤波（UKF）框架内融合，UKF因其处理非线性相对动力学的能力而被选中。关键贡献是集成的系统架构和UKF内的双重自适应策略：动态调整测量噪声协方差以补偿CNN测量不确定性，以及利用测量残差分析自适应调整过程噪声协方差以应对未建模动力学或在线机动。

**Result:** 所提出的自适应集成系统通过使用逼真的ENVISAT模型进行高保真模拟，并在包括测量中断在内的各种条件下将估计值与真实值进行比较，验证了其性能。该方法增强了对测量缺陷和动态模型不确定性的鲁棒性。

**Conclusion:** 这种综合方法为鲁棒的机载相对导航提供了一种增强的解决方案，显著提升了ADR任务中安全接近操作所需的能力。

> **ai_Abstract:** 本文提出了一种用于主动空间碎片清除（ADR）任务中翻滚卫星相对姿态估计的自适应框架。该框架结合了基于CNN的计算机视觉技术和自适应非线性卡尔曼滤波（UKF）。其核心创新在于UKF内的双重噪声调整策略：动态调整测量噪声以适应CNN输出的不确定性，并自适应调整过程噪声以应对未建模的动力学。高保真模拟验证了该系统在各种条件下的鲁棒性和准确性，为ADR任务中的安全接近操作提供了增强的机载相对导航解决方案。

> **摘要翻译:** 准确和鲁棒的相对姿态估计对于实现具有挑战性的主动空间碎片清除（ADR）任务至关重要，这些任务的目标是翻滚的废弃卫星，例如欧空局的ENVISAT。这项工作提出了一个完整的管道，将先进的计算机视觉技术与自适应非线性滤波相结合，以应对这一挑战。一个通过图像预处理增强的卷积神经网络（CNN）从追踪器图像中检测结构标记（角点），其2D坐标通过相机建模转换为3D测量。这些测量值在一个非线性卡尔曼滤波（UKF）框架内融合，该框架因其处理非线性相对动力学的能力而被选中，以估计完整的相对姿态。主要贡献包括集成的系统架构和UKF内的双重自适应策略：测量噪声协方差的动态调整补偿了变化的CNN测量不确定性，而利用测量残差分析对过程噪声协方差的自适应调整则考虑了未建模的动力学或在线机动。这种双重适应性增强了对测量缺陷和动态模型不确定性的鲁棒性。所提出的自适应集成系统的性能通过使用逼真的ENVISAT模型进行高保真模拟进行评估，在各种条件（包括测量中断）下将估计值与真实值进行比较。这种综合方法为鲁棒的机载相对导航提供了一种增强的解决方案，显著提升了ADR任务中安全接近操作所需的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [68] [A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots](https://arxiv.org/abs/2507.18462)
> *一种用于遥感机器人高效路径规划的新型蒙特卡洛压缩感知与字典学习方法*

*Alghalya Al-Hajri, Ejmen Al-Ubejdij, Aiman Erbad, Ali Safa* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 压缩感知, 字典学习, 路径规划, 遥感机器人, 蒙特卡洛优化

**Comment:** 

> **TL;DR:** 本文提出了一种结合蒙特卡洛优化和字典学习的压缩感知方法，用于优化遥感机器人的数据采集路径，显著减少了行程并提高了重建精度。

**AI_Comments:** 本文的创新点在于首次将压缩感知测量矩阵的结构与蒙特卡洛优化和字典学习相结合，用于遥感机器人的高效路径规划。其重要性体现在能够显著减少机器人数据采集的时间和能耗，同时提高数据重建的质量，对于环境监测等实际应用具有重要意义。该方法为未来自主机器人高效感知和路径规划提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统遥感数据采集需要大量测量，且现有方法未能充分利用压缩感知测量矩阵的结构来优化机器人采样轨迹，导致路径规划效率低下和重建精度不足。

**Method:** 提出了一种新型蒙特卡洛优化框架，设计测量矩阵以最小化机器人遍历路径长度和信号重建误差。核心是应用字典学习获得数据驱动的稀疏变换，以增强重建精度并进一步减少所需样本数量。

**Result:** 该方法能将机器人行程减少到全覆盖路径的10%以下，与基于DCT和多项式字典的传统压缩感知方法相比，重建精度提高了五倍以上；与现有信息路径规划方法相比，精度提高了两倍。

**Conclusion:** 该研究首次利用压缩感知测量矩阵的结构来优化机器人环境数据采集的采样轨迹，并通过结合蒙特卡洛优化和字典学习，显著提高了遥感机器人路径规划的效率和数据重建的准确性。

> **ai_Abstract:** 本文提出了一种新颖的蒙特卡洛优化框架，结合字典学习和压缩感知，用于优化遥感机器人进行环境数据采集的路径规划。该方法通过设计测量矩阵来最小化机器人行程和信号重建误差，并利用字典学习提高稀疏表示能力。实验证明，与传统方法相比，该方法能大幅减少机器人行程并显著提高数据重建精度。

> **摘要翻译:** 近年来，压缩感知（CS）作为一种使用比传统奈奎斯特采样更少测量即可获取高分辨率传感数据的技术，引起了广泛关注。与此同时，无人机和漫游车等自主机器人平台已成为遥感和环境监测任务（包括温度、湿度和空气质量测量）越来越流行的工具。在此背景下，本文首次探讨了如何利用CS测量矩阵的结构来设计优化采样轨迹，以用于机器人环境数据采集。我们提出了一种新型蒙特卡洛优化框架，该框架生成的测量矩阵旨在最小化机器人的遍历路径长度和CS框架内的信号重建误差。我们方法的核心是应用字典学习（DL）来获得数据驱动的稀疏变换，这增强了重建精度，同时进一步减少了机器人需要收集的样本数量。我们通过重建海湾地区$NO_2$污染图的实验证明了我们方法的有效性。结果表明，我们的方法可以将机器人行程减少到全覆盖路径的10%以下，同时与基于DCT和多项式字典的传统CS方法相比，重建精度提高了五倍以上，与先前提出的信息路径规划（IPP）方法相比，精度提高了两倍。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [89] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
> *利用多源异构信号进行疲劳检测*

*Luobin Cui, Yanlai Wu, Tang Ying, Weikai Li* | **Category: cs.RO, cs.AI, 62H30, I.2** | **Updated: 2025-07-24**

**Keywords:** 疲劳检测, 多源信号, 异构信号, 传感器受限, 泛化能力

**Comment:** 1figures,32pages

> **TL;DR:** 本文提出一个利用多源异构信号进行疲劳检测的框架，以解决现有方法在真实世界中因传感器限制而适用性不足的问题，并在实验中证明了其有效性。

**AI_Comments:** 本文的创新点在于提出了一个针对传感器受限真实世界场景的疲劳检测问题，并提出了一个异构多源框架来解决该问题。其重要性在于提升了疲劳检测在实际应用中的可行性，尤其是在资源受限的环境下。该研究对于航空、运输等安全关键领域具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 疲劳检测在航空、采矿和长途运输等安全关键应用中至关重要。然而，现有方法多依赖高端传感器和受控环境，限制了其在真实世界中的应用。本文旨在解决在传感器受限的真实场景中进行疲劳检测的实用问题。

**Method:** 提出了一种异构多源疲劳检测框架，该框架能够自适应地利用目标领域中可用的模态，同时受益于源领域中存在的不同配置。

**Result:** 实验使用了真实的现场部署传感器设置和两个公开数据集，结果表明该方法具有实用性、鲁棒性和改进的泛化能力。

**Conclusion:** 本文提出的方法为在传感器受限的场景中实现有效的疲劳监测铺平了道路。

> **ai_Abstract:** 本文针对现有疲劳检测方法在真实世界中受传感器和环境限制的问题，提出了一个利用多源异构信号进行疲劳检测的框架。该框架能够整合来自不同配置源域的知识，并自适应地利用目标域的可用模态。实验证明了该方法在实际应用中的可行性、鲁棒性及更好的泛化能力，为传感器受限场景下的疲劳监测提供了有效途径。

> **摘要翻译:** 疲劳检测在航空、采矿和长途运输等安全关键应用中发挥着关键作用。然而，大多数现有方法依赖于高端传感器和受控环境，这限制了它们在真实世界环境中的适用性。本文正式定义了一个实用但尚未充分探索的真实世界疲劳检测问题设置，其中系统使用适合上下文的传感器，旨在利用来自不同仪器化来源的知识，包括那些在受控环境中部署不切实际的传感器。为了应对这一挑战，我们提出了一种异构多源疲劳检测框架，该框架自适应地利用目标领域中可用的模态，同时受益于源领域中存在的不同配置。我们使用真实的现场部署传感器设置和两个公开数据集进行的实验表明，我们的方法具有实用性、鲁棒性和改进的泛化能力，为在传感器受限的场景中进行有效疲劳监测铺平了实用道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [103] [Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces](https://arxiv.org/abs/2507.18502)
> *人形机器人任务加速度空间和任务力空间全身控制公式的实验比较*

*Sait Sovukluk, Grazia Zambella, Tobias Egle, Christian Ott* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 全身控制, 人形机器人, 逆动力学控制, 基于无源性控制, 实验比较

**Comment:** This paper has been accepted for publication in 2025 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS 2025). -
  Link to video: https://youtu.be/Nfm50ycz-FU

> **TL;DR:** 本文对人形机器人两种全身控制（ID-WBC和PB-WBC）在任务加速度和任务力空间中的鲁棒性进行了实验比较，并分析了它们的优缺点。

**AI_Comments:** 本文的创新之处在于通过实际机器人实验而非仅理论分析来比较两种主流全身控制方法的鲁棒性，这对于理解它们在真实世界复杂环境中的表现至关重要。研究结果能为人形机器人控制器的选择和改进提供宝贵的实践依据。

<details>
  <summary>Details</summary>

**Motivation:** 尽管逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）在理想条件下均能预测闭环动力学稳定性，但它们在关节摩擦、传感器噪声、未建模外部干扰和非完美接触条件下的鲁棒性尚不明确。

**Method:** 通过在人形机器人平台上进行摆动脚位置和姿态控制、有无额外重量的深蹲以及跳跃实验，对两种控制器进行了分析和实验比较。

**Result:** 论文将观察到的性能和特征差异与控制器公式相关联，并强调了每种控制器的优点和缺点。

**Conclusion:** 本文通过实验比较了两种不同的全身控制公式，并揭示了它们在实际应用中的鲁棒性差异及其各自的优缺点。

> **ai_Abstract:** 本文对人形机器人中两种不同的全身控制公式——逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）进行了实验比较。研究指出，尽管两者在理想条件下均能保持稳定，但在面对关节摩擦、传感器噪声和外部干扰等实际问题时，其鲁棒性表现不明。通过在人形机器人上执行多种任务（如摆动脚控制、深蹲和跳跃），实验分析了两种控制器的性能差异，并根据其公式特点阐述了各自的优缺点。

> **摘要翻译:** 本文研究了人形机器人两种不同全身控制公式的实验比较：逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）。这两种控制器从根本上有所不同，前者在任务加速度空间中制定，后者在考虑无源性的任务力空间中制定。尽管两种控制方法在闭环动力学中都能在理想条件下预测稳定性，但它们对关节摩擦、传感器噪声、未建模的外部干扰和非完美接触条件的鲁棒性并不明显。因此，我们通过摆动脚位置和姿态控制、有无未建模附加重量的深蹲以及跳跃实验，在人形机器人平台上分析并实验比较了这两种控制器。我们还将观察到的性能和特性差异与控制器公式联系起来，并强调了每种控制器的优点和缺点。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [129] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
> *适用于二维无人机路径规划器的地形感知适应*

*Kostas Karakontis, Thanos Petsanis, Athanasios Ch. Kapoutsis, Pavlos Ch. Kapoutsis, Elias B. Kosmatopoulos* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 无人机, 路径规划, 三维重建, 地形感知, DARP

**Comment:** 

> **TL;DR:** 该论文提出了一种模块化算法，用于扩展现有的二维无人机路径规划器，使其能够感知地形，通过调整高度和摄像头方向来改进三维重建，尤其是在垂直表面区域。

**AI_Comments:** 该论文提出了一种创新的模块化方法，有效地解决了现有商业无人机路径规划软件在处理复杂三维地形时存在的局限性。通过将二维规划器适配为地形感知型，显著提高了三维重建的完整性和准确性，尤其是在垂直表面区域，这对于测绘、检查等应用具有重要意义。其开源实现也便于后续研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 流行的商业软件中的多无人机覆盖路径规划（mCPP）算法通常将感兴趣区域（RoI）视为二维平面，忽略了重要的三维结构特征。这导致不完整的三维重建，特别是在遮挡或垂直表面周围。

**Method:** 本文提出了一种模块化算法，通过调整高度和摄像头方向，扩展商业二维路径规划器以实现地形感知规划。为演示其效果，该算法扩展了著名的DARP（Divide Areas for Optimal Multi-Robot Coverage Path Planning）算法，并生成了DARP-3D。

**Result:** 在多个三维环境中的仿真结果以及使用大疆硬件进行的真实世界飞行测试表明，与基线相比，我们的方法始终能捕获到改进的三维重建，尤其是在具有显著垂直特征的区域。

**Conclusion:** 本文提出的地形感知适应方法能够有效改进二维无人机路径规划器的性能，使其在复杂三维环境中实现更完整和准确的三维重建，尤其是在处理垂直特征方面表现出色。

> **ai_Abstract:** 针对商业多无人机覆盖路径规划（mCPP）算法忽略三维地形特征导致三维重建不完整的问题，本文提出了一种模块化算法。该算法通过调整无人机高度和摄像头方向，将现有二维路径规划器扩展为地形感知型规划器。通过将DARP算法扩展为DARP-3D进行演示，仿真和真实世界测试结果表明，该方法能够显著改善三维重建质量，尤其是在具有垂直特征的区域。

> **摘要翻译:** 多无人机覆盖路径规划（mCPP）算法在流行的商业软件中通常只将感兴趣区域（RoI）视为二维平面，忽略了重要的三维结构特征。这导致不完整的三维重建，尤其是在遮挡或垂直表面周围。在本文中，我们提出了一种模块化算法，可以通过调整高度和摄像头方向来扩展商业二维路径规划器，以促进地形感知规划。为了证明它，我们扩展了著名的DARP（Divide Areas for Optimal Multi-Robot Coverage Path Planning）算法，并生成了DARP-3D。我们在多个三维环境和使用大疆硬件进行的真实世界飞行测试中展示了仿真结果。与基线相比，我们的方法始终能捕获到改进的三维重建，特别是在具有显著垂直特征的区域。该算法的开源实现可在以下链接获取：https://github.com/konskara/TerraPlan

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [169] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
> *CA-Cut：农作物对齐抠图数据增强，以学习更鲁棒的冠层下导航*

*Robel Mamo, Taeyeong Choi* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 数据增强, 冠层下导航, 农作物对齐抠图, 鲁棒性, 深度学习

**Comment:** Accepted for publication at the 12th European Conference on Mobile
  Robots (ECMR 2025)

> **TL;DR:** CA-Cut是一种新颖的数据增强方法，通过在农作物行周围遮蔽区域来模拟遮挡，显著提高了冠层下导航模型的鲁棒性和准确性。

**AI_Comments:** 该论文的创新之处在于其“农作物对齐”的抠图方法，该方法专门针对冠层下导航的关键特征（农作物行）。这种特定领域的数据增强技术对于提高农业机器人实际应用中的鲁棒性至关重要，因为遮挡是常见的。其在显著降低预测误差方面的有效性突出了其在实践中的价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的冠层下视觉导航方法依赖大量昂贵的训练数据，且传统数据增强技术在复杂、频繁遮挡的冠层下环境中表现不佳，导致模型性能次优，因此需要更有效的数据增强方法来提高模型在真实世界部署中的可靠性。

**Method:** 本文提出了一种名为农作物对齐抠图（CA-Cut）的新型数据增强方法。该方法在输入图像中遮蔽随机区域，这些区域空间上分布在农作物行两侧，旨在鼓励训练模型即使在精细信息被遮挡时也能捕获高级上下文特征。研究还通过消融实验确定了遮蔽的数量、大小和空间分布，以最大化整体性能。

**Result:** 在公共玉米田数据集上的广泛实验表明，基于遮蔽的增强能有效模拟遮挡并显著提高视觉导航中语义关键点预测的鲁棒性。特别是，CA-Cut中将遮蔽分布偏向农作物行对于提高预测精度和在不同环境中的泛化能力至关重要，可将预测误差最多降低36.9%。

**Conclusion:** CA-Cut是一种新颖的农作物对齐抠图数据增强方法，它能有效模拟遮挡，并显著提高深度学习模型在冠层下导航中的鲁棒性、准确性和泛化能力，尤其是在复杂环境中。

> **ai_Abstract:** 本文提出了一种名为CA-Cut的新型数据增强技术，旨在提高深度学习在冠层下导航中的鲁棒性。针对训练数据有限且昂贵的挑战，CA-Cut通过在农作物行周围应用空间偏置遮蔽来模拟遮挡，促使模型学习更高级的上下文特征。实验表明，CA-Cut显著提高了预测精度和泛化能力，与传统增强方法相比，预测误差最多可减少36.9%，从而使模型在复杂的农业环境中更加可靠。

> **摘要翻译:** 最先进的视觉冠层下导航方法采用基于深度学习的感知模型来区分可通行空间和农作物行。虽然这些模型已表现出成功的性能，但它们需要大量的训练数据才能确保在实际田间部署中的可靠性。然而，数据收集成本高昂，需要大量人力进行田间采样和标注。为了解决这一挑战，模型训练期间通常采用各种数据增强技术，例如颜色抖动、高斯模糊和水平翻转，以使训练数据多样化并增强模型鲁棒性。在本文中，我们假设仅使用这些增强技术可能会导致次优性能，尤其是在频繁遮挡、碎片和农作物间距不均匀的复杂冠层下环境中。相反，我们提出了一种新颖的增强方法，即农作物对齐抠图（CA-Cut），它在输入图像中遮蔽随机区域，这些区域空间上分布在农作物行两侧，以鼓励训练模型捕获高级上下文特征，即使精细信息被遮挡。我们对公共玉米田数据集进行的广泛实验表明，基于遮蔽的增强对于模拟遮挡和显著提高视觉导航语义关键点预测的鲁棒性是有效的。特别是，我们表明在CA-Cut中将遮蔽分布偏向农作物行对于提高预测精度和在不同环境中的泛化能力至关重要，预测误差最多可减少36.9%。此外，我们进行了消融研究，以确定遮蔽数量、每个遮蔽的大小以及遮蔽的空间分布，以最大化整体性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [248] [Spatio-Temporal Motion Retargeting for Quadruped Robots](https://arxiv.org/abs/2404.11557)
> *四足机器人时空运动重定向*

*Taerim Yoon, Dongho Kang, Seungmin Kim, Jin Cheng, Minsung Ahn, Stelian Coros, Sungjoon Choi* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 运动重定向, 腿式机器人, 强化学习, 模仿学习, 时空运动

**Comment:** 20 pages, 12 figures, videos available at
  https://taerimyoon.me/Spatio-Temporal-Motion-Retargeting-for-Quadruped-Robots/

> **TL;DR:** 该工作提出一种运动重定向方法，将人类或嘈杂源的动态运动转移到腿式机器人上，通过两阶段（运动学和动力学）方法实现，并成功在真实机器人上部署。

**AI_Comments:** 这项工作的创新之处在于其两阶段的时空运动重定向方法，能够有效地弥合源运动与目标机器人之间的形态差异，并确保物理可行性。其亮点在于能够处理嘈杂的运动源（如手持视频），并成功将复杂技能部署到多种真实世界机器人上，这对于机器人模仿学习和运动生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将源运动中的动态敏捷动作转移到腿式机器人上，同时弥合形态差异并确保目标系统的物理可行性。

**Method:** 该方法分两阶段：首先在运动学层面通过关键点轨迹生成运动学上可行的全身运动；其次在动力学层面通过在时间域调整运动并遵守物理约束进行优化。此过程通过强化学习促进策略训练，实现精确鲁棒的运动跟踪。

**Result:** 该方法成功将手持摄像机视频等嘈杂运动源转换为与目标机器人形态和物理特性相符的机器人特定运动。此外，还展示了地形感知运动重定向（如在箱子上进行后空翻），并成功在四种不同尺寸和物理特性的真实机器人上通过硬件实验部署了这些技能。

**Conclusion:** 该研究成功开发并验证了一种时空运动重定向方法，能够将多样化的源运动转移到不同形态的腿式机器人上，并在真实世界中实现了稳健的运动表现。

> **ai_Abstract:** 本文提出了一种针对腿式机器人的时空运动重定向方法，旨在将源运动的动态特性转移到机器人。该方法分为运动学和动力学两个阶段，首先从关键点轨迹生成运动学可行的全身运动，然后通过调整时间域并遵守物理约束进行动态优化，并利用强化学习进行策略训练。实验证明，该方法能将嘈杂的运动源（如视频）转换为适应机器人形态和物理特性的运动，并成功在多种真实世界机器人上实现复杂动作，包括地形感知的后空翻。

> **摘要翻译:** 这项工作提出了一种用于腿式机器人的运动重定向方法，旨在将动态敏捷的运动从源运动转移到机器人。具体来说，我们通过将运动从源转移到目标来指导模仿学习过程，有效地弥合了形态差异，同时确保了目标系统的物理可行性。在第一阶段，我们专注于通过从关键点轨迹生成运动学上可行的全身运动来在运动学层面进行运动重定向。在此之后，我们通过在时间域调整运动并遵守物理约束来在动力学层面优化运动。这个过程通过强化学习促进策略训练，从而实现精确和鲁棒的运动跟踪。我们证明了我们的方法成功地将嘈杂的运动源（例如手持摄像机视频）转换为与目标机器人的形态和物理特性相符的机器人特定运动。此外，我们还展示了地形感知运动重定向，以在箱子顶部执行后空翻。我们通过硬件实验成功地将这些技能部署到具有不同尺寸和物理特性的四台真实世界机器人上。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [283] [RoboCar: A Rapidly Deployable Open-Source Platform for Autonomous Driving Research](https://arxiv.org/abs/2405.03572)
> *RoboCar：一个用于自动驾驶研究的快速部署开源平台*

*Mehdi Testouri, Gamal Elghazaly, Raphael Frank* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 自动驾驶, 开源平台, RoboCar, 研究平台, 车辆系统

**Comment:** 

> **TL;DR:** RoboCar是一个开源的、模块化、低成本的自动驾驶研究平台，基于2018款起亚秀尔电动车，已在卢森堡市的公共道路上进行过真实世界测试。

**AI_Comments:** RoboCar的创新之处在于其作为开放源代码平台的可访问性，降低了自动驾驶研究的门槛。其模块化和成本效益高的设计使其对学术界和研究机构具有吸引力。在真实世界中进行测试的重要性不言而喻，它验证了平台的实用性。作为开源项目，它有望促进社区协作和进一步开发。

<details>
  <summary>Details</summary>

**Motivation:** 为了提供一个模块化、经济高效的框架，用于开发实验性自动驾驶系统（ADS），并推进自动驾驶研究。

**Method:** RoboCar平台整合了强大的硬件和软件架构，与车辆现有系统对齐，最大限度地减少了大量修改的需求。它支持各种自动驾驶功能，并利用2018款起亚秀尔电动车进行开发。

**Result:** 该平台已在卢森堡市的公共道路上进行了真实世界测试，并提供了平台架构、集成挑战和初步测试结果的见解。

**Conclusion:** RoboCar是一个可供研究人员使用的开源自动驾驶研究平台，旨在推进自动驾驶研究。

> **ai_Abstract:** RoboCar是一个由卢森堡大学开发的开源自动驾驶研究平台。该平台基于2018款起亚秀尔电动车，提供了一个模块化、成本效益高的框架，用于开发和测试实验性自动驾驶系统。它集成了与车辆现有系统兼容的软硬件架构，并已在真实世界的公共道路上进行测试。本文详细介绍了其架构、集成挑战和初步测试结果，旨在促进自动驾驶研究的进展。

> **摘要翻译:** 本文介绍了RoboCar，一个在卢森堡大学开发的开源自动驾驶研究平台。RoboCar提供了一个模块化、经济高效的框架，用于开发实验性自动驾驶系统（ADS），它利用了2018款起亚秀尔电动车。该平台集成了一个强大的硬件和软件架构，与车辆现有系统对齐，最大限度地减少了大量修改的需求。它支持各种自动驾驶功能，并已在卢森堡市的公共道路上进行了真实世界测试。本文概述了该平台的架构、集成挑战和初步测试结果，为它在推进自动驾驶研究中的应用提供了见解。RoboCar可在https://github.com/sntubix/robocar上获取，并以MIT开源许可证发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [318] [RUMI: Rummaging Using Mutual Information](https://arxiv.org/abs/2408.10450)
> *RUMI: 基于互信息的翻找*

*Sheng Zhong, Nima Fazeli, Dmitry Berenson* | **Category: cs.RO, cs.AI, I.2.9** | **Updated: 2025-07-24**

**Keywords:** 机器人, 互信息, 动作规划, 姿态估计, 模型预测控制

**Comment:** 20 pages, 20 figures, accepted by IEEE Transactions on Robotics
  (T-RO), preprint

> **TL;DR:** RUMI是一种机器人在线生成动作序列的方法，用于在视觉遮挡环境下收集关于已知可移动物体姿态的信息，通过互信息进行动作规划，并在仿真和实际任务中表现优异。

**AI_Comments:** 该论文的创新点在于将互信息应用于机器人在线动作规划，以解决视觉遮挡环境下的物体姿态信息收集问题，特别是在接触丰富的翻找场景。其提出的信念框架、高效信息增益计算和鲁棒MPC控制方案是重要的技术贡献，展示了在复杂、不确定环境下机器人感知和操作的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉遮挡环境下，机器人需要有效地获取已知可移动物体的姿态信息，尤其是在接触丰富的翻找任务中。

**Method:** RUMI方法利用物体姿态分布和机器人轨迹之间的互信息进行动作规划。它从观察到的部分点云推断兼容的物体姿态分布，并实时近似其与工作空间占用之间的互信息。基于此，开发了一个信息增益成本函数和一个可达性成本函数，以保持物体在机器人可达范围内。这些函数被整合到一个带有随机动力学模型的模型预测控制（MPC）框架中，以闭环方式更新姿态分布。关键贡献包括一个新的物体姿态估计信念框架、一个高效的信息增益计算策略以及一个鲁棒的基于MPC的控制方案。

**Result:** RUMI在仿真和实际任务中均表现出优于基线方法的性能。

**Conclusion:** 该论文提出了RUMI方法，通过利用互信息和MPC框架，在视觉遮挡环境下实现了机器人对物体姿态信息的有效收集，并在性能上超越了现有方法。

> **ai_Abstract:** RUMI是一种新颖的机器人方法，旨在视觉遮挡环境中通过在线生成动作序列来获取已知可移动物体的姿态信息。该方法特别适用于接触丰富的翻找任务，其核心在于利用物体姿态分布与机器人轨迹之间的互信息进行规划。RUMI能够从点云推断物体姿态分布并实时计算信息增益，并通过结合信息增益和可达性成本函数到模型预测控制框架中，实现闭环的姿态分布更新。实验证明，RUMI在仿真和实际任务中的性能均优于现有基线方法。

> **摘要翻译:** 这篇论文提出了RUMI（基于互信息的翻找），一种用于在线生成机器人动作序列的方法，旨在视觉遮挡环境中收集关于已知可移动物体姿态的信息。该方法专注于接触丰富的翻找，利用物体姿态分布和机器人轨迹之间的互信息进行动作规划。RUMI从观察到的部分点云推断出兼容的物体姿态分布，并实时近似其与工作空间占用之间的互信息。在此基础上，我们开发了一个信息增益成本函数和一个可达性成本函数，以使物体保持在机器人的可达范围内。这些函数被集成到一个带有随机动力学模型的模型预测控制（MPC）框架中，以闭环方式更新姿态分布。主要贡献包括一个新的物体姿态估计信念框架、一个高效的信息增益计算策略和一个鲁棒的基于MPC的控制方案。与基线方法相比，RUMI在模拟和实际任务中都表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [355] [Differentiable Motion Manifold Primitives for Reactive Motion Generation under Kinodynamic Constraints](https://arxiv.org/abs/2410.12193)
> *用于运动学动力学约束下反应式运动生成的微分运动流形基元*

*Yonghyeon Lee* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 微分运动流形基元, 反应式运动生成, 运动学动力学约束, 机器人运动规划, 轨迹优化

**Comment:** 6 pages and 9 figures

> **TL;DR:** 本文提出了一种名为DMMP的新型神经网络架构，用于在运动学动力学约束下实时生成高维系统的运动。DMMP通过离线学习低维轨迹流形并在线快速搜索，并确保了约束满足，在机器人投掷任务中表现优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了DMMP，一个能够编码和生成连续时间、可微分轨迹的神经网络架构，并解决了现有方法中缺乏约束满足策略的问题。这对于高维系统在复杂约束下实现实时反应式运动生成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高维系统在运动学动力学约束下进行实时运动生成是实现反应性和自适应行为的关键且具有挑战性的问题。

**Method:** 本文提出了一种两步法：首先离线学习任务相关、满足约束的低维轨迹流形；然后在此流形内进行快速在线搜索。通过扩展离散时间运动流形基元（MMP）框架，本文提出了可微分运动流形基元（DMMP），这是一种新颖的神经网络架构，用于编码和生成连续时间、可微分的轨迹。DMMP使用通过轨迹优化离线收集的数据进行训练，并采用了一种确保约束满足的策略，这是现有方法所缺乏的。

**Result:** 在7自由度机械臂动态投掷实验中，DMMP在规划速度、任务成功率和约束满足方面优于现有方法。

**Conclusion:** DMMP是一种有效的方法，可以在运动学动力学约束下实现高维系统的实时反应式运动生成，其在规划速度、任务成功率和约束满足方面均优于现有方法。

> **ai_Abstract:** 本文提出了一种名为可微分运动流形基元（DMMP）的新型神经网络架构，旨在解决高维系统在运动学动力学约束下实时运动生成的挑战。DMMP通过离线学习低维轨迹流形和在线快速搜索来实现，其创新之处在于能够编码和生成连续时间、可微分的轨迹，并确保了约束满足。实验证明，DMMP在规划速度、任务成功率和约束满足方面均优于现有方法。

> **摘要翻译:** 实时运动生成对于实现反应性和自适应行为至关重要，然而在高维系统运动学动力学约束下的实时运动生成是一个关键但具有挑战性的问题。我们通过两步法来解决这个问题：首先离线学习任务相关且满足约束的低维轨迹流形，然后在此流形内进行快速在线搜索。本文扩展了离散时间运动流形基元（MMP）框架，提出了可微分运动流形基元（DMMP），这是一种新颖的神经网络架构，用于编码和生成连续时间、可微分的轨迹。DMMP使用通过轨迹优化离线收集的数据进行训练，并采用了一种确保约束满足的策略——这是现有方法所缺乏的。在7自由度机械臂动态投掷实验中，DMMP在规划速度、任务成功率和约束满足方面优于现有方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [397] [An Efficient Numerical Function Optimization Framework for Constrained Nonlinear Robotic Problems](https://arxiv.org/abs/2501.17349)
> *针对约束非线性机器人问题的有效数值函数优化框架*

*Sait Sovukluk, Christian Ott* | **Category: cs.RO, math.OC** | **Updated: 2025-07-24**

**Keywords:** 数值优化, 机器人, 约束优化, 实时, 零空间投影

**Comment:** \c{opyright} 2025 the authors. This work has been accepted to IFAC
  for publication under a Creative Commons Licence CC-BY-NC-ND. -
  Implementation: https://github.com/ssovukluk/ENFORCpp

> **TL;DR:** 本文提出了一个高效的数值函数优化框架，用于机器人领域中的实时约束非线性问题，其特点是不需要解析表示，并结合了梯度线搜索和零空间投影。

**AI_Comments:** 该论文的创新点在于提供了一个无需解析表示即可处理机器人中实时约束黑盒问题的数值优化框架，结合了梯度线搜索和零空间投影。其对实时性和在线可用性的强调，以及将C++实现开源，大大提升了其实用性和对机器人社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 解决机器人领域中需要实时处理的在线轨迹和控制输入优化等约束优化问题，尤其是不需要问题解析表示的场景。

**Method:** 该框架是一个数值函数优化框架，它结合了一阶基于梯度的线搜索算法和通过零空间投影到约束雅可比空间的约束优先级处理。该方法适用于约束黑盒优化函数，且不要求问题的解析表示。

**Result:** 该框架能够处理实时在线轨迹和控制输入优化问题，并且适用于约束黑盒优化函数。该工具已用C++实现，并在线提供给社区使用，同时提供了数值和机器人示例实现。

**Conclusion:** 该框架为机器人领域的实时约束非线性优化问题提供了一个高效且实用的解决方案，其无需解析表示的特性和在线可用性增强了其实用价值。

> **ai_Abstract:** 本文提出了一种高效的数值函数优化框架，专为机器人领域的实时约束非线性问题设计。该框架的特点是无需问题的解析表示，并能处理受约束的黑盒优化函数。其核心方法结合了一阶梯度线搜索算法与通过零空间投影实现的约束优先级处理。该工具以C++实现，并已在线发布，附带数值和机器人应用示例。

> **摘要翻译:** 本文提出了一个专为机器人领域约束优化问题设计的数值函数优化框架。该工具在设计时考虑了实时性，适用于在线轨迹和控制输入优化问题。所提出的框架不需要问题的任何解析表示，并且适用于约束黑盒优化函数。该方法将一阶基于梯度的线搜索算法与通过零空间投影到约束雅可比空间的约束优先级处理相结合。该工具用C++实现，并在线提供给社区使用，同时本文还介绍了一些数值和机器人示例实现。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [426] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
> *PinchBot：基于引导扩散策略的长周期可变形操作*

*Alison Bartsch, Arvind Car, Amir Barati Farimani* | **Category: cs.RO** | **Updated: 2025-07-23**

**Keywords:** 可变形操作, 扩散策略, 机器人陶艺, 捏合动作, 长周期任务

**Comment:** 

> **TL;DR:** PinchBot是一个机器人系统，利用引导扩散策略和捏合动作，成功实现了简单的陶艺创作，解决了长周期可变形操作的挑战。

**AI_Comments:** 这项工作在机器人可变形操作领域具有创新性，特别是将扩散策略应用于长周期、多模态的捏合陶艺任务。通过结合多种技术（扩散策略、3D点云、进度预测、碰撞约束），PinchBot展示了在复杂艺术创作中实现机器人自动化的潜力，为未来更精细的柔性物体操作奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 陶艺创作需要灵巧、精确和精细的动作来将粘土塑造成目标形状。这项工作旨在创建一个机器人系统，能够通过捏合动作完成简单的陶艺目标，并探索高度多模态和长周期可变形操作的挑战。

**Method:** 本文提出了PinchBot，一个目标条件扩散策略模型。该模型结合了预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影。

**Result:** 该系统能够成功创建各种简单的陶艺目标。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了PinchBot，一个旨在通过捏合动作实现简单陶艺创作的机器人系统。针对高度多模态和长周期可变形操作的挑战，PinchBot采用目标条件扩散策略模型，并结合了3D点云嵌入、任务进度预测和碰撞约束动作投影，成功实现了多种简单陶艺目标的塑形。

> **摘要翻译:** 陶艺创作是一种复杂的艺术形式，需要灵巧、精确和精细的动作，才能将一块粘土缓慢地塑造成有意义且通常有用的3D目标形状。在这项工作中，我们旨在创建一个机器人系统，该系统仅通过捏合动作即可创建简单的陶艺目标。这种捏合陶艺任务使我们能够探索高度多模态和长周期可变形操作任务的挑战。为此，我们提出了PinchBot，一个目标条件扩散策略模型，该模型结合了预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影，能够成功创建各种简单的陶艺目标。有关实验视频和演示数据集的访问，请访问我们的项目网站：https://sites.google.com/andrew.cmu.edu/pinchbot/home。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [444] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
> *非线性模型预测控制在安全移动机器人导航中的分步指南*

*Dennis Benders, Laura Ferranti, Johannes Köhler* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-23**

**Keywords:** 非线性模型预测控制, 移动机器人导航, 安全性, 避障, 分步指南

**Comment:** 51 pages, 3 figures

> **TL;DR:** 本报告提供了一份关于非线性模型预测控制（NMPC）在安全移动机器人导航中实现的分步指南，旨在帮助研究人员和工程师将理论应用于实践，确保机器人在有障碍物、干扰和测量噪声的环境中安全导航。

**AI_Comments:** 本报告的创新之处在于其作为一份实用的分步指南，旨在弥合非线性模型预测控制（NMPC）理论与实际机器人应用之间的鸿沟。它没有提出新的算法，而是专注于提供一个可操作的框架，这对于希望在实际系统中应用NMPC的工程师和研究人员来说非常重要。其价值在于其易用性和对安全性的强调。报告还提到了其作为一份“活文档”的性质，可以根据反馈进行更新，这表明了其开放性和对准确性的承诺，但也意味着它可能不是一个最终的研究成果。

<details>
  <summary>Details</summary>

**Motivation:** 在充满障碍物的环境中设计一个能使移动机器人安全导航的模型预测控制（MPC）方案，是机器人领域一项复杂但至关重要的任务。现有文献虽然提供了线性MPC（LMPC）和NMPC的全面概述，但本报告旨在弥合理论NMPC公式与现实世界机器人应用之间的差距，提供一个实用且易于理解的实现路径，特别关注安全要求。

**Method:** 本报告提供了一种分步方法来实施非线性模型预测控制（NMPC）方案，以满足移动机器人安全导航所需的状态和输入约束以及避障要求。该方法强调从理论概念到数学证明再到实际实现，并侧重于安全性和性能保证。

**Result:** 本报告提供了一条从理论概念到数学证明和实现的实用且易于理解的路径，强调了安全性和性能保证。它旨在帮助研究人员、机器人工程师和从业者弥合理论NMPC公式与现实世界机器人应用之间的鸿沟。

**Conclusion:** 本报告成功提供了一份关于非线性模型预测控制（NMPC）在安全移动机器人导航中实现的分步指南，旨在帮助从业者将复杂的理论应用于实际，确保机器人在复杂环境中安全高效地运行。

> **ai_Abstract:** 本报告提供了一份关于非线性模型预测控制（NMPC）在安全移动机器人导航中实现的分步指南。它旨在解决移动机器人在充满障碍物、存在干扰和测量噪声的环境中安全导航的复杂挑战。报告详细介绍了如何从理论概念到数学证明再到实际实现NMPC方案，特别强调了满足状态和输入约束以及避免碰撞的安全要求，旨在弥合NMPC理论与实际机器人应用之间的差距。

> **摘要翻译:** 设计一个能够使移动机器人在充满障碍物的环境中安全导航的模型预测控制（MPC）方案是机器人领域一项复杂但至关重要的任务。在本技术报告中，安全性是指确保机器人在存在干扰和测量噪声的情况下，遵守状态和输入约束，同时避免与障碍物碰撞。本报告提供了一种分步方法来实施非线性模型预测控制（NMPC）方案，以解决这些安全要求。大量的书籍和调查论文提供了线性MPC（LMPC）\cite{bemporad2007robust,kouvaritakis2016model}、NMPC \cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook}及其在包括机器人在内的各种领域应用\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}的全面概述。本报告无意复制那些详尽的综述。相反，它专门关注NMPC作为安全移动机器人导航的基础。目标是提供一条从理论概念到数学证明和实现的实用且易于理解的路径，强调安全性和性能保证。它面向寻求弥合理论NMPC公式与现实世界机器人应用之间差距的研究人员、机器人工程师和从业者。本报告不一定随时间保持不变。如果有人发现所呈理论中的错误，请通过提供的电子邮件地址联系。如有必要，我们乐意更新文档。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [445] [Realtime Limb Trajectory Optimization for Humanoid Running Through Centroidal Angular Momentum Dynamics](https://arxiv.org/abs/2501.17351)
> *基于质心角动量动力学的人形机器人实时肢体轨迹优化*

*Sait Sovukluk, Robert Schuller, Johannes Englsberger, Christian Ott* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 人形机器人, 肢体轨迹优化, 实时控制, 角动量动力学, 奔跑稳定性

**Comment:** This paper has been accepted for publication at the IEEE
  International Conference on Robotics and Automation (ICRA), Atlanta 2025.
  Link to video: https://www.youtube.com/watch?v=czfHjwh_A0Y

> **TL;DR:** 本文提出了一种实时非线性肢体轨迹优化方法，以解决人形机器人在高速奔跑时因肢体摆动不当导致的姿态不稳定问题，并在仿真环境中进行了验证。

**AI_Comments:** 本文的创新点在于提出了一个实时非线性优化问题来解决人形机器人奔跑中的肢体稳定性问题，特别是在角动量守恒作用下的腾空阶段。其重要性在于提升了人形机器人在复杂运动（如高速奔跑）中的自主性和稳定性，为未来人形机器人运动控制提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 人形机器人奔跑时，肢体摆动轨迹的确定至关重要。在腾空阶段，由于无法利用地面反作用力进行调节，不适当的肢体摆动会因角动量守恒导致着陆时身体严重倾斜和不稳定，尤其是在高速和高腾空时间轨迹下，机器人系统难以保持稳定的运动。

**Method:** 本文提出了一种用于人形机器人奔跑的实时非线性肢体轨迹优化问题。

**Result:** 该优化问题在两种不同的人形机器人模型上进行了测试，并使用奔跑算法在仿真环境中验证了所生成的轨迹。

**Conclusion:** 本文提出的实时非线性肢体轨迹优化方法能有效解决人形机器人奔跑时的肢体摆动导致的稳定问题，并在仿真中得到验证。

> **ai_Abstract:** 本文针对人形机器人在奔跑过程中，尤其是在腾空阶段，因不当肢体摆动导致姿态不稳的问题，提出了一种基于质心角动量动力学的实时非线性肢体轨迹优化方法。该方法旨在通过优化肢体摆动轨迹来确保着陆时的稳定性。研究在两种不同的人形机器人模型上进行了测试，并通过仿真环境中的奔跑算法验证了所生成轨迹的有效性。

> **摘要翻译:** 人形机器人奔跑的一个重要方面是确定肢体摆动轨迹。在腾空阶段，由于无法利用地面反作用力进行调节，肢体摆动轨迹对于下一个支撑阶段的稳定性至关重要。由于角动量守恒，不适当的腿部和手臂摆动会导致在下一个支撑阶段着陆时身体高度倾斜和不稳定。在这种情况下，机器人系统无法独立于质心轨迹的稳定性来维持运动。这个问题对于高速和高腾空时间的轨迹更为明显。本文提出了一种用于人形机器人奔跑的实时非线性肢体轨迹优化问题。该优化问题在两种不同的人形机器人模型上进行了测试，并使用奔跑算法在仿真环境中验证了两种机器人的生成轨迹。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [462] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
> *OpenNav: 基于多模态大语言模型的开放世界导航*

*Mingfeng Yuan, Letian Wang, Steven L. Waslander* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 开放世界导航, 多模态大语言模型, 零样本导航, 机器人导航, 语言指令

**Comment:** 

> **TL;DR:** OpenNav利用多模态大语言模型（MLLMs）的常识推理和代码生成能力，实现了机器人在开放世界中理解复杂语言指令并生成轨迹点进行导航，并通过大规模自动驾驶数据集和真实机器人验证了其在室外导航任务中的零样本视觉-语言导航能力。

**AI_Comments:** 该论文的创新点在于利用多模态大语言模型的代码生成能力，将高层语义理解与低层空间信息有效结合，从而实现了在开放世界中对复杂语言指令的零样本导航。这种方法超越了传统预定义运动原语的限制，为机器人导航带来了更强大的泛化性和适应性，尤其是在处理自然语言的复杂性和开放环境的不可预测性方面。其在真实机器人上的验证进一步证明了方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管预训练大语言模型在机器人导航和规划任务中展现出潜力，但在开放世界中将语言描述与实际机器人动作联系起来，而不仅仅是调用有限的预定义运动原语，仍然是一个开放的挑战。

**Method:** 本研究旨在使机器人能够解释和分解复杂的语言指令，最终合成一系列轨迹点来完成各种导航任务，即使在开放集指令和开放集对象的情况下。研究观察到多模态大语言模型（MLLMs）在处理自由形式语言指令时表现出强大的跨模态理解能力和鲁棒的场景理解能力。更重要的是，利用其代码生成能力，MLLMs可以与视觉-语言感知模型交互，生成组合式的2D鸟瞰图价值地图，有效地将MLLMs的语义知识与地图的空间信息相结合，以增强机器人的空间理解。该方法通过大规模自动驾驶数据集（AVDs）在室外导航任务中验证了所提出的零样本视觉-语言导航框架，并在Husky机器人上进行了室内外场景验证。

**Result:** 该方法在室外导航任务中展示了执行各种自由形式自然语言导航指令的能力，同时对目标检测错误和语言歧义保持鲁棒性。此外，系统在Husky机器人上的室内外场景验证也证明了其在现实世界中的鲁棒性和适用性。

**Conclusion:** 本研究成功地利用多模态大语言模型在开放世界中实现了机器人通过复杂语言指令进行导航，并展现了其在处理开放集指令、开放集对象以及对抗感知错误和语言歧义方面的强大能力，验证了其在真实世界环境中的实用性和鲁棒性。

> **ai_Abstract:** OpenNav提出了一种利用多模态大语言模型（MLLMs）进行开放世界机器人导航的框架。该框架使机器人能够理解和分解复杂的自然语言指令，并通过MLLM的代码生成能力与视觉-语言感知模型结合，生成2D鸟瞰图价值地图，从而将语义知识与空间信息融合，最终合成轨迹点。该方法在处理开放集指令和对象时表现出鲁棒性，并通过大规模自动驾驶数据集和真实机器人实验验证了其在零样本视觉-语言导航任务中的有效性和对感知错误、语言歧义的抵抗能力。

> **摘要翻译:** 预训练大语言模型（LLMs）展示了强大的常识推理能力，使其在机器人导航和规划任务中具有广阔前景。然而，尽管最近取得了进展，在开放世界中，将语言描述与实际机器人动作联系起来，而不仅仅是调用有限的预定义运动原语，仍然是一个开放的挑战。在这项工作中，我们的目标是使机器人能够解释和分解复杂的语言指令，最终合成一系列轨迹点以完成多样化的导航任务，即使在开放集指令和开放集对象的情况下。我们观察到多模态大语言模型（MLLMs）在处理自由形式语言指令时表现出强大的跨模态理解能力，展现出鲁棒的场景理解。更重要的是，利用其代码生成能力，MLLMs可以与视觉-语言感知模型交互，生成组合式的2D鸟瞰图价值地图，有效地将MLLMs的语义知识与地图的空间信息相结合，以增强机器人的空间理解。为了进一步验证我们的方法，我们有效地利用大规模自动驾驶数据集（AVDs）来验证我们提出的零样本视觉-语言导航框架在室外导航任务中的表现，展示了其执行各种自由形式自然语言导航指令的能力，同时对目标检测错误和语言歧义保持鲁棒性。此外，我们还在室内外场景的Husky机器人上验证了我们的系统，展示了其现实世界的鲁棒性和适用性。补充视频可在 https://trailab.github.io/OpenNav-website/ 查看。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [486] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
> *模块化机器人与地标定位，使用相对方位测量*

*Behzad Zamani, Jochen Trumpf, Chris Manzie* | **Category: cs.RO, cs.SY, eess.SP, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 模块化滤波, 机器人定位, 地标定位, 协方差交集, 非线性最小二乘

**Comment:** Submitted to RA-L

> **TL;DR:** 本文提出了一种模块化的非线性最小二乘滤波方法，用于由独立子系统组成的系统，即使存在耦合测量也能独立更新状态。该方法集成了协方差交集（CI）算法以避免信息重复计算，并在机器人-地标定位问题中进行了验证，显示出与整体联合状态滤波器的权衡，并能通过减少通信和带宽要求实现性能的优雅降级。

**AI_Comments:** 这项研究的创新之处在于提出了一种模块化的滤波方法，它允许独立子系统在存在耦合测量的情况下进行独立的状态更新，并通过巧妙地集成协方差交集（CI）算法来解决信息重复计算的问题。这对于分布式或资源受限的机器人系统具有重要意义，因为它可以在降低通信和带宽要求的同时保持合理的定位性能。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决由独立子系统组成的系统中的状态和误差协方差估计问题，即使当相对测量同时依赖于多个子系统的状态时，也能独立更新每个子系统的估计。主要动机是防止信息重复计算，尤其是在子系统之间共享估计时。

**Method:** 本文提出了一种模块化的非线性最小二乘滤波方法。该方法将协方差交集（CI）算法作为解决方案的一部分进行集成，以防止子系统共享估计时信息重复计算。CI算法的替代推导基于最小二乘估计，使得这种集成成为可能。该方法特别应用于机器人-地标定位问题，其中机器人姿态和地标位置的估计问题通过对地标方位角的噪声测量进行耦合。

**Result:** 在随机模拟研究中，所提出的模块化方法与整体联合状态滤波器进行了基准测试，以阐明它们各自的权衡。研究还包括了所提出方法的变体，这些变体在减少通信和带宽要求的情况下，实现了性能的优雅降级。

**Conclusion:** 所提出的模块化非线性最小二乘滤波方法能够有效地处理由独立子系统组成的系统中的定位问题，即使存在耦合测量也能独立更新状态。通过集成协方差交集算法，有效避免了信息重复计算，且在通信和带宽受限的情况下仍能保持良好的性能。

> **ai_Abstract:** 本文提出了一种模块化的非线性最小二乘滤波方法，用于处理由独立子系统组成的系统定位问题。该方法即使在相对测量耦合多个子系统状态的情况下也能实现独立的状态更新，并通过集成协方差交集（CI）算法有效避免信息重复计算。研究将该方法应用于机器人-地标定位问题，并与传统联合状态滤波器进行比较，结果表明其在性能和资源消耗之间存在权衡，并能通过减少通信实现性能的优雅降级。

> **摘要翻译:** 在本文中，我们提出了一种模块化的非线性最小二乘滤波方法，用于由独立子系统组成的系统。即使当相对测量同时依赖于多个子系统的状态时，每个子系统的状态和误差协方差估计也能独立更新。我们将协方差交集（CI）算法作为解决方案的一部分进行集成，以防止当子系统之间共享估计时信息重复计算。CI算法基于最小二乘估计的替代推导使得这种集成成为可能。我们将所提出的方法特别应用于机器人-地标定位问题。在这个问题中，对静止地标位置的方位角进行噪声测量，该测量相对于移动机器人的SE(2)姿态，从而耦合了机器人姿态和地标位置的估计问题。在随机模拟研究中，我们将所提出的模块化方法与整体联合状态滤波器进行基准测试，以阐明它们各自的权衡。在这项研究中，我们还包括了所提出方法的变体，这些变体在减少通信和带宽要求的情况下，实现了性能的优雅降级。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [497] [Safe, Task-Consistent Manipulation with Operational Space Control Barrier Functions](https://arxiv.org/abs/2503.06736)
> *基于操作空间控制障碍函数的安全、任务一致性机械臂操作*

*Daniel Morton, Marco Pavone* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 操作空间, 控制障碍函数, 机器人, 安全性, 任务一致性

**Comment:** 

> **TL;DR:** 本文提出了一种操作空间控制障碍函数（OSCBF）框架，用于在非结构化环境中对机器人机械臂进行安全、实时的控制，解决了传统方法的问题，并在保持任务一致性的同时处理大量安全约束。

**AI_Comments:** 该论文的创新点在于提出了OSCBF框架，将操作空间控制与控制障碍函数相结合，并在CBF目标中明确考虑任务层次结构，从而在保证安全性的同时，有效避免了传统CBFs可能导致的性能下降。其能够处理大量并发约束并保持实时性，对于复杂环境中的机器人安全操作具有重要意义。开源代码的发布也促进了研究的复现和发展。

<details>
  <summary>Details</summary>

**Motivation:** 在非结构化环境中对机器人机械臂进行安全实时控制，需要处理大量安全约束同时不损害任务性能。传统方法如人工势场（APFs）存在局部最小值、振荡和可扩展性有限的问题，而模型预测控制（MPC）计算成本高昂。控制障碍函数（CBFs）虽有潜力，但若设计不当会显著降低机械臂的整体性能。

**Method:** 本文引入了一种操作空间控制障碍函数（OSCBF）框架，该框架集成了安全约束，同时保留了任务一致性行为。该方法通过在CBF目标中明确考虑任务层次结构，解决了性能下降问题，并能扩展到数百个并发约束，同时保持实时控制速率。

**Result:** 该方法能够扩展到数百个并发约束，同时保持实时控制速率，确保在高度杂乱环境或动态运动中也能实现碰撞避免、奇点预防和工作空间限制。通过明确考虑CBF目标中的任务层次结构，防止了在安全极限下关节空间和操作空间任务的性能下降。该方法在仿真和硬件中均得到了验证。

**Conclusion:** OSCBF框架提供了一种鲁棒且计算成本低廉的解决方案，能够实现机械臂在复杂环境中的安全、任务一致性操作，有效克服了现有方法的局局限性。

> **ai_Abstract:** 本文提出了一种操作空间控制障碍函数（OSCBF）框架，旨在解决机器人机械臂在非结构化环境中安全实时控制的挑战。针对传统方法（如APFs和MPC）的局限性以及CBFs设计不当导致的性能下降问题，OSCBF通过集成安全约束并考虑任务层次结构，确保了任务一致性行为。该方法能够高效处理数百个并发约束，保持实时控制，并有效实现碰撞避免、奇点预防和工作空间限制，已在仿真和硬件中得到验证。

> **摘要翻译:** 在非结构化环境中对机器人机械臂进行安全实时控制，需要处理大量安全约束同时不损害任务性能。传统方法如人工势场（APFs）存在局部最小值、振荡和可扩展性有限的问题，而模型预测控制（MPC）计算成本高昂。控制障碍函数（CBFs）因其高鲁棒性和低计算成本而提供了一种有前景的替代方案，但这些安全滤波器必须精心设计，以避免显著降低机械臂的整体性能。在这项工作中，我们引入了一种操作空间控制障碍函数（OSCBF）框架，该框架集成了安全约束，同时保留了任务一致性行为。我们的方法可以扩展到数百个并发约束，同时保持实时控制速率，即使在高度杂乱的环境或动态运动中也能确保碰撞避免、奇点预防和工作空间限制。通过在CBF目标中明确考虑任务层次结构，我们在达到安全极限时，防止了关节空间和操作空间任务的性能下降。我们在仿真和硬件中都验证了性能，并在项目网页 https://stanfordasl.github.io/oscbf/ 上发布了我们的开源高性能代码和媒体。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [510] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
> *一种模块化残差学习框架，用于增强基于模型的方法以实现鲁棒运动*

*Min-Gyu Kim, Dongyun Kang, Hajun Kim, Hae-Won Park* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 残差学习, 鲁棒运动, 基于模型的控制, 基于学习的控制, 四足机器人

**Comment:** 8 pages, IEEE RA-L accepted (July 2025)

> **TL;DR:** 本文提出了一种模块化残差学习框架，结合基于模型和基于学习的方法，以提高在不确定环境中的鲁棒运动性能。该框架通过集成残差模块来补偿模型不匹配，从而提升控制性能、学习效率和控制器对参数调整的鲁棒性，并在真实的四足机器人上进行了验证。

**AI_Comments:** 该论文的创新之处在于将残差学习以模块化的方式集成到基于模型的框架的具体组件中，从而有效地解决了模型不匹配问题。这种方法不仅提高了性能和效率，还增强了控制器对参数调整的鲁棒性，这对于实际机器人应用具有重要意义。在存在不确定性的真实四足机器人上的演示，进一步突出了其实用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决基于模型的运动控制中因模型不匹配导致的性能下降问题，尤其是在不确定环境中实现鲁棒运动。

**Method:** 本文提出了一种新颖的方法，结合了基于模型和基于学习的框架。它将残差模块集成到基于模型的框架（包括启发式设计的落足规划器和动力学模型）的每个对应部分，以弥补模型不匹配造成的性能下降。该框架利用模块化结构，并为每个残差模块选择合适的基于学习的方法。通过在真实的四足机器人上结合模型预测控制进行了可行性验证。

**Result:** 与基线方法相比，该框架在高度不确定的环境中表现出改进的控制性能和更高的学习效率。此外，它还使标称控制器对参数调整更加鲁棒。在真实的四足机器人上，尽管存在超出模拟的不确定性，机器人仍成功保持平衡并跟踪指令速度。

**Conclusion:** 所提出的模块化残差学习框架通过减轻模型不匹配、提高控制性能、学习效率和控制器鲁棒性，有效地增强了基于模型的鲁棒运动方法，并在真实机器人上得到了验证。

> **ai_Abstract:** 本文提出了一种模块化残差学习框架，旨在通过结合基于模型和基于学习的方法来增强鲁棒运动。该框架将残差模块集成到基于模型的组件中，以补偿模型不匹配，从而在不确定环境中提高控制性能和学习效率。此外，它还提升了标称控制器对参数调整的鲁棒性。该方法已在真实的四足机器人上得到验证，机器人成功实现了稳定运动。

> **摘要翻译:** 本文提出了一种新颖的方法，结合了基于模型和基于学习框架的优点，以实现鲁棒运动。残差模块与基于模型的框架（通过启发式方法设计的落足规划器和动力学模型）的每个对应部分集成，以弥补模型不匹配导致的性能下降。通过利用模块化结构并为每个残差模块选择合适的基于学习的方法，我们的框架在高度不确定的环境中表现出改进的控制性能，同时与基线方法相比实现了更高的学习效率。此外，我们观察到我们提出的方法不仅增强了控制性能，还提供了额外的好处，例如使标称控制器对参数调整更加鲁棒。为了研究我们框架的可行性，我们在真实的四足机器人中演示了结合模型预测控制的残差模块。尽管存在超出模拟的不确定性，机器人仍成功保持平衡并跟踪指令速度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [534] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
> *基于计算机视觉和卷积神经网络的无人机自主导航用于搜救任务*

*Luka Šiktar, Branimir Ćaran, Bojan Šekoranja, Marko Švaco* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 无人机, 搜救, 计算机视觉, 卷积神经网络, 自主导航

**Comment:** The paper is accepted and presented on the 34th International
  Conference on Robotics in Alpe-Adria-Danube Region, RAAD 2025, Belgrade
  Serbia

> **TL;DR:** 开发了一个使用计算机视觉和CNN的无人机子系统，用于搜救任务中的人员检测、人脸识别和跟踪。

**AI_Comments:** 该论文的创新之处在于其将多种先进的计算机视觉模型（如YOLO系列和dlib）与ROS2框架下的无人机自主导航和控制（系统识别、PD控制器）相结合，以实现搜救任务中人员的自动检测、识别和跟踪。其重要性在于为搜救行动提供了一种高效、实时的自动化工具，能够显著提高救援效率和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 在搜救任务中，需要一个能够实现人员检测、人脸识别和已识别个体跟踪的自主系统，以提高效率和自动化程度。

**Method:** 该方案将无人机与ROS2框架集成，利用YOLOv11、YOLOv11-pose和dlib库的CNN进行跟踪和人脸识别。通过系统识别和PD控制器实现无人机自主导航，并利用YOLOv11-pose识别的人体关键点进行个体跟踪和保持安全距离。系统支持手动定位未知人员并启动跟踪。

**Result:** 在14名已知个体上进行的初步实验表明，所提出的子系统可以实时成功使用。

**Conclusion:** 所提出的无人机子系统可实时用于搜救任务。下一步是在大型实验无人机上实现，以进行野外使用，并将自主导航与GPS引导控制集成，用于救援行动规划。

> **ai_Abstract:** 本文提出了一种基于无人机（UAV）的搜救子系统，专注于人员检测、人脸识别和目标跟踪。该系统将无人机与ROS2框架集成，利用YOLOv11、YOLOv11-pose和dlib等卷积神经网络（CNN）实现自主导航、人脸识别和基于人体关键点的跟踪。通过系统识别和PD控制器确保精确跟踪和安全距离。初步实验证明该系统能够实时有效地运行，为未来的野外应用和GPS引导控制集成奠定基础。

> **摘要翻译:** 在本文中，我们提出了一种使用无人机（UAV）的搜救任务子系统，专注于人员检测、人脸识别和已识别个体的跟踪。所提出的解决方案将无人机与ROS2框架集成，该框架利用多个卷积神经网络（CNN）进行搜索任务。为了实现无人机自主导航，进行了系统识别和PD控制器部署。ROS2环境利用YOLOv11和YOLOv11-pose CNN进行跟踪，并利用dlib库的CNN进行人脸识别。系统检测到特定个体，执行人脸识别并开始跟踪。如果该个体尚不明确，无人机操作员可以手动定位该人员，保存其面部图像并立即启动跟踪过程。跟踪过程依赖于使用YOLOv11-pose CNN模型识别的人体特定关键点。这些关键点用于跟踪特定个体并保持安全距离。为了增强精确跟踪，基于无人机IMU的测量数据进行了系统识别。识别出的系统参数用于设计利用YOLOv11-pose估计无人机摄像头与已识别个体之间距离的PD控制器。在14名已知个体上进行的初步实验表明，所提出的子系统可以实时成功使用。下一步包括在大型实验无人机上实现该系统以进行野外使用，并将自主导航与GPS引导控制集成用于救援行动规划。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [541] [Learning Gentle Grasping Using Vision, Sound, and Touch](https://arxiv.org/abs/2503.07926)
> *学习使用视觉、声音和触觉进行轻柔抓取*

*Ken Nakahara, Roberto Calandra* | **Category: cs.RO, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 轻柔抓取, 多模态学习, 视觉, 触觉, 听觉

**Comment:** 8 pages. Accepted by 2025 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)

> **TL;DR:** 该论文提出了一种使用视觉、触觉和听觉信号学习轻柔抓取脆弱物体的方法，通过端到端模型预测抓取稳定性和轻柔性，并在实验中表现出优于基线的性能。

**AI_Comments:** 这篇论文的创新点在于将听觉信号引入到机器人抓取任务中，作为轻柔度的直接指标，并结合视觉和触觉数据形成多模态学习框架。这种方法不仅提高了抓取易碎物品的成功率，还通过避免触觉传感器校准和分析力建模，显著降低了工程复杂性，具有很强的实用价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在日常生活中，经常遇到易碎物品，过度的抓取力会损坏它们。因此，需要学习以最小而非最大的力进行轻柔抓取，以避免损坏。

**Method:** 本文提出利用视觉、触觉和听觉信号来学习稳定且轻柔的抓取和重新抓取物体。具体来说，使用音频信号作为抓取过程中轻柔度的指标，然后训练一个从原始视觉-触觉输入到预测未来抓取候选的稳定性和轻柔性的端到端动作条件模型。该方法无需触觉传感器校准或分析力建模。

**Result:** 在超过1500次抓取试验的多指手实验中，模型验证了预测性能（比仅视觉变体高3.27%的准确率）。真实世界实验证实，训练后的多模态模型抓取性能优于其他基线（稳定和轻柔抓取率比仅视觉高17%）。

**Conclusion:** 该研究证明了使用视觉、触觉和听觉信号进行多模态学习对于实现轻柔抓取是有效且实用的，并且显著减少了抓取易碎物品所需的工程工作量。

> **ai_Abstract:** 本文提出了一种创新的多模态学习方法，结合视觉、触觉和听觉信号，以实现对易碎物品的轻柔且稳定的抓取。通过将音频作为轻柔度指标，并训练一个端到端模型预测抓取稳定性和轻柔性，该方法在实验中显著优于仅视觉的基线，提高了抓取成功率和准确性。其优势在于无需复杂的传感器校准和力学建模，大大简化了工程实施。

> **摘要翻译:** 在我们的日常生活中，我们经常遇到易碎且可能因过度抓取力而损坏的物体，例如水果。对于这些物体，轻柔抓取至关重要——不是使用最大可能的力，而是使用最小必要的力。本文提出使用视觉、触觉和听觉信号来学习稳定且轻柔地抓取和重新抓取物体。具体来说，我们使用音频信号作为抓取过程中轻柔度的指标，然后训练一个从原始视觉-触觉输入到预测未来抓取候选的稳定性和轻柔性的端到端动作条件模型，从而选择并执行最有希望的动作。在超过1500次抓取试验的多指手实验结果表明，我们的模型通过验证预测性能（比仅视觉变体高3.27%的准确率）并提供其行为解释，对轻柔抓取非常有用。最后，真实世界实验证实，使用训练后的多模态模型抓取性能优于其他基线（稳定和轻柔抓取率比仅视觉高17%）。我们的方法既不需要触觉传感器校准，也不需要分析力建模，大大减少了抓取易碎物品的工程工作量。数据集和视频可在https://lasr.org/research/gentle-grasping获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [558] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
> *基于大语言模型的多机器人团队组合式协同*

*Zhehui Huang, Guangyao Shi, Yuwei Wu, Vijay Kumar, Gaurav S. Sukhatme* | **Category: cs.RO, cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 多机器人协同, 大型语言模型, 自然语言处理, 行为树, 代码生成

**Comment:** 9 pages, 4 figures

> **TL;DR:** LAN2CB是一个利用大语言模型将自然语言任务描述转化为多机器人可执行代码的框架，旨在简化多机器人协同。

**AI_Comments:** 该论文的创新点在于将大型语言模型引入多机器人协同领域，实现了从自然语言任务描述到可执行代码的自动化转化，极大地简化了传统流程。这对于非专家用户具有重要意义，并提升了系统的灵活性和泛化能力。未来，该方法有望在更复杂的任务和异构机器人团队中得到应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多机器人协同依赖于任务特定和专家驱动的流程，需要手动将自然语言任务描述转化为数学公式、算法和可执行代码，这导致过程劳动密集、非专家难以使用且对任务变化不灵活。

**Method:** 本文提出了LAN2CB（Language to Collective Behavior）框架，利用大语言模型（LLMs）来简化和泛化多机器人协同流程。LAN2CB通过两个核心模块将自然语言任务描述转换为多机器人系统的可执行Python代码：1) 任务分析模块，将任务描述解析为行为树；2) 代码生成模块，利用行为树和结构化知识库生成机器人控制代码。此外，还引入了一个自然语言任务描述数据集以支持开发和基准测试。

**Result:** 在仿真和真实世界环境中的实验表明，LAN2CB能够实现从自然语言进行鲁棒且灵活的多机器人协同，显著减少了手动工程工作，并支持跨不同任务类型的广泛泛化。

**Conclusion:** LAN2CB框架利用大语言模型成功地将自然语言任务描述转化为多机器人可执行代码，极大地简化了多机器人协同的传统流程，提高了其可访问性和灵活性。

> **ai_Abstract:** 本论文提出了一种名为LAN2CB（Language to Collective Behavior）的新型框架，旨在解决传统多机器人协同流程中劳动密集、缺乏灵活性和非专家难以操作的问题。LAN2CB利用大型语言模型，将自然语言的任务描述自动化地转换为可执行的Python代码，其核心包含任务分析和代码生成两大模块。通过在仿真和真实世界的实验验证，LAN2CB显著降低了手动工程投入，实现了从自然语言到多机器人行为的鲁棒且泛化的协同。

> **摘要翻译:** 多机器人协同传统上依赖于任务特定和专家驱动的流水线，其中自然语言任务描述由领域专家手动转换为数学公式、算法设计和可执行代码。这种传统过程劳动密集、非专家难以使用，并且对任务需求的变化不灵活。本文提出LAN2CB（Language to Collective Behavior），一个利用大型语言模型（LLMs）来简化和泛化多机器人协同流水线的新颖框架。LAN2CB通过两个核心模块将自然语言（NL）任务描述转换为多机器人系统的可执行Python代码：(1) 任务分析，将任务描述解析为行为树；(2) 代码生成，利用行为树和结构化知识库生成机器人控制代码。我们进一步引入了一个自然语言任务描述数据集以支持开发和基准测试。在仿真和真实世界环境中的实验表明，LAN2CB能够从自然语言实现鲁棒且灵活的多机器人协同，显著减少了手动工程工作，并支持跨不同任务类型的广泛泛化。网站：https://sites.google.com/view/lan-cb

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [564] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
> *MoRPI-PINN：一种用于移动机器人纯惯性导航的物理信息框架*

*Arup Kumar Sahoo, Itzik Klein* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 移动机器人, 惯性导航, 物理信息神经网络, MoRPI-PINN, 精度提升

**Comment:** 9 pages, 5 figures

> **TL;DR:** MoRPI-PINN是一种物理信息神经网络框架，通过嵌入物理定律和约束，显著提高了移动机器人在卫星/相机不可用情况下的纯惯性导航精度，且轻量级，适用于边缘设备。

**AI_Comments:** MoRPI-PINN的创新之处在于将物理定律和约束融入神经网络训练，以克服纯惯性导航中传感器误差导致的漂移问题。其重要性在于提供了一种在GPS或视觉受限环境下实现高精度导航的有效方案，尤其适用于资源受限的边缘设备，具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在卫星导航或摄像头不可用的情况下，移动机器人需要准确的导航。仅依靠惯性传感器会导致导航漂移，现有通过蛇形运动增加信噪比的方法可以缓解漂移，但仍需要更准确和鲁棒的解决方案。

**Method:** 本文提出了MoRPI-PINN，一个物理信息神经网络框架，用于精确的基于惯性的移动机器人导航。通过在训练过程中嵌入物理定律和约束，MoRPI-PINN能够提供准确和鲁棒的导航解决方案。

**Result:** 真实世界实验表明，MoRPI-PINN相比其他方法，精度提高了超过85%。它是一种轻量级方法，可以在边缘设备上实现，并用于任何典型的移动机器人应用。

**Conclusion:** MoRPI-PINN通过结合物理信息神经网络，显著提高了移动机器人纯惯性导航的精度和鲁棒性，且具有轻量级和广泛适用性。

> **ai_Abstract:** 本文提出了MoRPI-PINN，一个物理信息神经网络框架，旨在解决移动机器人在卫星或摄像头不可用时纯惯性导航的漂移问题。该框架通过将物理定律和约束嵌入训练过程，显著提高了导航精度和鲁棒性，在真实世界实验中显示出超过85%的精度提升，并且轻量化，适用于边缘设备和各种移动机器人应用。

> **摘要翻译:** 移动机器人实现完全自主的一个基本要求是即使在卫星导航或摄像头不可用的情况下也能进行精确导航。在这些实际情况下，仅依靠惯性传感器会导致导航解决方案漂移，这是由于传感器固有的噪声和误差项造成的。缓解漂移的一种新兴解决方案是让机器人进行蛇形滑动运动，以提高惯性信噪比，从而实现移动机器人位置的回归。在这项工作中，我们提出了MoRPI-PINN，作为一个物理信息神经网络框架，用于精确的基于惯性的移动机器人导航。通过在训练过程中嵌入物理定律和约束，MoRPI-PINN能够提供准确和鲁棒的导航解决方案。通过真实世界实验，我们展示了相比其他方法超过85%的精度提升。MoRPI-PINN是一种轻量级方法，甚至可以在边缘设备上实现，并用于任何典型的移动机器人应用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [588] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
> *手术环境中面部特征点定位性能评估*

*Ines Frajtag, Marko Švaco, Filip Šuligoj* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 面部特征点, MediaPipe, 手术环境, 计算机视觉, 机器人

**Comment:** 

> **TL;DR:** 本研究评估了MediaPipe算法在模拟手术环境下进行面部特征点定位的性能，发现其在手术光照下能显著提高在大偏航角和俯仰角时的检测精度，并探讨了其在医疗程序中的应用潜力。

**AI_Comments:** 本文创新性地在一个受控的手术模拟环境中评估了MediaPipe算法，这对于将计算机视觉技术应用于实际医疗场景具有重要意义。研究明确指出了算法在特定光照和角度下的性能提升，同时也坦诚了检测精度方面的局限性，为未来的改进提供了方向。其潜在的应用价值在于提高手术中患者定位的精确性。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗领域应用机器人和计算机视觉时，面部检测算法面临光照条件变化和检测位置灵活性的挑战，这使得精确识别和定位患者变得困难。本研究旨在评估MediaPipe算法在这些挑战下进行面部特征点定位的性能。

**Method:** 实验在一个受控环境中进行，使用机械臂自动调整位置，同时手术灯和人体模型保持固定。研究测试了MediaPipe算法用于检测面部特征点。

**Result:** 研究结果表明，在手术光照下，面部特征点检测的准确性提高，显著增强了在大偏航角和俯仰角时的检测性能。然而，由于某些选定面部特征点检测的不精确，导致标准差/离散度增加。

**Conclusion:** 本分析表明MediaPipe算法有潜力集成到医疗程序中，尤其是在手术环境中进行面部特征点定位。

> **ai_Abstract:** 本研究评估了MediaPipe算法在模拟手术环境中的面部特征点定位性能，以解决变光照和位置灵活性带来的挑战。实验在受控条件下进行，结果显示在手术光照下，该算法能显著提高在大偏航角和俯仰角下的检测精度。尽管存在某些特征点检测不精确导致离散度增加的问题，但研究仍指出MediaPipe算法在医疗程序中具有潜在的应用价值。

> **摘要翻译:** 机器人技术、计算机视觉及其应用在包括医学在内的各个领域正变得越来越广泛。许多人脸检测算法已在神经外科、眼科和整形外科中找到应用。使用这些算法的一个常见挑战是可变的光照条件和检测位置的灵活性，以识别和精确地定位患者。所提出的实验在受控环境中测试了MediaPipe算法检测面部特征点，使用机械臂自动调整位置，而手术灯和人体模型保持固定。本研究结果表明，手术光照下面部特征点检测精度的提高显著增强了在大偏航角和俯仰角时的检测性能。标准差/离散度的增加是由于选定面部特征点检测不精确所致。这项分析允许讨论MediaPipe算法潜在地集成到医疗程序中。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [589] [B4P: Simultaneous Grasp and Motion Planning for Object Placement via Parallelized Bidirectional Forests and Path Repair](https://arxiv.org/abs/2504.04598)
> *B4P：通过并行双向森林和路径修复实现物体放置的同步抓取和运动规划*

*Benjamin H. Leebron, Kejia Ren, Yiting Chen, Kaiyu Hang* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 机器人抓取, 运动规划, 物体放置, 双向森林, 并行化

**Comment:** 

> **TL;DR:** 本文提出了B4P框架，通过并行双向森林同步规划抓取和运动，解决机器人抓取放置中的次优性问题，提高在复杂环境中的效率。

**AI_Comments:** 该论文的创新点在于提出了一个并行化的双向森林框架B4P，用于同步解决机器人抓取和运动规划问题，而非传统的解耦方法。这种集成方法有效克服了次优性问题，尤其是在复杂和狭窄环境中，提高了机器人放置任务的效率和鲁棒性。其并行性带来的超线性加速是一个显著的优势，使得该方法在实际应用中更具吸引力，特别是对于高自由度机械臂。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器人拾取和放置系统将抓取、放置和运动规划解耦，导致次优性，特别是在杂乱且有狭窄通道的环境中，抓取选择可能限制或禁止机器人达到目标放置姿态的可行运动。

**Method:** 提出了一个基于森林的规划框架B4P，利用双向采样方法构建起始森林（根植于可行抓取区域）和目标森林（根植于可行放置区域），通过随机探索连接有效抓取和放置树的运动。该框架的并行性实现了超线性加速。

**Result:** 模拟实验证明，所提出的框架在与多种基线在不同场景下比较时，表现出鲁棒性和效率。它能够使冗余机械臂（如7自由度）在高度杂乱的环境中高效工作，并实现超线性加速。

**Conclusion:** B4P框架通过同步抓取和运动规划，克服了传统解耦方法的局限性，显著提高了机器人在复杂环境中的放置效率和鲁棒性。

> **ai_Abstract:** 本文提出了B4P，一个用于机器人物体放置的同步抓取和运动规划的森林框架。针对传统解耦方法在复杂环境中导致次优性的问题，B4P利用并行双向森林（分别从抓取和放置区域出发）来同时寻找最佳抓取配置和机器人运动。实验证明，该框架在杂乱环境中具有出色的鲁棒性和效率，并能实现超线性加速，尤其适用于冗余机械臂。

> **摘要翻译:** 机器人拾取和放置系统传统上将抓取、放置和运动规划解耦，以构建顺序优化管道，并假设各个组件能够协同工作。然而，这种分离引入了次优性，因为抓取选择可能会限制甚至禁止机器人达到目标放置姿态的可行运动，特别是在具有狭窄通道的杂乱环境中。为此，我们提出了一个基于森林的规划框架，以同步找到抓取配置和可行的机器人运动，这些运动明确满足与所选抓取配对的下游放置配置。我们提出的框架利用双向采样方法来构建一个起始森林，其根植于可行抓取区域，以及一个目标森林，其根植于可行放置区域，以促进通过随机探索连接有效抓取和放置树的运动进行搜索。我们证明了该框架固有的并行性能够实现超线性加速，使其可扩展用于冗余机械臂（例如7自由度）在高度杂乱的环境中高效工作的应用。在模拟中的大量实验证明了所提出框架在与多种基线在不同场景下比较时的鲁棒性和效率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [612] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
> *ReSem3D：通过细粒度语义接地实现可泛化机器人操作的可精炼3D空间约束*

*Chenyu Su, Weiwei Shang, Chen Qian, Fei Zhang, Shuang Cong* | **Category: cs.RO, cs.AI, cs.CV, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 机器人操作, 3D空间约束, 语义接地, 多模态大语言模型, 视觉基础模型

**Comment:** 12 pages,9 figures

> **TL;DR:** ReSem3D利用MLLM和VFM实现细粒度语义3D空间约束，以提高机器人操作在语义多样环境中的实时性和泛化能力。

**AI_Comments:** ReSem3D的创新点在于其引入的细粒度语义接地和动态构建分层3D空间约束的能力，这显著提升了机器人操作在复杂和语义多样环境中的性能。通过结合MLLMs和VFMs的协同推理，该方法有效地弥补了现有方法在语义理解和实时规划方面的不足，为实现更通用和鲁棒的机器人操作提供了新的范式。其在零样本条件下的表现尤为突出，预示着该技术在实际部署中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人操作方法在3D空间约束建模方面存在三个主要限制：语义粒度粗糙、缺乏实时闭环规划以及在语义多样环境中鲁棒性差。

**Method:** ReSem3D是一个统一的机器人操作框架，利用多模态大语言模型（MLLMs）和视觉基础模型（VFMs）的协同作用。它通过MLLM中的分层递归推理，与VFM交互，从自然语言指令和RGB-D观测中自动构建3D空间约束，分为部件级提取和区域级精炼两个阶段。这些约束随后被编码为关节空间中的实时优化目标，以实现对动态扰动的反应行为。

**Result:** 在语义丰富的家庭环境和稀疏的化学实验室环境中进行的广泛模拟和真实世界实验表明，ReSem3D在零样本条件下执行了多样化的操作任务，表现出强大的适应性和泛化能力。

**Conclusion:** ReSem3D通过其细粒度语义接地和动态构建的分层3D空间约束，显著提升了机器人在语义多样环境中的操作能力，实现了实时、鲁棒且泛化性强的机器人操作。

> **ai_Abstract:** ReSem3D是一个新颖的机器人操作框架，旨在解决现有方法在语义粒度、实时规划和环境鲁棒性方面的不足。它通过结合多模态大语言模型（MLLMs）和视觉基础模型（VFMs），实现了细粒度的视觉接地和分层3D空间约束的动态构建。该框架利用MLLM的分层递归推理，从自然语言和视觉输入中生成约束，并将其转化为实时优化目标。实验证明，ReSem3D在零样本条件下能有效执行多样化操作任务，展现出卓越的适应性和泛化能力。

> **摘要翻译:** 语义驱动的3D空间约束将高级语义表示与低级动作空间对齐，促进了机器人操作中任务理解和执行的统一。多模态大语言模型（MLLMs）和视觉基础模型（VFMs）的协同推理使得跨模态3D空间约束的构建成为可能。然而，现有方法存在三个主要局限性：（1）约束建模中的语义粒度粗糙，（2）缺乏实时闭环规划，（3）在语义多样环境中鲁棒性受损。为了解决这些挑战，我们提出了ReSem3D，一个用于语义多样环境的统一操作框架，利用VFM和MLLM之间的协同作用，实现细粒度视觉接地，并动态构建分层3D空间约束以实现实时操作。具体而言，该框架由MLLM中的分层递归推理驱动，MLLM与VFM交互，通过两个阶段（部件级提取和区域级精炼）从自然语言指令和RGB-D观测中自动构建3D空间约束。随后，这些约束被编码为关节空间中的实时优化目标，从而能够对动态扰动产生反应行为。在语义丰富的家庭和稀疏的化学实验室环境中进行了广泛的模拟和真实世界实验。结果表明，ReSem3D在零样本条件下执行了多样化的操作任务，表现出强大的适应性和泛化能力。代码和视频可在https://resem3d.github.io获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [631] [Target Tracking via LiDAR-RADAR Sensor Fusion for Autonomous Racing](https://arxiv.org/abs/2505.20043)
> *自动驾驶赛车中基于激光雷达-雷达传感器融合的目标跟踪*

*Marcello Cellina, Matteo Corno, Sergio Matteo Savaresi* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 激光雷达-雷达融合, 目标跟踪, 自动驾驶赛车, 传感器融合, 扩展卡尔曼滤波器

**Comment:** IEEE Conference, 6 pages

> **TL;DR:** 该研究开发了一种融合激光雷达和雷达数据的低延迟扩展卡尔曼滤波器（EKF）多目标跟踪算法，成功应用于自动驾驶赛车，实现了高达275公里/小时的高速自主超车。

**AI_Comments:** 该研究的创新之处在于其对LiDAR-RADAR传感器融合的深度利用，特别是通过整合距离速率和赛道先验知识来优化EKF性能。算法对乱序测量和传感器延迟的处理机制也提升了其在实际高动态环境下的鲁棒性。在275公里/小时高速下成功完成自主超车验证了其在自动驾驶领域，尤其是在竞技和高性能应用中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高高速多车自动驾驶赛车的安全性和性能，需要从移动平台上进行精确的车辆检测和动态估计，以规划和执行复杂的自主超车机动。

**Method:** 开发了一种基于延迟感知扩展卡尔曼滤波器（EKF）的多目标跟踪算法，融合了激光雷达和雷达测量数据。该算法通过在EKF测量函数中明确整合距离速率，并利用赛道先验知识进行状态预测，从而利用了不同传感器的特性。它通过使用双状态和测量缓冲区进行重处理，处理乱序测量，确保传感器延迟补偿且无信息丢失。

**Result:** 该算法已在PoliMOVE车队的自动赛车上实现，并通过完成多次最高时速275公里/小时的完全自主超车机动进行了实验验证。

**Conclusion:** 所开发的激光雷达-雷达融合多目标跟踪算法能够有效支持高速自动驾驶赛车中的精确目标跟踪和超车操作。

> **ai_Abstract:** 本文提出了一种用于高速自动驾驶赛车的延迟感知多目标跟踪算法。该算法融合了激光雷达和雷达数据，利用扩展卡尔曼滤波器（EKF）框架，并特别整合了距离速率信息和赛道先验知识。为解决传感器延迟和乱序测量问题，算法采用了双缓冲区重处理机制。该系统已成功部署在自主赛车上，并在高达275公里/小时的速度下完成了自主超车任务，验证了其在复杂高动态环境下的有效性。

> **摘要翻译:** 高速多车自动驾驶赛车将提高公路自动驾驶车辆的安全性和性能。从移动平台上精确的车辆检测和动态估计是规划和执行复杂自主超车机动的关键要求。为了满足这一要求，我们开发了一种延迟感知、基于扩展卡尔曼滤波器（EKF）的多目标跟踪算法，该算法融合了激光雷达和雷达的测量数据。该算法通过在EKF测量函数中明确整合距离速率，以及在状态预测期间利用赛道先验知识，从而利用了不同传感器的特性。它可以通过使用双状态和测量缓冲区进行重处理来处理乱序测量，确保传感器延迟补偿且无信息丢失。该算法已在PoliMOVE车队的自动赛车上实现，并通过完成多次最高时速275公里/小时的完全自主超车机动进行了实验验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [637] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
> *基于基础模型推理和部件接地的自适应铰接物体实时操作*

*Xiaojie Zhang, Yuanfei Wang, Ruihai Wu, Kunqi Xu, Yu Li, Liuyu Xiang, Hao Dong, Zhaofeng He* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 铰接物体操作, 基础模型, 部件接地, 自适应操作, 泛化能力

**Comment:** ICCV 2025

> **TL;DR:** AdaRPG是一个新颖的框架，利用基础模型提取物体部件并进行推理，以实现对铰接物体的自适应操作，并在模拟和现实世界中展现出强大的泛化能力。

**AI_Comments:** 本文的创新点在于将基础模型引入到铰接物体操作中，通过“部件接地”的概念有效地解决了物体几何多样性带来的视觉感知和理解难题。利用基础模型的常识推理复杂机制，也为开发统一的自适应操作策略提供了新的思路。该方法展现出的强大泛化能力对于机器人处理未知铰接物体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 铰接物体对机器人操作构成多样化挑战，其内部结构不可直接观测，且现有方法在跨类别泛化方面面临几何多样性和功能机制变化的挑战，难以开发统一的自适应操作策略。

**Method:** 本文提出了AdaRPG框架，利用基础模型提取物体部件，因为部件比整个物体具有更大的局部几何相似性，从而增强了功能性基本技能的视觉可供性泛化。为此，构建了一个部件级别的可供性标注数据集来训练可供性模型。此外，AdaRPG利用基础模型中嵌入的常识来推理复杂的机制，并根据部件可供性推理生成调用基本技能功能的高级控制代码。

**Result:** 模拟和真实世界的实验表明，AdaRPG在新的铰接物体类别上具有强大的泛化能力。

**Conclusion:** AdaRPG通过利用基础模型进行部件接地和推理，有效地解决了铰接物体自适应操作的挑战，展现出强大的泛化能力。

> **ai_Abstract:** 本文提出了AdaRPG框架，旨在解决铰接物体操作中几何多样性和功能机制复杂性带来的挑战。AdaRPG利用基础模型提取物体部件，这些部件具有更高的局部几何相似性，从而增强了视觉可供性泛化。通过构建部件级可供性数据集和利用基础模型的常识推理复杂机制，AdaRPG能够生成高级控制代码。实验证明，该框架在模拟和真实世界中对新型铰接物体类别具有强大的泛化能力。

> **摘要翻译:** 铰接物体对机器人构成多样化的操作挑战。由于其内部结构无法直接观测，机器人必须自适应地探索和完善动作以生成成功的操作轨迹。尽管现有工作已尝试在自适应铰接物体操作中实现跨类别泛化，但两大主要挑战依然存在：(1) 真实世界铰接物体的几何多样性使视觉感知和理解复杂化；(2) 物体功能和机制的变异阻碍了统一自适应操作策略的开发。为了解决这些挑战，我们提出了AdaRPG，一个新颖的框架，它利用基础模型来提取物体部件，这些部件比整个物体表现出更大的局部几何相似性，从而增强了功能性基本技能的视觉可供性泛化能力。为了支持这一点，我们构建了一个部件级别的可供性标注数据集来训练可供性模型。此外，AdaRPG利用基础模型中嵌入的常识来推理复杂的机制，并根据部件可供性推理生成调用基本技能功能的高级控制代码。模拟和真实世界的实验证明了AdaRPG在新的铰接物体类别上强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [672] [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://arxiv.org/abs/2507.18317)
> *AF-RLIO: 恶劣环境下雷达-激光雷达-惯性信息自适应融合的鲁棒里程计*

*Chenglong Qian, Yang Xu, Xiufang Shi, Jiming Chen, Liang Li* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 雷达-激光雷达融合, 里程计, 自适应融合, 鲁棒导航, 挑战性环境

**Comment:** 

> **TL;DR:** AF-RLIO通过自适应融合雷达、激光雷达、IMU和GPS数据，解决了复杂恶劣环境下机器人导航中单传感器系统性能下降的问题，实现了鲁棒的里程计估计。

**AI_Comments:** 该论文的创新点在于提出了一种自适应的多传感器融合策略，特别是在预处理阶段利用雷达数据辅助激光雷达处理动态障碍物和恶劣环境，这对于提升单传感器在复杂条件下的鲁棒性至关重要。其方法结合了雷达、激光雷达、IMU和GPS的优势，通过迭代误差状态卡尔曼滤波和因子图优化实现紧耦合和全局优化，有效解决了传统单传感器系统在挑战性环境下的性能瓶颈。该研究对于自主机器人在真实复杂环境中的可靠导航具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人导航中，复杂动态环境下保持精确的姿态估计和导航至关重要。然而，烟雾、隧道和恶劣天气等环境挑战会显著降低激光雷达或GPS等单传感器系统的性能，从而影响自主机器人的整体稳定性与安全性。为解决这些挑战，本文提出了AF-RLIO。

**Method:** 本文提出了AF-RLIO，一种自适应融合方法，集成了4D毫米波雷达、激光雷达、惯性测量单元（IMU）和GPS，以利用这些传感器的互补优势，在复杂环境中进行鲁棒的里程计估计。该方法包含三个关键模块：1. 预处理模块：利用雷达数据辅助激光雷达去除动态点，并判断激光雷达环境条件是否恶化。2. 动态感知多模态里程计：选择合适的点云数据进行扫描到地图匹配，并使用迭代误差状态卡尔曼滤波器与IMU紧密耦合。3. 因子图优化模块：平衡里程计和GPS数据之间的权重，构建姿态图进行优化。

**Result:** 所提出的方法已在数据集上进行评估，并在真实机器人环境中进行了测试，在烟雾和隧道等挑战性条件下，证明了其有效性以及相对于现有方法的优势。

**Conclusion:** AF-RLIO通过自适应融合多种传感器数据，能够在复杂和恶劣的环境中提供鲁棒的里程计估计，显著提升了机器人导航的稳定性和安全性，优于现有方法。

> **ai_Abstract:** 本文提出了AF-RLIO，一种针对复杂恶劣环境的自适应多传感器融合里程计方法。它融合了雷达、激光雷达、IMU和GPS数据，通过预处理模块利用雷达辅助激光雷达处理动态和恶劣环境，动态感知多模态里程计模块进行点云匹配和IMU紧耦合，以及因子图优化模块平衡里程计和GPS权重。实验证明，该方法在烟雾和隧道等挑战性条件下，相比现有方法具有更高的鲁棒性和有效性，显著提升了机器人导航的稳定性和安全性。

> **摘要翻译:** 在机器人导航中，在复杂动态环境中保持精确的姿态估计和导航至关重要。然而，烟雾、隧道和恶劣天气等环境挑战会显著降低激光雷达或GPS等单传感器系统的性能，从而影响自主机器人的整体稳定性和安全性。为了解决这些挑战，我们提出了AF-RLIO：一种自适应融合方法，它集成了4D毫米波雷达、激光雷达、惯性测量单元（IMU）和GPS，以利用这些传感器的互补优势，在复杂环境中进行鲁棒的里程计估计。我们的方法由三个关键模块组成。首先，预处理模块利用雷达数据辅助激光雷达去除动态点，并确定激光雷达环境条件何时恶化。其次，动态感知多模态里程计选择合适的点云数据进行扫描到地图匹配，并使用迭代误差状态卡尔曼滤波器将其与IMU紧密耦合。最后，因子图优化模块平衡里程计和GPS数据之间的权重，构建姿态图进行优化。所提出的方法已在数据集上进行评估，并在真实机器人环境中进行了测试，证明了其在烟雾和隧道等挑战性条件下相对于现有方法的有效性和优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [673] [Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections](https://arxiv.org/abs/2506.16685)
> *柔顺残差DAgger：通过人类修正改进真实世界接触密集型操作*

*Xiaomeng Xu, Yifan Hou, Zeyi Liu, Shuran Song* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-24**

**Keywords:** DAgger, 机器人操作, 人类修正, 柔顺控制, 残差学习

**Comment:** 

> **TL;DR:** 提出CR-DAgger，通过柔顺干预界面和柔顺残差策略，利用人类修正数据显著提升机器人接触密集型操作性能。

**AI_Comments:** 这篇论文的创新点在于提出了“柔顺干预界面”和“柔顺残差策略”，解决了DAgger在真实世界机器人操作中数据收集和利用的实际难题。允许人类在不中断机器人运行的情况下进行“柔顺”修正，这对于提高数据效率和安全性至关重要。结合力反馈和残差学习也增强了方法的鲁棒性，使其在接触密集型任务中表现出色。其实验结果（成功率提升50%以上）显示了其显著的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决真实世界接触密集型操作中DAgger的两个关键挑战：如何收集信息丰富的人类修正数据以及如何有效地用这些新数据更新策略。

**Method:** 引入了柔顺残差DAgger (CR-DAgger)，包含两个新颖组件：1) 柔顺干预界面，利用柔顺控制，允许人类提供轻柔、准确的delta动作修正，而不中断机器人策略执行；2) 柔顺残差策略公式，从人类修正中学习，并结合力反馈和力控制。

**Result:** 在精确接触密集型操作任务中，使用最少的修正数据显著提高性能，在两个具有挑战性的任务（翻书和皮带组装）上，基础策略成功率提高了50%以上，并且优于从头开始重新训练和微调方法。

**Conclusion:** CR-DAgger通过有效的人类修正数据收集和策略更新机制，显著提升了机器人进行真实世界接触密集型操作的性能，并为DAgger的实际应用提供了指导。

> **ai_Abstract:** 本文提出了柔顺残差DAgger（CR-DAgger），旨在解决真实世界接触密集型操作中高效收集和利用人类修正数据的挑战。CR-DAgger结合了柔顺干预界面，使人类能在不中断机器人执行的情况下提供精确修正，以及柔顺残差策略，该策略能从修正中学习并整合力反馈。实验证明，CR-DAgger能以极少量修正数据显著提升接触密集型任务的成功率，并优于传统方法。

> **摘要翻译:** 我们解决了真实世界接触密集型操作中数据集聚合（DAgger）的关键挑战：如何收集信息丰富的人类修正数据以及如何有效地用这些新数据更新策略。我们引入了柔顺残差DAgger（CR-DAgger），它包含两个新颖的组件：1）一个柔顺干预界面，利用柔顺控制，允许人类提供轻柔、准确的增量动作修正，而不会中断正在进行的机器人策略执行；2）一个柔顺残差策略公式，该公式从人类修正中学习，同时结合力反馈和力控制。我们的系统使用最少的修正数据，显著增强了精确接触密集型操作任务的性能，在两个具有挑战性的任务（翻书和皮带组装）上，将基础策略的成功率提高了50%以上，同时优于从头开始重新训练和微调方法。通过大量的真实世界实验，我们为在真实世界机器人学习任务中实施有效的DAgger提供了实用指导。结果视频可在以下网址观看：https://compliant-residual-dagger.github.io/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [709] [G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM](https://arxiv.org/abs/2507.18344)
> *G2S-ICP SLAM：几何感知高斯泼溅ICP SLAM*

*Gyuhyeon Pak, Hae Min Cho, Euntai Kim* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** SLAM, Gaussian Splatting, ICP, RGB-D, 3D Reconstruction

**Comment:** 8 pages, 6 figures

> **TL;DR:** G2S-ICP SLAM系统通过表面对齐的高斯盘实现实时高保真3D重建和鲁棒相机位姿跟踪，性能优于现有系统。

**AI_Comments:** 该论文的创新点在于引入了几何感知的2D高斯盘表示来建模局部表面，相比传统的3D椭球表示，它能提供更一致的深度解释。同时，该方法将这种新颖的表示无缝集成到广义ICP框架中，并通过结合几何感知损失进一步提升了系统的整体性能，实现了实时高保真重建和定位。这对于需要高精度和实时性的SLAM应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决传统3D椭球表示在多视角深度解释中存在的不一致性问题，并实现高保真3D重建和鲁棒的相机位姿跟踪，本文提出了一种新的几何感知表示方法。

**Method:** 提出G2S-ICP SLAM系统。该方法通过将每个场景元素表示为受限于局部切平面的高斯分布，有效地将局部表面建模为与底层几何对齐的2D高斯盘。这种表示被嵌入到广义ICP框架中，通过引入各向异性协方差先验，同时不改变底层配准公式。此外，引入了一个几何感知损失来监督光度、深度和法线一致性。

**Result:** 在Replica和TUM-RGBD数据集上的大量实验表明，G2S-ICP SLAM在定位精度、重建完整性方面优于先前的SLAM系统，同时保持了渲染质量。系统实现了实时操作，并保持了视觉和几何保真度。

**Conclusion:** G2S-ICP SLAM通过引入创新的几何感知2D高斯盘表示和优化的ICP框架，成功实现了实时、高保真的3D重建和鲁棒的相机位姿跟踪，并在多项性能指标上超越了现有系统。

> **ai_Abstract:** G2S-ICP SLAM是一种新颖的几何感知RGB-D SLAM系统，它通过将场景元素表示为受限于局部切平面的2D高斯盘，实现了实时高保真3D重建和鲁棒的相机位姿跟踪。该方法通过引入各向异性协方差先验将这种表示嵌入到广义ICP框架中，并结合了监督光度、深度和法线一致性的几何感知损失。实验证明，G2S-ICP SLAM在定位精度、重建完整性和渲染质量方面优于现有SLAM系统。

> **摘要翻译:** 在本文中，我们提出了一种新颖的几何感知RGB-D高斯泼溅SLAM系统，命名为G2S-ICP SLAM。所提出的方法通过使用受限于局部切平面的高斯分布来表示每个场景元素，从而实现实时高保真3D重建和鲁棒的相机位姿跟踪。与传统的基于3D椭球的各向同性不确定性表示相比，这有效地将局部表面建模为与底层几何对齐的2D高斯盘，从而在多个视角下实现更一致的深度解释。为了将这种表示集成到SLAM管线中，我们通过引入各向异性协方差先验，将表面对齐的高斯盘嵌入到广义ICP框架中，而无需改变底层的配准公式。此外，我们提出了一种几何感知损失，用于监督光度、深度和法线一致性。我们的系统实现了实时操作，同时保持了视觉和几何保真度。在Replica和TUM-RGBD数据集上的大量实验表明，G2S-ICP SLAM在定位精度、重建完整性方面优于先前的SLAM系统，同时保持了渲染质量。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [717] [Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model](https://arxiv.org/abs/2507.06174)
> *快速双边遥操作和模仿学习：通过精确动力学模型实现无力传感器力控制*

*Koki Yamane, Yunhan Li, Masashi Konosu, Koki Inami, Junji Oaki, Sho Sakaino, Toshiaki Tsuji* | **Category: cs.RO, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 双边遥操作, 无力传感器控制, 模仿学习, 动力学模型, 力反馈

**Comment:** 20 pages, 9 figures, Submitted to CoRL 2025

> **TL;DR:** 本文展示了即使对于无力传感器的低成本机械臂，也能通过精确的动力学模型和四通道双边控制实现快速带力反馈的遥操作，并提升模仿学习性能。

**AI_Comments:** 这项研究的创新点在于，即使在缺乏昂贵力传感器的情况下，也能通过精确的动力学模型和巧妙的控制策略（如四通道双边控制、非线性补偿和状态估计）实现高保真度的力反馈遥操作。这显著降低了实现高级机器人操作的硬件成本，使得模仿学习的数据收集更加经济可行，对于推动机器人技术在更广泛领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有低成本机械臂遥操作系统多采用单边控制，仅传输目标位置，易于实现但缺乏力反馈，难以应对快速或接触丰富的任务。

**Method:** 本文利用四通道双边控制，即使对于无力传感器的低成本机械臂也能实现带力反馈的快速遥操作。该方法基于精确识别的机械臂动力学模型，整合了非线性项补偿、速度和外力估计以及对应惯量变化的变增益。此外，利用四通道双边控制收集的数据，将力信息整合到学习策略的输入和输出中。

**Result:** 实现了即使对于无力传感器的低成本机械臂也能进行带力反馈的快速遥操作。通过将力信息整合到学习策略的输入和输出中，显著提升了模仿学习的性能。

**Conclusion:** 本系统在经济实惠的硬件上实现了高保真遥操作和数据收集，证明了其在实际应用中的有效性。

> **ai_Abstract:** 本文提出了一种使用精确动力学模型实现无力传感器力控制的快速双边遥操作方法，适用于低成本机械臂。通过四通道双边控制，结合非线性补偿、速度与外力估计及变增益，实现了带力反馈的快速遥操作。研究还表明，将力信息纳入模仿学习策略的输入输出能有效提升性能，为经济硬件上的高保真遥操作和数据收集提供了实用解决方案。

> **摘要翻译:** 近年来，模仿学习的进步使得人们对遥操作低成本机械臂以收集演示数据越来越感兴趣。然而，大多数现有系统依赖于单边控制，仅传输目标位置值。虽然这种方法易于实现且适用于缓慢、非接触任务，但由于缺乏力反馈，它在快速或接触丰富的操作中表现不佳。这项工作表明，即使对于无力传感器的低成本机械臂，通过利用四通道双边控制，实现带力反馈的快速遥操作也是可行的。基于精确识别的机械臂动力学，我们的方法整合了非线性项补偿、速度和外力估计以及对应惯量变化的变增益。此外，利用四通道双边控制收集的数据，我们展示了将力信息整合到学习策略的输入和输出中可以提高模仿学习的性能。这些结果突出了我们系统在高保真遥操作和经济实惠硬件上数据收集的实际有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [751] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
> *残差Koopman模型预测控制：以小量赛道数据输入提升车辆动力学性能*

*Yonghao Fu, Cheng Hu, Haokun Xiong, Zhangpeng Bao, Wenyuan Du, Edoardo Ghignone, Michele Magno, Lei Xie, Hongye Su* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 残差Koopman, 模型预测控制, 车辆动力学, 轨迹跟踪, 数据效率

**Comment:** 

> **TL;DR:** 本文提出了一种名为残差Koopman模型预测控制（RKMPC）的新方法，它结合了线性MPC和神经网络来提高车辆轨迹跟踪的性能，减少了对大量训练数据的需求，并在仿真和实际车辆上验证了其优于传统方法的性能。

**AI_Comments:** 这项工作在结合传统模型预测控制与数据驱动的残差建模方面具有创新性，有效解决了非线性系统建模的挑战，并大幅减少了对训练数据的需求，这对于实际应用具有重要意义。其双MPC架构的设计思路巧妙，既保留了传统模型的可靠性，又利用神经网络提升了性能，实现了良好的平衡。在数据效率和性能提升方面取得了显著成果。

<details>
  <summary>Details</summary>

**Motivation:** 在车辆轨迹跟踪任务中，Pure Pursuit (PP) 控制虽然简单但未能考虑车辆模型约束，影响驾驶安全。模型预测控制 (MPC) 依赖于精确的车辆建模，但传统建模方法在捕捉非线性动力学和计算效率之间存在固有的权衡，导致控制性能下降。为了解决这些挑战，本文提出了RKMPC框架。

**Method:** 本文提出了残差Koopman模型预测控制（RKMPC）框架。该方法采用双线性MPC架构来计算控制输入：一个线性模型预测控制（LMPC）基于车辆运动学模型计算基线控制输入，一个基于神经网络的RKMPC计算补偿输入。最终的控制命令通过将这两个分量相加获得。这种设计保留了传统机械模型的可靠性和可解释性，同时通过残差建模实现性能优化。

**Result:** RKMPC方法在Carsim-Matlab联合仿真平台和1:10比例的F1TENTH赛车上进行了验证。实验结果表明，RKMPC仅需要传统Koopman模型预测控制（KMPC）20%的训练数据，同时提供卓越的跟踪性能。与传统LMPC相比，RKMPC将横向误差减少了11.7%-22.1%，将航向误差减少了8.9%-15.8%，并将前轮转向稳定性提高了高达27.6%。

**Conclusion:** 残差Koopman模型预测控制（RKMPC）通过结合线性MPC和神经网络补偿，有效解决了车辆轨迹跟踪中传统方法的局限性，实现了在小量数据输入下优越的跟踪性能和稳定性提升，同时保持了模型的可解释性。

> **ai_Abstract:** 本文提出了一种名为残差Koopman模型预测控制（RKMPC）的新框架，用于解决车辆轨迹跟踪中传统MPC建模的挑战。RKMPC结合了基于车辆运动学模型的线性MPC（LMPC）和基于神经网络的残差补偿，以优化控制性能并保持模型可解释性。该方法在仿真和1:10比例的F1TENTH赛车上进行了验证，结果表明，与传统方法相比，RKMPC在仅需20%训练数据的情况下，显著提升了跟踪性能，包括减少横向误差和航向误差，并改善了转向稳定性。

> **摘要翻译:** 在车辆轨迹跟踪任务中，最简单的方法是Pure Pursuit（PP）控制。然而，这种单点预瞄跟踪策略未能考虑车辆模型约束，从而影响了驾驶安全。模型预测控制（MPC）作为一种广泛采用的控制方法，通过结合机械模型和物理约束来优化控制动作。然而，其控制性能关键取决于车辆建模的准确性。传统的车辆建模方法在捕捉非线性动力学和保持计算效率之间面临固有的权衡，这通常会导致控制性能下降。为了应对这些挑战，本文提出了一种残差Koopman模型预测控制（RKMPC）框架。该方法使用两个线性MPC架构来计算控制输入：一个线性模型预测控制（LMPC）根据车辆运动学模型计算基线控制输入，一个基于神经网络的RKMPC计算补偿输入。最终的控制命令通过将这两个分量相加获得。这种设计保留了传统机械模型的可靠性和可解释性，同时通过残差建模实现性能优化。该方法已在Carsim-Matlab联合仿真平台和物理1:10比例的F1TENTH赛车上进行了验证。实验结果表明，RKMPC仅需要传统Koopman模型预测控制（KMPC）20%的训练数据，同时提供卓越的跟踪性能。与传统LMPC相比，RKMPC将横向误差减少了11.7%-22.1%，将航向误差减少了8.9%-15.8%，并将前轮转向稳定性提高了高达27.6%。实现代码可在以下网址获取：https://github.com/ZJU-DDRX/Residual Koopman。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [5] [Captain Cinema: Towards Short Movie Generation](https://arxiv.org/abs/2507.18634)
> *电影船长：迈向短电影生成*

*Junfei Xiao, Ceyuan Yang, Lvmin Zhang, Shengqu Cai, Yang Zhao, Yuwei Guo, Gordon Wetzstein, Maneesh Agrawala, Alan Yuille, Lu Jiang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 短电影生成, 电影船长, 关键帧规划, 视频合成, 多模态扩散Transformer

**Comment:** Under review. Project page: https://thecinema.ai

> **TL;DR:** 提出名为“电影船长”的生成框架，用于根据文本描述生成视觉连贯、叙事一致的高质量短电影，通过分层规划和视频合成实现。

**AI_Comments:** 该论文提出了一个新颖的分层电影生成框架“电影船长”，通过结合关键帧规划和视频合成，有效解决了长程连贯性在电影生成中的挑战。其引入的MM-DiT交错训练策略对于处理长上下文视频数据具有创新性，有望推动AI电影创作领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决根据详细文本描述自动生成视觉连贯且叙事一致的短电影的挑战。

**Method:** 本研究提出了“电影船长”框架。首先，它通过“自上而下的关键帧规划”根据电影故事情节的文本描述生成一系列关键帧，以确保长程连贯性。然后，这些关键帧作为“自下而上的视频合成”步骤的条件信号，由支持长上下文学习的视频合成模型生成时空动态。为支持多场景长叙事电影作品的稳定高效生成，引入了一种针对多模态扩散Transformer（MM-DiT）的交错训练策略，并在专门策划的电影数据集上进行训练。

**Result:** 实验表明，“电影船长”在自动创建高质量、高效率的视觉连贯和叙事一致的短电影方面表现出色。

**Conclusion:** “电影船长”框架能够有效地根据文本描述生成高质量、连贯的短电影。

> **ai_Abstract:** “电影船长”是一个新颖的短电影生成框架。它以详细文本描述为输入，首先通过“自上而下的关键帧规划”生成关键帧序列以确保叙事和视觉连贯性，然后通过“自下而上的视频合成”利用这些关键帧作为条件信号生成视频的时空动态。为支持长叙事作品，该框架引入了多模态扩散Transformer（MM-DiT）的交错训练策略。实验证明，“电影船长”能高效生成高质量、视觉和叙事一致的短电影。

> **摘要翻译:** 我们提出了“电影船长”，一个用于短电影生成的框架。给定一个详细的电影故事情节文本描述，我们的方法首先生成一系列关键帧，勾勒出整个叙事，这确保了故事情节和视觉外观（例如，场景和角色）的长程连贯性。我们将此步骤称为自上而下的关键帧规划。然后，这些关键帧作为视频合成模型的条件信号，该模型支持长上下文学习，以生成它们之间的时空动态。此步骤被称为自下而上的视频合成。为了支持多场景长叙事电影作品的稳定高效生成，我们引入了一种针对多模态扩散Transformer（MM-DiT）的交错训练策略，专门用于长上下文视频数据。我们的模型在一个专门策划的由交错数据对组成的电影数据集上进行训练。我们的实验表明，“电影船长”在自动化创建高质量、高效率的视觉连贯和叙事一致的短电影方面表现出色。项目页面：https://thecinema.ai

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [6] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
> *重新思考FER中的遮挡：一个语义感知的视角及超越*

*Huiyu Zhai, Xingxing Yang, Yalan Ye, Chenyang Li, Bin Fan, Changze Li* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 面部表情识别, 遮挡, 语义引导, 多模态, 数据集

**Comment:** 

> **TL;DR:** ORSANet通过引入多模态语义引导（语义分割图和面部关键点）和动态对抗排斥增强损失（DARELoss），以及构建首个遮挡导向的FER数据集Occlu-FER，显著提升了遮挡场景下的面部表情识别（FER）性能。

**AI_Comments:** 这篇论文在解决遮挡场景下的面部表情识别问题上展现了显著的创新性。其核心亮点在于引入了多模态语义引导（结合了密集语义分割图和稀疏面部关键点），这为模型提供了更丰富、更鲁棒的面部信息。定制的多尺度交叉交互模块（MCM）和动态对抗排斥增强损失（DARELoss）进一步提升了模型的特征融合能力和区分度。此外，构建首个遮挡导向的FER数据集Occlu-FER对于推动该领域的研究具有重要意义，它为更真实、更具挑战性的遮挡条件下的模型评估提供了标准。这使得该研究不仅理论创新，而且具有很强的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 面部表情识别（FER）由于普遍存在的遮挡和数据集偏差而面临挑战。特别是当面部信息部分被遮挡时，现有FER模型难以提取有效的面部特征，导致分类不准确。

**Method:** 本文提出了ORSANet模型，包含三个主要贡献：1）引入辅助多模态语义引导，包括语义分割图（作为密集语义先验）和面部关键点（作为稀疏几何先验），以消除面部遮挡的歧义并学习高级语义知识，同时缓解身份和性别偏差等内在噪声。2）定制了多尺度交叉交互模块（MCM），以自适应地融合不同尺度下的关键点特征和语义增强表示。3）设计了动态对抗排斥增强损失（DARELoss），动态调整模糊类别的裕度，进一步增强模型区分相似表情的能力。此外，还构建了首个遮挡导向的FER数据集Occlu-FER，以促进对各种真实世界遮挡条件下的鲁棒性分析。

**Result:** 在公共基准测试和Occlu-FER数据集上的大量实验表明，ORSANet实现了最先进的（SOTA）识别性能。

**Conclusion:** ORSANet通过其语义感知方法和新颖的损失函数，有效解决了遮挡场景下的面部表情识别挑战，并在多个数据集上取得了最先进的性能，证明了其方法的有效性。

> **ai_Abstract:** 本论文提出了ORSANet，旨在解决面部表情识别（FER）在遮挡情况下的挑战。ORSANet利用多模态语义引导（包括语义分割图和面部关键点）来提取鲁棒的面部特征并缓解内在偏差。它引入了多尺度交叉交互模块（MCM）以有效融合多模态信息，并设计了动态对抗排斥增强损失（DARELoss）以提高对相似表情的区分能力。此外，论文还构建了首个遮挡导向的FER数据集Occlu-FER。实验结果表明，ORSANet在多个数据集上均达到了最先进的识别性能。

> **摘要翻译:** 面部表情识别（FER）由于普遍存在的遮挡和数据集偏差而面临挑战。特别是当面部信息部分被遮挡时，现有FER模型难以提取有效的面部特征，导致分类不准确。为此，我们提出了ORSANet，它引入了以下三个关键贡献：首先，我们引入辅助多模态语义引导来消除面部遮挡的歧义并学习高级语义知识，这包括两个方面：1）我们引入语义分割图作为密集语义先验，以生成语义增强的面部表示；2）我们引入面部关键点作为稀疏几何先验，以减轻FER中固有的噪声，如身份和性别偏差。其次，为了促进这两种多模态先验的有效结合，我们定制了一个多尺度交叉交互模块（MCM），以自适应地融合不同尺度下的关键点特征和语义增强表示。第三，我们设计了一种动态对抗排斥增强损失（DARELoss），动态调整模糊类别的裕度，进一步增强模型区分相似表情的能力。我们进一步构建了首个遮挡导向的FER数据集Occlu-FER，以促进对各种真实世界遮挡条件下的专门鲁棒性分析。在公共基准测试和Occlu-FER上的大量实验表明，我们提出的ORSANet实现了最先进的识别性能。代码已公开在https://github.com/Wenyuzhy/ORSANet-master。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [12] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
> *量化和缩小未知：基于不确定性最小化的交互式文本到视频检索*

*Bingqing Zhang, Zhuo Cao, Heming Du, Yang Li, Xue Li, Jiajun Liu, Sen Wang* | **Category: cs.CV, 68T45, I.2.10; H.3.3** | **Updated: 2025-07-24**

**Keywords:** 文本到视频检索, 不确定性最小化, 交互式系统, 语义熵, 信息检索

**Comment:** Accepted by ICCV 2025

> **TL;DR:** UMIVR是一个通过量化文本歧义、映射不确定性和帧不确定性来减少交互式文本到视频检索中不确定性的框架，并在多个基准测试中取得了显著效果。

**AI_Comments:** 该论文的创新点在于首次明确量化了交互式文本到视频检索中的多种不确定性，并以此指导交互过程。其提出的无需训练的度量方法具有通用性和可扩展性，为解决检索中的模糊性问题提供了一个新的、系统性的视角。这对于提升用户体验和检索精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到视频检索（TVR）取得了进展，但仍受文本查询模糊、文本-视频映射不明确和视频帧质量低等固有不确定性阻碍。现有交互系统通过澄清问题来完善用户意图，但通常依赖启发式或临时策略，未能明确量化这些不确定性，从而限制了其有效性。

**Method:** 提出了UMIVR框架，通过语义熵的文本歧义分数（TAS）、基于Jensen-Shannon散度的映射不确定性分数（MUS）和基于时间质量的帧采样器（TQFS）等原则性、无需训练的度量，明确量化了文本歧义、映射不确定性和帧不确定性这三种关键不确定性。UMIVR通过这些不确定性度量自适应地生成有针对性的澄清问题，迭代地完善用户查询。

**Result:** 在多个基准测试中验证了UMIVR的有效性，在MSR-VTT-1k数据集上，经过10轮交互后，Recall@1取得了显著提升（69.2%），从而为交互式TVR建立了不确定性最小化的基础。

**Conclusion:** UMIVR通过显式量化并最小化文本歧义、映射不确定性和帧不确定性，为交互式文本到视频检索奠定了不确定性最小化的基础，显著提高了检索精度。

> **ai_Abstract:** 本文提出了UMIVR，一个旨在通过量化和最小化固有不确定性来改进交互式文本到视频检索（TVR）的框架。针对文本查询模糊、文本-视频映射不明确和视频帧质量低等问题，UMIVR引入了文本歧义分数（TAS）、映射不确定性分数（MUS）和时间质量帧采样器（TQFS）来量化并指导澄清问题的生成。实验结果表明，UMIVR有效减少了检索歧义，并在多个基准测试中，特别是MSR-VTT-1k数据集上，取得了显著的性能提升。

> **摘要翻译:** 尽管最近取得了进展，但文本到视频检索（TVR）仍然受到多种固有不确定性的阻碍，例如模糊的文本查询、不明确的文本-视频映射以及低质量的视频帧。尽管交互式系统已经出现，通过澄清问题来完善用户意图以解决这些挑战，但当前的方法通常依赖启发式或临时策略，没有明确量化这些不确定性，从而限制了其有效性。受此差距的启发，我们提出了UMIVR，一个不确定性最小化的交互式文本到视频检索框架，它通过原则性的、无需训练的度量显式量化了三个关键不确定性——文本歧义、映射不确定性和帧不确定性：基于语义熵的文本歧义分数（TAS）、基于Jensen-Shannon散度的映射不确定性分数（MUS）以及基于时间质量的帧采样器（TQFS）。通过这些不确定性度量自适应地生成有针对性的澄清问题，UMIVR迭代地完善用户查询，显著减少了检索歧义。在多个基准测试上进行的广泛实验验证了UMIVR的有效性，在MSR-VTT-1k数据集上，经过10轮交互后，Recall@1取得了显著提升（69.2%），从而为交互式TVR建立了不确定性最小化的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [18] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
> *迈向整体手术场景图*

*Jongmin Shin, Enki Cho, Ka Young Kim, Jung Yong Kim, Seong Tae Kim, Namkee Oh* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 手术场景图, 工具-动作-目标, 手部身份, Endoscapes-SG201, SSG-Com

**Comment:** Accepted to MICCAI 2025

> **TL;DR:** 本文提出了一个新数据集 Endoscapes-SG201 和一个图基方法 SSG-Com，以解决现有手术场景图中对工具-动作-目标组合和手部身份表示不足的问题，并通过实验证明了这些新组件对理解手术场景的重要性。

**AI_Comments:** 这篇论文通过引入新的数据集和方法，有效地解决了现有手术场景图表示中对关键交互信息（如工具-动作-目标和手部身份）的不足，这对于提升计算机辅助干预系统的智能化水平具有重要意义。其创新之处在于对这些未被充分探索的元素的系统性整合，并验证了其价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的手术场景图方法未能充分表示手术场景中的某些重要方面，如工具-动作-目标组合的多样性以及操作工具的手部身份，尽管这些信息对手术场景理解至关重要。

**Method:** 提出了 Endoscapes-SG201 数据集，其中包含工具-动作-目标组合和手部身份的标注。同时，引入了 SSG-Com，这是一种基于图的方法，旨在学习和表示这些关键元素。

**Result:** 通过在安全关键视图评估和动作三元组识别等下游任务上的实验，证明了整合这些基本场景图组件的重要性，突出了它们对手术场景理解的显著贡献。

**Conclusion:** 整合工具-动作-目标组合和手部身份等关键信息到手术场景图表示中，能显著提升手术场景理解的能力。

> **ai_Abstract:** 本文旨在解决现有手术场景图在表示工具-动作-目标组合和手部身份方面存在的不足。为此，作者提出了 Endoscapes-SG201 数据集，其中包含详细的这些信息标注，并开发了图基方法 SSG-Com 来学习和整合这些关键元素。实验结果表明，这些新增组件显著提升了手术场景理解，尤其是在安全关键视图评估和动作三元组识别等任务上。

> **摘要翻译:** 手术场景理解对于计算机辅助干预系统至关重要，它需要对手术场景进行视觉理解，其中涉及手术工具、解剖结构及其相互作用等多种元素。为了有效表示手术场景中的复杂信息，研究人员探索了基于图的方法来结构化建模手术实体及其关系。先前的外科场景图研究已经证明了使用图表示手术场景的可行性。然而，手术场景的某些方面——例如工具-动作-目标的多样化组合以及操作工具的手的身份——在基于图的表示中仍未得到充分探索，尽管它们很重要。为了将这些方面纳入图表示中，我们提出了 Endoscapes-SG201 数据集，其中包含工具-动作-目标组合和手部身份的标注。我们还引入了 SSG-Com，这是一种基于图的方法，旨在学习和表示这些关键元素。通过在安全关键视图评估和动作三元组识别等下游任务上的实验，我们证明了整合这些基本场景图组件的重要性，突出了它们对手术场景理解的显著贡献。代码和数据集可在 https://github.com/ailab-kyunghee/SSG-Com 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [19] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
> *Lumina-mGPT 2.0：独立自回归图像建模*

*Yi Xin, Juncheng Yan, Qi Qin, Zhen Li, Dongyang Liu, Shicheng Li, Victor Shea-Jay Huang, Yupeng Zhou, Renrui Zhang, Le Zhuo, Tiancheng Han, Xiaoqing Sun, Siqi Luo, Mengmeng Wang, Bin Fu, Yuewen Cao, Hongsheng Li, Guangtao Zhai, Xiaohong Liu, Yu Qiao, Peng Gao* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 自回归模型, 图像生成, 基础模型, 多模态, Lumina-mGPT

**Comment:** Tech Report, 23 pages, 11 figures, 7 tables

> **TL;DR:** Lumina-mGPT 2.0是一个从头开始训练的独立自回归模型，在图像生成方面达到了与最先进扩散模型相当的质量，并能无缝处理多种任务，展现了其作为统一多模态生成基础模型的潜力。

**AI_Comments:** Lumina-mGPT 2.0的创新之处在于其完全从头开始训练的独立自回归架构，这打破了对预训练组件的依赖，提供了前所未有的设计和许可自由。其重要性在于证明了自回归模型在不依赖混合架构的情况下，也能在图像生成质量上媲美甚至超越顶尖扩散模型，并展现了强大的多任务处理能力，为统一多模态生成奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像生成方法依赖于预训练组件或混合架构，这限制了架构设计和许可自由。本文旨在通过提出一个从头开始训练的独立自回归模型来解决这些限制，以实现高质量图像生成并保持自回归建模的固有灵活性。

**Method:** Lumina-mGPT 2.0是一个独立的、仅解码器的自回归模型，完全从头开始训练。它采用统一的令牌化方案来处理广泛的任务，并结合了高效的解码策略，如推理时缩放和推测性雅可比采样，以提高质量和速度。

**Result:** Lumina-mGPT 2.0在生成质量上达到了与DALL-E 3和SANA等最先进扩散模型相当的水平，并且在某些情况下超越了它们。它在标准文本到图像基准测试（如GenEval、DPG）上表现出色，并在Graph200K基准测试中证实了其多任务能力。

**Conclusion:** Lumina-mGPT 2.0是一个强大、灵活的统一多模态生成基础模型，通过从头开始的自回归范式实现了与扩散模型相当的性能和广泛的多任务能力。

> **ai_Abstract:** Lumina-mGPT 2.0是一个创新的独立自回归模型，专为高质量图像生成设计。与现有依赖预训练组件的方法不同，Lumina-mGPT 2.0完全从零开始训练，实现了架构自由。它在生成质量上与最先进的扩散模型（如DALL-E 3和SANA）相媲美，甚至超越，同时保持了自回归模型的灵活性。该模型采用统一的令牌化方案，能够处理多项任务，包括主体驱动生成、图像编辑和可控合成。通过结合高效的解码策略，Lumina-mGPT 2.0在性能和速度上均有所提升，并被定位为统一多模态生成领域的强大基础模型。

> **摘要翻译:** 我们提出了Lumina-mGPT 2.0，一个独立的、仅解码器的自回归模型，它重新审视并振兴了用于高质量图像生成及其他领域的自回归范式。与依赖预训练组件或混合架构的现有方法不同，Lumina-mGPT 2.0完全从头开始训练，从而实现了不受限制的架构设计和许可自由。它在生成质量上达到了与DALL-E 3和SANA等最先进扩散模型相当的水平，同时保留了自回归建模固有的灵活性和组合性。我们统一的令牌化方案允许模型在单一生成框架内无缝处理广泛的任务——包括主体驱动生成、图像编辑、可控合成和密集预测。为了进一步提高可用性，我们结合了高效的解码策略，如推理时缩放和推测性雅可比采样，分别用于提高质量和速度。对标准文本到图像基准测试（例如GenEval、DPG）的广泛评估表明，Lumina-mGPT 2.0不仅与基于扩散的模型相匹配，在某些情况下甚至超越了它们。此外，我们在Graph200K基准测试上证实了其多任务能力，原生的Lumina-mGPT 2.0表现异常出色。这些结果将Lumina-mGPT 2.0定位为统一多模态生成的一个强大、灵活的基础模型。我们已在https://github.com/Alpha-VLLM/Lumina-mGPT-2.0发布了我们的训练细节、代码和模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [21] [LONG3R: Long Sequence Streaming 3D Reconstruction](https://arxiv.org/abs/2507.18255)
> *LONG3R：长序列流式三维重建*

*Zhuoguang Chen, Minghui Qin, Tianyuan Yuan, Zhe Liu, Hang Zhao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D重建, 流式处理, 长序列, 实时, 多视角

**Comment:** Accepted by ICCV 2025. Project page:
  https://zgchen33.github.io/LONG3R/

> **TL;DR:** LONG3R提出了一种新颖的模型，用于长序列流式多视角三维场景重建，通过循环操作和记忆门控机制实现实时处理，并引入三维时空记忆和两阶段课程训练策略以提高性能。

**AI_Comments:** LONG3R的创新之处在于其针对长序列流式3D重建的实时性挑战，通过引入循环处理、记忆门控和三维时空记忆来有效管理和利用长序列数据。这种方法对于需要实时动态场景重建的应用（如AR/VR、机器人导航）具有重要意义。两阶段课程训练策略也有效地平衡了性能和训练效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理流式输入图像时面临限制，要么依赖耗时的离线优化，要么仅限于短序列，这阻碍了它们在实时场景中的应用。

**Method:** 本文提出了LONG3R模型，通过循环操作，利用记忆门控机制过滤相关记忆，并结合新观测输入双源精炼解码器进行粗到细交互。为有效捕捉长序列记忆，提出了一种三维时空记忆，动态修剪冗余空间信息并自适应调整场景分辨率。此外，采用两阶段课程训练策略以提高长序列性能并保持训练效率。

**Result:** 实验表明，LONG3R在长序列上优于现有最先进的流式方法，同时保持实时推理速度。

**Conclusion:** LONG3R成功解决了长序列流式三维重建的挑战，通过其创新的架构和训练策略，实现了卓越的性能和实时处理能力。

> **ai_Abstract:** LONG3R是一种用于长序列流式多视角三维场景重建的新模型，旨在克服现有方法在实时处理长序列上的局限。它通过循环操作、记忆门控机制和双源精炼解码器实现实时处理，并引入三维时空记忆以有效管理长序列信息。模型采用两阶段课程训练策略优化性能。实验证明，LONG3R在长序列上表现优异并保持实时推理速度。

> **摘要翻译:** 近年来，多视角场景重建取得了显著进展，然而现有方法在处理图像流时面临局限。这些方法要么依赖耗时的离线优化，要么局限于较短的序列，这阻碍了它们在实时场景中的应用。在这项工作中，我们提出了LONG3R（长序列流式三维重建），这是一种新颖的模型，专为长序列的流式多视角三维场景重建而设计。我们的模型通过循环操作实现实时处理，并随每次新观测维护和更新记忆。我们首先采用记忆门控机制来过滤相关记忆，然后将其与新观测一起输入到双源精炼解码器中进行从粗到细的交互。为了有效捕获长序列记忆，我们提出了一个三维时空记忆，它能动态修剪冗余空间信息，同时自适应地调整场景分辨率。为了在保持训练效率的同时增强模型在长序列上的性能，我们采用了两阶段课程训练策略，每个阶段都针对特定的能力。实验表明，LONG3R优于最先进的流式方法，尤其是在较长序列上，同时保持实时推理速度。项目页面：https://zgchen33.github.io/LONG3R/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [24] [LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network](https://arxiv.org/abs/2507.16362)
> *LPTR-AFLNet：轻量级集成中文车牌校正与识别网络*

*Guangzhu Xu, Pengcheng Zuo, Zhi Ke, Bangjun Lei* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 中文车牌识别, 车牌校正, 轻量级网络, 深度学习, 实时

**Comment:** 28 pages, 33 figures

> **TL;DR:** 本文提出了LPTR-AFLNet，一个轻量级、端到端的中文字符车牌校正与识别网络，旨在解决复杂环境下透视畸变和多行车牌识别的挑战，并在边缘设备上实现高效实时部署。

**AI_Comments:** LPTR-AFLNet的创新之处在于其将车牌校正和识别集成到一个轻量级的端到端网络中，并巧妙地利用识别输出作为弱监督信号来优化校正过程。其针对边缘设备的优化以及在低端GPU上小于10毫秒的运行速度，显著提升了实际部署的效率和可行性，是该领域一个重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 在非受限和复杂环境下，中文车牌识别（CLPR）面临诸多挑战，特别是由于不同拍摄角度引起的透视畸变以及单行和双行车牌的校正问题。考虑到边缘设备有限的计算资源，开发一个低复杂度、端到端的集成校正和识别网络对于实现实时高效部署至关重要。

**Method:** 本文提出了LPTR-AFLNet，一个轻量级、统一的网络，用于校正和识别中文车牌。该网络将透视变换校正模块（PTR）与优化的车牌识别网络AFLNet相结合。它利用识别输出作为弱监督信号来有效指导校正过程。为提高识别精度，LPRNet引入了几项改进，包括改进的注意力模块以减少相似字符之间的混淆，以及使用Focal Loss来解决训练期间的类别不平衡问题。

**Result:** 实验结果表明，LPTR-AFLNet在校正透视畸变和识别双行车牌图像方面表现出色，在各种具有挑战性的场景中保持了高识别精度。此外，在中低端GPU平台上，该方法运行时间少于10毫秒。

**Conclusion:** LPTR-AFLNet是一个高效、实用的轻量级集成中文车牌校正与识别网络，特别适用于资源受限设备上的实时部署，具有广泛的适用性。

> **ai_Abstract:** LPTR-AFLNet是一个轻量级、端到端的中文字符车牌校正与识别网络，旨在解决复杂环境下透视畸变和多行车牌识别的挑战。它通过结合透视变换校正模块（PTR）和优化的AFLNet实现，并利用识别结果作为弱监督信号来指导校正。为提升识别精度，网络改进了注意力机制并引入Focal Loss。实验证明，该网络在校正和识别方面性能卓越，且运行速度快，适用于边缘设备上的实时部署。

> **摘要翻译:** 中文车牌识别（CLPR）在非受限和复杂环境中面临诸多挑战，特别是由于各种拍摄角度引起的透视畸变以及单行和双行车牌的校正问题。考虑到边缘设备有限的计算资源，开发一个低复杂度、端到端的集成校正和识别网络对于实现实时和高效部署至关重要。在这项工作中，我们提出了一个名为LPTR-AFLNet的轻量级统一网络，用于校正和识别中文车牌，它将透视变换校正模块（PTR）与优化的车牌识别网络AFLNet相结合。该网络利用识别输出作为弱监督信号，有效指导校正过程，确保准确的透视畸变校正。为了提高识别精度，我们对LPRNet引入了几项改进，包括改进的注意力模块以减少相似字符之间的混淆，以及使用Focal Loss来解决训练期间的类别不平衡问题。实验结果表明，LPTR-AFLNet在校正透视畸变和识别双行车牌图像方面表现出色，在各种具有挑战性的场景中保持了高识别精度。此外，在中低端GPU平台上，该方法运行时间少于10毫秒，表明其具有实际效率和广泛适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [26] [Adapting Large VLMs with Iterative and Manual Instructions for Generative Low-light Enhancement](https://arxiv.org/abs/2507.18064)
> *采用迭代和手动指令的生成式低光增强大型视觉语言模型自适应*

*Xiaoran Sun, Liyan Wang, Cong Wang, Yeying Jin, Kin-man Lam, Zhixun Su, Yang Yang, Jinshan Pan* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 低光图像增强, 视觉语言模型, 迭代指令, 语义指导, 跨模态融合

**Comment:** 

> **TL;DR:** 提出VLM-IMI框架，利用大型VLMs和迭代/手动指令进行低光增强，通过语义指导和跨模态融合提升效果。

**AI_Comments:** 该论文的创新点在于将大型视觉语言模型引入低光图像增强任务，并利用文本指令提供语义指导，这是一种新颖的跨模态融合方法。迭代和手动指令策略的引入也为提升极端低光条件下的细节恢复提供了有效途径，显著提高了图像的语义一致性和视觉质量，为LLIE领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有低光图像增强方法忽视了正常光图像的语义指导，导致在复杂光照条件下效果受限。

**Method:** 本文提出VLM-IMI框架，利用大型视觉语言模型（VLMs）与迭代和手动指令（IMIs）进行低光图像增强。VLM-IMI将所需正常光内容的文本描述作为增强线索，实现语义信息恢复。为有效整合跨模态先验，引入指令先验融合模块，动态对齐和融合图像与文本特征。推理时采用迭代和手动指令策略，逐步改进文本指令以提升视觉质量。

**Result:** VLM-IMI在不同场景下的大量实验表明，其在定量指标和感知质量方面均优于最先进的方法。

**Conclusion:** VLM-IMI通过利用大型VLMs和迭代和手动指令，结合语义指导和跨模态融合，有效解决了低光图像增强的挑战，并在各种场景下表现出色。

> **ai_Abstract:** 本文提出VLM-IMI框架，旨在解决现有低光图像增强方法忽视语义指导的问题。该框架利用大型视觉语言模型（VLMs），通过迭代和手动指令（IMIs）将正常光内容的文本描述作为增强线索，实现语义引导的图像恢复。VLM-IMI引入指令先验融合模块以整合图像和文本特征，并在推理时采用指令优化策略提升视觉质量、结构保真度和细节恢复。实验证明VLM-IMI在多方面超越了现有SOTA方法。

> **摘要翻译:** 大多数现有的低光图像增强（LLIE）方法依赖于预训练模型先验、低光输入或两者兼而有之，同时忽略了正常光图像可提供的语义指导。这种局限性阻碍了它们在复杂光照条件下的有效性。在本文中，我们提出了VLM-IMI，一个利用大型视觉语言模型（VLMs）与迭代和手动指令（IMIs）进行LLIE的新颖框架。VLM-IMI将所需正常光内容的文本描述作为增强线索，实现语义信息恢复。为了有效整合跨模态先验，我们引入了一个指令先验融合模块，该模块动态对齐和融合图像与文本特征，促进生成详细且语义一致的输出。在推理过程中，我们采用迭代和手动指令策略来优化文本指令，逐步提高视觉质量。这种优化增强了在极低光条件下的结构保真度、语义对齐和精细细节的恢复。在不同场景下进行的大量实验表明，VLM-IMI在定量指标和感知质量方面均优于最先进的方法。源代码可在https://github.com/sunxiaoran01/VLM-IMI获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [30] [PolarAnything: Diffusion-based Polarimetric Image Synthesis](https://arxiv.org/abs/2507.17268)
> *PolarAnything: 基于扩散的偏振图像合成*

*Kailong Zhang, Youwei Lyu, Heng Guo, Si Li, Zhanyu Ma, Boxin Shi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 偏振图像合成, 扩散模型, 图像生成, 3D重建, 零样本

**Comment:** 11 pages

> **TL;DR:** 提出PolarAnything，一个基于扩散模型从单张RGB图生成高保真偏振图像的框架，解决了偏振相机获取困难和现有模拟器依赖3D资产的问题。

**AI_Comments:** 该论文的创新点在于首次将扩散模型应用于偏振图像合成，并成功摆脱了对昂贵3D资产的依赖，显著降低了生成大规模真实感偏振图像的门槛，对偏振图像在图像增强和3D重建领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 偏振相机获取受限阻碍了偏振图像的广泛应用；现有偏振模拟器Mitsuba依赖参数化模型和大量3D资产，难以生成大规模真实感图像。

**Method:** 提出PolarAnything模型，一个基于预训练扩散模型的生成框架，它采用有效的表示策略，能从单张RGB输入生成兼具真实感和物理精度的偏振图像，无需3D资产。

**Result:** 模型能够生成高质量的偏振图像，并支持偏振形状恢复等下游任务。

**Conclusion:** PolarAnything成功解决了偏振图像合成中数据稀缺和现有方法依赖3D资产的问题，为偏振图像的应用提供了新的解决方案。

> **ai_Abstract:** 该论文提出了PolarAnything，一个基于扩散的生成框架，旨在解决偏振图像获取困难及现有模拟器对3D资产的依赖问题。通过从单一RGB输入合成兼具真实感和物理精度的偏振图像，PolarAnything利用了预训练扩散模型的零样本能力和有效的表示策略，能够生成高质量的偏振图像并支持如偏振形状恢复等下游任务。

> **摘要翻译:** 偏振图像有助于图像增强和3D重建任务，但偏振相机的有限可及性阻碍了其更广泛的应用。这一空白推动了对合成真实感偏振图像的需求。现有的偏振模拟器Mitsuba依赖于参数化的偏振图像形成模型，并且需要覆盖形状和PBR材料的广泛3D资产，这使其无法生成大规模真实感图像。为了解决这个问题，我们提出了PolarAnything，它能够从单一RGB输入合成兼具真实感和物理精度的偏振图像，消除了对3D资产集合的依赖。借鉴预训练扩散模型的零样本性能，我们引入了一个基于扩散的生成框架，该框架具有有效的表示策略，可以保持偏振属性的保真度。实验表明，我们的模型生成高质量的偏振图像，并支持偏振形状恢复等下游任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [36] [PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image](https://arxiv.org/abs/2507.17332)
> *PARTE：单幅图像3D人体重建中的部件引导纹理化*

*Hyeongjin Nam, Donghwan Kim, Gyeongsik Moon, Kyoung Mu Lee* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D人体重建, 纹理化, 部件引导, 单幅图像, 深度学习

**Comment:** Published at ICCV 2025, 22 pages including the supplementary material

> **TL;DR:** 提出PARTE框架，通过利用3D人体部件信息解决单幅图像3D人体重建中纹理错位问题，实现SOTA效果。

**AI_Comments:** PARTE的创新点在于明确利用了3D人体部件信息来指导纹理重建，这解决了现有方法中纹理错位这一核心问题。通过引入PartSegmenter和PartTexturer两个模块，该方法能够有效地在纹理对齐方面取得显著提升，对于单幅图像3D人体重建领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D人体重建方法的主要局限性在于不同人体部件之间的纹理错位，因为它们没有明确利用部件分割先验知识，导致重建纹理错位。

**Method:** 本文提出了PARTE框架，利用3D人体部件信息作为关键指导来重建3D人体纹理。该框架包含两个核心组件：1) PartSegmenter模块，用于从单幅图像推断3D人体部件信息，先重建无纹理人体表面并预测部件标签；2) PartTexturer模块，将部件信息融入纹理重建，从预训练的图像生成网络获取人体部件纹理对齐的先验知识。

**Result:** 实验证明该框架在3D人体重建方面取得了最先进的质量。

**Conclusion:** 通过显式利用3D人体部件信息，PARTE能够有效解决现有3D人体重建方法中纹理错位的问题，并显著提升重建质量。

> **ai_Abstract:** 本文提出了PARTE，一个用于从单幅图像重建3D人体的框架，旨在解决现有方法中因未利用部件分割先验而导致的纹理错位问题。PARTE包含PartSegmenter模块用于推断3D部件信息，以及PartTexturer模块用于将部件信息融入纹理重建。实验证明PARTE在3D人体重建质量上达到了最先进水平。

> **摘要翻译:** 现有3D人体重建方法的主要局限性之一是不同人体部件之间纹理的错位。每个身体部位，例如夹克或裤子，都应该保持独特的纹理而不会相互融合。人体部件的结构连贯性是推断单幅图像不可见区域人体纹理的关键线索。然而，大多数现有3D人体重建方法并未明确利用这种部件分割先验知识，导致其重建中纹理错位。为此，我们提出了PARTE，它利用3D人体部件信息作为重建3D人体纹理的关键指导。我们的框架包含两个核心组件。首先，为了从单幅图像推断3D人体部件信息，我们提出了一个3D部件分割模块（PartSegmenter），该模块首先重建一个无纹理的人体表面并根据该无纹理表面预测人体部件标签。其次，为了将部件信息融入纹理重建，我们引入了一个部件引导纹理化模块（PartTexturer），该模块从一个预训练的图像生成网络中获取人体部件纹理对齐的先验知识。大量的实验表明，我们的框架在3D人体重建方面取得了最先进的质量。项目页面可在https://hygenie1228.github.io/PARTE/访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [46] [CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting](https://arxiv.org/abs/2507.18473)
> *CRUISE：在V2X场景中利用高斯泼溅进行协作重建与编辑*

*Haoran Xu, Saining Zhang, Peishuo Li, Baijun Ye, Xiaoxue Chen, Huan-ang Gao, Jv Zheng, Xiaowei Song, Ziqiao Peng, Run Miao, Jinrang Jia, Yifeng Shi, Guangqi Yi, Hang Zhao, Hao Tang, Hongyang Li, Kaicheng Yu, Hao Zhao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** V2X, 高斯泼溅, 重建, 数据增强, 自动驾驶

**Comment:** IROS 2025, Code: https://github.com/SainingZhang/CRUISE

> **TL;DR:** CRUISE是一个用于V2X自动驾驶环境的重建与合成框架，利用分解高斯泼溅技术实现高保真场景重建和灵活编辑，并能生成大规模V2X数据集以改进3D检测和跟踪。

**AI_Comments:** CRUISE框架的创新之处在于将分解高斯泼溅技术应用于V2X场景的重建与编辑，实现了高保真度重建和灵活的数据增强。其重要性体现在解决了V2X自动驾驶数据稀缺的问题，通过合成数据有效提升了下游任务（如3D检测和跟踪）的性能，并能生成有价值的极端情况，这对于提高自动驾驶系统的鲁棒性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管仿真在自动驾驶任务中贡献巨大，但其在V2X场景数据生成和增强方面的潜力尚未得到充分挖掘。

**Method:** 本文引入了CRUISE框架，一个专为V2X驾驶环境设计的综合重建与合成框架。CRUISE采用分解高斯泼溅（decomposed Gaussian Splatting）技术，以高精度重建真实世界场景，并支持灵活编辑。通过将动态交通参与者分解为可编辑的高斯表示，CRUISE实现了驾驶场景的无缝修改和增强。此外，该框架能从自车和基础设施视角渲染图像，从而实现大规模V2X数据集增强，用于训练和评估。

**Result:** 实验结果表明：1) CRUISE能够高保真地重建真实世界的V2X驾驶场景；2) 使用CRUISE改进了自车、基础设施和协作视图下的3D检测性能，以及V2X-Seq基准上的协作3D跟踪性能；3) CRUISE能够有效地生成具有挑战性的极端情况。

**Conclusion:** CRUISE框架能够高保真地重建V2X驾驶场景并支持灵活编辑，有效增强了V2X数据集，从而显著提升了3D检测和跟踪等自动驾驶关键任务的性能，并能生成挑战性极端情况。

> **ai_Abstract:** CRUISE是一个创新的V2X场景重建与合成框架，旨在解决V2X数据生成和增强的不足。它利用分解高斯泼溅技术高保真地重建真实世界场景，并允许灵活编辑动态交通参与者。该框架能从多视角渲染图像，从而生成大规模V2X数据集，并实验证明其能显著提升3D检测和跟踪性能，同时有效生成挑战性极端情况。

> **摘要翻译:** 车联网（V2X）通信在自动驾驶中扮演着关键角色，实现了车辆与基础设施之间的协作。尽管仿真已为各种自动驾驶任务做出了重大贡献，但其在V2X场景数据生成和增强方面的潜力仍未得到充分探索。在本文中，我们引入了CRUISE，一个专为V2X驾驶环境设计的综合重建与合成框架。CRUISE采用分解高斯泼溅技术，以高精度重建真实世界场景，同时支持灵活编辑。通过将动态交通参与者分解为可编辑的高斯表示，CRUISE允许对驾驶场景进行无缝修改和增强。此外，该框架能从自车和基础设施视角渲染图像，从而实现大规模V2X数据集增强，用于训练和评估。我们的实验结果表明：1）CRUISE能够高保真地重建真实世界的V2X驾驶场景；2）使用CRUISE改进了自车、基础设施和协作视图下的3D检测性能，以及V2X-Seq基准上的协作3D跟踪性能；3）CRUISE能够有效地生成具有挑战性的极端情况。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [55] [Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection](https://arxiv.org/abs/2507.18260)
> *利用高斯无关表示学习和扩散先验增强红外小目标检测*

*Junyao Li, Yahao Lu, Xingyuan Guo, Xiaoyu Xian, Tiantian Wang, Yukai Shi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 红外小目标检测, 高斯无关表示学习, 扩散模型, 数据稀缺, 表示学习

**Comment:** Submitted to Neural Networks. We propose the Gaussian Group Squeezer,
  leveraging Gaussian sampling and compression with diffusion models for
  channel-based data augmentation

> **TL;DR:** 本文提出了一种利用高斯无关表示学习和两阶段扩散模型来增强红外小目标检测（ISTD）的方法，特别是在数据稀缺的情况下，解决了现有方法对大量手动标注数据依赖导致脆弱性的问题。

**AI_Comments:** 该论文的创新点在于结合了高斯无关表示学习和两阶段扩散模型来解决红外小目标检测中数据稀缺的挑战。通过“高斯组压缩器”进行非均匀量化以增强模型的鲁棒性，并通过扩散模型生成高质量的合成数据，这为在有限数据条件下提升ISTD性能提供了一个新颖且有前景的方向。这种方法有望降低对昂贵手动标注数据的依赖，从而提高ISTD在实际部署中的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 红外小目标检测（ISTD）在许多实际应用中至关重要。然而，当前最先进的ISTD方法严重依赖大量昂贵的手动标注数据进行表示学习，这使得它们在真实世界的挑战中（特别是高质量红外数据稀缺时）表现脆弱，并对现有的ISTD理论提出了挑战。

**Method:** 本文首先研究了在数据稀缺情况下，主流方法检测性能的变化。为解决数据稀缺问题，引入了高斯无关表示学习，并提出了“高斯组压缩器”（Gaussian Group Squeezer），利用高斯采样和压缩进行非均匀量化，以增强ISTD模型的鲁棒性。随后，引入了两阶段扩散模型进行真实世界重建，通过将量化信号与真实世界分布对齐，显著提高了合成样本的质量和保真度。

**Result:** 在各种数据稀缺场景下，与最先进的检测方法进行比较评估，结果表明所提出的方法是有效的。

**Conclusion:** 本文提出的利用高斯无关表示学习和扩散先验的方法，能够有效增强红外小目标检测性能，尤其是在高质量红外数据稀缺的实际应用场景中，展现出优越的鲁棒性和有效性。

> **ai_Abstract:** 本文针对红外小目标检测（ISTD）中现有方法因依赖大量标注数据而在数据稀缺场景下表现脆弱的问题，提出了高斯无关表示学习和两阶段扩散模型的新方法。通过引入高斯组压缩器进行非均匀量化以增强模型鲁棒性，并利用扩散模型进行高质量合成样本重建，显著提升了ISTD模型在数据稀缺条件下的性能和泛化能力。实验结果表明，该方法在各种稀缺场景下均优于现有先进方法。

> **摘要翻译:** 红外小目标检测（ISTD）在众多实际应用中发挥着至关重要的作用。为了探索性能边界，研究人员利用大量昂贵的手动标注数据进行表示学习。然而，这种方法使得最先进的ISTD方法在实际挑战中变得非常脆弱。本文首先研究了在各种稀缺性条件下（即缺乏高质量红外数据），几种主流方法检测性能的变化，这些变化挑战了当前关于实际ISTD的普遍理论。为了解决这个问题，我们引入了高斯无关表示学习。具体来说，我们提出了高斯组压缩器（Gaussian Group Squeezer），利用高斯采样和压缩进行非均匀量化。通过利用多样化的训练样本，我们增强了ISTD模型应对各种挑战的弹性。然后，我们引入了两阶段扩散模型进行真实世界重建。通过将量化信号与真实世界分布紧密对齐，我们显著提升了合成样本的质量和保真度。在各种稀缺场景下，与最先进的检测方法进行比较评估，结果证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [59] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
> *SV3.3B：一种用于动作识别的体育视频理解模型*

*Sai Varun Kodathala, Yashwanth Reddy Vutukoori, Rakesh Vunnam* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 体育视频理解, 动作识别, 轻量级模型, 自监督学习, 关键帧提取

**Comment:** 8 pages, 6 figures, 4 tables. Submitted to AIxSET 2025

> **TL;DR:** SV3.3B是一个轻量级体育视频理解模型，通过新颖的采样和自监督学习，在设备端高效运行，并能生成详细的体育动作描述，性能优于GPT-4o且计算成本更低。

**AI_Comments:** 该论文的创新点在于提出了一个轻量级且高效的体育视频理解模型SV3.3B，通过结合新颖的时间运动差异采样和自监督学习，实现了在设备端的部署。其采用DWT-VGG16-LDA进行关键帧提取，并结合V-DWT-JEPA2编码器和LLM解码器，能够生成技术详细和分析丰富的体育动作描述。该模型的优势在于在显著降低计算需求的同时，性能超越了大型闭源模型如GPT-4o，这对于实际应用和普及体育视频分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的体育视频分析模型计算量大，需要服务器处理，且难以捕捉细微的运动生物力学转换和关键动作阶段（如准备、执行、收尾），导致缺乏对运动的精细理解。

**Method:** 本文提出了SV3.3B，一个轻量级（3.3B参数）视频理解模型，结合了新颖的时间运动差异采样和自监督学习，旨在实现高效的设备端部署。该方法采用基于DWT-VGG16-LDA的关键帧提取机制来识别16个最具代表性的帧，然后是一个通过掩码去噪目标预训练的V-DWT-JEPA2编码器，以及一个针对体育动作描述生成进行微调的LLM解码器。

**Result:** SV3.3B在NSVA篮球数据集的一个子集上进行了评估，在传统文本生成指标和体育特定评估标准上均表现出色，超越了包括GPT-4o变体在内的更大闭源模型，同时保持了显著更低的计算要求。该模型在生成技术详细和分析丰富的体育描述方面表现出卓越的能力，在真实性验证指标上比GPT-4o提高了29.2%，并在信息密度、动作复杂性和测量精度等对全面运动分析至关重要的指标上也有显著提升。

**Conclusion:** SV3.3B模型能够高效地在设备端部署，并生成技术详细、分析丰富的体育动作描述，其性能优于现有大型模型，且计算成本更低，显著提升了体育视频分析的精细度和实用性。

> **ai_Abstract:** 本文介绍了SV3.3B，一个轻量级（3.3B参数）的体育视频理解模型，旨在克服现有模型计算量大且缺乏精细动作理解的限制。该模型结合了时间运动差异采样和自监督学习，采用DWT-VGG16-LDA进行关键帧提取，并使用V-DWT-JEPA2编码器和LLM解码器生成详细的体育动作描述。SV3.3B在NSVA篮球数据集上表现出色，在文本生成和体育特定指标上均优于GPT-4o等大型模型，同时显著降低了计算需求，尤其在信息密度、动作复杂性和测量精度方面有显著提升。

> **摘要翻译:** 本文旨在解决自动体育视频分析的挑战，该领域传统上受限于计算密集型模型，这些模型需要服务器端处理，并且缺乏对运动员动作的精细理解。当前的方法难以捕捉对有意义的体育分析至关重要的细微生物力学转换，经常错过在几秒钟内发生的关键阶段，例如准备、执行和收尾。为了解决这些限制，我们引入了SV3.3B，一个轻量级的33亿参数视频理解模型，它结合了新颖的时间运动差异采样和自监督学习，以实现高效的设备端部署。我们的方法采用基于DWT-VGG16-LDA的关键帧提取机制，智能地从体育序列中识别出16个最具代表性的帧，然后是一个通过掩码去噪目标预训练的V-DWT-JEPA2编码器，以及一个针对体育动作描述生成进行微调的LLM解码器。在NSVA篮球数据集的一个子集上进行评估，SV3.3B在传统文本生成指标和体育特定评估标准上均取得了卓越的性能，超越了包括GPT-4o变体在内的更大闭源模型，同时保持了显著更低的计算要求。我们的模型在生成技术详细和分析丰富的体育描述方面表现出卓越的能力，在真实性验证指标上比GPT-4o提高了29.2%，并在信息密度、动作复杂性和测量精度等对全面运动分析至关重要的指标上也有显著提升。模型可在https://huggingface.co/sportsvision/SV3.3B获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [62] [ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation](https://arxiv.org/abs/2312.05407)
> *ODES：在线医学图像分割的专家指导域适应*

*Md Shazid Islam, Sayak Nag, Arindam Dutta, Miraj Ahmed, Fahim Faisal Niloy, Amit K. Roy-Chowdhury* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 域适应, 医学图像分割, 在线学习, 专家指导, 主动学习

**Comment:** 

> **TL;DR:** ODES是一种在线医学图像分割的域适应方法，通过专家指导和图像剪枝策略，克服了在线流数据中伪标签的噪声问题，提高了分割质量。

**AI_Comments:** 这篇论文的创新点在于将专家指导引入在线域适应场景，并通过主动学习和图像剪枝策略高效利用有限的专家标注。这解决了在线医学图像分割中伪标签噪声和实时性要求之间的矛盾，对于提高医学图像分析的准确性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无监督域适应分割依赖的伪标签存在噪声，在在线数据流中适应分布变化时，这种噪声会导致低质量分割，对精度要求高的医学图像分析尤其不利。

**Method:** 提出ODES方法，通过主动学习整合专家反馈，选择信息量最大的像素进行专家标注。为减少标注时间并提高在线适应性，进一步提出了一种新颖的图像剪枝策略，选择当前批次中最有用的图像子集进行主动学习。

**Result:** 提出的方法优于现有的在线适应方法，并且与离线域适应主动学习方法相比产生了有竞争力的结果。

**Conclusion:** 通过少量专家像素级标注和图像剪枝策略，ODES能有效提升在线医学图像分割的域适应性能，即使在缺乏专用训练数据的情况下也能保持高精度。

> **ai_Abstract:** ODES是一种用于在线医学图像分割的域适应框架，旨在解决传统无监督方法中伪标签噪声导致性能下降的问题，尤其是在处理在线数据流时。该方法通过主动学习引入专家指导，选择最具信息量的像素进行标注，并进一步提出图像剪枝策略以优化标注效率和在线适应性。实验结果表明，ODES在在线适应任务中表现优异，并能与离线方法媲美。

> **摘要翻译:** 无监督域适应分割通常依赖于使用预训练网络在未标记目标数据集上预测的伪标签进行自训练。然而，此类伪标签的噪声性质是在源数据集和目标数据集之间适应网络分布变化的主要瓶颈。当网络以在线方式遇到传入数据流时，这一挑战会更加突出，因为网络受限于在一次前向和后向传播中适应传入的目标域数据流。在这种情况下，仅仅依赖不准确的伪标签可能导致低质量的分割，这对于精度和准确性至关重要的医学图像分析是极其有害的。我们假设从专家那里获得少量像素级注释可以解决这个问题，从而即使在没有专用训练数据的情况下，也能提高在线流数据域适应的性能。我们称我们的方法为ODES：在线医学图像分割的专家指导域适应，它以在线方式适应每个传入的数据批次，通过主动学习整合来自专家的反馈。通过主动学习，可以选择每张图像中最具信息量的像素进行专家注释。然而，在批次中所有图像上获取像素级注释通常会导致信息冗余，同时增加在线学习中的时间开销。为了减少注释获取时间并使适应过程更具在线友好性，我们进一步提出了一种新颖的图像剪枝策略，从当前批次中选择最有用的图像子集进行主动学习。我们提出的方法优于现有的在线适应方法，并且与离线域适应主动学习方法相比产生了有竞争力的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [69] [TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound](https://arxiv.org/abs/2507.18082)
> *TextSAM-EUS：基于文本提示学习的SAM模型在内镜超声中胰腺肿瘤的精确分割*

*Pascal Spiegler, Taha Koleilat, Arash Harirpoush, Corey S. Miller, Hassan Rivaz, Marta Kersten-Oertel, Yiming Xiao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 胰腺肿瘤分割, 内镜超声, SAM, 文本提示学习, 深度学习

**Comment:** Accepted to ICCV 2025 Workshop CVAMD

> **TL;DR:** TextSAM-EUS利用文本提示学习和LoRA适配SAM，在内镜超声中实现胰腺肿瘤的自动精确分割，优于现有SOTA模型。

**AI_Comments:** 该论文的创新点在于首次将文本提示学习引入SAM模型进行医学图像分割，特别是在EUS这种挑战性图像模态上。其轻量级（仅调整0.86%参数）和无需手动几何提示的特性，极大地提高了实用性和效率，有望降低对大量专家标注数据的依赖，并克服EUS图像质量差的问题。这对于临床应用，尤其是胰腺癌的诊断和治疗具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 胰腺癌预后不良，依赖内镜超声（EUS）进行靶向活检和放疗。然而，EUS图像的散斑噪声、低对比度和不直观外观使得全监督深度学习模型在胰腺肿瘤分割时容易出错，并且高度依赖大量专家标注数据集。

**Method:** 本文提出了TextSAM-EUS，一个轻量级、文本驱动的SAM模型改进版，在推理时无需手动几何提示。该方法结合BiomedCLIP文本编码器进行文本提示学习（上下文优化），并对SAM架构进行LoRA适配，以实现EUS中胰腺肿瘤的自动分割，仅调整了总参数的0.86%。

**Result:** 在公共胰腺内镜超声数据库上，TextSAM-EUS在自动提示下达到了82.69%的Dice系数和85.28%的归一化表面距离（NSD）；在手动几何提示下达到了83.10%的Dice系数和85.70%的NSD。其性能优于现有的最先进（SOTA）监督深度学习模型和基础模型（如SAM及其变体）。

**Conclusion:** TextSAM-EUS是首次尝试将提示学习引入基于SAM的医学图像分割，为高效、鲁棒的自动EUS分割提供了一个实用的选择。

> **ai_Abstract:** 本文提出TextSAM-EUS，一种基于文本提示学习和LoRA适配的SAM模型，旨在解决内镜超声（EUS）图像中胰腺肿瘤分割的挑战。该模型利用BiomedCLIP文本编码器实现自动分割，无需手动几何提示，并且仅调整少量参数。实验结果表明，TextSAM-EUS在公共数据集上表现优异，超越了现有SOTA监督模型和SAM变体，为EUS图像的肿瘤自动分割提供了高效且鲁棒的解决方案。

> **摘要翻译:** 胰腺癌预后不良，依赖内镜超声（EUS）进行靶向活检和放疗。然而，EUS图像的散斑噪声、低对比度和不直观外观使得使用全监督深度学习（DL）模型分割胰腺肿瘤既容易出错，又依赖于大量由专家整理的标注数据集。为了解决这些挑战，我们提出了TextSAM-EUS，这是一种新颖、轻量级、文本驱动的Segment Anything Model（SAM）适应性模型，在推理时无需手动几何提示。我们的方法利用BiomedCLIP文本编码器进行文本提示学习（上下文优化），结合基于LoRA的SAM架构适配，从而实现EUS中胰腺肿瘤的自动分割，仅调整了总参数的0.86%。在公共胰腺内镜超声数据库上，TextSAM-EUS在自动提示下达到了82.69%的Dice系数和85.28%的归一化表面距离（NSD），而在手动几何提示下达到了83.10%的Dice系数和85.70%的NSD，其性能优于现有的最先进（SOTA）监督深度学习模型和基础模型（例如SAM及其变体）。作为首次尝试将提示学习引入基于SAM的医学图像分割，TextSAM-EUS为高效、鲁棒的自动EUS分割提供了一个实用的选择。我们的代码将在接受后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [85] [Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis](https://arxiv.org/abs/2507.18287)
> *牙齿-肺癌轴的孟德尔随机化和中介分析解剖*

*Wenran Zhang, Huihuan Luo, Linda Wei, Ping Nie, Yiqun Wu, Dedong Yu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 龋齿, 肺癌, 孟德尔随机化, 中介分析, 肺功能

**Comment:** 

> **TL;DR:** 该研究利用孟德尔随机化和中介分析发现龋齿与肺癌风险存在因果关系，且肺功能下降部分介导了这种关系；牙周炎则无此关联。

**AI_Comments:** 这项研究通过使用孟德尔随机化，有效避免了传统观察性研究中常见的混杂因素和反向因果问题，从而更可靠地揭示了龋齿与肺癌之间的因果关系。发现肺功能在其中介导作用具有创新性，为肺癌预防提供了新的视角，即关注口腔健康。该研究的局限性可能在于其对特定人群的遗传数据依赖，以及中介效应的比例相对较小。

<details>
  <summary>Details</summary>

**Motivation:** 观察性研究表明牙周病和龋齿与肺癌之间可能存在关联，但因果关系仍不确定，因此本研究旨在通过孟德尔随机化和中介分析来探究其因果关系。

**Method:** 本研究采用双样本孟德尔随机化（MR）方法，利用来自大规模全基因组关联研究（GWAS）的遗传工具，数据包括487,823例龋齿和506,594例牙周炎病例，以及来自Transdisciplinary Research of Cancer in Lung联盟的肺癌数据。主要分析方法为逆方差加权（Inverse Variance Weighting），并使用delta方法评估肺功能（用力肺活量FVC和一秒用力呼气量FEV1）的中介作用。

**Result:** 结果显示龋齿对整体肺癌及其亚型（特别是鳞状细胞肺癌）存在显著的正向因果效应。龋齿发生率每增加一个标准差，鳞状细胞肺癌风险增加188.0% (OR = 2.880, 95% CI = 1.236–6.713, p = 0.014)。肺功能下降（FVC和FEV1）部分介导了这种效应，分别占总效应的5.124%和5.890%。未发现牙周炎的因果效应。

**Conclusion:** 龋齿在肺癌风险中扮演因果角色，支持将口腔护理和肺功能监测整合到癌症预防策略中。

> **ai_Abstract:** 本研究利用双样本孟德尔随机化和中介分析，探究了牙齿疾病（牙周炎、龋齿）与肺癌之间的因果关系。研究发现，龋齿与肺癌（尤其是鳞状细胞肺癌）风险存在显著的正向因果效应，且肺功能下降在其中发挥部分中介作用。然而，牙周炎与肺癌之间未发现因果关联。这些结果提示，龋齿是肺癌风险的一个潜在因果因素，强调了将口腔健康和肺功能监测纳入癌症预防策略的重要性。

> **摘要翻译:** 牙周炎和龋齿是影响全球数十亿人的常见口腔疾病。尽管观察性研究表明这些疾病与肺癌之间存在关联，但因果关系仍不确定。本研究采用双样本孟德尔随机化（MR）方法，探讨牙齿特征（牙周炎、龋齿）与肺癌亚型之间的因果关系，并评估肺功能的中介作用。遗传工具来源于现有最大规模的全基因组关联研究，包括来自487,823例龋齿和506,594例牙周炎病例的数据，以及来自肺癌跨学科研究联盟的肺癌数据。逆方差加权是主要的分析方法；肺功能中介作用通过delta方法评估。结果显示，龋齿对整体肺癌及其亚型具有显著的正向因果效应。具体而言，龋齿发生率每增加一个标准差，鳞状细胞肺癌风险增加188.0%（OR = 2.880，95% CI = 1.236–6.713，p = 0.014），且部分由用力肺活量（FVC）和一秒用力呼气量（FEV1）的下降介导，分别占总效应的5.124%和5.890%。未发现牙周炎的因果效应。这些发现强调了龋齿在肺癌风险中的因果作用，并支持将口腔护理和肺功能监测整合到癌症预防策略中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [87] [PLOT-TAL: Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization](https://arxiv.org/abs/2403.18915)
> *PLOT-TAL：基于最优传输的少样本时序动作定位提示学习*

*Edward Fish, Andrew Gilbert* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 少样本时序动作定位, 提示学习, 最优传输, 多提示集成, 动作定位

**Comment:** Accepted to ICCVWS

> **TL;DR:** PLOT-TAL通过多提示集成和最优传输，解决了少样本时序动作定位中单提示微调边界不精确的问题，实现了SOTA性能。

**AI_Comments:** 本文的创新点在于提出了多提示集成结合最优传输（OT）的新范式来解决少样本时序动作定位中的边界精度问题。通过鼓励提示专门化于动作的组成子事件，并利用OT进行全局最优对齐，有效克服了传统单提示微调的局限性。其无需复杂元学习即可达到SOTA的性能，显示了该方法的实用性和有效性，特别是在需要高精度边界的任务中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的少样本时序动作定位（TAL）方法在通过单提示微调大型模型时，难以生成精确的时序边界，因为模型从稀疏数据中学到的是非判别性的平均表示，这损害了泛化能力。

**Method:** 提出了一种基于多提示集成的新范式，为每个动作鼓励一组多样化、可学习的提示专门化于组成子事件。引入了PLOT-TAL框架，该框架利用最优传输（OT）来寻找提示集成与视频时序特征之间的全局最优对齐。

**Result:** 在THUMOS'14和EPIC-Kitchens这两个具有挑战性的少样本基准测试中，无需复杂的元学习，建立了新的最先进性能，尤其是在高IoU阈值下取得了显著的性能提升。

**Conclusion:** 显著的性能提升，特别是在高IoU阈值下，验证了作者的假设，并证明了学习分布式、组合表示对于精确时序定位的优越性。

> **ai_Abstract:** 本文提出了PLOT-TAL，一种用于少样本时序动作定位的新框架，旨在解决现有方法在边界精度上的不足。通过引入多提示集成和利用最优传输（OT）实现提示与视频特征的全局最优对齐，PLOT-TAL鼓励提示专门化于动作的组成子事件，从而学习分布式、组合表示。实验结果表明，该方法在THUMOS'14和EPIC-Kitchens基准测试中达到了新的SOTA性能，特别是在高IoU阈值下表现出色，证明了其在精确时序定位方面的优越性。

> **摘要翻译:** 少样本时序动作定位（TAL）方法通过单提示微调大型模型时，往往无法生成精确的时序边界。这源于模型从稀疏数据中学到了动作的非判别性平均表示，从而损害了泛化能力。我们通过提出一种基于多提示集成的新范式来解决这个问题，其中鼓励为每个动作设计一组多样化、可学习的提示，使其专门化于组成子事件。为了强制实现这种专业化，我们引入了PLOT-TAL框架，该框架利用最优传输（OT）来寻找提示集成与视频时序特征之间的全局最优对齐。我们的方法在THUMOS'14和EPIC-Kitchens这两个具有挑战性的少样本基准测试中，无需复杂的元学习，建立了新的最先进性能。显著的性能提升，特别是在高IoU阈值下，验证了我们的假设，并证明了学习分布式、组合表示对于精确时序定位的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [91] [Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection](https://arxiv.org/abs/2507.18481)
> *Q-Former自编码器：一种现代医学异常检测框架*

*Francesco Dalmonte, Emirhan Bayar, Emre Akbas, Mariana-Iuliana Georgescu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学异常检测, 自编码器, Q-Former, 视觉基础模型, 无监督学习

**Comment:** 15 pages

> **TL;DR:** 本文提出了一种名为Q-Former自编码器的新型无监督医学异常检测框架，它利用预训练的视觉基础模型作为特征提取器，并在多个医学异常检测基准上实现了最先进的性能，证明了基础模型在医学图像分析中的泛化能力。

**AI_Comments:** 这项工作的创新之处在于其巧妙地结合了预训练的视觉基础模型和Q-Former架构，以解决医学图像异常检测中数据标注不足的挑战。通过利用冻结的基础模型，该框架展现了卓越的泛化能力，无需对特定医学领域进行微调，这大大降低了开发成本和数据依赖性。其在多个基准测试中取得的最先进结果，突显了该方法在临床应用中的巨大潜力，为未来医学图像分析提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像中的异常检测是一项重要但具有挑战性的任务，因为异常的多样性以及难以收集全面的标注数据集。

**Method:** 本文提出了一种现代化的基于自编码器的框架——Q-Former自编码器，用于无监督医学异常检测。该框架利用DINO、DINOv2和Masked Autoencoder等最先进的预训练视觉基础模型作为特征提取器，无需从头训练编码器。它将Q-Former架构用作瓶颈，以控制重建序列的长度并有效聚合多尺度特征。此外，还引入了使用预训练Masked Autoencoder特征计算的感知损失，以指导重建趋向语义上有意义的结构。

**Result:** 该框架在四个不同的医学异常检测基准上进行了评估，并在BraTS2021、RESC和RSNA数据集上取得了最先进的结果。

**Conclusion:** 研究结果强调了在自然图像上预训练的视觉基础模型编码器，无需进一步微调，就能有效泛化到医学图像分析任务的潜力。

> **ai_Abstract:** 本文提出了一种名为Q-Former自编码器的新型无监督医学异常检测框架。该框架利用冻结的预训练视觉基础模型（如DINO、DINOv2、MAE）作为特征提取器，避免了从头训练编码器和领域特定微调的需求。通过将Q-Former作为瓶颈，它能有效控制重建序列长度并聚合多尺度特征。此外，引入了基于预训练MAE的感知损失以优化重建质量。该方法在BraTS2021、RESC和RSNA等多个医学异常检测基准上取得了最先进的性能，证明了基础模型在医学图像分析任务中的强大泛化能力。

> **摘要翻译:** 医学图像中的异常检测是一项重要但具有挑战性的任务，因为可能存在的异常多样性以及实际不可能收集到全面的标注数据集。在这项工作中，我们提出了一种现代化的、基于自编码器的框架——Q-Former自编码器，来解决无监督医学异常检测问题。该框架利用了最先进的预训练视觉基础模型，例如DINO、DINOv2和Masked Autoencoder。我们不从头开始训练编码器，而是直接利用冻结的视觉基础模型作为特征提取器，从而无需特定领域的微调即可获得丰富、多阶段、高层次的表示。我们建议使用Q-Former架构作为瓶颈，这使得能够控制重建序列的长度，同时有效聚合多尺度特征。此外，我们结合了使用预训练Masked Autoencoder特征计算的感知损失，指导重建趋向语义上有意义的结构。我们的框架在四个不同的医学异常检测基准上进行了评估，并在BraTS2021、RESC和RSNA上取得了最先进的结果。我们的结果突出了在自然图像上预训练的视觉基础模型编码器，无需进一步微调，就能有效泛化到医学图像分析任务的潜力。我们已在https://github.com/emirhanbayar/QFAE发布了代码和模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [93] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
> *Detail++: 文本到图像扩散模型的免训练细节增强器*

*Lifeng Chen, Jiner Wang, Zihao Pan, Beier Zhu, Xiaofeng Yang, Chi Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 文本到图像, 扩散模型, 细节增强, 免训练, 渐进式细节注入

**Comment:** 

> **TL;DR:** Detail++是一个免训练的框架，通过分阶段的细节注入和注意力机制，解决文本到图像模型在处理复杂多主体提示时细节和属性绑定不足的问题。

**AI_Comments:** Detail++的创新之处在于其免训练的特性和模仿人类绘画过程的分阶段细节注入策略（PDI），这使其能够有效处理复杂提示下的多主体细节和属性绑定问题。质心对齐损失的引入也进一步提升了属性一致性。该方法为文本到图像生成领域提供了一个实用且高性能的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像生成模型在处理包含多个具有不同属性的主体的复杂提示时面临显著挑战，难以实现准确的细节和属性绑定。

**Method:** 该论文提出了一个名为Detail++的免训练框架，引入了渐进式细节注入（PDI）策略。它将复杂提示分解为一系列简化的子提示，分阶段引导生成过程，利用自注意力机制确保全局构图，然后进行精确细化。为实现属性与主体之间的精确绑定，该方法利用交叉注意力机制，并在测试时引入质心对齐损失（Centroid Alignment Loss）来减少绑定噪声和增强属性一致性。

**Result:** 在T2I-CompBench和新构建的风格合成基准测试中进行的广泛实验表明，Detail++显著优于现有方法，特别是在涉及多个对象和复杂风格条件的情况下。

**Conclusion:** Detail++通过其创新的分阶段细节注入和注意力机制，有效解决了文本到图像模型在复杂提示下的细节和属性绑定挑战，显著提升了生成质量。

> **ai_Abstract:** Detail++是一个免训练的文本到图像扩散模型细节增强框架，旨在解决复杂提示下多主体属性绑定不准确的问题。该框架模仿人类绘画过程，采用渐进式细节注入（PDI）策略，将复杂提示分解为子提示分阶段生成，并结合自注意力进行全局构图控制。为确保属性与主体的精确绑定，Detail++利用交叉注意力并引入质心对齐损失。实验证明，Detail++在处理多对象和复杂风格条件时，性能显著优于现有方法。

> **摘要翻译:** 最近文本到图像（T2I）生成技术的进步带来了令人印象深刻的视觉效果。然而，这些模型在处理复杂提示时仍面临重大挑战，特别是那些涉及多个具有不同属性的主体的提示。受人类绘画过程的启发，即首先勾勒出构图，然后逐步添加细节，我们提出了Detail++，这是一个免训练的框架，引入了一种新颖的渐进式细节注入（PDI）策略来解决这一限制。具体来说，我们将复杂提示分解为一系列简化的子提示，分阶段引导生成过程。这种分阶段生成利用自注意力的固有布局控制能力，首先确保全局构图，然后进行精确细化。为了实现属性与相应主体之间的精确绑定，我们利用交叉注意力机制，并在测试时进一步引入质心对齐损失（Centroid Alignment Loss）以减少绑定噪声并增强属性一致性。在T2I-CompBench和新构建的风格合成基准测试中进行的广泛实验表明，Detail++显著优于现有方法，特别是在涉及多个对象和复杂风格条件的情况下。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [109] [Comparison of Segmentation Methods in Remote Sensing for Land Use Land Cover](https://arxiv.org/abs/2507.18099)
> *遥感土地利用土地覆盖分割方法比较*

*Naman Srivastava, Joel D Joy, Yash Dixit, Swarup E, Rakshit Ramesh* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 土地利用土地覆盖, 分割, 遥感, DeeplabV3+, 交叉伪监督

**Comment:** 

> **TL;DR:** 本研究评估了先进的土地利用土地覆盖（LULC）测绘技术，结合了基于查找表的大气校正、监督和半监督学习模型（DeeplabV3+和动态加权CPS），并在印度海得拉巴的案例研究中展示了其在城市规划中的实用性。

**AI_Comments:** 本文的创新之处在于结合大气校正和先进的半监督学习模型（如DeeplabV3+和动态加权CPS）进行LULC测绘。其重要性体现在关注实际城市规划应用，并通过真实的案例研究验证了技术的实用性。摘要中未明确提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 土地利用土地覆盖（LULC）测绘对于城市和资源规划至关重要，是发展智慧和可持续城市的关键要素之一。本研究旨在评估先进的LULC测绘技术。

**Method:** 本研究评估了先进的LULC测绘技术，重点关注应用于Cartosat多光谱（MX）传感器图像的基于查找表（LUT）的大气校正，随后使用监督和半监督学习模型进行LULC预测。研究探索了DeeplabV3+和交叉伪监督（CPS）模型，其中CPS模型通过动态加权进一步优化，以增强训练期间伪标签的可靠性。

**Result:** 该综合方法分析了LULC测绘技术在各种城市规划应用中的准确性和实用性。以印度海得拉巴为例，通过分析Cartosat MX图像随时间的变化，揭示了由于快速城市化导致的显著土地利用变化，如城市扩张、绿地萎缩和工业区扩大。

**Conclusion:** 本研究证明了这些LULC测绘技术对城市规划者和政策制定者的实际效用。

> **ai_Abstract:** 本论文评估了对城市和资源规划至关重要的先进土地利用土地覆盖（LULC）测绘技术。研究对Cartosat多光谱（MX）传感器图像应用了基于查找表（LUT）的大气校正，并结合了监督和半监督学习模型，特别是DeeplabV3+和经动态加权优化的交叉伪监督（CPS）模型，进行LULC预测。通过对印度海得拉巴的案例研究，分析了这些技术的准确性和实用性，揭示了城市扩张、绿地萎缩等显著的土地利用变化，从而证明了它们在城市规划中的实际价值。

> **摘要翻译:** 土地利用土地覆盖（LULC）测绘对于城市和资源规划至关重要，是发展智慧和可持续城市的关键要素之一。本研究评估了先进的LULC测绘技术，重点关注应用于Cartosat多光谱（MX）传感器图像的基于查找表（LUT）的大气校正，随后使用监督和半监督学习模型进行LULC预测。我们探索了DeeplabV3+和交叉伪监督（CPS）模型。CPS模型通过动态加权进一步优化，以增强训练期间伪标签的可靠性。这种综合方法分析了LULC测绘技术在各种城市规划应用中的准确性和实用性。以印度海得拉巴为例，揭示了由于快速城市化导致的显著土地利用变化。通过分析Cartosat MX图像随时间的变化，我们突出了城市扩张、绿地萎缩和工业区扩大等转变。这证明了这些技术对城市规划者和政策制定者的实际效用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [112] [Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual Prompts](https://arxiv.org/abs/2407.02075)
> *标记一切：基于视觉提示的多类别少样本语义分割*

*Pasquale De Marinis, Nicola Fanelli, Raffaele Scaringi, Emanuele Colonna, Giuseppe Fiameni, Gennaro Vessio, Giovanna Castellano* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 少样本语义分割, 视觉提示, 多类别, 端到端训练, 泛化能力

**Comment:** 

> **TL;DR:** 提出Label Anything，一个新颖的少样本语义分割模型，通过引入多种视觉提示并支持多类别端到端训练，实现了卓越的泛化能力和SOTA性能。

**AI_Comments:** Label Anything的创新之处在于其引入了多样化的视觉提示（点、边界框、掩码）来替代单一的掩码标注，极大地增强了少样本语义分割模型的灵活性和通用性。此外，其实现多类别FSS的端到端训练，无需重新训练即可适应不同配置的能力，是模型实用性和效率的关键突破，使其能够更广泛地应用于各种复杂的分割任务。在COCO-$20^i$上取得SOTA结果也验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 传统少样本语义分割方法主要依赖掩码进行标注，限制了框架的通用性和适应性。

**Method:** 提出Label Anything，一个神经网络架构，通过引入点、边界框和掩码等多种视觉提示来增强框架的通用性和适应性。该方法支持多类别少样本语义分割的端到端训练，无需重新训练即可从不同的支持集配置中学习，适用于各种N-way K-shot配置。

**Result:** 在COCO-$20^i$基准测试中取得了最先进的结果，证明了其强大的泛化能力和灵活性。

**Conclusion:** Label Anything通过引入多样化的视觉提示和实现多类别FSS的端到端训练，显著提升了少样本语义分割的通用性、适应性和泛化能力，并在标准基准上实现了卓越性能。

> **ai_Abstract:** 本文提出了Label Anything，一个用于少样本语义分割（FSS）的新型神经网络架构。该模型通过引入点、边界框和掩码等多种视觉提示，并支持多类别FSS的端到端训练，解决了传统FSS方法通用性受限的问题。Label Anything无需重新训练即可适应多种支持集配置和N-way K-shot场景，显著降低了计算需求，并提升了模型的适应性和泛化能力。在COCO-$20^i$基准测试中，该模型取得了最先进的性能。

> **摘要翻译:** 我们提出了Label Anything，一种创新的神经网络架构，专为少样本语义分割（FSS）设计，它在每个类别仅需少量示例的情况下，在多个类别中展现出卓越的泛化能力。与主要依赖掩码来标注支持图像的传统FSS方法不同，Label Anything引入了各种视觉提示——点、边界框和掩码——从而增强了框架的多功能性和适应性。我们方法的独特之处在于，Label Anything专为多类别FSS场景下的端到端训练而设计，能够高效地从多样化的支持集配置中学习，而无需重新训练。这种方法使得它能够“通用”应用于各种FSS挑战，从1-way 1-shot到复杂的N-way K-shot配置，同时对特定类别示例的数量保持无关。这种创新的训练策略减少了计算需求，并大幅提高了模型在不同分割任务中的适应性和泛化能力。我们全面的实验验证，特别是在COCO-$20^i$基准测试中取得了最先进的结果，突显了Label Anything强大的泛化能力和灵活性。源代码已公开：https://github.com/pasqualedem/LabelAnything。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [115] [LMM-Det: Make Large Multimodal Models Excel in Object Detection](https://arxiv.org/abs/2507.18300)
> *LMM-Det: 让大型多模态模型在目标检测中表现出色*

*Jincheng Li, Chunyu Xie, Ji Ao, Dawei Leng, Yuhui Yin* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 大型多模态模型, 目标检测, LMM-Det, 召回率, 数据分布调整

**Comment:** Accepted at ICCV 2025

> **TL;DR:** LMM-Det提出了一种简单有效的方法，使大型多模态模型无需专用检测模块即可在目标检测中表现出色，通过数据分布调整和推理优化提高召回率。

**AI_Comments:** LMM-Det的创新之处在于其“简单而有效”的方法，它挑战了传统观念，即大型多模态模型进行目标检测需要集成笨重的专业检测器。通过巧妙的数据分布调整和推理优化，以及指令对话重组，该工作成功地证明了LMM本身具备潜在的检测能力，这对于推动LMMs在更广泛视觉任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型多模态模型（LMMs）在图像字幕、视觉问答等任务中表现出色，但在目标检测方面与专业检测器存在显著差距。本研究旨在弥补这一差距，避免集成笨重的检测器。

**Method:** LMM-Det提出了一种简单有效的方法，不依赖专门的检测模块，使大型多模态模型进行目标检测。具体方法包括：对LMM与目标检测结合的综合探索性分析，发现召回率显著下降；通过引入为目标检测量身定制的数据分布调整和推理优化来提高召回率；重新组织指令对话以增强大型多模态模型的目标检测能力。

**Result:** 广泛的实验支持了LMM-Det的论点，即大型多模态模型在没有任何额外检测模块的情况下也具备检测能力，并展示了LMM-Det的多功能性和有效性。

**Conclusion:** 本研究声称大型多模态模型无需任何额外检测模块即可具备检测能力，并通过LMM-Det这一简单有效的方法，通过数据分布调整和推理优化，显著提高了LMM在目标检测任务中的召回率和整体性能。

> **ai_Abstract:** LMM-Det提出了一种新颖且有效的方法，旨在弥补大型多模态模型（LMMs）在目标检测方面与专业检测器之间的差距。该方法不依赖于集成额外的检测模块，而是通过对LMM与目标检测结合的深入分析，发现召回率的下降。为解决此问题，LMM-Det引入了数据分布调整、推理优化以及指令对话重组，以提升LMMs的目标检测能力。实验证明，LMM-Det能够使LMM在不增加专用检测模块的情况下，有效执行目标检测任务，并展现出优异的性能。

> **摘要翻译:** 大型多模态模型（LMMs）凭借其在多模态理解、推理和上下文学习等方面的卓越能力，在人工智能研究和工业界引起了广泛关注和兴趣。尽管LMMs在处理图像字幕、视觉问答和视觉基础等多种多模态任务中表现出良好的前景，但LMMs的目标检测能力与专业检测器相比存在显著差距。为了弥补这一差距，我们摒弃了将笨重检测器与LMMs集成的传统方法，提出了一种简单而有效的方法LMM-Det，该方法利用大型多模态模型进行普通目标检测，而无需依赖专门的检测模块。具体来说，我们对大型多模态模型与目标检测结合时进行了全面的探索性分析，发现与专业检测模型相比，召回率显著下降。为了缓解这一问题，我们提出通过引入针对目标检测量身定制的数据分布调整和推理优化来提高召回率。我们重新组织了指令对话，以增强大型多模态模型的目标检测能力。我们声称大型多模态模型无需任何额外检测模块即可具备检测能力。广泛的实验支持了我们的主张，并展示了多功能LMM-Det的有效性。数据集、模型和代码可在https://github.com/360CVGroup/LMM-Det获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [121] [DRWKV: Focusing on Object Edges for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18594)
> *DRWKV: 聚焦物体边缘的低光图像增强*

*Xuecheng Bai, Yuxiang Wang, Boyu Hu, Qinyuan Jie, Chuanzhi Xu, Hongru Xiao, Kechen Li, Vera Chung* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 低光图像增强, 边缘保持, Retinex, 注意力机制, DRWKV

**Comment:** 

> **TL;DR:** DRWKV是一种新颖的低光图像增强模型，通过结合全局边缘Retinex理论、演化WKV注意力机制以及双边光谱对齐器，有效解耦光照和边缘结构，提升边缘保真度、空间连续性和视觉自然度，并在多项基准测试中取得了领先的性能。

**AI_Comments:** 该论文通过引入全局边缘Retinex理论、演化WKV注意力机制和双边光谱对齐器等创新组件，有效解决了低光图像增强中边缘保持和细节恢复的难题。其在性能、计算效率和泛化能力方面的表现，预示着该模型在实际应用中具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 低光图像增强是一个具有挑战性的任务，尤其是在极端光照退化下，保持物体边缘连续性和精细结构细节方面存在困难。

**Method:** 本文提出了一种名为DRWKV（详细感受野加权键值）的新模型。该模型整合了以下三个主要部分：1. 全局边缘Retinex（GER）理论，用于有效解耦光照和边缘结构，增强边缘保真度。2. 演化WKV注意力机制，采用螺旋扫描机制捕获空间边缘连续性并更有效地建模不规则结构。3. 双边光谱对齐器（Bi-SAB）和定制的MS2-Loss，共同对齐亮度和色度特征，以提高视觉自然度并减少伪影。

**Result:** DRWKV在五个低光图像增强（LLIE）基准测试中表现出领先的性能（PSNR、SSIM和NIQE），同时保持较低的计算复杂度。此外，DRWKV还增强了低光多目标跟踪下游任务的性能，验证了其泛化能力。

**Conclusion:** DRWKV模型通过其独特的设计，在低光图像增强方面取得了显著进展，特别是在边缘保持和细节恢复方面，并展现出良好的泛化能力和计算效率。

> **ai_Abstract:** DRWKV是一种用于低光图像增强的新模型，旨在解决极端光照下边缘和细节保持的挑战。该模型包含三项创新：全局边缘Retinex（GER）理论用于解耦光照和边缘，演化WKV注意力机制用于捕获空间连续性，以及双边光谱对齐器（Bi-SAB）与MS2-Loss用于优化亮度和色度特征。实验证明，DRWKV在多个基准测试中实现了卓越的性能、低计算复杂度，并提升了下游多目标跟踪任务的表现，验证了其有效性和泛化能力。

> **摘要翻译:** 低光图像增强仍然是一项具有挑战性的任务，特别是在极端光照退化下，保持物体边缘连续性和精细结构细节方面。在本文中，我们提出了一种新颖的模型DRWKV（详细感受野加权键值），它整合了我们提出的全局边缘Retinex（GER）理论，能够有效解耦光照和边缘结构，从而增强边缘保真度。其次，我们引入了演化WKV注意力机制，这是一种螺旋扫描机制，能够捕获空间边缘连续性并更有效地建模不规则结构。第三，我们设计了双边光谱对齐器（Bi-SAB）和定制的MS2-Loss，以共同对齐亮度和色度特征，提高视觉自然度并减轻伪影。在五个LLIE基准测试上的大量实验表明，DRWKV在PSNR、SSIM和NIQE方面取得了领先的性能，同时保持较低的计算复杂度。此外，DRWKV增强了低光多目标跟踪任务的下游性能，验证了其泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [128] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
> *FishDet-M：一个用于多样水生视觉领域中鲁棒鱼类检测和CLIP引导模型选择的统一大规模基准*

*Muayad Abujabal, Lyes Saad Saoud, Irfan Hussain* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-23**

**Keywords:** 鱼类检测, 水下图像, 基准测试, 目标检测, CLIP, 模型选择

**Comment:** 

> **TL;DR:** FishDet-M是目前最大的统一鱼类检测基准，整合了13个公共数据集，并对28个目标检测模型进行了系统性基准测试。它还引入了一个基于CLIP的模型选择框架，以实现复杂水下场景中的自适应部署，提高检测性能。

**AI_Comments:** FishDet-M的创新之处在于其作为迄今为止最大的统一鱼类检测基准，通过整合和标准化多源数据集，有效解决了现有研究中数据碎片化和评估不一致的痛点。其引入的CLIP引导模型选择框架，通过零样本动态选择最适合的检测器，为实时水下应用提供了实用的自适应解决方案，显著提升了模型部署的灵活性和效率。这项工作为水下计算机视觉和智能海洋系统的发展奠定了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 水下图像中的精确鱼类检测对于生态监测、水产养殖自动化和机器人感知至关重要。然而，由于数据集碎片化、成像条件异构以及评估协议不一致，实际部署受到了限制。本研究旨在解决这些不足。

**Method:** 本研究提出了FishDet-M，这是最大的统一鱼类检测基准，包含13个跨海洋、咸水、遮挡和水族馆场景的公开数据集。所有数据都使用COCO风格的边界框和分割掩码进行统一标注。系统性地基准测试了28个当代目标检测模型，包括YOLOv8到YOLOv12系列、基于R-CNN的检测器和基于DETR的模型。评估使用mAP、mAP@50、mAP@75等标准指标，以及尺度特异性分析（AP$_S$、AP$_M$、AP$_L$）和推理性能分析（延迟和参数数量）。此外，引入了一个基于CLIP的模型选择框架，利用视觉-语言对齐来动态识别每个输入图像最语义合适的检测器，实现零样本选择。

**Result:** 结果显示，在FishDet-M上训练的不同模型检测性能各异，并且不同架构的模型在准确性和效率之间存在权衡。所提出的基于CLIP的零样本模型选择策略在不需要集成计算的情况下实现了高性能。

**Conclusion:** FishDet-M为复杂水生场景中的目标检测评估建立了一个标准化且可复现的平台。所有数据集、预训练模型和评估工具均已公开，以促进水下计算机视觉和智能海洋系统领域的未来研究。

> **ai_Abstract:** 本研究提出了FishDet-M，一个统一的大规模鱼类检测基准，整合了13个多样水生数据集并统一标注，旨在解决现有鱼类检测中数据集分散、评估不一致的问题。该基准系统性地评估了28种主流目标检测模型，分析了它们的性能和效率权衡。此外，论文引入了一种基于CLIP的零样本模型选择框架，能够根据图像内容动态选择最合适的检测器，从而在无需集成计算的情况下实现高效的自适应部署。FishDet-M为水下计算机视觉研究提供了一个标准化的评估平台。

> **摘要翻译:** 水下图像中精确的鱼类检测对于生态监测、水产养殖自动化和机器人感知至关重要。然而，由于数据集碎片化、成像条件异构以及评估协议不一致，实际部署仍然受到限制。为了解决这些空白，我们提出了FishDet-M，这是最大的统一鱼类检测基准，包含13个涵盖海洋、咸水、遮挡和水族馆场景等多样水生环境的公开数据集。所有数据都使用COCO风格的边界框和分割掩码进行统一标注，从而实现一致且可扩展的跨域评估。我们系统性地基准测试了28个当代目标检测模型，涵盖YOLOv8到YOLOv12系列、基于R-CNN的检测器和基于DETR的模型。评估使用包括mAP、mAP@50和mAP@75在内的标准指标，以及尺度特异性分析（AP$_S$、AP$_M$、AP$_L$）和延迟、参数数量方面的推理性能分析。结果突出了在FishDet-M上训练的不同模型检测性能的差异，以及不同架构模型在准确性和效率之间的权衡。为了支持自适应部署，我们引入了一个基于CLIP的模型选择框架，该框架利用视觉-语言对齐来动态识别每个输入图像最语义合适的检测器。这种零样本选择策略在不需要集成计算的情况下实现了高性能，为实时应用提供了可扩展的解决方案。FishDet-M为复杂水生场景中的目标检测评估建立了一个标准化且可复现的平台。所有数据集、预训练模型和评估工具均已公开，以促进水下计算机视觉和智能海洋系统领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [131] [A COCO-Formatted Instance-Level Dataset for Plasmodium Falciparum Detection in Giemsa-Stained Blood Smears](https://arxiv.org/abs/2507.18483)
> *适用于吉姆萨染色血涂片中恶性疟原虫检测的COCO格式实例级数据集*

*Frauke Wilm, Luis Carlos Rivera Monroy, Mathias Öttl, Lukas Mürdter, Leonid Mill, Andreas Maier* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 恶性疟原虫, 疟疾检测, COCO数据集, 深度学习, 目标检测

**Comment:** 7 pages, 4 figures, 2 tables, accepted at MICCAI 2025 Open Data

> **TL;DR:** 本文提出了一个COCO格式的恶性疟原虫实例级检测数据集，通过Faster R-CNN模型验证，在疟疾诊断中取得了高F1分数，并强调了高质量注释的重要性。

**AI_Comments:** 该论文通过创建并公开一个急需的COCO格式实例级疟疾数据集，为深度学习在自动化疟疾诊断领域的应用提供了重要支持。其结合自动化与人工校正的混合注释方法，为医疗图像数据集的构建提供了一个实用且高效的范例，对于推动相关研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在自动化疟疾诊断方面潜力巨大，但其应用受限于缺乏详细的实例级注释数据集，尤其是在吉姆萨染色血涂片中准确检测恶性疟原虫是可靠诊断的关键。

**Method:** 作者提供了一个增强版的NIH疟疾公开数据集，其中包含COCO格式的详细边界框注释，以支持目标检测训练。他们通过训练一个Faster R-CNN模型来检测受感染和未受感染的红细胞以及白细胞，从而验证了修订后的注释。

**Result:** 在原始数据集上进行交叉验证，受感染细胞检测的F1分数高达0.88。

**Conclusion:** 结果表明，注释的数量和一致性至关重要，并且自动化注释优化结合有针对性的人工校正可以生成足以支持鲁棒检测性能的高质量训练数据。

> **ai_Abstract:** 本文针对深度学习在自动化疟疾诊断中面临的实例级注释数据集稀缺问题，提出了一个增强版的NIH疟疾数据集，该数据集采用COCO格式并包含详细的边界框注释。通过训练Faster R-CNN模型进行验证，该数据集在受感染细胞检测上实现了高达0.88的F1分数。研究结果强调了注释数量和一致性的重要性，并证明了自动化注释优化结合人工校正能够生成高质量的训练数据，从而提升检测性能。该更新后的注释集已公开可用。

> **摘要翻译:** 在吉姆萨染色血涂片中准确检测恶性疟原虫是可靠疟疾诊断的重要组成部分，尤其是在发展中国家。基于深度学习的目标检测方法在自动化疟疾诊断方面显示出巨大潜力，但由于缺乏详细的实例级注释数据集，其应用受到限制。在这项工作中，我们提出了一个公开可用的NIH疟疾数据集的增强版本，其中包含COCO格式的详细边界框注释，以支持目标检测训练。我们通过训练一个Faster R-CNN模型来检测受感染和未受感染的红细胞以及白细胞，从而验证了修订后的注释。在原始数据集上进行交叉验证，受感染细胞检测的F1分数高达0.88。这些结果强调了注释数量和一致性的重要性，并表明自动化注释优化与有针对性的人工校正相结合，可以生成足以支持鲁棒检测性能的训练数据。更新后的注释集已通过GitHub公开提供：https://github.com/MIRA-Vision-Microscopy/malaria-thin-smear-coco。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [137] [PreMix: Label-Efficient Multiple Instance Learning via Non-Contrastive Pre-training and Feature Mixing](https://arxiv.org/abs/2408.01162)
> *PreMix：通过非对比预训练和特征混合实现标签高效的多示例学习*

*Bryan Wong, Mun Yong Yi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 多示例学习, 全玻片图像, 非对比预训练, 标签效率, 特征混合

**Comment:** Under review

> **TL;DR:** PreMix是一种新的多示例学习（MIL）框架，通过非对比预训练和特征混合，在有限的标记全玻片图像（WSI）数据下显著提高了WSI分类的性能。

**AI_Comments:** PreMix的创新点在于将非对比预训练（Barlow Twins）与Slide Mixing相结合，以解决MIL聚合器在有限标记数据下预训练不足的问题。这种方法有效地利用了未标记的WSI数据，显著提高了模型性能和鲁棒性，对于临床病理学应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前多示例学习（MIL）方法在全玻片图像（WSI）分类中存在一个关键限制，即MIL聚合器对预训练的利用不足。大多数现有方法随机初始化聚合器并从头开始训练，这使得性能对标记WSI的数量高度敏感，并且忽略了临床环境中常见的未标记WSI的丰富性。

**Method:** PreMix框架利用非对比预训练方法Barlow Twins，并结合Slide Mixing方法生成额外的正样本对以增强特征学习。在微调阶段，通过Mixup和Manifold Mixup进一步增强鲁棒性，以有效处理不同大小的千兆像素WSI。

**Result:** 将PreMix作为插件模块集成到HIPT中，在各种WSI训练大小和数据集上，相比基线HIPT，F1分数平均提高了4.7%。

**Conclusion:** 这些研究结果强调了PreMix在有限标记数据下推进WSI分类的潜力及其在真实世界组织病理学实践中的适用性。

> **ai_Abstract:** PreMix是一个旨在提高标签效率的多示例学习（MIL）框架，特别针对全玻片图像（WSI）分类。该方法通过结合非对比预训练（Barlow Twins）和Slide Mixing技术来充分利用未标记数据，以增强特征学习，尤其是在标记数据有限的情况下。此外，微调阶段采用Mixup和Manifold Mixup来提高模型对不同WSI尺寸的鲁棒性。实验证明，PreMix作为HIPT的插件模块，能够显著提升WSI分类的性能。

> **摘要翻译:** 多示例学习（MIL）已成为一种强大的框架，用于弱监督全玻片图像（WSI）分类，无需详细的补丁级注释即可实现玻片级预测。尽管取得了成功，但当前MIL方法的一个关键限制在于对MIL聚合器预训练的利用不足。大多数现有方法随机初始化聚合器并从头开始训练，这使得性能对标记WSI的数量高度敏感，并且忽略了临床环境中常见的未标记WSI的丰富性。为了解决这个问题，我们提出了PreMix，一个新颖的框架，它利用非对比预训练方法Barlow Twins，并结合Slide Mixing方法生成额外的正样本对并增强特征学习，特别是在标记WSI条件有限的情况下。使用Mixup和Manifold Mixup进行微调进一步增强了鲁棒性，通过有效处理千兆像素WSI的不同大小。实验结果表明，将PreMix作为一个插件模块集成到HIPT中，在各种WSI训练大小和数据集上，相比基线HIPT，F1分数平均提高了4.7%。这些发现强调了其在有限标记数据下推进WSI分类的潜力及其在真实世界组织病理学实践中的适用性。代码可在https://github.com/bryanwong17/PreMix获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [145] [Improving Large Vision-Language Models' Understanding for Field Data](https://arxiv.org/abs/2507.18311)
> *提高大型视觉语言模型对现场数据的理解*

*Xiaomei Zhang, Hanyu Zheng, Xiangyu Zhu, Jinghuan Wei, Junhong Zou, Zhen Lei, Zhaoxiang Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 大型视觉语言模型, 现场数据, 科学研究, 数据压缩, 机器学习

**Comment:** 

> **TL;DR:** FieldLVLM 框架通过现场感知语言生成和数据压缩多模态模型微调，显著提升了大型视觉语言模型对科学现场数据的理解能力。

**AI_Comments:** 这项工作具有重要的创新性，它解决了大型视觉语言模型在处理复杂科学现场数据时的局限性。通过引入现场感知语言生成和数据压缩微调，FieldLVLM有效地将领域特定的物理特征整合到模型理解中，极大地拓宽了LVLMs在自然科学领域的应用潜力，有助于加速科学发现。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉语言模型（LVLMs）在集成视觉和文本理解的任务中表现出色，但在科学领域，特别是在解释自然科学中常用的复杂现场数据方面，应用仍未充分探索。

**Method:** 本文介绍了FieldLVLM框架，包含两个主要组件：现场感知语言生成策略和数据压缩多模态模型微调。现场感知语言生成策略利用专门的机器学习管道从现场数据中提取关键物理特征（如流分类、雷诺数、涡流模式），并将其转换为结构化文本描述作为数据集。数据压缩多模态模型微调则针对这些生成的数据集对LVLMs进行微调，使用数据压缩策略来降低现场输入的复杂性并保留最具信息量的值，以确保与模型语言解码器的兼容性并有效引导学习。

**Result:** 在最新提出的基准数据集上的实验结果表明，FieldLVLM在涉及科学现场数据的任务中显著优于现有方法。

**Conclusion:** 我们的研究结果表明，这种方法为将大型视觉语言模型应用于科学研究开辟了新的可能性，有助于弥合大型模型与领域特定发现之间的鸿沟。

> **ai_Abstract:** 该论文提出了FieldLVLM框架，旨在提升大型视觉语言模型（LVLMs）对科学现场数据的理解能力。针对LVLMs在科学领域应用不足的问题，FieldLVLM通过现场感知语言生成策略提取现场数据的关键物理特征并转化为结构化文本，同时利用数据压缩多模态模型微调技术，优化LVLMs对这些数据的学习。实验证明，FieldLVLM在处理科学现场数据的任务上显著优于现有方法，为LVLMs在科学研究中的应用开辟了新途径。

> **摘要翻译:** 大型视觉语言模型（LVLMs）在整合视觉和文本理解的一系列任务中展现出令人印象深刻的能力，例如图像标注和视觉问答。这些模型在大规模图像和视频数据集与文本配对的基础上进行训练，使其能够连接视觉感知和自然语言处理。然而，它们在科学领域的应用，特别是在解释自然科学中常用的复杂现场数据方面，仍未得到充分探索。在这项工作中，我们引入了FieldLVLM，这是一个旨在提高大型视觉语言模型对现场数据理解的新颖框架。FieldLVLM由两个主要组件构成：现场感知语言生成策略和数据压缩多模态模型微调。现场感知语言生成策略利用一个专门的机器学习管道，从现场数据中提取关键物理特征，例如流分类、雷诺数和涡流模式。然后，这些信息被转换为结构化的文本描述，作为数据集。数据压缩多模态模型微调则侧重于使用这些生成的数据集对LVLMs进行微调，采用数据压缩策略来降低现场输入的复杂性并仅保留最具信息量的值。这确保了与模型语言解码器的兼容性，并更有效地引导其学习。在最新提出的基准数据集上的实验结果表明，FieldLVLM在涉及科学现场数据的任务中显著优于现有方法。我们的发现表明，这种方法为将大型视觉语言模型应用于科学研究开辟了新的可能性，有助于弥合大型模型与领域特定发现之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [149] [Datasets and Recipes for Video Temporal Grounding via Reinforcement Learning](https://arxiv.org/abs/2507.18100)
> *基于强化学习的视频时间定位数据集与方法*

*Ruizhe Chen, Zhiting Fan, Tianze Luo, Heqing Zou, Zhaopeng Feng, Guiyang Xie, Hansheng Zhang, Zhuochen Wang, Zuozhu Liu, Huaijian Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视频时间定位, 强化学习, 监督微调, 数据集, 泛化能力

**Comment:** 

> **TL;DR:** 本文提出了一种结合监督微调和强化学习的两阶段训练框架，用于改进视频时间定位（VTG）模型，并在多个基准测试中取得了优异表现。

**AI_Comments:** 该论文的创新点在于将强化学习引入视频时间定位任务，并通过两阶段训练框架有效提升了模型的准确性和鲁棒性。其重要性体现在解决了现有VTG模型泛化能力不足的问题，并为社区提供了宝贵的数据集和代码，有助于推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频时间定位（VTG）方法，尽管在大规模视觉语言模型（LVLMs）和指令微调方面取得了进展，但往往存在时间感知能力有限和泛化能力差的问题。

**Method:** 本文提出了一种两阶段训练框架，将监督微调（SFT）与强化学习（RL）相结合，以提高VTG模型的准确性和鲁棒性。该方法首先利用高质量的冷启动数据进行SFT初始化，然后通过难度控制的强化学习进一步增强时间定位和推理能力。

**Result:** 在多个VTG基准测试上的综合实验表明，本文方法始终优于现有模型，尤其是在具有挑战性的开放领域场景中。

**Conclusion:** 深入分析训练策略和数据集构建，强调了高质量冷启动数据和难度控制强化学习的重要性。为促进进一步研究和工业应用，本文发布了所有中间数据集、模型和代码。

> **ai_Abstract:** 本文提出了一种用于视频时间定位（VTG）的两阶段训练框架，该框架结合了监督微调（SFT）和强化学习（RL）。首先使用高质量冷启动数据进行SFT初始化，然后通过难度控制的RL进一步提升模型的时间定位和推理能力。实验结果表明，该方法在多个VTG基准测试中表现优异，尤其在开放领域场景中。研究强调了高质量冷启动数据和难度控制RL的重要性，并发布了相关资源以促进社区研究。

> **摘要翻译:** 视频时间定位（VTG）旨在根据自然语言查询在视频中定位相关的时序片段。尽管大规模视觉语言模型（LVLMs）和指令微调取得了最新进展，但现有方法往往存在时间感知能力有限和泛化能力差的问题。在这项工作中，我们引入了一个两阶段训练框架，将监督微调与强化学习（RL）相结合，以提高VTG模型的准确性和鲁棒性。我们的方法首先利用高质量的精选冷启动数据进行SFT初始化，然后通过难度控制的RL进一步增强时间定位和推理能力。在多个VTG基准测试上的综合实验表明，我们的方法始终优于现有模型，尤其是在具有挑战性的开放领域场景中。我们对训练策略和数据集构建进行了深入分析，强调了高质量冷启动数据和难度控制RL的重要性。为了促进进一步的研究和工业应用，我们向社区发布了所有中间数据集、模型和代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [162] [Optimizing against Infeasible Inclusions from Data for Semantic Segmentation through Morphology](https://arxiv.org/abs/2408.14672)
> *通过形态学优化语义分割中数据导致的不可行包含问题*

*Shamik Basu, Luc Van Gool, Christos Sakaridis* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 语义分割, 不可行包含, 形态学, 约束学习, 领域偏移

**Comment:** 

> **TL;DR:** 提出InSeIn方法，通过提取空间类别关系并施加可微分形态学损失，减少语义分割中不合理的包含预测，显著提升性能。

**AI_Comments:** 这项工作通过引入领域知识（空间包含约束）来弥补纯数据驱动模型在泛化性上的不足，特别是在处理领域偏移时的“荒谬”预测。其创新点在于将形态学操作转化为可微分损失，并将其融入到深度学习的训练框架中，使得模型能够学习到更符合现实逻辑的语义关系。这种方法提供了一种通用的即插即用解决方案，对于提升语义分割模型的鲁棒性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有语义分割模型纯粹依赖数据驱动的优化，导致在输入图像域发生变化时，会出现不合理的分割结果，例如将“道路”标签分配给被“天空”标签包含的区域，这与真实数据集中的可行包含关系相悖。

**Method:** 本文提出Infeasible Semantic Inclusions (InSeIn) 方法。首先，以离线、数据驱动的方式，从语义分割训练集中提取控制空间类别关系的显式包含约束；然后，在训练过程中施加一个形态学且可微分的损失函数，惩罚违反这些约束的行为，以促进预测的可行性。InSeIn是一个轻量级即插即用的方法。

**Result:** InSeIn方法显著减少了学习分割模型预测中不可行的语义包含，并在ADE20K、Cityscapes和ACDC数据集上，在各种最先进的网络上取得了持续且显著的性能改进。

**Conclusion:** InSeIn方法通过引入显式包含约束和形态学损失，有效解决了语义分割中不合理包含预测的问题，显著提升了模型的泛化能力和预测可行性。

> **ai_Abstract:** 现有语义分割模型在领域偏移时常产生不合理分割（如道路包含天空）。本文提出InSeIn方法，通过离线提取训练数据中的空间类别包含约束，并在训练时引入一个可微分的形态学损失来惩罚违反这些约束的行为，从而提高预测的可行性。该轻量级即插即用方法在多个标准数据集上显著提升了最先进模型的性能。

> **摘要翻译:** 现有最先进的语义分割模型通常以数据驱动的方式进行优化，仅最小化训练数据上的逐像素或逐片段分类目标。这种纯粹的数据驱动范式常常导致荒谬的分割结果，尤其当输入图像的领域与训练时遇到的领域发生偏移时。例如，最先进的模型可能会将“道路”标签分配给被另一个标签为“天空”的片段所包含的片段。然而，现有数据集的真实标注表明这种包含是不可行的。我们的方法，Infeasible Semantic Inclusions (InSeIn)，首先以离线、数据驱动的方式，从现有的语义分割训练集中提取控制空间类别关系的显式包含约束，然后施加一个形态学但可微分的损失函数，在训练期间惩罚违反这些约束的行为，以促进预测的可行性。InSeIn是一种轻量级即插即用的方法，是朝着最小化学习分割模型预测中不可行语义包含迈出的新一步，并在ADE20K、Cityscapes和ACDC数据集上，在各种最先进的网络上取得了持续且显著的性能改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [163] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
> *基于生成式AI图像合成促进AI皮肤病变分类器公平性评估*

*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 公平性评估, 生成式AI, 皮肤病变分类器, 合成数据, 偏见

**Comment:** 

> **TL;DR:** 本研究利用生成式AI合成图像来评估和促进AI皮肤病变分类器的公平性。

**AI_Comments:** 这篇论文的创新点在于利用生成式AI来解决AI公平性评估中数据代表性不足的挑战，特别是在医疗图像领域。这为在敏感领域（如医疗诊断）中，面对数据隐私和稀缺性问题时，评估和提升AI系统的公平性提供了一个有价值的思路。其局限性在于指出合成数据与评估模型训练数据不一致时，公平性验证的有效性会受到影响，这提示了未来研究需要关注合成数据与真实数据分布的匹配度问题。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在皮肤癌筛查中潜力巨大，但存在不可预见的固有偏见。公平性评估的关键挑战是确保评估数据集对不同个人身份信息（PII）和少数群体具有足够的代表性。因此，评估和改进这些系统的公平性至关重要。

**Method:** 本研究利用最先进的生成式AI (GenAI) LightningDiT模型来合成高度逼真的图像，并使用这些合成数据评估公开的黑色素瘤分类器的公平性。

**Result:** 结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，当用于评估的黑色素瘤检测模型所训练的数据与合成图像所依据的数据集不同时，验证公平性变得困难。

**Conclusion:** 尽管存在挑战，本研究提出的方法为利用合成数据来衡量和增强医学影像生成式AI系统的公平性提供了一条有价值的新途径。

> **ai_Abstract:** 本研究探讨了利用生成式AI（GenAI）合成图像来评估和促进AI皮肤病变分类器公平性的方法。鉴于AI在皮肤癌筛查中可能存在的偏见，研究提出通过GenAI模型（如LightningDiT）生成代表性数据来解决评估数据不足的挑战。结果显示，使用合成数据进行公平性评估具有前景，但当评估模型与合成数据的基础数据集不一致时，公平性验证会变得困难。尽管如此，该方法为医学影像GenAI系统中的公平性评估提供了一条新途径。

> **摘要翻译:** 深度学习及其在边缘设备上的最新进展，在彻底改变黑色素瘤等皮肤癌的常规筛查方面具有巨大潜力。伴随这项技术预期效益的同时，也出现了由不可预见和固有偏见带来的潜在危险。因此，评估和改进此类系统的公平性至关重要。公平性评估的一个关键挑战是确保评估数据集能够充分代表不同的个人身份信息（PII）（性别、年龄和种族）以及其他少数群体。在此背景下，本研究利用最先进的生成式AI（GenAI）LightningDiT模型来评估公开的黑色素瘤分类器的公平性。结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，我们的发现表明，当用于评估的黑色素瘤检测模型所训练的数据与合成图像所依据的数据集不同时，验证公平性变得困难。尽管如此，我们提出我们的方法为利用合成数据来衡量和增强医学影像生成式AI系统的公平性提供了一条有价值的新途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [164] [Real-Time Object Detection and Classification using YOLO for Edge FPGAs](https://arxiv.org/abs/2507.18174)
> *边缘FPGA上使用YOLO的实时目标检测与分类*

*Rashed Al Amin, Roman Obermaisser* | **Category: cs.CV, cs.AR** | **Updated: 2025-07-24**

**Keywords:** 目标检测, YOLOv5, FPGA, 边缘计算, 实时系统

**Comment:** This paper has been accepted for the 67th International Symposium on
  ELMAR 2025

> **TL;DR:** 本文提出了一种优化后的YOLOv5系统，解决了现有YOLO在边缘FPGA上资源效率低的问题，实现了99%的准确率和低功耗的实时目标检测。

**AI_Comments:** 该论文的创新点在于针对边缘FPGA平台对YOLOv5进行了优化，解决了资源效率的挑战。其重要性体现在为ADAS等边缘计算应用提供了实用的实时目标检测解决方案。实验结果量化了其在功耗和性能上的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于YOLO的目标检测和分类系统在边缘FPGA平台上难以实现资源效率。

**Method:** 提出了一种基于YOLOv5的资源高效实时目标检测和分类系统，并针对FPGA部署进行了优化。该系统在COCO和GTSRD数据集上训练，并在Xilinx Kria KV260 FPGA板上实现。

**Result:** 实验结果表明，该系统实现了99%的分类准确率，功耗为3.5W，处理速度为9帧/秒。

**Conclusion:** 提出的方法能够有效实现边缘计算应用中的实时、资源高效目标检测和分类。

> **ai_Abstract:** 本文提出了一种针对FPGA优化的资源高效实时YOLOv5目标检测与分类系统，旨在解决现有YOLO系统在边缘FPGA上资源效率不足的问题。该系统在COCO和GTSRD数据集上训练，并在Xilinx Kria KV260 FPGA板上实现。实验结果表明，系统在低功耗下能达到99%的分类准确率和9帧/秒的处理速度，验证了其在边缘计算中实时、资源高效目标检测的有效性。

> **摘要翻译:** 目标检测和分类是各种应用领域中的关键任务，特别是在开发安全可靠的高级驾驶辅助系统（ADAS）中。现有的基于深度学习的方法，如卷积神经网络（CNNs）、单发多框检测器（SSDs）和“你只看一次”（YOLO），在部署到现场可编程门阵列（FPGAs）时，在准确性和计算速度方面都表现出高性能。然而，尽管有这些进步，最先进的基于YOLO的目标检测和分类系统在实现适用于边缘FPGA平台的资源效率方面仍面临挑战。为了解决这一限制，本文提出了一种基于YOLOv5的资源高效实时目标检测和分类系统，并针对FPGA部署进行了优化。所提出的系统在COCO和GTSRD数据集上进行训练，并在Xilinx Kria KV260 FPGA板上实现。实验结果表明，分类准确率达到99%，功耗为3.5W，处理速度为每秒9帧（FPS）。这些发现突出了所提出方法在实现边缘计算应用中实时、资源高效目标检测和分类方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [165] [A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation](https://arxiv.org/abs/2507.18323)
> *用于心电图描绘中半监督语义分割的多数据集基准*

*Minje Park, Jeonghwa Lim, Taehyung Yu, Sunghoon Joo* | **Category: cs.CV, cs.AI, cs.LG, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 心电图描绘, 半监督学习, 语义分割, 基准, Transformer

**Comment:** 6 pages, 2 figures

> **TL;DR:** 首个用于心电图描绘中半监督语义分割的系统基准，整合多数据集，评估多种算法和架构，发现Transformer优于CNN。

**AI_Comments:** 该论文通过利用半监督学习解决了医学图像领域数据稀缺的关键实际问题。创建多数据集基准对社区非常有价值，为未来的研究提供了标准化平台。特别针对半监督心电图描绘对CNN和Transformer进行的比较是一个重要发现，可指导未来的模型选择。所提出的心电图特定配置和评估框架进一步增强了其实用性。其创新之处在于建立了全面的基准，并为一项具有挑战性的医学任务提供了模型性能的实用见解。

<details>
  <summary>Details</summary>

**Motivation:** 心电图描绘对临床诊断至关重要。尽管深度学习取得了进展，但由于公开可用标注数据集的稀缺，其进展受到限制。半监督学习通过利用大量未标注的心电图数据，提供了一个有前景的解决方案。

**Method:** 本研究提出了首个用于心电图描绘中半监督语义分割（SemiSeg）的系统基准。我们整理并统一了多个公共数据集，包括以前未充分利用的来源，以支持鲁棒和多样化的评估。我们采用了计算机视觉领域的五种代表性SemiSeg算法，并在卷积网络和Transformer两种不同架构上实现，在域内和跨域两种不同设置下进行评估。此外，我们提出了心电图特有的训练配置和数据增强策略，并引入了标准化的评估框架。

**Result:** 我们的结果表明，在半监督心电图描绘中，Transformer的表现优于卷积网络。

**Conclusion:** 我们预期我们的基准将作为推进半监督心电图描绘方法的基础，并促进该领域的进一步研究。

> **ai_Abstract:** 本研究提出了首个用于心电图描绘中半监督语义分割的系统基准，旨在解决标注数据稀缺的问题。该研究整合了多个公共数据集，在不同设置下，使用卷积网络和Transformer架构评估了五种半监督算法，并提出了心电图特有的训练和评估标准。关键结果表明，Transformer在该任务中表现优于卷积网络，为未来半监督心电图分析研究提供了基础资源。

> **摘要翻译:** 心电图（ECG）描绘，即有意义波形特征的分割，对于临床诊断至关重要。尽管深度学习最近取得了进展，但由于公开可用标注数据集的稀缺，其进展受到限制。半监督学习通过利用大量未标注的心电图数据，提供了一个有前景的解决方案。在本研究中，我们提出了首个用于心电图描绘中半监督语义分割（SemiSeg）的系统基准。我们整理并统一了多个公共数据集，包括以前未充分利用的来源，以支持鲁棒和多样化的评估。我们采用了计算机视觉领域的五种代表性SemiSeg算法，并在两种不同架构（卷积网络和Transformer）上实现，在两种不同设置（域内和跨域）下进行评估。此外，我们提出了心电图特有的训练配置和数据增强策略，并引入了标准化的评估框架。我们的结果表明，在半监督心电图描绘中，Transformer的表现优于卷积网络。我们预期我们的基准将作为推进半监督心电图描绘方法的基础，并促进该领域的进一步研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [171] [Delving into Mapping Uncertainty for Mapless Trajectory Prediction](https://arxiv.org/abs/2507.18498)
> *深入探究无地图轨迹预测中的地图不确定性*

*Zongzheng Zhang, Xuchong Qiu, Boran Zhang, Guantian Zheng, Xunjiang Gu, Guoxuan Chi, Huan-ang Gao, Leichen Wang, Ziming Liu, Xinrun Li, Igor Gilitschenski, Hongyang Li, Hang Zhao, Hao Zhao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 无地图轨迹预测, 地图不确定性, 运动学状态, 自动驾驶, 本体感知场景门控

**Comment:** Accepted to IROS 2025, Project Page:
  https://ethan-zheng136.github.io/Dev-Unc/

> **TL;DR:** 该研究通过识别智能体运动学状态，并提出本体感知场景门控和基于协方差的地图不确定性方法，自适应地将地图不确定性整合到无地图轨迹预测中，实现了显著的性能提升和可解释性。

**AI_Comments:** 本研究的创新之处在于识别出智能体的运动学状态是自适应利用地图不确定性的关键因素，并提出了具体的机制（本体感知场景门控和基于协方差的地图不确定性）来实现这一目标。这不仅显著提升了无地图轨迹预测的性能，还增强了其可解释性，为自动驾驶领域的一个关键挑战提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在无地图自动驾驶中，在线生成的高清地图的可靠性存在不确定性。尽管将地图不确定性纳入轨迹预测任务具有潜力，但现有策略对这种不确定性何时有益的特定场景缺乏深入洞察。

**Method:** 1. 分析了地图不确定性对轨迹预测影响最大的驾驶场景，并确定了关键因素：智能体的运动学状态。2. 提出了新颖的本体感知场景门控（Proprioceptive Scenario Gating），根据自我车辆未来运动学的预测自适应地整合地图不确定性。3. 引入了基于协方差的地图不确定性方法（Covariance-based Map Uncertainty），以更好地与地图几何对齐。

**Result:** 在真实世界nuScenes驾驶数据集上，无地图轨迹预测性能比现有最先进方法提高了23.6%。

**Conclusion:** 本研究提出的方法通过考虑智能体的运动学状态，有效且自适应地将地图不确定性整合到无地图轨迹预测中，显著提升了预测性能并增强了可解释性。

> **ai_Abstract:** 本研究解决了无地图自动驾驶中在线生成地图的可靠性不确定性问题。通过分析并识别智能体的运动学状态为关键影响因素，作者提出了两种新颖方法：本体感知场景门控和基于协方差的地图不确定性方法。这些方法能够根据车辆未来的运动学状态自适应地将地图不确定性整合到轨迹预测中，提升了在线地图与轨迹预测的协同作用，并提供了关于不确定性何时有益的可解释性。实验结果表明，该方法在nuScenes数据集上比现有最先进的无地图轨迹预测方法性能提高了23.6%。

> **摘要翻译:** 自动驾驶的最新进展正朝着无地图方法发展，其中高清（HD）地图直接从传感器数据在线生成，减少了昂贵的标注和维护需求。然而，这些在线生成地图的可靠性仍然存在不确定性。虽然将地图不确定性纳入下游轨迹预测任务已显示出性能提升的潜力，但目前的策略对这种不确定性何时有益的特定场景提供有限的洞察。在这项工作中，我们首先分析了地图不确定性对轨迹预测影响最大的驾驶场景，并确定了一个关键的、以前被忽视的因素：智能体的运动学状态。基于这些见解，我们提出了一种新颖的本体感知场景门控（Proprioceptive Scenario Gating），它根据自我车辆未来运动学的预测自适应地将地图不确定性整合到轨迹预测中。这种轻量级的自监督方法增强了在线地图与轨迹预测之间的协同作用，提供了关于不确定性何时有利的可解释性，并优于以前的集成方法。此外，我们引入了一种基于协方差的地图不确定性方法（Covariance-based Map Uncertainty），它更好地与地图几何对齐，进一步提高了轨迹预测。广泛的消融研究证实了我们方法的有效性，在使用真实世界nuScenes驾驶数据集时，其无地图轨迹预测性能比现有最先进方法提高了23.6%。我们的代码、数据和模型已在https://github.com/Ethan-Zheng136/Map-Uncertainty-for-Trajectory-Prediction 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [175] [Beyond Low-rankness: Guaranteed Matrix Recovery via Modified Nuclear Norm](https://arxiv.org/abs/2507.18327)
> *超越低秩性：通过改进核范数实现矩阵恢复保证*

*Jiangjun Peng, Yisi Luo, Xiangyong Cao, Shuang Xu, Deyu Meng* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 改进核范数, 矩阵恢复, 鲁棒主成分分析, 矩阵补全, 理论保证

**Comment:** 15 pages, 14 figures

> **TL;DR:** 本文提出了一种改进的核范数（MNN）框架，通过对变换后的矩阵应用核范数来联合捕获局部信息和全局低秩性，并在鲁棒主成分分析和矩阵补全任务中提供了精确的理论恢复保证。

**AI_Comments:** 本文的创新点在于提出了改进核范数（MNN）框架，它巧妙地通过对变换后的矩阵应用核范数，解决了现有方法在同时捕获局部和全局信息时缺乏理论保证和需要参数调优的问题。其核心贡献在于提供了精确的理论恢复保证，这在结合局部和全局信息的方法中是一个显著的进步。MNN的通用性和灵活性使其能够适应不同的变换，为结构化低秩恢复提供了一个统一且强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 核范数在矩阵恢复问题中被广泛应用，但现有方法在结合局部和全局信息时未能提供理论恢复保证，且通常需要参数调优。本文旨在解决这些局限性，提出一种能同时捕获局部信息和全局低秩性且无需调优参数的方法。

**Method:** 本文引入了一种新的改进核范数（MNN）框架。MNN范数家族通过采用合适的变换，并在变换后的矩阵上执行核范数来定义。该框架旨在联合捕获局部信息和全局低秩性，且无需权衡参数调优。

**Result:** 在对变换的温和假设下，MNN框架为鲁棒主成分分析（Robust PCA）和矩阵补全（MC）任务提供了精确的理论恢复保证，这是现有结合局部和全局信息的方法所不具备的。广泛的实验证明了该方法的有效性。

**Conclusion:** MNN框架提供了一种通用且灵活的设计，可以适应各种已验证的变换，从而为结构化低秩恢复提供了一种统一且有效的方法。它能够同时捕获局部信息和全局低秩性，并提供理论恢复保证。

> **ai_Abstract:** 本文提出了一种新的改进核范数（MNN）框架，旨在解决矩阵恢复问题中现有核范数方法在结合局部和全局信息时的局限性。MNN通过对变换后的矩阵应用核范数来定义，其优势在于能够联合捕获局部信息和全局低秩性，且无需参数调优。在温和假设下，MNN为鲁棒主成分分析和矩阵补全任务提供了精确的理论恢复保证。该框架设计通用灵活，可适应多种变换，为结构化低秩恢复提供了一种统一有效的方法。实验结果也验证了其有效性。

> **摘要翻译:** 核范数（NN）在矩阵恢复问题中得到了广泛探索，例如鲁棒主成分分析和矩阵补全，利用了数据固有的全局低秩结构。在本研究中，我们引入了一个新的改进核范数（MNN）框架，其中MNN家族范数通过采用合适的变换并在变换后的矩阵上执行NN来定义。MNN框架提供了两个主要优势：（1）它在不需要权衡参数调优的情况下联合捕获局部信息和全局低秩性；（2）在对变换的温和假设下，我们为鲁棒主成分分析和矩阵补全任务提供了精确的理论恢复保证——这是现有结合局部和全局信息的方法所不具备的成就。由于其通用和灵活的设计，MNN可以适应各种已验证的变换，从而为结构化低秩恢复提供了一种统一且有效的方法。广泛的实验证明了我们方法的有效性。代码和补充材料可在https://github.com/andrew-pengjj/modified_nuclear_norm获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [176] [Towards a Universal 3D Medical Multi-modality Generalization via Learning Personalized Invariant Representation](https://arxiv.org/abs/2411.06106)
> *迈向通过学习个性化不变表示实现通用3D医学多模态泛化*

*Zhaorui Tan, Xi Yang, Tan Pan, Tianyi Liu, Chen Jiang, Xin Guo, Qiufeng Wang, Anh Nguyen, Yuan Qi, Kaizhu Huang, Yuan Cheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 医学图像, 多模态泛化, 个性化表示, 不变性学习, 3D医学

**Comment:** Accepted by ICCV25

> **TL;DR:** 本文提出一种两阶段方法，通过学习个性化不变表示（$\mathbb{X}_h$）来解决医学图像多模态泛化中的个体差异和模态变异挑战，显著提升了泛化性能和可迁移性。

**AI_Comments:** 这篇论文的创新点在于提出了“个性化不变表示”的概念，并将其应用于解决医学图像多模态泛化中的个体差异问题。通过强调个体层面不变性而非仅仅通用模式，该方法有望在复杂的医学数据中实现更鲁棒和广泛的泛化能力，对提升AI在临床应用中的可靠性具有重要意义。其两阶段训练策略也提供了一个实用的框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学多模态任务的跨模态泛化方法常忽略个体解剖差异，仅关注通用模式，导致泛化性能受限。本文认为学习个体层面的不变性对增强多模态泛化至关重要。

**Method:** 提出一种两阶段方法：首先，利用不变表示$\mathbb{X}_h$进行预训练以实现个性化；然后，对多样化的下游任务进行微调。

**Result:** 理论和实证证据表明个性化方法的可行性和优势。与缺乏个性化的方法相比，该方法在多样化的多模态医学任务中表现出更强的泛化能力和可迁移性，并在各种泛化场景中显著提升了性能。

**Conclusion:** 通过学习个性化不变表示，可以有效克服医学图像多模态和个体差异带来的挑战，显著提升跨模态泛化能力，实现更通用的3D医学多模态泛化。

> **ai_Abstract:** 本文针对医学图像多模态任务中因模态变异和个体差异导致的泛化挑战，提出了一种通过学习个性化不变表示（$\mathbb{X}_h$）的两阶段方法。该方法首先通过预训练实现个性化，随后针对下游任务进行微调。研究表明，个体生物学特征到不同医学模态的映射在人群中是静态的。实验结果验证了该方法在多种多模态医学任务中显著提升了泛化能力和可迁移性，优于不考虑个性化的现有方法。

> **摘要翻译:** 医学成像模态和个体解剖差异的变化对多模态任务中的跨模态泛化提出了挑战。现有方法通常只关注共同的解剖模式，从而忽略了个体差异，并因此限制了其泛化性能。本文强调学习个体层面不变性，即个性化表示$\mathbb{X}_h$，在同质和异质设置下增强多模态泛化的关键作用。它揭示了个体生物学特征到不同医学模态的映射在人群中保持静态，这在个性化过程中有所体现。我们提出了一种两阶段方法：使用不变表示$\mathbb{X}_h$进行预训练以实现个性化，然后对多样化的下游任务进行微调。我们提供了理论和实证证据，证明了个性化的可行性和优势，表明与缺乏个性化的方法相比，我们的方法在各种多模态医学任务中产生了更大的泛化性和可迁移性。广泛的实验进一步验证了我们的方法在各种泛化场景中显著提高了性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [187] [Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space](https://arxiv.org/abs/2409.05260)
> *可扩展的视频分类帧采样：一种具有减小搜索空间的半最优策略方法*

*Junho Lee, Jeongwoo Shin, Seung Woo Ko, Seongsu Ha, Joonseok Lee* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 帧采样, 视频分类, 半最优策略, 搜索空间约减, 计算效率

**Comment:** 

> **TL;DR:** 该论文提出了一种可扩展的视频帧采样半最优策略，将搜索空间从O(T^N)显著减少到O(T)，从而在视频分类中实现高性能和低计算成本。

**AI_Comments:** 该论文的创新之处在于通过引入“半最优策略”显著降低了视频帧采样的计算复杂度，将指数级复杂度降至线性。这使得视频分类在处理长视频或高采样率时更具可扩展性和实用性，是解决实际应用中计算瓶颈的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 现有帧采样方法在从$T$帧中选择$N$帧以最大化视频分类器性能时，面临巨大的搜索空间（$O(T^N)$或$inom{T}{N}$）问题，尤其当$N$较大时，导致计算成本高昂。

**Method:** 本文引入了一种新颖的半最优策略，通过独立估计每帧的置信度值来选择前$N$帧，从而将搜索空间从$O(T^N)$显著减少到$O(T)$，而非探索整个高维空间。

**Result:** 该半最优策略能够有效地近似最优策略，尤其是在实际设置下。通过在各种数据集和模型架构上的广泛实验证明，该策略无论$N$和$T$的大小如何，都能确保稳定和高性能。

**Conclusion:** 本文提出的用于可扩展帧采样的半最优策略有效地解决了巨大搜索空间的问题，为视频分类提供了一种计算高效且高性能的解决方案。

> **ai_Abstract:** 本文针对视频分类中的帧采样问题，提出了一个创新的半最优策略，以解决现有方法因巨大搜索空间($O(T^N)$)导致的计算效率低下。该方法通过独立评估每帧置信度来选择最佳的$N$帧，成功将搜索空间复杂度降低到$O(T)$。实验结果表明，该策略能有效近似最优解，并在不同数据集和模型上实现稳定且高性能的视频分类，无论视频长度或采样比例如何。

> **摘要翻译:** 给定一个包含$T$帧的视频，帧采样是一项选择$N 	ext{«} T$帧的任务，以最大化固定视频分类器的性能。不仅是暴力搜索，大多数现有方法都受其巨大的搜索空间$inom{T}{N}$的困扰，特别是当$N$变大时。为了解决这个挑战，我们引入了一种新颖的视角，将搜索空间从$O(T^N)$减少到$O(T)$。我们提出的半最优策略不探索整个$O(T^N)$空间，而是根据使用每帧置信度独立估计的每帧值选择前$N$帧，显著降低了计算复杂度。我们验证了我们的半最优策略可以有效地近似最优策略，特别是在实际设置下。此外，通过在各种数据集和模型架构上进行的大量实验，我们证明了学习我们的半最优策略可以确保稳定和高性能，无论$N$和$T$的大小如何。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [189] [A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli](https://arxiv.org/abs/2507.18104)
> *一种用于预测大脑对自然刺激响应的多模态Seq2Seq Transformer*

*Qianyi He, Yuan Chang Leong* | **Category: cs.CV, q-bio.NC** | **Updated: 2025-07-24**

**Keywords:** 多模态, Seq2Seq Transformer, fMRI预测, 大脑响应, 自然刺激

**Comment:** 

> **TL;DR:** 一种多模态Seq2Seq Transformer模型，通过整合视觉、听觉和语言输入，预测大脑对自然电影的fMRI响应，捕捉长程时间结构和个体差异。

**AI_Comments:** 该论文通过使用多模态上下文序列来预测大脑活动序列，引入了一种创新方法，这对于捕获自然刺激和神经响应中的长程时间依赖性至关重要。结合共享编码器和部分受试者特异性解码器的混合架构也是一种巧妙的方法，可以平衡大脑响应中的共同模式和个体差异。在分布外数据上的强大性能表明了良好的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在响应Algonauts 2025挑战赛，开发能够预测全脑fMRI对自然多模态电影响应的编码模型。

**Method:** 该研究提出了一种序列到序列的Transformer模型，用于自回归预测基于视觉、听觉和语言输入的fMRI活动。刺激特征通过VideoMAE、HuBERT、Qwen和BridgeTower等预训练模型提取。解码器通过双重交叉注意力机制整合先前的脑状态、当前刺激和情节级摘要信息，同时关注感知信息和叙事信息。核心创新包括使用多模态上下文序列预测脑活动序列以捕获长程时间结构，以及结合共享编码器和部分受试者特异性解码器以平衡共同结构和个体差异。

**Result:** 该模型在分布内和分布外数据上均取得了强大的性能。

**Conclusion:** 该研究结果证明了时间感知多模态序列建模在脑活动预测中的有效性。

> **ai_Abstract:** 本文提出了一种多模态序列到序列的Transformer模型，用于预测大脑对自然主义电影的fMRI响应，以应对Algonauts 2025挑战赛。该模型从视觉、听觉和语言输入中自回归地预测fMRI活动，并利用预训练模型进行特征提取。它通过双重交叉注意力机制整合多种信息源，并创新性地使用多模态上下文序列来捕捉长程时间结构，同时采用混合编码器-解码器架构来处理受试者间的共性和个体差异。该模型在分布内和分布外数据上均表现出强大的性能，突显了其时间感知、多模态方法在脑活动预测中的有效性。

> **摘要翻译:** Algonauts 2025 挑战赛号召社区开发编码模型，以预测全脑 fMRI 对自然多模态电影的响应。在本次提交中，我们提出了一种序列到序列的 Transformer 模型，该模型从视觉、听觉和语言输入中自回归地预测 fMRI 活动。刺激特征使用预训练模型提取，包括 VideoMAE、HuBERT、Qwen 和 BridgeTower。解码器通过双重交叉注意力机制整合来自先前大脑状态、当前刺激和情节级摘要的信息，该机制同时关注从刺激中提取的感知信息以及由叙事内容高级摘要提供的叙事信息。我们方法的一个核心创新是使用多模态上下文序列来预测大脑活动序列，使模型能够捕获刺激和神经响应中的长程时间结构。另一个创新是结合了共享编码器和部分受试者特异性解码器，这利用了受试者之间的共同结构，同时考虑了个体差异。我们的模型在分布内和分布外数据上均取得了强大的性能，证明了时间感知多模态序列建模在脑活动预测中的有效性。代码可在 https://github.com/Angelneer926/Algonauts_challenge 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [195] [Improving Bird Classification with Primary Color Additives](https://arxiv.org/abs/2507.18334)
> *使用原色添加剂改进鸟类分类*

*Ezhini Rasendiran R, Chandresh Kumar Maurya* | **Category: cs.CV, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 鸟类分类, 声谱图, 频率信息, 原色添加剂, 深度学习

**Comment:** 5 pages (Accepted to Interspeech 2025)

> **TL;DR:** 通过将频率信息嵌入到声谱图中，使用原色添加剂，显著提高了鸟类声音分类的准确性，超越了现有模型。

**AI_Comments:** 该论文的创新点在于将频率信息通过原色添加剂的方式嵌入到声谱图中，将声学特征转化为视觉特征的增强，从而利用深度学习模型更好地进行鸟类分类。这种方法有效地解决了传统声谱图在区分相似鸟类主题时的局限性，并取得了显著的性能提升，超越了基线和竞赛获胜者。

<details>
  <summary>Details</summary>

**Motivation:** 鸟类物种的声音分类面临挑战，如环境噪音、重叠叫声和标签缺失，现有模型在低信噪比或多物种录音中表现不佳。

**Method:** 通过将频率信息嵌入到声谱图中，使用原色添加剂来增强物种区分度，并将深度学习模型应用于这些彩色声谱图像。

**Result:** 与未着色的模型相比，该方法取得了统计学上的显著提升，并超越了BirdCLEF 2024的冠军，F1分数提高了7.3%，ROC-AUC提高了6.2%，CMAP提高了6.6%。

**Conclusion:** 通过着色技术整合频率信息能有效提高鸟类物种分类的准确性。

> **ai_Abstract:** 本文提出了一种通过将频率信息编码为原色添加到声谱图中来改进鸟类声音分类的方法。针对现有模型在噪声、重叠声音和相似主题下表现不佳的问题，该创新方法显著增强了物种间的区分度。实验结果表明，该方法在F1、ROC-AUC和CMAP等指标上均取得了显著提升，并超越了BirdCLEF 2024的冠军，证明了通过颜色化整合频率信息的有效性。

> **摘要翻译:** 我们解决了使用鸟类歌曲录音对鸟类物种进行分类的问题，这是一项具有挑战性的任务，因为存在环境噪音、重叠发声和标签缺失。现有模型在低信噪比或多物种录音方面表现不佳。我们假设可以通过可视化它们的音高模式、速度和重复性（统称为主题）来对鸟类进行分类。应用于声谱图像的深度学习模型有所帮助，但跨物种的相似主题会导致混淆。为了缓解这种情况，我们使用原色添加剂将频率信息嵌入到声谱图中。这增强了物种区分度并提高了分类准确性。我们的实验表明，所提出的方法比未着色的模型取得了统计学上的显著增益，并超越了BirdCLEF 2024的冠军，F1分数提高了7.3%，ROC-AUC提高了6.2%，CMAP提高了6.6%。这些结果证明了通过着色技术整合频率信息的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [198] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
> *DiNAT-IR：探索扩张邻域注意力以实现高质量图像恢复*

*Hanzhou Liu, Binghan Li, Chengkai Liu, Mi Lu* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 图像恢复, Transformer, 扩张邻域注意力, DiNAT-IR, 通道感知模块

**Comment:** 

> **TL;DR:** DiNAT-IR 提出了一种结合扩张邻域注意力和通道感知模块的新型Transformer架构，以解决图像恢复中高计算成本和局部细节丢失问题，并在多个基准测试中取得了有竞争力的结果。

**AI_Comments:** 该论文的创新点在于针对Transformer在图像恢复中面临的计算成本和局部细节丢失问题，提出了DiNAT-IR架构。它巧妙地结合了扩张邻域注意力（DiNA）以扩大感受野，并通过引入通道感知模块来弥补DiNA在处理全局上下文时的不足，从而在效率和质量之间取得了平衡。这对于高分辨率图像恢复任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Transformer在图像恢复中计算成本高昂，难以扩展到高分辨率图像。通道维度的自注意力（如Restormer）可能忽略对高质量图像恢复至关重要的局部伪影。直接应用扩张邻域注意力（DiNA）会因全局上下文理解受限而影响准确的视觉恢复。

**Method:** 本文探索了扩张邻域注意力（DiNA），并引入了一个通道感知模块来补充局部注意力，有效整合全局上下文，同时保持像素级精度。所提出的DiNAT-IR是一种专门为图像恢复设计的基于Transformer的架构。

**Result:** 所提出的DiNAT-IR在多个基准测试中取得了有竞争力的结果。

**Conclusion:** DiNAT-IR为各种低级计算机视觉问题提供了一个高质量的解决方案。

> **ai_Abstract:** DiNAT-IR提出了一种新型的Transformer架构，旨在解决图像恢复中自注意力的高计算成本和局部细节丢失问题。该方法通过结合扩张邻域注意力（DiNA）和新引入的通道感知模块，有效平衡了全局上下文和局部精度。DiNAT-IR在多个图像恢复基准测试中表现出色，为低级计算机视觉任务提供了一个高质量的解决方案。

> **摘要翻译:** Transformer凭借其建模长距离依赖的自注意力机制，已成为图像恢复任务中的主导范式。然而，自注意力的高计算成本限制了其在高分辨率图像上的可扩展性，使得效率与质量的权衡成为研究的重点。为了解决这个问题，Restormer采用了通道维度的自注意力，它在通道而非空间维度上计算注意力。尽管有效，但这种方法可能会忽略对高质量图像恢复至关重要的局部伪影。为了弥补这一差距，我们探索了扩张邻域注意力（DiNA）作为一种有前景的替代方案，其灵感来源于其在高级视觉任务中的成功应用。DiNA通过将滑动窗口注意力与混合扩张因子相结合，平衡了全局上下文和局部精度，有效地扩展了感受野而没有过多的开销。然而，我们的初步实验表明，将这种全局-局部设计直接应用于经典的去模糊任务会阻碍准确的视觉恢复，这主要是由于局部注意力中受限的全局上下文理解。为了解决这个问题，我们引入了一个通道感知模块来补充局部注意力，有效地整合全局上下文，同时不牺牲像素级精度。所提出的DiNAT-IR是一种专门为图像恢复设计的基于Transformer的架构，在多个基准测试中取得了有竞争力的结果，为各种低级计算机视觉问题提供了一个高质量的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [201] [SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning](https://arxiv.org/abs/2507.18616)
> *SynC：基于一对多映射的合成图像字幕数据集精炼，用于零样本图像字幕生成*

*Si-Woo Kim, MinJu Jeon, Ye-Chan Kim, Soeun Lee, Taewhan Kim, Dong-Jin Kim* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 零样本图像字幕生成, 合成数据集, 数据精炼, 图像-字幕对齐, 一对多映射

**Comment:** Accepted to ACM Multimedia 2025

> **TL;DR:** SynC 是一种新颖的框架，通过将字幕重新分配给最匹配的图像来精炼合成图像字幕数据集，从而提高零样本图像字幕生成的性能。

**AI_Comments:** SynC的创新之处在于其独特的“一对多映射”和“循环一致性启发”的图像-字幕重新分配策略，而非传统的过滤或重新生成，这特别适用于处理合成数据中图像不准确但字幕质量高的问题。它有效地利用了已生成的图像池，提高了数据利用率和质量，对依赖合成数据的零样本任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 零样本图像字幕生成 (ZIC) 依赖文本到图像 (T2I) 模型生成的合成数据集，以减少昂贵的手动标注。然而，这些T2I模型生成的图像常与输入字幕语义不匹配（如缺少物体、属性错误），导致合成图像-字幕对存在噪声，阻碍模型训练。现有数据集修剪技术不适用于合成数据中图像不准确但字幕良好的独特挑战。

**Method:** SynC 框架旨在精炼合成图像字幕数据集。它不进行传统的过滤或重新生成，而是将字幕重新分配给合成图像池中语义最匹配的图像。该方法采用一对多映射策略，首先为每个字幕检索多个相关的候选图像，然后应用一个受循环一致性启发的对齐评分器，通过验证图像检索原始字幕的能力来选择最佳图像。

**Result:** SynC 在各种零样本图像字幕模型上，在标准基准测试（MS-COCO、Flickr30k、NoCaps）中持续显著提高性能，并在多个场景中实现了最先进的结果。

**Conclusion:** SynC 为整理精炼的合成数据以增强零样本图像字幕生成提供了有效的策略。

> **ai_Abstract:** 本文提出了SynC框架，旨在解决零样本图像字幕生成中合成数据集的图像与字幕语义不匹配问题。针对T2I模型生成的图像可能不准确但字幕良好的情况，SynC采用一对多映射策略，为每个字幕在现有图像池中找到最匹配的图像，并使用循环一致性启发的方法验证选择。实验证明，SynC显著提升了多个ZIC模型在标准基准上的性能，达到了先进水平，为精炼合成数据提供了有效方法。

> **摘要翻译:** 零样本图像字幕生成（ZIC）越来越多地利用文本到图像（T2I）模型生成的合成数据集，以减少对昂贵手动标注的需求。然而，这些T2I模型生成的图像经常与其对应的输入字幕表现出语义错位（例如，缺少物体、属性不正确），导致合成图像-字幕对存在噪声，从而阻碍模型训练。现有数据集修剪技术主要用于清除网络抓取数据中的噪声文本。然而，这些方法不适用于合成数据的独特挑战，即字幕通常格式良好，但图像可能是不准确的表示。为了解决这一空白，我们引入了SynC，一个专门为零样本图像字幕生成精炼合成图像-字幕数据集的新颖框架。SynC没有采用传统的过滤或重新生成，而是专注于将字幕重新分配给合成图像池中已有的语义最匹配的图像。我们的方法采用一对多映射策略，首先为每个字幕检索多个相关的候选图像。然后，我们应用一个受循环一致性启发的对齐评分器，通过验证其通过图像到文本检索检索原始字幕的能力来选择最佳图像。广泛的评估表明，SynC在标准基准测试（MS-COCO、Flickr30k、NoCaps）上持续显著提高了各种零样本图像字幕模型的性能，并在多个场景中取得了最先进的结果。SynC为整理精炼的合成数据以增强零样本图像字幕生成提供了一种有效的策略。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [205] [GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences](https://arxiv.org/abs/2507.18330)
> *GVCCS：一个用于可见光全天空相机序列中凝结尾迹识别与追踪的数据集*

*Gabriel Jarry, Ramon Dalmau, Philippe Very, Franck Ballerini, Stephania-Denisa Bocu* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 凝结尾迹, 数据集, 全天空相机, 深度学习, 气候影响

**Comment:** 

> **TL;DR:** GVCCS是一个新的开放数据集，用于从地面可见光全天空相机序列中识别和追踪凝结尾迹，旨在解决现有数据集缺乏时间追踪和来源航班归属的问题，并提供了一个统一的深度学习框架作为基准。

**AI_Comments:** 该论文的创新之处在于创建了一个高质量、时间分辨率高且包含航班识别码的凝结尾迹数据集，填补了现有数据集在时间追踪和来源归属方面的空白。这对于验证和校准气候模型中的凝结尾迹效应至关重要。同时，提出的统一深度学习框架为未来的凝结尾迹分析提供了一个有力的基准。该工作对于提升我们对航空气候影响的理解和评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 航空对气候的影响不仅包括二氧化碳排放，还包括显著的非二氧化碳效应，特别是凝结尾迹。凝结尾迹可以改变地球的辐射平衡，其升温效应可能与航空二氧化碳相当。尽管基于物理的模型提供了有用的估计，但其准确性受限于大气输入数据质量和复杂过程（如冰粒形成和湿度驱动的持久性）的假设。现有的观测数据集缺乏时间追踪，并且未能将凝结尾迹归因于其来源航班，这限制了对凝结尾迹动力学和形成的全面探索，从而阻碍了物理模型的验证和校准。

**Method:** 本研究提出了一个名为“地面可见光相机凝结尾迹序列”（GVCCS）的新型开放数据集，该数据集使用地面全天空相机在可见光范围内记录凝结尾迹。数据集中每个凝结尾迹都经过单独标记并进行时间追踪，以详细分析其生命周期。该数据集包含122个视频序列（24,228帧），并为在相机上方形成的凝结尾迹提供了航班识别码。此外，作为参考，作者还提出了一个统一的深度学习框架，使用一个全景分割模型进行凝结尾迹分析，该模型在单一架构中执行语义分割（凝结尾迹像素识别）、实例分割（个体凝结尾迹分离）和时间追踪。

**Result:** GVCCS数据集包含122个视频序列（24,228帧），每个凝结尾迹都经过单独标记和时间追踪，并且包含在相机上方形成的凝结尾迹的航班识别码。该数据集提供了高质量、时间分辨率高的标注，并为模型评估提供了一个基准。提出的统一深度学习框架能够进行凝结尾迹像素识别、个体凝结尾迹分离和时间追踪。

**Conclusion:** 本工作通过提供高质量、时间分辨率高的凝结尾迹标注数据集和模型评估基准，支持改进凝结尾迹监测，并将促进物理模型的更好校准。这为更准确地理解和评估气候影响奠定了基础。

> **ai_Abstract:** 本论文介绍了GVCCS（地面可见光相机凝结尾迹序列）数据集，这是一个新的开放数据集，旨在解决现有凝结尾迹观测数据在时间追踪和来源航班归属方面的不足。该数据集包含122个视频序列，记录了通过地面全天空相机在可见光范围内捕获的凝结尾迹，并对每个凝结尾迹进行了单独标记和时间追踪，部分凝结尾迹还关联了航班识别码，从而支持对其生命周期的详细分析。此外，论文还提出了一个统一的深度学习框架作为参考基准，该框架利用全景分割模型在一个架构中实现凝结尾迹的语义分割、实例分割和时间追踪。GVCCS数据集及其伴随的基准工作为改进凝结尾迹监测和物理模型校准提供了高质量的观测数据和评估工具，从而有助于更准确地理解和评估航空对气候的影响。

> **摘要翻译:** 航空对气候的影响不仅包括二氧化碳排放，还包括显著的非二氧化碳效应，特别是凝结尾迹。这些冰云可以改变地球的辐射平衡，其潜在的升温效应可能与航空二氧化碳相当。基于物理的模型提供了凝结尾迹形成和气候影响的有用估计，但其准确性严重依赖于大气输入数据的质量以及用于表示冰粒形成和湿度驱动的持久性等复杂过程的假设。来自遥感器（如卫星和地面相机）的观测数据可用于验证和校准这些模型。然而，现有数据集并未探索凝结尾迹动力学和形成的所有方面：它们通常缺乏时间追踪，并且不将凝结尾迹归因于其来源航班。为了解决这些限制，我们提出了“地面可见光相机凝结尾迹序列”（GVCCS），这是一个新的开放数据集，记录了通过地面全天空相机在可见光范围内捕获的凝结尾迹。每个凝结尾迹都被单独标记并随时间追踪，从而可以对其生命周期进行详细分析。该数据集包含122个视频序列（24,228帧），并包括在相机上方形成的凝结尾迹的航班识别码。作为参考，我们还提出了一个统一的深度学习框架，用于使用全景分割模型进行凝结尾迹分析，该模型在单一架构中执行语义分割（凝结尾迹像素识别）、实例分割（个体凝结尾迹分离）和时间追踪。通过提供高质量、时间分辨率高的标注以及模型评估的基准，我们的工作支持改进凝结尾迹监测，并将促进物理模型的更好校准。这为更准确的气候影响理解和评估奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [211] [Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention](https://arxiv.org/abs/2507.18503)
> *人类在目标存在视觉搜索中基于语义-中央凹贝叶斯注意的扫描路径预测*

*João Luzio, Alexandre Bernardino, Plinio Moreno* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扫描路径预测, 视觉注意力, 语义贝叶斯, 中央凹视觉, 深度学习

**Comment:** To be published in the 2025 IEEE International Conference on
  Development and Learning (ICDL)

> **TL;DR:** 该研究提出SemBA-FAST模型，一种结合深度学习和贝叶斯注意的自上而下框架，用于预测目标存在视觉搜索中的人类扫描路径，并在COCO-Search18数据集上表现出色，超越基线模型。

**AI_Comments:** 这篇论文提出了一种新颖的自上而下框架SemBA-FAST，巧妙地结合了深度学习（目标检测）和概率贝叶斯方法，并引入了人工中央凹视觉，以更准确地预测人类在目标存在视觉搜索中的扫描路径。其创新点在于动态生成注意力图和顺序更新机制。研究结果表明其在预测人类注视序列方面的优越性，为类人注意力建模提供了新的思路，并对认知计算和机器人领域的实际应用具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 在目标导向的视觉任务中，人类感知受到自上而下和自下而上线索的引导，中央凹视觉也发挥关键作用。现有受生物启发的计算注意力模型虽受益于深度学习和人类扫描路径数据，取得了新的最先进性能，但仍需更有效的方法来整合这些因素以准确预测人类视觉注意力。

**Method:** 提出SemBA-FAST模型，一个自上而下的框架，用于预测目标存在视觉搜索中的人类视觉注意力。它整合了深度目标检测与概率语义融合机制，以动态生成注意力图，并利用预训练检测器和人工中央凹视觉来顺序更新自上而下知识并改进注视点预测。

**Result:** SemBA-FAST在COCO-Search18基准数据集上进行了评估，其注视序列与人类真实扫描路径高度匹配。该方法超越了基线模型和其他自上而下方法，在某些情况下甚至能与受扫描路径信息影响的模型竞争。

**Conclusion:** 这些发现为类人注意力建模的语义-中央凹概率框架的能力提供了宝贵的见解，对实时认知计算和机器人技术具有重要意义。

> **ai_Abstract:** 该论文介绍了SemBA-FAST，一个用于目标存在视觉搜索中人类扫描路径预测的自上而下模型。该模型结合了深度目标检测和概率语义融合，利用预训练检测器和人工中央凹视觉动态生成注意力图并改进注视点预测。在COCO-Search18数据集上的评估表明，SemBA-FAST的预测与人类真实扫描路径高度匹配，且性能优于基线模型和其他自上而下方法，证明了语义-中央凹概率框架在类人注意力建模中的潜力。

> **摘要翻译:** 在目标导向的视觉任务中，人类感知受到自上而下和自下而上线索的引导。同时，中央凹视觉在有效引导注意力方面发挥着关键作用。现代受生物启发的计算注意力模型研究利用深度学习的进步，通过使用人类扫描路径数据实现了新的最先进性能。在这项工作中，我们评估了SemBA-FAST的性能，即基于语义的贝叶斯注意力用于中央凹主动视觉搜索任务，这是一个自上而下的框架，旨在预测目标存在视觉搜索中的人类视觉注意力。SemBA-FAST将深度目标检测与概率语义融合机制相结合，动态生成注意力图，利用预训练检测器和人工中央凹视觉顺序更新自上而下知识并改进注视点预测。我们在COCO-Search18基准数据集上评估了SemBA-FAST，并将其性能与其他扫描路径预测模型进行了比较。我们的方法实现了与人类真实扫描路径高度匹配的注视序列。值得注意的是，它超越了基线模型和其他自上而下方法，在某些情况下甚至能与受扫描路径信息影响的模型竞争。这些发现为类人注意力建模的语义-中央凹概率框架的能力提供了宝贵的见解，对实时认知计算和机器人技术具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [212] [DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition](https://arxiv.org/abs/2507.18444)
> *DSFormer：一种用于视觉地点识别的双尺度交叉学习Transformer*

*Haiyang Jiang, Songhao Piao, Chao Gao, Lei Yu, Liguo Chen* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 视觉地点识别, Transformer, 双尺度学习, 块聚类, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出DSFormer，一个结合双尺度交叉学习Transformer模块和创新块聚类策略的框架，用于视觉地点识别，实现了最先进的性能并降低了训练数据量。

**AI_Comments:** 该论文的创新点在于提出了DSFormer，一个结合了双尺度特征学习和跨尺度信息传输的Transformer模块，以及一种新颖的块聚类策略，共同提升了视觉地点识别的鲁棒性和效率。其显著减少训练数据量的能力也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 视觉地点识别（VPR）对于鲁棒的移动机器人定位至关重要，但其在不同环境条件和视角下保持可靠性能面临重大挑战。

**Method:** 本文提出DSFormer框架，包含一个基于Transformer的双尺度交叉学习模块（DSFormer）和一个创新块聚类策略。DSFormer通过双向信息传输增强特征表示，利用自注意力捕获长距离依赖，共享交叉注意力进行跨尺度学习。块聚类策略重新划分SF-XL训练数据集，优化数据组织以增强对视角变化的鲁棒性。

**Result:** 该方法在大多数基准数据集上实现了最先进的性能，超越了现有方法，作为全局检索解决方案使用512维全局描述符，同时显著提高了计算效率，并减少了约30%的所需训练数据量。

**Conclusion:** 提出的DSFormer框架结合块聚类策略，为视觉地点识别提供了一个鲁棒且高效的解决方案，在各种挑战性条件下表现出色。

> **ai_Abstract:** 本文提出DSFormer，一个用于视觉地点识别的新型框架，旨在解决环境和视角变化下的性能挑战。DSFormer整合了一个基于Transformer的双尺度交叉学习模块，通过双向信息传输增强特征表示，并结合创新的块聚类策略优化数据组织。实验证明，该方法在多个基准数据集上实现了最先进的性能，显著降低了训练数据需求，并提高了计算效率。

> **摘要翻译:** 视觉地点识别（VPR）对于鲁棒的移动机器人定位至关重要，但其在不同环境条件和视角下保持可靠性能面临重大挑战。为解决此问题，我们提出了一种新颖的框架，该框架将双尺度Transformer（DSFormer）——一个基于Transformer的交叉学习模块——与创新的块聚类策略相结合。DSFormer通过启用从最后两个CNN层提取的双尺度特征之间的双向信息传输来增强特征表示，通过自注意力捕获每个尺度内的长距离依赖关系，并通过共享的交叉注意力进行跨尺度学习，从而同时捕捉语义丰富性和空间细节。作为补充，我们的块聚类策略从多个不同视角重新划分了广泛使用的旧金山特大（SF-XL）训练数据集，优化了数据组织，以进一步增强对视角变化的鲁棒性。这些创新共同不仅产生了适应环境变化的鲁棒全局嵌入，而且与以前的划分方法相比，所需训练数据量减少了约30%。全面的实验表明，我们的方法在大多数基准数据集上取得了最先进的性能，作为使用512维全局描述符的全局检索解决方案，超越了DELG、Patch-NetVLAD、TransVPR和R2Former等先进的重排序方法，同时显著提高了计算效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [213] [PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting](https://arxiv.org/abs/2410.22128)
> *PF3plat: 无姿态前向3D高斯泼溅*

*Sunghwan Hong, Jaewoo Jung, Heeseong Shin, Jisang Han, Jiaolong Yang, Chong Luo, Seungryong Kim* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D Gaussian Splatting, Novel View Synthesis, Pose-Free, Depth Estimation, Visual Correspondence

**Comment:** Accepted by ICML'25

> **TL;DR:** 提出PF3plat，一种用于无姿态图像的新颖视图合成方法，通过解决3DGS中的对齐问题，实现了SOTA性能。

**AI_Comments:** 该论文的创新点在于将3DGS模型扩展到处理无姿态图像，这大大拓宽了其应用场景。通过引入粗对齐和可学习的细化模块，以及几何置信度评估，有效解决了无姿态数据带来的挑战，提升了模型的鲁棒性和实用性。这对于实际应用中难以获取精确相机姿态的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决从无姿态图像进行新颖视图合成的问题，同时放宽了对密集图像视图、精确相机姿态和大量图像重叠的常见假设，因为像素对齐的3DGS在高斯未对齐时会导致训练不稳定，阻碍收敛。

**Method:** 本方法利用3DGS的快速、可扩展和高质量特性，并解决了像素对齐3DGS在高斯未对齐时产生的独特挑战。具体而言，采用预训练的单目深度估计和视觉对应模型实现3D高斯的粗略对齐。随后，引入轻量级、可学习模块来细化深度和姿态估计，提升重建质量。此外，利用细化后的估计来评估几何置信度分数，并根据可靠性调整高斯参数的预测。

**Result:** 在大型真实世界数据集上的广泛评估表明，PF3plat在所有基准测试中都达到了新的最先进水平，并通过全面的消融研究验证了设计选择。

**Conclusion:** PF3plat通过有效解决无姿态图像的新颖视图合成中的挑战，显著提升了3DGS的性能和实用性，并达到新的SOTA。

> **ai_Abstract:** 本文提出了PF3plat，一种用于从无姿态图像进行新颖视图合成的框架，它扩展了3D高斯泼溅（3DGS）模型。为了解决无姿态图像中3D高斯未对齐导致的训练不稳定问题，PF3plat利用预训练的单目深度和视觉对应模型进行粗对齐，并引入轻量级可学习模块进行深度和姿态细化。此外，它还通过几何置信度分数来优化高斯参数预测。实验结果表明，PF3plat在多个大规模真实世界数据集上实现了最先进的性能。

> **摘要翻译:** 我们考虑在单次前向传播中从无姿态图像合成新颖视图的问题。我们的框架利用了3DGS的快速速度、可扩展性以及高质量的3D重建和视图合成能力，我们进一步扩展它以提供一个实用的解决方案，该方案放宽了诸如密集图像视图、精确相机姿态和大量图像重叠等常见假设。我们通过识别和解决使用像素对齐3DGS所带来的独特挑战来实现这一点：不同视图之间未对齐的3D高斯会导致噪声或稀疏的梯度，从而使训练不稳定并阻碍收敛，尤其是在不满足上述假设时。为了缓解这个问题，我们采用预训练的单目深度估计和视觉对应模型来实现3D高斯的粗略对齐。然后，我们引入轻量级、可学习的模块来从粗略对齐中细化深度和姿态估计，从而提高3D重建和新颖视图合成的质量。此外，利用细化的估计来估计几何置信度分数，该分数评估3D高斯中心点的可靠性并相应地调整高斯参数的预测。在大型真实世界数据集上的广泛评估表明，PF3plat在所有基准测试中都达到了新的最先进水平，并通过全面的消融研究验证了我们的设计选择。项目页面：https://cvlab-kaist.github.io/PF3plat/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [233] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
> *AFRDA：用于领域自适应语义分割的注意力特征细化*

*Md. Al-Masrur Khan, Durgakant Pushp, Lantao Liu* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 无监督领域自适应, 语义分割, 特征细化, 注意力机制, 高频分量

**Comment:** 

> **TL;DR:** AFRDA通过引入自适应特征细化模块，有效平衡局部和全局信息，显著提升了无监督领域自适应语义分割的准确性，并在多个基准测试中达到了最先进的性能。

**AI_Comments:** AFRDA的创新之处在于其AFR模块，通过结合语义先验、高频分量和不确定性驱动的注意力，有效地平衡了细粒度局部细节和全局上下文信息，解决了UDA-SS中的关键挑战。其轻量级设计和在多个基准数据集上取得的显著性能提升，表明了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无监督领域自适应语义分割（UDA-SS）方法难以平衡细粒度局部细节与全局上下文信息，导致在复杂区域出现分割错误。

**Method:** 本文提出了自适应特征细化（AFR）模块，该模块通过利用低分辨率logits的语义先验来细化高分辨率特征，并整合捕获细粒度结构和边界信息的高频分量。AFR还通过不确定性驱动的注意力自适应地平衡局部和全局信息。其轻量级设计允许其无缝集成到基于HRDA的UDA方法中。

**Result:** 该方法在GTA V --> Cityscapes数据集上将现有UDA-SS方法的mIoU提高了1.05%，在Synthia --> Cityscapes数据集上提高了1.04%。

**Conclusion:** AFRDA通过其创新的自适应特征细化模块，有效解决了无监督领域自适应语义分割中局部与全局信息平衡的挑战，显著提升了语义分割性能，达到了当前最先进水平。

> **ai_Abstract:** 本文提出了AFRDA（Attentive Feature Refinement for Domain Adaptive Semantic Segmentation），旨在解决无监督领域自适应语义分割（UDA-SS）中局部与全局信息平衡的挑战。其核心是自适应特征细化（AFR）模块，该模块通过语义先验细化高分辨率特征，整合高频分量以捕获细粒度结构和边界信息，并通过不确定性驱动的注意力自适应平衡局部和全局信息。AFRDA设计轻量级，可集成到现有UDA方法中，并在GTA V --> Cityscapes和Synthia --> Cityscapes数据集上显著提升了mIoU，达到了最先进的性能。

> **摘要翻译:** 在无监督领域自适应语义分割（UDA-SS）中，模型在带有标签的源域数据（例如，合成图像）上进行训练，并适应于无标签的目标域（例如，真实世界图像），而无需访问目标域的标注。现有的UDA-SS方法通常难以平衡细粒度局部细节与全局上下文信息，导致在复杂区域出现分割错误。为了解决这个问题，我们引入了自适应特征细化（AFR）模块，该模块通过利用低分辨率logits的语义先验来细化高分辨率特征，从而提高分割精度。AFR还整合了高频分量，这些分量捕获细粒度结构并提供关键的边界信息，从而改善了对象轮廓的描绘。此外，AFR通过不确定性驱动的注意力自适应地平衡局部和全局信息，减少了错误分类。其轻量级设计允许其无缝集成到基于HRDA的UDA方法中，从而带来了最先进的分割性能。我们的方法在GTA V --> Cityscapes上将现有UDA-SS方法的mIoU提高了1.05%，在Synthia --> Cityscapes上提高了1.04%。我们框架的实现可在以下网址获取：https://github.com/Masrur02/AFRDA

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [234] [Distributional Uncertainty for Out-of-Distribution Detection](https://arxiv.org/abs/2507.18106)
> *用于域外检测的分布不确定性*

*JinYoung Kim, DaeUng Jo, Kimin Yun, Jeonghyo Song, Youngjoon Yoo* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 域外检测, 分布不确定性, 自由能后验网络, Beta分布, 不确定性感知分割

**Comment:** 6 pages , 3 figures , IEEE International Conference on Advanced
  Visual and Signal-Based Systems

> **TL;DR:** 本文提出了一种名为自由能后验网络（Free-Energy Posterior Network）的新框架，用于联合建模分布不确定性，以改进域外（OoD）检测。该方法通过直接从学习参数中估计不确定性，无需随机采样，从而提高了计算效率和语义一致性。

**AI_Comments:** 本文的创新点在于其提出了一种联合建模分布不确定性的新颖方法，通过引入基于Beta分布的自由能密度估计器，实现了对模糊和未见区域的细粒度不确定性估计。此外，通过在后验网络中集成损失，实现了直接从学习参数中估计不确定性，避免了随机采样的需要，显著提高了计算效率。这使得其在域外检测和不确定性感知分割方面，相较于传统方法，具有更强的语义一致性和更高的效率。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度神经网络不确定性估计方法（如蒙特卡洛Dropout）在域外（OoD）样本检测中，通常只关注模型不确定性或数据不确定性，未能与OoD检测的语义目标对齐。此外，这些方法通常依赖于事后能量阈值设定。

**Method:** 本文提出了“自由能后验网络”（Free-Energy Posterior Network），这是一个新颖的框架，它使用自由能联合建模分布不确定性，并识别OoD区域和错误分类区域。该方法包含两个关键贡献：1) 一个基于自由能的密度估计器，由Beta分布参数化，用于在模糊或未见区域附近进行细粒度不确定性估计；2) 一个集成在后验网络中的损失函数，允许直接从学习参数中估计不确定性，而无需随机采样。通过将此方法与残差预测分支（RPL）框架结合，该方法超越了事后能量阈值设定，并能利用Beta分布的方差学习OoD区域。

**Result:** 该方法为不确定性感知分割提供了一个具有语义意义且计算高效的解决方案。其有效性在具有挑战性的真实世界基准测试（包括Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can）上得到了验证。

**Conclusion:** 本文提出的自由能后验网络通过联合建模分布不确定性，并利用Beta分布进行细粒度估计，为域外检测和不确定性感知分割提供了一种有效、具有语义意义且计算高效的解决方案，优于传统方法。

> **ai_Abstract:** 本文提出了自由能后验网络（Free-Energy Posterior Network），一个新颖的框架，旨在解决传统域外（OoD）检测方法仅关注模型或数据不确定性的局限性。该框架利用基于自由能的密度估计器（由Beta分布参数化）联合建模分布不确定性，并集成损失于后验网络中，实现从学习参数直接估计不确定性，无需随机采样。通过与残差预测分支（RPL）框架结合，该方法能够学习OoD区域，为不确定性感知分割提供了一个具有语义意义且计算高效的解决方案，并在多个真实世界基准测试中验证了其有效性。

> **摘要翻译:** 从深度神经网络估计不确定性是检测域外（OoD）样本的一种广泛使用的方法，这些样本通常表现出高预测不确定性。然而，传统方法如蒙特卡洛（MC）Dropout通常只关注模型或数据不确定性，未能与OoD检测的语义目标对齐。为了解决这个问题，我们提出了自由能后验网络（Free-Energy Posterior Network），这是一个新颖的框架，它使用自由能联合建模分布不确定性并识别OoD和错误分类区域。我们的方法引入了两个关键贡献：（1）一个由Beta分布参数化的基于自由能的密度估计器，它能够在模糊或未见区域附近进行细粒度不确定性估计；（2）一个集成在后验网络中的损失，允许直接从学习参数中估计不确定性，而无需随机采样。通过将我们的方法与残差预测分支（RPL）框架集成，所提出的方法超越了事后能量阈值设定，并使网络能够通过利用Beta分布的方差来学习OoD区域，从而为不确定性感知分割提供了一个具有语义意义且计算高效的解决方案。我们在具有挑战性的真实世界基准测试（包括Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can）上验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [235] [Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction](https://arxiv.org/abs/2507.18331)
> *通过自适应三维体构建提升多视角室内三维目标检测*

*Runmin Zhang, Zhu Yu, Si-Yuan Cao, Lingyu Zhu, Guangyi Zhang, Xiaokai Bai, Hui-Liang Shen* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 多视角3D目标检测, 自适应3D体构建, 体素特征, 稀疏体素构建, SGCDet

**Comment:** Accepted by ICCV2025

> **TL;DR:** SGCDet是一个新颖的多视角室内三维目标检测框架，通过自适应三维体构建，整合几何和上下文信息，并采用稀疏体素构建策略，有效提升了检测效率和性能，且仅需3D边界框进行监督。

**AI_Comments:** 该论文的创新点在于其自适应三维体构建方法，特别是几何和上下文感知聚合模块以及稀疏体素构建策略。这种设计有效提升了体素特征的表示能力并显著减少了计算冗余。此外，仅依赖3D边界框进行监督的能力，极大地降低了对复杂真值场景几何标注的依赖，提升了方法的实用性。这些特点使得SGCDet在室内3D目标检测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视角室内三维目标检测方法将体素的感受野限制在图像的固定位置，导致体素特征的表示能力不足且存在冗余计算。本文旨在通过自适应方法提升体素特征表示能力并减少计算量。

**Method:** 本文提出了SGCDet框架，其核心包括：1. 几何和上下文感知聚合模块，用于在图像的自适应区域内整合几何和上下文信息，并动态调整不同视角的贡献，以增强体素特征表示。2. 稀疏体素构建策略，自适应识别并选择高占用概率的体素进行特征细化，从而最小化自由空间中的冗余计算。3. 该网络仅通过3D边界框即可进行监督，无需依赖真值场景几何。

**Result:** SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上取得了最先进的性能。该框架实现了有效且高效的自适应体素构建。

**Conclusion:** SGCDet是一个新颖的多视角室内三维目标检测框架，通过引入自适应三维体构建，包括几何和上下文感知聚合以及稀疏体素构建策略，显著提升了体素特征的表示能力并减少了计算冗余。该方法仅需3D边界框即可监督，并在多个数据集上达到了最先进的性能。

> **ai_Abstract:** 本文提出了SGCDet，一个用于多视角室内三维目标检测的新型框架。它通过引入几何和上下文感知聚合模块来整合自适应区域内的信息并动态调整视角贡献，以及通过稀疏体素构建策略来减少自由空间中的冗余计算，从而解决了现有方法中体素感受野固定和计算效率低下的问题。SGCDet能够有效且高效地进行自适应三维体构建，并且仅需3D边界框即可进行监督。实验结果表明，SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上达到了最先进的性能。

> **摘要翻译:** 这项工作提出了SGCDet，一个基于自适应三维体构建的新型多视角室内三维目标检测框架。与以前将体素感受野限制在图像固定位置的方法不同，我们引入了一个几何和上下文感知聚合模块，用于在每张图像的自适应区域内整合几何和上下文信息，并动态调整来自不同视角的贡献，从而增强体素特征的表示能力。此外，我们提出了一种稀疏体素构建策略，该策略自适应地识别和选择具有高占用概率的体素进行特征细化，从而最大限度地减少自由空间中的冗余计算。受益于上述设计，我们的框架以自适应的方式实现了有效且高效的体素构建。更好的是，我们的网络仅使用三维边界框即可进行监督，消除了对真值场景几何的依赖。实验结果表明，SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上取得了最先进的性能。源代码可在https://github.com/RM-Zhang/SGCDet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [237] [CutS3D: Cutting Semantics in 3D for 2D Unsupervised Instance Segmentation](https://arxiv.org/abs/2411.16319)
> *CutS3D: 基于3D语义切割的2D无监督实例分割*

*Leon Sick, Dominik Engel, Sebastian Hartwig, Pedro Hermosilla, Timo Ropinski* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 无监督实例分割, 3D语义切割, 点云, 空间重要性, 目标检测

**Comment:** Accepted at ICCV 2025. Project Page with Code, Models & Demo:
  https://leonsick.github.io/cuts3d/

> **TL;DR:** CutS3D通过在3D空间中切割语义掩码并引入空间重要性与置信度组件，改进了2D无监督实例分割，有效解决了2D图像中实例重叠的问题。

**AI_Comments:** CutS3D的创新点在于将3D信息（点云）引入到2D无监督实例分割中，通过在3D空间中切割语义来解决2D重叠实例的难题。这种跨维度的方法是其核心亮点。同时，引入空间重要性和置信度组件以优化伪掩码质量和学习信号，也显示了其方法设计的精妙之处。该工作为无监督实例分割提供了一个新的视角和有效的解决方案，对于减少对大规模标注数据的依赖具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的2D实例分割算法严重依赖大量人工标注数据，而新兴的无监督方法虽然取得了最新进展，但由于仅考虑语义，在2D图像空间中常常无法正确分离重叠的实例。

**Method:** 我们提出利用场景的点云表示在3D中切割语义掩码以获得最终的2D实例。此外，我们推导了一个空间重要性函数，用于沿实例的3D边界重新锐化语义。为解决掩码模糊问题，我们进一步提出通过三个空间置信度组件来增强类别无关检测器的训练，旨在隔离干净的学习信号。

**Result:** 我们的方法在无监督实例分割和目标检测的多个标准基准上均优于竞争方法。

**Conclusion:** 通过在3D空间中引入语义切割以及空间重要性和置信度组件，CutS3D有效解决了2D无监督实例分割中实例重叠和掩码模糊的问题，并在多个基准上取得了领先性能。

> **ai_Abstract:** CutS3D提出了一种新的2D无监督实例分割方法，旨在克服传统方法对大量标注数据的依赖以及现有无监督方法在处理2D重叠实例时的不足。该方法通过利用场景的点云表示在3D空间中切割语义掩码来生成2D实例，并引入空间重要性函数以锐化3D边界语义。为解决伪掩码模糊性，CutS3D还通过三个空间置信度组件增强了类别无关检测器的训练。实验结果表明，该方法在多个标准基准上均超越了现有竞争方法。

> **摘要翻译:** 传统上，在2D图像中学习分割对象实例的算法严重依赖大量人工标注数据。直到最近，才出现了以无监督方式解决此问题的新颖方法。通常，这些方法首先生成伪掩码，然后训练一个类别无关的检测器。尽管此类方法达到了当前的最新水平，但由于仅考虑语义，它们通常无法正确分离在2D图像空间中重叠的实例。为了解决这个问题，我们提出利用场景的点云表示在3D中切割语义掩码以获得最终的2D实例。此外，我们推导了一个空间重要性函数，用于沿实例的3D边界重新锐化语义。然而，这些伪掩码仍然存在掩码模糊问题。为了解决这个问题，我们进一步提出通过三个空间置信度组件来增强类别无关检测器的训练，旨在隔离干净的学习信号。凭借这些贡献，我们的方法在无监督实例分割和目标检测的多个标准基准上均优于竞争方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [241] [SIDA: Synthetic Image Driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2507.18632)
> *SIDA：合成图像驱动的零样本域适应*

*Ye-Chan Kim, SeungJu Cha, Si-Woo Kim, Taewhan Kim, Dong-Jin Kim* | **Category: cs.CV, cs.AI, cs.LG, cs.MM** | **Updated: 2025-07-24**

**Keywords:** 零样本域适应, 合成图像, 域混合, 补丁风格迁移, 图像翻译

**Comment:** Accepted to ACM MM 2025

> **TL;DR:** SIDA提出了一种基于合成图像的新型零样本域适应方法，解决了现有文本驱动方法在捕捉复杂真实世界变异和适应时间上的不足，实现了先进的性能和高效率。

**AI_Comments:** SIDA的创新点在于摆脱了传统零样本域适应中对文本描述的依赖，转而利用合成图像提供更丰富和细致的风格线索。通过图像翻译生成目标域风格的代理，并结合Domain Mix和Patch Style Transfer模块来处理复杂变异，这种基于图像的方法显著提升了性能和效率，为零样本域适应提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有零样本域适应的文本驱动方法难以捕捉复杂的真实世界变异，并且由于其对齐过程显著增加了适应时间。

**Method:** 本文提出了SIDA，一种新颖高效的零样本域适应方法，利用合成图像。首先创建详细的源域图像，然后应用图像翻译以反映目标域的风格。接着，利用这些合成图像的风格特征作为目标域的代理。基于这些特征，引入了域混合（Domain Mix）和补丁风格迁移（Patch Style Transfer）模块，以有效建模真实世界变异。域混合混合多种风格以扩展域内表示，而补丁风格迁移为单个补丁分配不同的风格。

**Result:** 在各种零样本适应场景，特别是在具有挑战性的域中，展示了最先进的性能。此外，通过显著减少整体适应时间，实现了高效率。

**Conclusion:** SIDA通过利用合成图像并结合Domain Mix和Patch Style Transfer模块，有效解决了零样本域适应中现有方法的局限性，实现了卓越的性能和效率。

> **ai_Abstract:** 本文提出了SIDA，一种新颖高效的零样本域适应方法。针对现有文本驱动方法在捕捉复杂真实世界变异和适应时间上的不足，SIDA利用合成图像的风格特征作为目标域的代理。通过创建源域图像并进行图像翻译生成合成图像，并引入Domain Mix和Patch Style Transfer模块来有效建模真实世界变异。实验证明SIDA在零样本适应场景中达到了最先进的性能，并显著提高了适应效率。

> **摘要翻译:** 零样本域适应是一种无需利用目标域图像数据即可使模型适应目标域的方法。为了在没有目标图像的情况下实现适应，现有研究利用CLIP的嵌入空间和文本描述来模拟目标域风格特征。尽管零样本域适应在之前取得了进展，但我们观察到这些文本驱动的方法难以捕捉复杂的真实世界变异，并且由于其对齐过程显著增加了适应时间。我们没有依赖文本描述，而是探索利用图像数据来解决问题，图像数据提供了多样化和更细粒度的风格线索。在这项工作中，我们提出了SIDA，一种新颖高效的零样本域适应方法，利用合成图像。为了生成合成图像，我们首先创建详细的源域图像，然后应用图像翻译以反映目标域的风格。然后，我们利用这些合成图像的风格特征作为目标域的代理。基于这些特征，我们引入了域混合（Domain Mix）和补丁风格迁移（Patch Style Transfer）模块，这些模块能够有效地建模真实世界变异。特别是，域混合混合多种风格以扩展域内表示，而补丁风格迁移为单个补丁分配不同的风格。我们通过在各种零样本适应场景，特别是在具有挑战性的域中，展示了最先进的性能来证明我们方法的有效性。此外，我们的方法通过显著减少整体适应时间实现了高效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [253] [EVEv2: Improved Baselines for Encoder-Free Vision-Language Models](https://arxiv.org/abs/2502.06788)
> *EVEv2：改进的无编码器视觉-语言模型基线*

*Haiwen Diao, Xiaotong Li, Yufeng Cui, Yueze Wang, Haoge Deng, Ting Pan, Wenxuan Wang, Huchuan Lu, Xinlong Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 无编码器VLM, 视觉-语言模型, EVEv2, 多模态系统, 数据效率

**Comment:** 20 pages, 10 figures, Accepted by ICCV2025 (highlight)

> **TL;DR:** EVEv2提出了一种改进的无编码器视觉-语言模型系列，通过有效的策略和训练方法，实现了与主流基于编码器模型相媲美的性能，并展示了卓越的数据效率和视觉推理能力。

**AI_Comments:** EVEv2的创新之处在于其专注于无编码器、纯解码器的多模态架构，这简化了系统结构并提高了部署效率。通过在统一模型中有效处理模态间干扰和优化训练策略，该研究为构建更高效、更具扩展性的视觉-语言模型提供了重要基线和深入见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有无编码器视觉-语言模型(VLMs)正迅速缩小与基于编码器模型的性能差距，这凸显了结构简单且部署高效的统一多模态系统的巨大潜力。本文旨在深入挖掘无编码器VLM未被充分研究的特性，并系统性地阐明使用预训练视觉编码器、离散分词器和从头开始构建的极简视觉层VLM之间的性能差距。

**Method:** 本文系统性地阐明了VLM之间的性能差距，并开发了能与主流基于编码器VLM媲美的有效策略。通过深入研究，推出了EVEv2.0系列无编码器VLM。具体方法包括：(i) 在统一模型中正确分解并分层关联视觉和语言，以减少模态间的干扰。(ii) 设计良好的训练策略，以实现对无编码器VLM的有效优化。

**Result:** EVEv2.0系列模型展示了卓越的数据效率和强大的视觉推理能力，并且在性能上能够与主流的基于编码器VLM相媲美。

**Conclusion:** EVEv2.0代表了开发跨模态的纯解码器架构的全面研究。

> **ai_Abstract:** 本文介绍了EVEv2.0，一个改进的无编码器视觉-语言模型系列，旨在缩小与基于编码器模型之间的性能差距。研究深入探讨了无编码器VLM的特性，并通过在统一模型中分解和分层关联视觉与语言，以及设计高效的训练策略，实现了卓越的数据效率和视觉推理能力，使其性能可与主流基于编码器模型媲美。

> **摘要翻译:** 现有无编码器视觉-语言模型（VLMs）正迅速缩小与基于编码器模型的性能差距，这凸显了结构简单且部署高效的统一多模态系统的巨大潜力。我们系统地阐明了使用预训练视觉编码器、离散分词器和从头开始构建的极简视觉层的VLM之间的性能差距，深入挖掘了无编码器VLM未被充分研究的特性。我们为无编码器VLM开发了能与主流基于编码器VLM媲美的有效策略。经过深入研究，我们推出了EVEv2.0，一个全新改进的无编码器VLM系列。我们展示了：(i) 在统一模型中正确分解并分层关联视觉和语言可以减少模态间的干扰。(ii) 设计良好的训练策略能够实现对无编码器VLM的有效优化。通过广泛评估，我们的EVEv2.0代表了开发跨模态纯解码器架构的全面研究，展示了卓越的数据效率和强大的视觉推理能力。代码已在 https://github.com/baaivision/EVE 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [254] [Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection](https://arxiv.org/abs/2507.18513)
> *迈向大规模地统计甲烷监测：基于部件的目标检测*

*Adhemar de Senneville, Xavier Bou, Thibaud Ehret, Rafael Grompone, Jean Louis Bonne, Nicolas Dumelie, Thomas Lauvaux, Gabriele Facciolo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 目标检测, 遥感, 甲烷监测, 生物消化池, 地统计

**Comment:** 

> **TL;DR:** 本文提出了一种基于部件的目标检测方法，并构建了一个新的数据集，用于大规模遥感图像中稀有目标（如生物消化池）的甲烷生产和排放监测。

**AI_Comments:** 本文的创新点在于提出了针对大规模遥感图像中稀有目标检测的基于部件的方法，并构建了一个针对生物消化池的专用数据集，这对于环境监测和地统计分析具有重要意义。通过结合目标检测与地统计估计，为环境影响评估提供了实用的工具。

<details>
  <summary>Details</summary>

**Motivation:** 遥感数据量巨大，导致在大地理区域检测稀有目标面临挑战，但这对于评估人类活动的环境影响至关重要。本文旨在解决大规模地统计甲烷监测问题，具体关注法国生物消化池的甲烷生产和排放。

**Method:** 本文引入了一个包含生物消化池的新数据集，该数据集具有小规模的训练和验证集以及高度不平衡的大规模测试集。开发了一种基于部件的方法，该方法考虑了生物消化池的关键子元素以提高初始检测效果。随后，将此方法应用于新的、未见的区域以建立生物消化池清单，并计算给定区域和时间内归因于这些基础设施的甲烷产量地统计估计。

**Result:** 成功建立了生物消化池的清单，并计算了这些基础设施在给定区域和时间内的甲烷产量地统计估计。

**Conclusion:** 本文通过提出一种基于部件的目标检测方法和构建专用数据集，有效解决了大规模遥感图像中稀有目标（生物消化池）的检测和甲烷监测问题，为环境影响评估提供了重要工具。

> **ai_Abstract:** 本文提出了一种基于部件的目标检测方法，旨在解决大规模遥感图像中稀有目标检测的挑战，并应用于法国生物消化池的甲烷生产和排放监测。研究引入了一个新的生物消化池数据集，并开发了考虑生物消化池子元素的检测方法，以提高检测精度。该方法成功用于建立生物消化池清单，并进一步计算了甲烷产量的地统计估计，为大规模环境影响评估提供了解决方案。

> **摘要翻译:** 目标检测是计算机视觉在遥感图像中的主要应用之一。尽管遥感数据的可用性日益增加，但其庞大的数据量在广阔地理区域检测稀有目标时带来了挑战。矛盾的是，这一普遍挑战对于许多应用至关重要，例如大规模评估某些人类活动对环境的影响。在本文中，我们提出通过研究法国生物消化池的甲烷生产和排放来解决这个问题。我们首先引入了一个包含生物消化池的新数据集，该数据集具有小规模的训练和验证集，以及一个对无目标观测高度不平衡的大规模测试集，因为此类地点是稀有的。我们开发了一种基于部件的方法，该方法考虑了生物消化池的基本子元素以提升初始检测效果。为此，我们将我们的方法应用于新的、未见的区域，以建立生物消化池的清单。然后，我们计算了在给定区域和给定时间段内可归因于这些基础设施的甲烷产量的地统计估计。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [256] [Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion](https://arxiv.org/abs/2412.03515)
> *将扩散模型蒸馏为高效的3D LiDAR场景补全*

*Shengyuan Zhang, An Zhao, Ling Yang, Zejian Li, Chenye Meng, Haoran Xu, Tianrun Chen, AnYang Wei, Perry Pengyun GU, Lingyun Sun* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 3D LiDAR, 场景补全, 模型蒸馏, 结构损失

**Comment:** This paper is accept by ICCV'25(Oral), the model and code are
  publicly available on https: //github.com/happyw1nd/ScoreLiDAR

> **TL;DR:** 本文提出ScoreLiDAR，一种针对3D LiDAR场景补全的蒸馏方法，通过减少采样步骤并引入结构损失，显著提升了扩散模型的补全速度和质量，使其更适用于自动驾驶等实时应用。

**AI_Comments:** 本文通过提出ScoreLiDAR蒸馏方法和新型结构损失，有效地解决了扩散模型在3D LiDAR场景补全中速度慢的瓶颈，使其更适用于自动驾驶等对实时性要求高的应用。结构损失的引入是其创新点之一，确保了蒸馏后模型能够保持高质量的几何结构。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在3D LiDAR场景补全中展现出强大的训练稳定性和高质量，但其缓慢的采样速度限制了实际应用，尤其是在需要高效感知周围环境的自动驾驶车辆中。

**Method:** 本文提出ScoreLiDAR，一种专为3D LiDAR场景补全模型设计的新型蒸馏方法，能够使蒸馏后的模型在显著更少的步骤中完成采样。为提高补全质量，还引入了一种新颖的结构损失（Structural Loss），该损失包含一个约束整体结构的场景级项和一个约束关键地标点及其相对配置的点级项，以帮助模型捕获3D LiDAR场景的几何结构。

**Result:** 在SemanticKITTI数据集上，ScoreLiDAR将每帧补全时间从30.55秒显著加速到5.37秒（>5倍），并且与最先进的3D LiDAR场景补全模型相比，实现了卓越的性能。

**Conclusion:** ScoreLiDAR成功解决了扩散模型在3D LiDAR场景补全中采样速度慢的瓶颈，通过有效的蒸馏和结构损失，在显著加速的同时保持或提升了补全质量，使其更适合实际应用。

> **ai_Abstract:** 本文提出了一种名为ScoreLiDAR的新型蒸馏方法，旨在解决3D LiDAR场景补全中扩散模型采样速度慢的问题。ScoreLiDAR通过减少采样步骤显著提高效率，并引入结构损失以更好地捕捉场景的几何结构，从而在保持高质量的同时加速补全过程。实验结果表明，该方法在SemanticKITTI数据集上实现了超过5倍的加速，并超越了现有最先进的模型。

> **摘要翻译:** 扩散模型因其强大的训练稳定性和高补全质量而被应用于3D LiDAR场景补全。然而，缓慢的采样速度限制了基于扩散的场景补全模型的实际应用，因为自动驾驶车辆需要高效感知周围环境。本文提出了一种专门针对3D LiDAR场景补全模型的新型蒸馏方法，称为ScoreLiDAR，该方法实现了高效且高质量的场景补全。ScoreLiDAR使蒸馏后的模型能够在显著更少的步骤中进行采样。为了提高补全质量，我们还引入了一种新颖的结构损失（Structural Loss），它鼓励蒸馏模型捕获3D LiDAR场景的几何结构。该损失包含一个约束整体结构的场景级项和一个约束关键地标点及其相对配置的点级项。广泛的实验表明，ScoreLiDAR在SemanticKITTI数据集上将每帧补全时间从30.55秒显著加速到5.37秒（>5倍），并且与最先进的3D LiDAR场景补全模型相比，实现了卓越的性能。我们的模型和代码已在https://github.com/happyw1nd/ScoreLiDAR上公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [262] [EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs](https://arxiv.org/abs/2507.18342)
> *EgoExoBench：一个用于多模态大语言模型中第一人称和第三人称视角视频理解的基准*

*Yuping He, Yifei Huang, Guo Chen, Baoqi Pei, Jilan Xu, Tong Lu, Jiangmiao Pang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** EgoExoBench, 多模态大语言模型, 跨视角推理, 视频理解, 基准

**Comment:** 

> **TL;DR:** EgoExoBench是一个新的基准，用于评估多模态大语言模型（MLLMs）在第一人称和第三人称视角之间进行跨视角推理的能力。研究发现，尽管当前MLLMs在单视角任务上表现良好，但在跨视角语义对齐、视角关联和时间推理方面表现不佳。

**AI_Comments:** EgoExoBench的创新之处在于它是首个专门针对MLLMs跨第一人称和第三人称视角视频理解与推理的基准。这解决了当前MLLMs研究中一个未被充分探索的关键领域，对于开发更具类人智能的具身智能体和智能助手至关重要。基准的设计涵盖了多样的子任务和挑战，有助于全面揭示现有模型的局限性，并为未来的模型改进指明方向。其重要性在于为社区提供了一个标准化的评估工具，有望加速该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 人类智能固有的能力是在第一人称（自我中心）和第三人称（异我中心）视角之间转移和整合知识。尽管多模态大语言模型（MLLMs）取得了快速进展，但它们进行此类跨视角推理的能力尚未被探索。为了解决这一问题，研究人员引入了EgoExoBench。

**Method:** 研究人员引入了EgoExoBench，这是第一个用于自我中心-异我中心视频理解和推理的基准。该基准基于公开数据集构建，包含超过7,300个问答对，涵盖了语义对齐、视角关联和时间推理三个核心挑战下的十一个子任务。研究人员评估了13个最先进的MLLMs。

**Result:** 评估结果发现，尽管这些模型在单视角任务上表现出色，但它们在跨视角对齐语义、准确关联视角以及在自我-异我情境中推断时间动态方面存在困难。

**Conclusion:** EgoExoBench有望成为研究具身智能体和寻求类人跨视角智能的智能助手的重要资源。

> **ai_Abstract:** 本文介绍了EgoExoBench，一个旨在评估多模态大语言模型（MLLMs）在第一人称和第三人称视角之间进行跨视角视频理解和推理能力的基准。该基准包含超过7,300个问答对，覆盖语义对齐、视角关联和时间推理等任务。通过对13个SOTA MLLMs的评估发现，虽然它们在单视角任务上表现良好，但在跨视角推理方面仍面临挑战。EgoExoBench旨在推动具身智能体和智能助手领域在跨视角智能方面的研究。

> **摘要翻译:** 将第一人称（自我中心）和第三人称（异我中心）视角的知识进行转移和整合是人类智能的内在特性，使人类能够向他人学习并传达自身经验中的见解。尽管多模态大语言模型（MLLMs）取得了快速进展，但它们进行此类跨视角推理的能力尚未被探索。为了解决这一问题，我们引入了EgoExoBench，这是第一个用于自我中心-异我中心视频理解和推理的基准。EgoExoBench基于公开数据集构建，包含超过7,300个问答对，涵盖了语义对齐、视角关联和时间推理三个核心挑战下的十一个子任务。我们评估了13个最先进的MLLMs，发现尽管这些模型在单视角任务上表现出色，但它们在跨视角对齐语义、准确关联视角以及在自我-异我情境中推断时间动态方面存在困难。我们希望EgoExoBench能为研究具身智能体和寻求类人跨视角智能的智能助手提供宝贵资源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [268] [OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments](https://arxiv.org/abs/2507.17959)
> *OPEN：一个用于虚拟康复学习环境中老年患者参与度识别的基准数据集和基线*

*Ali Abedi, Sadaf Safa, Tracey J. F. Colella, Shehroz S. Khan* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 老年患者, 参与度识别, 虚拟康复, 数据集, 机器学习

**Comment:** 14 pages, 3 figures, 7 tables

> **TL;DR:** 本文介绍了OPEN数据集，这是一个为虚拟康复中老年人患者参与度识别而设计的最大规模基准数据集，并提供基线模型，准确率高达81%。

**AI_Comments:** 本文最大的创新在于创建了迄今为止最大的、专门针对老年患者在虚拟康复环境中参与度识别的开放数据集OPEN。这解决了现有研究中老年人群体数据缺乏的痛点，并考虑了隐私保护。数据集提供的多模态特征和详细标注，以及不同时间长度的样本，极大地促进了AI在老年健康领域的应用。其提出的基线模型也证明了数据集的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在虚拟学习环境中，特别是虚拟康复中，参与度对于患者满意度、表现和依从性至关重要，但准确测量虚拟群体环境中的参与度仍然是一个挑战。现有的针对老年人的研究和数据集有限，并且常常忽视语境相关性和跨会话的纵向性质。因此，需要一个支持AI驱动的参与度识别的新数据集。

**Method:** 研究引入了OPEN（老年患者参与度）数据集，该数据集从11名老年患者在为期六周的每周虚拟小组学习会话中收集，作为心脏康复的一部分，产生了超过35小时的数据。为保护隐私，原始视频被保留，发布的数据包括面部、手部和身体关节地标，以及从视频中提取的情感和行为特征。标注包括二元参与状态、情感和行为标签以及上下文类型指示器。数据集提供了5秒、10秒、30秒和可变长度的样本版本。为展示其效用，研究训练了多个机器学习和深度学习模型。

**Result:** OPEN数据集是同类中最大的数据集，包含超过35小时的数据。模型在参与度识别方面达到了高达81%的准确率。数据集包含面部、手部、身体关节地标以及情感和行为特征，并带有二元参与状态、情感和行为标签以及上下文类型指示器。数据集提供了不同长度的样本版本。

**Conclusion:** OPEN数据集为老龄人口的个性化参与度建模提供了可扩展的基础，并有助于更广泛的参与度识别研究。

> **ai_Abstract:** 本研究介绍了OPEN数据集，一个专门为虚拟康复学习环境中老年患者参与度识别设计的基准数据集。鉴于现有研究和数据在老年人群体中的不足，OPEN数据集通过收集11名老年患者在六周虚拟心脏康复课程中的超过35小时数据来填补这一空白，该数据集是同类中最大的。为保护隐私，数据集提供了面部、手部、身体关节地标以及情感行为特征，并进行了详细标注。研究还基于该数据集训练了多种机器学习和深度学习模型，实现了高达81%的参与度识别准确率，为老年人个性化参与度建模和更广泛的参与度识别研究奠定了基础。

> **摘要翻译:** 在虚拟学习中，参与度对于参与者的满意度、表现和依从性至关重要，尤其是在在线教育和虚拟康复中，互动交流起着关键作用。然而，在虚拟群体环境中准确测量参与度仍然是一个挑战。人们对使用人工智能（AI）进行大规模、真实世界、自动化参与度识别的兴趣日益增长。尽管参与度已在年轻学术人群中得到广泛研究，但针对虚拟和远程医疗学习环境中老年人的研究和数据集仍然有限。现有方法常常忽视语境相关性和参与度在会话间的纵向性质。本文介绍了OPEN（老年患者参与度），这是一个支持AI驱动的参与度识别的新颖数据集。它从11名老年患者在为期六周的每周虚拟小组学习会话中收集，作为心脏康复的一部分，产生了超过35小时的数据，使其成为同类中最大的数据集。为保护隐私，原始视频被保留；相反，发布的数据包括面部、手部和身体关节地标，以及从视频中提取的情感和行为特征。标注包括二元参与状态、情感和行为标签，以及上下文类型指示器，例如教师是面向小组还是个人。数据集提供了5秒、10秒、30秒和可变长度样本的版本。为了展示其效用，训练了多个机器学习和深度学习模型，参与度识别准确率高达81%。OPEN为老龄人口的个性化参与度建模提供了可扩展的基础，并有助于更广泛的参与度识别研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [278] [T2VWorldBench: A Benchmark for Evaluating World Knowledge in Text-to-Video Generation](https://arxiv.org/abs/2507.18107)
> *T2VWorldBench：一个评估文本到视频生成中世界知识的基准*

*Yubin Chen, Xuyang Guo, Zhenmei Shi, Zhao Song, Jiahao Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 文本到视频生成, 世界知识, 基准, 评估, 语义一致性

**Comment:** 

> **TL;DR:** 当前文本到视频 (T2V) 模型在利用世界知识方面存在不足。本文提出了 T2VWorldBench，一个用于系统评估 T2V 模型世界知识生成能力的基准，涵盖广泛领域。评估结果表明，大多数现有模型无法理解世界知识并生成事实正确的视频。

**AI_Comments:** 该论文的创新之处在于构建了第一个专门针对文本到视频生成中世界知识的系统评估基准，填补了该领域的一个重要空白。其重要性在于揭示了当前 T2V 模型在事实准确性方面的局限性，并为未来研究指明了方向，以开发更具常识推理和事实生成能力的模型。

<details>
  <summary>Details</summary>

**Motivation:** 文本到视频 (T2V) 模型在生成视觉上合理的场景方面表现出色，但它们利用世界知识以确保语义一致性和事实准确性的能力尚未得到充分研究。为了解决这一挑战，本文提出了 T2VWorldBench。

**Method:** 本文提出了 T2VWorldBench，这是第一个系统评估文本到视频模型世界知识生成能力的框架。该基准涵盖了 6 个主要类别、60 个子类别和 1,200 个提示，涉及物理、自然、活动、文化、因果关系和物体等广泛领域。为了兼顾人类偏好和可扩展评估，该基准结合了人工评估和使用视觉语言模型 (VLM) 的自动化评估。

**Result:** 本文评估了当前可用的 10 个最先进的文本到视频模型（包括开源和商业模型），发现大多数模型无法理解世界知识并生成真正正确的视频。

**Conclusion:** 这些发现指出了当前文本到视频模型在利用世界知识能力方面存在的关键差距，为构建具有强大常识推理和事实生成能力的模型提供了宝贵的研究机会和切入点。

> **ai_Abstract:** 本文介绍了 T2VWorldBench，一个用于系统评估文本到视频 (T2V) 生成模型世界知识能力的基准。该基准包含 6 个主要类别、60 个子类别和 1,200 个提示，并结合了人工评估和自动化 (VLM) 评估。对 10 个先进 T2V 模型的评估结果表明，当前模型在利用世界知识生成事实正确视频方面存在显著不足，这指出了该领域的一个关键研究空白。

> **摘要翻译:** 文本到视频 (T2V) 模型在生成视觉上合理的场景方面表现出卓越的性能，但其利用世界知识以确保语义一致性和事实准确性的能力在很大程度上尚未得到充分研究。针对这一挑战，我们提出了 T2VWorldBench，这是第一个系统评估文本到视频模型世界知识生成能力的框架，涵盖物理、自然、活动、文化、因果关系和物体等广泛领域的 6 个主要类别、60 个子类别和 1,200 个提示。为了兼顾人类偏好和可扩展评估，我们的基准结合了人工评估和使用视觉语言模型 (VLM) 的自动化评估。我们评估了目前最先进的 10 个文本到视频模型，包括开源模型和商业模型，发现大多数模型无法理解世界知识并生成真正正确的视频。这些发现指出了当前文本到视频模型在利用世界知识能力方面存在的关键差距，为构建具有强大常识推理和事实生成能力的模型提供了宝贵的研究机会和切入点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [279] [Robust Multi-View Learning via Representation Fusion of Sample-Level Attention and Alignment of Simulated Perturbation](https://arxiv.org/abs/2503.04151)
> *鲁棒多视图学习：通过样本级注意力表示融合和模拟扰动对齐*

*Jie Xu, Na Zhao, Gang Niu, Masashi Sugiyama, Xiaofeng Zhu* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 多视图学习, 鲁棒性, 表示融合, 注意力机制, 对比学习

**Comment:** 

> **TL;DR:** 本文提出了一种名为RML的鲁棒多视图学习方法，通过结合基于Transformer的融合网络（带样本级注意力）和基于模拟扰动的对比学习框架，有效处理异构和不完美的多视图数据。

**AI_Comments:** 本文提出了一种创新方法，通过直接解决数据不完美性和异构性来增强多视图学习的鲁棒性。结合基于Transformer的融合网络与样本级注意力，以及新颖的基于模拟扰动的对比学习框架，是一项重要贡献。其自监督特性和作为正则化技术的适用性进一步拓宽了其效用，使其成为解决真实世界多视图数据挑战的多功能方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视图学习（MVL）方法在处理真实世界中异构和不完美的多视图数据集时面临挑战，这限制了它们的有效性和应用潜力。

**Method:** 本文提出了一种新颖的鲁棒多视图学习方法（RML），它同时进行表示融合和对齐。具体来说，RML引入了一个多视图Transformer融合网络，将异构多视图数据转换为同质词嵌入，并通过样本级注意力机制整合多个视图以获得融合表示。此外，RML提出了一个基于模拟扰动的多视图对比学习框架，动态生成噪声和不可用扰动来模拟不完美数据条件。模拟的噪声和不可用数据获得两种不同的融合表示，并利用对比学习对它们进行对齐，以学习判别性和鲁棒性表示。RML是自监督的，也可以作为正则化应用于下游任务。

**Result:** RML在多视图无监督聚类、噪声标签分类以及作为跨模态哈希检索的即插即用模块中进行了实验应用。广泛的对比实验和消融研究验证了RML的有效性。

**Conclusion:** 本文成功提出了一种鲁棒的多视图学习方法RML，通过表示融合和模拟扰动对齐，解决了异构和不完美多视图数据带来的挑战，并在各种任务中展示了其有效性。

> **ai_Abstract:** 本文提出了一种名为RML的新型鲁棒多视图学习方法，旨在解决现有MVL方法在处理异构和不完美真实世界数据时的局限性。RML采用了一个多视图Transformer融合网络，利用样本级注意力从不同视图创建统一的表示。此外，它整合了一个基于模拟扰动的对比学习框架，生成合成噪声以对齐表示并学习鲁棒特征。RML是自监督的，并可作为下游任务的正则化器。在多视图无监督聚类、噪声标签分类和跨模态哈希检索等实验中，RML的有效性得到了证实。

> **摘要翻译:** 最近，多视图学习（MVL）因其融合来自多个视图的判别性信息的能力而受到广泛关注。然而，真实世界的多视图数据集通常是异构且不完美的，这通常导致为特定视图组合设计的MVL方法缺乏应用潜力并限制了它们的有效性。为了解决这个问题，我们提出了一种新颖的鲁棒MVL方法（即RML），该方法同时进行表示融合和对齐。具体来说，我们引入了一个简单但有效的多视图Transformer融合网络，我们将异构多视图数据转换为同质词嵌入，然后通过样本级注意力机制整合多个视图以获得融合表示。此外，我们提出了一种基于模拟扰动的多视图对比学习框架，该框架动态生成噪声和不可用扰动以模拟不完美数据条件。模拟的噪声和不可用数据获得了两种不同的融合表示，我们利用对比学习对它们进行对齐，以学习判别性和鲁棒性表示。我们的RML是自监督的，也可以作为正则化应用于下游任务。在实验中，我们将其应用于多视图无监督聚类、噪声标签分类，并作为跨模态哈希检索的即插即用模块。广泛的对比实验和消融研究验证了RML的有效性。代码可在https://github.com/SubmissionsIn/RML获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [286] [Object segmentation in the wild with foundation models: application to vision assisted neuro-prostheses for upper limbs](https://arxiv.org/abs/2507.18517)
> *野外环境下的物体分割与基础模型：在视觉辅助上肢神经假体中的应用*

*Bolutife Atoki, Jenny Benois-Pineau, Renaud Péteri, Fabien Baldacci, Aymar de Rugy* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 物体分割, 基础模型, SAM, 神经假体, 注视点

**Comment:** 

> **TL;DR:** 本文探讨了在复杂视觉场景中，如何利用基础模型（如SAM）结合注视点提示进行物体分割，并将其应用于视觉引导的上肢神经假体，实现了分割质量的显著提升。

**AI_Comments:** 本文的创新点在于将基础模型（SAM）应用于“野外”环境下的物体分割，并结合注视点生成提示来提高其在复杂场景中的性能，尤其是在上肢神经假体这一特定应用背景下，避免了对特定对象的广泛微调。这突显了基础模型在应对真实世界挑战性场景中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决在高度杂乱的视觉场景中，利用在大量和多样化对象上训练的基础模型进行语义对象分割的问题，尤其是在不进行特定图像微调的情况下，并将其应用于视觉引导上肢神经假体这一“野外”环境。

**Method:** 提出了一种基于注视点生成提示的方法，以引导Segment Anything Model (SAM) 进行分割，并使用以自我为中心的视觉数据对SAM进行微调。

**Result:** 在Grasping-in-the-Wild语料库的真实世界挑战性数据上，IoU分割质量指标提高了0.51点。

**Conclusion:** 所提出的方法成功地提高了基础模型在杂乱、真实世界场景中的物体分割能力，特别适用于神经假体等视觉辅助应用。

> **ai_Abstract:** 本研究探讨了在复杂“野外”视觉场景中，如何利用基础模型进行语义物体分割，尤其针对视觉辅助上肢神经假体的应用。作者提出一种基于注视点生成提示来引导Segment Anything Model (SAM)的方法，并使用以自我为中心的视觉数据对SAM进行微调。实验结果表明，该方法在Grasping-in-the-Wild数据集上，将IoU分割质量指标提高了0.51点，证明了其在实际应用中的有效性。

> **摘要翻译:** 在这项工作中，我们利用基础模型解决语义对象分割问题。我们研究了在大量和多样化对象上训练的基础模型，是否能够在不针对包含日常物品的特定图像进行微调的情况下，在高度杂乱的视觉场景中执行对象分割。“野外”环境的背景是由视觉引导上肢神经假体的目标应用所驱动的。我们提出了一种基于注视点生成提示的方法，以在我们的分割场景中引导Segment Anything Model (SAM)，并对其进行以自我为中心的视觉数据微调。我们方法的评估结果显示，在Grasping-in-the-Wild语料库的真实世界挑战性数据上，IoU分割质量指标提高了0.51点，该语料库已在RoboFlow平台（https://universe.roboflow.com/iwrist/grasping-in-the-wild）上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [287] [DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts](https://arxiv.org/abs/2412.10510)
> *DEFAME：基于动态证据的多模态专家事实核查*

*Tobias Braun, Mark Rothermel, Marcus Rohrbach, Anna Rohrbach* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 事实核查, 多模态, 零样本, 虚假信息, 动态证据

**Comment:** ICML 2025 version. 9 pages main paper, 35 pages with appendix, 18
  figures and 7 tables. Corrected two inconsistent numbers in Table 2

> **TL;DR:** DEFAME是一个模块化、零样本的多模态事实核查系统，通过动态选择工具和搜索深度来提取和评估文本和视觉证据，并在多个基准测试中超越现有方法，证明了其优越性和实时事实核查潜力。

**AI_Comments:** DEFAME的创新之处在于其模块化、零样本的多模态专家管道，能够动态选择工具和搜索深度，并处理文本和图像证据，这解决了现有事实核查系统在多模态和可解释性方面的不足。引入新的ClaimReview2024+基准测试，并证明其对GPT-4o基线的显著优势，突出了其在应对最新信息和实时场景下的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 虚假信息的泛滥要求可靠且可扩展的事实核查解决方案。现有方法存在仅限于文本、缺乏可解释性或仅依赖参数知识等局限性。

**Method:** 本文提出了DEFAME，一个模块化、零样本的MLLM管道，用于开放域的文本-图像声明验证。DEFAME采用六阶段过程，动态选择工具和搜索深度以提取和评估文本和视觉证据，并生成结构化的多模态报告。

**Result:** DEFAME在VERITE、AVerITeC和MOCHEG等流行基准测试中超越所有现有方法，成为单模态和多模态事实核查的最新SOTA系统。此外，在新引入的ClaimReview2024+多模态基准测试中，DEFAME显著优于GPT-4o基线，显示出时间泛化能力和实时事实核查的潜力。

**Conclusion:** DEFAME是目前最先进的事实核查系统，能够有效处理多模态信息，并具有良好的时间泛化能力和实时应用潜力。

> **ai_Abstract:** 本文介绍了DEFAME，一个用于开放域文本-图像声明验证的模块化、零样本多模态事实核查系统。DEFAME通过动态证据提取和评估，能够处理图像信息并生成结构化报告。它在多个现有基准测试中超越了所有先前方法，并在一项新的、避免数据泄露的多模态基准测试中显著优于GPT-4o基线，展示了其先进性、时间泛化能力和实时事实核查潜力。

> **摘要翻译:** 虚假信息的扩散要求可靠且可扩展的事实核查解决方案。我们提出了基于动态证据的多模态专家事实核查（DEFAME），这是一个模块化、零样本的MLLM（多语言大模型）管道，用于开放域的文本-图像声明验证。DEFAME采用六阶段过程，动态选择工具和搜索深度以提取和评估文本和视觉证据。与以往仅限于文本、缺乏可解释性或仅依赖参数知识的方法不同，DEFAME执行端到端验证，考虑声明和证据中的图像，同时生成结构化的多模态报告。在流行的VERITE、AVerITeC和MOCHEG基准测试中的评估表明，DEFAME超越了所有现有方法，确立了其作为单模态和多模态事实核查新SOTA系统的地位。此外，我们引入了一个新的多模态基准测试ClaimReview2024+，其中包含GPT-4o知识截止日期后的声明，从而避免了数据泄露。在此基准测试中，DEFAME显著优于GPT-4o基线，显示出时间泛化能力和实时事实核查的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [297] [When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning](https://arxiv.org/abs/2503.07588)
> *当大型视觉-语言模型遇上大型遥感图像：从粗到精的文本引导令牌剪枝*

*Junwei Luo, Yingying Zhang, Xue Yang, Kang Wu, Qi Zhu, Lei Liang, Jingdong Chen, Yansheng Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型遥感图像, 视觉-语言模型, 令牌剪枝, 粗到精, LRS-VQA

**Comment:** 18 pages, 6 figures, 18 tables

> **TL;DR:** 本文提出了一种用于大型遥感图像（RSI）的高效视觉-语言理解方法，通过文本引导的粗到精令牌剪枝和动态图像金字塔集成来减少计算量并保留细节，同时构建了一个新的大规模基准LRS-VQA。

**AI_Comments:** 本文的创新点在于提出了一个结合文本引导和动态图像金字塔的粗到精令牌剪枝框架，有效解决了LVLM处理大型遥感图像时的计算效率和信息保留难题。同时，构建大规模、高分辨率的LRS-VQA基准对于推动该领域的发展具有重要意义，弥补了现有评估工具的不足。该研究对于未来LVLM在遥感领域的实际应用具有重要的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型视觉-语言模型（LVLMs）在处理大型遥感图像（RSIs）时面临效率和信息丢失的挑战，因为它们要么使用有限的预定义网格导致信息丢失，要么使用无限网格导致计算成本过高。此外，现有用于评估LVLMs在大型RSI上感知能力的基准存在问题，例如问题多样性有限和图像尺寸受限。

**Method:** 本文提出了一种结合动态图像金字塔（DIP）的文本引导令牌剪枝方法。该方法包括：(i) 区域焦点模块（RFM），利用文本感知区域定位能力识别关键视觉令牌；(ii) 基于DIP的从粗到精图像瓦片选择和视觉令牌剪枝策略，由RFM输出引导，避免直接处理整个大型图像。此外，还构建了一个名为LRS-VQA的新基准，包含7,333个问答对，跨越8个类别，图像长度高达27,328像素。

**Result:** 本文方法在四个数据集上优于现有高分辨率策略，并且与现有令牌减少方法相比，在高分辨率设置下表现出更高的效率。

**Conclusion:** 本文提出的文本引导令牌剪枝方法，结合动态图像金字塔，有效解决了大型遥感图像在大型视觉-语言模型中处理的效率和细节保留问题。同时，构建的新基准LRS-VQA为评估LVLMs在大型遥感图像上的感知能力提供了更广阔和多样化的平台。

> **ai_Abstract:** 本文针对大型遥感图像（RSI）在大型视觉-语言模型（LVLMs）中处理时面临的效率和信息丢失问题，提出了一种名为“从粗到精的文本引导令牌剪枝”的新方法。该方法结合动态图像金字塔（DIP），通过区域焦点模块（RFM）识别关键视觉令牌，并采用粗到精的图像瓦片选择与令牌剪枝策略，以保留图像细节并降低计算成本。此外，为了弥补现有基准的不足，论文还构建了一个包含大量高分辨率问答对的新基准LRS-VQA。实验结果表明，该方法在性能和效率上均优于现有策略。

> **摘要翻译:** 高效地理解大型遥感图像（RSIs）的视觉-语言信息既有意义又充满挑战。当前的大型视觉-语言模型（LVLMs）通常采用有限的预定义网格来处理图像，这在处理千兆像素的RSIs时会导致信息丢失。反之，使用无限网格会显著增加计算成本。为了在减少计算复杂度的同时保留图像细节，我们提出了一种结合动态图像金字塔（DIP）的文本引导令牌剪枝方法。我们的方法引入了：(i) 一个区域焦点模块（RFM），该模块利用文本感知的区域定位能力来识别关键视觉令牌；(ii) 一个基于DIP的从粗到精的图像瓦片选择和视觉令牌剪枝策略，该策略由RFM的输出引导，并避免直接处理整个大型图像。此外，现有用于评估LVLMs在大型RSI上感知能力的基准存在问题，例如问题多样性有限和图像尺寸受限。我们构建了一个名为LRS-VQA的新基准，其中包含7,333个问答对，涵盖8个类别，图像长度高达27,328像素。我们的方法在使用相同数据的情况下，在四个数据集上优于现有高分辨率策略。此外，与现有令牌减少方法相比，我们的方法在高分辨率设置下表现出更高的效率。数据集和代码可在https://github.com/VisionXLab/LRS-VQA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [300] [VB-Mitigator: An Open-source Framework for Evaluating and Advancing Visual Bias Mitigation](https://arxiv.org/abs/2507.18348)
> *VB-Mitigator：一个用于评估和推进视觉偏差缓解的开源框架*

*Ioannis Sarridis, Christos Koutlis, Symeon Papadopoulos, Christos Diou* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉偏差, 偏差缓解, 开源框架, 计算机视觉, 公平性AI

**Comment:** 

> **TL;DR:** VB-Mitigator是一个开源框架，旨在统一和加速视觉偏差缓解方法的研究、评估和比较。

**AI_Comments:** VB-Mitigator的创新之处在于提供了一个统一且可扩展的开源平台，解决了视觉偏差缓解领域长期存在的碎片化实现和评估不一致问题。这对于促进公平AI研究的标准化和加速具有重要意义。它通过整合现有方法和数据集，并推荐最佳实践，极大地降低了研究门槛，并有助于更公平地比较不同方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 计算机视觉模型中的偏差是一个重大挑战，导致AI系统不公平、不可靠且泛化能力差。现有研究进展因实现分散和评估实践不一致而受阻，不同数据集和指标使得重现性和比较效果变得困难。

**Method:** 本文引入了Visual Bias Mitigator (VB-Mitigator)，一个开源框架，旨在简化视觉偏差缓解技术的开发、评估和比较分析。它提供了一个统一的研究环境，包含12种已建立的缓解方法和7个不同的基准数据集，并具有高度可扩展性，允许无缝集成额外的方法、数据集、指标和模型。

**Result:** VB-Mitigator作为一个基础代码库，旨在加速公平感知计算机视觉模型的研究。它还推荐了最佳评估实践，并提供了最先进方法之间的全面性能比较。

**Conclusion:** VB-Mitigator旨在通过提供统一的开源平台和推荐的评估实践，加速计算机视觉领域在偏差缓解方面的研究进展，从而促进公平AI系统的发展。

> **ai_Abstract:** 本文介绍了VB-Mitigator，一个开源框架，旨在解决计算机视觉模型中偏差缓解研究面临的挑战。通过提供统一的开发、评估和比较分析环境，VB-Mitigator集成了多种现有缓解方法和基准数据集，并具备高度可扩展性。该框架旨在标准化评估实践，加速公平感知AI系统的发展，并为研究人员提供一个进行方法比较和评估的基础平台。

> **摘要翻译:** 计算机视觉模型中的偏差仍然是一个重大挑战，常常导致人工智能系统不公平、不可靠且泛化能力差。尽管对偏差缓解的研究已经加剧，但由于碎片化的实现和不一致的评估实践，进展持续受阻。研究中使用的不同数据集和指标使可重现性复杂化，难以公平地评估和比较各种方法的有效性。为了克服这些限制，我们引入了视觉偏差缓解器（VB-Mitigator），一个开源框架，旨在简化视觉偏差缓解技术的开发、评估和比较分析。VB-Mitigator 提供了一个统一的研究环境，包含 12 种已建立的缓解方法和 7 个多样化的基准数据集。VB-Mitigator 的一个关键优势是其可扩展性，允许无缝集成额外的方法、数据集、指标和模型。VB-Mitigator 旨在通过作为研究社区开发和评估其方法的基础代码库，加速对公平感知计算机视觉模型的研究。为此，我们还推荐了最佳评估实践，并提供了最先进方法之间的全面性能比较。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [303] [Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring](https://arxiv.org/abs/2507.17987)
> *鬃狮蜥活动识别管线：一种基于AI的行为监测方法*

*Arsen Yermukan, Pedro Machado, Feliciano Domingos, Isibor Kennedy Ihianle, Jordan J. Bird, Stefano S. K. Kaburu, Samantha J. Ward* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 鬃狮蜥, 行为监测, YOLO, 目标检测, 自动化系统

**Comment:** 

> **TL;DR:** 该项目开发了一个基于YOLOv8s的自动化AI系统，用于实时视频监测鬃狮蜥的晒太阳和捕食行为，旨在提高行为监测的效率和数据质量。

**AI_Comments:** 这篇论文通过应用成熟的YOLO目标检测技术来解决爬行动物行为监测中的实际问题，具有创新性。其重要性在于提供了一个可扩展且高效的替代传统人工监测的方法，显著提升了动物行为学研究的效率和数据质量。然而，论文也明确指出了其局限性，即对小目标（如蟋蟀）的检测精度有待提高，这提示了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的鬃狮蜥行为监测耗时且易出错，因此需要一个自动化系统来提高效率和数据质量。

**Method:** 该项目引入了一个用于实时视频分析的自动化系统，使用YOLO对象检测模型（v5, v7, v8, v11, v12）来识别鬃狮蜥的晒太阳和捕食行为。模型在一个包含1200张鬃狮蜥、加热灯和蟋蟀的自定义公开数据集上进行训练，并选择YOLOv8s作为最佳模型。系统通过提取每帧对象坐标、应用时间插值和使用基于规则的逻辑来分类行为。

**Result:** YOLOv8s在准确性（mAP@0.5:0.95 = 0.855）和速度之间表现出最佳平衡。晒太阳行为检测可靠，但捕食行为检测准确性较低，主要原因是蟋蟀检测较弱（mAP@0.5 = 0.392）。

**Conclusion:** 该自动化系统为受控环境下爬行动物行为监测提供了一个可扩展的解决方案，显著提高了研究效率和数据质量。未来的改进将集中在通过扩展数据集或专用小物检测器来增强蟋蟀检测。

> **ai_Abstract:** 本文提出一个基于AI的自动化系统，利用YOLOv8s模型对鬃狮蜥的视频进行实时分析，以监测其晒太阳和捕食行为。该系统在自定义数据集上训练，并结合时间插值和规则逻辑进行行为分类。结果显示，晒太阳行为检测可靠，但捕食行为因蟋蟀检测精度不足而受限。该系统为爬行动物行为监测提供了高效且可扩展的解决方案。

> **摘要翻译:** 传统的鬃狮蜥（Pogona Viticeps）行为监测耗时且容易出错。本项目引入了一个用于实时视频分析的自动化系统，使用You Only Look Once（YOLO）对象检测模型来识别两种关键行为：晒太阳和捕食。我们使用一个包含1200张图像的自定义公开数据集训练了五种YOLO变体（v5、v7、v8、v11、v12），其中包括鬃狮蜥（600张）、加热灯（500张）和蟋蟀（100张）。YOLOv8s因其在准确性（mAP@0.5:0.95 = 0.855）和速度之间的卓越平衡而被选为最佳模型。该系统通过提取每帧对象坐标、应用时间插值以保持连续性，并使用基于规则的逻辑来分类特定行为来处理视频片段。晒太阳检测被证明是可靠的。然而，捕食检测的准确性较低，主要原因是蟋蟀检测较弱（mAP@0.5 = 0.392）。未来的改进将侧重于通过扩展数据集或专用小物检测器来增强蟋蟀检测。这种自动化系统为在受控环境中监测爬行动物行为提供了一个可扩展的解决方案，显著提高了研究效率和数据质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [304] [PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.17596)
> *PRIX: 从原始像素学习规划以实现端到端自动驾驶*

*Maciej K. Wozniak, Lianhang Liu, Yixi Cai, Patric Jensfelt* | **Category: cs.CV, cs.AI, cs.LG, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 端到端自动驾驶, 原始像素, 摄像头传感器, 规划, PRIX

**Comment:** under review

> **TL;DR:** PRIX是一种高效的端到端自动驾驶模型，仅使用摄像头数据直接从原始像素预测安全轨迹，无需激光雷达或显式BEV表示，并在性能上达到SOTA，同时显著提高了效率。

**AI_Comments:** PRIX的创新点在于它实现了仅基于原始像素的端到端自动驾驶，彻底摆脱了对昂贵激光雷达和计算密集型BEV特征的依赖，显著降低了部署成本和计算资源需求，对于推动量产车自动驾驶具有重要意义。CaRT模块的设计也提升了视觉特征的鲁棒性。其在性能上达到SOTA的同时，实现了更高的效率，这对于实际应用是关键的突破。

<details>
  <summary>Details</summary>

**Motivation:** 当前端到端自动驾驶模型面临模型尺寸大、依赖昂贵激光雷达传感器和计算密集型BEV特征表示的挑战，这限制了其可扩展性，尤其是在仅配备摄像头的量产车辆中。

**Method:** 本文提出了PRIX（Plan from Raw Pixels），一种新颖高效的端到端驾驶架构，仅使用摄像头数据，无需显式BEV表示，也无需激光雷达。PRIX利用视觉特征提取器与生成式规划头相结合，直接从原始像素输入预测安全轨迹。其核心组件是上下文感知重新校准Transformer（CaRT），一个旨在有效增强多级视觉特征以实现更鲁棒规划的新模块。

**Result:** PRIX在NavSim和nuScenes基准测试中达到了最先进的性能，与更大的多模态扩散规划器能力相当，但在推理速度和模型尺寸方面显著更高效。

**Conclusion:** PRIX为端到端自动驾驶提供了一个实用的解决方案，能够仅使用摄像头数据实现高水平的性能，同时具有更高的效率，使其适用于真实世界的部署。

> **ai_Abstract:** PRIX是一种新颖高效的端到端自动驾驶架构，旨在解决现有模型对激光雷达、BEV表示和大型模型尺寸的依赖。它仅通过摄像头数据，利用视觉特征提取器和生成式规划头，直接从原始像素预测安全轨迹。其核心是上下文感知重新校准Transformer（CaRT），用于增强视觉特征。PRIX在NavSim和nuScenes基准测试中展现了SOTA性能，且在推理速度和模型尺寸上远超现有大型多模态规划器，为实际部署提供了高效实用的解决方案。

> **摘要翻译:** 尽管端到端自动驾驶模型显示出有希望的结果，但其实际部署常常受到模型尺寸大、依赖昂贵激光雷达传感器和计算密集型BEV特征表示的阻碍。这限制了它们的可扩展性，特别是对于仅配备摄像头的量产车辆。为了应对这些挑战，我们提出了PRIX（Plan from Raw Pixels）。我们新颖高效的端到端驾驶架构仅使用摄像头数据运行，无需显式BEV表示，并放弃了对激光雷达的需求。PRIX利用视觉特征提取器与生成式规划头相结合，直接从原始像素输入预测安全轨迹。我们架构的核心组件是上下文感知重新校准Transformer（CaRT），一个旨在有效增强多级视觉特征以实现更鲁棒规划的新模块。我们通过全面的实验证明，PRIX在NavSim和nuScenes基准测试中达到了最先进的性能，与更大的多模态扩散规划器能力相当，同时在推理速度和模型尺寸方面显著更高效，使其成为实际部署的实用解决方案。我们的工作是开源的，代码将发布在https://maxiuw.github.io/prix。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [307] [Personalization Toolkit: Training Free Personalization of Large Vision Language Models](https://arxiv.org/abs/2502.02452)
> *个性化工具包：大型视觉语言模型的免训练个性化*

*Soroush Seifi, Vaggelis Dorovatas, Daniel Olmeda Reino, Rahaf Aljundi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 个性化, 大型视觉语言模型, 免训练, 检索增强生成, 视觉提示

**Comment:** 

> **TL;DR:** 提出一种新型免训练LVLM个性化方法，利用预训练模型、RAG和视觉提示，无需额外训练即可实现SOTA性能，并引入新基准。

**AI_Comments:** 本文的主要创新在于提出了“免训练”的个性化方法，与现有耗时训练方法相比，显著提高了实际部署的实用性。引入全面的真实世界基准对推动该领域发展也至关重要。这项工作通过使个性化更高效和可扩展，解决了大型视觉语言模型（LVLM）部署中的一个关键瓶颈。无需额外训练即可在图像和视频上执行多概念个性化是一项重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型视觉语言模型（LVLMs）的个性化方法依赖耗时的测试时训练，不适用于实际部署；当前的个性化基准也仅限于以对象为中心、单概念评估，缺乏全面性。因此，需要一种免训练的个性化方法和一个更全面的真实世界基准。

**Method:** 提出了一种新颖的免训练方法。该方法利用预训练的视觉基础模型提取独特特征，应用检索增强生成（RAG）技术识别视觉输入中的实例，并采用视觉提示策略指导模型输出。该模型无关的视觉工具包无需额外训练即可实现图像和视频的多概念个性化。

**Result:** 实现了最先进的结果，超越了现有的基于训练的方法。

**Conclusion:** 本文成功展示了一种新颖的、无需训练的大型视觉语言模型（LVLM）个性化方法，该方法高效、灵活，并取得了最先进的性能，解决了现有基于训练的方法和单概念基准的局限性。

> **ai_Abstract:** 本文介绍了一个“个性化工具包”，这是一种新颖的、无需训练的大型视觉语言模型（LVLM）个性化方法。针对现有耗时训练方法和狭窄基准的局限性，该方法利用预训练视觉基础模型、检索增强生成（RAG）和视觉提示，无需额外训练即可实现图像和视频的高效灵活多概念个性化。本文还引入了一个全面的真实世界基准。该方法取得了最先进的结果，超越了现有的基于训练的方法。

> **摘要翻译:** 大型视觉语言模型（LVLMs）的个性化涉及定制模型以识别特定用户和对象实例，并生成符合上下文的定制响应。现有方法通常依赖于耗时的测试时训练，针对每个用户或对象进行，这使得它们在实际部署中不切实际，这一限制也反映在当前的个性化基准中，这些基准侧重于以对象为中心、单概念的评估。在本文中，我们提出了一种新颖的免训练的LVLM个性化方法，并引入了一个全面的真实世界基准，旨在严格评估个性化任务的各个方面。我们的方法利用预训练的视觉基础模型提取独特特征，应用检索增强生成（RAG）技术识别视觉输入中的实例，并采用视觉提示策略指导模型输出。我们的模型无关视觉工具包无需任何额外训练即可实现图像和视频的高效灵活的多概念个性化。我们取得了最先进的结果，超越了现有的基于训练的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [316] [GaussianFusionOcc: A Seamless Sensor Fusion Approach for 3D Occupancy Prediction Using 3D Gaussians](https://arxiv.org/abs/2507.18522)
> *GaussianFusionOcc：一种使用3D高斯进行3D占用预测的无缝传感器融合方法*

*Tomislav Pavković, Mohammad-Ali Nikouei Mahani, Johannes Niedermayer, Johannes Betz* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D 占用预测, 传感器融合, 3D 高斯, 自动驾驶, 模态无关注意力

**Comment:** 

> **TL;DR:** GaussianFusionOcc利用3D高斯表示和无缝传感器融合（摄像头、激光雷达、雷达）进行3D占用预测，相比传统网格方法，显著提高了内存效率、推理速度，并超越了现有最先进的模型。

**AI_Comments:** 该论文的创新点在于将3D高斯表示引入3D语义占用预测任务，并结合了创新的无缝传感器融合机制。这种方法不仅显著提高了内存效率和推理速度，还通过模态无关的可变形注意力实现了更精确的环境表示和多模态数据的有效利用。其超越SOTA的性能和对多种传感器组合的适应性，使其在自动驾驶领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D语义占用预测是自动驾驶的关键任务，对于复杂环境中的精确安全解释和导航至关重要。可靠的预测需要有效的传感器融合，以利用不同模态的互补信息。

**Method:** GaussianFusionOcc提出了一种创新方法，使用语义3D高斯进行3D占用预测，而非传统的密集网格表示。它采用无缝传感器融合机制，集成来自摄像头、激光雷达和雷达传感器的数据，并通过模态无关的可变形注意力从每种传感器类型中提取关键特征，然后利用这些特征来细化高斯属性，以实现更准确的环境表示。

**Result:** 该方法实现了更精确和可扩展的占用预测，并显著提高了内存效率和推理速度。通过对各种传感器组合的广泛测试，证明了其多功能性。GaussianFusionOcc利用多模态融合的鲁棒性和高斯表示的效率，超越了当前的最新模型。

**Conclusion:** 通过利用多模态融合的鲁棒性和高斯表示的效率，GaussianFusionOcc在3D占用预测任务上优于现有最先进的模型。

> **ai_Abstract:** GaussianFusionOcc是一种用于自动驾驶中3D语义占用预测的新方法。它创新性地结合了语义3D高斯表示和无缝传感器融合机制，融合了来自摄像头、激光雷达和雷达的数据。与传统网格方法相比，该方法通过模态无关的可变形注意力提高了内存效率、推理速度和环境表示的准确性。实验证明，GaussianFusionOcc具有多功能性，并超越了现有最先进的模型。

> **摘要翻译:** 3D语义占用预测是自动驾驶的关键任务之一。它能在复杂环境中实现精确安全的解释和导航。可靠的预测依赖于有效的传感器融合，因为不同的模态可以包含互补信息。与依赖密集网格表示的传统方法不同，我们的方法GaussianFusionOcc使用语义3D高斯以及创新的传感器融合机制。无缝集成来自摄像头、激光雷达和雷达传感器的数据，实现了更精确和可扩展的占用预测，同时3D高斯表示显著提高了内存效率和推理速度。GaussianFusionOcc采用模态无关的可变形注意力从每种传感器类型中提取基本特征，然后用这些特征来细化高斯属性，从而更准确地表示环境。对各种传感器组合的广泛测试证明了我们方法的多功能性。通过利用多模态融合的鲁棒性和高斯表示的效率，GaussianFusionOcc超越了当前的最新模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder](https://arxiv.org/abs/2503.11937)
> *Att-Adapter：一种通过条件变分自编码器实现的鲁棒精确领域特定多属性T2I扩散适配器*

*Wonwoong Cho, Yan-Ying Chen, Matthew Klenk, David I. Inouye, Yanxia Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** Att-Adapter, T2I扩散模型, 多属性控制, 条件变分自编码器, 领域特定

**Comment:** ICCV'25 (Highlight), The project page is available at
  https://tri-mac.github.io/att-adapter/

> **TL;DR:** Att-Adapter是一个即插即用模块，通过解耦交叉注意力和条件变分自编码器，在预训练T2I扩散模型中实现对连续多属性的精确控制，且无需配对数据。

**AI_Comments:** Att-Adapter的创新点在于其即插即用的设计，以及通过解耦交叉注意力和CVAE实现对多属性的精细控制，同时解决了数据配对的难题。其无需配对数据和易于扩展的特性，使其在实际应用中具有很高的灵活性和实用价值，为T2I模型的属性控制提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 在新的领域中，通过纯文本指导实现对连续属性（特别是同时控制多个属性）的精确控制，对于文本到图像（T2I）扩散模型来说仍然是一个重大挑战。

**Method:** 本文引入了Att-Adapter，一个即插即用的模块，用于在预训练扩散模型中实现细粒度、多属性控制。它从一组非配对且包含多个视觉属性的样本图像中学习一个单一的控制适配器。Att-Adapter利用解耦的交叉注意力模块将多个领域属性与文本条件自然协调。此外，它引入了条件变分自编码器（CVAE）以缓解过拟合。

**Result:** Att-Adapter在控制连续属性方面优于所有基于LoRA的基线方法。该方法还实现了更宽的控制范围，并改善了多个属性之间的解耦，超越了基于StyleGAN的技术。Att-Adapter灵活，训练无需配对合成数据，并且可以轻松扩展到单个模型中的多个属性。

**Conclusion:** Att-Adapter为T2I扩散模型提供了鲁棒且精确的多属性控制能力，解决了现有方法的局限性，并展现出优越的性能和灵活性。

> **ai_Abstract:** Att-Adapter是一种新颖的即插即用模块，旨在解决文本到图像（T2I）扩散模型在新的领域中难以精确控制连续多属性的问题。该方法通过从非配对图像中学习单个控制适配器，并利用解耦的交叉注意力模块协调属性与文本条件。为缓解过拟合，Att-Adapter集成了条件变分自编码器（CVAE）。实验结果表明，Att-Adapter在连续属性控制方面优于LoRA和StyleGAN基线，提供更宽的控制范围和更好的属性解耦，且无需配对数据，易于扩展。

> **摘要翻译:** 文本到图像（T2I）扩散模型在生成高质量图像方面取得了显著的性能。然而，在新的领域（例如，眼睛睁开程度或汽车宽度等数值）中，仅通过文本指导实现对连续属性，特别是同时控制多个属性的精确控制，仍然是一个重大挑战。为了解决这个问题，我们引入了属性（Att）适配器，这是一种新颖的即插即用模块，旨在使预训练扩散模型能够进行细粒度的多属性控制。我们的方法从一组可以是非配对且包含多个视觉属性的样本图像中学习一个单一的控制适配器。Att-Adapter利用解耦的交叉注意力模块，自然地将多个领域属性与文本条件相结合。我们进一步在Att-Adapter中引入了条件变分自编码器（CVAE），以缓解过拟合，匹配视觉世界的多元性质。在两个公共数据集上的评估表明，Att-Adapter在控制连续属性方面优于所有基于LoRA的基线方法。此外，我们的方法实现了更广泛的控制范围，并改善了多个属性之间的解耦，超越了基于StyleGAN的技术。值得注意的是，Att-Adapter非常灵活，训练不需要配对的合成数据，并且可以轻松扩展到单个模型中的多个属性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [321] [Cloud gap-filling with deep learning for improved grassland monitoring](https://arxiv.org/abs/2403.09554)
> *基于深度学习的云间隙填充以改进草地监测*

*Iason Tsardanidis, Alkiviadis Koukos, Vasileios Sitokonstantinou, Thanassis Drivas, Charalampos Kontoes* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 深度学习, 云间隙填充, NDVI时间序列, 草地监测, 遥感

**Comment:** Published in Computers and Electronics in Agriculture

> **TL;DR:** 该研究提出了一种结合深度学习、光学和SAR数据的云间隙填充方法，以生成连续的NDVI时间序列，从而改进草地监测和割草事件检测。

**AI_Comments:** 该论文的创新之处在于结合了深度学习（CNNs和RNNs）、多源遥感数据（光学和SAR）以及NDVI时间序列生成，以解决云层对农业监测的影响。其重要性体现在为草地等作物提供高质量、连续的观测数据，这对于精准农业和环境监测至关重要。该方法在解决传统云掩膜不足方面的表现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 光学图像时间序列的连续性经常被云层中断，这阻碍了对草地等农业用地的及时监测。本研究旨在解决这一挑战，提供不间断的观测数据。

**Method:** 提出了一种创新的深度学习方法，该方法整合了无云光学（Sentinel-2）观测数据和不受天气影响的合成孔径雷达（Sentinel-1）数据。该方法采用结合了卷积神经网络（CNNs）和循环神经网络（RNNs）的混合架构，以生成连续的归一化植被指数（NDVI）时间序列。

**Result:** 该方法在立陶宛进行验证，其性能优于传统的插值技术（线性、Akima、二次）。平均平均绝对误差（MAE）为0.024，决定系数R²为0.92。此外，使用两种广泛应用的割草检测方法，割草事件检测的F1分数提高至84%。该方法还有效缓解了来自多云观测的突然偏移和噪声。

**Conclusion:** 该深度学习方法能够生成高质量、连续的NDVI时间序列，显著改善了在多云区域的草地监测和下游的割草事件检测任务，并有效解决了传统云掩膜的局限性。

> **ai_Abstract:** 本研究提出了一种创新的深度学习方法，用于填充因云层中断的光学图像时间序列中的间隙，以改进草地监测。该方法结合了Sentinel-2光学数据和Sentinel-1 SAR数据，并采用CNNs和RNNs的混合架构来生成连续的NDVI时间序列。在立陶宛的实验表明，该方法在生成连续NDVI方面优于传统插值技术，并显著提升了割草事件检测的准确性，有效解决了云层造成的观测中断和噪声问题。

> **摘要翻译:** 不间断的光学图像时间序列对于及时监测农业用地变化至关重要，尤其是在草地。然而，此类时间序列的连续性经常被云层中断。为了应对这一挑战，我们提出了一种创新的深度学习方法，该方法整合了无云光学（Sentinel-2）观测数据和不受天气影响的合成孔径雷达（Sentinel-1）数据。我们的方法采用结合了卷积神经网络（CNNs）和循环神经网络（RNNs）的混合架构，以生成连续的归一化植被指数（NDVI）时间序列，突出了NDVI在SAR和光学数据协同作用中的作用。我们通过评估所生成的NDVI时间序列对草地割草事件检测这一下游任务的影响，证明了观测连续性的重要性。我们在立陶宛进行了研究，该国以广泛的云覆盖为特征，并将我们的方法与替代插值技术（即线性、Akima、二次）进行了比较。我们的方法优于这些技术，实现了0.024的平均平均绝对误差（MAE）和0.92的决定系数R²。此外，我们的分析显示，使用两种广泛应用的割草检测方法，割草事件检测的性能有所改善，F1分数高达84%。我们的方法还有效缓解了来自多云观测的突然偏移和噪声，这些问题常常被传统云掩膜所忽略，并对割草检测精度产生不利影响。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [324] [Degradation-Consistent Learning via Bidirectional Diffusion for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18144)
> *低光图像增强中的降质一致性双向扩散学习*

*Jinhong He, Minglong Xue, Zhipu Liu, Mingliang Zhou, Aoxiang Ning, Palaiahnakote Shivakumara* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 低光图像增强, 双向扩散, 降质一致性学习, 自适应特征交互, 反射感知校正

**Comment:** 10page

> **TL;DR:** 提出了一种双向扩散机制（BidDiff）用于低光图像增强，通过同时建模低光和正常光的降质过程，并引入AFI和RACM模块，解决了单向扩散的局限性，实现了更一致的降质学习和高质量图像生成。

**AI_Comments:** 这篇论文通过引入双向扩散机制，创新性地解决了传统单向扩散模型在处理复杂真实世界降质模式时的不足，特别是在低光图像增强领域。其核心贡献在于同时建模了低光到正常光和正常光到低光的降质过程，并通过引入AFI和RACM模块进一步提升了特征表示和颜色恢复能力，确保了生成图像的结构和内容一致性。这种方法为扩散模型在图像恢复领域的应用提供了新的视角和有效的解决方案，具有重要的研究价值和潜在的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型在低光图像增强中因其单向降质建模，难以捕捉真实世界的复杂降质模式，导致结构不一致和像素错位，无法有效提升图像可见度以符合人类视觉感知。

**Method:** 提出了一种双向扩散优化机制，联合建模低光和正常光图像的降质过程，实现更精确的降质参数匹配。具体而言，在训练过程中执行从低光到正常光以及从正常光到低光的双向扩散，并引入自适应特征交互块（AFI）以优化特征表示。此外，设计了反射感知校正模块（RACM）用于去噪后的颜色恢复和过曝区域抑制。

**Result:** 在多个基准数据集上的大量实验表明，该方法在定量和定性评估中均优于现有最先进方法，并能有效泛化到不同的降质场景。

**Conclusion:** 该研究通过提出双向扩散优化机制、AFI和RACM模块，有效解决了低光图像增强中单向扩散模型的局限性，实现了降质一致性学习和高质量图像生成，显著提升了低光图像的可见度和感知质量。

> **ai_Abstract:** 本文提出了一种名为Bidirectional Diffusion for Low-Light Image Enhancement（BidDiff）的新方法，旨在解决现有扩散模型在低光图像增强中单向降质建模的局限性。通过引入双向扩散优化机制，同时建模低光和正常光图像的降质过程，并结合自适应特征交互块（AFI）和反射感知校正模块（RACM），该方法能够实现更精确的降质参数匹配，促进降质一致性学习，并生成高质量、符合人类视觉感知的图像，在多项基准测试中表现优异。

> **摘要翻译:** 低光图像增强旨在提高降质图像的可见度，使其更好地符合人类视觉感知。虽然基于扩散的方法因其强大的生成能力表现出有前景的性能，但其单向的降质建模往往难以捕捉真实世界降质模式的复杂性，导致结构不一致和像素错位。为了解决这些挑战，我们提出了一种双向扩散优化机制，该机制联合建模低光和正常光图像的降质过程，从而实现更精确的降质参数匹配并提高生成质量。具体而言，我们在训练期间执行从低光到正常光以及从正常光到低光的双向扩散，并引入自适应特征交互块（AFI）以优化特征表示。通过利用这两条路径之间的互补性，我们的方法对光照衰减和噪声分布施加了隐式对称约束，促进了降质一致性学习，并提高了模型感知光照和细节降质的能力。此外，我们设计了一个反射感知校正模块（RACM），用于在去噪后引导颜色恢复并抑制过曝区域，确保内容一致性并生成符合人类视觉感知的高质量图像。在多个基准数据集上的大量实验表明，我们的方法在定量和定性评估中均优于现有最先进方法，同时能有效泛化到不同的降质场景。代码地址：https://github.com/hejh8/BidDiff

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [327] [ELITE: Enhanced Language-Image Toxicity Evaluation for Safety](https://arxiv.org/abs/2502.04757)
> *ELITE：增强型语言-图像毒性评估以确保安全*

*Wonjun Lee, Doehyeon Lee, Eugene Choi, Sangyoon Yu, Ashkan Yousefpour, Haon Park, Bumsub Ham, Suhyun Kim* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 视觉语言模型安全, 毒性评估, 安全基准, 多模态有害内容, ELITE

**Comment:** ICML 2025. Project page at https://velpegor.github.io/ELITE/

> **TL;DR:** 当前视觉语言模型(VLM)在有害输出方面存在漏洞，现有安全基准评估方法不准确且数据质量低。本文提出了ELITE基准和评估器，通过引入毒性分数来提高多模态有害内容的检测准确性，并生成高质量、多样化的安全评估数据，实验证明其与人类评估更一致。

**AI_Comments:** 该论文创新性地提出了ELITE评估器，通过引入“毒性分数”来解决多模态内容中隐性有害内容的检测难题，这对于提高视觉语言模型（VLM）的安全性和鲁棒性至关重要。其方法不仅关注了评估的准确性，还强调了数据质量和多样性，解决了现有基准的痛点。ELITE有望成为VLM安全评估领域的重要工具，对实际应用中风险的评估和缓解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉语言模型（VLMs）容易受到恶意提示的诱导而产生有害输出。现有的VLM安全基准主要依赖自动化评估方法，但这些方法难以检测隐性有害内容或产生不准确的评估。研究发现现有基准的有害性水平低、数据模糊且图像-文本对组合多样性有限。

**Method:** 为了解决现有VLM安全基准的问题，本文提出了ELITE基准，这是一个高质量的VLM安全评估基准，其核心是增强型评估方法ELITE评估器。ELITE评估器明确纳入了毒性分数，以准确评估多模态上下文中的有害性。研究者使用ELITE评估器过滤掉现有基准中模糊和低质量的图像-文本对，并生成安全和不安全图像-文本对的多样化组合。

**Result:** 实验表明，与先前的自动化方法相比，ELITE评估器在与人类评估的一致性方面表现出卓越的性能。ELITE基准提供了更高的基准质量和多样性。

**Conclusion:** 通过引入ELITE，本文为更安全、更鲁棒的视觉语言模型铺平了道路，为评估和减轻实际应用中的安全风险贡献了必要的工具。

> **ai_Abstract:** 本文针对当前视觉语言模型(VLM)易受恶意提示诱导产生有害输出的问题，指出现有安全基准评估方法存在检测不准确、数据质量低和多样性不足的缺陷。为解决这些问题，论文提出了ELITE基准和ELITE评估器。ELITE评估器引入毒性分数，能更准确地评估多模态有害内容，并用于过滤和生成高质量、多样化的图像-文本对。实验证明，ELITE评估器与人类评估具有更高的一致性，且ELITE基准在质量和多样性上均有提升，有助于提升VLM的安全性。

> **摘要翻译:** 当前视觉语言模型（VLMs）仍然容易受到恶意提示的诱导而产生有害输出。现有的VLM安全基准主要依赖自动化评估方法，但这些方法难以检测隐性有害内容或产生不准确的评估。因此，我们发现现有基准的有害性水平低、数据模糊且图像-文本对组合多样性有限。为了解决这些问题，我们提出了ELITE基准，这是一个高质量的VLM安全评估基准，其核心是我们增强型评估方法——ELITE评估器。ELITE评估器明确纳入了毒性分数，以准确评估多模态上下文中的有害性，在这些场景中，VLMs通常会提供对图像具体、有说服力但无害的描述。我们使用ELITE评估器从现有基准中过滤掉模糊和低质量的图像-文本对，并生成安全和不安全图像-文本对的多样化组合。我们的实验表明，与先前的自动化方法相比，ELITE评估器在与人类评估的一致性方面取得了卓越的性能，并且ELITE基准提供了更高的基准质量和多样性。通过引入ELITE，我们为更安全、更鲁棒的VLM铺平了道路，为评估和减轻实际应用中的安全风险贡献了必要的工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [335] [Deformable Convolution Module with Globally Learned Relative Offsets for Fundus Vessel Segmentation](https://arxiv.org/abs/2507.18354)
> *具有全局学习相对偏移的可变形卷积模块用于眼底血管分割*

*Lexuan Zhu, Yuxuan Li, Yuning Ren* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 可变形卷积, 眼底血管分割, 全局特征, 注意力机制, GDCUnet

**Comment:** 

> **TL;DR:** 提出一种新的可变形卷积模块，通过学习全局相对偏移来增强特征学习，并在眼底血管分割上达到SOTA性能。

**AI_Comments:** 本文提出的可变形卷积模块创新性地通过学习亚像素位移场和扭曲特征图来实现变形，而非直接变形卷积核，并成功解耦了核大小与学习网络，这显著提升了其灵活性和特征捕获能力。其“即插即用”的特性使其具有很高的实用价值。在眼底血管分割任务中取得最先进的性能，证明了其在处理复杂生物医学图像特征方面的强大潜力。该模块对于其他具有复杂全局自相似特征的机器视觉任务也具有广泛的适用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可变形卷积在处理复杂形状特征时存在局限性，如直接变形卷积核和核大小与学习网络耦合。此外，眼底血管具有全局自相似的复杂边缘，需要更强的特征捕获能力。

**Method:** 提出了一种新颖的即插即用型可变形卷积模块，利用注意力机制和前馈网络学习偏移量。该模块通过学习亚像素位移场并自适应地扭曲所有通道的特征图，而非直接变形卷积核，从而实现全局特征变形以及核大小与学习网络的解耦。基于此模块，设计了用于眼底血管分割的深度学习模型GDCUnet。

**Result:** GDCUnet在公共数据集上取得了最先进的性能。所提出的可变形卷积模块能够更显著地学习眼底血管的复杂特征，并增强了模型的表示和泛化能力。

**Conclusion:** 所提出的可变形卷积模块能够有效地学习复杂特征，特别适用于眼底血管分割等任务，并提升了模型的表示和泛化能力。该模块可应用于更多具有复杂全局自相似特征的机器视觉任务。

> **ai_Abstract:** 本论文提出了一种新颖的即插即用型可变形卷积模块，通过注意力机制和前馈网络学习全局相对偏移，实现对特征图的自适应扭曲，从而捕获长距离全局特征并解耦核大小与学习网络。基于该模块，作者设计了用于眼底血管分割的GDCUnet模型，并在公共数据集上取得了最先进的性能。实验证明该模块能有效学习复杂特征，提升模型表示和泛化能力，适用于具有复杂全局自相似特征的机器视觉任务。

> **摘要翻译:** 可变形卷积通过学习偏移量来适应性地改变卷积核的形状，以处理复杂的形状特征。我们提出了一种新颖的即插即用型可变形卷积模块，该模块利用注意力机制和前馈网络来学习偏移量，从而使可变形模式能够捕获长距离全局特征。与现有可变形卷积相比，所提出的模块学习亚像素位移场并自适应地扭曲所有通道的特征图，而不是直接变形卷积核，这等效于核采样网格的相对变形，实现了全局特征变形以及核大小与学习网络的解耦。考虑到眼底血管具有全局自相似的复杂边缘，我们基于所提出的卷积模块设计了一个用于眼底血管分割的深度学习模型GDCUnet。在相同配置和统一框架下的经验评估表明，GDCUnet在公共数据集上取得了最先进的性能。进一步的消融实验证明，所提出的可变形卷积模块能够更显著地学习眼底血管的复杂特征，增强了模型的表示和泛化能力。所提出的模块类似于传统卷积的接口，我们建议将其应用于更多具有复杂全局自相似特征的机器视觉任务中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [337] [Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning](https://arxiv.org/abs/2503.12972)
> *视觉与语言对齐：免标注多模态知识图谱构建以增强大型语言模型推理*

*Junming Liu, Siyuan Meng, Yanting Gao, Song Mao, Pinlong Cai, Guohang Yan, Yirong Chen, Zilin Bian, Ding Wang, Botian Shi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 多模态知识图谱, LLMs, 视觉-语言模型, 免标注, 推理

**Comment:** 14 pages, 7 figures, 6 tables; Accepted to ICCV 2025

> **TL;DR:** 本文提出VaLiK，一种无需标注的多模态知识图谱（MMKG）构建方法，通过级联视觉-语言模型和跨模态相似性验证来增强大型语言模型（LLMs）的多模态推理能力，同时提高存储效率。

**AI_Comments:** 本文的创新之处在于其免标注的多模态知识图谱构建方法，解决了实际应用中的一大瓶颈。通过使用级联的视觉-语言模型和噪声过滤机制，VaLiK为LLMs集成视觉知识提供了一种更具可扩展性和效率的方式，从而增强了它们的推理能力并减轻了幻觉。其存储效率的提升也是一个显著的实际优势。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在多模态推理中存在知识不完整和幻觉问题，文本知识图谱（KGs）因模态隔离而效果有限。多模态知识图谱（MMKGs）虽有潜力，但其构建受限于手动标注的语义狭窄和视觉-语义实体链接中的噪声。

**Method:** 提出VaLiK（Vision-align-to-Language integrated Knowledge Graph）。该方法级联预训练的视觉-语言模型（VLMs）以将图像特征与文本对齐，并将其转换为图像特定描述。同时开发了跨模态相似性验证机制以量化语义一致性并过滤噪声。该方法无需手动标注图像标题。

**Result:** 与传统MMKG构建范式相比，VaLiK实现了显著的存储效率提升，并保持了直接实体到图像的链接能力。实验结果表明，用VaLiK增强的LLMs在多模态推理任务上优于现有最先进模型。

**Conclusion:** VaLiK提供了一种有效且高效的免标注多模态知识图谱构建方法，显著提升了大型语言模型的多模态推理能力。

> **ai_Abstract:** 本文介绍了一种名为VaLiK的创新性免标注方法，用于构建多模态知识图谱（MMKGs），旨在提升大型语言模型（LLMs）的多模态推理能力。VaLiK利用级联的预训练视觉-语言模型来对齐图像特征与文本，并采用跨模态相似性验证机制来减少噪声。该方法无需手动标注即可构建MMKG，显著提高了存储效率，并在多模态推理任务中超越了现有最先进的模型。

> **摘要翻译:** 大型语言模型（LLMs）中的多模态推理面临知识不完整和幻觉伪影的挑战，文本知识图谱（KGs）由于其模态隔离而只能部分缓解这些问题。尽管多模态知识图谱（MMKGs）有望增强跨模态理解，但其实际构建受到手动文本标注的语义狭窄和视觉-语义实体链接中固有噪声的阻碍。在本文中，我们提出了视觉对齐语言集成知识图谱（VaLiK），这是一种构建MMKG的新方法，通过跨模态信息补充来增强LLMs的推理能力。具体来说，我们级联预训练的视觉-语言模型（VLMs）以将图像特征与文本对齐，将它们转换为包含图像特定信息的描述。此外，我们开发了一种跨模态相似性验证机制来量化语义一致性，有效过滤掉特征对齐过程中引入的噪声。即使没有手动标注的图像标题，仅凭精炼的描述也足以构建MMKG。与传统的MMKGs构建范式相比，我们的方法在保持直接实体到图像链接能力的同时，实现了显著的存储效率提升。多模态推理任务的实验结果表明，用VaLiK增强的LLMs优于以前的最先进模型。我们的代码已发布在https://github.com/Wings-Of-Disaster/VaLiK。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [338] [AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID](https://arxiv.org/abs/2507.17995)
> *AG-VPReID.VIR：弥合空中与地面平台差距的视频可见光-红外行人重识别*

*Huy Nguyen, Kien Nguyen, Akila Pemasiri, Akmal Jahan, Clinton Fookes, Sridha Sridharan* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 行人重识别, 可见光-红外, 空中-地面, 跨模态, 视频数据

**Comment:** Accepted atIEEE International Joint Conference on Biometrics (IJCB)
  2025

> **TL;DR:** 本文介绍了AG-VPReID.VIR，首个结合空中和地面视角的可见光-红外视频行人重识别数据集，并提出了TCC-VPReID三流架构以应对跨平台和跨模态挑战。

**AI_Comments:** 本文的创新点在于构建了首个空中-地面跨模态视频行人重识别数据集AG-VPReID.VIR，有效弥补了现有数据集的不足。同时，提出的TCC-VPReID三流架构针对性地解决了跨平台和跨模态的复杂挑战，其多策略融合的学习方法具有借鉴意义。这项工作对于推动全天候智能监控系统的发展具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 行人重识别（Re-ID）在可见光和红外模态之间对于24小时监控系统至关重要，但现有数据集主要关注地面视角。基于地面的红外系统虽然提供夜间能力，但受限于遮挡、覆盖范围有限和易受阻碍等问题，而空中视角能独特地解决这些问题。

**Method:** 本文引入了AG-VPReID.VIR，这是首个空中-地面跨模态视频行人重识别数据集。该数据集包含1,837个身份，4,861个轨迹（124,855帧），使用无人机搭载和固定CCTV相机在RGB和红外模态下捕获。此外，本文提出了TCC-VPReID，一种新颖的三流架构，旨在解决跨平台和跨模态行人重识别的联合挑战。该方法通过风格鲁棒特征学习、基于记忆的跨视角适应和中间引导的时间建模，弥合了空中-地面视角和RGB-IR模态之间的域差距。

**Result:** 实验表明，与现有数据集相比，AG-VPReID.VIR提出了独特的挑战，并且TCC-VPReID框架在多个评估协议上取得了显著的性能提升。

**Conclusion:** 本文成功构建了首个空中-地面跨模态视频行人重识别数据集AG-VPReID.VIR，并提出的TCC-VPReID框架有效解决了跨平台和跨模态的行人重识别挑战，为24小时监控系统提供了关键技术支持。

> **ai_Abstract:** 本文针对现有行人重识别数据集在24小时监控中面临的地面视角局限性，首次提出了AG-VPReID.VIR数据集，该数据集结合了无人机和固定CCTV相机捕获的空中与地面、可见光与红外跨模态视频数据，包含1,837个身份。为应对数据集带来的跨视角和跨模态挑战，作者设计了TCC-VPReID三流架构，通过风格鲁棒特征学习、记忆库跨视角适应和中间引导的时间建模来弥合域差距。实验证明，该数据集具有独特的挑战性，且TCC-VPReID框架表现出显著的性能提升。

> **摘要翻译:** 行人重识别（Re-ID）在可见光和红外模态之间对于24小时监控系统至关重要，但现有数据集主要关注地面视角。虽然基于地面的红外系统提供夜间能力，但它们受限于遮挡、覆盖范围有限和易受阻碍——这些问题是空中视角独特解决的。为了解决这些限制，我们引入了AG-VPReID.VIR，这是首个空中-地面跨模态视频行人重识别数据集。该数据集使用无人机搭载和固定CCTV相机在RGB和红外模态下捕获了1,837个身份，跨越4,861个轨迹（124,855帧）。AG-VPReID.VIR带来了独特的挑战，包括跨视点变化、模态差异和时间动态。此外，我们提出了TCC-VPReID，一种新颖的三流架构，旨在解决跨平台和跨模态行人重识别的联合挑战。我们的方法通过风格鲁棒特征学习、基于记忆的跨视角适应和中间引导的时间建模，弥合了空中-地面视角和RGB-IR模态之间的域差距。实验表明，与现有数据集相比，AG-VPReID.VIR提出了独特的挑战，并且我们的TCC-VPReID框架在多个评估协议上取得了显著的性能提升。数据集和代码可在https://github.com/agvpreid25/AG-VPReID.VIR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [346] [IntentVCNet: Bridging Spatio-Temporal Gaps for Intention-Oriented Controllable Video Captioning](https://arxiv.org/abs/2507.18531)
> *IntentVCNet：弥合时空差距，实现意图导向的可控视频字幕生成*

*Tianheng Qiu, Jingchun Gao, Jingyu Li, Huiyi Leong, Xuan Huang, Xi Wang, Xiaocheng Zhang, Kele Xu, Lan Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视频字幕生成, 意图导向, 可控生成, 大型视觉语言模型, 时空对齐

**Comment:** 

> **TL;DR:** IntentVCNet通过结合提示组合策略和参数高效的框适配器，弥合了LVLM在处理用户意图导向的可控视频字幕生成中的时空差距，实现了SOTA性能。

**AI_Comments:** IntentVCNet的创新点在于从提示和模型两个层面系统性地解决了LVLM在细粒度意图导向视频字幕生成中的时空对齐难题。提示组合策略巧妙地利用LLM建模隐式关系，而框适配器则有效地将先验意图信息融入视觉上下文，这种双管齐下的方法增强了模型对复杂指令的遵循能力和对视频细节的捕捉能力，对于推动可控视频生成领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大型视觉语言模型（LVLMs）尽管在空间和时间理解方面表现出色，但无法在时间序列中直接响应指令进行细粒度的空间控制，这种显著的时空差距使得实现视频中细粒度的意图导向控制变得复杂。

**Method:** 本文提出了IntentVCNet，它从提示和模型两个角度统一了LVLMs固有的时间和空间理解知识。具体而言，首先提出了一个提示组合策略，旨在使LVLM能够建模表征用户意图的提示与视频序列之间的隐含关系。其次，提出了一个参数高效的框适配器，增强了全局视觉上下文中的对象语义信息，使视觉token具有用户意图的先验信息。

**Result:** 实验证明，这两种策略的结合可以进一步增强LVLM在视频序列中建模空间细节的能力，并促进LVLM准确生成受控的意图导向字幕。该方法在多个开源LVLMs上取得了最先进的结果，并在IntentVC挑战赛中获得了亚军。

**Conclusion:** IntentVCNet通过提出的提示组合策略和参数高效的框适配器，成功弥合了LVLM在意图导向可控视频字幕生成中的时空差距，显著提升了模型对视频序列中空间细节的建模能力，实现了卓越的性能。

> **ai_Abstract:** 本文提出了IntentVCNet，旨在解决大型视觉语言模型（LVLMs）在意图导向的可控视频字幕生成中存在的时空差距问题。该网络通过引入一种提示组合策略来建模用户意图与视频序列之间的隐含关系，并设计一个参数高效的框适配器来增强视觉token的对象语义信息。实验结果表明，这两种策略的结合显著提升了LVLM对视频空间细节的建模能力，使其能更准确地生成意图导向的字幕，并在多项基准测试中取得了SOTA性能。

> **摘要翻译:** 意图导向的可控视频字幕生成旨在根据定制的用户意图，为视频中的特定目标生成有针对性的描述。当前的大型视觉语言模型（LVLMs）已经获得了强大的指令遵循和视觉理解能力。尽管LVLMs分别在空间和时间理解方面表现出熟练性，但它们无法在时间序列中直接响应指令进行细粒度的空间控制。这种显著的时空差距使得实现视频中细粒度的意图导向控制变得复杂。为此，我们提出了一种新颖的IntentVCNet，它统一了LVLMs固有的时间和空间理解知识，从提示和模型两个角度弥合时空差距。具体而言，我们首先提出了一种提示组合策略，旨在使LLM能够建模表征用户意图的提示与视频序列之间的隐含关系。然后，我们提出了一种参数高效的框适配器，增强了全局视觉上下文中的对象语义信息，使得视觉token具有用户意图的先验信息。最终实验证明，这两种策略的结合可以进一步增强LVLM对视频序列中空间细节的建模能力，并促进LVLMs准确生成受控的意图导向字幕。我们提出的方法在几个开源LVLMs中取得了最先进的结果，并在IntentVC挑战赛中获得了亚军。我们的代码可在https://github.com/thqiu0419/IntentVCNet上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [347] [Robust sensitivity control in digital pathology via tile score distribution matching](https://arxiv.org/abs/2502.20144)
> *数字病理学中通过瓦片分数分布匹配实现鲁棒灵敏度控制*

*Arthur Pignet, John Klein, Genevieve Robin, Antoine Olivier* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 数字病理学, 敏感度控制, 分布偏移, 最优传输, 多实例学习

**Comment:** Camera ready version. Accepted at MICCAI 2025

> **TL;DR:** 本文提出了一种基于最优传输和多实例学习的新方法，用于在数字病理学中实现对全玻片图像分类模型鲁棒的敏感度控制，仅需少量校准样本即可实现可靠部署。

**AI_Comments:** 本文的创新之处在于提出了一种基于最优传输和多实例学习的新颖方法，以应对数字病理学中模型部署时敏感度控制的挑战。其重要性在于能够以少量校准样本实现鲁棒的敏感度控制，这对于计算病理系统在临床环境中的可靠和实用部署至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 由于分布偏移，在不同医疗中心部署数字病理学模型具有挑战性。虽然领域泛化提高了模型在AUC等聚合性能方面的可迁移性，但临床规范通常要求控制其他指标（如预设敏感度水平）的可迁移性。

**Method:** 本文引入了一种新方法，基于最优传输（optimal transport）和多实例学习（Multiple Instance Learning, MIL），用于控制全玻片图像（WSI）分类模型的敏感度。

**Result:** 该方法在多个队列和任务中得到验证，仅需少量校准样本即可实现鲁棒的敏感度控制。

**Conclusion:** 该方法为计算病理系统提供了可靠部署的实用解决方案。

> **ai_Abstract:** 本研究提出了一种解决数字病理学模型部署中分布偏移导致敏感度控制困难的新方法。该方法结合了最优传输和多实例学习，旨在控制全玻片图像分类模型的敏感度。经验证，该方法在不同队列和任务中表现出鲁棒的敏感度控制能力，且仅需少量校准样本，为计算病理系统的实际部署提供了可行方案。

> **摘要翻译:** 由于分布偏移，在医疗中心部署数字病理学模型具有挑战性。领域泛化方面的最新进展提高了模型在以曲线下面积 (AUC) 衡量的聚合性能方面的可迁移性。然而，临床法规通常要求控制其他指标的可迁移性，例如预设的敏感度水平。我们引入了一种基于最优传输和多实例学习 (MIL) 的新方法，用于控制全玻片图像 (WSI) 分类模型的敏感度。我们的方法在多个队列和任务中得到验证，仅需少量校准样本即可实现鲁棒的敏感度控制，为计算病理系统的可靠部署提供了实用解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [359] [Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models](https://arxiv.org/abs/2503.17724)
> *无痕触发：面向文生图扩散模型的隐蔽后门攻击*

*Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 后门攻击, 文生图扩散模型, 隐蔽性, 语义一致性, 注意力一致性

**Comment:** 

> **TL;DR:** 本文提出了一种名为“无痕触发”（TwT）的新型后门攻击方法，通过利用句法结构和KMMD正则化来规避对文生图扩散模型后门的现有防御机制。

**AI_Comments:** 本文的创新之处在于提出了一种新型的隐蔽后门攻击方法TwT，通过针对性地解决现有后门攻击中可检测的“痕迹”（语义一致性和注意力一致性），显著提高了攻击的隐蔽性。其利用句法结构和KMMD正则化的方法具有新颖性。这项工作揭示了当前文生图扩散模型后门防御的局限性，对未来的防御研究具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的文生图扩散模型后门攻击样本存在语义一致性和注意力一致性两种可检测的异常，使得后门易于被识别。本文旨在提出一种更隐蔽的后门攻击方法，以规避这些检测。

**Method:** 本文提出了“无痕触发”（TwT）方法，通过显式缓解语义一致性和注意力一致性来实现隐蔽后门。具体而言，它利用句法结构作为后门触发器，以放大对文本变化的敏感性，从而打破语义一致性。此外，提出了一种基于核最大均值差异（KMMD）的正则化方法，以对齐后门样本和良性样本之间的交叉注意力响应分布，从而破坏注意力一致性。

**Result:** 该方法实现了97.5%的攻击成功率，并表现出更强的防御抵抗力。它使平均超过98%的后门样本绕过了三种最先进的检测机制。

**Conclusion:** 本文提出的“无痕触发”（TwT）方法能够实现隐蔽的后门攻击，有效规避现有检测机制，揭示了当前后门防御方法的脆弱性。

> **ai_Abstract:** 本文提出了一种名为“无痕触发”（TwT）的隐蔽后门攻击方法，旨在解决现有文生图扩散模型后门攻击中存在的语义和注意力一致性问题。通过利用句法结构作为触发器来破坏语义一致性，并采用基于核最大均值差异（KMMD）的正则化方法来扰乱注意力一致性，TwT能够实现高攻击成功率（97.5%）并有效规避当前最先进的后门检测机制，凸显了现有防御方法的脆弱性。

> **摘要翻译:** 针对文生图扩散模型的后门攻击发展迅速。然而，与良性样本相比，当前的后门样本通常表现出两个关键异常：1）语义一致性，即后门提示即使在文本变化很大的情况下也倾向于生成具有相似语义内容的图像；2）注意力一致性，即触发器在交叉注意力图中诱导一致的结构响应。这些一致性为防御者留下了可检测的痕迹，使得后门更容易被识别。在本文中，为了实现隐蔽的后门样本，我们提出了“无痕触发”（TwT）方法，通过明确缓解这些一致性。具体而言，我们的方法利用句法结构作为后门触发器，以放大对文本变化的敏感性，有效打破语义一致性。此外，提出了一种基于核最大均值差异（KMMD）的正则化方法，以对齐后门样本和良性样本之间的交叉注意力响应分布，从而破坏注意力一致性。大量实验表明，我们的方法实现了97.5%的攻击成功率，同时表现出更强的防御抵抗力。它使平均超过98%的后门样本绕过了三种最先进的检测机制，揭示了当前后门防御方法的脆弱性。代码可在https://github.com/Robin-WZQ/TwT获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [361] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
> *从异质性中学习：通过分布鲁棒优化泛化动态面部表情识别*

*Feng-Qi Cui, Anyang Tong, Jinyang Huang, Jie Zhang, Dan Guo, Zhi Liu, Meng Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 动态面部表情识别, 异质性, 分布鲁棒优化, 泛化, 情感计算

**Comment:** Accepted by ACM MM'25

> **TL;DR:** 本文提出了一种名为异质性感知分布框架（HDF）的新方法，通过时间-频率分布注意力模块（DAM）和分布感知缩放模块（DSM）来解决动态面部表情识别（DFER）中由多源数据和个体表情变异引起的样本异质性问题，显著提高了识别准确性和鲁棒性，并在多样化和不平衡场景下表现出强大的泛化能力。

**AI_Comments:** 该论文的创新点在于提出了一个专门处理动态面部表情识别中异质性问题的框架（HDF），并通过集成DAM和DSM两个模块来解决时间-频率建模和优化不平衡的挑战。其通过分布鲁棒优化的思想来提升模型的泛化能力，对于实际应用中复杂多变的数据环境具有重要意义。文章提出的即插即用模块设计也增加了其方法的灵活性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态面部表情识别（DFER）方法在多源数据和个体表情变异引起的样本异质性下，性能会不可避免地下降。

**Method:** 本文提出了一种名为异质性感知分布框架（HDF）的新颖框架，并设计了两个即插即用模块。首先是时间-频率分布注意力模块（DAM），通过双分支注意力设计捕捉时间一致性和频率鲁棒性。其次是分布感知缩放模块（DSM），基于梯度敏感性和信息瓶颈原理，自适应地平衡分类和对比损失，从而实现更稳定和有区分度的表征学习。

**Result:** 在DFEW和FERV39k两个广泛使用的数据集上进行的广泛实验表明，HDF显著提高了识别准确性和鲁棒性。该方法在保持在多样化和不平衡场景中强大泛化能力的同时，实现了卓越的加权平均召回率（WAR）和未加权平均召回率（UAR）。

**Conclusion:** 本文提出的异质性感知分布框架（HDF），通过其独特的DAM和DSM模块，有效解决了动态面部表情识别中的样本异质性问题，显著提升了模型的准确性、鲁棒性和跨场景泛化能力。

> **ai_Abstract:** 本文针对动态面部表情识别（DFER）中由多源数据和个体差异造成的样本异质性导致的性能下降问题，提出了一种名为异质性感知分布框架（HDF）的新型框架。HDF包含两个核心模块：时间-频率分布注意力模块（DAM），用于增强时频建模并提升对序列不一致性和视觉风格变化的鲁棒性；以及分布感知缩放模块（DSM），用于动态平衡损失函数以优化表征学习。实验结果表明，HDF在识别准确性、鲁棒性和泛化能力方面均表现出色，尤其在处理多样化和不平衡数据集时效果显著。

> **摘要翻译:** 动态面部表情识别（DFER）在情感计算和人机交互中扮演着关键角色。尽管现有方法取得了可比的性能，但它们不可避免地受到多源数据和个体表情变异引起的样本异质性导致的性能下降。为了解决这些挑战，我们提出了一种新颖的框架，称为异质性感知分布框架（HDF），并设计了两个即插即用模块来增强时频建模并缓解由难样本引起的优化不平衡。具体而言，时频分布注意力模块（DAM）通过双分支注意力设计捕捉时间一致性和频率鲁棒性，提高了对序列不一致性和视觉风格变化的容忍度。然后，基于梯度敏感性和信息瓶颈原理，引入了一个自适应优化模块——分布感知缩放模块（DSM），以动态平衡分类和对比损失，从而实现更稳定和有区分度的表征学习。在两个广泛使用的数据集DFEW和FERV39k上进行的广泛实验表明，HDF显著提高了识别准确性和鲁棒性。我们的方法在保持在多样化和不平衡场景中强大泛化能力的同时，实现了卓越的加权平均召回率（WAR）和未加权平均召回率（UAR）。代码已在https://github.com/QIcita/HDF_DFER发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols](https://arxiv.org/abs/2507.18457)
> *重新审视针对激光雷达检测的物理可实现对抗性物体攻击：明确问题表述和实验协议*

*Luo Cheng, Hanwei Zhang, Lijun Zhang, Holger Hermanns* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 激光雷达检测, 对抗性攻击, 物理可实现性, 标准化框架, 鲁棒性

**Comment:** 

> **TL;DR:** 该研究提出了一个设备无关的标准化框架，用于物理对抗性物体攻击，解决了现有研究中可重复性差的问题，并通过模拟攻击到真实激光雷达系统的成功迁移进行了验证。

**AI_Comments:** 这篇论文的创新之处在于提出了一个设备无关的标准化框架，解决了物理对抗性物体攻击中长期存在的缺乏可重复性问题。通过提供开源代码和基准测试协议，它为该领域的研究提供了一个急需的统一平台，有望加速未来研究并促进公平比较。将模拟攻击成功转移到物理系统是其方法有效性的有力证明，对现实世界应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对激光雷达的3D目标检测中的对抗性鲁棒性是一个关键研究领域，但许多数字攻击缺乏物理可实现性。物理对抗性物体攻击研究不足，且由于设置不一致和硬件差异，导致可重复性差。

**Method:** 我们提出了一个设备无关的标准化框架，该框架抽象了物理对抗性物体攻击的关键要素，支持多种方法，并提供在模拟和真实世界设置中的开源代码和基准测试协议。

**Result:** 我们的框架实现了公平比较，加速了研究，并通过成功将模拟攻击转移到物理激光雷达系统进行了验证。

**Conclusion:** 除了框架之外，我们还提供了影响攻击成功的因素的见解，并促进了对真实世界激光雷达感知中对抗性鲁棒性的理解。

> **ai_Abstract:** 本研究旨在解决针对激光雷达的3D目标检测中物理对抗性物体攻击的可重复性差问题。作者提出了一个设备无关的标准化框架，该框架抽象了攻击要素，支持多种方法，并提供了开源代码和基准测试协议。该框架通过实现公平比较、加速研究以及成功将模拟攻击转移到真实激光雷达系统来验证其有效性。此外，该研究还提供了关于影响攻击成功因素的见解，并加深了对真实世界激光雷达感知中对抗性鲁棒性的理解。

> **摘要翻译:** 针对激光雷达的3D目标检测中的对抗性鲁棒性是一个关键研究领域，因为它在现实世界场景中有着广泛的应用。虽然许多数字攻击操纵点云或网格，但它们通常缺乏物理可实现性，限制了它们的实际影响。物理对抗性物体攻击研究不足，且由于设置不一致和硬件差异，导致可重复性差。为了解决这个问题，我们提出了一个设备无关的标准化框架，该框架抽象了物理对抗性物体攻击的关键要素，支持多种方法，并提供在模拟和真实世界设置中的开源代码和基准测试协议。我们的框架实现了公平比较，加速了研究，并通过成功将模拟攻击转移到物理激光雷达系统进行了验证。除了框架之外，我们还提供了影响攻击成功的因素的见解，并促进了对真实世界激光雷达感知中对抗性鲁棒性的理解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [368] [WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection](https://arxiv.org/abs/2507.18173)
> *WaveMamba: 小波驱动的Mamba融合用于RGB-红外目标检测*

*Haodong Zhu, Wenhao Dong, Linlin Yang, Hong Li, Yuguang Yang, Yangyang Ren, Qingcheng Zhu, Zichao Feng, Changbai Li, Shaohui Lin, Runqi Wang, Xiaoyan Luo, Baochang Zhang* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-24**

**Keywords:** RGB-红外目标检测, 小波变换, Mamba, 跨模态融合, 频率特征

**Comment:** 

> **TL;DR:** WaveMamba提出了一种新颖的跨模态融合方法，通过离散小波变换分解RGB和红外图像的频率特征，并利用Mamba框架进行高效融合，显著提升了RGB-红外目标检测性能。

**AI_Comments:** 本文的创新点在于将小波变换与Mamba架构相结合，用于RGB-红外图像的频率域融合。通过对低频和高频特征分别采用定制化的融合策略（特别是Mamba框架结合门控注意力用于低频），有效利用了多模态数据的互补信息，显著提升了目标检测性能。这种频率域的精细化融合方法是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 利用可见光（RGB）和红外（IR）图像的互补特性，在目标检测方面具有显著的改进潜力。

**Method:** 本文提出了WaveMamba，一种跨模态融合方法，通过离散小波变换（DWT）有效整合RGB和红外图像分解出的独特互补频率特征。同时提出了一个结合逆离散小波变换（IDWT）的改进检测头以减少信息损失。核心是引入了WaveMamba融合块（WMFB），该块促进了低频/高频子带的全面融合。WMFB内部，低频Mamba融合块（LMFB）基于Mamba框架构建，首先进行通道交换的初始低频特征融合，随后通过先进的门控注意力机制进行深度融合。高频特征则采用“绝对最大值”融合策略进行增强。

**Result:** 该方法在四个基准测试中平均mAP提升了4.5%，超越了现有最先进的方法。

**Conclusion:** WaveMamba通过有效融合RGB和红外图像的频率特征，显著提升了目标检测性能，证明了其在跨模态目标检测领域的有效性和优越性。

> **ai_Abstract:** WaveMamba是一种新颖的RGB-红外目标检测跨模态融合方法。它利用离散小波变换分解图像的频率特征，并通过WaveMamba融合块（WMFB）进行深度融合。WMFB包含低频Mamba融合块（LMFB）和高频特征增强策略，其中LMFB结合了通道交换和门控注意力机制。该方法通过逆离散小波变换减少信息损失，并在多个基准测试中实现了4.5%的平均mAP提升，超越了现有SOTA方法。

> **摘要翻译:** 利用可见光（RGB）和红外（IR）图像的互补特性，为提升目标检测提供了巨大潜力。本文提出WaveMamba，一种跨模态融合方法，能够有效整合由离散小波变换（DWT）分解的RGB和红外图像的独特且互补的频率特征。为了减少信息损失并生成最终检测结果，我们还提出了一个结合逆离散小波变换（IDWT）的改进检测头。我们方法的核心是引入了WaveMamba融合块（WMFB），它促进了低频/高频子带的全面融合。在WMFB内部，基于Mamba框架构建的低频Mamba融合块（LMFB）首先进行通道交换的初始低频特征融合，随后通过先进的门控注意力机制进行深度融合以增强整合。高频特征则采用“绝对最大值”融合策略进行增强。这些进步带来了显著的性能提升，我们的方法超越了现有最先进的方法，并在四个基准测试中平均mAP提升了4.5%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [Learning to Generalize without Bias for Open-Vocabulary Action Recognition](https://arxiv.org/abs/2502.20158)
> *无偏泛化开放词汇动作识别*

*Yating Yu, Congqi Cao, Yifan Zhang, Yanning Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 开放词汇动作识别, 元学习, 偏置消除, 泛化, CLIP

**Comment:** Accepted by ICCV2025 (Highlight)

> **TL;DR:** 本文提出了Open-MeDe，一个元优化框架，通过元学习和跨批次元优化来解决CLIP初始化模型在开放词汇动作识别中存在的静态偏置问题，显著提高了模型在上下文内和上下文外场景的泛化能力。

**AI_Comments:** 本文的创新点在于提出了Open-MeDe框架，通过元学习和跨批次元优化，有效解决了CLIP在开放词汇动作识别中引入的静态偏置问题，从而显著提升了模型在面对新颖上下文外数据时的泛化能力。其方法新颖，且实验效果显著，为开放词汇动作识别领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 利用CLIP进行开放词汇动作识别时，现有方法因CLIP的静态偏置而容易过拟合到捷径静态特征，从而损害其泛化能力，尤其是在新颖的、上下文之外的动作上。

**Method:** 本文引入了Open-MeDe，一个带有静态去偏置的元优化框架。它采用元学习方法来改进从已知到开放的泛化以及图像到视频的去偏置。具体来说，Open-MeDe引入了一种跨批次元优化方案，通过虚拟评估鼓励视频学习器快速泛化到任意后续数据，并平滑优化过程。在优化过程中，摆脱CLIP正则化隐式地减轻了视频元学习器的固有静态偏置。此外，还对优化轨迹应用了自集成，以获得通用的最优参数。

**Result:** Open-MeDe不仅超越了专门针对上下文内开放词汇动作识别的最新正则化方法，而且在上下文外场景中也表现出色。

**Conclusion:** Open-MeDe通过解决CLIP初始化的视频学习器在开放词汇动作识别中存在的静态偏置问题，显著提升了模型的泛化能力，尤其是在处理新颖和上下文外数据方面。

> **ai_Abstract:** 本文提出了一种名为Open-MeDe的元优化框架，旨在解决基于CLIP的视频学习器在开放词汇动作识别中因CLIP静态偏置导致的泛化能力受损问题。Open-MeDe采用元学习方法，通过跨批次元优化方案和去正则化来减轻静态偏置，并结合自集成技术，显著提升了模型在上下文内和上下文外场景下的泛化性能，超越了现有SOTA方法。

> **摘要翻译:** 利用CLIP有效的视觉-文本对齐和静态泛化能力，最近的视频学习器采用CLIP初始化，并进一步正则化或重组，以实现在上下文中的开放词汇动作识别的泛化。然而，由于CLIP的静态偏置，这些视频学习器倾向于过拟合捷径静态特征，从而损害其泛化能力，尤其是在新颖的、上下文之外的动作上。为了解决这个问题，我们引入了Open-MeDe，一个用于开放词汇动作识别的新颖的带有静态去偏置的元优化框架。从泛化的全新视角来看，Open-MeDe采用元学习方法，以经济高效的方式改进从已知到开放的泛化以及图像到视频的去偏置。具体来说，Open-MeDe引入了一种跨批次元优化方案，通过虚拟评估明确鼓励视频学习器快速泛化到任意后续数据，从而引导更平滑的优化过程。实际上，优化过程中摆脱CLIP正则化隐式地减轻了视频元学习器的固有静态偏置。我们进一步对优化轨迹应用自集成，以获得能够对上下文内和上下文外新颖数据实现鲁棒泛化的通用最优参数。广泛的评估表明，Open-MeDe不仅超越了专门针对上下文内开放词汇动作识别的最新正则化方法，而且在上下文外场景中也表现出色。代码已在https://github.com/Mia-YatingYu/Open-MeDe 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [375] [MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image](https://arxiv.org/abs/2507.18371)
> *MVG4D：基于图像矩阵的多视角和运动生成，用于从单张图像创建4D内容*

*Xiaotian Chen, DongFu Yin, Fei Richard Yu, Xuanchen Li, Xinhao Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 4D内容生成, 单图像, 多视角合成, 4D高斯溅射, 时间一致性

**Comment:** 

> **TL;DR:** MVG4D是一个新颖的框架，通过结合多视角合成和4D高斯溅射，从单张图像生成高保真、时间一致的动态4D内容，并在Objaverse数据集上表现优异。

**AI_Comments:** MVG4D的创新之处在于其从单张图像生成动态4D内容的独特方法，特别是引入了图像矩阵模块来合成时间连贯的多视角图像，这为后续的4D重建提供了强大的监督信号。它有效解决了4D内容生成中的关键挑战，如时间一致性和几何保真度，并通过实验证明了其优越性。这项工作为高效、可控的4D内容创作提供了一个新方向，对于AR/VR等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成建模在2D、3D和4D内容创作方面取得了显著进展，但生成高保真且时间一致的动态4D内容仍然是一个挑战。现有的基于4D GS的方法存在运动不连续和背景退化等问题。

**Method:** 本文提出了MVG4D框架，通过结合多视角合成和4D高斯溅射（4D GS）从单张静止图像生成动态4D内容。其核心是一个图像矩阵模块，用于合成时间连贯且空间多样的多视角图像，为后续的3D和4D重建提供丰富的监督信号。这些多视角图像用于优化3D高斯点云，并通过轻量级形变网络进一步扩展到时间域。

**Result:** MVG4D有效增强了时间一致性、几何保真度和视觉真实感，解决了先前基于4D GS方法中运动不连续和背景退化等关键挑战。在Objaverse数据集上的大量实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于最先进的基线方法。显著地，它减少了跨视角和时间上的闪烁伪影，并锐化了结构细节。

**Conclusion:** MVG4D为从最小输入高效且可控地生成4D内容开辟了新方向，能够实现更沉浸式的AR/VR体验。

> **ai_Abstract:** 本文提出了MVG4D，一个创新的框架，旨在从单张静止图像生成高保真、时间一致的动态4D内容。MVG4D通过图像矩阵模块合成多视角图像，并结合4D高斯溅射和轻量级形变网络进行4D重建。该方法有效解决了现有4D GS方法的运动不连续和背景退化问题，并通过实验证明在多项指标上优于现有技术，显著减少了闪烁并提升了细节，为沉浸式AR/VR体验奠定了基础。

> **摘要翻译:** 生成建模的进步显著提升了数字内容创作，从2D图像扩展到复杂的3D和4D场景。尽管取得了实质性进展，但生成高保真且时间一致的动态4D内容仍然是一个挑战。在本文中，我们提出了MVG4D，一个新颖的框架，通过结合多视角合成和4D高斯溅射（4D GS），从单张静止图像生成动态4D内容。MVG4D的核心是采用一个图像矩阵模块，该模块合成时间连贯且空间多样的多视角图像，为下游的3D和4D重建提供丰富的监督信号。这些多视角图像用于优化3D高斯点云，并通过轻量级形变网络进一步扩展到时间域。我们的方法有效增强了时间一致性、几何保真度和视觉真实感，解决了先前基于4D GS方法中运动不连续和背景退化等关键挑战。在Objaverse数据集上的大量实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于最先进的基线方法。值得注意的是，它减少了跨视角和时间上的闪烁伪影，并锐化了结构细节，从而实现更沉浸式的AR/VR体验。MVG4D为从最小输入高效且可控地生成4D内容开辟了新方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [379] [Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification](https://arxiv.org/abs/2507.17996)
> *探索标签偏差与亚组大小和可分离性的相互作用：乳腺密度分类的案例研究*

*Emma A. M. Stanley, Raghav Mehta, Mélanie Roschewitz, Nils D. Forkert, Ben Glocker* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 标签偏差, 亚组公平性, 医学影像AI, 深度学习, 乳腺密度分类

**Comment:** Accepted at MICCAI Workshop on Fairness of AI in Medical Imaging
  (FAIMI) 2025

> **TL;DR:** 本研究探讨了医学影像数据中标签偏差对深度学习模型特征学习和性能的影响，发现其效应取决于受影响亚组的大小和可分离性。

**AI_Comments:** 这项研究通过模拟实验深入探讨了医学影像AI中标签偏差这一关键但未被充分研究的公平性问题。其创新之处在于系统地分析了亚组大小和可分离性对标签偏差影响的调节作用。研究结果具有重要的实践意义，提醒开发者在构建和评估医疗AI系统时，必须关注数据中的标签偏差及其对不同亚组性能的影响，尤其是在验证集选择上。这对于确保医疗AI的公平性和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像数据集中影响特定亚组的系统性错误标记（即标签偏差）是医疗AI系统公平性方面一个未被充分研究的问题。

**Method:** 研究人员使用EMORY BrEast imaging Dataset (EMBED)训练深度学习模型进行二元组织密度分类。他们模拟了标签偏差影响可分离亚组（基于影像制造商）或不可分离的“伪亚组”的情况。同时，他们观察了使用带有干净标签或带有偏差标签的验证集定义分类阈值时对模型性能的影响。

**Result:** 模拟的亚组标签偏差导致模型学习到的特征表示发生显著偏移，且这些偏移取决于受标签偏差影响的亚组的相对大小和可分离性。当验证集带有偏差标签时，受标签偏差影响的多数可分离亚组的真阳性率从0.898下降到0.518。

**Conclusion:** 本研究为理解标签偏差对医学影像AI中亚组公平性的影响做出了重要贡献。

> **ai_Abstract:** 本研究探讨了医学影像数据中标签偏差对深度学习模型性能和特征学习的影响，特别关注受影响亚组的大小和可分离性。通过在乳腺影像数据集上训练模型并模拟标签偏差，研究发现标签偏差会导致模型特征表示的显著偏移，且这种偏移与亚组的大小和可分离性密切相关。此外，使用带有偏差标签的验证集会显著降低受影响亚组的性能。这项工作强调了标签偏差对医疗AI系统公平性的重要影响。

> **摘要翻译:** 医学影像数据集中影响特定亚组的系统性错误标记（即标签偏差）是医疗AI系统公平性方面一个未被充分研究的问题。在这项工作中，我们调查了受标签偏差影响的亚组的大小和可分离性如何影响深度学习模型学习到的特征和性能。因此，我们使用EMory BrEast imaging Dataset (EMBED)训练了用于二元组织密度分类的深度学习模型，其中标签偏差影响可分离亚组（基于影像制造商）或不可分离的“伪亚组”。我们发现，模拟的亚组标签偏差导致模型学习到的特征表示出现显著偏移。重要的是，特征空间中的这些偏移取决于受标签偏差影响的亚组的相对大小和可分离性。我们还观察到，根据是否使用带有干净标签的验证集来定义模型的分类阈值，亚组性能存在显著差异。例如，当标签偏差影响多数可分离亚组时，该亚组的真阳性率从验证集带有干净标签时的0.898下降到验证集带有偏差标签时的0.518。我们的工作是理解标签偏差对医学影像AI中亚组公平性后果的关键贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [382] [COT-AD: Cotton Analysis Dataset](https://arxiv.org/abs/2507.18532)
> *COT-AD：棉花分析数据集*

*Akbar Ali, Mahek Vyas, Soumyaratna Debnath, Chanda Grover Kamra, Jaidev Sanjay Khalane, Reuben Shibu Devanesan, Indra Deep Mastan, Subramanian Sankaranarayanan, Pankaj Khanna, Shanmuganathan Raman* | **Category: cs.CV, I.4.9; I.5.4; H.2.8** | **Updated: 2025-07-24**

**Keywords:** 棉花, 数据集, 计算机视觉, 农业, 病害管理

**Comment:** Dataset publicly available at:
  https://ieee-dataport.org/documents/cot-adcotton-analysis-dataset. Accepted
  to IEEE International Conference on Image Processing (ICIP) 2025

> **TL;DR:** COT-AD是一个用于棉花计算机视觉分析的综合数据集。

**AI_Comments:** COT-AD通过提供一个全面的、专门针对棉花的标注数据集，有效地填补了农业计算机视觉领域的一个重要空白，对于推进数据驱动的棉花作物管理和病害早期预警具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过计算机视觉增强棉花作物分析，解决棉花特定农业数据集中存在的关键空白。

**Method:** 本文提出了COT-AD数据集，这是一个包含超过25,000张在棉花生长周期中捕获的图像的综合数据集，其中5,000张已标注。数据集包括用于田间规模检测和分割的航空图像以及记录关键病害的高分辨率单反相机图像。标注内容涵盖病虫害识别、植被和杂草分析。

**Result:** COT-AD数据集支持分类、分割、图像恢复、增强、基于深度生成模型的棉花作物合成和早期病害管理等任务。

**Conclusion:** COT-AD数据集的创建旨在推进数据驱动的作物管理。

> **ai_Abstract:** COT-AD是一个专为棉花作物分析设计的综合计算机视觉数据集。它包含超过25,000张在棉花生长周期中捕获的图像，其中5,000张已标注，涵盖航空图像和高分辨率单反图像。该数据集的标注内容包括病虫害识别、植被和杂草分析，旨在填补棉花特定农业数据集的空白。COT-AD支持多种任务，如分类、分割、图像恢复、增强、深度生成模型合成以及早期病害管理，从而推动数据驱动的作物管理。

> **摘要翻译:** 本文介绍了COT-AD，这是一个旨在通过计算机视觉增强棉花作物分析的综合数据集。该数据集包含在棉花生长周期中捕获的超过25,000张图像，其中5,000张已标注。COT-AD包括用于田间规模检测和分割的航空图像，以及记录关键病害的高分辨率单反相机图像。标注涵盖病虫害识别、植被和杂草分析，解决了棉花特定农业数据集中的关键空白。COT-AD支持分类、分割、图像恢复、增强、基于深度生成模型的棉花作物合成和早期病害管理等任务，从而推进数据驱动的作物管理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [384] [PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding](https://arxiv.org/abs/2504.13180)
> *感知语言模型：用于详细视觉理解的开放获取数据和模型*

*Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma, Shuming Hu, Suyog Jain, Miguel Martin, Huiyu Wang, Hanoona Rasheed, Peize Sun, Po-Yao Huang, Daniel Bolya, Nikhila Ravi, Shashank Jain, Tammy Stark, Shane Moon, Babak Damavandi, Vivian Lee, Andrew Westbury, Salman Khan, Philipp Krähenbühl, Piotr Dollár, Lorenzo Torresani, Kristen Grauman, Christoph Feichtenhofer* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 视觉语言模型, 开放获取, 视频理解, 数据集, 基准测试

**Comment:** Technical Report

> **TL;DR:** PerceptionLM提供开放获取的数据和模型，以促进透明且可复现的图像和视频理解研究，解决了闭源视觉语言模型的数据和设计不透明问题。

**AI_Comments:** PerceptionLM的创新之处在于其完全开放和可复现的框架，这对于促进透明的科学研究至关重要。通过发布大规模高质量的人工标注视频理解数据集和专门的评估基准PLM-VideoBench，该工作有效地弥补了现有数据集在细粒度视频理解方面的不足，并为评估复杂视频推理任务提供了新工具。其重要性在于，它为社区提供了一个透明的替代方案，以应对闭源模型带来的挑战，有助于推动视觉语言模型领域的可持续发展。

<details>
  <summary>Details</summary>

**Motivation:** 许多高性能视觉语言模型是闭源的，这使得它们的数据、设计和训练方法不透明，阻碍了可测量的科学进展。尽管通过蒸馏可以获得强基准结果，但这牺牲了科学进步的透明度。因此，研究界需要一个完全开放和可复现的框架来促进图像和视频理解的透明研究。

**Method:** 本研究构建了一个感知语言模型 (PLM)，采用完全开放和可复现的框架。作者分析了不依赖专有模型蒸馏的标准训练流程，并探索了大规模合成数据以识别关键数据空白，尤其是在详细视频理解方面。为弥补这些空白，他们发布了2.8M个人工标注的细粒度视频问答对和时空定位的视频字幕。此外，他们还引入了PLM-VideoBench，一个评估复杂视频理解任务的套件，重点是推理视频的“什么”、“在哪里”、“何时”和“如何”。

**Result:** 研究结果包括发布了2.8M个人工标注的细粒度视频问答对和时空定位的视频字幕，以及引入了PLM-VideoBench基准套件，用于评估视频理解任务中对“什么”、“在哪里”、“何时”和“如何”的推理能力。作者还提供了数据、训练方法、代码和模型，使工作完全可复现。

**Conclusion:** 该论文通过提供开放获取的数据、模型、训练方法和代码，成功构建了一个透明且可复现的感知语言模型 (PLM) 框架，旨在促进图像和视频理解领域的科学研究。通过发布大规模高质量数据集和新的评估基准，为解决详细视频理解中的数据空白和挑战性任务提供了重要资源。

> **ai_Abstract:** 本文针对视觉语言模型闭源导致研究不透明的问题，提出了PerceptionLM，一个完全开放和可复现的框架，旨在促进图像和视频理解的透明研究。研究分析了现有训练流程，识别了数据空白，特别是详细视频理解方面。为解决此问题，作者发布了2.8M个人工标注的细粒度视频问答对和时空定位视频字幕，并推出了PLM-VideoBench基准，用于评估视频中“什么”、“在哪里”、“何时”和“如何”的推理能力。所有数据、代码和模型均已开源，确保可复现性。

> **摘要翻译:** 视觉语言模型是计算机视觉研究不可或缺的一部分，然而许多高性能模型仍然是闭源的，这模糊了它们的数据、设计和训练方法。研究社区通过使用黑盒模型蒸馏来标注训练数据，取得了强大的基准测试结果，但代价是可测量的科学进展。然而，在不知道教师模型及其数据源的细节情况下，科学进展仍然难以衡量。在本文中，我们研究了如何在完全开放和可复现的框架中构建一个感知语言模型 (PLM)，以进行图像和视频理解的透明研究。我们分析了不依赖专有模型蒸馏的标准训练流程，并探索了大规模合成数据以识别关键数据空白，特别是在详细视频理解方面。为了弥补这些空白，我们发布了2.8M个人工标注的细粒度视频问答对和时空定位的视频字幕。此外，我们引入了PLM-VideoBench，一个用于评估挑战性视频理解任务的套件，重点是推理视频的“什么”、“在哪里”、“何时”和“如何”的能力。我们通过提供数据、训练方法、代码和模型，使我们的工作完全可复现。https://github.com/facebookresearch/perception_models

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [388] [MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection](https://arxiv.org/abs/2502.16943)
> *MAD-AD：用于无监督脑部异常检测的掩蔽扩散模型*

*Farzad Beizaee, Gregory Lodygensky, Christian Desrosiers, Jose Dolz* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-23**

**Keywords:** 无监督异常检测, 脑部图像, 扩散模型, 掩蔽, 异常定位

**Comment:** 

> **TL;DR:** MAD-AD是一种利用掩蔽扩散模型进行无监督脑部异常检测的新方法，通过学习正常脑部结构并识别异常区域，在生成正常对应物和定位异常方面表现优越。

**AI_Comments:** 这篇论文提出了一种新颖的、基于扩散模型的无监督异常检测方法，其创新点在于将掩蔽机制引入扩散模型，使其能够更有效地学习正常脑部结构的表示，并将异常视为噪声进行隔离。这种方法避免了对大量带标签异常数据的依赖，这在医学图像领域尤为重要。其在生成正常对应物和定位异常方面的优越表现，表明了该方法在临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在没有标签的情况下，脑部图像的无监督异常检测对于识别损伤和病理至关重要。然而，由于脑部结构固有的复杂性和变异性以及带注释的异常数据稀缺，医学图像中异常的精确定位仍然具有挑战性。

**Method:** 该研究提出了一种新颖的方法MAD-AD，将掩蔽操作融入扩散模型中，利用其生成能力学习正常脑部解剖的鲁棒表示。在训练期间，模型仅处理正常脑部MRI扫描，并在潜在空间中对随机选择的图像块特征添加噪声进行前向扩散。模型通过双重目标学习识别哪些图像块是噪声并恢复其原始特征。在推理时，模型识别对应于异常的噪声图像块，并通过应用反向扩散过程为这些图像块生成一个正常的对应物。

**Result:** 该方法超越了现有的无监督异常检测技术，在生成准确的正常对应物和定位异常方面表现出卓越的性能。

**Conclusion:** MAD-AD通过利用扩散模型中的掩蔽机制，有效解决了无监督脑部异常检测和定位的挑战，并在性能上超越了现有技术。

> **ai_Abstract:** MAD-AD是一种创新的无监督脑部异常检测方法，它将掩蔽机制整合到扩散模型中。该模型通过在潜在空间中对正常脑部MRI图像块添加噪声进行训练，学习识别噪声并恢复原始特征，从而捕捉正常脑部解剖的复杂模式。在推理时，它能识别异常区域并生成其正常的对应物。实验结果表明，MAD-AD在生成正常对应物和定位异常方面优于现有技术。

> **摘要翻译:** 无监督的脑部图像异常检测对于在没有标签的情况下识别损伤和病理至关重要。然而，由于脑部结构固有的复杂性和变异性以及带注释的异常数据稀缺，医学图像中异常的精确定位仍然具有挑战性。为了解决这一挑战，我们提出了一种新颖的方法，将掩蔽操作融入扩散模型中，利用其生成能力学习正常脑部解剖的鲁棒表示。在训练期间，我们的模型仅处理正常脑部MRI扫描，并在潜在空间中对随机选择的图像块特征执行前向扩散过程，添加噪声。遵循双重目标，模型学习识别哪些图像块是噪声并恢复其原始特征。这种策略确保模型捕获正常脑部结构的复杂模式，同时将潜在异常隔离为潜在空间中的噪声。在推理时，模型识别对应于异常的噪声图像块，并通过应用反向扩散过程为这些图像块生成一个正常的对应物。我们的方法超越了现有的无监督异常检测技术，在生成准确的正常对应物和定位异常方面表现出卓越的性能。代码可在hhttps://github.com/farzad-bz/MAD-AD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [395] [External Knowledge Injection for CLIP-Based Class-Incremental Learning](https://arxiv.org/abs/2503.08510)
> *基于CLIP的类增量学习的外部知识注入*

*Da-Wei Zhou, Kai-Wen Li, Jingyi Ning, Han-Jia Ye, Lijun Zhang, De-Chuan Zhan* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 类增量学习, CLIP, 外部知识注入, 视觉-语言模型, GPT-4

**Comment:** Accepted to ICCV 2025. Code is available at:
  https://github.com/LAMDA-CL/ICCV25-ENGINE

> **TL;DR:** 本文提出ENGINE框架，通过视觉和文本双分支注入外部知识，以提升基于CLIP的类增量学习性能，并实现最先进的结果。

**AI_Comments:** 该论文的创新点在于提出了一个结合视觉和文本模态的外部知识注入框架ENGINE，特别是利用GPT-4生成判别性描述符来增强文本知识，并结合了数据增强和后调优策略。这为解决CLIP在类增量学习中对上下文信息利用不足以及特征遗忘问题提供了有效方案，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** CLIP在类增量学习中通过匹配视觉嵌入和类名进行决策，但忽略了语言中丰富的上下文信息，且在模型持续更新时，详细特征容易被覆盖，因此需要外部知识进行补偿。

**Method:** 本文提出了ExterNal knowledGe INjEction (ENGINE) 框架，用于基于CLIP的类增量学习。该框架采用双分支注入调优，从视觉和文本模态编码信息知识。视觉分支通过数据增强来丰富视觉特征，而文本分支利用GPT-4重写判别性描述符。此外，在推理过程中通过重新排序预测结果来实现后调优知识注入。

**Result:** 广泛的实验表明ENGINE实现了最先进的性能。

**Conclusion:** 通过注入外部知识，模型能够更好地捕获下游任务的信息特征，从而在数据演变时表现更佳。

> **ai_Abstract:** 该论文提出了ENGINE框架，旨在解决基于CLIP的类增量学习中因缺乏上下文信息和特征覆盖而导致的性能下降问题。ENGINE通过一个双分支注入调优框架，从视觉（数据增强）和文本（GPT-4生成的描述符）模态引入外部知识。此外，还通过推理时重排序实现了后调优知识。实验证明，ENGINE显著提升了CLIP在类增量学习中的表现，达到了最先进的水平。

> **摘要翻译:** 类增量学习（CIL）使学习系统能够持续适应不断演变的数据流。随着预训练的进步，利用预训练的视觉-语言模型（例如CLIP）为CIL提供了一个有前景的起点。然而，CLIP通过匹配视觉嵌入与类名进行决策，忽略了语言所传达的丰富上下文信息。例如，“猫”的概念可以分解为尾巴、皮毛和面部等特征进行识别。此外，由于模型不断更新，这些详细特征在CIL中会被覆盖，需要外部知识进行补偿。在本文中，我们引入了用于基于CLIP的CIL的外部知识注入（ENGINE）。为了增强数据集外部的知识转移，我们提出了一种双分支注入调优框架，该框架从视觉和文本两种模态编码信息知识。视觉分支通过数据增强来丰富视觉特征，而文本分支利用GPT-4重写判别性描述符。除了这种即时知识注入，我们还在推理过程中通过重新排序预测结果实现了后调优知识。通过注入的知识，模型可以更好地捕获下游任务的信息特征，随着数据演变。广泛的实验证明了ENGINE的最先进性能。代码可在：https://github.com/LAMDA-CL/ICCV25-ENGINE 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments](https://arxiv.org/abs/2507.18484)
> *强化具身主动防御：利用自适应交互实现对抗性3D环境中的鲁棒视觉感知*

*Xiao Yang, Lingxuan Wu, Lizhong Wang, Chengyang Ying, Hang Su, Jun Zhu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 强化具身主动防御, 对抗攻击, 3D环境, 视觉感知, 鲁棒性

**Comment:** arXiv admin note: text overlap with arXiv:2404.00540

> **TL;DR:** 本文提出了Rein-EAD，一种强化学习驱动的主动防御框架，通过自适应探索和环境交互，显著提高了3D对抗性环境中视觉感知的鲁棒性，并在多种任务中展现出对未知攻击的泛化能力。

**AI_Comments:** Rein-EAD的创新之处在于其主动防御范式，区别于传统的被动防御。它将强化学习引入对抗防御，通过与环境的自适应交互来动态调整防御策略，而非依赖预设的攻击模型。这种方法显著提升了防御的鲁棒性和对未知攻击的泛化能力，尤其在自动驾驶等高风险领域具有重要应用价值。此外，无需可微分环境的特性也大大拓宽了其在现实世界中的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 在3D环境中，对抗性攻击对视觉感知系统的可靠性构成严重威胁，尤其是在身份验证和自动驾驶等安全敏感应用中。现有防御机制多为被动策略，依赖于预设的攻击战术假设，导致在动态3D环境中适应性不足。

**Method:** 本文引入了强化具身主动防御（Rein-EAD）框架，这是一种主动防御策略。它通过与环境进行自适应探索和交互来提高感知鲁棒性。Rein-EAD采用多步目标，平衡即时预测准确性与预测熵最小化，并在多步时间范围内优化防御策略。此外，它还包含一个面向不确定性的奖励塑形机制，以实现高效的策略更新，减少计算开销，并支持在无需可微分环境下的实际应用。

**Result:** 综合实验验证了Rein-EAD的有效性，证明其在保持标准精度的同时，显著降低了攻击成功率。值得注意的是，Rein-EAD对未知和自适应攻击表现出强大的泛化能力。

**Conclusion:** Rein-EAD是一种有效的主动防御框架，能够显著提高3D对抗性环境中视觉感知系统的鲁棒性，并能泛化到未知攻击，使其适用于3D物体分类、人脸识别和自动驾驶等多种实际复杂任务。

> **ai_Abstract:** 本文提出了一种名为强化具身主动防御（Rein-EAD）的新型框架，旨在解决3D环境中对抗性攻击对视觉感知系统造成的威胁。与现有被动防御不同，Rein-EAD采用主动策略，通过自适应探索和环境交互来增强系统鲁棒性。该框架通过优化平衡预测准确性和熵最小化的多步目标，并利用面向不确定性的奖励塑形机制实现高效策略更新。实验结果表明，Rein-EAD能显著降低攻击成功率，保持高精度，并对未知及自适应攻击展现出强大的泛化能力，适用于多种真实世界应用。

> **摘要翻译:** 3D环境中的对抗性攻击已成为视觉感知系统可靠性的关键威胁，尤其是在身份验证和自动驾驶等安全敏感应用中。这些攻击利用复杂场景中的漏洞，通过对抗性补丁和3D对象来操纵深度神经网络（DNN）的预测。现有的防御机制，如对抗训练和净化，主要采用被动策略来增强鲁棒性。然而，这些方法通常依赖于对对抗性策略的预定义假设，限制了它们在动态3D环境中的适应性。为了解决这些挑战，我们引入了强化具身主动防御（Rein-EAD），这是一个主动防御框架，它利用自适应探索和与环境的交互来提高3D对抗性环境中的感知鲁棒性。通过实施一个平衡即时预测准确性和预测熵最小化的多步目标，Rein-EAD在多步时间范围内优化防御策略。此外，Rein-EAD还包含一个面向不确定性的奖励塑形机制，该机制有助于高效的策略更新，从而减少计算开销并支持无需可微分环境的实际应用。全面的实验验证了Rein-EAD的有效性，证明在保持标准精度的同时，显著降低了攻击成功率。值得注意的是，Rein-EAD对未知和自适应攻击表现出强大的泛化能力，使其适用于3D物体分类、人脸识别和自动驾驶等现实世界复杂任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [Vision Transformers in Precision Agriculture: A Comprehensive Survey](https://arxiv.org/abs/2504.21706)
> *农业中的视觉Transformer：一项综合调查*

*Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视觉Transformer, 精准农业, 植物病害检测, 深度学习, 计算机视觉

**Comment:** 

> **TL;DR:** 这篇综述探讨了视觉Transformer在精准农业中的应用，涵盖其架构、应用、挑战和未来方向，旨在帮助读者深入理解ViTs如何改变智能农业。

**AI_Comments:** 这篇综述及时地总结了视觉Transformer在精准农业这一新兴且重要的领域中的应用，填补了该领域的空白。它不仅详细介绍了ViTs的原理和优势，还深入分析了其面临的实际挑战和未来发展方向，为研究人员和实践者提供了宝贵的参考。其全面性体现在对架构、比较分析、挑战和未来趋势的覆盖，对于推动ViTs在农业领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法在作物健康维护和产量提升方面存在可扩展性和准确性限制。视觉Transformer（ViTs）作为一种有前景的替代方案，能更好地处理长距离依赖和提高视觉任务的可扩展性。因此，本研究旨在全面探索ViTs在精准农业中的应用潜力。

**Method:** 本文对现有文献进行了全面回顾，首先介绍了ViTs的基础架构及其从自然语言处理到计算机视觉的转变，并探讨了ViTs如何缓解传统模型（如CNNs）的归纳偏置。研究重点关注关键方法、数据集和性能指标，并对CNNs和ViTs进行比较分析，同时审查混合模型和性能增强技术。文章还探讨了数据要求、计算需求和模型可解释性等技术挑战及其潜在解决方案。

**Result:** 本综述系统地梳理了ViTs在精准农业中的应用，包括其架构、与CNNs的比较、混合模型、性能增强以及所面临的技术挑战和解决方案。研究旨在让从业者和研究人员深入理解ViTs如何有望改变智能和精准农业。

**Conclusion:** 视觉Transformer有望改变智能和精准农业，本研究为从业者和研究人员深入理解其应用潜力提供了全面的视角。

> **ai_Abstract:** 本文对视觉Transformer (ViTs) 在精准农业中的应用进行了全面综述。文章首先介绍了ViTs的基础架构及其从自然语言处理到计算机视觉的演变，并探讨了ViTs如何解决传统卷积神经网络的归纳偏置问题。随后，文章回顾了相关文献中的关键方法、数据集和性能指标，并比较了ViTs与CNNs，同时讨论了混合模型和性能增强技术。论文还分析了ViTs在农业应用中面临的数据、计算和可解释性等技术挑战，并提出了潜在解决方案，最后展望了未来的研究方向，旨在帮助研究人员和从业者理解ViTs在智能农业中的巨大潜力。

> **摘要翻译:** 检测植物病害是现代农业的关键方面，因为它在维持作物健康和提高整体产量方面发挥着重要作用。传统方法虽然仍有价值，但通常依赖人工检查或传统的机器学习技术，这两种方法在可扩展性和准确性方面都面临局限。最近，视觉Transformer（ViTs）作为一种有前景的替代方案出现，提供了处理长距离依赖性以及在视觉任务中更好可扩展性等优势。本综述探讨了ViTs在精准农业中的应用，涵盖了一系列任务。我们首先介绍了ViTs的基础架构，并讨论了它们从自然语言处理（NLP）到计算机视觉的转变。讨论内容包括卷积神经网络（CNNs）等传统模型中的归纳偏置概念，以及ViTs如何缓解这些偏置。我们对近期文献进行了全面回顾，重点关注关键方法、数据集和性能指标。本研究还包括对CNNs和ViTs的比较分析，以及对混合模型和性能增强的综述。文中探讨了数据要求、计算需求和模型可解释性等技术挑战，以及潜在的解决方案。最后，我们概述了未来的研究方向和技术进步，这些进步可以进一步支持ViTs在实际农业环境中的整合。本研究的目标是让从业者和研究人员更深入地了解ViTs如何有望改变智能和精准农业。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [417] [Towards Effective Human-in-the-Loop Assistive AI Agents](https://arxiv.org/abs/2507.18374)
> *迈向有效的人机协作辅助AI代理*

*Filippos Bellos, Yayuan Li, Cary Shu, Ruey Day, Jeffrey M. Siskind, Jason J. Corso* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人机协作, 辅助AI, 增强现实, 任务完成, 评估框架

**Comment:** 10 pages, 5 figures, 2 tables

> **TL;DR:** 本文介绍了一个评估框架、多模态数据集和一款AR辅助AI代理，旨在评估AI指导如何影响人类在物理任务中的表现，并通过人类研究证明AI辅助协作能提高任务完成度。

**AI_Comments:** 这项工作通过引入新的评估框架、数据集和AR辅助AI代理，为解决人机协作评估的复杂性提供了实用的方法。其创新之处在于结合了AR技术来提供实时交互式指导，并通过实证研究验证了AI辅助的有效性，对于提升人机协作效率和质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 有效的AI-人机协作在物理任务完成方面具有巨大潜力，但由于人机交互的复杂性，评估此类协作仍具挑战性。

**Method:** 本文引入了一个评估框架和一个人机交互的多模态数据集，用于评估AI指导如何影响程序性任务的执行、错误减少和学习成果。此外，开发了一个配备增强现实（AR）的AI代理，为现实世界任务提供交互式指导。

**Result:** 通过人类研究，本文分享了关于AI辅助人类表现的经验见解，并证明AI辅助协作能提高任务完成度。

**Conclusion:** AI辅助协作能够有效提高人类在物理任务中的表现和任务完成度。

> **ai_Abstract:** 本文针对人机协作中AI指导的评估挑战，提出了一个评估框架和多模态数据集，并开发了一款基于AR的AI辅助代理。通过人类研究，证明了AI辅助协作能有效提升物理任务的完成效率和人类表现。

> **摘要翻译:** 有效的人工智能-人类协作以完成物理任务在日常活动和专业领域都具有巨大潜力。配备信息指导的AI代理可以增强人类表现，但由于人机交互的复杂性，评估这种协作仍然具有挑战性。在这项工作中，我们引入了一个评估框架和一个人机交互的多模态数据集，旨在评估AI指导如何影响程序性任务的执行、错误减少和学习成果。此外，我们开发了一个配备增强现实（AR）的AI代理，可以在现实世界任务中提供交互式指导，从烹饪到战场医疗。通过人类研究，我们分享了关于AI辅助人类表现的经验见解，并证明AI辅助协作可以提高任务完成度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for Distractor-free 3D Reconstruction](https://arxiv.org/abs/2503.13176)
> *DeGauss：基于高斯泼溅的动静分解，实现无干扰三维重建*

*Rui Wang, Quentin Lohmeyer, Mirko Meboldt, Siyu Tang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 三维重建, 高斯泼溅, 动态场景, 无干扰, 自监督学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** DeGauss提出一种基于高斯泼溅的动静分解自监督框架，用于在动态环境中进行无干扰三维重建，并表现优异。

**AI_Comments:** DeGauss的创新点在于其解耦的动静高斯泼溅设计和自监督学习范式，有效解决了动态场景中干扰物去除和3D重建的难题。其无需复杂启发式或大量监督的特性，使其具有很强的实用性和普适性，为未来相关研究提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在高度动态和杂乱的场景（如第一视角视频）中，从真实世界捕获中重建干净、无干扰的三维场景仍然是一个重大挑战。

**Method:** DeGauss是一个简单、鲁棒的自监督框架，用于动态场景重建。它基于解耦的动静高斯泼溅设计，使用前景高斯建模动态元素，背景高斯建模静态内容，并通过概率掩码协调它们的组合，实现独立而互补的优化。

**Result:** DeGauss在包括NeRF-on-the-go、ADT、AEA、Hot3D和EPIC-Fields等基准测试中，始终优于现有方法，为高度动态、交互丰富的环境中的通用、无干扰三维重建建立了强大的基线。

**Conclusion:** DeGauss通过其解耦的动静高斯泼溅设计，成功解决了动态场景中无干扰三维重建的挑战，并展现了卓越的性能和泛化能力。

> **ai_Abstract:** DeGauss是一个针对动态杂乱场景中无干扰3D重建的自监督框架。它采用解耦的动静高斯泼溅设计，分别用前景和背景高斯建模动态和静态内容，并通过概率掩码协调优化。该方法在多种真实世界场景中表现出强大的泛化能力，并在多个基准测试中超越现有方法，为动态环境下的3D重建设定了新标准。

> **摘要翻译:** 从真实世界捕获中重建干净、无干扰的三维场景仍然是一个重大挑战，尤其是在高度动态和杂乱的环境中，如第一视角视频。为了解决这个问题，我们引入了DeGauss，一个简单而鲁棒的自监督框架，用于基于解耦的动静高斯泼溅设计进行动态场景重建。DeGauss使用前景高斯模型化动态元素，使用背景高斯模型化静态内容，并使用概率掩码协调它们的组合，实现独立而互补的优化。DeGauss在广泛的真实世界场景中表现出强大的泛化能力，从日常图像集合到长时间、动态的第一视角视频，无需依赖复杂的启发式方法或大量监督。在包括NeRF-on-the-go、ADT、AEA、Hot3D和EPIC-Fields在内的基准测试中，实验表明DeGauss始终优于现有方法，为在高度动态、交互丰富的环境中进行通用、无干扰的三维重建建立了强大的基线。项目页面：https://batfacewayne.github.io/DeGauss.io/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [421] [Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold](https://arxiv.org/abs/2507.17998)
> *超越点的配准：基于格拉斯曼流形测地距离的通用仿射子空间对齐*

*Jaeho Shin, Hyeonjae Gil, Junwoo Jang, Maani Ghaffari, Ayoung Kim* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 格拉斯曼流形, 仿射子空间配准, 测地距离, 刚体变换, 计算机视觉

**Comment:** 

> **TL;DR:** 本文提出一种基于格拉斯曼流形测地距离的可优化成本函数，用于通用仿射子空间配准，实现了全局最优并提高了性能。

**AI_Comments:** 本文通过首次在格拉斯曼流形上为配准问题提供了显式可优化成本函数，做出了重大贡献，解决了长期存在的挑战。其通过直接最小化测地距离，实现全局最优解且不受表示模糊性影响的能力是关键创新。这项工作有望提高涉及子空间对齐的各种计算机视觉任务的鲁棒性和准确性。提供代码进一步增强了其实际影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于仿射格拉斯曼流形测量线和平面邻近度的方法，缺乏一个明确的可优化刚体变换距离函数，从而限制了其在配准问题中的应用。

**Method:** 本文首次明确推导了关于刚体变换（R和t）的两个格拉斯曼特征之间的可优化成本函数。它严格证明了高维线性子空间基底可以作为成本的显式表示，并提出了一个基于变换基底的可优化成本函数，通过直接最小化测地距离来寻找全局最优解，该方法对表示模糊性不敏感。

**Result:** 所提出的方法通过直接最小化测地距离找到了全局最优解，该方法对表示模糊性不敏感。由此产生的成本函数及其在内点集最大化BnB求解器中的扩展，已被证明可以改善现有解决方案的收敛性，或在各种计算机视觉任务中超越它们。

**Conclusion:** 本文成功解决了格拉斯曼流形上缺乏可优化距离函数以用于配准的长期问题，提供了一种鲁棒且全局最优的解决方案，提升了计算机视觉任务的性能。

> **ai_Abstract:** 本文通过推导第一个用于格拉斯曼特征之间刚体变换的显式、可优化成本函数，解决了现有仿射格拉斯曼流形方法在配准中的局限性。它利用高维线性子空间基底来表示成本，并提出了一种新的函数，通过最小化测地距离来确保全局最优解，且不受表示模糊性的影响。与传统方法相比，该方法在各种计算机视觉任务中表现出更好的收敛性和优越的性能。

> **摘要翻译:** 仿射格拉斯曼流形因其在测量特征间距离方面的理论精确性而备受青睐，常用于表达线和平面之间的邻近度。尽管有此优势，现有方法只能测量邻近度，而不能将距离作为刚体变换的显式函数。因此，流形上的可优化距离函数一直未得到充分发展，阻碍了其在配准问题中的应用。本文首次明确推导了关于刚体变换（R和t）的两个格拉斯曼特征之间的可优化成本函数。具体来说，我们提出了一个严格的数学证明，表明高维线性子空间的基底可以作为成本的显式表示。最后，我们提出了一种基于变换基底的可优化成本函数，可应用于任何仿射子空间的配准问题。与基于向量参数的方法相比，我们的方法能够通过直接最小化测地距离来找到全局最优解，该距离对表示模糊性不敏感。由此产生的成本函数及其在内点集最大化BnB求解器中的扩展，已被证明可以改善现有解决方案的收敛性，或在各种计算机视觉任务中超越它们。代码可在https://github.com/joomeok/GrassmannRegistration上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [422] [Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling](https://arxiv.org/abs/2507.18176)
> *用于3D LiDAR语义分割的无监督域适应，采用对比学习和多模型伪标签*

*Abhishek Kaushik, Norbert Haala, Uwe Soergel* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 无监督域适应, 3D LiDAR语义分割, 对比学习, 多模型伪标签, 域偏移

**Comment:** 

> **TL;DR:** 本研究提出了一种两阶段框架，结合无监督对比学习和多模型伪标签策略，以解决3D LiDAR语义分割中的域适应问题，并在无标注目标数据集上取得了显著的分割精度提升。

**AI_Comments:** 该论文的创新点在于结合了无监督对比学习进行特征预训练和多模型伪标签策略。对比学习有助于学习更鲁棒的域不变特征，而多模型集成伪标签则有效缓解了单模型偏差，提高了伪标签的质量。这种两阶段的方法为解决3D LiDAR语义分割中的域适应难题提供了一个有效的解决方案，尤其是在目标域标注成本高昂的实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于域偏移（如传感器类型、地理位置）导致的3D LiDAR语义分割性能下降对自动驾驶系统至关重要，但目标数据的手动标注成本过高。

**Method:** 本研究提出了一种新颖的两阶段无监督域适应（UDA）框架。首先，使用无监督对比学习在片段级别预训练骨干网络，使其学习鲁棒的域不变特征。其次，引入多模型伪标签策略，利用多种最先进的架构（包括投影、体素、混合和基于圆柱的方法）的集成，通过硬投票聚合预测结果，为未标记的目标域生成高质量的精炼伪标签。最后，使用这些鲁棒的伪标签对对比预训练网络进行微调。

**Result:** 在从SemanticKITTI到未标记目标数据集（SemanticPOSS、SemanticSlamantic）的适应实验中，与直接迁移和单模型UDA方法相比，分割精度得到了显著提高。

**Conclusion:** 结合对比预训练和精炼的集成伪标签，可以有效地弥合复杂的域鸿沟，而无需目标域标注。

> **ai_Abstract:** 本论文提出了一种用于3D LiDAR语义分割的无监督域适应（UDA）两阶段框架，旨在解决域偏移导致的性能下降问题。第一阶段，通过无监督对比学习预训练骨干网络，以学习域不变特征。第二阶段，采用多模型伪标签策略，通过集成多种先进模型并硬投票生成高质量伪标签，然后用这些伪标签对预训练网络进行微调。实验结果表明，该方法在无标注目标数据集上显著提升了分割精度，证明了结合对比预训练和集成伪标签的有效性。

> **摘要翻译:** 由于域偏移（例如传感器类型、地理位置）导致的3D LiDAR语义分割性能下降对自动驾驶系统至关重要，然而目标数据的手动标注成本过高。本研究使用无监督域适应（UDA）来解决这一挑战，并引入了一个新颖的两阶段框架来解决它。首先，在片段级别使用无监督对比学习来预训练骨干网络，使其能够在没有标签的情况下学习鲁棒的、域不变的特征。随后，引入了一种多模型伪标签策略，利用多种多样最先进的架构（包括投影、体素、混合和基于圆柱的方法）的集成。通过硬投票聚合这些模型的预测结果，为未标记的目标域生成高质量的、精炼的伪标签，从而减轻了单模型偏差。然后，使用这些鲁棒的伪标签对对比预训练的网络进行微调。从SemanticKITTI到未标记目标数据集（SemanticPOSS、SemanticSlamantic）的适应实验表明，与直接迁移和单模型UDA方法相比，分割精度得到了显著提高。这些结果突出了结合对比预训练和精炼的集成伪标签在弥合复杂域鸿沟方面的有效性，而无需目标域标注。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models](https://arxiv.org/abs/2507.18534)
> *阐明基于任意噪声的扩散模型设计空间*

*Xingyu Qiu, Mengying Yang, Xinghua Ma, Dong Liang, Yuzhen Li, Fanding Li, Gongning Luo, Wei Wang, Kuanquan Wang, Shuo Li* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 任意噪声, 图像恢复, 设计空间, EDA

**Comment:** 21 pages, 4 figures

> **TL;DR:** 本文提出了EDA，一个基于任意噪声的扩散模型，解决了现有EDM模型在图像恢复中因固定高斯噪声模式导致的局限性。EDA在保留EDM灵活性的同时，扩展了噪声模式的自由度，并在MRI偏置场校正、CT金属伪影去除和阴影去除等任务中实现了最先进的性能，且计算开销没有增加。

**AI_Comments:** 本文的创新点在于将扩散模型的噪声模式从单一高斯噪声扩展到任意噪声，极大地拓宽了扩散模型在图像恢复领域的应用范围。其理论证明了噪声复杂性不增加计算开销，提升了实际应用价值。在多种任务中展现出卓越性能，特别是仅用5步采样就达到SOTA，体现了其高效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的EDM模型由于其固定且仅限于纯高斯噪声的模式，限制了其在图像恢复领域的进一步发展。强制注入高斯噪声会损坏降级图像，过度延长图像转换距离，并增加恢复复杂性。

**Method:** 本文提出了EDA（Elucidates the Design space of Arbitrary-noise-based diffusion models），旨在阐明基于任意噪声的扩散模型设计空间。EDA理论上扩展了噪声模式的自由度，同时保留了EDM原有的模块灵活性。研究证明，增加噪声复杂性不会在恢复过程中带来额外的计算开销。

**Result:** EDA在三种典型任务中进行了验证：MRI偏置场校正（全局平滑噪声）、CT金属伪影去除（全局尖锐噪声）和自然图像阴影去除（局部边界感知噪声）。仅用5个采样步长，EDA就超越了大多数特定任务方法，并在偏置场校正和阴影去除方面达到了最先进的性能。

**Conclusion:** EDA通过引入任意噪声模式，成功克服了传统扩散模型在图像恢复中的局限性，并在多种复杂噪声场景下的图像恢复任务中展现出卓越的性能和计算效率。

> **ai_Abstract:** 本文提出了EDA，一个创新性的基于任意噪声的扩散模型，旨在克服现有EDM模型在图像恢复中因固定高斯噪声模式带来的局限性。EDA扩展了噪声模式的自由度，同时保持了原始EDM的模块灵活性，并理论证明了噪声复杂性增加不会导致额外计算成本。经验证，EDA在MRI偏置场校正、CT金属伪影去除和自然图像阴影去除等任务中表现出色，仅需少量采样步骤即可超越多数特定任务方法，并在某些任务上达到最先进水平。

> **摘要翻译:** EDM阐明了扩散模型的统一设计空间，但其仅限于纯高斯噪声的固定噪声模式，限制了图像恢复的进展。我们的研究表明，强制注入高斯噪声会损坏退化图像，过度延长图像转换距离，并增加恢复复杂性。为解决此问题，我们提出的EDA阐明了基于任意噪声的扩散模型设计空间。理论上，EDA扩展了噪声模式的自由度，同时保留了EDM原始模块的灵活性，并有严格的证明表明增加噪声复杂性不会在恢复过程中产生额外的计算开销。EDA在三个典型任务中进行了验证：MRI偏置场校正（全局平滑噪声）、CT金属伪影去除（全局尖锐噪声）和自然图像阴影去除（局部边界感知噪声）。仅用5个采样步长，EDA就超越了大多数特定任务方法，并在偏置场校正和阴影去除方面达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation](https://arxiv.org/abs/2507.18558)
> *合成数据增强用于提升鸡胴体实例分割*

*Yihong Feng, Chaitanya Pallerla, Xiaomin Lin, Pouya Sohrabipour Sr, Philip Crandall, Wan Shou, Yu She, Dongyi Wang* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 合成数据, 数据增强, 实例分割, 鸡胴体, 家禽加工

**Comment:** Submitted for journal reviewing

> **TL;DR:** 本研究提出了一种生成逼真鸡胴体合成图像的流程，并创建了一个新的基准数据集，证明合成数据能显著提高鸡胴体实例分割的性能，尤其是在真实数据稀缺的情况下。

**AI_Comments:** 本研究的创新点在于首次提出了生成逼真鸡胴体合成图像的流程，并构建了专门的基准数据集，有效解决了家禽加工行业中深度学习模型训练面临的数据稀缺和标注成本高昂的痛点。其重要性在于为工业视觉检测领域提供了一种通用的数据增强策略，对推动AI在传统行业的应用具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 在家禽加工业中，自动化检测鸡胴体对于质量控制、食品安全和运营效率至关重要。然而，为实例分割等任务开发强大的深度学习模型，往往受限于获取和标注大规模真实世界图像数据集的繁琐工作。本研究旨在解决真实数据稀缺的问题。

**Method:** 本研究提出了第一个生成逼真、自动标注鸡胴体合成图像的流程。同时，引入了一个包含300张标注真实世界图像的新基准数据集。研究评估了合成数据和自动数据标注在增强鸡胴体实例分割方面的效用，尤其是在真实标注数据稀缺的情况下。在著名的实例分割模型中，使用不同比例合成图像的小型真实数据集进行了评估。

**Result:** 结果显示，合成数据显著提升了所有模型中鸡胴体的分割性能。

**Conclusion:** 本研究强调了合成数据增强作为一种可行且有效的策略的价值，它能够缓解数据稀缺、减少手动标注工作，并推动家禽加工业中鸡胴体强大的AI驱动自动化检测系统的发展。

> **ai_Abstract:** 本研究针对家禽加工业中鸡胴体自动化检测面临的真实数据稀缺问题，提出了一种创新的解决方案。研究开发了首个能够生成逼真、自动标注鸡胴体合成图像的流程，并构建了一个包含300张真实标注图像的新基准数据集。通过在主流实例分割模型中评估，结果表明合成数据能显著提升鸡胴体分割性能，有效缓解了数据标注的负担，为构建鲁棒的AI检测系统提供了有效途径。

> **摘要翻译:** 家禽业一直由肉鸡生产驱动，并已发展成为全球最大的动物蛋白产业。在加工线上自动化检测鸡胴体对于屠宰场和家禽加工厂的质量控制、食品安全和运营效率至关重要。然而，在这些快节奏的工业环境中，为实例分割等任务开发强大的深度学习模型，往往受限于获取和标注大规模真实世界图像数据集的繁琐工作。我们提出了第一个生成逼真、自动标注鸡胴体合成图像的流程。我们还引入了一个新的基准数据集，包含300张专门为家禽分割研究策划的标注真实世界图像。利用这些数据集，本研究调查了合成数据和自动数据标注在增强鸡胴体实例分割方面的功效，尤其是在加工线上真实标注数据稀缺的情况下。在著名的实例分割模型中，对包含不同比例合成图像的小型真实数据集进行了评估。结果表明，合成数据显著提升了所有模型中鸡胴体的分割性能。本研究强调了合成数据增强作为一种可行且有效的策略的价值，它能够缓解数据稀缺、减少手动标注工作，并推动家禽加工业中鸡胴体强大的AI驱动自动化检测系统的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [443] [Advances in 4D Generation: A Survey](https://arxiv.org/abs/2503.14501)
> *4D生成进展：一项综述*

*Qiaowei Miao, Kehan Li, Jinsheng Quan, Zhiyuan Min, Shaojie Ma, Yichao Xu, Yi Yang, Ping Liu, Yawei Luo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 4D生成, 综述, 动态3D资产, 生成式AI, 时空一致性

**Comment:** 

> **TL;DR:** 这篇综述系统地回顾了4D生成领域，涵盖了4D表示、生成框架、基本范式、应用以及面临的关键挑战，旨在为未来研究提供指导。

**AI_Comments:** 作为一篇综述论文，其创新性在于系统地梳理并统一了新兴的4D生成领域，填补了该领域缺乏全面理解的空白。其重要性体现在为研究人员提供了清晰的分类框架、技术分析、应用总结以及未来研究方向的指导，特别是对一致性、可控性等关键挑战的强调，对于推动4D生成技术的发展具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管4D生成作为新兴研究前沿取得了快速进展，但该领域缺乏对4D表示、生成框架、基本范式以及核心技术挑战的统一理解。因此，本综述旨在提供一个系统而深入的视角。

**Method:** 本综述通过以下方式全面描述4D生成：首先，对基本的4D表示进行分类并概述相关技术；其次，深入分析基于条件和表示方法的代表性生成流程；再次，讨论运动和几何先验如何集成到4D输出中以确保时空一致性；然后，从应用角度总结了4D生成任务；最后，总结并多维度比较了四种基本范式（端到端、基于生成数据、基于隐式蒸馏和基于显式监督），并强调了五个关键挑战（一致性、可控性、多样性、效率和保真度）。

**Result:** 本综述提供了对4D生成领域的系统和深入回顾，全面描述了4D表示和相关技术，分析了生成流程，讨论了运动和几何先验的集成，总结了4D生成任务，并比较了四种基本范式。同时，指出了该领域面临的五个关键挑战：一致性、可控性、多样性、效率和保真度。

**Conclusion:** 通过提炼最新进展并概述开放问题，这项工作为4D生成领域的未来研究提供了全面且前瞻性的视角。

> **ai_Abstract:** 本文是一篇关于4D生成领域的综述，旨在解决该领域缺乏统一理解的问题。它系统地回顾了4D表示、生成框架、基本范式、应用任务以及当前面临的关键挑战，如一致性、可控性、多样性、效率和保真度。通过对最新进展的梳理和对开放问题的探讨，本综述为未来4D生成研究提供了全面的指导和前瞻性视角。

> **摘要翻译:** 生成式人工智能最近已从静态图像和视频合成发展到3D内容生成，最终催生了4D生成——一项在用户输入指导下合成时间连贯动态3D资产的任务。作为新兴的研究前沿，4D生成实现了更丰富的交互式和沉浸式体验，应用范围从数字人类到自动驾驶。尽管进展迅速，但该领域缺乏对4D表示、生成框架、基本范式以及其面临的核心技术挑战的统一理解。本综述对4D生成领域进行了系统而深入的回顾。为了全面描述4D生成，我们首先对基本的4D表示进行分类，并概述了4D生成的相关技术。然后，我们深入分析了基于条件和表示方法的代表性生成流程。随后，我们讨论了运动和几何先验如何集成到4D输出中，以确保各种控制方案下的时空一致性。从应用角度来看，本文总结了动态对象/场景生成、数字人合成、可编辑4D内容和具身AI等领域的4D生成任务。此外，我们总结并多维度比较了4D生成的四种基本范式：端到端、基于生成数据、基于隐式蒸馏和基于显式监督。最后，我们重点强调了五个关键挑战——一致性、可控性、多样性、效率和保真度——并将这些挑战与当前方法联系起来。通过提炼最新进展并概述开放问题，这项工作为4D生成领域的未来研究提供了全面且前瞻性的视角。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [447] [Explaining How Visual, Textual and Multimodal Encoders Share Concepts](https://arxiv.org/abs/2507.18512)
> *解释视觉、文本和多模态编码器如何共享概念*

*Clément Cornet, Romaric Besançon, Hervé Le Borgne* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 稀疏自编码器, 多模态编码器, 特征共享, 跨模态比较, 文本预训练

**Comment:** 

> **TL;DR:** 本文提出新指标，量化比较视觉、文本和多模态编码器如何通过稀疏自编码器（SAE）特征共享概念，并发现跨模态共享的存在，尤其强调文本预训练的影响。

**AI_Comments:** 本文的创新点在于提出了新的量化指标，首次实现了视觉、文本和多模态编码器之间基于SAE特征的跨模态比较，填补了现有研究的空白。其发现，尤其是关于文本预训练对跨模态特征共享的影响，对于理解多模态模型的工作机制和未来模型设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 以前基于稀疏自编码器（SAE）特征的模型比较仅限于相同模态内，缺乏跨模态的量化比较方法。

**Method:** 提出了一种新的指标，用于跨SAE特征定量比较不同模态的模型，并引入“个体特征的比较共享性”来量化不同类型模型间个体特征的共享程度。利用这些工具对21种不同大小、通用和特定领域的视觉、文本和多模态编码器进行了比较研究。

**Result:** 结果重新审视了多模态背景下的编码器研究，量化了这些模型共享表示或特征的程度。研究还表明，视觉语言模型（VLMs）中特有的视觉特征与文本编码器共享，突出了文本预训练的影响。

**Conclusion:** 视觉、文本和多模态编码器之间存在显著的概念共享，特别是文本预训练对跨模态特征共享具有重要影响。

> **ai_Abstract:** 本文针对现有稀疏自编码器（SAE）特征比较仅限于同模态的局限性，提出了一种新颖的跨模态模型定量比较指标，并引入了“个体特征的比较共享性”概念。研究人员利用这些工具对21种不同规模和数据集的视觉、文本及多模态编码器进行了深入比较。研究结果不仅量化了这些模型之间表示和特征的共享程度，还特别指出视觉语言模型（VLMs）中的特定视觉特征与文本编码器共享，强调了文本预训练在促进跨模态概念共享方面的重要性。

> **摘要翻译:** 稀疏自编码器（SAE）已成为一种从神经网络激活中提取人类可解释特征的强大技术。以前的工作基于SAE导出的特征比较了不同的模型，但这些比较仅限于相同模态内的模型。我们提出了一种新颖的指标，允许跨SAE特征对模型进行定量比较，并用它来对视觉、文本和多模态编码器进行比较研究。我们还提出量化不同类型模型之间个体特征的“比较共享性”。利用这两个新工具，我们对21种三种类型的编码器进行了多项研究，考虑了两种显著不同的规模，以及通用和特定领域的数据集。结果允许在多模态背景下训练的编码器的视角下重新审视以前的研究，并量化所有这些模型共享某些表示或特征的程度。它们还表明，视觉编码器中视觉语言模型（VLMs）特有的视觉特征与文本编码器共享，突出了文本预训练的影响。代码可在https://github.com/CEA-LIST/SAEshareConcepts获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [455] [PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.03170)
> *PALADIN：文本到图像扩散模型的鲁棒神经指纹识别*

*Murthy L, Subarna Tripathi* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 神经指纹识别, 文本到图像模型, 扩散模型, 循环纠错码, 归因

**Comment:** 

> **TL;DR:** 本文提出一种名为PALADIN的神经指纹识别方法，利用循环纠错码的概念，旨在为文本到图像扩散模型提供高准确度的归因能力，以解决现有方法无法达到100%归因准确率的问题。

**AI_Comments:** 该论文的创新点在于将编码理论中的循环纠错码引入到神经指纹识别领域，为文本到图像扩散模型的归因提供了一种新颖且可能更准确的解决方案。如果该方法能实现接近100%的归因准确率，将对打击生成模型滥用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像生成模型（尤其是开源模型）被恶意使用的风险日益增加，引发严重担忧。现有神经指纹识别方法无法达到100%的归因准确率，导致其实际上无法部署。

**Method:** 本文提出一种准确的方法，利用编码理论中循环纠错码的概念，将神经指纹识别整合到文本到图像扩散模型中。

**Result:** 抽象中未提及具体结果。

**Conclusion:** 抽象中未提及。

> **ai_Abstract:** 本文提出一种名为PALADIN的鲁棒神经指纹识别方法，旨在应对文本到图像生成模型被恶意使用的风险。该方法创新性地将编码理论中的循环纠错码概念应用于文本到图像扩散模型，以期克服现有神经指纹识别技术无法达到100%归因准确率的局限性，从而提高模型归因的实用性和可靠性。

> **摘要翻译:** 文本到图像生成模型被恶意使用的风险，尤其由于此类模型的开源开发，已成为一个严重问题。作为一种风险缓解策略，通过神经指纹识别来归因生成模型正成为一种流行的技术。最近有大量工作旨在解决神经指纹识别问题。此类模型在归因准确性和生成质量之间的权衡已被广泛研究。然而，现有方法均未能达到100%的归因准确率。任何准确率低于百分之百的模型在实际中都无法部署。在这项工作中，我们提出了一种准确的方法，利用编码理论中循环纠错码的概念，将神经指纹识别融入到文本到图像扩散模型中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [459] [Towards Consistent Long-Term Pose Generation](https://arxiv.org/abs/2507.18382)
> *迈向一致的长期姿态生成*

*Yayuan Li, Filippos Bellos, Jason Corso* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 姿态生成, 长期姿态, 单阶段架构, 连续坐标, 相对运动预测

**Comment:** 10 pages, 5 figures, 4 tables

> **TL;DR:** 本文提出了一种新颖的单阶段架构，直接在连续坐标空间中生成长期姿态，无需中间表示或基于令牌的生成，显著优于现有方法。

**AI_Comments:** 该论文的关键创新在于提出了一个端到端的单阶段姿态生成模型，有效避免了传统方法中中间表示带来的误差累积问题，尤其对于长期姿态生成具有重要意义。其直接在连续坐标空间操作的思路和统一的占位符令牌方法是值得关注的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 当前姿态生成方法依赖中间表示（如两阶段量化或自回归模型），导致推理时误差累积，尤其在需要时间连贯性的长期姿态生成中性能下降。

**Method:** 提出了一种新颖的单阶段架构，直接从单个RGB图像和文本描述生成连续坐标空间中的姿态。关键创新在于通过相对运动预测机制直接操作姿态坐标，以及统一的占位符令牌方法，实现训练和推理时行为一致的单次前向生成，从而消除对中间表示或基于令牌的生成的需求。

**Result:** 在Penn Action和First-Person Hand Action Benchmark (F-PHAB) 数据集上的大量实验表明，该方法显著优于现有的基于量化和自回归方法，尤其在长期生成场景中表现更佳。

**Conclusion:** 该研究成功提出了一种无需中间表示的单阶段姿态生成方法，有效解决了现有方法在长期姿态生成中误差累积和时间连贯性差的问题，并在实验中验证了其优越性。

> **ai_Abstract:** 本研究提出了一种创新的单阶段架构，旨在解决现有姿态生成方法在长期生成中因依赖中间表示而导致的性能下降问题。该方法直接从图像和文本生成连续坐标空间中的姿态，通过相对运动预测和统一占位符令牌策略，避免了中间表示和令牌化过程。实验证明，该方法在长期姿态生成方面显著优于传统的量化和自回归方法。

> **摘要翻译:** 当前姿态生成方法严重依赖中间表示，无论是通过两阶段量化流水线还是在推理过程中累积误差的自回归模型。这种根本性限制导致性能下降，尤其是在保持时间连贯性至关重要的长期姿态生成中。我们提出了一种新颖的单阶段架构，可以直接从最少上下文（单个RGB图像和文本描述）在连续坐标空间中生成姿态，同时保持训练和推理之间的一致分布。我们的关键创新是通过相对运动预测机制直接操作姿态坐标，以及统一的占位符令牌方法，从而消除了对中间表示或基于令牌的生成的需要，实现了训练和推理时行为相同的单次前向生成。通过在Penn Action和First-Person Hand Action Benchmark (F-PHAB) 数据集上进行的大量实验，我们证明了我们的方法显著优于现有的基于量化和自回归方法，特别是在长期生成场景中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation](https://arxiv.org/abs/2507.18537)
> *TTS-VAR：一种用于视觉自回归生成的测试时缩放框架*

*Zhekai Chen, Ruihang Chu, Yukang Chen, Shiwei Zhang, Yujie Wei, Yingya Zhang, Xihui Liu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉自回归生成, 测试时缩放, 路径搜索, 多尺度生成, 聚类多样性搜索

**Comment:** 10 Tables, 9 Figures

> **TL;DR:** TTS-VAR是一个用于视觉自回归（VAR）模型的测试时缩放框架，它将生成过程建模为路径搜索问题，并通过自适应批处理大小调度、粗粒度聚类多样性搜索和细粒度重采样潜力选择来提高生成质量和效率。

**AI_Comments:** TTS-VAR的创新之处在于将测试时缩放应用于视觉自回归模型，并将其建模为路径搜索问题。其关键贡献在于引入了自适应批处理大小调度以及针对粗细粒度尺度的独特优化策略（聚类多样性搜索和重采样潜力选择）。这种方法有效地平衡了计算效率和生成质量，为资源受限的实际应用提供了新的思路。该框架的普适性和显著的性能提升使其具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩展视觉生成模型对于实际内容创作至关重要，但需要大量的训练和计算开销。测试时缩放因其资源效率和有前景的性能而受到越来越多的关注。

**Method:** 本文提出了TTS-VAR，这是第一个用于视觉自回归（VAR）模型的通用测试时缩放框架，它将生成过程建模为路径搜索问题。为了动态平衡计算效率和探索能力，该框架引入了以下组件：1) 在因果生成过程中采用自适应递减批处理大小调度。2) 在粗粒度尺度上，提出基于聚类的多样性搜索，通过语义特征聚类保留结构多样性，以选择具有更高潜力的样本。3) 在细粒度尺度上，基于重采样的潜力选择利用结合多尺度生成历史的奖励函数（潜力分数）来优先选择有希望的候选。

**Result:** 在强大的VAR模型Infinity上的实验显示，GenEval分数显著提高了8.7%（从0.69提高到0.75）。关键洞察表明，早期阶段的结构特征有效影响最终质量，并且重采样效率在不同生成尺度上有所不同。

**Conclusion:** TTS-VAR框架通过在测试时对视觉自回归生成过程进行优化，显著提高了生成质量，并通过动态平衡计算效率和探索能力，证明了早期结构特征对最终质量的重要性以及重采样在不同尺度下的有效性。

> **ai_Abstract:** 本文介绍了TTS-VAR，一个针对视觉自回归（VAR）模型的首个通用测试时缩放框架。该框架将生成过程视为路径搜索问题，旨在提高生成质量和效率。它通过引入自适应递减批处理大小调度、在粗粒度尺度上进行基于聚类的多样性搜索以保留结构多样性，以及在细粒度尺度上进行基于重采样的潜力选择来优化生成过程。实验证明，TTS-VAR在VAR模型上实现了显著的性能提升，表明早期结构特征对最终质量有重要影响。

> **摘要翻译:** 扩展视觉生成模型对于实际内容创建至关重要，但需要大量的训练和计算开销。作为替代方案，测试时缩放因其资源效率和有前景的性能而受到越来越多的关注。在这项工作中，我们提出了TTS-VAR，这是第一个用于视觉自回归（VAR）模型的通用测试时缩放框架，它将生成过程建模为路径搜索问题。为了动态平衡计算效率与探索能力，我们首先在整个因果生成过程中引入了自适应递减批处理大小调度。此外，受VAR分层粗到细多尺度生成的启发，我们的框架集成了两个关键组件：(i) 在粗粒度尺度上，我们观察到生成的标记难以评估，可能导致错误地接受劣质样本或拒绝优质样本。注意到粗粒度尺度包含足够的结构信息，我们提出了基于聚类的多样性搜索。它通过语义特征聚类保留了结构多样性，从而能够在后期选择具有更高潜力的样本。(ii) 在细粒度尺度上，基于重采样的潜力选择利用潜力分数优先选择有希望的候选，潜力分数被定义为结合多尺度生成历史的奖励函数。在强大的VAR模型Infinity上的实验显示，GenEval分数显著提高了8.7%（从0.69提高到0.75）。关键洞察表明，早期阶段的结构特征有效影响最终质量，并且重采样效率在不同生成尺度上有所不同。代码可在https://github.com/ali-vilab/TTS-VAR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [467] [One Look is Enough: A Novel Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation Models on High-Resolution Images](https://arxiv.org/abs/2503.22351)
> *一眼即足：一种用于高分辨率图像零样本单目深度估计模型的新颖无缝分块细化方法*

*Byeongjun Kwon, Munchurl Kim* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 零样本深度估计, 高分辨率图像, 分块细化, 泛化性, 深度不连续性

**Comment:** ICCV 2025 (camera-ready version). [Project
  page](https://kaist-viclab.github.io/One-Look-is-Enough_site)

> **TL;DR:** 本文提出了Patch Refine Once (PRO) 框架，通过分组补丁一致性训练和无偏掩蔽，解决了零样本单目深度估计模型在高分辨率图像处理中面临的深度不连续和泛化性差的问题，实现了高效且可泛化的深度细化。

**AI_Comments:** 本文提出了一种新颖的框架PRO，有效解决了零样本单目深度估计模型在高分辨率图像处理中的关键挑战。其创新点在于通过“分组补丁一致性训练”巧妙地处理了补丁拼接时的深度不连续问题，同时提高了效率；而“无偏掩蔽”则增强了模型从合成数据向真实世界的泛化能力，这对于实际应用至关重要。该方法通过模块化设计，允许无缝集成到现有模型中，具有很强的实用性。然而，摘要中未提供具体的量化性能提升数据。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本深度估计模型在处理高分辨率图像时表现不佳，原因在于训练和推理图像分辨率存在差异。全分辨率处理会导致精度下降和内存消耗巨大，而降采样则会使估计深度图像边缘模糊。此外，主流的基于补丁的方法在重新组合深度补丁时会引入深度不连续性，且测试效率低下。为了获得精细的深度细节，这些方法依赖于合成数据集，导致对真实世界数据的泛化能力差。

**Method:** 本文提出了一种名为Patch Refine Once (PRO) 的高效且可泛化的基于瓦片的框架。PRO包含两个关键组件：(i) 分组补丁一致性训练，通过在单个反向传播步骤中联合处理四个重叠补丁并在其重叠区域强制执行一致性损失来提高测试效率并缓解深度不连续问题；(ii) 无偏掩蔽，防止深度估计模型过度拟合特定数据集的偏差，即使在合成数据上训练后也能更好地泛化到真实世界数据集。

**Result:** 在Booster、ETH3D、Middlebury 2014和NuScenes数据集上的零样本评估表明，所提出的PRO框架可以无缝集成到现有的深度估计模型中。

**Conclusion:** PRO是一个高效且可泛化的框架，能够解决现有零样本单目深度估计模型在高分辨率图像处理中遇到的深度不连续和泛化性差等局限性。

> **ai_Abstract:** 现有的零样本单目深度估计模型在处理高分辨率图像时面临挑战，包括内存消耗大、降采样导致边缘模糊、基于补丁方法引入深度不连续以及对合成数据依赖导致泛化性差。本文提出了一种高效且可泛化的基于瓦片的框架——Patch Refine Once (PRO)。PRO通过“分组补丁一致性训练”解决了深度不连续和效率问题，并利用“无偏掩蔽”提升了模型对真实世界数据的泛化能力，即使在合成数据上训练也能表现良好。零样本评估结果显示，PRO可无缝集成到现有深度估计模型中。

> **摘要翻译:** 零样本深度估计 (DE) 模型由于在大规模数据集上训练而表现出强大的泛化性能。然而，现有模型在高分辨率图像处理方面表现不佳，原因在于训练（分辨率较低）和推理（分辨率较高）图像分辨率存在差异。以全分辨率处理会导致深度估计精度下降并消耗大量内存，而降采样到训练分辨率则会导致估计深度图像边缘模糊。主流的高分辨率深度估计方法采用基于补丁的方法，这在重新组合估计的深度补丁时引入了深度不连续性问题，导致测试时效率低下。此外，为了获得精细的深度细节，这些方法依赖于合成数据集，由于真实世界稀疏的地面实况深度，导致泛化能力差。为了解决这些局限性，我们提出了Patch Refine Once (PRO)，一个高效且可泛化的基于瓦片的框架。我们的PRO由两个关键组件组成：(i) 分组补丁一致性训练，通过在单个反向传播步骤中联合处理四个重叠补丁并在其重叠区域强制执行一致性损失来提高测试时效率并缓解深度不连续问题；(ii) 无偏掩蔽，防止DE模型过度拟合特定数据集的偏差，即使在合成数据上训练后也能更好地泛化到真实世界数据集。在Booster、ETH3D、Middlebury 2014和NuScenes数据集上的零样本评估表明，我们的PRO可以无缝集成到现有的深度估计模型中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures](https://arxiv.org/abs/2507.18009)
> *GRR-CoCa：在多模态模型架构中利用大型语言模型机制*

*Jake R. Patock, Nicole Catherine Lewis, Kevin McCoy, Christina Gomez, Canling Chen, Lorenzo Luzi* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** GRR-CoCa, 多模态模型, LLM机制, CoCa, 视觉-语言

**Comment:** 12 pages, 2 figures

> **TL;DR:** GRR-CoCa通过在多模态模型中引入LLM机制，显著提升了对比和生成任务的性能和泛化能力。

**AI_Comments:** 本文的创新点在于将大型语言模型（LLM）中已被验证有效的架构改进（如GELU、RMSNorm和RoPE）系统性地引入到多模态模型CoCa中，填补了多模态模型在架构复杂性上落后于LLM的空白。这提供了一个新的视角，即通过借鉴和融合不同领域最先进模型的优势，可以进一步提升现有模型的性能和泛化能力，对未来的多模态模型设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管最先进的多模态模型表现出色，但其架构复杂性仍落后于当代大型语言模型（LLMs）。本文旨在将已在LLMs中验证有效的架构改进引入多模态模型中，以提升其性能。

**Method:** 本文提出了GRR-CoCa，一个改进的CoCa模型，它在文本解码器和视觉Transformer（ViT）编码器中融入了高斯误差门控线性单元、均方根归一化和旋转位置嵌入。通过在对比和生成任务上，使用标准的预训练和微调流程，将GRR-CoCa与基线CoCa（具有相同修改的文本解码器但使用CoCa原始ViT编码器）进行了基准测试。

**Result:** GRR-CoCa在预训练数据集和三个不同的微调数据集上均显著优于基线CoCa。预训练阶段，对比损失降低27.25%，困惑度降低3.71%，CoCa损失降低7.15%。微调阶段，平均对比损失降低13.66%，困惑度降低5.18%，CoCa损失降低5.55%。

**Conclusion:** GRR-CoCa的修改架构证明能有效提升多模态模型的性能和在视觉-语言领域的泛化能力。

> **ai_Abstract:** 本文提出GRR-CoCa，一个改进的CoCa多模态模型，通过引入LLM中已验证有效的架构机制（如高斯误差门控线性单元、均方根归一化和旋转位置嵌入）到其文本解码器和ViT编码器中。实验结果表明，GRR-CoCa在预训练和微调阶段的对比和生成任务上均显著优于基线CoCa，验证了其在提升性能和跨视觉-语言领域泛化能力方面的有效性。

> **摘要翻译:** 最先进（SOTA）的图像和文本生成模型是多模态模型，它们与大型语言模型（LLMs）有许多相似之处。尽管取得了强大的性能，但领先的基础多模态模型架构在复杂性上常常落后于当代LLMs。我们提出了GRR-CoCa，一个改进的SOTA对比字幕模型（CoCa），它在文本解码器和视觉Transformer（ViT）编码器中融入了高斯误差门控线性单元、均方根归一化和旋转位置嵌入。每项架构修改都被证明能提升LLMs的模型性能，但尚未被CoCa采纳。我们针对基线CoCa（一个具有相同修改的文本解码器但使用CoCa原始ViT编码器的模型）对GRR-CoCa进行了基准测试。我们使用标准的预训练和微调工作流程，在对比和生成任务上对模型进行了基准测试。我们的GRR-CoCa在预训练数据集和三个不同的微调数据集上显著优于基线CoCa。预训练的改进包括对比损失降低27.25%，困惑度降低3.71%，CoCa损失降低7.15%。平均微调改进包括对比损失降低13.66%，困惑度降低5.18%，CoCa损失降低5.55%。我们展示了GRR-CoCa的修改架构提高了跨视觉-语言领域的性能和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios](https://arxiv.org/abs/2507.18177)
> *Differential-UMamba：重新思考有限数据场景下的肿瘤分割*

*Dhruv Jain, Romain Modzelewski, Romain Hérault, Clement Chatelain, Eva Torfeh, Sebastien Thureau* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 肿瘤分割, 有限数据, Diff-UMamba, 噪声抑制, 医学图像分割

**Comment:** 

> **TL;DR:** 本文提出Diff-UMamba架构，结合UNet和Mamba机制，并通过噪声抑制模块在有限数据场景下显著提高医学图像（特别是肿瘤）分割的准确性和鲁棒性。

**AI_Comments:** 这项研究通过引入噪声抑制模块（NRM）和结合UNet与Mamba机制，为有限数据场景下的医学图像分割提供了一种创新且有效的解决方案。其核心的信号差分策略能够有效抑制噪声，增强模型对关键区域的关注，对于解决医疗领域数据稀缺的挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在数据稀缺场景下，深度学习模型容易对噪声和不相关模式过拟合，这限制了其对未见样本的泛化能力，尤其是在医学图像分割领域。

**Method:** 引入Diff-UMamba，一种结合UNet框架和mamba机制的新颖架构，用于建模长程依赖。其核心是噪声抑制模块（NRM），该模块采用信号差分策略来抑制编码器内的噪声或不相关激活，以增强任务相关表示。

**Result:** 在MSD（肺和胰腺）和AIIB23等多个公共数据集上，性能比基线方法持续提升1-3%。在BraTS-21数据集上通过改变训练样本比例进行了额外实验。在小规模内部非小细胞肺癌（NSCLC）锥形束CT（CBCT）总肿瘤体积（GTV）分割数据集上，比基线提高了4-5%。

**Conclusion:** Diff-UMamba通过抑制噪声和增强任务相关表示，在有限数据设置下显著提高了肿瘤分割的准确性和鲁棒性。

> **ai_Abstract:** 本文提出Diff-UMamba，一种结合UNet和Mamba机制的新型深度学习架构，旨在解决医学图像分割在数据稀缺场景下的过拟合问题。Diff-UMamba的核心是噪声抑制模块（NRM），它通过信号差分策略有效抑制噪声和不相关激活，从而增强任务相关特征并提高模型对临床有意义区域的关注。实验结果表明，Diff-UMamba在多个公共和内部数据集上均展现出优于基线方法的分割精度和鲁棒性，特别是在低数据环境下。

> **摘要翻译:** 在数据稀缺的场景中，深度学习模型经常对噪声和不相关模式过拟合，这限制了它们对未见样本的泛化能力。为了解决医学图像分割中的这些挑战，我们引入了Diff-UMamba，这是一种新颖的架构，它将UNet框架与mamba机制结合起来，用于建模长程依赖。Diff-UMamba的核心是一个噪声抑制模块（NRM），它采用信号差分策略来抑制编码器内的噪声或不相关激活。这鼓励模型过滤掉虚假特征并增强与任务相关的表示，从而提高其对临床有意义区域的关注度。因此，该架构实现了更高的分割精度和鲁棒性，尤其是在低数据设置下。Diff-UMamba在多个公共数据集上进行了评估，包括MSD（肺和胰腺）和AIIB23，在各种分割任务中显示出比基线方法1-3%的持续性能提升。为了进一步评估有限数据条件下的性能，我们通过改变可用训练样本的比例，在BraTS-21数据集上进行了额外的实验。该方法还在一个小规模的内部非小细胞肺癌（NSCLC）锥形束CT（CBCT）总肿瘤体积（GTV）分割数据集上进行了验证，在该数据集上比基线提高了4-5%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [472] [DAA*: Deep Angular A Star for Image-based Path Planning](https://arxiv.org/abs/2507.09305)
> *DAA*：用于基于图像的路径规划的深度角度A星算法*

*Zhiwei Xu* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 路径规划, 深度学习, A*算法, 路径角度自由度, 模仿学习

**Comment:** International Conference on Computer Vision (ICCV), 2025

> **TL;DR:** 提出DAA*算法，通过引入路径角度自由度（PAF）改进A*，实现路径平滑性和相似性，在多个数据集上优于现有方法。

**AI_Comments:** 该论文提出DAA*算法，通过引入路径角度自由度（PAF）有效解决了路径模仿学习中路径平滑性被忽视的问题，并通过联合优化提升了路径相似性和最优性。其创新点在于将角度自由度引入路径规划，提高了算法的适应性。在多个数据集上的显著性能提升证明了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 路径模仿学习中常忽视路径平滑性。

**Method:** 本文引入了一种新颖的学习方法，称为深度角度A星（DAA*），通过将所提出的路径角度自由度（PAF）融入A*算法，并通过联合优化路径缩短（对应启发式距离）和平滑（对应PAF）来提高路径相似性和最优性，实现自适应路径平滑。

**Result:** 在7个数据集上，DAA*相比neural A*在预测路径与参考路径之间的路径相似性方面显著改进，且路径更短，SPR提高了9.0%，ASIM提高了6.9%，PSIM提高了3.9%。此外，当与路径损失和路径概率图损失共同学习路径规划时，DAA*显著优于最先进的TransPath，SPR提高了6.3%，PSIM提高了6.0%，ASIM提高了3.7%。

**Conclusion:** DAA*通过结合路径角度自由度（PAF）显著提升了路径模仿学习中的路径相似性和最优性，并探讨了路径最优性与搜索效率之间的权衡。

> **ai_Abstract:** 本文提出了一种名为深度角度A星（DAA*）的新型路径规划方法，旨在解决路径模仿学习中路径平滑性被忽视的问题。DAA*将路径角度自由度（PAF）集成到A*算法中，通过联合优化路径缩短和平滑来提高路径相似性和最优性。实验结果表明，在多个数据集上，DAA*在路径相似性方面显著优于neural A*，并超越了最先进的TransPath。

> **摘要翻译:** 路径模仿学习中，专家演示的路径平滑性常常被忽视。本文引入了一种新颖的学习方法，称为深度角度A星（DAA*），通过将所提出的路径角度自由度（PAF）融入A*算法，通过自适应路径平滑来提高路径相似性。PAF旨在通过寻找其最小值和最大值之间的权衡，探索移动角度对路径节点扩展的影响，从而为模仿学习提供高度适应性。DAA*通过联合优化路径缩短和平滑来提高路径最优性，分别对应启发式距离和PAF，使其与参考路径紧密对齐。
在包括4个迷宫数据集、2个视频游戏数据集以及一个包含2个场景的真实世界无人机视角数据集在内的7个数据集上进行全面评估，我们展示了DAA*在预测路径和参考路径之间的路径相似性方面相对于neural A*的显著改进，并且在最短路径合理时，路径长度更短，SPR提高了9.0%，ASIM提高了6.9%，PSIM提高了3.9%。此外，当与路径损失和路径概率图损失共同学习路径规划时，DAA*显著优于最先进的TransPath，SPR提高了6.3%，PSIM提高了6.0%，ASIM提高了3.7%。我们还讨论了路径最优性与搜索效率之间微小的权衡。我们的代码和模型权重可在https://github.com/zwxu064/DAAStar.git获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [479] [MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection](https://arxiv.org/abs/2506.03654)
> *MambaNeXt-YOLO: 一种用于实时目标检测的混合状态空间模型*

*Xiaochun Lei, Siqi Wu, Weilin Wu, Zetao Jiang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 实时目标检测, 状态空间模型, Mamba, YOLO, 边缘计算

**Comment:** This paper is under consideration at Image and Vision Computing

> **TL;DR:** MambaNeXt-YOLO 提出了一种结合 CNN 和 Mamba 的混合状态空间模型，以实现高效且准确的实时目标检测，特别适用于边缘设备。

**AI_Comments:** MambaNeXt-YOLO 的创新之处在于将线性状态空间模型 Mamba 与 CNN 和 YOLO 框架结合，有效解决了 Transformer 模型在实时和边缘部署中面临的计算复杂性挑战。其混合设计理念兼顾了局部特征和全局上下文，并通过专门的特征融合网络提升了多尺度检测能力，使其在资源受限的环境下具有显著的实用价值。在未预训练的情况下达到良好的性能并支持边缘设备部署，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 实时目标检测在计算资源有限的情况下仍是一项挑战。现有的 YOLO 系列模型在速度和准确性之间取得了平衡，但 Transformer 模型虽然能提供丰富的全局上下文，却因自注意力机制导致计算复杂度高，限制了其在实时和边缘部署中的实用性。

**Method:** 本文提出了 MambaNeXt-YOLO 目标检测框架，通过以下三项关键贡献平衡了准确性和效率：1) MambaNeXt Block：一种结合 CNN 和 Mamba 的混合设计，可有效捕获局部特征和长距离依赖；2) 多分支非对称融合金字塔网络 (MAFPN)：一种增强的特征金字塔架构，可改善跨各种目标尺寸的多尺度目标检测；3) 边缘聚焦效率：该方法在 PASCAL VOC 数据集上未经预训练即实现了 66.6% 的 mAP，帧率为 31.9 FPS，并支持在 NVIDIA Jetson Xavier NX 和 Orin NX 等边缘设备上部署。

**Result:** MambaNeXt-YOLO 在 PASCAL VOC 数据集上（未进行任何预训练）实现了 66.6% 的 mAP 和 31.9 FPS 的帧率，并支持在 NVIDIA Jetson Xavier NX 和 Orin NX 等边缘设备上部署。

**Conclusion:** MambaNeXt-YOLO 通过结合 CNN 和 Mamba 的混合设计，有效解决了实时目标检测中全局上下文建模的效率问题，实现了在边缘设备上部署的高效且准确的目标检测。

> **ai_Abstract:** MambaNeXt-YOLO 是一种新颖的实时目标检测框架，旨在解决传统 Transformer 模型在边缘设备上计算复杂度高的问题。它通过引入结合 CNN 和 Mamba 的 MambaNeXt Block 来有效捕获局部和长距离依赖，并利用多分支非对称融合金字塔网络 (MAFPN) 提升多尺度检测能力。该模型在 PASCAL VOC 数据集上表现出良好的性能，并在边缘设备上实现了高效部署。

> **摘要翻译:** 实时目标检测是计算机视觉中一项基础但具有挑战性的任务，尤其是在计算资源有限的情况下。尽管 YOLO 系列模型通过平衡速度和准确性设定了强大的基准，但对更丰富的全局上下文建模日益增长的需求导致了基于 Transformer 的架构的使用。然而，Transformer 由于其自注意力机制而具有高计算复杂度，这限制了它们在实时和边缘部署中的实用性。为了克服这些挑战，线性状态空间模型（如 Mamba）的最新发展提供了一种有前途的替代方案，通过线性复杂度实现高效的序列建模。基于这一见解，我们提出了 MambaNeXt-YOLO，一种新颖的目标检测框架，通过三项关键贡献平衡了准确性和效率：(1) MambaNeXt Block：一种混合设计，将 CNN 与 Mamba 集成，以有效捕获局部特征和长距离依赖；(2) 多分支非对称融合金字塔网络 (MAFPN)：一种增强的特征金字塔架构，可改善跨各种目标尺寸的多尺度目标检测；以及 (3) 边缘聚焦效率：我们的方法在 PASCAL VOC 数据集上未经任何预训练即实现了 66.6% 的 mAP 和 31.9 FPS，并支持在 NVIDIA Jetson Xavier NX 和 Orin NX 等边缘设备上部署。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [492] [Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing](https://arxiv.org/abs/2503.22929)
> *用于单类人脸防欺骗的无监督特征解耦与增强网络*

*Pei-Kai Huang, Jun-Xiong Chong, Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Hao-Chiang Shao, Chiou-Ting Hsu* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 人脸防欺骗, 特征解耦, 特征增强, 单类学习, 泛化能力

**Comment:** 

> **TL;DR:** 本文提出了一种名为UFDANet的无监督特征解耦与增强网络，通过解耦活体和域特征并进行特征增强，显著提升了单类人脸防欺骗的泛化能力。

**AI_Comments:** UFDANet的创新之处在于其无监督特征解耦机制，能够有效分离活体和域特征，这对于提升单类FAS的泛化能力至关重要。此外，结合两种特征增强策略来合成未见特征，进一步增强了模型应对未知欺骗和域变化的鲁棒性，是解决单类FAS实际应用挑战的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 传统的两类人脸防欺骗（FAS）方法存在对训练攻击过拟合的风险，而单类FAS方法虽然能很好地处理未见攻击，但对活体特征中纠缠的域信息鲁棒性较差，导致泛化能力不足。

**Method:** 本文提出了一种无监督特征解耦与增强网络（UFDANet），通过新颖的无监督特征解耦方法分离活体特征和域特征。它整合了一种域外活体特征增强方案，以合成未见欺骗类别的新活体特征，从而增强活体特征的表示能力和判别能力。此外，UFDANet还结合了域特征增强例程来合成未见域特征，以实现更好的泛化能力。

**Result:** 实验结果表明，所提出的UFDANet优于以前的单类人脸防欺骗方法，并达到了与最先进的两类人脸防欺骗方法相当的性能。

**Conclusion:** UFDANet通过无监督特征解耦和特征增强有效解决了单类人脸防欺骗中域信息纠缠的问题，显著提升了模型的泛化能力和性能。

> **ai_Abstract:** 本文提出了一种名为UFDANet的单类人脸防欺骗方法，旨在解决现有单类FAS方法中活体特征与域信息纠缠导致泛化能力不足的问题。UFDANet通过无监督方式解耦活体特征和域特征，并利用域外活体特征增强和域特征增强来合成新的活体和域特征，从而提高活体特征的表示能力、判别能力和模型的泛化能力。实验证明，UFDANet在性能上超越了现有单类FAS方法，并达到了与先进两类FAS方法相当的水平。

> **摘要翻译:** 人脸防欺骗（FAS）技术旨在通过区分真实的活体人脸和欺骗尝试来增强人脸身份验证的安全性。虽然两类FAS方法存在对训练攻击过拟合以获得更好性能的风险，但单类FAS方法能很好地处理未见攻击，但在活体特征中纠缠的域信息方面鲁棒性较差。为了解决这个问题，我们提出了一种无监督特征解耦与增强网络（UFDANet），这是一种通过解耦特征增强人脸图像来增强泛化能力的单类FAS技术。UFDANet采用一种新颖的无监督特征解耦方法来分离活体和域特征，促进判别性特征学习。它整合了一种域外活体特征增强方案，以合成未见欺骗类别的新活体特征，这些特征偏离活体类别，从而增强活体特征的表示能力和判别能力。此外，UFDANet还结合了域特征增强例程来合成未见域特征，从而实现更好的泛化能力。广泛的实验表明，所提出的UFDANet优于以前的单类FAS方法，并达到了与最先进的两类FAS方法相当的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [494] [HumanMaterial: Human Material Estimation from a Single Image via Progressive Training](https://arxiv.org/abs/2507.18385)
> *HumanMaterial：基于渐进式训练的单幅图像人体材质估计*

*Yu Jiang, Jiahao Xia, Jiongming Qin, Yusen Wang, Tuo Cao, Chunxia Xiao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人体材质估计, 逆向渲染, 渐进式训练, 物理渲染, OpenHumanBRDF

**Comment:** 14

> **TL;DR:** 本文提出了HumanMaterial模型和渐进式训练策略，以及高质量的OpenHumanBRDF数据集，用于从单幅图像估计高真实感人体材质，解决了现有方法在材质估计和真实感渲染方面的局限性。

**AI_Comments:** 该论文的创新点在于构建了高质量的OpenHumanBRDF数据集，特别是加入了位移和次表面散射以提升皮肤渲染的真实感，这对于人体材质估计至关重要。同时，提出的渐进式训练策略和CPR损失有效地解决了多材质图估计中各图重要性平衡和模型欠拟合的问题，提升了模型性能和渲染效果。该工作对于实现更逼真的人体数字替身和虚拟现实应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于物理渲染的全身体逆向渲染在获取高质量材质方面面临挑战，因为材质图缺乏约束，导致任务不适定。现有工作使用的简化材质数据和渲染方程限制了渲染的真实感，特别是皮肤。此外，随着预测任务的增加，端到端模型难以平衡各种材质图的重要性，导致模型欠拟合。

**Method:** 本文构建了一个更高质量的数据集OpenHumanBRDF，其中包含法线、漫反射反照率、粗糙度、镜面反照率，并额外生成了位移和次表面散射以增强渲染真实感，特别是皮肤。设计了一个名为HumanMaterial的模型，采用渐进式训练策略，首先通过三个先验模型获得初始材质结果，然后通过一个微调模型进行优化。为了平衡不同材质图的重要性，引入了受控PBR渲染（CPR）损失，以在先验模型训练期间增强待优化材质的重要性。

**Result:** 在OpenHumanBRDF数据集和真实数据上的大量实验表明，该方法实现了最先进的性能。

**Conclusion:** 本文提出的HumanMaterial模型、渐进式训练策略以及高质量的OpenHumanBRDF数据集，能够有效地从单幅图像估计高真实感人体材质，解决了逆向渲染中材质估计的挑战，并取得了最先进的性能。

> **ai_Abstract:** 本文针对单幅图像人体逆向渲染中材质估计的挑战，提出了HumanMaterial模型和渐进式训练策略。为解决现有数据集和模型在真实感和多材质平衡上的不足，作者构建了高质量的OpenHumanBRDF数据集，包含更丰富的材质图信息（如位移和次表面散射）。HumanMaterial模型采用先验模型获取初始材质，再通过微调模型精炼，并引入CPR损失以优化不同材质图的重要性。实验证明该方法在人体材质估计方面达到了最先进的性能。

> **摘要翻译:** 基于物理渲染的全身体逆向渲染旨在获取高质量的材质，这有助于在任意光照下实现照片级真实感渲染。该任务需要估计多个材质图，并且通常依赖于渲染结果的约束。材质图上缺乏约束使得逆向渲染成为一个病态问题。以前的工作通过构建用于训练的材质数据集来缓解这个问题，但其简化的材质数据和渲染方程导致渲染结果的真实感有限，特别是皮肤。为了进一步缓解这个问题，我们基于扫描的真实数据和统计材质数据构建了一个更高质量的数据集（OpenHumanBRDF）。除了法线、漫反射反照率、粗糙度、镜面反照率外，我们还生成了位移和次表面散射，以增强渲染结果的真实感，特别是对于皮肤。随着更多材质预测任务的增加，像以前工作那样使用端到端模型难以平衡各种材质图的重要性，并导致模型欠拟合。因此，我们设计了一个具有渐进式训练策略的模型（HumanMaterial），以充分利用材质图的监督信息并提高材质估计的性能。HumanMaterial首先通过三个先验模型获得初始材质结果，然后通过一个微调模型细化结果。先验模型估计不同的材质图，并且每个图对渲染结果具有不同的重要性。因此，我们设计了一种受控PBR渲染（CPR）损失，该损失在先验模型训练期间增强了待优化材质的重要性。在OpenHumanBRDF数据集和真实数据上的大量实验表明，我们的方法实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [500] [Diffuse and Disperse: Image Generation with Representation Regularization](https://arxiv.org/abs/2506.09027)
> *扩散与分散：基于表示正则化的图像生成*

*Runqian Wang, Kaiming He* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 表示学习, 正则化, 生成模型, 分散损失

**Comment:** 

> **TL;DR:** 提出了一种名为Dispersive Loss的即插即用正则化器，通过鼓励内部表示分散来显著改善扩散生成模型，无需额外数据或预训练。

**AI_Comments:** 该论文的创新点在于提出了Dispersive Loss，一个简单而有效的即插即用正则化器，解决了扩散模型缺乏显式正则化的问题。其无需正样本对、不干扰采样过程的特点，以及自包含、极简的设计使其具有很高的实用性。该工作在ImageNet上的显著改进证明了其有效性，并有望推动生成模型与表示学习领域的交叉融合。

<details>
  <summary>Details</summary>

**Motivation:** 扩散生成模型的发展与表示学习的进展相对独立，且这些模型通常依赖于基于回归的目标，缺乏显式正则化。

**Method:** 提出了Dispersive Loss，一个简单的即插即用正则化器。它鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但不需要正样本对，不干扰回归采样过程。该方法是自包含且极简的，不需要预训练、额外参数或外部数据。

**Result:** 在ImageNet数据集上对一系列模型进行了评估，并报告了相对于广泛使用和强大的基线模型的一致改进。

**Conclusion:** 该工作有助于弥合生成建模和表示学习之间的鸿沟。

> **ai_Abstract:** 本文提出了一种名为Dispersive Loss的新型即插即用正则化器，旨在改善扩散生成模型。该损失函数通过鼓励模型内部表示在隐藏空间中分散来增强模型性能，其灵感来源于对比自监督学习，但无需正样本对，避免了对回归采样过程的干扰。与现有方法相比，Dispersive Loss具有自包含和极简的特点，不依赖预训练、额外参数或外部数据。实验结果表明，在ImageNet数据集上，该方法能持续提升多种扩散模型的性能，超越了现有强基线，有望促进生成建模与表示学习的融合。

> **摘要翻译:** 在过去十年中，基于扩散的生成模型的发展与表示学习的进展在很大程度上是独立进行的。这些扩散模型通常依赖于基于回归的目标，并且普遍缺乏显式正则化。在这项工作中，我们提出了分散损失（Dispersive Loss），这是一种简单的即插即用正则化器，可以有效地改进基于扩散的生成模型。我们的损失函数鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，其关键区别在于它不需要正样本对，因此不会干扰用于回归的采样过程。与最近的表示对齐（REPA）方法相比，我们的方法是自包含且极简的，不需要预训练、不需要额外的参数，也不需要外部数据。我们在ImageNet数据集上对一系列模型评估了分散损失，并报告了相对于广泛使用和强大的基线的持续改进。我们希望我们的工作将有助于弥合生成建模和表示学习之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [508] [Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping](https://arxiv.org/abs/2507.18541)
> *无姿态3DGS重建与概率Procrustes映射*

*Chong Cheng, Zijian Wang, Sicheng Yu, Yu Hu, Nanjie Yao, Hao Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3DGS, 无姿态重建, 概率Procrustes映射, 多视角立体, 联合优化

**Comment:** 

> **TL;DR:** 提出了一种新的无姿态3DGS重建框架，通过概率Procrustes映射和联合优化，实现了大规模无姿态图像序列的准确重建，并在Waymo和KITTI数据集上达到了SOTA。

**AI_Comments:** 该论文的创新点在于将概率Procrustes映射引入到3DGS的无姿态重建中，有效解决了大规模点云对齐的挑战。同时，结合MVS先验和3DGS与姿态的联合优化，显著提升了重建精度和效率，特别是在处理无姿态室外图像序列方面具有重要意义。其提出的软垃圾箱机制和解析雅可比也增加了方法的鲁棒性和优化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D Gaussian Splatting (3DGS) 技术在无姿态重建任务中，当输入图像数量增多时，预训练的多视角立体(MVS)模型面临内存限制和精度下降的问题。

**Method:** 本文提出了一种结合预训练MVS先验与概率Procrustes映射策略的无姿态3DGS重建框架。该方法将输入图像划分为子集，将子图映射到全局空间，并联合优化几何和姿态。具体地，将千万级点云的映射公式化为概率Procrustes问题，并求解闭式对齐。通过概率耦合和软垃圾箱机制拒绝不确定对应，该方法在数分钟内全局对齐点云和姿态。此外，提出了一个3DGS和相机姿态的联合优化框架，从置信度感知的锚点构建高斯，并整合3DGS可微分渲染与解析雅可比，共同优化场景和姿态。

**Result:** 在Waymo和KITTI数据集上的实验表明，该方法能够从无姿态图像序列中实现准确的重建，并为无姿态3DGS重建树立了新的技术水平。

**Conclusion:** 该研究成功地解决了大规模无姿态图像序列下3DGS重建的挑战，通过创新的概率Procrustes映射和联合优化框架，实现了准确的场景重建和姿态估计，达到了无姿态3DGS重建的最新技术水平。

> **ai_Abstract:** 该论文提出了一种创新的无姿态3DGS重建框架，旨在解决现有方法在大规模室外图像场景中因内存限制和精度下降而导致的挑战。该框架通过将输入图像划分为子集，并利用概率Procrustes映射将子图精确对齐到全局空间，有效地处理了数千万点云的对齐问题。此外，该方法引入了3DGS与相机姿态的联合优化机制，通过置信度感知的锚点和解析雅可比，实现了场景和姿态的协同精细化。实验结果表明，该方法在Waymo和KITTI数据集上取得了显著的性能提升，为无姿态3DGS重建领域设立了新的技术标准。

> **摘要翻译:** 3D高斯泼溅（3DGS）已成为3D表示的核心技术。其有效性很大程度上取决于精确的相机姿态和准确的点云初始化，这些通常来源于预训练的多视角立体（MVS）模型。然而，在对数百张室外图像进行无姿态重建任务时，现有的MVS模型可能面临内存限制，并且随着输入图像数量的增加而失去精度。为了解决这一限制，我们提出了一种新颖的无姿态3DGS重建框架，该框架将预训练的MVS先验与概率Procrustes映射策略相结合。该方法将输入图像划分为子集，将子图映射到全局空间，并联合优化几何和姿态。从技术上讲，我们将数千万点云的映射公式化为概率Procrustes问题，并求解闭式对齐。通过采用概率耦合以及软垃圾箱机制来拒绝不确定对应，我们的方法在数百张图像中可在数分钟内全局对齐点云和姿态。此外，我们提出了一种3DGS和相机姿态的联合优化框架。它从置信度感知的锚点构建高斯，并将3DGS可微分渲染与解析雅可比相结合，共同优化场景和姿态，从而实现准确的重建和姿态估计。在Waymo和KITTI数据集上的实验表明，我们的方法能够从无姿态图像序列中实现准确的重建，为无姿态3DGS重建树立了新的技术水平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [515] [TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes](https://arxiv.org/abs/2503.23461)
> *TextCrafter：在复杂视觉场景中精确渲染多个文本*

*Nikai Du, Zhennan Chen, Zhizhou Chen, Shan Gao, Xi Chen, Zhengkai Jiang, Jian Yang, Ying Tai* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 复杂视觉文本生成, TextCrafter, 文本渲染, 渐进式策略, CVTG-2K

**Comment:** 

> **TL;DR:** TextCrafter是一种新的多视觉文本渲染方法，通过渐进式策略和令牌焦点增强机制，解决了复杂视觉文本生成（CVTG）中文本混淆、遗漏和模糊等挑战，并提出了新的CVTG-2K数据集。

**AI_Comments:** TextCrafter的创新之处在于其结合了渐进式分解策略和令牌焦点增强机制，这对于解决复杂视觉场景中多文本渲染的准确性和清晰度问题至关重要。同时，引入CVTG-2K数据集对于推动该领域的研究和提供标准评估基准具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂视觉文本生成（CVTG）中，图像生成模型经常渲染出扭曲、模糊或缺失的视觉文本。为了解决这些挑战，本文提出了TextCrafter。

**Method:** 本文提出了TextCrafter，一种新颖的多视觉文本渲染方法。TextCrafter采用渐进式策略将复杂的视觉文本分解为不同的组件，并确保文本内容与其视觉载体之间有强大的对齐。此外，它还结合了令牌焦点增强机制，以提高生成过程中视觉文本的突出性。

**Result:** TextCrafter有效解决了CVTG任务中的关键挑战，如文本混淆、遗漏和模糊。此外，本文提出了一个新的基准数据集CVTG-2K，用于严格评估生成模型在CVTG任务上的性能。大量的实验表明，TextCrafter超越了最先进的方法。

**Conclusion:** TextCrafter通过其创新的渐进式策略和令牌焦点增强机制，成功解决了复杂视觉文本生成中的关键问题，并在新提出的CVTG-2K数据集上表现出卓越的性能，超越了现有技术水平。

> **ai_Abstract:** 本文针对复杂视觉文本生成（CVTG）中图像生成模型存在的文本扭曲、模糊和缺失问题，提出了一种名为TextCrafter的新型多视觉文本渲染方法。TextCrafter采用渐进式策略分解复杂文本并确保文本与视觉载体的对齐，同时引入令牌焦点增强机制以提高文本突出性。该方法有效解决了CVTG中的文本混淆、遗漏和模糊等挑战。此外，本文还提出了一个新的基准数据集CVTG-2K。实验结果表明，TextCrafter的性能优于现有最先进的方法。

> **摘要翻译:** 本文探讨了复杂视觉文本生成（CVTG）任务，该任务的重点是在视觉图像内不同区域生成复杂的文本内容。在CVTG中，图像生成模型经常渲染出扭曲和模糊的视觉文本或缺少一些视觉文本。为了解决这些挑战，我们提出了TextCrafter，一种新颖的多视觉文本渲染方法。TextCrafter采用渐进式策略将复杂的视觉文本分解为不同的组件，同时确保文本内容与其视觉载体之间有强大的对齐。此外，它还结合了令牌焦点增强机制，以提高生成过程中视觉文本的突出性。TextCrafter有效解决了CVTG任务中的关键挑战，如文本混淆、遗漏和模糊。此外，我们提出了一个新的基准数据集CVTG-2K，用于严格评估生成模型在CVTG任务上的性能。大量的实验表明，我们的方法超越了最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [517] [Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics](https://arxiv.org/abs/2507.18015)
> *Celeb-DF++: 用于可泛化取证的大规模挑战性视频深度伪造基准*

*Yuezun Li, Delong Zhu, Xinjie Cui, Siwei Lyu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 深度伪造, 可泛化取证, 数据集, Celeb-DF++, 视频伪造

**Comment:** https://github.com/OUC-VAS/Celeb-DF-PP

> **TL;DR:** 本文介绍了Celeb-DF++，一个大规模且多样化的视频深度伪造数据集，旨在促进可泛化深度伪造检测技术的发展，并揭示现有方法的局限性。

**AI_Comments:** 本文的主要创新在于构建了一个大规模且高度多样化的深度伪造数据集Celeb-DF++，它特别关注“可泛化取证”这一关键挑战。通过包含多种伪造方法和场景，该数据集填补了现有数据集在伪造多样性方面的不足，为开发更鲁棒、更具泛化能力的深度伪造检测技术提供了重要的基准。其重要性在于，它不仅提供了用于训练和测试的数据，还通过评估协议揭示了当前检测方法的局限性，指明了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** AI技术的快速发展导致在线深度伪造视频种类激增，对“可泛化取证”（即使用单一模型检测各种未见过的深度伪造类型）提出了紧迫挑战。现有数据集虽然规模大，但伪造类型有限，不足以开发可泛化检测方法。

**Method:** 作者在Celeb-DF数据集的基础上，构建了Celeb-DF++，一个大规模且具有挑战性的视频深度伪造基准。该数据集涵盖了换脸（FS）、面部重演（FR）和说话人脸（TF）三种常见伪造场景，使用22种不同的深度伪造方法生成了大量高质量的伪造视频。此外，还引入了评估协议，用于衡量24种最新检测方法的泛化能力。

**Result:** Celeb-DF++数据集的难度很高，现有检测方法在面对其提出的可泛化取证挑战时表现出局限性。

**Conclusion:** Celeb-DF++是一个大规模、多样化的深度伪造基准，旨在推动可泛化深度伪造检测技术的发展，并揭示了现有检测方法的不足之处，为未来研究提供了挑战性的平台。

> **ai_Abstract:** 本文介绍了Celeb-DF++，一个专为解决深度伪造可泛化取证挑战而设计的大规模视频深度伪造基准数据集。该数据集扩展了Celeb-DF，包含了换脸、面部重演和说话人脸三种常见伪造场景，并利用22种不同的深度伪造方法生成了大量多样化的高质量伪造视频。研究者还提出了评估协议，用于测试现有24种检测方法的泛化能力，结果表明现有方法存在局限性，并强调了新数据集的挑战性。

> **摘要翻译:** AI技术的快速发展显著增加了在线传播的深度伪造视频的多样性，对“可泛化取证”（即使用单一模型检测各种未见过的深度伪造类型）构成了紧迫的挑战。应对这一挑战需要不仅规模大而且伪造多样性丰富的S数据集。然而，大多数现有数据集，尽管规模庞大，但仅包含有限种类的伪造类型，使其不足以开发可泛化检测方法。因此，我们以早期的Celeb-DF数据集为基础，引入了Celeb-DF++，一个新的大规模且具有挑战性的视频深度伪造基准，专门用于解决可泛化取证的挑战。Celeb-DF++涵盖了三种常见的伪造场景：换脸（FS）、面部重演（FR）和说话人脸（TF）。每个场景都包含大量高质量的伪造视频，这些视频是使用总共22种各种最新的深度伪造方法生成的。这些方法在架构、生成流程和目标面部区域方面各不相同，涵盖了野外最普遍的深度伪造案例。我们还引入了评估协议，用于衡量24种最新检测方法的泛化能力，突出了现有检测方法的局限性以及我们新数据集的难度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [524] [MatSSL: Robust Self-Supervised Representation Learning for Metallographic Image Segmentation](https://arxiv.org/abs/2507.18184)
> *MatSSL：用于金相图像分割的鲁棒自监督表示学习*

*Hoang Hai Nam Nguyen, Phan Nguyen Duc Hieu, Ho Won Lee* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 金相图像分割, 门控特征融合, 小样本学习, 表示学习

**Comment:** 

> **TL;DR:** MatSSL是一种新的自监督学习架构，通过门控特征融合，在少量未标记数据上实现金相图像分割的鲁棒表示学习，并显著优于现有方法。

**AI_Comments:** MatSSL的创新之处在于其采用门控特征融合的SSL架构，使其能够在小规模未标记数据集上进行有效学习，这对于数据标注成本高昂的金相领域具有重要意义。它成功解决了现有方法对大量标记数据或大规模未标记数据的依赖问题，并展示了在特定领域适应性的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的金属材料显微图像分析依赖于监督方法，这些方法需要为每个新数据集重新训练，并且在只有少量标记样本时表现不一致。虽然自监督学习（SSL）通过利用未标记数据提供了一种有前景的替代方案，但大多数现有方法仍然依赖于大规模数据集才能有效。MatSSL旨在克服这一局限性。

**Method:** MatSSL是一种流线型的自监督学习（SSL）架构，在骨干网络的每个阶段采用门控特征融合（Gated Feature Fusion）来有效整合多级表示。该方法首先在小规模、未标记的数据集上进行自监督预训练，然后对模型在多个基准数据集上进行微调。

**Result:** MatSSL分割模型在MetalDAM数据集上实现了69.13%的mIoU，优于ImageNet预训练编码器实现的66.73%。在环境屏障涂层（EBC）基准数据集上，与使用MicroNet预训练的模型相比，MatSSL在平均mIoU上持续提升了近40%。

**Conclusion:** MatSSL表明，它能够仅使用少量未标记数据有效适应金相领域，同时保留从大规模自然图像预训练中学习到的丰富且可迁移的特征。

> **ai_Abstract:** MatSSL提出了一种新的自监督学习（SSL）架构，通过在骨干网络中引入门控特征融合，解决了金相图像分割中现有监督方法对大量标记数据依赖以及现有SSL方法对大规模数据集需求的问题。该模型通过在少量未标记数据上进行预训练，并在多个基准数据集上进行微调，显著提升了分割性能，特别是在MetalDAM和EBC数据集上，证明了其在金相领域利用有限未标记数据进行有效适应和表示学习的能力。

> **摘要翻译:** MatSSL是一种流线型的自监督学习（SSL）架构，在骨干网络的每个阶段采用门控特征融合来有效整合多级表示。当前的金属材料显微图像分析依赖于监督方法，这些方法需要为每个新数据集重新训练，并且在只有少量标记样本时表现不一致。虽然SSL通过利用未标记数据提供了一种有前景的替代方案，但大多数现有方法仍然依赖于大规模数据集才能有效。MatSSL旨在克服这一局限性。我们首先在小规模、未标记的数据集上进行自监督预训练，然后对模型在多个基准数据集上进行微调。由此产生的分割模型在MetalDAM数据集上实现了69.13%的mIoU，优于ImageNet预训练编码器实现的66.73%，并且与使用MicroNet预训练的模型相比，在环境屏障涂层（EBC）基准数据集上的平均mIoU持续提升了近40%。这表明MatSSL能够仅使用少量未标记数据有效适应金相领域，同时保留从大规模自然图像预训练中学习到的丰富且可迁移的特征。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [526] [SyncMapV2: Robust and Adaptive Unsupervised Segmentation](https://arxiv.org/abs/2506.16297)
> *SyncMapV2：鲁棒自适应无监督分割*

*Heng Zhang, Zikang Wan, Danilo Vasconcellos Vargas* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 无监督分割, 鲁棒性, 在线适应, 自组织动力学, 随机网络

**Comment:** 

> **TL;DR:** SyncMapV2 是一种新的无监督分割算法，在不进行鲁棒训练的情况下，在数字损坏下表现出最先进的鲁棒性，并且能够在线适应新输入。

**AI_Comments:** SyncMapV2 的创新之处在于其无需显式鲁棒训练即可实现卓越鲁棒性的无监督分割，以及其在线适应新输入的能力，这显著区别于传统需要重新初始化的方法。这为开发更接近人类视觉的鲁棒自适应AI系统开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI算法在噪声增加时难以保持无监督分割的准确性，而人类视觉在此方面表现出色且鲁棒。

**Method:** SyncMapV2 基于自组织动力学方程与随机网络概念相结合的学习范式，无需鲁棒训练、监督或损失函数。它能够在线适应新输入，而非每次重新初始化。

**Result:** SyncMapV2 在数字损坏下mIoU仅下降0.01%，而SOTA方法下降23.8%。在噪声、天气和模糊等各种损坏类型下，其性能下降远小于SOTA方法（例如，噪声：7.3% vs. 37.7%）。在适应性测试中，性能退化接近零。

**Conclusion:** SyncMapV2 首次实现了无监督分割的最先进鲁棒性，并能在线适应输入，预示着未来鲁棒自适应智能的新发展。

> **ai_Abstract:** SyncMapV2 是一种新颖的无监督分割算法，旨在解决现有AI在噪声环境下分割准确性下降的问题。它在不依赖传统鲁棒训练、监督或损失函数的情况下，通过结合自组织动力学方程和随机网络概念，实现了最先进的鲁棒性。实验表明，SyncMapV2 在数字损坏和多种环境干扰下，性能下降远小于现有SOTA方法，并且具备在线适应新输入的能力，模仿了人类视觉的持续适应性。

> **摘要翻译:** 人类视觉在无需明确训练的情况下擅长分割视觉线索，即使噪声严重程度增加也能保持卓越的鲁棒性。相比之下，现有AI算法在类似条件下难以保持准确性。本文提出了 SyncMapV2，首次解决了无监督分割问题，并实现了最先进的鲁棒性。在数字损坏下，SyncMapV2 的mIoU仅下降0.01%，而SOTA方法则下降23.8%。这种卓越的性能延伸到各种类型的损坏：噪声（7.3% 对比 37.7%）、天气（7.5% 对比 33.8%）和模糊（7.0% 对比 29.5%）。值得注意的是，SyncMapV2 在没有任何鲁棒训练、监督或损失函数的情况下完成了这一点。它基于一种学习范式，该范式结合了自组织动力学方程和随机网络的概念。此外，与需要为每个新输入重新初始化的传统方法不同，SyncMapV2 能够在线自适应，模仿人类视觉的持续适应性。因此，我们超越了准确和鲁棒的结果，提出了第一个能够在线完成上述所有工作，并适应输入而非重新初始化的算法。在适应性测试中，SyncMapV2 表现出接近零的性能退化，这激励并促进了未来新一代鲁棒自适应智能的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [531] [VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding](https://arxiv.org/abs/2507.18552)
> *VideoMind：一个用于深度认知视频理解的意图接地全模态视频数据集*

*Baoyao Yang, Wanyun Li, Dixin Chen, Junxiang Chen, Wenbin Yao, Haifeng Lin* | **Category: cs.CV, cs.AI, 68T45, 68T50, 68U35,, I.4.8; I.2.7; I.2.10; H.5.1** | **Updated: 2025-07-24**

**Keywords:** 视频数据集, 意图接地, 深度认知, 全模态, 思维链

**Comment:** 7 pages; 14 figures

> **TL;DR:** 引入VideoMind，一个包含意图表达的全模态视频数据集，通过COT方法生成深度认知描述，并提供金标准基准用于深度视频理解。

**AI_Comments:** VideoMind数据集的创新之处在于其引入了“意图”这一深度认知层面的描述，并通过Chain-of-Thought方法生成，这对于推动需要复杂推理的视频理解任务（如情感和意图识别）至关重要。与现有数据集相比，它提供了更深层次的语义信息，有望促进多模态模型在复杂视频理解方面的进步。其公开可用性也极大地促进了研究社区的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据集缺乏深度认知视频理解所需的意图表达，而这些意图需要上下文整合且不直接可观察。本研究旨在通过提供意图接地的全模态视频数据集来促进深度视频内容认知和增强多模态特征表示。

**Method:** 论文介绍了VideoMind数据集，包含103K视频样本（3K用于测试），每个样本配有音频和详细文本描述。描述分为事实、抽象和意图三个层次。意图表达通过Chain-of-Thought (COT) 方法，利用mLLM进行逐步推理生成。每个描述包含主体、地点、时间、事件、动作和意图的标注。论文还建立了包含3,000个手动验证样本的金标准基准，并设计了混合认知检索实验，使用多级检索指标评估深度视频理解。

**Result:** VideoMind数据集已公开发布在GitHub、HuggingFace和OpenDataLab。论文发布了InternVideo、VAST、UMT-L等模型的评估结果，并表明VideoMind可作为细粒度跨模态对齐的强大基准。

**Conclusion:** VideoMind数据集为细粒度跨模态对齐提供了一个强大的基准，并推动了需要深度视频理解的领域发展，例如情感和意图识别。

> **ai_Abstract:** 本文推出了VideoMind，一个用于深度视频理解的全模态视频数据集。该数据集包含103K个视频样本，每个样本都配有音频和多层次（事实、抽象、意图）的详细文本描述，特别是通过思维链（COT）方法生成的难以直接观察的“意图”表达。VideoMind通过提供意图接地信息，显著区别于现有数据集，旨在促进深度视频内容认知和多模态特征学习。论文还建立了一个金标准基准，并进行了混合认知检索实验来评估模型，其结果已公开。VideoMind被定位为细粒度跨模态对齐和深度视频理解（如情感和意图识别）领域的强大基准。

> **摘要翻译:** 这篇论文介绍了VideoMind，一个以视频为中心的全模态数据集，专为深度视频内容认知和增强多模态特征表示而设计。该数据集包含103K个视频样本（其中3K用于测试），每个样本都配有音频和系统详细的文本描述。具体来说，每个视频及其音频都通过三个层次（事实、抽象和意图）进行描述，从表面到深度逐步深入。它包含超过2200万个单词，平均每个样本约225个单词。VideoMind与现有数据集的关键区别在于它提供了意图表达，这些意图需要整合整个视频的上下文，并且不能直接观察到。这些深度认知表达是使用思维链（COT）方法生成的，通过逐步推理提示mLLM。每个描述都包含主体、地点、时间、事件、动作和意图的标注，支持下游识别任务。至关重要的是，我们建立了一个包含3,000个手动验证样本的金标准基准，用于评估深度认知视频理解。我们设计了混合认知检索实验，通过多级检索指标进行评分，以适当评估深度视频理解。模型的评估结果（例如，InternVideo、VAST、UMT-L）已发布。VideoMind可作为细粒度跨模态对齐的强大基准，并推动了需要深度视频理解的领域发展，例如情感和意图识别。数据可在GitHub、HuggingFace和OpenDataLab上公开获取，网址为https://github.com/cdx-cindy/VideoMind。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [539] [NSegment : Label-specific Deformations for Remote Sensing Image Segmentation](https://arxiv.org/abs/2504.19634)
> *NSegment：遥感图像分割的标签特定形变*

*Yechan Kim, DongHo Yoon, SooYeon Kim, Moongu Jeon* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 遥感图像分割, 数据增强, 标签形变, 标注错误, NSegment

**Comment:** The paper is being revised substantially and will be resubmitted.

> **TL;DR:** NSegment是一种简单有效的数据增强方法，通过对遥感图像分割的标签进行弹性形变，以减轻标注错误并提高模型性能。

**AI_Comments:** NSegment的创新点在于其“标签特定”的弹性形变，这与传统的数据增强方法不同，后者通常作用于原始图像。通过仅在标签上引入受控的变形噪声，它直接模拟了标注中固有的不精确性，而避免了改变图像本身的语义内容。这种方法的简单性和有效性使其在处理遥感图像标注质量问题方面具有重要意义，尤其是在数据标注成本高昂的领域。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像分割数据集中由于模糊的类别边界、混合像素、阴影、复杂地形特征和主观标注偏差，常存在隐性和细微的标注错误。此外，高昂的图像采集和标注成本导致标注数据稀缺，使得训练鲁棒模型变得复杂。现有解决方案如标签选择或噪声校正会增加训练时间和实现复杂性。

**Method:** 本文提出了NSegment，一种简单而有效的数据增强解决方案。与传统方法不同，NSegment仅对分割标签应用弹性变换，并在每个训练周期中针对每个样本改变形变强度，以解决标注不一致性。

**Result:** 实验结果表明，NSegment方法提高了各种最先进模型在遥感图像分割上的性能。

**Conclusion:** NSegment作为一种简单有效的数据增强方案，能够有效缓解遥感图像分割中存在的标注错误问题，并显著提升现有模型的性能。

> **ai_Abstract:** NSegment是一种针对遥感图像分割的数据增强方法，旨在解决因模糊边界、混合像素、阴影和主观偏差导致的标注错误及数据稀缺问题。该方法独特之处在于，它仅对分割标签应用弹性形变，并动态调整形变强度，以适应标注的不一致性，从而避免了传统噪声鲁棒方法增加的训练时间和复杂性。实验证明，NSegment能有效提升现有最先进遥感图像分割模型的性能。

> **摘要翻译:** 遥感（RS）图像分割数据集中的标注错误由于模糊的类别边界、混合像素、阴影、复杂地形特征和主观标注偏差，通常是隐性和细微的。此外，由于高昂的图像采集和标注成本，标注的遥感数据稀缺性使得训练对噪声鲁棒的模型变得复杂。虽然标签选择或噪声校正等复杂机制可能解决这个问题，但它们往往会增加训练时间并增加实现复杂性。在这封信中，我们提出了NSegment——一个简单而有效的数据增强解决方案来缓解这个问题。与传统方法不同，它仅对分割标签应用弹性变换，并在每个训练周期中针对每个样本改变形变强度，以解决标注不一致性。实验结果表明，我们的方法提高了各种最先进模型在遥感图像分割上的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [543] [Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows](https://arxiv.org/abs/2507.18405)
> *Iwin Transformer：使用交错窗口的分层视觉Transformer*

*Simin Huo, Ning Li* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** Iwin Transformer, 视觉Transformer, 分层, 交错窗口注意力, 深度可分离卷积

**Comment:** 14 pages, 10 figures, Submitted to IEEE Transactions on Pattern
  Analysis and Machine Intelligence

> **TL;DR:** Iwin Transformer是一种新型的无位置嵌入分层视觉Transformer，通过交错窗口注意力与深度可分离卷积结合，实现了从低分辨率到高分辨率的直接微调，并在多项视觉任务上表现出色。

**AI_Comments:** Iwin Transformer的创新之处在于其独特的交错窗口注意力与深度可分离卷积的结合，这使得它能够在单个模块内实现全局信息交换，从而提升了效率并克服了现有Transformer模型的局限。其无位置嵌入和直接微调的能力也增加了其实用性。该研究为未来的视觉Transformer设计和应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服Swin Transformer需要两个连续块才能近似全局注意力的局限性，并实现单模块内的全局信息交换。

**Method:** 引入了Iwin Transformer，一种新型的无位置嵌入分层视觉Transformer。它通过创新的交错窗口注意力连接远距离token，并应用深度可分离卷积连接相邻token，从而在单个模块内实现全局信息交换。该方法支持从低分辨率到高分辨率的直接微调。

**Result:** Iwin Transformer在视觉基准测试中表现出强大的竞争力，包括在ImageNet-1K上达到87.4%的top-1图像分类准确率，并在语义分割和视频动作识别任务上也表现良好。此外，Iwin的核心组件作为独立模块，可以无缝替代类别条件图像生成中的自注意力模块，并验证了其有效性。

**Conclusion:** Iwin Transformer通过结合交错窗口注意力和深度可分离卷积，有效克服了现有视觉Transformer的局限性，实现了高效的全局信息交换，并在多个视觉任务上取得了SOTA性能。其概念和方法有望启发未来研究，如视频生成中的Iwin 3D注意力。

> **ai_Abstract:** Iwin Transformer是一种新颖的无位置嵌入分层视觉Transformer，它结合了交错窗口注意力与深度可分离卷积，能够在单个模块内实现高效的全局信息交换，解决了Swin Transformer在全局注意力方面的局限。该模型支持从低分辨率到高分辨率的直接微调，并在图像分类、语义分割和视频动作识别等多个视觉任务上取得了优异的性能。其核心组件还可作为独立模块应用于图像生成。

> **摘要翻译:** 我们引入了Iwin Transformer，这是一种新型的无位置嵌入分层视觉Transformer，它可以通过创新的交错窗口注意力和深度可分离卷积的协作，直接从低分辨率微调到高分辨率。这种方法使用注意力连接远距离token，并应用卷积连接相邻token，从而在单个模块内实现全局信息交换，克服了Swin Transformer需要两个连续块才能近似全局注意力的局限性。在视觉基准测试上的大量实验表明，Iwin Transformer在图像分类（ImageNet-1K上达到87.4%的top-1准确率）、语义分割和视频动作识别等任务中表现出强大的竞争力。我们还验证了Iwin中核心组件作为独立模块的有效性，它可以无缝替代类别条件图像生成中的自注意力模块。Iwin Transformer引入的概念和方法有潜力启发未来的研究，例如视频生成中的Iwin 3D注意力。代码和模型可在https://github.com/cominder/Iwin-Transformer获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [544] [A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration](https://arxiv.org/abs/2507.18551)
> *3D跨模态关键点描述子用于MR-US匹配与配准*

*Daniil Morozov, Reuben Dorent, Nazim Haouchine* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D跨模态, 关键点描述子, MR-US配准, 图像匹配, 合成数据

**Comment:** Under review

> **TL;DR:** 本文提出了一种3D跨模态关键点描述子，通过合成数据和对比学习实现鲁棒的MRI-US图像匹配与配准，性能超越现有技术，且无需手动初始化。

**AI_Comments:** 该论文通过引入“合成-匹配”的患者特异性方法和监督对比学习，有效地解决了MRI与iUS之间因模态差异导致的配准难题，展现了创新性。其提出的3D跨模态关键点描述子在鲁棒性（对抗伪影和视野变化）和自动化（无需手动初始化）方面具有显著优势，对临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 术中实时超声（iUS）与术前磁共振成像（MRI）之间的配准，因模态特异性（外观、分辨率、视野）的显著差异，仍是一个未解决的问题。

**Method:** 本文提出了一种新颖的3D跨模态关键点描述子，用于MRI-iUS的匹配与配准。该方法采用患者特异性的“合成-匹配”策略，从术前MRI生成合成iUS体积，从而实现监督对比训练以学习共享的描述子空间。接着，采用概率关键点检测策略识别解剖学上显著且模态一致的位置。在训练过程中，使用基于课程的三元组损失和动态困难负样本挖掘，以学习对iUS伪影（如散斑噪声和有限覆盖）鲁棒且旋转不变的描述子。在推理阶段，该方法在MR和真实iUS图像中检测关键点并识别稀疏匹配，进而用于执行刚性配准。

**Result:** 该方法在ReMIND数据集上进行了评估，实验结果表明，在11名患者中，该方法在关键点匹配方面优于最先进的方法，平均精度达到69.8%。在ReMIND2Reg基准测试中，图像配准的平均目标配准误差（TRE）为2.39毫米。

**Conclusion:** 该框架具有可解释性，无需手动初始化，并且对iUS视野变化表现出鲁棒性，在MRI-iUS配准方面表现出色。

> **ai_Abstract:** 本文提出了一种新颖的3D跨模态关键点描述子，旨在解决术中实时超声（iUS）与术前磁共振成像（MRI）之间的配准难题。该方法通过从MRI合成iUS体积进行监督对比学习，以在共享描述子空间中学习关键点。结合概率关键点检测和鲁棒的训练策略（如基于课程的三元组损失和动态困难负样本挖掘），该描述子能够克服iUS伪影和视野限制，实现MR与iUS图像间的稀疏匹配和刚性配准。实验结果表明，该方法在关键点匹配精度和配准误差方面均优于或媲美现有技术，且具有可解释性、无需手动初始化和对视野变化鲁棒的优点。

> **摘要翻译:** 术中实时超声（iUS）与术前磁共振成像（MRI）的配准因外观、分辨率和视野等模态特异性差异巨大，仍然是一个未解决的问题。为解决此问题，我们提出了一种新颖的3D跨模态关键点描述子，用于MRI-iUS的匹配与配准。我们的方法采用患者特异性的“合成-匹配”策略，从术前MRI生成合成iUS体积。这使得监督对比训练能够学习一个共享的描述子空间。然后，采用概率关键点检测策略来识别解剖学上显著且模态一致的位置。在训练期间，使用基于课程的三元组损失和动态困难负样本挖掘来学习以下描述子：i) 对iUS伪影（如散斑噪声和有限覆盖）具有鲁棒性，ii) 旋转不变。在推理时，该方法在MR和真实iUS图像中检测关键点并识别稀疏匹配，然后用于执行刚性配准。我们的方法使用来自ReMIND数据集的3D MRI-iUS对进行评估。实验表明，我们的方法在11名患者中优于最先进的关键点匹配方法，平均精度为69.8%。对于图像配准，我们的方法在ReMIND2Reg基准测试中实现了2.39毫米的竞争性平均目标配准误差。与现有iUS-MR配准方法相比，我们的框架具有可解释性，无需手动初始化，并且对iUS视野变化表现出鲁棒性。代码可在https://github.com/morozovdd/CrossKEY获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [553] [Scaling RL to Long Videos](https://arxiv.org/abs/2507.07966)
> *将强化学习扩展到长视频*

*Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 长视频, 视觉-语言模型, 推理, 训练框架

**Comment:** Code at https://github.com/NVlabs/Long-RL and model at
  https://huggingface.co/Efficient-Large-Model/LongVILA-R1-7B

> **TL;DR:** 该研究提出了一个用于将强化学习扩展到长视频推理的全栈框架，包括大规模数据集、两阶段训练流程和高效的训练基础设施，显著提升了模型性能和训练速度。

**AI_Comments:** 这篇论文的创新点在于提出了一个将强化学习应用于长视频推理的全栈框架，特别是在数据集构建（LongVideo-Reason）、两阶段训练策略以及高效的训练基础设施（MR-SP，尤其是其序列并行和缓存视频嵌入技术）方面。其重要性体现在有效解决了视觉-语言模型在处理长视频时面临的独特挑战，显著提升了模型性能和训练效率，并且开放了训练系统，有望推动相关领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 解决将视觉-语言模型（VLM）中的推理能力通过强化学习扩展到长视频时面临的独特挑战。

**Method:** 提出了一个全栈框架来扩展视觉-语言模型（VLM）在长视频中的推理能力，该框架利用强化学习。它整合了三个关键组件：1）一个包含104K长视频问答对的大规模数据集LongVideo-Reason；2）一个两阶段训练流程，通过链式思考监督微调（CoT-SFT）和强化学习（RL）扩展VLM；3）一个名为Multi-modal Reinforcement Sequence Parallelism (MR-SP) 的长视频RL训练基础设施，该设施结合了序列并行和基于vLLM的引擎，并利用缓存视频嵌入以实现高效的rollout和预填充。

**Result:** LongVILA-R1-7B在VideoMME基准测试中取得了显著性能，无字幕和有字幕的准确率分别达到65.0%和70.7%。它在多个基准测试中持续优于LongVILA-R1，并随着输入视频帧数的增加显示出稳定的性能提升。此外，MR-SP系统在长视频强化学习训练中实现了高达2.1倍的加速。研究还发布了支持多种模态和模型的训练系统，可在单个A100节点上支持长达一小时的视频RL训练。

**Conclusion:** 该研究成功地将强化学习应用于长视频推理，并通过创新的数据集、两阶段训练流程和高效的训练基础设施，显著提升了视觉-语言模型在长视频任务上的性能和训练效率。

> **ai_Abstract:** 本文提出了一个全栈框架，旨在通过强化学习将视觉-语言模型（VLM）的推理能力扩展到长视频。该框架包含三个核心要素：一个大规模的LongVideo-Reason数据集、一个结合链式思考监督微调和强化学习的两阶段训练流程，以及一个名为Multi-modal Reinforcement Sequence Parallelism (MR-SP) 的高效训练基础设施。实验结果表明，该方法显著提升了长视频理解任务的性能，并在训练效率上实现了高达2.1倍的加速。该研究还发布了其训练系统，以支持多模态和多种模型的强化学习训练。

> **摘要翻译:** 我们引入了一个全栈框架，利用强化学习将视觉-语言模型（VLM）中的推理能力扩展到长视频。我们通过整合三个关键组件来应对长视频推理的独特挑战：(1) 一个大规模数据集LongVideo-Reason，包含104K高质量的长视频问答对及其在体育、游戏和vlog等不同领域的推理标注；(2) 一个两阶段训练流程，通过链式思考监督微调（CoT-SFT）和强化学习（RL）来扩展VLM；以及(3) 一个用于长视频RL的训练基础设施，名为多模态强化序列并行（MR-SP），它结合了序列并行和专为长视频定制的基于vLLM的引擎，并使用缓存的视频嵌入来实现高效的rollout和预填充。在我们的实验中，LongVILA-R1-7B在视频基准测试中取得了强大的性能，在VideoMME上无字幕和有字幕的准确率分别达到65.0%和70.7%，并在多个基准测试中持续优于LongVILA-R1。此外，随着输入视频帧数的增加，LongVILA-R1的性能表现出稳定的提升。值得注意的是，我们的MR-SP系统在长视频RL训练中实现了高达2.1倍的加速。此外，我们发布了我们的训练系统供公众使用，该系统支持在各种模态（视频、文本和音频）、各种模型（VILA和Qwen系列）甚至图像和视频生成模型上进行RL训练。在单个A100节点（8个GPU）上，它支持对长达一小时的视频（例如3,600帧/约256k token）进行RL训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [MC3D-AD: A Unified Geometry-aware Reconstruction Model for Multi-category 3D Anomaly Detection](https://arxiv.org/abs/2505.01969)
> *MC3D-AD: 一种用于多类别三维异常检测的统一几何感知重建模型*

*Jiayi Cheng, Can Gao, Jie Zhou, Jiajun Wen, Tao Dai, Jinbao Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D异常检测, 多类别, 几何感知, 重建模型, 统一模型

**Comment:** 7 pages of main text, 3 pages of appendix, accepted to IJCAI 2025

> **TL;DR:** MC3D-AD提出了一种统一的几何感知重建模型，用于多类别3D异常检测，通过结合局部和全局几何信息，显著优于现有的单类别方法。

**AI_Comments:** 该论文的创新点在于提出了一个统一的几何感知重建模型MC3D-AD，解决了多类别3D异常检测中为每个类别单独训练模型的痛点。其通过结合局部和全局几何信息，并引入自适应几何感知掩蔽注意力和全局查询解码器，提高了模型的泛化能力和检测性能。在工业质检等领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D异常检测方法通常需要为每个类别单独训练特定任务模型，导致成本高、效率低和泛化能力弱。

**Method:** 本文提出了一种名为MC3D-AD的统一模型，用于多类别3D异常检测。它通过以下方式利用局部和全局几何感知信息重建正常表示：1. 提出自适应几何感知掩蔽注意力模块，提取几何变化信息以指导掩蔽注意力。2. 引入由改进的掩蔽注意力强化的局部几何感知编码器，编码组级特征tokens。3. 设计全局查询解码器，利用点云位置嵌入提高解码过程和重建能力。

**Result:** MC3D-AD在Real3D-AD和Anomaly-ShapeNet两个公开数据集上进行了评估，在对象级AUROC上分别比当前最先进的单类别方法提高了3.1%和9.3%。

**Conclusion:** MC3D-AD模型在多类别3D异常检测任务中表现出显著的优越性，能够有效利用局部和全局几何信息进行统一的正常表示重建，解决了现有方法的成本、效率和泛化问题。

> **ai_Abstract:** 本文提出了一种名为MC3D-AD的新型统一模型，用于多类别3D异常检测。该模型通过结合自适应几何感知掩蔽注意力、局部几何感知编码器和全局查询解码器，有效地利用局部和全局几何信息来重建不同类别的正常表示。实验结果表明，MC3D-AD在Real3D-AD和Anomaly-ShapeNet数据集上显著优于现有单类别方法，解决了传统方法成本高、效率低和泛化能力弱的问题。

> **摘要翻译:** 3D异常检测（AD）是控制制成品质量的一种很有前景的手段。然而，现有方法通常需要为每个类别独立地精心训练一个特定任务模型，导致成本高、效率低和泛化能力弱。因此，本文提出了一种新颖的统一模型，用于多类别3D异常检测（MC3D-AD），旨在利用局部和全局几何感知信息重建所有类别的正常表示。首先，为了学习不同类别的鲁棒和广义特征，我们提出了一种自适应几何感知掩蔽注意力模块，该模块提取几何变化信息以指导掩蔽注意力。然后，我们引入了一个由改进的掩蔽注意力强化的局部几何感知编码器，用于编码组级特征tokens。最后，我们设计了一个全局查询解码器，该解码器利用点云位置嵌入来改进解码过程和重建能力。这为AD任务带来了局部和全局几何感知重建的特征tokens。MC3D-AD在两个公开可用的Real3D-AD和Anomaly-ShapeNet数据集上进行了评估，并显示出对当前最先进的单类别方法的显著优越性，在Real3D-AD和Anomaly-ShapeNet上的对象级AUROC分别提高了3.1%和9.3%。代码可在https://github.com/iCAN-SZU/MC3D-AD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [565] [High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details](https://arxiv.org/abs/2507.18023)
> *高保真3D高斯修复：保持多视角一致性和真实感细节*

*Jun Zhou, Dinghao Li, Nannan Li, Mingjie Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D高斯泼溅, 3D修复, 多视角一致性, 场景重建, 真实感细节

**Comment:** 

> **TL;DR:** 提出了一种高保真3D高斯修复框架，通过掩码细化和不确定性引导优化，实现多视角一致的3D场景补全。

**AI_Comments:** 该论文通过将高斯泼溅技术与特定的细化和优化策略相结合，为3D场景修复提供了一种创新方法，直接解决了多视角一致性的关键问题。其对不规则结构和遮挡区域等实际挑战的关注，使其成为高保真3D内容创建领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管神经辐射场（NeRF）和3D高斯泼溅（3DGS）等技术在3D内容创建方面取得了显著进展，但由于3D结构固有的不规则性以及保持多视角一致性的关键需求，3D场景的修复仍然是一项具有挑战性的任务。

**Method:** 本文提出了一种新颖的3D高斯修复框架，利用稀疏修复视角重建完整的3D场景。该框架包含一个自动掩码细化过程（通过高斯场景滤波和反向投影）和一个区域不确定性引导优化策略（在训练期间评估多视角图像中每个区域的重要性）。

**Result:** 在不同数据集上进行的综合实验表明，所提出的方法在视觉质量和视角一致性方面均优于现有最先进的方法。

**Conclusion:** 该框架通过确保多视角一致性并增强真实感细节，有效解决了3D场景修复中的挑战，达到了最先进的性能。

> **ai_Abstract:** 本文提出了一种新颖的3D高斯修复框架，旨在重建完整的3D场景，同时保持多视角一致性和真实感细节。该框架通过自动掩码细化过程实现精确的遮挡区域定位和边界恢复，并通过不确定性引导优化策略缓解多视角不一致性并增强细节保真度，从而解决了3D修复的挑战。实验结果表明，其性能优于现有最先进的方法。

> **摘要翻译:** 最近在多视角3D重建和新视角合成方面的进展，特别是通过神经辐射场（NeRF）和3D高斯泼溅（3DGS），极大地提升了3D内容创建的保真度和效率。然而，由于3D结构固有的不规则性以及保持多视角一致性的关键需求，修复3D场景仍然是一项具有挑战性的任务。在这项工作中，我们提出了一种新颖的3D高斯修复框架，通过利用稀疏修复视角来重建完整的3D场景。我们的框架结合了自动掩码细化过程和区域不确定性引导优化。具体来说，我们通过一系列操作（包括高斯场景滤波和反向投影）细化修复掩码，从而更准确地定位被遮挡区域并恢复逼真的边界。此外，我们的不确定性引导的细粒度优化策略在训练期间估计多视角图像中每个区域的重要性，从而缓解多视角不一致性并增强修复结果中精细细节的保真度。在不同数据集上进行的综合实验表明，我们的方法在视觉质量和视角一致性方面均优于现有的最先进方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [577] [TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance](https://arxiv.org/abs/2507.18192)
> *TeEFusion: 融合文本嵌入以蒸馏无分类器指导*

*Minghao Fu, Guo-Hua Wang, Xiaohao Chen, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 文本到图像合成, 无分类器指导, 蒸馏, 文本嵌入, 推理加速

**Comment:** Accepted by ICCV 2025. The code is publicly available at
  https://github.com/AIDC-AI/TeEFusion

> **TL;DR:** TeEFusion通过融合文本嵌入来蒸馏无分类器指导，显著加速文本到图像生成，同时保持图像质量。

**AI_Comments:** TeEFusion的创新之处在于其将CFG指导信息直接融入文本嵌入的策略，避免了额外的参数和前向传播，从而实现了高效的蒸馏。这种方法显著降低了文本到图像模型的推理成本，对于实际应用具有重要意义。在保持图像质量的同时实现6倍的速度提升，展现了其强大的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像合成中的无分类器指导（CFG）虽然能确保高质量生成，但其依赖两次前向传播，结合复杂的采样算法，导致推理成本过高。

**Method:** TeEFusion（文本嵌入融合）是一种新颖高效的蒸馏方法，通过线性操作简单融合条件和无条件文本嵌入，将指导幅度直接融入文本嵌入中，并蒸馏教师模型的复杂采样策略，无需额外参数。

**Result:** 在SD3等最先进模型上的广泛实验表明，TeEFusion使学生模型能够以更简单、更高效的采样策略，紧密模仿教师模型的性能。学生模型推理速度比教师模型快6倍，同时图像质量与教师模型的复杂采样方法相当。

**Conclusion:** TeEFusion通过融合文本嵌入来有效蒸馏无分类器指导和复杂采样策略，显著提高了文本到图像合成的推理效率，同时保持了生成质量。

> **ai_Abstract:** 本文提出了TeEFusion，一种高效的文本到图像合成蒸馏方法，旨在解决无分类器指导（CFG）和复杂采样策略导致的高推理成本问题。TeEFusion通过线性融合条件和无条件文本嵌入，直接将指导信息编码到文本嵌入中，并蒸馏教师模型的复杂采样过程。实验证明，TeEFusion使学生模型在保持图像质量的同时，推理速度比教师模型快6倍，显著提升了生成效率。

> **摘要翻译:** 文本到图像合成的最新进展在很大程度上得益于复杂的采样策略和无分类器指导（CFG），以确保高质量生成。然而，CFG对两次前向传播的依赖，特别是与复杂的采样算法结合时，导致了过高的推理成本。为了解决这个问题，我们引入了TeEFusion（文本嵌入融合），一种新颖高效的蒸馏方法，它将指导幅度直接融入文本嵌入中，并蒸馏教师模型复杂的采样策略。通过简单地使用线性操作融合条件和无条件文本嵌入，TeEFusion在不增加额外参数的情况下重建了所需的指导，同时使学生模型能够从教师模型通过其复杂的采样方法产生的输出中学习。在SD3等最先进模型上的广泛实验表明，我们的方法使学生模型能够以更简单、更高效的采样策略，紧密模仿教师模型的性能。因此，学生模型实现了比教师模型快6倍的推理速度，同时保持了与通过教师模型复杂采样方法获得的图像质量相当的水平。代码已在github.com/AIDC-AI/TeEFusion公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [586] [Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement](https://arxiv.org/abs/2507.18565)
> *基于深度学习的年龄估计和性别分类用于精准广告投放*

*Muhammad Imran Zaman, Nisar Ahmed* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 深度学习, 年龄估计, 性别分类, 卷积神经网络, 精准广告

**Comment:** 6

> **TL;DR:** 本文提出一种新颖的基于深度学习的方法，用于从面部图像中同时进行年龄和性别分类，以提高精准广告投放的有效性。

**AI_Comments:** 本文的创新点在于提出了一个能够同时进行年龄和性别分类的定制CNN架构，通过学习共享表示来提高性能，这优于许多独立处理这两个任务的现有方法。其重要性体现在为精准广告投放提供了更有效的人群识别工具。论文也坦诚地指出了在年轻个体年龄估计上的局限性，并提出了未来改进的方向，这增加了研究的实用性和可信度。

<details>
  <summary>Details</summary>

**Motivation:** 为提高精准广告投放活动的有效性，需要一种能够从面部图像中同时进行年龄和性别分类的方法。

**Method:** 本文提出了一种定制的卷积神经网络（CNN）架构，该架构针对年龄和性别分类任务进行了优化，并利用了面部特征中年龄和性别信息固有的相关性。模型在一个大型多样化的面部图像数据集上进行训练，该数据集经过精心预处理以确保对光照、姿势和图像质量变化的鲁棒性。

**Result:** 实验结果表明，性别分类准确率显著提高，达到95%，年龄估计的平均绝对误差为5.77年。研究还分析了不同年龄组的表现，并指出了在准确估计年轻个体年龄方面的挑战。

**Conclusion:** 本文提出的深度学习方法在年龄和性别分类方面表现出色，特别是在性别分类准确率上取得了显著提升。研究揭示了在年轻个体年龄估计方面存在的挑战，并强调了未来研究中针对性数据增强和模型改进的必要性。

> **ai_Abstract:** 本文提出了一种创新的深度学习方法，利用定制的卷积神经网络（CNN）架构，实现从面部图像中同时进行年龄和性别分类。该模型通过学习共享表示，在大型多样化数据集上进行训练，旨在提高精准广告投放的效率。实验结果显示，性别分类准确率达到95%，年龄估计平均绝对误差为5.77年。研究还深入分析了不同年龄组的表现，并指出了在年轻个体年龄估计方面的挑战，为未来的数据增强和模型优化提供了方向。

> **摘要翻译:** 本文提出了一种新颖的基于深度学习的方法，用于从面部图像中同时进行年龄和性别分类，旨在提高精准广告活动的有效性。我们提出了一种定制的卷积神经网络（CNN）架构，该架构针对这两个任务进行了优化，并利用了面部特征中年龄和性别信息固有的相关性。与现有方法通常独立处理这些任务不同，我们的模型学习共享表示，从而提高了性能。该网络在一个大型、多样化的面部图像数据集上进行训练，该数据集经过精心预处理，以确保对光照、姿势和图像质量变化的鲁棒性。我们的实验结果表明，性别分类准确率显著提高，达到95%，年龄估计的平均绝对误差为5.77年。重要的是，我们分析了不同年龄组的表现，识别出在准确估计年轻个体年龄方面存在的具体挑战。这项分析揭示了需要有针对性的数据增强和模型改进来解决这些偏差。此外，我们探讨了不同CNN架构和超参数设置对整体性能的影响，为未来的研究提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [587] [ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars](https://arxiv.org/abs/2505.10072)
> *ToonifyGB：基于StyleGAN的高斯混合形变用于3D风格化头部形象*

*Rui-Yang Ju, Sheng-Yen Huang, Yi-Ping Hung* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** ToonifyGB, StyleGAN, 高斯混合形变, 3D风格化头部形象, 实时重建

**Comment:** 

> **TL;DR:** ToonifyGB提出了一个两阶段框架，利用改进的StyleGAN和高斯混合形变，从单目视频高效生成具有任意表情的高质量3D风格化头部形象。

**AI_Comments:** ToonifyGB的创新之处在于其两阶段框架，巧妙地将改进的StyleGAN与高斯混合形变结合，实现了从单目视频到高质量3D风格化头部形象的生成。这种方法克服了传统StyleGAN在预处理上的限制，并通过生成稳定的风格化视频，提升了高斯混合形变捕捉细节的能力。其重要性在于为实时、可动画的风格化3D头像创建提供了一个高效且高质量的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了扩展Toonify方法，使其能够利用高斯混合形变合成多样化的风格化3D头部形象。

**Method:** 提出ToonifyGB，一个高效的两阶段框架。第一阶段（风格化视频生成）采用改进的StyleGAN从输入视频帧生成风格化视频，解决了传统StyleGAN对固定分辨率裁剪对齐面部的限制，提供更稳定的风格化视频。第二阶段（高斯混合形变合成）从生成的风格化视频中学习风格化的中性头部模型和一系列表情混合形变。通过结合中性头部模型和表情混合形变，ToonifyGB可以高效渲染具有任意表情的风格化形象。

**Result:** 在基准数据集上使用Arcane和Pixar两种代表性风格验证了ToonifyGB的有效性。

**Conclusion:** ToonifyGB能够有效地合成具有任意表情的高质量3D风格化头部形象。

> **ai_Abstract:** 本文提出了ToonifyGB，一个基于StyleGAN和高斯混合形变的双阶段框架，旨在从单目视频高效生成多样化且高质量的3D风格化头部形象。第一阶段通过改进的StyleGAN生成稳定的风格化视频，克服了传统StyleGAN的局限性。第二阶段则从风格化视频中学习中性头部模型和表情混合形变。该方法能够渲染具有任意表情的风格化形象，并在Arcane和Pixar等风格上验证了其有效性。

> **摘要翻译:** 3D高斯混合形变的引入使得从单目视频实时重建可动画头部形象成为可能。Toonify作为一种基于StyleGAN的方法，已被广泛用于面部图像风格化。为了扩展Toonify，使其能够利用高斯混合形变合成多样化的风格化3D头部形象，我们提出了一个高效的两阶段框架——ToonifyGB。在第一阶段（风格化视频生成）中，我们采用改进的StyleGAN从输入视频帧生成风格化视频，这克服了传统StyleGAN需要预处理裁剪固定分辨率对齐面部的限制。这个过程提供了更稳定的风格化视频，使得高斯混合形变能够更好地捕捉视频帧的高频细节，从而促进在下一阶段合成高质量动画。在第二阶段（高斯混合形变合成）中，我们的方法从生成的风格化视频中学习一个风格化的中性头部模型和一组表情混合形变。通过将中性头部模型与表情混合形变结合，ToonifyGB可以高效渲染具有任意表情的风格化形象。我们在基准数据集上使用两种代表性风格：奥术（Arcane）和皮克斯（Pixar）验证了ToonifyGB的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [591] [DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation](https://arxiv.org/abs/2507.18407)
> *DCFFSNet：用于医学图像分割的深度连接特征融合分离网络*

*Xun Ye, Ruixiang Tang, Mingda Zhang, Jianglong Qin* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学图像分割, 深度学习, 特征融合, 特征分离, 连通性

**Comment:** 16 pages , 11 figures

> **TL;DR:** DCFFSNet是一种新的医学图像分割网络，通过引入特征空间解耦策略解决现有方法中连接特征注入的问题，并在多个数据集上取得了SOTA性能，有效改善了分割碎片化和边缘平滑性。

**AI_Comments:** 这项工作创新性地提出了特征空间解耦策略，解决了现有方法中连接特征与其它特征耦合的问题，并实现了对不同特征强度的量化。DCFFSNet在多个基准数据集上取得了显著的性能提升，尤其是在解决分割碎片化和实现平滑边缘过渡方面，这对于提高医学图像分割的临床可用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的将连通性融入深度网络的医学图像分割方法，常将其强制作为附加特征模块注入，导致特征空间耦合且缺乏量化不同特征强度的标准化机制。

**Method:** 本文提出了DCFFSNet（深度连接特征融合分离网络），通过引入创新的特征空间解耦策略，量化连通性特征与其他特征之间的相对强度。该网络构建了一个深度连通特征融合分离架构，能够动态平衡多尺度特征表达。

**Result:** 在ISIC2018、DSB2018和MoNuSeg数据集上进行了实验。在ISIC2018上，DCFFSNet在Dice和IoU上分别优于CMUNet 1.3%和1.2%。在DSB2018上，Dice和IoU分别超过TransUNet 0.7%和0.9%。在MoNuSeg上，Dice和IoU分别超过CSCAUNet 0.8%和0.9%。结果表明DCFFSNet在所有指标上均优于现有主流方法。

**Conclusion:** DCFFSNet在所有指标上均超越了现有主流方法，有效解决了分割碎片化问题并实现了平滑的边缘过渡，显著增强了临床可用性。

> **ai_Abstract:** 本文提出了DCFFSNet（深度连接特征融合分离网络），旨在解决现有医学图像分割方法中连接特征强制注入导致特征空间耦合和强度量化不足的问题。DCFFSNet引入创新的特征空间解耦策略，能够量化并动态平衡连接特征与其他特征的表达。实验证明，该网络在ISIC2018、DSB2018和MoNuSeg等多个医学图像分割数据集上均超越了现有主流方法，有效改善了分割碎片化和边缘平滑性，显著提升了临床可用性。

> **摘要翻译:** 医学图像分割利用拓扑连通性理论来增强边缘精度和区域一致性。然而，现有整合连通性的深度网络通常将其强制注入作为附加特征模块，导致特征空间耦合，并且没有标准化的机制来量化不同特征的强度。为了解决这些问题，我们提出了DCFFSNet（深度连接特征融合分离网络）。它引入了一种创新的特征空间解耦策略。该策略量化了连通性特征与其他特征之间的相对强度。然后它构建了一个深度连通性特征融合分离架构。该架构动态平衡多尺度特征表达。实验在ISIC2018、DSB2018和MoNuSeg数据集上进行。在ISIC2018上，DCFFSNet在Dice和IoU上分别比次优模型（CMUNet）高出1.3%和1.2%。在DSB2018上，它在Dice和IoU上分别超过TransUNet 0.7%和0.9%。在MoNuSeg上，它在Dice和IoU上分别超过CSCAUNet 0.8%和0.9%。结果表明，DCFFSNet在所有指标上都超越了现有主流方法。它有效地解决了分割碎片化问题，并实现了平滑的边缘过渡。这显著增强了临床可用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [599] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
> *逆转-DPO：扩散模型精确高效的后训练*

*Zejian Li, Yize Li, Chenye Meng, Zhongni Liu, Yang Ling, Shengyuan Zhang, Guang Yang, Changyuan Yang, Zhiyuan Yang, Lingyun Sun* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 后训练, 对齐, 直接偏好优化, DDIM逆转

**Comment:** Accepted by ACM MM25

> **TL;DR:** Inversion-DPO提出了一种新的扩散模型后训练对齐框架，通过DDIM逆转重构DPO，无需奖励模型，显著提高了训练的精度和效率。

**AI_Comments:** Inversion-DPO的创新点在于其通过DDIM逆转重新设计了DPO，从而完全规避了奖励模型的训练，这在计算效率和训练精度上都是一个显著的进步。它为扩散模型的高效对齐提供了一个新颖且有前景的方向，特别是在处理复杂生成任务时。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型的对齐方法需要计算密集型的基础模型和奖励模型训练，导致计算开销大，并可能损害模型精度和训练效率。

**Method:** 本文提出了Inversion-DPO，一种通过DDIM逆转重构直接偏好优化（DPO）的新型对齐框架，从而规避了奖励建模。该方法通过从获胜和失败样本到噪声的确定性逆转进行棘手的后验采样，消除对辅助奖励模型或不准确近似的需求。作者将Inversion-DPO应用于文本到图像生成和组合图像生成任务，并为此任务构建了一个包含11,140张图像的配对数据集。

**Result:** Inversion-DPO在文本到图像生成和组合图像生成任务中，相比现有后训练方法实现了显著的性能提升，并且训练出的生成模型能够生成高保真、组合连贯的图像。

**Conclusion:** Inversion-DPO为扩散模型中高效、高精度的对齐探索了一条新途径，提升了其在复杂现实生成任务中的适用性。

> **ai_Abstract:** 本文提出了Inversion-DPO，一种针对扩散模型的新型对齐框架，旨在解决现有后训练方法计算成本高且可能损害精度的问题。Inversion-DPO通过使用DDIM逆转重构直接偏好优化（DPO），从而避免了对奖励模型的依赖。该方法通过对获胜和失败样本进行确定性逆转到噪声来推导新的后训练范式，显著提升了训练的精度和效率。实验证明，Inversion-DPO在文本到图像和组合图像生成任务中表现出显著的性能提升，能够生成高保真、组合连贯的图像。

> **摘要翻译:** 扩散模型（DMs）的最新进展得益于将模型进行后训练以更好地符合人类偏好的对齐方法。然而，这些方法通常需要计算密集型的基础模型和奖励模型训练，这不仅会产生大量的计算开销，还可能损害模型的准确性和训练效率。为了解决这些限制，我们提出了Inversion-DPO，一种新颖的对齐框架，通过使用DDIM逆转重构扩散模型的直接偏好优化（DPO），从而规避了奖励建模。我们的方法通过从获胜和失败样本到噪声的确定性逆转进行扩散-DPO中难以处理的后验采样，从而推导出一个新的后训练范式。这种范式消除了对辅助奖励模型或不准确近似的需求，显著提高了训练的精度和效率。我们将Inversion-DPO应用于文本到图像生成的基本任务和组合图像生成的挑战性任务。广泛的实验表明，与现有后训练方法相比，Inversion-DPO实现了显著的性能改进，并突出了训练后的生成模型生成高保真、组合连贯图像的能力。对于组合图像生成的后训练，我们策划了一个包含11,140张具有复杂结构注释和综合分数的配对数据集，旨在增强生成模型的组合能力。Inversion-DPO为扩散模型中高效、高精度的对齐探索了一条新途径，推动了其在复杂现实生成任务中的适用性。我们的代码可在https://github.com/MIGHTYEZ/Inversion-DPO获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [611] [FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities](https://arxiv.org/abs/2505.20147)
> *FUDOKI：基于离散流的统一理解与生成，通过动能最优速度实现*

*Jin Wang, Yao Lai, Aoxue Li, Shifeng Zhang, Jiacheng Sun, Ning Kang, Chengyue Wu, Zhenguo Li, Ping Luo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 离散流匹配, 多模态模型, 统一理解与生成, 动能最优速度, 自回归替代

**Comment:** 37 pages, 12 figures

> **TL;DR:** FUDOKI是一种基于离散流匹配的多模态模型，克服了自回归MLLM的局限性，在视觉理解和图像生成任务上表现与现有SOTA模型相当。

**AI_Comments:** 这篇论文的创新点在于提出了FUDOKI，一个基于离散流匹配的统一多模态模型，成功地挑战并替代了当前主流的自回归（AR）架构在多模态理解和生成中的主导地位。其引入的动能最优速度、迭代细化和双向上下文集成机制显著提升了模型的灵活性和性能。此外，从预训练AR模型进行初始化的策略有效降低了训练成本，使其具有实际应用价值。FUDOKI的出现为下一代多模态模型的开发提供了新的范式和方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型（MLLMs）主要依赖自回归（AR）架构，这限制了其未来发展，例如图像生成中的光栅扫描顺序和因果上下文建模中受限的推理能力。

**Method:** FUDOKI是一种纯粹基于离散流匹配的统一多模态模型，作为传统自回归范式的替代。它利用度量诱导的概率路径和动能最优速度，实现了具有自校正能力的迭代细化和更丰富的双向上下文集成，超越了基于掩蔽的损坏过程。为了降低从头训练的成本，FUDOKI从预训练的自回归MLLM初始化，并自适应地过渡到离散流匹配范式。

**Result:** FUDOKI在视觉理解和图像生成任务上均达到了与最先进的自回归MLLMs相当的性能。此外，对FUDOKI应用测试时缩放技术可带来显著的性能提升。

**Conclusion:** FUDOKI展示了作为下一代统一多模态模型基础的潜力，并且通过强化学习等方式有望在未来进一步增强。

> **ai_Abstract:** FUDOKI是一种新型统一多模态模型，旨在克服现有自回归（AR）多模态大语言模型（MLLMs）的局限性。该模型纯粹基于离散流匹配，利用动能最优速度实现迭代细化和双向上下文集成，优于传统的掩蔽损坏过程。通过从预训练的AR-MLLM初始化，FUDOKI在视觉理解和图像生成任务上达到了与最先进AR模型相当的性能，并通过测试时缩放技术进一步提升，展现了其作为未来多模态模型基础的巨大潜力。

> **摘要翻译:** 大语言模型（LLMs）的快速发展催生了多模态大语言模型（MLLMs）的出现，这些模型在单一框架内统一了视觉理解和图像生成。然而，大多数现有MLLMs依赖于自回归（AR）架构，这对其未来发展施加了固有的限制，例如图像生成中的光栅扫描顺序和因果上下文建模中受限的推理能力。在这项工作中，我们通过引入FUDOKI来挑战AR方法的主导地位，FUDOKI是一个纯粹基于离散流匹配的统一多模态模型，作为传统AR范式的替代方案。通过利用带有动能最优速度的度量诱导概率路径，我们的框架超越了之前基于掩蔽的损坏过程，实现了具有自校正能力的迭代细化和生成过程中更丰富的双向上下文集成。为了减轻从头开始训练的高成本，我们从预训练的AR基MLLMs初始化FUDOKI，并自适应地过渡到离散流匹配范式。实验结果表明，FUDOKI在视觉理解和图像生成任务上均达到了与最先进的AR基MLLMs相当的性能，突显了其作为下一代统一多模态模型基础的潜力。此外，我们表明将测试时缩放技术应用于FUDOKI会产生显著的性能增益，进一步强调了其通过强化学习实现未来增强的希望。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [613] [Emotion Recognition from Skeleton Data: A Comprehensive Survey](https://arxiv.org/abs/2507.18026)
> *基于骨架数据的情绪识别：一项综合性综述*

*Haifeng Lu, Jiuyi Chen, Zhen Zhang, Ruida Liu, Runhao Zeng, Xiping Hu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 情绪识别, 骨架数据, 身体运动, 综述

**Comment:** 34 pages, 5 figures, 13 tables

> **TL;DR:** 这篇综述全面回顾了基于骨架数据的情绪识别技术，包括心理模型、数据集、方法分类（姿态和步态），并提出了一个统一的技术范式分类，讨论了应用、挑战和未来方向。

**AI_Comments:** 这篇综述全面且系统地梳理了基于骨架数据的情绪识别领域，尤其创新性地提出了一个统一的技术分类范式，这对于理解和组织现有研究具有重要意义。同时，它不仅涵盖了技术方法，还涉及心理学基础、数据集和实际应用，为该领域的未来研究提供了清晰的路线图和挑战点。

<details>
  <summary>Details</summary>

**Motivation:** 通过身体运动进行情绪识别，作为一种保护隐私的替代方案，正逐渐取代依赖面部表情或生理信号的传统方法。3D骨架采集技术和姿态估计算法的最新进展显著增强了基于全身运动进行情绪识别的可行性。

**Method:** 本综述对基于骨架的情绪识别技术进行了全面系统的回顾。首先，介绍了情绪的心理模型以及身体运动与情绪表达的关系。其次，总结了公开可用的数据集，并区分了数据采集方法和情绪标注策略。然后，将现有方法分为基于姿态和基于步态的方法，从数据驱动和技术角度进行分析。特别是，提出了一个统一的分类法，包括四种主要技术范式：传统方法、Feat2Net、FeatFusionNet和End2EndNet。最后，回顾和比较了各类别的代表性工作，并讨论了该领域的扩展应用、开放挑战和未来研究方向。

**Result:** 本综述提出了一个统一的、涵盖四种主要技术范式（传统方法、Feat2Net、FeatFusionNet、End2EndNet）的骨架数据情绪识别分类法，并对各类别的代表性工作进行了回顾、比较，提供了常用数据集的基准测试结果。

**Conclusion:** 基于骨架数据的情绪识别是一个快速发展的领域，具有在心理健康评估（如抑郁症和自闭症检测）等方面的扩展应用潜力。该领域仍面临开放挑战，需要进一步研究。

> **ai_Abstract:** 本篇综合性综述深入探讨了基于骨架数据的情绪识别技术，将其作为传统方法的隐私保护替代方案。文章首先介绍了情绪的心理学基础和身体运动与情绪的关系，随后总结了现有数据集的特点。核心内容在于对现有方法进行了分类，提出了一个统一的技术范式（包括传统方法、Feat2Net、FeatFusionNet和End2EndNet），并对各类代表性工作进行了比较。最后，讨论了该技术在心理健康评估中的应用潜力以及未来的研究方向和挑战。

> **摘要翻译:** 通过身体运动进行情绪识别已成为一种引人注目且保护隐私的替代方案，取代了依赖面部表情或生理信号的传统方法。3D骨架采集技术和姿态估计算法的最新进展显著增强了基于全身运动进行情绪识别的可行性。本综述对基于骨架的情绪识别技术进行了全面系统的回顾。首先，我们介绍了情绪的心理模型，并研究了身体运动与情绪表达之间的关系。其次，我们总结了公开可用的数据集，强调了数据采集方法和情绪标注策略的差异。然后，我们将现有方法分为基于姿态和基于步态的方法，并从数据驱动和技术角度对其进行分析。特别是，我们提出了一个统一的分类法，涵盖了四种主要的技术范式：传统方法、Feat2Net、FeatFusionNet和End2EndNet。我们对每个类别中的代表性工作进行了回顾和比较，并提供了常用数据集上的基准测试结果。最后，我们探讨了情绪识别在心理健康评估（如检测抑郁症和自闭症）中的扩展应用，并讨论了这个快速发展领域中开放的挑战和未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [621] [Facial Demorphing from a Single Morph Using a Latent Conditional GAN](https://arxiv.org/abs/2507.18566)
> *基于潜在条件GAN的单张融合人脸图像解融*

*Nitish Shukla, Arun Ross* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人脸解融合, 潜在条件GAN, 融合攻击检测, 生物识别安全

**Comment:** 

> **TL;DR:** 该论文提出了一种使用潜在条件GAN从单张融合人脸图像中恢复原始人脸的方法，解决了现有方法存在的融合复制问题和泛化性差的问题。

**AI_Comments:** 这篇论文通过引入潜在条件GAN来解决人脸解融合中的关键挑战，即“融合复制问题”和对未知融合技术的泛化能力不足。其创新点在于利用潜在空间分解，使得模型能够处理各种未见的融合图像类型。该研究对生物识别安全领域具有重要意义，因为它能帮助识别和追踪滥用融合图像的个体。

<details>
  <summary>Details</summary>

**Motivation:** 融合人脸图像（morph）可以伪装成多个身份，对生物识别系统构成威胁。虽然融合攻击检测（MAD）可以识别融合图像，但无法恢复原始组成图像。现有的解融合方法存在输出与融合图像过于相似（融合复制问题）或依赖于训练和测试使用相同融合技术的问题，因此需要一种新的、更有效的解融合方法来提供额外证据并克服这些局限性。

**Method:** 本文提出了一种基于潜在条件GAN的解融合方法。该方法在潜在空间中分解融合图像，使其能够解融合由未知融合技术和人脸风格创建的图像。模型在合成人脸生成的融合图像上进行训练，并在使用任意融合技术从真实人脸创建的融合图像上进行测试。

**Result:** 该方法显著优于现有方法，并能生成高保真度的解融合人脸图像。

**Conclusion:** 本文提出的基于潜在条件GAN的解融合方法有效解决了现有方法的局限性，实现了从单张融合图像中恢复原始人脸的高性能和高保真度，即使面对未知融合技术也能表现出色。

> **ai_Abstract:** 本文提出了一种新颖的基于潜在条件GAN的解融合方法，旨在从单张融合人脸图像中恢复原始组成人脸。该方法通过在潜在空间中分解融合图像，有效解决了现有解融合方法面临的“融合复制”问题以及对特定融合技术依赖的问题。实验结果表明，该方法在处理未知融合技术和不同人脸风格的融合图像时，性能显著优于现有方法，并能生成高质量的解融合图像。

> **摘要翻译:** 融合图像是通过组合两张（或更多）来自不同身份的人脸图像来创建的复合图像，这种图像与所有组成身份高度相似，从而使伪造的融合图像能够与多个个体进行生物识别关联。融合攻击检测（MAD）可用于检测融合图像，但不能揭示组成图像。因此，解融合——即推断组成图像的过程——对于提供关于融合图像的额外证据至关重要。现有的解融合方法存在融合复制问题，即输出往往与融合图像本身非常相似，或者假设训练和测试的融合图像是使用相同的融合技术生成的。所提出的方法克服了这些问题。该方法在潜在空间中分解融合图像，使其能够解融合由未知融合技术和人脸风格创建的图像。我们在由合成人脸创建的融合图像上训练我们的方法，并在使用任意融合技术从真实人脸创建的融合图像上进行测试。我们的方法在很大程度上优于现有方法，并生成了高保真度的解融合人脸图像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [623] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
> *用于密集预测的频率动态注意力调制*

*Linwei Chen, Lin Gu, Ying Fu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** Vision Transformers, 频率动态注意力调制, 注意力反演, 频率衰减, 密集预测

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出了一种名为频率动态注意力调制（FDAM）的新策略，通过引入注意力反演（AttInv）和频率动态缩放（FreqScale）来解决Vision Transformers（ViTs）中注意力机制导致的频率衰减问题，从而在多种视觉任务上持续提升性能并避免表示坍塌。

**AI_Comments:** 本文的创新点在于从电路理论的角度出发，提出了频率动态注意力调制（FDAM）来解决ViTs中普遍存在的频率衰减问题，这是一种新颖且有效的视角。通过引入注意力反演和频率动态缩放，FDAM能够精细地控制模型的频率响应，从而保留重要的细节和纹理信息，有效避免了表示坍塌，对ViTs的性能提升具有重要意义。该方法的普适性和在多项任务上取得的显著改进，特别是遥感领域的应用，进一步凸显了其价值。

<details>
  <summary>Details</summary>

**Motivation:** Vision Transformers（ViTs）的注意力机制使每个层都充当低通滤波器，导致现有Transformer的堆叠层架构出现频率衰减问题，从而丢失关键细节和纹理。

**Method:** 本文提出了一种受电路理论启发的新策略，称为频率动态注意力调制（FDAM），它可以轻松地插入ViTs。FDAM直接调制ViTs的整体频率响应，包含两种技术：注意力反演（AttInv）和频率动态缩放（FreqScale）。AttInv通过反转注意力矩阵中的低通滤波器生成互补的高通滤波，并动态组合两者。FreqScale用于加权不同频率分量，以对目标响应函数进行细粒度调整。

**Result:** 通过特征相似性分析和有效秩评估，本文证明FDAM方法避免了表示坍塌，并在SegFormer、DeiT和MaskDINO等多种模型上实现了持续的性能改进。这些改进在语义分割、目标检测和实例分割等任务中表现明显。此外，该方法应用于遥感检测，在单尺度设置下取得了最先进的结果。

**Conclusion:** 频率动态注意力调制（FDAM）通过有效解决ViTs中的频率衰减问题，显著提升了模型在各种密集预测任务上的性能，并避免了表示坍塌。

> **ai_Abstract:** 本文提出了一种名为频率动态注意力调制（FDAM）的新型策略，旨在解决Vision Transformers（ViTs）中因注意力机制作为低通滤波器而导致的频率衰减问题。FDAM受电路理论启发，包含注意力反演（AttInv）和频率动态缩放（FreqScale）两种技术，能够直接调制ViTs的频率响应。AttInv通过反转注意力矩阵生成高通滤波，与低通滤波动态结合；FreqScale则精细调整不同频率分量。实验证明，该方法有效避免了表示坍塌，并在语义分割、目标检测和实例分割等任务中持续提升了SegFormer、DeiT和MaskDINO等模型的性能，尤其在遥感检测中取得了最先进的结果。

> **摘要翻译:** Vision Transformers（ViTs）在计算机视觉领域取得了显著进展，在各种任务中展现出强大的性能。然而，ViTs中的注意力机制使得每个层都充当低通滤波器，并且现有Transformer中堆叠层架构存在频率衰减问题。这导致关键细节和纹理的丢失。我们提出了一种新颖的、受电路理论启发的策略，称为频率动态注意力调制（FDAM），它可以轻松地插入到ViTs中。FDAM直接调制ViTs的整体频率响应，并由两种技术组成：注意力反演（AttInv）和频率动态缩放（FreqScale）。由于电路理论使用低通滤波器作为基本元件，我们引入了AttInv，一种通过反转注意力矩阵中的低通滤波器来生成互补高通滤波并动态结合两者的方。我们进一步设计了FreqScale，用于加权不同的频率分量，以对目标响应函数进行细粒度调整。通过特征相似性分析和有效秩评估，我们证明了我们的方法避免了表示坍塌，从而在包括SegFormer、DeiT和MaskDINO在内的各种模型上实现了持续的性能改进。这些改进在语义分割、目标检测和实例分割等任务中表现明显。此外，我们将我们的方法应用于遥感检测，在单尺度设置下取得了最先进的结果。代码可在https://github.com/Linwei-Chen/FDAM上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [626] [LEAF: Latent Diffusion with Efficient Encoder Distillation for Aligned Features in Medical Image Segmentation](https://arxiv.org/abs/2507.18214)
> *LEAF：用于医学图像分割中对齐特征的潜在扩散与高效编码器蒸馏*

*Qilin Huang, Tianyu Lin, Zhiguang Chen, Fudan Zheng* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学图像分割, 潜在扩散模型, 特征蒸馏, 效率, 图像分割

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** LEAF是一种高效的医学图像分割模型，通过修改潜在扩散模型的预测模式和引入特征蒸馏来提升性能，且不增加推理时的参数或计算量。

**AI_Comments:** LEAF的创新点在于其针对医学图像分割任务对潜在扩散模型进行了高效的定制化改造，特别是通过直接预测分割图和引入特征蒸馏来优化性能。其不增加推理阶段计算成本的特性，使其在实际应用中具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型在医学图像分割任务中直接迁移训练过程，缺乏针对性调整，且预训练扩散模型在特征提取方面存在不足。

**Method:** 本文提出了LEAF模型，基于潜在扩散模型。在微调过程中，将原始的噪声预测模式替换为直接预测分割图，以减少分割结果的方差。同时，采用特征蒸馏方法，将卷积层的隐藏状态与基于Transformer的视觉编码器的特征对齐。

**Result:** 实验结果表明，该方法在多个针对不同疾病类型的分割数据集上，提升了原始扩散模型的性能。值得注意的是，该方法不改变模型架构，也不增加推理阶段的参数数量或计算量。

**Conclusion:** LEAF通过改进潜在扩散模型的微调策略和引入特征蒸馏，显著提升了医学图像分割的性能和效率。

> **ai_Abstract:** LEAF是一种针对医学图像分割任务的潜在扩散模型。该模型通过将原始噪声预测模式替换为直接分割图预测来减少结果方差，并采用特征蒸馏技术将卷积层特征与Transformer编码器特征对齐。实验证明，LEAF在不增加推理阶段参数或计算量的情况下，显著提升了扩散模型在多个医学图像分割数据集上的性能和效率。

> **摘要翻译:** 利用扩散模型的强大功能在医学图像分割任务中取得了相当有效的结果。然而，现有方法通常直接转移原始训练过程，没有针对分割任务进行具体调整。此外，常用的预训练扩散模型在特征提取方面仍然存在缺陷。基于这些考虑，我们提出了LEAF，一个基于潜在扩散模型的医学图像分割模型。在微调过程中，我们将原始的噪声预测模式替换为直接预测分割图，从而减少了分割结果的方差。我们还采用了一种特征蒸馏方法，将卷积层的隐藏状态与来自基于Transformer的视觉编码器的特征对齐。实验结果表明，我们的方法在多个针对不同疾病类型的分割数据集上增强了原始扩散模型的性能。值得注意的是，我们的方法不改变模型架构，也不增加推理阶段的参数或计算量，使其具有高效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [635] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
> *闪存-VStream：长视频流的高效实时理解*

*Haoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, Xiaojie Jin* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视频理解, 长视频, 实时处理, 语言模型, 记忆网络

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 提出Flash-VStream，一个高效的视频语言模型，通过独特的Flash Memory模块，显著降低推理延迟，实现对超长视频的实时理解，并在多个基准测试中达到SOTA性能和卓越效率。

**AI_Comments:** 这篇论文通过引入创新的Flash Memory模块，有效解决了长视频理解中的核心挑战——高计算和内存开销。其提出的双记忆机制（上下文记忆和增强记忆）能够高效地处理长上下文信息，同时保持实时响应能力，这对于实际应用具有重要意义。该方法的效率和性能提升使其在视频理解领域具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大语言模型在长视频理解上面临计算和内存开销大的挑战，且现有方法对长视频处理效率低下，难以推广。

**Method:** 提出Flash-VStream模型，核心是设计了一个Flash Memory模块，包含：1) 低容量上下文记忆，用于聚合长上下文时间信息并建模信息密度分布；2) 高容量增强记忆，用于根据信息密度分布检索详细空间信息。

**Result:** Flash-VStream显著降低了推理延迟，并在EgoSchema, MLVU, LVBench, MVBench和Video-MME等长视频和综合视频基准测试中展示了最先进的性能和卓越的效率。

**Conclusion:** Flash-VStream有效解决了长视频理解中的效率和实时性问题，通过创新的记忆模块实现了高性能和低延迟，是长视频理解领域的重要进展。

> **ai_Abstract:** 本文提出了Flash-VStream，一个专为高效实时理解超长视频流设计的视频语言模型。针对现有模型在处理长视频时面临的计算和内存开销大的问题，Flash-VStream引入了一个独特的Flash Memory模块，该模块结合了低容量上下文记忆来聚合时间信息并建模信息密度，以及高容量增强记忆来检索详细空间信息。实验结果表明，Flash-VStream相比现有模型显著降低了推理延迟，并在多个长视频和综合视频基准测试中展现出最先进的性能和卓越的效率。

> **摘要翻译:** 受益于大型语言模型和跨模态对齐的进步，现有的多模态大型语言模型在图像和短视频理解方面取得了显著性能。然而，长视频的理解仍然具有挑战性，因为其长上下文特性导致了显著的计算和内存开销。大多数现有工作将长视频与短视频同等对待，这对于实际应用来说效率低下，并且难以推广到更长的视频。为了解决这些问题，我们提出了 Flash-VStream，一个高效的视频语言模型，能够处理超长视频并实时响应用户查询。特别地，我们设计了一个闪存模块（Flash Memory module），包含一个低容量的上下文记忆（context memory）用于聚合长上下文时间信息并模拟信息密度分布，以及一个高容量的增强记忆（augmentation memory）用于根据此分布检索详细的空间信息。与现有模型相比，Flash-VStream 显著降低了推理延迟。在长视频基准和综合视频基准（即 EgoSchema、MLVU、LVBench、MVBench 和 Video-MME）上进行的广泛实验证明了我们方法的最新性能和卓越效率。代码可在 https://github.com/IVGSZ/Flash-VStream 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [639] [Self-Supervised Ultrasound-Video Segmentation with Feature Prediction and 3D Localised Loss](https://arxiv.org/abs/2507.18424)
> *自监督超声视频分割与特征预测和3D局部损失*

*Edward Ellis, Robert Mendel, Andrew Bulpitt, Nasim Parsa, Michael F Byrne, Sharib Ali* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 超声视频分割, V-JEPA, 3D局部化损失, 视觉Transformer

**Comment:** 

> **TL;DR:** 本研究首次将V-JEPA应用于超声视频分割，并引入3D局部化辅助任务以提升ViT模型在小数据集上的局部性理解能力，显著提高了超声视频的分割性能，尤其在数据量有限时效果更佳。

**AI_Comments:** 该研究的创新点在于首次将V-JEPA应用于超声视频数据，并针对ViT在医学图像上的局限性引入了3D局部化辅助任务，有效提升了自监督学习在超声分割领域的应用效果。其在数据稀缺时的显著性能提升，对于临床实践中难以获取大量标注数据的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 超声图像数据的获取和标注面临低对比度、高噪声和伪影等挑战，耗时且需要专业的临床知识。自监督学习（SSL）提供了一个有前景的解决方案，通过利用未标注数据来学习有用的表示，从而在标注数据有限的情况下改善分割性能。

**Method:** 本研究首次将基于特征预测的自监督学习框架V-JEPA应用于超声视频数据，旨在利用时间信息并减少对像素级噪声的敏感性。为解决ViT模型在小型医学数据集上因缺乏归纳偏置和有限空间局部性而表现不佳的问题，提出了一种新颖的3D局部化辅助任务，用于在V-JEPA预训练期间改善ViT表示的局部性理解。

**Result:** V-JEPA结合提出的3D局部化辅助任务显著提高了各种冻结编码器配置下的分割性能。使用100%训练数据时，性能提升高达3.4%；仅使用10%训练数据时，性能提升高达8.35%。

**Conclusion:** 结合V-JEPA和3D局部化辅助任务是解决超声视频分割中数据标注挑战的有效自监督学习方法，尤其在数据稀缺场景下表现出显著的性能提升。

> **ai_Abstract:** 本文针对超声视频数据标注困难的问题，首次将基于特征预测的自监督学习框架V-JEPA应用于超声视频分割。为解决视觉Transformer（ViT）模型在小型医学数据集上局部性理解不足的局限性，提出了一种新颖的3D局部化辅助任务。实验结果表明，结合V-JEPA和3D局部化辅助任务显著提升了超声视频的分割性能，尤其在标注数据有限的情况下效果更为显著。

> **摘要翻译:** 在超声成像中获取和标注大型数据集具有挑战性，原因在于低对比度、高噪声和易受伪影影响。这个过程需要大量时间和临床专业知识。自监督学习（SSL）通过利用未标注数据学习有用表示，在标注数据有限时实现改进的分割性能，提供了一个有前景的解决方案。视频数据SSL的最新技术进展包括V-JEPA，这是一个完全基于特征预测的框架，避免了像素级重建或负样本。我们假设V-JEPA非常适合超声成像，因为它对嘈杂的像素级细节不那么敏感，同时有效利用了时间信息。据我们所知，这是首次将V-JEPA应用于超声视频数据。与其他基于补丁掩蔽的SSL技术（如VideoMAE）类似，V-JEPA非常适合基于ViT的模型。然而，由于缺乏归纳偏置、有限的空间局部性和缺乏分层特征学习，ViT在小型医学数据集上可能表现不佳。为了提高局部性理解，我们提出了一种新颖的3D局部化辅助任务，以在V-JEPA预训练期间改善ViT表示的局部性。我们的结果表明，V-JEPA结合我们的辅助任务在各种冻结编码器配置下显著提高了分割性能，使用100%训练数据时增益高达3.4%，仅使用10%训练数据时增益高达8.35%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [641] [Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation](https://arxiv.org/abs/2507.17347)
> *Swin-TUNA：一种用于精确食物图像分割的新型PEFT方法*

*Haotian Chen, Zhiyong Xiao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** Swin-TUNA, PEFT, 食物图像分割, Transformer, 适配器

**Comment:** After discussion among the authors, some parts of the paper are
  deemed inappropriate and will be revised and resubmitted

> **TL;DR:** Swin-TUNA是一种参数高效微调（PEFT）方法，通过引入多尺度可训练适配器到Swin Transformer中，仅更新4%的参数即可实现高性能食物图像分割，同时大幅减少参数量并超越全参数模型。

**AI_Comments:** Swin-TUNA在解决大型Transformer模型在实际部署中的参数和计算资源瓶颈方面具有重要意义。其核心创新在于分层特征适应机制，巧妙地通过可分离卷积和多尺度维度映射来优化特征处理，并结合动态平衡策略，这在PEFT领域是值得关注的进展。该方法在大幅减少模型参数的同时，性能超越了全参数模型，并在低数据量场景下表现出更强的鲁棒性，展示了其在工业应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大规模基于Transformer的模型（如FoodSAM）由于参数量巨大和计算资源需求高，难以满足实际部署要求。

**Method:** 本文提出Swin-TUNA，一种参数高效微调（PEFT）方法。它将多尺度可训练适配器集成到Swin Transformer架构中，通过仅更新4%的参数实现高性能食物图像分割。其核心创新在于分层特征适应机制，通过深度可分离卷积和不同尺度的维度映射来处理浅层和深层网络之间的特征差异，并结合任务无关和任务特定特征的动态平衡策略。

**Result:** Swin-TUNA在FoodSeg103和UECFoodPix Complete数据集上分别实现了50.56%和74.94%的mIoU，超越了全参数的FoodSAM模型，同时将参数量减少了98.7%（仅8.13M）。此外，Swin-TUNA在低数据量场景下表现出更快的收敛速度和更强的泛化能力。

**Conclusion:** Swin-TUNA为构建轻量级食物图像分割提供了高效的解决方案。

> **ai_Abstract:** Swin-TUNA提出了一种新颖的参数高效微调（PEFT）方法，用于食物图像的语义分割。该方法通过将多尺度可训练适配器集成到Swin Transformer中，仅需更新4%的参数即可实现高性能。其创新点在于分层特征适应机制，通过可分离卷积和多尺度维度映射处理不同深度网络的特征差异，并动态平衡任务无关和任务特定特征。实验证明，Swin-TUNA在FoodSeg103和UECFoodPix Complete数据集上取得了优异的mIoU表现，超越了FoodSAM模型，同时参数量大幅减少98.7%。此外，它在低数据量场景下展现出更快的收敛速度和更强的泛化能力，为轻量级食物图像分割提供了高效方案。

> **摘要翻译:** 在食物图像处理领域，高效的语义分割技术对于工业应用至关重要。然而，现有的大规模基于Transformer的模型（如FoodSAM）由于其庞大的参数数量和高计算资源需求，在满足实际部署要求方面面临挑战。本文介绍了一种可调适配器模块（Swin-TUNA），这是一种参数高效微调（PEFT）方法，它将多尺度可训练适配器集成到Swin Transformer架构中，通过仅更新4%的参数实现了高性能的食物图像分割。Swin-TUNA的核心创新在于其分层特征适应机制：它设计了深度可分离卷积和不同尺度的维度映射，以解决浅层和深层网络之间的特征差异，并结合了任务无关和任务特定特征的动态平衡策略。实验表明，该方法在FoodSeg103和UECFoodPix Complete数据集上分别达到了50.56%和74.94%的mIoU，超越了全参数的FoodSAM模型，同时将参数量减少了98.7%（仅为8.13M）。此外，Swin-TUNA在低数据量场景下表现出更快的收敛速度和更强的泛化能力，为构建轻量级食物图像提供了高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [651] [RadioDUN: A Physics-Inspired Deep Unfolding Network for Radio Map Estimation](https://arxiv.org/abs/2506.08418)
> *无线电DUN：一种物理启发式深度展开网络用于无线电地图估计*

*Taiqin Chen, Zikun Zhou, Zheng Fang, Wenzhen Zou, Kangjun Liu, Ke Chen, Yongbing Zhang, Yaowei Wang* | **Category: cs.CV, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 无线电地图估计, 深度展开网络, 物理传播模型, 稀疏信号恢复, 动态重加权

**Comment:** 

> **TL;DR:** 提出RadioDUN，一个物理启发式深度展开网络，通过将无线电地图估计视为稀疏信号恢复问题并结合物理传播模型，从稀疏样本中高效估计密集无线电地图，性能优于现有方法。

**AI_Comments:** 这篇论文的创新点在于将物理传播模型与深度学习的展开网络相结合，有效解决了现有深度学习方法难以整合物理特性的问题。通过将无线电地图估计问题转化为稀疏信号恢复，并引入动态重加权和阴影损失等机制，RadioDUN能够更准确地建模无线电传播的复杂性，尤其是在处理障碍物引起的信号衰减方面。这种物理启发式的方法有望在无线电资源管理和干扰缓解中发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 无线电地图对频谱资源分配和干扰缓解至关重要，但实际中难以从有限样本构建密集地图。现有深度学习方法难以整合无线电地图的物理特性。

**Method:** 将无线电地图估计视为稀疏信号恢复问题。整合物理传播模型将问题分解为多个因子优化子问题以降低复杂度。提出RadioDUN，通过展开优化过程实现自适应参数调整和先验拟合。开发动态重加权模块（DRM）来自适应建模各因子对无线电地图的重要性。整合与障碍物相关的因子以表达障碍物引起的信号随机衰减，并设计阴影损失作为补充监督目标。

**Result:** 所提出的方法在实验中表现出优于现有最先进方法的性能。

**Conclusion:** RadioDUN通过结合物理特性和深度展开技术，有效地从稀疏样本中估计出密集的无线电地图，并取得了优越的性能。

> **ai_Abstract:** 这篇论文提出了一种名为RadioDUN的物理启发式深度展开网络，用于从稀疏测量样本中估计密集的无线电地图。该方法将无线电地图估计问题转化为稀疏信号恢复，并通过整合物理传播模型来分解问题。RadioDUN通过展开优化过程实现参数自适应和先验拟合，并引入动态重加权模块和障碍物相关因子（结合阴影损失）来有效捕捉无线电传播特性。实验结果表明，RadioDUN的性能优于现有最先进的方法。

> **摘要翻译:** 无线电地图表示一个区域内频谱资源的空间分布，支持高效的资源分配和干扰缓解。然而，由于在实际场景中只能测量有限数量的样本，构建密集无线电地图很困难。尽管现有工作已使用深度学习从稀疏样本中估计密集无线电地图，但它们难以与无线电地图的物理特性相结合。为了解决这一挑战，我们将无线电地图估计视为稀疏信号恢复问题。进一步结合物理传播模型将问题分解为多个因子优化子问题，从而降低恢复复杂度。受现有压缩感知方法的启发，我们提出了无线电深度展开网络（RadioDUN），以可学习的方式展开优化过程，实现自适应参数调整和先验拟合。为了考虑无线电传播特性，我们开发了一个动态重加权模块（DRM）来自适应地建模每个因子对无线电地图的重要性。受物理传播模型中阴影因子的启发，我们整合了与障碍物相关的因子来表达障碍物引起的信号随机衰减。进一步设计了阴影损失来约束因子预测并作为补充监督目标，这增强了RadioDUN的性能。已进行了大量实验证明所提出的方法优于现有最先进的方法。我们的代码将在发布时公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [653] [Zero-Shot Skeleton-Based Action Recognition With Prototype-Guided Feature Alignment](https://arxiv.org/abs/2507.00566)
> *基于原型引导特征对齐的零样本骨架行为识别*

*Kai Zhou, Shuhai Zhang, Zeng You, Jinwu Hu, Mingkui Tan, Fei Liu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 零样本动作识别, 骨架行为识别, 特征对齐, 原型引导, 对比学习

**Comment:** This paper is accepted by IEEE TIP 2025 (The journal version is
  available at https://doi.org/10.1109/TIP.2025.3586487). Code is publicly
  available at https://github.com/kaai520/PGFA

> **TL;DR:** 本文提出了一种名为PGFA的零样本骨架行为识别新范式，通过端到端跨模态对比训练和原型引导的文本特征对齐策略，显著提高了在多个数据集上的识别准确率，解决了现有方法中骨架特征判别力不足和对齐偏差的问题。

**AI_Comments:** PGFA的创新点在于其结合了端到端跨模态对比训练和原型引导的文本特征对齐策略，有效地解决了零样本骨架行为识别中特征判别力不足和对齐偏差的两个核心难题。该方法不仅提供了理论支持，而且在多个标准数据集上取得了显著的性能提升，展示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 零样本骨架行为识别任务面临从已知动作泛化到未知动作的巨大挑战。现有方法存在两个主要问题：1) 骨架特征判别力不足，固定骨架编码器无法捕获有效的对齐信息；2) 测试时忽略了骨架特征与未知文本特征之间的对齐偏差。

**Method:** 本文提出了PGFA（原型引导特征对齐）范式。具体来说，开发了一个端到端跨模态对比训练框架，以提高骨架-文本对齐并确保骨架特征的充分判别力。此外，引入了原型引导的文本特征对齐策略，以减轻测试期间分布差异的不利影响。提供了理论分析支持该策略。

**Result:** 与顶尖竞争方法SMIE相比，PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现了22.96%、12.53%和18.54%的绝对准确率提升。

**Conclusion:** 本文提出的PGFA范式通过解决现有方法的关键局限性，在零样本骨架行为识别任务上取得了显著的性能提升，为该领域提供了一种有效的新方法。

> **ai_Abstract:** 本文针对零样本骨架行为识别中骨架特征判别力不足和对齐偏差问题，提出了一种名为PGFA的原型引导特征对齐范式。PGFA包含一个端到端跨模态对比训练框架，用于增强骨架-文本对齐，以及一个原型引导文本特征对齐策略，以缓解测试时的分布差异。实验证明，PGFA在多个知名数据集上相较于现有最佳方法实现了显著的准确率提升。

> **摘要翻译:** 零样本骨架行为识别旨在对训练期间未曾接触过的骨架基人类动作进行分类。由于难以从已知动作泛化到未知动作，这项任务极具挑战性。以往的研究通常采用两阶段训练：使用交叉熵损失在已知动作类别上预训练骨架编码器，然后对预提取的骨架和文本特征进行对齐，通过骨架-文本对齐和语言模型的泛化能力将知识转移到未知类别。然而，它们的有效性受到以下因素的阻碍：1) 骨架特征判别力不足，因为固定的骨架编码器无法捕获有效骨架-文本对齐所需的必要对齐信息；2) 测试时忽略了骨架特征与未知文本特征之间的对齐偏差。为此，我们提出了一种用于零样本骨架行为识别的原型引导特征对齐范式，命名为PGFA。具体来说，我们开发了一个端到端跨模态对比训练框架，以改善骨架-文本对齐，确保骨架特征具有足够的判别力。此外，我们引入了一种原型引导文本特征对齐策略，以减轻测试期间分布差异的不利影响。我们提供了理论分析来支持我们的原型引导文本特征对齐策略，并在三个知名数据集上对我们的整体PGFA进行了实证评估。与顶尖竞争方法SMIE相比，我们的PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现了22.96%、12.53%和18.54%的绝对准确率提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [655] [ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031)
> *ViGText：基于视觉-语言模型解释和图神经网络的深度伪造图像检测*

*Ahmad ALBarqawi, Mahmoud Nazzal, Issa Khalil, Abdallah Khreishah, NhatHai Phan* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 深度伪造检测, 视觉-语言模型, 图神经网络, 泛化性, 鲁棒性

**Comment:** 

> **TL;DR:** ViGText是一种新颖的深度伪造图像检测方法，它通过结合视觉大语言模型解释和图神经网络来提高泛化性和鲁棒性，尤其对定制化深度伪造表现出色。

**AI_Comments:** ViGText的创新之处在于将VLLM文本解释与视觉数据的新颖集成，提供了比传统字幕更具上下文感知能力的分析。图基框架和GNN的使用，结合多级特征提取，增强了其检测细微不一致性以及对抗复杂深度伪造和定向攻击的鲁棒性，标志着在确保媒体完整性方面迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度伪造检测方法难以应对复杂的、定制化的深度伪造内容，在泛化性和对抗恶意攻击的鲁棒性方面表现不足。

**Method:** ViGText将图像与视觉大语言模型（VLLM）文本解释集成到基于图的框架中。它系统地将图像分割成图像块，构建图像图和文本图，并使用图神经网络（GNNs）进行集成分析以识别深度伪造。该方法还利用跨空间和频率域的多级特征提取。

**Result:** 在泛化性评估中，平均F1分数从72.45%提高到98.32%，显示出对未见过的、经过微调的稳定扩散模型变体具有卓越的泛化能力。在鲁棒性方面，ViGText的召回率比其他深度伪造检测方法提高了11.1%。面对利用其图基架构的定向攻击时，分类性能下降限制在4%以内。

**Conclusion:** ViGText通过详细的视觉和文本分析为深度伪造检测设定了新标准，有助于确保媒体真实性和信息完整性。

> **ai_Abstract:** ViGText通过将视觉大语言模型（VLLM）的文本解释与视觉数据集成到图基框架中，解决了传统深度伪造检测方法在泛化性和鲁棒性方面的局限性。该方法将图像分解为图像块，构建图像图和文本图，并利用图神经网络（GNNs）结合多级特征提取进行分析。实验证明，ViGText在检测复杂和定制化深度伪造方面显著提升了泛化性和鲁棒性，能够有效识别未见过的变体并抵御定向攻击，从而增强了媒体的真实性。

> **摘要翻译:** 深度伪造技术迅速崛起，产生逼真但欺诈性的数字内容，威胁着媒体的真实性。传统的深度伪造检测方法往往难以应对复杂的、定制化的深度伪造，尤其是在泛化性和对抗恶意攻击的鲁棒性方面。本文介绍了一种名为ViGText的新方法，它将图像与视觉大语言模型（VLLM）文本解释集成到基于图的框架中，以改进深度伪造检测。ViGText的创新之处在于它将详细解释与视觉数据相结合，与通常缺乏特异性且未能揭示细微不一致的字幕相比，它提供了更具上下文感知能力的分析。ViGText系统地将图像分割成图像块，构建图像图和文本图，并使用图神经网络（GNNs）进行集成分析以识别深度伪造。通过在空间和频率域使用多级特征提取，ViGText捕获了增强其鲁棒性和准确性以检测复杂深度伪造的细节。大量的实验表明，ViGText显著增强了泛化性，并在检测用户定制深度伪造时实现了显著的性能提升。具体而言，在泛化性评估下，平均F1分数从72.45%上升到98.32%，反映了该模型对未见过的、经过微调的稳定扩散模型变体的卓越泛化能力。至于鲁棒性，与其他深度伪造检测方法相比，ViGText的召回率提高了11.1%。在面对利用其图基架构的定向攻击时，ViGText将分类性能下降限制在4%以内。ViGText利用详细的视觉和文本分析为深度伪造检测设定了新标准，有助于确保媒体真实性和信息完整性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [658] [Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis](https://arxiv.org/abs/2507.18569)
> *扩散蒸馏中的对抗性分布匹配：迈向高效图像和视频合成*

*Yanzuo Lu, Yuxi Ren, Xin Xia, Shanchuan Lin, Xing Wang, Xuefeng Xiao, Andy J. Ma, Xiaohua Xie, Jian-Huang Lai* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散蒸馏, 对抗性学习, 分布匹配, 图像合成, 视频合成

**Comment:** Accepted by ICCV 2025 (Highlight)

> **TL;DR:** 本文提出了对抗性分布匹配（ADM），通过引入对抗性学习来解决现有扩散蒸馏方法（DMD）中潜在的模式崩溃问题，从而实现更高效、更高质量的图像和视频合成。

**AI_Comments:** 本文的创新之处在于将对抗性学习引入扩散模型蒸馏，通过基于扩散的判别器有效解决了传统DMD方法中的模式崩溃问题。引入混合判别器和分布损失进一步优化了蒸馏过程，显著提升了图像和视频合成的效率和质量，为高效部署扩散模型提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分布匹配蒸馏（DMD）技术在压缩预训练扩散模型时，由于依赖反向Kullback-Leibler（KL）散度最小化，可能在某些应用中导致模式崩溃（或模式寻求）问题。

**Method:** 本文提出了对抗性分布匹配（ADM）框架，利用基于扩散的判别器以对抗性方式对真实和伪分数估计器之间的潜在预测进行对齐，用于分数蒸馏。在一步蒸馏中，通过在潜在空间和像素空间使用混合判别器进行对抗性蒸馏来改进预训练生成器。与DMD2预训练中使用的均方误差不同，该方法结合了从教师模型收集的ODE对上的分布损失，为分数蒸馏微调提供了更好的初始化。将对抗性蒸馏预训练与ADM微调结合成统一的DMDX流程。

**Result:** 所提出的DMDX方法在SDXL上实现了优于DMD2的一步性能，同时消耗更少的GPU时间。此外，在SD3-Medium、SD3.5-Large和CogVideoX上应用多步ADM蒸馏，为高效图像和视频合成树立了新的基准。

**Conclusion:** 本文提出的对抗性分布匹配（ADM）框架，通过结合对抗性蒸馏预训练和ADM微调形成统一的DMDX流程，有效解决了现有扩散蒸馏方法中的模式崩溃问题，并在图像和视频合成方面实现了卓越的性能和效率，树立了新的行业基准。

> **ai_Abstract:** 本文提出了一种名为对抗性分布匹配（ADM）的新框架，旨在解决现有分布匹配蒸馏（DMD）中因依赖反向KL散度而导致的模式崩溃问题。ADM利用基于扩散的判别器，以对抗性方式对真实和伪分数估计器之间的潜在预测进行对齐。针对挑战性的一步蒸馏，该方法通过在潜在和像素空间使用混合判别器，并引入ODE对上的分布损失进行更好的初始化。将对抗性蒸馏预训练与ADM微调整合为DMDX流程，实验证明DMDX在SDXL上实现了优于DMD2的一步性能和更低的GPU时间。此外，多步ADM蒸馏在SD3-Medium、SD3.5-Large和CogVideoX上为高效图像和视频合成设定了新基准。

> **摘要翻译:** 分布匹配蒸馏（DMD）是一种有前景的分数蒸馏技术，能够将预训练的教师扩散模型压缩成高效的一步或多步学生生成器。然而，其对反向Kullback-Leibler（KL）散度最小化的依赖可能在某些应用中导致模式崩溃（或模式寻求）。为了规避这一固有缺点，我们提出了对抗性分布匹配（ADM），这是一种新颖的框架，它利用基于扩散的判别器以对抗性方式对真实和伪分数估计器之间的潜在预测进行对齐，以进行分数蒸馏。在极具挑战性的一步蒸馏背景下，我们通过在潜在空间和像素空间使用混合判别器进行对抗性蒸馏，进一步改进了预训练生成器。与DMD2预训练中使用的均方误差不同，我们的方法结合了从教师模型收集的ODE对上的分布损失，从而为下一阶段的分数蒸馏微调提供了更好的初始化。通过将对抗性蒸馏预训练与ADM微调结合成统一的流程，命名为DMDX，我们提出的方法在SDXL上实现了优于DMD2的一步性能，同时消耗更少的GPU时间。在SD3-Medium、SD3.5-Large和CogVideoX上应用多步ADM蒸馏的额外实验，为高效图像和视频合成树立了新的基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [665] [Rectifying Magnitude Neglect in Linear Attention](https://arxiv.org/abs/2507.00698)
> *纠正线性注意力中的幅度忽略问题*

*Qihang Fan, Huaibo Huang, Yuang Ai, ran He* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 线性注意力, 幅度忽略, MALA, Transformer, 注意力机制

**Comment:** Accepted by ICCV2025, highlight paper

> **TL;DR:** 本文提出了一种名为MALA的新型线性注意力机制，通过考虑查询的幅度信息，解决了传统线性注意力性能下降的问题，并在多项任务上取得了显著成果。

**AI_Comments:** 本文识别并解决了线性注意力中的一个关键缺陷——对查询幅度信息的忽略，这对于提升其性能至关重要。MALA的提出不仅具有理论洞察力，其在多模态任务上的广泛验证也显示了其实用性和潜在的广泛应用前景，为高效全局建模提供了一个有力的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** Softmax注意力在全局建模方面表现出色，但其二次复杂度限制了其在视觉任务中的应用。线性注意力虽然实现了线性复杂度，但与Softmax注意力相比，性能显著下降。本文旨在分析并解决线性注意力性能下降的根本原因。

**Method:** 本文分析了线性注意力性能下降的原因，发现其完全忽略了查询（Query）的幅度信息，导致注意力分数分布无法动态适应查询的尺度变化。基于此观察，本文提出了幅度感知线性注意力（Magnitude-Aware Linear Attention, MALA），通过修改线性注意力的计算方式，充分整合了查询的幅度信息。这种调整使MALA能够生成与Softmax注意力更相似且结构更均衡的注意力分数分布。

**Result:** MALA在图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成等多项任务上进行了评估，并取得了强大的结果。

**Conclusion:** 通过纠正线性注意力对查询幅度信息的忽略，MALA成功地提升了线性注意力的性能，使其在保持线性复杂度的同时，能够更好地模拟Softmax注意力的注意力分布，并在多种任务中展现出卓越的有效性。

> **ai_Abstract:** 本文针对线性注意力相较于Softmax注意力性能显著下降的问题进行了深入分析。研究发现，线性注意力在计算过程中完全忽略了查询的幅度信息，导致其注意力分数分布无法动态调整。为解决此问题，本文提出了一种新型的幅度感知线性注意力（MALA），通过修改计算方式，有效整合了查询的幅度信息。实验结果表明，MALA在图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成等多个领域均取得了优异表现，验证了其有效性。

> **摘要翻译:** 作为Transformer的核心操作，Softmax注意力展现出卓越的全局建模能力。然而，其二次复杂度限制了其在视觉任务中的适用性。相比之下，线性注意力与Softmax注意力具有相似的公式，同时实现了线性复杂度，从而实现了高效的全局信息建模。尽管如此，与标准Softmax注意力相比，线性注意力遭受了显著的性能下降。在本文中，我们基于线性注意力的公式分析了这一问题的根本原因。我们发现，与Softmax注意力不同，线性注意力完全忽略了查询（Query）的幅度信息。这导致注意力分数分布无法随着查询尺度的变化而动态适应。因此，尽管其结构与Softmax注意力相似，线性注意力却表现出显著不同的注意力分数分布。基于这一观察，我们提出了幅度感知线性注意力（Magnitude-Aware Linear Attention, MALA），它修改了线性注意力的计算方式，以充分整合查询的幅度。这种调整使得MALA能够生成与Softmax注意力非常相似且结构更均衡的注意力分数分布。我们在多项任务中评估了MALA的有效性，包括图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成。我们的MALA在所有这些任务上都取得了强大的结果。代码将在https://github.com/qhfan/MALA提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [674] [3D Test-time Adaptation via Graph Spectral Driven Point Shift](https://arxiv.org/abs/2507.18225)
> *基于图谱驱动点位移的三维测试时间自适应*

*Xin Wei, Qin Yang, Yijie Fang, Mingrui Zhu, Nannan Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 三维点云, 测试时间自适应, 图谱域, 图傅里叶变换, 域偏移

**Comment:** 

> **TL;DR:** 针对三维点云不规则和无序结构的挑战，本文提出GSDTTA，一种在图谱域进行自适应的新方法，通过优化低频分量实现高效且性能更优的三维点云分类。

**AI_Comments:** 本文的创新之处在于将三维测试时间自适应从传统的空间域转移到图谱域。这种方法通过关注全局结构属性并仅优化低频分量，显著提高了自适应的效率，并有效解决了现有方法计算成本高和对额外数据依赖的问题。这对于三维点云的域自适应是一个重要的进展。

<details>
  <summary>Details</summary>

**Motivation:** 虽然测试时间自适应（TTA）方法能有效解决域偏移问题，但由于三维点云不规则和无序的结构，其在三维点云中的应用受阻。当前的3D TTA方法通常依赖于计算成本高昂的空间域优化，并且可能需要额外的训练数据。

**Method:** 本文提出图谱域测试时间自适应（GSDTTA）。它将目标域点云表示为异常值感知图，并通过图傅里叶变换（GFT）转换到图谱域。为了提高效率，自适应仅通过优化最低的10%频率分量来执行。然后应用逆GFT（IGFT）重建自适应后的点云。此过程通过特征图引导的自训练策略得到增强。

**Result:** 在基准数据集上的实验结果和消融研究表明GSDTTA的有效性，其性能优于现有的三维点云分类TTA方法。

**Conclusion:** GSDTTA通过利用图谱域，为三维点云分类提供了一种高效且有效的新方法，其性能优于现有的三维测试时间自适应方法。

> **ai_Abstract:** 本文提出了一种新颖的三维点云测试时间自适应方法——图谱域测试时间自适应（GSDTTA），以解决现有方法在处理三维点云不规则结构时的局限性和高计算成本。GSDTTA将点云表示为异常值感知图，并通过图傅里叶变换在图谱域进行自适应，仅优化捕获大部分能量的最低10%频率分量，从而实现高效的自适应。随后通过逆GFT重建点云，并辅以特征图引导的自训练策略。实验结果表明，GSDTTA在三维点云分类任务上优于现有方法。

> **摘要翻译:** 虽然测试时间自适应（TTA）方法通过在在线推理期间将预训练模型动态适应目标域数据来有效解决域偏移问题，但由于三维点云不规则和无序的结构，其在三维点云中的应用受到阻碍。当前的3D TTA方法通常依赖于计算成本高昂的空间域优化，并且可能需要额外的训练数据。与此不同，我们提出了图谱域测试时间自适应（GSDTTA），这是一种用于三维点云分类的新颖方法，它将自适应转移到图谱域，通过捕获全局结构属性并使用更少的参数来实现更高效的自适应。目标域中的点云被表示为异常值感知图，并通过图傅里叶变换（GFT）转换为图谱域。为了提高效率，自适应仅通过优化最低的10%频率分量来执行，这些分量捕获了点云的大部分能量。然后应用逆GFT（IGFT）重建经过图谱驱动点位移自适应后的点云。此过程通过特征图引导的自训练策略得到增强，该策略迭代地细化谱调整和模型参数。在基准数据集上的实验结果和消融研究表明，GSDTTA的有效性，其性能优于现有的三维点云分类TTA方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [677] [Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification](https://arxiv.org/abs/2507.01884)
> *基于双知识协作的自增强原型演化半监督终身行人重识别*

*Kunlun Xu, Fan Zhuo, Jiangmeng Li, Xu Zou, Jiahuan Zhou* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 半监督终身行人重识别, 原型演化, 双知识协作, 伪标签, 噪声知识

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出SPRED框架，通过自增强原型演化和双知识协作解决半监督终身行人重识别中的噪声知识问题，并实现了SOTA性能。

**AI_Comments:** 该论文开创性地研究了半监督终身行人重识别（Semi-LReID）问题，具有重要的实际意义。其提出的自增强循环和双知识协作机制，在处理终身学习环境中未标注数据的噪声问题方面具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有终身行人重识别方法主要依赖全标注数据流，但在标注资源有限的实际场景中，大量未标注数据与少量标注样本并存，导致半监督终身行人重识别（Semi-LReID）问题。现有方法即使结合半监督策略，也因难以处理未标注数据中的噪声知识而导致长期适应性受限。

**Method:** 本文开创性地研究Semi-LReID，并提出SPRED框架。其关键创新在于建立动态原型引导的伪标签生成与新旧知识协作净化之间的自增强循环，以增强未标注数据利用率。具体而言，引入可学习的身份原型动态捕获身份分布并生成高质量伪标签，然后双知识协作方案整合当前模型特化和历史模型泛化以提炼噪声伪标签。这种循环设计逐步挖掘可靠伪标签，改善当前阶段学习并确保长期学习中的积极知识传播。

**Result:** 在已建立的Semi-LReID基准测试中，SPRED实现了最先进的性能。

**Conclusion:** 本文通过提出SPRED框架，成功解决了半监督终身行人重识别（Semi-LReID）问题，该框架通过自增强机制有效利用未标注数据，并实现了最先进的性能。

> **ai_Abstract:** SPRED是一种新颖的半监督终身行人重识别（Semi-LReID）框架，旨在解决未标注数据中的噪声问题。它通过自增强循环实现，该循环包括动态原型引导的伪标签生成和双知识协作（整合当前模型特化和历史模型泛化）以净化伪标签。这种方法逐步挖掘可靠伪标签，改善学习并确保知识的积极传播，从而在Semi-LReID基准测试中取得了最先进的性能。

> **摘要翻译:** 当前终身行人重识别（LReID）方法主要依赖于完全标注的数据流。然而，在标注资源有限的现实场景中，大量未标注数据与稀缺的标注样本并存，导致了半监督终身行人重识别（Semi-LReID）问题，在该问题下LReID方法的性能严重下降。现有的LReID方法，即使结合半监督策略，也因难以处理未标注数据利用过程中出现的噪声知识而导致长期适应性能受限。在本文中，我们开创性地研究了Semi-LReID问题，并引入了一种新颖的基于双知识协作的自增强原型演化框架（SPRED）。我们的关键创新在于建立动态原型引导的伪标签生成与新旧知识协作净化之间的自增强循环，以增强未标注数据的利用率。具体而言，引入了可学习的身份原型来动态捕获身份分布并生成高质量的伪标签。然后，双知识协作方案整合了当前模型特化和历史模型泛化，以提炼噪声伪标签。通过这种循环设计，可靠的伪标签被逐步挖掘，以改善当前阶段的学习并确保长期学习中积极的知识传播。在已建立的Semi-LReID基准测试中，我们的SPRED实现了最先进的性能。我们的源代码可在https://github.com/zhoujiahuan1991/ICCV2025-SPRED获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [689] [Leveraging the Structure of Medical Data for Improved Representation Learning](https://arxiv.org/abs/2507.02987)
> *利用医学数据结构改进表示学习*

*Andrea Agostini, Sonia Laguna, Alain Ryser, Samuel Ruiperez-Campillo, Moritz Vandenhirtz, Nicolas Deperrois, Farhad Nooralahzadeh, Michael Krauthammer, Thomas M. Sutter, Julia E. Vogt* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 医学AI, 表示学习, 自监督学习, 医学数据结构, 预训练

**Comment:** 

> **TL;DR:** 本文提出了一种自监督框架，通过利用医学数据（如多视图X射线）的固有结构，在数据稀缺但结构化的领域进行有效的表示学习，并在MIMIC-CXR数据集上取得了优异性能。

**AI_Comments:** 该论文的创新之处在于提出了一种新颖的自监督学习框架，专门针对医学数据的特性，即数据稀缺但具有丰富的内部结构（如多视图图像）。通过将配对的X射线视图视为自然阳性对，并结合重建和嵌入对齐，有效学习了信息表示，避免了对稀缺文本标注的依赖。其重要性在于为医学领域中数据受限的预训练提供了一个可行的、轻量级的通用蓝图，具有良好的泛化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 构建可泛化的医学AI系统需要数据高效且领域感知的预训练策略。与互联网规模语料库不同，临床数据集（如MIMIC-CXR）图像数量有限且标注稀缺，但通过多视图成像展现出丰富的内部结构。

**Method:** 我们提出了一个自监督框架，利用医学数据集的固有结构。具体来说，我们将配对的胸部X射线（即，正面和侧面视图）视为自然的阳性对，学习从稀疏补丁重建每个视图，同时对齐它们的潜在嵌入。我们的方法不需要文本监督。

**Result:** 在MIMIC-CXR数据集上的评估表明，与有监督目标和未利用结构训练的基线相比，我们的方法表现出强大的性能，并产生了信息丰富的表示。

**Conclusion:** 这项工作为数据结构化但稀缺的领域特定预训练提供了一个轻量级、模态无关的蓝图。

> **ai_Abstract:** 本文提出了一种自监督框架，旨在解决医学AI系统中数据稀缺但结构丰富的挑战。该方法将配对的多视图医学图像（如胸部X射线）视为自然阳性对，通过从稀疏补丁重建视图并对齐潜在嵌入来学习表示，无需文本监督。在MIMIC-CXR数据集上的实验证明，该方法在不利用外部监督的情况下，性能优于传统有监督方法和未利用结构训练的基线，为领域特定的预训练提供了一种轻量级且模态无关的解决方案。

> **摘要翻译:** 构建可泛化的医学AI系统需要数据高效且领域感知的预训练策略。与互联网规模语料库不同，临床数据集（如MIMIC-CXR）图像数量有限且标注稀缺，但通过多视图成像展现出丰富的内部结构。我们提出了一种自监督框架，利用医学数据集的固有结构。具体来说，我们将配对的胸部X射线（即，正面和侧面视图）视为自然的阳性对，学习从稀疏补丁重建每个视图，同时对齐它们的潜在嵌入。我们的方法不需要文本监督，并产生信息丰富的表示。在MIMIC-CXR数据集上的评估表明，与有监督目标和未利用结构训练的基线相比，我们展示了强大的性能。这项工作为数据结构化但稀缺的领域特定预训练提供了一个轻量级、模态无关的蓝图。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [693] [NLML-HPE: Head Pose Estimation with Limited Data via Manifold Learning](https://arxiv.org/abs/2507.18429)
> *NLML-HPE：通过流形学习在有限数据下进行头部姿态估计*

*Mahdi Ghafourian, Federico M. Sukno* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 头部姿态估计, 流形学习, 张量分解, 有限数据, 深度学习

**Comment:** 

> **TL;DR:** NLML-HPE提出了一种基于非线性流形学习的深度学习方法，用于在有限训练数据下进行头部姿态估计，将姿态估计视为回归问题，并实现了实时性能。

**AI_Comments:** 该论文的创新点在于提出了NLML-HPE，一种结合非线性流形学习和张量分解的深度学习方法，将头部姿态估计从分类问题转化为回归问题。其重要性体现在解决了传统HPE方法在有限数据下性能不佳以及数据集标注不准确的挑战。通过生成精确数据集和优化模型结构，实现了在有限数据下的实时高性能，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 头部姿态估计在人机交互和面部识别等计算机视觉应用中至关重要。现有的头部姿态估计数据集普遍存在不正确和不准确的姿态标注问题，且难以在有限数据下实现高效性能。

**Method:** 本文提出了一种名为NLML-HPE的新型深度学习方法，通过非线性流形学习在有限训练数据下进行头部姿态估计。该方法结合了张量分解（即Tucker分解）和前馈神经网络，将头部姿态估计公式化为回归问题，将输入地标映射到姿态角度的连续表示。具体而言，该方法使用张量分解将每个欧拉角（偏航、俯仰、滚动）分解到单独的子空间中，并将底层流形的每个维度建模为余弦曲线。为了解决数据标注问题，研究者通过旋转3D头部模型并渲染相应的2D图像，生成了一个精确且一致的2D头部姿态数据集用于训练。

**Result:** NLML-HPE在有限训练数据下实现了实时性能，能够准确捕捉物体从面部地标旋转的本质。一旦学习了围绕每个轴旋转的底层流形，模型在预测未见数据时速度非常快。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种名为NLML-HPE的新型深度学习方法，旨在解决有限训练数据下的头部姿态估计问题。该方法结合了张量分解和前馈神经网络，将姿态估计视为回归任务，通过将面部地标映射到连续的姿态角度表示来实现。它通过将欧拉角分解到单独的子空间并将流形维度建模为余弦曲线来捕捉旋转本质。为解决数据标注不准确问题，研究者生成了一个精确的2D头部姿态数据集。NLML-HPE在有限数据下实现了实时性能和快速预测。

> **摘要翻译:** 头部姿态估计（HPE）在人机交互和面部识别等各种计算机视觉应用中扮演着关键角色。在本文中，我们提出了一种新颖的深度学习方法，名为NLML-HPE，通过非线性流形学习在有限训练数据下进行头部姿态估计。该方法基于张量分解（即Tucker分解）和前馈神经网络的结合。与传统的基于分类的方法不同，我们的方法将头部姿态估计公式化为一个回归问题，将输入地标映射到姿态角度的连续表示。为此，我们的方法使用张量分解将每个欧拉角（偏航、俯仰、滚动）分解到单独的子空间中，并将底层流形的每个维度建模为余弦曲线。我们解决了两个关键挑战：1. 几乎所有HPE数据集都存在不正确和不准确的姿态标注。因此，我们通过旋转3D头部模型以固定姿态并渲染相应的2D图像，为我们的训练集生成了一个精确且一致的2D头部姿态数据集。2. 我们的方法在有限训练数据下实现了实时性能，因为它准确地捕捉了物体从面部地标旋转的本质。一旦学习了围绕每个轴旋转的底层流形，模型在预测未见数据时速度非常快。我们的训练和测试代码以及训练好的模型可在网上获取：https://github.com/MahdiGhafoorian/NLML_HPE。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [697] [Enhancing Scene Transition Awareness in Video Generation via Post-Training](https://arxiv.org/abs/2507.18046)
> *通过后期训练增强视频生成中的场景转换感知*

*Hanwen Shen, Jiajie Lu, Yupeng Cao, Xiaonan Yang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视频生成, 场景转换, 后期训练, TAV数据集, 多场景视频

**Comment:** 

> **TL;DR:** 本文提出TAV数据集并通过后期训练，以提高AI视频模型在多场景生成中对场景转换的理解能力。

**AI_Comments:** 本文通过引入专门的TAV数据集并采用后期训练的方法，有效地解决了现有视频生成模型在处理复杂场景转换时的核心痛点。其创新之处在于通过数据驱动的方式，弥补了现有模型在多场景理解上的不足，对于提升AI生成视频的实用性和连贯性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI视频生成模型在生成包含连贯场景转换的长视频时表现不佳，主要因为它们无法从提示中推断何时需要转换。大多数开源模型在单场景视频剪辑数据集上训练，限制了其学习和响应需要多场景提示的能力。

**Method:** 本文提出了Transition-Aware Video (TAV) 数据集，该数据集包含经过预处理的具有多个场景转换的视频剪辑。通过在TAV数据集上进行后期训练。

**Result:** 实验表明，在TAV数据集上进行后期训练可以改善基于提示的场景转换理解，缩小所需场景与生成场景之间的差距，并保持图像质量。

**Conclusion:** 通过在TAV数据集上进行后期训练，可以有效提升视频生成模型对场景转换的感知能力，从而更好地生成多场景视频。

> **ai_Abstract:** 本文针对现有AI视频生成模型在处理多场景视频转换时的不足，提出了一种名为Transition-Aware Video (TAV) 的数据集。通过在TAV数据集上进行后期训练，模型能够增强对场景转换的理解，有效减少生成视频与提示需求之间的差距，同时保持良好的图像质量，从而提升长视频的连贯性。

> **摘要翻译:** 最近AI生成视频的进展在文本到视频任务上表现出强大的性能，特别是对于描绘单一场景的短视频。然而，当前模型难以生成具有连贯场景转换的更长视频，主要是因为它们无法从提示中推断何时需要转换。大多数开源模型在由单场景视频剪辑组成的数据集上进行训练，这限制了它们学习和响应需要多场景提示的能力。发展场景转换感知对于多场景生成至关重要，因为它允许模型通过准确检测转换来识别视频并将其分割成不同的剪辑。
为了解决这个问题，我们提出了Transition-Aware Video (TAV) 数据集，该数据集由包含多个场景转换的预处理视频剪辑组成。我们的实验表明，在TAV数据集上进行后期训练可以改善基于提示的场景转换理解，缩小所需场景与生成场景之间的差距，并保持图像质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [700] [HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation](https://arxiv.org/abs/2507.18575)
> *HybridTM：结合Transformer和Mamba用于3D语义分割*

*Xinyu Wang, Jinghua Hou, Zhe Liu, Yingying Zhu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D语义分割, Transformer, Mamba, 混合架构, 点云

**Comment:** 7 pages, 5 figures

> **TL;DR:** 本文提出了HybridTM，一个结合了Transformer和Mamba的混合架构，用于3D语义分割，解决了现有方法在处理长距离依赖和特征表示上的局限性，并在多个基准测试中取得了最先进的性能。

**AI_Comments:** 这篇论文的创新点在于首次提出了结合Transformer和Mamba的混合架构HybridTM，以解决3D语义分割中长距离依赖和特征表示的挑战。通过引入Inner Layer Hybrid Strategy，该方法能够更精细地融合两种模型的优势，具有重要的理论和实践意义。其在多个基准测试中达到SOTA性能，证明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** Transformer在3D语义分割中具有强大的注意力机制，但其二次复杂度限制了在大规模点云中建模长距离依赖。Mamba方法虽然效率高，具有线性复杂度，但在提取3D特征时难以进行有效的特征表示。因此，如何有效结合两者的优势是一个开放的挑战。

**Method:** 本文提出了HybridTM，这是第一个将Transformer和Mamba集成的混合架构，用于3D语义分割。此外，还提出了Inner Layer Hybrid Strategy，以更细的粒度结合注意力和Mamba，从而同时捕获长距离依赖和细粒度局部特征。

**Result:** 广泛的实验证明了HybridTM在各种室内和室外数据集上的有效性和泛化能力。此外，HybridTM在ScanNet、ScanNet200和nuScenes基准测试中取得了最先进的性能。

**Conclusion:** HybridTM通过有效结合Transformer和Mamba的优势，成功解决了3D语义分割中长距离依赖建模和特征表示的挑战，并在多个基准测试中实现了卓越的性能。

> **ai_Abstract:** 本文提出HybridTM，一个创新的混合架构，首次将Transformer和Mamba集成应用于3D语义分割。针对Transformer在长距离依赖上的复杂度和Mamba在特征表示上的不足，HybridTM通过引入Inner Layer Hybrid Strategy，实现了同时捕捉长距离依赖和细粒度局部特征的能力。实验证明，该方法在多个室内外数据集上表现出优异的有效性和泛化能力，并在ScanNet、ScanNet200和nuScenes等基准测试中达到了最先进的性能。

> **摘要翻译:** 基于Transformer的方法通过其强大的注意力机制在3D语义分割中展现出卓越的能力，但其二次复杂度限制了它们在大规模点云中建模长距离依赖。虽然最近基于Mamba的方法提供了线性复杂度的有效处理，但它们在提取3D特征时难以进行特征表示。然而，有效结合这些互补优势仍然是该领域的一个开放挑战。在本文中，我们提出了HybridTM，这是第一个将Transformer和Mamba集成的混合架构，用于3D语义分割。此外，我们提出了Inner Layer Hybrid Strategy，它以更细的粒度结合注意力和Mamba，从而能够同时捕获长距离依赖和细粒度局部特征。广泛的实验证明了我们的HybridTM在各种室内和室外数据集上的有效性和泛化能力。此外，我们的HybridTM在ScanNet、ScanNet200和nuScenes基准测试中取得了最先进的性能。代码将可在https://github.com/deepinact/HybridTM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [701] [Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps](https://arxiv.org/abs/2507.03737)
> *具有全局尺度一致性3D高斯点图的室外单目SLAM*

*Chong Cheng, Sicheng Yu, Zijian Wang, Yifan Zhou, Hao Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D高斯泼溅, 单目SLAM, 尺度一致性, 室外场景, 实时

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出S3PO-GS，一种鲁棒的RGB单目室外3DGS SLAM方法，通过自洽跟踪模块和基于补丁的点图动态映射，解决了传统方法在室外场景中缺乏几何先验和尺度漂移的问题，实现了高精度跟踪和高质量重建。

**AI_Comments:** 该论文通过引入自洽跟踪模块和基于补丁的点图动态映射，创新性地解决了室外单目3DGS SLAM中长期存在的尺度漂移和几何先验缺乏问题。其方法不仅提高了跟踪精度和场景重建质量，还特别适用于复杂的室外环境，展现了其在实际应用中的重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3DGS SLAM方法在室外场景中存在挑战：一些方法缺乏几何先验，另一些则在相机大幅移动时累积误差导致尺度漂移。

**Method:** 本文提出S3PO-GS，一种鲁棒的RGB单目室外3DGS SLAM方法。技术上，它建立了一个锚定在3DGS点图中的自洽跟踪模块，避免了累积尺度漂移，并实现了更精确和鲁棒的跟踪。此外，它设计了一个基于补丁的点图动态映射模块，引入了几何先验，同时避免了尺度模糊性。

**Result:** 在Waymo、KITTI和DL3DV数据集上的实验表明，S3PO-GS在新颖视图合成方面达到了最先进的结果，并在跟踪精度方面优于其他3DGS SLAM方法。

**Conclusion:** S3PO-GS通过其创新的自洽跟踪和基于补丁的动态映射模块，成功解决了室外单目3DGS SLAM中几何先验缺乏和尺度漂移的问题，并在新颖视图合成和跟踪精度上取得了卓越表现。

> **ai_Abstract:** 本文提出S3PO-GS，一种针对室外单目3DGS SLAM的鲁棒RGB方法。它通过在3DGS点图上建立自洽跟踪模块，有效避免了尺度漂移，并利用基于补丁的点图动态映射引入几何先验，解决了现有方法在室外场景中缺乏先验和累积误差的问题。实验证明，S3PO-GS在新颖视图合成和跟踪精度方面均达到最先进水平。

> **摘要翻译:** 3D高斯泼溅（3DGS）因其高保真度和实时新颖视图合成性能，已成为SLAM领域流行的解决方案。然而，一些以前的3DGS SLAM方法采用可微分渲染管道进行跟踪，在室外场景中缺乏几何先验。其他方法引入了独立的跟踪模块，但它们在相机大幅移动时会累积误差，导致尺度漂移。为了解决这些挑战，我们提出了一种鲁棒的仅RGB室外3DGS SLAM方法：S3PO-GS。技术上，我们建立了一个锚定在3DGS点图中的自洽跟踪模块，这避免了累积尺度漂移，并以更少的迭代实现了更精确和鲁棒的跟踪。此外，我们设计了一个基于补丁的点图动态映射模块，该模块引入了几何先验，同时避免了尺度模糊性。这显著提高了跟踪精度和场景重建质量，使其特别适用于复杂的室外环境。我们在Waymo、KITTI和DL3DV数据集上的实验表明，S3PO-GS在新颖视图合成方面取得了最先进的结果，并在跟踪精度方面优于其他3DGS SLAM方法。项目页面：https://3dagentworld.github.io/S3PO-GS/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [703] [3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation](https://arxiv.org/abs/2507.18625)
> *由约束表达中间表示引导的3D软件合成*

*Shuqing Li, Anson Y. Lam, Yun Peng, Wenxuan Wang, Michael R. Lyu* | **Category: cs.CV, cs.AI, cs.MM, cs.SE** | **Updated: 2025-07-24**

**Keywords:** 3D软件合成, 中间表示, 约束表达, 领域特定语言, 用户界面

**Comment:** 

> **TL;DR:** 本文提出了Scenethesis，一个基于约束感知中间表示ScenethesisLang的3D软件合成方法，解决了现有方法在处理复杂约束和细粒度控制方面的不足，并显著提高了合成准确性和约束满足率。

**AI_Comments:** 本文的创新点在于引入了ScenethesisLang作为约束表达的中间表示，有效解决了3D软件合成中长期存在的复杂性和精细控制难题。其分阶段的方法论也提升了合成过程的可验证性和可修改性。这对于未来3D UI和沉浸式环境的自动化构建具有重要意义，尤其是在处理多模态和复杂场景需求时。

<details>
  <summary>Details</summary>

**Motivation:** 现有2D软件生成已取得成功，但3D软件生成仍未充分探索。当前3D生成方法通常将3D环境作为一个整体生成，无法修改或控制特定元素，且难以处理复杂的空间和语义约束。

**Method:** 本文提出了Scenethesis，一种新颖的需求敏感型3D软件合成方法。Scenethesis建立在ScenethesisLang之上，这是一种领域特定语言，作为粒度约束感知的中间表示（IR），用于连接自然语言需求和可执行3D软件。ScenethesisLang既是全面的场景描述语言，能够对3D软件元素进行细粒度修改，又是一种形式化的约束表达规范语言，能够表达复杂的空间约束。通过将3D软件合成分解为在ScenethesisLang上操作的阶段，Scenethesis实现了独立验证、目标修改和系统约束满足。

**Result:** Scenethesis能准确捕获超过80%的用户需求，满足90%以上的硬约束，同时处理100多个约束。与最先进的方法相比，BLIP-2视觉评估分数提高了42.8%。

**Conclusion:** Scenethesis通过其创新的约束表达中间表示，有效解决了3D软件合成中的复杂性问题，显著提升了合成质量和约束满足能力。

> **ai_Abstract:** 本文提出了Scenethesis，一种用于3D软件合成的新方法，旨在解决现有方法在细粒度控制和处理复杂空间/语义约束方面的不足。Scenethesis的核心是ScenethesisLang，一个作为约束感知中间表示的领域特定语言，它能够将自然语言需求转化为可执行的3D软件，并支持对3D元素进行精细修改和表达复杂约束。通过这种分阶段的方法，Scenethesis实现了高效的验证和修改。实验结果表明，Scenethesis在用户需求捕获、硬约束满足以及视觉评估方面均表现出色，显著优于现有技术。

> **摘要翻译:** 图形用户界面（UI）软件已经从传统的二维（2D）桌面/网络/移动界面发生了根本性的转变，转向空间三维（3D）环境。虽然现有工作在自动化2D软件生成，如HTML/CSS和移动应用界面代码合成方面取得了显著成功，但3D软件的生成仍然有待探索。当前的3D软件生成方法通常将3D环境作为一个整体生成，无法修改或控制软件中的特定元素。此外，这些方法难以处理现实世界中固有的复杂空间和语义约束。为了解决这些挑战，我们提出了Scenethesis，一种新颖的需求敏感型3D软件合成方法，该方法在用户规范和生成的3D软件之间保持形式化的可追溯性。Scenethesis建立在ScenethesisLang之上，这是一种领域特定语言，作为粒度约束感知的中间表示（IR），用于连接自然语言需求和可执行3D软件。它既是一种全面的场景描述语言，能够对3D软件元素进行细粒度修改，又是一种形式化的约束表达规范语言，能够表达复杂的空间约束。通过将3D软件合成分解为在ScenethesisLang上操作的阶段，Scenethesis实现了独立验证、目标修改和系统约束满足。我们的评估表明，Scenethesis准确捕获了超过80%的用户需求，满足了90%以上的硬约束，同时处理了100多个约束。此外，与最先进的方法相比，Scenethesis在BLIP-2视觉评估分数方面实现了42.8%的提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [711] [DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception](https://arxiv.org/abs/2507.18237)
> *DATA：协同感知中高质量特征融合的域与时间对齐*

*Chengchang Tian, Jianwei Ma, Yan Huang, Zhanye Chen, Honghao Wei, Hui Zhang, Wei Hong* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 协同感知, 特征融合, 域对齐, 时间对齐, DATA网络

**Comment:** ICCV 2025, accepted as poster. 22 pages including supplementary
  materials

> **TL;DR:** DATA是一种用于协同感知的网络，通过对齐特征来克服域差距和时间错位，实现了最先进的性能。

**AI_Comments:** 本文的创新点在于系统性地解决了协同感知中特征融合所面临的域差距和时间未对齐两大关键挑战，并提出了模块化的解决方案。DATA网络通过其专门设计的CDAM和PTAM模块，有效提升了特征质量，进而显著改善了协同感知的性能和鲁棒性，特别是在复杂和不稳定的实际部署条件下，这对于未来协同感知系统的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 协同感知中特征级融合的有效性严重依赖于输入特征质量。高质量特征的获取面临硬件多样性和部署条件造成的域差距，以及传输延迟造成的时间未对齐问题。这些挑战会累积性地降低协同网络中的特征质量。

**Method:** 本文提出了域与时间对齐（DATA）网络，旨在系统地对齐特征，同时最大化其语义表示以进行融合。具体而言，提出了一个保持一致性的域对齐模块（CDAM），通过近邻区域分层下采样和可观测性约束判别器来减少域差距。此外，还提出了一个渐进式时间对齐模块（PTAM），通过多尺度运动建模和两阶段补偿来处理传输延迟。在对齐特征的基础上，开发了一个实例聚焦特征聚合模块（IFAM）来增强语义表示。

**Result:** 大量实验表明，DATA在三个典型数据集上实现了最先进的性能，并在严重的通信延迟和姿态误差下保持了鲁棒性。

**Conclusion:** DATA网络通过系统地对齐特征并增强语义表示，有效解决了协同感知中域差距和时间未对齐问题，并在多种挑战条件下实现了最先进的性能和鲁棒性。

> **ai_Abstract:** 本文提出了DATA（域与时间对齐）网络，旨在解决协同感知中特征级融合面临的域差距和时间未对齐问题。DATA网络包含三个核心模块：保持一致性的域对齐模块（CDAM）通过分层下采样和判别器减少域差距；渐进式时间对齐模块（PTAM）通过多尺度运动建模处理传输延迟；实例聚焦特征聚合模块（IFAM）增强语义表示。实验证明，DATA在多个数据集上实现了最先进的性能，并在严重通信延迟和姿态误差下保持了鲁棒性。

> **摘要翻译:** 特征级融合通过平衡性能和通信带宽的权衡，在协同感知（CP）中显示出前景。然而，其有效性关键依赖于输入特征质量。高质量特征的获取面临硬件多样性和部署条件造成的域差距，以及传输延迟造成的时间未对齐问题。这些挑战在整个协同网络中会累积性地降低特征质量。在本文中，我们提出了域与时间对齐（DATA）网络，旨在系统地对齐特征，同时最大化其语义表示以进行融合。具体而言，我们提出了一个保持一致性的域对齐模块（CDAM），通过近邻区域分层下采样和可观测性约束判别器来减少域差距。我们进一步提出了一个渐进式时间对齐模块（PTAM），通过多尺度运动建模和两阶段补偿来处理传输延迟。在对齐特征的基础上，开发了一个实例聚焦特征聚合模块（IFAM）来增强语义表示。大量实验表明，DATA在三个典型数据集上实现了最先进的性能，并在严重的通信延迟和姿态误差下保持了鲁棒性。代码将在https://github.com/ChengchangTian/DATA发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [714] [QR-LoRA: Efficient and Disentangled Fine-tuning via QR Decomposition for Customized Generation](https://arxiv.org/abs/2507.04599)
> *QR-LoRA：通过QR分解实现高效解耦微调以进行定制生成*

*Jiahui Yang, Yongjia Ma, Donglin Di, Hao Li, Wei Chen, Yan Xie, Jianxun Cui, Xun Yang, Wangmeng Zuo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** QR分解, LoRA, 微调, 特征解耦, 生成模型

**Comment:** ICCV 2025, 30 pages, 26 figures

> **TL;DR:** QR-LoRA提出了一种基于QR分解的新型微调框架，通过结构化参数更新有效分离视觉属性，解决了现有LoRA模型在内容-风格融合任务中特征纠缠的问题，并实现参数量减半和卓越的解耦性能。

**AI_Comments:** 这篇论文提出了一种新颖的微调方法QR-LoRA，通过引入QR分解来解决LoRA在多模型融合时存在的特征纠缠问题，这是一个重要的创新点。其利用正交矩阵Q和上三角矩阵R的特性来自然地实现特征解耦，并显著减少了可训练参数，这对于资源受限的环境和更高效的模型部署具有重要意义。文章提出的“新范式”预示着未来微调技术可能的发展方向，尤其是在需要精细控制和组合不同视觉属性的生成任务中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像模型，如LoRA，在组合多个模型进行内容-风格融合任务时，由于权重矩阵的非结构化修改，常常导致内容和风格属性之间出现不期望的特征纠缠。

**Method:** QR-LoRA是一种新的微调框架，利用QR分解进行结构化参数更新，以有效分离视觉属性。其核心思想是，正交Q矩阵最小化不同视觉特征间的干扰，而上三角R矩阵高效编码属性特定变换。该方法固定Q和R矩阵，仅训练一个额外的任务特定ΔR矩阵。这种结构化设计将可训练参数减少到传统LoRA方法的一半，并支持有效合并多个适应模型而不会因ΔR矩阵间的强解耦特性而产生交叉污染。

**Result:** 实验表明，QR-LoRA在内容-风格融合任务中实现了卓越的解耦性能，并且可训练参数量减少到传统LoRA方法的一半。

**Conclusion:** QR-LoRA为生成模型中的参数高效、解耦微调建立了一种新范式，显著提升了内容-风格融合任务中的解耦能力。

> **ai_Abstract:** QR-LoRA是一种针对文本到图像模型的新型微调框架，旨在解决现有LoRA模型在内容-风格融合任务中存在的特征纠缠问题。该方法利用QR分解，通过固定Q和R矩阵并仅训练一个任务特定的ΔR矩阵，实现视觉属性的有效分离。QR-LoRA不仅将可训练参数量减少至传统LoRA的一半，还通过其强解耦特性支持无交叉污染的多模型合并。实验证明，它在内容-风格融合任务中展现出卓越的解耦性能，开创了生成模型中参数高效且解耦微调的新范式。

> **摘要翻译:** 现有文本到图像模型通常依赖于参数微调技术，例如低秩适应（LoRA），以定制视觉属性。然而，当组合多个LoRA模型进行内容-风格融合任务时，权重矩阵的非结构化修改常常导致内容和风格属性之间出现不期望的特征纠缠。我们提出了QR-LoRA，一个利用QR分解的新型微调框架，用于结构化参数更新，有效分离视觉属性。我们的关键见解是，正交Q矩阵自然地最小化了不同视觉特征之间的干扰，而上三角R矩阵高效地编码了属性特定的变换。我们的方法固定了Q和R矩阵，同时仅训练一个额外的任务特定ΔR矩阵。这种结构化设计将可训练参数减少到传统LoRA方法的一半，并支持有效合并多个适应模型而不会因ΔR矩阵之间的强解耦特性而产生交叉污染。实验表明，QR-LoRA在内容-风格融合任务中实现了卓越的解耦性能，为生成模型中的参数高效、解耦微调建立了一种新范式。项目页面可在：https://luna-ai-lab.github.io/QR-LoRA/ 访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [728] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
> *融合图像的残差先验驱动频率感知网络*

*Guan Zheng, Xue Wang, Wenhua Qian, Peng Liu, Runzhuo Ma* | **Category: cs.CV, cs.LG, cs.MM** | **Updated: 2025-07-24**

**Keywords:** 图像融合, 残差先验, 频率感知网络, RPFNet, 深度学习

**Comment:** 

> **TL;DR:** 本文提出RPFNet，一个残差先验驱动的频率感知网络，通过结合空间域的残差信息和频域的全局建模，有效解决了图像融合中计算成本高和缺乏真值的问题，提升了融合性能和高级视觉任务的表现。

**AI_Comments:** 本文提出的RPFNet通过结合空间域的残差先验和频域的全局建模，为图像融合提供了一种新颖且高效的解决方案。其创新点在于将模态特异性差异信息作为残差先验引入，并通过频域卷积进行高效的全局特征整合，有效规避了空间域长距离依赖带来的高计算成本。多模块协作（RPM、FDFM、CPM）以及精心设计的损失函数（辅助解码器、显著性结构损失、频率对比损失、SSIM损失）共同确保了模型在捕获局部细节和全局特征方面的能力，同时解决了缺乏真值数据的挑战。该方法在提升融合图像质量的同时，也强调了对高级视觉任务的促进作用，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 图像融合旨在整合跨模态的互补信息以生成高质量的融合图像，从而增强高级视觉任务的性能。然而，全局空间建模机制的计算成本高昂，且缺乏真值使得有效捕获互补特征变得更加困难。

**Method:** 本文提出了一个残差先验驱动的频率感知网络（RPFNet），其采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态特异性差异信息，提供互补先验；频域融合模块（FDFM）通过频域卷积实现高效的全局特征建模和整合。此外，交叉促进模块（CPM）通过双向特征交互增强局部细节和全局结构的协同感知。训练过程中，引入辅助解码器和显著性结构损失以增强模型对模态特异性差异的敏感性，并结合基于自适应权重的频率对比损失和SSIM损失来有效约束解空间，以联合捕获局部细节和全局特征并保留互补信息。

**Result:** 广泛的实验验证了RPFNet的融合性能，它能有效整合判别性特征，增强纹理细节和显著性目标，并能有效促进高级视觉任务的部署。

**Conclusion:** RPFNet通过有效整合判别性特征、增强纹理细节和显著性目标，成功解决了图像融合中的挑战，并能够有效促进高级视觉任务的部署。

> **ai_Abstract:** 本文提出了RPFNet，一个用于图像融合的残差先验驱动频率感知网络，旨在解决传统方法中计算成本高和缺乏真值的问题。RPFNet采用双分支架构，通过残差先验模块（RPM）提取模态特异性差异信息，并通过频域融合模块（FDFM）进行高效的全局特征建模。同时，交叉促进模块（CPM）增强了局部和全局特征的协同感知。结合多种损失函数进行训练，实验证明RPFNet能有效整合判别性特征，增强细节，并促进高级视觉任务的部署。

> **摘要翻译:** 图像融合旨在整合跨模态的互补信息以生成高质量的融合图像，从而增强高级视觉任务的性能。虽然全局空间建模机制显示出有希望的结果，但在空间域中构建长距离特征依赖关系会产生大量的计算成本。此外，缺乏真值加剧了有效捕获互补特征的难度。为了解决这些挑战，我们提出了一个残差先验驱动的频率感知网络，命名为RPFNet。具体而言，RPFNet采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态特异性差异信息，从而为融合提供互补先验；频域融合模块（FDFM）通过频域卷积实现高效的全局特征建模和整合。此外，交叉促进模块（CPM）通过双向特征交互增强局部细节和全局结构的协同感知。在训练过程中，我们引入了一个辅助解码器和显著性结构损失，以增强模型对模态特异性差异的敏感性。此外，结合基于自适应权重的频率对比损失和SSIM损失有效约束了解决方案空间，有助于联合捕获局部细节和全局特征，同时确保互补信息的保留。广泛的实验验证了RPFNet的融合性能，它能有效整合判别性特征，增强纹理细节和显著性目标，并能有效促进高级视觉任务的部署。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [738] [Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions](https://arxiv.org/abs/2507.07464)
> *恶劣天气条件下盲人脸修复的降级无关统计面部特征转换*

*Chang-Hwan Son* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人脸修复, 恶劣天气, GAN, SFFT, DAFE

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于GAN的盲人脸图像修复框架，通过引入局部统计面部特征转换（SFFT）和降级无关特征嵌入（DAFE）模块，显著提升了在恶劣天气下的人脸修复性能，优于现有方法。

**AI_Comments:** 该论文的创新之处在于其明确地通过SFFT和DAFE模块解决了现有GAN和扩散模型在处理天气引起的图像降级方面的不足，这对于提高户外智能监控系统中的人脸识别精度至关重要。其方法针对性强，通过统计分布对齐和特征嵌入，有效改善了面部纹理和结构的修复质量，显示出显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 户外智能CCTV系统对恶劣天气下优化的人脸识别系统需求日益增长。恶劣天气会严重降低图像质量，从而降低识别精度。尽管现有基于GAN和扩散模型的人脸修复（FIR）模型有所进展，但它们缺乏专门处理天气引起的降级的模块，导致面部纹理和结构失真。

**Method:** 本文提出了一种新的基于GAN的盲人脸图像修复框架，该框架集成了两个关键组件：局部统计面部特征转换（SFFT）和降级无关特征嵌入（DAFE）。SFFT模块通过对齐低质量（LQ）面部区域与高质量（HQ）对应区域的局部统计分布，增强面部结构和颜色保真度。DAFE模块通过对齐LQ和HQ编码器表示，实现在恶劣天气条件下鲁棒的统计面部特征提取，使修复过程适应严重的、由天气引起的降级。

**Result:** 实验结果表明，所提出的降级无关SFFT模型优于现有最先进的基于GAN和扩散模型的人脸修复方法，特别是在抑制纹理失真和准确重建面部结构方面。此外，SFFT和DAFE模块都被经验验证能够增强恶劣天气场景下人脸修复的结构保真度和感知质量。

**Conclusion:** 本文提出的基于GAN的盲人脸图像修复框架，通过其集成的SFFT和DAFE模块，有效解决了恶劣天气下人脸图像降级的问题，显著提升了修复质量和结构保真度，超越了现有技术水平。

> **ai_Abstract:** 本文提出了一种名为降级无关统计面部特征转换（SFFT）的新型GAN框架，用于解决恶劣天气下人脸图像修复的挑战。该框架包含两个核心模块：局部SFFT和降级无关特征嵌入（DAFE）。SFFT通过对齐局部统计分布来增强面部结构和颜色，而DAFE则通过对齐编码器表示来实现鲁棒的特征提取，从而使修复过程适应天气降级。实验证明，该方法在抑制纹理失真和重建面部结构方面优于现有SOTA GAN和扩散模型，显著提升了恶劣天气下人脸修复的结构保真度和感知质量。

> **摘要翻译:** 随着智能CCTV系统在户外环境中的部署日益增多，对针对恶劣天气条件优化的人脸识别系统的需求也日益增长。恶劣天气会显著降低图像质量，进而降低识别精度。尽管最近基于生成对抗网络（GAN）和扩散模型的人脸图像修复（FIR）模型已经取得了进展，但由于缺乏专门处理天气引起的降级的模块，其性能仍然有限。这导致了面部纹理和结构的失真。为了解决这些限制，我们提出了一种新颖的基于GAN的盲FIR框架，该框架集成了两个关键组件：局部统计面部特征转换（SFFT）和降级无关特征嵌入（DAFE）。局部SFFT模块通过对齐低质量（LQ）面部区域与高质量（HQ）对应区域的局部统计分布，增强面部结构和颜色保真度。作为补充，DAFE模块通过对齐LQ和HQ编码器表示，实现在恶劣天气条件下鲁棒的统计面部特征提取，从而使修复过程适应严重的、由天气引起的降级。实验结果表明，所提出的降级无关SFFT模型优于现有最先进的基于GAN和扩散模型的人脸修复方法，特别是在抑制纹理失真和准确重建面部结构方面。此外，SFFT和DAFE模块都被经验验证能够增强恶劣天气场景下人脸修复的结构保真度和感知质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [740] [Identifying Prompted Artist Names from Generated Images](https://arxiv.org/abs/2507.18633)
> *从生成图像中识别提示的艺术家名称*

*Grace Su, Sheng-Yu Wang, Aaron Hertzmann, Eli Shechtman, Jun-Yan Zhu, Richard Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 文本到图像模型, 艺术家识别, 图像生成, 基准测试, 风格归属

**Comment:** Project page:
  https://graceduansu.github.io/IdentifyingPromptedArtists

> **TL;DR:** 研究人员创建了一个基准数据集和评估方法，用于从生成的图像中识别提示中引用的艺术家名称，以促进对文本到图像模型的负责任的审核。

**AI_Comments:** 该论文通过构建一个大规模数据集和评估基准，解决了文本到图像模型中一个重要且有争议的问题——艺术家风格归属识别。其创新性在于提出了一个用于评估不同识别方法泛化能力的全面框架，并指出了多艺术家提示识别的挑战性。这项工作对于推进文本到图像模型的版权保护和负责任的内容审核具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像模型中通过明确提及艺术家名称来生成图像是一种常见且有争议的使用方式。本研究旨在为这种提示艺术家识别提供一个基准，以促进文本到图像模型的负责任的审核。

**Method:** 研究引入了一个用于提示艺术家识别的基准。该数据集包含195万张图像，涵盖110位艺术家，并涵盖四种泛化设置：保留艺术家、增加提示复杂性、多艺术家提示和不同的文本到图像模型。评估方法包括特征相似性基线、对比风格描述符、数据归因方法、监督分类器和少样本原型网络。

**Result:** 泛化模式各不相同：监督模型和少样本模型在已见艺术家和复杂提示上表现出色，而风格描述符在艺术家风格明显时迁移效果更好；多艺术家提示仍然是最具挑战性的情况。

**Conclusion:** 该基准揭示了巨大的改进空间，并提供了一个公共测试平台，以推进对文本到图像模型的负责任的审核。数据集和基准已发布以促进进一步研究。

> **ai_Abstract:** 本研究针对文本到图像模型中通过艺术家名称提示生成图像的争议性用途，提出了一个从生成图像中识别所提示艺术家名称的基准。该基准包含一个包含195万张图像的大型数据集，涵盖110位艺术家和四种泛化场景。研究评估了多种识别方法，发现监督和少样本模型在特定条件下表现良好，而多艺术家提示识别仍是主要挑战。该工作旨在为文本到图像模型的负责任审核提供工具和研究基础，并已公开发布数据集和基准。

> **摘要翻译:** 文本到图像模型的一种常见且有争议的用途是通过明确命名艺术家来生成图片，例如“以格雷格·鲁特科夫斯基的风格”。我们引入了一个用于提示艺术家识别的基准：仅根据图像预测提示中调用了哪些艺术家名称。该数据集包含195万张图像，涵盖110位艺术家，并涵盖四种泛化设置：保留艺术家、增加提示复杂性、多艺术家提示和不同的文本到图像模型。我们评估了特征相似性基线、对比风格描述符、数据归因方法、监督分类器和少样本原型网络。泛化模式各不相同：监督模型和少样本模型在已见艺术家和复杂提示上表现出色，而风格描述符在艺术家风格明显时迁移效果更好；多艺术家提示仍然是最具挑战性的。我们的基准揭示了巨大的改进空间，并提供了一个公共测试平台，以推进对文本到图像模型的负责任的审核。我们发布了数据集和基准，以促进进一步研究：https://graceduansu.github.io/IdentifyingPromptedArtists/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [741] [A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area](https://arxiv.org/abs/2507.10084)
> *一种基于迁移学习的遥感影像水体分割方法：以扎达土林地区为例*

*Haonan Chen, Xin Tong* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 迁移学习, 水体分割, 遥感影像, SegFormer, 青藏高原

**Comment:** 13 pages, 6 figures, 2 tables

> **TL;DR:** 本研究提出了一种两阶段迁移学习策略，利用SegFormer模型提高遥感影像中水体分割的精度，并在扎达土林地区实现了显著的性能提升，为水资源管理和防灾减灾提供了高精度地图。

**AI_Comments:** 该论文创新性地将两阶段迁移学习策略应用于遥感影像的水体分割，有效克服了气候敏感地区数据稀缺和领域偏移的难题。其显著的精度提升（IoU从25.50%到64.84%）表明了该方法的强大潜力。此外，研究不仅提供了技术解决方案，还通过高精度地图揭示了水体空间分布的定量发现，这对水资源管理和防灾减灾具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 青藏高原作为“亚洲水塔”，因对气候变化高度敏感而面临严峻的水安全挑战。推进地球观测以实现可持续水资源监测对于该地区的气候韧性建设至关重要。开发用于气候敏感应用的强大AI模型存在领域偏移和数据稀缺的关键障碍。

**Method:** 本研究提出了一种两阶段迁移学习策略，使用SegFormer模型。该模型首先在一个多样化的源域进行预训练，然后针对干旱的扎达土林地区进行微调。

**Result:** 实验结果显示性能显著提升：水体分割的交并比（IoU）从直接迁移的25.50%大幅提高到64.84%。高精度地图揭示水体空间分布高度集中，超过80%的水域面积集中在不到20%的河道长度内。

**Conclusion:** 这种AI驱动的精度对于减少灾害风险至关重要，特别是监测易发山洪的系统。该定量发现为理解水文过程、设计有针对性的水资源管理和气候适应策略提供了关键证据。本工作展示了一种监测干旱高原地区的有效技术解决方案，并有助于推动AI驱动的地球观测在关键跨界河流源头地区灾害准备方面的进展。

> **ai_Abstract:** 本研究提出了一种基于SegFormer模型的两阶段迁移学习策略，以应对遥感影像水体分割中领域偏移和数据稀缺的问题。通过在多样化源域预训练并在干旱的扎达土林地区微调，模型将水体分割的IoU从25.50%提升至64.84%。高精度结果揭示了水体的高度集中分布，为灾害风险管理、水文理解和气候适应策略提供了关键数据和有效技术方案。

> **摘要翻译:** 青藏高原被称为“亚洲水塔”，因其对气候变化的高度敏感性而面临严峻的水安全挑战。因此，推进地球观测以实现可持续水资源监测对于该地区的气候韧性建设至关重要。本研究提出了一种使用SegFormer模型的两阶段迁移学习策略，以克服领域偏移和数据稀缺——这是开发用于气候敏感应用的强大AI模型的关键障碍。在多样化的源域进行预训练后，我们的模型针对干旱的扎达土林地区进行了微调。实验结果显示性能显著提升：水体分割的交并比（IoU）从直接迁移的25.50%大幅提高到64.84%。这种AI驱动的精度对于减少灾害风险至关重要，特别是在监测易发山洪的系统方面。更重要的是，高精度地图揭示了水体高度集中的空间分布，超过80%的水域面积集中在不到20%的河道长度内。这一定量发现为理解水文过程和设计有针对性的水资源管理及气候适应策略提供了关键证据。因此，我们的工作展示了一种监测干旱高原地区的有效技术解决方案，并有助于推动AI驱动的地球观测在关键跨界河流源头地区灾害准备方面的进展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [744] [BokehDiff: Neural Lens Blur with One-Step Diffusion](https://arxiv.org/abs/2507.18060)
> *BokehDiff：基于一步扩散的神经镜头模糊*

*Chengxuan Zhu, Qingnan Fan, Qi Zhang, Jinwei Chen, Huaqi Zhang, Chao Xu, Boxin Shi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 镜头模糊, 扩散模型, 神经渲染, 自注意力, 图像合成

**Comment:** Accepted by ICCV 2025

> **TL;DR:** BokehDiff引入了一种新的镜头模糊渲染方法，利用生成扩散先验，通过物理启发式自注意力模块和一步扩散推理，实现高质量、逼真的模糊效果，解决了传统方法在深度估计上的局限性，并提出了合成数据的方法。

**AI_Comments:** BokehDiff的创新点在于将物理启发式自注意力模块与一步扩散模型相结合，有效解决了传统镜头模糊渲染中深度不连续处的伪影问题。其提出利用扩散模型合成训练数据的方法，也为解决这类任务中数据稀缺的挑战提供了新的思路，具有重要的实践意义和研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统镜头模糊渲染方法受限于深度估计的准确性，在深度不连续处会产生伪影。本文旨在克服这些限制，实现物理精确且视觉吸引人的镜头模糊渲染。

**Method:** BokehDiff采用物理启发式自注意力模块，该模块与图像形成过程对齐，并结合了深度相关的模糊圈约束和自遮挡效应。该方法将扩散模型调整为一步推理方案，无需引入额外噪声。为解决配对数据不足的问题，提出使用扩散模型合成具有透明度的真实感前景。

**Result:** BokehDiff实现了高质量和高保真度的镜头模糊渲染结果，克服了先前方法在深度估计准确性上的局限性，避免了在深度不连续处产生伪影。

**Conclusion:** BokehDiff成功地提供了一种新颖的、物理精确且视觉吸引人的镜头模糊渲染方法，通过结合生成扩散先验、物理启发式模块和一步推理方案，解决了现有方法的缺点，并展示了其在生成高质量结果方面的有效性。

> **ai_Abstract:** BokehDiff提出了一种基于生成扩散先验的新型神经镜头模糊渲染方法，旨在解决传统方法因深度估计不准确而在深度不连续处产生的伪影问题。该方法引入了物理启发式的自注意力模块，结合深度相关的模糊圈约束和自遮挡效应，并采用一步扩散推理方案以实现高质量高保真度的模糊效果。为应对数据稀缺，BokehDiff还提出利用扩散模型合成逼真的透明前景数据，以平衡真实性和多样性。

> **摘要翻译:** 我们引入了BokehDiff，这是一种新颖的镜头模糊渲染方法，借助生成扩散先验，实现了物理精确且视觉吸引人的效果。以前的方法受限于深度估计的准确性，在深度不连续处会产生伪影。我们的方法采用了一个物理启发式的自注意力模块，该模块与图像形成过程对齐，并结合了深度相关的模糊圈约束和自遮挡效应。我们将扩散模型适应于一步推理方案，无需引入额外噪声，并实现了高质量和高保真度的结果。为了解决可扩展配对数据不足的问题，我们提出使用扩散模型合成具有透明度的真实感前景，平衡了真实性和场景多样性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [745] [DepthDark: Robust Monocular Depth Estimation for Low-Light Environments](https://arxiv.org/abs/2507.18243)
> *DepthDark：弱光环境下鲁棒的单目深度估计*

*Longjian Zeng, Zunjie Zhu, Rongfeng Lu, Ming Lu, Bolun Zheng, Chenggang Yan, Anke Xue* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 单目深度估计, 弱光环境, 基础模型, 数据模拟, PEFT

**Comment:** Accepted by ACM MM 2025 conference

> **TL;DR:** 当前单目深度估计方法在弱光环境下效果不佳。DepthDark通过引入数据模拟和参数高效微调（PEFT）策略，解决了弱光下深度估计的鲁棒性问题，并在夜间数据集上取得了最先进的性能。

**AI_Comments:** 本文创新性地解决了弱光环境下深度估计的难题，这对自动驾驶等实际应用至关重要。其通过合成数据生成（眩光和噪声模拟）和专门的PEFT策略（光照引导、多尺度特征融合）双管齐下的方法，有效克服了数据限制并提升了模型鲁棒性。在有限资源下在挑战性夜间数据集上验证了其有效性，凸显了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 当前单目深度估计算法主要针对日光条件，在弱光环境下性能显著下降。主要原因是缺乏大规模、高质量的弱光配对深度数据集和有效的参数高效微调（PEPT）策略。

**Method:** 提出了DepthDark，一个鲁棒的弱光单目深度估计基础模型。首先，引入眩光模拟模块和噪声模拟模块，以准确模拟夜间成像过程，生成高质量的弱光配对深度数据集。其次，提出了一种有效的弱光PEFT策略，该策略利用光照引导和多尺度特征融合来增强模型在弱光环境中的能力。

**Result:** 在具有挑战性的nuScenes-Night和RobotCar-Night数据集上实现了最先进（SOTA）的深度估计性能，并验证了其在有限训练数据和计算资源下的有效性。

**Conclusion:** DepthDark有效解决了弱光单目深度估计的挑战，通过数据模拟和创新的PEFT策略，在有限资源下实现了最先进的性能。

> **ai_Abstract:** 本文提出了DepthDark，一个针对弱光环境下鲁棒单目深度估计的基础模型。为解决弱光数据稀缺和微调策略不足的问题，DepthDark引入了眩光和噪声模拟模块来生成高质量的弱光配对深度数据集。此外，它还提出了一种结合光照引导和多尺度特征融合的有效参数高效微调（PEFT）策略。实验结果表明，DepthDark在nuScenes-Night和RobotCar-Night等挑战性夜间数据集上取得了最先进的深度估计性能，证明了其在有限数据和计算资源下的有效性。

> **摘要翻译:** 近年来，单目深度估计的基础模型受到了越来越多的关注。当前的方法主要针对典型的日光条件，但它们在弱光环境下的有效性显著降低。目前缺乏专门为弱光场景设计的鲁棒单目深度估计基础模型。这主要源于弱光条件下缺乏大规模、高质量的配对深度数据集以及有效的参数高效微调（PEFT）策略。为了解决这些挑战，我们提出了DepthDark，一个用于弱光单目深度估计的鲁棒基础模型。我们首先引入了一个眩光模拟模块和一个噪声模拟模块，以准确模拟夜间条件下的成像过程，从而生成高质量的弱光配对深度数据集。此外，我们提出了一种有效的弱光PEFT策略，该策略利用光照引导和多尺度特征融合来增强模型在弱光环境中的能力。我们的方法在具有挑战性的nuScenes-Night和RobotCar-Night数据集上实现了最先进的深度估计性能，验证了其使用有限训练数据和计算资源的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [754] [PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior](https://arxiv.org/abs/2507.18447)
> *PDB-Eval：大型多模态模型在个性化驾驶行为描述与解释方面的评估*

*Junda Wu, Jessica Echterhoff, Kyungtae Han, Amr Abdelraouf, Rohit Gupta, Julian McAuley* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 大型多模态模型, 个性化驾驶行为, 基准, PDB-Eval, 驾驶辅助

**Comment:** 

> **TL;DR:** 本文介绍了PDB-Eval，一个用于评估和校准大型多模态模型（MLLMs）在个性化驾驶行为理解和推理方面的基准，包含PDB-X（时间驾驶场景理解）和PDB-QA（视觉解释问答），实验证明其能显著提升MLLMs在驾驶领域的性能。

**AI_Comments:** 本文提出PDB-Eval这一创新性基准，特别是其PDB-X和PDB-QA组件，旨在弥合大型多模态模型（MLLMs）与复杂个性化驾驶行为理解之间的领域差距。通过专注于从外部视觉证据解释内部驾驶员行为，该工作为提升驾驶辅助系统和事故预防提供了重要途径。实验结果表明，该方法在提升MLLMs在驾驶相关任务中的性能方面非常有效，具有重要的实际应用价值。摘要中未明确提及限制。

<details>
  <summary>Details</summary>

**Motivation:** 理解驾驶员行为和意图对于风险评估和事故预防至关重要。现有数据集在基于外部视觉证据描述和解释一般车辆运动方面存在局限性，导致安全和驾驶辅助系统难以针对个体驾驶员行为进行定制。

**Method:** 本文引入了PDB-Eval基准，用于详细理解个性化驾驶行为，并使大型多模态模型（MLLMs）与驾驶理解和推理对齐。该基准包含PDB-X和PDB-QA两个主要组件。PDB-X用于评估MLLMs对时间驾驶场景的理解，旨在从外部视角寻找有效的视觉证据来解释驾驶员的内部行为。PDB-QA被提出作为视觉解释问答任务，用于MLLM指令微调，以弥合领域差距而不损害MLLMs的通用性。

**Result:** 微调MLLMs在细粒度描述和解释上能有效弥合MLLMs与驾驶领域之间的差距，使问答任务的零样本性能提高高达73.2%。在Brain4Cars的转向意图预测任务中观察到高达12.5%的性能提升。在AIDE的所有任务中，性能持续提升高达11.0%。

**Conclusion:** PDB-Eval基准及其组件（PDB-X和PDB-QA）成功地评估并提升了大型多模态模型（MLLMs）理解和解释个性化驾驶行为的能力，在相关任务中取得了显著的性能提升。

> **ai_Abstract:** 本文介绍了PDB-Eval，一个旨在评估和增强大型多模态模型（MLLMs）在理解和解释个性化驾驶行为方面的能力的新基准。PDB-Eval包含PDB-X（用于评估时间驾驶场景理解）和PDB-QA（一个用于MLLM微调的视觉解释问答任务）。研究表明，使用PDB-Eval对MLLMs进行微调能显著提升其在驾驶领域的性能，在零样本问答任务中表现提升高达73.2%，并在驾驶员意图预测和识别任务中取得显著进步。

> **摘要翻译:** 理解驾驶员的行为和意图对于潜在的风险评估和早期事故预防至关重要。安全和驾驶辅助系统可以根据个体驾驶员的行为进行定制，从而显著增强其有效性。然而，现有数据集在基于外部视觉证据描述和解释一般车辆运动方面存在局限性。本文引入了一个基准PDB-Eval，用于详细理解个性化驾驶行为，并使大型多模态模型（MLLMs）与驾驶理解和推理对齐。我们的基准由两个主要组件组成：PDB-X和PDB-QA。PDB-X可以评估MLLMs对时间驾驶场景的理解。我们的数据集旨在从外部视角寻找有效的视觉证据来解释驾驶员的内部行为。为了使MLLMs的推理能力与驾驶任务对齐，我们提出了PDB-QA作为视觉解释问答任务，用于MLLM指令微调。作为像MLLMs这样的生成模型的通用学习任务，PDB-QA可以在不损害MLLMs通用性的情况下弥合领域差距。我们的评估表明，在细粒度描述和解释上对MLLMs进行微调可以有效弥合MLLMs与驾驶领域之间的差距，这将问答任务的零样本性能提高了高达73.2%。我们进一步评估了在PDB-X上微调的MLLMs在Brain4Cars的意图预测和AIDE的识别任务中的表现。我们观察到在Brain4Cars的转向意图预测任务中性能提高了高达12.5%，并且在AIDE的所有任务中性能持续提高了高达11.0%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [755] [ViLU: Learning Vision-Language Uncertainties for Failure Prediction](https://arxiv.org/abs/2507.07620)
> *ViLU：学习视觉-语言不确定性以进行故障预测*

*Marc Lafon, Yannis Karmim, Julio Silva-Rodríguez, Paul Couairon, Clément Rambour, Raphaël Fournier-Sniehotta, Ismail Ben Ayed, Jose Dolz, Nicolas Thome* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉-语言模型, 不确定性量化, 故障预测, 多模态学习, 后处理

**Comment:** 

> **TL;DR:** ViLU是一个新的视觉-语言不确定性量化框架，通过利用所有任务相关的文本表示来预测视觉-语言模型的故障，并在多种数据集上取得了显著优于现有方法的效果。

**AI_Comments:** ViLU的创新之处在于其损失无关的故障预测方法，将其建模为一个二元分类问题，而非依赖于损失预测，这使其更具通用性。此外，其在后处理设置下的适用性，即无需直接访问原始模型即可进行不确定性量化，极大地拓展了其实用场景。通过整合多模态信息来构建不确定性表示，也提升了预测的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）的可靠不确定性量化（UQ）和故障预测仍然是开放的挑战。

**Method:** ViLU通过整合视觉嵌入、预测的文本嵌入和图像条件文本表示（通过交叉注意力）构建了一个不确定性感知的多模态表示。它将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确和不正确的预测，使其与损失无关。该方法特别适用于仅有视觉和文本嵌入而无法直接访问模型本身的后处理设置。

**Result:** 在ImageNet-1k、CC12M和LAION-400M等多样化数据集上的大量实验表明，ViLU相比最先进的故障预测方法取得了显著的性能提升。消融研究强调了其架构和训练在实现有效不确定性量化方面的关键作用。

**Conclusion:** ViLU框架通过其创新的多模态表示和损失无关的二元分类器方法，有效地解决了视觉-语言模型的不确定性量化和故障预测问题，并在多种应用场景中展现出优越的性能。

> **ai_Abstract:** ViLU是一个旨在解决视觉-语言模型（VLMs）不确定性量化和故障预测挑战的新框架。它通过整合视觉和多源文本表示构建不确定性感知的多模态特征，并训练一个损失无关的二元分类器来区分预测的正确性。该方法尤其适用于后处理场景。实验证明，ViLU在多个数据集上均显著优于现有最先进的故障预测方法，其架构和训练方式对有效的不确定性量化至关重要。

> **摘要翻译:** 可靠的不确定性量化（UQ）和故障预测对于视觉-语言模型（VLMs）来说仍然是开放的挑战。我们引入了ViLU，一个全新的视觉-语言不确定性量化框架，它通过利用所有任务相关的文本表示来情境化不确定性估计。ViLU通过整合视觉嵌入、预测的文本嵌入以及通过交叉注意力获得的图像条件文本表示，构建了一个不确定性感知的多模态表示。与基于损失预测的传统UQ方法不同，ViLU将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确和不正确的预测，使其与损失无关。特别地，我们提出的方法非常适用于后处理设置，即只有视觉和文本嵌入可用，而无法直接访问模型本身。在各种数据集上的广泛实验表明，我们的方法与最先进的故障预测方法相比取得了显著的提升。我们将我们的方法应用于标准分类数据集，如ImageNet-1k，以及大规模图像-标题数据集，如CC12M和LAION-400M。消融研究强调了我们的架构和训练在实现有效不确定性量化方面的关键作用。我们的代码是公开的，可以在这里找到：https://github.com/ykrmm/ViLU。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [759] [Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy](https://arxiv.org/abs/2507.18135)
> *基于信息熵的睑板腺不均匀萎缩弯曲度量化框架*

*Kesheng Wang, Xiaoyu Chen, Chunlei He, Fenfen Li, Xinxin Yu, Dexing Kong, Shoujun Huang, Qi Dai* | **Category: cs.CV, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 信息熵, 弯曲度量化, 睑板腺萎缩, 医学图像分析, 参考曲线

**Comment:** This manuscript contains 7 figures. All comments are welcome

> **TL;DR:** 本研究提出了一种基于信息熵的曲线弯曲度量化新框架，通过与参考曲线比较而非理想直线来评估弯曲度，并在睑板腺萎缩均匀性评估中验证了其有效性和临床实用性。

**AI_Comments:** 该研究的创新之处在于引入了信息熵和参考曲线对比的概念来量化曲线弯曲度，这为医学图像分析提供了一种更符合生物学实际且更鲁棒的评估方法。其在睑板腺萎缩评估中的应用展示了其潜在的临床价值，为疾病诊断提供了新的量化指标。该框架的通用性也使其有望应用于其他需要形态学定量评估的医学领域。

<details>
  <summary>Details</summary>

**Motivation:** 在医学图像分析中，曲线弯曲度的精确量化对于各种疾病的辅助诊断和病理评估至关重要。传统方法（如曲率或弧弦比）依赖于理想直线比较，本研究旨在提供一种更鲁棒、客观的评估指标。

**Method:** 提出了一种基于信息熵的弯曲度量化框架，该框架结合了概率建模、熵理论和曲线数据域变换。与传统方法不同，它通过将目标曲线与指定参考曲线进行比较来评估弯曲度。首先进行了数值模拟实验评估其稳定性和有效性，随后应用于量化睑板腺萎缩的空间均匀性，并分析了蠕形螨阴性与阳性患者组间均匀性的差异。

**Result:** 数值模拟实验初步评估了方法的稳定性与有效性。在睑板腺萎缩评估中，结果显示蠕形螨阴性与阳性组之间基于弯曲度的均匀性存在显著差异，曲线下面积为0.8768，敏感性为0.75，特异性为0.93。

**Conclusion:** 所提出的框架在曲线弯曲度分析中具有临床实用性，并有望成为医学诊断中定量形态学评估的通用工具。

> **ai_Abstract:** 本研究提出了一种新颖的基于信息熵的曲线弯曲度量化框架，该框架通过将目标曲线与生物学上合理的参考曲线进行比较来评估弯曲度，从而克服了传统方法依赖理想直线比较的局限性。该框架集成了概率建模、熵理论和域变换。通过数值模拟验证其稳定性和有效性后，将其应用于睑板腺萎缩的均匀性评估，并成功区分了蠕形螨阴性和阳性患者组，显示出显著的临床诊断潜力。

> **摘要翻译:** 在医学图像分析领域，曲线弯曲度的精确量化在各种疾病的辅助诊断和病理评估中起着关键作用。在本研究中，我们提出了一种新颖的弯曲度量化框架，并通过评估睑板腺萎缩均匀性（作为代表性应用场景）来证明其有效性。
我们引入了一个基于信息熵的弯曲度量化框架，该框架将概率建模与熵理论相结合，并融入了曲线数据的域变换。与曲率或弧弦比等传统方法不同，这种方法通过将目标曲线与指定参考曲线进行比较来评估目标曲线的弯曲度。因此，它更适用于医学数据中存在生物学上合理的参考曲线的弯曲度评估任务，提供了一种更鲁棒和客观的评估指标，而无需依赖理想化的直线比较。
首先，我们进行了数值模拟实验，初步评估了该方法的稳定性和有效性。随后，该框架被应用于量化睑板腺萎缩的空间均匀性，并分析了蠕形螨阴性组和蠕形螨阳性患者组之间这种均匀性的差异。结果表明，两组之间基于弯曲度的均匀性存在显著差异，曲线下面积为0.8768，敏感性为0.75，特异性为0.93。这些发现突出了所提出的框架在曲线弯曲度分析中的临床实用性及其作为医学诊断中定量形态学评估的通用工具的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [763] [Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks](https://arxiv.org/abs/2507.16761)
> *忠实、可解释的抗锯齿B-cos网络胸部X光诊断*

*Marcel Kleinmann, Shashank Agnihotri, Margret Keuper* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 胸部X光诊断, 可解释性, B-cos网络, 抗锯齿, 医疗影像

**Comment:** 

> **TL;DR:** 通过引入抗锯齿策略，改进了B-cos网络，使其在保持诊断性能的同时，为胸部X光诊断提供忠实且无伪影的可解释性，适用于临床应用。

**AI_Comments:** 这项工作通过解决B-cos网络在医疗影像解释中的关键限制——锯齿伪影，显著提升了其临床可用性。其创新点在于将抗锯齿策略引入到可解释性网络中，使得解释图更加清晰可靠。这对于将深度学习模型部署到对可信度要求极高的医疗领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗影像等安全关键领域部署深度神经网络时，忠实性和可解释性至关重要。标准B-cos模型虽然具有竞争力，但其解释图存在严重的锯齿伪影，不适合对清晰度要求极高的临床使用。

**Method:** 本文通过引入使用FLCPooling (FLC) 和BlurPool (BP) 的抗锯齿策略，显著改善了B-cos网络的解释质量。

**Result:** 实验表明，改进后的$\text{B-cos}_\text{FLC}$和$\text{B-cos}_\text{BP}$在多类别和多标签设置下，保持了强大的预测性能，同时提供了忠实且无伪影的解释，适用于临床应用。

**Conclusion:** 改进后的抗锯齿B-cos网络（$\text{B-cos}_\text{FLC}$和$\text{B-cos}_\text{BP}$）能够为胸部X光诊断提供忠实、无伪影且适用于临床的解释，同时保持强大的预测性能。

> **ai_Abstract:** 本文针对B-cos网络在医疗影像诊断中解释图存在的锯齿伪影问题，提出并引入了FLCPooling和BlurPool两种抗锯齿策略。实验证明，经过这些策略改进的B-cos网络（$\text{B-cos}_\text{FLC}$和$\text{B-cos}_\text{BP}$）在胸部X光诊断中不仅保持了与现有技术相当的预测性能，还能提供忠实、清晰且无伪影的解释，使其非常适合临床应用。

> **摘要翻译:** 忠实性和可解释性对于在医疗成像等安全关键领域部署深度神经网络 (DNN) 至关重要。B-cos网络通过用权重-输入对齐机制取代标准线性层，提供了一种有前景的解决方案，无需后验方法即可生成固有的可解释的、特定于类别的解释。虽然在诊断性能上与最先进的DNNs保持竞争力，但标准B-cos模型在其解释图中存在严重的锯齿伪影，这使得它们不适合对清晰度要求极高的临床使用。在这项工作中，我们通过引入使用FLCPooling (FLC) 和BlurPool (BP) 的抗锯齿策略来解决这些限制，以显著提高解释质量。我们在胸部X光数据集上的实验表明，改进后的$\text{B-cos}_\text{FLC}$和$\text{B-cos}_\text{BP}$在提供忠实且无伪影的解释的同时，保持了强大的预测性能，适用于多类别和多标签设置下的临床应用。代码可在GitHub仓库获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [7] [Insights from Railway Professionals: Rethinking Railway assumptions regarding safety and autonomy](https://arxiv.org/abs/2507.17756)
> *铁路专业人士的见解：重新思考铁路关于安全和自主性的假设*

*Josh Hunter, John McDermid, Simon Burton* | **Category: cs.HC, cs.AI** | **Updated: 2025-05-06**

**Keywords:** 铁路安全, 自动化, 专业人士见解, 辅助技术, 安全评估模型

**Comment:** 9 pages, 3 figures, published in European Dependable Computing
  Conference 2025

> **TL;DR:** 这项研究通过访谈铁路专业人士，探讨了他们对铁路安全的看法以及自动化在铁路中的应用潜力，发现他们对自动化持谨慎态度，偏好辅助技术，并强调需要铁路特有的安全评估模型。

**AI_Comments:** 这项研究通过直接听取铁路专业人士的意见，为铁路安全和自动化提供了宝贵的实践视角。其创新之处在于强调了铁路系统与汽车系统的差异性，并呼吁建立铁路特有的安全模型，这对于确保未来铁路技术发展的稳健性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查铁路专业人员如何看待铁路内部的安全概念，以期为该行业未来的技术发展提供信息。

**Method:** 通过对司机、路线规划员和行政人员进行一系列访谈。

**Result:** 主要发现包括：对自动化持谨慎态度，偏好辅助技术，对安全有复杂的理解（整合了人为、系统和技术因素）。研究还指出汽车自动化技术转移到铁路的局限性，以及需要一个铁路特定的因果模型。

**Conclusion:** 本研究旨在弥合当代研究与实际应用之间的差距，为开发更有效的安全指标做出贡献。

> **ai_Abstract:** 本研究通过访谈铁路司机、路线规划员和行政人员，探讨了铁路专业人士对安全和自动化的看法。研究发现，专业人士对自动化持谨慎态度，倾向于辅助技术，并对安全有全面的理解。论文强调了将汽车自动化技术直接应用于铁路的局限性，并提出了开发铁路特定安全评估模型的必要性，以促进更有效的安全指标和未来的技术发展。

> **摘要翻译:** 本研究调查了铁路专业人员如何看待铁路内部的安全概念，旨在为该行业未来的技术发展提供信息。通过对司机、路线规划员和行政人员进行一系列访谈，本研究探讨了当前的安全实践状况、自动化的潜力以及对铁路作为系统之系统的理解。主要发现强调了对自动化持谨慎态度、偏好辅助技术，以及对安全有着整合了人为、系统和技术因素的复杂理解。本研究还探讨了将汽车自动化技术转移到铁路的局限性，以及需要一个铁路特定的因果模型，以便在不断发展的技术环境中更好地评估和提高安全性。本研究旨在弥合当代研究与实际应用之间的差距，为开发更有效的安全指标做出贡献。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [20] [PosterMate: Audience-driven Collaborative Persona Agents for Poster Design](https://arxiv.org/abs/2507.18572)
> *PosterMate：受众驱动的协作式角色代理用于海报设计*

*Donghoon Shin, Daniel Lee, Gary Hsieh, Gromit Yeuk-Yin Chan* | **Category: cs.HC, cs.AI, cs.CL, H.5.2; I.2.7** | **Updated: 2025-07-24**

**Keywords:** 海报设计, AI角色代理, 受众反馈, 协作设计, 生成式AI

**Comment:** 

> **TL;DR:** PosterMate是一个利用AI角色代理模拟受众反馈并促进海报设计协作的工具，通过用户研究证明其能捕捉被忽视的观点并有效整合不同视角。

**AI_Comments:** 这篇论文通过引入AI角色代理来模拟受众反馈，解决了海报设计中获取多样化、同步反馈的挑战。其创新之处在于将生成式AI应用于设计反馈流程，并通过模拟不同“人设”的代理进行协作和讨论，有效地综合了多方观点。这为设计领域利用AI提供了新的思路，特别是在用户研究和原型迭代方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 海报设计需要目标受众的同步反馈，但召集多样化的受众并协调设计修改具有挑战性。尽管生成式AI模型提供了模拟人际互动的机会，但它们如何用于设计反馈过程尚不明确。

**Method:** 论文介绍了PosterMate，一个海报设计助手。它通过从营销文档中构建受众驱动的角色代理来促进协作。PosterMate收集每个角色代理关于海报组件的反馈，并在主持人的帮助下激发讨论以达成共识。这些达成一致的修改可以直接集成到海报设计中。

**Result:** 用户研究（N=12）表明PosterMate有潜力捕捉被忽视的观点，并可作为有效的原型设计工具。受控在线评估（N=100）显示，个体角色代理的反馈与其角色身份相符，并且讨论有效地综合了不同角色代理的观点。

**Conclusion:** PosterMate是一个有效的工具，能够通过模拟受众驱动的角色代理来改进海报设计过程，它能捕捉多样化的观点并有效整合不同视角，从而促进设计协作。

> **ai_Abstract:** PosterMate是一种创新的海报设计助手，它通过利用从营销文档构建的AI驱动的角色代理来模拟目标受众的反馈。该系统能够收集不同角色的意见，并通过主持人引导的讨论达成设计修改共识，然后将这些修改直接应用到海报中。用户研究和在线评估证实了PosterMate在捕捉多样化视角、作为原型工具以及有效整合不同AI角色代理反馈方面的潜力。

> **摘要翻译:** 海报设计可以受益于目标受众的同步反馈。然而，召集具有不同视角的受众并在设计修改上达成一致可能具有挑战性。最近的生成式AI模型提供了模拟人际互动的机会，但它们如何用于设计反馈过程尚不明确。我们引入了PosterMate，一个海报设计助手，它通过创建基于营销文档的受众驱动的角色代理来促进协作。PosterMate收集每个角色代理关于海报组件的反馈，并在主持人的帮助下激发讨论以达成结论。这些达成一致的修改可以直接集成到海报设计中。通过我们的用户研究（N=12），我们发现PosterMate有潜力捕捉被忽视的观点，同时作为一种有效的原型设计工具。此外，我们的受控在线评估（N=100）显示，个体角色代理的反馈与其角色身份相符，并且讨论有效地综合了不同角色代理的观点。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [48] [BrisT1D Dataset: Young Adults with Type 1 Diabetes in the UK using Smartwatches](https://arxiv.org/abs/2507.17757)
> *BrisT1D数据集：英国使用智能手表的1型糖尿病青年人*

*Sam Gordon James, Miranda Elaine Glynis Armstrong, Aisling Ann O'Kane, Harry Emerson, Zahraa S. Abdallah* | **Category: cs.HC, cs.LG** | **Updated: 2025-05-07**

**Keywords:** 1型糖尿病, 智能手表, 数据集, 纵向研究, 慢性病管理

**Comment:** 13 pages, 14 figures

> **TL;DR:** BrisT1D数据集是一个包含英国24名使用智能手表进行1型糖尿病管理的年轻人的纵向研究数据，旨在促进对T1D管理技术真实世界使用和新数据流的探索。

**AI_Comments:** 该数据集的创新之处在于其结合了定量（设备数据）和定性（访谈和焦点小组）数据，为深入理解1型糖尿病患者在现实世界中使用智能手表的情况提供了独特的机会。它不仅支持技术开发（如预测算法），还允许探索用户体验和行为，这对于提升慢性病管理技术的用户采纳度和有效性至关重要。其纵向研究设计也增加了数据的价值。

<details>
  <summary>Details</summary>

**Motivation:** 1型糖尿病（T1D）管理技术发展迅速，是其他慢性病未来管理的一个有用案例。进一步开发这种管理技术需要探索其在现实世界中的使用以及额外数据流的潜力。为了促进这一点，研究人员创建了BrisT1D数据集，以补充不断增长的公共T1D管理数据集。

**Method:** BrisT1D数据集来源于一项对英国24名年轻人的纵向研究，这些年轻人在日常T1D管理的同时使用智能手表。该数据集包含参与者使用的T1D管理系统和智能设备数据，以及研究期间进行的每月访谈和焦点小组的笔录。设备数据提供处理后的状态（便于使用和快速分析）和原始状态（用于深入探索新见解）。

**Result:** BrisT1D数据集包含了来自T1D管理系统和参与者使用的智能手表的设备数据，以及研究期间进行的每月访谈和焦点小组的笔录。设备数据以处理后的状态（便于使用和快速分析）和原始状态（用于深入探索新见解）提供。

**Conclusion:** 该数据集具有广泛的潜在应用。定量元素可以支持血糖预测、低血糖预测和闭环算法开发。定性元素可以探索用户体验和意见，以及对智能手表在T1D管理中作用的更广泛的混合方法研究。

> **ai_Abstract:** BrisT1D数据集是一个新的公共数据集，旨在促进对1型糖尿病（T1D）管理技术在现实世界中使用的探索。该数据集来源于一项对英国24名使用智能手表进行T1D管理的年轻人的纵向研究，包含了来自T1D管理系统和智能手表的设备数据（包括处理后的和原始数据），以及每月访谈和焦点小组的定性数据。该数据集具有多方面的应用潜力，包括支持血糖和低血糖预测、闭环算法开发，以及探索用户体验和智能手表在T1D管理中的作用。

> **摘要翻译:** 背景：1型糖尿病（T1D）的管理技术发展迅速，为未来其他慢性病的管理提供了一个有用的案例研究。这种管理技术的进一步发展需要探索其在现实世界中的使用以及额外数据流的潜力。为了促进这一点，我们贡献了BrisT1D数据集，以补充不断增长的公共T1D管理数据集。该数据集来源于一项对英国24名年轻人的纵向研究，这些年轻人在日常T1D管理的同时使用智能手表。发现：BrisT1D数据集包含参与者使用的T1D管理系统和智能手表的设备数据，以及研究期间进行的每月访谈和焦点小组的笔录。设备数据以处理后的状态提供，便于使用和更快速的分析；也以原始状态提供，用于深入探索研究中捕捉到的新见解。结论：该数据集具有一系列潜在应用。定量元素可以支持血糖预测、低血糖预测和闭环算法开发。定性元素可以探索用户体验和意见，以及对智能手表在T1D管理中作用的更广泛的混合方法研究。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [64] [MeloKids: Multisensory VR System to Enhance Speech and Motor Coordination in Children with Hearing Loss](https://arxiv.org/abs/2507.18619)
> *MeloKids：用于增强听障儿童言语和运动协调的多感官VR系统*

*Yichen Yu, Qiaoran Wang* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 听障儿童, 多感官VR, fNIRS, 言语协调, 运动协调

**Comment:** 

> **TL;DR:** 本研究探索了基于虚拟现实的多感官反馈技术如何改善听障儿童的语言和运动发展，并使用fNIRS评估了皮层激活模式。

**AI_Comments:** 该研究的创新之处在于结合了多感官VR技术和fNIRS脑成像技术来评估听障儿童的康复效果，为个性化康复系统的设计提供了潜在的生物学证据支持。

<details>
  <summary>Details</summary>

**Motivation:** 听障儿童在语言和运动发展方面面临持续挑战，本研究旨在探索多感官VR技术如何增强康复效果。

**Method:** 研究使用了基于虚拟现实（VR）的多感官反馈技术，整合了听觉、视觉和触觉刺激。通过功能性近红外光谱（fNIRS）技术，评估了儿童在音高匹配任务中不同互动模式下的皮层激活模式。

**Result:** 研究结果旨在为设计个性化、交互式康复系统提供证据，以增强听障儿童的认知参与和运动控制。

**Conclusion:** 本研究旨在为设计个性化、交互式康复系统提供证据，以增强听障儿童的认知参与和运动控制，从而改善其语言和运动康复。

> **ai_Abstract:** 本研究提出MeloKids系统，一个基于虚拟现实的多感官系统，旨在改善听障儿童的语言和运动协调。研究探索了整合听觉、视觉和触觉刺激的多感官反馈技术对康复效果的影响。通过fNIRS技术评估儿童在音高匹配任务中的皮层激活模式，旨在为开发个性化、交互式康复系统提供依据，以增强听障儿童的认知参与和运动控制。

> **摘要翻译:** 听障儿童在语言和运动发展方面面临持续挑战。本研究探索了基于虚拟现实（VR）的多感官反馈技术，如何通过整合听觉、视觉和触觉刺激来增强康复效果。我们使用功能性近红外光谱（fNIRS）技术，评估了儿童在音高匹配任务中不同互动模式下的皮层激活模式。我们的研究结果旨在为设计个性化、交互式康复系统提供证据，以增强听障儿童的认知参与和运动控制。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [83] [DHMS: A Digital Hostel Management System Integrating Campus ChatBot, Predictive Intelligence, and Real-Time Automation](https://arxiv.org/abs/2507.17759)
> *DHMS：一个集成校园聊天机器人、预测智能和实时自动化的数字化宿舍管理系统*

*Riddhi Heda, Sidhant Singh, Umair Yasir, Tanmay Jaiswal, Anil Mokhade* | **Category: cs.HC** | **Updated: 2025-05-08**

**Keywords:** 宿舍管理系统, 聊天机器人, 预测智能, 自动化, 学生满意度

**Comment:** 

> **TL;DR:** DHMS是一个数字化宿舍管理系统，通过集成聊天机器人、预测智能和自动化来解决传统宿舍管理的低效问题，并在模拟测试中表现良好。

**AI_Comments:** DHMS的创新之处在于其将校园聊天机器人、预测智能和实时自动化集成到一个统一的宿舍管理系统中，以解决传统管理的痛点。它通过自动化和智能分析显著减轻了工作人员负担并提升了学生体验。然而，该论文也明确指出了系统在实际大规模部署前所需进行的进一步测试，如可扩展性和ERP兼容性，这显示了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 传统学术机构的宿舍管理实践常常受困于低效率、延误和碎片化沟通，未能满足数字化原住民学生的期望，并给宿舍工作人员带来沉重的运营负担。

**Method:** 本文引入了DHMS（数字化宿舍管理系统），一个模块化集成平台，旨在数字化并简化基本的宿舍管理功能。DHMS利用现代网络技术、人工智能和云基础设施，通过自然语言聊天机器人自动化宿舍分配、申诉处理、出入证物流和沟通。附加功能包括用于主动维护计划的预测分析和用于反馈处理的情感分析。

**Result:** 在模拟测试中，DHMS在宿舍分配方面实现了92%的学生满意度，并保持了平均聊天机器人响应时间低于一秒。

**Conclusion:** DHMS系统前景光明，但需要在多宿舍楼集成、用户接受度、负载下的可扩展性以及ERP兼容性方面进行进一步测试，然后才能在全校部署。该工作讨论了系统架构、实施方法以及对改善用户体验、管理效率和决策过程至关重要的因素。

> **ai_Abstract:** 本文介绍了DHMS（数字化宿舍管理系统），一个旨在解决传统宿舍管理低效问题的集成平台。DHMS利用现代技术、人工智能和云基础设施，自动化宿舍分配、申诉处理、出入证物流和通过聊天机器人进行沟通。模拟测试显示其在学生满意度和响应时间方面表现出色，并具备预测分析和情感分析功能。该系统有望提升管理效率和用户体验，但仍需进一步测试以实现全面部署。

> **摘要翻译:** 传统学术机构的宿舍管理实践常常受困于低效率、延误和碎片化沟通。这些系统未能满足数字化原住民学生的期望，并给宿舍工作人员带来沉重的运营负担。本文介绍了DHMS（数字化宿舍管理系统），一个模块化集成平台，旨在数字化并简化基本的宿舍管理功能。DHMS利用现代网络技术、人工智能和云基础设施，通过自然语言聊天机器人自动化宿舍分配、申诉处理、出入证物流和沟通。在模拟测试中，DHMS在宿舍分配方面实现了92%的学生满意度，并保持了平均聊天机器人响应时间低于一秒。附加功能包括用于主动维护计划的预测分析和用于反馈处理的情感分析。尽管前景光明，但在全校部署之前，该系统还需要在多宿舍楼集成、用户接受度、负载下的可扩展性以及ERP兼容性方面进行进一步测试。这项工作讨论了系统架构、实施方法以及对改善用户体验、管理效率和决策过程至关重要的关键因素。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [105] [Evaluation of a Provenance Management Tool for Immersive Virtual Fieldwork](https://arxiv.org/abs/2507.18622)
> *沉浸式虚拟野外考察的溯源管理工具评估*

*Armin Bernstetter, Tom Kwasnitschka, Isabella Peters* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 溯源, 可重复性, 虚拟野外考察, 沉浸式, 数字实验记录本

**Comment:** Accepted for Mensch und Computer 2025 Short Paper Track

> **TL;DR:** 评估了一个用于虚拟野外考察研究溯源的数字实验记录本（DLB）工具；发现其有用且易于使用，在沉浸式和非沉浸式设置下使用模式无显著差异。

**AI_Comments:** 该论文通过提出和评估一个用于虚拟野外考察的溯源管理工具，解决了科学实践中的一个关键问题：可重复性。其对沉浸式环境和用户感知的关注，为高级研究环境中此类工具的可用性和实用性提供了宝贵的见解。使用模式在沉浸式和非沉浸式设置之间没有显著差异的发现尤其有趣，这可能表明该工具的设计稳健性或用户的适应能力。

<details>
  <summary>Details</summary>

**Motivation:** 确保研究的可重复性是良好科学实践的重要组成部分。溯源信息（从数据收集到研究人员理解过程的所有工作流信息）对于支持可重复性至关重要，尤其是在地球科学等领域，研究人员需要对地理空间数据进行交互式和沉浸式可视化，并在3D模型上进行虚拟测量。

**Method:** 该研究评估了一个溯源管理工具（数字实验记录本，DLB），该工具能够记录与虚拟野外考察工具的交互并注释可视化状态。通过用户研究，调查了研究人员如何使用DLB，以及在沉浸式和非沉浸式环境中，DLB的感知易用性和感知有用性是否存在差异。

**Result:** 参与者认为DLB既有用又易于使用。虽然感知易用性存在差异的迹象（沉浸式设置下更高），但使用模式没有显示出显著的组间差异。

**Conclusion:** 该溯源管理工具（DLB）被用户认为是有效且易于使用的，并且在沉浸式和非沉浸式环境下，其使用模式没有显著差异，表明其在不同虚拟野外考察设置中均具有普适性。

> **ai_Abstract:** 本论文评估了一个用于沉浸式虚拟野外考察（特别是在地球科学领域）中管理研究溯源的数字实验记录本（DLB）。该DLB能够记录交互和可视化注释。用户研究发现，研究人员认为DLB既有用又易于使用。尽管在沉浸式环境中感知易用性更高，但使用模式在沉浸式和非沉浸式组之间没有显示出显著差异，这表明该工具具有广泛的适用性。

> **摘要翻译:** 确保研究的可重复性是良好科学实践不可或缺的一部分。支持这一点的一种方式是通过溯源：关于研究工作流程的信息，从数据收集到研究人员的理解过程，最终形成已发表的结果。这在地球科学等学科中尤为重要，因为研究人员使用软件进行地理空间数据的交互式和沉浸式可视化，在3D模型上进行模拟野外考察中的虚拟测量。我们评估了一个溯源管理工具，它允许记录与虚拟野外考察工具的交互并注释可视化的不同状态。用户研究调查了研究人员如何使用这个数字实验记录本（DLB），以及在沉浸式或非沉浸式设置中，感知易用性和感知有用性是否存在组间差异。参与者认为DLB既有用又易于使用。虽然感知易用性存在差异的迹象（沉浸式设置下更高），但使用模式没有显示出显著的组间差异。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [118] [Co-constructing Explanations for AI Systems using Provenance](https://arxiv.org/abs/2507.17761)
> *使用溯源共同构建AI系统解释*

*Jan-Christoph Kalo, Fina Polat, Shubha Guha, Paul Groth* | **Category: cs.HC** | **Updated: 2025-05-31**

**Keywords:** AI解释, 数据溯源, 共同构建, 交互式代理, 可解释AI

**Comment:** 5 pages

> **TL;DR:** 提出了一种交互式代理的愿景，该代理与用户共同构建基于数据溯源的、对用户有用的AI系统解释，并展示了初步原型和评估框架。

**AI_Comments:** 该论文的创新之处在于提出“共同构建”解释的概念，通过交互式代理解决现有溯源解释的可用性问题。其重要性在于提升了AI系统解释的可理解性和用户参与度。提出的评估框架，特别是使用大型语言模型作为裁判，也为未来AI解释系统的评估提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现代AI系统复杂且难以理解，数据溯源虽然能提供解释能力，但往往过于详细且缺乏上下文，导致用户难以理解AI系统输出。

**Method:** 提出了一种交互式代理的愿景，该代理与用户协同工作，共同构建既对用户有用又基于数据溯源的解释。为实现此愿景，他们展示了一个初步原型，并提出了一个基于用户模拟和大型语言模型作为裁判的可扩展评估框架。

**Result:** 展示了一个交互式代理的初步原型，并提出了一个可扩展的评估框架。具体结果（如实验数据、性能提升等）未在摘要中提及。

**Conclusion:** 该研究提出了一个使用交互式代理共同构建AI系统解释的新方法，并提供了初步实现和评估框架，旨在使AI系统解释更具用户可用性和溯源基础。

> **ai_Abstract:** 本研究提出了一种创新方法，通过一个交互式代理与用户共同构建AI系统解释。针对现有数据溯源解释过于详细且缺乏上下文的问题，该代理旨在提供既有用又根植于数据溯源的解释。文章展示了该代理的初步原型，并提出了一个基于用户模拟和大型语言模型判定的可扩展评估框架。

> **摘要翻译:** 现代AI系统是包含多个组件和数据源的复杂工作流。数据溯源提供了询问和潜在解释这些系统输出的能力。然而，溯源通常过于详细，并且没有为试图理解AI系统的用户提供上下文。在这项工作中，我们提出了一个交互式代理的愿景，该代理与用户共同构建一个既对用户有用又基于数据溯源的解释。为了阐明这一愿景，我们提出了：1）这样一个代理的初步原型；2）一个基于用户模拟和大型语言模型作为裁判方法的可扩展评估框架。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [153] [Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems](https://arxiv.org/abs/2507.17774)
> *人机协同创作：智能系统中协作设计的框架*

*Zhangqi Liu* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 人机协同创作, 智能系统, 协作设计, 大型语言模型, 扩散模型

**Comment:** 

> **TL;DR:** 本文探讨了人机协同创作的新范式，其中AI作为积极的创意伙伴参与设计过程，并以LLM和扩散模型为例进行研究。

**AI_Comments:** 本文提出了一种创新的人机协同创作框架，强调AI从工具向协作伙伴的角色转变，这对于智能系统中的设计流程具有重要意义。通过利用LLM和扩散模型，该框架为未来人机交互设计提供了新的思路和实践方向。其创新点在于将AI融入到设计早期阶段的创意和决策过程中，而非仅仅作为效率工具。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI从后端计算工具演变为交互式、生成式协作工具，传统以人为中心的设计工作流程需要重新思考，以适应AI在早期设计阶段的整合。

**Method:** 本文探索了人机协同创作的新范式，其中AI积极参与构思、视觉概念化和决策。具体而言，研究调查了GPT-4等大型语言模型和Stable Diffusion等多模态扩散模型作为创意代理，如何让设计师参与迭代的提议、批判和修订循环。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了人机协同创作这一新兴范式，旨在重新定义AI在设计过程中的角色。作者提出AI应从单纯的自动化工具转变为积极参与构思、视觉概念化和决策的协作伙伴。研究具体考察了大型语言模型（如GPT-4）和多模态扩散模型（如Stable Diffusion）作为创意代理，如何促进设计师在迭代的提案、批判和修订周期中进行协作。

> **摘要翻译:** 随着人工智能（AI）不断从后端计算工具演变为交互式、生成式协作者，其在早期设计过程中的整合要求重新思考以人为中心设计中的传统工作流程。本文探讨了人机协同创作这一新兴范式，其中AI不仅仅用于自动化或提高效率，而是积极参与构思、视觉概念化和决策。具体而言，我们研究了如何将GPT-4等大型语言模型（LLM）和Stable Diffusion等多模态扩散模型用作创意代理，使设计师参与到提案、批判和修订的迭代循环中。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [177] [Automated Brake Onset Detection in Naturalistic Driving Data](https://arxiv.org/abs/2507.17943)
> *自然驾驶数据中自动刹车起始点检测*

*Shu-Yuan Liu, Johan Engström, Gustav Markkula* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-23**

**Keywords:** 刹车起始点检测, 自动驾驶系统, 自然驾驶数据, 响应时间, 分段线性加速度模型

**Comment:** 

> **TL;DR:** 开发了一种基于分段线性加速度模型的算法，用于在车辆控制信号不可用的大规模驾驶数据中自动检测刹车起始点，以评估自动驾驶系统。

**AI_Comments:** 该论文提出了一种创新的方法来解决在缺乏传统车辆控制信号的情况下，从大规模自然驾驶数据中自动检测刹车起始点的问题。这对于自动驾驶系统的评估，特别是其响应时间性能的分析，具有重要意义。该算法的优势在于其高效性、通用性以及对不同数据和场景的适用性，这大大扩展了其应用范围。虽然论文提到了局限性，但其贡献在于为未来大规模ADS数据分析提供了关键工具。

<details>
  <summary>Details</summary>

**Motivation:** 在碰撞避免场景中评估自动驾驶系统（ADS）需要测量响应时间，但这依赖于手动标注或车辆控制信号，这些方法不适用于大规模驾驶数据（特别是ADS日志数据），因为车辆控制信号通常不可用。因此，需要一种新的方法来在缺乏此类信号的情况下测量响应时间。

**Method:** 开发了一种基于分段线性加速度模型的简单高效算法，用于自动估计刹车起始点。该算法适用于包含车辆纵向时间序列数据的任何类型驾驶数据。同时提出了一种手动标注方法作为真值进行验证。使用R2作为置信度指标来衡量算法的准确性，并在ADS和人类的自然碰撞避免数据上分析了其分类性能，并与人工手动标注进行了验证。

**Result:** 该算法能够有效估计刹车起始点，其分类性能在自然碰撞避免数据中得到验证。尽管存在局限性，但它高效、通用、适用于任何道路使用者和场景类型，且高度可配置。

**Conclusion:** 所开发的基于分段线性加速度模型的自动刹车起始点检测算法，即使在车辆控制信号不可用的情况下，也能高效、通用地应用于大规模自然驾驶数据，为自动驾驶系统的评估提供了新的技术。

> **ai_Abstract:** 该研究针对大规模驾驶数据中自动驾驶系统（ADS）评估中缺乏车辆控制信号导致响应时间测量困难的问题，提出了一种基于分段线性加速度模型的自动刹车起始点检测算法。该算法能够高效、通用地从车辆纵向时间序列数据中估计刹车起始点。通过与手动标注的真值对比，在ADS和人类的自然碰撞避免数据上验证了其性能，证明了其在解决现有方法局限性方面的有效性。

> **摘要翻译:** 响应时间测量在碰撞避免场景中评估自动驾驶系统（ADS）中发挥着关键作用，包括但不限于建立人类基准和比较ADS与人类驾驶员的响应性能。例如，测量（人类驾驶员或ADS）对冲突的响应时间需要确定刺激起始点和响应起始点。在现有研究中，响应起始点依赖于手动标注或车辆控制信号（如油门和刹车踏板运动）。当分析无法获得车辆控制信号的大规模数据时，这些方法不适用。对于快速扩展的ADS日志数据尤其如此，其中通过车载传感器观察周围道路使用者的行为。为了推进ADS的评估技术并在车辆控制信号不可用时测量响应时间，我们开发了一种基于分段线性加速度模型的简单高效算法，以自动估计刹车起始点，该算法可应用于包含车辆纵向时间序列数据的任何类型驾驶数据。我们还提出了一种手动标注方法来识别刹车起始点，并将其用作验证的真值。R2被用作衡量算法准确性的置信度指标，并使用ADS和人类的自然碰撞避免数据分析了其分类性能，其中我们的方法通过人类手动标注进行了验证。尽管我们的算法存在某些局限性，但它高效、通用、适用于任何道路使用者和场景类型，并且高度可配置。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [194] [Same Data, Different Audiences: Using Personas to Scope a Supercomputing Job Queue Visualization](https://arxiv.org/abs/2507.17898)
> *相同数据，不同受众：使用用户画像界定超级计算作业队列可视化范围*

*Connor Scully-Allison, Kevin Menear, Kristin Potter, Andrew McNutt, Katherine E. Isaacs, Dmitry Duplyakin* | **Category: cs.HC** | **Updated: 2025-07-23**

**Keywords:** 超级计算, 可视化, 用户画像, 多受众, 队列数据

**Comment:** 11 Pages, 4 figures

> **TL;DR:** 该论文提出了一种名为`Guidepost`的可视化工具，该工具利用用户画像帮助不同用户群体有效地分析超级计算作业队列数据，平衡了广泛的实用性与特定任务支持。

**AI_Comments:** 该论文的创新之处在于其设计多受众可视化工具的系统方法，特别是通过调整用户画像来定义任务分类模型（共享任务与独特任务）。这为在超级计算等复杂数据环境中平衡广泛实用性与特定用户需求提供了一个实用的框架。其重要性在于提供了一个具体示例（`Guidepost`）和一项评估，展示了这种方法的可行性和益处，可能为未来针对不同用户群体的可视化设计提供指导。

<details>
  <summary>Details</summary>

**Motivation:** 领域特定的可视化工具通常只关注某一用户群体的狭窄任务，这限制了其对使用相同数据的其他群体的效用。本文旨在通过开发支持多个群体的可视化工具来解决这一问题，尽管这会带来权衡。

**Method:** 作者进行了一项设计研究，开发了`Guidepost`——一个嵌入在笔记本中的超级计算机队列数据可视化工具。他们借鉴了人机交互和软件工程领域的现有文献，调整了用户画像的使用，根据任务在不同利益相关者用户画像中的独特性进行分类。所有群体共享的任务通过交互式可视化支持，而每个群体独有的任务则通过脚本和嵌入笔记本的可视化设计来处理。他们与分为两组（“研究分析师”和“超级计算机用户”）的九名专家分析师一起评估了他们的可视化工具。

**Result:** 所开发的可视化工具`Guidepost`通过使用户能够通过点击交互成功执行共享任务，并促进特定情况下的程序化分析工作流程，从而服务于三个利益相关者群体（科学家、机器学习研究人员和系统维护人员）。

**Conclusion:** 论文得出结论，在可视化设计中使用用户画像可以有效地平衡对多个用户群体的广泛实用性与对特定任务的支持，从而提高整体实用性，正如`Guidepost`所展示的那样。

> **ai_Abstract:** 本文通过提出一种支持多个受众使用相同数据的设计方法，解决了领域特定可视化工具仅服务于单一用户群体的局限性。通过一项设计研究，他们开发了`Guidepost`，一个用于超级计算机队列数据的嵌入笔记本的可视化工具。其主要创新在于改编用户画像来对任务进行分类，其中共享任务由交互式可视化支持，而独特任务则通过脚本处理。对专家分析师的评估表明，`Guidepost`通过支持共享的点击式交互和特定情况下的程序化分析，有效地服务于不同的利益相关者，展示了如何平衡范围和特定支持以提高整体实用性。

> **摘要翻译:** 领域特定的可视化有时会专注于针对某一用户群体的狭窄但重要的任务。这种专注限制了可视化工具对处理相同数据的其他群体的效用。虽然从其他群体中引出的任务，如果未明确区分，可能会带来设计缺陷，但它们也提供了设计机会——开发支持多个群体的可视化工具。这种开发选择带来了拓宽范围但限制对任何一个群体更狭窄任务支持的权衡，但在某些情况下，这可以提高可视化的整体效用。我们通过一项设计研究来调查这种情况，在该研究中，我们开发了`Guidepost`，一个嵌入在笔记本中的超级计算机队列数据可视化工具，它帮助科学家评估超级计算机队列等待时间，帮助机器学习研究人员理解预测准确性，并帮助系统维护人员分析使用趋势。我们将人机交互和软件工程领域现有文献中用户画像在可视化设计中的应用进行改编，并将其应用于根据任务在利益相关者用户画像中的独特性进行分类。在此模型下，所有群体共享的任务应由交互式可视化支持，而每个群体独有的任务则可以推迟到使用嵌入笔记本的可视化设计进行脚本编写。我们与九名专家分析师一起评估了我们的可视化工具，他们分为两组：“研究分析师”组（在研究中使用超级计算机队列数据，代表机器学习研究人员和作业数据分析师用户画像）和“超级计算机用户”组（有条件地使用此数据，代表HPC用户用户画像）。我们发现，我们的可视化工具通过使用户能够通过点击交互成功执行共享任务，同时促进特定情况下的程序化分析工作流程，从而服务于我们的三个利益相关者群体。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [214] [Designing Effective Human-Swarm Interaction Interfaces: Insights from a User Study on Task Performance](https://arxiv.org/abs/2504.02250)
> *设计有效的人机群交互界面：一项关于任务表现的用户研究洞察*

*Wasura D. Wattearachchi, Erandi Lakshika, Kathryn Kasmarik, Michael Barlow* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 人机群交互, 用户界面设计, 群体机器人, 用户研究, 任务表现

**Comment:** 8 pages, 4 figures, 5 tables

> **TL;DR:** 一项用户研究评估了一种用于人类引导机器人群进行目标搜索任务的平板界面，该界面在引导机器人和最小化机器人失活方面表现出高成功率，尤其是在分布式危险情景下。

**AI_Comments:** 该论文通过结合理论推导和实证用户研究，系统地解决了人机群交互界面设计问题，具有创新性。其亮点在于从现有文献中提炼设计原则并将其应用于实际界面开发和测试。用户研究提供了量化的性能指标，验证了界面的有效性，尤其是在不同危险情景下的表现分析，为未来设计优化提供了宝贵的洞察。研究结果表明，该界面在提高任务成功率和减少机器人损耗方面表现良好，但在不同危险类型下支持效果的差异性也为后续研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在设计有效的人机群交互界面，以提升人类引导机器人群执行任务时的表现。

**Method:** 研究首先从现有文献中推导出了十项设计原则，并将其应用于通过目标导向任务分析识别出的关键信息维度。随后，开发了一款用于目标搜索任务的平板界面。接着，进行了一项包含31名参与者的用户研究，要求参与者在存在分布式、移动和扩散三种危险的情况下，引导机器人群到达目标。性能衡量标准是机器人与目标的接近程度以及任务结束时失效机器人的数量。

**Result:** 结果显示，在98%的任务中，至少有一个机器人被引导得更接近目标，表明该界面成功地实现了任务的主要目标。此外，在近67%的任务中，超过50%的机器人到达了目标。在移动危险情景下表现尤其出色。界面还有助于最大程度地减少机器人失活，在近94%的任务中，参与者成功保持了超过50%的机器人处于活动状态。然而，其有效性因危险类型而异，在分布式危险情景下机器人失活率最低，表明界面在这些条件下提供了最大的支持。

**Conclusion:** 该人机群交互界面在引导机器人群完成目标搜索任务方面表现出较高的有效性，尤其在分布式危险情景下对机器人失活的抑制效果最为显著，但其有效性会因危险类型而异。

> **ai_Abstract:** 本研究提出了一种系统化的人机群交互界面设计方法，结合理论原则与实证评估。通过从现有文献中提炼出十项设计原则并应用于目标导向任务分析，开发了一款平板界面用于目标搜索任务。一项包含31名参与者的用户研究显示，该界面在引导机器人群规避分布式、移动和扩散危险并成功接近目标方面表现出色，98%的任务中至少一个机器人接近目标，且在94%的任务中超过50%的机器人保持活跃。界面在减少机器人失活方面有效，尤其在分布式危险情景下支持效果最佳。

> **摘要翻译:** 在本文中，我们提出了一种系统化的人机群交互界面设计方法，该方法结合了理论洞察和经验评估。我们首先从现有文献中推导出了十项设计原则，并将其应用于通过目标导向任务分析识别出的关键信息维度，随后开发了一款用于目标搜索任务的平板界面。接着，我们进行了一项包含31名参与者的用户研究，要求人类在存在三种对机器人构成风险的危险（分布式、移动和扩散）的情况下，引导机器人群到达目标。性能衡量标准是机器人与目标的接近程度以及任务结束时失效机器人的数量。结果表明，在98%的任务中，至少有一个机器人被引导得更接近目标，这表明该界面成功地实现了任务的主要目标。此外，在近67%的任务中，超过50%的机器人到达了目标。而且，在移动危险情景下表现尤为出色。此外，该界面似乎有助于最大限度地减少机器人失活，在近94%的任务中，参与者成功保持了超过50%的机器人处于活动状态，确保了大部分集群保持运行。然而，其有效性因危险类型而异，在分布式危险情景下机器人失活率最低，这表明该界面在这些条件下提供了最大的支持。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [228] [Decoding Instructional Dialogue: Human-AI Collaborative Analysis of Teacher Use of AI Tool at Scale](https://arxiv.org/abs/2507.17985)
> *解码教学对话：大规模人机协作分析教师对AI工具的使用*

*Alex Liu, Lief Esbenshade, Shawon Sarkar, Victor Tian, Zachary Zhang, Kevin He, Min Sun* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 人机协作, 定性分析, 教师AI使用, 大型语言模型, 教育技术

**Comment:** 

> **TL;DR:** 本研究提出了一种人机协作方法，对14万多条教师与AI的消息进行大规模定性分析，以了解教师如何使用AI工具。结果显示LLM（特别是Claude 3.5 Haiku）能可靠地支持主题识别和编码，并揭示了教师使用AI进行教学实践、内容创建、评估反馈和学生支持等方面的模式。

**AI_Comments:** 本研究的创新之处在于提出了一个可扩展的人机协作方法，用于大规模定性分析教师与AI的互动数据，这对于理解AI在教育实践中的实际应用具有重要意义。它不仅揭示了教师使用AI的具体模式，还验证了LLM在定性编码任务中的潜力，为未来的AI辅助教育研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）融入教育工具具有巨大潜力，但目前对教育工作者如何在实践中使用这些工具以及如何大规模有效地研究人机交互知之甚少。

**Method:** 本研究提出了一种人机协作方法，对来自K-12教师使用的生成式AI平台的超过14万条教育工作者-AI消息进行了大规模定性分析。通过一个四阶段的编码流程，结合了归纳主题发现、代码本开发、结构化注释和模型基准测试，以检查教育工作者的参与模式并评估LLM在定性编码任务中的表现。开发了一个与既定教师评估框架对齐的分层代码本。

**Result:** 研究发现，LLMs，特别是Claude 3.5 Haiku，可以可靠地支持主题识别，在复杂场景中扩展人类识别能力，并在准确性和结构可靠性方面优于开源模型。分析还揭示了教育工作者如何向AI提问以增强教学实践（79.7%）、创建或调整内容（76.1%）、支持评估和反馈循环（46.9%）、关注学生个性化教学需求（43.3%）以及协助其他专业职责（34.2%）的实质性模式。

**Conclusion:** 本研究提供了一个可扩展、透明的AI增强定性研究模型，并为生成式AI在教育实践中不断演进的角色提供了基础性见解。

> **ai_Abstract:** 本研究提出了一种人机协作方法，对超过14万条K-12教师与生成式AI平台的互动消息进行了大规模定性分析。通过四阶段编码流程，研究旨在理解教师如何使用AI工具以及LLM在定性编码中的表现。结果显示，LLM（特别是Claude 3.5 Haiku）能有效支持主题识别，并揭示了教师利用AI进行教学实践、内容创建、评估反馈和学生支持等多种用途。该研究提供了一个可扩展的AI增强定性研究模型，并为生成式AI在教育中的作用提供了见解。

> **摘要翻译:** 大型语言模型（LLMs）融入教育工具，有潜力极大地影响教师如何规划教学、支持不同学习者以及进行专业反思。然而，对于教育工作者在实践中如何实际使用这些工具，以及如何大规模有效地研究他们与AI的互动，我们知之甚少。本文提出了一种人机协作方法，对来自K-12教师使用的生成式AI平台的超过14万条教育工作者-AI消息进行了大规模定性分析。通过一个四阶段的编码流程，我们结合了归纳主题发现、代码本开发、结构化注释和模型基准测试，以检查教育工作者的参与模式并评估LLM在定性编码任务中的表现。我们开发了一个与既定教师评估框架对齐的分层代码本，捕捉了教育工作者的教学目标、情境需求和教学策略。我们的发现表明，LLMs，特别是Claude 3.5 Haiku，可以可靠地支持主题识别，在复杂场景中扩展人类识别能力，并在准确性和结构可靠性方面优于开源模型。分析还揭示了教育工作者如何向AI提问以增强教学实践（占总对话的79.7%）、创建或调整内容（76.1%）、支持评估和反馈循环（46.9%）、关注学生个性化教学需求（43.3%）以及协助其他专业职责（34.2%）的实质性模式，这突出了新兴的AI相关能力，对教师准备和专业发展具有直接影响。本研究提供了一个可扩展、透明的AI增强定性研究模型，并为生成式AI在教育实践中不断演进的角色提供了基础性见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [229] [A Scoping Review of Functional Near-Infrared Spectroscopy (fNIRS) Applications in Game-Based Learning Environments](https://arxiv.org/abs/2411.02650)
> *功能性近红外光谱 (fNIRS) 在游戏化学习环境中应用的范围综述*

*Shayla Sharmin, Gael Lucero-Palacios, Behdokht Kiafar, Mohammad Fahim Abrar, Mohammad Al-Ratrout, Aditya Raikwar, Roghayeh Leila Barmaki* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** fNIRS, 游戏化学习, 认知状态, 自适应学习, 范围综述

**Comment:** 28 pages, 3 figures

> **TL;DR:** 本范围综述系统地分析了功能性近红外光谱 (fNIRS) 在游戏化学习环境中的应用现状，旨在了解其如何研究学习者大脑活动并支持自适应学习系统开发，同时指出其潜力与挑战。

**AI_Comments:** 这篇综述的重要性在于它系统地梳理了fNIRS在游戏化学习这一新兴且重要的领域中的应用现状，识别了其潜力与挑战。它强调了fNIRS在理解学习者认知状态方面的价值，并指出了其在实时自适应系统实现中的局限性，为未来研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨fNIRS在游戏化学习系统中的应用，帮助研究人员了解fNIRS如何用于研究大脑活动，并展示其捕获的大脑数据如何通过监测学习者的认知状态来支持自适应学习系统的发展。选择游戏集成学习系统是因为它们能使学习更具吸引力、互动性和沉浸感，这对于自适应学习设计至关重要。

**Method:** 采用PRISMA-ScR框架，筛选了1300篇论文，最终选择了21项实证研究进行深入分析。研究被归类为情感/认知反应研究或比较研究，并根据学习平台、游戏设备、fNIRS配置、结果测量和研究设计进一步分析。

**Result:** 研究发现，游戏集成学习系统在提高参与度和投入度方面可以与传统方法同样有效。fNIRS为认知状态提供了有价值的见解，但尚未在实时自适应系统中广泛实施。研究识别了标准化和数据解释方面的关键挑战，并强调了fNIRS在开发脑感知、互动学习环境方面的潜力。

**Conclusion:** 本综述为未来利用大脑数据支持自适应学习和智能系统设计的研究提供了见解。

> **ai_Abstract:** 本范围综述旨在探讨功能性近红外光谱 (fNIRS) 在游戏化学习环境中的应用，以理解其如何研究大脑活动并支持自适应学习系统开发。研究筛选了21项实证研究，发现游戏化学习系统在提高参与度方面与传统方法同样有效，且fNIRS能提供认知洞察。然而，fNIRS在实时自适应系统中的应用尚不普及，且面临标准化和数据解释的挑战。本综述为未来利用大脑数据设计自适应和智能学习系统提供了指导。

> **摘要翻译:** 功能性近红外光谱 (fNIRS) 已成为研究学习过程中认知和情感过程的重要工具。我们特别关注游戏集成学习系统作为基于fNIRS的大脑数据分析的背景。我们选择游戏集成学习系统是因为此类系统使学习更具吸引力、互动性和沉浸感，所有这些都是自适应学习设计的关键特征。本范围综述的目标是帮助研究人员了解fNIRS迄今为止如何用于研究游戏集成学习系统中的大脑活动。我们还旨在展示通过fNIRS捕获的大脑数据如何通过监测学习者的认知状态来支持自适应学习系统的发展。使用PRISMA-ScR框架，筛选了1300篇论文，并选择了21项实证研究进行深入分析。研究被归类为情感/认知反应研究或比较研究，并根据学习平台、游戏设备、fNIRS配置、结果测量和研究设计进一步分析。研究结果表明，游戏集成学习系统在提高参与度和投入度方面可以与传统方法一样有效。研究结果还表明，fNIRS为认知状态提供了有价值的见解，但尚未在实时自适应系统中广泛实施。我们识别了标准化和数据解释方面的关键挑战，并强调了fNIRS在开发脑感知、互动学习环境方面的潜力。本综述为未来利用大脑数据支持自适应学习和智能系统设计的研究提供了见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [259] [Evaluating judgment of spatial correlation in visual displays of scalar field distributions](https://arxiv.org/abs/2507.17997)
> *评估标量场分布可视化显示中空间相关性判断*

*Yayan Zhao, Matthew Berger* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 空间相关性, 标量场, 可视化显示, 人类判断, 颜色尺度

**Comment:** 

> **TL;DR:** 研究人类在不同可视化显示中识别二维标量场空间相关性的能力。

**AI_Comments:** 这项研究通过系统地比较不同的可视化显示方式和分布特征，为理解人类如何判断空间相关性提供了实证依据，对于优化数据可视化设计具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨在不同形式的视觉显示中，人类如何识别二维标量场分布中的空间相关性。

**Method:** 实验设计比较了两种基本的可视化设计：基于动画的显示与标量场的并列视图，并考虑了不同颜色尺度的选择。此外，研究还调查了分布本身的影响，控制了空间相关性水平和空间尺度的可辨性。

**Result:** 研究结果表明，分布特征对空间相关性判断有影响，并且不同的视觉显示也会影响评估空间相关性时所做的判断类型。

**Conclusion:** 不同的视觉显示方式以及标量场分布的特征会影响人类在评估空间相关性时的判断。

> **ai_Abstract:** 本文研究了人类在不同视觉显示中识别二维标量场空间相关性的能力。通过实验比较了基于动画的显示和并列视图，并探讨了颜色尺度以及空间相关性水平和空间尺度可辨性等分布特征的影响。研究结果揭示了这些因素如何影响人类在评估空间相关性时的判断。

> **摘要翻译:** 在这项工作中，我们研究了二维标量场分布中空间相关性的识别，这些分布以不同形式的可视化显示呈现。我们研究了直接显示颜色映射标量场的简单视觉显示，即那些从分布中提取的显示，以及人类是否能够识别这些显示中强相关的空间区域。在这种设置中，相关性的识别需要对一组场进行判断，而不仅仅是一个场。因此，在我们的实验设计中，我们比较了两种基本的可视化设计：基于动画的显示与标量场的并列视图，以及不同颜色尺度的选择。此外，我们调查了分布本身的影响，控制了空间相关性水平和空间尺度的可辨性。我们的研究结果说明了这些分布特征的影响，同时也强调了不同的视觉显示如何影响在评估空间相关性时所做的判断类型。补充材料可在https://osf.io/zn4qy获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [274] [Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction](https://arxiv.org/abs/2412.14209)
> *将证据整合到可解释人工智能和基于人工智能的决策支持系统设计中：面向建筑领域终端用户的手段-目的框架*

*Peter E. D. Love, Jane Matthews, Weili Fang, Hadi Mahamivanan* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 可解释人工智能, 决策支持系统, 证据整合, 建筑行业, 手段-目的框架

**Comment:** 74 pages, 5 figures and 3 tables

> **TL;DR:** 本文提出了一个基于证据的手段-目的框架，旨在将支持性证据整合到可解释人工智能和基于人工智能的决策支持系统设计中，以提高人工智能生成输出的可靠性和可信度，特别是在建筑行业。

**AI_Comments:** 该论文的创新之处在于解决了将支持性证据整合到可解释人工智能设计中的关键空白，这对于在建筑等关键领域建立信任和问责制至关重要。其提出的“手段-目的框架”及其对认知基础的关注，为可解释人工智能的结构化开发提供了有前景的方法。该框架广泛的适用性也是其一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 在建筑行业中，基于人工智能的决策支持系统日益普及，但对于支持人工智能生成输出的可靠性和问责制的证据整合却关注甚少。缺乏此类证据会损害解释的有效性和系统推荐的可信度。

**Method:** 本文通过叙述性综述开发并引入了一个理论性的、基于证据的手段-目的框架。该框架侧重于评估支持人工智能生成解释的不同类型证据的强度、相关性和实用性。

**Result:** 本文引入了一个理论性、基于证据的手段-目的框架。该框架为设计能够生成根据用户知识需求和决策背景量身定制的有意义解释的可解释人工智能决策支持系统提供了认知基础。

**Conclusion:** 通过整合证据，该框架改善了可解释人工智能决策支持系统的设计，使解释更有意义和可信。尽管主要面向建筑专业人士，该框架也适用于具有不同认知目标的开发人员、监管机构和项目经理。

> **ai_Abstract:** 本文提出一个基于证据的手段-目的框架，该框架通过叙述性综述开发，旨在将支持性证据整合到可解释人工智能（XAI）和基于人工智能的决策支持系统（DSS）的设计中。针对当前人工智能输出中证据整合的不足，特别是在建筑行业，该框架通过评估证据的强度、相关性和实用性，旨在增强解释的有效性和推荐的可信度。它为设计能够提供有意义、上下文感知解释的XAI-DSS提供了认知基础，并适用于包括建筑专业人士在内的各类利益相关者。

> **摘要翻译:** 可解释人工智能旨在使人工智能模型的推理过程透明化和可解释，特别是在复杂的决策环境中。在建筑行业，基于人工智能的决策支持系统日益普及，但对支持人工智能生成输出的可靠性和问责制证据的整合却关注甚少。缺乏此类证据会损害解释的有效性和系统推荐的可信度。本文通过引入一个通过叙述性综述开发的理论性、基于证据的手段-目的框架来解决这一空白。该框架为设计能够生成根据用户知识需求和决策背景量身定制的有意义解释的可解释人工智能决策支持系统提供了认知基础。它侧重于评估支持人工智能生成解释的不同类型证据的强度、相关性和实用性。虽然该框架主要面向建筑专业人士作为主要终端用户开发，但它也适用于具有不同认知目标开发人员、监管机构和项目经理。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [298] ["I Would Not Be This Version of Myself Today": Elaborating on the Effects of Eudaimonic Gaming Experiences](https://arxiv.org/abs/2507.18084)
> *“我今天不会是现在这个样子”：阐述幸福感游戏体验的影响*

*Nisha Devasia, Georgia Kenderova, Michele Newman, Julie Kientz, Jin Ha Lee* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 幸福感游戏体验, 积极结果, 有意义的游戏, 混合方法, 玩家福祉

**Comment:** Accepted to CHI PLAY 2025

> **TL;DR:** 本研究通过一项166人的调查，运用混合方法，探讨了幸福感游戏体验（与个人意义和成长相关）如何对玩家的反射、学习、社交、健康和职业产生积极影响，填补了现有研究对这种体验效果探索不足的空白。

**AI_Comments:** 这项研究通过关注幸福感游戏体验的“效果”这一未充分探索的领域，填补了数字游戏研究的一个重要空白。其混合方法论结合了定性和定量数据，增强了研究结果的稳健性。研究不仅扩展了理论模型，还提供了实用的启示，对研究者和游戏开发者都具有价值，有助于设计更能促进玩家个人成长的游戏。

<details>
  <summary>Details</summary>

**Motivation:** 数字游戏研究多强调享乐体验，而幸福感游戏体验（涉及混合情感、个人意义和成长）的“效果”方面，以及它们如何影响积极的个体结果，迄今为止尚未得到充分探索。

**Method:** 研究采用混合方法，对166名受访者进行了调查，让他们回顾有意义的游戏体验及其对当前生活的影响。通过此方法对效果进行分类，并识别其形成的重要子成分。

**Result:** 研究发现，有意义的游戏体验可以带来积极的反思、学习、社交、健康和职业影响。

**Conclusion:** 本研究扩展了当前幸福感游戏体验的理论模型，并为研究人员和实践者如何利用这些发现促进玩家的积极结果提供了启示。

> **ai_Abstract:** 本研究旨在弥补现有数字游戏研究中对幸福感游戏体验（与个人意义和成长相关）效果探索不足的空白。通过对166名玩家进行混合方法调查，收集他们有意义的游戏经历及其对生活的影响。研究识别并分类了这些体验所产生的积极效果，包括反思、学习、社交、健康和职业方面。本工作不仅增进了对幸福感游戏效应的实证理解，还扩展了相关理论模型，并为促进玩家福祉提供了实践指导。

> **摘要翻译:** 虽然数字游戏的大部分研究都强调享乐体验，例如心流、享受和积极情感，但近年来对幸福感游戏体验的兴趣日益增长，这种体验通常是混合情感的，并与个人意义和成长相关。游戏中这种体验的形成被理论化为包含四个构成要素：动机、游戏使用、体验和效果。然而，虽然前三个要素在文献中已得到相对充分的探索，但效果——以及它们如何影响积极的个体结果——迄今为止尚未得到充分探索。为此，在这项工作中，我们调查了幸福感游戏感知的成果以及体验的不同组成部分如何影响这些效果。我们进行了一项调查（n = 166），受访者在其中回忆了有意义的游戏体验以及它们如何影响他们现在的生活。我们使用混合方法来分类效果并识别其形成的重要子成分。我们对有意义的游戏体验如何带来积极的反思、学习、社交、健康和职业影响提供了实证理解，扩展了当前幸福感游戏体验的理论模型，并为研究人员和实践者如何利用这些发现促进玩家的积极结果提供了启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [319] [WigglyEyes: Inferring Eye Movements from Keypress Data](https://arxiv.org/abs/2412.15669)
> *WigglyEyes：从按键数据推断眼球运动*

*Yujun Zhu, Danqing Shi, Hee-Seung Moon, Antti Oulasvirta* | **Category: cs.HC** | **Updated: 2025-07-23**

**Keywords:** 眼球运动推断, 按键数据, 扫描路径, 个体特征, 凝视推断

**Comment:** 

> **TL;DR:** WigglyEyes是一个基于按键数据推断用户眼球运动的模型，可用于替代昂贵的眼动追踪数据。

**AI_Comments:** 该论文提出的WigglyEyes模型具有创新性，通过仅利用按键数据来推断眼球运动，解决了传统眼动追踪技术成本高昂或实施受限的问题。其将用户个体特征编码为低维参数向量并设计同步损失函数的方法是其技术亮点。该研究对于在资源受限环境下进行用户行为分析具有重要意义，可能在人机交互、可用性研究等领域有广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 在收集真实眼动追踪数据昂贵或不可能的情况下，需要一种替代方法来获取人类数据。

**Method:** 该模型基于按键日志，输出一个扫描路径，显示用户在输入按键时眼球如何移动。其技术核心是一个考虑用户个体特征的推理架构，这些特征被推断为一个低维参数向量。论文提出了一种新颖的损失函数，用于同步推断的眼球运动与按键数据。

**Result:** 在触摸屏打字上的评估表明，该模型能够准确推断凝视。

**Conclusion:** 该模型可以作为人类数据的替代，尤其适用于难以获取真实眼动追踪数据的场景。

> **ai_Abstract:** WigglyEyes提出了一种仅基于按键数据推断用户眼球运动的模型。该模型能够从按键日志中生成扫描路径，显示用户在输入时眼球的实时移动。其创新之处在于一个能够考虑用户个体特征的推理架构，并引入了一个新的损失函数来同步眼球运动与按键。在触摸屏打字上的评估验证了其凝视推断的准确性，为昂贵或不可行的眼动追踪数据提供了一种有效的替代方案。

> **摘要翻译:** 我们提出了一个仅基于按键数据推断用户交互期间注视位置的模型。给定一个按键日志，它会输出一个扫描路径，该路径逐时地描述了用户在输入这些按键时眼球是如何移动的。该模型可以在收集真实眼动追踪数据昂贵或不可能的情况下，作为人类数据的替代品。我们的技术洞察在于一个推理架构，它考虑了用户的个体特征，这些特征被推断为一个低维参数向量。我们提出了一种新颖的损失函数，用于同步推断的眼球运动与按键。在触摸屏打字上的评估证明了凝视推断的准确性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [333] [Understood: Real-Time Communication Support for Adults with ADHD Using Mixed Reality](https://arxiv.org/abs/2507.18151)
> *Understood：使用混合现实为成人多动症患者提供实时沟通支持*

*Shizhen Zhang, Shengxin Li, Quan Li* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** ADHD, 混合现实, 沟通支持, HoloLens 2, 实时

**Comment:** Appear UIST2025

> **TL;DR:** Understood是一个基于混合现实的系统，旨在通过实时总结、词语建议和跑题检测来帮助患有多动症的成年人改善日常沟通。

**AI_Comments:** 这项研究的创新之处在于利用混合现实技术为成人多动症患者提供实时的、非侵入性的沟通支持，填补了现有成人干预工具的空白。其结合认知负荷管理、表达流畅性辅助和跑题提醒的综合功能设计具有很强的实用性。该系统为多动症成年人的日常社会融入提供了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 患有多动症的成年人常面临沟通挑战，现有干预措施多针对儿童，缺乏将临床策略转化为日常沟通支持的成人工具。

**Method:** 研究团队通过半结构化访谈和设计研讨会确定了沟通障碍和设计目标。他们开发了名为Understood的混合现实系统（基于Microsoft HoloLens 2），该系统包含三个主要功能：实时对话摘要、语境感知后续词语建议以及跑题检测和提醒。通过一项受试者内用户研究和专家访谈来评估系统。

**Result:** 用户研究和专家访谈表明，Understood系统能有效支持沟通，且具有高可用性，可作为治疗师介导干预的补充。

**Conclusion:** Understood系统为患有多动症的成年人提供了一种有效的、高可用性的实时沟通支持，弥补了现有成人干预工具的空白。

> **ai_Abstract:** 本研究提出了Understood，一个基于微软HoloLens 2的混合现实系统，旨在解决成人多动症患者的沟通障碍。该系统通过实时对话摘要、语境感知词语建议和话题转移检测等功能，有效支持了成人多动症患者的日常沟通，并在一项用户研究和专家访谈中展现出高可用性，可作为现有治疗方法的补充。

> **摘要翻译:** 注意力缺陷多动障碍（ADHD）成年人即使经过多年社会融合，也常因执行功能障碍和情绪失调而面临沟通挑战。现有干预措施主要通过结构化或侵入性方法针对儿童，而成人缺乏能将临床策略转化为日常沟通支持的工具。为解决这一空白，我们提出了Understood，一个在微软HoloLens 2上实现的混合现实（MR）系统，旨在帮助ADHD成年人在现实世界中进行沟通。通过形成性半结构化访谈和设计研讨会，我们确定了关键沟通障碍并推导了系统的设计目标。Understood结合了三个关键功能：(1) 实时对话摘要以减少认知负荷，(2) 在表达不流畅时提供上下文感知的后续词语建议，以及 (3) 话题转移检测和提醒以缓解跑题。一项受试者内用户研究和专家访谈表明，Understood有效支持沟通，具有高可用性，为治疗师介导的干预提供了补充。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [362] [HandProxy: Expanding the Affordances of Speech Interfaces in Immersive Environments with a Virtual Proxy Hand](https://arxiv.org/abs/2503.10029)
> *HandProxy：通过虚拟代理手扩展沉浸式环境中语音界面的可供性*

*Chen Liang, Yuxuan Liu, Martez Mott, Anhong Guo* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** HandProxy, 语音界面, 虚拟代理手, 沉浸式环境, 手部交互

**Comment:** Accepted in ACM IMWUT 2025

> **TL;DR:** HandProxy是一个系统，它通过虚拟代理手扩展了语音界面的可供性，使其能够支持沉浸式环境中更具表现力的手部交互，从而克服了直接手部输入和现有语音命令的局限性，实现了高任务完成率和准确性。

**AI_Comments:** HandProxy的创新之处在于其虚拟代理手的概念，它超越了僵化的语音命令，实现了对复杂手部动作的自然语言控制。这显著提升了沉浸式环境中的可访问性和自然性，解决了当前输入方法的主要局限。其在VR/AR可访问性和用户体验方面的潜在影响是巨大的。

<details>
  <summary>Details</summary>

**Motivation:** 沉浸式环境中的手部交互作为主要输入方式面临可行性问题，例如情境障碍、运动限制和环境约束。现有的语音界面作为手部输入的替代方案，其功能有限，仅能启动基本手势和系统控制，无法支持更具表现力的手部交互。

**Method:** HandProxy系统通过引入一个虚拟代理手来扩展语音界面的可供性。用户通过语音控制虚拟手的移动，自然地描述预期交互，系统将语音翻译成一系列手部控制指令进行实时执行，而非依赖预定义的语音命令。

**Result:** 一项针对20名参与者的用户研究表明，HandProxy能有效支持虚拟环境中的多样化手部交互，实现了100%的任务完成率，平均每个语音命令尝试1.09次，命令执行准确率为91.8%，同时支持灵活、自然的语音输入，具有不同程度的控制和粒度。

**Conclusion:** HandProxy成功地扩展了语音界面的可供性，使其能够在沉浸式环境中支持富有表现力的手部交互，提供了一种强大且自然的替代方案，以克服直接手部输入的局限性。

> **ai_Abstract:** HandProxy是一个创新系统，旨在通过引入一个虚拟代理手来增强沉浸式环境中的语音界面。该系统允许用户通过自然语音描述来控制虚拟手的动作，从而实现比传统预定义命令更丰富的交互。用户研究结果表明，HandProxy在支持多样化手部交互方面表现出色，任务完成率高，命令执行准确性强，并能灵活处理不同粒度的语音输入，有效克服了直接手部输入和现有语音命令的局限性。

> **摘要翻译:** 手部交互正越来越多地成为沉浸式环境中的主要输入方式，但由于情境障碍、运动限制和环境约束，它们并非总是可行。研究和商业解决方案中已探索将语音界面作为手部输入的替代方案，但其仅限于启动基本手势和系统控制。我们引入了HandProxy，这是一个扩展语音界面可供性以支持富有表现力手部交互的系统。HandProxy不依赖于直接映射到可能交互的预定义语音命令，而是允许用户控制虚拟手作为交互代理的移动，使他们能够自然地描述预期的交互，同时系统将语音翻译成一系列手部控制指令进行实时执行。一项针对20名参与者的用户研究表明，HandProxy有效地支持了虚拟环境中的多样化手部交互，实现了100%的任务完成率，平均每个语音命令尝试1.09次，命令执行准确率为91.8%，同时支持灵活、自然的语音输入，具有不同程度的控制和粒度。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [373] [ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent](https://arxiv.org/abs/2507.18165)
> *ProactiveVA：基于LLM的UI智能体的主动式可视化分析*

*Yuheng Zhao, Xueli Shu, Liwen Fan, Lin Gao, Yu Zhang, Siming Chen* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 可视化分析, LLM, UI智能体, 主动式辅助, 人机交互

**Comment:** 11 pages, 8 figures

> **TL;DR:** ProactiveVA是一个基于LLM的UI智能体框架，通过监控用户交互提供主动式、上下文感知的可视化分析辅助。

**AI_Comments:** 该论文创新性地提出了主动式可视化分析的概念，通过LLM驱动的UI智能体解决了传统VA系统被动响应的局限性。其方法论严谨，从用户行为研究出发提炼设计要求，并构建了完整的三阶段智能体管道。该框架的通用性和有效性通过多维度评估得到验证，为未来智能VA系统的发展提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 可视化分析工具通常很复杂，用户在使用过程中可能会迷失。现有的LLM辅助VA系统只在用户明确请求时提供帮助，无法在用户最需要时主动提供建议。

**Method:** 提出了ProactiveVA框架，其中LLM驱动的UI智能体监控用户交互并主动提供上下文感知辅助。首先进行了形成性研究，分析了用户在交互日志中的求助行为，识别了用户何时需要主动帮助、需要何种帮助以及智能体应如何干预。基于此，提炼了意图识别、解决方案生成、可解释性和可控性方面的关键设计要求。根据这些要求，开发了一个包括感知、推理和行动的三阶段UI智能体管道。智能体自主感知用户在VA交互日志中的需求，通过系统的交互式探索提供量身定制的建议和直观的指导。

**Result:** 在两种代表性的VA系统中实现了该框架，证明了其通用性。通过算法评估、案例研究、专家研究和用户研究评估了其有效性。

**Conclusion:** ProactiveVA框架通过LLM驱动的UI智能体，能够主动地为用户提供上下文感知的可视化分析辅助，解决了现有系统被动响应的局限性，并展示了其有效性和通用性。

> **ai_Abstract:** ProactiveVA是一个旨在解决可视化分析中用户迷失问题的框架。它引入了一个基于LLM的UI智能体，该智能体通过监控用户交互来主动提供上下文感知的帮助。研究通过形成性研究识别了用户主动帮助的需求模式，并提炼出意图识别、解决方案生成、可解释性和可控性等设计要求。在此基础上，开发了一个感知-推理-行动的三阶段智能体管道，能够自主识别用户需求并提供定制化建议。该框架在两种VA系统中得到实现和验证，证明了其通用性和有效性。

> **摘要翻译:** 可视化分析（VA）通常应用于复杂数据，因此需要复杂的工具。虽然可视化分析使分析师能够进行数据分析，但分析师有时可能会迷失在复杂性中。这突出了对智能辅助机制的需求。然而，即使是最新的LLM辅助VA系统也只在用户明确请求时提供帮助，这使得它们在分析师最需要时提供建议方面不够智能。我们提出了一个ProactiveVA框架，其中LLM驱动的UI智能体监控用户交互并主动提供上下文感知辅助。为了设计有效的主动辅助，我们首先进行了一项形成性研究，分析了用户交互日志中的求助行为，识别了用户何时需要主动帮助、需要何种帮助以及智能体应如何干预。基于这项分析，我们提炼了意图识别、解决方案生成、可解释性和可控性方面的关键设计要求。在这些要求的指导下，我们开发了一个包括感知、推理和行动的三阶段UI智能体管道。该智能体自主感知用户在VA交互日志中的需求，通过系统的交互式探索提供量身定制的建议和直观的指导。我们在两种代表性的VA系统中实现了该框架，证明了其通用性，并通过算法评估、案例和专家研究以及用户研究评估了其有效性。我们还讨论了主动式VA当前的设计权衡和需要进一步探索的领域。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [415] [Recommender systems, representativeness, and online music: A psychosocial analysis of Italian listeners](https://arxiv.org/abs/2507.18169)
> *推荐系统、代表性与在线音乐：意大利听众的社会心理分析*

*Lorenzo Porcaro, Chiara Monaldi* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 推荐系统, 代表性危害, 在线音乐, 社会心理分析, 意大利听众

**Comment:** 

> **TL;DR:** 本研究通过对意大利听众的访谈，从社会心理学角度分析了他们与在线音乐推荐系统的关系，发现听众对推荐系统的批判性理解不足，且对表征性危害（尤其是性别差异）的认识有限，强调需要跨学科研究和算法素养来构建可信赖的推荐系统。

**AI_Comments:** 本研究的创新之处在于其独特的社会心理学视角，弥补了以往研究多集中于认知行为主义的不足。它通过定性分析揭示了听众对推荐系统和代表性问题的复杂认知，强调了文化背景和个人叙事的重要性。研究结果对未来推荐系统设计和数字素养教育具有重要启示意义，尤其是对解决算法偏见和促进公平性方面。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统塑造了全球的音乐聆听习惯，但人们对其可能造成的表征性危害日益担忧。现有研究多从认知行为主义角度探讨听众观点，却鲜少从社会心理和文化视角进行情境化分析。本研究旨在填补这一空白，从社会心理角度理解意大利听众与推荐系统的复杂关系。

**Method:** 研究通过访谈一组意大利音乐听众，并运用情感文本分析（Emotional Textual Analysis）方法分析他们的叙事。

**Result:** 研究识别出共享的文化范式，揭示了人们与聆听实践的复杂关系：即使熟悉在线平台，听众仍可能缺乏对推荐系统的批判性理解。此外，表征性问题，特别是性别差异，在在线音乐聆听的背景下似乎尚未被完全理解。

**Conclusion:** 本研究强调需要进行跨学科研究以解决表征性危害，并指出算法意识和数字素养在开发值得信赖的推荐系统中的作用。

> **ai_Abstract:** 本研究从社会心理学视角，通过对意大利音乐听众的访谈和情感文本分析，探讨了他们与在线音乐推荐系统的关系。研究发现，听众对推荐系统的批判性理解不足，且对表征性危害（特别是性别差异）的认识有限。论文强调了跨学科研究、算法意识和数字素养在构建可信赖推荐系统中的重要性。

> **摘要翻译:** 推荐系统因其在在线平台上的广泛采用而塑造了全球的音乐聆听方式。这些系统可能造成的代表性危害日益成为科学和公众辩论的一部分，其中音乐听众的观点常常从认知行为主义的角度被报道和讨论，但很少在社会心理和文化视角下进行情境化。我们朝这个方向迈进，通过访谈一群意大利音乐听众并通过情感文本分析来分析他们的叙事。通过这种方式，我们识别出共享的文化图式，揭示了人们与聆听实践的复杂关系：即使熟悉在线平台，听众可能仍然缺乏对推荐系统的批判性理解。此外，代表性问题，特别是性别差异，似乎在在线音乐聆听的背景下尚未被完全掌握。这项研究强调了需要跨学科研究来解决代表性危害，以及算法意识和数字素养在开发值得信赖的推荐系统中的作用。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [416] [On the Complexities of Testing for Compliance with Human Oversight Requirements in AI Regulation](https://arxiv.org/abs/2504.03300)
> *关于测试人工智能监管中人类监督要求合规性的复杂性*

*Markus Langer, Veronika Lazar, Kevin Baum* | **Category: cs.HC, cs.CY, K.4.1; K.5.2; J.4** | **Updated: 2025-07-24**

**Keywords:** 人工智能监管, 人类监督, 合规性测试, 社会技术人工智能治理, 欧洲人工智能法案

**Comment:** 

> **TL;DR:** 本文探讨了测试人工智能系统是否符合人类监督要求的复杂性，强调了在简单与实证测试之间取得平衡、何时更新测试、上下文依赖性以及标准操作化等方面的挑战，并指出这是社会技术人工智能治理未来面临的更广泛挑战。

**AI_Comments:** 该论文切中了当前人工智能治理中一个高度相关且关键的议题。其创新之处在于系统性地概述了确保人类监督合规性的实践和概念性困难，超越了理论讨论，突出了操作层面的复杂性。它有效地指出了人工智能治理需要从纯技术考量转向社会技术考量这一范式转变，这是一项重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在强调测试人工智能监管中人类监督要求合规性的主要挑战，这些要求是欧洲人工智能法案和人工智能治理的核心组成部分。

**Method:** 本文通过识别和讨论测试人工智能监管中人类监督要求合规性的关键挑战，并论证这些挑战反映了社会技术人工智能治理的更广泛问题。

**Result:** 测试人类监督要求合规性的主要挑战包括：平衡简单（基于清单）与资源密集型（实证）测试的难度；何时更新合规性测试的问题；人类监督要求的上下文依赖性；以及标准难以操作化。

**Conclusion:** 这些挑战揭示了社会技术人工智能治理未来面临的更广泛挑战，即从确保良好的技术产品转向确保良好的社会技术系统。

> **ai_Abstract:** 本文探讨了人工智能监管中人类监督要求合规性测试的复杂性，这是欧洲人工智能法案的关键组成部分。文章指出了多项挑战，包括在简单清单式方法与资源密集型实证测试之间进行权衡、更新合规性测试的时机、要求的上下文依赖性以及标准操作化的困难。作者认为，这些问题反映了人工智能治理从纯粹的技术产品转向社会技术系统治理的更广泛范式转变。

> **摘要翻译:** 人类监督要求是欧洲人工智能法案和人工智能治理的核心组成部分。在本文中，我们强调了测试这些要求合规性的主要挑战。一个核心困难在于平衡简单但可能无效的基于清单的方法与资源密集型和上下文敏感的对人工智能人类监督有效性的实证测试。关于何时更新合规性测试、人类监督要求的上下文依赖性以及难以操作化的标准等问题进一步使合规性测试复杂化。我们认为，这些挑战说明了社会技术人工智能治理未来面临的更广泛挑战，即从确保良好的技术产品转向确保良好的社会技术系统。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [463] [Multimodal Behavioral Patterns Analysis with Eye-Tracking and LLM-Based Reasoning](https://arxiv.org/abs/2507.18252)
> *基于眼动追踪和LLM推理的多模态行为模式分析*

*Dongyang Guo, Yasmeen Abdrabou, Enkeleda Thaqi, Enkelejda Kasneci* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 眼动追踪, 大语言模型, 多模态分析, 认知建模, 人机交互

**Comment:** 

> **TL;DR:** 本文提出一个多模态人机协作框架，结合眼动追踪数据和LLM推理，以增强认知模式提取，并在难度预测任务中表现出显著改进。

**AI_Comments:** 该论文的创新点在于将LLM的文本推理能力与眼动追踪数据的非语言特性相结合，并通过构建多模态人机协作框架来克服各自的局限性。其提出的专家-模型协同评分和混合异常检测模块增强了结果的可靠性和实用性。该方法为认知建模提供了一个可扩展且可解释的方案，在多个应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 眼动追踪数据能揭示用户认知状态但难以分析，而大语言模型（LLMs）虽擅长文本推理但难以处理时序和数值数据。因此，需要一种方法来弥合这一差距，以更有效地从眼动追踪数据中提取认知模式。

**Method:** 本文提出了一个多模态人机协作框架，包括：1) 使用水平和垂直分割结合LLM推理的多阶段管道，以发现潜在的注视模式；2) 专家模型协同评分模块，整合专家判断和LLM输出以生成行为解释的信任分数；3) 混合异常检测模块，结合基于LSTM的时间建模和LLM驱动的语义分析。

**Result:** 该方法在多项LLM和提示策略下，显示出一致性、可解释性和性能的提升，在难度预测任务中准确率高达50%。

**Conclusion:** 该方法为认知建模提供了一个可扩展、可解释的解决方案，在自适应学习、人机交互和教育分析等领域具有广泛潜力。

> **ai_Abstract:** 本文提出一个多模态人机协作框架，旨在通过结合眼动追踪数据和LLM推理来提升认知模式的提取。该框架包含一个多阶段管道用于发现注视模式，一个专家-模型协同评分模块用于评估行为解释，以及一个混合异常检测模块。实验结果表明，该方法显著提高了认知模式分析的一致性、可解释性和性能，尤其在难度预测任务中表现出色，为认知建模提供了可扩展且可解释的解决方案。

> **摘要翻译:** 眼动追踪数据揭示了用户认知状态的宝贵见解，但由于其结构化、非语言性质而难以分析。虽然大型语言模型（LLMs）擅长对文本进行推理，但它们在处理时间性和数值数据方面存在困难。本文提出了一个多模态人机协作框架，旨在增强从眼动追踪信号中提取认知模式的能力。该框架包括：(1) 一个多阶段管道，利用水平和垂直分割结合LLM推理来发现潜在的注视模式；(2) 一个专家-模型协同评分模块，将专家判断与LLM输出相结合，为行为解释生成信任分数；以及(3) 一个混合异常检测模块，结合基于LSTM的时间建模和LLM驱动的语义分析。我们在多个LLM和提示策略上的结果显示，在一致性、可解释性和性能方面均有所改进，在难度预测任务中准确率高达50%。这种方法为认知建模提供了一个可扩展、可解释的解决方案，并在自适应学习、人机交互和教育分析方面具有广泛潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [464] [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org/abs/2504.17999)
> *快慢流：认知负荷感知流媒体用于高效LLM服务*

*Chang Xiao, Brenda Yang* | **Category: cs.HC, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 流媒体, 认知负荷, 资源效率, 自适应

**Comment:** 

> **TL;DR:** 本文提出一种自适应流媒体方法，根据用户认知负荷动态调整LLM输出速度，以减少计算资源浪费并提高效率。

**AI_Comments:** 该论文的创新点在于将认知负荷的概念引入到LLM的流媒体服务中，提出了一种新颖的自适应流媒体策略。这对于优化LLM服务中的资源分配和提升用户体验具有重要意义，尤其是在云计算环境下，能够有效缓解高峰期的资源压力。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLM）的生成式对话界面通常以计算预算决定的速度逐令牌输出，忽略了人类阅读速度和内容相关的认知负荷，导致计算资源低效利用，尤其在高峰期造成资源浪费和延迟。

**Method:** 作者提出一种自适应流媒体方法，根据推断的认知负荷实时动态调整LLM流输出的速度。该方法估计与流内容相关的认知负荷，并在复杂或信息丰富的片段中策略性地减慢流速，从而为其他用户释放计算资源。研究通过基于众包用户研究数据（涵盖各类LLM生成内容）统计模型进行的统计分析和模拟来验证其方法。

**Result:** 结果表明，这种自适应方法可以有效减少计算消耗，同时大部分时间将流媒体速度保持在用户正常阅读速度之上。

**Conclusion:** 本文提出了一种认知负荷感知的自适应流媒体方法，通过动态调整LLM输出速度，有效解决了现有LLM服务中计算资源浪费的问题，实现了资源效率的提升，同时保持了良好的用户体验。

> **ai_Abstract:** 本文提出了一种名为“快慢流”的自适应流媒体方法，旨在解决大型语言模型（LLM）在生成对话时因忽视用户认知负荷和阅读速度而导致的计算资源浪费问题。该方法根据推断的认知负荷动态调整LLM输出速度，在内容复杂时减慢速度，从而节省计算资源。通过统计分析和模拟，研究证明该方法能有效降低资源消耗，同时保持用户可接受的阅读速度。

> **摘要翻译:** 由大型语言模型（LLM）驱动的生成式对话界面通常以计算预算决定的速度逐令牌输出，但往往忽略了实际的人类阅读速度和与内容相关的认知负荷。这种不匹配经常导致计算资源的低效利用。例如，在基于云的服务中，流媒体内容的速度快于用户阅读速度显得不必要，从而导致计算资源的浪费和可能给其他用户带来延迟，尤其是在高峰使用期间。为了解决这个问题，我们提出了一种自适应流媒体方法，该方法根据推断的认知负荷实时动态调整LLM流输出的速度。我们的方法估计与流内容相关的认知负荷，并在复杂或信息丰富的片段中策略性地减慢流速，从而为其他用户释放计算资源。我们基于从众包用户研究中收集到的各种LLM生成内容数据得出的统计模型进行了统计分析和模拟。我们的结果表明，这种自适应方法可以有效减少计算消耗，同时大部分时间将流媒体速度保持在用户正常阅读速度之上。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [511] [Talking to...uh...um...Machines: The Impact of Disfluent Speech Agents on Partner Models and Perspective Taking](https://arxiv.org/abs/2507.18315)
> *与...呃...嗯...机器对话：不流畅语音代理对伙伴模型和视角采纳的影响*

*Rhys Jacka, Paola R. Peña, Sophie Leonard, Éva Székely, Benjamin R. Cowan* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 语音不流畅, 人机对话, 伙伴模型, 视角采纳, 自我中心沟通

**Comment:** 12 pages, 3 figures, in Proceedings of the 7th ACM Conference on
  Conversational User Interfaces

> **TL;DR:** 在人机对话中，语音不流畅对伙伴模型和视角采纳的影响尚不明确。一项研究发现，参与者认为不流畅的语音代理更胜任，但与不流畅代理的互动似乎增加了以自我为中心的沟通，尽管效果不明确。

**AI_Comments:** 这项研究的创新之处在于将语音不流畅这一在人际交流中被广泛研究的现象引入人机对话领域。其发现不流畅的机器代理被认为更胜任，这与直觉相反，并提出了有趣的解释空间。然而，关于以自我为中心沟通增加的结论因可信区间宽泛而显得不够“清晰”，这提示了未来研究需要更精细的实验设计来验证这些效果。

<details>
  <summary>Details</summary>

**Motivation:** 语音不流畅在人际交流（HHC）中的视角采纳和受众设计中发挥作用，但在人机对话（HMD）中其影响知之甚少。

**Method:** 在一次在线命名匹配任务中，61名参与者与使用流畅或不流畅语音的语音代理进行互动。参与者在任务前后都完成了伙伴建模问卷（PMQ）。

**Result:** 互动后评估显示，参与者认为不流畅的代理更具能力，尽管任务前评分没有显著差异。但在对话灵活性或类人性评估方面没有观察到显著差异。研究还揭示了参与者与语音代理互动时自我中心和异他中心语言产生的证据。与不流畅语音代理的互动似乎增加了以自我为中心的沟通，但由于可信区间宽泛，这种效果并不明确。

**Conclusion:** 论文讨论了这一发现的潜在解释，重点关注不流畅性如何影响人机对话中的伙伴模型和语言产生。

> **ai_Abstract:** 本研究探讨了语音不流畅在人机对话（HMD）中的影响，这是人际交流中已知的因素。通过一项在线任务，61名参与者与流畅或不流畅的语音代理互动。结果显示，参与者在互动后认为不流畅的代理更具能力，尽管任务前评价无差异。然而，对话灵活性和类人性方面没有显著差异。研究还发现，与不流畅代理的互动可能增加参与者的自我中心沟通，尽管这一效果的确定性因宽泛的可信区间而受限。论文讨论了不流畅性如何影响HMD中的伙伴模型和语言产生。

> **摘要翻译:** 语音不流畅在人际交流（HHC）中的视角采纳和受众设计中发挥作用，但在人机对话（HMD）中其影响知之甚少。在一项在线命名匹配任务中，61名参与者与使用流畅或不流畅语音的语音代理进行互动。参与者在任务前后都完成了伙伴建模问卷（PMQ）。互动后评估显示，参与者认为不流畅的代理更具能力，尽管任务前评分没有显著差异。但在对话灵活性或类人性评估方面没有观察到显著差异。我们的研究结果还揭示了参与者与语音代理互动时自我中心和异他中心语言产生的证据。与不流畅语音代理的互动似乎增加了以自我为中心的沟通，与流畅代理相比。尽管宽泛的可信区间意味着这种效果并不明确。我们讨论了这一发现的潜在解释，重点关注不流畅性如何影响人机对话中的伙伴模型和语言产生。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [518] [LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models](https://arxiv.org/abs/2506.06874)
> *LLM-D12：大型语言模型工具性和关系性依赖的双维度量表*

*Ala Yankouskaya, Areej B. Babiker, Syeda W. F. Rizvi, Sameha Alshakhsi, Magnus Liebherr, Raian Ali* | **Category: cs.HC, cs.AI, Human-Centered Computing -- > Human computer interaction (HCI) -->
  HCI design and evaluation methods** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 依赖, 问卷, 工具性依赖, 关系性依赖

**Comment:** 

> **TL;DR:** 本文开发并验证了一个名为LLM-D12的12项问卷，用于衡量人们对大型语言模型的依赖程度，并发现其包含工具性依赖和关系性依赖两个维度。

**AI_Comments:** 本文的创新之处在于提出了一个全新的双维度视角来衡量对大型语言模型的依赖，区分了工具性依赖和关系性依赖。这超越了传统行为成瘾的框架，更细致地捕捉了人与LLM互动的复杂性。该研究对于理解和评估LLM在社会中的影响具有重要意义，尤其是在识别潜在问题性使用方面提供了新的工具和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 目前评估个人对大型语言模型（LLMs）依赖程度的有效工具稀缺，且主要基于传统的行为成瘾症状进行改编，这被认为是一个概念上的局限性，因为LLM与人类的关系更为微妙，需要一个全新的视角。

**Method:** 研究开发并验证了一个新的12项问卷LLM-D12来衡量LLM依赖性。该量表基于作者先前的理论工作，并从英国的526名参与者那里收集了答复。采用分样本方法，对总样本的独立两半进行了探索性因子分析和验证性因子分析。

**Result:** 因子分析支持了LLM-D12量表的双因子结构：工具性依赖（六项）和关系性依赖（六项）。工具性依赖反映个体在决策和认知任务中依赖LLM的程度，而关系性依赖则捕捉个体将LLM视为具有社交意义、有知觉或类似伴侣实体的倾向。该双因子结构表现出卓越的内部一致性和清晰的判别效度，外部验证也证实了其概念基础和两个子量表之间的区别。

**Conclusion:** LLM-D12量表的心理测量学特性和结构表明，对LLM的依赖不一定意味着功能障碍，但仍可能反映在特定情境下可能变得有问题的依赖水平。

> **ai_Abstract:** 本文针对现有衡量大型语言模型（LLM）依赖工具的局限性，开发并验证了一个名为LLM-D12的12项问卷。该问卷基于526名英国参与者的数据，通过因子分析确立了工具性依赖和关系性依赖两个核心维度，并展示了良好的心理测量学特性。研究强调对LLM的依赖是一个多维度的现象，不必然是病态的，但仍需关注其潜在问题。

> **摘要翻译:** 人们越来越关注如何与大型语言模型（LLMs）互动，以及此类模型是否会引发依赖甚至成瘾行为。评估个人对LLMs依赖程度的有效工具稀缺，且主要基于经典的行为成瘾症状，并适应LLM使用情境。我们认为这是一个概念上的局限性，因为LLM与人类的关系更为微妙，需要一个全新而独特的视角。为了弥补这一空白，我们开发并验证了一个新的12项问卷，用于衡量LLM依赖性，称为LLM-D12。该量表基于作者先前的理论工作，相应地开发了项目，并从英国的526名参与者那里收集了答复。采用分样本方法，对总样本的独立两半进行了探索性因子分析和验证性因子分析，结果支持了双因子结构：工具性依赖（六项）和关系性依赖（六项）。工具性依赖反映了个体在决策和认知任务中依赖LLMs以获得支持或协作的程度。关系性依赖则捕捉了将LLMs视为具有社交意义、有知觉或类似伴侣实体的倾向。该双因子结构表现出卓越的内部一致性和清晰的判别效度。外部验证证实了其概念基础以及两个子量表之间的区别。我们对LLM-D12量表的心理测量学特性和结构进行了阐释，结合了新兴的观点，即对LLMs的依赖不一定表明功能障碍，但仍可能反映在某些情况下可能变得有问题的依赖水平。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [559] [PALM: PAnoramic Learning Map Integrating Learning Analytics and Curriculum Map for Scalable Insights Across Courses](https://arxiv.org/abs/2507.18393)
> *PALM：集成学习分析和课程图谱的广角学习地图，实现跨课程的可扩展洞察*

*Mahiro Ozaki, Li Chen, Shotaro Naganuma, Valdemar Švábenský, Fumiya Okubo, Atsushi Shimada* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 学习分析, 课程图谱, 可扩展性, 自我调节学习, 学习仪表板

**Comment:** To appear in the Proceedings of the IEEE SMC 2025 conference

> **TL;DR:** PALM是一个将学习分析与课程图谱结合的仪表板，旨在提供跨课程的可扩展洞察，并增强学生的学习意识和自我调节能力。

**AI_Comments:** PALM的创新之处在于其将学习分析与课程图谱相结合，突破了传统学习分析仅关注个体课程的局限，实现了跨课程的宏观洞察。这对于学生理解自身长期学习轨迹和提升自我调节能力具有重要意义。其可扩展性和对学生意识的提升是亮点，但论文也指出系统仍需持续改进。

<details>
  <summary>Details</summary>

**Motivation:** 传统学习分析（LA）主要集中在个体课程或学习者，缺乏考虑课程之间关系和长期学习轨迹的框架，导致可扩展性挑战。

**Method:** 本研究提出并评估了PAnoramic Learning Map (PALM)，一个将多层教育数据整合到课程图谱中的学习分析仪表板。通过系统评估来衡量PALM对学生学习行为意识的影响以及其与现有系统的比较表现。

**Result:** PALM增强了学习者对学习规划和反思的意识，特别是通过视觉呈现个人学习历史和统计趋势，提高了感知行为控制。PALM在视觉吸引力和可用性方面获得了比现有系统显著更高的评价。

**Conclusion:** PALM通过提供以前无法获得的洞察，增强了学生的自我调节学习和参与度，代表了学习分析领域向全面和可扩展方法迈出的重要一步。

> **ai_Abstract:** 本研究提出了PALM（广角学习地图），一个结合学习分析和课程图谱的仪表板，旨在解决传统学习分析在跨课程和长期学习轨迹方面的局限性。PALM通过整合多层教育数据，帮助学生直观理解学习记录和学业进展。系统评估显示，PALM有效提升了学生的学习规划和反思意识，并因其出色的视觉吸引力和可用性而优于现有系统，从而促进了学生的自我调节学习和参与度。

> **摘要翻译:** 本研究提出并评估了广角学习地图（PALM），这是一种学习分析（LA）仪表板，旨在通过整合课程级别信息来解决学习分析的可扩展性挑战。传统的学习分析研究主要集中在个体课程或学习者，并且通常缺乏一个考虑课程之间关系和长期学习轨迹的框架。为了弥补这一差距，开发了PALM，将多层教育数据整合到课程图谱中，使学习者能够直观地理解他们的学习记录和学业进展。我们进行了系统评估，以评估PALM在两个关键领域中的有效性：（1）其对学生学习行为意识的影响，以及（2）其与现有系统的比较表现。结果表明，PALM增强了学习者对学习规划和反思的意识，特别是通过视觉呈现个人学习历史和统计趋势，这阐明了学习行为和结果之间的联系，从而提高了感知行为控制。尽管PALM作为一个系统需要持续改进，但其在视觉吸引力和可用性方面获得了比现有系统显著更高的评价。通过作为一种提供以前无法获得洞察的信息资源，PALM增强了自我调节学习和参与度，代表了超越传统学习分析，迈向全面和可扩展方法的重大一步。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [572] [Full-body WPT: wireless powering with meandered e-textiles](https://arxiv.org/abs/2506.17606)
> *全身WPT：采用弯曲电子纺织品的无线供电*

*Ryo Takahashi, Takashi Sato, Wakako Yukita, Tomoyuki Yokota, Takao Someya, Yoshihiro Kawahara* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 无线电力传输, 电子纺织品, 弯曲线圈, 可穿戴技术, 以身体为中心的网络

**Comment:** 

> **TL;DR:** 该论文介绍了全身WPT，一种使用纺织线圈在皮肤表面局部生成磁场的安全高效无线供电系统，适用于可穿戴设备。

**AI_Comments:** 该研究的创新之处在于利用弯曲电子纺织品在线圈中限制磁场，使其仅作用于皮肤表面，从而显著提高了以身体为中心的无线供电的安全性。这解决了传统感应系统的一个关键限制，并为可穿戴电子设备和连续健康监测开辟了新的可能性。将技术集成到纺织品中使其适用于普适应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的感应系统将强磁场发射到深层组织中，存在安全隐患。因此，需要一种安全高效的人体周围无线供电系统，特别是为普适健康监测、增强现实和人机交互系统提供支持。

**Method:** 本文提出了“全身WPT”系统，该系统使用弯曲纺织线圈在皮肤表面局部生成强磁场。它采用低损耗导电纱线以实现节能和轻量化设计。通过仿真和实验原型分析了其性能。

**Result:** 该系统表现出高功率传输效率以及对用户运动和姿势的适应性。它利用集成到可穿戴材料中的弯曲纺织线圈提供了一个安全高效的分布式电力网络。

**Conclusion:** 全身WPT系统利用弯曲纺织线圈，提供了一个安全高效的人体周围分布式电力网络，突出了其作为普适健康监测、增强现实和人机交互系统基础层的潜力。

> **ai_Abstract:** 本文介绍了全身WPT，一种新颖的无线电力传输系统，它使用弯曲纺织线圈在皮肤表面创建局部磁场。与传统感应系统相比，这种方法通过避免深层组织暴露来提高安全性和效率。该系统采用低损耗导电纱线设计，以实现节能和轻量化，并通过仿真和原型验证了其高功率传输效率和对用户运动的适应性。它为可穿戴应用提供了一个安全高效的分布式电力网络，为先进的健康监测、增强现实和人机交互铺平了道路。

> **摘要翻译:** 我们提出了全身WPT，一种使用弯曲纺织线圈在人体周围进行无线电力网络连接的方法。与传统将强磁场发射到体内深层组织的感应系统不同，弯曲线圈即使在扩展到人体大小时，也能在皮肤表面局部生成强磁场。这种局部感应系统提高了人体周围无线电力的安全性和效率。此外，使用低损耗导电纱线实现了节能轻量化设计。我们通过仿真和实验原型分析了我们设计的性能，展示了高功率传输效率以及对用户运动和姿势的适应性。我们的系统利用集成到可穿戴材料中的弯曲纺织线圈提供了一个安全高效的分布式电力网络，突出了以身体为中心的无线电力网络作为普适健康监测、增强现实和人机交互系统基础层的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [606] [Multisensory Integration and Sensory Substitution Across Vision, Audition, and Haptics: Answering the What, Which, and When in Study Protocols](https://arxiv.org/abs/2507.18401)
> *多感官整合与视觉、听觉和触觉的感官替代：回答研究方案中的内容、选择和时机*

*Andrew Jeyathasan, Swati Banerjee* | **Category: cs.HC, q-bio.NC** | **Updated: 2025-07-24**

**Keywords:** 多感官整合, 感官替代, 研究方案, 视觉, 听觉, 触觉

**Comment:** 

> **TL;DR:** 本文探讨了多感官整合（MSI）研究中设计有效研究方案的关键因素，特别是当涉及三种或更多感官模态时。

**AI_Comments:** 本文的重要性在于为多感官整合研究提供了方法论上的指导，特别是在处理三种或更多感官模态时的复杂性。它强调了设计严谨研究方案的关键因素，有助于推动该领域的研究规范化和深入发展。其创新之处在于系统性地梳理了多模态MSI研究中的挑战与应对策略。

<details>
  <summary>Details</summary>

**Motivation:** 理解多感官整合（MSI）需要检查感官模态之间的相互作用，但三或更多模态的整合仍未得到充分探索。现有的MSI研究必须考虑跨模态对应、一致性、认知负荷和刺激时机等因素，而这些因素在模态增多时变得越来越复杂。

**Method:** 本文通过检查关键因素，并探讨如何将这些因素应用于设计有效的多感官整合（MSI）研究方案。

**Result:** 本文探讨了跨模态对应、一致性、认知负荷和刺激时机等关键因素，并说明了它们如何应用于设计有效的MSI研究方案。

**Conclusion:** 本文旨在通过探讨关键因素，为设计更有效、更全面的多感官整合研究方案提供指导。

> **ai_Abstract:** 本文探讨了多感官整合（MSI）研究中涉及视觉、听觉和触觉等多种感官模态时的复杂性。研究指出，尽管单模态或双模态研究较多，但三种或更多模态的整合仍是未充分探索的领域。文章详细分析了影响MSI研究设计的关键因素，如跨模态对应、一致性、认知负荷和刺激时机，并阐述了如何运用这些因素来构建有效的MSI研究方案。

> **摘要翻译:** 我们通过多种感官体验世界，这些感官协同工作，无论是日常生活还是沉浸式技术，都能创造出连贯的感知。理解这种多感官整合（MSI）需要检查感官模态之间的相互作用，每种模态都有独特的时间动态和特征。虽然大多数研究关注单模态或双模态线索，但三种或更多模态的整合仍未得到充分探索。MSI研究必须考虑跨模态对应、一致性、认知负荷和刺激时机等因素，这些因素在模态增多时变得越来越复杂。本文探讨了这些关键因素以及如何将它们应用于设计有效的MSI研究方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [620] [Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations](https://arxiv.org/abs/2507.17248)
> *Reality Proxy：通过抽象表示实现MR中与真实世界对象的流畅交互*

*Xiaoan Liu, Difan Jia, Xianhao Carton Liu, Mar Gonzalez-Franco, Chen Zhu-Tian* | **Category: cs.HC, cs.AI, cs.GR, H.5.2; I.3.6** | **Updated: 2025-07-24**

**Keywords:** 混合现实, 人机交互, 抽象表示, 代理, Reality Proxy

**Comment:** 16 pages, 9 figures. Accepted for publication in UIST'25 (The 38th
  Annual ACM Symposium on User Interface Software and Technology), Busan,
  Republic of Korea, 28 Sep - 1 Oct 2025

> **TL;DR:** “Reality Proxy”通过引入真实世界对象的抽象代理来解决混合现实中与拥挤、遥远或部分遮挡对象的交互难题，从而实现更流畅、更丰富的人机交互。

**AI_Comments:** 该论文提出了一种创新的交互范式，通过引入“代理”的概念，巧妙地解决了混合现实中与复杂真实世界对象交互的固有难题。其核心创新在于将交互从物理约束中解耦，并利用AI丰富代理的语义信息，从而在不增加用户负担（无需新手势）的情况下，极大地提升了MR交互的流畅性和丰富性。该方法具有很强的通用性和潜力，对未来MR系统的设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在混合现实（MR）中，与真实世界对象（如拥挤、遥远或部分遮挡的对象）交互通常很困难，阻碍了直接的选择和操作。这源于直接在物理对象上进行交互，输入与物理约束紧密耦合。

**Method:** 论文提出“代理”——真实世界对象的抽象表示，将交互从物理约束中解耦。具体实现是“Reality Proxy”系统，该系统在选择过程中将交互目标从物理对象无缝转移到其代理。系统利用AI丰富代理的语义属性和分层空间关系，支持新的交互方式（如浏览、基于属性的过滤、导航嵌套组、复杂多对象选择），且无需新手势或菜单系统。

**Result:** 演示了Reality Proxy在多种场景下的多功能性，包括办公室信息检索、大规模空间导航和多无人机控制。专家评估表明该系统具有实用性和可用性。

**Conclusion:** 基于代理的抽象为未来的MR系统提供了一种强大且可泛化的人机交互范式。

> **ai_Abstract:** 本文提出“Reality Proxy”系统，旨在解决混合现实中与拥挤、遥远或被遮挡真实世界对象交互的难题。该系统通过引入真实世界对象的抽象“代理”来解耦交互与物理约束。Reality Proxy利用AI为代理添加语义属性和空间关系，从而实现浏览、过滤和复杂多对象选择等新型交互，且无需额外手势。系统在多种场景下展现出实用性，并被认为为未来MR系统提供了一种通用且强大的交互范式。

> **摘要翻译:** 在混合现实（MR）中与真实世界对象交互时，当它们拥挤、遥远或部分被遮挡时，往往会变得困难，阻碍了直接的选择和操作。我们观察到这些困难源于直接在物理对象上进行交互，其中输入与它们的物理约束紧密耦合。我们的关键洞察是通过引入代理——真实世界对象的抽象表示——将交互从这些约束中解耦。我们将这一概念体现在Reality Proxy中，这是一个在选择过程中无缝地将交互目标从物理对象转移到其代理的系统。除了促进基本选择之外，Reality Proxy还使用AI来丰富代理的语义属性及其对应物理对象的分层空间关系，从而在MR中实现新颖且以前繁琐的交互——例如浏览、基于属性的过滤、导航嵌套组和复杂的多对象选择——所有这些都无需新的手势或菜单系统。我们展示了Reality Proxy在多种场景下的多功能性，包括办公室信息检索、大规模空间导航和多无人机控制。专家评估表明该系统具有实用性和可用性，这表明基于代理的抽象为未来的MR系统提供了一种强大且可泛化的人机交互范式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [649] [Towards Understanding Decision Problems As a Goal of Visualization Design](https://arxiv.org/abs/2507.18428)
> *走向理解决策问题作为可视化设计的目标*

*Lena Cibulski, Stefan Bruckner* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 决策制定, 可视化设计, 表征方案, 任务模型, 决策支持

**Comment:** 

> **TL;DR:** 本文提出了一个决策问题表征方案，旨在更好地支持可视化中的决策制定任务，并为未来的决策中心可视化研究提供指导。

**AI_Comments:** 这篇论文的创新点在于提出了一个结构化的方案来表征可视化中的决策问题，填补了现有任务模型对决策背景条件关注不足的空白。其重要性在于为可视化设计提供了更精确的指导，有助于开发出真正支持用户决策的工具。

<details>
  <summary>Details</summary>

**Motivation:** 决策制定是可视化研究中一个核心但定义不足的目标，现有任务模型在处理决策过程时常忽略构成决策的条件。

**Method:** 本文提出了一个表征方案，该方案通过描述数据、用户和任务背景的关键属性来刻画决策问题。通过将该方案应用于表征现有设计研究中以决策为目标的任务，来证明其效用。

**Result:** 该方案有助于可视化研究人员更精确地阐明决策支持主张，并指导适当的视觉编码和交互设计。通过应用验证，突出了以决策为中心的可视化未来研究机会。

**Conclusion:** 通过提出的决策问题表征方案，可以更好地理解和支持可视化中的决策任务，并为未来的决策中心可视化研究指明方向。

> **ai_Abstract:** 本文旨在解决可视化研究中决策制定目标定义不清的问题，提出了一种决策问题表征方案。该方案通过描述数据、用户和任务背景的关键属性来刻画决策问题，从而帮助研究者更精确地阐明决策支持主张，并指导视觉编码和交互设计。论文通过应用于现有设计研究，展示了该方法的实用性，并为未来以决策为中心的可视化研究提供了方向。

> **摘要翻译:** 决策制定是可视化研究中一个核心但定义不足的目标。尽管现有任务模型处理决策过程，但它们常常忽略了构成决策的条件。为了更好地支持决策制定任务，我们提出了一个表征方案，通过数据、用户和任务背景的关键属性来描述决策问题。该方案有助于可视化研究人员更精确地阐明决策支持主张，并指导适当的可视化编码和交互设计。我们通过将其应用于表征现有设计研究中以决策为目标的任务来证明我们方法的实用性，突出了以决策为中心的可视化未来研究机会。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [654] [Exploring Communication Strategies for Collaborative LLM Agents in Mathematical Problem-Solving](https://arxiv.org/abs/2507.17753)
> *探索协作式LLM智能体在数学问题解决中的沟通策略*

*Liang Zhang, Xiaoming Zhai, Jionghao Lin, Jionghao Lin, Jennifer Kleiman, Diego Zapata-Rivera, Carol Forsyth, Yang Jiang, Xiangen Hu, Arthur C. Graesser* | **Category: cs.HC, cs.AI, cs.CL, cs.CY** | **Updated: 2025-05-02**

**Keywords:** LLM智能体, 沟通策略, 协作问题解决, 数学教育, GPT-4o

**Comment:** 

> **TL;DR:** 本研究探讨了协作式LLM智能体在数学问题解决中的沟通策略。结果显示，双智能体设置优于单智能体，其中“点对点协作”模式在MATH数据集上取得了最高的准确率，强调了有效沟通策略的重要性。

**AI_Comments:** 该研究创新性地系统评估了LLM智能体间的沟通策略，填补了现有研究的空白。其发现点对点协作在数学问题解决中表现最佳，且双智能体优于单智能体，为多智能体系统的设计提供了宝贵的实证依据。这项工作对于推动AI辅助教育和多智能体LLM应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）智能体在AI辅助教育中日益普及，但目前鲜有研究系统地评估不同沟通策略对智能体问题解决能力的影响。

**Method:** 本研究在双智能体、基于聊天的数学问题解决环境中使用OpenAI GPT-4o模型，考察了四种沟通模式：师生互动、点对点协作、互惠式同伴教学和批判性辩论。评估基于MATH数据集进行。

**Result:** 研究结果显示，双智能体设置优于单智能体，其中“点对点协作”模式达到了最高准确率。此外，陈述、确认和提示等对话行为在协作问题解决中发挥着关键作用。

**Conclusion:** 多智能体框架可以增强计算任务，而有效的沟通策略对于解决AI教育中的复杂问题至关重要。

> **ai_Abstract:** 本研究旨在探索协作式LLM智能体在数学问题解决中的沟通策略。论文在一个基于GPT-4o的双智能体、聊天环境中，评估了师生互动、点对点协作、互惠式同伴教学和批判性辩论四种沟通模式。在MATH数据集上的实验结果表明，双智能体配置优于单智能体，其中点对点协作模式表现出最高的准确率。研究强调了特定对话行为在协作中的关键作用，并指出有效的沟通策略对于解决AI教育中的复杂问题至关重要。

> **摘要翻译:** 大型语言模型（LLM）智能体在AI辅助教育中越来越多地被用于支持辅导和学习。LLM智能体之间有效的沟通策略可以提高协作式问题解决的效率，并促进在教育中经济高效的采用。然而，很少有研究系统地评估不同沟通策略对智能体问题解决能力的影响。我们的研究在双智能体、基于聊天的数学问题解决环境中使用OpenAI GPT-4o模型，考察了四种沟通模式：师生互动、点对点协作、互惠式同伴教学和批判性辩论。在MATH数据集上进行评估，我们的结果表明，双智能体设置优于单智能体，其中“点对点协作”实现了最高准确率。陈述、确认和提示等对话行为在协作问题解决中发挥着关键作用。虽然多智能体框架增强了计算任务，但有效的沟通策略对于解决AI教育中的复杂问题至关重要。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [690] [A Custom-Built Ambient Scribe Reduces Cognitive Load and Documentation Burden for Telehealth Clinicians](https://arxiv.org/abs/2507.17754)
> *定制环境听写员降低远程医疗临床医生的认知负荷和文档负担*

*Justin Morse, Kurt Gilbert, Kyle Shin, Rick Cooke, Peyton Rose, Jack Sullivan, Angelo Sisante* | **Category: cs.HC, cs.AI, cs.CY** | **Updated: 2025-05-02**

**Keywords:** 环境听写员, 远程医疗, 认知负荷, 文档负担, GPT-4o

**Comment:** 

> **TL;DR:** 该论文介绍了一种为远程医疗临床医生定制的AI驱动环境听写员，旨在减轻认知负荷和文档负担，该系统利用Whisper、GPT-4o和BART。

**AI_Comments:** 该论文展示了先进AI技术（Whisper、GPT-4o、BART）在医疗保健领域的实际应用，直接解决了临床医生倦怠问题。其亮点在于展示了实际应用中的广泛采纳和可量化的效益（认知负荷和文档负担的减少），并通过用户反馈和客观质量指标（LLM作为评判者）进行了验证。与现有EHR系统的集成也强调了成功医疗科技实施的关键方面。

<details>
  <summary>Details</summary>

**Motivation:** 临床医生倦怠促使环境医疗听写员在临床中得到越来越多的采用，该研究旨在通过AI系统减轻行政负担，支持临床医生提供高效、高质量的护理。

**Method:** 开发了一个定制的环境听写员应用程序，并将其集成到EHR系统中。该应用程序使用Whisper进行转录，并利用GPT-4o的模块化上下文学习管道自动生成SOAP笔记和患者指导。此外，还使用微调的BART模型对笔记进行后处理以提高简洁性。

**Result:** 该应用程序生成的笔记质量超过了LLM作为评判者确定的专家手写笔记的质量。已在Included Health被超过540名临床医生广泛采用。94%的受访临床医生报告认知负荷降低，97%报告文档负担减轻。使用BART模型后处理笔记可提高简洁性。

**Conclusion:** AI系统在减轻行政负担和支持临床医生提供高效、高质量护理方面具有巨大潜力。

> **ai_Abstract:** 这篇论文介绍了一款为远程医疗临床医生定制的AI驱动环境听写员应用程序，该程序已集成到EHR系统。它利用Whisper进行转录，并结合GPT-4o生成SOAP笔记和患者指导。系统生成的笔记质量优于专家手写笔记，并已被广泛采用，显著减轻了临床医生的认知负荷和文档负担。此外，通过BART模型处理还能提高笔记的简洁性，展示了AI在简化医疗管理和提升护理质量方面的巨大潜力。

> **摘要翻译:** 临床医生倦怠促使环境医疗听写员在临床中得到越来越多的采用。在这项工作中，我们介绍了一个定制的环境听写员应用程序，该应用程序集成到Included Health的EHR系统中，Included Health是一家提供远程医疗服务的个性化一体化医疗公司。该应用程序使用Whisper进行转录，并采用模块化上下文学习管道与GPT-4o自动生成SOAP笔记和患者指导。对模拟就诊数据的测试表明，该应用程序生成的笔记质量超过了由LLM作为评判者确定的专家手写笔记的质量。该应用程序已被临床实践广泛采用，Included Health有超过540名临床医生至少使用过该应用程序一次。94%（n=63）的受访临床医生报告在使用该应用程序时认知负荷降低，97%（n=66）报告文档负担减轻。此外，我们还表明，使用微调的BART模型对笔记进行后处理可以提高简洁性。这些发现突出了AI系统在减轻行政负担和支持临床医生提供高效、高质量护理方面的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [691] [High-Dimensional Data Classification in Concentric Coordinates](https://arxiv.org/abs/2507.18450)
> *同心坐标系中的高维数据分类*

*Alice Williams, Boris Kovalerchuk* | **Category: cs.HC, cs.LG** | **Updated: 2025-05-16**

**Keywords:** 同心坐标系, 高维数据可视化, 机器学习, 平行坐标系, 通用线坐标

**Comment:** 8 pages, 21 figures

> **TL;DR:** 本文提出了一种利用无损同心坐标系的可解释框架，以解决高维数据可视化中现有方法的局限性，并支持机器学习算法可视化和人机交互。

**AI_Comments:** 该论文提出了一种新颖的坐标系——同心坐标系，旨在解决高维数据可视化中长期存在的遮挡和计算效率问题。其创新点在于将多种现有坐标系进行概括和整合，并强调了对机器学习算法可视化和人机交互的直接支持，这在高维数据分析领域具有潜在的重要性。然而，摘要中并未提供实验结果或性能评估，因此无法判断其实际效果和局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有解释性多维数据可视化方法在高维无损可视化方面存在局限性，无法避免遮挡，并且在参数化可视化方面计算能力有限。

**Method:** 本文提出了一种支持低维到高维数据的框架，该框架使用无损同心坐标系，同心坐标系是平行坐标系和圆形坐标系的更紧凑的概括。这些是通用线坐标可视化的一种形式，可以直接支持机器学习算法可视化并促进人机交互。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对现有高维数据可视化方法在无损性、遮挡和计算能力上的局限性，提出了一种基于无损同心坐标系的新型框架。该框架是平行坐标系和圆形坐标系的紧凑泛化，属于通用线坐标可视化，能够直接支持机器学习算法的可视化并促进人机交互。

> **摘要翻译:** 多维数据通过可解释方法的可视化仍然受到高维无损可视化能力以及参数化可视化计算能力的限制，这些限制导致遮挡问题。本文提出了一种支持低维到高维数据的框架，该框架使用无损同心坐标系，同心坐标系是平行坐标系和圆形坐标系的更紧凑的概括。这些是通用线坐标可视化的一种形式，可以直接支持机器学习算法可视化并促进人机交互。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [730] [ForcePinch: Force-Responsive Spatial Interaction for Tracking Speed Control in XR](https://arxiv.org/abs/2507.18510)
> *ForcePinch：用于XR中跟踪速度控制的力响应空间交互*

*Chenyang Zhang, Tiffany S Ma, John Andrews, Eric J Gonzalez, Mar Gonzalez-Franco, Yalong Yang* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 力响应, 空间交互, XR, 跟踪速度控制, ForcePinch

**Comment:** 

> **TL;DR:** ForcePinch是一种新型的力响应空间交互方法，允许用户通过改变捏合力来直观地调节指针跟踪速度，在快速和精确移动之间平稳过渡，以解决现有XR交互中跟踪速度调整与手部动作耦合的问题。

**AI_Comments:** ForcePinch的创新之处在于将物理世界中“摩擦控制”的直观概念引入到XR空间交互中，通过捏合力而非纯粹的手部移动来调节跟踪速度，极大地提升了交互的灵活性和精度。这种将力反馈与空间追踪结合的方法为XR设备的输入方式提供了新的可能性，尤其是在需要精细控制的场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在3D环境中进行空间交互需要在效率和精度之间取得平衡，这需要动态调整跟踪速度。然而，现有技术通常将跟踪速度调整与手部动作直接耦合，从而降低了交互的灵活性。

**Method:** 受物理世界中固有的自然摩擦控制的启发，本文引入了ForcePinch，一种新型的力响应空间交互方法。为了实现这一概念，开发了一个硬件原型，该原型集成了压力传感器和可定制的映射函数，将捏合力转换为跟踪速度调整。研究人员对20名参与者进行了用户研究，执行了1D、2D和3D物体操作任务，并将ForcePinch与距离响应技术Go-Go和速度响应技术PRISM进行了比较。

**Result:** 结果突出了力响应方法在不同交互环境中的独特特征。

**Conclusion:** 基于这些发现，本文通过四个说明性示例强调了力响应交互的上下文意义和多功能性，旨在为未来的空间交互设计提供信息和启发。

> **ai_Abstract:** 本文提出了一种名为ForcePinch的新型力响应空间交互方法，旨在解决XR环境中跟踪速度调整与手部动作耦合导致交互灵活性降低的问题。ForcePinch允许用户通过改变捏合力来直观地调节指针跟踪速度，从而在快速和精确移动之间平稳过渡。研究团队开发了一个集成压力传感器的硬件原型，并通过用户研究将其与现有技术进行比较，结果显示力响应方法在不同交互场景下具有独特的优势，为未来的空间交互设计提供了新的思路。

> **摘要翻译:** 在3D环境中进行空间交互需要在效率和精度之间取得平衡，这需要动态调整跟踪速度。然而，现有技术通常将跟踪速度调整与手部动作直接耦合，从而降低了交互的灵活性。受物理世界中固有的自然摩擦控制的启发，我们引入了ForcePinch，一种新型的力响应空间交互方法，它使用户能够通过改变捏合力来直观地调节指针跟踪速度，并在快速和精确移动之间平稳过渡。为了实现这一概念，我们开发了一个硬件原型，该原型集成了压力传感器和可定制的映射函数，将捏合力转换为跟踪速度调整。我们对20名参与者进行了用户研究，执行了成熟的1D、2D和3D物体操作任务，并将ForcePinch与距离响应技术Go-Go和速度响应技术PRISM进行了比较。结果突出了力响应方法在不同交互环境中的独特特征。基于这些发现，我们通过四个说明性示例强调了力响应交互的上下文意义和多功能性，旨在为未来的空间交互设计提供信息和启发。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [731] [Between Filters and Feeds: Investigating Douyin and WeChat's Influence on Chinese Adolescent Body Image](https://arxiv.org/abs/2507.17755)
> *滤镜与信息流之间：探究抖音和微信对中国青少年身体意象的影响*

*Jianfeng Lan, Yingjia Huang* | **Category: cs.HC, cs.CY, cs.SI** | **Updated: 2025-05-02**

**Keywords:** 抖音, 微信, 身体意象, 青少年, 平台化

**Comment:** 

> **TL;DR:** 本研究调查了抖音和微信对中国男性青少年身体意象的影响，发现抖音使用与身体意象显著相关，而微信则无显著相关性，表明平台特性在社交媒体对身体意象的影响中至关重要。

**AI_Comments:** 本研究的创新之处在于其平台化视角，区分了不同社交媒体平台（抖音与微信）对身体意象影响的差异，而非将其视为同质的“社交媒体”。它强调了技术设计（如算法推荐、视频内容）如何具体影响心理结果，为深入理解数字环境下的身体意象问题提供了宝贵见解。研究结果对于制定干预措施以应对中国男性青少年身体意象问题具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在数字时代，社交媒体平台在塑造青少年身体意象方面发挥着关键作用。本研究旨在探讨抖音和微信这两种截然不同的中国社交媒体平台如何影响中国男性青少年的身体意象，并强调考虑平台特定特征在理解社交媒体对身体意象影响的重要性。

**Method:** 本研究采用平台化视角，对395名年龄在10至24岁的男性青少年进行了问卷调查，使用多维度身体自我关系问卷-外貌量表（MBSRQ-AS）来评估自我评价和身体满意度。

**Result:** 研究发现，抖音使用与外貌评价和身体部位满意度显著相关，而微信使用与任何身体意象维度均无显著相关性。这些结果表明，抖音算法驱动、以视频为中心的环境加剧了对理想化身体标准的接触，从而在认知层面影响用户。

**Conclusion:** 本研究强调了在理解社交媒体对身体意象的影响时，考虑平台特定特征的重要性。它为关于技术设计和内容模式如何调节心理结果的更广泛讨论做出了贡献，并为解决中国男性青少年身体意象问题提供了见解。

> **ai_Abstract:** 本研究调查了中国抖音和微信平台对男性青少年身体意象的影响。通过对395名10-24岁男性青少年的调查，发现抖音的使用与外貌评价和身体部位满意度显著相关，而微信则无此关联。研究指出，抖音的视频中心和算法驱动环境可能通过增加理想化身体标准的暴露来影响用户认知。这强调了在理解社交媒体对身体意象影响时，需重视平台特性和技术设计的作用。

> **摘要翻译:** 在数字时代，社交媒体平台在塑造青少年身体意象方面发挥着关键作用。本研究探讨了抖音和微信这两种截然不同的中国社交媒体平台如何影响中国男性青少年的身体意象。我们采用平台化视角，对395名年龄在10至24岁的男性青少年进行了问卷调查，使用多维度身体自我关系问卷-外貌量表（MBSRQ-AS）来评估自我评价和身体满意度。我们的研究结果显示，抖音使用与外貌评价和身体部位满意度显著相关，而微信使用与任何身体意象维度均无显著相关性。这些结果表明，抖音算法驱动、以视频为中心的环境加剧了对理想化身体标准的接触，从而在认知层面影响用户。本研究强调了在理解社交媒体对身体意象的影响时，考虑平台特定特征的重要性。它为关于技术设计和内容模式如何调节心理结果的更广泛讨论做出了贡献，并为解决中国男性青少年身体意象问题提供了见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [746] [Effects of variation in system responsiveness on user performance in virtual environments](https://arxiv.org/abs/2507.18085)
> *系统响应性变化对虚拟环境中用户表现的影响*

*Benjamin Watson, Neff Walker, William Ribarsky, Victoria Spaulding* | **Category: cs.HC, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 系统响应性, 虚拟环境, 用户表现, 响应时间, 人机交互

**Comment:** 

> **TL;DR:** 本研究探讨了虚拟环境中系统响应性（包括均值和标准差）对用户抓取和放置任务表现的影响，发现响应性标准差超过82毫秒才会影响表现，且放置任务对响应性更敏感。

**AI_Comments:** 这项研究为虚拟环境设计提供了实用的指导，特别是在优化系统响应性方面。其创新之处在于区分了系统响应性均值和标准差对用户表现的影响，并提出了具体的阈值（82毫秒），这对于提升用户体验和系统效率具有重要意义。研究结果可以直接应用于科学可视化、训练、心理健康和娱乐等多个领域的人机界面改进。

<details>
  <summary>Details</summary>

**Motivation:** 系统响应性（SR）在虚拟环境中会随时间波动，需要用均值（MSR）和标准差（SDSR）进行统计描述。本研究旨在探究SR的变化如何影响用户在虚拟环境中的表现，以期改善人机交互界面。

**Method:** 研究首先概述了虚拟环境中系统响应性的组成部分以及实验测量和操作方法。随后进行了三项针对MSR和SDSR对抓取和放置任务表现影响的研究，分别使用了11、12和10名参与者的被试内设计。

**Result:** 研究结果表明，系统响应性标准差（SDSR）仅在高于82毫秒时才会影响用户表现。放置任务需要更频繁的视觉反馈，并且对系统响应性（SR）更为敏感。

**Conclusion:** 虚拟环境（VE）设计师无需严格控制系统响应性标准差（SDSR），并且可以根据所需视觉反馈的频率来调整系统响应性（SR）的控制策略。这些结果可用于改进各种交互式图形应用中的人机界面。

> **ai_Abstract:** 本研究考察了虚拟环境中系统响应性（SR）的均值和标准差对用户执行抓取和放置任务表现的影响。通过三项被试内研究发现，SR的标准差仅在超过82毫秒时才会影响用户表现，而放置任务对SR更为敏感且需要更频繁的视觉反馈。研究建议虚拟环境设计师可根据视觉反馈频率调整SR控制，无需过度关注SR标准差的严格控制，这有助于改善广泛交互式图形应用的人机界面。

> **摘要翻译:** 系统响应性（SR）被定义为系统响应用户控制所经过的时间。SR会随时间波动，因此必须用均值（MSR）和标准差（SDSR）进行统计描述。本文在虚拟环境（VEs）中考察了SR，概述了其组成部分以及实验测量和操作方法。随后介绍了三项关于MSR和SDSR对抓取和放置任务表现影响的研究。这些研究分别使用了11、12和10名参与者的被试内设计。结果表明，SDSR仅在高于82毫秒时才会影响表现。放置任务需要更频繁的视觉反馈，并且对SR更为敏感。我们推断，VE设计师无需严格控制SDSR，并且可能希望根据所需的视觉反馈频率来改变SR控制。这些结果可用于改进各种交互式图形应用中的人机界面，包括科学可视化、训练、心理健康和娱乐。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [53] [Quantum Machine Learning in Precision Medicine and Drug Discovery -- A Game Changer for Tailored Treatments?](https://arxiv.org/abs/2502.18639)
> *量子机器学习在精准医疗和药物发现中的应用——量身定制疗法的颠覆者？*

*Markus Bertl, Alan Mott, Salvatore Sinno, Bhavika Bhalgamiya* | **Category: cs.ET, cs.AI, quant-ph** | **Updated: 2025-07-24**

**Keywords:** 量子机器学习, 精准医疗, 药物发现, 形式化方法, 量子计算

**Comment:** presented at AISoLA 2024

> **TL;DR:** 量子机器学习(QML)和量子计算(QC)有望革新精准医疗，但面临算法错误和高成本等挑战。本文提出利用形式化方法来提高QC的可靠性和效率，从而使其潜力得以充分发挥。

**AI_Comments:** 这篇论文强调了采用量子机器学习/量子计算等前沿技术的一个关键方面：确保其可靠性和正确性。提出使用形式化方法（传统上应用于关键软件系统）来验证量子算法是一种创新方法。这解决了实际的局限性，并可能加速量子技术在医疗保健等敏感领域的可靠集成。其对实际挑战和解决方案的关注非常有价值。

<details>
  <summary>Details</summary>

**Motivation:** 医疗保健的数字化面临生物系统复杂性、海量数据生成和个性化治疗需求等挑战。传统计算方法力有不逮，导致诊断和治疗延迟且有时无效。量子计算（QC）和量子机器学习（QML）提供了变革性的进展，有望彻底改变医学。然而，将量子技术整合到精准医疗中也存在挑战，包括算法错误和高成本。

**Method:** 本文提出利用基于数学的形式化方法来增强量子计算（QC）的可靠性和正确性。这些方法包括形式化规约语言，用于精确定义量子算法的行为和属性；模型检测工具，用于系统地探索算法的所有可能状态以确保其在所有条件下都能正确运行；定理证明技术，用于提供数学证明以确保算法满足其指定属性；以及形式化优化技术，用于通过减少资源使用（如量子比特数和门操作）来提高量子算法的效率和性能。

**Result:** 通过应用形式化方法，可以显著提高量子算法的可靠性、正确性和效率，从而使量子计算在精准医疗领域充分发挥其潜力。

**Conclusion:** 形式化方法可以极大地促进量子计算发挥其在精准医疗领域的全部潜力，成为该领域的颠覆者。

> **ai_Abstract:** 本文探讨了量子计算（QC）和量子机器学习（QML）在解决精准医疗和药物发现挑战（如复杂生物系统和海量数据）方面的变革潜力。尽管认识到量子技术在算法错误和高成本方面的问题，论文提出形式化方法——一种用于软件规约、开发和验证的数学技术——可以显著提高量子算法的可靠性、正确性和效率。通过应用形式化规约语言、模型检测、定理证明和形式化优化等技术，特别是在基因组数据分析中，形式化方法能够帮助量子计算充分发挥其在量身定制治疗方面的颠覆性作用。

> **摘要翻译:** 医疗保健的数字化带来了诸多挑战，包括生物系统的复杂性、海量数据生成以及对个性化治疗方案的需求。传统的计算方法往往力不从心，导致诊断和治疗的延迟，有时甚至无效。量子计算（QC）和量子机器学习（QML）提供了变革性的进展，有望彻底改变医学。本文总结了量子计算有望提供前所未有的计算能力，从而实现更快、更准确的诊断、个性化治疗以及增强药物发现过程的领域。然而，将量子技术整合到精准医疗中也带来了挑战，包括算法错误和高成本。我们表明，用于指定、开发和验证软件的基于数学的技术（形式化方法）可以提高量子计算的可靠性和正确性。通过提供严谨的数学框架，形式化方法有助于高精度地指定、开发和验证系统。在基因组数据分析中，形式化规约语言可以精确地（1）定义旨在识别与疾病相关的遗传标记的量子算法的行为和属性。模型检测工具可以系统地探索算法的所有可能状态，以（2）确保其在所有条件下都能正确运行，而定理证明技术则提供数学（3）证明，证明算法满足其指定的属性，从而确保准确性和可靠性。此外，形式化优化技术可以通过减少资源使用，例如量子比特数和门操作，来（4）提高量子算法的效率和性能。因此，我们认为形式化方法可以极大地促进量子计算发挥其作为精准医疗领域颠覆者的全部潜力。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [660] [Low-power switching of memristors exhibiting fractional-order dynamics](https://arxiv.org/abs/2507.18487)
> *分数阶动力学忆阻器的低功耗开关*

*Nathan Astin, Yuriy V. Pershin* | **Category: cs.ET, cond-mat.mes-hall** | **Updated: 2025-07-24**

**Keywords:** 忆阻器, 分数阶动力学, 低功耗开关, 神经形态计算, 焦耳损耗

**Comment:** 

> **TL;DR:** 该研究通过电流脉冲实现了具有分数阶行为的忆阻器低功耗开关，并发现最佳开关策略取决于分数阶导数阶数和功率指数。

**AI_Comments:** 这篇论文的创新点在于将分数阶动力学引入忆阻器开关策略的研究，并找到了基于分数阶导数阶数和功率指数的优化方法。其重要性在于为开发下一代节能、更接近生物的神经形态计算架构提供了理论基础和实验方向，有望推动低功耗计算设备的发展。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在为下一代节能神经形态计算架构的发展奠定基础，使其更接近生物对应物。

**Method:** 研究人员提出了一个模型，其中状态变量的演化遵循涉及Caputo型导数的分数阶微分方程。通过研究焦耳损耗来确定最佳开关策略。

**Result:** 当分数阶导数的阶数超过功率指数的一半时，最佳方法是采用宽脉冲。反之，当不满足此条件时，通过施加零电流，然后施加最高允许幅度的窄电流脉冲来最小化焦耳损耗。这些发现还在多脉冲控制的背景下进行了进一步探讨。

**Conclusion:** 该研究确定了基于分数阶导数阶数和功率指数的忆阻器低功耗开关的最佳策略，为开发节能神经形态计算架构提供了基础。

> **ai_Abstract:** 这篇会议论文介绍了使用电流脉冲切换具有分数阶动力学行为的忆阻器的初步结果。研究模型假设状态变量遵循Caputo型分数阶微分方程。通过分析焦耳损耗，论文发现最小化损耗的最佳开关策略取决于分数阶导数的阶数和功率指数。具体而言，当分数阶导数阶数超过功率指数一半时，宽脉冲是最佳选择；否则，先施加零电流再施加最高幅度窄脉冲能最小化损耗。这些发现对未来节能神经形态计算架构的发展具有重要意义。

> **摘要翻译:** 在本会议贡献中，我们介绍了一些关于使用电流脉冲切换具有分数阶行为的忆阻器设备的初步结果。在我们的模型中，假设状态变量的演化遵循涉及Caputo型导数的分数阶微分方程。焦耳损耗研究表明，最小化这些损耗的最佳开关策略取决于分数阶导数的阶数和运动方程中的功率指数。研究发现，当分数阶导数的阶数超过功率指数的一半时，最佳方法是采用宽脉冲。相反，当不满足此条件时，通过施加零电流，然后施加最高允许幅度的窄电流脉冲来最小化焦耳损耗。这些发现将在多脉冲控制的背景下进一步探讨。我们的研究为下一代更接近生物对应物的节能神经形态计算架构的进步奠定了基础。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [32] [Exploring and Evaluating Interplays of BPpy with Deep Reinforcement Learning and Formal Methods](https://arxiv.org/abs/2501.15480)
> *探索和评估BPpy与深度强化学习和形式化方法的相互作用*

*Tom Yaacov, Gera Weiss, Adiel Ashrov, Guy Katz, Jules Zisser* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 行为编程, 深度强化学习, 形式化方法, BPpy, 系统建模

**Comment:** Accepted to the 20th International Conference on Evaluation of Novel
  Approaches to Software Engineering (ENASE 2025)

> **TL;DR:** 该研究探索并评估了行为编程 (BP) 框架 BPpy 与人工智能 (AI) 和形式化方法 (FM) 工具（如深度强化学习和模型检测）的集成，旨在展示 BP 作为统一开发框架的潜力，以建模复杂系统。

**AI_Comments:** 这篇论文的创新点在于提出了将行为编程 (BP) 作为一种统一的抽象层，来整合多种人工智能 (AI) 和形式化方法 (FM)。这种集成有望显著提升复杂系统建模和分析的能力，为开发人员提供更强大的工具集。其重要性体现在为跨领域技术的融合提供了一个具体的框架，可能促进更健壮、更可扩展的软件开发。

<details>
  <summary>Details</summary>

**Motivation:** 旨在证明行为编程 (BP) 可以作为一种抽象层，整合各种人工智能 (AI) 和形式化方法 (FM) 技术，从而实现多方面的分析和丰富的开发过程。

**Method:** 论文通过评估将 BPpy 框架（BP 的 Python 实现）与可满足性模理论 (SMT) 求解器、符号和概率模型检测以及深度强化学习 (DRL) 等工具集成，来研究 BPpy 如何增强这些工具并被其增强。研究提供了定量和定性证据。

**Result:** 整合 BP 与 SMT 求解器、符号和概率模型检测以及 DRL 等工具可以扩展 BP 建模复杂系统的能力。开发人员可以在单一建模和开发任务中利用多种工具。研究提供了支持其愿景可行性的定量和定性证据。

**Conclusion:** 论文证明了 BPpy 能够作为统一的开发框架，整合人工智能和形式化方法，从而创建用于建模复杂系统的全面工具箱。

> **ai_Abstract:** 本文探讨了行为编程 (BP) 框架 BPpy 如何与人工智能 (AI) 和形式化方法 (FM) 工具（如深度强化学习和模型检测）相互作用并集成。研究旨在证明 BP 可以作为一种抽象层，统一多种技术，以增强复杂系统的建模能力。通过定量和定性证据，论文展示了 BPpy 作为一个综合工具箱的可行性，能够在一个统一的开发框架中有效利用 AI 和 FM 方法。

> **摘要翻译:** 我们探索并评估了行为编程 (BP) 与一系列人工智能 (AI) 和形式化方法 (FM) 技术之间的相互作用。我们的目标是证明 BP 可以作为一种抽象层，整合各种技术，从而实现多方面的分析和丰富的开发过程。具体而言，本文研究了 BPpy 框架（一个基于 Python 的 BP 实现）如何被各种 FM 和 AI 工具增强并增强这些工具。我们评估了将 BP 与可满足性模理论 (SMT) 求解器、符号和概率模型检测以及深度强化学习 (DRL) 等工具集成，如何使我们能够扩展 BP 建模复杂系统的能力。此外，我们还阐述了开发人员如何在单一建模和开发任务中利用多种工具。本文提供了定量和定性证据，支持我们创建综合工具箱的愿景，以在统一的开发框架中利用 AI 和 FM 方法的可行性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [63] [How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations](https://arxiv.org/abs/2507.17930)
> *软件工程师如何与AI协作：一个基于行业观察的实用流程模型和决策框架*

*Vahid Garousi, Zafar Jafarov* | **Category: cs.SE** | **Updated: 2025-07-23**

**Keywords:** AI辅助软件工程, 流程模型, 决策框架, 人机协作, 软件工程师

**Comment:** 

> **TL;DR:** 本研究提出了一个实用的流程模型和一个二维决策框架，以帮助软件工程师更有效地使用AI工具，解决他们在日常任务中如何与AI工具协作、信任、优化或拒绝AI生成输出的问题。

**AI_Comments:** 本文通过提出实用的流程模型和决策框架，填补了软件工程师在实际工作中如何与AI工具协作这一未充分探索的领域。其创新性在于将理论模型与行业观察相结合，为软件工程师提供了具体可操作的指导，有助于提升AI在软件工程中的应用效率和人机协作的质量。该研究的重要性在于其对实际开发场景的关注，为未来人机协作的研究提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI工具如GitHub Copilot和ChatGPT在软件工程中日益普及，但软件工程师在日常任务中如何与这些工具互动，特别是在决定信任、改进或拒绝AI生成输出方面的实践，仍未得到充分探索。

**Method:** 研究基于土耳其和阿塞拜风三个行业环境中从业者的报告和直接观察。

**Result:** 本研究提出了两个互补的贡献：首先，一个实用的流程模型，捕捉了现实世界中AI辅助的软件工程活动，包括提示设计、检查、回退和优化；其次，一个二维决策框架，可以帮助开发者权衡省力与输出质量之间的关系。

**Conclusion:** 这些模型为软件工程中AI工具的更审慎和有效使用提供了结构化、轻量级的指导，有助于推动人机协作的实际讨论。

> **ai_Abstract:** 本研究旨在解决软件工程师在日常任务中如何有效使用AI工具的问题。论文提出了一个实用的AI辅助软件工程流程模型，涵盖提示设计、检查、回退和优化等活动，以及一个二维决策框架，帮助开发者权衡节省的努力与输出质量。这些模型基于行业观察，为软件工程师提供结构化指导，以促进人机协作并提升AI工具在软件工程中的应用效率。

> **摘要翻译:** 人工智能（AI）有潜力通过提高生产力、效率和决策支持来改变软件工程（SE）。GitHub Copilot和ChatGPT等工具催生了“氛围编程”——一种探索性的、提示驱动的开发风格。然而，软件工程师在日常任务中如何与这些工具互动，特别是在决定信任、改进或拒绝AI生成输出方面，仍未得到充分探索。本文提出了两个互补的贡献。首先，一个实用的过程模型，捕捉了现实世界中AI辅助的SE活动，包括提示设计、检查、回退和优化。其次，一个二维决策框架，可以帮助开发者权衡省力与输出质量之间的关系。基于土耳其和阿塞拜疆三个行业环境中的从业者报告和直接观察，我们的工作阐明了工程师如何在人工监督下使用AI。这些模型为SE中AI工具的更审慎和有效使用提供了结构化、轻量级的指导，有助于推动人机协作的实际讨论。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [74] [On the Structure and Semantics of Identifier Names Containing Closed Syntactic Category Words](https://arxiv.org/abs/2505.18444)
> *关于包含封闭句法类别词的标识符名称的结构和语义*

*Christian D. Newman, Anthony Peruma, Eman Abdullah AlOmar, Mahie Crabbe, Syreen Banabilah, Reem S. AlSuhaibani, Michael J. Decker, Farhad Akhbardeh, Marcos Zampieri, Mohamed Wiem Mkaouer, Jonathan I. Maletic* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 标识符名称, 封闭句法类别, 语法模式, 程序理解, 软件工程

**Comment:** Accepted by Empirical Software Engineering (EMSE)

> **TL;DR:** 本研究通过扩展语法模式概念并构建新的数据集，调查了标识符名称中封闭句法类别词的语言结构，揭示了开发者如何通过命名表达程序行为。

**AI_Comments:** 该论文的创新点在于首次将自然语言处理中对封闭句法类别词的研究引入软件工程领域，并构建了专门的数据集（CCID）来分析其在标识符命名中的作用。这为理解代码的语言学基础提供了新的视角，对于程序理解、命名规范化和开发者教育都具有重要意义。其贡献在于填补了该研究空白，提供了实证数据支持。

<details>
  <summary>Details</summary>

**Motivation:** 标识符名称是代码的关键组成部分，为开发者理解程序行为提供了主要线索。本研究特别关注封闭句法类别词（如介词、连词、限定词），尽管它们在自然语言中扮演核心角色，但在软件工程中却鲜有研究。

**Method:** 通过扩展语法模式概念（代表标识符短语底层的词性序列）来调查标识符名称的语言结构。构建了一个新的手动标注数据集——封闭类别标识符数据集（CCID），包含从30个开源系统中提取的1,275个标识符。然后，使用扎根理论启发的编码、统计和模式分析方法，分析了封闭类别语法模式与程序行为之间的关系。

**Result:** 结果揭示了开发者通过命名表达控制流、数据转换、时间推理及其他行为角色的重复结构。

**Conclusion:** 这项工作为理解语言资源如何在标识符名称中编码行为提供了经验基础，并为命名、程序理解和教育领域的新研究方向提供了支持。

> **ai_Abstract:** 本研究深入探讨了代码中标识符名称的语言结构，特别是其中包含的封闭句法类别词。通过扩展语法模式概念并构建一个包含1,275个标识符的新数据集（CCID），作者分析了封闭类别语法模式与程序行为之间的关系。研究发现，开发者利用特定的命名结构来表达控制流、数据转换和时间推理等程序行为。这项工作为理解标识符命名中的语言编码提供了实证基础，并为相关研究领域开辟了新方向。

> **摘要翻译:** 标识符名称是代码的关键组成部分，为开发者理解程序行为提供了主要线索。本文通过扩展语法模式概念（代表标识符短语底层的词性序列），研究了标识符名称的语言结构。具体关注封闭句法类别词（如介词、连词、限定词），尽管它们在一般自然语言中扮演核心角色，但在软件工程中却鲜有研究。为了研究这些类别，本文构建并提出了一个名为封闭类别标识符数据集（CCID）的新手动标注数据集，其中包含从30个开源系统中提取的1,275个标识符。随后，使用扎根理论启发的编码、统计和模式分析方法，分析了封闭类别语法模式与程序行为之间的关系。结果揭示了开发者通过命名表达控制流、数据转换、时间推理及其他行为角色的重复结构。这项工作为理解语言资源如何在标识符名称中编码行为提供了经验基础，并为命名、程序理解和教育领域的新研究方向提供了支持。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [98] [Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work](https://arxiv.org/abs/2507.17991)
> *按指示使用？旨在检查已发表工作严谨性和透明度的软件工具比较*

*Peter Eckmann, Adrian Barnett, Alexandra Bannach-Brown, Elisa Pilar Bascunan Atria, Guillaume Cabanac, Louise Delwen Owen Franzen, Małgorzata Anna Gazda, Kaitlyn Hair, James Howison, Halil Kilicoglu, Cyril Labbe, Sarah McCann, Vladislav Nachev, Martijn Roelandse, Maia Salholz-Hillel, Robert Schulz, Gerben ter Riet, Colby Vorland, Anita Bandrowski, Tracey Weissgerber* | **Category: cs.SE, cs.IR** | **Updated: 2025-07-23**

**Keywords:** 可重复性危机, 自动化工具, 严谨性, 透明度, 科学报告

**Comment:** 

> **TL;DR:** 本文比较了11种自动化工具，用于检查科学研究的严谨性和透明度，发现不同工具在不同标准上表现各异，并为工具开发提供了建议。

**AI_Comments:** 本文通过评估实用的自动化解决方案，直接回应了可重复性危机，具有重要意义。对多种工具在不同严谨性标准上的比较，提供了对其当前能力和局限性的宝贵见解。其侧重于识别改进领域，为未来的工具开发提供了可行的建议，这对于提高科学报告的严谨性和透明度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 科学报告中缺乏标准化和透明度导致了可重复性危机。尽管ARRIVE和CONSORT等清单旨在提高透明度，但作者并不总是遵循，同行评审也常未能发现遗漏项。为解决这些问题，一些自动化工具被设计用于检查不同的严谨性标准。

**Method:** 研究对来自ScreenIT组的11种自动化工具，在9个不同的严谨性标准上进行了广泛比较。

**Result:** 研究发现，在某些标准（如开放数据检测）上，工具组合中存在一个表现远优于其他工具的“赢家”。而在其他情况（如纳入和排除标准检测）下，工具组合的表现优于任何单一工具。研究还指出了工具开发者应着力改进的关键领域，以最大化工具的效用。

**Conclusion:** 研究为严谨性和透明度检测工具的开发者提供了见解和建议。

> **ai_Abstract:** 本文旨在解决可重复性危机，比较了11种旨在检查已发表科学工作严谨性和透明度的自动化软件工具，评估了9个不同的标准。研究发现，虽然某些工具在特定领域（如开放数据检测）表现突出，但在其他标准（如纳入和排除标准检测）上，工具组合通常能取得最佳性能。研究指出了工具需要改进的领域，并为这类工具的开发者提供了建议。

> **摘要翻译:** 可重复性危机的原因包括科学报告中缺乏标准化和透明度。ARRIVE和CONSORT等清单旨在提高透明度，但作者并不总是遵循，同行评审也常未能发现遗漏项。为解决这些问题，已有一些自动化工具被设计用于检查不同的严谨性标准。我们对来自ScreenIT组的11种自动化工具，在9个不同的严谨性标准上进行了广泛比较。我们发现，在某些标准（包括开放数据检测）上，工具组合中出现了一个明确的“赢家”，该工具的表现远优于其他工具。在其他情况下（包括纳入和排除标准检测），工具组合的表现超过了任何单一工具。我们还指出了工具开发者应着力改进的关键领域，以最大化其工具的效用。最后，我们为严谨性和透明度检测工具的开发者提供了一系列见解和建议。本研究的代码和数据可在https://github.com/PeterEckmann1/tool-comparison获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [114] [OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advancing Next-Generation Intelligent Transportation Systems Research](https://arxiv.org/abs/2507.09186)
> *OpenCAMS：一个用于推进下一代智能交通系统研究的开源网联和自动化出行协同仿真平台*

*Minhaj Uddin Ahmad, Akid Abrar, Sagar Dasgupta, Mizanur Rahman* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 协同仿真, 智能交通系统, SUMO, CARLA, OMNeT++, 开源

**Comment:** 

> **TL;DR:** OpenCAMS是一个开源的协同仿真平台，它紧密结合了SUMO、CARLA和OMNeT++，旨在支持交通安全、出行和网络安全方面的先进研究。

**AI_Comments:** OpenCAMS的创新之处在于其将SUMO、CARLA和OMNeT++这三个在各自领域表现卓越的仿真工具进行紧密且时间同步的协同，从而能够在一个统一的框架内处理交通流、车辆动力学、传感器感知和V2X通信等复杂ITS研究场景。其开源性质和可扩展性显著降低了研究门槛，促进了社区协作和下一代ITS技术的快速发展，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过结合SUMO、CARLA和OMNeT++的优势，支持交通安全、出行和网络安全领域的先进研究，以推进下一代智能交通系统。

**Method:** OpenCAMS是一个开源、同步、可扩展的协同仿真框架，它紧密耦合了SUMO（用于大规模微观交通建模）、CARLA（用于高保真3D感知、车辆动力学和控制仿真）和OMNeT++（用于模块化、事件驱动的网络通信，如C-V2X）。它采用时间同步、双向耦合架构，确保交通、感知和通信领域的一致仿真进展，同时保持模块化和可复现性。

**Result:** 该论文介绍了OpenCAMS平台，这是一个完全开源且公开可用的协同仿真平台，为研究社区提供了一个可访问、灵活且协作的环境，以推进下一代智能交通系统研究。

**Conclusion:** OpenCAMS平台是一个完全开源且公开可用的协同仿真平台，它为研究社区提供了一个可访问、灵活且协作的环境，以推进下一代智能交通系统研究。

> **ai_Abstract:** OpenCAMS是一个开源的协同仿真平台，它将SUMO、CARLA和OMNeT++三个领先的仿真工具紧密结合。该平台通过时间同步的双向耦合架构，实现了交通、感知和通信领域的一致性仿真，旨在支持智能交通系统（ITS）中交通安全、出行和网络安全等方面的先进研究。OpenCAMS具有模块化、可扩展和可复现的特点，并已完全开源，为ITS研究社区提供了一个灵活的协作环境。

> **摘要翻译:** 我们介绍了OpenCAMS（开源网联和自动化出行协同仿真平台），这是一个开源、同步、可扩展的协同仿真框架，它紧密耦合了三个同类最佳的仿真工具：(i) SUMO，(ii) CARLA，和(iii) OMNeT++。OpenCAMS旨在通过结合每个仿真领域的优势来支持交通安全、出行和网络安全方面的先进研究。具体来说，SUMO提供大规模、微观的交通建模；CARLA提供高保真3D感知、车辆动力学和控制仿真；而OMNeT++支持模块化、事件驱动的网络通信，例如蜂窝车联网（C-V2X）。OpenCAMS采用时间同步、双向耦合架构，确保交通、感知和通信领域的一致仿真进展，同时保持模块化和可复现性。例如，CARLA可以仿真和渲染需要详细传感器仿真和控制逻辑的车辆子集；SUMO协调全网络交通流、车辆路径规划和交通信号管理；而OMNeT++动态地将通信节点映射到移动实体（例如车辆）和静态实体（例如路边单元），以实现C-V2X通信。虽然这三个仿真器构成了OpenCAMS的基础核心，但该平台被设计为可扩展和面向未来，允许在不改变系统架构基本前提下集成额外的仿真器。OpenCAMS平台是完全开源的，并通过其GitHub仓库https://github.com/minhaj6/carla-sumo-omnetpp-cosim公开可用，为研究社区提供了一个可访问、灵活且协作的环境，以推进下一代智能交通系统。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [133] [An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges](https://arxiv.org/abs/2507.18029)
> *开源游戏开发中生成式AI采纳的实证研究：工具、任务与开发者挑战*

*Xiang Echo Chen, Wenhan Zhu, Guoshuai Albert Shi, Michael W. Godfrey* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 生成式AI, 开源游戏开发, GitHub, 实证研究, 开发者挑战

**Comment:** 

> **TL;DR:** 本研究通过分析GitHub议题，探讨了生成式AI在开源游戏开发中的工具、任务和开发者挑战，并与传统AI及非AI话题进行了比较。

**AI_Comments:** 本研究的创新之处在于其专注于生成式AI在“开源”游戏开发这一特定且重要领域的实证采纳，这与以往研究侧重传统AI或更广泛的AI应用有所不同。通过分析GitHub议题，研究能够获得真实的开发者讨论和实践数据，这对于理解GenAI在实际开发环境中的影响至关重要。研究的重要性体现在它为理解新兴技术在特定社区中的落地提供了宝贵的经验数据，有助于未来工具设计和社区支持。局限性可能在于其数据源仅限于GitHub议题，可能无法全面反映所有GenAI的采纳情况，且分析结果的普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI（GenAI）正在重塑游戏设计与开发，但目前对于开发者在真实世界环境中，尤其是在开源社区中如何采纳GenAI的实证理解有限。本研究旨在填补这一空白，探索GenAI技术在开源游戏开发中的讨论、采纳和整合方式。

**Method:** 本研究通过分析GitHub上的议题讨论，构建了一个讨论AI相关话题的开源游戏仓库数据集。研究对分层抽样的GitHub议题应用开放式卡片分类和主题分析，并对每种类型和内容进行标记。这些注释使得能够对GenAI、传统AI（TradAI）和非AI（NonAI）组进行比较分析。

**Result:** 本研究旨在揭示GenAI在使用模式、开发者关注点和集成实践方面与传统方法有何不同，并深入了解GenAI如何塑造开源游戏开发者的工作流程和痛点。具体结果未在摘要中提及。

**Conclusion:** 本研究旨在通过比较分析GenAI、传统AI和非AI话题，提供对生成式AI在开源游戏开发中采纳情况的深入洞察。具体结论未在摘要中提及。

> **ai_Abstract:** 本研究旨在对生成式AI（GenAI）在开源游戏开发中的采纳情况进行实证考察。通过分析GitHub上的相关议题，研究探讨了GenAI在开源游戏开发中所涉及的工具、任务和开发者面临的挑战。研究方法包括构建数据集、应用开放式卡片分类和主题分析，并对GenAI、传统AI（TradAI）和非AI话题进行比较，以揭示GenAI在用法模式、开发者关注点和集成实践方面的独特性，并理解其对开发者工作流程和痛点的影响。

> **摘要翻译:** 生成式AI（GenAI）日益增长的能力已开始重塑游戏的设计和开发方式，为内容创作、游戏玩法模拟和设计构思提供了新工具。尽管先前的研究已经探索了AI在游戏中的传统用途，例如控制智能体或生成程序化内容，但对于开发者在真实世界环境中，特别是在开源社区中如何采纳GenAI的实证理解有限。本研究旨在通过分析GitHub上的议题讨论，探索GenAI技术如何在开源游戏开发中被讨论、采纳和整合。我们通过比较GenAI相关议题与涉及传统AI（TradAI）和非AI话题的议题，调查与GenAI相关的工具、任务和挑战。我们的目标是揭示GenAI在使用模式、开发者关注点和集成实践方面与传统方法有何不同。为了实现这一目标，我们构建了一个讨论AI相关话题的开源游戏仓库数据集。我们对分层抽样的GitHub议题应用开放式卡片分类和主题分析，并对每种类型和内容进行标记。这些注释使得能够对GenAI、TradAI和NonAI组进行比较分析，并深入了解GenAI如何塑造开源游戏开发者的工作流程和痛点。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [154] [LLMShot: Reducing snapshot testing maintenance via LLMs](https://arxiv.org/abs/2507.10062)
> *LLMShot：通过大型语言模型减少快照测试维护*

*Ergün Batuhan Kaynak, Mayasah Lami, Sahand Moslemi, Anil Koyuncu* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 快照测试, UI验证, 视觉语言模型, 自动化测试, 维护开销

**Comment:** Accepted to ICSME 2025

> **TL;DR:** LLMShot利用视觉语言模型（VLMs）自动分析快照测试失败，通过语义分类UI变化来减少手动维护工作。

**AI_Comments:** LLMShot的创新之处在于首次将视觉语言模型（VLMs）应用于快照测试的自动化语义分析，解决了长期困扰开发者的手动分类痛点。其重要性在于显著降低了UI测试的维护成本，提高了开发效率。尽管在可控视觉推理方面仍存在局限性，但它为智能UI测试开辟了新路径，具有重要的实践意义和研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 快照测试在UI验证中很重要，但由于频繁的UI变化导致测试失败，维护成本很高，需要手动检查以区分真正的回归和有意设计更改，这变得越来越繁重，因此需要自动化分析解决方案。

**Method:** 本文介绍了LLMShot，一个利用视觉语言模型（VLMs）通过UI变化的语义分类来自动分析快照测试失败的新颖框架。为了评估其有效性，我们开发了一个综合数据集，使用一个功能丰富的iOS应用程序，该应用程序具有可配置的功能标志，创建了产生真实快照差异的现实场景。

**Result:** 使用Gemma3模型的评估显示出强大的分类性能，其中12B变体在识别故障根本原因方面达到了超过84%的召回率，而4B模型在持续集成环境中提供了实际的部署优势和可接受的性能。然而，对选择性忽略机制的探索揭示了当前基于提示的方法在可控视觉推理方面的显著局限性。

**Conclusion:** LLMShot是第一个自动进行语义快照测试分析的方法，为开发人员提供了结构化洞察，可以大大减少手动分类工作，并推动更智能的UI测试范式。

> **ai_Abstract:** LLMShot是一个利用视觉语言模型（VLMs）自动分析快照测试失败的新框架，旨在解决传统快照测试因UI频繁变化导致高维护成本的问题。通过对UI变化进行语义分类，LLMShot能有效识别故障根源。实验结果表明，该方法在故障原因识别方面表现出色，尤其12B模型召回率超过84%，4B模型也适用于CI环境。该研究是语义快照测试分析的首个自动化尝试，有望显著减少开发者的手动分类工作并推动UI测试智能化。

> **摘要翻译:** 快照测试已成为现代软件开发中UI验证的关键技术，但由于频繁的UI变化导致测试失败，需要手动检查以区分真正的回归和有意设计更改，因此维护开销巨大。随着应用程序的发展，这种手动分类过程变得越来越繁重，从而产生了对自动化分析解决方案的需求。本文介绍了LLMShot，一个新颖的框架，它利用视觉语言模型（VLMs）通过UI变化的语义分类来自动分析快照测试失败。为了评估LLMShot的有效性，我们使用一个功能丰富的iOS应用程序开发了一个综合数据集，该应用程序具有可配置的功能标志，创建了产生真实快照差异的现实场景，这些场景代表了真实的开发工作流程。我们使用Gemma3模型的评估显示出强大的分类性能，其中12B变体在识别故障根本原因方面达到了超过84%的召回率，而4B模型在持续集成环境中提供了实际的部署优势和可接受的性能。然而，我们对选择性忽略机制的探索揭示了当前基于提示的方法在可控视觉推理方面的显著局限性。LLMShot代表了第一个自动进行语义快照测试分析的方法，为开发人员提供了结构化洞察，可以大大减少手动分类工作，并推动更智能的UI测试范式。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [158] [OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization](https://arxiv.org/abs/2507.09682)
> *OrQstrator: 一个用于高级量子电路优化的AI驱动框架*

*Laura Baird, Armin Moin* | **Category: cs.SE, cs.AI, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 量子电路优化, 深度强化学习, NISQ, 电路编排, 模块化框架

**Comment:** IEEE International Conference on Quantum Computing and Engineering
  (QCE) 2025 - Extended Abstract

> **TL;DR:** OrQstrator是一个基于深度强化学习的模块化框架，用于在NISQ时代优化量子电路，通过智能协调多种优化器来减少深度、门计数并提高保真度。

**AI_Comments:** OrQstrator的创新之处在于其模块化设计和由深度强化学习驱动的中央编排引擎，能够智能地协调多种互补的电路优化器。这种方法有望在NISQ时代显著提升量子电路的优化水平，特别是在减少深度、门计数和提高保真度方面。

<details>
  <summary>Details</summary>

**Motivation:** 在噪声中等规模量子（NISQ）时代进行量子电路优化是必要的，以应对硬件限制并提高电路性能。

**Method:** 该论文提出了OrQstrator，一个由深度强化学习（DRL）驱动的模块化框架。它包含一个DRL驱动的电路重写器、一个执行局部门重合成和数值优化的领域特定优化器，以及一个在门集转换期间优化模板电路的参数化电路实例化器。一个中央编排引擎根据电路结构、硬件约束和后端感知性能特征（如门计数、深度和预期保真度）学习协调策略，以选择和协调这些模块。该系统还利用现有技术（NISQ Analyzer）来适应后端约束。

**Result:** 该系统输出一个经过优化的电路，用于硬件感知的转译和执行。

**Conclusion:** OrQstrator是一个新颖的、由AI驱动的模块化框架，用于在NISQ时代进行高级量子电路优化，通过智能协调多种优化器来提高电路性能。

> **ai_Abstract:** OrQstrator是一个新颖的、由深度强化学习驱动的模块化框架，旨在解决噪声中等规模量子（NISQ）时代的量子电路优化问题。该框架通过一个智能编排引擎协调三种互补的电路优化器：一个基于DRL的电路重写器、一个领域特定优化器和一个参数化电路实例化器。编排引擎根据电路结构、硬件约束和性能特征学习协调策略，最终输出一个针对硬件转译和执行优化的电路，以提高性能。

> **摘要翻译:** 我们提出了一种新颖的方法，OrQstrator，它是一个用于在噪声中等规模量子（NISQ）时代进行量子电路优化的模块化框架。我们的框架由深度强化学习（DRL）驱动。我们的编排引擎在三个互补的电路优化器之间智能选择：一个基于DRL的电路重写器，经过训练通过学习的重写序列来减少深度和门计数；一个执行高效局部门重合成和数值优化的领域特定优化器；一个参数化电路实例化器，通过在门集转换期间优化模板电路来改进编译。这些模块由一个中央编排引擎协调，该引擎根据电路结构、硬件约束以及后端感知的性能特征（如门计数、深度和预期保真度）学习协调策略。该系统输出一个用于硬件感知转译和执行的优化电路，利用现有最先进方法（NISQ Analyzer）的技术来适应后端约束。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [168] [Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey](https://arxiv.org/abs/2507.18039)
> *计算教育中教师采纳项目式学习的影响因素：一项调查*

*Ahmad D. Suleiman, Yiming Tang, Daqing Hou* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 项目式学习, 教师采纳, 计算教育, 机构支持, 调查

**Comment:** Accepted at IEEE Frontiers in Education (FIE) 2025. This work has
  been submitted to the IEEE for possible publication

> **TL;DR:** 本研究调查了计算教育中教师采纳项目式学习（PjBL）的影响因素，包括障碍和促进因素，强调了系统性支持的重要性。

**AI_Comments:** 该研究深入探讨了计算教育领域项目式学习采纳的实际挑战，并提供了基于实证的解决方案。其混合方法学增强了研究的可靠性。研究结果特别强调了机构支持而非仅仅个人努力在推广PjBL中的关键作用，这对于教育政策制定者和管理者具有重要参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 项目式学习（PjBL）被认为是提升学生能力（如动机、参与度、批判性思维、协作和问题解决能力）的有效教学方法。然而，尽管PjBL有诸多益处，教师的采纳却不一致，面临机构支持不足、时间限制、培训机会有限、项目设计与来源困难以及与课程目标对齐等挑战。本研究旨在探讨这些障碍并寻找促进成功采纳的策略和资源。

**Method:** 本研究采用混合方法，通过在线问卷调查收集了80名计算领域教师的数据。问卷包含量化障碍、促进因素和资源需求的封闭式问题，以及收集定性见解的开放式问题。定量数据采用统计方法分析，定性回答则进行主题分析。

**Result:** 研究结果显示，尽管PjBL被广泛重视，但其采纳往往是选择性的，并受到学习过程规划和管理、设计合适项目以及缺乏机构支持（如时间、资金和助教）等挑战的影响。当教师能够获得同行协作、专业发展和机构激励时，他们更有可能采纳或维持PjBL。此外，从研究、行业合作和同行那里获取项目是新项目的重要促进因素。

**Conclusion:** 研究结果强调，需要建立系统性的支持结构，以赋能教师尝试和推广项目式学习实践。

> **ai_Abstract:** 本研究调查了计算教育中教师采纳项目式学习（PjBL）的影响因素。尽管PjBL对学生能力提升有益，但教师采纳面临机构支持不足、时间限制和项目设计困难等挑战。研究采用混合方法，对80名计算教师进行了问卷调查，发现采纳受规划管理、项目设计及机构支持缺乏的影响，而同行协作、专业发展和机构激励能促进采纳。研究强调需建立系统性支持结构以推广PjBL实践。

> **摘要翻译:** 本研究论文调查了影响计算教育者在软件工程和计算课程中采纳项目式学习（PjBL）的因素。PjBL被认为是一种以学生为中心的教学方法，有潜力增强学生的动机、参与度、批判性思维、协作和解决问题的能力。尽管有这些益处，由于机构支持不足、时间限制、培训机会有限、设计或寻找项目以及将项目与课程目标对齐等挑战，教师的采纳仍然不一致。本研究探讨了这些障碍，并调查了促进成功采纳的策略和资源。研究采用混合方法，通过在线问卷调查收集了80名计算领域教师的数据，问卷包括量化障碍、促进因素和资源需求的封闭式问题，以及收集定性见解的开放式问题。定量数据采用统计方法分析，定性回答则进行主题分析。结果显示，尽管PjBL被广泛重视，但其采纳往往是选择性的，并受到学习过程规划和管理、设计合适项目以及缺乏机构支持（如时间、资金和助教）等挑战的影响。当教师能够获得同行协作、专业发展和机构激励时，他们更有可能采纳或维持PjBL。此外，从研究、行业合作和同行那里获取项目是新项目的重要促进因素。这些发现强调了需要系统性支持结构来赋能教师尝试和推广PjBL实践。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [193] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
> *当检索器遇见生成器：一个用于代码注释生成的联合模型*

*Tien P. T. Le, Anh M. T. Bui, Huy N. D. Pham, Alessio Bucaioni, Phuong T. Nguyen* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 代码注释生成, 检索增强, CodeT5, 联合模型, RAGSum

**Comment:** The paper has been peer-reviewed and accepted for publication in the
  proceedings of the 19th ACM/IEEE International Symposium on Empirical
  Software Engineering and Measurement (ESEM 2025)

> **TL;DR:** RAGSum是一个结合检索和生成的新方法，用于自动生成代码注释，通过单一的CodeT5骨干网络实现，并在多个基准测试中表现优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了RAGSum模型，它有效地将检索和生成过程融合到一个单一的CodeT5骨干网络中，解决了传统检索增强方法中检索与生成独立优化带来的噪声传播问题。通过对比预训练和复合损失函数进行端到端训练，以及轻量级的自优化循环，显著提高了代码注释生成的质量和效率，为自动化代码文档提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 自动生成代码注释可以减轻文档工作量并加速程序理解。然而，现有的检索增强方法通常独立优化检索和生成，导致不相关的邻居传播噪声。

**Method:** 我们提出了一种名为RAGSum的新方法，旨在提高推荐的有效性和效率。RAGSum建立在CodeT5骨干网络之上，融合了检索和生成。它包括一个对比预训练阶段来塑造代码嵌入，以及一个带有复合损失的端到端训练阶段，该损失奖励准确的top-k检索并最小化注释生成错误。此外，还部署了一个轻量级的自优化循环来完善最终输出。

**Result:** 我们在三个跨语言基准测试（Java、Python、C）上评估了该框架，并与三个成熟的基线进行了比较。结果表明，我们的方法在BLEU、METEOR和ROUTE-L方面显著优于基线。

**Conclusion:** 这些发现表明，紧密耦合检索和生成可以提高注释自动化的上限，并促使未来的复制和定性开发者研究。

> **ai_Abstract:** 本文提出了一种名为RAGSum的新型代码注释生成方法，该方法通过单一的CodeT5骨干网络紧密结合了代码检索和注释生成。针对现有检索增强方法中检索与生成独立优化导致噪声传播的问题，RAGSum采用对比预训练来优化代码嵌入，并通过复合损失函数进行端到端训练，以同时提高检索准确性和生成质量，并辅以自优化循环。在Java、Python和C语言的跨语言基准测试中，RAGSum在BLEU、METEOR和ROUTE-L指标上均显著优于现有基线，证明了检索与生成紧密耦合的有效性。

> **摘要翻译:** 自动为源代码生成简洁、信息丰富的注释可以减轻文档工作并加速程序理解。检索增强方法首先获取带有现有注释的代码片段，然后合成新的注释，但检索和生成通常是独立优化的，这使得不相关的邻居将噪声向下传播。为了解决这个问题，我们提出了一种名为RAGSum的新方法，旨在提高推荐的有效性和效率。RAGSum建立在单一的CodeT5骨干网络之上，融合了检索和生成。我们报告了基于CodeT5构建的统一检索-生成框架的初步结果。一个对比预训练阶段塑造了用于最近邻搜索的代码嵌入；然后这些权重用于端到端训练，并采用复合损失函数，该函数（i）奖励准确的top-k检索；（ii）最小化注释生成错误。更重要的是，部署了一个轻量级的自优化循环来完善最终输出。我们在三个跨语言基准测试（Java、Python、C）上评估了该框架，并与三个成熟的基线进行了比较。结果表明，我们的方法在BLEU、METEOR和ROUTE-L方面显著优于基线。这些发现表明，紧密耦合检索和生成可以提高注释自动化的上限，并促使未来的复制和定性开发者研究。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [203] [An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows](https://arxiv.org/abs/2507.18062)
> *GitHub Actions工作流的复杂性、异构性和合规性实证研究*

*Edward Abrokwah, Taher A. Ghaleb* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** GitHub Actions, 持续集成, 工作流, 复杂性, 合规性, 实证研究

**Comment:** Registered Report Accepted at the 41st IEEE International Conference
  on Software Maintenance and Evolution 2025 (ICSME'25)

> **TL;DR:** 对GitHub Actions工作流的复杂性、异构性和最佳实践合规性进行了实证研究，发现了一些需要改进的领域。

**AI_Comments:** 这篇论文通过对实际开源项目中的GitHub Actions工作流进行大规模实证研究，填补了CI实践合规性理解的空白。其创新之处在于结合了复杂性、异构性和合规性多个维度进行分析，并预期提供对CI服务文档和指南的实际改进建议，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管GitHub Actions (GHA) 有官方文档和最佳实践，但对开源项目中实际CI工作流如何遵循这些实践缺乏实证理解，许多工作流可能过于复杂且不符合CI的简洁目标。

**Method:** 本研究使用来自Java、Python和C++仓库的大型GHA工作流数据集，旨在识别工作流复杂性，分析重复和异构的结构模式，评估与GHA最佳实践的合规性，并揭示不同编程语言之间CI管道设计的差异。

**Result:** 预期发现将揭示对最佳实践的强烈遵守领域以及需要改进的领域。

**Conclusion:** 这些见解将对CI服务产生影响，凸显了CI文档中需要更清晰的指南和全面的示例。

> **ai_Abstract:** 本研究对开源软件仓库中的GitHub Actions (GHA) 工作流进行了实证分析，旨在理解其结构、复杂性、异构性以及对最佳实践的合规性。通过分析来自Java、Python和C++项目的大型数据集，研究人员旨在识别复杂性、模式、合规性差距以及跨语言的设计差异，以期为CI服务提供改进指南和文档的见解。

> **摘要翻译:** 持续集成（CI）已从一种工具策略发展成为现代CI工程中的基本思维模式。它使团队能够快速协作地开发、测试和交付软件。在众多CI服务中，GitHub Actions（GHA）因其与GitHub的深度集成和庞大的可重用工作流生态系统而成为主导服务。尽管GHA提供了官方文档和社区支持的最佳实践，但对于开源项目中实际CI工作流如何遵循这些实践的实证理解似乎有限。许多工作流可能不必要地复杂，并且不符合CI实践的简洁目标。本研究将调查开源软件仓库中GHA工作流的结构、复杂性、异构性和合规性。我们使用来自Java、Python和C++仓库的大型GHA工作流数据集，目标是（a）识别工作流复杂性，（b）分析重复和异构的结构模式，（c）评估与GHA最佳实践的合规性，以及（d）揭示不同编程语言之间CI管道设计的差异。我们的发现预计将揭示对最佳实践的强烈遵守领域以及需要改进的领域。这些见解还将对CI服务产生影响，因为它们将突出CI文档中需要更清晰的指南和全面的示例。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [238] [Identifier Name Similarities: An Exploratory Study](https://arxiv.org/abs/2507.18081)
> *标识符名称相似性：一项探索性研究*

*Carol Wong, Mai Abe, Silvia De Benedictis, Marissa Halim, Anthony Peruma* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 标识符名称, 名称相似性, 程序理解, 分类法, 软件工程

**Comment:** The 19th ACM/IEEE International Symposium on Empirical Software
  Engineering and Measurement - Emerging Results and Vision Track

> **TL;DR:** 标识符名称的相似性会阻碍代码理解和协作。本研究探索了软件项目中标识符名称相似性的发生情况，并提出了一个分类法来对其进行分类，旨在为未来研究提供基础。

**AI_Comments:** 这篇论文探讨了软件开发中一个实用且经常被忽视的问题：相似标识符名称的微妙负面影响。所提出的分类法是一个有价值的贡献，它提供了一种结构化的方法来分析复杂问题。其探索性性质表明它是未来定量研究的基础步骤。

<details>
  <summary>Details</summary>

**Motivation:** 标识符名称是程序理解的关键。选择不当的名称会增加认知负荷并阻碍协作。即使单独看可读的名称，当与其他名称在结构或功能上相似时，也可能导致误解。

**Method:** 本研究对软件项目中标识符名称相似性的发生情况进行了探索性研究，并开发了一个分类法来对不同形式的标识符名称相似性进行分类。

**Result:** 本研究展示了关于标识符名称相似性发生情况的初步发现，并提出了一个初始分类法。

**Conclusion:** 本研究设想，所提出的初始分类法将为研究人员提供一个平台，用于分析和评估标识符名称相似性对代码理解、可维护性和开发人员之间协作的影响，并允许进一步的完善和扩展。

> **ai_Abstract:** 这项探索性研究调查了软件项目中标识符名称相似性现象，这种现象会阻碍程序理解和开发人员协作。作者提出了初步发现，并引入了一个分类法来对各种形式的标识符名称相似性进行分类。该分类法被提议作为未来研究的基础工具，以评估名称相似性对代码质量和开发人员交互的影响。

> **摘要翻译:** 标识符名称构成了代码库的很大一部分，是有效程序理解的基石。然而，研究表明，选择不当的名称会显著增加认知负荷并阻碍协作。即使是独立看起来可读的名称，当它们在结构或功能上与其他名称非常相似时，也可能在特定上下文中导致误解。在这项探索性研究中，我们通过开发一个对不同形式的标识符名称相似性进行分类的分类法，展示了我们在软件项目中标识符名称相似性发生情况的初步发现。我们设想我们的初始分类法能为研究人员提供一个平台，用于分析和评估标识符名称相似性对代码理解、可维护性以及开发人员之间协作的影响，同时也允许对该分类法进行进一步的完善和扩展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [273] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
> *NoCode-bench：一个评估自然语言驱动功能添加的基准*

*Le Deng, Zhonghao Jiang, Jialun Cao, Michael Pradel, Zhongxin Liu* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 无代码开发, 自然语言处理, 大型语言模型, 基准测试, 功能添加

**Comment:** 

> **TL;DR:** 该研究引入了NoCode-bench，一个用于评估大型语言模型在自然语言驱动的无代码开发中添加功能的基准。实验结果表明，尽管大型语言模型有潜力，但其在真实任务中的成功率仅为15.79%，表明它们尚未完全准备好进行自然语言驱动的无代码开发。

**AI_Comments:** 这篇论文的创新之处在于提出了一个专门用于评估自然语言驱动无代码开发能力的基准，这对于量化LLMs在该领域的表现至关重要。其重要性在于明确指出了当前LLMs在处理复杂软件开发任务（如跨文件编辑和代码库理解）方面的局限性，为未来的研究指明了方向。NoCode-bench的引入为该领域提供了一个标准化的评估工具，有助于推动LLMs在软件工程领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言驱动的无代码开发承诺提高生产力并实现开发民主化，而大型语言模型（LLMs）在此范式中展现潜力。为了评估LLMs在现实世界中实现这一潜力的能力，需要一个专门的基准。

**Method:** 本研究引入了NoCode-bench，这是一个旨在评估LLMs在真实世界自然语言驱动功能添加任务上的基准。它包含来自10个项目的634个任务和11.4万次代码更改，每个任务将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。此外，还创建了一个包含114个高质量、人工验证实例的子集，即NoCode-bench Verified，以确保评估的可靠性。

**Result:** 实验结果显示，尽管大型语言模型（LLMs）的token使用量很高，但最佳LLMs的任务成功率仅为15.79%。这突显了跨文件编辑、代码库理解和工具调用方面的挑战。

**Conclusion:** LLMs尚未完全准备好进行自然语言驱动的无代码开发。NoCode-bench为该领域的未来发展奠定了基础。

> **ai_Abstract:** 本论文介绍了NoCode-bench，一个用于评估大型语言模型（LLMs）在自然语言驱动功能添加任务上的新基准。该基准包含真实世界的任务，通过将文档更新与代码实现配对，并由开发者测试用例验证。研究发现，尽管LLMs在无代码开发方面有潜力，但它们在这些任务上的成功率仅为15.79%，揭示了跨文件编辑、代码库理解和工具调用等方面的挑战。这表明LLMs尚未成熟到可以完全支持自然语言驱动的无代码开发，但NoCode-bench为该领域的未来研究奠定了基础。

> **摘要翻译:** 自然语言驱动的无代码开发允许用户使用自然语言（NL）而非编辑源代码来指定软件功能，有望提高生产力并实现开发的民主化。大型语言模型（LLMs）在此范式中展现出潜力。在这种背景下，软件文档充当了功能的NL规范。这项工作引入了NoCode-bench，一个旨在评估LLMs在真实世界NL驱动功能添加任务上的基准，它包含来自10个项目的634个任务和11.4万次代码更改。每个任务将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。一个包含114个高质量、人工验证实例的子集，即NoCode-bench Verified，确保了可靠的评估。我们的实验表明，尽管token使用量很高，但最佳LLMs的任务成功率仅为15.79%，这突显了跨文件编辑、代码库理解和工具调用方面的挑战。这些发现表明LLMs尚未完全准备好进行完全由NL驱动的无代码开发。NoCode-bench为该领域的未来发展奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [308] [SMECS: A Software Metadata Extraction and Curation Software](https://arxiv.org/abs/2507.18159)
> *SMECS：一款软件元数据提取与管理软件*

*Stephan Ferenz, Aida Jafarbigloo, Oliver Werth, Astrid Nieße* | **Category: cs.SE, cs.DL** | **Updated: 2025-07-24**

**Keywords:** 软件元数据, FAIR原则, 元数据提取, 元数据管理, 研究软件

**Comment:** 

> **TL;DR:** SMECS是一款软件，通过从在线仓库提取元数据并提供用户友好的界面进行管理，从而简化了研究软件元数据的创建，以支持FAIR原则。

**AI_Comments:** SMECS的创新之处在于它将元数据自动提取与用户友好的手动管理相结合，有效解决了研究软件元数据创建的痛点。这对于推动研究软件的FAIR原则落地具有重要意义，因为它降低了研究人员创建高质量元数据的门槛，从而提高了软件的可发现性和可重用性。

<details>
  <summary>Details</summary>

**Motivation:** 研究软件的元数据对于遵循FAIR原则、提高可查找性和可重用性至关重要。然而，创建高质量的元数据对研究人员和研究软件工程师来说耗费资源。为了解决这一挑战，本文开发了SMECS。

**Method:** SMECS（软件元数据提取与管理软件）整合了从现有来源（如GitHub等在线仓库）提取元数据的功能，并提供了一个用户友好的界面供用户管理。它将提取的元数据通过交互式界面呈现给研究人员，以便进一步管理并可导出为CodeMeta文件。

**Result:** 通过可用性实验评估了SMECS的可用性，实验结果证实SMECS提供了令人满意的用户体验。

**Conclusion:** SMECS通过简化元数据创建过程，支持了研究软件的FAIR化。

> **ai_Abstract:** 本文介绍了一款名为SMECS的软件元数据提取与管理工具。该工具旨在解决研究软件元数据创建耗时费力的问题，通过从GitHub等在线仓库自动提取元数据，并提供直观的用户界面进行管理和导出（CodeMeta格式）。可用性评估证实SMECS能提供良好的用户体验，从而有效简化元数据创建，促进研究软件的FAIR化。

> **摘要翻译:** 元数据在研究软件采用FAIR原则中扮演着关键角色，并能实现可查找性和可重用性。然而，创建高质量的元数据对于研究人员和研究软件工程师来说可能资源密集。为了解决这一挑战，我们开发了软件元数据提取与管理软件（SMECS），它集成了从现有来源提取元数据的功能，并提供了一个用户友好的元数据管理界面。SMECS从GitHub等在线仓库提取元数据，并通过交互式界面将其呈现给研究人员，以进行进一步的管理并导出为CodeMeta文件。SMECS的可用性通过可用性实验进行了评估，实验证实SMECS提供了令人满意的用户体验。SMECS通过简化元数据创建过程，支持了研究软件的FAIR化。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [343] [GenAI for Automotive Software Development: From Requirements to Wheels](https://arxiv.org/abs/2507.18223)
> *汽车软件开发中的生成式AI：从需求到车轮*

*Nenad Petrovic, Fengjunjie Pan, Vahid Zolfaghari, Krzysztof Lebioda, Andre Schamschurko, Alois Knoll* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 生成式AI, 汽车软件开发, ADAS, 大型语言模型, 模型驱动工程

**Comment:** 

> **TL;DR:** 本文介绍了一种利用生成式AI（GenAI）自动化开发汽车软件，特别是自动驾驶和ADAS功能的方法，旨在缩短开发和测试周期。

**AI_Comments:** 本文的创新点在于将生成式AI（GenAI）与模型驱动工程（MDE）及检索增强生成（RAG）相结合，形成了一个端到端的汽车软件自动化开发流程，涵盖了从需求到代码生成的全生命周期。这对于加速复杂且高安全要求的汽车软件（尤其是ADAS和自动驾驶系统）的开发具有重要意义，有望大幅提升开发效率并降低成本。

<details>
  <summary>Details</summary>

**Motivation:** 缩短合规和再工程周期，以及减少ADAS相关功能的开发和测试时间。

**Method:** 本文提出一种由生成式AI赋能的汽车软件自动化开发方法，以需求作为输入，主要生成用于仿真环境的测试场景代码和车辆硬件平台的ADAS功能实现代码。该方法利用模型驱动工程（MDE）进行需求一致性检查，并使用大型语言模型（LLMs）进行基于模型的需求摘要、测试场景生成、仿真代码（Python）和目标平台代码（C++）生成。此外，还采用检索增强生成（RAG）从自动驾驶法规文档中增强测试场景生成。

**Result:** 该方法旨在缩短合规和再工程周期，以及减少ADAS相关功能的开发和测试时间。

**Conclusion:** 该方法有望加速汽车软件，特别是ADAS功能的开发和测试流程，提高效率并缩短上市时间。

> **ai_Abstract:** 本文提出了一种利用生成式AI（GenAI）自动化开发汽车软件，特别是自动驾驶和高级驾驶辅助系统（ADAS）功能的新方法。该方法从需求输入开始，通过大型语言模型（LLMs）生成测试场景代码、仿真代码（Python）和目标平台代码（C++），并结合模型驱动工程（MDE）进行需求一致性检查。此外，采用检索增强生成（RAG）从法规文档中增强测试场景生成。该方法旨在显著缩短汽车软件的开发和测试周期，提高效率。

> **摘要翻译:** 本文介绍了一种由生成式AI赋能的汽车软件自动化开发方法，重点关注自动驾驶和高级驾驶辅助系统（ADAS）功能。该过程以需求作为输入，主要生成输出是用于仿真环境的测试场景代码，以及针对连接到测试台的车辆硬件平台的目标ADAS功能实现。此外，我们引入了利用模型驱动工程（MDE）进行需求一致性检查的额外步骤。在提议的工作流程中，大型语言模型（LLM）用于基于模型的需求摘要（Ecore元模型、XMI模型实例和OCL约束创建）、测试场景生成、仿真代码（Python）和目标平台代码生成（C++）。此外，采用检索增强生成（RAG）来增强从自动驾驶法规相关文档中生成测试场景。我们的方法旨在缩短合规和再工程周期，以及减少开发和测试时间，特别是针对ADAS相关功能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [385] [An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs](https://arxiv.org/abs/2507.18267)
> *具身人工智能机器人 (EAIR) 软件缺陷的实证研究*

*Zeqin Liao, Zibin Zheng, Peifan Reng, Henglong Liang, Zixu Gao, Zhixiang Chen, Wei Li, Yuhong Nan* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 具身人工智能机器人, 软件缺陷, 实证研究, 缺陷分析, 缺陷分类

**Comment:** 

> **TL;DR:** 对具身人工智能机器人（EAIR）的885个软件缺陷进行了首次系统性研究，分类了缺陷症状、根本原因和模块分布，并发现了EAIR特有的缺陷类型及其原因，构建了原因与模块的映射，以帮助未来的缺陷预测、检测和修复。

**AI_Comments:** 这项研究的创新之处在于它是首次对EAIR系统软件缺陷进行大规模的系统性实证研究，填补了该领域对缺陷理解的空白。其重要性在于，通过识别EAIR特有的缺陷症状和根本原因，并构建原因与模块的映射，为未来EAIR软件的质量保证、缺陷预测、检测和修复提供了宝贵的经验数据和理论基础，对于确保EAIR的成功部署和安全性具有重要意义。该研究的局限性可能在于其样本的代表性，即80个项目和885个缺陷是否能完全覆盖所有EAIR系统的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 具身人工智能机器人（EAIR）是一个新兴且快速发展的技术领域，确保其程序正确性对其成功部署至关重要。然而，目前对EAIR系统缺陷的普遍和深入理解仍然缺乏，这阻碍了解决EAIR系统缺陷的实践和技术的发展。

**Method:** 研究人员对从80个EAIR系统项目中收集的885个EAIR系统缺陷进行了首次系统性研究，以调查其症状、根本原因和模块分布。分析将这些缺陷分为18种根本原因、15种不同的症状，并识别了13个受影响的模块。为了促进精确高效的缺陷预测、检测和修复，构建了根本原因与最常发生模块之间的映射。

**Result:** 研究揭示了几个新的有趣发现和启示。首先，在15个已识别的症状中，有8个是EAIR系统特有的，其特点是严重的系统功能故障和潜在的物理危险。其次，在18个根本原因中，定义了8个EAIR特有的原因，其中大多数源于AI代理推理和决策的复杂问题。最后，构建了根本原因与模块的映射，使研究人员能够将诊断工作集中在最容易出现特定类型缺陷的模块上。

**Conclusion:** 本研究首次对EAIR系统缺陷进行了系统性分析，识别了EAIR特有的缺陷症状和根本原因，并构建了根本原因与模块的映射，这些发现有助于阐明未来解决或修复EAIR系统缺陷的研究方向，促进精确高效的缺陷预测、检测和修复。

> **ai_Abstract:** 本研究首次对具身人工智能机器人（EAIR）的软件缺陷进行了系统性实证分析。通过调查来自80个项目的885个EAIR系统缺陷，论文详细分类了缺陷的15种症状、18种根本原因和13个受影响模块。研究特别识别出8种EAIR特有的严重功能故障和潜在物理危害症状，以及8种主要源于AI推理和决策复杂性的EAIR特有根本原因。此外，论文还构建了根本原因与高频发生模块的映射，旨在为未来EAIR系统缺陷的预测、检测和修复提供指导，提高诊断效率。

> **摘要翻译:** 具身人工智能机器人（EAIR）是一个新兴且快速发展的技术领域。确保其程序正确性对其成功部署至关重要。然而，目前对EAIR系统缺陷的普遍和深入理解仍然缺乏，这阻碍了解决EAIR系统缺陷的实践和技术的发展。
为了弥补这一差距，我们对从80个EAIR系统项目中收集的885个EAIR系统缺陷进行了首次系统性研究，以调查其症状、根本原因和模块分布。我们的分析付出了巨大的努力，将这些缺陷分为18种根本原因、15种不同的症状，并识别了13个受影响的模块。它揭示了几个新的有趣发现和启示，有助于阐明未来解决或修复EAIR系统缺陷的研究。首先，在15个已识别的症状中，我们的发现强调了8个EAIR系统特有的症状，其特点是严重的系统功能故障和潜在的物理危险。其次，在18个根本原因中，我们定义了8个EAIR特有的原因，其中大多数源于AI代理推理和决策的复杂问题。最后，为了促进精确高效的缺陷预测、检测和修复，我们构建了根本原因与最常发生模块之间的映射，这使得研究人员能够将诊断工作集中在最容易出现特定缺陷类型的模块上。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [427] [YATE: The Role of Test Repair in LLM-Based Unit Test Generation](https://arxiv.org/abs/2507.18316)
> *YATE：测试修复在基于LLM的单元测试生成中的作用*

*Michael Konstantinou, Renzo Degiovanni, Jie M. Zhang, Mark Harman, Mike Papadakis* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 单元测试生成, LLM, 测试修复, 代码覆盖率, 变异测试

**Comment:** 12 pages, 4 figures

> **TL;DR:** YATE通过修复LLM生成的错误测试来提高单元测试的覆盖率和变异杀死率。

**AI_Comments:** 本文的创新点在于提出了“测试修复”这一概念，将LLM生成的错误测试视为“错失的机会”，并通过一套简单有效的方法对其进行修复，从而显著提升了LLM在单元测试生成领域的实用性和效率。这对于提高自动化测试的质量和降低人工干预的需求具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于语言模型的单元测试生成方法会产生大量语法和语义错误，这些错误测试如果能被修复，将非常有价值，但目前被浪费了。

**Method:** 提出了一种名为YATE的简单技术，结合了基于规则的静态分析和重新提示来修复不正确的测试。

**Result:** YATE在6个开源项目上，比普通的LLM方法平均多覆盖32.06%的代码行，多杀死21.77%的变异体。与HITS、SYMPROMPT、TESTSPARK和COVERUP等其他LLM方法相比，YATE在相似成本下实现了22%更高的行覆盖率，20%更高的分支覆盖率，并多杀死20%的变异体。

**Conclusion:** YATE通过修复LLM生成的错误测试，显著提高了单元测试的质量和效率。

> **ai_Abstract:** 本文提出了YATE，一种修复大型语言模型（LLM）生成的不正确单元测试的技术。通过结合规则分析和重新提示，YATE能够有效修复LLM最初生成的错误测试，将其转化为有价值的测试用例。实验结果表明，YATE显著提高了测试的行覆盖率、分支覆盖率和变异杀死率，优于现有多种LLM基线方法，且成本相当。

> **摘要翻译:** 自动化测试生成的最新进展利用语言模型来生成单元测试。尽管有效，但语言模型在语法和语义上往往会生成许多不正确的测试。虽然这些不正确的测试可以很容易地被检测和丢弃，但它们构成了一个“错失的机会”——如果被修复，它们通常很有价值，因为它们直接增加了测试价值（它们有效地针对了要测试的底层程序逻辑），并间接形成了生成额外测试的良好种子。为此，我们提出了一种简单的技术，通过结合基于规则的静态分析和重新提示来修复其中一些不正确的测试。我们在6个开源项目上评估了这种名为YATE的简单方法，结果表明它能有效地生成测试，比普通的基于LLM的方法平均多覆盖32.06%的代码行，多杀死21.77%的变异体。我们还将YATE与HITS、SYMPROMPT、TESTSPARK和COVERUP等其他四种基于LLM的方法进行了比较，结果表明它能生成覆盖更多代码的测试。YATE在可比较的成本（LLM调用次数）下，实现了22%更高的行覆盖率，20%更高的分支覆盖率，并多杀死20%的变异体。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [432] [Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping](https://arxiv.org/abs/2507.18037)
> *您的攻击技术到任务：MITRE ATT&CK 攻击技术到 P-SSCRM 任务映射*

*Sivana Hamer, Jacob Bowen, Md Nazmul Haque, Chris Madden, Laurie Williams* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** MITRE ATT&CK, 软件供应链风险管理, P-SSCRM, 攻击技术, 任务映射

**Comment:** Mapping generated from: arXiv:2503.12192

> **TL;DR:** 本文描述了将MITRE ATT&CK攻击技术映射到P-SSCRM任务的方法，旨在帮助软件组织了解如何通过P-SSCRM任务来缓解软件供应链攻击。

**AI_Comments:** 该论文通过建立MITRE ATT&CK与P-SSCRM之间的映射，为软件组织提供了一个实用的工具，以更好地理解和应对软件供应链攻击。其创新之处在于采用四种独立策略来确保映射的准确性与共识性，并且通过P-SSCRM的连接性，间接实现了ATT&CK与其他主流框架的整合。这对于提升软件供应链安全管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是帮助软件组织确定不同的P-SSCRM任务如何缓解软件供应链攻击的ATT&CK攻击技术。

**Method:** 该映射是通过四种独立的策略创建的，以找到一致的映射关系。

**Result:** 该研究提供了一个将MITRE ATT&CK攻击技术映射到主动软件供应链风险管理框架（P-SSCRM）任务的映射。此外，由于每个P-SSCRM任务都映射到10个框架中的一个或多个任务，因此该映射也间接连接了MITRE ATT&CK与其他重要的政府和行业框架。

**Conclusion:** 该映射有助于软件组织理解P-SSCRM任务如何缓解软件供应链攻击，并且还提供了一个将MITRE ATT&CK与其他重要政府和行业框架关联起来的途径。

> **ai_Abstract:** 本文介绍了一个将MITRE ATT&CK攻击技术映射到P-SSCRM任务的详细方法，旨在帮助软件组织识别和缓解软件供应链攻击。该映射通过四种独立的策略构建，并由于P-SSCRM任务与其他10个框架的关联，该映射也间接连接了MITRE ATT&CK与其他重要的政府和行业框架。

> **摘要翻译:** 本文描述的MITRE对抗性战术、技术和通用知识（MITRE ATT&CK）攻击技术到主动软件供应链风险管理框架（P-SSCRM）任务的映射，有助于软件组织确定不同的任务如何缓解软件供应链攻击的攻击技术。该映射是通过四种独立的策略创建的，以找到一致的映射。由于每个P-SSCRM任务都映射到10个框架中的一个或多个任务，因此我们提供的映射也是MITRE ATT&CK与其他重要政府和行业框架之间的映射。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [450] [Understanding the Supply Chain and Risks of Large Language Model Applications](https://arxiv.org/abs/2507.18105)
> *理解大型语言模型应用的供应链与风险*

*Yujie Ma, Lili Quan, Xiaofei Xie, Qiang Hu, Jiongchi Yu, Yao Zhang, Sen Chen* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 供应链安全, 风险评估, 数据集, 漏洞分析

**Comment:** 26 pages

> **TL;DR:** 该研究介绍了首个用于分析和基准测试LLM供应链安全的综合数据集，揭示了LLM应用中深度嵌套的依赖关系和显著的供应链漏洞，并提出了实际建议。

**AI_Comments:** 该论文的创新之处在于构建了首个全面的LLM供应链安全数据集，填补了现有研究在系统性基准方面的空白。其重要性在于揭示了LLM应用中被忽视的供应链风险，提醒业界需要进行更全面的安全分析，并为未来的研究和开发提供了宝贵的资源和指导。

<details>
  <summary>Details</summary>

**Motivation:** LLM系统日益普及，但大多数风险评估仅关注模型或数据层面，忽视了更广泛的供应链漏洞。虽然已有研究开始关注LLM供应链风险，但缺乏系统性研究的基准。

**Method:** 收集了3,859个真实世界LLM应用，并进行了相互依赖分析，识别出109,211个模型、2,474个数据集和9,862个库。提取了模型微调路径、数据集重用和库依赖，并从公共漏洞数据库收集了1,555个风险相关问题（应用50个、模型325个、数据集18个、库1,229个）。使用该数据集对组件依赖和风险进行了实证分析。

**Result:** 研究发现LLM应用中存在深度嵌套的依赖关系，并且整个供应链中存在显著的漏洞。

**Conclusion:** 需要对LLM供应链进行全面的安全分析，并为研究人员和开发人员提供了实用建议，以构建更安全、更值得信赖的LLM系统。

> **ai_Abstract:** 本研究旨在解决当前对大型语言模型（LLM）系统风险评估中忽视供应链漏洞的问题。作者构建了首个综合数据集，包含3,859个真实LLM应用及其组件（模型、数据集、库）的相互依赖关系和1,555个相关安全问题。通过对该数据集的实证分析，研究揭示了LLM应用中深度嵌套的依赖关系和整个供应链中的显著漏洞，并提出了构建更安全LLM系统的实用建议。

> **摘要翻译:** 大型语言模型（LLM）的兴起导致基于LLM的系统在不同领域得到广泛部署。随着这些系统的普及，理解其复杂供应链相关的风险变得越来越重要。基于LLM的系统并非独立存在，它们依赖于相互关联的供应链，涉及预训练模型、第三方库、数据集和基础设施。然而，大多数风险评估仅狭隘地关注模型或数据层面，忽视了更广泛的供应链漏洞。尽管最近的研究已经开始解决LLM供应链风险，但仍缺乏系统性研究的基准。
为了弥补这一空白，我们引入了首个用于分析和基准测试LLM供应链安全的综合数据集。我们收集了3,859个真实世界的LLM应用，并进行了相互依赖分析，识别出109,211个模型、2,474个数据集和9,862个库。我们提取了模型微调路径、数据集重用和库依赖，从而绘制出生态系统的结构。为了评估安全性，我们从公共漏洞数据库收集了1,555个风险相关问题——其中50个针对应用，325个针对模型，18个针对数据集，1,229个针对库。
利用该数据集，我们实证分析了组件依赖和风险。我们的发现揭示了LLM应用中深度嵌套的依赖关系以及整个供应链中存在的显著漏洞，强调了进行全面安全分析的必要性。最后，我们提出了实用建议，以指导研究人员和开发人员构建更安全、更值得信赖的LLM赋能系统。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [474] [Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling](https://arxiv.org/abs/2507.18289)
> *Scheduzz: 基于约束的双重调度模糊驱动生成*

*Yan Li, Wenzhang Yang, Yuekun Wang, Jian Gao, Shaohua Wang, Yinxing Xue, Lijun Zhang* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 模糊测试, LLM, 模糊驱动生成, 双重调度, 约束条件

**Comment:** 15 pages, 12 figures, 5 tables

> **TL;DR:** Scheduzz是一种基于LLM的模糊测试技术，通过理解库的使用约束和双重调度来高效生成模糊驱动并发现更多bug，显著优于现有技术。

**AI_Comments:** Scheduzz的创新之处在于结合了大型语言模型（LLM）来理解库的使用规范和API约束，解决了传统模糊测试在生成“理性”驱动方面的难题。其引入的双重调度框架将驱动生成和模糊测试过程视为在线优化问题，有效提升了资源利用效率。这项工作的重要性体现在其显著提高了模糊测试的效率和效果，尤其是在发现真实世界中未知bug方面，且部分漏洞获得了CVE，证明了其在实际安全保障中的价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有模糊驱动生成技术未能遵循正确的库使用约定（如资源关闭），导致生成非理性驱动，浪费计算资源，覆盖率低，并产生假阳性bug报告。

**Method:** 提出Scheduzz，一种基于LLM的库模糊测试技术。它利用LLM理解库的合理使用并提取API组合约束。为优化计算资源利用，实现了双重调度框架，将驱动生成和模糊测试活动建模为在线优化问题，在调度循环中选择API组合生成驱动，并调度优化后的驱动执行或暂停。

**Result:** Scheduzz显著降低了计算开销，在21个库中的16个上优于UTopia。与CKGFuzzer、Promptfuzz和手工项目OSS-Fuzz相比，总覆盖率分别提高了1.62倍、1.50倍和1.89倍。发现了33个未知的bug，其中3个已分配CVE。

**Conclusion:** Scheduzz通过结合LLM理解库使用约束和双重调度框架，有效解决了现有模糊测试技术生成非理性驱动和资源浪费的问题，显著提高了覆盖率并发现了大量实际bug。

> **ai_Abstract:** Scheduzz是一种创新的基于LLM的库模糊测试技术，旨在解决现有方法在生成合理模糊驱动和优化资源利用方面的不足。它通过利用LLM理解库使用约束并引入双重调度框架来高效生成和管理模糊驱动。实验结果表明，Scheduzz显著减少了计算开销，提高了代码覆盖率，并成功发现了大量实际bug，包括获得CVE的漏洞。

> **摘要翻译:** 模糊测试库需要专家深入理解库的使用并编写高质量的模糊驱动，这既棘手又繁琐。因此，许多技术被提出以自动生成模糊驱动。然而，由于未能遵循正确的库使用约定，例如确保资源在使用后被关闭，它们无法生成合理的模糊驱动。更糟糕的是，现有的库模糊测试技术无条件地执行每个驱动，导致大量非理性驱动浪费计算资源，同时对覆盖率贡献甚微并生成假阳性bug报告。
为了解决这些挑战，我们提出了一种新颖的自动库模糊测试技术——Scheduzz，一种基于LLM的库模糊测试技术。它利用LLM来理解库的合理使用并提取API组合约束。为了优化计算资源利用，实现了一个双重调度框架，以高效管理API组合和模糊驱动。该框架将驱动生成和相应的模糊测试活动建模为在线优化问题。在调度循环中，选择多个API组合来生成模糊驱动，同时调度各种优化后的模糊驱动执行或暂停。
我们实现了Scheduzz并在33个真实世界库中进行了评估。与基线方法相比，Scheduzz显著降低了计算开销，并在21个库中的16个上优于UTopia。它分别比最先进的技术CKGFuzzer、Promptfuzz和手工项目OSS-Fuzz实现了1.62倍、1.50倍和1.89倍的更高总体覆盖率。此外，Scheduzz在这些经过充分测试的库中发现了33个以前未知的错误，其中3个已被分配CVE。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [475] [Gotta catch 'em all! Towards File Localisation from Issues at Large](https://arxiv.org/abs/2507.18319)
> *全都抓住！迈向大规模问题的文件定位*

*Jesse Maarleveld, Jiapan Guo, Daniel Feitosa* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 文件定位, 问题定位, 数据管道, 信息检索, 通用模型

**Comment:** 12 pages, 6 figures

> **TL;DR:** 本文提出了一种处理任意分支和合并实践的问题文件定位数据集的数据管道，并使用传统信息检索方法进行了基线性能评估。研究发现，针对特定bug的方法在通用问题类型上表现不佳，需要通用模型，且性能存在项目依赖性。

**AI_Comments:** 本文的创新之处在于其将文件定位的范围从传统的bug扩展到所有大规模问题，并为此设计了通用的数据管道。研究结果强调了开发通用文件定位模型的必要性，因为它揭示了现有bug特定方法在通用问题上的局限性，并指出了项目依赖性，这对未来的研究方向具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文件定位研究主要集中在bug或特定类型的问题上，但作者的目标是处理所有大规模问题，以节省开发人员的时间。

**Method:** 本文提供了一个用于创建问题文件定位数据集的数据管道，该管道能够处理任意分支和合并实践。作者使用传统信息检索方法对文件定位问题进行了基线性能评估，并利用统计分析调查了bug定位社区中已知的偏差对数据集的影响。

**Result:** 研究结果表明，使用bug特定启发式设计的方法在通用问题类型上表现不佳，这表明需要研究通用模型。此外，不同问题类型之间存在微小但统计学上显著的性能差异。最后，标识符的存在对大多数问题类型的性能影响很小。许多结果是项目依赖的。

**Conclusion:** 针对bug优化的方法在通用问题定位任务上表现不佳，需要开发能够适应项目特定特征的通用文件定位模型。

> **ai_Abstract:** 本文旨在解决现有文件定位研究主要关注bug或特定问题类型的局限性，提出了一种处理所有大规模问题的文件定位方法。作者构建了一个能够处理任意分支和合并实践的数据管道，用于创建问题文件定位数据集，并利用传统信息检索方法进行了基线性能评估。研究发现，基于bug特定启发式的方法在通用问题类型上表现不佳，凸显了开发通用模型的重要性，并指出性能与项目特性密切相关，鼓励开发可调优的方法。

> **摘要翻译:** Bug定位，即研究开发方法来定位解决bug所需的文件，这项研究已经进行了很长时间，旨在开发能够节省开发者时间的方法。最近，研究人员开始考虑bug之外的问题。然而，大多数现有关于从问题进行文件定位的研究都集中在bug上，或者使用其他选择方法来确保只有特定类型的问题被视为工作重点。我们的目标是处理所有大规模问题，不进行任何特定选择。
在这项工作中，我们提供了一个用于创建问题文件定位数据集的数据管道，能够处理任意分支和合并实践。我们使用传统信息检索方法为文件定位问题提供了基线性能评估。最后，我们使用统计分析来调查bug定位社区中已知的偏差对我们数据集的影响。
我们的结果表明，使用bug特定启发式设计的方法在通用问题类型上表现不佳，这表明需要研究通用模型。此外，我们发现不同问题类型之间存在微小但统计学上显著的性能差异。最后，我们发现标识符的存在对大多数问题类型的性能影响很小。许多结果是项目依赖的，这鼓励开发能够针对项目特定特征进行调整的方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [523] [FMI Meets SystemC: A Framework for Cross-Tool Virtual Prototyping](https://arxiv.org/abs/2507.18339)
> *FMI 遇见 SystemC：一个跨工具虚拟原型设计框架*

*Nils Bosbach, Meik Schmidt, Lukas Jünger, Matthias Berthold, Rainer Leupers* | **Category: cs.SE, cs.DC** | **Updated: 2025-07-24**

**Keywords:** FMI, SystemC, 虚拟原型设计, 协同仿真, 软件测试

**Comment:** PREPRINT - accepted by the 16th International Modelica and FMI
  Conference 2025

> **TL;DR:** 该论文提出了一个将功能模型接口（FMI）与SystemC结合的新框架，以实现跨工具的虚拟原型设计和软件测试，弥补了SystemC缺乏原生FMI支持的不足。

**AI_Comments:** 该论文的创新点在于弥补了SystemC在跨工具协同仿真方面的不足，通过引入FMI支持，极大地扩展了SystemC在复杂系统虚拟原型设计和软件测试中的应用范围。其重要性体现在能够加速软件开发和系统认证过程，尤其是在需要高可靠性的领域。

<details>
  <summary>Details</summary>

**Motivation:** 随着系统日益复杂，对全面测试和虚拟原型设计的需求不断增长。模拟整个系统通常需要多种工具。现代系统中的控制部分通常是计算单元（如SoC或MCU），其软件开发需要虚拟平台（VP）。SystemC TLM是VP开发的IEEE标准化框架，但SystemC缺乏原生FMI支持，这限制了其与更广泛的协同仿真环境的集成。

**Method:** 本文提出了一个新颖的框架，使用功能模型接口（FMI）来控制和与基于SystemC的虚拟平台（VP）进行交互。

**Result:** 通过一个案例研究展示了SystemC仿真中的模拟温度传感器如何通过FMI从外部工具获取温度值。这种方法允许未修改的目标软件在VP上运行，并接收来自其他工具的真实环境输入数据（如温度、速度或加速度值）。这使得广泛的软件测试和验证成为可能。

**Conclusion:** 通过将FMI与SystemC结合，可以实现更全面的系统级虚拟原型设计和软件测试，从而加速认证过程，如ISO 26262。

> **ai_Abstract:** 本论文提出了一种将功能模型接口（FMI）与SystemC结合的新框架，旨在解决SystemC在虚拟原型设计中缺乏原生FMI支持的问题。该框架允许基于SystemC的虚拟平台（VP）通过FMI与外部工具进行交互，从而为未修改的目标软件提供真实的外部环境输入。通过案例研究验证了其可行性，并指出该方法能够实现更全面的软件测试和验证，有助于提前完成如ISO 26262等认证。

> **摘要翻译:** 随着系统变得越来越复杂，对彻底测试和虚拟原型设计的需求也日益增长。为了模拟整个系统，通常需要多种工具来覆盖不同的部分。这些部分包括系统的硬件以及系统与之交互的环境。功能模型接口（FMI）协同仿真标准可用于连接这些工具。
现代系统的控制部分通常是一个计算单元，例如片上系统（SoC）或微控制器单元（MCU），它执行来自连接内存的软件并与外设交互。为了在不需要物理硬件的情况下开发软件，通常使用全系统模拟器，即所谓的虚拟平台（VP）。IEEE标准化VP开发框架是SystemC TLM。SystemC提供了接口和概念，实现了模块化设计和模型交换。然而，SystemC缺乏原生FMI支持，这限制了其集成到更广泛的协同仿真环境中。
本文提出了一个新颖的框架，旨在使用FMI控制和与基于SystemC的VP进行交互。我们提出了一个案例研究，展示了SystemC仿真中的模拟温度传感器如何通过FMI从外部工具获取温度值。这种方法允许未修改的目标软件在VP上运行，并接收来自其他工具的真实环境输入数据，例如温度、速度或加速度值。因此，这使得广泛的软件测试和验证成为可能。通过在物理硬件可用时，使用VP准备好测试并预先测试软件，可以更早地完成ISO 26262等认证。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [571] [Automated Code Review Using Large Language Models with Symbolic Reasoning](https://arxiv.org/abs/2507.18476)
> *结合符号推理的大型语言模型自动化代码审查*

*Busra Icoz, Goksel Biricik* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 自动化代码审查, 大型语言模型, 符号推理, 代码质量, 混合方法

**Comment:** 

> **TL;DR:** 论文提出了一种结合大型语言模型（LLMs）和符号推理的混合方法，以提高自动化代码审查的准确性和效率，解决了LLMs在代码理解和评估中逻辑推理能力不足的问题。

**AI_Comments:** 该论文的创新点在于结合了大型语言模型的强大文本生成和理解能力与符号推理的精确逻辑判断能力，有效弥补了LLMs在复杂代码逻辑理解上的不足，为自动化代码审查提供了一个更鲁棒和高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 手动代码审查主观且耗时，虽然AI已用于自动化，但当前大型语言模型（LLMs）缺乏完全理解和评估代码所需的逻辑推理能力。

**Method:** 提出了一种将符号推理技术与大型语言模型（LLMs）相结合的混合方法，用于自动化代码审查。使用CodexGlue数据集测试该方法，并与CodeT5、CodeBERT和GraphCodeBERT等模型进行比较。

**Result:** 结果表明，结合符号推理和提示技术与大型语言模型的混合方法提高了自动化代码审查的准确性和效率。

**Conclusion:** 结合符号推理可以有效克服大型语言模型在代码审查中逻辑推理能力的不足，从而提升自动化代码审查的性能。

> **ai_Abstract:** 本研究提出了一种结合大型语言模型（LLMs）和符号推理的混合方法，旨在解决LLMs在自动化代码审查中逻辑推理能力不足的问题。通过在CodexGlue数据集上与现有模型进行比较，结果显示该方法显著提高了自动化代码审查的准确性和效率。

> **摘要翻译:** 代码审查是软件开发生命周期中的关键过程之一，对于维护代码质量至关重要。然而，手动代码审查具有主观性且耗时。鉴于其基于规则的性质，代码审查非常适合自动化。近年来，在人工智能的帮助下，人们在自动化这一过程方面做出了巨大努力。大型语言模型（LLMs）的最新发展也已成为该领域有前景的工具，但这些模型通常缺乏完全理解和评估代码所需的逻辑推理能力。为了克服这一限制，本研究提出了一种混合方法，将符号推理技术与大型语言模型相结合，以实现代码审查过程的自动化。我们使用CodexGlue数据集测试了我们的方法，比较了包括CodeT5、CodeBERT和GraphCodeBERT在内的几种模型，以评估将符号推理和提示技术与大型语言模型结合的有效性。我们的结果表明，这种方法提高了自动化代码审查的准确性和效率。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [619] [A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat](https://arxiv.org/abs/2507.18515)
> *深入探究检索增强生成在代码补全中的应用：微信实践经验*

*Zezhou Yang, Ting Peng, Cuiyun Gao, Chaozheng Wang, Hailiang Huang, Yuetang Deng* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 代码补全, 检索增强生成, 大型语言模型, 闭源代码库, 微信

**Comment:** Accepted in ICSME 25 Industry Track

> **TL;DR:** 本文在微信工业级代码库中实证研究了检索增强生成（RAG）在代码补全中的表现，发现RAG方法有效，特别是结合词汇和语义检索的相似性RAG效果最佳。

**AI_Comments:** 本文的创新点在于首次将检索增强生成（RAG）方法应用于大规模工业级闭源代码库（如微信）的代码补全任务中，填补了开源与闭源环境之间RAG性能差异的空白。研究通过详尽的实验和开发者调查，不仅验证了RAG的有效性，还深入分析了不同RAG类型和检索技术的性能，为未来在实际软件工程环境中部署和优化RAG提供了宝贵的经验和指导。其发现对于提升企业级代码补全工具的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究已证明检索增强生成（RAG）在公共代码库上对代码补全的有效性，但开源和闭源代码库之间潜在的分布差异带来的独特挑战尚未被探索。本文旨在弥补这一空白，研究RAG方法在工业级闭源代码库（如微信）中的表现。

**Method:** 本研究在微信的工业级代码库（包含1,669个内部仓库）上进行了一项实证研究，以调查广泛使用的RAG方法在代码补全中的性能。具体而言，研究探索了两种主要的RAG方法：基于标识符的RAG和基于相似性的RAG，并在26个不同参数规模（0.5B至671B）的开源大型语言模型上进行了测试。对于基于相似性的RAG，采用了包括词汇（如BM25）和语义（如GTE-Qwen）在内的不同检索技术。此外，还进行了一项开发者调查以验证RAG方法的实际效用。

**Result:** 1. 两种RAG方法在闭源代码库中均有效，其中基于相似性的RAG表现更优。
2. 基于相似性的RAG的有效性随更先进的检索技术而提高，其中BM25（词汇检索）和GTE-Qwen（语义检索）表现出色。
3. 词汇和语义检索技术的结合产生了最佳结果，显示出互补的优势。

**Conclusion:** 检索增强生成（RAG）方法在工业级闭源代码库中的代码补全任务上具有显著的实用价值和有效性，特别是通过结合词汇和语义检索技术可以达到最优性能。

> **ai_Abstract:** 本文在微信的工业级闭源代码库中，对检索增强生成（RAG）在代码补全中的应用进行了深入的实证研究。研究探索了基于标识符和基于相似性的RAG方法，并测试了不同检索技术（词汇和语义）的有效性。结果表明，RAG方法在闭源环境中有效，其中结合词汇和语义检索的相似性RAG表现最佳。开发者调查也验证了RAG在实际开发中的实用性。

> **摘要翻译:** 代码补全作为软件工程中一项关键任务，可提高开发人员的生产力，随着大型语言模型（LLM）的迅速发展，其性能得到了显著提升。近年来，检索增强生成（RAG）作为一种有前景的方法，通过利用代码库中的相关上下文而无需模型再训练，增强了LLM的代码补全能力。尽管现有研究已证明RAG在公共仓库和基准测试上的有效性，但开源和闭源代码库之间潜在的分布差异带来了独特的挑战，这些挑战仍未被探索。为了弥补这一差距，我们进行了一项实证研究，以调查广泛使用的RAG方法在微信（最大的专有软件系统之一）的工业级代码库中进行代码补全的性能。具体而言，我们广泛探索了两种主要类型的RAG方法，即基于标识符的RAG和基于相似性的RAG，涵盖了26个参数范围从0.5B到671B的开源LLM。为了进行更全面的分析，我们对基于相似性的RAG采用了不同的检索技术，包括词汇检索和语义检索。基于1,669个内部仓库，我们取得了几个关键发现：(1) 两种RAG方法在闭源仓库中均表现出有效性，其中基于相似性的RAG表现更优，(2) 基于相似性的RAG的有效性随着更先进的检索技术而提高，其中BM25（词汇检索）和GTE-Qwen（语义检索）取得了卓越性能，(3) 词汇和语义检索技术的结合产生了最佳结果，显示出互补的优势。此外，我们进行了一项开发者调查，以验证RAG方法在实际开发环境中的实用性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [742] [SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis](https://arxiv.org/abs/2506.17798)
> *SAVANT：通过语义引导可达性分析检测应用程序依赖项中的漏洞*

*Wang Lingxiang, Quanzhi Fu, Wenjia Song, Gelei Deng, Yi Liu, Dan Williams, Ying Zhang* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 漏洞检测, 应用程序依赖项, 语义分析, 大型语言模型, 软件成分分析

**Comment:** 

> **TL;DR:** SAVANT利用LLM和语义预处理来准确检测Java应用依赖项中的已知漏洞，优于现有SCA工具。

**AI_Comments:** SAVANT的创新之处在于结合了语义预处理和大型语言模型（LLM）来解决现有SCA工具在理解API使用语义方面的局限性。利用LLM进行上下文分析是其核心优势，能够更准确地识别实际的漏洞影响，从而减少误报并提高检测效率。这对于提升软件供应链安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Java开发中集成开源第三方库依赖项会引入显著安全风险，现有软件成分分析（SCA）工具因不理解API使用语义和计算挑战，难以有效检测漏洞，导致不准确的警报并延迟关键安全修复。

**Method:** SAVANT结合语义预处理和LLM驱动的上下文分析进行漏洞检测。它首先将源代码分段为有意义的块并保留语义关系，然后利用基于LLM的反射来分析API使用上下文并确定实际漏洞影响。

**Result:** 在55个真实世界应用程序上的评估显示，SAVANT的精度为83.8%，召回率为73.8%，准确率为69.0%，F1分数为78.5%，优于最先进的SCA工具。

**Conclusion:** Not mentioned in abstract.

> **ai_Abstract:** 本文提出了SAVANT，一个用于检测Java应用依赖项中已知漏洞的工具。针对现有SCA工具在理解API使用语义和处理复杂代码库方面的不足，SAVANT结合了语义预处理和大型语言模型（LLM）驱动的上下文分析。它通过将源代码分段并利用LLM分析API使用上下文来确定实际漏洞影响。实验结果表明，SAVANT在精度、召回率、准确率和F1分数上均优于现有SCA工具。

> **摘要翻译:** Java开发中集成开源第三方库依赖项时，如果这些库包含已知漏洞，会引入显著的安全风险。现有的软件成分分析（SCA）工具由于在理解API使用语义方面的局限性以及分析复杂代码库时的计算挑战，难以有效检测来自这些库的易受攻击的API使用，导致不准确的漏洞警报，给开发团队带来负担并延迟关键安全修复。为了应对这些挑战，我们提出了SAVANT，它利用了两个见解：漏洞验证测试用例展示了如何在特定上下文中触发漏洞，以及大型语言模型（LLMs）可以理解代码语义。SAVANT将语义预处理与LLM驱动的上下文分析相结合，以实现准确的漏洞检测。SAVANT首先将源代码分割成有意义的代码块，同时保留语义关系，然后利用基于LLM的反射来分析API使用上下文并确定实际的漏洞影响。我们对55个真实世界应用程序的评估表明，SAVANT实现了83.8%的精度、73.8%的召回率、69.0%的准确率和78.5%的F1分数，优于最先进的SCA工具。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [752] [It is Giving Major Satisfaction: Why Fairness Matters for Software Practitioners](https://arxiv.org/abs/2410.02482)
> *它带来了极大的满足感：为什么公平对软件从业者很重要*

*Emeralda Sesari, Federica Sarro, Ayushi Rastogi* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 公平感知, 工作满意度, 软件从业者, 人际公平, 人口统计学差异

**Comment:** Accepted in ACM Transactions on Software Engineering and Methodology
  (TOSEM)

> **TL;DR:** 公平感显著影响软件从业者的工作满意度，尤其是人际公平，对女性、少数族裔、经验不足者和有工作限制者影响更大。

**AI_Comments:** 这篇论文填补了公平与工作满意度之间关系在软件工程领域研究不足的空白。其创新之处在于不仅验证了公平维度的普遍影响，还揭示了不同人口群体对公平敏感度的差异，特别是人际公平的重要性。这为软件组织提供了有针对性的改进策略，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 软件从业者经常遇到职场不公，尽管公平与工作满意度在其他领域已确立关联，但在软件专业人士中的相关性仍未充分探索。

**Method:** 本研究对108名软件从业者进行了一项在线调查，随后采用序数逻辑回归分析了软件工程背景下公平感知与工作满意度之间的关系，并进行了调节分析以检查这种关系在不同人口群体中的差异。

**Result:** 所有四种公平维度（分配公平、程序公平、人际公平和信息公平）都显著影响整体工作满意度和工作保障满意度。其中，人际公平影响最大。公平与工作满意度之间的关系对女性、少数族裔、经验不足的从业者以及有工作限制的从业者更强。署名公平是集体工作满意度的重要因素，而政策执行、高需求情况和工作时间方面的公平则影响特定人口群体。

**Conclusion:** 本研究强调了公平在软件从业者中的作用，为组织提供了促进公平实践的策略以及针对特定人口群体的目标方法。

> **ai_Abstract:** 本研究通过对108名软件从业者的在线调查和序数逻辑回归分析，探讨了公平感知与工作满意度之间的关系。研究发现，分配、程序、人际和信息公平均显著影响软件从业者的工作满意度，其中人际公平影响最大。此外，公平对女性、少数族裔、经验不足和有工作限制的从业者的工作满意度影响更强。研究强调了公平的重要性，并为组织提供了促进公平实践和针对特定群体的方法。

> **摘要翻译:** 软件从业者经常遇到职场不公，例如不平等的认可和性别偏见。尽管公平与工作满意度之间的联系已在其他领域建立，但其与软件专业人士的相关性仍未充分探索。本研究旨在探讨软件从业者的公平感知如何与工作满意度相关，重点关注总体趋势和人口统计学上的具体差异。我们对108名软件从业者进行了一项在线调查，随后采用序数逻辑回归分析了软件工程背景下公平感知与工作满意度之间的关系，并进行了调节分析以检查这种关系在不同人口群体中的差异。我们的研究结果表明，所有四种公平维度（即分配公平、程序公平、人际公平和信息公平）都显著影响整体工作满意度和工作保障满意度。其中，人际公平影响最大。公平与工作满意度之间的关系对女性、少数族裔、经验不足的从业者以及有工作限制的从业者更强。署名公平被认为是集体工作满意度的重要因素，而政策执行、高需求情况和工作时间方面的公平则影响特定人口群体。本研究强调了公平在软件从业者中的作用，为组织提供了促进公平实践的策略以及针对特定人口群体的目标方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [585] [Mapping Technological Futures: Anticipatory Discourse Through Text Mining](https://arxiv.org/abs/2504.02853)
> *绘制技术未来：通过文本挖掘进行的预期性话语分析*

*Maciej Skorski, Alina Landowska, Krzysztof Rajda* | **Category: cs.SI, cs.CL, cs.CY, cs.LG, K.4; H.3.3** | **Updated: 2025-03-25**

**Keywords:** 技术未来, 预期性话语, 文本挖掘, 关键意见领袖, 社交媒体

**Comment:** Accepted to Humanities and Social Sciences Communications. arXiv
  admin note: text overlap with arXiv:2407.17522

> **TL;DR:** 本研究通过分析X平台上关键意见领袖的帖子，利用文本挖掘技术，揭示了围绕新兴技术未来（如AI）的预期性话语，并强调了KOL在塑造当前和未来社会叙事中的关键作用。

**AI_Comments:** 该研究创新性地将大规模社交媒体数据与先进文本挖掘技术相结合，揭示了关键意见领袖在塑造公众对新兴技术未来认知中的复杂作用。其重要性在于，它提供了一个量化视角来理解预期性话语的动态，并强调了KOL在技术驱动社会变革中的影响力。

<details>
  <summary>Details</summary>

**Motivation:** 新兴技术（如人工智能）的波动性和不可预测性产生了巨大的不确定性，这些不确定性在社交媒体上被广泛讨论。本研究旨在通过分析社交媒体上的讨论来探究围绕技术未来的预期性话语。

**Method:** 本研究分析了2021年至2023年期间，400位关键意见领袖（KOLs）在X平台（推特）上发布的150万条帖子。研究采用了先进的文本挖掘技术，包括BERTopic主题建模、情感分析、情绪分析和态度分析。

**Result:** 研究识别出100个反映预期技术驱动未来的不同主题。研究结果强调了KOL在构建“当前未来”（对AI和物联网等变革性技术的乐观愿景）和影响“未来现在”（这些预测塑造当代社会和地缘政治辩论）方面的双重作用。积极情绪如“希望”占主导地位，超过了“焦虑”，尤其是在“机器学习、数据科学和深度学习”等主题中；而关于“气候变化”以及“战争、乌克兰和特朗普支持者”的讨论则引发了“焦虑”。

**Conclusion:** 通过将技术描绘成社会挑战的解决方案，KOLs充当了社会叙事的调解者，连接了想象中的未来和当前的现实。这些见解强调了他们在高度不确定时期引导公众对新兴技术关注的关键作用，并加深了我们对技术介导背景下预期性话语的理解。

> **ai_Abstract:** 本研究利用文本挖掘技术，分析了X平台上150万条KOL帖子，以探究新兴技术（如AI）相关的预期性话语。研究识别出100个主题，并发现KOL在塑造技术未来的乐观愿景和影响当前社会辩论中扮演双重角色。结果显示“希望”情绪普遍存在，尤其是在技术相关主题中，而特定社会政治主题则引发“焦虑”。论文强调了KOL在不确定时期作为社会叙事调解者的关键作用。

> **摘要翻译:** 新兴技术（如人工智能）的波动性和不可预测性产生了巨大的不确定性，这些不确定性在社交媒体上被广泛讨论。本研究通过分析400位关键意见领袖（KOLs）在X平台（2021年至2023年）上发布的150万条帖子，探讨了围绕技术未来的预期性话语。研究采用先进的文本挖掘技术，包括BERTopic主题建模、情感、情绪和态度分析，识别出100个反映预期技术驱动未来的不同主题。我们的发现强调了KOL在构建“当前未来”（对人工智能和物联网等变革性技术的乐观愿景）和影响“未来现在”（这些预测塑造当代社会和地缘政治辩论）方面的双重作用。积极情绪如“希望”占主导地位，超过了“焦虑”，尤其是在“机器学习、数据科学和深度学习”等主题中；而关于“气候变化”和“战争、乌克兰和特朗普支持者”的讨论则引发了“焦虑”。通过将技术描绘成社会挑战的解决方案，KOLs充当了社会叙事的调解者，连接了想象中的未来和当前的现实。这些见解强调了他们在高度不确定时期引导公众对新兴技术关注的关键作用，并加深了我们对技术介导背景下预期性话语的理解。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [243] [Frame-Based Zero-Shot Semantic Channel Equalization for AI-Native Communications](https://arxiv.org/abs/2507.17835)
> *面向AI原生通信的基于帧的零样本语义信道均衡*

*Simone Fiorellino, Claudio Battiloro, Emilio Calvanese Strinati, Paolo Di Lorenzo* | **Category: cs.NI** | **Updated: 2025-07-23**

**Keywords:** AI原生通信, 语义信道均衡, 零样本学习, Parseval帧, 潜在空间对齐

**Comment:** 

> **TL;DR:** 本文提出了Parseval帧均衡器（PFE），一个零样本、基于帧的语义信道均衡器，用于对齐异构编码器的潜在空间，以解决AI原生通信中语义信道噪声导致性能下降的问题，并在多智能体场景中优化资源以平衡能耗、延迟和任务性能。

**AI_Comments:** 本文的创新点在于提出了零样本、基于帧的Parseval帧均衡器（PFE），能够在不进行系统再训练的情况下解决AI原生通信中异构编码器潜在空间不匹配导致的语义噪声问题。这对于提升未来AI原生无线网络的互操作性和性能具有重要意义。此外，其动态资源优化策略也考虑了实际应用中的多重约束，体现了较强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在未来的AI原生无线网络中，独立设计和训练的深度神经网络（DNN）编码器之间潜在空间的不匹配可能导致语义信道噪声，从而阻碍相互理解，并降低接收器解释传输表示的能力，进而降低整体系统性能。

**Method:** 本文提出了Parseval帧均衡器（PFE），这是一种零样本、基于帧的语义信道均衡器，它无需系统再训练即可对齐异构编码器的潜在空间。PFE支持动态信号压缩和扩展，以减轻语义噪声并保持下游任务的性能。在此基础上，本文引入了一种动态优化策略，协调通信、计算和学习资源，以在多智能体语义通信场景中平衡能耗、端到端（E2E）延迟和任务性能。

**Result:** 广泛的仿真结果证实了该方法在多样化和时变网络条件下，保持语义一致性并满足延迟和精度长期约束的有效性。

**Conclusion:** 本文提出的Parseval帧均衡器（PFE）能够有效解决AI原生通信中语义信道噪声导致的潜在空间不匹配问题，通过动态优化策略在多智能体场景中平衡系统性能、能耗和延迟。

> **ai_Abstract:** 该论文针对AI原生通信中因DNN编码器潜在空间不匹配导致的语义信道噪声问题，提出了一种零样本的基于帧的语义信道均衡器——Parseval帧均衡器（PFE）。PFE无需再训练即可对齐异构编码器的潜在空间，并通过动态信号压缩与扩展来减轻语义噪声。此外，论文还引入了一种动态优化策略，用于在多智能体语义通信场景中平衡能耗、延迟和任务性能。仿真结果验证了该方法在复杂网络条件下保持语义一致性和满足系统约束的有效性。

> **摘要翻译:** 在未来的AI原生无线网络中，独立设计和训练的深度神经网络（DNN）编码器之间潜在空间的不匹配可能会阻碍相互理解，因为语义信道噪声的出现。这削弱了接收器解释传输表示的能力，从而降低了整体系统性能。为了解决这个问题，我们提出了Parseval帧均衡器（PFE），一个零样本、基于帧的语义信道均衡器，它无需系统再训练即可对齐异构编码器的潜在空间。PFE能够实现动态信号压缩和扩展，减轻语义噪声，同时保持下游任务的性能。在此基础上，我们引入了一种动态优化策略，协调通信、计算和学习资源，以在多智能体语义通信场景中平衡能耗、端到端（E2E）延迟和任务性能。广泛的仿真证实了我们方法在多样化和时变网络条件下，保持语义一致性并满足延迟和精度长期约束的有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [277] [Talk with the Things: Integrating LLMs into IoT Networks](https://arxiv.org/abs/2507.17865)
> *与物对话：将大型语言模型集成到物联网网络中*

*Alakesh Kalita* | **Category: cs.NI** | **Updated: 2025-07-23**

**Keywords:** LLMs, IoT, 边缘计算, 自然语言处理, 智能家居

**Comment:** arXiv admin note: text overlap with arXiv:2407.20970

> **TL;DR:** 该研究提出了一个将LLM集成到物联网边缘网络的框架，实现了自然语言控制，降低了延迟并提升了隐私性，并通过智能家居原型进行了验证。

**AI_Comments:** 该论文的创新之处在于提出了一个以边缘为中心的框架，将大型语言模型直接集成到物联网网络中，这对于实现低延迟、保护隐私和智能化的物联网系统至关重要。在边缘设备上使用基于RAG的LLM是迈向实际部署的重要一步。通过智能家居原型进行的验证为其适用性提供了具体证据。对权衡和挑战的讨论体现了实用和现实的视角。

<details>
  <summary>Details</summary>

**Motivation:** 将大型语言模型（LLMs）与物联网（IoT）网络结合，为构建智能、响应迅速且用户友好的系统带来了新的机遇。

**Method:** 本文提出了一个以边缘为中心的框架，将LLMs集成到物联网架构中，以实现基于自然语言的控制、上下文感知决策和增强自动化。所提出的模块化、轻量级、基于检索增强生成（RAG）的LLMs部署在连接到物联网网关的边缘计算设备上，从而实现用户命令和传感器数据的本地处理，以减少延迟、提高隐私性和增强推理质量。

**Result:** 研究通过一个使用LLaMA 3和Gemma 2B模型控制智能设备的智能家居原型验证了该框架。实验结果强调了模型精度和推理时间之间与模型大小相关的权衡。

**Conclusion:** 最后，论文还讨论了基于LLM的物联网系统的潜在应用，以及与此类系统相关的一些关键挑战。

> **ai_Abstract:** 本文提出一个将轻量级RAG-based LLM集成到物联网网络的边缘中心框架，以实现自然语言控制和增强自动化。该框架部署在边缘设备上，旨在降低延迟、提高隐私并增强推理质量。通过智能家居原型验证了该框架的有效性，并揭示了模型大小、准确性和推理时间之间的权衡，同时探讨了潜在应用和挑战。

> **摘要翻译:** 大型语言模型（LLMs）与物联网（IoT）网络的融合为构建智能、响应迅速且用户友好的系统开辟了新的机遇。这项工作提出了一个以边缘为中心的框架，将LLMs集成到物联网架构中，以实现基于自然语言的控制、上下文感知决策和增强自动化。所提出的模块化、轻量级、基于检索增强生成（RAG）的LLMs部署在连接到物联网网关的边缘计算设备上，从而实现用户命令和传感器数据的本地处理，以减少延迟、提高隐私性和增强推理质量。我们通过一个使用LLaMA 3和Gemma 2B模型控制智能设备的智能家居原型验证了该框架。实验结果强调了模型精度和推理时间之间与模型大小相关的权衡。最后，我们还讨论了基于LLM的物联网系统的潜在应用，以及与此类系统相关的一些关键挑战。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [314] [Enabling Scalability in Asynchronous and Bidirectional Communication in LPWAN](https://arxiv.org/abs/2507.17905)
> *在LPWAN中实现异步和双向通信的可扩展性*

*Mahbubur Rahman* | **Category: cs.NI, cs.DC** | **Updated: 2025-07-23**

**Keywords:** LPWAN, 可扩展性, 异步通信, 双向通信, SNOW, D-OFDM

**Comment:** 12 pages

> **TL;DR:** 通过改进SNOW技术并引入基于Gold码的PN序列，本研究显著提升了LPWAN在异步和双向通信中的可扩展性，实现了9倍的性能提升。

**AI_Comments:** 本文的创新点在于通过引入基于Gold码的PN序列，实现了在同一子载波上对多传感器数据进行并发编码和解码，极大地提升了LPWAN的频谱效率和可扩展性。这种方法有效解决了大规模物联网部署中异步通信的挑战，对于需要大量传感器且对电池寿命和实时性有较高要求的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LPWAN技术难以在低延迟下实现大规模传感器的高效数据传输，这阻碍了新兴IoT和CPS应用的发展。

**Method:** 本文通过显著改进LPWAN技术SNOW来解决上述挑战。SNOW利用分布式正交频分复用（D-OFDM）子载波使基站能够并行接收来自多个异步传感器的数据。为实现大规模可扩展性，研究人员开发了一套基于Gold码的伪随机噪声（PN）序列，这些序列在子载波内部和之间互不干扰，使每个传感器能使用其PN序列对数据进行编码或解码，从而实现大规模并发。

**Result:** 评估结果表明，SNOW的可扩展性提高了约9倍，同时基站的数据收集及时，传感器能效高。

**Conclusion:** 这项工作可能支持需要数万个传感器、电池寿命更长并能做出数据驱动、时间敏感决策的新兴物联网和CPS应用。

> **ai_Abstract:** 本文针对低功耗广域网（LPWAN）在实现大规模、低延迟传感器连接方面的挑战，提出了一种改进的SNOW技术。通过利用D-OFDM子载波和开发基于Gold码的互不干扰的伪随机噪声（PN）序列，该研究使基站能够并发处理来自同一或不同子载波上多个异步传感器的数据，并支持传感器在同一子载波上并行接收不同数据。实验结果显示，SNOW的可扩展性提高了约9倍，同时保持了数据收集的及时性和传感器的能效，为新兴物联网和网络物理系统应用提供了支持。

> **摘要翻译:** 低功耗广域网（LPWAN）因其能够在一个跳点内连接大地理区域的传感器而变得无处不在。然而，在LPWAN中实现大规模可扩展性非常具有挑战性，即大量传感器能够高效、低延迟地传输数据，而新兴的物联网（IoT）和网络物理系统（CPS）应用可能需要这一点。在本文中，我们通过显著改进一种名为SNOW的LPWAN技术来解决上述挑战。SNOW利用分布式正交频分复用（D-OFDM）子载波，使基站能够并行接收来自多个异步传感器的数据，每个传感器使用不同的子载波。在本文中，我们通过使基站能够解码来自同一子载波上大量异步传感器的并发数据，同时并行解码其他子载波上的数据，从而在SNOW中实现了大规模可扩展性。此外，我们还使大量异步传感器能够在同一子载波上接收来自基站的不同数据，同时其他传感器也能在其他子载波上并行接收数据。为此，我们开发了一套基于Gold码的伪随机噪声（PN）序列，这些序列在子载波内部和之间互不干扰。每个传感器使用其自身的PN序列对子载波上的数据进行编码或解码，从而实现大规模并发。我们的评估结果表明，我们可以在SNOW中实现大约9倍的可扩展性，同时基站的数据收集及时，传感器能效高。这可能使需要数万个传感器、电池寿命更长并能做出数据驱动、时间敏感决策的新兴物联网和CPS应用成为可能。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [349] [Enhanced Velocity-Adaptive Scheme: Joint Fair Access and Age of Information Optimization in Vehicular Networks](https://arxiv.org/abs/2507.18328)
> *增强的速度自适应方案：车载网络中联合公平接入与信息年龄优化*

*Xiao Xu, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief* | **Category: cs.NI** | **Updated: 2025-07-24**

**Keywords:** 公平接入, 信息年龄, 车载网络, 5G NR, 半持久调度

**Comment:** This paper has been submitted to IEEE TMC

> **TL;DR:** 本文提出了一种增强的速度自适应方案，通过调整SPS选择窗口，在车载网络中联合优化公平接入和信息年龄（AoI），并使用基于LLM的MOEA/D算法求解。

**AI_Comments:** 该论文的创新点在于首次在5G NR V2I Mode 2环境下，同时考虑了公平接入和信息年龄（AoI）的联合优化问题。其方法结合了随机混合系统（SHS）建模和基于LLM的MOEA/D算法，为解决复杂的车载通信资源分配问题提供了新颖的思路。特别是引入LLM来辅助进化算法解决多目标优化问题，是一个值得关注的探索方向。

<details>
  <summary>Details</summary>

**Motivation:** 在5G NR V2I Mode 2车载网络中，车辆速度差异导致RSU驻留时间不同，造成网络资源接入不公平，影响驾驶安全。同时，为确保数据新鲜度，需要分析信息年龄（AoI）。Mode 2的抢占机制要求同时优化公平接入和AoI，以保证及时且相关的数据传输。

**Method:** 提出一个联合优化框架，定义公平性指标，并使用随机混合系统（SHS）建模抢占机制下的AoI。通过自适应调整Mode 2中半持久调度（SPS）的选择窗口来解决公平性和AoI的优化问题。使用基于大型语言模型（LLM）的基于分解的多目标进化算法（MOEA/D）来解决该问题。

**Result:** 仿真结果表明，该方案在平衡公平接入和最小化AoI方面是有效的。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对5G NR V2I Mode 2车载网络中车辆速度差异导致的公平接入问题和信息年龄（AoI）问题，提出了一种增强的速度自适应方案。该方案旨在联合优化公平接入和AoI，通过定义公平性指标并使用随机混合系统（SHS）建模AoI。通过自适应调整半持久调度（SPS）的选择窗口来实现优化，并利用基于大型语言模型（LLM）的MOEA/D算法求解。仿真结果验证了该方案在平衡公平接入和最小化AoI方面的有效性。

> **摘要翻译:** 本文研究了5G新空口（NR）车-基础设施（V2I）模式2车载网络中的公平接入问题和信息年龄（AoI）问题。具体而言，车辆遵循模式2与路边单元（RSU）通信，以获取准确数据用于驾驶辅助。然而，车辆在相邻车道行驶时通常速度不同，导致RSU驻留时间和通信持续时间存在差异。这导致网络资源接入不公平，可能影响驾驶安全。为确保接收数据的新鲜度，需要分析AoI。模式2引入了一种新的抢占机制，这需要同时优化公平接入和AoI，以保证及时和相关的数据传输。我们提出了一种车载网络联合优化框架，定义了公平性指标，并采用随机混合系统（SHS）建模抢占机制下的AoI。通过自适应调整模式2中半持久调度（SPS）的选择窗口，我们解决了公平性和AoI的优化问题。我们应用基于大型语言模型（LLM）的基于分解的多目标进化算法（MOEA/D）来解决这个问题。仿真结果表明，我们的方案在平衡公平接入和最小化AoI方面是有效的。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [391] [Improving Wi-Fi 8 Latency with Coordinated Spatial Reuse](https://arxiv.org/abs/2507.18480)
> *通过协调空间复用改善 Wi-Fi 8 延迟*

*David Nunez, Francesc Wilhelmi, Lorenzo Galati-Giordano, Giovanni Geraci, Boris Bellalta* | **Category: cs.NI** | **Updated: 2025-07-24**

**Keywords:** Wi-Fi 8, 延迟, 协调空间复用, 频谱效率, 网络性能

**Comment:** Submitted to IEEE Communications Standards Magazine

> **TL;DR:** 本论文提出并评估了一种与 Wi-Fi 8 标准化工作兼容的协调空间复用 (Co-SR) 机制，旨在降低密集 Wi-Fi 环境中的延迟，并在模拟中显示出显著的延迟降低。

**AI_Comments:** 这篇论文探讨了协调空间复用 (Co-SR) 在改善 Wi-Fi 8 网络延迟方面的潜力，特别是在满足云游戏和 XR 等新兴应用需求方面。其创新之处在于提出了与 Wi-Fi 8 标准化工作对齐的 Co-SR 实现，并通过模拟验证了其有效性。结果显示出显著的延迟降低，这对于提高用户体验和网络效率至关重要。该研究为 Wi-Fi 技术的未来发展提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 为了满足云游戏、扩展现实 (XR) 和视频流等新兴应用对高吞吐量、低延迟和高可靠性的严格要求，IEEE 802.11 网络需要持续适应。协调空间复用 (Co-SR) 有潜力优化频谱资源利用，实现同时传输，从而提高密集环境中的频谱效率和整体网络性能，以解决这些挑战。

**Method:** 本文提出了一种与正在进行的 Wi-Fi 8 标准化工作相符的协调空间复用 (Co-SR) 实现方案。该方案在 Wi-Fi 模拟器上进行评估，以研究其在相关场景下的性能。

**Result:** 在由四个 AP 组成的无线局域网 (WLAN) 中进行的评估结果显示，与分布式协调功能 (DCF) 相比，Co-SR 将延迟降低了 31% 到 95%。

**Conclusion:** 协调空间复用 (Co-SR) 是一种有效的机制，能够显著降低 Wi-Fi 8 网络中的延迟，从而满足新兴应用的需求并提高整体网络性能。

> **ai_Abstract:** 本文研究了协调空间复用 (Co-SR) 在 Wi-Fi 8 网络中改善延迟的性能。作者提出了一种与 Wi-Fi 8 标准化工作一致的 Co-SR 实现方案，并通过 Wi-Fi 模拟器进行评估。结果表明，在包含四个 AP 的 WLAN 环境中，与传统分布式协调功能相比，Co-SR 能够将延迟显著降低 31% 至 95%，证明了其在满足新兴应用低延迟需求方面的潜力。

> **摘要翻译:** IEEE 802.11 网络不断适应，以满足云游戏、扩展现实 (XR) 和视频流服务等新兴应用的严格要求，这些应用需要高吞吐量、低延迟和高可靠性。为了应对这些挑战，协调空间复用 (Co-SR) 有潜力促进频谱资源利用的优化。预计该机制能够实现同时传输，从而提高密集环境中的频谱效率并提升整体网络性能。在本文中，我们阐明了 Co-SR 在 Wi-Fi 8 网络中的性能。为此，我们提出了一种与正在进行的 Wi-Fi 8 标准化工作相符的 Co-SR 实现方案。评估是在 Wi-Fi 模拟器上进行的，这使我们能够研究所提出的 Co-SR 机制在相关场景下的性能。在由四个 AP 组成的无线局域网 (WLAN) 中获得的结果显示，与分布式协调功能 (DCF) 相比，Co-SR 将延迟降低了 31% 到 95%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [481] [IEEE 802.11be Wi-Fi 7: Feature Summary and Performance Evaluation](https://arxiv.org/abs/2309.15951)
> *IEEE 802.11be Wi-Fi 7：特性总结与性能评估*

*Xiaoqian Liu, Yuhan Dong, Yiqing Li, Yousi Lin, Ming Gan* | **Category: cs.NI, eess.SP** | **Updated: 2025-07-24**

**Keywords:** Wi-Fi 7, IEEE 802.11be, EHT, 吞吐量, 延迟

**Comment:** 

> **TL;DR:** Wi-Fi 7（IEEE 802.11be）是为满足4K/8K视频和VR/AR等高吞吐量、低延迟应用需求而推出的新标准。本文介绍了其主要目标、关键技术，并通过系统级仿真验证了其最高可达30 Gbps的吞吐量和更低的延迟。

**AI_Comments:** 这篇论文及时地总结了Wi-Fi 7的关键特性和性能，对于理解新一代无线局域网标准具有重要意义。其创新之处在于系统级仿真验证了Wi-Fi 7在吞吐量和延迟方面的显著提升，这对于推动相关应用的发展具有指导价值。论文的贡献在于为读者提供了Wi-Fi 7的全面概览，并证实了其满足未来高带宽、低延迟应用需求的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 新兴应用对吞吐量和延迟提出了更高的要求，例如4K/8K视频需要数十Gbps的吞吐量，虚拟现实（VR）和增强现实（AR）等视频应用需要低延迟。IEEE 802.11be (Wi-Fi 7) 标准旨在满足这些需求。

**Method:** 本文首先介绍了Wi-Fi 7的主要目标和时间线，然后列出了提升Wi-Fi 7性能的最新关键技术。最后，通过系统级仿真验证了Wi-Fi 7最关键的目标——潜在的最高30 Gbps吞吐量和更低的延迟。

**Result:** 系统级仿真结果表明，通过结合新引入的技术，Wi-Fi 7能够实现30 Gbps的吞吐量，并达到比Wi-Fi 6更低的延迟。

**Conclusion:** Wi-Fi 7通过引入新特性和技术，成功地实现了高达30 Gbps的吞吐量和更低的延迟，从而满足了新兴应用日益增长的需求，并为Wi-Fi带来了革命性的变革。

> **ai_Abstract:** 本文概述了IEEE 802.11be (Wi-Fi 7) 标准，该标准于2025年发布，旨在满足4K/8K视频和VR/AR等新兴应用对超高吞吐量和低延迟的需求。文章介绍了Wi-Fi 7的主要目标、时间线及其关键技术，并通过系统级仿真验证了其最高可达30 Gbps的吞吐量和优于Wi-Fi 6的低延迟性能，预示着Wi-Fi技术的重大进步。

> **摘要翻译:** 随着新兴应用对吞吐量需求的不断提高，IEEE 802.11be——极高吞吐量（EHT）标准，也被称为Wi-Fi 7，已于2025年7月22日发布。它可用于满足4K/8K视频高达数十Gbps的吞吐量需求以及虚拟现实（VR）和增强现实（AR）等低延迟视频应用的需求。Wi-Fi 7不仅将Wi-Fi 6的带宽翻倍，还支持实时应用，这为Wi-Fi带来了革命性的变化。在本文中，我们首先介绍了Wi-Fi 7的主要目标和时间线，然后列出了提升Wi-Fi 7性能的最新关键技术。最后，我们验证了Wi-Fi 7最关键的目标——潜在的最高30 Gbps吞吐量和更低的延迟。系统级仿真结果表明，通过结合新技术，Wi-Fi 7实现了30 Gbps的吞吐量，并达到了比Wi-Fi 6更低的延迟。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [529] [UAV Communications: Impact of Obstacles on Channel Characteristics](https://arxiv.org/abs/2412.17934)
> *无人机通信：障碍物对信道特性的影响*

*Kamal Shayegan* | **Category: cs.NI, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 无人机通信, 障碍物, 信道特性, 空对地信道, 定位优化

**Comment:** 

> **TL;DR:** 本文研究了障碍物对无人机（UAV）通信信道特性的影响，并提出了一种考虑障碍物的模拟测量方法，以优化无人机定位，从而改善无线网络性能。

**AI_Comments:** 这篇论文通过引入障碍物对空对地信道特性的影响，为无人机通信的优化定位提供了一个新颖的视角。其创新点在于将实际环境中的障碍物因素纳入信道表征和定位算法中，这对于提高未来高频无人机网络的可靠性和服务质量至关重要。研究结果通过关键性能指标的比较，验证了考虑障碍物的定位方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 随着下一代无线通信向更高频率发展，障碍物对信号的阻碍变得更加突出。为了确保无人机与用户设备之间的视距（LoS）、提高服务质量（QoS）并建立最大覆盖范围的可靠无线链路，在无人机部署时必须考虑障碍物的影响。

**Method:** 本文提出了一种基于仿真的测量方法，用于在简单场景中表征空对地（AG）信道，并在此过程中考虑了障碍物。

**Result:** 结果比较了使用所提出的定位方法在吞吐量、数据包传输、数据包丢失和延迟方面的表现。

**Conclusion:** 通过将障碍物整合到无人机放置算法中，可以有效改善无线网络的吞吐量、数据包传输、减少数据包丢失和延迟，从而提高服务质量并建立可靠的无线链路。

> **ai_Abstract:** 本文探讨了障碍物对无人机通信信道特性的影响。鉴于未来无线通信将使用易受阻碍的高频，研究强调了在无人机放置算法中整合障碍物的重要性，以确保视距、提升服务质量和最大化覆盖。文章提出了一种基于仿真的空对地信道测量方法，该方法考虑了障碍物，并比较了所提定位方法在吞吐量、数据包传输、数据包丢失和延迟方面的性能。

> **摘要翻译:** 近年来，无人机（UAV）已被用作携带Wi-Fi接入点（AP）和蜂窝基站（BS）的有效平台，实现了低成本、敏捷、灵活且具有高质量服务（QoS）的无线网络。下一代无线通信将依赖于越来越高的频率，这些频率很容易受到障碍物的阻碍。一个尚未完全解决的最关键概念是，在考虑障碍物的情况下，将无人机定位在最佳坐标处。为了确保无人机和用户设备（UE）之间的视距（LoS），提高QoS，并建立具有最大覆盖范围的可靠无线链路，必须将障碍物整合到所提出的放置算法中。本文介绍了一种基于仿真的测量方法，用于在简单场景中表征空对地（AG）信道。通过考虑障碍物，我们提出了信道表征的新颖视角。结果在吞吐量、数据包传输、数据包丢失和延迟方面，使用所提出的定位方法进行了比较。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [696] [ARCADE: A RAN Diagnosis Methodology in a Hybrid AI Environment for 6G Networks](https://arxiv.org/abs/2507.17861)
> *ARCADE：6G网络中混合AI环境下的RAN诊断方法*

*Daniel Ricardo Cunha Oliveira, Rodrigo Moreira, Flávio de Oliveira Silva* | **Category: cs.NI, cs.ET** | **Updated: 2025-07-23**

**Keywords:** 6G网络, RAN诊断, 混合AI, 网络自动化, 异常检测

**Comment:** 

> **TL;DR:** ARCADE是一种用于6G网络蜂窝接入网异常检测和诊断的方法，展示了混合AI架构如何增强AI应用。

**AI_Comments:** 该论文提出了一种针对6G网络RAN诊断的特定方法ARCADE，创新性在于其混合AI环境的应用，这对于6G网络中实现更高程度的自动化和AI应用具有重要意义。它弥补了现有5G规范中NWDAF的不足，并为未来6G网络的智能化运维提供了实践案例。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在6G网络开发中扮演关键角色。现有网络数据分析功能（NWDAF）虽能提供核心信息，但不足以实现5G中尚未充分探索的网络段的自动化，因此需要更全面的方法来支持6G网络的自动化。

**Method:** 本文提出了ARCADE（自动化无线覆盖异常检测与评估），一种用于识别和诊断蜂窝接入网络异常的方法。此外，还展示了在向6G演进过程中，网络分析功能的混合架构如何利用ARCADE来增强AI在更广泛网络环境中的应用。

**Result:** 论文展示了ARCADE作为一种实用方法，如何在一个更广泛的网络环境中，通过向6G演进的混合网络分析功能架构，增强人工智能的应用。

**Conclusion:** ARCADE是一种有效的蜂窝接入网络异常诊断方法，并且混合AI架构能够增强AI在6G网络中的应用。

> **ai_Abstract:** 本文提出了ARCADE，一种针对6G网络中蜂窝接入网的异常检测和诊断方法。鉴于AI在6G中的关键作用以及现有NWDAF的局限性，ARCADE旨在实现未充分探索的网络段的自动化。论文还展示了混合网络分析功能架构如何利用ARCADE增强AI在更广泛网络环境中的应用。

> **摘要翻译:** 人工智能（AI）在6G网络开发中发挥着关键作用。虽然目前的规范已经将网络数据分析功能（NWDAF）作为负责提供核心信息的网络元素，但需要一种更全面的方法来实现尚未在5G背景下充分探索的网络段的自动化。在本文中，我们提出了自动化无线覆盖异常检测与评估（ARCADE），这是一种用于识别和诊断蜂窝接入网络中异常的方法。此外，我们以ARCADE作为这种方法的实际示例，展示了向6G演进过程中网络分析功能的混合架构如何在一个更广泛的网络背景下增强AI的应用。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [79] [Asymptotically Minimax Regret by Bayes Mixtures](https://arxiv.org/abs/2406.17929)
> *渐近最小最大遗憾的贝叶斯混合*

*Jun'ichi Takeuchi, Andrew R. Barron* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 贝叶斯混合, 最小最大遗憾, Jeffreys先验, 数据压缩, 随机复杂度

**Comment:** 

> **TL;DR:** 本文研究了在数据压缩、赌博和序列预测问题中，贝叶斯混合分布相对于最大似然估计的遗憾值，并发现使用Jeffreys先验的变体可以达到渐近最小最大遗憾。

**AI_Comments:** 这篇论文在信息理论和统计推断领域具有重要意义。其创新之处在于将贝叶斯混合方法应用于实现渐近最小最大遗憾，并提出了Jeffreys先验的修改形式以适应更广泛的非指数族分布。通过局部指数倾斜扩展密度族的概念，为处理复杂模型提供了新的视角。此外，与Rissanen随机复杂度的关联也增加了其理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在研究在数据压缩、赌博和序列预测等问题中，贝叶斯混合分布的遗憾值表现，并寻找实现渐近最小最大遗憾的方法。

**Method:** 通过比较贝叶斯混合分布与最大似然估计的遗憾值，并在最大似然估计位于参数空间内部的条件下进行评估。对于一般指数族，使用Jeffreys先验的变体；对于非指数族，则提出了一种Jeffreys先验的修改形式，通过局部指数倾斜扩展了密度族。

**Result:** 在最大似然估计位于参数空间内部的条件下，对于一般指数族（包括非i.i.d.情况），使用Jeffreys先验的变体可以达到渐近最小最大遗憾值。对于非指数族，通过修改Jeffreys先验（该修改在给定密度族之外，通过局部指数倾斜扩展了族），也能实现最小最大遗憾。这些条件在某些非指数族（包括曲线族、混合族和污染模型）中得到了证实。对于混合族，论文展示了如何处理完整的参数单纯形。这些结果也提供了对Rissanen随机复杂度的刻画。

**Conclusion:** 本文证明了在数据压缩、赌博和序列预测问题中，通过使用Jeffreys先验的变体或其修改形式，贝叶斯混合分布能够达到渐近最小最大遗憾，并对Rissanen的随机复杂度进行了刻画。

> **ai_Abstract:** 本文研究了数据压缩、赌博和序列预测问题中的遗憾值，重点比较了贝叶斯混合分布与最大似然估计。研究发现，在最大似然估计位于参数空间内部的条件下，对于一般指数族，使用Jeffreys先验的变体可实现渐近最小最大遗憾；对于非指数族，通过对Jeffreys先验进行修改（引入局部指数倾斜）也能达到相同的目标。这些结果适用于多种非指数族，并有助于刻画Rissanen的随机复杂度。

> **摘要翻译:** 我们研究了从字母表${\cal X}$中提取的序列$x^n=x_1x_2...x_n$的数据压缩、赌博和预测问题，关注其相对于各种平滑概率分布族的遗憾值和预期遗憾值（冗余）。我们评估了贝叶斯混合分布相对于最大似然的遗憾值，条件是最大似然估计位于参数空间的内部。对于一般指数族（包括非独立同分布情况），当使用Jeffreys先验的变体时，可以达到渐近最小最大值。有趣的是，我们还获得了Jeffreys先验的一种修改形式，其测度位于给定密度族之外，以实现相对于非指数型族的最小最大遗憾。这种修改通过局部指数倾斜（一种纤维丛）扩大了族。我们的条件在某些非指数族中得到了证实，包括曲线族和混合族（其中混合分量或其组合权重是参数化的）以及污染模型。此外，对于混合族，我们展示了如何处理完整的参数单纯形。这些结果也提供了对Rissanen随机复杂度的刻画。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [119] [Polarization Aware Movable Antenna](https://arxiv.org/abs/2411.06690)
> *极化感知可移动天线*

*Runxin Zhang, Yulin Shao, Yonina C. Eldar* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 极化感知, 可移动天线, 极化匹配, 毫米波, 无线通信

**Comment:** 

> **TL;DR:** 本文提出了一个极化感知可移动天线 (PAMA) 框架，将极化效应整合到可移动天线的优化中，通过考虑极化匹配来扩展其应用范围并提升无线通信性能。

**AI_Comments:** 该论文的创新之处在于将极化效应引入到可移动天线的设计和优化中，突破了传统MA研究仅关注相位变化的局限。通过引入极化感知信道模型，揭示了MA在优化极化匹配方面的独特优势，并成功将MA的应用扩展到毫米波等高频段，即使在单一直线视距路径下也能发挥作用。这对于提升未来无线网络的效率和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可移动天线 (MA) 研究主要关注由不同传播路径引起的相位变化，并通过天线移动来最大化信道增益。这种狭隘的关注限制了MA的全部潜力，未能充分利用其优化极化匹配的能力。

**Method:** 本文提出了一个极化感知可移动天线 (PAMA) 框架。该框架将极化效应整合到可移动天线 (MA) 的设计和优化中，并引入了一个基于电磁理论的极化感知信道模型，以优化极化匹配。

**Result:** 研究结果表明，将极化考虑纳入可移动天线显著提高了效率、链路可靠性和数据吞吐量。PAMA 能够将MA的应用范围从射频、多径丰富场景扩展到更高频段（如毫米波），即使在单一直线视距 (LOS) 径下也有效。

**Conclusion:** 将极化因素纳入可移动天线的设计和优化中，能够显著提升无线通信的性能，尤其是在高频段和单一直线视距场景下，为未来更鲁棒和高效的无线网络铺平了道路。

> **ai_Abstract:** 本文提出了一个极化感知可移动天线（PAMA）框架，旨在通过整合极化效应来克服现有可移动天线（MA）研究的局限性。通过引入基于电磁理论的极化感知信道模型，PAMA揭示了MA在优化极化匹配方面的独特优势。这项工作将MA的应用扩展到毫米波等高频段，即使在单一视距路径下也能有效工作。研究表明，考虑极化因素显著提升了MA的效率、链路可靠性和数据吞吐量，为未来无线网络的发展奠定了基础。

> **摘要翻译:** 本文提出了一种极化感知可移动天线（PAMA）框架，该框架将极化效应整合到可移动天线（MA）的设计和优化中。虽然MA已被证明在提升无线通信性能方面有效，但现有研究主要集中于由不同传播路径引起的相位变化，并利用天线移动来最大化信道增益。这种狭隘的关注限制了MA的全部潜力。在这项工作中，我们引入了一个植根于电磁理论的极化感知信道模型，揭示了MA相对于其他无线技术（如预编码）的一个决定性优势：优化极化匹配的能力。这种新理解使PAMA能够将MA的适用性从射频、多径丰富场景扩展到更高频段，例如毫米波，即使在单一视距（LOS）路径下也能实现。我们的研究结果表明，将极化考虑纳入MA显著增强了效率、链路可靠性和数据吞吐量，为未来更鲁棒和高效的无线网络铺平了道路。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [159] [Integrated Sensing and Edge AI: Realizing Intelligent Perception in 6G](https://arxiv.org/abs/2501.06726)
> *融合感知与边缘AI：在6G中实现智能感知*

*Zhiyan Liu, Xu Chen, Hai Wu, Zhanwei Wang, Xianhao Chen, Dusit Niyato, Kaibin Huang* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 6G, 融合感知, 边缘AI, 智能感知, ISEA

**Comment:** To appear in IEEE Communications Surveys and Tutorials

> **TL;DR:** 本文对6G中融合感知与边缘AI（ISEA）进行了全面综述，介绍了其技术基础、用例、设计原则、技术和未来研究方向。

**AI_Comments:** 这篇综述论文及时地总结了6G网络中融合感知与边缘AI（ISEA）这一关键交叉领域。其创新之处在于提出了ISEA这一任务导向的整体设计范式，超越了传统单一功能的研究。论文涵盖了从技术基础到用例、设计原则、具体技术及未来展望的全面内容，对于理解和推动6G智能感知的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 感知和边缘人工智能（AI）被设想为第六代（6G）移动网络中两个基本且相互关联的功能。感知赋能的应用依赖强大的AI模型处理无线传感器数据，而海量感知数据又为边缘AI模型提供训练燃料。这种深度融合催生了融合感知与边缘AI（ISEA）这一新的任务导向范式，旨在通过对通信、AI计算和感知进行整体设计，以实现最佳的感知任务性能。

**Method:** 本文对融合感知与边缘AI（ISEA）进行了全面综述。首先提供了ISEA中感知、边缘AI和新型通信范式的技术基础。然后研究了ISEA的几个用例，介绍了当前的标准化和产业进展。接下来，确立了ISEA的设计原则、指标、权衡和架构，并全面概述了ISEA技术，包括数字空口、空口计算和先进信号处理。最后，提出了ISEA未来的研究机会。

**Result:** 本文全面概述了ISEA的技术基础、用例、设计原则、指标、权衡、架构以及关键技术（如数字空口、空口计算、先进信号处理），并探讨了其与6G其他进展的相互作用。

**Conclusion:** ISEA是6G中实现智能感知的关键范式，未来的研究机会包括与基础模型的集成、ISEA与ISAC的融合、超低延迟ISEA以及实用性问题。

> **ai_Abstract:** 本文对6G网络中新兴的融合感知与边缘AI（ISEA）范式进行了全面综述。ISEA旨在通过整体设计通信、AI计算和感知，优化感知任务性能。文章详细阐述了ISEA的技术基础、实际用例、设计原则、关键技术以及与6G其他进展的协同作用，并展望了未来的研究方向，如与基础模型、ISAC的融合以及超低延迟和实用性挑战。

> **摘要翻译:** 感知和边缘人工智能（AI）被设想为第六代（6G）移动网络中两个基本且相互关联的功能。一方面，感知赋能的应用依赖于强大的AI模型从无处不在的无线传感器中提取特征并理解语义。另一方面，大量的感知数据作为燃料，不断完善边缘AI模型。这种感知与边缘AI的深度融合催生了一种新的任务导向范式，称为融合感知与边缘AI（ISEA），其特点是对通信、AI计算和感知采用整体设计方法，以实现最佳的感知任务性能。在本文中，我们对ISEA进行了全面综述。我们首先提供了ISEA中感知、边缘AI和新型通信范式的技术基础。然后，我们研究了ISEA的几个用例，以展示其实际相关性，并介绍了当前的标准化和产业进展。接下来，确立了ISEA的设计原则、指标、权衡和架构，随后全面概述了ISEA技术，包括数字空口、空口计算和先进信号处理。还介绍了其与各种6G进步的相互作用，例如新的物理层和网络技术。最后，我们提出了ISEA未来的研究机会，包括基础模型的集成、ISEA与融合感知与通信（ISAC）的融合、超低延迟ISEA以及实用性问题。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [199] [Dual-Domain Exponent of Maximum Mutual Information Decoding](https://arxiv.org/abs/2501.13724)
> *最大互信息解码的双域指数*

*AmirPouya Moeini, Albert Guillén i Fàbregas* | **Category: cs.IT, math.IT, math.PR** | **Updated: 2025-07-24**

**Keywords:** 最大互信息解码, 错误指数, 双域推导, 联合源信道编码, 最大似然解码

**Comment:** This paper is scheduled to be presented at IEEE ITW 2025, Sydney,
  Australia

> **TL;DR:** 本文通过双域推导证明了MMI解码的错误指数与ML解码在离散无记忆信道上相同，并将其扩展到联合源信道编码，表明广义MMI解码器与MAP解码器具有相同的随机编码错误指数。

**AI_Comments:** 这篇论文的创新点在于提出了MMI解码错误指数的双域推导，并揭示了MMI解码在理论上与ML和MAP解码在错误指数性能上的等效性。这对于理解MMI解码的性能极限及其在通信系统中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机是深入理解最大互信息（MMI）解码的错误指数特性，并将其与最大似然（ML）解码和最大后验（MAP）解码进行比较，尤其是在双域和联合源信道编码的背景下。

**Method:** 本文采用双域推导方法来分析最大互信息（MMI）解码与恒定组成码的错误指数。此外，该分析还扩展到联合源信道编码场景。

**Result:** 结果表明，在离散无记忆信道下，最大互信息（MMI）解码的错误指数与最大似然（ML）解码的错误指数一致。进一步的分析显示，在联合源信道编码中，广义MMI解码器能够达到与最大后验（MAP）解码器相同的随机编码错误指数。

**Conclusion:** 最大互信息（MMI）解码在错误指数性能上与最大似然（ML）解码和最大后验（MAP）解码具有等效性，这表明MMI解码在不同编码和信道条件下具有强大的理论基础和实用潜力。

> **ai_Abstract:** 本文通过双域推导，证明了使用恒定组成码的最大互信息（MMI）解码的错误指数与离散无记忆信道下的最大似然（ML）解码的错误指数相同。此外，研究还将此分析扩展到联合源信道编码，结果显示广义MMI解码器能达到与最大后验（MAP）解码器相同的随机编码错误指数。

> **摘要翻译:** 本文提供了最大互信息（MMI）解码在恒定组成码下的错误指数的双域推导，表明其与离散无记忆信道下的最大似然解码的错误指数一致。该分析进一步扩展到联合源信道编码，证明了广义MMI解码器实现了与最大后验解码器相同的随机编码错误指数。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [244] [Quantum Hypothesis Testing Lemma for Deterministic Identification over Quantum Channels](https://arxiv.org/abs/2504.20991)
> *量子信道确定性识别的量子假设检验引理*

*Pau Colomer, Christian Deppe, Holger Boche, Andreas Winter* | **Category: cs.IT, math.IT, quant-ph** | **Updated: 2025-07-24**

**Keywords:** 量子假设检验引理, 确定性识别, 量子信道, 容量下限, 闵可夫斯基维数

**Comment:** 7 pages, double column

> **TL;DR:** 该工作提出了量子假设检验引理的量子模拟，用以证明量子信道上确定性识别码的存在性，并提升了容量下限的紧致性。

**AI_Comments:** 这项工作创新性地将经典信息论中的假设检验引理推广到量子领域，为量子信道上的确定性识别码提供了坚实的理论基础和构造方法。通过将容量下限与闵可夫斯基维数关联，它不仅提供了更紧致的界限，还开辟了理解量子信息协议的新视角，对于量子通信和量子信息处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 之前的假设检验引理适用于有记忆信道，但缺乏一个完整的量子模拟来研究量子信道上的确定性识别码的存在性及其容量界限。

**Method:** 本文提出了经典假设检验引理的完整量子模拟，证明了量子设置下确定性识别（DI）码的存在性源于修改后的输出量子态空间中的适当填充。具体地，通过从该填充中导出的乘积态来构建编码。

**Result:** 该结果能够收紧量子信道上确定性识别（DI）的容量下限，超越了同步解码方法。特别是，这些界限现在可以完全用特定状态空间的闵可夫斯基维数来表示，从而提供了对协议性质以及同步和非同步码之间分离的新见解。此外，论文还通过一个特定的信道示例展示了最优码的构造。

**Conclusion:** 通过引入量子假设检验引理的量子模拟，该研究不仅为量子信道上的确定性识别码的存在性提供了理论基础，还显著改进了容量下限的表达和理解，揭示了新的协议洞察。

> **ai_Abstract:** 本文提出了经典假设检验引理的完整量子模拟，证明了在量子信道上确定性识别（DI）码的存在性可以通过修改后的输出量子态空间中的适当填充来实现，并可以通过乘积态构造。这项工作显著收紧了量子信道上DI的容量下限，并首次将其纯粹用闵可夫斯基维数表示，从而深入理解了量子DI协议的本质以及同步与非同步码的区别。

> **摘要翻译:** 在我们之前的工作中，我们提出了“假设检验引理”，这是一个关键工具，为具有有限输出但任意输入字母表的无记忆信道建立良好确定性识别（DI）码存在的充分条件。在这项工作中，我们提供了该引理的完整量子模拟，这表明量子设置中DI码的存在源于修改后的输出量子态空间中的适当填充。具体来说，我们证明了可以使用从这种填充中导出的乘积态来构造这样的码。这个结果使我们能够收紧量子信道上DI的容量下限，超越了同步解码方法。特别是，我们现在可以仅用某个状态空间的闵可夫斯基维数来表示这些界限，这为我们更好地理解协议的性质以及同步和非同步码之间的分离提供了新见解。我们通过一个特定的信道示例扩展了讨论，在该示例中我们可以构造一个最优码。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [284] [RDD Function: A Tradeoff Between Rate and Distortion-in-Distortion](https://arxiv.org/abs/2507.09712)
> *RDD 函数：速率与失真-失真之间的权衡*

*Lingyi Chen, Haoran Tang, Shitong Wu, Jiakun Liu, Huihui Wu, Wenyi Zhang, Hao Wu* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 速率失真函数, Gromov-Wasserstein距离, 交替镜像下降, 源编码, 失真-失真

**Comment:** 

> **TL;DR:** 本文提出了RDD函数，它是经典速率-失真函数的扩展，用Gromov型失真代替了期望失真约束，并开发了一种交替镜像下降算法来解决其计算复杂性，数值结果证明了其有效性。

**AI_Comments:** 本文的创新点在于提出了RDD函数，它将Gromov型失真引入速率失真理论，使其能够处理不同维度空间中的相似性问题，这在传统RD函数中是难以实现的。此外，为解决由Gromov型失真带来的高计算复杂性，开发了一种高效的交替镜像下降算法，这对于其实际应用至关重要。该研究为源编码领域提供了一个新的理论框架和计算工具，具有重要的理论和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了扩展经典的速率-失真 (RD) 函数，解决在不同维度空间中定义相似性的问题，其中传统的期望失真约束被Gromov型失真取代，以实现即使没有直接度量也能有效定义空间中的相似性。

**Method:** 提出了速率失真-失真 (RDD) 函数，将经典RD函数中的期望失真约束替换为Gromov型失真。为解决Gromov型失真带来的高计算复杂性，开发了一种交替镜像下降算法，该算法通过采用分解、线性化和松弛技术显著降低了计算复杂性。

**Result:** 在经典源和不同网格上的数值结果表明，所开发的交替镜像下降算法是有效的。

**Conclusion:** RDD函数作为一种信息RD函数和可操作的RD函数，在未来场景中可能具有潜在的应用，因为它能有效定义不同维度空间中的相似性。

> **ai_Abstract:** 本文提出了一种名为速率失真-失真 (RDD) 的新型函数，作为经典速率-失真 (RD) 函数的扩展。RDD函数用Gromov型失真取代了传统的期望失真约束，这使得即使在没有直接度量的不同维度空间中也能有效定义相似性。尽管RDD函数具有高计算复杂性，但编码定理证实了其作为可操作RD函数的地位。为解决计算难题，研究人员开发了一种基于分解、线性化和松弛技术的交替镜像下降算法，并数值验证了其在经典源上的有效性。研究表明，RDD函数在未来的源编码场景中具有潜在应用。

> **摘要翻译:** 在本文中，我们提出了一种新颖的函数，名为速率失真-失真 (RDD) 函数，作为经典速率-失真 (RD) 函数的扩展，其中期望失真约束被Gromov型失真取代。这种失真，作为Gromov-Wasserstein (GW) 距离的组成部分，即使在没有直接度量的情况下，也能有效地定义不同维度空间中的相似性。虽然RDD函数符合信息RD函数的条件，但编码定理证实了其作为可操作RD函数的地位，从而突出了其在实际源编码中的潜在适用性。由于Gromov型失真通常具有高计算复杂性，RDD函数通常无法进行解析评估。因此，我们开发了一种交替镜像下降算法，通过采用分解、线性化和松弛技术显著降低了计算复杂性。在经典源和不同网格上的数值结果证明了所开发算法的有效性。通过探索RDD函数与RD函数之间的关系，我们认为RDD函数在未来场景中可能具有潜在应用。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [329] [Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding](https://arxiv.org/abs/2507.17432)
> *间接Wyner-Ziv信源编码的非渐近可达率失真区域*

*Jiahui Wei, Philippe Mary, Elsa Dupraz* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** Wyner-Ziv编码, 率失真, 间接设置, 语义信息, Blahut-Arimoto算法

**Comment:** 8 pages, 2 figures, 3 pages' appendix

> **TL;DR:** 本文研究了间接Wyner-Ziv信源编码问题，其中解码器需要重建一个潜在的、未被观察到的源S。论文推导了渐近和有限块长下的可达区域，并提出了一个Blahut-Arimoto算法进行数值评估。

**AI_Comments:** 这项工作通过引入一个潜在源S，扩展了经典的Wyner-Ziv问题，使其更适用于面向目标的通信场景，特别是语义信息传输。其创新点在于推导了非渐近的可达率失真区域，并提出了一个实用的数值评估算法。

<details>
  <summary>Details</summary>

**Motivation:** 传统Wyner-Ziv编码中，解码器仅有旁信息Y。本文研究的间接Wyner-Ziv设置中，解码器还需要重建一个编码器和解码器均未观察到的潜在源S。这种场景在面向目标的通信中日益重要，其中S可以代表从X获得的语义信息。

**Method:** 本文推导了渐近体制下的间接Wyner-Ziv率失真函数，并提供了有限块长下的可达区域。此外，还提出了一种专门针对间接Wyner-Ziv设置的Blahut-Arimoto算法。

**Result:** 所提出的Blahut-Arimoto算法被用于在S被视为分类标签时，对可达的间接率失真区域进行数值评估。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了间接Wyner-Ziv信源编码问题，其中解码器除了旁信息Y外，还需要重建一个潜在源S。这种设置在面向目标的通信中具有重要意义。作者推导了渐近和有限块长下的间接Wyner-Ziv率失真函数和可达区域，并提出了一种定制的Blahut-Arimoto算法。该算法被用于在S作为分类标签时，对可达区域进行数值评估。

> **摘要翻译:** 在Wyner-Ziv信源编码问题中，源X需要被编码，而解码器可以访问旁信息Y。本文研究了间接设置，其中解码器还必须重建一个编码器和解码器均未观察到的潜在源S。这种场景在面向目标的通信中日益相关，其中S可以代表从X获得的语义信息。本文推导了渐近体制下的间接Wyner-Ziv率失真函数，并提供了有限块长下的可达区域。此外，还提出了一种专门针对间接Wyner-Ziv设置的Blahut-Arimoto算法。当S被视为分类标签时，该算法随后被用于对可达的间接率失真区域进行数值评估。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [433] [On the Role of Age and Semantics of Information in Remote Estimation of Markov Sources](https://arxiv.org/abs/2507.18514)
> *马尔可夫源远程估计中信息年龄和语义的作用*

*Jiping Luo, Nikolaos Pappas* | **Category: cs.IT, cs.NI, cs.SY, eess.SY, math.IT** | **Updated: 2025-07-24**

**Keywords:** 马尔可夫链, 远程估计, 信息年龄, 连续错误年龄, 传输策略

**Comment:** Submitted for possible journal publication. A shorter version has
  been accepted as invited paper at Asilomar 2025

> **TL;DR:** 本文研究了有限状态马尔可夫链的语义感知远程估计，利用信息年龄（AoI）和连续错误年龄（AoCE）优化传输策略，显著提高了估计质量。

**AI_Comments:** 该研究创新性地结合了信息年龄（AoI）和连续错误年龄（AoCE）这两个指标，用于优化马尔可夫源的远程估计，并提出了一个理论上完备且算法高效的解决方案。通过考虑信息的语义和时效性，显著提升了在资源受限环境下的估计性能，对于无线传感器网络、工业物联网等领域的实时状态监测具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究有限状态马尔可夫链的语义感知远程估计问题，并设计一种传输策略，以在传输频率约束下优化估计性能。

**Method:** 采用最大后验（MAP）估计器。引入连续错误年龄（AoCE）和信息年龄（AoI）两个指标来量化错误显著性和过时信息的可预测性。将最优传输问题建模为具有无界成本的受限马尔可夫决策过程（CMDP）。开发了一种高效的结构感知算法Insec-SPI来计算最优策略。

**Result:** 证明了存在一种最优的简单混合策略，该策略以固定概率随机选择两种确定性切换策略。每种切换策略仅当AoCE超过一个取决于AoI和瞬时估计误差的阈值时触发传输。导出了切换策略简化为简单阈值策略的充分条件。开发的Insec-SPI算法能以较低的计算开销计算最优策略。结果表明，同时结合AoI和AoCE能显著提高估计质量。

**Conclusion:** 结合信息年龄（AoI）和连续错误年龄（AoCE）这两个指标，能够显著提高马尔可夫源远程估计的质量。

> **ai_Abstract:** 本文研究了有限状态马尔可夫链的语义感知远程估计，旨在通过优化传输策略来提高估计性能。研究引入了连续错误年龄（AoCE）和信息年龄（AoI）作为关键指标，并将问题建模为受限马尔可夫决策过程（CMDP）。论文证明了一种最优简单混合策略的存在性，该策略根据AoCE、AoI和当前估计误差的阈值来触发传输。此外，还提出了简化策略的条件并开发了高效的Insec-SPI算法。实验结果表明，同时考虑AoI和AoCE能显著提升估计质量。

> **摘要翻译:** 本文研究了有限状态马尔可夫链的语义感知远程估计。我们采用最大后验（MAP）估计器，旨在设计一种传输策略以在传输频率约束下优化估计性能。我们利用连续错误年龄（AoCE）和信息年龄（AoI）两个指标，分别量化发射端的估计错误显著性和接收端过时信息的可预测性。最优传输问题被建模为具有无界成本的受限马尔可夫决策过程（CMDP）。我们证明了存在一种最优的简单混合策略，该策略以固定概率随机选择两种确定性切换策略。值得注意的是，每种切换策略仅当AoCE超过一个取决于AoI和瞬时估计误差的阈值时才触发传输。我们进一步导出了切换策略简化为简单阈值策略的充分条件；即，它对所有估计误差都采用相同的阈值。利用这些结果，我们开发了一种高效的结构感知算法Insec-SPI，该算法以降低的计算开销计算最优策略。我们的结果表明，结合AoI和AoCE比单独使用任一指标能显著提高估计质量。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [439] [Action-List Reinforcement Learning Syndrome Decoding for Binary Linear Block Codes](https://arxiv.org/abs/2507.17893)
> *基于动作列表强化学习的二进制线性分组码综合征译码*

*Milad Taghipour, Bane Vasic* | **Category: cs.IT, cs.AI, cs.LG, math.IT** | **Updated: 2025-07-23**

**Keywords:** 强化学习, 综合征译码, 线性分组码, 马尔可夫决策过程, LDPC码

**Comment:** 

> **TL;DR:** 本文提出了一种名为“动作列表译码”的强化学习方案，用于提升二进制线性分组码的译码性能，通过将译码过程映射为MDP并优化状态空间，在LDPC码上表现出高效性。

**AI_Comments:** 该论文创新性地将强化学习应用于二进制线性分组码的译码，提出了一种通用的“动作列表译码”方案。其通过将译码过程映射为MDP并有效减少状态空间（如截断MDP），以及结合Deep-Q网络和码的自同构群，显著提升了译码性能并降低了复杂度。此外，提出的反馈机制也为现有高性能译码器提供了性能增强途径，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过应用强化学习技术，特别是基于比特翻转和寻找最优决策的方法，来提升线性分组码的译码性能。

**Method:** 1. 将迭代译码过程映射为马尔可夫决策过程（MDP）。2. 提出不同的方法来减少MDP中的状态数量，包括引入截断MDP，通过学习码字周围特定半径的汉明球来减少状态。3. 提出一种通用的、适用于任何码类的基于强化学习的译码方案，称为“动作列表译码”。4. 设计基于Deep-Q网络值的动作列表译码器。5. 利用码的自同构群进一步提升性能。6. 提出一种基于反馈的方法，在现有高性能译码器之后应用强化学习算法，以利用和增强其性能。

**Result:** 1. 基于Deep-Q网络值的动作列表译码器显著提升了译码性能。2. 利用码的自同构群进一步改善了码的性能。3. 提出的方法有效降低了强化学习块的复杂性。4. 在二元对称信道（BSC）上的低密度奇偶校验码（LDPC）实验结果证明了所提方法的效率。

**Conclusion:** 本文提出的动作列表强化学习译码方案通过将译码过程建模为MDP并优化状态空间，有效提升了二进制线性分组码的译码性能，并在LDPC码上验证了其高效性。

> **ai_Abstract:** 本文提出了一种将线性分组码迭代译码过程映射为马尔可夫决策过程（MDP）的强化学习方案，旨在提升译码性能。通过引入截断MDP和利用码的自同构群等方法，有效减少了MDP状态空间并优化了译码器。文中设计了基于Deep-Q网络的“动作列表译码”方案，并在LDPC码上进行了验证，结果表明该方法能显著提升译码性能并降低强化学习的复杂度。

> **摘要翻译:** 本文探讨了强化学习技术在提升线性分组码译码性能方面的应用，该译码基于比特翻转和寻找最优决策。我们描述了将迭代译码过程映射到马尔可夫决策过程（MDPs）的方法，并提出了不同的方法来减少MDP中的状态数量。提出了一种截断MDP，通过学习码字周围具有指定半径的汉明球来减少MDP中的状态数量。然后，我们提出了一种通用的、适用于任何码类的基于强化学习的译码方案，以提高译码器的性能。我们将此方案称为动作列表译码。我们设计了一个基于Deep-Q网络值的动作列表译码器，该译码器显著提升了性能。我们还利用了码的自同构群来进一步提高码的性能。此外，我们提出了一种基于反馈的方法，通过在现有译码器之后应用强化学习算法，来利用和增强现有高性能译码器的性能。这些方法有效地降低了强化学习块的复杂性。最后，我们展示了在二元对称信道（BSC）上对低密度奇偶校验码（LDPC）进行的实验结果，以证明所提方法的效率。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [487] [Minimax Data Sanitization with Distortion Constraint and Adversarial Inference](https://arxiv.org/abs/2507.17942)
> *具有失真约束和对抗性推断的最小最大数据净化*

*Amirarsalan Moatazedian, Yauhen Yakimenka, Rémi A. Chou, Jörg Kliewer* | **Category: cs.IT, cs.AI, math.IT** | **Updated: 2025-07-23**

**Keywords:** 数据净化, 隐私保护, 最小最大优化, 对抗性推断, 秘密共享

**Comment:** Accepted to IEEE ITW 2025

> **TL;DR:** 本文研究了一种隐私保护数据共享设置，其中数据净化器在满足重构器失真约束的同时，最大化两个未经授权的对手的最小损失，并通过交替更新的训练程序解决这一最小最大优化问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个考虑多方对抗和协作的隐私保护数据共享框架，特别是在需要协作才能恢复数据的场景下。其将问题建模为约束最小最大优化并提出交替训练方法，并提供理论最优解作为基准，为数据净化领域的复杂隐私-效用权衡提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有场景中，单个用户无法准确重构数据，但他们的联合侧信息可以在失真阈值内进行估计。研究旨在解决这种情况下，如何通过协作实现准确重构，同时最大化对手的个人损失，类似于秘密共享原则但允许有损恢复。

**Method:** 将问题构建为约束数据驱动的最小最大优化问题，并提出了一种数据驱动的训练过程，该过程交替更新净化器、重构器和对手。此外，还分析了高斯和二进制情况作为特殊场景，以获得理论最优解作为评估所提出方法的基准。

**Result:** 提出了一个数据驱动的最小最大优化训练程序，并为高斯和二进制情况提供了理论最优解作为评估所提出方法的基准。

**Conclusion:** 本文提出了一个解决隐私保护数据共享中最小最大数据净化问题的框架和训练方法，特别是针对需要协作才能准确重构的场景，并提供了理论基准来评估其性能。

> **ai_Abstract:** 本文研究了一种隐私保护的数据共享机制，其中数据净化器在满足授权重构器失真约束的前提下，最大化两个具有侧信息的非授权对手的最小损失。该机制旨在模拟需要多方协作才能准确重构数据的场景，类似于有损秘密共享。作者将此问题建模为一个约束数据驱动的最小最大优化问题，并提出了一种交替更新净化器、重构器和对手的训练方法。此外，论文还分析了高斯和二进制情况下的理论最优解，作为评估所提出训练方法的基准。

> **摘要翻译:** 我们研究了一种隐私保护的数据共享设置，其中净化器将私有数据转换为经授权的重构器和两个未经授权的对手观察到的净化版本，每个对手都可以访问与私有数据相关的侧信息。
重构器在失真函数下进行评估，而每个对手则使用单独的损失函数进行评估。净化器确保重构器失真保持在固定阈值以下，同时最大化两个对手的最小损失。这种双对手设置模拟了单个用户无法准确重构数据的情况，但他们的组合侧信息可以在失真阈值内进行估计。净化器最大化个人损失，同时仅通过协作才允许准确重构。这与秘密共享原则相呼应，但允许有损而非完美的恢复。我们将此问题框架化为约束数据驱动的最小最大优化问题，并提出了一种数据驱动的训练过程，该过程交替更新净化器、重构器和对手。我们还将高斯和二进制情况作为特殊场景进行分析，其中可以获得最优解。这些理论最优结果是评估所提出的最小最大训练方法的基准。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [535] [Deep Learning-based Position-domain Channel Extrapolation for Cell-Free Massive MIMO](https://arxiv.org/abs/2507.17950)
> *基于深度学习的无蜂窝大规模MIMO定位域信道外推*

*Jiajia Guo, Chao-Kai Wen, Xiao Li, Shi Jin* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-23**

**Keywords:** 深度学习, 信道外推, 无蜂窝大规模MIMO, 定位域, PCEnet

**Comment:** IEEE TWC. copyright2025 IEEE. Personal use of this material is
  permitted. Permission from IEEE must be obtained for all other uses, in any
  current or future media, including reprinting/republishing this material for
  advertising or promotional purposes, creating new collective works, for
  resale or redistribution to servers or lists, or reuse of any copyrighted
  component of this work in other works

> **TL;DR:** 该论文提出PCEnet，一个基于深度学习的框架，通过利用用户位置信息进行信道外推，以减少无蜂窝大规模MIMO系统中的信道获取开销。

**AI_Comments:** 该论文创新性地将用户位置作为无蜂窝大规模MIMO中信道外推的“桥梁”，与传统的空间、时域和频域方法相比，这是一种新颖的方法。这有望显著提高下一代无线系统的效率。引入简化和无标签方法也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了减少无蜂窝大规模MIMO系统中的信道获取开销，尽管现有研究广泛关注空间、时域和频域信道外推技术，但用户位置包含重要的信道特征信息，可以显著提高信道获取效率。

**Method:** 论文提出了名为PCEnet的深度学习框架。该框架首先利用神经网络从已获取的信道中推断出用户位置。然后，通过中央处理单元在基站间共享的估计位置被用于设计导频符号，并与反馈信息一起输入到信道重建神经网络以重建其他信道。此外，还提出了一种简化策略（仅使用估计位置进行重建而不修改导频设计）和一种无位置标签的方法（推断相对用户位置）。

**Result:** 所提出的PCEnet框架将导频和反馈开销降低了高达50%。

**Conclusion:** PCEnet框架通过利用用户位置信息，显著提高了无蜂窝大规模MIMO系统中的信道获取性能并降低了开销。

> **ai_Abstract:** 本文提出PCEnet，一个用于无蜂窝大规模MIMO的基于深度学习的定位域信道外推框架。它利用用户在不同信道中不变的位置信息，从一个已获取的信道推断用户位置，然后利用该位置重建其他信道，从而显著减少高达50%的导频和反馈开销。该框架还包括简化策略和无位置标签方法。

> **摘要翻译:** 为了减少信道获取开销，空间、时域和频域信道外推技术得到了广泛研究。在本文中，我们提出了一种新颖的基于深度学习的定位域信道外推框架（命名为PCEnet），用于无蜂窝大规模多输入多输出（MIMO）系统。用户的定位信息包含重要的信道特征信息，可以大大提高信道获取的效率。在无蜂窝大规模MIMO中，尽管不同基站与特定用户之间的传播环境各异，且各自的信道不相关，但用户的位置在所有信道中保持不变且唯一。在此基础上，所提出的PCEnet框架利用位置作为信道之间的桥梁，建立不同信道特征之间的映射，从而利用一个已获取的信道来辅助其他信道的估计和反馈。具体而言，该方法首先利用神经网络（NNs）从获得的信道中推断出用户的位置。{通过中央处理单元（CPU）在基站之间共享的估计位置}随后被输入到一个NN中以设计导频符号，并与反馈信息连接到信道重建NN以重建其他信道，从而显著提高信道获取性能。此外，我们提出了一种简化策略，其中仅在重建过程中使用估计位置而不修改导频设计，从而减少了延迟。此外，我们引入了一种无位置标签的方法，该方法推断相对用户位置而不是绝对位置，消除了在定位NN训练过程中对真实位置标签的需求。仿真结果表明，所提出的PCEnet框架将导频和反馈开销降低了高达50%。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [583] [A Novel Coded Computing Approach for Distributed Multi-Task Learning](https://arxiv.org/abs/2507.18025)
> *分布式多任务学习的一种新型编码计算方法*

*Minquan Cheng, Yongkang Wang, Lingyu Zhang, Youlong Wu* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 分布式多任务学习, 编码计算, 通信瓶颈, 矩阵分解, 异构数据放置

**Comment:** 17 pages, 2 figures

> **TL;DR:** 提出了一种新颖的编码分布式多任务学习（DMTL）方案，通过将通信过程建模为矩阵分解问题，显著降低了DMTL在异构数据放置下的通信开销，并达到了理论最优。

**AI_Comments:** 本文的创新点在于将分布式多任务学习中的通信瓶颈问题转化为矩阵分解问题，并利用编码计算理论设计了一种高效的通信方案。其重要性在于，该方案不仅在理论上达到了通信开销的下限，而且在异构环境下依然保持最优性，解决了实际大规模DMTL系统中的关键性能瓶颈。此外，其对线性可分离计算问题的可扩展性也展现了该方法的普适潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在大规模分布式多任务学习（DMTL）场景中，通信瓶颈严重限制了系统性能，尤其是在采用非线性全局更新的DMTL系统中。

**Method:** 将通信过程表征为矩阵分解问题，将工作节点的数据存储约束转化为上行编码矩阵的结构特性，并将工作节点的数据检索需求转化为下行编码矩阵的最大距离可分离（MDS）特性。在此基础上，提出了一种新型的编码DTML方案。

**Result:** 该方案能够大大降低异构数据放置下DTML的通信成本。理论分析表明，该方案在温和条件下达到了通信开销的理论下限，并且在传统同构计算环境和各种异构场景中都保持了最优性。

**Conclusion:** 所提出的编码分布式多任务学习方案通过创新的编码计算方法有效解决了大规模DMTL中的通信瓶颈问题，达到了理论最优的通信开销，并具有良好的可扩展性，为解决分布式应用中的异构数据放置挑战提供了新途径。

> **ai_Abstract:** 本文针对大规模分布式多任务学习（DMTL）中存在的通信瓶颈问题，提出了一种新颖的编码计算方法。该方法将通信过程建模为矩阵分解，并在此基础上设计了一种编码DMTL方案，显著降低了异构数据放置下的通信开销。理论分析证明，该方案在多种环境下均能达到通信开销的理论下限，并具有良好的可扩展性，为解决分布式应用中的异构数据挑战提供了有效途径。

> **摘要翻译:** 分布式多任务学习（DMTL）通过多个相关模型的协同训练有效提高了模型的泛化性能。然而，在大型学习场景中，通信瓶颈严重限制了实际系统性能。在本文中，我们研究了采用非线性全局更新的典型DMTL系统中的通信瓶颈。该系统涉及由中央服务器协助的分布式工作节点，它们协同学习源自其局部模型参数的非线性聚合的不同模型。我们首先将通信过程表征为矩阵分解问题。它将工作节点的数据存储约束转换为上行编码矩阵的结构特性，并将工作节点的数据检索需求转换为下行编码矩阵的最大距离可分离（MDS）特性。在此基础上，我们提出了一种新型的编码DTML方案，可以大大降低异构数据放置下DTML的通信成本。理论分析表明，所提出的方案在温和条件下达到了通信开销的理论下限。值得注意的是，这种最优性适用于传统的同构计算环境和各种异构场景。此外，我们的方案可以扩展到分布式线性可分离计算问题，其中目标函数涉及局部更新值的多个线性组合。这表明我们的方案为解决各种分布式应用中的异构数据放置挑战提供了一种新方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [625] [Covert Communications in MEC-Based Networked ISAC Systems Towards Low-Altitude Economy](https://arxiv.org/abs/2507.18194)
> *MEC网络化ISAC系统中面向低空经济的隐蔽通信*

*Weihao Mao, Yang Lu, Bo Ai, Tony Q. S. Quek* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 隐蔽通信, 移动边缘计算, 集成传感与通信, 低空经济, 无人机

**Comment:** 

> **TL;DR:** 本文研究MEC网络化ISAC系统中面向低空经济的隐蔽传输设计，通过优化通信、感知和计算资源以及无人机轨迹来最小化总能耗，并提出了一种基于交替优化的算法来解决此复杂问题。

**AI_Comments:** 本文将隐蔽通信、MEC和ISAC融合，以解决低空经济背景下的复杂系统设计问题，具有较高的创新性。其提出的交替优化算法有效处理了多目标、多约束的复杂优化，为低空经济中的安全高效通信提供了理论和技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 低空经济（LAE）是一种新兴的商业模式，它严重依赖于集成传感与通信（ISAC）、移动边缘计算（MEC）和隐蔽通信。

**Method:** 论文研究了MEC网络化ISAC系统中面向LAE的隐蔽传输设计，其中MEC服务器协调多个接入点同时进行计算任务接收、目标定位和隐蔽传输维护。首先推导了监听者处的检测错误概率（DEP）的闭式表达式。然后，通过优化通信、感知和计算资源以及无人机（UAV）轨迹，构建了一个总能耗最小化问题。该问题通过一种基于交替优化的算法解决，分解为两个子问题：通信、感知和计算资源的联合优化（通过逐次凸逼近算法解决）和UAV轨迹优化（通过信任域算法解决）。

**Result:** 仿真验证了所提算法相对于各种基准的有效性，并揭示了LAE系统中通信、感知和计算之间的权衡。

**Conclusion:** 所提出的算法在MEC网络化ISAC系统中实现了有效的隐蔽传输设计，并揭示了通信、感知和计算资源间的权衡关系。

> **ai_Abstract:** 本文针对低空经济（LAE）中对集成传感与通信（ISAC）、移动边缘计算（MEC）和隐蔽通信的依赖性，研究了MEC网络化ISAC系统中的隐蔽传输设计。研究目标是通过优化通信、传感、计算资源和无人机轨迹来最小化总能耗，同时确保服务质量和隐蔽性。文章推导了检测错误概率，并提出了一种基于交替优化的算法来解决复杂的优化问题，该算法将问题分解为资源优化和轨迹优化两个子问题，并分别采用逐次凸逼近和信任域方法求解。仿真结果验证了算法的有效性并揭示了资源间的权衡。

> **摘要翻译:** 低空经济（LAE）是一种新兴的商业模式，它严重依赖于集成传感与通信（ISAC）、移动边缘计算（MEC）和隐蔽通信。本文研究了基于MEC的网络化ISAC系统中面向LAE的隐蔽传输设计，其中MEC服务器协调多个接入点，同时接收来自多个无人机（UAV）的计算任务，在传感区域定位目标，并对抗多个监听者维护无人机的隐蔽传输。我们首先推导了监听者处检测错误概率（DEP）的闭式表达式。然后，通过优化通信、感知和计算资源以及无人机轨迹，构建了一个总能耗最小化问题，同时满足MEC服务质量、DEP、雷达信噪比以及无人机轨迹因果性要求。提出了一种基于交替优化的算法来解决所考虑的问题，该算法将其分解为两个子问题：通信、感知和计算资源的联合优化，以及无人机轨迹优化。前者通过基于逐次凸逼近的算法解决，后者通过基于信任域的算法解决。仿真验证了所提算法与各种基准相比的有效性，并揭示了LAE系统中通信、感知和计算之间的权衡。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [666] [Private Counterfactual Retrieval](https://arxiv.org/abs/2410.13812)
> *私有反事实检索*

*Mohamed Nomeir, Pasan Dissanayake, Shreya Meel, Sanghamitra Dutta, Sennur Ulukus* | **Category: cs.IT, cs.CR, cs.LG, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 私有信息检索, 反事实解释, 隐私, 机器学习, 可解释性

**Comment:** 

> **TL;DR:** 该论文提出了受私有信息检索（PIR）技术启发的方案，用于私有地检索反事实解释，确保用户隐私，同时量化并减少数据库泄露。

**AI_Comments:** 该论文的创新点在于将PIR技术应用于反事实解释领域，填补了隐私保护的关键空白。鉴于黑盒模型日益广泛的应用以及对可解释性和隐私并存的需求，这项研究具有高度重要性。对数据库泄露的量化和缓解策略也是一项重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在部署高风险应用的黑盒机器学习模型时，透明度和可解释性是两个极其重要的方面。提供反事实解释是满足这一要求的一种方式，但这也会对提供解释的机构和请求解释的用户造成隐私威胁。

**Method:** 本文提出了多种受私有信息检索（PIR）技术启发的方案。其中一个方案能够从已接受点数据库中检索出精确的最近邻反事实解释，并为用户实现完美（信息论）隐私。这些方案依赖于有限域算术。此外，他们还扩展了这些方案以纳入用户的属性转换偏好。

**Result:** 所提出的方案为用户实现了完美（信息论）隐私。量化了数据库不可避免的泄露，并使用基于互信息度量进行衡量。提出了减少这种泄露的策略，以实现更高程度的数据库隐私。在真实数据集上对方案进行了实证验证，以理解准确性和有限域大小之间的权衡。数值结果支持了理论发现，并比较了所提出方案的数据库泄露。

**Conclusion:** 该论文成功提出并验证了受PIR启发的私有反事实解释检索方案，确保了用户隐私，同时解决了数据库泄露问题。

> **ai_Abstract:** 本论文旨在解决黑盒机器学习模型提供反事实解释时产生的隐私问题。它提出了受私有信息检索（PIR）启发的创新方案，以确保用户在检索反事实解释时的隐私。核心贡献包括一种能够保证用户完美隐私的精确最近邻反事实检索方法。尽管数据库泄露不可避免，但论文对其进行了量化并提出了缓解策略。这些方案还扩展以适应用户偏好，并通过真实数据集进行实证验证，分析了准确性与有限域大小之间的权衡。

> **摘要翻译:** 透明度和可解释性是在高风险应用中采用黑盒机器学习模型时需要考虑的两个极其重要的方面。提供反事实解释是满足这一要求的一种方式。然而，这也对提供解释的机构和请求解释的用户构成了隐私威胁。在这项工作中，我们提出了多种受私有信息检索（PIR）技术启发的方案，这些方案在检索反事实解释时确保了用户的隐私。我们提出了一个方案，该方案从已接受点数据库中检索出精确的最近邻反事实解释，同时为用户实现了完美（信息论）隐私。尽管该方案为用户实现了完美隐私，但数据库的一些泄露是不可避免的，我们使用基于互信息的度量对其进行了量化。此外，我们提出了减少这种泄露的策略，以实现更高程度的数据库隐私。我们将这些方案扩展到包含用户对其属性转换的偏好，以便获得更具可操作性的解释。由于我们的方案依赖于有限域算术，我们通过真实数据集对我们的方案进行了实证验证，以了解准确性和有限域大小之间的权衡。最后，我们提供了数值结果来支持我们的理论发现，并比较了所提出方案的数据库泄露。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [667] [Hermitian hull of some GRS codes and new EAQMDS codes](https://arxiv.org/abs/2507.18361)
> *某些GRS码的Hermitian核和新的EAQMDS码*

*Oisin Campion, Rodrigo San-José* | **Category: cs.IT, math.IT, 81P70 (Primary) 94B05 (Secondary)** | **Updated: 2025-07-24**

**Keywords:** Hermitian核, GRS码, EAQMDS码, 量子纠错码, 格计数问题

**Comment:** 

> **TL;DR:** 本文研究了特定GRS码的Hermitian核，将核维数计算转化为格上的计数问题，并提供了显式公式，进而用于构造新的纠缠辅助量子MDS码。

**AI_Comments:** 本文通过将代数编码理论中的Hermitian核维数计算问题巧妙地转化为格上的计数问题，提供了一种新颖且有效的解决思路。其研究成果——核维数的显式公式，直接关联到量子纠错码的实际应用，即确定构建EAQMDS码所需的纠缠资源。这种方法不仅具有理论上的创新性，也为构造新型量子码提供了灵活且有效的工具，对于量子信息领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机是研究特定广义Reed-Solomon (GRS) 码的Hermitian核，并确定其维数，因为这直接关系到构建相关纠缠辅助量子纠错码所需的最大纠缠对的最小数量。

**Method:** 该研究将计算Hermitian核维数的问题转化为一个格上的计数问题。通过解决这个计数问题，提供了核维数的显式公式。

**Result:** 研究提供了Hermitian核维数的显式公式，这些公式决定了相关纠缠辅助量子纠错码所需的最大纠缠对的最小数量。这种灵活的构造方法能够获得广泛的纠缠辅助量子MDS码以及新的参数。

**Conclusion:** 通过计算GRS码Hermitian核的维数，成功地为纠缠辅助量子MDS码提供了一种灵活的构造方法，从而能够获得具有新参数的广泛的EAQMDS码。

> **ai_Abstract:** 本文研究了特定广义Reed-Solomon (GRS) 码的Hermitian核。通过将核维数的计算问题转化为格上的计数问题，作者推导出了核维数的显式公式。这些公式直接决定了构建纠缠辅助量子纠错码所需的最大纠缠对的最小数量。这项研究提供了一种灵活的构造方法，从而能够获得具有新参数的广泛的纠缠辅助量子MDS (EAQMDS) 码。

> **摘要翻译:** 我们研究了特定广义Reed-Solomon码族的Hermitian核。计算核维数的问题被转化为格中的一个计数问题。通过解决这个问题，我们提供了核维数的显式公式，该公式决定了相关联的纠缠辅助量子纠错码所需的最大纠缠对的最小数量。这种灵活的构造允许获得广泛的纠缠辅助量子MDS码以及新的参数。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [710] [AI/ML Life Cycle Management for Interoperable AI Native RAN](https://arxiv.org/abs/2507.18538)
> *AI/ML生命周期管理用于可互操作的AI原生无线接入网*

*Chu-Hsiang Huang, Chao-Kai Wen, Geoffrey Ye Li* | **Category: cs.IT, cs.LG, math.IT** | **Updated: 2025-07-24**

**Keywords:** AI/ML, 生命周期管理, 5G RAN, 3GPP, 互操作性

**Comment:** 8 pages, 4 figures, 2 table. This work has been submitted to the IEEE
  for possible publication

> **TL;DR:** 5G RAN中AI/ML模型面临模型漂移、厂商锁定等挑战。3GPP从Rel-16到Rel-20逐步标准化AI/ML生命周期管理，本文回顾了其五块LCM架构和监控机制，并指出未来挑战，为6G AI原生收发器奠定基础。

**AI_Comments:** 这篇论文探讨了5G RAN中AI/ML应用的关键痛点——缺乏标准化生命周期管理。其创新之处在于梳理了3GPP在这一领域的标准化演进，并提出了一个五块LCM架构。论文的重要性在于其为解决模型漂移、厂商锁定等实际问题提供了路线图，并展望了AI在6G中的应用前景。然而，论文也指出了仍需解决的开放挑战，如资源效率和环境漂移检测，这表明了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 5G无线接入网（RAN）中AI/ML模型日益普及，但缺乏标准化的生命周期管理（LCM）框架，导致模型漂移、厂商锁定和透明度受限等挑战，阻碍了大规模应用。

**Method:** 本文回顾了3GPP从Rel-16到Rel-20在AI/ML生命周期管理方面的逐步演进，包括网络数据分析功能（NWDAF）的引入、模型传输、执行、性能监控和闭环控制的标准化接口，以及Rel-20的厂商无关LCM配置文件。具体审查了由此产生的五块LCM架构、基于KPI的监控机制和厂商间协作方案。

**Result:** 3GPP的进展为AI/ML在5G RAN中的大规模应用提供了标准化的生命周期管理框架，形成了五块LCM架构、KPI驱动的监控机制和厂商间协作方案。

**Conclusion:** 3GPP在AI/ML生命周期管理方面的标准化工作为AI原生收发器奠定了基础，并被视为6G的关键推动因素，但仍存在资源效率监控、环境漂移检测、智能决策和灵活模型训练等开放挑战。

> **ai_Abstract:** 本文探讨了5G无线接入网（RAN）中AI/ML模型部署面临的挑战，强调了标准化生命周期管理（LCM）框架的重要性。文章回顾了3GPP从Rel-16到Rel-20在AI/ML LCM方面的进展，包括引入NWDAF、标准化接口以及厂商无关的LCM配置文件。文中详细审查了由此形成的五块LCM架构、KPI驱动的监控机制和厂商间协作方案，并识别了资源效率监控、环境漂移检测、智能决策和灵活模型训练等开放挑战。这些标准化工作为6G的AI原生收发器奠定了基础。

> **摘要翻译:** 人工智能（AI）和机器学习（ML）模型正在迅速渗透到5G无线接入网（RAN）中，为波束管理、信道状态信息（CSI）反馈、定位和移动性预测提供支持。然而，如果没有标准化的生命周期管理（LCM）框架，模型漂移、厂商锁定和透明度受限等挑战会阻碍大规模应用。3GPP Releases 16-20逐步将AI/ML从实验性功能发展为可管理、可互操作的网络功能。从Rel-16的网络数据分析功能（NWDAF）开始，后续版本引入了模型传输、执行、性能监控和闭环控制的标准化接口，最终在Rel-20中形成了双向CSI压缩工作项和厂商无关的LCM配置文件。本文回顾了由此产生的五块LCM架构、基于KPI的监控机制和厂商间协作方案，同时指出了资源高效监控、环境漂移检测、智能决策和灵活模型训练等开放挑战。这些发展为AI原生收发器奠定了基础，使其成为6G的关键推动因素。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [13] [PRACtical: Subarray-Level Counter Update and Bank-Level Recovery Isolation for Efficient PRAC Rowhammer Mitigation](https://arxiv.org/abs/2507.18581)
> *PRACtical: 子阵级计数器更新和Bank级恢复隔离以实现高效PRAC Rowhammer缓解*

*Ravan Nazaraliyev, Saber Ganjisaffar, Nurlan Nazaraliyev, Nael Abu-Ghazaleh* | **Category: cs.AR, cs.ET** | **Updated: 2025-07-24**

**Keywords:** Rowhammer, DRAM, PRAC, DDR5, 性能优化

**Comment:** 

> **TL;DR:** PRACtical通过子阵级计数器更新和Bank级恢复隔离，显著提升了DDR5 Rowhammer缓解的性能和能效。

**AI_Comments:** PRACtical的创新之处在于其对DDR5 PRAC+ABO机制的精细硬件优化，通过引入集中式增量电路和实现Bank级恢复隔离，有效解决了现有方案在计数器更新和恢复刷新过程中造成的性能瓶颈。特别是Bank级隔离，它显著提高了内存资源的利用效率，是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** DRAM密度增加导致Rowhammer问题日益严重。DDR5的PRAC+ABO机制虽然能缓解此威胁，但存在性能开销：计数器更新在预充电阶段进行会增加延迟，且恢复刷新会停滞整个内存通道，即使只有部分Bank受攻击。

**Method:** PRACtical通过两方面优化PRAC+ABO：1. 引入集中式增量电路，使计数器更新与其它子阵的后续行激活重叠，减少更新延迟。2. 增强RFMab缓解机制，实现Bank级恢复隔离，通过DRAM驻留寄存器识别并仅暂停受攻击的Bank，而非整个通道。

**Result:** 相比现有技术，PRACtical平均性能提升8%（最高20%），能耗降低19%，并将激进性能攻击下的性能下降限制在6%以下，同时保持Rowhammer保护。

**Conclusion:** PRACtical在保持Rowhammer保护的同时，显著提高了DDR5 PRAC+ABO缓解机制的性能和能效。

> **ai_Abstract:** PRACtical是一种针对DDR5 PRAC+ABO Rowhammer缓解机制的性能优化方法。它通过引入集中式增量电路减少计数器更新延迟，并实现Bank级恢复隔离，仅暂停受攻击的Bank而非整个内存通道。实验结果表明，PRACtical在保持相同安全保障的前提下，显著提升了性能和能效。

> **摘要翻译:** 随着DRAM密度的增加，由于电荷泄漏的加剧，Rowhammer问题变得更加严重，诱发位翻转所需的激活次数也随之减少。DDR5标准通过DRAM内每行激活计数器（PRAC）和警报回退（ABO）信号来触发缓解，以应对这一威胁。然而，PRAC在预充电阶段增加计数器会带来性能开销，并且恢复刷新会使整个内存通道停滞，即使只有一个Bank受到攻击。
我们提出了PRACtical，一种性能优化的PRAC+ABO方法，它保持相同的安全保障。首先，我们通过引入一个集中式增量电路来减少计数器更新延迟，从而使计数器更新与其它子阵中的后续行激活重叠。其次，我们通过启用Bank级粒度来增强$RFM_{ab}$缓解：不再停滞整个通道，而只暂停受影响的Bank。这是通过一个DRAM驻留寄存器实现的，该寄存器用于识别受攻击的Bank。
PRACtical相比现有技术平均提升了8%的性能（最高20%），降低了19%的能耗，并将激进性能攻击造成的性能下降限制在6%以下，同时保留了Rowhammer保护。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [44] [Designing High-Performance and Thermally Feasible Multi-Chiplet Architectures enabled by Non-bendable Glass Interposer](https://arxiv.org/abs/2507.18040)
> *设计高性能和热可行的多小芯片架构，由不可弯曲玻璃中介层实现*

*Harsh Sharma, Janardhan Rao Doppa, Umit Y. Ogras, Partha Pratim Pande* | **Category: cs.AR** | **Updated: 2025-07-24**

**Keywords:** 多小芯片, 玻璃中介层, 翘曲, 协同优化, 深度神经网络

**Comment:** Paper accepted at ACM Transactions on Embedded Computing Systems. To
  be presented in Taiwan, Sept. 2025

> **TL;DR:** 该研究提出了一种热、翘曲和性能感知的协同设计框架，用于基于玻璃中介层的多小芯片架构，以解决翘曲问题并提高性能和功耗效率，与传统2.5D系统相比，在深度神经网络工作负载下实现了显著的性能提升和功耗降低。

**AI_Comments:** 这项研究的创新之处在于其提出的热、翘曲和性能感知的协同设计框架，它通过架构与封装的联合优化，有效解决了玻璃中介层多小芯片系统中的关键挑战——翘曲问题。这种方法不仅提升了系统的结构可靠性，还在性能和功耗方面取得了显著进步，特别是在深度神经网络应用中展现出巨大潜力。其重要性在于为未来高性能、高集成度计算系统的设计提供了新的思路和解决方案，克服了传统2.5D封装技术的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 基于玻璃中介层的多小芯片架构虽然具有优越的电气性能和更低的功耗，但随着系统尺寸的增加，封装变形（翘曲）成为一个关键挑战，导致严重的机械应力和可靠性问题。传统封装技术无法有效管理大型系统的翘曲，因此需要新的方法来缓解翘曲引起的弯曲，同时保持可扩展的性能。

**Method:** 提出了一种热、翘曲和性能感知的协同设计框架，该框架采用架构和封装协同优化。该框架将表面和嵌入式小芯片分离，以平衡相互冲突的设计目标，确保在性能、功耗和结构可靠性之间达到最佳权衡。

**Result:** 通过该设计框架优化后的多小芯片架构，与传统2.5D系统相比，在执行深度神经网络工作负载时，性能提升高达64.7%，功耗降低40%，同时制造成本更低。

**Conclusion:** 该研究提出的协同设计框架成功地解决了玻璃中介层多小芯片架构中的翘曲和性能挑战，实现了显著的性能提升和功耗降低，并降低了制造成本，为下一代高性能计算系统提供了可行方案。

> **ai_Abstract:** 本研究提出了一种创新性的协同设计框架，用于基于玻璃中介层的多小芯片架构，旨在克服因系统尺寸增大而导致的封装翘曲问题，同时优化性能和功耗。该框架通过架构和封装的联合优化，并分离表面和嵌入式小芯片，以平衡性能、功耗和结构可靠性等相互冲突的设计目标。实验结果表明，该优化方法在深度神经网络工作负载下，相较于传统2.5D系统，实现了显著的性能提升（高达64.7%）和功耗降低（40%），并具有更低的制造成本。

> **摘要翻译:** 基于玻璃中介层的多小芯片架构比目前的硅中介层系统具有更优越的电气性能，由于串扰减少而支持更高的总线宽度，并且再分布层中的电容更低。这些优势带来了更低的每比特能耗、更高的通信频率和更长的互连范围。然而，随着系统尺寸的增加，基于玻璃中介层的系统中封装的变形（翘曲）成为一个关键挑战，导致严重的机械应力和可靠性问题。超出一定尺寸后，传统封装技术无法有效管理翘曲，因此需要新的方法来减轻翘曲引起的弯曲，同时为基于玻璃中介层的多小芯片系统提供可扩展的性能。为了解决这些相互交织的挑战，我们提出了一种热、翘曲和性能感知的协同设计框架，该框架采用架构和封装协同优化。所提出的框架分解了表面和嵌入式小芯片，以平衡相互冲突的设计目标，确保在性能、功耗和结构可靠性之间实现最佳权衡。我们的实验表明，通过我们设计框架优化后的多小芯片架构，与传统的2.5D系统相比，在执行深度神经网络工作负载时，性能提升高达64.7%，功耗降低40%，同时制造成本更低。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [84] [Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving](https://arxiv.org/abs/2507.18454)
> *Sandwich: 分离预填充-解码编译以实现高效CPU LLM服务*

*Juntao Zhao, Jiuru Li, Chuan Wu* | **Category: cs.AR, cs.AI, cs.DC, cs.PL** | **Updated: 2025-05-19**

**Keywords:** CPU LLM服务, 预填充-解码, 编译优化, 吞吐量, 延迟

**Comment:** 

> **TL;DR:** Sandwich是一种针对CPU LLM服务的新型引擎，通过分别优化预填充和解码阶段的执行计划，显著提高了吞吐量并降低了延迟。

**AI_Comments:** Sandwich的创新之处在于其对LLM推理中预填充和解码阶段的细致区分和独立优化，这解决了现有CPU服务方案的固有缺陷。通过硬件中心的设计，它在多种CPU架构上展示了显著的性能提升，尤其是在吞吐量和延迟方面。其GEMM内核的性能和低调优成本也显示了其工程上的优势。这项工作对于推动LLM在资源受限环境中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CPU LLM服务解决方案忽略了LLM推理中预填充和解码阶段的工作负载差异，采用静态的NUMA节点模型划分并依赖供应商库进行操作级执行，导致次优性能。

**Method:** 我们提出了Sandwich，一个以硬件为中心的CPU LLM服务引擎。它为预填充和解码阶段使用不同的执行计划，并分别进行优化。

**Result:** Sandwich在吞吐量方面平均提升了2.01倍，并实现了90%的满意首令牌时间（TTFT）和每输出令牌时间（TPOT）延迟，在单序列服务中需求降低了3.40倍，在连续批处理服务中显著改善了Goodput。Sandwich生成的GEMM内核性能优于代表性供应商内核和其他动态形状解决方案，实现了与静态编译器相当的性能，而内核调优成本降低了三个数量级。

**Conclusion:** Sandwich通过分离和优化LLM推理的预填充和解码阶段，显著提升了CPU上LLM服务的效率和性能，展现出优于现有解决方案的优势。

> **ai_Abstract:** Sandwich是一种创新的CPU LLM服务引擎，旨在解决现有CPU解决方案中预填充和解码阶段工作负载差异被忽视的问题。它通过为这两个阶段设计并分别优化不同的执行计划来提高效率。实验结果表明，Sandwich在吞吐量、延迟和资源需求方面均显著优于现有基线，并且其生成的GEMM内核性能卓越，显著降低了内核调优成本。

> **摘要翻译:** 利用CPU服务大型语言模型（LLM）是GPU服务的一种资源友好型替代方案。现有的基于CPU的解决方案忽略了LLM推理的预填充和解码阶段之间的工作负载差异，采用静态的每NUMA（非统一内存访问）节点模型划分并利用供应商库进行操作级执行，这导致了次优性能。我们提出了Sandwich，一个以硬件为中心的基于CPU的LLM服务引擎，它为预填充和解码阶段使用不同的执行计划，并分别进行优化。
我们在五个CPU平台（包括带AVX-2和AVX-512的x86，以及带NEON的ARM）上，通过不同的基线和数据集对Sandwich进行了评估。Sandwich平均实现了2.01倍的吞吐量提升，并在单序列服务中实现了90%的满意首令牌时间（TTFT）和每输出令牌时间（TPOT）延迟，需求降低了3.40倍，在连续批处理服务中Goodput显著改善。Sandwich生成的GEMM内核优于代表性供应商内核和其他动态形状解决方案，实现了与静态编译器相当的性能，而内核调优成本降低了三个数量级。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [249] [DiP: A Scalable, Energy-Efficient Systolic Array for Matrix Multiplication Acceleration](https://arxiv.org/abs/2412.09709)
> *DiP：一种用于矩阵乘法加速的可扩展、高能效脉动阵列*

*Ahmed J. Abdelmaksoud, Shady Agwa, Themis Prodromakis* | **Category: cs.AR, cs.DC** | **Updated: 2025-07-24**

**Keywords:** 脉动阵列,矩阵乘法,Transformer,能效,DiP

**Comment:** 

> **TL;DR:** DiP是一种新型脉动阵列架构，通过消除FIFO并优化数据流，显著提升了矩阵乘法的吞吐量和能效，尤其适用于Transformer工作负载。

**AI_Comments:** DiP架构的创新点在于其独特的Diagonal-Input和Permutated weight stationary数据流，以及成功消除了传统脉动阵列中用于同步的FIFO。这一改进不仅带来了显著的面积、功耗和能耗节省，更重要的是，它极大地提高了计算资源利用率和吞吐量。该研究为Transformer等数据密集型AI模型的硬件加速提供了高效且可扩展的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型在NLP领域表现出色但对现有计算架构性能要求高；现有脉动阵列架构（如Google TPU采用的）虽能效高但因FIFO同步导致吞吐量和能耗损失。

**Method:** 本文提出了一种名为DiP（Diagonal-Input and Permutated weight stationary）的新型可扩展脉动阵列架构，用于矩阵乘法加速。该架构通过对角线输入和置换权重驻留数据流，消除了现有最先进权重驻留脉动阵列所需的同步FIFO。此外，还开发了权重驻留和DiP架构的分析模型，并使用22nm商用技术进行了全面的硬件设计空间探索。

**Result:** DiP架构通过消除FIFO实现了面积、功耗和能耗的节省。与传统权重驻留架构相比，DiP的计算资源利用率最大化，吞吐量提升高达50%。在能效方面，每单位面积能效提升高达2.02倍。在Transformer工作负载上，DiP优于类TPU架构，能效提升高达1.81倍，延迟提升高达1.49倍。在64x64尺寸、4096个PE的配置下，DiP实现了8.192 TOPS的峰值吞吐量和9.548 TOPS/W的能效。

**Conclusion:** DiP架构通过其创新的数据流和FIFO消除机制，显著提升了矩阵乘法加速器的吞吐量和能效，展现出优异的可扩展性，特别适合Transformer等高性能AI模型。

> **ai_Abstract:** 本文提出了一种名为DiP（Diagonal-Input and Permutated weight stationary）的新型脉动阵列架构，旨在加速矩阵乘法，尤其针对Transformer模型。DiP通过创新性地消除传统脉动阵列中用于输入输出同步的FIFO，并优化数据流，显著提升了计算资源利用率、吞吐量和能效。实验结果表明，DiP在吞吐量、每面积能效以及对Transformer工作负载的性能上均优于现有架构，最高可实现50%的吞吐量提升和2.02倍的每面积能效提升。

> **摘要翻译:** Transformer模型因其出色的准确性在自然语言处理（NLP）应用领域受到越来越多的关注。然而，这些数据密集型模型对现有计算架构提出了显著的性能要求。脉动阵列架构，如谷歌TPU等商用AI计算平台所采用的，提供了高能效的数据重用，但由于通过先进先出（FIFO）缓冲器进行输入输出同步，面临吞吐量和能耗损失。本文提出了一种新型可扩展脉动阵列架构，该架构采用对角线输入和置换权重驻留（DiP）数据流，用于矩阵乘法加速。所提出的架构消除了现有最先进权重驻留脉动阵列所需的同步FIFO。除了通过消除这些FIFO实现的面积、功耗和能耗节省外，DiP架构还最大限度地提高了计算资源利用率，与传统权重驻留架构相比，吞吐量提升高达50%。本文为权重驻留和DiP架构开发了分析模型，包括延迟、吞吐量、PE完全利用时间（TFPU）和FIFO开销。使用22纳米商用技术进行的全面硬件设计空间探索表明，DiP具有可扩展性优势，每单位面积能效提升高达2.02倍。此外，DiP在广泛使用的模型中的Transformer工作负载上表现优于类TPU架构，能效提升高达1.81倍，延迟提升高达1.49倍。在64x64尺寸、4096个PE的配置下，DiP实现了8.192 TOPS的峰值吞吐量和9.548 TOPS/W的能效。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [289] [GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction](https://arxiv.org/abs/2504.10240)
> *GNN-ACLP：基于图神经网络的模拟电路链路预测*

*Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Zhi Li, Yugui Lin, Pietro Lio, Shuai Wang* | **Category: cs.AR, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 图神经网络, 模拟电路, 链路预测, 网表, 设计自动化

**Comment:** Code and data will be made available on request to the corresponding
  author. V4 Update: Add Future Work; Improve Typesetting

> **TL;DR:** GNN-ACLP提出了一种基于图神经网络的方法，通过引入SEAL框架、Netlist Babel Fish工具和构建SpiceNetlist数据集，解决了模拟电路链路预测中拓扑模式利用不足、数据稀缺和网表格式适应性差的问题，显著提升了预测精度和跨数据集泛化能力。

**AI_Comments:** GNN-ACLP的创新性体现在其多方面的综合解决方案：1) 引入SEAL框架以更有效地利用电路图拓扑信息；2) 提出Netlist Babel Fish，结合LLM和RAG解决网表格式多样性问题，这是将大型语言模型应用于传统工程领域的一个亮点；3) 构建并发布大规模数据集SpiceNetlist，解决了数据稀缺的痛点。这些创新共同提升了模拟电路链路预测的准确性和实用性，对模拟电路设计自动化领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 模拟电路设计自动化中，从不完整的网表中识别缺失的元件连接（电路链路预测）至关重要。然而，现有方法面临三大挑战：1) 未充分利用电路图中的拓扑模式，导致预测精度降低；2) 注释复杂导致数据稀缺，影响模型泛化能力；3) 对各种网表格式的适应性有限。

**Method:** 本文提出了GNN-ACLP，一种基于图神经网络（GNNs）的方法，具有三项创新：1) 引入SEAL（从子图、嵌入和属性中学习进行链路预测）框架，实现端口级精度；2) 提出Netlist Babel Fish，一个利用检索增强生成（RAG）与大型语言模型（LLM）的网表格式转换工具，以提高网表格式的兼容性；3) 构建了SpiceNetlist，一个包含775个带注释电路和10种不同元件类别的综合数据集。

**Result:** 实验表明，在数据集内部评估中，GNN-ACLP在SpiceNetlist上精度提高了16.08%，在Image2Net上提高了11.38%，在Masala-CHAI上提高了16.01%，相比基线有显著提升。在跨数据集评估中，精度保持在92.05%到99.07%之间，展现出强大的特征迁移能力。

**Conclusion:** GNN-ACLP通过创新的GNN方法、数据增强工具和新数据集的构建，有效解决了模拟电路链路预测中的关键挑战，显著提升了预测精度和跨数据集的泛化能力，为模拟电路设计自动化提供了强大的支持。

> **ai_Abstract:** 本文提出GNN-ACLP，一种基于图神经网络的模拟电路链路预测方法，旨在解决现有方法中拓扑信息利用不足、数据稀缺和网表格式兼容性差的问题。GNN-ACLP通过引入SEAL框架实现高精度预测，开发Netlist Babel Fish工具提升网表格式适应性，并构建了大规模SpiceNetlist数据集。实验结果表明，GNN-ACLP在多个数据集上显著提升了预测精度，并展现出强大的跨数据集泛化能力。

> **摘要翻译:** 电路链路预测，即从不完整的网表中识别缺失的元件连接，在模拟电路设计自动化中至关重要。然而，现有方法面临三大主要挑战：1) 未充分利用电路图中的拓扑模式，降低了预测精度；2) 由于注释的复杂性导致数据稀缺，阻碍了模型的泛化能力；3) 对各种网表格式的适应性有限。我们提出了GNN-ACLP，一种基于图神经网络（GNNs）的方法，其具有三项创新来解决这些挑战。首先，我们引入了SEAL（从子图、嵌入和属性中学习进行链路预测）框架，并在电路链路预测中实现了端口级精度。其次，我们提出了Netlist Babel Fish，一个利用检索增强生成（RAG）与大型语言模型（LLM）的网表格式转换工具，以提高网表格式的兼容性。最后，我们构建了SpiceNetlist，一个包含775个带注释电路和10种不同元件类别的综合数据集。实验表明，在数据集内部评估中，GNN-ACLP在SpiceNetlist上精度提高了16.08%，在Image2Net上提高了11.38%，在Masala-CHAI上提高了16.01%，相比基线有显著提升，同时在跨数据集评估中精度保持在92.05%到99.07%之间，展现出强大的特征迁移能力。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [334] [The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts](https://arxiv.org/abs/2507.15465)
> *新型LLM瓶颈：潜注意力与专家混合模型的系统视角*

*Sungmin Yun, Seonyong Park, Hwayong Nam, Younjoo Lee, Gunjun Lee, Kwanhee Kyung, Sangpyo Kim, Nam Sung Kim, Jongmin Kim, Hyungyo Kim, Juhwan Cho, Seungmin Baek, Jung Ho Ahn* | **Category: cs.AR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** LLM瓶颈, 潜注意力, 专家混合, 系统设计, Transformer

**Comment:** 15 pages, 11 figures

> **TL;DR:** 本文认为，多头潜注意力（MLA）和专家混合（MoE）等新型Transformer架构改变了传统注意力机制的计算特性，使其不再是内存瓶颈，从而削弱了对专用注意力硬件的需求。未来的挑战在于设计平衡的系统来管理大规模模型的多元化计算需求。

**AI_Comments:** 这篇论文提出了一个重要的观点转变，挑战了对Transformer模型中注意力机制专用硬件的传统认知。它强调了新型架构如何改变计算特性，将瓶颈从内存密集型注意力转移到更平衡的系统设计。这对于未来LLM硬件和系统架构的发展方向具有指导意义，特别是强调了通用加速器（如GPU）在处理这些新型负载时的潜力，并呼吁关注整体系统平衡而非单一组件优化。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Transformer模型中，多头注意力（MHA）是内存密集型且算术强度低，而前馈层是计算密集型。这种二分法长期以来推动了对专用硬件以缓解MHA瓶颈的研究。本文旨在挑战这一前提，指出新型架构如MLA和MoE改变了这一计算特性。

**Method:** 本文通过分析多头潜注意力（MLA）和专家混合（MoE）这两种新型架构的计算特性来提出论点。具体地，观察到MLA的算术强度比MHA高出两个数量级，使其接近计算密集型；同时，MoE专家通过批处理可以在多个加速器上分布，从而调整其算术强度以匹配密集层，实现更平衡的计算分布。

**Result:** 研究发现，多头潜注意力（MLA）的算术强度比传统多头注意力（MHA）高出两个数量级以上，使其接近计算密集型，更适合现代GPU等加速器。其次，通过在加速器池中分配专家混合（MoE）的专家，其算术强度可以通过批处理进行调整，以匹配密集层的算术强度，从而创建更平衡的计算配置文件。

**Conclusion:** 这些发现表明对专用注意力硬件的需求正在减少。下一代Transformer的核心挑战不再是加速单一内存密集型层。相反，重点必须转向设计具有足够计算能力、内存容量、内存带宽和高带宽互连的平衡系统，以管理大规模模型的多样化需求。

> **ai_Abstract:** 该论文探讨了大型语言模型（LLM）中计算瓶颈的转变。传统Transformer模型中的多头注意力（MHA）是内存密集型瓶颈，但论文指出，新型架构如多头潜注意力（MLA）和专家混合（MoE）改变了这一局面。MLA的算术强度显著提高，使其接近计算密集型，适合现代GPU。MoE则可以通过跨加速器分布和批处理实现计算平衡。因此，论文认为专用注意力硬件的需求正在减弱，未来的挑战在于设计能够平衡处理大规模模型多样化计算需求的通用系统。

> **摘要翻译:** 传统Transformer模型的计算负载明显分为两部分。多头注意力（MHA）是内存密集型的，算术强度低，而前馈层是计算密集型的。这种二分法长期以来推动了对专用硬件以缓解MHA瓶颈的研究。本文认为，最近的架构转变，即多头潜注意力（MLA）和专家混合（MoE），挑战了专用注意力硬件的前提。我们提出了两个关键观察。首先，MLA的算术强度比MHA高出两个数量级以上，使其接近计算密集型状态，非常适合现代加速器如GPU。其次，通过在加速器池中分布MoE专家，可以通过批处理调整其算术强度，以匹配密集层的算术强度，从而创建更平衡的计算配置文件。这些发现揭示了对专用注意力硬件需求的减少。下一代Transformer的核心挑战不再是加速单一内存密集型层。相反，重点必须转向设计具有足够计算能力、内存容量、内存带宽和高带宽互连的平衡系统，以管理大规模模型的多样化需求。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [27] [A large-scale distributed parallel discrete event simulation engines based on Warped2 for Wargaming simulation](https://arxiv.org/abs/2507.18050)
> *基于Warped2的大规模分布式并行离散事件仿真引擎用于兵棋推演仿真*

*Xiaoning Jia, Ruilin Kong, Guangya Si, Bilong Shen, Zhe Ji* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 并行离散事件仿真, 兵棋推演, Warped2, 负载均衡, 空间哈希

**Comment:** 

> **TL;DR:** 该论文提出了一种优化的并行离散事件仿真（PDES）框架，通过引入异步监听线程、METIS负载再平衡、实体交互求解器和空间哈希算法，显著提升了大规模兵棋推演仿真的性能和效率。

**AI_Comments:** 该论文通过针对性地优化Warped2引擎，解决了大规模兵棋推演仿真中的核心性能瓶颈。其创新点在于引入了多项协同机制，包括异步事件监控、动态负载均衡、冲突解决和高效空间搜索，这些都直接对应了实际仿真中的挑战。特别是负载均衡策略的显著贡献，表明了对动态系统行为的深刻理解。这些改进对于提升复杂仿真系统的实用性和可扩展性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有并行离散事件仿真（PDES）引擎，如Warped2，在处理大规模兵棋推演仿真时面临挑战，包括同步过程中逻辑进程（LP）资源分配效率低下以及复杂实体交互模式未得到有效解决，导致可扩展性受限。

**Method:** 本研究提出了一个优化的框架，包含四项协同改进：1) 引入异步监听线程替代同步轮询机制，解决大规模场景下的事件监控延迟问题；2) 结合基于METIS的负载再平衡策略，解决实际仿真中动态事件分配问题；3) 设计带有约束满足机制的实体交互求解器，以缓解状态冲突；4) 采用空间哈希算法克服大规模最近邻搜索中的O(n^2)复杂度瓶颈。

**Result:** 通过GridWorld演示的实验验证表明，该框架显著增强了时间保真度和计算效率。基准测试结果显示，与基线实现相比，该框架实现了16倍的加速，并且在MPI和Pthreads实现中，相对于单线程配置保持了8倍的加速。负载均衡和LP迁移策略的结合使同步开销降低了58.18%，其中负载均衡贡献了总改进的57%，是主要的优化因素。

**Conclusion:** 这些改进为大规模仿真场景中的并行离散事件仿真（PDES）实施提供了增强的解决方案。

> **ai_Abstract:** 该论文提出了一个针对大规模兵棋推演仿真的优化并行离散事件仿真（PDES）框架，旨在解决现有Warped2引擎在资源分配效率和复杂实体交互方面的不足。通过引入异步监听线程、METIS负载再平衡策略、实体交互求解器和空间哈希算法等四项协同改进，该框架显著提升了时间保真度和计算效率。实验结果表明，该框架实现了高达16倍的加速，并有效降低了同步开销，为大规模仿真提供了增强的PDES解决方案。

> **摘要翻译:** 对复杂仿真日益增长的需求凸显了传统引擎的可扩展性限制，这促使了并行离散事件仿真（PDES）的采用。Warped2是一个利用时间扭曲同步和待处理事件集优化的PDES引擎，虽然它提供了强大的性能，但其在固有的兵棋推演限制方面表现不佳：同步过程中LP资源分配效率低下以及复杂实体交互模式未得到解决。为了应对这些挑战，我们提出了一个优化的框架，该框架具有四项协同改进：(1) 引入异步监听线程以解决大规模场景中的事件监控延迟，而不是同步轮询机制；(2) 结合基于METIS的负载再平衡策略以解决实际仿真中动态事件分配的问题；(3) 设计带有约束满足机制的实体交互求解器以缓解状态冲突；(4) 采用空间哈希算法克服大规模最近邻搜索中的O(n^2)复杂度瓶颈。通过GridWorld演示的实验验证证明了时间保真度和计算效率的显著提升。基准测试结果显示，我们的框架比基线实现实现了16倍的加速，并在MPI和Pthreads实现中，相对于1线程配置保持了8倍的加速。负载均衡和LP迁移策略的结合使同步开销降低了58.18%，其中负载均衡贡献了总改进的57%，是主要的优化因素。这些改进为大规模仿真场景中的PDES实施提供了增强的解决方案。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [60] [Towards Designing an Energy Aware Data Replication Strategy for Cloud Systems Using Reinforcement Learning](https://arxiv.org/abs/2507.18459)
> *面向云系统强化学习的节能数据复制策略设计*

*Amir Najjar, Riad Mokadem, Jean-Marc Pierson* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 数据复制, 强化学习, 云系统, 能源感知, 服务质量

**Comment:** 

> **TL;DR:** 本文提出了一种利用强化学习的云系统数据复制策略，旨在自动适应工作负载变化，并在提供满意QoS的同时，优化提供商利润与环境影响之间的权衡。

**AI_Comments:** 该论文的创新点在于将强化学习应用于数据复制策略，以实现动态适应和能源感知。通过自动化地学习系统特性并优化提供商利润与环境影响的权衡，它有望解决传统手动阈值调整的难题，并为云系统的数据管理提供更智能、更可持续的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统的数据复制策略依赖于手动调整的基于阈值的激活机制，难以适应工作负载变化和系统架构差异。为了解决这一挑战，需要一种能够动态适应的策略。

**Method:** 本文提出了一种新颖的云系统数据复制策略，该策略利用强化学习来自动学习系统特性并适应工作负载变化。该策略旨在提供满意的服务质量，同时优化提供商利润和环境影响之间的权衡。文中还介绍了解决方案的架构，并通过定义状态、动作和奖励来描述强化学习模型。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本论文提出了一种创新的云系统数据复制策略，该策略利用强化学习来克服传统阈值方法的局限性，实现对工作负载和系统架构的动态适应。其目标是在保证服务质量的同时，优化提供商利润与环境影响的平衡。论文详细阐述了该策略的架构及强化学习模型（包括状态、动作和奖励的定义）。

> **摘要翻译:** 全球数据量的快速增长对可扩展的分布式系统提出了需求，这些系统需要保持高质量的服务。数据复制是一种广泛使用的技术，可提供容错性、提高性能和更高的可用性。传统的实现通常依赖于基于阈值的激活机制，这些机制会根据工作负载变化和系统架构而有所不同。系统管理员通常负责调整这些阈值。为了应对这一挑战，可以使用强化学习来动态适应工作负载变化和不同的架构。在本文中，我们提出了一种新颖的云系统数据复制策略，该策略采用强化学习来自动学习系统特性并适应工作负载变化。该策略的目标是在提供令人满意的服务质量的同时，优化提供商利润和环境影响之间的权衡。我们介绍了我们解决方案的架构，并通过定义状态、动作和奖励来描述强化学习模型。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [90] [Staleness-Centric Optimizations for Parallel Diffusion MoE Inference](https://arxiv.org/abs/2411.16786)
> *面向并行扩散MoE推理的陈旧性优化*

*Jiajun Luo, Lizhuo Luo, Jianru Xu, Jiajun Song, Rongwei Lu, Chen Tang, Zhi Wang* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** Mixture-of-Experts, Diffusion Models, Parallel Inference, Staleness, Optimization

**Comment:** 

> **TL;DR:** MoE扩散模型在并行推理中存在通信瓶颈和“陈旧性”问题，影响质量。本文提出DICE框架，通过交织并行、选择性同步和条件通信三种策略，有效减少陈旧性，实现1.26倍加速且质量损失极小。

**AI_Comments:** 这篇论文的创新点在于首次明确提出了MoE扩散模型并行推理中的“陈旧性”问题，并提出了一个以解决此问题为核心的优化框架DICE。其三管齐下的方法，特别是“交织并行”能在不增加额外开销的情况下减半陈旧性，以及“条件通信”的训练无关性，都显示了其方法设计的巧妙和实用性。该研究对于提升大规模MoE扩散模型的推理效率和质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于专家混合（MoE）的扩散模型在高保真图像生成中具有可扩展性，但其专家并行化引入了通信瓶颈。现有方法通过计算-通信重叠（位移并行）缓解了开销，但我们发现这些技术会导致严重的“陈旧性”（即使用来自先前时间步的过时激活），这会显著降低质量，尤其是在专家并行场景中。本研究旨在解决这一根本性矛盾。

**Method:** 本文提出了DICE，一个以陈旧性为中心的优化框架，采用三方面方法：（1）交织并行：引入交错流水线，有效地将步级陈旧性免费减半；（2）选择性同步：在层级操作，保护易受陈旧激活影响的层；（3）条件通信：一种令牌级、无需训练的方法，根据令牌重要性动态调整通信频率。

**Result:** 这些策略共同有效地减少了陈旧性，实现了1.26倍的加速，同时质量下降极小。

**Conclusion:** 实验结果表明DICE是一个有效且可扩展的解决方案。

> **ai_Abstract:** 该论文针对基于MoE的扩散模型在并行推理中因专家并行导致的通信瓶颈和“陈旧性”问题，提出了DICE框架。DICE通过交织并行、选择性同步和条件通信三项创新策略，有效减少了使用过时激活导致的质量下降。实验结果表明，DICE在实现1.26倍加速的同时，保持了最小的质量损失，证明了其作为一种有效且可扩展的解决方案的潜力。

> **摘要翻译:** 基于专家混合（MoE）的扩散模型在高保真图像生成中展现出卓越的可扩展性，但其对专家并行化的依赖引入了关键的通信瓶颈。最先进的方法通过计算-通信重叠（称为位移并行）来缓解并行扩散推理中的此类开销。然而，我们发现这些技术会引起严重的“陈旧性”——即使用来自先前时间步的过时激活，这会显著降低质量，尤其是在专家并行场景中。我们解决了这一根本性矛盾，并提出了DICE，一个以陈旧性为中心的优化框架，采用三方面方法：（1）交织并行引入交错流水线，有效地将步级陈旧性免费减半；（2）选择性同步在层级操作，保护易受陈旧激活影响的层；（3）条件通信是一种令牌级、无需训练的方法，根据令牌重要性动态调整通信频率。总的来说，这些策略有效地减少了陈旧性，实现了1.26倍的加速，同时质量下降极小。实验结果表明DICE是一个有效且可扩展的解决方案。我们的代码已在https://github.com/Cobalt-27/DICE 公开。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [120] [Distributed Load Balancing with Workload-Dependent Service Rates](https://arxiv.org/abs/2411.17103)
> *具有工作负载相关服务速率的分布式负载均衡*

*Wenxin Zhang, Santiago R. Balseiro, Robert Kleinberg, Vahab Mirrokni, Balasubramanian Sivan, Bartek Wydrowski* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 分布式负载均衡, 工作负载相关服务速率, GMSR策略, 流体模型, 排队系统

**Comment:** 

> **TL;DR:** 该研究提出了一种名为GMSR的闭环策略，用于在具有工作负载相关服务速率的异构后端系统中进行分布式负载均衡，旨在最小化平均延迟并实现全局收敛到最优路由，即使在过载情况下也能优化吞吐量和后端稳定性。

**AI_Comments:** 该论文的创新之处在于提出了GMSR闭环策略，解决了在分布式、异构且具有工作负载相关服务速率的系统中，前端独立操作下如何实现有效负载均衡的问题。其理论分析严谨，通过流体模型证明了策略的收敛性和次优性，并在过载情况下展示了其对系统性能的优化能力，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在具有异构后端和工作负载相关服务速率的双向队列系统中，前端独立运行且没有通信，目标是最小化所有作业的预期平均延迟。

**Method:** 提出了一种名为“最大边际服务速率”（GMSR）的闭环策略，该策略无需了解到达率即可实现有效协调。在离散时间随机模型中，证明了该路由策略的行为在作业大小趋于零且作业到达率按比例缩放时（使每单位时间到达的作业总预期量保持固定）几乎必然收敛到流体模型的行为。在流体状态下，证明了该策略可以在$O(\delta + \log{1/\epsilon})$时间内从$\delta$-次优初始工作负载达到$\epsilon$-次优解，这意味着全局收敛到集中协调的最优路由。

**Result:** 在流体状态下，GMSR策略能从$\delta$-次优初始工作负载在$O(\delta + \log{1/\epsilon})$时间内达到$\epsilon$-次优解，这意味着全局收敛到集中协调的最优路由。当系统过载时，GMSR策略按字典序最大化吞吐量，最大化稳定后端数量，并最小化其集体工作负载。

**Conclusion:** GMSR策略在分布式负载均衡系统中表现出色，能够有效协调并实现全局最优路由，即使在过载情况下也能优化系统性能。

> **ai_Abstract:** 该论文研究了在具有工作负载相关服务速率的异构后端分布式负载均衡系统中的作业路由问题。系统由任意二分图表示连接性，前端独立运行，目标是最小化作业的平均延迟。论文提出了一种名为GMSR的闭环策略，该策略无需了解到达率即可实现有效协调。在离散时间随机模型中，GMSR策略的行为被证明在特定条件下收敛到流体模型。在流体状态下，该策略能够快速达到次优解并实现全局收敛到集中协调的最优路由。此外，当系统过载时，GMSR策略能够最大化吞吐量、稳定后端数量，并最小化后端集体工作负载。

> **摘要翻译:** 我们研究了双向排队系统中的分布式负载均衡，其中前端将作业路由到具有工作负载相关服务速率的异构后端。系统的连接性——由数据驻留或资源要求等兼容性约束决定——由任意二分图表示。每个前端独立运行，不与其他前端通信，目标是最小化所有作业的预期平均延迟。我们提出了一种名为“最大边际服务速率”（GMSR）的闭环策略，该策略无需了解到达率即可实现有效协调。
在离散时间随机模型中，我们证明了我们的路由策略的行为在作业大小趋于零且作业到达率按比例缩放时（使每单位时间到达的作业总预期量保持固定）几乎必然收敛到流体模型的行为。然后，在流体状态下，我们证明该策略可以在$O(\delta + \log{1/\epsilon})$时间内从$\delta$-次优初始工作负载达到$\epsilon$-次优解，这意味着全局收敛到集中协调的最优路由。最后，我们分析了系统过载时的流体模型。我们表明GMSR按字典序最大化吞吐量，最大化稳定后端数量，并最小化其集体工作负载。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [299] [Incentivised Orchestrated Training Architecture (IOTA): A Technical Primer for Release](https://arxiv.org/abs/2507.17766)
> *激励式编排训练架构 (IOTA)：发布技术入门*

*Felix Quinque, Alan Aboudib, Szymon Fonau, Rodrigo Lopez Portillo Alcocer, Brian McCrindle, Steffen Cruz* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 分布式训练, 大型语言模型, 区块链, 去中心化, 激励机制

**Comment:** 

> **TL;DR:** IOTA 是一个解决分布式 LLM 预训练中模型大小限制和奖励不公问题的新架构，通过协同训练和精细激励实现可扩展的、公平的 LLM 训练。

**AI_Comments:** IOTA的创新之处在于其将去中心化LLM训练中的竞争关系转化为协作关系，并通过一系列技术突破解决了分布式训练中的核心难题，如模型扩展性、通信效率和公平激励。特别是激活压缩和蝶形全归约在提高训练速度和可扩展性方面具有重要意义。CLASP机制也为复杂的分布式贡献归因提供了新的思路。该架构有望推动去中心化AI训练的进一步发展，降低LLM训练的门槛。

<details>
  <summary>Details</summary>

**Motivation:**  Bittensor的子网9（SN9）虽然验证了基于区块链的去中心化LLM预训练是可行的，但存在核心问题：(i) 每个矿工必须在本地适应一个完整的模型；(ii) “赢者通吃”的奖励机制鼓励模型囤积。

**Method:** IOTA 通过将SN9中先前孤立的竞争者转变为一个可以任意扩展同时仍公平奖励每个贡献者的单一协作单元来解决上述限制。其关键组成部分包括：数据和流水线并行SWARM架构，实现模型层分发和激活流式传输；细粒度、持续激励，按贡献比例分配代币；激活压缩，将通信带宽减少高达128倍；蝶形全归约，实现O(1)带宽的参数平均；以及CLASP方案，公平归因并检测漏洞。

**Result:** IOTA实现了模型大小随参与者数量扩展，突破了单机VRAM限制。通过细粒度激励确保了公平的贡献奖励。激活压缩将通信带宽减少高达128倍，显著提高了训练速度。蝶形全归约提供了线性可扩展性、冗余和内置串通检测。CLASP确保了公平的贡献归因并能检测漏洞。

**Conclusion:** IOTA通过将独立的参与者转变为一个协作单元，解决了分布式LLM预训练中模型大小限制和奖励分配不公的核心问题，实现了可扩展、高效且公平的去中心化训练。

> **ai_Abstract:** IOTA（激励式编排训练架构）旨在解决现有分布式大型语言模型（LLM）预训练（如Bittensor SN9）中存在的模型规模受限和奖励分配不公问题。IOTA通过将独立的训练参与者转化为一个协同工作单元，实现了模型训练的可任意扩展性，并确保公平的贡献奖励。其核心创新包括数据和流水线并行SWARM架构、细粒度持续激励机制、高效的激活压缩技术、线性的蝶形全归约以及公平的CLASP贡献评估方案，这些技术共同提升了去中心化LLM训练的可扩展性、效率和公平性。

> **摘要翻译:** 2024年8月，Bittensor的子网9（SN9）证明了一个由激励的、无需许可的参与者组成的分布式网络可以预训练从7亿到140亿参数不等的大型语言模型（LLMs），同时超越了既定基线。虽然这项工作验证了基于区块链的去中心化预训练是可行的，但它存在核心问题：（i）每个矿工必须在本地适应一个完整的模型，以及（ii）“赢者通吃”的奖励机制鼓励模型囤积。
在此，我们介绍了IOTA（激励式编排训练架构），一个通过将SN9先前孤立的竞争者转变为一个可以任意扩展同时仍公平奖励每个贡献者的单一协作单元来解决这些限制的架构。
主要初步结果：（1）数据和流水线并行SWARM架构——一个编排器将模型层分发给异构矿工，并在它们之间流式传输激活，使模型大小能够随参与者数量扩展，而不是受限于单台机器的显存；（2）细粒度、持续激励——验证器衡量每个矿工的贡献并按比例分配代币排放；（3）激活压缩——我们使用模型瓶颈将激活的通信带宽减少高达128倍，大大提高了训练速度；（4）蝶形全归约——矿工以O(1)带宽平均不相交的参数切片，提供线性可扩展性、冗余和内置串通检测；（5）CLASP（通过路径采样评估贡献损失）——一个公平的归因方案，即使贡献在整个流水线中相互依赖，也能根据矿工的边际效用按比例分配信用并检测漏洞。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [344] [PolyServe: Efficient Multi-SLO Serving at Scale](https://arxiv.org/abs/2507.17769)
> *PolyServe：大规模高效多SLO服务*

*Kan Zhu, Haiyang Shi, Le Xu, Jiaxin Shan, Arvind Krishnamurthy, Baris Kasikci, Liguang Xie* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-17**

**Keywords:** LLM服务, 多SLO调度, 吞吐量优化, 尾部延迟控制, 自动扩展

**Comment:** 

> **TL;DR:** PolyServe是一种新颖的多SLO调度策略，旨在解决LLM应用中多样化延迟要求带来的挑战，通过分组、路由和动态调整，显著提高了吞吐量和SLO达成率。

**AI_Comments:** PolyServe的创新之处在于其对多SLO LLM服务挑战的全面解决，特别是通过引入细粒度的请求分组、智能的负载梯度路由和跨SLO层资源共享，有效平衡了SLO达成率和系统吞吐量。其对尾部延迟的精细控制，通过请求等待时间感知调度、动态分块和连续分块预填充预测，展现了对实际部署中关键性能指标的关注。该工作对于优化LLM服务基础设施的效率和用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM应用具有多样化的令牌生成延迟要求，简单地将工作负载分为延迟敏感型（LS）或尽力而为型（BE）会忽略LS类别中的细微差别，导致用户体验和调度机会不佳。为具有多个服务水平目标（SLO）要求的请求提供高效服务面临挑战：批量请求同时生成新令牌导致与SLO不匹配；现有系统侧重于整体请求率的自动扩展，而多样化的SLO需要更细粒度的自动扩展；不同延迟敏感型SLO的请求无法容忍长时间延迟，尾部延迟必须得到控制。

**Method:** PolyServe是一种新颖的大规模多SLO调度策略，旨在保持高SLO达成率的同时最大化吞吐量。它首先根据每个令牌的延迟要求将请求分组到多个桶中，然后将每个桶调度到服务器集群的子集。PolyServe将请求路由到负载最高但仍能达到SLO的服务器，以创建有利于自动扩展的负载梯度。为提高利用率，当自身服务器饱和时，PolyServe允许较宽松SLO的请求共享较严格SLO的实例。PolyServe利用分析数据指导调度决策，并通过请求等待时间感知调度、动态分块和连续分块预填充预测来管理尾部延迟。

**Result:** PolyServe相比现有策略实现了1.23倍的良好吞吐量增益，达到了最优良好吞吐量的92.5%。

**Conclusion:** PolyServe有效解决了大规模LLM服务中多SLO请求的调度挑战，显著提高了吞吐量和SLO达成率，为多样化延迟需求的LLM应用提供了高效的服务解决方案。

> **ai_Abstract:** 本文提出了PolyServe，一种针对大规模LLM应用的新型多SLO调度策略，旨在解决现有方法在处理多样化延迟要求时的不足。PolyServe通过将请求按每令牌延迟分组、智能路由到负载最高但仍能满足SLO的服务器、允许宽松SLO请求共享资源，并利用分析数据进行尾部延迟管理，显著提高了系统吞吐量和SLO达成率。实验结果显示，PolyServe比现有策略实现了1.23倍的良好吞吐量增益，达到最优的92.5%。

> **摘要翻译:** 大型语言模型（LLM）的进步导致了LLM驱动应用程序的激增。这些应用程序具有多样化的令牌生成延迟要求。因此，简单地将工作负载分类为延迟敏感型（LS）或尽力而为型（BE）会忽略延迟敏感型类别中的细微差别，并导致次优的用户体验和调度机会。然而，高效地为具有多个服务水平目标（SLO）要求的请求提供服务带来了重大挑战。首先，批处理中的所有请求同时生成新令牌，这可能导致它们与其不同的SLO要求不匹配。此外，尽管现有系统侧重于自动扩展以处理各种整体请求率，但SLO的多样性需要这些SLO层之间进行细粒度的自动扩展。最后，与LS/BE场景不同，在这些场景中，BE请求可以随时中止以确保LS请求的SLO达成，而具有不同延迟敏感SLO的请求无法容忍长时间延迟，并且必须控制尾部延迟。
为了应对这些挑战，我们提出了PolyServe，一种新颖的大规模多SLO调度策略，它在最大化吞吐量的同时保持高SLO达成率。PolyServe首先根据每个令牌的延迟要求将请求分组到多个桶中，然后将每个桶调度到服务器集群的子集。PolyServe将请求路由到负载最高但仍能达到SLO的服务器，以创建有利于自动扩展的负载梯度。为提高利用率，当自身服务器饱和时，PolyServe允许较宽松SLO的请求共享较严格SLO的实例。PolyServe利用分析数据指导调度决策，并通过请求等待时间感知调度、动态分块和连续分块预填充预测来管理尾部延迟。PolyServe相比现有策略实现了1.23倍的良好吞吐量增益，达到了最优良好吞put的92.5%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [392] [Comparative Evaluation of PyTorch, JAX, SciPy, and Neal for Solving QUBO Problems at Scale](https://arxiv.org/abs/2507.17770)
> *PyTorch、JAX、SciPy 和 Neal 求解大规模 QUBO 问题的比较评估*

*Pei-Kun Yang* | **Category: cs.DC, quant-ph** | **Updated: 2025-07-17**

**Keywords:** QUBO, 组合优化, PyTorch, JAX, SciPy, Neal, 性能评估, 可扩展性

**Comment:** 14 pages, 5 figures

> **TL;DR:** 本研究比较了PyTorch、JAX、SciPy和Neal在解决大规模二次无约束二元优化（QUBO）问题上的性能，发现PyTorch在可扩展性和运行时效率上表现最佳，是处理大规模QUBO问题的平衡选择。

**AI_Comments:** 这项研究通过对不同QUBO求解器在实际大规模问题上的性能进行详细基准测试，提供了宝贵的实践指导。其创新点在于对多种流行机器学习框架（PyTorch, JAX）与传统科学计算库（SciPy）和专用求解器（Neal）在解决特定优化问题上的直接比较。研究结果强调了在选择求解器时，需要在解决方案质量、可扩展性和计算效率之间进行权衡，并明确指出PyTorch在处理大规模QUBO问题时的优势，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 二次无约束二元优化（QUBO）是建模组合优化问题的通用框架。为了帮助用户选择合适的工具，本研究旨在对不同的软件QUBO求解器在大规模问题上的性能进行基准测试，以评估它们在解决方案质量、可扩展性和运行时效率之间的权衡。

**Method:** 本研究对Neal、PyTorch (CPU)、PyTorch (GPU)、JAX和SciPy这五种软件QUBO求解器进行了基准测试。测试使用了随机生成的1000x1000到45000x45000的QUBO矩阵，并在六个从10^-1到10^-6的收敛阈值下进行。性能评估指标包括解决方案质量（能量）和计算时间。

**Result:** 在测试的求解器中：Neal实现了最低的能量值，但由于高内存消耗，仅限于处理多达6000变量的问题。PyTorch产生的能量结果略高于Neal，但展现出卓越的可扩展性，能够解决多达45000变量的实例，并因支持GPU加速和CPU多线程而显著缩短了运行时间。JAX产生的能量值略高于PyTorch，受限于25000变量，运行时间与PyTorch在GPU上相当。SciPy是限制最多的求解器，只能处理多达6000变量，并且持续产生最高的能量值和最长的计算时间。

**Conclusion:** 研究结果突出了解决方案质量、可扩展性和运行时效率之间的权衡。在计算资源允许的情况下，PyTorch被认为是解决大规模QUBO问题的最平衡选择。

> **ai_Abstract:** 本文比较了Neal、PyTorch (CPU/GPU)、JAX和SciPy五种软件求解器在解决大规模二次无约束二元优化（QUBO）问题上的性能。研究评估了它们在不同规模（1000x1000至45000x45000矩阵）和收敛阈值下的解决方案质量（能量）和计算时间。结果显示，Neal提供了最佳解质量但可扩展性差；SciPy性能最差；JAX性能中等；而PyTorch在可扩展性、运行时效率和解质量之间取得了最佳平衡，尤其是在GPU加速下，使其成为处理大规模QUBO问题的首选。

> **摘要翻译:** 二次无约束二元优化（QUBO）是建模组合优化问题的通用框架。本研究对五种基于软件的QUBO求解器进行了基准测试：Neal、PyTorch (CPU)、PyTorch (GPU)、JAX和SciPy，测试对象是随机生成的1000x1000到45000x45000的QUBO矩阵，并在六个从10^-1到10^-6的收敛阈值下进行。我们评估了它们在解决方案质量（能量）和计算时间方面的性能。在测试的求解器中，Neal实现了最低的能量值，但由于高内存消耗，仅限于处理多达6000变量的问题。PyTorch产生的能量结果略高于Neal，但显示出卓越的可扩展性，能够解决多达45000变量的实例。它对GPU加速和CPU多线程的支持也显著缩短了运行时间。JAX产生的能量值略高于PyTorch，受限于25000变量，运行时间与PyTorch在GPU上相当。SciPy是限制最多的求解器，只能处理多达6000变量，并且持续产生最高的能量值和最长的计算时间。这些发现突出了解决方案质量、可扩展性和运行时效率之间的权衡，并表明在计算资源允许的情况下，PyTorch是解决大规模QUBO问题的最平衡选择。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [440] [Flexible Vector Integration in Embedded RISC-V SoCs for End to End CNN Inference Acceleration](https://arxiv.org/abs/2507.17771)
> *嵌入式RISC-V SoC中用于端到端CNN推理加速的灵活向量集成*

*Dmitri Lyalikov* | **Category: cs.DC, eess.IV** | **Updated: 2025-07-19**

**Keywords:** RISC-V Vector, CNN推理, 嵌入式SoC, 深度学习加速器, 硬件集成

**Comment:** 

> **TL;DR:** 本研究利用RISC-V Vector 1.0扩展，通过优化缓存层次结构，解决了嵌入式SoC中CNN推理的硬件集成挑战和预处理瓶颈，实现了图像预处理高达9倍以及YOLOv3回退层执行高达3倍的加速，并提供了一种功耗更低的灵活编程模型。

**AI_Comments:** 本论文的创新之处在于其对CNN端到端推理过程的关注，特别是解决了常被忽视的预处理和CPU回退层的性能瓶颈。通过利用RISC-V Vector 1.0这一新兴且灵活的指令集，论文展示了在嵌入式SoC中实现高效硬件集成和平衡计算的潜力。这对于在边缘设备上部署深度学习模型具有重要意义，因为它不仅关注加速器本身的性能，更强调了整个系统集成和优化。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的嵌入式平台上部署现代CNN面临挑战，需要异构和领域特定架构（如DLA和NPU）来克服传统硅扩展的限制并解决功耗/性能权衡。现有研究多关注加速器本身，但端到端CNN推理中的系统集成、编译/执行模型以及预处理和CPU回退过程中的性能瓶颈是关键挑战。

**Method:** 本研究通过实验验证了CNN执行、预处理和后处理运行时的性能瓶颈。利用RISC-V Vector 1.0扩展，结合优化的缓存层次结构，旨在减少预处理瓶颈和CPU回退过程。该方法旨在展示RVV-1.0作为灵活目标，实现计算和内存占用的平衡。

**Result:** 结果显示，图像预处理速度提升高达9倍，YOLOv3回退层执行速度比CPU快3倍。该方法在支持现代深度学习数据流的富加速器嵌入式SoC上实现了计算和内存占用的平衡，同时比传统并行执行平台功耗更低。

**Conclusion:** RISC-V Vector 1.0扩展提供了一个灵活的编程模型，能够有效解决嵌入式SoC中CNN推理的硬件集成和预处理瓶颈，在实现高性能的同时降低功耗，并支持现代深度学习数据流。

> **ai_Abstract:** 本论文探讨了在嵌入式RISC-V SoC中集成向量单元以加速端到端CNN推理的挑战与解决方案。研究指出，在资源受限的嵌入式平台上部署CNN需要高效的硬件集成和平衡的执行模型，尤其是在预处理和CPU回退层方面存在性能瓶颈。通过利用RISC-V Vector 1.0扩展和优化的缓存层次结构，该工作成功地将图像预处理速度提高了9倍，YOLOv3回退层执行速度比CPU快了3倍。研究证明了RISC-V向量扩展提供了一个灵活且功耗更低的编程模型，适用于加速器丰富的嵌入式系统中的深度学习工作负载。

> **摘要翻译:** 异构性和针对深度学习推理的领域特定架构的出现，为在资源受限的嵌入式平台上部署现代CNNs展现了巨大潜力。一个重要的发展是专门针对CNNs最昂贵部分的定制硬件多样化。DLA（深度学习加速器）和NPU（神经网络处理单元）等可以克服传统硅扩展的局限，为嵌入式SoCs内的功耗/性能权衡提供解决方案。高效的DSA利用需要适当的系统集成和编译/执行模型，以在这些异构架构中实现平衡执行。对于这些异构架构中平衡执行的适当系统集成和高效编译/执行模型存在关键需求。这项工作强调了将这些单元有效放置在内存层次结构中并使其与其它执行块保持正确接近度的硬件集成挑战。我们通过实验验证了CNN执行以及运行时预处理/后处理的性能瓶颈，而此前通常只关注加速器加速。这项工作利用了RISC-V Vector 1.0扩展的批准，并展示了其作为在良好适配的缓存层次结构方案中灵活目标的潜力，以减少预处理瓶颈和CPU回退过程。我们的结果显示，图像预处理速度比CPU提高了9倍，YOLOv3回退层执行速度提高了3倍。我们展示了RVV-1.0在提供灵活编程模型方面的能力，该模型可以在富加速器嵌入式SoCs上实现平衡的计算和内存占用，支持现代深度学习数据流，同时比传统并行执行平台消耗更少的功耗。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [488] [CHAMP: A Configurable, Hot-Swappable Edge Architecture for Adaptive Biometric Tasks](https://arxiv.org/abs/2507.17793)
> *CHAMP：一种用于自适应生物识别任务的可配置热插拔边缘架构*

*Joel Brogan, Matthew Yohe, David Cornett* | **Category: cs.DC** | **Updated: 2025-07-23**

**Keywords:** 边缘计算, 生物识别, FPGA, 模块化架构, 热插拔

**Comment:** 

> **TL;DR:** CHAMP是一种模块化的边缘计算平台，允许用户动态更换AI能力模块，以适应面部识别、对象跟踪和文档分析等任务。它利用低功耗FPGA加速器和自定义操作系统VDiSK，实现了即插即用的AI管道和加密保护的生物识别数据集。实验表明其吞吐量接近线性扩展。

**AI_Comments:** CHAMP的创新之处在于其模块化和热插拔设计，使得边缘AI系统能够像乐高积木一样灵活配置，极大地提高了现场部署的适应性。其结合FPGA加速器和自定义OS的架构，在实现高性能的同时兼顾了低功耗和数据安全。性能验证方面，展示了良好的扩展性，但同时也指出了总线饱和的限制，为未来改进提供了方向。该系统对于需要快速适应不同AI任务的野外或应急场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有技术需要灵活、高性能的边缘AI系统，能够即时适应现场操作员的需求。本论文旨在提供一种像乐高积木一样可自由组装的定制生物识别和AI分析系统。

**Method:** 本文介绍了CHAMP（可配置热插拔机器感知架构），一个模块化边缘计算平台。它允许操作员动态插入专用AI“能力模块”，用于面部识别、对象跟踪和文档分析等任务。CHAMP利用基于低功耗FPGA的加速器和高吞吐量总线，并通过自定义操作系统VDiSK进行编排，以实现即插即用的AI管道和加密保护的生物识别数据集。论文描述了CHAMP的设计，包括其与多个加速器的模块化扩展以及用于运行时重新配置的VDiSK操作系统，以及其加密能力以确保模块上存储的数据安全和私密。

**Result:** 实验表明，从1到5个神经网络计算加速器，吞吐量实现了接近线性的扩展。这突出了性能增益和基于USB3的总线的饱和限制。

**Conclusion:** CHAMP平台在现场生物识别、监控和灾难响应等领域具有应用前景。未来的改进将集中在总线协议、模块能力和系统软件方面。

> **ai_Abstract:** CHAMP是一个模块化、可热插拔的边缘计算平台，旨在为现场操作员提供灵活、高性能的AI系统。它通过允许动态更换AI能力模块（如面部识别、对象跟踪）来适应不同任务。该系统利用低功耗FPGA加速器、高吞吐量总线和自定义VDiSK操作系统，支持即插即用的AI管道和加密安全的数据集。实验证明了其吞吐量的近线性扩展能力，并在现场生物识别、监控和灾难响应中展现了应用潜力。

> **摘要翻译:** 如果你能像乐高积木一样，自己组装定制的生物识别和AI分析系统会怎么样？我们的目标是将这项技术带给现场操作人员，他们需要灵活、高性能、能够即时适应的边缘AI系统。本文介绍了CHAMP（可配置热插拔机器感知架构），一个模块化边缘计算平台，允许操作员动态地插入专门的AI“能力模块”，用于面部识别、对象跟踪和文档分析等任务。CHAMP利用高吞吐量总线上的低功耗FPGA加速器，并通过自定义操作系统（VDiSK）进行协调，以实现即插即用的AI管道和加密保护的生物识别数据集。在本文中，我们描述了CHAMP的设计，包括其与多个加速器的模块化扩展和用于运行时重新配置的VDiSK操作系统，以及其加密能力以确保模块上存储的数据安全和私密。实验表明，从1到5个神经网络计算加速器，吞吐量实现了接近线性的扩展，突出了性能增益和基于USB3的总线的饱和限制。最后，我们讨论了CHAMP在现场生物识别、监控和灾难响应中的应用，并概述了总线协议、模块能力和系统软件方面的未来改进。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [491] [Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments](https://arxiv.org/abs/2507.17772)
> *物联网环境中联邦学习通信成本降低的缓存技术*

*Ahmad Alhonainy, Praveen Rao* | **Category: cs.DC, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-19**

**Keywords:** 联邦学习, 缓存, 物联网, 通信成本, 模型更新

**Comment:** Journal

> **TL;DR:** 本文提出FIFO、LRU和优先级缓存策略，通过选择性转发重要模型更新来减少联邦学习在物联网环境中的通信成本，同时保持模型精度。

**AI_Comments:** 该论文通过引入智能缓存策略来解决联邦学习在物联网环境中面临的关键通信成本挑战，具有重要的实用价值。其创新点在于将传统缓存机制应用于联邦学习的模型更新传输，有效地在通信效率和模型精度之间取得了平衡。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）尽管允许分布式设备共同训练模型而无需集中数据，但通信成本仍然是一个主要瓶颈，尤其是在资源受限的环境中。

**Method:** 本文引入了FIFO、LRU和基于优先级的缓存策略，通过选择性地转发重要的模型更新来减少不必要的模型更新传输。

**Result:** 在CIFAR-10和医疗数据集上的实验表明，通信量减少且精度损失极小。结果证实，智能缓存提高了可扩展性、内存效率，并支持边缘物联网网络中可靠的联邦学习。

**Conclusion:** 智能缓存技术使联邦学习在智能城市、医疗保健和其他延迟敏感应用中的部署变得可行。

> **ai_Abstract:** 本文提出并评估了针对物联网环境中联邦学习的缓存策略（包括FIFO、LRU和优先级缓存），旨在通过选择性地传输重要的模型更新来降低通信成本。实验结果表明，这些策略在减少通信量的同时保持了模型精度，从而提高了联邦学习在资源受限边缘网络中的可伸缩性和效率，使其适用于智能城市和医疗保健等应用。

> **摘要翻译:** 联邦学习（FL）允许多个分布式设备在不集中数据的情况下共同训练共享模型，但通信成本仍然是一个主要瓶颈，尤其是在资源受限的环境中。本文介绍了缓存策略——FIFO、LRU和基于优先级的——以减少不必要的模型更新传输。通过选择性地转发重要的更新，我们的方法降低了带宽使用，同时保持了模型精度。在CIFAR-10和医疗数据集上的实验显示，通信量减少且精度损失极小。结果证实，智能缓存提高了可扩展性、内存效率，并支持边缘物联网网络中可靠的FL，使其在智慧城市、医疗保健和其他延迟敏感应用中具有实用性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [542] [Optimizing Edge Gaming Slices through an Enhanced User Plane Function and Analytics in Beyond-5G Networks](https://arxiv.org/abs/2507.17843)
> *通过增强用户面功能和分析优化超5G网络中的边缘游戏切片*

*Bruno Marques da Silva, Larissa Ferreira Rodrigues Moreira, Flávio de Oliveira Silva, Rodrigo Moreira* | **Category: cs.DC** | **Updated: 2025-07-23**

**Keywords:** 边缘游戏, 用户面功能, 网络数据分析功能, 延迟测量, 5G

**Comment:** 

> **TL;DR:** 该论文提出了一种集成了NWDAF和UPF的闭环架构，用于在超5G网络中估计用户延迟，并通过嵌入AI模型实现游戏分类，以优化边缘游戏切片。

**AI_Comments:** 这篇论文的创新点在于提出了NWDAF与UPF的闭环集成架构，以实现非侵入式用户延迟测量，并使控制平面具备延迟感知能力。此外，将AI模型嵌入NWDAF进行游戏分类，也为边缘游戏优化提供了新的视角和研究方向。该方法对于提升超5G网络中边缘游戏的QoE（体验质量）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最新一代的游戏和普及的通信技术对移动用户的服务管理和服务水平协议合规性提出了挑战。尽管现有边缘游戏技术能提升吞吐量、降低延迟并利用云计算，但仍需要进一步开发用户面功能（UPF）等核心功能，以实现无侵入的用户延迟测量。

**Method:** 本文提出了一种集成了网络数据分析功能（NWDAF）和用户面功能（UPF）的闭环架构，旨在估计用户延迟并使5G控制平面具备延迟感知能力。此外，该方法在NWDAF中嵌入了一个人工智能模型。

**Result:** 研究结果表明，在NWDAF中嵌入人工智能模型能够实现游戏分类，并为移动边缘游戏研究开辟了新的途径。

**Conclusion:** 通过将NWDAF和UPF集成并嵌入AI模型，可以有效估计用户延迟、增强5G控制平面的延迟感知能力，并实现游戏分类，从而为未来的移动边缘游戏研究奠定基础。

> **ai_Abstract:** 该论文旨在解决超5G网络中边缘游戏服务管理和SLA合规性面临的挑战，特别是在无侵入用户延迟测量方面的不足。为此，作者提出了一种创新的闭环架构，将网络数据分析功能（NWDAF）与增强的用户面功能（UPF）相结合，以准确估计用户延迟并使5G控制平面具备延迟感知能力。研究结果表明，通过在NWDAF中集成人工智能模型，不仅能够有效地进行游戏分类，也为未来移动边缘游戏领域的研究方向提供了新的思路和可能性。

> **摘要翻译:** 最新一代的游戏和普及的通信技术对移动用户的服务管理和服务水平协议（SLA）合规性提出了挑战。最先进的边缘游戏技术能够提高吞吐量、降低延迟并利用云计算。然而，为了实现无侵入的用户延迟测量，用户面功能（UPF）等核心功能仍需进一步发展。本文提出了一种集成了网络数据分析功能（NWDAF）和用户面功能（UPF）的闭环架构，旨在估计用户延迟并通过使其具备延迟感知能力来增强5G控制平面。结果表明，在NWDAF中嵌入人工智能模型能够实现游戏分类，并为移动边缘游戏研究开辟了新的途径。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [597] [PowerTrip: Exploiting Federated Heterogeneous Datacenter Power for Distributed ML Training](https://arxiv.org/abs/2507.17904)
> *PowerTrip：利用联邦异构数据中心电源进行分布式机器学习训练*

*Talha Mehboob, Luanzheng Guo, Nathan Tallent, Michael Zink, David Irwin* | **Category: cs.DC** | **Updated: 2025-07-23**

**Keywords:** 分布式机器学习训练, 异构电源, 数据中心, 功率-通信权衡, PowerTrip

**Comment:** 

> **TL;DR:** PowerTrip是一个系统，旨在优化在地理分布式数据中心进行的大规模机器学习训练，通过动态选择站点来平衡电力可用性和通信开销，与现有基线策略相比，可将达到精度的训练时间缩短高达50%。

**AI_Comments:** 该论文解决了大规模AI训练中一个日益重要且关键的问题，即分布式数据中心之间的电力限制和异构性。其基于功率成本启发式和边际增益的动态站点选择方法，是管理电力-通信权衡的创新方式。使用真实世界电力跟踪数据进行评估，极大地增强了其将达到精度时间缩短高达50%的主张的可信度。这项工作对于提高真实世界资源受限环境中大型模型训练的效率和可扩展性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大规模AI模型的指数级增长导致计算和电力需求可能超过单个数据中心的容量，因为区域电网供电有限。将训练工作负载分布到地理上分散的站点变得至关重要，但这引入了通信开销。现有方法假设电源供应是恒定且同质的，忽略了站点间异构电源可用性的挑战。

**Method:** 本文提出了PowerTrip系统，它在运行时动态选择站点的子集以优化电力-通信权衡。PowerTrip根据功率成本启发式方法选择站点，优先考虑电力可用性高且网络延迟低的站点。它采用动态贪婪方法，并使用训练效率的边际增益（即单位时间内的精度改进）来优化站点数量。

**Result:** 使用真实的谷歌电力跟踪数据进行评估表明，与现有基线策略相比，PowerTrip可以将达到精度的训练时间缩短高达50%。

**Conclusion:** PowerTrip系统通过优化电力-通信权衡，有效解决了在电力受限的地理分布式环境中训练大型机器学习模型的挑战，显著缩短了达到精度的时间。

> **ai_Abstract:** 本文介绍了PowerTrip，一个用于优化地理分布式数据中心大规模机器学习训练的系统。它通过动态选择站点来解决异构电源可用性和通信开销的挑战，利用功率成本启发式方法和动态贪婪策略。PowerTrip优先选择高电力可用性和低网络延迟的站点，旨在最大化训练效率。使用真实世界电力跟踪数据的评估表明，PowerTrip可以将达到精度的训练时间缩短高达50%。

> **摘要翻译:** 大规模AI模型的指数级增长导致计算和电力需求可能超过单个数据中心的容量。这是由于区域电网供电有限，导致区域计算能力受限。因此，将训练工作负载分布到地理上分散的站点变得至关重要。然而，这种方法引入了通信开销这一重大挑战，在获取更大聚合能力带来的性能提升与网络延迟增加带来的性能损失之间造成了根本性的权衡。尽管以往的工作侧重于减少通信量或使用启发式方法进行分布，但这些方法假设电源供应是恒定且同质的，并忽略了站点间异构电源可用性的挑战。
为了解决在电力受限的地理分布式环境中训练大型模型的挑战，我们引入了PowerTrip系统，该系统在运行时动态选择站点的子集，以优化电力-通信权衡。具体来说，PowerTrip根据功率成本启发式方法选择站点，优先选择那些电力可用性高且网络延迟低的站点。PowerTrip采用动态贪婪方法，并使用训练效率的边际增益（即单位时间内的精度改进）来优化站点数量，以避免网络开销带来的性能损失抵消增加更多计算能力带来的好处。我们的评估使用真实的谷歌电力跟踪数据来模拟实际的电力容量限制，结果表明，与现有基线策略相比，PowerTrip可以将达到精度的训练时间缩短高达50%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [638] [Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso](https://arxiv.org/abs/2507.12106)
> *城市绿色治理：物联网驱动的坎波巴索城市绿地管理与提升*

*Antonio Salis, Gabriele Troina, Gianluca Boanelli, Marco Ottaviano, Paola Fortini, Soraya Versace* | **Category: cs.DC, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 城市绿色治理, 物联网, 智慧城市, 绿地管理, 数据驱动

**Comment:** 18 pages, 6 Figures

> **TL;DR:** 该项目在坎波巴索利用物联网和数据驱动平台，实现城市绿地（包括树木）的实时监测、数据分析和智能管理，优化灌溉并提供预警，以支持可持续的城市绿色治理。

**AI_Comments:** 这篇论文的创新点在于将物联网技术、数据驱动的治理平台与机器学习算法相结合，实现了对城市绿地的精细化、实时化管理。其重要性体现在提供了一个实际的“智慧绿色城市”应用案例，展示了技术如何有效提升城市生态系统的管理效率和可持续性，并直接关联到市民的健康福祉。

<details>
  <summary>Details</summary>

**Motivation:** 城市公共绿地的有效设计和管理对促进城市人口健康福祉至关重要，它们是城市生态系统的“绿色之肺”，提供生态服务，提升生活质量。世界卫生组织、联合国环境规划署和欧洲环境署均强调了这一点。

**Method:** 该项目采用先进的集成和可互操作的新兴技术系统，整合物联网系统和数据驱动的治理平台。它通过决策支持系统（DSS）实时监测树木和绿地的健康状况，并收集分析来自不同来源（如天气、空气质量、土壤湿度、污染水平）的数据。利用基于云的平台和Tree Talker传感器，结合土壤湿度和水势监测系统，通过基于机器学习算法的预测模型优化公共公园的灌溉，并提供定制警报。

**Result:** 该项目实现了对城市绿地的实时决策支持和智能控制管理，优化了公共公园的灌溉，并能针对超出预设阈值的参数（如土壤温度、湿度、水势）激活定制警报。

**Conclusion:** 该用例表明，数字化、物联网传感器融合和技术创新能够支持可持续的城市治理，促进环境韧性，并改善市民生活质量。

> **ai_Abstract:** 本文介绍了坎波巴索市的“智慧绿色城市”项目，该项目利用物联网系统和数据驱动的治理平台，实现对城市绿地的可持续管理和增强。通过实时监测树木健康状况、收集环境数据（天气、空气质量、土壤湿度等），并结合机器学习预测模型，该系统能够优化灌溉、提供实时决策支持和定制警报。该案例展示了数字化和物联网技术如何促进可持续城市治理、增强环境韧性并改善居民生活质量。

> **摘要翻译:** 公共绿地的有效设计和管理是促进城市人口健康和福祉的关键因素，世界卫生组织、联合国环境规划署和欧洲环境署都强调了这一点。这些区域是城市生态系统的“绿色之肺”，通过提供生态系统服务，在提高生活质量方面发挥着至关重要的作用。在此背景下，由意大利企业部（MIMIT）资助的坎波巴索市的智慧绿色城市用例，作为一个创新模型出现，通过采用集成和可互操作的先进新兴技术系统，实现城市绿地的可持续管理。该项目整合了物联网系统和数据驱动的治理平台，通过决策支持系统（DSS）实现对树木和绿地健康状况的实时监测。它还促进了来自不同来源（包括天气条件、空气质量、土壤湿度、污染水平）的数据收集和分析。由此产生的基于云的平台支持城市绿地管理者、技术专家和操作人员进行整体实时决策。它通过使用Tree Talker传感器，并与土壤湿度和水势监测系统集成，实现城市绿地的智能控制和管理。得益于基于机器学习算法的预测模型和物联网传感器提供的实时数据，公共公园的灌溉可以得到优化，提供何时以及施用多少水的建议。当监测参数（如土壤温度、湿度或水势）超过预设阈值时，还会激活定制警报层以警告用户。该用例展示了数字化、物联网传感器融合和技术创新如何支持可持续的城市治理，促进环境韧性并改善市民生活质量。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [644] [C-Koordinator: Interference-aware Management for Large-scale and Co-located Microservice Clusters](https://arxiv.org/abs/2507.18005)
> *C-Koordinator：大规模及共置微服务集群的干扰感知管理*

*Shengye Song, Minxian Xu, Zuowei Zhang, Chengxi Gao, Fansong Zeng, Yu Ding, Kejiang Ye, Chengzhong Xu* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 微服务, 干扰管理, 资源共置, CPI, C-Koordinator

**Comment:** 15 pages

> **TL;DR:** C-Koordinator是一个开源平台，通过使用CPI作为干扰测量指标和多维预测模型，实现了大规模共置微服务集群的干扰感知管理，显著降低了应用延迟。

**AI_Comments:** 本文的创新点在于提出了C-Koordinator平台，并特别强调了在实际生产环境中（阿里巴巴）采用CPI作为干扰测量指标及其多维预测方法，这对于大规模微服务集群的资源管理具有重要实践意义。其开源性质也增加了研究的贡献度。该研究解决了共置微服务面临的关键性能挑战，展示了在复杂生产环境中实现高效干扰缓解的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统单体应用转向微服务后，云平台通过共置微服务提升资源利用率，但这引入了资源竞争和干扰。大规模、共置微服务集群的干扰感知策略对于提升资源利用率和减轻干扰至关重要，尤其是在不可靠指标、应用多样性和节点异构性加剧挑战的情况下。

**Method:** 本文首先分析了阿里巴巴大规模共置微服务集群的特性，讨论了为何采用CPI（每指令周期数）作为大规模生产集群的干扰测量指标，以及如何通过多维指标实现CPI的准确预测。基于CPI干扰预测和分析，提出了C-Koordinator平台的设计，这是一个在阿里巴巴集群中使用的开源解决方案，整合了共置和干扰缓解策略。

**Result:** 干扰预测模型准确率超过90.3%，实现了操作环境中干扰的精确预测和快速缓解。与现有最先进系统相比，在各种系统负载下，应用延迟在所有百分位数（P50、P90、P99）响应时间（RT）上均得到降低并稳定，改进范围从16.7%到36.1%。

**Conclusion:** 这些结果表明该系统能够在共置环境中保持流畅的应用性能。

> **ai_Abstract:** 本文针对大规模共置微服务集群中存在的资源竞争和干扰问题，提出了C-Koordinator平台。该平台通过分析阿里巴巴集群特性，创新性地采用CPI作为干扰测量指标，并结合多维指标进行高精度预测。C-Koordinator整合了共置与干扰缓解策略，实验结果表明其干扰预测准确率超90.3%，并能将应用延迟降低16.7%至36.1%，有效提升了共置环境下的应用性能稳定性。

> **摘要翻译:** 微服务将传统的单体应用转化为轻量级、松散耦合的应用组件，并已在许多企业中广泛采用。云平台基础设施提供商通过共置不同的微服务来提高微服务系统的资源利用效率。然而，这种方法也引入了微服务之间的资源竞争和干扰。为大规模、共置微服务集群设计干扰感知策略对于提高资源利用率和减轻竞争引起的干扰至关重要。不可靠的指标、应用多样性和节点异构性进一步加剧了这些挑战。

在本文中，我们首先分析了阿里巴巴大规模共置微服务集群的特性，并进一步讨论了为什么采用每指令周期数（CPI）作为大规模生产集群的干扰测量指标，以及如何通过多维指标实现CPI的准确预测。基于CPI干扰预测和分析，我们还介绍了C-Koordinator平台的设计，这是一个在阿里巴巴集群中使用的开源解决方案，它整合了共置和干扰缓解策略。干扰预测模型始终达到90.3%以上的准确率，从而能够在操作环境中精确预测并快速缓解干扰。因此，在各种系统负载下，与现有最先进系统相比，应用程序延迟在所有百分位数（P50、P90、P99）响应时间（RT）上均得到降低并稳定，实现了16.7%到36.1%的改进。这些结果表明该系统能够在共置环境中保持流畅的应用程序性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [661] [MultiKernelBench: A Multi-Platform Benchmark for Kernel Generation](https://arxiv.org/abs/2507.17773)
> *MultiKernelBench：一个多平台内核生成基准测试*

*Zhongzhen Wen, Yinghui Zhang, Zhong Li, Zhongxin Liu, Linna Xie, Tian Zhang* | **Category: cs.DC, cs.LG, cs.PF, cs.SE** | **Updated: 2025-07-20**

**Keywords:** 深度学习内核生成, LLM, 基准测试, 多平台, MultiKernelBench

**Comment:** 

> **TL;DR:** 引入MultiKernelBench，一个用于LLM生成深度学习内核的多平台基准测试，解决了现有基准测试的局限性，并揭示了LLM在此领域的表现。

**AI_Comments:** 该论文通过引入MultiKernelBench，解决了当前LLM在深度学习内核生成领域评估基准的重大缺陷，特别是其多平台支持和细粒度分类填补了空白。其模块化设计提升了未来研究的灵活性，而类别感知提示方法的提出也为提升LLM生成质量提供了实用策略。这项工作对于推动LLM在高性能计算领域的应用和发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于评估大型语言模型（LLMs）在深度学习（DL）内核生成方面表现的基准测试存在硬件支持有限、内核分类粒度粗糙以及任务覆盖不平衡的问题。本文旨在通过引入MultiKernelBench来解决这些局限性。

**Method:** 本文引入了MultiKernelBench，这是第一个全面的、多平台的基于LLM的DL内核生成基准测试。它涵盖了14个良好定义的内核类别中的285个任务，并支持Nvidia GPU、华为NPU和谷歌TPU三大硬件平台。为实现未来可扩展性，设计了一个模块化的后端抽象层。此外，还提出了一种简单而有效的类别感知一次性提示方法，通过提供类别内示例来提高生成质量。通过对七个最先进的LLM进行系统评估。

**Result:** 系统评估结果揭示了任务难度的显著差异，LLMs对训练曝光较少的平台泛化能力差，以及目标提示策略的有效性。

**Conclusion:** MultiKernelBench为LLM驱动的深度学习内核生成提供了一个全面的评估工具，并揭示了当前LLM在此领域的能力和局限性，强调了对特定平台和任务进行优化提示的重要性。

> **ai_Abstract:** 本文介绍了MultiKernelBench，一个针对基于LLM的深度学习内核生成的首个全面多平台基准测试。它旨在解决现有基准测试在硬件支持、内核分类和任务覆盖方面的不足。MultiKernelBench包含285个任务，涵盖14种内核类别，并支持Nvidia GPU、Huawei NPU和Google TPU。该基准测试采用模块化设计以实现可扩展性，并提出了一种类别感知的一次性提示方法来提高生成质量。通过对七个LLM的评估，研究发现任务难度差异大，LLM对不熟悉平台的泛化能力弱，以及特定提示策略的有效性。

> **摘要翻译:** 使用大型语言模型（LLMs）自动生成深度学习（DL）内核已成为一种很有前景的方法，可以减少编写高性能算子实现所需的人工工作和硬件特定专业知识。然而，现有用于评估LLMs在此领域表现的基准测试存在硬件支持有限、内核分类粒度粗糙以及任务覆盖不平衡的问题。为了解决这些局限性，我们引入了MultiKernelBench，第一个全面的、多平台的基于LLM的DL内核生成基准测试。MultiKernelBench涵盖了14个良好定义的内核类别中的285个任务，并支持三大主流硬件平台：Nvidia GPU、华为NPU和谷歌TPU。为了实现未来的可扩展性，我们设计了一个模块化的后端抽象层，将平台特定逻辑与核心基准测试基础设施解耦，从而方便地集成新的硬件平台。我们进一步提出了一种简单而有效的类别感知一次性提示方法，通过提供类别内示例来提高生成质量。通过对七个最先进的LLMs进行系统评估，我们揭示了任务难度的显著差异、对训练曝光较少的平台泛化能力差以及目标提示策略的有效性。MultiKernelBench已在https://github.com/wzzll123/MultiKernelBench 公开可用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [680] [Unlock the Potential of Fine-grained LLM Serving via Dynamic Module Scaling](https://arxiv.org/abs/2507.18006)
> *通过动态模块扩展释放细粒度LLM服务潜力*

*Jingfeng Wu, Yiyuan He, Minxian Xu, Xitong Gao, Kejiang Ye, Chengzhong Xu* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** LLM服务, 动态扩展, 模块级操作, 资源管理, 自动扩展

**Comment:** 15 pages

> **TL;DR:** CoCoServe是一个弹性系统，通过模块级操作实现LLM的动态细粒度扩展，从而显著降低成本并提高性能。

**AI_Comments:** CoCoServe的创新之处在于其模块级扩展方法，这比传统的实例级扩展更为细粒度，能够更有效地管理LLM的计算资源。这种动态、精细的资源分配机制对于优化LLM服务在不可预测工作负载下的成本效益和性能至关重要。该方法在降低成本和提升性能方面的显著成果，预示着它在未来LLM部署中具有广阔的应用潜力，尤其是在需要高效率和成本控制的场景。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM服务系统在有限资源下平衡服务需求和适应不可预测的流量模式时面临挑战。静态部署导致资源利用率低下和性能下降，而调整实例的高成本阻碍了动态扩展，限制了LLM服务的效率。

**Method:** 我们提出了CoCoServe，一个弹性系统，通过对LLM模块（如解码器层和投影）进行模块级复制和迁移操作，实现动态和细粒度扩展。通过对这些操作的权衡进行全面分析，开发了一种自动扩展机制，动态调节模块级资源分配和性能优化。

**Result:** CoCoServe的扩展操作展现出卓越的可扩展性，可降低46%的成本并保持可用性。与现有LLM服务系统（如Hugging Face Transformers和vLLM）相比，我们的方法可将延迟降低14%-75%，并在不同模型大小和工作负载下平均实现1.16倍-4倍的吞吐量。

**Conclusion:** CoCoServe通过动态模块扩展，显著提高了LLM服务的成本效益和性能，解决了现有系统在资源管理和动态工作负载适应方面的挑战。

> **ai_Abstract:** 该论文提出了CoCoServe，一个针对LLM服务的弹性系统，旨在通过动态模块扩展解决当前系统在资源管理和适应动态流量方面的挑战。CoCoServe的核心创新在于其模块级操作，允许对LLM模块进行细粒度的复制和迁移，并结合自动扩展机制进行资源分配和性能优化。实验结果表明，CoCoServe显著降低了成本（46%），减少了延迟（14%-75%），并提高了吞吐量（1.16x-4x），优于现有解决方案。

> **摘要翻译:** 大型语言模型（LLM）的兴起在各个领域创造了新的机遇，但也给资源管理带来了重大挑战。当前的LLM服务系统面临着一个根本性的矛盾：在有限的资源下平衡服务需求，同时适应不可预测的流量模式。静态部署导致在动态工作负载下资源利用率低下和性能下降。此外，调整实例的高成本阻碍了动态扩展，限制了高效LLM服务的真正潜力。
为了解决这个问题，我们提出了CoCoServe，一个促进动态和细粒度扩展的弹性系统。其关键创新在于LLM模块（如解码器层和投影）的复制和迁移的模块级操作。通过对这些操作相关的权衡进行全面分析，我们开发了一种自动扩展机制，动态调节模块级资源分配和性能优化，从而实现更具成本效益的LLM部署。我们的评估表明，CoCoServe采用的扩展操作表现出卓越的可扩展性，并且在保持可用性的同时可以降低46%的成本。与最先进的LLM服务系统（例如Hugging Face Transformers和vLLM）相比，我们的方法在不同模型大小和工作负载下，平均可将延迟降低14%-75%，吞吐量提高1.16倍-4倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [718] [Cloud Native System for LLM Inference Serving](https://arxiv.org/abs/2507.18007)
> *云原生系统用于LLM推理服务*

*Minxian Xu, Junhan Liao, Jingfeng Wu, Yiyuan He, Kejiang Ye, Chengzhong Xu* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 大语言模型, 云原生, 推理服务, Kubernetes, 自动伸缩

**Comment:** 10 pages

> **TL;DR:** 大语言模型（LLMs）部署面临计算需求高、效率低等挑战。本文展示了云原生技术（如容器化、微服务、动态调度）结合Kubernetes自动伸缩，如何显著提升LLM推理服务的资源效率、降低延迟、提高吞吐量，并能动态适应工作负载，为未来的可扩展LLM推理服务提供了新方向。

**AI_Comments:** 这篇论文的创新点在于将成熟的云原生技术栈（如容器、微服务、Kubernetes）系统性地应用于LLM推理服务这一新兴且计算密集型领域，解决了LLM部署中的核心痛点。其重要性在于为LLM在生产环境中的高效、可伸缩部署提供了实用的解决方案和前景，对于降低运营成本和提高用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）计算需求巨大，导致高效部署面临挑战，尤其是在云环境中。传统的推理服务方法存在资源效率低下、运营成本高、延迟高和可扩展性有限等问题。

**Method:** 本文探讨并利用了容器化、微服务和动态调度等云原生技术来改进LLM推理服务。通过使用基于Kubernetes的自动伸缩进行真实世界评估，展示了云原生系统的效果。

**Result:** 该系统实现了更高效的资源分配，降低了延迟，提高了高需求场景下的吞吐量。云原生架构能够动态适应工作负载波动，减轻性能瓶颈，并优化LLM推理服务性能。

**Conclusion:** 云原生框架能够重塑可扩展LLM推理服务的未来，为云计算和人工智能领域的研究人员、从业者和行业领导者提供了关键见解。

> **ai_Abstract:** 本文提出并评估了一种基于云原生技术的LLM推理服务系统，旨在解决传统方法在资源效率、延迟和可扩展性方面的不足。通过利用容器化、微服务和动态调度，结合Kubernetes自动伸缩，该系统显著提升了资源分配效率、降低了延迟并增加了吞吐量，并能动态适应工作负载，展现了云原生架构在未来可扩展LLM推理服务中的巨大潜力。

> **摘要翻译:** 大语言模型（LLMs）正在彻底改变众多行业，但其巨大的计算需求给高效部署带来了挑战，特别是在云环境中。传统的推理服务方法往往存在资源效率低下、导致高运营成本、延迟问题和可扩展性有限的问题。本文探讨了容器化、微服务和动态调度等云原生技术如何从根本上改进LLM推理服务。通过利用这些技术，我们展示了云原生系统如何实现更高效的资源分配、降低延迟并提高高需求场景下的吞吐量。通过使用基于Kubernetes的自动伸缩进行的真实世界评估，我们表明云原生架构可以动态适应工作负载波动，在优化LLM推理服务性能的同时减轻性能瓶颈。本次讨论为云原生框架如何重塑可扩展LLM推理服务的未来提供了更广阔的视角，为云计算和人工智能领域的研究人员、从业者和行业领导者提供了关键见解。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [753] [FCPO: Federated Continual Policy Optimization for Real-Time High-Throughput Edge Video Analytics](https://arxiv.org/abs/2507.18047)
> *FCPO：面向实时高吞吐边缘视频分析的联邦持续策略优化*

*Lucas Liebe, Thanh-Tung Nguyen, Dongman Lee* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 边缘视频分析, 联邦强化学习, 持续强化学习, 策略优化, 实时推理

**Comment:** 13 pages, 14 figures, 2 tables

> **TL;DR:** FCPO结合联邦持续强化学习，显著提升边缘视频分析的吞吐量并降低延迟和内存消耗。

**AI_Comments:** FCPO的创新之处在于将持续强化学习与联邦强化学习相结合，以应对边缘视频分析中动态环境下的实时性能挑战。这种组合允许系统在保持适应性的同时，通过联邦学习机制共享知识并加速收敛，显著提升了资源受限边缘设备的效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有边缘视频分析调度系统在快速变化的边缘环境中效率低下，而本地强化学习存在可扩展性、知识集成和适应性问题。

**Method:** 提出FCPO，将持续强化学习（CRL）与联邦强化学习（FRL）结合，动态调整推理批大小、输入分辨率和多线程。CRL适应动态环境，FRL通过经验集成提高泛化和收敛速度。通过代理特定的聚合方案和多样性感知经验缓冲区实现。

**Result:** 在真实边缘视频分析测试台上，有效吞吐量提高5倍以上，延迟降低60%，收敛速度提高20%，内存消耗减少10倍。

**Conclusion:** FCPO通过结合CRL和FRL，有效解决了边缘视频分析中的实时推理挑战，显著提高了性能和资源效率。

> **ai_Abstract:** 本文提出FCPO，一种结合持续强化学习（CRL）和联邦强化学习（FRL）的新框架，旨在解决边缘视频分析（EVA）中实时推理服务系统的挑战。FCPO通过动态调整推理参数来适应快速变化的边缘环境，并利用CRL处理环境动态性及FRL提高泛化和收敛性。实验结果表明，FCPO在吞吐量、延迟、收敛速度和内存效率方面均显著优于现有SOTA基于RL的方法。

> **摘要翻译:** 边缘视频分析（EVA）日益增长的复杂性促进了新型智能应用的发展，但也给实时推理服务系统带来了挑战。最先进（SOTA）的调度系统优化了异构设备的全局工作负载分布，但通常会遇到调度周期延长的问题，导致在快速变化的边缘环境中处理效率低下。本地强化学习（RL）可以在周期之间进行快速调整，但面临可扩展性、知识集成和适应性问题。因此，我们提出了FCPO，它将持续强化学习（CRL）与联邦强化学习（FRL）相结合，以解决这些挑战。这种集成在预处理和后处理过程中动态调整推理批大小、输入分辨率和多线程。CRL允许代理从不断变化的马尔可夫决策过程中学习，捕获动态环境变化，而FRL通过集成跨推理模型的经验来提高泛化能力和收敛速度。FCPO通过代理特定的聚合方案和多样性感知经验缓冲区将这些结合起来。在真实世界的EVA测试台上的实验表明，与SOTA基于RL的方法相比，有效吞吐量提高了5倍以上，延迟降低了60%，收敛速度加快了20%，内存消耗减少了10倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [144] [Weaving the Future: Generative AI and the Reimagining of Fashion Design](https://arxiv.org/abs/2507.17758)
> *编织未来：生成式AI与时尚设计的重塑*

*Pierre-Marie Chauvin, Angèle Merlin, Xavier Fresquet, Hugo Caselles-Dupré, Benjamin Simmenauer, Mathieu de Fayet* | **Category: cs.CY, cs.HC** | **Updated: 2025-05-07**

**Keywords:** 生成式AI, 时尚设计, 人机协作, 创意工作流程, 伦理影响

**Comment:** 

> **TL;DR:** 本文探讨了生成式AI如何融入时尚设计过程，分析了其对创意工作流程、伦理、美学和劳动力影响，并强调了人机协作的潜力与挑战。

**AI_Comments:** 本文探讨了生成式AI在时尚设计领域的应用，其创新之处在于关注了人机共创的动态以及伦理、美学和劳动力等多维度影响，而非仅仅技术实现。其重要性在于揭示了AI对创意产业深远变革的潜力与挑战。局限性可能在于其主要基于研讨会见解，缺乏具体的案例研究或实验数据支撑。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨生成式AI如何融入时尚设计过程，以及它如何重塑创意工作流程。

**Method:** 本文借鉴了2025年1月“Tisser le futur”研讨会的见解。

**Result:** 研究结果强调了人机之间的共创动态、美学创新的潜力，以及算法设计带来的环境和文化挑战。

**Conclusion:** 生成式AI在时尚设计中展现出巨大的潜力，能够重塑创意流程并带来美学创新，但同时也伴随着伦理、环境和文化方面的挑战，需要关注人机协作的动态。

> **ai_Abstract:** 本文深入探讨了生成式AI在时尚设计领域的应用及其影响。基于“Tisser le futur”研讨会的见解，文章分析了AI如何从概念到原型阶段重塑设计流程，并审视了其对伦理、美学和劳动力市场的影响。研究重点关注了人机协作的潜力、审美创新的可能性，以及算法设计所带来的环境与文化挑战。

> **摘要翻译:** 本文探讨了生成式AI融入时尚设计过程的整合。借鉴2025年1月“Tisser le futur”研讨会的见解，本文研究了AI如何重塑创意工作流程，从构思到原型制作，同时审视了其伦理、美学和劳动力影响。本文强调了人机之间的共创动态、美学创新的潜力，以及算法设计带来的环境和文化挑战。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [209] [Countering Privacy Nihilism](https://arxiv.org/abs/2507.18253)
> *反击隐私虚无主义*

*Severin Engelmann, Helen Nissenbaum* | **Category: cs.CY** | **Updated: 2025-07-24**

**Keywords:** 隐私虚无主义, 人工智能, 概念过拟合, 隐私保护, 语境完整性

**Comment:** 

> **TL;DR:** 本文提出“隐私虚无主义”来描述AI推断能力被无限夸大后对隐私理论的冲击，并引入“概念过拟合”来反驳这种夸大，主张隐私保护应超越单纯的数据类型考量。

**AI_Comments:** 本文创新性地提出了“隐私虚无主义”和“概念过拟合”这两个概念，精准描述了AI时代隐私保护面临的核心挑战和误区。它不仅指出了现有隐私框架的局限性，即过度依赖数据分类，也提供了一个思考AI能力边界和伦理应对的视角。其价值在于促使隐私研究者和政策制定者重新审视AI时代的隐私保护策略，从单一的数据类型视角转向更全面的语境化评估，为构建更具韧性的隐私框架提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 隐私学界日益关注AI作为强大的推断生产者，可能被认为能够“从一切推断一切”，从而使任何基于数据类别（敏感/非敏感、私人/公共）的隐私保护规范变得站不住脚。这种无条件接受AI推断能力导致放弃数据类别作为隐私保护规范基础的现象，被称为“隐私虚无主义”，本文旨在对其进行反驳。

**Method:** 本文通过引入“概念过拟合”的概念来揭示隐私虚无主义如何忽视AI开发中存在缺陷的认知实践。“概念过拟合”指为了简化AI模型开发而采纳便利规范，强行将复杂概念拟合到概念上代表性不足甚至不相关的数据上。文章建议摆脱仅关注数据类型的隐私框架，转而采纳考虑数据类型、参与方和信息使用目的等多参数的理论，如“语境完整性”。

**Result:** “概念过拟合”概念有助于反驳基于夸大AI能力主张的规范性建议。然而，AI的推断能力确实动摇了所有依赖于数据类别限制来提供保护的隐私法规。

**Conclusion:** 论文主张隐私保护应从仅关注数据类型的框架转向考虑包括数据类型、参与共享的行动者以及信息使用目的等多个参数的理论，例如语境完整性理论。

> **ai_Abstract:** 本文探讨了人工智能（AI）日益增长的推断能力对隐私理论的冲击，特别是AI可能“从一切推断一切”的假设，这威胁到基于数据类别（如敏感性）的传统隐私保护框架。作者将这种无条件接受AI推断能力并因此放弃数据类别作为隐私保护基础的现象定义为“隐私虚无主义”。为反驳这种观点，论文引入了“概念过拟合”的概念，指出AI开发中存在将复杂概念强行拟合不相关数据的缺陷实践。虽然“概念过拟合”有助于反驳夸大的AI能力主张，但作者也承认AI推断确实挑战了仅基于数据类别的隐私法规。因此，论文建议隐私保护应超越单纯的数据类型考量，转向更全面的框架，如“语境完整性”理论，该理论会评估数据类型、涉及的行动者以及信息的使用目的等多个参数。

> **摘要翻译:** 在隐私学术研究中，人工智能（AI）作为强大的推断生产者，日益受到关注。如果将其推断能力推向极限，AI可能被假定能够“从一切推断一切”，从而使任何依赖于数据类别（敏感与非敏感、私人与公共）来保护隐私的规范性方案，包括隐私理论和隐私法规，都变得站不住脚。由于无条件接受AI的推断能力而放弃数据类别作为隐私和数据保护的规范锚点，我们称之为隐私虚无主义。对AI推断做出符合伦理的反应，需要对AI能力进行清醒的思考，而不是发出认知上的全权委托。我们引入了概念过拟合的概念，以揭示隐私虚无主义如何对AI开发中存在缺陷的认知实践视而不见。概念过拟合是指采纳便利规范，通过强迫复杂构造适应概念上代表性不足甚至不相关的数据来简化AI模型的开发。虽然概念过拟合可以作为一种有用的工具来反驳基于夸大AI能力主张的规范性建议，但AI推断确实动摇了所有依赖于数据类别限制来提供保护的隐私法规。我们建议摆脱那些只关注数据类型而忽略所有其他因素的隐私框架。语境完整性等理论在多个参数上评估隐私的规范价值，包括数据类型、参与共享的行动者以及信息的使用目的。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [258] [A Concept for Efficient Scalability of Automated Driving Allowing for Technical, Legal, Cultural, and Ethical Differences](https://arxiv.org/abs/2507.18326)
> *一种实现自动驾驶高效可扩展性的概念，兼顾技术、法律、文化和伦理差异*

*Lars Ullrich, Michael Buchholz, Jonathan Petit, Klaus Dietmayer, Knut Graichen* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 自动驾驶, 可扩展性, 微调, 迁移学习, 社会政治因素

**Comment:** Accepted to be published at 2025 28th IEEE International Conference
  on Intelligent Transportation Systems (ITSC), Gold Coast, Australia, November
  18-21, 2025

> **TL;DR:** 提出一种两阶段微调的数据驱动概念，以实现自动驾驶在不同技术、法律、文化和伦理环境下的高效可扩展性。

**AI_Comments:** 本文的创新之处在于提出了一种系统性的方法来解决自动驾驶领域中长期存在的“软性”差异（如法律、文化、伦理）对技术部署的阻碍，而不仅仅关注技术层面的适配。其两阶段微调模型，特别是引入“国家特定奖励模型”作为技术与社会政治要求之间的接口，是其独特且重要的贡献，为自动驾驶的全球化和本地化部署提供了新的视角和实用框架。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶的高效可扩展性对于降低成本、提高安全性、节约资源和最大化影响力至关重要。然而，现有研究侧重于特定车辆和环境，而广泛部署需要跨各种配置和环境的可扩展性，尤其要应对车辆类型、传感器、法规、法律、文化和伦理等差异。

**Method:** 该概念采用两阶段微调过程。第一阶段，通过特定国家奖励模型对特定环境进行微调，该模型作为技术适应与社会政治要求之间的接口。第二阶段，车辆特定迁移学习促进系统适应并管理设计决策的验证。

**Result:** 该概念提供了一个数据驱动的过程，整合了技术和社会政治方面，实现了跨技术、法律、文化和伦理差异的有效可扩展性。

**Conclusion:** 该概念通过整合技术和社会政治方面，能够有效解决自动驾驶在不同背景下的可扩展性挑战。

> **ai_Abstract:** 本文提出了一种数据驱动的两阶段微调概念，旨在解决自动驾驶在面对不同技术、法律、文化和伦理差异时如何实现高效可扩展性的挑战。该概念通过第一阶段的特定国家奖励模型进行环境微调，以及第二阶段的车辆特定迁移学习进行系统适应和验证，从而整合了技术和社会政治因素，实现了通用自动驾驶能力的灵活部署。

> **摘要翻译:** 自动驾驶（AD）的高效可扩展性是降低成本、提高安全性、节约资源和最大化影响力的关键。然而，研究侧重于特定车辆和环境，而广泛部署需要跨各种配置和环境的可扩展性。车辆类型、传感器、执行器，以及交通法规、法律要求、文化动态甚至伦理范式的差异，都要求数据驱动开发的能力具有高度灵活性。本文旨在解决将通用能力可扩展地适应到所需系统和环境的挑战。我们的概念遵循两阶段微调过程。第一阶段，通过特定国家奖励模型对特定环境进行微调，该模型作为技术适应和社会政治要求之间的接口。第二阶段，车辆特定迁移学习促进系统适应并管理设计决策的验证。总而言之，我们的概念提供了一个数据驱动的过程，该过程整合了技术和社会政治方面，从而实现了跨技术、法律、文化和伦理差异的有效可扩展性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [293] [What does the public want their local government to hear? A data-driven case study of public comments across the state of Michigan](https://arxiv.org/abs/2507.18431)
> *公众希望地方政府听到什么？密歇根州公共评论的数据驱动案例研究*

*Chang Ge, Justine Zhang, Haofei Xu, Yanna Krupnikov, Jenna Bednar, Sabina Tomkins* | **Category: cs.CY** | **Updated: 2025-07-24**

**Keywords:** 公共评论, 地方政府, 数据驱动, 密歇根州, 机器学习

**Comment:** 

> **TL;DR:** 本研究利用密歇根州15个城市的大量公共评论数据，提出一个框架来表征公众关注的本地问题和社会问题，并使用机器学习方法分析这些评论，以了解公众希望地方政府听到的内容。

**AI_Comments:** 该论文的创新之处在于利用大规模、地域多样化的公共会议数据，结合数据驱动的分类法和机器学习方法，对公民参与和地方政府互动进行了深入分析。这克服了传统研究中数据受限的挑战，为理解公众需求和提升地方治理提供了有价值的工具和见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于市政会议的研究常受限于缺乏大规模、地域多样化的数据。本研究旨在克服这一限制，通过分析公共评论来理解公众希望地方政府关注的议题。

**Method:** 研究团队收集了密歇根州15个城市的公共会议记录中的大量公共评论数据。他们提出了一个框架，将评论分为本地关注点（如住房、选举管理）和社会关注点（如功能性民主、反种族主义）两个维度。接着，他们生成了数据驱动的本地关注点和社会关注点分类法，并利用机器学习方法将这些分类法可扩展地应用于整个数据集。

**Result:** 研究团队制作了数据驱动的本地关注点和社会关注点分类法，并展示了其提出的框架如何能够检查数据中出现的显著本地关注点和社会关注点，以及这些方面如何相互作用。

**Conclusion:** 通过对密歇根州公共评论的大规模分析，本研究提供了一个数据驱动的框架，用于理解公众向地方政府表达的本地和社会关注点，揭示了这些关注点的显著性和相互作用。

> **ai_Abstract:** 本研究旨在克服市政会议研究中数据可用性不足的限制，利用密歇根州15个城市的大规模公共评论数据。文章提出一个数据驱动的框架，将公共评论分为本地关注点（如住房、选举管理）和社会关注点（如功能性民主、反种族主义）两个维度。通过机器学习方法，研究团队生成并应用了这些分类法，以分析和展示公众向地方政府表达的显著关注点及其相互作用。

> **摘要翻译:** 市政会议是公民参与的重要场所，公众可以在此直接向地方政府表达意见。通过向市政府官员发言并呼吁他们采取行动，公众评论者有可能影响涵盖住房、可持续发展、社会公正等广泛关注领域的政策决策。然而，对这些会议的研究往往受限于缺乏大规模、地域多样化的数据。本研究利用地方政府日益普遍地使用YouTube和其他技术来存档其公共会议的趋势，提出了一个框架，从两个维度来表征评论：关注点所处的本地关注点（例如住房、选举管理）和所提出的社会关注点（例如功能性民主、反种族主义）。基于我们从密歇根州15个城市收集的大量公共评论记录，我们生成了这些评论所涵盖的本地关注点和社会关注点的数据驱动分类法，并采用机器学习方法可扩展地将我们的分类法应用于整个数据集。然后，我们展示了我们的框架如何使我们能够检查数据中出现的显著本地关注点和社会关注点，以及这些方面如何相互作用。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [386] [A Walk across Europe: Development of a high-resolution walkability index](https://arxiv.org/abs/2504.17897)
> *漫步欧洲：高分辨率步行指数的开发*

*Nishit Patel, Hoang-Ha Nguyen, Jet van de Geest, Alfred Wagtendonk, Mohan JS Raju, Payam Dadvand, Kees de Hoogh, Marta Cirach, Mark Nieuwenhuijsen, Thao Minh Lam, Jeroen Lakerveld* | **Category: cs.CY** | **Updated: 2025-07-24**

**Keywords:** 步行指数, 欧洲, 地理空间, 城市规划, 公共健康

**Comment:** 

> **TL;DR:** 本研究为欧洲开发了一个标准化的高分辨率步行指数，揭示了步行性的城乡梯度，并识别出步行性领先城市，旨在支持积极生活和公共健康。

**AI_Comments:** 该研究创新性地为整个欧洲开发了标准化、高分辨率的步行指数，填补了现有空白。其重要性在于为研究人员、规划师和政策制定者提供了实用的工具，以支持积极生活和公共健康。抽象中未提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 身体不活动是导致肥胖和非传染性疾病的重要原因，而现有提高身体活动水平的努力成效有限。建成环境在鼓励步行等积极行为方面发挥着关键作用，而步行指数是促进健康步行环境的重要工具。然而，欧洲一直缺乏标准化的高分辨率步行指数，本研究旨在填补这一空白。

**Method:** 研究选取了七个核心构成要素来定义步行性，包括可步行街道长度、交叉口密度、绿地、坡度、公共交通可达性、土地利用混合度以及15分钟步行等时线。这些数据来源于Sentinel-2、NASA高程模型、OpenStreetMap和CORINE土地覆盖等高分辨率数据集。采用100米x100米的分层网格系统和先进的地理空间方法（如网络缓冲区和距离衰减）进行大规模建模。所得指数按人口加权，并通过可视化地图、空间聚类和相关性分析在不同空间层面进行分析。

**Result:** 研究结果揭示了明显的城乡梯度，高步行性得分集中在街道连通性强、土地利用多样化的紧凑城市中心。该指数突出显示了巴塞罗那、柏林、慕尼黑、巴黎和华沙等城市是步行性方面的领先者。

**Conclusion:** 所开发的标准化、高分辨率步行指数可作为研究人员、规划师和政策制定者的实用工具，以支持欧洲不同背景下的积极生活和公共健康。

> **ai_Abstract:** 本研究为欧洲开发了一个标准化的高分辨率步行指数，以填补现有工具的空白。该指数基于七个核心构成要素，利用高分辨率数据集和先进地理空间方法构建。研究结果显示步行性存在明显的城乡梯度，高分区域集中在紧凑的城市中心，并识别出步行性领先城市。该工具对促进欧洲的积极生活和公共健康具有重要意义。

> **摘要翻译:** 身体不活动是导致肥胖和其他非传染性疾病的重要原因，然而，旨在提高全人口身体活动水平的努力收效甚微。建成环境在鼓励步行等积极行为方面发挥着关键作用。步行指数汇总了各种环境特征，为促进健康、适宜步行的环境提供了有价值的工具。然而，欧洲一直缺乏标准化的高分辨率步行指数。本研究通过为整个欧洲地区开发一个标准化的高分辨率步行指数来弥补这一空白。选择了七个核心组成部分来定义步行性：可步行街道长度、交叉口密度、绿地、坡度、公共交通可达性、土地利用混合度以及15分钟步行等时线。这些数据来源于Sentinel-2、NASA高程模型、OpenStreetMap和CORINE土地覆盖等协调一致的高分辨率数据集。研究采用了100米x100米的分层网格系统和先进的地理空间方法，如网络缓冲区和距离衰减，以大规模高效地模拟真实世界的密度和邻近效应。所得指数按人口加权，并使用可视化地图、空间聚类和相关性分析在不同空间层面进行分析。研究结果揭示了明显的城乡梯度，高步行性得分集中在街道连通性强、土地利用多样化的紧凑城市中心。该指数突出显示了巴塞罗那、柏林、慕尼黑、巴黎和华沙等城市是步行性方面的领先者。这个标准化的高分辨率步行指数可作为研究人员、规划师和政策制定者的实用工具，旨在支持欧洲不同背景下的积极生活和公共健康。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [403] [How Instructional Sequence and Personalized Support Impact Diagnostic Strategy Learning](https://arxiv.org/abs/2507.17760)
> *教学序列和个性化支持如何影响诊断策略学习*

*Fatma Betül Güreş, Tanya Nazaretsky, Bahar Radmehr, Martina Rau, Tanja Käser* | **Category: cs.CY, cs.AI, cs.HC, K.3.1** | **Updated: 2025-05-08**

**Keywords:** 教学序列, 个性化支持, 诊断策略学习, 情景式学习, 知识迁移

**Comment:** Submitted to AIED 2025 main track

> **TL;DR:** 本研究探讨了在情景式学习中，在问题解决前后提供诊断策略指导对学习效果和迁移的影响。结果显示，在问题解决后提供指导能显著提高迁移任务的表现。

**AI_Comments:** 该研究通过实证探索了情景式学习中教学序列的优化问题，其创新点在于比较了在问题解决前后提供明确指导的效果，并强调了后者在知识迁移方面的优势。这对于设计更有效的教育干预措施具有重要的实践意义，尤其是在需要复杂诊断推理的领域。

<details>
  <summary>Details</summary>

**Motivation:** 在各种教育领域中，支持学生发展有效的诊断推理是一个关键挑战。新手常受认知偏差（如过早下结论和过度依赖启发式）困扰。情景式学习（SBL）虽能提供真实案例和迭代练习，但最佳的教学和问题解决活动序列尚不明确。

**Method:** 本研究采用组间设计，在一个名为PharmaSim的在线SBL环境中进行，该环境模拟药剂师学徒的真实客户互动。研究比较了在问题解决前（I-PS）或后（PS-I）提供明确诊断策略指导的效果，并结合了个性化支持。

**Result:** 结果表明，两种教学类型都有益，但PS-I（在问题解决后提供指导）在迁移任务中导致显著更高的表现。

**Conclusion:** 在情景式学习环境中，将诊断策略指导放在问题解决之后，比放在问题解决之前，更能有效提升学习的迁移能力。

> **ai_Abstract:** 本研究探讨了在情景式学习（SBL）中，教学序列和个性化支持对学生诊断策略学习的影响。针对新手在诊断推理中面临的认知偏差问题，研究比较了在问题解决前（I-PS）或后（PS-I）提供明确诊断策略指导的效果。通过在在线SBL环境PharmaSim中进行的实验，结果显示，尽管两种指导方式均有益，但在问题解决后提供指导（PS-I）能显著提高学习者在迁移任务中的表现。

> **摘要翻译:** 支持学生发展有效的诊断推理是各种教育领域的关键挑战。新手常受认知偏差（如过早下结论和过度依赖启发式）困扰。情景式学习（SBL）可通过提供真实的案例经验和迭代练习来解决这些挑战，但最佳的教学和问题解决活动序列仍不明确。本研究探讨了如何将个性化支持融入不同的教学序列中，以及在问题解决之前（I-PS）或之后（PS-I）提供明确的诊断策略指导是否能改善学习及其迁移。我们采用组间设计，在一个名为PharmaSim的在线SBL环境中进行，该环境模拟药剂师学徒的真实客户互动。结果表明，虽然两种教学类型都有益，但PS-I在迁移任务中表现显著更高。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [434] [The Impact of Pseudo-Science in Financial Loans Risk Prediction](https://arxiv.org/abs/2507.16182)
> *伪科学在金融贷款风险预测中的影响*

*Bruno Scarone, Ricardo Baeza-Yates* | **Category: cs.CY, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 伪科学, 金融风险预测, 生存偏差, 机器学习, 社会成本

**Comment:** 

> **TL;DR:** 该研究探讨了在金融贷款风险预测中，伪科学假设和生存偏差对机器学习模型的影响，揭示了模型在准确性、社会成本和公平性方面的复杂动态，并指出表面上的性能提升可能掩盖了日益严重的不公平性。

**AI_Comments:** 这篇论文的创新之处在于它不仅关注了机器学习模型的预测准确性，更深入地探讨了“伪科学假设”和“生存偏差”在金融风险预测中的深层社会影响。它揭示了一个关键问题：表面上看似“进步”的指标（如召回率和精确率的提高）可能掩盖了模型内在公平性的恶化。这对于负责任的AI开发和部署具有重要意义，提醒我们不能仅仅依赖传统的性能指标，而需要考虑更广泛的社会成本和伦理影响，尤其是在高风险的金融领域。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨在金融贷款风险预测中，伪科学假设和生存偏差对机器学习应用的社会影响。特别关注了这种应用如何体现生存偏差对贷款偿还预测的影响。

**Method:** 研究通过分析模型的准确性和社会成本来评估其性能，并指出社会最优模型可能不会导致显著的准确性损失。研究结果在常用学习方法和数据集上得到了验证。

**Result:** 研究发现，社会最优模型在下游任务中可能不会导致显著的准确性损失。此外，当模型存在生存偏差时，其准确性会略微下降，但召回率和精确率会随时间提高，这造成了一种系统正在变好的错觉，但实际上模型正遭受越来越严重的不公平性和生存偏差。

**Conclusion:** 研究表明，在金融贷款风险预测中，表面上的模型性能提升（如召回率和精确率的提高）可能是一个假象，它掩盖了模型中日益增长的不公平性和生存偏差，这要求在评估和部署此类系统时需更加谨慎。

> **ai_Abstract:** 本文研究了伪科学假设和生存偏差在金融贷款风险预测中对机器学习应用的社会影响。通过分析模型的准确性和社会成本，发现社会最优模型不一定会显著降低准确性。重要的是，研究揭示了当模型存在生存偏差时，其准确性可能略有下降，但召回率和精确率会随时间提高，这营造了一种系统性能改善的假象，实际上却导致了日益加剧的不公平性和偏差。

> **摘要翻译:** 我们研究了在金融借贷风险预测中，伪科学假设在预测人们行为方面的社会影响，这是一个机器学习的直接应用。这个用例也例证了生存偏差在贷款偿还预测中的影响。我们从准确性和社会成本方面分析了这些模型，表明对于这个下游任务，社会最优模型可能不会导致显著的准确性损失。我们的结果在常用的学习方法和数据集上得到了验证。我们的发现还表明，当训练受生存偏差影响的模型时，存在一种自然的动态：准确性略微下降，而召回率和精确率随时间提高。这些结果造成了一种幻觉，导致观察者认为系统正在变好，而事实上模型正遭受越来越严重的不公平性和生存偏差。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [339] [Digital Twin Technologies in Predictive Maintenance: Enabling Transferability via Sim-to-Real and Real-to-Sim Transfer](https://arxiv.org/abs/2507.18449)
> *预测性维护中的数字孪生技术：通过虚实和实虚转换实现可迁移性*

*Sizhe Ma, Katherine A. Flanigan, Mario Bergés* | **Category: cs.CE, cs.AI, cs.CY, cs.LG** | **Updated: 2025-05-15**

**Keywords:** 数字孪生, 预测性维护, 虚实转换, 实虚转换, 现实差距分析

**Comment:** Accepted and presented at 2024 ASCE International Conference on
  Computing in Civil Engineering (i3CE 2024)

> **TL;DR:** 本文提出了一种在数字孪生框架中集成现实差距分析（RGA）模块的方法，以实现模拟与现实之间的双向知识迁移，从而提高预测性维护中数字孪生的可迁移性。

**AI_Comments:** 本文创新性地提出通过集成现实差距分析（RGA）模块来解决数字孪生中模拟与现实之间知识迁移的“现实差距”问题，这对于数字孪生从学术走向工业应用具有重要意义。通过双向知识转移，提高了数字孪生在预测性维护中的准确性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有数字孪生研究主要关注资产迁移，但模拟与现实操作之间的知识迁移（虚实和实虚转换）对于数字孪生全面的生命周期管理至关重要。主要挑战是校准“现实差距”。

**Method:** 研究通过数据管道将一个现实差距分析（RGA）模块集成到现有的数字孪生框架中，该模块连接历史存储库和仿真模型，以管理虚实和实虚转换。通过卡内基梅隆大学人行天桥的案例研究展示了方法的性能。

**Result:** 在完全实现RGA模块和完整数据管道的情况下，该方法能够在不影响效率的前提下，实现模拟与现实操作之间的双向知识迁移。

**Conclusion:** 通过在数字孪生框架中集成现实差距分析模块并建立完整的数据管道，可以有效管理虚实和实虚转换，实现模拟与现实之间的双向知识迁移，从而提高数字孪生在预测性维护中的应用能力。

> **ai_Abstract:** 本文探讨了数字孪生在预测性维护中的可迁移性问题，特别是虚实和实虚知识转换。研究提出了一种将现实差距分析（RGA）模块集成到现有数字孪生框架中的方法，通过数据管道连接历史数据和仿真模型，以有效校准“现实差距”。案例研究表明，该方法能够实现模拟与现实之间的双向知识迁移，且不影响效率，从而促进数字孪生在工业中的标准化应用。

> **摘要翻译:** 物联网（IoT）和人工智能（AI）的进步推动了数字孪生（DTs）从概念性想法发展为更具可实施性的现实。然而，由于缺乏标准化框架，从学术界到工业界的过渡是复杂的。本文基于作者先前建立的支持标准化数字孪生开发的功能和信息要求，重点关注一个关键方面：可迁移性。虽然现有数字孪生研究主要集中在资产迁移上，“虚实转换”（sim-to-real transfer）和“实虚转换”（real-to-sim transfer）——即在模拟和现实操作之间传递知识——对于数字孪生全面的生命周期管理至关重要。此过程中的一个关键挑战是校准“现实差距”，即模拟预测与实际结果之间的差异。我们的研究调查了将单个现实差距分析（RGA）模块集成到现有数字孪生框架中，以有效管理虚实和实虚转换的影响。这种集成通过数据管道实现，这些管道将RGA模块与数字孪生框架的现有组件（包括历史存储库和仿真模型）连接起来。卡内基梅隆大学一座人行天桥的案例研究展示了我们方法与现有框架不同集成水平的性能。在完全实现RGA模块和完整数据管道的情况下，我们的方法能够在不影响效率的前提下，实现模拟与现实操作之间的双向知识迁移。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [498] [Select2Drive: Pragmatic Communications for Real-Time Collaborative Autonomous Driving](https://arxiv.org/abs/2501.12040)
> *Select2Drive：用于实时协同自动驾驶的实用通信*

*Jiahao Huang, Jianhang Zhu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang* | **Category: cs.CE** | **Updated: 2025-07-24**

**Keywords:** 协同自动驾驶, 实用通信, 预测感知, 资源优化, V2X通信

**Comment:** 

> **TL;DR:** Select2Drive是一个优化有限计算和通信资源的协同自动驾驶框架，通过分布式预测感知和基于重要区域的实用通信，显著提升了感知和决策性能，尤其在拥堵和高速场景下。

**AI_Comments:** Select2Drive的创新点在于结合了分布式预测感知和基于重要区域的实用通信，以应对协同自动驾驶中的资源限制和延迟问题。其“少即是多”的原则，即聚焦关键区域的通信，具有很强的实用意义和效率提升潜力。该方法在实际交通场景中的表现提升，预示了其在未来V2X辅助自动驾驶中的应用前景和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 解决协同自动驾驶中有限计算和通信资源利用率低以及感知和决策累积延迟的问题。

**Method:** 提出Select2Drive框架，该框架通过以下方式优化资源利用：1) 引入分布式预测感知，将高维语义特征预测简化为计算成本高效的运动感知重建，以减轻累积延迟。2) 利用基于重要区域的实用通信（PragComm）优先传输关键区域的信息，从而提高通信效率和决策效率。

**Result:** 在V2Xverse和DAIR-V2X数据集上的实证评估显示：1) 在有限带宽下，离线感知任务（姿态误差）分别提高了2.60%和1.99%。2) 在闭环驾驶分数和路线完成率方面，分别提升了8.35%和2.65%，特别是在交通密集和高速动态场景中表现突出。

**Conclusion:** Select2Drive框架通过优化资源利用、减轻延迟和提升通信与决策效率，显著提高了协同自动驾驶的性能，尤其在复杂交通条件下具有优势。

> **ai_Abstract:** 本论文提出了Select2Drive框架，旨在解决协同自动驾驶中有限计算和通信资源的优化利用问题。该框架通过引入分布式预测感知来减轻感知和决策的累积延迟，并利用基于重要区域的实用通信来优先传输关键信息，从而提高通信和决策效率。实验结果表明，Select2Drive在离线感知任务和闭环驾驶性能上均取得了显著提升，尤其适用于交通繁忙和高速场景。

> **摘要翻译:** 车辆到一切（V2X）通信辅助的自动驾驶近年来取得了显著进展，其中实用通信（PragComm）作为一种有前景的范式，用于车辆和其他代理之间的实时协作。同时，广泛的研究探索了端到端驾驶框架中协同感知和决策之间的相互作用。在这项工作中，我们重新审视了协同驾驶问题，并提出了Select2Drive框架，以优化有限计算和通信资源的利用。特别是，为了减轻感知和决策中的累积延迟，Select2Drive通过制定主动预测范式并简化高维语义特征预测为计算成本高效、运动感知的重建，引入了分布式预测感知。鉴于“少即是多”的原则，即过于宽泛的感知范围可能会使决策模块感到困惑而不是为其做出贡献，Select2Drive利用基于重要区域的实用通信来优先处理关键区域的通信，从而提高通信效率和决策效率。在V2Xverse和真实世界的DAIR-V2X上的实证评估表明，Select2Drive在有限带宽（分别为姿态误差条件）下的离线感知任务中实现了2.60%和1.99%的改进。此外，它在闭环驾驶分数和路线完成率方面分别提供了最多8.35%和2.65%的增强，尤其是在交通密集和高速动态的场景中。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [549] [Agentar-DeepFinance-100K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization](https://arxiv.org/abs/2507.12901)
> *Agentar-DeepFinance-100K：一个通过系统性思维链合成优化的大规模金融数据集*

*Xiaoke Zhao, Zhaowen Zhou, Lin Chen, Lihong Wang, Zhiyi Huang, Kaiyuan Zheng, Yanjun Zheng, Xiyang Du, Longfei Liao, Jiawei Liu, Xiang Qi, Bo Zhang, Peng Zhang, Wei Wang, Zhe Li* | **Category: cs.CE** | **Updated: 2025-07-24**

**Keywords:** 金融推理, 大规模数据集, 思维链, LLMs, 数据合成

**Comment:** 

> **TL;DR:** 本文介绍了Agentar-DeepFinance-100K，一个大规模金融推理数据集，通过系统性思维链（CoT）合成优化构建，包含多视角知识提取（MKE）和自我纠正重写（SCR）管道，并在金融基准测试中取得了显著改进。

**AI_Comments:** 本文的创新之处在于通过系统性CoT合成优化，包括多视角知识提取（MKE）和自我纠正重写（SCR），构建了一个大规模、高质量的金融推理数据集。这种方法解决了现有CoT采样深度不足的问题，并提供了更详尽的推理路径。此外，CoT Cube研究为高质量CoT的构建提供了宝贵见解，对未来研究具有指导意义。该数据集的公开发布对推动金融推理模型的发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在金融领域具有潜力，但现有思维链（CoT）合成方法存在CoT采样深度不足的问题，且缺乏设计良好的金融推理知识空间。

**Method:** 本文提出了Agentar-DeepFinance-100K，一个大规模金融推理数据集。其核心是系统性CoT合成优化，引入了包含多视角知识提取（MKE）和自我纠正重写（SCR）的CoT合成管道，以生成详尽和深入的金融推理轨迹。此外，还进行了名为“CoT Cube”的系统性研究，分析了影响CoT有效性的关键因素，如必要性、长度和合成器。

**Result:** 在Agentar-DeepFinance-100K上训练的模型在金融基准测试中取得了显著改进。

**Conclusion:** 本文成功构建并发布了Agentar-DeepFinance-100K，一个通过系统性CoT合成优化生成的大规模、高质量金融推理数据集，显著提升了金融推理模型的性能。

> **ai_Abstract:** 本文介绍了Agentar-DeepFinance-100K，一个大规模金融推理数据集，旨在解决现有思维链（CoT）合成方法在金融领域面临的局限性。该数据集通过一个新颖的CoT合成管道构建，该管道整合了多视角知识提取（MKE）和自我纠正重写（SCR）技术，以生成深入的金融推理轨迹。此外，通过“CoT Cube”分析，研究了影响CoT有效性的关键因素。实验证明，在该数据集上训练的模型在金融基准测试中取得了显著性能提升。Agentar-DeepFinance-100K已公开发布。

> **摘要翻译:** 大型语言模型（LLMs）最近的进展展示了卓越的通用推理能力，在金融领域（一个需要稳健可靠推理的领域）具有巨大应用潜力。事实证明，从先进的通用推理模型中提炼高质量的思维链（CoT）原理为金融推理模型提供了一条有前景且高效的途径。然而，现有的CoT合成方法存在CoT采样深度不足的问题，关于如何构建一个设计良好的金融推理知识空间的问题仍未被探索。在本文中，我们提出了Agentar-DeepFinance-100K，一个以系统性CoT合成优化为特点的大规模金融推理数据集。我们首先引入了一个全面的CoT合成管道，包括多视角知识提取（MKE）和自我纠正重写（SCR），以生成详尽且深入的金融推理轨迹。此外，还进行了一项名为CoT Cube的系统性研究，分析了影响CoT有效性的关键因素，如必要性、长度和合成器，为高质量金融CoT的构建提供了宝贵见解。实验表明，在我们的Agentar-DeepFinance-100K上训练的模型在金融基准测试中取得了显著改进。我们公开发布了Agentar-DeepFinance-100K，希望能推动金融推理模型的研究。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [493] [Time for Quiescence: Modelling quiescent behaviour in testing via time-outs in timed automata](https://arxiv.org/abs/2507.18205)
> *静止时间：通过定时自动机中的超时建模测试中的静止行为*

*Laura Brandán Briones, Marcus Gerhold, Petra van den Bos, Mariëlle Stoelinga* | **Category: cs.FL** | **Updated: 2025-07-24**

**Keywords:** 基于模型的测试, 静止, 超时, 定时自动机, 一致性测试

**Comment:** 

> **TL;DR:** 该论文引入了一个提升算子，用于在简单的带标签迁移系统（LTS）中通过超时建模静止行为，从而弥合了实际测试与形式化定时自动机之间的鸿沟，并证明了其与现有方法的等效性。

**AI_Comments:** 该论文的创新之处在于通过引入一个轻量级的提升算子，弥合了工业实践测试（使用简单模型和超时来判断静止）与形式化定时自动机之间的鸿沟。该算子允许对基于超时的静止进行形式化验证，而无需定时自动机的全部复杂性，从而使形式化方法更易于访问并适用于实际场景。论文中与现有符合性测试框架（ioco）的等效性形式化证明增强了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 基于模型的测试（MBT）在实践中常用简单的LTS模型，但处理“静止”（无可见输出）需要设置超时。现有的定时MBT依赖于复杂的定时自动机（TA），这在实际需求与形式模型之间造成了差距。本研究的动机是为工业实践中通过超时判断静止提供形式化基础，同时避免定时自动机的全部复杂性。

**Method:** 论文提出了一种“提升算子”$\chi^{\scriptstyle M}\!$，该算子通过引入一个单一时钟，并设置用户定义的超时M，将时间特性添加到现有的带标签迁移系统（LTS）中。在定时自动机中，该时钟用于建模输出应在时钟达到M之前发生，而静止则恰好在时间M时发生。这种方法避免了定时自动机的全部开销。

**Result:** 1. 当一个实现符合ioco时，当且仅当其提升版本符合定时tioco_M。2. 在标准ioco测试生成算法之前或之后应用$\chi^{\scriptstyle M}\!$会产生相同的测试集。3. 提升后的TA测试套件和原始LTS测试套件对每个实现都给出相同的结论。

**Conclusion:** 该论文为工业实践中通过超时判断静止提供了形式化基础，证明了所提出的提升算子有效地弥合了简单LTS模型和复杂定时自动机之间的差距，同时与现有的一致性测试框架保持了等效性。

> **ai_Abstract:** 本文解决了基于模型的测试中建模“静止”（无可见输出）的挑战，因为实际应用使用超时，而形式化方法依赖于复杂的定时自动机。它引入了一种新颖的提升算子$\chi^{\scriptstyle M}\!$，该算子为简单的带标签迁移系统（LTS）添加了一个单一时钟，用于用户定义的超时M，从而在不增加定时自动机全部开销的情况下，为工业实践提供了形式化基础。论文展示了三项关键贡献：提升模型在ioco和定时tioco_M下的一致性等效性；将该算子应用于ioco测试生成算法时，测试集的保留性；以及提升和原始测试套件对测试结果的一致性。

> **摘要翻译:** 基于模型的测试（MBT）从被测系统的行为规范中导出测试套件。在实践中，工程师倾向于使用简单的模型，例如带标签的迁移系统（LTS）。然而，为了在实践中处理静止状态——即可观察输出的缺失——需要设置一个超时来判断静止状态的观察结束。定时MBT确实存在，但它通常依赖于定时自动机（TA）的全部功能。
我们提出了一种提升算子$\chi^{\scriptstyle M}\!$，它可以在没有TA开销的情况下添加时间：给定一个LTS，$\chi^{\scriptstyle M}\!$引入一个单一的时钟，用于用户选择的时间界限M>0来声明静止。在定时自动机中，该时钟用于建模输出应在时钟达到值M之前发生，而静止恰好在时间M时发生。通过这种方式，我们为工业实践中选择超时来判断静止提供了形式化基础。我们的贡献是三方面的：(1) 当一个实现符合ioco时，当且仅当其提升版本符合定时tioco_M；(2) 在标准ioco测试生成算法之前或之后应用$\chi^{\scriptstyle M}\!$会产生相同的测试集；(3) 提升后的TA测试套件和原始LTS测试套件对每个实现都给出相同的结论。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [554] [The complexity of reachability problems in strongly connected finite automata](https://arxiv.org/abs/2504.13784)
> *强连通有限自动机中可达性问题的复杂性*

*Stefan Kiefer, Andrew Ryzhikov* | **Category: cs.FL** | **Updated: 2025-07-23**

**Keywords:** 有限自动机, 可达性问题, 强连通, 计算复杂性, NL完全

**Comment:** To appear in MFCS 2025

> **TL;DR:** 本文研究了强连通有限自动机中几个可达性问题的计算复杂性，发现即使在强连通的情况下，一些NL完全问题仍然是NL完全的。

**AI_Comments:** 本文的创新之处在于其通用技术，能够证明在强连通这种看似能简化问题的特定条件下，某些可达性问题的计算复杂性并未降低。这对于理解这些问题的内在难度具有重要意义，并可能影响相关算法的设计。

<details>
  <summary>Details</summary>

**Motivation:** 有限自动机中的可达性问题（如NFA的完备性和全DFA的同步性）对应于非负矩阵集的某些基本性质。强连通自动机（对应于不可约非负矩阵集）在应用中频繁出现，并且通常比一般情况具有更好的性质。本文旨在从计算复杂性角度探讨这些性质的存在性。

**Method:** 开发了一种通用技术，以证明在强连通情况下，几个NL完全问题仍然是NL完全的。

**Result:** 证明了即使承诺是强连通的，判断二元全DFA是否同步是NL完全的；在相同承诺下，判断具有非常有限非确定性的二元无歧义NFA的完备性也是NL完全的。

**Conclusion:** 即使在强连通的特定情况下，某些可达性问题的计算复杂性（NL完全性）并未降低。

> **ai_Abstract:** 本文探讨了强连通有限自动机中几个可达性问题的计算复杂性。这些问题与非负矩阵的性质（如矩阵消亡性和遍历性）相关。尽管强连通情况在应用中常见且通常具有更优的性质，但研究表明，通过一种通用技术，一些已知的NL完全问题（例如判断二元全DFA的同步性，以及二元无歧义NFA的完备性）即使在强连通的约束下，其复杂性仍然保持为NL完全。

> **摘要翻译:** 有限自动机中的几个可达性问题，例如NFA的完备性和全DFA的同步性，对应于非负矩阵集的基本性质。特别是，上述两种性质分别对应于矩阵的消亡性和遍历性，它们询问是否存在输入矩阵的乘积等于零矩阵，或等于一个仅包含一列严格正项的矩阵。当输入自动机是强连通的（即，相应的非负矩阵集是不可约的）情况，在应用中频繁出现，并且通常比一般情况具有更好的性质。在本文中，我们从计算复杂性的角度探讨了这些性质的存在性，并开发了一种通用技术来表明，在强连通情况下，几个NL完全问题仍然是NL完全的。特别是，我们证明了即使承诺是强连通的，判断二元全DFA是否同步是NL完全的；在相同承诺下，判断具有非常有限非确定性的二元无歧义NFA的完备性也是NL完全的。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [602] [Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)](https://arxiv.org/abs/2506.10377)
> *马尔可夫决策过程中概率的几率和质量解释（扩展版）*

*Yun Chen Tsai, Kittiphon Phalakarn, S. Akshay, Ichiro Hasuo* | **Category: cs.FL** | **Updated: 2025-07-24**

**Keywords:** 马尔可夫决策过程, 概率解释, 统一语义, 几率-质量分类器, 可达性问题

**Comment:** To appear at CONCUR'25

> **TL;DR:** 本文提出了一个统一的语义框架，整合了马尔可夫决策过程（MDPs）中概率的两种现有解释和两种新解释，并通过几率-质量（CM）分类器系统地统一了这些语义。

**AI_Comments:** 本文的创新之处在于提出了一个统一的语义框架，巧妙地整合了MDP中概率的多种解释，并通过引入“几率-质量分类器”这一新颖的数学工具实现了系统性的统一。这不仅深化了对MDP中不确定性建模的理解，也为未来在动态系统建模和验证领域中的应用奠定了基础。通过研究新语义下的可达性问题并提供算法，也展现了其理论与实践的结合。

<details>
  <summary>Details</summary>

**Motivation:** 现有的马尔可夫决策过程（MDPs）有两种不同的解释（状态转换器与分布转换器），本文旨在提供一个统一的语义框架来整合这些现有解释并引入新的解释，以更好地处理MDP中的不确定性。

**Method:** 本文通过识别MDP中不同的随机性来源（调度器、配置和转换）并提供不同的概率解释方式（几率解释和质量解释），构建了一个统一的语义框架。这种统一是通过一个名为几率-质量（CM）分类器的数学构造实现的。此外，本文还研究了两种新语义中的可达性问题，并提供了两种解决算法。

**Result:** 本文提出了一个统一的语义框架，能够容纳MDP中概率的两种现有解释和两种新解释。通过识别不同的随机性来源和解释方式，自然产生了四种MDP语义。这些语义通过几率-质量（CM）分类器得到了系统性统一。此外，本文还研究了两种新语义中的可达性问题，证明了其难度并提供了两种解决算法。

**Conclusion:** 本文成功地为马尔可夫决策过程中的概率解释提供了一个统一的语义框架，整合了现有观点并引入了新观点，并通过几率-质量分类器实现了系统性统一。同时，对新语义下的可达性问题进行了分析并提出了解决方案。

> **ai_Abstract:** 本文提出了一个统一的语义框架，旨在整合和扩展马尔可夫决策过程（MDPs）中概率的解释方式。通过识别调度器、配置和转换等随机性来源，并结合几率和质量两种解释，该框架自然地产生了四种MDP语义，并通过几率-质量（CM）分类器实现了系统性统一。此外，文章还探讨了两种新语义下的可达性问题，并提供了相应的解决算法。

> **摘要翻译:** 马尔可夫决策过程（MDPs）是处理不确定性下决策的流行模型。验证领域中MDP的传统观点将其视为状态转换器，其中概率定义在状态序列上，并且调度器进行随机选择。另一种观点，特别适用于建模动态系统，将MDP定义为分布转换器，其中调度器分配概率质量。我们的主要贡献是一个统一的语义框架，它容纳了这两种观点以及两种新观点。这四种MDP语义通过识别MDP中不同的随机性来源（即调度器、配置和转换）并提供不同的概率解释方式（称为几率解释和质量解释）自然产生。这些语义通过一个名为几率-质量（CM）分类器的数学构造得到系统性统一。作为另一个主要贡献，我们研究了两种新语义中的可达性问题，证明了它们的难度并提供了两种解决算法。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [33] [Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach](https://arxiv.org/abs/2507.18095)
> *通过移动电源和抢修队增强微电网韧性：一种多智能体强化学习方法*

*Yi Wang, Dawei Qiu, Fei Teng, Goran Strbac* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 微电网韧性, 移动电源, 抢修队, 多智能体强化学习, 去中心化调度

**Comment:** 

> **TL;DR:** 本文提出了一种去中心化的多智能体强化学习方法，用于协调移动电源和抢修队，以增强微电网的韧性，特别是在通信受损的情况下。

**AI_Comments:** 创新点在于提出了一种去中心化的多智能体强化学习方法来解决微电网韧性问题，特别是在通信故障这一现实挑战下。其分层两级框架和用于稳定性的嵌入式函数是显著的特点。重要性在于解决了在极端事件中通信基础设施受损导致集中控制不可行时，维持电网韧性的关键实际问题。局限性方面，摘要没有详细说明与集中式方法或其他去中心化方法的具体性能提升，也没有讨论对于超出所测试总线网络的大型系统的计算复杂性或可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 以往关于移动电源（MPS）和抢修队（RC）协调以增强微电网韧性的研究，通常采用集中式方法并假设通信网络在事件发生后仍能完全运行。然而，极端事件可能损坏通信基础设施，使集中式决策不切实际。本文旨在填补这一空白，提出一个去中心化框架。

**Method:** 本文将MPS和RC的韧性驱动调度问题公式化为一个去中心化框架。为解决此问题，提出了一种分层多智能体强化学习方法，该方法具有两级框架：高层动作用于在电力和交通网络之间切换决策，低层动作通过混合策略构建，用于计算电力和交通网络中的连续调度和离散路由决策。该方法还使用一个封装系统动态的嵌入式函数来增强学习稳定性和可扩展性。

**Result:** 基于IEEE 33节点和69节点电力网络的案例研究验证了所提出方法在负荷恢复方面的有效性。

**Conclusion:** 所提出的去中心化分层多智能体强化学习方法，在协调移动电源和抢修队以增强微电网韧性及负荷恢复方面表现出有效性，即使在通信中断的情况下亦是如此。

> **ai_Abstract:** 本文旨在解决在通信受损情况下，通过移动电源（MPS）和抢修队（RC）增强微电网韧性的挑战。与传统的集中式方法不同，本文提出了一个去中心化框架来协调MPS和RC的调度。研究引入了一种新颖的分层多智能体强化学习方法，该方法具有用于电力和交通网络的二级决策过程，并包含一个用于提高稳定性的嵌入式函数。在IEEE 33节点和69节点网络上的案例研究表明，该方法在负荷恢复方面表现出有效性。

> **摘要翻译:** 移动电源（MPS）作为关键资源，因其在处理复杂的电力-交通耦合系统中的灵活性和移动性，已逐渐部署在微电网中，以与抢修队（RC）协调，从而增强韧性。然而，以往的工作以集中式方式解决了MPS和RC的协调调度问题，并假设事件发生后通信网络仍能完全正常运行。然而，越来越多的证据表明，某些极端事件会损坏或降级通信基础设施，这使得集中式决策变得不切实际。为了填补这一空白，本文在一个去中心化框架中构建了MPS和RC的韧性驱动调度问题。为了解决这个问题，提出了一种具有两级框架的层次化多智能体强化学习方法，其中高层动作用于在电力和交通网络之间切换决策，低层动作通过混合策略构建，分别用于计算电力和交通网络中的连续调度和离散路由决策。所提出的方法还使用一个封装系统动态的嵌入式函数来增强学习稳定性和可扩展性。基于IEEE 33节点和69节点电力网络的案例研究验证了所提出方法在负荷恢复方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [65] [Regional Frequency-Constrained Planning for the Optimal Sizing of Power Systems via Enhanced Input Convex Neural Networks](https://arxiv.org/abs/2507.18102)
> *区域频率约束下基于增强型输入凸神经网络的电力系统最优规模规划*

*Yi Wang, Goran Strbac* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 区域频率约束, 电力系统规划, 输入凸神经网络, 频率安全, 最优规模

**Comment:** 

> **TL;DR:** 针对可再生能源渗透导致的系统惯量下降和频率响应需求增加，本文提出一种考虑区域频率安全和区际频率振荡的电力系统最优规模规划模型，通过增强型输入凸神经网络提取区域频率约束，并采用自适应遗传算法求解，有效确保了区域系统安全并获得了实际投资决策。

**AI_Comments:** 本文的创新点在于首次将区域频率安全和区际频率振荡纳入电力系统最优规模规划中，并通过增强型输入凸神经网络解决了传统ICNN的梯度消失问题，提升了模型的拟合能力。结合自适应遗传算法的两阶段求解方法也提高了模型的求解效率。这一研究对于高比例可再生能源电力系统的规划和安全运行具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着可再生能源在电力系统中大规模渗透，系统惯量水平降低，对频率响应服务的要求提高。现有频率约束模型大多只考虑统一的频率安全，而忽略了不同区域的频率空间差异。

**Method:** 本文提出一种新颖的电力系统最优规模规划模型，该模型捕获区域频率安全和区际频率振荡。具体地，首先通过增强型输入凸神经网络 (ICNN) 提取区域频率约束，并将其嵌入到原始的频率安全优化中。该增强型ICNN采用一种原则性的权重初始化策略，以解决传统ICNN中非负权重的梯度消失问题并增强其拟合能力。为了有效迭代求解规划模型，开发了一种带有稀疏度计算和局部搜索的自适应遗传算法，将规划模型分为两个阶段进行求解。

**Result:** 在三种不同的电力系统上进行了案例研究，验证了所提出的频率约束规划模型在确保区域系统安全和获得实际投资决策方面的有效性。

**Conclusion:** 所提出的基于增强型输入凸神经网络的区域频率约束规划模型能够有效解决电力系统最优规模问题，同时考虑区域频率安全和区际频率振荡，并能确保区域系统安全和获得现实的投资决策。

> **ai_Abstract:** 本文针对可再生能源高渗透下电力系统惯量降低和频率响应需求增加的问题，提出了一种考虑区域频率安全和区际频率振荡的电力系统最优规模规划模型。该模型利用增强型输入凸神经网络提取区域频率约束，并采用自适应遗传算法进行两阶段求解。案例研究验证了该模型在保障区域系统安全和支持实际投资决策方面的有效性。

> **摘要翻译:** 大规模可再生能源渗透已在电力系统中普遍存在，导致系统惯量水平降低以及对频率响应服务的需求增加。已经有大量研究开发了用于电力系统安全的频率约束模型。然而，大多数现有文献只考虑统一的频率安全，而忽略了不同区域的频率空间差异。为了弥补这一空白，本文提出了一种新颖的电力系统最优规模规划模型，该模型捕获了区域频率安全和区际频率振荡。具体而言，首先通过增强型输入凸神经网络 (ICNN) 提取区域频率约束，然后将其嵌入到原始的频率安全优化中，其中采用了一种原则性的权重初始化策略来处理传统ICNN中非负权重的梯度消失问题并增强其拟合能力。开发了一种带有稀疏度计算和局部搜索的自适应遗传算法，将规划模型分为两个阶段并有效地进行迭代求解。在三种不同的电力系统上进行了案例研究，以验证所提出的频率约束规划模型在确保区域系统安全和获得实际投资决策方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [95] [Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination](https://arxiv.org/abs/2507.18110)
> *电动汽车协调的两阶段TSO-DSO服务提供框架*

*Yi Wang, Dawei Qiu, Fei Teng, Goran Strbac* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 电动汽车, TSO, DSO, 频率响应, 电压支持, 两阶段框架, 强化学习

**Comment:** 

> **TL;DR:** 提出一种两阶段框架，协调电动汽车为输电系统提供频率服务和为配电系统提供电压支持。

**AI_Comments:** 本文的创新之处在于提出了一个协调TSO和DSO需求的两阶段框架，并针对大规模电动汽车调度引入了去中心化操作范式和通信高效的强化学习算法，有效解决了V2G应用中的频率-电压协调难题和通信开销问题，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 应对高可再生能源渗透导致的系统惯量降低和频率响应服务需求增加，同时解决电动汽车提供频率服务可能对配电网造成的电压安全问题。

**Method:** 提出一个两阶段服务提供框架：第一阶段，电动汽车参与日前TSO-DSO互动以安排频率储备；第二阶段，电动汽车在配电网中进行实时调度，在提供储备的同时支持DSO电压。第二阶段采用去中心化操作范式，并引入一种通信高效的强化学习算法。

**Result:** 在6总线输电与33总线配电网络以及69总线配电网络上的案例研究表明，所提方法在使电动汽车提供频率服务和电压支持方面有效且具有可扩展性。

**Conclusion:** 所提出的两阶段框架能够有效协调电动汽车，同时满足输电系统运营商的频率响应需求和配电系统运营商的电压安全要求，并具有良好的可扩展性。

> **ai_Abstract:** 本文提出了一种创新的两阶段服务提供框架，旨在协调大量电动汽车，使其既能为输电系统运营商提供频率响应服务，又能为配电系统运营商提供电压支持。该框架在日前阶段规划频率储备，在实时阶段通过去中心化操作和通信高效的强化学习算法实现电动汽车的智能调度，解决了高可再生能源渗透下电网的频率和电压稳定性挑战。

> **摘要翻译:** 高可再生能源渗透已在电力系统中普遍存在，导致系统惯性降低和频率响应服务需求增加。电动汽车（EVs）凭借其车网互动（V2G）能力，可以为输电系统运营商（TSOs）提供经济高效的频率服务。然而，电动汽车本质上连接到配电网络，在支持TSO频率时可能对配电系统运营商（DSOs）造成电压安全问题。为了协调TSO频率和DSO电压，本文提出了一种针对多电动汽车的两阶段服务提供框架。在第一阶段，电动汽车参与日前TSO-DSO互动，进行频率储备调度；在第二阶段，电动汽车在配电网络中进行实时调度行为，在提供储备的同时支持DSO电压。考虑到电动汽车数量可能庞大且环境复杂，第二阶段引入了去中心化操作范式进行实时电动汽车调度，同时提出了一种通信高效的强化学习（RL）算法，以在不损害策略性能的情况下减少大规模多智能体RL训练期间的通信开销。在6总线输电和33总线配电网络以及69总线配电网络上进行了案例研究，以评估所提方法在使电动汽车提供频率服务和电压支持方面的有效性和可扩展性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [125] [Data-Driven Model Order Reduction for Continuous- and Discrete-Time Nonlinear Systems](https://arxiv.org/abs/2507.18131)
> *连续和离散时间非线性系统的数据驱动模型降阶*

*Behrad Samari, Henrik Sandberg, Karl H. Johansson, Abolfazl Lavaei* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 模型降阶, 数据驱动, 非线性系统, 仿真函数, 控制器合成

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动框架，用于为数学模型未知的连续和离散时间非线性系统构建降阶模型（ROMs），并展示其在控制器合成中的应用。

**AI_Comments:** 本文的创新点在于提出了一个纯数据驱动的方法来解决未知非线性系统的模型降阶问题，特别是在系统模型不可用的实际场景中具有重要意义。通过引入仿真函数和半定程序，为ROM的正确性提供了理论保证。此外，将ROM应用于控制器合成，进一步拓展了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为高维非线性动态系统构建有效的降阶模型（ROMs）面临巨大挑战，尤其是在系统数学模型未知的情况下，这在实际应用中非常常见。

**Method:** 本文提出一个数据驱动框架，利用系统收集到的两组输入-状态轨迹数据，首先构建系统的数据化闭环表示。然后，通过仿真函数（SFs）概念，建立原始系统输出轨迹与其数据驱动ROM输出轨迹之间的相似关系，并提出数据依赖的半定程序作为充分条件，同时构建ROMs和SFs，并提供正确性保证。

**Result:** 所获得的数据驱动ROMs可用于合成控制器，以确保未知系统满足高级逻辑特性。通过为数据驱动ROMs设计控制器，然后通过接口函数将结果转换回原始系统来实现。通过四个涉及未知高度非线性动力学的基准案例研究，评估了数据驱动发现的有效性。

**Conclusion:** 本文成功提出了一种数据驱动的方法来构建未知非线性系统的降阶模型，并证明了这些模型在控制器设计中的有效性，为处理复杂实际系统提供了新的途径。

> **ai_Abstract:** 本文针对数学模型未知的连续和离散时间非线性系统，提出了一种创新的数据驱动框架来构建有效的降阶模型（ROMs）。该方法利用两组输入-状态轨迹数据构建系统的数据化闭环表示，并通过仿真函数和数据依赖的半定程序来建立并保证ROM与原始系统输出轨迹的相似性。研究表明，所构建的ROMs能有效用于合成控制器，以使未知系统满足高级逻辑特性，并通过多个基准案例验证了其有效性。

> **摘要翻译:** 模型降阶通过推导保留基本系统特性的低维模型来简化高维动力系统。这些技术对于复杂系统的控制器设计至关重要，同时显著降低了计算成本。然而，构建有效的降阶模型（ROMs）带来了相当大的挑战，特别是对于以高度非线性项为特征的动力系统。当实际系统模型不可用时，这些挑战会进一步加剧，这种情况在实际应用中经常遇到。在这项工作中，我们提出了一种数据驱动的框架，用于构建数学模型未知的连续和离散时间非线性动力系统的ROMs。通过利用从系统收集到的两组数据，即两个输入-状态轨迹，我们首先构建了一个基于数据系统的闭环表示。然后，我们利用仿真函数（SFs）的概念，在原始系统及其数据驱动ROM的输出轨迹之间建立相似关系，从而能够形式化地描述它们的接近程度。为了实现这一点，我们提出了数据依赖的半定程序作为充分条件，以同时构建ROMs和SFs，同时提供正确性保证。我们证明了所获得的数据驱动ROMs可用于合成控制器，以确保未知系统满足高级逻辑特性。这是通过首先为数据驱动ROMs设计控制器，然后通过接口函数将结果转换回原始系统来实现的。我们通过涉及未知高度非线性项的四个基准案例研究，评估了我们数据驱动发现的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [150] [Data-Driven Incremental GAS Certificate of Nonlinear Homogeneous Networks: A Formal Modular Approach](https://arxiv.org/abs/2507.18141)
> *数据驱动的非线性同质网络增量GAS认证：一种形式化模块化方法*

*Mahdieh Zaker, David Angeli, Abolfazl Lavaei* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 数据驱动, 增量全局渐近稳定性, 同质网络, 组合方法, 样本复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动的组合方法，用于验证具有未知动力学的互联同质网络的增量全局渐近稳定性（delta-GAS），解决了现有方法样本复杂度呈指数增长的问题。

**AI_Comments:** 本文的创新之处在于提出了一种数据驱动的组合方法来解决大规模互联网络增量GAS认证中的样本复杂度问题。通过将复杂度从指数级降低到线性级，该方法极大地提高了实际应用的可行性。其模块化和形式化的方法也为未来处理复杂系统的稳定性分析提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献中的整体方法在子系统数量增加时，样本复杂度呈指数增长，使其在实际应用中不切实际。因此，需要一种更高效、可扩展的方法来验证具有未知动力学的互联网络的增量全局渐近稳定性。

**Method:** 本研究提出了一种组合式数据驱动方法来验证互联同质网络的增量全局渐近稳定性（delta-GAS）。该方法利用子系统的增量输入到状态稳定性（delta-ISS）概念，并通过delta-ISS Lyapunov函数进行表征。为了实现数据驱动方案，首先将delta-ISS Lyapunov条件重新构建为鲁棒优化程序（ROP）。由于ROP约束中存在未知子系统动力学，通过从每个未知子系统的轨迹中收集数据，开发了一个场景优化程序（SOP）来解决SOP并构建delta-ISS Lyapunov函数。随后，利用小增益组合条件，基于单个子系统的数据驱动delta-ISS Lyapunov函数，为未知互联网络构建增量Lyapunov函数，并提供正确性保证。

**Result:** 该数据驱动组合方法将样本复杂度与子系统粒度对齐，导致所需数据量随子系统数量线性增加。相比之下，现有整体方法样本复杂度呈指数增长。该方法已成功应用于一个包含10000个子系统的未知非线性同质网络，并证明了互联网络是delta-GAS，并具有正确性保证。

**Conclusion:** 本文提出的数据驱动组合方法能够有效且可扩展地验证具有未知动力学的互联同质网络的增量全局渐近稳定性，其样本复杂度随子系统数量线性增长，显著优于现有方法的指数增长。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动组合方法，用于验证具有未知动力学的非线性同质网络中的增量全局渐近稳定性（delta-GAS）。该方法基于子系统的增量输入到状态稳定性（delta-ISS）和Lyapunov函数概念，并通过将delta-ISS条件转化为场景优化程序（SOP）来处理未知动力学。通过数据收集和SOP求解，为每个子系统构建delta-ISS Lyapunov函数，并结合小增益条件为整个网络构建增量Lyapunov函数。与现有整体方法相比，该方法将样本复杂度从指数级降低到线性级，显著提高了可扩展性。在包含10000个子系统的网络上的应用验证了其有效性和正确性。

> **摘要翻译:** 这项工作专注于一种组合式数据驱动方法，用于验证具有未知数学动力学的一度互联同质网络的增量全局渐近稳定性（delta-GAS）。我们提出的方法利用了子系统增量输入到状态稳定性（delta-ISS）的概念，其特征是delta-ISS Lyapunov函数。为了实现我们的数据驱动方案，我们最初将delta-ISS Lyapunov条件重新构建为一个鲁棒优化程序（ROP）。然而，由于ROP约束中存在未知子系统动力学，我们通过从每个未知子系统的轨迹中收集数据，开发了一个场景优化程序（SOP）。我们解决了SOP并为每个具有未知动力学的子系统构建了一个delta-ISS Lyapunov函数。然后，我们利用一个小增益组合条件，基于其单个子系统的数据驱动delta-ISS Lyapunov函数，促进了为具有未知动力学的未知互联网络构建增量Lyapunov函数，同时提供正确性保证。我们证明了我们的数据驱动组合方法将样本复杂度与子系统粒度对齐，导致所需数据量随子系统数量线性增加。相比之下，现有文献中的整体方法样本复杂度随子系统数量呈指数增长，使其在实际应用中不切实际。为了验证我们组合数据驱动方法的有效性，我们将其应用于一个包含10000个子系统的未知非线性同质网络。通过从每个未知子系统收集数据，我们证明了互联网络是delta-GAS，并具有正确性保证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [180] [Unit Commitment Framework for Nuclear Reactors with Reactivity Decline](https://arxiv.org/abs/2507.18150)
> *考虑反应性衰减的核反应堆机组承诺框架*

*Shiny Choudhury, Michael Davidson, George Tynan* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 核反应堆, 机组承诺, 反应性衰减, 氙中毒, 燃料循环

**Comment:** 11 pages, preliminary version, comments welcome

> **TL;DR:** 该研究提出了一种将燃料循环动力学与机组承诺（UC）框架相结合的物理信息元启发式建模方法，用于更准确地调度核反应堆，考虑其燃料循环阶段和氙中毒效应，以实现更灵活的运行并可能延长燃料循环。

**AI_Comments:** 该论文的创新之处在于将核反应堆的燃料循环动力学和关键物理约束（如氙中毒）直接嵌入到机组承诺框架中，这克服了传统模型将核反应堆视为不灵活发电机的问题。其重要性在于提供了一种更准确、更灵活的核反应堆调度方法，有助于优化核电的运行，延长燃料循环，并促进核电在现代能源系统中的整合。这对于提高核电的经济性和运行效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 核反应堆通常被建模为不灵活的基荷发电机，具有固定的停机时间和严格的爬坡限制。然而，实际上，反应堆的运行灵活性与其燃料循环阶段和相关的反应性裕度密切相关。功率机动性的一个关键物理限制是氙中毒，这会导致功率下降后中子吸收氙浓度增加，从而延迟或阻止后续的功率上升，甚至导致停机时间显著变化。因此，需要一个能更准确反映核反应堆实际运行灵活性和物理行为的调度框架。

**Method:** 该研究引入了一种物理信息、元启发式建模方法，将燃料循环动力学直接嵌入到机组承诺（UC）框架中。该框架跟踪反应性裕度，动态激活与氙相关的约束，并根据堆芯条件内生地实施燃料更换停堆。通过捕获循环内反应性演化和氙中毒的条件性发生，该公式允许操作依赖的核调度，反映了监管限制和物理行为。

**Result:** 当应用于在不同运行模式（从基荷到部分负荷）下运行的代表性反应堆群时，该框架揭示了灵活操作可以减缓反应性衰退并延长燃料循环。结果表明，考虑燃料循环的灵活性建模对于核反应堆的准确调度至关重要。

**Conclusion:** 考虑燃料循环的灵活性建模对于核反应堆的准确调度至关重要，并为将核电集成到能源系统模型中提供了一条可行的途径。灵活操作可以减缓反应性衰退并延长燃料循环。

> **ai_Abstract:** 本研究提出了一种新的机组承诺（UC）框架，用于核反应堆的调度和运行，该框架创新性地将燃料循环动力学和反应性衰减（特别是氙中毒效应）直接整合到模型中。与传统将核反应堆视为不灵活基荷发电机的做法不同，该框架考虑了燃料循环阶段对操作灵活性的影响，并能动态激活与氙相关的约束。通过这种物理信息和元启发式的方法，模型能够根据堆芯条件内生地管理燃料更换停堆，并允许操作依赖的核调度。研究结果表明，这种考虑燃料循环的灵活性建模方法对于核反应堆的准确调度至关重要，并且灵活运行能够有效减缓反应性衰减并延长燃料循环，为核电在能源系统中的整合提供了可行的路径。

> **摘要翻译:** 核反应堆通常被建模为不灵活的基荷发电机，具有固定的停机时间和严格的爬坡限制。然而，实际上，反应堆的运行灵活性与其燃料循环阶段和相关的反应性裕度密切相关。功率机动性的一个关键物理限制是氙中毒，这是由功率下降后中子吸收氙浓度增加引起的。这会由于堆芯反应性受抑制而延迟甚至阻止后续的功率上升。此外，如果反应堆在低反应性期间停堆，由于这些氙瞬态，重启时间可能会显著变化，导致更长的停机时间。这项工作引入了一种物理信息、元启发式建模方法，将燃料循环动力学直接嵌入到机组承诺（UC）框架中。该框架跟踪反应性裕度，动态激活与氙相关的约束，并根据堆芯条件内生地实施燃料更换停堆。通过捕获循环内反应性演化和氙中毒的条件性发生，该公式允许操作依赖的核调度，反映监管限制和物理行为。当应用于在不同运行模式（从基荷到部分负荷）下运行的代表性反应堆群时，该框架揭示了灵活操作可以减缓反应性衰退并延长燃料循环。结果表明，考虑燃料循环的灵活性建模对于核反应堆的准确调度至关重要，并为将核电集成到能源系统模型中提供了一条可行的途径。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [210] [Stability Constrained Voltage Control in Distribution Grids with Arbitrary Communication Infrastructure](https://arxiv.org/abs/2507.18158)
> *具有任意通信基础设施的配电网中稳定性受限的电压控制*

*Zhenyi Yuan, Jie Feng, Yuanyuan Shi, Jorge Cortés* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 电压控制, 配电网, 稳定性约束, 通信基础设施, 学习型控制器

**Comment:** 

> **TL;DR:** 本文提出一种统一设计框架，利用任意通信基础设施，设计基于ICNN的学习型无功功率控制器，实现配电网电压稳定控制，并通过仿真验证了其有效性及通信对性能提升的作用。

**AI_Comments:** 本文的创新之处在于提出了一个统一的设计框架，允许学习型控制器利用任意通信基础设施，突破了现有方法中控制器必须去中心化的限制。这使得控制器能够利用更广泛的信息，从而在保证稳定性的前提下实现更优的控制性能，为未来智能电网的电压控制提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有证明稳定的控制器仅限于去中心化，限制了其利用非本地信息。本文旨在设计一种能够利用任意通信基础设施的、学习型无功功率控制器，以实现配电网的电压调节并确保系统稳定性，从而放宽控制器设计约束。

**Method:** 提出一个统一的设计框架，使控制器能够利用任意通信基础设施。在此框架下，提供了一种设计程序，用于构建基于输入凸神经网络（ICNN）的控制器，这些控制器在任意通信场景下都能满足预设的稳定性约束，并通过监督学习进行训练。

**Result:** 在加州大学圣地亚哥分校（UCSD）微电网测试平台上的仿真结果表明，所提出的框架是有效的，并突出显示了通信在改善控制性能方面的作用。

**Conclusion:** 本文成功设计并验证了一种利用任意通信基础设施的稳定性受限电压控制器，证明了其在配电网中实现有效电压调节和系统稳定性的能力，并强调了通信对提升控制性能的关键作用。

> **ai_Abstract:** 本文提出一种新颖的统一设计框架，用于在配电网中实现稳定性受限的电压控制。与传统去中心化方法不同，该框架允许学习型无功功率控制器利用任意通信基础设施，从而能够获取非本地信息，并降低控制器设计的保守性。研究人员开发了基于输入凸神经网络（ICNN）的控制器构建流程，这些控制器通过监督学习进行训练，并能满足任意通信场景下的稳定性约束。仿真结果验证了该框架的有效性，并强调了通信在提升控制性能中的关键作用。

> **摘要翻译:** 我们考虑设计基于学习的无功功率控制器的问题，这些控制器在配电网中执行电压调节，同时确保闭环系统稳定性。与现有方法（其中可证明稳定的控制器仅限于去中心化）不同，我们提出了一种统一的设计框架，该框架使控制器能够利用物理电网之上的任意通信基础设施。这使得控制器能够整合其本地总线之外的信息，将现有方法作为特例涵盖，并导致控制器设计的约束更不保守。然后，我们提供了一个设计程序来构建基于输入凸神经网络（ICNN）的控制器，这些控制器在任意通信场景下通过设计满足已识别的稳定性约束，并使用监督学习训练这些控制器。在加州大学圣地亚哥分校（UCSD）微电网测试平台上的仿真结果说明了该框架的有效性，并突出了通信在改善控制性能方面的作用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [240] [Optimal Integration Of Heat-Pump And Solar Thermal Energy In The Pre-heating Loop Of Wood And Gas Boiler Based District Heating System](https://arxiv.org/abs/2507.18204)
> *燃木和燃气锅炉区域供热系统中热泵和太阳能热能预热回路的优化集成*

*Hamza Mettali, Rousset François, Eric Bideaux, Clausse Marc* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-24**

**Keywords:** 热泵, 太阳能热能, 区域供热, MILP, 脱碳

**Comment:** 

> **TL;DR:** 本研究旨在优化区域供热系统中热泵和太阳能热能与燃木/燃气锅炉的集成，以实现技术经济和环境效益。通过开发混合整数线性规划（MILP）模型，并在不同碳税和二氧化碳排放情景下进行多场景分析，揭示了太阳能、燃木锅炉和碳税对系统性能、成本和可再生能源渗透率的影响。

**AI_Comments:** 这篇论文的创新点在于构建了一个考虑温度离散化和动态特性的MILP模型，用于优化多种可再生能源在区域供热系统中的集成，并结合了碳税影响的分析。其重要性在于为区域供热系统的脱碳提供了量化的决策支持，揭示了不同能源组合和政策情景下的技术经济与环境权衡。局限性可能在于模型假设的简化性，以及实际工程实施中可能面临的复杂性，例如不同能源的实际运行特性、并网挑战以及更精细的市场动态。

<details>
  <summary>Details</summary>

**Motivation:** 在区域能源网络中，整合可再生能源对于热生产的脱碳至关重要。除了基于生物质的解决方案，太阳能热能（无论是否结合热泵）都提供了重要的机遇。然而，系统性能高度依赖于室外和设定温度，因此需要优化系统设计。

**Method:** 本研究采用多目标方法，考虑技术经济和环境（CO2）因素，开发了一个混合整数线性规划（MILP）模型来优化系统设计。该模型通过温度离散化实现问题线性化，并捕获热发生器的关键动态特性。此外，还进行了在两种碳税水平和不同CO2排放情况下的多场景分析。

**Result:** 开发的MILP模型改善了收敛性，将19%的MIP间隙在26小时内减少到12小时内的10%，通过消散6%的过剩太阳能热量。多场景分析显示，太阳能集成可达11,932平方米，但增加了对天然气的依赖（50%）和储热损耗（49%）。纳入燃木锅炉减少了对太阳能的依赖，覆盖了45%的热负荷，降低了平均热力成本（LCOH），但限制了可再生能源的渗透。更高的碳税促进了太阳能的采用，但面临存储效率低下的问题，而生物质提高了成本效率和系统稳定性。

**Conclusion:** 优化区域供热系统中热泵和太阳能热能与传统锅炉的集成，需要在技术经济和环境效益之间进行权衡。太阳能集成有助于脱碳，但可能增加对天然气的依赖和储热损失。燃木锅炉能有效降低成本并提供稳定性，但可能限制整体可再生能源渗透率。碳税能促进太阳能采用，但需要解决储能效率问题。实现有效的脱碳需要综合考虑多种可再生能源和策略。

> **ai_Abstract:** 本研究旨在优化区域供热系统中热泵和太阳能热能与燃木/燃气锅炉的集成，以实现脱碳目标。作者开发了一个混合整数线性规划（MILP）模型，该模型结合了温度离散化以提高收敛性，并进行了多场景分析，评估了不同碳税水平和CO2排放情景下的系统性能。研究发现，大规模太阳能集成会增加对天然气的依赖和储热损失，而燃木锅炉虽能降低成本但限制了可再生能源渗透。高碳税能促进太阳能采用，但也凸显了储能效率问题，同时生物质显示出良好的成本效益和系统稳定性。

> **摘要翻译:** 在区域能源网络中，整合可再生能源对于热生产的脱碳至关重要。除了基于生物质的解决方案，太阳能热能（无论是否结合热泵）都提供了重要的机遇。然而，系统性能高度依赖于室外和设定温度。本研究旨在采用多目标方法优化系统设计，该方法考虑了技术经济和环境（CO2）因素。开发了一个混合整数线性规划（MILP）模型，该模型通过温度离散化实现问题线性化，并捕获热发生器的关键动态特性。该模型改善了收敛性，通过消散6%的过剩太阳能热量，将26小时内的19%MIP间隙减少到12小时内的10%。在两种碳税水平和不同CO2排放情况下的多场景分析显示，太阳能集成可达11,932平方米，但增加了对天然气的依赖（50%）和储热损耗（49%）。纳入燃木锅炉减少了对太阳能的依赖，覆盖了45%的热负荷，降低了平均热力成本（LCOH），但限制了可再生能源的渗透。更高的碳税促进了太阳能的采用，但面临存储效率低下的问题，而生物质提高了成本效率和系统稳定性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [270] [Designing efficient interventions for pre-disease states using control theory](https://arxiv.org/abs/2507.18269)
> *基于控制理论的疾病前状态高效干预设计*

*Makito Oku* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 控制理论, 疾病前状态, 干预, 马尔可夫链, 稀疏控制

**Comment:** 24 pages, 14 figures, 1 table, submitted to NOLTA

> **TL;DR:** 该研究提出了一种基于控制理论的方法，即马尔可夫链稀疏控制（MCSC），用于设计疾病前状态的高效干预措施，并通过数值模拟和真实数据分析验证了其有效性。

**AI_Comments:** 该论文的创新点在于将控制理论应用于疾病前状态的干预治疗，填补了现有理论在疾病前检测与治疗之间的空白。通过引入马尔可夫链稀疏控制（MCSC），提供了一种量化且高效识别干预靶点的新颖方法，对于延长健康预期寿命具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在老龄化社会中，延长健康预期寿命至关重要，而预防疾病在疾病前状态是关键。尽管已经发展了用于疾病前检测的动态网络生物标志物理论，但疾病前治疗的数学框架尚未完善。

**Method:** 提出了一种基于控制理论的疾病前治疗方法，命名为马尔可夫链稀疏控制（MCSC）。该方法将马尔可夫链上概率分布的时间演化描述为离散时间线性系统。通过设计稀疏控制器，可以识别出少数几个用于干预的候选状态。

**Result:** MCSC的有效性通过数值模拟和真实数据分析得到了证明。

**Conclusion:** 该研究成功地提出并验证了马尔可夫链稀疏控制（MCSC）作为一种基于控制理论的疾病前治疗方法，为疾病预防提供了新的数学框架。

> **ai_Abstract:** 本研究针对老龄化社会中疾病前状态干预治疗数学框架缺失的问题，提出了一种基于控制理论的马尔可夫链稀疏控制（MCSC）方法。该方法将马尔可夫链上的概率分布演化建模为离散时间线性系统，并通过稀疏控制器设计识别出高效的干预目标状态。数值模拟和真实数据分析验证了MCSC在疾病前治疗中的有效性。

> **摘要翻译:** 为了在老龄化社会中延长健康预期寿命，在疾病前状态预防各种疾病至关重要。尽管已经发展了用于疾病前检测的动态网络生物标志物理论，但疾病前治疗的数学框架尚未完善。在此，我提出了一种基于控制理论的疾病前治疗方法，命名为马尔可夫链稀疏控制（MCSC），其中马尔可夫链上概率分布的时间演化被描述为离散时间线性系统。通过设计稀疏控制器，可以识别出少数几个用于干预的候选状态。MCSC的有效性通过数值模拟和真实数据分析得到了证明。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [305] [Maneuvering-based Dynamic Thrust Allocation for Fully-Actuated Vessels](https://arxiv.org/abs/2507.18309)
> *基于机动的全驱动船舶动态推力分配*

*Emir Cem Gezer, Roger Skjetne* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 推力分配, 全驱动船舶, 控制Lyapunov函数, 控制障碍函数, 船舶机动

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于机动问题的全驱动船舶推力分配方法，利用控制Lyapunov函数和控制障碍函数实现动态跟踪和推力饱和限制。

**AI_Comments:** 该论文通过引入控制Lyapunov函数和控制障碍函数，为全驱动船舶的动态推力分配提供了一种新颖且实用的方法。其创新之处在于结合了机动问题和先进控制理论，以确保推力参考信号的平滑性和对饱和限制的遵守，这对于实际船舶操作至关重要。该方法的简单性和有效性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 为全驱动船舶的推力分配提供一种简单、有效且能产生平滑动态推力参考信号的新方法。

**Method:** 该方法利用控制Lyapunov函数为推力创建非线性参考滤波器，以确保对最优推力分配解的动态跟踪，并限制输出推力参考的速率。此外，使用控制障碍函数来确保推力饱和限制得到遵守。

**Result:** 该方法在船舶推力分配的实现中，实现了简单性、有效性以及平滑和动态的推力参考信号。

**Conclusion:** 本文提出的基于机动的动态推力分配方法，通过结合控制Lyapunov函数和控制障碍函数，能够为全驱动船舶提供有效且平滑的推力控制，同时尊重推力限制。

> **ai_Abstract:** 本文提出了一种针对全驱动船舶的基于机动的动态推力分配新方法。该方法结合使用控制Lyapunov函数来创建非线性参考滤波器以实现最优推力分配解的动态跟踪和速率限制，并利用控制障碍函数来确保推力饱和限制。该方法旨在提供一种简单、有效且能生成平滑动态推力参考信号的推力分配解决方案。

> **摘要翻译:** 本文介绍了一种利用海事领域机动问题解决全驱动船舶推力分配问题的新方法。该方法使用控制Lyapunov函数为推进器力创建一个非线性参考滤波器。该滤波器确保了对最优推力分配解决方案的动态跟踪，并限制了输出推进器参考的速率。它还进一步使用控制障碍函数来确保推进器力饱和限制得到遵守。该方法旨在实现船舶推力分配的简单性、有效性以及平滑和动态的推进器参考信号。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [340] [Toward Sustainable Vertical Farming: Impacts of Environmental Factors and Energy Mix on Performance and Costs](https://arxiv.org/abs/2507.18419)
> *迈向可持续垂直农业：环境因素和能源组合对性能和成本的影响*

*Francesco Ceccanti, Aldo Bischi, Umberto Desideri, Andrea Baccioli* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 垂直农业, 能源效率, 环境因素, 成本分析, 可持续性

**Comment:** 

> **TL;DR:** 本研究分析了垂直农业系统的生产性能和能耗，评估了其效率、可持续性和经济可行性。研究发现，光合光子通量密度（PPFD）是作物生长和能耗的主导因素，且仅有近乎脱碳的能源系统才能支持垂直农业而不增加碳排放。

**AI_Comments:** 本文通过对大量情景的模拟分析，为垂直农业的设计和运营提供了宝贵的量化数据和指导。其创新之处在于系统地评估了多个环境因素、保温层和气候区对性能和成本的综合影响。研究结果，特别是PPFD的主导作用以及成本效益最高的参数组合，对未来垂直农场的优化设计和可持续发展具有重要指导意义。此外，对能源系统脱碳的强调，也指出了垂直农业实现真正环境效益的关键路径。

<details>
  <summary>Details</summary>

**Motivation:** 垂直农业因其能够确保稳定、高质量、无虫害的蔬菜生产，并支持与能源系统和城市发展的协同作用而日益受到关注。为了提高能源效率和降低成本，制定标准化的设计和操作指南至关重要。

**Method:** 本研究通过结合三种温度、光合光子通量密度（PPFD）和二氧化碳浓度水平，在挪威、中国和迪拜三个不同气候区评估了162种情景，同时在每种情景中测试了两种保温层厚度，以分析垂直农业系统的生产性能和能耗，评估其效率、可持续性和经济可行性。

**Result:** 结果表明，由于暖通空调和除湿（HVACD）系统，保温层和外部气候对作物生产力没有显著影响。PPFD被证明是作物生长的主要因素（相关性：0.85），其次是CO2（0.36）和室内温度（0.22）。PPFD也是总能耗的主要驱动因素（相关性：0.73），因为它影响照明和HVACD负荷。值得注意的是，最低的比能耗（SEC）与最低的作物生产力（55千克/平方米）相吻合。生菜的平准化成本（LCoL）平衡了生产力和能源使用，确定了最具成本效益的设置是24摄氏度、250 PPFD、1400 ppm CO2，带保温层，在所有气候下均保持一致。

**Conclusion:** 最终，只有近乎脱碳的能源系统才能支持垂直农业，而不会与进口生菜相比增加二氧化碳排放。

> **ai_Abstract:** 本研究全面评估了垂直农业系统的性能和成本，考虑了环境因素和能源组合的影响。通过对162种不同情景的分析，研究发现光合光子通量密度（PPFD）是作物生长和能源消耗的关键驱动因素。尽管外部气候和保温层对生产力影响不大，但优化室内环境参数（如24℃、250 PPFD、1400 ppm CO2）并结合保温层能实现最佳的成本效益。研究强调，为实现可持续垂直农业，必须采用近乎脱碳的能源系统以避免增加碳排放。

> **摘要翻译:** 对垂直农业日益增长的兴趣源于其能够确保稳定、高质量、无虫害的蔬菜生产，同时支持与能源系统和城市发展的协同作用。因此，标准化的设计和操作指南对于提高能源效率和降低成本至关重要。本研究分析了垂直农业系统的生产性能和能耗，评估了其效率、可持续性和经济可行性。通过结合三种温度、光合光子通量密度（PPFD）和二氧化碳浓度水平，在挪威、中国和迪拜三个不同的气候区（这些区域在社会环境方面也有所不同）评估了总共162种情景。每种情景中还测试了两种保温层厚度。结果表明，由于暖通空调和除湿（HVACD）系统，无论是保温层还是外部气候都对作物生产力没有显著影响。PPFD被证明是作物生长的主要因素（相关性：0.85），其次是CO2（0.36）和室内温度（0.22）。PPFD也成为总能耗的主要驱动因素（相关性：0.73），因为它影响照明和HVACD负荷。值得注意的是，最低的比能耗（SEC）与最低的作物生产力（55千克/平方米）相吻合。生菜的平准化成本（LCoL）平衡了生产力和能源使用，确定了最具成本效益的设置是24摄氏度、250 PPFD、1400 ppm CO2，带保温层，在所有气候下均保持一致。最终，只有近乎脱碳的能源系统才能支持垂直农业，而不会与进口生菜相比增加二氧化碳排放。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [381] [A Robust Predictive Control Method for Pump Scheduling in Water Distribution Networks](https://arxiv.org/abs/2507.18492)
> *水分配网络中水泵调度的鲁棒预测控制方法*

*Mirhan Ürkmez, Carsten Kallesøe, Jan Dimon Bendtsen, Eric C. Kerrigan, John Leth* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 鲁棒预测控制, 水泵调度, 水分配网络, 模型预测控制, 不确定性

**Comment:** 

> **TL;DR:** 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于水分配网络中水泵的优化调度，以应对模型不确定性和需求预测误差，同时降低运营成本。

**AI_Comments:** 该论文的创新之处在于提出了一种鲁棒模型预测控制（RMPC）方法，专门用于处理水分配网络中水泵调度所面临的不确定性（如模型不确定性和需求预测误差）。通过将优化问题从$\\mathcal{O}(N^6)$重构为$\\mathcal{O}(N^3)$，显著提高了计算效率，这对于实际应用至关重要。其重要性在于为水务公司提供了一种更可靠、更经济的泵调度解决方案，有助于降低运营成本并确保系统约束的满足。抽象中未提及具体局限性。

<details>
  <summary>Details</summary>

**Motivation:** 水务公司旨在降低水分配网络（WDNs）中主要由抽水驱动的高昂电费。然而，由于模型不确定性和用水需求预测误差，水泵调度具有挑战性。

**Method:** 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于水泵的优化和可靠调度。该方法扩展了之前针对其模型量身定制的高效鲁棒控制方法。使用具有有界加性扰动的线性模型来表示水箱水位演变，不确定性边界从WDN仿真和需求数据中得出。在每个时间步，优化一个与过去扰动相关的仿射水泵调度策略，以在预测范围内满足系统约束。生成的策略以滚动时域方式应用。优化问题最初的计算复杂度为$\\mathcal{O}(N^6)$，通过重构为稀疏形式，将其降低到$\\mathcal{O}(N^3)$。

**Result:** 该方法在代表丹麦中等城市兰德斯的水分配网络模型上进行评估时，在满足约束方面超越了名义和约束紧缩模型预测控制（MPC）方法，并提供了可比较的经济结果。

**Conclusion:** 本文提出的鲁棒预测控制方法在处理水分配网络中水泵调度的不确定性和满足系统约束方面表现出色，同时保持了与现有MPC方法相当的经济效益。

> **ai_Abstract:** 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于优化水分配网络（WDNs）中的水泵调度，旨在降低高昂的电费并解决模型不确定性和需求预测误差。该方法采用带有有界扰动的线性模型来描述水箱水位，并根据过去扰动优化仿射调度策略，以滚动时域方式应用。通过将优化问题重构为稀疏形式，计算复杂度从$\\mathcal{O}(N^6)$显著降低到$\\mathcal{O}(N^3)$。在丹麦兰德斯的水分配网络模型上进行的评估表明，该方法在满足约束方面优于传统的名义和约束紧缩MPC方法，同时保持了可比的经济效益。

> **摘要翻译:** 水务公司旨在降低水分配网络（WDNs）中主要由抽水驱动的高昂电费。然而，由于模型不确定性和用水需求预测误差，水泵调度具有挑战性。本文提出了一种鲁棒模型预测控制（RMPC）方法，用于水泵的优化和可靠调度，该方法扩展了之前针对我们模型量身定制的高效鲁棒控制方法。使用具有有界加性扰动的线性模型来表示水箱水位演变，不确定性边界从WDN仿真和需求数据中得出。在每个时间步，优化一个与过去扰动相关的仿射水泵调度策略，以在预测范围内满足系统约束。生成的策略以滚动时域方式应用。优化问题最初的计算复杂度为$\\mathcal{O}(N^6)$，通过重构为稀疏形式，将其降低到$\\mathcal{O}(N^3)$。在代表丹麦中等城市兰德斯的水分配网络模型上进行评估时，该方法在满足约束方面超越了名义和约束紧缩模型预测控制（MPC）方法，并提供了可比较的经济结果。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [420] [Rapid Modeling Architecture for Lightweight Simulator to Accelerate and Improve Decision Making for Industrial Systems](https://arxiv.org/abs/2507.17990)
> *用于轻量级模拟器的快速建模架构，以加速和改进工业系统决策*

*Takumi Kato, Zhi Li Hu* | **Category: eess.SY, cs.MA, cs.RO, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 快速建模架构, 轻量级模拟器, 工业系统, 决策制定, 建模时间

**Comment:** 8 pages, 13 figures. Manuscript accepted at the 2025 IEEE 21st
  International Conference on Automation Science and Engineering (CASE 2025)

> **TL;DR:** 本文提出了一种快速建模架构（RMA），用于轻量级工业模拟器，可显著减少建模时间（78.3%），从而加速和改进工业系统设计中的决策制定。

**AI_Comments:** 这项工作提出了一种创新的方法，通过快速建模架构解决了工业系统设计中模拟器建模耗时过长的问题，这对于早期决策制定具有重要意义。其核心创新在于在保持必要细节的同时，显著减轻了建模负担，从而实现了建模时间的显著缩减。78.3%的建模时间减少是一个非常具体且有力的结果，证明了该方法的有效性。这项研究对于需要快速迭代和优化设计的工业应用具有高实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在工业系统（如配送中心和制造工厂）的设计早期阶段，决策制定往往信息有限，导致设计不准确且难以后期修正。虽然模拟器能有效发现问题，但传统模拟器所需的建模时间过长，无法满足快速决策的需求。

**Method:** 本文提出了一种快速建模架构（RMA），用于轻量级工业模拟器。该架构旨在减轻建模负担，同时保留必要细节，以加速和改进决策制定。作者基于RMA原型化了一个模拟器，并将其应用于实际工厂布局设计问题。

**Result:** 所提出的基于RMA的模拟器在实际工厂布局设计问题中得到了应用。与传统模拟器相比，该模拟器将建模时间减少了78.3%。

**Conclusion:** 本文提出的快速建模架构（RMA）能够显著减少工业系统模拟器的建模时间，从而有效加速并改进工业系统设计中的决策制定过程。

> **ai_Abstract:** 本文针对工业系统设计中传统模拟器建模时间过长的问题，提出了一种快速建模架构（RMA），用于构建轻量级工业模拟器。该架构旨在减轻建模负担并保持关键细节，以加速和改进决策制定。实验结果表明，基于RMA的原型模拟器在实际工厂布局设计中，相较于传统模拟器，建模时间减少了78.3%，有效提升了决策效率。

> **摘要翻译:** 设计工业系统，例如建造、改进和自动化配送中心和制造工厂，在早期阶段涉及信息有限的关键决策。信息缺乏导致系统设计准确性较低，这些问题往往难以在后期解决。使用模拟器对设计系统进行建模并及早发现问题是有效的。然而，传统模拟器所需的建模时间过长，无法实现快速模型创建以满足决策需求。在本文中，我们提出了一种用于轻量级工业模拟器的快速建模架构（RMA），该架构在保持必要细节的同时减轻了建模负担，以加速和改进决策制定。我们已经基于RMA原型化了一个模拟器，并将其应用于实际工厂布局设计问题。我们还将我们的模拟器与现有模拟器的建模时间进行了比较，结果显示，我们的模拟器与传统模拟器相比，建模时间减少了78.3%。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [423] [Global Observer Design for a Class of Linear Observed Systems on Groups](https://arxiv.org/abs/2507.18493)
> *群上一类线性观测系统的全局观测器设计*

*Changwu Liu, Yuan Shen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 全局观测器, 李群, 状态估计, 类卡尔曼, 导航

**Comment:** 16 pages, 1 figure

> **TL;DR:** 本文提出了一种针对群上线性观测系统的统一全局观测器框架，通过系统浸入和类卡尔曼观测器实现全局指数稳定性。

**AI_Comments:** 该论文的创新之处在于为李群上的系统提出了一个统一的观测器框架，成功处理了非欧几里德状态空间固有的拓扑难题。通过将系统浸入到线性时变系统中，并结合类卡尔曼观测器与优化方法进行状态重建，为实现复杂系统中的全局指数稳定性提供了一种新颖的方法。其在导航问题中的应用也凸显了其实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 群上的线性观测系统编码了各种实际状态估计问题的几何结构。本文旨在为这类系统提出一个统一的观测器框架。

**Method:** 该方法通过将李群上的双不变系统限制到其正规子群，从而将原始系统浸入到一个线性时变系统中。观测器首先为浸入系统设计一个类卡尔曼观测器，然后通过优化重建群值状态。当输入偏差联合估计时，保证半全局稳定性。

**Result:** 在满足秩条件且找到重建优化的一个全局最优解时，实现了全局指数稳定性（GES）。当输入偏差联合估计时，可以保证半全局稳定性。该理论成功应用于双帧系统的GES观测器设计，能够建模一系列导航问题，并提供了两个非平凡的例子。

**Conclusion:** 该论文提出的统一观测器框架为群上的线性观测系统提供了一种实现全局指数稳定性的方法，尽管存在非欧几里德状态空间固有的拓扑困难，但仍能应用于导航等实际问题。

> **ai_Abstract:** 本文提出了一种用于李群上线性观测系统的统一全局观测器框架。该框架利用结构特性将原始系统浸入到线性时变系统中。观测器通过为浸入系统设计类卡尔曼滤波器并优化群值状态重建来构建。在满足秩条件且找到全局最优解时，该框架可实现全局指数稳定性；在联合估计输入偏差时，可保证半全局稳定性，解决了非欧几里德状态空间的拓扑挑战。其在双帧系统导航问题中的应用得到了证明。

> **摘要翻译:** 群上的线性观测系统编码了各种实际状态估计问题的几何结构。本文通过将李群上的双不变系统限制到其正规子群，提出了一类线性观测系统的统一观测器框架。这种结构特性有力地将原始系统浸入到一个线性时变系统中。利用这种浸入，首先为浸入系统设计一个类卡尔曼观测器，然后通过优化重建群值状态来构建观测器。在满足秩条件的情况下，如果能找到重建优化的一个全局最优解，则实现了全局指数稳定性 (GES)，这反映了非欧几里德状态空间固有的拓扑困难。当输入偏差联合估计时，可以保证半全局稳定性。该理论应用于双帧系统的GES观测器设计，能够建模一系列导航问题。提供了两个非平凡的例子来说明实现细节。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [465] [Design and optimization of a novel leaf-shape antenna for RF energy transfer](https://arxiv.org/abs/2507.18630)
> *新型叶形天线在射频能量传输中的设计与优化*

*Junbin Zhong, Mingtong Chen, Zhengbao Yang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 叶形天线, 射频能量传输, 生物启发, 915 MHz, 天线优化

**Comment:** 

> **TL;DR:** 本研究设计并优化了一种受自然叶片结构启发的新型叶形天线，用于射频能量传输，并在915 MHz频段实现了高效的能量捕获和设备供电。

**AI_Comments:** 该论文的创新点在于将自然界叶片结构应用于天线设计，提出了一种生物启发式的新颖方法。其重要性在于为射频能量传输领域提供了一种高效且可能具有更广应用前景的天线解决方案。未来的研究方向，如穿透混凝土和自主对准反馈系统，显示了该技术进一步发展的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种受生物启发的射频能量传输天线，优化其在915 MHz频段的性能，并评估其捕获射频能量的效率。

**Method:** 设计过程包括选择合适的叶形、使用AutoCAD和HFSS软件建模、制造PCB原型，并进行仿真和物理测试以优化天线性能。

**Result:** 天线在915 MHz频段的S11参数接近-20 dB，表明有效能量捕获。实验结果显示天线能在最远200厘米的距离为设备供电，充电时间反映了其效率。

**Conclusion:** 本研究得出结论，所提出的生物启发式天线设计改进了射频能量传输。

> **ai_Abstract:** 本研究提出并优化了一种受自然叶片启发的创新型叶形天线，专为射频能量传输设计。通过AutoCAD和HFSS建模及PCB原型制造，该天线在915 MHz频段实现了近-20 dB的S11参数，有效捕获能量。实验证明，该天线能够远距离为设备供电，验证了其在射频能量传输方面的效率提升。

> **摘要翻译:** 本研究提出了一种受自然叶片结构启发的新型叶形天线的设计与优化，用于射频能量传输。本研究的目标是开发一种生物启发式天线，通过阻抗匹配优化其在915 MHz频段的性能，并评估其捕获射频能量的效率。设计过程包括选择合适的叶形、使用AutoCAD和HFSS软件对天线进行建模、以及制造印刷电路板（PCB）原型。通过仿真和物理测试优化天线性能，在915 MHz频率下实现了接近-20 dB的S11参数，表明有效的能量捕获。实验结果表明，该天线能够在最远200厘米的距离为设备供电，充电时间反映了其效率。研究结论是，所提出的生物启发式设计改进了射频能量传输。未来的工作应侧重于测试天线穿透混凝土的能力以及开发用于自主对准的反馈系统。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [645] [A software framework for stochastic model predictive control of nonlinear continuous-time systems (GRAMPC-S)](https://arxiv.org/abs/2407.09261)
> *非线性连续时间系统随机模型预测控制的软件框架 (GRAMPC-S)*

*Daniel Landgraf, Andreas Völz, Knut Graichen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 随机模型预测控制, 非线性系统, 不确定性, 开源框架, GRAMPC-S

**Comment:** This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this article is
  published in Optimization and Engineering, and is available online at
  https://doi.org/10.1007/s11081-025-10006-z

> **TL;DR:** GRAMPC-S是一个开源的随机模型预测控制框架，适用于具有机会约束的非线性不确定系统，它通过不确定性传播方法和高斯过程回归将随机MPC问题转化为确定性问题，并已在实际应用中验证其毫秒级采样时间的性能。

**AI_Comments:** GRAMPC-S的创新之处在于其将随机MPC问题转化为确定性问题的能力，并结合了不确定性传播和高斯过程回归。作为一个开源框架，它降低了随机MPC技术的应用门槛。其在毫秒级采样时间下的实际应用能力，对于实时控制系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为具有机会约束的非线性不确定系统提供一个实用的、开源的随机模型预测控制框架，以解决传统方法在处理不确定性时的挑战。

**Method:** GRAMPC-S框架采用了多种不确定性传播方法来预测系统状态的随机矩，并利用高斯过程回归处理系统动力学中的未知部分。它将随机MPC公式重新表述为确定性问题，并使用GRAMPC求解。

**Result:** 通过对各种技术领域的示例进行评估，实验结果表明GRAMPC-S可以在毫秒级采样时间内，实际应用于非线性不确定系统的控制。

**Conclusion:** GRAMPC-S是一个有效的开源框架，能够实际应用于具有毫秒级采样时间的非线性不确定系统的随机模型预测控制。

> **ai_Abstract:** GRAMPC-S是一个开源的随机模型预测控制(MPC)软件框架，专为具有机会约束的非线性不确定系统设计。它集成了多种不确定性传播技术和高斯过程回归，能将复杂的随机MPC问题转化为可由GRAMPC求解的确定性问题。该框架在多领域应用中表现出色，尤其证明了其在毫秒级采样时间下对非线性不确定系统进行实际控制的能力。

> **摘要翻译:** 本文提出了一个用于具有机会约束的非线性不确定系统的开源随机模型预测控制框架GRAMPC-S。它提供了多种不确定性传播方法来预测系统状态的随机矩，并且可以通过高斯过程回归考虑系统动力学中的未知部分。这些方法被用于将随机MPC公式重新表述为确定性公式，并使用GRAMPC进行求解。所提出的框架的性能通过来自广泛技术领域的示例进行了评估。实验评估表明，GRAMPC-S可以在毫秒级采样时间内用于非线性不确定系统的实际控制。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [650] [Safe Reinforcement Learning-based Automatic Generation Control](https://arxiv.org/abs/2507.17868)
> *基于安全强化学习的自动发电控制*

*Amr S. Mohamed, Emily Nguyen, Deepa Kundur* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 强化学习, 自动发电控制, 安全, 控制屏障函数, 电力系统

**Comment:** 5 pages, conference: IEEE Power and Energy Systems General Meeting
  2025

> **TL;DR:** 针对电力系统控制中强化学习的安全问题，本文提出了一种基于控制屏障函数的框架，以实现自动发电控制的安全强化学习与部署。

**AI_Comments:** 这篇论文解决了强化学习在关键基础设施（如电力系统）应用中的核心挑战——安全性问题。通过引入控制屏障函数，它为强化学习的安全部署提供了一个有前景的解决方案，这对于推动RL在实际工程中的应用至关重要。其创新点在于将控制理论中的安全保障机制与强化学习相结合，弥补了传统RL在安全保证方面的不足。

<details>
  <summary>Details</summary>

**Motivation:** 随着电力系统对实施先进控制和决策算法以增强其可靠性、弹性和稳定性的需求日益增长，采用机器学习技术的安全性问题日益突出，因为这些方法通常缺乏安全保障。

**Method:** 本文提出了一种基于控制屏障函数（Control Barrier Functions）的框架，用于促进强化学习代理在电力系统控制应用（特别是自动发电控制）中的安全学习和部署。

**Result:** 论文开发了必要的安全屏障和强化学习框架，旨在建立对强化学习作为自动发电控制安全选项的信任。

**Conclusion:** 该研究为未来详细的验证和应用研究奠定了基础，旨在证明强化学习在自动发电控制中的安全性。

> **ai_Abstract:** 本文针对电力系统中强化学习应用缺乏安全保障的问题，提出了一种基于控制屏障函数的框架。该框架旨在实现强化学习代理在自动发电控制中的安全学习和部署，并开发了相应的安全屏障和强化学习机制，以建立对强化学习作为自动发电控制安全选项的信任，为未来的深入研究奠定基础。

> **摘要翻译:** 标题：基于安全强化学习的自动发电控制
摘要：在电力系统对实施先进控制和决策算法以增强其可靠性、弹性和稳定性的需求日益增长的同时，采用机器学习技术的安全性问题也日益突出。尽管这些方法可以用于得出更优的控制决策，但它们通常缺乏安全保障。本文提出了一种基于控制屏障函数的框架，以促进强化学习代理在电力系统控制应用中（特别是自动发电控制）的安全学习和部署。我们开发了必要的安全屏障和强化学习框架，旨在建立对强化学习作为自动发电控制安全选项的信任——这为未来详细的验证和应用研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [685] [Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles](https://arxiv.org/abs/2507.17875)
> *可信数据融合、多智能体自主性、自主车辆*

*R. Spencer Hallyburton, Miroslav Pajic* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 信任框架, 传感器融合, 多智能体, 隐马尔可夫模型, 网络安全

**Comment:** 

> **TL;DR:** 本文提出了一种基于信任的框架，利用隐马尔可夫模型（HMM）在分布式多智能体网络中进行可靠的传感器融合，以提高情报、监视和侦察（ISR）任务的性能并检测恶意行为者。

**AI_Comments:** 本文的创新之处在于提出了一种基于HMM的去中心化信任评估方法，并将其应用于多智能体环境中的传感器融合，以应对网络攻击。其重要性体现在提升了ISR任务的安全性、准确性和系统韧性。通过构建新的数据集和案例研究，验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体协作在情报、监视和侦察（ISR）任务中增强了态势感知，但无人机（UAV）的临时网络由于其去中心化性质面临安全挑战，容易受到网络物理攻击。本文旨在解决在分布式多智能体网络中确保传感器融合的信任问题。

**Method:** 本文引入了一个基于信任的框架，用于分布式多智能体网络中的可靠传感器融合。该框架利用基于隐马尔可夫模型（HMM）的方法，以去中心化的方式估计智能体及其提供信息的信任度。信任感知的数据融合优先融合来自可靠来源的数据。为了评估在系统/任务感知攻击下的可靠传感器融合，本文还构建了一个基于虚幻引擎模拟器的新型多智能体空中数据集。

**Result:** 通过案例研究，本文证明了改进的ISR性能以及在对抗环境中检测恶意行为者的能力。

**Conclusion:** 本文提出的基于信任的传感器融合框架能够提高ISR性能并在对抗环境中检测恶意行为者，从而增强了分布式多智能体网络在面临网络攻击时的韧性和准确性。

> **ai_Abstract:** 本文提出了一种用于分布式多智能体网络中可靠传感器融合的信任框架，旨在解决无人机临时网络面临的网络安全挑战。该框架采用基于隐马尔可夫模型（HMM）的方法来评估智能体信任度，并通过优先融合来自可靠来源的数据来提高数据融合的韧性和准确性。研究通过在虚幻引擎模拟器中构建的多智能体空中数据集进行评估，并展示了在对抗环境中改进的ISR性能和恶意行为者检测能力。

> **摘要翻译:** 多智能体协作增强了情报、监视和侦察（ISR）任务中的态势感知。无人机（UAV）的临时网络允许实时数据共享，但由于其去中心化性质，它们面临安全挑战，使其容易受到网络物理攻击。本文引入了一个基于信任的框架，用于分布式多智能体网络中的可靠传感器融合，利用基于隐马尔可夫模型（HMM）的方法，以去中心化的方式估计智能体及其提供信息的信任度。信任感知的数据融合优先融合来自可靠来源的数据，从而增强了在对抗环境中的韧性和准确性。为了评估在系统/任务感知攻击下的可靠传感器融合，我们提出了一个基于虚幻引擎模拟器构建的新型多智能体空中数据集。我们通过案例研究证明了改进的ISR性能以及在对抗环境中检测恶意行为者的能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [699] [Integrating and Comparing Radiality Constraints for Optimized Distribution System Reconfiguration](https://arxiv.org/abs/2411.11596)
> *配电系统重构中辐射状约束的集成与比较*

*Pablo Cortes, Alejandra Tabares, Fredy Franco, Astrid Xiomara Rodríguez, David Álvarez-Martínez* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 配电系统重构, 辐射状约束, 优化, 计算效率, 功率损耗

**Comment:** 

> **TL;DR:** 本文综合比较了配电系统重构中不同辐射状约束的计算负担，发现不同的约束集对计算效率有显著影响。

**AI_Comments:** 该研究通过系统地比较不同辐射状约束对配电系统重构计算效率的影响，为实际应用提供了实用指导。其创新点在于对现有约束的集成分析和性能对比，揭示了看似细节的约束选择对整体优化效率的重大影响，这对于大规模配电网络的优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 配电系统重构是一个旨在通过改变系统拓扑来最小化功率损耗的关键优化问题，但对于大规模网络，该问题计算资源需求高，且需要专门的辐射状约束来维持配电网络的树状结构。本文旨在分析和比较不同辐射状约束公式的计算负担。

**Method:** 本文对专业文献中提出的用于配电系统重构的不同辐射状约束公式进行了全面的分析，并对其计算负担进行了集成和比较。研究通过使用一致的硬件和软件设置，在多个知名测试案例中评估了这些约束的性能。

**Result:** 研究结果表明，根据所选择的辐射状约束集，计算效率存在显著差异。

**Conclusion:** 选择合适的辐射状约束集对于优化实际配电网络中的重构策略至关重要，能够显著影响计算效率。

> **ai_Abstract:** 本文研究了配电系统重构问题中不同辐射状约束公式的计算效率。通过在统一的软硬件环境下对多种约束进行测试案例评估，发现所选约束对计算性能有显著影响，为优化配电网络重构策略提供了重要指导。

> **摘要翻译:** 电力配电系统的重构是一个关键的优化问题，旨在通过操作互联开关来改变系统拓扑，从而最大程度地减少功率损耗。这个问题通常被建模为混合整数非线性规划，对于大型网络需要高计算资源，并且需要专门的辐射状约束来维持配电网络的树状结构。本文提出了一项全面的分析，该分析集成了并比较了专业文献中提出的用于配电系统重构的不同辐射状约束公式相关的计算负担。通过使用一致的硬件和软件设置，我们在几个知名测试案例中评估了这些约束的性能。我们的发现揭示了计算效率的显著差异，这取决于所选择的辐射状约束集，为优化实际配电网络中的重构策略提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [725] [Quantitative Damping Calculation and Compensation Method for Global Stability Improvement of Inverter-Based Systems](https://arxiv.org/abs/2507.18001)
> *逆变器系统全局稳定性改进的定量阻尼计算与补偿方法*

*Yang Li, Zenghui Zheng, Xiangyang Wu, Jiayong Li, Wei Wang, Qiang Zeng, Zhikang Shuai* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 定量阻尼, 稳定性改进, 逆变器系统, 阻尼补偿, 节点导纳模型

**Comment:** 

> **TL;DR:** 本文提出了一种定量阻尼计算和补偿方法，以提高基于逆变器系统的全局稳定性，并通过仿真和实验验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了定量阻尼计算方法，并结合特定的AD控制策略，解决了逆变器系统稳定性中阻尼量化和高效补偿的难题，对于提升电力系统稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多逆变器系统中的小信号稳定性问题导致的宽带振荡对系统安全运行构成重大威胁。研究表明系统不稳定是由于缺乏正阻尼，但目前尚未明确确保系统全局稳定所需的精确阻尼补偿量。

**Method:** 首先，基于系统节点导纳模型，提出了一种定量阻尼计算算法，可以建议所需的阻尼补偿量和补偿位置。然后，提出了一种带有输出电流前馈控制的特定AD策略，使AD接近纯电阻特性，有效提高系统阻尼效率。最后，使用一个包含三个逆变器的测试系统进行案例研究。

**Result:** 案例研究表明，所提出的方法为高效提升基于逆变器系统的全局稳定性提供了一个有前景的解决方案。仿真和实验验证了所提出方法的有效性。

**Conclusion:** 本文提出了一种定量阻尼计算和补偿方法，能够有效提升基于逆变器系统的全局稳定性，并通过仿真和实验得到了验证。

> **ai_Abstract:** 本文针对多逆变器系统中的宽带振荡问题，提出了一种定量阻尼计算与补偿方法以提升系统全局稳定性。该方法首先基于节点导纳模型计算所需的阻尼补偿量和位置，随后引入一种带有输出电流前馈控制的AD策略以提高阻尼效率。通过三逆变器系统案例研究，仿真和实验验证了所提方法的有效性。

> **摘要翻译:** 小信号稳定性问题引起的宽带振荡对多逆变器系统的安全运行构成重大威胁，吸引了广泛的研究关注。研究表明系统不稳定是由于缺乏正阻尼，但尚未明确指定确保系统全局稳定所需的精确阻尼补偿量。本文提出了一种可行的定量阻尼计算和补偿解决方案，以增强基于逆变器系统的全局稳定性。首先，基于系统节点导纳模型，提出了一种定量阻尼计算算法，该算法可以建议所需的阻尼补偿以及补偿位置，以充分改善稳定性。然后，我们提出了一种带有输出电流前馈控制的特定AD策略，该策略使AD具有准纯电阻特性，并能有效提高系统阻尼效率。最后，一个包含三个逆变器的测试系统被用作案例研究，结果表明所提出的方法为高效提升基于逆变器系统的全局稳定性提供了一个有前景的解决方案。仿真和实验验证了所提出的方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [760] [Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study](https://arxiv.org/abs/2507.18077)
> *碳排放流追踪：快速算法与加州电网研究*

*Yuqing Shen, Yuanyuan Shi, Daniel Kirschen, Yize Chen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 碳排放流追踪, 电网, 快速算法, 排放量化, 加州电网

**Comment:** In Submission, 16 pages, 11 figures, code available at
  https://github.com/yuqing5/Carbon-Tracker-California

> **TL;DR:** 本文提出了一种新颖高效的算法，用于精确量化电网中节点碳排放率，并通过加州电网案例研究验证了其有效性，揭示了排放的空间分布模式。

**AI_Comments:** 本文的创新之处在于提出了一种计算高效的碳排放流追踪算法，能够精确量化电网中各节点的排放贡献，填补了现有系统级排放信息缺乏空间精细度的空白。其结合图论方法处理复杂电网的排放传输，并通过实际大规模电网数据验证，具有较高的实用价值和研究基础性。开源的特性也促进了未来相关领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 电力系统脱碳是清洁能源转型的核心，但目前尚不清楚单个发电机组的排放如何在电网中传输以及如何影响特定位置的电力用户。现有系统级碳排放信息公开，但缺乏对排放空间分布的精细化理解。

**Method:** 本文提出了一种新颖且计算高效的方法，用于精确量化节点平均和边际碳排放率，适用于交流和直流最优潮流问题。该方法利用基于图的拓扑排序和有向循环消除技术，应用于由发电调度和最优潮流解形成的有向图。该算法能有效识别每个发电机组对每个节点的贡献，捕捉排放如何在不同系统条件下空间分布。通过使用实际CAISO数据和CATS模型模拟8,870总线的加州电网进行验证。

**Result:** 该方法准确估计了电力潮流条件、发电组合和全系统排放，并为加州每个县提供了细粒度的时空排放分析。研究揭示了真实世界中的位置和时间排放模式。

**Conclusion:** 本文提出的算法和加州研究是开源的，为未来电网排放、规划、运营和能源政策研究提供了基础。

> **ai_Abstract:** 本文提出了一种新颖高效的算法，用于追踪电力系统中碳排放的流动，并精确量化节点平均和边际碳排放率。该方法利用图论技术，分析发电机组对各节点的贡献，揭示排放的空间分布。通过对加州电网的实际数据模拟验证，该算法能够准确估计电力潮流和排放，并提供细粒度的时空排放分析，为电网脱碳和能源政策制定提供支持。

> **摘要翻译:** 电力系统脱碳是清洁能源转型的焦点。尽管系统运营商和公用事业公司越来越多地公布系统级的碳排放信息，但目前仍不清楚单个发电机组的排放是如何通过电网传输以及如何影响特定位置的电力用户的。本文提出了一种新颖且计算高效的方法，用于精确量化节点平均和边际碳排放率，适用于交流和直流最优潮流问题。该方法利用基于图的拓扑排序和有向循环消除技术，应用于由发电调度和最优潮流解形成的有向图。我们提出的算法能有效识别每个发电机组对每个节点的贡献，捕捉排放如何在不同系统条件下空间分布。为了验证其有效性并揭示真实世界中的位置和时间排放模式，我们使用实际CAISO数据和CATS模型模拟了8,870总线的真实加州电网。基于从CAISO公共数据获取或估计的一年期逐小时节点负荷和可再生能源发电数据，我们的方法准确估计了电力潮流条件、发电组合和全系统排放，并为加州每个县提供了细粒度的时空排放分析。我们的算法和加州研究都是开源的，为未来电网排放、规划、运营和能源政策研究提供了基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [761] [Integrated Learning and Optimization for Congestion Management and Profit Maximization in Real-Time Electricity Market](https://arxiv.org/abs/2412.18003)
> *实时电力市场中拥堵管理与利润最大化的集成学习与优化*

*Imran Pervez, Ricardo Pinto Lima, Omar Knio* | **Category: eess.SY, cs.AI, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 集成学习与优化, 实时电力市场, 经济调度, 直流最优潮流, 拥堵管理

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的集成学习与优化（ILO）方法，用于解决实时电力市场中的经济调度和直流最优潮流问题，旨在最小化事后惩罚和线路拥堵，从而显著改善经济运行。

**AI_Comments:** 本文的创新点在于提出了将学习和优化过程深度融合的ILO框架，而非传统的先预测后优化的序贯方法。这种集成方法能够直接针对经济运行目标进行优化，而非仅仅追求预测精度，这对于实时电力市场中的实际操作具有重要意义。通过直接解决事后惩罚和线路拥堵，该方法有望提升电力系统的运行效率和经济效益。

<details>
  <summary>Details</summary>

**Motivation:** 在实时电力市场中，存在事后惩罚和线路拥堵问题，这影响了电力系统的经济运行和利润最大化。传统的序贯学习与优化（SLO）方法主要关注预测准确性而非直接的经济效益。

**Method:** 本文开发了新颖的集成学习与优化（ILO）方法，以解决经济调度（ED）和直流最优潮流（DCOPF）问题。在这些优化问题中，负荷和功率传输分布因子（PTDF）矩阵被视为未知参数。ILO方法通过捕捉实时电力市场和线路拥堵行为来训练后悔函数，进而训练不同母线上的未知负荷和线路PTDF矩阵，以实现最小化事后惩罚和线路拥堵的目标。该方法与专注于预测准确性的序贯学习与优化（SLO）进行了比较。

**Result:** 实验证明，所提出的集成学习与优化（ILO）方法在最小化电力市场的事后惩罚和最小化线路拥堵方面表现出优越性，从而显著改善了经济运行。

**Conclusion:** 集成学习与优化（ILO）方法能够有效解决实时电力市场中的经济调度和直流最优潮流问题，通过直接优化以最小化事后惩罚和线路拥堵，显著提升了电力系统的经济运行效率。

> **ai_Abstract:** 本文提出了一种新颖的集成学习与优化（ILO）方法，用于解决实时电力市场中的经济调度（ED）和直流最优潮流（DCOPF）问题。该方法将负荷和功率传输分布因子（PTDF）作为未知参数，并通过训练后悔函数来捕捉市场和拥堵行为，进而优化这些未知参数以最小化事后惩罚和线路拥堵。实验结果表明，与传统的序贯学习与优化（SLO）方法相比，ILO在提升电力市场经济运行方面表现出显著的优越性。

> **摘要翻译:** 我们开发了新颖的集成学习与优化（ILO）方法，以解决经济调度（ED）和直流最优潮流（DCOPF）问题，从而实现更好的经济运行。经济调度的优化问题将负荷作为未知参数，而直流最优潮流问题则将负荷和功率传输分布因子（PTDF）矩阵作为未知参数。PTDF表示由于两个区域之间的实功率传输而导致的输电线路上实功率的增量变化。这些值代表了输电线上潮流的线性化近似。我们开发了新颖的ILO公式，利用ED和DCOPF优化公式来解决电力市场中的事后惩罚和线路拥堵问题。我们提出的方法捕捉实时电力市场和线路拥堵行为，以训练后悔函数，该函数最终训练不同母线上的未知负荷和线路PTDF矩阵，以实现上述事后目标。所提出的方法与序贯学习与优化（SLO）进行了比较，后者训练负荷和PTDF预测以提高准确性而非经济运行。我们的实验证明，ILO在最小化电力市场中的事后惩罚和最小化线路拥堵方面具有优越性，从而显著改善了经济运行。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [3] [Time and Frequency Synchronization for Multiuser OTFS in Uplink](https://arxiv.org/abs/2507.17966)
> *上行链路多用户OTFS中的时间和频率同步*

*Mohsen Bayat, Sanoopkumar P. S., Arman Farhang* | **Category: eess.SP** | **Updated: 2025-07-23**

**Keywords:** 多用户OTFS, 时间同步, 频率同步, 高移动性, 导频结构

**Comment:** 

> **TL;DR:** 本文提出并详细阐述了针对高移动性场景下上行链路多用户OTFS系统的时间和频率同步技术，通过引入新颖的导频结构和估计算法，旨在精确估计和校正定时偏移（TOs）和载波频率偏移（CFOs）。

**AI_Comments:** 该论文的创新点在于提出了两种新颖的定时偏移（TO）估计算法和一种载波频率偏移（CFO）估计算法，特别是在导频结构设计（SU-PCP和MU-PCP）和估计算法（基于相关性、滤波器组结合阈值、CPF-BEM简化ML搜索）方面。其重要性在于解决了高移动性多用户OTFS系统中的关键同步挑战，对于提升未来无线通信系统的性能具有实际意义。摘要中未明确提及实验结果或性能对比，因此无法评估其具体提升效果或潜在局限性。

<details>
  <summary>Details</summary>

**Motivation:** 在高移动性场景下，上行链路多用户正交时频空（MU-OTFS）系统中，准确估计和校正定时偏移（TOs）和载波频率偏移（CFOs）至关重要。TOs估计对于定位用户导频至关重要，而CFOs估计则能提高信道估计精度。

**Method:** 本文提出了两种定时偏移（TO）估计算法和一种载波频率偏移（CFO）估计算法。首先，针对现有MU-OTFS多用户导频结构，将脉冲导频（IMP）替换为更实用的带循环前缀导频（PCP），称为单用户启发式PCP（SU-PCP），并利用不同的Zadoff-Chu（ZC）序列通过接收端相关性实现导频分离，进而提出一种基于相关性的TO估计算法。其次，提出一种频谱效率高且实用的导频模式（MU-PCP），其中每个用户在时延-多普勒平面上的共享导频区域内传输PCP。接收端利用滤波器组分离不同用户信号并精确估计TO，并通过推导数学阈值范围来增强TO估计精度，即寻找相关函数中的第一个主要峰值而非仅依赖最高峰。最后，提出的CFO估计算法将多维最大似然（ML）搜索问题简化为多个一维搜索问题，并应用第一类切比雪夫多项式基展开模型（CPF-BEM）有效处理信道时变性以获得所有用户的CFO估计。

**Result:** 所提出的技术旨在精确估计和校正定时偏移和载波频率偏移，提高信道估计精度，并有效处理信道时变性。具体量化结果未在摘要中提及。

**Conclusion:** 本文成功提出了针对高移动性场景下上行链路多用户OTFS系统的时间和频率同步技术，通过创新的导频结构设计、相关性及滤波器组相结合的TO估计算法，以及简化多维ML搜索并结合CPF-BEM的CFO估计算法，有效解决了复杂信道环境下的同步挑战，有望提升系统性能。

> **ai_Abstract:** 本文针对高移动性场景下的上行链路多用户OTFS系统，提出了创新的时间和频率同步技术。研究重点在于精确估计和校正定时偏移（TOs）和载波频率偏移（CFOs）。在TO估计方面，论文提出了两种方法：一是将现有导频结构中的脉冲导频替换为SU-PCP，并利用Zadoff-Chu序列进行相关性分离和估计；二是提出一种频谱高效的MU-PCP模式，通过滤波器组分离用户信号并结合数学阈值寻找相关函数的主峰来提高精度。在CFO估计方面，通过将多维最大似然搜索问题简化为一维问题，并引入第一类切比雪夫多项式基展开模型（CPF-BEM）来有效处理信道时变性。这些方法旨在提高多用户OTFS系统在复杂动态环境下的同步准确性和信道估计性能。

> **摘要翻译:** 在本文中，我们提出了用于高移动性场景下上行链路多用户OTFS（MU-OTFS）系统的时间和频率同步技术。这项工作专注于精确估计和校正定时偏移（TOs）和载波频率偏移（CFOs）。具体来说，TO估计对于在时延-时间平面上定位用户导频至关重要，而CFO估计则能提高信道估计精度。首先，我们针对MU-OTFS中现有的多用户导频结构提出了一种TO估计算法。我们将该导频结构中的脉冲导频（IMP）替换为一种更实用的带循环前缀导频（PCP），称为单用户启发式PCP（SU-PCP）。该结构采用不同的Zadoff-Chu（ZC）序列，通过接收端相关性实现导频分离。因此，我们引入了一种使用该导频结构的基于相关性的上行链路MU-OTFS TO估计算法。接下来，提出了一种频谱效率高且实用的导频模式，其中每个用户在时延-多普勒平面上的共享导频区域内传输PCP，称为MU-PCP。在接收端，第二种TO估计算法利用滤波器组分离不同用户的信号并精确估计其TO。然后，我们推导了一个数学阈值范围，通过寻找相关函数中的第一个主要峰值而非仅仅依赖最高峰来增强TO估计精度。在使用所提出的TO估计算法之一定位接收到的用户导频信号后，我们提出的CFO估计算法将多维最大似然（ML）搜索问题简化为多个一维搜索问题。在该技术中，我们应用第一类切比雪夫多项式基展开模型（CPF-BEM）来有效处理信道的时变性，以获得所有用户的CFO估计。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [38] [GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing](https://arxiv.org/abs/2507.18166)
> *通过多天线处理缓解GNSS干扰器和欺骗器*

*Jonas Elmiger, Gian Marti, Christoph Studer* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** GNSS, 干扰, 欺骗, 多天线, 缓解

**Comment:** 

> **TL;DR:** 本文提出了一种名为 SCHIEBER 的新型多天线 GNSS 接收器方法，无需先验知识即可有效缓解干扰器和欺骗攻击。

**AI_Comments:** SCHIEBER 方法的创新之处在于其无需先验知识即可同时处理干扰和欺骗攻击的能力，特别是针对欺骗攻击采用的与接收器位置无关的到达方向和伪距一致性测试，这对于提高GNSS系统的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代定位依赖于全球导航卫星系统（GNSS）的无线电信号，但这些信号接收功率低，容易受到干扰攻击（恶意发射机发出强干扰以破坏信号获取）和欺骗攻击（恶意发射机通过传输虚假 GNSS 信号来模仿合法卫星）。

**Method:** 本文提出了一种名为 SCHIEBER 的新型多天线 GNSS 接收器方法，无需接收器位置或攻击类型的任何先验知识。该方法通过以下方式缓解攻击：在信号获取期间使用新开发的自适应空间滤波技术缓解干扰器；在信号获取后，通过比较所获取信号的到达方向（DoA）和伪距估计值的一致性来识别和拒绝欺骗器，该测试与未知的接收器位置无关。

**Result:** 通过对 GPS L1 C/A 系统在欺骗和干扰攻击下进行广泛仿真，证明了该方法的有效性。

**Conclusion:** SCHIEBER 方法能够有效缓解 GNSS 干扰和欺骗攻击，且无需先验知识。

> **ai_Abstract:** 本文提出了一种名为 SCHIEBER 的新型多天线 GNSS 接收器方法，旨在缓解干扰和欺骗攻击，且无需接收器位置或攻击类型的先验知识。该方法通过在信号获取阶段使用自适应空间滤波来缓解干扰器，并通过在信号获取后比较信号到达方向和伪距估计值的一致性来识别和拒绝欺骗器。研究通过对 GPS L1 C/A 系统在不同攻击下的仿真验证了其有效性。

> **摘要翻译:** 现代定位依赖于全球导航卫星系统（GNSS）的无线电信号。它们的低接收功率使得这些无线电信号容易受到干扰攻击，在这种攻击中，恶意发射器发出强干扰以破坏信号获取。此外，GNSS 容易受到欺骗攻击，在这种攻击中，恶意发射器通过传输虚假的 GNSS 信号来模仿合法的卫星。我们提出了一种名为 SCHIEBER 的新型多天线 GNSS 接收器方法，该方法无需接收器位置或攻击类型的任何先验知识即可缓解干扰器和欺骗器：干扰器在信号获取期间使用最近开发的自适应空间滤波技术进行缓解。欺骗器在信号获取后通过一种新方法识别和拒绝，该方法通过比较其各自的到达方向（DoA）和伪距估计值的一致性来测试所获取信号的一致性，该测试与未知的接收器位置无关。我们通过对 GPS L1 C/A 系统在欺骗和干扰攻击下的广泛仿真来证明我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [39] [Metasurface-based Fluid Antennas: from Electromagnetics to Communications Model](https://arxiv.org/abs/2507.17982)
> *基于超表面流体天线：从电磁学到通信模型*

*Pablo Ramírez-Espinosa, Cleofás Segura-Gómez, Ángel Palomares-Caballero, F. Javier López-Martínez, David Morales-Jiménez* | **Category: eess.SP** | **Updated: 2025-07-23**

**Keywords:** 流体天线系统, 超表面, 动态超表面天线, 分析模型, 通信模型

**Comment:** 

> **TL;DR:** 本文提出了一种用于基于超表面的流体天线系统（FASs）的完整分析模型，并通过全波仿真验证，证明其性能可与理想FASs媲美。

**AI_Comments:** 该论文的创新之处在于为基于超表面的流体天线系统（FASs）提供了一个完整的分析模型，解决了现有电子可重构天线在理论建模上的难题。通过引入动态超表面天线（DMAs）并结合电路理论，该研究为FAS的性能分析和系统设计提供了宝贵的理论洞察和闭合形式表达式，对于推动FAS的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 电子可重构天线在分析建模方面面临挑战，常常需要全波仿真或测量进行表征，这严重限制了理论洞察的提取。为了解决这些困难并响应对流体天线系统（FASs）日益增长的兴趣，本文旨在提出一个完整的分析模型。

**Method:** 本文提出通过动态超表面天线（DMAs）实现流体天线系统（FAS）的概念，并利用电路理论，以导纳矩阵的形式重写了FAS的传统信号模型，从而考虑了超表面固有的电磁效应。该模型通过全波仿真进行验证，并提供了关键指标的闭合形式表达式。

**Result:** 所提出的模型通过全波仿真验证，显示出良好的一致性。结果证实，基于DMA的实际FASs可以实现与理想位置灵活天线相似的性能。

**Conclusion:** 本文成功提出了基于超表面的流体天线系统的完整分析模型，并通过仿真验证了其有效性，表明实际的动态超表面天线（DMA）实现能够达到与理想FASs相当的性能。

> **ai_Abstract:** 本文针对电子可重构流体天线系统（FAS）分析建模的挑战，提出了一种基于动态超表面天线（DMA）的完整分析模型。该模型利用电路理论，以导纳矩阵形式重构了FAS的信号模型，并经全波仿真验证，显示出良好的准确性。研究结果表明，实际的DMA-based FASs能够达到与理想FASs相媲美的性能，为FAS的系统设计提供了理论基础和实用工具。

> **摘要翻译:** 流体天线系统（FAS）作为一种有效而简单的空间分集利用方式，已成为无线通信领域的热门话题。由于物理移动辐射单元的局限性，电子可重构天线正成为FAS的实际实现方式，因为改变辐射模式在功能上等同于物理移动设备。然而，电子可重构天线在分析建模方面带来了挑战，通常需要全波仿真或测量才能进行表征；这严重限制了对系统设计有用的理论洞察的提取。受这些困难以及对FAS日益增长的兴趣的驱动，本文提出了一种基于超表面FAS的完整分析模型。具体来说，我们提倡通过动态超表面天线（DMA）实现FAS概念，DMA迄今已在多输入多输出（MIMO）系统中被提议作为阵列替代品。我们利用电路理论，根据导纳矩阵重写了FAS的传统信号模型，从而考虑了超表面固有的电磁效应。该模型通过全波仿真验证，显示出良好的一致性。我们进一步阐述了如何将该模型应用于标准性能分析，并提供了关键指标的闭合形式表达式，包括得到的信号协方差矩阵。结果证实，实际的基于DMA的FAS可以实现与理想的位置灵活天线相似的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [70] [Multiple Active STAR-RIS-Assisted Secure Integrated Sensing and Communication via Cooperative Beamforming](https://arxiv.org/abs/2507.18035)
> *多主动STAR-RIS辅助的协同波束成形安全集成感知与通信*

*Hyeonho Noh, Hyeonsu Lyu, Hyun Jong Yang* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** STAR-RIS, 集成感知与通信, 安全通信, 波束成形, 交替优化

**Comment:** 

> **TL;DR:** 本文研究了多主动STAR-RIS辅助的安全集成感知与通信网络，通过协同波束成形优化以最大化通信和速率，同时满足感知和安全约束。

**AI_Comments:** 本文的创新点在于将多个主动STAR-RIS引入到安全ISAC网络中，并通过协同波束成形优化来提升系统性能。其提出的交替优化框架有效解决了高度非凸的优化难题，并通过仿真验证了其在和速率增益和约束满足方面的优越性。这对于未来6G通信中ISAC和RIS技术的融合发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索在多主动STAR-RIS赋能的集成感知与通信（ISAC）网络中，如何在满足严格感知和安全要求的同时，最大化通信和速率。

**Method:** 提出了一种高效的交替优化（AO）框架来解决高度非凸的优化问题。该框架将问题重构并分解为子问题，基站波束成形器通过KKT条件以闭合形式更新，而STAR-RIS的反射/传输矢量通过逐次凸逼近（SCA）细化，并利用半定规划（SDP）和半定松弛（SDR）求解。

**Result:** 所提出的算法在满足感知和安全约束的同时，相较于无源RIS和单STAR-RIS基线，实现了显著的和速率增益。

**Conclusion:** 通过协同优化基站波束成形器和STAR-RIS系数，可以在多主动STAR-RIS辅助的ISAC网络中有效提高通信性能，同时严格满足感知和安全要求。

> **ai_Abstract:** 本文研究了多主动STAR-RIS辅助的安全集成感知与通信（ISAC）网络，旨在通过联合优化基站波束成形器和STAR-RIS系数，在满足严格感知SINR、信息泄露上限以及功率约束的前提下，最大化通信和速率。针对所形成的高度非凸优化问题，提出了一种基于交替优化（AO）的解决方案，结合KKT条件和逐次凸逼近（SCA）进行求解。仿真结果表明，该算法在实现显著和速率增益的同时，能有效满足各项感知与安全要求。

> **摘要翻译:** 本文探讨了一种由多个主动同时发射和反射可重构智能表面（STAR-RIS）赋能的集成感知与通信（ISAC）网络。基站（BS）为多个用户提供下行通信，同时询问一个感知目标。我们联合优化基站发射波束成形器和每个主动STAR-RIS的反射/传输系数，以最大化总通信和速率，同时满足（i）严格的感知信噪比（SINR）要求，（ii）机密信息泄露的上限，以及（iii）基站和STAR-RISs的独立硬件和总功率限制。由此产生的高度非凸问题通过高效的交替优化（AO）框架解决。首先，将原始公式重构为等价但更易处理的形式，并划分为子问题。基站波束成形器通过Karush-Kuhn-Tucker（KKT）条件以闭合形式更新，而STAR-RIS的反射和传输矢量通过逐次凸逼近（SCA）进行细化，生成一个半定规划，然后通过半定松弛求解。全面的仿真表明，所提出的算法在严格满足规定的感知和安全约束的同时，相对于无源RIS和单STAR-RIS基线，提供了显著的和速率增益。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [100] [Geometrical portrait of Multipath error propagation in GNSS Direct Position Estimation](https://arxiv.org/abs/2507.18096)
> *GNSS直接定位中多径误差传播的几何表征*

*Jihong Huang, Rong Yang, Wei Gao, Xingqun Zhan, Zheng Yao* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** GNSS, 直接定位估计, 多径误差, 几何分析, SCMB模型

**Comment:** 

> **TL;DR:** 本文通过几何分析，提出了GNSS直接定位（DPE）中多径误差的几何表征方法，引入了SCMB模型，并通过仿真和实测验证，为DPE卫星选择提供几何参考。

**AI_Comments:** 本文创新性地从几何角度分析了GNSS直接定位（DPE）中的多径误差传播，并提出了SCMB模型，填补了DPE多径理论表征的空白。其研究结果对于优化DPE系统在复杂城市环境中的性能，特别是卫星选择策略具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前GNSS直接定位估计（DPE）理论缺乏对多径误差的理论表征。

**Method:** 本文通过几何分析，量化了多径对交叉模糊函数（CAF）和位置、速度、时间（PVT）解的偏差影响，并引入了卫星圆形多径偏差（SCMB）模型，该模型整合了来自多个卫星通道的CAF和PVT误差。通过蒙特卡洛仿真和城市峡谷测试验证了该方法的正确性。

**Result:** 研究结果表明，最大PVT偏差取决于在各个卫星通道中观察到的最大多径误差。此外，PVT偏差随卫星仰角的增加而增加，受CAF多径偏差投影的影响。

**Conclusion:** 本研究为从几何角度选择DPE卫星提供了参考，强调了选择高低仰角平衡组合以实现最佳卫星几何配置的重要性。

> **ai_Abstract:** 本文针对GNSS直接定位估计（DPE）中多径误差缺乏理论表征的问题，通过几何分析，提出了多径误差的几何表征方法。研究量化了多径对交叉模糊函数（CAF）和位置、速度、时间（PVT）解的影响，并引入了卫星圆形多径偏差（SCMB）模型。通过蒙特卡洛仿真和城市峡谷测试验证了该方法的正确性，结果表明最大PVT偏差与最大多径误差相关，并随卫星仰角增大而增大。该研究为DPE卫星的选择提供了几何参考。

> **摘要翻译:** 直接定位估计（DPE）是一种直接从GNSS信号的交叉模糊函数（CAF）中估计位置、速度和时间（PVT）信息的方法，显著增强了接收机在城市环境中的鲁棒性。然而，在DPE理论背景下，多径误差的理论表征仍然缺乏。几何观测突出显示了源自多径和热噪声的DPE误差的独特特征，分别表现为估计偏差和方差。本文在通过几何分析扩展DPE噪声方差理论框架的基础上，通过量化由于偏心偏差相对于方位角和仰角引起的CAF和PVT解的偏差，重点关注多径误差的几何表示。引入了一种卫星圆形多径偏差（SCMB）模型，该模型整合了来自多个卫星通道的CAF和PVT误差。通过讨论各种多径条件，建立了最大或最小PVT偏差的边界。通过蒙特卡洛仿真和城市峡谷测试，证实了多径几何表征的正确性。研究结果表明，最大PVT偏差取决于在各个卫星通道中观察到的最大多径误差。此外，PVT偏差随卫星仰角的增加而增加，受CAF多径偏差投影的影响。这为从几何角度选择DPE卫星提供了参考，强调了选择高低仰角平衡组合以实现最佳卫星几何配置的重要性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [130] [Envelope Control Enabled Probabilistic Shaping for Peak Power Constrained IM DD Systems](https://arxiv.org/abs/2507.18149)
> *峰值功率受限IM-DD系统中包络控制实现的概率整形*

*Dongdong Zou, Wei Wang, Jiawen Yao, Zhongxing Tian, Zeyu Feng, Huan Huang, Fan Li, Gordon Ning Liu, Gangxiang Shen, Yi Cai* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 概率整形, 强度调制和直接检测, 包络控制, 动态选择映射, 记忆效应

**Comment:** 

> **TL;DR:** 提出了一种新的间接概率整形方案，通过包络控制和动态选择映射，提高了峰值功率受限IM-DD系统在存在记忆效应时的性能。

**AI_Comments:** 该工作提出了一种新颖的间接概率整形方案，通过独特的包络控制和动态选择映射机制来解决IM-DD系统中记忆效应带来的挑战，有效提升了系统性能，并为该领域的未来研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 概率整形（PS）在强度调制和直接检测（IM-DD）系统中受到关注，但由于其独特的系统模型和固有约束，PS技术在IM-DD系统中的有效应用仍是一个开放问题，尤其是在存在记忆效应的系统中。

**Method:** 提出了一种针对峰值功率受限（PPC）IM-DD系统的间接PS方案。关键思想在于策略性地控制信号包络以减轻记忆效应引起的损伤。该方案在发射端引入动态选择映射（DSLM）机制，使当前符号不仅由当前比特模式决定，还由指定记忆长度内先前生成的符号决定。在接收端，提出了一种带有改进M-BCJR算法的涡轮均衡器来恢复DSLM引起的模糊比特。

**Result:** 在56GBaud PAM8系统中的实验验证表明，所提出的方案在2km单模光纤传输上实现了1dB的接收机灵敏度提升。此外，该方案还被证明与典型的概率幅度整形架构兼容，实现了简单且细粒度的速率自适应能力。

**Conclusion:** 这项工作为PS技术在存在记忆效应的峰值功率受限IM-DD系统中的应用开辟了新视野。

> **ai_Abstract:** 本论文提出了一种针对峰值功率受限IM-DD系统的新型间接概率整形（PS）方案，旨在解决PS在存在记忆效应的IM-DD系统中应用面临的挑战。该方案通过策略性地控制信号包络来减轻记忆效应引起的损伤，并在发射端引入动态选择映射（DSLM）机制，在接收端采用改进的M-BCJR算法的涡轮均衡器进行比特恢复。实验结果表明，该方案在56GBaud PAM8系统中实现了1dB的接收机灵敏度提升，并兼容现有概率幅度整形架构，支持灵活的速率自适应。该工作为PS技术在具有记忆效应的IM-DD系统中的应用提供了新思路。

> **摘要翻译:** 概率整形（PS）在强度调制和直接检测（IM-DD）系统中引起了广泛关注。然而，由于独特的系统模型和固有限制，PS技术在IM-DD系统中的有效应用仍然是一个开放问题，特别是在具有记忆效应的系统中。在本文中，提出了一种专门针对峰值功率受限（PPC）IM-DD系统的新型间接PS方案。其核心思想在于策略性地控制信号包络，以减轻记忆效应引起的损伤，例如非线性、过冲、峰均功率比增强等。所提出的方案在发射端引入了动态选择映射（DSLM）机制，实现了非典型的比特到符号映射，其中当前符号不仅由当前比特模式决定，还由指定记忆长度内先前生成的符号决定。在接收端，提出了一种带有改进M-BCJR算法的涡轮均衡器，以实现DSLM引起的模糊比特的恢复。在56GBaud PAM8系统中的实验验证表明，所提出的方案在2km单模光纤传输上实现了1dB的接收机灵敏度提升。此外，所提出的方案还被证明与典型的概率幅度整形架构兼容，从而实现了简单且细粒度的速率自适应能力。据我们所知，这项工作为PS技术在具有记忆效应的峰值功率受限IM-DD系统中的应用开辟了新视野。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [155] [ICWLM: A Multi-Task Wireless Large Model via In-Context Learning](https://arxiv.org/abs/2507.18167)
> *ICWLM：一种基于上下文学习的多任务无线大模型*

*Yuxuan Wen, Xiaoming Chen, Maojun Zhang, Zhaoyang Zhang* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 无线大模型, 上下文学习, 多任务学习, 物理层, 泛化能力

**Comment:** 

> **TL;DR:** ICWLM是一个无线原生的基础模型，利用上下文学习和动态权重平均，在物理层同时解决多任务问题，表现出强大的泛化能力。

**AI_Comments:** ICWLM的创新之处在于其作为无线原生基础模型的定位，结合上下文学习（ICL）以实现高效的泛化和适应性，以及动态权重平均（DWA）来优化多任务训练。这为未来无线网络中统一、自适应AI模型的开发提供了一个有前景的方向，有望显著降低部署复杂性和提高资源管理效率。

<details>
  <summary>Details</summary>

**Motivation:** 当前的深度学习方法在无线通信物理层应用中通常是任务特定的，并且面临数据稀缺和泛化能力差的挑战，尤其是在大规模MIMO和毫米波技术引入的网络复杂性和计算需求增加的背景下。

**Method:** 本文提出了一种新颖的上下文无线大模型（ICWLM），这是一个无线原生的基础模型，直接在大型、混合无线数据集上从头开始训练。它利用上下文学习（ICL）来适应不同的系统配置和信道条件，无需大量再训练。此外，采用动态权重平均（DWA）算法来动态平衡多任务训练期间的各个任务损失。

**Result:** 仿真结果表明，ICWLM与任务特定方法相比，实现了具有竞争力的性能，并对未见的系统配置表现出卓越的泛化能力。

**Conclusion:** ICWLM为未来无线网络开发统一和自适应的AI模型提供了一个有前景的范例，有望降低部署复杂性并增强智能资源管理。

> **ai_Abstract:** 本文提出了ICWLM，一个无线原生的多任务大模型，旨在解决物理层深度学习中数据稀缺和泛化能力差的问题。ICWLM直接在混合无线数据集上训练，并利用上下文学习实现对不同系统配置的自适应，同时采用动态权重平均优化多任务学习。实验证明，ICWLM在多用户预编码和信道预测等任务上性能优越，并展现出强大的泛化能力。

> **摘要翻译:** 无线通信技术的快速发展，特别是大规模多输入多输出（mMIMO）和毫米波（mmWave），带来了显著的网络复杂性和计算需求。为改善物理层性能，已投入大量研究努力，采用深度学习（DL）方法，然而这些方法通常是任务特定的，且面临数据稀缺和泛化能力差的问题。为应对这些挑战，我们提出了一种新颖的上下文无线大模型（ICWLM），这是一个专为物理层同时进行多任务学习而设计的无线原生基础模型。与将无线数据适配到预训练大语言模型（LLMs）的传统方法不同，ICWLM直接从头开始在大规模、混合无线数据集上进行训练。它共同解决了多个经典的物理层问题，包括多用户预编码（和速率最大化和最大最小信噪比）和信道预测。ICWLM的一个关键创新是其利用上下文学习（ICL），使模型能够以最少的演示对适应不同的系统配置和信道条件，从而无需进行大量再训练。此外，我们采用动态权重平均（DWA）算法来动态平衡多任务训练期间的各个任务损失，确保在不同目标下实现高效稳定的学习。广泛的仿真结果表明，与任务特定方法相比，ICWLM实现了具有竞争力的性能，同时对未见的系统配置表现出卓越的泛化能力。这项工作为未来无线网络开发统一和自适应的AI模型提供了一个有前景的范例，有望降低部署复杂性并增强智能资源管理。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [185] [Quantized Signal Recovery with Interference via Parametrized Look-Up Tables](https://arxiv.org/abs/2507.18370)
> *通过参数化查找表进行带干扰的量化信号恢复*

*Morriel Kasher, Michael Tinston, Predrag Spasojevic* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 量化信号恢复, 参数化查找表, 干扰消除, 低分辨率ADC, 信号处理

**Comment:** 13 pages, 18 figures

> **TL;DR:** 本文提出了一种利用参数化查找表（LUT）进行低分辨率模数转换器数字后校正的方法，该方法能有效恢复带干扰的量化信号，并在均方误差和无杂散动态范围方面显著优于传统线性滤波技术。

**AI_Comments:** 本文的创新点在于将参数化模型与查找表结合，用于低分辨率ADC的数字后校正，并通过仿真验证了其在复杂干扰环境下恢复信号的高精度和鲁棒性。其重要性在于提供了一种优于传统线性滤波技术且对非线性、时变干扰更具适应性的解决方案，在无线通信等领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了高效地对低分辨率模数转换器进行全数字后校正，并优化查找表的性能，需要结合输入信号、噪声和干扰信号的参数模型来提高信号恢复的准确性和鲁棒性。

**Method:** 研究评估了三种分析估计器与参数化查找表的集成，特别适用于低分辨率、非线性或宽带量化器。同时，提出了几种近似方法，以提高对移相键控输入信号和线性调频干扰信号的估计问题的可处理性。

**Result:** 仿真结果验证了所提出的估计器能够实时高精度地恢复所需输入信号的瞬时值，包括消除由高功率带外干扰引起的前端饱和导致的谐波失真。与传统线性滤波技术相比，该估计器实现了显著增益，并且对输入参数、非线性量化器和时变干扰源的变化具有鲁棒性。对于3位量化的音调输入信号，使用固定的12抽头模型，均方误差改善超过10 dB，无杂散动态范围改善超过20 dBc。

**Conclusion:** 本文提出的基于参数化查找表的估计器能够高效、准确且鲁棒地恢复带干扰的量化信号，显著优于传统线性滤波技术，尤其适用于低分辨率和非线性量化器。

> **ai_Abstract:** 本文提出了一种基于参数化查找表（LUTs）的信号恢复方法，用于高效地对低分辨率模数转换器进行数字后校正。通过结合输入信号、噪声和干扰的参数模型，优化了LUTs的性能。研究评估了三种分析估计器，并提出了近似方法以提高估计可处理性。仿真结果表明，该方法能高精度实时恢复信号，有效消除谐波失真，且在均方误差和无杂散动态范围上显著优于传统线性滤波，同时对多种输入变化和干扰源具有鲁棒性。

> **摘要翻译:** 通过使用查找表（LUTs），可以实现低分辨率模数转换器的高效全数字后校正。通过为预期输入信号、噪声水平和干扰信号引入参数模型，可以优化查找表的性能。我们评估了三种分析估计器与参数化查找表的集成，特别适用于低分辨率、非线性或宽带量化器。我们还提出了几种近似方法，以提高移相键控输入信号和线性调频干扰信号估计问题的可处理性。仿真结果验证了我们的估计器能够实时高精度地恢复所需输入信号的瞬时值。这包括消除由于高功率带外干扰导致的前端饱和，从而混叠到所需信号带宽内的谐波失真。我们的估计器被证明比传统的线性滤波技术取得了显著增益，同时对输入参数、非线性量化器和时变干扰源的变化具有鲁棒性。对于一个量化为3位的音调输入，并使用固定的12抽头模型进行估计，我们在均方误差方面实现了大于10 dB的改进，在无杂散动态范围方面实现了大于20 dBc的改进。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [215] [A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff](https://arxiv.org/abs/2507.18587)
> *用于大规模MIMO预编码的自适应用户速率-功率权衡基础模型*

*Jérôme Emery, Ali Hasanzadeh Karkan, Jean-François Frigon, François Leduc-Primeau* | **Category: eess.SP, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大规模MIMO, 预编码, 基础模型, 深度学习, 数据增强

**Comment:** 6 pages, 3 figures. Accepted to the IEEE International Symposium on
  Personal, Indoor and Mobile Radio Communications (PIMRC) 2025

> **TL;DR:** 本文提出了一种基于Transformer的基础模型，用于大规模MIMO预编码，旨在最小化发射机能耗并自适应用户速率需求。该模型在零样本部署下性能优于零迫，接近加权最小均方误差且复杂度降低8倍，并通过数据增强解决了数据稀缺问题，从而促进了深度学习在实际中的应用。

**AI_Comments:** 本文提出了一种创新的Transformer基础模型，解决了深度学习在mMIMO预编码实际应用中面临的数据稀缺和训练复杂性两大核心挑战。其零样本部署能力和显著降低的复杂度是重要的亮点，有望加速DL在无线通信领域的落地。动态适应用户速率需求的能力也为更高层协议的优化提供了灵活性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在解决大规模多输入多输出（mMIMO）系统预编码问题上展现出潜力，但其训练需要高质量的本地数据集，这在实际部署中往往难以收集。

**Method:** 本文提出了一种基于Transformer的基础模型，用于mMIMO预编码，旨在最小化发射机能耗，同时动态适应每个用户的速率需求。为解决数据稀缺环境下的模型适应性问题，引入了一种数据增强方法，通过计算预训练特征提取器输出之间的余弦相似度来寻找与目标分布相似的训练样本。

**Result:** 在相同能耗下，所提出的基础模型在零样本部署时显著优于零迫（Zero Forcing），并且在复杂度降低8倍的情况下，性能接近加权最小均方误差（Weighted Minimum Mean Squared Error）。

**Conclusion:** 本文的工作通过解决数据可用性和训练复杂性方面的挑战，使得基于深度学习的解决方案得以在实践中实施。此外，动态配置每个用户速率需求的能力可被更高层的资源分配和调度算法利用，以更好地控制能源效率、频谱效率和公平性。

> **ai_Abstract:** 本文针对大规模MIMO预编码中深度学习模型训练数据难以获取的挑战，提出了一种基于Transformer的基础模型。该模型能够最小化发射机能耗并动态调整用户速率需求。实验结果表明，在零样本部署下，该模型性能显著优于零迫，并能以8倍低的复杂度接近加权最小均方误差的性能。此外，论文还引入了一种数据增强方法来应对数据稀缺场景下的模型适应性问题。这项工作为深度学习在实际通信系统中的应用提供了可行性，并为高级资源分配算法提供了更多控制能力。

> **摘要翻译:** 深度学习（DL）由于其学习传播环境特征的能力，已成为大规模多输入多输出（mMIMO）系统预编码的一种解决方案。然而，训练这种模型需要部署现场高质量的本地数据集，这通常难以收集。我们提出了一种基于Transformer的mMIMO预编码基础模型，旨在最小化发射机的能耗，同时动态适应每个用户的速率需求。在相同能耗下，所提出的基础模型在零样本部署时显著优于零迫（Zero Forcing），并且在复杂度降低8倍的情况下，性能接近加权最小均方误差（Weighted Minimum Mean Squared Error）。为了解决数据稀缺环境下的模型适应性问题，我们引入了一种数据增强方法，通过计算预训练特征提取器输出之间的余弦相似度来寻找与目标分布相似的训练样本。我们的工作通过解决数据可用性和训练复杂性方面的挑战，使得基于深度学习的解决方案得以在实践中实施。此外，动态配置每个用户速率需求的能力可被更高层的资源分配和调度算法利用，以更好地控制能源效率、频谱效率和公平性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [275] [Multi-frame Detection via Graph Neural Networks: A Link Prediction Approach](https://arxiv.org/abs/2410.13436)
> *基于图神经网络的多帧检测：一种链接预测方法*

*Zhihao Lin, Chang Gao, Junkun Yan, Qingfu Zhang, Bo Chen, Hongwei Liu* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 多帧检测, 图神经网络, 链接预测, 弱目标检测, 虚警抑制

**Comment:** 

> **TL;DR:** 本文将多帧检测问题重构为图中的链接预测任务，利用图神经网络提升弱目标检测性能并抑制虚警。

**AI_Comments:** 本文的创新点在于将多帧检测问题巧妙地重构为图神经网络中的链接预测任务，而非传统的节点分类或三阶段处理，这统一了航迹搜索和检测过程，有效减少了性能损失。其重要性体现在能够更充分地利用多帧回波信息，显著提升了弱目标检测能力并降低了虚警率，为雷达信号处理领域提供了新的视角和高效解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有高效多帧检测算法（基于三个顺序步骤）存在检测性能损失且未能充分利用回波信息；现有应用于多帧检测的图神经网络算法主要基于节点分类任务，无法直接输出目标航迹。

**Method:** 本文将多帧检测问题重构为图中的链接预测任务。首先，对超过低阈值的多帧观测进行粗略关联，构建观测关联图。随后，设计了一个基于图神经网络的多特征链接预测网络，该网络集成了回波结构、多普勒信息和点迹时空耦合等多维信息。通过链接预测，将航迹搜索和航迹检测统一为一个步骤。

**Result:** 实验结果表明，与传统单帧和多帧检测算法相比，所提出的算法在抑制虚警的同时，提高了弱目标的检测性能。此外，可解释性分析表明，所设计的网络有效整合了利用的特征，实现了目标和虚警之间的准确关联。

**Conclusion:** 本文提出的基于图神经网络的链接预测方法，通过将多帧检测问题重构为链接预测任务，有效提升了弱目标检测性能，并统一了航迹搜索和航迹检测步骤，实现了对多维信息的有效整合。

> **ai_Abstract:** 本文针对现有多帧检测算法存在性能损失且未能充分利用多帧信息的问题，以及图神经网络应用于该领域主要基于节点分类且无法直接输出航迹的局限性，提出了一种基于图神经网络的链接预测方法。该方法将多帧检测重构为图中的链接预测任务，通过构建观测关联图并设计多特征链接预测网络，集成了多维信息，并统一了航迹搜索与检测步骤。实验证明，该算法有效提升了弱目标检测性能并抑制了虚警。

> **摘要翻译:** 多帧检测算法能有效利用连续回波之间的相关性，以提高弱目标的检测性能。现有高效的多帧检测算法通常基于三个顺序步骤：通过相对较低的主阈值进行点迹提取、航迹搜索和航迹检测。然而，这些三阶段处理算法可能会导致显著的检测性能损失，并且未能充分利用跨帧的可用回波信息。至于将图神经网络应用于多帧检测，现有算法主要基于节点分类任务，无法直接输出目标航迹。在本文中，我们将多帧检测问题重构为图中的链接预测任务。首先，我们对超过低阈值的多帧观测进行粗略关联，以构建观测关联图。随后，设计了一个基于图神经网络的多特征链接预测网络，该网络集成了回波结构、多普勒信息和点迹时空耦合等多维信息。通过利用链接预测的原理，我们将航迹搜索和航迹检测过程统一为一个步骤，以减少性能损失并直接输出目标航迹。实验结果表明，与传统单帧和多帧检测算法相比，所提出的算法在抑制虚警的同时，提高了弱目标的检测性能。此外，可解释性分析表明，所设计的网络有效整合了利用的特征，实现了目标和虚警之间的准确关联。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [310] [Learning Wideband User Scheduling and Hybrid Precoding with Graph Neural Networks](https://arxiv.org/abs/2503.04233)
> *基于图神经网络的宽带用户调度与混合预编码学习*

*Shengjie Liu, Chenyang Yang, Shengqian Han* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 图神经网络, 用户调度, 混合预编码, 宽带多天线系统, 资源分配

**Comment:** 

> **TL;DR:** 本文提出了一种基于图神经网络（GNN）的架构，用于联合学习宽带多天线系统中的用户调度和混合预编码策略，解决了传统方法面临的挑战，并展示了其在性能、效率和泛化性方面的优势。

**AI_Comments:** 该论文的创新点在于首次尝试使用图神经网络（GNN）联合学习宽带多天线系统中的用户调度和混合预编码，并提出了一个两阶段的GNN架构。特别值得关注的是，作者发现并分析了“同参数同决策（SPSD）”特性，揭示了GNN在处理相似信道用户时的局限性，并据此设计了改进的调度器和新的注意力机制，这体现了深入的理论分析与实际问题解决的结合。其重要性在于为未来无线通信系统中的复杂资源分配问题提供了一个可泛化、高效的机器学习解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 宽带多天线系统中的用户调度和混合预编码由于资源块上庞大的用户组合以及资源块间共享模拟预编码器等挑战，从未被联合学习。

**Method:** 本文将联合优化问题重新表述为调度和预编码策略的等效函数优化问题，并提出了一个由两个级联模块组成的基于GNN的架构来学习这两种策略。发现了集合上定义的无线策略的同参数同决策（SPSD）特性，并基于此开发了一系列GNN来增强调度器模块，并设计了一种新颖的注意力机制用于预编码器模块中的信息聚合。

**Result:** 仿真结果表明，所提出的架构在短推理时间和低训练复杂度下实现了令人满意的频谱效率，并且可以泛化到用户、资源块以及基站和用户天线数量的变化。

**Conclusion:** 本文提出的基于GNN的联合学习用户调度和混合预编码的架构，有效地解决了现有挑战，并在性能、效率和泛化性方面表现出色，为宽带多天线系统优化提供了有效方案。

> **ai_Abstract:** 本文提出了一种基于图神经网络（GNN）的新型架构，用于联合优化宽带多天线系统中的用户调度和混合预编码，解决了传统方法难以同时学习这两者的问题。通过将联合优化问题转化为函数优化问题，该架构利用两个级联的GNN模块学习调度和预编码策略。针对GNN在处理相似信道用户时的局限性（SPSD特性），文章引入了一系列GNN来增强调度器，并为预编码器模块设计了新的注意力机制。实验证明，该方法在频谱效率、推理速度和训练复杂度方面表现优异，并具有良好的泛化能力。

> **摘要翻译:** 宽带多天线系统中的用户调度和混合预编码从未被联合学习，原因在于资源块（RBs）上庞大的用户组合以及资源块之间共享模拟预编码器所带来的挑战。在本文中，我们致力于利用图神经网络（GNNs）联合学习调度和预编码策略，GNNs因其在问题规模上的泛化潜力而成为优化资源分配的强大工具。通过将联合优化问题重新表述为调度和预编码策略的等效函数优化问题，我们提出了一种基于GNN的架构，该架构由两个级联模块组成，用于学习这两种策略。我们发现了集合上定义的无线策略的同参数同决策（SPSD）特性，揭示了当用户具有相似信道时，GNN无法很好地学习最优调度策略。这促使我们开发一系列GNN来增强调度器模块。此外，通过分析SPSD特性，我们发现GNN中的线性聚合器何时会阻碍规模泛化。基于这一观察，我们为预编码器模块中的信息聚合设计了一种新颖的注意力机制。仿真结果表明，所提出的架构在短推理时间和低训练复杂度下实现了令人满意的频谱效率，并且可以泛化到用户、资源块以及基站和用户天线数量的变化。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [345] [Evaluating the Scalability of Binary and Ternary CNN Workloads on RRAM-based Compute-in-Memory Accelerators](https://arxiv.org/abs/2505.07490)
> *评估基于RRAM的存内计算加速器上二值和三值CNN工作负载的可扩展性*

*José Cubero-Cascante, Rebecca Pelke, Noah Flohr, Arunkumar Vaidyanathan, Rainer Leupers, Jan Moritz Joseph* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** RRAM, 存内计算, CNN, ADC, 寄生效应

**Comment:** PREPRINT - Presented at the 2025 IEEE Computer Society Annual
  Symposium on VLSI (ISVLSI 2025)

> **TL;DR:** 基于RRAM的存内计算（CIM）加速器在处理CNN时面临ADC限制。本研究引入了新的仿真方法来建模导线寄生和有限ADC分辨率的影响，并提出了一种变步长ADC。结果显示，三值CNN对寄生和低ADC分辨率更具鲁棒性，但能效降低40%。

**AI_Comments:** 这篇论文通过建立精确的仿真模型，深入分析了RRAM-CIM加速器在处理CNN工作负载时面临的关键挑战，特别是导线寄生效应和ADC分辨率的限制。其创新点在于提出了矢量化寄生模型和变步长ADC及校准方法。通过对二值和三值CNN的比较分析，揭示了三值CNN在鲁棒性方面的优势以及其能效劣势，为未来RRAM-CIM设计提供了权衡依据，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 卷积神经网络（CNN）日益增长的计算需求需要节能的加速策略。基于电阻式随机存取存储器（RRAM）的存内计算（CIM）架构通过减少数据移动和实现低功耗原位计算提供了一个有前景的解决方案。然而，其效率受到外围电路（特别是模数转换器（ADC））高成本的限制。通常采用大型交叉阵列和低ADC分辨率来缓解这一问题，但这可能会损害精度。

**Method:** 本研究引入了新颖的仿真方法，以建模电阻线寄生效应和有限ADC分辨率对RRAM交叉阵列的影响。我们的寄生模型采用矢量化算法计算交叉阵列输出电流，与SPICE相比误差低于0.15%。此外，我们提出了一种变步长ADC和一种校准方法，显著降低了ADC分辨率要求。这些精度模型与基于统计的能耗模型集成。利用我们的框架，我们对二值和三值CNN进行了比较分析。

**Result:** 实验结果表明，三值CNN对导线寄生和较低的ADC分辨率表现出更强的鲁棒性，但能效降低了40%。

**Conclusion:** 这些发现为优化基于RRAM的CIM加速器以实现节能深度学习提供了有价值的见解。

> **ai_Abstract:** 本文针对RRAM存内计算（CIM）加速器在处理CNN工作负载时面临的ADC成本和精度限制，提出了一套新颖的仿真框架。该框架包含精确的电阻线寄生模型、一种变步长ADC设计及其校准方法，并与能耗模型集成。通过该框架，研究人员比较了二值和三值CNN在RRAM-CIM上的表现。结果显示，三值CNN对寄生效应和低ADC分辨率更具鲁棒性，但能效降低40%。这些发现为优化RRAM-CIM加速器提供了重要指导。

> **摘要翻译:** 卷积神经网络（CNN）日益增长的计算需求需要节能的加速策略。基于电阻式随机存取存储器（RRAM）的存内计算（CIM）架构通过减少数据移动和实现低功耗原位计算提供了一个有前景的解决方案。然而，其效率受到外围电路（特别是模数转换器（ADC））高成本的限制。通常采用大型交叉阵列和低ADC分辨率来缓解这一问题，但这可能会损害精度。本工作引入了新颖的仿真方法，以建模电阻线寄生效应和有限ADC分辨率对RRAM交叉阵列的影响。我们的寄生模型采用矢量化算法计算交叉阵列输出电流，与SPICE相比误差低于0.15%。此外，我们提出了一种变步长ADC和一种校准方法，显著降低了ADC分辨率要求。这些精度模型与基于统计的能耗模型集成。利用我们的框架，我们对二值和三值CNN进行了比较分析。实验结果表明，三值CNN对导线寄生和较低的ADC分辨率表现出更强的鲁棒性，但能效降低了40%。这些发现为优化基于RRAM的CIM加速器以实现节能深度学习提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [387] [Theoretical Analysis for the CommSense Measurement System](https://arxiv.org/abs/2506.07685)
> *CommSense测量系统的理论分析*

*Sandip Jana, Amit Kumar Mishra, Mohammed Zafar Ali Khan* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** CommSense, 6G, ISAC, PCA, SVM

**Comment:** 

> **TL;DR:** 本研究对CommSense框架进行了深入分析，该框架将基于PCA的轻量级检测器嵌入标准OFDM接收器，实现了实时、无设备的无源散射体检测。结果表明，结合PCA和SVM的检测方法能提供快速、准确和鲁棒的感知能力，为6G及未来集成感知与通信（ISAC）铺平道路。

**AI_Comments:** 该论文的创新之处在于将PCA技术与标准OFDM接收器相结合，实现了高效的无设备感知，并证明了PCA结合SVM在处理参数估计误差方面的优越鲁棒性。这对于未来6G网络中集成感知与通信（ISAC）的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 未来的6G网络旨在融合通信与感知，利用OFDM波形实现高吞吐量数据传输和环境感知。本研究的动机是彻底分析基于通信的感知（CommSense）框架，以实现实时、无设备的无源散射体检测。

**Method:** 本研究对CommSense框架进行了深入分析，该框架将轻量级、基于PCA的检测器嵌入到标准OFDM接收器中，以实现无额外发射器的实时、无设备无源散射体检测。研究从一个现实的三链路Rician信道模型（直接Tx到Rx，级联Tx到散射体，散射体到Rx）出发，比较了四种检测器：全维度似然比检验（Full LRT）、基于PCA的LRT、以及带有线性和RBF核的PCA-SVM。通过将N维CSI投影到P（远小于N）个主成分子空间上进行分析。

**Result:** 通过将N维CSI投影到P个主成分子空间上，推理时间比全LRT减少了一个数量级，同时实现了最佳错误率，即经验误差与Bhattacharyya误差界限紧密对齐，并且当P约等于10时，ROC曲线下面积（AUC）约等于1。模拟结果表明，基于LRT的技术容易受到参数估计误差的影响，而SVM则对此具有弹性。

**Conclusion:** 本研究的结果表明，当PCA驱动的检测与轻量级SVM结合时，可以提供快速、准确和鲁棒的散射体感知，为6G及未来集成感知与通信（ISAC）铺平了道路。

> **ai_Abstract:** 本论文对CommSense框架进行了全面的理论分析，该框架通过在标准OFDM接收器中嵌入基于PCA的轻量级检测器，实现对无源散射体的实时、无设备感知。研究比较了多种检测器，并发现将N维CSI投影到主成分子空间可显著减少推理时间，同时保持优异的错误率。特别是，结合PCA的SVM检测器展现出对参数估计误差的鲁棒性。该研究为6G及未来集成感知与通信（ISAC）提供了快速、准确且鲁棒的解决方案。

> **摘要翻译:** 未来的6G网络设想模糊通信和感知之间的界限，利用无处不在的OFDM波形实现高吞吐量数据和环境感知。在这项工作中，我们对基于通信的感知（CommSense）框架进行了彻底分析，该框架将轻量级、基于PCA的检测器嵌入到标准OFDM接收器中；从而无需任何额外的发射器即可实现实时、无设备的无源散射体（例如无人机、车辆等）检测。从一个现实的三链路Rician信道模型（直接Tx到Rx，级联Tx到散射体，散射体到Rx）开始，我们比较了四种检测器：全维度似然比检验（Full LRT）、基于PCA的LRT、以及带有线性和RBF核的PCA-SVM。通过将N维CSI投影到P（远小于N）个主成分子空间上，与全LRT相比，推理时间减少了一个数量级，同时实现了最佳错误率，即经验误差与Bhattacharyya误差界限紧密对齐，并且当P约等于10时，ROC曲线下面积（AUC）约等于1。从模拟结果中我们发现，基于LRT的技术容易受到参数估计误差的影响，而SVM则对此具有弹性。我们的结果表明，当PCA驱动的检测与轻量级SVM结合时，可以提供快速、准确和鲁棒的散射体感知，为6G及未来集成感知与通信（ISAC）铺平了道路。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [429] [Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses](https://arxiv.org/abs/2506.22495)
> *感觉心脏的掩码自编码器：揭示心电图分析中的简单性偏差*

*He-Yang Xu, Hongxiang Gao, Yuwen Li, Xiu-Shen Wei, Chengyu Liu* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 简单性偏差, 心电图分析, 自监督学习, 时间-频率特征, 多粒度原型重建

**Comment:** there are factual errors

> **TL;DR:** 本文提出了一种基于自监督学习的新方法，通过时间-频率感知滤波器和多粒度原型重建来缓解心电图分析中的简单性偏差（Simplicity Bias），并在大规模数据集上实现了最先进的性能。

**AI_Comments:** 该论文创新性地关注了心电图分析中的“简单性偏差”问题，并首次实证证明了其存在。通过引入自监督学习范式，并结合时间-频率感知滤波器和多粒度原型重建，为解决这一关键问题提供了有效方案。此外，构建大规模多站点心电图数据集也为该领域的未来研究奠定了重要基础，具有显著的实践价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 监督式心电图模型倾向于过拟合主导和重复模式，从而忽略了细微但临床关键的线索，这种现象被称为简单性偏差（Simplicity Bias, SB），即模型偏爱易于学习的信号而非细微但信息丰富的信号。这种偏差对诊断性能产生负面影响，而自监督学习（SSL）有望缓解它。

**Method:** 本文提出了一种遵循自监督学习范式的新方法，包含两个关键组件：1）时间-频率感知滤波器，用于捕获反映心电图信号动态特性的时间-频率特征；2）在此基础上构建的多粒度原型重建，用于跨双域的粗粒度和细粒度表示学习，进一步缓解简单性偏差。此外，还整理了一个包含来自300多个临床中心的153万条记录的大规模多站点心电图数据集。

**Result:** 在六个心电图数据集上的三个下游任务的实验表明，本文提出的方法有效地减少了简单性偏差，并取得了最先进的性能。

**Conclusion:** 本文提出的方法有效地减少了心电图分析中的简单性偏差，并通过自监督学习实现了最先进的性能，为解决这一偏差提供了一个有前景的方向。

> **ai_Abstract:** 本研究首先实证揭示了心电图（ECG）分析中存在的简单性偏差（Simplicity Bias, SB）及其对诊断性能的负面影响，并发现自监督学习（SSL）能有效缓解此偏差。在此基础上，提出了一种新颖的自监督学习方法，包含时间-频率感知滤波器以捕获动态特征，以及多粒度原型重建以进行粗细粒度表示学习，从而进一步减轻SB。为支持ECG分析中的SSL发展，研究团队构建了一个包含153万条记录的大规模多站点ECG数据集。实验证明，该方法能有效降低SB并达到最先进的性能。

> **摘要翻译:** 心电图（ECG）的诊断价值在于其动态特性，从心律波动到随时间和频率域演变的细微波形变形。然而，监督式心电图模型倾向于过拟合主导和重复模式，从而忽略了细微但临床关键的线索，这种现象被称为简单性偏差（Simplicity Bias, SB），即模型偏爱易于学习的信号而非细微但信息丰富的信号。在这项工作中，我们首先通过实证证明了心电图分析中简单性偏差的存在及其对诊断性能的负面影响，同时发现自监督学习（SSL）可以缓解它，为解决这一偏差提供了一个有前景的方向。遵循自监督学习范式，我们提出了一种新方法，包含两个关键组件：1）时间-频率感知滤波器，用于捕获反映心电图信号动态特性的时间-频率特征；2）在此基础上构建的多粒度原型重建，用于跨双域的粗粒度和细粒度表示学习，进一步缓解简单性偏差。为了推进心电图分析中的自监督学习，我们整理了一个包含来自300多个临床中心的153万条记录的大规模多站点心电图数据集。在六个心电图数据集上的三个下游任务的实验表明，我们的方法有效地减少了简单性偏差并取得了最先进的性能。代码和数据集将公开发布。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [471] [EEG Foundation Models: A Critical Review of Current Progress and Future Directions](https://arxiv.org/abs/2507.11783)
> *EEG基础模型：当前进展和未来方向的批判性综述*

*Gayal Kuruppu, Neeraj Wagh, Yogatheesan Varatharajah* | **Category: eess.SP, cs.AI, cs.LG, q-bio.NC** | **Updated: 2025-07-23**

**Keywords:** EEG基础模型, 自监督学习, 脑电图, 批判性综述, 表征学习

**Comment:** 20 pages, 5 figures, 3 tables (main + supplement)

> **TL;DR:** 本文对早期EEG基础模型（EEG-FMs）进行了批判性综述，发现它们普遍采用基于Transformer的序列建模，但评估方法不一致且有限，阻碍了其实用性评估。文章呼吁标准化评估并与领域专家合作，以推动EEG-FMs的实际应用。

**AI_Comments:** 这篇综述文章非常及时且重要，因为它揭示了EEG基础模型领域当前面临的核心挑战，特别是在标准化评估和实际应用方面。作者不仅指出了现有方法的局限性，还为未来的研究提供了明确且可操作的建议，强调了跨学科合作的重要性。其创新之处在于对早期模型的系统性梳理，并为该新兴领域设定了研究议程。

<details>
  <summary>Details</summary>

**Motivation:** 由于监督式EEG编码器无法学习鲁棒的EEG模式且过度依赖昂贵的信号标注，研究转向了通用自监督EEG编码器（即EEG基础模型，EEG-FMs）。然而，早期EEG-FMs的实际应用准备程度以及长期研究进展的衡量标准尚不明确。因此，有必要对第一代EEG-FMs进行系统而全面的回顾，以了解当前的技术水平并确定未来EEG-FMs的关键发展方向。

**Method:** 本研究回顾了10个早期EEG基础模型（EEG-FMs），并对其方法论、实证发现和突出的研究空白进行了批判性综合分析。

**Result:** 研究发现，大多数EEG基础模型（EEG-FMs）采用基于序列的建模方案，依赖于基于Transformer的骨干网络和掩码序列的重构进行自监督。然而，模型评估仍然异构且大多有限，这使得评估其现成的实际效用变得具有挑战性。

**Conclusion:** 未来的工作除了采用标准化和现实的评估外，还应展示更显著的规模效应，并在EEG表征学习流程中做出有原则和值得信赖的选择。通过与领域专家合作开发基准、软件工具、技术方法和应用，可以进一步提升EEG基础模型的转化效用和实际应用。

> **ai_Abstract:** 本文对早期EEG基础模型（EEG-FMs）的当前进展进行了批判性回顾，旨在评估其在实际应用中的准备程度并指导未来的研究方向。研究分析了10个早期EEG-FMs，发现它们普遍采用基于Transformer的序列建模和掩码序列重构进行自监督学习。然而，现有的模型评估方法缺乏标准化且存在局限性，使得难以准确评估其离线实用性。因此，未来的研究应侧重于实施标准化、真实的评估，展示更强的扩展效应，并在整个EEG表征学习过程中做出可靠的选择。与领域专家合作开发基准、工具和应用被认为是推动EEG-FMs转化和实际应用的关键。

> **摘要翻译:** 通过脑电图（EEG）记录的脑电活动模式对科学和临床研究具有巨大的价值。监督式EEG编码器无法学习鲁棒的EEG模式，并且过度依赖昂贵的信号标注，这促使研究转向了通用自监督EEG编码器，即EEG基础模型（EEG-FMs），以实现鲁棒和可扩展的EEG特征提取。然而，早期EEG-FMs的实际应用准备程度以及长期研究进展的衡量标准仍不明确。因此，有必要对第一代EEG-FMs进行系统而全面的回顾，以了解当前的技术水平并确定未来EEG-FMs的关键发展方向。为此，本研究回顾了10个早期EEG基础模型，并对其方法论、实证发现和突出的研究空白进行了批判性综合分析。我们发现，大多数EEG-FMs采用基于序列的建模方案，依赖于基于Transformer的骨干网络和掩码序列的重构进行自监督。然而，模型评估仍然异构且大多有限，这使得评估其现成的实际效用变得具有挑战性。除了采用标准化和现实的评估外，未来的工作还应展示更显著的规模效应，并在EEG表征学习流程中做出有原则和值得信赖的选择。我们相信，与领域专家合作开发基准、软件工具、技术方法和应用，可能会进一步提升EEG-FMs的转化效用和实际应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [513] [Phase-optimised linearly-constrained minimum-variance beamformers](https://arxiv.org/abs/2507.14937)
> *相位优化的线性约束最小方差波束形成器*

*Hugh L Kennedy* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 波束形成器, 线性约束最小方差, 群延迟, 噪声功率, 处理延迟

**Comment:** Fixed a few minor things spotted since the initial upload

> **TL;DR:** 本文提出了一种确定线性约束最小方差（LCMV）波束形成器最佳群延迟的新方法，并推荐了两种优化策略（最小化噪声功率或处理延迟），通过模拟VHF通信和UHF雷达应用验证了其潜力。

**AI_Comments:** 这篇论文的创新点在于提出了LCMV波束形成器中群延迟这一新的设计自由度，并提供了两种具体的优化策略。其重要性在于可能为波束形成器性能优化提供新的途径，特别是在噪声抑制和延迟优化方面。通过在VHF通信和UHF雷达中的应用探索，也展现了其潜在的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 探索线性约束最小方差（LCMV）波束形成器中迄今未被探索的设计自由度——最优群延迟的潜力。

**Method:** 提出了一种确定LCMV波束形成器最佳群延迟的新程序。推荐了两种选择最佳延迟的方法：一是最小化噪声功率的解决方案；二是最小化处理延迟的解决方案。

**Result:** 通过模拟甚高频（VHF）通信和超高频（UHF）双基地雷达应用，探索了这种未被探索的设计自由度的潜力。

**Conclusion:** 该研究成功探索了线性约束最小方差（LCMV）波束形成器中群延迟这一未被探索的设计自由度，并提出了两种优化方案（最小化噪声功率和最小化处理延迟），证明了其在VHF通信和UHF双基地雷达应用中的潜在价值。

> **ai_Abstract:** 本文提出了一种新颖的方法来确定线性约束最小方差（LCMV）波束形成器的最佳群延迟。该方法提供了两种优化策略：一是最小化噪声功率，二是最小化处理延迟。通过模拟VHF通信和UHF双基地雷达应用，研究探索了这一未被充分利用的设计自由度的潜力。

> **摘要翻译:** 提出了一种确定线性约束最小方差（LCMV）波束形成器最佳群延迟的新程序。推荐了两种选择最佳延迟的方法：第一种是最小化噪声功率的解决方案；第二种是最小化处理延迟的解决方案。利用模拟的甚高频（VHF）通信和超高频（UHF）双基地雷达应用，探索了这种迄今未被探索的设计自由度的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [556] [SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices](https://arxiv.org/abs/2507.17623)
> *SA-WiSense：一种适用于单天线Wi-Fi设备的无盲点呼吸感知框架*

*Guangteng Liu, Xiayue Liu, Zhixiang Xu, Yufeng Yuan, Hui Zhao, Yuxuan Liu, Yufei Jiang* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** Wi-Fi感知, 呼吸监测, 盲点, 单天线, 物联网

**Comment:** 12pages, 10figures

> **TL;DR:** SA-WiSense提出了一种用于单天线Wi-Fi设备的无盲点呼吸感知框架，通过跨子载波CSI比率（CSCR）消除随机相位偏移，并利用遗传算法进行子载波选择，在8米范围内实现了91.2%的呼吸监测检测率。

**AI_Comments:** SA-WiSense的创新之处在于其针对单天线Wi-Fi设备解决了呼吸监测中的盲点问题，这使其具有显著的成本效益和广泛的物联网应用潜力。通过引入跨子载波CSI比率（CSCR）来抵消随机相位偏移，以及利用遗传算法优化子载波选择（GASS），该研究在技术上取得了突破。91.2%的检测率在8米距离上对于单天线系统而言是一个令人印象深刻的成果，表明了其在实际应用中的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 当前Wi-Fi呼吸监测技术存在由随机相位偏移引起的盲点问题，这会破坏呼吸信号的互补性，降低监测准确性。此外，现有方案多依赖多天线系统，不适用于成本敏感且多为单天线的物联网（IoT）设备。

**Method:** SA-WiSense框架通过两个核心方法解决问题：1) 跨子载波CSI比率（CSCR）方法：利用子载波间CSI值的比率来消除随机相位偏移，从而恢复信号的互补性，实现无盲点感知。2) 基于遗传算法的子载波选择（GASS）方法：将子载波间CSCR的感知信噪比（SSNR）作为优化目标，利用遗传算法选择最佳子载波。该框架在商用ESP32微控制器上进行了实验构建和验证。

**Result:** 所提出的SA-WiSense框架在最远8.0米的距离上，呼吸监测的检测率达到91.2%，并且比现有的单天线方法准确得多。

**Conclusion:** SA-WiSense框架通过创新的CSCR和GASS方法，成功解决了单天线Wi-Fi设备在呼吸监测中的盲点问题，提供了一种成本效益高且适用于物联网场景的鲁棒、高精度解决方案。

> **ai_Abstract:** SA-WiSense是一种针对单天线Wi-Fi设备的呼吸感知框架，旨在解决由随机相位偏移引起的盲点问题。该框架通过跨子载波CSI比率（CSCR）方法消除相位偏移，并利用遗传算法（GA）进行子载波选择（GASS）以优化感知信噪比。SA-WiSense具有成本效益，适用于物联网设备。实验验证表明，该系统在8米距离内呼吸监测的检测率达到91.2%，优于现有单天线方法。

> **摘要翻译:** Wi-Fi感知为非接触式人体呼吸监测提供了一种有前景的技术。然而，一个关键挑战是随机相位偏移引起的盲点问题，它破坏了呼吸信号的互补性。为了解决这一挑战，我们提出了一种单天线Wi-Fi感知（SA-WiSense）框架，以提高人体呼吸监测的准确性，并对抗随机相位偏移。所提出的SA-WiSense框架具有成本效益，因为它只使用单个天线，而不是像以前的工作那样使用多个天线。因此，所提出的框架适用于物联网（IoT），因为大多数传感器都配备了单个天线。一方面，我们提出了一种基于跨子载波信道状态信息（CSI）比率（CSCR）的盲点缓解方法，适用于物联网，该方法利用子载波之间两个CSI值的比率来缓解随机相位偏移。我们证明了所提出的CSCR方法可以消除随机相位偏移，从而恢复信号固有的互补性，实现无盲点感知。另一方面，我们通过根据子载波之间CSCR的感知信噪比（SSNR）建立优化问题，提出了一种基于遗传算法（GA）的子载波选择（GASS）方法。GA被用于解决所建立的优化问题。我们使用商用ESP32微控制器构建了一个实验测试。所提出的工作经验证，在最远8.0米的距离上，呼吸监测的检测率达到91.2%，比现有的单天线方法准确得多。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [584] [Prime and Co-prime Integer Matrices](https://arxiv.org/abs/2505.00862)
> *素数和互质整数矩阵*

*Xiang-Gen Xia, Guangpu Guo* | **Category: eess.SP, cs.DM, cs.IT, math.IT** | **Updated: 2025-07-23**

**Keywords:** 素数矩阵, 互质矩阵, 整数矩阵, 多维互质传感, 中国剩余定理

**Comment:** 

> **TL;DR:** 本文研究素数和互质整数矩阵的性质，并刻画了既是素数又是成对互质的整数矩阵，提供了一种构造此类矩阵族的方法，可能应用于多维互质传感和多维中国剩余定理。

**AI_Comments:** 这篇论文通过深入研究素数和互质整数矩阵的特性，提出了一种新颖且实用的构造方法。其创新之处在于将数论概念应用于矩阵理论，并揭示了其在多维信号处理和数论应用中的潜在重要性。该研究为相关领域提供了一个新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究素数和互质整数矩阵的性质，并提供一种简单的构造方法，以期应用于多维互质传感和多维中国剩余定理。

**Method:** 论文通过刻画所有既是素数整数矩阵又是成对互质整数矩阵的特性。

**Result:** 提供了构造成对互质整数矩阵族的简单方法。

**Conclusion:** 这种构造方法可能在多维互质传感和多维中国剩余定理中具有应用潜力。

> **ai_Abstract:** 本文探讨素数和互质整数矩阵的性质，并重点刻画了同时满足素数和成对互质条件的整数矩阵。研究成果提供了一种简便的构造方法，用于生成成对互质整数矩阵族，这对于多维互质传感和多维中国剩余定理等领域具有潜在应用价值。

> **摘要翻译:** 本文研究素数和互质整数矩阵及其性质。它刻画了所有既是素数整数矩阵又是成对互质整数矩阵的特性。这提供了一种构造成对互质整数矩阵族的简单方法，可能在多维互质传感和多维中国剩余定理中具有应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [4] [Modality-Agnostic Brain Lesion Segmentation with Privacy-aware Continual Learning](https://arxiv.org/abs/2503.20326)
> *模态无关的脑损伤分割与隐私保护持续学习*

*Yousef Sadegheih, Pratibha Kumari, Dorit Merhof* | **Category: eess.IV** | **Updated: 2025-07-24**

**Keywords:** 脑损伤分割, 持续学习, 模态无关, 隐私保护, 知识蒸馏

**Comment:** Accepted in MICCAI 2025 PRIME Workshop!

> **TL;DR:** 提出一种隐私保护的持续学习框架，用于模态无关的脑损伤分割，通过混合专家和双重知识蒸馏，在一个模型中处理多种MRI数据和病理，并显著优于现有方法。

**AI_Comments:** 这项工作通过引入隐私保护的持续学习框架，有效地解决了脑损伤分割领域中多模态数据适应性差和灾难性遗忘的关键挑战。其创新性在于结合了混合专家和双重知识蒸馏，实现了单一模型处理多样化数据，显著提高了模型的实用性和通用性，并且在性能上取得了显著提升，对临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统脑损伤分割模型为特定病理和预定义模态定制，适应新模态或病理需训练新模型，与人类渐进式学习方式不同，效率低下。

**Method:** 提出一个统一的分割模型，能够从不同模态和病理的多个数据集顺序学习。该方法利用隐私保护的持续学习框架，整合了混合专家机制和双重知识蒸馏，以缓解灾难性遗忘，同时不影响在新数据集上的性能。

**Result:** 在五个不同的脑部MRI数据集和四种数据集序列上进行了广泛实验，证明了该框架在保持单一适应性模型方面的有效性。与LwF、SI、EWC、MiB和TED等广泛使用的隐私保护持续学习方法相比，本方法平均Dice分数提高了约14%。

**Conclusion:** 该框架代表了向更通用、更实用的脑损伤分割模型迈出的重要一步。

> **ai_Abstract:** 本文提出一个名为“模态无关的脑损伤分割与隐私保护持续学习”的框架，旨在解决传统模型无法有效适应新MRI模态和病理的问题。受人类学习过程启发，该模型通过整合混合专家机制和双重知识蒸馏，在一个隐私保护的持续学习框架下，实现从多样化数据集的顺序学习，有效缓解灾难性遗忘。实验证明，该方法在处理多变数据方面表现出色，并显著优于现有持续学习方法，平均Dice分数提升14%，为开发更通用、实用的脑损伤分割模型奠定基础。

> **摘要翻译:** 传统的多模态MRI脑损伤分割模型通常针对特定病理定制，依赖于预定义模态的数据集。适应新的MRI模态或病理通常需要训练单独的模型，这与医学专业人员通过随着时间从多样化数据集中学习来逐步扩展其专业知识的方式形成对比。受这种人类学习过程的启发，我们提出了一种统一的分割模型，能够顺序地从具有不同模态和病理的多个数据集中学习。我们的方法利用一个隐私保护的持续学习框架，该框架集成了专家混合机制和双重知识蒸馏，以减轻灾难性遗忘，同时不损害在新遇到数据集上的性能。在五个不同的脑部MRI数据集和四种数据集序列上进行的广泛实验证明了我们框架在维护一个单一适应性模型方面的有效性，该模型能够处理不同的医院协议、成像模态和疾病类型。与LwF、SI、EWC、MiB和TED等广泛使用的隐私保护持续学习方法相比，我们的方法平均Dice分数提高了约14%。我们的框架代表了向更通用和实用的脑损伤分割模型迈出的重要一步，其实现代码可在GitHub上获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [56] [SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution](https://arxiv.org/abs/2505.00046)
> *SR-NeRV：通过超分辨率提高神经视频表示的嵌入效率*

*Taiga Hayami, Kakeru Koizumi, Hiroshi Watanabe* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 隐式神经表示, 神经视频压缩, 超分辨率, 高频细节, 视频表示

**Comment:** 

> **TL;DR:** 提出SR-NeRV，将超分辨率网络集成到隐式神经视频表示中，以在紧凑模型下提高高频细节的重建质量。

**AI_Comments:** SR-NeRV的创新之处在于将超分辨率网络集成到隐式神经视频表示中，巧妙地利用了高频细节时间冗余低的特点，将这部分重建任务卸载给专用的SR网络，从而在保持模型紧凑性的前提下显著提升了视频重建质量，特别是在高频细节方面。这对于实际的神经视频压缩场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于隐式神经表示（INR）的神经视频压缩方法在模型尺寸严格受限时，难以重建高频细节，这在实际压缩场景中是一个关键限制。

**Method:** 提出一种基于INR的视频表示框架，该框架集成了通用超分辨率（SR）网络。通过将精细细节的重建卸载到预训练的自然图像SR网络，利用高频分量在帧间时间冗余低的特点。

**Result:** 实验结果表明，所提出的方法在重建质量方面优于传统的基于INR的基线方法，同时保持了可比的模型尺寸。

**Conclusion:** 通过集成超分辨率网络，SR-NeRV有效解决了神经视频表示在模型尺寸受限下高频细节重建困难的问题，显著提高了视觉保真度。

> **ai_Abstract:** 本文提出SR-NeRV，一个基于隐式神经表示（INR）的视频表示框架，旨在解决现有神经视频压缩方法在模型尺寸受限下难以重建高频细节的问题。SR-NeRV通过集成一个预训练的通用超分辨率网络来处理视频中的高频分量，从而提高视觉保真度。实验证明，SR-NeRV在保持相似模型尺寸的同时，显著优于传统INR基线方法。

> **摘要翻译:** 隐式神经表示（INRs）因其在各个领域建模复杂信号的能力而受到广泛关注。最近，基于INR的框架在通过将视频内容嵌入到紧凑神经网络中进行神经视频压缩方面展现出潜力。然而，这些方法在模型尺寸受到严格限制时，往往难以重建高频细节，而这在实际压缩场景中至关重要。为了解决这一限制，我们提出了一种基于INR的视频表示框架，该框架集成了通用超分辨率（SR）网络。这种设计的动机是观察到高频分量在帧间往往表现出较低的时间冗余。通过将精细细节的重建卸载到预训练的自然图像SR网络，所提出的方法提高了视觉保真度。实验结果表明，所提出的方法在重建质量方面优于传统的基于INR的基线方法，同时保持了可比的模型尺寸。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [96] [BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression](https://arxiv.org/abs/2505.09193)
> *BiECVC：用于学习视频压缩的双向上下文门控多样化*

*Wei Jiang, Junru Li, Kai Zhang, Li Zhang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视频压缩, 双向上下文, 深度学习, 上下文门控, 非局部相关性

**Comment:** Accepted to ACMMM 2025

> **TL;DR:** BiECVC是一个新的学习型双向视频压缩框架，通过多样化的局部和非局部上下文建模以及自适应上下文门控，首次在所有标准测试数据集上超越了VTM 13.2 RA。

**AI_Comments:** BiECVC的创新之处在于其对双向上下文建模的全面优化，特别是非局部相关性建模和自适应上下文门控机制。它通过集成多种策略有效地解决了现有BVC的局限性，并且首次在所有标准测试数据集上超越了VTM 13.2 RA，这对于学习型视频压缩领域是一个重要的里程碑。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型双向视频压缩（BVC）方法在性能上落后于前向预测方法，主要原因是难以提取多样化和准确的上下文，且缺乏动态抑制有害上下文的能力。

**Method:** BiECVC通过以下方式解决挑战：1) 局部上下文增强：重用下层高质量特征并使用解码运动向量对齐；2) 非局部依赖建模：采用线性注意力机制；3) 自适应上下文门控：引入双向上下文门控，根据条件编码结果动态过滤上下文信息。

**Result:** BiECVC实现了最先进的性能，与VTM 13.2在随机访问（RA）配置下相比，比特率分别降低了13.4%（帧内周期32）和15.7%（帧内周期64）。它是第一个在所有标准测试数据集上超越VTM 13.2 RA的学习型视频编解码器。

**Conclusion:** BiECVC通过其创新的上下文建模和门控机制，显著提升了学习型双向视频压缩的性能，并首次在所有标准测试数据集上超越了VTM 13.2 RA，证明了其优越性。

> **ai_Abstract:** 该论文提出了BiECVC，一个用于学习型双向视频压缩（BVC）的新框架。针对现有BVC在上下文提取和适应性方面的不足，BiECVC引入了多样化的局部和非局部上下文建模以及自适应上下文门控机制。通过重用高质量特征、采用线性注意力机制和基于条件编码结果的上下文门控，BiECVC显著提升了性能，并在随机访问配置下首次超越了VTM 13.2 RA，实现了比特率的显著降低。

> **摘要翻译:** 最近基于前向预测的学习型视频压缩（LVC）方法取得了令人印象深刻的成果，甚至在低延迟B（LDB）配置下超越了VVC参考软件VTM。相比之下，学习型双向视频压缩（BVC）仍然探索不足，并且仍然落后于其仅前向的对应方法。这种性能差距主要是由于提取多样化和准确上下文的能力有限：大多数现有BVC主要利用时间运动，而忽略了跨帧的非局部相关性。此外，它们缺乏动态抑制由快速运动或遮挡引起的有害上下文的适应性。为了应对这些挑战，我们提出了BiECVC，一个BVC框架，它结合了多样化的局部和非局部上下文建模以及自适应上下文门控。为了增强局部上下文，BiECVC重用来自较低层的高质量特征，并使用解码运动向量对齐它们，而不会引入额外的运动开销。为了有效地建模非局部依赖性，我们采用了一种平衡性能和复杂性的线性注意力机制。为了进一步减轻不准确上下文预测的影响，我们引入了双向上下文门控，其灵感来自于最近自回归语言模型中的数据依赖衰减，以根据条件编码结果动态过滤上下文信息。广泛的实验表明，BiECVC实现了最先进的性能，与VTM 13.2在随机访问（RA）配置下相比，帧内周期分别为32和64时，比特率分别降低了13.4%和15.7%。据我们所知，BiECVC是第一个在所有标准测试数据集上超越VTM 13.2 RA的学习型视频编解码器。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [135] [TCM-Tongue: A Standardized Tongue Image Dataset with Pathological Annotations for AI-Assisted TCM Diagnosis](https://arxiv.org/abs/2507.18288)
> *TCM-Tongue：一个用于AI辅助中医诊断的标准化舌象数据集，带有病理标注*

*Xuebo Jin, Longfei Gao, Anshuo Tong, Zhengyang Chen, Jianlei Kong, Ning Sun, Huijun Ma, Qiang Wang, Yuting Bai, Tingli Su* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 中医诊断, 舌象数据集, AI, 病理标注, 深度学习

**Comment:** 16 pages, 11 figures, 2 Tables

> **TL;DR:** 该研究提出了TCM-Tongue，一个包含6719张标准化舌象图片和病理标注的大规模数据集，旨在解决中医舌诊标准化和AI开发数据缺乏的问题，并通过深度学习模型验证了其效用。

**AI_Comments:** 该论文的创新点在于构建并发布了首个大规模、标准化且带有详细病理标注的舌象数据集TCM-Tongue，这对于推动AI在中医舌诊领域的应用具有里程碑意义。它直接解决了当前中医AI发展面临的数据标准化和数据量不足的关键瓶颈，为后续研究提供了坚实的基础。其重要性体现在能够促进中医诊断的客观化和智能化，加速AI在中医领域的研发与临床转化。

<details>
  <summary>Details</summary>

**Motivation:** 传统中医舌诊面临主观解读和成像协议不一致导致的标准化挑战，且缺乏大规模带标注数据集阻碍了AI在舌诊领域的发展。

**Method:** 研究构建了TCM-Tongue数据集，包含6719张在标准化条件下采集的高质量舌象图片，并用20种病理症状类别进行了标注（每张图片平均2.54个临床验证标签，均由执业中医师验证）。该数据集支持多种标注格式（COCO, TXT, XML），并使用九种深度学习模型（YOLOv5/v7/v8变体、SSD和MobileNetV2）进行了基准测试以验证其效用。

**Result:** TCM-Tongue数据集成功构建，包含6719张高质量、标准化采集的舌象图片，并进行了详细的病理标注。通过九种深度学习模型的基准测试，验证了该数据集对于AI辅助中医诊断开发的实用性。

**Conclusion:** TCM-Tongue数据集为推进中医领域可靠的计算工具提供了关键基础，弥补了阻碍该领域进展的数据短缺，并通过标准化、高质量的诊断数据促进了AI在研究和临床实践中的整合。

> **ai_Abstract:** 本研究提出了TCM-Tongue，一个针对AI辅助中医舌诊的标准化舌象数据集。该数据集包含6719张在标准化条件下采集并由中医师标注的图像，涵盖20种病理症状类别。为确保其广泛应用，数据集支持多种标注格式，并通过九种主流深度学习模型的基准测试验证了其在AI开发中的实用性。TCM-Tongue旨在解决中医舌诊标准化和AI数据短缺的问题，为中医AI研究与临床应用奠定基础。

> **摘要翻译:** 传统中医（TCM）舌诊虽然具有临床价值，但由于主观解释和不一致的成像协议而面临标准化挑战，同时缺乏大规模、带标注的数据集也阻碍了人工智能（AI）的发展。为了弥补这一空白，我们提出了首个专用于AI驱动中医舌诊的数据集，包含6719张在标准化条件下捕获的高质量图像，并标注了20种病理症状类别（每张图像平均有2.54个经过临床验证的标签，均由执业中医师验证）。该数据集支持多种标注格式（COCO、TXT、XML），以实现广泛可用性，并已使用九种深度学习模型（YOLOv5/v7/v8变体、SSD和MobileNetV2）进行了基准测试，以证明其在AI开发中的实用性。这一资源为推进中医领域可靠的计算工具提供了关键基础，弥补了阻碍该领域进展的数据短缺，并通过标准化、高质量的诊断数据促进了AI在研究和临床实践中的整合。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [136] [Rate-Accuracy Bounds in Visual Coding for Machines](https://arxiv.org/abs/2505.14980)
> *机器视觉编码中的速率-精度界限*

*Ivan V. Bajić* | **Category: eess.IV** | **Updated: 2025-07-23**

**Keywords:** 速率-精度界限, 机器视觉编码, 压缩, 计算机视觉, 理论界限

**Comment:** 8 pages, 8 figures, IEEE MIPR 2025

> **TL;DR:** 该研究推导了机器视觉编码的速率-精度界限，并发现现有方法在比特率方面与理论最优仍有1-3个数量级的差距，表明有巨大改进空间。

**AI_Comments:** 该论文通过建立理论速率-精度界限，为机器视觉编码领域提供了重要的基准。其创新之处在于将经典信息论中的有损编码理论应用于新兴的“编码为机器”范式。研究结果揭示了现有技术与理论最优之间的巨大性能差距，这不仅凸显了该领域巨大的研究潜力，也为未来算法优化指明了方向，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着图像、视频和点云等视觉信号越来越多地专用于计算机视觉模型的自动化分析（如交通监控、机器人、自动驾驶、智能家居），需要开发针对分析而非重建目的的压缩策略，即“机器视觉编码”。

**Method:** 通过与离散无记忆信源的有损编码进行类比，本文推导了机器视觉编码中几个常见问题的速率-精度界限，并将其与现有文献中的最新成果进行了比较。

**Result:** 比较结果表明，当前方法在达到特定精度水平所需的比特率方面，与理论界限之间至少存在一个数量级，在某些情况下甚至两到三个数量级的差距。

**Conclusion:** 现有机器视觉编码方法与理论最优之间存在巨大差距，表明当前方法有很大的改进空间。

> **ai_Abstract:** 本文研究了机器视觉编码中的速率-精度界限，这是为计算机视觉模型自动化分析而设计的视觉信号压缩策略。作者通过类比离散无记忆信源的有损编码，推导了相关理论界限，并与现有最先进方法进行对比。研究发现，当前方法的比特率效率远低于理论最优，存在1到3个数量级的差距，这预示着该领域有巨大的改进潜力。

> **摘要翻译:** 视觉信号，如图像、视频和点云，正越来越多地被捕获，目的仅仅是为了计算机视觉模型的自动化分析。应用包括交通监控、机器人、自动驾驶、智能家居等。这一趋势导致需要开发针对这些信号的压缩策略，以用于分析而非重建，这一领域通常被称为“机器视觉编码”。通过与离散无记忆信源的有损编码进行类比，本文推导了机器视觉编码中几个流行问题的速率-精度界限，并将其与文献中的最新成果进行了比较。比较结果表明，当前方法在达到特定精度水平所需的比特率方面，与理论界限之间至少存在一个数量级，在某些情况下甚至两到三个数量级的差距。这反过来意味着，当前机器视觉编码方法有很大的改进空间。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [160] [Improving Multislice Electron Ptychography with a Generative Prior](https://arxiv.org/abs/2507.17800)
> *使用生成先验改进多层电子叠层衍射成像*

*Christian K. Belardi, Chia-Hao Lee, Yingheng Wang, Justin Lovelace, Kilian Q. Weinberger, David A. Muller, Carla P. Gomes* | **Category: eess.IV, cond-mat.mtrl-sci, cs.CV, physics.optics** | **Updated: 2025-07-23**

**Keywords:** 多层电子叠层衍射成像, 扩散模型, 生成先验, 图像重建, SSIM

**Comment:** 16 pages, 10 figures, 5 tables

> **TL;DR:** 开发了一种名为MEP-Diffusion的扩散模型，作为生成先验，显著提高了多层电子叠层衍射成像的重建质量。

**AI_Comments:** 这项工作的创新之处在于利用扩散模型作为生成先验来解决多层电子叠层衍射成像中逆问题的不适定性，为原子晶体结构重建的质量带来了显著提升。这种混合方法有效地结合了深度学习与传统迭代求解器的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多层电子叠层衍射成像（MEP）算法在重建原子晶体结构图像时，由于问题的不适定性，通常耗时且产生次优解。

**Method:** 开发了MEP-Diffusion，这是一个在大型晶体结构数据库上训练的扩散模型。该模型通过扩散后验采样（DPS）作为生成先验集成到现有的迭代重建方法中，形成一种混合方法。

**Result:** 重建的三维图像质量显著提升，SSIM（结构相似性指数）比现有方法提高了90.50%。

**Conclusion:** 将MEP-Diffusion作为生成先验的混合方法极大地提高了多层电子叠层衍射成像中重建三维图像的质量。

> **ai_Abstract:** 本文介绍了一种名为MEP-Diffusion的新型扩散模型，旨在作为多层电子叠层衍射成像（MEP）的生成先验。通过将MEP-Diffusion通过扩散后验采样（DPS）集成到现有的迭代重建方法中，所提出的混合方法有效解决了当前算法耗时且结果次优的局限性。该方法显著提高了重建三维图像的质量，SSIM提升了90.50%。

> **摘要翻译:** 多层电子叠层衍射成像（MEP）是一种逆成像技术，通过计算从衍射图样中重建原子晶体结构的最高分辨率图像。现有的算法通常迭代地解决这个逆问题，但由于其不适定性，它们既耗时又产生次优解。我们开发了MEP-Diffusion，一个专门针对MEP在大型晶体结构数据库上训练的扩散模型，以增强现有的迭代求解器。MEP-Diffusion通过扩散后验采样（DPS）很容易地作为生成先验集成到现有的重建方法中。我们发现这种混合方法极大地提高了重建三维图像的质量，比现有方法在SSIM上实现了90.50%的改进。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [178] [Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding](https://arxiv.org/abs/2506.02574)
> *动态标签的动态映射：基于时空光谱嵌入的遥感动态样本生成*

*Shuai Yuan, Shuang Chen, Tianwu Lin, Jincheng Yuan, Geng Tian, Yang Xu, Jie Wang, Peng Gong* | **Category: eess.IV, cs.CV, cs.MM** | **Updated: 2025-07-24**

**Keywords:** 遥感, 动态样本生成, 时空光谱嵌入, 异常检测, HTS-VAE

**Comment:** 

> **TL;DR:** 本文提出TasGen，一种两阶段时空光谱感知自动样本生成方法，利用时空光谱嵌入从静态标签生成动态遥感样本，以应对地表快速变化导致的样本过时问题。

**AI_Comments:** 该论文创新性地提出了一种自动生成遥感动态样本的方法，解决了传统静态样本更新困难的问题。其核心在于利用时空光谱嵌入捕捉地表动态，并结合HTS-VAE进行异常检测和动态样本生成。特别地，解耦再耦合的方法以及异常解释机制提升了模型的鲁棒性和可解释性。这对于提高遥感制图的及时性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感地理制图需要及时且有代表性的样本，但地表快速变化导致静态样本迅速过时，手动更新费力且不可持续。

**Method:** 本文提出了TasGen，一种两阶段的时空光谱感知自动样本生成方法。第一阶段，引入分层时空光谱变分自编码器（HTS-VAE），通过解耦并联合嵌入时空光谱信息，学习正常样本的低维潜在模式，实现鲁棒的异常检测。第二阶段，在稳定样本上训练的分类器重新标记随时间变化的变点以生成动态样本。此外，还提出了一种基于吉布斯采样的异常解释方法，将变化归因于特定的光谱-时间维度。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出TasGen，一种两阶段的时空光谱感知自动样本生成方法，旨在解决遥感地理制图中华静态样本因地表快速变化而过时的问题。TasGen利用时空光谱嵌入从单日期静态标签生成动态训练样本。第一阶段通过分层时空光谱变分自编码器（HTS-VAE）学习正常样本的潜在模式并进行异常检测；第二阶段则通过分类器重新标记变化点以生成动态样本。此外，还提出了基于吉布斯采样的异常解释方法。

> **摘要翻译:** 遥感地理制图的准确性需要及时且具有代表性的样本。然而，地表快速变化常常使静态样本在数月内过时，导致手动样本更新费力且不可持续。为解决这一挑战，我们提出了TasGen，一种两阶段的时空光谱感知自动样本生成方法，用于在无人干预的情况下从单日期静态标签生成动态训练样本。地表动态通常表现为时空光谱序列中的异常。这些异常是多变量但统一的：时间、光谱或联合异常源于不同的机制，不能简单地耦合，因为这可能会掩盖变化的性质。然而，任何地表状态都对应着连贯的时空光谱特征，如果将这两个维度分开建模，这些特征将会丢失。为了有效捕捉这些动态，TasGen首先解耦时间和光谱特征以隔离它们各自的贡献，然后将它们耦合以建模它们的协同相互作用。在第一阶段，我们引入了一个分层时空光谱变分自编码器（HTS-VAE），具有双维度嵌入，通过首先解耦然后联合嵌入时间和光谱信息来学习正常样本的低维潜在模式。这种时空光谱嵌入通过识别与学习到的联合模式的偏差来实现鲁棒的异常检测。在第二阶段，一个在稳定样本上训练的分类器重新标记随时间变化的变点以生成动态样本。为了不仅检测而且解释地表动态，我们进一步提出了一种基于吉布斯采样的异常解释方法，该方法将变化归因于特定的光谱-时间维度。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [190] [Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging](https://arxiv.org/abs/2507.17869)
> *将特征选择与机器学习相结合，利用田间高光谱成像评估葡萄叶片氮含量*

*Atif Bilal Asad, Achyut Paudel, Safal Kshetri, Chenchen Kang, Salik Ram Khanal, Nataliya Shcherbatyuk, Pierre Davadant, R. Paul Schreiner, Santosh Kalauni, Manoj Karkee, Markus Keller* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 高光谱成像, 氮评估, 葡萄藤, 特征选择, 机器学习

**Comment:** 

> **TL;DR:** 本研究利用田间高光谱成像、特征选择和机器学习方法，实现了葡萄叶片和冠层氮浓度的预测，并确定了预测氮含量的关键光谱区域。

**AI_Comments:** 该研究将高光谱成像、特征选择和机器学习算法有效结合，为葡萄园氮营养监测提供了一种非侵入式、高效的解决方案。通过识别关键光谱波段，提高了预测的鲁棒性。虽然R平方值显示仍有提升空间，但其在田间条件下的应用潜力巨大，有助于实现精准农业管理。

<details>
  <summary>Details</summary>

**Motivation:** 氮是葡萄园中最重要的营养物质之一，影响植物生长和产品。由于土壤氮具有高度时空变异性，因此需要准确估算葡萄叶片氮浓度并进行个体化施肥管理。

**Method:** 本研究使用400-1000nm范围的田间高光谱图像，收集自不同葡萄园、两个生长阶段和两个生长季节的四种葡萄品种。图像处理后，采用两种特征选择方法识别与叶片氮浓度相关的最佳光谱波段。选定的波段用于训练和测试梯度提升（Gradient Boosting）和XGBoost两种机器学习模型来预测氮浓度。

**Result:** 特征选择方法识别的大部分光谱区域在不同方法和数据集类型（叶片级和冠层级）之间具有一致性，特别是在500-525nm、650-690nm、750-800nm和900-950nm等关键区域。氮预测结果显示，尽管使用了不同的光谱波段集，机器学习模型在冠层级数据上的R平方为0.49，在叶片级数据上的R平方为0.57。

**Conclusion:** 该研究证明了利用田间高光谱成像以及结合特征选择和机器学习技术来监测葡萄园氮状态的潜力。

> **ai_Abstract:** 本研究旨在利用田间高光谱成像技术，结合特征选择和机器学习（梯度提升、XGBoost）方法，准确预测葡萄叶片和冠层氮浓度。研究收集了来自不同葡萄园、不同生长阶段和季节的四种葡萄品种的高光谱图像。结果发现，特定光谱区域（如500-525nm、650-690nm、750-800nm、900-950nm）在预测氮含量方面表现出鲁棒性，模型在叶片级和冠层级数据上分别达到了0.57和0.49的R平方。该研究证明了高光谱成像结合智能算法在葡萄园氮状态监测中的应用潜力。

> **摘要翻译:** 氮（N）是葡萄园中最关键的营养物质之一，影响植物生长以及随后的产品，如葡萄酒和果汁。由于土壤氮具有高度时空变异性，因此需要准确估算葡萄叶片的氮浓度，并以个体植物水平管理施肥，以最佳地满足植物需求。在本研究中，我们使用波长范围为400至1000纳米的田间高光谱图像，这些图像来自不同葡萄园和两个生长季节的两个生长阶段收集的四种不同葡萄品种，以开发预测叶片级和冠层级氮浓度的模型。图像处理后，采用两种特征选择方法来识别对叶片氮浓度有响应的最佳光谱波段集。选定的光谱波段用于训练和测试两种不同的机器学习（ML）模型，即梯度提升（Gradient Boosting）和XGBoost，用于预测氮浓度。叶片级和冠层级数据集的选定波段比较表明，特征选择方法识别的大部分光谱区域在两种方法和数据集类型（叶片级和冠层级数据集）中都存在，特别是在关键区域：500-525nm、650-690nm、750-800nm和900-950nm。这些发现表明这些光谱区域在预测氮含量方面的鲁棒性。氮预测结果表明，尽管每次分析级别使用了不同的选定光谱波段集，但ML模型在冠层级数据上的R平方为0.49，在叶片级数据上的R平方为0.57。该研究证明了利用田间高光谱成像以及在集成特征选择和ML技术中使用光谱数据来监测葡萄园氮状态的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [217] [crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)
> *crossMoDA 挑战：2021 年至 2023 年前庭神经鞘瘤和耳蜗分割的跨模态域适应技术演变*

*Navodini Wijethilake, Reuben Dorent, Marina Ivory, Aaron Kujawa, Stefan Cornelissen, Patrick Langenhuizen, Mohamed Okasha, Anna Oviedova, Hexin Dong, Bogyeong Kang, Guillaume Sallé, Luyi Han, Ziyuan Zhao, Han Liu, Yubo Fan, Tao Yang, Shahad Hardan, Hussain Alasmawi, Santosh Sanjeev, Yuzhou Zhuang, Satoshi Kondo, Maria Baldeon Calisto, Shaikh Muhammad Uzair Noman, Cancan Chen, Ipek Oguz, Rongguo Zhang, Mina Rezaei, Susana K. Lai-Yuen, Satoshi Kasai, Yunzhi Huang, Chih-Cheng Hung, Mohammad Yaqub, Lisheng Wang, Benoit M. Dawant, Cuntai Guan, Ritse Mann, Vincent Jaouen, Tae-Eui Kam, Li Zhang, Jonathan Shapey, Tom Vercauteren* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 跨模态域适应, 医学图像分割, 前庭神经鞘瘤, 耳蜗, crossMoDA挑战

**Comment:** 

> **TL;DR:** crossMoDA挑战系列报告了2021-2023年间前庭神经鞘瘤和耳蜗跨模态分割技术的发展，强调数据多样性对性能的积极影响及未来挑战方向。

**AI_Comments:** 这篇论文通过分析crossMoDA挑战的演变，展示了医学图像分割领域在跨模态域适应方面的进展和挑战。其创新点在于持续推动数据集的异质性和任务的复杂性，模拟真实临床场景。论文强调了增加数据多样性对模型泛化能力的积极影响，即使是在解决看似同质的数据集问题时。然而，耳蜗Dice分数下降的观察也揭示了在增加任务复杂性时可能遇到的瓶颈，提示研究者在追求精细分割的同时，需平衡任务难度与现有技术的成熟度。这项工作为未来的跨模态分割基准测试提供了宝贵的经验和方向。

<details>
  <summary>Details</summary>

**Motivation:** 该挑战旨在推动无监督跨模态分割技术，特别是在对比增强T1（ceT1）到T2 MRI的迁移学习中，以自动化前庭神经鞘瘤（VS）和耳蜗在T2扫描上的分割，从而实现更具成本效益的VS管理。

**Method:** crossMoDA挑战系列于2021年启动，重点是无监督的跨模态分割，从ceT1学习并迁移到T2 MRI。挑战目标随时间演变：2021年使用单一机构数据进行基本分割；2022年引入多机构数据和Koos分级；2023年涵盖异构常规数据和肿瘤亚分割。本文报告了2022年和2023年的发现，并对挑战多年来的进展进行了回顾性分析。

**Result:** 观察结果显示，随着数据集的扩展，异常值的数量减少，尽管扫描协议的多样性同时增加。2023年获胜方法在2021年和2022年测试数据上减少了异常值，表明数据异质性增加可以提高即使在同质数据上的分割性能。然而，2023年耳蜗的Dice分数有所下降，这可能是由于肿瘤亚注释增加了复杂性，影响了整体分割性能。

**Conclusion:** 尽管前庭神经鞘瘤分割要达到临床可接受水平仍需努力，但性能的平台期表明，未来基准测试可能需要更具挑战性的跨模态任务。

> **ai_Abstract:** 本文回顾了2021年至2023年跨模态域适应（crossMoDA）挑战系列的发展，该挑战旨在推动无监督的跨模态医学图像分割，特别是前庭神经鞘瘤和耳蜗在T2 MRI上的自动化分割。挑战从单一机构数据和基本分割发展到多机构异构数据和复杂亚分割任务。研究发现，随着数据集的扩展和多样性增加，分割性能的异常值减少，尤其是在2023年获胜方案中表现出即使在同质数据上也能提升性能。然而，耳蜗分割的Dice分数在2023年有所下降，可能与任务复杂性增加有关。文章指出，尽管取得了进展，但仍需进一步提升以达到临床可接受的分割精度，并建议未来挑战应探索更具挑战性的跨模态任务。

> **摘要翻译:** cross-Modality Domain Adaptation (crossMoDA) 挑战系列于2021年与国际医学图像计算和计算机辅助干预会议 (MICCAI) 同时启动，专注于无监督的跨模态分割，从对比增强T1 (ceT1) 学习并迁移到T2 MRI。这项任务是域偏移的一个极端例子，被选作一个有意义且具有启发性的基准。从临床应用角度来看，它旨在自动化T2扫描上的前庭神经鞘瘤 (VS) 和耳蜗分割，以实现更具成本效益的VS管理。随着时间的推移，挑战目标已演变以增强其临床相关性。挑战从2021年使用单一机构数据和基本分割，到2022年纳入多机构数据和Koos分级，到2023年，它包括异构常规数据以及肿瘤内和外耳道成分的亚分割。在这项工作中，我们报告了2022年和2023年版本的结果，并对多年来的挑战进展进行了回顾性分析。连续挑战贡献的观察结果表明，随着数据集的扩展，异常值的数量减少。这一点值得注意，因为数据集的扫描协议多样性同时增加。2023年版本的获胜方法减少了2021年和2022年测试数据上的异常值，展示了数据异质性增加如何提高即使在同质数据上的分割性能。然而，2023年耳蜗的Dice分数有所下降，这可能是由于肿瘤亚注释增加了复杂性，影响了整体分割性能。尽管临床可接受的前庭神经鞘瘤分割仍需进展，但性能的平台期表明，更具挑战性的跨模态任务可能更适合未来的基准测试。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [220] [Hierarchical Diffusion Framework for Pseudo-Healthy Brain MRI Inpainting with Enhanced 3D Consistency](https://arxiv.org/abs/2507.17911)
> *用于增强3D一致性的伪健康脑部MRI图像修复的分层扩散框架*

*Dou Hoon Kwark, Shirui Luo, Xiyue Zhu, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-23**

**Keywords:** 伪健康图像修复, 脑部MRI, 分层扩散, 3D一致性, 图像修复

**Comment:** 11 pages, 2 figures

> **TL;DR:** 该论文提出了一种分层扩散框架，通过结合两个垂直的2D扩散模型，解决了伪健康脑部MRI图像修复中2D方法缺乏3D一致性和3D方法需要大量数据的挑战，并在真实感和体积一致性方面优于现有技术。

**AI_Comments:** 该论文的创新之处在于其分层扩散框架，巧妙地结合了2D模型的效率和3D模型的体积一致性。通过分解为两个垂直的2D阶段，它避免了直接3D建模对大量数据的需求，同时有效解决了传统2D方法带来的切片间不连续问题。这种设计对于医疗图像处理，尤其是数据稀缺的场景，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 伪健康图像修复是分析病理脑部MRI扫描的重要预处理步骤。现有大多数2D切片方法虽然平面内保真度高，但切片间独立性导致体积不连续；而全3D模型虽能缓解此问题，但其高模型容量需要大量训练数据，这在医疗环境中往往不切实际。

**Method:** 本研究提出了一种分层扩散框架，通过用两个垂直的粗到细2D阶段取代直接的3D建模。首先，一个轴向扩散模型生成粗略的、全局一致的图像修复；然后，一个冠状扩散模型对解剖细节进行细化。该方法通过结合垂直空间视图和自适应重采样，平衡了数据效率和体积一致性。

**Result:** 实验结果表明，该方法在真实感和体积一致性方面均优于现有最先进的基线方法。

**Conclusion:** 该分层扩散框架是伪健康图像修复的一个有前景的解决方案。

> **ai_Abstract:** 该论文提出了一种新颖的分层扩散框架，用于伪健康脑部MRI图像修复，旨在解决现有2D方法导致的体积不连续性和3D方法对大量训练数据的需求。该框架采用两个垂直的2D扩散阶段：首先通过轴向扩散模型获得粗略的全局一致性修复，随后通过冠状扩散模型精细化解剖细节。这种结合垂直空间视图和自适应重采样的方法，在数据效率和体积一致性之间取得了平衡，并在实验中表现出优于现有技术的真实感和体积一致性。

> **摘要翻译:** 伪健康图像修复是分析病理脑部MRI扫描的重要预处理步骤。目前大多数图像修复方法偏爱基于切片的2D模型，因其具有较高的平面内保真度，但切片间的独立性导致体积中出现不连续性。完全3D模型缓解了这个问题，但其高模型容量需要大量的训练数据才能实现可靠、高保真度的合成——这在医疗环境中往往不切实际。我们通过用两个垂直的粗到细2D阶段取代直接的3D建模，解决了这些限制，提出了一个分层扩散框架。一个轴向扩散模型首先产生一个粗略的、全局一致的图像修复；然后，一个冠状扩散模型细化解剖细节。通过结合垂直空间视图和自适应重采样，我们的方法平衡了数据效率和体积一致性。我们的实验表明，我们的方法在真实感和体积一致性方面均优于现有最先进的基线，使其成为伪健康图像修复的一个有前景的解决方案。代码可在https://github.com/dou0000/3dMRI-Consistent-Inpaint 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [250] [Benchmarking of Deep Learning Methods for Generic MRI Multi-OrganAbdominal Segmentation](https://arxiv.org/abs/2507.17971)
> *深度学习方法在通用MRI多器官腹部分割中的基准测试*

*Deepa Krishnaswamy, Cosmin Ciausu, Steve Pieper, Ron Kikinis, Benjamin Billot, Andrey Fedorov* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-23**

**Keywords:** MRI分割, 深度学习, 基准测试, 腹部器官, 泛化能力

**Comment:** 

> **TL;DR:** 本文对现有最先进的MRI腹部多器官分割深度学习模型进行了全面的基准测试，并引入了一个基于CT分割数据训练的新模型ABDSynth，结果表明MRSegmentator表现最佳，而ABDSynth在数据预算有限时是一个可行替代方案。

**AI_Comments:** 本文对MRI腹部多器官分割领域的现有深度学习方法进行了全面的基准测试，填补了该领域缺乏系统评估的空白。其创新之处在于引入了ABDSynth模型，该模型通过利用丰富的CT分割数据来规避MRI数据标注的难题，为数据受限场景提供了新思路。研究结果清晰，并提供了开源代码和数据集，对推动该领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习在CT腹部分割方面取得了进展，但MRI分割由于固有的信号变异性和训练数据标注的高成本而更具挑战性，现有方法受限于有限的MRI序列训练，泛化能力可能不足。因此，需要对MRI腹部分割工具进行全面的评估。

**Method:** 研究对三种最先进的开源模型（MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI）进行了全面的基准测试。此外，引入并评估了ABDSynth，一个纯粹基于广泛可用的CT分割数据训练的SynthSeg模型（不使用真实MRI图像）。通过利用三个公共数据集（训练时未见）评估了这些模型的准确性和泛化能力，这些数据集涵盖了主要制造商、五种MRI序列以及各种受试者条件、体素分辨率和视野。

**Result:** 结果显示MRSegmentator表现最佳且泛化能力最强。相比之下，ABDSynth的准确性略低，但由于其对训练数据的要求较低，在标注预算有限的情况下，它提供了一个可行的替代方案。

**Conclusion:** MRSegmentator是目前MRI腹部多器官分割的最佳选择，而ABDSynth则为数据标注资源受限的情况提供了一个有价值的替代方案。未来的基准测试和研究可以利用本文提供的评估代码和数据集。

> **ai_Abstract:** 本研究旨在评估深度学习方法在MRI多器官腹部分割中的性能和泛化能力。文章对MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI三种主流开源模型进行了全面基准测试，并提出了一个新模型ABDSynth，该模型仅使用CT分割数据进行训练。通过在三个未见过的公共数据集上进行评估，研究发现MRSegmentator表现最佳且泛化能力最强。尽管ABDSynth的准确性略逊一筹，但其对标注数据的低需求使其成为数据预算有限时的可行选择。研究提供了评估代码和数据集以促进未来的基准测试。

> **摘要翻译:** 深度学习的最新进展催生了用于腹部计算机断层扫描（CT）分割的强大自动化工具。与此同时，由于固有的信号变异性和标注训练数据集所需工作量的增加，磁共振成像（MRI）的分割更具挑战性。因此，现有方法在有限的MRI序列数据集上进行训练，这可能会限制它们的泛化能力。为了表征MRI腹部分割工具的现状，我们在此对三种最先进的开源模型进行了全面的基准测试：MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI。由于这些模型是使用劳动密集型手动标注周期进行训练的，我们还引入并评估了ABDSynth，一个纯粹基于广泛可用的CT分割（无真实图像）训练的基于SynthSeg的模型。更广泛地说，我们通过利用三个公共数据集（所有评估方法在训练期间均未见过）来评估准确性和泛化能力，这些数据集涵盖了所有主要制造商、五种MRI序列以及各种受试者条件、体素分辨率和视野。我们的结果表明，MRSegmentator取得了最佳性能且泛化能力最强。相比之下，ABDSynth的准确性略低，但其训练数据要求较低，使其在标注预算有限时成为一种替代方案。评估代码和数据集可在https://github.com/deepakri201/AbdoBench上获取，用于未来的基准测试，同时还提供了ABDSynth的推理代码和权重。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [263] [EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Control](https://arxiv.org/abs/2507.15292)
> *EndoControlMag：具有周期性参考重置和分层组织感知双掩模控制的鲁棒内窥镜血管运动放大*

*An Wang, Rulin Zhou, Mengya Xu, Yiru Ye, Longfei Gou, Yiting Chang, Hao Chen, Chwee Ming Lim, Jiankun Wang, Hongliang Ren* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 内窥镜, 血管运动放大, 周期性参考重置, 组织感知, 双掩模控制

**Comment:** 

> **TL;DR:** EndoControlMag是一种无训练的拉格朗日框架，通过周期性参考重置和分层组织感知双掩模控制，实现内窥镜下血管运动的鲁棒放大，显著优于现有方法。

**AI_Comments:** 该论文提出了一种创新的内窥镜血管运动放大框架EndoControlMag，其亮点在于无需训练的拉格朗日方法、周期性参考重置机制有效抑制误差累积，以及分层组织感知双掩模控制的精细化处理。特别是HTM模块中的双模式软化策略，能根据不同手术场景自适应调整，提升了方法的鲁棒性和普适性。该研究对于提高内窥镜手术的精度和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在内窥镜手术中，观察细微的血管运动对于手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这仍然是一个挑战。

**Method:** 本文提出了EndoControlMag，一个无需训练的、基于拉格朗日的框架，用于内窥镜环境下的掩模条件血管运动放大。该方法包含两个关键模块：周期性参考重置（PRR）方案，将视频分割成短的重叠片段，并动态更新参考帧以防止误差累积并保持时间连贯性；以及分层组织感知放大（HTM）框架，具有双模式掩模膨胀。HTM首先使用预训练的视觉跟踪模型跟踪血管核心，然后对周围组织应用两种自适应软化策略：基于运动的软化（根据观察到的组织位移调制放大强度）或基于距离的指数衰减（模拟生物力学衰减）。

**Result:** EndoControlMag在EndoVMM24数据集上进行了评估，该数据集涵盖了四种不同类型的手术和各种挑战性场景，包括遮挡、器械干扰、视角变化和血管变形。定量指标、视觉评估和外科专家评估表明，EndoControlMag在放大精度和视觉质量方面显著优于现有方法，同时在挑战性手术条件下保持了鲁棒性。

**Conclusion:** EndoControlMag通过其周期性参考重置和分层组织感知双掩模控制，成功解决了内窥镜手术中血管运动可视化面临的挑战，提供了更精确和高质量的放大效果，并在复杂场景中表现出强大的鲁棒性。

> **ai_Abstract:** EndoControlMag是一个为内窥镜手术设计的无训练血管运动放大框架。它通过周期性参考重置（PRR）解决误差累积问题，并利用分层组织感知放大（HTM）实现双模式组织软化，精确跟踪血管核心并自适应处理周围组织。在EndoVMM24数据集上的评估显示，EndoControlMag在放大精度、视觉质量和鲁棒性方面均显著优于现有方法，为内窥镜手术提供了关键的视觉辅助。

> **摘要翻译:** 在内窥镜手术中，观察细微的血管运动对于手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这仍然是一个挑战。为了解决这个问题，我们引入了EndoControlMag，一个无需训练的、基于拉格朗日的框架，用于内窥镜环境下的掩模条件血管运动放大。我们的方法具有两个关键模块：周期性参考重置（PRR）方案，将视频分割成短的重叠片段，并动态更新参考帧以防止误差累积，同时保持时间连贯性；以及分层组织感知放大（HTM）框架，具有双模式掩模膨胀。HTM首先使用预训练的视觉跟踪模型跟踪血管核心，即使在遮挡和视角变化的情况下也能保持准确的定位。然后，它对周围组织应用两种自适应软化策略之一：基于运动的软化，根据观察到的组织位移按比例调节放大强度；或基于距离的指数衰减，模拟生物力学力的衰减。这种双模式方法适应了不同的手术场景——基于运动的软化在复杂组织变形时表现出色，而基于距离的软化在光学流不可靠的条件下提供稳定性。我们在我们的EndoVMM24数据集上评估了EndoControlMag，该数据集涵盖了四种不同类型的手术和各种挑战性场景，包括遮挡、器械干扰、视角变化和血管变形。定量指标、视觉评估和外科专家评估表明，EndoControlMag在放大精度和视觉质量方面显著优于现有方法，同时在挑战性手术条件下保持了鲁棒性。代码、数据集和视频结果可在https://szupc.github.io/EndoControlMag/获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [280] [Direct Dual-Energy CT Material Decomposition using Model-based Denoising Diffusion Model](https://arxiv.org/abs/2507.18012)
> *基于模型去噪扩散模型的直接双能CT物质分解*

*Hang Xu, Alexandre Bousse, Alessandro Perelli* | **Category: eess.IV, cs.CV, physics.med-ph, 92C55, 94A08, I.4.5; J.3** | **Updated: 2025-07-24**

**Keywords:** 双能CT, 物质分解, 扩散模型, 深度学习, 束硬化效应

**Comment:** 13 pages, 10 figures, 2 tables

> **TL;DR:** 提出DEcomp-MoD，一种深度学习方法，通过直接从投影数据生成物质图像，优于现有双能CT物质分解方法。

**AI_Comments:** 本文的创新点在于提出了DEcomp-MoD，一种直接从投影数据进行物质分解的深度学习方法，有效解决了传统方法中束硬化效应和次优结果的问题。通过将领域知识（光谱DECT模型）与先进的扩散模型结合，提升了分解的准确性和一致性。其超越现有SOTA方法的性能以及在临床诊断中的潜力，使其具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有双能CT物质分解方法通常在图像域进行后处理，未能解决束硬化效应，导致次优结果。

**Method:** 本文提出了一种名为双能分解基于模型扩散（DEcomp-MoD）的深度学习程序，用于定量物质分解。该方法直接将双能CT投影数据转换为物质图像，通过将光谱DECT模型的知识融入深度学习训练损失中，并结合物质图像域中基于分数的去噪扩散学习先验。推理优化损失直接以正弦图作为输入，并通过基于模型的条件扩散模型转换为物质图像，保证结果的一致性。

**Result:** 在低剂量AAPM数据集的合成双能CT正弦图上，DEcomp-MoD在定量和定性评估方面均优于最先进的无监督基于分数模型和有监督深度学习网络。

**Conclusion:** DEcomp-MoD在双能CT物质分解方面表现出色，具有用于临床诊断的潜力。

> **ai_Abstract:** 本文提出了一种名为DEcomp-MoD的深度学习方法，用于双能CT中的定量物质分解。与传统在图像域进行后处理的方法不同，DEcomp-MoD直接将DECT投影数据转换为物质图像，并通过将光谱DECT模型知识与基于分数的去噪扩散先验相结合来优化。该方法通过直接处理正弦图并利用条件扩散模型确保结果一致性，并在合成数据集上表现出优于现有最先进方法的性能，有望应用于临床诊断。

> **摘要翻译:** 双能X射线计算机断层扫描（DECT）是一项先进技术，它利用X射线线性衰减与能量的依赖性，无需手动分割即可自动分解临床图像中的物质。然而，大多数方法在图像域中作为重建后的后处理步骤进行物质分解，但此过程未考虑束硬化效应，导致次优结果。在这项工作中，我们提出了一种名为双能分解基于模型扩散（DEcomp-MoD）的深度学习程序，用于定量物质分解，它直接将DECT投影数据转换为物质图像。该算法基于将光谱DECT模型的知识融入深度学习训练损失中，并结合物质图像域中基于分数的去噪扩散学习先验。重要的是，推理优化损失直接将正弦图作为输入，并通过基于模型的条件扩散模型转换为物质图像，从而保证结果的一致性。我们使用低剂量AAPM数据集的合成DECT正弦图，对所提出的DEcomp-MoD方法进行了定量和定性评估。最后，我们表明DEcomp-MoD优于最先进的无监督基于分数模型和有监督深度学习网络，具有部署用于临床诊断的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [291] [MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2507.16122)
> *MLRU++：用于高效3D医学图像分割的多尺度轻量级残差UNETR++与注意力机制*

*Nand Kumar Yadav, Rodrigue Rizk, William CW Chen, KC* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学图像分割, 3D分割, UNETR++, 注意力机制, 轻量级模型

**Comment:** 

> **TL;DR:** MLRU++是一种新的轻量级CNN-Transformer混合架构，通过引入轻量级通道和瓶颈注意力模块以及多尺度瓶颈块，在保持高精度的同时显著提高了3D医学图像分割的效率。

**AI_Comments:** 该论文提出了一种创新的轻量级CNN-Transformer混合架构MLRU++，通过结合注意力机制和多尺度特征聚合，有效解决了3D医学图像分割中精度与效率难以兼顾的问题。其主要创新点在于LCBAM和M2B模块，它们在保持高性能的同时显著降低了模型复杂度和计算开销，这对于实际医疗应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 精确高效的医学图像分割至关重要，但由于解剖变异性和对体数据的高计算需求而充满挑战。现有的混合CNN-Transformer架构虽然取得了最先进的结果，但增加了显著的复杂性。

**Method:** 本文提出了MLRU++，一种多尺度轻量级残差UNETR++架构，旨在平衡分割精度和计算效率。它引入了两项关键创新：轻量级通道和瓶颈注意力模块（LCBAM），以最小的开销增强上下文特征编码；以及解码器中的多尺度瓶颈块（M2B），通过多分辨率特征聚合捕获细粒度细节。

**Result:** 在四个公开基准数据集（Synapse、BTCV、ACDC和Decathlon Lung）上的实验表明，MLRU++取得了最先进的性能，在Synapse上的平均Dice分数达到87.57%，ACDC上为93.00%，Lung上为81.12%。与现有领先模型相比，MLRU++在Synapse和ACDC上的Dice分数分别提高了5.38%和2.12%，同时显著减少了参数数量和计算成本。消融研究进一步证实了所提出架构组件的有效性。

**Conclusion:** MLRU++为3D医学图像分割任务提供了一个实用且高性能的解决方案。

> **ai_Abstract:** MLRU++是一种新型的多尺度轻量级残差UNETR++架构，专为高效的3D医学图像分割而设计。它通过引入轻量级通道和瓶颈注意力模块（LCBAM）以增强特征编码，以及多尺度瓶颈块（M2B）以捕获细粒度细节，从而在分割精度和计算效率之间取得平衡。实验结果表明，MLRU++在多个基准数据集上均达到了最先进的性能，并在显著降低计算成本的同时提高了Dice分数，为3D医学图像分割提供了一个实用的高性能解决方案。

> **摘要翻译:** 精确高效的医学图像分割至关重要，但由于解剖变异性和对体数据的高计算需求而充满挑战。最近的混合CNN-Transformer架构取得了最先进的结果，但增加了显著的复杂性。在本文中，我们提出了MLRU++，一种多尺度轻量级残差UNETR++架构，旨在平衡分割精度和计算效率。它引入了两项关键创新：一个轻量级通道和瓶颈注意力模块（LCBAM），以最小的开销增强上下文特征编码；以及解码器中的多尺度瓶颈块（M2B），通过多分辨率特征聚合捕获细粒度细节。在四个公开基准数据集（Synapse、BTCV、ACDC和Decathlon Lung）上的实验表明，MLRU++取得了最先进的性能，在Synapse上的平均Dice分数达到87.57%（Synapse），93.00%（ACDC），和81.12%（Lung）。与现有领先模型相比，MLRU++在Synapse和ACDC上的Dice分数分别提高了5.38%和2.12%，同时显著减少了参数数量和计算成本。评估LCBAM和M2B的消融研究进一步证实了所提出架构组件的有效性。结果表明，MLRU++为3D医学图像分割任务提供了一个实用且高性能的解决方案。源代码可在以下地址获取：https://github.com/1027865/MLRUPP

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [315] [UniSegDiff: Boosting Unified Lesion Segmentation via a Staged Diffusion Model](https://arxiv.org/abs/2507.18362)
> *UniSegDiff: 通过分阶段扩散模型提升统一病灶分割*

*Yilong Hu, Shijie Chang, Lihe Zhang, Feng Tian, Weibing Sun, Huchuan Lu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 病灶分割, 统一分割, 分阶段训练, 医学图像处理

**Comment:** MICCAI2025

> **TL;DR:** UniSegDiff是一个新颖的分阶段扩散模型框架，通过动态调整预测目标和预训练特征提取网络，解决了现有扩散模型在病灶分割中注意力不均和训练时间长的问题，实现了多模态和多器官的统一病灶分割，并显著优于现有SOTA方法。

**AI_Comments:** UniSegDiff的创新在于其分阶段训练和推理方法，有效解决了DPM在医学图像分割中面临的注意力分布不均和效率问题。通过动态调整预测目标和预训练特征提取网络，该模型实现了统一的病灶分割，并在多个模态和器官上展现出卓越性能，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 扩散概率模型（DPM）在医学图像分割中存在注意力在不同时间步分布不均、训练时间长和产生次优解的问题。

**Method:** 提出UniSegDiff框架，引入分阶段训练和推理方法，动态调整不同阶段的预测目标，强制模型在所有时间步保持高注意力，并通过预训练特征提取网络实现统一病灶分割。

**Result:** UniSegDiff在六个不同器官、多种成像模态上的综合实验结果表明，它显著优于之前的最先进（SOTA）方法。

**Conclusion:** UniSegDiff通过其创新的分阶段训练和推理策略，有效解决了扩散模型在统一病灶分割中的挑战，并取得了卓越的性能，证明了其作为一种有前景的统一病灶分割方法的潜力。

> **ai_Abstract:** 本文提出了UniSegDiff，一个新颖的分阶段扩散模型框架，旨在解决多模态和多器官的统一病灶分割问题。针对现有扩散模型训练和推理中注意力分布不均、训练时间长的问题，UniSegDiff引入了动态调整预测目标的分阶段训练和推理策略，并结合预训练特征提取网络。实验结果表明，UniSegDiff在多种成像模态和器官上显著超越了现有的最先进方法。

> **摘要翻译:** 扩散概率模型（DPM）在各种生成任务中表现出卓越的性能。扩散模型固有的随机性有助于解决医学图像和标签边缘模糊等问题，使扩散概率模型（DPMs）成为病灶分割的一种有前景的方法。然而，我们发现当前扩散模型的训练和推理策略导致注意力在不同时间步分布不均，从而导致训练时间更长和次优解。为此，我们提出了UniSegDiff，一个新颖的扩散模型框架，旨在以统一的方式解决多模态和多器官的病灶分割问题。该框架引入了一种分阶段的训练和推理方法，动态调整不同阶段的预测目标，强制模型在所有时间步保持高注意力，并通过预训练分割特征提取网络实现统一病灶分割。我们在六个不同器官、多种成像模态上评估了性能。综合实验结果表明，UniSegDiff显著优于之前的最先进（SOTA）方法。代码可在 https://github.com/HUYILONG-Z/UniSegDiff 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [351] [DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis](https://arxiv.org/abs/2507.18433)
> *DiagR1：一种通过强化学习训练的用于消化病理诊断的视觉-语言模型*

*Minxi Ouyang, Lianghui Zhu, Yaqing Bao, Qiang Huang, Jingli Ouyang, Tian Guan, Xitong Ling, Jiawen Li, Song Duan, Wenbin Dai, Li Zheng, Xuemei Zhang, Yonghong He* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉-语言模型, 强化学习, 消化病理诊断, 多模态, GRPO

**Comment:** 

> **TL;DR:** DiagR1是一个通过强化学习训练的视觉-语言模型，用于消化病理诊断，通过构建新数据集、提示论证策略和强化学习微调，显著提高了诊断报告的质量、完整性和临床相关性。

**AI_Comments:** 这项研究通过结合新数据集的构建、创新的提示策略以及强化学习（GRPO）的引入，有效提升了病理诊断AI模型的性能和可信度。特别是在解决“幻觉”和“推理透明度”这两个关键临床挑战上，显示了其创新性和重要性。强化学习的应用有助于优化模型输出的结构和推理链，使其更符合临床需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态模型在胃肠道病理分析中面临数据质量差（导致幻觉）和推理透明度不足（难以审计）的问题，这限制了其在临床实践中的应用。

**Method:** 作者构建了一个大规模胃肠道病理数据集；提出了一个结合病变分类和解剖部位信息的提示论证策略；并采用结合监督微调和群相对策略优化（GRPO）的后训练流程来提高推理质量和输出结构。

**Result:** 该方法在病理报告生成任务中显著优于现有基线模型，临床相关性提高18.7%，结构完整性提高32.4%，诊断错误减少41.2%，显示出卓越的准确性和临床实用性。

**Conclusion:** 通过新的数据集、提示策略和强化学习训练，DiagR1模型有效解决了现有模型在消化病理诊断中的数据质量和推理透明度问题，显著提高了诊断报告的质量和临床实用性。

> **ai_Abstract:** 本文提出了DiagR1，一个用于消化病理诊断的视觉-语言模型，旨在解决现有模型在数据质量和推理透明度方面的不足。通过构建大规模胃肠道病理数据集、引入提示论证策略以及结合监督微调和GRPO的强化学习训练，DiagR1显著提高了诊断报告的生成质量、结构完整性和临床相关性，并在真实世界任务中表现出优于现有基线的准确性和实用性。

> **摘要翻译:** 多模态大模型在自动化病理图像分析中展现出巨大潜力。然而，当前用于胃肠道病理学的多模态模型受到数据质量和推理透明度的双重限制：公共数据集中普遍存在的噪声和不完整的注释使得视觉语言模型在生成诊断文本时容易产生事实性幻觉，而缺乏明确的中间推理链使得输出难以审计，从而在临床实践中可信度较低。为解决这些问题，我们构建了一个包含微观描述和诊断结论的大规模胃肠道病理数据集，并提出了一种提示论证策略，该策略结合了病变分类和解剖部位信息。这种设计指导模型更好地捕捉图像特定特征并保持生成中的语义一致性。此外，我们采用了一种结合监督微调和群相对策略优化（GRPO）的后训练流程，以提高推理质量和输出结构。在真实世界病理报告生成任务上的实验结果表明，我们的方法在生成质量、结构完整性和临床相关性方面显著优于最先进的开源和专有基线。我们的解决方案在临床相关性方面比最先进模型高出18.7%，结构完整性提高32.4%，诊断错误减少41.2%，与现有解决方案相比，显示出卓越的准确性和临床实用性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [477] [X-ray2CTPA: Leveraging Diffusion Models to Enhance Pulmonary Embolism Classification](https://arxiv.org/abs/2406.16109)
> *X-ray2CTPA：利用扩散模型增强肺栓塞分类*

*Noa Cahan, Eyal Klang, Galit Aviram, Yiftach Barash, Eli Konen, Raja Giryes, Hayit Greenspan* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 跨模态翻译, 肺栓塞分类, 胸部X光, CT肺动脉造影

**Comment:** preprint, project code: https://github.com/NoaCahan/X-ray2CTPA

> **TL;DR:** 该研究利用扩散模型将2D胸部X光片转换为3D CT肺动脉造影图像，从而在肺栓塞分类任务中取得了性能提升，旨在提供更易于获取且成本效益更高的诊断工具。

**AI_Comments:** 这项研究的创新之处在于其利用了先进的扩散模型进行医学图像的跨模态翻译，将低成本、易获取的2D X光片转换为高信息量的3D CTPA图像。这不仅解决了传统CTPA的局限性，还在肺栓塞分类中展现出显著的诊断潜力。其通用性也预示着在其他医学影像领域的广泛应用前景，对提高诊断的可及性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 胸部X光片（CXR）在诊断方面存在局限性，而计算机断层扫描（CT）特别是CT肺动脉造影（CTPA）虽然能提供更详细的三维数据，但成本高、辐射大且不易获取。本研究旨在解决CTPA的可及性和成本问题。

**Method:** 本研究探索了一种跨模态翻译方法，将低对比度分辨率的2D X光输入转换为高对比度和空间分辨率的3D CTPA扫描。该方法引入了一种新颖的基于扩散模型的方法，并使用定量指标和放射科医生的定性反馈来评估模型性能。此外，合成的3D图像被用于分类框架。

**Result:** 研究结果表明，通过使用合成的3D图像，在肺栓塞（PE）分类任务中，AUC（受试者工作特征曲线下面积）得到了改善。所提出的方法具有通用性，能够执行医学成像中的其他跨模态翻译。

**Conclusion:** 该方法可能为开发更易于获取且成本效益更高的先进诊断工具铺平道路。

> **ai_Abstract:** 本研究提出了一种名为X-ray2CTPA的新颖方法，利用扩散模型将2D胸部X光片转换为3D CT肺动脉造影（CTPA）图像。该方法旨在解决传统CTPA扫描成本高、辐射大且不易获取的问题。通过生成高分辨率的3D图像，该模型在肺栓塞分类任务中显著提升了性能（改善了AUC）。研究表明，该方法具有通用性，可应用于其他医学图像的跨模态翻译，有望推动更经济、更便捷的先进诊断工具的发展。

> **摘要翻译:** 胸部X光片或胸部X射线照相（CXR）常用于医学诊断，但与计算机断层扫描（CT）相比，其成像能力通常有限。CT扫描，特别是CT肺动脉造影（CTPA）等对比增强扫描，能提供更详细、更准确的三维数据。然而，CT扫描成本更高、辐射暴露更大，且不如CXR易于获取。在这项工作中，我们探索了从2D低对比度分辨率X射线输入到3D高对比度和空间分辨率CTPA扫描的跨模态翻译。受生成式AI最新进展的推动，我们引入了一种新颖的基于扩散模型的方法来完成这项任务。我们使用定量指标和放射科医生的定性反馈来评估模型性能，以确保生成图像的诊断相关性。此外，我们将合成的3D图像应用于分类框架中，并显示在使用初始CXR输入的情况下，PE分类任务的AUC有所改善。所提出的方法具有通用性，能够执行医学成像中的其他跨模态翻译。它可能为更易于获取且成本效益更高的先进诊断工具铺平道路。该项目的代码可在以下网址获取：https://github.com/NoaCahan/X-ray2CTPA。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [506] [Parameter-Efficient Fine-Tuning of 3D DDPM for MRI Image Generation Using Tensor Networks](https://arxiv.org/abs/2507.18112)
> *使用张量网络对3D DDPM进行参数高效微调以生成MRI图像*

*Binghua Li, Ziqing Chang, Tong Liang, Chao Li, Toshihisa Tanaka, Shigeki Aoki, Qibin Zhao, Zhe Sun* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 参数高效微调, 3D DDPM, MRI图像生成, 张量网络, TenVOO

**Comment:** 

> **TL;DR:** 本文提出TenVOO，一种基于张量网络的新型参数高效微调方法，用于3D DDPM在MRI图像生成中，以极少参数实现最先进的性能。

**AI_Comments:** 该论文创新性地将张量网络引入3D DDPM的参数高效微调中，有效解决了3D卷积核参数量大的问题。其提出的TenVOO方法以极低的参数成本实现了SOTA性能，对于资源受限的MRI图像生成任务具有重要意义。这一方法为未来深度学习模型的高效部署和应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前在磁共振成像（MRI）图像生成中，针对基于三维（3D）U-Net的去噪扩散概率模型（DDPMs）的参数高效微调（PEFT）研究，特别是3D卷积操作的参数高效表示方面，仍然非常有限。

**Method:** 本文提出了一种新颖的PEFT方法，名为张量体积算子（TenVOO），专门设计用于微调具有3D卷积骨干的DDPMs。TenVOO利用张量网络建模，通过低维张量表示3D卷积核，从而在微调过程中以少量参数有效捕获复杂的空间依赖性。

**Result:** TenVOO在三个脑部MRI数据集（ADNI、PPMI和BraTS2021）上进行了评估，结果表明，它在多尺度结构相似性指数（MS-SSIM）方面达到了最先进的性能，在捕获空间依赖性方面优于现有方法，同时仅需原始模型0.3%的可训练参数。

**Conclusion:** 通过引入TenVOO，本文成功解决了3D DDPM在MRI图像生成中参数高效微调的挑战，以极少的参数实现了卓越的性能，并有效捕获了复杂的空间依赖性。

> **ai_Abstract:** 本文提出了一种名为TenVOO的新型参数高效微调（PEFT）方法，用于优化三维（3D）U-Net去噪扩散概率模型（DDPMs）在磁共振成像（MRI）图像生成中的应用。针对3D卷积操作参数高效表示的局限性，TenVOO利用张量网络建模，通过低维张量表示3D卷积核，从而在微调过程中以极少的参数（仅占原始模型的0.3%）有效捕获复杂的空间依赖性。在ADNI、PPMI和BraTS2021等脑部MRI数据集上的实验证明，TenVOO在多尺度结构相似性指数（MS-SSIM）方面取得了最先进的性能。

> **摘要翻译:** 我们解决了磁共振成像（MRI）图像生成中，基于三维（3D）U-Net的去噪扩散概率模型（DDPMs）的参数高效微调（PEFT）挑战。尽管其具有实际意义，但关于3D卷积操作的参数高效表示研究仍然有限。为了弥补这一差距，我们提出了张量体积算子（TenVOO），这是一种专门为微调具有3D卷积骨干的DDPMs而设计的新型PEFT方法。TenVOO利用张量网络建模，通过低维张量表示3D卷积核，在微调过程中以少量参数有效捕获复杂的空间依赖性。我们在三个下游脑部MRI数据集——ADNI、PPMI和BraTS2021上评估了TenVOO，通过微调一个在英国生物银行59,830个T1加权脑部MRI扫描上预训练的DDPM。我们的结果表明，TenVOO在多尺度结构相似性指数（MS-SSIM）方面取得了最先进的性能，在捕获空间依赖性方面优于现有方法，同时仅需要原始模型0.3%的可训练参数。我们的代码可在以下网址获取：https://github.com/xiaovhua/tenvoo

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [519] [AI Workflow, External Validation, and Development in Eye Disease Diagnosis](https://arxiv.org/abs/2409.15087)
> *眼病诊断中的AI工作流程、外部验证与发展*

*Qingyu Chen, Tiarnan D L Keenan, Elvira Agron, Alexis Allot, Emily Guan, Bryant Duong, Amr Elsawy, Benjamin Hou, Cancan Xue, Sanjeeb Bhandari, Geoffrey Broadhead, Chantal Cousineau-Krieger, Ellen Davis, William G Gensheimer, David Grasic, Seema Gupta, Luis Haddock, Eleni Konstantinou, Tania Lamba, Michele Maiberger, Dimosthenis Mantopoulos, Mitul C Mehta, Ayman G Nahri, Mutaz AL-Nawaflh, Arnold Oshinsky, Brittany E Powell, Boonkit Purt, Soo Shin, Hillary Stiefel, Alisa T Thavikulwat, Keith James Wroblewski, Tham Yih Chung, Chui Ming Gemmy Cheung, Ching-Yu Cheng, Emily Y Chew, Michelle R. Hribar, Michael F. Chiang, Zhiyong Lu* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** AI工作流程, 眼病诊断, 外部验证, 持续学习, 黄斑变性

**Comment:** Published in JAMA Network Open,
  doi:10.1001/jamanetworkopen.2025.17204

> **TL;DR:** 本研究设计并实现了AI辅助的年龄相关性黄斑变性诊断工作流程，通过与临床医生表现对比和模型持续增强，证明AI显著提升了诊断准确性和效率，并在不同数据集上表现出鲁棒性。

**AI_Comments:** 该论文的创新点在于不仅验证了AI在诊断准确性上的提升，更重要的是将其置于真实的临床工作流程中进行外部验证，并考察了对临床医生效率的影响。通过引入持续学习和大规模外部数据集进行模型增强和泛化能力测试，增加了研究的可靠性和实际应用价值。这对于推动医疗AI从实验室走向临床具有重要意义，尤其是在强调下游责任和多样化人群验证方面。

<details>
  <summary>Details</summary>

**Motivation:** 由于疾病负担增加和临床医生资源有限，及时诊断面临挑战。尽管AI在诊断准确性方面有潜力，但由于在临床工作流程和多样化人群中缺乏充分验证，其在实际应用中遇到问题。本研究旨在解决医疗AI下游责任的空白。

**Method:** 本研究以年龄相关性黄斑变性（AMD）诊断和严重程度分类为例。设计并实施了一个AI辅助诊断工作流程，并与来自12家机构的24位临床医生在真实患者数据（来自年龄相关性眼病研究AREDS）上比较了有无AI辅助的诊断性能。此外，通过加入约40,000张额外医学图像（AREDS2数据集）持续增强现有AI模型。改进后的模型在AREDS、AREDS2以及新加坡的外部测试集上进行了系统评估。

**Result:** AI辅助显著提高了24位临床医生中23位的诊断准确性和分类能力，平均F1分数从37.71（手动）提高到45.52（手动+AI），增长了20%（P值<0.0001），在某些情况下改进超过50%。在效率方面，AI辅助缩短了19位被追踪临床医生中17位的诊断时间，节省时间高达40%。此外，具备持续学习能力的模型在三个独立数据集上表现出稳健性能，准确率提高了29%，在新加坡人群中F1分数从42提升到54。

**Conclusion:** AI辅助诊断工作流程显著提高了临床医生的诊断准确性和效率。通过持续学习增强的AI模型在不同人群和数据集上表现出强大的泛化能力和鲁棒性，为医疗AI的实际应用提供了有效验证。

> **ai_Abstract:** 本研究设计并评估了一个AI辅助的年龄相关性黄斑变性（AMD）诊断工作流程，旨在解决医疗AI在临床应用中缺乏充分验证的问题。实验结果表明，AI辅助显著提升了24位临床医生中绝大多数的诊断准确性（F1分数提高20%）和效率（诊断时间缩短达40%）。此外，通过持续学习和额外数据（AREDS2）增强的AI模型在多个独立数据集（AREDS、AREDS2、新加坡外部数据集）上展现出强大的泛化能力和稳健性能，进一步验证了AI在眼病诊断中的实际应用潜力和价值。

> **摘要翻译:** 由于疾病负担增加和临床医生资源有限，及时诊断面临挑战。尽管AI在诊断准确性方面有潜力，但由于在临床工作流程和多样化人群中缺乏充分验证，其在实际应用中遇到问题。本研究通过年龄相关性黄斑变性（AMD）诊断和严重程度分类的案例研究，解决了医疗AI下游责任的空白。我们设计并实施了一个AI辅助的AMD诊断工作流程，并与来自12家机构的24位临床医生使用从年龄相关性眼病研究（AREDS）中抽取的真实患者数据，比较了有无AI辅助的诊断性能。此外，我们通过整合大约40,000张额外医学图像（命名为AREDS2数据集），展示了现有AI模型的持续增强。改进后的模型随后使用AREDS和AREDS2测试集以及来自新加坡的外部测试集进行了系统评估。AI辅助显著提高了24位临床医生中23位的诊断准确性和分类能力，平均F1分数从37.71（手动）提高到45.52（手动+AI），增长了20%（P值<0.0001），在某些情况下改进超过50%。在效率方面，AI辅助缩短了19位被追踪临床医生中17位的诊断时间，节省时间高达40%。此外，具备持续学习能力的模型在三个独立数据集上表现出稳健性能，准确率提高了29%，在新加坡人群中F1分数从42提升到54。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [562] [ECVC: Exploiting Non-Local Correlations in Multiple Frames for Contextual Video Compression](https://arxiv.org/abs/2410.09706)
> *ECVC：利用多帧非局部相关性进行上下文视频压缩*

*Wei Jiang, Junru Li, Kai Zhang, Li Zhang* | **Category: eess.IV** | **Updated: 2025-07-24**

**Keywords:** 视频压缩, 非局部相关性, 误差累积, 深度学习, 率失真

**Comment:** Accepted to CVPR 2025

> **TL;DR:** ECVC通过利用多帧非局部相关性和引入部分级联微调策略，显著提升了视频压缩的率失真性能，并达到了最先进水平。

**AI_Comments:** 该论文的创新点在于其提出了利用多帧非局部相关性来增强时间先验，这突破了传统LVC仅关注时域运动的局限。同时，引入的部分级联微调策略有效地解决了长期序列训练中的误差累积问题，并且兼顾了计算资源限制，具有实际应用价值。其在性能上的显著提升表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有学习型视频压缩（LVC）模型主要侧重于挖掘时域运动，却忽略了帧间的非局部相关性。此外，当前的上下文视频压缩模型仅使用单个参考帧，这不足以处理复杂的运动，导致率失真性能提升受限。

**Method:** 本文提出了ECVC视频压缩方案。该方案通过利用多帧间的非局部相关性来增强时间先验，从而显著提升率失真性能。为缓解误差累积，还引入了一种部分级联微调策略，该策略支持在计算资源受限的情况下对全长序列进行微调，有效减少了训练-测试序列长度不匹配并显著降低了累积误差。

**Result:** ECVC取得了最先进的性能，在VTM-13.2低延迟B (LDB)下，与之前的SOTA方法DCVC-FM相比，在帧内周期(IP)分别为32和-1时，码率分别额外降低了10.5%和11.5%。

**Conclusion:** ECVC通过有效利用多帧非局部相关性并引入创新的部分级联微调策略，显著提升了学习型视频压缩的性能，成功解决了现有方法在处理复杂运动和误差累积方面的不足，并取得了最先进的成果。

> **ai_Abstract:** 本文提出了ECVC，一种新的学习型视频压缩方案，旨在通过利用多帧非局部相关性来增强时间先验，并引入部分级联微调策略以缓解误差累积，从而解决现有LVC模型在处理复杂运动和单参考帧不足的问题。实验结果显示，ECVC在率失真性能上达到了最先进水平，相较于现有最佳方法DCVC-FM，码率有显著降低。

> **摘要翻译:** 在学习型视频压缩（LVC）中，改进帧间预测，例如增强时域上下文挖掘和缓解累积误差，对于提升率失真性能至关重要。现有的LVC主要侧重于挖掘时域运动，却忽略了帧间的非局部相关性。此外，当前的上下文视频压缩模型使用单个参考帧，这不足以处理复杂的运动。为了解决这些问题，我们提出利用多帧间的非局部相关性来增强时间先验，显著提升率失真性能。为了缓解误差累积，我们引入了一种部分级联微调策略，该策略支持在计算资源受限的情况下对全长序列进行微调。这种方法减少了序列长度上的训练-测试不匹配，并显著降低了累积误差。基于所提出的技术，我们提出了一种视频压缩方案ECVC。实验表明，我们的ECVC取得了最先进的性能，在帧内周期（IP）分别为32和-1的情况下，比之前的SOTA方法DCVC-FM在VTM-13.2低延迟B（LDB）下多降低了10.5%和11.5%的码率。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [608] [U-Net Based Healthy 3D Brain Tissue Inpainting](https://arxiv.org/abs/2507.18126)
> *U-Net 基于的健康三维脑组织修复*

*Juexin Zhang, Ying Weng, Ke Chen* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** U-Net, 脑组织修复, 3D图像合成, 数据增强, BraTS

**Comment:** Accepted by the International Brain Tumor Segmentation (BraTS)
  challenge organized at MICCAI 2024 conference. Included 7 pages, 2 figures

> **TL;DR:** 本文提出了一种基于U-Net的健康三维脑组织修复方法，在ASNR-MICCAI BraTS挑战中取得了第一名。

**AI_Comments:** 这项研究的创新点在于将U-Net架构与专门的数据增强策略相结合，用于三维脑组织修复任务。其重要性在于为医学图像重建提供了一个高性能且可靠的解决方案，尤其是在处理缺失或损坏的MRI数据方面。在ASNR-MICCAI BraTS挑战中获得第一名进一步证实了其有效性和领先地位。

<details>
  <summary>Details</summary>

**Motivation:** 解决从蒙版输入图像中合成健康3D脑组织的问题，特别是针对“ASNR-MICCAI BraTS局部组织修复合成”任务。

**Method:** 采用基于U-Net的架构来重建缺失或损坏的脑部MRI扫描区域。通过随机遮蔽健康图像进行综合数据增强，以提高模型的泛化能力和鲁棒性。模型在BraTS-Local-Inpainting数据集上进行训练。

**Result:** 在BraTS-Local-Inpainting验证集上，模型在SSIM、PSNR和MSE指标上表现出色，分别达到0.841 (SSIM), 23.257 (PSNR), 0.007 (MSE)，且标准差较低，表明模型可靠和一致。该方法在挑战中获得第一名。

**Conclusion:** 该基于U-Net的方法能够有效且稳定地合成健康3D脑组织，并在相关挑战中表现卓越。

> **ai_Abstract:** 本文提出了一种新颖的基于U-Net的深度学习方法，用于从部分遮蔽的MRI图像中合成健康的三维脑组织。该方法利用U-Net架构和全面的数据增强策略来提高重建缺失区域的准确性和模型的泛化能力。在BraTS-Local-Inpainting数据集上的评估显示，该模型在SSIM、PSNR和MSE等关键指标上取得了卓越的性能和稳定性，并在相关挑战中获得第一名。

> **摘要翻译:** 本文介绍了一种从蒙版输入图像中合成健康3D脑组织的新方法，特别关注“ASNR-MICCAI BraTS局部组织修复合成”任务。我们提出的方法采用基于U-Net的架构，旨在有效重建脑部MRI扫描中缺失或损坏的区域。为了增强模型的泛化能力和鲁棒性，我们实施了一项全面的数据增强策略，包括在训练期间随机遮蔽健康图像。我们的模型在BraTS-Local-Inpainting数据集上进行训练，并在恢复健康脑组织方面表现出卓越的性能。所采用的评估指标，包括结构相似性指数（SSIM）、峰值信噪比（PSNR）和均方误差（MSE），持续产生令人印象深刻的结果。在BraTS-Local-Inpainting验证集上，我们的模型实现了0.841的SSIM分数、23.257的PSNR分数和0.007的MSE分数。值得注意的是，这些评估指标显示出相对较低的标准差，即SSIM分数为0.103，PSNR分数为4.213，MSE分数为0.007，这表明我们的模型在各种输入场景中的可靠性和一致性。我们的方法还在挑战中获得了第一名。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [609] [Physics-Informed Implicit Neural Representations for Joint B0 Estimation and Echo Planar Imaging](https://arxiv.org/abs/2503.00230)
> *物理信息隐式神经表示用于B0估计和回波平面成像*

*Wenqi Huang, Nan Wang, Congyu Liao, Yimeng Lin, Mengze Gao, Daniel Rueckert, Kawin Setsompop* | **Category: eess.IV** | **Updated: 2025-07-24**

**Keywords:** 回波平面成像, B0不均匀性, 隐式神经表示, 物理信息模型, 几何畸变校正

**Comment:** 

> **TL;DR:** 提出一种结合物理信息隐式神经表示的新方法，可同时进行B0场估计和回波平面成像的畸变校正，优于传统方法。

**AI_Comments:** 该论文的创新点在于将隐式神经表示（INRs）引入到EPI的B0场校正中，实现了B0估计和图像重建的联合优化，克服了传统分步方法的误差累积问题。INRs的连续性和适应性为处理复杂的B0不均匀性提供了新的思路，有望提高MR图像的质量和诊断价值。

<details>
  <summary>Details</summary>

**Motivation:** 回波平面成像（EPI）因B0不均匀性导致严重几何畸变，尤其是在相位编码方向。现有方法分两步进行，易导致误差累积，降低校正精度，在高B0区域问题尤为突出。

**Method:** 提出一种新方法，将隐式神经表示（INRs）与物理信息校正模型相结合，从旋转视图EPI采集数据中联合估计B0不均匀性并重建无畸变图像。INRs提供灵活连续的表示，无需预定义网格场图，能动态适应受试者特异性B0变化。

**Result:** 在来自三名受试者的180个脑部图像切片上的实验结果表明，该方法在重建质量和场估计精度方面优于传统方法。

**Conclusion:** 该方法通过联合估计B0场和图像重建，有效解决了EPI的几何畸变问题，并提高了校正精度和鲁棒性。

> **ai_Abstract:** 本文提出一种将隐式神经表示（INRs）与物理信息校正模型结合的新方法，用于解决回波平面成像（EPI）中由B0不均匀性引起的几何畸变问题。与传统的分步方法不同，该方法能够从旋转视图EPI采集数据中联合估计B0场并重建无畸变图像。INRs的连续表示特性使其能灵活适应个体B0变化，提高鲁棒性。实验证明，该方法在重建质量和场估计精度方面均优于现有方法。

> **摘要翻译:** 回波平面成像（EPI）因其快速采集而被广泛使用，但由于B0不均匀性，特别是沿着相位编码方向，会遭受严重的几何畸变。现有方法遵循两步过程：重建blip-up/down EPI图像，然后估计B0，这会引入误差累积并降低校正精度。这在高B0区域尤其成问题，因为畸变沿着同一轴线对齐，使其更难分离。在这项工作中，我们提出了一种新颖的方法，将隐式神经表示（INRs）与物理信息校正模型相结合，以联合估计B0不均匀性并从旋转视图EPI采集数据中重建无畸变图像。INRs提供了一种灵活、连续的表示，固有地捕捉复杂的空间变化，无需预定义基于网格的场图。通过利用这一特性，我们的方法动态适应受试者特异性B0变化，并提高了在不同成像条件下的鲁棒性。在来自三名受试者的180个脑部图像切片上的实验结果表明，我们的方法在重建质量和场估计精度方面优于传统方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [656] [Deep Learning for Glioblastoma Morpho-pathological Features Identification: A BraTS-Pathology Challenge Solution](https://arxiv.org/abs/2507.18133)
> *深度学习在胶质母细胞瘤形态病理特征识别中的应用：一项BraTS-Pathology挑战赛解决方案*

*Juexin Zhang, Ying Weng, Ke Chen* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 胶质母细胞瘤, 深度学习, BraTS-Path挑战赛, 形态病理特征, 脑肿瘤

**Comment:** Accepted by the International Brain Tumor Segmentation (BraTS)
  challenge organized at MICCAI 2024 conference

> **TL;DR:** 用于胶质母细胞瘤诊断的深度学习模型表现参半，但在挑战赛中获得第二名。

**AI_Comments:** 该论文展示了深度学习在解决胶质母细胞瘤诊断这一实际挑战中的应用。尽管在验证集上的一些绝对性能指标（如准确率、F1-score）较低，但模型的高特异性是一大亮点，表明其在排除非目标病例方面的强大能力。更重要的是，在竞争激烈的挑战赛中获得第二名，这表明该方案在与其他参赛者相比具有相对优势和实用价值，尽管其绝对性能仍有提升空间。这种结果的矛盾性可能反映了挑战赛的评估标准或模型在特定任务上的优势。

<details>
  <summary>Details</summary>

**Motivation:** 胶质母细胞瘤（一种高度侵袭性的脑肿瘤）由于其异质性，诊断面临挑战。准确诊断和评估这种异质性对于选择正确的治疗方案和改善患者预后至关重要。传统的诊断方法依赖于组织样本中特定特征的识别，而深度学习为改进胶质母细胞瘤诊断提供了一种有前景的方法。

**Method:** 本研究提出了参加BraTS-Path Challenge 2024的解决方案，利用一个预训练模型并在BraTS-Path训练数据集上进行微调。

**Result:** 该模型在BraTS-Path验证集上表现一般，准确率、召回率和F1-score均为0.392229，但特异性高达0.898704，表明其在正确分类阴性病例方面表现出色。Matthews相关系数（MCC）为0.255267。值得注意的是，该解决方案在测试阶段获得了第二名。

**Conclusion:** 尽管模型在验证集上的绝对性能指标（如准确率、召回率、F1-score）表现一般，但其在分类阴性病例方面具有出色的特异性，并且在BraTS-Path Challenge 2024的测试阶段获得了第二名，显示出其在竞争环境下的相对优势和潜力。

> **ai_Abstract:** 本论文介绍了为BraTS-Path Challenge 2024开发的深度学习解决方案，旨在识别胶质母细胞瘤的形态病理特征。该方法利用预训练模型并在BraTS-Path训练数据集上进行微调。尽管模型在验证集上的准确率、召回率和F1-score均约为0.39，但其特异性高达0.89，并且在挑战赛的测试阶段获得了第二名。

> **摘要翻译:** 胶质母细胞瘤是一种高度侵袭性的脑肿瘤，具有多样的分子和病理特征，其异质性给诊断带来了挑战。准确诊断和评估这种异质性对于选择正确的治疗方案和改善患者预后至关重要。传统方法依赖于识别组织样本中的特定特征，但深度学习为改进胶质母细胞瘤诊断提供了一种有前景的方法。在本文中，我们介绍了我们参加BraTS-Path Challenge 2024的方法。我们利用一个预训练模型并在BraTS-Path训练数据集上进行微调。我们的模型在具有挑战性的BraTS-Path验证集上表现不佳，正如Synapse在线平台严格评估的那样。该模型获得了0.392229的准确率、0.392229的召回率和0.392229的F1-score，这表明在目标条件下正确识别实例的能力一致。值得注意的是，我们的模型表现出0.898704的完美特异性，显示出正确分类阴性病例的卓越能力。此外，计算出的Matthews相关系数（MCC）为0.255267，表示预测值与实际值之间存在有限的正相关，并突出了我们模型的整体预测能力。我们的解决方案在测试阶段也获得了第二名。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [657] [Tackling Hallucination from Conditional Models for Medical Image Reconstruction with DynamicDPS](https://arxiv.org/abs/2503.01075)
> *使用 DynamicDPS 解决医用图像重建中条件模型产生的伪影*

*Seunghoi Kim, Henry F. J. Tregidgo, Matteo Figini, Chen Jin, Sarang Joshi, Daniel C. Alexander* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 伪影, 医学图像重建, 扩散模型, DynamicDPS, 图像质量转换

**Comment:** 

> **TL;DR:** DynamicDPS是一个基于扩散模型的框架，通过结合条件和无条件扩散模型来减少医学图像重建中的伪影，同时显著提高效率和图像质量。

**AI_Comments:** DynamicDPS的创新之处在于其结合条件和无条件扩散模型来解决医学图像重建中的伪影问题，并通过自适应采样策略显著提升了效率，实现了高质量的图像重建。其模型无关和无需微调的特性使其具有广泛的应用潜力，对于临床实践具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 伪影是医学图像重建中的一个关键挑战，尤其对于数据驱动的条件模型而言，它们会产生地面真实中不存在的虚假结构。

**Method:** 本文提出了DynamicDPS，一个结合条件和无条件扩散模型的扩散框架。它首先使用条件模型生成初始重建，然后通过自适应的基于扩散的逆问题求解器进行细化。DynamicDPS通过为每个样本选择最佳起始时间点来跳过逆向过程的早期阶段，并应用Wolfe线搜索来自适应步长，以提高效率和图像保真度。该方法利用扩散先验和数据一致性来减少任何条件模型输出中的伪影。

**Result:** 在低场MRI增强的图像质量转换中，DynamicDPS被验证有效。在合成和真实MR扫描以及组织体积估计的下游任务中，DynamicDPS减少了伪影，使关键组织的相对体积估计提高了15%以上，同时仅使用了基线扩散模型所需采样步骤的5%。

**Conclusion:** DynamicDPS作为一种模型无关且无需微调的方法，为医学成像中的伪影减少提供了一个鲁棒的解决方案。

> **ai_Abstract:** 本文提出了DynamicDPS，一个创新的扩散框架，旨在解决医学图像重建中条件模型产生的伪影问题。该方法结合了条件和无条件扩散模型，通过先生成初始重建再进行自适应细化的方式，有效减少了伪影。DynamicDPS通过优化采样步骤和步长，显著提高了效率和图像保真度。实验证明，它能有效减少伪影，提高关键组织体积估计的准确性，并且比现有方法更高效，同时具有模型无关和无需微调的优点。

> **摘要翻译:** 幻觉是地面真实中不存在的虚假结构，在医学图像重建中，特别是对于数据驱动的条件模型，构成了严峻的挑战。我们假设将无条件扩散模型与在多样化数据集上训练的数据一致性相结合，可以减少这些幻觉。在此基础上，我们提出了DynamicDPS，一个基于扩散的框架，它集成了条件和无条件扩散模型，以增强低质量医学图像，同时系统地减少幻觉。我们的方法首先使用条件模型生成初始重建，然后使用自适应的基于扩散的逆问题求解器对其进行细化。DynamicDPS通过为每个样本选择最佳起始时间点来跳过逆向过程的早期阶段，并应用Wolfe线搜索来自适应步长，从而提高效率和图像保真度。利用扩散先验和数据一致性，我们的方法有效减少了任何条件模型输出中的幻觉。我们在低场MRI增强的图像质量转换中验证了其有效性。对合成和真实MR扫描（包括用于组织体积估计的下游任务）的广泛评估表明，DynamicDPS减少了幻觉，使关键组织的相对体积估计提高了15%以上，同时仅使用了基线扩散模型所需采样步骤的5%。作为一种模型无关且无需微调的方法，DynamicDPS为医学成像中的幻觉减少提供了一个鲁棒的解决方案。代码将在发布后公开提供。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [705] [L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation](https://arxiv.org/abs/2503.05245)
> *L-FUSION：拉普拉斯胎儿超声分割与不确定性估计*

*Johanna P. Müller, Robert Wright, Thomas G. Day, Lorenzo Venturini, Samuel F. Budd, Hadrien Reynaud, Joseph V. Hajnal, Reza Razavi, Bernhard Kainz* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 胎儿超声分割, 不确定性估计, 基础模型, 拉普拉斯近似, 异常检测

**Comment:** Accepted at MICCAI ASMUS 2025

> **TL;DR:** L-FUSION是一个结合了无监督学习和大型基础模型的框架，用于在胎儿超声图像中实现鲁棒的结构分割和不确定性估计，旨在提高异常检测的准确性和诊断反馈的速度。

**AI_Comments:** L-FUSION的创新之处在于其将不确定性量化与胎儿超声分割相结合，特别是在不依赖手动疾病标记的情况下实现异常量化。这对于提高诊断效率和准确性具有重要意义，并且通过利用基础模型和拉普拉斯近似，展示了在医疗图像分析领域结合先进AI技术的潜力。其提供可扩展解决方案的特点也使其在临床应用中具有广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 产前超声的准确分析对于早期发现发育异常至关重要。然而，操作员依赖性、技术限制（如固有伪影、设置错误）以及图像解释和诊断不确定性评估的复杂性，阻碍了这一过程。

**Method:** 本文提出了L-FUSION框架，它通过无监督的规范学习和大规模基础模型整合不确定性量化。它利用随机分割网络的偶然逻辑分布和带有快速Hessian估计的拉普拉斯近似，仅从分割头部估计认知不确定性。结合集成的Dropout组件，L-FUSION能够通过增强的不确定性图和分割反事实来区分病变与正常胎儿解剖结构。

**Result:** L-FUSION在多个数据集上的评估显示，它实现了卓越的分割精度和一致的不确定性量化。它提高了认知和偶然不确定性的解释，并且无需手动标记疾病。

**Conclusion:** L-FUSION提供了一种可扩展的解决方案，用于推进临床环境中的胎儿超声分析，支持现场决策，并能够可靠地量化异常，实现即时诊断反馈。

> **ai_Abstract:** L-FUSION是一个创新的框架，旨在解决胎儿超声图像分析中的不确定性问题，提高异常检测的准确性。它通过整合无监督学习、大型基础模型以及利用随机分割网络的偶然逻辑分布和拉普拉斯近似来量化不确定性，从而实现对胎儿结构的鲁棒分割。该方法能够区分病变与正常解剖结构，并提供增强的不确定性图，无需手动疾病标记。实验证明L-FUSION在分割精度和不确定性量化方面表现优异，为临床决策提供了可靠支持。

> **摘要翻译:** 产前超声（US）的准确分析对于早期发现发育异常至关重要。然而，操作员依赖性和技术限制（例如固有伪影和效应、设置错误）可能会使图像解释和诊断不确定性评估复杂化。我们提出了L-FUSION（带有集成基础模型的拉普拉斯胎儿超声分割），这是一个通过无监督、规范学习和大规模基础模型整合不确定性量化的框架，用于在正常和病理扫描中鲁棒地分割胎儿结构。我们建议利用随机分割网络的偶然逻辑分布和带有快速Hessian估计的拉普拉斯近似，仅从分割头部估计认知不确定性。这使我们能够实现可靠的异常量化，以实现即时诊断反馈。结合集成的Dropout组件，L-FUSION能够在超声成像中通过增强的不确定性图和分割反事实，可靠地区分病变与正常胎儿解剖结构。它改善了认知和偶然不确定性解释，并消除了手动疾病标记的需要。在多个数据集上的评估表明，L-FUSION实现了卓越的分割精度和一致的不确定性量化，支持现场决策，并为推进临床环境中的胎儿超声分析提供了可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [724] [Towards Robust Foundation Models for Digital Pathology](https://arxiv.org/abs/2507.17845)
> *迈向数字病理学领域的鲁棒基础模型*

*Jonah Kömen, Edwin D. de Jong, Julius Hense, Hannah Marienwald, Jonas Dippel, Philip Naumann, Eric Marcus, Lukas Ruff, Maximilian Alber, Jonas Teuwen, Frederick Klauschen, Klaus-Robert Müller* | **Category: eess.IV, cs.AI, cs.CV, cs.LG, q-bio.QM** | **Updated: 2025-07-22**

**Keywords:** 鲁棒性, 基础模型, 数字病理学, PathoROB, 生物医学AI

**Comment:** 

> **TL;DR:** 生物医学基础模型易受非生物技术特征影响，本研究首次系统性调查病理学基础模型的鲁棒性，提出PathoROB基准，揭示所有评估模型均存在鲁棒性缺陷，并强调鲁棒性评估对临床部署至关重要。

**AI_Comments:** 该论文创新性地首次系统性地研究了病理学基础模型在临床应用中面临的关键鲁棒性问题，特别关注了非生物技术特征的影响。其提出的PathoROB基准和新颖指标为评估和提升基础模型的鲁棒性提供了具体工具和蓝图，对推动AI在数字病理学领域的安全和有效应用具有重要意义。论文揭示了当前基础模型的普遍鲁棒性缺陷，并强调了鲁棒性评估的必要性，这对于指导未来基础模型的设计和开发具有深远的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学基础模型在医疗健康领域迅速发展，但它们容易学习非生物技术特征（如手术技术、实验室流程、扫描仪硬件的变化），这给临床部署带来了风险。本研究旨在解决病理学基础模型的鲁棒性问题。

**Method:** 本研究首次系统性调查病理学基础模型对非生物特征的鲁棒性。工作内容包括：(i) 引入量化基础模型鲁棒性的度量方法；(ii) 证明有限鲁棒性的后果；(iii) 提出一个用于基础模型鲁棒化的框架以缓解这些问题。具体开发了PathoROB，一个包含三个新颖指标（包括鲁棒性指数）和四个数据集（涵盖来自34个医疗中心的28个生物学类别）的鲁棒性基准。实验评估了20个基础模型。

**Result:** 实验结果显示，所有20个被评估的基础模型都存在鲁棒性缺陷，且它们之间存在显著的鲁棒性差异。研究发现，不鲁棒的基础模型表征可能导致严重的诊断下游错误和临床失误，从而阻碍安全临床应用。使用更鲁棒的基础模型和事后鲁棒化方法显著降低（但尚未完全消除）了此类错误的风险。

**Conclusion:** 本研究确立了鲁棒性评估对于病理学基础模型在临床应用前进行验证的必要性，并表明未来的基础模型开发必须将鲁棒性作为核心设计原则。PathoROB为生物医学领域评估鲁棒性提供了蓝图，指导基础模型改进工作，以构建更鲁棒、更具代表性且临床可部署的AI系统，优先考虑生物学信息而非技术伪影。

> **ai_Abstract:** 本研究首次系统性地探讨了数字病理学基础模型对非生物技术特征的鲁棒性问题。研究引入了量化鲁棒性的新度量，并开发了PathoROB基准，包含新颖指标和多中心数据集。实验结果显示，所有测试的基础模型均存在鲁棒性缺陷，这可能导致严重的临床诊断错误。论文强调鲁棒性评估对于基础模型安全临床部署的重要性，并呼吁将鲁棒性作为未来基础模型设计的核心原则。

> **摘要翻译:** 生物医学基础模型（FMs）正在迅速改变人工智能赋能的医疗健康研究，并进入临床验证阶段。然而，它们容易学习非生物技术特征——包括手术/内窥镜技术、实验室程序和扫描仪硬件的变化——这给临床部署带来了风险。我们首次系统性地调查了病理学基础模型对非生物特征的鲁棒性。我们的工作（i）引入了量化基础模型鲁棒性的度量方法，（ii）证明了有限鲁棒性的后果，以及（iii）提出了一个用于基础模型鲁棒化的框架以缓解这些问题。具体来说，我们开发了PathoROB，这是一个鲁棒性基准，包含三个新颖指标，其中包括鲁棒性指数，以及涵盖来自34个医疗中心的28个生物学类别的四个数据集。我们的实验揭示了所有20个被评估的基础模型都存在鲁棒性缺陷，并且它们之间存在显著的鲁棒性差异。我们发现，不鲁棒的基础模型表征可能导致重大的诊断下游错误和临床失误，从而阻碍安全的临床应用。使用更鲁棒的基础模型和事后鲁棒化方法显著降低（但尚未完全消除）了此类错误的风险。这项工作确立了鲁棒性评估对于病理学基础模型在临床应用前进行验证的必要性，并表明未来的基础模型开发必须将鲁棒性作为核心设计原则。PathoROB为生物医学领域评估鲁棒性提供了蓝图，指导基础模型改进工作，以构建更鲁棒、更具代表性且临床可部署的AI系统，优先考虑生物学信息而非技术伪影。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [10] [Segmentation-free Goodness of Pronunciation](https://arxiv.org/abs/2507.16838)
> *免分割发音优度*

*Xinwei Cao, Zijian Fan, Torbjørn Svendsen, Giampiero Salvi* | **Category: eess.AS, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 发音优度, 免分割, CTC, 发音错误检测, 音素评估

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文提出两种免分割的发音优度（GOP）方法（GOP-SA和GOP-AF），用于纠正发音检测和诊断，尤其GOP-AF在音素级别发音评估上达到了最先进水平。

**AI_Comments:** 本文的主要创新在于提出了两种免分割的发音优度（GOP）评估方法，特别是GOP-AF，它克服了传统GOP对语音预分割的依赖，并能有效利用现代CTC训练的声学模型。这对于计算机辅助语言学习中的发音错误检测与诊断具有重要意义，提升了评估的准确性和实用性，达到了音素级别发音评估的最新水平。其理论推导和数值稳定性处理也增强了方法的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的发音优度（GOP）系统通常需要将语音预先分割成音素单元，这限制了其准确性，并阻碍了使用基于CTC的现代声学模型进行评估。为了解决这一限制，本文旨在开发无需预分割的GOP方法。

**Method:** 本文首先提出了自对齐发音优度（GOP-SA），它允许将CTC训练的ASR模型用于发音错误检测与诊断（MDD）。接着，定义了一种更通用的免对齐方法，即发音优度-免对齐（GOP-AF），该方法考虑了目标音素的所有可能对齐方式。作者提供了GOP-AF的理论解释、解决了潜在数值问题的实现以及适当的归一化，使其适用于不同峰度随时间变化的声学模型。

**Result:** 在CMU Kids和Speechocean762数据集上进行了广泛的实验。结果显示，提出的GOP-AF方法在音素级别发音评估方面，其派生的特征向量达到了最先进的性能。实验还比较了不同方法的定义，并评估了GOP-AF对声学模型峰度以及目标音素周围上下文数量的依赖性。

**Conclusion:** 本文提出的免分割发音优度方法，特别是GOP-AF，在音素级别发音评估中取得了最先进的成果，有效解决了传统GOP方法对预分割的依赖性，并能更好地利用现代CTC声学模型。

> **ai_Abstract:** 本文针对计算机辅助语言学习中发音错误检测与诊断的挑战，提出了一种免分割的发音优度（GOP）评估方法。传统GOP依赖于预分割语音单元，限制了准确性和CTC模型的使用。为此，研究引入了两种新方法：自对齐GOP（GOP-SA），支持CTC训练的ASR模型；以及更通用的免对齐GOP（GOP-AF），考虑所有可能对齐并解决数值问题，同时进行了归一化处理。实验结果表明，GOP-AF在音素级别发音评估上取得了最先进的性能，有效提升了发音诊断的准确性和模型适用性。

> **摘要翻译:** 发音错误检测和诊断（MDD）是现代计算机辅助语言学习（CALL）系统的重要组成部分。在MDD中，音素级别的发音评估是帮助二语学习者提高发音的关键。然而，大多数系统都基于一种需要将语音预分割成音素单元的发音优度（GOP）形式。这限制了这些方法的准确性以及使用现代基于CTC的声学模型进行评估的可能性。在这项研究中，我们首先提出了自对齐GOP（GOP-SA），它使得CTC训练的ASR模型能够用于MDD。接下来，我们定义了一种更通用的免对齐方法，该方法考虑了目标音素的所有可能对齐（GOP-AF）。我们对GOP-AF的定义进行了理论说明，并提供了一个解决潜在数值问题的实现以及适当的归一化，这使得该方法适用于具有不同时间峰度的声学模型。我们在CMU Kids和Speechocean762数据集上提供了广泛的实验结果，比较了我们方法的不同定义，评估了GOP-AF对声学模型峰度以及目标音素周围上下文数量的依赖性。最后，我们将我们的方法与Speechocean762数据上的最新研究进行了比较，结果表明，从所提出的方法导出的特征向量在音素级别的发音评估方面取得了最先进的成果。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [285] [A Concept-based approach to Voice Disorder Detection](https://arxiv.org/abs/2507.17799)
> *语音障碍检测中的概念化方法*

*Davide Ghia, Gabriele Ciravegna, Alkis Koudounas, Marco Fantini, Erika Crosetti, Giovanni Succo, Tania Cerquitelli* | **Category: eess.AS, cs.LG, cs.SD** | **Updated: 2025-07-23**

**Keywords:** 语音障碍检测, 可解释AI, 概念型模型, 深度学习, 临床可信度

**Comment:** 

> **TL;DR:** 本文探讨使用可解释AI（XAI）中的概念模型（如CBM和CEM）进行语音障碍检测，旨在提高AI诊断的透明度和可信度，同时保持与传统深度学习相当的性能。

**AI_Comments:** 本文的创新点在于将可解释AI（XAI）的概念型模型应用于医疗诊断领域，特别是语音障碍检测。这对于解决深度学习模型在临床应用中“黑箱”问题至关重要，有望显著提升AI诊断的可信度和采纳度。如果能成功证明其性能可比性，将对AI在医疗领域的实际落地产生积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 语音障碍影响大量人口，自动化诊断是医疗保健的重大进步。然而，现有深度神经网络（DNNs）模型决策过程不透明，限制了其在临床环境中的可信度。

**Method:** 本文研究了一种基于可解释AI (XAI) 的替代方法，特别是关注概念型模型，如概念瓶颈模型 (CBM) 和概念嵌入模型 (CEM)。

**Result:** 论文旨在展示概念型模型（如CBM和CEM）如何在提供更透明和可解释的决策框架的同时，实现与传统深度学习方法相当的性能。

**Conclusion:** 概念型模型为语音障碍检测提供了一种有前景的解决方案，它在保持诊断性能的同时，显著提高了AI模型的透明度和可解释性，从而增强了其在临床应用中的可信度。

> **ai_Abstract:** 本文探讨了一种基于可解释AI（XAI）的概念型方法来检测语音障碍。鉴于传统深度神经网络（DNNs）在临床应用中因决策不透明而缺乏可信度，本研究重点考察概念瓶颈模型（CBM）和概念嵌入模型（CEM）如何能在提供与传统深度学习相当性能的同时，提供更透明和可解释的决策框架，以期提高自动化诊断的可信度。

> **摘要翻译:** 语音障碍影响着相当一部分人口，而使用自动化、非侵入性技术对其进行诊断将代表医疗保健领域的重大进步，从而改善患者的生活质量。最近的研究表明，人工智能模型，特别是深度神经网络（DNNs），可以有效地解决这项任务。然而，由于其复杂性，此类模型的决策过程往往不透明，限制了它们在临床环境中的可信度。本文研究了一种基于可解释AI（XAI）的替代方法，XAI是一个旨在通过提供不同形式的解释来提高DNNs可解释性的领域。具体而言，这项工作侧重于概念型模型，如概念瓶颈模型（CBM）和概念嵌入模型（CEM），以及它们如何在提供更透明和可解释的决策框架的同时，实现与传统深度学习方法相当的性能。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [320] [Recent Trends in Distant Conversational Speech Recognition: A Review of CHiME-7 and 8 DASR Challenges](https://arxiv.org/abs/2507.18161)
> *远距离会话语音识别的最新趋势：CHiME-7 和 8 DASR 挑战回顾*

*Samuele Cornell, Christoph Boeddeker, Taejin Park, He Huang, Desh Raj, Matthew Wiesner, Yoshiki Masuyama, Xuankai Chang, Zhong-Qiu Wang, Stefano Squartini, Paola Garcia, Shinji Watanabe* | **Category: eess.AS, cs.CL, cs.SD** | **Updated: 2025-07-24**

**Keywords:** 远距离语音识别, CHiME 挑战, 端到端 ASR, 说话人区分, 语音分离, 大型语言模型

**Comment:** 

> **TL;DR:** 回顾了 CHiME-7 和 8 远距离会话语音识别挑战，分析了参赛系统的主要趋势，发现端到端系统普及、神经语音分离仍有限制、目标说话人区分技术重要以及大型语言模型对转录错误的处理能力。

**AI_Comments:** 这篇论文通过对 CHiME-7 和 8 DASR 挑战的全面回顾，提供了远距离会话语音识别领域当前研究趋势的宝贵见解。其创新之处在于系统地分析了大量参赛系统，揭示了从混合系统到端到端 ASR 的转变，并强调了神经语音分离的局限性以及说话人区分细化的关键作用。论文还提出了大型语言模型对下游任务中转录错误处理能力的有趣观察，这可能对未来 ASR 系统的评估和应用产生影响。局限性在于，它主要是一个回顾性分析，并未提出新的方法，但其对现有技术瓶颈和未来研究方向的洞察力非常重要。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在概述 CHiME-7 和 8 远距离语音识别 (DASR) 挑战的设计、评估指标、数据集和基线系统，并分析参赛提交的关键趋势，以促进该领域的最新研究。

**Method:** 论文通过分析 CHiME-7 和 8 DASR 挑战中 9 支团队提交的 32 个系统，总结了主要趋势，包括端到端 ASR 系统的使用、神经语音分离/增强技术的应用、说话人区分技术的重要性以及下游评估与转录质量的相关性。

**Result:** 1. 大多数参与者使用端到端 (e2e) ASR 系统，而非混合系统，这主要得益于鲁棒的大规模预训练模型。
2. 尽管神经语音分离和增强 (SSE) 有进展，但所有团队仍严重依赖引导源分离，表明当前神经 SSE 仍难以处理复杂场景。
3. 所有最佳系统都通过目标说话人区分技术进行说话人区分细化，准确的说话人计数至关重要。
4. 通过会议摘要进行的下游评估可能与转录质量相关性较弱，因为大型语言模型能有效处理错误。
5. 即使使用计算密集型系统集成，在挑战性声学环境中准确转录自发语音仍然困难。

**Conclusion:** 尽管在远距离会话语音识别方面取得了进展，但准确转录复杂声学环境中的自发语音仍然是一个挑战，并且大型语言模型在处理下游任务中的转录错误方面表现出显著的有效性。

> **ai_Abstract:** 本文回顾了 CHiME-7 和 8 远距离会话语音识别 (DASR) 挑战，这些挑战旨在推动多通道、可泛化、联合 ASR 和说话人区分的研究。通过分析 9 支团队提交的 32 个系统，论文揭示了该领域的最新趋势，包括端到端 ASR 系统的普及、神经语音分离技术的局限性、说话人区分细化（尤其是准确的说话人计数）的重要性，以及大型语言模型在下游任务中处理转录错误的有效性。研究指出，尽管取得了进展，但在复杂声学环境下准确转录自发语音仍是一大挑战。

> **摘要翻译:** CHiME-7 和 8 远距离语音识别 (DASR) 挑战侧重于多通道、可泛化、会话语音的联合自动语音识别 (ASR) 和说话人区分。9 支团队提交了 32 个不同的系统，这些挑战为该领域的最新研究做出了贡献。本文概述了挑战的设计、评估指标、数据集和基线系统，同时分析了参赛提交的关键趋势。从这项分析中得出：1) 大多数参与者使用端到端 (e2e) ASR 系统，而混合系统在之前的 CHiME 挑战中很普遍。这种转变主要是由于鲁棒的大规模预训练模型的可用性，这降低了 e2e-ASR 的数据负担。2) 尽管神经语音分离和增强 (SSE) 最近取得了进展，但所有团队仍然严重依赖引导源分离，这表明当前的神经 SSE 技术仍然无法可靠地处理复杂场景和不同的录音设置。3) 所有最佳系统都通过目标说话人区分技术进行说话人区分细化。因此，在第一次说话人区分通过中准确的说话人计数对于避免复合错误至关重要，CHiME-8 DASR 参与者尤其关注这一部分。4) 通过会议摘要进行的下游评估可能与转录质量相关性较弱，因为大型语言模型在处理错误方面具有卓越的有效性。在 NOTSOFAR-1 场景中，即使系统的时间约束最小置换词错误率超过 50%，其性能也能与最有效的系统（约 11%）大致持平。5) 尽管最近取得了进展，但在具有挑战性的声学环境中准确转录自发语音仍然很困难，即使使用计算密集型系统集成也是如此。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [357] [SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding](https://arxiv.org/abs/2507.18181)
> *SpecASR：通过推测解码加速基于LLM的自动语音识别*

*Linye Wei, Shuzhang Zhong, Songqiang Xu, Runsheng Wang, Ru Huang, Meng Li* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-24**

**Keywords:** 自动语音识别, 推测解码, 大型语言模型, 实时ASR, 解码加速

**Comment:** 

> **TL;DR:** SpecASR提出了一种新的推测解码框架，专门用于加速基于LLM的ASR，通过利用音频条件特性、自适应草稿序列生成、草稿序列回收和两阶段稀疏令牌树生成，实现了显著的解码速度提升，同时不损失识别精度。

**AI_Comments:** SpecASR的创新之处在于其专门针对ASR任务的特性（音频条件性）设计了推测解码框架，这使其能够比通用推测解码方法取得更好的加速效果。提出的自适应草稿序列生成、草稿序列回收和两阶段稀疏令牌树生成算法都是针对ASR场景的优化，有效地解决了LLM在ASR中高延迟的挑战，对于推动实时LLM-ASR应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于大型语言模型（LLM）的自动语音识别（ASR）虽然识别精度高且支持多方言，但其高解码延迟阻碍了实时ASR应用。现有的推测解码方法未能充分利用ASR任务的特性，加速效果有限。

**Method:** 本文提出了一种名为SpecASR的ASR专用推测解码框架。SpecASR基于ASR解码是音频条件这一核心观察，即使中间解码步骤出现不匹配，也能实现小型和大型ASR模型之间的高输出对齐。其主要特点包括：1. 自适应草稿序列生成过程，动态修改草稿序列长度以最大化令牌接受长度。2. 草稿序列回收策略，重用之前生成的草稿序列以减少草稿ASR模型的延迟。3. 两阶段稀疏令牌树生成算法，用于平衡草稿和目标ASR模型的延迟。

**Result:** SpecASR在不损失识别精度的情况下，相对于基线自回归解码实现了3.04倍至3.79倍的加速，相对于推测解码实现了1.25倍至1.84倍的加速。

**Conclusion:** SpecASR通过专门为ASR任务设计的推测解码框架，显著降低了基于LLM的ASR的实时解码延迟，并在不牺牲识别准确性的前提下取得了显著的加速效果。

> **ai_Abstract:** 本文提出了一种名为SpecASR的新型推测解码框架，旨在加速基于LLM的自动语音识别（ASR）的实时解码延迟。SpecASR利用ASR解码的音频条件特性，通过自适应草稿序列生成、草稿序列回收策略和两阶段稀疏令牌树生成算法，显著提高了解码效率。实验结果表明，SpecASR在不损失识别精度的情况下，比传统的自回归解码和现有推测解码方法有显著的速度提升。

> **摘要翻译:** 大型语言模型（LLM）驱动的自动语音识别（ASR）最近因其高识别精度和增强的多方言支持而备受关注。然而，LLM的高解码延迟对实时ASR需求构成了挑战。尽管推测解码已被探索以提高解码效率，但它们通常忽略了ASR任务的关键特性，并取得了有限的加速效果。为了进一步降低实时ASR延迟，本文提出了一种专门用于ASR的新型推测解码框架，名为SpecASR。SpecASR基于我们的核心观察结果开发，即ASR解码是音频条件下的，即使在中间解码步骤中出现输出不匹配，也能导致小型和大型ASR模型之间的高度输出对齐。因此，SpecASR的特点是自适应草稿序列生成过程，该过程动态修改草稿序列长度以最大化令牌接受长度。SpecASR进一步提出了一种草稿序列回收策略，该策略重复使用先前生成的草稿序列以减少草稿ASR模型的延迟。此外，还提出了一种两阶段稀疏令牌树生成算法，以平衡草稿和目标ASR模型的延迟。通过广泛的实验结果，我们证明SpecASR相对于基线自回归解码实现了3.04倍至3.79倍的加速，相对于推测解码实现了1.25倍至1.84倍的加速，且没有任何识别精度损失。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [399] [Speech Enhancement with Dual-path Multi-Channel Linear Prediction Filter and Multi-norm Beamforming](https://arxiv.org/abs/2507.18350)
> *基于双路径多通道线性预测滤波器和多范数波束形成的语音增强*

*Chengyuan Qin, Wenmeng Xiong, Jing Zhou, Maoshen Jia, Changchun Bao* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-24**

**Keywords:** 语音增强, 多通道线性预测, 多范数波束形成, 混响, 双路径

**Comment:** Paper accepted by Interspeech 2025

> **TL;DR:** 本文提出了一种结合双路径多通道线性预测（MCLP）滤波器和多范数波束形成的语音增强方法，在高混响场景中表现优于基线方法。

**AI_Comments:** 该论文的创新点在于将双路径MCLP滤波器与多范数波束形成相结合，有效解决了高混响环境下的语音增强难题。提出的鲁棒性预测阶数选择方法是一项重要贡献，有望应用于其他基于MCLP的系统。其在高混响场景中的优越性能是该方法的重要优势。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种有效的语音增强方法，以提高语音质量，尤其是在高混响等挑战性环境中。

**Method:** 该方法结合了双路径多通道线性预测（MCLP）滤波器（在时间和频率维度上设计）和多范数波束形成。波束形成部分通过最小化麦克风阵列输出功率和去噪信号的L1范数来工作，同时保留目标源信号。此外，还提出了一种高效且鲁棒的预测阶数选择方法。

**Result:** 评估表明，所提出的方法在语音增强方面优于基线方法，特别是在高混响场景中。

**Conclusion:** 本文提出的基于双路径MCLP滤波器和多范数波束形成的语音增强方法能够有效提升语音质量，尤其是在高混响环境下表现出色。所提出的预测阶数选择方法也增强了其鲁棒性和适用性。

> **ai_Abstract:** 本文介绍了一种新颖的语音增强技术，该技术结合了在时域和频域设计的双路径多通道线性预测（MCLP）滤波器和多范数波束形成。其中，波束形成组件旨在最小化输出功率和去噪信号的L1范数，同时保留目标源。文中还提出了一种高效且鲁棒的预测阶数选择方法。实验结果表明，该方法超越了现有基线方法，特别是在高混响条件下表现更佳。

> **摘要翻译:** 本文提出了一种利用双路径多通道线性预测（MCLP）滤波器和多范数波束形成的语音增强方法。具体而言，所提出的方法中的MCLP部分设计有时间和频率维度上的双路径滤波器。对于波束形成部分，我们最小化麦克风阵列输出的功率以及去噪信号的L1范数，同时保留来自目标方向的源信号。文中还提出了一种选择双路径滤波器中预测阶数的有效方法，该方法对于具有不同混响时间（T60）值的信号具有鲁棒性，并且可以应用于其他基于MCLP的方法。评估表明，我们提出的方法在语音增强方面优于基线方法，特别是在高混响场景中。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [441] [Streaming Sortformer: Speaker Cache-Based Online Speaker Diarization with Arrival-Time Ordering](https://arxiv.org/abs/2507.18446)
> *流式Sortformer：基于说话人缓存和到达时间排序的在线说话人分离*

*Ivan Medennikov, Taejin Park, Weiqing Wang, He Huang, Kunal Dhawan, Jinhan Wang, Jagadeesh Balam, Boris Ginsburg* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-24**

**Keywords:** 说话人分离, 流式处理, Sortformer, 说话人缓存, 实时处理

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 本文提出了流式Sortformer，一个基于到达时间排序的在线说话人分离框架，通过到达顺序说话人缓存(AOSC)有效跟踪说话人，并在低延迟设置下表现出色。

**AI_Comments:** 这项工作在Sortformer框架的基础上进行了流式扩展，通过引入“到达顺序说话人缓存 (AOSC)”实现了高效和精确的在线说话人分离。其创新点在于AOSC的到达时间排序机制以及动态更新策略，这对于实时多说话人语音处理具有重要意义，尤其是在低延迟场景下展现了其鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现多说话人语音处理的实时性，需要一个能够在线且高效地进行说话人分离的框架。

**Method:** 该方法提出了一个流式扩展的Sortformer框架，其核心是“到达顺序说话人缓存 (AOSC)”。AOSC存储先前观察到的说话人的帧级声学嵌入，并根据说话人的到达时间顺序进行索引。它通过模型过去的预测，动态选择具有最高分数的帧来更新，并且每个说话人存储的嵌入数量也是动态确定的，以确保高效的缓存利用和精确的说话人跟踪。

**Result:** 在基准数据集上的实验证实了该方法的有效性和灵活性，即使在低延迟设置下也能表现良好。

**Conclusion:** 流式Sortformer被确立为一种用于实时多说话人跟踪的稳健解决方案，并为流式多说话人语音处理奠定了基础。

> **ai_Abstract:** 本文介绍了一种名为“流式Sortformer”的在线说话人分离框架，它是Sortformer的流式扩展，并以输出说话人的到达时间排序为核心特性。该方法引入了“到达顺序说话人缓存 (AOSC)”，用于存储和动态更新说话人的声学嵌入，其独特之处在于按说话人到达时间顺序进行索引，并根据模型预测动态调整存储的嵌入数量，从而实现高效的缓存利用和精准的说话人跟踪。实验结果表明，该方法在实时、低延迟的多说话人跟踪方面表现出卓越的有效性和灵活性。

> **摘要翻译:** 本文提出了Sortformer说话人分离框架的流式扩展，其关键特性是输出说话人的到达时间排序。所提出的方法采用到达顺序说话人缓存（AOSC）来存储先前观察到的说话人的帧级声学嵌入。与传统的说话人追踪缓冲区不同，AOSC根据说话人索引（对应于他们的到达时间顺序）对嵌入进行排序，并通过根据模型过去的预测选择得分最高的帧进行动态更新。值得注意的是，每个说话人存储的嵌入数量由更新机制动态确定，确保高效的缓存利用和精确的说话人跟踪。在基准数据集上的实验证实了我们方法的有效性和灵活性，即使在低延迟设置下也是如此。这些结果确立了流式Sortformer作为实时多说话人跟踪的强大解决方案，并为流式多说话人语音处理奠定了基础。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [451] [ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding](https://arxiv.org/abs/2507.17765)
> *ASR引导的说话人角色识别与说话人识别引导的ASR解码*

*Arindam Ghosh, Mark Fuhs, Bongjun Kim, Anurag Chowdhury, Monika Woszczyna* | **Category: eess.AS, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 说话人角色识别, 自动语音识别, 端到端模型, 强制对齐, 小词删除

**Comment:** Interspeech 2025 Submission

> **TL;DR:** 本文将现有的端到端ASR+说话人识别框架扩展到说话人角色识别，通过简化训练、使用独立的任务特定预测器，并利用角色识别后验活动来改进ASR解码，减少小词删除错误。

**AI_Comments:** 该论文的创新之处在于将传统的说话人识别扩展到更实用的说话人角色识别，并针对现有端到端ASR+SD模型的痛点进行了改进。通过简化训练流程和引入独立的任务特定预测器，提升了模型的训练效率和预测精度。尤其重要的是，提出了利用角色识别结果反向指导ASR解码，以减少小词删除错误，这对于提高语音识别的鲁棒性和准确性具有重要意义。此方法在实际应用中，如医疗、会议记录等场景，将具有显著的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 从应用角度来看，说话人角色识别（如医生 vs. 患者）通常比传统的说话人识别（如说话人1 vs. 说话人2）更有用。在联合自动语音识别（ASR）和说话人识别的背景下，现有模型虽然能预测每词的说话人，但未充分利用角色信息，且存在训练复杂和预测器共享的问题。

**Method:** 本文将现有端到端ASR+说话人识别框架扩展到说话人角色识别，主要有三个贡献：1) 通过强制对齐和交叉熵损失简化训练，取代RNNT损失；2) 证明词预测和角色预测需要不同量的预测器上下文，因此采用独立的任务特定预测器，而非现有共享预测器模型；3) 提出一种利用说话人角色识别后验活动来影响ASR解码并减少小词删除错误的方法。

**Result:** 通过利用说话人角色识别后验活动，可以减少ASR解码中的小词删除错误。

**Conclusion:** 本文成功将联合ASR+说话人识别框架扩展到更具应用价值的说话人角色识别，并通过简化训练、优化预测器结构以及引入角色识别引导的ASR解码，有效提升了系统的性能，尤其是在减少小词删除错误方面。

> **ai_Abstract:** 本文将现有的端到端自动语音识别（ASR）与说话人识别（SD）联合框架扩展到更具应用价值的说话人角色识别（RD）。研究提出了三项主要改进：一是通过强制对齐和交叉熵损失简化了训练过程；二是针对词预测和角色预测的不同上下文需求，引入了独立的任务特定预测器，而非传统的共享预测器；三是提出了一种利用RD后验活动来引导ASR解码，从而有效减少了小词删除错误的方法。

> **摘要翻译:** 从应用的角度来看，说话人角色识别（RD），例如医生与患者、主持人与嘉宾等，通常比传统的说话人识别（SD）（它分配通用标签，如说话人1、说话人2等）更有用。在联合自动语音识别（ASR）+ SD（谁说了什么？）的背景下，最近的端到端模型采用一个辅助的SD传感器，与ASR传感器同步，以预测每个词的说话人。在本文中，我们将这个框架扩展到RD，并有三个关键贡献：(1) 我们通过强制对齐和交叉熵损失而不是RNNT损失来简化训练；(2) 我们表明词预测和角色预测需要不同数量的预测器上下文，从而导致独立的任务特定预测器，这与现有共享预测器模型不同；(3) 我们提出了一种利用RD后验活动来影响ASR解码并减少小词删除错误的方法。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [712] [DiffRhythm+: Controllable and Flexible Full-Length Song Generation with Preference Optimization](https://arxiv.org/abs/2507.12890)
> *DiffRhythm+：基于偏好优化的可控灵活全长歌曲生成*

*Huakang Chen, Yuepeng Jiang, Guobin Ma, Chunbo Hao, Shuai Wang, Jixun Yao, Ziqian Ning, Meng Meng, Jian Luan, Lei Xie* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-24**

**Keywords:** 全长歌曲生成, 扩散模型, 可控生成, 偏好优化, 音乐风格条件化

**Comment:** 

> **TL;DR:** DiffRhythm+通过使用更大的平衡数据集、多模态风格条件化和偏好优化，改进了全长歌曲生成，从而提高了质量和控制力。

**AI_Comments:** DiffRhythm+的创新之处在于其对数据不平衡的解决、多模态可控性的增强以及直接用户偏好优化的整合，这些对于实际的音乐生成应用至关重要。该方法显著提升了生成音乐的质量、可控性和用户满意度，是音乐AI领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的全长歌曲合成系统面临数据不平衡、可控性不足和音乐质量不一致等挑战。先前的DiffRhythm模型受限于不平衡的训练数据集和有限的音乐风格可控性，导致质量差异和创作灵活度受限。

**Method:** 我们提出了DiffRhythm+，一个增强的基于扩散的框架。它利用显著扩展和平衡的训练数据集，引入了多模态风格条件化策略（通过描述性文本和参考音频），并进一步引入了与用户偏好对齐的直接性能优化。

**Result:** DiffRhythm+在自然度、编排复杂性和听众满意度方面比以前的系统取得了显著改进。它缓解了歌词重复和遗漏等问题，培养了更丰富的音乐技能和表现力，并显著增强了创作控制和多样性。

**Conclusion:** DiffRhythm+通过解决现有模型在数据、可控性和用户偏好对齐方面的局限性，成功实现了卓越的全长歌曲生成。

> **ai_Abstract:** 本文提出了DiffRhythm+，一个增强的基于扩散的全长歌曲生成框架，旨在解决现有系统的数据不平衡、可控性不足和音乐质量不一致等问题。DiffRhythm+通过扩大和平衡训练数据集来提高音乐技能和表现力，引入多模态风格条件化策略以增强创作控制和多样性，并采用直接偏好优化以生成更符合用户期望的输出。实验证明，DiffRhythm+在自然度、编排复杂性和听众满意度方面均优于现有系统。

> **摘要翻译:** 歌曲作为一种核心的音乐艺术形式，体现了人类智能和创造力的丰富性。尽管生成建模的最新进展在长篇歌曲生成方面取得了显著进展，但当前的全长歌曲合成系统仍面临主要挑战，包括数据不平衡、可控性不足和音乐质量不一致。DiffRhythm作为一种开创性的基于扩散的模型，通过生成具有表现力的人声和伴奏的全长歌曲，推动了该领域的发展。然而，其性能受到不平衡的模型训练数据集和对音乐风格有限的可控性的限制，导致明显的质量差异和受限的创作灵活性。为了解决这些局限性，我们提出了DiffRhythm+，一个用于可控灵活全长歌曲生成的增强型基于扩散的框架。DiffRhythm+利用显著扩展和平衡的训练数据集来缓解歌词重复和遗漏等问题，同时促进更丰富的音乐技能和表现力的出现。该框架引入了一种多模态风格条件化策略，使用户能够通过描述性文本和参考音频精确指定音乐风格，从而显著增强创作控制和多样性。我们进一步引入了与用户偏好对齐的直接性能优化，引导模型在评估指标上始终产生偏好的输出。广泛的实验表明，DiffRhythm+在自然度、编排复杂性和听众满意度方面比以前的系统取得了显著改进。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [8] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
> *VeriMinder：缓解NL2SQL中的分析漏洞*

*Shubham Mohole, Sainyam Galhotra* | **Category: cs.CL, cs.AI, cs.DB** | **Updated: 2025-07-23**

**Keywords:** NL2SQL, 认知偏差, 分析漏洞, VeriMinder, 自然语言接口到数据库

**Comment:** 

> **TL;DR:** VeriMinder是一个交互式系统，旨在检测和缓解NLIDB中用户分析问题中的认知偏差，并通过三项创新和用户测试验证了其有效性。

**AI_Comments:** VeriMinder的创新之处在于它首次系统性地关注NL2SQL领域中分析问题的认知偏差，而不仅仅是SQL生成准确性。其结合了语义映射、认知原则（Hard-to-Vary）和先进的LLM提示工程，提供了一个全面的解决方案。作为开源项目发布也极大地促进了其在社区中的应用和进一步研究，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自然语言到数据库接口（NLIDBs）使数据分析民主化，但它也带来了帮助缺乏统计分析背景的用户提出无偏见的分析问题的紧迫挑战。当前研究主要关注文本到SQL的生成准确性，而分析问题中的认知偏差问题仍未得到充分探索。

**Method:** 本研究提出了VeriMinder系统，该系统通过以下三项关键创新来检测和缓解分析漏洞：1) 一个针对特定分析上下文的偏差上下文语义映射框架；2) 一个操作化“难以改变原则”并指导用户进行系统数据分析的分析框架；3) 一个优化的、由大型语言模型（LLM）驱动的系统，该系统通过涉及多个候选、批评反馈和自我反思的结构化过程生成高质量、特定任务的提示。

**Result:** 用户测试证实了VeriMinder方法的优点。在直接用户体验评估中，82.5%的参与者表示其积极影响了分析质量。在比较评估中，VeriMinder在分析的具体性、全面性和准确性指标上，得分比替代方法至少高出20%。

**Conclusion:** VeriMinder系统旨在帮助用户在数据分析过程中避免“错误问题”的漏洞。该系统作为Web应用程序实现，并且其代码库和提示以MIT许可的开源软件形式提供，以促进社区内的进一步研究和采用。

> **ai_Abstract:** VeriMinder是一个交互式系统，旨在解决自然语言到数据库接口（NLIDBs）中用户分析问题存在的认知偏差和分析漏洞。该系统通过引入上下文语义映射框架、基于“难以改变原则”的分析框架以及优化的LLM驱动提示生成系统，帮助用户提出无偏见的分析问题。用户测试和比较评估结果表明，VeriMinder显著提高了分析质量和准确性，并已作为开源Web应用程序发布。

> **摘要翻译:** 使用自然语言接口到数据库（NLIDBs）的应用程序系统已经使数据分析民主化。这一积极发展也带来了一个紧迫的挑战，即帮助那些可能在没有统计分析背景的情况下使用这些系统的用户，来制定无偏见的分析问题。尽管大量研究集中在文本到SQL的生成准确性上，但解决分析问题中的认知偏差仍未得到充分探索。我们提出了VeriMinder，https://veriminder.ai，一个用于检测和缓解此类分析漏洞的交互式系统。我们的方法引入了三项关键创新：(1) 一个针对特定分析上下文的偏差上下文语义映射框架；(2) 一个操作化“难以改变原则”并指导用户进行系统数据分析的分析框架；(3) 一个优化的、由大型语言模型（LLM）驱动的系统，该系统通过涉及多个候选、批评反馈和自我反思的结构化过程生成高质量、特定任务的提示。用户测试证实了我们方法的优点。在直接用户体验评估中，82.5%的参与者报告积极影响了分析质量。在比较评估中，VeriMinder在分析的具体性、全面性和准确性指标上，得分比替代方法至少高出20%。我们的系统作为Web应用程序实现，旨在帮助用户在数据分析过程中避免“错误问题”的漏洞。VeriMinder的代码库和提示，https://reproducibility.link/veriminder，作为MIT许可的开源软件提供，以促进社区内的进一步研究和采用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [9] [SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models](https://arxiv.org/abs/2507.18182)
> *SCOPE：用于评估大型语言模型的随机和反偏置选项放置*

*Wonjun Jeong, Dongseok Kim, Taegkeun Whangbo* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型评估, 选择偏差, 选项放置, 去偏, SCOPE

**Comment:** 34 pages, 1 figure

> **TL;DR:** SCOPE是一个评估框架，旨在通过随机和反偏置选项放置来缓解大型语言模型在多项选择任务中的选择偏差。

**AI_Comments:** SCOPE的创新之处在于其通过“空提示”来估计模型位置偏差并进行反偏置选项放置，从而提供了一种数据集无关的去偏方法。这对于提高大型语言模型评估的公平性和可靠性至关重要，因为它能更准确地反映模型的真实理解能力而非其对偏差的利用。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在多项选择任务中可能通过利用选项位置或标签的固有偏差来获得虚高的分数，而非真正展示其理解能力。

**Method:** SCOPE通过重复调用缺乏语义内容的空提示来估计每个模型独特的偏置分布。然后，它根据逆偏置分布重新分配答案槽，从而均衡“幸运率”（即偶然选择正确答案的概率）。此外，它还阻止语义相似的干扰项与答案相邻放置，以防止基于表面邻近线索的“近失”猜测。

**Result:** 在多项基准实验中，SCOPE在稳定的性能改进方面始终优于现有去偏方法，并对正确选项显示出更清晰的置信度分布。

**Conclusion:** 该框架为提升大型语言模型评估的公平性和可靠性提供了一个新标准。

> **ai_Abstract:** SCOPE是一个旨在解决大型语言模型在多项选择任务中因利用选项偏差而导致分数虚高问题的评估框架。它通过估计模型的独特位置偏差并根据逆偏差重新分配答案槽，以均衡偶然猜对的概率，同时防止语义相似的干扰项紧邻正确答案。实验结果表明，SCOPE在稳定性能提升方面优于现有去偏方法，为LLM评估提供了更公平和可靠的新标准。

> **摘要翻译:** 大型语言模型（LLM）在多项选择任务中可能通过利用选项位置或标签的固有偏差来获得虚高的分数，而非真正展示真正的理解。本研究引入了SCOPE，这是一个旨在以数据集无关的方式测量和缓解此类选择偏差的评估框架。通过重复调用缺乏语义内容的空提示，SCOPE估计每个模型独特的偏置分布。然后，它根据逆偏置分布重新分配答案槽，从而均衡“幸运率”，即偶然选择正确答案的概率。此外，它还阻止语义相似的干扰项与答案相邻放置，从而阻止基于表面邻近线索的“近失”猜测。在多项基准实验中，SCOPE在稳定的性能改进方面始终优于现有去偏方法，并对正确选项显示出更清晰的置信度分布。因此，该框架为提升LLM评估的公平性和可靠性提供了一个新标准。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [11] [Checklists Are Better Than Reward Models For Aligning Language Models](https://arxiv.org/abs/2507.18624)
> *清单优于奖励模型用于对齐语言模型*

*Vijay Viswanathan, Yanchao Sun, Shuang Ma, Xiang Kong, Meng Cao, Graham Neubig, Tongshuang Wu* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 语言模型对齐, 清单反馈, 强化学习, 指令遵循, 奖励模型

**Comment:** 

> **TL;DR:** RLCF使用指令特定清单反馈，在多个基准测试中优于其他对齐方法，显著提升了语言模型遵循指令的能力。

**AI_Comments:** 这项工作创新性地将灵活的、指令特定清单引入强化学习，作为替代传统固定奖励模型的方法。其重要性在于，它提供了一种更细粒度、更具适应性的方式来评估和改进语言模型的指令遵循能力，特别是在处理复杂和多样化用户需求时。实验结果在多个基准上的一致提升，突显了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型需要适应理解和遵循用户指令，但现有强化学习方法通常使用固定的标准，限制了其在引导指令遵循方面的影响。

**Method:** 提出“基于清单反馈的强化学习”（RLCF）。从指令中提取清单，使用AI评判和专业验证程序评估响应满足每个项目的程度，然后结合这些分数来计算强化学习的奖励。

**Result:** RLCF是唯一在所有五个广泛研究的基准测试中都能提升性能的方法，包括在FollowBench上硬满意率提升4个百分点，在InFoBench上提升6个百分点，以及在Arena-Hard上胜率提升3个百分点。

**Conclusion:** 清单反馈是改进语言模型支持表达多种需求查询的关键工具。

> **ai_Abstract:** 本文提出一种名为“基于清单反馈的强化学习”（RLCF）的新方法，旨在提升语言模型遵循用户指令的能力。与传统依赖固定奖励模型的方法不同，RLCF利用指令特定的清单，通过AI评判和验证程序评估响应质量，并据此计算奖励。实验结果表明，RLCF在多个主流基准测试中均显著优于其他对齐方法，证明了清单反馈在提升语言模型指令遵循能力方面的有效性。

> **摘要翻译:** 语言模型必须适应理解和遵循用户指令。强化学习被广泛用于促进这一点——通常使用“有用性”和“有害性”等固定标准。在我们的工作中，我们提出使用灵活的、指令特定的标准，以此拓宽强化学习在引发指令遵循方面的影响。我们提出了“基于清单反馈的强化学习”（RLCF）。从指令中，我们提取清单并评估响应满足每个项目的程度——使用AI评判和专业验证程序——然后结合这些分数来计算强化学习的奖励。我们将RLCF与其他应用于强大的指令遵循模型（Qwen2.5-7B-Instruct）的对齐方法在五个广泛研究的基准测试上进行比较——RLCF是唯一在每个基准测试中都能提升性能的方法，包括在FollowBench上硬满意率提高4个百分点，在InFoBench上提高6个百分点，以及在Arena-Hard上胜率提高3个百分点。这些结果确立了清单反馈是改进语言模型支持表达多种需求查询的关键工具。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [22] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
> *TeleChat2、TeleChat2.5和T1技术报告*

*Zihan Wang, Xinzhang Liu, Yitong Yao, Chao Wang, Yu Zhao, Zhihao Yang, Wenmin Deng, Kaipeng Jia, Jiaxin Peng, Yuyao Huang, Sishi Xiong, Zhuo Jiang, Kaidong Yu, Xiaohui Hu, Fubei Yao, Ruiyu Fang, Zhuoru Jiang, Ruiting Song, Qiyi Xie, Rui Xue, Xuewei He, Yanlei Xue, Zhu Yuan, Zhaoxi Zhang, Zilu Huang, Shiquan Wang, Xin Wang, Hanming Wu, Mingyuan Wang, Xufeng Zhan, Yuhan Sun, Zhaohu Xing, Yuhao Jiang, Bingkai Yang, Shuangyong Song, Yongxiang Li, Zhongjiang He, Xuelong Li* | **Category: cs.CL, I.2.7** | **Updated: 2025-07-24**

**Keywords:** TeleChat, 大语言模型, 训练策略, 复杂推理, 模型发布

**Comment:** 32 pages, 5 figures

> **TL;DR:** 本文介绍了TeleChat模型的最新系列：TeleChat2、TeleChat2.5和T1。这些新模型通过增强的训练策略实现了显著的性能提升，特别是T1在复杂推理方面表现出色，并且T1-115B在某些任务上超越了专有模型。这些模型已被公开。

**AI_Comments:** 本文介绍了TeleChat系列模型的显著进展，通过优化训练策略而非大规模架构更改实现性能飞跃，这表明了训练数据和方法优化的重要性。特别是T1在复杂推理和超越专有模型方面的表现，突显了其在AI领域中的竞争力。模型的公开性将极大地促进相关研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 开发TeleChat模型的最新系列（TeleChat2、TeleChat2.5和T1），旨在通过增强的训练策略在预训练和后训练阶段实现对其前身TeleChat的显著性能升级。

**Method:** TeleChat2在10万亿高质量多样化tokens上进行预训练，并结合监督微调（SFT）和直接偏好优化（DPO）。TeleChat2.5和T1通过引入领域特定数据集的持续预训练阶段，并结合强化学习（RL）来扩展流水线。T1专注于复杂推理，支持长CoT推理。TeleChat2.5和T1均为具有115B参数的密集Transformer架构。

**Result:** 新系列模型在推理和通用任务性能上比原始TeleChat有显著提升。T1-115B在数学和编码方面有显著改进，并且性能超越了OpenAI的o1-mini和GPT-4o等专有模型。TeleChat2.5优先考虑速度，提供快速推理。

**Conclusion:** TeleChat2、TeleChat2.5和T1系列模型通过改进的训练策略和架构优化，实现了对其前身的显著性能提升，特别是在复杂推理、代码生成和数学推理方面。这些模型，包括35B和115B参数的后训练版本，已公开，旨在为开发者和研究人员提供最先进的语言模型。

> **ai_Abstract:** 本文介绍了TeleChat模型的最新系列：TeleChat2、TeleChat2.5和T1。这些新模型通过改进预训练和后训练策略，在模型架构变化不大的情况下，实现了显著的性能提升。TeleChat2在大量数据上预训练并进行SFT和DPO。TeleChat2.5和T1则通过持续预训练和强化学习，特别是在代码生成和数学推理方面进行了优化。T1专长于复杂推理，而TeleChat2.5则注重推理速度。T1和TeleChat2.5均是115B参数的Transformer模型，并在推理和通用任务上超越了前代TeleChat，其中T1-115B甚至优于GPT-4o等专有模型。所有模型均已公开。

> **摘要翻译:** 我们介绍了TeleChat模型的最新系列：\textbf{TeleChat2}、\textbf{TeleChat2.5}和\textbf{T1}，它们是其前身TeleChat的重大升级。尽管模型架构变化不大，但新系列通过在预训练和后训练阶段增强训练策略，实现了显著的性能提升。该系列始于\textbf{TeleChat2}，它在10万亿高质量和多样化tokens上进行预训练。随后进行监督微调（SFT）和直接偏好优化（DPO），以进一步增强其能力。\textbf{TeleChat2.5}和\textbf{T1}通过结合领域特定数据集的持续预训练阶段，并结合强化学习（RL）来扩展流水线，以提高代码生成和数学推理任务的性能。\textbf{T1}变体专为复杂推理而设计，支持长链式思维（CoT）推理，并在数学和编码方面表现出显著改进。相比之下，\textbf{TeleChat2.5}优先考虑速度，提供快速推理。\textbf{T1}和\textbf{TeleChat2.5}这两款旗舰模型都是具有115B参数的密集Transformer架构，与原始TeleChat相比，在推理和通用任务性能方面展现出显著进步。值得注意的是，\textbf{T1-115B}的性能优于OpenAI的o1-mini和GPT-4o等专有模型。我们公开了\textbf{TeleChat2}、\textbf{TeleChat2.5}和\textbf{T1}，包括35B和115B参数的后训练版本，旨在为开发者和研究人员提供适用于各种应用的最先进语言模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [41] [Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias](https://arxiv.org/abs/2212.10678)
> *因果测试大型语言模型中的性别偏见：一项职业偏见的案例研究*

*Yuen Chen, Vethavikashini Chithrra Raghuram, Justus Mattern, Rada Mihalcea, Zhijing Jin* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 性别偏见, 大型语言模型, 因果测试, 职业偏见, 偏见测量

**Comment:** 

> **TL;DR:** 本研究提出了一种衡量大型语言模型（LLMs）中偏见的因果公式，并开发了OccuGender基准来测试职业性别偏见。结果显示，Llama和Mistral等主流LLMs存在显著的职业性别偏见。

**AI_Comments:** 本文的创新之处在于引入了偏见测量的因果公式，为理解和量化LLMs中的偏见提供了一个更严谨的理论基础。提出的OccuGender基准为评估职业性别偏见提供了一个具体的工具。研究结果揭示了主流LLMs中存在的显著偏见，强调了持续研究和缓解工作的重要性。对框架通用性和偏见缓解策略的讨论增加了实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的文本表现出对不同人群的有害偏见，这促使研究人员努力理解和测量这些影响。

**Method:** 本研究引入了一种用于生成式语言模型中偏见测量的因果公式，并在此理论基础上概述了设计稳健偏见基准的必要条件。随后，提出了一个名为OccuGender的基准，并附带偏见测量程序，用于调查职业性别偏见。研究人员使用OccuGender测试了包括Llama和Mistral及其指令调优版本在内的多个最先进的开源LLMs。

**Result:** 测试结果显示，这些大型语言模型表现出显著的职业性别偏见。

**Conclusion:** 本研究发现主流大型语言模型存在显著的职业性别偏见。论文还讨论了偏见缓解的提示策略以及因果公式的扩展，以说明其框架的通用性。

> **ai_Abstract:** 本论文提出了一种新的因果公式来测量大型语言模型（LLMs）中的偏见，并以此为基础设计了稳健偏见基准的必要条件。研究引入了名为OccuGender的基准及其偏见测量程序，专门用于调查职业性别偏见。通过对Llama和Mistral等前沿LLMs的测试，研究发现这些模型存在显著的职业性别偏见。此外，论文还探讨了偏见缓解的提示策略，并展示了所提出因果框架的通用性。

> **摘要翻译:** 大型语言模型（LLMs）生成的文本已被证明对各种人群表现出各种有害的、类似人类的偏见。这些发现促使研究努力旨在理解和测量此类影响。本文引入了一种用于生成式语言模型中偏见测量的因果公式。基于这一理论基础，我们概述了设计稳健偏见基准的一系列必要条件。然后，我们提出了一个名为OccuGender的基准，并附带偏见测量程序，以调查职业性别偏见。我们在OccuGender上测试了几种最先进的开源LLMs，包括Llama、Mistral及其指令调优版本。结果显示，这些模型表现出显著的职业性别偏见。最后，我们讨论了偏见缓解的提示策略以及我们因果公式的扩展，以说明我们框架的通用性。我们的代码和数据可在https://github.com/chenyuen0103/gender-bias获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [45] [Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection](https://arxiv.org/abs/2507.18202)
> *使用GMTP保护RAG管道：一种基于梯度的掩码令牌概率中毒文档检测方法*

*San Kim, Jonghwi Kim, Yejin Jeon, Gary Geunbae Lee* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** RAG, 中毒文档, 安全, 基于梯度, 掩码语言模型

**Comment:** 18 pages, accepted to ACL Findings 2025

> **TL;DR:** RAG管道容易受到中毒文档攻击，本文提出GMTP方法，利用基于梯度的掩码令牌概率来检测和过滤这些文档，实验证明能有效消除90%以上的中毒内容。

**AI_Comments:** 该论文解决了RAG系统面临的一个关键安全漏洞，这在当前LLM广泛应用的背景下具有重要意义。GMTP方法通过结合梯度分析和掩码语言模型进行检测，展现了创新性。其在有效去除中毒内容（超过90%）的同时保持系统性能，是该方法的一个显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）依赖外部知识库来增强大型语言模型（LLM），但这引入了安全风险：攻击者可以注入中毒文档，导致LLM生成有害或误导性输出。因此，需要一种防御机制来检测和过滤这些恶意文档。

**Method:** 本文提出了基于梯度的掩码令牌概率（GMTP）方法。具体步骤是：首先，通过检查检索器相似性函数的梯度来识别高影响力令牌；然后，对这些关键令牌进行掩码处理；最后，通过掩码语言模型（MLM）检查这些掩码令牌的概率。由于注入的令牌通常显示出明显低的掩码令牌概率，GMTP能够以此检测恶意文档并实现高精度过滤。

**Result:** 实验结果表明，GMTP能够消除90%以上的中毒内容，同时保留了相关文档。这使得RAG系统在多样化的数据集和对抗性设置下，依然能够保持稳健的检索和生成性能。

**Conclusion:** GMTP是一种有效且新颖的防御方法，能够成功检测和过滤RAG管道中的中毒文档，显著提高了系统的安全性，并保持了其检索和生成性能。

> **ai_Abstract:** 本文提出了一种名为GMTP（基于梯度的掩码令牌概率）的新方法，旨在保护RAG管道免受中毒文档的攻击。GMTP通过分析检索器相似性函数的梯度来识别高影响力令牌，并将其掩码后，利用掩码语言模型（MLM）检查其概率。由于恶意注入的令牌通常具有较低的掩码概率，GMTP能够高效地检测并过滤这些中毒文档。实验证明，该方法能有效去除90%以上的中毒内容，同时保持RAG系统的检索和生成性能。

> **摘要翻译:** 检索增强生成（RAG）通过提供外部知识来增强大型语言模型（LLM），以实现准确和最新的响应。然而，这种对外部来源的依赖暴露出安全风险，攻击者可以将中毒文档注入知识库，从而将生成过程引导至有害或误导性的输出。在本文中，我们提出了一种新颖的防御方法——基于梯度的掩码令牌概率（GMTP），用于检测和过滤对抗性制作的文档。具体而言，GMTP通过检查检索器相似性函数的梯度来识别高影响力令牌。然后，这些关键令牌被掩码，并通过掩码语言模型（MLM）检查它们的概率。由于注入的令牌通常表现出明显低的掩码令牌概率，这使得GMTP能够轻松检测恶意文档并实现高精度过滤。实验表明，GMTP能够消除90%以上的中毒内容，同时保留相关文档，从而在不同数据集和对抗性设置下保持稳健的检索和生成性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [67] [DocTER: Evaluating Document-based Knowledge Editing](https://arxiv.org/abs/2308.09954)
> *DocTER：评估基于文档的知识编辑*

*Suhang Wu, Ante Wang, Minlong Peng, Yujie Lin, Wenbo Li, Mingming Sun, Jinsong Su* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 知识编辑, 文档, DocTER, 基准评估, 知识提取

**Comment:** Information processing & management

> **TL;DR:** 本文提出了第一个基于文档的知识编辑评估基准DocTER，并发现基于文档的知识编辑比基于三元组的更具挑战性。

**AI_Comments:** 本文通过引入首个基于文档的知识编辑评估基准DocTER，填补了该领域的一个重要空白，并揭示了基于文档的知识编辑面临的巨大挑战。其提出的四维评估方法和“提取-然后-编辑”管道具有创新性。研究结果强调了文档编辑的复杂性，并为未来研究指明了方向，特别是在提高文档提取质量、优化知识在文档中的表示以及增强推理能力方面。

<details>
  <summary>Details</summary>

**Motivation:** 旨在纠正神经网络中过时或不准确的知识，并探索使用易于获取的文档进行知识编辑，以替代先前研究中手动标注的事实三元组。

**Method:** 建立了第一个基于文档的知识编辑评估基准DocTER，包含用于编辑的反事实知识文档。引入了从编辑成功率、局部性、推理和跨语言迁移四个维度进行的综合评估。开发了一个“提取-然后-编辑”（Extract-then-Edit）管道，用于将传统基于三元组的知识编辑方法应用于文档，该管道首先从文档中提取三元组，然后应用现有方法。

**Result:** 实验表明，使用文档进行知识编辑比使用三元组更具挑战性。在基于文档的场景中，即使是表现最佳的上下文编辑方法，其编辑成功率仍比使用黄金三元组低10个百分点。这一观察结果在推理和跨语言测试集上也同样成立。进一步分析了影响任务性能的关键因素，包括提取三元组的质量、编辑知识在文档中的频率和位置、增强推理的方法以及跨语言知识编辑在不同方向上的性能差异。

**Conclusion:** 基于文档的知识编辑比基于三元组的更具挑战性，需要进一步的研究来弥补性能差距，并且论文分析的关键因素为未来的研究提供了有价值的见解。

> **ai_Abstract:** 本文介绍了DocTER，一个用于评估基于文档的知识编辑的开创性基准，旨在纠正神经网络中的知识。与传统基于三元组的方法不同，DocTER利用易于获取的文档进行编辑。作者提出了一个四维评估框架（编辑成功率、局部性、推理和跨语言迁移），并开发了一个“提取-然后-编辑”管道来适应现有方法。实验结果表明，基于文档的知识编辑比基于三元组的更具挑战性，即使是最佳方法也存在显著性能差距。研究还深入分析了影响性能的关键因素，为未来的研究提供了宝贵见解。

> **摘要翻译:** 知识编辑旨在纠正神经网络中过时或不准确的知识。在本文中，我们探索使用易于获取的文档进行知识编辑，而不是早期研究中使用的手动标注的事实三元组。为了推动该领域的发展，我们建立了第一个评估基准\textit{DocTER}，其特点是包含用于编辑的反事实知识文档。引入了全面的四视角评估：编辑成功率、局部性、推理和跨语言迁移。为了使传统的基于三元组的知识编辑方法适应这项任务，我们开发了一个“提取-然后-编辑”管道，该管道在应用现有方法之前从文档中提取三元组。对流行的知识编辑方法进行的实验表明，使用文档进行编辑比使用三元组提出了显著更大的挑战。在基于文档的场景中，即使是表现最佳的上下文编辑方法，其编辑成功率仍比使用黄金三元组低10个百分点。这一观察结果在推理和跨语言测试集上也同样成立。我们进一步分析了影响任务性能的关键因素，包括提取三元组的质量、编辑知识在文档中的频率和位置、增强推理的各种方法以及跨语言知识编辑在不同方向上的性能差异，这些为未来的研究提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [71] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
> *使用大型语言模型生成具有多样化写作风格的隐私保护合成评论*

*Tevin Atwal, Chan Nam Tieu, Yefeng Yuan, Zhan Shi, Yuhong Liu, Liang Cheng* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 合成数据, 隐私保护, 大型语言模型, 写作风格多样性, 评估指标

**Comment:** 

> **TL;DR:** 该研究评估并发现大型语言模型在生成多样化且保护隐私的合成评论数据方面存在局限性，并提出了一种基于提示的方法来改善多样性并保护隐私。

**AI_Comments:** 该论文创新性地提出了一套量化评估LLM生成合成数据多样性和隐私风险的指标，填补了该领域的空白。其发现LLM在生成多样化和隐私保护数据方面的局限性具有重要意义，并为未来的研究指明了方向。提出的基于提示的方法为改善合成数据质量提供了一个实用的解决方案，对数据增强和隐私保护领域具有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型生成的合成数据在数据驱动应用中日益普及，但其多样性和隐私风险尚未得到充分探索。

**Method:** 提出了一套全面的指标来量化评估LLM生成的合成数据集的多样性（语言表达、情感、用户视角）和隐私（重识别风险、风格异常值）。基于评估结果，提出了一种基于提示的方法来增强合成评论的多样性，同时保护评论者隐私。

**Result:** 实验结果表明，大型语言模型在生成多样化和隐私保护的合成数据方面存在显著局限性。

**Conclusion:** 大型语言模型在生成多样化和隐私保护的合成数据方面存在局限性，但可以通过提出的基于提示的方法来增强合成评论的多样性并保护隐私。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLMs）生成的合成数据在多样性和隐私保护方面的未充分探索问题。作者提出了一套全面的评估指标，用于量化分析LLM生成合成文本数据的多样性（包括语言表达、情感和用户视角）和隐私（包括重识别风险和风格异常值）。实验结果表明，现有LLMs在生成多样化且保护隐私的合成数据方面存在明显不足。为克服这些局限性，研究进一步提出了一种基于提示的方法，旨在有效提升合成评论的多样性，同时确保用户隐私得到保护。

> **摘要翻译:** 大型语言模型（LLMs）生成的合成数据日益普及，这在数据驱动应用中既带来了机遇也带来了挑战。虽然合成数据为真实世界数据提供了一种经济高效、可扩展的替代方案，以促进模型训练，但其多样性和隐私风险仍未得到充分探索。我们专注于基于文本的合成数据，提出了一套全面的指标来定量评估由几种最先进的LLM生成的合成数据集的多样性（即语言表达、情感和用户视角）和隐私（即重新识别风险和风格异常值）。实验结果揭示了LLM在生成多样化和隐私保护合成数据方面的显著局限性。在评估结果的指导下，提出了一种基于提示的方法来增强合成评论的多样性，同时保护评论者隐私。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [81] [AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs](https://arxiv.org/abs/2507.18584)
> *AQuilt：将逻辑和自检融入低成本、高相关性的专业领域LLM数据合成*

*Xiaopeng Ke, Hexuan Deng, Xuebo Liu, Jun Rao, Zhenxi Song, Jun Yu, Min Zhang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 数据合成, 专业LLM, 指令微调, 逻辑推理, 自检

**Comment:** 32 pages, 4 figures

> **TL;DR:** AQuilt是一个低成本、高效的数据合成框架，通过结合逻辑和自检机制，为专业领域LLM构建高质量的指令微调数据，性能与DeepSeek-V3相当但成本更低。

**AI_Comments:** AQuilt的创新之处在于其将逻辑和自检机制融入数据合成过程，这不仅提升了生成数据的质量和相关性，还显著降低了成本。该方法对于在资源有限的情况下，为特定专业领域快速构建高效LLM具有重要意义。其关注数据相关性和成本效益，解决了现有数据合成方法的关键痛点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域往往表现不佳。现有数据合成方法虽然有前景，但计算成本高昂或性能受限，且在不同任务上的泛化能力不足。

**Method:** 本文提出了AQuilt框架，用于从无标签数据构建任何专业领域的指令微调数据。AQuilt包含Answer、Question、Unlabeled data、Inspection、Logic和Task type六个组成部分。通过融入逻辑和自检，AQuilt促进推理过程和自我检查以提升模型性能，并通过可定制的任务指令生成高质量数据。

**Result:** AQuilt构建了一个包含70.3万个示例的数据集来训练一个强大的数据合成模型。实验表明，AQuilt的性能与DeepSeek-V3相当，但生产成本仅为后者的17%。进一步分析显示，AQuilt生成的数据与下游任务的相关性更高。

**Conclusion:** AQuilt通过结合逻辑和自检机制，成功地提供了一种低成本、高效且高质量的数据合成方法，有效解决了专业领域LLM数据不足和现有方法局限性的问题，显著提升了模型在专业领域的表现和数据相关性。

> **ai_Abstract:** AQuilt是一种为专业领域大型语言模型（LLMs）构建指令微调数据的框架，旨在解决现有数据合成方法成本高、性能受限及泛化能力不足的问题。该框架通过结合答案、问题、无标签数据、检查、逻辑和任务类型等组件，并融入逻辑和自检机制，生成高质量且与下游任务高度相关的数据。实验证明，AQuilt在仅使用DeepSeek-V3 17%的成本下，达到了相似的性能，显示出其在低成本、高效率数据合成方面的显著优势。

> **摘要翻译:** 尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域往往表现不佳。现有方法通常依赖数据合成方法，通过使用未标记数据捕获领域特定特征来获得有希望的结果。然而，这些方法要么产生高昂的计算成本，要么受限于性能，同时在不同任务上的泛化能力也表现不足。为了解决这些挑战，我们提出了AQuilt，一个用于从相应未标记数据构建任何专业领域指令微调数据的框架，其组成包括答案（Answer）、问题（Question）、未标记数据（Unlabeled data）、检查（Inspection）、逻辑（Logic）和任务类型（Task type）。通过融入逻辑和检查，我们鼓励推理过程和自我检查以增强模型性能。此外，可定制的任务指令能够为任何任务生成高质量数据。因此，我们构建了一个包含70.3万个示例的数据集来训练一个强大的数据合成模型。实验表明，AQuilt与DeepSeek-V3相当，而生产成本仅为其17%。进一步分析表明，我们生成的数据对下游任务表现出更高的相关性。源代码、模型和脚本可在https://github.com/Krueske/AQuilt获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [92] [Weak-to-Strong Jailbreaking on Large Language Models](https://arxiv.org/abs/2401.17256)
> *大型语言模型上的弱到强越狱攻击*

*Xuandong Zhao, Xianjun Yang, Tianyu Pang, Chao Du, Lei Li, Yu-Xiang Wang, William Yang Wang* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 越狱攻击, 安全, 对齐, 弱到强

**Comment:** ICML 2025

> **TL;DR:** 提出了一种高效的“弱到强”越狱攻击，仅用一次前向传播即可使大型语言模型产生有害内容，揭示了LLM对齐中的紧迫安全问题。

**AI_Comments:** 这项研究创新性地提出了一种高效的越狱攻击方法，通过利用模型间解码分布的差异，实现了在推理时对大型语言模型的有效攻击。其重要性在于揭示了LLM对齐过程中存在的严重且紧迫的安全漏洞，对未来的LLM安全研究和部署具有重要警示意义。尽管提出了初步防御，但其指出的防御挑战性也为后续研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型容易受到越狱攻击，导致生成有害、不道德或有偏见的文本，但现有越狱方法计算成本高昂。

**Method:** 提出了一种名为“弱到强越狱攻击”的高效推理时攻击。其核心思想是利用两个较小的模型（一个安全模型和一个不安全模型）对抗性地修改一个显著更大的安全模型的解码概率，基于越狱模型和对齐模型仅在初始解码分布上存在差异的观察。

**Result:** 该方法在两个数据集上，仅需每个示例一次前向传播，即可将未对齐率提高到99%以上，并在来自3个组织的5个不同的开源LLM上进行了评估。

**Conclusion:** 本研究揭示了在对齐大型语言模型时需要解决的紧迫安全问题。作为初步尝试，论文提出了一种防御策略来抵御此类攻击，但创建更先进的防御仍然具有挑战性。

> **ai_Abstract:** 本文提出了一种高效的“弱到强越狱攻击”，该方法利用两个较小的辅助模型来对抗性地修改大型安全模型的解码概率，从而在推理时促使其生成有害内容。实验证明，该方法能以极低的计算成本（单次前向传播）在多个开源LLM上将未对齐率提升至99%以上，揭示了LLM对齐中的严重安全漏洞。作者也提出了初步的防御策略，但强调了更高级防御的挑战性。

> **摘要翻译:** 大型语言模型（LLMs）容易受到越狱攻击——导致生成有害、不道德或有偏见的文本。然而，现有的越狱方法计算成本高昂。在本文中，我们提出了一种弱到强越狱攻击，这是一种针对已对齐LLMs产生有害文本的有效推理时攻击。我们的关键直觉基于越狱模型和对齐模型仅在初始解码分布上存在差异的观察。弱到强攻击的关键技术洞察是使用两个较小的模型（一个安全模型和一个不安全模型）来对抗性地修改一个显著更大的安全模型的解码概率。我们在来自3个组织的5个不同的开源LLMs上评估了弱到强攻击。结果表明，我们的方法在两个数据集上，仅需每个示例一次前向传播，即可将未对齐率提高到99%以上。我们的研究揭示了在对齐LLMs时需要解决的紧迫安全问题。作为初步尝试，我们提出了一种防御策略来保护免受此类攻击，但创建更先进的防御仍然具有挑战性。复制该方法的代码可在https://github.com/XuandongZhao/weak-to-strong获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [94] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
> *评估AI文本检测器、少样本和思维链提示在使用DeepSeek生成文本时的性能*

*Hulayyil Alshammari, Praveen Rao* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** AI文本检测, DeepSeek, 对抗性攻击, 少样本提示, 思维链, 人文化

**Comment:** 

> **TL;DR:** 评估了六种AI文本检测器对DeepSeek生成文本的性能，发现人文化攻击最有效。DeepSeek结合少样本和思维链提示能高精度地检测文本。

**AI_Comments:** 这项研究通过关注新兴的DeepSeek模型，填补了现有AI文本检测文献的空白，具有重要意义。它不仅评估了现有检测工具的局限性，特别是在人文化攻击下的脆弱性，还创新性地探索了LLM自身（DeepSeek）通过高级提示技术（少样本和思维链）进行自我检测的潜力，为未来AI文本检测提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的普及引发了写作诚信问题，促使AI检测技术发展。现有研究主要关注ChatGPT等模型，但对DeepSeek的检测性能存在空白，尤其是在对抗性攻击下。

**Method:** 收集了49对人类撰写的问答对，并使用DeepSeek-v3生成了49个AI文本样本。通过复述和人文化处理增加了196个对抗性样本。使用六种常见的AI检测工具（AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, GPTZero）进行测试。此外，还通过少样本和思维链提示将DeepSeek本身作为检测器进行文本分类。

**Result:** QuillBot和Copyleaks在原始及复述的DeepSeek文本上表现近乎完美；AI Text Classifier和GPT-2结果不稳定。人文化是最有效的攻击，将Copyleaks、QuillBot和GPTZero的准确率分别降至71%、58%和52%。少样本和思维链提示表现出高准确率，其中最佳的五样本结果仅错误分类1个样本（AI召回率96%，人类召回率100%）。

**Conclusion:** 人文化处理是AI文本检测器面临的有效对抗性攻击。虽然一些外部检测器表现良好，但DeepSeek自身通过少样本和思维链提示展示了强大的文本检测能力。

> **ai_Abstract:** 本文评估了六种主流AI文本检测工具（AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, GPTZero）对DeepSeek生成文本的检测性能，并考察了标准复述和人文化等对抗性攻击对其准确性的影响。研究发现，QuillBot和Copyleaks在原始和复述文本上表现良好，但人文化攻击能显著降低所有检测器的准确率。此外，研究还探索了DeepSeek自身通过少样本和思维链提示进行文本分类的能力，结果显示其能以高精度区分AI和人类文本。

> **摘要翻译:** 大型语言模型（LLM）迅速改变了书面材料的创作方式。LLM引发了关于写作诚信的疑问，从而推动了人工智能（AI）检测技术的诞生。对抗性攻击，如标准复述和人文化复述，抑制了检测器检测机器生成文本的能力。以往的研究主要集中在ChatGPT和其他知名LLM上，并且检测器的准确性各不相同。然而，在关于DeepSeek这一最近发布的LLM的文献中存在明显的空白。因此，在这项工作中，我们调查了六种普遍可用的AI检测工具——AI Text Classifier、Content Detector AI、Copyleaks、QuillBot、GPT-2和GPTZero——是否能持续识别DeepSeek生成的文本。这些检测器暴露于上述对抗性攻击之下。我们还将DeepSeek作为检测器，通过执行少样本提示和思维链推理（CoT）来分类AI和人类撰写的文本。我们收集了49对LLM时代之前的人类创作的问答对，并使用DeepSeek-v3生成了匹配的响应，从而产生了49个AI生成样本。然后，我们应用复述和人文化等对抗性技术，增加了196个样本。这些样本用于挑战检测器的鲁棒性并评估对准确性的影响。虽然QuillBot和Copyleaks在原始和复述的DeepSeek文本上表现出近乎完美的性能，但其他检测器——特别是AI Text Classifier和GPT-2——显示出不一致的结果。最有效的攻击是人文化，将Copyleaks的准确率降低到71%，QuillBot降低到58%，GPTZero降低到52%。少样本和CoT提示显示出高准确率，其中最佳的五样本结果仅错误分类了49个样本中的一个（AI召回率96%，人类召回率100%）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [101] [Step-Audio 2 Technical Report](https://arxiv.org/abs/2507.16632)
> *Step-Audio 2 技术报告*

*Boyong Wu, Chao Yan, Chen Hu, Cheng Yi, Chengli Feng, Fei Tian, Feiyu Shen, Gang Yu, Haoyang Zhang, Jingbei Li, Mingrui Chen, Peng Liu, Wang You, Xiangyu Tony Zhang, Xingyuan Li, Xuerui Yang, Yayue Deng, Yechang Huang, Yuxin Li, Yuxin Zhang, Zhao You, Brian Li, Changyi Wan, Hanpeng Hu, Jiangjie Zhen, Siyu Chen, Song Yuan, Xuelin Zhang, Yimin Jiang, Yu Zhou, Yuxiang Yang, Bingxin Li, Buyun Ma, Changhe Song, Dongqing Pang, Guoqiang Hu, Haiyang Sun, Kang An, Na Wang, Shuli Gao, Wei Ji, Wen Li, Wen Sun, Xuan Wen, Yong Ren, Yuankai Ma, Yufan Lu, Bin Wang, Bo Li, Changxin Miao, Che Liu, Chen Xu, Dapeng Shi, Dingyuan Hu, Donghang Wu, Enle Liu, Guanzhe Huang, Gulin Yan, Han Zhang, Hao Nie, Haonan Jia, Hongyu Zhou, Jianjian Sun, Jiaoren Wu, Jie Wu, Jie Yang, Jin Yang, Junzhe Lin, Kaixiang Li, Lei Yang, Liying Shi, Li Zhou, Longlong Gu, Ming Li, Mingliang Li, Mingxiao Li, Nan Wu, Qi Han, Qinyuan Tan, Shaoliang Pang, Shengjie Fan, Siqi Liu, Tiancheng Cao, Wanying Lu, Wenqing He, Wuxun Xie, Xu Zhao, Xueqi Li, Yanbo Yu, Yang Yang, Yi Liu, Yifan Lu, Yilei Wang, Yuanhao Ding, Yuanwei Liang, Yuanwei Lu, Yuchu Luo, Yuhe Yin, Yumeng Zhan, Yuxiang Zhang, Zidong Yang, Zixin Zhang, Binxing Jiao, Daxin Jiang, Heung-Yeung Shum, Jiansheng Chen, Jing Li, Xiangyu Zhang, Yibo Zhu* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 多模态大语言模型, 音频理解, 语音对话, 强化学习, 检索增强生成

**Comment:** 

> **TL;DR:** Step-Audio 2是一个端到端的多模态大语言模型，通过集成潜在音频编码器、强化学习和检索增强生成，实现了工业级音频理解和语音对话的先进性能。

**AI_Comments:** 这篇技术报告介绍的Step-Audio 2模型，其创新点在于将多模态大语言模型应用于端到端的音频理解和语音对话，并特别强调了对副语言信息的处理能力。通过结合RL、RAG和外部工具调用，该模型展现了在复杂对话场景中的强大潜力，并有望推动语音AI技术在工业应用中的发展。其在SOTA性能上的表现也证明了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一个用于工业级音频理解和语音对话的端到端多模态大语言模型，并增强其对副语言信息的响应能力，同时有效利用真实世界数据中的丰富文本和声学知识。

**Method:** Step-Audio 2集成了潜在音频编码器和以推理为中心的强化学习（RL）。它将离散音频标记的生成整合到语言建模中，以增强对副语言信息的响应。此外，它还集成了检索增强生成（RAG），并能够调用外部工具（如网络搜索和音频搜索）来缓解幻觉并切换音色。

**Result:** Step-Audio 2在自动语音识别（ASR）和音频理解方面取得了有前景的性能，显著增强了对语速和情感等副语言信息的响应能力。它在各种音频理解和对话基准测试中，与现有的开源和商业解决方案相比，实现了最先进的性能。

**Conclusion:** Step-Audio 2通过其多模态设计和先进的技术集成（如RL和RAG），能够提供跨多样对话场景的智能和表现力，并在音频理解和对话任务上达到最先进的水平。

> **ai_Abstract:** Step-Audio 2是一个创新的端到端多模态大语言模型，专为工业级音频理解和语音对话设计。它结合了潜在音频编码器、推理中心强化学习、离散音频标记生成以及检索增强生成（RAG），并能调用外部工具。该模型在数百万小时数据上训练，在ASR、音频理解和对话任务上实现了最先进的性能，并增强了对副语言信息的响应。

> **摘要翻译:** 本文介绍了 Step-Audio 2，一个旨在实现工业级音频理解和语音对话的端到端多模态大语言模型。通过集成潜在音频编码器和以推理为中心的强化学习 (RL)，Step-Audio 2 在自动语音识别 (ASR) 和音频理解方面取得了有前景的性能。为了促进真正的端到端语音对话，Step-Audio 2 将离散音频标记的生成整合到语言建模中，显著增强了其对语速和情感等副语言信息的响应能力。为了有效利用真实世界数据中丰富的文本和声学知识，Step-Audio 2 集成了检索增强生成 (RAG)，并能够调用外部工具，如网络搜索以缓解幻觉，以及音频搜索以切换音色。Step-Audio 2 经过数百万小时的语音和音频数据训练，在各种对话场景中展现出智能和表现力。评估结果表明，与其他的开源和商业解决方案相比，Step-Audio 2 在各种音频理解和对话基准测试中实现了最先进的性能。请访问 https://github.com/stepfun-ai/Step-Audio2 获取更多信息。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [104] [Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models](https://arxiv.org/abs/2507.18263)
> *定位与聚焦：增强语音语言模型中的术语翻译*

*Suhang Wu, Jialong Tang, Chengyi Yang, Pei Zhang, Baosong Yang, Junhui Li, Junfeng Yao, Min Zhang, Jinsong Su* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 语音翻译, 术语翻译, 定位与聚焦, 语音语言模型, 翻译知识

**Comment:** Accepted at ACL 2025

> **TL;DR:** 本文提出了一种名为“定位与聚焦”的新方法，用于提高语音语言模型中的术语翻译准确性，通过有效定位术语语音片段并将其与翻译知识关联起来，从而减少无关信息干扰并更好地利用翻译知识。

**AI_Comments:** 该论文提出的“定位与聚焦”方法具有创新性，通过两阶段（定位和聚焦）处理，有效解决了语音翻译中术语翻译受噪声干扰和知识利用不足的问题。其贡献在于提供了一种更精细化的术语处理机制，提升了特定领域翻译的准确性，对专业领域的语音翻译具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 直接语音翻译（ST）中术语的准确翻译仍然是一个巨大挑战。现有方法主要利用各种翻译知识，但常受无关噪声干扰且未能充分利用翻译知识。

**Method:** 本文提出了一种新颖的“定位与聚焦”方法。首先，它有效定位话语中包含术语的语音片段以构建翻译知识，从而最小化ST模型的无关信息。其次，它将翻译知识与话语和假设从音频和文本两种模态关联起来，使ST模型在翻译过程中能更好地聚焦于翻译知识。

**Result:** 实验结果表明，该方法能有效定位话语中的术语，提高术语翻译的成功率，同时保持稳定的通用翻译性能。

**Conclusion:** 所提出的“定位与聚焦”方法能够有效解决语音翻译中术语翻译的挑战，通过精确的定位和知识聚焦显著提升术语翻译的准确性，并保持整体翻译性能。

> **ai_Abstract:** 本文针对语音翻译（ST）中术语翻译的挑战，提出了一种名为“定位与聚焦”的新方法。该方法首先精确识别并提取语音中包含术语的片段，以构建去噪的翻译知识；随后，它将这些知识与原始话语及其假设在音频和文本模态上进行关联，引导ST模型更有效地利用翻译知识。实验证明，该方法显著提升了术语翻译的准确率，并保持了良好的整体翻译性能。

> **摘要翻译:** 直接语音翻译（ST）如今受到越来越多的关注，然而，话语中术语的准确翻译仍然是一个巨大的挑战。在这方面，当前的研究主要集中于将各种翻译知识融入ST模型。然而，这些方法常常受到无关噪声的干扰，并且不能充分利用翻译知识。为了解决这些问题，本文提出了一种新颖的“定位与聚焦”方法用于术语翻译。它首先有效定位话语中包含术语的语音片段以构建翻译知识，从而最大程度地减少ST模型的无关信息。随后，它将翻译知识与话语和假设从音频和文本两种模态关联起来，使得ST模型在翻译过程中能更好地聚焦于翻译知识。在各种数据集上的实验结果表明，我们的方法能够有效定位话语中的术语并提高术语翻译的成功率，同时保持稳健的通用翻译性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [111] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
> *大型语言模型的混合与酉微调：资源受限下的方法与基准测试*

*Haomin Qi, Zihan Dai, Chengbo Huang* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 微调, 参数高效微调, 混合策略, 资源约束

**Comment:** 10 pages, 2 figures and 1 table

> **TL;DR:** 本文提出了一种新的混合微调策略，结合了BOFT和LoRA-GA的优点，并在资源受限下显著提高了大型语言模型的微调效率和性能，同时首次探索了酉RNN原则在Transformer LLM中的应用。

**AI_Comments:** 本文的创新点在于提出了结合BOFT和LoRA-GA优点的混合微调策略，并通过逐层自适应更新实现了卓越的效率和性能。同时，首次将酉RNN原则引入Transformer LLMs也具有开创性。这项工作对于在资源受限环境下部署大型语言模型具有重要实践意义，有效缓解了LLM微调的计算瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 由于大型语言模型（LLMs）的规模和内存需求，微调仍然是一个计算瓶颈。

**Method:** 本文提出了一种新颖的混合微调策略，动态整合了BOFT的正交稳定性和LoRA-GA的梯度对齐快速收敛特性。该方法通过梯度范数引导的逐层自适应更新实现。此外，首次探索了将酉RNN（uRNN）原则应用于基于Transformer的LLMs，通过结构化酉约束增强梯度稳定性。

**Result:** 在GLUE、GSM8K、MT-Bench和HumanEval四个基准测试中，使用7B到405B参数的模型进行评估，结果表明，该混合方法始终优于单独的PEFT基线，接近完全微调的准确性，同时训练时间减少高达2.1倍，内存使用减少50%。

**Conclusion:** 这些发现确立了混合方法作为在资源受限下实际部署LLMs的一种实用且可扩展的微调解决方案。

> **ai_Abstract:** 本文针对大型语言模型微调的计算瓶颈问题，提出并评估了一种新颖的混合微调策略。该策略融合了BOFT的正交稳定性和LoRA-GA的快速收敛特性，并通过梯度范数引导的逐层自适应更新优化了收敛效率和泛化能力。研究还首次将酉RNN原则应用于Transformer LLMs以增强梯度稳定性。实验结果表明，该混合方法在多个基准测试中显著优于现有PEFT技术，在接近全量微调性能的同时，大幅降低了训练时间和内存消耗，为资源受限下的LLM部署提供了高效实用的解决方案。

> **摘要翻译:** 对大型语言模型（LLMs）进行微调由于其规模和内存需求仍然是一个计算瓶颈。本文对参数高效微调（PEFT）技术进行了全面评估，包括LoRA、BOFT、LoRA-GA和uRNN，并引入了一种新颖的混合策略，该策略动态整合了BOFT的正交稳定性和LoRA-GA的梯度对齐快速收敛特性。通过计算由梯度范数引导的逐层自适应更新，该混合方法在不同任务中实现了卓越的收敛效率和泛化能力。我们还首次探索了将酉RNN（uRNN）原则应用于基于Transformer的LLMs，通过结构化酉约束增强梯度稳定性。在GLUE、GSM8K、MT-Bench和HumanEval四个基准测试中，使用7B到405B参数的模型进行经验评估，结果表明，我们的混合方法始终优于单独的PEFT基线，接近完全微调的准确性，同时训练时间减少高达2.1倍，内存使用减少50%。这些发现确立了混合方法作为在资源受限下实际部署LLMs的一种实用且可扩展的微调解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [117] [P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts](https://arxiv.org/abs/2406.12548)
> *P-React：通过混合专用LoRA专家合成主题自适应的人格特质反应*

*Yuhao Dan, Jie Zhou, Qin Chen, Junfeng Tian, Liang He* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 个性化LLM, 人格特质, 专家混合模型, P-React, OCEAN-Chat

**Comment:** 

> **TL;DR:** P-React是一个基于专家混合模型的个性化大型语言模型，通过捕捉人格特质来生成更真实、心理学上更接地气的AI反应。

**AI_Comments:** P-React通过将心理学中的“大五”人格特质引入LLM建模，为个性化AI系统提供了新的视角。其创新点在于结合了专家混合模型和人格特化损失，以更精细地捕捉人格表现。同时，构建高质量的OCEAN-Chat数据集也为该领域的研究奠定了基础，具有较高的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型主要关注显式字符配置文件，而忽略了真正塑造行为和决策的潜在人格特质，这阻碍了更拟人化和心理学上更接地气的AI系统的发展。

**Method:** 本文探索了“大五”人格特质的建模，并提出了P-React，一个基于专家混合（MoE）的个性化LLM。特别地，它集成了人格特化损失（PSL）以更好地捕捉个体特质表达。此外，还策划了一个高质量、人工验证的数据集OCEAN-Chat，用于训练LLM在不同主题中表达人格特质。

**Result:** 大量的实验证明了P-React在保持一致且真实的人格方面的有效性。

**Conclusion:** P-React通过有效建模“大五”人格特质并利用PSL和OCEAN-Chat数据集，成功实现了更拟人化和心理学上更真实的个性化LLM。

> **ai_Abstract:** 本文提出了P-React，一个基于专家混合（MoE）的个性化大型语言模型，旨在解决现有LLM在模拟人类行为时忽略深层人格特质的问题。P-React专注于建模心理学中的“大五”人格特质，并通过引入人格特化损失（PSL）来增强对个体特质表达的捕捉。为支持研究，作者还构建了高质量的OCEAN-Chat数据集。实验结果表明P-React在维持一致且真实的人格方面表现出色，有助于开发更拟人化和心理学上更真实的AI系统。

> **摘要翻译:** 个性化大型语言模型（LLMs）在情感支持和角色扮演等许多应用中引起了广泛关注。然而，现有工作主要关注建模显式字符配置文件，而忽略了真正塑造行为和决策的潜在人格特质，这阻碍了更拟人化和心理学上更接地气的AI系统的发展。在本文中，我们探索了“大五”人格特质的建模，这是心理学中使用最广泛的特质理论，并提出了P-React，一个基于专家混合（MoE）的个性化LLM。特别地，我们集成了人格特化损失（PSL）以更好地捕捉个体特质表达，提供了一个更细致入微、心理学上更接地气的人格模拟。为了促进该领域的研究，我们策划了OCEAN-Chat，一个高质量、人工验证的数据集，旨在训练LLM在不同主题中表达人格特质。大量的实验证明了P-React在保持一致且真实的人格方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [127] [VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks](https://arxiv.org/abs/2407.19795)
> *VolDoGer：LLM辅助的视觉-语言任务域泛化数据集*

*Juhwan Choi, Junehyoung Kwon, JungMin Yun, Seunguk Yu, YoungBin Kim* | **Category: cs.CL, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 域泛化, 视觉-语言任务, 数据集, LLM辅助标注, VolDoGer

**Comment:** ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)

> **TL;DR:** 提出了VolDoGer数据集，利用LLM辅助标注，解决视觉-语言任务在域泛化研究中数据集缺乏的问题。

**AI_Comments:** VolDoGer利用LLM辅助标注来高效构建视觉-语言域泛化数据集，这在数据标注成本高昂的领域具有创新性。它填补了视觉-语言任务域泛化研究中数据集的空白，为未来的模型评估和开发提供了重要资源。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在未见域数据上表现的域泛化能力至关重要，但目前视觉-语言任务的域泛化研究有限，主要原因是缺乏必要的数据集。

**Method:** 提出了VolDoGer（视觉-语言域泛化数据集），专门用于域泛化研究，涵盖图像字幕、视觉问答和视觉蕴含三个视觉-语言任务。该数据集通过将LLM（大型语言模型）辅助的数据标注技术扩展到视觉-语言任务来构建，从而减轻了人工标注的负担。

**Result:** 通过VolDoGer数据集评估了从微调模型到最近的多模态大型语言模型等各种模型的域泛化能力。

**Conclusion:** VolDoGer数据集的提出为视觉-语言任务的域泛化研究提供了急需的数据基础，并能够用于评估不同模型的域泛化能力。

> **ai_Abstract:** 本文提出了VolDoGer数据集，旨在解决视觉-语言任务中域泛化研究缺乏专用数据集的问题。VolDoGer涵盖图像字幕、视觉问答和视觉蕴含，并利用大型语言模型辅助标注技术构建，有效减轻了人工标注负担。该数据集已用于评估多种视觉-语言模型的域泛化能力。

> **摘要翻译:** 域泛化能力是深度学习模型的一个关键方面，因为它决定了模型在来自未见域数据上良好表现的能力。然而，深度学习模型在视觉-语言任务上的域泛化研究仍然有限，这主要是由于缺乏所需的数据集。为了解决这些挑战，我们提出了VolDoGer：一个专门为域泛化设计的视觉-语言数据集，它解决了三个视觉-语言任务：图像字幕、视觉问答和视觉蕴含。我们通过将基于LLM的数据标注技术扩展到视觉-语言任务来构建VolDoGer，从而减轻了招募人类标注者的负担。我们通过VolDoGer评估了从微调模型到最近的多模态大型语言模型等各种模型的域泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [141] [Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice](https://arxiv.org/abs/2507.17527)
> *Seed LiveInterpret 2.0：端到端同声传译与您的声音*

*Shanbo Cheng, Yu Bao, Zhichao Huang, Yu Lu, Ningxin Peng, Lu Xu, Runsheng Yu, Rong Cao, Ting Han, Zeyang Li, Sitong Liu, Shengtao Ma, Shiguang Pan, Jiongchen Xiao, Nuo Xu, Meng Yang, Rong Ye, Yiming Yu, Ruofei Zhang, Wanyi Zhang, Wenhao Zhu, Liehao Zou, Lu Lu, Yuxuan Wang, Yonghui Wu* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 同声传译, 语音到语音翻译, 语音克隆, 实时性, 深度学习

**Comment:** Seed-LiveInterpret 2.0 Technical Report

> **TL;DR:** Seed LiveInterpret 2.0 是一个端到端同声传译系统，通过新的框架、大规模预训练和强化学习，解决了现有系统在转录、翻译质量、实时性、多说话人混淆和语音膨胀等方面的挑战，显著提高了翻译准确性和降低了延迟，并支持语音克隆。

**AI_Comments:** 该论文介绍的 Seed LiveInterpret 2.0 在同声传译领域具有显著创新性，通过其独特的双工理解-生成框架以及结合大规模预训练和强化学习，有效解决了困扰自动同声传译多年的关键挑战。其在翻译质量和延迟方面的显著提升，尤其是将语音克隆延迟大幅缩短，极大地增强了系统的实用性和商业潜力。该研究为产品级同声传译系统的发展提供了重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 同声传译是翻译行业中最具挑战性的领域之一，现有产品级自动系统面临诸多难题，包括转录和翻译质量不佳、缺乏实时语音生成、多说话人混淆以及翻译语音膨胀（尤其是在长篇语篇中）。

**Method:** 本研究引入了 Seed-LiveInterpret 2.0，这是一个端到端同声传译模型。它通过一种新颖的双工语音到语音理解-生成框架来解决现有挑战。该模型通过大规模预训练和强化学习进行优化。

**Result:** Seed-LiveInterpret 2.0 在翻译准确性和延迟之间实现了显著更好的平衡，并经人工译员验证在复杂场景下正确率超过70%。它在翻译质量方面显著优于商业同声传译解决方案，同时将克隆语音的平均延迟从近10秒大幅降低到接近实时的3秒，减少了近70%。

**Conclusion:** Seed-LiveInterpret 2.0 提供了一个功能完善的产品级同声传译解决方案，显著提升了翻译质量和实时性，并通过语音克隆能力增强了实用性，有效解决了同声传译领域的长期挑战。

> **ai_Abstract:** Seed LiveInterpret 2.0 是一种新型的端到端同声传译系统，旨在解决现有SI系统面临的转录、翻译质量、实时性、多说话人混淆和语音膨胀等问题。该系统采用双工语音到语音理解-生成框架，并结合大规模预训练和强化学习。实验证明，Seed LiveInterpret 2.0 在翻译准确性和延迟之间取得了更好的平衡，在复杂场景下正确率超过70%，并且在翻译质量上显著优于商业解决方案，同时将语音克隆延迟从10秒缩短至3秒，大幅提升了实用性。

> **摘要翻译:** 同声传译（SI）代表着翻译行业中最严峻的前沿之一，产品级自动化系统长期以来一直受到难以解决的挑战困扰：转录和翻译质量不佳、缺乏实时语音生成、多说话人混淆以及翻译语音膨胀，尤其是在长篇语篇中。在本研究中，我们介绍了 Seed-LiveInterpret 2.0，这是一个端到端SI模型，可提供高保真、超低延迟的语音到语音生成，并具备语音克隆能力。作为一项功能完善的产品级解决方案，Seed-LiveInterpret 2.0 通过我们新颖的双工语音到语音理解-生成框架，直接解决了这些挑战。实验结果表明，通过大规模预训练和强化学习，该模型在翻译准确性和延迟之间实现了显著更好的平衡，并经人工译员验证在复杂场景下正确率超过70%。值得注意的是，Seed-LiveInterpret 2.0 在翻译质量方面显著优于商业SI解决方案，同时将克隆语音的平均延迟从近10秒大幅削减至接近实时的3秒，减少了近70%，这极大地增强了实际可用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [142] [LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios](https://arxiv.org/abs/2411.07037)
> *LIFBench：评估大型语言模型在长上下文场景中的指令遵循性能和稳定性*

*Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, He Yan, Xiangju Lu, Junmin Zhu, Wei Zhang* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 指令遵循, 长上下文, 性能评估, 稳定性

**Comment:** 17 pages, 3 figures

> **TL;DR:** 本文介绍了LIFBench，一个新颖的基准测试和评估方法（LIFEval），旨在评估大型语言模型（LLMs）在长上下文场景中的指令遵循能力和稳定性，无需人工或LLM辅助判断。

**AI_Comments:** 本文的创新之处在于解决了LLM在长上下文环境中指令遵循和稳定性这一关键但尚未充分探索的领域。自动化数据生成和评估（LIFEval）具有重要意义，因为它减少了对昂贵的人工或LLM辅助判断的依赖，使得基准测试更具可扩展性和可靠性。这项工作为指导更强大的LLM在实际应用中的发展提供了重要工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准测试很少关注大型语言模型在长上下文场景中的指令遵循能力和稳定性，而这对于实际应用至关重要。

**Method:** 引入了LIFBench，一个可扩展的数据集，包含三个长上下文场景和十一个不同任务，通过自动化扩展方法生成了2,766条指令。同时提出了LIFEval，一种基于评估标准的自动化评估方法，能够对复杂的LLM响应进行精确、自动评分，且无需依赖LLM辅助评估或人工判断。

**Result:** 对20个知名大型语言模型在六个长度区间进行了详细实验。该工作贡献了LIFBench和LIFEval作为评估大型语言模型在复杂和长上下文设置中性能的强大工具。

**Conclusion:** LIFBench和LIFEval为评估大型语言模型在复杂和长上下文设置中的性能提供了强大的工具，为LLM未来的发展提供了宝贵的见解。

> **ai_Abstract:** 本文介绍了LIFBench，一个新颖的可扩展数据集和基准测试，以及LIFEval，一种基于评估标准的自动化评估方法，旨在解决评估大型语言模型（LLMs）在长上下文场景中指令遵循性能和稳定性方面的空白。LIFBench包含多样化的任务和指令，而LIFEval则允许在没有人或LLM干预的情况下进行精确的自动化评分。对20个LLM进行的实验证明了这些工具在为未来LLM发展提供见解方面的实用性。

> **摘要翻译:** 随着大型语言模型（LLMs）在自然语言处理（NLP）领域的演进，它们在长上下文输入中稳定遵循指令的能力对于实际应用至关重要。然而，现有基准测试很少关注长上下文场景中的指令遵循或不同输入下的稳定性。为了弥补这一空白，我们引入了LIFBench，这是一个可扩展的数据集，旨在评估LLM在长上下文中的指令遵循能力和稳定性。LIFBench包含三个长上下文场景和十一个不同任务，具有通过长度、表达和变量三个维度自动化扩展方法生成的2,766条指令。为了进行评估，我们提出了LIFEval，一种基于评估标准的评估方法，可以对复杂的LLM响应进行精确、自动评分，而无需依赖LLM辅助评估或人工判断。该方法允许从多个角度对模型性能和稳定性进行全面分析。我们对20个知名LLM在六个长度区间进行了详细实验。我们的工作贡献了LIFBench和LIFEval作为评估LLM在复杂和长上下文设置中性能的强大工具，为LLM未来的发展提供了宝贵见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [151] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
> *一套新的GloVe模型*

*Riley Carlson, John Bauer, Christopher D. Manning* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** GloVe, 词嵌入, 自然语言处理, NER, 语言演变

**Comment:** 

> **TL;DR:** 为了应对语言和世界的不断演变，并弥补旧模型文档不足的问题，本文介绍了新的2024年英语GloVe模型。这些模型使用更新的数据集训练，并在命名实体识别（NER）等任务上展现出改进的性能，同时在结构性任务上保持可比性。

**AI_Comments:** 该论文解决了语言模型需要定期更新的实际且重要需求，尤其考虑到语言和文化的快速演变。对数据和预处理的详细文档也比早期版本有了显著改进，增强了可复现性和可用性。在最近的、时间依赖的命名实体识别数据集上性能的提升，突显了这些模型与当前语言趋势的相关性。

<details>
  <summary>Details</summary>

**Motivation:** 2014年构建的原始GloVe模型虽然被广泛使用，但语言和世界不断演变，现有使用可以从更新的模型中受益。此外，2014年的模型缺乏对所用数据版本和预处理的详细文档。

**Method:** 研究人员使用维基百科、Gigaword和Dolma的一个子集训练了两组词嵌入。评估通过词汇比较、直接测试和命名实体识别（NER）任务进行。

**Result:** 2024年的向量包含了新的文化和语言相关词汇，在类比和相似性等结构性任务上表现相当，并在最近的、时间依赖的NER数据集（如非西方新闻数据）上表现出改进的性能。

**Conclusion:** 新的2024年英语GloVe模型成功地更新了旧模型，包含了新的词汇，并在特定任务上表现出更好的性能，同时解决了旧模型的文档不足问题。

> **ai_Abstract:** 本文介绍了新的2024年英语GloVe模型，旨在更新过时的2014年版本，并提供更详细的文档。这些模型使用维基百科、Gigaword和Dolma等更新的数据集进行训练。评估结果显示，新模型包含了与文化和语言相关的新词汇，在类比和相似性等结构性任务上表现与旧模型相当，并在最近的、时间依赖的命名实体识别（NER）数据集上展现出改进的性能。

> **摘要翻译:** 本报告记录、描述并评估了新的2024年英语GloVe（词表示的全局向量）模型。尽管2014年构建的原始GloVe模型已被广泛使用并被认为有用，但语言和世界仍在不断发展，我们认为当前的使用可以从更新的模型中受益。此外，2014年的模型没有仔细记录所使用的确切数据版本和预处理方法，我们通过记录这些新模型来纠正这一点。我们使用维基百科、Gigaword和Dolma的一个子集训练了两组词嵌入。通过词汇比较、直接测试和命名实体识别（NER）任务的评估表明，2024年的向量包含了新的文化和语言相关词汇，在类比和相似性等结构性任务上表现相当，并在最近的、时间依赖的NER数据集（如非西方新闻数据）上表现出改进的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [167] [A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects](https://arxiv.org/abs/2411.10371)
> *事件因果识别综述：分类、挑战、评估与展望*

*Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 事件因果识别, 自然语言处理, 综述, 深度学习, 大型语言模型

**Comment:** 

> **TL;DR:** 该综述系统地审视了事件因果识别（ECI）领域，包括其分类、模型、挑战、评估和未来方向。

**AI_Comments:** 这篇综述对于事件因果识别领域具有重要意义。它不仅提供了全面的分类和现有方法的详细回顾，还特别关注了多语言、跨语言和零样本ECI等前沿方向，并结合了LLM的应用，这对于该领域的未来发展具有指导作用。其对优缺点和挑战的分析，以及定量评估，为研究者提供了宝贵的参考。

<details>
  <summary>Details</summary>

**Motivation:** 事件因果识别（ECI）是自然语言处理（NLP）中的一项重要任务，旨在自动检测文本中的事件因果关系。随着该领域的发展，需要对现有概念、模型、挑战和未来方向进行系统性调查和评估。

**Method:** 该综述系统地调查了事件因果识别（ECI）的基本概念和模型，开发了一个系统分类法，并批判性地评估了各种模型。它定义了核心概念，形式化了ECI问题，概述了标准评估协议，并将ECI模型分为句子级（SECI）和文档级（DECI）任务。对于SECI，回顾了基于特征模式匹配、机器学习分类器、深度语义编码、基于提示的微调和因果知识预训练的模型，以及数据增强策略。对于DECI，关注了利用深度语义编码、事件图推理和基于提示的微调的方法。特别关注了多语言、跨语言ECI以及利用大型语言模型（LLMs）的零样本ECI的最新进展。对每种方法的优缺点和未解决的挑战进行了分析，并在四个基准数据集上进行了广泛的定量评估。

**Result:** 综述系统地分类了ECI模型为句子级（SECI）和文档级（DECI）任务，并详细审视了这两类任务下的各种方法（包括基于特征模式匹配、机器学习、深度语义编码、提示微调、知识预训练、事件图推理等）。它分析了每种方法的优缺点和未解决的挑战，并通过在四个基准数据集上进行定量评估来评估各种ECI模型的性能。

**Conclusion:** 该综述讨论了未来的研究方向，并强调了进一步推进该领域的机会。

> **ai_Abstract:** 这篇综述全面探讨了自然语言处理中的事件因果识别（ECI）任务。它建立了一个系统分类法，将ECI模型划分为句子级和文档级任务，并详细回顾了各类模型（包括传统方法和基于深度学习、LLM的方法）。文章分析了现有方法的优缺点和挑战，并进行了定量评估。最后，展望了未来的研究方向。

> **摘要翻译:** 事件因果识别（ECI）已成为自然语言处理（NLP）中的一项重要任务，专注于自动检测文本中的事件因果关系。这项全面的综述系统地调查了基本概念和模型，开发了一个系统分类法并批判性地评估了各种模型。我们首先定义了核心概念，形式化了ECI问题，并概述了标准评估协议。我们的分类框架将ECI模型分为两个主要任务：句子级事件因果识别（SECI）和文档级事件因果识别（DECI）。对于SECI，我们回顾了采用特征模式匹配、机器学习分类器、深度语义编码、基于提示的微调以及因果知识预训练的模型，以及数据增强策略。对于DECI，我们专注于利用深度语义编码、事件图推理和基于提示的微调的方法。特别关注了多语言和跨语言ECI的最新进展，以及利用大型语言模型（LLM）的零样本ECI。我们分析了每种方法的优点、局限性和未解决的挑战。在四个基准数据集上进行了广泛的定量评估，以严格评估各种ECI模型的性能。最后，我们讨论了未来的研究方向，并强调了进一步推进该领域的机会。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [173] [Quantifying the Uniqueness and Divisiveness of Presidential Discourse](https://arxiv.org/abs/2401.01405)
> *衡量总统言论的独特性和分裂性*

*Karen Zhou, Alexander A. Meitus, Milo Chase, Grace Wang, Anne Mykland, William Howell, Chenhao Tan* | **Category: cs.CL, cs.AI, cs.CY, cs.SI** | **Updated: 2025-07-23**

**Keywords:** 总统言论, 独特性, 分裂性, 大型语言模型, 唐纳德·特朗普

**Comment:** Published in PNAS Nexus:
  https://academic.oup.com/pnasnexus/article/3/10/pgae431/7814873

> **TL;DR:** 本文提出了一种衡量总统言论独特性的新方法，并发现唐纳德·特朗普的言论模式与近期其他主要政党总统候选人显著不同，尤其在于其分裂性和对抗性语言。

**AI_Comments:** 本文的创新之处在于引入了基于大型语言模型的新颖指标来量化言论独特性，并专门开发了分裂性言论词典，为分析政治话语提供了新的工具和视角。其重要性在于揭示了特定政治人物言论模式的显著特点，为理解当代政治沟通和极化现象提供了实证证据。

<details>
  <summary>Details</summary>

**Motivation:** 调查美国总统的言论是否存在可辨别的差异，以及这些差异的性质和是否局限于特定沟通媒介。

**Method:** 引入基于大型语言模型的独特性新指标，开发分裂性言论新词典，并提出评估总统描述政治对手独特方式的框架。将这些工具应用于总统演讲语料库。

**Result:** 发现唐纳德·特朗普的言论模式与近期所有主要政党总统候选人显著不同，他比共和党同僚更具独特性。其差异归因于使用了分裂性和对抗性语言，尤其针对政治对手。这些差异在多种测量策略、竞选活动和官方演讲中均成立，并非总统沟通世俗变化的产物。

**Conclusion:** 美国总统的言论存在显著差异，特别是唐纳德·特朗普的言论模式具有独特的独特性和分裂性，这与他使用对抗性语言有关。

> **ai_Abstract:** 本文通过引入基于大型语言模型的独特性指标、开发分裂性言论词典以及构建评估总统言论特征的框架，研究了美国总统言论的独特性和分裂性。研究发现，唐纳德·特朗普的言论模式与近期其他主要政党总统候选人显著不同，其独特性高于共和党同僚，且其分裂性和对抗性语言是造成这些差异的关键因素，尤其体现在针对政治对手时。这些发现适用于不同沟通场合和测量方法。

> **摘要翻译:** 美国总统的言论是否彼此之间存在明显差异？如果存在，以何种方式存在？这些差异是否仅限于单一的沟通媒介？为了调查这些问题，本文引入了一种基于大型语言模型的独颖性新指标，开发了一个用于分裂性言论的新词汇表，并提出了一个评估总统以独特方式谈论其政治对手的框架。将这些工具应用于各种总统演讲语料库后，我们发现了大量证据表明唐纳德·特朗普的言论模式与近期历史上所有主要政党总统候选人的言论模式存在显著差异。特朗普比他的共和党同僚更具独特性，其独特性值似乎更接近民主党人。造成这些差异的原因是特朗普使用了分裂性和对抗性语言，尤其是在针对其政治对手时。这些差异在各种测量策略中均成立，出现在竞选活动和官方总统讲话中，并且似乎并非总统沟通中世俗变化的产物。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [174] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
> *大型语言模型信念更新与贝叶斯定理一致吗？*

*Sohaib Imran, Ihor Kendiukhov, Matthew Broerman, Aditya Thomas, Riccardo Campanella, Rob Lamb, Peter M. Atkinson* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 贝叶斯定理, 信念更新, 贝叶斯一致性系数, 模型能力

**Comment:** Accepted at the ICML 2025 Workshop on Assessing World Models

> **TL;DR:** 研究发现，更大、能力更强的预训练语言模型在信念更新方面与贝叶斯定理更一致。

**AI_Comments:** 这篇论文通过引入贝叶斯一致性系数（BCC）这一创新指标，量化评估了LLM信念更新的贝叶斯一致性，为理解LLM的推理能力提供了一个新的视角。其重要性在于揭示了LLM规模与贝叶斯理性之间的潜在关联，可能对未来LLM的设计和应用有指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 探讨大型语言模型在接收上下文证据时，其“信念”更新是否更符合贝叶斯定理。

**Method:** 1. 提出了贝叶斯一致性系数（BCC）指标。 2. 生成了用于测量BCC的数据集。 3. 测量了来自五个模型家族的多个仅预训练语言模型的BCC。 4. 将BCC与模型参数数量、训练数据量以及常见基准测试分数进行比较。

**Result:** 结果支持了作者的假设，即更大、能力更强的预训练语言模型在信念分配上与贝叶斯定理更一致。

**Conclusion:** 研究表明，大型语言模型在信念更新方面与贝叶斯定理的一致性随模型规模和能力增长而提高，这对理解和管理LLM具有重要意义。

> **ai_Abstract:** 这项研究旨在探究大型语言模型（LLM）的“信念”更新是否与贝叶斯定理一致，尤其是在模型规模和能力增强的情况下。研究人员为此提出了贝叶斯一致性系数（BCC）指标，并构建了相应的数据集。他们对多个预训练LLM进行了测试，并发现规模更大、能力更强的LLM在分配置信度时与贝叶斯定理表现出更高的一致性。这些发现对深入理解和有效管理LLM具有重要的理论和实践意义。

> **摘要翻译:** 较大的、能力更强的语言模型在提供上下文证据时，是否会学着更一致地根据贝叶斯定理更新它们对命题的“信念”？为了验证这一点，我们制定了一个贝叶斯一致性系数（BCC）指标，并生成了一个用于测量BCC的数据集。我们测量了来自五个模型家族的多个仅预训练语言模型的BCC，并将其与模型参数数量、训练数据量以及常见基准测试分数进行比较。我们的结果为我们的假设提供了证据，即更大、能力更强的预训练语言模型分配的置信度与贝叶斯定理更一致。这些结果对我们理解和管理大型语言模型具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [184] [The Moral Gap of Large Language Models](https://arxiv.org/abs/2507.18523)
> *大型语言模型的道德鸿沟*

*Maciej Skorski, Alina Landowska* | **Category: cs.CL, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 道德推理, 道德鸿沟, 微调, 提示工程

**Comment:** preprint

> **TL;DR:** 大型语言模型在道德推理方面存在显著性能差距，任务特定微调优于提示工程。

**AI_Comments:** 这项研究揭示了大型语言模型在道德推理方面的一个重要局限性，即所谓的“道德鸿沟”。它强调了在开发负责任和符合道德的AI系统时，不能仅依赖于通用LLMs的提示工程能力，而任务特定微调仍然是提高其道德判断准确性的关键。这对于AI伦理和LLM的应用边界具有重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 道德基础检测对于分析社会话语和开发符合道德规范的AI系统至关重要。尽管大型语言模型在各种任务中表现出色，但它们在专门道德推理方面的表现仍不清楚，因此需要进行全面比较。

**Method:** 本研究首次全面比较了最先进的大型语言模型（LLMs）和微调的Transformer模型，使用了Twitter和Reddit数据集，并通过ROC、PR和DET曲线分析进行评估。

**Result:** 结果显示存在显著的性能差距，尽管进行了提示工程，LLMs仍表现出高假阴性率和对道德内容的系统性低检测。这表明LLMs在道德推理方面存在“道德鸿沟”。

**Conclusion:** 任务特定的微调在道德推理应用中仍然优于提示工程。

> **ai_Abstract:** 本研究首次对大型语言模型（LLMs）在道德推理方面的表现进行了全面评估，并与任务特定微调的Transformer模型进行了比较。研究发现，尽管LLMs在一般任务中表现出色，但在道德内容检测上存在显著的“道德鸿沟”，表现为高假阴性率和系统性低检测。研究结论指出，在道德推理应用中，任务特定微调仍然优于提示工程。

> **摘要翻译:** 道德基础检测对于分析社会话语和开发符合道德规范的AI系统至关重要。尽管大型语言模型在各种任务中表现出色，但它们在专门道德推理方面的表现仍不清楚。
本研究首次全面比较了最先进的大型语言模型（LLMs）和微调的Transformer模型，使用了Twitter和Reddit数据集，并通过ROC、PR和DET曲线分析进行评估。
结果显示存在显著的性能差距，尽管进行了提示工程，LLMs仍表现出高假阴性率和对道德内容的系统性低检测。这些发现表明，任务特定的微调在道德推理应用中仍然优于提示工程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [186] [MathOPEval: A Fine-grained Evaluation Benchmark for Visual Operations of MLLMs in Mathematical Reasoning](https://arxiv.org/abs/2507.18140)
> *MathOPEval：一个用于多模态大语言模型在数学推理中视觉操作的细粒度评估基准*

*Xiaoyuan Li, Moxin Li, Wenjie Wang, Rui Men, Yichang Zhang, Fuli Feng, Dayiheng Liu, Junyang Lin* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 多模态大语言模型, 数学推理, 视觉操作, 代码生成, 评估基准

**Comment:** Under Review

> **TL;DR:** 本文提出了MathOPEval，一个评估多模态大语言模型(MLLMs)在数学推理中通过代码执行视觉操作能力的基准，发现现有模型在细粒度视觉操作方面远低于人类表现。

**AI_Comments:** 本文通过MathOPEval基准填补了多模态大语言模型(MLLMs)评估中的一个重要空白，即其通过代码执行视觉操作的能力。其创新之处在于提出了多模态代码生成和编辑这两个细粒度评估维度，并构建了涵盖多种数学图形的综合数据集。这项工作对于推动MLLMs在复杂数学推理中视觉交互能力的进步具有重要意义，揭示了当前模型的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型(MLLMs)评估主要关注文本推理输出，忽略了MLLM通过代码执行精确视觉操作的能力。本文旨在填补这一空白，评估MLLM在多模态数学推理中基于代码的视觉能力。

**Method:** 本文提出了一个评估框架，专注于两个关键评估方面：1) 多模态代码生成(MCG)，评估模型从头开始准确理解和构建可视化的能力；2) 多模态代码编辑(MCE)，评估模型细粒度操作的能力，包括删除、修改和注释。为此，构建了一个包含五种最流行数学图形（几何图、函数图和三种统计图表）的数据集，并对九个主流MLLM进行了实验评估。

**Result:** 实验结果表明，现有模型在执行细粒度视觉操作方面与人类表现存在显著差距。

**Conclusion:** 现有的多模态大语言模型在通过代码进行细粒度视觉操作方面表现不佳，远未达到人类水平，这表明未来需要在此领域进行大量改进。

> **ai_Abstract:** 本文提出了MathOPEval，一个专门用于评估多模态大语言模型（MLLMs）在数学推理中视觉操作能力的细粒度基准。针对现有评估忽视MLLM通过代码执行视觉操作的不足，该工作引入了多模态代码生成（MCG）和多模态代码编辑（MCE）两大评估维度，后者细分为删除、修改和注释操作。通过构建一个包含五种常见数学图形的数据集，并对九个主流MLLM进行测试，研究发现当前模型在细粒度视觉操作方面与人类表现存在显著差距。

> **摘要翻译:** 多模态大语言模型（MLLMs）的最新进展使得通过基于文本指令执行视觉操作来实现逐步多模态数学推理成为可能。一种有前途的方法是使用代码作为中间表示来精确表达和操作推理步骤中的图像。然而，现有评估主要关注纯文本推理输出，使得MLLM通过代码执行精确视觉操作的能力在很大程度上未被探索。这项工作迈出了解决这一空白的第一步，通过评估MLLM在多模态数学推理中基于代码的能力。具体而言，我们的框架侧重于两个关键评估方面：（1）多模态代码生成（MCG）评估模型从头开始准确理解和构建可视化的能力。（2）多模态代码编辑（MCE）评估模型进行细粒度操作的能力，包括三种类型：删除、修改和注释。为了评估上述任务，我们纳入了一个涵盖五种最流行数学图形（包括几何图、函数图和三种统计图表）的数据集，以提供对现有MLLM的全面有效测量。我们的实验评估涉及九个主流MLLM，结果显示现有模型在执行细粒度视觉操作方面仍显著落后于人类表现。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [192] [BlockDialect: Block-wise Fine-grained Mixed Format Quantization for Energy-Efficient LLM Inference](https://arxiv.org/abs/2501.01144)
> *BlockDialect：块级细粒度混合格式量化用于能效LLM推理*

*Wonsuk Jang, Thierry Tambe* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 量化, LLM推理, 能效, 混合格式, DialectFP4

**Comment:** ICML 2025

> **TL;DR:** BlockDialect提出一种块级细粒度混合格式量化方法，通过适应数据分布的FP4变体提高LLM推理的能效和精度。

**AI_Comments:** 本文的创新点在于提出了“块级细粒度混合格式量化”的概念，并引入了“DialectFP4”这一独特的FP4变体集合，以更好地适应复杂的数据分布，而非仅仅依赖于缩放因子。这种“如何表示”的视角为LLM的能效推理开辟了新路径，对于降低大型模型部署的内存和计算成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的规模迅速增长，导致内存使用和计算成本面临巨大挑战。现有量化方法难以捕捉细微的块数据分布。

**Method:** 提出BlockDialect，一种块级细粒度混合格式技术，为每个数据块从格式本中分配最优数值格式以实现更好的数据表示。引入DialectFP4，一个包含FP4变体（类似于方言）的格式本，以适应多样化的数据分布。为有效利用，提出两阶段在线DialectFP4激活量化方法。DialectFP4通过选择可表示的值作为与低精度整数算术兼容的缩放整数来确保能效。

**Result:** BlockDialect在LLaMA3-8B (LLaMA2-7B) 模型上比MXFP4格式实现了10.78% (7.48%) 的精度提升，同时每数据位使用率更低。即使在量化全路径矩阵乘法时，其精度也仅比全精度低5.45% (2.69%)。

**Conclusion:** 本工作专注于如何表示而非如何缩放，为能效LLM推理提供了一条有前景的路径。

> **ai_Abstract:** 本文提出BlockDialect，一种用于能效LLM推理的块级细粒度混合格式量化技术。针对现有方法难以捕捉复杂块数据分布的问题，BlockDialect通过为每个数据块从预设的“格式本”中选择最优数值格式来改进数据表示。为此，作者引入了DialectFP4，一个包含多种FP4变体的格式本，以适应不同的数据分布，并设计了两阶段在线激活量化方法。该方法通过选择与低精度整数算术兼容的值来确保能效。实验结果显示，BlockDialect在LLaMA3-8B和LLaMA2-7B模型上相比MXFP4格式实现了显著的精度提升，同时保持了较低的位使用率，并展现出接近全精度的性能。

> **摘要翻译:** 大型语言模型（LLMs）规模的迅速增长对内存使用和计算成本带来了巨大挑战。量化权重和激活可以解决这些问题，其中硬件支持的细粒度缩放作为一种有前景的解决方案，可以缓解异常值问题。然而，现有方法难以捕捉细微的块数据分布。我们提出BlockDialect，一种块级细粒度混合格式技术，它为每个数据块从格式本中分配最优数值格式以实现更好的数据表示。此外，我们引入了DialectFP4，一个包含FP4变体（类似于方言）的格式本，可以适应多样化的数据分布。为了有效利用这一点，我们提出了一种用于在线DialectFP4激活量化的两阶段方法。重要的是，DialectFP4通过选择可表示的值作为与低精度整数算术兼容的缩放整数来确保能效。与MXFP4格式相比，BlockDialect在LLaMA3-8B (LLaMA2-7B) 模型上实现了10.78% (7.48%) 的精度提升，同时每数据位使用率更低，并且即使在量化全路径矩阵乘法时，也仅比全精度低5.45% (2.69%)。我们的工作侧重于如何表示而非如何缩放，为能效LLM推理提供了一条有前景的路径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [216] [Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs](https://arxiv.org/abs/2502.12988)
> *超越表象：从表面事实到大型语言模型中的深度角色模拟*

*Zixiao Wang, Duzhen Zhang, Ishita Agrawal, Shen Gao, Le Song, Xiuying Chen* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 角色模拟, 大型语言模型, CharacterBot, 思想模式, CharLoRA

**Comment:** Accepted by ACL 2025 Findings

> **TL;DR:** CharacterBot是一个旨在模拟角色语言和思想模式的LLM，通过对鲁迅作品的预训练和微调（问答、风格迁移）实现，并引入CharLoRA机制优化学习，在语言准确性和观点理解上优于基线。

**AI_Comments:** 本文的创新之处在于超越了传统LLM角色模拟的表面层次，深入探索了对个体思想模式的模拟。通过引入CharacterBot模型和基于鲁迅作品的独特训练任务（特别是深层思想对齐的微调任务），以及CharLoRA优化机制，为更逼真、更复杂的角色模拟提供了新颖的途径。其重要性在于推动了LLM在个性化和情感智能方面的发展，为文学分析、虚拟伴侣等应用场景提供了潜力。同时，作者也提及了伦理标准的重要性，体现了对未来研究潜在影响的考量。

<details>
  <summary>Details</summary>

**Motivation:** 以往的角色模拟大型语言模型（LLMs）主要依赖于学习基本的传记信息或有限的角色扮演对话数据集，但作者认为对个体的全面表征应超越表面事实和对话，深入到更深层的思想和思维。

**Method:** 本文引入了CharacterBot模型，旨在复制角色的语言模式和独特的思想模式。以中国作家鲁迅为例，提出了四项训练任务：一项专注于掌握外部语言结构和知识的预训练任务，以及三项微调任务：多项选择问答、生成式问答和风格迁移，旨在使LLM与鲁迅的内部思想和写作风格对齐。为优化跨任务学习，引入了CharLoRA参数更新机制，其中通用语言风格专家与其他特定任务专家协作，以更好地研究语言风格和对深层思想的理解。

**Result:** CharacterBot在语言准确性和观点理解的三个任务上进行了评估，结果表明它在作者调整的指标上显著优于基线模型。

**Conclusion:** 这项工作有望启发未来关于深度角色个性模拟LLM的研究，同时强调了伦理标准的重要性。

> **ai_Abstract:** 本文提出CharacterBot，一个用于大型语言模型（LLMs）深度角色模拟的模型。与以往仅依赖表面事实和对话的方法不同，CharacterBot旨在捕捉角色的深层思想和独特的语言模式。以鲁迅作品为案例，模型通过预训练和多项选择问答、生成式问答、风格迁移等微调任务学习，并引入CharLoRA机制优化语言和思想理解。实验结果表明，CharacterBot在语言准确性和观点理解方面显著优于基线。

> **摘要翻译:** 以往的角色模拟大型语言模型（LLMs）通常依赖于学习基本的传记信息，或使用有限的角色扮演对话数据集来捕捉角色的回应。然而，对个体的全面表征超越了表面事实或对话，深入到更深层的思想和思维。在这项工作中，我们引入了CharacterBot，一个旨在复制角色文本作品中体现的语言模式和独特的思想模式的模型。以著名中国作家鲁迅为案例研究，我们提出了源自其17部散文集的四项训练任务。其中包括一项专注于掌握外部语言结构和知识的预训练任务，以及三项微调任务：多项选择问答、生成式问答和风格迁移，每项任务都使LLM与鲁迅的内部思想和写作风格对齐。为了优化这些任务的学习，我们引入了一种CharLoRA参数更新机制，其中通用语言风格专家与其他特定任务专家协作，以更好地研究语言风格和对深层思想的理解。我们评估了CharacterBot在三个语言准确性和观点理解任务上的表现，结果表明它在我们调整的指标上显著优于基线。我们希望这项工作能启发未来关于深度角色个性模拟LLMs的研究，同时考虑伦理标准的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [219] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
> *提格利尼亚语的自然语言处理：现状与未来方向*

*Fitsum Gaim, Jong C. Park* | **Category: cs.CL, cs.AI, I.2.7** | **Updated: 2025-07-23**

**Keywords:** 提格利尼亚语, 自然语言处理, 调查, 低资源语言, 形态复杂性

**Comment:** 

> **TL;DR:** Despite Tigrinya being spoken by millions, its NLP research is severely underrepresented. This paper surveys over 40 studies from 2011-2025, analyzing resources, models, and applications. It identifies challenges like morphological complexity and resource scarcity, and proposes future directions such as morphology-aware modeling and cross-lingual transfer, serving as a reference and roadmap.

**AI_Comments:** 这项调查工作对于提格利尼亚语NLP领域具有重要意义，因为它系统地梳理了该语言NLP研究的现状，并明确指出了未来的发展方向和挑战。特别值得称赞的是，它不仅提供了全面的文献综述，还强调了资源创建的重要性，并提出了具体的、可行的研究路径，如形态感知建模和跨语言迁移，这对于资源匮乏的低资源语言NLP研究具有普遍的指导意义。公开元数据也促进了社区的协作。

<details>
  <summary>Details</summary>

**Motivation:** 尽管提格利尼亚语有数百万使用者，但其在自然语言处理（NLP）研究中严重缺乏代表性。这项工作旨在全面调查提格利尼亚语的NLP研究现状，并为未来的发展提供路线图。

**Method:** 本文对2011年至2025年间超过40项提格利尼亚语NLP研究进行了全面调查，系统性地回顾了计算资源、模型和跨十个不同下游任务（包括形态处理、机器翻译、语音识别和问答）的应用现状。

**Result:** 分析揭示了从基础的、基于规则的系统到现代神经网络架构的清晰发展轨迹，进展持续通过资源创建里程碑得以实现。研究还指出了提格利尼亚语形态复杂性和资源稀缺性带来的关键挑战。

**Conclusion:** 提格利尼亚语NLP研究正从基于规则的系统向神经网络架构发展，资源创建是关键驱动因素。未来的研究应关注形态感知建模、跨语言迁移和社区驱动的资源开发，以克服形态复杂性和资源稀缺性挑战。这项工作为研究人员提供了全面的参考和前进的路线图。

> **ai_Abstract:** 本文对提格利尼亚语的自然语言处理（NLP）研究进行了全面调查，分析了2011年至2025年间的40多项研究。文章回顾了计算资源、模型和在形态处理、机器翻译、语音识别、问答等十个下游任务中的应用现状。研究发现，提格利尼亚语NLP的发展轨迹是从基于规则的系统转向现代神经网络架构，且进展与资源创建密切相关。论文指出了形态复杂性和资源稀缺是主要挑战，并提出了形态感知建模、跨语言迁移和社区资源开发等未来研究方向。该工作旨在为研究人员提供参考和发展路线图。

> **摘要翻译:** 尽管提格利尼亚语有数百万人使用，但它在自然语言处理（NLP）研究中仍然严重缺乏代表性。这项工作对提格利尼亚语的NLP研究进行了全面调查，分析了2011年至2025年十多年间的40多项研究。我们系统地回顾了计算资源、模型以及跨十个不同下游任务（包括形态处理、机器翻译、语音识别和问答）的应用现状。我们的分析揭示了从基础的、基于规则的系统到现代神经网络架构的清晰发展轨迹，进展持续通过资源创建里程碑得以解锁。我们指出了提格利尼亚语形态复杂性和资源稀缺性所带来的关键挑战，同时强调了有前景的研究方向，包括形态感知建模、跨语言迁移和以社区为中心的资源开发。这项工作既可以作为研究人员的全面参考，也可以作为推动提格利尼亚语NLP的路线图。所调查研究和资源的精选元数据已公开提供。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [225] [CLEAR: Error Analysis via LLM-as-a-Judge Made Easy](https://arxiv.org/abs/2507.18392)
> *CLEAR：让基于LLM评判的错误分析变得简单*

*Asaf Yehudai, Lilach Eden, Yotam Perlitz, Roy Bar-Haim, Michal Shmueli-Scheuer* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM评估, 错误分析, LLM评判者, 交互式工具, 开源

**Comment:** 

> **TL;DR:** CLEAR是一个开源交互式工具包，用于通过LLM作为评判者对LLM进行错误分析，提供详细的反馈和可视化，以揭示模型性能背后的具体原因，而非仅仅是单一分数。

**AI_Comments:** CLEAR的创新之处在于它提供了一个系统化的框架，将LLM-as-a-Judge的评估能力从简单的分数或排名提升到细致的错误分析层面。这对于理解LLM的行为模式、识别其弱点并指导模型改进至关重要。其开源和交互式仪表板的特性也大大降低了错误分析的门槛，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）的评估范式通常只提供单一分数或排名，回答“哪个模型更好”而非“为什么”，这掩盖了模型性能背后的具体、可操作的原因，阻碍了深入理解和改进模型。

**Method:** CLEAR是一个交互式开源包，用于基于LLM的错误分析。它首先生成每个实例的文本反馈，然后创建一套系统级错误问题，并量化每个已识别问题的普遍性。该包还提供一个交互式仪表板，允许通过聚合可视化进行全面的错误分析，应用交互式过滤器隔离特定问题或分数范围，并深入到代表特定行为模式的单个实例。

**Result:** 该研究在RAG（检索增强生成）和数学基准测试中展示了CLEAR的分析能力，并通过用户案例研究展示了其效用。

**Conclusion:** CLEAR提供了一种有效的方法，通过LLM作为评判者进行细致的错误分析，弥补了传统单一分数评估的不足，揭示了LLM性能背后的具体原因，从而有助于更深入地理解和改进模型。

> **ai_Abstract:** 本文介绍了CLEAR，一个开源交互式工具包，旨在弥补当前LLM评估中只提供单一分数而缺乏具体错误原因的不足。CLEAR利用LLM作为评判者，生成实例级文本反馈和系统级错误问题，并量化其普遍性。它还提供一个交互式仪表板，支持聚合可视化、过滤和深入分析，以揭示LLM性能背后的可操作原因。研究通过RAG和数学基准测试及用户案例研究展示了CLEAR的实用性。

> **摘要翻译:** 大型语言模型（LLM）的评估越来越依赖于其他LLM作为评判者。然而，当前的评估范式通常只产生一个单一的分数或排名，回答的是哪个模型更好，而不是为什么。虽然这对基准测试至关重要，但这些顶层分数掩盖了模型性能背后的具体、可操作的原因。为了弥补这一差距，我们引入了CLEAR，一个用于基于LLM的错误分析的交互式开源软件包。CLEAR首先生成每个实例的文本反馈，然后创建一套系统级错误问题，并量化每个已识别问题的普遍性。我们的软件包还为用户提供了一个交互式仪表板，允许通过聚合可视化进行全面的错误分析，应用交互式过滤器隔离特定问题或分数范围，并深入到代表特定行为模式的单个实例。我们在RAG和数学基准测试中展示了CLEAR的分析，并通过用户案例研究展示了其效用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [226] [TN-AutoRCA: Benchmark Construction and Agentic Framework for Self-Improving Alarm-Based Root Cause Analysis in Telecommunication Networks](https://arxiv.org/abs/2507.18190)
> *TN-AutoRCA：电信网络中基于告警的自改进根因分析的基准构建与智能体框架*

*Keyu Wu, Qianjin Yu, Manlin Mei, Ruiting Liu, Jun Wang, Kailai Zhang, Yelun Bao* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 根因分析, 电信网络, AI, 基准, 智能体框架

**Comment:** 10 pages

> **TL;DR:** 该论文旨在解决电信网络中基于告警的根因分析（RCA）对AI而言面临的复杂推理和基准稀缺的挑战。

**AI_Comments:** 该论文旨在解决AI在电信网络根因分析应用中的一个重要挑战，这对于网络稳定性和效率至关重要。其关注基准构建和自改进智能体框架，表明了克服数据稀缺性和复杂性的创新方法。

<details>
  <summary>Details</summary>

**Motivation:** 电信网络中的根因分析（RCA）是一项关键任务，但由于其复杂的、基于图的推理要求和缺乏现实基准，对人工智能（AI）提出了严峻挑战。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了TN-AutoRCA，一个用于电信网络中基于告警的自改进根因分析的基准构建与智能体框架。论文指出，由于复杂的基于图的推理需求和现实基准的稀缺性，电信网络中的根因分析对人工智能构成了严峻挑战。

> **摘要翻译:** 电信网络中的根因分析（RCA）是一项关键任务，但由于其复杂的、基于图的推理要求以及缺乏现实基准，它对人工智能（AI）提出了严峻的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [242] [ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models](https://arxiv.org/abs/2502.15487)
> *评估大型语言模型中的显式因果推理能力*

*Martina Miliani, Serena Auriemma, Alessandro Bondielli, Emmanuele Chersoni, Lucia Passaro, Irene Sucameli, Alessandro Lenci* | **Category: cs.CL, cs.AI, 68T50, 68T07, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 因果推理, 数据集, ExpliCa, 语言理解

**Comment:** Accepted for publication in Findings of ACL 2025

> **TL;DR:** 引入ExpliCa数据集评估LLM的显式因果推理能力，发现即使是顶级模型也表现不佳，且易混淆因果与时间关系，性能受语言顺序和模型大小影响。

**AI_Comments:** 该研究创新性地提出了ExpliCa数据集，专门用于评估LLM的显式因果推理能力，填补了现有评估的空白。其发现LLM在理解因果关系时易受时间关系和语言顺序干扰，揭示了当前LLM在深层语义理解方面的局限性，对未来LLM的改进方向具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在需要解释和推理准确性的任务中应用日益广泛，因此需要有效评估其显式因果推理能力。

**Method:** 本文引入了名为ExpliCa的新数据集，用于评估LLM的显式因果推理能力。该数据集独特地整合了以不同语言顺序呈现并由语言连接词明确表达的因果和时间关系，并富含众包的人类可接受度评分。研究通过提示和基于困惑度的指标测试了七个商业和开源LLM。

**Result:** 研究显示，即使是顶级LLM也难以在ExpliCa数据集上达到0.80的准确率。模型倾向于将时间关系与因果关系混淆，并且其性能受到事件语言顺序的强烈影响。此外，基于困惑度的分数和提示性能受模型大小的不同影响。

**Conclusion:** 大型语言模型在显式因果推理方面存在显著不足，尤其是在区分因果与时间关系以及处理不同语言顺序时。模型大小对不同评估指标的影响方式也有所不同。

> **ai_Abstract:** 本文推出了ExpliCa数据集，旨在评估大型语言模型（LLM）的显式因果推理能力。该数据集包含了结合因果和时间关系的语言实例，并附带人类评分。研究测试了七种LLM，发现即使是先进模型在因果推理方面也表现不佳，准确率低于0.80。模型普遍将因果与时间关系混淆，且性能受语言顺序和模型大小的影响。

> **摘要翻译:** 大型语言模型（LLM）越来越多地应用于需要解释和推理准确性的任务中。在本文中，我们介绍了ExpliCa，这是一个用于评估LLM显式因果推理能力的新数据集。ExpliCa独特地整合了以不同语言顺序呈现并由语言连接词明确表达的因果和时间关系。该数据集通过众包的人类可接受度评分得到丰富。我们通过提示和基于困惑度的指标在ExpliCa上测试了LLM。我们评估了七个商业和开源LLM，结果显示即使是顶级模型也难以达到0.80的准确率。有趣的是，模型倾向于将时间关系与因果关系混淆，并且它们的表现也受到事件语言顺序的强烈影响。最后，基于困惑度的分数和提示性能受模型大小的不同影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [255] [Integrating an ISO30401-compliant Knowledge management system with existing business processes of an organization](https://arxiv.org/abs/2507.18197)
> *将符合ISO30401标准的知识管理系统与组织现有业务流程整合*

*Aline Belloni, Patrick Prieur* | **Category: cs.CL, cs.DL** | **Updated: 2025-07-24**

**Keywords:** ISO30401, 知识管理系统, 业务流程整合, SECI模型, PDCA循环

**Comment:** in French language. AGeCSO2025 : 18{\`e}me Colloque International de
  l'Association pour la Gestion des Connaissances dans la Soci{\'e}t{\'e} et
  les Organisations, Association pour la Gestion des Connaissances dans la
  Soci{\'e}t{\'e} et les Organisations (AGECSO), Jun 2025, TROYES, France

> **TL;DR:** 本文基于作者经验，探讨了如何将符合ISO30401标准的知识管理系统与组织的现有业务流程整合，并阐述了通过SECI模型和PDCA循环实现整合的方法。

**AI_Comments:** 本文聚焦于ISO30401知识管理标准与现有业务流程的实际整合问题，具有较强的实践指导意义。其创新之处在于结合了SECI模型和PDCA循环来提供具体的实施框架，这对于面临知识管理系统落地挑战的企业而言，提供了宝贵的经验借鉴。文章基于“实施者”的经验而非纯粹的理论分析，使其更具说服力。

<details>
  <summary>Details</summary>

**Motivation:** 组织在将ISO30401中描述的知识开发、转化和传递活动与现有运营流程整合时面临挑战，本文旨在解决这一问题。

**Method:** 本文回顾了ISO9001背景下的流程建模原则，并基于作者的经验，探讨了符合ISO30401标准的知识管理系统如何与集成管理系统的其他流程相结合，特别是如何通过SECI模型和PDCA循环的步骤来部署实现。

**Result:** 文章基于经验探索了ISO30401兼容的知识管理系统如何与集成管理系统的所有其他流程相结合，并提出了通过SECI模型机制和PDCA循环步骤实现其部署的方法。

**Conclusion:** 本文总结了ISO9001背景下的流程建模原则，并根据经验探讨了如何将符合ISO30401标准的知识管理系统与现有业务流程整合，特别是通过SECI模型和PDCA循环实现其部署。

> **ai_Abstract:** 本文探讨了将符合ISO30401标准的知识管理系统（KMS）与组织现有业务流程整合的挑战与方法。文章首先回顾了ISO9001背景下的业务流程建模原则，随后基于作者的实践经验，详细阐述了KMS如何与集成管理系统的其他流程协同工作，并提出了通过SECI模型和PDCA循环来实现KMS部署和整合的具体途径。

> **摘要翻译:** 大多数组织都使用业务流程建模作为确保员工工作效率和有效性以及工作流程与战略目标保持一致的基本框架。对于符合或接近符合ISO 9001的组织，这种方法涉及流程、子流程、活动和任务的详细映射。ISO30401是2018年引入的管理体系标准，为组织中知识管理系统的建立设定了通用要求。作为“ISO30401实施者”，我们经常面临向客户解释ISO30401中描述的知识开发、转化和传递活动如何与现有运营流程整合的挑战。本文回顾了ISO9001背景下的流程建模原则，并根据我们的经验，探讨了符合ISO30401标准的知识管理系统（KMS）如何与集成管理系统的所有其他流程交织在一起，特别是如何通过部署SECI模型的机制通过PDCA循环的步骤来实现。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [260] [AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data](https://arxiv.org/abs/2507.18442)
> *AraTable：基准测试大型语言模型对阿拉伯语表格数据的推理和理解能力*

*Rana Alshaikh, Israa Alghanmi, Shelan Jeawak* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 阿拉伯语表格数据, 大型语言模型, 基准测试, 认知能力, 自动化评估

**Comment:** 

> **TL;DR:** AraTable是一个新的基准测试，用于评估LLM在阿拉伯语表格数据上的推理和理解能力。研究发现LLM在简单任务上表现良好，但在复杂推理和事实验证任务上仍面临挑战。该研究还提出了一个自动化评估框架。

**AI_Comments:** AraTable的创新之处在于填补了阿拉伯语表格数据基准测试的空白，这对促进LLM在非英语语言环境下的发展至关重要。其混合数据生成管道（LLM生成+人工验证）确保了数据集的质量和可靠性。研究结果明确指出了LLM在复杂推理任务上的局限性，为未来的研究指明了方向。自动化评估框架的提出也大大提高了评估效率和可重复性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在自然语言处理方面取得了显著进展，但它们在解释结构化数据（尤其是表格格式）方面的性能仍然有限。针对英语表格数据的基准测试广泛可用，但阿拉伯语由于公共资源有限和其独特的语言特征而代表性不足。为了弥补这一空白，本研究提出了AraTable。

**Method:** 本研究提出了AraTable，一个新颖且全面的基准测试，旨在评估LLM应用于阿拉伯语表格数据时的推理和理解能力。AraTable包含多种评估任务，如直接问答、事实验证和复杂推理，涉及广泛的阿拉伯语表格来源。其方法遵循混合管道，初始内容由LLM生成，随后由人类专家过滤和验证以确保数据集质量。研究还提出了一个使用自审议机制的完全自动化评估框架。

**Result:** 使用AraTable的初步分析表明，LLM在直接问答等简单表格任务上表现足够好，但在需要更深层次推理和事实验证的任务上仍面临显著的认知挑战。这表明未来在改进复杂表格推理任务性能方面存在巨大机会。此外，所提出的自动化评估框架实现了与人类评判几乎相同的性能。

**Conclusion:** 本研究提供了一个有价值的、可公开获取的资源和评估框架，可以帮助加速处理和分析阿拉伯语结构化数据的基础模型的发展。LLM在复杂阿拉伯语表格推理任务上仍有很大的改进空间。

> **ai_Abstract:** 本论文介绍了AraTable，一个专门为评估大型语言模型（LLMs）在阿拉伯语表格数据上的推理和理解能力而设计的综合基准测试。该基准测试包含直接问答、事实验证和复杂推理等多种任务，并采用LLM生成结合人工验证的混合管道来确保数据质量。初步结果显示，LLMs在简单任务上表现尚可，但在需要深度推理的复杂表格任务上仍有待提高。论文还提出了一个高效的自动化评估框架。这项工作为阿拉伯语结构化数据处理领域提供了重要的公共资源和评估工具。

> **摘要翻译:** 大型语言模型（LLMs）的认知和推理能力使得自然语言处理取得了显著进展。然而，它们在解释结构化数据，尤其是在表格格式方面的性能仍然有限。尽管英语表格数据的基准测试广泛可用，但阿拉伯语由于公共资源有限及其独特的语言特征而代表性不足。为了弥补这一空白，我们提出了AraTable，这是一个新颖而全面的基准测试，旨在评估LLMs应用于阿拉伯语表格数据时的推理和理解能力。AraTable包含各种评估任务，如直接问答、事实验证和复杂推理，涉及广泛的阿拉伯语表格来源。我们的方法遵循混合管道，其中初始内容由LLMs生成，随后由人类专家过滤和验证，以确保高数据集质量。使用AraTable的初步分析表明，虽然LLMs在直接问答等简单表格任务上表现足够好，但当任务需要更深层次的推理和事实验证时，它们继续面临显著的认知挑战。这表明未来在提高复杂表格推理任务性能方面存在大量机会。我们还提出了一个完全自动化的评估框架，该框架使用自审议机制，并实现了与人类评判几乎相同的性能。这项研究提供了一个有价值的、可公开获取的资源和评估框架，可以帮助加速处理和分析阿拉伯语结构化数据的基础模型的发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [266] [Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data](https://arxiv.org/abs/2502.18679)
> *不依赖奖励模型和人类偏好数据的生成式大型语言模型的判别式微调*

*Siqi Guo, Ilgee Hong, Vicente Balmaseda, Changlong Yu, Liang Qiu, Xin Liu, Haoming Jiang, Tuo Zhao, Tianbao Yang* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 判别式微调, 大型语言模型, 监督微调, 偏好优化, 奖励模型

**Comment:** 18 pages, 7 figures

> **TL;DR:** 本文提出判别式微调（DFT），一种无需奖励模型或人类偏好数据即可有效微调生成式大型语言模型的方法，其性能优于SFT并与SFT+PO相当。

**AI_Comments:** 该论文的创新之处在于将判别式学习应用于生成式LLM的微调，这与常见的生成式SFT和偏好优化流程不同。这种方法显著降低了对昂贵的人类偏好数据或复杂奖励模型的依赖，使得LLM对齐更加易于实现和高效。其在不增加额外开销的情况下，性能可与SFT+PO媲美，是一个显著的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 监督微调（SFT）受其生成式训练目标的限制。现有偏好优化（PO）方法需要昂贵的人工标注偏好数据或强大的奖励模型，增加了负担。本文旨在解决SFT的局限性并减轻对偏好数据/奖励模型的依赖。

**Method:** 本文引入了判别式微调（DFT），作为SFT的改进变体。DFT采用判别式范式，通过明确建模答案在所有可能输出中的判别式似然来增加正面答案的概率并抑制负面答案，旨在进行数据预测而非令牌预测。它包括一个判别式概率框架和高效的优化算法。

**Result:** 实验证明DFT有效，其性能优于SFT，并且与SFT→PO相当甚至更好。

**Conclusion:** DFT为生成式大型语言模型的微调提供了一种有效且高效的替代方案，它无需昂贵的人类偏好数据或奖励模型，同时能达到与传统SFT和偏好优化方法相当的性能。

> **ai_Abstract:** 本文提出了一种名为判别式微调（DFT）的新方法，用于微调生成式大型语言模型。与受限于生成式目标的传统监督微调（SFT）以及需要奖励模型或人类偏好数据的后续偏好优化（PO）不同，DFT采用判别式学习范式。它旨在提高正面响应的概率同时抑制负面响应，专注于数据预测。DFT提供了一个概率框架和高效的算法，并在实验中表现出优于SFT的性能，且与SFT结合PO的方法效果相当或更好，同时无需额外的偏好数据或奖励模型。

> **摘要翻译:** 监督微调 (SFT) 已成为使用输入-输出对的监督数据集对预训练大型语言模型 (LLM) 进行对齐的关键步骤。然而，尽管是监督式的，SFT 本质上受其生成式训练目标的限制。为了解决其局限性，现有的常见策略是在 SFT 之后进行单独的偏好优化 (PO) 阶段，这依赖于人工标注的偏好数据或强大的奖励模型来指导学习过程。在本文中，我们通过探索传统监督学习中最成功的技术之一：判别式学习，来解决 SFT 的局限性。我们引入了判别式微调 (DFT)，这是 SFT 的改进变体，它减轻了收集人工标注偏好数据或训练强大奖励模型的负担。与采用生成式方法并忽略负面数据的 SFT 不同，DFT 采用判别式范式，增加正面答案的概率，同时抑制潜在的负面答案，旨在进行数据预测而非令牌预测。我们的贡献包括：(i) 一个用于微调 LLM 的判别式概率框架，通过明确建模给定输入下所有可能输出中答案的判别式似然；(ii) 优化此判别式似然的有效算法；以及 (iii) 广泛的实验证明了 DFT 的有效性，其性能优于 SFT，并且与 SFT→PO 相当甚至更好。代码可在 https://github.com/Optimization-AI/DFT 找到。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [290] [Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language](https://arxiv.org/abs/2507.18448)
> *恢复韵律：使用Transformer模型对孟加拉语（一种低资源语言）进行标点符号恢复*

*Md Obyedullahil Mamun, Md Adyelullahil Mamun, Arif Ahmad, Md. Imran Hossain Emu* | **Category: cs.CL, cs.AI, cs.LG, I.2; I.7** | **Updated: 2025-07-24**

**Keywords:** 标点符号恢复, Transformer模型, 孟加拉语, 低资源语言, 数据增强

**Comment:** 

> **TL;DR:** 本文使用XLM-RoBERTa-large模型，结合数据增强技术，对孟加拉语（一种低资源语言）的标点符号进行恢复，取得了高准确率，并提供了数据集和代码。

**AI_Comments:** 该研究的创新之处在于将先进的Transformer模型应用于低资源语言的标点符号恢复，并有效利用数据增强技术弥补资源不足。其重要性体现在为孟加拉语ASR后处理提供了实用解决方案，并为低资源NLP领域提供了宝贵的基线和公开资源，促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 标点符号恢复能增强文本可读性，对自动语音识别（ASR）的后处理任务至关重要，特别是对于孟加拉语等低资源语言。

**Method:** 研究探索了基于Transformer的模型，特别是XLM-RoBERTa-large，用于自动恢复孟加拉语无标点文本中的句号、逗号、问号和感叹号。为解决带标注资源稀缺问题，构建了大型多样化训练语料库并应用了数据增强技术。

**Result:** 最佳模型（增强因子alpha = 0.20%）在新闻测试集上达到了97.1%的准确率，在参考集上达到91.2%，在ASR集上达到90.2%。结果显示模型对参考和ASR转录本具有很强的泛化能力。

**Conclusion:** 这项工作为孟加拉语标点符号恢复建立了强大的基线，并提供了公开可用的数据集和代码以支持低资源NLP的未来研究。

> **ai_Abstract:** 本研究旨在解决孟加拉语（一种低资源语言）的标点符号恢复问题，该问题对文本可读性和ASR后处理至关重要。研究采用XLM-RoBERTa-large等Transformer模型，通过构建大型训练语料库和数据增强技术，成功预测了句号、逗号、问号和感叹号。模型在新闻、参考和ASR测试集上均表现出高准确率和强大的泛化能力，为低资源NLP领域的未来研究提供了坚实的基础、公开数据集和代码。

> **摘要翻译:** 标点符号恢复增强了文本的可读性，对于自动语音识别（ASR）的后处理任务至关重要，特别是对于孟加拉语等低资源语言。在本研究中，我们探索了基于Transformer的模型，特别是XLM-RoBERTa-large，应用于自动恢复无标点孟加拉语文本中的标点符号。我们专注于预测四种标点符号：句号、逗号、问号和感叹号，涵盖不同的文本领域。为了解决带标注资源稀缺的问题，我们构建了一个大型、多样化的训练语料库并应用了数据增强技术。我们表现最佳的模型，在增强因子alpha = 0.20%的情况下进行训练，在新闻测试集上达到了97.1%的准确率，在参考集上达到了91.2%，在ASR集上达到了90.2%。结果显示出对参考和ASR转录本的强大泛化能力，证明了该模型在真实世界、嘈杂场景中的有效性。这项工作为孟加拉语标点符号恢复建立了强大的基线，并贡献了公开可用的数据集和代码以支持低资源NLP的未来研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [292] [How do language models learn facts? Dynamics, curricula and hallucinations](https://arxiv.org/abs/2503.21676)
> *语言模型如何学习事实？动力学、课程与幻觉*

*Nicolas Zucchet, Jörg Bornschein, Stephanie Chan, Andrew Lampinen, Razvan Pascanu, Soham De* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 语言模型, 知识获取, 学习动态, 数据分布, 幻觉, 事实回忆

**Comment:** Accepted at the 2nd Conference on Language Modeling (2025)

> **TL;DR:** 研究发现语言模型学习事实知识有三个阶段，包括一个表现平台期，与注意力机制形成有关。训练数据分布影响学习动态，不平衡分布会缩短平台期。幻觉与知识同时出现，微调整合新知识会破坏现有记忆。强调数据分布的重要性，并提出新的数据调度策略。

**AI_Comments:** 这项研究通过深入分析语言模型学习事实知识的内部机制，揭示了学习过程中的阶段性特征（如平台期）及其与注意力回路的关联，这具有创新性。它还强调了数据分布对学习动态和幻觉产生的重要影响，为理解和改进语言模型的知识获取和避免幻觉提供了宝贵的见解，并可能启发更有效的数据调度策略。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在预训练期间积累了大量知识，但其知识获取的动态机制仍知之甚少。本研究旨在探究语言模型学习事实知识的动态过程。

**Method:** 研究通过在一个合成事实回忆任务上调查语言模型的学习动态。

**Result:** 1. 语言模型以三个阶段学习，在获得精确事实知识之前会出现性能平台期，该平台期与支持回忆的基于注意力的电路形成同时发生。2. 训练数据分布显著影响学习动态，不平衡的分布会导致更短的平台期。3. 幻觉与知识同时出现，通过微调将新知识整合到模型中具有挑战性，因为它会迅速破坏现有的参数记忆。

**Conclusion:** 研究结果强调了数据分布在知识获取中的重要性，并提出了加速神经网络训练的新型数据调度策略。

> **ai_Abstract:** 本研究通过在一个合成事实回忆任务上，深入探究了大型语言模型学习事实知识的动态过程。研究发现，知识学习分为三个阶段，其中包含一个性能平台期，该时期与注意力机制的形成紧密相关。此外，训练数据分布对学习动态有显著影响，不平衡分布会缩短平台期。值得注意的是，幻觉与知识的获取同时发生，且通过微调整合新知识易导致现有记忆受损。这些发现强调了数据分布在知识学习中的关键作用，并为优化神经网络训练的数据调度策略提供了新思路。

> **摘要翻译:** 大型语言模型在预训练期间积累了大量知识，但控制这种获取的动态机制仍然知之甚少。这项工作调查了语言模型在合成事实回忆任务上的学习动态，揭示了三个关键发现：首先，语言模型分三个阶段学习，在获得精确事实知识之前表现出性能平台期。从机制上讲，这个平台期与支持回忆的基于注意力的电路的形成同时发生。其次，训练数据分布显著影响学习动态，因为不平衡的分布会导致更短的平台期。最后，幻觉与知识同时出现，并且通过微调将新知识整合到模型中具有挑战性，因为它会迅速破坏其现有的参数记忆。我们的结果强调了数据分布在知识获取中的重要性，并提出了加速神经网络训练的新型数据调度策略。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [296] [Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation](https://arxiv.org/abs/2507.18203)
> *探究指令微调对大型语言模型误信息易感性的影响*

*Kyubeen Han, Junseo Jang, Hongjin Kim, Geunyeong Jeong, Harksoo Kim* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 指令微调, 大型语言模型, 误信息, 易感性, 用户依赖

**Comment:** ACL 2025 Main Accepted

> **TL;DR:** 研究发现指令微调会显著增加大型语言模型接受用户提供误信息的倾向，并使其更依赖用户输入，从而将误信息易感性从助手角色转移到用户角色。

**AI_Comments:** 本文揭示了指令微调这一常用技术的一个意料之外但重要的副作用：它可能使LLMs更容易接受用户提供的误信息。这一发现具有重要的实际意义，尤其是在LLMs被广泛应用于信息生成和传播的背景下。研究通过对比基础模型和分析多种影响因素，深入探讨了这种易感性的来源和表现形式，为未来设计更健壮、更值得信赖的LLMs提供了关键见解。

<details>
  <summary>Details</summary>

**Motivation:** 指令微调提高了大型语言模型遵循指令的能力，但也可能导致其无过滤地接受误信息并产生幻觉。现有研究主要关注大型语言模型对与其参数知识相矛盾的外部信息的接受度，但很少有研究直接探讨指令微调对此现象的影响。

**Method:** 本研究调查了指令微调对大型语言模型误信息易感性的影响。通过与基础模型进行比较，并探讨了影响误信息易感性的额外因素，如提示结构中用户的角色、误信息长度以及系统提示中警告的存在。

**Result:** 指令微调后的大型语言模型在用户提供误信息时，显著更容易接受。与基础模型相比，指令微调增加了对用户提供信息的依赖，将易感性从助手角色转移到用户角色。此外，还发现了提示结构中用户的角色、误信息长度和系统提示中警告的存在等因素会影响误信息易感性。

**Conclusion:** 研究结果强调需要系统性方法来减轻指令微调的意外后果，并提高大型语言模型在实际应用中的可靠性。

> **ai_Abstract:** 本研究探讨了指令微调对大型语言模型（LLMs）接受误信息倾向的影响。研究发现，指令微调显著增加了LLMs在用户提供误信息时接受这些信息的可能性，并使其对用户输入表现出更高的依赖性，从而将误信息易感性从模型本身转移到用户输入上。论文还进一步分析了用户角色、误信息长度和系统警告等因素对误信息易感性的影响。研究结果强调了开发策略以缓解指令微调潜在负面影响的重要性，从而提升LLMs在实际应用中的可靠性。

> **摘要翻译:** 指令微调增强了大型语言模型（LLMs）更准确地遵循用户指令的能力，提高了可用性，同时减少了有害输出。然而，这一过程可能会增加模型对用户输入的依赖，可能导致其无过滤地接受误信息并产生幻觉。现有研究主要强调LLMs易于接受与其参数知识相矛盾的外部信息，但很少有研究直接探讨指令微调对此现象的影响。在我们的研究中，我们调查了指令微调对LLM误信息易感性的影响。我们的分析揭示，指令微调后的LLMs在用户提供误信息时，显著更容易接受。与基础模型的比较表明，指令微调增加了对用户提供信息的依赖，将易感性从助手角色转移到用户角色。此外，我们探讨了影响误信息易感性的额外因素，例如提示结构中用户的角色、误信息长度以及系统提示中警告的存在。我们的发现强调需要系统性方法来减轻指令微调的意外后果，并提高LLMs在实际应用中的可靠性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [309] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
> *NeuralDB：使用神经键值数据库将LLM中的知识编辑扩展到100,000个事实*

*Weizhi Fei, Hao Shi, Jing Xu, Jingchen Peng, Jiazheng Li, Jingzhao Zhang, Bo Bai, Wei Han, Zhenyuan Chen, Xueyan Niu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 知识编辑, 大型语言模型, 键值数据库, NeuralDB, 可扩展性

**Comment:** 

> **TL;DR:** NeuralDB通过神经KV数据库和门控检索模块，实现了LLM知识编辑的高效扩展，支持多达10万个事实的修改，同时保持模型通用能力。

**AI_Comments:** 这篇论文通过引入神经KV数据库和门控检索机制，解决了LLM知识编辑中规模扩展和通用能力保持的难题。其创新点在于将知识编辑视为KV数据库查询，并设计了专门的门控模块来避免对模型整体性能的影响。能够将知识编辑扩展到100,000个事实，显著超越了现有技术，对于LLM的动态更新和维护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Locate-and-Edit (L&E) 方法在扩展到数千个事实编辑时，可能会损害LLM的通用能力，甚至导致遗忘已编辑的事实。

**Method:** 论文将现有线性L&E方法建模为查询键值(KV)数据库。在此基础上，提出了NeuralDB框架，它将编辑后的事实明确表示为配备非线性门控检索模块的神经KV数据库。该门控模块仅在推理涉及编辑事实时才操作，有效保留了LLM的通用能力。

**Result:** 在ZsRE和CounterFacts数据集上，对GPT2-XL、GPT-J (6B) 和Llama-3 (8B) 进行了10,000个事实的编辑实验。结果表明，NeuralDB不仅在编辑效率、泛化性、特异性、流畅性和一致性方面表现出色，而且在六项代表性文本理解和生成任务中保持了整体性能。进一步实验表明，NeuralDB在扩展到100,000个事实（比现有工作多50倍）时仍能保持有效性。

**Conclusion:** NeuralDB提供了一种高效、可扩展且能保持LLM通用能力的知识编辑解决方案，显著提升了LLM在大量事实编辑场景下的性能。

> **ai_Abstract:** 本文提出了NeuralDB，一个用于大型语言模型知识编辑的框架。它将编辑事实表示为神经键值数据库，并使用非线性门控检索模块，该模块仅在需要时激活，从而在编辑大量事实（高达100,000个）的同时，有效避免了对LLM通用能力的损害和知识遗忘。实验证明，NeuralDB在多项编辑指标和任务性能上均优于现有方法，并展现出卓越的可扩展性。

> **摘要翻译:** 高效编辑存储在大型语言模型 (LLM) 中的知识，可以在不进行大规模训练的情况下更新模型。一种可能的解决方案是定位-编辑 (Locate-and-Edit, L&E) 方法，它允许同时修改大量事实。然而，这种编辑可能会损害LLM的通用能力，甚至在扩展到数千次编辑时导致遗忘已编辑的事实。在本文中，我们将现有的线性L&E方法建模为查询键值 (KV) 数据库。从这个角度出发，我们提出了NeuralDB，一个编辑框架，它将编辑后的事实明确表示为一个配备非线性门控检索模块的神经KV数据库。特别是，我们的门控模块仅在推理涉及编辑事实时才操作，有效保留了LLM的通用能力。在ZsRE和CounterFacts数据集上，使用GPT2-XL、GPT-J (6B) 和Llama-3 (8B) 进行了涉及编辑10,000个事实的综合实验。结果表明，NeuralDB不仅在编辑效率、泛化性、特异性、流畅性和一致性方面表现出色，而且在六项代表性文本理解和生成任务中保持了整体性能。进一步的实验表明，即使扩展到100,000个事实（比现有工作多50倍），NeuralDB仍能保持其有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [312] [Exploiting individual differences to bootstrap communication](https://arxiv.org/abs/2504.05211)
> *利用个体差异引导沟通的建立*

*Richard A. Blythe, Casimir Fisch* | **Category: cs.CL, physics.soc-ph, q-bio.PE** | **Updated: 2025-07-24**

**Keywords:** 沟通系统, 个体差异, 自举, 社会认知, 共享意图

**Comment:** Revised version is a full paper with considerable additional
  exposition and discussion. Now 21 pages including supplementary information,
  11 figures

> **TL;DR:** 本文提出了一个模型，展示了沟通系统如何能在没有预先存在的反馈机制的情况下，通过个体行为差异、可预测行为和共享意图而自举产生。

**AI_Comments:** 本文的创新之处在于提出了一种无需预设反馈机制即可解释沟通自举产生的新模型，解决了传统理论的局限性。其重要性在于为理解复杂沟通系统（如语言）的起源提供了新的视角，并强调了社会认知能力在其中的核心作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的沟通系统建立理论依赖于反馈机制，但这需要预先具备沟通能力，因此无法解释沟通如何从非沟通行为中自举产生。本文旨在解决这一难题。

**Method:** 本文提出了一个模型，展示了在大型群体中，沟通系统如何通过个体行为差异、在特定情境下的可预测行为以及源于共享意图的信号产生前心理状态对齐而自举产生，无需预先确定沟通成功的方法。

**Result:** 研究结果表明，一个能够表达无限多含义的沟通系统，可以在没有预先确定沟通成功方式的情况下，通过大型群体中的个体行为差异而出现。实现这一结果的两个关键认知能力是在特定情境下行为的可预测性，以及信号产生前源于共享意图的心理状态对齐。

**Conclusion:** 由于可预测行为和共享意图这两种能力可以独立于沟通而存在，因此本研究结果与将语言等大型灵活的社会习得沟通系统视为普遍但发展良好的社会认知能力产物的理论相符。

> **ai_Abstract:** 本文提出了一种新模型，旨在解释沟通系统如何能在没有预先反馈机制的情况下自举产生。模型显示，在大型群体中，沟通系统可以通过个体行为差异、在特定情境下的可预测行为以及源于共享意图的心理状态对齐而出现。这一发现挑战了传统理论对反馈的依赖，并支持了将语言等复杂沟通系统视为普遍社会认知能力产物的观点。

> **摘要翻译:** 建立沟通系统很困难，因为信号首次产生时，其预期含义对接收者来说是未知的，而信号发出者也不知道该信号将如何被解读。大多数关于沟通系统出现的理论都依赖于反馈来强化过去导致成功沟通的行为。然而，提供这种反馈需要已经能够传达预期的或被解读的含义。因此，这些理论无法解释沟通如何从非沟通行为中自举产生。本文提出了一个模型，展示了在一个大型群体中，一个能够表达无限多含义的沟通系统如何能在没有预先确定沟通成功方式的情况下，通过个体行为差异而出现。实现这一结果的两个关键认知能力是在特定情境下行为的可预测性，以及信号产生前源于共享意图的心理状态对齐。由于这两种能力都可以独立于沟通而存在，因此我们的结果与将语言等大型灵活的社会习得沟通系统视为普遍但发展良好的社会认知能力产物的理论相符。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [325] [Generation of Synthetic Clinical Text: A Systematic Review](https://arxiv.org/abs/2507.18451)
> *合成临床文本的生成：一项系统综述*

*Basel Alshaikhdeeb, Ahmed Abdelmonem Hemedan, Soumyabrata Ghosh, Irina Balaur, Venkata Satagopam* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 合成临床文本, 系统综述, 自然语言处理, 隐私保护, Transformer

**Comment:** 

> **TL;DR:** 本文对合成临床文本的生成进行了系统综述，分析了其目的、技术和评估方法，发现它能有效解决临床NLP中的数据稀疏和隐私问题，但隐私仍是挑战。

**AI_Comments:** 本文通过系统综述，全面梳理了合成临床文本生成领域的现状，指出了其在解决NLP数据问题上的重要性，并强调了Transformer模型的主导地位。其创新性在于对生成目的、技术和评估方法的定量分析，为后续研究提供了清晰的路线图。然而，论文也明确指出了隐私保护仍是该领域面临的重大挑战，这对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 解决临床自然语言处理（NLP）中常见的数据稀疏性和隐私问题。

**Method:** 通过对PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv等数据库进行系统检索，识别并分析了94篇相关文章，对生成目的、技术和评估方法进行了定量分析。

**Result:** 确定了94篇相关文章，发现自2018年起对合成医学文本的生成关注度大增，主要目的是文本增强、辅助写作、语料库构建、隐私保护、标注和实用性。Transformer架构（尤其是GPTs）是主要技术。评估方法主要包括相似性、隐私、结构和实用性，其中实用性最常用。合成文本在下游NLP任务中可作为真实文档的补充，有助于提高准确性和解决稀疏/欠采样问题。

**Conclusion:** 合成医学文本在不同下游NLP任务中作为真实医学文档的补充具有巨大价值，能提高准确性并克服数据稀疏问题。然而，隐私仍然是其主要问题，需要更多人工评估来检查敏感信息。尽管如此，合成医学文本的进步将大大加速工作流程和管道的采用，从而省去耗时的数据传输法律程序。

> **ai_Abstract:** 这项系统综述旨在分析合成临床文本的生成，以解决临床NLP中的数据稀疏和隐私问题。研究审查了94篇相关文章，发现自2018年以来，Transformer架构（特别是GPTs）被广泛用于生成合成文本，主要用于数据增强和隐私保护。尽管合成文本在提高下游NLP任务准确性方面表现出巨大潜力，并能克服数据稀疏问题，但隐私泄露仍是一个关键挑战，需要进一步的人工评估。

> **摘要翻译:** 生成临床合成文本是解决临床自然语言处理（NLP）中常见稀疏性和隐私问题的有效方案。本文旨在通过对三个研究问题（i）生成目的、（ii）技术和（iii）评估方法进行定量分析，对生成合成医学自由文本进行系统综述。我们检索了PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv数据库中与生成合成医学非结构化自由文本相关的出版物。从收集的1,398篇文章中，我们识别出94篇相关文章。自2018年以来，合成医学文本的生成受到了极大的关注，其主要目的是文本增强、辅助写作、语料库构建、隐私保护、标注和实用性。Transformer架构，特别是GPTs，是生成文本的主要主流技术。另一方面，评估主要有四个方面，包括相似性、隐私、结构和实用性，其中实用性是评估生成的合成医学文本最常用的方法。尽管生成的合成医学文本在不同的下游NLP任务中作为真实医学文档表现出中等可能性，但它已被证明作为增强真实文档的补充，在提高准确性和克服稀疏/欠采样问题方面是巨大的资产。然而，隐私仍然是生成合成医学文本背后的主要问题，需要更多的人工评估来检查是否存在任何敏感信息。尽管如此，合成医学文本的进步将大大加速工作流程和管道的采用，从而省去耗时的数据传输法律程序。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [326] [Prune&Comp: Free Lunch for Layer-Pruned LLMs via Iterative Pruning with Magnitude Compensation](https://arxiv.org/abs/2507.18212)
> *Prune&Comp：通过带有幅度补偿的迭代剪枝为层剪枝LLMs提供免费午餐*

*Xinrui Chen, Hongxing Zhang, Fanyi Zeng, Yongxian Wei, Yizhi Wang, Xitong Ling, Guanghao Li, Chun Yuan* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 层剪枝, 大语言模型, 幅度补偿, 模型压缩, Prune&Comp

**Comment:** 

> **TL;DR:** 提出Prune&Comp，一种训练无关的层剪枝方案，通过幅度补偿显著提升LLM剪枝性能，且无运行时开销。

**AI_Comments:** Prune&Comp的创新之处在于其“免费午餐”式的训练无关的幅度补偿机制，有效解决了层剪枝中隐藏状态幅度差距导致的性能下降问题。这种即插即用的特性使其能够轻松集成到现有剪枝流程中，显著提升剪枝效果而无需额外训练或运行时开销，这对于LLM的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 层剪枝在大型语言模型（LLMs）压缩中很有前景，但研究发现移除任何层都会在隐藏状态中引起显著的幅度差距，从而导致性能大幅下降。

**Method:** 提出Prune&Comp，一种即插即用层剪枝方案，利用幅度补偿来减轻层移除引起的幅度差距。具体而言，该方法首先估计幅度差距，然后通过离线重新缩放剩余权重来消除此差距，不产生零运行时开销。通过与迭代剪枝-补偿循环结合，Prune&Comp持续增强现有层剪枝指标。

**Result:** 当使用流行的块影响力指标对LLaMA-3-8B的5层进行剪枝时，Prune&Comp几乎将困惑度减半，并保留了原始模型问答性能的93.19%，优于基线4.01%。

**Conclusion:** Prune&Comp通过引入训练无关的幅度补偿机制，有效解决了层剪枝LLM中因层移除导致的性能下降问题，显著提升了剪枝效果且不增加运行时开销。

> **ai_Abstract:** 这项研究提出了Prune&Comp，一种针对大型语言模型（LLMs）的创新层剪枝方案，旨在解决层移除导致的隐藏状态幅度差距及其引起的性能下降问题。Prune&Comp通过无训练的幅度补偿机制，离线重新缩放权重以消除这些差距，且不产生运行时开销。结合迭代剪枝策略，Prune&Comp显著提升了现有层剪枝方法的性能，例如在LLaMA-3-8B上将困惑度几乎减半，并大幅提高了问答性能。

> **摘要翻译:** 层剪枝已成为一种很有前景的压缩大型语言模型（LLMs）的技术，同时实现了与剪枝比例成比例的加速。在这项工作中，我们发现移除任何层都会在隐藏状态中引起显著的幅度差距，导致性能大幅下降。为了解决这个问题，我们提出了Prune&Comp，一种新颖的即插即用层剪枝方案，它利用幅度补偿以无训练的方式减轻这种差距。具体来说，我们首先估计层移除引起的幅度差距，然后通过离线重新缩放剩余权重来消除此差距，不产生零运行时开销。我们通过迭代剪枝策略进一步展示了Prune&Comp的优势。当与迭代剪枝-补偿循环结合时，Prune&Comp持续增强现有层剪枝指标。例如，当使用流行的块影响力指标对LLaMA-3-8B的5层进行剪枝时，Prune&Comp几乎将困惑度减半，并保留了原始模型问答性能的93.19%，优于基线4.01%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [332] [Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge](https://arxiv.org/abs/2505.20658)
> *使用具有多样化外部知识的LLM增强自然语言到信号时序逻辑的转换*

*Yue Fang, Zhi Jin, Jie An, Hongshen Chen, Xiaohong Chen, Naijun Zhan* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 自然语言处理, 信号时序逻辑, 大型语言模型, 数据集, 知识引导转换

**Comment:** 11 pages, 5 figures, published to ACL 2025

> **TL;DR:** 本文提出了一个新数据集STL-DivEn和KGST框架，用于将自然语言转换为STL，解决了数据集缺乏和转换精度不足的问题，并显著提升了转换的准确性和多样性。

**AI_Comments:** 本文通过构建大规模且多样化的数据集以及提出结合LLM和外部知识的生成-细化框架，有效解决了自然语言到STL转换的挑战。其创新性在于利用LLM的生成能力并辅以严格的验证机制来解决数据稀缺问题，同时通过知识引导提升转换质量。这项工作对于推动网络物理系统中的形式化规范自动化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手动将自然语言（NL）转换为信号时序逻辑（STL）耗时且易出错；现有自动转换方法由于缺乏高质量数据集而面临重大挑战，尚未得到充分探索。

**Method:** 本文提出了一个名为STL-Diversity-Enhanced (STL-DivEn) 的NL-STL数据集，包含16,000个样本。数据集的构建流程包括：首先手动创建小规模NL-STL种子集；接着通过聚类识别代表性示例，指导大型语言模型（LLMs）生成额外的NL-STL对；最后通过严格的规则过滤器和人工验证确保多样性和准确性。此外，本文还引入了Knowledge-Guided STL Transformation (KGST) 框架，这是一种基于外部知识的“生成-然后-细化”过程，用于自然语言到STL的转换。

**Result:** 统计分析表明，STL-DivEn数据集比现有NL-STL数据集表现出更大的多样性。基于指标和人工评估均表明，KGST方法在STL-DivEn和DeepSTL数据集上的转换精度优于基线模型。

**Conclusion:** 本文成功开发了多样化的NL-STL数据集STL-DivEn和创新的KGST框架，显著提升了自然语言到STL自动转换的准确性和效率，克服了现有方法的局限性。

> **ai_Abstract:** 本文旨在解决自然语言到信号时序逻辑（STL）自动转换中数据集缺乏和准确性不足的问题。为此，作者提出了一个包含16,000个样本的新数据集STL-Diversity-Enhanced (STL-DivEn)，该数据集通过结合人工创建、LLM生成和严格过滤确保了多样性和准确性。同时，论文还引入了Knowledge-Guided STL Transformation (KGST) 框架，利用外部知识进行“生成-然后-细化”的转换过程。实验结果表明，STL-DivEn数据集比现有数据集更具多样性，并且KGST方法在转换精度上优于基线模型。

> **摘要翻译:** 时序逻辑（TL），特别是信号时序逻辑（STL），能够进行精确的形式化规范，因此广泛应用于自主驾驶和机器人等网络物理系统。将自然语言（NL）自动转换为STL是一种有吸引力的方法，可以克服手动转换的局限性，因为手动转换耗时且容易出错。然而，由于数据集的缺乏，自动转换目前面临重大挑战，并且尚未得到充分探索。在本文中，我们提出了一个名为STL-Diversity-Enhanced (STL-DivEn) 的NL-STL数据集，该数据集包含16,000个富含多样化模式的样本。为了开发该数据集，我们首先手动创建了一个小规模的NL-STL对种子集。接下来，通过聚类识别代表性示例，并用于指导大型语言模型（LLMs）生成额外的NL-STL对。最后，通过严格的基于规则的过滤器和人工验证来确保多样性和准确性。此外，我们引入了知识引导的STL转换（KGST）框架，这是一种将自然语言转换为STL的新方法，涉及基于外部知识的“生成-然后-细化”过程。统计分析表明，STL-DivEn数据集比现有的NL-STL数据集表现出更大的多样性。此外，基于指标和人工评估均表明，我们的KGST方法在STL-DivEn和DeepSTL数据集上的转换精度优于基线模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [341] [FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs](https://arxiv.org/abs/2507.18417)
> *FinDPO：通过LLM偏好优化实现算法交易的金融情感分析*

*Giorgos Iacovides, Wuyang Zhou, Danilo Mandic* | **Category: cs.CL, cs.LG, q-fin.ST, q-fin.TR** | **Updated: 2025-07-24**

**Keywords:** 金融情感分析, 大型语言模型, 直接偏好优化, 算法交易, FinDPO

**Comment:** 

> **TL;DR:** FinDPO是首个基于直接偏好优化（DPO）的金融领域LLM框架，在情感分析基准测试中表现出色，并能为算法交易带来显著正回报。

**AI_Comments:** FinDPO的创新点在于首次将DPO应用于金融领域LLM的情感分析，并引入了“logit-to-score”转换，使其能够有效整合到实际交易策略中。这解决了现有SFT模型在金融领域泛化能力不足的痛点，为算法交易提供了更可靠的情感信号。其在实际交易模拟中展示的显著回报和风险调整性能，证明了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在线金融文本数据中表达的观点对交易决策和市场走势有深远影响，情感分析至关重要。然而，传统的监督微调（SFT）大型语言模型（LLMs）在金融领域存在泛化能力差、易记忆训练数据的问题，难以适应未见事件和领域特定语言。

**Method:** 本文提出了FinDPO，这是首个基于直接偏好优化（DPO）的后训练人类偏好对齐的金融领域LLM框架。它通过“logit-to-score”转换将离散情感预测转化为连续、可排序的情感分数，从而将微调后的因果LLM整合到实际投资组合策略中。

**Result:** FinDPO在标准情感分类基准测试中取得了最先进的性能，平均优于现有监督微调模型11%。模拟结果显示，即使在0.05%的实际交易成本下，FinDPO作为首个基于情感的方法，每年仍能保持67%的显著正回报，并具有2.0的夏普比率，表现出强大的风险调整性能。

**Conclusion:** FinDPO通过结合偏好优化和独特的logit-to-score转换，显著提升了金融情感分析的性能，并能有效地应用于算法交易，实现持续的积极回报和优异的风险调整表现。

> **ai_Abstract:** 本研究提出FinDPO，一个专为金融领域设计的大型语言模型框架，通过直接偏好优化（DPO）进行后训练的人类偏好对齐，旨在克服传统监督微调模型在金融情感分析中泛化能力差的局限性。FinDPO在情感分类任务中取得了最先进的性能，并在算法交易模拟中展示了显著的正回报和优异的风险调整表现，这得益于其独特的“logit-to-score”转换方法，能将离散情感预测转化为连续分数。

> **摘要翻译:** 在线金融相关文本数据中表达的观点对交易决策和市场走势产生着越来越深远的影响。这一趋势突显了情感分析作为量化此类观点性质和强度的工具的关键作用。随着生成式AI（GenAI）的快速发展，监督微调（SFT）大型语言模型（LLMs）已成为金融情感分析的事实标准。然而，SFT范式可能导致训练数据的记忆化，并且往往无法泛化到未见样本。这在金融领域是一个关键的限制，因为模型必须适应以前未观察到的事件和金融领域细致入微的特定语言。为此，我们引入了FinDPO，这是首个基于通过直接偏好优化（DPO）进行后训练人类偏好对齐的金融特定LLM框架。所提出的FinDPO在标准情感分类基准测试中取得了最先进的性能，平均优于现有监督微调模型11%。独特的是，FinDPO框架通过一种新颖的“logit-to-score”转换，将离散情感预测转化为连续、可排序的情感分数（概率），从而将微调后的因果LLM整合到实际投资组合策略中。通过这种方式，模拟结果表明，即使在0.05%的实际交易成本下，FinDPO也是第一个能够保持每年67%的显著正回报和2.0夏普比率所指示的强大风险调整性能的基于情感的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [350] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
> *GrAInS：基于梯度的归因，用于LLM和VLM的推理时引导*

*Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal* | **Category: cs.CL, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 推理时引导, 大型语言模型, 视觉-语言模型, 梯度归因, 模型控制

**Comment:** 21 pages. Code: https://github.com/duykhuongnguyen/GrAInS

> **TL;DR:** GrAInS通过基于梯度的归因在推理时引导LLM和VLM，显著优于现有方法，无需微调。

**AI_Comments:** GrAInS的创新之处在于其利用梯度归因实现token级别的精细控制，解决了传统推理时引导方法中全局干预和忽略因果影响的问题。其无需微调即可显著提升模型性能，尤其在多模态场景下的表现，凸显了其重要性。这种方法为LLM和VLM的行为控制提供了一个高效且可解释的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有推理时引导方法依赖固定、全局干预向量，忽略个体输入token的因果影响，未能利用模型logits中信息丰富的梯度，尤其是在视觉和文本输入贡献不均匀的多模态设置中。

**Method:** GrAInS使用对比性的、基于梯度的归因（通过集成梯度）识别出对期望/非期望输出贡献最大的top-k个影响最大的token。然后，这些token用于构建方向性引导向量，捕捉从不良到理想行为的语义转变。在推理时，GrAInS根据token级归因信号调整Transformer层的隐藏激活，并归一化激活以保持表示尺度。

**Result:** GrAInS在使用Llama-3.1-8B的TruthfulQA上实现了13.22%的准确率提升，使用LLaVA-1.6-7B将MMHal-Bench上的幻觉率从0.624降低到0.514，并在SPA-VL上将对齐胜率提高8.11%，同时保持了模型的流畅性和通用能力。

**Conclusion:** GrAInS提供了一种无需重新训练或辅助监督的细粒度、可解释和模块化的模型行为控制方法，并且在经验上持续优于微调和现有引导基线。

> **ai_Abstract:** 本文介绍了GrAInS，一种新的推理时引导方法，用于LLM和VLM。它通过基于梯度的归因识别关键token，并构建方向性引导向量来调整模型行为，从而实现细粒度、可解释的控制，无需微调。实验证明，GrAInS在多个任务上显著优于现有微调和引导基线，提升了准确性、减少了幻觉并改善了对齐。

> **摘要翻译:** 推理时引导方法通过在测试时修改内部激活而不更新模型权重，为微调大型语言模型（LLM）和视觉-语言模型（VLM）提供了一种轻量级替代方案。然而，大多数现有方法依赖于固定的、全局的干预向量，忽视了单个输入token的因果影响，并且未能利用模型logits中信息丰富的梯度，尤其是在视觉和文本输入贡献不均匀的多模态设置中。为了解决这些限制，我们引入了GrAInS，一种推理时引导方法，适用于纯语言模型和视觉-语言模型以及任务。GrAInS通过集成梯度使用对比性的、基于梯度的归因来识别top-k个最具影响力的token，这些token根据它们对偏好输出和非偏好输出的贡献进行正面和负面归因。然后，这些token用于构建方向性引导向量，捕捉从不良行为到理想行为的语义转变。在推理过程中，GrAInS根据token级归因信号调整Transformer层的隐藏激活，并归一化激活以保持表示尺度。这使得对模型行为的细粒度、可解释和模块化控制成为可能，无需重新训练或辅助监督。在经验上，GrAInS始终优于微调和现有引导基线：它在使用Llama-3.1-8B的TruthfulQA上实现了13.22%的准确率提升，使用LLaVA-1.6-7B将MMHal-Bench上的幻觉率从0.624降低到0.514，并在SPA-VL上将对齐胜率提高了8.11%，所有这些都同时保持了模型的流畅性和通用能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [353] [Large Language Models in Argument Mining: A Survey](https://arxiv.org/abs/2506.16383)
> *大型语言模型在论证挖掘中的应用：一项综述*

*Hao Li, Viktor Schlegel, Yizheng Sun, Riza Batista-Navarro, Goran Nenadic* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 论证挖掘, 大型语言模型, 自然语言处理, 综述, 计算论证

**Comment:** Work draft

> **TL;DR:** 本综述系统地总结了大型语言模型在论证挖掘领域的最新进展，并提出了未来的研究议程。

**AI_Comments:** 这篇综述论文的重要性在于它为大型语言模型在论证挖掘这一快速发展领域提供了一个及时且全面的概览。它不仅系统地整理了现有知识和技术，还识别了关键挑战并提出了未来的研究方向，对于该领域的初学者和资深研究人员都具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 论证挖掘（AM）是自然语言处理（NLP）的一个关键子领域，大型语言模型（LLMs）的出现深刻地改变了AM，使其具备了高级的上下文学习、基于提示的生成和强大的跨领域适应性。本综述旨在系统地综合LLM驱动的AM的最新进展。

**Method:** 本综述系统地综合了LLM驱动的AM的最新进展，提供了基础理论和标注框架的简明回顾，以及精心整理的数据集目录。它还构建了一个全面的AM子任务分类法，阐明了当代LLM技术（如提示、思维链推理和检索增强）如何重新配置其执行方式。此外，还详细介绍了当前的LLM架构和方法论，批判性地评估了评估实践，并描绘了关键挑战。

**Result:** 本综述提供了一个全面的概述，包括：基础理论和标注框架的简明回顾；精心整理的数据集目录；一个全面的AM子任务分类法，阐明了LLM技术如何影响其执行；当前LLM架构和方法论的详细介绍；对评估实践的批判性评估；以及对长上下文推理、可解释性和标注瓶颈等关键挑战的界定。

**Conclusion:** 本综述强调了新兴趋势，并为基于LLM的计算论证提出了一个前瞻性的研究议程，旨在战略性地指导研究人员在这个快速发展的领域。

> **ai_Abstract:** 本综述系统地考察了大型语言模型（LLMs）在论证挖掘（AM）领域的最新应用和进展。文章回顾了AM的基础理论、标注框架和数据集，并提出了一个全面的AM子任务分类法，详细阐述了LLM技术如何影响这些任务的执行。此外，它探讨了当前LLM的架构、方法论和评估实践，并指出了长上下文推理、可解释性和标注瓶颈等挑战。最后，综述提出了新兴趋势和未来的研究议程，旨在指导该领域的研究。

> **摘要翻译:** 论证挖掘（AM）是自然语言处理（NLP）的一个关键子领域，专注于从文本中提取论证结构。大型语言模型（LLMs）的出现深刻地改变了AM，使其具备了高级的上下文学习、基于提示的生成和强大的跨领域适应能力。本综述系统地综合了LLM驱动的AM的最新进展。我们简明扼要地回顾了基础理论和标注框架，并提供了一个精心策划的数据集目录。一个关键贡献是我们对AM子任务的全面分类，阐明了当代LLM技术——例如提示、思维链推理和检索增强——如何重新配置它们的执行。我们进一步详细介绍了当前的LLM架构和方法论，批判性地评估了评估实践，并描绘了包括长上下文推理、可解释性和标注瓶颈在内的关键挑战。最后，我们强调了新兴趋势，并为基于LLM的计算论证提出了一个前瞻性的研究议程，旨在战略性地指导研究人员在这个快速发展的领域。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [358] [Zero-shot OCR Accuracy of Low-Resourced Languages: A Comparative Analysis on Sinhala and Tamil](https://arxiv.org/abs/2507.18264)
> *低资源语言的零样本OCR准确性：僧伽罗语和泰米尔语的比较分析*

*Nevidu Jayatilleke, Nisansa de Silva* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 低资源语言, OCR, 零样本, 僧伽罗语, 泰米尔语

**Comment:** 10 pages, 4 figures, Accepted paper at Recent Advances in Natural
  Language Processing (RANLP) 2025

> **TL;DR:** 本研究比较了六种OCR引擎在僧伽罗语和泰米尔语两种低资源语言上的零样本性能，发现Surya在僧伽罗语表现最佳，Document AI在泰米尔语表现最佳，并引入了一个新的泰米尔语OCR基准数据集。

**AI_Comments:** 这篇论文的创新点在于专注于低资源语言的零样本OCR，并对多种商业和开源OCR引擎进行了系统性的比较分析。其重要性在于揭示了现有OCR技术在低资源语言上的表现差异，并为未来针对这些语言的OCR研究和开发提供了有价值的基准和洞察。引入新的合成泰米尔语OCR基准数据集也为社区贡献了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 针对拉丁语系等高资源语言的OCR问题已基本解决，但对于使用独特文字的低资源语言，OCR仍然是一个未解决的问题。本研究旨在解决这一空白，对现有OCR引擎在低资源语言上的零样本性能进行评估。

**Method:** 本研究对六种不同的OCR引擎（包括商业和开源系统，如Cloud Vision API, Surya, Document AI, Tesseract, Subasa OCR, EasyOCR）在僧伽罗语和泰米尔语两种低资源语言上的零样本性能进行了比较分析。性能评估采用了五种测量技术，评估了字符和单词级别的准确性。此外，还引入了一个新的合成泰米尔语OCR基准数据集。

**Result:** Surya在僧伽罗语的所有指标上表现最佳，词错误率（WER）为2.61%。Document AI在泰米尔语的所有指标上表现出色，字符错误率（CER）低至0.78%。

**Conclusion:** 对于低资源语言的零样本OCR，不同的引擎在不同语言上表现各异，例如Surya在僧伽罗语上表现最佳，而Document AI在泰米尔语上表现最佳。这表明需要针对特定低资源语言选择或优化OCR解决方案。

> **ai_Abstract:** 本研究旨在解决低资源语言OCR的开放问题，通过比较分析六种OCR引擎在僧伽罗语和泰米尔语上的零样本性能。研究评估了商业和开源系统，发现Surya在僧伽罗语上表现最佳（WER 2.61%），而Document AI在泰米尔语上表现最佳（CER 0.78%）。此外，本研究还推出了一个新的合成泰米尔语OCR基准数据集。

> **摘要翻译:** 解决拉丁语及其衍生文字的印刷文本光学字符识别（OCR）问题，由于对英语及其他高资源语言（HRL）的大量研究，现在可以认为是已解决的。然而，对于使用独特文字的低资源语言（LRL），这仍然是一个开放的问题。本研究对六种不同的OCR引擎在两种低资源语言：僧伽罗语和泰米尔语上的零样本性能进行了比较分析。所选引擎包括商业和开源系统，旨在评估每种类别的优势。Cloud Vision API、Surya、Document AI和Tesseract对僧伽罗语和泰米尔语都进行了评估，而Subasa OCR和EasyOCR由于其局限性仅对一种语言进行了评估。这些系统的性能使用五种测量技术进行了严格分析，以评估字符和单词级别的准确性。根据研究结果，Surya在僧伽罗语的所有指标上表现最佳，WER为2.61%。相反，Document AI在泰米尔语的所有指标上表现出色，其字符错误率（CER）低至0.78%。除了上述分析，我们还引入了一个新颖的合成泰米尔语OCR基准数据集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [377] [Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?](https://arxiv.org/abs/2506.19733)
> *打破障碍：强化后训练的收益能否转移到未见过的领域？*

*Chuxuan Hu, Yuxuan Zhu, Antony Kellermann, Caleb Biddulph, Suppakit Waiwitlikhit, Jason Benn, Daniel Kang* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 强化后训练, 大型语言模型, 泛化性, 未见领域, 推理能力

**Comment:** 9 pages, 4 figures, 2 tables

> **TL;DR:** 强化后训练（RPT）对大型语言模型（LLMs）的推理能力有所提升，但在未见过的领域中，这种提升的泛化效果不一致，甚至可能消失。

**AI_Comments:** 该论文填补了RPT泛化能力研究的空白，指出了RPT在跨领域应用中存在的局限性，对理解和改进LLM的泛化能力具有重要意义。其创新之处在于通过观察性和干预性两种研究方法，系统地评估了RPT的泛化表现。

<details>
  <summary>Details</summary>

**Motivation:** 强化后训练（RPT）在提高大型语言模型（LLMs）推理能力方面展现出潜力，但其改进是否能很好地泛化到新领域尚不清楚，因为先前的研究都是在与微调数据相同的领域进行评估的。

**Method:** 本研究进行了两项实验来理解RPT的泛化能力：1. 观察性研究：比较了广泛的开源RPT模型及其对应的基础模型在多个领域（包括微调数据中见过和未见过的领域）的表现。2. 干预性研究：在单个领域对LLMs进行RPT微调，并评估它们在多个领域中的表现。

**Result:** 两项研究得出相同的结论：尽管RPT在与微调数据相似的任务上带来了显著的收益，但这些收益的泛化性不一致，并且在推理模式不同的领域中可能会消失。

**Conclusion:** 强化后训练（RPT）对大型语言模型（LLMs）的推理能力提升在相似任务上效果显著，但在面对不同推理模式的未见领域时，其泛化能力不足，收益可能无法保持。

> **ai_Abstract:** 本研究旨在探究强化后训练（RPT）对大型语言模型（LLMs）推理能力提升的泛化性，特别是在未见过的领域。通过观察性研究和干预性研究，比较了RPT模型在不同领域（包括微调数据中见过和未见过的）的表现。研究发现，虽然RPT在与微调数据相似的任务上能带来显著提升，但在推理模式不同的未见领域中，其泛化效果不一致，甚至可能消失。

> **摘要翻译:** 强化后训练（RPT）最近在提高大型语言模型（LLMs）的推理能力方面显示出潜力。然而，这些改进如何很好地泛化到新领域仍不清楚，因为之前的工作评估RPT模型时，使用的是与微调数据相同的领域。为了理解RPT的泛化能力，我们进行了两项研究。(1) 观察性研究：我们比较了广泛的开源RPT模型及其对应的基础模型在多个领域（包括微调数据中见过和未见过的领域）的表现。(2) 干预性研究：我们对LLMs在单个领域进行RPT微调，并评估它们在多个领域中的表现。两项研究都得出了相同的结论：尽管RPT在与微调数据相似的任务上带来了显著的收益，但这些收益的泛化性不一致，并且在推理模式不同的领域中可能会消失。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [394] [StyleAdaptedLM: Enhancing Instruction Following Models with Efficient Stylistic Transfer](https://arxiv.org/abs/2507.18294)
> *StyleAdaptedLM：增强指令遵循模型的高效风格迁移*

*Pritika Ramu, Apoorv Saxena, Meghanath M Y, Varsha Sankar, Debraj Basu* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 风格迁移, LLM, LoRA, 指令遵循, 个性化

**Comment:** 

> **TL;DR:** StyleAdaptedLM利用LoRA技术，高效地将特定风格特性迁移到大型语言模型中，同时保持其指令遵循能力。

**AI_Comments:** 该论文创新性地提出了一种高效的风格迁移方法，解决了LLM在企业通信中实现特定品牌或作者风格的痛点，尤其是在缺乏配对数据的情况下。其利用LoRA进行分阶段训练和合并的策略，有效平衡了风格适应和指令遵循能力，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 将大型语言模型（LLMs）适应特定的风格特征（如品牌声音或作者语调）对于企业通信至关重要，但从缺乏指令-响应格式的语料库中实现这一点具有挑战性，且可能损害指令依从性。

**Method:** 引入StyleAdaptedLM框架，该框架使用低秩适应（LoRA）将风格特征高效地迁移到指令遵循模型中。LoRA适配器首先在基础模型上使用多样化的非结构化风格语料库进行训练，然后与单独的指令遵循模型合并。这实现了鲁棒的风格定制，无需配对数据或牺牲任务性能。

**Result:** 在多个数据集和模型上的实验表明，在保持指令依从性的同时，风格一致性得到改善，并且人工评估证实了品牌特定规范的采纳。

**Conclusion:** StyleAdaptedLM为LLMs中的风格个性化提供了一条高效的路径。

> **ai_Abstract:** StyleAdaptedLM是一个利用LoRA技术将特定风格特征高效地迁移到指令遵循大型语言模型中的框架。它通过在非结构化风格语料库上训练LoRA适配器并将其与指令遵循模型合并，解决了在不牺牲指令依从性的前提下进行风格适应的挑战。实验证明，该方法在保持任务性能的同时，显著提高了风格一致性，并支持品牌特定风格定制。

> **摘要翻译:** 将大型语言模型（LLMs）适应特定的风格特征，如品牌声音或作者语调，对于企业通信至关重要，但从缺乏指令-响应格式的语料库中实现这一点具有挑战性，且可能损害指令依从性。我们引入了StyleAdaptedLM，这是一个使用低秩适应（LoRA）高效地将风格特征迁移到指令遵循模型中的框架。LoRA适配器首先在基础模型上使用多样化的非结构化风格语料库进行训练，然后与单独的指令遵循模型合并。这实现了鲁棒的风格定制，无需配对数据或牺牲任务性能。在多个数据集和模型上的实验表明，在保持指令依从性的同时，风格一致性得到改善，并且人工评估证实了品牌特定规范的采纳。StyleAdaptedLM为LLMs中的风格个性化提供了一条高效的路径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [401] [Mechanistic Indicators of Understanding in Large Language Models](https://arxiv.org/abs/2507.08017)
> *大型语言模型理解的机制性指标*

*Pierre Beckmann, Matthieu Queloz* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 机制可解释性, 机器理解, 内部结构, 理解概念

**Comment:** 32 pages

> **TL;DR:** 本文综合了机制可解释性领域的最新发现，提出了一个三层理解概念框架，以阐明大型语言模型如何发展出类似理解的内部结构，并指出其与人类理解的根本差异。

**AI_Comments:** 本文的创新之处在于提出了一个新颖的三层理解概念框架，为理解大型语言模型（LLMs）的内部运作提供了一种结构化的视角。它超越了传统上对LLMs是否理解的二元争论，转而探讨“如何”理解，这对于机制可解释性领域具有重要意义。然而，论文也明确指出了LLMs的理解形式与人类理解的根本差异，这为未来的研究设定了界限。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究挑战了大型语言模型（LLMs）仅依赖表面统计的观点。本文旨在综合这些发现，并将其整合到一个新的理论框架中，以思考机器理解，并深入探讨LLMs内部运作机制。

**Method:** 本文提供了一项关于机制可解释性（MI）领域最新发现的综合，并将其作为MI的入门介绍。在此基础上，本文提出了一个新颖的理论框架来思考机器理解，并提出了一个三层理解概念：概念理解、世界状态理解和原则理解。

**Result:** 大型语言模型发展出功能上类似于“看到联系”的理解的内部结构。本文提出了一个三层理解概念：第一，概念理解（形成潜在空间中的“特征”）；第二，世界状态理解（学习特征间的偶然事实联系并动态跟踪变化）；第三，原则理解（发现连接事实的“电路”）。然而，由于“并行机制”现象，这些理解形式与人类理解仍有根本区别。

**Conclusion:** 关于大型语言模型是否理解的争论应超越简单的“是或否”问题，转而研究它们独特的思维运作方式，并构建适合它们的理解概念。

> **ai_Abstract:** 本文综合了机制可解释性领域的最新发现，挑战了大型语言模型（LLMs）仅依赖表面统计的观点。作者提出了一种新的理论框架，将LLMs发展出的内部结构视为功能上类似于“理解”的表现，并提出了一个三层理解概念：概念理解、世界状态理解和原则理解。尽管LLMs展现出这些理解形式，但作者强调它们与人类理解存在根本差异，并呼吁将对LLMs理解的讨论从简单的“是或否”转向对其独特思维方式的深入探究。

> **摘要翻译:** 机制可解释性（MI）领域——探索大型语言模型（LLMs）内部运作的领域——的最新发现挑战了这些模型仅依赖表面统计的观点。我们对这些发现进行了易于理解的综合，这既是对MI的介绍，又将这些发现整合到一个新的理论框架中，以思考机器理解。我们认为LLMs发展出功能上类似于由“看到联系”构成的理解的内部结构。为了深化这一观点，我们提出了一个三层理解概念。首先，当模型在潜在空间中形成“特征”，学习某事物不同表现形式之间的联系时，概念理解便出现了。其次，当模型学习特征之间偶然的事实联系并动态跟踪世界变化时，世界状态理解便出现了。第三，当模型不再依赖于一系列记忆的事实，而是发现连接这些事实的“电路”时，原则理解便出现了。然而，正如“并行机制”现象所示，这些理解形式与人类理解仍有根本不同。我们总结认为，争论应超越LLMs是否理解的“是或否”问题，转而研究它们奇怪的思维如何运作，并形成适合它们的理解概念。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [404] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
> *大语言模型生成合成数据用于短语停顿预测*

*Hoyeon Lee, Sejung Son, Ye-Eun Kang, Jong-Hwan Kim* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 短语停顿预测, 合成数据生成, 大语言模型, 文本到语音, 数据增强

**Comment:** Accepted at Interspeech 2025

> **TL;DR:** 使用大语言模型生成合成数据以解决短语停顿预测中人工标注的挑战。

**AI_Comments:** 本文的创新点在于将大语言模型应用于语音领域的短语停顿预测任务，通过生成合成数据来解决传统方法中数据标注成本高昂和数据质量难以保证的问题。这为语音领域的数据稀缺问题提供了一个有前景的解决方案，并进一步拓展了LLM的应用边界。

<details>
  <summary>Details</summary>

**Motivation:** 当前的短语停顿预测方法严重依赖大量人工标注数据，导致高昂的成本和精力。语音领域的内在变异性也使得获取高质量、一致的数据变得复杂。大语言模型在解决NLP数据挑战方面表现出色，激发了本文利用LLM生成合成数据来克服这些问题。

**Method:** 探索利用大语言模型生成合成短语停顿标注，通过与传统标注进行比较，并在多种语言上评估其有效性。

**Result:** 研究结果表明，基于大语言模型的合成数据生成有效缓解了短语停顿预测中的数据挑战。

**Conclusion:** 大语言模型在短语停顿预测中生成合成数据是有效的，并凸显了LLM作为语音领域可行解决方案的潜力。

> **ai_Abstract:** 本研究旨在解决短语停顿预测中对大量人工标注数据的依赖问题。作者提出利用大语言模型生成合成短语停顿标注，以减少人工成本并应对语音数据的复杂性。实验结果表明，LLM生成的合成数据能有效缓解数据挑战，并展示了LLM在语音领域的应用潜力。

> **摘要翻译:** 当前短语停顿预测方法解决了文本到语音系统中关键的韵律方面，但严重依赖于来自音频或文本的大量人工标注，这带来了显著的人力投入和成本。语音领域由语音因素驱动的内在变异性进一步使获取一致、高质量的数据复杂化。最近，大语言模型（LLM）在通过生成定制的合成数据同时减少人工标注需求方面，在解决自然语言处理（NLP）中的数据挑战方面取得了成功。受此启发，我们探索利用LLM生成合成短语停顿标注，通过与传统标注进行比较并在多种语言中评估其有效性，解决了人工标注和语音相关任务的挑战。我们的研究结果表明，基于LLM的合成数据生成有效缓解了短语停顿预测中的数据挑战，并突出了LLM作为语音领域可行解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [418] [Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models](https://arxiv.org/abs/2507.18504)
> *并非所有特征都值得关注：面向语言模型表格数据生成的图引导依赖学习*

*Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 表格数据生成, 大型语言模型, 注意力机制, 图引导学习, 稀疏依赖

**Comment:** 

> **TL;DR:** 本文提出GraDe方法，通过将稀疏依赖图集成到LLM的注意力机制中，解决了LLM在表格数据生成中对不重要特征分配注意力的问题，显著提升了复杂数据集上的表现。

**AI_Comments:** GraDe的创新点在于它通过引入外部知识（功能依赖图）来指导LLM的注意力机制，解决了LLM在处理表格数据时固有缺陷。这种方法不仅提高了模型在复杂数据集上的性能，还保持了对LLM的最小侵入性，使其易于应用。该研究强调了在利用通用模型处理特定结构化数据时，结合领域知识的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在表格数据生成方面潜力巨大，但其自注意力机制会不可避免地将注意力分散到所有特征对上，稀释了对关键关系的关注，尤其是在具有复杂依赖或语义模糊特征的数据集中，这与表格数据固有的稀疏特征级依赖性存在根本性不匹配。

**Method:** 本文提出了GraDe（Graph-Guided Dependency Learning），一种将稀疏依赖图显式集成到LLMs注意力机制中的新方法。GraDe采用轻量级动态图学习模块，由外部提取的功能依赖关系引导，优先处理关键特征交互，同时抑制不相关的交互。

**Result:** 在多样化的真实世界数据集上的实验表明，GraDe在复杂数据集上的性能比现有基于LLM的方法提高了12%，同时在合成数据质量方面与最先进的方法取得了有竞争力的结果。

**Conclusion:** GraDe方法对LLM的侵入性最小但有效，为使用LLM进行结构感知表格数据建模提供了一个实用的解决方案。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在表格数据生成中，因自注意力机制将注意力分散到所有特征对上，导致对关键稀疏依赖关系关注不足的问题，提出了一种名为GraDe（图引导依赖学习）的新方法。GraDe通过将外部提取的功能依赖关系形成的稀疏依赖图显式集成到LLMs的注意力机制中，以优先处理重要的特征交互并抑制不相关的交互。实验结果表明，GraDe在复杂数据集上比现有LLM方法性能提升高达12%，并在合成数据质量方面与SOTA方法持平，提供了一种实用且有效的结构感知表格数据建模方案。

> **摘要翻译:** 大型语言模型（LLMs）通过建模文本化的特征-值对，在表格数据生成方面显示出强大的潜力。然而，表格数据固有地表现出稀疏的特征级依赖关系，其中许多特征交互在结构上是不重要的。这造成了一个根本性的不匹配，因为LLMs的自注意力机制不可避免地会将注意力分散到所有特征对上，稀释了对关键关系的关注，尤其是在具有复杂依赖或语义模糊特征的数据集中。为了解决这一限制，我们提出了GraDe（图引导依赖学习），这是一种将稀疏依赖图显式集成到LLMs注意力机制中的新方法。GraDe采用轻量级动态图学习模块，由外部提取的功能依赖关系引导，优先处理关键特征交互，同时抑制不相关的交互。我们在多样化的真实世界数据集上的实验表明，GraDe在复杂数据集上的性能比现有基于LLM的方法提高了12%，同时在合成数据质量方面与最先进的方法取得了有竞争力的结果。我们的方法对LLM的侵入性最小但有效，为使用LLM进行结构感知表格数据建模提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [424] [A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](https://arxiv.org/abs/2507.08621)
> *基于LLM的论证分类综合研究：从LLAMA到GPT-4o再到Deepseek-R1*

*Marcin Pietroń, Rafał Olszowski, Jakub Gomułka, Filip Gampel, Andrzej Tomski* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 论证分类, 大型语言模型, GPT-4o, Deepseek-R1, 思维链

**Comment:** 

> **TL;DR:** 本研究对选定的LLM（包括GPT、Llama和DeepSeek及其CoT变体）在论证分类任务中的表现进行了全面评估，发现GPT-4o整体表现最佳，而Deepseek-R1在结合推理能力时表现突出，但所有模型仍存在错误。

**AI_Comments:** 本文对LLM在论证分类领域的应用进行了首次全面的横向比较研究，涵盖了当前流行的多个模型，并深入探讨了思维链等推理增强算法的效果，具有重要的实践和理论价值。其创新点在于对数据集和提示算法弱点的揭示，为未来的研究指明了方向。然而，论文也指出即使是当前最先进的模型也存在错误，提示了该领域仍有很大的提升空间。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）在论证挖掘领域取得了显著进展，但目前仍缺乏关于这些模型在公开论证分类数据库中表现的研究和结果。本研究旨在填补这一空白，深入分析LLM在论证分类任务中的应用。

**Method:** 本研究选取了多种大型语言模型（LLM），包括不同版本的GPT、Llama和DeepSeek，并测试了结合思维链（Chain-of-Thoughts）算法的推理增强变体。研究使用了Args.me和UKP等多样化数据集进行论证分类基准测试。

**Result:** 结果显示，ChatGPT-4o在论证分类基准测试中表现优于其他模型。在结合推理能力的模型中，Deepseek-R1展现出其优越性。然而，尽管表现出色，GPT-4o和Deepseek-R1仍然会犯错误。研究还讨论了所有模型中最常见的错误类型。

**Conclusion:** 本研究是首次对所提及数据集使用LLM和提示算法进行的更广泛分析。工作揭示了已知提示算法在论证分析中的一些弱点，并指出了改进方向。此外，该工作还对现有论证数据集进行了深入分析，并揭示了它们的不足之处。

> **ai_Abstract:** 本研究全面评估了大型语言模型（LLM）在论证分类任务中的表现，涵盖了从Llama到GPT-4o和Deepseek-R1等多种模型，并探讨了思维链（CoT）等推理增强算法的影响。研究发现GPT-4o在整体论证分类基准测试中表现最佳，而Deepseek-R1在结合推理能力时显示出优势。尽管LLM表现出色，但仍会犯错，研究分析了常见错误类型。此工作首次对公共论证数据集进行了广泛的LLM和提示算法分析，揭示了现有提示算法的局限性并提出了改进方向，同时也深入分析了数据集本身的不足。

> **摘要翻译:** 论证挖掘（AM）是一个跨学科研究领域，融合了逻辑学、哲学、语言学、修辞学、法学、心理学和计算机科学的见解。它涉及论证成分（如前提和主张）的自动识别和提取，以及它们之间关系（如支持、攻击或中立）的检测。最近，该领域取得了显著进展，特别是随着大型语言模型（LLM）的出现，与传统方法和其他深度学习模型相比，LLM显著提升了分析和提取论证语义的效率。尽管有许多基准测试用于检验和验证LLM的质量，但对于这些模型在公开论证分类数据库中的运行情况，仍缺乏研究和结果。本文对选定的大型语言模型进行了研究，使用了Args.me和UKP等多样化数据集。测试的模型包括GPT、Llama和DeepSeek的各种版本，以及结合了思维链算法的推理增强变体。结果表明，ChatGPT-4o在论证分类基准测试中表现优于其他模型。在结合推理能力的模型中，Deepseek-R1展现出其优越性。然而，尽管表现出色，GPT-4o和Deepseek-R1仍然会犯错误。文中讨论了所有模型中最常见的错误。据我们所知，本研究是首次使用LLM和提示算法对上述数据集进行的更广泛分析。该工作还揭示了已知提示算法在论证分析中的一些弱点，并指出了改进方向。该工作的附加价值在于对现有论证数据集的深入分析以及对它们不足之处的展示。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [436] [BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](https://arxiv.org/abs/2507.18305)
> *BadReasoner：在大推理模型中植入可调的过度思考后门，以供娱乐或盈利*

*Biao Yi, Zekun Fei, Jianing Geng, Tong Li, Lihai Nie, Zheli Liu, Yiming Li* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 大型推理模型, 过度思考后门, 数据投毒, 链式思考, 资源消耗

**Comment:** 

> **TL;DR:** 本研究发现并实现了一种针对大型推理模型（LRMs）的新型可调过度思考后门攻击，通过数据投毒使模型在保持正确性的前提下产生冗余的链式思考，从而增加资源消耗。

**AI_Comments:** 这项研究提出了一种新颖且具有潜在威胁的攻击方式，其创新之处在于引入了“可调”和“隐蔽性”的过度思考后门。该攻击通过数据投毒实现，并能精确控制模型推理的冗余程度，同时不影响最终输出的正确性，这使得攻击更难被察觉。其重要性在于揭示了大型推理模型在资源消耗方面的潜在脆弱性，对于未来模型安全和鲁棒性研究具有指导意义。该研究为理解和防御这种新型攻击提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）在复杂推理任务中展现出强大的链式思考（CoT）能力，但本研究发现并探索了一种此前未被发现的攻击向量，即“过度思考后门”，旨在揭示并利用其潜在的资源消耗弱点。

**Method:** 作者提出了一种新颖的可调后门，通过数据投毒实现。该方法将一个可调触发器（重复次数指示所需强度）与相应冗长的链式思考（CoT）响应配对。这些响应由一个教师LLM程序化生成，通过注入受控数量的冗余细化步骤到正确的推理过程中，从而在不影响最终答案正确性的前提下，增加推理过程的冗余度。

**Result:** 在各种大型推理模型（LRMs）上进行的广泛实证结果表明，该方法能够可靠地触发可控的、多倍的推理过程长度增加，同时不降低最终答案的正确性。

**Conclusion:** 本研究成功演示了一种针对大型推理模型（LRMs）的隐蔽性“过度思考后门”攻击，该攻击通过增加推理过程的冗余度来消耗资源，而不影响输出的正确性，揭示了LRMs潜在的资源消耗漏洞。

> **ai_Abstract:** 本文介绍了一种针对大型推理模型（LRMs）的新型“过度思考后门”攻击，名为BadReasoner。该攻击利用数据投毒技术，通过在训练数据中注入带有重复触发器和冗余链式思考（CoT）响应的样本，使得LRMs在特定触发下生成过长的推理过程，从而消耗更多计算资源，同时保持最终答案的正确性。实验证明，这种方法能有效且可控地增加推理长度而不损害模型性能，揭示了LRMs潜在的资源消耗型漏洞。

> **摘要翻译:** 大型推理模型（LRMs）作为人工智能领域的一项重大进展，代表了一类专门设计用于解决复杂推理任务的大型语言模型（LLMs）。LRMs的决定性特征在于其广泛的思维链（CoT）推理能力。在本文中，我们发现了一种此前未被探索过的针对LRMs的攻击向量，我们称之为“过度思考后门”。我们通过提出一种新型的可调后门来推进这一概念，它超越了简单的开/关攻击，攻击者可以精确控制模型推理冗余的程度。我们的攻击通过一种新颖的数据投毒方法实现。它将一个可调触发器（其中重复次数表示所需的强度）与一个相应冗长的CoT响应配对。这些响应是通过指示一个教师LLM在正确的推理过程中注入受控数量的冗余细化步骤来程序化生成的。这种方法保持了输出的正确性，从而确保了隐蔽性，并将这种攻击确立为一种纯粹的资源消耗向量。在各种LRMs上进行的广泛实证结果表明，我们的方法可以可靠地触发推理过程长度的可控的、多倍的增加，而不会降低最终答案的正确性。我们的源代码可在https://github.com/FZaKK/BadReasoner获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [449] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
> *深度学习在几何问题解决中的综述*

*Jianzhe Ma, Wenxuan Wang, Qin Jin* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 深度学习, 几何问题解决, 综述, 数学推理, 多模态大型语言模型

**Comment:** Work in progress

> **TL;DR:** 这篇综述全面回顾了深度学习在几何问题解决中的应用，涵盖了任务、方法、评估和未来方向，旨在为该领域提供参考。

**AI_Comments:** 这是一篇重要的综述性论文，因为它系统地梳理了深度学习在几何问题解决这一复杂且关键领域中的应用。其价值在于为研究人员提供了一个结构化的知识框架，涵盖了任务、方法、评估和未来挑战，有助于新入门者快速了解该领域，并为资深研究者提供全面的参考。论文还提供了一个持续更新的GitHub资源列表，这对于促进社区协作和知识共享非常有益。

<details>
  <summary>Details</summary>

**Motivation:** 几何问题解决是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估和多模态能力评估。近年来，深度学习技术，特别是多模态大型语言模型的快速发展，引发了广泛的研究热潮。

**Method:** 本文对深度学习在几何问题解决中的应用进行了综述，包括：(i) 对几何问题解决中相关任务的全面总结；(ii) 对相关深度学习方法的彻底回顾；(iii) 对评估指标和方法的详细分析；以及 (iv) 对当前挑战和未来方向的批判性讨论。

**Result:** 本文提供了一个关于深度学习在几何问题解决中应用的全面而实用的参考，总结了相关任务、回顾了深度学习方法、分析了评估指标和方法，并讨论了挑战和未来方向。

**Conclusion:** 本文旨在为深度学习在几何问题解决领域提供一个全面且实用的参考，以促进该领域的进一步发展。

> **ai_Abstract:** 本文对深度学习在几何问题解决领域的应用进行了全面综述。它详细总结了相关任务、深入回顾了深度学习方法、分析了评估指标，并讨论了该领域的当前挑战和未来发展方向。该综述旨在为研究人员提供一个实用且全面的参考，以推动几何问题解决与深度学习交叉领域的发展。

> **摘要翻译:** 几何问题解决是数学推理的一个关键领域，广泛涉及教育、人工智能数学能力评估和多模态能力评估等许多重要领域。近年来，深度学习技术的快速发展，特别是多模态大型语言模型的兴起，引发了广泛的研究热潮。本文对深度学习在几何问题解决中的应用进行了综述，包括 (i) 对几何问题解决中相关任务的全面总结；(ii) 对相关深度学习方法的彻底回顾；(iii) 对评估指标和方法的详细分析；以及 (iv) 对当前挑战和未来方向的批判性讨论。我们的目标是为深度学习在几何问题解决领域提供一个全面而实用的参考，以促进该领域的进一步发展。我们创建了一个持续更新的GitHub论文列表：https://github.com/majianz/dl4gps。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [452] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
> *TELEVAL：一个为中文交互场景下口语语言模型设计的动态基准测试*

*Zehan Li, Hongjie Chen, Yuxin Zhang, Jing Zhou, Xuening Wang, Hang Lv, Mengjie Du, Yaodong Song, Jie Lian, Jian Kang, Jie Li, Yongxiang Li, Zhongjiang He, Xuelong Li* | **Category: cs.CL, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 口语语言模型, 基准测试, 中文交互, 对话代理, TELEVAL

**Comment:** 

> **TL;DR:** TELEVAL是一个针对中文交互场景下口语语言模型（SLM）的动态基准测试，旨在评估SLM在真实对话中的表现，并发现现有模型在自然对话任务中仍有很大改进空间。

**AI_Comments:** TELEVAL的创新之处在于其以用户为中心的设计理念，关注SLM在真实对话场景中的表现，特别是对隐式语义的捕捉能力，这弥补了现有基准在评估SLM实际交互能力上的不足。该基准有望推动SLM向更自然、更符合用户体验的方向发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数口语语言模型（SLM）评估基准主要侧重于评估SLM是否能执行与大型语言模型（LLM）相当的复杂任务，但往往未能与用户在真实对话场景中的自然交互方式保持一致。

**Method:** 本文提出了TELEVAL，一个专门用于评估SLM在真实中文交互环境中作为对话代理有效性的动态基准测试。TELEVAL定义了三个评估维度：显式语义、副语言和隐式语义、以及系统能力。它采用与实际使用一致的对话格式，并分别评估文本和音频输出。TELEVAL特别关注模型从用户语音中提取隐式线索并无需额外指令即可适当响应的能力。

**Result:** 我们的实验表明，尽管近期取得了进展，但现有口语语言模型在自然对话任务方面仍有相当大的改进空间。

**Conclusion:** TELEVAL旨在作为一个以用户为中心的评估框架，直接反映用户体验，并有助于开发更强大的面向对话的口语语言模型。

> **ai_Abstract:** 本文提出了TELEVAL，一个专为评估中文交互场景下口语语言模型（SLM）在真实对话中表现的动态基准测试。该基准定义了显式语义、副语言和隐式语义以及系统能力三个评估维度，并采用真实的对话格式，分别评估文本和音频输出，尤其关注模型从用户语音中提取隐式线索的能力。实验结果显示，现有SLM在自然对话任务上仍有显著提升空间。TELEVAL旨在成为一个用户中心的评估框架，以促进更优秀的对话型SLM的发展。

> **摘要翻译:** 口语语言模型（SLM）近年来取得了快速进展，同时涌现了许多用于评估其性能的基准测试。然而，大多数现有基准主要侧重于评估SLM是否能执行与大型语言模型（LLM）相当的复杂任务，往往未能与用户在真实世界对话场景中的自然交互方式保持一致。在本文中，我们提出了TELEVAL，一个专门设计用于评估SLM在真实中文交互环境中作为对话代理有效性的动态基准测试。TELEVAL定义了三个评估维度：显式语义、副语言和隐式语义，以及系统能力。它采用与实际使用一致的对话格式，并分别评估文本和音频输出。TELEVAL特别关注模型从用户语音中提取隐式线索并无需额外指令即可适当响应的能力。我们的实验表明，尽管近期取得了进展，但现有SLM在自然对话任务方面仍有相当大的改进空间。我们希望TELEVAL能作为一个以用户为中心的评估框架，直接反映用户体验，并有助于开发更强大的面向对话的SLM。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [473] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
> *FLEXITOKENS：面向演化语言模型的灵活分词*

*Abraham Toluase Owodunni, Orevaoghene Ahia, Sachin Kumar* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 灵活分词, 语言模型, 可学习分词器, 字节级模型, 过度碎片化

**Comment:** 

> **TL;DR:** FLEXITOKENS提出了一种灵活的分词方法，通过可学习的分词器和简化的训练目标，解决了现有语言模型在适应新数据分布时因分词器僵化导致的分词效率低下问题，显著提升了下游任务性能。

**AI_Comments:** 本文的创新点在于提出了FLEXITOKENS，通过引入可学习的字节级分词器和简化的训练目标，有效解决了传统分词器在语言模型适应新数据分布时面临的僵化和效率问题。其核心思想是让分词本身变得灵活和自适应，而非固定不变，这对于处理多样化和不断演变的语言数据至关重要。该方法在减少过度碎片化和提升下游任务性能方面的显著效果，表明了其在实际应用中的巨大潜力，尤其是在多语言和形态丰富的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型（LMs）难以适应新的数据分布，因为其子词分词器在适应过程中通常保持不变，导致分词僵化，进而造成域外数据、未见语言或脚本的过度碎片化分词，效率低下。

**Method:** 本文开发了具有可学习分词器的字节级语言模型。模型包含一个子模块，该模块学习预测输入字节序列之间的边界，并将其编码为可变长度的片段。与现有强制固定压缩率（引入新僵化）的无分词器方法不同，本文提出了FLEXITOKENS，这是一种简化的训练目标，可在适应过程中实现更大的灵活性。

**Result:** FLEXITOKENS在多个多语言基准、形态多样的任务和领域中进行评估，结果表明它能持续减少分词过度碎片化，并且在下游任务性能方面比子词分词器和其他基于梯度的分词器提高了高达10%。

**Conclusion:** FLEXITOKENS通过引入灵活的可学习分词器和简化的训练目标，有效解决了语言模型在适应新数据分布时面临的僵化分词问题，显著提高了分词效率和下游任务性能。

> **ai_Abstract:** 本研究提出FLEXITOKENS，旨在解决语言模型在适应新数据分布时，因传统子词分词器僵化导致的分词效率低下和过度碎片化问题。作者开发了带有可学习分词器的字节级语言模型，其核心是一个预测字节边界并生成可变长度片段的子模块。FLEXITOKENS引入了一个简化的训练目标，相较于现有无分词器方法中强制固定压缩率的僵化，提供了更大的适应灵活性。实验结果显示，FLEXITOKENS能显著减少分词碎片化，并在多语言和形态多样任务上将下游性能提升高达10%。

> **摘要翻译:** 语言模型（LMs）难以通过简单的微调来适应新的数据分布。这是由于其子词分词器的僵化性，这些分词器在适应过程中通常保持不变。这种不灵活性常常导致分词效率低下，造成域外领域、未见语言或脚本的过度碎片化。在这项工作中，我们开发了带有可学习分词器的字节级语言模型，以使分词具有适应性。我们的模型包含一个子模块，该子模块学习预测输入字节序列之间的边界，将其编码为可变长度的片段。现有的无分词器方法使用辅助损失来训练这个边界预测器，该损失在整个训练语料库中强制执行固定的压缩率，引入了一种新的僵化。我们提出了FLEXITOKENS，这是一种简化的训练目标，可在适应过程中实现显著更大的灵活性。通过在多个多语言基准、形态多样的任务和领域中进行评估，我们证明了FLEXITOKENS持续减少了分词过度碎片化，并且与子词分词器和其他基于梯度的分词器相比，在下游任务性能上实现了高达10%的改进。我们实验的代码和数据将在https://github.com/owos/flexitokens发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [478] [Uncertainty Quantification for Evaluating Machine Translation Bias](https://arxiv.org/abs/2507.18338)
> *机器翻译偏差评估中的不确定性量化*

*Ieva Raminta Staliūnaitė, Julius Cheng, Andreas Vlachos* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 机器翻译偏见, 不确定性量化, 性别偏见, 语义不确定性, 去偏

**Comment:** 

> **TL;DR:** 本研究探讨了机器翻译模型在处理性别模糊词时的偏见问题，并发现模型在模糊实例中未能表现出预期的不确定性，且去偏效果对模糊和明确实例是独立的。

**AI_Comments:** 该论文通过引入不确定性量化来评估机器翻译中的性别偏见，提供了一个新颖的视角，超越了传统的准确性评估。其发现模型在模糊情况下的不确定性不足以及去偏效果的独立性，对未来开发更公平、更鲁棒的机器翻译系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在机器翻译中，当源语句包含性别未明确标记但目标语言需要指定性别的词素时，模型必须推断性别。然而，现有研究表明机器翻译模型存在偏见行为，即使与上下文冲突也依赖刻板印象。本文提出，除了在性别明确时准确翻译，模型在性别模糊时也应保持不确定性。

**Method:** 使用最近提出的语义不确定性度量标准进行评估。

**Result:** 研究发现，在性别明确实例上具有高翻译和性别准确性的模型，在性别模糊实例中不一定表现出预期的不确定性水平。此外，去偏对模糊和明确的翻译实例具有独立的影响。

**Conclusion:** 现有机器翻译模型及其去偏方法在处理性别模糊的翻译实例时，未能有效量化不确定性，且去偏效果对不同类型的实例作用独立，这表明需要更精细的方法来解决性别偏见问题。

> **ai_Abstract:** 该论文探讨了机器翻译模型在处理性别模糊词时的偏见问题。研究指出，当源语言词汇性别不明确而目标语言需要指定时，模型往往依赖刻板印象而非上下文。作者提出模型在性别模糊时应量化不确定性。通过使用语义不确定性度量，研究发现即使在明确实例上表现良好的模型，在模糊实例上也不具备预期的不确定性，并且去偏对模糊和明确的翻译实例具有独立影响。

> **摘要翻译:** 在机器翻译（MT）中，当源句包含一个性别未明确标记的词素，但其目标语言对应词需要性别指定时，模型必须从上下文和/或外部知识中推断出适当的性别。研究表明，机器翻译模型表现出有偏见的行为，即使与上下文信息冲突，也会依赖刻板印象。我们认为，除了在输入明确时自信地使用正确性别进行翻译外，模型在性别模糊时也应保持不确定性。我们使用最近提出的语义不确定性度量标准，发现对于明确实例具有高翻译和性别准确性的模型，在模糊实例中不一定表现出预期的不确定性水平。同样，去偏对模糊和明确的翻译实例具有独立的影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [489] [GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface](https://arxiv.org/abs/2507.18546)
> *GLiNER2：一种高效的多任务信息抽取系统，具有模式驱动接口*

*Urchade Zaratiana, Gil Pasternak, Oliver Boyd, George Hurn-Maloney, Ash Lewis* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 信息抽取, 多任务, 命名实体识别, 文本分类, 模式驱动, GLiNER2

**Comment:** 

> **TL;DR:** GLiNER2是一个高效、统一的多任务信息抽取系统，它在单个模型中支持命名实体识别、文本分类和层次化数据抽取，并通过模式驱动接口实现多任务组合。它在性能上与大型语言模型相当，但在部署可访问性方面有显著优势。

**AI_Comments:** GLiNER2的创新之处在于其统一的多任务处理能力和高效性，避免了对昂贵LLM的依赖，并提高了部署的便捷性。其模式驱动接口也提升了系统的灵活性和易用性。作为一个开源库，它有望促进信息抽取领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有信息抽取（IE）解决方案通常需要针对不同任务的专用模型，或者依赖于计算成本高昂的大型语言模型，这限制了其效率和部署便捷性。

**Method:** GLiNER2是一个统一的框架，它增强了原始的GLiNER架构。该系统基于预训练的Transformer编码器架构，旨在保持CPU效率和紧凑尺寸，并通过直观的模式驱动接口引入多任务组合，支持命名实体识别、文本分类和层次化结构数据抽取。

**Result:** 实验表明，GLiNER2在抽取和分类任务上表现出有竞争力的性能，与基于大型语言模型（LLM）的替代方案相比，在部署可访问性方面有显著改进。

**Conclusion:** GLiNER2提供了一个高效、统一的多任务信息抽取解决方案，该方案在性能上具有竞争力，并在部署可访问性方面优于基于大型语言模型的替代方案，是NLP应用的宝贵开源工具。

> **ai_Abstract:** GLiNER2是一个高效、统一的多任务信息抽取系统，旨在解决现有IE方案的局限性。它基于增强的GLiNER架构和预训练Transformer编码器，支持命名实体识别、文本分类和层次化数据抽取，并通过模式驱动接口实现多任务组合。GLiNER2在保持CPU效率和紧凑性的同时，在性能上与LLM替代方案相当，并在部署可访问性方面表现出显著优势。该系统已作为开源库发布。

> **摘要翻译:** 信息抽取（IE）是众多自然语言处理（NLP）应用的基础，然而现有的解决方案通常需要针对不同任务的专用模型，或者依赖于计算成本高昂的大型语言模型。我们提出了GLiNER2，这是一个统一的框架，它增强了原始的GLiNER架构，以在一个高效的模型中支持命名实体识别、文本分类和层次化结构数据抽取。GLiNER2基于预训练的Transformer编码器架构构建，在保持CPU效率和紧凑尺寸的同时，通过直观的基于模式的接口引入了多任务组合。我们的实验表明，与基于LLM的替代方案相比，GLiNER2在抽取和分类任务上表现出有竞争力的性能，并在部署可访问性方面有显著改进。我们将GLiNER2作为开源的pip可安装库发布，其中包含预训练模型和文档，网址为https://github.com/fastino-ai/GLiNER2。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [504] [Multilingual LLMs Are Not Multilingual Thinkers: Evidence from Hindi Analogy Evaluation](https://arxiv.org/abs/2507.13238)
> *多语言大型语言模型并非多语言思考者：来自印地语类比评估的证据*

*Ashray Gupta, Rohan Joseph, Sunny Rai* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 多语言LLMs, 印地语, 类比推理, HATS, 提示策略

**Comment:** 

> **TL;DR:** 研究表明，多语言LLMs在印地语类比推理方面表现不佳，且英语提示效果最好，引入了新的印地语类比测试集HATS。

**AI_Comments:** 这项研究的创新之处在于引入了首个专门用于评估LLM在印地语类比推理能力上的测试集HATS，填补了该领域的空白。同时，其发现多语言LLMs在印地语类比推理中仍依赖英语提示，表明当前多语言LLMs的“多语言思考”能力可能不如预期，这对于未来多语言LLM的设计和优化具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** LLMs在英语推理方面得到了广泛评估，但在印地语等印度语言中的能力仍未得到充分研究，这限制了我们对这些模型是否能跨语言泛化的理解。

**Method:** 引入了一个新的印地语类比测试集（HATS），包含405个来自印度政府考试的多项选择题；使用各种提示策略对最先进的多语言LLMs进行基准测试；引入了一种基于认知类比推理理论的“接地链式思维”（grounded Chain of Thought）方法。

**Result:** “接地链式思维”方法提高了模型在印地语类比问题上的表现；模型在使用英语提示时表现最佳，无论提示策略如何。

**Conclusion:** 多语言LLMs在印地语类比推理方面表现不佳，且英语提示效果最好。新引入的HATS测试集解决了评估LLM在印地语推理能力方面关键资源的缺乏问题。

> **ai_Abstract:** 该研究旨在解决多语言LLMs在印度语言（特别是印地语）推理能力评估方面的不足。为此，作者创建了一个新的印地语类比测试集（HATS），并对当前最先进的多语言LLMs进行了基准测试。研究还提出了一种基于认知理论的“接地链式思维”方法，该方法能提升模型在印地语类比任务上的表现。实验结果显示，模型在使用英语提示时效果最好，这表明多语言LLMs在非英语语言的类比推理方面仍存在局限。HATS的引入填补了印地语LLM推理能力评估资源的空白。

> **摘要翻译:** 类比测试模型推断概念间隐含关系的能力，使其成为评估推理能力的关键基准。尽管大型语言模型（LLMs）在英语推理方面得到了广泛评估，但它们在印度语言中的能力仍未得到充分研究，这限制了我们对这些模型是否能跨语言泛化的理解。为了弥补这一空白，我们引入了一个新的印地语类比测试集（HATS），包含405个来自印度政府考试的多项选择题。我们使用各种提示策略对最先进的多语言LLMs进行基准测试，并引入了一种基于类比推理认知理论的“接地链式思维”方法。这种方法提高了模型在印地语类比问题上的表现。我们的实验表明，无论提示策略如何，模型在使用英语提示时表现最佳。我们的测试集解决了评估LLM在印地语推理能力方面关键资源的缺乏问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [514] [TDR: Task-Decoupled Retrieval with Fine-Grained LLM Feedback for In-Context Learning](https://arxiv.org/abs/2507.18340)
> *TDR：基于细粒度大型语言模型反馈的任务解耦检索，用于上下文学习*

*Yifu Chen, Bingchen Huang, Zhiling Wang, Yuanchao Du, Junfeng Luo, Lei Shen, Zhineng chen* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 上下文学习, 示例检索, 大型语言模型, 任务解耦, 细粒度反馈

**Comment:** 

> **TL;DR:** TDR是一种新的框架，通过任务解耦和细粒度LLM反馈来提高上下文学习（ICL）的示例检索质量，在30个NLP任务上实现了最先进的性能。

**AI_Comments:** TDR的创新之处在于其双重策略：任务解耦和利用细粒度LLM反馈。任务解耦解决了多任务数据集中示例检索的难题，而LLM反馈则提供了更精确的指导，以选择高质量示例。其即插即用的特性也增加了其实用性和潜在影响力。该研究对于提升大型语言模型在实际应用中的ICL性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 上下文学习（ICL）的效果严重依赖于示例质量，但现有的示例检索方法面临两个挑战：1）难以区分跨任务数据分布；2）难以在检索器输出和LLM反馈之间建立细粒度连接。

**Method:** 本文提出了一个名为TDR的新型框架。TDR将不同任务的ICL示例解耦，使检索模块能够在多任务数据集中检索特定于目标任务的示例。此外，TDR建模了来自LLM的细粒度反馈，以监督和指导检索模块的训练。

**Result:** 在30个NLP任务上进行了广泛实验，结果表明TDR在所有数据集上持续改进了结果，并取得了最先进的性能。同时，该方法是一种即插即用方法，可以轻松与各种LLM结合，以提高ICL的示例检索能力。

**Conclusion:** TDR通过任务解耦和利用细粒度LLM反馈，显著提高了上下文学习的示例检索质量，并在多项NLP任务中表现出优越性。

> **ai_Abstract:** 本文提出了一种名为TDR的新型框架，旨在解决上下文学习（ICL）中高质量示例检索的挑战。TDR通过任务解耦来处理跨任务数据分布问题，并利用大型语言模型（LLM）的细粒度反馈来优化检索模块的训练。实验结果表明，TDR在30个NLP任务上均取得了持续的性能提升，并达到了最先进的水平。该方法具有即插即用特性，易于与现有LLM结合以增强ICL的示例检索能力。

> **摘要翻译:** 上下文学习（ICL）已成为使大型语言模型（LLM）能够基于少量输入-输出示例处理各种任务的经典方法。ICL的有效性严重依赖于这些示例的质量，以前专注于增强示例检索能力的工作已经取得了令人印象深刻的性能。然而，在检索高质量示例方面仍然存在两个挑战：（1）难以区分跨任务数据分布，（2）难以在检索器输出和LLM反馈之间建立细粒度连接。在本文中，我们提出了一个名为TDR的新型框架。TDR将不同任务的ICL示例解耦，这使得检索模块能够在多任务数据集中检索特定于目标任务的示例。此外，TDR建模了来自LLM的细粒度反馈，以监督和指导检索模块的训练，这有助于检索高质量的示例。我们在30个NLP任务套件上进行了广泛的实验，结果表明TDR在所有数据集上持续改进了结果，并取得了最先进的性能。同时，我们的方法是一种即插即用方法，可以轻松与各种LLM结合，以提高ICL的示例检索能力。代码可在https://github.com/Nnn-s/TDR获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [521] [What Makes You CLIC: Detection of Croatian Clickbait Headlines](https://arxiv.org/abs/2507.14314)
> *是什么让你点击：克罗地亚点击诱饵标题检测*

*Marija Anđelić, Dominik Šipek, Laura Majer, Jan Šnajder* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 点击诱饵检测, 克罗地亚语, 数据集, 微调, 上下文学习

**Comment:** Accepted at Slavic NLP 2025

> **TL;DR:** 构建了克罗地亚语点击诱饵标题检测数据集CLIC，并比较了微调模型和上下文学习（ICL）方法的性能，发现微调模型表现更好。

**AI_Comments:** 本研究的创新点在于为克罗地亚语这一资源较少的语言构建了首个点击诱饵检测数据集CLIC，并明确比较了微调模型和上下文学习（ICL）方法在该任务上的表现。其发现微调模型优于通用LLM，为特定语言和任务的自然语言处理提供了宝贵见解，对于维护数字媒体的信息质量和读者信任具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在线新闻主要依赖广告收入，导致记者创作点击诱饵标题。自动检测点击诱饵对于维护数字媒体的信息质量和读者信任至关重要。对于资源较少的语言，目前尚不清楚微调方法还是上下文学习（ICL）能取得更好的结果。

**Method:** 本文编译了一个名为CLIC的克罗地亚语新闻点击诱饵检测新数据集，涵盖20年期间的主流和边缘媒体。研究将BERTi'c模型进行微调，并将其性能与基于大型语言模型（LLM）的上下文学习（ICL）方法进行比较，提示语包括克罗地亚语和英语。最后，分析了点击诱饵的语言特性。

**Result:** 研究发现，近一半的分析标题包含点击诱饵，并且微调模型比通用大型语言模型（LLMs）提供了更好的结果。

**Conclusion:** 微调模型在克罗地亚语点击诱饵检测任务上优于通用大型语言模型，且点击诱饵在克罗地亚新闻中普遍存在。

> **ai_Abstract:** 本研究介绍了CLIC，一个用于克罗地亚语新闻点击诱饵标题检测的新数据集。论文比较了微调的BERTi'c模型与基于大型语言模型（LLM）的上下文学习（ICL）方法，结果表明微调模型表现更优。此外，研究还分析了点击诱饵的语言特性，并指出近半数标题存在点击诱饵。

> **摘要翻译:** 在线新闻媒体主要依靠基于广告的收入模式运作，这迫使记者创作常常具有煽动性、引人入胜和挑衅性的标题——通常被称为点击诱饵。自动检测点击诱饵标题对于维护数字媒体的信息质量和读者信任至关重要，这既需要上下文理解也需要世界知识。对于这项任务，特别是在资源较少的语言中，微调方法还是上下文学习（ICL）能产生更好的结果尚不明确。在本文中，我们编译了CLIC，这是一个用于克罗地亚新闻点击诱饵检测的新数据集，涵盖了20年期间的主流和边缘媒体。我们对BERTi'c模型进行了微调，并将其性能与基于LLM的ICL方法进行了比较，提示语包括克罗地亚语和英语。最后，我们分析了点击诱饵的语言特性。我们发现，近一半的分析标题包含点击诱饵，并且微调模型比通用LLMs提供了更好的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [525] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
> *一个Whisper模型评估所有*

*Nhan Phan, Anusha Porwal, Yaroslav Getman, Ekaterina Voskoboinik, Tamás Grósz, Mikko Kurimo* | **Category: cs.CL, eess.AS** | **Updated: 2025-07-23**

**Keywords:** 自动口语评估, Whisper模型, 端到端, 数据效率, 第二语言学习

**Comment:** Accepted to SLaTE 2025 workshop

> **TL;DR:** 本文提出了一种高效的端到端自动口语评估（ASA）方法，利用单个Whisper-small编码器处理多部分第二语言测试，并结合轻量级聚合器直接预测分数。该方法无需转录和分部分模型，显著缩短推理时间，且性能优于基线，同时展现出高数据效率。

**AI_Comments:** 这篇论文的创新点在于其端到端的单模型架构，特别是利用单个Whisper编码器处理多部分口语评估，这大大简化了传统上需要转录和多个模型的流程。这种方法显著提高了效率，降低了推理成本，使其在大规模计算机辅助语言学习系统（CALL）中具有很高的实用价值。此外，提出的数据采样策略也有效地解决了数据不平衡问题，进一步提升了模型的鲁棒性和数据利用率。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动口语评估（ASA）系统在处理多部分第二语言测试时效率不高，通常需要转录和分部分模型，导致推理时间长，限制了其在大规模计算机辅助语言学习系统中的实用性。

**Method:** 提出了一种高效的端到端自动口语评估方法，其核心是使用单个Whisper-small编码器处理所有四个口语回答，并通过一个轻量级聚合器整合信息，直接预测最终分数。这种架构消除了对转录和分部分模型的依赖。此外，还提出了一种数据采样策略，以提高模型在不平衡类别上的性能和数据效率。

**Result:** 该系统在均方根误差（RMSE）上达到0.384，优于基于文本的基线（0.44），且参数量最多为1.68亿（约Whisper-small的70%）。所提出的数据采样策略使模型仅使用语料库中44.8%的说话者数据即可达到0.383的RMSE，证明了其在不平衡类别上的性能提升和强大的数据效率。

**Conclusion:** 该研究提出了一种高效且性能优越的自动口语评估方法，通过简化模型架构和优化数据使用，显著提升了ASA在大规模计算机辅助语言学习系统中的实用性，并展现出良好的数据效率和对不平衡类别的处理能力。

> **ai_Abstract:** 本文提出了一种针对多部分第二语言测试的端到端自动口语评估（ASA）系统。该系统创新性地利用单个Whisper-small编码器处理所有口语回答，并通过轻量级聚合器直接预测分数，从而避免了传统的转录和多模型需求，显著提升了推理效率和在大规模计算机辅助语言学习系统中的实用性。实验结果表明，该系统在RMSE上优于基于文本的基线，且在参数效率和数据效率方面表现出色，尤其对不平衡类别具有良好的处理能力。

> **摘要翻译:** 我们提出了一种高效的端到端方法，用于对多部分第二语言测试进行整体自动口语评估（ASA），该方法是为2025年Speak & Improve挑战赛开发的。我们系统的主要新颖之处在于能够使用单个Whisper-small编码器处理所有四个口语回答，通过一个轻量级聚合器组合所有信息，并预测最终分数。这种架构消除了对转录和分部分模型的需要，缩短了推理时间，并使ASA在大规模计算机辅助语言学习系统中变得实用。我们的系统实现了0.384的均方根误差（RMSE），优于基于文本的基线（0.44），同时最多使用1.68亿参数（约Whisper-small的70%）。此外，我们提出了一种数据采样策略，允许模型仅使用语料库中44.8%的说话者进行训练，仍能达到0.383的RMSE，这表明在不平衡类别上的性能有所改善，并具有强大的数据效率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [536] [Identity-related Speech Suppression in Generative AI Content Moderation](https://arxiv.org/abs/2409.13725)
> *生成式AI内容审核中的身份相关言论抑制*

*Grace Proebsting, Oghenefejiro Isaacs Anigboro, Charlie M. Crawford, Danaé Metaxa, Sorelle A. Friedler* | **Category: cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-24**

**Keywords:** 内容审核, 生成式AI, 言论抑制, 身份偏见, 自动化过滤

**Comment:** ACM Conference on Equity and Access in Algorithms, Mechanisms, and
  Optimization, 2025

> **TL;DR:** 生成式AI内容审核系统倾向于错误地抑制与边缘化身份相关的言论，原因因身份而异。

**AI_Comments:** 这篇论文揭示了生成式AI内容审核中一个关键且紧迫的社会偏见问题，即对边缘化身份相关言论的系统性抑制。其创新之处在于定义了言论抑制的衡量标准，并构建了新的数据集和基准来量化这一现象。研究结果揭示了具体的错误标记模式和原因，为未来AI内容审核系统的公平性改进提供了重要见解。论文的重要性在于其对AI伦理和负责任AI开发的贡献，提醒开发者在追求生成质量的同时，不能忽视对言论多样性和包容性的潜在负面影响。

<details>
  <summary>Details</summary>

**Motivation:** 自动化内容审核系统在识别和过滤不良内容方面存在问题，尤其是在错误标记与边缘化身份相关的内容方面。生成式AI系统也使用这些过滤器，但较少关注确保适当文本的生成。随着生成式AI越来越多地用于创意或表达性文本生成，了解哪些故事可以被讲述，哪些会被抑制变得至关重要。

**Method:** 定义并引入言论抑制的衡量标准，重点关注被内容审核API错误过滤的与不同身份群体相关的言论。使用传统的用户生成短格式数据集和更长的生成式AI专用数据（包括本文引入的两个数据集），创建了一个用于衡量九个身份群体言论抑制的基准。测试了一个传统和四个生成式AI自动内容审核服务。

**Result:** 发现身份相关言论比其他言论更容易被错误抑制。错误标记行为的原因因身份而异，基于刻板印象和文本关联，例如，残疾相关内容更容易被标记为自残或健康相关，而非基督教内容更容易被标记为暴力或仇恨。

**Conclusion:** 随着生成式AI系统越来越多地用于创意工作，需要进一步关注这可能如何影响身份相关内容的创作。

> **ai_Abstract:** 本文研究了生成式AI内容审核系统中存在的身份相关言论抑制问题。研究发现，这些系统倾向于错误地过滤与边缘化身份相关的言论，其原因与刻板印象和文本关联有关。作者定义了言论抑制的衡量标准，并使用新旧数据集创建了一个基准，测试了多个内容审核服务，证实了身份相关言论更容易被错误抑制的现象。论文强调了随着生成式AI在创意领域的广泛应用，关注其对身份相关内容创作影响的重要性。

> **摘要翻译:** 自动化内容审核长期以来一直被用于帮助识别和过滤在线 undesired 用户生成内容。但此类系统在错误标记和删除边缘化身份相关内容方面有历史记录。生成式AI系统现在使用此类过滤器来防止 undesired 生成内容被用户创建或显示。虽然很多关注点都放在确保此类系统不会产生 undesired 结果上，但对确保能够生成适当文本的关注却少得多。从教室到好莱坞，随着生成式AI越来越多地用于创意或表达性文本生成，这些技术将允许谁的故事被讲述，又将抑制谁的故事？
在本文中，我们定义并引入了言论抑制的衡量标准，重点关注被一系列内容审核API错误过滤的与不同身份群体相关的言论。我们使用内容审核中传统的短格式用户生成数据集和更长的以生成式AI为中心的数据（包括我们在这项工作中引入的两个数据集），创建了一个用于衡量九个身份群体言论抑制的基准。在测试的一个传统和四个以生成式AI为中心的自动化内容审核服务中，我们发现身份相关言论比其他言论更容易被错误抑制。我们发现错误标记行为的原因因身份而异，基于刻板印象和文本关联，例如，残疾相关内容更容易因自残或健康相关原因被标记，而非基督教内容则更容易被标记为暴力或仇恨。随着生成式AI系统越来越多地用于创意工作，我们敦促进一步关注这可能如何影响身份相关内容的创作。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [545] [Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning](https://arxiv.org/abs/2507.16802)
> *Agentar-Fin-R1：通过领域专业知识、训练效率和高级推理增强金融智能*

*Yanjun Zheng, Xiyang Du, Longfei Liao, Xiaoke Zhao, Zhaowen Zhou, Jingze Song, Bo Zhang, Jiawei Liu, Xiang Qi, Zhe Li, Zhiqiang Zhang, Wei Wang, Peng Zhang* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 金融LLM, 推理, 可信度, 训练效率, Finova

**Comment:** 

> **TL;DR:** Agentar-Fin-R1是一系列新的金融大语言模型，通过优化方法、两阶段训练和新型评估基准，显著提升了金融任务上的最先进性能和通用推理能力，解决了现有模型在金融应用中推理、可信度和领域适应性方面的局限。

**AI_Comments:** 本文提出的Agentar-Fin-R1系列模型在金融领域大语言模型的发展中具有重要意义。其创新点在于结合了Qwen3基础模型，并特别强调了可信度保障框架和训练效率优化。引入Finova评估基准，专注于智能体级别的金融推理和合规性验证，是评估金融领域LLM实用性和可靠性的关键一步，填补了现有基准的空白。这对于推动金融AI的实际部署和应用具有显著价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型在金融应用中面临推理能力、严格的可信度标准和高效适应领域特定需求方面的局限性。

**Method:** 研究团队引入了基于Qwen3基础模型的Agentar-Fin-R1系列金融大语言模型（8B和32B参数）。优化方法整合了高质量、系统化的金融任务标签系统和多层次可信度保障框架，包括可信知识工程、多智能体可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段训练流程和动态归因系统，显著提高了训练效率。模型在Fineva、FinEval和FinanceIQ等主流金融基准以及MATH-500和GPQA-diamond等通用推理数据集上进行了全面评估。此外，还提出了Finova评估基准，专注于智能体级别的金融推理和合规性验证。

**Result:** Agentar-Fin-R1模型不仅在金融任务上取得了最先进的性能，而且展现出卓越的通用推理能力。

**Conclusion:** Agentar-Fin-R1被验证为高风险金融应用中有效且值得信赖的解决方案。

> **ai_Abstract:** Agentar-Fin-R1是一系列基于Qwen3的金融大语言模型（8B和32B），旨在解决现有LLM在金融应用中推理、可信度和领域适应性不足的问题。该模型通过集成高质量金融任务标签系统、多层次可信度保障框架（包括知识工程、数据合成和验证）以及优化训练效率的两阶段流程进行开发。在包括新提出的Finova在内的多个金融和通用推理基准上进行评估，Agentar-Fin-R1在金融任务上达到了SOTA性能，并展现出卓越的通用推理能力，证明了其作为高风险金融应用中可信解决方案的有效性。

> **摘要翻译:** 大型语言模型（LLMs）在金融应用中展现出巨大的潜力；然而，现有模型在需要复杂推理能力、严格可信度标准和高效适应领域特定场景时，经常表现出局限性。我们引入了Agentar-Fin-R1系列金融大语言模型（8B和32B参数），这些模型专门基于Qwen3基础模型进行工程设计，旨在增强金融应用的推理能力、可靠性和领域专业化。我们的优化方法整合了一个高质量、系统化的金融任务标签系统和一个全面的多层次可信度保障框架。该框架包括高质量的可信知识工程、多智能体可信数据合成以及严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段训练流程和动态归因系统，我们实现了训练效率的显著提升。我们的模型在包括Fineva、FinEval和FinanceIQ在内的主流金融基准以及MATH-500和GPQA-diamond等通用推理数据集上进行了全面评估。为了彻底评估实际部署能力，我们创新性地提出了Finova评估基准，该基准专注于智能体级别的金融推理和合规性验证。实验结果表明，Agentar-Fin-R1不仅在金融任务上取得了最先进的性能，而且展现出卓越的通用推理能力，验证了其作为高风险金融应用中可信解决方案的有效性。Finova基准可在https://github.com/antgroup/Finova获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [550] [Hybrid Annotation for Propaganda Detection: Integrating LLM Pre-Annotations with Human Intelligence](https://arxiv.org/abs/2507.18343)
> *宣传检测的混合标注：整合大型语言模型预标注与人类智能*

*Ariana Sahitaj, Premtim Sahitaj, Veronika Solopova, Jiaao Li, Sebastian Möller, Vera Schmitt* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 宣传检测, 混合标注, 大型语言模型, 知识蒸馏, 数据标注

**Comment:** NLP4PI at ACL

> **TL;DR:** 本文提出一种结合LLM预标注和人工验证的混合标注框架，以提高社交媒体宣传检测的数据标注一致性和可扩展性，并通过知识蒸馏训练小型模型进行结构化标注。

**AI_Comments:** 这篇论文的创新点在于提出了LLM辅助的混合标注方法，有效解决了高质量标注数据稀缺和标注一致性差的问题。通过将LLM的预标注能力与人类验证相结合，极大地提高了标注效率和数据质量。此外，利用LLM生成数据并通过知识蒸馏训练小型模型，为数据生成和模型训练提供了一条新颖且高效的路径，对于未来构建可扩展的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体上的宣传检测面临任务复杂性和高质量标注数据有限的挑战。

**Method:** 1. 提出一个将14种细粒度宣传技术组织成3个大类的分层分类法。2. 进行人类标注研究，发现细粒度标签的标注者间一致性低。3. 实施LLM辅助的预标注流程，提取宣传跨度，生成解释，并分配局部和全局标签。4. 进行二次人工验证研究。5. 微调小型语言模型(SLM)，通过知识蒸馏在LLM生成的高质量数据上进行训练，而不是在人工标注上训练。

**Result:** 人工验证研究显示，一致性和时间效率都有显著提高。通过LLM生成数据训练的SLM能够进行结构化标注。

**Conclusion:** 本工作有助于开发可扩展且稳健的宣传检测系统，支持透明和负责任的媒体生态系统。

> **ai_Abstract:** 本文提出一种新颖的混合标注框架，将大型语言模型（LLM）预标注与人工验证相结合，旨在解决社交媒体宣传检测中高质量标注数据稀缺和一致性低的问题。该框架包括一个分层分类法、LLM辅助的预标注流程以及后续的人工验证，实验证明显著提高了标注的一致性和效率。此外，研究还通过知识蒸馏利用LLM生成的高质量数据训练小型语言模型进行结构化标注，而非依赖传统的人工标注，从而推动了可扩展和鲁棒的宣传检测系统发展。

> **摘要翻译:** 社交媒体上的宣传检测由于任务复杂性和高质量标注数据有限而仍然具有挑战性。本文引入了一种新颖的框架，该框架结合了人类专业知识和大型语言模型（LLM）的辅助，以提高标注的一致性和可扩展性。我们提出了一个分层分类法，将14种细粒度宣传技术组织成三个更广泛的类别，在HQP数据集上进行了一项人类标注研究，揭示了细粒度标签的标注者间一致性较低，并实现了一个LLM辅助的预标注管道，该管道提取宣传跨度，生成简洁的解释，并分配局部标签以及一个全局标签。一项二次人工验证研究表明，在一致性和时间效率方面都有显著改进。在此基础上，我们微调了小型语言模型（SLM）以执行结构化标注。我们不是在人类标注上进行微调，而是在高质量的LLM生成数据上进行训练，允许大型模型生成这些标注，而小型模型通过知识蒸馏学习生成它们。我们的工作有助于开发可扩展且稳健的宣传检测系统，支持符合可持续发展目标16的透明和负责任的媒体生态系统。代码已在我们的GitHub仓库公开。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [560] [GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness](https://arxiv.org/abs/2507.18119)
> *GOAT-SLM：一个具有副语言和说话者特征感知的口语模型*

*Hongjie Chen, Zehan Li, Yaodong Song, Wenming Deng, Yitong Yao, Yuxin Zhang, Hang Lv, Xuechao Zhu, Jian Kang, Jie Lian, Jie Li, Chao Wang, Shuangyong Song, Yongxiang Li, Zhongjiang He* | **Category: cs.CL, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 口语模型, 副语言, 说话者特征, 语音生成, 语音交互

**Comment:** 

> **TL;DR:** GOAT-SLM是一个新型口语模型，它不仅处理语言内容，还能感知并利用语音中的副语言和说话者特征，从而实现更自然、自适应的语音交互。

**AI_Comments:** GOAT-SLM的创新之处在于其超越了传统口语模型仅关注语言内容的局限，引入了对副语言和说话者特征的感知，这对于构建更接近人类交流的、自然和社交感知的AI系统至关重要。其双模态头架构和模块化训练策略也提高了模型的效率和通用性，为未来口语AI的发展提供了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有口语模型仅将语音视为语言内容的载体，忽视了人类语音中丰富的副语言和说话者特征（如方言、年龄、情感、非语音发声），这限制了AI系统进行自然口语交互的能力。

**Method:** 本文提出了GOAT-SLM，一个具有副语言和说话者特征感知的口语模型。它采用双模态头架构，将语言建模与声学实现解耦，以实现稳健的语言理解并支持富有表现力和自适应的语音生成。为提高效率和多功能性，模型采用模块化、分阶段的训练策略，利用大规模语音-文本语料库逐步对齐语言、副语言和说话者特征信息。

**Result:** 在多维度评估基准TELEVAL上的实验结果表明，GOAT-SLM在语义和非语义任务上均实现了良好平衡的性能，并在处理情感、方言变异和年龄敏感交互方面优于现有开源模型。

**Conclusion:** 这项工作强调了在口语建模中超越语言内容进行建模的重要性，并推动了更自然、自适应和社交感知的口语系统发展。

> **ai_Abstract:** 本文介绍了一种名为GOAT-SLM的新型口语模型，旨在超越传统SLM仅关注语言内容的局限，通过感知和利用人类语音中丰富的副语言和说话者特征（如方言、年龄、情感）来提升AI系统的自然交互能力。该模型采用双模态头架构解耦语言建模与声学实现，并通过模块化、分阶段训练策略对齐多模态信息。实验证明，GOAT-SLM在语义和非语义任务上均表现出色，尤其在处理情感、方言和年龄敏感交互方面超越了现有开源模型，为开发更自然、自适应和社交感知的口语系统奠定了基础。

> **摘要翻译:** 端到端口语模型（SLM）的最新进展显著提高了AI系统进行自然口语交互的能力。然而，大多数现有模型仅将语音视为语言内容的载体，常常忽视人类语音中嵌入的丰富副语言和说话者特征线索，例如方言、年龄、情感和非语音发声。在这项工作中，我们引入了GOAT-SLM，一个具有副语言和说话者特征感知的新型口语模型，旨在将口语建模扩展到文本语义之外。GOAT-SLM采用双模态头架构，将语言建模与声学实现解耦，从而实现强大的语言理解，同时支持富有表现力和自适应的语音生成。为了提高模型效率和多功能性，我们提出了一种模块化、分阶段的训练策略，利用大规模语音-文本语料库逐步对齐语言、副语言和说话者特征信息。在多维度评估基准TELEVAL上的实验结果表明，GOAT-SLM在语义和非语义任务上均实现了良好平衡的性能，并在处理情感、方言变异和年龄敏感交互方面优于现有开源模型。这项工作强调了超越语言内容进行建模的重要性，并推动了更自然、自适应和社交感知的口语系统发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [569] [LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs](https://arxiv.org/abs/2507.16809)
> *LingBench++：一个用于LLM多步和跨文化推理的语言学知情基准和推理框架*

*Da-Chen Lian, Ri-Sheng Huang, Pin-Er Chen, Chunki Lim, You-Kuan Lin, Guan-Yu Tseng, Zi-Cheng Yang, Zhen-Yu Lin, Pin-Cheng Chen, Shu-Kai Hsieh* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 基准测试, 语言学推理, 跨文化, 多智能体系统

**Comment:** 42p, 17f, 10t. Revisions: Merged paragraphs in Intro to emphasize
  contributions. Clarified benchmark design (Sec 3.5.1). Added single-agent,
  OpenAI-guided & 6-round experiments (Sec 5.2). Note: we only ran each
  experiment once; statistical tests are needed for strong claims. Revised Sec
  6. Added acknowledgements, 2 new co-authors, and corrected typos/grammar

> **TL;DR:** LingBench++是一个新的基准和推理框架，用于评估大型语言模型在复杂语言任务上的表现，特别关注多步和跨文化推理，并引入了多智能体架构。

**AI_Comments:** LingBench++的创新之处在于其对LLM推理过程的细致评估，特别是引入了结构化推理轨迹和逐步评估，这超越了传统基准仅关注最终答案的局限性。其涵盖90多种低资源和跨文化语言的范围，以及多智能体架构的集成，使其在推动LLM的语言学和文化知情推理方面具有重要意义。该工作为未来的LLM评估和开发提供了一个更全面和可解释的框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试主要关注最终答案的准确性，而缺乏对LLMs在复杂语言任务上推理过程的细致评估，特别是在低资源和跨文化语言背景下。

**Method:** 提出LingBench++，一个语言学知情基准和推理框架，灵感来源于国际语言学奥林匹克。该框架提供结构化推理轨迹、逐步评估协议和涵盖90多种低资源和跨文化语言的丰富类型学元数据。此外，开发了一个集成了语法知识检索、工具增强推理和审慎假设检验的多智能体架构。

**Result:** 通过对基线模型和所提出的智能体模型的系统比较，结果表明，配备外部知识源和迭代推理的模型在准确性和可解释性方面均优于单次通过的方法。

**Conclusion:** LingBench++为推动LLMs中基于语言学、文化知情和认知合理性推理提供了全面的基础。

> **ai_Abstract:** LingBench++是一个新的语言学知情基准和推理框架，旨在评估大型语言模型（LLMs）在复杂的多步和跨文化语言任务上的能力。与现有基准不同，LingBench++提供详细的推理轨迹、逐步评估和丰富的多语言元数据。该框架还引入了一个多智能体架构，结合了知识检索、工具使用和假设检验。实验结果表明，这种方法显著提高了LLMs的准确性和可解释性，为LLMs在语言学和文化背景下的推理能力发展奠定了基础。

> **摘要翻译:** 我们提出了LingBench++，一个语言学知情的基准和推理框架，旨在评估大型语言模型（LLMs）在受国际语言学奥林匹克（IOL）启发的复杂语言任务上的表现。与以往仅关注最终答案准确性的基准不同，LingBench++提供了结构化推理轨迹、逐步评估协议以及涵盖90多种低资源和跨文化语言的丰富类型学元数据。我们进一步开发了一种多智能体架构，集成了语法知识检索、工具增强推理和审慎假设检验。通过对基线模型和我们提出的智能体模型的系统比较，我们证明了配备外部知识源和迭代推理的模型在准确性和可解释性方面均优于单次通过的方法。LingBench++为推进LLMs中基于语言学、文化知情和认知合理性的推理提供了全面的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [592] [Factual Inconsistencies in Multilingual Wikipedia Tables](https://arxiv.org/abs/2507.18406)
> *多语言维基百科表格中的事实不一致性*

*Silvia Cappa, Lingxiao Kong, Pille-Riin Peet, Fanfu Wei, Yuchen Zhou, Jan-Christoph Kalo* | **Category: cs.CL, cs.DB, cs.DL** | **Updated: 2025-07-24**

**Keywords:** 事实不一致性, 多语言维基百科, 表格数据, 跨语言对齐, AI系统

**Comment:** 11 pages, 7 figures, White Paper for RTF Work at ISWS Summer School
  2025

> **TL;DR:** 维基百科多语言版本独立更新导致事实不一致，尤其是在表格中。本研究开发了分析这些不一致性的方法，并探讨了其对AI和知识系统的影响。

**AI_Comments:** 这篇论文解决了维基百科这种大规模、协作构建的知识库中数据质量的关键问题。鉴于表格数据在AI系统中的直接应用，关注结构化表格数据尤其有价值。所提出的识别和分类不一致性的方法是创新的，为未来的数据协调和提高AI可靠性奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 维基百科的多语言版本独立更新导致事实不一致，影响百科全书的可靠性及依赖其作为训练源的AI系统。本研究旨在调查这些跨语言不一致性，尤其关注表格数据。

**Method:** 开发了一种方法来收集、对齐和分析维基百科多语言文章中的表格，并定义了不一致性的类别。使用样本数据集应用了多种定量和定性指标来评估多语言对齐情况。

**Result:** 本研究开发了一种方法并应用了指标来评估多语言对齐情况，提供了关于维基百科结构化内容中跨语言不一致性的见解。

**Conclusion:** 这些见解对事实核查、多语言知识交互以及设计利用维基百科内容的可靠AI系统具有重要意义。

> **ai_Abstract:** 维基百科的多语言版本独立更新，导致事实不一致，尤其是在表格数据中，这影响了其可靠性及依赖它的AI系统。本研究提出了一种方法，用于收集、对齐和分析多语言维基百科表格，对不一致性进行分类，并使用定量和定性指标评估对齐情况。研究结果对事实核查、多语言知识交互和可靠AI系统设计至关重要。

> **摘要翻译:** 维基百科是一个全球可访问的知识来源，包含300多种语言的内容。尽管涵盖相同的主题，但维基百科的不同版本是独立编写和更新的。这导致了事实不一致性，可能影响百科全书和AI系统的中立性和可靠性，而AI系统通常依赖维基百科作为主要的训练来源。本研究调查了维基百科结构化内容中的跨语言不一致性，重点关注表格数据。我们开发了一种方法来收集、对齐和分析维基百科多语言文章中的表格，并定义了不一致性的类别。我们使用样本数据集应用了多种定量和定性指标来评估多语言对齐情况。这些见解对事实核查、多语言知识交互以及设计利用维基百科内容的可靠AI系统具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [593] [Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models](https://arxiv.org/abs/2507.17702)
> *实现更大杠杆：高效专家混合语言模型的缩放定律*

*Changxin Tian, Kunlong Chen, Jia Liu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou* | **Category: cs.CL, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 专家混合, 缩放定律, 语言模型, 效率杠杆, 模型容量

**Comment:** 

> **TL;DR:** 本研究引入了效率杠杆（EL）指标，并通过大规模实证研究，揭示了MoE模型配置与效率杠杆之间的缩放定律，并验证了其准确性，为高效MoE模型的扩展提供了基础。

**AI_Comments:** 这项工作非常重要，它为理解和优化MoE架构的效率提供了量化的工具和实证基础。引入效率杠杆（EL）指标和发现明确的缩放定律是其创新之处。通过大规模实验和实际模型验证，论文为未来高效LLM的设计和扩展指明了方向，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管专家混合（MoE）架构通过解耦总参数与计算成本，成为扩展大型语言模型（LLM）的有效方式，但如何预测给定MoE配置（如专家激活比和粒度）的模型容量仍是一个未解决的问题。本研究旨在解决这一空白。

**Method:** 研究引入了“效率杠杆”（Efficiency Leverage, EL）指标来量化MoE模型相对于同等稠密模型的计算优势。通过训练超过300个模型（参数量高达28B）进行大规模实证研究，系统地调查了MoE架构配置与EL之间的关系。研究将发现整合到一个统一的缩放定律中，以准确预测MoE架构的EL。为了验证这些缩放定律，研究设计并训练了Ling-mini-beta（Ling-2.0系列的试点模型，仅0.85B活跃参数），并与一个6.1B的稠密模型进行比较，两者在相同的1T高质量token数据集上进行训练。

**Result:** 研究发现，效率杠杆（EL）主要由专家激活比和总计算预算驱动，两者均遵循可预测的幂律关系。专家粒度则作为非线性调节器，存在一个明确的最优范围。整合这些发现的统一缩放定律能够准确预测MoE架构的EL。验证实验表明，Ling-mini-beta（0.85B活跃参数）在与6.1B稠密模型相同的1T高质量token数据集上训练后，性能与后者持平，但计算资源消耗减少了7倍以上，从而证实了缩放定律的准确性。

**Conclusion:** 这项工作为高效MoE模型的扩展提供了原则性且基于实证的基础。

> **ai_Abstract:** 本研究旨在解决专家混合（MoE）模型中预测模型容量的挑战。研究引入了“效率杠杆”（EL）这一新指标，量化MoE模型相对于稠密模型的计算优势。通过对300多个模型的大规模实证研究，揭示了EL主要受专家激活比和总计算预算的幂律关系驱动，并发现专家粒度存在最优范围。这些发现被整合为一个统一的缩放定律。通过训练一个名为Ling-mini-beta的0.85B活跃参数模型，并与6.1B稠密模型进行比较，实验证实Ling-mini-beta在相同性能下，计算资源消耗减少了7倍以上，验证了所提出缩放定律的准确性，为高效MoE模型的扩展提供了坚实的基础。

> **摘要翻译:** 专家混合（MoE）已成为通过解耦总参数与计算成本来高效扩展大型语言模型（LLM）的主流架构。然而，这种解耦带来了一个关键挑战：预测给定MoE配置（例如，专家激活比和粒度）的模型容量仍然是一个未解决的问题。为了解决这一空白，我们引入了效率杠杆（EL），这是一个量化MoE模型相对于同等稠密模型的计算优势的指标。我们进行了一项大规模实证研究，训练了300多个参数量高达28B的模型，系统地调查了MoE架构配置与EL之间的关系。我们的发现揭示，EL主要由专家激活比和总计算预算驱动，两者都遵循可预测的幂律关系，而专家粒度则作为非线性调节器，具有明确的最优范围。我们将这些发现整合到一个统一的缩放定律中，该定律能够根据MoE架构的配置准确预测其EL。为了验证我们推导出的缩放定律，我们设计并训练了Ling-mini-beta，这是一个Ling-2.0系列的试点模型，仅有0.85B的活跃参数，并与一个6.1B的稠密模型进行比较。当在相同的1T高质量token数据集上进行训练时，Ling-mini-beta的性能与6.1B稠密模型匹配，同时消耗的计算资源减少了7倍以上，从而证实了我们缩放定律的准确性。这项工作为高效MoE模型的扩展提供了原则性且基于实证的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [616] [TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards](https://arxiv.org/abs/2507.18618)
> *TRPrompt：从文本奖励引导查询感知提示优化*

*Andreea Nica, Ivan Zakazov, Nicolas Mario Baldwin, Saibo Geng, Robert West* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 提示优化, 大型语言模型, 文本奖励, 查询感知, 提示模型

**Comment:** 

> **TL;DR:** TRPrompt通过将文本反馈直接整合到提示模型训练中，实现了查询感知的提示优化，并在数学数据集上取得了最先进的结果。

**AI_Comments:** TRPrompt的创新之处在于它首次将文本反馈直接融入到提示模型的训练过程中，而非仅仅作为训练无关的启发式或数值奖励。这种方法不仅避免了昂贵的数据集收集，还通过迭代反馈实现了自我改进，这对于提示优化领域是一个重要的进步。其在数学推理任务上的SOTA表现也证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有提示优化方法要么依赖启发式/训练无关的文本反馈，要么依赖数值奖励训练专门的提示模型，缺乏一种统一且高效的利用文本反馈训练提示模型的方法。

**Method:** 论文提出了TRPrompt（Textual Reward Prompt）框架，该框架通过将文本反馈直接整合到提示模型的训练中，统一了现有方法。它不需要预先收集数据集，并通过对生成提示的反馈进行迭代改进。利用LLM对“好”提示的内在理解能力和文本奖励提供的高分辨率信号来训练提示模型。

**Result:** TRPrompt训练的提示模型在具有挑战性的数学数据集GSMHard和MATH上，为问题生成了最先进的查询特定提示。

**Conclusion:** TRPrompt成功地将文本反馈整合到提示模型的训练中，提供了一种无需预先数据集收集且能迭代改进的提示优化方法，并在复杂数学推理任务上展现出卓越性能。

> **ai_Abstract:** 本文提出了TRPrompt框架，旨在统一现有的提示优化方法。TRPrompt通过将文本反馈直接整合到提示模型的训练中，克服了传统方法对预先数据集收集的需求，并支持迭代改进。该框架利用LLM对“好”提示的内在理解以及文本奖励提供的高分辨率信号，成功训练出能为复杂数学问题生成最先进查询特定提示的模型，并在GSMHard和MATH数据集上验证了其有效性。

> **摘要翻译:** 提示优化在不要求目标模型参数更新的情况下，提高了大型语言模型（LLM）的推理能力。继基于启发式的“一步一步思考”方法之后，该领域已发展出两个主要方向：一组方法利用文本反馈以无训练的方式从通用LLM中引出改进的提示，而另一条研究路线则依赖数值奖励来训练一个特殊的提示模型，专为目标模型提供最优提示。在本文中，我们引入了文本奖励提示框架（TRPrompt），它通过将文本反馈直接整合到提示模型的训练中，统一了这些方法。我们的框架不需要预先的数据集收集，并且通过对生成提示的反馈进行迭代改进。当结合LLM内化“好”提示概念的能力时，文本奖励提供的高分辨率信号使我们能够训练出一个提示模型，为具有挑战性的数学数据集GSMHard和MATH中的问题生成最先进的查询特定提示。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [627] [GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation](https://arxiv.org/abs/2507.18562)
> *GIIFT：图引导归纳免图像多模态机器翻译*

*Jiafeng Xiong, Yuting Zhao* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 多模态机器翻译, 图注意力网络, 归纳学习, 免图像翻译, 场景图

**Comment:** 

> **TL;DR:** GIIFT是一个新的多模态机器翻译框架，它使用图结构学习多模态知识并能归纳到免图像翻译领域，在多个数据集上实现了最先进的性能。

**AI_Comments:** GIIFT的创新之处在于其图引导的归纳学习方法，使得模型能够从多模态数据中学习知识并泛化到纯文本（免图像）翻译场景，解决了传统MMT方法对图像依赖和推理领域受限的问题，显著提升了实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态机器翻译（MMT）方法在利用模态间隙方面面临挑战，因为它们强制执行严格的视觉-语言对齐，并且仅限于在其训练过的多模态领域内进行推理。

**Method:** 本文提出了GIIFT，一个两阶段的图引导归纳免图像多模态机器翻译框架。它构建了新颖的多模态场景图来保留和整合模态特定信息，并使用跨模态图注意力网络适配器在一个统一的融合空间中学习多模态知识，然后将其归纳推广到更广泛的免图像翻译领域。

**Result:** 在Multi30K数据集的英译法和英译德任务上，GIIFT超越了现有方法并达到了最先进的水平，即使在推理时无需图像。在WMT基准测试中，GIIFT比免图像翻译基线有显著改进。

**Conclusion:** GIIFT在归纳免图像推理方面表现出强大的能力。

> **ai_Abstract:** 本文提出了GIIFT，一个创新的图引导归纳免图像多模态机器翻译框架，旨在解决现有MMT方法在模态间隙利用和推理领域限制上的挑战。GIIFT通过构建多模态场景图和使用跨模态图注意力网络适配器，学习并整合多模态知识，使其能够推广到免图像翻译场景。实验证明GIIFT在Multi30K和WMT数据集上均超越现有方法，实现了最先进的性能，尤其是在推理时无需图像。

> **摘要翻译:** 多模态机器翻译（MMT）已证明视觉信息在机器翻译中的显著帮助。然而，现有MMT方法在利用模态间隙方面面临挑战，因为它们强制执行严格的视觉-语言对齐，并且仅限于在其训练过的多模态领域内进行推理。在这项工作中，我们构建了新颖的多模态场景图来保留和整合模态特定信息，并引入了GIIFT，一个两阶段的图引导归纳免图像MMT框架，它使用跨模态图注意力网络适配器在一个统一的融合空间中学习多模态知识，并将其归纳推广到更广泛的免图像翻译领域。在Multi30K数据集的英译法和英译德任务上的实验结果表明，我们的GIIFT超越了现有方法并达到了最先进的水平，即使在推理时无需图像。WMT基准测试的结果显示，与免图像翻译基线相比有显著改进，证明了GIIFT在归纳免图像推理方面的强大能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [628] [Effective Multi-Task Learning for Biomedical Named Entity Recognition](https://arxiv.org/abs/2507.18542)
> *生物医学命名实体识别的有效多任务学习*

*João Ruano, Gonçalo M. Correia, Leonor Barreiros, Afonso Mendes* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 命名实体识别, 多任务学习, 生物医学, 嵌套实体, SRU-NER

**Comment:** Accepted at the 24th BioNLP workshop (ACL2025), 15 pages, 3 figures

> **TL;DR:** 本文提出SRU-NER，一种用于生物医学命名实体识别的新方法，通过多任务学习处理嵌套实体并弥补标注差距，在生物医学和通用领域NER任务中表现出色。

**AI_Comments:** 该论文的创新点在于提出了SRU-NER，并结合了多任务学习和动态损失调整来有效处理生物医学命名实体识别中的嵌套实体和标注不一致问题。其跨语料库评估和人工评估增强了结果的可信度，显示出该方法在提高泛化能力方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学命名实体识别由于术语复杂性和数据集标注不一致性而面临重大挑战。

**Method:** 本文引入SRU-NER（基于槽的循环单元NER），一种处理嵌套命名实体的新方法。它通过有效的多任务学习策略整合多个数据集，并通过动态调整损失计算来避免惩罚数据集中不存在的实体类型预测，从而弥补标注差距。

**Result:** 通过广泛的实验，包括跨语料库评估和模型预测的人工评估，SRU-NER在生物医学和通用领域NER任务中取得了有竞争力的性能，同时提高了跨领域泛化能力。

**Conclusion:** SRU-NER在生物医学和通用领域命名实体识别任务中表现出有效性，并能提高跨领域泛化能力。

> **ai_Abstract:** 本文提出SRU-NER，一种新型生物医学命名实体识别方法，旨在通过基于槽的循环单元和多任务学习策略解决生物医学术语复杂性和标注不一致性问题。SRU-NER能处理嵌套实体，并通过动态损失调整弥补标注差距。实验结果表明，该方法在生物医学和通用NER任务中均表现出色，并显著提升了跨领域泛化能力。

> **摘要翻译:** 生物医学命名实体识别由于生物医学术语的复杂性和数据集之间标注的不一致性而面临重大挑战。本文引入了SRU-NER（基于槽的循环单元NER），这是一种旨在处理嵌套命名实体，并通过有效的多任务学习策略整合多个数据集的新方法。SRU-NER通过动态调整损失计算来避免惩罚给定数据集中不存在的实体类型的预测，从而弥补标注差距。通过广泛的实验，包括跨语料库评估和模型预测的人工评估，SRU-NER在生物医学和通用领域NER任务中取得了有竞争力的性能，同时提高了跨领域泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [664] [Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods](https://arxiv.org/abs/2507.18570)
> *用于DNA语言模型的字节对编码和K-MER方法混合分词策略*

*Ganesh Sapkota, Md Hasibur Rahman* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** DNA语言模型, 混合分词, 字节对编码, K-MER, 基因组建模

**Comment:** 

> **TL;DR:** 本文提出了一种结合6-mer和BPE-600的新型混合分词策略，显著提升了DNA语言模型在下一k-mer预测任务上的性能，超越了现有SOTA模型。

**AI_Comments:** 这项研究的创新之处在于提出了一种混合分词策略，有效地结合了k-mer的局部特征捕获能力和BPE的全局上下文理解能力。通过解决传统k-mer分词的局限性，该方法显著提升了DNA语言模型的性能，对基因组语言建模领域具有重要意义。其在下一k-mer预测任务上的优异表现，特别是超越现有SOTA模型，证明了其有效性。这为未来的DNA序列分析和生物研究提供了新的工具和方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统k-mer分词在捕获局部DNA序列结构方面有效，但面临分词分布不均和对全局序列上下文理解有限的挑战。为了解决这些限制，本文提出了新的方法。

**Method:** 本文提出了一种新颖的混合分词策略，通过将独特的6-mer标记与通过600次BPE循环生成的优化选择的BPE标记相结合。这种混合方法确保了平衡且上下文感知的词汇表，使模型能够同时捕获DNA序列中的短模式和长模式。一个基于此混合词汇表训练的基础DLM在下一k-mer预测任务中进行了评估。

**Result:** 该模型在3-mers预测精度达到10.78%，4-mers达到10.1%，5-mers达到4.12%，优于NT、DNABERT2和GROVER等最先进的模型。这些结果突出了混合分词策略在DNA建模中保留局部序列结构和全局上下文信息的能力。

**Conclusion:** 这项工作强调了高级分词方法在基因组语言建模中的重要性，并为未来在下游DNA序列分析和生物研究中的应用奠定了坚实的基础。

> **ai_Abstract:** 本文提出了一种创新的混合分词策略，结合了6-mer和字节对编码（BPE-600），旨在解决传统k-mer分词在DNA语言模型中遇到的局限性，如分词分布不均和全局上下文理解不足。该策略通过融合独特的6-mer和BPE标记，构建了一个平衡且上下文感知的词汇表，使得模型能同时捕捉DNA序列的短程和长程模式。在下一k-mer预测任务上的评估显示，该混合方法显著提升了DNA语言模型的性能，其预测精度超越了现有先进模型，证明了其在保留局部结构和全局上下文信息方面的优越性，为基因组语言建模和DNA序列分析奠定了基础。

> **摘要翻译:** 本文提出了一种新颖的混合分词策略，通过结合6-mer分词与字节对编码（BPE-600）来增强DNA语言模型（DLMs）的性能。传统的k-mer分词在捕获局部DNA序列结构方面有效，但通常面临挑战，包括分词分布不均和对全局序列上下文理解有限。为了解决这些限制，我们建议将独特的6-mer分词与通过600次BPE循环生成的优化选择的BPE分词合并。这种混合方法确保了平衡且上下文感知的词汇表，使模型能够同时捕获DNA序列中的短模式和长模式。一个基于此混合词汇表训练的基础DLM在下一k-mer预测作为微调任务中进行了评估，展示了显著提高的性能。该模型在3-mers预测精度达到10.78%，4-mers达到10.1%，5-mers达到4.12%，优于NT、DNABERT2和GROVER等最先进的模型。这些结果突出了混合分词策略在DNA建模中保留局部序列结构和全局上下文信息的能力。这项工作强调了高级分词方法在基因组语言建模中的重要性，并为未来在下游DNA序列分析和生物研究中的应用奠定了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [670] [LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org/abs/2502.03699)
> *LLM 对齐作为检索器优化：一个信息检索视角*

*Bowen Jin, Jinsung Yoon, Zhen Qin, Ziqi Wang, Wei Xiong, Yu Meng, Jiawei Han, Sercan O. Arik* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-23**

**Keywords:** LLM对齐, 信息检索, 直接优化, LarPO, 检索器偏好优化

**Comment:** 26 pages

> **TL;DR:** 本文提出了一种名为LarPO的新型直接优化方法，通过借鉴信息检索（IR）原理来对齐大型语言模型（LLM），并在实验中显示出显著的性能提升。

**AI_Comments:** 本文的创新之处在于将信息检索（IR）的成熟原理引入到大型语言模型（LLM）的对齐问题中，提出了一种新颖的直接优化方法LarPO。这种方法相较于传统的强化学习（RL）方法，具有简化对齐过程的潜力。通过将LLM的生成和奖励模型映射到IR的检索器-重排器范式，提供了一个独特的视角。实验结果显示出显著的性能提升，表明该方法在提高LLM对齐质量方面的有效性。这项工作为LLM对齐领域开辟了新的研究方向，特别是探索IR与LLM结合的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的真正潜力依赖于有效的对齐，以确保其行为正确、可信和符合道德，从而解决错误信息、幻觉、偏见和滥用等挑战。现有基于强化学习（RL）的对齐方法过于复杂，而直接优化方法提供了一个更简单的替代方案。

**Method:** 本文引入了一种新颖的直接优化方法，通过借鉴已建立的信息检索（IR）原理来实现LLM对齐。提出了一个系统框架，将LLM生成和奖励模型映射到IR的检索器-重排器范式。在此基础上，提出了LLM对齐作为检索器偏好优化（LarPO），这是一种新的对齐方法，旨在提高整体对齐质量。

**Result:** LarPO在AlpacaEval2上平均提高了38.9%，在MixEval-Hard上平均提高了13.7%。

**Conclusion:** 本工作通过整合IR基础，为推进LLM对齐开辟了新途径，为未来的研究提供了有前景的方向。

> **ai_Abstract:** 本文提出了一种名为LLM对齐作为检索器偏好优化（LarPO）的新型直接优化方法，用于大型语言模型（LLM）的对齐。该方法借鉴了信息检索（IR）原理，将LLM的生成和奖励模型映射到IR的检索器-重排器范式。实验结果表明，LarPO在AlpacaEval2和MixEval-Hard数据集上分别取得了38.9%和13.7%的显著性能提升，为LLM对齐研究提供了新的方向。

> **摘要翻译:** 大型语言模型（LLMs）以其在推理、编码和沟通方面的能力彻底改变了人工智能，推动了各行各业的创新。它们的真正潜力取决于有效的对齐，以确保正确、可信和符合道德的行为，从而解决错误信息、幻觉、偏见和滥用等挑战。虽然现有的基于强化学习（RL）的对齐方法众所周知地复杂，但直接优化方法提供了一个更简单的替代方案。在这项工作中，我们借鉴已建立的信息检索（IR）原理，引入了一种新颖的LLM对齐直接优化方法。我们提出了一个系统框架，将LLM对齐和IR方法论联系起来，将LLM生成和奖励模型映射到IR的检索器-重排器范式。在此基础上，我们提出了LLM对齐作为检索器偏好优化（LarPO），这是一种新的对齐方法，可以提高整体对齐质量。广泛的实验验证了LarPO的有效性，在AlpacaEval2和MixEval-Hard上分别平均提高了38.9%和13.7%。我们的工作通过整合IR基础，为推进LLM对齐开辟了新途径，为未来的研究提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [675] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
> *Shop-R1：通过强化学习奖励大型语言模型以模拟在线购物中的人类行为*

*Yimeng Zhang, Tian Wang, Jiri Gesi, Ziyi Wang, Yuxuan Lu, Jiacheng Lin, Sinong Zhan, Vianne Gao, Ruochen Jiao, Junze Liu, Kun Qian, Yuxin Tang, Ran Xue, Houyu Zhang, Qingjun Cui, Yufan Guo, Dakuo Wang* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 强化学习, 人类行为模拟, 在线购物, 奖励机制

**Comment:** 

> **TL;DR:** Shop-R1是一个新的强化学习框架，通过分解任务和设计分层奖励来增强大型语言模型在在线购物中模拟人类行为的能力，实现了显著的性能提升。

**AI_Comments:** Shop-R1的创新之处在于其将人类行为模拟任务分解为理由生成和动作预测两个阶段，并为每个阶段设计了特定的强化学习奖励机制。特别是，利用内部模型信号进行理由生成的自监督学习，以及难度感知的分层奖励结构，有效解决了以往方法中推理能力受限的问题，并防止了奖励作弊。这对于提升LLM在复杂交互环境中的行为模拟真实性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通过增强训练数据和监督微调来提高大型语言模型（LLMs）的推理能力，但其性能受限于用于生成推理的模型本身的推理能力。

**Method:** 本文引入了Shop-R1，一个新颖的强化学习（RL）框架，旨在增强大型语言模型在在线购物环境中模拟真实人类行为的推理能力。Shop-R1将人类行为模拟任务分解为两个阶段：推理生成和动作预测，每个阶段都由不同的奖励信号引导。对于推理生成，利用内部模型信号（例如，logit分布）以自监督方式指导推理过程。对于动作预测，提出了一个具有难度感知缩放的分层奖励结构，以防止奖励作弊，并实现细粒度奖励分配，根据输出的难度按比例奖励高级动作类型和细粒度子动作细节的正确性。

**Result:** 实验结果表明，与基线相比，我们的方法实现了超过65%的相对改进。

**Conclusion:** Shop-R1框架通过其创新的两阶段方法和分层奖励机制，有效提升了大型语言模型在在线购物环境中模拟人类行为的推理能力，并取得了显著的性能提升。

> **ai_Abstract:** 本文提出了Shop-R1，一个基于强化学习的新框架，旨在提升大型语言模型在在线购物中模拟人类行为的推理能力。该框架将任务分解为理由生成和动作预测两个阶段，并分别设计了奖励机制：理由生成利用内部模型信号进行自监督，动作预测则采用分层且难度感知的奖励结构。实验证明，Shop-R1相较于基线有超过65%的性能提升。

> **摘要翻译:** 大型语言模型（LLMs）最近在网络环境中展示了生成“可信的人类行为”的强大潜力。之前的工作探索了通过LLM合成的理由来增强训练数据，并应用监督微调（SFT）来提高推理能力，这反过来可以改善下游的动作预测。然而，这些方法的性能本质上受限于用于生成理由的模型本身的推理能力。在本文中，我们引入了Shop-R1，一个新颖的强化学习（RL）框架，旨在增强LLMs在在线购物环境中模拟真实人类行为的推理能力。具体来说，Shop-R1将人类行为模拟任务分解为两个阶段：理由生成和动作预测，每个阶段都由不同的奖励信号引导。对于理由生成，我们利用内部模型信号（例如，logit分布）以自监督方式指导推理过程。对于动作预测，我们提出了一个具有难度感知缩放的分层奖励结构，以防止奖励作弊并实现细粒度奖励分配。这种设计评估了高级动作类型和细粒度子动作细节（属性和值）的正确性，并根据其难度按比例奖励输出。实验结果表明，我们的方法比基线提高了超过65%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [692] [HIVMedQA: Benchmarking large language models for HIV medical decision support](https://arxiv.org/abs/2507.18143)
> *HIVMedQA：基准测试大型语言模型在艾滋病医疗决策支持中的应用*

*Gonzalo Cardenal Antolin, Jacques Fellay, Bashkim Jaha, Roger Kouyos, Niko Beerenwinkel, Diane Duroux* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 艾滋病, 基准测试, 医疗决策支持, HIVMedQA

**Comment:** 

> **TL;DR:** 本研究引入HIVMedQA基准，评估大型语言模型在艾滋病医疗决策支持中的能力，发现Gemini 2.5 Pro表现最佳，但模型仍需针对性开发以确保安全有效集成。

**AI_Comments:** 这项研究通过引入HIVMedQA数据集和详细的评估框架，填补了LLMs在艾滋病护理领域基准测试的空白，具有重要意义。其创新之处在于结合了词汇相似性和扩展的“LLM作为评判者”方法来评估临床相关性。研究结果揭示了现有LLMs的优势和局限性，特别是指出医学微调模型并非总是优于通用模型，且模型大小并非性能的可靠指标，这为未来的模型开发提供了关键见解。强调需要针对性开发以解决推理和偏见问题，对推动LLMs在医疗领域的安全应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在临床决策支持中显示出潜力，但艾滋病（HIV）管理复杂，且LLMs在HIV护理中的应用及基准测试仍未充分探索。当前LLMs在临床实践中的集成面临准确性、潜在危害和临床医生接受度等问题。

**Method:** 本研究引入了HIVMedQA，一个旨在评估艾滋病护理中开放式医疗问答的基准数据集，其中包含经传染病医生输入策划的临床相关问题。研究评估了七个通用型和三个医学专业型LLMs，并应用提示工程。评估框架结合了词汇相似性和“LLM作为评判者”的方法，并扩展以更好地反映临床相关性，评估维度包括问题理解、推理、知识回忆、偏见、潜在危害和事实准确性。

**Result:** Gemini 2.5 Pro在大多数维度上持续优于其他模型。前三名中有两个是专有模型。问题复杂性增加时，模型性能下降。医学微调模型并非总是优于通用模型，且更大的模型尺寸并非性能的可靠预测指标。推理和理解比事实回忆更具挑战性，并观察到近期偏见和现状偏见等认知偏见。

**Conclusion:** 研究结果强调，需要针对性地开发和评估，以确保大型语言模型在临床护理中安全有效地集成。

> **ai_Abstract:** 本研究引入了HIVMedQA，这是一个用于评估大型语言模型（LLMs）在艾滋病医疗决策支持中表现的新基准数据集。该研究评估了多种通用和医学专业LLMs，并发现Gemini 2.5 Pro表现最佳。研究揭示了LLMs在处理复杂问题和推理方面的局限性，并观察到认知偏见。结果强调了为确保LLMs在临床护理中安全有效集成，需要进行有针对性的开发和评估。

> **摘要翻译:** 大型语言模型（LLMs）正在成为支持临床医生日常决策的重要工具。艾滋病（HIV）管理因其复杂性，包括多样的治疗选择、合并症和依从性挑战，是一个引人注目的应用案例。然而，将LLMs整合到临床实践中引发了对准确性、潜在危害和临床医生接受度的担忧。尽管前景广阔，但人工智能在艾滋病护理中的应用仍未充分探索，且LLM的基准测试研究稀缺。本研究评估了LLMs在艾滋病管理中的当前能力，突出了它们的优势和局限性。我们引入了HIVMedQA，一个旨在评估艾滋病护理中开放式医疗问答的基准。该数据集包含经过传染病医生输入的精心策划的临床相关问题。我们评估了七个通用型和三个医学专业型LLMs，并应用提示工程来提高性能。我们的评估框架结合了词汇相似性和“LLM作为评判者”的方法，并扩展以更好地反映临床相关性。我们评估了关键维度上的性能：问题理解、推理、知识回忆、偏见、潜在危害和事实准确性。结果显示，Gemini 2.5 Pro在大多数维度上持续优于其他模型。值得注意的是，前三名中有两个是专有模型。问题复杂性增加时，性能下降。医学微调模型并非总是优于通用模型，且更大的模型尺寸并非性能的可靠预测指标。推理和理解比事实回忆更具挑战性，并观察到近期偏见和现状偏见等认知偏见。这些发现强调了需要针对性地开发和评估，以确保LLMs在临床护理中安全有效地集成。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [704] [OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation](https://arxiv.org/abs/2506.05606)
> *OPeRA：一个用于评估大型语言模型在人类在线购物行为模拟中表现的观察、角色、理由和行动数据集*

*Ziyi Wang, Yuxuan Lu, Wenbo Li, Amirali Amini, Bo Sun, Yakov Bart, Weimin Lyu, Jiri Gesi, Tian Wang, Jing Huang, Yu Su, Upol Ehsan, Malihe Alikhani, Toby Jia-Jun Li, Lydia Chilton, Dakuo Wang* | **Category: cs.CL, cs.HC** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 人类行为模拟, 数据集, 在线购物, 数字孪生

**Comment:** 

> **TL;DR:** OPERA是一个包含观察、角色、理由和行动的数据集，用于评估大型语言模型模拟人类在线购物行为的能力。

**AI_Comments:** 本文的创新之处在于，它首次提供了一个全面捕捉人类在线购物行为的行动和内部推理（理由）的公开数据集，这对于训练和评估大型语言模型使其成为逼真的数字孪生至关重要。使用自定义浏览器插件确保了数据的高保真度。该工作直接解决了大型语言模型评估中的一个关键空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型在模拟真实用户行为方面缺乏高质量、公开的数据集，难以有效评估其能力，因为这些数据集未能捕捉到用户的可观察行为和内部推理。

**Method:** 本文引入了OPERA数据集，该数据集通过在线问卷和自定义浏览器插件从真实人类参与者的在线购物会话中收集，包含用户角色、浏览器观察、细粒度网络行为和实时自我报告的理由。基于此数据集，建立了首个评估大型语言模型在给定用户角色和历史信息下预测其下一步行动和理由的基准。

**Result:** 成功创建了OPERA数据集，它是首个全面捕捉用户角色、浏览器观察、细粒度网络行为和实时理由的公开数据集。并基于此数据集，建立了第一个用于评估大型语言模型预测用户下一步行动和理由能力的基准。

**Conclusion:** 该数据集为未来研究旨在成为人类个性化数字孪生的大型语言模型代理奠定了基础。

> **ai_Abstract:** 本文引入了OPERA数据集，这是一个从真实人类在线购物会话中收集的、包含观察、角色、理由和行动的新型公开数据集。该数据集旨在解决当前缺乏高质量数据来评估大型语言模型模拟真实用户行为能力的挑战。基于OPERA，作者建立了首个评估大型语言模型预测特定用户下一步行动和理由的基准，为未来开发个性化数字孪生大型语言模型代理奠定了基础。

> **摘要翻译:** 大型语言模型（LLMs）能否准确模拟特定用户的下一个网络行为？尽管大型语言模型在生成“可信”的人类行为方面表现出有希望的能力，但评估它们模仿真实用户行为的能力仍然是一个开放的挑战，这主要是由于缺乏高质量、公开可用的数据集，这些数据集既能捕捉实际人类用户的可观察行为，又能捕捉其内部推理。为了解决这一空白，我们引入了OPERA，这是一个从真实人类参与者在线购物会话中收集的观察、角色、理由和行动的新颖数据集。OPERA是第一个全面捕捉用户角色、浏览器观察、细粒度网络行为和实时自我报告理由的公开数据集。我们开发了在线问卷和自定义浏览器插件，以高保真度收集此数据集。使用OPERA，我们建立了第一个基准，用于评估当前大型语言模型在给定角色和<观察、行动、理由>历史的情况下，预测特定用户下一步行动和理由的能力。该数据集为未来研究旨在成为人类个性化数字孪生的大型语言模型代理奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [706] [Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs](https://arxiv.org/abs/2507.18578)
> *宽入窄出：高效且有效的DLLM可撤销解码*

*Feng Hong, Geng Yu, Yushi Ye, Haicheng Huang, Huangjie Zheng, Ya Zhang, Yanfeng Wang, Jiangchao Yao* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 扩散大语言模型, 可撤销解码, WINO, 质量-速度权衡, 并行生成

**Comment:** 

> **TL;DR:** WINO是一种无需训练的DLLM解码算法，通过并行草稿和验证机制实现可撤销解码，显著提升了DLLMs的速度和质量。

**AI_Comments:** WINO通过引入可撤销解码机制，有效解决了DLLMs在并行生成中面临的质量下降问题，其无需训练的特性增加了实用性。并行草稿和验证机制是其核心创新点，显著提升了效率和效果。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散大语言模型（DLLMs）存在严重的速度-质量权衡问题，快速并行解码会导致性能显著下降，这归因于标准解码的不可逆性以及早期错误上下文的累积。

**Method:** 本文引入了“宽入窄出”（WINO）算法，这是一种无需训练的解码算法，为DLLMs实现了可撤销解码。WINO采用并行草稿和验证机制，在积极草拟多个token的同时，利用模型的双向上下文来验证并重新掩盖可疑token以进行优化。

**Result:** WINO在GSM8K数学基准测试上将推理速度提高了6倍，同时准确率提高了2.58%；在Flickr30K图像描述任务上，实现了10倍的加速并提高了性能。

**Conclusion:** WINO算法通过实现可撤销解码，显著改善了扩散大语言模型的质量-速度权衡。

> **ai_Abstract:** 本文提出了一种名为WINO（宽入窄出）的无需训练解码算法，旨在解决扩散大语言模型（DLLMs）中存在的速度与质量之间的权衡问题。WINO通过引入一种可撤销的并行草稿-验证机制，允许模型在生成多个token的同时，利用双向上下文来识别并修正潜在错误。实验结果表明，WINO显著提升了DLLMs的推理速度和准确性，例如在GSM8K上加速6倍并提高2.58%准确率，在Flickr30K上实现10倍加速并提升性能。

> **摘要翻译:** 扩散大语言模型（DLLMs）已成为自回归模型的一个引人注目的替代方案，旨在实现快速并行生成。然而，现有DLLMs受到严重的质量-速度权衡问题的困扰，其中更快的并行解码会导致显著的性能下降。我们将此归因于DLLMs中标准解码的不可逆性，其容易随着早期错误上下文的积累而偏向错误的解码方向。为了解决这个问题，我们引入了“宽入窄出”（WINO），这是一种无需训练的解码算法，使DLLMs能够进行可撤销解码。WINO采用并行草稿和验证机制，在积极草拟多个token的同时，利用模型的双向上下文来验证并重新掩盖可疑token以进行优化。在LLaDA和MMaDA等开源DLLMs中验证，WINO被证明可以决定性地改善质量-速度权衡。例如，在GSM8K数学基准测试上，它将推理速度提高了6倍，同时准确率提高了2.58%；在Flickr30K图像描述任务上，它实现了10倍的加速并提高了性能。本文进行了更全面的实验，以证明WINO的优越性并提供对其深入理解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [726] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
> *动态且可泛化的过程奖励建模*

*Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 过程奖励模型, 大型语言模型, 泛化性, 奖励树, 帕累托支配

**Comment:** Accepted by ACL 2025 Main

> **TL;DR:** 提出DG-PRM，通过奖励树和帕累托支配估计，解决现有过程奖励模型泛化性差和评估标准静态的问题，显著提升模型性能和泛化能力。

**AI_Comments:** 该论文的创新点在于提出了DG-PRM框架，通过引入“奖励树”来捕捉细粒度、多维度的奖励标准，并实现了奖励信号的动态选择。更重要的是，它开创性地将帕累托支配估计应用于处理多方面的奖励信号，这为解决复杂奖励信号的整合提供了一个新颖的视角。其重要性在于提升了过程奖励模型的泛化能力和适应性，这对于指导大型语言模型在复杂、动态环境中的表现至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有过程奖励模型（PRMs）主要依赖启发式方法，难以跨领域泛化；LLM-as-judge方法忽视了文本中嵌入的有意义指导；静态和粗粒度评估标准难以适应复杂过程监督。

**Method:** 提出动态且可泛化的过程奖励建模（DG-PRM），其特点是使用奖励树捕获和存储细粒度、多维度的奖励标准。DG-PRM动态选择奖励信号进行逐步奖励评分。为处理多方面的奖励信号，开创性地采用帕累托支配估计来识别判别性的正负对。

**Result:** 实验结果表明，DG-PRM在现有基准测试上取得了惊人的性能，显著提升了密集奖励任务中的模型性能。进一步分析表明，DG-PRM能很好地适应分布外场景，表现出卓越的泛化能力。

**Conclusion:** DG-PRM通过引入奖励树和帕累托支配估计，有效解决了现有过程奖励模型在泛化性、动态性和细粒度评估方面的挑战，显著提升了模型在复杂场景下的性能和跨领域泛化能力。

> **ai_Abstract:** 本文提出了动态且可泛化的过程奖励建模（DG-PRM），旨在解决现有过程奖励模型在跨领域泛化能力不足以及静态评估标准无法适应复杂过程监督的问题。DG-PRM引入了奖励树来存储细粒度、多维度的奖励标准，并能动态选择奖励信号进行逐步评分。此外，它创新性地利用帕累托支配估计处理多方面奖励信号。实验证明，DG-PRM在基准测试上表现出色，显著提升了模型在密集奖励任务中的性能，并展现了卓越的泛化能力，尤其是在分布外场景下。

> **摘要翻译:** 过程奖励模型（PRMs）通过提供密集的奖励信号，对于指导大型语言模型（LLMs）在复杂场景中至关重要。然而，现有的PRMs主要依赖启发式方法，这在跨领域泛化方面存在困难。尽管LLM-as-judge已被提出用于提供泛化奖励，但目前的研究主要集中在反馈结果上，忽视了文本中嵌入的有意义指导。此外，静态和粗粒度的评估标准难以适应复杂的过程监督。为了解决这些挑战，我们提出了动态且可泛化的过程奖励建模（DG-PRM），其特点是使用奖励树来捕获和存储细粒度、多维度的奖励标准。DG-PRM动态选择奖励信号进行逐步奖励评分。为了处理多方面的奖励信号，我们开创性地采用帕累托支配估计来识别判别性的正负对。实验结果表明，DG-PRM在现有基准测试上取得了惊人的性能，显著提升了密集奖励任务中的模型性能。进一步分析表明，DG-PRM能很好地适应分布外场景，表现出卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [735] [Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models](https://arxiv.org/abs/2507.18171)
> *紧随平均值：检测文本嵌入模型中的“粘性”词元*

*Kexin Chen, Dongxia Wang, Yi Liu, Haonan Zhang, Wenhai Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 粘性词元, 文本嵌入, Transformer模型, 分词, 异常检测

**Comment:** ACL 2025 main

> **TL;DR:** 文本嵌入模型中存在“粘性词元”，它们会破坏嵌入的可靠性并降低下游任务的性能。本文定义并提出了一种检测方法（STD），分析了其来源和影响，并强调需要改进分词策略和模型设计。

**AI_Comments:** 这篇论文识别并解决了Transformer文本嵌入模型中一个新颖且重要的实际问题——“粘性词元”。它不仅正式定义了这一现象，还提出了一种实用的检测方法STD，具有很高的创新性。研究深入分析了粘性词元的来源及其对下游任务的显著负面影响（高达50%的性能下降），并通过注意力层分析揭示了其在模型内部表示中的主导地位，为理解问题提供了深刻见解。这对于提升文本嵌入模型的可靠性和鲁棒性至关重要，并为未来的分词策略和模型设计指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于Transformer的文本嵌入模型在NLP任务中广泛使用，但令人惊讶的“粘性词元”会破坏嵌入的可靠性。这些词元在重复插入句子时，会将句子相似度拉向某个特定值，扰乱嵌入距离的正常分布，并降低下游性能。因此，本研究旨在系统地调查这些异常词元。

**Method:** 本文正式定义了粘性词元，并引入了一种基于句子和词元过滤的高效检测方法，即粘性词元检测器（STD）。研究人员将STD应用于14个模型家族的40个检查点。此外，还通过注意力层分析来探究粘性词元对模型内部表示的影响。

**Result:** 研究共发现了868个粘性词元。分析显示，这些词元通常源自词汇表中特殊或未使用的条目，以及来自多语言语料库的碎片化子词。值得注意的是，它们的出现与模型大小或词汇量大小没有严格关联。粘性词元导致聚类和检索等下游任务的性能显著下降，降幅高达50%。通过注意力层分析表明，粘性词元在模型内部表示中占据了过高的主导地位。

**Conclusion:** 研究结果表明，需要更好的分词策略和模型设计来减轻粘性词元在未来文本嵌入应用中的影响。

> **ai_Abstract:** 本文调查了基于Transformer的文本嵌入模型中存在的“粘性词元”，这些异常词元会扭曲嵌入分布并损害模型性能。研究正式定义了这些词元，并提出了一种高效的检测方法——粘性词元检测器（STD）。通过将STD应用于多个模型，研究发现了868个粘性词元，它们通常源于特殊词汇或碎片化子词。这些词元导致下游任务性能显著下降（最高达50%），并在模型内部表示中占据主导地位。研究强调了未来文本嵌入应用中改进分词策略和模型设计的必要性。

> **摘要翻译:** 尽管基于Transformer的文本嵌入模型在自然语言处理（NLP）任务中得到了广泛应用，但令人惊讶的“粘性词元”可能会损害嵌入的可靠性。当这些词元被重复插入句子时，它们会将句子相似度拉向某个特定值，扰乱嵌入距离的正常分布，并降低下游性能。在本文中，我们系统地研究了这些异常词元，对其进行了正式定义，并引入了一种基于句子和词元过滤的高效检测方法——粘性词元检测器（Sticky Token Detector, STD）。将STD应用于14个模型家族的40个检查点，我们共发现了868个粘性词元。我们的分析揭示，这些词元通常来源于词汇表中特殊或未使用的条目，以及来自多语言语料库的碎片化子词。值得注意的是，它们的存在与模型大小或词汇量大小没有严格关联。我们进一步评估了粘性词元如何影响聚类和检索等下游任务，观察到性能显著下降，最高可达50%。通过注意力层分析，我们发现粘性词元在模型内部表示中占据了不成比例的主导地位，引发了对分词鲁棒性的担忧。我们的发现表明，需要更好的分词策略和模型设计来减轻粘性词元在未来文本嵌入应用中的影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [736] [System Report for CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition](https://arxiv.org/abs/2507.18580)
> *CCL25-Eval 任务10系统报告：用于细粒度中文仇恨言论识别的SRAG-MAV*

*Jiahao Wang, Ramen Liu, Longhui Zhang, Jing Li* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 中文仇恨言论识别, SRAG-MAV, 细粒度识别, 任务重构, 自检索增强生成

**Comment:** 8 pages, 3 figures, accepted as oral presentation at CCL25-Eval

> **TL;DR:** 本文提出了一个名为SRAG-MAV的新框架，用于细粒度中文仇恨言论识别，通过任务重构、自检索增强生成和多轮累积投票，显著优于基线模型。

**AI_Comments:** 该论文的创新点在于提出了SRAG-MAV框架，通过任务重构、自检索增强和多轮投票的协同作用，有效提升了细粒度中文仇恨言论识别的性能。其在基线模型上的显著超越表明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决细粒度中文仇恨言论识别（FGCHSR）任务，并参与CCL25-Eval 任务10。

**Method:** 本文提出了SRAG-MAV框架，该框架整合了任务重构（将四元组提取重构为三元组提取）、自检索增强生成（从训练集动态检索创建上下文提示）和多轮累积投票（提高输出稳定性和性能）。系统基于Qwen2.5-7B模型。

**Result:** 该系统在STATE ToxiCN数据集上取得了26.66的硬分数、48.35的软分数和37.505的平均分数。这显著优于基线模型，如GPT-4o（平均分数15.63）和微调后的Qwen2.5-7B（平均分数35.365）。

**Conclusion:** SRAG-MAV框架在细粒度中文仇恨言论识别任务上表现出色，显著优于现有基线模型，证明了其在提高识别性能方面的有效性。

> **ai_Abstract:** 本文提出了一个名为SRAG-MAV的新框架，用于CCL25-Eval 任务10中的细粒度中文仇恨言论识别。该框架结合了任务重构、自检索增强生成和多轮累积投票，以提高识别性能和稳定性。基于Qwen2.5-7B模型，该系统在STATE ToxiCN数据集上取得了显著优于GPT-4o和微调Qwen2.5-7B的平均分数。

> **摘要翻译:** 本文介绍了我们为CCL25-Eval 任务10设计的系统，旨在解决细粒度中文仇恨言论识别（FGCHSR）问题。我们提出了一个新颖的SRAG-MAV框架，该框架协同整合了任务重构（TR）、自检索增强生成（SRAG）和多轮累积投票（MAV）。我们的方法将四元组提取任务重构为三元组提取，利用训练集中的动态检索来创建上下文提示，并应用多轮推理和投票来提高输出稳定性和性能。我们的系统基于Qwen2.5-7B模型，在STATE ToxiCN数据集上取得了26.66的硬分数、48.35的软分数和37.505的平均分数，显著优于基线模型，例如GPT-4o（平均分数15.63）和微调后的Qwen2.5-7B（平均分数35.365）。代码可在https://github.com/king-wang123/CCL25-SRAG-MAV获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [16] [On recognizing graphs representing Persistent Perfect Phylogenies](https://arxiv.org/abs/2507.18281)
> *关于识别表示持久完美系统发育的图*

*Paola Bonizzoni, Gianluca Della Vedova, Mauricio Soto Gomez, Gabriella Trucco* | **Category: cs.DS** | **Updated: 2025-07-24**

**Keywords:** 持久完美系统发育, 图识别, 多项式时间算法, 二分图, 系统发育

**Comment:** 

> **TL;DR:** 本文提出了一种多项式时间算法，用于识别表示持久完美系统发育的最大图，缩小了与简单完美系统发育算法和Dollo-k系统发育NP难问题之间的差距。

**AI_Comments:** 本文的创新之处在于为持久完美系统发育在最大图情况下的识别问题提供了一个多项式时间算法，这在理论上填补了完美系统发育简单算法和Dollo-k问题NP难结果之间的空白，对于理解和解决系统发育推断问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 持久完美系统发育的存在性问题可以归结为识别一类二分图的问题，因此直接解决识别这些图的问题是一个有趣的研究方向。

**Method:** 本文提出了一种多项式时间算法，用于判断在最大图中是否存在持久完美系统发育。该算法仅依赖于图属性。

**Result:** 该算法能够判断在最大图中是否存在持久完美系统发育，并且缩小了线性时间简单完美系统发育算法与Dollo-k系统发育（k>1）的NP难结果之间的差距。

**Conclusion:** 本文提出的多项式时间算法成功解决了在最大图中识别持久完美系统发育图的问题，为该领域的研究提供了重要进展。

> **ai_Abstract:** 本文研究了持久完美系统发育（Dollo-1）的图识别问题，该问题是完美系统发育模型的推广。作者指出，判断持久完美系统发育存在性可简化为识别一类二分图。为此，论文提出了一种多项式时间算法，用于在最大图中识别这类图。该算法仅基于图属性，并成功缩小了线性时间完美系统发育算法与Dollo-k系统发育的NP难问题之间的差距。

> **摘要翻译:** 持久完美系统发育，也称为Dollo-1，被引入作为众所周知的二元特征完美系统发育模型的推广，以处理特征的潜在丢失。判断持久完美系统发育存在性的问题可以简化为识别一类以物种和特征为节点的二分图的问题。因此，一个有趣的问题是直接解决识别这类图的问题。我们提出了一种多项式时间算法，用于判断在最大图中是否存在持久完美系统发育，其中没有任何一个特征的物种集合包含在另一个特征的物种集合中。我们的解决方案仅依赖于图属性，缩小了线性时间简单完美系统发育算法与Dollo-k系统发育（k>1）的NP难结果之间的差距。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [107] [Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions](https://arxiv.org/abs/2406.03674)
> *学习在统一价格拍卖中价值最大化买家的安全策略*

*Negin Golrezaei, Sourav Sahoo* | **Category: cs.DS, cs.GT, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 统一价格拍卖, 安全策略, 投资回报率, 学习算法, 次线性遗憾

**Comment:** 84 pages, 5 figures. Appeared at ICML 2025

> **TL;DR:** 本文研究了重复统一价格多单位拍卖中，价值最大化买家在满足投资回报率约束下的安全竞价策略，并设计了一个实现次线性遗憾的算法。

**AI_Comments:** 本文的创新点在于提出了“安全竞价策略”的概念，这为在具有严格RoI约束的战略性拍卖环境中，买家如何进行竞价提供了一个新的视角。通过证明这些策略的特性并设计出实现次线性遗憾的多项式时间学习算法，解决了实际应用中的鲁棒性和效率问题。特别是在评估鲁棒性时引入的“丰富度比率”是一个有价值的度量。该研究的重要性在于为受限条件下的自动竞价系统提供了理论基础和实用算法，尤其是在金融市场等对风险控制有高要求的领域。

<details>
  <summary>Details</summary>

**Motivation:** 在重复统一价格多单位拍卖中，价值最大化买家面临如何在战略性环境中，在T轮次内最大化累积价值，同时遵守每轮投资回报率（RoI）约束的竞价问题。

**Method:** 1. 引入了“安全竞价策略”的概念，这些策略无论竞争性出价如何都能满足RoI约束。2. 证明了安全策略满足温和的不超额出价条件，仅依赖于竞标者的估值曲线，并且竞标者可以无损地关注一个有限子集。3. 设计了一种多项式时间学习算法，该算法在完全信息和赌博机（bandit）设置下，相对于事后最优安全策略实现了次线性遗憾。4. 评估了安全策略相对于更丰富类别的事后最优策略的鲁棒性，定义了丰富度比率α，并构建了困难实例来展示其紧密性。

**Result:** 1. 安全竞价策略被证明满足温和的不超额出价条件，仅依赖于竞标者的估值曲线，并且可以关注一个有限子集。2. 设计的多项式时间学习算法在完全信息和赌博机设置下，相对于事后最优安全策略实现了次线性遗憾。3. 该算法相对于更强的基准（来自更丰富类别的策略）实现了α-近似的次线性遗憾。4. 半合成拍卖数据的模拟结果显示，经验丰富度比率显著优于理论最坏情况下的界限。

**Conclusion:** 本文提出了安全竞价策略和学习算法，这些方法可以自然地扩展到更细致的买家和竞争对手模型，为在受限拍卖环境中最大化价值提供了鲁棒且高效的解决方案。

> **ai_Abstract:** 本文研究了重复统一价格多单位拍卖中，价值最大化买家如何在满足每轮投资回报率约束下进行竞价。作者引入了“安全竞价策略”的概念，这些策略在任何竞争出价下都能满足RoI约束，并证明了其关键特性。在此基础上，设计了一种多项式时间学习算法，该算法在完全信息和赌博机设置下，相对于事后最优安全策略实现了次线性遗憾。研究还评估了安全策略的鲁棒性，并证明了算法对于更强的基准也能实现近似次线性遗憾。模拟结果表明，提出的策略在实践中表现良好，并且具有可扩展性。

> **摘要翻译:** 我们从价值最大化买家的角度研究了重复统一价格多单位拍卖中的竞价问题。买家旨在在T轮次内最大化其累积价值，同时在战略性（或对抗性）环境中遵守每轮投资回报率（RoI）约束。使用m-统一竞价格式，买家提交m个竞价-数量对(bi, qi)以在竞价bi时需求qi单位，实际上m远小于M，其中M表示买家的最大需求。
我们引入了安全竞价策略的概念，即那些无论竞争性出价如何都能满足RoI约束的策略。尽管要求严格，我们表明这些策略满足温和的不超额出价条件，仅依赖于竞标者的估值曲线，并且竞标者可以无损地关注一个有限子集。尽管子集大小为O(Mm)，我们设计了一种多项式时间学习算法，该算法在完全信息和赌博机设置下，相对于事后最优安全策略实现了次线性遗憾。
我们评估了安全策略相对于更丰富类别的事后最优策略的鲁棒性。我们定义了丰富度比率α ∈ (0,1]为最优安全策略的价值与来自更丰富类别的最优策略的价值之比的最小值，并构建了显示α紧密性的困难实例。我们的算法相对于这些更强的基准实现了α-近似的次线性遗憾。对半合成拍卖数据的模拟显示，经验丰富度比率显著优于理论最坏情况下的界限。所提出的安全策略和学习算法自然地扩展到更细致的买家和竞争对手模型。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [146] [Distributed Model Checking in Graphs Classes of Bounded Expansion](https://arxiv.org/abs/2411.14825)
> *有界膨胀图类中的分布式模型检测*

*Lélia Blin, Fedor V. Fomin, Pierre Fraigniaud, Sylvain Gay, Petr A. Golovach, Pedro Montealegre, Ivan Rapaport, Ioan Todinca* | **Category: cs.DS, F.2** | **Updated: 2025-07-24**

**Keywords:** 分布式模型检测, 有界膨胀图, 稀疏性理论, 一阶逻辑, CONGEST模型

**Comment:** 

> **TL;DR:** 本文首次为有界膨胀图上的分布式一阶（FO）模型检测提供了通用的算法结果，解决了Nešetřil和Ossona de Mendez提出的开放问题，并展示了局部FO公式可在O(log n)轮内解决，任意FO公式可在O(D+log n)轮内解决。

**AI_Comments:** 这项工作具有重要意义，因为它首次将稀疏性理论应用于分布式算法设计，为有界膨胀图上的分布式模型检测提供了通用的算法结果。解决了长期存在的开放问题，并展示了在CONGEST模型下实现对复杂图类进行高效分布式计算的可能性，这对于理论计算机科学和实际应用都具有价值。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏图的稀疏性理论已在模型检测、参数化复杂性和近似算法方面取得了重大进展。本文旨在证明该理论同样适用于分布式算法的设计，以解决有界膨胀图上分布式一阶（FO）模型检测的开放问题。

**Method:** 本文将Nešetřil和Ossona de Mendez的稀疏性理论应用于分布式算法设计，在标准CONGEST模型下，为有界膨胀图类中的分布式一阶（FO）模型检测开发了通用的算法元定理。

**Result:** 1. 对于每个局部FO公式$\\varphi(x)$，存在一个确定性算法，在$O(\\log n)$轮内识别所有满足条件的顶点，解决了Nešetřil和Ossona de Mendez提出的开放问题。
2. 对于每个FO公式$\\varphi$，存在一个确定性算法，在$O(D+\\log n)$轮内决定图是否满足公式，其中$D$是图的直径。
这些技术可扩展到分布式计数、优化和认证问题。

**Conclusion:** 稀疏性理论非常适用于分布式算法的设计，本文为有界膨胀图上的分布式一阶模型检测提供了通用的、高效的算法元定理，并解决了重要的开放问题。

> **ai_Abstract:** 本文研究了在有界膨胀图类中进行分布式一阶（FO）模型检测的问题，该图类涵盖了多种重要的稀疏图。作者利用Nešetřil和Ossona de Mendez的稀疏性理论，首次在标准CONGEST模型下为这类图的分布式FO模型检测提供了通用的算法元定理。主要成果包括解决了Nešetřil和Ossona de Mendez提出的一个开放问题，证明了局部FO公式的满足性可在$O(\\log n)$轮内确定，以及任意FO公式的满足性可在$O(D+\\log n)$轮内确定。这些技术还可应用于分布式计数、优化和认证问题。

> **摘要翻译:** Nešetřil和Ossona de Mendez的稀疏性理论为许多稀疏图类提供了通用的组合和算法方法。因此，它已经在模型检测、参数化复杂度和近似算法方面取得了重大进展。我们证明，该理论同样适用于分布式算法的设计，为有界膨胀图上的分布式一阶（FO）模型检测提供了首个通用算法结果。后者形成了一个丰富的图族，包括平面图、有界亏格图、有界树宽图和有界度图，以及排除固定次图或拓扑次图的图，以及稀疏的Erdos-Rényi图（几乎必然）。
我们的主要结果是在标准CONGEST模型下，针对每个有界膨胀图类$\\mathcal{G}$中的分布式算法的以下算法元定理。
首先，我们解决了一个由Nešetřil和Ossona de Mendez（Distributed Computing 2016）最初提出，并由Pilipczuk、Siebertz和Toruńczyk（LICS 2018）重申的开放问题。如果公式$\\varphi(x)$的满足性仅取决于其自由变量$x$的$r$-邻域（对于某个固定的$r$），则称该公式是局部的。例如，公式“$x$属于一个三角形”是局部的。我们证明，对于每个局部FO公式$\\varphi(x)$，存在一个确定性算法，对于每个$n$顶点图$G\\in \\mathcal{G}$，可在$O(\\log n)$轮内识别所有满足$G\\models \\varphi(v)$的顶点$v\\in V(G)$。
其次，我们证明，对于每个FO公式$\\varphi$，存在一个确定性算法，对于每个$n$顶点图$G\\in \\mathcal{G}$，可在$\\mathcal{O}(D+\\log n)$轮内决定$G\\models \\varphi$是否成立，其中$D$是$G$的直径。这些技术可扩展到分布式计数、优化和认证问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [181] [Combinatorial Selection with Costly Information](https://arxiv.org/abs/2412.03860)
> *带成本信息的组合选择*

*Shuchi Chawla, Dimitris Christou, Amit Harlev, Ziv Scully* | **Category: cs.DS** | **Updated: 2025-07-24**

**Keywords:** 组合选择, 成本信息, 马尔可夫决策过程, 强盗超过程, 近似优化

**Comment:** 

> **TL;DR:** 本文提出了一个用于近似优化带约束的随机变量组合选择问题的框架，通过新颖的成本分摊和局部近似方法，为多种强盗超过程问题提供了近似最优解。

**AI_Comments:** 该论文的创新之处在于提出了一个通用的框架，能够处理带有拟阵可行性约束的任意非循环MDP，这显著扩展了现有强盗超过程解决方案的适用范围。通过引入新颖的成本分摊和局部近似概念，该框架能够有效地将局部近似解组合成全局近似解，解决了之前仅限于特定情况的局限性。其重要性体现在为实际中需要权衡信息获取成本和决策收益的复杂组合优化问题提供了有效的近似求解方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的关于随机变量优化问题（强盗超过程）的解决方案仅限于非常受限的特殊情况，因此需要开发一个更通用的近似优化框架。

**Method:** 开发了一个适用于任意非循环MDP和拟阵可行性约束的强盗超过程近似优化框架。该框架通过新颖的成本分摊建立最优成本的界限，并结合局部近似概念，使得超过程中每个组件MDP的近似解可以无损地组合成全局近似。

**Result:** 为最大化和最小化的强盗超过程的几个变体获得了近似最优解。具体包括：之前研究的“带可选检查的潘多拉魔盒”和“带部分检查的潘多拉魔盒”的组合版本的新近似；研究较少的“累加潘多拉魔盒”问题；以及一个新的“称重尺度”问题。

**Conclusion:** 本文提出的框架能够为带有成本信息获取的组合选择问题（即强盗超过程）提供近似最优解，并成功应用于多种具体问题。

> **ai_Abstract:** 本文针对一类涉及昂贵信息获取的随机变量组合优化问题（建模为马尔可夫决策过程的强盗超过程），提出了一个通用的近似优化框架。该框架适用于具有拟阵约束的任意非循环MDP，并利用成本分摊和局部近似技术，能够将组件的近似解组合成全局近似。研究者利用此框架为多种强盗超过程变体，包括潘多拉魔盒问题的不同版本和新提出的称重尺度问题，提供了近似最优解。

> **摘要翻译:** 我们考虑一类随机变量的优化问题，其中算法可以通过一系列昂贵的步骤学习任何变量的值信息；我们将这种信息获取过程建模为马尔可夫决策过程（MDP）。算法的目标是最小化其解决方案的成本加上信息获取的成本，或者，最大化其解决方案的价值减去信息获取的成本。这类强盗超过程以前曾被研究过，但解决方案仅限于相当受限的特殊情况。
我们开发了一个用于强盗超过程近似优化的框架，该框架适用于具有拟阵可行性约束的任意非循环MDP。我们的框架通过一种新颖的成本分摊建立了最优成本的界限；然后将这个界限与局部近似的概念结合起来，使得超过程中每个组件MDP的近似解可以在不损失的情况下组合成全局近似。
我们使用这个框架为最大化和最小化的强盗超过程的几个变体获得了近似最优解。我们获得了之前研究的“带可选检查的潘多拉魔盒”和“带部分检查的潘多拉魔盒”的组合版本的新近似；研究较少的“累加潘多拉魔盒”问题；以及一个我们称之为“称重尺度”的新问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [573] [Smoothed Analysis of Online Metric Problems](https://arxiv.org/abs/2507.17834)
> *在线度量问题的平滑分析*

*Christian Coester, Jack Umenberger* | **Category: cs.DS** | **Updated: 2025-07-23**

**Keywords:** 平滑分析, 在线算法, k-服务器问题, 竞争比, 度量空间

**Comment:** Accepted to ESA 2025, Track S

> **TL;DR:** 本文通过平滑分析研究了k-服务器、k-出租车和追逐大小为k的集合这三个在线问题，证明在特定条件下它们存在多对数竞争算法，且匹配了下界，显著优于完全对抗设置下的表现。

**AI_Comments:** 本文的创新之处在于将平滑分析引入到经典的在线度量问题中，成功地弥合了最坏情况和平均情况分析之间的鸿沟，并显著提高了算法的竞争比。其方法简单且以黑盒方式利用现有算法，具有很强的普适性。匹配的上下界证明了结果的紧密性。

<details>
  <summary>Details</summary>

**Motivation:** 针对k-服务器、k-出租车和追逐大小为k的集合等经典在线问题，在完全对抗设置下的竞争比表现不佳（分别为$2k-1$、$\\infty$和$\\Theta(k^2)$），本文旨在通过平滑分析提供一种介于最坏情况和平均情况模型之间的新视角，以期获得更好的算法性能。

**Method:** 本文采用平滑分析方法，允许请求位置在小扰动下是对抗性的。具体方法是将平滑实例简化为有限度量上的完全对抗实例，并以黑盒方式利用现有算法。

**Result:** 如果度量空间包含在任何范数空间的一个球中，并且请求来自密度函数上限为球上均匀密度1/σ倍的分布，那么所有三个问题都存在polylog$(k/\\sigma)$-竞争算法。此外，本文还提供了下界，表明没有算法能实现低于polylog$(k/\\sigma)$的竞争比，与上界在多对数指数上匹配。

**Conclusion:** 本文通过平滑分析显著改进了k-服务器、k-出租车和追逐大小为k的集合这三个经典在线问题的竞争比，从完全对抗设置下的较差表现提升到polylog$(k/\\sigma)$，并通过匹配的上下界证明了算法的有效性。

> **ai_Abstract:** 本文利用平滑分析研究了k-服务器、k-出租车和追逐大小为k的集合这三个在线度量问题。研究表明，在度量空间位于范数空间的一个球内且请求分布密度受限的条件下，这些问题可以实现polylog$(k/\\sigma)$的竞争比，这通过将平滑实例简化为有限度量上的对抗实例并利用现有算法得以实现。研究还提供了匹配的下界，并与完全对抗设置下较差的竞争比形成了鲜明对比，展示了平滑分析的有效性。

> **摘要翻译:** 我们通过平滑分析的视角研究了三个经典的在线问题——$k$-服务器、 $k$-出租车和追逐大小为$k$的集合。我们的设置允许请求位置在小扰动下是对抗性的，这在最坏情况和平均情况模型之间进行插值。具体来说，我们表明如果度量空间包含在任何范数空间的一个球中，并且请求来自密度函数上限为球上均匀密度$1/\sigma$倍的分布，那么所有这三个问题都承认多对数$(k/\sigma)$-竞争算法。我们的方法很简单：它将平滑实例简化为有限度量上的完全对抗实例，并以黑盒方式利用现有算法。我们还提供了一个下界，表明没有算法可以实现低于多对数$(k/\sigma)$的竞争比，这与我们的上界在多对数指数上匹配。相比之下，这些问题在完全对抗设置下已知的最佳竞争比分别为$2k-1$、$\infty$和$\Theta(k^2)$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [622] [Better Bounds for Semi-Streaming Single-Source Shortest Paths](https://arxiv.org/abs/2507.17841)
> *半流式单源最短路径的更好界限*

*Sepehr Assadi, Gary Hoppenworth, Janani Sundaresan* | **Category: cs.DS, cs.CC** | **Updated: 2025-07-23**

**Keywords:** 半流, 单源最短路径, 近似算法, 上下界, 通道复杂度

**Comment:** 64 pages, 9 figures

> **TL;DR:** 论文在半流模型中为单源最短路径问题提供了改进的上下界，显著缩小了通道复杂度差距。

**AI_Comments:** 这项工作在半流模型中单源最短路径的近似问题上取得了重要进展，通过提供紧密的上下界，显著缩小了长期存在的理论差距。其创新点在于同时提供了优化的算法（上界）和更强的理论下界，为该领域的进一步研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在半流模型中，近似处理无向图上的单源最短路径是一个长期存在的开放问题。

**Method:** 本研究提出了一个简单的随机算法，用于计算 $(1+\epsilon)$-近似最短路径，并证明了任何半流算法在给定源点计算常数近似最短路径所需的通道下界。

**Result:** 算法方面，提出了一个简单的随机算法，能以高概率计算 $(1+\epsilon)$-近似最短路径，其空间复杂度为 $O\left(\frac{1}{\epsilon} \cdot n \log^3 n \right)$，通道复杂度为 $O\left(\frac{1}{\epsilon} \cdot \left(\frac{\log n}{\log\log n} \right) ^2\right)$。该算法可去随机化并适用于动态流，仅需额外增加一些 $\text{poly}(\log n, 1/\epsilon)$ 因子。此前，该问题的最佳算法需要 $1/\epsilon \cdot \log^{c}(n)$ 次通道。理论下界方面，证明了任何半流算法若要以高常数概率输出给定源点到最短路径的任何常数近似（即使只针对单个固定目标顶点和距离），则需要 $\Omega\left(\frac{\log n}{\log\log n}\right)$ 次通道。此前，仅知常数通道下界，且仅适用于小于二的较小近似比。

**Conclusion:** 我们的结果共同将半流模型中近似单源最短路径的通道复杂度差距从 $\text{polylog } n$ 与 $\omega(1)$ 缩小到仅二次方差距。

> **ai_Abstract:** 这篇论文在半流模型中解决了无向图单源最短路径的近似问题。作者提出了一个简单的随机算法，能在低空间和低通道复杂度下计算 $(1+\epsilon)$-近似最短路径，并给出了匹配的通道下界。这些成果显著缩小了该问题在通道复杂度上的理论差距。

> **摘要翻译:** 在半流模型中，算法必须通过对边流进行一或几次遍历来处理任何 $n$ 顶点图，使用 $O(n \cdot \text{polylog }n)$ 字的空间，并在最后一次遍历结束时输出问题的解决方案。在无向图上近似（单源）最短路径是该模型中一个长期存在的开放问题。在这项工作中，我们从上下界两方面对此问题取得了进展：我们提出了一个简单的随机算法，对于任何 $\epsilon > 0$，该算法以高概率计算给定源点的 $(1+\epsilon)$-近似最短路径，所需空间为 $O\left(\frac{1}{\epsilon} \cdot n \log^3 n \right)$，所需通道为 $O\left(\frac{1}{\epsilon} \cdot \left(\frac{\log n}{\log\log n} \right) ^2\right)$。该算法也可以去随机化，并能在动态流上工作，只需在空间方面增加一些额外的 $\text{poly}(\log n, 1/\epsilon)$ 因子。此前，该问题的最佳已知算法需要 $1/\epsilon \cdot \log^{c}(n)$ 次通道，其中 $c$ 是一个未指定的较大常数。我们证明了任何半流算法，如果以高常数概率输出给定源点到最短路径的任何常数近似（即使只针对单个固定目标顶点和仅需距离，不一定需要路径），则需要 $\Omega\left(\frac{\log n}{\log\log n}\right)$ 次通道。我们强调，我们的下界适用于任何常数因子近似的最短路径。此前，仅知常数通道下界，且仅适用于小于二的较小近似比。我们的结果共同将半流模型中近似单源最短路径的通道复杂度差距从 $\text{polylog } n$ 与 $\omega(1)$ 缩小到仅二次方差距。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [669] [Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa](https://arxiv.org/abs/2507.17878)
> *通过多项式Freiman-Ruzsa定理对1-in-3-SAT进行强稀疏化*

*Benjamin Bedert, Tamio-Vesa Nakajima, Karolina Okrasa, Stanislav Živný* | **Category: cs.DS, cs.CC, cs.DM, math.CO** | **Updated: 2025-07-23**

**Keywords:** 强稀疏化, 1-in-3-SAT, Polynomial Freiman-Ruzsa定理, 超图着色, 次二次界

**Comment:** Full version of a FOCS'25 paper

> **TL;DR:** 本文引入了一种新的稀疏化概念，称为“强稀疏化”，并提出了一个针对1-in-3-SAT的强稀疏化算法。该算法的正确性依赖于使用多项式Freiman-Ruzsa定理建立的向量集大小的次二次界，并应用于改进3-均匀超图的线性有序着色算法。

**AI_Comments:** 本文的创新点在于提出了“强稀疏化”这一新颖的稀疏化范式，通过变量合并而非传统的约束移除实现。更重要的是，它巧妙地将最新的Polynomial Freiman-Ruzsa定理应用于解决1-in-3-SAT问题，并得到了一个具有独立理论价值的次二次界结果。这一理论突破不仅为组合数学和理论计算机科学提供了新的工具，还成功地提升了超图着色问题的最新算法性能，展示了其在理论和应用层面的双重贡献。

<details>
  <summary>Details</summary>

**Motivation:** 引入一种新的稀疏化概念（强稀疏化）以解决问题，并改进现有算法的性能。

**Method:** 提出了一种针对1-in-3-SAT的强稀疏化算法。该算法通过变量合并而非约束移除实现稀疏化。其正确性依赖于建立$\mathbb{F}_2^d$中特定向量集的次二次界，这通过使用最近的Polynomial Freiman-Ruzsa定理实现。

**Result:** 主要结果是为1-in-3-SAT提供了一个强稀疏化算法。该算法建立了一个关于$\mathbb{F}_2^d$中向量集大小的次二次界，该结果可能具有独立的理论意义。作为一个应用，它改进了3-均匀超图线性有序着色的最新算法。

**Conclusion:** 本文成功提出了一个针对1-in-3-SAT的强稀疏化算法，并利用Polynomial Freiman-Ruzsa定理证明了其正确性，得到了一个具有独立兴趣的次二次界结果。此外，该方法还成功应用于改进了超图着色问题的最新算法。

> **ai_Abstract:** 本文介绍了一种名为“强稀疏化”的新概念，其特点是合并变量而非移除约束。研究的核心成果是开发了一个针对1-in-3-SAT的强稀疏化算法。该算法的有效性基于Polynomial Freiman-Ruzsa定理，成功地为$\mathbb{F}_2^d$中特定向量集的大小建立了次二次界，这一理论发现本身也具有重要意义。此外，该方法的一个实际应用是显著提升了3-均匀超图线性有序着色问题的现有最佳算法性能。

> **摘要翻译:** 我们引入了一种新的稀疏化概念，称为“强稀疏化”，其中不移除约束但可以合并变量。作为我们的主要成果，我们提出了一个针对1-in-3-SAT的强稀疏化算法。该算法的正确性依赖于建立$\mathbb{F}_2^d$中某些向量集大小的次二次界。这一结果是使用最近的“多项式Freiman-Ruzsa定理”（Gowers, Green, Manners and Tao, Ann. Math. 2025）获得的，可能具有独立的兴趣。作为一项应用，我们改进了3-均匀超图线性有序着色的最新算法（H{\aa}stad, Martinsson, Nakajima and{\v{Z}}ivn{\v{y}}, APPROX 2024）。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [719] [Dual Charging for Half-Integral TSP](https://arxiv.org/abs/2507.17999)
> *半整数TSP的双重充电*

*Nathan Klein, Mehrshad Taziki* | **Category: cs.DS** | **Updated: 2025-07-24**

**Keywords:** 半整数TSP, 最大熵算法, 近似算法, 对偶分析, 线性规划

**Comment:** 

> **TL;DR:** 本文通过使用对偶分析，将半整数旅行商问题（TSP）的最大熵算法的近似比从1.49993提高到1.49776。

**AI_Comments:** 本文的创新点在于采用对偶而非原始问题来分析匹配的预期成本，这使得半整数TSP的近似比得到了显著改进。这种分析方法的潜力在于它可能为更普遍的近似算法提供更简洁的理论证明，显示了其在理论计算机科学，特别是近似算法领域的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在改进半整数旅行商问题（TSP）的现有近似比，特别是提高最大熵算法的性能，并探索一种可能简化一般情况下证明的方法。

**Method:** 本文使用最大熵算法处理半整数TSP。关键改进在于使用对偶而非原始问题来分析匹配的预期成本。此外，还对没有适当最小割且顶点数为偶数的半整数LP解进行了分析，并将其扩展到顶点数为奇数的情况。

**Result:** 1. 将半整数TSP的最大熵算法的近似比从Karlin等人之前已知的1.49993提高到1.49776。2. 将没有适当最小割且顶点数为偶数的半整数LP解的近似比从Haddadan和Newman的1.476提高到1.4671。3. 将分析扩展到顶点数为奇数的情况，额外增加了O(1/n)的因子。

**Conclusion:** 通过使用对偶分析，本文成功提高了半整数TSP的最大熵算法的近似比，并对特定条件下的半整数LP解给出了更好的近似。研究者相信这种分析方法可能为证明最大熵算法在一般情况下优于3/2近似提供更简单的证据。

> **ai_Abstract:** 本文通过采用对偶分析方法，将半整数旅行商问题（TSP）的最大熵算法的近似比从先前的1.49993提升至1.49776。此外，研究还为没有适当最小割且顶点数为偶数的半整数线性规划（LP）解提供了一个1.4671的近似，并进一步将分析推广到顶点数为奇数的情况。研究者认为这种对偶分析方法有望为证明最大熵算法在一般情况下的更优性能提供更简洁的证明。

> **摘要翻译:** 我们证明了最大熵算法是半整数TSP的一个随机1.49776近似算法，改进了Karlin等人之前已知的1.49993的界限。这也改进了Gupta等人对半整数TSP的最佳已知近似。我们的改进源于使用对偶而非原始问题来分析匹配的预期成本。我们相信这种分析方法可能导致一个更简单的证明，即在一般情况下，最大熵算法是优于3/2的近似。
我们还为没有适当最小割且顶点数为偶数的半整数LP解提供了一个1.4671的近似，改进了Haddadan和Newman的1.476的界限。然后，我们将分析扩展到顶点数为奇数n的情况，代价是额外增加了O(1/n)的因子。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [28] [DanceGraph: A Complementary Architecture for Synchronous Dancing Online](https://arxiv.org/abs/2507.18052)
> *舞图：一种用于在线同步舞蹈的补充架构*

*David Sinclair, Ademyemi Ademola, Babis Koniaris, Kenny Mitchell* | **Category: cs.GR, I.3.2; C.2.1** | **Updated: 2025-07-24**

**Keywords:** 在线同步舞蹈, 延迟克服, 实时架构, 运动预测, 舞蹈风格化

**Comment:** 36th International Conference on Computer Animation and Social Agents

> **TL;DR:** DanceGraph是一种用于在线同步舞蹈的架构，通过实时、带宽高效的设计来克服网络延迟，并支持舞蹈动作的参数化风格化。

**AI_Comments:** 该论文提出了一种解决在线同步舞蹈中关键延迟问题的创新架构。其关注实时性、带宽效率以及减少运动预测时间的特点，对于提升用户体验至关重要。此外，支持舞蹈动作风格化的功能增加了其应用的多样性。

<details>
  <summary>Details</summary>

**Motivation:** 在线同步舞蹈中，网络身体姿态共享的延迟是一个主要挑战。

**Method:** DanceGraph通过开发一种实时、带宽高效的架构来最小化延迟，并减少与音乐节奏同步所需的运动预测时间。此外，它还展示了一种使用在线舞蹈纠正器对有节奏舞蹈动作进行参数化风格化的交互式方法。

**Result:** 该架构旨在克服网络身体姿态共享的延迟，并通过实时、带宽高效的设计最小化延迟并减少同步所需的运动预测时间。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** DanceGraph是一种创新的架构，旨在解决在线同步舞蹈中由网络身体姿态共享引起的延迟问题。该架构通过实时、带宽高效的设计来最小化延迟并优化音乐同步所需的运动预测。此外，它还提供了一种交互式方法，利用在线舞蹈纠正器对节奏性舞蹈动作进行参数化风格化。

> **摘要翻译:** DanceGraph是一种用于在线同步舞蹈的架构，旨在克服网络身体姿态共享的延迟。我们通过开发一种实时、带宽高效的架构来分解这一挑战，以最小化延迟并减少与音乐节奏同步所需的运动预测时间。此外，我们展示了一种使用在线舞蹈纠正器对有节奏舞蹈动作进行参数化风格化的交互式方法。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [76] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
> *GeoAvatar：用于3D头部化身的自适应几何高斯泼溅*

*SeungJun Moon, Hah Min Lew, Seungeun Lee, Ji-Su Kang, Gyeong-Moon Park* | **Category: cs.GR, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 3D头部化身, 高斯泼溅, 自适应几何, 面部动画, 身份保留

**Comment:** ICCV 2025, Project page: https://hahminlew.github.io/geoavatar/

> **TL;DR:** GeoAvatar提出一种自适应几何高斯泼溅框架，通过自适应预分配、嘴部结构优化和精确绑定损失，显著提升3D头部化身在重建和动画方面的质量。

**AI_Comments:** GeoAvatar的创新点在于其多层次的自适应策略，包括高斯点的刚柔分割、针对口腔的精细化建模以及精确的绑定损失，这些都直接针对现有方法在面部几何适应性上的痛点。发布新数据集DynamicFace也为该领域的研究提供了有价值的资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D头部化身生成方法难以平衡身份保留（重建）与新姿态/表情（动画），且难以使高斯点适应面部区域的不同几何偏差，导致质量不佳。

**Method:** GeoAvatar提出自适应几何高斯泼溅框架。它包含：1. 自适应预分配阶段（APS），一种无监督方法，将高斯点分割为刚性和柔性集合，用于自适应偏移正则化。2. 基于口腔解剖学和动力学，引入新颖的口腔结构和分部件变形策略，以增强口腔的动画保真度。3. 提出一种正则化损失，用于高斯点与3DMM人脸之间的精确绑定。此外，还发布了DynamicFace视频数据集。

**Result:** 广泛的实验表明，GeoAvatar在重建和新颖动画场景中均优于现有最先进的方法。

**Conclusion:** GeoAvatar通过其自适应几何高斯泼溅框架，成功解决了3D头部化身生成中身份保留与动画平衡的挑战，显著提升了重建和动画的质量。

> **ai_Abstract:** GeoAvatar提出一种自适应几何高斯泼溅框架，旨在解决3D头部化身生成中重建与动画平衡的挑战。该框架通过自适应预分配阶段（APS）对高斯点进行刚性和柔性分割，引入新颖的口腔结构和分部件变形策略以提升口腔动画保真度，并使用正则化损失实现高斯点与3DMM人脸的精确绑定。实验证明，GeoAvatar在重建和新颖动画方面均优于现有方法，并且还贡献了一个名为DynamicFace的新数据集。

> **摘要翻译:** 尽管3D头部化身生成最近取得了进展，但在身份保留（即重建）与新姿态和表情（即动画）之间取得平衡仍然是一个挑战。现有方法难以使高斯点适应面部区域的不同几何偏差，导致质量不佳。为了解决这个问题，我们提出了GeoAvatar，一个用于自适应几何高斯泼溅的框架。GeoAvatar利用自适应预分配阶段（APS），这是一种无监督方法，将高斯点分割为刚性和柔性集合，用于自适应偏移正则化。然后，基于口腔解剖学和动力学，我们引入了一种新颖的口腔结构和分部件变形策略，以增强口腔的动画保真度。最后，我们提出了一种正则化损失，用于高斯点与3DMM人脸之间的精确绑定。此外，我们发布了DynamicFace，一个包含高度表达面部动作的视频数据集。广泛的实验表明，GeoAvatar在重建和新颖动画场景中均优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [116] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
> *PS-GS：用于多视角光度立体法的高斯泼溅*

*Yixiao Chen, Bin Liang, Hanzhi Guo, Yongqing Cheng, Jiayi Zhao, Dongdong Weng* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 高斯泼溅, 多视角光度立体, 逆向渲染, 三维重建, 光照估计

**Comment:** 

> **TL;DR:** PS-GS提出了一种结合高斯泼溅和多视角光度立体的新方法，能够高效准确地进行逆向渲染，实现三维重建、材质和光照估计。

**AI_Comments:** 该论文通过将高斯泼溅技术引入多视角光度立体法，有效解决了逆向渲染的效率和精度挑战。其创新点在于结合2D高斯泼溅进行初始化、利用MLP进行延迟逆向渲染以及通过正则化和2D高斯光线追踪来优化光照和法线估计。该方法不仅提高了重建质量和计算效率，还支持广泛的下游应用，显示出其在三维重建领域的潜在重要性。

<details>
  <summary>Details</summary>

**Motivation:** 将逆向渲染与多视角光度立体法（MVPS）结合可以获得比依赖固定环境光照的逆向渲染方法更准确的3D重建，但其高效实现仍然具有挑战性。

**Method:** 本文引入了PS-GS（用于多视角光度立体法的高斯泼溅），它能高效地联合估计物体在多种定向光（多光源）下的几何、材质和光照。该方法首先重建一个标准的2D高斯泼溅模型作为初始几何。基于此初始化模型，通过包含光照计算多层感知机（MLP）的完整渲染方程进行延迟逆向渲染。在整个优化过程中，通过未校准的光度立体法估计的法线对渲染的法线图进行正则化。此外，还提出了用于单一定向光的2D高斯光线追踪以细化入射光照。这些正则化以及多视角和多光源图像的使用缓解了逆向渲染的病态问题。

**Result:** 优化后重建的物体可用于新视角合成、重新打光以及材质和形状编辑。在合成数据集和真实数据集上的实验表明，该方法在重建精度和计算效率方面均优于现有工作。

**Conclusion:** PS-GS通过结合高斯泼溅和多视角光度立体法，有效解决了高效逆向渲染的挑战，实现了高精度的三维重建、材质和光照估计，并支持多种后续应用。

> **ai_Abstract:** PS-GS是一种针对多视角光度立体法（MVPS）的逆向渲染新方法，它结合了高斯泼溅技术，旨在高效且联合地估计物体的几何、材质和光照。该方法通过2D高斯泼溅模型初始化几何，并利用包含光照计算MLP的延迟逆向渲染方程进行优化。通过未校准的光度立体法估计法线进行正则化，并引入2D高斯光线追踪来细化光照，有效缓解了逆向渲染的病态问题。实验证明，PS-GS在重建精度和计算效率上均超越了现有方法，其重建结果可用于新视角合成、重新打光和材质/形状编辑。

> **摘要翻译:** 将逆向渲染与多视角光度立体法（MVPS）结合可以获得比依赖固定环境光照的逆向渲染方法更准确的3D重建。然而，高效地进行MVPS的逆向渲染仍然具有挑战性。为了弥补这一空白，我们引入了用于多视角光度立体法的高斯泼溅（PS-GS），它能高效地联合估计物体在多种定向光（多光源）下的几何、材质和光照。我们的方法首先重建一个标准的2D高斯泼溅模型作为初始几何。基于该初始化模型，它接着通过包含光照计算多层感知机（MLP）的完整渲染方程进行延迟逆向渲染。在整个优化过程中，我们通过未校准的光度立体法估计的法线对渲染的法线图进行正则化。我们还提出了用于单一定向光的2D高斯光线追踪以细化入射光照。这些正则化以及多视角和多光源图像的使用缓解了逆向渲染的病态问题。优化后，重建的物体可用于新视角合成、重新打光以及材质和形状编辑。在合成数据集和真实数据集上的实验表明，我们的方法在重建精度和计算效率方面均优于现有工作。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [191] [Assessing Learned Models for Phase-only Hologram Compression](https://arxiv.org/abs/2507.06646)
> *评估学习模型用于纯相位全息图压缩*

*Zicong Peng, Yicheng Zhan, Josef Spjut, Kaan Akşit* | **Category: cs.GR** | **Updated: 2025-07-24**

**Keywords:** 纯相位全息图压缩, 学习模型, INR, VAE, SIREN

**Comment:** SIGGRAPH 2025 Poster

> **TL;DR:** 本文评估了INR和VAE模型在纯相位全息图压缩上的性能，发现SIREN表现良好，而预训练的图像VAE效果不佳。

**AI_Comments:** 本文对不同类型的学习模型在特定任务——纯相位全息图压缩上的性能进行了对比评估，尤其突出了INR模型（如SIREN）的潜力，并揭示了直接应用通用图像压缩VAE的局限性，这对于未来全息显示技术的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了评估学习模型在全息显示中纯相位全息图压缩的性能，并找出适合该任务的模型。

**Method:** 评估了四种利用INR和VAE结构的学习模型（包括MLP、SIREN、FilmSIREN和TAESD）在压缩纯相位全息图上的表现。

**Result:** 预训练的图像VAE (TAESD) 在纯相位全息图压缩上表现不佳，需要任务特定的适应。INR模型中的SIREN实现了40%的压缩率，并在重建的3D图像中保持了高质量 (PSNR = 34.54 dB)。

**Conclusion:** INR模型在纯相位全息图压缩中有效，而预训练的图像压缩VAE在该任务上存在局限性。

> **ai_Abstract:** 本文评估了四种基于INR和VAE结构的学习模型（MLP、SIREN、FilmSIREN、TAESD）在全息显示中纯相位全息图压缩方面的性能。研究发现，预训练的图像VAE (TAESD) 在此任务上表现不佳，而INR模型中的SIREN则以较低的参数量实现了高压缩率和高质量的3D图像重建，强调了INR的有效性并指出了预训练VAE的局限性。

> **摘要翻译:** 我们评估了四种常用学习模型（利用INR和VAE结构）在全息显示中纯相位全息图压缩的性能。评估模型包括一个普通MLP、SIREN和FilmSIREN，以及作为代表性VAE模型的TAESD。我们的实验表明，一个拥有2.2M参数的预训练图像VAE (TAESD) 在纯相位全息图压缩方面表现不佳，揭示了任务特定适应的必要性。在INR模型中，拥有4.9k参数的SIREN实现了40%的压缩率，并在重建的3D图像中获得了高质量（PSNR = 34.54 dB）。这些结果强调了INR模型的有效性，并指出了预训练图像压缩VAE在全息图压缩任务中的局限性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [231] [Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation](https://arxiv.org/abs/2507.08513)
> *通过大规模3D视觉指令数据集生成推进多模态LLM*

*Liu He, Xiao Zeng, Yizhi Song, Albert Y. C. Chen, Lu Xia, Shashwat Verma, Sankalp Dayal, Min Sun, Cheng-Hao Kuo, Daniel Aliaga* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-23**

**Keywords:** 多模态LLM, 3D视觉指令, 数据集生成, 相机-物体关系, Ultimate3D

**Comment:** 

> **TL;DR:** 本文提出一种合成生成管道，用于创建大规模3D视觉指令数据集，旨在解决多模态LLM在准确捕捉相机-物体关系方面的不足，并显著提升了模型在该任务上的性能。

**AI_Comments:** 本文的创新点在于提出了一种新颖且高效的合成生成管道，巧妙地融合了3D资产、渲染技术、扩散模型和大型语言模型（LLMs），以系统性地解决多模态LLMs在理解复杂相机-物体关系上的数据瓶颈。通过生成大规模、高质量的合成数据集，该研究有效地克服了真实世界数据采集和标注的固有挑战。其在相机-物体关系识别任务上取得的显著性能提升（33.4%的平均准确率提升）充分证明了该方法的有效性和重要性，为未来多模态LLMs在需要精确空间理解的应用中提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）在准确捕捉相机-物体关系，特别是物体方向、相机视角和相机镜头方面存在困难。这主要是因为现有MLLMs所训练的图像在相机-物体关系多样性及其对应的文本描述方面都比较有限。

**Method:** 本文提出一个合成生成管道来创建大规模3D视觉指令数据集。该框架以3D资产作为输入，利用渲染和基于扩散的图像生成模型来创建保留精确相机-物体关系的照片级真实图像。此外，大型语言模型（LLMs）被用于生成文本提示，以指导视觉指令微调和控制图像生成。

**Result:** 本文创建了Ultimate3D数据集，包含24万个带有精确相机-物体标注的视觉问答（VQAs）及其相应的基准。在该数据集上微调的MLLMs在相机-物体关系识别任务上平均准确率提高了33.4%，大幅超越了商业模型。

**Conclusion:** 该论文的工作，包括其代码、数据集和基准，将为广泛的多模态LLM应用做出贡献。

> **ai_Abstract:** 本文提出了一种新颖的合成生成管道，旨在创建大规模3D视觉指令数据集，以解决多模态LLMs在准确理解相机-物体关系方面的现有挑战。该方法结合了3D资产、渲染技术、扩散模型和LLM生成的文本提示，从而生成带有精确相机-物体关系标注的照片级真实图像和VQAs。通过使用所构建的Ultimate3D数据集进行微调，MLLMs在相机-物体关系识别任务上实现了显著的性能提升，平均准确率提高了33.4%。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在准确捕捉相机-物体关系方面面临困难，特别是物体方向、相机视角和相机镜头。这源于现有MLLMs在相机-物体关系多样性和相应文本描述有限的图像上进行训练。为了解决这个问题，我们提出了一种合成生成管道来创建大规模3D视觉指令数据集。我们的框架以3D资产作为输入，并利用渲染和基于扩散的图像生成模型创建保留精确相机-物体关系的照片级真实图像。此外，大型语言模型（LLMs）被用于生成文本提示，以指导视觉指令微调和控制图像生成。我们创建了Ultimate3D，一个包含24万个带有精确相机-物体标注的VQAs数据集，以及相应的基准。在我们的数据集上微调的MLLMs大幅优于商业模型，在相机-物体关系识别任务上平均准确率提高了33.4%。我们的代码、数据集和基准将为广泛的MLLM应用做出贡献。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [663] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
> *“小”还不够小：通过混合知识蒸馏实现高质量、低资源的面部动画模型*

*Zhen Han, Mattias Teye, Derek Yadgaroff, Judith Bütepage* | **Category: cs.GR, cs.LG, cs.MM, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 面部动画, 知识蒸馏, 低资源模型, 实时推理, 语音驱动

**Comment:** Accepted to ACM Transactions on Graphics 2025 (SIGGRAPH journal
  track)

> **TL;DR:** 本文通过混合知识蒸馏方法，训练出在设备上运行的微小模型，实现了高质量、低资源消耗的实时面部动画。

**AI_Comments:** 本文的创新点在于提出了混合知识蒸馏结合伪标签的方法，成功地将大型高性能模型的知识迁移到极小的学生模型中，从而实现了在资源受限设备上的实时面部动画。这对于游戏开发和移动应用等场景具有重要意义，解决了传统方法模型过大、无法实时运行的痛点。其贡献在于证明了即使是“微小”的模型也能通过巧妙的训练策略达到高质量表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的高质量语音驱动3D面部动画模型需要大量数据且模型庞大，只能离线运行。研究目标是为游戏开发探索适用于设备端的实时面部动画模型，解决数据集缺乏和模型过大的问题。

**Method:** 通过混合知识蒸馏和伪标签技术，利用高性能的教师模型训练非常小的学生模型。学生模型仅包含卷积层和全连接层，移除了注意力机制和循环更新。

**Result:** 模型内存占用减少至3.4 MB，所需未来音频上下文减少至81 ms，同时保持了高质量的动画效果。

**Conclusion:** 本研究为设备端推理铺平了道路，是实现逼真、模型驱动的数字角色的重要一步。

> **ai_Abstract:** 本文针对现有高质量语音驱动3D面部动画模型过于庞大且需离线运行的问题，提出了一种通过混合知识蒸馏和伪标签训练低资源、设备端实时面部动画模型的方法。研究利用高性能教师模型训练小型学生模型，学生模型仅由卷积层和全连接层构成，显著减少了内存占用和音频上下文需求，同时保持了高质量动画效果，为逼真数字角色在设备端推理奠定了基础。

> **摘要翻译:** 高质量、鲁棒的语音驱动3D面部动画机器学习模型训练需要大量、多样化的高质量音频-动画对数据集。为了克服这种数据集的缺乏，最近的工作引入了大型预训练语音编码器，这些编码器对输入音频的变化具有鲁棒性，因此使得面部动画模型能够跨说话者、音频质量和语言进行泛化。然而，由此产生的面部动画模型过于庞大，只能在专用机器上进行离线推理。
在这项工作中，我们在游戏开发的背景下探索设备端、实时面部动画模型。我们通过使用带有伪标签的混合知识蒸馏来克服大型数据集的缺乏。给定一个大型音频数据集，我们采用一个高性能的教师模型来训练非常小的学生模型。与预训练的语音编码器不同，我们的学生模型只包含卷积层和全连接层，消除了对注意力上下文或循环更新的需求。在我们的实验中，我们证明了我们可以将内存占用减少到3.4 MB，并将所需的未来音频上下文减少到81 ms，同时保持高质量的动画。这为设备端推理铺平了道路，是实现逼真、模型驱动的数字角色的重要一步。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [737] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
> *基于网格LoRA的零样本动态概念个性化*

*Rameen Abdal, Or Patashnik, Ekaterina Deyneka, Hao Chen, Aliaksandr Siarohin, Sergey Tulyakov, Daniel Cohen-Or, Kfir Aberman* | **Category: cs.GR, cs.CV, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 零样本, 动态概念个性化, 文本到视频, LoRA, 网格

**Comment:** Project Page and Video :
  https://snap-research.github.io/zero-shot-dynamic-concepts/

> **TL;DR:** 本文提出了一种零样本框架，利用网格LoRA适配器和网格填充模块，实现文本到视频模型中动态概念的个性化，无需针对每个实例进行微调，显著提高了可扩展性和泛化能力。

**AI_Comments:** 该论文的创新点在于提出了一个完全零样本的动态概念个性化框架，通过引入结构化的视频网格和轻量级的Grid-LoRA适配器，有效解决了现有方法中每个实例都需要微调的扩展性限制。其“单次前向传播”和“泛化到未见概念”的能力显著提高了效率和实用性，对于文本到视频生成领域具有重要的推进作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态概念个性化方法通常需要针对每个实例进行微调，这限制了它们的可扩展性。

**Method:** 本文引入了一个零样本框架，利用结构化的2x2视频网格来空间组织输入和输出对。通过训练轻量级的Grid-LoRA适配器进行网格内的编辑和合成，并在推理时使用专门的Grid Fill模块完成部分观察到的布局，生成时间连贯且保持身份的输出。

**Result:** 广泛的实验表明，该方法在各种主体和编辑场景中，甚至对于训练概念之外的未见动态概念，也能产生高质量和一致的结果。

**Conclusion:** 一旦训练完成，整个系统只需一次前向传播即可运行，无需任何测试时优化，就能泛化到以前未见的动态概念，实现了高效且可扩展的动态概念个性化。

> **ai_Abstract:** 本文提出了一种名为“基于网格LoRA的零样本动态概念个性化”的创新框架，旨在解决现有文本到视频生成中动态概念个性化方法可扩展性受限的问题。该方法通过引入结构化的2x2视频网格来组织输入输出，并训练轻量级的Grid-LoRA适配器进行编辑和合成。在推理阶段，利用Grid Fill模块完成部分布局，确保输出的时间连贯性和身份保持。该系统在训练后能以单次前向传播实现对未见动态概念的泛化，无需测试时优化，并在实验中展现出高质量和一致的结果。

> **摘要翻译:** 文本到视频生成的最新进展使得从文本和图像提示中合成高质量内容成为可能。虽然捕获特定主体外观和运动的动态概念的个性化（从单个视频中）现在是可行的，但大多数现有方法需要针对每个实例进行微调，这限制了可扩展性。我们引入了一个完全零样本的框架，用于文本到视频模型中的动态概念个性化。我们的方法利用结构化的2x2视频网格，空间组织输入和输出对，从而能够训练轻量级的Grid-LoRA适配器，用于这些网格内的编辑和合成。在推理时，一个专门的Grid Fill模块完成部分观察到的布局，生成时间连贯且保持身份的输出。一旦训练完成，整个系统只需一次前向传播即可运行，无需任何测试时优化，就能泛化到以前未见的动态概念。广泛的实验证明了在训练概念之外的各种主体和编辑场景中，高质量和一致的结果。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [34] [DR.EHR: Dense Retrieval for Electronic Health Record with Knowledge Injection and Synthetic Data](https://arxiv.org/abs/2507.18583)
> *DR.EHR：用于电子健康记录的知识注入和合成数据密集检索*

*Zhengyun Zhao, Huaiyuan Ying, Yue Zhong, Sheng Yu* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 电子健康记录, 密集检索, 知识注入, 合成数据, 语义鸿沟

**Comment:** Model and code released upon acceptance

> **TL;DR:** DR.EHR提出了一种新的密集检索模型，通过知识注入和合成数据生成，显著提升了电子健康记录（EHR）检索的性能，并在CliniQ基准测试中达到了最先进水平。

**AI_Comments:** DR.EHR的创新之处在于其结合知识注入和合成数据生成的两阶段训练管道，有效解决了EHR检索中医学知识匮乏和数据不足的问题。模型的通用性和在复杂语义匹配上的优越性，使其在临床应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 电子健康记录（EHRs）在临床实践中至关重要，但由于语义鸿沟问题，其检索仍然面临挑战。现有的密集检索模型，无论是通用领域还是生物医学领域，都因医学知识不足或训练语料不匹配而表现不佳。

**Method:** 本文提出了DR.EHR，一个专门针对EHR检索的密集检索模型系列。采用两阶段训练管道，利用MIMIC-IV出院摘要。第一阶段涉及医学实体提取和来自生物医学知识图谱的知识注入；第二阶段利用大型语言模型生成多样化的训练数据。训练了110M和7B参数的两种DR.EHR变体。

**Result:** DR.EHR模型在CliniQ基准测试中显著优于所有现有密集检索器，取得了最先进的结果。详细分析证实了模型在各种匹配和查询类型上的优越性，特别是在含义和缩写等挑战性语义匹配中。消融研究验证了每个管道组件的有效性，EHR QA数据集上的补充实验证明了模型在自然语言问题（包括具有多个实体的复杂问题）上的泛化能力。

**Conclusion:** 这项工作显著推进了EHR检索领域，为临床应用提供了强大的解决方案。

> **ai_Abstract:** 本文介绍了DR.EHR，一个专为电子健康记录（EHR）检索设计的密集检索模型系列，旨在解决现有方法因医学知识不足和训练数据不匹配导致的语义鸿沟问题。DR.EHR采用两阶段训练管道：首先从生物医学知识图谱注入医学实体知识，然后利用大型语言模型生成大规模合成训练数据。该模型在CliniQ基准测试中表现出色，显著超越了现有密集检索器，达到了最先进水平，并在复杂语义匹配和自然语言问答方面展现出强大的泛化能力。

> **摘要翻译:** 电子健康记录（EHRs）在临床实践中至关重要，但其检索仍然面临挑战，主要原因是语义鸿沟问题。密集检索的最新进展提供了有前景的解决方案，但现有模型，无论是通用领域还是生物医学领域，都因医学知识不足或训练语料不匹配而表现不佳。本文介绍了\texttt{DR.EHR}，一系列专门为EHR检索定制的密集检索模型。我们提出了一个两阶段训练管道，利用MIMIC-IV出院摘要来解决对广泛医学知识和大规模训练数据的需求。第一阶段涉及医学实体提取和生物医学知识图谱的知识注入，而第二阶段则采用大型语言模型生成多样化的训练数据。我们训练了\texttt{DR.EHR}的两个变体，分别具有1.1亿和70亿参数。在CliniQ基准测试中进行评估，我们的模型显著优于所有现有密集检索器，取得了最先进的结果。详细分析证实了我们的模型在各种匹配和查询类型上的优越性，特别是在含义和缩写等挑战性语义匹配中。消融研究验证了每个管道组件的有效性，并且在EHR QA数据集上的补充实验证明了模型在自然语言问题（包括具有多个实体的复杂问题）上的泛化能力。这项工作显著推进了EHR检索，为临床应用提供了强大的解决方案。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [134] [VERIRAG: Healthcare Claim Verification via Statistical Audit in Retrieval-Augmented Generation](https://arxiv.org/abs/2507.17948)
> *VERIRAG：通过检索增强生成中的统计审计进行医疗保健声明验证*

*Shubham Mohole, Hongjun Choi, Shusen Liu, Christine Klymko, Shashank Kushwaha, Derek Shi, Wesam Sakla, Sainyam Galhotra, Ruben Glatt* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 检索增强生成, 医疗保健, 声明验证, 统计审计, 证据质量

**Comment:** 

> **TL;DR:** VERIRAG是一个评估检索增强生成（RAG）系统中证据科学质量的框架，通过可信度清单、硬变化分数和动态接受阈值，显著提高了医疗保健声明验证的F1分数。

**AI_Comments:** VERIRAG框架的创新之处在于其引入了对RAG系统中检索证据进行科学质量评估的能力，这对于提高临床决策支持的可靠性至关重要。其结合清单、量化分数和动态阈值的方法提供了一个全面的解决方案，解决了现有RAG系统在方法论上的盲点。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）系统在临床决策支持中日益普及，但它们在方法论上是盲目的，无法评估检索到的证据的科学质量，例如将缺乏严谨性甚至已撤回的论文与严谨的研究同等对待。为了解决这一挑战，本研究引入了VERIRAG框架。

**Method:** 本研究提出了VERIRAG框架，包含三个主要组成部分：(i) Veritable，一个11点清单，用于评估每个来源的方法学严谨性，包括数据完整性和统计有效性；(ii) 硬变化（HV）分数，一个定量聚合器，根据证据的质量和多样性对其进行加权；(iii) 动态接受阈值，根据声明的非凡程度校准所需证据。该方法在四个数据集上进行了测试。

**Result:** VERIRAG方法在四个数据集（包括撤回、冲突、综合和已确立科学语料库）上始终优于所有基线，实现了0.53至0.65的绝对F1分数，比每个数据集中次优方法提高了10到14个百分点。

**Conclusion:** VERIRAG框架通过引入评估证据科学质量的机制，显著提高了检索增强生成（RAG）系统在医疗保健声明验证中的性能和可靠性。

> **ai_Abstract:** 本论文介绍了VERIRAG框架，旨在解决检索增强生成（RAG）系统在临床决策支持中无法评估证据科学质量的问题。VERIRAG包含一个评估方法学严谨性的11点清单（Veritable）、一个根据质量和多样性加权证据的硬变化（HV）分数，以及一个根据声明“非凡”程度调整所需证据的动态接受阈值。实验结果表明，在包含撤回、冲突、综合和已确立科学数据的四个数据集上，VERIRAG方法在F1分数上均显著优于现有基线，实现了10至14个百分点的提升。

> **摘要翻译:** 检索增强生成（RAG）系统在临床决策支持中日益普及，但它们在方法论上仍然是盲目的——它们检索证据，但无法验证其科学质量。一篇声称“异干扰素治疗后抗氧化蛋白减少”的论文和一项严谨的多实验室复制研究将被视为同样可信，即使前者缺乏科学严谨性甚至已被撤回。为了应对这一挑战，我们引入了VERIRAG，一个具有三个显著贡献的框架：(i) Veritable，一个11点清单，评估每个来源的方法学严谨性，包括数据完整性和统计有效性；(ii) 硬变化（HV）分数，一个定量聚合器，根据证据的质量和多样性对证据进行加权；(iii) 动态接受阈值，根据声明的非凡程度校准所需证据。在四个数据集——包括撤回、冲突、综合和已确立科学语料库——中，VERIRAG方法始终优于所有基线，实现了0.53至0.65的绝对F1分数，比每个相应数据集中次优方法提高了10到14个百分点。我们将发布重现我们结果所需的所有材料。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [196] [Failure Prediction in Conversational Recommendation Systems](https://arxiv.org/abs/2507.17976)
> *会话推荐系统中的故障预测*

*Maria Vlachou* | **Category: cs.IR** | **Updated: 2025-07-23**

**Keywords:** 会话推荐系统,故障预测,自编码器,系统故障,目录故障

**Comment:** 

> **TL;DR:** 本文引入了会话性能预测任务，并提出了一种基于自编码器的预测器，用于检测会话推荐系统中的系统故障和目录故障，以减少用户挫败感。

**AI_Comments:** 本文的创新之处在于首次提出了会话推荐系统中的故障预测任务，并将其细分为系统故障和目录故障，这对于提升用户体验具有重要意义。提出的基于自编码器的方法利用多轮语义信息进行预测，是一种新颖的尝试。然而，文章也指出了在目录故障预测方面性能下降的局限性，这表明未来研究可以在此方向进行改进。该研究为构建更健壮、用户友好的会话推荐系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在会话式图像推荐任务中，系统可能无法返回用户期望的商品（例如，商品不在目录中），这会导致用户需要与系统进行更多轮次的交互，从而产生挫败感。为了缓解这个问题，需要预测系统何时会失败。

**Method:** 本文引入了“监督式会话性能预测”任务，其灵感来源于查询性能预测（QPP）。研究人员提出了会话性能预测器，利用检索到的图像项嵌入表示中包含的多轮语义信息来检测会话失败。具体来说，他们提出了一种基于自编码器（AutoEncoder）的预测器，该预测器学习训练轮次中排名靠前的检索项的压缩表示，并使用分类标签来预测评估轮次。评估场景区分了系统故障（系统无法找到目标）和目录故障（目标不存在于商品目录中）。

**Result:** 在Shoes和FashionIQ Dresses数据集上的实验表明，所提出的预测器在预测系统故障（现有评估场景）方面表现出前景。然而，在目录故障预测（当引入缺失商品场景时）的情况下，预测性能与系统故障相比有显著下降。

**Conclusion:** 本文成功地引入并探索了会话推荐系统中的故障预测任务，并提出了有效的预测器来识别系统故障。尽管在目录故障预测方面仍有提升空间，但该研究为提升会话推荐系统的用户体验提供了重要的方向。

> **ai_Abstract:** 本文针对会话式图像推荐系统中用户期望商品未能返回导致用户挫败的问题，引入了“监督式会话性能预测”任务。受查询性能预测的启发，研究人员提出了一种基于自编码器的预测器，它利用多轮语义信息来检测会话失败。该预测器能够学习检索到的商品项的压缩表示，并区分系统故障和目录故障。实验结果表明，该预测器在预测系统故障方面表现良好，但在预测目录故障时的性能有所下降。

> **摘要翻译:** 在会话式图像推荐任务中，用户可以对推荐的图像项目提供自然语言反馈，从而在下一轮中获得改进的推荐。虽然这类任务的典型实例化假设用户的目标项目最终会被返回，但这可能常常不真实，例如，用户寻找的商品不在商品目录中。未能返回用户期望的商品可能导致用户挫败感，因为用户需要与系统进行更多轮次的交互。为了缓解这个问题，本文引入了监督式会话性能预测任务，其灵感来源于用于预测搜索引擎查询响应有效性的查询性能预测（QPP）。在这方面，我们提出了会话性能预测器，它们利用检索到的图像项嵌入表示中包含的多轮语义信息来检测会话失败。具体来说，我们基于自编码器（AutoEncoder）的预测器学习训练轮次中排名靠前的检索项的压缩表示，并使用分类标签来预测评估轮次。我们的评估场景解决了两种推荐场景，通过区分系统故障（系统无法找到目标）和目录故障（目标不存在于商品目录中）。在我们使用Shoes和FashionIQ Dresses数据集进行的实验中，我们测量了系统故障和目录故障预测器的准确性。我们的结果表明，我们提出的预测器在预测系统故障（现有评估场景）方面前景广阔，但与系统故障相比，在目录故障预测（当引入缺失商品场景时）的情况下，预测性能出现了相当大的下降。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [236] [RecPS: Privacy Risk Scoring for Recommender Systems](https://arxiv.org/abs/2507.18365)
> *RecPS：推荐系统隐私风险评分*

*Jiajie He, Yuechun Gu, Keke Chen* | **Category: cs.IR** | **Updated: 2025-07-24**

**Keywords:** 推荐系统, 隐私风险, 成员推断攻击, 差分隐私, RecPS

**Comment:** 

> **TL;DR:** RecPS提出了一种基于成员推断攻击的隐私评分方法，用于量化推荐系统中用户交互和用户级别的隐私风险，以促进隐私保护的推荐系统开发。

**AI_Comments:** 该论文创新性地将成员推断攻击与差分隐私概念相结合，提出了一个量化推荐系统数据隐私风险的实用框架。RecPS能够对交互和用户两个层面进行风险评分，填补了现有方法无法告知用户哪些交互更敏感的空白。其在风险评估和模型遗忘方面的应用潜力巨大，对推动隐私保护的推荐系统发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统依赖敏感的用户-物品交互数据进行模型训练，但现有的隐私保护措施不足，用户无法识别哪些交互数据更敏感。因此，量化推荐系统训练数据的隐私风险对于实现隐私感知的模型开发和部署至关重要。

**Method:** 本文提出了一种名为RecPS的基于成员推断攻击（MIA）的隐私评分方法，用于衡量交互和用户两个层面的隐私风险。RecPS的交互级评分定义源自差分隐私，并扩展到用户级评分方法。其关键组成部分是交互级MIA方法RecLiRA，该方法提供了高质量的成员估计。

**Result:** 通过在知名基准数据集和推荐系统模型上进行广泛实验，证明了RecPS评分在风险评估和推荐系统模型遗忘方面的独特特性和优势。

**Conclusion:** RecPS提供了一种量化推荐系统数据隐私风险的有效方法，有助于实现隐私感知的推荐系统模型开发和部署。

> **ai_Abstract:** 本文提出了一种名为RecPS的隐私风险评分方法，旨在量化推荐系统中用户交互和用户级别的隐私风险。鉴于现有推荐系统在隐私保护方面的不足，RecPS利用成员推断攻击（MIA）来评估数据的敏感性，其交互级评分源自差分隐私，并引入RecLiRA以提高成员估计的质量。实验证明，RecPS在风险评估和模型遗忘方面具有显著优势，为开发隐私感知的推荐系统提供了关键工具。

> **摘要翻译:** 推荐系统（RecSys）已成为许多网络应用不可或缺的组成部分。系统的核心是使用高度敏感的用户-物品交互数据训练的推荐模型。尽管隐私增强技术在研究社区中得到积极研究，但现实世界的模型开发仍然依赖于最低限度的隐私保护，例如通过受控访问。此类系统的用户应该有权选择不分享高度敏感的交互。然而，目前没有方法允许用户知道哪些交互比其他交互更敏感。因此，量化推荐系统训练数据的隐私风险是实现隐私感知RecSys模型开发和部署的关键一步。我们提出了一种基于成员推断攻击（MIA）的隐私评分方法RecPS，用于衡量交互和用户两个层面的隐私风险。RecPS的交互级评分定义受差分隐私启发并从中推导，然后扩展到用户级评分方法。一个关键组成部分是交互级MIA方法RecLiRA，它提供了高质量的成员估计。我们已经在知名基准数据集和RecSys模型上进行了广泛的实验，以展示RecPS评分在风险评估和RecSys模型遗忘方面的独特特性和优势。我们的代码可在https://anonymous.4open.science/r/RsLiRA-4BD3/readme.md获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [261] [Fashion-AlterEval: A Dataset for Improved Evaluation of Conversational Recommendation Systems with Alternative Relevant Items](https://arxiv.org/abs/2507.18017)
> *Fashion-AlterEval：一个用于改进会话推荐系统评估的替代相关物品数据集*

*Maria Vlachou* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 会话推荐系统, 用户模拟器, 数据集, 评估, 替代物品

**Comment:** arXiv admin note: substantial text overlap with arXiv:2401.05783

> **TL;DR:** 现有会话推荐系统（CRS）的评估受限于单目标用户模拟器，导致低估了系统效率。本文提出了Fashion-AlterEval数据集和元用户模拟器，通过纳入替代相关物品和模拟用户可变耐心来改进评估，并发现现有模型被低估了其有效性。

**AI_Comments:** 本文通过解决CRS评估中的一个关键限制（即当前用户模拟器不切实际的单目标关注和无限耐心）而具有创新性。通过引入人类判断的替代物品和更具动态性的元用户模拟器，它提供了一个更健壮和现实的评估框架。其重要性在于，它可能有助于更好地设计和理解CRS模型，因为它表明现有模型被低估了。这种方法可能促使开发出更以用户为中心和更高效的CRS。

<details>
  <summary>Details</summary>

**Motivation:** 当前会话推荐系统（CRS）的用户模拟器在训练和评估时存在局限性，它们仅基于单一目标物品进行评价，并且具有无限耐心，这导致对系统有效性的低估。

**Method:** 本文提出了Fashion-AlterEval，一个新数据集，通过在常见的时尚CRS数据集中添加新注释，包含人类对一系列替代物品的判断。此外，提出了两个新颖的元用户模拟器，它们利用收集到的判断，不仅允许模拟用户表达对原始目标替代物品的偏好，还允许他们改变主意和耐心程度。

**Result:** 在使用Shoes和Fashion IQ作为原始数据集以及三个CRS模型的实验中，研究发现模拟器使用替代品知识可以对现有CRS模型的评估产生相当大的影响，特别是现有单目标评估低估了它们的有效性，并且当模拟用户被允许考虑替代相关物品时，系统可以快速响应以更快地满足用户。

**Conclusion:** 本文提出的Fashion-AlterEval数据集和元用户模拟器提供了一种更现实、更有效的CRS模型评估方式，揭示了现有模型在更灵活的用户行为下表现优于先前评估的结果。

> **ai_Abstract:** 本文介绍了Fashion-AlterEval，一个新颖的数据集，以及两个元用户模拟器，旨在解决会话推荐系统（CRS）评估中的局限性。现有的评估方法依赖于专注于单一目标物品和无限耐心的用户模拟器，倾向于低估CRS模型的有效性。通过纳入人类对替代物品的判断，并允许模拟用户表达对这些替代品的偏好、改变主意和调整耐心程度，这种新方法提供了更现实的评估。实验表明，考虑替代相关物品显著影响评估结果，揭示了当前CRS模型比先前评估的更有效。

> **摘要翻译:** 在会话推荐系统（CRS）中，用户在每个回合提供对推荐物品的反馈，从而使CRS的推荐得到改进。由于需要大量数据，用户模拟器被用于训练和评估。这类用户模拟器根据对单一目标物品的了解来评价当前检索到的物品。然而，在离线设置中，使用模拟器进行系统评估受到单一目标物品的限制以及它们在大量回合中无限耐心的限制。为了克服现有模拟器的这些局限性，我们提出了Fashion-AlterEval，这是一个新数据集，通过在常见的时尚CRS数据集中添加新注释，包含了人类对一系列替代物品的判断。因此，我们提出了两个新颖的元用户模拟器，它们利用收集到的判断，不仅允许模拟用户表达对原始目标替代物品的偏好，还允许他们改变主意和耐心程度。在我们使用Shoes和Fashion IQ作为原始数据集以及三个CRS模型的实验中，我们发现模拟器使用替代品的知识可以对现有CRS模型的评估产生相当大的影响，特别是现有单目标评估低估了它们的有效性，并且当模拟用户被允许考虑替代相关物品时，系统可以快速响应以更快地满足用户。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [265] [LLM-based Embedders for Prior Case Retrieval](https://arxiv.org/abs/2507.18455)
> *基于LLM的嵌入器用于先例检索*

*Damith Premasiri, Tharindu Ranasinghe, Ruslan Mitkov* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 先例检索, LLM, 文本嵌入器, 无监督学习, 法律信息检索

**Comment:** Accepted in Recent Advancements in Natural Language Processing (RANLP
  2025) conference

> **TL;DR:** 本研究利用基于LLM的文本嵌入器来解决先例检索中的文本长度限制和训练数据不足问题，并在基准数据集上超越了传统方法和监督式模型。

**AI_Comments:** 本文的创新之处在于将LLM-based嵌入器引入先例检索领域，并以无监督的方式克服了该领域长期存在的文本长度限制和训练数据不足的挑战。这对于法律信息检索是一个重要的进展，因为它提供了一种无需大量标注数据即可有效处理长篇法律文本的方法，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在普通法系中，法律专业人士依赖先例来构建论点。随着案件数量的激增，有效检索先例变得至关重要。先例检索（PCR）旨在从大量候选案例中自动识别与特定查询最相关的法院案例。然而，现有的信息检索方法，特别是深度学习方法，在PCR中面临两大挑战：一是法律文本过长导致BERT等Transformer模型输入长度受限，截断或分割会丢失法律上下文信息；二是法律训练数据稀缺，因数据隐私问题导致可用PCR数据集规模有限，难以有效训练深度学习模型。

**Method:** 本研究通过利用基于大型语言模型（LLM）的文本嵌入器来解决先例检索（PCR）中的挑战。LLM-based嵌入器支持更长的输入长度，并且以无监督方式使用，因此不需要训练数据，从而同时解决了文本长度限制和数据稀缺问题。研究在四个PCR基准数据集上评估了最先进的LLM-based文本嵌入器。

**Result:** 实验结果表明，基于LLM的文本嵌入器在先例检索任务中表现优于传统的BM25方法和监督式Transformer模型。

**Conclusion:** 基于LLM的文本嵌入器能够有效解决先例检索中面临的文本长度限制和训练数据不足问题，并在性能上超越了现有方法，为法律信息检索提供了新的解决方案。

> **ai_Abstract:** 本研究旨在解决先例检索（PCR）中存在的法律文本长度限制和训练数据稀缺两大挑战。传统的深度学习方法因这些问题在PCR中表现不佳。论文提出利用基于大型语言模型（LLM）的文本嵌入器，这些嵌入器支持更长的输入长度且无需训练数据，能够以无监督方式应用。实验在四个PCR基准数据集上进行，结果显示基于LLM的嵌入器在性能上超越了BM25和监督式Transformer模型，为法律信息检索提供了有效的新途径。

> **摘要翻译:** 在普通法系中，律师和法官等法律专业人士依赖先例来构建他们的论点。随着时间的推移，案件数量大幅增长，有效检索先例变得至关重要。先例检索（PCR）是一项信息检索（IR）任务，旨在从大量潜在候选案例中自动识别与特定查询最相关的法院案例。尽管信息检索方法在过去几年中经历了多次范式转变，但绝大多数PCR方法仍然依赖传统的IR方法，例如BM25。最先进的深度学习IR方法在PCR中未能成功，原因在于两个关键挑战：i. 冗长法律文本的限制；当使用强大的基于BERT的Transformer模型时，输入文本长度存在限制，这不可避免地需要通过截断或分割来缩短输入，从而导致法律上下文信息的丢失。ii. 法律训练数据的缺乏；由于数据隐私问题，可用的PCR数据集通常规模有限，这使得深度学习模型的有效训练变得困难。在本研究中，我们通过利用基于LLM的文本嵌入器来解决这些挑战。基于LLM的嵌入器支持更长的输入长度，并且由于我们以无监督方式使用它们，它们不需要训练数据，从而同时解决了这两个挑战。在本文中，我们在四个PCR基准数据集上评估了最先进的基于LLM的文本嵌入器，并表明它们优于BM25和监督式基于Transformer的模型。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [301] [How Well Do LLMs Predict Prerequisite Skills? Zero-Shot Comparison to Expert-Defined Concepts](https://arxiv.org/abs/2507.18479)
> *大型语言模型预测先决技能的能力如何？与专家定义概念的零样本比较*

*Ngoc Luyen Le, Marie-Hélène Abel* | **Category: cs.IR** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 先决技能, 零样本学习, ESCO-PrereqSkill, 技能建模

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型在零样本设置下预测先决技能的能力，发现某些LLM（如LLaMA4-Maverick、Claude-3-7-Sonnet和Qwen2-72B）能生成与专家标注高度一致的预测，表明LLM在可扩展的先决技能建模方面具有巨大潜力。

**AI_Comments:** 该论文的创新之处在于首次系统性地评估了LLM在零样本设置下预测先决技能的能力，并构建了一个新的基准数据集。其重要性在于为解决教育领域中技能关系维护的规模化挑战提供了有前景的AI驱动解决方案。研究结果令人鼓舞，但未来的工作可以探索多模态信息的使用或更复杂的推理任务。

<details>
  <summary>Details</summary>

**Motivation:** 先决技能对于有效的学习、评估和技能差距分析至关重要，但传统上由领域专家维护这些关系成本高昂且难以扩展。本研究旨在探讨大型语言模型（LLMs）是否能在零样本设置下预测先决技能，从而提供一种可扩展的解决方案。

**Method:** 研究引入了ESCO-PrereqSkill基准数据集，该数据集包含3,196项技能及其专家定义的先决条件链接。采用标准化提示策略，评估了包括GPT-4、Claude 3、Gemini、LLaMA 4、Qwen2和DeepSeek在内的13个最先进的LLM，评估指标包括语义相似度、BERTScore和推理延迟。

**Result:** 结果显示，LLaMA4-Maverick、Claude-3-7-Sonnet和Qwen2-72B等模型生成的预测与专家标注的真实情况高度一致，在没有监督的情况下展示出强大的语义推理能力。

**Conclusion:** 研究结果突出了大型语言模型在支持可扩展的先决技能建模方面的潜力，可应用于个性化学习、智能辅导和基于技能的推荐系统。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在零样本设置下预测先决技能的潜力，以解决传统专家维护成本高昂且难以扩展的问题。通过构建包含3,196项技能及其专家定义链接的ESCO-PrereqSkill基准数据集，并评估13个主流LLM，研究发现LLaMA4-Maverick、Claude-3-7-Sonnet和Qwen2-72B等模型能生成与专家标注高度一致的预测，展示了强大的语义推理能力。这表明LLMs在个性化学习和智能辅导等领域的可扩展先决技能建模方面具有广阔前景。

> **摘要翻译:** 先决技能——掌握更高级概念之前所需的基础能力——对于支持有效的学习、评估和技能差距分析至关重要。传统上由领域专家策划的这些关系维护成本高昂且难以扩展。本文研究了大型语言模型（LLMs）是否可以在零样本设置下预测先决技能，仅使用自然语言描述，无需针对特定任务进行微调。我们引入了ESCO-PrereqSkill，一个从ESCO分类法构建的基准数据集，包含3,196项技能及其专家定义的先决条件链接。使用标准化的提示策略，我们评估了13个最先进的LLM，包括GPT-4、Claude 3、Gemini、LLaMA 4、Qwen2和DeepSeek，评估指标包括语义相似度、BERTScore和推理延迟。我们的结果表明，LLaMA4-Maverick、Claude-3-7-Sonnet和Qwen2-72B等模型生成的预测与专家真值高度一致，在没有监督的情况下展示了强大的语义推理能力。这些发现突出了LLM在个性化学习、智能辅导和基于技能的推荐系统等应用中支持可扩展的先决技能建模的潜力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [331] [The Best is Yet to Come: Graph Convolution in the Testing Phase for Multimodal Recommendation](https://arxiv.org/abs/2507.18489)
> *最好的还在后头：多模态推荐中测试阶段的图卷积*

*Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Edith C. H. Ngai* | **Category: cs.IR** | **Updated: 2025-07-24**

**Keywords:** 图卷积网络, 多模态推荐, 测试阶段, 效率, 可扩展性

**Comment:** Accepted by MM 2025

> **TL;DR:** FastMMRec 提出在多模态推荐中仅在测试阶段使用图卷积，以提高效率、可扩展性并解决模态隔离问题，同时保持性能优势。

**AI_Comments:** 这篇论文的创新点在于颠覆了传统GCNs在训练阶段应用的范式，提出在测试阶段进行图卷积，这对于解决多模态推荐中GCNs的效率和可扩展性问题具有重要意义。这种方法可能为未来推荐系统的设计提供新的思路，尤其是在资源受限或需要快速部署的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 图卷积网络（GCNs）在推荐系统训练中的效率和可扩展性是关键挑战，尤其在多模态推荐（MMRec）中，训练GCNs会带来高昂的时间和空间成本，并加剧不同模态之间的差距，导致推荐准确性不佳。研究指出，在训练阶段使用GCNs可能创建无益甚至有害的配对，并隔离不同模态。

**Method:** 本文提出了FastMMRec，一个高效的多模态推荐框架，其核心在于仅在测试阶段部署图卷积，从而避免在训练阶段使用GCNs。

**Result:** 实验表明，仅在测试阶段采用GCNs显著提高了模型的效率和可扩展性，并缓解了训练阶段GCNs导致的模态隔离问题。在三个公共数据集上的广泛实验一致证明了FastMMRec相对于竞争基线的性能优势，同时实现了高效率和可扩展性。

**Conclusion:** 在多模态推荐中，将图卷积应用于测试阶段而非训练阶段，能够显著提升推荐系统的效率和可扩展性，并有效解决模态隔离问题，同时保持甚至超越现有方法的性能。

> **ai_Abstract:** 本文针对多模态推荐系统中图卷积网络（GCNs）在训练阶段存在的效率、可扩展性低下以及模态隔离问题，提出了一种名为FastMMRec的新框架。FastMMRec的核心创新在于将图卷积的应用限制在测试阶段，从而避免了训练阶段的复杂性和负面影响。实验结果表明，这种方法显著提升了模型的效率和可扩展性，有效缓解了模态隔离，并且在性能上优于现有基线。

> **摘要翻译:** 图卷积网络（GCNs）在推荐系统训练中的效率和可扩展性仍然是关键挑战，阻碍了它们在实际场景中的部署。在多模态推荐（MMRec）领域，训练GCNs需要更昂贵的时间和空间成本，并加剧了不同模态之间的差距，导致次优的推荐准确性。本文批判性地指出，在MMRec训练阶段采用GCNs存在固有的挑战，揭示了GCNs在模型优化过程中不可避免地会创建无益甚至有害的配对，并隔离不同模态。为此，我们提出了FastMMRec，一个高效的多模态推荐框架，该框架仅在测试阶段部署图卷积，从而绕过了在训练阶段使用它们。我们证明，仅在测试阶段采用GCNs显著提高了模型的效率和可扩展性，同时缓解了在训练阶段使用GCNs通常导致的模态隔离问题。我们在三个公共数据集上进行了广泛的实验，一致证明了FastMMRec相对于竞争基线的性能优势，同时实现了效率和可扩展性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [364] [Transform Before You Query: A Privacy-Preserving Approach for Vector Retrieval with Embedding Space Alignment](https://arxiv.org/abs/2507.18518)
> *查询前转换：一种基于嵌入空间对齐的隐私保护向量检索方法*

*Ruiqi He, Zekun Fei, Jiaqi Li, Xinyuan Zhu, Biao Yi, Siyi Lv, Weijie Liu, Zheli Liu* | **Category: cs.IR** | **Updated: 2025-07-24**

**Keywords:** 隐私保护, 向量检索, 嵌入空间对齐, STEER, 向量数据库

**Comment:** 

> **TL;DR:** STEER是一种隐私保护向量检索框架，通过利用不同嵌入模型语义空间之间的对齐关系，生成近似查询嵌入，从而在不修改现有向量数据库服务器的情况下，保护敏感查询文本的隐私，同时保持检索准确性。

**AI_Comments:** STEER的创新之处在于其“查询前转换”的理念，即在将查询发送到VDB之前对其进行隐私保护处理，而无需修改VDB服务器。这对于现有VDB服务的广泛应用具有重要意义，因为它提供了一种实用的隐私增强方案，而不会引入额外的部署复杂性。其在保护隐私的同时保持高检索准确率的成果，使其成为敏感领域向量检索的有力候选。

<details>
  <summary>Details</summary>

**Motivation:** 当前的向量数据库（VDB）服务提供商大多使用专有黑盒模型，用户被迫通过API向其暴露原始查询文本以获取向量检索服务。如果查询文本涉及金融或医疗领域的机密记录，这种机制将不可避免地导致用户敏感信息的关键泄露。

**Method:** 本文引入了STEER（Secure Transformed Embedding Vector Retrieval）框架。STEER利用不同嵌入模型语义空间之间的对齐关系，推导出查询文本的近似嵌入。它使用这些近似嵌入在原始VDB中执行检索，且无需修改服务器端。

**Result:** STEER有效保护了查询文本隐私，同时保持了检索准确性。即使近似嵌入是专有模型嵌入的近似值，它们仍能阻止提供商通过嵌入反演攻击（EIAs）恢复查询文本。实验结果显示，STEER的Recall@100下降不到5%。在数百万条目文本语料库中搜索时，STEER的Recall@20准确率比现有基线高20%。

**Conclusion:** STEER框架成功地在不牺牲检索准确性的前提下，解决了向量检索中的隐私泄露问题，并通过生成近似嵌入有效保护了用户敏感查询文本的隐私。

> **ai_Abstract:** 本文提出了STEER框架，旨在解决向量数据库查询中敏感信息泄露的问题。通过利用不同嵌入模型语义空间的对齐关系，STEER生成查询文本的近似嵌入，并在不修改现有VDB服务器的情况下进行检索。实验证明，STEER在保护用户隐私的同时，能有效维持高检索准确率，甚至在某些情况下优于现有基线。

> **摘要翻译:** 向量数据库（VDB）可以高效地索引和搜索非结构化数据中的高维向量嵌入，这对于生成式AI和推荐系统等现代AI应用中必不可少的快速语义相似性搜索至关重要。由于当前的VDB服务提供商主要使用专有黑盒模型，用户被迫通过API向其暴露原始查询文本以获取向量检索服务。因此，如果查询文本涉及金融或医疗领域的机密记录，这种机制将不可避免地导致用户敏感信息的关键泄露。为了解决这个问题，我们引入了STEER（安全转换嵌入向量检索），一个隐私向量检索框架，它利用不同嵌入模型的语义空间之间的对齐关系来推导查询文本的近似嵌入。STEER使用原始VDB中的近似嵌入执行检索，并且不需要对服务器端进行任何修改。我们的理论和实验分析表明，STEER有效地保护了查询文本隐私，同时保持了检索准确性。尽管近似嵌入是专有模型嵌入的近似值，它们仍然可以防止提供商通过嵌入反演攻击（EIAs）恢复查询文本。大量的实验结果表明，STEER的Recall@100基本可以实现小于5%的下降。此外，即使在数百万条目的文本语料库中进行搜索时，STEER的Recall@20准确率也比现有基线高20%。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [400] [Neural Machine Unranking](https://arxiv.org/abs/2408.05330)
> *神经机器解排序*

*Jingrui Hou, Axel Finke, Georgina Cosma* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 机器遗忘, 神经信息检索, 数据隐私, 解排序, 对比学习

**Comment:** 

> **TL;DR:** 该论文引入了神经机器解排序（NuMuR）这一新任务，旨在解决神经信息检索系统中的数据隐私和选择性信息删除问题。针对现有方法在非归一化分数和纠缠数据场景下的不足，提出了一种名为CoCoL的双目标框架，通过对比损失和一致性损失实现了有效的数据遗忘，同时最大限度地减少了对保留和泛化性能的影响。

**AI_Comments:** 该论文创新性地将机器遗忘的概念引入到神经信息检索领域，提出了“神经机器解排序”这一新任务，填补了该领域的空白。其提出的CoCoL框架通过双目标损失，巧妙地解决了神经排序器输出特性和数据纠缠带来的挑战，在保证遗忘效果的同时，有效维持了系统对保留数据的性能和泛化能力，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机源于神经信息检索（IR）系统中对数据隐私合规性日益增长的需求以及选择性信息删除的必要性。现有的机器遗忘方法主要针对分类任务设计，不适用于神经IR系统，因为神经排序器输出的是非归一化的相关性分数，且在查询和文档同时出现在遗忘集和保留集的纠缠数据场景下，现有方法可能导致保留性能下降。

**Method:** 为解决上述问题，论文提出了一个名为“对比和一致性损失”（Contrastive and Consistent Loss, CoCoL）的双目标框架。CoCoL包含两部分：1) 对比损失，旨在降低遗忘集上的相关性分数，同时保持纠缠样本的性能；2) 一致性损失，用于保持保留集上的准确性。

**Result:** 在MS MARCO和TREC CAR数据集上，通过四种不同的神经IR模型进行的广泛实验表明，CoCoL在实现显著遗忘的同时，对保留和泛化性能的损失最小。该方法比现有技术能更有效、更可控地实现数据删除。

**Conclusion:** 该论文提出的方法能够比现有技术更有效、更可控地实现数据删除，解决了神经信息检索中机器遗忘的关键挑战。

> **ai_Abstract:** 该论文引入了神经机器解排序（NuMuR）这一新任务，旨在解决神经信息检索系统中的数据隐私合规和选择性信息删除问题。针对现有遗忘方法在非归一化分数和纠缠数据场景下的局限性，作者提出了双目标框架CoCoL。CoCoL通过对比损失降低遗忘集相关性并保持纠缠样本性能，同时通过一致性损失维护保留集准确性。实验证明，CoCoL在实现显著遗忘的同时，对保留和泛化性能的影响最小，并提供了比现有技术更有效的数据删除能力。

> **摘要翻译:** 我们解决了神经信息检索（IR）中的机器遗忘问题，引入了一项名为神经机器解排序（NuMuR）的新任务。这项任务的提出是由于神经IR系统中对数据隐私合规性和选择性信息删除的需求日益增长。现有的任务或模型无关的遗忘方法，主要为分类任务设计，对于NuMuR来说并非最优，原因在于两个核心挑战：（1）神经排序器输出的是未归一化的相关性分数而非概率分布，这限制了传统师生蒸馏框架的有效性；（2）纠缠数据场景，即查询和文档同时出现在遗忘集和保留集中，可能导致现有方法的保留性能下降。为了解决这些问题，我们提出了一种双目标框架：对比和一致性损失（CoCoL）。CoCoL包括（1）一种对比损失，用于降低遗忘集上的相关性分数，同时保持纠缠样本的性能；（2）一种一致性损失，用于保持保留集上的准确性。在MS MARCO和TREC CAR数据集上，通过四种神经IR模型进行的广泛实验表明，CoCoL在实现大量遗忘的同时，保留和泛化性能损失最小。我们的方法比现有技术能更有效、更可控地实现数据删除。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [442] [Neural Corrective Machine Unranking](https://arxiv.org/abs/2411.08562)
> *神经纠正机器降级*

*Jingrui Hou, Axel Finke, Georgina Cosma* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 机器遗忘, 信息检索, 神经IR, 纠正性降级, 蒸馏

**Comment:** submitted to Information Sciences

> **TL;DR:** 提出了一种名为CuRD的新型框架，用于在不损害检索效果和暴露删除操作的情况下，对神经信息检索系统进行机器遗忘。

**AI_Comments:** 这篇论文通过引入“纠正性降级”和CuRD框架，创新性地解决了神经IR中机器遗忘的复杂问题。其独特之处在于不仅关注数据的移除，更强调通过引入替代文档来维护排序完整性和用户体验，有效避免了传统遗忘方法可能带来的性能下降和隐私泄露风险。师生蒸馏范式也使其在实际应用中具有较高的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器遗忘方法应用于神经信息检索系统时，可能会损害检索效率或因从检索结果中删除特定项目而无意中暴露遗忘操作，需要一种既能移除数据又能保持模型性能的方法。

**Method:** 形式化了“纠正性降级”（corrective unranking），通过整合替代文档来保持排序完整性，并提出了一个新颖的师生框架——纠正性降级蒸馏（CuRD）。CuRD通过调整模型使被遗忘样本的相关性得分模仿低排名、不可检索样本的得分来实现遗忘；通过微调替代样本的相关性得分以匹配被遗忘样本来实现纠正；并努力保持对非目标遗忘样本的性能。

**Result:** 在MS MARCO和TREC CAR数据集上，使用四种神经信息检索模型（BERTcat, BERTdot, ColBERT, PARADE）进行了评估。实验表明，CuRD在遗忘和纠正方面优于七种最先进的基线方法，同时保持了模型保留和泛化能力。

**Conclusion:** CuRD框架有效解决了神经信息检索系统中机器遗忘的挑战，实现了高效的遗忘和纠正，同时保持了系统的整体性能和隐私。

> **ai_Abstract:** 这篇论文提出了一种名为“纠正性降级”的新范式，旨在解决神经信息检索系统中机器遗忘的挑战，即在移除特定数据的同时维护检索效果和避免泄露遗忘行为。为此，作者提出了一个创新的师生框架——纠正性降级蒸馏（CuRD）。CuRD通过调整被遗忘样本的相关性得分、微调替代样本得分以及保持非遗忘样本性能来实现遗忘、纠正和性能保留。实验结果表明，CuRD在遗忘和纠正方面显著优于现有基线方法，同时保持了模型的泛化能力。

> **摘要翻译:** 神经信息检索（IR）系统中的机器遗忘要求在移除特定数据的同时保持模型性能。将现有机器遗忘方法应用于IR可能会损害检索效率，或由于从呈现给用户的检索结果中移除了特定项目而无意中暴露遗忘操作。我们形式化了纠正性降级，通过整合替代文档来保持排序完整性，从而扩展了（神经）IR语境下的机器遗忘，并为这项任务提出了一种新颖的师生框架——纠正性降级蒸馏（CuRD）。CuRD（1）通过调整（训练过的）神经IR模型，使其对将被遗忘样本的输出相关性得分模仿低排名、不可检索样本的得分，从而促进遗忘；（2）通过微调替代样本的相关性得分使其与相应的将被遗忘样本的得分紧密匹配，从而实现纠正；（3）力求保持对非目标遗忘样本的性能。我们在MS MARCO和TREC CAR数据集上，使用四种神经IR模型（BERTcat、BERTdot、ColBERT、PARADE）评估了CuRD。对训练数据集中遗忘集大小从1%到20%的实验表明，CuRD在遗忘和纠正方面优于七种最先进的基线方法，同时保持了模型保留和泛化能力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [484] [AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark](https://arxiv.org/abs/2412.13102)
> *AIR-Bench：自动化异构信息检索基准*

*Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 信息检索, 评估基准, 大型语言模型, 自动化, 异构

**Comment:** 32 pages, 6 figures; Accepted to ACL 2025 Main

> **TL;DR:** AIR-Bench是一个自动化、异构且动态的信息检索基准，通过大型语言模型自动生成测试数据，以解决现有基准在新兴领域评估中的局限性。

**AI_Comments:** AIR-Bench的创新之处在于其自动化、异构和动态的数据生成范式，这显著降低了创建和维护IR评估基准的成本和工作量。通过利用大型语言模型，它能够快速适应新兴领域和语言，解决了传统人工标注基准的痛点。其与人工标注数据的一致性验证了其可靠性，对于推动信息检索模型在多样化场景下的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的信息检索（IR）基准依赖预定义领域和人工标注数据，在评估新兴领域时面临成本和效率方面的限制，无法有效满足评估需求。

**Method:** 该论文提出了自动化异构信息检索基准（AIR-Bench）。AIR-Bench通过大型语言模型（LLMs）自动生成测试数据，无需人工干预。它开发了一个可靠且鲁棒的数据生成管道，基于真实世界的语料库自动创建多样化和高质量的评估数据集。该基准具有自动化、异构（涵盖不同任务、领域和语言）和动态（领域和语言持续扩充）的特点。

**Result:** AIR-Bench生成的测试数据与人工标注的测试数据高度一致。

**Conclusion:** AIR-Bench是一个可靠的、可用于评估信息检索模型的基准。

> **ai_Abstract:** 该论文提出了AIR-Bench，一个自动化、异构且动态的信息检索基准，旨在解决现有IR基准在评估新兴领域时面临的局限性。AIR-Bench利用大型语言模型自动生成多样化且高质量的测试数据，涵盖不同任务、领域和语言，并能持续扩展。研究表明，AIR-Bench生成的测试数据与人工标注数据保持良好的一致性，证明了其作为可靠IR模型评估工具的潜力。

> **摘要翻译:** 评估在信息检索（IR）模型的发展中起着至关重要的作用。然而，当前基于预定义领域和人工标注数据的基准在解决新兴领域的评估需求方面面临成本和效率上的限制。为了应对这一挑战，我们提出了自动化异构信息检索基准（AIR-Bench）。AIR-Bench具有三个关键特征：1）自动化。AIR-Bench中的测试数据由大型语言模型（LLMs）自动生成，无需人工干预。2）异构。AIR-Bench中的测试数据是针对多样化的任务、领域和语言生成的。3）动态。AIR-Bench涵盖的领域和语言不断增加，以为社区开发者提供一个日益全面的评估基准。我们开发了一个可靠且鲁棒的数据生成管道，以基于真实世界的语料库自动创建多样化和高质量的评估数据集。我们的研究结果表明，AIR-Bench中生成的测试数据与人工标注的测试数据高度一致，这使得AIR-Bench成为一个可靠的IR模型评估基准。AIR-Bench的资源已在https://github.com/AIR-Bench/AIR-Bench公开。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [520] [OneRec Technical Report](https://arxiv.org/abs/2506.13695)
> *OneRec 技术报告*

*Guorui Zhou, Jiaxin Deng, Jinghao Zhang, Kuo Cai, Lejian Ren, Qiang Luo, Qianqian Wang, Qigen Hu, Rui Huang, Shiyao Wang, Weifeng Ding, Wuchao Li, Xinchen Luo, Xingmei Wang, Zexuan Cheng, Zixing Zhang, Bin Zhang, Boxuan Wang, Chaoyi Ma, Chengru Song, Chenhui Wang, Di Wang, Dongxue Meng, Fan Yang, Fangyu Zhang, Feng Jiang, Fuxing Zhang, Gang Wang, Guowang Zhang, Han Li, Hengrui Hu, Hezheng Lin, Hongtao Cheng, Hongyang Cao, Huanjie Wang, Jiaming Huang, Jiapeng Chen, Jiaqiang Liu, Jinghui Jia, Kun Gai, Lantao Hu, Liang Zeng, Liao Yu, Qiang Wang, Qidong Zhou, Shengzhe Wang, Shihui He, Shuang Yang, Shujie Yang, Sui Huang, Tao Wu, Tiantian He, Tingting Gao, Wei Yuan, Xiao Liang, Xiaoxiao Xu, Xugang Liu, Yan Wang, Yi Wang, Yiwu Liu, Yue Song, Yufei Zhang, Yunfan Wu, Yunfeng Zhao, Zhanyu Liu* | **Category: cs.IR** | **Updated: 2025-07-24**

**Keywords:** 推荐系统, 端到端, 生成式模型, 强化学习, 基础设施优化

**Comment:** Authors are listed alphabetically by their first name

> **TL;DR:** OneRec通过端到端生成式方法重塑推荐系统，显著提升性能并降低成本。

**AI_Comments:** OneRec的创新之处在于其采用端到端生成式方法重塑了推荐系统，这与传统的多阶段级联架构形成鲜明对比，解决了长期存在的计算碎片化和优化不一致问题。其将推荐系统的优化水平提升到与LLM社区相近的MFU水平，并显著降低了运营成本，具有重要的工程和经济价值。同时，它展示了强化学习在推荐系统中的巨大潜力，并提供了宝贵的实践经验，对未来推荐系统的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统依赖多阶段级联架构，导致计算碎片化和优化不一致，阻碍了人工智能社区的关键突破性技术在推荐场景中的有效应用。

**Method:** 本文提出了OneRec，通过端到端生成式方法重塑推荐系统。方法包括：将推荐模型计算FLOPs提升10倍并发现缩放定律；利用强化学习技术；通过基础设施优化，提升训练和推理的MFU，并大幅降低通信和存储开销。

**Result:** OneRec将当前推荐模型的计算FLOPs提升了10倍；在训练和推理期间，旗舰GPU上的模型FLOPs利用率（MFU）分别达到23.7%和28.8%；运营成本仅为传统推荐管道的10.6%；在快手/快手极速版APP中，处理了25%的总查询量，并分别将整体APP停留时间提升了0.54%和1.24%；7天生命周期等关键指标显著增加。

**Conclusion:** OneRec通过端到端生成式方法成功重塑了推荐系统，显著提升了性能和效率，并在大规模生产环境中取得了显著的实际效果，同时提供了宝贵的开发、优化和维护经验。

> **ai_Abstract:** 本技术报告提出了OneRec，一个通过端到端生成式方法重塑推荐系统的新框架，以解决现有系统计算碎片化和优化不一致的问题。OneRec显著提升了模型计算能力（FLOPs提升10倍），优化了基础设施以提高GPU利用率和降低运营成本（降至10.6%），并成功整合了强化学习。其在快手/快手极速版APP的实际部署表明，OneRec有效提升了用户参与度（App停留时间分别提升0.54%和1.24%）和长期用户价值，证明了其在大规模推荐场景中的优越性和实用性。

> **摘要翻译:** 推荐系统多年来已广泛应用于各种大规模面向用户的平台。然而，与人工智能社区的快速发展相比，推荐系统近年来并未取得突破。例如，它们仍然依赖于多阶段级联架构而非端到端方法，这导致计算碎片化和优化不一致，阻碍了人工智能社区的关键突破性技术在推荐场景中的有效应用。
为了解决这些问题，我们提出了OneRec，它通过端到端生成式方法重塑了推荐系统，并取得了可喜的成果。首先，我们将当前推荐模型的计算FLOPs提升了10倍，并在一定范围内确定了推荐的缩放定律。其次，以前难以应用于优化推荐的强化学习技术，在此框架中显示出巨大的潜力。最后，通过基础设施优化，我们在训练和推理期间在旗舰GPU上分别实现了23.7%和28.8%的模型FLOPs利用率（MFU），这与大型语言模型（LLM）社区的水平非常接近。这种架构显著减少了通信和存储开销，导致运营成本仅为传统推荐管道的10.6%。部署在快手/快手极速版APP中，它处理了总查询量（QPS）的25%，分别将整体APP停留时间提升了0.54%和1.24%。此外，我们观察到7天生命周期等指标显著增加，这是衡量推荐体验的关键指标。我们还提供了从开发、优化和维护具有显著实际影响的生产规模推荐系统中获得的实践经验和见解。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [555] [RMIT-ADM+S at the SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.14516)
> *RMIT-ADM+S 在 SIGIR 2025 LiveRAG 挑战赛中的表现*

*Kun Ran, Shuoqi Sun, Khoi Nguyen Dinh Anh, Damiano Spina, Oleg Zendel* | **Category: cs.IR** | **Updated: 2025-07-23**

**Keywords:** G-RAG, 检索增强生成, LLM, SIGIR 2025 LiveRAG 挑战赛, 重排序

**Comment:** SIGIR 2025 LiveRAG winning system

> **TL;DR:** 本文介绍了 RMIT-ADM+S 团队在 SIGIR 2025 LiveRAG 挑战赛中夺冠的系统，该系统采用 G-RAG 方法，结合假设答案生成和基于 LLM 的重排序，并在手动评估中取得了最高分。

**AI_Comments:** 本文展示了 G-RAG 方法在检索增强生成任务中的有效性，通过结合假设答案生成和 LLM 重排序，显著提升了系统性能。其系统性评估方法，特别是使用“网格点”和 N-way ANOVA 进行受控比较，为未来的 RAG 系统设计提供了宝贵的经验。在知名挑战赛中获得第一名，验证了其方法的创新性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文介绍了 RMIT-ADM+S 团队在 SIGIR 2025 LiveRAG 挑战赛中获胜的系统，旨在展示其 G-RAG 方法及其设计选择。

**Method:** 该方法名为 G-RAG（Generation-Retrieval-Augmented Generation），它在检索阶段使用生成的假设答案以及原始问题。G-RAG 还包含一个在最终答案生成之前的基于点式大型语言模型（LLM）的重排序步骤。系统设计选择通过使用“网格点”方法和 N-way ANOVA 进行系统评估，对包括查询变体生成、问题分解、排名融合策略和答案生成提示技术在内的多种配置进行了受控比较。

**Result:** 提交的系统基于人工评估的覆盖率、相关性和质量得分的聚合，获得了最高的 Borda 分数，在 SIGIR 2025 LiveRAG 挑战赛中排名第一。

**Conclusion:** RMIT-ADM+S 团队的 G-RAG 系统在 SIGIR 2025 LiveRAG 挑战赛中表现出色并获得冠军，证明了其方法在检索增强生成任务中的有效性。

> **ai_Abstract:** 本文介绍了 RMIT-ADM+S 团队在 SIGIR 2025 LiveRAG 挑战赛中获胜的系统。该系统采用 G-RAG 方法，通过生成假设答案辅助检索，并结合基于 LLM 的重排序。研究详细阐述了系统架构和设计原理，并利用网格点方法和 N-way ANOVA 对不同配置进行了系统性评估。最终，该系统在人工评估中取得了最高的 Borda 分数，赢得了挑战赛。

> **摘要翻译:** 本文介绍了 RMIT-ADM+S 团队在 SIGIR 2025 LiveRAG 挑战赛中夺冠的系统。我们的生成-检索-增强生成 (G-RAG) 方法生成一个假设答案，该答案在检索阶段与原始问题一起使用。G-RAG 还在最终答案生成之前，整合了一个基于点式大型语言模型 (LLM) 的重排序步骤。我们描述了系统架构及其设计选择背后的原理。特别是，使用“网格点”方法和 N-way ANOVA 进行的系统评估，能够对多种配置进行受控比较，包括查询变体生成、问题分解、排名融合策略和答案生成提示技术。提交的系统根据人工评估的覆盖率、相关性和质量得分的聚合，获得了最高的 Borda 分数，在 SIGIR 2025 LiveRAG 挑战赛中排名第一。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [596] [An Ecosystem for Ontology Interoperability](https://arxiv.org/abs/2507.12311)
> *本体互操作性的生态系统*

*Zhangcheng Qiang* | **Category: cs.IR** | **Updated: 2025-07-23**

**Keywords:** 本体互操作性, 知识图谱, 本体设计模式, 本体匹配, 本体版本控制

**Comment:** 5 pages, 8 figures

> **TL;DR:** 本文提出了一个本体互操作性生态系统，通过在本体工程生命周期的不同阶段采用本体设计模式、本体匹配与版本控制以及本体兼容知识图谱，以解决知识图谱中本体互操作性难题。

**AI_Comments:** 该论文提出了一种系统化的方法来解决本体互操作性这一关键问题，其创新之处在于将多种先进的语义技术整合到一个统一的生态系统中，并覆盖了本体工程的整个生命周期。这种集成方法有望显著提升本体在实际应用中的可用性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 本体互操作性是限制本体在知识图谱中使用的复杂问题。不同本体之间的概念冲突和重叠，使得为下游任务设计、开发和部署可互操作的本体变得困难。

**Method:** 本文提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种先进的语义技术：设计阶段的本体设计模式（ODPs）、开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的本体兼容知识图谱（OCKGs）。

**Result:** 通过在建筑领域传感器观测的案例研究，验证了所提出生态系统的有用性。

**Conclusion:** 所提出的本体互操作性生态系统，通过在本体工程生命周期不同阶段应用特定的语义技术，能够有效提升本体在实际应用中的互操作性。

> **ai_Abstract:** 本文针对知识图谱中本体互操作性受限的问题，提出了一个本体互操作性生态系统。该系统在本体工程生命周期的设计、开发和部署阶段分别整合了本体设计模式、本体匹配与版本控制以及本体兼容知识图谱这三种先进语义技术，旨在提高本体在实际应用中的互操作性。通过建筑领域传感器观测的案例研究验证了其有效性。

> **摘要翻译:** 本体互操作性是限制本体在知识图谱（KGs）中使用的复杂问题之一。具有冲突和重叠概念的不同本体使得为下游任务设计、开发和部署可互操作的本体变得困难。我们提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种最先进的语义技术：设计阶段的本体设计模式（ODPs）、开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的本体兼容知识图谱（OCKGs），以在实际应用中实现更好的本体互操作性。建筑领域传感器观测的案例研究验证了所提出生态系统的有用性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [634] [RankMixer: Scaling Up Ranking Models in Industrial Recommenders](https://arxiv.org/abs/2507.15551)
> *RankMixer：工业推荐系统中排序模型的扩展*

*Jie Zhu, Zhifang Fan, Xiaoxie Zhu, Yuchen Jiang, Hangyu Wang, Xintian Han, Haoran Ding, Xinmin Wang, Wenlin Zhao, Zhen Gong, Huizhi Yang, Zheng Chai, Zhe Chen, Yuchao Zheng, Qiwei Chen, Feng Zhang, Xun Zhou, Peng Xu, Xiao Yang, Di Wu, Zuotao Liu* | **Category: cs.IR** | **Updated: 2025-07-24**

**Keywords:** RankMixer, 推荐系统, 排序模型, 模型扩展, GPU利用率

**Comment:** 

> **TL;DR:** RankMixer是一种针对工业推荐系统的硬件感知模型，通过替换自注意力机制和引入Per-token FFNs，显著提升了模型效率和可扩展性，并在生产环境中实现了参数量100倍的增长而推理延迟不变，同时提升了用户活跃度和应用使用时长。

**AI_Comments:** RankMixer的创新之处在于其硬件感知设计，特别是在工业推荐系统这种对延迟和QPS要求极高的场景下。通过替换Transformer的自注意力机制并优化GPU利用率，它有效解决了传统特征交叉模块的瓶颈。其在实际生产环境中的大规模部署及其带来的显著业务提升（用户活跃度和使用时长）证明了其重要性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的最新进展激发了人们对扩展推荐系统的兴趣，但仍存在两个实际障碍：1. 工业推荐器上的训练和服务成本必须遵守严格的延迟限制和高QPS需求。2. 排序模型中大多数人工设计的特征交叉模块继承自CPU时代，未能充分利用现代GPU，导致模型浮点运算利用率（MFU）低和可扩展性差。

**Method:** 引入RankMixer，这是一种硬件感知的模型设计，旨在实现统一且可扩展的特征交互架构。RankMixer保留了Transformer的高并行性，同时用多头token混合模块替换了二次自注意力机制以提高效率。此外，RankMixer通过Per-token FFNs保持了对不同特征子空间和跨特征空间交互的建模。进一步将其扩展到十亿参数量，采用稀疏MoE变体以获得更高ROI。采用动态路由策略解决专家训练的不足和不平衡问题。

**Result:** 实验表明RankMixer在万亿规模生产数据集上具有卓越的扩展能力。通过用RankMixer替换以前多样化的手工低MFU模块，将模型MFU从4.5%提高到45%，并将排序模型参数量扩展了100倍，同时保持大致相同的推理延迟。通过在线A/B测试在推荐和广告两个核心应用场景中验证了RankMixer的通用性。最后，上线了10亿密集参数的RankMixer以服务全部流量，而没有增加服务成本，这使得用户活跃天数提高了0.3%，应用内总使用时长提高了1.08%。

**Conclusion:** RankMixer通过创新的硬件感知设计，成功解决了工业推荐系统中模型扩展性和效率的挑战，显著提升了模型性能和用户体验，同时有效控制了服务成本。

> **ai_Abstract:** 本文提出了RankMixer，一种针对工业推荐系统的硬件感知模型设计，旨在解决现有排序模型在GPU上的效率低下和可扩展性差的问题。RankMixer通过引入多头token混合模块替代传统自注意力，并结合Per-token FFNs，实现了高效的特征交互。通过扩展至稀疏MoE变体，模型达到了十亿参数规模。实验证明，RankMixer显著提升了模型MFU，实现了参数量100倍的扩展而推理延迟不变，并在生产环境中显著提升了用户活跃度和应用使用时长，展现了其卓越的扩展能力和通用性。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展激发了人们对扩展推荐系统的兴趣，但仍存在两个实际障碍。首先，工业推荐器上的训练和服务成本必须遵守严格的延迟限制和高QPS需求。其次，排序模型中大多数人工设计的特征交叉模块继承自CPU时代，未能充分利用现代GPU，导致模型浮点运算利用率（MFU）低和可扩展性差。我们引入了RankMixer，这是一种硬件感知的模型设计，旨在实现统一且可扩展的特征交互架构。RankMixer保留了Transformer的高并行性，同时用多头token混合模块替换了二次自注意力机制以提高效率。此外，RankMixer通过Per-token FFNs保持了对不同特征子空间和跨特征空间交互的建模。我们进一步将其扩展到十亿参数量，采用稀疏MoE变体以获得更高ROI。采用动态路由策略解决专家训练的不足和不平衡问题。实验表明RankMixer在万亿规模生产数据集上具有卓越的扩展能力。通过用RankMixer替换以前多样化的手工低MFU模块，我们将模型MFU从4.5%提高到45%，并将排序模型参数量扩展了100倍，同时保持大致相同的推理延迟。我们通过在线A/B测试在两个核心应用场景（推荐和广告）中验证了RankMixer的通用性。最后，我们上线了10亿密集参数的RankMixer以服务全部流量，而没有增加服务成本，这使得用户活跃天数提高了0.3%，应用内总使用时长提高了1.08%。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [124] [Neuromorphic Computing: A Theoretical Framework for Time, Space, and Energy Scaling](https://arxiv.org/abs/2507.17886)
> *神经拟态计算：时间、空间和能量扩展的理论框架*

*James B Aimone* | **Category: cs.NE, cs.AR, cs.DC** | **Updated: 2025-07-23**

**Keywords:** 神经拟态计算, 能量扩展, 稀疏算法, 理论框架, 冯·诺依曼架构

**Comment:** True pre-print; to be submitted at future date

> **TL;DR:** 本文提出了一个神经拟态计算的理论框架，解释了其作为通用可编程系统的潜力，并详细分析了其与传统系统在时间、空间和能量扩展方面的差异，指出其特别适用于稀疏和可扩展算法。

**AI_Comments:** 这篇论文的创新之处在于它为神经拟态计算提供了一个明确的理论框架，特别是精确定义了其能量扩展特性，并将其与传统计算架构进行了对比。这有助于理解NMC的独特优势和适用场景，不再仅仅将其视为“低功耗”的模糊概念，而是从更深层次的计算原理上揭示了其价值。它强调了NMC在处理特定类型（稀疏、可扩展）算法上的优势，这对于未来异构计算系统的设计和算法的适配具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经拟态计算（NMC）被视为传统冯·诺依曼架构（如CPU和GPU）的低功耗替代方案，但其计算价值一直难以精确定义。本文旨在解释NMC如何被视为通用且可编程的，并明确其计算价值。

**Method:** 本文通过理论分析，比较了神经拟态计算与传统系统在时间、空间和能量扩展方面的特性。

**Result:** 研究表明，神经拟态计算的时间和空间扩展与理论上无限处理器传统系统相当，但能量扩展显著不同。传统系统的能量随绝对算法功耗扩展，而神经拟态系统的能量随算法状态的导数扩展。这种独特特性使NMC非常适合不同于传统多核系统（如GPU）的算法类别，特别是可扩展和稀疏算法，如迭代优化和大规模采样（例如蒙特卡罗）。

**Conclusion:** 神经拟态计算凭借其独特的能量扩展特性，使其成为处理特定类型算法（尤其是稀疏和可扩展算法）的理想选择，与传统多核系统形成了互补。

> **ai_Abstract:** 这篇论文提出了一个关于神经拟态计算（NMC）的理论框架，旨在明确其作为低功耗通用可编程系统的计算价值。文章分析了NMC在时间、空间和能量扩展方面的特性，发现其时间与空间扩展与传统无限处理器系统相当，但在能量扩展上存在显著差异：NMC的能量消耗与算法状态的导数相关，而非传统系统的绝对算法功耗。这一特性使得NMC特别适用于处理稀疏、可扩展的算法，如迭代优化和大规模采样，与为密集数值应用优化的传统多核系统形成对比。

> **摘要翻译:** 神经拟态计算（NMC）越来越被视为传统冯·诺依曼架构（如中央处理器和图形处理器）的低功耗替代方案，然而其计算价值主张一直难以精确定义。在此，我们解释了NMC应如何被视为通用且可编程的，尽管它与传统的存储程序架构有很大不同。我们展示了NMC的时间和空间扩展与理论上无限处理器的传统系统相当，但能量扩展显著不同。具体来说，传统系统的能量随绝对算法功耗扩展，而神经拟态系统的能量随算法状态的导数扩展。NMC架构的独特特性使其非常适合与传统多核系统（如GPU）不同类别的算法，后者已针对线性代数等密集数值应用进行了优化。相比之下，NMC的独特特性使其非常适合活动与目标函数成比例的可扩展和稀疏算法，例如迭代优化和大规模采样（例如蒙特卡罗）。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [204] [Explicit Sign-Magnitude Encoders Enable Power-Efficient Multipliers](https://arxiv.org/abs/2507.18179)
> *显式符号-幅度编码器实现高能效乘法器*

*Felix Arnold, Maxence Bouvier, Ryan Amaudruz, Renzo Andri, Lukas Cavigelli* | **Category: cs.NE, cs.AR, cs.PF** | **Updated: 2025-07-24**

**Keywords:** 定点乘法器, 功耗效率, 符号-幅度编码, AI工作负载, 开关活动

**Comment:** Accepted and presented at the 34th International Workshop on Logic &
  Synthesis June 2025

> **TL;DR:** 通过将定点乘法器分解并利用符号-幅度编码，显著降低了功耗，尤其适用于AI工作负载。

**AI_Comments:** 这项工作创新性地通过将乘法器分解并引入显式符号-幅度编码器来解决定点乘法器的功耗问题，尤其针对AI工作负载中的特定输入特性。其重要性在于，在保持逻辑等效性的前提下实现了显著的功耗降低，这对于能效要求高的硬件设计至关重要。此外，结合开关活动驱动的优化方法进一步提升了效果，展示了在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在最大化定点乘法器单元的功耗效率，因为AI工作负载中常见输入值集中在零附近。

**Method:** 该方法将定点乘法器分解为子组件。首先，编码器块将操作数从补码转换为符号-幅度表示；接着，乘法器模块执行计算并将结果输出为原始格式。这两个组件被单独综合和优化，以利用符号-幅度编码的功耗效率，并确保计算格式不变。此外，还探讨了基于开关活动驱动的设计空间探索的综合优化方法。

**Result:** 在标准偏差为3.0的正态分布输入流下，4位乘法器设计在后综合仿真中显示，与不分解的综合相比，开关活动降低了高达12.9%。在取消兼容性限制且输入范围为-7到+7时，开关活动降低可达33%。此外，基于开关活动驱动的设计空间探索的综合优化方法可进一步提高5-10%的功耗效率。

**Conclusion:** 通过将定点乘法器分解并利用符号-幅度编码，可以显著提高乘法器的功耗效率，特别是在AI工作负载中常见的输入值集中在零附近的情况下，且能保持电路的逻辑等效性。

> **ai_Abstract:** 本文提出了一种通过将定点乘法器分解为编码器和乘法器模块来提高功耗效率的方法。编码器将补码操作数转换为符号-幅度表示，然后乘法器执行计算。这种分解允许利用符号-幅度编码的节能优势，且两个组件独立优化以保持兼容性。该方法在AI工作负载中常见的输入值集中在零附近时表现出显著的功耗节省，开关活动降低高达12.9%至33%。研究还表明，通过开关活动驱动的设计空间探索可以进一步优化功耗。

> **摘要翻译:** 这项工作提出了一种通过将定点乘法器单元分解为子组件来最大化其功耗效率的方法。首先，一个编码器块将操作数从补码转换为符号-幅度表示，然后乘法器模块执行计算并将结果以原始格式输出。这使得乘法可以利用符号-幅度编码的功耗效率。为了确保计算格式不被改变，这两个组件被单独综合和优化。我们的方法对于输入值集中在零附近（这在AI工作负载中很常见）的情况，带来了显著的功耗节省。在标准偏差为3.0的正态分布的真实输入流下，4位乘法器设计的后综合仿真显示，与不分解的综合相比，开关活动降低了高达12.9%。这些增益是在确保符合任何生产就绪系统的情况下实现的，因为整个电路保持逻辑等效。在取消兼容性限制且输入范围略小为-7到+7的情况下，开关活动降低可达33%。此外，我们还证明了基于开关活动驱动的设计空间探索的综合优化方法，与功耗无关的方法相比，可以进一步提高5-10%的功耗效率。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [271] [Contraction, Criticality, and Capacity: A Dynamical-Systems Perspective on Echo-State Networks](https://arxiv.org/abs/2507.18467)
> *收缩性、临界性与容量：回声状态网络的一个动力系统视角*

*Pradeep Singh, Lavanya Sankaranarayanan, Balasubramanian Raman* | **Category: cs.NE, nlin.CD, 68T07, 37M25, 37N30, 41A30, I.2.6; F.1.1; G.3** | **Updated: 2025-07-24**

**Keywords:** 回声状态网络, 动力系统, 渐逝记忆, 普适性, 临界性

**Comment:** 10 pages

> **TL;DR:** 本文从动力系统角度统一分析了回声状态网络（ESNs）的稳定性、记忆和表达能力，证明了其渐逝记忆特性和普适性，量化了计算资源，并建立了与皮层临界性的联系，为ESNs的设计提供了具体指导。

**AI_Comments:** 本文通过将泛函分析、随机吸引子理论和神经科学相结合，为回声状态网络提供了一个全面且统一的动力学系统理论框架，极大地深化了对ESNs工作原理的理解。其创新之处在于严谨地证明了ESNs的关键特性（如渐逝记忆和普适性），并将其计算资源与“混沌边缘”的动力学联系起来，这不仅具有重要的理论价值，也为ESNs的实际设计提供了具体的、可操作的指导原则，解释了其在实际应用中的高效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管回声状态网络（ESNs）在处理时间序列方面表现出色，但其稳定性、记忆和表达能力等基本问题在不同学科中仍存在碎片化的理解。

**Method:** 本文采用统一的动力系统处理方法，融合了泛函分析、随机吸引子理论和最新的神经科学发现。具体地，证明了回声状态特性与渐逝记忆特性的关系；使用Stone-Weierstrass策略证明了ESNs的普适性；通过记忆容量谱量化了计算资源；并将ESNs建模为斜积随机动力系统，建立了单点回溯吸引子的存在性。

**Result:** 研究证明，具有回声状态特性和全局Lipschitz动力学的ESNs必然具有渐逝记忆特性，并提供了代数测试方法。证明了ESNs在特定条件下对因果、时不变渐逝记忆滤波器具有普适性，并扩展到随机输入。量化了计算资源，展示了拓扑结构和泄露率如何重新分配延迟特定容量，并将其与“混沌边缘”的Lyapunov谱联系起来。建立了单点回溯吸引子的存在性，并推导了条件Lyapunov界限，提供了皮层临界性的严格类比。

**Conclusion:** 该分析为回声状态网络的设计提供了具体的指导原则（如谱半径、输入增益、激活函数选择），这些原则同时基于数学和神经科学。研究还阐明了为什么适度大小的储层在实践中常常能与完全训练的循环网络相媲美。

> **ai_Abstract:** 本文从动力系统角度对回声状态网络（ESNs）进行了统一的理论分析。研究证明了ESNs的洗出特性与渐逝记忆特性之间的关系，并提供了严格的代数测试。通过Stone-Weierstrass策略，证明了ESNs在处理时间序列时的普适性，甚至包括随机输入。此外，论文量化了ESNs的计算资源和记忆容量，并揭示了网络拓扑与临界状态的关系。这些理论成果为ESNs的实际设计提供了数学和神经科学双重依据，并解释了其在实践中表现优异的原因。

> **摘要翻译:** 回声状态网络（ESNs）提炼了一个关键的神经生物学洞见：丰富循环但固定的电路结合自适应线性读出，可以以卓越的效率转换时间流。然而，关于稳定性、记忆和表达能力的基本问题在不同学科中仍然是碎片化的。我们提出了一个统一的动力系统处理方法，它将泛函分析、随机吸引子理论和最新的神经科学发现编织在一起。首先，在紧凑的多变量输入字母表上，我们证明了回声状态特性（初始条件的洗出）与全局Lipschitz动力学必然产生渐逝记忆特性（对远端输入的几何遗忘）。严格的代数测试将激活特定的Lipschitz常数转化为经过认证的谱范数界限，涵盖了饱和和整流非线性。其次，采用Stone-Weierstrass策略，我们提供了一个简化的证明，即具有多项式储层和线性读出的ESNs在因果、时不变渐逝记忆滤波器的Banach空间中是稠密的，将普适性扩展到随机输入。第三，我们通过记忆容量谱量化计算资源，展示了拓扑结构和泄露率如何重新分配延迟特定容量，并将这些权衡与“混沌边缘”的Lyapunov谱联系起来。最后，将ESNs视为斜积随机动力系统，我们建立了单点回溯吸引子的存在性，并推导了条件Lyapunov界限，为皮层临界性提供了严格的类比。该分析产生了具体的、同时基于数学和神经科学的设计规则——谱半径、输入增益、激活选择——并阐明了为什么适度大小的储层在实践中常常能与完全训练的循环网络相媲美。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [47] [Energy-preserving continuous-stage partitioned Runge-Kutta methods](https://arxiv.org/abs/1808.02391)
> *能量守恒连续阶分段Runge-Kutta方法*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 能量守恒, 连续阶分段Runge-Kutta方法, 哈密顿系统, 数值积分, Butcher权重系数

**Comment:** The paper needs to be improved.

> **TL;DR:** 本文提出了用于哈密顿系统能量守恒积分的连续阶分段Runge-Kutta (csPRK) 方法，并推导了其能量守恒的充分条件，证明了该条件包含了现有方法的特例，并得到了构造高阶方法时某些系数必须为1的有趣结果，并通过数值实验验证了理论。

**AI_Comments:** 这项工作通过引入连续阶分段Runge-Kutta方法并推导其能量守恒条件，为哈密顿系统的数值积分提供了一种新的、可能更灵活的途径。发现特定系数必须为1是一个有趣的理论结果，可能简化高阶方法的构造或提供新的见解。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发用于哈密顿系统能量守恒积分的数值方法。

**Method:** 提出了连续阶分段Runge-Kutta (csPRK) 方法，推导了其能量守恒的充分条件，并利用简化阶条件和归一化移位Legendre多项式构造高阶方法。通过数值实验验证了理论结果。

**Result:** 导出了csPRK方法能量守恒的充分条件，该条件包含现有连续阶Runge-Kutta方法条件的特例。发现构造高阶能量守恒csPRK方法时，Butcher“权重”系数$B_\tau$和$\widehat{B}_\tau$必须等于1。获得了新的能量守恒积分器，并进行了数值实验验证。

**Conclusion:** 本文成功提出了能量守恒的csPRK方法，并推导了其能量守恒的条件，证明了该方法的有效性和在构造高阶方法时的特定性质。

> **ai_Abstract:** 本文介绍了一种新的连续阶分段Runge-Kutta (csPRK) 方法，用于哈密顿系统的能量守恒积分。研究导出了该方法能量守恒的充分条件，并指出此条件是现有连续阶Runge-Kutta方法条件的一种推广。特别地，研究发现，在构建高阶能量守恒csPRK方法时，通过结合阶条件简化假设和归一化移位Legendre多项式，某些关键的Butcher权重系数必须为1。通过具体示例和数值实验验证了这些理论发现。

> **摘要翻译:** 在本文中，我们提出了用于哈密顿系统能量守恒积分的连续阶分段Runge-Kutta (csPRK) 方法。导出了csPRK方法能量守恒的充分条件。结果表明，所提出的条件包含了现有能量守恒连续阶Runge-Kutta方法的条件作为特例。一个值得注意且有趣的结果是，当我们使用阶条件简化假设和归一化移位Legendre多项式来构造高阶能量守恒csPRK方法时，Butcher“权重”系数$B_\tau$和$\widehat{B}_\tau$都必须等于1。作为说明性示例，通过所提出的条件获得了新的能量守恒积分器，为了验证我们的理论结果，报告了一些数值实验。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [72] [Energy-preserving continuous-stage Runge-Kutta-Nyström methods](https://arxiv.org/abs/1808.08451)
> *能量守恒的连续阶段龙格-库塔-尼斯特朗方法*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 能量守恒, Runge-Kutta-Nyström, 二阶系统, 数值积分, 连续阶段

**Comment:** The paper needs to be improved.

> **TL;DR:** 本文开发了能量守恒的连续阶段Runge-Kutta-Nyström (csRKN) 方法，用于解决二阶系统，并给出了其能量守恒的充分条件。

**AI_Comments:** 这项研究通过引入能量守恒的连续阶段Runge-Kutta-Nyström方法，解决了传统数值积分器在处理二阶系统时不保留物理不变量的局限性。其创新之处在于提出并证明了能量守恒的充分条件，并揭示了与连续阶段分块Runge-Kutta方法的内在联系，对于提高复杂物理系统数值模拟的准确性和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多实际问题由二阶系统描述，这些系统具有能量、动量、角动量等重要不变量。然而，传统的数值积分器无法保持这些量，可能导致定性不正确的数值解。

**Method:** 本文致力于开发用于求解二阶系统的能量守恒连续阶段Runge-Kutta-Nyström (csRKN) 方法。提出了csRKN方法能量守恒的充分条件，并证明了所有满足这些充分条件的能量守恒csRKN方法本质上都可以由能量守恒连续阶段分块Runge-Kutta方法导出。

**Result:** 提出了能量守恒csRKN方法的充分条件，并证明了所有满足这些条件的能量守恒csRKN方法本质上可以由能量守恒连续阶段分块Runge-Kutta方法导出。提供了说明性示例并报告了相关的数值结果。

**Conclusion:** 本文成功开发了能量守恒的连续阶段Runge-Kutta-Nyström方法，并证明了其能量守恒的充分条件以及与能量守恒连续阶段分块Runge-Kutta方法的内在联系，从而为解决二阶系统的物理不变量保持问题提供了有效途径。

> **ai_Abstract:** 本文针对具有能量、动量等重要不变量的二阶系统，提出并开发了能量守恒的连续阶段Runge-Kutta-Nyström (csRKN) 方法。研究给出了csRKN方法能量守恒的充分条件，并证明了满足这些条件的能量守恒csRKN方法可由能量守恒连续阶段分块Runge-Kutta方法导出。通过示例和数值结果验证了方法的有效性。

> **摘要翻译:** 许多实际问题可以用二阶系统 $\ddot{q}=-M\nabla U(q)$ 来描述，其中人们特别强调一些具有明确物理意义的不变量，例如能量、动量、角动量等。然而，这些系统的传统数值积分器无法保持任何这些量，这可能导致定性不正确的数值解。本文关注开发用于求解二阶系统的能量守恒连续阶段龙格-库塔-尼斯特朗 (csRKN) 方法。提出了csRKN方法能量守恒的充分条件，并证明了所有满足这些充分条件的能量守恒csRKN方法本质上都可以由能量守恒连续阶段分块龙格-库塔方法导出。给出了一些说明性示例并报告了相关的数值结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [97] [Fast And Scalable FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices With Application to Linear Inverse Problems Governed by Autonomous Dynamical Systems](https://arxiv.org/abs/2407.13066)
> *快速可扩展的基于FFT的GPU加速分块三角Toeplitz矩阵算法及其在自治动力系统线性逆问题中的应用*

*Sreeram Venkat, Milinda Fernando, Stefan Henneking, Omar Ghattas* | **Category: math.NA, cs.NA** | **Updated: 2025-07-23**

**Keywords:** 分块Toeplitz矩阵, 快速傅里叶变换, GPU加速, 线性逆问题, Hessian矩阵-向量乘法

**Comment:** 

> **TL;DR:** 提出了一种基于FFT和GPU加速的算法，用于高效计算分块Toeplitz矩阵的矩阵-向量乘法，显著加速了大规模线性逆问题中的Hessian矩阵-向量乘法。

**AI_Comments:** 这篇论文的创新点在于巧妙地利用了线性时不变系统所固有的分块Toeplitz矩阵结构，并结合快速傅里叶变换（FFT）和GPU并行计算，极大地加速了大规模逆问题中计算成本高昂的Hessian矩阵-向量乘法。其重要性在于为解决实际应用中常见的复杂逆问题提供了高性能的计算工具，尤其是在需要实时或近实时处理的场景下具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决大规模线性逆问题中，传统基于正向/伴随PDE求解的无矩阵Hessian矩阵-向量乘法计算成本过高的问题。

**Method:** 提出了一种高效可扩展的算法，利用时间不变性导致的参数-观测映射的分块Toeplitz结构，通过快速傅里叶变换（FFT）实现高效的Hessian矩阵-向量乘法，并将其映射到多GPU集群上。

**Result:** 该算法在NVIDIA A100 GPU上实现了超过80%的峰值带宽，在多达48个A100 GPU上显示出优异的弱扩展性。对于目标问题，Hessian矩阵-向量乘法可在几分之一秒内完成，比传统方法快几个数量级。

**Conclusion:** 该算法通过利用分块Toeplitz结构和GPU加速，显著提高了大规模线性逆问题中Hessian矩阵-向量乘法的计算效率和可扩展性。

> **ai_Abstract:** 本文提出了一种高效且可扩展的GPU加速算法，用于处理大规模线性逆问题中出现的块Toeplitz矩阵的矩阵-向量乘法。该算法利用了时不变动力系统导致的参数-观测映射的分块Toeplitz结构，并通过快速傅里叶变换（FFT）实现高效的Hessian矩阵-向量乘法。实验证明，该方法在多GPU集群上表现出色，显著提高了计算速度和扩展性，远超传统基于PDE求解的方法。

> **摘要翻译:** 我们提出了一种高效且可扩展的算法，用于分块Toeplitz矩阵的矩阵-向量乘法（"matvecs"）。这类矩阵对其块具有平移不变性，出现在由自治系统，特别是时不变系统控制的逆问题求解中。在本文中，我们考虑从以偏微分方程（PDE）形式给出的线性时不变动力系统的观测数据中推断未知参数的逆问题。无矩阵牛顿共轭梯度法通常是解决这些逆问题的黄金标准，但它们需要大量的Hessian作用于向量。基于伴随的无矩阵Hessian矩阵-向量乘法需要每次Hessian作用求解一对线性化正向/伴随PDE，这对于大规模逆问题可能成本过高。正向PDE问题的时不变性导致离散化参数到观测（p2o）映射的分块Toeplitz结构，该映射定义了PDE输入（参数）到输出（观测）的映射。这种分块Toeplitz结构使我们能够利用两个关键特性：（1）p2o映射及其伴随的紧凑存储；（2）高效的基于快速傅里叶变换（FFT）的Hessian矩阵-向量乘法。所提出的算法被映射到大型多GPU集群上，并在NVIDIA A100 GPU上实现了超过80%的峰值带宽。在多达48个A100 GPU上显示出优异的弱扩展性。对于目标问题，该实现可在几分之一秒内执行Hessian矩阵-向量乘法，比通过正向/伴随PDE求解的传统无矩阵Hessian矩阵-向量乘法快几个数量级。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [122] [Continuous data assimilation for hydrodynamics: consistent discretization and application to moment recovery](https://arxiv.org/abs/2409.03872)
> *流体动力学的连续数据同化：一致离散化及其在矩恢复中的应用*

*Jingcheng Lu, Kunlun Qi, Li Wang, Jeff Calder* | **Category: math.NA, cs.NA, 93C20, 70S10, 65Dxx, 42A15, 82C40** | **Updated: 2025-07-23**

**Keywords:** 连续数据同化, 流体动力学, 矩恢复, 数据驱动, 推移系统

**Comment:** Updated version in Journal of Computational Physics

> **TL;DR:** 本文提出了一种结合松弛式推移系统和新型离散化技术的连续数据同化方法，用于从稀疏观测数据中同时恢复流体动力学模型的力项和高分辨率解，并应用于动理学理论中的矩恢复问题，为机器学习的矩闭合模型提供数据准备。

**AI_Comments:** 该论文的创新点在于将连续数据同化与一种新型的松弛式推移系统和离散化技术相结合，以解决流体动力学模型中的矩恢复问题，特别是为基于机器学习的矩闭合模型提供关键的数据准备步骤。其能够从稀疏数据中同时恢复力项和高分辨率解，并利用核回归处理数据，展现了实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 动理学理论中流体动力学近似中矩恢复的挑战。

**Method:** 本文提出了一种数据驱动的流体动力学模型方法，灵感来源于连续数据同化。该方法引入了一个基于松弛的推移系统，并结合了一种新颖的离散化技术，旨在从稀疏观测数据中同时恢复力项和高分辨率解。为解决潜在的数值伪影，使用核回归拟合观测数据。此外，还分析了所提出的推移系统在完整和部分数据场景下的收敛性。

**Result:** 多个数值实验证明了该算法的有效性。

**Conclusion:** 当应用于矩系统（其中源项涉及高阶矩的导数）时，该方法是基于机器学习的矩闭合模型中数据准备的关键步骤。

> **ai_Abstract:** 本文提出了一种用于流体动力学模型的数据驱动方法，旨在解决动理学理论中矩恢复的挑战。该方法借鉴了连续数据同化，引入了一个结合新型离散化技术的基于松弛的推移系统，能够从稀疏观测数据中同时恢复力项和高分辨率解。研究中采用了核回归处理数据，并分析了系统的收敛性。数值实验证实了其有效性，并指出其在机器学习驱动的矩闭合模型数据准备中的关键作用。

> **摘要翻译:** 受动理学理论中流体动力学近似中矩恢复挑战的启发，我们提出了一种用于流体动力学模型的数据驱动方法。受连续数据同化的启发，我们的方法引入了一个基于松弛的推移系统，并结合了一种新颖的离散化技术。这种方法有助于从稀疏观测数据中同时恢复力项和高分辨率解。为了解决潜在的数值伪影，我们使用核回归来拟合观测数据。我们还分析了所提出的推移系统在完整和部分数据场景下的收敛性。当应用于矩系统时，源项涉及高阶矩的导数，我们的方法是基于机器学习的矩闭合模型中数据准备的关键步骤。多个数值实验证明了我们算法的有效性，并且我们讨论了其扩展到高维系统的潜力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [147] [$hp$-error analysis of mixed-order hybrid high-order methods for elliptic problems on simplicial meshes](https://arxiv.org/abs/2410.02540)
> *$hp$-误差分析的混合阶混合高阶方法用于单纯形网格上的椭圆问题*

*Zhaonan Dong, Alexandre Ern* | **Category: math.NA, cs.NA, 65N15, 65N30** | **Updated: 2025-07-24**

**Keywords:** 混合高阶方法, $hp$-误差分析, 椭圆问题, 先验估计, 后验估计

**Comment:** 

> **TL;DR:** 本文对用于椭圆问题的混合阶混合高阶（HHO）方法进行了$hp$-先验和$hp$-后验误差分析，获得了次优的先验估计和首个HHO方法的后验误差估计。

**AI_Comments:** 这项工作在数值分析领域具有重要意义，因为它首次为混合非协调方法和HHO方法提供了全面的$hp$-误差分析，填补了理论空白。特别是，它对$p$-次优性和最优性的细致区分，以及新颖的非协调误差估计方法，都体现了其创新性。这些理论结果对于理解和改进HHO方法的精度和效率至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为近似二阶椭圆问题的混合阶混合高阶（HHO）方法提供$hp$-先验和$hp$-后验误差分析，填补了现有混合非协调方法和HHO方法在此类误差估计上的空白。

**Method:** 提出了一种混合阶混合高阶（HHO）方法，用于近似单纯形网格上的二阶椭圆问题。通过基于由帽基函数提供的单位分解和顶点星上的局部亥姆霍兹分解的新方法来估计非协调误差。通过数值例子验证了理论。

**Result:** 1. $hp$-先验误差分析: 得到了一个$\frac12$-阶$p$-次优的误差估计，这是混合非协调方法中的首个此类结果，并与现有其他非协调方法（如间断伽辽金方法）的最新成果相匹配。
2. $hp$-后验误差分析: 得到了一个基于残差的$hp$-后验误差上限，包括残差、法向通量跳跃、切向跳跃和稳定化估计器。前三项是$p$-最优的，最后一项是$\frac12$-阶$p$-次优的。这是HHO方法的首个$hp$-后验误差估计。
3. 建立了局部下界误差，并发现法向通量跳跃估计器是$\frac12$-阶$p$-次优的，可被稳定化项约束。

**Conclusion:** 本文成功对混合阶混合高阶（HHO）方法在椭圆问题上的$hp$-误差进行了全面的先验和后验分析，填补了该领域的重要空白，并为未来研究提供了理论基础。

> **ai_Abstract:** 本文对单纯形网格上用于近似二阶椭圆问题的混合阶混合高阶（HHO）方法进行了全面的$hp$-误差分析。研究首次为混合非协调方法提供了$\frac12$-阶$p$-次优的$hp$-先验误差估计，并首次为HHO方法提供了基于残差的$hp$-后验误差上限，其中包含$p$-最优和$\frac12$-阶$p$-次优的估计器。通过引入基于单位分解和局部亥姆霍兹分解的新方法来处理非协调误差，并建立了局部下界误差。数值实验验证了理论结果。

> **摘要翻译:** 我们提出了混合阶混合高阶（HHO）方法在单纯形网格上近似二阶椭圆问题的$hp$-先验和$hp$-后验误差分析。我们关于$hp$-先验误差分析的主要结果是一个$\frac12$-阶$p$-次优的误差估计。据我们所知，这是混合非协调方法中首个此类结果，并且与具有一般（混合Dirichlet/Neumann）边界条件的其他非协调方法（如间断伽辽金方法）的最新水平相匹配。我们的第二个主要结果是基于残差的$hp$-后验误差上限，包括残差、法向通量跳跃、切向跳跃和稳定化估计器（加上数据振荡项）。前三项是$p$-最优的，只有最后一项是$\frac12$-阶$p$-次优的。据我们所知，这是HHO方法的首个$hp$-后验误差估计。为了估计非协调误差，我们设计了一种基于由帽基函数提供的单位分解和顶点星上的局部亥姆霍兹分解的新方法。最后，我们建立了局部下界误差。值得注意的是，法向通量跳跃估计器仅是$\frac12$-阶$p$-次优的，因为HHO方法的局部守恒性质使其可以被稳定化项限制。数值例子证实了该理论。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [172] [Inverse scattering for Schrödinger equation in the frequency domain via data-driven reduced order modeling](https://arxiv.org/abs/2503.11034)
> *薛定谔方程在频域中的逆散射问题：基于数据驱动降阶模型的解决方案*

*Andreas Tataris, Tristan van Leeuwen, Alexander V. Mamonov* | **Category: math.NA, cs.NA, 65M32, 41A20** | **Updated: 2025-07-23**

**Keywords:** 逆散射, 薛定谔方程, 频域, 降阶模型, 数据驱动

**Comment:** 

> **TL;DR:** 本文提出了一种基于数据驱动降阶模型（ROM）的数值方法，用于解决频域薛定谔方程的逆散射问题，该方法通过最小化ROM失配来估计散射势，并在合成示例中表现优于传统方法。

**AI_Comments:** 这篇论文的创新点在于将数据驱动的降阶模型应用于逆散射问题，特别是通过最小化ROM失配而非传统的数据失配来优化散射势的估计。这种方法在性能上的提升值得关注，为解决复杂的逆散射问题提供了一个有前景的新途径。

<details>
  <summary>Details</summary>

**Motivation:** 解决从频域测量数据中估计薛定谔方程散射势的逆散射问题。

**Method:** 开发了一种基于降阶模型（ROM）的数值方法。ROM通过将薛定谔算子投影到由特定波数下的解快照张成的子空间来构建，并可以从散射体周围表面上的测量数据以数据驱动的方式构建。通过非线性优化最小化ROM失配来估计散射势。开发了两种ROM算法变体，并在二维合成示例上进行了测试。

**Result:** 所提出的方法通常优于基于数据失配最小化的传统方法。在二维合成示例上测试了两种ROM算法变体。

**Conclusion:** 成功开发并测试了两种基于ROM的数值算法，用于解决频域薛定谔方程的逆散射问题，并证明其性能优于传统方法。

> **ai_Abstract:** 本文提出了一种新颖的数值方法，利用数据驱动的降阶模型（ROM）来解决频域薛定谔方程的逆散射问题。该方法通过将薛定谔算子投影到由解快照构建的子空间来形成ROM，并从测量数据中构建。通过最小化ROM失配的非线性优化来估计散射势。研究表明，该ROM方法通常优于传统的基于数据失配最小化的方法，并在二维合成示例中得到了验证。

> **摘要翻译:** 在本文中，我们开发了一种数值方法，用于解决基于降阶模型（ROM）的逆散射问题，该问题旨在从频域测量数据中估计薛定谔方程中的散射势。ROM是将薛定谔算子投影到由其在特定波数下的解快照所张成的子空间。如果测量是在这些波数下进行的，ROM可以根据散射体周围表面上的测量数据以数据驱动的方式构建。一旦计算出ROM，就可以使用最小化ROM失配的非线性优化来估计散射势。这种方法通常优于基于数据失配最小化的传统方法。我们开发了两种基于ROM的逆散射算法变体，并在一个二维空间合成示例上进行了测试。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [197] [Flow Through Porous Media: A Hopf-Cole Transformation Approach for Modeling Pressure-Dependent Viscosity](https://arxiv.org/abs/2504.21603)
> *多孔介质流：一种用于模拟压力依赖性粘度的Hopf-Cole变换方法*

*V. S. Maduri, K. B. Nakshatrala* | **Category: math.NA, cs.NA, math-ph, math.MP** | **Updated: 2025-07-24**

**Keywords:** 多孔介质流, 压力依赖性粘度, Hopf-Cole变换, 非线性模型, 达西方程

**Comment:** 

> **TL;DR:** 本文展示了Hopf-Cole变换如何将描述具有压力依赖性粘度的多孔介质流动的非线性方程线性化，从而实现更高效的分析和数值求解。

**AI_Comments:** 本文的创新之处在于巧妙地将Hopf-Cole变换应用于具有压力依赖性粘度的多孔介质流问题，成功地将复杂的非线性方程转化为线性形式。这一方法极大地简化了数学分析，并为开发高效的数值求解器提供了可能，从而有望显著提升在高压条件下多孔介质流建模的效率和准确性。该方法对于地质碳封存等实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数有机液体表现出压力依赖性粘度，这在压力显著高于环境条件的应用中（例如地质碳封存）至关重要。描述多孔介质中流动的数学模型若考虑粘度-压力依赖性，则为非线性（例如Barus模型），这使得数学分析复杂化，并导致数值解耗时且容易出现收敛问题。

**Method:** 本文展示了Hopf-Cole变换（最初为Burgers方程开发）可以将描述具有压力依赖性粘度的多孔介质流动的控制方程重铸为线性形式。

**Result:** 转换后的方程类似于变换变量中的达西方程，这使得(a)能够进行系统的数学分析以建立唯一性和最大值原理，(b)能够推导基于力学的原理，以及(c)能够使用针对达西方程优化的求解器开发高效的数值解。值得注意的是，线性达西方程的许多性质自然地扩展到依赖于压力的非线性模型，例如，这些非线性模型的解遵循类似于达西方程中观察到的互易关系。

**Conclusion:** Hopf-Cole变换可以有效地将具有压力依赖性粘度的多孔介质流动的非线性模型线性化，从而简化了数学分析，促进了高效数值求解，并揭示了线性模型属性在非线性模型中的可扩展性。

> **ai_Abstract:** 本文提出了一种利用Hopf-Cole变换来处理多孔介质中具有压力依赖性粘度的流体模型的方法。鉴于此类模型固有的非线性特性导致分析和数值求解困难，作者证明了Hopf-Cole变换能够将控制方程转化为线性形式，使其类似于达西方程。这种线性化不仅有助于系统地进行数学分析（如确立唯一性和最大值原理），推导基于力学的原理，还能利用针对达西方程优化的求解器开发高效的数值方法。研究还发现，线性达西方程的许多性质可以自然地推广到这些非线性模型中。

> **摘要翻译:** 大多数有机液体表现出压力依赖性粘度，这使得在压力显著高于环境条件（例如地质碳封存）的应用中考虑这种行为至关重要。描述多孔介质中流动的数学模型，若考虑粘度-压力依赖性，则为非线性（例如Barus模型）。这种非线性使得数学分析复杂化，并使数值解更加耗时且容易出现收敛问题。在本文中，我们证明了最初为Burgers方程开发的Hopf-Cole变换可以将描述具有压力依赖性粘度的多孔介质流动的控制方程重铸为线性形式。转换后的方程，在变换变量中类似于达西方程，使得(a)能够进行系统的数学分析以建立唯一性和最大值原理，(b)能够推导基于力学的原理，以及(c)能够使用针对达西方程优化的求解器开发高效的数值解。值得注意的是，线性达西方程的许多性质自然地扩展到依赖于压力的非线性模型。例如，这些非线性模型的解遵循类似于达西方程中观察到的互易关系。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [222] [1/2 order convergence rate of Euler-type methods for time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients](https://arxiv.org/abs/2507.14562)
> *具有超线性增长漂移和扩散系数的时间变换随机微分方程欧拉型方法的1/2阶收敛速度*

*Yuanling Niu, Shuai Wang, Ying Zhang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 时间变换随机微分方程, 欧拉方法, 收敛速度, 超线性增长, 均方收敛

**Comment:** 

> **TL;DR:** 本文研究了具有超线性增长系数的时间变换随机微分方程的两种欧拉型方法，并证明它们在均方意义上达到了1/2的最优强收敛速度，且数值模拟证实了理论发现。

**AI_Comments:** 这项研究通过扩展欧拉型方法到更复杂的随机微分方程，即具有超线性增长系数的时间变换随机微分方程，并证明了其最优收敛速度，具有重要的理论和实践意义。其创新之处在于将现有方法适应到新的方程类型并引入新的显式方法，同时通过数值模拟验证了理论结果，增强了研究的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究一类具有超线性增长漂移和扩散系数的时间变换随机微分方程的收敛率。

**Method:** 本文在现有研究基础上，将后向欧拉方法应用于时间变换随机微分方程，并引入了其显式对应物——投影欧拉方法。

**Result:** 研究表明，这两种欧拉型方法对于此类方程在均方意义上均达到了1/2阶的最优强收敛速度。数值模拟证实了理论发现。

**Conclusion:** 对于具有超线性增长漂移和扩散系数的时间变换随机微分方程，后向欧拉方法和投影欧拉方法均能达到1/2的最优强收敛速度，且其有效性已通过数值模拟验证。

> **ai_Abstract:** 本文研究了针对具有超线性增长漂移和扩散系数的时间变换随机微分方程的欧拉型方法的收敛率。通过调整后向欧拉方法并提出投影欧拉方法，研究表明这两种方法在均方意义上均能达到1/2的最优强收敛速度，且这一理论结果得到了数值模拟的验证。

> **摘要翻译:** 本文研究了一类具有超线性增长漂移和扩散系数的时间变换随机微分方程的两种欧拉型方法的收敛速度。在现有研究的基础上，我们将后向欧拉方法应用于漂移和扩散系数均表现出超线性增长的时间变换随机微分方程，并引入了其显式对应物——投影欧拉方法。结果表明，对于这类方程，这两种方法在均方意义上均达到了1/2阶的最优强收敛速度。数值模拟证实了理论发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [247] [Analysis of fully discrete Crank-Nicolson finite element methods for a stochastic Keller-Segel chemotaxis system with gradient-type multiplicative noise](https://arxiv.org/abs/2507.15103)
> *具有梯度型乘性噪声的随机Keller-Segel趋化系统的全离散Crank-Nicolson有限元方法分析*

*Liet Vo* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 随机Keller-Segel系统, Crank-Nicolson, 有限元方法, Stratonovich噪声, 收敛率

**Comment:** 

> **TL;DR:** 本文提出并分析了一种针对随机Keller-Segel趋化系统的全离散Crank-Nicolson有限元方法，并证明了其在时间和空间上的收敛率。

**AI_Comments:** 这项工作创新性地将Crank-Nicolson有限元方法应用于随机Keller-Segel系统，并详细分析了随机噪声对收敛率的影响，揭示了其与确定性情况的差异，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在随机波动的环境条件下，模拟趋化行为的随机Keller-Segel系统需要有效的数值方法。

**Method:** 所提出的全离散方案将Crank-Nicolson时间离散化与空间上的分裂混合有限元方法相结合。

**Result:** 数值方案的稳定性得到了严格证明，并建立了$O(k^{1/2} + k^{-1/2}h^2)$的强收敛率，其中k和h分别是时间和空间步长。随机力的存在导致误差估计中对k的逆依赖性，这与确定性情况下的收敛行为不同。数值实验验证了理论结果并展示了所提出方法的有效性和准确性。

**Conclusion:** 本文成功开发并分析了针对随机Keller-Segel趋化系统的全离散Crank-Nicolson有限元方法，证明了其收敛性和有效性，并指出了随机噪声对收敛行为的影响。

> **ai_Abstract:** 本文提出并分析了一种用于模拟随机Keller-Segel趋化系统的全离散Crank-Nicolson有限元方法。该方法结合了Crank-Nicolson时间离散和分裂混合有限元空间离散。研究严格证明了该数值方案的稳定性和收敛率，并强调了随机噪声对收敛行为的独特影响。数值实验证实了理论结果和方法的有效性。

> **摘要翻译:** 我们开发并分析了受Stratonovich噪声扰动的随机Keller-Segel系统的数值方法，该系统模拟了随机波动环境条件下的趋化行为。所提出的全离散方案将Crank-Nicolson时间离散化与空间上的分裂混合有限元方法相结合。我们严格证明了数值方案的稳定性，并建立了$O(k^{1/2} + k^{-1/2}h^2)$的强收敛率，其中k和h分别表示时间和空间步长。值得注意的是，随机力的存在导致误差估计中对k的逆依赖性，这使得收敛行为与确定性情况不同。数值实验验证了理论结果并展示了所提出方法的有效性和准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [406] [Recovery Thresholding Hyperinterpolations in Signal Processing](https://arxiv.org/abs/2507.17916)
> *信号处理中的恢复阈值超插值*

*Congpei An, Jiashu Ran* | **Category: math.NA, cs.NA, 65K10, 65D15, 94A12, 65F10, 33C52** | **Updated: 2025-07-23**

**Keywords:** 稀疏信号重建, 超插值, 阈值处理, 牛顿法, 去噪

**Comment:** 16 pages, 3 figures, 5 tables

> **TL;DR:** 本文提出了一种新的恢复阈值超插值方法，用于在噪声存在下进行鲁棒的稀疏信号重建，并在保持信号稀疏性的同时实现了准确恢复，优于传统方法。

**AI_Comments:** 本文的创新之处在于将阈值算子与超插值框架新颖地结合起来，并应用牛顿法解决稀疏信号恢复中的非凸问题。这种方法在噪声条件下，通过有效保持信号稀疏性并确保准确重建，显著优于传统方法。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种在存在噪声的情况下进行稀疏信号重建的新型方法。

**Method:** 本文引入了恢复阈值超插值，将硬阈值、回弹阈值和牛顿阈值等阈值算子直接集成到超插值结构中，以在信号恢复过程中保持稀疏性。该方法利用牛顿法最小化一维非凸函数，并将其扩展到解决多变量非凸正则化问题。

**Result:** 所提出的方法在重建受高斯噪声和脉冲噪声损坏的信号方面表现出稳健的性能。数值实验验证了这些恢复阈值超插值在信号重建和函数去噪应用中的有效性，并展示了它们在保持信号稀疏性的同时实现准确恢复方面优于传统方法的优势。

**Conclusion:** 恢复阈值超插值能够有效地重建受噪声污染的稀疏信号，通过保持稀疏性和实现准确恢复，优于传统方法。

> **ai_Abstract:** 本文提出了一种名为恢复阈值超插值的新型方法，用于在噪声环境下进行稀疏信号重建。该框架将多种阈值算子直接整合到超插值结构中，并利用牛顿法解决非凸正则化问题。数值实验证明，这些方法在重建受高斯和脉冲噪声损坏的信号方面表现出强大的性能和有效性，在保持信号稀疏性和实现准确恢复方面优于传统方法，适用于信号重建和去噪应用。

> **摘要翻译:** 本文引入了恢复阈值超插值，这是一种在存在噪声的情况下进行稀疏信号重建的新型方法。我们开发了一个框架，将阈值算子——包括硬阈值、回弹阈值和牛顿阈值——直接集成到超插值结构中，以在信号恢复过程中保持稀疏性。我们的方法利用牛顿法来最小化一维非凸函数，然后将其扩展到解决多变量非凸正则化问题。所提出的方法在重建受高斯噪声和脉冲噪声损坏的信号方面表现出稳健的性能。通过数值实验，我们验证了这些恢复阈值超插值在信号重建和函数去噪应用中的有效性，展示了它们在保持信号稀疏性的同时实现准确恢复方面优于传统方法的优势。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [446] [A stabilized Two-Step Formulation of Maxwell's Equations in the time-domain](https://arxiv.org/abs/2507.18235)
> *麦克斯韦方程组时域稳定两步公式*

*Leon Herles, Mario Mally, Jörg Ostrowski, Sebastian Schöps, Melina Merkel* | **Category: math.NA, cs.CE, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 麦克斯韦方程组, 时域, 低频不稳定性, 稳定化, 树-余树规范

**Comment:** 6 pages, 9 figures

> **TL;DR:** 本文提出一种稳定的时域麦克斯韦方程组两步公式，通过结合广义树-余树规范解决低频不稳定性，并在3D问题上验证了其稳定性、精度及对非线性材料的适用性。

**AI_Comments:** 这项工作通过将稳定的两步公式扩展到时域并引入广义树-余树规范来解决电磁场模拟中的低频不稳定性问题，具有重要的创新性。其方法在处理复杂材料（如非线性、温度依赖性材料）方面也显示出良好的适用性，这对于实际工程应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 模拟宽频率范围内的电磁场在低频时存在数值不稳定性，这是一个挑战。

**Method:** 将稳定的两步麦克斯韦方程组公式扩展到时域。在空间上使用伽辽金离散，并应用两种不同的时间离散方案来处理两步求解过程中出现的一阶和二阶时间偏微分方程。通过引入广义树-余树规范来消除旋度-旋度算子的奇异性，以解决低频不稳定性。

**Result:** 数值结果在学术和应用导向的3D问题上证实了该方法的稳定性、准确性以及对非线性、温度相关材料的适用性。

**Conclusion:** 该方法能够稳定、准确地模拟宽频率范围内的电磁场，特别是在低频下表现出鲁棒性，并适用于复杂材料。

> **ai_Abstract:** 本文提出一种将麦克斯韦方程组的稳定两步公式扩展到时域的方法，旨在解决宽频率范围内电磁场模拟在低频时出现的数值不稳定性问题。该方法结合了空间上的伽辽金离散和为两步求解过程定制的时间离散方案，并通过引入广义树-余树规范消除了旋度-旋度算子的奇异性，从而确保了低频下的鲁棒性。数值实验在3D问题上验证了该方法的稳定性、准确性及其对非线性、温度依赖性材料的适用性。

> **摘要翻译:** 模拟宽频率范围内的电磁场因低频时的数值不稳定性而具有挑战性。这项工作将麦克斯韦方程组的稳定两步公式扩展到时域。在空间上使用伽辽金离散，我们应用了两种不同的时间离散方案，这些方案是为本文使用的两步求解过程中的一阶和二阶时间偏微分方程量身定制的。为了解决低频不稳定性，我们引入了一种广义树-余树规范，该规范消除了旋度-旋度算子的奇异性，即使在静态极限下也能确保鲁棒性。在学术和应用导向的3D问题上的数值结果证实了该方法的稳定性、准确性以及对非线性、温度相关材料的适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [448] [A novel finite element method for simulating surface plasmon polaritons on complex graphene sheets](https://arxiv.org/abs/2507.17928)
> *模拟复杂石墨烯薄片上表面等离子体激元的一种新型有限元方法*

*Jichun Li, Michael Neunteufel, Li Zhu* | **Category: math.NA, cs.NA** | **Updated: 2025-07-23**

**Keywords:** 表面等离子体激元, 石墨烯, 有限元方法, 模拟, 复杂界面

**Comment:** 

> **TL;DR:** 本文提出了一种新的有限元方法和简化的石墨烯模型，以准确模拟复杂石墨烯薄片上的表面等离子体激元（SPPs）。

**AI_Comments:** 该论文的创新点在于提出了一个简化的石墨烯模型和一种新型有限元方法，以克服在复杂界面和边界条件下模拟表面等离子体激元（SPPs）的挑战。这对于推进纳米光学中SPPs的理解和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确模拟表面等离子体激元（SPPs）面临独特的挑战，因为SPPs通常出现在不同介电常数材料的复杂界面处，并且石墨烯界面处的适当边界条件至关重要。

**Method:** 本文开发了一种简化的石墨烯模型，并相应地提出了一种新的有限元方法。

**Result:** 连续模型的稳定性得到了证实，大量的数值结果表明新模型可以很好地捕捉各种复杂石墨烯薄片上的SPPs。

**Conclusion:** 所提出的简化石墨烯模型和新型有限元方法能够有效且准确地模拟复杂石墨烯薄片上的表面等离子体激元。

> **ai_Abstract:** 本文针对石墨烯表面上表面等离子体激元（SPPs）的精确模拟所面临的挑战，提出了一种基于简化石墨烯模型的新型有限元方法。研究表明，该方法能够有效地捕捉各种复杂石墨烯薄片上的SPPs，并具有良好的稳定性。

> **摘要翻译:** 表面等离子体激元（SPPs）在石墨烯表面产生，并为宿主材料及其介电环境的纳米光学和电动力学响应提供了窗口。SPPs的精确模拟提出了几个独特的挑战，因为SPPs通常发生在不同介电常数材料的复杂界面处，并且石墨烯界面处的适当边界条件至关重要。本文开发了一种简化的石墨烯模型，并相应地提出了一种新的有限元方法。连续模型的稳定性得到了证实，大量的数值结果表明新模型可以很好地捕捉各种复杂石墨烯薄片上的SPPs。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [490] [EigenWave: An Optimal O(N) Method for Computing Eigenvalues and Eigenvectors by Time-Filtering the Wave Equation](https://arxiv.org/abs/2507.18282)
> *EigenWave：一种通过时间滤波波动方程计算特征值和特征向量的最优O(N)方法*

*Daniel Appelo, Jeffrey W. Banks, William D. Henshaw, Ngan Le, Donald W. Schwendeman* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 特征值, 特征向量, 波动方程, 时间滤波, O(N)算法

**Comment:** 

> **TL;DR:** EigenWave是一种新的O(N)算法，通过时间滤波波动方程来高效计算椭圆边值问题的特征值和特征向量，无需反演不定矩阵。

**AI_Comments:** EigenWave算法的创新之处在于其通过时间滤波波动方程来计算特征值和特征向量，避免了传统方法中常见的反演不定矩阵的难题。其O(N)的计算复杂度，结合隐式时间步进和多重网格技术，使其在处理大规模问题时具有显著的效率优势。该方法在计算整个频谱范围内的特征值方面表现出极大的灵活性，且能够高效地计算目标频率附近的多个特征对，对于数值线性代数和偏微分方程的数值求解领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通常需要反演不定矩阵，这增加了计算复杂性。本文旨在开发一种更高效、更灵活的方法来计算整个频谱范围内的特征值和特征向量。

**Method:** EigenWave算法基于WaveHoltz方案，通过迭代求解一个相关的时间依赖波动方程。在每次迭代中，对波动方程的解进行时间滤波，使过滤后的解逐渐包含更多接近目标频率的特征模态。该方法能够选择任意目标频率，无需反演不定矩阵。为提高效率，时间依赖波动方程采用隐式时间步进求解，并且可以嵌入到无矩阵Arnoldi算法中，以高效计算目标频率附近的多个特征对。当隐式时间步进方程通过多重网格算法求解时，EigenWave方案的计算成本与网格点数N呈线性关系，达到最优O(N)复杂度。

**Result:** 该方法通过使用重叠网格在复杂几何中寻找拉普拉斯算子的特征对进行了验证。在二维和三维空间中，使用二阶和四阶精确近似得到了结果。

**Conclusion:** EigenWave是一种最优的O(N)算法，能够高效地计算椭圆边值问题的特征值和特征向量，且避免了传统方法中反演不定矩阵的需要。

> **ai_Abstract:** 本文提出了一种名为EigenWave的O(N)算法，用于高效计算椭圆边值问题的特征值和特征向量。该算法基于WaveHoltz方案，通过时间滤波一个时间依赖波动方程来聚焦于目标频率附近的特征模态，从而避免了传统方法中反演不定矩阵的需要。它能够计算频谱中任意位置的特征值，并通过与无矩阵Arnoldi算法结合来高效计算多个特征对。该方法采用隐式时间步进和多重网格求解，实现了与网格点数线性相关的最优O(N)复杂度，并在复杂几何的拉普拉斯算子特征对计算中得到了验证。

> **摘要翻译:** 描述了一种名为EigenWave的算法，用于计算椭圆边值问题的特征值和特征向量。该算法基于最近开发的WaveHoltz方案，作为迭代的一部分，求解一个相关的时间依赖波动方程。在每次迭代中，波动方程的解在时间上进行滤波。随着迭代的进行，滤波后的解通常包含越来越大比例的特征模态，其特征值接近选定的目标频率（目标特征值）。选择任意目标频率的能力使得可以在频谱的任何位置计算特征值，而无需像其他常见方法那样反演不定矩阵。此外，该迭代可以嵌入到无矩阵Arnoldi算法中，从而能够高效计算目标频率附近的多个特征对。为了提高效率，时间依赖波动方程可以使用隐式时间步进求解，并且每周期只需大约10个时间步，这与网格间距无关。当（定正的）隐式时间步进方程通过多重网格算法求解时，所得EigenWave方案的成本随网格点数N的增加而线性扩展，从而得到最优的O(N)算法。该方法通过使用重叠网格在复杂几何中寻找拉普拉斯算子的特征对进行了演示。使用二阶和四阶精确近似给出了二维和三维空间的结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [527] [Parametric design and adaptive sizing of lattice structures for 3d additive manufacturing](https://arxiv.org/abs/2507.18318)
> *增材制造点阵结构的参数化设计与自适应尺寸确定*

*Jorge Manuel Mercado-Colmenero, Daniel Diaz - Perete, Miguel Angel Rubio- Paramio, Cristina Martin-Donate* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 点阵结构, 参数化设计, 自适应尺寸, 增材制造, 结构优化

**Comment:** 

> **TL;DR:** 本研究提出了一种用于3D增材制造复杂零件的点阵结构参数化设计模型和自适应力学分析方法，旨在优化零件体积、质量和结构刚度，并通过数值验证。

**AI_Comments:** 这篇论文的创新点在于将参数化设计与自适应力学分析相结合，为3D增材制造的点阵结构提供了系统化的设计方法。其重要性体现在能够动态优化复杂零件的结构性能（如体积、质量和刚度），并适应不同的载荷和边界条件，这对于提升增材制造的效率和应用范围具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对复杂零件的3D增材制造领域，研究旨在引入一种参数化设计模型和自适应力学分析方法，以优化最终打印零件的体积、质量和结构刚度。

**Method:** 提出了一种新颖点阵结构的几何参数化、力学自适应尺寸确定和数值验证方法。核心方法是将分析自动化与基于二维梁单元模型的力学分析相结合，并利用子单元的刚度模型分析点阵结构的尺寸，通过叠加原理评估其全局结构行为。通过数值验证确保分析模型与实际力学行为相符。

**Result:** 通过完整的点阵结构参数化，确保几何参数根据定义限制进行调整，实现了基于载荷状态和边界条件的动态适应性，从而提高了力学性能。该方法优化了最终打印零件的体积、质量和结构刚度。

**Conclusion:** 本文旨在通过提供一种系统化和自适应的点阵结构设计方法，来推动增材制造技术的发展。参数化和自适应技术促进了新的工业设计工程方法，能够动态调整点阵结构以满足其力学需求并提高其整体效率和性能。

> **ai_Abstract:** 本文提出了一种针对3D增材制造复杂零件的点阵结构参数化设计与自适应尺寸确定方法。通过几何参数化、力学自适应分析和数值验证，该方法旨在优化打印零件的体积、质量和结构刚度。研究利用基于二维梁单元的分析自动化和子单元刚度模型，实现了点阵结构的动态适应性，从而提升了其机械性能和整体效率。

> **摘要翻译:** 本研究深入工业设计工程和增材制造领域，引入了一种新的点阵结构的参数化设计模型和自适应力学分析方法，重点关注复杂零件的3D增材制造。针对复杂零件增材制造的现状，本研究提出了一种新颖点阵结构的几何参数化、力学自适应尺寸确定和数值验证方法，以优化最终打印零件的体积和质量，以及其结构刚度。点阵结构的拓扑结构呈现金字塔形。点阵结构的完整参数化确保已知的几何参数根据定义的限制进行调整，从而实现基于其载荷状态和边界条件的动态适应性，进而提高其力学性能。核心方法是将分析自动化与采用基于二维梁单元模型的力学分析相结合。通过其子单元的刚度模型分析点阵结构的尺寸，并在应用叠加原理后评估其全局结构行为。进行了数值验证以验证所提出的分析模型。这一步确保了为点阵结构尺寸确定定义的分析模型能够适应其真实的力学行为并允许其验证。本手稿旨在通过提供一种系统化和自适应的点阵结构设计方法，来推进增材制造方法。参数化和自适应技术促进了新的工业设计工程方法，能够动态调整点阵结构以满足其力学需求并提高其整体效率和性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [561] [On MAP estimates and source conditions for drift identification in SDEs](https://arxiv.org/abs/2507.18443)
> *关于SDE中漂移识别的MAP估计和源条件*

*Daniel Tenbrinck, Nikolas Uesseler, Philipp Wacker, Benedikt Wirth* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** MAP估计, 漂移识别, SDE, 逆问题, 收敛率

**Comment:** 

> **TL;DR:** 本文研究了从SDE解的观测数据中识别漂移项的逆问题，推导了MAP估计，并证明了前向算子的可微性和切锥条件，数值模拟支持了收敛率的存在。

**AI_Comments:** 本文在SDE漂移识别的逆问题上取得了进展，特别是推导了MAP估计并分析了其数学性质。数值模拟结果验证了理论推断，为该领域的进一步研究提供了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 从SDE解的观测数据中识别漂移项是一个逆问题，本文旨在解决此问题并探讨相关估计的性质和收敛性。

**Method:** 本文推导了对应的MAP估计，证明了前向算子的可微性属性和所谓的切锥条件。此外，还回顾了现有相关问题的理论。

**Result:** 推导出了对应的MAP估计，并证明了前向算子的可微性属性和切锥条件。数值模拟表明，MAP估计的收敛率确实成立。

**Conclusion:** 本文成功推导了SDE中漂移识别的MAP估计，并验证了其前向算子的性质和收敛率，为相关问题的理论提供了支持。

> **ai_Abstract:** 本研究探讨了从有限观测数据中识别随机微分方程（SDE）漂移项的逆问题。文章推导了最大后验（MAP）估计，并证明了其前向算子的可微性和切锥条件。此外，通过回顾现有理论并进行一维数值模拟，结果表明MAP估计的收敛率（当观测数据量趋于无穷时）确实存在。

> **摘要翻译:** 我们考虑了从其解的$n$次观测数据（在$M+1$个不同时间点）中识别SDE中漂移项的逆问题。我们推导了相应的MAP估计，证明了前向算子的可微性属性以及所谓的切锥条件，并回顾了现有相关问题的理论，该理论在稍强的切锥条件下，将额外地给出当$n\to\infty$时MAP估计的收敛率。一维数值模拟表明，这种收敛率确实成立。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [604] [Solution of Least Squares Problems with Randomized Preconditioned Normal Equations](https://arxiv.org/abs/2507.18466)
> *随机预处理正规方程求解最小二乘问题*

*Ilse C. F. Ipsen* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 最小二乘, 随机预处理, 正规方程, 病态矩阵, 扰动界

**Comment:** 

> **TL;DR:** 本文研究了使用随机预处理正规方程求解全列秩最小二乘问题。研究表明，即使对于病态矩阵，这种方法也能达到与QR分解方法相当的精度，且其误差界与原始问题基本一致。

**AI_Comments:** 该论文的创新点在于引入了随机预处理技术来解决最小二乘问题，尤其是在处理病态矩阵时的表现。其重要性体现在提供了一种计算效率高且精度可观的替代方法，能够与成熟的QR分解方法相媲美，这对于大规模或实时计算的最小二乘问题具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决全列秩最小二乘问题，特别是针对高度病态矩阵，提高求解精度并使其接近QR分解等成熟方法的精度。

**Method:** 通过随机预处理（对称或非对称）的正规方程来求解全列秩最小二乘问题。提出了非直观但实际的相对误差扰动界，并使用概率条件数界来验证随机预处理器的有效性。

**Result:** 使用有效预处理器的解的精度几乎与基于QR分解的Matlab反斜杠命令（mldivide）一样准确，即使对于高度病态的矩阵也是如此。计算出的解的相对误差扰动界在有效预处理器下基本等同于原始最小二乘问题的扰动界。通过少量采样计算的随机预处理器的概率条件数界证实了其有效性。

**Conclusion:** 随机预处理正规方程方法能够有效地求解最小二乘问题，其精度和误差特性与现有高效方法相当，即使面对病态矩阵也能保持良好性能。

> **ai_Abstract:** 本文探讨了使用随机预处理正规方程求解全列秩最小二乘问题的方法。研究发现，即使对于高度病态的矩阵，采用有效的随机预处理器也能使计算出的解的精度达到与Matlab中基于QR分解的mldivide命令相当的水平。论文提出了实际的相对误差扰动界，并证明这些界限在有效预处理器下与原始最小二乘问题的扰动界基本一致。通过概率条件数界进一步验证了该随机预处理器在少量采样情况下的有效性。

> **摘要翻译:** 我们考虑通过随机预处理（对称或非对称）的正规方程来求解全列秩最小二乘问题。通过有效的预处理器，预处理正规方程的解的精度几乎与基于QR分解的Matlab反斜杠命令（mldivide）一样准确——即使对于高度病态的矩阵也是如此。这意味着预处理正规方程的精度取决于原始最小二乘问题的残差。我们提出了非直观但实际的计算解相对误差的扰动界，并表明在有效预处理器下，这些界限本质上等于原始最小二乘问题的扰动界。概率条件数界证实了通过少量采样计算的随机预处理器的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [640] [Fast Multipole Method for Maxwell's Equations in Layered Media](https://arxiv.org/abs/2507.18491)
> *层状介质中麦克斯韦方程的快速多极子方法*

*Heng Yuan, Bo Wang, Wenzhong Zhang, Wei Cai* | **Category: math.NA, cs.NA, 15A15, 15A09, 15A23** | **Updated: 2025-07-24**

**Keywords:** 快速多极子方法, 麦克斯韦方程, 层状介质, 格林函数, 计算电磁学

**Comment:** Submitted to SIAM Journal on Scientific Computing

> **TL;DR:** 本文提出了一种用于三维层状介质中麦克斯韦方程的快速多极子方法，该方法具有$\mathcal O(N\log N)$的计算复杂度和快速收敛性。

**AI_Comments:** 本文创新性地将快速多极子方法应用于三维层状介质中的麦克斯韦方程求解，通过引入特定的格林函数表示、等效像方法和切比雪夫多项式展开等技术，有效提升了计算效率和数值稳定性，解决了复杂介质中电磁场计算的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种求解三维层状介质中麦克斯韦方程的快速多极子方法。

**Method:** 该方法基于洛伦兹规范下的磁矢量势推导层状并矢格林函数，并使用三个标量亥姆霍兹层状格林函数表示。通过引入源的等效极化像和目标的有效位置，推导出远场的多极子展开和局部展开。为提高计算效率和数值稳定性，采用伴随勒让德函数的切比雪夫多项式展开加速多极子到局部展开的平移计算。最终，利用三维层状介质中亥姆霍兹方程的FMM框架，开发了适用于麦克斯韦方程并矢格林函数的FMM。

**Result:** 数值实验表明，所提出的FMM方法具有$\mathcal O(N\log N)$的计算复杂度，并且对于三维层状介质中低频电磁波源的相互作用具有快速收敛性。

**Conclusion:** 所开发的快速多极子方法能够高效、稳定地解决三维层状介质中的麦克斯韦方程问题。

> **ai_Abstract:** 本文提出了一种针对三维层状介质中麦克斯韦方程的快速多极子方法（FMM）。该方法基于磁矢量势推导层状并矢格林函数，并利用标量亥姆霍兹格林函数和等效极化像进行展开。通过切比雪夫多项式展开加速计算，最终构建了高效的FMM。数值结果验证了其$\mathcal O(N\log N)$的计算复杂度和对低频电磁波源的快速收敛性。

> **摘要翻译:** 我们提出了一种基于洛伦兹规范下磁矢量势的三维（3-D）层状介质中麦克斯韦方程的快速多极子方法（FMM），以推导层状并矢格林函数。并矢格林函数使用三个标量亥姆霍兹层状格林函数表示，所有界面引起的反应场分量都通过统一的积分表示来表达。通过引入源的等效极化像和目标的有效位置，以反映不同反应场分量的实际传输距离，推导出由实际传输距离控制的远场多极子展开（MEs）和局部展开（LEs）。为了进一步提高计算效率和数值稳定性，我们采用伴随勒让德函数的切比雪夫多项式展开来加速多极子到局部（M2L）展开平移的计算。最后，利用三维层状介质中亥姆霍兹方程的FMM框架，我们开发了一种用于层状介质中麦克斯韦方程并矢格林函数的FMM。数值实验表明，所得到的FMM方法具有$\mathcal O(N\log N)$的复杂度，并且对于三维层状介质中低频电磁波源的相互作用具有快速收敛性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [25] [LENS-DF: Deepfake Detection and Temporal Localization for Long-Form Noisy Speech](https://arxiv.org/abs/2507.16220)
> *LENS-DF：针对长时程嘈杂语音的深度伪造检测与时间定位*

*Xuechen Liu, Wanying Ge, Xin Wang, Junichi Yamagishi* | **Category: cs.SD, cs.CR, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 音频深度伪造检测, 时间定位, 噪声语音, LENS-DF, 自监督学习

**Comment:** Accepted by IEEE International Joint Conference on Biometrics (IJCB)
  2025, Osaka, Japan

> **TL;DR:** LENS-DF是一个新颖的、全面的方法，用于在复杂和真实的音频条件下训练和评估音频深度伪造检测和时间定位，并显示出优异的性能。

**AI_Comments:** LENS-DF的创新之处在于其综合性的训练和评估方法，特别是在模拟现实世界中复杂音频条件（如长时程、噪声和多说话人）方面的能力。这对于提升深度伪造检测模型在实际应用中的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂和真实的音频条件下（如长时程、嘈杂和多说话人环境），现有的音频深度伪造检测和时间定位方法表现不佳，需要更鲁棒的解决方案。

**Method:** 本研究引入了LENS-DF，一个用于训练和评估音频深度伪造检测和时间定位的综合方法。其生成部分能够可控地输出具有长持续时间、嘈杂条件和多说话人特征的音频。检测和定位协议使用模型，并基于自监督学习前端和简单后端进行实验。

**Result:** 实验结果表明，使用LENS-DF生成的数据训练的模型始终优于通过传统方法训练的模型，证明了LENS-DF在鲁棒音频深度伪造检测和定位方面的有效性和实用性。消融研究也揭示了引入的变体对现实挑战的影响和相关性。

**Conclusion:** LENS-DF在复杂和现实的音频条件下，对于鲁棒的音频深度伪造检测和时间定位是有效且有用的。

> **ai_Abstract:** 本文提出了LENS-DF，一个用于在复杂真实条件下进行音频深度伪造检测和时间定位的训练与评估框架。LENS-DF能够生成长时程、嘈杂、多说话人的音频数据用于训练。实验证明，使用LENS-DF生成数据训练的模型在鲁棒性上显著优于传统方法，证实了其在应对现实挑战中的有效性。

> **摘要翻译:** 本研究介绍了LENS-DF，这是一种新颖而全面的方法，用于在复杂和真实的音频条件下训练和评估音频深度伪造检测和时间定位。该方法的生成部分能够可控地从输入数据集中输出具有长持续时间、嘈杂条件和包含多个说话人等关键特征的音频。相应的检测和定位协议使用了模型。我们基于自监督学习前端和简单后端进行了实验。结果表明，使用LENS-DF生成的数据训练的模型始终优于通过传统方法训练的模型，这证明了LENS-DF在鲁棒音频深度伪造检测和定位方面的有效性和实用性。我们还对引入的变体进行了消融研究，调查它们对该领域现实挑战的影响和相关性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [54] [Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation](https://arxiv.org/abs/2507.17937)
> *鲍勃的纸屑：音乐和视频生成中的语音记忆攻击*

*Jaechul Roh, Zachary Novack, Yuefeng Peng, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick, Amir Houmansadr* | **Category: cs.SD, cs.AI, cs.CL, eess.AS** | **Updated: 2025-07-23**

**Keywords:** 语音记忆, 生成模型, 音乐生成, 视频生成, 攻击

**Comment:** 

> **TL;DR:** LS2模型在语音层面存在记忆漏洞，即使歌词被同音词替换，也能重现训练数据中的音视频内容。

**AI_Comments:** 这项研究揭示了生成模型中一个此前未被充分认识的深层记忆漏洞，即模型不仅记忆语义内容，还能记忆底层的语音结构，并能通过这种结构重现训练数据中的多模态内容。这种“语音到视觉反刍”的发现尤其创新，对版权保护和内容溯源提出了新的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 歌词到歌曲（LS2）生成模型对训练数据记忆的脆弱性尚未得到充分探索。

**Method:** 本文引入了对抗性语音提示（APT）攻击，通过同音词替换在语义上改变歌词但保留其声学结构。研究人员使用这些修改后的歌词来测试LS2模型（如SUNO和YuE）的音频记忆能力，并测试文本到视频模型（如Veo 3）的视觉记忆能力，评估生成内容与原始训练数据的相似性。

**Result:** LS2模型（如SUNO和YuE）在面对同音词替换的歌词时，会重新生成与已知训练内容惊人相似的输出，在音频域指标上获得高相似度。这种漏洞在多种语言和流派中持续存在。更令人惊讶的是，语音改变的歌词也能触发文本到视频模型的视觉记忆，即使提示中没有视觉线索，模型也能重建原始音乐视频中的视觉元素，这种现象被称为“语音到视觉反刍”。

**Conclusion:** 单独的语音提示可以解锁记忆的视听内容，这在转录条件下的多模态生成中暴露了一个关键漏洞，对现代生成系统中的版权、安全和内容来源提出了紧迫问题。

> **ai_Abstract:** 本文介绍了对抗性语音提示（APT）攻击，揭示了歌词到歌曲（LS2）和文本到视频模型中存在的语音记忆漏洞。研究发现，即使歌词经过同音词替换而语义改变，LS2模型仍能重现训练数据中的音频内容，甚至文本到视频模型也能仅凭语音提示重建视觉元素。这表明多模态生成模型在处理语音信息时存在严重的安全和版权风险，对现代生成系统的内容溯源和版权保护提出了新的挑战。

> **摘要翻译:** 歌词到歌曲（LS2）生成模型承诺实现从文本到音乐的端到端合成，然而它们对训练数据记忆的脆弱性仍未得到充分探索。我们引入了对抗性语音提示（Adversarial PhoneTic Prompting, APT），这是一种新颖的攻击，通过同音词替换（例如，Eminem著名的“mom's spaghetti”→“Bob's confetti”）在语义上改变歌词，同时保留其声学结构。尽管存在这些扭曲，我们发现了一种强大的次词汇记忆形式：像SUNO和YuE这样的模型会重新生成与已知训练内容惊人相似的输出，并在CLAP、AudioJudge和CoverID等音频域指标上实现高相似度。这种漏洞在多种语言和流派中持续存在。更令人惊讶的是，我们发现仅通过语音改变的歌词就能触发文本到视频模型的视觉记忆。当用《Lose Yourself》中语音修改过的歌词进行提示时，Veo 3重建了原始音乐视频中的视觉元素——包括人物外观和场景构图——尽管提示中没有视觉线索。我们将这种现象称为语音到视觉反刍。总而言之，这些发现揭示了转录条件下的多模态生成中的一个关键漏洞：单独的语音提示可以解锁记忆的视听内容，对现代生成系统中的版权、安全和内容来源提出了紧迫问题。示例生成可在我们的演示页面（jrohsc.github.io/music_attack/）上找到。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [61] [Benchmarking Cross-Domain Audio-Visual Deception Detection](https://arxiv.org/abs/2405.06995)
> *跨领域音视频欺骗检测基准测试*

*Xiaobao Guo, Zitong Yu, Nithish Muthuchamy Selvaraj, Bingquan Shen, Adams Wai-Kin Kong, Alex C. Kot* | **Category: cs.SD, cs.CV, cs.MM, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 跨领域, 欺骗检测, 音视频, 泛化, 基准测试

**Comment:** 15 pages

> **TL;DR:** 本文介绍了首个跨领域音视频欺骗检测基准，旨在评估现有方法在真实场景中的泛化能力，并提出了新的算法（MM-IDGM和Attention-Mixer）来提高性能。

**AI_Comments:** 本文提出了一个急需的跨领域音视频欺骗检测基准，解决了现实应用中泛化能力的关键空白。所提出的MM-IDGM和Attention-Mixer方法是提高泛化能力和融合效果的创新尝试。其贡献在于提供了一个标准化的评估框架和新的技术，这对于该领域的发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自动欺骗检测对于协助人类准确评估真实性至关重要，但现有音视频欺骗检测方法在不同场景下的泛化能力尚未得到充分探索。

**Method:** 本文提出了首个跨领域音视频欺骗检测基准，用于评估现有方法在真实世界场景中的泛化能力。研究使用了广泛采用的音频和视觉特征以及不同的架构进行基准测试，比较了单域到单域和多域到单域的泛化性能。为了进一步利用来自多个源域的数据进行训练的影响，研究调查了三种域采样策略：域同步、域交替和逐域采样。此外，本文提出了一种名为“MM-IDGM”的算法，通过最大化模态编码器之间的梯度内积来增强泛化性能，并提出了Attention-Mixer融合方法以提高性能。

**Result:** 本文提出了首个跨领域音视频欺骗检测基准，该基准能够评估现有方法在真实世界场景中的泛化能力。所提出的Attention-Mixer融合方法提高了性能。

**Conclusion:** 新提出的跨领域基准将促进未来在音视频欺骗检测领域的研究，并且所提出的方法能够增强泛化能力和性能。

> **ai_Abstract:** 本文针对现有音视频欺骗检测方法泛化能力不足的问题，引入了首个跨领域基准测试。该研究评估了不同特征、架构和域采样策略对跨域泛化性能的影响。此外，论文提出了两种新颖的算法：MM-IDGM用于增强泛化能力，以及Attention-Mixer用于改进融合效果，旨在推动真实世界欺骗检测的研究进展。

> **摘要翻译:** 自动欺骗检测对于协助人类准确评估真实性和识别欺骗行为至关重要。传统的接触式技术，如测谎仪，依赖生理信号来确定个人陈述的真实性。然而，自动化欺骗检测的最新发展表明，源自音频和视频模态的多模态特征在公开数据集上可能优于人类观察者。尽管取得了这些积极的发现，但现有音视频欺骗检测方法在不同场景下的泛化能力在很大程度上仍未被探索。为了弥补这一空白，我们提出了首个跨领域音视频欺骗检测基准，使我们能够评估这些方法在真实世界场景中的泛化能力。我们使用了广泛采用的音频和视觉特征以及不同的架构进行基准测试，比较了单域到单域和多域到单域的泛化性能。为了进一步利用来自多个源域的数据进行训练的影响，我们研究了三种域采样策略，包括域同步、域交替和逐域采样，用于多域到单域的泛化评估。我们还提出了一种通过最大化模态编码器之间的梯度内积来增强泛化性能的算法，名为“MM-IDGM”。此外，我们提出了Attention-Mixer融合方法以提高性能，我们相信这个新的跨领域基准将促进未来在音视频欺骗检测领域的研究。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [374] [Information and motor constraints shape melodic diversity across cultures](https://arxiv.org/abs/2408.12635)
> *信息和运动约束塑造了跨文化的旋律多样性*

*John M McBride, Nahie Kim, Yuri Nishikawa, Mekhmed Saadakeev, Marcus T Pearce, Tsvi Tlusty* | **Category: cs.SD, cs.IT, eess.AS, math.IT, physics.soc-ph** | **Updated: 2025-07-24**

**Keywords:** 信息约束, 旋律多样性, 文化演变, 运动约束, 信息率

**Comment:** 

> **TL;DR:** 本研究探讨了信息和运动约束如何塑造跨文化旋律的多样性。研究发现，信息约束在文化传播过程中限制了音阶中的音符数量，并表明中等旋律复杂性反映了旋律文化演变的基本约束。

**AI_Comments:** 这项研究通过引入信息约束的概念来解释旋律的共同特征，是对现有运动约束假说的重要补充，从而提供了对旋律文化演变更全面的理解。其创新之处在于使用无参数模型预测音阶度分布，并对比分析了民间音乐和艺术音乐，揭示了不同文化传播方式可能带来的影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管旋律具有无限的潜在变异性，但来自不同社会的旋律却惊人地相似。运动约束假说可以解释某些相似性，但无法解释其他主要共同特征（如重复、歌曲长度和音阶大小）。本研究旨在调查信息约束在塑造这些旋律特征中的作用。

**Method:** 研究测量了跨越多个大洲的62个民间旋律语料库中信息率的决定因素，并与来自欧洲（包括土耳其）的39个艺术音乐语料库进行了对比。此外，还使用了一个无参数模型，利用标量运动、旋律长度和信息率的信息约束来预测经验音阶度分布。

**Result:** 研究发现，存在多种权衡，这些权衡都限制了跨社会的信息率。与民间音乐相比，艺术音乐表现出更长、更复杂的旋律，并且随着时间的推移复杂性增加。无参数模型成功地预测了经验音阶度分布。

**Conclusion:** 研究结果提供了强有力的证据，表明音乐文化传播过程中的信息约束限制了音阶中的音符数量，并表明中等旋律复杂性倾向反映了旋律文化演变的基本约束。

> **ai_Abstract:** 本研究探讨了信息和运动约束如何共同塑造跨文化旋律的多样性。研究人员分析了62个民间旋律语料库和39个艺术音乐语料库，发现信息约束通过多种权衡限制了音乐的信息率。结果表明，信息约束在文化传播中限制了音阶中的音符数量，并且中等旋律复杂性是旋律文化演变的一个基本约束。

> **摘要翻译:** 旋律的数量是深不可测的，然而尽管旋律变异的潜力几乎无限，但来自不同社会的旋律却可能惊人地相似。运动约束假说解释了某些相似性，例如音阶运动和轮廓形状，但未能解释其他主要共同特征，例如重复、歌曲长度和音阶大小。在这里，我们研究了信息约束在塑造这些旋律特征中的作用。我们测量了跨越多个大洲的62个民间旋律语料库中信息率的决定因素，发现了多种权衡，这些权衡都限制了跨社会的信息率。相比之下，来自欧洲（包括土耳其）的39个艺术音乐语料库显示出更长、更复杂的旋律，并且随着时间的推移复杂性增加，这表明艺术音乐和民间音乐中存在不同的文化演化选择压力，这可能是由于书面传播与口头传播的使用。我们的无参数模型利用标量运动、旋律长度以及最重要的信息率的信息约束来预测经验音阶度分布。这些结果提供了强有力的证据，表明音乐文化传播过程中的信息约束限制了音阶中的音符数量，并表明中等旋律复杂性倾向反映了旋律文化演变的基本约束。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [483] [Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability](https://arxiv.org/abs/2507.17851)
> *基于可解释性的语音预训练模型说话人解耦*

*Xiaoxu Zhu, Junhua Li* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-19**

**Keywords:** 说话人解耦, 语音预训练模型, 可解释性, 音色残余, SHAP

**Comment:** 20 pages, 9 figures, 2 tables

> **TL;DR:** 本研究提出了一种基于可解释性的方法，用于量化和减少语音预训练模型中的音色残余，从而实现说话人解耦，同时保留语音内容并提升相关任务性能。

**AI_Comments:** 本文的创新点在于首次提出了直接量化语音预训练模型中音色残余的基准，并利用可解释性技术（如SHAP）进行音色过滤，这为语音解耦领域提供了一个新颖且有效的视角。其模型无关的特性和在音色残余去除方面的显著效果，显示出该方法在提升语音处理任务性能和保护隐私方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 语音预训练模型中内容和音色信息解耦困难，移除说话人特定信息常导致内容丢失。当前研究缺乏直接指标来量化模型编码中的音色残余，主要依赖下游任务进行间接评估。

**Method:** 本研究通过基于可解释性的方法解决语音预训练模型中的说话人解耦问题。提出了InterpTRQE-SptME基准，这是一个使用可解释性的音色残余识别框架，通过Gradient SHAP Explainer量化音色残余。同时，提出了InterpTF-SptME方法，这是一种基于可解释性的音色过滤方法，利用SHAP Noise和SHAP Cropping技术转换中间编码，以去除音色并保留内容。

**Result:** 在VCTK数据集和HuBERT LARGE模型上的实验表明，本方法成功保留了内容并显著优化了说话人解耦。SHAP Noise方法能将音色残余从18.05%降低到接近0%，同时保持内容完整性。

**Conclusion:** 本研究提出的方法有助于提升内容相关语音处理任务的性能，并有效防止音色隐私泄露。

> **ai_Abstract:** 本论文提出了一种基于可解释性的新方法，以解决语音预训练模型中内容和音色信息解耦的难题。研究引入了InterpTRQE-SptME基准，用于直接量化模型嵌入中的音色残余，并开发了InterpTF-SptME方法（利用SHAP Noise和SHAP Cropping技术）来有效地过滤音色信息，同时确保内容完整性。实验结果表明，该方法能显著降低音色残余，为提升内容相关语音处理任务性能和保护音色隐私提供了有效途径。

> **摘要翻译:** 语音预训练模型在不同层包含特定任务信息，但解耦内容和音色信息仍然具有挑战性，因为移除说话人特定信息通常会导致内容丢失。当前研究缺乏直接指标来量化模型编码中的音色残余，依赖通过下游任务进行间接评估。本文通过语音预训练模型中基于可解释性的说话人解耦来解决这些挑战。我们定量评估模型嵌入中的音色残余，并利用解释性表示改进说话人解耦。我们的贡献包括：(1) InterpTRQE-SptME基准——一个使用可解释性的音色残余识别框架。该基准将内容嵌入与音色嵌入连接用于说话人分类，然后应用Gradient SHAP Explainer来量化音色残余。我们评估了七种语音预训练模型变体。(2) InterpTF-SptME方法——一种使用SHAP Noise和SHAP Cropping技术基于可解释性的音色过滤方法。这种模型无关的方法转换中间编码以去除音色同时保留内容。在VCTK数据集上使用HuBERT LARGE进行的实验表明，成功保留了内容并显著优化了说话人解耦。结果显示，SHAP Noise方法可以将音色残余从18.05%降低到接近0%，同时保持内容完整性，这有助于增强内容相关语音处理任务的性能并防止音色隐私泄露。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [567] [Resnet-conformer network with shared weights and attention mechanism for sound event localization, detection, and distance estimation](https://arxiv.org/abs/2507.17941)
> *基于Resnet-conformer共享权重和注意力机制的声事件定位、检测和距离估计网络*

*Quoc Thinh Vo, David Han* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-23**

**Keywords:** 声事件定位与检测, SELD, DCASE 2024, Resnet-conformer, 距离估计

**Comment:** This paper has been submitted as a technical report outlining our
  approach to Task 3A of the Detection and Classification of Acoustic Scenes
  and Events (DCASE) 2024 and can be found in DCASE2024 technical reports

> **TL;DR:** 针对DCASE 2024挑战赛，本文提出了一个基于EINV2的Resnet-conformer网络，结合对数梅尔频谱图和强度向量，并在声事件定位、检测和距离估计任务上取得了改进结果。

**AI_Comments:** 该论文的创新之处在于，它将基于EINV2的架构（特别是带有共享权重和注意力机制的Resnet-conformer）应用于具有挑战性的SELD任务，该任务现在包含了距离估计。报告的结果表明，该方法在DCASE 2024挑战赛中表现出具有竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在参与DCASE 2024挑战赛的Task 3A（声事件定位和检测，SELD），该任务通过估计声事件的定位和检测，为环境推理、导航等机器认知任务提供有价值的见解。今年的挑战引入了距离估计，使得评估更加全面。

**Method:** 该方法利用对数梅尔频谱图和强度向量作为输入，并采用多种数据增强技术。核心是提出了一种基于EINV2的网络架构，该架构在标题中明确指出是Resnet-conformer网络，并具有共享权重和注意力机制。该提交是针对挑战赛的纯音频（Track A）部分。

**Result:** 在开发数据集的测试集上，该方法取得了40.2%的F-score，17.7度的角度误差（DOA），以及0.32的相对距离误差（RDE）。

**Conclusion:** 该方法在DCASE 2024 Task 3A的声事件定位、检测和距离估计任务上取得了改进的结果。

> **ai_Abstract:** 本文描述了为DCASE 2024挑战赛任务3A（声事件定位、检测和距离估计，SELD）提出的方法，该方法仅使用音频输入。所提出的方法利用对数梅尔频谱图和强度向量，并结合多种数据增强技术，采用了一种基于EINV2的Resnet-conformer网络架构，该网络具有共享权重和注意力机制。在开发数据集的测试集上，该方法取得了40.2%的F-score、17.7度的角度误差和0.32的相对距离误差。

> **摘要翻译:** 本技术报告概述了我们参与2024年声学场景和事件检测与分类（DCASE）挑战赛任务3A的方法，重点是声事件定位和检测（SELD）。SELD通过估计声事件的定位和检测，提供有价值的见解，有助于各种机器认知任务，如环境推断、导航和其他与声定位相关的应用。今年的挑战通过在真实声场景的标注录音上使用纯音频（Track A）或视听（Track B）输入来评估模型。今年一个显著的变化是引入了距离估计，并相应调整了评估指标以进行全面评估。我们的提交是针对挑战赛的任务A，即纯音频赛道。我们的方法利用对数梅尔频谱图、强度向量，并采用了多种数据增强。我们提出了一种基于EINV2的网络架构，取得了改进的结果：在开发数据集的测试集上，F-score为40.2%，角度误差（DOA）为17.7度，相对距离误差（RDE）为0.32。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [568] [DIFFA: Large Language Diffusion Models Can Listen and Understand](https://arxiv.org/abs/2507.18452)
> *DIFFA：大型语言扩散模型能够倾听和理解*

*Jiaming Zhou, Hongjie Chen, Shiwan Zhao, Jian Kang, Jie Li, Enzhi Wang, Yujie Guo, Haoqin Sun, Hui Wang, Aobo Kong, Yong Qin, Xuelong Li* | **Category: cs.SD** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 音频理解, 大型语言模型, 语音驱动AI, DIFFA

**Comment:** 

> **TL;DR:** DIFFA是首个基于扩散的大型音频-语言模型，用于口语理解，在少量数据上训练后，在多个基准测试中表现出色。

**AI_Comments:** DIFFA的创新之处在于它是首个将扩散模型应用于大型音频-语言理解任务的工作，这为语音驱动的AI开辟了新方向。其双适配器架构和两阶段训练策略，特别是利用LLM生成合成数据来学习指令遵循能力，显著提升了模型在有限数据下的性能，展示了扩散模型在音频领域的高效性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）和扩散语言模型在文本和多模态领域取得了显著进展，但扩散模型在音频模态的应用仍未得到充分探索。本文旨在填补这一空白，探索扩散模型在口语理解方面的潜力。

**Method:** 本文提出了DIFFA，一个基于扩散的大型音频-语言模型，用于口语理解。DIFFA将一个冻结的扩散语言模型与一个轻量级的双适配器架构相结合，以连接语音理解和自然语言推理。该模型采用两阶段训练：首先通过ASR目标对齐语义表示；然后通过LLM自动生成的合成音频-字幕对学习指令遵循能力。

**Result:** DIFFA仅在960小时的ASR数据和127小时的合成指令数据上进行训练，但在MMSU、MMAU和VoiceBench等主要基准测试中表现出有竞争力的性能，并优于多个自回归开源基线模型。

**Conclusion:** 本研究揭示了基于扩散的语言模型在高效和可扩展的音频理解方面的巨大潜力，为语音驱动的AI开辟了新的方向。

> **ai_Abstract:** DIFFA是首个基于扩散的大型音频-语言模型（LA-LM），旨在实现口语理解。它结合了冻结的扩散语言模型和双适配器架构，并通过两阶段训练（ASR语义对齐和LLM生成的合成数据指令学习）进行优化。尽管训练数据量较小，DIFFA在多个主流基准测试中表现出色，超越了现有自回归模型，证明了扩散模型在高效音频理解方面的巨大潜力。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展在文本和多模态领域展现了卓越的能力。与此同时，基于扩散的语言模型作为自回归范式的有前景的替代方案出现，提供了改进的可控性、双向上下文建模和鲁棒的生成能力。然而，它们在音频模态的应用仍未得到充分探索。在这项工作中，我们介绍了DIFFA，这是第一个基于扩散的大型音频-语言模型，旨在执行口语理解。DIFFA将一个冻结的扩散语言模型与一个轻量级的双适配器架构集成，该架构桥接了语音理解和自然语言推理。我们采用两阶段训练流程：首先，通过ASR目标对齐语义表示；然后，通过提示LLM自动生成的合成音频-字幕对学习指令遵循能力。尽管仅在960小时的ASR数据和127小时的合成指令数据上进行训练，DIFFA在包括MMSU、MMAU和VoiceBench在内的主要基准测试中展现出有竞争力的性能，超越了几个自回归开源基线。我们的结果揭示了基于扩散的语言模型在高效和可扩展的音频理解方面的潜力，为语音驱动的AI开辟了新方向。我们的代码将在https://github.com/NKU-HLT/DIFFA.git上提供。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [615] [The TEA-ASLP System for Multilingual Conversational Speech Recognition and Speech Diarization in MLC-SLM 2025 Challenge](https://arxiv.org/abs/2507.18051)
> *MLC-SLM 2025挑战赛中用于多语言对话语音识别和语音分离的TEA-ASLP系统*

*Hongfei Xue, Kaixun Huang, Zhikai Zhou, Shen Huang, Shidong Shang* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 多语言语音识别, 语音分离, MLC-SLM 2025挑战赛, Ideal-LLM, MOE LoRA

**Comment:** Interspeech 2025 workshop

> **TL;DR:** TEA-ASLP团队在MLC-SLM 2025挑战赛中提交了多语言对话ASR和语音分离ASR系统，通过改进模型和优化方法，在两项任务中分别获得第一和第二名。

**AI_Comments:** 该论文展示了在多语言ASR和语音分离方面结合先进模型（如Ideal-LLM增强、MOE LoRA）和大规模数据训练的有效性。其在挑战赛中取得的优异成绩（第一和第二名）证明了所提出方法的实用性和竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 参与MLC-SLM 2025挑战赛，解决多语言对话自动语音识别（ASR）和语音分离ASR问题。

**Method:** 对于任务一（多语言对话ASR），通过整合已知语言识别和多语言MOE LoRA结构来增强Ideal-LLM模型，并使用CTC预测的token作为提示改进自回归生成，模型在约18万小时的多语言ASR数据上训练。对于任务二（语音分离ASR），将基线中英双语说话人分离模型替换为更适合的纯英语版本。

**Result:** 与基线语音语言模型相比，词错误率（WER）降低了30.8%。在任务一中，最终WER为9.60%，获得第一名。在任务二中，时间受限最小置换WER为17.49%，获得第二名。

**Conclusion:** TEA-ASLP系统在MLC-SLM 2025挑战赛的多语言对话ASR和语音分离ASR任务中表现出色，分别获得第一和第二名，证明了其方法的有效性和竞争力。

> **ai_Abstract:** TEA-ASLP团队在MLC-SLM 2025挑战赛中提交了其多语言对话ASR和语音分离ASR系统。在多语言ASR任务中，通过改进Ideal-LLM模型并利用大量多语言数据训练，实现了9.60%的WER并获得第一名。在语音分离ASR任务中，通过优化说话人分离模型，取得了17.49%的WER并获得第二名，系统整体WER比基线降低30.8%。

> **摘要翻译:** 本文介绍了TEA-ASLP团队提交给MLC-SLM 2025挑战赛的系统，该系统旨在解决任务一中的多语言对话自动语音识别（ASR）和任务二中的语音分离ASR问题。对于任务一，我们通过整合已知语言识别和多语言MOE LoRA结构，并使用CTC预测的token作为提示来改进自回归生成，从而增强了Ideal-LLM模型。该模型在约18万小时的多语言ASR数据上进行训练。在任务二中，我们将基线中英说话人分离模型替换为更适合的纯英语版本。我们的方法与基线语音语言模型相比，词错误率（WER）降低了30.8%，在任务一中最终WER为9.60%，在任务二中时间受限最小置换WER为17.49%，分别在各自的挑战任务中获得第一名和第二名。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='mathdg'></a>
## math.DG 

### [17] [Jacobi Hamiltonian Integrators](https://arxiv.org/abs/2507.18573)
> *雅可比哈密顿积分器*

*Adérito Araújo, Gonçalo Inocêncio Oliveira, João Nuno Mestre* | **Category: math.DG, cs.NA, math-ph, math.MP, math.NA, math.SG, 37M15 (Primary) 53D17, 37J39 (Secondary)** | **Updated: 2025-07-24**

**Keywords:** 雅可比哈密顿积分器, 结构保持积分器, 雅可比流形, 齐次泊松流形, 几何积分器

**Comment:** 32 pages

> **TL;DR:** 本文开发了一种在雅可比流形中构建哈密顿系统结构保持积分器的方法，通过利用雅可比流形与齐次泊松流形之间的对应关系，扩展了泊松哈密顿积分器技术，适用于处理时变和耗散系统。

**AI_Comments:** 这项工作通过将雅可比流形与齐次泊松流形联系起来，巧妙地扩展了几何积分器在更广泛系统（包括时变和耗散系统）中的应用范围。其创新性在于为处理非保守系统提供了结构保持的数值方法，对于物理建模和数值模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的哈密顿力学主要用于保守系统建模，而雅可比流形能够推广此理论，适用于包含时变、耗散和热力学现象的系统。因此，需要为雅可比流形中的哈密顿系统开发结构保持积分器。

**Method:** 该方法构建了雅可比哈密顿积分器，其核心在于探索雅可比流形与齐次泊松流形之间的对应关系，并在此基础上扩展泊松哈密顿积分器（PHI）技术，同时确保齐次结构的保持。

**Result:** 论文开发了泛化所需的理论工具，并概述了一种与雅可比动力学兼容的数值积分技术。通过关注齐次泊松视角而非直接接触实现，为雅可比框架内时变和耗散系统的结构保持积分提供了清晰的路径。

**Conclusion:** 本文通过利用雅可比与齐次泊松流形之间的对应关系，成功开发了雅可比哈密顿积分器，为处理时变和耗散系统的结构保持数值积分提供了有效且清晰的方法。

> **ai_Abstract:** 本文提出了一种用于雅可比流形中哈密顿系统的结构保持积分器——雅可比哈密顿积分器。鉴于雅可比流形能够描述时变、耗散和热力学现象，该工作通过利用雅可比流形与齐次泊松流形之间的对应关系，扩展了现有的泊松哈密顿积分器技术，并确保了齐次结构的保持。研究开发了所需的理论工具和数值积分技术，为在雅可比框架内对时变和耗散系统进行结构保持积分提供了新的途径。

> **摘要翻译:** 我们开发了一种在雅可比流形中构建哈密顿系统结构保持积分器的方法。哈密顿力学植根于辛几何和泊松几何，长期以来为经典物理学中的保守系统建模提供了基础。雅可比流形概括了接触流形和泊松流形，扩展了这一理论，适用于包含时变、耗散和热力学现象。
基于几何积分器——特别是泊松哈密顿积分器（PHI）——的最新进展，我们提出了一种雅可比哈密顿积分器的构建方法。我们的方法探索了雅可比流形与齐次泊松流形之间的对应关系，旨在扩展PHI技术，同时确保齐次结构的保持。
这项工作开发了这种泛化所需的理论工具，并概述了一种与雅可比动力学兼容的数值积分技术。通过关注齐次泊松视角而非直接接触实现，我们为雅可比框架内时变和耗散系统的结构保持积分提供了清晰的路径。

</details>

[⬆️ 返回分类顶部](#mathdg) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [35] [Diffusion-Assisted Frequency Attention Model for Whole-body Low-field MRI Reconstruction](https://arxiv.org/abs/2507.17764)
> *全身低场MRI重建的扩散辅助频率注意力模型*

*Xin Xie, Yu Guan, Zhuoxu Cui, Dong Liang, Qiegen Liu* | **Category: physics.med-ph, cs.CV** | **Updated: 2025-07-09**

**Keywords:** 低场MRI重建, 扩散模型, 频率注意力, DFAM, 低信噪比

**Comment:** 29 pages,7 figures

> **TL;DR:** DFAM模型结合扩散模型和频率域注意力，显著提升低信噪比条件下低场MRI重建性能。

**AI_Comments:** 该研究通过结合扩散模型和频率域注意力，为低场MRI重建提供了一种创新方法，特别针对低信噪比环境下的性能提升，具有重要的临床应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限或欠发达的临床环境中，提高低场MRI的重建性能。

**Method:** 提出了扩散辅助频率注意力模型（DFAM），该模型结合了扩散模型的生成能力和频率域注意力的表示能力。

**Result:** DFAM在低信噪比条件下有效增强了重建性能，并且表现优于传统重建算法和近期基于学习的方法。

**Conclusion:** DFAM在推进低场MRI重建方面具有潜力，特别是在资源受限或欠发达的临床环境中。

> **ai_Abstract:** 本文提出了一种扩散辅助频率注意力模型（DFAM），该模型结合了扩散模型和频率域注意力机制，以提高低信噪比条件下的全身低场MRI重建性能。实验证明，DFAM在重建表现上优于现有传统及基于学习的方法，显示出其在资源受限临床环境中推动低场MRI重建的巨大潜力。

> **摘要翻译:** 通过整合扩散模型的生成优势与频域注意力的表示能力，DFAM在低信噪比条件下有效提升了重建性能。实验结果表明，DFAM持续优于传统的重建算法和近期基于学习的方法。这些发现突出了DFAM作为一种有前景的解决方案，在推进低场MRI重建方面的潜力，特别是在资源受限或欠发达的临床环境中。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [598] [Design and fabrication of ultrasound linear array transducer used in ultrasound endoscope](https://arxiv.org/abs/2507.18628)
> *超声内窥镜用超声线性阵列换能器的设计与制造*

*Yuan Zhang, Mingtong Chen, Zhengbao Yang* | **Category: physics.med-ph, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 超声内窥镜, 线性阵列换能器, 超声成像平台, 微创应用, 探头设计

**Comment:** 

> **TL;DR:** 本研究成功构建了一个超声成像平台并设计制造了用于微创内窥镜应用的新型超声内窥镜探头。

**AI_Comments:** 该论文的创新点在于将现成的TI评估模块与自主设计的微型化超声内窥镜探头相结合，为微创超声成像提供了一个集成解决方案。其重要性体现在为特定医疗应用领域提供了潜在的诊断工具。然而，摘要中未提及具体的性能评估数据或临床验证。

<details>
  <summary>Details</summary>

**Motivation:** 该项目的主要目标是建立一个功能性系统，用于获取和处理超声信号，特别是针对微创内窥镜应用。

**Method:** 研究基于德州仪器 (TI) 评估模块 (EVMs) 开发了一个超声成像平台，该平台支持32通道高压信号传输和回波信号接收，具备片上信号放大、采集能力，并集成了TGC和CWD路径。同时，设计并制造了一个64单元、5MHz中心频率的相控阵线性超声内窥镜探头，并完成了其匹配层、背衬层、2-2压电复合材料和电极的制作与组装。

**Result:** 成功构建了超声成像平台，该平台能够传输32通道高压信号并接收回波，支持线性阵列、凸阵列和相控阵探头成像。同时，成功设计并制造了一个64单元、5MHz的微型化相控阵线性超声内窥镜探头，并完成了关键部件的组装。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文描述了用于微创内窥镜应用的超声成像平台和新型超声内窥镜探头的设计与制造。该平台基于TI EVMs，支持多通道信号传输、接收和处理，并集成了TGC和CWD功能，兼容多种阵列探头。同时，成功开发了一个64单元、5MHz的相控阵线性超声内窥镜探头，并完成了其核心部件的制造和组装。

> **摘要翻译:** 本报告详细介绍了超声成像平台的成功构建以及新型超声内窥镜探头的设计与制造。该项目的主要目标是建立一个用于获取和处理超声信号的功能系统，特别针对微创内窥镜应用。超声成像平台主要基于德州仪器 (TI) 评估模块 (EVMs) 设计开发。它能够传输32通道高压信号和接收回波信号，并具备片上信号放大和采集能力。此外，该平台集成了完整的时增益控制 (TGC) 成像路径和连续波多普勒 (CWD) 路径。结合主机电脑软件，它支持线性阵列、凸阵列和相控阵探头的成像。同时，设计了一个64单元、5MHz中心频率的相控阵线性超声内窥镜探头，旨在实现小型化和最佳成像性能。其匹配层、背衬层、2-2压电复合材料和电极的制造和组装已完成。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsacc-ph'></a>
## physics.acc-ph 

### [40] [A Supervised Machine Learning Framework for Multipactor Breakdown Prediction in High-Power Radio Frequency Devices and Accelerator Components: A Case Study in Planar Geometry](https://arxiv.org/abs/2507.17881)
> *高功率射频器件和加速器组件中多重击穿预测的监督机器学习框架：平面几何案例研究*

*Asif Iqbal, John Verboncoeur, Peng Zhang* | **Category: physics.acc-ph, cs.LG, physics.app-ph, physics.plasm-ph** | **Updated: 2025-07-23**

**Keywords:** 多重击穿, 机器学习, 射频设备, 预测, 加速器组件

**Comment:** 

> **TL;DR:** 使用监督机器学习预测高功率射频设备中的多重击穿现象，并评估了不同模型的性能和局限性。

**AI_Comments:** 这项研究的创新之处在于首次将监督机器学习应用于多重击穿预测，为解决传统计算密集型挑战提供了新途径。它不仅展示了机器学习在加速器组件设计中的巨大潜力，也坦诚地指出了当前方法的局限性，即需要更广泛的数据集覆盖来解决不同材料特征空间分布不一致的问题，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 多重击穿是一种非线性电子雪崩现象，会严重损害高功率射频设备和加速器系统的性能。在加速器组件设计和射频工程中，准确预测不同材料和操作状态下的多重击穿敏感性仍然是一个关键但计算密集型的挑战。

**Method:** 本研究首次应用监督机器学习来预测双表面平面几何中的多重击穿敏感性。使用跨越六种不同二次电子产额（SEY）材料剖面的模拟数据集来训练回归模型，包括随机森林（RF）、Extra Trees（ET）、极端梯度提升（XGBoost）和漏斗结构多层感知器（MLP），以预测时间平均电子增长率${\delta}_{avg}$。性能评估使用交并比（IoU）、结构相似性指数（SSIM）和皮尔逊相关系数。

**Result:** 树形模型在跨不相交材料域的泛化能力上始终优于MLP。使用结合了IoU和SSIM的标量化目标函数进行贝叶斯超参数优化并采用5折交叉验证训练的MLP，其性能优于使用单目标损失函数训练的MLP。主成分分析表明，某些材料的性能下降源于不相交的特征空间分布，这强调了需要更广泛的数据集覆盖。

**Conclusion:** 本研究展示了基于机器学习的多重击穿预测的潜力和局限性，并为先进射频和加速器系统设计中加速的数据驱动建模奠定了基础。

> **ai_Abstract:** 本研究首次探索了监督机器学习在预测高功率射频设备和加速器组件中多重击穿现象的应用。通过使用模拟数据集训练了包括随机森林、Extra Trees、XGBoost和多层感知器在内的回归模型，以预测时间平均电子增长率。研究发现树形模型在泛化能力上优于MLP，并且结合多目标损失函数训练的MLP表现更好。同时，研究也揭示了由于特征空间分布差异导致的性能局限性，并强调了更广泛数据集覆盖的重要性，为未来数据驱动的射频和加速器系统设计奠定了基础。

> **摘要翻译:** 多重击穿是一种非线性电子雪崩现象，会严重损害高功率射频（RF）设备和加速器系统的性能。在加速器组件设计和射频工程中，准确预测不同材料和操作状态下的多重击穿敏感性仍然是一个关键但计算密集型的挑战。本研究首次应用监督机器学习（ML）来预测双表面平面几何中的多重击穿敏感性。使用跨越六种不同二次电子产额（SEY）材料剖面的模拟数据集来训练回归模型——包括随机森林（RF）、Extra Trees（ET）、极端梯度提升（XGBoost）和漏斗结构多层感知器（MLP）——以预测时间平均电子增长率${\delta}_{avg}$。性能评估使用交并比（IoU）、结构相似性指数（SSIM）和皮尔逊相关系数。树形模型在跨不相交材料域的泛化能力上始终优于MLP。使用结合了IoU和SSIM的标量化目标函数进行贝叶斯超参数优化并采用5折交叉验证训练的MLP，其性能优于使用单目标损失函数训练的MLP。主成分分析表明，某些材料的性能下降源于不相交的特征空间分布，这强调了需要更广泛的数据集覆盖。本研究展示了基于机器学习的多重击穿预测的潜力和局限性，并为先进射频和加速器系统设计中加速的数据驱动建模奠定了基础。

</details>

[⬆️ 返回分类顶部](#physicsacc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [42] [Orthogonal Constrained Minimization with Tensor $\ell_{2,p}$ Regularization for HSI Denoising and Destriping](https://arxiv.org/abs/2407.03605)
> *带有张量 $\ell_{2,p}$ 正则化的正交约束最小化用于高光谱图像去噪和去条纹*

*Xiaoxia Liu, Shijie Yu, Jian Lu, Xiaojun Chen* | **Category: math.OC, cs.CV, 68U10, 90C26, 15A18, 65F22** | **Updated: 2025-07-24**

**Keywords:** 高光谱图像, 去噪, 去条纹, 张量 $\ell_{2,p}$ 正则化, 低秩

**Comment:** 

> **TL;DR:** 本文提出了一种名为MLTL2p的多尺度低秩张量正则化方法，用于高光谱图像（HSI）的去噪和去条纹，该方法基于正交约束最小化模型和迭代算法，并在实验中表现出优于现有方法的性能。

**AI_Comments:** 本文创新性地结合了多尺度低秩张量正则化和非凸的张量 $\ell_{2,p}$ 范数，并利用HOSVD进行稀疏性增强，以更有效地处理高光谱图像的复杂噪声。算法具备收敛性保证，增强了方法的理论可靠性。在与深度学习方法进行比较并取得优异表现，凸显了其在传统优化方法中的竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱图像（HSIs）经常受到多种噪声的污染，如高斯噪声、死线和条纹等，这影响了图像质量和后续应用。

**Method:** 本文提出了一种多尺度低秩张量正则化 $\ell_{2,p}$ (MLTL2p) 方法。该方法构建于一种新的稀疏性增强多尺度低秩张量正则化和张量 $\ell_{2,p}$ 范数（其中 $p \in (0,1)$）之上。多尺度低秩正则化利用了HSIs的全局和局部光谱相关性以及空间非局部自相似先验。低秩约束通过独立高阶奇异值分解（HOSVD）并在其核心张量上进行稀疏性增强来制定。张量 $\ell_{2,p}$ 范数是矩阵 $\ell_{2,p}$ 范数的扩展。为了解决由此产生的非凸非光滑正交约束最小化问题，提出了一种近端块坐标下降算法，并证明了算法生成的序列的任何累积点都收敛到一阶稳定点。

**Result:** 在数值实验中，MLTL2p方法与包括基于深度学习的方法在内的最先进方法进行了比较，并在模拟和真实HSI数据集上进行了测试。结果表明，所提出的MLTL2p方法在平均峰值信噪比等指标以及视觉质量方面均表现出优异性能。

**Conclusion:** 本文提出的MLTL2p方法通过结合多尺度低秩张量正则化和张量 $\ell_{2,p}$ 范数，有效解决了高光谱图像的去噪和去条纹问题，并在性能上超越了现有先进方法。

> **ai_Abstract:** 本文提出了一种名为MLTL2p的多尺度低秩张量正则化 $\ell_{2,p}$ 方法，用于高光谱图像（HSI）的去噪和去条纹。该方法通过结合稀疏性增强的多尺度低秩张量正则化和张量 $\ell_{2,p}$ 范数，构建了一个正交约束最小化模型。为解决此非凸非光滑问题，提出了一种近端块坐标下降算法并证明了其收敛性。实验结果表明，MLTL2p方法在去噪和去条纹性能上优于现有的先进方法。

> **摘要翻译:** 高光谱图像（HSIs）经常受到多种噪声的污染，如高斯噪声、死线和条纹等。在本文中，我们提出了一种多尺度低秩张量正则化 $\ell_{2,p}$ (MLTL2p) 方法，用于HSI去噪和去条纹，该方法包含一个正交约束最小化模型和一个具有收敛保证的迭代算法。所提出的MLTL2p方法的模型是基于一种新的稀疏性增强多尺度低秩张量正则化和张量 $\ell_{2,p}$ 范数（其中 $p \in (0,1)$）构建的。用于HSI去噪的多尺度低秩正则化利用了HSIs的全局和局部光谱相关性以及空间非局部自相似先验。相应的低秩约束是基于独立高阶奇异值分解（HOSVD）并在其核心张量上进行稀疏性增强以促进更强的低秩性而制定的。用于HSI去条纹的张量 $\ell_{2,p}$ 范数是从矩阵 $\ell_{2,p}$ 范数扩展而来的。MLTL2p方法中提出了一种近端块坐标下降算法来解决由此产生的非凸非光滑正交约束最小化问题。我们证明了所提算法生成的序列的任何累积点都收敛到一阶稳定点，该稳定点通过子平稳性、对称性和正交约束的可行性这三个等式定义。在数值实验中，我们将所提方法与包括基于深度学习的方法在内的最先进方法进行了比较，并在模拟和真实HSI数据集上进行了测试。我们提出的MLTL2p方法在平均峰值信噪比等指标以及视觉质量方面均表现出优异性能。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [206] [Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control I: Penalty Approach](https://arxiv.org/abs/2507.18114)
> *非凸优化框架用于组稀疏反馈线性二次最优控制I：惩罚方法*

*Lechen Feng, Xun Li, Yuan-Hua Ni* | **Category: math.OC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 组稀疏控制, 非凸优化, 线性二次调节器, 惩罚方法, PALM算法

**Comment:** 

> **TL;DR:** 本文提出了一个统一的非凸优化框架，用于设计无限时域线性二次问题中的组稀疏反馈控制器，并提供了一种基于惩罚的算法及其收敛性分析。

**AI_Comments:** 创新点在于直接采用非凸优化和$\ell_0$范数正则化来处理组稀疏控制器设计，避免了传统凸松弛或限制性结构假设的缺点。所提出的PALM算法及其收敛性分析为这类复杂问题提供了理论保证。重要性体现在为大规模系统中的可伸缩和结构感知控制提供了新的、更直接的设计方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法依赖凸松弛或仅限于块对角结构，无法直接设计具有理论保证的组稀疏反馈增益。本文旨在解决大规模系统中对可伸缩和结构感知控制的需求，并填补直接设计组稀疏反馈增益的理论空白。

**Method:** 本文开发了一个统一的非凸优化框架，将控制器综合直接公式化为具有组$\\ell_0$范数正则化的有限维非凸优化问题。提出了一种基于惩罚的近端交替线性化最小化（PALM）算法，并提供了严格的收敛性分析。

**Result:** 建立了分布式LQ问题（DFT-LQ）和稀疏反馈LQ问题（SF-LQ）之间的联系，表明两者都可在统一框架内解决。所提出的方法对所有子问题都支持高效求解，并保证全局收敛到临界点。

**Conclusion:** 本文成功开发了一个统一的非凸优化框架和一种基于惩罚的PALM算法，能够直接设计具有理论保证的组稀疏反馈增益，克服了现有方法对凸替代或限制性结构假设的依赖。

> **ai_Abstract:** 本文提出了一个统一的非凸优化框架，用于在无限时域线性二次问题中设计组稀疏反馈控制器。该框架通过组$\ell_0$范数正则化将控制器综合直接表述为有限维非凸优化问题，以应对分布式和稀疏反馈LQ问题中大规模系统对可伸缩和结构感知控制的需求。研究建立了DFT-LQ和SF-LQ问题之间的联系，并提出了一个基于惩罚的PALM算法，提供了严格的收敛性分析。该方法能够高效求解子问题并保证全局收敛，从而填补了直接设计具有理论保证的组稀疏反馈增益的文献空白。

> **摘要翻译:** 本文开发了一个统一的非凸优化框架，用于设计无限时域线性二次（LQ）问题中的组稀疏反馈控制器。我们解决了经典LQ问题的两个突出扩展：具有固定通信拓扑的分布式LQ问题（DFT-LQ）和稀疏反馈LQ问题（SF-LQ），两者都是由大规模系统中对可伸缩和结构感知控制的需求所驱动的。与依赖凸松弛或仅限于块对角结构的现有方法不同，我们直接将控制器综合公式化为一个具有组$\ell_0$范数正则化的有限维非凸优化问题，捕捉一般的稀疏模式。我们建立了DFT-LQ和SF-LQ问题之间的联系，表明两者都可以在我们统一的框架内解决。此外，我们提出了一种基于惩罚的近端交替线性化最小化（PALM）算法，并在温和假设下提供了严格的收敛性分析，克服了目标函数缺乏强制性的问题。所提出的方法对所有子问题都支持高效的求解器，并保证全局收敛到临界点。我们的结果填补了文献中的一个关键空白，通过直接设计具有理论保证的组稀疏反馈增益，而无需诉诸凸替代或限制性结构假设。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [352] [Provably Convergent Plug-and-play Proximal Block Coordinate Descent Method for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2412.14824)
> *高光谱异常检测的可证明收敛即插即用近端块坐标下降方法*

*Xiaoxia Liu, Shijie YU* | **Category: math.OC, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 高光谱异常检测, 即插即用, 近端块坐标下降, 低秩表示, 去噪

**Comment:** 

> **TL;DR:** 本文提出了一种基于低秩表示和即插即用框架的新型高光谱异常检测模型，并开发了可证明收敛的PnP-PBCD方法，在有无噪声情况下均表现出色。

**AI_Comments:** 本文的创新点在于将低秩表示模型与即插即用（PnP）框架相结合，并融入了基于深度学习的去噪先验，以解决高光谱异常检测中的噪声问题。同时，提出的PnP-PBCD方法具有严格的理论收敛性证明，增强了方法的可靠性。其重要性在于提供了一种在复杂噪声环境下也能有效识别异常的鲁棒解决方案，弥补了现有方法在噪声干扰下性能不佳的缺陷。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱异常检测需要识别高光谱图像中光谱特性与背景显著不同的像素。现有方法可能将噪声误识别为异常或因噪声干扰而漏识别异常对象，因此需要一种更鲁棒的方法来解决这些问题。

**Method:** 本文引入了一个新颖的模型，该模型使用低秩表示来表示背景信息。它将一个与深度学习去噪器相关的隐式近端去噪先验集成到一个即插即用（PnP）框架中，以有效去除与低秩表示相关的特征图像中的噪声。异常通过广义组稀疏度量$\|\cdot\|_{2,\psi}$来表征。为解决由此产生的正交约束非凸非光滑优化问题，开发了一种PnP-近端块坐标下降（PnP-PBCD）方法，其中特征图像使用PnP框架内的近端去噪器进行更新。

**Result:** 所提出的PnP-PBCD方法能够有效检测异常对象，并且在有无高斯噪声污染的情况下，其性能优于可能将噪声误识别为异常或因噪声干扰而错误识别异常对象的竞争方法。

**Conclusion:** PnP-PBCD方法是一种有效且鲁棒的高光谱异常检测方法，特别是在存在噪声干扰的情况下，能够准确识别异常，并具有理论收敛性保证。

> **ai_Abstract:** 本文提出了一种用于高光谱异常检测的新型模型和算法。该模型利用低秩表示背景信息，并将基于深度学习的去噪器与即插即用框架相结合以处理噪声。异常通过广义组稀疏度量进行表征。为了解决由此产生的复杂优化问题，作者开发了可证明收敛的即插即用近端块坐标下降（PnP-PBCD）方法。实验结果表明，该方法在有无噪声环境下均能有效、准确地检测异常，并优于现有方法。

> **摘要翻译:** 高光谱异常检测是指识别高光谱图像中光谱特性与背景显著不同的像素。在本文中，我们引入了一种新颖的模型，该模型使用低秩表示来表示背景信息。我们将与基于深度学习去噪器相关的隐式近端去噪先验集成到即插即用（PnP）框架中，以有效去除与低秩表示相关的特征图像中的噪声。异常使用广义组稀疏度量$\|\cdot\|_{2,\psi}$来表征。为了解决由此产生的正交约束非凸非光滑优化问题，我们开发了一种PnP-近端块坐标下降（PnP-PBCD）方法，其中特征图像使用PnP框架内的近端去噪器进行更新。我们证明了PnP-PBCD方法生成的序列的任何累积点都是一个驻点。我们在有无高斯噪声污染的情况下评估了PnP-PBCD方法在高光谱异常检测中的有效性。结果表明，所提出的方法可以有效检测异常对象，优于可能将噪声误识别为异常或因噪声干扰而错误识别异常对象的竞争方法。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [507] [Sparse optimal control for infinite-dimensional linear systems with applications to graphon control](https://arxiv.org/abs/2507.18030)
> *无限维线性系统的稀疏最优控制及其在图论控制中的应用*

*Takuya Ikeda, Masaaki Nagahara* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 稀疏最优控制, 无限维系统, 图论, L1优化, 网络系统

**Comment:** 16 pages

> **TL;DR:** 本文研究了无限维线性系统的稀疏最优控制，并将其应用于图论网络系统，通过L1优化和图论逼近解决了资源约束和网络结构未知的问题。

**AI_Comments:** 该论文在处理大规模网络系统的资源约束和网络结构未知问题上具有创新性。通过结合稀疏控制、L1优化和图论（graphon）理论，为无限维系统提供了一种新的控制方法。特别是引入图论来近似复杂网络结构，以及证明了稀疏控制与L1优化和特定非凸问题解的关联，是其重要贡献。这对于理解和控制大型复杂系统具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大规模网络系统通常在资源受限下运行，并且难以精确获取节点间的网络结构。为解决这些问题，本文研究了无限维线性系统的稀疏最优控制及其在网络系统中的应用。

**Method:** 本文通过推导在何种条件下稀疏最优控制可以通过求解其对应的L1优化问题获得，从而降低计算复杂度。此外，引入了一类非凸最优控制问题，使得在这些问题存在最优解的情况下，最优解总是与稀疏最优控制一致。同时，证明了大规模有限维网络系统的稀疏最优控制可以通过相应的极限图论系统进行近似，前提是底层图在割范数拓扑中接近极限图论。

**Result:** 推导出了稀疏最优控制可通过求解L1优化问题获得的充分条件。提出了一类非凸最优控制问题，其最优解与稀疏最优控制一致。证明了大规模有限维网络系统的稀疏最优控制可以由相应的极限图论系统近似。

**Conclusion:** 本文为解决大规模网络系统中的资源约束和网络结构未知问题，提出了无限维线性系统的稀疏最优控制方法，并通过L1优化和图论近似提供了有效的解决方案，并通过数值示例验证了其有效性。

> **ai_Abstract:** 本文研究了无限维线性系统的稀疏最优控制及其在以图论表示网络结构的网络系统中的应用，以解决大规模网络系统面临的资源约束和网络结构难以精确获取的问题。文章主要贡献包括：一是推导了稀疏最优控制可通过求解L1优化问题获得的充分条件，并引入了一类非凸最优控制问题，其最优解与稀疏最优控制一致，以降低计算复杂度；二是证明了大规模有限维网络系统的稀疏最优控制可以通过相应的极限图论系统进行近似。所提出的方法的有效性通过数值示例得到了验证。

> **摘要翻译:** 大规模网络系统通常在资源受限下运行，并且难以精确获取节点间的网络结构。为解决这些问题，本文研究了无限维线性系统的稀疏最优控制及其在网络系统中的应用，其中网络结构由称为图论的极限函数表示，该函数捕获了整体连接模式。本文的贡献有两方面：(i) 为了降低计算复杂度，我们推导出了稀疏最优控制可以通过求解其对应的L1优化问题获得的充分条件。此外，我们引入了一类非凸最优控制问题，使得只要非凸问题存在最优解，最优解总是与稀疏最优控制一致。(ii) 我们表明，大规模有限维网络系统的稀疏最优控制可以通过相应的极限图论系统进行近似，前提是底层图在割范数拓扑中接近极限图论。所提出方法的有效性通过数值示例进行了说明。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [548] [Partial-State DADS Control for Matched Unmodeled Dynamics](https://arxiv.org/abs/2507.18609)
> *部分状态DADS控制用于匹配的未建模动力学*

*Iasson Karafyllis, Miroslav Krstic* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** DADS控制, 未建模动力学, 鲁棒调节, 部分状态反馈, 无限维系统

**Comment:** 28 pages. arXiv admin note: text overlap with arXiv:2311.07938,
  arXiv:2402.17222, arXiv:2410.16691

> **TL;DR:** 扩展了DADS控制，使其能处理具有未知边界扰动和参数的匹配未建模动态系统，包括无限维情况，实现鲁棒调节且无增益和状态漂移。

**AI_Comments:** 这项研究的创新之处在于DADS控制能够处理无已知边界的扰动和未知参数，并能绕过小增益条件，这对于实际应用中常见的强不确定性系统非常重要。此外，其在无限维系统中的适用性展示了该方法的强大普适性。

<details>
  <summary>Details</summary>

**Motivation:** 针对具有满足匹配条件且扰动和未知参数无已知边界的动态不确定性的时不变系统，实现鲁棒调节。

**Method:** 将死区自适应扰动抑制（DADS）控制扩展到具有动态不确定性的时不变系统，这些系统满足匹配条件且扰动和未知参数的边界未知。该方法等同于部分状态自适应反馈，其中动态不确定性建模的状态是未测量的。

**Result:** DADS控制器能够绕过小增益条件，即使互连强度没有已知边界也能实现系统的鲁棒调节。此外，无论扰动和未知参数的大小如何，都不会出现增益和状态漂移。即使在未测量状态是无限维的情况下（由反应扩散偏微分方程描述），DADS控制器也能设计并保证植物状态的鲁棒调节。

**Conclusion:** DADS控制器可以有效地处理具有未知边界扰动和参数的匹配未建模动力学系统，包括无限维情况，并保证鲁棒调节且无增益和状态漂移。

> **ai_Abstract:** 本文扩展了死区自适应扰动抑制（DADS）控制方法，以处理具有匹配条件且扰动和未知参数边界均未知的时不变动态不确定性系统。研究表明，DADS控制器能够绕过传统的小增益条件，实现鲁棒调节，且不产生增益和状态漂移。特别地，该方法还被证明适用于由偏微分方程描述的无限维未测量状态系统，并能保证其鲁棒调节。

> **摘要翻译:** 我们扩展了死区自适应扰动抑制（DADS）控制，使其适用于具有满足匹配条件的动态不确定性、且扰动和未知参数边界均未知的时不变系统。这个问题等同于部分状态自适应反馈，其中建模动态不确定性的状态是未测量的。我们表明，DADS控制器可以绕过小增益条件，即使互连强度没有已知边界，也能实现系统的鲁棒调节。此外，无论扰动和未知参数的大小如何，都不会出现增益和状态漂移。最后，本文详细分析了一个控制系统，其中未测量状态（或动态不确定性）是无限维的，并由一个反应扩散偏微分方程描述，其中扩散系数和反应项是未知的。结果表明，即使在无限维情况下，也可以设计DADS控制器并保证植物状态的鲁棒调节。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [52] [Learning Concepts Definable in First-Order Logic with Counting](https://arxiv.org/abs/1909.03820)
> *学习可由带计数的FOCN一阶逻辑定义的概*

*Steffen van Bergerem* | **Category: cs.LO, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 一阶逻辑, 带计数逻辑, 亚线性时间学习, 关系结构, 分类器

**Comment:** 

> **TL;DR:** 本文将一阶逻辑分类器在关系结构上的亚线性时间学习推广到带计数的一阶逻辑(FOCN)，证明在多对数度数结构上可一致学习，并指出度数限制对亚线性时间学习至关重要。

**AI_Comments:** 这项工作在理论计算机科学领域具有重要意义，它将高效学习的边界从传统的一阶逻辑扩展到了表达力更强的带计数的一阶逻辑。特别指出结构度数对学习效率的影响，为未来设计高效的逻辑学习算法提供了重要的理论指导。这为机器学习与逻辑推理的结合，尤其是处理包含数值信息的复杂数据，奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，在多对数度数结构上，一阶逻辑可定义的分类器可以在亚线性时间内学习。本文的动机在于将这一结果推广到更具表达力的带计数的一阶逻辑(FOCN)，并探索将机器学习框架扩展到包含数值方面。

**Method:** 本文通过理论证明的方式，研究了在关系背景结构上使用带计数的一阶逻辑(FOCN)定义的布尔分类问题。具体地，证明了在多对数度数结构类别上，FOCN可定义的分类器可以被一致地在亚线性时间内学习。同时，还将结果扩展到针对度数至多为$(\log \log n)^c$的结构类别的不可知PAC学习。此外，通过反证法，证明了限制度数对于获得亚线性时间学习算法的重要性。

**Result:** 1. 在多对数度数结构类别上，可由带计数的一阶逻辑(FOCN)定义的分类器可以在亚线性时间内被一致地学习。
2. 该学习框架可扩展到针对度数至多为$(\log \log n)^c$的结构类别的不可知PAC学习。
3. 证明了限制结构度数对于实现亚线性时间学习算法至关重要。
4. 对于无界度数的结构，即使是普通一阶逻辑定义的分类器，也无法在亚线性时间内学习。

**Conclusion:** 本研究成功将一阶逻辑分类器的亚线性时间学习结果推广到表达力更强的带计数的一阶逻辑(FOCN)，并强调了结构度数限制对于实现高效学习算法的关键作用。这为将机器学习框架扩展到包含数值方面迈出了重要一步。

> **ai_Abstract:** 本文研究了在关系背景结构上使用带计数的一阶逻辑(FOCN)进行布尔分类的问题。在先前工作的基础上，作者证明了在多对数度数结构上，FOCN可定义的分类器可以在亚线性时间内被一致地学习，并将此结果扩展到不可知PAC学习。研究还强调了限制结构度数对于实现亚线性时间学习算法的关键性，指出无界度数结构无法实现亚线性时间学习。

> **摘要翻译:** 我们研究了Grohe和Turán（TOCS 2004）引入的逻辑框架中关系背景结构上的布尔分类问题。已知（Grohe和Ritzert，LICS 2017），在多对数度数结构上可由一阶逻辑定义的分类器可以在亚线性时间内学习，其中结构的度数和运行时间是根据结构的大小来衡量的。我们将这些结果推广到带计数的一阶逻辑FOCN，该逻辑由Kuske和Schweikardt（LICS 2017）引入，作为一种概括各种其他计数逻辑的表达力强的逻辑。具体来说，我们证明了在多对数度数结构类别上可由FOCN定义的分类器可以被一致地在亚线性时间内学习。这可以看作是将学习框架扩展到包含机器学习数值方面的第一步。我们将结果扩展到针对度数至多为$(\log \log n)^c$（c为某个常数）的结构类别的不可知大概正确（PAC）学习。此外，我们表明限制度数对于获得亚线性时间学习算法至关重要。也就是说，我们证明，对于无界度数的结构，即使是普通一阶逻辑定义的分类器，也无法在亚线性时间内学习。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [161] [Approximate SMT Counting Beyond Discrete Domains](https://arxiv.org/abs/2507.18612)
> *离散域之外的近似SMT计数*

*Arijit Shaw, Kuldeep S. Meel* | **Category: cs.LO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** SMT, 模型计数, 混合公式, 近似计数, 哈希

**Comment:** To be published in the proceedings of Design Automation Conference
  (DAC) 2025

> **TL;DR:** 引入了“pact”，一个用于混合公式的新型SMT模型计数器，它使用基于哈希的近似计数，显著优于基线方法。

**AI_Comments:** 这项创新的核心在于将近似SMT模型计数扩展到混合公式，这在以前是由于仅限离散域的方法的局限性而面临的挑战。利用基于哈希的技术并提供理论保证以及对数数量的SMT调用，是解决这个问题的巧妙而高效的方法。所展示的显著性能提升突出了其重要的实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的SMT计数方法仅限于离散变量，这对于将解投影到离散域的混合SMT公式来说是一个挑战。因此，需要扩展SMT能力以对混合公式进行模型计数。

**Method:** 本文介绍了`pact`，一种用于混合公式的SMT模型计数器。它使用基于哈希的近似模型计数来估计解，并提供理论保证。`pact`相对于投影变量进行对数数量的SMT求解器调用，并利用优化的哈希函数。

**Result:** `pact`在大型基准测试套件上比基线方法取得了显著的性能提升。在14,202个实例中，`pact`成功完成了603个实例，而基线方法只能完成13个实例。

**Conclusion:** `pact`有效地将SMT模型计数扩展到混合公式，解决了现有方法的局限性，并展示了卓越的实际性能。

> **ai_Abstract:** 本文介绍了一种名为`pact`的新型SMT模型计数器，专为混合公式设计。它通过采用基于哈希的近似模型计数方法，解决了现有方法仅限于离散域的局限性。`pact`实现了理论保证，并且只需要对数数量的SMT求解器调用。实验结果表明，`pact`显著优于基线方法，成功解决了更多的实例。

> **摘要翻译:** 可满足性模理论（SMT）求解器推动了自动化推理的发展，解决了离散和连续域中的复杂公式。命题模型计数方面的最新进展促使将SMT能力扩展到模型计数，特别是对于混合SMT公式。现有方法，如比特展开，仅限于离散变量，这突出了在混合公式中将解投影到离散域的计数挑战。
我们引入了`pact`，一个用于混合公式的SMT模型计数器，它使用基于哈希的近似模型计数来估计具有理论保证的解。`pact`相对于投影变量进行对数数量的SMT求解器调用，利用优化的哈希函数。`pact`在大型基准测试套件上比基线方法取得了显著的性能提升。特别是，在14,202个实例中，`pact`成功完成了603个实例，而基线方法只能完成13个实例。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [239] [muRelBench: MicroBenchmarks for Zonotope Domains](https://arxiv.org/abs/2404.16243)
> *muRelBench：区域域的微基准测试*

*Kenny Ballou, Elena Sherman* | **Category: cs.LO, cs.SE** | **Updated: 2025-07-23**

**Keywords:** 抽象域, 微基准测试, 弱关系, 数值算法, muRelBench

**Comment:** SRP accepted at SEET 2025

> **TL;DR:** muRelBench 是一个用于弱关系抽象域的合成微基准测试框架，旨在帮助研究人员快速评估和验证数值抽象域算法的性能和正确性。

**AI_Comments:** muRelBench 的创新点在于提供了一个专门针对弱关系抽象域的合成微基准测试环境，这对于抽象解释和静态分析领域的研究至关重要。它允许研究人员在早期阶段快速迭代和验证算法的性能和正确性，显著降低了开发和测试的成本。其可扩展性和内建的正确性检查机制是其重要优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在评估数值抽象域算法（如闭包、最小上界、遗忘等）的性能改进时，可能需要更密集的实验。研究人员需要一个工具来快速原型验证和评估这些算法的性能和正确性。

**Method:** 提出了 muRelBench 框架，这是一个可扩展的合成微基准测试框架，用于弱关系抽象域及其操作。它提供了实验评估数值抽象域算法的能力，并包含检查基准测试正确性属性的机制。

**Result:** 该框架使研究人员能够实验性地评估数值抽象域的算法，快速原型验证和验证性能改进，并在进行更密集的实验之前确保合成基准测试的正确性。

**Conclusion:** muRelBench 提供了一个高效且可靠的工具，用于对数值抽象域算法进行微基准测试，从而加速这些算法的开发和验证过程。

> **ai_Abstract:** muRelBench 是一个为弱关系抽象域及其操作设计的合成微基准测试框架。它旨在帮助研究人员快速实验性地评估数值抽象域算法（如闭包、最小上界、遗忘）的性能改进，并提供机制来验证这些合成基准测试的正确性，从而在进行大规模实验前实现快速原型和验证。

> **摘要翻译:** 我们提出了 \texttt{muRelBench}，一个用于弱关系抽象域及其操作的合成基准测试框架。这个可扩展的微基准测试框架使研究人员能够实验性地评估数值抽象域的提议算法，例如闭包、最小上界和遗忘操作，从而使他们能够在考虑更密集的实验之前快速原型验证和验证性能改进。此外，该框架还提供了检查每个基准测试正确性属性的机制，以确保合成基准测试的正确性。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [681] [Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications](https://arxiv.org/abs/2507.18567)
> *第19届ACL2定理证明器及其应用国际研讨会论文集*

*Ruben Gamboa, Panagiotis Manolios* | **Category: cs.LO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** ACL2, 定理证明器, 自动化推理, 研讨会, Boyer-Moore

**Comment:** 

> **TL;DR:** ACL2研讨会是关于ACL2定理证明器及其应用的年度技术论坛，ACL2是一个工业级自动化推理系统，曾获ACM软件系统奖。

**AI_Comments:** 这篇论文集突出了ACL2定理证明器作为一种工业级自动化推理系统的重要性，并指出其开发者因其工作获得了著名的ACM软件系统奖，这表明ACL2在自动化推理领域具有显著的影响力。

<details>
  <summary>Details</summary>

**Motivation:** 举办ACL2研讨会的动机是为ACL2定理证明系统的用户提供一个主要的、展示与ACL2定理证明器及其应用相关的研究的技术论坛。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了第19届ACL2定理证明器国际研讨会，强调其是关于ACL2系统及其应用研究的主要论坛。ACL2被描述为一个工业级自动化推理系统，属于Boyer-Moore定理证明器家族，其创建者曾荣获2005年ACM软件系统奖。

> **摘要翻译:** ACL2研讨会系列是ACL2定理证明系统用户展示与ACL2定理证明器及其应用相关研究的主要技术论坛。ACL2是一个工业级自动化推理系统，是Boyer-Moore定理证明器家族的最新成员。Boyer、Kaufmann和Moore因其在ACL2和Boyer-Moore家族中其他定理证明器方面的工作而荣获2005年ACM软件系统奖。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [66] [Zeroth-order log-concave sampling](https://arxiv.org/abs/2507.18021)
> *零阶对数凹采样*

*Yunbum Kook* | **Category: math.ST, cs.DS, cs.LG, math.FA, math.PR, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 零阶采样, 对数凹, 查询复杂度, 近端采样器, Rényi散度

**Comment:** 30 pages

> **TL;DR:** 本文研究了对数凹采样的零阶查询复杂度，提出了一种改进的近端采样器和退火方案，在Rényi散度下实现了更好的查询复杂度，并增强了混合保证。

**AI_Comments:** 该论文在对数凹采样领域做出了重要贡献，为零阶查询复杂度提供了具体的界限。引入用于暖启动的退火方案以及通过超收缩性和对数Sobolev不等式提供的理论基础是值得注意的。这项工作提升了对从复杂分布中进行有限信息采样的理解和效率。

<details>
  <summary>Details</summary>

**Motivation:** 研究对数凹采样的零阶查询复杂度，特别是使用成员预言机对凸体进行均匀采样。

**Method:** 提出了一种近端采样器的简单变体，以实现特定的查询复杂度。引入了一种简单的退火方案，用于生成 $q$-Rényi 散度下的暖启动。建立了同步热流下的超收缩性，并将其转化为对数Sobolev不等式下近端采样器的改进混合保证。

**Result:** 所提出的采样器实现了 $\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\,\lVert\operatorname{cov}\pi\rVert\log\frac{1}{\varepsilon})$ 的成员查询复杂度，用于在 $q$-Rényi 散度下实现 $\varepsilon$-接近。退火方案使用 $\widetilde{O}(qd^{2}R^{3/2}\,\lVert\operatorname{cov}\pi\rVert^{1/4})$ 查询来产生暖启动。这些结果自然地扩展到通过评估预言机可访问的通用对数凹分布，但会产生额外的二次查询。

**Conclusion:** 本文为对数凹采样提供了改进的查询复杂度，特别是在暖启动生成和混合方面，并可扩展到通用对数凹分布。

> **ai_Abstract:** 本文研究了对数凹采样的零阶查询复杂度，特别是从凸体中进行均匀采样。它提出了一种近端采样器的变体，该变体在Rényi散度下实现了特定的查询复杂度。此外，还引入了一种退火方案来生成暖启动，并给出了改进的查询界限。该工作还建立了同步热流下的超收缩性，以增强混合保证。这些发现适用于一般的对数凹分布。

> **摘要翻译:** 我们研究了对数凹采样的零阶查询复杂度，特别是使用成员预言机对凸体进行均匀采样。我们提出了一种近端采样器的简单变体，该变体在初始“暖度”和输出保证之间实现了匹配的Rényi阶数的查询复杂度。具体来说，对于任何 $\varepsilon>0$ 和 $q\geq2$，该采样器在 $\pi_{0}$ 初始化后，输出的样本其分布在 $q$-Rényi 散度下与 $\mathbb{R}^{d}$ 中凸体上的均匀分布 $\pi$ 相距 $\varepsilon$，使用的成员查询次数为 $\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\,\lVert\operatorname{cov}\pi\rVert\log\frac{1}{\varepsilon})$，其中 $M_{q}=\lVert\text{d}\pi_{0}/\text{d}\pi\rVert_{L^{q}(\pi)}$。
我们进一步引入了一种简单的退火方案，该方案在 $q$-Rényi 散度下产生“暖启动”（即 $M_{q}=O(1)$），使用的查询次数为 $\widetilde{O}(qd^{2}R^{3/2}\,\lVert\operatorname{cov}\pi\rVert^{1/4})$，其中 $R^{2}=\mathbb{E}_{\pi}[|\cdot|^{2}]$。这插值了总变差和Rényi无穷散度中已知暖启动生成的复杂度。为了在退火方案中传递Rényi暖度，我们建立了同步热流下的超收缩性，并将其转化为对数Sobolev不等式下近端采样器的改进混合保证。这些结果自然地扩展到通过评估预言机可访问的通用对数凹分布，但会产生额外的二次查询。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [75] [From Individual Learning to Market Equilibrium: Correcting Structural and Parametric Biases in RL Simulations of Economic Models](https://arxiv.org/abs/2507.18229)
> *从个体学习到市场均衡：纠正经济模型RL模拟中的结构和参数偏差*

*Zeqiang Zhang, Ruxin Chen* | **Category: econ.GN, cs.AI, q-fin.EC** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 经济模型, 市场均衡, 均值场强化学习, 结构偏差

**Comment:** 

> **TL;DR:** 本文通过提出一种校准的均值场强化学习框架，解决了强化学习在经济模型模拟中存在的结构性偏差和参数性偏差，使其能够收敛到市场均衡。

**AI_Comments:** 这篇论文的创新点在于它识别并解决了强化学习应用于经济模型时出现的两个核心偏差：结构性偏差（代理行为与均衡理论假设不符）和参数性偏差（贴现率处理不当）。通过引入校准的均值场强化学习框架，并设计迭代算法使其收敛到经济均衡，该研究提供了一个将微观学习行为与宏观经济均衡理论有效结合的通用方法，这对于计算社会科学和经济学交叉领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习应用于经济建模时，均衡理论假设与学习代理行为之间存在根本冲突。传统的单智能体RL模拟会使代理成为环境的“操纵者”而非“接受者”，导致非均衡的买方垄断策略。此外，经济贴现与RL对跨期成本处理不匹配，产生参数偏差。

**Method:** 提出了一种校准的均值场强化学习（Mean-Field Reinforcement Learning）框架。该框架将代表性代理嵌入固定的宏观经济场中，并调整成本函数以反映经济机会成本。通过迭代算法使其收敛到自洽的定点。

**Result:** 提出的迭代算法能够收敛到一个自洽的定点，使得智能体的策略与竞争均衡相一致。

**Conclusion:** 该方法为计算社会科学领域中经济系统学习代理的建模提供了一种可行且理论上可靠的方法。

> **ai_Abstract:** 本文探讨了强化学习在经济建模中应用时遇到的结构性（学习代理成为“操纵者”而非“接受者”）和参数性（经济贴现与RL跨期成本处理不匹配）偏差。通过在一个搜索匹配模型中验证这些问题后，作者提出了一种校准的均值场强化学习框架。该框架将代理置于固定的宏观经济场中并调整成本函数，通过迭代算法使其策略收敛到竞争均衡，从而为经济系统中的学习代理建模提供了一种理论上可靠且可行的方法。

> **摘要翻译:** 强化学习（RL）在经济建模中的应用揭示了均衡理论假设与学习代理涌现行为之间的根本冲突。虽然规范的经济模型假设原子化代理是总市场条件的“接受者”，但天真的单智能体RL模拟会激励代理成为其环境的“操纵者”。本文首先在一个具有凹生产的搜索匹配模型中展示了这种差异，表明标准RL代理学习到的是非均衡的、买方垄断策略。此外，我们还识别出由经济贴现与RL对跨期成本处理不匹配所引起的参数偏差。为了解决这两个问题，我们提出了一种校准的均值场强化学习框架，该框架将代表性代理嵌入固定的宏观经济场中，并调整成本函数以反映经济机会成本。我们的迭代算法收敛到一个自洽的定点，其中代理的策略与竞争均衡相一致。这种方法为计算社会科学领域中经济系统学习代理的建模提供了一种可行且理论上可靠的方法。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [86] [Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)](https://arxiv.org/abs/2507.17897)
> *多模态循环集成模型预测自然电影中的大脑反应 (Algonauts 2025)*

*Semih Eren, Deniz Kucukahmetler, Nico Scherf* | **Category: q-bio.NC, cs.CV, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 多模态, 循环集成, 大脑反应, fMRI, 自然电影

**Comment:** 8 pages, 2 figures, 1 table. Invited report, CCN 2025 Algonauts
  Project session (3rd-place team). Code:
  https://github.com/erensemih/Algonauts2025_ModalityRNN

> **TL;DR:** 该研究提出了一种分层多模态循环集成模型，用于预测观看自然电影时的大脑fMRI反应，并在Algonauts 2025挑战赛中获得第三名，验证了其在整合多模态信息以理解大脑响应方面的有效性。

**AI_Comments:** 该研究提出了一种新颖的分层多模态循环集成模型，其创新之处在于有效整合了视觉、听觉和语义信息来预测大脑对自然电影的复杂反应。其在Algonauts 2025挑战赛中取得的第三名和最高的单区域峰值分数，充分证明了该方法的有效性和鲁棒性。该方法为未来的多模态大脑编码研究提供了一个简单且可扩展的基线，对理解大脑如何处理自然刺激具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测对自然刺激的分布式皮层反应，需要能够随时间整合视觉、听觉和语义信息的模型。

**Method:** 研究提出了一种分层多模态循环集成模型，该模型将预训练的视频、音频和语言嵌入映射到fMRI时间序列。模型包含特定模态的双向RNN编码时间动态，其隐藏状态被融合并传递到第二个循环层，然后轻量级主体特定头部输出1000个皮层区域的响应。训练采用复合MSE-相关损失和课程学习策略，并对100个模型变体进行平均以增强鲁棒性。

**Result:** 该系统在Algonauts 2025挑战赛中排名第三，总体Pearson r = 0.2094，并取得了所有参与者中最高的单区域峰值分数（平均r = 0.63），尤其在最具挑战性的主体（主体5）上表现突出。

**Conclusion:** 该方法为未来的多模态大脑编码基准建立了一个简单、可扩展的基线。

> **ai_Abstract:** 该论文介绍了一种分层多模态循环集成模型，用于预测人类大脑对自然电影刺激的fMRI反应。该模型整合了视频、音频和语言嵌入，并利用双向RNN处理时间动态。通过复合损失函数和课程学习进行训练，并在Algonauts 2025挑战赛中获得第三名，表现出卓越的预测能力，尤其在最具挑战性的受试者上。该研究为多模态大脑编码研究提供了一个可扩展的基线。

> **摘要翻译:** 准确预测对自然刺激的分布式皮层反应，需要能够随时间整合视觉、听觉和语义信息的模型。我们提出了一种分层多模态循环集成模型，该模型将预训练的视频、音频和语言嵌入映射到四名受试者在观看Algonauts 2025挑战赛提供的近80小时电影时记录的fMRI时间序列。特定模态的双向RNN编码时间动态；它们的隐藏状态被融合并传递到第二个循环层，然后轻量级主体特定头部输出1000个皮层区域的响应。训练依赖于复合MSE-相关损失和逐渐将重点从早期感觉区域转移到晚期关联区域的课程学习。对100个模型变体进行平均进一步增强了鲁棒性。由此产生的系统在竞赛排行榜上排名第三，总体Pearson r = 0.2094，并在所有参与者中取得了最高的单区域峰值分数（平均r = 0.63），尤其在最具挑战性的受试者（主体5）上获得了显著提升。该方法为未来的多模态大脑编码基准建立了一个简单、可扩展的基线。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [88] [Non-Variational Quantum Random Access Optimization with Alternating Operator Ansatz](https://arxiv.org/abs/2502.04277)
> *非变分量子随机存取优化与交替算子Ansatz*

*Zichang He, Rudy Raymond, Ruslan Shaydulin, Marco Pistoia* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 量子优化, QRAO, QAOA, 非变分, MaxCut

**Comment:** 9 pages, 8+1 figures, accepted by Scientific Reports

> **TL;DR:** 提出了一种基于QAOA的非变分量子随机存取优化(QRAO)方法，解决了变分QRAO参数训练的扩展性问题，并发现固定参数表现良好。

**AI_Comments:** 这篇论文通过提出非变分QRAO方法，有效解决了现有变分QRAO在扩展性上的挑战，特别是在参数训练方面的限制。其创新点在于证明了固定参数在QRAO中也能达到良好性能，这对于未来在量子硬件上实现大规模优化具有重要意义，降低了对昂贵变分参数优化的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 近期量子计算机在解决工业规模优化问题时受限于其规模和量子纠错的开销。现有的量子随机存取优化（QRAO）方法仅通过变分算法实现，需要训练特定实例的变分参数，导致难以扩展。

**Method:** 提出并评估了一种基于量子交替算子Ansatz (QAOA) 的非变分QRAO方法，应用于MaxCut问题。该方法使用实例无关的“固定”参数，并评估了不同的设计选择，如混合器、初始状态和QRAO特有的QAOA成本算子实现。

**Result:** 实例无关的“固定”参数表现良好，消除了变分参数优化的需要。研究还识别出了一种在实践中表现良好的策略。

**Conclusion:** 该研究结果为早期容错量子计算机上QRAO的实际执行铺平了道路。

> **ai_Abstract:** 本文针对现有量子随机存取优化（QRAO）中变分算法难以扩展的问题，提出了一种基于量子交替算子Ansatz (QAOA) 的非变分QRAO方法。研究表明，使用实例无关的固定参数即可获得良好性能，从而避免了繁琐的变分参数优化过程。通过对混合器、初始状态和成本算子等设计选择的评估，确定了一种有效的实践策略，为QRAO在早期容错量子计算机上的实际应用奠定了基础。

> **摘要翻译:** 解决困难优化问题是量子计算机最有前景的应用领域之一，因为此类问题在工业中普遍存在，并且量子加速具有广泛适用性。然而，近期量子计算机处理工业规模优化问题的能力受限于其规模和量子纠错的开销。量子随机存取优化（QRAO）已被提出以减少量子优化所需的空间。但迄今为止，QRAO仅通过变分算法实现，这受限于需要训练特定实例的变分参数，使其难以扩展。我们提出并评估了一种基于量子交替算子Ansatz (QAOA) 的非变分QRAO方法，应用于MaxCut问题。我们表明，实例无关的“固定”参数能取得良好性能，消除了变分参数优化的需要。此外，我们评估了不同的设计选择，例如各种混合器、初始状态以及QRAO特有的QAOA成本算子实现，并确定了一种在实践中表现良好的策略。我们的结果为早期容错量子计算机上QRAO的实际执行铺平了道路。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [123] [Is Circuit Depth Accurate for Comparing Quantum Circuit Runtimes?](https://arxiv.org/abs/2505.16908)
> *量子电路深度能准确比较量子电路运行时长吗？*

*Matthew Tremba, Paul Hovland, Ji Liu* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 量子电路运行时长, 电路深度, 门感知深度, 硬件实现, 性能评估

**Comment:** 8 pages, 6 figures

> **TL;DR:** 量子电路深度在比较运行时长时不准确，因为它忽略了不同门的时长差异。本文提出了一种新的门感知深度指标，通过考虑门执行时间来显著提高运行时长预测的准确性。

**AI_Comments:** 这篇论文创新性地提出了“门感知深度”这一新指标，解决了传统量子电路深度在评估运行时长时忽略不同量子门执行时间差异的关键局限。通过引入门权重，它提供了一种更实用和准确的运行时长预测方法，对于量子编译优化和硬件性能评估具有重要意义。其优势在于无需精确的门时间数据，仅依赖平均值即可提升准确性和可移植性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的量子电路深度指标在估算电路运行时长时不够准确，因为它忽略了当前硬件实现中不同量子门具有不同执行时间的特性，这可能导致运行时长比较出现偏差。

**Method:** 作者首先评估了传统深度和多量子位深度在预测运行时长相对差异以及识别最短运行时长电路版本方面的准确性。随后，他们引入了一种新的度量标准——门感知深度（gate-aware depth），该度量通过使用架构的平均门执行时间来加权门对运行时的贡献，从而在不需精确了解所有门时间的情况下捕获门类型间的差异。

**Result:** 研究发现，传统的电路深度对于上述两项任务均不准确。与传统深度和多量子位深度相比，门感知深度在任务（1）中将预测的平均相对误差分别降低了68倍和18倍，在任务（2）中将平均正确识别率分别提高了20和43个百分点。此外，论文还提供了IBM Eagle和Heron架构的门感知深度权重配置。

**Conclusion:** 传统的量子电路深度不足以准确比较量子电路运行时长。新提出的门感知深度指标通过考虑不同门的执行时间，显著提高了运行时长预测的准确性和识别最短运行时长电路版本的能力，为量子电路性能评估提供了一个更精确的工具。

> **ai_Abstract:** 本文探讨了量子电路深度在比较量子电路运行时长时的准确性问题，指出其未能考虑不同量子门执行时间不同的硬件特性。研究发现传统深度和多量子位深度在预测运行时长差异和识别最短运行时长版本方面均不准确。为此，论文提出了一种新的门感知深度指标，该指标通过加权门的平均执行时间来更准确地评估运行时长。实验结果表明，门感知深度显著优于现有方法，大幅降低了预测误差并提高了最短运行时长版本的识别率，并提供了IBM Eagle和Heron架构的权重配置。

> **摘要翻译:** 尽管量子电路深度常用于近似电路运行时长，但它忽略了当前硬件实现的一个普遍特征：不同门具有不同的执行时间。认识到潜在的差异，我们研究了深度在比较同一电路不同编译版本运行时长时的准确性。特别是，我们评估了传统深度和多量子位深度在以下方面的准确性：(1) 预测运行时长的相对差异，以及 (2) 识别运行时长最短的编译电路版本。我们发现电路深度对于这两项任务都不准确，因此引入了一种新的度量标准——门感知深度，它使用架构的平均门执行时间来加权门对运行时的贡献。使用平均门时间使得门感知深度能够捕获门类型间的变化，而无需精确了解所有门的时间，从而在提高准确性的同时保持了在相同架构设备间的可移植性。与传统深度和多量子位深度相比，门感知深度在任务 (1) 中将预测的平均相对误差分别降低了68倍和18倍，在任务 (2) 中将平均正确识别率分别提高了20和43个百分点。最后，我们提供了当前IBM Eagle和Heron架构的门感知深度权重配置。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [126] [Quantum Machine Learning Playground](https://arxiv.org/abs/2507.17931)
> *量子机器学习游乐场*

*Pascal Debus, Sebastian Issel, Kilian Tscharke* | **Category: quant-ph, cs.GR, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 量子机器学习, 可视化, 交互式工具, 数据重上传, 量子分类器

**Comment:** Accepted to IEEE Computer Graphics and Applications. Final version:
  https://doi.org/10.1109/MCG.2024.3456288

> **TL;DR:** 开发了一个交互式可视化工具，旨在简化量子机器学习算法的学习。

**AI_Comments:** 该工具通过提供一个易于访问的交互式平台，有望显著降低量子机器学习的学习曲线，对于教育和研究领域都具有重要意义。其创新之处在于将经典ML可视化工具的成功经验应用于新兴的QML领域。

<details>
  <summary>Details</summary>

**Motivation:** 受到经典机器学习可视化工具（如TensorFlow Playground）的启发，旨在弥补量子机器学习领域可视化资源的空白，降低量子计算的入门门槛。

**Method:** 概述了量子计算和经典机器学习中相关的可视化隐喻，开发了算法可视化概念，并设计了一个具体的交互式Web应用程序实现，结合了数据重上传通用量子分类器的可视化隐喻。

**Result:** 提出了一个量子机器学习游乐场的第一个版本，作为学习和探索QML模型的交互式应用程序。

**Conclusion:** 该工具通过可视化降低了量子计算的入门门槛，并鼓励该领域的进一步创新。

> **ai_Abstract:** 本文介绍了一个名为“量子机器学习游乐场”的创新交互式可视化工具，旨在通过直观的可视化界面简化量子机器学习算法的学习。该工具受经典机器学习可视化工具启发，旨在弥合QML可视化资源的差距，通过结合量子计算和经典机器学习的可视化隐喻，特别是针对数据重上传通用量子分类器，从而降低量子计算的入门门槛并促进该领域的创新。

> **摘要翻译:** 本文介绍了一种创新的交互式可视化工具，旨在揭开量子机器学习（QML）算法的神秘面纱。我们的工作灵感来源于经典机器学习可视化工具（如TensorFlow Playground）的成功，旨在弥补QML领域可视化资源的空白。本文包括对量子计算和经典机器学习中相关可视化隐喻的全面概述、算法可视化概念的开发，以及作为交互式Web应用程序的具体实现设计。通过结合用于所谓数据重上传通用量子分类器（作为代表性QML模型）的常见可视化隐喻，本文旨在降低量子计算的入门门槛，并鼓励该领域的进一步创新。随附的交互式应用程序是量子机器学习游乐场的第一个版本提案，用于学习和探索QML模型。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [202] [Scalable Parameter Design for Superconducting Quantum Circuits with Graph Neural Networks](https://arxiv.org/abs/2411.16354)
> *基于图神经网络的超导量子电路可扩展参数设计*

*Hao Ai, Yu-xi Liu* | **Category: quant-ph, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 超导量子电路, 图神经网络, 参数设计, 可扩展性, 量子串扰

**Comment:** 

> **TL;DR:** 提出了一种利用图神经网络（GNNs）的“三步缩放”机制，用于大规模超导量子电路的参数设计算法，显著提高了效率、有效性和可扩展性，并在降低量子串扰误差方面表现优异。

**AI_Comments:** 本文的创新点在于首次将图神经网络应用于超导量子芯片的参数设计，并提出了“三步缩放”机制以解决大规模电路的模拟复杂性。其重要性在于显著提升了量子芯片设计的效率和可扩展性，为未来大规模量子计算芯片的开发提供了新的工具和思路。

<details>
  <summary>Details</summary>

**Motivation:** 随着大规模超导量子计算芯片的设计和制造，模拟量子系统的复杂性对量子芯片的计算机辅助设计构成了重大挑战，尤其对于大规模芯片。

**Method:** 提出了一种基于图神经网络（GNNs）的参数设计算法，该算法依赖于“三步缩放”机制，包含两个神经网络模型：一个在小规模电路上进行监督训练并应用于中规模电路的评估器，以及一个在中规模电路上进行无监督训练并应用于大规模电路的设计器。同时考虑了单量子位和双量子位门的频率（对应于节点和边的参数）。

**Result:** 该算法在减轻量子串扰误差方面表现出色。对于包含约870个量子位的大规模超导量子电路，与现有最先进算法相比，基于GNNs的算法将误差降低了51%，时间从90分钟缩短到27秒。

**Conclusion:** 研究提出了一种性能更好、可扩展性更强的超导量子芯片参数设计算法，首次展示了将GNNs应用于超导量子芯片的优势。

> **ai_Abstract:** 本文提出了一种基于图神经网络（GNNs）的参数设计算法，用于解决大规模超导量子电路计算机辅助设计中的挑战。该算法采用独特的“三步缩放”机制，包含一个评估器和一个设计器，分别通过监督和无监督学习在不同规模电路上训练。实验结果表明，该方法在降低量子串扰误差方面表现出色，并显著提高了大规模电路设计的效率、有效性和可扩展性，例如，对于870量子位电路，错误率降低51%，计算时间从90分钟缩短到27秒。

> **摘要翻译:** 为了证明量子计算的优越性，人们正在设计和制造越来越大规模的超导量子计算芯片。然而，模拟量子系统的复杂性对量子芯片的计算机辅助设计构成了重大挑战，尤其对于大规模芯片。我们在此利用图神经网络（GNNs）的可扩展性，提出了一种用于大规模超导量子电路的参数设计算法。该算法依赖于所谓的“三步缩放”机制，该机制包括两个神经网络模型：一个在小规模电路上进行监督训练并应用于中规模电路的评估器，以及一个在中规模电路上进行无监督训练并应用于大规模电路的设计器。我们展示了该算法在减轻量子串扰误差方面的应用。单量子位和双量子位门的频率（对应于节点和边的参数）被同时考虑。数值结果表明，训练有素的设计器在效率、有效性和可扩展性方面取得了显著优势。例如，对于包含约870个量子位的大规模超导量子电路，我们基于GNNs的算法产生的误差仅为现有最先进算法的51%，并且时间从90分钟缩短到27秒。总的来说，本文提出了一种性能更好、可扩展性更强的超导量子芯片参数设计算法，首次展示了将GNNs应用于超导量子芯片的优势。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [538] [Hybrid quantum-classical algorithm for near-optimal planning in POMDPs](https://arxiv.org/abs/2507.18606)
> *混合量子-经典算法用于部分可观测马尔可夫决策过程中的近最优规划*

*Gilberto Cunha, Alexandra Ramôa, André Sequeira, Michael de Oliveira, Luís Barbosa* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 量子强化学习, 部分可观测马尔可夫决策过程, 混合算法, 贝叶斯网络, 计算加速

**Comment:** 

> **TL;DR:** 本文提出了一种混合量子-经典算法QBRL，用于部分可观测马尔可夫决策过程（POMDPs）中的近最优规划，通过量子增强的信念更新实现了次二次方加速，并通过数值实验验证了其性能优势。

**AI_Comments:** 本文的创新之处在于提出了QBRL这一针对部分可观测马尔可夫决策过程（POMDPs）的混合量子-经典强化学习算法，并特别关注了量子增强信念更新的机制。其提供的无预言机时间复杂度分析，相比于传统的黑盒假设，更具理论严谨性和实际指导意义。该研究的重要性体现在将量子计算的潜力引入到解决复杂强化学习问题中，为未来在计算受限场景下的决策制定提供了新的思路。然而，论文中提到实验是在“简单但具有说明性的”任务上进行的，且量子优势的“大小在不同的部署设置中可能显著不同”，这暗示了该技术在实际大规模应用中可能仍面临挑战，例如量子设备的容错性要求和实际部署的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 在部分可观测环境中，决策制定（可建模为马尔可夫决策过程并用动态贝叶斯网络表示）面临计算挑战。近期研究表明，结合量子拒绝采样和振幅放大可以加速稀疏贝叶斯网络上的推理，从而加速接受概率的估计。本文旨在利用这一进展，为部分可观测环境中的模型基强化学习提供计算加速。

**Method:** 本文引入了量子贝叶斯强化学习（QBRL），这是一种用于部分可观测环境中模型基强化学习的混合量子-经典前瞻算法。该方法利用量子拒绝采样和振幅放大来加速稀疏贝叶斯网络上的推理，特别是通过量子增强的信念更新。论文提供了在容错量子设备假设下的严谨、无预言机的时空复杂度分析，明确指定了推理过程。此外，还通过数值实验将QBRL与经典对应算法在简单但具有说明性的决策任务上进行了基准测试。

**Result:** 研究表明，对于动态形成稀疏贝叶斯网络的环境，通过量子增强的信念更新可以实现次二次方加速的基于视界的近最优规划。数值实验结果详细分析了量子计算优势如何转化为决策性能，并指出该优势的大小在不同的部署设置中可能显著不同。

**Conclusion:** QBRL提供了一种量子增强的近最优规划方法，适用于部分可观测马尔可夫决策过程。量子计算优势能够转化为决策性能的提升，但其实际效益会因部署环境的不同而显著变化。

> **ai_Abstract:** 本文提出了一种名为量子贝叶斯强化学习（QBRL）的混合量子-经典前瞻算法，专为部分可观测环境中的模型基强化学习设计。该算法利用量子拒绝采样和振幅放大技术，加速稀疏贝叶斯网络上的推理过程，从而实现量子增强的信念更新。研究表明，在动态为稀疏贝叶斯网络的环境中，QBRL能够以次二次方速度更快地实现基于视界的近最优规划。论文提供了在容错量子设备假设下的严谨、无预言机的时间复杂度分析，并通过数值实验验证了量子计算优势如何转化为实际决策性能，同时指出该优势的程度会因部署环境而异。

> **摘要翻译:** 强化学习（RL）为部分可观测环境中的决策制定提供了一个原则性框架，这些环境可以建模为马尔可夫决策过程，并通过动态决策贝叶斯网络紧凑表示。最近的进展表明，结合量子拒绝采样和振幅放大可以加速稀疏贝叶斯网络上的推理，从而在估计接受概率方面实现计算加速。\n在此基础上，我们引入了量子贝叶斯强化学习（QBRL），这是一种用于部分可观测环境中模型基强化学习的混合量子-经典前瞻算法。我们对量子设备在容错假设下的时间复杂度进行了严格的、无预言机的分析。与假设黑盒预言机的标准处理方法不同，我们明确指定了推理过程，这使得我们的界限能更准确地反映真实的计算成本。我们表明，对于其动态形成稀疏贝叶斯网络的环境，通过量子增强的信念更新，可以次二次方地更快地实现基于视界的近最优规划。\n此外，我们还通过数值实验，在简单但具有说明性的决策任务上，将QBRL与其经典对应算法进行了基准测试。我们的结果详细分析了量子计算优势如何转化为决策制定性能，并强调了该优势的大小在不同的部署设置中可能显著不同。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [632] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
> *混合奖励驱动的强化学习用于高效量子电路合成*

*Sara Giordano, Kornikar Sen, Miguel A. Martin-Delgado* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 量子电路合成, 强化学习, Q-学习, 混合奖励, 量子优化

**Comment:** 13 pages, 4 figures, color figures

> **TL;DR:** 本文提出了一种混合奖励驱动的强化学习框架，利用表格Q-学习在离散量子态空间中高效合成量子电路，解决了量子计算中的电路优化挑战，并在多量子比特图态制备和通用门集上实现了最小深度和优化的门计数电路。

**AI_Comments:** 本文的创新点在于将强化学习应用于量子电路合成，并通过混合奖励机制（结合领域知识和动态惩罚）有效解决了态空间指数增长和电路效率问题。其采用的离散化和稀疏矩阵表示方法也有效地降低了计算开销，展现了在NISQ时代量子计算优化方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在NISQ时代和未来的容错量子计算中，从固定初始态生成特定目标量子态的量子电路合成是一个核心挑战，需要高效的方法来优化电路结构。

**Method:** 该方法引入了一个强化学习（RL）框架，采用基于动作序列的表格Q-学习，在离散化的量子态空间中进行。它结合了静态的、领域信息驱动的奖励来引导代理接近目标态，以及可定制的动态惩罚来阻止低效的电路结构（如门拥堵和重复访问状态）。通过利用稀疏矩阵表示和态空间离散化，该方法能够扩展到高维环境并最小化计算开销。

**Result:** 在多达七个量子比特的图态制备任务上进行基准测试，该算法持续发现具有优化门计数的最小深度电路。此外，将该框架扩展到用于任意量子态的通用门集时，它仍然能生成最小深度电路，这突显了算法的鲁棒性和适应性。

**Conclusion:** 该强化学习驱动的方法能够高效探索复杂的量子态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

> **ai_Abstract:** 本文提出了一种基于强化学习的量子电路合成框架，旨在从固定初始态高效生成目标量子态。该框架利用表格Q-学习和离散量子态空间，通过结合静态领域奖励和动态惩罚的混合奖励机制，有效管理高维空间并避免低效电路结构。实验证明，该方法在图态制备和通用门集下均能合成最小深度和优化门计数的量子电路，展现了其在量子电路优化中的高效性和鲁棒性。

> **摘要翻译:** 本文引入了一种强化学习（RL）框架，用于高效合成从固定初始态生成指定目标量子态的量子电路，解决了NISQ时代和未来容错量子计算中的一个核心挑战。该方法在离散量子态空间内利用基于动作序列的表格Q-学习，有效管理空间维度的指数增长。该框架引入了一种混合奖励机制，结合了指导代理趋向目标态的静态、领域信息奖励，以及阻止门拥堵和重复访问状态等低效电路结构的可定制动态惩罚。通过利用稀疏矩阵表示和态空间离散化，该方法能够可扩展地导航高维环境，同时最大限度地减少计算开销。在多达七个量子比特的图态制备任务上进行基准测试，我们证明该算法持续发现具有优化门计数的最小深度电路。此外，将该框架扩展到用于任意量子态的通用门集时，它仍然能生成最小深度电路，这突出了算法的鲁棒性和适应性。结果证实，这种RL驱动的方法能够高效探索复杂的量子态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [702] [Translating Between the Common Haar Random State Model and the Unitary Model](https://arxiv.org/abs/2503.11634)
> *普通哈尔随机态模型与酉模型之间的转换*

*Eli Goldin, Mark Zhandry* | **Category: quant-ph, cs.CR** | **Updated: 2025-07-23**

**Keywords:** 量子密码学, 黑盒分离, 普通哈尔随机态模型, 酉模型, 证明

**Comment:** 39 pages

> **TL;DR:** 鉴于现有将量子黑盒分离从普通哈尔随机态（CHRS）模型提升到酉模型的工作存在错误，本文提出了通用且无错误的提升条件。

**AI_Comments:** 本文通过纠正现有研究中的错误并提供通用的提升条件，显著推动了量子密码学中黑盒分离理论的发展。其创新在于提供了一种可靠且系统的方法，将不完整的CHRS模型中的分离转化为更具决定性意义的酉模型分离，这对于理解量子密码原语的局限性至关重要。其贡献在于不仅简化了现有证明，还扩展了已知的分离范围，为未来的量子密码学研究奠定了更坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的将量子密码原语的黑盒分离从普通哈尔随机态（CHRS）模型提升到酉模型的工作存在显著错误，且CHRS模型本身不被认为是完整的。

**Method:** 证明了CHRS分离可以通用提升的普适条件，从而为各种量子原语之间的完整酉分离提供了简单、模块化且无错误的证明。

**Result:** 提供了简单、模块化且无错误的各种量子原语之间完整酉分离的证明。该技术使得现有分离的证明更简单，并发现了以前仅在CHRS模型中已知的新分离。

**Conclusion:** 通过提供CHRS分离到酉分离的通用且无错误提升条件，本研究为量子密码学中的黑盒分离提供了更坚实的基础，并简化了现有证明并发现了新的分离。

> **ai_Abstract:** 本文研究了量子密码学中黑盒分离的提升问题。鉴于现有将普通哈尔随机态（CHRS）模型中的分离提升到更完整的酉模型的工作存在错误，作者提出了 CHRS 分离可以普遍提升的通用条件。这使得能够为各种量子原语之间的完整酉分离提供简单、模块化且无错误的证明。该方法不仅简化了现有分离的证明，还发现了以前仅在 CHRS 模型中已知的新分离。

> **摘要翻译:** 黑盒分离是密码学的基石，它指明了实现各种目标的障碍。最近一系列工作探索了量子密码原语的黑盒分离。具体来说，在普通哈尔随机态（CHRS）模型中已知许多分离，尽管该模型不被认为是完整的，而只是一个起点。最近的一些工作试图将这些分离提升到酉分离，这被认为是完整的。不幸的是，我们发现其中一些提升结果存在重大错误。
我们证明了CHRS分离可以通用提升的普适条件，从而为各种量子原语之间的完整酉分离提供了简单、模块化且无错误的证明。我们的技术使得现有分离的证明更简单，并发现了以前仅在CHRS模型中已知的新分离。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [156] [Topology-Preserving Coupling of Compressible Fluids and Thin Deformables](https://arxiv.org/abs/2507.18460)
> *拓扑保持的可压缩流体与薄可变形体的耦合*

*Jonathan Panuelos, Eitan Grinspun, David Levin* | **Category: physics.comp-ph, cs.GR, physics.flu-dyn** | **Updated: 2025-05-29**

**Keywords:** 可压缩流体, 可变形结构, 流固耦合, Voronoi分区, 防漏性

**Comment:** 

> **TL;DR:** 提出了一种新的离散化方法，用于可压缩流体与薄可变形结构的耦合，通过保持流体域的路径连通性，实现了足够的防漏性，并展示了流体与固体之间的双向能量传递。

**AI_Comments:** 该论文的创新之处在于其“拓扑保持”和“防漏”的耦合方法，有效解决了流固耦合领域中，特别是针对极薄结构时流体泄漏的关键挑战。受约束的基于Voronoi的方法在界面符合性方面的应用是其重要的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 为可压缩流体和薄可变形结构提供足够且必要的防漏性，通过保持流体域的路径连通性，即使固体任意薄也能确保流体不泄漏。

**Method:** 该方法采用了一种受约束的基于Voronoi的空间分区，结合了Godunov风格的有限体积时间积分。流体域被离散化为与流固界面精确吻合的单元，从而在界面处精确地解析边界条件，实现流体与固体之间的直接力交换。

**Result:** 该方法确保即使固体任意薄，也没有流体通过固体泄漏，并在气球、香槟塞和超音速小行星等一系列具有挑战性的场景中得到了验证，展示了流体与固体之间的双向能量传递。

**Conclusion:** 所提出的新离散化方法成功实现了可压缩流体与薄可变形结构之间的防漏耦合和准确的双向能量传递。

> **ai_Abstract:** 本文提出了一种新颖的离散化方法，用于耦合可压缩流体和薄可变形结构。该方法通过保持流体域的路径连通性来确保防漏性，并采用受约束的基于Voronoi的空间分区与Godunov风格的有限体积时间积分相结合。流体域单元与流固界面精确吻合，实现了边界条件的精确解析和流体与固体间的直接力交换，即使固体极薄也能防止流体泄漏。通过在多个挑战性场景中的验证，该方法成功展示了流体与固体间的双向能量传递。

> **摘要翻译:** 我们提出了一种新的可压缩流体与薄可变形结构耦合的离散化方法，通过保持流体域的路径连通性，提供了足够且必要的防漏性。我们的方法采用了受约束的基于Voronoi的空间分区，结合了Godunov风格的有限体积时间积分。流体域被离散化为与流固界面精确吻合的单元，从而可以在界面处精确地解析边界条件。这使得流体与固体之间能够直接进行力交换，同时确保即使固体任意薄，也没有流体通过固体泄漏。我们在包括内部压缩空气驱动的气球、克服摩擦后喷出的香槟塞以及超音速小行星在内的一系列挑战性场景中验证了我们的方法，展示了流体与固体之间的双向能量传递。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

### [166] [Machine Learning Workflow for Analysis of High-Dimensional Order Parameter Space: A Case Study of Polymer Crystallization from Molecular Dynamics Simulations](https://arxiv.org/abs/2507.17980)
> *用于分析高维序参数空间的机器学习工作流程：聚合物分子动力学模拟结晶的案例研究*

*Elyar Tourani, Brian J. Edwards, Bamin Khomami* | **Category: physics.comp-ph, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 机器学习工作流程, 聚合物结晶, 分子动力学模拟, 序参数, 结晶度指数

**Comment:** 30 pages, 8 figures, 1 table

> **TL;DR:** 本文提出了一种集成机器学习工作流程，用于准确量化聚合物结晶度，克服了传统方法对截断点和单一序参数的依赖性，并实现了高效的结晶度计算和结构转变监测。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的机器学习工作流程，用于克服传统聚合物结晶度分析中单一序参数和截断点带来的偏差。它结合了多尺度特征表示、降维、无监督聚类和监督学习，以数据驱动的方式识别关键序参数并定义了高效的结晶度指标。其重要性在于提供了一种更准确、鲁棒且高效的聚合物结晶度量化方法，特别是能够实时计算和监测结构转变，对大规模分子模拟具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 目前，聚合物结晶路径的识别依赖于基于分子模拟数据，通过预设的单一序参数截断点来定义成核或结晶区域。这种方法不仅对截断点敏感，而且每个序参数都引入了其自身的系统性偏差。

**Method:** 本研究提出了一种集成的机器学习工作流程。首先，每个原子由结合了几何、类热力学和对称性描述符的高维特征向量表示。其次，采用低维嵌入来揭示原子环境中的潜在结构指纹。随后，对嵌入进行无监督聚类以高保真度识别结晶和非晶原子。在生成高质量多维数据标签后，使用监督学习技术识别能够完全捕获这些标签的最小序参数集。通过各种测试将特征集减少到仅三个序参数。基于这些观察到的序参数，将结晶度指数（C-index）定义为逻辑回归模型预测结晶度的概率。

**Result:** 该方法仅使用三个序参数就足以重新创建结晶标签。定义的结晶度指数（C-index）在整个过程中保持双峰性，并实现了超过0.98的分类性能（AUC）。值得注意的是，在一个或几个快照上训练的模型能够高效地实时计算结晶度。研究还表明，最佳C-index拟合在结晶的不同阶段演变，支持了熵在早期成核中占主导地位，而对称性在后期变得更相关的假设。

**Conclusion:** 该工作流程为序参数选择提供了一种数据驱动的策略，并提供了一种用于监测大规模聚合物模拟中结构转变的指标。

> **ai_Abstract:** 本研究提出了一种创新的机器学习工作流程，旨在克服传统方法在聚合物结晶度量化中的局限性。通过将原子表示为高维特征向量并利用低维嵌入和无监督聚类，该方法能够高精度识别结晶和非晶原子。随后，采用监督学习技术识别出仅需三个关键序参数即可准确捕捉结晶标签，并在此基础上定义了高效且高分类性能的结晶度指数（C-index）。该工作流程不仅实现了实时结晶度计算，还揭示了结晶过程中序参数演变的规律，为聚合物模拟中的序参数选择和结构转变监测提供了数据驱动的新策略。

> **摘要翻译:** 目前，聚合物结晶路径的识别是通过基于分子模拟数据，在单一序参数（OP）上的预设截断点来定义成核或结晶区域进行的。除了对截断点敏感外，这些序参数中的每一个都引入了其自身的系统性偏差。在本研究中，提出了一种集成的机器学习工作流程，用于使用原子级分子动力学数据准确量化聚合物系统中的结晶度。每个原子由一个高维特征向量表示，该向量结合了几何、类热力学和基于对称性的描述符。采用低维嵌入来揭示原子环境中的潜在结构指纹。随后，对嵌入进行无监督聚类，以高保真度识别结晶和非晶原子。在使用多维数据生成高质量标签后，我们使用监督学习技术来识别能够完全捕获此标签的最小序参数集。进行了各种测试以减少特征集，结果表明仅使用三个序参数足以重新创建结晶标签。基于这些观察到的序参数，结晶度指数（C-index）被定义为逻辑回归模型预测结晶度的概率，在整个过程中保持双峰性，并实现了超过0.98的分类性能（AUC）。值得注意的是，在一个或几个快照上训练的模型能够高效地实时计算结晶度。最后，我们展示了最佳C-index拟合如何在结晶的不同阶段演变，支持了熵在早期成核中占主导地位，而对称性在后期变得更相关的假设。该工作流程为序参数选择提供了一种数据驱动的策略，并提供了一种用于监测大规模聚合物模拟中结构转变的指标。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [221] [Certificate-Sensitive Subset Sum: Realizing Instance Complexity](https://arxiv.org/abs/2507.15511)
> *证书敏感子集和：实现实例复杂性*

*Jesus Salas* | **Category: cs.CC, cs.DS, F.1.3; F.2.2** | **Updated: 2025-07-24**

**Keywords:** 子集和, 证书敏感算法, 实例复杂度, NP完全问题, 算法分析

**Comment:** 14 pages + appendix. Companion to arXiv:2503.20162 ("Beyond
  Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-2^{n/2}
  Enumeration"

> **TL;DR:** 本文提出了首个确定性的、证书敏感的子集和算法，其运行时间可根据输入结构自适应调整，并首次在所有实例上严格优于经典方法。

**AI_Comments:** 这篇论文的创新点在于提出了“证书敏感”算法的概念，并将其应用于NP完全问题“子集和”。通过利用实例的内在结构（即实例复杂度证书），该算法能够实现自适应的运行时间，并在所有实例上严格优于传统的$O^*(2^{n/2})$方法。这不仅是理论上的突破，也为未来设计更高效的NP完全问题求解算法开辟了新的研究方向。它挑战了传统上对NP完全问题固定最坏情况复杂度的认知，引入了实例复杂度的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有NP完全问题的算法通常不考虑输入实例的内在结构。本文旨在开发一种新的算法，其运行时间能够根据特定实例的信息理论最小证据（即实例复杂度证书）进行自适应调整，从而实现更高效的求解。

**Method:** 本文提出了IC-SubsetSum算法，该算法通过枚举所有不同的子集和集合$\Sigma(S)$的元素来实现。对于子集和实例$(S, t)$，其中$U = |\Sigma(S)|$是实例复杂度（IC）证书。该算法的复杂度直接由证书大小决定。

**Result:** IC-SubsetSum算法的确定性版本在$O(U \cdot n^2)$时间复杂度和$O(U \cdot n)$空间复杂度下运行。其随机化版本实现了$O(U \cdot n)$的预期运行时间。该算法保证了在最坏情况下达到$O^*(2^{n/2 - \varepsilon})$的运行时间，首次在所有实例上严格优于经典的$O^*(2^{n/2})$方法。此外，研究表明，依赖于经典$2^{n/2}$子集和硬度的细粒度归约仅适用于$U$达到最大值的无冲突实例。

**Conclusion:** 本文提出了一个证书敏感的子集和算法，其性能与实例的内在结构（通过实例复杂度证书衡量）紧密相关，并在所有实例上超越了传统方法。这为NP完全问题引入了一种新的证书敏感算法范式。

> **ai_Abstract:** 本文首次提出了一种针对NP完全问题“子集和”的确定性、证书敏感算法IC-SubsetSum。该算法的运行时间$O(U \cdot n^2)$（确定性）或$O(U \cdot n)$（随机化）直接取决于实例复杂度证书$U$的大小，并且在最坏情况下性能优于所有经典方法。研究还发现，依赖于$2^{n/2}$硬度的细粒度归约仅对特定类型的实例有效。这项工作为NP完全问题提供了一个新的证书敏感算法范式。

> **摘要翻译:** 据我们所知，本文首次提出了一种针对典型NP完全问题的确定性、证书敏感算法，其运行时间可根据每个输入的结构进行自适应调整。对于一个子集和实例$(S, t)$，令$\Sigma(S)$表示不同子集和的集合，并定义$U = |\Sigma(S)|$。这个集合作为信息论上最小的证据，即实例复杂度（IC）证书。
我们的求解器IC-SubsetSum以确定性时间$O(U \cdot n^2)$和空间$O(U \cdot n)$枚举$\Sigma(S)$的每个元素。一个随机化变体实现了$O(U \cdot n)$的预期运行时间。因此，该算法的复杂度直接由证书大小决定，并且这种结构敏感的性能伴随着$O^*(2^{n/2 - \varepsilon})$（对于某个常数$\varepsilon > 0$）的最坏情况运行时间保证，这是首次在每个实例上严格优于经典方法的结果。
我们重新审视了依赖于子集和经典$2^{n/2}$硬度的细粒度归约，并表明这些论证仅适用于$U$最大化的无冲突实例。IC-SubsetSum从结构上重新定义了这一障碍，并为NP完全问题引入了一种新的证书敏感算法范式。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [227] [Online Housing Market](https://arxiv.org/abs/2501.15916)
> *在线住房市场*

*Julien Lesca* | **Category: cs.GT, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 在线住房市场, 机制设计, 帕累托效率, 策略抗性, 串行独裁

**Comment:** 

> **TL;DR:** 本文研究在线住房市场问题，发现现有机制难以同时保持所有理想特性，并提出了新的变体。

**AI_Comments:** 这项研究通过将经典的住房市场问题置于动态的在线环境中，探讨了机制设计在实时、不完全信息条件下的挑战。其创新之处在于指出了在线环境下实现所有理想特性（如帕累托效率和策略抗性）的局限性，并提出了实用的权衡方案，这对于理解和设计动态市场机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究著名的住房市场问题的一个在线变体，其中代理人可以随时进入和离开市场，且不总是在市场中同时出现。

**Method:** 将经典的串行独裁机制和Gale的最高交易循环机制扩展到在线场景，旨在保留帕累托效率、个体理性和策略抗性等理想特性，并防止代理人策略性地延迟或提前行动。

**Result:** 证明在在线环境下不可能同时实现所有理想特性，并提出了实现这些特性不同子集的几种变体。

**Conclusion:** 在线住房市场中，同时实现帕累托效率、个体理性和策略抗性等所有理想特性是不可能的，需要权衡取舍。

> **ai_Abstract:** 本文探讨了在线住房市场问题，其中代理人可以动态进出。作者将传统的串行独裁和最高交易循环机制扩展到在线环境，旨在保持帕累托效率、个体理性和策略抗性等关键特性，并避免代理人的策略性行为。研究结果表明，在在线设置中无法同时实现所有这些理想特性，因此提出了多种机制变体，它们各自实现这些特性中的一部分。

> **摘要翻译:** 本文研究了著名的住房市场问题的一个在线变体，其中每个代理人拥有一套住房，并根据其偏好寻求将其交换为另一套。在这种在线设置中，代理人可能随时到达和离开，这意味着并非所有代理人同时出现在住房市场上。我将众所周知的串行独裁机制和Gale的最高交易循环机制扩展到这种在线场景，旨在保留它们理想的特性，例如帕累托效率、个体理性和策略抗性。这些扩展还旨在防止代理人策略性地延迟其到达或提前其离开。我证明了在在线环境下同时实现所有这些特性是不可能的，并且我提出了几种实现这些特性不同子集的变体。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [245] [Modular and Automated Workflow for Streamlined Raman Signal Analysis](https://arxiv.org/abs/2507.17917)
> *模块化自动化流程，简化拉曼信号分析*

*Mykyta Kizilov, Vsevolod Cheburkanov, Joseph Harrington, Vladislav V. Yakovlev* | **Category: physics.optics, eess.SP, physics.chem-ph** | **Updated: 2025-07-23**

**Keywords:** 拉曼光谱, 数据预处理, Voigt峰拟合, 自动化工作流程, 开源

**Comment:** Preprint. Submitted to Journal of Raman Spectroscopy

> **TL;DR:** 本文提出了一种模块化、自动化的拉曼光谱数据生成、预处理和峰拟合方法，并证明了其有效性，代码已开源。

**AI_Comments:** 该论文的创新之处在于提供了一个模块化和自动化的拉曼信号分析工作流程，这对于简化复杂的拉曼数据预处理至关重要。将代码开源，进一步提高了研究的实用性和可复现性。它解决了拉曼光谱分析中常见的挑战，有助于提高分析效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 拉曼光谱分析需要细致的预处理来识别和处理噪声、基线漂移和随机尖峰。

**Method:** 论文提出了一种生成和预处理拉曼光谱的综合方法，并描述了使用Voigt峰拟合光谱以确定峰参数的方法。

**Result:** 这些方法的有效性通过合成和真实的拉曼光谱得到了证明，并且代码在开源GitHub仓库中提供。

**Conclusion:** 本文提出的模块化自动化工作流程能够有效简化拉曼信号分析，提高数据处理的效率和准确性。

> **ai_Abstract:** 本文介绍了一种模块化且自动化的拉曼光谱数据分析工作流程。该流程涵盖了拉曼光谱的生成、预处理（处理噪声、基线漂移和尖峰）以及通过Voigt峰拟合确定峰参数的方法。研究通过合成和真实数据验证了所提方法的有效性，并提供了开源代码。

> **摘要翻译:** 拉曼光谱是材料表征的强大工具。然而，为了识别和处理噪声、基线漂移和随机尖峰，需要仔细的预处理。本文提出了一种生成和预处理拉曼光谱的综合方法。此外，我们描述了将Voigt峰拟合到光谱以确定峰参数的方法。这些方法的有效性通过合成和真实的拉曼光谱得到了证明，代码已在开源GitHub仓库中提供。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

### [430] [Theoretical Model of Microparticle-Assisted Super-Resolution Microscopy](https://arxiv.org/abs/2504.10268)
> *微粒辅助超分辨显微镜的理论模型*

*A. R Bekirov* | **Category: physics.optics, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 微粒辅助成像, 超分辨显微镜, 理论模型, 空间相干性, 波动光学

**Comment:** 

> **TL;DR:** 提出了首个微粒辅助超分辨成像的三维理论模型，并揭示了部分空间相干性对超分辨成像的重要性，同时提出了一种新的照明策略以提高图像对比度和分辨率。

**AI_Comments:** 这项工作首次提出了微粒辅助超分辨成像的三维理论模型，填补了该领域的空白。其创新之处在于强调了照明部分空间相干性的重要性，并提出了一种新颖的照明策略。这为理解和优化微粒辅助超分辨显微技术提供了坚实的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 准确模拟虚拟图像形成，并阐明微粒辅助超分辨成像的物理机制。

**Method:** 提出了首个微粒辅助超分辨成像的三维理论模型，并提出了一种基于抑制入射光法向分量的新型照明策略。

**Result:** 模型揭示了考虑照明的部分空间相干性是实现超分辨的基本前提。提出的照明策略增强了图像对比度和分辨率。结果建立了一个与实验观察到的亚波长成像一致的波动光学框架，并阐明了其潜在的物理机制。

**Conclusion:** 建立了一个一致的波动光学框架，能够重现实验观察到的亚波长成像，并阐明了微粒辅助超分辨成像的潜在物理机制，强调了照明部分空间相干性的重要性。

> **ai_Abstract:** 本研究提出了首个用于微粒辅助超分辨成像的三维理论模型，旨在准确模拟虚拟图像形成。该模型强调了照明部分空间相干性对于实现超分辨的重要性。此外，论文还提出了一种通过抑制入射光法向分量来提高图像对比度和分辨率的新型照明策略。研究结果建立了一个与实验观察相符的波动光学框架，并阐明了亚波长成像的物理机制。

> **摘要翻译:** 我们提出了首个微粒辅助超分辨成像的三维理论模型，能够准确模拟虚拟图像的形成。该模型揭示了考虑照明的部分空间相干性是实现超分辨的基本前提。我们还提出了一种基于抑制入射光法向分量的新型照明策略，该策略能增强图像对比度和分辨率。研究结果建立了一个一致的波动光学框架，再现了实验观察到的亚波长成像，并阐明了其潜在的物理机制。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [246] [A Two-armed Bandit Framework for A/B Testing](https://arxiv.org/abs/2507.18118)
> *A/B测试的双臂赌博机框架*

*Jinjuan Wang, Qianglin Wen, Yu Zhang, Xiaodong Yan, Chengchun Shi* | **Category: stat.ML, cs.LG, stat.AP** | **Updated: 2025-07-24**

**Keywords:** A/B测试, 双臂赌博机, 双重稳健估计, 置换检验, 统计功效

**Comment:** 

> **TL;DR:** 本文提出了一种基于双臂赌博机框架的新型A/B测试方法，通过结合双重稳健估计和置换方法，显著提高了现有方法的功效。

**AI_Comments:** 该论文的创新点在于将双臂赌博机框架引入到A/B测试中，并结合了双重稳健估计和置换检验，这为提高A/B测试的统计功效提供了一个新颖且有效的方法。其在理论和实践中的验证增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** A/B测试在现代科技公司中广泛用于策略评估和产品部署，但现有方法的统计功效可能需要提升。本文旨在引入一个双臂赌博机框架来提高现有方法的功效。

**Method:** 所提出的方法包含三个主要步骤：(i) 采用双重稳健估计生成伪结果；(ii) 利用双臂赌博机框架构建检验统计量；(iii) 应用基于置换的方法计算p值。

**Result:** 通过渐近理论、数值实验和来自一家网约车公司的真实世界数据，证明了所提出方法的有效性，并显示其性能优于现有方法。

**Conclusion:** 提出的双臂赌博机框架显著提高了A/B测试的统计功效，并在理论和实践中展现出优越性。

> **ai_Abstract:** 本文提出了一种新颖的双臂赌博机框架用于A/B测试，旨在提升现有方法的统计功效。该方法结合了双重稳健估计生成伪结果、利用双臂赌博机构建检验统计量，以及应用置换方法计算p值。通过理论分析、数值模拟和真实世界数据验证，该框架展现出优于现有方法的性能。

> **摘要翻译:** A/B测试在现代科技公司中被广泛应用于策略评估和产品部署，旨在比较新开发策略与标准对照策略下的结果。文献中开发的各种因果推断和强化学习方法都适用于A/B测试。本文引入了一个双臂赌博机框架，旨在提高现有方法的功效。所提出的程序包括三个主要步骤：(i) 采用双重稳健估计生成伪结果；(ii) 利用双臂赌博机框架构建检验统计量；(iii) 应用基于置换的方法计算p值。我们通过渐近理论、数值实验以及来自一家网约车公司的真实世界数据证明了所提出方法的有效性，结果显示其性能优于现有方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [311] [On Reconstructing Training Data From Bayesian Posteriors and Trained Models](https://arxiv.org/abs/2507.18372)
> *从贝叶斯后验和训练模型中重建训练数据*

*George Wynne* | **Category: stat.ML, cs.LG, math.ST, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 训练数据重建, 贝叶斯模型, 分数匹配, 最大平均差异, 机器学习安全

**Comment:** 

> **TL;DR:** 本文针对现代机器学习中训练数据重建攻击的漏洞，提出了一个数学框架来表达问题，通过最大平均差异等价来表征易受攻击的训练数据特征，并概述了一个用于贝叶斯和非贝叶斯模型的数据重建分数匹配框架，其中贝叶斯模型的应用是首次提出。

**AI_Comments:** 该论文解决了机器学习领域一个重要的隐私和安全问题。其创新之处在于将数据重建方法扩展到贝叶斯模型，并提供了一个结构化的数学方法来处理这一挑战。

<details>
  <summary>Details</summary>

**Motivation:** 当模型的规范及其训练参数被公开时，攻击者可以通过训练数据重建攻击来尝试重建训练数据的信息，这被认为是现代机器学习方法的一个主要漏洞。

**Method:** 本文建立了表达训练数据重建问题的数学框架，通过最大平均差异（MMD）等价来表征易受攻击的训练数据特征，并提出了一个用于贝叶斯和非贝叶斯模型中重建数据的分数匹配框架。

**Result:** 本文的主要成果是建立了表达训练数据重建问题的数学框架，表征了训练数据中易受攻击的特征，并提出了一个全新的分数匹配框架，用于在贝叶斯和非贝叶斯模型中重建数据，其中针对贝叶斯模型的数据重建是文献中的首次尝试。

**Conclusion:** 本文通过建立数学框架、表征易受攻击特征和提出分数匹配框架，为解决从贝叶斯后验和训练模型中重建训练数据的挑战做出了贡献。

> **ai_Abstract:** 本文旨在解决现代机器学习模型中训练数据重建攻击的重大漏洞。论文贡献包括建立一个数学框架来形式化该问题，利用最大平均差异等价来识别训练数据中易受攻击的特征，并提出了一个新颖的分数匹配框架，用于在贝叶斯和非贝叶斯模型中进行数据重建，其中在贝叶斯模型中的应用是首次提出。

> **摘要翻译:** 公开模型及其训练参数的规范意味着攻击者可以通过训练数据重建攻击来尝试重建训练数据的信息，这是现代机器学习方法的一个主要漏洞。本文提出了三个主要贡献：建立一个表达该问题的数学框架；通过最大平均差异等价来表征训练数据中易受攻击的特征；以及概述一个用于在贝叶斯和非贝叶斯模型中重建数据的分数匹配框架，其中后者在文献中是首次提出。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [376] [DriftMoE: A Mixture of Experts Approach to Handle Concept Drifts](https://arxiv.org/abs/2507.18464)
> *DriftMoE：一种处理概念漂移的专家混合方法*

*Miguel Aspis, Sebastián A. Cajas Ordónez, Andrés L. Suárez-Cetrulo, Ricardo Simón Carbajo* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 概念漂移, 专家混合, 在线学习, 数据流, 自适应集成

**Comment:** Accepted at the SYNDAiTE@ECMLPKDD 2025 workshop

> **TL;DR:** DriftMoE是一种在线专家混合模型，通过协同训练的路由器和专门的Hoeffding树专家，有效处理概念漂移，性能与现有最佳方法相当。

**AI_Comments:** DriftMoE的创新之处在于其独特的共生学习循环，它通过路由器和专家之间的动态反馈机制实现了高效的专家专业化和适应性。这种方法克服了传统集成方法在处理概念漂移时粗粒度适应和知识利用不足的局限性，为在线数据流学习提供了一个有前景的框架。

<details>
  <summary>Details</summary>

**Motivation:** 在非平稳数据流中学习并应对概念漂移需要模型能够即时适应并保持资源效率。现有的自适应集成方法通常依赖粗粒度适应机制或简单的投票方案，未能充分利用专业知识。

**Method:** 本文提出了DriftMoE，一种在线专家混合（MoE）架构，通过新颖的协同训练框架解决现有局限性。DriftMoE包含一个紧凑的神经网络路由器，与一组增量Hoeffding树专家协同训练。其关键创新在于一个共生学习循环，该循环实现专家专业化：路由器选择最合适的专家进行预测，相关专家用真实标签进行增量更新，路由器使用多热正确性掩码细化其参数，以强化每个准确的专家。这种反馈循环为路由器提供了清晰的训练信号，同时加速了专家专业化。

**Result:** DriftMoE在涵盖突变、渐变和真实世界漂移的九个最先进数据流学习基准上进行了评估，测试了两种不同的配置（专家专注于数据机制的多类别变体和专注于单类别专业化的任务型变体）。结果表明，DriftMoE与最先进的流学习自适应集成方法取得了竞争性结果。

**Conclusion:** DriftMoE为概念漂移适应提供了一种有原则且高效的方法。

> **ai_Abstract:** 本文提出DriftMoE，一种在线专家混合（MoE）架构，旨在解决概念漂移问题。它通过协同训练的神经网络路由器和增量Hoeffding树专家实现自适应。DriftMoE引入了一个共生学习循环，使专家能够专业化，并通过路由器选择、专家更新和基于正确性掩码的路由器参数优化来加速这一过程。实验结果表明，DriftMoE在处理多种概念漂移方面与现有最先进的自适应集成方法表现相当，提供了一种高效且有原则的解决方案。

> **摘要翻译:** 从受概念漂移影响的非平稳数据流中学习，需要模型能够即时适应并保持资源效率。现有的自适应集成方法通常依赖粗粒度的适应机制或简单的投票方案，未能最佳地利用专业知识。本文引入了DriftMoE，一种在线专家混合（MoE）架构，通过新颖的协同训练框架解决了这些局限性。DriftMoE的特点是一个紧凑的神经网络路由器，与一组增量Hoeffding树专家协同训练。其关键创新在于一个共生学习循环，该循环实现了专家专业化：路由器选择最适合预测的专家，相关专家用真实标签进行增量更新，路由器使用多热正确性掩码细化其参数，以强化每个准确的专家。这种反馈循环为路由器提供了清晰的训练信号，同时加速了专家专业化。我们在涵盖突变、渐变和真实世界漂移的九个最先进数据流学习基准上评估了DriftMoE的性能，测试了两种不同的配置：一种是专家专注于数据机制（多类别变体），另一种是专家专注于单类别专业化（任务型变体）。我们的结果表明，DriftMoE与最先进的流学习自适应集成方法取得了竞争性结果，为概念漂移适应提供了一种有原则且高效的方法。所有代码、数据管道和可重现性脚本都可在我们的公共GitHub存储库中获取：https://github.com/miguel-ceadar/drift-moe。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [393] [Sliding Window Informative Canonical Correlation Analysis](https://arxiv.org/abs/2507.17921)
> *滑动窗口信息规范相关分析*

*Arvind Prasadan* | **Category: stat.ML, cs.LG, eess.IV, math.ST, stat.CO, stat.ME, stat.TH, 62H20, 62H25 (Primary) 62J10, 62L10 (Secondary)** | **Updated: 2025-07-23**

**Keywords:** 规范相关分析, 流数据, 滑动窗口, 主成分分析, 高维

**Comment:** 22 pages, submitted

> **TL;DR:** 本文提出了一种用于在线流数据的新型CCA扩展方法SWICCA，该方法结合流式PCA和滑动窗口实现实时CCA，适用于高维数据。

**AI_Comments:** 本文的创新之处在于将规范相关分析 (CCA) 扩展到在线流数据环境，这对于实时数据处理至关重要。结合流式主成分分析 (PCA) 和滑动窗口的方法，巧妙地解决了流数据动态性和高维计算效率的挑战。理论性能保证和真实数据示例进一步增强了该方法的可靠性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 规范相关分析 (CCA) 是一种用于在两个数据集中寻找相关特征集的技术，但传统的CCA可能不适用于在线、流数据设置。因此，本文旨在提出一种适用于这种数据环境的CCA扩展。

**Method:** 本文提出了一种名为滑动窗口信息规范相关分析 (SWICCA) 的新型CCA扩展方法。该方法使用流式主成分分析 (PCA) 算法作为后端，并将这些输出与一小部分滑动窗口样本结合，以实时估计CCA分量。

**Result:** 通过数值模拟表征了其性能，并提供了理论性能保证。SWICCA方法适用于并可扩展到极高维度，并通过真实数据示例证明了其能力。

**Conclusion:** SWICCA是一种有效且可扩展的在线流数据规范相关分析方法，能够实时处理高维数据。

> **ai_Abstract:** 本文介绍了一种名为SWICCA的新型规范相关分析 (CCA) 扩展，专为在线流数据设计。SWICCA通过结合流式主成分分析 (PCA) 和滑动窗口技术，实现了CCA分量的实时估计。该方法在高维数据处理方面表现出良好的适用性和可扩展性，并通过数值模拟和真实数据示例验证了其性能和理论保证。

> **摘要翻译:** 规范相关分析 (CCA) 是一种用于在两个数据集中寻找相关特征集的技术。在本文中，我们提出了一种CCA的新颖扩展，适用于在线、流数据设置：滑动窗口信息规范相关分析 (SWICCA)。我们的方法使用流式主成分分析 (PCA) 算法作为后端，并结合这些输出和一小部分滑动窗口样本来实时估计CCA分量。我们阐述并描述了我们的算法，提供了数值模拟来表征其性能，并提供了理论性能保证。SWICCA方法适用于并可扩展到极高维度，我们提供了一个真实数据示例来证明其能力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [428] [Robust Non-adaptive Group Testing under Errors in Group Membership Specifications](https://arxiv.org/abs/2409.05345)
> *鲁棒非适应性群组测试，在群组成员规范错误下*

*Shuvayan Banerjee, Radhendushka Srivastava, James Saunderson, Ajit Rajwade* | **Category: stat.ML, cs.IT, cs.LG, math.IT** | **Updated: 2025-07-24**

**Keywords:** 群组测试, 鲁棒性, Lasso, 去偏, 成员错误

**Comment:** 

> **TL;DR:** 本文提出了一种新的群组测试方法（DRLT），用于在群组成员规范存在错误的情况下识别缺陷样本和错误指定组，该方法基于去偏Lasso，并数值结果显示其优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了DRLT方法，将Lasso的去偏技术应用于群组测试领域，以应对实际应用中常见的群组成员规范错误问题。其理论贡献包括提供了重建误差的理论上限，并结合了识别缺陷样本和错误指定组的特定假设检验。该工作扩展了统计估计器偏差缓解的文献，特别是在测量数据包含由特定错误（如组成员规范错误）引起的异常值的情况下。该方法对于需要高精度缺陷识别但数据采集可能存在误差的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有群组测试（GT）方法都假设群组成员关系是准确指定的，然而在实际应用中，由于资源限制或人为错误，这种假设可能不成立，导致群组成员规范出现错误。这些错误会影响缺陷样本的识别准确性。

**Method:** 本文开发了一种新的GT方法，称为去偏鲁棒Lasso测试方法（DRLT），旨在处理群组成员规范错误。DRLT方法基于去偏（或减少Lasso估计中固有偏差）Lasso技术。该方法还提供了重建误差的理论上限，并结合了两个精心设计的假设检验，分别用于(i)在群组成员规范错误存在的情况下识别缺陷样本，以及(ii)识别具有错误成员规范的组。

**Result:** 数值结果表明，所提出的DRLT方法在识别缺陷样本和错误指定组方面，优于多种基线方法和鲁棒回归技术。

**Conclusion:** DRLT方法有效解决了群组测试中群组成员规范错误的问题，通过去偏Lasso和特定的假设检验，实现了对缺陷样本和错误指定组的鲁棒识别，并且性能优于现有技术。

> **ai_Abstract:** 本文提出了一种名为去偏鲁棒Lasso测试方法（DRLT）的新型群组测试框架，旨在解决现有群组测试方法在群组成员规范存在错误时的局限性。DRLT方法通过去偏Lasso估计并结合两个专门设计的假设检验，实现了在存在成员规范错误的情况下对缺陷样本和错误指定组的鲁棒识别。数值实验结果表明，DRLT在性能上超越了多种基线和鲁棒回归技术。

> **摘要翻译:** 给定p个样本，每个样本可能存在缺陷也可能没有，群组测试（GT）旨在通过对n < p个“组”进行测试来确定它们的缺陷状态，其中一个组是通过混合p个样本的子集形成的。假设缺陷样本的数量与p相比非常小，GT算法即使使用少量组也能出色地恢复所有p个样本的状态。然而，大多数现有方法都假设群组成员关系被准确指定。由于各种资源限制，这个假设在所有应用中可能并非总是如此。例如，当技术人员在实验室准备组时，无意中混合了与指定不符的错误样本子集，就可能发生此类错误。我们开发了一种新的GT方法，即去偏鲁棒Lasso测试方法（DRLT），用于处理此类群组成员规范错误。所提出的DRLT方法基于一种去偏或减少Lasso（一种流行且有效的稀疏回归技术）产生的估计中固有偏差的方法。我们还提供了我们的估计器产生的重建误差的理论上限。然后，我们的方法结合了两个精心设计的假设检验，分别用于(i)在群组成员规范错误存在的情况下识别缺陷样本，以及(ii)识别具有错误成员规范的组。DRLT方法扩展了统计估计器（如LASSO）的偏差缓解文献，以处理由于群组成员规范错误等因素导致某些测量值包含异常值的重要情况。我们提供了数值结果，表明我们的方法在识别缺陷样本以及错误指定组方面优于几种基线方法和鲁棒回归技术。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [460] [Euclidean Distance Deflation Under High-Dimensional Heteroskedastic Noise](https://arxiv.org/abs/2507.18520)
> *高维异方差噪声下的欧几里德距离消除*

*Keyi Li, Yuval Kluger, Boris Landa* | **Category: stat.ML, cs.LG, math.ST, stat.TH, 62R07, 62G** | **Updated: 2025-07-24**

**Keywords:** 欧几里德距离, 异方差噪声, 高维, 噪声估计, 距离校正

**Comment:** 

> **TL;DR:** 本文提出了一种在不预设干净数据结构或噪声分布的情况下，在高维异方差噪声下可靠地估计噪声大小并校正欧几里德距离的方法，并提供了理论保证和实验验证。

**AI_Comments:** 本文的创新点在于提出了一个无需超参数且无需先验知识的通用方法来处理高维异方差噪声对欧几里德距离的影响。理论保证的提供增强了其可靠性，而其在实际应用（如单细胞RNA测序数据）中的有效性则凸显了其重要性，为许多依赖于精确距离计算的下游任务提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，成对欧几里德距离经常被异方差噪声（一种噪声大小因数据观测而异的不均匀损坏形式）扭曲。这种噪声会非平凡地膨胀计算出的距离，导致对底层数据几何的错误表示，影响许多机器学习和数据分析算法。

**Method:** 开发了一种原则性的、无超参数的方法，可以联合估计每个观测值的噪声大小并校正成对欧几里德距离。该方法提供了理论保证，建立了噪声大小和距离估计误差的概率界限，这些界限在特征维度和数据集大小增加时以多项式速率收敛到零。

**Result:** 在合成数据集上的实验表明，该方法在具有挑战性的情况下能准确估计距离，显著提高了后续基于距离计算的鲁棒性。值得注意的是，当应用于单细胞RNA测序数据时，该方法产生的噪声大小估计与已建立的原型模型一致，并能实现对许多下游分析至关重要的精确近邻识别。

**Conclusion:** 在高维异方差噪声下，即使没有关于干净数据结构或噪声分布的先验知识，本文提出的方法也能可靠地估计噪声大小并校正欧几里德距离，从而显著提高后续距离相关计算的准确性和鲁棒性。

> **ai_Abstract:** 本研究解决了在高维异方差噪声下估计噪声大小并校正成对欧几里德距离的问题。现有方法常因噪声导致距离膨胀并扭曲数据几何。本文提出了一种无超参数的原则性方法，能够在不预设先验知识的情况下，联合估计噪声大小并校正距离，并提供了严格的理论保证。实验结果表明，该方法在合成数据和单细胞RNA测序数据上均表现出色，显著提高了距离计算的准确性和下游分析的鲁棒性。

> **摘要翻译:** 成对欧几里德距离计算是许多机器学习和数据分析算法中的基本步骤。然而，在实际应用中，这些距离经常被异方差噪声——一种普遍存在的不均匀损坏形式，其特征是数据观测中的噪声大小可变——所扭曲。这种噪声以一种非平凡的方式膨胀了计算出的距离，导致对底层数据几何的错误表示。在这项工作中，我们解决了在高维异方差噪声下估计每个观测值的噪声大小并校正成对欧几里德距离的任务。或许令人惊讶的是，我们表明在一般高维设置中，并且在不假设关于干净数据结构或噪声分布的先验知识的情况下，即使噪声水平变化很大，这两个任务也可以可靠地执行。具体来说，我们开发了一种原则性的、无超参数的方法，可以联合估计噪声大小并校正距离。我们为我们的方法提供了理论保证，建立了噪声大小和距离估计误差的概率界限。这些以归一化L1范数衡量的界限，在特征维度和数据集大小都增加时以多项式速率收敛到零。合成数据集上的实验表明，我们的方法在具有挑战性的情况下能准确估计距离，显著提高了后续基于距离计算的鲁棒性。值得注意的是，当应用于单细胞RNA测序数据时，我们的方法产生的噪声大小估计与已建立的原型模型一致，从而实现了对许多下游分析至关重要的精确近邻识别。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [605] [Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance](https://arxiv.org/abs/2303.01256)
> *通过梯度子空间距离为隐私机器学习选择公共数据集*

*Xin Gu, Gautam Kamath, Zhiwei Steven Wu* | **Category: stat.ML, cs.CR, cs.CV, cs.DS, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 差分隐私, 机器学习, 公共数据集, 梯度子空间距离, 数据集选择

**Comment:** Accepted to SaTML 2025

> **TL;DR:** 本文提出了一种通过测量公共和私有数据梯度之间的子空间距离来选择最佳公共数据集的算法，以提高差分隐私机器学习的准确性。

**AI_Comments:** 本文提出了一种新颖且有理论依据的方法来解决差分隐私机器学习中公共数据集选择的关键问题。通过引入梯度子空间距离，该方法为如何有效利用公共数据来提高隐私模型的性能提供了一个清晰的指导，具有重要的实践意义和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 在差分隐私机器学习中，利用公共数据可以减少训练过程中的噪声。然而，目前尚不清楚如何在多个公共数据集中选择最适合特定隐私任务的数据集。

**Method:** 作者提出了一种算法，通过计算公共和私有示例梯度之间的低维子空间距离来选择公共数据集。

**Result:** 理论分析表明，超额风险与这种子空间距离成正比。该距离易于计算且对设置修改具有鲁棒性。经验评估显示，训练模型的准确性与该距离单调相关。

**Conclusion:** 梯度子空间距离是选择用于隐私机器学习的公共数据集的有效标准，能够提高模型准确性并降低风险。

> **ai_Abstract:** 该论文解决了差分隐私机器学习中公共数据集选择的挑战。作者提出了一种算法，通过测量公共和私有数据梯度之间的低维子空间距离来选择最合适的公共数据集。理论分析表明，超额风险与该子空间距离呈比例关系，且该距离易于计算并具有鲁棒性。经验评估进一步证实，训练模型的准确性与该距离单调相关，证明了所提出方法的有效性。

> **摘要翻译:** 差分隐私随机梯度下降通过在每次迭代中注入噪声来隐私化模型训练，其中噪声幅度随模型参数的数量而增加。最近的工作表明，我们可以通过利用公共数据进行隐私机器学习来减少噪声，方法是将梯度投影到公共数据规定的子空间上。然而，在给定一系列公共数据集的情况下，事先不清楚哪一个最适合隐私任务。我们提出了一种算法，通过测量公共和私有示例梯度之间的低维子空间距离来选择公共数据集。我们提供了理论分析，表明超额风险与此子空间距离成比例。该距离易于计算，并且对设置的修改具有鲁棒性。经验评估表明，训练模型的准确性与该距离单调相关。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [683] [Fixing the Pitfalls of Probabilistic Time-Series Forecasting Evaluation by Kernel Quadrature](https://arxiv.org/abs/2503.06079)
> *通过核正交修正概率时间序列预测评估的陷阱*

*Masaki Adachi, Masahiro Fujisawa, Michael A Osborne* | **Category: stat.ML, cs.LG, 62C10, 62F15** | **Updated: 2025-07-24**

**Keywords:** 概率时间序列预测, 评估, 连续排名概率分数, 核正交, 偏差

**Comment:** 11 pages, 6 figures

> **TL;DR:** 本文通过引入核正交方法，解决了概率时间序列预测评估中连续排名概率分数（CRPS）估计器的偏差问题，并提高了评估准确性。

**AI_Comments:** 本文创新性地提出了核正交方法来解决概率时间序列预测评估中CRPS估计器的固有偏差问题。通过提供无偏估计和可扩展的计算，该工作对于提高时间序列预测模型评估的准确性和可靠性具有重要意义，有望避免因评估偏差导致的错误模型选择。

<details>
  <summary>Details</summary>

**Motivation:** 概率时间序列预测模型的评估指标（如CRPS）涉及难以处理的积分，其计算需要近似。然而，现有的流行CRPS估计器（如GluonTS中基于分位数的估计器和概率加权矩近似）存在固有的估计偏差，导致近似粗糙，并在CRPS值接近时导致预测模型性能排名不准确。

**Method:** 引入了一种核正交方法，该方法利用无偏的CRPS估计器，并采用立体化构造（cubature construction）实现可扩展的计算。

**Result:** 实验结果表明，所提出的方法始终优于两种广泛使用的CRPS估计器。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文解决了概率时间序列预测模型评估中的一个关键问题，即连续排名概率分数（CRPS）估计器的偏差。研究发现，现有流行的CRPS估计器（如GluonTS中的分位数估计器和概率加权矩近似）存在固有偏差，导致模型性能排名不准确。为解决此问题，作者提出了一种基于核正交的新方法，该方法利用无偏CRPS估计器并采用立体化构造以实现可扩展计算。实验证明，该方法在性能上持续优于现有的两种广泛使用的CRPS估计器。

> **摘要翻译:** 尽管概率时间序列预测模型具有重要意义，但其评估指标通常涉及难以处理的积分。最广泛使用的指标——连续排名概率分数（CRPS），是一个严格适当的评分函数；然而，它的计算需要近似。我们发现流行的CRPS估计器——特别是广泛使用的GluonTS库中实现的分位数估计器和概率加权矩近似——都表现出固有的估计偏差。这些偏差导致粗糙的近似，当CRPS值接近时，会导致预测模型性能排名不当。为了解决这个问题，我们引入了一种核正交方法，该方法利用无偏的CRPS估计器，并采用立体化构造（cubature construction）实现可扩展的计算。从经验上看，我们的方法始终优于两种广泛使用的CRPS估计器。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [695] [Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization](https://arxiv.org/abs/2503.15704)
> *通过贪婪增量散度最小化调整序贯蒙特卡罗采样器*

*Kyurae Kim, Zuheng Xu, Jacob R. Gardner, Trevor Campbell* | **Category: stat.ML, cs.LG, stat.CO** | **Updated: 2025-07-23**

**Keywords:** 序贯蒙特卡罗采样器, 马尔可夫核, KL散度, 步长调整, 无梯度算法

**Comment:** Accepted to ICML'25; v4: fixed typos

> **TL;DR:** 本文提出一种新的通用自适应框架，通过最小化增量Kullback-Leibler（KL）散度来高效调整序贯蒙特卡罗（SMC）采样器中的马尔可夫核，其计算成本远低于基于梯度的方法。

**AI_Comments:** 这篇论文通过引入增量KL散度最小化作为新的调整目标，解决了SMC采样器中马尔可夫核调整的效率问题，特别是对于无法使用传统度量的场景。其创新之处在于提供了一种无需梯度且计算成本显著降低的调整方法，这对于SMC采样器在实际应用中的可扩展性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 序贯蒙特卡罗（SMC）采样器的性能严重依赖于马尔可夫核的调整。对于使用未调整马尔可夫核的SMC采样器，标准调整目标不再适用。现有的基于随机梯度的端到端优化方法通常会产生过高的训练成本。

**Method:** 提出一个通用的自适应框架，通过最小化提议路径和目标路径之间的增量Kullback-Leibler（KL）散度来调整SMC采样器中的马尔可夫核。对于步长调整，提供了一种无需梯度和调整的算法，普遍适用于Langevin Monte Carlo（LMC）等核。还为SMC采样器中使用的动能LMC提供了定制方案。

**Result:** 我们的实现能够以几次普通SMC运行的成本获得完整的调整参数表，这只是基于梯度方法所需成本的一小部分。

**Conclusion:** 本文提出的框架通过最小化增量KL散度，提供了一种高效且计算成本显著降低的马尔可夫核调整方法，尤其适用于无法使用传统度量的SMC采样器，并能有效进行无梯度步长调整。

> **ai_Abstract:** 本文针对序贯蒙特卡罗（SMC）采样器中马尔可夫核调整的效率问题，提出了一种新的通用自适应框架。该框架通过最小化提议路径与目标路径之间的增量Kullback-Leibler（KL）散度来调整马尔可夫核，旨在解决现有标准调整目标不适用及基于梯度方法训练成本过高的问题。研究提供了一种无需梯度且普遍适用的步长调整算法，并展示了其在动能Langevin Monte Carlo（LMC）中的应用。结果表明，该方法能以远低于基于梯度方法的计算成本获得完整的调整参数。

> **摘要翻译:** 序贯蒙特卡罗（SMC）采样器的性能严重依赖于路径提议中使用的马尔可夫核的调整。对于使用未调整马尔可夫核的SMC采样器，标准的调整目标，例如Metropolis-Hastings接受率或预期平方跳跃距离，不再适用。虽然已经探索了基于随机梯度的端到端优化来调整SMC采样器，但它们通常会产生过高的训练成本，即使仅仅是为了调整核步长。在这项工作中，我们提出了一种通用的自适应框架，通过最小化提议路径和目标路径之间的增量Kullback-Leibler（KL）散度来调整SMC采样器中的马尔可夫核。对于步长调整，我们提供了一种无需梯度和调整的算法，该算法普遍适用于Langevin Monte Carlo（LMC）等核。我们通过为SMC采样器中使用的动能LMC提供量身定制的方案，进一步证明了我们方法的实用性。我们的实现能够以几次普通SMC运行的成本获得完整的调整参数表，这只是基于梯度方法的一小部分。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='physicsplasm-ph'></a>
## physics.plasm-ph 

### [272] [Multiple solutions to the static forward free-boundary Grad-Shafranov problem on MAST-U](https://arxiv.org/abs/2503.05674)
> *MAST-U上静态前向自由边界Grad-Shafranov问题的多重解*

*K. Pentland, N. C. Amorisco, P. E. Farrell, C. J. Ham* | **Category: physics.plasm-ph, cs.NA, math.NA** | **Updated: 2025-07-24**

**Keywords:** Grad-Shafranov方程, 多重解, 托卡马克, MAST-U, 自由边界

**Comment:** 

> **TL;DR:** 在MAST-U托卡马克几何中，使用FreeGSNKE和紧缩连续算法，发现了静态前向自由边界Grad-Shafranov问题的多个解，填补了以往研究在理想化几何中发现多重解但未在实际托卡马克中验证的空白。

**AI_Comments:** 这项研究的创新之处在于，它首次在真实的托卡马克几何（MAST-U）中，验证了Grad-Shafranov方程存在多重解的可能性，填补了以往研究仅限于理想化几何的空白。这对于理解托卡马克等离子体行为及其在受控核聚变中的应用具有重要意义。该工作强调了在实际工程应用中，即使是标准的平衡代码，也可能存在多个有效的物理解，这对于下游的模拟和实验操作提出了新的考虑。其局限性可能在于，虽然发现了多重解，但其物理稳定性或在实验中实际可达性仍需进一步验证。此外，对于积分自由边界条件限制更多解的推测，也需要更深入的理论和数值分析来支持。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究在理想化几何中，简化等离子体电流密度分布和边界条件下，已经证明了Grad-Shafranov (GS) 方程存在多个解。然而，在具有更复杂电流密度分布和积分自由边界条件（常用于生产级平衡代码）的真实世界托卡马克几何中，是否存在多个平衡解的问题一直未得到解答。

**Method:** 本研究使用经过验证的演化平衡求解器FreeGSNKE和紧缩连续算法，在MAST-U托卡马克几何中发现了静态前向自由边界Grad-Shafranov问题的多个解。通过改变等离子体电流、电流密度剖面系数或GS方程中的线圈电流，识别并表征了不同的平衡解。

**Result:** 研究发现了静态前向自由边界Grad-Shafranov问题的多个解，包括深度和浅度受限的等离子体状态。研究表明，积分自由边界条件的限制性可能阻止了更多平衡解的存在。

**Conclusion:** 本研究发现MAST-U托卡马克中存在GS方程的多重解，并讨论了这些发现对更广泛的平衡建模的意义。强调需要探索其他平衡代码和托卡马克中是否存在多重解，以及它们对依赖GS平衡的下游模拟的潜在影响。研究还提出，积分自由边界条件的限制性可能阻止了更多平衡解的存在。

> **ai_Abstract:** 本研究首次在真实的MAST-U托卡马克几何中，使用FreeGSNKE求解器和紧缩连续算法，发现了静态前向自由边界Grad-Shafranov (GS) 方程的多个平衡解，包括深度和浅度受限的等离子体状态。这解决了以往研究中在理想化几何中发现多重解，但在实际托卡马克中未能验证的问题。研究通过改变等离子体电流、电流密度剖面系数或线圈电流来识别这些解，并提出积分自由边界条件的限制性可能阻止了更多平衡解的存在。这些发现对更广泛的等离子体平衡建模具有重要意义，并呼吁在其他平衡代码和托卡马克中进一步探索多重解及其对下游模拟的影响。

> **摘要翻译:** Grad-Shafranov (GS) 方程是一个非线性椭圆偏微分方程，它控制着托卡马克等离子体的理想磁流体力学平衡。先前的研究已经证明，在理想化的几何中，当使用简化的等离子体电流密度分布和边界条件求解时，GS方程存在多个解。直到现在，在具有更复杂电流密度分布和积分自由边界条件（常用于生产级生产级平衡代码）的真实世界托卡马克几何中，是否存在多个平衡解的问题一直未得到解答。在这项工作中，我们使用经过验证的演化平衡求解器FreeGSNKE和紧缩连续算法，在MAST-U托卡马克几何中发现了静态前向自由边界GS问题的多个解。通过改变GS方程中的等离子体电流、电流密度剖面系数或线圈电流，我们识别并表征了不同的平衡解，包括深度和浅度受限的等离子体状态。我们认为，更多平衡解的存在可能受到积分自由边界条件的限制性性质的阻碍，该条件将计算边界上的极向磁通与内部的极向磁通全局耦合。我们最后讨论了这些发现对更广泛的平衡建模的意义，并强调了探索其他平衡代码和托卡马克中是否存在多重解，以及它们对依赖GS平衡的下游模拟的潜在影响的必要性。

</details>

[⬆️ 返回分类顶部](#physicsplasm-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [281] [Hierarchical Dimensionless Learning (Hi-π): A physics-data hybrid-driven approach for discovering dimensionless parameter combinations](https://arxiv.org/abs/2507.18332)
> *分层无量纲学习 (Hi-π)：一种物理数据混合驱动的无量纲参数组合发现方法*

*Mingkun Xia, Haitao Lin, Weiwei Zhang* | **Category: physics.flu-dyn, cs.LG, physics.data-an** | **Updated: 2025-07-24**

**Keywords:** 量纲分析, 符号回归, 无量纲参数, 流体力学, 分层学习

**Comment:** 

> **TL;DR:** 该论文介绍了一种名为分层无量纲学习（Hi-π）的方法，它结合了量纲分析和符号回归，以自动发现复杂物理系统中的关键无量纲参数组合。该方法在流体力学经典案例中得到了验证。

**AI_Comments:** 这项研究的创新之处在于将传统的量纲分析与现代的符号回归技术相结合，有效解决了高维物理系统中无量纲参数冗余的问题。这种混合驱动的方法不仅提高了参数发现的效率和准确性，还展示了其发现具有物理意义的分层结构表达式的潜力，对于物理规律的揭示具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量纲分析在处理高维系统时会产生冗余的无量纲参数，这使得建立具有物理意义的描述变得具有挑战性。

**Method:** 分层无量纲学习（Hi-π），一种物理数据混合驱动的方法，它结合了量纲分析和符号回归，以自动发现关键的无量纲参数组合。

**Result:** 该方法成功应用于流体力学中的经典案例：对于瑞利-贝纳对流，它准确提取了瑞利数和普朗特数；对于圆形管道中的粘性流，它自动发现了雷诺数和相对粗糙度；对于亚音速流中的可压缩性校正，它有效地提取了经典的可压缩性校正公式，并展示了发现分层结构表达式的能力。

**Conclusion:** Hi-π方法能够有效地提取物理系统中的固有无量纲参数和公式，并在多尺度数据中展现出统一的表示优势以及发现分层结构表达式的能力。

> **ai_Abstract:** 本研究提出了一种名为分层无量纲学习（Hi-π）的物理数据混合驱动方法，该方法结合了量纲分析和符号回归，旨在解决高维系统中量纲参数冗余的问题，并自动发现关键的无量纲参数组合。通过在瑞利-贝纳对流、圆形管道粘性流和亚音速流可压缩性校正等流体力学经典案例中的应用，Hi-π方法被证明能够准确提取固有无量纲参数，发现最优参数组合，并揭示分层结构表达式，从而在准确性和复杂性之间取得平衡。

> **摘要翻译:** 量纲分析提供了一个通用的框架，用于降低物理复杂性并揭示内在规律。然而，其应用于高维系统时仍然会产生冗余的无量纲参数，使得建立具有物理意义的描述变得具有挑战性。在此，我们引入了分层无量纲学习（Hi-π），这是一种物理数据混合驱动的方法，它结合了量纲分析和符号回归，以自动发现关键的无量纲参数组合。我们将此方法应用于流体力学各个研究领域的经典示例。对于瑞利-贝纳对流，该方法准确提取了两个内在的无量纲参数：瑞利数和普朗特数，验证了其在多尺度数据中统一表示的优势。对于圆形管道中的粘性流，该方法自动发现了两个最优的无量纲参数：雷诺数和相对粗糙度，实现了准确性和复杂性之间的平衡。对于亚音速流中的可压缩性校正，该方法有效地提取了经典的可压缩性校正公式，同时展示了通过最优参数变换发现分层结构表达式的能力。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [398] [On zero-order consistency residue and background pressure for the conservative SPH fluid dynamics](https://arxiv.org/abs/2507.18210)
> *关于守恒型SPH流体动力学中的零阶一致性残差和背景压力*

*Feng Wang, Xiangyu Hu* | **Category: physics.flu-dyn, cs.CE, physics.comp-ph** | **Updated: 2025-07-24**

**Keywords:** SPH, 零阶一致性, 数值阻尼, 背景压力, 残差

**Comment:** 50 pages and 27 figures and 6 tables

> **TL;DR:** 守恒型SPH中的零阶一致性问题导致流动阻尼，其根本原因是零阶梯度一致性残差，且受背景压力影响。现有校正方法有效但有限，需关注复杂几何场景。

**AI_Comments:** 本文对SPH方法中一个长期存在的挑战——零阶一致性问题进行了深入分析，并明确指出了其根本原因（零阶梯度一致性残差）以及背景压力的不利影响。研究不仅提供了理论分析，还通过多种数值实验和工程基准测试验证了其发现，增强了结果的说服力。此外，指出现有校正技术的局限性，为未来的研究方向提供了重要启示，即需要开发更鲁棒的SPH校正方案，尤其是在处理高背景压力和复杂几何流场时。

<details>
  <summary>Details</summary>

**Motivation:** 守恒型光滑粒子流体动力学（SPH）方法中的零阶一致性问题，即使通过粒子正则化方案（如输运速度公式）缓解，仍会显著抑制长通道中的层流和湍流。本研究旨在深入分析这种阻尼现象的原因，并探索其与重力驱动自由表面流中过度数值耗散的关联。

**Method:** 本文彻底分析了压驱动通道流中的阻尼原因，并将其与重力驱动自由表面流中的过度数值耗散问题联系起来，揭示了两种典型流动场景中非物理数值阻尼的共同根源——零阶梯度一致性残差。研究揭示并讨论了背景压力对两种场景中残差的不利影响。为全面理解残差行为并减轻其潜在不利影响，进行了理论分析和数值实验，重点关注关键敏感因素。针对残差引起的重力驱动自由表面流中非物理能量耗散，测试了无粘驻波情况下的水深和输入动压力。为研究压驱动通道流中的速度损失，检查了通道长度、分辨率和出口压力的影响。引入并测试了最先进的反向核梯度校正技术，并将其应用于两种典型流动，证明其在减少残差效应方面有效。最后，测试了FDA喷嘴这一工程基准，以证明残差在复杂几何形状中的影响。

**Result:** 研究发现，零阶梯度一致性残差是两种典型流动场景（压驱动通道流和重力驱动自由表面流）中非物理数值阻尼的共同根源。背景压力对残差有不利影响。最先进的反向核梯度校正技术能有效减少残差效应，但其校正能力存在根本性限制。在复杂几何形状（如FDA喷嘴）中，残差影响显著，凸显了在不可避免存在高背景压力的场景中校正方案的必要性。

**Conclusion:** 守恒型SPH方法中零阶梯度一致性残差是导致非物理阻尼的关键问题，且受背景压力的不利影响。尽管反向核梯度校正技术能有效减轻残差效应，但其能力有限，尤其在复杂几何和高背景压力场景下，仍需进一步研究和改进校正方案。

> **ai_Abstract:** 本文深入探讨了守恒型SPH方法中零阶一致性问题导致的流动阻尼现象。研究发现，无论是压驱动通道流还是重力驱动自由表面流，其非物理数值阻尼的共同根源在于零阶梯度一致性残差，并且背景压力对其有不利影响。通过理论分析和数值实验，本文考察了残差行为的关键敏感因素。尽管引入的反向核梯度校正技术能有效降低残差效应，但其校正能力存在根本性限制。研究还通过工程基准测试强调了在复杂几何和高背景压力场景下校正方案的重要性。

> **摘要翻译:** 作为守恒型光滑粒子流体动力学（SPH）方法的主要挑战之一，零阶一致性问题，尽管被认为可以通过粒子正则化方案（如输运速度公式）缓解，但仍会显著抑制长通道中的层流和湍流模拟的流动。基于这一发现，本文不仅彻底分析了这种压驱动通道流中的阻尼原因，而且将此问题与重力驱动自由表面流中过度的数值耗散联系起来。揭示了两种典型流动场景中非物理数值阻尼的共同根源——零阶梯度一致性残差。揭示并讨论了背景压力对两种场景中残差的不利影响。为了全面理解残差的行为并减轻其潜在的不利影响，我们进行了理论分析和数值实验，重点关注关键敏感因素。为了研究重力驱动自由表面流中残差引起的非物理能量耗散，测试了无粘驻波情况下的水深和输入动压力。为了研究压驱动通道流中的速度损失，我们检查了通道长度、分辨率和出口压力的影响。针对这两种典型流动引入了最先进的反向核梯度校正技术，并证明其在减少残差效应方面有效，但我们发现其校正能力受到根本限制。最后，测试了FDA喷嘴这一工程基准，以证明残差在复杂几何形状中的影响，强调了在不可避免存在高背景压力的场景中校正方案的必要性。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='physicsins-det'></a>
## physics.ins-det 

### [380] [A 55-nm SRAM Chip Scanning Errors Every 125 ns for Event-Wise Soft Error Measurement](https://arxiv.org/abs/2504.08305)
> *55纳米SRAM芯片每125纳秒扫描一次错误，用于事件级软错误测量*

*Yuibi Gomi, Akira Sato, Waleed Madany, Kenichi Okada, Satoshi Adachi, Masatoshi Itoh, Masanori Hashimoto* | **Category: physics.ins-det, cs.AR** | **Updated: 2025-07-24**

**Keywords:** SRAM芯片, 软错误测量, 事件级测量, 55纳米CMOS, 时间同步

**Comment:** 4 pages, 9 figures, accepted for publication in IEEE Solid-State
  Circuits Letters (SSCL)

> **TL;DR:** 开发了一种55纳米SRAM芯片系统，能以高精度进行事件级软错误测量，区分传统方法无法识别的错误类型。

**AI_Comments:** 创新点在于开发了高速扫描SRAM芯片和粒子探测器结合的系统，实现了事件级的软错误测量以及对传统方法无法区分的软错误类型的精确识别，这对于半导体器件的可靠性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法无法区分伪多位翻转(Pseudo-MCUs)和远距离多位翻转(Distant MCUs)等软错误误分类，需要更精确的事件级测量和识别。

**Method:** 开发了一种55纳米CMOS SRAM芯片，每125纳秒扫描所有数据并通过SPI接口输出带时间戳的软错误数据。该系统结合了开发的芯片和粒子探测器。

**Result:** 该系统实现了事件级软错误测量，能够精确识别单比特翻转(SBU)和多比特翻转(MCU)，解决了传统方法无法区分的误分类问题。在80-MeV质子辐照实验中验证了系统操作。SRAM芯片和粒子探测器之间的时间戳成功同步，并考虑了辐射引起的PLL干扰。事件构建通过确定亚纳秒分辨率的复位偏移实现，空间同步保持在几十微米以内。

**Conclusion:** 该系统成功实现了高精度的事件级软错误测量和软错误类型识别，解决了传统方法的局限性。

> **ai_Abstract:** 该论文介绍了一种55纳米CMOS SRAM芯片及其组成的系统，该系统能够每125纳秒扫描一次数据并输出带时间戳的软错误信息。结合粒子探测器，该系统实现了事件级的软错误测量，并能精确区分单比特和多比特翻转，解决了传统方法在软错误分类上的局限性。系统在质子辐照实验中得到验证，显示出成功的时间和空间同步能力。

> **摘要翻译:** 我们开发了一种55纳米CMOS SRAM芯片，该芯片每125纳秒扫描所有数据，并通过SPI接口经由FIFO输出带时间戳的软错误数据。所提出的系统，由开发的芯片和粒子探测器组成，能够实现事件级软错误测量和SBU与MCU的精确识别，从而解决了传统方法无法区分的伪多位翻转和远距离多位翻转等误分类问题。在日本东北大学RARiS进行的80-MeV质子辐照实验验证了系统操作。SRAM芯片和粒子探测器之间的时间戳成功同步，并考虑了辐射引起的PLL干扰。通过确定亚纳秒分辨率的复位偏移实现了事件构建，空间同步保持在几十微米以内。

</details>

[⬆️ 返回分类顶部](#physicsins-det) | [⬆️ 返回总目录](#toc)

---

<a id='statot'></a>
## stat.OT 

### [431] [Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification](https://arxiv.org/abs/2505.09619)
> *集成到物联网医疗平台中的机器学习解决方案，用于心力衰竭风险分层*

*Aiman Faiz, Anna Maria De Roberto, Claudio Pascarelli, Gianvito Mitrano, Gianluca Fimiani, Marina Garofano, Genoveffa Tortora, Mariangela Lazoi, Claudio Passino, Alessia Bramanti* | **Category: stat.OT, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 心力衰竭风险分层, 机器学习, 集成学习, 物联网医疗, 预测模型

**Comment:** 

> **TL;DR:** 该研究提出了一种基于机器学习的集成学习模型，用于心力衰竭风险分层，并在实际数据集中表现出高敏感度和可接受的准确性，优于基线模型，可作为医疗决策支持工具。

**AI_Comments:** 该论文的创新点在于提出了一个基于改进堆叠技术的集成学习模型，并将其应用于心力衰竭风险分层，特别强调了高敏感度以确保高风险患者的识别。其重要性在于将机器学习模型集成到物联网医疗平台中，为慢性病管理提供实用的决策支持工具。模型在识别高风险患者方面的高敏感度是其在医疗应用中的关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 慢性心力衰竭（HF）的管理面临重大挑战，需要持续监测、早期发现恶化和个性化治疗策略。

**Method:** 本文提出了一种基于机器学习技术的预测模型，采用集成学习方法，具体是改进的堆叠技术。该模型使用两个专门模型（分别利用临床和超声心动图特征），然后通过一个元模型来结合这两个模型的预测。

**Result:** 在真实数据集上评估了模型，结果表明其在心力衰竭患者风险分层方面表现良好。获得了95%的高敏感度（确保几乎所有高风险患者都被识别），以及84%的准确性。初步结果还表明，该预测模型优于不区分特征的基线模型。

**Conclusion:** 基于机器学习的风险分层模型可以作为有价值的决策支持工具，用于早期干预和个性化患者管理。

> **ai_Abstract:** 本研究提出了一种集成到物联网医疗平台中的机器学习模型，用于心力衰竭风险分层。该模型采用改进的堆叠集成学习方法，结合了利用临床和超声心动图特征的两个专门模型的预测。在真实数据集上的评估显示，该模型在识别高风险患者方面具有95%的高敏感度和84%的准确性，并且优于基线模型。研究结果表明，该ML模型可作为医疗专业人员进行早期干预和个性化患者管理的重要决策支持工具。

> **摘要翻译:** 慢性心力衰竭（HF）的管理在现代医疗保健中面临重大挑战，需要持续监测、早期发现恶化和个性化治疗策略。在本文中，我们提出了一种基于机器学习（ML）技术的预测模型，用于识别有HF风险的患者。该模型是一种集成学习方法，采用改进的堆叠技术，使用两个专门模型来利用临床和超声心动图特征，然后使用一个元模型来结合这两个模型的预测。我们最初在一个真实数据集上评估了该模型，获得的结果表明它在HR风险患者的分层方面表现良好。具体来说，我们获得了高敏感度（95%），确保几乎所有高风险患者都被识别。至于准确性，我们获得了84%，这在某些ML环境中可能被认为是中等的。然而，考虑到我们优先识别有HF风险的患者，因为他们将被要求参与PrediHealth研究项目的远程监测计划（该论文的一些作者正在参与该项目），这是可以接受的。初步发现还表明，基于ML的风险分层模型不仅可以在PrediHealth项目中，而且可以为医疗专业人员提供有价值的决策支持工具，帮助早期干预和个性化患者管理。为了更好地理解我们预测模型的价值和潜力，我们还将其结果与使用三种基线模型获得的结果进行了对比。初步结果表明，我们的预测模型优于这些简单地考虑特征（即不将它们分组为临床和超声心动图特征）的基线模型。

</details>

[⬆️ 返回分类顶部](#statot) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstr-el'></a>
## cond-mat.str-el 

### [496] [Deep Variational Free Energy Calculation of Hydrogen Hugoniot](https://arxiv.org/abs/2507.18540)
> *氢Hugoniot的深度变分自由能计算*

*Zihang Li, Hao Xie, Xinyang Dong, Lei Wang* | **Category: cond-mat.str-el, cs.LG, physics.comp-ph** | **Updated: 2025-07-24**

**Keywords:** 深度变分自由能, 氢Hugoniot, 物态方程, 暖稠密物质, 深度生成模型

**Comment:** 7+17 pages, 5+14 figures, for source code and raw data, see
  https://github.com/fermiflow/Hugoniot

> **TL;DR:** 开发了一种深度变分自由能框架，用于计算暖稠密物质区氢的物态方程，并通过与现有结果比较，旨在解决氘Hugoniot曲线上的差异。

**AI_Comments:** 该论文创新性地将深度生成模型（归一化流、Transformer、置换等变流）应用于物理学中的变分自由能计算，为暖稠密物质的物态方程研究提供了一种新的、基于AI的方法。其重要性在于能够处理复杂的多体系统，并有望解决现有理论与实验之间的不一致。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决现有氘Hugoniot曲线上理论和实验结果之间的差异，并为暖稠密物质区氘提供有价值的基准。

**Method:** 开发了一个深度变分自由能框架。该方法使用三个深度生成模型（归一化流模型、自回归Transformer和置换等变流模型）参数化有限温度下氢核和电子的变分密度矩阵。通过联合优化这三个神经网络以最小化变分自由能。

**Result:** 获得了致密氢的物态方程和相关的热力学性质。计算结果与氘Hugoniot曲线上的其他理论和实验结果进行了比较，并为暖稠密物质区氘提供了有价值的基准。

**Conclusion:** 该深度变分自由能框架成功计算了暖稠密物质区氢的物态方程和热力学性质，并为解决现有差异和提供氘的基准做出了贡献。

> **ai_Abstract:** 本文提出了一种深度变分自由能框架，用于计算暖稠密物质区氢的物态方程。该框架结合了归一化流、自回归Transformer和置换等变流三种深度生成模型，以参数化氢核和电子的变分密度矩阵。通过联合优化这些神经网络，成功获得了致密氢的物态方程和热力学性质，并与现有氘Hugoniot曲线的理论和实验结果进行了比较，旨在解决其间的差异，为该区域的氘提供了宝贵的基准。

> **摘要翻译:** 我们开发了一个深度变分自由能框架，用于计算暖稠密物质区氢的物态方程。该方法利用三个深度生成模型在有限温度下参数化氢核和电子的变分密度矩阵：一个表示经典核玻尔兹曼分布的归一化流模型，一个模拟激发态电子分布的自回归Transformer，以及一个构建Hartree-Fock轨道中电子回流坐标的置换等变流模型。通过联合优化这三个神经网络以最小化变分自由能，我们获得了致密氢的物态方程和相关的热力学性质。我们将我们的结果与关于氘Hugoniot曲线的其他理论和实验结果进行了比较，旨在解决现有差异。计算结果为暖稠密物质区氘提供了有价值的基准。

</details>

[⬆️ 返回分类顶部](#cond-matstr-el) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [547] [Comparison of Optimised Geometric Deep Learning Architectures, over Varying Toxicological Assay Data Environments](https://arxiv.org/abs/2507.17775)
> *优化几何深度学习架构在不同毒理学分析数据环境下的比较*

*Alexander D. Kalian, Lennart Otte, Jaewook Lee, Emilio Benfenati, Jean-Lou C. M. Dorne, Claire Potter, Olivia J. Osborne, Miao Guo, Christer Hogstrand* | **Category: q-bio.QM, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 几何深度学习, 图神经网络, 毒理学分析, 贝叶斯优化, 化学信息学

**Comment:** 

> **TL;DR:** 本研究比较了GCN、GAT和GIN在不同数据量毒理学分析数据集上的性能，发现GIN在数据量充足时表现更好，而GAT在数据量稀缺时更优，同时揭示了GIN的独特性。

**AI_Comments:** 本文通过系统地比较不同GNN架构在不同数据量毒理学数据集上的性能，填补了该领域研究的空白。其创新之处在于揭示了不同GNN架构在数据丰度和稀缺性方面的适用性，为实际应用提供了重要的指导。贝叶斯优化方法的使用也增强了结果的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 几何深度学习是人工智能驱动的化学信息学中的一项新兴技术，但不同图神经网络（GNN）架构在该领域的独特影响尚未得到充分探索。

**Method:** 本研究比较了图卷积网络（GCN）、图注意力网络（GAT）和图同构网络（GIN）在7个不同毒理学分析数据集上的性能，这些数据集数据量和终点各异，用于分析激活的二元分类。方法包括分子图预处理、类别平衡、5折分层以及对每个GNN和数据集进行贝叶斯优化（共21次）。

**Result:** 优化后的GNNs的曲线下面积（AUC）得分范围为0.728-0.849。GINs在数据量最充足的5个毒理学分析中始终优于GCNs和GATs。GATs在数据量最稀缺的2个分析中表现显著更优。GCNs和GATs的优化状态比GINs更接近。

**Conclusion:** GINs是数据量充足环境下的更优架构，而GATs是数据量稀缺环境下的更优架构。GINs作为GNN算法具有独特性。

> **ai_Abstract:** 本研究比较了三种图神经网络（GCN、GAT、GIN）在不同数据量的毒理学分析数据集上的性能，旨在为人工智能驱动的化学信息学选择最佳架构。研究通过贝叶斯优化对模型进行优化，并发现GIN在数据量充足的环境下表现最佳，而GAT则在数据量稀缺的环境下表现更优。此外，研究还揭示了GIN在超参数空间中的独特性。

> **摘要翻译:** 几何深度学习是人工智能驱动的化学信息学中的一项新兴技术，然而，不同图神经网络（GNN）架构在该领域的独特含义尚未得到充分探索。本研究比较了图卷积网络（GCN）、图注意力网络（GAT）和图同构网络（GIN）的性能，将其应用于7个不同数据量和终点的毒理学分析数据集，以执行分析激活的二元分类。在对分子图进行预处理、强制类别平衡并将所有数据集分层为5折后，对应用于每个分析数据集的每个GNN进行了贝叶斯优化（共21次独特的贝叶斯优化）。优化后的GNN的曲线下面积（AUC）得分范围为0.728-0.849（在所有折叠中平均），自然地在特定分析和GNN之间变化。结果发现，在7个数据量最充足的毒理学分析中，GINs始终优于GCNs和GATs。然而，GATs在剩余的2个数据量最稀缺的分析中表现显著更优。这表明GINs是数据量充足环境下的更优架构，而GATs是数据量稀缺环境下的更优架构。随后对探索的高维超参数空间以及优化后的超参数状态进行分析发现，与GINs相比，GCNs和GATs彼此之间达到了更接近的优化状态，这进一步表明了GINs作为GNN算法的独特本质。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [574] [A PBN-RL-XAI Framework for Discovering a "Hit-and-Run" Therapeutic Strategy in Melanoma](https://arxiv.org/abs/2507.10136)
> *一种用于发现黑色素瘤“一击即走”治疗策略的PBN-RL-XAI框架*

*Zhonglin Liu* | **Category: q-bio.QM, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 黑色素瘤, 免疫疗法耐药性, 概率布尔网络, 强化学习, 可解释人工智能

**Comment:** 9 pages, 5 figures. Submitted to the IEEE International Conference on
  Bioinformatics and Biomedicine (BIBM) 2025. Code is available at
  https://github.com/Liu-Zhonglin/pbn-melanoma-project

> **TL;DR:** 本研究开发了一个结合概率布尔网络（PBN）、强化学习（RL）和可解释人工智能（XAI）的框架，以发现黑色素瘤中克服抗PD-1免疫疗法耐药性的“一击即走”治疗策略，并发现短暂抑制LOXL2蛋白是有效的。

**AI_Comments:** 该论文的创新之处在于结合了概率布尔网络、强化学习和可解释人工智能来发现复杂生物系统中的非显而易见治疗策略。其“一击即走”的治疗理念，即通过短暂干预实现长期疗效，对于减少治疗副作用和提高患者依从性具有重要意义。该框架为其他复杂疾病的药物发现和干预策略优化提供了强大的计算工具。

<details>
  <summary>Details</summary>

**Motivation:** 转移性黑色素瘤对抗PD-1免疫疗法存在先天性耐药性，且其潜在的分子网络尚不明确，这是一个主要的临床挑战。

**Method:** 研究构建了一个动态概率布尔网络模型，使用患者肿瘤活检的转录组数据来阐明调控治疗反应的逻辑。随后，使用强化学习智能体系统地发现最佳的多步骤治疗干预措施，并利用可解释人工智能来机械性地解释智能体的控制策略。

**Result:** 分析显示，精确计时的四步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。可解释性分析表明，这种“一击即走”的干预足以消除驱动耐药性的分子特征，使网络能够自我纠正而无需持续干预。

**Conclusion:** 这项研究提出了一种新颖的、时间依赖的治疗假设，用于克服免疫疗法耐药性，并提供了一个强大的计算框架，用于在复杂生物系统中识别非显而易见的干预方案。

> **ai_Abstract:** 本研究提出了一个PBN-RL-XAI框架，旨在解决转移性黑色素瘤对PD-1抗体免疫疗法的先天性耐药性问题。通过构建动态概率布尔网络模型并结合强化学习和可解释人工智能，该框架成功发现了一种精确计时的四步暂时性抑制LOXL2蛋白的“一击即走”治疗策略。这种干预被证明足以消除耐药性分子特征，使网络自我纠正，为克服免疫疗法耐药性提供了一种新颖的时间依赖性治疗假设和强大的计算工具。

> **摘要翻译:** 转移性黑色素瘤对PD-1抗体免疫疗法存在先天性耐药性，这是一个主要的临床挑战，且其潜在的分子网络尚不明确。为了解决这个问题，我们利用患者肿瘤活检的转录组数据构建了一个动态概率布尔网络模型，以阐明调控治疗反应的逻辑。随后，我们采用强化学习智能体系统地发现最佳的多步骤治疗干预措施，并利用可解释人工智能来机械性地解释智能体的控制策略。分析显示，精确计时的四步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。我们的可解释性分析表明，这种“一击即走”的干预足以消除驱动耐药性的分子特征，使网络能够自我纠正而无需持续干预。这项研究提出了一种新颖的、时间依赖的治疗假设，用于克服免疫疗法耐药性，并提供了一个强大的计算框架，用于在复杂生物系统中识别非显而易见的干预方案。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [687] [CM-UNet: A Self-Supervised Learning-Based Model for Coronary Artery Segmentation in X-Ray Angiography](https://arxiv.org/abs/2507.17779)
> *CM-UNet：一种基于自监督学习的X射线血管造影冠状动脉分割模型*

*Camille Challier, Xiaowu Sun, Thabo Mahendiran, Ortal Senouf, Bernard De Bruyne, Denise Auberson, Olivier Müller, Stephane Fournier, Pascal Frossard, Emmanuel Abbé, Dorina Thanou* | **Category: q-bio.QM, cs.LG, I.2; I.4; I.5; J.3** | **Updated: 2025-07-22**

**Keywords:** 冠状动脉分割, 自监督学习, X射线血管造影, 迁移学习, CM-UNet

**Comment:** IEEE EMBC 2025, 7 pages, 6 figures

> **TL;DR:** CM-UNet利用自监督学习和迁移学习，在有限标注数据下显著提升X射线血管造影中冠状动脉分割的准确性。

**AI_Comments:** 这项研究通过引入自监督学习和迁移学习的结合，有效地解决了医学图像分割中数据标注稀缺的关键问题，具有重要的创新性。其在仅使用少量标注数据时仍能保持高分割性能的发现，对于推动临床实践中自动化诊断工具的开发具有重大意义，有望减轻放射科医生的负担并提高诊断效率。

<details>
  <summary>Details</summary>

**Motivation:** 冠状动脉的准确分割在临床实践中仍是挑战，阻碍了冠心病的诊断和管理。主要问题是缺乏大型标注数据集，限制了自动化工具的开发。

**Method:** 本文提出CM-UNet模型，该模型利用在未标注数据集上进行自监督预训练，然后在有限的标注数据上进行迁移学习，以实现准确的疾病检测，同时最大限度地减少对大量手动标注的需求。

**Result:** 使用18张标注图像而非500张对CM-UNet进行微调，Dice分数仅下降15.2%，而没有预训练的基线模型下降46.5%。这表明自监督学习可以提高分割性能并减少对大型数据集的依赖。

**Conclusion:** 自监督学习在改善X射线血管造影中的冠状动脉分割方面至关重要，有望提升临床诊断准确性，改善临床工作流程，减轻放射科医生的工作量，并加速疾病检测。

> **ai_Abstract:** 本文提出CM-UNet，一个基于自监督学习的模型，用于X射线血管造影中的冠状动脉分割。针对缺乏大型标注数据集的问题，CM-UNet在未标注数据上进行自监督预训练，并在有限标注数据上进行迁移学习。实验结果表明，在仅使用少量标注数据的情况下，CM-UNet的性能远优于无预训练的基线模型，证明了自监督学习在减少对大量标注数据依赖方面的有效性，对临床诊断和工作流程具有重要意义。

> **摘要翻译:** 冠状动脉的精确分割在临床实践中仍然是一个重大挑战，阻碍了有效诊断和管理冠状动脉疾病的能力。用于模型训练的大型标注数据集的缺乏加剧了这一问题，限制了可辅助放射科医生的自动化工具的开发。为了解决这个问题，我们引入了CM-UNet，它利用在未标注数据集上的自监督预训练和在有限标注数据上的迁移学习，从而实现准确的疾病检测，同时最大限度地减少对大量手动标注的需求。仅用18张标注图像而非500张对CM-UNet进行微调，Dice分数下降了15.2%，相比之下，没有预训练的基线模型下降了46.5%。这表明自监督学习可以提高分割性能并减少对大型数据集的依赖。这是首批强调自监督学习在改善X射线血管造影冠状动脉分割方面重要性的研究之一，对提升临床实践中的诊断准确性具有潜在影响。通过提高X射线血管造影图像的分割精度，所提出的方法旨在改善临床工作流程，减轻放射科医生的工作量，并加速疾病检测，最终有助于改善患者预后。源代码可在https://github.com/CamilleChallier/Contrastive-Masked-UNet 获取。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='q-finpm'></a>
## q-fin.PM 

### [579] [HARLF: Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization](https://arxiv.org/abs/2507.18560)
> *HARLF：分层强化学习与轻量级LLM驱动情感整合在金融投资组合优化中的应用*

*Benjamin Coriat, Eric Benhamou* | **Category: q-fin.PM, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 金融投资组合优化, 分层强化学习, 轻量级LLM, 情感分析, 深度强化学习

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的分层强化学习框架HARLF，结合轻量级LLM和DRL，利用金融新闻情感信号和市场指标进行投资组合优化，实现了26%的年化收益和1.2的夏普比率，优于基准。

**AI_Comments:** 这篇论文通过将轻量级LLM与分层强化学习结合，为金融投资组合优化提供了一个创新的解决方案，尤其是在整合非结构化情感数据方面。其三层架构设计有助于提高决策的稳定性和处理混合数据的能力。实验结果表明了其相对于传统基准的显著优势，且强调了可扩展性和可复现性，这对于实际应用和后续研究都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过整合金融新闻情感信号与传统市场指标，解决金融投资组合优化问题，并提出一种新颖的分层框架来提高优化效果。

**Method:** 提出了一种新颖的分层框架HARLF，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合。该框架采用三层架构：基础RL代理处理混合数据，元代理聚合其决策，以及一个超级代理根据市场数据和情感分析合并决策。

**Result:** 该框架在2018年至2024年的数据上（2000-2017年训练）评估，实现了26%的年化收益和1.2的夏普比率，优于等权重和标普500基准。

**Conclusion:** 该分层强化学习框架通过结合轻量级LLM和DRL，有效整合了金融新闻情感信号与市场指标，显著提升了金融投资组合优化性能，并具有可扩展的跨模态集成、增强的稳定性以及可复现性。

> **ai_Abstract:** 本文介绍了一个名为HARLF的新型分层框架，用于金融投资组合优化。该框架创新性地结合了轻量级大型语言模型（LLMs）与深度强化学习（DRL），以整合金融新闻的情感信号和传统市场指标。其三层架构包含基础RL代理、元代理和超级代理，用于逐步处理和合并决策。在2018-2024年的数据上评估显示，HARLF实现了26%的年化收益和1.2的夏普比率，显著优于现有基准，突出了其在跨模态集成、稳定性及可复现性方面的优势。

> **摘要翻译:** 本文提出了一种新颖的投资组合优化分层框架，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合，旨在将金融新闻中的情感信号与传统市场指标结合起来。我们的三层架构采用基础RL代理来处理混合数据，元代理来聚合它们的决策，以及一个超级代理根据市场数据和情感分析来合并决策。该框架在2000-2017年训练后，于2018年至2024年的数据上进行了评估，实现了26%的年化收益和1.2的夏普比率，优于等权重和标普500基准。主要贡献包括可扩展的跨模态集成、增强稳定性的分层RL结构以及开源可复现性。

</details>

[⬆️ 返回分类顶部](#q-finpm) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [580] [Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents](https://arxiv.org/abs/2507.18607)
> *可解释的映射器：使用基于扰动的解释和验证代理绘制LLM嵌入空间*

*Xinyuan Yan, Rita Sevastjanova, Sinie van der Ben, Mennatallah El-Assady, Bei Wang* | **Category: cs.CG, cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM嵌入空间, 映射图, 可解释性, 扰动解释, 语言属性

**Comment:** 

> **TL;DR:** 提出一个名为“可解释的映射器”的框架，利用基于LLM的扰动代理半自动地探索和解释大型语言模型嵌入空间的拓扑结构。

**AI_Comments:** 这项工作通过引入基于LLM的代理和扰动技术，为理解和解释LLM的高维嵌入空间提供了一种创新的半自动化方法。它解决了传统手动探索耗时耗力的问题，并通过可视化分析工作空间提供了实用的工具。其创新性在于将可解释性与LLM嵌入空间的可视化探索相结合，对于深入理解LLM内部机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLM）高维嵌入空间的拓扑结构以理解其底层语言属性需要大量人工努力，因此需要一种半自动化的方法。

**Method:** 提出一个名为“可解释的映射器”的框架，用于半自动标注LLM嵌入属性。该框架首先定义了映射图中可探索元素的分类（如节点、边、路径等）。然后，通过两种可定制的、基于LLM的代理利用扰动技术进行可扩展和自动化分析，这些代理用于探索、解释映射元素特征并验证解释的鲁棒性。该框架在一个可视化分析工作空间中实现。

**Result:** 通过案例研究验证了框架的有效性。具体来说，它复制了先前关于BERT不同层嵌入属性的研究发现，并提供了关于拓扑邻域语言属性的进一步观察。

**Conclusion:** 该框架通过半自动化的方式，利用基于LLM的扰动代理，有效地揭示和解释了大型语言模型嵌入空间的复杂语言属性，显著减少了人工探索的负担。

> **ai_Abstract:** 这篇论文介绍了一个名为“可解释的映射器”的框架，旨在解决手动探索大型语言模型（LLM）高维嵌入空间以理解其语言属性的挑战。该框架利用映射图来表示嵌入空间的拓扑结构，并通过定制化的LLM驱动代理，结合扰动技术，实现对映射图元素的半自动化探索、解释和验证。论文通过案例研究，包括复制BERT嵌入属性的发现，证明了其在可视化分析工作空间中的有效性。

> **摘要翻译:** 大型语言模型（LLM）产生高维嵌入，捕获词语、句子和概念之间丰富的语义和句法关系。通过映射图（mapper graphs）研究LLM嵌入空间的拓扑结构，使我们能够理解其底层结构。具体而言，映射图总结了嵌入空间的拓扑结构，其中每个节点代表一个拓扑邻域（包含一组嵌入），如果两个节点的相应邻域重叠，则它们之间连接一条边。然而，手动探索这些嵌入空间以揭示编码的语言属性需要大量的人力。为了解决这一挑战，我们引入了一个用于半自动标注这些嵌入属性的框架。为了组织探索过程，我们首先定义了映射图中可探索元素的分类，例如节点、边、路径、组件和轨迹。这些元素的标注通过两种可定制的、基于LLM的代理执行，这些代理采用扰动技术进行可扩展和自动化分析。这些代理有助于探索和解释映射元素（mapper elements）的特征，并验证所生成解释的鲁棒性。我们在一个可视化分析工作空间中实例化了该框架，并通过案例研究展示了其有效性。特别是，我们复制了先前关于BERT在不同架构层中嵌入属性的研究发现，并对拓扑邻域的语言属性提供了进一步的观察。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='mathlo'></a>
## math.LO 

### [595] [Axiomatizing Rumsfeld Ignorance](https://arxiv.org/abs/2507.17776)
> *鲁姆斯菲尔德无知公理化*

*Jie Fan* | **Category: math.LO, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 鲁姆斯菲尔德无知, 公理化, 可达关系, 逻辑性质, 可定义性

**Comment:** This is an almost-final version

> **TL;DR:** 针对鲁姆斯菲尔德无知与无知之间的可定义性问题，通过假设不同的可达关系来避免，并给出了新的公理化。

**AI_Comments:** 这篇论文通过修改关键的假设（可达关系），巧妙地解决了现有理论中鲁姆斯菲尔德无知概念的“平凡化”问题，从而使得其公理化研究变得有意义。这种对基本概念的重新审视和形式化是逻辑学研究中常见且重要的方法。

<details>
  <summary>Details</summary>

**Motivation:** Kit Fine 的研究中，鲁姆斯菲尔德无知可由无知定义，这使得现有结果和公理化问题变得微不足道，原因是两者隐式知识算子的可达关系相同。

**Method:** 假设鲁姆斯菲尔德无知和无知所包含的隐式知识算子的两个可达关系是不同的，其中一个可达关系是另一个的任意子集。这将避免可定义性问题并保留大部分先前的有效性。

**Result:** 主要结果是在各种适当的双框架类上的公理化。

**Conclusion:** 通过假设不同的可达关系，成功避免了鲁姆斯菲尔德无知与无知之间的可定义性问题，并保留了先前的有效性，最终对Kit Fine的结果进行了分析。

> **ai_Abstract:** 本文旨在解决 Kit Fine 提出的鲁姆斯菲尔德无知与无知之间的可定义性问题，该问题源于两者隐式知识算子具有相同的可达关系。为解决此问题，作者假设这两个可达关系不同，其中一个为另一个的任意子集，从而成功避免了可定义性问题并保留了先前的大部分有效性。主要贡献是给出了在各种适当双框架类上的公理化，并应用该框架分析了 Fine 的原始结果。

> **摘要翻译:** 在最近的一篇论文中，Kit Fine 提出了关于（一阶）无知、二阶无知和鲁姆斯菲尔德无知的逻辑性质的一些引人注目的结果。然而，鲁姆斯菲尔德无知可以用无知来定义，这使得一些现有结果和公理化问题变得微不足道。一个主要原因是，无知和鲁姆斯菲尔德无知这些打包算子中包含的隐式知识算子的可达关系是相同的。在这项工作中，我们假设这两个可达关系是不同的，其中一个可达关系是另一个的任意子集。这将避免可定义性问题并保留大部分先前的有效性。主要结果是在各种适当的双框架类上的公理化。最后，我们将我们的框架应用于分析 Fine 的结果。

</details>

[⬆️ 返回分类顶部](#mathlo) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [630] [A Simulated Reconstruction and Reidentification Attack on the 2010 U.S. Census: Full Technical Report](https://arxiv.org/abs/2312.11283)
> *2010年美国人口普查的模拟重建和再识别攻击：完整技术报告*

*John M. Abowd, Tamara Adams, Robert Ashmead, David Darais, Sourya Dey, Simson L. Garfinkel, Nathan Goldschlag, Daniel Kifer, Philip Leclerc, Ethan Lew, Scott Moore, Rolando A. Rodríguez, Ramy N. Tadros, Lars Vilhuber* | **Category: stat.AP, cs.CR, econ.EM** | **Updated: 2025-07-23**

**Keywords:** 人口普查, 隐私, 重建攻击, 再识别, 披露限制

**Comment:** Replaces "The 2010 Census Confidentiality Protections Failed, Here's
  How and Why'' with the published version, which has a new title. Harvard Data
  Science Review (2025)

> **TL;DR:** 2010年美国人口普查的表格数据，尽管被认为隐私性更高，但实际上极易受到重建和再识别攻击，证明其与微观数据一样具有泄露风险。2020年人口普查的框架更为安全，而其他替代方案则不可行。

**AI_Comments:** 这篇论文具有极其重要的意义，因为它挑战了统计披露控制领域长期以来的一个假设，揭示了2010年美国人口普查中存在的重大隐私缺陷。其创新之处在于，它通过实际操作证明了对高度聚合的公共数据进行重建和再识别攻击的可行性。研究结果强调了在官方统计中加强隐私保护机制的必要性，并直接影响了2020年人口普查披露规避系统的设计。此外，它还对隐私和数据实用性之间的权衡进行了有价值的分析。

<details>
  <summary>Details</summary>

**Motivation:** 统计机构通常假设表格数据比微观数据具有更低的披露风险。然而，本研究旨在挑战这一假设，特别是针对2010年美国人口普查中发布的包含大量详细地理级别统计数据的表格数据，揭示其潜在的隐私泄露风险。

**Method:** 研究人员仅使用2010年美国人口普查发布的180个表格集中的34个，重建了五个人口变量（普查区、性别、年龄、种族和民族）的微观数据。随后，他们进行了再识别研究以验证攻击的有效性。此外，研究还评估了2020年美国人口普查所采用的更稳健的披露限制框架对重建攻击的防御能力，并分析了其他替代方案的有效性。

**Result:** 研究表明，在70%的普查区（涉及9700万人）中，所有记录都可以被完美重建。在这些完美重建的普查区内，攻击者能够以95%的准确率推断出340万弱势人群（普查区内种族和民族与多数人不同的独特个体）的真实普查回答。研究还发现，2020年美国人口普查采用的披露限制框架能够有效防御基于重建的攻击。然而，与2020年人口普查披露规避系统可用的替代方案要么无法保护机密性，要么会过度降低统计数据的实用性，无法满足其主要法定用途，即根据1965年《投票权法案》重新划分全国所有立法和投票区边界。

**Conclusion:** 本研究表明，2010年美国人口普查中表格数据固有地比其底层微观数据泄露风险更低的假设是错误的。2020年人口普查的披露限制框架在防御重建攻击方面更为稳健，并且现有替代方案在保护机密性或保持数据实用性方面存在不足。

> **ai_Abstract:** 本论文揭示了2010年美国人口普查表格数据中存在的严重隐私漏洞。与普遍假设相反，作者证明了利用公开的聚合统计数据，可以完美重建并再识别大量个人记录。研究显示，70%的普查区记录（9700万人）可以被完美重建，并且数百万人的敏感属性可以被准确推断。论文还评估了2020年人口普查披露限制框架对此类攻击的防御能力，发现其更为有效，并讨论了在保护机密性与保持数据实用性（例如用于重新划分选区）之间权衡时，其他替代方法的不足。

> **摘要翻译:** 统计机构通常使用不同策略来保护表格数据的机密性，这与保护公开微观数据中的个人记录的策略不同。聚合被认为使得生成的统计数据固有地比微观数据更不易泄露。2010年美国人口普查对其表格和微观数据发布使用了不同的披露限制规则。我们表明，这些表格数据固有地比其底层微观数据不易泄露的假设是错误的。2010年人口普查发布了超过1500亿条统计数据，分为180个表格集，几乎所有都处于最详细的地理级别——个体普查区。仅使用已发布的34个表格集，我们重建了五个变量（普查区、性别、年龄、种族和民族）的微观数据。仅使用已发布的数据，攻击者使用我们的方法可以验证70%的所有普查区（9700万人）中的所有记录都已完美重建。我们通过再识别研究证实，在完美重建准确性的普查区内，攻击者可以以95%的准确率正确推断出340万弱势人群（普查区内种族和民族与多数人不同的独特个体）的真实普查回答。接下来，我们表明2020年美国人口普查使用的更稳健的披露限制框架能够防御基于重建的攻击。最后，我们表明2020年人口普查披露规避系统可用的替代方案要么无法保护机密性，要么会过度降低统计数据的实用性，无法满足其主要法定用途：根据1965年《投票权法案》重新划分全国所有立法和投票区边界。这是完整的技术报告。摘要论文请参见https://doi.org/10.1162/99608f92.4a1ebf70。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [707] [Active Learning For Repairable Hardware Systems With Partial Coverage](https://arxiv.org/abs/2503.16315)
> *可修复硬件系统部分覆盖下的主动学习*

*Michael Potter, Beyza Kalkanlı, Deniz Erdoğmuş, Michael Everett* | **Category: stat.AP, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 主动学习, 可修复硬件系统, 诊断覆盖率, 可靠性, 获取函数

**Comment:** Submitted to IEEE Access - Reliability Society

> **TL;DR:** 本文提出了一种基于松弛混合整数半定规划的主动学习获取函数（AF），用于可修复硬件系统的可靠性模型参数推断，该函数在部分测试场景下，通过实验证明其性能优于现有方法。

**AI_Comments:** 该论文的创新点在于将主动学习应用于可修复硬件系统的可靠性模型参数推断，并设计了专门的获取函数来处理硬件老化和部分测试的实际约束。通过结合MISDP、DC和FIMs，该方法在理论上具有坚实基础，并通过大规模模拟实验验证了其有效性，解决了该领域的一个重要空白。其潜在影响是优化诊断测试策略，降低维护成本。

<details>
  <summary>Details</summary>

**Motivation:** 在固定预算和最少维护周期限制下，利用现场数据推断可靠性特征的最佳诊断测试和硬件系统实例具有挑战性。尽管主动学习（AL）在机器学习/深度学习任务中表现出潜力，但其在可修复硬件系统可靠性模型参数推断方面的应用尚未得到充分探索。这需要专门的AL获取函数来考虑硬件老化和部分测试情况。

**Method:** 本文提出了一种松弛混合整数半定规划（MISDP）AL获取函数，该函数结合了诊断覆盖率（DC）、费雪信息矩阵（FIMs）和诊断测试预算。此外，设计了侧重于两种诊断测试场景的经验模拟实验：1) 具有重叠子系统覆盖的硬件系统部分测试；2) 一个诊断测试完全包含另一个子系统覆盖的部分测试。该方法与文献中最广泛使用的熵AF以及其他直观的AL AFs进行了评估。

**Result:** 在6,000种实验配置中，本文提出的AF在绝对总预期事件误差（ATEER）和均方误差（MSE）曲线的曲线下面积（AUC）方面，平均表现优于其他替代AFs，并通过0.05显著性水平的Friedman假设检验进行了统计学显著性验证。

**Conclusion:** 本文提出的基于松弛混合整数半定规划的主动学习获取函数，在可修复硬件系统部分覆盖下的可靠性模型参数推断中表现出卓越的性能，显著优于现有方法。

> **ai_Abstract:** 本文针对可修复硬件系统在预算和维护周期限制下进行可靠性特征推断的挑战，提出了一种新颖的基于松弛混合整数半定规划（MISDP）的主动学习获取函数（AF）。该AF创新性地整合了诊断覆盖率、费雪信息矩阵和测试预算，以应对硬件老化及部分测试的复杂性。通过模拟实验验证，在两种部分测试场景下，该方法在参数推断准确性方面显著优于现有主流主动学习方法，为可修复硬件系统的可靠性评估提供了有效工具。

> **摘要翻译:** 识别最佳诊断测试和硬件系统实例以利用现场数据推断可靠性特征具有挑战性，尤其是在固定预算和最少维护周期限制下。主动学习（AL）在有限数据和预算约束下的参数推断方面已在机器学习/深度学习任务中展现出潜力。然而，对于可修复硬件系统，用于可靠性模型参数推断的AL仍未得到充分探索。它需要专门的AL获取函数（AFs），以考虑硬件老化以及硬件系统由多个子系统组成，并且在给定诊断测试中可能只进行部分测试的事实。为应对这些挑战，我们提出了一种松弛混合整数半定规划（MISDP）AL AF，该函数结合了诊断覆盖率（DC）、费雪信息矩阵（FIMs）和诊断测试预算。此外，我们设计了经验性模拟实验，重点关注两种诊断测试场景：(1) 具有重叠子系统覆盖的硬件系统部分测试；(2) 一个诊断测试完全包含另一个子系统覆盖的部分测试。我们评估了我们提出的方法与文献中最广泛使用的AL AF（熵），以及一些为可靠性模型参数推断量身定制的直观AL AFs。在6,000种实验配置中，我们的AF在绝对总预期事件误差（ATEER）和均方误差（MSE）曲线的曲线下面积（AUC）方面，平均表现最佳，并通过0.05显著性水平的Friedman假设检验计算出统计学显著性。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [721] [Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation](https://arxiv.org/abs/2506.22607)
> *通过神经后验估计从总和生育率中学习个体生殖行为*

*Daniel Ciganda, Ignacio Campón, Iñaki Permanyer, Jakob H Macke* | **Category: stat.AP, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 生育率, 个体行为, 神经后验估计, 微观模拟, 人口预测

**Comment:** 

> **TL;DR:** 该研究引入了一种新的贝叶斯框架，利用神经后验估计从聚合的生育率数据中推断个体的生殖行为，并成功预测了个体层面的结果。

**AI_Comments:** 这项研究的创新之处在于其能够从聚合数据中推断出个体层面的复杂行为机制，这在人口学研究中是一个重大挑战。通过结合模拟模型和神经后验估计，它为理解和预测人口趋势提供了强大的新工具，并有望显著降低微观模拟模型对大量个体数据的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 年龄别生育率（ASFRs）作为生殖变化的广泛记录，其聚合性掩盖了驱动生育趋势的个体层面行为机制。本研究旨在弥合这种微观与宏观之间的鸿沟。

**Method:** 本研究引入了一个无似然贝叶斯框架，该框架将一个人口学上可解释的个体层面生殖过程模拟模型与序贯神经后验估计（SNPE）相结合。

**Result:** 该框架成功地仅使用年龄别生育率（ASFRs）恢复了控制当代生育的核心行为参数，包括家庭规模偏好、生殖时机和避孕失败。该框架的有效性在四个生育制度不同的国家队列中得到了验证。最令人信服的是，该模型仅根据聚合数据进行估计，成功预测了样本外个体层面的结果分布，包括首次性行为年龄、期望家庭规模和生育间隔。

**Conclusion:** 本框架能够生成完整的合成生命史，显著降低了构建微观模拟模型的数据需求，并实现了行为明确的人口预测。

> **ai_Abstract:** 本研究提出了一种创新的无似然贝叶斯框架，结合个体生殖模拟模型和序贯神经后验估计（SNPE），旨在从聚合的年龄别生育率（ASFRs）数据中推断个体层面的生殖行为。该框架被证明能够成功恢复关键行为参数，并在多个国家验证其有效性。此外，它还能从聚合数据预测样本外的个体行为结果，从而减少微观模拟模型的数据需求，并支持行为明确的人口预测。

> **摘要翻译:** 年龄别生育率（ASFRs）提供了生殖变化最广泛的记录，但其聚合性掩盖了驱动生育趋势的个体层面行为机制。为了弥合这种微观与宏观之间的鸿沟，我们引入了一个无似然贝叶斯框架，该框架将一个人群学上可解释的个体层面生殖过程模拟模型与序贯神经后验估计（SNPE）相结合。我们证明，该框架仅使用ASFRs就成功恢复了控制当代生育的核心行为参数，包括家庭规模偏好、生殖时机和避孕失败。该框架的有效性在四个生育制度不同的国家队列中得到了验证。最令人信服的是，该模型仅根据聚合数据进行估计，成功预测了样本外个体层面的结果分布，包括首次性行为年龄、期望家庭规模和生育间隔。因为我们的框架产生了完整的合成生命史，它显著降低了构建微观模拟模型的数据需求，并实现了行为明确的人口预测。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [636] [An advanced AI driven database system](https://arxiv.org/abs/2507.17778)
> *一个先进的AI驱动的数据库系统*

*M. Tedeschi, S. Rizwan, C. Shringi, V. Devram Chandgir, S. Belich* | **Category: cs.DB, cs.AI, cs.SE, 68P20, H.2.4; I.2.7** | **Updated: 2025-07-22**

**Keywords:** AI数据库, 自然语言处理, 大型语言模型, 自动化, 数据库管理

**Comment:** 10 pages, 5 figures, appears in EDULEARN25 Conference Proceedings

> **TL;DR:** 本文提出一个由AI支持的新型数据库系统，通过自然语言处理和大型语言模型，旨在简化数据库操作，自动化任务，减少对技术技能的需求和人为错误。

**AI_Comments:** 这篇论文提出了一种创新方法，通过深度整合AI技术（特别是NLP和LLMs）来彻底改革传统数据库系统的交互和管理方式。其创新点在于将自然语言处理能力直接融入数据库接口，并利用生成式AI进行模式推理和自动化任务，这有望显著降低非技术用户的门槛，并提高效率。其重要性在于，它可能代表了数据库技术发展的一个重要方向，即从以技术人员为中心转向以用户为中心。然而，具体的实现细节、性能基准以及在复杂企业级环境中的可伸缩性和安全性将是其面临的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 当代数据库系统在复杂性和可用性方面存在严重问题，尤其是在缺乏技术专业知识且不熟悉SQL等查询语言的用户中。

**Method:** 本文提出了一个由人工智能（AI）支持的新型数据库系统，该系统利用基于自然语言处理（NLP）的直观界面，自动创建结构化查询和半结构化数据格式（如YAML、JSON、API文档）。它通过集成大型语言模型（LLMs）和先进机器学习算法来增强数据库的潜力，并采用生成式模式推理和格式选择来构建其模式模型和执行格式。

**Result:** 该系统旨在改善数据管理，自动化数据建模、模式创建、查询理解和性能优化等基本任务。它旨在减轻当前数据库技术的主要问题，减少对技术技能、手动调优的需求以及人为错误的潜在可能性。

**Conclusion:** 该AI驱动的数据库系统旨在通过集成先进的AI技术来解决现有数据库系统的复杂性和可用性问题，从而简化数据库操作，提高效率和准确性。

> **ai_Abstract:** 本文介绍了一个先进的AI驱动数据库系统，旨在解决现有数据库在复杂性和可用性方面的问题。该系统利用自然语言处理、大型语言模型和机器学习算法，提供直观的接口，并自动化数据建模、查询生成和性能优化等核心任务。其目标是降低数据库操作的技术门槛，减少手动干预和人为错误，从而提高数据管理的效率和准确性。

> **摘要翻译:** 当代数据库系统虽然有效，但在复杂性和可用性方面存在严重问题，尤其是在缺乏技术专业知识但又不熟悉结构化查询语言（SQL）等查询语言的个人中。本文提出了一种由人工智能（AI）支持的新型数据库系统，旨在通过基于自然语言处理（NLP）的直观界面以及自动创建结构化查询和半结构化数据格式（如YAML、JSON和API文档）来改进数据管理。该系统旨在通过集成大型语言模型（LLM）和先进的机器学习算法来增强数据库的潜力。这种集成旨在实现数据建模、模式创建、查询理解和性能优化等基本任务的自动化。我们在本文中提出的系统旨在缓解当前数据库技术的主要问题。它旨在减少对技术技能的需求、为提高性能而进行的手动调优以及人为错误的潜在可能性。该AI数据库采用生成式模式推理和格式选择来构建其模式模型和执行格式。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [659] [Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift](https://arxiv.org/abs/2302.10160)
> *协变量偏移下核岭回归的伪标签方法*

*Kaizheng Wang* | **Category: stat.ME, cs.LG, math.ST, stat.ML, stat.TH, 62J07, 62G05** | **Updated: 2025-07-24**

**Keywords:** 伪标签, 核岭回归, 协变量偏移, 模型选择, 均方误差

**Comment:** 45 pages, 2 figures

> **TL;DR:** 本文提出并分析了一种在协变量偏移下进行核岭回归的伪标签方法，通过将带标签数据分为两部分，并利用伪标签进行模型选择，实现了接近最优的误差率。

**AI_Comments:** 该论文的创新点在于提出了一种在协变量偏移下利用伪标签进行核岭回归的系统方法。通过将带标签数据智能地划分为两部分，并利用插补模型生成伪标签进行模型选择，有效解决了数据分布不匹配的问题。其非渐近超额风险界限的理论分析，以及对有效样本量的量化，提供了坚实的理论支撑。研究结果表明，伪标签在模型选择中的应用是有效的，并且不会显著损害性能，这对于处理现实世界中数据分布不一致的问题具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在协变量偏移的情况下，目标是基于目标分布的无标签数据和特征分布可能不同的带标签数据，学习一个在目标分布上具有小均方误差的回归函数。

**Method:** 将带标签数据分成两个子集，分别进行核岭回归以获得候选模型集合和插补模型。利用插补模型填充缺失标签，然后选择最佳候选模型。

**Result:** 非渐近超额风险界限表明，该估计器能有效适应目标分布结构和协变量偏移。这种适应性通过反映带标签源数据对目标回归任务价值的有效样本量概念进行量化。该估计器达到了在多对数因子下的最小最大最优误差率，并且使用伪标签进行模型选择不会显著影响性能。

**Conclusion:** 在协变量偏移下，本文提出的伪标签核岭回归方法能够有效适应目标分布和协变量偏移，并实现了接近最优的性能，表明伪标签在模型选择中的应用是有效的且不影响性能。

> **ai_Abstract:** 本文提出了一种在协变量偏移下进行核岭回归的伪标签方法。该方法将带标签数据分为两部分，分别进行核岭回归以获得候选模型和插补模型。通过插补模型填充缺失标签后，选择最佳候选模型。研究表明，该估计器能有效适应目标分布和协变量偏移，并达到了接近最优的误差率，且伪标签的使用不显著影响性能。

> **摘要翻译:** 我们开发并分析了一种在协变量偏移下进行核岭回归的原则性方法。目标是基于目标分布的无标签数据和特征分布可能不同的带标签数据，学习一个在目标分布上具有小均方误差的回归函数。我们建议将带标签数据分成两个子集，并分别对它们进行核岭回归，以获得一组候选模型和一个插补模型。我们使用后者来填充缺失的标签，然后相应地选择最佳候选。我们的非渐近超额风险界限表明，我们的估计器能有效适应目标分布的结构和协变量偏移。这种适应性通过反映带标签源数据对目标回归任务价值的有效样本量概念进行量化。我们的估计器达到了在多对数因子下的最小最大最优误差率，并且我们发现使用伪标签进行模型选择不会显著影响性能。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [671] [Variational inference for pile-up removal at hadron colliders with diffusion models](https://arxiv.org/abs/2410.22074)
> *强子对撞机中基于扩散模型的堆叠去除变分推断*

*Malte Algren, Tobias Golling, Christopher Pollard, John Andrew Raine* | **Category: hep-ph, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 堆叠去除, 变分推断, 扩散模型, 强子对撞机, 粒子物理

**Comment:** 19 pages, 13 figures

> **TL;DR:** 本文提出了一种名为vipr的新型方法，利用扩散模型进行变分推断，以去除强子对撞机pp相互作用中的堆叠效应，并在性能上优于或媲美现有方法。

**AI_Comments:** 该论文的创新点在于首次将变分推断与扩散模型结合应用于强子对撞机中的堆叠去除问题，并能够估计硬散射喷注成分的完整后验分布，这在现有方法中尚未探索。此方法在存在不完美探测器效率时显示出明显优势，对于提高高能物理实验数据分析的精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 去除强子对撞机中pp相互作用的堆叠效应，现有方法可能存在局限性，特别是在探测器效率不完美的情况下。

**Method:** 提出了一种名为vipr的新型方法，利用扩散模型进行变分推断。该方法训练一个生成模型来预测去除堆叠后的硬散射粒子喷注成分，而不是使用分类方法。这能够估计硬散射喷注成分的完整后验，这是以前未探索过的。

**Result:** vipr在模拟的t$\bar{t}$事件中对喷注样本进行评估，并优于softdrop，与puppiml在预测硬散射喷注的子结构方面性能相当，适用于各种堆叠场景。

**Conclusion:** vipr方法在堆叠去除方面表现出优越性或可比性，尤其是在存在不完美探测器效率的情况下，通过估计完整的后验分布，提供了优于现有方法的优势。

> **ai_Abstract:** 本文提出了一种名为vipr的新型堆叠去除方法，该方法在强子对撞机中结合了变分推断和扩散模型。与传统的分类方法不同，vipr训练一个生成模型来预测去除堆叠后的硬散射粒子喷注成分，从而估计完整的后验分布。该方法在模拟的t$\bar{t}$事件中进行了性能评估，结果显示vipr在预测硬散射喷注子结构方面优于softdrop，并与puppiml表现出相当的性能，尤其在不完美探测器效率下具有明显优势。

> **摘要翻译:** 在本文中，我们提出了一种利用扩散模型进行变分推断的新型pp相互作用堆叠去除方法，称为vipr。该方法不使用分类方法来识别哪些粒子来自初级碰撞，而是训练一个生成模型来预测去除堆叠后的硬散射粒子喷注成分。这产生了对硬散射喷注成分的完整后验估计，这在堆叠去除的背景下尚未被探索，从而在现有方法，特别是在探测器效率不完美的情况下，具有明显的优势。我们在模拟的t$\bar{t}$事件中，叠加堆叠污染的喷注样本中评估了vipr的性能。vipr在预测硬散射喷注的子结构方面优于softdrop，并在各种堆叠场景下与puppiml表现出相当的性能。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='hep-th'></a>
## hep-th 

### [676] [Analytic Regression of Feynman Integrals from High-Precision Numerical Sampling](https://arxiv.org/abs/2507.17815)
> *从高精度数值采样中对费曼积分进行解析回归*

*Oscar Barrera, Aurélien Dersy, Rabia Husain, Matthew D. Schwartz, Xiaoyuan Zhang* | **Category: hep-th, cs.NA, hep-ph, math.NA** | **Updated: 2025-07-23**

**Keywords:** 费曼积分, 解析回归, 高精度数值采样, 格点归约, 函数空间

**Comment:** 

> **TL;DR:** 通过结合高精度数值采样和函数空间知识，本研究提出了一种从数值数据中精确推导出费曼积分解析形式的方法。

**AI_Comments:** 本文提出了一种创新且重要的自下而上的方法，用于从高精度数值数据中推导精确的解析表达式。其核心创新在于巧妙地结合了高精度数值采样、函数空间知识和格点归约，这对于理论物理和数学中追求精确解析解的问题具有重大价值。该方法不仅填补了传统数值方法在获取精确解析形式上的空白，还与现有的自上而下方法形成了有益的互补，极大地扩展了解决复杂问题的工具箱。

<details>
  <summary>Details</summary>

**Motivation:** 在数学和理论物理中，经常需要获取数据的精确解析描述，但传统的数值方法通常只能提供近似解，无法得到精确的解析形式。

**Method:** 结合高精度数值积分与对函数空间的解析知识，通过在足够数量和精度的点上采样数据，并利用格点归约（lattice reduction）来推导出精确的解析答案。

**Result:** 成功展示了该方法在计算费曼积分中的应用，能够推导出精确的解析形式。文中给出了多个例子，并探讨了数据点数量、函数谓词数量、数据精度和计算量之间的权衡。

**Conclusion:** 该方法提供了一种自下而上的途径，与自上而下的Landau-bootstrap方法形成互补，且所提出的技术具有普遍性，可应用于其他需要精确答案且函数空间已知的问题。

> **ai_Abstract:** 本文提出了一种创新方法，通过结合高精度数值采样和对函数空间的解析知识，利用格点归约技术，从数值数据中精确推导出费曼积分的解析形式。该方法克服了传统数值方法仅能提供近似解的局限性，提供了一种自下而上的解决方案，与现有的自上而下方法形成互补。研究通过费曼积分的实例验证了其有效性，并分析了相关参数的权衡，表明该技术具有广泛的适用性，可用于解决需要精确答案且函数空间已知的各类问题。

> **摘要翻译:** 在数学或理论物理中，人们通常对可以原则上以任意精度生成的数据的精确解析描述感兴趣。例如，人们可能想知道一个定积分的精确解析形式。这类问题不适合数值符号回归，因为典型的数值方法只能得到近似值。然而，如果对解析结果应位于的函数空间有所了解，则可以通过在足够数量的点上以足够的精度审慎地采样数据来推导出精确答案。我们展示了如何将此应用于费曼积分的计算。我们表明，通过将高精度数值积分与函数空间的解析知识相结合，通常可以使用格点归约推导出精确答案。文中给出了一些例子，并探讨了数据点数量、函数谓词数量、数据精度和计算量之间的权衡。这种方法提供了一种自下而上的方法，巧妙地补充了仅利用解析结构来约束精确答案的自上而下的Landau-bootstrap方法。尽管我们主要关注费曼积分的应用，但这里提出的技术更具普遍性，可以应用于需要精确答案且函数空间已知的大范围问题。

</details>

[⬆️ 返回分类顶部](#hep-th) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [679] [In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator](https://arxiv.org/abs/2507.17780)
> *共同沉思：与机器协作者十年来的数学发现*

*Randy Davila, Boris Brimkov, Ryan Pepper* | **Category: cs.DM, cs.AI, math.CO** | **Updated: 2025-07-23**

**Keywords:** 图论, 自动化猜想, 人机协作, TxGraffiti, 数学发现

**Comment:** 

> **TL;DR:** 论文介绍了由自动化猜想系统TxGraffiti生成的四个图论开放猜想，它们经过验证但仍未解决，旨在展示机器在数学创造性过程中的作用并激发社区参与。

**AI_Comments:** 这篇论文的创新之处在于其展示了AI系统在生成开放性数学猜想方面的能力，突出了机器在数学发现中作为“协作者”的潜力，而不仅仅是工具。它提出了一个引人深思的问题：机器如何参与并促进人类的创造性思维过程，这对于未来人机协作模式具有重要启示。其局限性可能在于，虽然生成了猜想，但证明过程仍需人类智慧。

<details>
  <summary>Details</summary>

**Motivation:** 旨在展示机器在数学发现和创造性过程中的潜力，并通过提出未解决的猜想来激发人类数学家和AI系统参与解决，并反思机器在数学思维中参与的意义。

**Method:** 使用自动化猜想系统TxGraffiti生成图论猜想，这些猜想基于符号模式识别和数学家定义的启发式方法，并通过人类对话进行完善，再通过数百个图进行经验验证。

**Result:** 提出了四个由TxGraffiti系统生成的图论开放猜想。这些猜想简洁、基于图不变量，并通过经验验证，但至今仍未被证明或找到反例。

**Conclusion:** 机器可以作为有意义的协作者参与数学发现的创造性过程，生成的猜想不仅是数学挑战，也促使人们反思人机协作在科学探索中的作用和潜力。

> **ai_Abstract:** 这篇论文介绍了由自动化猜想系统TxGraffiti生成的四个图论开放猜想。这些猜想经过经验验证但尚未解决，它们不仅是数学难题，也体现了机器在数学发现中的创造性贡献。论文旨在通过这些猜想，激发数学界对人机协作在科学探索中作用的思考与参与。

> **摘要翻译:** 共同沉思：与机器协作者十年来的数学发现

我们介绍了由自动化猜想系统TxGraffiti生成的四个图论开放猜想。每个猜想都简洁明了，基于自然的图不变量，并在数百个图上得到了经验验证。尽管付出了大量努力，这些陈述仍然悬而未决——既无法证明也找不到反例。它们不仅是数学挑战，也是创造性的表达——它们诞生于符号模式识别和数学家定义的启发式方法，通过多年的人类对话得以完善，现在作为协作成果回馈给社区。这些猜想不仅邀请形式化的证明，也促使人们反思机器如何能唤起奇迹、激发好奇心，并为发现提供原始材料。通过突出这些问题，我们旨在激励人类数学家和AI系统参与其中——不仅是为了解决它们，更是为了反思当机器有意义地参与数学思维的创造性过程时意味着什么。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='gr-qc'></a>
## gr-qc 

### [682] [OGRePy: An Object-Oriented General Relativity Package for Python](https://arxiv.org/abs/2409.03803)
> *OGRePy：一个面向对象的Python广义相对论软件包*

*Barak Shoshany* | **Category: gr-qc, cs.MS, cs.SC, math.DG, G.4; I.1; J.2** | **Updated: 2025-07-23**

**Keywords:** 广义相对论, Python, 符号计算, 张量, 面向对象

**Comment:** 5 pages, version published in JORS, full documentation and source
  code available at https://github.com/bshoshany/OGRePy

> **TL;DR:** OGRePy是一个基于Python的面向对象开源软件包，用于广义相对论中的符号张量计算，旨在改进现有工具并促进研究和教学。

**AI_Comments:** OGRePy的创新之处在于它将广义相对论中的复杂张量计算与Python的面向对象特性相结合，提供了比现有Mathematica软件包OGRe更现代、更易用的替代方案。其开源性质和对SymPy、Jupyter的集成使其在学术界具有很高的实用价值和教学潜力。该项目的重要性在于它降低了广义相对论计算的门槛，使得更多研究人员和学生能够利用Python进行高级物理和数学研究。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是创建一个现代、开源的Python软件包，用于广义相对论中的符号张量计算，以改进流行的Mathematica软件包OGRe的功能，并通过利用Python原生的面向对象语法来提供更好的用户体验和功能。

**Method:** OGRePy采用面向对象架构，将张量、度量和坐标系封装为独立对象。它自动处理指标的升降、坐标变换、收缩、偏导数或协变导数以及所有张量操作。它利用SymPy和Jupyter Notebook的功能。

**Result:** OGRePy提供了一个健壮、用户友好的环境，有助于广义相对论和微分几何领域的研究和教学。它复制了流行的Mathematica软件包OGRe的功能，并通过利用Python的面向对象语法大大改进了它。

**Conclusion:** OGRePy的设计和实现使其在数学和物理领域的研究和教育中具有巨大的重用潜力。

> **ai_Abstract:** OGRePy是一个现代的开源Python软件包，专为广义相对论中的符号张量计算而设计。它采用面向对象架构，将张量和相关概念封装为对象，并自动化处理各种张量操作。该软件包利用SymPy和Jupyter Notebook，提供了一个用户友好且功能强大的环境，旨在促进广义相对论和微分几何的研究与教学，并改进了现有Mathematica软件包OGRe的功能。

> **摘要翻译:** OGRePy是一个现代的开源Python软件包，旨在执行符号张量计算，特别专注于广义相对论中的应用。OGRePy建立在面向对象的架构之上，将张量、度量和坐标系封装为独立的自包含对象，自动处理指标的升降、坐标变换、收缩、偏导数或协变导数以及所有张量操作。通过利用SymPy和Jupyter Notebook的功能，OGRePy提供了一个健壮、用户友好的环境，有助于广义相对论和微分几何领域的研究和教学。这个Python软件包复制了流行的Mathematica软件包OGRe的功能，同时通过利用Python原生的面向对象语法大大改进了它。在本文中，我们描述了OGRePy的设计和实现，并讨论了其在数学和物理领域的研究和教育中的重用潜力。

</details>

[⬆️ 返回分类顶部](#gr-qc) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phga'></a>
## astro-ph.GA 

### [713] [Numerical Study of Bar Suppression in Galaxy Models Due to Disc Heating](https://arxiv.org/abs/2507.18083)
> *星系模型中由于盘加热引起的棒抑制的数值研究*

*Alejandro López Gómez, Ruslan Gabbasov, Isaura Luisa Fuentes-Carrera* | **Category: astro-ph.GA, cs.NA, math.NA** | **Updated: 2025-07-24**

**Keywords:** 星系棒抑制, 数值加热, N体模拟, 软化参数, 盘质量分数

**Comment:** Accepted for publication in the Galaxies journal. 34 pages (including
  references),12 figures and 2 tables

> **TL;DR:** 本研究通过N体模拟，探讨了软化参数和盘质量分数对星系棒形成和演化的综合影响，发现数值加热特别是小软化值会导致棒的抑制。

**AI_Comments:** 这项研究通过详细的N体模拟，深入探讨了数值参数（如软化参数）对星系棒动力学模拟结果的显著影响，揭示了数值加热可能导致棒的抑制，这对于理解和改进星系模拟的精度具有重要意义。它强调了在进行高分辨率星系动力学模拟时，需要仔细选择和校准数值参数，以避免引入虚假效应。

<details>
  <summary>Details</summary>

**Motivation:** 星系棒的形成、演化和破坏过程在星系动力学中仍存在争议，且数值模拟表明这些现象强烈依赖于物理和数值参数。

**Method:** 通过N体模拟，研究了孤立盘-晕模型中软化参数($\epsilon$)和盘质量分数($m_{\mathrm{d}}$)对棒形成和演化的综合影响，使用了不同的粒子分辨率。

**Result:** 先前的研究表明棒强度与$m_{\mathrm{d}}$呈$\propto m_{\mathrm{d}}^{-1}$关系，但畸变参数($\eta$)显示$m_{\mathrm{d}}$增加不总是导致棒形成延迟；$\epsilon$与$m_{\mathrm{d}}$相互作用，可能增强或削弱棒；在软化值较小的模型中，数值加热占主导地位，无论$m_{\mathrm{d}}$或分辨率如何，都会在盘中心产生高度加速的粒子；增强的粒子加速度在$\epsilon \leq 5\,$pc时产生混沌轨道，由于中心碰撞动力学导致棒被抑制；在高分辨率模型中，小的软化值无法重现棒不稳定性；对于中等$\epsilon$（$\geq 10\,$pc），增加$m_{\mathrm{d}}$会减少加速度剖面中的漂移量，但不影响棒的行为；较低$m_{\mathrm{d}}$值与小软化值结合的模型，有过量的高度加速粒子，给可靠的模拟引入了不必要的影响。

**Conclusion:** 盘的垂直加速度剖面演化是衡量由$\epsilon$和棒引入的数值加热的可靠指标。

> **ai_Abstract:** 本研究使用N体模拟探讨了软化参数($\epsilon$)和盘质量分数($m_{\mathrm{d}}$)对星系棒形成和演化的综合影响。研究发现，数值加热，尤其是在小$\epsilon$值下，会在盘中心产生高度加速粒子，导致混沌轨道和棒的抑制。高分辨率模型中，小$\epsilon$值无法重现棒不稳定性。研究还指出，盘的垂直加速度剖面是衡量数值加热的可靠指标。

> **摘要翻译:** 星系棒的形成、演化和破坏过程在星系动力学中仍然是一个有争议的话题。数值模拟表明这些现象强烈依赖于物理和数值参数。在这项工作中，我们通过不同粒子分辨率的N体模拟，研究了在孤立盘-晕模型中，软化参数$\epsilon$和盘质量分数$m_{\mathrm{d}}$对棒形成和演化的综合影响。先前的研究表明，棒强度与$m_{\mathrm{d}}$呈$\propto m_{\mathrm{d}}^{-1}$关系，这被视为棒形成的延迟。然而，衡量棒随时间动量的畸变参数$\eta$显示，$m_{\mathrm{d}}$的增加并不总是导致棒形成的延迟。这表明$\epsilon$和$m_{\mathrm{d}}$相互作用，以增强或削弱棒。此外，在软化值较小的模型中，数值加热占主导地位，无论$m_{\mathrm{d}}$或分辨率如何，都会在盘中心产生高度加速的粒子。这些增强的粒子加速度在$\epsilon \leq 5\,$pc时产生混沌轨道，由于中心碰撞动力学导致棒被抑制。在我们的高分辨率模型（$N \approx 10^{7}$）中，小的软化值无法重现棒不稳定性。盘质量的作用如下：对于中等$\epsilon$（$\geq 10\,$pc），增加$m_{\mathrm{d}}$会减少加速度剖面中的漂移量，而不影响棒的行为。较低$m_{\mathrm{d}}$值与小软化值结合的模型，有过量的高度加速粒子，给原本可靠的模拟引入了不必要的影响。最后，我们表明盘的垂直加速度剖面演化是衡量由$\epsilon$和棒引入的数值加热的可靠指标。

</details>

[⬆️ 返回分类顶部](#astro-phga) | [⬆️ 返回总目录](#toc)

---

<a id='q-fincp'></a>
## q-fin.CP 

### [733] [Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18577)
> *利用基础模型推进金融工程：进展、应用与挑战*

*Liyuan Chen, Shuoling Liu, Jiangpeng Yan, Xiaoyu Wang, Henglin Liu, Chuang Li, Kecheng Jiao, Jixuan Ying, Yang Veronica Liu, Qiang Yang, Xiu Li* | **Category: q-fin.CP, cs.AI, cs.LG** | **Updated: 2025-07-07**

**Keywords:** 金融基础模型, 金融工程, 基础模型, 综述, 人工智能

**Comment:** Under Review

> **TL;DR:** 本综述全面概述了金融基础模型（FFMs），包括其分类、架构、训练方法、数据集和实际应用，并指出了数据可用性、算法可扩展性和基础设施方面的挑战，展望了未来的研究机会。

**AI_Comments:** 这篇综述非常及时且重要，因为它系统地整理了新兴的金融基础模型领域。其创新之处在于提出了FFMs的明确分类，并深入探讨了其技术细节和实际应用。文章清晰地指出了当前面临的数据隐私、监管合规、数据可用性、可扩展性和基础设施等关键挑战，为未来的研究指明了方向，对于推动金融AI的发展具有重要的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 通用基础模型（如GPT-4和Gemini）在金融任务中表现出潜力，但金融应用的独特领域要求（如多模态推理、监管合规性、数据隐私）限制了其发展。这促使了专为金融领域设计的金融基础模型（FFMs）的出现，本研究旨在对FFMs进行全面概述。

**Method:** 本研究对金融基础模型（FFMs）进行了全面的综述，提出了一个涵盖金融语言基础模型（FinLFMs）、金融时间序列基础模型（FinTSFMs）和金融视觉语言基础模型（FinVLFMs）三种关键模态的分类法。研究回顾了它们的架构、训练方法、数据集和实际应用，并识别了数据可用性、算法可扩展性和基础设施方面的关键挑战。

**Result:** 综述提供了FFMs的全面分类，涵盖了FinLFMs、FinTSFMs和FinVLFMs三种模态。详细审查了它们的架构、训练方法、数据集和实际应用。同时，识别了数据可用性、算法可扩展性和基础设施方面的关键挑战，并提出了未来的研究机会。

**Conclusion:** 金融基础模型（FFMs）代表了金融工程领域的新前沿，本综述旨在为理解FFMs提供全面的参考，并为未来的创新提供实用的路线图，以克服当前挑战并利用新兴机遇。

> **ai_Abstract:** 本论文综述了金融基础模型（FFMs）在推进金融工程方面的进展、应用和挑战。鉴于通用基础模型在金融领域面临的独特限制，FFMs应运而生。文章提出了FFMs的分类法，包括金融语言、时间序列和视觉语言模型，并详细介绍了它们的架构、训练、数据集和实际应用。此外，论文还指出了数据、算法和基础设施方面的挑战，并展望了未来的研究方向，旨在为该领域提供全面的参考和发展蓝图。

> **摘要翻译:** 基础模型（FMs）——具有强大泛化能力的大规模预训练模型——的出现为金融工程开辟了新领域。虽然GPT-4和Gemini等通用基础模型在从金融报告摘要到情感感知预测等任务中都表现出令人鼓舞的性能，但许多金融应用仍受限于独特的领域要求，如多模态推理、监管合规性和数据隐私。这些挑战促使了金融基础模型（FFMs）的出现——一类专为金融设计的新模型。本综述全面概述了FFMs，其分类涵盖了三个关键模态：金融语言基础模型（FinLFMs）、金融时间序列基础模型（FinTSFMs）和金融视觉语言基础模型（FinVLFMs）。我们回顾了它们的架构、训练方法、数据集和实际应用。此外，我们还指出了数据可用性、算法可扩展性和基础设施方面的关键挑战，并提供了对未来研究机会的见解。我们希望本综述既能作为理解FFMs的全面参考，也能作为未来创新的实用路线图。FFM相关出版物和资源的最新集合将维护在我们的网站https://github.com/FinFM/Awesome-FinFMs上。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

### [749] [Alternative Loss Function in Evaluation of Transformer Models](https://arxiv.org/abs/2507.16548)
> *Transformer模型评估中的替代损失函数*

*Jakub Michańków, Paweł Sakowski, Robert Ślepaczuk* | **Category: q-fin.CP, cs.LG, q-fin.TR** | **Updated: 2025-07-24**

**Keywords:** 损失函数, Transformer模型, 量化金融, 均值绝对方向损失, LSTM模型

**Comment:** 12 pages, fixed grammar, typos and minor error in tables

> **TL;DR:** 本研究通过实证实验，将均值绝对方向损失（MADL）函数应用于Transformer模型，用于股票和加密货币资产的预测。结果显示，与LSTM模型相比，Transformer模型在几乎所有情况下都表现显著更好。

**AI_Comments:** 本文的创新点在于将均值绝对方向损失（MADL）函数应用于Transformer模型在量化金融领域的预测，并与LSTM模型进行了对比。研究结果强调了Transformer模型在金融预测中的优越性，并指出选择合适的损失函数对于模型性能的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习模型（尤其是在量化金融问题中的应用）的测试设计和架构至关重要，其中选择一个足够的损失函数用于训练、验证、估计和超参数调优是过程中最重要的方面。

**Method:** 通过对股票和加密货币资产进行实证实验，应用均值绝对方向损失（MADL）函数来优化用于算法投资策略的预测生成模型。将MADL函数的结果在Transformer和LSTM模型之间进行比较。

**Result:** Transformer模型的结果在几乎所有情况下都显著优于LSTM模型。

**Conclusion:** 均值绝对方向损失（MADL）函数更适合优化用于算法投资策略的预测生成模型，并且Transformer模型在该应用中表现优于LSTM模型。

> **ai_Abstract:** 本研究探讨了在量化金融领域中，为Transformer模型选择合适的损失函数的重要性。通过对股票和加密货币资产的实证实验，论文应用了均值绝对方向损失（MADL）函数，并将其与LSTM模型进行比较。结果表明，使用MADL函数的Transformer模型在预测性能上显著优于LSTM模型，强调了MADL在优化金融预测模型中的有效性。

> **摘要翻译:** 机器学习模型（尤其是在量化金融问题中的应用）的正确设计和架构至关重要。此过程中最重要的方面是为训练、验证、估计和超参数调优选择一个足够的损失函数。因此，在本研究中，通过对股票和加密货币资产进行实证实验，我们应用了均值绝对方向损失（MADL）函数，该函数更适合优化用于算法投资策略的预测生成模型。MADL函数的结果在Transformer和LSTM模型之间进行了比较，我们发现，在几乎所有情况下，Transformer模型的结果都显著优于LSTM模型。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phhe'></a>
## astro-ph.HE 

### [747] [On the Energy Distribution of the Galactic Center Excess' Sources](https://arxiv.org/abs/2507.17804)
> *关于银河系中心过剩源的能量分布*

*Florian List, Yujin Park, Nicholas L. Rodd, Eve Schoen, Florian Wolf* | **Category: astro-ph.HE, astro-ph.CO, astro-ph.IM, cs.LG, hep-ph** | **Updated: 2025-07-23**

**Keywords:** 银河系中心过剩, 伽马射线, 暗物质, 点源, 神经网络, 光谱分析

**Comment:** 7+20 pages, 2+20 figures, comments welcome

> **TL;DR:** 新研究使用神经网络结合空间和光谱数据分析银河系中心伽马射线过剩（GCE），发现如果GCE由点源组成，则需要远超预期的数量，或者GCE本质上是弥散的，这与暗物质假说更一致。

**AI_Comments:** 这篇论文通过引入光谱信息和先进的机器学习方法（神经网络辅助的模拟推理）来分析GCE，克服了以往研究的局限性，具有重要的创新性。其结果对GCE的起源提出了新的视角，即如果不是暗物质，那么点源的数量将远超预期，这对于理解GCE的本质具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 银河系中心过剩（GCE）是费米伽马射线空间望远镜发现的一个未解之谜。之前的分析在研究点源假说时受技术限制，仅限于空间分析，丢弃了光谱信息，因此无法有效区分GCE与复杂的背景天体物理辐射。

**Method:** 本文提出了一种神经网络辅助的基于模拟的推理方法，以克服技术限制，从而能够同时利用空间和光谱数据来检验GCE的点源解释。

**Result:** 引入能量信息后，推定的点源显著变暗。定量分析显示，对于最佳拟合背景模型，该过剩与暗物质预测的泊松发射基本一致。如果过剩是由点源引起的，中值预测为银河系中心约有 $10^5$ 个源，或在90%置信度下超过35,000个源。这些数量远大于早期点源分析所倾向的数百个源。

**Conclusion:** 结合空间和光谱数据分析GCE表明，GCE要么本质上是弥散的，要么由数量异常庞大的点源组成。这一发现使得GCE与暗物质的泊松发射预测更为一致，对传统的点源解释提出了挑战。

> **ai_Abstract:** 本文针对费米伽马射线望远镜发现的银河系中心过剩（GCE）进行了研究。与以往仅依赖空间分析不同，作者采用了一种神经网络辅助的模拟推理方法，首次将光谱信息纳入GCE的点源解释中。研究发现，结合能量信息后，如果GCE由点源构成，则这些点源必须非常暗且数量极其庞大（例如，中值预测为约10^5个源），远超此前分析的估计。这暗示GCE可能本质上是弥散的，或者其来源数量巨大，使得其与暗物质湮灭产生的泊松发射预测更为一致。

> **摘要翻译:** 银河系中心过剩（GCE）仍然是费米伽马射线空间望远镜揭示的决定性谜团之一。尽管它可能预示着湮灭暗物质的发现，但与这一结论相悖的是，分析表明其辐射的空间结构似乎与一组暗点源更一致。技术限制使得先前的分析纯粹在空间上研究点源假说。所有可能有助于将GCE与复杂且不确定的天体物理辐射区分开来的光谱信息都被丢弃了。我们证明，一种神经网络辅助的基于模拟的推理方法可以克服这些限制，从而利用空间和光谱数据来检验GCE的点源解释。这一补充意义深远：能量信息使得假定的点源显著变暗，表明GCE要么本质上是弥散的，要么由数量异常庞大的源组成。定量地，对于我们最佳拟合的背景模型，该过剩与暗物质预测的泊松发射基本一致。如果该过剩是由点源引起的，我们的中值预测是银河系中心有约 $\mathcal{O}(10^5)$ 个源，或者在90%置信度下超过35,000个源，这两者都显著大于早期GCE点源分析所倾向的数百个源。

</details>

[⬆️ 返回分类顶部](#astro-phhe) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [748] [Guessing sequences of eigenvectors for LMPs defining spectrahedral relaxations of Eulerian rigidly convex sets](https://arxiv.org/abs/2507.18434)
> *猜测定义欧拉刚性凸集的谱锥松弛的LMP特征向量序列*

*Alejandro González Nevado* | **Category: math.CO, cs.NA, math.NA, math.OC, 05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,
  90C23 (Secondary), G.2.1; G.1.2; G.1.3; G.1.5; G.1.6** | **Updated: 2025-07-24**

**Keywords:** 欧拉多项式, 谱锥松弛, 刚性凸集, 特征向量, 精度测量

**Comment:** 51 pages. Preprint extracted from a selection, rewrite and
  recombination of several sections and chapters from my PhD thesis. For more
  possible lines of research in these related directions, we direct the
  interested reader to arXiv:2503.04628 and to arXiv:2507.03800

> **TL;DR:** 该研究通过数值实验和特定的向量序列，提出了一种新的线性化方法，以提高欧拉刚性凸集谱锥松弛的对角线精度测量，并得到了更好的界限。

**AI_Comments:** 这篇论文的创新之处在于通过数值实验发现并利用了一个特定的向量序列进行线性化，从而显著提高了欧拉刚性凸集谱锥松弛的精度测量，并获得了指数级改善的界限。这种方法为优化高维几何对象的近似提供了新的视角和工具，具有重要的理论和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高欧拉刚性凸集谱锥松弛的近似精度，特别是对角线上的精度测量。

**Method:** 使用数值实验构建一个特定的向量序列，并通过该序列进行线性化处理，以改善对角线精度测量。具体使用了向量序列$\{(y,(-2^{m-i})_{i=3}^{m},(0,\frac{1}{2}),(1)_{i=1}^{m})\in\mathbb{R}^{n+1}\}_{n=1}^{\infty}$（对于偶数$n=2m$）。

**Result:** 本文建立了一个更好的（对角线）欧拉刚性凸集谱锥松弛的精度测量方法。通过这种方法获得的界限显著优于文献中以前的界限，其与已知界限的差异是一个增长的指数函数。

**Conclusion:** 通过数值实验和特定的向量序列线性化，本文成功地为欧拉刚性凸集的谱锥松弛建立了更精确的对角线测量方法，并获得了显著优于现有技术的界限。

> **ai_Abstract:** 本文研究了如何提高欧拉刚性凸集谱锥松弛的近似精度。通过使用数值实验构建并利用一个特定的向量序列进行线性化，本文提出了一种新的、更优的对角线精度测量方法。该方法获得的界限显著优于现有文献中的界限，尤其是在n趋于无穷大时，其与已知界限的差异呈指数增长，从而有效提升了近似精度。

> **摘要翻译:** 稳定的多元欧拉多项式由Brändén引入。通过特殊化某些变量，可以从中提取实零多元欧拉多项式。这些实零多元欧拉多项式可以用于构建谱锥松弛，从而提供对这些多项式定义的（欧拉）刚性凸集的近似。这些近似的精度通过对角线上的行为来衡量，通常的单变量欧拉多项式位于此处。特别是，从这个意义上讲，由谱锥松弛产生的全局谱锥近似的精度可以通过单变量欧拉多项式极端根的界限来衡量。由此获得的界限优于文献中以前发现的界限。然而，之前明确研究和获得的界限，其与已知界限的差异在n趋于无穷大时趋于0。在这里，我们使用数值实验来构建一个向量序列，提供一个（线性化）界限，其与先前已知界限的差是一个增长的指数函数（因此当n增长时快速趋于无穷大）。这使我们能够为欧拉刚性凸集的谱锥松弛建立一个更好的（对角线）精度测量。特别是，我们将通过向量序列$\{(y,(-2^{m-i})_{i=3}^{m},(0,\frac{1}{2}),(1)_{i=1}^{m})\in\mathbb{R}^{n+1}\}_{n=1}^{\infty}$（对于偶数n=2m）进行线性化来实现这一点。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

